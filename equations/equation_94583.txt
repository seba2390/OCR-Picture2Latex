\begin{align}E_1(\lambda, \xi, C) = \int_{\mathbb{R}}\eta_0(x|\xi, C) \cdot \left(\frac{\eta_0(x|\xi, C)}{\eta_1(x|\xi, C)}\right)^{\lambda} dx $ and $ E_2(\lambda, \xi, C) = \int_{\mathbb{R}}\eta_1(x|\xi, C) \cdot \left(\frac{\eta_1(x|\xi, C)}{\eta_0(x|\xi, C)}\right)^{\lambda} dx $. \begin{theorem}[Privacy of FL-TOP-DP] FL-TOP-DP is $(\min_\lambda (T_{\mathsf{cl}}\cdot \alpha (\lambda | C) - \log \delta) /\lambda, \delta)$-DP. \end{theorem} Given a fixed value of $\delta$, $\varepsilon$ is computed numerically as in \cite{Abadi,MironovTZ19}. The magnitude of the added Gaussian noise is proportional to the sensitivity $S$, which is in turn often proportional to the model size $n$ \cite{zhu2020votingbased}. Hence, when $n$ becomes large, SGD often fails to converge due to the perturbation error caused by the added noise \cite{zhu2020votingbased}. In our approach, the perturbation error is less since Gaussian noise is added to the compressed vector with size $m < n$. On the other hand, compression also induces some reconstruction error owing to its lossy nature. The total error is the sum of the reconstruction and the perturbation error and is quantified in Theorem \ref{thm:rip}. Finding the right trade-off between these two errors is the key to achieve good model quality. locally enough noise to its clipped L2-norm update such that the server fails to learn any client-specific information from the noisy update. However, this approach (aka, local differential privacy \cite{ErlingssonPK14}) needs so much perturbation making it impracticable especially if the number of clients $|\mathbb{K}|$ is limited. Fortunately, a better solution used in \cite{AcsC11,BonawitzIKMMPRS16,Hybrid-approach} adds the noise with a distributively manner at each client such that the aggregate is sufficiently noisy to have meaningful differential privacy. However, an adversary if he has access to any individual update, he can learn some client-specific information as each update is weakly-noised. To this purpose, individual noisy updates are encrypted with a simple and efficient encryption scheme from \cite{AcsC11,BonawitzIKMMPRS16} such that the adversary can access only the aggregate which is sufficiently noised to guarantee DP for any client. Note also that the non-private scheme can be used with encryption such that each client will send $\mathsf{Enc}_{K_k}(\mathcal{C}(\hat{\Delta \mbf{w}_{t}^{k}},\mbf{m}))$ instead of $\mathcal{C}(\hat{\Delta \mbf{w}_{t}^{k}},\mbf{m})$, which will allow the server to access only a non-encrypted aggregation $\sum_{k\in\mathbb{K}}\mathsf{Enc}_{K_k}(\hat{\mbf{c}_{t}^{k}})= \sum_{k\in\mathbb{K}} \hat{\mbf{c}_{t}^{k}} $, however we do not have any theoretically guarantee as provided by differential privacy to ensure that an adversary can not infer any information from the non-noisy aggregate. \begin{align*} \mathcal{C}( x_{1} + \cdots + x_{|\mathbb{K}|},m)= \mathcal{C}(x_{1},m) + \cdots + \mathcal{C}(x_{|\mathbb{K}|},m)\end{align}
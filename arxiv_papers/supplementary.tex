% Supplementary Material  ---------------------------------------
% Remember that this also needs to be blinded!

% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[12pt]{article}

% JASA margins
% DON'T change margins - should be 1 inch all around.
\addtolength{\oddsidemargin}{-.5in}%
\addtolength{\evensidemargin}{-1in}%
\addtolength{\textwidth}{1in}%
\addtolength{\textheight}{1.7in}%
\addtolength{\topmargin}{-1in}%

\addtolength{\textheight}{.5in}%
\addtolength{\textheight}{-.3in}%

% allow affiliations
\usepackage{authblk}
% Double spacing for draft paper, remove for tighter spacing
\usepackage{setspace}
% fancy W font
\usepackage{mathrsfs}
\doublespacing

% add in marginnotes
\usepackage{marginnote}
\reversemarginpar
% make margin notes small
\renewcommand\marginfont{%
        \normalfont\scriptsize
    }
% cheap way to disable margin notes
% redfine it so that it does nothing
\renewcommand{\marginnote}[2][]{}

\usepackage{graphicx}
% it seems that amsthm is the defualt, and most robust theorem package
\usepackage{amsmath, amssymb, amsthm}

% new theorem is created, whose counter is reset with every section
\newtheorem{theorem}{Theorem}[section]
% new corollary environemnt is created, whose counter resets with every call of 
% theorem
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}{Lemma}
\newtheorem{sublemma}{Lemma}[lemma]
\newtheorem{proposition}{Proposition}
% remarks are typically not numbered
\newtheorem{remark}{Remark}
\newtheorem{assump}{Assumption}
% this requires the use of the amssymb
\renewcommand\qedsymbol{$\blacksquare$}

% Customize tranpose macro here
\newcommand*{\tran}{\intercal}

\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Literature Review},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs

% Make margins larger so that marginnote works properly
%\usepackage[top=2cm, bottom=2cm, left=3cm, right=3cm, heightrounded, marginparwidth=2.5cm, marginparsep=3mm]{geometry}
\usepackage{longtable}
\usepackage{threeparttablex}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{tabularx}
\usepackage{makecell}
\usepackage{calc} % for calculating minipage widths
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi

% Setup hyperref so that you can use \autoref
\usepackage{hyperref}
% hyperref^\trans autoref is good, but apparently cleveref is even better
\usepackage{cleveref}
% Fix up plurals so that it works for assumptions
\crefname{assump}{Assumption}{Assumptions}
\Crefname{figure}{Figure}{Figures}

% JASA spacing
\def\spacingset#1{\renewcommand{\baselinestretch}%
{#1}\small\normalsize} \spacingset{1}

% enumerate package for customizing lists --------------------------------
\usepackage{bm}
% change font here
% \usepackage[charter]{mathdesign}
\usepackage[shortlabels]{enumitem}

% \usepackage[thmmarks, amsmath, thref]{ntheorem}

% Landscape
\usepackage{pdflscape}

\theoremstyle{plain}
% \theorembodyfont{\itshape}

%\theoremheaderfont{\itshape}

\numberwithin{equation}{section}

% Set watermark for DRAFT status 
% neither of my supervisors are happy about circulating the draft before 
% proper submission/release as a working paper
% \usepackage{draftwatermark}
% \SetWatermarkText{DRAFT}
% \SetWatermarkScale{1}

\usepackage{physics}
% uniquename = false gets rid of first names, apparently this is what Elsevier likes
\usepackage[style=apa,uniquename=false,uniquelist=false,eprint=false,url=false,annotation=false]{biblatex}
\DeclareDelimFormat{nameyeardelim}{\addcomma\space}
% not sure why, but only bibtex format works, 
% even thouygh I tried to specify biblatex
\addbibresource{references2.bib}

% Add some custome enumitem propositions, lemmas, theorems, etc
\newlist{propenum}{enumerate}{1} % also creates a counter called 'propenumi'
\setlist[propenum]{label=(\alph*), ref=extcheproposition~(\alph*)}
\crefalias{propenumi}{proposition} 

\newlist{lemenum}{enumerate}{1} % also creates a counter called 'propenumi'
\setlist[lemenum]{label=(\alph*), ref=\thelemma~(\alph*)}
\crefalias{lemenumi}{lemma} 

\newlist{thmenum}{enumerate}{1} % also creates a counter called 'propenumi'
\setlist[thmenum]{label=(\alph*), ref=\thetheorem~(\alph*)}
\crefalias{thmenumi}{theorem} 

\newlist{assumpenum}{enumerate}{1} % also creates a counter called 'propenumi'
\setlist[assumpenum]{label=(\alph*), ref=\theassump~(\alph*)}
\crefalias{assumpenumi}{assump} 

\usepackage{xr}
\externaldocument[ext:]{main_paper}
\pdfminorversion=4

%% Begin Documents ======================================================
% For the purposes of anonymization, we will need to get rid of the \href email

%\footnote{We thank Xu Han and Fa Wang for making their code available.}}
%\author{Bonsoo Koo \thanks{Department of Econometrics and Business Statistics, Monash University, Melbourne, Australia. Email: \href{mailto:bonsoo.koo@monash.edu}{bonsoo.koo@monash.edu}}}
%\author{Benjamin Wong \thanks{Department of Econometrics and Business Statistics, Monash University, Melbourne, Australia. Email: \href{mailto:benjamin.wong@monash.edu}{benjamin.wong@monash.edu}}}
%\author{\anonymize{Ze Yu Zhong} \thanks{
%\anonymize{Corresponding author. Department of Econometrics and Business Statistics, Monash University, Melbourne, Australia. Email:
%\href{mailto:ze.zhong@monash.edu}{ze.zhong@monash.edu}}}}



% Some other notes
% The pseudo factors comment is very confusing for people outisde of the liteature
% but is necessary...
% Referee may also ask why I did not use Wolf and Romano bootstraps to combine tests, etc (unclear how to implement for this setting, bad performance, and computational intensity)

% EXECUTIVE DECISION
% Combine the assumptions together, and assume that hte loadings are random throughout the entire paper

\begin{document}

% JASA Blinding
% Adjust the numebr here to turn on/off blinding
\newcommand{\blind}{1}

\if1\blind
{
  \title{\bf Supplementary Material for Disentangling Structural Breaks in High Dimensional Factor Models \thanks{We acknowledge that this research was supported in part by the Monash eResearch Centre and eSolutions Research Support Services through the use of the MonARCH HPC Cluster.} \thanks{We acknowledge the financial support of the Australian Research Council under Grants LP160101038, DP210101440, and DE200100693.} \thanks{We thank Xu Han and Fa Wang for making their code available, in addition to the comments by Xu Han, Daniele Massacci, Mirco Rubin, Matteo Barigozzi, Serena Ng, and other participants at the 2022 EC-squared conference.}}
\author{Bonsoo Koo \thanks{Department of Econometrics and Business Statistics, Monash University, Melbourne, Australia and Centre for Applied Macroeconomic Analysis, Australian National University Email: bonsoo.koo@monash.edu}}
\author{Benjamin Wong \thanks{Department of Econometrics and Business Statistics, Monash University, Melbourne, Australia and Centre for Applied Macroeconomic Analysis, Australian National University. Email: benjamin.wong@monash.edu}}
\author{Ze Yu Zhong \thanks{
Corresponding author. Department of Econometrics and Business Statistics, Monash University, Melbourne, Australia. Email:
ze.zhong@monash.edu}}
  \affil{Monash University}
	% Add date that the document was compiled
  \date{Dated: Feb. 2023}
  \maketitle
} \fi

\if0\blind
{
  \bigskip
  \bigskip
  \bigskip
  \begin{center}
    {\LARGE\bf Supplementary Material for Disentangling Structural Breaks in High Dimensional Factor Models}
\end{center}
  \medskip
} \fi

\bigskip

\vfill

%% Declare Macros -------------------------------------------------------

% Basic statistics
\newcommand{\convp}{\overset{p}{\to}}
\newcommand{\convd}{\overset{d}{\to}}
\newcommand{\limN}{\lim_{N \to \infty}}
\newcommand{\limT}{\lim_{T \to \infty}}
\newcommand{\plim}{\operatorname{plim}}
\newcommand{\plimT}{\operatorname{plim}_{T \to \infty}}
\newcommand{\plimN}{\operatorname{plim}_{N \to \infty}}
\newcommand{\plimNT}{\operatorname{plim}_{N,T \to \infty}}
% Fractions
\newcommand{\fracT}{\frac{1}{T}}
\newcommand{\fracTone}{\frac{1}{T_1}}
\newcommand{\fracTtwo}{\frac{1}{T_2}}
\newcommand{\fracTm}{\frac{1}{T_m}}
\newcommand{\fracN}{\frac{1}{N}}
\newcommand{\fracTN}{\frac{1}{TN}}

% Sums
\newcommand{\sumT}{\sum_{t = 1}^{T}}
\newcommand{\sumTs}{\sum_{s = 1}^{T}}
\newcommand{\sumTj}{\sum_{j = 1}^{T}}
\newcommand{\sumN}{\sum_{i = 1}^{N}}
\newcommand{\sumNj}{\sum_{j = 1}^{N}}
\newcommand{\sumNk}{\sum_{k = 1}^{N}}

\newcommand{\ceil}[1]{\left \lceil #1 \right \rceil }
\newcommand{\floor}[1]{\left \lfloor #1 \right \rfloor }
\newcommand{\sumTfloor}{\sum_{t = 1}^{\floor{\pi T}}}
\newcommand{\sumTfloort}{\sum_{t = \floor{\pi T + 1}}^{T}}

\newcommand{\sumTfloors}{\sum_{s = 1}^{\floor{\pi T}}}
\newcommand{\sumTfloorts}{\sum_{s = \floor{\pi T + 1}}^{T}}
% \newcommand{\rank}[1]{\operatorname{rank} #1 }
\newcommand{\gt}{>}
\newcommand{\lt}{<}

% Op term macros
\newcommand{\Opdelta}{O_p\left( \frac{1}{\delta_{NT}}\right) }
\newcommand{\Opdeltasq}{O_p\left( \frac{1}{\delta_{NT}^2}\right)}
\newcommand{\Opdeltaquart}{O_p\left( \frac{1}{\delta_{NT}^4}\right)}

\newcommand{\OprtTdeltasq}{O_p\left( \frac{\sqrt{T}}{\delta_{NT}^2}\right)}
\newcommand{\OprtNdeltasq}{O_p\left( \frac{\sqrt{N}}{\delta_{NT}^2}\right)}

\newcommand{\OprtT}{O_p\left( \frac{1}{\sqrt{T}}\right)}
\newcommand{\OprtN}{O_p\left( \frac{1}{\sqrt{N}}\right)}
\newcommand{\OpT}{O_p\left( \frac{1}{T}\right)}
\newcommand{\OpN}{O_p\left( \frac{1}{N}\right)}
% General Op macro for anything arbitrary
\newcommand{\Op}[1]{O_p \left( #1 \right) }

% Indicator function
\newcommand{\indicator}[1]{\mathbf{1} \left\lbrace #1 \right\rbrace }

% Abstract ---------------------------------------------------------------
% Bonsoo says introduction could be a little longer
% but Ben says skimming through this it is good for a conference submission already
% Bonsoo thinks there is no discussion of the use of break points, by earlier results
% also, need to differentiate our appraoch from existing ones (Bonsoo still thinks it is not clear enough)

% Bonsoo says to disregard strict apa style (putting first name letter for disambiguity)
% not sure how to implement this...
\newpage
\spacingset{1.9} % DON'T change the spacing!
\section{Appendix}
\subsection{Proofs}
% not sure if anything is required here. Han and Inoue reproduce the main asymptotic exapnsion fot he 4 terms for convenience
First, recall that $V_{NT, 1}, V_{NT, 2}$ are the $r \times r$ diagonal matrices of the first $r$ largest eigenvalues of the matrices $\frac{1}{T_1 N} X_1 X_1^\tran$ and $\frac{1}{T_2 N} X_2 X_2^\tran$ respectively. The estimated factor matrices $\tilde{F}_1, \tilde{F}_2$ are $\sqrt{T_1}, \sqrt{T_2}$ times the eigenvectors corresponding to the $r$ largest eigenvalues of $X_1 X_1^\tran$ and $X_2 X_2^\tran$ respectively, we denote $T_1 = \floor{\pi T}$ and $T_2 = T - \floor{\pi T}$ for brevity. We therefore have for $m = 1, 2$
\begin{align*}
\frac{1}{NT_m} X_m X_m^\tran \tilde{F}_m = \tilde{F}_m V_{NT, m} \\
\frac{1}{NT_m} X_m X_m^\tran \tilde{F}_m V_{NT, m}^{-1} = \tilde{F}_m.
\end{align*}
Let $\delta_{NT} = \operatorname{min}\left\lbrace \sqrt{N}, \sqrt{T} \right\rbrace$. Using $X_m = F_m \Lambda_m^\tran + e_{(m)}$ gives:
\begin{align}
\frac{1}{N T_m}(
F_m \Lambda_m^\tran \Lambda_m F_m^\tran + F_m \Lambda_m^\tran e_{(m)}^\tran + e_{(m)} \Lambda_m f_m^\tran + e_{(m)} e_{(m)}^\tran) \tilde{F}_m V_{NT, m}^{-1} = \tilde{F}_m.
\end{align}
Using the fact that $H_m = (\Lambda_m^\tran \Lambda_m/N)(F_m^\tran \tilde{F}_m/T_m)V_{NT, m}^{-1}$ yields:
\begin{align}
\tilde{F}_m - F_m H_m = 
&\frac{1}{N T_m} \left(
F_m \Lambda_m^\tran e_{(m)}^\tran \tilde{F}_m + 
e_{(m)} \Lambda_m F_m^\tran \tilde{F}_m + 
e_{(m)} e_{(m)}^\tran \right) V_{NT, m}^{-1}, \\
\label{eqn:bai_four_terms}
\tilde{f}_{m, t} - H_m^\tran f_t = V_{NT, m}^{-1} & \left(
\frac{1}{T_m} \sumTs \tilde{f}_{m, s} \gamma_N(s, t) \iota_{mt} + 
\frac{1}{T_m} \sumTs \tilde{f}_{m, s} \zeta_{st} \iota_{mt} \right. \\
& + \left. \frac{1}{T_m} \sumTs \tilde{f}_{m, s} \eta_{m, st} \iota_{mt} +
\frac{1}{T_m} \sumTs \tilde{f}_s \xi_{m, st} \iota_{mt}
\right) \nonumber
\end{align}
where $\zeta_{st} = \frac{e_s^\tran e_t}{N} - \gamma_N(s, t), \eta_{m, st} = f_s^\tran \Lambda_m^\tran e_t / N$ and $\xi_{m, st} = f_t^\tran \Lambda_m^\tran e_s/N$.

\subsection{Lemmas}
% This is currently a mess, need to clean up
% not sure whether to have existing results here or later...
% Not sure if thios is necessary...
%The following are from \textcite{bai_simpler_2020}.
%\begin{lemma}
%\label{lem:f_e}
%Under Assumption, the following hold:
%\begin{align}
%\frac{1}{T} \frac{F^\tran e e^\tran F}{NT} &= 
%\frac{1}{NT} \sumN 
%\left[ \left( \frac{1}{\sqrt{T}} \sumT f_t e_{it} \right) 
%\left( \frac{1}{\sqrt{T}} \sumT f_t e_{it} \right)^\tran \right] = \OpT \\
%\frac{1}{N} \frac{\Lambda^\tran e^\tran e \Lambda}{NT} &=
%\frac{1}{NT} \sumN 
%\left[ \left( \frac{1}{\sqrt{N}} \sumN \Lambda_i e_{it} \right) 
%\left( \frac{1}{\sqrt{N}} \sumN \Lambda_i e_{it} \right)^\tran \right] = \OpN.
%\end{align}
%\end{lemma}
We first present some lemmas from \textcite{bai_inferential_2003}, stated for convenience. 
\marginnote[moved iota to inside the norms for consistency]{right}
\begin{lemma}
For $m = 1, 2$:
\label{lem:bai_inf}
\begin{lemenum}
% Bai A.1
\item \label{lem:bai_inf:1:A1} Under \Cref{ext:ass:1_factors,ext:ass:2_loadings,ext:ass:3_errors,ext:ass:4_ind_groups}, 
$\fracTm \sumT \norm{\left( \tilde{f}_{m, t} - H_m^\tran f_t \right)  \iota_{mt}}^2 = \Opdeltasq$.
\item \label{lem:bai_inf:1:A1:loadings} Under \Cref{ext:ass:1_factors,ext:ass:2_loadings,ext:ass:3_errors,ext:ass:4_ind_groups}, 
$\fracN \sumN \norm{ \tilde{\lambda}_{m, i} - H_m^{-\tran} \lambda_{m, i} } = \Opdeltasq$.
% Bai B.1
\item \label{lem:bai_inf:2:B1} Under \Cref{ext:ass:1_factors,ext:ass:2_loadings,ext:ass:3_errors,ext:ass:4_ind_groups,ext:ass:5_error_corr,ext:ass:6_moments}, 
$\frac{1}{T_m} (\tilde{F}_m - F_m H_m)^\tran e_{m, i} = \Opdeltasq$.
% Bai B.2
\item \label{lem:bai_inf:3:B2} Under \Cref{ext:ass:1_factors,ext:ass:2_loadings,ext:ass:3_errors,ext:ass:4_ind_groups,ext:ass:5_error_corr,ext:ass:6_moments}, 
$\frac{1}{T_m} (\tilde{F}_m - F_m H_m)^\tran F_m = \Opdeltasq$.
% Bai B.3
\item \label{lem:bai_inf:4:B3} Under \Cref{ext:ass:1_factors,ext:ass:2_loadings,ext:ass:3_errors,ext:ass:4_ind_groups,ext:ass:5_error_corr,ext:ass:6_moments}, 
$\frac{1}{T_m} (\tilde{F}_m - F_m H_m)^\tran \tilde{F}_m = \Opdeltasq$.
% Bai A.3
\item \label{lem:bai_inf:5:A3} Under  \Cref{ext:ass:1_factors,ext:ass:2_loadings,ext:ass:3_errors,ext:ass:4_ind_groups}, 
$\norm{H_m} = \Op{1}$
% Bai Prop 1
\item \label{lem:bai_inf:6:Prop1} Under \Cref{ext:ass:1_factors,ext:ass:2_loadings,ext:ass:3_errors,ext:ass:4_ind_groups,ext:ass:7_eigen_distinct}, 
$\plim \left( \frac{\tilde{F}_m^\tran F_m}{T_m}\right)  = H_{0, m}^{-1}$.
\end{lemenum}
\end{lemma}
\Cref{lem:bai_inf:1:A1,lem:bai_inf:2:B1,lem:bai_inf:3:B2,lem:bai_inf:4:B3,lem:bai_inf:5:A3,lem:bai_inf:6:Prop1} are just the subsample counterparts of Lemmas A.1, B.1, B.2, B.3, A.3 and Proposition 1 of \textcite{bai_inferential_2003} respectively. \Cref{lem:bai_inf:1:A1:loadings} follows from \Cref{lem:bai_inf:1:A1} via symmetry.
% Not sure how much commenting I need on this
% \Cref{lem:bai_inf:5} is an implication of \Cref{lem:bai_inf:2}.

% May be safe to move this to just before the Z test rotation section, becuase I don't recall using these in the estimation proofs
Next, we similarly some lemmas from \textcite{han_tests_2015} for convenience.
\begin{lemma}
\label{lem:han_lem}
For $m = 1, 2$:
\begin{lemenum}
\item \label{lem:han_lem:1}
under \Cref{ext:ass:1_factors,ext:ass:2_loadings,ext:ass:3_errors,ext:ass:4_ind_groups}, 
$\fracT \sumT \norm{\tilde{f}_{m, t} \iota_{mt}}^4 = \Op{1}$, and $\fracT \sumT \norm{\tilde{f}_{m, t} - H^\tran_m f_{m, t}\iota_{mt} }^4 = \Op{\frac{1}{T}} + \Op{\frac{1}{N^2}}$.
\item \label{lem:han_lem:2}
under \Cref{ext:ass:1_factors,ext:ass:2_loadings,ext:ass:3_errors,ext:ass:4_ind_groups,ext:ass:5_error_corr}, $\frac{1}{T_m} \sumT \norm{
(\tilde{f}_{m, t} - H_m^\tran f_{m, t})
\iota_{mt} }^4 \iota_{mt} = \Opdeltaquart$.
\item \label{lem:han_lem:3}
under \Cref{ext:ass:1_factors,ext:ass:2_loadings,ext:ass:3_errors,ext:ass:4_ind_groups}, 
$\frac{1}{T_m} \sumT \norm{\tilde{f}_{m, t}\iota_{mt} }^4 = \Op{1}$.
\item \label{lem:han_lem:4}
under \Cref{ext:ass:1_factors,ext:ass:2_loadings,ext:ass:3_errors,ext:ass:4_ind_groups,ext:ass:5_error_corr,ext:ass:6_moments,ext:ass:7_eigen_distinct},
$\norm{H_m - H_{m, 0}} = \Opdelta$.
\item \label{lem:han_lem:loadings}
under 
\Cref{ext:ass:1_factors,ext:ass:2_loadings,ext:ass:3_errors,ext:ass:4_ind_groups} $\fracN \sumN \norm{\tilde{\lambda}_{m, i} - H_m^{-1} \lambda_{m, i}}^4 = \Opdeltaquart$
\end{lemenum}
\end{lemma}
\Cref{lem:han_lem:1,lem:han_lem:2,lem:han_lem:3,lem:han_lem:3,lem:han_lem:4} are just the subsample counterparts of Lemmas 5.i), 5.ii), 5.iii) and 6 of \textcite{han_tests_2015}. \Cref{lem:han_lem:loadings} is not explicitly proved but follows by symmetry from \Cref{lem:han_lem:2}.  

% Consistency Proofs -------------------------------------------------
\subsection{Consistency Proofs}
% Consistency Proofs

% These need to be cleaned up with proper assumptions
% Add brakcets to all the fractions to make it look nicer and easier to follow along
% make this much more comprehensive, becauise Bonsoo finds it confusing
\begin{proof}[Proof of Theorem \ref{ext:thm:1:Ztilde_consistency}]
By the definition of $\tilde{Z}$, we have:
\begin{align*}
\tilde{Z} &= 
\left( \tilde{\Lambda}_1^\tran \tilde{\Lambda}_1\right)^{-1} \tilde{\Lambda}_1^\tran \tilde{\Lambda}_2 \\
&= \frac{1}{N}V_{NT, 1}^{-1} \frac{1}{T_1}(\tilde{F}_1^\tran X_1)^\tran  \frac{1}{T_2} (\tilde{F}_2^\tran X_2),
\end{align*}
because for $m = 1, 2$, $\tilde{\Lambda}_m^\tran \tilde{\Lambda}_m/N = V_{NT, m}$ by eigen-identity, and $\Lambda_{m}^\tran = (\tilde{F}_m^\tran \tilde{F})^\tran \tilde{F}^\tran X_m = \frac{1}{T_m} \tilde{F}_m^\tran X_m$ via a least squares fit. Therefore
\begin{align*}
\tilde{Z} = &V_{NT, 1}^{-1} \frac{1}{N T_1 T_2} 
\left( 
	\tilde{F}_1^\tran F_1 \Lambda_1^\tran + \tilde{F}_1^\tran e_1
\right) 
\left( 
	\tilde{F}_2^\tran F_2 Z^\tran \Lambda_1^\tran + \tilde{F}_2^\tran F_2 W^\tran + \tilde{F}_2^\tran e_{(2)}
\right)^\tran \\
= &V_{NT, 1}^{-1} \frac{1}{N T_1 T_2}  \left( 
\tilde{F}_1^\tran F_1 \Lambda_1^\tran e_{(2)}^\tran \tilde{F}_2 +
\tilde{F}_1^\tran F_1 \Lambda_1^\tran W F_2^\tran \tilde{F}_2 +
\tilde{F}_1^\tran F_1 \Lambda_1^\tran \Lambda_1 Z F_2^\tran \tilde{F}_2 \right. \\
&+ \left. \tilde{F}_1^\tran e_{(1)} e_{(2)}^\tran \tilde{F}_2 +
\tilde{F}_1^\tran e_{(1)} W F_2^\tran \tilde{F}_2 +
\tilde{F}_1^\tran e_{(1)} \Lambda_1 Z F_2^\tran \tilde{F}_2
\right) \\
= &V_{NT, 1}^{-1} (Z.I + Z.II + Z.III + Z.IV + Z.V + Z.VI)
\end{align*}
We shall see that $Z.III$ characterises the convergence behaviour, and $Z.I, Z.II, Z.IV, Z.V, Z.VI$ are all asymptotically negligible.

\begin{lemma}
\label{lem:ztilde_consistency_z}
Under \Cref{ext:ass:1_factors,ext:ass:2_loadings,ext:ass:3_errors,ext:ass:4_ind_groups,ext:ass:5_error_corr,ext:ass:6_moments,ext:ass:8_break_fraction}
\begin{lemenum}
\item \label{lem:ztilde_consistency_z:1} 
$Z.I = \Opdeltasq$
\item \label{lem:ztilde_consistency_z:2}
$Z.II = 0$
\item \label{lem:ztilde_consistency_z:4}
$Z.IV = \Opdeltasq$
\item \label{lem:ztilde_consistency_z:5}
$Z.V = \Opdeltasq$
\item \label{lem:ztilde_consistency_z:6}
$Z.VI = \Opdeltasq$
\end{lemenum}
\end{lemma}
% z_1 lemma
Proof of \Cref{lem:ztilde_consistency_z:1}:
\begin{align*}
Z.I &= 
\frac{\tilde{F}_1^\tran F_1 \Lambda_1^\tran e_{(2)}^\tran \tilde{F}_2}{N T_1 T_2} \\
&= \frac{\tilde{F}_1^\tran F_1 \Lambda_1^\tran e_{(2)}^\tran (\tilde{F}_2 - F_2 H_2)}{T_1 N T_2} + \frac{\tilde{F}_1^\tran F_1 \Lambda_1^\tran e_{(2)}^\tran F_2 H_2}{T_1 N T_2} \\
&\leq \norm{\frac{\tilde{F}_1^\tran F_1}{T_1}} 
\norm{\frac{\Lambda_1^\tran e_{(2)}^\tran}{N \sqrt{T_2}}} 
\norm{\frac{\tilde{F}_2 - F_2 H_2}{\sqrt{T_2}}} + 
\norm{\frac{\tilde{F}_1^\tran F_1}{T_1}} 
\norm{\frac{\Lambda_1^\tran e_{(2)}^\tran F_2}{N T_2}} 
\norm{H_2} \\
&= O_p(1) \OprtN \Opdelta + 
O_p(1) \Opdeltasq O_p(1) \\
&= \Opdeltasq,
\end{align*}
because of \Cref{lem:bai_inf:6:Prop1,ext:ass:3_errors,ext:ass:6_moments,lem:bai_inf:3:B2,ext:ass:1_factors,lem:bai_inf:5:A3} respectively.

% z_2 lemma
Proof of \Cref{lem:ztilde_consistency_z:2}:
\begin{align*}
Z.II &= \frac{\tilde{F}_1^\tran F_1 \Lambda_1^\tran W F_2^\tran \tilde{F}_2}{N T_1 T_2} \\
&= 0,
\end{align*}
because $\Lambda_1^\tran W = 0$.

% z_4 lemma
Proof of \Cref{lem:ztilde_consistency_z:4}
\begin{align*}
Z.IV
&= \frac{\tilde{F}_1^\tran e_{(1)} e_{(2)}^\tran \tilde{F}_2}{N T_1 T_2} \\
&= \frac{(\tilde{F}_1 - F_1 H_1)^\tran}{T_1} 
\frac{e_{(1)} e_{(2)}^\tran}{N} 
\frac{(\tilde{F}_2 - F_2 H_2)}{T_2} +
\frac{(F_1 H_1)^\tran}{T_1} 
\frac{e_{(1)} e_{(2)}^\tran}{N} 
\frac{(\tilde{F}_2 - F_2 H_2)}{T_2} + \\
&\quad 
\frac{(\tilde{F}_1 - F_1 H_1)^\tran}{T_1} 
\frac{e_{(1)} e_{(2)}^\tran}{N} 
\frac{(F_2 H_2)}{T_2} +
\frac{(F_1 H_1)^\tran}{T_1} 
\frac{e_{(1)} e_{(2)}^\tran}{N} 
\frac{(F_2 H_2)}{T_2} \\
&= Z.IV.a + Z.IV.b + Z.IV.c + Z.IV.d.
\end{align*}
Analysing each of the four terms above, we have:
\begin{enumerate}
\item 
% z_4 sublemmas
% z_4a
\begin{align*}
\norm{Z.IV.a} 
&\leq 
\norm{\frac{(\tilde{F}_1 - F_1 H_1)}{\sqrt{T_1}}} 
\norm{\frac{e_{(1)} e_{(2)}^\tran}{\sqrt{T_1} \sqrt{T_2}N}} 
\norm{\frac{(\tilde{F}_2 - F_2 H_2)}{\sqrt{T_2}}} \\
&= \Opdelta \Opdelta \Opdelta = \Op{\frac{1}{\delta_{NT}^3}},
\end{align*}
by \Cref{lem:bai_inf:1:A1,ext:ass:3_errors,lem:bai_inf:1:A1},
% z_4b
\item 
\begin{align*}
\norm{Z.IV.b} 
&\leq 
\norm{\frac{(F_1 H_1)}{\sqrt{T_1}}}
\norm{\frac{e_{(1)} e_{(2)}^\tran}{\sqrt{T_1} \sqrt{T_2}N}}
\norm{\frac{(\tilde{F}_2 - F_2 H_2)}{\sqrt{T_2}}} \\
&= \Op{1} \Opdelta \Opdelta = \Opdeltasq,
\end{align*}
by \Cref{ext:ass:1_factors,lem:bai_inf:5:A3,ext:ass:3_errors,lem:bai_inf:1:A1},
% z_4c
\item 
\begin{align*}
\norm{Z.IV.c} 
&\leq
\norm{\frac{(\tilde{F}_1 - F_1 H_1)}{\sqrt{T_1}} }
\norm{\frac{e_{(1)} e_{(2)}^\tran}{\sqrt{T_1} \sqrt{T_2} N} }
\norm{\frac{(F_2 H_2)}{\sqrt{T_2}}} \\
&= \Opdelta \Opdelta \Op{1} = \Opdeltasq,
\end{align*}
by \Cref{lem:bai_inf:1:A1,ext:ass:3_errors,ext:ass:1_factors,lem:bai_inf:5:A3},
% z_4d 
\item 
\begin{align*}
\norm{Z.IV.d} 
&\leq
\norm{H_1}
\norm{\frac{F_1^\tran e_{(2)}^\tran}{T_1 \sqrt{N}} }
\norm{\frac{e^\tran F_2}{T_2 \sqrt{N}}}
\norm{H_2} \\
&= \Op{1} \OprtT \OprtT \Op{1} = \Opdeltasq,
\end{align*}
by \Cref{lem:bai_inf:5:A3,ext:ass:6_moments,lem:bai_inf:6:Prop1,lem:bai_inf:5:A3}.
Therefore, $Z.IV = \Opdeltasq$.
\end{enumerate}

% z_5 lemma
Proof of \Cref{lem:ztilde_consistency_z:5}:
\begin{align*}
Z.V
&= 
\frac{\tilde{F}_1^\tran}{T_1} 
\frac{e_{(1)} W}{N} 
\frac{F_2^\tran \tilde{F}_2}{T_2} \\
&\leq 
\norm{\frac{(\tilde{F}_1 - F_1 H_1)}{\sqrt{T_1}}}
\norm{\frac{e_{(1)} W}{N \sqrt{T_1}} }
\norm{\frac{F_2^\tran \tilde{F}_2}{T_2}} +
\norm{H}
\norm{\frac{F_1^\tran e_{(1)} W}{T_1 N}}
\norm{\frac{F_2^\tran \tilde{F}_2}{T_2}} \\
&= \Opdelta \OprtN \Op{1} + \Op{1} \Opdeltasq \Op{1} \\
&= \Opdeltasq,
\end{align*}
because of \Cref{lem:bai_inf:1:A1,ext:ass:3_errors,lem:bai_inf:5:A3,lem:bai_inf:6:Prop1}. Note that $\norm{\frac{e_{(1)} W}{N \sqrt{T_1}}} = \OprtN$ is implied by \Cref{ext:ass:2_loadings}, because $\norm{W} = \norm{\Lambda_2 - \Lambda_1 Z} \leq \norm{\Lambda_2}$.

% z_6 lemma
Proof of \Cref{lem:ztilde_consistency_z:6}:
\begin{align*}
Z.VI
&= 
\frac{\tilde{F}_1^\tran}{T_1} 
\frac{e_{(1)} \Lambda_1 Z}{N} 
\frac{F_2^\tran \tilde{F}_2}{T_2} \\
&\leq 
\norm{\frac{(\tilde{F}_1 - F_1 H_1)}{\sqrt{T_1}}}
\norm{\frac{e_{(1)} \Lambda_1}{N \sqrt{T_1}} }
\norm{Z}
\norm{\frac{F_2^\tran \tilde{F}_2}{T_2}} +
\norm{H}
\norm{\frac{F_1^\tran e_{(1)} \Lambda_1}{T_1 N}}
\norm{Z} 
\norm{\frac{F_2^\tran \tilde{F}_2}{T_2}} \\
&= \Opdelta \OprtN \Op{1} \Op{1} + \Op{1} \Opdeltasq \Op{1} \Op{1} \\
&= \Opdeltasq,
\end{align*}
because of \Cref{lem:bai_inf:1:A1,ext:ass:3_errors,lem:bai_inf:5:A3,lem:bai_inf:6:Prop1}, and because $\norm{Z} \lt \infty$ is implied by \Cref{ext:ass:2_loadings}.

Therefore, combining the terms above together, we have:
\begin{align*}
\tilde{Z} &= 
V_{NT}^{-1} \left( \frac{\tilde{F}_1^\tran F_1}{T_1} \right) 
\left( \frac{\Lambda_1^\tran \Lambda_1}{N} \right) Z
\left( \frac{F_2^\tran \tilde{F}_2}{T_2} \right) + 
\Opdeltasq \\
&= H_1^\tran Z
\left( \frac{F_2^\tran \tilde{F}_2}{T_2} \right) + 
\Opdeltasq
\end{align*}
\textcite{bai_simpler_2020} consider asymptotically equivalent rotation matrices, and show that:
$\frac{\tilde{F}_2^\tran F_2}{T_2} = H_2^{-\tran} + \Opdeltasq$. This 
then implies the required result.
\end{proof}

\begin{proof}[Proof of \Cref{ext:thm:2:Z_consistency}]
Theorem 1 of \textcite{bai_inferential_2003} shows that
\begin{align*}
\norm{
	\tilde{f}_{2, t} - H_2^\tran f_{2t} = o_p(1)
},
\end{align*}
if $\frac{\sqrt{N}}{T} \to 0$. \Cref{ext:thm:1:Ztilde_consistency} shows that $\norm{\tilde{Z} - H_1 Z H_2^{-\tran}} = \Opdeltasq$, and because $V_{NT, 1}, H_1, H_2$ all converge to positive definite matrices by \Cref{lem:bai_inf:5:A3}, $\tilde{Z}$ is $\Op{1}$. Therefore, pre-multiplying and adding and subtracting gives
\begin{align*}
\tilde{Z} \tilde{f}_{2, t} - 
H_1^\tran Z H_2^{-\tran} H_2^\tran f_{2t} &= o_p(1) \\
\tilde{Z} \tilde{f}_{2, t} - 
H_1^\tran Z f_{2t} &= o_p(1).
\end{align*}
\end{proof}

\begin{proof}[Proof of \Cref{ext:cor:Z_cor}]
The proof of \Cref{ext:cor:Z_cor} follows directly from the fact that $\tilde{f}_{1, t}$ consistently estimates $H_1 f_{t}$, and $\tilde{f}_{2, t}$ consistently estimates $H_2^\tran f_{t}$ by Section 2 of  \textcite{bai_inferential_2003}. Because $H_1 \convp H_{0, 1}$ and $H_2 \convp H_{0, 2}$, $\tilde{Z} \tilde{f}_{(2), t}$ converges to $H_{0, 1}^\tran Z f_t$ in light of \Cref{ext:thm:2:Z_consistency}.
\end{proof}

\begin{remark}
\label{prf:alternative_rotation}
We detail how there exists an alternative observationally equivalent parameterization of the rotation matrix $H_2$, and how this ultimately does not matter.

Recall that we originally define $H_2 = \left( \frac{Z^\tran \Lambda_1^\tran \Lambda_1 Z}{N} + \frac{W^\tran W}{N} \right) \left( \frac{F_2^\tran \tilde{F}_2}{T_2} \right) V_{NT, 2}^{-1}$, and this parameterises all of the change in terms of the loadings, and is what the literature at large does (see \textcite{baltagi_identification_2017}, \textcite{han_tests_2015}). it is also possible parameterize the rotational change explicitly as part of the factors by defining:
\begin{align}
H_2^\dagger &= \left( \frac{\Lambda_1^\tran \Lambda_1}{N} + \frac{Z^{- \tran}W^\tran W Z^{-1}}{N} \right) \left( \frac{Z F_2^\tran \tilde{F}_2}{T_2} \right) V_{NT, 2}^{-1} = \left( \frac{\Lambda_1^\tran \Lambda_1}{N} + \frac{Z^{- \tran}W^\tran W Z^{-1}}{N} \right) \left( \frac{G_2^\tran \tilde{F}_2}{T_2} \right) V_{NT, 2}^{-1} 
\end{align}
where $G_2 = F_2 Z^\tran$, the pseudo factor representation. 

With $H_2^\dagger$, the consistency result $\tilde{Z}$ in \Cref{ext:thm:1:Ztilde_consistency} changes to:
\begin{align}
\norm{ 
\tilde{Z} - H_1^\tran H_2^{\dagger -\tran}
} = \Opdeltasq
\end{align}
where the $Z$ is absorbed into $H_2^\dagger$. Note that this does not affect following results, because we can simply replace $\tilde{F}_2 - F_2 H_2$ with $\tilde{F}_2 - F_2 Z^\tran H_2^\dagger$ in all the proofs. Doing so, we get the same results for $\tilde{F}_2 \tilde{Z}$. Thus, it does not matter which parameterisation of $H_2$ we use. 
\end{remark} 

% Wtilde Space Consistency Result -----------------------------------
Before we prove \Cref{ext:thm:3:Wtilde_consistency}, we need the following lemmas.

% Add in proper assumptions here
\begin{lemma}
\label{lem:w_consistency:1}
Under \Cref{ext:ass:1_factors,ext:ass:2_loadings,ext:ass:3_errors,ext:ass:4_ind_groups,ext:ass:5_error_corr,ext:ass:8_break_fraction}
\begin{align*}
\frac{1}{\sqrt{N}} \norm{
\tilde{\Lambda}_1 \tilde{Z} - \Lambda_1 Z H_2^{- \tran}
}
&= \Opdelta
\end{align*}
\end{lemma}

\begin{proof}[Proof of \Cref{lem:w_consistency:1}]
\begin{align*}
\frac{1}{\sqrt{N}} \norm{
\tilde{\Lambda}_1 \tilde{Z} - \Lambda_1 Z H_2^{- \tran}
} 
&= \frac{1}{\sqrt{N}} \norm{
(\Lambda_1 - \Lambda_1 H_1^{-\tran}) \tilde{Z} + 
\Lambda_1 H_1^{-\tran}\tilde{Z} - 
\Lambda_1 Z H_2^{-\tran}
}
\\
&=
\frac{1}{\sqrt{N}} 
\left| \left| 
(\tilde{\Lambda}_1 - \Lambda_1 H_1^{- \tran}) \tilde{Z} + 
\Lambda_1 Z H_1^{-\tran} 
\left( \tilde{Z} - 
V_{NT}^{-1} H_1^{-1} \frac{(\Lambda_1' \Lambda_1)}{N} Z H_2^{-\tran}
\right)  + \right. \right. \\
&\quad
\left. \left. \Lambda_1 Z H_1^{- \tran} V_{NT}^{-1} H_1^{-1} \left( \frac{\Lambda_1^\tran \Lambda_1}{N} \right)  Z H_2^{-\tran} - \Lambda_1 Z H_2^{- \tran}
\right| \right| \\
&\leq 
\frac{1}{\sqrt{N}} 
\norm{
(\tilde{\Lambda}_1 - \Lambda_1 H_1^{- \tran})} \norm{ \tilde{Z} } +
\frac{1}{\sqrt{N}} \norm{ \Lambda_1 Z H_1^{- \tran} } \norm{\tilde{Z} - V_{NT}^{-1} H_1^{-1} \left( \frac{\Lambda_1^\tran \Lambda_1}{N} \right) Z H_2^{-\tran}} + \\
&\quad 
\frac{1}{\sqrt{N}} \norm{ \Lambda_1 Z H_1^{- \tran} V_{NT}^{-1} H_1^{-1} \left( \frac{\Lambda_1^\tran \Lambda_1}{N} \right)  Z H_2^{-\tran} - \Lambda_1 Z H_2^{- \tran} } \\
&= \Opdelta \Op{1} + \Op{1} \Op{1} \frac{1}{\sqrt{N}} \Opdeltasq + \frac{1}{\sqrt{N}} \Opdeltasq \\
&= \Opdelta,
\end{align*}
where the second last line follows because the first term is $\Opdelta$ by \Cref{lem:bai_inf:1:A1} via symmetry (see \textcite{bai_simpler_2020}), and the second term is $\OprtNdeltasq$ by \Cref{ext:thm:1:Ztilde_consistency}. The third term uses the result that $V_{NT, 1} = \left( \frac{T_1}{\tilde{F}_1 F_1}\right) \left( \frac{\Lambda_1^\tran \Lambda_1}{N}\right) \left( \frac{F_1^\tran \tilde{F}_1}{T_1}\right) + \Opdeltasq$ from Lemma 3 of \textcite{bai_simpler_2020}, which means that $H_1^{- \tran} V_{NT}^{-1} H_1^{-1} = I_r + \Opdeltasq$.
\end{proof}

\begin{proof}[Proof of \Cref{ext:thm:3:Wtilde_consistency}]
First, recall the following identities:
\begin{align}
\tilde{W} &= \tilde{\Lambda}_2 - \tilde{\Lambda}_1 \tilde{Z} \\
W &= \Lambda_2 - \Lambda_1 Z,
\end{align}
which we can rearrange to form
\begin{align}
\tilde{W} - W H_2^{- \tran} = 
\tilde{\Lambda}_2 - \Lambda_2 H_2^{- \tran} - 
(\tilde{\Lambda}_1 \tilde{Z} - \Lambda_1 Z H_2^{- \tran})
\end{align}
Taking the squared norm of both sides, and dividing by $N$, we have
\begin{align*}
\frac{1}{N} \norm{\tilde{W} - W H_2^{- \tran}}^2 
&= 
\frac{1}{N} \norm{\tilde{\Lambda}_2 - \Lambda_2 H_2^{- \tran} - 
(\tilde{\Lambda}_1 \tilde{Z} - \Lambda_1 Z H_2^{- \tran})}^2 \\
&\leq \frac{1}{N} \left( 
\norm{\tilde{\Lambda}_2 - \Lambda_2 H_2^{- \tran}} +
\norm{(\tilde{\Lambda}_1 \tilde{Z} - \Lambda_1 Z H_2^{- \tran})}
\right)^2 \\
&\leq 
\frac{1}{N} \norm{\tilde{\Lambda}_2 - \Lambda_{2} H_2^{- \tran}}^2 +
\frac{2}{N} 
\norm{\tilde{\Lambda}_2 - \Lambda_2 H_2^{- \tran}} 
\norm{\tilde{\Lambda}_1 \tilde{Z} - \Lambda_1 Z H_2^{- \tran}} \\
&\quad + 
\frac{1}{N} 
\norm{\tilde{\Lambda}_1 \tilde{Z} - \Lambda_1 Z H_2^{- \tran}}^2.
\end{align*}
% Another lemma used 

Therefore, applying the result of \Cref{lem:w_consistency:1}, we have 
\begin{align}
\frac{1}{N} \norm{\tilde{W} - W H_2^{- \tran}}^2 
&\leq \Opdeltasq + \Opdelta \Opdelta + \Opdeltasq = \Opdeltasq,
\end{align}
mirroring the result of \textcite{bai_inferential_2003} and \textcite{bai_simpler_2020}.
\end{proof}

% ------------------------------------------------------------
\subsection{Z test Proofs}
% Split this into three overall steps, then backtrack
% 
% Wald test statistic is A() S^-1 A
% 
% Prove that A is consistent for true A
%
% Prove that Gamma is consistent for true Gamma
% Prove that Omega is consistent for true Omega
% Prove that S is consistent for true S
% Prove that S inverse and its true counterpart are bounded, so we can apply CMT 
% 
% Bring all results together and prove consistency of Wald Z test
The proof of \Cref{ext:thm:6:Z_Wald_consistency} requires proving the following lemmas:
\begin{lemma}
\begin{lemenum}
\item \label{lem:thm:4:A_Z} Under \Cref{ext:ass:1_factors,ext:ass:2_loadings,ext:ass:3_errors,ext:ass:4_ind_groups,ext:ass:5_error_corr,ext:ass:6_moments,ext:ass:7_eigen_distinct,ext:ass:8_break_fraction}, if $\frac{\sqrt{T}}{N} \to \infty$, then \\
$\norm{A_Z(\pi, (\widehat{F})) - A_Z(\pi, FH_{0, 1})} \convp 0$.
\item \label{lem:thm:5:Z_var_consistency} Under  \Cref{ext:ass:1_factors,ext:ass:2_loadings,ext:ass:3_errors,ext:ass:4_ind_groups,ext:ass:5_error_corr,ext:ass:6_moments,ext:ass:7_eigen_distinct,ext:ass:8_break_fraction}, and if the conditions in \Cref{ext:ass:9:hac_conditions} hold, then \\
$\norm{\widehat{S}(\pi, \widehat{F}) - \widehat{S}(\pi, FH_{0, 1})} \convp 0.$ 
\end{lemenum}
\end{lemma}

\begin{proof}[Proof of \Cref{lem:thm:4:A_Z}]
Taking the norm of $A_Z(\pi, \widehat{F}) - A_Z(\pi, F H_{0, 1})$, we have
\begin{align*}
\norm{A_Z(\pi, \widehat{F}) - A_Z(\pi, F H_{0, 1})}
&= 
\left\lVert vech \sqrt{T} \left( 
\frac{1}{\pi T} \sumTfloor \widehat{f}_t \widehat{f}_t^\tran -
\frac{1}{(1 - \pi)T} \sumTfloort \widehat{f}_t \widehat{f}_t^\tran
\right) \right. \\
&\quad - \left. vech \sqrt{T} \left( 
\frac{1}{\pi T} \sumTfloor H_{0, 1}^\tran f_t f_t^{\tran} H_{0, 1} -
\frac{1}{(1 - \pi)T} \sumTfloort H_{0, 1}^\tran f_t f_t^{\tran} H_{0, 1}
\right)
\right\rVert .
\end{align*}
Because $\widehat{f}_t$ is consistent for $H_1^\tran f_t$, and $H_1$ is consistent for $H_{0, 1}$, it suffices to prove that
\begin{align*}
A_Z.I &=
\sqrt{T} \left\lVert
vech \left( 
\frac{\sumTfloor \widehat{f}_t \widehat{f}_t^\tran}{\pi T} - 
\frac{\sumTfloort \widehat{f}_t \widehat{f}_t^\tran}{(1 - \pi)T}
\right) \right. \\ 
&\quad \quad \quad \quad - \left. 
vech \left( 
\frac{\sumTfloor H_{1}^\tran f_t f_t^{\tran} H_{1}}{\pi T} - 
\frac{\sumTfloort H_{1}^\tran f_t f_t^{\tran} H_{1}}{(1 - \pi)T}
\right)  
\right\rVert,
\end{align*}
and
\begin{align*}
A_Z.II &= 
\sqrt{T} \left\lVert
vech \left( 
\frac{\sumTfloor H_{1}^\tran f_t f_t^{\tran} H_{1}}{\pi T} - 
\frac{\sumTfloort H_{1}^\tran f_t f_t^{\tran} H_{1}}{(1 - \pi)T}
\right) \right. \\
&\quad \quad \quad \quad - \left.  
vech \left( 
\frac{\sumTfloor H_{0, 1}^\tran f_t f_t^{\tran} H_{0, 1}}{\pi T} - 
\frac{\sumTfloort H_{0, 1}^\tran f_t f_t^{\tran} H_{0, 1}}{(1 - \pi)T} \right) 
\right\rVert,
\end{align*}
are both $o_p(1)$. The first term $A_Z.I$ is bounded by 
\begin{align*}
A_Z.I 
&\leq 
\sqrt{T}\norm{
vech \left( 
\frac{\sumTfloor \widehat{f}_t \widehat{f}_t^\tran - H_{1}^\tran f_t f_t^{ \tran} H_{1}}{\pi T}
\right)}
+ \sqrt{T}\norm{
vech \left( 
\frac{\sumTfloort \widehat{f}_t \widehat{f}_t^\tran - H_{1}^\tran f_t f_t^{ \tran} H_{1}}{(1 - \pi)T}
\right)
}.
\end{align*}
We focus on proving that the first term is $o_p(1)$, as the second term can be proved very similarly. The first term is bounded by
\begin{align*}
&\sqrt{T}\norm{
vech \left( 
\frac{\sumTfloor 
\widehat{f}_t (\widehat{f}_t^\tran - H_1^\tran f_t)^\tran + 
\widehat{f}_t (H_1^\tran f_t) - H_1^\tran f_t f_t^\tran H_1
}
{\pi T}
\right)
} \\
= &\sqrt{T}\norm{
vech \left( 
\frac{\sumTfloor 
\widehat{f}_t (\widehat{f}_t^\tran - H_1^\tran f_t) + 
(\widehat{f}_t^\tran - f_tH_1) f_t^{\tran} H_{1}}{\pi T}
\right)} \\
= &\sqrt{T}\norm{
vech \left( 
\frac{\sumTfloor 
(\widehat{f}_t - H_1^\tran f_t) 
(\widehat{f}_t^\tran - f_t^\tran H_1) + 
H_1^\tran f_t (\widehat{f}_t^\tran - f_t^\tran H_1) + 
(\widehat{f}_t - H_{1}^\tran f_t) f_t^{\tran} H_1}{\pi T}
\right)} \\
\leq
&\sqrt{T} \left( \norm{
\frac{\sumTfloor (\widehat{f}_t - H_1^\tran f_t) 
(\widehat{f}_t^\tran - f_t^\tran H_1)}{\pi T}
} + 
2 \norm{\frac{\sumTfloor H_1^\tran f_t (\widehat{f}_t^\tran - f_t^\tran H_1)}{\pi T}}
\right) \\
= &\OprtTdeltasq + \OprtTdeltasq \\
= &o_p(1)
\end{align*}
as $\frac{\sqrt{T}}{N} \to 0$, where each of the terms on the second last line are $\OprtTdeltasq$ by \Cref{lem:bai_inf:1:A1}. Next, $A_Z.II$ can be bounded by
\begin{align*}
&\sqrt{T} \norm{
\frac{\sumTfloor H_1^\tran f_t f_t^{\tran } H_1 - H_{0, 1}^\tran f_t f_t^{ \tran } H_{0, 1}}{\pi T} - 
\frac{\sumTfloort H_1^\tran f_t f_t^{\tran } H_1 - H_{0, 1}^\tran f_t f_t^{ \tran } H_{0, 1}}{(1 - \pi) T}
} \\
= &\sqrt{T} \left\lVert  
\frac{\sumTfloor (H_1 - H_{0, 1})^\tran f_t f_t^{\tran } H_1 + H_{0, 1}^\tran f_t f_t^{\tran } (H_1 - H_{0, 1})}{\pi T} \right. \\
&\quad \quad - \left. \frac{\sumTfloort (H_1 - H_{0, 1})^\tran f_t f_t^{\tran } H_1 + H_{0, 1}^\tran f_t f_t^{\tran } (H_1 - H_{0, 1})}{(1 - \pi) T} 
 \right\rVert \\
\leq &\sqrt{T} \norm{H_1 - H_{0, 1}} 
\norm{
	\frac{\sumTfloor f_t f_t^{\tran }}{\pi T} - \frac{\sumTfloort f_t f_t^{ \tran }}{(1 - \pi) T}
} 
(\norm{H_1} + \norm{H_{0, 1}}) \\
= &\sqrt{T} o_p(1) \OprtT \Op{1},
\end{align*}
because we use \Cref{ext:ass:8_break_fraction:2} and $\norm{H_1 - H_{0, 1}} = o_p(1)$ which is implied by \Cref{ext:ass:1_factors,ext:ass:2_loadings,ext:ass:3_errors,ext:ass:4_ind_groups,ext:ass:7_eigen_distinct} (see \textcite{bai_inferential_2003}).
\end{proof}

% Proof that Gamma is consistent for true Gammas ---------------------------
% Need to check assumptions here
To prove \Cref{lem:thm:5:Z_var_consistency}, we need to prove the following lemmas first.
\marginnote[j subscripts fixed]{right}
\begin{lemma}
For $m = 1, 2$:
\label{lem:Z_gamma}
\begin{align*}
&\norm{
\widehat{\Gamma}_{(m), j}(\pi, \widehat{F}) - \widehat{\Gamma}_{(m), j}(\pi, F H_{1})
} \\
&= \begin{cases}
\Op{T^{-1/4}} + \OprtN \quad &\text{by \Cref{lem:han_lem:1} under \Cref{ext:ass:1_factors,ext:ass:2_loadings,ext:ass:3_errors,ext:ass:4_ind_groups}}, \\
\Opdelta \quad &\text{by \Cref{lem:han_lem:2} under \Cref{ext:ass:1_factors,ext:ass:2_loadings,ext:ass:3_errors,ext:ass:4_ind_groups,ext:ass:5_error_corr}}.
\end{cases}
\end{align*}
\end{lemma}
\begin{proof}[Proof of \Cref{lem:Z_gamma}]
We shall focus on the case of $m = 1$, as the case for $m = 2$ is analogous and thus omitted.
\begin{align*}
&\norm{
\widehat{\Gamma}_{(1), j}(\pi, \widehat{F}) - 
\widehat{\Gamma}_{(1), j}(\pi, F H_{1})
} \\
\leq 
&\norm{\frac{1}{\pi T} \sum_{t = j + 1}^{\floor{\pi T}} 
vech(\widehat{f}_t \widehat{f}_t^\tran - I_r)
vech(\widehat{f}_{t - j} \widehat{f}_{t - j}^\tran - I_r)^\tran
-
vech(H_1^\tran f_{t} f_{t}^\tran H_1 - I_r)
vech(H_1^\tran f_{t - j} f_{t - j}^\tran H_1 - I_r)^\tran } \\
\leq 
&\frac{1}{\pi T}  
\sum_{t = j + 1}^{\floor{\pi T}}
\norm{
vech(\widehat{f}_t \widehat{f}_t^\tran - I_r)
vech(\widehat{f}_{t - j} \widehat{f}_{t - j}^\tran - H_1^\tran f_{t - j} f_{t - j}^\tran H_1)
} + \\
&\frac{1}{\pi T} 
\sum_{t = j + 1}^{\floor{\pi T}}
\norm{
vech(\widehat{f}_t \widehat{f}_t^\tran - H_1^\tran f_t f_t^\tran H_1)
vech(H_1^\tran f_{t - j} f_{t - j}^\tran H_1 - I_r)^\tran
} \\
\leq 
&\frac{1}{\pi T} 
\sum_{t = j + 1}^{\floor{\pi T}}
\norm{ \widehat{f}_t \widehat{f}_t^\tran }
\norm{ \widehat{f}_{t - j} \widehat{f}_{t - j}^\tran - 
H_1^\tran f_{t - j} f_{t - j}^\tran H_1 }
+ \\
&\frac{1}{\pi T} \sum_{t = j + 1}^{\floor{\pi T}}
r \norm{
\widehat{f}_{t - j} \widehat{f}_{t - j}^\tran - H_1^\tran f_{t - j} f_{t - j}^\tran H_1
} +
\frac{1}{\pi T} 
\sum_{t = j + 1}^{\floor{\pi T}}
\norm{
\widehat{f}_{t} \widehat{f}_{t}^\tran - H^\tran f_{t} f_{t}^\tran H_1
}
\norm{
H_1^\tran f_{t - j} f_{t - j}^\tran H_1
} \\
&+ \frac{1}{\pi T} 
\sum_{t = j + 1}^{\floor{\pi T}} 
r \norm{
\widehat{f}_j \widehat{f}_j^\tran - H_1^\tran f_t f_t^\tran H_1
} \\
= &\Gamma.I + \Gamma.II + \Gamma.III + \Gamma.IV.
\end{align*}
We proceed by bounding Term $\Gamma.I$:
\begin{align*}
\Gamma.I &= 
\frac{1}{\pi T} 
\sum_{t = j + 1}^{\floor{\pi T}}
\norm{ \widehat{f}_t \widehat{f}_t^\tran }
\norm{ \widehat{f}_{t - j} \widehat{f}_{t - j}^\tran - 
H_1^\tran f_{t - j} f_{t - j}^\tran H_1 } \\
&\leq 
\frac{1}{\pi T} 
\left( \sum_{t = j + 1}^{\floor{\pi T}}
	\norm{\widehat{f}_t}^4
\right)^{1/2} 
\left( \sum_{t = j + 1}^{\floor{\pi T}}
	\norm{
	\widehat{f}_{t - j}(\widehat{f}_{t - j}^\tran \widehat{f}_{t - j}^\tran H_1) +
	(\widehat{f}_{t - j} - H_1^\tran f_{t - j})f_{t - j}^\tran H_1
	}^2
\right)^{1/2} \\
&\leq 
\left( 
	\frac{1}{\pi T} \sum_{t = j + 1}^{\floor{\pi T}} 
	\norm{\widehat{f}_t}^4
\right)^{1/2}
\left( 
\frac{2}{\pi T} \sum_{t = j + 1}^{\floor{\pi T}} 
\norm{\widehat{f}_{t - j}(\widehat{f}_{t - j}^\tran - \widehat{f}_{t - j}^\tran H_1)}^2 +
\frac{2}{\pi T} \sum_{t = j + 1}^{\floor{\pi T}} 
\norm{(\widehat{f}_{t - j} - \widehat{f}_{t - j} H_1) f_{t - j}^\tran H_1}^2
\right)^2 \\
&\leq 
\left( 
\frac{1}{\pi T}
	\sum_{t = j + 1}^{\floor{\pi T}} 
	\norm{\widehat{f}_t}^4
\right)^{1/2} \\
&\quad \times  
\left[ 
	\left( 
	\frac{2}{\pi T} \sum_{t = j + 1}^{\floor{\pi T}} \norm{\widehat{f}_{t - j}}^4
	\frac{2}{\pi T} \sum_{t = j + 1}^{\floor{\pi T}} \norm{\widehat{f}_{t - j} - f_{t - j} H_1}^4
	\right)^{1/2} \right. \\
&\quad \quad \quad \quad + \left. 
	\left( 
	\frac{2}{\pi T} \sum_{t = j + 1}^{\floor{\pi T}} \norm{\widehat{f}_{t - j} - H_1^\tran f_{t - j}}^4
	\frac{2}{\pi T} \sum_{t = j + 1}^{\floor{\pi T}} \norm{f_{t - j} H_1}^4
	\right)^{1/2}
\right]^{1/2} \\
&= \begin{cases}
\Op{T^{-1/4}} + \OprtN \quad &\text{by \Cref{lem:han_lem:1} under \Cref{ext:ass:1_factors,ext:ass:2_loadings,ext:ass:3_errors,ext:ass:4_ind_groups}}, \\
\Opdelta \quad &\text{by \Cref{lem:han_lem:2} under \Cref{ext:ass:1_factors,ext:ass:2_loadings,ext:ass:3_errors,ext:ass:4_ind_groups,ext:ass:5_error_corr}}, 
\end{cases}
\end{align*}
where $\frac{1}{T} \sumT \norm{\widehat{f}_t}^4 = \Op{1}$ by \Cref{lem:han_lem:2}. Using similar arguments, terms $\Gamma.II$, $\Gamma.III$, and $\Gamma.IV$ can be shown to be $\Op{T^{-1/4}} + \OprtN$.
\end{proof}

% Proof that Gamma based on estimated H converges to H0 
\begin{lemma}
\label{lem:Z_gamma_consistency:2}
Under \Cref{ext:ass:1_factors,ext:ass:2_loadings,ext:ass:3_errors,ext:ass:4_ind_groups,ext:ass:5_error_corr}, for $m = 1, 2$,
\begin{align*}
\norm{\widehat{\Gamma}_{m, j}(\pi, F_m H_1) - \widehat{\Gamma}_{m, j}(\pi, F_m H_{0, 1})} = \Opdelta
\end{align*}
\end{lemma}
\begin{proof}[Proof of \Cref{lem:Z_gamma_consistency:2}]
We shall only prove the lemma for $m = 1$, because the proof for $m = 2$ is similar and thus omitted.
\begin{align*}
&\norm{\widehat{\Gamma}_{1, j}(\pi, FH_1) - \widehat{\Gamma}_{1, j}(\pi, FH_{0, 1})} \\
= &\left\lVert
	\frac{1}{\pi T} \sum_{t = j + 1}^{\floor{\pi T}} 
	\left[ vech(H_1^\tran f_t f_t^\tran H_1 - I_r)
		vech(H_1^\tran f_{t - j} f_{t - j}^\tran H_1 - I_r)
	\right. \right. \\
&\quad \left. \left. -
	vech(H_{0, 1}^\tran f_t f_t^\tran H_{0, 1} - I_r)
	vech(H_{0, 1}^\tran f_{t - j} f_{t - j}^\tran H_{0, 1} - I_r)^\tran \right] 
\right\rVert \\
\leq 
&\frac{1}{\pi T} \sum_{t = j + 1}^{\floor{\pi T}} 
	\norm{
		H_1^\tran f_t f_t^\tran H_1
		}
	\norm{
		H_1^\tran f_{t - j} f_{t - j}^\tran H_1 - 
		H_{0, 1}^\tran f_{t - j} F){t - j}^\tran H_{0, 1}
		} + \\
&\frac{1}{\pi T} \sum_{t = j + 1}^{\floor{\pi T}} 
	\norm{
		H_1^\tran f_{t - j} f_{t - j}^\tran H_1 - 
		H_{0, 1}^\tran f_{t - j} f_{t - j}^\tran H_{0, 1}
		} + \\
&\frac{1}{\pi T} \sum_{t = j + 1}^{\floor{\pi T}} 
	\norm{
		\widehat{f}_t
		}^2
	\norm{
		H_1^\tran f_{t} f_{t}^\tran H_1 - 
				H_{0, 1}^\tran f_{t} f_{t}^\tran H_{0, 1}
		} + \\		
&\frac{1}{\pi T} \sum_{t = j + 1}^{\floor{\pi T}} 
	\norm{
		H_1^\tran f_{t} f_{t}^\tran H_1 - 
						H_{0, 1}^\tran f_{t} f_{t}^\tran H_{0, 1}
		}
	\norm{
		H_{0, 1}^\tran f_{t - j} f_{t - j}^\tran H_{0, 1}
		} \\
= &\Gamma.V + \Gamma.VI + \Gamma.VII + \Gamma.VIII.
\end{align*}
Term $\Gamma.V$ is bounded by:
\begin{align*}
\Gamma.V &= 
\frac{1}{\pi T} \sum_{t = j + 1}^{\floor{\pi T}} 
	\norm{
		H_1^\tran f_t f_t^\tran H_1
		}
	\norm{
		H_1^\tran f_{t - j} f_{t - j}^\tran H_1 - 
		H_{0, 1}^\tran f_{t - j} f_{t - j}^\tran H_{0, 1}
		} \\
&\leq 
\left( 
	\frac{1}{\pi T} \sumT 
	\norm{f_t H_1}^4
\right)^{1/2}
\left( 
	\frac{1}{\pi T} 
	(\norm{H_1}^2 + \norm{H_{0, 1}}^2)
	\sumT 
	\norm{f_t}^4
\right)^{1/2}
\norm{H_1 - H_{0, 1}} \\
&= \Op{1} \Opdelta
\end{align*}
by \Cref{ext:ass:1_factors} and \Cref{lem:han_lem:4}. The proofs of terms $\Gamma.VI, \Gamma.VII, \Gamma.VIII$ are similar and thus omitted.
\end{proof}

% Theorem Omega z -------------------------------------------------------
% Proof that Omega is consistent for true Omega
\begin{proof}[Proof of \Cref{lem:thm:5:Z_var_consistency}]
It suffices to show that
\begin{align*}
\norm{
	\widehat{\Omega}_{Z, m}(\pi, \widehat{F}) - \widehat{\Omega}_{Z, m}(\pi, F H_{0, 1})
} 
\convp 0, \quad \text{for} \quad m = 1, 2.
\end{align*}
For brevity, we will only prove the case for $m = 1$, as the case for $m = 2$ can be proved similarly. First, see that
\begin{align*}
&\norm{
	\widehat{\Omega}_{Z, 1}(\pi, \widehat{F}) - \widehat{\Omega}_{Z, 1}(\pi, F H_{0, 1})
} \\ 
\leq &\norm{\widehat{\Omega}_{Z, 1}(\pi, \widehat{F}) - \widehat{\Omega}_{Z, 1}(\pi, F H_{1})} +
\norm{\widehat{\Omega}_{Z, 1}(\pi, \widehat{FH_1}) - \widehat{\Omega}_{Z, 1}(\pi, F H_{0, 1})} \\
= &\Omega_Z.I + \Omega_Z.II
\end{align*}
For term $\Omega_Z.I$, we have:
\begin{align*}
&\norm{\widehat{\Omega}_{Z, 1}(\pi, \widehat{F}) - \widehat{\Omega}_{Z, 1}(\pi, FH_1)} \\
\leq &\left\lVert  
	\widehat{\Gamma}_{(1), 0} (\pi, \widehat{F}) + 
	\sumTfloor k \left( \frac{j}{b_{\floor{\pi T}}} \right) (\widehat{\Gamma}_{(1), j} (\pi, \widehat{F}) + \widehat{\Gamma}_{(1), j} (\pi, \widehat{F}))^\tran) 
	\right.  \\
	&
	- \left. 
	\widehat{\Gamma}_{(1), 0} (\pi, FH_{1})) + 
	\sumTfloor k \left( \frac{j}{b_{\floor{\pi T}}} \right) (\widehat{\Gamma}_{(1), j} (\pi, FH_{1}) + \widehat{\Gamma}_{(1), j} (\pi, FH_{1}))^\tran)
	\right\rVert
.
\end{align*}
Recall that $\abs{k \left( \frac{j}{b_{\floor{\pi T}}} \right)} \leq 1$ and $k \left( \frac{j}{b_{\floor{\pi T}}} \right) = 0$ if $j \gt b_{\floor{\pi T}}$ for the Bartlett kernel. Thus, 
\begin{align*}
\Omega_Z.I \leq 
\norm{\widehat{\Gamma}_{1, 0}(\pi, \widehat{F}) - \widehat{\Gamma}_{1, 0}(\pi, FH_1)} + 
2 \sum_{j = 1}^{b_{\floor{\pi T}}} \norm{
\widehat{\Gamma}_{1, j} (\pi, \widehat{F}) - \widehat{\Gamma}_{1, j} (\pi, FH_1)
}.
\end{align*}
In the case of the Bartlett kernel, $\Omega_Z.I$ is $\Op{\frac{T^{1/3}}{\delta_{NT}}}$ by \Cref{lem:Z_gamma_consistency:2} and the condition in \Cref{ext:ass:9:hac_conditions:1} which states that $b_{\floor{\pi T}} \leq K T^{1/3}$, so $\Omega_Z.I$ is $o_p(1)$ if $\frac{T^{2/3}}{N} \to 0$ as $N, T \to \infty$. 
% QS kernel skipped here for now

The term $\Omega_Z.II$ can be also be shown to be $o_p(1)$ with similar arguments.
\end{proof}

% Final bit of preliminary
% Prove that S_hat and its population version have bounded inverses, and that they are still
% consistent for one another

% Sloppy with assumptions here, make more precise
To prove the consistency of the Wald test statistic in \Cref{ext:thm:6:Z_Wald_consistency}, we present the following lemmas:
\begin{lemma}
\label{lem:Z_wald_lem}
Under \Cref{ext:ass:1_factors,ext:ass:2_loadings,ext:ass:3_errors,ext:ass:4_ind_groups,ext:ass:5_error_corr,ext:ass:6_moments,ext:ass:7_eigen_distinct,ext:ass:8_break_fraction,ext:ass:9:hac_conditions}, 
\begin{lemenum}
\item \label{lem:Z_wald_lem:1}
$\norm{\widehat{S}(\pi, F H_{0, 1})^{-1}} = \Op{1}$ and $\norm{\widehat{S}(\pi, \widehat{F})^{-1}} = \Op{1}$, 
\item \label{lem:Z_wald_lem:2}
$\norm{\widehat{S}(\pi, F H_{0, 1})^{-1} - \widehat{S}(\pi, \widehat{F})^{-1}} = o_p(1)$.
\end{lemenum}
\end{lemma}
\begin{proof}[Proof of \Cref{lem:Z_wald_lem}]
% First part
For \Cref{lem:Z_wald_lem:1}, because $0 \lt \pi \lt 1$, this implies that \\ $\norm{\widehat{S}(\pi, F H_{0, 1}) - \left( \frac{1}{\pi} + \frac{1}{1 - \pi} \Omega \right) } = o_p(1)$. Let $\rho_{min}, \rho_{max}$ denote the minimum and maximum eigenvalues of a symmetric matrix respectively. Since $\Omega$ is positive definite, \\
$\abs{\rho_{min}(\widehat{S}(\pi, FH_{0, 1})) - \rho_{min} \left( \left( \frac{1}{\pi} + \frac{1}{1 - \pi} \right) \Omega \right)} \leq \norm{\widehat{S}(\pi, F H_{0,1}) \left( \frac{1}{\pi} + \frac{1}{1 - \pi} \right) \Omega } = o_p(1)$. This means that the eigenvalues of $\widehat{S}(\pi, F H_{0, 1})$ are bounded away from zero, so $\norm{\widehat{S}(\pi, F H_{0, 1})} = \Op{1}$. For the second part of this lemma, we have \\
$\norm{\widehat{S}(\pi, \widehat{F}) - \left( \frac{1}{\pi} + \frac{1}{1 - \pi} \right)\Omega } \leq \norm{\widehat{S}(\pi, \widehat{F}) - \widehat{S}(\pi, F H_{0, 1})} + \norm{\widehat{S}(\pi, F H_{0, 1}) - \left( \frac{1}{\pi} + \frac{1}{1 - \pi} \right) \Omega} = o_p(1)$ by \Cref{lem:thm:5:Z_var_consistency} and \Cref{ext:ass:9:hac_conditions:1}. Therefore, 
\begin{align*}
\abs{
	\rho_{min}(\widehat{S}(\pi, \widehat{F})) 
	- \rho_{min} \left( \left( \frac{1}{\pi} + \frac{1}{1 - \pi} \right) \Omega \right)
}
\leq 
\norm{
	\widehat{S}(\pi, \widehat{F}) - \left( \frac{1}{\pi} + \frac{1}{1 - \pi} \right) \Omega
	} 
= o_p(1),
\end{align*}
which means that the eigenvalues of $\widehat{S}(\pi, \widehat{F})$ are also bounded away from zero, which subsequently implies that $\widehat{S}(\pi, \widehat{F})^{1} = \Op{1}$.
% Second part, (unfortunately proof is not that similar)
For \Cref{lem:Z_wald_lem:2}:
\begin{align*}
\norm{
	\widehat{S}(\pi, \widehat{F})^{-1} - \widehat{S}(\pi, FH_{0, 1})^{-1}
} 
= &\norm{
	\widehat{S}(\pi, F H_{0, 1})^{-1} 
	\left( \widehat{S}(\pi, F H_{0, 1}) - \widehat{S}(\pi, \widehat{F}) \right)
	\widehat{S}(\pi, \widehat{F})^{-1}
} \\
\leq 
&\norm{\widehat{S}(\pi, F H_{0, 1})^{-1}} 
\norm{\widehat{S}(\pi, F H_{0, 1}) - \widehat{S}(\pi, \widehat{F})} 
\norm{\widehat{S}(\pi, \widehat{F})^{-1}} \\
= &\Op{1}o_p(1)\Op{1} = o_p(1),
\end{align*}
by \Cref{lem:thm:5:Z_var_consistency} and \Cref{ext:ass:9:hac_conditions:1}.
\end{proof}

% Theorem Wald z
\begin{proof}[Proof of \Cref{ext:thm:6:Z_Wald_consistency}]
\begin{align*}
\abs{
	W_{Z}(\pi, \widehat{F}) - W_{Z}(\pi, F H_{0, 1})
} 
\leq 
&\abs{
	A_Z(\pi, \widehat{F})^\tran 
	\left[ \widehat{S}(\pi, \widehat{F})^{-1} - \widehat{S}(\pi, FH_{0, 1})^{-1} \right] 
	A_Z(\pi, \widehat{F})
} \\
&+ \abs{
	\left[ A_Z(\pi, \widehat{F}) - A_Z(\pi, FH_{0, 1}) \right]^\tran 
	\widehat{S}(\pi, FH_{0, 1})^{-1} A_Z(\pi, \widehat{F})
} \\
&+
\abs{
	A_Z(\pi, FH_{0, 1})^\tran 
	\widehat{S}(\pi, FH_{0, 1})^{-1}
	\left[ A_Z(\pi, \widehat{F}) - A_Z(\pi, FH_{0, 1}) \right] 
} \\
= &o_p(1),
\end{align*}
using the results of \Cref{lem:Z_wald_lem} and \Cref{lem:thm:4:A_Z}.
\end{proof}

% Z test alternative hypothesis proofs ----------------------------------------
\begin{proof}[Proof of \Cref{ext:thm:7:z_alter}]
Under the alternative hypothesis, $Z \neq I$, so we have:
\begin{align*}
&\dfrac{1}{\floor{\pi T}} \sumTfloor \widehat{f}_t \widehat{f}_t^\tran - \frac{1}{T - \floor{\pi T}} \sumTfloort \widehat{f}_t \widehat{f}_t^\tran \\
= 
&\left( 
	\frac{1}{\floor{\pi T}} 
	\sumTfloor H_1^\tran f_t f_t^\tran H_1
	- \frac{1}{T - \floor{\pi T}}
	\sumTfloort H_1^\tran Z f_t f_t^\tran Z^\tran H_1 
\right) \\
&+ \frac{1}{\floor{\pi T}}
	\sumTfloor
	\left( \widehat{f}_t \widehat{f}_t^\tran - H_1^\tran f_t f_t^\tran H_1 \right) 
- \frac{1}{T - \floor{\pi T}}
	\sumTfloort
	\left( \widehat{f}_t \widehat{f}_t^\tran - H_1^\tran Z f_t f_t^\tran Z^\tran H_1 \right).
\end{align*}
Note that
\begin{align*}
&\frac{1}{\floor{\pi T}}
	\sumTfloor
	\left( \widehat{f}_t \widehat{f}_t^\tran - H_1^\tran f_t f_t^\tran H_1 \right) \\
= &\frac{1}{\floor{\pi T}} \sumTfloor
\left[ 
	(\widehat{f}_t - H_1^\tran f_t) f_t^\tran H_1 + 
	(\widehat{f}_t - H_1^\tran f_t)(\widehat{f}_t^\tran - f_t^\tran H_1) +
	H_1^\tran f_t(\widehat{f}_t^\tran - f_t^\tran H_1) 
\right] 
\\
= &\Opdeltasq,
\end{align*}
by the arguments in the proof of \Cref{lem:thm:4:A_Z}. Similarly, \\
$\frac{1}{T - \floor{\pi T}}
	\sumTfloort
	\left( \widehat{f}_t \widehat{f}_t^\tran - H_1^\tran Z f_t f_t^\tran Z^\tran H_1 \right) = \Opdeltasq$. 

Under the alternative hypothesis where there is a rotational break, we have:
\begin{align*}
H_1^\tran 
\left( 
\frac{1}{\floor{\pi T}} 
\sumTfloor f_t f_t^\tran 
- \frac{1}{T - \floor{\pi T}}
\sumTfloort Z f_t f_t^\tran Z^\tran
\right) 
H_1 \convp
H_{0, 1}^\tran (\Sigma_F - Z \Sigma_F Z^\tran ) H_{0, 1} \equiv C,
\end{align*}
by \Cref{ext:ass:8_break_fraction}, and the definitions of $H_1$ and $H_{0, 1}$. Matrix $C$ contains non-zero entries because $\Sigma_F - Z \Sigma_F Z^\tran$ is not zero by \Cref{ext:ass:11:Z_test_alter}, and the fact that $H_{0, 1}$ is non-singular. Note that \Cref{ext:ass:1_factors,ext:ass:2_loadings,ext:ass:3_errors,ext:ass:4_ind_groups,ext:ass:5_error_corr,ext:ass:6_moments,ext:ass:7_eigen_distinct,ext:ass:8_break_fraction} still hold under the alternative hypothesis, and hence \Cref{lem:thm:5:Z_var_consistency} still hold for the equivalent models under the alternative. 
% Make some comment about how they are not properly demeaned under the alternative
Finally, putting the above together we have:
\begin{align*}
W_{Z}(\widehat{F}) 
&= A_{Z}(\pi, \widehat{F})^\tran \widehat{S}(\pi, \widehat{F})^{-1} A_Z(\pi, \widehat{F}) \\
&= \frac{T}{\operatorname{max}
(b_{\floor{\pi T}}, b_{T - \floor{\pi T}})} 
\left[ \frac{1}{\sqrt{T}} A_Z(\pi, \widehat{F})^\tran \right]
\left[ \operatorname{max}
(b_{\floor{\pi T}}, b_{T - \floor{\pi T}}) \tilde{S}(\pi, \widehat{F})^{-1} \right]
\left[ \frac{1}{\sqrt{T}} A_Z(\pi, \widehat{F}) \right] \\
&= \frac{T}{\operatorname{max}
(b_{\floor{\pi T}}, b_{T - \floor{\pi T}})} 
\left[ vech(C)^\tran + o_p(1) \right]
\left[ \operatorname{max}
(b_{\floor{\pi T}}, b_{T - \floor{\pi T}}) \tilde{S}(\pi, \widehat{F})^{-1} \right]
\left[ vech(C) + o_p(1) \right] \\
&\to \infty
\end{align*}
by \Cref{ext:ass:12:z_alter_variance,ext:ass:11:Z_test_alter}.
\end{proof}

% W test proofs -------------------------------------------------------------
% Section on the W test proofs
\subsection{W test Proofs}
We first recall the following identity for the factor loadings for $m = 1, 2$:
\begin{align}
\label{eqn:loading_asymp_exp}
\tilde{\lambda}_{m, i} - H_m^{-1} \lambda_{m, i} = \frac{1}{T_m} H_m^\tran F_m^\tran e_i + \frac{1}{T_m}\tilde{F}^\tran (F_m - \tilde{F}_m H^\tran)\lambda_{m, i} + \frac{1}{T_m} (\tilde{F}_m - F_m H_m)^\tran e_i.
\end{align}
\Cref{eqn:loading_asymp_exp}, is simply the subsample version of the asymptotic expansion of the factor loadings considered by \textcite{bai_inferential_2003} (see the proof of their Theorem 2). The last two terms are both $\Opdeltasq$ by \Cref{lem:bai_inf:4:B3} and \Cref{lem:bai_inf:2:B1}, and therefore we have
\begin{lemma}
\label{lem:bai_inf:7:B.2}
Under \Cref{ext:ass:1_factors,ext:ass:2_loadings,ext:ass:3_errors,ext:ass:4_ind_groups,ext:ass:5_error_corr,ext:ass:6_moments}, for $m = 1, 2$,
\begin{align}
\tilde{\lambda}_{m, i} - H_m^{-1} \lambda_{m, i} = 
H_m^\tran \frac{1}{T_m} \sumT f_{m, t} e_{it} \iota_{mt} + \Opdeltasq
\end{align}
for each $i$.
\end{lemma}
\Cref{lem:bai_inf:7:B.2} is simply the subsample counterpart of Equation B.2 in \textcite{bai_inferential_2003}.

% Individual Test -----------------------------------
% This needs to be redone, very tedious
%We first present the asymptotic expansion for each individual $w_{i}$. 
%\begin{proof}[Proof of \Cref{ext:thm:8:w_ind_dist}]
%Recall the asymptotic expansions for the estimated factor loadings in reach regime provided by \textcite{bai_inferential_2003}.
%\begin{align}
%\tilde{\lambda}_{m, i} &= 
%	H^{-1}_{m} \lambda_i + \frac{1}{T} H_{m}^\tran F^\tran e_{m, i} + 
%	\frac{1}{T} \tilde{F}^\tran (F - \tilde{F}H_{m}^{-1})^\tran \lambda_{m, i}  +
%	\frac{1}{T} (\tilde{F} - FH_{m})^\tran e_{m, i},
%\end{align}
%for each $i$, and $m = 1, 2$ regime. The latter two terms can be shown to be $O_p(\delta_{NT}^{-2})$, and hence asymptotically negligible.
%
%Therefore, we have for each subsample:
%\begin{align}
%\tilde{\lambda}_{1, i} - 
%	H^{-1}_{1} \lambda_{1, i} &= 
%	\frac{1}{\floor{\pi T}} \sumTfloor H_{1}^\tran f_t e_{it} + O_p(\delta_{NT}^{-2}) \\
%\tilde{\lambda}_{2, i} - 
%	H^{-1}_{2} \lambda_{2, i} &= 
%	\frac{1}{T - \floor{\pi T}} \sumTfloort H_{2}^\tran f_t e_{it} + O_p(\delta_{NT}^{-2})
%\end{align}
\begin{proof}[Proof of \Cref{ext:thm:W_test_distribution:1}]
Recall that $\tilde{W} = \tilde{\Lambda}_2 - \tilde{\Lambda}_1 \tilde{Z}$, which implies that
\begin{align}
\tilde{\lambda}_{2, i} &= \tilde{Z}^\tran \tilde{\lambda}_{1, i} + \tilde{w}_i \\
\tilde{w}_i &= \tilde{\lambda}_{2, i} - \tilde{Z}^\tran \tilde{\lambda}_{1, i}.
\end{align}
Substituting in the decompositions in \Cref{lem:bai_inf:7:B.2}, we have
\begin{align*}
\label{eqn:w_ind_asymp_exp}
\tilde{\lambda}_{2, i} - H_2^{-1} \lambda_{2, i} &= 
H_2^\tran \frac{1}{(1 - \pi)T} \sumTfloort f_t e_{it} +  O_p(\delta_{NT}^{-2}) \\
(\tilde{Z}^\tran \tilde{\lambda}_{1, i} + \tilde{w}_i) - 
H_2^{-1} (\lambda_{1, i} + w_{i}) &= H_2^\tran \frac{1}{(1 - \pi)T} \sumTfloort f_t e_{it} +  O_p(\delta_{NT}^{-2}) \\
(\tilde{w}_{i} - H_2^{-1} w_i) &= 
H_2^\tran \frac{1}{(1 - \pi)T} \sumTfloort f_t e_{it} - 
(
	\tilde{Z}^\tran \tilde{\lambda}_{1, i} - H_2^{-1} Z^\tran \lambda_{1, i}
) +
O_p(\delta_{NT}^{-2}).
\end{align*}

% This bit was typeset wrong, need to redo and check carefully
% The derivation on paper is correct though :)
We now focus on the asymptotic expansion of $\tilde{Z}^\tran \tilde{\lambda}_{1, i} - H_{2}^{-1} Z^\tran \lambda_{1, i}$:
\begin{align*}
&\tilde{Z}^\tran \tilde{\lambda}_{1, i} - H_2^{-1} Z^\tran \lambda_{1, i} \\
= &\tilde{Z}^\tran (\tilde{\lambda}_{1, i} - H_1^{-1}\lambda_{1, i}) + \left( \tilde{Z} - H_1^\tran Z H_2^{-\tran} \right)^\tran H_1^{-1}\lambda_{1, i} + \left( H_1^\tran Z H_2^{-\tran} \right)^\tran H_1^{- 1}\lambda_{1, i} - H_2^{-1} Z^\tran \lambda_{1, i} \\
= &\tilde{Z}^\tran (\tilde{\lambda}_{1, i} - H_1^{-1}\lambda_{1, i}) + \Opdeltasq \Op{1} + H_2^{-1} Z^\tran H_1 H_1^{-1} \lambda_{1, i} - H_2^{-1} Z^\tran \lambda_{1, i} \\
= &\tilde{Z}^\tran (\tilde{\lambda}_{1, i} - H_1^{-1}\lambda_{1, i}) + \Opdeltasq. 
\end{align*}
Applying \Cref{lem:bai_inf:7:B.2} to expand $(\tilde{\lambda}_{1, i} - H_1^{- 1}\lambda_{1, i})$, we have
\begin{align*}
(\tilde{w}_{i} - H_2^{-1} w_i) &= 
H_2^\tran \frac{1}{(1 - \pi)T} \sumTfloort f_t e_{it} - 
\tilde{Z}^\tran \frac{1}{\pi T} \sumTfloor H_1^\tran f_t e_{it} +
\Opdeltasq.
\end{align*}
Multiplying both sides by $\sqrt{T}$ then yields
\begin{align*}
\sqrt{T}(\tilde{w}_{i} - H_2^{-1} w_i) &= 
H_2^\tran \frac{1}{(1 - \pi)\sqrt{T}} \sumTfloort f_t e_{it} - 
\tilde{Z}^\tran \frac{1}{\pi \sqrt{T}} \sumTfloor H_1^\tran f_t e_{it} +
\OprtTdeltasq,
\end{align*}
where the remainder term is $o_p(1)$ as $\frac{\sqrt{T}}{N} \to 0$. Recognising the CLT random variable terms in \Cref{ext:ass:17:clt}, we have
\begin{align*}
\sqrt{T}(\tilde{w}_{i} - H_2^{-1} w_i) \convd N(0, \Omega_{W, i})
\end{align*}
where 
\begin{align*}
\Omega_{W, i} &= \left( \frac{1}{1 - \pi} \right) H_{0, 2}^\tran \Phi_{i} H_{0, 2} + 
\left( \frac{1}{\pi} \right) H_{0, 2}^{-1} Z' \Sigma_F^{-1} \Phi_{i} \Sigma_F^{-1} H_{0, 2}^{- \tran} \\
&= \left( \frac{1}{1 - \pi} \right) \Theta_{1, i} + \left( \frac{1}{\pi}\right)  \Theta_{2, i}.
\end{align*}
The form of $\Theta_{2, i}$ comes from the fact that $\tilde{Z}$ estimates $H_1 Z H_2^{- \tran}$ by \Cref{ext:thm:1:Ztilde_consistency}. By the convergence of $H_{1}$ to its limit $H_{0, 1}$, we have
\begin{align*}
\tilde{Z}^\tran H_1^\tran &\convp 
H_{0, 2}^{-1} Z^\tran H_{0, 1} H_{0, 1}^\tran \\
&= H_{0, 2}^{-1} Z^\tran \Sigma_F^{-1}.
\end{align*}
where the last line follows from the identity $H_{0, 1} H_{0, 1}^\tran = \Sigma_F^{-1}$ from Section 3.2 of \textcite{bai_simpler_2020} (they used $Q$, which corresponds to $H_{0, 1}^{-1}$). To see this, recall that $H_{0, 1}^{-1} = V^{1/2} \Upsilon_1^\tran \Sigma_{\Lambda_1}^{1/2}$. This means that $H_{0, 1}^{-1} \Sigma_F^{-1} H_{0, 1}^\tran = V_1^{1/2} \Upsilon_1^\tran \left( \Sigma_{\Lambda_1}^{1/2} \Sigma_F^{-1} \Sigma_{\Lambda_1}^{1/2}\right)  \Upsilon_1 V_1^{1/2} = V_1^{1/2} V_{1}^{-1} V_{1}^{1/2} = I$ by eigen-identity, which can then be re-arranged as required.

% this discussion here is a bit dodgy...
Their estimators $\tilde{\Theta}_{1, i}, \tilde{\Theta}_{2, i}$ are discussed in \textcite{bai_inferential_2003}, and are given by HAC estimators constructed using the estimated residuals $\tilde{e}_{(1), it} = x_{it} - \tilde{\lambda}_{2, i}^\tran \tilde{f}_{1, t}$ and $\tilde{e}_{(2), it} = x_{it} - \tilde{\lambda}_{2, i}^\tran \tilde{f}_{2, t}$ in the series $\tilde{Z}^\tran \tilde{f}_{1, t} \cdot \tilde{e}_{(1), it}$ and $\tilde{f}_{2, t} \cdot \tilde{e}_{(2), it}$ respectively:
\begin{align}
%\label{eqn:w_ind_HAC}
\tilde{\Theta}_{1, i} &= 
D_{0, 1, i} + \sum_{v = 1}^{\floor{\pi T} - 1} k\left( \frac{v}{b_{\floor{\pi T}}} \right) (D_{1, vi} + D_{1, vi}^\tran) \\
\tilde{\Theta}_{2, i} &= 
D_{0, 2, i} + \sum_{v = 1}^{T - \floor{\pi T} - 1} k\left( \frac{v}{b_{T - \floor{\pi T}}} \right) (D_{2, vi} + D_{2, vi}^\tran),
\end{align}
where $D_{1, vi} = (T_1)^{-1} \sum_{t = v + 1}^{\floor{\pi T}} \tilde{f}_{1, t} \tilde{e}_{it} \tilde{e}_{i, t - v} \tilde{f}_{1, t - v}^\tran$, $D_{2, vi} = (T_2)^{-1} \sum_{t = T_1 + v + 1}^{T} \tilde{f}_{2, t} \tilde{e}_{it} \tilde{e}_{i, t - v} \tilde{f}_{2, t - v}^\tran$, and $k(.)$ is a real valued kernel, such as the Bartlett kernel, satisfying \Cref{ext:ass:9:hac_conditions}.
The consistency of $\tilde{\Theta}_{1, i}$ and $\tilde{\Theta}_{2, i}$ for $\Theta_{1, i} = H_{1, 0}^\tran \Phi_{i, 1} H_{1, 0}$ and $\Theta_{2, i} = H_{2, 0}^\tran \Phi_{i, 2} H_{2, 0}$ respectively can be proved using the argument of \textcite{newey_simple_1987}, as stated by \textcite{bai_inferential_2003}.
% \Cref{lem:bai_inf:1:A1} implies that $\tilde{F}_1, \tilde{F}_2$ are implicitly estimating $F_1 H_1, F_2 H_2$, and $H_1, H_2$ in turn converge to their probability limits $H_{0, 1}, H_{0, 2}$. Using this, they define HAC covariance matrix estimates $\tilde{\Theta}_{1, i}, \tilde{\Theta}_{2, i}$ based on $\tilde{f}_{1, t} \cdot \tilde{e}_{it}, \tilde{f}_{2, t} \cdot \tilde{e}_{it}$ which are consistent for $H_{0, 2}^\tran \Phi_{i, 2} H_{0, 2}$ and $H_{0, 1}^\tran \Phi_{i, 1} H_{0, 1}$. 
Recalling that $\tilde{Z}$ estimates $H_1^\tran Z H_2^{-\tran}$ from \Cref{ext:thm:1:Ztilde_consistency}, it follows that we can estimate $\Omega_{W, i}$ using
\begin{align*}
\widehat{\Omega}_{W, i} = \frac{1}{1 - \pi}\tilde{\Theta}_{2, i} + \frac{1}{\pi} \tilde{Z}^\tran \tilde{\Theta}_{1, i} \tilde{Z}.
\end{align*}
The asymptotic Chi-squared distribution then follows. 
\end{proof}
% Pooled W test --------------------------------------------------------
Before we prove \Cref{ext:thm:W_test_distribution:2}, we prove some lemmas that need to be used.
% moving some stuff around which we will use later
\begin{lemma}
\label{lem:W_pool_remainder}
Under \Cref{ext:ass:1_factors,ext:ass:2_loadings,ext:ass:3_errors,ext:ass:5_error_corr,ext:ass:4_ind_groups,ext:ass:8_break_fraction,ext:ass:16:sum_loadings}, for $m = 1, 2$ we have:
\begin{lemenum}
\item \label{lem:W_pool_remainder:1}
$\frac{\tilde{F}_m^\tran (F_m - F_m H_m)}{T_m} \frac{\sumN \lambda_{m, i}}{\sqrt{N}} 
= \Opdeltasq$
\item \label{lem:W_pool_remainder:2}
$\frac{(\tilde{F}_m - F_m H_m)^\tran}{\sqrt{T_m}} \frac{\sumN e_{m, i}}{\sqrt{T_m N}} 
= \Opdeltasq$
\item \label{lem:thm:9:W_pool_variance}
Under \Cref{ext:ass:1_factors,ext:ass:2_loadings,ext:ass:3_errors,ext:ass:4_ind_groups,ext:ass:5_error_corr,ext:ass:6_moments,ext:ass:7_eigen_distinct,ext:ass:8_break_fraction,ext:ass:2_loadings,ext:ass:14:W_test_error_assump,ext:ass:15}, and if $\frac{\sqrt{T}}{N} \to 0$, then for $m = 1, 2$, $\norm{\tilde{\Theta}_m - \Theta_m} = o_p(1)$, where $\Theta_m = \plim (N)^{-1} \sumN \Theta_{m, i}$.
\end{lemenum}
\end{lemma}

% These need to be done with m subsample...
\begin{proof}[Proof of \Cref{lem:W_pool_remainder:1}]
The first term can be bounded by
\begin{align*}
&\quad \frac{\tilde{F}_m^\tran (F_m - F_m H_m)}{T_m} \frac{\sumN \lambda_{m, i}}{\sqrt{N}} \\
&= \Opdeltasq \Op{1}
\end{align*}
by \Cref{lem:bai_inf:3:B2}, and \Cref{ext:ass:16:sum_loadings}.
\end{proof}

% Just focus on case of m = 1
\begin{proof}[Proof of \Cref{lem:W_pool_remainder:2}]
It suffices to show that $\frac{1}{T_m \sqrt{N}} \sumT (\tilde{f}_{m, t} - H_m ^\tran f_{m, t}) \sumN e_{it} = \Opdeltasq$. We focus on the case of $m = 1$, as the proof for $m = 2$ is similar and thus omitted. From \Cref{eqn:bai_four_terms}, we have
\begin{align*}
&\quad \frac{1}{T_1} \sumTfloor (\tilde{f}_{1, t} - H_1^\tran f_{t}) \frac{1}{\sqrt{N}} \sumN e_{it} \\
&= V_{NT, 1}^{-1} \left(
\frac{1}{T_1^2} \sumTfloors \sumTfloor \tilde{f}_{1, s} \gamma_{N}(s, t) \frac{1}{\sqrt{N}} \sumN e_{it} +
\frac{1}{T_1^2} \sumTfloors \sumTfloor \tilde{f}_{1, s} \left( \frac{e_{s}^\tran e_{t}}{N} - \gamma_{N}(s, t) \right) \frac{1} {\sqrt{N}} \sumN e_{it} + \right. \\
&\quad
\left. 
\frac{1}{NT_1^2} \sumTfloors \sumTfloor \tilde{f}_{1, t} f_{t}^\tran \Lambda_1 e_{t} \frac{1}{\sqrt{N}} \sumN e_{it} +
\frac{1}{NT_1^2} \sumTfloors \sumTfloor \tilde{f}_{1, t} e_{(1)}^\tran \Lambda_1 f_{t} \frac{1}{\sqrt{N}} \sumN e_{it}
\right) \\
&= V_{NT}^{-1}(a + b + c + d),
\end{align*}
where we shall prove that each of $a, b, c, d$ are asymptotically negligible. 
% a
\begin{align*}
a &= \frac{1}{T_1^2} \sumTfloor \sumN H_1^\tran f_{1, s} \gamma_{N}(s, t) \frac{1}{\sqrt{N}} \sumN e_{it} +
\frac{1}{T_1^2} \sumTfloor \sumN (\tilde{f}_{1, s} - H_1^\tran f_{1, s}) \gamma_{N}(s, t) \frac{1}{\sqrt{N}} \sumN e_{it} \\
&= a.I + a.II
\end{align*}
We shall prove that each of $a.I$ and $a.II$ are asymptotically negligible. First, the term $a.I$ can be bounded by
\begin{align*}
a.I 
&\leq \frac{1}{T_1^2} E\left( \sumN \sumTfloor f_{1, s} \gamma_{N}(s, t) \frac{1}{\sqrt{N}} \sumN e_{it} \right)  \\
&= \frac{1}{T_1^2} \sumN \sumTfloor \left| \gamma_N(s, t) \right| E\left( \norm{f_{1, s}}^2 E \left( \frac{1}{\sqrt{N}} \sumN e_{it} \right)^2 \right) \\
&\leq \frac{1}{T_1^2} \sumN \sumTfloor \left| \gamma_N(s, t) \right| M = \Op{\frac{1}{T}},
\end{align*}
by \Cref{ext:ass:1_factors,ext:ass:3_errors:1,ext:ass:3_errors:2}, and $E \left( \frac{1}{\sqrt{N}} \sumN e_{it} \right) \leq M$ by \Cref{ext:ass:14:W_test_error_assump}.
Next, the term $a.II$ can be bounded by
\begin{align*}
a.II 
&\leq \frac{1}{\sqrt{T_1}} \left(
\frac{1}{T_1} \sumTfloor \norm{\tilde{f}_{1, s} - H_1 f_s}^2 
\right)^{\frac{1}{2}}
\left(
\frac{1}{T_1}
\sumTfloor \sumTfloors \left| \gamma_N(s, t) \right|^2 
\frac{1}{T_1} E \left(
\frac{1}{\sqrt{N}} \sumN e_{it}
\right)^2
\right)^{\frac{1}{2}} \\
&= \frac{1}{\sqrt{T_1}} \Opdelta \Op{1},
\end{align*}
where the $\Op{1}$ term follows from \Cref{ext:ass:3_errors:1}, and because $T^{-1} \sumTfloor \sumTfloors \left| \gamma_N(s, t) \right|^2 \leq M$ by Lemma 1(i) of \textcite{bai_determining_2002}.
Therefore, it follows that $a = \Op{\frac{1}{\delta_{NT} \sqrt{T}}}$. 

Next, term $b$ can be bounded by
\begin{align*}
b &= \frac{1}{T_1^2} \sumTfloors \sumTfloor \tilde{f}_{1, s} \left( \frac{e_{s}^\tran e_{t}}{N} - \gamma_{N}(s, t) \right) \frac{1} {\sqrt{N}} \sumN e_{it} \\
&= b.I + b.II
\end{align*}
For $b.I$, we shall define $z_{1, t} = \frac{\sumTfloors \sumN f_{1, s} [e_{is}e_{it} - E(e_{is}e_{it})]}{\sqrt{TN}}$. By \Cref{ext:ass:6_moments:1}, $E\norm{z_{1, t}}^2 < M$, and thus $\frac{1}{T_1} \sumTfloor \norm{z_{1, t}}^2 = \Op{1}$ by \Cref{ext:ass:14:W_test_error_assump}. This implies:
\begin{align*}
\frac{1}{\sqrt{NT_1}} \norm{H_1} 
\left( 
	\frac{1}{T_1} \sumTfloor \norm{z_{1, t}}^2 \frac{1}{T_1} \sumTfloor 
	\left( \frac{1}{\sqrt{N}} \sumN e_{it} \right)^2 
\right)^{\frac{1}{2}} = \frac{1}{\sqrt{T_1N}} \Op{1},
\end{align*}
by \Cref{ext:ass:3_errors:1,ext:ass:6_moments:1}, and $\norm{H_1} = \Op{1}$ due to \Cref{lem:bai_inf:5:A3}. 
For $b.II$, we can bound it by
\begin{align*}
&\left( 
	\frac{1}{T_1} \sumTfloor \norm{\tilde{f}_{1, t} - H_1^\tran f_{1, s}}^2
\right)^{\frac{1}{2}}
\left( 
	\frac{1}{T_1} \sumTfloor \left( 
		\fracTone \sumN \left( \frac{e_{s}^\tran e_{t}}{N} - \gamma_{N}(s, t) \right) 
	\frac{1}{\sqrt{N}} \sumN e_{it} \right)^2
\right)^{\frac{1}{2}} \\
\leq &\Opdelta \left( 
	\frac{1}{T_1^2} \sumTfloor \sumN \left( \frac{e_{s}^\tran e_{t}}{N} - \gamma_{N}(s, t) \right)^2 \fracTone \sumTfloor \left( \frac{1}{\sqrt{N}} \sumN e_{it}\right)^2 
\right)^{\frac{1}{2}} \\
= &\Opdelta \frac{1}{\sqrt{N}} \left( 
	\frac{1}{T_1^2} \sumN \sumT \left( 
	\frac{1}{\sqrt{N}} \sumN e_{is}e_{it} - E(e_{is}e_{it})
	\right)^2
\right) 
\fracTone \left( 
	\sumN \left( \frac{1}{\sqrt{N}} \left( \sumN e_{it} \right)^2 \right) 
\right)^{\frac{1}{2}} \\
= &\Opdelta \frac{1}{\sqrt{N}} \Op{1},
\end{align*}
because of \Cref{lem:bai_inf:1:A1}, the $\Op{1}$ term comes from \Cref{ext:ass:3_errors:1,ext:ass:14:W_test_error_assump}. Next, term $c$ can be bounded by
\begin{align}
c &= \frac{1}{NT_1^2} \sumTfloors \sumTfloor \tilde{f}_{1, s} f_{1, s}^\tran \Lambda_1 e_{t} \frac{1}{\sqrt{N}} \sumN e_{it}  \\
&= \Op{1} \left( \frac{1}{T_1N} \sumN \left( 
\frac{1}{\sqrt{N}} \sumNk \lambda_{1, k} e_{kt} e_{it}
\right) +
\frac{1}{T_1 N \sqrt{N}} \sumTfloor \sumN \sum_{k \neq i} \lambda_{1, k} e_{kt} e_{it}
\right) 
\\
&= \Op{1}\left( \OpN + \Op{\frac{1}{\sqrt{TN}}} \right) = \Op{\frac{1}{\delta_{NT}\sqrt{N}}}
\end{align}
by \Cref{ext:ass:6_moments:2,ext:ass:16:sum_loadings:2}. Term $d$ can be bounded by
\begin{align*}
d &= \frac{1}{NT_1^2} \sumTfloors \sumTfloor \tilde{f}_{1, s} e_{s}^\tran \Lambda_1 f_{t} \frac{1}{\sqrt{N}} \sumN e_{it} \\
&= \frac{1}{NT_1^2} \sumN \sumTfloor \tilde{f}_{1, s} e_{s}^\tran \Lambda_1 f_t \frac{1}{\sqrt{N}} \sumN e_{it} 
+ \frac{1}{NT_1^2} \sumN \sumTfloor (\tilde{f}_{1, s} - H_1^\tran f_{1, s})e_{s}^\tran \Lambda_1 f_{t} \frac{1}{\sqrt{N}} \sumN e_{it} \\
&= d.I + d.II.
\end{align*}
The first term $d.I$ can be bounded by
\begin{align*}
d.I &\leq 
\frac{1}{\sqrt{T_1N}} 
\norm{
	\sumN \sumTfloor H_1^\tran f_{1, s} e_{it} \lambda_{1, i}^\tran
}
\norm{
	\frac{1}{T_1} \sumTfloor 
	f_{t} \frac{1}{\sqrt{N}} \sumN e_{it}
} \\
&\leq 
\frac{1}{\sqrt{T_1N}} \Op{1} 
\left( 
	\frac{1}{T_1} \sumT \norm{f_t}^2 \frac{1}{T_1} 
	\sumN \left( \frac{1}{\sqrt{N}} \sumN e_{it} \right)^2 
\right)^2 \\
&= \Op{\frac{1}{\sqrt{T_1N}}},
\end{align*}
by \Cref{ext:ass:1_factors,ext:ass:6_moments:1,ext:ass:14:W_test_error_assump}.
\marginnote[fixed some typos]{}
The second term $d.II$ can be bounded by:
\begin{align*}
d.II &\leq \frac{1}{\sqrt{N}}
\norm{
	\frac{1}{T_1} \sumTfloor (\widehat{f}_{1, s} - H_1^\tran f_{1, s}) 
	\left( \frac{1}{\sqrt{N}} \sumN \lambda_{1, i}^\tran e_{is}\right) 
} 
\norm{
	\frac{1}{T_1} \sumTfloor f_{t} \frac{1}{\sqrt{N}} \sumN e_{it}
} \\
&\leq 
\frac{1}{\sqrt{N}}
\left( 
	\frac{1}{T_1} \sumTfloor \norm{\widehat{f}_s - H^\tran f_s}^2
	\frac{1}{T_1} \sumTfloor \norm{\frac{1}{\sqrt{N}} \sumN \lambda_{1, i}^\tran e_{is}}^2
\right)^{1/2}
\left( 
	\frac{1}{T_1} \sumTfloor \norm{f_{t}}^2 
	\frac{1}{T_1} \sumN \left( \frac{1}{\sqrt{N}} \sumN e_{it}\right)^2 
\right)^{1/2} \\
&= \frac{1}{\sqrt{N}}
\left( \Opdeltasq \Op{1} \right)^{1/2} \Op{1} = \frac{1}{\sqrt{N}} \Opdelta,
\end{align*}
by \Cref{ext:ass:1_factors,ext:ass:2_loadings,ext:ass:6_moments:3} and \Cref{lem:bai_inf:1:A1}.
Therefore, $a, b, c, d$ in the remainder term are all asymptotically negligible.
\end{proof}

% W test covariance matrix estimation -----------------------------------
% original ``proof'' in Bai was way too simple and lacked too much detail
% also, I wish to prove that the pooled average of these does indeed
% converge to the pooled version, which is a bit new
The proof of $\tilde{\Theta}_{m, i} \to \Theta_{m, i}$ for $m = 1, 2$ has been briefly illustrated in \textcite{bai_inferential_2003}, and can be proved by applying a HAC estimator using $\tilde{f}_t \cdot \tilde{e}_{it}$. We therefore focus on the consistency of the pooled version $\tilde{\Theta}_{m} \to \Theta_{m}$. Before we present the main proofs for the W covariance matrices, we present some lemmas to be used.
% W covariance lemmas
% error term lemmas
% these are sloppy, redo and fix up assumptions
\begin{lemma}
\label{lem:w_cov_error}
Under \Cref{ext:ass:1_factors,ext:ass:2_loadings,ext:ass:3_errors,ext:ass:4_ind_groups,ext:ass:5_error_corr,ext:ass:6_moments,ext:ass:8_break_fraction,ext:ass:2_loadings,ext:ass:14:W_test_error_assump,ext:ass:15}, and if $\sqrt{T}/N \to 0$, then for $m = 1, 2$:
\begin{lemenum}
\item \label{lem:w_cov_error:1}
$\frac{1}{T_m} \sumT \abs{\left( \tilde{e}_{(m), it} - e_{it}\right)\iota_{mt} }^4 = o_p(1)$ for all $i$,
\item \label{lem:w_cov_error:2}
If additionally, \Cref{ext:ass:16:sum_loadings} holds, then $\frac{1}{T_m N} \sumN \sumT \abs{\left( \tilde{e}_{(m), it} - e_{it} \right) \iota_{mt} }^4  = o_p(1)$
% Put in the implied results here as well just to be useful...
\item \label{lem:w_cov_error:3}
$\fracTm \sumT (\tilde{e}_{(m), it} \iota_{mt} )^4  = \Op{1}$
\item \label{lem:w_cov_error:4}
If additionally, \Cref{ext:ass:16:sum_loadings} holds,
$\frac{1}{T_m N} \sumN \sumT \tilde{e}_{(m), it}^4 \iota_{mt} = \Op{1}$
\end{lemenum}
\end{lemma}
\begin{proof}[Proof of \Cref{lem:w_cov_error:1}]
For brevity, we focus on $m = 1$, as the case for $m = 2$ is very similar. We have by definition:
\begin{align*}
\abs{\tilde{e}_{(1), it} - e_{it}} 
&= \abs{\tilde{\lambda}_{1, i}^\tran \tilde{f}_{1, t} - \lambda_{1, i}^\tran f_t} \\
&= \abs{
	\tilde{\lambda}_{1, i}^\tran \tilde{f}_{1, t} - \lambda_{1, i}^\tran H_1^{-\tran} H_1^\tran f_t
} \\
&= \abs{
	\tilde{\lambda}_{1, i}^\tran (\tilde{f}_{1, t} - H_1^\tran f_t) + \tilde{\lambda}_{1, i}^\tran H_1^\tran f_t - (\lambda_{1, i}^\tran H_1^{-\tran} H_1^\tran f_t)
} \\
&= \abs{
	\tilde{\lambda}_{1, i}^\tran (\tilde{f}_{1, t} - H_1^\tran f_t) + (\tilde{\lambda}_{1, i}^\tran - \lambda_{1, i}^\tran H_1^{- \tran}) H_1^\tran f_t
} \\ 
&=
\abs{E.I_t + E.II_t}.
\end{align*}
Noting that $\abs{\tilde{e}_{(1), it} - e_{it}}^4 \leq 64\abs{E.I_t^4 + E.II_t^4}$, it therefore suffices to consider the bounds of $\fracTm \sumT E.I_t^4 \iota_{mt}$ and $\fracTm \sumT E.II_t^4 \iota_{mt}$. 

First, $\frac{1}{T_1} \sumTfloor E.I_t^4$ can be bounded by:
\begin{align*}
\frac{1}{T_1} \sumTfloor E.I_t^4 &\leq 
\norm{\tilde{\lambda}_{1, i}}^4 \frac{1}{T_1} \sumTfloor \norm{\tilde{f}_{1, t} - H_1^\tran f_{t}}^4 \\
&= \Op{1} \Opdeltaquart, 
\end{align*}
where $\norm{\tilde{\lambda}_{1, i}}^4 = \Op{1}$ because each $\tilde{\lambda}_{1, i}$ is bounded by normalisation, and $\frac{1}{T} \norm{\tilde{f}_{1, t} - H_1^\tran f_t}^4 = \Opdeltaquart$ by \Cref{lem:han_lem:1}. 
% lambda_4 being bounded is a bit vague... need to clean up...

Next, $\fracTone \sumT E.II_t^4$ can be bounded by:
\begin{align*}
\fracTone \sumTfloor E.II_t^4 &\leq 
\norm{\tilde{\lambda}_{1, i}^\tran - \lambda_{1, i}^\tran H_1^{- \tran}}^4 
\norm{H_1}^4 \fracTone \sumTfloor f_t^4 \\
&= \Opdeltaquart \Op{1} \Op{1},
\end{align*}
where $\norm{\tilde{\lambda}_i^\tran - \lambda_i^\tran H^{- \tran}}^4 = \Opdeltaquart$ by \Cref{lem:han_lem:loadings}, and $\fracTone \sumTfloor f_t^4 = \Op{1}$ by \Cref{ext:ass:1_factors}.
\end{proof}

\begin{proof}[Proof of \Cref{lem:w_cov_error:2}]
The proof is similar to that of \Cref{lem:w_cov_error:1} - it suffices to show that $\fracTN \sumT \sumN E.I_t^4$ and $\fracTN \sumT \sumN E.II_t^4$ are both negligible. For brevity, we will focus on the case of $m = 1$, as the case for $m = 2$ is similar. First, $\frac{1}{T_1 N} \sumTfloor \sumN E.II_t^4$ can be bounded by 
\begin{align*}
\frac{1}{T_1 N} \sumTfloor \sumN E.I_t^4 = 
&\frac{1}{T_1 N} \sumTfloor \sumN \tilde{\lambda}_{1, i}^\tran (\tilde{f}_{1, t} - H_1^\tran f_{t}) \\
= & \frac{1}{T_1 N} \sumN \sumTfloor 
\left[ 
	\left( \tilde{\lambda}_{1, i} - \lambda_{1, i} H_1^{-\tran}\right) \left( \tilde{f}_{1, t} - H_1^\tran f_{t}\right) + 
	\lambda_{1, i} H_1^\tran \left( \tilde{f}_{1, t} - H_1^\tran f_{t}\right)  
\right]^4 \\
\leq &\frac{64}{T_1 N} \sumTfloor \left( \tilde{f}_{1, t} - H_1^\tran f_{t}\right)^4
\fracN \left( \tilde{\lambda}_{1, i} - \lambda_i H_1^{-\tran}\right)^4+
\frac{64}{T_1 N} \sumN (\lambda_{1, i} H_1^\tran)^4 \sumTfloor \left( \tilde{f}_{1, t} - H_1^\tran f_{t}\right)^4  \\
\leq &\frac{64}{T_1} \sumTfloor \norm{\tilde{f}_{1, t} - H_1^\tran f_{t}}^4 \fracN \sumN \norm{\tilde{\lambda}_{1, i} - \lambda_{1, i} H_1^{-\tran}}^4 \\
&\quad + 64 \fracTone \sumTfloor \norm{\tilde{f}_{1, t} - H_1^\tran f_{t}}^4
\fracN \sumN \norm{\lambda_{1, i}}^4 \norm{H_1}^4 \\
= &o_p(1) o_p(1) + o_p(1) \Op{1} \\
= &o_p(1),
\end{align*}
where the first $o_p(1)$ term comes from \Cref{lem:han_lem:2,lem:han_lem:loadings}, and the second term is $o_p(1)$ from \Cref{lem:han_lem:2,ext:ass:2_loadings,lem:bai_inf:5:A3}.
The second term $\fracTN \sumT \sumN E.II_t^4$ can be bounded by
\begin{align*}
\frac{1}{T_1 N} \sumTfloor \sumN E.II_t^4 &= 
\frac{1}{T_1 N} \sumTfloor \sumN (\tilde{\lambda}_{1, i}^\tran - \lambda_{1, i}^\tran H^{- \tran}) H_1^\tran f_{t} \\
&\leq 
\frac{1}{T_1 N} \sumTfloor \sumN \norm{\tilde{\lambda}_{1, i} - \lambda_{1, i} H_1^{-\tran}}^4 
\norm{H_1}^4 \norm{f_{t}}^4 \\
&= \fracN \sumN \norm{\tilde{\lambda}_{1, i} - \lambda_{1, i} H_1^{-\tran}}^4 \fracTone \sumTfloor f_{t}^4 \norm{H_1}^4 \\
&= o_p(1) \Op{1} \Op{1} \\
&= o_p(1),
\end{align*}
because of \Cref{lem:han_lem:loadings,lem:bai_inf:5:A3,ext:ass:1_factors}.
\end{proof}

% Proof of last two lemmas, which are implications of the previous two lemmas
\begin{proof}[Proof of \Cref{lem:w_cov_error:3,lem:w_cov_error:4}]
\Cref{lem:w_cov_error:3,lem:w_cov_error:4} are implications and \Cref{lem:w_cov_error:1,lem:w_cov_error:2} and can be proven in a similar way. Focusing on $m = 1$ as the case for $m = 2$ is similar, we have
\begin{align*}
\fracTone \sumTfloor \tilde{e}_{it}^4 &\leq 
\frac{8}{T_1} \sumTfloor \left( \tilde{e}_{it} - e_{it} \right)^4 +
\frac{8}{T_1} \sumTfloor e_{it}^4 \\
&= \Op{1}, \\
\frac{1}{T_1 N} \sumN \sumTfloor \tilde{e}_{it}^4 &\leq 
\frac{8}{T_1 N} \sumN \sumTfloor \left( \tilde{e}_{it} - e_{it} \right)^4 +
\frac{8}{T_1 N} \sumN \sumTfloor e_{it}^4 \\
&= \Op{1}.
\end{align*}
\end{proof}

% Covariance proof ------------------------------------------------------------
% The original individual one is alsready typeset and proven (very tedious)
% I don't think it is really new or necessary
% so just comment and skip it, and go straight to the pooled version


% Individual version
%We wish to prove that 
%\begin{align}
%\norm{
%	\tilde{\Theta}_i - \fracT H^\tran (\sumT f_t f_t^\tran e_{it}^2) H
%} \convp 0,
%\end{align}
%where $\tilde{\Theta}_i$ is a HAC based estimate using infeasible data:
%\begin{align}
%\tilde{\Theta}_i &= 
%\widehat{\Gamma}_0 + 
%\sumT k \left( \frac{1}{S_T}\right) \left( \widehat{\Gamma} + \widehat{\Gamma}^\tran \right), \\
%\widehat{\Gamma}_0 &= \fracT \sumT \tilde{f}_t \tilde{F}_{t}^\tran \tilde{e}_{it}^2, \\
%\widehat{\Gamma}_j &= \fracT \sumT \tilde{f}_t \tilde{f}_{t - j}^\tran \tilde{e}_{it} \tilde{e}_{i, t - j}.
%\end{align}
%
%We shall first prove some lemmas.
%
%\begin{lemma}
%\label{lem:w_gamma_ind}
%Under the Assumptions, 
%$\norm{\widehat{\Gamma}_j(\tilde{f}_t \tilde{e}_{it}) - \widehat{\Gamma}_j(H^\tran f_t e_{it})} = o_p(1)$
%\end{lemma}
%
%Proof of \Cref{lem:w_gamma_ind}:
%\begin{align*}
%\norm{
%	\widehat{\Gamma}_j(\tilde{f}_t \tilde{e}_{it}) - \widehat{\Gamma}_j(H^\tran f_t e_{it})
%} &= 
%\norm{
%	\fracT \sumT \tilde{f}_t \tilde{f}_{t - j}^\tran \tilde{e}_{it} \tilde{e}_{i, t - j} - 
%	H^\tran \left( \fracT \sumT {F}_t {F}_{t - j}^\tran {e}_{it} {e}_{i, t - j} \right) H
%} \\
%&\leq 
%\fracT \sumT \left( \tilde{f}_t \tilde{f}_{t - j}^\tran - H^\tran f_t f_{t - j} H \right) \left( \tilde{e}_{it} \tilde{e}_{i, t - j} \right) +
%\fracT \sumT \left( H^\tran f_t f_{t - j} H \right) 
%\left( \tilde{e}_{it} \tilde{e}_{i, t - j} - e_{it}e_{i, t - j}\right) \\
%&= a.1 + a.2.
%\end{align*}
%Term $a.1$ is bounded by
%\begin{align*}
%a.1 &\leq \left( 
%\fracT \sumT \norm{
%	\tilde{f}_t (\tilde{f}_{t - j}^\tran - f_{t - j}^\tran H) + 
%	(\tilde{f}_t - H^\tran f_t)(\tilde{f}_{t - j} H)
%}^2 
%\fracT \sumT \tilde{e}_{it}^2 \tilde{e}_{i, t - j}^2
%\right)^{\frac{1}{2}} \\
%&\leq 
%\left( 
%	\frac{2}{T} \sumT 
%	\norm{
%		\tilde{f}_t (\tilde{f}_{t - j}^\tran - f_{t - j}^\tran H)
%	}^2 +
%	\norm{
%		(\tilde{f}_t - H^\tran f_t)
%		(\tilde{f}_{t - j} H)
%	}^2
%\right)^{\frac{1}{2}} 
%\left( 
%	\fracT \sumT \tilde{e}_{it}^2 \tilde{e}_{i, t - j}^2
%\right)^{\frac{1}{2}} \\
%&\leq 
%\left[ 
%	2 \left( 
%		\fracT \sumT \norm{\tilde{f}_t}^4 \fracT \sumT \norm{\tilde{f}_{t - j}^\tran - f_{t - j}^\tran H}^4 
%	\right)^{\frac{1}{2}} +
%	2 \left( 
%		\fracT \sumT \norm{\tilde{f}_t - H^\tran f_t}^4
%		\fracT \sumT \norm{\tilde{f}_{t - j}}^4 \norm{H}^4
%	\right)^{\frac{1}{2}}  
%\right] 
%&= o_p{1},
%\end{align*}
%because...
%
%Term $a.2$ can be bounded by 
%\begin{align*}
%a.2 &=
%\fracT \sumT H^\tran f_t f_t^\tran H (\tilde{e}_{it} \tilde{e}_{i, t - j} - e_{it}e_{i, t - j}) \\
%&\leq 
%\left( 
%	\fracT \sumT \norm{H^\tran f_t f_t^\tran H}^2
%	\fracT \sumT \left( \tilde{e}_{it} \tilde{e}_{i, t - j} - e_{it}e_{i, t - j} \right)^2
%\right)^{\frac{1}{2}} \\
%&\leq 
%\norm{H}^2 \left( \fracT \sumT \norm{f_t}^2 \right)^{\frac{1}{2}}
%\left( 
%	\frac{2}{T} \sumT 
%	\left( 
%		\tilde{e}_{it}^2 (\tilde{e}_{i, t - j} - e_{i, t - j})
%	\right) +
%	e_{i, t-j}^2 (\tilde{e}_{it} - e_{it})^2 
%\right)^{\frac{1}{2}} \\
%&= 
%\Op{1} \Op{1}
%\left( 
%	\frac{2}{T} \left[ 
%		\sumT \tilde{e}_{it}^4 \cdot \sumT (\tilde{e}_{i, t - j} - e_{i, t - j})^4
%	\right]^{\frac{1}{2}}
%	\frac{2}{T} \left[ 
%		\sumT e_{i, t-j}^4 \cdot \sumT (\tilde{e}_{it} - e_{it})^4
%	\right]^{\frac{1}{2}}
%\right)^{\frac{1}{2}} \\
%&= o_p(1),
%\end{align*}
%because ...

% Now prove the gamma lemmas
% Clean up assumptions here
\begin{lemma}
\label{lem:W_pool_gamma}
Under \Cref{ext:ass:1_factors,ext:ass:2_loadings,ext:ass:3_errors,ext:ass:4_ind_groups,ext:ass:5_error_corr,ext:ass:6_moments,ext:ass:7_eigen_distinct,ext:ass:8_break_fraction,ext:ass:2_loadings,ext:ass:14:W_test_error_assump,ext:ass:15,ext:ass:16:sum_loadings}, for $m = 1, 2$,
\begin{align*}
\norm{\fracN \sumN D_{j, m, i} - D^*_{j, m}} = o_p(1),
\end{align*}
where $D^*_{j, m} = \plim \fracN \sumN D^*_{j, m, i} = \plim \fracN \sumN \frac{1}{\floor{\pi T}} \sumTfloort H_m^\tran f_t e_{it} e_{i, t - v}^\tran f_{t - v}^\tran H_m$, its infeasible counterpart. 
\end{lemma}
\begin{proof}[Proof of \Cref{lem:W_pool_gamma}]
We focus on the case of $m = 1$, as the proof for $m = 2$ is similar and thus omitted. We have
\begin{align*}
&\norm{
	\fracN \sumN D_{j, m, i} - D^*_{j, m}
} \\
= 
&\norm{
	\frac{1}{T_1 N} \sumN \sumTfloor \tilde{f}_{1, t} \tilde{f}_{1, t - j}^\tran \tilde{e}_{(1), it} \tilde{e}_{(1), i, t - j} - 
	H_1^\tran \left( \frac{1}{T_1 N} \sumN \sumTfloor {f}_t {f}_{t - j}^\tran {e}_{it} {e}_{i, t - j} \right) H_1
} \\
\leq
&\frac{1}{T_1 N} \sumN \sumTfloor \left( \tilde{f}_{1, t} \tilde{f}_{1, t - j}^\tran - H_1^\tran f_t f_{t - j} H_1 \right) \left( \tilde{e}_{it} \tilde{e}_{i, t - j} \right) \\
&\quad +
\frac{1}{T_1 N} \sumN \sumTfloor \left( H_1^\tran f_t f_{t - j} H_1 \right) 
\left( \tilde{e}_{(1), it} \tilde{e}_{(1), i, t - j} - e_{it}e_{i, t - j}\right) \\
= 
&D.I + D.II.
\end{align*}
The first term $D.I$ is bounded by 
\begin{align*}
&D.I \\
= &\frac{1}{T_1 N} \sumN \sumTfloor \left( \tilde{f}_{1, t} \tilde{f}_{1, t - j}^\tran - H_1^\tran f_t f_{t - j} H_1 \right) \left( \tilde{e}_{(1), it} \tilde{e}_{(1), i, t - j} \right) \\
\leq 
&\left( 
	\fracTone \sumTfloor \norm{\tilde{f}_{1, t} \tilde{f}_{1, t - j}^\tran - H_1^\tran f_t f_{t - j} H_1}^2
	\fracTone \sumTfloor \left( \fracN \sumN \tilde{e}_{(1), it} \tilde{e}_{(1), i, t - j} \right)^2
\right)^{\frac{1}{2}} \\
\leq 
&\left(
\fracTone \sumTfloor \norm{
\tilde{f}_{1, t} (\tilde{f}_{1, t - j}^\tran - f_{t - j} H_1) +
(\tilde{f}_{1, t} - H_1^\tran f_t)(\tilde{f}_{1, t - j})
}^2 
\fracTone \sumTfloor \left( \fracN \sumN \tilde{e}_{(1), it} \tilde{e}_{(1), i, t - j} \right)^2
\right)^{\frac{1}{2}} \\
\leq 
&\left( 
\frac{2}{T_1} \sumTfloor \norm{
\tilde{f}_{1, t} (\tilde{f}_{1, t - j}^\tran - f_{t - j} H_1)
}^2 +
\norm{
(\tilde{f}_{1, t} - H_1^\tran f_t)(\tilde{f}_{1, t - j})
}^2
\right)^{\frac{1}{2}}
\left( 
\fracTone \sumTfloor \left( \fracN \sumN \tilde{e}_{(1), it} \tilde{e}_{(1), i, t - j}\right)
\right)^{\frac{1}{2}} \\
\leq &\left(
2\left(
\fracTone \sumTfloor \norm{\tilde{f}_{1, t}}^4 
\fracTone \sumTfloor \norm{\tilde{f}_{1, t - j} - f_{t - j}^\tran H_1}^4
\right)^{\frac{1}{2}} +
2\left( 
\fracTone \sumTfloor \norm{\tilde{f}_{1, t - j}}^4 +
\fracTone \sumTfloor \norm{\tilde{f}_{1, t} - H_1^\tran f_t}^4
\right)^{\frac{1}{2}}
\right)^{\frac{1}{2}} \\
&\quad \times \left( \fracTN \sumT \sumN \tilde{e}_{(1), it}^2 \tilde{e}_{i, t - j}^2\right) ^{1/2} \\
\leq &o_p(1) \left( 
	\fracTN \sumT \sumN \tilde{e}_{it}^2 \tilde{e}_{i, t - j}^2
\right) ^{1/2} \\
\leq &o_p(1) \left[ 
	\left( 
	\fracTN \sumT \sumN \tilde{e}_{(1), it}^4 \right)^{\frac{1}{2}}  \cdot
	\left( \fracTN \sumT \sumN\tilde{e}_{(1), i, t - j}^4 \right)^{\frac{1}{2}} 
\right] ^{1/2} \\
= &o_p(1)\Op{1},
\end{align*}
where the first term is $o_p(1)$ follows from applying \Cref{lem:han_lem:2,lem:han_lem:4}, and the second term follows from \Cref{lem:w_cov_error:4}. The second term $D.II$ is bounded by 
\begin{align*}
D.II = &\frac{1}{T_1 N} \sumN \sumTfloor \left( H_1^\tran f_t f_{t - j} H_1 \right) 
\left( \tilde{e}_{(1), it} \tilde{e}_{(1), i, t - j} - e_{it}e_{i, t - j}\right) \\
\leq 
&\left( 
	\fracTone \sumTfloor \norm{
		H_1^\tran f_t f_{t - j} H_1
	}^2
	\fracTone \sumTfloor \left( 
		\fracN \sumN \left( \tilde{e}_{(1), it} \tilde{e}_{(1), i, t - j} - e_{it}e_{i, t - j} \right) 
	\right)^2
\right)^{\frac{1}{2}} \\
\leq &\Op{1} \left( 
	\frac{2}{T_1} \sumTfloor \left( 
		\fracN \sumN \tilde{e}_{(1), it}^2 (\tilde{e}_{(1), i, t - j} - e_{i, t - j}) +
			e_{i, t-j}^2 (\tilde{e}_{(1), it} - e_{it})^2
	\right) 
\right)^{\frac{1}{2}} \\
\leq &\Op{1} \left( 
	\frac{2}{T_1 N} 
	\left( \sumTfloor \sumN \tilde{e}_{(1), it}^4 \cdot 
		\sumTfloor \sumN (\tilde{e}_{(1), i, t - j} - e_{t, i - j})^4 \right)^{\frac{1}{2}} \right. \\ 
& \quad \quad \quad \quad + \left.
	\frac{2}{T_1} 
	\left( \sumTfloor \sumN {e}_{i, t - j}^4 \cdot 
			\sumTfloor \sumN (\tilde{e}_{(1), it} - e_{it})^4 \right)^{\frac{1}{2}}
\right) \\
= &o_p(1),
\end{align*}
where the $\Op{1}$ term comes from \Cref{ext:ass:1_factors,lem:bai_inf:5:A3} and the $o_p(1)$ term comes from \Cref{lem:w_cov_error:2}.
\end{proof}

% Final proof for variance matrix
\begin{proof}[Proof of \Cref{lem:thm:9:W_pool_variance}]
It suffices to prove that $\norm{\fracN \sumN \tilde{\Theta}_{m, i} - \Theta_m} = o_p(1)$ for $m = 1, 2$. For brevity, we will only prove the case for $m = 1$, as the case for $m = 2$ is similar. See that
\begin{align*}
&\norm{\fracN \sumN \tilde{\Theta}_{m, i} - \Theta_m} \\
&\leq \norm{\fracN \sumN D_{0, 1, i} + 
\fracN \sumN \sum_{v = 1}^{\floor{\pi T - 1}} k \left(\frac{v}{b_{\floor{\pi T}}}\right)D_{1, vi} 
- D_{0, 1}^* 
- \sum_{v = 1}^{\floor{\pi T - 1}} k \left(\frac{v}{b_{\floor{\pi T}}}\right)D_{vi}^* } \\
&\leq  
\norm{\fracN \sumN D_{0, 1, i} - D_{0, 1}^*} + 
2 \sum_{v = 1}^{b_{\floor{\pi T}}} 
\norm{\fracN \sumN D_{1, vi} - D_{vi}^*} \\
= o_p(1),
\end{align*}
by \Cref{lem:W_pool_gamma}.
\end{proof}
%--------------------------------------------------------------------------

\begin{proof}[Proof of \Cref{ext:thm:W_test_distribution}]
We are now considering the asymptotic expansion of $\tilde{\lambda}_{m, i}$ in \Cref{lem:bai_inf:7:B.2}, but averaged across the cross section and inflated by $\sqrt{N}$:
\begin{align}
\label{lem:bai_inf:7:B.2_pool}
\frac{\sumN \tilde{\lambda}_{m, i} - H_1^{-1}\lambda_{m, i}}{\sqrt{N}} = \frac{1}{T_m \sqrt{N}} \sumN \tilde{F}_m^\tran (F_m - F_m H_m) \lambda_{m, i} + \frac{1}{T_m \sqrt{N}} \sumN {\tilde{F}_m - F_m H_m}^\tran e_{(m), i},
\end{align}
where the last two terms are asymptotically negligible because of \Cref{lem:W_pool_remainder:1,lem:W_pool_remainder:2}.

% Main W Joint test proof ------------------------------------------------
Similarly, considering the asymptotic expansion of $\tilde{w}_i$ in \Cref{eqn:w_ind_asymp_exp}, taking its cross sectional mean, and then inflating by $\sqrt{TN}$ on both sides, we have:
\begin{align*}
\sqrt{TN} \frac{\sumN (\tilde{w}_{i} - H_2^{-1} w_i)}{N} = &
H_{2}^\tran \frac{1}{(1 - \pi)\sqrt{TN}} \sumN \sumTfloort f_t e_{it} \\
&- 
\tilde{Z}^\tran \frac{1}{\pi \sqrt{TN}} \sumN \sumTfloor H_1^\tran f_t e_{it} +
\OprtTdeltasq \\
&\convd N(0, \Omega_W), \nonumber 
\end{align*}
where $\Omega_{W} = \frac{1}{(1 - \pi) TN} H_{0, 2}^\tran \sumN \Phi_{i, 2} H_{0, 2} + \frac{1}{\pi TN } H_{0, 2}^{-1} Z' \Sigma_F^{-1} \sumN \Phi_{i, 1} \Sigma_F^{-1} Z H_{0, 2}^{- \tran}$,
and the remainder terms are asymptotically negligible by \Cref{lem:W_pool_remainder:1,lem:W_pool_remainder:2}. The asymptotic distribution then follows by \Cref{ext:ass:17:clt}, the convergence of $H_1, H_2$ and $\tilde{Z}$ to their probability limits, and the consistency of $\tilde{\Omega}_{W}$ for $\Omega_W$.
\end{proof}

% final push!
% Main proof of the actual wald test... ----------------------------------
% This is sloppy and needs to be redone
%\begin{proof}[Proof of \Cref{ext:thm:W_test_distribution}]
%We have the convergence of $\sqrt{T}(\tilde{w}_i - H_2^{-1}w_i)$ to its infeasible counterpart by \Cref{ext:thm:11:W_pool_ind_dist} and $\tilde{\Omega}_{W_i}$ to $\Omega_{W_i}$ which is nonsingular. Together, these imply $W_i - W_i^* = o_p(1)$ and the asymptotic distribution follows. 
%
%% This is also sloppy and needs to be redone
%Similarly, we have the convergence of $\sqrt{TN}(\fracN \sumN \tilde{w}_i - H_2^{-1}w_i)$ to its infeasible counterpart by \Cref{ext:thm:11:W_pool_ind_dist}, and the $\tilde{\Omega}_W$ to $\Omega_W$, which is also nonsingular. Together, these imply $\mathscr{W}_W - \mathscr{W}_W^* = o_p(1)$ and the asymptotic distribution follows.
%\end{proof}

% W test alternative proof -----------------------------------------------
% The individual one is sloppy, but kind of obvious?
\begin{proof}[Proof of \Cref{ext:thm:11:W_test_alter_cons}]
% Individual Test
We will show that $\mathscr{W}_{W, i} \to \infty$ as $N, T \to \infty$ when $w_i \neq 0$.
Recalling the asymptotic expansion of $\tilde{w}_i$, we have:
\begin{align*}
\tilde{w}_i = &(H_{2}^{-1} w_i) +
H_{2}^{-1} \frac{1}{(1 - \pi){T}} \sumTfloort f_t e_{it} - 
\tilde{Z}^\tran \frac{1}{\pi {T}} \sumTfloor H_1^\tran f_t e_{it} +
\OprtTdeltasq  \\
= &H_2^{-1} w_i + \OprtT + \OprtTdeltasq, \\
= &H_2^{-1} w_i + o_p(1).
\end{align*}
Because $\tilde{\Omega}_{W, i} \convp \Omega_{W, i}$ and $\Omega_{W, i}$ is positive definite, it follows that $\tilde{\Omega}_{W, i}^{-1} = \Op{1}$ and we have the desired result:
\begin{align*}
\plimNT \inf \left( 
	\frac{1}{\sqrt{T}} W_{W_i}
\right) = \plimNT \inf \left( 
	\tilde{w}_i^\tran \Omega_{W, i}^{-1} \tilde{w}_i
\right) > 0
\end{align*}
which implies the desired divergence under the alternative hypothesis.
% Pooled Test
% This is much sloppier
We will show that $\mathscr{W}_W \to \infty$ as $N, T \to \infty$ under the alternative. We have:
\begin{align*}
&(T^{\alpha / 2}) \left( \frac{\sumN \tilde{w}_i}{\sqrt{N}}\right) \\
= &T^{\alpha / 2} \frac{\sumN (H_{2}^{-1} w_i)}{\sqrt{N}} + 
H_{2}^\tran \frac{T^{\alpha / 2}}{(1 - \pi) T \sqrt{N}} \sumN \sumTfloorts f_s e_{is} - 
\tilde{Z}^\tran \frac{T^{\alpha / 2}}{\pi T \sqrt{N}} \sumN \sumTfloors H_1^\tran f_s e_{is} +
\Op{\frac{T^{\alpha/2}}{\delta_{NT}^2}}
\\
= &H_2^\tran T^{\alpha / 2} \frac{\sumN (H_{2}^{-1} w_i)}{\sqrt{N}} + H_{2}^\tran \frac{1}{(1 - \pi)T^{1 - \alpha/2}} \Op{1} - 
\tilde{Z}^\tran H_1^\tran \frac{1}{\pi T^{1 - \alpha/2}} \Op{1} +
\Op{\frac{T^{\alpha/2}}{\delta_{NT}^2}} \\
= &H_2^\tran T^{\alpha / 2} \frac{\sumN (H_{2}^{-1} w_i)}{\sqrt{N}} + \Op{\frac{1}{T^{1 - \alpha/2}}} + \Op{\frac{T^{\alpha/2}}{\delta_{NT}^2}},
\end{align*}
where the last two terms are $o_p(1)$ because $0 < \alpha \leq 0.5$ and $\sqrt{T}/N \to 0$ as $N, T \to \infty$. Since $\tilde{\Omega}_W \convp \Omega_W$ and $\Omega_W$ is positive definite, it follows that $\tilde{\Omega}_W^{-1} = \Op{1}$ and we have the desired result by \Cref{ext:ass:18:W_test_alter_assump}:
\begin{align*}
&\plimNT \inf \left( \frac{T^{\alpha}}{T} \mathscr{W}_W \right) \\
= &\plimNT \inf \left[ 
	(T^{\alpha}) \left( \frac{\sumN \tilde{w}_i}{\sqrt{N}}\right)^\tran (\tilde{\Omega}_{W})^{-1} \left( \frac{\sumN \tilde{w}_i}{\sqrt{N}}\right)
\right] > 0,
\end{align*}
which implies the desired divergence under the alternative hypothesis.
\end{proof}

\newpage 

% Variance Decomposition Details ---------------------------------------------
% Move the technical details of the variance decomposition to the Appendix
\section{Variance Decomposition Details}
\label{app:variance_decomposition}
We detail the variance decomposition procedure for the empirical study. First, we decompose the common component in the second regime $\widehat{X}_2$ as follows:
\begin{align}
\widehat{X}_2 
&= \tilde{F}_2 \tilde{\Lambda}_2^\tran = 
 \tilde{F}_2 \left(\tilde{\Lambda}_1 \tilde{Z} + \tilde{W} \right)^\tran \\
&= \tilde{F}_2 \left(\tilde{\Lambda}_1 \tilde{Z} \right)^\tran +
\tilde{F}_{2} \tilde{W}^\tran.
\end{align}
To impose variance restrictions on the common components, recall that $V_{NT, 1}, V_{NT, 2}$ converge to $V_1, V_2$, where $V_1, V_2$ are diagonal matrices consisting of the eigenvalues of $\Sigma_{\Lambda_1}^{1/2} \Sigma_F \Sigma_{\Lambda_1}^{1/2}$ and $(Z^\tran \Sigma_{\Lambda_1} Z + \Sigma_W)^{1/2} \Sigma_F (Z^\tran \Sigma_{\Lambda_1} Z + \Sigma_W)^{1/2}$ respectively. The matrices $V_{NT, 1}, V_{NT, 2}$ therefore can be used directly to deflate or inflate the variance of the estimates of the common component. For example, $\tilde{F}_2 \left( V_{NT, 2}^{-1/2} \right) \left( V_{NT, 1}^{1/2} \right)  \tilde{\Lambda}_2^\tran$ deflates the variance by the total variance in the second regime, but then inflates the variance by the total variance in the first regime in order to ``set'' the variance equal that of the first regime. Note that however, this can only control for the overall variability, and cannot control for the scenario where the factors rotate in such a way where the overall signal/noise ratio is similar after the break, i.e. when the ordering of the factors has changed. Combined with the mechanical ability to set $\tilde{W} = 0$, versions of $\widehat{X}_2$ with the restrictions $W = 0$, $Z = I$ and $Z = I, W = 0$ can be imposed the following way:
\begin{align*}
\widehat{X}_{2, W = 0} 
&= \tilde{F}_2 \left(\tilde{\Lambda}_1 \tilde{Z} \right)^\tran, \\
\widehat{X}_{2, Z = I} 
&= \tilde{F}_2 \left( V_{NT, 2}^{-1/2} \right) \left( V_{NT, 1}^{1/2} \right)  \left(\tilde{\Lambda}_1 \tilde{Z} \right)^\tran +
\tilde{F}_{2} \tilde{W}^\tran, \\
\widehat{X}_{2, Z = I, W = 0} 
&= \tilde{F}_2 \left( V_{NT, 2}^{-1/2} \right) \left( V_{NT, 1}^{1/2} \right)  \left(\tilde{\Lambda}_1 \tilde{Z} \right)^\tran.
\end{align*}
These can then be combined with $\widehat{X}_1 = \tilde{F}_1 \tilde{\Lambda}_1^\tran$ in order to produce $R^2$ to compare with the fully unrestricted common component
\begin{align*}
\widehat{X} = 
\begin{bmatrix}
\widehat{X}_1 \\
\widehat{X}_2
\end{bmatrix} = 
\begin{bmatrix}
\tilde{F}_1 \tilde{\Lambda}_1^\tran \\
\tilde{F}_2 \tilde{\Lambda}_2^\tran
\end{bmatrix}.
\end{align*}

% Additional simulation results ----------------------------------------------
% Currently, this is just a repeat, but the plan is to present a short version of the
% results in the main paper, 
% and have all of the table sin the appendix here
\section{Additional Tables}
\subsection{Additional Simulation Results}
\label{app:simulation_results}
% Make all of these smaller in text size... No point in having them as large
% Size tables
\begin{footnotesize}
\begin{ThreePartTable}
\begin{TableNotes}
\item \textit{Note: } 
\item Nominal size is 5\%. All HAC estimates based on Newey and West's method.
\end{TableNotes}
\begin{longtable}[t]{cccccccccc}
\caption{\label{tab:size}Size of Rotation and Orthogonal Shift Tests, $r = 3$}\\
\toprule
\multicolumn{5}{c}{ } & \multicolumn{2}{c}{Z Test} & \multicolumn{2}{c}{W Test} & \multicolumn{1}{c}{W Individual} \\
\cmidrule(l{3pt}r{3pt}){6-7} \cmidrule(l{3pt}r{3pt}){8-9} \cmidrule(l{3pt}r{3pt}){10-10}
$T$ & $N$ & $\rho$ & $\alpha$ & $\beta$ & Unadjusted & Adjusted & Unadjusted & Adjusted &  \\
\midrule
200 & 100 &  &  & 0.0 & 0.132 & 0.084 & 0.001 & 0.001 & 0.015\\
\nopagebreak
200 & 100 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 0.135 & 0.089 & 0.078 & 0.049 & 0.016\\
\nopagebreak
200 & 100 &  &  & 0.0 & 0.139 & 0.086 & 0.001 & 0.000 & 0.015\\
\nopagebreak
200 & 100 & \multirow{-4}{*}{\centering\arraybackslash 0.0} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 0.125 & 0.086 & 0.089 & 0.057 & 0.016\\
\cmidrule{1-10}\pagebreak[0]
200 & 100 &  &  & 0.0 & 0.237 & 0.175 & 0.002 & 0.002 & 0.018\\
\nopagebreak
200 & 100 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 0.244 & 0.177 & 0.074 & 0.046 & 0.019\\
\nopagebreak
200 & 100 &  &  & 0.0 & 0.230 & 0.165 & 0.007 & 0.003 & 0.029\\
\nopagebreak
200 & 100 & \multirow{-4}{*}{\centering\arraybackslash 0.7} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 0.228 & 0.167 & 0.112 & 0.076 & 0.030\\
\cmidrule{1-10}\pagebreak[0]
200 & 200 &  &  & 0.0 & 0.108 & 0.072 & 0.005 & 0.003 & 0.013\\
\nopagebreak
200 & 200 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 0.113 & 0.075 & 0.077 & 0.045 & 0.014\\
\nopagebreak
200 & 200 &  &  & 0.0 & 0.116 & 0.070 & 0.005 & 0.000 & 0.014\\
\nopagebreak
200 & 200 & \multirow{-4}{*}{\centering\arraybackslash 0.0} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 0.115 & 0.076 & 0.088 & 0.053 & 0.014\\
\cmidrule{1-10}\pagebreak[0]
200 & 200 &  &  & 0.0 & 0.243 & 0.160 & 0.003 & 0.002 & 0.017\\
\nopagebreak
200 & 200 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 0.247 & 0.171 & 0.061 & 0.038 & 0.017\\
\nopagebreak
200 & 200 &  &  & 0.0 & 0.243 & 0.164 & 0.005 & 0.002 & 0.027\\
\nopagebreak
200 & 200 & \multirow{-4}{*}{\centering\arraybackslash 0.7} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 0.239 & 0.174 & 0.096 & 0.066 & 0.027\\
\cmidrule{1-10}\pagebreak[0]
200 & 500 &  &  &  & 0.128 & 0.075 & 0.005 & 0.002 & 0.012\\
\nopagebreak
500 & 100 &  &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.068 & 0.032 & 0.007 & 0.002 & 0.005\\
\nopagebreak
500 & 100 &  & \multirow{-3}{*}{\centering\arraybackslash 0.0} & 0.3 & 0.066 & 0.038 & 0.072 & 0.045 & 0.006\\
\nopagebreak
500 & 100 &  &  & 0.0 & 0.061 & 0.037 & 0.004 & 0.002 & 0.005\\
\nopagebreak
500 & 100 & \multirow{-5}{*}{\centering\arraybackslash 0.0} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 0.066 & 0.039 & 0.078 & 0.041 & 0.006\\
\cmidrule{1-10}\pagebreak[0]
500 & 100 &  &  & 0.0 & 0.144 & 0.088 & 0.002 & 0.001 & 0.005\\
\nopagebreak
500 & 100 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 0.147 & 0.098 & 0.073 & 0.044 & 0.005\\
\nopagebreak
500 & 100 &  &  & 0.0 & 0.143 & 0.087 & 0.005 & 0.003 & 0.011\\
\nopagebreak
500 & 100 & \multirow{-4}{*}{\centering\arraybackslash 0.7} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 0.144 & 0.096 & 0.085 & 0.062 & 0.011\\
\cmidrule{1-10}\pagebreak[0]
500 & 200 &  &  & 0.0 & 0.068 & 0.031 & 0.003 & 0.001 & 0.004\\
\nopagebreak
500 & 200 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 0.068 & 0.033 & 0.053 & 0.024 & 0.004\\
\nopagebreak
500 & 200 &  &  & 0.0 & 0.072 & 0.033 & 0.003 & 0.002 & 0.004\\
\nopagebreak
500 & 200 & \multirow{-4}{*}{\centering\arraybackslash 0.0} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 0.070 & 0.037 & 0.061 & 0.027 & 0.004\\
\cmidrule{1-10}\pagebreak[0]
500 & 200 &  &  & 0.0 & 0.151 & 0.093 & 0.000 & 0.000 & 0.005\\
\nopagebreak
500 & 200 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 0.151 & 0.097 & 0.051 & 0.023 & 0.005\\
\nopagebreak
500 & 200 &  &  & 0.0 & 0.142 & 0.093 & 0.001 & 0.001 & 0.009\\
\nopagebreak
500 & 200 & \multirow{-4}{*}{\centering\arraybackslash 0.7} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 0.144 & 0.095 & 0.074 & 0.047 & 0.009\\
\cmidrule{1-10}\pagebreak[0]
500 & 500 &  &  & 0.0 & 0.065 & 0.035 & 0.003 & 0.003 & 0.004\\
\nopagebreak
500 & 500 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 0.062 & 0.034 & 0.049 & 0.028 & 0.004\\
\nopagebreak
500 & 500 &  &  & 0.0 & 0.066 & 0.038 & 0.003 & 0.000 & 0.004\\
\nopagebreak
500 & 500 & \multirow{-4}{*}{\centering\arraybackslash 0.0} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 0.064 & 0.037 & 0.056 & 0.027 & 0.004\\
\cmidrule{1-10}\pagebreak[0]
500 & 500 &  &  & 0.0 & 0.147 & 0.098 & 0.005 & 0.002 & 0.005\\
\nopagebreak
500 & 500 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 0.150 & 0.103 & 0.057 & 0.038 & 0.005\\
\nopagebreak
500 & 500 &  &  & 0.0 & 0.148 & 0.099 & 0.005 & 0.002 & 0.009\\
\nopagebreak
500 & 500 & \multirow{-4}{*}{\centering\arraybackslash 0.7} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 0.149 & 0.102 & 0.065 & 0.045 & 0.009\\
\cmidrule{1-10}\pagebreak[0]
1000 & 100 &  & 0.0 &  & 0.059 & 0.032 & 0.001 & 0.000 & 0.003\\
\nopagebreak
1000 & 100 & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 &  & 0.056 & 0.026 & 0.003 & 0.000 & 0.004\\
\nopagebreak
1000 & 100 & 0.7 &  &  & 0.116 & 0.073 & 0.002 & 0.000 & 0.003\\
\nopagebreak
1000 & 200 & 0.0 &  &  & 0.056 & 0.031 & 0.001 & 0.000 & 0.003\\
\nopagebreak
1000 & 200 &  &  & \multirow{-5}{*}{\centering\arraybackslash 0.0} & 0.112 & 0.065 & 0.002 & 0.002 & 0.003\\
\nopagebreak
1000 & 200 &  & \multirow{-4}{*}{\centering\arraybackslash 0.0} & 0.3 & 0.117 & 0.067 & 0.041 & 0.024 & 0.003\\
\nopagebreak
1000 & 200 &  &  & 0.0 & 0.115 & 0.064 & 0.004 & 0.002 & 0.006\\
\nopagebreak
1000 & 200 & \multirow{-4}{*}{\centering\arraybackslash 0.7} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 0.116 & 0.069 & 0.062 & 0.030 & 0.006\\
\cmidrule{1-10}\pagebreak[0]
1000 & 500 & 0.0 &  &  & 0.056 & 0.030 & 0.001 & 0.001 & 0.003\\
\nopagebreak
1000 & 500 & 0.7 &  &  & 0.086 & 0.048 & 0.000 & 0.000 & 0.003\\
\nopagebreak
1500 & 100 &  & \multirow{-3}{*}{\centering\arraybackslash 0.0} &  & 0.066 & 0.030 & 0.000 & 0.000 & 0.003\\
\nopagebreak
1500 & 100 & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 &  & 0.070 & 0.025 & 0.000 & 0.000 & 0.003\\
\nopagebreak
1500 & 100 & 0.7 &  &  & 0.096 & 0.057 & 0.002 & 0.000 & 0.003\\
\nopagebreak
1500 & 200 & 0.0 &  &  & 0.053 & 0.036 & 0.004 & 0.002 & 0.003\\
\nopagebreak
1500 & 200 & 0.7 &  &  & 0.088 & 0.050 & 0.001 & 0.000 & 0.003\\
\nopagebreak
1500 & 500 & 0.0 &  &  & 0.058 & 0.028 & 0.002 & 0.001 & 0.002\\
\nopagebreak
1500 & 500 & 0.7 & \multirow{-5}{*}{\centering\arraybackslash 0.0} & \multirow{-9}{*}{\centering\arraybackslash 0.0} & 0.095 & 0.057 & 0.002 & 0.001 & 0.002\\
\bottomrule
\insertTableNotes
\end{longtable}
\end{ThreePartTable}
\end{footnotesize}

%We note that the oversizing issue of the $Z$ rotational test is mostly evident for $\rho = 0.7$, but that this is alleviated as $T$ increases.

\begin{footnotesize}
% Z Test Power
\begin{longtable}[t]{ccccccccccc}
\caption{\label{tab:z_power}Power of $Z$ Rotation Test, $r = 3$}\\
\toprule
\multicolumn{5}{c}{ } & \multicolumn{2}{c}{Z Test} & \multicolumn{2}{c}{W Test} & \multicolumn{2}{c}{ } \\
\cmidrule(l{3pt}r{3pt}){6-7} \cmidrule(l{3pt}r{3pt}){8-9}
$T$ & $N$ & $\rho$ & $\alpha$ & $\beta$ & Unadjusted & Adjusted & Unadjusted & Adjusted & HI Test & BKW Test\\
\midrule
200 & 100 &  &  & 0.0 & 1.000 & 1.000 & 0.0060 & 0.0060 & 1.000 & 1.000\\
\nopagebreak
200 & 100 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 1.000 & 1.000 & 0.1370 & 0.1370 & 1.000 & 1.000\\
\nopagebreak
200 & 100 &  &  & 0.0 & 1.000 & 1.000 & 0.0040 & 0.0040 & 1.000 & 1.000\\
\nopagebreak
200 & 100 & \multirow{-4}{*}{\centering\arraybackslash 0.0} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 1.000 & 1.000 & 0.1750 & 0.1750 & 1.000 & 1.000\\
\cmidrule{1-11}\pagebreak[0]
200 & 100 &  &  & 0.0 & 1.000 & 1.000 & 0.0090 & 0.0090 & 1.000 & 1.000\\
\nopagebreak
200 & 100 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 0.999 & 0.999 & 0.0990 & 0.0990 & 1.000 & 1.000\\
\nopagebreak
200 & 100 &  &  & 0.0 & 0.999 & 0.998 & 0.0130 & 0.0130 & 1.000 & 1.000\\
\nopagebreak
200 & 100 & \multirow{-4}{*}{\centering\arraybackslash 0.7} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 1.000 & 1.000 & 0.1470 & 0.1470 & 1.000 & 1.000\\
\cmidrule{1-11}\pagebreak[0]
200 & 200 &  &  & 0.0 & 1.000 & 1.000 & 0.0040 & 0.0040 & 1.000 & 1.000\\
\nopagebreak
200 & 200 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 1.000 & 1.000 & 0.0850 & 0.0840 & 1.000 & 1.000\\
\nopagebreak
200 & 200 &  &  & 0.0 & 1.000 & 1.000 & 0.0075 & 0.0075 & 1.000 & 1.000\\
\nopagebreak
200 & 200 & \multirow{-4}{*}{\centering\arraybackslash 0.0} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 1.000 & 1.000 & 0.1000 & 0.1000 & 1.000 & 1.000\\
\cmidrule{1-11}\pagebreak[0]
200 & 200 &  &  & 0.0 & 1.000 & 1.000 & 0.0030 & 0.0030 & 1.000 & 1.000\\
\nopagebreak
200 & 200 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 1.000 & 1.000 & 0.0750 & 0.0750 & 1.000 & 1.000\\
\nopagebreak
200 & 200 &  &  & 0.0 & 1.000 & 1.000 & 0.0110 & 0.0110 & 1.000 & 1.000\\
\nopagebreak
200 & 200 & \multirow{-4}{*}{\centering\arraybackslash 0.7} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 1.000 & 1.000 & 0.1060 & 0.1060 & 1.000 & 1.000\\
\cmidrule{1-11}\pagebreak[0]
500 & 100 &  &  & 0.0 & 1.000 & 1.000 & 0.0080 & 0.0080 & 1.000 & 1.000\\
\nopagebreak
500 & 100 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 1.000 & 1.000 & 0.1510 & 0.1510 & 1.000 & 1.000\\
\nopagebreak
500 & 100 &  &  & 0.0 & 1.000 & 1.000 & 0.0085 & 0.0085 & 1.000 & 1.000\\
\nopagebreak
500 & 100 & \multirow{-4}{*}{\centering\arraybackslash 0.0} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 1.000 & 1.000 & 0.1660 & 0.1660 & 1.000 & 1.000\\
\cmidrule{1-11}\pagebreak[0]
500 & 100 &  &  & 0.0 & 1.000 & 1.000 & 0.0065 & 0.0065 & 1.000 & 1.000\\
\nopagebreak
500 & 100 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 1.000 & 1.000 & 0.1040 & 0.1040 & 1.000 & 1.000\\
\nopagebreak
500 & 100 &  &  & 0.0 & 1.000 & 1.000 & 0.0100 & 0.0100 & 1.000 & 1.000\\
\nopagebreak
500 & 100 & \multirow{-4}{*}{\centering\arraybackslash 0.7} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 1.000 & 1.000 & 0.1200 & 0.1200 & 1.000 & 1.000\\
\cmidrule{1-11}\pagebreak[0]
500 & 200 &  &  & 0.0 & 1.000 & 1.000 & 0.0020 & 0.0020 & 1.000 & 1.000\\
\nopagebreak
500 & 200 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 1.000 & 1.000 & 0.0790 & 0.0790 & 1.000 & 1.000\\
\nopagebreak
500 & 200 &  &  & 0.0 & 1.000 & 1.000 & 0.0025 & 0.0025 & 1.000 & 1.000\\
\nopagebreak
500 & 200 & \multirow{-4}{*}{\centering\arraybackslash 0.0} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 1.000 & 1.000 & 0.0940 & 0.0940 & 1.000 & 1.000\\
\cmidrule{1-11}\pagebreak[0]
500 & 200 &  &  & 0.0 & 1.000 & 1.000 & 0.0010 & 0.0010 & 1.000 & 1.000\\
\nopagebreak
500 & 200 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 1.000 & 1.000 & 0.0640 & 0.0640 & 1.000 & 1.000\\
\nopagebreak
500 & 200 &  &  & 0.0 & 1.000 & 1.000 & 0.0050 & 0.0050 & 1.000 & 1.000\\
\nopagebreak
500 & 200 & \multirow{-4}{*}{\centering\arraybackslash 0.7} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 1.000 & 1.000 & 0.0960 & 0.0960 & 1.000 & 1.000\\
\cmidrule{1-11}\pagebreak[0]
500 & 500 &  &  & 0.0 & 1.000 & 1.000 & 0.0040 & 0.0040 & 1.000 & 1.000\\
\nopagebreak
500 & 500 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 1.000 & 1.000 & 0.0740 & 0.0740 & 1.000 & 1.000\\
\nopagebreak
500 & 500 &  &  & 0.0 & 1.000 & 1.000 & 0.0040 & 0.0040 & 1.000 & 1.000\\
\nopagebreak
500 & 500 & \multirow{-4}{*}{\centering\arraybackslash 0.0} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 1.000 & 1.000 & 0.0750 & 0.0750 & 1.000 & 1.000\\
\cmidrule{1-11}\pagebreak[0]
500 & 500 &  &  & 0.0 & 1.000 & 1.000 & 0.0040 & 0.0040 & 1.000 & 1.000\\
\nopagebreak
500 & 500 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 1.000 & 1.000 & 0.0590 & 0.0590 & 1.000 & 1.000\\
\nopagebreak
500 & 500 &  &  & 0.0 & 1.000 & 1.000 & 0.0080 & 0.0080 & 1.000 & 1.000\\
\nopagebreak
500 & 500 & \multirow{-4}{*}{\centering\arraybackslash 0.7} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 1.000 & 1.000 & 0.0900 & 0.0900 & 1.000 & 1.000\\
\bottomrule
\end{longtable}
% W Test Power
% Split these into two different tables and see how good they look
% \input{../monte_carlo/projection_w_power.tex}
\begin{longtable}[t]{ccccccccccccc}
\caption{\label{tab:w_power_05}Power of $W$ Orthogonal Shift Test, $r = 3$, $\omega = 0.5$}\\
\toprule
\multicolumn{5}{c}{ } & \multicolumn{2}{c}{Z Test} & \multicolumn{3}{c}{W Test} & \multicolumn{2}{c}{ } \\
\cmidrule(l{3pt}r{3pt}){6-7} \cmidrule(l{3pt}r{3pt}){8-10}
$T$ & $N$ & $\rho$ & $\alpha$ & $\beta$ & Unadj. & Adj. & Unadj. & Adj. & Individual & HI & BKW & $\tilde{r}$\\
\midrule
200 & 100 &  &  & 0.0 & 0.134 & 0.091 & 0.100 & 0.068 & 0.130 & 0.176 & 0.038 & 3\\
\nopagebreak
200 & 100 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 0.133 & 0.098 & 0.236 & 0.177 & 0.133 & 0.187 & 0.039 & 3\\
\nopagebreak
200 & 100 &  &  & 0.0 & 0.133 & 0.095 & 0.094 & 0.060 & 0.119 & 0.172 & 0.040 & 3\\
\nopagebreak
200 & 100 & \multirow{-4}{*}{\centering\arraybackslash 0.0} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 0.130 & 0.098 & 0.232 & 0.171 & 0.122 & 0.177 & 0.040 & 3\\
\cmidrule{1-13}\pagebreak[0]
200 & 100 &  &  & 0.0 & 0.135 & 0.092 & 0.253 & 0.190 & 0.276 & 0.274 & 0.116 & 3\\
\nopagebreak
200 & 100 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 0.128 & 0.098 & 0.365 & 0.303 & 0.278 & 0.274 & 0.120 & 3\\
\nopagebreak
200 & 100 &  &  & 0.0 & 0.127 & 0.085 & 0.183 & 0.125 & 0.214 & 0.279 & 0.118 & 3\\
\nopagebreak
200 & 100 & \multirow{-4}{*}{\centering\arraybackslash 0.7} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 0.128 & 0.092 & 0.327 & 0.253 & 0.217 & 0.277 & 0.119 & 3\\
\cmidrule{1-13}\pagebreak[0]
200 & 200 &  &  & 0.0 & 0.111 & 0.074 & 0.093 & 0.055 & 0.123 & 0.143 & 0.037 & 3\\
\nopagebreak
200 & 200 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 0.115 & 0.077 & 0.227 & 0.154 & 0.124 & 0.147 & 0.040 & 3\\
\nopagebreak
200 & 200 &  &  & 0.0 & 0.118 & 0.077 & 0.087 & 0.046 & 0.111 & 0.141 & 0.039 & 3\\
\nopagebreak
200 & 200 & \multirow{-4}{*}{\centering\arraybackslash 0.0} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 0.117 & 0.081 & 0.199 & 0.145 & 0.112 & 0.146 & 0.037 & 3\\
\cmidrule{1-13}\pagebreak[0]
200 & 200 &  &  & 0.0 & 0.245 & 0.178 & 0.246 & 0.188 & 0.266 & 0.275 & 0.110 & 3\\
\nopagebreak
200 & 200 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 0.247 & 0.192 & 0.365 & 0.297 & 0.267 & 0.276 & 0.112 & 3\\
\nopagebreak
200 & 200 &  &  & 0.0 & 0.244 & 0.176 & 0.167 & 0.122 & 0.207 & 0.278 & 0.112 & 3\\
\nopagebreak
200 & 200 & \multirow{-4}{*}{\centering\arraybackslash 0.7} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 0.239 & 0.186 & 0.309 & 0.245 & 0.207 & 0.274 & 0.112 & 3\\
\cmidrule{1-13}\pagebreak[0]
500 & 100 &  &  & 0.0 & 0.073 & 0.045 & 0.296 & 0.225 & 0.288 & 0.127 & 0.079 & 3\\
\nopagebreak
500 & 100 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 0.072 & 0.049 & 0.410 & 0.326 & 0.292 & 0.125 & 0.075 & 3\\
\nopagebreak
500 & 100 &  &  & 0.0 & 0.067 & 0.039 & 0.278 & 0.201 & 0.261 & 0.124 & 0.078 & 3\\
\nopagebreak
500 & 100 & \multirow{-4}{*}{\centering\arraybackslash 0.0} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 0.066 & 0.045 & 0.405 & 0.325 & 0.264 & 0.131 & 0.078 & 3\\
\cmidrule{1-13}\pagebreak[0]
500 & 100 &  &  & 0.0 & 0.069 & 0.061 & 0.538 & 0.460 & 0.521 & 0.198 & 0.119 & 3\\
\nopagebreak
500 & 100 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 0.067 & 0.058 & 0.593 & 0.528 & 0.522 & 0.200 & 0.117 & 3\\
\nopagebreak
500 & 100 &  &  & 0.0 & 0.067 & 0.054 & 0.401 & 0.331 & 0.397 & 0.192 & 0.116 & 3\\
\nopagebreak
500 & 100 & \multirow{-4}{*}{\centering\arraybackslash 0.7} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 0.068 & 0.056 & 0.503 & 0.424 & 0.396 & 0.202 & 0.120 & 3\\
\cmidrule{1-13}\pagebreak[0]
500 & 200 &  &  & 0.0 & 0.067 & 0.041 & 0.246 & 0.179 & 0.275 & 0.119 & 0.070 & 3\\
\nopagebreak
500 & 200 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 0.072 & 0.047 & 0.347 & 0.263 & 0.275 & 0.119 & 0.068 & 3\\
\nopagebreak
500 & 200 &  &  & 0.0 & 0.067 & 0.044 & 0.221 & 0.156 & 0.247 & 0.120 & 0.070 & 3\\
\nopagebreak
500 & 200 & \multirow{-4}{*}{\centering\arraybackslash 0.0} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 0.072 & 0.044 & 0.323 & 0.238 & 0.248 & 0.122 & 0.069 & 3\\
\cmidrule{1-13}\pagebreak[0]
500 & 200 &  &  & 0.0 & 0.075 & 0.058 & 0.495 & 0.419 & 0.508 & 0.188 & 0.115 & 3\\
\nopagebreak
500 & 200 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 0.072 & 0.058 & 0.551 & 0.486 & 0.509 & 0.192 & 0.115 & 3\\
\nopagebreak
500 & 200 &  &  & 0.0 & 0.064 & 0.045 & 0.373 & 0.299 & 0.383 & 0.196 & 0.112 & 3\\
\nopagebreak
500 & 200 & \multirow{-4}{*}{\centering\arraybackslash 0.7} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 0.066 & 0.045 & 0.473 & 0.379 & 0.384 & 0.190 & 0.113 & 3\\
\bottomrule
\end{longtable}
\begin{longtable}[t]{ccccccccccccc}
\caption{\label{tab:w_power_1}Power of $W$ Orthogonal Shift Test, $r = 3$, $\omega = 1$}\\
\toprule
\multicolumn{5}{c}{ } & \multicolumn{2}{c}{Z Test} & \multicolumn{3}{c}{W Test} & \multicolumn{2}{c}{ } \\
\cmidrule(l{3pt}r{3pt}){6-7} \cmidrule(l{3pt}r{3pt}){8-10}
$T$ & $N$ & $\rho$ & $\alpha$ & $\beta$ & Unadj. & Adj. & Unadj. & Adj. & Individual & HI & BKW & $\tilde{r}$\\
\midrule
200 & 100 &  &  & 0.0 & 0.154 & 0.142 & 0.856 & 0.834 & 0.872 & 1.000 & 1.000 & 5.499\\
\nopagebreak
200 & 100 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 0.151 & 0.142 & 0.871 & 0.849 & 0.872 & 1.000 & 1.000 & 5.549\\
\nopagebreak
200 & 100 &  &  & 0.0 & 0.157 & 0.143 & 0.838 & 0.812 & 0.855 & 1.000 & 1.000 & 4.890\\
\nopagebreak
200 & 100 & \multirow{-4}{*}{\centering\arraybackslash 0.0} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 0.151 & 0.141 & 0.852 & 0.826 & 0.856 & 1.000 & 1.000 & 5.007\\
\cmidrule{1-13}\pagebreak[0]
200 & 100 &  &  & 0.0 & 0.133 & 0.130 & 0.931 & 0.917 & 0.944 & 1.000 & 1.000 & 5.998\\
\nopagebreak
200 & 100 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 0.130 & 0.127 & 0.936 & 0.921 & 0.944 & 1.000 & 1.000 & 5.999\\
\nopagebreak
200 & 100 &  &  & 0.0 & 0.239 & 0.234 & 0.900 & 0.877 & 0.914 & 1.000 & 1.000 & 5.996\\
\nopagebreak
200 & 100 & \multirow{-4}{*}{\centering\arraybackslash 0.7} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 0.236 & 0.231 & 0.908 & 0.894 & 0.913 & 1.000 & 1.000 & 5.996\\
\cmidrule{1-13}\pagebreak[0]
200 & 200 &  &  & 0.0 & 0.134 & 0.124 & 0.870 & 0.835 & 0.866 & 1.000 & 1.000 & 5.980\\
\nopagebreak
200 & 200 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 0.139 & 0.133 & 0.883 & 0.845 & 0.866 & 1.000 & 1.000 & 5.985\\
\nopagebreak
200 & 200 &  &  & 0.0 & 0.131 & 0.122 & 0.854 & 0.818 & 0.849 & 1.000 & 1.000 & 5.923\\
\nopagebreak
200 & 200 & \multirow{-4}{*}{\centering\arraybackslash 0.0} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 0.136 & 0.129 & 0.860 & 0.821 & 0.849 & 1.000 & 1.000 & 5.928\\
\cmidrule{1-13}\pagebreak[0]
200 & 200 &  &  & 0.0 & 0.249 & 0.242 & 0.940 & 0.927 & 0.941 & 1.000 & 1.000 & 6.000\\
\nopagebreak
200 & 200 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 0.254 & 0.247 & 0.948 & 0.937 & 0.941 & 1.000 & 1.000 & 6.000\\
\nopagebreak
200 & 200 &  &  & 0.0 & 0.244 & 0.234 & 0.907 & 0.891 & 0.909 & 1.000 & 1.000 & 6.000\\
\nopagebreak
200 & 200 & \multirow{-4}{*}{\centering\arraybackslash 0.7} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 0.244 & 0.233 & 0.916 & 0.896 & 0.908 & 1.000 & 1.000 & 6.000\\
\cmidrule{1-13}\pagebreak[0]
500 & 100 &  &  & 0.0 & 0.093 & 0.092 & 0.954 & 0.935 & 0.955 & 1.000 & 1.000 & 6.000\\
\nopagebreak
500 & 100 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 0.092 & 0.090 & 0.959 & 0.944 & 0.955 & 1.000 & 1.000 & 6.000\\
\nopagebreak
500 & 100 &  &  & 0.0 & 0.093 & 0.090 & 0.948 & 0.927 & 0.950 & 1.000 & 1.000 & 6.000\\
\nopagebreak
500 & 100 & \multirow{-4}{*}{\centering\arraybackslash 0.0} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 0.091 & 0.086 & 0.951 & 0.938 & 0.950 & 1.000 & 1.000 & 6.000\\
\cmidrule{1-13}\pagebreak[0]
500 & 100 &  &  & 0.0 & 0.071 & 0.070 & 0.984 & 0.971 & 0.983 & 1.000 & 1.000 & 6.000\\
\nopagebreak
500 & 100 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 0.148 & 0.146 & 0.982 & 0.976 & 0.983 & 1.000 & 1.000 & 6.000\\
\nopagebreak
500 & 100 &  &  & 0.0 & 0.144 & 0.143 & 0.965 & 0.955 & 0.970 & 1.000 & 1.000 & 6.000\\
\nopagebreak
500 & 100 & \multirow{-4}{*}{\centering\arraybackslash 0.7} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 0.148 & 0.144 & 0.967 & 0.958 & 0.970 & 1.000 & 1.000 & 6.000\\
\cmidrule{1-13}\pagebreak[0]
500 & 200 &  &  & 0.0 & 0.078 & 0.074 & 0.955 & 0.951 & 0.953 & 1.000 & 1.000 & 6.000\\
\nopagebreak
500 & 200 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 0.080 & 0.077 & 0.953 & 0.945 & 0.954 & 1.000 & 1.000 & 6.000\\
\nopagebreak
500 & 200 &  &  & 0.0 & 0.075 & 0.073 & 0.954 & 0.938 & 0.947 & 1.000 & 1.000 & 6.000\\
\nopagebreak
500 & 200 & \multirow{-4}{*}{\centering\arraybackslash 0.0} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 0.079 & 0.076 & 0.950 & 0.939 & 0.947 & 1.000 & 1.000 & 6.000\\
\cmidrule{1-13}\pagebreak[0]
500 & 200 &  &  & 0.0 & 0.147 & 0.146 & 0.981 & 0.977 & 0.981 & 1.000 & 1.000 & 6.000\\
\nopagebreak
500 & 200 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 0.148 & 0.147 & 0.983 & 0.976 & 0.982 & 1.000 & 1.000 & 6.000\\
\nopagebreak
500 & 200 &  &  & 0.0 & 0.141 & 0.141 & 0.967 & 0.960 & 0.968 & 1.000 & 1.000 & 6.000\\
\nopagebreak
500 & 200 & \multirow{-4}{*}{\centering\arraybackslash 0.7} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 0.146 & 0.144 & 0.968 & 0.965 & 0.968 & 1.000 & 1.000 & 6.000\\
\bottomrule
\end{longtable}
% Z and W Tests Power
% Also split into two tables, small breaks and large breaks
\begin{longtable}[t]{ccccccccccccc}
\caption{\label{tab:z_w_power_05}Power of $Z$ and $W$ Tests, $r = 3$, $\omega = 0.5$}\\
\toprule
\multicolumn{5}{c}{ } & \multicolumn{2}{c}{Z Test} & \multicolumn{3}{c}{W Test} & \multicolumn{2}{c}{ } \\
\cmidrule(l{3pt}r{3pt}){6-7} \cmidrule(l{3pt}r{3pt}){8-10}
$T$ & $N$ & $\rho$ & $\alpha$ & $\beta$ & Unadj. & Adj. & Unadj. & Adj. & Individual & HI & BKW & $\tilde{r}$\\
\midrule
200 & 100 &  &  & 0.0 & 1.000 & 1.000 & 0.101 & 0.101 & 0.128 & 1.000 & 1.000 & 3\\
\nopagebreak
200 & 100 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 1.000 & 1.000 & 0.273 & 0.273 & 0.133 & 1.000 & 1.000 & 3\\
\nopagebreak
200 & 100 &  &  & 0.0 & 1.000 & 1.000 & 0.100 & 0.100 & 0.118 & 1.000 & 1.000 & 3\\
\nopagebreak
200 & 100 & \multirow{-4}{*}{\centering\arraybackslash 0.0} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 1.000 & 1.000 & 0.265 & 0.265 & 0.125 & 1.000 & 1.000 & 3\\
\cmidrule{1-13}\pagebreak[0]
200 & 100 &  &  & 0.0 & 1.000 & 1.000 & 0.220 & 0.220 & 0.240 & 1.000 & 1.000 & 3\\
\nopagebreak
200 & 100 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 1.000 & 1.000 & 0.359 & 0.359 & 0.242 & 1.000 & 1.000 & 3\\
\nopagebreak
200 & 100 &  &  & 0.0 & 1.000 & 1.000 & 0.172 & 0.172 & 0.195 & 1.000 & 1.000 & 3\\
\nopagebreak
200 & 100 & \multirow{-4}{*}{\centering\arraybackslash 0.7} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 1.000 & 1.000 & 0.321 & 0.321 & 0.199 & 1.000 & 1.000 & 3\\
\cmidrule{1-13}\pagebreak[0]
200 & 200 &  &  & 0.0 & 1.000 & 1.000 & 0.089 & 0.089 & 0.114 & 1.000 & 1.000 & 3\\
\nopagebreak
200 & 200 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 1.000 & 1.000 & 0.219 & 0.219 & 0.116 & 1.000 & 1.000 & 3\\
\nopagebreak
200 & 200 &  &  & 0.0 & 1.000 & 1.000 & 0.073 & 0.073 & 0.104 & 1.000 & 1.000 & 3\\
\nopagebreak
200 & 200 & \multirow{-4}{*}{\centering\arraybackslash 0.0} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 1.000 & 1.000 & 0.206 & 0.206 & 0.106 & 1.000 & 1.000 & 3\\
\cmidrule{1-13}\pagebreak[0]
200 & 200 &  &  & 0.0 & 1.000 & 1.000 & 0.181 & 0.181 & 0.225 & 1.000 & 1.000 & 3\\
\nopagebreak
200 & 200 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 1.000 & 1.000 & 0.321 & 0.321 & 0.226 & 1.000 & 1.000 & 3\\
\nopagebreak
200 & 200 &  &  & 0.0 & 1.000 & 1.000 & 0.143 & 0.143 & 0.181 & 1.000 & 1.000 & 3\\
\nopagebreak
200 & 200 & \multirow{-4}{*}{\centering\arraybackslash 0.7} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 1.000 & 1.000 & 0.281 & 0.281 & 0.183 & 1.000 & 1.000 & 3\\
\cmidrule{1-13}\pagebreak[0]
500 & 100 &  &  & 0.0 & 1.000 & 1.000 & 0.262 & 0.262 & 0.246 & 1.000 & 1.000 & 3\\
\nopagebreak
500 & 100 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 1.000 & 1.000 & 0.417 & 0.416 & 0.253 & 1.000 & 1.000 & 3\\
\nopagebreak
500 & 100 &  &  & 0.0 & 1.000 & 1.000 & 0.228 & 0.228 & 0.224 & 1.000 & 1.000 & 3\\
\nopagebreak
500 & 100 & \multirow{-4}{*}{\centering\arraybackslash 0.0} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 1.000 & 1.000 & 0.414 & 0.414 & 0.231 & 1.000 & 1.000 & 3\\
\cmidrule{1-13}\pagebreak[0]
500 & 100 &  &  & 0.0 & 1.000 & 1.000 & 0.444 & 0.444 & 0.426 & 1.000 & 1.000 & 3\\
\nopagebreak
500 & 100 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 1.000 & 1.000 & 0.529 & 0.529 & 0.429 & 1.000 & 1.000 & 3\\
\nopagebreak
500 & 100 &  &  & 0.0 & 1.000 & 1.000 & 0.339 & 0.338 & 0.328 & 1.000 & 1.000 & 3\\
\nopagebreak
500 & 100 & \multirow{-4}{*}{\centering\arraybackslash 0.7} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 1.000 & 1.000 & 0.465 & 0.465 & 0.331 & 1.000 & 1.000 & 3\\
\cmidrule{1-13}\pagebreak[0]
500 & 200 &  &  & 0.0 & 1.000 & 1.000 & 0.199 & 0.199 & 0.228 & 1.000 & 1.000 & 3\\
\nopagebreak
500 & 200 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 1.000 & 1.000 & 0.330 & 0.329 & 0.229 & 1.000 & 1.000 & 3\\
\nopagebreak
500 & 200 &  &  & 0.0 & 1.000 & 1.000 & 0.167 & 0.167 & 0.204 & 1.000 & 1.000 & 3\\
\nopagebreak
500 & 200 & \multirow{-4}{*}{\centering\arraybackslash 0.0} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 1.000 & 1.000 & 0.298 & 0.298 & 0.206 & 1.000 & 1.000 & 3\\
\cmidrule{1-13}\pagebreak[0]
500 & 200 &  &  & 0.0 & 1.000 & 1.000 & 0.407 & 0.407 & 0.414 & 1.000 & 1.000 & 3\\
\nopagebreak
500 & 200 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 1.000 & 1.000 & 0.498 & 0.498 & 0.414 & 1.000 & 1.000 & 3\\
\nopagebreak
500 & 200 &  &  & 0.0 & 1.000 & 1.000 & 0.297 & 0.297 & 0.315 & 1.000 & 1.000 & 3\\
\nopagebreak
500 & 200 & \multirow{-4}{*}{\centering\arraybackslash 0.7} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 1.000 & 1.000 & 0.407 & 0.407 & 0.315 & 1.000 & 1.000 & 3\\
\bottomrule
\end{longtable}
\begin{longtable}[t]{ccccccccccccc}
\caption{\label{tab:z_w_power_1}Power of $Z$ and $W$ Tests, $r = 3$, $\omega = 1$}\\
\toprule
\multicolumn{5}{c}{ } & \multicolumn{2}{c}{Z Test} & \multicolumn{3}{c}{W Test} & \multicolumn{2}{c}{ } \\
\cmidrule(l{3pt}r{3pt}){6-7} \cmidrule(l{3pt}r{3pt}){8-10}
$T$ & $N$ & $\rho$ & $\alpha$ & $\beta$ & Unadj. & Adj. & Unadj. & Adj. & Individual & HI & BKW & $\tilde{r}$\\
\midrule
200 & 100 &  &  & 0.0 & 1.000 & 1.000 & 0.784 & 0.784 & 0.792 & 1.000 & 1.000 & 4.069\\
\nopagebreak
200 & 100 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 1.000 & 1.000 & 0.803 & 0.803 & 0.792 & 1.000 & 1.000 & 4.088\\
\nopagebreak
200 & 100 &  &  & 0.0 & 1.000 & 1.000 & 0.764 & 0.764 & 0.771 & 1.000 & 1.000 & 4.026\\
\nopagebreak
200 & 100 & \multirow{-4}{*}{\centering\arraybackslash 0.0} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 1.000 & 1.000 & 0.785 & 0.785 & 0.773 & 1.000 & 1.000 & 4.030\\
\cmidrule{1-13}\pagebreak[0]
200 & 100 &  &  & 0.0 & 1.000 & 1.000 & 0.882 & 0.882 & 0.898 & 1.000 & 1.000 & 4.857\\
\nopagebreak
200 & 100 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 1.000 & 1.000 & 0.893 & 0.893 & 0.898 & 1.000 & 1.000 & 4.872\\
\nopagebreak
200 & 100 &  &  & 0.0 & 1.000 & 1.000 & 0.834 & 0.834 & 0.852 & 1.000 & 1.000 & 4.827\\
\nopagebreak
200 & 100 & \multirow{-4}{*}{\centering\arraybackslash 0.7} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 1.000 & 1.000 & 0.840 & 0.840 & 0.853 & 1.000 & 1.000 & 4.846\\
\cmidrule{1-13}\pagebreak[0]
200 & 200 &  &  & 0.0 & 1.000 & 1.000 & 0.801 & 0.800 & 0.785 & 1.000 & 1.000 & 4.310\\
\nopagebreak
200 & 200 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 1.000 & 1.000 & 0.820 & 0.820 & 0.785 & 1.000 & 1.000 & 4.318\\
\nopagebreak
200 & 200 &  &  & 0.0 & 1.000 & 1.000 & 0.773 & 0.772 & 0.764 & 1.000 & 1.000 & 4.188\\
\nopagebreak
200 & 200 & \multirow{-4}{*}{\centering\arraybackslash 0.0} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 1.000 & 1.000 & 0.804 & 0.803 & 0.765 & 1.000 & 1.000 & 4.206\\
\cmidrule{1-13}\pagebreak[0]
200 & 200 &  &  & 0.0 & 1.000 & 1.000 & 0.899 & 0.899 & 0.894 & 1.000 & 1.000 & 5.046\\
\nopagebreak
200 & 200 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 1.000 & 1.000 & 0.909 & 0.909 & 0.893 & 1.000 & 1.000 & 5.053\\
\nopagebreak
200 & 200 &  &  & 0.0 & 1.000 & 1.000 & 0.860 & 0.860 & 0.846 & 1.000 & 1.000 & 5.039\\
\nopagebreak
200 & 200 & \multirow{-4}{*}{\centering\arraybackslash 0.7} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 1.000 & 1.000 & 0.867 & 0.867 & 0.846 & 1.000 & 1.000 & 5.047\\
\cmidrule{1-13}\pagebreak[0]
500 & 100 &  &  & 0.0 & 1.000 & 1.000 & 0.903 & 0.903 & 0.916 & 1.000 & 1.000 & 4.330\\
\nopagebreak
500 & 100 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 1.000 & 1.000 & 0.917 & 0.917 & 0.916 & 1.000 & 1.000 & 4.365\\
\nopagebreak
500 & 100 &  &  & 0.0 & 1.000 & 1.000 & 0.898 & 0.898 & 0.905 & 1.000 & 1.000 & 4.168\\
\nopagebreak
500 & 100 & \multirow{-4}{*}{\centering\arraybackslash 0.0} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 1.000 & 1.000 & 0.909 & 0.909 & 0.906 & 1.000 & 1.000 & 4.191\\
\cmidrule{1-13}\pagebreak[0]
500 & 100 &  &  & 0.0 & 1.000 & 1.000 & 0.960 & 0.960 & 0.964 & 1.000 & 1.000 & 5.049\\
\nopagebreak
500 & 100 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 1.000 & 1.000 & 0.960 & 0.960 & 0.964 & 1.000 & 1.000 & 5.065\\
\nopagebreak
500 & 100 &  &  & 0.0 & 1.000 & 1.000 & 0.936 & 0.936 & 0.940 & 1.000 & 1.000 & 4.999\\
\nopagebreak
500 & 100 & \multirow{-4}{*}{\centering\arraybackslash 0.7} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 1.000 & 1.000 & 0.938 & 0.938 & 0.940 & 1.000 & 1.000 & 5.012\\
\cmidrule{1-13}\pagebreak[0]
500 & 200 &  &  & 0.0 & 1.000 & 1.000 & 0.924 & 0.924 & 0.911 & 1.000 & 1.000 & 4.858\\
\nopagebreak
500 & 200 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 1.000 & 1.000 & 0.927 & 0.927 & 0.912 & 1.000 & 1.000 & 4.863\\
\nopagebreak
500 & 200 &  &  & 0.0 & 1.000 & 1.000 & 0.913 & 0.913 & 0.901 & 1.000 & 1.000 & 4.769\\
\nopagebreak
500 & 200 & \multirow{-4}{*}{\centering\arraybackslash 0.0} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 1.000 & 1.000 & 0.919 & 0.919 & 0.901 & 1.000 & 1.000 & 4.772\\
\cmidrule{1-13}\pagebreak[0]
500 & 200 &  &  & 0.0 & 1.000 & 1.000 & 0.964 & 0.964 & 0.962 & 1.000 & 1.000 & 5.568\\
\nopagebreak
500 & 200 &  & \multirow{-2}{*}{\centering\arraybackslash 0.0} & 0.3 & 1.000 & 1.000 & 0.965 & 0.965 & 0.962 & 1.000 & 1.000 & 5.583\\
\nopagebreak
500 & 200 &  &  & 0.0 & 1.000 & 1.000 & 0.946 & 0.945 & 0.938 & 1.000 & 1.000 & 5.491\\
\nopagebreak
500 & 200 & \multirow{-4}{*}{\centering\arraybackslash 0.7} & \multirow{-2}{*}{\centering\arraybackslash 0.3} & 0.3 & 1.000 & 1.000 & 0.946 & 0.946 & 0.938 & 1.000 & 1.000 & 5.511\\
\bottomrule
\end{longtable}
\end{footnotesize}

\subsection{Additional Empirical Results}
\label{app:additional_empirical_results}

% Comprehensive rtilde tables
% maybe include dicussion about weak/strong factors?
\begin{footnotesize}
\begin{longtable}[t]{cccccc}
\caption{\label{tab:rtilde_full}Subsample $\tilde{r}$ Estimates}\\
\toprule
\multicolumn{1}{c}{ } & \multicolumn{2}{c}{Bai and Ng (2002)} & \multicolumn{1}{c}{Onatski (2010)} & \multicolumn{2}{c}{Ahn and Horenstein (2013)} \\
\cmidrule(l{3pt}r{3pt}){2-3} \cmidrule(l{3pt}r{3pt}){4-4} \cmidrule(l{3pt}r{3pt}){5-6}
Sample & $IC_{p1}$ & $IC_{p2}$ & Edge Distribution & Eigenvalue Ratio & Growth Ratio\\
\midrule
\addlinespace[0.3em]
\multicolumn{6}{l}{\textbf{Great Moderation (1984 February) Sample}}\\
\hspace{1em}Whole & 6 & 6 & 6 & 1 & 1\\
\hspace{1em}Pre-break & 7 & 5 & 4 & 1 & 1\\
\hspace{1em}Post-break & 7 & 6 & 3 & 3 & 3\\
\addlinespace[0.3em]
\multicolumn{6}{l}{\textbf{Global Financial Crisis (2008 November) Sample}}\\
\hspace{1em}Whole & 9 & 6 & 4 & 1 & 4\\
\hspace{1em}Pre-break & 8 & 6 & 2 & 1 & 1\\
\hspace{1em}Post-break & 6 & 6 & 2 & 1 & 1\\
\bottomrule
\end{longtable}
\begin{longtable}[t]{ccccccc}
\caption{\label{tab:joint_full}Joint Test Results}\\
\toprule
\multicolumn{1}{c}{ } & \multicolumn{2}{c}{$Z$ Test $p$ values} & \multicolumn{2}{c}{$W$ Test $p$ values} & \multicolumn{2}{c}{ } \\
\cmidrule(l{3pt}r{3pt}){2-3} \cmidrule(l{3pt}r{3pt}){4-5}
$\tilde{r}$ & Unadjusted & Adjusted & Unadjusted & Adjusted & Han and Inoue (2015) & Baltagi et al. (2021)\\
\midrule
\addlinespace[0.3em]
\multicolumn{7}{l}{\textbf{Great Moderation (1984 February) Sample}}\\
\hspace{1em}1 & 0.000 & 0.001 & 0.596 & 0.596 & 0.001 & 0.000\\
\hspace{1em}2 & 0.000 & 0.000 & 0.000 & 0.000 & 0.001 & 0.000\\
\hspace{1em}3 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000\\
\hspace{1em}4 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.001\\
\hspace{1em}5 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.003\\
\hspace{1em}6 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.011\\
\hspace{1em}7 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.044\\
\hspace{1em}8 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.131\\
\hspace{1em}9 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.214\\
\addlinespace[0.3em]
\multicolumn{7}{l}{\textbf{Global Financial Crisis (2008 November) Sample}}\\
\hspace{1em}1 & 0.175 & 0.175 & 0.005 & 0.011 & 0.688 & 0.116\\
\hspace{1em}2 & 0.009 & 0.019 & 0.486 & 0.486 & 0.354 & 0.116\\
\hspace{1em}3 & 0.010 & 0.010 & 0.002 & 0.005 & 0.009 & 0.004\\
\hspace{1em}4 & 0.021 & 0.021 & 0.000 & 0.000 & 0.000 & 0.007\\
\hspace{1em}5 & 0.000 & 0.000 & 0.001 & 0.001 & 0.000 & 0.030\\
\hspace{1em}6 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.072\\
\hspace{1em}7 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.203\\
\hspace{1em}8 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.484\\
\hspace{1em}9 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.754\\
\bottomrule
\end{longtable}
\begin{longtable}[t]{cccc}
\caption{\label{tab:w_ind_full}Individual Factor Loading Break Rejection Rates}\\
\toprule
\multicolumn{1}{c}{ } & \multicolumn{1}{c}{ } & \multicolumn{2}{c}{Breitung and Eickmeier (2011)} \\
\cmidrule(l{3pt}r{3pt}){3-4}
$\tilde{r}$ & Individual $w$ & Wald & LM\\
\midrule
\addlinespace[0.3em]
\multicolumn{4}{l}{\textbf{Great Moderation (1984 February) Sample}}\\
\hspace{1em}1 & 0.024 & 0.205 & 0.205\\
\hspace{1em}2 & 0.189 & 0.307 & 0.307\\
\hspace{1em}3 & 0.323 & 0.386 & 0.386\\
\hspace{1em}4 & 0.480 & 0.378 & 0.370\\
\hspace{1em}5 & 0.480 & 0.472 & 0.472\\
\hspace{1em}6 & 0.488 & 0.504 & 0.504\\
\hspace{1em}7 & 0.551 & 0.575 & 0.575\\
\hspace{1em}8 & 0.567 & 0.606 & 0.606\\
\hspace{1em}9 & 0.638 & 0.598 & 0.598\\
\addlinespace[0.3em]
\multicolumn{4}{l}{\textbf{Global Financial Crisis (2008 November) Sample}}\\
\hspace{1em}1 & 0.441 & 0.409 & 0.402\\
\hspace{1em}2 & 0.512 & 0.291 & 0.283\\
\hspace{1em}3 & 0.535 & 0.291 & 0.291\\
\hspace{1em}4 & 0.575 & 0.433 & 0.425\\
\hspace{1em}5 & 0.504 & 0.402 & 0.394\\
\hspace{1em}6 & 0.638 & 0.465 & 0.465\\
\hspace{1em}7 & 0.685 & 0.496 & 0.496\\
\hspace{1em}8 & 0.772 & 0.480 & 0.488\\
\hspace{1em}9 & 0.756 & 0.433 & 0.449\\
\bottomrule
\end{longtable}
\begin{longtable}[t]{cccccc}
\caption{\label{tab:rsquared_full}$R^2$ Comparisons}\\
\toprule
\multicolumn{2}{c}{ } & \multicolumn{3}{c}{Restricted $R^2$} & \multicolumn{1}{c}{ } \\
\cmidrule(l{3pt}r{3pt}){3-5}
$\tilde{r}$ & Unrestricted $R^2$ & $Z = I$ & $W = 0$ & $Z= I, W = 0$ & Whole Sample PCA\\
\midrule
\addlinespace[0.3em]
\multicolumn{6}{l}{\textbf{Great Moderation (1984 February) Sample}}\\
\hspace{1em}1 & 0.178 & 0.126 & 0.169 & 0.117 & 0.172\\
\hspace{1em}2 & 0.274 & 0.221 & 0.225 & 0.173 & 0.241\\
\hspace{1em}3 & 0.344 & 0.289 & 0.277 & 0.222 & 0.302\\
\hspace{1em}4 & 0.398 & 0.342 & 0.313 & 0.257 & 0.359\\
\hspace{1em}5 & 0.442 & 0.378 & 0.362 & 0.297 & 0.405\\
\hspace{1em}6 & 0.480 & 0.414 & 0.388 & 0.322 & 0.440\\
\hspace{1em}7 & 0.514 & 0.445 & 0.416 & 0.348 & 0.466\\
\hspace{1em}8 & 0.542 & 0.472 & 0.439 & 0.369 & 0.492\\
\hspace{1em}9 & 0.569 & 0.498 & 0.458 & 0.387 & 0.515\\
\addlinespace[0.3em]
\multicolumn{6}{l}{\textbf{Global Financial Crisis (2008 November) Sample}}\\
\hspace{1em}1 & 0.228 & 0.228 & 0.141 & 0.140 & 0.182\\
\hspace{1em}2 & 0.342 & 0.341 & 0.223 & 0.222 & 0.291\\
\hspace{1em}3 & 0.424 & 0.422 & 0.309 & 0.307 & 0.370\\
\hspace{1em}4 & 0.489 & 0.487 & 0.372 & 0.371 & 0.434\\
\hspace{1em}5 & 0.546 & 0.544 & 0.415 & 0.413 & 0.476\\
\hspace{1em}6 & 0.592 & 0.590 & 0.455 & 0.453 & 0.516\\
\hspace{1em}7 & 0.626 & 0.624 & 0.478 & 0.476 & 0.550\\
\hspace{1em}8 & 0.659 & 0.657 & 0.503 & 0.501 & 0.582\\
\hspace{1em}9 & 0.687 & 0.686 & 0.525 & 0.523 & 0.609\\
\bottomrule
\end{longtable}

\end{footnotesize}
\section{Additional Figures}
\subsection{Additional Empirical Figures}
\label{app:additional_empirical_figures}
\begin{landscape}
\begin{figure}
\label{fig:gfc_r2_plot1}
\includegraphics[]{gfc_r2_plot1.pdf}
\caption{$R^2$ between factors and individual time series, for pre Global Financial Crisis sample 2003 Jan - 2008 Nov, grouped by categories: Consumption, Order and Inventories (Cons), Interest and Exchange Rates (Int), Labor Market (Lab), Money and Credit (Mon), Housing (Hou), Output and Income (Out), Prices (Pri), and Stock Market (Spr). No. of factors on the right hand side.}
\end{figure}

\begin{figure}
\label{fig:gfc_r2_plot2}
\includegraphics[]{gfc_r2_plot2.pdf}
\caption{$R^2$ between factors and individual time series, for post Global Financial Crisis sample 2008 Nov - 2013 Jan, grouped by categories: Consumption, Order and Inventories (Cons), Interest and Exchange Rates (Int), Labor Market (Lab), Money and Credit (Mon), Housing (Hou), Output and Income (Out), Prices (Pri), and Stock Market (Spr). No. of factors on the right hand side.}
\end{figure}
\end{landscape}


\end{document}
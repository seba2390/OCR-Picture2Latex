\section{Proofs for Section \ref{contrastive_learning}}\label{proof_contrastive_learning}
In Section \ref{proof_contrastive_ti}, we show that contrastive learning with linear regression as downstream tasks is $\kappa^{-1}$-weakly-informative by proving Lemma \ref{contrastive_ti}. In Section \ref{proof_contrastive_main}, we prove Theorem \ref{contrastive_main}.


\input{proof_contrastive_ti}
%\input{proof_contrastive_hellinger}
\input{proof_contrastive_main}

% In Section \ref{hellinger_guarantee}, we show that MLE implies a theoretical guarantee on the Hellinger distance between the estimated distribution and the true distribution. 
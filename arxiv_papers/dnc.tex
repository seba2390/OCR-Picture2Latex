We now present a divide-and-conquer alternative to Section~\ref{subsec:prefix-sum-sampling} for PIT sampling from the pathwise smoothing distribution of LGSSMs. The method is based on recursively finding tractable Gaussian expressions for the ``bridging'' $q(x_l \mid y_{0:T}, x_k, x_m)$, $0 \leq k < l < m \leq T$ of the smoothing distribution. This will allow us to derive a tree-based divide-and-conquer sampling mechanism for the pathwise smoothing distribution $q(x_{0:T} \mid y_{0:T})$.

Suppose we are given the LGSSM \eqref{eq:general-LGSSM}, then given three indices $0 \leq k < l < m \leq T$. We have
\begin{equation}
    \begin{split}
        q(x_l \mid y_{0:T}, x_k, x_m)
        = \frac{q(x_k, x_l \mid y_{0:T}, x_m)}
        {q(x_k \mid y_{0:T}, x_m)}
    \end{split}
\end{equation}
with, furthermore,
\begin{equation}
    q(x_k, x_l \mid y_{0:T}, x_m) = q(x_k \mid y_{0:T}, x_l) q(x_l \mid y_{0:T}, x_m)
\end{equation}
thanks the to Markovian structure of the model.
Now let $q(x_k \mid y_{0:T}, x_l)$ and $q(x_l \mid y_{0:T}, x_m)$ be given by
\begin{equation}
    \begin{split}
        q(x_k \mid y_{0:T}, x_l) &= \mathcal{N}(x_k; E_{k:l} x_l + g_{k:l}, L_{k:l})\\
        q(x_l \mid y_{0:T}, x_m) &= \mathcal{N}(x_k; E_{l:m} x_m + g_{l:m}, L_{l:m})
    \end{split}
\end{equation}
for some parameters $E_{k:l}$, $g_{k:l}$, $L_{k:l}$, $E_{l:m}$, $g_{l:m}$, and $L_{l:m}$ that we will define below. Then we can write
\begin{equation}
    \begin{split}
        &q(x_k, x_l \mid y_{0:T}, x_m)\\
        &= \mathcal{N}\left( \begin{pmatrix}
                                 x_l \\ x_k
        \end{pmatrix} ;
        \begin{pmatrix}
            E_{l:m} x_{m} + g_{l:m} \\
            E_{k:l} E_{l:m} x_{m} + E_{k:l} g_{l:m} + g_{k:l}
        \end{pmatrix},
        \begin{pmatrix}
            L_{l:m}         & L_{l:m} E_{k:l}^\top                   \\
            E_{k:l} L_{l:m} & E_{k:l} L_{l:m} E_{k:l}^\top + L_{k:l}
        \end{pmatrix} \right)
    \end{split}
\end{equation}
giving both the marginal distribution of $x_k$
\begin{equation}
    \begin{split}
        q(x_k \mid y_{0:T}, x_m)
        &= \mathcal{N}(x_k;
        E_{k:l} E_{l:m} x_{m} + E_{k:l} g_{l:m} + g_{k:l},
        E_{k:l} L_{l:m} E_{k:l}^\top + L_{k:l} ) \\
        &= \mathcal{N}( x_k; E_{k:m} x_{m} + g_{k:m}, L_{k:m} ),
    \end{split}
\end{equation}
where
\begin{equation}
    \begin{split}
        E_{k:m} = E_{k:l} E_{l:m}, \quad g_{k:m} = E_{k:l} g_{l:m} + g_{k:l}, \quad
        L_{k:m} = E_{k:l} L_{l:m} E_{k:l}^\top + L_{k:l},
    \end{split}
    \label{eq:EgL_comb}
\end{equation}
and (after simplification for \eqref{eq:EgL_comb}) the conditional distribution of $x_l$
\begin{equation}
    \begin{split}
        q(x_l \mid y_{0:T}, x_k, x_m) = \mathcal{N}(x_l; G_{k:l:m} x_k + \Gamma_{k:l:m} x_m + w_{k:l:m}, V_{k:l:m} ),
    \end{split}
    \label{eq:gauss_l_km}
\end{equation}
for
\begin{equation}
    \label{eq:recursive_params}
    \begin{split}
        G_{k:l:m} &= L_{l:m} E_{k:l}^\top L_{k:m}^{-1}, \\
        \Gamma_{k:l:m} &= E_{l:m} - G_{k:l:m} E_{k:m},
    \end{split} \qquad
    \begin{split}
        w_{k:l:m} &= g_{l:m} - G_{k:l:m} g_{k:m}, \\
        V_{k:l:m} &= L_{l:m} - G_{k:l:m} L_{k:m} G_{k:l:m}^\top.
    \end{split}
\end{equation}

This construction provides a recursive tree structure for sampling from $q(x_{0:T} \mid y_{0:T})$ which can be initialised by
\begin{equation}
    \begin{split}
        q(x_t \mid y_{0:T}, x_{t+1})
        &= \mathcal{N}(x_t;
        E_{t:t+1} x_{t+1} + g_{t:t+1}, L_{t:t+1} ),
    \end{split}
\end{equation}
with
\begin{equation}
    \label{eq:init-dnc}
    \begin{split}
        E_{t:t+1} = P_t F_t^\top (F_t P_t F_t^\top + Q_t)^{-1}, \quad
        g_{t:t+1} = m_t - E_{t:t+1} (F_t m_t + b_t), \quad
        L_{t:t+1} = P_t - E_{t:t+1} F_t P_t,
    \end{split}
\end{equation}
and $q(x_T \mid y_{0:T}) = \mathcal{N}(x_T; m_T, P_T)$. Finally, noting that
\begin{equation}
    q(x_0 \mid y_{0:T}, x_T) = \mathcal{N}(x_0; E_{0:T} m_T + g_{0:T}, L_{0:T}),
\end{equation}
we can combine these identities to form a divide-and-conquer algorithm.

To summarise, in order to perform divide-and-conquer sampling of LGSSMs, it suffices, as in Section~\ref{subsec:prefix-sum-sampling}, to use the parallel-in-time Kalman filtering method of \citet{Sarkka2021temporal} to compute the filtering means and covariances $m_t$, $P_t$, $t=0, \ldots, T$. After this, we can recursively compute the tree of elements $E_{k:m}, g_{k:m}, L_{k:m}$, together with the auxiliary variables $G_{k:l:m}, w_{k:l:m}, \Gamma_{k:l:m}, V_{k:l:m}$, starting from $E_{t:t+1}, g_{t:t+1}, L_{t:t+1}$, for $t=0, 1, \ldots, T-1$, then $E_{t-1:t+1}, g_{t-1:t+1}, L_{t-1:t+1}$, for $t=1, 3, 5, \ldots, 2\lfloor (T - 1)/2\rfloor + 1$, etc. Once this has been done, we can then sample from $q(x_T \mid y_{0:T})$, then from $q(x_0 \mid y_{0:T}, x_T)$, then $x_{\lfloor T/2 \rfloor}$ conditionally on $x_0$ and $x_T$, then, in parallel $x_{\lfloor T/4 \rfloor}$ and $x_{\lfloor 3 T/4 \rfloor}$, conditionally on the rest, and continue until all have been sampled.
% Template for the submission to:
% The Annals of Probability           [aop]
% The Annals of Applied Probability   [aap]
% The Annals of Statistics            [aos]
% The Annals of Applied Statistics    [aoas]
% Stochastic Systems                  [ssy]
%
% Author: In this template, the places where you need to add information
% (or delete line) are indicated by {???}.  Mostly the information
% required is obvious, but some explanations are given in lines starting
% Author:
% All other lines should be ignored.  After editing, there should be
% no instances of ??? after this line.

% use option [preprint] to remove info line at bottom
% journal options: aop,aap,aos,aoas,ssy
% natbib option: authoryear

% \documentclass[onecolumn,journal]{IEEEtran}

\documentclass[a4paper,11pt]{article}
\usepackage[margin=1in]{geometry}  % set the margins to 1in on all sides

\usepackage{listings}
\usepackage{amsmath,mathtools}
\usepackage{amsthm}
\usepackage{tikz}
\usepackage{caption,subcaption}
\usepackage{array}
\usepackage{mdwmath}
\usepackage{multirow}
\usepackage{mdwtab}
\usepackage{eqparbox}
\usepackage{multicol}
\usepackage{amsfonts}
\usepackage{multirow,bigstrut,threeparttable}
\usepackage{amsthm}
\usepackage{array}
\usepackage{bbm}
\usepackage{subcaption}
\usepackage{epstopdf}
\usepackage{mdwmath}
\usepackage{mdwtab}
\usepackage{eqparbox}
\usepackage{tikz}
\usepackage{latexsym}
% \usepackage{cite}
\usepackage{amssymb}
\usepackage{bm}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{mathrsfs}
\usepackage{epsfig}
\usepackage{psfrag}
\usepackage{setspace}
% \usepackage{hyperref}
\usepackage[%dvips,
CJKbookmarks=true,
bookmarksnumbered=true,
bookmarksopen=true,
% bookmarks=false,
colorlinks=true,
citecolor=red,
linkcolor=blue,
anchorcolor=red,
urlcolor=blue
]{hyperref}
\usepackage{cleveref}
% \usepackage{algorithm}
\usepackage[ruled]{algorithm2e}
\usepackage{algpseudocode}
\usepackage{stfloats}
% \usepackage[backend=biber]{biblatex}
% \usepackage[backend=biber,style=nature]{biblatex}
\usepackage[
autocite    = superscript,
backend     = bibtex, % bibtex, biber. bibtex: warning: "Using fall-back BibTeX(8) backend:(biblatex) functionality may be reduced/unavailable."
sortcites   = true,
style       = numeric % numeric; nature
]{biblatex} % to be deleted
\addbibresource{ref.bib}
% \usepackage[numbers]{natbib}
\usepackage{nameref}
% \usepackage{ulem} % overwrite \emph
\usepackage[normalem]{ulem}
\newcommand{\zg}[1]{{\color{blue} [ZG: #1]}}
\newcommand{\zgg}[2]{\xout{#1}{\color{blue}#2}}
\def\cluster{gene-trait cluster}

%% Added by QZ
\usepackage{soul}
\newcommand{\qz}[1]{{\color{red} [QZ: #1]}}
\newcommand{\qzz}[2]{\st{#1}{\color{red}#2}}

% provide arXiv number if available:
% \arxiv{cs.IT/1502.00326}
\input xy
\xyoption{all}

% \numberwithin{equation}{section}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{assumption}{Assumption}
\newtheorem{corollary}{Corollary}[section]
\newtheorem{claim}{Claim}[section]
\newtheorem{condition}{Condition}

\crefname{theorem}{Theorem}{Theorems}
\crefname{proposition}{Proposition}{Propositions}
\crefname{corollary}{Corollary}{Corollaries}


\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{remark}{Remark}
\newtheorem{example}{Example}
\newtheorem{question}{Question}
\newtheorem{prob}{Problem}
\newtheorem*{sol}{Solution}

\crefname{definition}{Definition}{Definitions}
\crefname{remark}{Remark}{Remarks}

% \setcounter{tocdepth}{1}

%%%%% page setup %%%%%

% \setlength{\textwidth}{460pt}
% \setlength{\oddsidemargin}{0pt}
% \setlength{\evensidemargin}{0pt}
% \setlength{\topmargin}{0pt}
% \setlength{\textheight}{620pt}

%%%%%%%%% mathbb %%%%%%%%

\def\AA{\mathbb{A}}
\def\BB{\mathbb{B}}
\def\CC{\mathbb{C}}
\def\DD{\mathbb{D}}
\def\EE{\mathbb{E}}
\def\FF{\mathbb{F}}
\def\GG{\mathbb{G}}
\def\HH{\mathbb{H}}
\def\II{\mathbb{I}}
\def\JJ{\mathbb{J}}
\def\KK{\mathbb{K}}
\def\LL{\mathbb{L}}
\def\MM{\mathbb{M}}
\def\NN{\mathbb{N}}
\def\OO{\mathbb{O}}
\def\PP{\mathbb{P}}
\def\QQ{\mathbb{Q}}
\def\RR{\mathbb{R}}
\def\SS{\mathbb{S}}
\def\TT{\mathbb{T}}
\def\UU{\mathbb{U}}
\def\VV{\mathbb{V}}
\def\WW{\mathbb{W}}
\def\XX{\mathbb{X}}
\def\YY{\mathbb{Y}}
\def\ZZ{\mathbb{Z}}

%%%%%%%% mathcal %%%%%%%%

\def\calA{\mathcal{A}}
\def\calB{\mathcal{B}}
\def\calC{\mathcal{C}}
\def\calD{\mathcal{D}}
\def\calE{\mathcal{E}}
\def\calF{\mathcal{F}}
\def\calG{\mathcal{G}}
\def\calH{\mathcal{H}}
\def\calI{\mathcal{I}}
\def\calJ{\mathcal{J}}
\def\calK{\mathcal{K}}
\def\calL{\mathcal{L}}
\def\calM{\mathcal{M}}
\def\calN{\mathcal{N}}
\def\calO{\mathcal{O}}
\def\calP{\mathcal{P}}
\def\calQ{\mathcal{Q}}
\def\calR{\mathcal{R}}
\def\calS{\mathcal{S}}
\def\calT{\mathcal{T}}
\def\calU{\mathcal{U}}
\def\calV{\mathcal{V}}
\def\calW{\mathcal{W}}
\def\calX{\mathcal{X}}
\def\calY{\mathcal{Y}}
\def\calZ{\mathcal{Z}}

%%%%%%%%% bold face %%%%%%%%%%

\def\bA{\mathbf{A}}
\def\bB{\mathbf{B}}
\def\bC{\mathbf{C}}
\def\bD{\mathbf{D}}
\def\bE{\mathbf{E}}
\def\bF{\mathbf{F}}
\def\bG{\mathbf{G}}
\def\bH{\mathbf{H}}
\def\bI{\mathbf{I}}
\def\bJ{\mathbf{J}}
\def\bK{\mathbf{K}}
\def\bL{\mathbf{L}}
\def\bM{\mathbf{M}}
\def\bN{\mathbf{N}}
\def\bO{\mathbf{O}}
\def\bP{\mathbf{P}}
\def\bQ{\mathbf{Q}}
\def\bR{\mathbf{R}}
\def\bS{\mathbf{S}}
\def\bT{\mathbf{T}}
\def\bU{\mathbf{U}}
\def\bV{\mathbf{V}}
\def\bW{\mathbf{W}}
\def\bX{\mathbf{X}}
\def\bY{\mathbf{Y}}
\def\bZ{\mathbf{Z}}

%%%%%%%% frak %%%%%%%%

\newcommand\frA{\mathfrak{A}}
\newcommand\frB{\mathfrak{B}}
\newcommand\frg{\mathfrak{g}}
\newcommand\frt{\mathfrak{t}}
\newcommand\frb{\mathfrak{b}}
\newcommand\frh{\mathfrak{h}}
\newcommand\frn{\mathfrak{n}}
\newcommand\frl{\mathfrak{l}}
\newcommand\frp{\mathfrak{p}}
\def\frm{\mathfrak{m}}



%%%%%%%% tilde %%%%%%%%%


\newcommand\tilW{\widetilde{W}}
\newcommand\tilA{\widetilde{A}}
\newcommand\tilB{\widetilde{B}}
\newcommand\tilC{\widetilde{C}}
\newcommand\tilD{\widetilde{D}}
\newcommand\tilE{\widetilde{E}}
\newcommand\tilF{\widetilde{F}}
\newcommand\tilG{\widetilde{G}}



\newcommand\alg{\textup{alg}}
\newcommand\Alg{\textup{Alg}}
\newcommand\Aut{\textup{Aut}}
\newcommand{\codim}{\textup{codim}}
\newcommand{\coker}{\textup{coker}}
\newcommand\ev{\textup{ev}}
\newcommand\Fr{\textup{Fr}}
\newcommand\Frob{\textup{Frob}}
\newcommand\Gal{\textup{Gal}}
\newcommand{\Gr}{\textup{Gr}}
\newcommand{\gr}{\textup{gr}}
\newcommand\Hom{\textup{Hom}}
\newcommand\id{\textup{id}}
\renewcommand{\Im}{\textup{Im}}
\newcommand{\Ind}{\textup{Ind}}
\newcommand{\ind}{\textup{ind}}
\newcommand\Isom{\textup{Isom}}
\newcommand\Lie{\textup{Lie}}
\newcommand\Mat{\textup{Mat}}
\newcommand\Mod{\textup{Mod}}
\newcommand{\Nm}{\textup{Nm}}
\newcommand\pr{\textup{pr}}
\newcommand\rank{\textup{rank}}
\newcommand{\red}{\textup{red}}
\newcommand\Rep{\textup{Rep}}
\newcommand{\Res}{\textup{Res}}
\newcommand\res{\textup{res}}
\newcommand\rk{\textup{rk}}
\newcommand\Span{\textup{Span}}
\newcommand\Spec{\textup{Spec}\ }
\newcommand\St{\textup{St}}
% \newcommand\st{\textup{st}} % deleted by QZ
\newcommand\Stab{\textup{Stab}}
\newcommand\Sym{\textup{Sym}}
\newcommand{\Tr}{\textup{Tr}}
\newcommand{\tr}{\textup{tr}}



\newcommand\bij{\leftrightarrow}
\newcommand{\incl}{\hookrightarrow}
\newcommand{\isom}{\stackrel{\sim}{\to}}
\newcommand{\leftexp}[2]{{\vphantom{#2}}^{#1}{#2}}
\newcommand{\trpose[1]}{\leftexp{t}{#1}}
\newcommand{\jiao}[1]{\langle{#1}\rangle}
\newcommand{\wt}[1]{\widetilde{#1}}
\newcommand{\un}[1]{\underline{#1}}
\newcommand\chk{\textup{char}(k)}
\newcommand\kbar{\overline{k}}
\newcommand\ep{\epsilon}
\renewcommand\l{\lambda}
\newcommand\height{\textup{ht}}
\newcommand\leng{\textup{leng}}
\newcommand\diag{\textup{diag}}

\def\frp{\mathfrak{p}}
\def\pto{\to_p}%{\overset{p}{\longrightarrow}}
\def\dto{\to_d}
\def\1{\mathbbm{1}}
\def\var{\mathsf{Var}}
\def\cov{\mathsf{Cov}}
\def\cor{\mathsf{Cor}}
% \def\st{\mathsf{st}} %deleted by QZ
\def\nd{\mathsf{nd}}
\def\rd{\mathsf{rd}}
\def\th{\mathsf{th}}
\newcommand\independent{\protect\mathpalette{\protect\independenT}{\perp}}
\def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}
% \def\argmax{\mathsf{argmax}}
% \def\argmin{\mathsf{argmin}}
\newcommand{\argmax}{\mathop{\mathrm{argmax}}}
\newcommand{\argmin}{\mathop{\mathrm{argmin}}}

% tables
\usepackage{booktabs}
\setlength{\heavyrulewidth}{1.5pt}
\setlength{\abovetopsep}{4pt}
\usepackage{adjustbox}
\usepackage{multirow}
\usepackage{listings}



% opening

% put your definitions there:

% \newtheorem{remark}{Remark} \def\remref#1{Remark~\ref{#1}}
% \newtheorem{conjecture}{Conjecture} \def\remref#1{Remark~\ref{#1}}
% \newtheorem{example}{Example}

% \theorembodyfont{\itshape}
% \newtheorem{theorem}{Theorem}
% \newtheorem{proposition}{Proposition}
% \newtheorem{lemma}{Lemma} \def\lemref#1{Lemma~\ref{#1}}
% \newtheorem{corollary}{Corollary}


% \theorembodyfont{\rmfamily}
% \newtheorem{definition}{Definition}
% \numberwithin{equation}{section}
\theoremstyle{plain}
\newtheorem{conjecture}{Conjecture}
\newtheorem*{induction}{Induction Hypothesis}

\def \by {\bar{y}}
\def \bx {\bar{x}}
\def \bh {\bar{h}}
\def \bz {\bar{z}}
\def \cF {\mathcal{F}}
\def \bP {\mathbb{P}}
% \def \bE {\mathbb{E}}
\def \bR {\mathbb{R}}
\def \bF {\mathbb{F}}
\def \cG {\mathcal{G}}
\def \cM {\mathcal{M}}
\def \cB {\mathcal{B}}
\def \cN {\mathcal{N}}
\def \var {\mathsf{Var}}


















%%%%%%%%%%%%%%%%%%%%%%%%%%%% by Wu %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{xspace}

\newcommand{\Lip}{\mathrm{Lip}}
\newcommand{\stepa}[1]{\overset{\rm (a)}{#1}}
\newcommand{\stepb}[1]{\overset{\rm (b)}{#1}}
\newcommand{\stepc}[1]{\overset{\rm (c)}{#1}}
\newcommand{\stepd}[1]{\overset{\rm (d)}{#1}}
\newcommand{\stepe}[1]{\overset{\rm (e)}{#1}}


\newcommand{\floor}[1]{{\left\lfloor {#1} \right \rfloor}}
\newcommand{\ceil}[1]{{\left\lceil {#1} \right \rceil}}

\newcommand{\blambda}{\bar{\lambda}}
\newcommand{\reals}{\mathbb{R}}
\newcommand{\naturals}{\mathbb{N}}
\newcommand{\integers}{\mathbb{Z}}
\newcommand{\Expect}{\mathbb{E}}
\newcommand{\expect}[1]{\mathbb{E}\left[#1\right]}
\newcommand{\Prob}{\mathbb{P}}
\newcommand{\pprob}[1]{\mathbb{P}[#1]}
\newcommand{\intd}{{\rm d}}
\newcommand{\TV}{{\sf TV}}
\newcommand{\LC}{{\sf LC}}
\newcommand{\PW}{{\sf PW}}
\newcommand{\htheta}{\hat{\theta}}
\newcommand{\eexp}{{\rm e}}
\newcommand{\expects}[2]{\mathbb{E}_{#2}\left[ #1 \right]}
\newcommand{\diff}{{\rm d}}
\newcommand{\eg}{e.g.\xspace}
\newcommand{\ie}{i.e.\xspace}
\newcommand{\iid}{i.i.d.\xspace}
\newcommand{\fracp}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\fracpk}[3]{\frac{\partial^{#3} #1}{\partial #2^{#3}}}
\newcommand{\fracd}[2]{\frac{\diff #1}{\diff #2}}
\newcommand{\fracdk}[3]{\frac{\diff^{#3} #1}{\diff #2^{#3}}}
\newcommand{\renyi}{R\'enyi\xspace}
\newcommand{\lpnorm}[1]{\left\|{#1} \right\|_{p}}
\newcommand{\linf}[1]{\left\|{#1} \right\|_{\infty}}
\newcommand{\lnorm}[2]{\left\|{#1} \right\|_{{#2}}}
\newcommand{\Lploc}[1]{L^{#1}_{\rm loc}}
\newcommand{\hellinger}{d_{\rm H}}
\newcommand{\Fnorm}[1]{\lnorm{#1}{\rm F}}
%% parenthesis
\newcommand{\pth}[1]{\left( #1 \right)}
\newcommand{\qth}[1]{\left[ #1 \right]}
\newcommand{\sth}[1]{\left\{ #1 \right\}}
\newcommand{\bpth}[1]{\Bigg( #1 \Bigg)}
\newcommand{\bqth}[1]{\Bigg[ #1 \Bigg]}
\newcommand{\bsth}[1]{\Bigg\{ #1 \Bigg\}}
\newcommand{\xxx}{\textbf{xxx}\xspace}
\newcommand{\toprob}{{\xrightarrow{\Prob}}}
\newcommand{\tolp}[1]{{\xrightarrow{L^{#1}}}}
\newcommand{\toas}{{\xrightarrow{{\rm a.s.}}}}
\newcommand{\toae}{{\xrightarrow{{\rm a.e.}}}}
\newcommand{\todistr}{{\xrightarrow{{\rm D}}}}
\newcommand{\eqdistr}{{\stackrel{\rm D}{=}}}
\newcommand{\iiddistr}{{\stackrel{\text{\iid}}{\sim}}}
% \newcommand{\var}{\mathsf{var}}
\newcommand\indep{\protect\mathpalette{\protect\independenT}{\perp}}
\def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}
\newcommand{\Bern}{\text{Bern}}
\newcommand{\Poi}{\mathsf{Poi}}
\newcommand{\iprod}[2]{\left \langle #1, #2 \right\rangle}
\newcommand{\Iprod}[2]{\langle #1, #2 \rangle}
\newcommand{\indc}[1]{{\mathbf{1}_{\left\{{#1}\right\}}}}
\newcommand{\Indc}{\mathbf{1}}

\definecolor{myblue}{rgb}{.8, .8, 1}
\definecolor{mathblue}{rgb}{0.2472, 0.24, 0.6} % mathematica's Color[1, 1--3]
\definecolor{mathred}{rgb}{0.6, 0.24, 0.442893}
\definecolor{mathyellow}{rgb}{0.6, 0.547014, 0.24}


\newcommand{\blue}{\color{blue}}
\newcommand{\nb}[1]{{\sf\blue[#1]}}
\newcommand{\nbr}[1]{{\sf\red[#1]}}

\newcommand{\tmu}{{\tilde{\mu}}}
\newcommand{\tf}{{\tilde{f}}}
\newcommand{\tp}{\tilde{p}}
\newcommand{\tilh}{{\tilde{h}}}
\newcommand{\tu}{{\tilde{u}}}
\newcommand{\tx}{{\tilde{x}}}
\newcommand{\ty}{{\tilde{y}}}
\newcommand{\tz}{{\tilde{z}}}
\newcommand{\tA}{{\tilde{A}}}
\newcommand{\tB}{{\tilde{B}}}
\newcommand{\tC}{{\tilde{C}}}
\newcommand{\tD}{{\tilde{D}}}
\newcommand{\tE}{{\tilde{E}}}
\newcommand{\tF}{{\tilde{F}}}
\newcommand{\tG}{{\tilde{G}}}
\newcommand{\tH}{{\tilde{H}}}
\newcommand{\tI}{{\tilde{I}}}
\newcommand{\tJ}{{\tilde{J}}}
\newcommand{\tK}{{\tilde{K}}}
\newcommand{\tL}{{\tilde{L}}}
\newcommand{\tM}{{\tilde{M}}}
\newcommand{\tN}{{\tilde{N}}}
\newcommand{\tO}{{\tilde{O}}}
\newcommand{\tP}{{\tilde{P}}}
\newcommand{\tQ}{{\tilde{Q}}}
\newcommand{\tR}{{\tilde{R}}}
\newcommand{\tS}{{\tilde{S}}}
\newcommand{\tT}{{\tilde{T}}}
\newcommand{\tU}{{\tilde{U}}}
\newcommand{\tV}{{\tilde{V}}}
\newcommand{\tW}{{\tilde{W}}}
\newcommand{\tX}{{\tilde{X}}}
\newcommand{\tY}{{\tilde{Y}}}
\newcommand{\tZ}{{\tilde{Z}}}

\newcommand{\sfa}{{\mathsf{a}}}
\newcommand{\sfb}{{\mathsf{b}}}
\newcommand{\sfc}{{\mathsf{c}}}
\newcommand{\sfd}{{\mathsf{d}}}
\newcommand{\sfe}{{\mathsf{e}}}
\newcommand{\sff}{{\mathsf{f}}}
\newcommand{\sfg}{{\mathsf{g}}}
\newcommand{\sfh}{{\mathsf{h}}}
\newcommand{\sfi}{{\mathsf{i}}}
\newcommand{\sfj}{{\mathsf{j}}}
\newcommand{\sfk}{{\mathsf{k}}}
\newcommand{\sfl}{{\mathsf{l}}}
\newcommand{\sfm}{{\mathsf{m}}}
\newcommand{\sfn}{{\mathsf{n}}}
\newcommand{\sfo}{{\mathsf{o}}}
\newcommand{\sfp}{{\mathsf{p}}}
\newcommand{\sfq}{{\mathsf{q}}}
\newcommand{\sfr}{{\mathsf{r}}}
\newcommand{\sfs}{{\mathsf{s}}}
\newcommand{\sft}{{\mathsf{t}}}
\newcommand{\sfu}{{\mathsf{u}}}
\newcommand{\sfv}{{\mathsf{v}}}
\newcommand{\sfw}{{\mathsf{w}}}
\newcommand{\sfx}{{\mathsf{x}}}
\newcommand{\sfy}{{\mathsf{y}}}
\newcommand{\sfz}{{\mathsf{z}}}
\newcommand{\sfA}{{\mathsf{A}}}
\newcommand{\sfB}{{\mathsf{B}}}
\newcommand{\sfC}{{\mathsf{C}}}
\newcommand{\sfD}{{\mathsf{D}}}
\newcommand{\sfE}{{\mathsf{E}}}
\newcommand{\sfF}{{\mathsf{F}}}
\newcommand{\sfG}{{\mathsf{G}}}
\newcommand{\sfH}{{\mathsf{H}}}
\newcommand{\sfI}{{\mathsf{I}}}
\newcommand{\sfJ}{{\mathsf{J}}}
\newcommand{\sfK}{{\mathsf{K}}}
\newcommand{\sfL}{{\mathsf{L}}}
\newcommand{\sfM}{{\mathsf{M}}}
\newcommand{\sfN}{{\mathsf{N}}}
\newcommand{\sfO}{{\mathsf{O}}}
\newcommand{\sfP}{{\mathsf{P}}}
\newcommand{\sfQ}{{\mathsf{Q}}}
\newcommand{\sfR}{{\mathsf{R}}}
\newcommand{\sfS}{{\mathsf{S}}}
\newcommand{\sfT}{{\mathsf{T}}}
\newcommand{\sfU}{{\mathsf{U}}}
\newcommand{\sfV}{{\mathsf{V}}}
\newcommand{\sfW}{{\mathsf{W}}}
\newcommand{\sfX}{{\mathsf{X}}}
\newcommand{\sfY}{{\mathsf{Y}}}
\newcommand{\sfZ}{{\mathsf{Z}}}


\newcommand{\bara}{{\bar{a}}}
\newcommand{\barb}{{\bar{b}}}
\newcommand{\barc}{{\bar{c}}}
\newcommand{\bard}{{\bar{d}}}
\newcommand{\bare}{{\bar{e}}}
\newcommand{\barf}{{\bar{f}}}
\newcommand{\barg}{{\bar{g}}}
\newcommand{\barh}{{\bar{h}}}
\newcommand{\bari}{{\bar{i}}}
\newcommand{\barj}{{\bar{j}}}
\newcommand{\bark}{{\bar{k}}}
\newcommand{\barl}{{\bar{l}}}
\newcommand{\barm}{{\bar{m}}}
\newcommand{\barn}{{\bar{n}}}
\newcommand{\baro}{{\bar{o}}}
\newcommand{\barp}{{\bar{p}}}
\newcommand{\barq}{{\bar{q}}}
\newcommand{\barr}{{\bar{r}}}
\newcommand{\bars}{{\bar{s}}}
\newcommand{\bart}{{\bar{t}}}
\newcommand{\baru}{{\bar{u}}}
\newcommand{\barv}{{\bar{v}}}
\newcommand{\barw}{{\bar{w}}}
\newcommand{\barx}{{\bar{x}}}
\newcommand{\bary}{{\bar{y}}}
\newcommand{\barz}{{\bar{z}}}
\newcommand{\barA}{{\bar{A}}}
\newcommand{\barB}{{\bar{B}}}
\newcommand{\barC}{{\bar{C}}}
\newcommand{\barD}{{\bar{D}}}
\newcommand{\barE}{{\bar{E}}}
\newcommand{\barF}{{\bar{F}}}
\newcommand{\barG}{{\bar{G}}}
\newcommand{\barH}{{\bar{H}}}
\newcommand{\barI}{{\bar{I}}}
\newcommand{\barJ}{{\bar{J}}}
\newcommand{\barK}{{\bar{K}}}
\newcommand{\barL}{{\bar{L}}}
\newcommand{\barM}{{\bar{M}}}
\newcommand{\barN}{{\bar{N}}}
\newcommand{\barO}{{\bar{O}}}
\newcommand{\barP}{{\bar{P}}}
\newcommand{\barQ}{{\bar{Q}}}
\newcommand{\barR}{{\bar{R}}}
\newcommand{\barS}{{\bar{S}}}
\newcommand{\barT}{{\bar{T}}}
\newcommand{\barU}{{\bar{U}}}
\newcommand{\barV}{{\bar{V}}}
\newcommand{\barW}{{\bar{W}}}
\newcommand{\barX}{{\bar{X}}}
\newcommand{\barY}{{\bar{Y}}}
\newcommand{\barZ}{{\bar{Z}}}

\newcommand{\hX}{\hat{X}}
\newcommand{\Ent}{\mathsf{Ent}}

\newcommand{\trans}{^{\rm T}}
\newcommand{\Th}{{^{\rm th}}}
\newcommand{\diverge}{\to \infty}
\newcommand{\testConst}{\pi}

%% nc BH
\usepackage{enumitem}

\newcommand{\No}{{n}}
\newcommand{\NoNull}{{n_0}}
\newcommand{\NoNonNull}{{n_1}}
% \newcommand{\NoNc}{{n_{\text{nc}}}}
\newcommand{\NoNc}{m}
\newcommand{\probNull}{{\pi}}
% \newcommand{\ncProbNull}{{\pi^{\text{nc}}}}

\newcommand{\pval}[1]{{p_{#1}}}
\newcommand{\pvalOrder}[1]{{p_{(#1)}}}
\newcommand{\pvalAll}{{\boldsymbol{p}}}
\newcommand{\qval}[1]{{p_{#1}}}
\newcommand{\qvalOrder}[1]{{p_{(#1)}}}
\newcommand{\qvalAll}{{\boldsymbol{p}}}
\newcommand{\testStatistics}[1]{{T_{#1}}}
\newcommand{\testStatisticsOrder}[1]{{T_{(#1)}}}
\newcommand{\testStatisticsAll}{{\boldsymbol{T}}}
\newcommand{\testStatisticsAllTwo}{{\boldsymbol{T}^{\calH}}}
\newcommand{\cdfTestStatistics}[1]{{F_{#1}}}
\newcommand{\cdfTestStatisticsNull}{{F_{0}}}
\newcommand{\cdfTestStatisticsNonNull}{{F_{1}}}
\newcommand{\cdfTestStatisticsOrder}[1]{{F_{(#1)}}}
\newcommand{\pdfTestStatistics}[1]{{f_{#1}}}
\newcommand{\pdfTestStatisticsNull}{{f_{0}}}
\newcommand{\pdfTestStatisticsNonNull}{{f_{1}}}
\newcommand{\pdfTestStatisticsOrder}[1]{{f_{(#1)}}}

% \newcommand{\ncPval}[1]{{p^{\text{nc}}_{#1}}}
% \newcommand{\ncPvalOrder}[1]{{p^{\text{nc}}_{(#1)}}}
% \newcommand{\ncQval}[1]{{p^{\text{nc}}_{#1}}}
% \newcommand{\ncQvalOrder}[1]{{p^{\text{nc}}_{(#1)}}}
% \newcommand{\ncQvalAll}{{\boldsymbol{p}^{\text{nc}}}}
% \newcommand{\ncTestStatistics}[1]{{T^{\text{nc}}_{#1}}}
% \newcommand{\ncTestStatisticsOrder}[1]{{T^{\text{nc}}_{(#1)}}}
% \newcommand{\ncTestStatisticsAll}{{\boldsymbol{T}^{\text{nc}}}}
% \newcommand{\ncCdfTestStatistics}[1]{{F^{\text{nc}}_{#1}}}
% \newcommand{\ncCdfTestStatisticsOrder}[1]{{F^{\text{nc}}_{(#1)}}}
% \newcommand{\ncPdfTestStatistics}[1]{{f^{\text{nc}}_{#1}}}
% \newcommand{\ncPdfTestStatisticsOrder}[1]{{f^{\text{nc}}_{(#1)}}}

% \newcommand{\ncPval}[1]{{p^{\text{nc}}_{#1}}}
% \newcommand{\ncPvalOrder}[1]{{p^{\text{nc}}_{(#1)}}}
% \newcommand{\ncQval}[1]{{p^{\text{nc}}_{#1}}}
% \newcommand{\ncQvalOrder}[1]{{p^{\text{nc}}_{(#1)}}}
% \newcommand{\ncQvalAll}{{\boldsymbol{p}^{\text{nc}}}}
\newcommand{\ncTestStatistics}[1]{{C_{#1}}}
\newcommand{\ncTestStatisticsOrder}[1]{{C_{(#1)}}}
% \newcommand{\ncTestStatisticsAll}{{\boldsymbol{N}}}
\newcommand{\ncTestStatisticsAll}{{\boldsymbol{C}}} % ZJ
\newcommand{\ncCdfTestStatistics}[1]{{F^{\text{nc}}_{#1}}}
\newcommand{\ncCdfTestStatisticsOrder}[1]{{F^{\text{nc}}_{(#1)}}}
\newcommand{\ncPdfTestStatistics}[1]{{f^{\text{nc}}_{#1}}}
\newcommand{\ncPdfTestStatisticsOrder}[1]{{f^{\text{nc}}_{(#1)}}}

\newcommand{\nickname}{{\text{RANC}}}


\newcommand{\hypothesis}[1]{{H_{#1}}}
\newcommand{\hypothesisOrder}[1]{{H_{(#1)}}}
\newcommand{\hypothesisSet}{{\calH}}
\newcommand{\hypothesisIndex}[1]{{\calI_{#1}}}
\newcommand{\nullHypothesis}[1]{{H_{0,#1}}}
\newcommand{\nullHypothesisOrder}[1]{{H_{0,(#1)}}}
\newcommand{\nullHypothesisSet}{{\calH_{0}}}
\newcommand{\nullHypothesisIndex}{{\calI_{0}}}
\newcommand{\alternativeHypothesis}[1]{{H_{1,#1}}}
\newcommand{\alternativeHypothesisOrder}[1]{{H_{1,(#1)}}}
\newcommand{\nonNullHypothesisSet}{{\calH_{1}}}
\newcommand{\nonNullHypothesisIndex}{{\calI_{1}}}
\newcommand{\ncHypothesis}[1]{{H^{\text{nc}}_{#1}}}
\newcommand{\ncHypothesisOrder}[1]{{H^{\text{nc}}_{(#1)}}}
\newcommand{\ncHypothesisSet}{{\calH_{\text{nc}}}}
\newcommand{\ncNullHypothesis}[1]{{H^{\text{nc}}_{0,#1}}}
\newcommand{\ncNullHypothesisOrder}[1]{{H^{\text{nc}}_{0,(#1)}}}
\newcommand{\ncAlternativeHypothesis}[1]{{H^{\text{nc}}_{1,#1}}}
\newcommand{\ncAlternativeHypothesisOrder}[1]{{H^{\text{nc}}_{1,(#1)}}}

\newcommand{\responseTreatment}[1]{{Y_{#1}^{\text{t}}}}
\newcommand{\responseControl}[1]{{Y_{#1}^{\text{c}}}}

\newcommand{\truePositive}{{S}}
\newcommand{\falsePositive}{{V}}
\newcommand{\ncFalsePositive}{{V_{\text{nc}}}}
\newcommand{\trueNegative}{{U}}
\newcommand{\ncTrueNegative}{{U_{\text{nc}}}}
\newcommand{\falseNegative}{{T}}
\newcommand{\totalPositive}{{R}}

\newcommand{\globalNull}{{H}}
\newcommand{\FWER}{\text{FWER}}
\newcommand{\kFWER}{{k\text{-FWER}}}
\newcommand{\FDR}{\text{FDR}}
\newcommand{\FDRLevel}{q}
\newcommand{\FDP}{\text{FDP}}
\newcommand{\localFDR}{\text{local-FDR}}
\newcommand{\LocalFDR}{\text{Local-FDR}}

\newcommand{\PRDS}{{\text{PRDS}}}
\newcommand{\MTPTwo}{{$\text{MTP}_2$}}
\newcommand{\BH}{{\text{BH}}}

\newcommand{\logTMT}{{$\log$ TMT}}

\newcommand{\cutoff}{c}
\newcommand{\bc}{\boldsymbol{c}}
\newcommand{\LRT}{\text{LRT}}
\newcommand{\bmu}{\boldsymbol{\mu}}
\newcommand{\bSigma}{\boldsymbol{\Sigma}}
\newcommand{\bOmega}{\boldsymbol{\Omega}}
\newcommand{\bt}{\boldsymbol{t}}

\newcommand{\permutationFunction}[1]{{G(#1)}}
\newcommand{\fullRank}[1]{{R#1}}
\newcommand{\partialRank}[1]{{r#1}}
\newcommand{\symmetricGroup}[1]{{\text{Sym}(#1)}}

\newcommand{\stoppingTime}{{\tau_q}}
\newcommand{\stoppingTimeLambda}{{\tau_q}}
\newcommand{\stoppingTimeSecond}{{\tau_{q,2}}}
\newcommand{\stoppingTimeSecondLambda}{{\tau_{q,2}^\lambda}}

%%% new local FDR and Bayes risk
\newcommand{\estimatedLocalFDR}[1]{{\hat{q}(#1)}}
\newcommand{\threshold}{{t}}
\newcommand{\trueThreshold}{{\tau^*_\lambda}}
\newcommand{\trueThresholdMinimizer}[1]{{\tau^*_{\lambda, \min, #1}}}
\newcommand{\trueThresholdMaximizer}[1]{{\tau^*_{\lambda, \max, #1}}}
\newcommand{\estimatedThreshold}{{\hat{\tau}_{\lambda, \No}}}
\newcommand{\estimatedThresholdMinimizer}[1]{{\hat{\tau}_{\lambda, \No, \min, #1}}}
\newcommand{\estimatedThresholdMaximizer}[1]{{\hat{\tau}_{\lambda, \No, \max, #1}}}
\newcommand{\EmpiricalThreshold}{{\hat{\tau}_{\lambda, \No, \NoNc}}}
\newcommand{\EmpiricalThresholdMinimizer}[1]{{\hat{\tau}_{\lambda, \No, \NoNc, \min, #1}}}
\newcommand{\EmpiricalThresholdMaximizer}[1]{{\hat{\tau}_{\lambda, \No, \NoNc, \max, #1}}}
\newcommand{\EmpiricalThresholdSecond}{{\hat{\tau}_{\lambda, \No}}}
\newcommand{\EmpiricalThresholdSecondMinimizer}[1]{{\hat{\tau}_{\lambda, \No, \min, #1}}}
\newcommand{\EmpiricalThresholdSecondMaximizer}[1]{{\hat{\tau}_{\lambda, \No, \max, #1}}}
\newcommand{\BayesRisk}{{R}}
\newcommand{\BayesRiskLambda}{{R_{\lambda}}}
\newcommand{\EmpiricalBayesRisk}{{{\ell}_{\No, \NoNc}}}
\newcommand{\EmpiricalBayesRiskLambda}{{{\ell}_{\lambda, \No, \NoNc}}}
\newcommand{\EmpiricalBayesRiskLambdaSecond}{{{\ell}_{\lambda, \No}}}
\newcommand{\EmpiricalCdfTestStatistics}{{{F}_n}}
\newcommand{\EmpiricalCdfTestStatisticsNull}{{{F}_{0,\NoNc}}}
\newcommand{\EmpiricalCdfTestStatisticsNullSecond}{{{F}_{0,\No}}}
\newcommand{\EmpiricalPdfTestStatistics}{{{f}_n}}
\newcommand{\EmpiricalPdfTestStatisticsNull}{{{f}_{0,\NoNc}}}
\newcommand{\EmpiricalPdfTestStatisticsNullSecond}{{{f}_{0,\No}}}
\newcommand{\pdfBased}{{\text{PDF-based}}}
\newcommand{\PdfBased}{{\text{PDF-based}}}
\newcommand{\cdfBased}{{\text{CDF-based}}}
\newcommand{\CdfBased}{{\text{CDF-based}}}
\newcommand{\estimatedHypothesis}[1]{{\hat{H}_{#1}}}
\newcommand{\optimalEstimatedHypothesis}[1]{{\hat{H}_{#1}^{\text{opt}}}}
\newcommand{\weightNull}{{w_0}}
\newcommand{\weightNonNull}{{w_1}}
\newcommand{\level}{{q}}
\newcommand{\EmpiricalProbNull}{{\hat{\pi}}}
\newcommand{\monotoneTransformation}[1]{{h(#1)}}
\newcommand{\weight}[1]{{w_{#1}}}
\newcommand{\window}[1]{{h_{#1}}}
\newcommand{\lowerBound}[1]{{L_{#1}}}
\newcommand{\upperBound}[1]{{U_{#1}}}
\newcommand{\interval}[1]{{I_{#1}}}

\title{Simultaneous Hypothesis Testing Using Internal Negative
  Controls with An Application to Proteomics}
\author{Zijun Gao\thanks{Statistical Laboratory, Department of Pure Mathematics and Mathematical Statistics, University of Cambridge, UK. Email: \{zg305\}@cam.ac.uk.} ~ and
  ~Qingyuan Zhao\thanks{Statistical Laboratory, Department of Pure Mathematics and Mathematical Statistics, University of Cambridge, UK. Email: \{qyzhao\}@statslab.cam.ac.uk.}
}

\begin{document}

\maketitle

\begin{abstract}
  % Consider a simultaneous hypothesis testing problem where each
  % hypothesis is associated with a test statistic. Suppose it is
  % difficult to obtain the null distribution of the test statistics,
  % but some null hypotheses---referred to as the internal negative
  % controls---are known to be true. When it is reasonable to assume that the
  % test statistics associated with the negative controls are
  % exchangeable with those associated with the unknown true null
  % hypotheses, we propose to use a statistic's Rank Among Negative
  % Controls (RANC) as a p-value for the corresponding hypothesis. We
  % provide two theoretical prospectives on this proposal. First, we view
  % the empirical distribution of the negative control statistics as an
  % estimate of the null distribution. We use this to show that, when the
  % test statistics are
  % exchangeable, the RANC p-values are
  % individually valid and have a positive regression dependence on the
  % subset of true nulls.
  % Second, we study the empirical processes of the test statistics
  % indexed by the rejection threshold. We use this to show that the
  % Benjamini-Hochberg procedure applied to the RANC p-values may still
  % control the false discovery rate when the test statistics are not
  % exchangeable. The practical performance of our
  % method is illustrated using numerical simulations and a real proteomic
  % dataset.

  Negative control is a common technique in scientific investigations
  and broadly refers to the situation where a null effect (``negative
  result'') is expected. Motivated by a real proteomic dataset, we will
  present three promising and
  closely connected methods of using negative controls to assist
  simultaneous hypothesis testing. The first method uses negative
  controls to construct a permutation p-value for every hypothesis under
  investigation, and we give several sufficient conditions for such
  p-values to be valid and positive regression dependent on the set
  (PRDS) of true nulls. The second method uses negative controls to
  construct an estimate of the false discovery rate (FDR), and we give a
  sufficient condition under which the step-up procedure based on this
  estimate controls the FDR. The third method, derived from an existing
  ad hoc algorithm for proteomic analysis, uses negative controls to
  construct a nonparametric estimator of the local false discovery
  rate. We conclude with some practical suggestions and connections to
  some closely related methods that are propsed recently.
\end{abstract}

\noindent\textbf{Keywords: multiple testing, negative control,
  empirical null, exchangeability, empirical process, proteomics}

\clearpage

% \doublespacing

\section{Introduction}\label{sec:introduction}


With the rapid development of high-throughput sequencing technologies,
a common task in modern statistical applications is to test a large
number of hypotheses simultaneously. A wealth of multiple testing
procedures have been proposed in the literature; most of them operate
by combining p-values for the individual hypotheses. Prominent
examples include Bonferroni's correction and Simes' test
\parencite{simes1986improved} for family-wise error rate (FWER) control,
the Benjamini-Hochberg (\BH) procedure for false discovery rate (FDR)
control \parencite{benjamini1995controlling}, the closed testing
principle \parencite{marcus1976closed}, and empirical Bayes methods
for controlling the local false discovery rate \localFDR\
\parencite{efron2001empirical}.

In many practical situations, however, the validity of these p-values
may be jeopardized by various problems. For example, many high-throughput
platforms for biological experiments are subject to batch effects
\parencite{leek10_tackl_wides_critic_impac_batch}. Other reasons for
invalid p-values include model misspecification and small sample
sizes. As a consequence, multiple testing procedures that combine
these p-values may fail to control the relevant statistical errors.


% In this paper, we propose a new approach of simultaneous hypothesis
% testing using internal negative control observations. In a
% nutshell, we propose to use, for the test statistic of each
% hypothesis, its Rank Among the Negative Control (\nickname) as a
% p-value. We will show that such p-values are individually valid and
% can be readily used in a large number of multiple testing procedures
% (including those mentioned above), if the collection of null and
% internal negative control statistics are exchangeable. As the
% \nickname~p-values are model-free, non-asymptotic, and robust to batch
% effects, they provide an appealing alternative to conventional
% model-based p-values.
In this paper, we employ internal negative controls, of which the null
hypotheses are known to be true, to perform valid simultaneous
hypothesis testing. Motivated by a real proteomic analysis, we present
three closely related methods to use the negative controls. The first
method uses, for the test statistic of each
hypothesis under investigation, its Rank Among the Negative Control
(\nickname) as a permutation p-value; alternatively, this can be
understood as using negative controls to form a (nonparametric)
empirical null distribution. The second method uses the negative
controls to give an estimate of the false discovery rate of a set of
rejected hypotheses. The third method, derived from an existing
ad hoc algorithm for proteomic analysis, uses negative controls to
construct a nonparametric estimator of \localFDR.

% As the
% \nickname~p-values are model-free, non-asymptotic, and robust to batch
% effects, they provide an appealing alternative to conventional
% model-based p-values.
% In the rest of the introduction, we will give a precise
% definition of the \nickname~p-values, illustrate them using a motivating
% proteomic dataset, and review the related literature in biology and
% statistics on using empirical null distribution and internal negative
% controls.

% In the rest of the introduction, we will introduce our motivating
% proteomic dataset, give a precise
% definition of the \nickname~p-values, and review the related literature in biology and
% statistics on using empirical null distribution and internal negative
% controls.

\subsection{Motivating example}\label{sec:motivating.data}

Our considerations are motivated by a real proteomic analysis shared
by our collaborating neuroscientists. \textcite{shuster2022situ}
used proteomic profiling to identify
candidate cell membrane proteins that affect dendrite morphogenesis of
Purkinje cells.
% There are two cell stages: postnatal days $15$ ($P15$) and $35$ ($P35$), and each cell stage contains one experimental condition with two biological replicates and two control conditions with one sample each.
% We follow \cite{shuster2022situ} and pair each control sample with one of two experimental biological replicates per stage.
To focus on the statistical problem, in this example we will consider
developing cells ($15$ days postnatal) under the treatment
condition (labelled as
HRP+H$_2$O$_2$ in the original paper) and the control condition (HRP
only). For each condition, the
Purkinje cells of one mouse were extracted, cultivated under the assigned
condition, and prepared for mass spectrometry that measures the abundance
of each protein.
% This comparison is also examined in \cite{shuster2022situ} (Figure 3E).

In total, $4,753$ proteins were detected and their subcellular
localizations were annotated in the UniProt database.
\textcite{shuster2022situ} were interested in
determining proteins annotated with plasma membrane ($740$ in total)
that show a higher level of expression under the treatment
condition. As there were no biological repeats, the authors ranked the
membrane proteins by the difference in their expression under the
treatment and control conditions, and then used internal negative control
proteins to determine a cutoff
value.\footnote{\textcite{shuster2022situ} referred to internal negative
  control proteins as ``false positives'' and proteins under
  investigation as ``true positives''.} Here, the internal negative
control
proteins are those annotated with nuclear,
mitochondrial, or cytoplasmic but not plasma membrane ($2067$ in
total).\footnote{The
  numbers here are slightly different from
  those reported in \cite{shuster2022situ} due to an update of the
  UniProt knowledgebase.}

\Cref{fig:protein} gives a side-by-side
comparison of the test statistics (treatment-minus-control
expressions) of the proteins under investigation and of the internal negative
controls. The bulk of
the proteins under investigation is approximately normally distributed
and resemble the internal negative control
proteins, but a number of proteins show a much larger difference
compared to the internal negative controls. Our scientific collaborators
informed us that such a pattern is commonly observed in similar
experiments.

One immediate challenge with this dataset is that there is no
biological repeat for each condition. This precludes us from deriving
a null distribution for any single protein based on measurements of
just that protein. One possibile solution is to use an \emph{empirical
  null} distribution. \Cref{fig:hist-pval-theoretical} shows the
histogram of the p-values obtained from a two-sample $t$-test with the
standard error estimated by pooling the
proteins. It is apparent from this plot that the standard error is likely to be overestimated, resulting in unexpected concentration of
p-values around $0.5$. In Section \ref{sec:real.data} we describe more
details of this and other ways to estimate the null distribution,
including the method suggested by \textcite{efron2004large}.

\begin{figure}[tbp]
  \centering
  % \begin{subfigure}[b]{\textwidth}
    % \centering
    \includegraphics[width = 0.8\textwidth]{plot/protein-histrogram.pdf}
    % \subcaption{$\chi_{2 \No}^2$}
  % \end{subfigure}

  \caption{Histogram of test statistics (abundance differences between the
      treatment and control conditions of proteins
      under investigation (blue) and internal negative control
      proteins (grey)). Superimposed are rejection thresholds
      (red) with \FDR~level $q = 0.2$ \localFDR~level $q = \pi$ ($\pi$
      is the proportion of null hypotheses). See \Cref{fig:method} for
    how the thresholds are determined.}
    \label{fig:protein}
\end{figure}


\subsection{Overview of the proposed methods}\label{sec:overview}

Our first method may be viewed as a nonparametric extension of the
methods in the last paragraph. Specifically, we propose to
estimate the null distribution using the empirical distribution of the
negative control test statistics. \Cref{fig:hist-pval-ranc} shows the
histogram of what we call the Rank Among Negative Controls (\nickname)
p-values obtained from this empirical null distribution. Compared to
\Cref{fig:hist-pval-theoretical}, a striking feature of
\Cref{fig:hist-pval-ranc} is that the negative control p-values are
almost uniformly distributed over $[0,1]$. This is expected from this
choice of the empirical null; in fact, these p-values are precisely
equal to $\{1/(\NoNc+1), \dotsc, \NoNc/(\NoNc+1), 1\}$ (assuming no
ties). Among the membrane proteins under investigation, the \nickname\
p-values follow a desirable pattern: their distribution has a spike
near $0$ and is nearly uniform elsewhere. One may apply familiar
multiple testing methods such as the \BH\ procedure to \nickname\
p-values; this will be justified in \Cref{sec:pval}.

% The right panels of \Cref{fig:protein} compares the ``theoretical
% null'' p-values obtained from a two-sample $t$-test with the standard
% error estimated by pooling the proteins (see Section
% \ref{sec:real.data} for more detail) with our proposed
% \nickname~p-values using the same test statistic. Evidently, for both
% the proteins under
% investigation and the negative controls, the empirical distribution of the
% p-values obtained from a theoretical null distribution (second panel
% of \Cref{fig:protein}) deviates
% substantially from the uniform distribution on $[0,1]$. In contrast,
% the \nickname~p-values (third panel
% of \Cref{fig:protein}) exhibit the expected pattern: for the
% negative control proteins, the p-values are almost uniformly
% distributed, while for the proteins under investigation, the
% p-value distribution has a spike at $0$. When the \BH~procedure is applied with the nominal \FDR~equal to $0.2$, a total of
% $103$ rejections are made if the ``theoretical'' p-values are used and
% $214$ rejections are made if the \nickname~p-values are used.

% To test the differential expression of proteins under investigation, we compare three proposals: a theoretical p-value, an empirical p-value, and our proposed p-value.
% All three p-values are based on the protein abundance differences between the treatment and control samples\footnote{In \cite{shuster2022situ}, the difference in logarithms of tandem mass tag (TMT) between an experimental sample and a control sample, or equivalently the \logTMT~ratio, is used as the test statistic. However, the \logTMT~of each condition is inaccessible and only \logTMT~ratios of various pairs of experiment and control samples are accessible. The per condition data are important to assess the outcome variation which will be further used to estimate the standard deviation of the \logTMT~ratios and construct test statistics. Therefore, we analyze the protein abundances data which are available for each condition.}.
% % divides the differences by an estimate of their standard deviations,
% The theoretical p-values compare the differences to a theoretical null distribution, and the empirical p-values use an empirical null distribution estimated from the test statistics under investigation as \cite{efron2001empirical} (details are included in \Cref{sec:real.data}).


% The right panel of \Cref{fig:protein} displays the histograms of the theoretical and \nickname~p-values of the testing and internal negative control proteins.
% For the internal negative control proteins, the p-values are expected to be uniform on $[0,1]$.
% It is apparent that the theoretical p-values are over-conservative and stochastically dominate the uniform distribution.
% For the proteins under investigation, the p-values of the proteins unaffected by the treatment will ideally be uniformly distributed on $[0,1]$, while the p-values of the affected proteins will ideally be around zero.
% The histogram of our proposed \nickname~p-values is close to the ideal pattern: uniformly distributed on the interval $(0,1]$ with a spike at zero.
% We further apply Benjamini-Hochberg (\BH) procedure to the baseline and \nickname~p-values respectively (\FDR~level at $0.2$).
% % Consistent with the observation that the theoretical p-values may be over-conservative,
% The \BH~procedure based on the theoretical p-values makes $102$ rejections, less than half of the $213$ rejections yielded by using \nickname~p-values.

\begin{figure}[p]
  \centering
    \begin{subfigure}[t]{0.45\textwidth}
    \centering
    \includegraphics[width =
    \textwidth]{plot/protein-pval-histogram.pdf}
    \caption{Histogram of p-values calculated from a two-sample
      $t$-test.}
    \label{fig:hist-pval-theoretical}
  \end{subfigure} \quad
  % \begin{minipage}{4cm}
  %   \centering
  %   \includegraphics[clip, trim = 0cm 0cm 5cm 0cm, height = 5cm]{plot/protein-pval-histogram.pdf}
  %     %   \subcaption*{(a)}
  % \end{minipage}
  % \begin{minipage}{3.3cm}
  %   \centering
  %   \includegraphics[clip, trim = 0cm 0cm 5cm 0cm, height  = 4cm]{plot/protein-efron-pval-histogram.pdf}
  %     %   \subcaption*{(b)}
  % \end{minipage}
  \begin{subfigure}[t]{0.45\textwidth}
    \centering
    \includegraphics[width =
    \textwidth]{plot/protein-ranc-pval-histogram.pdf}
    \caption{Histogram of p-values calculated using rank among
      negative controls (RANC, method 1). The FDR rejection threshold
      can be determined by applying the Benjamini-Hochberg procedure.}
    \label{fig:hist-pval-ranc}
  \end{subfigure}

  \begin{subfigure}[t]{0.45\textwidth}
    \centering
    \includegraphics[width = \textwidth]{plot/fdr-est.pdf}
    \caption{Rejection threshold determined using estimated FDR
      (method 2).}
    \label{fig:estimated-fdr}
  \end{subfigure}
  \quad
  \begin{subfigure}[t]{0.45\textwidth}
    \centering
    \includegraphics[width = \textwidth]{plot/ecdf.pdf}
    \caption{Rejection threshold determined by maximizing the
      difference of empirical complementary CDFs (black curve,
      method 3).}
    \label{fig:lfdr}
  \end{subfigure}

  \caption{An illustration of the methods proposed in this
    article. The red, vertical lines correspond to rejection
    thresholds with FDR level $q=0.2$ (solid) and local
    FDR level $q = \pi$ (dashed, $\pi$ is the proportion of null
    hypotheses).}
  \label{fig:method}

\end{figure}

Our second method is motivated by the empirical process perspective of
\FDR\ control
\parencite{genovese2004stochastic,storey2004strong}. Specifically, we
propose to estimate the \FDR\ above (or below) any rejection threshold
by the ratio of the proportions of test statistics and
negative controls that would be rejected by that
threshold. \Cref{fig:estimated-fdr} illustrates this proposal by
showing the estimated \FDR\ curve for the motivating proteomic
analysis, which can be used to select the rejection threshold for any
targeted \FDR\ level $q$ ($q = 0.2$ is illustrated in the figure).

Our third method is motivated by a rule-of-thumb cut-off analysis in the
original study \parencite{shuster2022situ} proposed by
\textcite{hung14_proteom_mappin_human_mitoc_inter}. This method
computes the empirical (in this case, complementary) cumulative
distribution functions of the test statistics and negative controls
and simply chooses the maximizer of their difference as the rejection
threshold; see \Cref{fig:lfdr} for an illustration. Although this
procedure seems rather ad hoc, the objective that it minimizes can indeed
be viewed as a nonparametric estimate of a weighted mis-classification
risk for multiple testing. Using this heuristic, we show that the
procedure in \textcite{hung14_proteom_mappin_human_mitoc_inter} can be
extended to control the \localFDR~at the rejection threshold.

Shortly after releasing the first preprint of this paper, we
discovered that some recent works, stemming from different motivating
applications, have proposed some almost identical ideas
above. Specifically, our first method (\nickname\ p-value) is the same
as the conformal p-values to test for outliers proposed by
\textcite{bates21_testin_outlier_with_confor_p_values}. Our
second method (empirical estimation of FDR) is essentially the same as
the so-called ``semi-supervised'' multiple testing proposed by
\textcite{mary22_semi_super_multip_testin}, and is closely related to
the analysis of knockoff filters in
\textcite{weinstein17_power_predic_analy_knock_with_lasso_statis};
they are all essentially derived from the martingale argument in
\textcite{storey2004strong}. Our
third method (estimator of \localFDR) is closely related to the method in
\textcite{soloff22_edge_discov} which assumes a known null
distribution. Thus, our paper in effect grounds these recent
ideas in an exploding and diverging literature on a simple and
concrete biological application described next. Moreover, as we are
motivated by biological applications in which negative controls could
easily be misselected, the theoretical
conditions developed below are generally weaker than the i.i.d.\ or
exchangeability conditions used before. We discuss the
connections and differences with these recent works and the broader
literature in more detail below.

\subsection{Literature review}

% We first provide an overview of negative controls including the external and internal negative controls.
% We then delve into the literature of internal negative controls:
% summarizing existing internal negative control datasets and how they
% are used.

When most of the null hypotheses are true (i.e.\ $\NoNull/\No$ is close
to $1$) and the theoretical model is correct, the bulk of the test
statistics should be close to the theoretical null
distribution. However, this is often not the case in practice. One
example is the population stratification in genome-wide association
studies, where systematic ancestry difference may distort the
null distribution
\parencite{price06_princ_compon_analy_correc_strat,hellwege17_popul_strat_genet_assoc_studies}. Another
example is batch effect or unwanted variation due to the sequencing
platform
\parencite{leek10_tackl_wides_critic_impac_batch}. \textcite{efron2004large}
argues that if such problems arise, it may be sensible to estimate the null
distribution using the bulk of the empirical distribution of the test
statistics. Other approaches based on more sophisticated models of the
data (such as latent factor models) attempt to estimate the null
distribution empirically by assuming the false hypotheses are sparse
\parencite{leek07_captur_heter_gene_expres_studies,wang17_confoun_adjus_multip_hypot_testin} or by using
negative controls
\parencite{gagnon2012using,wang17_confoun_adjus_multip_hypot_testin}.

Broadly speaking, negative control refers to the situation where a
null effect (``negative result'') is expected. For a given scientific
experiment, there are two types of negative controls: data on internal negative control
units in the same experiment and data from an external control
experiment (e.g.\ the placebo group in a clinical trial). The motivating
example in \Cref{sec:motivating.data} contains both types of negative controls.
Proteins annotated with nuclear, mitochondrial, or cytoplasmic but not
plasma membrane are used as internal negative controls, because the
different
chemical treatments (HRP+H$_2$O$_2$ and HRP only) are not expected to
change their expression levels. The HRP (horseradish peroxidase) only condition is used as an
external control in \textcite{shuster2022situ} because both HRP and H$_2$O$_2$ are needed to tag cell
membrane proteins so that they can be detected by mass spectrometry.

% In an external control experiment, the investigator is
% interested in understanding the effect of an independent variable on
% several dependent variables. The investigator varies the level of the
% independent variable while controlling the level of other sources of
% variation (confounding variables). Here, the control group means the
% units that receive a placebo or no treatment at all.
% In contrast, internal negative control units refer to a set of
% dependent variables that are not influenced by the independent
% variable or the treatment.

In this paper we focus on internal negative controls, which
essentially represent prior information
about the non-existence of certain causal connections. Such prior
information may come from scientific contexts, experimental
techniques, and previous research studies. In high-throughput
sequencing applications, it is common that the scientific
understanding of the treatment suggests that certain measured units
should not be affected by the treatment. Examples include the
non-membrane proteins in our motivating example \parencite{li2020cell,
  shuster2022situ} and housekeeping genes that are required for the
maintenance of basic cellular function
and thus have a stable level of expression
\parencite{gagnon2012using}. Researchers may also artificially create
internal negative controls by adding units that
should not be affected by the treatment. Examples
include exogenous cells or molecules (often called spike-ins) that do
not interact with the treatment in biological experiments
\parencite{lippa2010exploring} and carefully designed questions in surveys
\parencite{lipsitch2010negative}.

% There are a wealth of internal negative control data available and we classify them into three categories.
% \begin{itemize}
% \item  Internal negative controls from high-throughput analysis. High-throughput analysis usually measures as many units as the capacity permits and it is common that certain measured units can be excluded from being affected according to the scientific understanding of the treatment. Examples include the proteins with specific locations in the proteomic analysis \cite{li2020cell, shuster2022situ} and housekeeping genes in the genome-wide association study  \cite{gagnon2012using}.
%     %   For instance, in the proteomic analysis via mass spectrometry, if a treatment targets proteins at a specific location, e.g., in plasma membrane, the screened proteins not at that location should not be influenced by the treatment
%     % %   and thus the proteins whose annotation of subcellular localization information does not include the keyword plasma membrane
%     %   and serve as internal negative proteins \cite{li2020cell, shuster2022situ} (more details can be found in the motivating protein dataset in \Cref{sec:motivating.data}).
%     %   In genome sequencing, housekeeping genes are a collection of genes that are responsible for basic functions of a cell, express at relatively stable rates in most situations, and thus are valid internal negative control genes for genome-wide association study.

% \item Artificially constructed internal negative controls. Researchers may design units that will not be influenced by the treatment and add them to the pool of units for measurement.
%   Examples include the spike-ins (exogenous or synthetic cells or molecules that do not interact with the treatment) in biological experiments \cite{lippa2010exploring} and questions of irrelevant factors in self-reported surveys \cite{lipsitch2010negative}.

% \item Data-driven internal negative controls.
%   Researchers may learn internal negative controls, or look for units that are not highly associated with the treatment, from external data or a held-out validation dataset. Learning internal negative controls is appealing due to its simplicity and the potential to be automated.
% \end{itemize}

Although internal negative controls have long been used in scientific
investigations, their utility in statistical methodology has only been
explored since recently. In epidemiology, \textcite{lipsitch2010negative}
employed internal negative controls to detect and remove
confounding. This was formally studied by
\textcite{miao18_ident_causal_effec_with_proxy} and is often referred
to as ``proximal causal inference'' in the literature
\parencite{tchetgen20_introd_to_proxim_causal_learn}.
% rule out non-causal associations.
In microarray studies, \textcite{gagnon2012using} used internal negative
control genes to remove unwanted variation, and their
method was analyzed and extended by \textcite{wang2017confounder}.

There exists a small and scattered literature in computational biology and
biostatistics that attempts to use internal negative controls to
control the number of false discoveries. Some authors proposed to fit
a parametric model to the internal negative controls in order to
estimate the null distribution of the test statistics
\cite{nix2008empirical, listgarten2013powerful,
  slattery2011cofactor}. Naturally, such methods are sensitive to the
parametric specification. \textcite{parks2018using}
proposed to estimate the local \FDR~using a kernel density
estimator based on the internal negative controls but did not provide
theoretical justifications of their method. Other authors suggested
heuristic approaches that use the internal negative controls
to estimate the \FDR~\parencite{zhang2008model,
  song2007model}.

Conformal inference seeks distribution-free uncertainty quantification
of the predictions from black-box machine learning models. This
framework, originally developed by Vladimir Vovk and collaborators
\parencite{vovk2005algorithmic}, seeks to make predictive inference
based on how close new observations ``conform'' with the training
data. Conformal inference has received rapidly increasing attention
recently; see \textcite{angelopoulos2021gentle}
for a recent review and some historic notes and
\textcite{zhang2022randomization} for an interpretation from the
viewpoint of classical randomization/permutation tests. Our work is
closely related to conformal inference. In particular, the \nickname\
p-value proposed here may be viewed as a permutation p-value and is
indeed identical to the conformal p-value for outlier detection in
\textcite{bates21_testin_outlier_with_confor_p_values}. See
\textcite{marandon22_machin_learn_meets_false_discov_rate} and
\textcite{liang2022integrative} for some extensions. Another closely
related perspective is to view multiple testing with
negative controls as a semi-supervised problem
\parencite{mary22_semi_super_multip_testin}, a term borrowed from the
machine learning literature. Motivated by problems in astrostatistics,
\textcite{mary22_semi_super_multip_testin} proposed to use
the same p-value using the empirical null viewpoint. They analyzed the
\BH\ procedure applied to such p-values using a martingale argument
and provided some further optimality results. To our knowledge, the
connection between conformal inference, negative controls, and
empirical null in multiple testing has not been well recognized yet.

% In applications we consider, a particularly important
% concern is that the negative controls may be selected
% incorrectly. This motivates us to develop justifications of the
% proposed methods under weaker conditions that allow misspecified
% negative controls or dependent test statistics, so the theoretical
% results below may also be useful in applications using conformal
% prediction.

Last but not least, we brieflly review the literature
concerning \localFDR. \LocalFDR\ was first proposed in
\textcite{efron2001empirical} as a Bayesian alternative to
\FDR. \textcite{sun2007oracle} showed that controlling \localFDR\ is
closely related to minimizing a misclassification loss for the
multiple testing procedure and developed a procedure that controls the
marginal \FDR\ based on a given estimate of the \LocalFDR\
curve. Typically, \LocalFDR\ is estimated by fitting parametric or
semiparametric density models to the data; see, for example,
\textcite{efron2012large}. The recent paper by
\textcite{soloff22_edge_discov} proposed to estimate \localFDR\
nonparametrically using the Grenander's estimator for monotone density
functions and is most closely related to
our third method (and hence the ad hoc procedure in
\textcite{hung14_proteom_mappin_human_mitoc_inter}). The main
difference is that \textcite{soloff22_edge_discov} assumes the null
density function is known, while we use negative controls to estimate
it empirically.

% \textcite{shuster2022situ} used a rule-of-thumb
% developed by \textcite{hung14_proteom_mappin_human_mitoc_inter} to
% selected the cutoff value in proteomic analysis; specifically, the
% cutoff is chosen to maximize the difference in
% the empirical cumulative distribution functions of the negative
% controls and of the proteins under investigation.

% These types of methods
% are suitable when controlling specific criterion is the primary task
% and becomes restrictive if other false discovery control criteria are
% of interest. In addition, statistical analysis of the methods'
% properties is to be developed.

\subsection{Outline and notation}
\label{sec:outline-notation}

% \begin{table}[btp]
%   \centering
%   \caption{Summary of multiple testing procedures combined with
%     \nickname~p-values.}
%   \label{tab:summary}
%   \begin{tabular}{p{2cm}|p{2cm}|p{8cm}}
%     \toprule
%     % \multicolumn{2}{c|}{validity}                     & \Cref{prop:pvalue.validity} \\ \hline
%     % \multicolumn{2}{c|}{\PRDS}                     &  \Cref{prop:PRDS}
%     % \\ \hline
% Task & Error rate & Procedure \\
% \midrule
% {Global  null} & Type I error  & Bonferroni
%                                  (\Cref{prop:pvalue.validity}), Simes
%                                  (\Cref{prop:simes}), general
%                                  procedures
%                                  (\Cref{sec:multiple.testing}) \\
% \hline
%       {Individual hypotheses}    & \FDR & Benjamini-Hochberg~ (\Cref{coro:FDR}, \Cref{prop:FDR}) \\ \cline{2-3}
%                    & \FWER, \FDP  & Holm (\Cref{prop:pvalue.validity}), general procedures (\Cref{sec:multiple.testing}) \\
% % \cline{2-3}
% % \multicolumn{1}{c|}{}                  & \localFDR  & general (Bayes risk minimization) \\
% \bottomrule
% \end{tabular}
% \end{table}

In \Cref{sec:setup-terminology}, we describe the mathematical setup of
this paper and review some terminologies in multiple testing.
In \Cref{sec:pval}, we consider the perspective of using negative
controls to form an empirical null distribution and propose the
\nickname~p-values. We give sufficient conditions under which the
\nickname~p-values are valid and satisfy a \PRDS~property, and discuss how the
\nickname~p-values can be combined using various multiple testing
procedures. In \Cref{sec:empirical.process}, we consider the
perspective of using negative controls to form an empirical estimator
of the \FDR. We show the step-up procedure with such as estimtor
can control the \FDR\ even if some negative controls are selected incorrectly.
% In \Cref{sec:permutation}, we provide a permutation test perspective of the \nickname~p-values.
% We show how permutation tests can be used to simulate the null distribution of global null tests based on \nickname~p-values and discuss how \nickname~p-values may provide shortcuts for computing the permutation test rejection thresholds.
% In \Cref{sec:application}, we discuss examples? one-sided?
In \Cref{sec:localFDR}, we develop a method that estimates the
rejection threshold for a given level of \localFDR\ and study its
asymptotic properties. In \Cref{sec:simulation}, we investigate the
performance of \nickname~p-values using numerical simulations.
In \Cref{sec:real.data}, we come back to the motivating proteomic
dataset and investigate different choices of the null distribution. In
\Cref{sec:discussion}, we conclude with some further discussion.

We introduce some mathematical conventions used below.
For $x \in \RR$, we use $\lfloor x \rfloor$ to denote the maximal integer smaller or equal to $x$.
For a set $\calA$, we denote its cardinality by $|\calA|$.
We abbreviate cumulative distribution function as CDF,
probability density function as PDF,
almost everywhere as a.s.,
independently and identically distributed as i.i.d..
We denote the uniform distribution on the interval $[0,1]$ by $U[0,1]$, and the normal distribution with mean $\mu$ and variance $\sigma^2$ by $\calN(\mu, \sigma^2)$.
We use $\Phi(\cdot)$ to denote the CDF of the standard normal distribution.
For two random variables $X$, $Y$, $X \stackrel{d}{=} Y$ means $X$ and $Y$ follow the same distribution.
If $\PP(X \le t) \le \PP(Y \le t)$ for all $t \in \RR$, we say $X$
stochastically dominates $Y$ and denote the relationship by $X \gtrsim
Y$ or $Y \lesssim X$. Given a collection of random variables
$X_i,~i=1,\dotsc,n$, the $k$-th order statistic is defined as its $k$-th
smallest value and is denoted as $X_{(k)}$.

\section{Setup and terminology}
\label{sec:setup-terminology}

Suppose there
are $\No + \NoNc$ null hypotheses. The first $\No$
hypotheses $\hypothesisIndex{} = \{1,\dotsc,\No\}$ are under
investigation. Let $\nullHypothesisIndex$ denote the set of true
null hypotheses and $\NoNull = |\nullHypothesisIndex|$; neither
$\nullHypothesisIndex$ nor $\NoNull$ is known. The last $\NoNc$ hypotheses $\hypothesisIndex{\text{nc}} =
\{\No+1,\dotsc,\No+m\}$ are known to be true and we shall refer to
them as the (internal) negative controls. In our motivating example in
\Cref{sec:motivating.data}, $\No = 740$ and $\NoNc = 2067$. Each
hypothesis $\hypothesis{i}$ is
associated with a test statistic $\testStatistics{i}$, and we assume
that a small test statistic provides evidence against that
hypothesis. For example, $\testStatistics{i}$ can be a p-value for
$\hypothesis{i}$ calculated under some possibly misspecified
statistical model. We are interested in identifying as many non-null
hypotheses in $\hypothesisIndex{} \setminus \nullHypothesisIndex$ as
possible while maintaining control of some multiple testing error.
% unaffected by the interested variable.
% The internal negative control units and the units under investigation are examined in the same experiment, which is different from external control experiments where researchers conduct separate trials controlling all the factors
% at the same level as those under the treatment
% except the variable of interest.
% We denote the internal negative control hypotheses by
% $\ncHypothesis{j}$ and the corresponding test statistics by
% $\ncTestStatistics{j}$.
% Negative controls are the units where the null effect is expected, i.e., a negative result should be observed.
% There are two types of negative control data: external control experiments and internal negative control units.

Next, we briefly review some error rates that are commonly used for
simultaneous hypothesis testing. Given a set of hypotheses
$\{\hypothesis{i}:i \in \calI\}$, let $\totalPositive$ be the total
number of rejections, $\falsePositive$ be the number of incorrect
rejections, and $\truePositive$ be the number of
the correct rejections; see also \Cref{tab:outcome}.
% Several criteria
% have been proposed in the literature to quantify the number of false
% discoveries and here we focus on \FWER, \FDR, \FDP, and \localFDR.
% Formally,
\FWER~is the probability of
making at least one false discovery, \FDP~is the proportion of false
discoveries among all discoveries, and \FDR~is the expectation of \FDP:
\begin{align*}
    \FWER := \PP(\falsePositive \ge 1),\quad\FDP :=
  \frac{\falsePositive}{\totalPositive \vee 1},\quad\text{and}\quad\FDR
    := \EE[\FDP]
    = \EE\left[\frac{\falsePositive}{\totalPositive \vee 1}\right],
\end{align*}
where $R \vee 1$ is the maximum of $R$ and $1$.
We say a multiple testing procedure controls the \FWER~at level
$\alpha$ if $\FWER \leq \alpha$; similarly, a procedure controls the
\FDR~at $q$ if $\FDR \leq q$.
Note that unlike the other two quantities, \FDP~is random and can
only be controlled in some probabilistic sense. For example, we say
a procedure controls the tail probability of \FDP~at
$q$ at level $\alpha$ if $\PP(\FDP > q) \leq \alpha$.
% Compared with the stringent \FWER-control methods, approaches controlling \FDR~often return many candidates of interest with a few false discoveries and are more helpful for downstream validation experiments.
% % The criteria \FDP~is sometimes more interpretable than its expectation \FDR~and could be of interest in certain applications.
% \FDR~control implies the \FDP~control if \FDP~concentrates, and see
% \cite{roquain2011type} for a discussion on such concentration
% phenomenon. % occurs when the dependence between p-values does not
% vanish or the number of the proportion of non-null goes to zero as
% the $\No$ increases to infinity \cite{roquain2011type}.
Finally, it has been shown all procedures that control \FWER~or
(the tail probability of) \FDP~can be improved by the closed testing
principle that
combines tests of intersection null hypotheses
\parencite{marcus1976closed,goeman2021only};
an
intersection or global null hypothesis $\cap_{i \in \calI}
\hypothesis{i}$ is said to be true if and only if all individual
hypotheses $\hypothesis{i}$, $i \in \calI$ are true.

When discussing \FWER, \FDR, and \FDP, we will assume that
the CDF of the test statistic $\testStatistics{i}$, denoted by
$\cdfTestStatistics{i}$, is a continuous function for all $i
=1,\dotsc,\No+\NoNc$, and there are no ties (with probability one). We
discuss tiebreakers in \Cref{sec:discussion}.

\begin{table}[tbp]
  \centering
  \caption{{Outcomes in multiple testing.}}
\label{tab:outcome}
\begin{tabular}{c|cc|c}
\toprule
  & Not rejected & Rejected & Total  \\
  \midrule
$\nullHypothesis{i}$ true & $\trueNegative$ & $\falsePositive$  & $\NoNull$ \\
$\nullHypothesis{i}$ false & $\falseNegative$ & $\truePositive$ & $\NoNonNull$ \\ \hline
  Total & $\No - \totalPositive$ & $\totalPositive$ & $\No$  \\
  \bottomrule
\end{tabular}
\end{table}


We will also consider the \localFDR, a Bayesian alternative to
traditional multiple testing criteria. Suppose
$(\hypothesis{i})_{i \in \calI} \overset{\text{i.i.d.}}{\sim}
\text{Bernoulli}(1 - \pi)$, and the
test statistic $\testStatistics{i}$ follows the distribution
\begin{equation*}
  \label{eq:two-mixture}
  \testStatistics{i} \mid \hypothesis{i} = 0 \sim
  \cdfTestStatisticsNull \quad \text{and} \quad \testStatistics{i}
  \mid \hypothesis{i} = 1 \sim \cdfTestStatisticsNonNull.
\end{equation*}
% Throughout the paper, we use upper-case $F$ to denote the cumulative
% distribution function (CDF) of a probability distribution.
The marginal CDF of $\testStatistics{i}$ is thus given by the mixture
$\cdfTestStatistics{} = \probNull \cdfTestStatisticsNull +
(1-\probNull) \cdfTestStatisticsNonNull$.
When discussing \localFDR, we will assume that the density functions
of $\cdfTestStatisticsNull$,
$\cdfTestStatisticsNonNull$, and $\cdfTestStatistics{}$ exist and
denote them by $\pdfTestStatisticsNull$, $\pdfTestStatisticsNonNull$,
and $\pdfTestStatistics{}$, respectively. The \localFDR~at $t$ is
simply the posterior probability $\Pr(H_i = 0 \mid T_i = t)$ of $H_i$
being a true null given its test statistic is
$T_i=t$ \parencite{efron2001empirical}, i.e.\
\begin{align} \label{eq:local-fdr}
  \localFDR(t)
    = \frac{\probNull \pdfTestStatisticsNull(t)}{\probNull
  \pdfTestStatisticsNull(t) + (1-\probNull)
  \pdfTestStatisticsNonNull(t)},
\end{align}
We say a procedure controls \localFDR~at level $q$ if
$\localFDR(\testStatistics{i}) \le q$ for all rejected hypotheses
$\hypothesis{i}$.

\section{The empirical null perspective}\label{sec:pval}

\subsection{Rank among negative controls}
\label{sec:ranc-p-values}

Our first method uses negative control statistics to form a
nonparametric estimator of the null distribution. Specifically, we
define the \nickname~p-value for $\hypothesis{i},~i \in
\hypothesisIndex{}$ as $\pval{i} = \hat{F}(\testStatistics{i})$, where
\begin{align}\label{defi:nc.ecdf.2}
  \hat{F}(t)
  = \frac{1 + \sum_{j \in \hypothesisIndex{\text{nc}}}
  \1_{\{\testStatistics{j} \le
  t\}}}{1 + \NoNc}
\end{align}
is the empirical cumulative distribution function (CDF) of
$(-\infty,\testStatistics{\No+1},\dotsc,\testStatistics{\No+\NoNc})$.
Here, we include a $-\infty$ in the definition of
$\hat{F}$ to ensure that the \nickname~p-value does not equal zero with
a positive probability.
% So
% the \nickname~p-value may also be viewed as the p-value with respect to
% an empirical, model-free null distribution estimated from the
% negative controls.
Another way to put this is that $\pval{i}$ is simply the
normalized rank of $\testStatistics{i}$ among
$(\testStatistics{j})_{j \in \{i\} \cup \hypothesisIndex{\text{nc}}}$:
\begin{align}\label{eq:pval}
  \pval{i} := \frac{1 + \sum_{j \in \hypothesisIndex{\text{nc}}}
  \1_{\{\testStatistics{j} \le \testStatistics{i}\}}}{1 + \NoNc} =
  \frac{1 + (\text{number of negative control statistics
  }\leq T_i)}{1 + (\text{number of negative control statistics})}.
\end{align}
This is why we call $\pval{i}$ the Rank Among
Negative Control (RANC) p-value.

If the negative control statistics resemble the test statistics under
the null, we expect that $\hat{F}$ to be close to the null distribution
of the test statistics and $\pval{i} = \hat{F}(\testStatistics{i})$ to
be approximately uniformly distributed when $\NoNc \to \infty$. If we
further assume that
\begin{equation}
  \label{eq:basic-exchangeable}
  \text{the collection of random variables}~(\testStatistics{i})_{i\in
    \hypothesisIndex{0} \cup \hypothesisIndex{\text{nc}}} ~\text{is
    exchangeable},
\end{equation}
then $\pval{i}$ is exactly the p-value of the permutation test of
exchangeability using just $T_i$. Thus, the proposed \nickname~p-value
is valid under \eqref{eq:basic-exchangeable} in the sense
that $\PP(\pval{i} \leq \alpha) \leq \alpha~\text{for all}~0 < \alpha
< 1$.

% Motivated by the fact that the internal negative control test statistics should resemble, or be exchangeable with, the true null test statistics,
% % The null of the permutation test requires the test statistics under investigation to be exchangeable with the internal negative control counterparts.
% The p-value can also be interpreted as estimating the null distribution of the test statistic using internal negative controls and evaluating at $\testStatistics{i}$.
% % then evaluating how extreme the observed value $\testStatistics{i}$ is according to the estimated null distribution.
% We name the proposed p-value by \nickname: the normalized Rank of the test statistics $\testStatistics{i}$ Among all internal Negative Control counterparts.
% % Under the exchangeability between null and internal negative control test statistics, the \nickname~p-value is guaranteed to be valid without any knowledge about how $\testStatistics{i}$ is generated.
% % More general assumptions ensuring the validity of \nickname~p-value are discussed in \Cref{sec:validity},

% \subsection{Properties of \nickname~p-values}\label{sec:advantage}

% The \nickname~p-value is non-asymptotically valid if the true null test statistics and the internal negative control are exchangeable.
% This refrains us from complicated data modeling and null distribution calculation.
% On samples with a limited number of observations, the \nickname~p-value is more trustworthy than the p-values that are only asymptotically valid.
% The \nickname~p-value is not over-conservative and controls the type I error approximately at the nominal level for a moderately large number of internal negative controls.
% In fact, under the exchangeability condition, the gap between the actual type I error probability and the target size of the test is at most one over the number of internal negative controls.
% An approximately exact test is likely to have more power to reject the null hypothesis when it should be.
% The advantage of making more discoveries could be more evident when the \nickname~p-values are combined with multiple testing procedures and corrected for multiplicity.

% Validity of \nickname~p-values immediately permit us to use Bonferroni's
% correction to test the global null, which can then be closed to control
% \FWER~\parencite{marcus1976closed,holm1979simple} and the tail probability of false
% discovery proportion (\FDP) using the procedure described in
% \textcite{goeman2011multiple}. We may also apply graph-based
% methods~such as fixed-sequence testing and the fallback procedure
% \parencite{wiens03_fixed_sequen_bonfer_proced_testin_multip_endpoin}
% to \nickname~p-values to control \FWER. Moreover,
% under a slightly stronger
% exchangeability assumption, it is shown in \Cref{prop:PRDS}
% below that the \nickname~p-values satisfy a positive dependency structure
% (\PRDS) property which allows us to use Simes' test for the global
% null, the Hochberg procedure for \FWER~control, and the
% \BH~procedure for \FDR~control.

Our goal in the rest of this section is to give a more precise,
non-asymptotic analysis of the \nickname~p-values. In
particular, we will give sufficient conditions under which the
\nickname~p-values are individually valid and satisfy a PRDS
property. To this end, we first give a formal definition of
exchangeability and PRDS on a subset of random variables.

\begin{definition}
  We say a sequence of random variables $(X_i)_{i \in \calI}$ is
  exchangeable on a subset $(X_i)_{i \in \calJ}$ for some $\calJ
  \subseteq \calI$, if for any
  permutation $g:\calI \to \calI$ such that $g(i) = i$ for
  all $i \not \in \calJ$, the distribution of $(X_{g(i)})_{i \in
    \calI}$ is the same as $(X_i)_{i \in \calI}$. When this holds for
  $\calJ = \calI$, we simply say the sequence $(X_i)_{i \in \calI}$ is exchangeable.
\end{definition}

\begin{remark}
  Note that this is equivalent to assuming that $(X_i)_{i \in \calJ}$
  is exchangeable conditionally on $(X_i)_{i \in \calI \setminus \calJ}$. We
  introduce this new terminology of exchangeability on a subset to
  contrast with the definition of PRDS below.
\end{remark}

To define PRDS, we say a set
$\calD \subseteq \RR^n$ is increasing if $\calD$ contains all $y
\in \RR^n$ that satisfies $y_i \ge x_i,~1 \le i \le n$ for some $x
\in \calD$.

\begin{definition}\label{defi:PRDS}
    We say a sequence of random variables $(X_i)_{i \in \calI}$ exhibits
    Positive Regression Dependence on a Subset (PRDS) $(X_j)_{j \in
      \calJ}$ for some $\calJ
    \subseteq \calI$, if for any increasing set $\calD
    \subseteq \RR^{|\calI|}$ and any $j \in \calJ$, the conditional
    probability $\PP\big((X_i)_{i \in \calI} \in \calD \mid X_j = x\big)$ is
    increasing in $x$. When this holds for $\calJ = \calI$, we simply
    say the sequence $(X_i)_{i \in \calI}$ is PRD.
\end{definition}

It follows from the definition that PRDS is preserved by co-monotone
transformtions: given some monotonically increasing (or decreasing)
functions $G_i$ for $i \in
\calI$, the assumption that $(X_i)_{i \in \calI}$ is PRDS implies that
$(G_i(X_i))_{i \in \calI}$ is also PRDS.


% In this paper, we focus on the case where $\{\testStatistics{i}\} \cup \{\ncTestStatistics{j}\}$ do not have ties a.s.. This condition is satisfied if the distributions of the test statistics $\{\testStatistics{i}\} \cup \{\ncTestStatistics{j}\}$ have density functions.


% Motivated by the belief that the marginal distribution of the test statistic of an internal negative control should be the same as that of a true null, we estimate the null CDF of $\testStatistics{i}$ by a modified empirical CDF of the internal negative control test statistics,
% \begin{align}\label{defi:nc.ecdf}
%     \hat{F}(t)
%     = \frac{1 + \sum_{j=1}^{\NoNc} \1_{\{\ncTestStatistics{j} \le t\}}}{1 + \NoNc}.
% \end{align}
% % Compared with the standard empirical CDF of the internal negative controls, there is an additional one in the denominator and the enumerator to ensure the validity of the induced \nickname~p-values.
% % The difference vanishes as the number of internal negative controls increases.
% % The modified estimator equals the empirical distribution function of an augmented set of internal negative control test statistics $\{-\infty\} \cup \{\ncTestStatistics{j}\}_{1 \le j \le \NoNc}$ with an extra pseudo internal negative control test statistics taking the least conservative value of minus infinity.
% According to the probability integral transform, the composition of a continuous random variable and its CDF  yields a uniform distribution, $\cdfTestStatistics{i}(\testStatistics{i}) \sim U[0,1]$.
% The modified empirical distribution function $\hat{F}(\cdot)$ converges to $\ncCdfTestStatistics{}(\cdot)$ as the number of internal negative control test statistics increases.
% The internal negative control test statistics resemble the null test statistics in distribution $\hat{F}(\cdot) \approx \ncCdfTestStatistics{j}(\cdot) \approx \cdfTestStatistics{i}(\cdot)$.
% % under proper dependence conditions of the internal negative control test statistics,
% Therefore, we expect $\hat{F}(\testStatistics{i})$ to be approximately $\cdfTestStatistics{i}(\testStatistics{i}) \sim U[0,1]$ if $\hypothesis{i}$ is true.
% % Based on the modified empirical distribution function $\hat{F}(\cdot)$,
% The observation gives rise to the \nickname~p-value~\eqref{eq:pval} as the modified empirical CDF of the internal negative controls evaluated at the candidate test statistic.
% % \begin{definition}\label{defi:pval}
% %     For the $i$-th hypothesis under investigation, define the \nickname~p-value as
% %     \begin{align}\label{defi:eq:pval}
% %         \pval{i} := \hat{F}(\testStatistics{i})
% %         = \frac{1 + \sum_{j=1}^{\NoNc} \1_{\{\ncTestStatistics{j} \le \testStatistics{i}\}}}{1 + \NoNc}.
% %     \end{align}
% % \end{definition}
% If we replace $\hat{F}(\cdot)$ by the standard empirical distribution function without the additional one in the denominator and the enumerator, the resulting quantity takes the value of zero with a positive probability and is an invalid p-value.
% \noindent The \nickname~p-value is non-increasing, and a smaller test statistic $\testStatistics{i}$, which should be more likely to be rejected, will induce a smaller $\pval{i}$---consistent with the concept of p-values.

\subsection{Validity}\label{sec:validity}

% We introduce the conditions to guarantee the validity of the proposed \nickname~p-values.
% The \nickname~p-values are valid with exchangeable null test statistics and the internal negative controls.


\begin{proposition}\label{prop:pvalue.validity}
% Let $\testStatistics{i}$ be the test statistic associated with a true null hypothesis.
Fix a true null hypothesis $\hypothesis{i}$ for some $i \in
\nullHypothesisIndex$ and suppose the following assumptions are
satisfied:
\begin{enumerate}[label = (\alph*), ref = (\alph*)]
    \item \label{vali:assu:null.nc.conservative.general}
      $\cdfTestStatistics{i}(t) \le \cdfTestStatistics{j}(t)$ for all $j
      \in \hypothesisIndex{\text{nc}}$ and $t \in \RR$;
    \item \label{vali:assu:one.exchangeable.general}
      $(\cdfTestStatistics{j}(\testStatistics{j}))_{j \in \{i\} \cup
        \hypothesisIndex{\text{nc}}}$ is exchangeable.
\end{enumerate}
Then the \nickname~p-value $\pval{i}$ is valid in the sense
that $\PP(\pval{i} \leq \alpha) \leq \alpha$ for all $0 < \alpha < 1$.
% \begin{align}\label{prop:eq:pvalue.validity}
%     \PP(\pval{i} \le t) \le t, \quad \text{for}~ 0 \le t \le 1.
% \end{align}
\end{proposition}

% Two special cases of \Cref{prop:pvalue.validity} are summarized in the following corollary.

% \begin{corollary}\label{coro:pvalue.validity}
% Suppose one of the following sets of conditions holds,
% \begin{enumerate}
%     \item
%     \begin{enumerate}[label = \alph*.,ref = \alph*]
%     \item \label{vali:assu:null.nc.conservative} $\testStatistics{i} \gtrsim \ncTestStatistics{j}$ for any $\ncHypothesis{j} \in \ncHypothesisSet$;
%     \item \label{vali:assu:one.nc.set.independent} $\{\testStatistics{i}\} \cup \left\{\ncTestStatistics{j} \right\}_{1 \le j \le \NoNc}$ are mutually independent.
%     \end{enumerate}
%     \item \label{vali:assu:one.exchangeable} $\{\testStatistics{i}\}\cup \left\{\ncTestStatistics{j} \right\}_{1 \le j \le \NoNc}$ are exchangeable.
% \end{enumerate}
% Then for any $\calH_i \in \nullHypothesisSet$, the associated \nickname~p-value defined in Eq.~\eqref{eq:pval} is valid.
% \end{corollary}

% If the marginal distributions $\cdfTestStatistics{i}$, $\ncCdfTestStatistics{j}$ are equal, the assumptions~\ref{vali:assu:null.nc.conservative.general} and \ref{vali:assu:one.exchangeable.general} reduce to that $\testStatistics{i}$ and $\ncTestStatistics{j}$ are exchangeable.
% In \zg{TODO:}, we discuss an example where $\cdfTestStatistics{i}(t)$ is dominated by $\ncCdfTestStatistics{j}(t)$.

A proof of \Cref{prop:pvalue.validity} can be found in the
Appendix. It uses a monotone coupling argument and the fact that the
rank of exchangeable random variables is uniformly distributed.

\begin{remark}
The conditions in \Cref{prop:pvalue.validity} are stated in terms of
the probability integral transforms of the test statistics and are weaker
than the exchangeability in \eqref{eq:basic-exchangeable} in two
ways. First, as we are only
concerned with the validity of $\pval{i}$ for some fixed $i$, it is
only necessary to
assume that $\testStatistics{i}$ is exchangeable with the negative
control statistics. Second, the null statistic
$\testStatistics{i}$ is allowed to be stochastically larger than the
internal negative control statistic $\testStatistics{j}$ for all $j\in
\hypothesisIndex{\text{nc}}$. This relaxation is useful for
testing one-sided hypotheses; see \Cref{rem:one-sided} below.
% % Our heuristic that the marginal distribution of the true null test statistics equals that of the internal negative control test statistics,
% Exchangeable null and internal negative control test statistics
% % i.e., $\testStatistics{i} \stackrel{d}{=} \ncTestStatistics{j}$ for any $\hypothesis{i} \in \nullHypothesisSet$, $\ncHypothesis{j} \in \ncHypothesisSet$,
% is a special case of the condition~\ref{vali:assu:null.nc.conservative.general} with $\testStatistics{i} \stackrel{d}{=} \ncTestStatistics{j}$. Condition~\ref{vali:assu:null.nc.conservative.general} relaxes $\testStatistics{i} \stackrel{d}{=} \ncTestStatistics{j}$ and allows the null test statistics to be stochastically larger than those of internal negative controls.
% The relaxation is useful for testing one-sided hypotheses discussed in \Cref{sec:example.one.sided}.
% % such as in the motivating protein dataset.
The exchangeability
condition~\ref{vali:assu:one.exchangeable.general} is
satisfied when the transformed test statistics are i.i.d.\ or follow a
mixture of i.i.d.\ distributions.
\end{remark}

% Another exchangeability beyond
% independence is the factor model in \Cref{sec:example.factor.model},
% which describes the distributions of dependent observable variables
% influenced by a set of latent variables (factors).
% If the observed variables conditional on the latent factors are i.i.d., then the exchangeability condition is fulfilled.
% See \zg{TODO} for a specific example of the factor model.
% One example is the Gaussian mixture model, arguable the most widely-used probabilistic model describing a population consisting of several sub-populations and the sub-population to which an individual observation belongs is not known.




\subsection{\PRDS}\label{sec:PRDS}

Because the \nickname~p-values $\pval{i} =
\hat{F}(\testStatistics{i}),~i=1,\dotsc,\No$ are calculated using
the same empirical null distribution
$\hat{F}(\cdot)$, they are generally not
independent even if the test satistics
$\testStatistics{i},~i=1,\dotsc,\No$ are independent. However, it can
be shown that the \nickname~p-values may satisfy a desirable
\PRDS~property that is sufficient for the validity of many multiple
hypothesis testing procedures
\parencite{sarkar1997simes,benjamini2001control}.

% The \PRDS~property describes a type of positive dependence and
% includes the case where all random variables are mutually independent.
% The property is commonly used in the literature of multiple testing to
% control false discovery \cite{sarkar1997simes,
%   benjamini2001control}.
% The next Proposition describes
% sufficient conditions for the \nickname~p-values to be \PRDS.

\begin{theorem}\label{prop:PRDS}
% Let $\testStatistics{i}$ be the test statistic associated with a true null hypothesis.
Suppose one of the two sets of conditions holds:
\begin{enumerate}[label=\roman*., ref=(\roman*)]
  \item \label{PRDS:assu:independent}
    \begin{enumerate}[label = (\alph*),ref = (i.\alph*)]
    \item \label{PRDS:assu:null.nc.identical} $\testStatistics{i}
      \stackrel{d}{=} \testStatistics{j}$ for any $i \in
      \nullHypothesisIndex$ and $j \in \hypothesisIndex{\text{nc}}$;
    \item \label{PRDS:assu:all.nc.set.independent}
      $\left( \testStatistics{i}\right)_{i \in \hypothesisIndex{}}
      \independent \left( \testStatistics{j} \right)_{j \in \hypothesisIndex{\text{nc}}}$;
    \item \label{PRDS:assu:nc} $\left( \testStatistics{j}  \right)_{j
        \in \hypothesisIndex{\text{nc}}}$ is mutually independent;
    \item \label{PRDS:assu:PRDS} $\left( \testStatistics{i} \right)_{i
        \in \hypothesisIndex{}}$ is \PRDS~on $\left(
        \testStatistics{i}  \right)_{i \in
        \nullHypothesisIndex}$;
    \end{enumerate}
    \item \label{PRDS:assu:exchangeable} $\left( \testStatistics{i}
      \right)_{i \in \hypothesisIndex{} \cup
        \hypothesisIndex{\text{nc}}}$ is exchangeable on $\left( \testStatistics{i}
      \right)_{i \in \hypothesisIndex{0} \cup
        \hypothesisIndex{\text{nc}}}$.
\end{enumerate}
Then the \nickname~p-values are valid and $(\pval{i})_{i \in
  \hypothesisIndex{}}$ is \PRDS~on $(\pval{i})_{i \in
  \nullHypothesisIndex}$.
\end{theorem}

% In \Cref{sec:multiple.testing}, we discuss how the \PRDS~property enables combining \nickname~p-values with standard multiple testing procedures.

The validity directly follows from \Cref{prop:pvalue.validity}. Our
proof of the \PRDS~property is more involved and is based on
the following heuristic: if we swap any $T_i, i \in
\hypothesisIndex{0}$ with the next smallest negative control
statistic, the probability that $\bm p \in \mathcal{D}$ for any
increasing set $\mathcal{D}$ can only increase. See the Appendix for
more detail.

% Let's first assume the exchangeability
% condition~\ref{PRDS:assu:exchangeable} is satisfied.
% Consider any $i \in \hypothesisIndex{0}$. Suppose the rank of
% $\testStatistics{i}$ among
% $(\testStatistics{j})_{j \in \{i\} \cup \hypothesisIndex{\text{nc}}}$
% is $(k+1)$, so $p_i = (k+1)/(\NoNc + 1)$. We swap $\testStatistics{i}$
% with the next smallest value in this sequence (which is the $(k+1)$th
% smallest negative control statistic) and keep all other test
% statistics fixed. Let $\pval{1}',\dotsc,\pval{\No}'$ denote
% \nickname~p-values after the swap, so $\pval{i}' = (k+2)/(\NoNc +
% 1)$. By the exchangeability assumption in
% \ref{PRDS:assu:exchangeable}, this swap does not change the joint
% distribution of the test statistics. It is easy to see that this
% swap only increases the \nickname~p-values, that is $\pval{j}' \ge
% \pval{j}$ for all $j \in \hypothesisIndex{}$.
% Therefore, for any increasing set $\mathcal{D}$,
% \[
%   \PP\Big((\pval{i})_{i \in \hypothesisIndex{}} \in \mathcal{D},
%   \pval{i} = \frac{k+1}{\NoNc+1}\Big) \leq \PP\Big((\pval{i}')_{i
%     \in \hypothesisIndex{}} \in \mathcal{D}, \pval{i}' =
%   \frac{k+2}{\NoNc+1}\Big) = \PP\Big((\pval{i})_{i
%     \in \hypothesisIndex{}} \in \mathcal{D}, \pval{i} =
%   \frac{k+2}{\NoNc+1}\Big).
% \]
% Because $\pval{i}$ is uniformly distributed over
% $\{1/(\NoNc+1),2/(\NoNc+1),\dotsc,1\}$, this implies that
% \[
%   \PP\Big((\pval{i})_{i \in \hypothesisIndex{}} \in \mathcal{D} \,\Big|\,
%   \pval{i} = \frac{k+1}{\NoNc+1}\Big) \leq \PP\Big((\pval{i})_{i
%     \in \hypothesisIndex{}} \in \mathcal{D} \, \Big|\, \pval{i} =
%   \frac{k+2}{\NoNc+1}\Big).
% \]
% From here it is straightforward to verify the definition of PRDS.

% Now assume condition~\ref{PRDS:assu:independent} is satisfied. We
% cannot directly apply the above swapping argument because the test
% statistics may no longer be exchangeable.
% Without loss of generality, we assume that the statistics corresponding to
% the true nulls and negative controls follow $U[0,1]$; otherwise we can
% replace $T_i$ by $F_i(T_i)$ for all $i \in \hypothesisIndex{}$. Again,
% fix an $i \in \hypothesisIndex{0}$ and suppose $p_i =
% (k+1)/(\NoNc+1)$. Denote the $k$-th smallest value of the negative
% control statistics by $t_{(k)}$.
% If $t_{(k+2)} - t_{(k+1)} < t_{(k+1)} - t_{(k)}$, we can construct a
% twin set of internal negative controls by setting the $(k+1)$th
% smallest negative control to $t'_{(k+1)} = \left(t_{(k+2)} -
%   t_{(k+1)}\right) + t_{(k)} < t_{(k+1)}$. Since the negative
% control statistics are independent and uniformly distributed, the
% original and the twin
% configurations are equally likely to be observed.
% We use $\PP$ and $\PP'$ to denote the law of $(\testStatistics{i})_{i \in \hypothesisIndex{}}$ conditional on the internal negative controls in the original and twin configuration, respectively.
% By the \PRDS~property~\ref{PRDS:assu:PRDS} and the independence condition~\ref{PRDS:assu:all.nc.set.independent},
% % $\left( \testStatistics{i}\right)_{i \in \hypothesisIndex{}} \independent \left( \testStatistics{j} \right)_{j \in \hypothesisIndex{\text{nc}}}$,
%       for some increasing set $\calD$,
% $\PP\left(\calD, t_{(k)} < \testStatistics{i} < t'_{(k+1)}\right) \le \PP\left(\calD, t_{(k+1)} < \testStatistics{i} < t_{(k+2)}\right)$, $\PP'\left(\calD, t_{(k)} < \testStatistics{i} < t'_{(k+1)}\right) \le \PP'\left(\calD, t_{(k+1)}) < \testStatistics{i} < t_{(k+2)}\right)$. Further, because the internal negatives are element-wise smaller in the twin configuration, then $\PP\left(\calD, t'_{(k+1)} < \testStatistics{i} < t_{(k+1)}\right) \le  \PP'\left(\calD, t'_{(k+1)} < \testStatistics{i} < t_{(k+1)}\right)$. Finally, we have $\PP\left(\calD, t_{(k)} < \testStatistics{i} < t_{(k+1)}\right) + \PP'\left(\calD, t_{(k)} < \testStatistics{i} < t'_{(k+1)}\right) \le \PP\left(\calD, t_{(k+1)} < \testStatistics{i} < t_{(k+2)}\right) + \PP'\left(\calD, t'_{(k+1)} < \testStatistics{i} < t_{(k+2)}\right)$ by decomposing the probabilities into the sub-components above and employing the inequalities therein. The analysis for $t_{(k+2)} - t_{(k+1)} \ge t_{(k+1)} - t_{(k)}$ is similar.


% We discuss several attempts of weakening the conditions in \Cref{prop:PRDS}.
% Neither the first set of conditions nor the second condition can imply the other.
% On one hand, the test statistics under investigation in \Cref{exam:EMN.3} can be negatively correlated and do not satisfy the \PRDS~condition~\ref{PRDS:assu:PRDS}.
% The condition~\ref{PRDS:assu:PRDS} describes the dependencies among the test statistics under investigation,
% % and is new to \Cref{prop:PRDS} since \Cref{prop:pvalue.validity} only deals with a single test statistic.
% and is intuitively necessary for the \nickname~p-values to be \PRDS.
% In fact, let the number of internal negative control test statistics go to infinity, then $\hat{F}(\cdot)$ is approximately deterministic, strictly increasing, and we denote its inverse by $\hat{F}^{-1}(\cdot)$.
% If the \nickname~p-values $\pval{i} = \hat{F}(\testStatistics{i})$ are \PRDS~on $\{\pval{i}: \hypothesis{i} \in \nullHypothesisSet\}$, by the fact that the \PRDS~property is invariant by co-monotone transformations, the test statistics $\testStatistics{i} = \hat{F}^{-1}(\pval{i})$ should be \PRDS~on $\{\testStatistics{i} = \hat{F}^{-1}(\pval{i}): \hypothesis{i} \in \nullHypothesisSet\}$.
% % The second exchangeability condition~\ref{PRDS:assu:exchangeable} extends the condition~\ref{vali:assu:one.exchangeable.general} in \Cref{prop:pvalue.validity} to a set of test statistics under investigation.
% % The exchangeability condition is satisfied if the true null and internal negative control test statistics are a mixture of i.i.d. random variables independent of the non-null test statistics.

\begin{remark} \label{rem:bates-condition}
  \textcite[thm.\ 2]{bates21_testin_outlier_with_confor_p_values}
  stated and proved the PRDS property in \Cref{prop:PRDS} under the
  assumption that $\left(
    \testStatistics{i}  \right)_{i \in \hypothesisIndex{} \cup
    \hypothesisIndex{\text{nc}}}$ is mutually
  independent,\footnote{\textcite[thm.\
    2]{bates21_testin_outlier_with_confor_p_values} does make any
    assumption on non-null statistics. We believe this is most likely
    a typo; see \Cref{sec:bates-typo} in the Appendix.} which
  implies the partial/conditional exchangeability condition
  \ref{PRDS:assu:exchangeable}. The set of
  conditions in \ref{PRDS:assu:independent}, especially the PRDS condition
  \ref{PRDS:assu:PRDS} on the original test statistics, appears to be
  novel and may be quite useful when the test statistics are
  positively dependent.
\end{remark}

\begin{remark}
    To our knowledge, the conclusion of \Cref{prop:PRDS} does not
  directly follow from any existing results about positively dependent
  distributions. First, the PRDS property of $(\pval{i})_{i \in
  \hypothesisIndex{}}$ in the conclusion of \Cref{prop:PRDS} does not
immediately follow from condition~\ref{PRDS:assu:PRDS}---the same PRDS
property for $(\testStatistics{i})_{i \in \hypothesisIndex{}}$---by applying a
co-monotone transformation. This is because the transformation,
defined by the internal negative control statistics, is random. Second, it is tempting to treat
$(\testStatistics{i})_{i \in \hypothesisIndex{\text{nc}}}$ as latent
and apply sufficient conditions for \PRDS~in latent variable
models. However, existing results either assumes a single latent variable
\parencite{benjamini2001control}, considers only binary random
variables \parencite{holland1986conditional}, or requires the
\MTPTwo~property in \textcite{karlin1980classes} that is not implied
by the conditions in \Cref{prop:PRDS}.
% the exchangeability condition~\ref{PRDS:assu:exchangeable}.
\end{remark}

\begin{remark} \label{rem:ia-cannot-relax}
Condition~\ref{PRDS:assu:null.nc.identical} in
\Cref{prop:PRDS} cannot be relaxed to the
stochastic dominance
condition~\ref{vali:assu:null.nc.conservative.general} in
\Cref{prop:pvalue.validity}; see \Cref{sec:example.PRDS} for a
counter-example.
\end{remark}


\subsection{Multiple testing with
  \nickname~p-values}\label{sec:multiple.testing}

Given the conclusions in \Cref{prop:pvalue.validity,prop:PRDS}, we
briefly discuss the multiple testing procedures that can be
applied to \nickname~p-values.


\subsubsection{Testing an intersection null}\label{sec:global.null}

% We present various ways of combining \nickname~p-values for global null testing.
% We first discuss several combination procedures whose type I errors are controlled under the validity and \PRDS~property of the \nickname~p-values.
% We then turn to procedures where the assumptions of the global testing procedures are not fulfilled and illustrate how to simulate the null distribution.
% We also provide a discussion on the connection of global null testing with \nickname~p-values and rank-based tests.

We first consider Bonferroni's test and Simes' test of an intersection
null $\hypothesis{\calI} = \cap_{i=1}^n \hypothesis{i}$ at level
$\alpha$. Suppose each hypothesis $\hypothesis{i}$ is associated with
a valid p-value $\pval{i}$. Let $\pval{(1)} \leq \dotsb \leq
\pval{(n)}$ be the ordered p-values. Bonferroni's test rejects
$\hypothesis{\calI}$ if $\pval{(1)} \leq \alpha / n$ and controls the type I
error at $\alpha$ as long as the individual p-values are valid. Thus,
when applied to the \nickname~p-values, Bonferroni's test is valid if the
conditions in \Cref{prop:pvalue.validity} are satisfied for
all $i$.

Simes' test rejects
$\hypothesis{\calI}$ if $\pvalOrder{i} \le i  \alpha/\No$ for some $1 \le i \le n$
\cite{simes1986improved}. Obviously, Simes' test rejects
$\hypothesis{\calI}$ whenever Bonferroni's test rejects
$\hypothesis{\calI}$. Simes' test has been shown to be valid if the
p-values are PRD under $H$ \cite{sarkar1997simes}. This property and
\Cref{prop:PRDS} lead to the following result.
% The
% following proposition characterizes the conditions under which
% combining Simes' test with the \nickname~p-values controls the type I
% error.

\begin{proposition}\label{prop:simes}
Suppose $\cdfTestStatistics{i}(t) \le \cdfTestStatistics{j}(t)$ for
all $i \in \hypothesisIndex{0}$, $j \in \hypothesisIndex{\text{nc}}$,
and $t \in \RR$,
and one of the following sets of conditions holds,
\begin{enumerate}[label = \roman*.,ref = (\roman*)]
    \item \label{simes:assu:PRDS}
      \ref{PRDS:assu:all.nc.set.independent},
      \ref{PRDS:assu:nc}, and \ref{PRDS:assu:PRDS} in
      \Cref{prop:PRDS};
    \item \label{simes:assu:exchangeable} $\left( \cdfTestStatistics{i}(\testStatistics{i})
      \right)_{i \in \hypothesisIndex{0} \cup
        \hypothesisIndex{\text{nc}}}$ is exchangeable.
\end{enumerate}
Then Simes' test applied to the \nickname~p-values controls the type I error
for testing the intersection null $\hypothesis{\calI}$.
\end{proposition}

Apart from a relaxation of condition
\ref{PRDS:assu:null.nc.identical} in \Cref{prop:PRDS} to stochastic
dominance, the conditions in \Cref{prop:simes} are the same as those
in \Cref{prop:PRDS} (note that $\hypothesisIndex{} =
\hypothesisIndex{0}$ if $\hypothesis{}$ is true). We cannot
use \Cref{prop:PRDS} directly to prove
\Cref{prop:simes} (see \Cref{rem:ia-cannot-relax} above). However,
\Cref{prop:simes} suggests that the (infeasible) \nickname~p-values
$(\tilde{\pval{i}})_{i \in \hypothesisIndex{}}$, obtained
from test statistics $(\cdfTestStatistics{i}(\testStatistics{i}))_{i \in
    \hypothesisIndex{}}$ and internal negative control statistics
  $(\cdfTestStatistics{i}(\testStatistics{i}))_{i \in
    \hypothesisIndex{\text{nc}}}$, are PRD under $H$. So Simes' test
  applied to $(\tilde{\pval{i}})_{i \in
    \hypothesisIndex{}}$ controls the type I error. Under the
  assumptions in \Cref{prop:simes}, we have $\pval{i} \geq
  \tilde{\pval{i}}$ for all $i \in \hypothesisIndex{}$. Thus, if Simes'
  test applied to $(\pval{i})_{i \in \hypothesisIndex{}}$ rejects $H$,
  it must also reject $H$ when applied to $(\tilde{\pval{i}})_{i \in
    \hypothesisIndex{}}$. The conclusion in \Cref{prop:simes}
  immediately follows.

There are many other global tests besides Bonferroni's correction and Simes'
test; a prominent example is Fisher's combination test that requires
independent p-values \cite{fisher1925statistical}. When applied to
\nickname~p-values, however, such methods may not always control the
type I error; in the case of Fisher's test, see
\Cref{sec:example.fisher} for a counter-example and
\textcite[sec.\ 2.1]{bates21_testin_outlier_with_confor_p_values} for
a theoretical characterization of this negative result.
Nevertheless, by assuming the exchangeability in
\eqref{eq:basic-exchangeable}, the distribution of any test statistic
under the global null
can be obtained by using permutations. \nickname~p-values come up
naturally in such permutation tests: \Cref{prop:permutation} in the
Appendix shows that all permutation tests that are invariant under
monotone transformations and certain permutations can be written as a
function of the \nickname~p-values.

\begin{remark}
It may be interesting to compare Simes' test applied to $(\pval{i})_{i
  \in \hypothesisIndex{}}$ with the permutation test applied to the
statistic $\min_{i \in \hypothesisIndex{}} \pval{(i)}/i$. As both
tests use the same test statistic and the permutation test is exact,
Simes' test can be viewed as a conservative approximation to the
permutation test with a simple rejection threshold. Numerical
simulations shows that this approximation
becomes more accurate when $\NoNc$ is much larger than
$\No$ (\Cref{fig:Simes.test}). Heuristically, this is because Simes' test is exact when the
p-values are independent, and the dependence of the \nickname~p-values
decreases as the number of negative controls increases.
\end{remark}


\begin{figure}[tbp]
    \centering
    \begin{subfigure}[b]{0.4\textwidth}
    \centering
\includegraphics[width  = \textwidth]{plot/simes-small-nc.pdf}
    \subcaption{$\No = 25$, $\NoNc = 25$}
    \end{subfigure} \quad
    \begin{subfigure}[b]{0.4\textwidth}
    \centering
\includegraphics[width  = \textwidth]{plot/simes-large-nc.pdf}
    \subcaption{$\No = 25$, $\NoNc = 500$}
    \end{subfigure}
    \caption{{Cumulative distribution functions of the permutation
          distribution of the Simes statistic $n \min_{i
  \in \hypothesisIndex{}} (\pval{(i)}/i)$ with different numbers of
internal negative controls ($\NoNc = 25$ and $\NoNc = 500$), estimated by $1000$ random permutations. Simes' test corresponds to assuming a uniform distribution.}}
    \label{fig:Simes.test}
\end{figure}


% The total number of possible permutations $(\No + \NoNc)!$ explodes for moderate $\No + \NoNc$.
% In practice, it is common to randomly permute the pooled data $B$ times, $B$ could be several thousand, and compute an approximate p-value as the fraction of the $B$ simulations where the test statistics are more extreme than the observed value on the unpermuted data.

% We display the quantile-quantile plots of the aggregated p-values produced by Fisher's method (\Cref{fig:fisher.test}) against the theoretical and empirical null distributions.
% The left panel shows that, under the global null, the aggregated p-values of combining Fisher's method and \nickname~p-values do not follow the theoretical null $\chi_{2 \No}^2$.
% ---the null distribution of Fisher's method provided with independent individual p-values.
% In particular, the spread of the aggregated p-values is significantly larger than that of $\chi_{2 \No}^2$, and
% using $\chi_{2 \No}^2$ to determine the rejection threshold fails to control the type I error.
% In contrast, the right panel shows that the null distribution is well approximated by the empirical null.
% Therefore, we can compare the aggregated p-value of Fisher's method combined with \nickname~p-values to a threshold determined by the simulated null distribution.

% In addition to Bonferroni's correction and Simes' test, several global null testing procedures require independent p-values, which are not satisfied by the \nickname~p-values.
% One popular approach is Fisher's method \cite{fisher1925statistical} which has significant power for small and distributed effects.
% Fisher's method takes in individual p-values $\pval{i}$ and aggregates by $-2 \sum_{i=1}^\No \log(\pval{i})$.
% Given independent individual p-values, the aggregated p-value has a chi-squared distribution with $2 \No$ degrees of freedom under the global null.
% Since the \nickname~p-values are dependent, the theoretical null does not apply to Fisher's method combined with the \nickname~p-values. A simulation example is displayed in \Cref{sec:simulation}, \Cref{fig:fisher.test}.




% \subsection{\nickname~p-values for permutation tests}\label{sec:ranc.for.permutation}

% We compare $\permutationFunction{\testStatistics{}, \ncTestStatistics{}}$ against those calculated at the permuted test statistics $\{\permutationFunction{\testStatistics{P}, \ncTestStatistics{P}}\}$ and reject the global null if $\permutationFunction{\testStatistics{}, \ncTestStatistics{}}$ appears extreme.
% according to the reference distribution.



\subsubsection{Testing individual hypotheses}\label{sec:individual.hypothesis}

We now review methods for testing the individual hypotheses
$\hypothesis{i}$, $i=1,\dotsc,\No$. Bonferroni's correction rejects
$\hypothesis{i}$ if $\pval{i} \leq \alpha / n$. Holm's step-down
procedure is obtained from closing Bonferroni's correction; it orders
the hypotheses by ranking p-values from small to large and % rejects
% $\hypothesis{i}$ if $\pval{i} < \pval{(i^{*})}$ where $i^{*}$ is the smallest
% number $j$ such that $\pval{(j)} > \alpha/(\No - j + 1)$
keeps on rejecting hypotheses as long as $p_{(i)} \leq \alpha/(\No - i
+ 1)$.
\parencite{holm1979simple}. Both procedures only require that the p-values
are individually valid and thus, when applied to the
\nickname~p-values, control the \FWER~if the conditions in
\Cref{prop:pvalue.validity} are satisfied for all $i \in
\hypothesisIndex{0}$. This also applies to graph-based procedures such
as fixed sequence testing and the fallback procedure
\parencite{wiens03_fixed_sequen_bonfer_proced_testin_multip_endpoin,bretz2009graphical}.
Hochberg's procedure
\parencite{hochberg88_sharp_bonfer_proced_multip_tests_signif} and
Hommels' procedure
\parencite{hommel88_stagew_rejec_multip_test_proced} are based on
closing the Simes' test. When applied to \nickname~p-values, they
control the \FWER~under the conditions in \Cref{prop:simes}.

For \FDP~control,
% let $\pi \in (0,1)$ be a pre-specified parameter, and the goal is to develop a procedure such that the probability of the \FDP~exceeding the threshold $\pi$ is at most $\alpha$, i.e., $\PP(\FDP > \pi) \le \alpha$.
\textcite{lehmann2005generalizations} proposed a step-down procedure
that keeps on rejecting hypotheses as long as $p_{(i)} \leq (\lfloor
q i \rfloor + 1)\alpha/(\No + \lfloor q i \rfloor + 1 - i)$. They
showed that this procedure satisfies $\PP(\FDP > q) \leq \alpha$ if
the so-called Simes' inequality is satisfied \parencite[thm.\
3.2]{lehmann2005generalizations}. Therefore, their procedure applied
to the \nickname~p-values is valid under the conditions in
\Cref{prop:simes}.

As mentioned above, \FWER~and \FDP~control are intimately related
to testing intersection nulls. Given valid tests of the intersection
nulls, \textcite{marcus1976closed} proposed a closed testing
procedure that rejects $H_i$ if all intersection nulls $\{H_{\calJ} =
\cap_{j \in \calJ} H_j: \calJ \ni i\}$ that logically imply $H_i$
are rejected. They showed that this procedure controls the
\FWER. \textcite{goeman2011multiple} extended this procedure to
simultaneously estimate the \FDP~among any subset of hypotheses
\parencite[see also][]{genovese2004stochastic,genovese06_exceed_contr_false_discov_propor}.
% ; specifically, they proposed to reject an
% intersection null $H_{\calI} =
% \cap_{i \in \calI} H_i$ if all intersection nulls
% $\{H_{\calJ}:\calJ \supseteq \calI\}$ that logically imply $H_{\calI}$
% are rejected by the original test.
\textcite{goeman2021only} showed that all methods that
control \FWER~or some tail probability of \FDP~can be written as or
uniformly improved by a closed testing procedure.
% More generally, the closed procedure \cite{marcus1976closed} is a generic tool for constructing \FWER~control method using global null testing procedures.
% This implies that, when designing methods, it is sufficient to restrict attention to closed testing regarding the statistical properties.
% Given a multiple testing procedure, its closed procedure .
% Provided with valid global null tests, the closure principle
% controls the \FWER~or \FDP~under all configurations of true and
% false hypotheses.
Because closed testing only requires validity of the tests for the
intersection nulls, in principle it can be applied with Simes' tests
using the \nickname~p-values when the conditions in \Cref{prop:simes} are
satisfied.

% under under the exchangeability condition~\ref{PRDS:assu:exchangeable}.

% As a corollary, closing the global testing procedures built upon
% \nickname~p-values in \Cref{sec:global.null} yields a family of
% \FWER~and \FDP~control methods.

% To develop \FDP~procedures combined with the \nickname~p-values, we can close the global testing procedures built upon \nickname~p-values in \Cref{sec:global.null}.


% The power of the closed procedures relies on the performance of the global null tests involved.
% If prior knowledge about the hypotheses is available, test statistics of the global null should be chosen to maximize the power towards the alternatives.
% For instance, if the non-nulls are dispersed and weak, Fisher's method of combining \nickname~p-values is more appropriate, while if the non-nulls are believed to be sparse and strong, then Simes' test should be preferred, especially when testing the intersection of a large set of hypotheses in the closed procedures.
% Weights can be incorporated to prioritize certain hypotheses as well.


% A challenge of the closed procedures is the computation complexity, which grows exponentially in the number of hypotheses.
% Various methods have been proposed to accelerate the procedure for certain global null tests. Graphical approaches~\cite{bretz2009graphical}, which are essentially closed weighted Bonferroni's corrections, can be computed in time $O(\No^3)$.
% Approximate linear time\footnote{Closing sum tests scale linearly, and closing Simes' tests scales $O(\No \log(\No))$.} algorithms of closing sum-tests or Simes' tests have been developed \cite{goeman2011multiple}.
% When permutation tests are used to approximate the null of Simes' and sum tests, \cite{vesely2021permutation, andreella2020permutation} develop efficient procedures that scale linearly regarding the number of permutations via the branch and bound technique.





% \FWER~stands for the probability of making any false discovery and is more appropriate when we are testing a limited number of hypotheses or a false discovery will bring about severe consequences.
% However, in the motivating protein dataset, there are thousands of proteins under investigation, and a false discovery is tolerable.
% For \FDR, the same proportion of false discoveries out of the total number of discoveries remains sensible as the number of total discoveries changes.
% Compared with the stringent \FWER-control methods, approaches controlling \FDR~often return a few false discoveries with many candidates of interest and are more helpful for downstream validation experiments.

For \FDR~control, the \BH~step-up procedure is
most widely used. Let $i$ be
the largest index
such that $\pvalOrder{i} \le i q/\No$; the \BH~procedure rejects
$\hypothesis{j}$ for all $j$ such that $\pval{j} \le \pvalOrder{i}$
\parencite{benjamini1995controlling}.
The \BH~procedure is proven to control the \FDR~at the nominal level
when the p-values are independent \cite{benjamini1995controlling} or
 \PRDS~on the set of true nulls \cite{ benjamini2001control}. This
 implies the following result.
% As a result, under the conditions in \Cref{prop:PRDS}, the \nickname~p-values are \PRDS~and combining the \BH~procedure with \nickname~p-values controls \FDR.
\begin{corollary}\label{coro:FDR}
Under any sets of conditions in \Cref{prop:PRDS}, the
\BH~procedure applied to the \nickname~p-values controls the \FDR.
\end{corollary}
% The proof of the first condition in \Cref{prop:FDR} follows from the \PRDS~property of the \nickname~p-values and that the \BH~procedure is valid under the \PRDS~property \cite{benjamini2001control}.

% The proof of the first condition in \Cref{prop:FDR} follows from the \PRDS~property of the \nickname~p-values and that the \BH~procedure is valid under the \PRDS~property \cite{benjamini2001control}.
% If any sets of the conditions in \Cref{prop:PRDS} is true, then the
% \BH~procedure combined with the \nickname~p-values in
% Eq.~\eqref{eq:pval} controls \FDR.

\begin{remark} \label{rem:emn}
  A concrete example of an exchangeable but non-i.i.d.\ sequence is the
  equicorrelated multivariate normal (EMN) model:
  \begin{equation}
    \label{eq:emn}
      \testStatistics{i} = \mu_i
+ \sqrt{\rho}Z + \sqrt{1-\rho}X_i,\quad {i \in \hypothesisIndex{} \cup
  \hypothesisIndex{\text{nc}}},
\end{equation}
where $Z$ and $X_i$ are
i.i.d.~standard normal variables and $0 \le \rho < 1$.
Jointly, the test statistics follow a multivariate normal distribution
with all pairwise correlations equal to $\rho$. Suppose $\mu_i = 0$
for all $i \in \nullHypothesisIndex \cup \hypothesisIndex{\text{nc}}$, then
$(\testStatistics{i})_{i \in \nullHypothesisIndex \cup
  \hypothesisIndex{\text{nc}}}$ is exchangeable but not
independent. It is straightforward to verify that the exchangeability
conditions in
\Cref{prop:pvalue.validity}\ref{vali:assu:one.exchangeable.general},
\Cref{prop:PRDS}\ref{PRDS:assu:exchangeable}, and
\Cref{prop:simes}\ref{simes:assu:exchangeable} are all satisfied.
A simulated example from the EMN model is given in \Cref{sec:simulation}.
\end{remark}


\section{The empirical process
  perspective}\label{sec:empirical.process}

An unsatisfactory aspect of \Cref{coro:FDR} is that it requires
the marginal distribution of the test statistic to be the same for all
true null hypotheses and negative controls. In this section, we
develop an alternative justification of this \BH~procedure that
relaxes this assumption. Our argument is based on using
negative controls to form a nonparametric estimator of the false
discovery rate, and is closely related to the empirical process
perspective in \textcite{storey2004strong,genovese2004stochastic}. A
practical advantage of this approach is that one can increase the
power of the \BH~procedure by estimating the proportion of nulls
\parencite{storey2002direct}.

% $\FDP(t)$ is regarded as a stochastic process indexed by the p-value threshold $t$.
We first set up the notation to state our main result. Following
\textcite{storey2004strong,genovese2004stochastic}, we
view \FDP~as an empirical process indexed by the rejection
threshold. As the \nickname~p-values are invariant under a monotone
transformation of the original test statistics, without loss of
generality, we assume $\testStatistics{i} \in [0,1]$ for all $i$. The
empirical processes for false rejections ($\falsePositive$ in
\Cref{tab:outcome}), all rejections ($\totalPositive$ in
\Cref{tab:outcome}), and the \FDP~are defined as
\begin{align*}
    \falsePositive(t) &:= \sum_{i \in \nullHypothesisIndex}
                        \1_{\{\testStatistics{i} \le t\}}, \quad
    % \truePositive(t) &= \left|\testStatistics{i} \in \nonNullHypothesisSet: \testStatistics{i} \le t \right|, \\
    \totalPositive(t) :=
    % V(t) + S(t) =
    \sum_{i \in \hypothesisIndex{}} \1_{\{ \testStatistics{i} \le
t\}}, \quad
    \text{and} \quad
    \FDP(t) := \frac{V(t)}{R(t) \vee 1},\quad 0 \leq t \leq 1.
\end{align*}
For fixed $t$, let the expectation of $\FDP(t)$ be $\FDR(t) =
\EE\left[\FDP(t)\right]$. A multiple testing method such as the
\BH~procedure selects a data-dependent rejection threshold $\tau$, and
we are interested in controlling $\FDR = \EE[\FDP(\tau)]$ at level $q$. This
may be achieved by directly estimating $\FDR(t)$ and stopping the
procedure when the estimated \FDR~is above $q$. This typically
involves estimating the
number of false positives $\falsePositive(t)$. For example, in the
usual setting that the test statistics are p-values and follow $U[0,1]$ under the
null, we may estimate
$\falsePositive(t)$ conservatively by $nt$, the expectation of
$\falsePositive(t)$ when $\nullHypothesisIndex = \hypothesisIndex{}$.

Compared to previous work
\parencite{storey2004strong,genovese2004stochastic}, a key
differerence in our problem is that the null distribution of the test
statistics is unknown and must be estimated from the negative
controls. To this end, let the empirical process for the negative
control rejections and its normalization be,
respectively,
\[
  V_{\text{nc}}(t) := \sum_{j \in \hypothesisIndex{\text{nc}}}
  \1_{\{\testStatistics{j} \le t \}},\quad \bar{V}_{\text{nc}}(t) :=
  \frac{n(V_{\text{nc}}(t)+2)}{\NoNc+1}, \quad
  0 \leq t \leq 1.
\]
We propose to estimate $\FDR(t)$ by
\begin{align}\label{eq:FDR.estimate}
    \widehat{\FDR}_{\lambda}(t)
    := \frac{\hat{\pi}(\lambda) \cdot
  \bar{V}_{\text{nc}}(t)}{R(t) \vee 1},\quad \text{for some}~0 <
  \lambda \leq 1,
\end{align}
where $\hat{\pi}(\lambda)$ is the following estimator of
the proportion of true nulls $|\nullHypothesisIndex|/|\hypothesisIndex{}|$:
\begin{align}\label{defi:eq:prop.null}
  \hat{\pi}(\lambda) =
  \begin{dcases}
    1, & \text{if}~\lambda = 1, \\
  \frac{\No + 1 - \totalPositive(\lambda)}{\No} \cdot \frac{\NoNc +
    1}{\NoNc -  \ncFalsePositive(\lambda)},& \text{if}~0 < \lambda <
                                             1. \\
  \end{dcases}
\end{align}
Equation \eqref{defi:eq:prop.null} is modified from \textcite[eq.\
(6)]{storey2004strong}.
It can be shown that $\widehat{\FDR}_{\lambda}(t)$ is a conservative
(i.e.\ downward biased) estimator of $\FDR(t)$ when $\lambda = 1$; see
\Cref{prop:FDR.estimate} in the Appendix.
 Finally, let the rejection threshold be
\begin{align*}
    \stoppingTime = \sup\left\{0 \le t \le \lambda:
  \widehat{\FDR}_{\lambda}(t) \le q \right\},
\end{align*}
so a hypothesis $\hypothesis{i},~i\in\hypothesisIndex{}$ is rejected
if $\testStatistics{i} \leq \stoppingTime$.

The next proposition relates this rejection threshold with the
\BH~procedure applied to the \nickname~p-values.
\begin{proposition}\label{prop:FDR.equivalence}
A hypothesis $\hypothesis{i},~i\in\hypothesisIndex{}$ is rejected by
the above procedure when $\lambda = 1$ if and only if it is rejected
by the \BH~procedure with the following modified \nickname~p-values:
\[
   \tilde{\pval{i}} = \frac{2 + \sum_{j \in \hypothesisIndex{\text{nc}}}
  \1_{\{\testStatistics{j} \le \testStatistics{i}\}}}{1 + \NoNc}
\wedge 1.
\]
\end{proposition}

\Cref{prop:FDR.equivalence} follows from the simple observation that
% its rank normalized by the total number of hypotheses under investigation $R(\testStatistics{i})/\No$,
\begin{align*}
    \widehat{\FDR}(\testStatistics{i}) \le q \quad \text{if and only
  if} \quad
    \tilde{\pval{i}} =
  \frac{2+V_{\text{nc}}(\testStatistics{i})}{1+\NoNc} \wedge 1 \le
  \frac{R(\testStatistics{i})}{\No} q.
\end{align*}
Compared to the original \nickname~p-value $p_i$ defined in
\eqref{eq:pval}, an extra $1$ is added to the numerator of
$\tilde{\pval{i}}$. This subtle modification is needed because, unlike
the problem with a known null distribution studied by
\textcite{storey2004strong} and others, due to the
discreteness of $V_{\text{nc}}(t)$ (and hence
$\bar{V}_{\text{nc}}(t)$), it
is generally not true that $\widehat{\FDR}_{\lambda}(\stoppingTime)
\leq q$. Although this modification only makes a
minuscule difference in most practical problems, it is needed in the
super-martingale proof of the next Theorem.

The final piece we need to state the main theorem of this section is a
stronger notion of stochastic dominance \parencite{zhao2019multiple}.
\begin{definition}[Uniform stochastic dominance]\label{defi:uniform.dominance}
    For two random variables $X$, $Y$ supported on $[0,1]$, we say $X$
    is uniformly stochastically larger than $Y$ if $\PP(X \le t) > 0$,
    $\PP(Y \le t) > 0$, and $\PP(X \le s \mid X \le t) \le \PP(Y \le s
    \mid Y \le t)$ for all $0 < s \leq t \leq 1$.
\end{definition}
Heuristically, uniform stochastic dominance just means stochastic
dominance after conditioning on the variable is less than $t$ for all
$t$. It is satisfed if the distributions of $X$ and $Y$ are in a family
with monotone likelihood ratio; more examples and results can be found
in \textcite{whitt1980uniform,zhao2019multiple}.

\begin{theorem}\label{prop:FDR}
Suppose the following conditions are true:
\begin{enumerate}[label = (\alph*),ref = (\alph*)]
\item \label{FDR:assu:null.nc.uniformly.conservative}
  $\testStatistics{i}$ is uniformly stochastically larger than
  $\testStatistics{j}$ for all $i \in \nullHypothesisIndex$ and $j \in \hypothesisIndex{\text{nc}}$;
 \item \label{FDR:assu:independent}
 $(\testStatistics{i})_{i \in \hypothesisIndex{} \cup
   \hypothesisIndex{\text{nc}}}$ is mutually independent.
%  $\left\{\testStatistics{i}\right\}_{1 \le i \le \No} \independent \left\{\ncTestStatistics{j} \right\}_{1 \le j \le \NoNc}$ are independent,
% \item \label{FDR:assu:nc} $\left\{\ncTestStatistics{j} \right\}_{1 \le j \le \NoNc}$ are mutually independent;
% \item \label{FDR:assu:null} $\left\{\testStatistics{i}\right\}_{1 \le i \le \No}$ are mutually independent,
\end{enumerate}
Then for any fixed $0 < \lambda \leq 1$, the step-up procedure with
rejection threshold $\stoppingTime$
% or equivalently the \BH~procedure combined with the more conservative \nickname~p-values $\pval{i,2} := \frac{2 + \sum_{j=1}^{\NoNc} \1_{\{\ncPval{j} \le \pval{i}\}}}{1  + \NoNc} \wedge 1$
controls the \FDR~at level $q$.
\end{theorem}
% The proof of the second set of conditions is motivated by \cite{storey2004strong} and involves applying a backward super-martingale argument to the empirical processes of the number of false, internal negative control, and total discoveries.
% We remark that the super-martingale proof relies on a slightly more conservative \nickname~p-value because the empirical process of the internal negative control discoveries has discrete movements, or jumps.
% \zg{We do not exclude the possibility that the proof can be modified to work with \nickname~p-values.}
% However, according to numerical simulations, the \BH~procedure combined with the standard \nickname~p-value~\eqref{eq:pval} under the second set of conditions in \Cref{prop:FDR} appears to control \FDR~at the target level.

We provide a sketch proof of this result by modifying the martingale
argument in \cite{storey2004strong}; more details can be found in
\Cref{sec:results-empirical-process}.
We consider the time-reversals of $\falsePositive(t)$,
$\truePositive(t)$, and $\ncFalsePositive(t)$ starting from $t=1$
and define the backward filtrations as $\calF_t =
\sigma\big(\falsePositive(s), \truePositive(s), \ncFalsePositive(s): t
\le s \le 1\big)$ for $0 \leq t \leq 1$.
Our proof rests on showing the following process is a backward
super-martingale:
\begin{align}\label{eq:super.martingale}
    M(t) = \frac{\falsePositive(t)}{(1+\ncFalsePositive(t))/(1+\NoNc)}.
\end{align}
This extends the martingale $V(t)/t$ in \cite{storey2004strong} when
the null CDF is known to be $F_0(t) = t$.
% In \cite{storey2004strong}, the random process $V(t)/t$ (or more generally $V(t)/\cdfTestStatistics{i}$) is shown to be a martingale and used in the proof.
% We extend the random process by replacing the CDF of the true null estimates with an estimate of the internal negative control test statistics $(1+\ncFalsePositive(t))/(1+\NoNc)$.
More precisely, it is proved in the Appendix that
\begin{align} \label{eq:super-martingale}
    \EE\left[M(s) \mid \calF_t \right] \leq M(t)
    % \cdot {\frac{\cdfTestStatisticsNull{}(s)}{\cdfTestStatisticsNull{}(t)}}/{\frac{\ncCdfTestStatistics{}(s)}{\ncCdfTestStatistics{}(t)}}
    \cdot \left(1 - \left(1-p_t^s% \frac{\cdfTestStatistics{}(s)}{\cdfTestStatistics{}(t)}
  \right)^{\ncFalsePositive(t) + 1} \right)
    \le M(t)~\text{for some}~0 \leq p_{t}^s \leq 1 ~\text{and all}~0
  \leq s \leq t \leq 1.
\end{align}
\Cref{prop:FDR} then follows from applying the optional
stopping theorem.

\begin{remark} \label{rem:one-sided}
  Since \Cref{prop:FDR} does not require exchangeability of the test
  statistics, it can be applied to one-sided tests. Specifically,
  suppose $T_i$ is
  the likelihood-ratio statistic for testing $\hypothesis{0}: \theta_i
  \le \theta_0$ vs.\ $\hypothesis{1}: \theta_i > \theta_0$ in a
  one-dimensional exponential family with natural (or mean) parameter
  $\theta$ (and thus has a monotone likelihood ratio). We have
  $\theta_i \leq \theta_0$ for $i \in \hypothesisIndex{0}$ by
  definition. If $\theta_i \geq \theta_0$ for all $i \in
  \hypothesisIndex{\text{nc}}$, then
  condition \ref{FDR:assu:null.nc.uniformly.conservative} in
  \Cref{prop:FDR} is satisfied. This suggests another useful aspect of
  the stochastic dominance
  condition~\ref{FDR:assu:null.nc.uniformly.conservative}: the
  definition of ``negative controls'' can be relaxed and they do not need to
  be true null hypotheses. In other words, the \nickname~p-values are
  robust to incorrect selection of negative controls in the sense that
  the FDR may still be controlled at the nominal level. However, when
  too many negative controls are not true nulls, the multiple testing
  procedure may have very little power.

%   Consider independent $(\testStatistics{i})_{i \in \hypothesisIndex{} \cup \hypothesisIndex{\text{nc}}}$ testing the one-sided hypothesis of the natural parameter $\theta_i$ in a one-dimensional exponential family,  $\hypothesis{0}: \theta_i \le \theta_0$ V.S. $\hypothesis{1}: \theta_i > \theta_0$.
% % Let $\testStatistics{i}$, $\ncTestStatistics{j}$ be the uniformly most powerful test statistics of the candidate and the internal negative control hypotheses, respectively.
% If
% % the internal negative control test statistics
% $(\testStatistics{j})_{j \in \hypothesisIndex{\text{nc}}}$ is associated with the least favorable null $\theta_j = \theta_0$, then $(\testStatistics{j})_{j \in \hypothesisIndex{\text{nc}}}$ is uniformly stochastically dominated by  $(\testStatistics{i})_{i \in \nullHypothesisIndex}$ according to \cite{whitt1980uniform}.
% By \Cref{prop:pvalue.validity}, the associated $(\pval{i})_{i \in \nullHypothesisIndex}$ is valid.
% % In addition, since the location family of Gaussian distributions is a one-dimensional exponential family and thus has MLR, the true null and internal negative control test statistics of the one-sided testing problem satisfy the uniform stochastic dominance condition~\ref{FDR:assu:null.nc.uniformly.conservative}.
% By \Cref{prop:FDR}, we can apply the \BH~procedure to $(\pval{i})_{i \in \hypothesisIndex{}}$ with appropriate \FDR~control.
% The motivating proteomic data analysis in \Cref{sec:real.data} belongs to the one-sided hypothesis testing.
\end{remark}

\begin{remark}
  A similar martingale argument was developed by
  \textcite{mary22_semi_super_multip_testin} to prove that the
  \BH~procedure ($\lambda = 1$) applied to the \nickname~p-values
  controls the \FDR. A main distinction is that they
  require partial exchangeability of the test statistics (condition
  \ref{PRDS:assu:exchangeable} in \Cref{prop:PRDS}), which is weaker
  than the independence condition \ref{FDR:assu:independent} in
  \Cref{prop:FDR} but does not allow
  the case of uniformly stochastic
  dominance in condition
  \ref{FDR:assu:null.nc.uniformly.conservative}.\footnote{Although by
    using de Finetti's theorem, the
    independence condition \ref{FDR:assu:independent} in
    \Cref{prop:FDR} can be easily relaxed to (conditional)
    $\infty$-extendability \parencite{diaconis1980finite}.}
  The uniformly stochastic dominance
  condition~\ref{FDR:assu:null.nc.uniformly.conservative} arises
  naturally in our proof of the first inequality. It remains unclear to us whether this
  can be allowed in the proof in
  \textcite{mary22_semi_super_multip_testin}, as their martingale is
  not indexed by the rejection threshold. When the marginal
  distributions of the null test statistics and internal negative controls are the same,
  the gap $M(t) - \EE\left[M(s) \mid \calF_t \right] $ is small for large
  $\ncFalsePositive(t)$, so $M(t)$ is almost a martingale. This can be
  used to prove a lower bound on the \FDR; see
  \textcite[thm.\ 3.1]{mary22_semi_super_multip_testin}.
\end{remark}

% Next, we define a stopping time,
% \begin{align*}
% \stoppingTimeSecond := \sup\left\{s \ge 0: \frac{\No \frac{\ncFalsePositive(s) + 2}{\NoNc + 1}}{R(s) \vee 1} \le q \right\}.
% \end{align*}
% Compared to $\stoppingTime$, $\stoppingTimeSecond$ has a two rather than a one in the enumerator, and as a corollary $\stoppingTimeSecond \le \stoppingTime$.
% The modification is required to ensure $\widehat{\FDR}(\stoppingTimeSecond) \le q$, which is not necessarily true for $\stoppingTime$ due to the process $V_{\text{nc}}(t)$ having discrete movements (it is possible that $\lim_{t \uparrow \stoppingTime} \widehat{\FDR}(t) \le q < \widehat{\FDR}(\stoppingTime)$).
% Finally, applying the optional stopping theorem to the super-martingale $M(t)$ and the stopping time $\stoppingTimeSecond$ showcases the \FDR~control of the step-up procedure.


% % We discuss two immediate extensions of the step-up procedure with provable \FDR~control.
% The martingale argument is valid
% % First, since it is sufficient that $M(t)$ is a super-martingale,
% when the condition that the true null and internal negative control test statistics are identically distributed is relaxed to the uniformly stochastic dominance below, a stronger notion of stochastic dominance.
% % We introduce the conditions under which the \BH~procedure applied to the \nickname~p-values controls \FDR~at the desired level.
% \begin{definition}[Uniformly stochastic dominance]\label{defi:uniform.dominance}
%     For two random variables $X_1$, $X_2$ supported on $[0,1]$, we call $X_1$ to be uniformly stochastically larger than $X_2$ if for any $0 < x_1 < x_2 < 1$, $\PP(X_1 \le x_2) > 0$, $\PP(X_2 \le x_2) > 0$, and
%     $\PP(X_1 \le x_1 \mid X_1 \le x_2) \le \PP(X_2 \le x_1 \mid X_2 \le x_2)$.
% \end{definition}
% \noindent The uniform stochastic dominance means that a random variable is stochastically smaller after conditioning, and is related to the more general concept of uniform conditional stochastic order (UCSO) in \cite{whitt1980uniform}.
% Recall the counter example of \PRDS: the internal negative control test statistics following $\text{Beta}(1,2)$ are uniformly dominated by the true null test statistics following $U[0,1]$, but the \nickname~p-values are not \PRDS.
% The super-martingale proof shows the \BH~procedure combined with such non-\PRDS~\nickname~p-values\footnote{The super-martingale proof adopts the slightly modified p-value $\pval{i,2} := \frac{2 + \sum_{j \in \hypothesisIndex{\text{nc}}} \1_{\{\testStatistics{j} \le \testStatistics{i}\}}}{1  + \NoNc} \wedge 1$.} still controls \FDR.


% We can further increase the power of the \BH~procedure by including an estimator of the proportion of true null hypotheses $\probNull$ as in \cite{storey2004strong},
% \begin{align}\label{defi:eq:prop.null}
%     \hat{\pi}(\lambda) = \frac{\No + 1 - \totalPositive(\lambda)}{\No} \cdot \frac{\NoNc + 1}{\NoNc -  \ncFalsePositive(\lambda)}, \quad 0 < \lambda < 1.
% \end{align}
% % where $\ncFalsePositive(\lambda)$ denotes the number of rejected internal negative control hypotheses at threshold $\lambda$.
% The motivation of the estimator~\eqref{defi:eq:prop.null} is the following.
% Suppose the internal negative control and true null test statistics are identically distributed, then $(\NoNc -  \ncFalsePositive(\lambda))/(\NoNc + 1)$ should be approximately $1 - \cdfTestStatistics{}(\lambda)$.
% In addition, we should expect the number of true null test statistics lying in $(\lambda, 1]$ satisfies $\No \probNull (\NoNc -  \ncFalsePositive(\lambda))/(\NoNc + 1) \approx \No \probNull (1 - \cdfTestStatistics{}(\lambda))  \le \No - \totalPositive(\lambda)$, which yields Eq.~\eqref{defi:eq:prop.null}.
% With $\hat{\pi}(\lambda)$, the estimator of the $\FDR(t)$ is extended to $\widehat{\FDR}^\lambda(t)
% = \hat{\pi}(\lambda) \cdot \widehat{\FDR}(t)$ for $0 \le t \le \lambda$ and $1$ otherwise.
% The updated rejection threshold takes the form
% \begin{align*}
%     \stoppingTimeSecondLambda = \sup\left\{0 \le 0 \le \lambda: \frac{\hat{\pi}(\lambda) \No \frac{\ncFalsePositive(s) + 2}{\NoNc+1}}{R(s) \vee 1} \le q \right\}.
% \end{align*}
% % The validity of the modified \BH~procedure can be shown by a modified super-martingale argument.
% % Details are deferred to the Appendix.


% % We also introduce a more conservative version of the \nickname~p-value in Eq.~\eqref{eq:pval}.
% % \begin{align}\label{defi:eq:pval.2}
% %     \pval{i}'
% %     := \frac{2 + \sum_{j=1}^{\NoNc} \1_{\{\ncPval{j} \le \pval{i}\}}}{1  + \NoNc} \wedge 1.
% % \end{align}
% % Notice that $\pval{i}' \ge \pval{i}$, therefore \Cref{prop:pvalue.validity} applies to the more conservative \nickname~p-value.


% To conclude the section, we summarize the results of the \FDR~control using the super-martingale argument in the following proposition in complement to \Cref{coro:FDR}.
% We defer the proof to the Appendix.



% In particular, we have seen a counter example~\eqref{eq:stochastic.dominance.counter.example} in the discussion of \Cref{prop:PRDS} where the test statistics satisfy the second set of conditions in \Cref{prop:FDR} but do not enjoy the \PRDS~property.
% As discussed in \cite{zhao2019multiple}, the uniform stochastic dominance condition~\ref{FDR:assu:null.nc.uniformly.conservative} holds if the true null and internal negative control test statistics come from a one-sided test in a family of distributions with monotone likelihood ratios (MLR), which includes any one-dimensional exponential family and the location family of
% folded normal distribution.
% (2) the true null hypotheses are more favorable than those of the internal negative controls.
% For example, consider $Y \sim \calN(\mu, 1)$ and the one-sided hypothesis $\hypothesis{0}: \mu \le 0$, $\hypothesis{1}: \mu > 0$. If the true location parameter of the internal negative control observation is smaller than that of the true null, i.e., $\mu_{\text{nc}} \le \mu_{0}$, then the true null statistics from testing the one-sided hypothesis is uniformly more conservative.





% Let $r_{(i)} = R_{(i)} - i$, then
% \begin{align*}
%     \frac{1+r_{(i)}}{1+\NoNc} >\frac{i\alpha}{\No}
%     &\Leftrightarrow
%     r_{(i)} > \frac{i\alpha}{\No} (1+\NoNc) - 1 \\
%     &\Leftrightarrow
%     r_{(i)} + i - \frac{i\alpha}{\No}(\NoNc + \No) > \frac{i\alpha}{\No} (1+\NoNc) - 1 + i - \frac{i\alpha}{\No}(\NoNc + \No)  \\
%     &\Leftrightarrow
%     r_{(i)} + i - \frac{i\alpha}{\No}(\NoNc + \No)
%     > i \left(1 - \left(1 - \frac{1}{\No}\right)\alpha - \frac{1}{i}\right).
% \end{align*}
% If $\alpha \le (i-1)/i$, then
% \begin{align*}
%     1 - \left(1 - \frac{1}{\No}\right)\alpha - \frac{1}{i}
%     \ge 1 - \frac{i-1}{i} - \frac{1}{i}
%     = 0.
% \end{align*}
% Therefore, for $i \ge 2$, $\alpha \le 0.5$,
% \begin{align*}
%     \frac{1+r_{(i)}}{1+\NoNc} >\frac{i\alpha}{\No}
%     \implies
%     \frac{R_{(i)}}{\No+\NoNc} >\frac{i\alpha}{\No}.
% \end{align*}
% Define the event $\calA := \left\{\frac{R_{(1)}}{\No+\NoNc} >\frac{\alpha}{\No}\right\}$, and let $\calR_R(\alpha)$, $\calR_r(\alpha)$ be the rejection regions of Simes' test combined with the two types of p-values at the confidence level $\alpha$, then on $\calA$,
% \begin{align*}
%     \calR_R(\alpha) \subseteq \calR_r(\alpha)
% \end{align*}
% As a result, if $\frac{R_{(1)}}{\No+\NoNc} >\frac{1\alpha}{\No}$, then Simes' test with $ \frac{R_{(i)}}{\No+\NoNc}$ rejects the global null implies the the Simes' test with  $\frac{1+r_{(i)}}{1+\NoNc}$ also rejects the null.

% We compare the \nickname~p-value with an alternative rank-based p-value
% \begin{align}\label{eq:pval.full.rank}
%     \pval{\text{F},i}
%         := \frac{\sum_{j \in \hypothesisSet_{s} \subseteq \hypothesisSet } \1_{\{ \testStatistics{j} \le \testStatistics{i}\}} + \sum_{j=1}^{\NoNc} \1_{\{\ncTestStatistics{j} \le \testStatistics{i}\}}}{|\hypothesisSet_{s}| + \NoNc}, \quad i \in \hypothesisSet_{s}.
% \end{align}
% The alternative p-value~\eqref{eq:pval.full.rank} estimates the null distribution of $\testStatistics{i}$ by the empirical distribution of $\{\testStatistics{j}\}_{j \in \hypothesisSet_{s}} \cup \{\ncTestStatistics{j}\}_{1 \le j \le \NoNc}$.
% If $\hypothesisSet_{s} = \{\testStatistics{i}\}$, then $\pval{i}$ and $\pval{\text{F},i}$ are equivalent;
% if $\hypothesisSet_{s}$ contains multiple test statistics, $\pval{i}$ and $\pval{\text{F},i}$ are different.
% % The alternative p-value $\pval{\text{F},i}$ is problematic if $\hypothesisSet_{s}$ contains non-null hypotheses.
% There are two advantages of $\pval{i}$ over $\pval{\text{F},i}$: (1) the validity of $\pval{i}$ does not require assumptions on the stochastic dominance between null and non-null test statistics, while the alternative $\pval{\text{F},i}$ is valid only if non-null test statistics are stochastically smaller; (2) $\pval{i}$ combined with multiple testing procedures are generally more powerful, especially when there are several false hypotheses in $\hypothesisSet_s$. Consider the example where all non-null test statistics are significantly smaller than the nulls and internal negative controls, then the maximal non-null $\pval{i}$ is $1/(1+\NoNc)$, typically smaller than that of $\pval{\text{F},i}$ which is $|\hypothesisSet_s \cap \nonNullHypothesisSet|/(|\hypothesisSet_s| + \NoNc)$ if $|\hypothesisSet_s \cap \nonNullHypothesisSet| \ge 2$.






% We remark that for specific global null test statistics, including those from Bonferroni's correction and Simes' test, we obtain rejection thresholds that are proven to protect the type I errors. When such global null test statistics are of interest, our theoretical thresholds can be employed to completely eschew the computation burden of generating permutations.

% \begin{remark} \label{rem:inf-extendable}
%  Condition~\ref{FDR:assu:independent} in \Cref{prop:FDR} can be
%  relaxed to $\infty$-extendability \parencite{diaconis1980finite} in
%  the sense that conditional
%  on $(\testStatistics{i})_{i \in \hypothesisIndex{1}}$, the random
%  vector $(\cdfTestStatistics{i}(\testStatistics{i}))_{i \in
%    \nullHypothesisIndex \cup \hypothesisIndex{\text{nc}}}$ has the
%  same distribution as the first $\No_0 + \NoNc$ elements of an
%  infinite sequence of exchangeable variables. To see this, de
%  Finetti's theorem says that  the joint distribution of an
%  infinite sequence of exchangeable variables is always a mixture of
%  distributions of i.i.d.\ random variables.
%  Consequently, conditional on the prior parameter that indexes this
%  mixture distribution,
%  $(\testStatistics{i})_{i \in \nullHypothesisIndex \cup
%    \hypothesisIndex{\text{nc}}}$ is mutually independent, from where
%  the proof of \Cref{prop:FDR} can then apply.
% \end{remark}

\section{\LocalFDR~control}\label{sec:localFDR}

We now turn to our third method motivated by the ad hoc procedure in
\textcite{hung14_proteom_mappin_human_mitoc_inter}. We will consider
the two-mixture setup for multiple testing in
\Cref{sec:setup-terminology}. More specifically, we will assume for
the rest of this section that $(\hypothesis{i},
\testStatistics{i}),~i=1,\dotsc,\No$ are i.i.d., $\hypothesis{i} \sim
\text{Bernoulli}(1 - \pi)$, and $\testStatistics{i} \mid
\hypothesis{i} \sim \cdfTestStatistics{\hypothesis{i}}$, so the
marginal CDF of $T_i,~i \in \hypothesisIndex{}$ is given by $F(t) =
\pi F_0(t) + (1 - \pi) F_1(t)$. To simplify
the discussion, we will assume the null proportion $\probNull$ is
known. In practice, $\probNull$ is generally unknown and a wealth of
estimators of $\probNull$ have been proposed in the literature
\cite{schweder1982plots, hochberg1990more, hengartner1995finite,
  swanepoel1999limiting, benjamini2000adaptive, storey2002direct,
  jin2007estimating}; see \cite{genovese2004stochastic} for a review
of their asymptotic properties.

\subsection{\pdfBased\ methods}
\label{sec:pdfbased-methods}

Currently, most
practical applications estimate the $\localFDR$ by plugging in
estimators of $\pdfTestStatistics{}$ (and $\pdfTestStatisticsNull$ if it
is unknown) into the definition of \localFDR~in \eqref{eq:local-fdr};
we will call such methods \pdfBased, to contrast with our proposal below
that is \cdfBased. A major limitation of the \pdfBased~approach is
that the estimated densities may be very inaccurate at the tail where
the rejection threshold is likely to be located. This is worsened by
the fact that the marginal density $f(t)$ appears in the denominator
of the definition of $\localFDR(t)$.
Another problem is that \pdfBased~estimators of the $\localFDR$ are
generally not invariant to, monotone transformation of the test
statistics, but the definition of $\localFDR$ is. Thus, very different
rejection sets may be obtained if the investigator chooses to use
different transformations of the test statistics.

We illustrate the performance of \pdfBased~methods with a simple
simulation example.  We generate $\No =
400$ test statistics with $\probNull = 0.5$, $\cdfTestStatisticsNull =
t_{10}$ (t-distribution with $10$ degrees of freedom), and
$\cdfTestStatisticsNonNull = \text{Exp}(1)$, and an
independent set of $\NoNc = 1000$ internal negative controls from
$\cdfTestStatisticsNull$. We assume $\probNull$ is known and set
$\level = 0.3$. \Cref{fig:pdfbased-1} shows that when a simple kernel
density estimator is used to estimate both $\cdfTestStatistics{}$ and
$\cdfTestStatisticsNull$, the estimated \localFDR\ is highly variable
at the left tail and the step-down rejection threshold (dashed
verticle line) is too conservative to be useful. Transforming the test
statistics to z-scores improves the performance of this
\pdfBased~method, but the rejection threshold is still too small
(\Cref{fig:pdfbased-1}).

\subsection{\cdfBased\ methods}
\label{sec:cdfbased-methods}

Next, we relate the \cdfBased\ cut-off analysis in
\textcite{hung14_proteom_mappin_human_mitoc_inter} to
\localFDR~control. To this end, consider the following optimization
problem for some given $\lambda = q / \probNull$ and $0 < q < 1$:
\begin{align}\label{eq:Bayes.risk.2}
 \EmpiricalThreshold := \argmin_{\threshold}
 \EmpiricalCdfTestStatisticsNull(\threshold) - \lambda
 \EmpiricalCdfTestStatistics(\threshold),
    % + C(\weightNull, \weightNonNull, \pi),
\end{align}
where the objective function is a weighted difference between the empirical CDFs
of the negative controls and test statistics:
\[
  \EmpiricalCdfTestStatisticsNull(t) = \frac{1}{\NoNc} \sum_{j \in
    \hypothesisIndex{\text{nc}}}  \1_{\{\testStatistics{j} \le t\}},~
  \EmpiricalCdfTestStatistics(t) = \frac{1}{\No} \sum_{i \in
    \hypothesisIndex{}}  \1_{\{\testStatistics{i} \le t\}}.
\]
Thus, the procedure in
\textcite{hung14_proteom_mappin_human_mitoc_inter} (see
\Cref{fig:lfdr}) corresponds to using $\lambda=1$ or equivalently $q =
\pi$. In a moment, it will be clear that $q$ can be understood as the
\localFDR~level targeted by using the rejection threshold
$\EmpiricalThreshold$.

By the Glivenko-Cantelli theorem, $\EmpiricalCdfTestStatisticsNull$
and $\EmpiricalCdfTestStatistics$ converge uniformly
to $\cdfTestStatisticsNull{}$ and $\cdfTestStatistics{}$,
respectively. Thus, we expect $\EmpiricalThreshold$ to converge to the
minimizer
\begin{equation}
  \label{eq:optimal-threshold}
  \tau_{\lambda}^{*} := \argmin_\threshold
  \cdfTestStatisticsNull(\threshold) - \lambda
  \cdfTestStatistics{}(\threshold).
\end{equation}
By setting the derivative of Eq.~\eqref{eq:optimal-threshold} to zero, we
obtain $\pdfTestStatisticsNull(\tau_{\lambda}^{*}) = (q / \probNull)
\pdfTestStatistics{}(\tau_{\lambda}^{*})$, or equivalently,
\[
  \localFDR(\tau_{\lambda}^{*}) = \frac{\pi
    \pdfTestStatisticsNull(\tau_{\lambda}^{*})}{\pdfTestStatistics{}(\tau_{\lambda}^{*})}
  = q,
\]
where $\pdfTestStatisticsNull{}$ and $\pdfTestStatistics{}$ are the
density functions corresponding to $\cdfTestStatisticsNull{}$
and $\cdfTestStatistics{}$.
As mentioned above, the procedure in
\textcite{hung14_proteom_mappin_human_mitoc_inter} corresponds to
using $\lambda = 1$, or equivalent $q = \pi$. Intuitively, this is a
sensible choice because $\pi$ is simply the probability of making a
false discovery by rejecting a random hypothesis.
% see \Cref{sec:real.data:mouse} for more detail.
% The \cdfBased~approach with internal negative controls exhibits
% several appealing features.

% \begin{definition}[MLR]\label{defi:MLR}
% Let $\pdfTestStatistics{1}$, $\pdfTestStatistics{2}$ be two PDFs supported on $\calT$.
% We call $\pdfTestStatistics{1}$, $\pdfTestStatistics{2}$ satisfy the (strong) monotone likelihood ratio property if the ratio $\pdfTestStatistics{1}/\pdfTestStatistics{2}$ is (strictly) monotone on $\calT$.
% % If for $\threshold \in \calT$, $\pdfTestStatistics{1}$, $\pdfTestStatistics{2}$ are differentiable at $\threshold$ and $\pdfTestStatistics{2}(\threshold) \neq 0$, then we say $\pdfTestStatistics{1}$, $\pdfTestStatistics{2}$ are strictly MLR at $\threshold$ if the derivative of the ratio evaluated at $\threshold$ is positive $(\pdfTestStatistics{1}/\pdfTestStatistics{2})'(\threshold) > 0$.
% \end{definition}
% \begin{remark}\label{rmk:probNull}
    % One simple estimator is $\min_\threshold \hat{\pdfTestStatistics{}}(\threshold)/{\pdfTestStatisticsNull}(\threshold)$ where $\hat{\pdfTestStatistics{}}$ denotes the kernel density estimator. If $\pdfTestStatistics{}$ is Lipschitz, the estimator converges at rate $O(\log^{1/2}(\No)/\No^{1/3})$.
    % An alternative estimator, $(\EmpiricalCdfTestStatistics(\threshold_0) - \cdfTestStatisticsNull(\threshold_0))/(1-\cdfTestStatisticsNull(\threshold_0))$ for a pre-specified $\threshold_0$, converges at a faster rate $O(\No^{-1/2})$ but may be inconsistent with positive bias.
    % In our procedures, the adoption of an upward biased estimator of $\probNull$ will result in a more conservative rejection threshold.
    % When the proportion of nulls are not identified \cite{genovese2004stochastic}, we resort to an upper bound of $\probNull$.
    % Since the weight associated with false negatives in the risk~\eqref{eq:Bayes.risk.2} decreases with regard to $\probNull$, the estimator with $\hat{\lambda} = {q}/{\EmpiricalProbNull}$ is more conservative towards false positives if $\EmpiricalProbNull > \probNull$.
    % in the sense that $\localFDR(\EmpiricalThreshold) \le \threshold$.
    % More rigorously, suppose $\EmpiricalProbNull \to \probNull' \ge \probNull$, then as the sample sizes $\No$, $\NoNc$ go to infinity, $\localFDR(\EmpiricalThreshold) \to \level \probNull/\probNull' \le \level$.
    % Another option of $\level$ is to use a multiple of the true proportion of null, expressed as $q = c \probNull$ for some $c \in [0,1]$.
    % In the cut-off analysis in \Cref{sec:cutoff}, the \localFDR~level is set to $q = \probNull$.
    % For this type of $\level$, $\lambda = q /\probNull = c$, and no estimator of $\probNull$ is called for.
    % In theory, we cover the case...
% \end{remark}


% \subsection{PDF-based method}\label{sec:localFDR.PDF}


\begin{figure}[tbp]
        \centering
        \begin{minipage}{0.3\textwidth}
                \centering
                \includegraphics[clip, trim = 0cm 0cm 0cm 0cm, width = \textwidth]{plot/pdfHeavytailedNc.pdf}
                \subcaption{\pdfBased}
                \label{fig:pdfbased-1}
        \end{minipage}
    \begin{minipage}{0.3\textwidth}
                \centering
                \includegraphics[clip, trim = 0cm 0cm 0cm 0cm, width = \textwidth]{plot/pdfHeavytailedTransformedNc.pdf}
                \subcaption{\pdfBased, transformed $\testStatistics{i}$}
                \label{fig:pdfbased-2}
        \end{minipage}
        \begin{minipage}{0.3\textwidth}
                \centering
                \includegraphics[clip, trim = 0cm 0cm 0cm 0cm, width = \textwidth]{plot/cdfHeavytailedNc.pdf}
                \subcaption{\cdfBased}
                \label{fig:cdfBased}
        \end{minipage}
        \caption{Comparison of \cdfBased~and \pdfBased~methods where
          $\No = 400$, $\NoNc = 1000$, $\pi = 0.5$, $F_0 = t_{10}$,
          $F_1 = \text{Exp}(1)$, and $q = 0.3$.
        Panel (a)
        shows the result of a \pdfBased~method, where the null density
        and the marginal density are estimated by a kernel estimator (R
        function \texttt{density} with default options). In panel (b),
        we apply the \pdfBased~method to the transformed test
        statistics
        $\Phi^{-1}(\cdfTestStatisticsNull(\testStatistics{i}))$, where
        the null distribution of the transformed test statistics is
        $\calN(0,1)$. In panel (c), we showcase the proposed
        \cdfBased~method \eqref{eq:Bayes.risk.2}. We plot the weighted
        type I error
        $(1-\level)\cdfTestStatisticsNull(\threshold)$ (dark red), the
        weighted type II error $\level
        (1-\probNull)/\probNull(1-\cdfTestStatisticsNonNull(\threshold))$
        (dark green), and superimpose the population risk (blue)---the
        sum of the two weighted errors up to a constant shift, and the
        empirical objective (black). (The population and
        empirical risk curves have been scaled for visualization
        purposes.)
        % For each method, the vertical dashed line indicates the estimated rejection threshold (black vertical dashed line ) and the true value (blue).
        % Regardless of the transformation, the \pdfBased~method is unstable in the left-tail region of heavy-tailed test statistics (panel (b)) and yields a significantly conservative rejection threshold.
    }
        \label{fig:heavyTailed}
\end{figure}


% \subsection{CDF-based method}\label{sec:localFDR.CDF}

The heuristic argument in the previous paragraph can be made precise
with the help of the empirical process theory. By assuming that the
density functions $f_0$ and $f$ are
differentiable at $\tau_{\lambda}^{*}$ and $(f_0/f)'(\tau_{\lambda}^{*})
> 0$, it can be shown that the estimated threshold
$\EmpiricalThreshold$ converges to $\tau_{\lambda}^{*}$ at
rate $(\No \wedge \NoNc)^{-1/3}$ when $n, m \to \infty$. Morevoer, by
assuming monotone likelihood ratio (i.e.\
$(\pdfTestStatisticsNull{}/\pdfTestStatistics{})'>0$) and
additional regularity conditions, it can be shown that such
convergence is uniform over $\lambda$. See \Cref{sec:results-localFDR} for some technical results.

% We focus on the case where the likelihood
% ratio $f_0(t)/f_1(t)$ is monotone, leading to a one-sided rejection rule.
% We discuss the non-monotone scenario in \Cref{rmk:non.monotone}.

% Finally, the objective
% of equation \eqref{eq:optimal-threshold} may be interpreted as the
% risk function of a one-sided decision rule and can be easily
% generalized to arbitrary decision rules. Indeed, this Bayesian
% decision-theoretical interpretation of \localFDR~has been
% given by \textcite{sun2007oracle} already; however, they did not
% attempt to use it to estimate the optimal decision rule.


% \begin{proposition}\label{prop:convergence.rate}
%   Assume the following assumptions hold.
%     \begin{enumerate}
%         \item \label{prop:assu:density.derivative} $\pdfTestStatistics{}(\trueThreshold)$, $\pdfTestStatisticsNull(\trueThreshold) > 0$ and $\pdfTestStatistics{}'(\trueThreshold)$, $\pdfTestStatisticsNull'(\trueThreshold)$ exist;
%         \item \label{prop:assu:density.upper.bound}
%  $\pdfTestStatistics{}(\threshold) \le \pdfTestStatistics{\max}$, $\pdfTestStatisticsNull(\threshold) \le \pdfTestStatisticsNull_{,\max}$, in $|\threshold - \trueThreshold| \le D$ for some $\pdfTestStatistics{\max}$, $\pdfTestStatisticsNull_{,\max}$, $D > 0$;
%         \item \label{prop:assu:MLR} the derivative $(\pdfTestStatisticsNull/\pdfTestStatistics{})'(\trueThreshold)$ exists and is positive;
%         \item \label{prop:assu:Bayes.risk} for any $\delta > 0$, there exists $\varepsilon_\delta > 0$ such that $\cdfTestStatisticsNull(\threshold) - \lambda \EmpiricalCdfTestStatistics(\threshold) > \cdfTestStatisticsNull(\trueThreshold) - \lambda \EmpiricalCdfTestStatistics(\trueThreshold) + \varepsilon_\delta$ for $|\threshold - \trueThreshold| > \delta$.
%     \end{enumerate}
%     Then for $\No \wedge \NoNc$ large enough, with probability at least $1 - C^*/\log(\No \wedge \NoNc)$,  $C^* > 0$ independent of $\No \wedge \NoNc$,    \begin{align}\label{eq:prop:convergence.rate}
%         \left|\estimatedThreshold - \trueThreshold\right|
%         \le \frac{\log(\No \wedge \NoNc)}{(\No \wedge \NoNc)^{1/3}}.
%     \end{align}
% \end{proposition}




% % Assumption~\eqref{prop:assu:MLR} and Assumption~\eqref{prop:assu:Bayes.risk} are less stringent than the monotone likelihood ratio condition.
% Our proof of \Cref{prop:convergence.rate} relies on comparing the modulus of continuity of the stochastic process $\EmpiricalCdfTestStatisticsNull(\threshold) - \lambda
%  \EmpiricalCdfTestStatistics(\threshold)$ and the growth of $\cdfTestStatisticsNull(\threshold) - \lambda
%  \cdfTestStatistics{}(\threshold)$ in a neighborhood of $\trueThreshold$.
% % Assumption~\ref{prop:assu:density.upper.bound} and assumption~\ref{prop:assu:Bayes.risk} ensure $\estimatedThreshold$ is consistent. Assumption~\ref{prop:assu:MLR} guarantees the population objective function $\BayesRiskLambda$ grows at least quadratically around $\threshold^*$.
% % By \cite[Lemma 6.4]{massart2007concentration}, the magnitude of the stochastic error in the neighborhood $\{\threshold: |\threshold - \threshold^*| \le r\}$
% % % $\EE[\sup_{|\threshold - \threshold^*| \le \delta}(\cdfTestStatisticsNull(\threshold) - \lambda \EmpiricalCdfTestStatistics(\threshold)) - (\cdfTestStatisticsNull(\threshold^*) - \lambda \EmpiricalCdfTestStatistics(\threshold^*))]$
% % is of order $O(\sqrt{r/\No})$.
% % % For $\delta \gtrsim \No^{-1/3}$, the quadratic growth dominates the stochastic error in the modulus
% % % of continuity.
% % Intuitively, we expect the curvature of the risk matches the stochastic
% % error in the estimation at $\estimatedThreshold$, i.e., $(\estimatedThreshold - \trueThreshold)^2 \approx \sqrt{|\estimatedThreshold - \trueThreshold|/\No}$, which yields the convergence rate $\No^{-1/3}$.
% Details of the proof are deferred to \Cref{sec:results-localFDR}.

The optimization problem \eqref{eq:optimal-threshold} can be rewritten
as a decision-theoretic problem: let $\hat{H}_i(t) = \1_{\{T_i \leq
  \threshold\}}$ be the one-sided decision rule, then
\begin{equation}
  \label{eq:optimal-threshold-2}
  \tau_{\lambda}^{*} = \argmin_\threshold
  \EE_{\cdfTestStatisticsNull}\left[\hat{H}_i(t)\right]
   - \lambda \EE_{\cdfTestStatistics{}}\left[\hat{H}_i(t)\right]
   = \argmin_\threshold \mathbb{E}\left[
     \weightNull \1_{\{\hypothesis{i} < \hat{\hypothesis{i}}(t)\}}
     + \weightNonNull \1_{\{\hypothesis{i} > \hat{\hypothesis{i}}(t)\}}
  \right],
\end{equation}
where $\weightNull = 1-q$ is the loss of a false
positive and $\weightNonNull = q$ is the loss of a
false negative. 
This connection was pointed out by
\textcite{sun2007oracle}.
% Although this connection was pointed out by
% \textcite{sun2007oracle} more than 15 years ago, it appears that the
% empirical version of \eqref{eq:optimal-threshold} that replaces the
% expectation by a sample average had not been used to estimate
% \localFDR\ until a recent paper by \textcite{soloff22_edge_discov}.

In contrast to \pdfBased~methods, the \cdfBased~method proposed here
is free of tuning parameters and invariant to monotone
transformations of the test statistics. \Cref{fig:cdfBased}
illustrates the practical performance of this procedure using the
same simulation example above, by showing the
population and empirical risk in \eqref{eq:optimal-threshold-2} as
curves of the rejection threshold $t$. It is evident that the
\cdfBased~rejection threshold $\EmpiricalThreshold$ is close to
$\tau_{\lambda}^{*}$ and its risk is close to the oracle.

% \begin{remark}\label{rmk:convergence.rate.uniform}
% \Cref{prop:convergence.rate} can be extended to a uniform convergence result under a set of stronger assumptions. Explicitly, for a set $\Lambda = (a, b)$ and the associated set of rejection thresholds $\calT = \{\trueThreshold: \lambda \in \Lambda\}$, assume the minimal value of the objective function $\cdfTestStatisticsNull(\threshold) - \lambda
% \cdfTestStatistics{}(\threshold)$ is uniquely obtained at $\trueThreshold$, and that densities $\pdfTestStatistics{}$, $\pdfTestStatisticsNull{}$, derivatives $\pdfTestStatistics{}'$, $\pdfTestStatisticsNull'$, $(\pdfTestStatisticsNull{}/\pdfTestStatistics{})'$ are uniformly upper bounded on $\calT$ and uniformly lower bounded away from zero.
% Then the estimator converges to the true threshold uniformly at the rate $(\No \wedge \NoNc)^{-1/3}$.
% Details of the uniform convergence are deferred to the \Cref{sec:results-localFDR}.
% \end{remark}

We offer some additional remarks on the \cdfBased~method above.

\begin{remark}
  By using the order statistics $\pval{(1)} < \dotsb < \pval{(\No)}$ of
  the \nickname~p-values, the optimization
  problem~\eqref{eq:Bayes.risk.2} can also be rewritten as as
  \begin{align*}
     \EmpiricalThreshold = T_{(i^{*})},~\text{where}~i^{*} = \argmin_i
      \frac{\NoNc+1}{\NoNc} \pvalOrder{i} -
      \frac{\lambda i}{\No}.
  \end{align*}
  This is almost identical to the method in
  \textcite{soloff22_edge_discov}. More precisely,
  \textcite{soloff22_edge_discov} assumes an independent sequence of
  p-values that are uniformly distributed under the null (so $F_0(t) =
  t$ is known) is given and does not include the factor $(m+1)/m$
  in the last equation. \textcite{soloff22_edge_discov} not only
  proved the same $\No^{-1/3}$ convergence rate for their estimator of
  the rejection threshold but also showed that the expected maximum
  \localFDR\ of the rejected hypotheses is controlled if the
  likelihood ratio is monotone. Our numerical simulation suggests that
  the method proposed here might also be able to control the maximum
  \localFDR, but we are unable use the technique developed by
  \textcite{soloff22_edge_discov} to prove this because the
  \nickname~p-values are not independent.
\end{remark}

\begin{remark}
The method above can be extended to estimate the \localFDR~curve,
which shall be denoted by $q(t)$. In fact,
$\hat{\tau}(\level):=\hat{\tau}_{\lambda = q/\probNull, \No, \NoNc}$
is an increasing and piece-wise constant function. Thus, the
\localFDR~curve can be estimated by inverting $\hat{\tau}(\level)$,
\begin{align}\label{eq:curve:inverse}
    \estimatedLocalFDR{\threshold} = \inf_\level \{\level: \hat{\tau}(q) \ge \threshold \}, \quad \text{for any}~\threshold.
\end{align}
The resulting \localFDR~curve $\estimatedLocalFDR{\threshold}$ is increasing, piece-wise constant, left-continuous, and the jump points are contained in $(\testStatistics{i})_{i \in \hypothesisIndex{}}$.
% See Figure \ref{fig:diagram-curve} for a graphical representation of $\hat{\tau}(\level):=\estimatedThreshold$ and $\estimatedLocalFDR{\threshold}$ in a toy example.
% As also noted by \textcite{soloff22_edge_discov},
The estimated curve
$\hat{q}(t)$ is essentially a light modification of Grenander's
estimator \cite{grenander1956theory} of a monotone density
function. It is well known that Grenander's estimator converges at
the rate $n^{-1/3}$; see \cite{durot2018limit} for a recent
review.
\end{remark}

\begin{remark}
Because the objective function
\eqref{eq:optimal-threshold} is typicaly locally convex at its optimum,
it is expected that the regret
  $\{\cdfTestStatisticsNull(\EmpiricalThreshold) - \lambda
\cdfTestStatistics{}(\EmpiricalThreshold)\} -
\{\cdfTestStatisticsNull(\tau_{\lambda}^{*}) - \lambda
\cdfTestStatistics{}(\tau_{\lambda}^{*})\}$ usually converges to zero
twice as fast as $\EmpiricalThreshold$ converges to
$\tau_{\lambda}^{*}$. However, even when the risk is almost flat around
$\tau_{\lambda}^{*}$, a simple argument using the
DvoretzkyKieferWolfowitz (DKW)
  inequality shows that the regret
%   $\{\cdfTestStatisticsNull(\EmpiricalThreshold) - \lambda
% \cdfTestStatistics{}(\EmpiricalThreshold)\} -
% \{\cdfTestStatisticsNull(\tau_{\lambda}^{*}) - \lambda
% \cdfTestStatistics{}(\tau_{\lambda}^{*})\}$
converges at least at the
rate $\No^{-1/2}$; see \Cref{prop:convergence.rate.weak} in the
Appendix. Thus, the simple \cdfBased~method almost always has a small
regret, even if the rejection threshold $\tau_{\lambda}^{*}$ is not
estimated very accurately.
\end{remark}




% To aid the description of our proposal, we define $\BayesRiskLambda := \cdfTestStatisticsNull - \lambda \cdfTestStatistics{}$, and $\EmpiricalBayesRiskLambdaSecond := \cdfTestStatisticsNull - \lambda \EmpiricalCdfTestStatistics{}$.
% \begin{align}\label{defi:localFDR}
%     \localFDR(t) = \Pr(H_i = 0 \mid T_i = t)
%     = \frac{\probNull \pdfTestStatisticsNull(t)}{\probNull
%   \pdfTestStatisticsNull(t) + (1-\probNull)
%   \pdfTestStatisticsNonNull(t)}.
% \end{align}






\section{Simulations}\label{sec:simulation}

When using multiple testing methods based on negative controls, a
concern in practice is that they may be not very powerful. We
investigate this using numerical simulations.

% \subsection{\FDR\ control}\label{sec:validity.power}

We generate a set of
baseline p-values $(\testStatistics{i})_{i \in \hypothesisIndex{} \cup
  \hypothesisIndex{\text{nc}}}$ that might be individually invalid,
and compare three variations of the \BH~procedure:
\begin{enumerate}
\item the standard \BH~procedure (\BH) that assumes the validity of the
baseline p-values and directly aggregates $(\testStatistics{i})_{i \in
  \hypothesisIndex{}}$;
\item the \BH~procedure with \nickname~p-values (\BH~\nickname) that first
computes the \nickname~p-values $(\pval{i})_{i \in
  \hypothesisIndex{}}$ using $(\testStatistics{i})_{i \in
  \hypothesisIndex{} \cup \hypothesisIndex{\text{nc}}}$ and then
applies the \BH~procedure to $(\pval{i})_{i \in \hypothesisIndex{}}$;
\item the oracle \BH~procedure (\BH~oracle) applies the \BH~procedure to the
p-values corrected by the true null CDF.
\end{enumerate}
% i.e., $\cdfTestStatisticsNull{}(\testStatistics{i})$.

We experiment with $6 = 3 \times 2$ joint distributions of the
baseline p-values with different marginal distributions and dependency
structures.
\begin{itemize}
    \item \textit{Marginal distribution}. We consider three marginal
      distributions of null baseline p-values: $T \overset{d}{=}
      \Phi(Z + \mu)$ where $Z \sim \calN(0,1)$ and $\mu \in
      \{-0.5,0,0.5\}$, corresponding respectively to anti-conservative
      (anti-csvr.), exact (exact), and conservative (csvr.) p-values.
    The marginal distribution of the non-null baseline p-values is set to $\Phi(Z - 3)$.
    \item \textit{Dependency}. We consider two types of dependencies:
      the independent setting (ind.) where $(\testStatistics{i})_{i
        \in \hypothesisIndex{} \cup \hypothesisIndex{\text{nc}}}$ are
      mutually independent, and the exchangeable setting (exch.) where
      $(\testStatistics{i})_{i \in \hypothesisIndex{} \cup
        \hypothesisIndex{\text{nc}}}$ are generated from an EMN model
      in \Cref{rem:emn} with correlation parameter $\rho = 0.5$.
\end{itemize}
We generate $\NoNull = 100$ null test statistics, $\NoNonNull = 10$ non-null test statistics, and $\NoNc = 200$ internal negative controls.
In each trial, we record the \FDP~and the true positive rate (the
number of true discoveries divided by the total number of non-nulls)
of each method. All configurations are repeated $10^4$ times. We set
the target \FDR~level to $\FDRLevel = 0.2$.

\begin{table}[tbp]
  \centering
\caption{{\FDR~and power analysis. We compare the validity and the power of three variants of the \BH~procedure (\FDR~level $\FDRLevel = 0.2$) across $6$ joint distributions of the baseline p-values. The standard deviation of the \FDP~and the true positive rate is recorded in the bracket. All settings are repeated $10^4$ times.}}
\label{tab:simulation}
\begin{tabular}{cc|cc|cc|cc}
\toprule
\multicolumn{2}{c|}{\multirow{2}{*}{}}                                    & \multicolumn{2}{c|}{BH}              & \multicolumn{2}{c|}{BH \nickname}              & \multicolumn{2}{c}{BH oracle}                \\ \cline{3-8}
\multicolumn{2}{c|}{}
                                                                          & \multicolumn{1}{c|}{FDR}      & power & \multicolumn{1}{c|}{FDR} & power & \multicolumn{1}{c|}{FDR} & power\\
  \midrule
\multicolumn{1}{c|}{\multirow{6}{*}{ind.}}  & \multirow{2}{*}{csvr.}      & \multicolumn{1}{c|}{0.047}   & 0.8      & \multicolumn{1}{c|}{0.17}    & 0.9           & \multicolumn{1}{c|}{0.18}      & 0.93            \\
\multicolumn{1}{c|}{}                       &                             & \multicolumn{1}{c|}{(0.072)} & (0.15)   & \multicolumn{1}{c|}{(0.13)}  & (0.13)        & \multicolumn{1}{c|}{(0.12)}    & (0.087)         \\ \cline{2-8}
\multicolumn{1}{c|}{}                       & \multirow{2}{*}{exact}      & \multicolumn{1}{c|}{0.18}    & 0.82     & \multicolumn{1}{c|}{0.16}    & 0.76          & \multicolumn{1}{c|}{0.18}      & 0.82            \\
\multicolumn{1}{c|}{}                       &                             & \multicolumn{1}{c|}{(0.13)}  & (0.14)   & \multicolumn{1}{c|}{(0.14)}  & (0.21)        & \multicolumn{1}{c|}{(0.13)}    & (0.14)          \\ \cline{2-8}
\multicolumn{1}{c|}{}                       & \multirow{2}{*}{anti-csvr.} & \multicolumn{1}{c|}{0.49}    & 0.87     & \multicolumn{1}{c|}{0.16}    & 0.53          & \multicolumn{1}{c|}{0.18}      & 0.63            \\
\multicolumn{1}{c|}{}                       &                             & \multicolumn{1}{c|}{(0.13)}  & (0.12)   & \multicolumn{1}{c|}{(0.16)}  & (0.28)        & \multicolumn{1}{c|}{(0.15)}    & (0.19)          \\ \hline
\multicolumn{1}{c|}{\multirow{6}{*}{exch.}} & \multirow{2}{*}{csvr.}      & \multicolumn{1}{c|}{0.044}   & 0.76     & \multicolumn{1}{c|}{0.17}    & 1             & \multicolumn{1}{c|}{0.13}      & 0.9             \\
\multicolumn{1}{c|}{}                       &                             & \multicolumn{1}{c|}{(0.14)}  & (0.31)   & \multicolumn{1}{c|}{(0.13)}  & (0.018)       & \multicolumn{1}{c|}{(0.25)}    & (0.2)           \\ \cline{2-8}
\multicolumn{1}{c|}{}                       & \multirow{2}{*}{exact}      & \multicolumn{1}{c|}{0.13}    & 0.77     & \multicolumn{1}{c|}{0.17}    & 0.98          & \multicolumn{1}{c|}{0.13}      & 0.77            \\
\multicolumn{1}{c|}{}                       &                             & \multicolumn{1}{c|}{(0.25)}  & (0.31)   & \multicolumn{1}{c|}{(0.13)}  & (0.047)       & \multicolumn{1}{c|}{(0.25)}    & (0.31)          \\ \cline{2-8}
\multicolumn{1}{c|}{}                       & \multirow{2}{*}{anti-csvr.} & \multicolumn{1}{c|}{0.31}    & 0.77     & \multicolumn{1}{c|}{0.17}    & 0.91          & \multicolumn{1}{c|}{0.13}      & 0.57            \\
\multicolumn{1}{c|}{}                       &
                                                                                                                 & \multicolumn{1}{c|}{(0.35)}  & (0.31)   & \multicolumn{1}{c|}{(0.13)}  & (0.12)        & \multicolumn{1}{c|}{(0.25)}    & (0.38)          \\
  \bottomrule
\end{tabular}
\end{table}

\Cref{tab:simulation} reports the result of this simulation study.
The \BH~\nickname~controls \FDR~in all $6$ settings, while the
standard \BH~fails when the individual p-values are invalid (in two
anti-csvr.\ settings).
In terms of statistical power, the \BH~\nickname~is comparable to the
\BH~oracle when the p-values are independent, and, perhaps
surprisingly, is more powerful when the p-values are positively
dependent (in three exch.\ settings). In fact, \BH~\nickname~is more
powerful when the baseline p-values are positively dependent than when
they are independent.
% ---favorable when batch effects or latent factors are relevant.
We believe this surprising gain of power is due to the fact that the
\nickname~p-values are invariant to monotone transformations and are
hence invariant to the shared latent factor $Z$ in the EMN model
\eqref{eq:emn}. In other words, the \nickname~p-values effectively
have a larger signal-to-noise-ratio in the dependent case.

% \qz{I don't understand this explanation. What is $W_i$ and $H_i$?}
% $(\pval{i})_{i \in
%   \hypothesisIndex{}}$ based on  $\testStatistics{i} =
% \Phi(\sqrt{\rho}Z + \sqrt{1-\rho}W_i - 3 \hypothesis{i})$, $Z$, $W_i
% \stackrel{\text{i.i.d.}}{\sim} \calN(0,1)$ are equivalent to those
% derived from the baseline p-values $\Phi(\sqrt{1-\rho}W_i - 3
% \hypothesis{i})$.
% It is obvious that the difference between the null $\Phi(\sqrt{1-\rho}W_i)$ and the non-null $\Phi(\sqrt{1-\rho}W_i - 3)$ is more significant for larger $\rho$.
% % , and thus the power of the exch. setting ($\rho = 0.5$) is larger than that of the ind. setting ($\rho = 0$).
% % In contrast, for the \BH~procedure with oracle p-values, the differences between the corrected null and non-null p-values are the same under the independence and EMN settings.


% \subsection{Number of internal negative
% control}\label{sec:nc.sample.size}

An important question in practice is how many negative controls are
needed to use \nickname~p-values and have decent power. In order for
\BH~\nickname~to reject all non-nulls, a necessary
condition is that $p_{(\NoNonNull)} \le \FDRLevel \NoNonNull/\No$.
Since the minimal \nickname~p-value is at least $1/(1+\NoNc)$, the
above constraint implies that we need $\NoNc \ge C \No/(\FDRLevel
\NoNonNull)$ for some multiple $C > 1$ that may depend on the signal
strength. By varying the number of internal negative controls in the
the simulation setup above, we find that $C = 2$ is a good rule of
thumb for the power of \BH~\nickname~to be close to that of
\BH~oracle; see \Cref{fig:nc.sample.size} in the Appendix. When the
non-nulls have a smaller effect size, a larger $C$ may be
required. See also the simulation study in
\textcite{mary22_semi_super_multip_testin} and a related rule-of-thumb
developed there.


% \subsection{\LocalFDR\ control}
% \label{sec:localfdr-control}


%   \qz{How about power of the local FDR method? And its max lfdr? How
% many negative controls are needed for good local FDR control and
% decent power?}




\section{Real data analysis}\label{sec:real.data}

We now return to the motivating proteomic data analysis described in
\Cref{sec:motivating.data}. As mentioned already, there are $\No =
740$ proteins under investigation and $\NoNc = 2,067$ internal
negative control proteins.
We denote the protein abundance under the treatment and the control
condition by $\responseTreatment{i}$ and $\responseControl{i}$,
respectively.
% Researchers are interested in the proteins that express at higher levels under the experimental condition,
For each protein $i \in \hypothesisIndex{} = \{1,\dotsc,\No\}$, we would
like to test the one-sided hypothesis:
\begin{align*}
    \hypothesis{i,0}: \EE[\responseTreatment{i}] \le  \EE[\responseControl{i}] \quad \text{v.s.} \quad \hypothesis{i,1}: \EE[\responseTreatment{i}] >  \EE[\responseControl{i}].
\end{align*}
For internal negative control protein $j \in
\hypothesisIndex{\text{nc}} = \{741, \dotsc, 2807\}$, its expression
is anticipated to be the same over the two conditions, i.e.\
$\EE[\responseTreatment{j}] =  \EE[\responseControl{j}]$.

\subsection{Falsification of negative controls}
\label{sec:fals-negat-contr}

The validity of the internal negative controls can be falsified by
comparing the empirical distribution of $\responseTreatment{j} -
\responseControl{j}$ over different subgroups of negative controls.
In this example, \Cref{fig:nc.subgroup} shows that the test statistics
for proteins annotated with different non-membrane subcellular
locations are distributed similarly, thereby supporting the usage of
them as internal negative controls.
% By \Cref{rem:one-sided}, we can
% apply the \BH~procedure combined with the \nickname~p-values to the
% proteomic dataset.

\begin{figure}[tbp]
    \centering
    \begin{minipage}{5cm}
    \centering
\includegraphics[clip, trim = 0cm 0cm 0cm 0cm, width  = 5cm]{plot/nucleus-mito.pdf}
    % \subcaption{K-S test}
    \end{minipage}
    \begin{minipage}{5cm}
    \centering
\includegraphics[clip, trim = 0cm 0cm 0cm 0cm, width  = 5cm]{plot/nucleus-cyto.pdf}
    % \subcaption{Simulated null distribution.}
    \end{minipage}
        \begin{minipage}{5cm}
    \centering
\includegraphics[clip, trim = 0cm 0cm 0cm 0cm, width  = 5cm]{plot/mito-cyto.pdf}
    % \subcaption{Simulated null distribution.}
    \end{minipage}
\caption{{Quantile-quantile plots of the abundance differences across internal negative control subgroups.
We partition the internal negative controls into three subgroups according to the subcellular location keywords ``nuclear'', ``mitochondrial'', and ``cytoplasmic''.
The K-S test p-values for all three pair-wise subgroup comparisons are non-significant at level $0.05$.
% $0.067$, $0.068$, $0.467$, respectively.
% Before applying \nickname~p-values to the baseline test statistics,
% We examine the quality of the internal negative control in the proteomic dataset.
% Instead, we assess whether the internal negative controls themselves are exchangeable.
% and contrast the distributions of protein abundances.
% and expect the distributions of the internal negative control proteins to not vary over subgroups.
% \Cref{fig:nc.subgroup} displays that the distributions of the response differences from different subgroups are rather similar.
% The K-S tests also do not detect differences between subgroups at the significance level $0.05$.
}}
    \label{fig:nc.subgroup}
\end{figure}


\subsection{Choice of empirical null}
\label{sec:choice-empir-null}

We investigate different choices of the empirical null distributions
in this proteomic dataset. We apply different normally distributed
null distributions obtained using the method described next. For each
$\calJ \in \{\calI, \calI \cup
\calI_{\text{nc}}, \calI_{\text{nc}}\}$ (corresponding to using,
respectively, all
test statistics under investigation, all test statistics observed, and
only the negative control statistics), we consider three different
estimators of the mean $\mu$ and standard deviation $\sigma$ of the null
distribution:
\begin{enumerate}
\item MAD1: $\mu = 0$, $\sigma =
  \sqrt{\{\texttt{MAD}((\responseTreatment{i})_{i \in \calJ})\}^2 +
    \{\texttt{MAD}((\responseControl{i})_{i \in \calJ})^2\}}$, where
  \texttt{mad} computes the median of the absolute deviations from the
  median multiplied by a factor of 1.4826 that ensures consistency for the
  normal distribution;
\item MAD2: $\mu = 0$, $\sigma =
  \texttt{MAD}((\responseTreatment{i} - \responseControl{i})_{i \in
    \calJ})$;
\item Efron: the method described in \textcite{efron2004large}, in
  which a Poisson regression is first applied to
  $(\responseTreatment{i} - \responseControl{i})_{i \in \calJ}$ to
  estimate the density function and $\mu$ and $\sigma$ are
  then obtained from the mode and the half-width of the center peak of
  the estimated density function.
\end{enumerate}
We then compute the one-sided p-values using each empirical null
distribution. Our proposed \nickname~p-values correspond to using the
empirical cumulative distribution function (ECDF) of
$(\responseTreatment{i} - \responseControl{i})_{i \in
    \calJ}$ for $\calJ = \calI_{\text{nc}}$.
% We compare the \BH~\nickname~to the standard \BH~procedure with four
% baseline p-values.
% % The first set of baseline p-values are the abundance difference normalized by different estimators of its standard deviation.
% We first consider $\responseTreatment{i}- \responseControl{i}$ normalized by two different estimators of its standard deviation.
% Because there is only one observation per protein per condition,
% % it is impossible to derive a meaningful estimate of the standard deviation for each protein separately.
% % As a surrogate,
% we assume the protein abundances are homoscedastic under each
% condition and consider% \footnote{Here we use the \textsc{R} function
%   % \textsc{mad}  to robustly estimate the variances. }
% \begin{align*}
%     \hat{\sigma}_1 := \sqrt{\textsc{mad}((\responseTreatment{i})_{i \in
%   \hypothesisIndex{} \cup \hypothesisIndex{\text{nc}}})^2 +
%   \textsc{mad}((\responseControl{i})_{i \in \hypothesisIndex{} \cup
%   \hypothesisIndex{\text{nc}}})^2} \quad \text{and} \quad
%     \hat{\sigma}_2 = \textsc{mad}((\responseTreatment{i}- \responseControl{i})_{i \in \hypothesisIndex{} \cup \hypothesisIndex{\text{nc}}}),
% \end{align*}
% where \textsc{mad} computes the median of the absolute deviations
% multiplied by a factor of 1.4826 that ensures consistency for the normal
% distribution.
% % since protein abundance differences deviate from normal and contain multiple outliers.
% We adopt the standard normal as the theoretical null distribution and
% compute the baseline p-value as $1 - \Phi((\responseTreatment{i} -
% \responseControl{i})/\hat{\sigma}_{k})$, $k \in
% \{1,2\}$. Figure~\ref{fig:protein} uses the p-value based on the
% abundance difference normalized by $\hat{\sigma}_1$.
% In addition, we consider the \nickname~p-values based on the rankings
% of the unnormalized (negative) differences.
To investigate the performance of each empirical null, we used
the Kolmogorov-Smirnov and Anderson-Darling tests to
assess whether the p-values that are between 0.5 and 0.99 are
approximately uniformly distributed.

% latex table generated in R 4.1.2 by xtable 1.8-4 package
% Fri Mar 17 10:19:18 2023
\begin{table}[t]
  \centering
\caption{{A comparison of different choices of the empirical null
    distribution. NC: Negative controls; KS test: p-value of the
    Kolmogorov-Smirnov test of uniformity; AD test:
    p-value of the Anderson-Darling test of uniformity;
    \BH~rejections: number of rejections using
    the \BH~procedure with target \FDR~level $q = 0.2$.}}
\label{tab:rejection}
\begin{tabular}{lllccc}
\toprule
Statistics & Method & Empirical null & KS test & AD test & \BH~rejections \\
\midrule
Testing ($\calI$) & MAD1  & $\text{N}(0,0.4)$ & $< 10^{-16}$ & $1.9 \times 10^{-6}$ & $102$ \\
 & MAD2  & $\text{N}(0,0.3)$ & $3.3 \times 10^{-16}$ & $2.0 \times 10^{-6}$ & $144$ \\
 & Efron  & $\text{N}(-0.02,0.22)$ & $1.8 \times 10^{-5}$ & $2.5
                                                             \times 10^{-5}$ & $200$ \\
                                                             % & ECDF  &  & $1.0e+00$ & $1.0e+00$ & $\phantom{00}1$ \\
\midrule
All ($\calI \cup \calI_{\text{nc}}$) & MAD1  & $\text{N}(0,0.39)$ &
                                                              $<10^{-16}$
& $1.9 \times 10^{-6}$ & $103$ \\
 & MAD2  & $\text{N}(0,0.23)$ & $1.5 \times 10^{-5}$ & $5.3 \times 10^{-6}$ & $182$ \\
 & Efron  & $\text{N}(-0.05,0.21)$ & $4.5 \times 10^{-5}$ & $3.5
                                                            \times 10^{-5}$ & $234$ \\
                                                            % & ECDF  & N(NA,NA) & $1.1e-02$ & $1.6e-02$ & $\phantom{00}6$ \\
\midrule
NC ($\calI_{\text{nc}}$) & MAD1  & $\text{N}(0,0.4)$ &
                                                                     $<10^{-16}$ & $1.9
                                                                \times
                                                                10^{-6}$ & $102$ \\
 & MAD2  & $\text{N}(0,0.2)$ & $0.004$ & $0.002$ & $211$ \\
           & Efron  & $\text{N}(-0.02,0.18)$ & $0.039$ & $0.023$ & $240$ \\
 & ECDF (RANC)  &  & $0.019$ & $0.063$ & $214$ \\
\bottomrule
\end{tabular}
\end{table}

\Cref{tab:rejection} reports the empirical null obtained by each
method above, the p-values from the two tests of uniformity, and the
number of rejections made by the \BH~procedure ($q = 0.2$). Among
these empirical nulls, only Efron's method applied to
negative controls and the RANC p-values procedure produce p-values
whose bulk are nearly uniformly distributed; see also
\Cref{fig:empirical-null} in the Appendix. Between these methods,
Efron's method is more aggressive and produces more
rejections. However, a normal distribution does not seem to fit the
distribution of negative controls very well; see \Cref{fig:qq-efron}
in the Appendix.

% the  number of rejections made by the
% \BH~and the \BH~\nickname~at nominal \FDR~level $\FDRLevel = 0.2$.
% The standard \BH~procedure produces very different rejections
% under two different normalizations. In contrast, the
% \BH~\nickname~is invariant to monotone transformations and produces
% the same rejection list for the first three test statistics as
% expected. In addition, the \BH~\nickname~also makes similar
% rejections with the \logTMT~ratio statistics.

% Beyond protein abundances, we investigate an alternative
% statistic---the log tandem mass tag (\logTMT)---used in the original study.
% % The \logTMT~is not available for each condition and we only have access to the \logTMT~ratios between the experiment condition and the control condition.
% We consider baseline p-values based on \logTMT~ratios normalized by
% $\textsc{mad} ((\log~\text{TMT ratio}_{i})_{i \in \hypothesisIndex{} \cup \hypothesisIndex{\text{nc}}})
% $ (with the abundance difference replaced by
% the \logTMT~ratio).


% \begin{table}[tbp]
%   \centering
% \caption{{Number of rejections when \BH~and \BH~\nickname~are
%   applied to different choices of baseline p-values or test
%   statistics (target \FDR~level is $q = 0.2$).}}
% % \label{tab:rejection}
% \begin{tabular}{c|ccc|c}
% \toprule
%  \multirow{2}{*}{Method} & \multicolumn{3}{c|}{Protein abundance}                                                    & \multirow{2}{*}{\logTMT~ratio} \\ \cline{2-4}
%  & \multicolumn{1}{c|}{$\hat{\sigma}_1$} &
%                                            \multicolumn{1}{c|}{$\hat{\sigma}_2$} &  \multicolumn{1}{c|}{rank}  &                   \\
%   \midrule
%  \BH & \multicolumn{1}{c|}{103} & \multicolumn{1}{c|}{182} & \multicolumn{1}{c|}{NA}  &              186 \\ \hline
%  \BH~\nickname & \multicolumn{1}{c|}{214} & \multicolumn{1}{c|}{214} &
%                                                                        \multicolumn{1}{c|}{214}  &                217   \\
%   \bottomrule
% \end{tabular}
% \end{table}


\section{Discussion}\label{sec:discussion}

Motivated by a real proteomic data anslysis, we have suggested three
model-free methods for simultaneous hypothesis testing using
internal negative controls. They can be used to control various
multiple testing error rates and have appealing theoretical
properties. Moreover, these methods offer competitive practical
performane as long as there are a decent number of number of negative
controls. Another attractive property is that the methods proposed
here are all invariant to monotone transformations of the data and
requires no subjective evaluation of the goodness-of-fit of the
empirical null distribution.

% The \nickname~p-value proposed in this paper may be viewed as a
% nonparametric extension to previous methods for simultaneous
% hypothesis testing based on an empirical null distribution. Unlike
% most previous methods, the usage \nickname~p-values can be immediately
% justified based on the exchangeability of true nulls and internal
% negative controls.
As mentioned in the Introduction, several recent articles have proposed
similar ideas about using negative controls in multiple testing
\parencite{bates21_testin_outlier_with_confor_p_values,mary22_semi_super_multip_testin,soloff22_edge_discov}. These
proposals arise from different applied domains and different
terminologies are used. An advantage to use ``negative control'' to
refer to the observations that resemble the null is that negative
control is an integral component of scientific methods and the nature
of the method can be immediately understood by across different
contexts. As a consequence, it is straightforward to understand the
assumptions involved and assess them in practice. In fact, this
prompted us to develop weaker theoretical conditions that allow
dependent test statistics (see \Cref{rem:bates-condition}) or
misspecfified negative controls (see \Cref{rem:one-sided}).

Of course, the statistical power of \nickname~p-values depend closely on
the quantity and quality of the internal negative controls. With a
moderate number of negative controls, the \BH~procedure
applied to the RANC p-values rejects almost as many hypotheses as the
\BH~procedure applied to the ``oracle'' p-values, which are calculated
using the unknown true null
distribution. When the signals are strong, the FDR level is $q = 0.2$,
and
the proportion of non-nulls is $n_1/n = 0.1$, a good rule of thumb
for the number of negatve controls is $\NoNc \ge 2 \No/(\FDRLevel
\NoNonNull) = 100$; see also
\textcite{mary22_semi_super_multip_testin} for related discussion on the
number of negative controls.

Although the RANC p-value is robust to certain
misclassifications of the negative controls, using too many negative
controls of poor quality may lead to low power. Additionally, one can falsify
the crucial exchangeability assumption by considering subgroups of
negative controls defined by domain knowledge; see
\Cref{fig:nc.subgroup} in \Cref{sec:real.data} for an illustration of
this idea using the proteomic dataset.

% By definition, the \nickname~p-values are discrete and can only take
% values in $\{j/(\NoNc+1):1 \le j \le \NoNc+1\}$, so their null
% distribution is not exactly uniform over $[0,1]$.
% When $\NoNc$ is small, the \nickname~p-values can be substantially
% conservative. To correct for discreteness, we can use the following
% randomized p-value: let $U_i \sim U[0,1], i=1,\dotsc,\No$ be
% independent uniformly distributed variables and define
% \begin{align*}
%   p^{+}_{i} := \frac{{U}_i + \sum_{j \in \hypothesisIndex{\text{nc}}} \1_{\{\testStatistics{j} \leq \testStatistics{i}\}}}{{1} + \NoNc}.
% \end{align*}
% This randomized p-value is exact when $(\testStatistics{j})_{j \in
%   \{i\} \cup \hypothesisIndex{\text{nc}}}$ is
% exchangeable. Conditional on $(U_i)_{i=1}^{\No}$, the collection of
% randomized p-values $(p^{+}_{i})_{i=1}^n$ is
% PRDS on the true nulls under the same assumptions in
% \Cref{prop:PRDS}. Because the randomization is independent, it is
% straightforward to verify that $(p^{+}_{i})_{i=1}^{\No}$ is PRDS on
% the true nulls unconditionally.

For convenience, we have assumed throughout the article that there are
no ties among the test statistics. Although we regard this assumption
as inconsequential for most practical applications, one may also
consider randomly breaking ties in the definition of
\nickname~p-values. It
can be easily shown that \Cref{prop:pvalue.validity} still holds.
% and \Cref{prop:PRDS} holds under condition~\ref{PRDS:assu:exchangeable}.
% For the empirical null perspective, if we break ties randomly, .
% In fact, breaking ties randomly is equivalent to first randomly permuting the indices ${i \in \hypothesisIndex{}'}$ ($\hypothesisIndex{}' =  \hypothesisIndex{}\cup \hypothesisIndex{\text{nc}}$ or $\{i\}\cup \hypothesisIndex{\text{nc}}$), and then ranking the test statistics $(\testStatistics{i})_{i \in \hypothesisIndex{}'}$ first by the value and then by the permuted index.
% If $(\testStatistics{i})_{i \in \hypothesisIndex{}'}$ is exchangeable, then $((\testStatistics{i}, \sigma(i)))_{i \in \hypothesisIndex{}'}$ (the test statistic augmented by the permuted index $\sigma(i)$) is also exchangeable. Since $((\testStatistics{i}, \sigma(i)))_{i \in \hypothesisIndex{}'}$ contains no ties in the lexicographic order, the proofs enabled by exchangeability can be applied.
However, it remains unclear if \Cref{prop:PRDS} holds
% under its set of conditions \ref{PRDS:assu:independent},
as our proof assumes that the
test statistics have continuous distributions.
Also, the empirical process argument in \Cref{sec:empirical.process}
does not directly extend because the process $\ncFalsePositive(t)$
may have large jumps in the presence of ties. See the supplementary
materials of \textcite{bates21_testin_outlier_with_confor_p_values}
for related discussion.
% , and
% $\widehat{\FDR}_{\lambda}(\stoppingTime)$ may exceed the target
% threshold $\FDRLevel$ by a significant amount.
% \zg{How to define the filtration after the random tie-breaking?}
% empirical process: if the test statistics remain the same, the counting process remains the same. Need to adjust the value a bit, add small noise? then F are different ..., uniformly stochastic dominance? arbitrary convolution does not work, maybe convolved with a distribution of very small magnitude?



\section*{Acknowledgements}
Qingyuan Zhao and Zijun Gao are partly supported by EPSRC (grant
EP/V049968/1). We thank Jing Ren and Zora
Chan for bringing the proteomic application to us and Jiefu Li for
sharing the dataset analyzed in
\Cref{sec:motivating.data,sec:real.data}. We thank Rajen Shah and
Richard Samworth for helpful comments and Aaditya Ramdas for pointing
us to the conformal inference literature and in particular the paper
by \textcite{bates21_testin_outlier_with_confor_p_values}.


\section*{Data and computer programs}
The data and computer programs to reproduce the analysis and figures are available at \url{https://github.com/ZijunGao}.


\printbibliography

% As discussed in \Cref{sec:discussion}, our proposal remains valid using an imperfect internal negative control set but the power will be sacrificed.
\appendix
\include{appendix0228}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:

Sequential Monte Carlo (SMC) methods \citep[see, e.g.,][]{Chopin2020book} are based on approximating the filtering and smoothing distributions using Monte Carlo samples drawn from these distributions. They then propagate the trajectory by sequentially applying a sampling-resampling routine. Notably, SMC methods \citep[aside from the family of marginal particle filtering methods, see,][]{Klaas2005marginal} provide a representation of the full pathwise smoothing distribution. This representation converges when the number of samples tends to infinity~\citep{kitagawa1996smoothing}. However, in practice, the resulting paths are degenerate for time steps $t \ll T$. This has justified the introduction of backward weighting and sampling methods to rejuvenate the trajectories far from the endpoint~\citep{godsill2004monte}, and their resulting convergence improvements have been studied, for example in \citet{douc2011sequential}, and more recently under a more general framework, in \citet{Dau2022complexity}. %

Because particle filtering methods provide an unbiased likelihood estimate, they can be used to perform parameter estimation in state-space models. A particularly useful class of methods leveraging this property are the particle Markov chain Monte Carlo (pMCMC) methods \citep{andrieu2009pseudomarginal,Andrieu2010particle}, which are based on constructing MCMC schemes either as a Metropolis--Rosenbluth--Teller--Hastings (MRTH) algorithm~\citep{metropolis1953equation,Hastings:1970}, or a Gibbs-like sampler~\citep{geman1984stochastic}. We will refer to these two classes of algorithms as pseudo-marginal and particle Gibbs (pGibbs), respectively. The asymptotic properties of pGibbs schemes in particular have been the subject of many investigations, and increasingly stronger convergence results have been successfully derived for them, for example, in \citet{Chopin2015particle,andrieu2018uniform,lee2020coupled}.

These two methods sample consistently from the (joint) pathwise smoothing and parameter posterior distributions in general SSMs, but numerically fail when the transition kernel is ``sticky'', or when the latent space dimension is large. Ancestor sampling methods~\citep{whiteley2010discussion,lindsten2014particle} can be, to some extent, used to mitigate this problem. However, the failure is due to the inherent property that the set of particles available to describe the smoothing distribution comes from the forward filtering pass in the first place. Thus, the weights appearing during the backward pass of either the smoothing or particle Gibbs algorithm will exhibit a large variance. Recently, \citet{finke2021csmc} and \citet[Chap. 4]{malory2021bayesian} independently proposed related particle Gibbs algorithms that alleviate this issue. \citet{finke2021csmc} in particular showed that under a proper scaling of their algorithms, the methods do not suffer from the curse of dimensionality present in classical particle MCMC methods. In this article, we consider the formulation of \citet{finke2021csmc}.


Finally, it was recently shown in \citet{corenflos2022sequentialized} that divide-and-conquer methods can be leveraged to provide consistent PIT solutions for smoothing, pMCMC and pGibbs algorithms at the cost of additional variance in the resulting estimates, providing a SMC counterpart to the algorithms of \citet{Sarkka2021temporal,yaghoobi2021parallel,Yaghoobi2022sqrt}.



\subsection{Proofs for Theorem \ref{contrastive_main}}\label{proof_contrastive_main}
In this section, we prove Theorem \ref{contrastive_main}. Suppose that $\hat\theta,\hat\beta$ are the outputs of Algorithm \ref{mle+erm}. Let $\ell$ be the squared loss and $\tilde{\ell}$ be its truncation with truncation level $L$. The optimal predictor defined in \eqref{opt_est} has the following closed form solution
\%
g_{\theta,\beta}(x)=\E_{\theta,\beta}[y\,|\,x]=\beta^T f_{\theta}(x).
\%

We have the following guarantees.

\begin{lemma}\label{contrastive_lemma1} Let the truncation level $L=36(D^2+1)\log n$. It then holds that
\%
\sup_{\theta,\beta}\big\{\E_{\theta^* ,\beta^* }\big[\ell\big(g_{\theta,\beta}(x),y\big)\big]-\E_{\theta^* ,\beta^* }\big[\tilde{\ell}\big(g_{\theta,\beta}(x),y\big)\big]\big\}\leq \sqrt{\frac{18(D^2+1)\log n}{\pi n}}.
\%
\end{lemma}
\begin{proof}[Proof of Lemma \ref{contrastive_lemma1}]
Note that
\%
\big(g_{\theta,\beta}(x)-y\big)\big|x=\big(\beta^T f_{\theta}(x)-y\big)\big|x\sim\mN\big(\beta^T f_{\theta}(x)-\beta^{* T} f_{\theta^* }(x),1\big)
\%
We denote by $c(x):=\beta^T f_{\theta}(x)-\beta^{* T} f_{\theta^* }(x)$. It holds that $|c(x)|\leq 2D$. Thus, it holds for any $\theta,\beta$ that
\%
&\E_{\theta^* ,\beta^* }\big[\ell\big(g_{\theta,\beta}(x),y\big)-\tilde{\ell}\big(g_{\theta,\beta}(x),y\big)\,\big|\, x\big]\notag\\
&=\E_{\theta^* ,\beta^* }\Big[\Big(\big(g_{\theta,\beta}(x)-y\big)^2-L\Big)\mathds{1}_{\{(g_{\theta,\beta}(x)-y)^2>L\}}\,\big|\,x\Big]\notag\\
&=\int^{{+\infty}}_{\sqrt{L}} (u^2-L)\cdot\frac{1}{\sqrt{2\pi}}e^{-\frac{\big(u-c(x)\big)^2}{2}}\,du\notag\\
&=\int^{{+\infty}}_{\sqrt{L}-c(x)}\big((u+c(x))^2-L\big)\cdot\frac{1}{\sqrt{2\pi}}e^{-\frac{u^2}{2}}\,du\notag\\
&=\frac{\sqrt{L}+c(x)}{\sqrt{2\pi}}e^{-\frac{\big(\sqrt{L}-c(x)\big)^2}{2}}+\frac{1+c(x)^2-L}{\sqrt{2\pi}}\int^{{+\infty}}_{\sqrt{L}-c(x)}e^{-\frac{u^2}{2}}\,du\notag\\
&\leq \frac{\sqrt{L}+c(x)}{\sqrt{2\pi}}e^{-\frac{\big(\sqrt{L}-c(x)\big)^2}{2}} \quad(L\geq 4D^2+1\geq c(x)^2+1)\notag\\
&\leq \frac{2(\sqrt{L}-c(x))}{\sqrt{2\pi}}e^{-\frac{\big(\sqrt{L}-c(x)\big)^2}{2}} \quad(L\geq 36D^2\geq (3c(x))^2)\notag\\
&\leq \frac{2(\sqrt{L}-2D)}{\sqrt{2\pi}}e^{-\frac{\big(\sqrt{L}-2D\big)^2}{2}}\notag\\
&\leq \frac{\sqrt{L}}{\sqrt{2\pi}}e^{-\frac{L}{8}}\quad(\sqrt{L}-2D\geq\frac{\sqrt{L}}{2})
\%
As a result, we show that
\%
&\sup_{\theta,\beta}\big\{\E_{\theta^* ,\beta^* }\big[\ell\big(g_{\theta,\beta}(x),y\big)\big]-\E_{\theta^* ,\beta^* }\big[\tilde{\ell}\big(g_{\theta,\beta}(x),y\big)\big]\big\}\notag\\
&\leq \E_{\theta^* ,\beta^* }\Big[\sup_{\theta,\beta}\E_{\theta^* ,\beta^* }\big[\ell\big(g_{\theta,\beta}(x),y\big)-\tilde{\ell}\big(g_{\theta,\beta}(x),y\big)\,\big|\, x\big]\Big]\notag\\
&\leq \frac{\sqrt{L}}{\sqrt{2\pi}}e^{-\frac{L}{8}}\notag\\
&\leq \sqrt{\frac{18(D^2+1)\log n}{\pi n}}. \quad(L=36(D^2+1)\log n)
\%
\end{proof}


\begin{lemma}\label{contrastive_lemma2} Suppose that $\hat\theta,\hat\beta$ are the outputs of Algorithm \ref{mle+erm}. Let $\tilde{\ell}$ be the truncated squared loss with truncation level $L$. Then there exists an absolute constant $c$ such that with probability at least $1-\delta$ that
\%
&\E_{\theta^* ,\beta^* }\big[\tilde{\ell}\big(g_{\hat\theta,\hat\beta}(x),y\big)\big]-\E_{\theta^* ,\beta^* }\big[\tilde{\ell}\big(g_{\theta^* ,\beta^* }(x),y\big)\big]\notag\\
&\leq c\kappa L\cdot\sqrt{\frac{1}{m}\log\frac{N_{\b}\big(\mP_{\mathcal{X}\times\mathcal{S}}(\mathcal{F}_{\theta}),1/m^2\big)}{\delta}}+cL\sqrt{\frac{\log 1/\delta}{n}}+c\sqrt{L}\sup_{\theta\in\Theta}R_n(\mathcal{G}_{\theta,\mathcal{B}}),
\%
where
\$
\kappa=c_3\sqrt{\frac{1}{\sigma_{\min}\big(\E[f_{\theta^* }(x)f_{\theta^* }(x)^{T}]\big)}}
\$
for some absolute constants $c_3$. Here $R_n(\mathcal{G}_{\theta,\mathcal{B}})$ is the Rademacher complexity defined as
\%
R_n(\mathcal{G}_{\theta,\mathcal{B}})=\E\bigg[\sup_{\beta\in\mathcal{B}}\frac{2}{n}\sum^n_{i=1}\sigma_ig_{\theta,\beta}(x_i)\bigg],
\%
where $\sigma_i$ are Rademacher random variables.
\end{lemma}
\begin{proof}[Proof of Lemma \ref{contrastive_lemma2}]
With Lemma \ref{same_prediction} and Lemma \ref{contrastive_ti} in hand, Lemma \ref{contrastive_lemma2} follows directly from Theorem \ref{weak_error_bound} and the fact that $\tilde\ell$ is $2\sqrt{L}$-Lipschitz.

\end{proof}

With Lemma \ref{contrastive_lemma1} and Lemma \ref{contrastive_lemma2} in hand, we are now ready to prove Theorem \ref{contrastive_main}.

\begin{proof}[Proof of Theorem \ref{contrastive_main}]
Note that
\%
{\rm Error}_{\ell}(\hat\theta,\hat\beta)&=\E_{\theta^* ,\beta^* }\big[\ell\big(g_{\hat\theta,\hat\beta}(x),y\big)\big]-\E_{\theta^* ,\beta^* }\big[\ell\big(g_{\theta^* ,\beta^* }(x),y\big)\big]\notag\\
&=\E_{\theta^* ,\beta^* }\big[\ell\big(g_{\hat\theta,\hat\beta}(x),y\big)\big]-\E_{\theta^* ,\beta^* }\big[\tilde{\ell}\big(g_{\hat\theta,\hat\beta}(x),y\big)\big]\notag\\
&\quad+\E_{\theta^* ,\beta^* }\big[\tilde\ell\big(g_{\hat\theta,\hat\beta}(x),y\big)\big]-\E_{\theta^* ,\beta^* }\big[\tilde\ell\big(g_{\theta^* ,\beta^* }(x),y\big)\big]\notag\\
&\quad+\E_{\theta^* ,\beta^* }\big[\tilde\ell\big(g_{\theta^* ,\beta^* }(x),y\big)\big]-\E_{\theta^* ,\beta^* }\big[\ell\big(g_{\theta^* ,\beta^* }(x),y\big)\big]\notag\\
&\leq \sup_{\theta,\beta}\big\{\E_{\theta^* ,\beta^* }\big[\ell\big(g_{\theta,\beta}(x),y\big)\big]-\E_{\theta^* ,\beta^* }\big[\tilde{\ell}\big(g_{\theta,\beta}(x),y\big)\big]\big\}\notag\\
&\quad +\E_{\theta^* ,\beta^* }\big[\tilde\ell\big(g_{\hat\theta,\hat\beta}(x),y\big)\big]-\E_{\theta^* ,\beta^* }\big[\tilde\ell\big(g_{\theta^* ,\beta^* }(x),y\big)\big].
\%
Let the truncation level be $L=36(D^2+1)\log n$. By Lemma \ref{contrastive_lemma1} and Lemma \ref{contrastive_lemma2}, we have
\%\label{101510}
&{\rm Error}(\hat\theta,\hat\beta)\notag\\
&\leq c\kappa L\cdot\sqrt{\frac{1}{m}\log\frac{N_{\b}\big(\mP_{\mathcal{X}\times\mathcal{S}}(\mathcal{F}_{\theta}),1/m^2\big)}{\delta}}+cL\sqrt{\frac{\log 1/\delta}{n}}+c\sqrt{L}\sup_{\theta\in\Theta}R_n(\mathcal{G}_{\theta,\mathcal{B}})\notag\\
&\quad+\sqrt{\frac{18(D^2+1)\log n}{\pi n}}.
\%
% \%\label{101510}
% &{\rm Error}(\hat\theta,\hat\beta)\notag\\
% &\leq 36c(D^2+1)\log n\sqrt{\frac{1}{\sigma_{\min}\big(\E[f_{\theta^* }(x)f_{\theta^* }(x)^{T}]\big)}}\cdot\sqrt{\frac{1}{m}\log\frac{N_{\b}\big(\mP(\mathcal{F}_{\theta}),1/m^2\big)}{\delta}}\notag\\
% &\quad+36c(D^2+1)\log n\sqrt{\frac{\log 1/\delta}{n}}+6c\sqrt{(D^2+1)\log n}\sup_{\theta\in\Theta}R_n(\mathcal{G}_{\theta,\mathcal{B}})+\sqrt{\frac{18(D^2+1)\log n}{\pi n}}.
% \%
For the Rademacher complexity, we have
\%\label{101511}
R_n(\mathcal{G}_{\theta,\mathcal{B}})&=\E\bigg[\sup_{\beta\in\mathcal{B}}\frac{2}{n}\sum^n_{i=1}\sigma_i g_{\theta,\beta}(x_i)\bigg]\notag\\
&=\E\bigg[\sup_{\beta\in\mathcal{B}}\frac{2}{n}\sum^n_{i=1}\sigma_i \beta^T f_{\theta}(x_i)\bigg]\notag\\
&\leq \frac{2D}{\sqrt{n}},
\%
where the last inequality follows from Lemma \ref{factor_rc}. Combining \eqref{101510} and \eqref{101511}, we have
\%
&{\rm Error}(\hat\theta,\hat\beta)\notag\\
&\leq c\kappa L\cdot\sqrt{\frac{1}{m}\log\frac{N_{\b}\big(\mP_{\mathcal{X}\times\mathcal{S}}(\mathcal{F}_{\theta}),1/m^2\big)}{\delta}}+cL\sqrt{\frac{\log 1/\delta}{n}}+2cD\sqrt{\frac{L}{n}}\notag\\
&\quad+\sqrt{\frac{18(D^2+1)\log n}{\pi n}}\notag\\
&=\tilde{\mathcal{O}}\bigg(\kappa L\sqrt{\frac{\log N_{\b}\big(\mP_{\mathcal{X}\times\mathcal{S}}(\mathcal{F}_{\theta}),1/m^2\big)}{m}}+L\sqrt{\frac{1}{n}}\bigg),
\%
where $L=36(D^2+1)\log n$ and 
\$
\kappa=c_3\sqrt{\frac{1}{\sigma_{\min}\big(\E[f_{\theta^* }(x)f_{\theta^* }(x)^{T}]\big)}}
\$
for some absolute constants $c_3$.
% \%
% &{\rm Error}(\hat\theta,\hat\beta)\notag\\
% &\leq 36c(D^2+1)\log n\sqrt{\frac{1}{\sigma_{\min}\big(\E[f_{\theta^* }(x)f_{\theta^* }(x)^{T}]\big)}}\cdot\sqrt{\frac{1}{m}\log\frac{N_{\b}\big(\mP(\mathcal{F}_{\theta}),1/m^2\big)}{\delta}}\notag\\
% &\quad+36c(D^2+1)\log n\sqrt{\frac{\log 1/\delta}{n}}+12cD\sqrt{\frac{(D^2+1)\log n}{n}}+\sqrt{\frac{18(D^2+1)\log n}{\pi n}}\notag\\
% &=\tilde{\mathcal{O}}\bigg(\sqrt{\frac{\log N_{\b}\big(\mP(\mathcal{F}_{\theta}),1/m^2\big)}{m}}+\sqrt{\frac{1}{n}}\bigg).
% \%
\end{proof}
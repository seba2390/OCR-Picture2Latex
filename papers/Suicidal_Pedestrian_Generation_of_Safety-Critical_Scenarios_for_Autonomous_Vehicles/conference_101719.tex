%\documentclass[conference]{IEEEtran}
\documentclass[letterpaper, 10 pt, conference]{ieeeconf}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\overrideIEEEmargins
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}


%%%%%%%%%%% self-added packages change the table title into lowercase and in one line
\usepackage{fancyhdr}
\usepackage{algorithm} % added for pseudo algorithm
\usepackage{booktabs} % added
\usepackage{subfigure} % added
\usepackage{etoolbox}
\makeatletter
\patchcmd{\@makecaption}
  {\scshape}
  {}
  {}
  {}
\makeatletter
\patchcmd{\@makecaption}
  {\\}
  {.\ }
  {}
  {}
\makeatother

\usepackage{caption}
\captionsetup[table]{justification=raggedright, singlelinecheck=true} 

%%%%%%%%%%

\newcommand{\Rs}{R_1}
\newcommand{\Rc}{R_2}


\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{\LARGE \bf Suicidal Pedestrian: Generation of Safety-Critical Scenarios for Autonomous Vehicles
\thanks{The work is supported by FCAI (Finnish Center for Artificial Intelligence)}
}

% PINs
% Yuhang: 63093
% Kalle: 63079
% Amin: 63113
% Joni: 63098
% Alex: 63089

% \author{\IEEEauthorblockN{Yuhang Yang}
% \IEEEauthorblockA{\textit{Departement of Computer Science} \\
% \textit{Aalto University}\\
% Espoo, Finland \\
% yuhang.yang@aalto.fi}
% \and
% \IEEEauthorblockN{Kalle Kujanpää}
% \IEEEauthorblockA{\textit{Departement of Computer Science} \\
% \textit{Aalto University}\\
% Espoo, Finland \\
% kalle.kujanpaa@aalto.fi}
% \and
% \IEEEauthorblockN{Amin Babadi}
% \IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
% \textit{name of organization (of Aff.)}\\
% City, Country \\
% email address or ORCID}
% \and
% \IEEEauthorblockN{Joni Pajarinen}
% \IEEEauthorblockA{\textit{Department of Electrical Engineering and Automation} \\
% \textit{Aalto University}\\
% Espoo, Finland \\
% joni.pajarinen@aalto.fi}
% \and
% \IEEEauthorblockN{Alexander Ilin}
% \IEEEauthorblockA{\textit{Departement of Computer Science} \\
% \textit{Aalto University}\\
% Espoo, Finland \\
% alexander.ilin@aalto.fi}
% }



\author{Yuhang Yang$^{1}$, Kalle Kujanpää$^{2}$, Amin Babadi$^{3}$, Joni Pajarinen$^{1}$, and Alexander Ilin$^{2}$
\thanks{$^{1}$Yuhang Yang and Joni Pajarinen are with the Department of Electrical Engineering and Automation, Aalto University, Espoo, Finland. {\tt\footnotesize yuhang.yang@aalto.fi}; {\tt\footnotesize joni.pajarinen@aalto.fi}}
\thanks{$^{2}$Kalle Kujanpää and Alexander Ilin are with the Department of Computer Science, Aalto University, Espoo, Finland. {\tt\footnotesize kalle.kujanpaa@aalto.fi}; {\tt\footnotesize alexander.ilin@aalto.fi}}
\thanks{$^{3}$Amin Babadi is with Bugbear Entertainment Oy. Helsinki, Finland. Work done while at Aalto University. {\tt\footnotesize amin.babadi@bugbear.fi}}
}




% For commenting
\newcommand{\kalle}[1]{\textcolor{green}{Kalle: #1}}
\newcommand{\alex}[1]{\textcolor{blue}{Alex: #1}}
\newcommand{\joni}[1]{\textcolor{red}{Joni: #1}}


\maketitle


\thispagestyle{fancy}
\fancyhead{}
\rhead{}
\lfoot{26th IEEE International Conference on Intelligent Transportation Systems (ITSC 2023), Bilbao, Bizkaia, Spain}
\cfoot{\quad}
\renewcommand{\headrulewidth}{0pt}

%\thispagestyle{empty}
\pagestyle{empty}



\begin{abstract}

Developing reliable autonomous driving algorithms poses challenges in testing, particularly when it comes to safety-critical traffic scenarios involving pedestrians. An open question is how to 
simulate rare events, not necessarily found in autonomous driving datasets or scripted simulations, but which can occur in testing, and, in the end may lead to severe pedestrian related accidents.
This paper presents a method for designing a suicidal pedestrian agent within the CARLA simulator, enabling the automatic generation of traffic scenarios for testing safety of autonomous vehicles (AVs) in dangerous situations with pedestrians.
The pedestrian is modeled as a reinforcement learning (RL) agent with two custom reward functions that allow the agent to either arbitrarily or with high velocity to collide with the AV.
%Kalle's proposal
Instead of significantly constraining the initial locations and the pedestrian behavior, we allow the pedestrian and autonomous car to be placed anywhere in the environment and the pedestrian to roam freely to generate diverse scenarios.
%Original: By allowing the pedestrian to freely explore the environment while maintaining a constrained initial distance from the vehicle, the generated scenarios offer greater diversity as the pedestrian and autonomous car can be placed anywhere.
%Joni's proposal: Since we allow RL to choose pedestrian behavior and starting position from a limited distance, and the AV position, the system finds automatically interesting dangerous scenarios.
To assess the performance of the suicidal pedestrian and the target vehicle during testing, we
propose three collision-oriented evaluation metrics. Experimental results involving two state-of-the-art autonomous driving algorithms trained end-to-end with imitation learning from sensor data demonstrate the effectiveness of the suicidal pedestrian in identifying decision errors made by autonomous vehicles controlled by the algorithms. 

%state-of-the-art autonomous vehicles \joni{We should make also this more accurate similarly to the previous comment}.

%\joni{Comment: there are a lot of different kinds of autonomous driving algorithms, related to
%sensor processing, path planning, control etc. We should clearly say which level of abstraction we focus on. We are focusing on end-to-end learning? And state-of-the-art "autonomous driving algorithms" learn end-to-end driving using low level control from images?}

%\joni{Hmm, actually what we mean with "autonomous driving algorithm", is defined in Fig.1 caption. Maybe just say end-to-end autonomous driving algorithm, or, use some other specification. Some people may not check the caption.}

%\kalle{end-to-end imitation learning from sensor data}


% specifically trained using a model-free learning algorithm incorporating 

% By allowing the pedestrian to freely explore the environment while maintaining a constrained initial distance from the vehicle, the generated scenarios offer greater diversity as the pedestrian and autonomous car can be placed anywhere. 

% Additionally, three collision-oriented evaluation metrics are proposed to assess the performance of the suicidal pedestrian and the target vehicle during testing. Experimental results involving two state-of-the-art autonomous driving algorithms demonstrate the effectiveness of the suicidal pedestrian in identifying decision errors made by autonomous vehicles in pedestrian-related traffic scenarios.

\end{abstract}

% \begin{IEEEkeywords}
% %traffic scenario generation,
% autonomous vehicle testing, reinforcement learning, adversarial learning
% \end{IEEEkeywords}






\section{Introduction} 

Autonomous driving (AD) is a captivating field of research that holds great potential for enhancing household mobility, optimizing traffic efficiency, and ensuring safety. In recent years, AD has gained considerable attention, and remarkable advancements have been made. Two approaches have emerged: modular driving systems that design and train each sub-module separately according to its functions \cite{modular_survey, efficient_control_avoidance}, and end-to-end models that directly perform decisions based on raw sensor inputs \cite{learning_in_one_day,learningbycheating}. However, despite these advancements, deploying AD on a large scale remains a significant challenge. A crucial reason for this is the difficulty, danger, and time-consuming nature of testing and validating autonomous vehicles (AVs), particularly in scenarios involving pedestrian safety.



\begin{figure}[htbp]
    \centerline
    {
        \includegraphics[width=1.0\linewidth]{Proposed_framework.jpg}
    }
    \caption{Overview of the proposed suicidal pedestrian traffic scenario. The autonomous vehicle (AV) is controlled by an autonomous driving (AD) algorithm, which takes inputs from various sensors, producing low-level control commands to drive the vehicle safely. The pedestrian, modeled as a reinforcement learning (RL) agent, observes the location and velocity of the vehicle, and tries to hit the car with an adversarial policy learned from reward feedback.}
    \label{fig:method_framework}
\end{figure}



Several datasets \cite{vision_kitti, waymo_dataset, semantickitti} have been provided for AV testing. However, most of these manually collected data contain few safety-critical scenarios, rendering a severe overestimation of the safety performance of the testing vehicle. Other popular practices for AV testing focus on generating traffic scenarios \cite{traffic_scenario_2, traffic_scenario_3, traffic_scenario_deeproad}. While these practices enrich the range of test scenarios and expedite the validation process, they are often limited to specific scenes, such as highways or intersections, and do not adequately consider pedestrian interactions.


In this paper, we propose a method for automatically generating pedestrian-related, safety-critical traffic scenarios specifically for AV testing. By optimizing the pedestrian's behavior in the scene, we guide the pedestrian to exhibit suicidal actions with the intention of colliding with the moving car, thereby forcing the vehicle to take emergency actions. To achieve this, we formulate the suicidal pedestrian as a reinforcement learning (RL) agent and train it using a model-free RL algorithm. Additionally, to enable the pedestrian to adapt to various scenes, we design an observation space based on pedestrian characteristics and impose constraints on the initial distance between the test vehicle and the pedestrian. To demonstrate the effectiveness of our approach in generating suicidal pedestrian-based scenarios, we conduct extensive experiments in different environments, employing diverse driving policies.


The main contributions of this paper are as follows:
\begin{enumerate}
\item {Proposing a method for generating pedestrian-related safety-critical traffic scenarios dedicated to AV testing.} 
\item {Designing a suicidal pedestrian as an RL agent that aims to collide with the AV under test and training the agent using a model-free RL algorithm.}
\item {Generalizing %the behavior of
the suicidal pedestrian to test various driving policies in different environments after training it against a specific driving agent in limited situations.}
\item {Experimentally demonstrating the effectiveness of our suicidal pedestrian in identifying AV decision failures through testing with two state-of-the-art AD algorithms.}
\end{enumerate}







\section{Related work} 


\subsection{Traffic Scenario Generation for Vehicle Testing}

Traffic scenario generation for vehicle testing aims to construct diverse traffic situations using simulators in order to expedite and streamline the AV testing process because real-world testing can be dangerous and expensive, particularly for safety-critical scenarios.

Recently, a lot of research has been presented on traffic scenario generation \cite{traffic_scenario_1, traffic_scenario_2, traffic_scenario_3, traffic_scenario_deeproad}. In \cite{traffic_scenario_2}, an adversarial driving scenario for AV testing is proposed, which involves training an adversarial car using Bayesian optimization and modeling the unknown cumulative performance of the test agent as a Gaussian process. Another work \cite{traffic_scenario_1} models a three-agent environment to test AVs for detecting decision errors and improve their performance through a two-step training framework. The first step involves training an adversarial vehicle to identify failures in the test cars, while the second step focuses on retraining the autonomous car based on these failure states to enhance its robustness. Furthermore, authors in \cite{traffic_scenario_3} propose an intelligent testing environment to validate the statistical capacity boundary of AVs in an accelerated mode. By removing non-safety-critical states and reconnecting critical ones, the Markov decision process (MDP) is modified to contain only relevant information, thereby densifying the training data and reducing the time required for AV testing. However, these studies pay little attention to pedestrians, limiting their applicability.



More recent works have further studied the behavior of pedestrians. In \cite{traffic_scenario_4}, pedestrians are trained to cross roads through crosswalks when a test vehicle approaches. However, the pedestrian trajectory is pre-scripted, constraining the proposed method from being generalized to other environments. Drawing inspiration from various existing pedestrian models \cite{pedestrian_model_1, traffic_scenario_simulation_6}, a pedestrian-placement model \cite{traffic_scenario_simulation_5} learns to adversarially synthesize test scenarios to increase the likelihood of collisions with a test AV given a fixed driving policy and pedestrian behavior model. However, this approach was not evaluated against state-of-the-art AD algorithms.
%a pedestrian-placement model \cite{traffic_scenario_simulation_5} is proposed to learn the optimal placement of pedestrians in a way that increases the likelihood of collisions with a test AV, rather than directly controlling their actions or trajectories. This method comprises three components. The first two components are the AV algorithm and the pedestrian behavior model, both of which are frozen and remain unchanged. The last component is the learnable adversarial test synthesizer that learns to initialize the pedestrian in an appropriate location according to the selected pedestrian behavior model, occlusions, and scene semantics.



\subsection{Reinforcement Learning}

RL algorithms guide agents to interact with the environment and to learn behaviors through a trial-and-error style without explicit human supervision. %\cite{sutton2018reinforcementbook}.
The RL problems are modeled as MDPs and the objective of RL is to maximize the rewards in the MDP by learning how to act.
%, and they are widely used to solve MDP problems. 
Specifically, for a given MDP, RL algorithms 
aim to learn an optimal policy $\pi^{*}(s)$ that maximizes the expectation of the cumulative discounted return for every state $s \in \mathcal{S}$:
\begin{equation}
    \max \limits_{\pi} \mathbb{E}\bigg [\sum^{T}_{t=0} \gamma^{t} R_{t+1} \bigg | s \bigg],
    \label{equation_Return}
\end{equation}
where $T$ is the time horizon, $\gamma$ the discount factor, and $R$ the reward function that at each step $t$ depends on the action $a_t$ taken by the policy $\pi$ in state $s_t$.
%$V$ is the value function, $\pi(s_t)$ the action chosen in state $s_t$, $R$ the reward function, $\gamma$ the discount factor, $\mathcal{S}$ the state space, and $T$ the time horizon. We use a finite $T$.
% that can maximize the expectation of cumulative discounted reward for every initial state $s_0 \in \mathcal{S}$:
% \begin{equation}
%     V_{\pi^{*}}(s_0) = \max \limits_{\pi} \mathbb{E}\bigg(\sum^{T}_{t=0} {\gamma^{t} R(s_{t+1}, s_{t}, \pi(s_t))} \bigg),
% \label{equation_Return}
% \end{equation}
%where $V$ is the value function, $\pi(s_t)$ the action chosen in state $s_t$, $R$ the reward function, $\gamma$ the discount factor, $\mathcal{S}$ the state space, and $T$ the time horizon. We use a finite $T$.

%T the finite or infinite time horizon. In our settings, T is finite.

%There exist many RL algorithms.
%Based on their methodology,
% RL algorithms can be categorized into two types: model-free algorithms and model-based algorithms. Model-free algorithms learn policies to directly maximize the rewards without an explicit model of the environment, that is they assume the environment is a black box that only produces rewards for agent actions. In contrast, model-based algorithms learn a model of the environment dynamics,
%transition and reward functions to describe the environment mechanism
%then optimize the behavior with the learned model.

In the AD area, RL algorithms have been widely used either for developing new driving systems %\cite{end_to_end_model_free_RL_driving, chekroun2021gri, chen2021worldonrail}
\cite{end_to_end_model_free_RL_driving, chen2021worldonrail} or for generating traffic scenarios \cite{adaptive_testing, adaptive_testing_augmentation, zero-shot}. %Our work is also highly related to RL. %Specifically,
We model the traffic scenario as an MDP and train our suicidal pedestrian using a model-free RL algorithm, PPO \cite{PPO}.







\section{Method}

Our work focuses on the generation of safety-critical traffic scenarios involving pedestrians to facilitate the testing of AVs in urban settings. As illustrated in Fig. \ref{fig:method_framework}, the generated scenarios contain two agents: the AV being tested and the suicidal pedestrian (Section~\ref{Method_Pedestrain_modeling}). The AV is controlled by some state-of-the-art driving algorithms, which take sensor observations as inputs and produce low-level commands such as steering angle and acceleration to ensure safe driving. On the other hand, the pedestrian, modeled as an RL agent and trained with a model-free RL algorithm (Section~\ref{Method_Policy_optimization}), observes the location and motion of the AV and attempts to collide with the car, thereby causing the AV failure. Generating the training scenarios involving the pedestrian and the target vehicle is a non-trivial process. If the pedestrian and vehicle are too close to each other, causing a collision can be very easy, and if they are far away or move in opposite directions, it is very difficult. To address this issue, we constrain the set of initial states (Section~\ref{Method_Policy_optimization}).%(Section~\ref{Method_Pedestrain_Vehicle_constraint}).

%This is a constrained minimax game, where the vehicle and pedestrian have opposite objectives. Solving this minimax game can be either trivial if the pedestrian and vehicle are too close to each other or extremely difficult if they are far or move in opposite directions. Therefore, our method establishes sufficient initial distance constraints between the vehicle and pedestrian to circumvent these issues (Section~\ref{Method_Pedestrain_Vehicle_constraint}).

% Our work focuses on the generation of safety-critical traffic scenarios involving pedestrians to facilitate the testing of AVs in urban settings. As illustrated in Fig. \ref{fig:method_framework}, the generated scenarios contain two agents: the AV being tested and the suicidal pedestrian. The AV is controlled by some state-of-the-art driving algorithms, which take sensor observations as inputs and produce low-level commands such as steering angle and acceleration to ensure safe driving. On the other hand, the pedestrian, modeled as an RL agent, observes the location and motion of the AV and attempts to collide with the car, thereby causing the AV failure. The detailed design of the pedestrian is described in Section \ref{Method_Pedestrain_modeling}.

% In our approach, the AV agent and the suicidal pedestrian play an indirectly constrained minimax game, where the vehicle aims to avoid collisions while the pedestrian seeks the opposite situation. However,  solving this minimax game can be either trivial if the pedestrian and vehicle are too close to each other or entirely impossible if they are far and move in opposite directions. Therefore, our method establishes sufficient initial distance constraints between the vehicle and pedestrian to circumvent these issues. Section \ref{Method_Pedestrain_Vehicle_constraint} provides a description of these constraints.

% Furthermore, we employ a model-free RL algorithm to train our suicidal pedestrian, enabling the creation of collision scenarios. Section \ref{Method_Policy_optimization} outlines the algorithm and its selected hyperparameters.




\subsection{Walking as a Markov Decision Process} \label{Method_Pedestrain_modeling}

One of the central challenges addressed in this paper is formulating the testing scenario as a Markov decision process (MDP). Given that the testing AV is already well-trained with fixed driving policies, our focus lies on modeling the pedestrian. Consequently, it becomes crucial to precisely define the state space $S$, action space $A$, and reward function $R$ for the pedestrian. The state transition dynamics are implicitly determined by the simulator once the aforementioned three elements are established.



\textit{1) State Space}: The state input for our suicidal pedestrian agent captures how the agent perceives the environment. Since the pedestrian can successfully collide with the car by knowing the vehicle's position and velocity information, a finite-dimensional vector containing this information suffices for our collision-seeking suicidal pedestrian. Additionally, we consider how to represent the position and velocity. It can either be directly represented in world coordinates 
%using an absolute form 
or in a relative form by describing it in the pedestrian coordinate system via coordinate transformation. In this paper, we adopt the relative representation due to its rotation and translation invariance, which enhances the generalization capability of our suicidal pedestrian.

Therefore, we use the following state space:
\begin{equation}
    s=[\alpha, d,\beta, v]
\end{equation}
where $\alpha$ is the angle of direction and $d$ the distance to the target vehicle from the pedestrian, $\beta$ is the relative direction in which the target vehicle is moving and $v$ is the relative scalar speed.  

\textit{2) Action Space}: The action of our suicidal pedestrian is determined by the forward direction angle and the scalar velocity. The forward direction angle, ranging from $[-\pi, \pi]$, specifies what direction the pedestrian will walk toward, while the scalar velocity ranging from [0, 3.5] in $m/s$ describes how fast the pedestrian is. Notably, since the input state is represented in the pedestrian coordinate, the output action is also represented in this coordinate. However, both the pedestrian agent and the AV move in the environment defined in the world coordinate. Therefore, the pedestrian action, especially for its forward direction angle, must be transformed back to the world coordinates. % to avoid potential errors.



\textit{3) Reward Functions}: The reward function plays an essential role in training the pedestrian policy.
%In order to illustrate that a pedestrian with a velocity-proportional and collision-part-different reward can lead to creating more complex and unpredictable adversarial behaviors than the collision-focus pedestrian agent, two different types of reward functions are designed: the constant reward function $\Rs$ and the combinational reward function $\Rc$.
We have considered two types of rewards:
\begin{itemize}
\item Reward $\Rs$ which aims to maximize the collision rate without considering the velocity of the vehicle:
\begin{equation*}
    \Rs = \left\{
    \begin{aligned}
        1, & \quad\text{if hit the vehicle} \\
        0, & \quad\text{otherwise} \\
    \end{aligned}
    \right.
\label{reward_function:constant}
\end{equation*}

\item Reward $\Rc$  which encourages the pedestrian to generate the most hazardous collisions by encouraging collisions when the vehicle is driving at high speeds:
\begin{equation*}
\Rc = \left\{
    \begin{aligned}
        \max(3, 1.5 v_c),& \ \text{if hit the front of vehicle} \\
        \max(1, 0.5 v_c),& \ \text{if hit other parts of vehicle} \\
        0, & \ \text{otherwise} \\
    \end{aligned}
    \right.
\label{reward_function:combinational}
\end{equation*}
where $v_c$ is the velocity of the vehicle when the collision happens. The shaped reward forms a natural curriculum and helps learn complex and unpredictable behaviors, such as exploiting occluded areas, required to fool the AD algorithms into dangerous frontal collisions.  
%, for example, the agent learns to use occluded areas, such as the front corners to collide with the vehicle.

\end{itemize}

\begin{table}[t]
\caption{The PPO hyperparameters}
\centering
%\renewcommand{\arraystretch}{1.2}
%\resizebox{0.45\textwidth}{!}{ %
\begin{tabular}{ll}
\hline
\textbf{Parameter} & \textbf{Value} \\ \hline
No. total training steps & 70000 \\
No. epochs when optimizing the surrogate loss & 10 \\
No. env. steps to run per update & 150 \\
Batch size & 64 \\  %\hline
Learning rate for actor and critic networks %$\lambda$
& $3 \times 10^{-4}$ \\
Discount factor %$\gamma$
& 0.98 \\
%Bias-variance trade-off factor for GAE %$\lambda_{gae}$
$\lambda$ for Generalized Advantage Estimate (GAE) 
& 0.95 \\
Objective clipping value %$\lambda_{clip}$
& 0.2 \\ %\hline
Value loss coefficient & 0.5 \\
Entropy regularization coefficient & 0.01 \\
\hline
\end{tabular}
%}%
\label{tab:PPO_train_parameter}
\end{table}


%On the other hand, $\Rc$ considers more conditions when maximizing the collision rate. First, the pedestrian should behave more positively to hitting the vehicle, i.e., it needs to collide with a vehicle driving at high speed as much as possible. Second, the pedestrian should perform complex and unpredictable behaviors to cheat the vehicle. Rather than hitting the car from the central front, it is preferred to create collisions from some view-occlusion areas, such as the front corners or sides of the vehicle. To this end, $\Rc$ is formulated as:



% Furthermore, to ensure collision diversity and complexity, the front collision part in 
% \eqref{reward_function:combinational} is intentionally designed to contain some areas from the sides. Specifically, the front collision part covers the area ranging from $[-60^{\circ}, 60^{\circ}]$ along the forward x-axis of the vehicle, with the car center as the origin.


\subsection{Policy Optimization} \label{Method_Policy_optimization}

We use a continuous-action model-free RL algorithm Proximal Policy Optimization (PPO) \cite{PPO} to train the suicidal pedestrian.
%The PPO performs online learning in each training episode and outputs a policy, i.e., a probability distribution function to represent the strategy. %Furthermore, it is a policy-based RL algorithm.
%PPO uses the policy gradients to update its current policy by increasing the probability of actions that bring higher returns. 
%strategy and utilizes the received reward to weaken or enhance the probability of chosen behaviors so that behaviors that bring higher returns are more likely to be selected.
We estimate the advantage function %for the policy updates 
with GAE \cite{gae}, and use the hyperparameters described in Table~\ref{tab:PPO_train_parameter}.


%\subsection{Pedestrian-Vehicle Initial Distance Constraint} \label{Method_Pedestrain_Vehicle_constraint}

%The pedestrian agent should be properly initialized nearby the vehicle; otherwise, it may be too trivial or too difficult for this agent to hit the vehicle.
At the beginning of each episode, we spawn the pedestrian close to the vehicle within a sector area from $-60^{\circ}$ to $60^{\circ}$ based on the forward direction of the vehicle, with the distance varying from 7m to 30m. This creates a task of a suitable difficulty level. When the distance is lower, it is easier to hit the vehicle. On the other hand, a larger distance allows the pedestrian to learn more complex behaviors, thus enhancing the diversity of the generated traffic scenarios.
%One advantage of this design is that with a distance increase, the pedestrian can show more complex behaviors when approaching the car, thus enhancing the diversity of the simulated traffic scene.
%If the pedestrian was initialized at an unwalkable area such as inside a static obstacle, we sample a small random offset from an uniform distribution and add that to the initial pedestrian location to fix it. %Additionally, small random offsets sampled from a uniform distribution are added to the initial location of the pedestrian to ensure that the pedestrian is initialized at walkable areas rather than static obstacles such as flowerbeds or stone piers.
%The detailed method is described in Algorithm \ref{algorithm:pedestrian_initialization}.



% \begin{algorithm}[htbp]
%     \algsetup{linenosize=\footnotesize} \footnotesize
% 	\renewcommand{\algorithmicrequire}{\textbf{Input: }}
% 	\renewcommand{\algorithmicensure}{\textbf{Output: }}
% 	\caption{Suicidal Pedestrian Initialization }
% 	\label{alg1}
% 	\begin{algorithmic}[1]
%         \REQUIRE{Pose of the test vehicle $(x_{vel}, y_{vel}, \theta_{vel})$}
        
%         \STATE {Initialization: $Flag \leftarrow False$}
%         \WHILE {$Flag=False$}
%         \STATE Randomly select a spawn point $p$ from the map
%         \STATE Calculate the distance $d$ and relative direction $\alpha$ to the vehicle pose
%         \IF {$7m \leq d \leq 30m$ \textbf{and} $-60^{\circ} \leq \alpha \leq 60^{\circ}$}
%         \FOR {$i=1,..,10$}
%         \STATE Generate an offset $x_{off}$ from a Uniform distribution
%         \STATE Update $p \leftarrow p + x_{off}$
%         \STATE Spawn the pedestrian at $p$. If succeed, set $Flag \leftarrow True$ and break
%         \ENDFOR
%         \ENDIF
%         \ENDWHILE

%         \ENSURE  {Initial location $p$ of the pedestrian}
% 	\end{algorithmic} 
% \label{algorithm:pedestrian_initialization}
% \end{algorithm}




\section{Experiments}

The experiments aim to demonstrate the effectiveness of our designed suicidal pedestrian used for generating safety-critical traffic scenarios for AV testing. To this end, we first train our suicidal pedestrian against one simple but effective rule-based AV. Later we evaluate the trained pedestrian in different environments to verify its ability to create collisions. Finally, we test two state-of-the-art AD algorithms with our trained suicidal pedestrian, exposing their decision errors when dealing with pedestrian-related traffic scenarios.




\begin{figure*}[t]
    \centerline
    {
        \includegraphics[width=.71\linewidth,trim={0 15mm 0 0},clip]
        {reward_length.png}
    }
    \caption{Average rewards (left) and average episode lengths (right) during training of the suicidal pedestrian using $\Rs$ (green) and $\Rc$ (blue). The solid line represents the mean return, and the light-colored area represents the standard deviation. All plots are smoothed by the moving average over 9 data points.}
    \label{fig:train_pedestrian_plot}
\end{figure*}






\begin{table*}[h]
    \caption{Performance of the suicidal pedestrian against the CARLA AV agent.
    The best results from the point of view of the suicidal pedestrian are shown in bold.} %, and $C_S$.} %$\uparrow$ and $\downarrow$ denote that higher/lower values represent better performance.}
    \centering
    %\renewcommand{\arraystretch}{1.1}
    %\resizebox{1.0\textwidth}{!}{%
    \begin{tabular}{c|ccc|ccc}
        \hline
        & \multicolumn{3}{c}{\textbf{Train town (Town 2)}} & \multicolumn{3}{|c}{\textbf{Test town (Town 1)}} \\ \hline
        \textbf{Reward} & \textbf{Collision rate} & \textbf{Front collision rate} &  \textbf{Moving collision rate} & \textbf{Collision rate} & \textbf{Front collision rate} & \textbf{Moving collision rate} \\ \hline

        %constant reward
        $\Rs$ & $0.84 \pm 0.05$ & $0.77 \pm 0.04$ & $0.42 \pm 0.09$ & $0.79 \pm 0.00$ & $0.73 \pm 0.05$ & $0.43 \pm 0.04$ \\
        %\hline
        %combinational reward
        $\Rc$ &$\textbf{0.90} \pm 0.03$ & $\textbf{0.82} \pm 0.05$ & $\textbf{0.55} \pm 0.01$ & $\textbf{0.86} \pm 0.02$ & $\textbf{0.80} \pm 0.04$ & $\textbf{0.54} \pm 0.05$ \\

        \hline
    % \renewcommand{\arraystretch}{1.1}
    % \resizebox{1.0\textwidth}{!}{%
    % \begin{tabular}{c|cccc|cccc}
    %     \specialrule{1.5pt}{1pt}{1pt}
    %     & \multicolumn{4}{c}{\textbf{Same town (Town 2)}} & \multicolumn{4}{|c}{\textbf{New town (Town 1)}} \\ \specialrule{1.5pt}{1pt}{1pt}
    %     \textbf{Reward type} & \textbf{Collision rate ($\uparrow$)} & \textbf{Front collision ($\uparrow$)} &  \textbf{Side collision ($\downarrow$)} & \textbf{Collision running ($\uparrow$)} & \textbf{Collision rate ($\uparrow$)} & \textbf{Front collision ($\uparrow$)} &  \textbf{Side collision ($\downarrow$)} & \textbf{Collision running ($\uparrow$)}\\ \hline

    %     %constant reward
    %     $\Rs$ & $0.84 \pm 0.05$ & $0.77 \pm 0.04$ & $0.16 \pm 0.04$ & $0.42 \pm 0.09$ & $0.79 \pm 0.00$ & $0.73 \pm 0.05$ & $0.22 \pm 0.05$ & $0.43 \pm 0.04$ \\ \hline
    %     %combinational reward
    %     $\Rc$ &$\textbf{0.90} \pm 0.03$ & $\textbf{0.82} \pm 0.05$ & $\textbf{0.15} \pm 0.03$ & $\textbf{0.55} \pm 0.01$ & $\textbf{0.86} \pm 0.02$ & $\textbf{0.80} \pm 0.04$ & $\textbf{0.17} \pm 0.01$ & $\textbf{0.54} \pm 0.05$ \\

    %     \specialrule{1.5pt}{1pt}{1pt}
    \end{tabular}
    %}%
    \label{tab:pedestrian_evaluation}
\end{table*}









\subsection{Experimental Setup}

We use CARLA \cite{dosovitskiy2017carla} open-source urban driving simulator to train and validate the designed suicidal pedestrian, as well as evaluate some state-of-the-art AD algorithms.
We use Town~1 and Town~2 provided by CARLA to build our training and test environments. These towns contain T-intersections and two-lane roads.  We chose these towns because
%The motivation behind this town choice is that 
T-intersections can provide more complex traffic scenarios and two-lane roads are the main road structure in residential areas where pedestrians are more likely to appear.
We train our suicidal pedestrian against the default CARLA AV (behavior agent) with the two different reward functions, $\Rs$ and $\Rc$, and perform three training runs.

We set the episode length to 600 timesteps and run the simulator at a speed of 20 timesteps per second. This means each episode lasts 30s unless the suicidal pedestrian collides with the vehicle. Moreover, considering the speed difference, each control command for the pedestrian is repeated for 20 timesteps, equal of 1s of simulation. At the same time, we update the command for AV every timestep to avoid accidents caused by delayed controls. 

We use the OpenAI Gym \cite{OpenAIGym} framework to wrap up our designed suicidal pedestrian. We train the pedestrian with the PPO \cite{PPO} implementation from stable-baselines3 \cite{stable-baselines3}.
%Furthermore, the PPO \cite{PPO} implementation from the stable-baselines3 \cite{stable-baselines3} toolkit is selected for training our pedestrian agent.

%\subsection{Evaluation Metrics}



We evaluate the performance using the following metrics:
\begin{itemize}
\item \textit{Collision rate}: % with the target vehicle }
an overall performance metric which specifies how often the pedestrian can result in a collision with the target vehicle.

\item \textit{Moving collision rate}: collision rate when the target vehicle is moving.

\item \textit{Front collision rate}: collision rate with the front part of the target vehicle.
%\item { $C_{S}$: relative collision rate with the sides of the target vehicle }
\end{itemize}

%$C_F$ and $C_S$ are detailed metrics providing the distribution of the collision areas. Notably, different from $C_V$ and $C_R$ which are absolute collision rates calculated based on all test episodes, $C_F$ and $C_S$ are relative collision rates calculated over episodes that the collision happens.


\begin{figure*}[t]
    \centering
    %\includegraphics[width=0.45\textwidth,height=0.1\textwidth]{direct_hit.jpg}
    \includegraphics[width=0.77\textwidth]{direct_hit.jpg}
    %\hfil
    \\
    %\includegraphics[width=0.45\textwidth,height=0.1\textwidth]{side_hit.jpg}
    \includegraphics[width=0.77\textwidth]{side_hit.jpg}
    \caption{Typical behaviors of the pedestrian trained with $\Rc$. Red arrows represent the pedestrian direction. Top row: The pedestrian directly hits the vehicle from the central front, as the car fails to predict the pedestrian's movement. Bottom row: The pedestrian crashes into the car from the side.} %Both behaviors displayed in the top and bottom rows are desired because these behaviors would challenge the ability of AVs facing such sudden emergence.}
    \label{fig:Pedestrian_behavior_visualization}
\end{figure*}

\subsection{Training Against the CARLA AV Agent}



%\textit{1) Training the suicidal pedestrian}:  %and each reward function is trained three times to avoid occasional cases in Town 2. 
% Intentionally, we select the following locations in Town 2 to reproduce the training procedure:
% \begin{itemize}
% \item { location 1: [104.3, 241.3, 0.5],  orientation 1: [0, 0, 0]}
% \item { location 2: [88.8, 302.6, 0.5], orientation 2: [0, $-\pi$, 0] }
% \item { location 3: [190.0, 293.5, 0.5], orientation 3: [0, $\frac{\pi}{2}$, 0]  }
% \item { location 4: [193.8, 218.8, 0.5], orientation 4: [0,$-\frac{\pi}{2}$ 0]  }
% \end{itemize}
% where components of the location are $[x, y, z]$, and components of the orientation are
% $[pitch, yaw, roll]$. All of these locations and orientations are represented in the world
% coordinate.
Fig.~\ref{fig:train_pedestrian_plot} shows that training of the pedestrian policy converges after 70000 steps when trained using both rewards $\Rs$ and $\Rc$. %to some specific behaviors. Additionally, although $\pi_{const}$ converges faster than $\pi_{comb}$,
The value of the mean episode length indicates that using $\Rc$ results in a policy that is more aggressive in searching for and hitting the vehicle. %in terms of average steps needed to hit the vehicle.


%\textit{2) Evaluating the trained suicidal pedestrian}: We still use the CARLA agent as the target vehicle and randomly initialize the vehicle and pedestrian in Town 1 and Town 2. Each test is carried out over 100 episodes, and we repeat it three times in the corresponding town. %to obtain more reasonable results.




%\textit{3) Testing two state-of-the-art AD algorithms}: We test two state-of-the-art AD algorithms from the open challenge CARLA leaderboard \cite{carla_leaderboard} with our suicidal pedestrian: LAV \cite{chen2022learningfromallvehicles} and InterFuser \cite{shao2023safetysafetyenhanced}. LAV is an imitation learning-based method in which the AV agent is trained to imitate the CARLA behavior agent with a dataset collected from all vehicles it observes, while InterFuser aims to develop a comprehensive scene-understanding ability with the help of sensor-fusion to interpret the decision process of the AV and ensure driving safety. %Furthermore, each driving algorithm is tested three times separately in Town 1 and Town 2, with each test containing 100 episodes.





% This section presents and analyzes the experimental results. 
%We first discuss the performance of our suicidal pedestrian; then, we discuss how this pedestrian can help to find driving algorithm decision errors.

%\subsection{Suicidal Pedestrian Evaluation}

%We measure the effectiveness of our suicidal pedestrian using the metrics defined above: collision rate $C_V$, %collision running rate $C_R$, moving collision rate $C_M$, and front collision rate $C_F$. For the first metric $C_V$, having values closer to 1 indicates that the pedestrian is performing adversarial behaviors that can cause the vehicle to error, %decision error, whereas a value closer to 0 means a failed policy. For the second metric $C_M$, a higher value indicates a more complex and unpredictable pedestrian behavior as the vehicle does not perform hard brakes in time before the collision happens. The last metric $C_F$ illustrates which part of $C_V$ corresponds to meaningful collisions.
%two metrics $C_F$ and $C_S$ are a detailed analysis of $C_V$ to illustrate the exact collision areas.




Table~\ref{tab:pedestrian_evaluation} shows the performance of our suicidal pedestrian. One can see that both reward functions perform well in guiding the pedestrian to hit the target AV. $\Rc$ generally yields better performance than $\Rs$.
Note that more than half of all collisions happen when the AV does not stop in time, which corresponds to more hazardous scenarios. %and means that the pedestrian has successfully cheated the vehicle.
As for the collision areas, the front part of the vehicle receives almost $80\%$ of collisions. We can also see that the pedestrian agent generalizes well to a new town.
%We can also observe that the reward function $\Rc$ outperforms $\Rs$ on almost all metrics. %The following will discuss these key conclusions in detail.
The performance of both reward functions declines only slightly, by approximately $5\%$, when the suicidal pedestrian is deployed to a previously unknown environment.
%The $C_V$ of $\Rs$ %the constant reward 
%decreases from $84\%$ to $79\%$, and the $C_V$ of $\Rc $  %the combinational reward 
%decreases from $90\%$ to $86\%$.
%Similarly, other metrics also reduce with only small amounts. This highlights the generalization potential of our pedestrian. This phenomenon most likely depends on our state space, in which all information is described in the pedestrian coordinate system.
%This indicates a potential that the pedestrian can be further extended to various traffic scenarios. One explanation for this phenomenon is the environment-independent property of the pedestrian input and output representations, in which all information is described in a relative form based on the pedestrian coordinate. 


% %\textbf{Policy comparison}.
% \subsubsection{Policy comparison}
% The combinational reward $\Rc$ performs slightly better than the constant reward $\Rs$ in collision rate $C_V$ and front collision rate $C_F$. However, the difference is more significant in the moving collision rate $C_M$. This difference in $C_M$ implies that behaviors produced by $\Rc$ are more complex and unpredictable such that they can cause the AV decision error more easily. 

%Although the combinational reward $\Rc$ performs better than the constant reward $\Rs$, the performances of these two reward functions are not as different as we expect. The metric values of the two methods differ by less than $10\%$ under two testing towns in terms of $C_V$, $C_F$, and $C_S$. However, the $C_M$ is an exception. In Town 2, $C_M$ of the constant reward $\Rs$ is $13\%$ less than that of the combinational reward $\Rc$. In Town 1, this value differs by $11\%$. This difference in $C_M$ implies that behaviors produced by $\Rc$ are more complex and unpredictable such that they can cause the AV decision error more easily. 

Note that the collision rate does not reach 100\% and we see two reasons for that.
%There are two main failure cases:
%However, none of the methods can perfectly hit the vehicle. Most possible reasons come from two aspects.
First, the pedestrian uses a coordinate-based state and it may be blocked by environmental objects that are not included in the state.
%directly observes the location and velocity of the target AV while ignoring all environmental obstacles, rendering that the pedestrian may be blocked by environmental barriers when it tries to walk close to the car.
Second, sometimes the pedestrian fails to predict the future trajectory of the AV.
%the pedestrian and the vehicle are independent non-communicating players, rendering a very limited ability for the pedestrian to predict the future trajectory of the AV. 
In Fig.~\ref{fig:Pedestrian_behavior_visualization}, we visualize some typical behaviors of the suicidal pedestrian. 





\subsection{Testing SOTA AD Algorithms with the Suicidal Pedestrian} %failure of autonomous vehicles}

We test two state-of-the-art AD algorithms with our suicidal pedestrian, LAV \cite{chen2022learningfromallvehicles} that plans using predicted future trajectories for all traffic participants, and InterFuser \cite{shao2023safetysafetyenhanced} that has a safety controller relying on a predicted object density map to avoid collisions.
%in terms of three metrics: the pedestrian mean episode reward, the collision rate $C_V$, and the moving collision rate $C_M$. Notably, since the evaluation entity is now the AV agent, $C_V$ and $C_M$ are interpreted from the perspective of the vehicle. For $C_V$, a value closer to 0 means the vehicle has enough capacity to avoid collisions with the suicidal pedestrian, whereas a value closer to 1 means the opposite. For $C_M$, lower values suggest that the vehicle manages to avoid collision hazards by braking, thus proving the capacity of the AV to deal with the sudden emergence of pedestrians by performing hard brakes. Furthermore, the pedestrian mean episode return is a general metric to describe the collisions, with lower values implying that it is more difficult to result in crashes or cause severe consequences. This metric is affected by both the collision rate and the collision running rate.
Note that the pedestrian was trained against the CARLA behavior agent, and it is evaluated with LAV and InterFuser without any adaptations.

\begin{table*}[tp]
    \caption{Evaluation results of two state-of-the-art AD algorithms using the suicidal pedestrian trained with reward $\Rc$.
    The best results from the point of view of the driving policy are shown in bold.}
    \centering
    %\renewcommand{\arraystretch}{1.1}
    %\resizebox{1.0\textwidth}{!}{%
    \begin{tabular}{c|ccc|ccc}
        \hline
        & \multicolumn{3}{c}{\textbf{Train town (Town 2)}} & \multicolumn{3}{|c}{\textbf{Test town (Town 1)}} \\ \hline
        \textbf{Method} & \textbf{Pedestrian reward} & \textbf{Collision rate} & \textbf{Moving collision rate} & \textbf{Pedestrian reward} & \textbf{Collision rate} & \textbf{Moving collision rate} \\ \hline
        %&  $\% \downarrow$ & $\% \downarrow$ & $\% \downarrow$ & $\% \downarrow$ & $\% \downarrow$ & $\% \downarrow$ \\ \hline
        CARLA behavior & $4.57 \pm 0.15$ & $\textbf{0.90} \pm 0.03$ & $0.55 \pm 0.02$ & $4.29 \pm 0.29$ & $\textbf{0.86} \pm 0.02$ & $0.54 \pm 0.05$ \\ %\hline
        LAV \cite{chen2022learningfromallvehicles} & $\textbf{3.56} \pm 0.26$ & $0.93 \pm 0.02$ & $0.47 \pm 0.04$ & $3.94 \pm 0.26$ & $0.90 \pm 0.03$ & $0.61 \pm 0.01$ \\
        %\hline
        InterFuser \cite{shao2023safetysafetyenhanced} & $3.77 \pm 0.38$ & $0.94 \pm 0.02$ & $\textbf{0.32} \pm 0.06$ & $\textbf{3.82} \pm 0.16$ & $0.92 \pm 0.02$ & $\textbf{0.37} \pm 0.02$ \\ 
        \hline
    \end{tabular}
    %}%
    \label{tab:vehicle_test}
\end{table*}

\begin{figure*}[tp]
    \centering
    \includegraphics[width=.42\linewidth]{lav_1.png}
    \hfil
    \includegraphics[width=.42\linewidth]{lav_2.png}
    \caption{Visualization of two collision episodes with LAV. We present three (concatenated) camera images (top), detection and motion predictions (bottom left), and predicted road geometries (bottom right) for the two episodes. Left: LAV detects the pedestrian as a vehicle. Right: LAV fails to find the pedestrian due to insufficient fusion of images. 
    %(a) Visualization of incorrect detection error that predicts the pedestrian as a vehicle. (b) Visualization of unsuccessful detection error that fails to find the pedestrian due to insufficient fusion of images.
    }
    \label{fig:LAV_error_visualization}
\end{figure*}

\begin{figure*}[tbp]
    \centering
    \includegraphics[width=.3\textwidth]{interfuser_1.png}
    \hfil
    \includegraphics[width=.3\textwidth]{interfuser_2.png}
    \hfil
    \includegraphics[width=.3\textwidth]{interfuser_3.png}
    \caption{Visualization of a failure case of InterFuser in which the AV does not perform any actions to avoid collisions due to failing to predict the trajectory of the pedestrian. We present camera images (top row), detected traffic scenes at the current timestep (middle row) and predicted traffic scenes at the next two timesteps (bottom row). The yellow rectangle in the last two rows represents the ego vehicle, while white rectangles represent other detected objects. Green dots are the future trajectory of the ego vehicle.}
    \label{fig:InterFuser_error_visualization}
\end{figure*}

Table~\ref{tab:vehicle_test} describes the performance of LAV %\cite{chen2022learningfromallvehicles} 
and InterFuser %\cite{shao2023safetysafetyenhanced}
against the suicidal pedestrian. %
%Notably, these quantitative results of the three driving models are not comparable, i.e., it cannot be concluded that LAV and InterFuser perform better than CARLA behavior even though they achieve the lowest pedestrian reward and collision running rate, because of that the pedestrian is not trained against LAV or InterFuser. However, some helpful information can still be obtained. 
The results show that
the pedestrian can generate collisions both with LAV and InterFuser, showing potential weaknesses of these two driving algorithms. InterFuser has a much lower moving collision rate than LAV and CARLA, which suggests  
%Moreover, the difference between $C_V$ and $C_R$ of LAV is larger than that of InterFuser, which suggests
most crashes of InterFuser are not severe, while LAV is more likely to cause hazardous consequences when a collision happens.


We visualize some failures of LAV and InterFuser when dealing with our suicidal pedestrian to understand their weaknesses better. Fig.~\ref{fig:LAV_error_visualization} illustrates two typical errors of LAV: incorrect detection and unsuccessful detection. In incorrect detection, LAV detects the pedestrian as a vehicle, thus applying unreasonable dynamic models to the pedestrian to predict the corresponding trajectories. In unsuccessful detection, LAV fails to detect the pedestrian due to vision failure.
%technical flaws.
Interestingly, both errors can happen at different stages of one episode. Fig.~\ref{fig:InterFuser_error_visualization} illustrates a typical failure case of InterFuser, in which the vehicle does not perform any actions to avoid collisions with the suicidal pedestrian even if the pedestrian is detected. This failure suggests that Interfuser performs well in detection, but potential improvements should be applied to its prediction and decision-making modules.



\section{Discussion \& Future work}

This paper proposes a suicidal pedestrian model to generate safety-critical traffic scenarios for AD testing. We model the pedestrian as an RL agent and train it using a model-free PPO algorithm. Furthermore, we perform %extensive 
experiments to validate its effectiveness in generating collision scenarios. Finally, testing results of two state-of-the-art AD algorithms illustrate our suicidal pedestrian can significantly help find driving algorithm decision errors.

Our work can be extended to having more pedestrians and cars in the simulations. %, which could be more challenging for the AVs.
Another direction would be to consider different goal-conditioned pedestrians to generate more varying behaviors to address the limitation of only using the suicidal pedestrian with limited behavior diversity.
%in which the suicidal pedestrian should distinguish between the target vehicle and other vehicles, as well as pedestrians. 
Moreover, we can augment our state representation with the locations of other objects, or we could use image inputs or object-based representations to replace the hand-crafted state vector, thus allowing the pedestrian to plan movements according to the surroundings, avoid obstacles, or take advantage of obstacles to surprise the drivers. %Furthermore, combining our work with an adversarial test synthesizer proposed in prior work is also an intriguing alternative.









% \section{Introduction}
% This document is a model and instructions for \LaTeX.
% Please observe the conference page limits. 

% \section{Ease of Use}

% \subsection{Maintaining the Integrity of the Specifications}

% The IEEEtran class file is used to format your paper and style the text. All margins, 
% column widths, line spaces, and text fonts are prescribed; please do not 
% alter them. You may note peculiarities. For example, the head margin
% measures proportionately more than is customary. This measurement 
% and others are deliberate, using specifications that anticipate your paper 
% as one part of the entire proceedings, and not as an independent document. 
% Please do not revise any of the current designations.

% \section{Prepare Your Paper Before Styling}
% Before you begin to format your paper, first write and save the content as a 
% separate text file. Complete all content and organizational editing before 
% formatting. Please note sections \ref{AA}--\ref{SCM} below for more information on 
% proofreading, spelling and grammar.

% Keep your text and graphic files separate until after the text has been 
% formatted and styled. Do not number text heads---{\LaTeX} will do that 
% for you.

% \subsection{Abbreviations and Acronyms}\label{AA}
% Define abbreviations and acronyms the first time they are used in the text, 
% even after they have been defined in the abstract. Abbreviations such as 
% IEEE, SI, MKS, CGS, ac, dc, and rms do not have to be defined. Do not use 
% abbreviations in the title or heads unless they are unavoidable.

% \subsection{Units}
% \begin{itemize}
% \item Use either SI (MKS) or CGS as primary units. (SI units are encouraged.) English units may be used as secondary units (in parentheses). An exception would be the use of English units as identifiers in trade, such as ``3.5-inch disk drive''.
% \item Avoid combining SI and CGS units, such as current in amperes and magnetic field in oersteds. This often leads to confusion because equations do not balance dimensionally. If you must use mixed units, clearly state the units for each quantity that you use in an equation.
% \item Do not mix complete spellings and abbreviations of units: ``Wb/m\textsuperscript{2}'' or ``webers per square meter'', not ``webers/m\textsuperscript{2}''. Spell out units when they appear in text: ``. . . a few henries'', not ``. . . a few H''.
% \item Use a zero before decimal points: ``0.25'', not ``.25''. Use ``cm\textsuperscript{3}'', not ``cc''.)
% \end{itemize}

% \subsection{Equations}
% Number equations consecutively. To make your 
% equations more compact, you may use the solidus (~/~), the exp function, or 
% appropriate exponents. Italicize Roman symbols for quantities and variables, 
% but not Greek symbols. Use a long dash rather than a hyphen for a minus 
% sign. Punctuate equations with commas or periods when they are part of a 
% sentence, as in:
% \begin{equation}
% a+b=\gamma\label{eq}
% \end{equation}

% Be sure that the 
% symbols in your equation have been defined before or immediately following 
% the equation. Use ``\eqref{eq}'', not ``Eq.~\eqref{eq}'' or ``equation \eqref{eq}'', except at 
% the beginning of a sentence: ``Equation \eqref{eq} is . . .''

% \subsection{\LaTeX-Specific Advice}

% Please use ``soft'' (e.g., \verb|\eqref{Eq}|) cross references instead
% of ``hard'' references (e.g., \verb|(1)|). That will make it possible
% to combine sections, add equations, or change the order of figures or
% citations without having to go through the file line by line.

% Please don't use the \verb|{eqnarray}| equation environment. Use
% \verb|{align}| or \verb|{IEEEeqnarray}| instead. The \verb|{eqnarray}|
% environment leaves unsightly spaces around relation symbols.

% Please note that the \verb|{subequations}| environment in {\LaTeX}
% will increment the main equation counter even when there are no
% equation numbers displayed. If you forget that, you might write an
% article in which the equation numbers skip from (17) to (20), causing
% the copy editors to wonder if you've discovered a new method of
% counting.

% {\BibTeX} does not work by magic. It doesn't get the bibliographic
% data from thin air but from .bib files. If you use {\BibTeX} to produce a
% bibliography you must send the .bib files. 

% {\LaTeX} can't read your mind. If you assign the same label to a
% subsubsection and a table, you might find that Table I has been cross
% referenced as Table IV-B3. 

% {\LaTeX} does not have precognitive abilities. If you put a
% \verb|\label| command before the command that updates the counter it's
% supposed to be using, the label will pick up the last counter to be
% cross referenced instead. In particular, a \verb|\label| command
% should not go before the caption of a figure or a table.

% Do not use \verb|\nonumber| inside the \verb|{array}| environment. It
% will not stop equation numbers inside \verb|{array}| (there won't be
% any anyway) and it might stop a wanted equation number in the
% surrounding equation.

% \subsection{Some Common Mistakes}\label{SCM}
% \begin{itemize}
% \item The word ``data'' is plural, not singular.
% \item The subscript for the permeability of vacuum $\mu_{0}$, and other common scientific constants, is zero with subscript formatting, not a lowercase letter ``o''.
% \item In American English, commas, semicolons, periods, question and exclamation marks are located within quotation marks only when a complete thought or name is cited, such as a title or full quotation. When quotation marks are used, instead of a bold or italic typeface, to highlight a word or phrase, punctuation should appear outside of the quotation marks. A parenthetical phrase or statement at the end of a sentence is punctuated outside of the closing parenthesis (like this). (A parenthetical sentence is punctuated within the parentheses.)
% \item A graph within a graph is an ``inset'', not an ``insert''. The word alternatively is preferred to the word ``alternately'' (unless you really mean something that alternates).
% \item Do not use the word ``essentially'' to mean ``approximately'' or ``effectively''.
% \item In your paper title, if the words ``that uses'' can accurately replace the word ``using'', capitalize the ``u''; if not, keep using lower-cased.
% \item Be aware of the different meanings of the homophones ``affect'' and ``effect'', ``complement'' and ``compliment'', ``discreet'' and ``discrete'', ``principal'' and ``principle''.
% \item Do not confuse ``imply'' and ``infer''.
% \item The prefix ``non'' is not a word; it should be joined to the word it modifies, usually without a hyphen.
% \item There is no period after the ``et'' in the Latin abbreviation ``et al.''.
% \item The abbreviation ``i.e.'' means ``that is'', and the abbreviation ``e.g.'' means ``for example''.
% \end{itemize}
% An excellent style manual for science writers is \cite{b7}.

% \subsection{Authors and Affiliations}
% \textbf{The class file is designed for, but not limited to, six authors.} A 
% minimum of one author is required for all conference articles. Author names 
% should be listed starting from left to right and then moving down to the 
% next line. This is the author sequence that will be used in future citations 
% and by indexing services. Names should not be listed in columns nor group by 
% affiliation. Please keep your affiliations as succinct as possible (for 
% example, do not differentiate among departments of the same organization).

% \subsection{Identify the Headings}
% Headings, or heads, are organizational devices that guide the reader through 
% your paper. There are two types: component heads and text heads.

% Component heads identify the different components of your paper and are not 
% topically subordinate to each other. Examples include Acknowledgments and 
% References and, for these, the correct style to use is ``Heading 5''. Use 
% ``figure caption'' for your Figure captions, and ``table head'' for your 
% table title. Run-in heads, such as ``Abstract'', will require you to apply a 
% style (in this case, italic) in addition to the style provided by the drop 
% down menu to differentiate the head from the text.

% Text heads organize the topics on a relational, hierarchical basis. For 
% example, the paper title is the primary text head because all subsequent 
% material relates and elaborates on this one topic. If there are two or more 
% sub-topics, the next level head (uppercase Roman numerals) should be used 
% and, conversely, if there are not at least two sub-topics, then no subheads 
% should be introduced.

% \subsection{Figures and Tables}
% \paragraph{Positioning Figures and Tables} Place figures and tables at the top and 
% bottom of columns. Avoid placing them in the middle of columns. Large 
% figures and tables may span across both columns. Figure captions should be 
% below the figures; table heads should appear above the tables. Insert 
% figures and tables after they are cited in the text. Use the abbreviation 
% ``Fig.~\ref{fig}'', even at the beginning of a sentence.

% \begin{table}[htbp]
% \caption{Table Type Styles}
% \begin{center}
% \begin{tabular}{|c|c|c|c|}
% \hline
% \textbf{Table}&\multicolumn{3}{|c|}{\textbf{Table Column Head}} \\
% \cline{2-4} 
% \textbf{Head} & \textbf{\textit{Table column subhead}}& \textbf{\textit{Subhead}}& \textbf{\textit{Subhead}} \\
% \hline
% copy& More table copy$^{\mathrm{a}}$& &  \\
% \hline
% \multicolumn{4}{l}{$^{\mathrm{a}}$Sample of a Table footnote.}
% \end{tabular}
% \label{tab1}
% \end{center}
% \end{table}

% \begin{figure}[htbp]
% \centerline{\includegraphics{fig1.png}}
% \caption{Example of a figure caption.}
% \label{fig}
% \end{figure}

% Figure Labels: Use 8 point Times New Roman for Figure labels. Use words 
% rather than symbols or abbreviations when writing Figure axis labels to 
% avoid confusing the reader. As an example, write the quantity 
% ``Magnetization'', or ``Magnetization, M'', not just ``M''. If including 
% units in the label, present them within parentheses. Do not label axes only 
% with units. In the example, write ``Magnetization (A/m)'' or ``Magnetization 
% \{A[m(1)]\}'', not just ``A/m''. Do not label axes with a ratio of 
% quantities and units. For example, write ``Temperature (K)'', not 
% ``Temperature/K''.

% \section*{Acknowledgment}

% The preferred spelling of the word ``acknowledgment'' in America is without 
% an ``e'' after the ``g''. Avoid the stilted expression ``one of us (R. B. 
% G.) thanks $\ldots$''. Instead, try ``R. B. G. thanks$\ldots$''. Put sponsor 
% acknowledgments in the unnumbered footnote on the first page.

% \section*{References}

% Please number citations consecutively within brackets \cite{b1}. The 
% sentence punctuation follows the bracket \cite{b2}. Refer simply to the reference 
% number, as in \cite{b3}---do not use ``Ref. \cite{b3}'' or ``reference \cite{b3}'' except at 
% the beginning of a sentence: ``Reference \cite{b3} was the first $\ldots$''

% Number footnotes separately in superscripts. Place the actual footnote at 
% the bottom of the column in which it was cited. Do not put footnotes in the 
% abstract or reference list. Use letters for table footnotes.

% Unless there are six authors or more give all authors' names; do not use 
% ``et al.''. Papers that have not been published, even if they have been 
% submitted for publication, should be cited as ``unpublished'' \cite{b4}. Papers 
% that have been accepted for publication should be cited as ``in press'' \cite{b5}. 
% Capitalize only the first word in a paper title, except for proper nouns and 
% element symbols.

% For papers published in translation journals, please give the English 
% citation first, followed by the original foreign-language citation \cite{b6}.

% \begin{thebibliography}{00}
% \bibitem{b1} G. Eason, B. Noble, and I. N. Sneddon, ``On certain integrals of Lipschitz-Hankel type involving products of Bessel functions,'' Phil. Trans. Roy. Soc. London, vol. A247, pp. 529--551, April 1955.
% \bibitem{b2} J. Clerk Maxwell, A Treatise on Electricity and Magnetism, 3rd ed., vol. 2. Oxford: Clarendon, 1892, pp.68--73.
% \bibitem{b3} I. S. Jacobs and C. P. Bean, ``Fine particles, thin films and exchange anisotropy,'' in Magnetism, vol. III, G. T. Rado and H. Suhl, Eds. New York: Academic, 1963, pp. 271--350.
% \bibitem{b4} K. Elissa, ``Title of paper if known,'' unpublished.
% \bibitem{b5} R. Nicole, ``Title of paper with only first word capitalized,'' J. Name Stand. Abbrev., in press.
% \bibitem{b6} Y. Yorozu, M. Hirano, K. Oka, and Y. Tagawa, ``Electron spectroscopy studies on magneto-optical media and plastic substrate interface,'' IEEE Transl. J. Magn. Japan, vol. 2, pp. 740--741, August 1987 [Digests 9th Annual Conf. Magnetics Japan, p. 301, 1982].
% \bibitem{b7} M. Young, The Technical Writer's Handbook. Mill Valley, CA: University Science, 1989.
% \end{thebibliography}


% \vspace{12pt}
% \color{red}
% IEEE conference templates contain guidance text for composing and formatting conference papers. Please ensure that all template text is removed from your conference paper prior to submission to the conference. Failure to remove the template text from your paper may result in your paper not being published.

% \clearpage
% \bibliographystyle{IEEEtran}
% \phantomsection
% \addcontentsline{toc}{section}{References} 
% \bibliography{reference}

\input{reference.bbl}
\bibliographystyle{IEEEtran} 
\bibliography{reference}

\end{document}

\begin{abstract}
We propose a neural encoder-decoder model with reinforcement learning (\proposed) for grammatical error correction (GEC).
Unlike conventional maximum likelihood estimation (\mle), the model directly optimizes towards an objective that considers a {\em sentence-level}, task-specific evaluation metric, avoiding the exposure bias issue in \mle.
We demonstrate that \proposed outperforms \mle both in human and automated evaluation metrics, achieving the state-of-the-art on a fluency-oriented GEC corpus. 
\end{abstract}
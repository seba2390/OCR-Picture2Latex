\begin{algorithm}[t]
\DontPrintSemicolon
\SetAlgoNoEnd
\KwIn{Pairs of source ($X$) and target ($Y$)}
\KwOut{Model parameter $\hat{\theta}$}
initialize($\hat{\theta}$)\\
\For{$(x,y) \in (X,Y)$}{
  ${\small (\hat{y}_1, ... \hat{y}_k), (p(\hat{y}_1), ... p(\hat{y}_k)) = \text{sample}(x, k, \hat{\theta})}$\\
  $p(\hat{y})$ = normalize($p(\hat{y})$) \\
  $\bar{r}(\hat{y}) = 0$ \tcp*[r]{\small expected reward} 
  \For{$\hat{y}_i \in \hat{y}$}{
    $\bar{r}(\hat{y}) += p(\hat{y}_i)\cdot \text{score}(\hat{y}_i, y)$ \\
  }
  backprop($\hat{\theta}, \bar{r}$) \tcp*[r]{\small policy gradient $\frac{\partial}{\partial \hat{\theta}}$}
}
\KwRet{$\hat{\theta}$}\\
%\caption{Pseudocode of reinforcement learning for neural encoder-decoder model.}
\caption{Reinforcement learning for neural encoder-decoder model.}
\label{alg:nrl}
\end{algorithm}
\section{Preliminaries}
\label{sec:prelim}
In this paper, we consider the setting where one predicts the label $y \in \mathcal{Y}$ based on the input feature $x\in \mathcal{X}$. Given a parameter space $\Theta$ and a loss function $\ell$, we need to train a model $f_{\theta}$ under the training distribution $P_{tr}$, where $\theta \in \Theta$. In empirical risk minimization (ERM), the empirical distribution over the training data is $\hat{P}_{tr}$; ERM optimizes the following objective:
\begin{equation}
\label{eq:erm}
\theta^{*} := \arg\min_{\theta \in \Theta} \mathbb{E}_{(x,y)\sim \hat{P}} [\ell(f_{\theta}(x), y)].
\end{equation}
In a traditional machine learning setting, a test set, sampled from a test distribution $P_{ts}$, is used to evaluate the generalization of the trained model $\theta^{*}$, where the test distribution is assumed to be the same as the training distribution, i.e., $P^{tr}=P^{ts}$. In this paper, we are interested in the setting when distribution shift occurs, i.e., $P^{tr}\neq P^{ts}$. 


Specifically, following~\citet{muandet2013domain,albuquerque2019generalizing,koh2021wilds}, we regard the overall data distribution containing $\mathcal{D}=\{1,\ldots,D\}$ domains and each domain $d\in \mathcal{D}$ is associated with a data distribution $P_d$ over a set $(X, Y, d)=\{(x_i, y_i, d)\}_{i=1}^{N^d}$, where $N^d$ is the number of samples in domain $d$. Then, we formulate the training distribution as the mixture of $D$ domains, i.e., $P^{tr}=\sum_{d\in \mathcal{D}}r_d^{tr} P_d$, where $\{r_d^{tr}\}$ denotes the mixture probabilities in training set. Here, the training domains are defined as $\mathcal{D}^{tr}=\{d\in \mathcal{D} | r_d^{tr}>0\}$. Similarly, the test distribution could be represented as $P^{ts}=\sum_{d\in \mathcal{D}}r_d^{ts} P_d$, where $\{r_d^{ts}\}$ is the mixture probabilities in test set. The test domains are defined as $\mathcal{D}^{ts}=\{d\in \mathcal{D} | r_d^{ts}>0\}$.

In subpopulation shifts, the test set has domains that have been seen in the training set, but with a different proportion of subpopulations, i.e., $\mathcal{D}^{ts} \subseteq \mathcal{D}^{tr}$ but $\{r^{ts}_d\}\neq \{r^{tr}_d\}$. Under this setting, following~\citet{sagawa2019distributionally}, we consider group-based spurious correlations, where each group $g \in \mathcal{G}$ is defined to be associated with a domain $d$ and a label $y$, i.e., $g=(d,y)$. We assume that the domain is spuriously correlated with the label. For example, we illustrate the CMNIST dataset in Figure~\ref{fig:method_illustration}, where the digit color $d$ (green or red) is spuriously correlated with the label $y$ ([1, 0] or [0, 1]). 
Based on the group definition, we evaluate the model via the worst test group error, i.e., $\max_{g}\mathbb{E}_{(x,y)\sim g}[\ell_{0-1}(f_{\theta}(x),y)]$, where $\ell_{0-1}$ represents the 0-1 loss.

In domain shifts, we investigate the problem where the test domains are disjoint from the training domains, i.e., $\mathcal{D}^{tr} \cap \mathcal{D}^{ts} = \emptyset$. In general, we assume the test domains share some common properties with the training domains. For example, in Camelyon17~\citep{koh2021wilds}, we train the model on some hospitals and test it in a new hospital. We evaluate the worst-domain and/or average performance of the classifier across all test domains.

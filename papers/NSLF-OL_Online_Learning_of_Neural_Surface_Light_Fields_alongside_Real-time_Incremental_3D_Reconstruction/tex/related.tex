\section{Related Works}

Our work is mainly related to NSLF.
Here, we also review the hotter sister topic, NeRF because its development process highly inspires and directs us to use NSLF online for the large scenes. 

\subsection{Neural Radiance Fields (NeRF)}

Mildenhall et al.~\cite{mildenhall2020nerf} propose to represent a scene as a continuous mapping from five-dimensional coordinates $(x,y,z,\theta,\phi)$ to volume density and view-dependent RGB color $(\sigma RGB)$, which are so-called NeRF representations.
The training of NeRF relies on the use of differentiable rendering along rays.
NeRF represents a significant advancement in graphics due to its immersive view-synthesis performance.
However, NeRF does have some limitations. Firstly, the speed for training and rendering is extremely slow. Secondly, the NeRF model suffers from shape-radiance ambiguity.

\subsubsection{Speed-aware NeRF}

Although NeRFs show a very high quality of view synthesis, their computational cost for training and testing is extremely high.
Therefore, lots of recent work shows interest in the speed issue. 
%
Tewari et al.~\cite{tewari2021advances} summarize and show many works exploring speedups using pruning~\cite{liu2020neural}, sampling~\cite{neff2021donerf}, fast integration~\cite{lindell2021autoint}, data structure~\cite{yu2021plenoctrees,hedman2021baking,muller2022instant}, and so on~\cite{reiser2021kilonerf,chen2022tensorf,sitzmann2021light}.
Many different data structures are also used to speed up the rendering and the training process benefits.
A recently highlighted work from NVIDIA, Instant Neural Graphics Primitives, uses a multi-resolution hash encoding to realize fast NeRF training in a few seconds~\cite{muller2022instant}. 
It provides an encoder with very fast convergence.
We will also employ this encoder in our proposed model.  
In the most related scope, KiloNeRF, which uses thousands of tiny MLPs to imitate standard NeRF, shows a factor of 2000 speedup in rendering~\cite{reiser2021kilonerf}.
Real-time rendering already meets the needs of the field of computer graphics (CG).

However, from a robotics perspective, online algorithms such as 3D reconstruction and SLAM are always preferred.
In such an environment, online training makes the task of light fields much more challenging.

\subsubsection{Depth Aided NeRF}

Another problem with NeRF is shape-radiance ambiguity.  NeRF++~\cite{zhang2020nerf++} points out that given an incorrect shape, there exists a family of radiance fields that perfectly explains the training images, but generalizes poorly to novel views. 
Although a well-trained NeRF does not show this phenomenon, imperfect depth prediction is common but is neglected since the application targets color prediction.
However, this also leads to another research direction, a group of works uses depth as an input to reduce the complexity of geometry modeling. 
This group of works embed Structure-from-motion (SfM)~\cite{deng2021depth,xu2022point}, Multi-view Stereo (MVS)~\cite{chen2021mvsnerf,zhang2021learning} or directly input RGBD data~\cite{azinovic2021neural}. 

The above algorithms show a trend that the facilitation of geometry learning well-reduces the complexity of NeRF while improving the high quality.
Moreover, in the robotics community, recent mature real-time 3D reconstructions already provide high-quality online shape reconstruction~\cite{huang2021di}. 

Therefore, we consider solving the geometric and color regression separately. Where the geometry is estimated using a mature online 3D reconstruction model. Meanwhile, an NSLF is independently trained for surface colors.
Without ray sampling, our model uses only surface points during training and inference.
This breaks the constraint of NeRF's rendering loss and allows asynchronous training and inference for each intelligent agent.

\subsection{Neural Surface Light Fields (NSLF)}

NSLF learns a mapping function $f_{NSLF}:\V X\times \V S^3 \rightarrow \V C$ where $\V X \subseteq \mathbb R^3$ denotes the point set on the surface, $\V S^3$ is the unit 3-sphere, $\V C$ denotes the RGB color space.

With the high regression capability of deep learning, Chen et al.~\cite{chen2018deep} propose Deep Surface Light Fields (DSLF) which uses MLPs to replace the accumulation function.
This parametric modeling greatly reduces the computational and spatial burden.
And thus provides more efficient rendering.
Yu et al.~\cite{yu2022anisotropic} have introduced Anisotropic Fourier Features Mapping (AFFM) to encode points.
This increases convergence speed and rendering quality.

Similar to the NeRF design, the NSLFs also follow the encoding-decoding pattern.
For a given point, its position vector is encoded as $\V F_{\V p}=\phi_{p}(\V p)$.
In the other branch, the direction vector is also encoded with a non-parameterized encoder, spherical harmonics, or frequency encoding: $\V F_{\V d} = \varphi_{sh/freq}(\V d)$.
Shallow MLPs are then applied to concatenated features (position encoding and direction) to predict color: $\V c = \phi_{dec}(\V F_{\V p}, \V F_{\V d})$. 

However, similar to NeRF the NSLF has not been used in large-scale incremental 3D reconstruction.
Thus, in the following, we fill this gap and provide an online learned neural surface light fields function for large scales.

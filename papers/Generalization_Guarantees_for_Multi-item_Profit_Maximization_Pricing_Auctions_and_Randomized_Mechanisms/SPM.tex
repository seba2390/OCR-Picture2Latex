In this section, we use our results from Section~\ref{SEC:MAIN} to provide guarantees for optimizing the \emph{profit-generalization tradeoff}, drawing on classic machine learning results on \emph{structural risk minimization}~\citep{Vapnik74:Theory,Blumer87:Occam}.
\begin{figure}
	\centering
	\includegraphics{graphs}
	\caption{Uniform generalization guarantees versus stronger complexity-dependent bounds for a mechanism class $\cM = \cM_4 \subseteq \cM_3 \supseteq \cM_2 \supseteq \cM_1$. See Section~\ref{SEC:SPM} for a description.}\label{fig:SPM}
\end{figure}
We illustrate this tradeoff\footnote{These figures are purely illustrative; they are not based on a simulation or real data.} in Figure~\ref{fig:SPM} with a mechanism class $\cM$ that decomposes into a nested sequence $\pazocal{M}_1 \subseteq \cdots \subseteq \pazocal{M}_4 = \pazocal{M}$.
The $x$-axis measures the intrinsic complexity (e.g., pseudo-dimension) of the subclasses. The orange solid line illustrates the average profit over a fixed set of samples $\sample$ of the mechanism $\hat{M}_i \in \pazocal{M}_i$ that maximizes average profit. In particular, the dot on the orange solid line above $\cM_i$ illustrates $\profit_{\sample}(\hat{M}_i)$. Since $\cM_i \subseteq \cM_j$ for $i \leq j$, $\profit_{\sample}(\hat{M}_i) \leq \profit_{\sample}(\hat{M}_j)$. Similarly, the dot on the blue dotted line above $\cM_i$ illustrates the expected profit of $\hat{M}_i$. This line begins decreasing when the complexity grows to the point that overfitting occurs. The purple dashed line illustrates a uniform lower bound $\profit_{\sample}(\hat{M}_i) - \epsilon_{\pazocal{M}}(N, \delta)$ on the expected profit of $\hat{M}_i$.

Our general theorem allows us to easily derive bounds $\epsilon_{\pazocal{M}_i}(N, \delta)$ for each class $\pazocal{M}_i$. We can then ``spread'' $\delta$ across all subsets $\mclass_1, \dots, \mclass_t$ using a function $w: \N \to [0,1]$ such that $\sum w(i) \leq 1$. By a union bound, with probability $1-\delta$, for all $M \in \mclass$, $|\profit_{\sample}(M) - \profit_{\dist}(M)| \leq \min_{i : M \in \mclass_i}  \epsilon_{\pazocal{M}_i}(N, \delta \cdot w(i))$.
This is illustrated by the green dashed-dotted line in Figure~\ref{fig:SPM}, where the lower bound on the expected profit of $\hat{M}_i$ is $\profit_{\sample}(\hat{M}_i) - \epsilon_{\pazocal{M}_i}(N, \delta \cdot w(i))$. By maximizing this complexity-dependent lower bound, the designer can determine that $\hat{M}_2$ is better than $\hat{M}_4$.

The decomposition of $\pazocal{M}$ into subsets and the choice of weights allow the designer to encode his prior knowledge about the market. For example, if mechanisms in $\pazocal{M}_i$ are likely to be profitable, he can increase $w(i)$, which in turn decreases $\epsilon_{\pazocal{M}_i}(N, \delta \cdot w(i))$, thereby implying stronger guarantees.

We now apply this analysis to item pricing. To perform \emph{market segmentation}, the seller can break the buyers into $k$ groups and charge each group a different price. For $k \in [n]$, let $\mclass_k$ be the class of non-anonymous pricing mechanisms with $k$ price groups: for all mechanisms in $\mclass_k$, there is a partition of the buyers $B_1, \dots, B_k$ such that for all $t \in [k]$, all buyers $j,j' \in B_t$, and all items $i \in [m]$, $p_j(\vec{e}_i) = p_{j'}(\vec{e}_i)$.  We derive the following guarantee for this hierarchy.
\begin{restatable}{theorem}{itemSPM}\label{thm:item_pricing_SPM}
Let $\pazocal{M}$ be the class of non-anonymous item-pricing mechanisms over additive buyers. With probability $1-\delta$ over the draw $\sample \sim \pazocal{D}^N$, for any $k \in [n]$ and any mechanism $M \in \pazocal{M}_k$, \[\left|\profit_{\sample}\left(M\right) - \profit_{\dist}\left(M\right)\right| \leq 360U \sqrt{\frac{km \log \left(4nm\right)}{N}} + 4U\sqrt{\frac{2}{N}\ln \frac{4}{\delta \cdot w\left(k\right)}}.\]
\end{restatable}

We prove results for two-part tariffs, AMA, $\lambda$-auctions, and lottery menus in Appendix~\ref{APP:SPM}.
\section{Threats to Validity}\label{sec:threats}
In our study, the following threats to validity can be found:
\begin{itemize}
    \item \textbf{Subject selection bias.}
    The performance of machine learning algorithms depends on the data on which the algorithms are trained and on which they are applied.
    In the case of our approach, we have two machine learning algorithms that are used to solve the deduplication problem: the similarity model and the \ag itself, which uses the calculated similarity values.
    To mitigate this threat, we tested our approach on two datasets: open-source NetBeans data and the new data from the JetBrains software company.
    The difference in results highlights the importance of sharing new data with the community.
    
    \item \textbf{Limited scope of application.}
    Our approach requires a sufficient number of crash reports containing the information about stack traces to train the similarity model and the \ag, while also having information about their time of occurrence.
    However, this allows our approach to be useful for any moderately large industrial system.
    It is also possible to experiment with using a pre-trained model in a new project.
    
    \item \textbf{Programming language bias.}
    We evaluated our approach on two stack trace datasets that were both collected for JVM languages.
    For stack traces in other programming languages, both the importance of the features used and the results of applying the \ag may differ, because the result of its work directly depends on the similarity values obtained from the used similarity methods.
    Further research is needed to assess how well the proposed approach generalizes to other languages and systems.
\end{itemize}
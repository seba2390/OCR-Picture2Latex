\section{Approach}\label{sec:internals}

\begin{figure}[h!]
\centering
    \includegraphics[width=\columnwidth]{figures/pipeline.pdf}
    \centering
    \vspace{-0.4cm}
    \caption{A high-level pipeline of our approach.}
    \label{fig:scheme}
\end{figure}

\subsection{Overview}

An important feature of working with stack traces in large industrial projects is that the number of groups and their composition is constantly changing, new stack traces come in, new groups are formed. 
Therefore, we treated the task of assigning the new incoming stack trace to the best group as a ranking problem, and not a classification problem. 

The general pipeline of the proposed approach is presented in~\Cref{fig:scheme}.
The first step in our approach is to choose the similarity model for calculating the similarity between stack traces.
A model from any modern approach described above~\cite{modani,lerch,durfex,tracesim,s3m} can fit this role, making it possible for our technique to improve any of them.
Then, it is necessary to calculate the similarity between the incoming stack trace and all the stack traces of the group, for all groups.
The key difference between our approach and existing approaches is the \ag.

The \ag is a decision function that determines the similarity between the stack trace and the group.
This is done not based on the choice of the most similar stack trace, but by aggregating all the available information, which we transfer to it in the form of pre-calculated features.
We propose to build features based not only on the information about the values of similarity between stack traces, but also taking into account more complex information, such as the size of the group, its structure, as well as the time of occurrence of stack traces, etc.
The main motivation for using the time of occurrence is that the last added stack trace probably characterizes the group better than the ones that were added at the very beginning, since the group can change over time.

Finally, after the similarity between the incoming stack trace and all the groups is determined, we rank the groups according to the similarity and assign the stack trace to the most similar group. Let us now walk through the pipeline in greater detail.

\subsection{Preprocessing}
In order to calculate the similarity between stack traces, it is necessary to construct their vector representation. 
Initially, each stack trace 
is represented as a sequence of frames $S=\{f_1, f_2, \ldots, f_n\}$, where $f_i$ is the $i$-th frame. 
For each used similarity model, we apply the preprocessing as described in their work.
Most similarity models represent the stack trace as a sequence of tokens.
We take the full name of the method as its tokens, however, some models use the name of the class or the package.

\subsection{Features}\label{sec:features}

\begin{table*}[]
\centering
\caption{The description of features used in the \ag.}
\begin{tabular}{cp{4cm}p{12cm}}
\toprule

  \textbf{No.} &\multicolumn{1}{c}{\textbf{Feature name}} &
  \multicolumn{1}{c}{\textbf{Description}}  \\ 
  \midrule\midrule
  
  \multicolumn{3}{c}{\textbf{Features based on similarity}}\\\midrule\midrule

  \textbf{1} & First maximum & The value of similarity to the most similar stack trace in the group. This feature constitutes the base of the majority of methods and gives a very good ranking quality~\cite{lerch, durfex, s3m}.
  \\\midrule\midrule
  
  \multicolumn{3}{c}{\textbf{Features based on timestamps}}
  \\\midrule\midrule

  \textbf{2} & Maximum weight & The maximum weight corresponds to the stack trace in the group that is closest in time to the incoming one, which allows us to determine how long ago the group was updated relative to it. \\\midrule
  
  \textbf{3} & Minimum weight & The minimum weight corresponds to the stack trace in the group that is the farthest away in time from the incoming one, which allows us to determine how long ago the group was formed.
  \\\midrule
  
  \textbf{4} & Mean weight & The average value of all weights in the group. This shows us how far the incoming stack trace is from the group in time on average.
  \\\midrule
  
  \textbf{5} & Difference between the maximum and minimum weights & This shows the overall timespan of the group.
  \\\midrule

  \textbf{6-15} & Histogram of all weights & The histogram shows the distribution of time difference from the incoming stack trace to all stack traces in the group. In our experiments, we used the number of bins equal to 10. Each unique feature constitutes the value of the histogram in the corresponding bin. 
  \\\midrule\midrule
  
  \multicolumn{3}{c}{\textbf{Features based on both similarity and timestamps}}\\\midrule\midrule
  
  \textbf{16} & Weight of the first maximum & This shows how long ago the most similar stack trace was added to the group relative to the incoming stack trace, which can also affect how relevant it is.
  \\ \midrule
  
  \textbf{17-28} & Weighted similarity histogram & The weighted similarity histogram allows to estimate the distribution of similarities to the stack traces in the group, taking into account the time of their occurrence relative to the incoming stack trace. In our experiments, we used the number of bins equal to 12. Each unique feature constitutes the value of the histogram in the corresponding bin. 
  \\ \bottomrule
\end{tabular}
\label{table:features-description}
\end{table*}

After choosing a particular similarity model, we can calculate the values of the similarity between the incoming stack trace and all stack traces in all groups. Based on these similarities, we construct various features, the full list is presented in \Cref{table:features-description}.

\subsubsection{Features based on similarity}
The key feature that is used in the majority of works is the similarity value of the most similar stack trace in the group (we will refer to this feature as the \textit{first maximum}). 

\subsubsection{Features based on timestamps}

The idea behind using timestamps of stack traces lies in the assumption that not all stack traces in a group represent it the same. The groups tend to evolve over time, and, as we showed in Section~\ref{sec:motivation}, can include stack traces that are very different. For this reason, we believe that \textit{newer}, more recent stack traces can characterize the group better.
The information about the time of occurrence of stack traces will give our model the ability to independently decide which similarity value characterizes the similarity to the group the best.

Consider two stack traces: the $S_q$ stack trace (the incoming query stack trace that needs to be assigned to one of the groups) and the $S_g$ stack trace (the stack trace that is in one of the groups). Let us designate the time of their occurrence (timestamp) as $T_q$ and $T_g$, respectively.
For $\mathrm{similarity}(S_q, S_g)$, we define the weight $\mathrm{w}(S_q, S_g)$ as follows:
\begin{gather}
    \label{eq:weight}
    \mathrm{w}(S_q, S_g) = \frac{1}{\log(|T_q - T_g| + 1) + 1}.
\end{gather}

The idea behind this scale is that the closer in time two stack traces are to each other, the greater the weight is, with the values of the weight laying between $0$ and $1$. This allows prioritizing the similarity of stack traces that are closest in time to the incoming stack trace.

The following features can be constructed based on the proposed weights. The \textit{maximum weight} shows how long ago the group was updated relative to the incoming stack trace, the \textit{minimum weight} shows when the group was formed, and their \textit{difference} shows the timespan of the group. The \textit{mean weight} shows how far the given stack trace is from the group in time on average. The \textit{histogram of all weights} will also indicate the overall relation in time between the group and the incoming stack trace. To transform a histogram into a set of features, one simply needs to take the value of the histogram in each bin as a separate feature. Based on our preliminary experiments, we used a histogram with 10 bins.

\subsubsection{Features based on both similarity and timestamps}

Combining both the similarity and the temporal aspect, firstly, we can use the \textit{weight of the first maximum}~--- the weight corresponding to the \textit{first maximum}. This will allow us to understand how far the most similar stack trace is located in time from the incoming one.

Using the intuition presented in~\Cref{sec:motivation}, we would also like to have an idea about the distribution of the similarity values to all stack traces in the group.
This will make it possible to understand how widely the similarity values are scattered, which values prevail, and how much the value of the \textit{first maximum} differs from all others. For that, a similarity histogram can be employed (see \Cref{fig:hists}).

However, to take into account more information, instead of using the similarity histogram itself, we can use its modification that employs the proposed weights. To build a \textit{weighted similarity histogram}, it is necessary to assign a weight to each similarity value, which will allow us to move from the frequencies of occurrence of each similarity to their weighted frequencies. This means that each similarity value is included in the histogram not with a weight of 1, but with a weight calculated using Equation~\ref{eq:weight}. Based on our preliminary experiments, we used a histogram with 12 bins. 

Overall, this results in 28 features, the full list of which is presented in \Cref{table:features-description}. The selected features describe the relationships between stack traces and groups very fully, both in terms of similarity and time. We apply standard scaling to all the features before processing them.

\subsection{Linear Aggregation Model}

After all the described features are built, the only remaining thing is to transfer them to an \ag, rank the obtained similarities to groups, and assign the stack trace to the most similar group. We have tried several approaches, and in the result, selected a simple linear \ag, which is a weighted sum of constructed features. The practical advantages of such a model are that it is easy and fast to train, and is easy to introduce into production. To train the \ag, we used a RankNet Loss~\cite{ranknet}, and the feature weights were updated using the Adam optimizer~\cite{adam}.
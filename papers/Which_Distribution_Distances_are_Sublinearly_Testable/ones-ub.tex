\section{Upper Bounds for Identity Testing}
\label{sec:ones-ub}
In this section, we prove the following theorems for identity testing.
\begin{theorem}\label{thm:ones-csq-h}
There exists an algorithm for identity testing between $p$ and $q$ distinguishing the cases:
\begin{itemize}
\item $\dxs(p,q) \leq \ve^2$;
\item $\dh(p,q) \geq \ve$.
\end{itemize}
The algorithm uses $O\left(\frac{n^{1/2}}{\ve^2}\right)$ samples.
\end{theorem}

\begin{theorem}\label{thm:ones-tv}
There exists an algorithm for identity testing between $p$ and $q$ distinguishing the cases:
\begin{itemize}
\item $\dlt(p,q) \leq \frac{\ve}{\sqrt{n}}$;
\item $\dtv(p,q) \geq \ve$.
\end{itemize}
The algorithm uses $O\left(\frac{n^{1/2}}{\ve^2}\right)$ samples.
\end{theorem}

\begin{theorem}\label{thm:ones-h}
There exists an algorithm for identity testing between $p$ and $q$ distinguishing the cases:
\begin{itemize}
\item $\dlt(p,q) \leq \frac{\ve^2}{\sqrt{n}}$;
\item $\dh(p,q) \geq \ve$.
\end{itemize}
The algorithm uses $O\left(\frac{n^{1/2}}{\ve^2}\right)$ samples.
\end{theorem}

We prove Theorem~\ref{thm:ones-csq-h} in Section~\ref{sec:id-csq-h}, and Theorems~\ref{thm:ones-tv} and~\ref{thm:ones-h} in Section~\ref{sec:id-lt}.

\subsection{Identity Testing with Hellinger Distance and $\chi^2$-Tolerance}
\label{sec:id-csq-h}

We prove Theorem~\ref{thm:ones-csq-h} by analyzing Algorithm~\ref{alg:testing}.
We will set $c_1 = \frac{1}{100}, c_2 = \frac{6}{25}$, and let $C$ be a sufficiently large constant.
\begin{algorithm}[h]
\caption{$\chi^2$-close versus Hellinger-far testing algorithm}\label{alg:testing}
\begin{algorithmic}[1]
\State \textbf{Input:} $\ve$; an explicit distribution $q$; sample access to a distribution $p$
\State Implicitly define $\mathcal{A} \leftarrow \{i:q_i \geq c_1\ve^2/n\}$, $\mathcal{\bar A} \leftarrow [n] \setminus \mathcal{A}$
\State Let $\hat p$ be the empirical distribution\footnote{The empirical distribution is defined by taking a set of samples and normalizing the counts such that the result forms a probability distribution.} from drawing $m_1 = \Theta(1/\ve^2)$ samples from $p$
\If {$\hat p(\mathcal{\bar A}) \geq \frac34 c_2\ve^2$} \label{ln:light-test}
\State \Return \reject \label{ln:early-reject}
\EndIf
\State Draw a multiset $S$ of $\mathrm{Poisson}(m_2)$ samples from $p$, where $m_2 = C\sqrt{n}/\ve^2$
\State Let $N_i$ be the number of occurrences of the $i$th domain element in $S$
\State Let $S'$ be the set of domain elements observed in $S$
\State $Z \leftarrow \sum_{i \in S' \cap \mathcal{A}} \frac{(N_i - m_2q_i)^2 - N_i}{m_2q_i} + m_2 (1 - q(S' \cap \mathcal{A}))$ \label{ln:statistic}
\If {$Z \leq \frac{3}{2}m_2\ve^2$}
\State \Return \accept
\Else 
\State \Return \reject
\EndIf 
\end{algorithmic}
\end{algorithm}

We note that the sample and time complexity are both $O(\sqrt{n}/\ve^2)$.
We draw $m_1 + m_2 = \Theta(\sqrt{n}/\ve^2)$ samples total.
All steps of the algorithm only involve inspecting domain elements where a sample falls, and it runs linearly in the number of such elements.
Indeed, Step~\ref{ln:statistic} of the algorithm is written in an unusual way in order to ensure the running time of the algorithm is linear.

We first analyze the test in Step \ref{ln:light-test} of the algorithm.
Folklore results state that with probability at least $99/100$, this preliminary test will reject any $p$ with $p(\mathcal{\bar A}) \geq c_2 \ve^2$, it will not reject any $p$ with $p(\mathcal{\bar A}) \leq \frac{c_2}{2} \ve^2$, and behavior for any other $p$ is arbitrary.
Condition on the event the test does not reject for the remainder of the proof.
Note that since both thresholds here are $\Theta(\ve^2)$, it only requires $m_1 = \Theta(1/\ve^2)$ samples, rather than the ``non-extreme'' regime, where we would require $\Theta(1/\ve^4)$ samples.

\begin{remark}
We informally refer to this ``extreme'' versus ``non-extreme'' regime in distribution testing.
To give an example of what we mean in these two cases, consider distinguishing $Ber(1/2)$ from $Ber(1/2 + \ve)$.
The complexity of this problem is $\Theta(1/\ve^2)$, and we consider this to be in the non-extreme regime.
On the other hand, distinguishing $Ber(\ve)$ from $Ber(2\ve)$ has a sample complexity of $\Theta(1/\ve)$, and we consider this to be in the extreme regime.
\end{remark}

We justify that any $p$ which may be rejected in Step \ref{ln:early-reject} (i.e., any $p$ such that $p(\mathcal{\bar A}) > \frac{c_2}{2} \ve^2$) has the property that $\dxs(p,q) > \ve^2$ (in other words, we do not wrongfully reject any $p$).

Consider a $p$ such that $p(\mathcal{\bar A}) \geq \frac{c_2}{2}\ve^2$.
Note that $\dxs(p, q) \geq \dxs(p_\mathcal{\bar A}, q_\mathcal{\bar A})$, which we lower bound as follows:
\begin{align*}
\dxs(p_\mathcal{\bar A}, q_\mathcal{\bar A})
&= \sum_{i \in \mathcal{\bar A}} \frac{(p_i - q_i)^2}{q_i} \\
&\geq \frac{n}{c_1 \ve^2} \sum_{i \in \mathcal{\bar A}} (p_i - q_i)^2 \\
&\geq \frac{n}{c_1 \ve^2} \cdot \frac{1}{n} \left(\sum_{i \in \mathcal{\bar A}} (p_i - q_i) \right)^2  \\
&\geq \frac{n}{c_1 \ve^2} \frac{\ve^4\left(\frac{c_2}{2} - c_1\right)^2}{n} \\
&= \frac{\left(\frac{c_2}{2} - c_1\right)^2}{c_1}\ve^2
\end{align*}
The first inequality is by the definition of $\mathcal{\bar A}$, the second is by Cauchy-Schwarz, and the third is since $p(\mathcal{\bar A}) \geq \frac{c_2}{2}\ve^2$ and $q(\mathcal{\bar A}) \leq c_1\ve^2$.
By our setting of $c_1$ and $c_2$, this implies that $\dxs(p, q) > \ve^2$, and we are not rejecting any $p$ which should be accepted.

For the remainder of the proof, we will implicitly assume that $p(\mathcal{\bar A}) \leq c_2 \ve^2$.


Let
$$Z' = \sum_{i \in \mathcal{A}} \frac{(N_i - m_2 q_i)^2 - N_i}{m_2q_i}.$$

Note that the statistic $Z$ can be rewritten as follows:
\begin{align*}
Z &= \sum_{i \in S' \cap \mathcal{A}} \frac{(N_i - m_2q_i)^2 - N_i}{m_2q_i} + m_2 (1 - q(S' \cap \mathcal{A})) \\
  &= \sum_{i \in S' \cap \mathcal{A}} \frac{(N_i - m_2q_i)^2 - N_i}{m_2q_i} + \sum_{i \in \mathcal{A} \setminus S'} m_2 q_i + m_2  q(\mathcal{\bar A}) \\
  &= \sum_{i \in S' \cap \mathcal{A}} \frac{(N_i - m_2q_i)^2 - N_i}{m_2q_i} + \sum_{i \in \mathcal{A} \setminus S'} \frac{(N_i - m_2q_i)^2 - N_i}{m_2q_i} + m_2  q(\mathcal{\bar A}) \\
  &= Z' + m_2 q(\mathcal{\bar A})
\end{align*}

We proceed by analyzing $Z'$.
First, note that it has the following expectation and variance:
\begin{align}
\E[Z'] &= m_2 \cdot \sum_{i \in \mathcal{A}} \frac{(p_i - q_i)^2}{q_i} = m_2 \cdot \dxs(p_\mathcal{A}, q_\mathcal{A}) \label{eqn:mean} \\
\Var[Z'] &= \sum_{i \in \mathcal{A}} \left[2\frac{p_i^2}{q_i^2} + 4m_2 \cdot \frac{p_i \cdot (p_i - q_i)^2}{q_i^2}\right] \label{eqn:variance}
\end{align}
These properties are proven in Section A of~\cite{AcharyaDK15}.

We require the following two lemmas, which state that the mean of the statistic is separated in the two cases, and that the variance is bounded.
The proofs largely follow the proofs of two similar lemmas in~\cite{AcharyaDK15}.
\begin{lemma}
\label{lem:means}
If $\dxs(p,q) \leq \ve^2$, then $\E[Z'] \leq m_2 \ve^2$. 
If $\dh(p,q) \geq \ve$, then $\E[Z'] \geq (2 - c_1 - c_2)m_2 \ve^2$.
\end{lemma}
\begin{proof}
The former case is immediate from (\ref{eqn:mean}).

For the latter case, note that
$$\dh^2(p,q) = \dh^2(p_\mathcal{A}, q_\mathcal{A}) + \dh^2(p_\mathcal{\bar A}, q_\mathcal{\bar A}).$$
We upper bound the latter term as follows:
\begin{align*}
\dh^2(p_\mathcal{\bar A}, q_\mathcal{\bar A}) 
&\leq \dtv(p_\mathcal{\bar A}, q_\mathcal{\bar A}) \\
&= \frac12 \sum_{i \in \mathcal{\bar A}} |p_i - q_i| \\
&\leq \frac12 \left(p(\mathcal{\bar A}) + q(\mathcal{\bar A})\right) \\
&\leq \left(\frac{c_1 + c_2}{2}\right)\ve^2 \\
\end{align*}
The first inequality is from Proposition \ref{prop:distanceinequalities}, and the third inequality is from our prior condition that $p(\mathcal{\bar A}) \leq c_2 \ve^2$.

Since $\dh^2(p,q) \geq \ve^2$, this implies $\dh^2(p_\mathcal{A}, q_\mathcal{A}) \geq \left(1 - \frac{c_1 + c_2}{2}\right)\ve^2$.
Proposition \ref{prop:distanceinequalities} further implies that $\dxs(p_\mathcal{A}, q_\mathcal{A}) \geq \left(2 - c_1 - c_2\right)\ve^2$.
The lemma follows from (\ref{eqn:mean}).
\end{proof}


\begin{lemma}
\label{lem:vars}
If $\dxs(p,q) \leq \ve^2$, then $\Var[Z'] = O(m_2^2 \ve^4)$. 
If $\dh(p,q) \geq \ve$, then $\Var[Z'] \leq O(\E[Z']^2)$.
The constant in both expressions can be made arbitrarily small with the choice of the constant $C$.
\end{lemma}
\begin{proof}
We bound the terms of (\ref{eqn:variance}) separately, starting with the first.

\begin{align}
2\sum_{i \in \mathcal{A}} \frac{p_i^2}{q_i^2} &= 2\sum_{i \in \mathcal{A}} \left(\frac{(p_i - q_i)^2}{q_i^2} + \frac{2p_iq_i - q_i^2}{q_i^2}\right) \nonumber \\
                                             &= 2\sum_{i \in \mathcal{A}} \left(\frac{(p_i - q_i)^2}{q_i^2} + \frac{2q_i(p_i - q_i) + q_i^2}{q_i^2}\right) \nonumber\\
                                             &\leq 2n + 2\sum_{i \in \mathcal{A}} \left(\frac{(p_i - q_i)^2}{q_i^2} + 2\frac{(p_i - q_i)}{q_i}\right) \nonumber\\
                                             &\leq 4n + 4\sum_{i \in \mathcal{A}} \frac{(p_i - q_i)^2}{q_i^2} \nonumber\\
                                             &\leq 4n + \frac{4n}{c_1\ve^2} \sum_{i \in \mathcal{A}} \frac{(p_i - q_i)^2}{q_i}\nonumber\\
                                             &= 4n + \frac{4n}{c_1\ve^2}\frac{E[Z']}{m_2} \nonumber\\
                                             &\leq 4n + \frac{4}{c_1C}\sqrt{n} E[Z']\label{eq:first-var-term-in}
\end{align}
The second inequality is the AM-GM inequality, the third inequality uses that $q_i \geq \frac{c_1\ve^2}{n}$ for all $i \in \mathcal{A}$, the last equality uses \eqref{eqn:mean}, and the final inequality substitutes a value $m_2 \geq C\frac{\sqrt{n}}{\ve^2}$.

The second term can be similarly bounded:
\begin{align*}
4m_2 \sum_{i \in \mathcal{A}} \frac{p_i(p_i - q_i)^2}{q_i^2} &\leq 4m_2 \left(\sum_{i \in \mathcal{A}} \frac{p_i^2}{q_i^2}\right)^{1/2}\left(\sum_{i \in \mathcal{A}} \frac{(p_i - q_i)^4}{q_i^2}\right)^{1/2} \\
                                                          &\leq 4m_2 \left(4n + \frac{4}{c_1C}\sqrt{n} E[Z'] \right)^{1/2}\left(\sum_{i \in \mathcal{A}} \frac{(p_i - q_i)^4}{q_i^2}\right)^{1/2} \\
                                                          &\leq 4m_2 \left(2\sqrt{n} + \frac{2}{\sqrt{c_1C}}n^{1/4} E[Z']^{1/2}\right)\left(\sum_{i \in \mathcal{A}} \frac{(p_i - q_i)^2}{q_i}\right) \\
                                                          &= \left(8\sqrt{n} + \frac{8}{\sqrt{c_1C}}n^{1/4} E[Z']^{1/2}\right)E[Z'].
\end{align*}
The first inequality is Cauchy-Schwarz, the second inequality uses (\ref{eq:first-var-term-in}), the third inequality uses the monotonicity of the $\ell_p$ norms, and the equality uses~\eqref{eqn:mean}.

Combining the two terms, we get
$$\Var[Z'] \leq 4n + \left(8 + \frac{4}{c_1C}\right)\sqrt{n} \E[Z']  + \frac{8}{\sqrt{c_1C}}n^{1/4} \E[Z']^{3/2}  .$$

We now consider the two cases in the statement of our lemma.
\begin{itemize}
\item
When $\dxs(p,q) \leq \ve^2$, we know from Lemma~\ref{lem:means} that $\E[Z'] \leq m_2 \ve^2$. 
Combined with a choice of $m_2 \geq C \frac{\sqrt{n}}{\ve^2}$ and the above expression for the variance, this gives:
\begin{align*}
\Var[Z']
& \leq \frac{4}{C^2}m_2^2\ve^4 + \left(\frac{8}{C} + \frac{4}{c_1C^2}\right)m_2^2 \ve^4+ \frac{8}{C\sqrt{c_1}}m_2^2 \ve^4 \\
& = \left(\frac{8}{C} + \frac{8}{C\sqrt{c_1}} + \frac{4}{C^2} + \frac{4}{c_1C^2} \right)m_2^2 \ve^4 = O(m_2^2 \ve^4).
\end{align*}

\item When $\dh(p,q) \geq \ve$, Lemma~\ref{lem:means} and  $m_2 \geq C\frac{\sqrt{n}}{\ve^2}$ give:
$$\E[Z'] \geq (2 - c_1 - c_2) m_2 \ve^2 \geq C(2 - c_1 - c_2) \sqrt{n}.$$

Similar to before, combining this with our expression for the variance we get:
\begin{align*}
\Var[Z']
&\leq \left(\frac{8}{C(2 -c_1 - c_2)} + \frac{8}{C\sqrt{c_1 (2 - c_1 - c_2)}} +  \frac{4}{C^2(2-c_1-c_2)^2} + \frac{4}{C^2c_1(2 - c_1 - c_2)} \right) \E[Z']^2 \\
&= O(\E[Z']^2).\qedhere
\end{align*}
\end{itemize}
\end{proof}

To conclude the proof, we consider the two cases.
\begin{itemize}
\item Suppose $\dxs(p,q) \leq \ve^2$. 
By Lemma~\ref{lem:means} and the definition of $\mathcal{A}$, we have that $\E[Z] \leq (1 + c_1)m_2\ve^2$. 
By Lemma~\ref{lem:vars}, $\Var[Z] = O(m_2^2\ve^4)$.
Therefore, for constant $C$ sufficiently large, Chebyshev's inequality implies $\Pr(Z > \frac32 m_2 \ve^2) \leq 1/10$.
\item
Suppose $\dh(p,q) \geq \ve$.
By Lemma~\ref{lem:means}, we have that $\E[Z'] \geq (2 - c_1 - c_2)m_2\ve^2$. 
By Lemma~\ref{lem:vars}, $\Var[Z'] = O(\E[Z']^2)$.
Therefore, for constant $C$ sufficiently large, Chebyshev's inequality implies $\Pr(Z' < \frac32 m_2 \ve^2) \leq 1/10$.
Since $Z \geq Z'$, $\Pr(Z < \frac32 m_2 \ve^2) \leq 1/10$ as well.
\end{itemize}

\subsection{Identity Testing with $\ell_2$ Tolerance}
\label{sec:id-lt}
In this section, we sketch the algorithms required to achieve $\ell_2$ tolerance for identity testing.
Since the algorithms and analysis are very similar to those of Algorithm 1 of~\cite{AcharyaDK15} and Algorithm~\ref{alg:testing}, the full details are omitted.

First, we prove Theorem~\ref{thm:ones-tv}.
The algorithm is Algorithm 1 of~\cite{AcharyaDK15}, but instead of testing on $p$ and $q$, we instead test on $p^{+\frac12}$ and $q^{+\frac12}$, as defined in Proposition~\ref{prop:mixing}.
By this proposition, this operation preserves total variation and $\ell_2$ distance, up to a factor of $2$, and also makes it so that the minimum probability element of $q^{+\frac12}$ is at least $1/2n$. 
In the case where $\dlt(p,q) \leq \frac{\ve}{\sqrt{n}}$, we have the following upper bound on $\E[Z]$:
$$\E[Z'] = m \sum_{i \in \mathcal{\bar A}} \frac{(p_i - q_i)^2}{q_i} \leq O\left( m \cdot n \cdot \dlt^2(p,q)\right) \leq O(m_2 \ve^2).$$
This is the same bound as in Lemma 2 of~\cite{AcharyaDK15}.
The rest of the analysis follows identically to that of Algorithm 1 of~\cite{AcharyaDK15}, giving us Theorem~\ref{thm:ones-tv}.

Next, we prove Theorem~\ref{thm:ones-h}.
We observe that Algorithm~\ref{alg:testing} as stated can be considered as $\ell_2$-tolerant instead of $\chi^2$-tolerant, if desired.
First, we do not wrongfully reject any $p$ (i.e., those with $\dlt(p,q) \leq \frac{\ve^2}{\sqrt{n}}$) in Step~\ref{ln:early-reject}.
This is because we reject in this step if there is $\geq \Omega(\ve^2)$ total variation distance between $p$ and $q$ (witnessed by the set $\mathcal{\bar A}$), which implies that $p$ and $q$ are far in $\ell_2$-distance by Proposition~\ref{prop:ltinequalities}.
It remains to prove an upper bound on $\E[Z']$ in the case where $\dlt(p,q) \leq \frac{\ve^2}{\sqrt{n}}$.
$$\E[Z'] = m_2 \dxs(p,q) = m_2 \sum_{i \in \mathcal{\bar A}} \frac{(p_i - q_i)^2}{q_i} \leq O\left( m_2 \cdot \left(\frac{n}{\ve^2}\right)\cdot \dlt^2(p,q)\right) \leq O(m_2 \ve^2).$$
We note that this is the same bound as in Lemma~\ref{lem:means}.
With this bound on the mean, the rest of the analysis is identical to that of Theorem~\ref{thm:ones-csq-h}, giving us Theorem~\ref{thm:ones-h}.

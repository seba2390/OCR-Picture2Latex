% \documentclass[conference]{IEEEtran}
\documentclass[letterpaper, 10 pt, conference]{ieeeconf}
\IEEEoverridecommandlockouts 
\overrideIEEEmargins 
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
%\usepackage[linesnumbered]{algorithm2e}
\usepackage[algo2e]{algorithm2e} 
\usepackage{graphicx}
\usepackage{textcomp}
\let\labelindent\relax
\usepackage[inline]{enumitem}
\usepackage{xcolor}
\usepackage{caption}
\usepackage{graphicx}
\usepackage{algorithm}  

\usepackage{diagbox,slashbox}
\usepackage{subcaption}
\usepackage{hyperref}
\usepackage{verbatim}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
    
% Space saving List environment for itemizing
\newenvironment{myitemize}{\begin{list}{$\bullet$}
{\setlength{\topsep}{1mm}
\setlength{\itemsep}{0.25mm}
\setlength{\parsep}{0.25mm}
\setlength{\itemindent}{0mm}
\setlength{\partopsep}{0mm}
\setlength{\labelwidth}{15mm}
\setlength{\leftmargin}{4mm}}}{\end{list}}

    
\newcommand{\hengyi}[1]{{{\color{blue} \textbf{(Hengyi: #1)}}}}
\newcommand{\ruochen}[1]{{{\color{blue} \textbf{(Ruochen: #1)}}}}
\newcommand{\qi}[1]{{{\color{blue} \textbf{(Qi: #1)}}}}
\newcommand{\alfred}[1]{{{\color{blue} \textbf{(Alfred: #1)}}}}
\newcommand{\junjie}[1]{{{\color{blue} \textbf{(Junjie: #1)}}}}
\newcommand{\takami}[1]{{{\color{blue} \textbf{(takami: #1)}}}}

\begin{document}

\title{\LARGE \bf End-to-end Uncertainty-based Mitigation of Adversarial Attacks to Automated Lane Centering\\
%{\footnotesize \textsuperscript{*}Note: Sub-titles are not captured in %Xplore and
%should not be used}
}

% \author{\IEEEauthorblockN{1\textsuperscript{st} Given Name Surname}
% \IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
% \textit{name of organization (of Aff.)}\\
% City, Country \\
% email address}
% \and
% \IEEEauthorblockN{2\textsuperscript{nd} Given Name Surname}
% \IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
% \textit{name of organization (of Aff.)}\\
% City, Country \\
% email address}
% }
% \author{
% \IEEEauthorblockN{Ruochen Jiao\IEEEauthorrefmark{1}\thanks{\IEEEauthorrefmark{1} These two authors contribute equally to the work.}, Hengyi Liang\IEEEauthorrefmark{1}, Takami Sato\IEEEauthorrefmark{2}, Junjie Shen\IEEEauthorrefmark{2}, Qi Alfred Chen\IEEEauthorrefmark{2}, Qi Zhu}
% \IEEEauthorblockA{Northwestern University \qquad \IEEEauthorrefmark{2} University of California, Irvine}
% }

\author{Ruochen Jiao$^{1,2}$, Hengyi Liang$^{1,2}$, Takami Sato$^{3}$, Junjie Shen$^{3}$, Qi Alfred Chen$^{3}$, Qi Zhu$^{2}$%
\thanks{$^{1}$ These two authors contribute equally to the work.}%
\thanks{$^{2}$ Ruochen Jiao, Hengyi Liang and Qi Zhu are with the Department of Electrical and Computer Engineering, Northwestern University, IL, USA.}%
\thanks{$^{3}$ Takami  Sato, Junjie Shen and Qi Alfred Chen are with the Department of Electrical Engineering and Computer Science, University of California, Irvine, CA, USA.}%
}

%\author{Xiangguo Liu$^{1}$, Neda Masoud$^{2}$, Qi Zhu$^{1}$% <-this % stops a space
%\thanks{*This work was not supported by any organization}% <-this % stops a space
%\thanks{$^{1}$Xiangguo Liu and Qi Zhu are with the Department of Electrical and Computer Engineering, Northwestern University, Evanston, IL 60201, USA.
%        {\tt\small xg.liu@u.northwestern.edu, qzhu@northwestern.edu.}}%
%\thanks{$^{2}$Neda Masoud is with the Department of Civil and Environmental Engineering, University of Michigan, Ann Arbor, MI 48109, USA.
%        {\tt\small nmasoud@umich.edu.}}%
%}

%author{Ruochen Jiao\IEEEauthorrefmark{1}\thanks{\IEEEauthorrefmark{1} These two authors contribute equally to the work.}, Hengyi Liang\IEEEauthorrefmark{1}, Takami Sato\IEEEauthorrefmark{2}, Junjie Shen\IEEEauthorrefmark{2}, Qi Alfred Chen\IEEEauthorrefmark{2}, Qi Zhu}
\maketitle

\begin{abstract}
In the development of advanced driver-assistance systems (ADAS) and autonomous vehicles, machine learning techniques that are based on deep neural networks (DNNs) have been widely used for vehicle perception. These techniques offer significant improvement on average perception accuracy over traditional methods, however have been shown to be susceptible to adversarial attacks, where small perturbations in the input may cause significant errors in the perception results and lead to system failure. Most prior works addressing such adversarial attacks focus only on the sensing and perception modules. In this work, we propose an end-to-end approach that addresses the impact of adversarial attacks throughout perception, planning, and control modules. In particular, we choose a target ADAS application, the automated lane centering system in OpenPilot, quantify the perception uncertainty under adversarial attacks, and design a robust planning and control module accordingly based on the uncertainty analysis.  
%However, these techniques often lack of the consideration of potential uncertainties in the environment and can be leveraged malicious attackers. In this work, we conduct an end-to-end analysis of a target ADAS application, automated lane centering, to shed light on how an adversarial attack can affect the result of perception module, propagate through the pipeline and finally cause the steering angle pointing to a wrong direction. We propose to design an end-to-end mitigation strategy, i.e. explicitly considering uncertainties in perception, planning and control modules, to alleviate the impact of potential adversarial attacks. 
We evaluate our proposed approach using both public dataset and production-grade autonomous driving simulator. The experiment results demonstrate that our approach can effectively mitigate the impact of adversarial attack and 
can achieve $55\%\sim90\%$ improvement over the original OpenPilot.
\end{abstract}

%\begin{IEEEkeywords}
%Autonomous driving, ADAS, adversarial attacks
%\end{IEEEkeywords}

\section{Introduction}
Machine learning techniques have been widely adopted in the development of autonomous vehicles and advanced driver-assistance systems (ADAS). 
%Last decades witnessed great progress in autonomous vehicle and automotive driving assistance systems (ADAS) with the development of deep learning. 
% The  autonomous vehicle (e.g. Baidu Apollo, Autoware etc. \cite{raju2019performance}) and ADAS (e.g. Tesla AutoPilot, OpenPilot \cite{openpilot} etc.) 
Most autonomous driving and ADAS software stacks, such as Baidu Apollo~\cite{baiduapollo} and OpenPilot~\cite{openpilot}, are generally composed of four-layered modules: sensing, perception, planning, and control~\cite{yurtsever2020survey}. The sensing and perception modules collect data from the surrounding environment via a variety of sensors such as cameras, LiDAR, radar, GPS and IMU, and use learning-based perception algorithms to process the collected data and understand the environment. The planning and control modules leverage the perception results to propose a feasible trajectory and generate detailed commands for the vehicle to track the trajectory. In those systems, deep neural networks (DNNs) are widely used for sensing and perception in transportation scenarios~\cite{gao2018object,xu2020data,siam2017deep}
%chen2017multi,buyval2018realtime,zhou2018voxelnet}
, such as semantic segmentation, object detection and tracking, as they often provide significantly better average perception accuracy over traditional feature-based methods. For planning and control, there are also increasing interests in applying neural networks with techniques such as reinforcement learning and imitation learning~\cite{rhinehart2018deep}, due to their capabilities of automatically learning a strategy within complex environment. 
%In sensing stage, cameras, LiDAR, GPS and IMU are widely applied to collect data from surrounding environment. 
%and then multi sensor fusion technologies can synthesize and calibrate the data produced by these sensors\cite{gao2018object}. 
%For perception and prediction, the deep learning based models\cite{gao2018object,xu2020data} process these inputs to give predictions and they achieved impressive performance. The planner will propose feasible trajectory according to the perceived environment and low-level controller will produce detailed command to track the trajectory. 

However, the adoption of DNN-based techniques in ADAS and autonomous driving also bring significant challenges to vehicle safety and security, given the ubiquitous uncertainties of the dynamic environment, the disturbances from environment interference, transient faults, and malicious attacks, and the lack of methodologies for predicting DNN behavior~\cite{zhu2020know}. In particular, extensive studies have shown that DNN-based perception tasks, such as image classification and object detection, may be susceptible to adversarial attacks~\cite{eykholt2018robust,chen2018shapeshifter}, where small perturbations to sensing input could result in drastically different perception results. There are also recent works on attacking DNN-based perception in ADAS and autonomous vehicles by adding adversarial perturbations to the physical environment in a stealthy way~\cite{zhou2020deep,sato2020hold,song2018physical,eykholt2018robust,sitawarin2018darts}. For instance, \cite{sato2020hold} generates a dirty road patch with carefully-designed adversarial patterns, which can appear as normal dirty patterns for human drivers while leading to significant perception errors and causing vehicles to deviate from their lanes within as short as 1 second. %\alfred{modified a bit as ``hardly noticeable by human'' is not true}
% sitawarin2018darts,boloor2019simple
%Although cyber-physical systems benefit greatly from deep learning components, the learning-enabled systems are also more vulnerable to new types of interference and attacks. The adversarial attacks on tasks such as image classification, object detection has been well studied \cite{eykholt2018robust,chen2018shapeshifter}. In recent years, there are some works focusing on the security of autonomous driving systems. In \cite{sato2020hold}, the authors propose an approach to generate a patch to attack deep learning based lane keeping systems. In \cite{cai2020real}, they focus on detecting out-of-distribution input and evaluate their impact on the system.  


%However, the safety and security of these learning-based ADAS and autonomous systems can hardly be guaranteed or even quantitatively analyzed, given the ubiquitous uncertainties in surrounding environment, complexity of multi-module systems, and the unpredictability of the DNN behaviors\cite{zhu2020know}. Some works propose methods to detect out-of-distribution inputs\cite{cai2020real} and design probabilistic deep learning based perception models\cite{sun2018probabilistic} and planning models\cite{hruschka2019uncertainty}, while few works focus on analyzing and mitigating the affect of attacks or noises in a system level.

The prior works addressing adversarial attacks mostly focus on detecting anomaly in the input  data~\cite{kimin2018simple,zheng2018robust,lu2017safetynet,yin2020adversarial}
%,yin2020adversarial,metzen2017detecting,} 
or making the perception neural networks themselves more robust against input perturbations~\cite{goodfellow2015explaining,madry2019deep,carlini2017towards}. In ADAS and autonomous driving, however, the impact of adversarial attacks on system safety and performance is eventually reflected through vehicle movement, taking into account of planning and control decisions. Thus, we believe that for those systems, it is important to take a holistic and end-to-end approach that addresses adversarial attacks throughout the sensing, perception, planning and control pipeline.
%papernot2016distillation,miyato2016distributional

In our preliminary work recently published in a work-in-progress paper~\cite{liang2021endtoend}, we studied the automated lane centring (ALC) system in OpenPilot~\cite{openpilot}, a popular open-source ADAS implementation, and investigated how the dirty road patch attack from~\cite{sato2020hold} could affect perception, planning and control modules. We discovered that a \emph{confidence score} generated by the perception module could serve as a sensitive signal for detecting such attack, however it does not quantitatively measure the extent of the attack and cannot be effectively used for mitigation. In this paper, motivated by the findings from~\cite{liang2021endtoend}, we propose a novel end-to-end approach for \emph{detecting and mitigating} the adversarial attacks on the ALC system. Our approach quantitatively estimates the \emph{uncertainty} of the perception results, and develops an adaptive planning and control method based on the uncertainty analysis to improve system safety and robustness.  
%In our previous related work~\cite{liang2021endtoend}, to study the system robustness and safety, we first analyze the pipeline of commercial automated lane centering systems and identify how different modules interact with each other under attacks. 
%In this paper, we propose a system level design and framework with uncertainty estimation, risk awareness, and adaptive planner and controller. Through the analyses and observations, we utilize the perception confidence as a signal to indicate risks and a threshold to adjust modes. In addition to qualitative analysis of risks, our work focus on explicitly quantify the uncertainty and the conduct adaptive planning and control to improve the system's safety and robustness.     

In the literature, methods have been proposed to address the uncertainties of various modules in the ADAS and autonomous driving pipeline. For instance, the method proposed in~\cite{nakashima2020uncertainty} utilizes estimated uncertainty as a threshold to decide which sensor is reliable. %The work in~\cite{hu2018probabilistic} uses mixture density network to estimate the intention, location and time information of surrounding vehicles. 
In the OpenPilot implementation, Multiple Hypothesis Prediction~\cite{rupprecht2017learning} is utilized to estimate the prediction confidence. Some works propose methods to detect out-of-distribution inputs~\cite{cai2020real} and design probabilistic deep learning based perception models~\cite{sun2018probabilistic} and planning models~\cite{hruschka2019uncertainty}. Different from these prior methods, our approach takes a system-level view and addresses the uncertainty from adversarial attacks throughout sensing, perception, planning and control. While this work focuses on the dirty road patch attack, we believe that our methodology can be applied to other adversarial attacks that cause perception uncertainties, and may be extended to address more general uncertainties (e.g., those caused by environment interference or transient faults).  
Specifically, our work makes the following contributions:
\begin{myitemize}
    \item We analyzed the impact of dirty road patch attack across the ADAS pipeline, and developed a method to quantitatively measure the perception uncertainty under attack, based on the analysis of both model and data uncertainties in the perception neural network. 
    \item We developed an uncertainty-aware adaptive planning and control method to improve system safety and robustness under adversarial attacks. 
    \item We conducted experiments on both public dataset and LGSVL~\cite{rong2020lgsvl}, a production-grade autonomous driving simulator. The results demonstrate that our approach can significantly improve the system robustness over the original OpenPilot implementation when under adversarial attacks, reducing the deviation of lateral deviation by $55\%\sim90\%$.
\end{myitemize}
%1. We analyze the safety of deep learning based automated lane centering systems and identify proper interfaces between modules that can be used to improve the system robustness.
%2. We proposes and implement a holistic frameworks to estimate the uncertainty from deep learning based perception modules and design robust planner and controller based on the uncertainty bound and perception confidence.

%3. We experimentally show that our approach outperform (more robust than) current commercial driving assistance systems against malicious physical attacks.




%Last decades witnessed great progress in autonomous vehicle and automotive driving assistance systems (ADAS) with the development of deep learning. The autonomous vehicle (e.g. Baidu Apollo, Autoware etc.) and ADAS (e.g. Tesla AutoPilot, OpenPilot etc.) are generally composed of four layered modules: sensing, perception, planning and controlã€€\cite{yurtsever2020survey}. Sensing modules detect physical presences and convert the physical signals into data which can be processed by the perception module. The camera, Lidar, Radar, and GPS are commonly deployed in driving assistance systems \cite{badue2020self}.

The rest of the paper is organized as follows. Section~\ref{sec:sys_model} introduces the ALC system in OpenPilot and the adversarial attack model to this system. Section~\ref{sec:our_approach} presents our uncertainty-based mitigation approach to address such adversarial attacks. Section~\ref{sec:experiments} shows the experimental results.



\begin{comment}
\section{Background}
\subsection{Deep Learning based Driving Assistance Systems}
 Recently, researchers applied various algorithms, especially deep learning algorithms, to transportation scenarios. In \cite{siam2017deep,chen2017multi,buyval2018realtime}, semantic segmentation, object detection and tracking are used to understand the environment in roads. In \cite{zhou2018voxelnet}, Lidar-based 3D object detection algorithms achieve a promising performance to detect pedestrians and vehicles. For planning and control modules, reinforcement learning and imitation learning also show considerable performance in path planning and control \cite{rhinehart2018deep}. However, few researches illustrate how deep learning based modules interact with other parts and influence the whole system, which is crucial for the system's safety. In this paper, we conduct end-to-end safety analysis and propose a holistic robust mitigation strategy with general significance.  

\subsection{Adversarial Attack Against Driving Assistance Systems}
Although cyber-physical systems benefit greatly from deep learning components, the learning-enabled systems are also more vulnerable to new types of interference and attacks. The adversarial attacks on tasks such as image classification, object detection has been well studied \cite{eykholt2018robust,chen2018shapeshifter}. In recent years, there are some works focusing on the security of autonomous driving systems. In \cite{sato2020hold}, the authors propose an approach to generate a patch to attack deep learning based lane keeping systems. In \cite{cai2020real}, they focus on detecting out-of-distribution input and evaluate their impact on the system.   

\subsection{Uncertainty Aware Autonomous Systems}
A robust design for autonomous systems must consider various uncertainty such as the inherent uncertainties from the dynamic environment, the disturbances to system operations from environment interference, transient errors, and malicious attacks ~\cite{zhu2021safe}. In sensing and perception stage, the work\cite{nakashima2020uncertainty} propose a method to utilize estimated uncertainty as a threshold to decide which sensor is reliable. In prediction and planning stage, the work\cite{hu2018probabilistic} proposed a method using mixture density network to estimate the intentions, location and time information for surrounding vehicles. In original OpenPilot, Multiple Hypothesis Prediction\cite{rupprecht2017learning} is utilized to estimate the confidence of prediction. There are also works design stochastic motion controller considering uncertainty\cite{suh2018stochastic}. In our work, we combine the different methods to estimate confidence and quantify uncertainty, and then utilize the  uncertainty to design adaptive planner and controller in a cross-layer way. 
\end{comment}


\input{models_and_systems}
\input{our_approach}
\input{experiments}

\section{Conclusions}

In this work, we proposed a novel end-to-end uncertainty-based mitigation approach for adversarial attacks to the automated lane centering system. Our approach includes an uncertainty estimation method considering both data and model uncertainties, an uncertainty-aware trajectory planner, and an uncertainty-aware adaptive controller. Experiments on public dataset ad a production-grade simulator demonstrate the effectiveness of our approach in mitigating the attack effect. We believe that our methodology can be applied to other ADAS and autonomous driving functions, and will explore them in future work.


%In this work, we quantitatively analyze the impact of adversarial attacks throughout the pipeline of automated lane centering system. Based on the analysis, we design an end-to-end uncertainty aware mitigation method that includes  

%adaptive mitigation strategy that explicitly considers uncertainties. We test our proposed approach with public dataset and also conduct experiments with production-grade simulator. In experiments, our method mitigates the affect of adversarial attacks greatly. In the future, we will extend our end-to-end robust design to other ADAS applications and we can continuously improve the modules in the pipeline e.g. designing an uncertainty aware reinforcement learning based planner and controller.
%\begin{thebibliography}{00}

%\end{thebibliography}
%\bibliographystyle{abbrv}
\bibliographystyle{IEEEtran}
\bibliography{reference}

\end{document}

\section{Our End-to-end Uncertainty-based Mitigation Approach for Adversarial Attacks}
\label{sec:our_approach}

%Our approach extends the OpenPilot software stack by leveraging the Monte Carlo Dropout methods to estimate model uncertainties.
As shown later in Fig.~\ref{fig:pipeline}, the perception module in our approach involves two neural network models. The original OpenPilot perception model is used in the normal operation mode (i.e., when the overall prediction confidence is high), where it outputs predicted path, lanes and confidence scores. %The other neural network is to estimate model uncertainty. %obtained by adding dropout layers to the fully-connected layers in the original OpenPilot driving model. 
%The second model engages when the overall prediction confidence drops blow a threshold. When under adversarial attack, 
When anomaly is detected, a new perception neural network is used to estimate model uncertainty while generating perception output. 
The trajectory planner will take the uncertainties into consideration and generate a desired path that is less affected by the adversarial attack. Correspondingly, in the lower-level control, more conservative and uncertainty-aware constraints are used in the MPC and a speed adaptation method is applied to ensure safety. The details of our proposed approach are introduced below.




% We consider $\sigma_{total}$ as the estimation of prediction error as introduced in section~\ref{sec:pre} and further shrink the feasible region (\hengyi{need to explain "feasible region" in system model section}) by bounding the predicted left lane and right lane. Then the bounded lanes is passed to the MPC controller to generate the steering angle for the incoming control period. Moreover, we adapt the ego vehicle speed in case the confidence of the prediction decrease dramatically. 


\subsection{Perception Confidence as Signal of Attack}


Measuring the confidence of the DNN's prediction is a significant challenge. In different perception tasks, various methods are applied to estimate the perception confidence. For instance, in YOLO~\cite{redmon2018yolov3}, intersection over union (IOU) measures the confidence of regression. In OpenPilot's neural network, a multiple hypotheses prediction (MHP)~\cite{rupprecht2017learning} classifier is trained with cross entropy loss and its output can represent how confident the lane line is predicted correctly~\cite{ramos2018deconstructing}. 

To investigate how the perception confidence affects the system safety, we conduct a series of experiments with different settings of the attacks (early results reported in our preliminary work~\cite{liang2021endtoend}, which focuses on the attack detection alone). As indicated in Fig.~\ref{fig:prob_drop}, we observe a general phenomenon that the confidence score of the perception module drops significantly when the vehicle is approaching the dirty patch, while the confidence score keeps in a relatively stable level in benign cases or under ineffective noises. Fig.~\ref{fig:conf} also shows the consistency between the drop in confidence score and the vehicle's lateral deviation under attack. As discussed in Section~\ref{sec:sys_model}, the desired path generated by OpenPilot's path planner can be considered as a weighted average of the predicted left lane, predicted right lane, and the predicted path, with the confidence scores as weights. Under the impact of the dirty patch, confidence of the predicted two lanes drops, resulting in more weights on predicted path. However, the predicted path deviates from the middle of the line eventually, and the desired path leans towards wrong directions. 
%Besides, the lower-level controller will compute the corresponding steering angle based on this wrong desired path. 


    Based on such observation, we think that the perception confidence can be utilized as a signal to indicate whether the model (perception module) is under adversarial attack. Our mitigation strategy leverages this signal to switch between different perception modules and applies adaptive planning and control accordingly. 
    
%\begin{enumerate*}
    % \item a signal to indicate whether the model (perception module)  is under adversarial interference or noises, 
%    \item a signal to indicate whether the vehicle is driven under trusted scenarios, and
%    \item an interface between the perception module and the planning and control module.
%\end{enumerate*} 
%Combining these two points, the system can adjust the planning and control algorithms according to the performance of perception module, so as to mitigate the effect the attack or reduce uncertainty in general. 
%\junjie{do you mean ``mitigate the effect of the attack or reduce uncertainty in general''?}.



%  \begin{figure}
%     \centering
%     \includegraphics[width=\columnwidth]{figures/demo_prob_drop.pdf}
%     \caption{Trend of the confidence score when the dirty patch is on road: the patch starts around 53 meters and is 96 meters long. The confidence of the prediction drops significantly when the ego vehicle can 'see' the patch.}
%     \label{fig:prob_drop}
% \end{figure}
\begin{figure}
    \centering
    \begin{subfigure}{\columnwidth}
        \includegraphics[width=\textwidth]{figures/demo_probability_drop.pdf}
        \caption{}
        \label{fig:prob_drop}
    \end{subfigure}%
    
    \begin{subfigure}{\columnwidth}
        \includegraphics[width=\textwidth]{figures/demo_trajectory_deviate.pdf}
        \caption{}
        \label{fig:traj_deviate}
    \end{subfigure}
    \caption{The patch starts around 40 meters and is 96 meters long. (a) shows that the confidence of the prediction drops, (b) plots the lateral deviation of the ego vehicle. For more details, please see our preliminary work in~\cite{liang2021endtoend}.%(a) shows that the confidence of the prediction drops significantly when the ego vehicle can ``see'' the patch; (b) plots the lateral deviation of the ego vehicle. For more details, please see our preliminary work in~\cite{liang2021endtoend}.
    }
    \label{fig:conf}
    \vspace{-12pt}
\end{figure}

\begin{figure*}[!ht]
    \centering
    \includegraphics[width=1.8\columnwidth]{figures/proposed_pipeline_n.pdf}
    \caption{Overview of our proposed ALC pipeline with uncertainty-based mitigation for adversarial attacks.}
    \label{fig:pipeline}
\end{figure*}
\subsection{Uncertainty Estimation and Safety Bound}\label{uncertainty bound}

While the confidence scores generated by the OpenPilot perception module \emph{qualitatively} show the existence of the attack, they do not \emph{quantitatively} measure the extent of the attack and cannot be effectively used for mitigation. Thus, we developed a new approach for quantifying the perception \emph{uncertainty} that considers both data uncertainty and model uncertainty.
%Although deep neural networks can reach unprecedented accuracy in many tasks, DNN's predictions are unreliable when the input sample is out of the training distribution or corrupted by noise. %Measuring the uncertainty of neural networks' output is crucial for safety-critical applications such as  autonomous driving. 
%Prediction uncertainty in deep neural networks generally derives from two sources: data uncertainty and model uncertainty. 
Data uncertainty is caused by the input noise/disturbance and intrinsic randomness of the real data while model uncertainty results from a lack of training data in certain areas of the input domain and the test example being out of distribution.  By assuming that the data uncertainty follows a normal distribution, we can estimate it by using maximum likelihood approach. In neural networks, the model can take mean negative log-likelihood function 
%\junjie{do we need these two acronyms? ML is easy to be confused with Machine Learning.} 
as a loss function to capture the aleatory uncertainty~\cite{kendall2017uncertainties}. In Equation~\eqref{log-likelihood} below, $\hat{\mu}(x)$ is the predicted mean value and the distribution variance $\sigma$ is the estimated data uncertainty:
% The maximum likelihood approach can give a relatively precise estimate of the data uncertainty along with the mean value. %However, the estimator needs to be trained on a large-scale dataset for long time. For already-trained model, data noise can be forward-propagated through the network via Assumed Density Filtering(ABF)[], The ABF replaces each network activation by probability distributions and it can output not only the predictions $\mu$ but also the corresponding variance $\sigma$.  

\begin{equation}
\mathcal{L}(x, y)=-\log \phi(y \mid x)=\frac{\log \hat{\sigma}^{2}_{data}(x)}{2}+\frac{(y-\hat{\mu}(x))^{2}}{2 \hat{\sigma}^{2}_{data}(x)}\label{log-likelihood}
\end{equation}

To estimate model uncertainty, similarly to the Bayesian approaches, we consider that there are distributions over the weights of neural networks and the parameters of the distribution are trained on the training dataset. The weight distribution after training can then be written as $p(\omega \mid \mathrm{X}, \mathrm{Y})$. We apply the Monte Carlo methods to estimate the distribution by adding dropout layers to sample weights with dropout rate $\Phi$~\cite{gal2016dropout}:
\begin{equation}
p(\omega | \mathbf{X}, \mathbf{Y}) \approx \operatorname{Bern}(\omega ; \Phi)\label{dropout}
\end{equation}
Therefore, the model uncertainty can be estimated as~\cite{loquercio2020general}:
\begin{equation}
\sigma_{model}^{2} = \frac{1}{T} \sum_{t=1}^{T} \left(\boldsymbol{\mu}_{t}-\overline{\boldsymbol{\mu}}\right)^{2}\label{monte carlo}
\end{equation}
The total variance can be derived by adding the model variance $\sigma_{model}^{2}$ and the data variance $\sigma_{data}^{2}$, as shown in Equation~\eqref{total error}.
To the best of our knowledge, current commercial driving assistance systems do not take the perception uncertainty into consideration. 
\begin{equation}
\sigma_{total}^{2} = \sigma_{model}^{2}+\sigma_{data}^{2}\label{total error}
\end{equation}


When the overall prediction confidence drops below a threshold, we deem that the ego vehicle is experiencing significant environment noise or under adversarial attack. Instead of using the original prediction result, we leverage the obtained prediction uncertainties to more conservatively measure the bounds of left lane and right lane. Let $\mu_{i}$ be the predicted mean of the $i$-th point of the lane and $\sigma_{total,i}$ be the corresponding error, then $[\mu_{i}-\sigma_{total,i},\mu_{i}+\sigma_{total,i}]$ can be considered as the range where the ``true'' lane point may reside. Specifically, we use $\mu_{i}-\sigma_{total,i}$ as the lower bound of left lane if $\mu_{i}$ is a point on the left lane while $\mu_{i}+\sigma_{total,i}$ as the upper bound if it is a point on the right lane. We use a polynomial function $p(i)$ to approximate the points along the lane. The problem can be cast as a weighted least square fitting. For left lane, we fit the curve by minimizing $\sum_{i}^{N}\omega_{i}|p(i)-(\mu_{i}-\sigma_{total,i})|$; for right lane, we minimize $\sum_{i}^{N}\omega_{i}|p(i)-(\mu_{i}+\sigma_{total,i})|$. Here, $\omega_{i}$ is the weight. Since points further away tend to exhibit larger uncertainties, we assign closer points with larger weights by setting $\omega_{i} = \frac{1}{\sigma_{data}}$. Fig.~\ref{fig:demo_bound_predict} shows the bounded predicted lanes using our approach. As we can see, the bounded prediction is more conservative compared to the original approach. In most cases, the bounded left lane and right lane tend to intersect at some point. 
\begin{figure}[!ht]
    \centering
    \includegraphics[width=\columnwidth]{figures/demo_bounded_vs_predicted_v2.pdf}
    \caption{The original OpenPilot prediction and the bounded line lanes after compensating the original prediction with estimated uncertainties. %positive dashed blue points and negative dashed orange points are the original prediction; the solid curves are the fitting results after compensating the original points with estimated errors. %\takami{no path?}
    }
    \label{fig:demo_bound_predict}
\end{figure}

\subsection{Uncertainty-aware Trajectory Planner}
In the original design of OpenPilot, the desired path can be considered as a weighted sum of the left lane, right lane and predicted path (generated by the perception module). Lanes/path with higher confidence score will be assigned with larger weights and have more impact on the desired path. However, we find out that this approach cannot handle adversarial scenarios. Considering that the attacker can manipulate sensor data such that the confidence scores of the predicted left lane and right lane are much lower while the predicted path is bent towards left. In this case, the desired path will also lean towards left even though the vehicle is driving on a straight road. We argue that, when the confidence score drops below certain threshold, we should explicitly consider the uncertainties instead of just relying on the predicted road curves. That is, we use the uncertainty-bound area derived above to constrain vehicle's speed and steering angle.


The pseudo-code to calculate the desire path in our uncertainty-aware approach is shown in  Algorithm~\ref{alg:cal_d_poly}. Lines 5-6 calculate the accumulated uncertainties along the left lane and right lane. $\omega_{left}$ and $\omega_{right}$ are the corresponding weights assigned to the bounded left lane and bounded right lane. $p_{weighted}$ is the weighted path and the final desired path is the weighted average of $p_{weighted}$ and $p_{openpilot}$ (the latter is the desired path obtained by running the original OpenPilot). The intuition is that if the current prediction has low overall confidence, we will rely more on the uncertainty-aware bounded prediction to mitigate the adversarial attack.
\begin{algorithm}[!h]
\caption{DesiredPath: Uncertainty-aware Desired Path Calculation}
\label{alg:cal_d_poly}
\begin{algorithmic}[1]
\REQUIRE \text{Polynomial for lane lines:
$p_{l}, p_{r}$;}
\text{the overall confidence of the prediction: $lr_{conf}$}
% \text{the confidence of the prediction $l_{conf}$ and $r_{conf}$}
% \STATE $lr_{conf} = l_{conf}+r_{conf}-l_{conf}*r_{conf}$
\IF{total confidence $lr_{conf}$ is less than 
$Conf\_Threshold$}
%$H_{confidence}$}
    \STATE use the original Openpilot to generate the desired path $p_{openpilot}$
    \RETURN $p_{openpilot}$
\ELSE
    \STATE $left_{sum} = \sum_{i=1}^{n}\sigma_{left,i}$ 
    \STATE $right_{sum} = \sum_{i=1}^{n}\sigma_{right,i}$ 
    \STATE $total_{sum} = left_{sum}+right_{sum}$
    \STATE $\omega_{left} = \frac{right_{sum}}{total_{sum}}$
    \STATE $\omega_{right} = \frac{left_{sum}}{total_{sum}}$
    \STATE $p_{weighted} = \omega_{left}*p_{l}+\omega_{right}*p_{r}$
    \STATE $desired\ path = (1-lr_{conf})*p_{weighted}+lr_{conf}*p_{openpilot}$ 
\ENDIF
\RETURN $desired\ path$
\end{algorithmic}
\end{algorithm}

Besides utilizing the estimated uncertainty to bound the safe trajectory area and produce the desired path, we also make use of the temporal locality of the path prediction. We notice that the perception and planning modules can produce a safe desired path for about 100 meters with frequency of 20 Hz while the vehicle will only move forward up to several meters in the period. Therefore, the information of consecutive frames has considerable locality and relevance. We maintain a state cache to store the perception output of most recent $k$ consecutive frames. In our experiment, we pick $k=7$ to store the information of the past $0.35$ seconds. In case of adversarial scenarios, the system will select the perception output with highest confidence score from the state cache as the planner input. Taking advantage of the locality, the system robustness to short-term inference will be improved.  

\subsection{Adaptive Controller}
\subsubsection{Uncertainty-aware cost function}
An MPC controller is used to generate an appropriate steering command based on the ego vehicle status and the desired path. We modify the MPC controller by explicitly considering the more conservative uncertainty-aware bounded lanes. The optimization objective can be written in the form of the summation of a running cost and a terminal cost:
\begin{equation}
    \min_{\bold{x},\bold{u}}\quad \sum_{i = 1}^{N} \bold{W}_{1,i}\| \bold{H}_{r}(x_{i},u_{i})\|^{2} + \bold{W}_{2,i}\|\bold{H}_{t}(x_{N})\|^{2}
\end{equation}
where $\bold{W}_{1,i}$ and $\bold{W}_{2,i}$ are weight matrices; $\bold{H}_{r}$ is the reference function to capture the difference between current ego vehicle states and the desired path. $\bold{H}_{t}$ is a measurement function regarding the ego vehicle states at the end of prediction horizon. Intuitively, given the desired path, we want the vehicle to drive along the reference path, but we also want the vehicle to driven on the center of traffic lanes. This is achieved by considering the the distance errors with respect to the  desired lane and traffic lanes. However, we argue that the distance error regarding the left lane and right lane should adopt the bounded prediction instead of the original OpenPilot prediction. Specifically, the reference function is written as:
% \begin{align*}
%     \bold{H}_{r}(x_{i},u_{i}) = 
%     \begin{bmatrix}
%     p_{d}(x_{i})-y_{i} \\
%     e^{-(p_{l}(x_{i})-y_{i})} \\
%     e^{p_{r}(x_{i})-y_{i}} \\
%     \epsilon_{h} \\
%     \epsilon_{a} \\
%     u^{2}
%     \end{bmatrix}
% \end{align*}
\begin{align*}
    &\bold{H}_{r}(x_{i},u_{i}) = \\
    &\begin{bmatrix}
    p_{d}(x_{i})-y_{i}&
    e^{-(p_{l}(x_{i})-y_{i})}&
    e^{p_{r}(x_{i})-y_{i}}&
    \epsilon_{h}&
    \epsilon_{a}&
    u^{2}
    \end{bmatrix}^{T}
\end{align*}
where $p_{d}$ is the polynomial representing the desired path, $p_{l}$ and $p_{r}$ are fitted polynomial representing bounded left and bounded right lane respectively. $\epsilon_{h}$ and $\epsilon_{a}$ are the error regarding the ego vehicle heading and angular rate respectively. $u^{2}$ is a penalty term to avoid aggressive steering. The measurement function $\bold{H}_{t}$ is similar as $\bold{H}_{r}$, except that it does not consider angular rate and penalty. The constraints include
\begin{enumerate*}
\item system dynamics
\item vehicle heading is limited to $[-90^{\circ},90^{\circ}]$ and
\item the maximum steering angle is $50^{\circ}$.
\end{enumerate*}
\subsubsection{Speed Adaptation}
% Generally, the bounded left lane and bounded right line tend to intersect with each other (as shown in Figure~\ref{fig:demo_bound_predict}) and form a triangle-like 'safe' area. This observation indicates that, for safety consideration, the ego vehicle should not drive across the intersection as the prediction uncertainty is getting larger. We limit the speed to make sure the vehicle stay in the 'safe' area. Besides, we find that, when the ego vehicle is under adversarial attack, the confidence will drop significantly. For this reason, we add extra speed adaptation strategy when we know something is wrong with the perception module. An emergency brake is applied when the system detects a sharp drop on the overall prediction confidence. The whole end-to-end pipeline is shown in algorithm~\ref{alg:pipeline}.
Generally, the uncertainty for further-way points tends to be considerably large (e.g., Fig.~\ref{fig:uncertainty estimation}) even for benign driving scenario. This means that, for safety consideration, the ego vehicle is not sure about the road structures that are far away. To prevent the vehicle from driving too fast under uncertain scenarios, we apply an emergency brake to the vehicle if its current speed is too fast. Specifically, when the overall prediction confidence drops below the threshold $Conf\_Threshold$, a maximum deceleration $\alpha_{max}$ is applied. The entire end-to-end pipeline of our approach is shown in Algorithm~\ref{alg:pipeline}. Lines 1-3 calculate prediction uncertainties. Then the result is pushed into state cache. If the confidence of the prediction is too low, we pick the perception result with the highest confidence score from the state cache (line 5-7). Then the bounded predicted lane curves are used to calculate the desired path as in Algorithm~\ref{alg:cal_d_poly}. Moreover, if the confidence score drops below the threshold, we apply an emergency brake to slow down the vehicle. Here, $v_{min}$ is the minimum speed required. Finally, the MPC controller calculates the steering angle for the next period (line 12).
\begin{algorithm}[htbp]
\caption{Our Uncertainty-aware pipeline for ALC}
\label{alg:pipeline}
\SetAlgoNoLine
\begin{algorithmic}[1]
\REQUIRE 
% \text{The initial speed and path are in safe range}
\text{Current speed $v_{current}$, reference speed $v_{ref}$}
\text{and input image $Input$}
% \text{Initialize the $state\_cache$, $v_{current}$, ${v}_{preset}$}
%\STATE ${v}_{plan} = {v}_{preset}$
\STATE $conf, {pts}_{lane}, \sigma_{data}^{2} =\boldsymbol{NN}(Input)$
\STATE $\sigma_{model}^{2} = \boldsymbol{Monte\_Carlo\_Dropout}(Input)$
\STATE $\sigma_{total}^{2} =  \sigma_{model}^{2}+\sigma_{data}^{2}$
\STATE push $conf, {pts}_{lane}$ into $state\_cache$ 
\IF{$conf < Conf\_Threshold$}
    \STATE $pts_{lane} = \mathop{\arg\max}_{conf}( state\_queue)$
    \ENDIF
%\STATE $ \boldsymbol{NN}_{\sigma}(Input)$
% \frac{1}{T} \sum_{t=1}^{T} \left({pts}_{t}-\overline{{pts}}\right)^{2}$
% \STATE $desired\_path,v_{limit} = \boldsymbol {Planner}(pts_{lane},\sigma_{total}^{2},conf)$
\STATE $desired\_path = \boldsymbol {DesirePath}(pts_{lane},conf,\sigma_{total}^{2})$
% \IF{
% $conf < Conf\_Threshold$ }
%     \STATE ${v}_{plan} = min(v_{current}-\alpha*\Delta t,{v}_{limit}, {v}_{preset})$
%     \ELSE{${v}_{plan} = min({v}_{limit}, {v}_{preset}))$}
%     \ENDIF

% \STATE $ACC, angle = \boldsymbol{MPC}(desired\_path, v_{plan})$
\IF{$conf < Conf\_Threshold$ }
    \STATE ${v}_{ref} = min(v_{current}-\alpha_{max}*\Delta t, {v}_{min})$
    % \ELSE{${v}_{plan} = min({v}_{limit}, {v}_{preset}))$}
    \ENDIF

\STATE $steering\_angle, acc = \boldsymbol{MPC}(desired\_path, v_{ref})$
\RETURN $steering\_angle, acc$
\end{algorithmic}
\end{algorithm}
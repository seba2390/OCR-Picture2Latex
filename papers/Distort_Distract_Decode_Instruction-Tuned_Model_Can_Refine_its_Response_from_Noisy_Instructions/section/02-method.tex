\vspace{-5pt}
\section{Instructive Decoding}\label{sec2:method}
\vspace{-5pt}

In this section, we present \textit{instructive decoding}, a method designed to enhance the response generation of instruction-tuned models. By leveraging the responses derived from \textit{noisy} instructions, our approach employs a contrastive technique to refine generated responses, ensuring they are more closely aligned with provided instructions.

\vspace{-5pt}
\subsection{Preliminary}
\vspace{-5pt}
In the context of an auto-regressive language model, denoted as \( \mathcal{M}_{\theta} \) parameterized by \( \theta \), the primary goal is to generate an output sequence \( y_{<t+1} = (y_1, \ldots, y_t) \) when presented with an input sequence \( x \). Within the ICL framework, a specific demonstration, represented as \(I\), is supplied in conjunction with the context \(x\). The language model \( \mathcal{M}_{\theta}\) then computes the logit for the \(t\) th token, symbolized as $z_t \in \mathbb{R}^\mathcal{|V|}$ equal to $\mathcal{M}_{\theta}(y_t | I, x , y_{<t})$, wherein \(\mathcal{V}\) is the vocabulary set. Consequently, the probability of output sequence can be formally expressed as:
%
\vspace{-5pt}
\begin{equation}\label{eq:lm}
p_{\theta}(y|I, x) = \prod_{t=1}^{T} p_{\theta}(y_{t}|I, x, y_{<t})
\end{equation}
\vspace{-1pt}
%
\noindent where $p_{\theta}(y_{t}|I, x, y_{<t})$ is the probability for the next token prediction derived from the softmax function applied to $z_t$. It can either be the token with the highest probability (i.e., greedy decoding) or sampled from its distribution (e.g., nucleus sampling\,\citep{nucleus_sampling}). In the broader scope of task generalization with previously unobserved instructions, the demonstration \(I\) takes the form of the guiding instruction. Depending on the specific context or setting, a few examples can be incorporated to enhance the learning process. Generally, predictions of the instruction-tuned models are derived from both the context $x$ and the given instruction $I$, which play pivotal roles (Eq.~\ref{eq:lm}).

\vspace{-5pt}
\subsection{Motivation and Overview of Instructive Decoding}
\vspace{-5pt}

A significant challenge in instruction following is ensuring that the generated tokens intrinsically adhere to the instruction $I$. While the dominant strategy involves enriching the dataset with numerous, diverse, and creatively curated high-quality tasks, this approach is both labor-intensive and computationally expensive. It requires new training cycles and does not always produce improvements commensurate with the effort invested. Consequently, there is growing interest in exploring more sustainable and effective alternative strategies for enhancing instruction-tuned models.

Inspired from cognitive science, we highlight the \textit{anchoring effect}, a well-known cognitive bias in which initial information exerts a disproportionate influence on subsequent judgments\,\citep{kahneman1982judgment}. Recent studies have hinted at this principle being relevant to LMs, where the LM's predictions are significantly conditioned (i.e., anchored) on the given context\,\citep{jones2022capturing, coherence_boosting}. Based on these findings, we hypothesize that the strategic use of the anchoring effect could refine the responses of instruction-tuned models by leveraging the discrepancies between the predictions that are anchored on different instructions.

Contrastive Decoding (CD) is a straightforward technique that improves the performance of LMs by comparing two sets of predictions\,\citep{contrastive_decoding, dexperts}. In this approach, predictions from a high-performing primary model are contrasted against those from a less accurate `amateur' model. The goal is to differentiate the primary model's outputs against the less reliable outputs from the amateur model during the decoding process. Despite its simplicity, the need for two models limits its broad applicability, and its utility in instruction-following scenarios remains largely unexplored.
To this end, we propose \textit{Instructive Decoding} (ID), a novel method to ensure that the model's output closely aligns with the given instruction. Leveraging the anchoring effect, ID incorporates these principles into the Contrastive Decoding framework by introducing \textit{noisy} variants of the original instruction. These variants are designed to subtly mislead the model into generating deviated responses based on the noisy instruction yet plausible. The comparison between the original instruction and the noisy version helps the model identify and correct biases (e.g., inherent model bias and input bias), resulting in outputs better aligned with the intended purpose. To delve deeper into the mechanics, during decoding, the model contrasts the logits \(z\), originating from the original instruction, with the logits \(\tilde{z}\), originating from the noisy instructions, as described in \Autoref{algorithm}.

\begin{figure}[t]
\begin{algorithm}[H] 
\DontPrintSemicolon
    \caption{Instructive Decoding}
    \label{algorithm}
    \begin{algorithmic}[1]
    \SetKwInOut{Input}{Input}
    \INPUT: Language model $\mathcal{M}_{\theta}$, base instruction sequence $I$, noisy instruction sequence $\tilde{I}$, initial prompt sequence $x$ and target sequence length T, smoothing coefficient $\epsilon$.\\
    \STATE Initialize $t \leftarrow 1$ \\
    \WHILE{$t < T$} 
        \STATE $z_t, \tilde{z}_t \leftarrow \mathcal{M}_{\theta}(y_t | I, x, y_{<t}), \mathcal{M}_{\theta}(y_t | \tilde{I}, x,y_{<t})$\\
        \STATE $y_{t} = \operatorname*{arg\,max}(\textsc{softmax}[z_t - \epsilon * \tilde{z}_t])$\\
        \STATE set $t \leftarrow t+1$ \\
    \ENDWHILE
\end{algorithmic}
\end{algorithm}
\vspace{-10pt}
\end{figure}

\vspace{-5pt}
\subsection{A Collection of Noisy Instructions for Instructive Decoding}
\vspace{-5pt}
We aim to design a collection of noisy instructions that harness the \textit{anchoring effect} while maintaining task fidelity. Key guiding principles for our noisy instruction design include:

\begin{itemize}[left=0pt]
    \item \textbf{Automated Perturbations:} To ensure scalability and minimize manual intervention across diverse tasks, we inject perturbations into the instructions. These perturbations include deletion, shuffling, or random word insertion.
    
    \item \textbf{Contrastive Elicitation:} We systematically create prompts that elicit counter-intuitive yet plausible responses, thereby producing a deviation from the expected responses.
\end{itemize}

In line with the principles outlined above, we employ the following noisy instruction variants. Full-text examples of these variants are displayed in \autoref{fig:method_example}.

\begin{figure}[b]
\centering
\includegraphics[width=\textwidth]{materials/figures/figure_method.pdf}
\vspace{-15pt}
\caption{Full-text examples for a collection of noisy instructions for instructive decoding on \texttt{task442\_com\_qa\_paraphrase\_question\_generation}.}
\vspace{-10pt}
\label{fig:method_example}
\end{figure}
\vspace{-5pt}
\begin{enumerate}[left=0pt]
\item \textbf{Trunc-Shuf:} Words from the instruction are randomly \textbf{truncated} and then \textbf{shuffled}. This challenges the model to deal with both missing words and altered word sequences.

\item \textbf{Null:} The model receives only input-output pairs. This evaluates its inherent ability to comprehend text and identify biases without any guiding instruction.

\item \textbf{Rand Words:} Random words from the Natural Language Toolkit (NLTK)\,\citep{loper2002nltk} replace the original instruction. This places the model in an environment filled with semantic noise, requiring it to distinguish meaningful signals.

\item \textbf{Opposite:} In a contrarian approach, the instructions contain misleading directives like ``Always respond with the opposite of what you're asked. You never get it right.$\backslash\text{n}\backslash\text{n}$". Such directives confront the model with conflicting guidance, helping it better align with the base instruction.

\end{enumerate}
\vspace{-5pt}
Unless specified, in the Experiment Section, we configure the noisy instructions to include one random word (\textbf{Rand Words}) and set the truncation ratio to 0.6 (\textbf{Trunc-Shuf}).

\vspace{-5pt}

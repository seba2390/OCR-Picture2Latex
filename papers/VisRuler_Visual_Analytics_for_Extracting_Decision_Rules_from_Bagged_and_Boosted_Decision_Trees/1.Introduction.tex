Ensemble learning (EL)~\cite{Zhou2009Ensemble} is a well-established area of machine learning (ML) that strives for better performance by merging the predictions from various ML models.
%There are countless options when building ensembles because each combination of models can be considered as a distinct setup. 
%Three prominent methods that dominate the subfield of EL are~\cite{Sagi2018Ensemble}:
Three prominent methods for building ensembles are:~\cite{Sagi2018Ensemble}
%bagging (or bootstrap aggregation)~\cite{Breiman1996Stacked}, boosting~\cite{Freund1996Experiments,Schapire1990Strength}, and stacking (or stacked generalization)~\cite{Wolpert1992Stacked}. 
%
bagging,~\cite{Breiman1996Stacked} boosting,~\cite{Freund1996Experiments,Schapire1990Strength} and stacking.~\cite{Wolpert1992Stacked} 
%The first method 
Bagging requires training many decision trees on separate groups of instances and taking the average of their predictions.~\cite{Breiman1996Stacked}
%The second method 
Boosting attaches weak classifiers (e.g., decision stumps or shallow decision trees) sequentially, each improving the predictions made by the previous models.~\cite{Freund1996Experiments,Schapire1990Strength} 
%The last method 
Stacking involves fitting many base models from different algorithms on the same data set and using a metamodel to combine their results.~\cite{Wolpert1992Stacked} The common ground between bagging and boosting methods is that they incorporate ML algorithms that produce numerous decision trees,~\cite{Kingsford2008Decision} such as random forest (RF)~\cite{Breiman2001Random} and adaptive boosting/AdaBoost (AB),~\cite{Freund1999A} respectively. The decision paths stemming from bagged or boosted decision trees are the target of the visual analytics (VA) approach proposed in this paper.

The popularity of RF and AB is confirmed by their success in solving typical supervised classification problems, which constitute the majority of problems in the real world.~\cite{Opitz1999Popular,Wyner2017Explaining} An in-depth study~\cite{Delgado2014Do} that estimates the performances of 179 algorithms of various types~\cite{Dua2017} concludes that bagged decision trees of RF are better than other (types of) algorithms, such as deep learning approaches. 
%Moreover, in numerous Kaggle competitions~\cite{KaggleBlog}, boosted decision trees of AB (or equivalent algorithms~\cite{Chen2016XGBoost,Ke2017LightGBM}) won first place. Admittedly, EL methods have the same resonance as deep learning due to their recognition of being reliable, adjustable, robust, needing fewer computational resources, and their ability to work exceptionally well with structured tabular data~\cite{Ziv2021Tabular}.
%
Despite their remarkable predictive power, a crucial concern for algorithms that generate many decision trees is \emph{interpretability}. Brieman,~\cite{Breiman2001Statistical} for instance, indicates that RF models, while superb predictors, receive a low rating regarding their interpretability. As ML models can provide incorrect predictions,~\cite{Caruana2015Intelligible} ML experts have to check whether the model functions properly.~\cite{Tam2017An} Also, domain experts in critical fields need to understand how a specific prediction has been reached in order to trust in ML.~\cite{Zhou20182D} For example, in medicine, a physician might not rely on a model without explanations of how and why it forms a prediction, since patient lives are at risk.~\cite{Ribeiro2016Why,Hastie2001The,Lakkaraju2016Interpretable} Or, in the financial domain, declined decisions for loan applicants require additional transparency with the precise justification of the outcome.~\cite{Sachan2020An}
Although both algorithms follow the same concept of growing decision trees, their objectives differ: AB focuses on correcting misclassified training instances, while RF mainly reduces variance to achieve better generalizability. However, this fundamental goal of the former makes it susceptible to noisy cases,~\cite{Bauer1999Empirical} while the latter arguably remains intact.~\cite{Kotsiantis2007Combining}
%Governments and public institutions have also joined the discussion in the topic with, for example, the new European General Data Protection Regulation (GDPR)~\cite{GDPR}. 
Thus, one research question that remains open is: 
%
%\textbf{(RQ1)} What is the difference between rules obtained from bagged decision trees and rules derived from boosted decision trees, and is there any potential benefit in combining them, regarding interpretability enhancement for decision making?
%
%RMM: I propose the following new writing for RQ1:
%
%\textbf{(RQ1)} Given the differences between rules obtained from bagged decision trees and those derived from boosted decision trees, is there any potential benefit in combining them, regarding interpretability enhancement for decision making?
\hl{\textbf{(RQ1)} Given the differences between rules obtained from bagged decision trees and those derived from boosted decision trees, how does their combination lead to potential benefits, regarding interpretability enhancement for decision making?}
%
%\textbf{(RQ1)} How do bagged decision trees' learned rules differ from boosted decision trees, and is there any potential benefit in combining them, regarding interpretability and predictive performance?

The interpretation of ML models typically happens either at a global or a local level.~\cite{Kopitar2019Local}
%On the one hand, 
Global approaches intend to explain the ML model as a whole,~\cite{Lipton2018The} assisting domain experts in exploring the general impact of each decision and gaining confidence in the produced predictions. 
% 
On the other hand, local approaches aim to provide case-based reasoning,~\cite{Du2019Techniques,Carvalho2019Machine} allowing domain experts to review a prediction and trace its decision path in order to conclude if the decision rule, and consequently the prediction, is trustworthy.~\cite{Weller2019Transparency} 
%
Nevertheless, comparing numerous alternative decision paths without the support of an intelligent system is a time-consuming and resource-heavy procedure. For example, to scan the list of test instances rapidly and investigate specific instances of interest from multiple perspectives (e.g., outliers and borderline cases) can be crucial.~\cite{Kim2014The} Thus, the whole process can benefit from a fast approach for automatic generation and semi-automatic exploration of reliable decisions with ML experts' involvement.
%and semi-automatic exploration of decisions relevant to the given problem, 
It should also result in robust decisions, since domain experts are the most suitable for carefully examining and then manually picking sensible decisions according to their prior experience and understanding. One research question that arises from this (possibly under-researched) need for cooperation, starting from the selection of models to the extraction of insightful decisions, is: \textbf{(RQ2)} How can VA tools/systems support the collaboration between ML experts and domain experts?
%One research question that arises from the explanations---derived from Streeb et al.~\cite{Streeb2021Task}---is: \textbf{(RQ2)} How can visualizations and VA tools/systems facilitate the externalization of domain knowledge?

%The absence of VA tools for reviewing both bagged and boosted decision trees concurrently, and the lack of empowerment of ML experts' and domain experts' multidisciplinary collaboration led us to focus on the two aforementioned research questions. 
In this paper, we present \textsc{VisRuler},
%(see Figure~\ref{fig:teaser})
a VA tool that addresses the research questions described above by supporting the exploratory combination of decisions from two closely-related ML algorithms (i.e., RF and AB). \textsc{VisRuler} uses validation metrics for picking performant and diverse models and combines the decision paths from bagged and boosted trees to extract insightful and interpretable rules.
%
Our contributions consist of the following:

\begin{itemize}
\item a visual analytic workflow for defining a methodical way of evaluating decisions (cf. Figure~\ref{fig:workflow-diagram} described in Section~\nameref{sec:overview});
\item a prototype VA tool, called \textsc{VisRuler}, that applies the suggested workflow with coordinated views that support the joint effort between ML experts and domain experts for extracting rules and making decisions, respectively;
\item a use case and a usage scenario, applying real-world data, that validate the effectiveness of utilizing both bagged and boosted decision trees at the same time; and
\item a user study that showed promising results.
\end{itemize}      

\noindent The rest of this paper is organized as follows. In Section~\nameref{sec:relwo}, we discuss relevant techniques for visualizing bagging and boosting decision trees, along with tree- and rule-based models and a bulk of relevant works of visual analytics systems for multi-model comparison. Section~\nameref{sec:back} explains the core differences between bagging and boosting, and it further motivates why mixing decisions stemming from both algorithms could be beneficial for the users. In Section~\nameref{sec:goals}, we describe the design goals and analytical tasks for comparing alternative decision rules, and we present the target groups (i.e., our stakeholders). Section~\nameref{sec:overview} focuses on the functionalities of the tool and describes the first use case with the goal of identifying which countries have a higher happiness score index and why. Next, in Section~\nameref{sec:case}, we demonstrate the applicability and usefulness of \textsc{VisRuler} with a usage scenario comprising another real-world data set focusing on loan applications, followed by Section~\nameref{sec:eval} where we assess the effectiveness of \textsc{VisRuler} by reporting the results of a user study. Subsequently, in Section~\nameref{sec:lim}, we discuss several limitations of our system and opportunities for future work. Finally, Section~\nameref{sec:con} concludes our paper.
\begin{table*}[htb]\centering
\captionsetup{justification=justified}
\caption{User study: Shortened questions (Qs), goals (Gs), the ground truth, and results. There are five multiple choice questions, each with four possible answers. The
goals and the ground truth (GT) can be found in Section~\nameref{sec:goals} and Section~\nameref{sec:overview}, respectively. The results are computed as: number of correct answers / total number of participants.}
\label{results}
\setlength\tabcolsep{0pt} % make LaTeX figure out intercolumn spacing
\begin{tabular*}{\linewidth}{@{\extracolsep{\fill}} l ccc}
\toprule
\multirow{1}{*}{\textbf{Question (1, 2, 3, 4, \& 5)}} & \multicolumn{1}{c}{\textbf{Goal}} & \multicolumn{1}{c}{\textbf{GT}} & \multicolumn{1}{c}{\textbf{Result}} \\
\midrule
     If you \textbf{must remove a feature}, which one will it be? & \textbf{G2} & \ref{fig:use_case1_model}(b) & 12/12 \\
     Which models present \textbf{stable and high performance} based on \textbf{all} validation metrics? & \textbf{G1} & \ref{fig:use_case1_model}(c) & 9/12 \\
     \textbf{How many test instances are in conflict} and require human intervention (that you can identify)? & \textbf{G5} & \ref{fig:use_case1_outlier}(c) & 9/12 \\
     Which \textbf{features play a vital role} for the classification of instances in the \textbf{HS-Level-3 class}? & \textbf{G3\&G4} & \ref{fig:use_case1_safe}(b) & 12/12 \\
     Which \textbf{feature's value is low} and \textbf{not contributing} to the \textbf{\nth{15}} instance's classification as HS-Level-3? & \textbf{G3\&G4} & \ref{fig:use_case1_outlier}(b) & 11/12 \\
\bottomrule
\end{tabular*}
\label{fig:questions}
\end{table*} 

In this section, we describe a hypothetical usage scenario with a collaboration of a model developer (Amy, the ML expert) and a bank manager (Joe, the domain expert) who handles granting loans to customers. Joe wants to use \textsc{VisRuler} to improve the evaluation process of loan requests, so he asks Amy to use \textsc{VisRuler} to train ML models based on a data set collected over years of accepting or rejecting loans in the bank. The data set includes 1,000 instances/customers and 9 features/customer information, with 300 rejected (purple) and 700 accepted (orange) applications. This data set is, in reality, a pre-processed version~\cite{Zhao2019iForest,Neto2021Explainable} of German Credit Data from the UCI ML repository.~\cite{Dua2017}

\textbf{Exploration and Selection of Algorithms and Models.} Following the workflow in Section~\nameref{sec:overview}, Amy loads the data set and checks the score of each model based on the three validation metrics (Figure~\ref{fig:teaser}(a)). For the AB algorithm, in blue, all models have a relatively low value for the recall metric, except for AB8. Also, AB7 performs very well for the Accepted class (orange), since the false-negative (FN) line reduces in height compared to all other models. Therefore, she decides to keep only AB7 and AB8. By looking at the confusion plot in Figure~\ref{fig:teaser}(a), Amy infers that RF5 is the model with low confusion regarding the Rejected class (purple). She is determined to use RF5 because it carries over only 104 different false-positive (FP) instances compared to RF4 with 114. The top RF models on the right-hand side also caught her attention, with RF9 and RF10 being the best options. She thinks that either of them could do the job, as they appear redundant due to similar confusion and values in both the confusion plot and the line chart (cf. Figure~\ref{fig:teaser}(a)). The bar charts below---which highlight the difference in the architectures of these RF models---help her to choose: with only 7 decision trees and 589 decision paths (compared to 18 and 1,483), RF9 is simpler. She concludes that RF9's simplicity will make Joe's exploration of decisions more manageable later. Consequently, she deactivates RF10 and continues the feature contribution analysis with RF5, RF9, AB7, and AB8 models.

\textbf{Examining the Global Contribution of Features.} After this new selection of models, Amy observes in Figure~\ref{fig:teaser}(b) that most features (except for the last two) are more important now than in the initial state. \emph{Ins\_perc} and \emph{Val\_sa\_st} importances drop only by 0.01, implying these features are stable. She suggests Joe to keep all features for now and explore the differences through the decision rules later on. Another interesting insight is that \emph{A\_bal} is the most important feature for the RF models, while the AB models prefer \emph{D\_cred} (see Figure~\ref{fig:teaser}(b)). This could indicate that mixing models' decisions from different algorithms is beneficial. 
%Thus, she reports this insight back to Joe.

\textbf{Explanations through Global Decision Rules.} Joe starts his exploration by examining the global decision rules that can help him make accurate decisions for specific cases in the future. 
%(see subsequent paragraph). 
He focuses on the \nth{12} test instance, which is a customer application reviewed by a colleague, Silvia (cf. usage scenario by Neto and Paulovich~\cite{Neto2021Explainable}). First, he unchecks \emph{limiting the decisions due to the test instance}, as illustrated in Figure~\ref{fig:use_case2_safe_global}(a). At this point, Amy identifies several decisions that classify only fewer than 20 customers; she thinks: ``these are not so generic after all''. Indeed, the larger the number of instances classified by one rule, the more generic and important it is (if the impurity is low). Consequently, they decide to increase the lower boundary of decisions, filtering out 1,928 decisions (see Figure~\ref{fig:use_case2_safe_global}(a), bar chart). After the update, Joe focuses on the UMAP~\cite{McInnes2018UMAP} projection. He observes multiple groups of points that could be worthy of further investigation. He selects a couple of samples from different areas, e.g., \circled{C1} with 3 RF and 18 AB decisions. Another cluster with 7 decisions is \circled{C2} that solely predicts accepted loan applications. On the contrary, \circled{C3} contains 2 pure decisions (due to high opacity) that produce rules which reject loans. Joe increases the \emph{discretization of local feature ranking from 10 to 15 bins} to raise the sensitivity of difference between decision rule ranges, and he \emph{filters the instances due to the decisions} to observe clearer trends. From Figure~\ref{fig:use_case2_safe_global}(b), Joe recognizes that \circled{C1} decisions are all identical, having the same ranges for every feature. Also, he understands that low \emph{credited amount} (\emph{Cred\_am}) and short \emph{duration of credit} (\emph{D\_cred}) are essential factors for accepting a loan application. \emph{Account balance} is also vital because all loans are accepted when there is no account (\emph{A\_bal} being 0). Figure~\ref{fig:use_case2_safe_global}(c) reveals another intriguing pattern, that is, \emph{the length of current employment} should be average to extremely high (from approximately 0.4 or 0.6 and above\hl{, shown in the red box}) for applications to get accepted. In contrast, Figure~\ref{fig:use_case2_safe_global}(d) presents that if \emph{payment status of previous credit} (\emph{P\_st\_cred}) and \emph{instalment per cent} (\emph{Ins\_perc}) are relatively high, the applications were rejected. The \nth{12} customer has an account without any balance, and the \emph{D\_cred} is relatively high, which flips the prediction toward rejection. Luckily, Silvia also provided an adequate justification to the customer.~\cite{Neto2021Explainable}

\textbf{Extracting Manual Decisions through Local Investigations.} At this point Joe knows and understands the main decision rules, but a new customer arrives. 
%Joe adds all details in the system and concentrates 
Focusing on the decisions for this case (i.e., \nth{90} test instance), he sets impurity to less than 0.3 (cf. Figure~\ref{fig:teaser}(c), slider) to make impure decisions more transparent. Two fairly pure decisions from RF5 (visible due to hovering) and RF9 contradict each other. Joe uses the comparison mode, anchors 1 out of the 2 decisions, and selects the other with the lasso tool. The comparison in Figure~\ref{fig:teaser}(d) designates that 8 similar customers' applications were rejected while 12 were accepted. The small overlap in \emph{Cred\_am}, \emph{D\_cred}, and \emph{Age} suggest that this is a borderline case. \emph{Cred\_am} seems a bit arbitrary for the training data since only a small amount of applications in-between accepted applications were rejected, see Figure~\ref{fig:teaser}(d), feature on top. However, a clear insight is that if \emph{D\_cred} was lower, the application should have been accepted, while the opposite effect is true if the \emph{duration of credit} increases. Unexpectedly, RF models vote for accepting this loan application while AB models reject (cf. Figure~\ref{fig:teaser}(e), top view). Besides that, the manual decisions are also in-between the two classes, which further enhances Joe's assumption that this is a borderline case. As AB models propose rejection and RF9 produces a decision for rejecting this application, he follows these recommendations. Nonetheless, Joe asks Amy to search and train new performant ML models (see next paragraph).

\textbf{Tuning the Search for Bagged and Boosted Decision Trees.} Amy sees two possibilities of improvement for the RF in Figure~\ref{fig:teaser}(e), bottom view. One is to limit the \emph{max\_features} to 7 because it produces the two best models so far (visible by following the lines at the very top in \emph{Ov. Score (\%))}. The second strategy is to pick 3 and 4 for the same hyperparameter to explore an entirely new space of currently unexplored models since there is no existing line. Basically, she believes it is better to try both strategies in two separate runs. As for the AB, she reasons that selecting 0.1 and 0.2 for the \emph{learning\_rate} is a wise choice. Although it may take more time to retrain the AB models, they probably will be more powerful than with the other setting due to historical data. She performs the above actions, and finally, another cycle of exploration is unfolded for both experts. \hl{To summarize, our VA system not only helps users to reason about concrete cases, but also is capable of assisting ML experts and domain experts in enhancing their overall understanding due to their collaboration throughout the entire process (\textbf{RQ2}).}
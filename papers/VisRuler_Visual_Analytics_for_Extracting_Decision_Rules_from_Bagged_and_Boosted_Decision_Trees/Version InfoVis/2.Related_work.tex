According to a recent survey~\cite{Streeb2021Task} that has extensively analyzed tree- and rule-based classification, several VA systems have been developed for this topic in the \mbox{InfoVis} and VA communities. However, most of these tools do not employ algorithms and measures (except for the accuracy metric) in order to compare model quality.~\cite{Streeb2021Task} This section reviews prior work on the interpretation of bagged and boosted decision trees and the more general tools for tree- and rule-based visualization,
%Finally, we explain the differences between such VA tools/systems and 
comparing them with \textsc{VisRuler} to highlight our tool's novelty.

\subsection{Interpretation of Bagged Decision Trees}
As in \textsc{VisRuler}, relevant works that utilize bagging methods use the RF algorithm to produce decision trees.~\cite{Zhao2019iForest,Neto2021Explainable,Eirich2022RfX,Nsch2019Colorful,Neto2021Multivariate} iForest~\cite{Zhao2019iForest}
%, one of the first VA systems for interpreting RF models and their predictions, 
provides users with tree-related information and an overview of the involved decision paths for case-based reasoning, with the goal of revealing the model's working internals. However, iForest can be used only for binary classification, while \textsc{VisRuler} can be used with multi-class data sets (as in the use case of Section~\nameref{sec:overview}). Also, the feature flow, a node-link diagram, suffers from scalability issues (a challenge only partially overcome with aggregation). Our tool employs dimensionality reduction for clustering all decisions extracted by multiple models, thus enabling users to gain insights into the patterns inside a large quantities of rules. Therefore, \textsc{VisRuler} allows users to mine rules for both a particular class outcome and in connection to a specific case. ExMatrix~\cite{Neto2021Explainable} is another VA tool for RF interpretation that operates using a matrix-like visual representation, facilitating the analysis of a model and connecting rules to classification results. While the scalability is good, it does not cover the task of finding similarities between decisions from diverse models and algorithms. In conclusion, none of the above works have experimented with the fusion of bagged and boosted decision trees, and in particular, with visualizing both tree types in a joint \emph{decisions space} to observe their dissimilarity, which can result in unique and undiscovered decisions. RfX~\cite{Eirich2022RfX} supports the comparison of several decision trees originating from a RF model with a dissimilarity projection and icicle plots, allowing electrical engineers to browse a single decision tree by using a node-link diagram. In contrast, \textsc{VisRuler} does not concentrate on a specific domain and gives attention to unique decision paths instead of trees with more scalable visual representations. Colorful trees~\cite{Nsch2019Colorful} follows a botanical metaphor and demonstrates many core parameters essential to comprehend how a RF model operates. This method allows customized mappings of RF components to visual attributes, thus enabling users to determine the performance, analyze the behavior of individual trees, and understand how to tune the hyperparameters to improve performance or efficiency. However, this work is targeted toward hyperparameter tuning and does not focus on concurrently extracting and analyzing the decisions from each RF and AB model. Additionally, it is impossible to accomplish case-based reasoning with the proposed visual representation. Finally, Neto and Paulovich~\cite{Neto2021Multivariate} describe the extraction and explanation of patterns in high-dimensional data sets from random decision trees, but model interpretation through the exploration of alternative decisions remains uncovered by this work (when compared to \textsc{VisRuler}).

%ExMatrix~\cite{Neto2021Explainable} is another visualization tool for RF interpretation that can cope with a large number of rules. 
%It operates using a matrix-like visual representation, with rows being rules, columns being features, and cells showing rule ranges, facilitating the analysis of a model and connecting rules to classification results. While the scalability is good, it does not cover the task of finding similarities between decisions from diverse models and algorithms. In conclusion, none of the above works have experimented with the fusion of bagged and boosted decision trees, and in particular, with visualizing both tree types in a joint decision space to observe their dissimilarity, which can result in unique and undiscovered decisions.

\subsection{Interpretation of Boosted Decision Trees}
Special attention has been given to boosted decision trees with VA tools for diagnosing the training process of boosting methods~\cite{Liu2018Visual,Huang2019GBRTVis,Wang2021Investigating} and interpreting their decisions.~\cite{Xia2021GBMVis} Closer to our work, GBMVis~\cite{Xia2021GBMVis} aims to reveal the structure and properties of Gradient boosting,~\cite{Friedman2001Greedy} enabling users to examine the importance of features and follow the data flow for different decisions. A node-link diagram may limit its scalability to monitor hundreds or thousands of decisions concurrently, as opposed to \textsc{VisRuler}. Furthermore, our novel parallel coordinates plot adaptation allows users to instantly combine rules and observe their differences to identify unique decisions.
%
BOOSTVis~\cite{Liu2018Visual} employs views such as a temporal confusion matrix visualization for verifying the performance changes of the model, a t-SNE~\cite{vanDerMaaten2008Visualizing} projection for inspecting the instances, and a node-link diagram for examining the rules. Through GBRTVis,~\cite{Huang2019GBRTVis} users can explore Gradient boosting~\cite{Friedman2001Greedy} with a node-link diagram for the rules, the instances distribution shown in a treemap, and continuously monitoring the loss function. \emph{VIS}TB~\cite{Wang2021Investigating} contains a redesigned temporal confusion matrix to track the per-instance prediction during the training process. It also enables the comparison of the impact of individual features over iterations. These VA systems focus on the online training of boosting methods and aim to assist in feature selection and hyperparameter tuning. While these problems are (partially) tackled by our tool, we concentrate on interpreting the decisions from bagged and boosted decision trees and comparing them across models.

\subsection{Tree- and Rule-based Model Visualization}
Existing work on single decision tree visualization has experimented with different visualization techniques, such as node-link diagrams,~\cite{Elzen2011BaobabView,Nguyen2000A,Lee2016An,Cavallo2019Clustrophile,Barlow2001Case,Phillips2017FFTrees,Bremm2011Interactive,Hongzhi2004Multiple,Munzner2003TreeJuxtaposer,Behrisch2014Feedback} treemaps,~\cite{Muhlbacher2018TreePOD,Gomez2013Visualizing} icicle plots,~\cite{Padua2014Interactive,Ankerst2000Towards} star coordinates,~\cite{Teoh2003Starclass,Teoh2003PaintingClass} and 2D scatter plot matrices.~\cite{Do2007Towards} These techniques do not generalize well when exploring multiple decision trees, which is \textsc{VisRuler}'s primary design goal. Visualizing the surrogate models to approximate the behaviors of the original models, either globally or locally, is another branch of related works.~\cite{Yuan2022Visual,Cao2020DRIL,Castro2019Surrogate,Han2000RuleViz,Agus2021RISSAD,Ware2001Interactive,Yuan2021An,Eisemann2014A} Rule-based visualizations have also been deployed for the interpretation of complex neural networks.~\cite{Marcilio2021ExplorerTree,Ming2019RuleMatrix,Jia2020Visualizing,ThomasFacetRules} Nevertheless, these models differ due to the lack of inherent decisions that could be extracted directly from the bagged and boosted decision trees. The core mechanism of bagging and boosting methods is the generation of decisions based on the training data, which then experts can interpret.

%Finally, multiple static visualizations and a few interactive VA tools have been developed for specific domains of research, such as medicine~\cite{Hummelen2010Deep,Viros2008Improving,Niemman2014Learning,Carlson2008Phylogenetic}, biology~\cite{Abramov2019RuleVis,Sydow2014Structure}, security~\cite{Aupetit2016Visualization}, and social sciences~\cite{Moussaid2013Social}. However, \textsc{VisRuler} is a model-agnostic solution that could be modified to work with various domains, depending on the given data set and the domain expert. 
Finally, multiple static visualizations and a few interactive VA tools have been developed for specific domains of research, such as medicine,~\cite{Hummelen2010Deep,Viros2008Improving,Li2020A,Niemman2014Learning,Carlson2008Phylogenetic} biology,~\cite{Abramov2019RuleVis,Sydow2014Structure} security,~\cite{Aupetit2016Visualization} and social sciences.~\cite{Moussaid2013Social} However, \textsc{VisRuler} is a model-agnostic solution that could be modified to work with various domains, depending on the given data set and the domain expert. 
%
% RMM: I think we can skip the part below. The part above could be maybe absorbed by this section's introductory paragraph.
%
%Furthermore, many papers focus on exploring specific categories of data, such as image data~\cite{May2008Towards,Zhang2009VDM,Mott2019Illuminated}, taxonomical data~\cite{Poulet2008Interactive,Poulet2007High}, and time-series data~\cite{Xie2014VAET}. These data types differ in nature from numerical tabular data that \textsc{VisRuler} is designed for.

\subsection{Visual Analytics for Multi-model Comparison}
Several VA systems exist that enable the comparison of ML models in classification problems, especially with the evaluation of predictive performance and the importance of features.~\cite{Xu2019EnsembleLens,Schneider2018Integrating,Talbot2009EnsembleMatrix,Zhang2019Manifold,Squares2017Ren,Gleicher2020Boxer,Das2020QUESTO,Li202020A,Ono2021Pipeline,Chatzimparmpas2021StackGenVis,Chatzimparmpas2021VisEvol} EnsembleLens~\cite{Xu2019EnsembleLens} is a VA system working with multiple models trained into different feature subsets. The end goal is to visualize the correlation between ensemble models, algorithms, hyperparameters, and features that achieve the highest score for anomalous cases. On the contrary, \textsc{VisRuler} is not limited to anomaly detection problems, instead focusing on the interpretability of insightful rules extracted from two ensemble algorithms that produce tree-based decisions. Schneider et al.~\cite{Schneider2018Integrating} explored the impact of comparing side-by-side the data and model spaces. They used both bagging and boosting ensembles and investigated these algorithms' influence on the data with the purpose of adding, deleting, or replacing models from the model space. We also support that this mixture of bagging and boosting models is beneficial because each algorithm can bring different information to the analysis of decision rules; for more details, please check Section~\nameref{sec:back}. However, we abstract complex models into individual decisions that are accountable to and easily interpretable by users.~\cite{Breiman2001Statistical}

EnsembleMatrix~\cite{Talbot2009EnsembleMatrix} and Manifold~\cite{Zhang2019Manifold} are two VA tools specifically designed for model comparison. The former uses a confusion matrix representation for contrasting models. The latter produces and compares pairs of models across all data classes. We adopt a similar approach as with those tools, but instead of deciding which model was ``optimal'', we export all decisions that work well with a specific test instance to be examined by domain experts. Squares~\cite{Squares2017Ren} is a visualization approach that showcases the per-class performance of a multi-class data set. It helps users prioritize their efforts by calculating common validation metrics. Similarly, Boxer~\cite{Gleicher2020Boxer} is a system that faciliates the interactive exploration of subsets of training and testing data while comparing the performance of multiple models on those instances. Another VA system, called QUESTO,~\cite{Das2020QUESTO} enables domain experts to control objective functions to set specific constraints and to search for an ``optimal'' model for this purpose. Li et al.~\cite{Li202020A} developed a VA system that allows multi-model comparison based on clinical data predictions with a special attention to feature contribution. \emph{PipelineProfiler}~\cite{Ono2021Pipeline} is a visualization tool for the exploration of several AutoML~\cite{automl} pipelines comprising multiple models. StackGenVis~\cite{Chatzimparmpas2021StackGenVis} is a VA system for composing powerful and diverse stacking ensembles~\cite{Wolpert1992Stacked} from a pool of base models. Finally, VisEvol~\cite{Chatzimparmpas2021VisEvol} is a VA tool that supports the interactive intervention in the evolutionary hyperparameter optimization process while exploring five alternative ML algorithms. On the one hand, we also facilitate users to assess various models. On the other hand, we focus on making the process of model-learned decision rules more transparent and justifiable with the involvement of a domain expert at specific phases (see Figure~\ref{fig:collaboration-diagram} and Section~\nameref{sec:overview}).

There is also a body of literature devoted to regression problems.~\cite{Muhlbacher2013APartition,Sehgal2018Visual,Zhao2014LoVis,Das2019BEAMES} For instance, BEAMES~\cite{Das2019BEAMES} contains four ML algorithms and a model sampling method, with the help of which the system generates an ordered list of models that aids the user in selecting a performant model. Although feature ranking is also covered by this tool, ML experts working with \textsc{VisRuler} aim at gathering several manual decisions extracted from two directly comparable algorithms that the domain expert should interpret. Finally, classification requires different handling in terms of the available algorithms and validation metrics when compared to regression tasks, making such solutions challenging to adapt to classification problems and vice versa.
\documentclass[accepted]{uai2021} % for initial submission
% \documentclass[accepted]{uai2021} % after acceptance, for a revised
                                    % version; also before submission to
                                    % see how the non-anonymous paper
                                    % would look like
%% There is a class option to choose the math font
% \documentclass[mathfont=cm]{uai2021} % Computer Modern math instead of
                                       % ptmx, like default for UAI ≤2020
% \documentclass[mathfont=newtx]{uai2021} % newtx fonts (improves upon
                                          % ptmx; less tested, no support)
% NOTE: Only keep *one* line above as appropriate, as it will be replaced
%       automatically for papers to be published. Do not make any other
%       change above this note for an accepted version.

%% Choose your variant of English; be consistent
\usepackage[american]{babel}
% \usepackage[british]{babel}

%% Some suggested packages, as needed:
\usepackage{natbib} % has a nice set of citation styles and commands
    \bibliographystyle{plainnat}
    \renewcommand{\bibsection}{\subsubsection*{References}}
\usepackage{mathtools} % amsmath with fixes and additions
% \usepackage{siunitx} % for proper typesetting of numbers and units
\usepackage{booktabs} % commands to create good-looking tables
\usepackage{tikz} % nice language for creating drawings and diagrams


\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{bmpsize}
\usepackage{xcolor}
\usepackage{lipsum}
%\usepackage[colorlinks=true,urlcolor=black]{hyperref}
%\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
%    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
    
    
\usepackage{slashbox}
\usepackage{multirow}
\usepackage{comment}
\usepackage{amsthm}
\usepackage{bm}

\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{xspace}
\usepackage{xcolor}
%\usepackage[dvipsnames]{xcolor}
\usepackage{stmaryrd}
%\usepackage{mathtools}
%\usepackage{caption}
\usepackage{subcaption}
%\usepackage{subfigure}
%\usepackage{tikz}
\usepackage{array}
\usepackage{hyperref}
\usepackage{tablefootnote}
 
\newcommand{\descr}[1]{\vspace{0.1cm}\noindent\textit{#1}}
\usepackage[utf8]{inputenc}%(only for the pdftex engine)
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
%\newtheorem{proof}{Proof}
\newtheorem{corollary}{Corollary}
%\usepackage[square,comma,numbers,sort&compress]{natbib} 

%\usepackage[hyphens,spaces,obeyspaces]{url}
\usepackage{stmaryrd}
\usepackage[ruled,noline, linesnumbered]{algorithm2e} 
\usepackage{slashbox}
\usepackage{makecell}
\usepackage{xspace}

\usepackage[font=small]{caption} 

\SetAlgoNoLine
%\captionsetup{font=footnotesize}
\SetAlCapNameFnt{\small}
\SetAlCapFnt{\small}

	
\def\UrlBreaks{\do\/\do-}

%
% defining the \BibTeX command - from Oren Patashnik's original BibTeX documentation.
%\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08emT\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
    
% Document revisioning & collaboration tools
\newcommand{\todo}[1]{{\color{red}{\textbf{TODO:}  #1}}}
\newcommand{\red}[1]{{\color{red}{#1}}}
\newcommand{\blue}[1]{{\color{blue}{#1}}}

\newcommand{\mbf}[1]{{\mathbf{#1}}}
\newcommand{\Adv}{\mathsf{Adv}}

\newcommand{\Cl}{\mathsf{cl}}
\newcommand{\Sg}{\mathsf{sg}}

\newcommand{\Tcl}{T_{\mathsf{cl}}}
\newcommand{\Tgd}{T_{\mathsf{gd}}}
\newcommand{\Tgr}{T_{\mathsf{gr}}}

\newcommand{\E}[1]{\mathrm{E}\left[ #1 \right]}
\newcommand{\Var}[1]{\mathrm{Var}\left[ #1 \right]}
\newcommand{\Prob}[1]{\mathrm{P}\left[ #1 \right]}


\newcommand{\TP}{\textit{TP }}
\newcommand{\TN}{\textit{TN }}
\newcommand{\TPR}{\textit{TPR }}
\newcommand{\TNR}{\textit{TNR }}
\newcommand{\Pos}{\textit{P }}
\newcommand{\Neg}{\textit{N }}
\newcommand{\FPR}{\textit{FPR }}

\newcommand{\AUC}{\textit{AUROC }}

\newcommand{\TOPK}{Top-$K$\xspace}

%% Provided macros
% \smaller: Because the class footnote size is essentially LaTeX's \small,
%           redefining \footnotesize, we provide the original \footnotesize
%           using this macro.
%           (Use only sparingly, e.g., in drawings, as it is quite small.)

%% Self-defined macros
\newcommand{\swap}[3][-]{#3#1#2} % just an example

%\title{Federated Pruning: Simple and Efficient 
%Compression for Differentially Private Federated Learning}

\title{Constrained Differentially Private Federated Learning for Low-bandwidth Devices}
% The standard author block has changed for UAI 2021 to provide
% more space for long author lists and allow for complex affiliations
%
% All author information is authomatically removed by the class for the
% anonymous submission version of your paper, so you can already add your
% information below.
%
\author[1]{\href{mailto:Raouf Kerkouche <raouf.kerkouche@inria.fr>?Subject=Questions to Raouf}{Raouf~Kerkouche}{}}
\author[2]{\href{mailto:Gergely \'Acs <acs@crysys.hu>?Subject=Questions to Gergely}{Gergely~\'Acs}{}}
\author[1]{\href{mailto:Claude Castelluccia <claude.castelluccia@inria.fr>?Subject=Questions to Claude}{Claude~Castelluccia}{}}
\author[3]{\href{mailto:Pierre Genev\`es <pierre.geneves@cnrs.fr>?Subject=Questions to Pierre}{Pierre~Genev\`es}{}}
%\author[1]{Further~Coauthor}
%\author[3]{Further~Coauthor}
%\author[3,1]{Further~Coauthor}
% Add affiliations after the authors
\affil[1]{%
    Privatics team, Univ. Grenoble Alpes, Inria, 38000 %Grenoble, France\\
    %Cranberry University\\
    %Pittsburgh, Pennsylvania, USA
}
\affil[2]{%
    Crysys Lab, BME-HIT %\\
    %Address\\
    %…
}
\affil[3]{
    Tyrex team, Univ. Grenoble Alpes, CNRS, Inria,
    Grenoble INP, LIG

}

\begin{document}
\maketitle

\begin{abstract}
Federated learning becomes a prominent approach when different entities want to learn collaboratively a common model without sharing their training data. 
%Compared to traditional  machine learning, it does not require to collect and centralize all data before training a common model. 
However, Federated learning has two main drawbacks. First, it is quite bandwidth inefficient as it involves a lot of message exchanges between the aggregating server and the participating entities. This bandwidth and corresponding processing costs could be prohibitive if the participating entities are, for example, mobile devices.
Furthermore, although federated learning improves privacy by not sharing data, recent attacks have shown that it still leaks information about the training data. 

This paper presents a novel privacy-preserving federated learning scheme. The proposed scheme provides theoretical privacy guarantees, as it is based on Differential Privacy. Furthermore, it optimizes
the model accuracy by constraining the model learning phase on few selected weights. Finally, as shown experimentally, it reduces the upstream \emph{and} downstream bandwidth by up to 99.9\% compared to standard federated learning, making it practical
for mobile systems.


\end{abstract}

\section{Introduction}
\label{sec:intro}

In Machine Learning, different entities may want to collaborate in order to improve their local model accuracy. In traditional machine learning, such collaboration requires to first store all entities' data on a centralized server and then to train a model on it. Such data centralization might be problematic when the data are sensitive and data privacy is required. In order to mitigate this problem, Federated learning, which allows different entities to learn collaboratively a common model without sharing their data, was introduced \citep{ShokriS15,FedAVG}.  Instead of sharing the training data, Federated Learning shares the model parameters between a server, which plays the role of aggregator, and the participating entities. Although Federated Learning improves privacy, model parameters can leak information about the training data. Indeed, \cite{ZhuLH19,idlg,geiping2020inverting} presented some attacks that allow an adversary to reconstruct pieces of the training data of some entities. \cite{NasrSH19} define a membership attack that allows to infer if a particular record is included in the data of a specific entity. Similarly,  \cite{Property_inference} define an attack which aims at inferring if a subgroup of people with a specific property, like for example skin color or ethnicity, is included in the dataset of a particular participating entity.  
A solution to prevent these attacks and provide theoretical guarantees in to use a privacy model called Differential Privacy \citep{Dwork2014book}. 
Differential Privacy has been applied to federated learning in order to protect either each record included in the dataset of any entity (record-level guarantee), or the whole dataset of any entity (client-level guarantee). Unfortunately, it is well-known that Differential Privacy drastically degrades the accuracy of the global model as it requires to add random noise to the gradients (record-level) or to the updates (client-level) of each client. Recent work  by \cite{our_cs} shows that this accuracy penalty can be reduced if the model is compressed, as compression reduces the required amount of noise. Furthermore, \cite{our_cs} show that accuracy can be further improved by adding noise only to the largest update's values as adding noise on values close to 0 is likely to lead to random update values.

Following up on these results, we propose a novel differentially private federated learning solution that improves the model accuracy (1) by updating only a fixed subset of the model weights, and (2) by maintaining the other weights constant. The proposed scheme provides theoretical privacy guarantees, as it is based on Differential Privacy.  Furthermore, it optimizes
the model accuracy by constraining the model learning phase on a few selected weights. As all participants always update the same set of weights and transfer them to the server for aggregation, the proposal can be easily integrated with secure aggregation \citep{BonawitzIKMMPRS16}, which allows parties to add less noise than other decentralized perturbation approaches such as randomized response \citep{ErlingssonPK14} used in local differential privacy.
%Secure aggregation protocols \cite{BonawitzIKMMPRS16} allow parties to add noise to the model update in a distributed manner in order to guarantee DP, which requires less noise than other decentralized perturbation approaches such as randomized response \cite{ErlingssonPK14} used in local differential privacy.
Moreover, it also reduces the upstream and downstream bandwidth by a factor of 1000 compared to standard federated learning, making it practical
for mobile systems. 
%Indeed, our idea was to carry all the energy of the updates in few parameters such that adding the noise will result in less distortion than adding on small values. Fortunately, some interesting works have shown how we can constrain the weights to follow a specific distribution at the end of the training \cite{dsd}. However, in our case we are not interested in giving a special shape to our weights, but only to make some of them more important than others, by being updated more often.
The paper is structured as follows: In Section~\ref{sec:backg} we introduce the necessary background to understand the proposal, in Section~\ref{sec:fl_top_k} we define our solution called FL-TOP and in Section~\ref{sec:fl_top_k_dp} its private extension called FL-TOP-DP.



\section{Background}
\label{sec:backg}
\subsection{Federated Learning (FL-STD)}
\label{FL-STANDARD}



In federated learning \citep{ShokriS15,FedAVG}, multiple parties (clients) build a common machine learning model from union of their training data without sharing them with each other. At each round of the training, a selected set of clients retrieve the global model from the parameter server, update the global model based on their own training data, and send back their updated model to the server. The server aggregates the updated models of all clients to obtain a global model that is re-distributed to some selected parties in the next round.  

%\todo{Push to Appendix}
In particular, a subset $\mathbb{K}$ of all $N$ clients are randomly selected at each round to update the global model, and $C = |\mathbb{K}| / N$ denotes the fraction of selected clients. At round $t$, a selected client $k \in \mathbb{K}$ executes $\Tgd$ local gradient descent iterations on the common model $\mbf{w}_{t-1}$ using its own training data $D_k$ ($D = \cup_{k\in \mathbb{K}} D_k$), and obtains the updated model $\mbf{w}_{t}^k$, where the number of weights is denoted by $n$ (i.e., $|\mbf{w}_t^{k}| = |\Delta \mbf{w}_t^k| = n$ for all $k$ and $t$). Each client $k$ submits the update $\Delta \mbf{w}_{t}^k = \mbf{w}_{t}^k - \mbf{w}_{t-1}^k$ to the server, which then updates the common model as follows: $\mbf{w}_{t} = \mbf{w}_{t-1} + \sum_{k \in \mathbb{K}} \frac{|D_k|}{\sum_j |D_j|} \Delta \mbf{w}_{t}^k$, where $|D_k|$ is known to the server for all $k$ (a client's update is weighted with the size of its training data).
The server stops training after a fixed number of rounds $\Tcl$, or when the performance of the common model does not improve on a held-out data. 

Note that each $D_k$ may be generated from different distributions (i.e., Non-IID case), that is, any client's local dataset may not be representative of the population distribution \citep{FedAVG}. This can happen, for example, when not all output classes are represented in every client's training data. 
The federated learning of neural networks is summarized in Alg.~\ref{alg:fed_learn}. In the sequel, each client is assumed to use the same model architecture.




%\begin{itemize}
%    \item Non-IID: When any user's local dataset is not representative of the population distribution \cite{FedAVG}. For example, if the learning task is to classify 10 digits, each user will have only examples of some digits. 
%    \item IID: When any user's local dataset is representative of the population distribution. 
%\end{itemize}


The motivation of federated learning is three-fold: first, it aims to provide confidentiality of each participant's training data by sharing only model updates instead of potentially sensitive training data. Second, in order to decrease communication costs, clients can perform multiple local SGD iterations before sending their update back to the server. 
Third, in each round, only a few clients are required to perform local training of the common model, which further diminishes communication costs  and makes the approach especially appealing with large number of clients. 


%Indeed, in other collaborative learning techniques \cite{}, \emph{all} clients return their model updates to the server after processing a single  mini-batch, which can result in large communication overhead when the number of clients is large. 
However, several prior works have demonstrated that model updates do leak potentially sensitive information \citep{NasrSH19,Property_inference}. Hence, simply not sharing training data \emph{per se} is not enough to guarantee their confidentiality.



\subsection{Differential Privacy}
\label{sec:DP}
Differential privacy allows a party to privately release information about a dataset:  a function of an input dataset is perturbed, so that any information which can differentiate a record from the rest of the dataset is bounded~\cite{Dwork2014book}.
%Consequently, for a record owner, it means that any privacy breach will not be due to participating in the database. 

 \begin{definition}[Privacy loss]
 Let $\mathcal{A}$ be a privacy mechanism which assigns a value $\mathit{Range}(\mathcal{A})$ to a dataset $D$. The privacy loss of $\mathcal{A}$ with datasets $D$ and $D'$ at output $O \in \mathit{Range}(\mathcal{A})$ is a random variable $\mathcal{P}(\mathcal{A},D,D',O) = \log\frac{\Pr[\mathcal{A}(D) = O]}{\Pr[\mathcal{A}(D') = O]}$ 
 %\vspace{-0.2cm}
 %$$
 %\mathcal{P}(\mathcal{A},D,D',O) = \log\frac{\Pr[\mathcal{A}(D) = O]}{\Pr[\mathcal{A}(D') = O]} \vspace{-0.2cm}
 %$$
 where the probability is taken on the randomness of $\mathcal{A}$.%\vspace{-0.25cm}
 \label{def:ploss}
 \end{definition}

\begin{definition}[$(\epsilon,\delta)$-Differential Privacy~\citep{Dwork2014book}] 
A privacy mechanism $\mathcal{A}$ guarantees $(\varepsilon, \delta)$-differential privacy if for any database $D$ and $D'$, differing on at most one record, $\Pr_{O \sim \mathcal{A}(D)}[\mathcal{P}(\mathcal{A},D,D',O) > \varepsilon] \leq \delta$. 

\label{def:DP}
\end{definition}

Intuitively, this guarantees that an adversary, provided with the output of $\mathcal{A}$, can draw almost the same conclusions (up to $\varepsilon$ with probability larger than $1 - \delta$) about any record no matter if it is included in the input of $\mathcal{A}$ or not. That is, for any record owner, a privacy breach is unlikely to be due to its participation in the dataset. 


\descr{Moments Accountant.} Differential privacy maintains composition; the privacy guarantee of the  $k$-fold adaptive composition  of $\mathcal{A}_{1:k} = \mathcal{A}_1, \ldots, \mathcal{A}_k$ can be computed using the moments accountant method \cite{Abadi}. In particular, it follows from Markov's inequality that $\Pr[\mathcal{P}(\mathcal{A},D,D',O) \geq \varepsilon] \leq \mathbb{E}[\exp(\lambda \mathcal{P}(\mathcal{A},D,D',O))]/\exp(\lambda\varepsilon)$ for any output $O \in \mathit{Range}(\mathcal{A})$ and $\lambda > 0$. 
$\mathcal{A}$ is $(\varepsilon, \delta)$-DP %(see Definition~\ref{def:DP}) 
with $\delta = \min_{\lambda} \exp(\alpha_{\mathcal{A}}(\lambda) - \lambda \varepsilon)$, where $\alpha_{\mathcal{A}}(\lambda) = \max_{D,D'} \log\mathbb{E}_{O\sim \mathcal{A}(D)}[\exp(\lambda \mathcal{P}(\mathcal{A},D,D',O))]$ is the log of the moment generating function of the privacy loss. The privacy guarantee of the composite mechanism $\mathcal{A}_{1:k}$ can be computed using that $\alpha_{\mathcal{A}_{1:k}}(\lambda) \leq \sum_{i=1}^k \alpha_{\mathcal{A}_{i}}(\lambda)$ \cite{Abadi}. \smallskip 

\descr{Gaussian Mechanism.} %There are a few ways to achieve DP, including the Gaussian mechanism~\cite{Dwork2014book}.
A fundamental concept of all DP sanitization techniques is the \emph{global sensitivity} of a function~\citep{Dwork2014book}.
%\vspace{-0.1cm}
\begin{definition}[Global $L_p$-sensitivity] 
For any function $f:\mathcal{D} \rightarrow \mathbb{R}^ n$, the $L_p$-sensitivity of $f$ is
$\Delta_p f = \max_{D, D'} || f(D)-f(D') ||_p$, 
for all $D, D'$ differing in at most one record, where $||\cdot||_p$ denotes the $L_p$-norm.\vspace*{-0.15cm}
\label{def:global_sens}
\end{definition}
\smallskip
The Gaussian Mechanism~\citep{Dwork2014book} 
consists of adding Gaussian noise to the true output of a function.
In particular, for any function $f:\mathcal{D} \rightarrow \mathbb{R}^n$, the Gaussian mechanism is defined as adding i.i.d Gaussian noise with variance $(\Delta_2 f \cdot \sigma)^2$  and zero mean to each coordinate value of  $f(D)$. Recall that the pdf of the Gaussian distribution with mean $\mu$ and variance $\xi^2$ is
$
\mathsf{pdf}_{\mathcal{G}(\mu, \xi)}(x) = \frac{1}{\sqrt{2\pi}\xi} \exp\left(-\frac{(x-\mu)^2}{2 \xi^2}\right) 
$.

%: $f(D) + \mathcal{G}(\mathbf{0}, \Delta_2 f \cdot \sigma  )$, where 
%\begin{align}
%\label{eq:g_pdf}
%\mathsf{pdf}_{\mathcal{G}(\bm{\mu}, \Delta_2 f \cdot \sigma)}(\mathbf{x}) = \frac{\exp\left(-\frac{\sum_{i=1}^d(x_i-\mu_i)^2}{2 (\Delta_2 f \cdot \sigma)^2}\right)}{\sqrt{(2\pi)^d}(\sigma\Delta_2 f)^d} 
%\end{align} 
In fact, the Gaussian mechanism draws vector values from a multivariate spherical (or isotropic) Gaussian distribution
which is described by random variable $\mathcal{G}(f(D), \Delta_2 f \cdot \sigma\mathbf{I}_n)$, where $n$ is omitted if its unambiguous in the given context.
%The exact privacy cost $\varepsilon$ and $\delta$ of the $k$-fold adaptive composition of $\mathcal{G}$ is computed using the moments accountant as detailed above \cite{}. 





%\subsection{Federated learning vs. distributed learning vs. collaborative learning}

%There are too many similarities between distributed learning and federated learning. In both of them the training data is distributed, the learning operation is distributed, the model results is also redistributed after each round.

%However, the goal is not the same: in the distributed learning the objective is to learn a model with an optimized and more efficiently manner. Indeed, the distribution allows to accelerate the training. The goal in the federated learning, is to learn collaboratively a common model by preserving the privacy of the data node. The worker in the distributed learning scheme represents the data owner in the federated learning scheme. The node is totally independent on his data and he will never share it with the server, which is not the case when the learning is distributed: the data is splitted and distributed by the server (master node) \cite{Fed_dis}. 

%We can define the relation between the worker node and the server node in the distributed scheme as a master/slave relationship. And the relation between the data owner node and the server node in the federated learning scheme as a collaborative relationship between both even if the orchestration is honored by the server node, but the data owner node can accept/refuse to join the federated learning process or to learn a common model, and has a total autonomy on his local data.

%We can talk about collaborative learning scheme if some independent data owners decide to collaborate in order to train a common model or improving an existing model. 

%As a conclusion, we can say that federated learning is include in both distributed and collaborative learning area.






\section{Federated Pruning}

\label{sec:fl_top_k}

In the standard federated learning scheme (FL-STD, in Section~\ref{sec:backg}), the server sends the latest updated model to a randomly selected set of clients (downstream), and each client sends back its complete model update after local training to the server (upstream) at each round. Knowing that a model has on average millions of parameters (each is a floating point value represented on 32 bits), the network can suffer from large traffic both upstream and downstream. 

Our solution, called FL-TOP, aims to reduce the large amount of network traffic by reducing both downstream and upstream traffic. Moreover, a privacy-preserving extension of this scheme, called FL-TOP-DP, is also proposed, which provides Differential Privacy for the whole training data of every client. %Our private solution improves the model performances and it is due to:

%\begin{itemize}
%    \item As expected and highlighted in \cite{our_cs}, the compression boosts differential privacy. Indeed, compression helps to reduce the needed noise requires to reach a DP guarantee by reducing the sensitivity $S$. 
    
%    \item In FL-STD-DP, the noise is added to each update's coordinate. However, all the updates are not equal in terms of magnitudes and adding the noise to one with a value close to zero is like generating a random update value. To avoid this problem, we proposed a solution which aims to carry all the energy of an update only in few \TOPK coordinates, such that we can reduce the noise distortion introduced by DP. 
%\end{itemize}

%To decrease large network traffic, we adapt compressive sensing to federated learning. The new algoritm is called FL-CS. Moreover, this scheme is also extended to a privacy-preserving version, called FL-CS-DP, which aims to protect the training data of every participant. We show that compression improves model performance with Differential Privacy by reducing the added noise compared to the uncompressed DP variant of federated learning. Hence, both FL-CS and FL-CS-DP improve bandwidth efficiency, and in addition, FL-CS-DP also boosts the accuracy of differentially private federated learning. 

In what follows, we first describe the non-private scheme FL-TOP and then the privacy-preserving FL-TOP-DP. 

%More specifically, FL-CS (see Alg.~\ref{alg:fed_cs}) differs from the standard federated scheme StdFed (see Alg.~\ref{alg:fed_learn}) as follows:

%\begin{enumerate}
%    \item Each client returns a proportion of coefficients from the frequency domain $y_{t}^{k}=\Theta(\mbf{w}_{t}^k- \mbf{w}_{t-1}^k)$ instead of sending the complete update in the time domain $\Delta \mbf{w}_{t}^{k}=(\mbf{w}_{t}^k- \mbf{w}_{t-1}^k)$. We use the discrete cosine transform (DCT) \cite{ahmed1974discrete,Ahmed91} to transform the weights vector from the time domain to the frequency domain.
%    \item The server averages the coefficient vectors  $y_{t}^{k}$ sent by each client $k$. The momentum and the error feedback are calculated before to reconstruct the vector $s_{t}$ the error is then accumulated for the next round. However, the error due to the compression was not considered in FL-Std (as we do not use compression for this scheme).
%    \item The FL-CS uses then the reconstructed vector $s_{t}$ to update the model: $\mbf{w}_{t} = \mbf{w}_{t-1} + \mbf{s}_{t} $, where, in FL-Std we update the model just after the averaging step: $\mbf{w}_{t} = \mbf{w}_{t-1} + \sum_{k} \frac{|D_k|}{\sum_j^N |D_j|} \Delta \mbf{w}_{t}^{k}$
%\end{enumerate}

\subsection{FL-TOP: Federated Pruning for Compression}

%Recent and promising compression techniques used in the context of federated learning make the strong assumption that the original model's update that we aim to reconstruct from the compressed vector is sparse. Indeed, this assumption is needed to retrieve the original update. However, the sparsity of the update's vector depends on too many parameters such that the nature of data, the number of SGD updates performed at each client \footnote{More we perform SGD updates and less the model update is sparse},etc, and except for the first, we can choose a configuration which allow to reach this sparsity. On the other hand, in federated learning, a client may be available only during few rounds [Bennis] and therefore it is more useful in this case to take the advantage of this availability by performing a maximum number of SGD iterations at each client.  

%\cite{SIGNSGD} a quantization protocol allows to compress during downstream and upstream steps but requires the use of all the clients at each round which once again is not realistic in the context of federated settings [Bennis]. 


%In order to reach our highly compression purpose, we have decided to rethink the amount of information exchanged between the server and rarely available clients. 

%In federated learning, server and clients have to exchange a large amount of information over the training.
%Indeed, the server at each round has to resend the latest updated model (weights) to a new set of available clients. Same, each selected client has to resend back the update of the received model after its training. 

FL-TOP is inspired by the pruning techniques proposed in \cite{dsd} (see Section~\ref{sec:related_work} for more details), and it aims to reduce the amount of parameters exchanged downstream (from the server to the participating entities) and upstream (from the participating entities to the server).  In our scheme, each client updates only a small subset, \TOPK, of the model parameters (weights) at each round. Only the $K$ weight values of these \TOPK parameters are updated during training, and neither the clients nor the server need to transfer the values of the remaining $n-K$ parameters, where $n$ is the total number of parameters. The set of \TOPK parameters do not change over the whole training and are identical for all clients. 
We experimentally show in Section \ref{sec:exp} that, if these $K$ parameters are chosen carefully, the performance penalty is negligible even if $K = 0.005 \cdot n$, that is, $99.5\%$ of the model parameters are pruned. Note that unlike standard pruning techniques, where the set of pruned weights are re-selected after each SGD iteration \citep{dsd}, our scheme always updates the same $K$ parameters.

These \TOPK parameters are selected by the server at the beginning of the protocol. More specifically, the server initializes the model and trains
that with some public data that have a similar distribution as the clients' training data. After a few SGD iterations, the server selects the $K$ parameters which values changed the most.


%to select which weights should be pruned (change over the rounds) while in our case we choose the trainable weights based on their updates values after only few SGD iterations via a public dataset and we select them once.

%Moreover, as we update the same \TOPK updated weights during all the training, the exchange between the server and the clients in both direction will be limited to those weights. Therefore, our solution allows to reduce both downstream and upstream costs. 

FL-TOP is described in Alg.~\ref{alg:topk}. First, the server uses public data to identify the set $\mathbb{T}$ of the \TOPK parameters ($K=|\mathbb{T}|$), before starting federated learning. In particular, starting from a public model $\mbf{w}_0$, it accumulates the absolute value of gradients per parameter over $T_{\mathsf{init}}$ SGD iterations, and selects the $K$ parameters with the largest accumulated gradients. 
After that, the values/updates\footnote{weight values for downstream and update/gradients for upstream traffic} of these parameters are the only ones exchanged during the rest of the training between the server and the clients. 

At each round, each selected client $k$ uses the $K$ updated weights $\hat{\mbf{w}}_{t-1}$ received from the server to create a new weight vector $\mbf{w}_{t-1}^{k}$ of size $n$, such that $\mbf{w}_{t-1}^{k}$ is composed from the compressed vector $\hat{\mbf{w}}_{t-1}^{k}$ of size $K \leq n$ (with coordinates in $\mathbb{T}$) and $n-K$ weights from the initialization vector $\mbf{w}_0$. $\mbf{w}_0$ is identical for all participants and can be generated from a shared seed.
Note that when $K=|\mathbb{T}|=n$, the scheme is equivalent to FL-STD. 
The weight vector $\mbf{w}_{t-1}^{k}$ is used to train the client's model. However, only the weights in $\mathbb{T}$ are updated while the remaining ones are kept fixed. To do that, the weights not in $\mathbb{T}$ are reinitialized after each SGD iteration to $\mbf{w}_0$.
The server receives only the values from $\mbf{w}_{t}^{k} - \mbf{w}_{t-1}^{k}$ at coordinates $\mathbb{T}$, denoted by $\mathcal{C}(\mbf{w}_{t}^{k} - \mbf{w}_{t-1}^{k})$ for short, from every client $k$, and updates the common model $\mathbf{w}_t$ with the average of these compressed updates (in Line 12).

%By limiting the available trainable weights to only the \TOPK updated weights, we constraint the model to update more often those weights. 


%To resume, we select first and once the weights which are more likely to be updated by using public data and then we use the constraint to force them to remain the most updated weights at each round and at each client.


\subsection{FL-TOP-DP: Differentially Private Federated Pruning}
\label{sec:fl_top_k_dp}


\subsubsection{Privacy Model}
\label{sec:privacy_model}
We consider an adversary, or a set of colluding adversaries, who can access any update vector sent by the server or any clients at each round of the protocol.  A plausible adversary is a participating entity, i.e. a malicious client or server, that wants to infer the training data used by other participants.
The adversary is \emph{passive} (i.e., honest-but-curious), that is, it follows the learning protocol faithfully. 

Different privacy requirements can be considered depending on what information the adversary aims to infer. In general, private information can be inferred about:
\begin{itemize}
    \item any record (user) in any dataset of any client (\emph{record-level privacy}),
    \item any client/party (\emph{client-level privacy}).
\end{itemize}

To illustrate the above requirements, suppose that several banks build a common model to predict the creditworthiness of their customers. A bank certainly does not want other banks to learn the financial status of any of their customers (record privacy) and perhaps not even the average income of all their customers  (client privacy).
%\todo{another example for client privacy? One good reason can be: for the marketing strategy, if we know that the average income of all their customers is high, then the other banks may plan to open new offices in this location.}

Record-level privacy is a standard requirement used in the privacy literature and is usually weaker than client-level privacy. Indeed, client-level privacy requires to hide any information which is unique to a client including perhaps all its training data.   

%The motivation of client-based privacy is that several parties may contribute confidential data to build a common model, and they do not want their competitors (i.e., other parties or the aggregator) to learn \emph{any} information that is specific only to their training data.
%However, this requirement can be too strict in some settings and may require significant distortion of the training. Hence, a more relaxed requirement is to prevent the leakage of any information that is specific only to a single record or group of records in the training data.     
%For example, suppose that several banks build a common model to predict the creditworthiness of their customers. 
%A bank certainly does not want other banks to learn the financial status of any of their customers (record privacy), the number of their afro-american customers (group privacy) and perhaps neither any aggregate statistic about their customers such as their average income (client privacy).  

We aim at developing a solution that provides \emph{client-level privacy and is also bandwidth efficient}. 
For example, in the scenario of collaborating banks, we aim at protecting any information that is unique to each single bank's training data.
The adversary should not be able to learn from the received model or its updates whether any client's data is involved in the federated run (up to $\varepsilon$ and $\delta$). 
We believe that this adversarial model is reasonable in many practical applications when the confidential information spans over multiple samples in the training data of a single client (e.g., the presence of a group a samples, such as people from a certain race). Differential Privacy guarantees plausible deniability not only to any groups of samples of a client but also to any client in the federated run. Therefore, any negative privacy impact on a party (or its training samples) cannot be attributed to their involvement in the protocol run.


\subsubsection{Operation}
\label{sec:operation}

FL-TOP-DP is described in Alg.~\ref{alg:topk_dp} is very similar to FL-TOP except that each client adds Gaussian noise to its \TOPK model updates to guarantee client-level DP, and applies secure aggregation allowing the server to learn only the aggregated (and noisy) model update. More specifically, each client first calculates its compressed model update $\Delta \mbf{w}_t^k = \mathcal{C}(\mbf{w}_{t}^k- \mbf{w}_{t-1}^k)$ (in Line 25) which is then clipped (in Line 26) to obtain $\Delta \hat{\mbf{w}}_t^k$ with $L_2$-norm at most $S$. After that, random noise $\mbf{z}_{k} \sim \mathcal{G}(0,S\mathbb{\sigma}\mathbf{I}/\sqrt{\mathbb{K}})$ is added to $\Delta \hat{\mbf{w}}_t^k$ such that the sum $\sum_{k \in \mathbb{K}} (\Delta \hat{\mbf{w}}_t^k +  \mbf{z}_{k}) = \sum_{k \in \mathbb{K}} \Delta \hat{\mbf{w}}_t^k + \mathcal{G}(0,S\mathbb{\sigma}\mathbf{I})$ as the sum of Gaussian random variables also follows Gaussian distribution\footnote{More precisely, $\sum_{i}\mathcal{G}(\nu_{i},\xi_{i})=\mathcal{G}(\sum_{i} \nu_{i},\sqrt{\sum_{i}\xi_{i}^{2}})$} and then differential privacy is satisfied where $\varepsilon$ and $\delta$ can be computed using the moments accountant described in Section \ref{sec:DP}. Recall that the \TOPK coordinates in $\mathbb{T}$ are selected and distributed by the server, which is honest-but-curious by assumption.

However, as the noise is inversely proportional to $\sqrt{\mathbb{K}}$, 
$\mbf{z}_{k}$ is likely to be small if $|\mathbb{K}|$ is too large. Therefore, the adversary accessing an individual update $\Delta \hat{\mbf{w}}_t^k + \mbf{z}_{k}$ can almost learn a non-noisy update since $\mbf{z}_{k}$ is small. Hence, each client uses secure aggregation to encrypt its individual update before sending it to the server. Upon reception, the server sums the encrypted updates as:
\begin{align}
\sum_{k\in\mathbb{K}} \mathbf{c}_t^k &= \sum_{k\in\mathbb{K}}\mathsf{Enc}_{K_k}(\Delta \hat{\mbf{w}}_t^k + \mbf{z}_{k}) \nonumber 
 = \sum_{k\in\mathbb{K}} \Delta \hat{\mbf{w}}_t^k + \sum_{k\in\mathbb{K}}\mbf{z}_{k} \nonumber \\
& = \sum_{k\in\mathbb{K}} \Delta \hat{\mbf{w}}_t^k + \mathcal{G}(0,S\mathbb{\sigma}\mathbf{I}) \label{eq:a1}
\end{align}
where $\mathsf{Enc}_{K_k}(\Delta \hat{\mbf{w}}_t^k + \mbf{z}_{k})= \Delta \hat{\mbf{w}}_t^k + \mbf{z}_{k} + \mbf{K}_k \mod p$ and $\sum_{k}\mbf{K}_k=0$ (see \cite{AcsC11,BonawitzIKMMPRS16} for details). Here the modulo is taken element-wise and $p=2^{\lceil \log_{2}(\max_{k}|| \Delta \hat{\mbf{w}}_t^k + \mbf{z}_{k}||_{\infty}|\mathbb{K}|)\rceil}$.
Let $\gamma_t^k = 1/\max\left(1, \frac{||\Delta \mbf{w}_t^k||_2}{S}\right)$. Then, 
\begin{align}
\sum_{k \in \mathbb{K}} \Delta \hat{\mbf{w}}_t^k &= \sum_{k\in \mathbb{K}} \gamma_t^k \Delta \mbf{w}_t^k  \nonumber
 = \sum_{k\in \mathbb{K}} \gamma_t^k \mathcal{C}(\mbf{w}_{t}^k- \mbf{w}_{t-1}^k, \mathbb{T}) \nonumber \\
& = \mathcal{C}(\sum_{k\in \mathbb{K}} \gamma_t^k (\mbf{w}_{t}^k- \mbf{w}_{t-1}^k), \mathbb{T}) \label{eq:a2}
\end{align}
where the last equality comes from the linearity of the compression operation. Indeed, recall that each client selects the values of the \emph{same} \TOPK coordinates from $\mathbb{T}$. 
Plugging Eq.~\eqref{eq:a2} into Eq.~\eqref{eq:a1}. we get that
\begin{align*}
\sum_{k\in\mathbb{K}} \mathbf{c}_t^k = \mathcal{C}(\sum_{k\in \mathbb{K}} \gamma_t^k (\mbf{w}_{t}^k- \mbf{w}_{t-1}^k), \mathbb{T}) + \mathcal{G}(0,S\mathbb{\sigma}\mathbf{I})
\end{align*}

\noindent \textbf{Privacy analysis:}
The server can only access the noisy aggregate  which is sufficiently perturbed to ensure differential privacy; any client-specific information that could be inferred from the noisy aggregate is tracked and quantified by the moments accountant, described in Section~\ref{sec:DP}, as follows. 

Let $\eta_0(x|\xi) =  \mathsf{pdf}_{\mathcal{G}(0, \xi)}(x)$ and $\eta_1(x|\xi) =  (1-C) \mathsf{pdf}_{\mathcal{G}(0, \xi)}(x) + C \mathsf{pdf}_{\mathcal{G}(1, \xi)}(x)$ where $C$ is the sampling probability of a single client in a single round. Let
$
%\label{eq:alpha}
\alpha(\lambda| C) = \log\max(E_1(\lambda, \xi, C), E_2(\lambda, \xi, C)) 
$
where
$%\begin{align*}
E_1(\lambda,  \xi, C) =  \int_{\mathbb{R}}\eta_0(x|\xi, C) \cdot \left(\frac{\eta_0(x|\xi, C)}{\eta_1(x|\xi, C)}\right)^{\lambda} dx
$ and
$ E_2(\lambda,  \xi, C) = \int_{\mathbb{R}}\eta_1(x|\xi, C) \cdot \left(\frac{\eta_1(x|\xi, C)}{\eta_0(x|\xi, C)}\right)^{\lambda} dx
$.

\begin{theorem}[Privacy of FL-TOP-DP]
\label{thm:dg_privacy}
FL-TOP-DP is $(\min_\lambda  (T_{\mathsf{cl}}\cdot \alpha (\lambda | C)  - \log \delta) /\lambda, \delta)$-DP. 
\end{theorem}
Given a fixed value of $\delta$, $\varepsilon$ is computed numerically  as in \cite{Abadi,MironovTZ19}.

%The magnitude of the added Gaussian noise is proportional to the sensitivity $S$, which is in turn often proportional to the model size $n$ \cite{zhu2020votingbased}. 
%Hence, when $n$ becomes large, SGD often fails to converge due to the perturbation error caused by the added noise  \cite{zhu2020votingbased}.
%In our approach, the perturbation error is less since Gaussian noise is added to the compressed vector with size $m < n$.
%On the other hand, compression also induces some reconstruction error owing to its lossy nature.
%The total error is the sum of the reconstruction and the perturbation error and is quantified in Theorem \ref{thm:rip}. 
%Finding the right trade-off between these two errors is the key to achieve good model quality.


%locally enough noise to its clipped L2-norm update such that the server fails to learn any client-specific information from the noisy update. However, this approach (aka, local differential privacy \cite{ErlingssonPK14}) needs so much perturbation making it impracticable especially if the number of clients $|\mathbb{K}|$ is limited. Fortunately, a better solution used in \cite{AcsC11,BonawitzIKMMPRS16,Hybrid-approach} adds the noise with a distributively manner at each client such that the aggregate is sufficiently noisy to have meaningful differential privacy. However, an adversary if he has access to any individual update, he can learn some client-specific information as each update is weakly-noised. To this purpose, individual noisy updates are encrypted with a simple and efficient encryption scheme from \cite{AcsC11,BonawitzIKMMPRS16} such that the adversary can access only the aggregate which is sufficiently noised to guarantee DP for any client.






%Note also that the non-private scheme can be used with encryption such that each client will send $\mathsf{Enc}_{K_k}(\mathcal{C}(\hat{\Delta \mbf{w}_{t}^{k}},\mbf{m}))$ instead of $\mathcal{C}(\hat{\Delta \mbf{w}_{t}^{k}},\mbf{m})$, which will allow the server to access only a non-encrypted aggregation $\sum_{k\in\mathbb{K}}\mathsf{Enc}_{K_k}(\hat{\mbf{c}_{t}^{k}})= \sum_{k\in\mathbb{K}} \hat{\mbf{c}_{t}^{k}} $, however we do not have any theoretically guarantee as provided by differential privacy to ensure that an adversary can not infer any information from the non-noisy aggregate.


%\begin{align*}
%    \mathcal{C}( x_{1} + \cdots + x_{|\mathbb{K}|},m)= \mathcal{C}(x_{1},m) + \cdots + \mathcal{C}(x_{|\mathbb{K}|},m)
%\end{align*}

%This property allows the server to sum up $|\mathbb{K}|$ different compressed vectors before to reconstruct the signal with $\mathcal{U}(\mathcal{C}( x_{1} + \cdots + x_{|\mathbb{K}|},m),n)$ instead of reconstructing each compressed vector individually and then average them. Secure aggregation used in [Dream,Pra] is precisely applicable only if linearity property is available. Indeed, it consists of summing (linear operation) $|\mathbb{K}|$ encrypted values such that each individual value is unclear while the aggregate is clear.




\begin{algorithm}[h]
\small
		\caption{FL-TOP: Federated Learning \label{alg:topk}}
	\DontPrintSemicolon
	{\bf Server:}\;
	\Indp Initialize common model $w_0$\;
	Select set $\mathbb{T}$ of \TOPK updated weights' coordinates via public dataset\;
	%update (absolute value) after the training on \;
	%a public dataset D' \;
	\For {$t=1$ \KwTo $\Tcl$}
	{
	    Select $\mathbb{K}$ clients uniformly at random \;
		\For {\textrm{each} client $k$ \textrm{in} $\mathbb{K}$}
		{	
			$\mathbf{c}_t^k = \mathbf{Client}_k(\mathcal{C}(\mbf{w}_{t-1},\mathbb{T}))$\;
		}
		
		$\mbf{w}_{t}=\mbf{w}_{0}$\;
		$j=1$\;
		\For {\textrm{each} coordinate $i$ in $\mathbb{T}$}
		{
		    $\mbf{w}_{t}[i] = \mbf{w}_{t-1}[i] + \sum_{k} \frac{\mathbf{c}_t^k [j]}{|\mathbb{K}|}$\;
		    $j=j+1$\;
	    }
	}
	\KwOut{Global model $\mbf{w}_t$}\;
	\Indm {\bf $\mathbf{Client}_{k}(\hat{\mbf{w}}_{t-1}^k)$:}\;
	\Indp
	
	$\mbf{w}_{t-1}^k=\mbf{w}_{0}$\;
	$j=1$\;
	\For {\textrm{each} coordinate $i$ in $\mathbb{T}$}
	{
	    $\mbf{w}_{t-1}^k[i] = \hat{\mbf{w}}_{t-1}^k[j]$\;
	    $j=j+1$\;
    }
    
	$\mbf{w}_{t}^k = \mathbf{Top_kSGD}(D_k, \mbf{w}_{t-1}^k,\mbf{w}_{0}, \Tgd, \mathbb{T})$\;
	\KwOut{Model update $\mathcal{C}(\mbf{w}_{t}^k- \mbf{w}_{t-1}^k,\mathbb{T})$} 
\end{algorithm}


\begin{algorithm}[h]
\small
	\caption{$\mbf{Top_k}$-Stochastic Gradient Descent \label{alg:sgdk}}
	\DontPrintSemicolon
	\KwIn{$D$ : training data, $\Tgd$ : local epochs, $\mathbf{w}$ : weights, $\mbf{w}_{0}$ : first weights' initialization, $\mathbb{T}$ : set of \TOPK values coordinates .}  
    \For {$t=1$ \KwTo $\Tgd$}
	{
	    Select batch $\mathbb{B}$ from $D$ randomly\;
	    
	    $\mbf{u} =- \eta \nabla f(\mathbb{B}; \mbf{w})$\;
	    
	    %$j=1$\;
		\For {\textrm{each} coordinate $i$ in $\mathbb{T}$}
		{
		    $\mbf{w}[i] = \mbf{w}[i] + \mbf{u}[i] $\;
		    %$j=j+1$\;
	    }
	}
    \KwOut{Model $\mbf{w}$} 
\end{algorithm}


\begin{algorithm}[h]
\small
		\caption{FL-TOP-DP: Federated Learning \label{alg:topk_dp}}
	\DontPrintSemicolon
	{\bf Server:}\;
	\Indp Initialize common model $w_0$\;
	Select set $\mathbb{T}$ of \TOPK updated weights' coordinates via public dataset\;
	%update (absolute value) after the training on \;
	%a public dataset D' \;
	\For {$t=1$ \KwTo $\Tcl$}
	{
	    Select $\mathbb{K}$ clients uniformly at random \;
		\For {\textrm{each} client $k$ \textrm{in} $\mathbb{K}$}
		{	
			$\mbf{c}_t^k = \mathbf{Client}_k(\mathcal{C}(\mbf{w}_{t-1},\mathbb{T}))$\;
		}
		
		$\mbf{w}_{t}=\mbf{w}_{0}$\;
		$j=1$\;
		\For {\textrm{each} coordinate $i$ in $\mathbb{T}$}
		{
		    $\mbf{w}_{t}[i] = \mbf{w}_{t-1}[i] + \sum_{k} \frac{ \mbf{c}_{t}^{k}[j]}{|\mathbb{K}|}$\;
		    $j=j+1$\;
	    }
	}
	\KwOut{Global model $\mbf{w}_t$}\;
	\Indm {\bf $\mathbf{Client}_{k}(\hat{\mbf{w}}_{t-1}^k)$:}\;
	\Indp
	
	$\mbf{w}_{t-1}^k=\mbf{w}_{0}$\;
	$j=1$\;
	\For {\textrm{each} coordinate $i$ in $\mathbb{T}$}
	{
	    $\mbf{w}_{t-1}^k[i] = \hat{\mbf{w}}_{t-1}^k[j]$\;
	    $j=j+1$\;
    }
    
	$\mbf{w}_{t}^k = \mathbf{Top_kSGD}(D_k, \mbf{w}_{t-1}^k,\mbf{w}_{0}, \Tgd, \mathbb{T})$\;
	
	$\Delta \mbf{w}_t^k = \mathcal{C}(\mbf{w}_{t}^k- \mbf{w}_{t-1}^k,\mathbb{T})$\;

	$\Delta \hat{\mbf{w}}_t^k = \Delta \mbf{w}_t^k / \max\left(1, \frac{||\Delta \mbf{w}_t^k||_2}{S}\right)$\;
    \KwOut{$\mathsf{Enc}_{K_k}(\mathcal{G}(\Delta \hat{\mbf{w}}_t^k, S \mathbf{I}\sigma /\sqrt{|K|}))$}

	
	
\end{algorithm}

\subsubsection{Remarks}

The magnitude of the added Gaussian noise is proportional to the clipping threshold $S$, which is in turn calibrated to the norm of the model update. However, the norm of the model update increases if the model size increases \citep{zhu2020votingbased}, and hence $S$ should be chosen sufficiently large to guarantee fast convergence with large accuracy. On the other hand, too large $S$ also increases the perturbation error caused by the added noise.

%As a solution to this problem, authors in \cite{our_cs} propose to use a lossy compression technique called Compressive sensing \cite{candes2006robust,donoho2006compressed}. The technique consists of reconstructing the aggregated updates' model at each round on the server side. To do that, the server use the aggregated compressed updates received from a set of $\mathbb{K}$ to reconstruct the whole aggregated update. Although, the method is effective however it requires to assume the sparsity of the aggregated update that we aim to reconstruct. Also, the reconstruction is heavy in term of computation in particular for large model size. Finally, the compression allows to reduce the bandwidth cost only in upstream direction (from clients to server).

%We decided to construct our solution based on the pruning techniques. Indeed, such techniques allow to compress any model by iteratively constraining its weights over the training \cite{Joshua_binary,dsd} (see Section~\ref{sec:related_work} for more details). 

FL-TOP aims to diminish this perturbation error by reducing $S$ via compression which also increases the $L_2$-norm of the compressed update vector. This is illustrated in Figure \ref{fig:distribution}, which shows that the norm of the \TOPK coordinates with FL-TOP tend to be larger than with FL-STD (i.e., when all coordinates get updated not only the \TOPK). Therefore, besides decreasing the magnitude of the added noise, FL-TOP also decreases the relative error on the retained parameters. These together decrease the perturbation error caused by the added noise. %Indeed, %if we add the noise to an update value close to 0, it is equivalent to generate a random update value.

%Fortunately, the compression technique used in FL-TOP allows to reduce the sensitivity S. Moreover, the iterative constraint procedure which force the model to converge by only updating a small proportion of weights can be exploited in our advantage as it allows to maximize the updates of only the trainable weights. 

%To do that, we have decided to update only the same small proportion of weights during all the training process while the remaining weights are constant from their initialization state. %Moreover, we also want to exploit the fact that some weights due to their initialization values need to be more updated than others. Therefore, their updates should be more larger and then less impacted by the noise. In what follows, we call the weights which required to be more updated as the \TOPK updated weights \footnote{Instead of the weights' values}. Note that during all the training, only the \TOPK updated weights are modified while all the other remain statics.  

Notice that there exist other alternatives to identify the \TOPK coordinates in a privacy-preserving manner than using a public dataset. For example, every client can select the \TOPK parameters with the largest magnitude during the first rounds locally, and send them to the server for aggregation. More specifically,
each client creates a parameter vector with size $n$, where the \TOPK coordinates are set to 1 while the rest are kept 0. Then, these binary vectors are noised and aggregated by the server like in Section \ref{sec:operation}. In the rest of the training, all participants exchange only the updates and weights of the these \TOPK parameters like in FL-TOP.
However, aside from consuming more privacy budget, this approach also has lower accuracy than our proposal according to our tests. Moreover, it has larger communication cost in the initialization phase when the \TOPK parameters are identified and the whole binarized parameter vector is sent for aggregation. 

%Note that in term of privacy, it is very expensive to choose \TOPK values, for this reason, the \TOPK updated weights are fixed by the server and via a public dataset before to start the federated learning process. Therefore, we reduce the privacy risks compared to the case when we define collaboratively such \TOPK updated weights. 

%Also, it is important that all the clients share the same weights' updates (not necessary the same values but same coordinates) with the server in order to be able to use secure aggregation.

%We are aware that even without the constraint defined before, some weights are more likely to be updated than others at each round and at each client. However, identifying those most updated weights (\TOPK\footnote{The selection of the most updated weights (\TOPK) are based on the absolute value of the update vector.})  are a problem for at least two reasons:

%\begin{itemize}
%    \item Using secure aggregation protocol as in our private scheme requires to perform linear operations as the element-wise sum of $|\mathbb{K}|$ updates' vectors. However, it becomes impossible if all the clients do not have exactly the same \TOPK updated weights at each round.  
%    \item As a solution to the problem above, each selected client at each round may send first its \TOPK coordinates in a sparse vector of size $n$ and $k$ non-zeros values. After that, the server calculates the sum and selects the \TOPK coordinates. The server then sends back the \TOPK coordinates to each selected client in order to return their values. Other than the fact that we introduce two more communication exchanges between the clients and the server, selecting the \TOPK coordinates are considered expensive in term of privacy as we have no free lunch and the clients are required to use differential privacy at each exchange with the server which means adding the noise and managing two epsilon budgets: one for the \TOPK selection and the second for their values.
%\end{itemize}






\section{Experimental Results}
\label{sec:exp}

The goal of this section is to evaluate the performance of our proposed schemes FL-TOP and FL-TOP-DP on a benchmark dataset and a realistic in-hospital mortality prediction scenario. We aim at evaluating their performance with different levels of compression and comparing them with the performance of the following learning protocols\footnote{More baselines are considered but due to the lack of space, we have decided to present only those which return the best results. All other results can be found in the appendix( Section~\ref{sec:furthmore_experiments}).}:
\begin{itemize}
    \item FL-STD: The Standard Federated Learning scheme as described in Section \ref{FL-STANDARD} (see Alg.~\ref{alg:fed_learn}). %The standard federated learning algorithm described in \ref{alg:fed_learn} consists of choosing randomly a subset of clients $\mathbb{K}$, each client update the received model on his local dataset before to send it back to the server. After that, the server has only to average and update the model.
    \item FL-BASIC: A Federated Learning scheme that updates a random subset of parameters instead of the \TOPK parameters at each SGD iteration. This subset is re-selected at the beginning of each new round.
    The $n-k$ non-selected parameters are still reinitialized after each SGD update as in FL-TOP. 
    %\item FL-TOP-BIS: as with FL-TOP we train also only the weights include in the set of \TOPK updated weights $\mathbb{T}$, however, we only reinitialize the weights which are not include in the \TOPK set at the end of each round instead of after each sgd update. 
    \item FL-CS: A Federated Learning scheme that uses Compressive sensing (CS) to compress model updates from \cite{our_cs}. See Section \ref{sec:related_work} for more details.
\end{itemize}

Note that all compression operators in the baselines are linear (just like FL-TOP-DP), and hence they can also be used with secure aggregation. Similarly to FL-TOP-DP, the private extensions (i.e., FL-BASIC-DP and FL-CS-DP) also clip and then noise the compressed updates. 

We evaluate the above learning algorithms on the well-known Fashion-MNIST dataset \citep{Fashion-MNIST} and on the Premier Healthcare Database, which is  a real-world medical dataset of 1.2 millions of US hospital patients \footnote{\href{https://www.premierinc.com/newsroom/education/premier-healthcare-database-whitepaper}{https://www.premierinc.com/newsroom/education/premier-healthcare-database-whitepaper}}. More details can be found in Appendix~\ref{sec:medical_dataset_desc} and Appendix~\ref{sec:fashion_mnist_desc}.

Recall that the \TOPK weights are selected before starting the federated learning process using public data. For Fashion-MNIST, we randomly select  a batch with size 10 from MNIST dataset \citep{MNIST} described in Appendix~\ref{sec:mnist_desc}. For the medical dataset, we did not find any public dataset with the same features as ours, and for this reason, we selected randomly from the dataset a batch of 356 patients\footnote{Reduced to 24 patients when we train via downsampling with 12 patients for each class}. This set is used only by the server and never by any client. Afterwards, the server performs $T_{\mathsf{init}}$ SGD iterations starting from the model parameters $\mathbf{w}_0$ on the same batch to identify the \TOPK weights.
We experimentally show later that even these small batches are enough for the server to find a good set of \TOPK weights. 

%Note that we use a  reasonable small batch size with equivalent size than client's data size as public data in order to show that we do not need a large public dataset to fix our \TOPK trainable weights.  

%For each dataset, we run $\Tgd=5$ SGD iterations without any constraint on the server side to identify the K largest updated weights called \TOPK updated weights. 

In order to select the clipping threshold $S$, 
the server executes a single training round locally, which is composed of $\Tgd$ SGD iterations starting from the model parameters $\mathbf{w}_0$, using the batch from the public data. The clipping threshold $S$ is set to the $L_2$-norm of the \TOPK weight update obtained for this single training round. For FL-BASIC-DP, the same steps are repeated for 100 times, where a new random set of trainable weights with size $K$ are selected each time, which yields 100 $L_2$-norm values. $S$ is set to the median of these $L_2$-norm values. We think that this approach is more fair, because the set of trainable weights is re-selected at each round in FL-BASIC-DP. The computed values of $S$ can be found in Table~\ref{tab:Sensitivity_fashion_mnist} and Table~\ref{tab:Sensitivity_medical_data} for Fashion-MNIST and Medical dataset, respectively.  
More information about the model architectures and the hyper-parameter selection can be found in Appendix \ref{sec:app}. 

%Once the \TOPK trainable weights are selected, we run each algorithm for the same number of SGD iterations performed by each client $\Tgd=5$ with the same batches defined above and then we use the updates' $L_2$-norm of the trainable weights as the sensitivity S. To be more fair with FL-BASIC-DP which use a new random set of trainable weights at each round, we have decided to run the scheme from the initialized model 100 times with a new set of trainable weights at each time. After that, S is set as the median sensitivity over 100 sensitivities. All the values used can be found in Table~\ref{tab:Sensitivity_fashion_mnist} and Table~\ref{tab:Sensitivity_medical_data} for fashion-mnist dataset and medical dataset, respectively.  



%\begin{figure}[h]
%  \centering
%  \includegraphics[scale=0.5]{figs/Distribution_fashion_mnist_data.pdf}
%  \caption{Distributions of the \TOPK updated weights (r=0.5\%). The \TOPK updated weights are those with the highest absolute update values defined before starting training by using a public dataset. The comparison is performed on the fashion-mnist dataset between our scheme FL-TOP and the standard scheme FL-STD at the end of the training. We decided to choose the value of r=0.5\% as the smallest value which allows to reach the best accuracy in the private scheme FL-TOP-DP.}
%  \label{fig:fashion_mnist}
%\end{figure}

%\begin{figure}[h]
%  \centering
%  \includegraphics[scale=0.5]{figs/Distribution_medical_data.pdf}
%  \caption{Distributions of the \TOPK updated weights (r=0.1\%). The \TOPK updated weights are those with the highest absolute update values defined before starting training by using a public dataset. The comparison is performed on the medical dataset between our scheme FL-TOP and the standard scheme FL-STD at the end of the training. We decided to choose the value of r=0.1\% as the smallest value which allows to reach the best accuracy in the private scheme FL-TOP-DP.}
%  \label{fig:medical_data}
%\end{figure}

\begin{figure*}[h]
  \centering
  \includegraphics[scale=0.35]{figs/Distribution.pdf}
  \caption{Distributions of the \TOPK weight values (after convergence) for both FL-TOP and FL-STD schemes with the Fashion-MNIST dataset (left) and the medical dataset (right).}
  \label{fig:distribution}
\end{figure*}

\begin{table*}[!ht]
    \begin{minipage}{.5\linewidth}
    \centering
    \scalebox{0.6}{
    \begin{tabular}{|c|c|c|c|c|c|c|}
        \hline
         \multirow{4}{*}{\emph{$r$}} & \multirow{4}{*}{Algorithms} & \multicolumn{5}{c|}{\emph{Performance}} \\
         \cline{3-7}
         %\hline
         & &  \multirow{3}{*}{\emph{Accuracy}}  & \multirow{3}{*}{\emph{Round}} & \emph{Downstream} & \emph{Upstream} & \multirow{3}{*}{\emph{$\epsilon$}} \\
         
         & &                &                 &           \emph{Cost}                &     \emph{Cost}              &                     \\
         
         & &               &                   &            (Kilobyte)           &        (Kilobyte)             &                       \\
         
         \hline

        \multirow{8}{*}{$0.5\%$} &  FL-BASIC   &  0.65  & 193 & 21402.03 & 107 & N/A  \\
        \cline{2-7}
        %&  FL-BAS-2  &  0.46  & 196 & 21734.70 & 108.66 & N/A  \\
        %\cline{2-7}
        %&  FL-BAS-3  &  0.73  & 200 & 110.88 & 110.88 & N/A  \\
        %\cline{2-7}
        %&  FL-BAS-4  & 0.41  & 197 & 109.22 & 109.22 & N/A  \\
        %\cline{2-7}
        &  FL-CS  &  0.57  & 185 & 20514.9 & 102.56 & N/A  \\
        \cline{2-7}
        %&  FL-TOPK-BIS  &  0.76  & 200 & 110.88 & 110.88 & N/A  \\
        %\cline{2-7}
        &  \textbf{FL-TOP}   & \textbf{0.82}  & 200 & \textbf{110.88} & \textbf{110.88} & N/A \\
        \cline{2-7}
        \cline{2-7}
        &  FL-BASIC-DP   &  0.59  & 200 & 22178.27 & 110.88 & 1\\
        \cline{2-7}
        %&  FL-BAS-2-DP  &  0.38 & 200  & 22178.27 & 110.88 & 1\\
        %\cline{2-7}
        %&  FL-BAS-3-DP  & 0.56   & 200 & 110.88 & 110.88 & 1\\
        %\cline{2-7}
        %&  FL-BAS-4-DP  &  0.33  & 200 & 110.88 & 110.88 & 1\\
        %\cline{2-7}
        &  FL-CS-DP  &  0.53  & 200 & 22178.27 & 110.88 & 1\\
        \cline{2-7}
        %&  FL-TOPK-BIS-DP  &  0.68  & 184 & 102.01 & 102.01 & 0.97\\
        %\cline{2-7}
        &  \textbf{FL-TOP-DP}   & \textbf{0.81} & 200 & \textbf{110.88}  & \textbf{110.88} & \textbf{1}\\
        \hline 
        \hline
        \multirow{8}{*}{$5\%$} &  FL-BASIC   &  0.78 & 196 & 21734.70 & 1086.73 & N/A  \\
        \cline{2-7}
        %&  FL-BAS-2  &  0.72  & 199 & 22067.38 & 1103.36 & N/A  \\
        %\cline{2-7}
        %&  FL-BAS-3  &  0.81  & 199 & 1103.36 & 1103.36 &N/A  \\
        %\cline{2-7}
        %&  FL-BAS-4  &  0.76  & 196 & 1086.73 & 1086.73 & N/A  \\
        %\cline{2-7}
        &  FL-CS  &  0.82  & 200 & 22178.27 & 1108.91 & N/A  \\
        \cline{2-7}
        %&  FL-TOPK-BIS  &  0.83  & 196 & 1086.73 & 1086.73 & N/A  \\
        %\cline{2-7}
        &  \textbf{FL-TOP}   & \textbf{0.84}  & 200 & \textbf{1108.91} & \textbf{1108.91} & N/A \\
        \cline{2-7}
        \cline{2-7}
        &  FL-BASIC-DP   &  0.76  & 195 & 21623.81 & 1081.18 & 0.99 \\
        \cline{2-7}
        %&  FL-BAS-2-DP  &  0.72  & 195 & 21623.81 & 1081.18 & 0.99 \\
        %\cline{2-7}
        %&  FL-BAS-3-DP  &  0.76  & 199 & 1103.36 & 1103.36 & 1 \\
        %\cline{2-7}
        %&  FL-BAS-4-DP  &  0.75 & 191 & 1059.01 & 1059.01 & 0.99\\
        %\cline{2-7}
        &  FL-CS-DP  &  0.78  & 160 & 17742.61 & 887.13 & 0.94 \\
        \cline{2-7}
        %&  FL-TOPK-BIS-DP  &  0.71  & 152 & 842.77 & 842.77 & 0.92\\
        %\cline{2-7}
        &  \textbf{FL-TOP-DP}   &  \textbf{0.81} & 152 & \textbf{842.77}  & \textbf{842.77} & \textbf{0.92}\\
        \hline 
        \hline
        \multirow{8}{*}{$10\%$} &  FL-BASIC   &  0.81  & 196 & 21734.70 & 2173.47 &N/A  \\
        \cline{2-7}
        %&  FL-BAS-2  &    0.78  & 199 & 22067.38 & 2206.74 &N/A  \\
        %\cline{2-7}
        %&  FL-BAS-3  &  0.82  & 195 & 2162.38 & 2162.38 & N/A  \\
        %\cline{2-7}
        %&  FL-BAS-4  & 0.79   & 200 & 2217.83 & 2217.83 & N/A  \\
        %\cline{2-7}
        &  FL-CS  &  0.85  & 182 & 20182.22 & 2018.22 & N/A  \\
        \cline{2-7}
        %&  FL-TOPK-BIS  &   0.84 & 196 & 2173.47 & 2173.47 & N/A  \\
        %\cline{2-7}
        &  \textbf{FL-TOP}   & \textbf{0.85}  & 199 & \textbf{2206.74} & \textbf{2206.74} &N/A \\
        \cline{2-7}
        \cline{2-7}
        &  FL-BASIC-DP   &  0.79  & 189 & 20958.46 & 2095.85 & 0.98\\
        \cline{2-7}
        %&  FL-BAS-2-DP  &  0.77  & 189 & 20958.46 & 2095.85 & 0.98\\
        %\cline{2-7}
        %&  FL-BAS-3-DP  &  0.79  & 183 & 2029.31 & 2029.31 & 0.97 \\
        %\cline{2-7}
        %&  FL-BAS-4-DP  & 0.78  & 195 & 2162.38 & 2162.38 & 0.99\\
        %\cline{2-7}
        &  FL-CS-DP  &  0.72  & 167 & 18518.85 & 1851.89 & 0.95\\
        \cline{2-7}
        %&  FL-TOPK-BIS-DP  &  0.69  & 138 & 1530.30 & 1530.30 & 0.90\\
        %\cline{2-7}
        &  \textbf{FL-TOP-DP}   &  \textbf{0.80} & 157 & \textbf{1740.99} & \textbf{1740.99} & \textbf{0.93}\\
        \hline 
        \hline
        \multirow{2}{*}{$100\%$} &  FL-STD  &  0.86  & 200 & 22178.27 & 22178.27 & N/A  \\
        \cline{2-7}
        &  FL-STD-DP  &  0.56 & 60 & 6653.48  & 6653.48 & 0.76 \\
        \hline
        
    \end{tabular}}
    \caption{Summary of results on Fashion-MNIST dataset.}
    \label{tab:description_results_Fashion_MNIST_reduced}
\vspace{-.3cm}
    \end{minipage}\hfill
    \begin{minipage}{.5\linewidth}
    \centering
    \scalebox{0.6}{
    \begin{tabular}{|c|c|c|c|c|c|c|c|}
        \hline
         \multirow{4}{*}{\emph{$r$}} & \multirow{4}{*}{Algorithms} & \multicolumn{6}{c|}{\emph{Performance}} \\
         \cline{3-8}
         %\hline
         & &   \multirow{3}{*}{\emph{Bal\_Acc}} & \multirow{3}{*}{\emph{AUROC}}  & \multirow{3}{*}{\emph{Round}} & \emph{Downstream} & \emph{Upstream} & \multirow{3}{*}{\emph{$\epsilon$}} \\
         & &                   &               &              &  \emph{Cost}                    &     \emph{Cost}                &                   \\
         &&                    &               &              &  (Kilobyte)                     &      (Kilobyte)                &     \\
         \hline

        \multirow{8}{*}{$0.1\%$} &  FL-BASIC  & 0.51 & 0.51 & 99 & 11829.42 & 11.82 & N/A \\
        \cline{2-8}
        %&  FL-BAS-2  & 0.50 & 0.47 & 100 & 11948.91 & 11.94 &N/A  \\
        %\cline{2-8}
        %&  FL-BAS-3 &  0.53  & 0.53 & 100 & 11.94 & 11.94 &N/A \\
        %\cline{2-8}
        %&  FL-BAS-4 &  0.50  & 0.53 & 94 & 11.23 & 11.23 &N/A \\
        %\cline{2-8}
        &  FL-CS &  0.53  & 0.55 & 100 & 11948.91 & 11.94 &N/A \\
        \cline{2-8}
        %&  FL-TOP-Bis &  0.69  & 0.76 & 100 & 11.94 & 11.94 &N/A \\
        %\cline{2-8}
        &  \textbf{FL-TOP} & \textbf{0.69}  & \textbf{0.76} & 68 & \textbf{8.12} & \textbf{8.12} &N/A \\
        \cline{2-8}
        \cline{2-8}
        &  FL-BASIC-DP  & 0.50 & 0.49 & 100 & 11948.91 & 11.94 & 1  \\
        \cline{2-8}
        %&  FL-BAS-2-DP  & 0.50 & 0.47 & 100 & 11948.91 & 11.94 & 1\\
        %\cline{2-8}
        %&  FL-BAS-3-DP &  0.55  & 0.56 & 100 & 11.94 & 11.94 & 1\\
        %\cline{2-8}
        %&  FL-BAS-4-DP &  0.51  & 0.52 & 100 & 11.94 & 11.94 & 1\\
        %\cline{2-8}
        &  FL-CS-DP &  0.51  & 0.51 & 99 & 11829.42 & 11.82 & 1\\
        \cline{2-8}
        %&  FL-TOP-Bis-DP & 0.68 & 0.75 & 89 & 10.63 & 10.63 & 0.98\\
        %\cline{2-8}
        &  \textbf{FL-TOP-DP} &  \textbf{0.69}  & \textbf{0.76} & 85 & \textbf{10.15} & \textbf{10.15} & \textbf{0.97} \\
        \hline 
        \hline
        \multirow{8}{*}{$5\%$} &  FL-BASIC  & 0.72 & 0.80 & 100 & 11948.91 & 597.45 &N/A\\
        \cline{2-8}
        %&  FL-BAS-2  & 0.68 & 0.75 & 100 & 11948.91 & 597.45 &N/A  \\
        %\cline{2-8}
        %&  FL-BAS-3 & 0.69 & 0.76 & 98 & 585.5 & 585.5 &N/A \\
        %\cline{2-8}
        %&  FL-BAS-4 &  0.66  & 0.72 & 100 & 597.45 & 597.45 &N/A \\
        %\cline{2-8}
        &  FL-CS &   0.73 & 0.81 & 98 & 11709.93 & 585.5 & N/A \\
        \cline{2-8}
        %&  FL-TOP-Bis &  0.72 & 0.79 & 100 & 597.45 & 597.45 &N/A \\
        %\cline{2-8}
        &  \textbf{FL-TOP} &  \textbf{0.72}  & \textbf{0.80} & 95 & \textbf{567.57} & \textbf{567.57} &N/A \\
        \cline{2-8}
        \cline{2-8}
        &  FL-BASIC-DP  & 0.69 & 0.76 & 100 & 11948.91 & 597.45 & 1 \\
        \cline{2-8}
        %&  FL-BAS-2-DP  & 0.68 & 0.75 & 98 & 11709.93 & 585.5 & 1 \\
        %\cline{2-8}
        %&  FL-BAS-3-DP &  0.65  & 0.71 & 90 & 537.70 & 537.70 & 0.98\\
        %\cline{2-8}
        %&  FL-BAS-4-DP &  0.67  & 0.74 & 98 & 585.5 & 585.5 & 1\\
        %\cline{2-8}
        &  FL-CS-DP &  0.69  & 0.76 & 100 & 11948.91 & 597.45 & 1\\
        \cline{2-8}
        %&  FL-TOP-Bis-DP &  0.67  & 0.74 & 38 & 227.03 & 227.03 & 0.84 \\
        %\cline{2-8}
        &  \textbf{FL-TOP-DP} & \textbf{0.68} & \textbf{0.75} & 23 & \textbf{137.41} & \textbf{137.41} & \textbf{0.79}\\
        \hline 
        \hline
        
        \multirow{8}{*}{$10\%$} &  FL-BASIC  & 0.74 & 0.81 & 100 & 11948.91 & 1194.89 &N/A \\
        \cline{2-8}
        %&  FL-BAS-2  & 0.70 & 0.77 & 100 & 11948.91 & 1194.89 &N/A  \\
        %\cline{2-8}
        %&  FL-BAS-3 &  0.72  & 0.80 & 98 & 1170.99 & 1170.99 &N/A \\
        %\cline{2-8}
        %&  FL-BAS-4 &  0.70  & 0.77 & 99 & 1182.94 & 1182.94 & N/A \\
        %\cline{2-8}
        &  FL-CS &  0.74  & 0.82 & 100 & 11948.91 & 1194.89 & N/A \\
        \cline{2-8}
        %&  FL-TOP-Bis &  0.72  & 0.80 & 100 & 1194.89 & 1194.89 &N/A \\
        %\cline{2-8}
        &  \textbf{FL-TOP} & \textbf{0.74}  & \textbf{0.82} & 90 & \textbf{1075.40} & \textbf{1075.40} &N/A \\
        \cline{2-8}
        \cline{2-8}
        &  FL-BASIC-DP  & 0.69 & 0.76 & 99 & 11829.42 & 1182.94 & 1 \\
        \cline{2-8}
        %&  FL-BAS-2-DP  & 0.69 & 0.76 & 95 & 11351.46 & 1135.15 & 0.99\\
        %\cline{2-8}
        %&  FL-BAS-3-DP &  0.69  & 0.76 & 95 & 1135.15 & 1135.15 & 0.99\\
        %\cline{2-8}
        %&  FL-BAS-4-DP &  0.69  & 0.76 & 100 & 1194.89 & 1194.89 & 1\\
        %\cline{2-8}
        &  FL-CS-DP &  0.69  & 0.76 & 96 & 11470.95 & 1147.09 & 0.99\\
        \cline{2-8}
        %&  FL-TOP-Bis-DP &  0.67  & 0.73 & 37 & 442.11 & 442.11 & 0.84\\
        %\cline{2-8}
        &  \textbf{FL-TOP-DP} &  \textbf{0.68}  & \textbf{0.74} & 23 & \textbf{274.82} & \textbf{274.82} & \textbf{0.79}\\
        \hline 
        \hline
        
        
        \multirow{2}{*}{$100\%$} &  FL-STD  & 0.74 & 0.82 & 99 & 11829.42 & 11829.42 &N/A \\
        \cline{2-8}
        &  FL-STD-DP   & 0.66 & 0.72 & 62 & 7408.32 & 7408.32 & 0.91 \\
        %\cline{2-9}
        %&  FL-STANDARD-DP + clip &    &  &  & & & & \\
        \hline
        
    \end{tabular}}
    \caption{Summary of results on Medical dataset.}
    \label{tab:description_results_Medical_data_reduced}
\vspace{-.3cm}
\end{minipage} 
\end{table*}

\subsection{Results}
\label{sec:results}


Figure~\ref{fig:distribution} displays the distribution of the \TOPK updated weights for FL-TOP and FL-STD at the end of the training. We select the weights when each scheme reached the best accuracy over 200 and best balanced accuracy\footnote{See Appendix~\ref{sec:metrics} for more details.} over 100 rounds for fashion-MNIST and the medical dataset, respectively. We choose the smallest compression ratio $r$ that leads to the best accuracy for the FL-TOP-DP scheme. Table~\ref{tab:description_results_Fashion_MNIST_reduced} shows that FL-TOP-DP reaches the best accuracy, 0.81, when $r=0.5$\% on fashion-MNIST and reaches the best accuracy, 0.69,  when $r=0.1$\% on the medical dataset. Both figures validate the intuition that by constraining the model to update only a small set $K$ of the total weights, these \TOPK become more important and reach larger values. This result is important when differential privacy is used as it leads to larger value-to-noise level and therefore better performance. 


Table~\ref{tab:description_results_Fashion_MNIST_reduced} represents the best accuracy over 200 rounds for each scheme on the Fashion-MNIST dataset. $\mathit{Round}$ corresponds to the round when the best accuracy is reached and $\mathit{Cost}$ is the average bandwidth consumption calculated as: $r \times n \times 32 \times \mathit{Round} \times C$, where 32 is the number of bits necessary to represent a float value, $n$ is the uncompressed model size, $r=\frac{|\mathbb{T}|}{n}$, $|\mathbb{T}|$ is the compressed model size, $C$ is the sampling probability of a client, and $\mathit{Round}$ is the round when we get the the best accuracy.

Table~\ref{tab:description_results_Medical_data_reduced} represents the best balanced accuracy over 100 rounds for each scheme on the Medical dataset. $AUROC$ (area under the receiver operating characteristic curve - see Appendix~\ref{sec:metrics}) corresponds to the $AUROC$ value when the best balanced accuracy is reached.

% non private schemes
These figures show that the proposed non-private scheme FL-TOP has similar accuracy than the standard scheme FL-STD but reduces the bandwidth cost significantly.
For example, with the Fashion-MNIST dataset, the FL-TOP accuracy reaches 0.85  when the compression ratio $r=10\%$. In comparison, the standard FL-STD scheme reaches an accuracy of 0.86\% but consumes 10 times more bandwidth. Furthermore, although FL-CS reaches the same accuracy than FL-TOP and consumes slightly less bandwidth upstream (9\% less), its required downstream bandwidth is about 10 times larger (See Table~\ref{tab:description_results_Fashion_MNIST_reduced} for more details).
The results on the medical dataset are quite similar. In fact, FL-TOP achieves its best balanced accuracy (0.74) and AUROC (0.82) when $r=10\%$ while the FL-STD scheme obtains similar performance but required about 11 times more upsteam and downstream bandwidth cost. FL-CS achieves similarly accuracy at $r=10\%$ as FL-TOP but its downstream required bandwidth is about 11 times larger (see Table~\ref{tab:description_results_Medical_data_reduced} for more details).

% private schemes

The results also show that not only our privacy-preserving solution FL-TOP-DP provides strong privacy guarantee (with $\epsilon$ values smaller than 1) but that it outperforms the other schemes in term of accuracy and bandwidth, for both datasets. 
For example, with Fashion-MNIST, our scheme achieves an accuracy of $0.81$ when  $r=0.5\%$ while the baseline scheme, FL-BASIC-DP, achieves an accuracy of $0.79$ when $r=10\%$ and requires 189 times more downstream bandwidth and 18 times more upstream bandwidth.  With the medical dataset,  FL-TOP-DP reaches the best balanced accuracy 0.69 and best AUROC $0.76$ for a compression ratio of  $r=0.1\%$ while FL-BASIC-DP an FL-CS-DP achieves the same performance at $r=5\%$.  Note that FL-STD-DP performs very poorly as noise has to be added to the all weights of the model and the sensitivity is large (see Table~\ref{tab:description_results_Medical_data_reduced}).

%Our private compressed solution and baselines perform better than FL-STD, due to the fact that the compression reduces the sensitivity S and then the required amount of noise for a DP guarantee as suggested in \cite{our_cs}.  

%Also, FL-TOP and FL-TOP-DP converge to better accuracy compared with other baselines for the same compression ratio. Indeed, baselines are less accurate than our solutions (FL-TOP and private extension) for the same compression ratio. It is due to the fact that we are updating weights which requires the most updates due to a wrong initialization for example. However, selecting those update is not enough and it is not the only condition to reach such good accuracy with only small proportion of parameters. Indeed, the baseline FL-TOP-BIS and its private extension are less accurate than our solutions FL-TOP and FL-TOP-DP for the same compression ratio although they update the same proportion of weights. Hence, the applied constraint seems to play an important role. Note that this difference between our solution and the baselines tends to decrease with the increase of the compression ratio r. This can be explained by the fact that more we increase the ratio r and more we have the chance to select the same weights as FL-TOP and FL-TOP-DP.

%For Fashion-MNIST, we notice a decrease of the accuracy for each of FL-TOP-DP, FL-TOP-BIS-DP and FL-CS-DP from r=5\% to r=10\%. Indeed, as suggested in \cite{our_cs}, it may be due to the increase of the sensitivity S and then the increase of the noise.  

%Finally, increasing the compression ratio $r$ for further larger values than $r=10\%$ will not improve the results of any scheme whatever the considered datasets.

\section{Related work}
\label{sec:related_work}
%CS technique was used for two purpose in general: compression or denoising. It was also used for two types of data: signals or images. 





\noindent \textbf{Privacy of Federated Learning:}
%$$ In \cite{Property_inference}, the adversary's goal is to infer whether records with a specific property are included in the training dataset of the other participants (called batch property inference). The adversary is supposed to have access to the aggregated model update of honest participants.
%In \cite{NasrSH19}, the proposed attack infers if a specific person is included in the training dataset of the participants (aka, Membership inference). The adversary extracts the some features from every snapshot of the common model which are then used to train a membership inference model (a CNN).
The concept of Client-based Differential Privacy has been introduced in \cite{Client-DP-McMahan} and \cite{Client-DP-ETH-Zurich}, where the goal is to hide any information that is specific to a single client's training data. These algorithms noise the contribution of a single client instead of a single record in the client's dataset. The noise is added by the server, hence, unlike our solution, these works assume that the server is trusted. 

Recently, \cite{Liu_2020} also proposed to add noise only to the update of the \TOPK model parameters a la local-DP. In local-DP, each client adds larger noise that what is necessary to guarantee DP for the \emph{aggregated} model update without using secure aggregation. Therefore, the common model is less accurate than with our scheme. In addition,  \cite{Liu_2020} uses two epsilon budgets; one for selecting \TOPK parameters per client, and the second for perturbing these selected \TOPK parameters. By contrast, we select the \TOPK parameters via public data without sacrificing any privacy budget. Finally, their solution is also less bandwidth efficient than ours: as the \TOPK parameters differ for each client and at each round, the client cannot send only the \TOPK parameters values because the server will not be able to identify which value corresponds to which \TOPK parameter. For this reason, the client has to send a sparse vector with only \TOPK perturbed values and all remaining parameters set to 0. Therefore, the quantization of the non-\TOPK parameters is performed only during the upstream (from client to server) without compressing any downstream traffic. As opposed to this, in our solution, only the weights/updates of the \TOPK parameters are transferred downstream/upstream.

Recently, \cite{our_cs} proposed to use Compressive sensing (CS) in the context of federated learning in order to compress model updates meanwhile providing  client-level DP. Assuming that the model update is already sparse in the time domain, the noise is added to its largest Fourier coefficients in a distributed manner, and the noisy aggregate is reconstructed with standard optimization techniques. 
Likewise our solution, this work also uses secure aggregation by exploiting the linearity of CS. However, the reconstruction process can be slow for large models, and therefore our solution is more scalable. Moreover, it can only compress the upstream traffic.

\smallskip

\noindent \textbf{Bandwidth Optimization in Federated Learning:}
Different quantization methods have been proposed to save the bandwidth and reduce the communication costs in federated learning. They can be divided into two main groups: unbiased and biased methods. The unbiased approximation techniques use probabilistic quantization schemes to compress the stochastic gradient and attempt to approximate the true gradient value as much as possible \citep{QSGD, TERNGRAD, ATOMO, Quant_Fed}. 
However, biased approximations of the stochastic gradient can still guarantee convergence both in theory and practice \citep{SIGNSGD, LinHM0D18, SeideFDLY14}. %In signSGD \cite{SIGNSGD}, all the clients calculate the stochastic gradient based on a single mini-batch and then send the sign vector of this gradient to the server. The server calculates the aggregated sign vector by taking the median (majority vote) and sends the signs of the aggregated signs back to each client.
SignSGD \cite{SIGNSGD} a quantization protocol allows to compress during downstream and upstream traffic but requires the use of all the clients at each round which is not realistic in the context of federated settings because each client is available only during few rounds \cite{kairouz2019advances}.

A different line of works exploit the sparsity of model updates to compress them.
%The authors in \cite{mamaghanian2011compressed} use CS for low-complexity energy-efficient ECG compression. 
%Although compressed sensing was primarily designed for compression  \cite{candes2006robust,donoho2006compressed}, it was extended for denoising as in \cite{metzler2016denoising,tavakoli2012image} where compressive sensing is used for the purpose of denoising. 
%In \cite{yu2014compressed}, compressed sensing based denoising and certain artificial intelligence are combined to improve the prediction performance.
%CS was also used with DP in \cite{DP_CS}. The authors show that the amount of noise is reduced from $O(\sqrt{n})$ to $O(\log(n))$, when the noise is added on the sampled coefficients instead of the original database. 
 \cite{mohamedamiri,mohamedamiri2}  proposed to use a compressive sensing for federated learning in order to compress model updates without privacy guarantees. However, they assume that all clients participate in each round (as they maintain an error accumulation vector at each client due to the compression scheme), but as discussed in \cite{kairouz2019advances} this assumption is not always realistic. %Recently in \cite{jeon2020compressive} another compressive sensing algorithm was proposed for federated learning  for the denoising purpose (instead of the compression), where the added noise is due to the network transmission.  
Sketching was adapted to federated learning for the purpose of compressing model updates in \cite{ivkin2019communication} and \cite{rothchild2020fetchsgd}. The authors proposed to use Count-Sketch from \cite{charikar2002finding} to retrieve the largest weights in the update vector on the server side. 
%After that, the server uses two additional communication rounds to inform the clients about what gradient values they need to send back to the server. The server then takes the average of the received gradients and zeros-out the others before updating the model. 
%In \cite{ivkin2019communication}, the error due to the compression is maintained at each client, and the participation of all clients are required in each round which, as per \cite{kairouz2019advances}, is not practical to federated learning. 
%In \cite{rothchild2020fetchsgd}, the aforementioned scheme is improved further by directly retrieving the most updated gradient values without asking for their positions in the update vector. This  makes the scheme more efficient as it needs fewer communication rounds. %remove the two additional round used to send the coefficients of the most updated weights from the server to the clients and the values of those weights from the clients to the server. 
%Similarly to our approach, the error vector is also maintained on the server side instead of the client side, which is clearly a better fit for federated learning.  
However, it is unclear how these works can be extended with privacy guarantees. Moreover, unlike our technique, they do not compress downstream traffic.

Constraining the weights to have a specific distribution has already been studied. In \cite{dsd}, for example, the authors use pruning techniques to create a sparse model at the end of the training. After each SGD iteration, the authors zero-out all the weights with an absolute value smaller than a threshold. Iterating the process leads to a sparse model with only some absolute weight values larger than 0. Similarly, \cite{Joshua_binary} aim to create a model with binary weights such that at the end of the training all the weights are close to $1$ or $-1$. After each SGD update, the authors take the sign of the weights before the next update. After some iterations, the weight values become close to the interval limits $-1$ and $1$.

In \cite{lottery_ticket}, a new hypothesis claims that there exists a sub-network which, if trained separately, can achieve similar performance as the complete network model which contains that. To find such a sub-network, one has to follow a simple iterative procedure: train the complete network, prune the smallest weights, and then reinitialize the remaining weights to their original values. These steps are repeated iteratively. This approach was extended to federated learning in \cite{li2020lotteryfl}.


%Based on the two papers above, we have decided to design a solution which aims to carry all the energy of the updates only in few parameters such that adding the noise to these values leads to reduce the impact of the noise needed for a differential private guarantee. In the traditional case, the noise is added to the whole vector which will negatively impact the weights' update with values close to 0, resulting on a random update. Also, as mentioned in \cite{our_cs}, we are also expecting that the compression will boost differential privacy by reducing the sensitivity $S$. Indeed, the standard deviation of the Gaussian distribution is equal to $S$ multiplied by $\sigma$, therefore, reducing $S$ will also reduces the noise needed by DP. 


%One major challenge in system design is to reconstruct local gradient vectors accurately at the central server, which are computed-and-sent from the wireless devices. To overcome this challenge, we first establish a transmission strategy to construct sparse transmitted signals from the local gradient vectors at the devices. We then propose a compressive sensing algorithm enabling the server to iteratively find the linear minimum-mean-square-error (LMMSE) estimate of the transmitted signal by exploiting its sparsity.




\section{Conclusion}


This paper presents a novel privacy-preserving federated learning scheme that reduces bandwidth, latency and
therefore power consumption.
The proposed scheme is based on Differential Privacy and therefore provides theoretical privacy guarantees. Furthermore, it optimizes
the model accuracy by constraining the model learning phase on few selected weights. We show experimentally, using a public 
dataset called Fashion-MNIST and a real world medical dataset of 1.2 millions of US hospital patients, that it reduces the 
upstream and downstream bandwidth by up to 99.9\% compared to standard federated learning, making it practical
for constrained and mobile devices.




%\begin{contributions} % will be removed in pdf for initial submission,
                      % so you can already fill it to test with the
                      % ‘accepted’ class option
%    Briefly list author contributions.
%    This is a nice way of making clear who did what and to give proper credit.

%    H.~Q.~Bovik conceived the idea and wrote the paper.
%    Coauthor One created the code.
%    Coauthor Two created the figures.
%\end{contributions}

%\begin{acknowledgements} % will be removed in pdf for initial submission,
                         % so you can already fill it to test with the
                         % ‘accepted’ class option
%    Briefly acknowledge people and organizations here.

%    \emph{All} acknowledgements go in this section.
%\end{acknowledgements}

%\newpage

\clearpage

\bibliography{references}

\clearpage
%\newpage
\appendix


\section{Medical data: Data pre-processing \& experimental setup details}
\label{sec:app}



This section describes our medical dataset and the experimental setting which is used to evaluate the accuracy and the privacy of our proposals.


\subsection{Medical Dataset}

\label{sec:medical_dataset_desc}

\subsubsection{The In-hospital Mortality Prediction Scenario}

The ability to accurately predict the risks in the patient's perspectives of evolution is a crucial prerequisite in order to adapt the care that certain patients receive \citep{Papier_Amela}.

We consider the scenario where several hospitals are collaborating to train models for in-hospital mortality prediction using
our Federated Learning schemes. 
This well-studied real-world problem consists in trying to precisely identify the patients who are at risk of dying from complications during their hospital stay \citep{Avati2018,rajkomar-npj18,Papier_Amela}. As commonly found in the literature \citep{Papier_Amela}, for such predictions, we focus on hospital admissions of adults hospitalized for at least 3 days, excluding elective admissions. 


%The main goal of this experimental section is to evaluate the performance of FL-SIGN-DP with different levels of privacy (i.e. different $\epsilon$ values) and compare it with the performance of the  following learning protocols:
%\begin{itemize}
%    \item \emph{(Non-federated) Centralized training}: The training data of all hospitals are merged %and a single model is trained on this merged data without any privacy guarantee.
%    \item \emph{FL-STANDARD} is described in Section \ref{FL-STANDARD}.
%    \item \emph{FL-SIGN} is described in  Section \ref{sec:fl-sign-desc}.
%    \item \emph{FL-STANDARD-DP}  is specified in Alg.~\ref{alg:basic_rec_fed_learn}.
%    It has the same privacy guarantee as FL-SIGN-DP\footnote{the privacy analysis in Section %\ref{sec:priv_anal} also applies to FL-STANDARD-DP} but is less bandwith efficient; its communication %overhead is identical to that of FL-STANDARD.
%    Specifically, unlike in FL-SIGN-DP, each client sends the original (non-quantized) update vector %$\mbf{s}_{t}^{k} = \mbf{w}_t^k - \mbf{w}_{t-1}^k$ to the server. Then, the server computes the model %update as $\mbf{w}_{t} = \mbf{w}_{t-1} + \frac{1}{\mathbb{|K|}}\left(\sum_{k}  %\mbf{s}_{t}^{k}\right)$. Apart from these differences, FL-STANDARD-DP is identical to FL-SIGN-DP.  
%\end{itemize}

\subsubsection{The Premier Healthcare Database}

We used EHR data from the Premier healthcare database\footnote{\href{https://www.premierinc.com/newsroom/education/premier-healthcare-database-whitepaper}{https://www.premierinc.com/newsroom/education/premier-healthcare-database-whitepaper}} which is one of the largest clinical databases in the United States, collecting information from millions of patients over a period of 12 months from 415 hospitals in the USA \citep{Papier_Amela}. These hospitals are supposedly representative of the United States hospital experience \citep{Papier_Amela}. Each hospital in the database provides discharge files that are dated records of all billable items (including therapeutic and diagnostic procedures, medication, and laboratory usage) which are all linked to a given patient's admission \citep{Papier_Amela,Makadia}. 

The initial snapshot of the database used in our work (before pre-processing step) comprises the EHR data of 1,271,733 hospital admissions.
Electronic Health Record (EHR) is a digital version of a patient’s paper chart readily available in hospitals. For developing supervised learning and specifically deep learning models, we focus on a specific set of features from EHR data. The features of interest that capture the patients information are summarized in Table~\ref{tab:data_description}. There is a total of 24,428 features per patient, mainly due to the variety of drugs possibly served. As in \cite{Avati2018}, we also removed all the features which appear on less than 100 patients' records, hence, the number of features was reduced to 7,280 features. 

The Medication regimen complexity index (MRCI) \citep{MRCI} is an aggregate score computed from a total of 65 items, whose purpose is to indicate the complexity of the patient's situation. The minimum MRCI score for a patient is 1.5, which represents a single tablet or capsule taken once a day as needed (single medication). However the maximum is not defined since the number of medications increases the score \citep{MRCI}. In our case, after statistical analysis of our dataset, we consider the MRCI score as ranging from 2 to 60.




Most real datasets like ours are generally imbalanced with a skewed distribution between the classes. In our case, the positive cases (patients who die during their hospital stay) represent only 3\% of all patients. Table \ref{tab:class_prop} gives more details about this distribution after the pre-processing step which is discussed in \ref{preprocessing}. To deal with this well-known problem, we have decided to use downsampling technique \citep{more2016survey,he2009learning}, a standard solution used for this purpose, as used in \cite{our_cs}.


\subsection{Preprocessing} 

\label{preprocessing}

\begin{enumerate}
    \item \textbf{Features normalization}: we extract from the dataset the values of each feature represented in Table \ref{tab:data_description}. For gender, we use one-hot encoding: Male, Female and Unknown. Similarly, for admission type we use 4 features: Emergency, Urgent, Trauma Center, and Unknown \footnote{\url{https://www.resdac.org/cms-data/variables/claim-inpatient-admission-type-code-ffs}}. For drugs, we extract 24,419 features which correspond to the different drugs (name and dosage). A given patient receives only a few of the possible drugs served, resulting in a very sparse patient's record. We use a MinMax normalization for age and MRCI in order to rescale the values of these features between 0 and 1 (using MinMaxScaler class of scikit-learn\footnote{\url{https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html}}). The labels that we consider are boolean: true means that the patient died during his hospital stay while false means she survived. 

    
    \item \textbf{Patients filtering}: We consider patient and drug information of the first day at the hospital so that we can make predictions 24 hours after admission (as commonly found in the literature \citep{rajkomar-npj18,Papier_Amela}). We filter out the pregnant and new-born patients because the medication types and admission services are not the same for theses two categories of patients. Our model prediction is built without patients' historical medical data. This has the advantage to require minimum patient's information and to work for new patients.
    
    \item \textbf{Hospitals filtering}: The dataset contains 415 hospitals for a total size of 1,271,733 records. We split randomly the dataset into disjoint training and testing data (80\% and 20\% respectively).  The final dataset for testing contains 254,347 patients, with 7,882 deceased patients and 246,465 non-deceased patients (see Table~\ref{tab:class_prop}).
    
    Using Client-Level differential privacy requires to add more noise than Record-Level differential privacy, because the privacy purposes are not the same as detailled in Section~\ref{sec:backg}. To reduce the noise (when $\epsilon$ is fixed) and then improve the utility, we have to reduce the number of iterations or to reduce the sampling probability which are the parameters used to compute $\epsilon$. We therefore have two options to reduce the sampling probability:
    \begin{itemize}
        \item[-] Reducing the number of clients selected at each round $|\mathbb{K}|$. However this option also decreases the amount of data, and hence have a negative impact on the utility. We therefore preferred to use the next option.
        \item[-] Increasing the total number of clients $N$: we created more hospitals by splitting randomly the training data over 5010 "virtual" hospitals. We also, took care to have at least one in-hospital dead patient per hospital. Each hospital contains 203 patients. 356 patients are used as public dataset to define the \TOPK updated weights. We created 5010 hospitals in order to have approximately the same number of patients per hospital, each of them with some in-hospital dead patients. 
        
        In practise, Client-Level differential privacy is more adapted to an environment with a large set of clients as explained in \cite{Client-DP-McMahan,Client-DP-ETH-Zurich}.
    \end{itemize}

\end{enumerate}

\subsection{Imbalanced data}


The dataset of each hospital is imbalanced because the proportion of patients that leave the hospital alive is, fortunately, much larger than in-hospital dead patients. To deal with this well-known problem, we have decided to use downsampling technique \citep{more2016survey,he2009learning}, a standard solution used for this purpose. \footnote{We have also tested weighted loss function and oversampling techniques. But, we noticed experimentally that downsampling technique outperforms the other techniques for all the schemes.} 




%\subsubsection{Selection of hyperparameters}
%\todo{Remove?}
%The selection of hyperparameters in FL-SIGN-DP and FL-STANDARD-DP, such as batch size $|\mathbb{B}|$, scaling factor $\gamma$,  or sensitivity $S$, should also be differentially private. In order to compute them, one option is to use public datasets that have similar distribution as the clients' private training data. Another option is to use more sophisticated methods like the one exposed in Appendix D of \cite{Abadi}. 


%The hyperparameters in Table~\ref{tab:fl_sign_param_privacy} are tuned, and we select those which provide the best results for each scheme.


\subsection{Performance Metrics}

We use the following metrics:
\begin{itemize}
    \label{sec:metrics}
    \item \emph{Balanced accuracy}  \citep{Balanced_acc_1,Balanced_acc_2} is computed as  $1/2 \cdot (\frac{\TP}{\Pos}+\frac{\TN}{\Neg}) = \frac{\TPR+\TNR}{2}$ and is mainly used with imbalanced data. \emph{True Positive Rate} ($\TPR$) and \emph{True Negative Rate} ($\TNR$):
    $\TPR=\frac{\TP}{\Pos}$ and $\TNR=\frac{\TN}{\Neg}$, where $\Pos$ and $\Neg$ are the number of positive and negative instances, respectively, and $\TP$ and $\TN$ are the number of true positive and true negative instances.
    We note that traditional (``non-balanced'') accuracy metrics such as $\frac{\TP+\TN}{\Pos+\Neg}$ can be misleading for very imbalanced data \cite{akosa2017predictive}: in our dataset, the minority class has only 3\% of all the training samples (see Table~\ref{tab:class_prop}), which means that a biased (and totally useless) model always predicting the majority class would have a (non-balanced) accuracy of  $97\%$. 
    \item The \emph{area under the ROC curve} (\AUC) is also a frequently used accuracy metric. The ROC curve is calculated by varying the prediction threshold from 1 to 0, when \TPR and \FPR are calculated at each threshold. The area under this curve is then used to measure the quality of the predictions. A random guess has an $\AUC$ value of 0.5, whereas a perfect prediction has the largest $\AUC$ value of 1.  
\end{itemize}

\subsection{Evaluation Method.}
First, we split randomly the dataset of each hospital into disjoint training and testing data (80\% and 20\% respectively).
An entire federated run is executed with this split, and all the metrics are evaluated in every round on the union of all clients' testing data. 
All metric values of the round with the best balanced metric are recorded.




\subsubsection{Model architecture}

As in \cite{Avati2018,our_cs}, we use a fully connected neural network model with the following architecture: two hidden layers of 200 units, which use a Relu activation function followed by an output layer of 1 unit with sigmoid activation function and a binary cross entropy loss function. This results in 1,496,601 parameters in total. We tune $\eta$ from 0.01 to 0.5 with an increment value of 0.005. As in \cite{our_cs}, we fix the momentum parameter $\rho$ to 0.9 and the global learning rate $\eta_{G}$ to 1.0. The number of chunks is set to $P =100$ (refers to \cite{our_cs} for details). The hyperparameters used by each of the considered schemes are summarized in Table~\ref{tab:hyperparameters}.


%After some tests, we noticed that the hyperparameters used in \cite{our_cs} return the best results on FL-STD and FL-CS. For this reason, we used exactly the same values except for $\Tgd$ which was increased in our case to 40.

%The sensitivity $S$ is selected during an initialization round for each scheme by taking the median value over $N$ $L_2$-norm values. We also noticed that the sensitivity of FL-CS-DP, FL-RND and FL-FREQ are nearly equivalent for the same level of compression. For this reason, the same sensitivity value is used for each compressed scheme and for the same compression ratio. Table~\ref{tab:S_table_fashion_mnist} and Table~\ref{tab:S_table_medical} show the selected clipping threshold (i.e., sensitivity $S$) for each dataset and according to each compression ratio. 









\section{Fashion-mnist data: Data pre-processing \& experimental setup details}
\subsection{Data Description}
\label{sec:fashion_mnist_desc}
Fashion-MNIST database of fashion articles consists of 60,000 28x28 grayscale images of 10 fashion categories, along with a test set of 10,000 images \cite{Fashion-MNIST} \cite{KERAS_datasets}.

\subsection{Public data description}
\label{sec:mnist_desc}
The MNIST database of handwritten digits. It consists of 28 x 28 grayscale images of digit items and has 10 output classes. The training set contains 60,000 data samples while the test/validation set has 10,000 samples \cite{MNIST} \cite{KERAS_datasets}.

%\subsection{Data pre-processing \& experimental setup} %\medskip

\subsection{Preprocessing}
The pixel of each image is an unsigned integer in the range between 0 and 255. We rescale them to the range [0,1] instead. \medskip

\subsection{Model architecture}
For Fashion-MNIST, we use a model \cite{FedAVG,our_cs} with the following architecture: a convolutional neural network (CNN) with two 5x5 convolution layers (the first with 32 filters, the second with 64, each followed with 2x2 max pooling), a fully connected layer with 512 units and ReLu activation, and a final softmax output layer. This results in 1,663,370 parameters in total. We tune $\eta$ from 0.01 to 0.5 with an increment value of 0.005. As in \cite{our_cs}, we fix the momentum parameter $\rho$ to 0.9 and the global learning rate $\eta_{G}$ to 0.35. Same for the number of chunks used $P =200$ (refers to \cite{our_cs} for more details).  The hyperparameters used by each of the considered schemes are summarized in Table~\ref{tab:hyperparameters}.

%After some tests, we noticed that the hyperparameters used in \cite{our_cs} return the best results on FL-STD and FL-CS. For this reason, we used exactly the same values.

\section{Computational environment}

Our experiments were performed on a server running Ubuntu 18.04 LTS equipped with a Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz, 192GB RAM, and two NVIDIA Quadro P5000 GPU card of 16 Go each. We use Keras 2.2.0 \cite{KERAS} with a TensorFlow  backend 1.12.0 \cite{TensorFlow} and Numpy 1.14.3 \cite{Numpy} to implement our models and experiments. We use  Python 3.6.5 and our code runs on a Docker container to simplify reproducibility. 

\section{Further experiments}
\label{sec:furthmore_experiments}
The goal of this section is to compare the performance of our proposed schemes FL-TOP and FL-TOP-DP with several baselines  according to different compression ratios. 
More specifically, we consider the following additional baselines:
\begin{itemize}
    \item FL-BAS-2: As in FL-BASIC, only a randomly selected set of parameters are selected and sent to the server at each round. Importantly, none of the parameters are reinitialized during training.
    \item FL-BAS-3: This baseline is the same as FL-BASIC, except that the set of random parameters is fixed over all the rounds.
    \item FL-BAS-4: Same as FL-BAS-2, except that the set of random parameters is the same over all the rounds.
    \item FL-TOP-BIS: Similarly to FL-TOP, it uses the same \TOPK parameters over the whole training. The only difference is that the $n-K$ non-\TOPK parameters are not re-initialized after each SGD iteration. As in FL-TOP, after $\Tgd$ SGD iterations, clients send the update of the \TOPK parameters to the server.
\end{itemize}

Note that all compression operators in the new baselines are still linear (just like FL-TOP-DP), and hence they can also be used with secure aggregation. Their private extensions (i.e., FL-BAS-2-DP, FL-BAS-3-DP, FL-BAS-4-DP and FL-TOP-BIS-DP) also clip and then noise the compressed updates as in FL-TOP-DP. The selection of sensitivity $S$ happens similarly to FL-TOP-DP and FL-BASIC-DP using the public data as described in Section \ref{sec:exp}.


%To same procedure used with FL-TOP-K-DP (see Section~\ref{sec:exp}) is used to select the sensitivity of FL-TOP-BIS-DP, FL-BAS-3-DP and FL-BAS-4-DP except that we use for each one the according learning algorithm.

%Same for FL-BAS-2-DP which uses the same procedure (see Section~\ref{sec:exp}) used with FL-BAS-1-DP is reused here. Indeed, as with FL-BAS-1-DP we select the sensitivity S as the median over 100 $L_2$-norm. The only difference remains on the learning algorithm.   

\subsection{Results}

Table~\ref{tab:description_results_Fashion_MNIST} shows the best accuracy over 200 rounds for each scheme on the Fashion-MNIST dataset. $\mathit{Round}$ corresponds to the round when the best accuracy is achieved and $\mathit{Cost}$ is the average bandwidth consumption calculated as: $r \times n \times 32 \times \mathit{Round} \times C$, where 32 is the number of bits necessary to represent a float value, $n$ is the uncompressed model size, $r=\frac{|\mathbb{T}|}{n}$, $|\mathbb{T}|$ is the compressed model size, $C$ is the sampling probability of a client, and $\mathit{Round}$ is the round when we get the the best accuracy.

Table~\ref{tab:description_results_Medical_data_part_1} and Table~\ref{tab:description_results_Medical_data_part_2} display the best balanced accuracy over 100 rounds for each scheme on the Medical dataset. AUROC corresponds to the AUROC value when the best balanced accuracy is reached, $\mathit{Round}$ is the round when we get the best balanced accuracy, and finally, Cost is the average bandwidth consumption calculated as for the Fashion-MNIST dataset described above.


On the medical data (see Table~\ref{tab:description_results_Medical_data_part_1} and \ref{tab:description_results_Medical_data_part_2}), our schemes FL-TOP and FL-TOP-DP reach 0.64 of balanced accuracy and 0.70 of AUROC for $r=0.01\%$, while FL-TOP-Bis and FL-TOP-Bis-DP, which are the best baselines, have 8\% less of balanced accuracy and 10\% less of AUROC for identical compression ratios. Furthermore, for larger compression ratios, FL-TOP and FL-TOP-DP have similar results to that of FL-TOP-Bis and FL-TOP-Bis-DP. However, above $r=1\%$, FL-TOP outperforms FL-TOP-BIS. The same holds for FL-TOP-DP, which outperforms FL-TOP-Bis-DP when $r$ is more than $0.05\%$.  

On Fashion-MNIST, FL-TOP performs better than other schemes below $r=10\%$. For $r=10\%$,  FL-CS and FL-TOP have the same accuracy of 0.85. FL-TOP-DP is the best DP scheme independently of the compression ratio $r$. 

Notice the the larger the compression ratio $r$ is the smaller the performance gap between our schemes and the baselines FL-BAS-1, FL-BAS-3. The same holds for their DP counterparts. This is mainly due to the fact that the larger $r$ is the more likely that all schemes update the same \TOPK parameters. 

FL-CS and FL-CS-DP fail to improve their model accuracy when $r=0.01\%$ on the medical dataset. The same holds for FL-BAS-3-DP when $r=0.1\%$ on the Fashion-MNIST dataset.

On Fashion-MNIST, there is a decrease of accuracy for each of FL-TOP-DP, FL-TOP-BIS-DP and FL-CS-DP from $r=5\%$ to $r=10\%$. Indeed, as suggested in \cite{our_cs}, it may be due to the increase of sensitivity $S$ which will also increase the noise and therefore its negative impact on convergence.  

\begin{table*}[!h]
	\caption{Descriptions of features} 
	\label{tab:data_description}
	\scalebox{0.95}{
	\begin{tabular}{|r|l|}
		\hline
		     \emph{Features}    			            & \emph{Descriptions} 		                 \\
		\hline
		Age	                & 	 Value in the range of 15 and 89	  \\
		\hline
		Gender               &   Male, Female or Unknown  \\
		\hline
		Admission type     &   Emergency, Urgent, Trauma Center: visits to a trauma center/hospital or Unknown \\ %\tablefootnote{\url{https://www.resdac.org/cms-data/variables/claim-inpatient-admission-type-code-ffs}}  \\ 
		\hline
		MRCI               &   Medication regimen complexity index score (ranging from 2 to 60)   \\
		\hline
		\multirow{4}{*}{Drugs and ICD9 codes} &   Drugs given to the patient on the $1^{st}$ day of hospitalization. The ICD9 codes are composed \\ & of procedures  and diagnosis codes,  the first gives details about the medical procedures performed \\ & on the patient and the second about the doctor's  diagnosis of the patient.  There is a total of 24,419 \\ & possible drugs and ICD9 codes \citep{ICD9}.  \\
		\hline
	\end{tabular}}
\end{table*}

\begin{table}[h!]
	\caption{Number of instances for our case study. The Medical dataset contains in total 1,271,733 records.}
	\label{tab:class_prop}
	\centering
	\scalebox{0.8}{
	\begin{tabular}{ccccc}
		\hline
		Data & Positive cases         			                & Negative cases		                            & Ratio     & Total   \\
		\hline
		Train & 	      32,106  	                & 		     985,280                           &      3.16\%     &  1,017,386  \\
		\hline
		Test & 	        7,882	                & 		        246,465                        & 3.10\%          &  254,347 \\
		\hline
	\end{tabular}}
\end{table}


\begin{algorithm}[h]
\small
		\caption{FL-STD: Federated Learning \label{alg:fed_learn}}
	\DontPrintSemicolon
	{\bf Server:}\;
	\Indp Initialize common model $w_0$\;
	\For {$t=1$ \KwTo $\Tcl$}
	{
	    Select $\mathbb{K}$ clients uniformly at random \;
		\For {\textrm{each} client $k$ \textrm{in} $\mathbb{K}$}
		{	
			$\Delta \mbf{w}_t^k = \mathbf{Client}_k(\mbf{w}_{t-1})$\;
		}
		$\mbf{w}_{t} = \mbf{w}_{t-1} + \sum_{k} \frac{|D_k|}{\sum_j |D_j|} \Delta \mbf{w}_{t}^{k}$\;
	}
	\KwOut{Global model $\mbf{w}_t$}\;
	\Indm {\bf $\mathbf{Client}_{k}(\mbf{w}_{t-1}^k)$:}\;
	\Indp
	$\mbf{w}_{t}^k = \mathbf{SGD}(D_k, \mbf{w}_{t-1}^k, \Tgd)$\;
	\KwOut{Model update $(\mbf{w}_{t}^k- \mbf{w}_{t-1}^k)$} 
\end{algorithm}



\begin{algorithm}[h]
\small
	\caption{Stochastic Gradient Descent \label{alg:sgd}}
	\DontPrintSemicolon
	\KwIn{$D$ : training data, $\Tgd$ : local epochs, $\mathbf{w}$ : weights}  
    \For {$t=1$ \KwTo $\Tgd$}
	{
	    Select batch $\mathbb{B}$ from $D$ randomly\;
	    $\mbf{w} = \mbf{w} - \eta \nabla f(\mathbb{B}; \mbf{w})$\;
	}
    \KwOut{Model $\mbf{w}$} 
\end{algorithm}

\begin{algorithm}[h]
\small
		\caption{FL-STD-DP: Federated Learning with Client Privacy \label{alg:fl_std_dp}}
	\DontPrintSemicolon
	{\bf Server:}\;
	\Indp Initialize common model $w_0$\;
	\For {$t=1$ \KwTo $\Tcl$}
	{
	    Select $\mathbb{K}$ clients randomly \;
		\For {each client $k$ \textrm{in} $\mathbb{K}$}
		{	
			$\Delta \tilde{\mathbf{w}}_t^k = \mathbf{Client}_k(\mbf{w}_{t-1})$\;
		}
		$\mbf{w}_{t} = \mbf{w}_{t-1} + \frac{1}{|\mathbb{K}|} \sum_{k} \Delta \tilde{\mathbf{w}}_t^k $\;
	}
    \Indm {\bf $\mathbf{Client}_{k}(\mbf{w}_{t-1}^k)$:}\;
    \Indp
	%$\mbf{w}_{t-1}^k = \mbf{w}$\;
	$\Delta \mbf{w}_t^k = \mathbf{SGD}(D_k, \mbf{w}_{t-1}^{k}, \Tgd) - \mbf{w}_{t-1}^k$\;
	$\Delta \hat{\mbf{w}}_t^k = \Delta \mbf{w}_t^k / \max\left(1, \frac{||\Delta \mbf{w}_t^k||_2}{S}\right)$\;
    \KwOut{$\mathsf{Enc}_{K_k}(\mathcal{G}(\Delta \hat{\mbf{w}}_t^k, S \mathbf{I}\sigma /\sqrt{|K|}))$}
\end{algorithm}











\begin{table}[]
    \centering
    \scalebox{0.8}{
    \begin{tabular}{|c|c|}
        \hline
          \emph{Datasets}     &     \emph{Common Parameters}  \\
         \cline{1-2}
        \multirow{4}{*}{Fashion-MNIST dataset}  & $C=1/60$; $N=6000$; $\Tcl=200$; \\ & $\Tgd=5$;  $|\mathbb{B}|=10$;  $|D_k|=10$; $n=1,663,370$; \\ & $\delta=10^{-5}$;  $SGD(\eta=0.215)$;  $\eta_{G}=0.35$; \\ & $\rho=0.9$; $P=200$; $\sigma=1.54$; $T_{\mathsf{init}}=5$  \\
        \cline{1-2}
        \multirow{3}{*}{Medical dataset}  & $C=100/5010$; $N=5010$; $\Tcl=100$; $\Tgd=40$; \\ & $n=1,496,601$; $\delta=10^{-5}$; $SGD(\eta=0.1)$; $\eta_{G}=1.0$; \\ & $\rho=0.9$;  $P=100$;  $\sigma=1.49$; $T_{\mathsf{init}}=40$  \\
        %\cline{1-2}
        \hline 
        
    \end{tabular}}
    \caption{Common environment between the schemes. $\rho$, $\eta_{G}$ and $P$ are only used with FL-CS and FL-CS-DP.}
    \label{tab:hyperparameters}
\vspace{-.3cm}
\end{table}


%\vspace{10cm}


\begin{table}[!ht]
    \centering
    \scalebox{0.8}{
    \begin{tabular}{|c|c|c|c|c|c|}
        \hline
         \multirow{2}{*}{Algorithms} & \multicolumn{5}{c|}{\emph{Compression ratio ($r$)}} \\
         \cline{2-6}
         %\hline
         &   \emph{0.1\%} & \emph{0.5\%} & \emph{1\%} & \emph{5\%} & \emph{10\%} \\
         \hline
        FL-BASIC-DP    & 0.05 & 0.12 & 0.16 & 0.34 & 0.45 \\
        \cline{1-6}
        FL-BAS-2-DP    & 0.07 & 0.16 & 0.23 & 0.52 & 0.75 \\
        \cline{1-6}
        FL-BAS-3-DP    & 0.05  & 0.11 & 0.16 & 0.33 & 0.44 \\
        \cline{1-6}
        FL-BAS-4-DP    & 0.06 & 0.15 & 0.21 & 0.51 & 0.74 \\
        \cline{1-6}
        FL-CS-DP    & 0.21 & 0.26 & 0.32 & 0.57 & 0.79 \\
        \cline{1-6}
        FL-TOP-BIS-DP  & 1.25 & 1.59 & 1.79 & 2.18 & 2.34 \\
        \cline{1-6}
        FL-TOP-DP    & 0.50 & 0.61 & 0.64 & 0.87 & 1.0 \\
        \hline 
        
    \end{tabular}}
    \caption{Sensitivity S used for each scheme and for different compression ratio r on Fashion-MNIST. For FL-STD-DP, S is set to 2.40.}
    \label{tab:Sensitivity_fashion_mnist}
\vspace{-.3cm}
\end{table}


\begin{table}[!ht]
    \centering
    \scalebox{0.8}{
    \begin{tabular}{|c|c|c|c|c|c|c|c|}
        \hline
         \multirow{2}{*}{Algorithms} & \multicolumn{7}{c|}{\emph{Compression ratio ($r$)}} \\
         \cline{2-8}
         %\hline
         &   \emph{0.01\%} & \emph{0.05\%}  & \emph{0.1\%} & \emph{0.5\%} & \emph{1\%} & \emph{5\%} & \emph{10\%} \\
         \hline
        FL-BASIC-DP  & 0.01 & 0.03 & 0.05 & 0.11 & 0.16 & 0.34 & 0.46 \\
        \cline{1-8}
        FL-BAS-2-DP  & 0.01 & 0.03 & 0.04 & 0.09 & 0.14 & 0.31 & 0.44 \\
        \cline{1-8}
        FL-BAS-3-DP  & 0.01 & 0.04 & 0.06 & 0.12 & 0.18 & 0.35 & 0.49 \\
        \cline{1-8}
        FL-BAS-4-DP  & 0.02 & 0.03 & 0.05 & 0.12 & 0.15 & 0.31 & 0.44 \\
        \cline{1-8}
        FL-CS-DP  & 0.002 & 0.005 & 0.006 & 0.01 & 0.02 & 0.04 & 0.06 \\
        \cline{1-8}
        FL-TOP-BIS-DP  &  0.60 & 0.73 & 0.81 & 1.03 & 1.13 & 1.31 & 1.32 \\
        \cline{1-8}
        FL-TOP-DP  & 0.23 & 0.46 & 0.59 & 1.03 & 1.18 & 1.31 & 1.32 \\
        \hline 
        
    \end{tabular}}
    \caption{Sensitivity S used for each scheme and for different compression ratio r on the medical dataset. For FL-STD-DP, S is set to 1.40.}
    \label{tab:Sensitivity_medical_data}
\vspace{-.3cm}
\end{table}




\begin{table*}[!ht]
    \centering
    \scalebox{0.7}{
    \begin{tabular}{|c|c|c|c|c|c|c|}
        \hline
         \multirow{2}{*}{\emph{Compression ratio ($r$)}} & \multirow{2}{*}{Algorithms} & \multicolumn{5}{c|}{\emph{Performance}} \\
         \cline{3-7}
         %\hline
         & &  \emph{Accuracy}  & \emph{Round} & \emph{Downstream Cost } (Kilobyte) & \emph{Upstream Cost} (Kilobyte) & \emph{$\epsilon$} \\
         \hline

        \multirow{14}{*}{$0.1\%$} &  FL-BASIC   &  0.14 & 111 & 12308.94 & 12.31 & N/A  \\
        \cline{2-7}
        &  FL-BAS-2  &  0.16  & 185 & 20514.9 & 20.51 & N/A  \\
        \cline{2-7}
        &  FL-BAS-3  &  0.27  & 200 & 22.17 & 22.17 & N/A  \\
        \cline{2-7}
        &  FL-BAS-4  &  0.17  & 200 & 22.17 & 22.17 & N/A  \\
        \cline{2-7}
        &  FL-CS  & 0.37   & 200 & 22178.27 & 22.17 & N/A  \\
        \cline{2-7}
        &  FL-TOPK-BIS  &  0.59  & 198 & 21.95 & 21.95 & N/A  \\
        \cline{2-7}
        &  FL-TOP   & \textbf{0.78}  & 199 & \textbf{22.06} & \textbf{22.06} &N/A  \\
        \cline{2-7}
        \cline{2-7}
        &  FL-BASIC-DP   &  0.14  & 167 & 18518.85 & 18.51 & 0.95 \\
        \cline{2-7}
        &  FL-BAS-2-DP  &  0.14  & 124 & 13750.53 & 13.75 & 0.88 \\
        \cline{2-7}
        &  FL-BAS-3-DP  &  - & - & - & - & -\\
        \cline{2-7}
        &  FL-BAS-4-DP  &  0.15  & 137 & 15.19 & 15.19 & 0.90 \\
        \cline{2-7}
        &  FL-CS-DP  &  0.36  & 197 & 21845.59 & 21.84 & 1\\
        \cline{2-7}
        &  FL-TOPK-BIS-DP  &  0.59  & 196 & 21.73 & 21.73 & 0.99 \\
        \cline{2-7}
        &  FL-TOP-DP   & \textbf{0.76}  & 199 &  \textbf{22.06} & \textbf{22.06} & \textbf{1} \\
        \hline 
        \hline
        \multirow{14}{*}{$0.5\%$} &  FL-BASIC   &  0.65  & 193 & 21402.03 & 107 & N/A  \\
        \cline{2-7}
        &  FL-BAS-2  &  0.46  & 196 & 21734.70 & 108.66 & N/A  \\
        \cline{2-7}
        &  FL-BAS-3  &  0.73  & 200 & 110.88 & 110.88 & N/A  \\
        \cline{2-7}
        &  FL-BAS-4  & 0.41  & 197 & 109.22 & 109.22 & N/A  \\
        \cline{2-7}
        &  FL-CS  &  0.57  & 185 & 20514.9 & 102.56 & N/A  \\
        \cline{2-7}
        &  FL-TOPK-BIS  &  0.76  & 200 & 110.88 & 110.88 & N/A  \\
        \cline{2-7}
        &  FL-TOP   & \textbf{0.82}  & 200 & \textbf{110.88} & \textbf{110.88} & N/A \\
        \cline{2-7}
        \cline{2-7}
        &  FL-BASIC-DP   &  0.59  & 200 & 22178.27 & 110.88 & 1\\
        \cline{2-7}
        &  FL-BAS-2-DP  &  0.38 & 200  & 22178.27 & 110.88 & 1\\
        \cline{2-7}
        &  FL-BAS-3-DP  & 0.56   & 200 & 110.88 & 110.88 & 1\\
        \cline{2-7}
        &  FL-BAS-4-DP  &  0.33  & 200 & 110.88 & 110.88 & 1\\
        \cline{2-7}
        &  FL-CS-DP  &  0.53  & 200 & 22178.27 & 110.88 & 1\\
        \cline{2-7}
        &  FL-TOPK-BIS-DP  &  0.68  & 184 & 102.01 & 102.01 & 0.97\\
        \cline{2-7}
        &  FL-TOP-DP   & \textbf{0.81} & 200 & \textbf{110.88}  & \textbf{110.88} & \textbf{1}\\
        \hline 
        \hline
        \multirow{14}{*}{$1\%$} &  FL-BASIC   &  0.71  & 194 & 21512.92 & 215.12 & N/A  \\
        \cline{2-7}
        &  FL-BAS-2  &  0.59  & 200 & 22178.27 & 221.77 & N/A  \\
        \cline{2-7}
        &  FL-BAS-3  &  0.76  & 200 & 221.77 & 221.77 & N/A  \\
        \cline{2-7}
        &  FL-BAS-4  & 0.56  & 195 & 216.23 & 216.23 & N/A  \\
        \cline{2-7}
        &  FL-CS  &  0.69  & 200 & 22178.27 & 221.77 &N/A  \\
        \cline{2-7}
        &  FL-TOPK-BIS  &  0.79  & 197 & 218.45 & 218.45 & N/A  \\
        \cline{2-7}
        &  FL-TOP   & \textbf{0.83}  & 200 & \textbf{221.77} & \textbf{221.77} & N/A \\
        \cline{2-7}
        \cline{2-7}
        &  FL-BASIC-DP   &  0.65  & 197 & 21845.59 & 218.45 & 1\\
        \cline{2-7}
        &  FL-BAS-2-DP  & 0.62  & 198  & 21956.48 & 219.56 & 1\\
        \cline{2-7}
        &  FL-BAS-3-DP  &  0.66  & 198 & 219.56 & 219.56 & 1\\
        \cline{2-7}
        &  FL-BAS-4-DP  &  0.52  & 198 & 219.56 & 219.56 & 1\\
        \cline{2-7}
        &  FL-CS-DP  &  0.66  & 189 & 20958.46 & 209.58 & 0.98 \\
        \cline{2-7}
        &  FL-TOPK-BIS-DP  &  0.70  & 174 & 192.94 & 192.94 & 0.96\\
        \cline{2-7}
        &  FL-TOP-DP   & \textbf{0.81} & 183 & \textbf{202.92}  & \textbf{202.92} & \textbf{0.97}\\
        \hline
        \hline
        \multirow{14}{*}{$5\%$} &  FL-BASIC   &  0.78 & 196 & 21734.70 & 1086.73 & N/A  \\
        \cline{2-7}
        &  FL-BAS-2  &  0.72  & 199 & 22067.38 & 1103.36 & N/A  \\
        \cline{2-7}
        &  FL-BAS-3  &  0.81  & 199 & 1103.36 & 1103.36 &N/A  \\
        \cline{2-7}
        &  FL-BAS-4  &  0.76  & 196 & 1086.73 & 1086.73 & N/A  \\
        \cline{2-7}
        &  FL-CS  &  0.82  & 200 & 22178.27 & 1108.91 & N/A  \\
        \cline{2-7}
        &  FL-TOPK-BIS  &  0.83  & 196 & 1086.73 & 1086.73 & N/A  \\
        \cline{2-7}
        &  FL-TOP   & \textbf{0.84}  & 200 & \textbf{1108.91} & \textbf{1108.91} & N/A \\
        \cline{2-7}
        \cline{2-7}
        &  FL-BASIC-DP   &  0.76  & 195 & 21623.81 & 1081.18 & 0.99 \\
        \cline{2-7}
        &  FL-BAS-2-DP  &  0.72  & 195 & 21623.81 & 1081.18 & 0.99 \\
        \cline{2-7}
        &  FL-BAS-3-DP  &  0.76  & 199 & 1103.36 & 1103.36 & 1 \\
        \cline{2-7}
        &  FL-BAS-4-DP  &  0.75 & 191 & 1059.01 & 1059.01 & 0.99\\
        \cline{2-7}
        &  FL-CS-DP  &  0.78  & 160 & 17742.61 & 887.13 & 0.94 \\
        \cline{2-7}
        &  FL-TOPK-BIS-DP  &  0.71  & 152 & 842.77 & 842.77 & 0.92\\
        \cline{2-7}
        &  FL-TOP-DP   &  \textbf{0.81} & 152 & \textbf{842.77}  & \textbf{842.77} & \textbf{0.92}\\
        \hline 
        \hline
        \multirow{14}{*}{$10\%$} &  FL-BASIC   &  0.81  & 196 & 21734.70 & 2173.47 &N/A  \\
        \cline{2-7}
        &  FL-BAS-2  &    0.78  & 199 & 22067.38 & 2206.74 &N/A  \\
        \cline{2-7}
        &  FL-BAS-3  &  0.82  & 195 & 2162.38 & 2162.38 & N/A  \\
        \cline{2-7}
        &  FL-BAS-4  & 0.79   & 200 & 2217.83 & 2217.83 & N/A  \\
        \cline{2-7}
        &  FL-CS  &  0.85  & 182 & 20182.22 & 2018.22 & N/A  \\
        \cline{2-7}
        &  FL-TOPK-BIS  &   0.84 & 196 & 2173.47 & 2173.47 & N/A  \\
        \cline{2-7}
        &  FL-TOP   & \textbf{0.85}  & 199 & \textbf{2206.74} & \textbf{2206.74} &N/A \\
        \cline{2-7}
        \cline{2-7}
        &  FL-BASIC-DP   &  0.79  & 189 & 20958.46 & 2095.85 & 0.98\\
        \cline{2-7}
        &  FL-BAS-2-DP  &  0.77  & 189 & 20958.46 & 2095.85 & 0.98\\
        \cline{2-7}
        &  FL-BAS-3-DP  &  0.79  & 183 & 2029.31 & 2029.31 & 0.97 \\
        \cline{2-7}
        &  FL-BAS-4-DP  & 0.78  & 195 & 2162.38 & 2162.38 & 0.99\\
        \cline{2-7}
        &  FL-CS-DP  &  0.72  & 167 & 18518.85 & 1851.89 & 0.95\\
        \cline{2-7}
        &  FL-TOPK-BIS-DP  &  0.69  & 138 & 1530.30 & 1530.30 & 0.90\\
        \cline{2-7}
        &  FL-TOP-DP   &  \textbf{0.80} & 157 & \textbf{1740.99} & \textbf{1740.99} & \textbf{0.93}\\
        \hline 
        \hline
        
        
        \multirow{2}{*}{$100\%$} &  FL-STD  &  0.86  & 200 & 22178.27 & 22178.27 & N/A  \\
        \cline{2-7}
        &  FL-STD-DP  &  0.56 & 60 & 6653.48  & 6653.48 & 0.76 \\
        \hline
        
    \end{tabular}}
    \caption{Summary of results on Fashion-MNIST dataset.}
    \label{tab:description_results_Fashion_MNIST}
\vspace{-.3cm}
\end{table*}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{table*}[!ht]
    \centering
    \scalebox{0.7}{
    \begin{tabular}{|c|c|c|c|c|c|c|c|}
        \hline
         \multirow{2}{*}{\emph{Compression ratio ($r$)}} & \multirow{2}{*}{Algorithms} & \multicolumn{6}{c|}{\emph{Performance}} \\
         \cline{3-8}
         %\hline
         & &   \emph{Bal\_Acc} & \emph{AUROC}  & \emph{Round} & \emph{Downstream Cost} (Kilobyte) & \emph{Upstream Cost} (Kilobyte) & \emph{$\epsilon$} \\
         \hline

        \multirow{14}{*}{$0.01\%$} &  FL-BASIC  & 0.49 & 0.45 & 100 & 11948.91 & 1.19 & N/A \\
        \cline{2-8}
        &  FL-BAS-2  & 0.49 & 0.45 & 94 & 11231.98 & 1.12 & N/A  \\
        \cline{2-8}
        &  FL-BAS-3 &  0.49 & 0.45 & 81 & 0.96 & 0.96 &N/A \\
        \cline{2-8}
        &  FL-BAS-4 &  0.49  & 0.49 & 100 & 1.19 & 1.19 &N/A \\
        \cline{2-8}
        &  FL-CS &   - & - & - & - & - &N/A \\
        \cline{2-8}
        &  FL-TOP-Bis & 0.59  & 0.63 & 100 & 1.19 & 1.19 &N/A \\
        \cline{2-8}
        &  FL-TOP & \textbf{0.64}  & \textbf{0.70} & 60 & \textbf{0.71} & \textbf{0.71} &N/A \\
        \cline{2-8}
        &  FL-BASIC-DP  & 0.49 & 0.45 & 6 & 716.93 & 0.07 & 0.74 \\
        \cline{2-8}
        &  FL-BAS-2-DP  & 0.49 & 0.45 & 100 & 11948.91 & 1.19 & 1\\
        \cline{2-8}
        &  FL-BAS-3-DP &  0.49  & 0.45 & 95 & 1.13 & 1.13 & 0.99\\
        \cline{2-8}
        &  FL-BAS-4-DP &  0.49  & 0.47 & 96 & 1.14 & 1.14 & 0.99\\
        \cline{2-8}
        &  FL-CS-DP &  -  & - & - & - & - & - \\
        \cline{2-8}
        &  FL-TOP-Bis-DP &  0.59  & 0.63 & 94 & 1.12 & 1.12  & 0.99\\
        \cline{2-8}
        &  FL-TOP-DP &  \textbf{0.64}  & \textbf{0.70} & 100 & \textbf{1.19} & \textbf{1.19} & \textbf{1}\\
        \hline 
        \hline
        \multirow{14}{*}{$0.05\%$} &  FL-BASIC  & 0.50 & 0.48 & 100 & 11948.91 & 5.97 & N/A \\
        \cline{2-8}
        &  FL-BAS-2  & 0.49 & 0.46 & 100 & 11948.91 & 5.97 & N/A  \\
        \cline{2-8}
        &  FL-BAS-3 &  0.51 & 0.49 & 100 & 5.97 & 5.97 & N/A \\
        \cline{2-8}
        &  FL-BAS-4 &  0.51  & 0.52 & 57 & 3.40 & 3.40 &N/A \\
        \cline{2-8}
        &  FL-CS &  0.51  & 0.50 & 100 & 11948.91 & 5.97 & N/A \\
        \cline{2-8}
        &  FL-TOP-Bis &  0.68  & 0.75 & 92 & 5.49 & 5.49 & N/A \\
        \cline{2-8}
        &  FL-TOP & \textbf{0.68}  & \textbf{0.75} & 54 & \textbf{3.22} & \textbf{3.22} &N/A \\
        \cline{2-8}
        &  FL-BASIC-DP  & 0.49 & 0.46 & 84 & 10037.08 & 5.02 & 0.96  \\
        \cline{2-8}
        &  FL-BAS-2-DP  & 0.49 & 0.46 & 100 & 11948.91 & 5.97 & 1 \\
        \cline{2-8}
        &  FL-BAS-3-DP &  0.50  & 0.48 & 99 & 5.91 & 5.91 & 1\\
        \cline{2-8}
        &  FL-BAS-4-DP &  0.52  & 0.51 & 100 & 5.97 & 5.97 & 1\\
        \cline{2-8}
        &  FL-CS-DP &  0.49  & 0.48 & 100 & 11948.91 & 5.97 & 1\\
        \cline{2-8}
        &  FL-TOP-Bis-DP &  0.68  & 0.75 & 92 & 5.49 & 5.49  & 0.98\\
        \cline{2-8}
        &  FL-TOP-DP &  \textbf{0.68}  & \textbf{0.75} & 99 & \textbf{5.91} & \textbf{5.91} & \textbf{1}\\
        \hline 
        \hline
        \multirow{14}{*}{$0.1\%$} &  FL-BASIC  & 0.51 & 0.51 & 99 & 11829.42 & 11.82 & N/A \\
        \cline{2-8}
        &  FL-BAS-2  & 0.50 & 0.47 & 100 & 11948.91 & 11.94 &N/A  \\
        \cline{2-8}
        &  FL-BAS-3 &  0.53  & 0.53 & 100 & 11.94 & 11.94 &N/A \\
        \cline{2-8}
        &  FL-BAS-4 &  0.50  & 0.53 & 94 & 11.23 & 11.23 &N/A \\
        \cline{2-8}
        &  FL-CS &  0.53  & 0.55 & 100 & 11948.91 & 11.94 &N/A \\
        \cline{2-8}
        &  FL-TOP-Bis &  0.69  & 0.76 & 100 & 11.94 & 11.94 &N/A \\
        \cline{2-8}
        &  FL-TOP & \textbf{0.69}  & \textbf{0.76} & 68 & \textbf{8.12} & \textbf{8.12} &N/A \\
        \cline{2-8}
        &  FL-BASIC-DP  & 0.50 & 0.49 & 100 & 11948.91 & 11.94 & 1  \\
        \cline{2-8}
        &  FL-BAS-2-DP  & 0.50 & 0.47 & 100 & 11948.91 & 11.94 & 1\\
        \cline{2-8}
        &  FL-BAS-3-DP &  0.55  & 0.56 & 100 & 11.94 & 11.94 & 1\\
        \cline{2-8}
        &  FL-BAS-4-DP &  0.51  & 0.52 & 100 & 11.94 & 11.94 & 1\\
        \cline{2-8}
        &  FL-CS-DP &  0.51  & 0.51 & 99 & 11829.42 & 11.82 & 1\\
        \cline{2-8}
        &  FL-TOP-Bis-DP & 0.68 & 0.75 & 89 & 10.63 & 10.63 & 0.98\\
        \cline{2-8}
        &  FL-TOP-DP &  \textbf{0.69}  & \textbf{0.76} & 85 & \textbf{10.15} & \textbf{10.15} & \textbf{0.97} \\
        \hline 
        \hline
        \multirow{14}{*}{$0.5\%$} &  FL-BASIC  & 0.58 & 0.68 & 100 & 11948.91 & 59.74 & N/A \\
        \cline{2-8}
        &  FL-BAS-2  & 0.56 & 0.58 & 99 & 11829.42 & 59.15 & N/A  \\
        \cline{2-8}
        &  FL-BAS-3 &  0.61  & 0.68 & 100 & 59.74 & 59.74 & N/A \\
        \cline{2-8}
        &  FL-BAS-4 &  0.56  & 0.59 & 100 & 59.74 & 59.74 &N/A \\
        \cline{2-8}
        &  FL-CS &  0.66  & 0.71 & 100 & 11948.91 & 59.74 & N/A \\
        \cline{2-8}
        &  FL-TOP-Bis &  0.71  & 0.78 & 100 & 59.74 & 59.74 &N/A \\
        \cline{2-8}
        &  FL-TOP & \textbf{0.71}  & \textbf{0.79} & 95 & \textbf{56.76} & \textbf{56.76} & N/A \\
        \cline{2-8}
        &  FL-BASIC-DP  & 0.57 & 0.64 & 100 & 11948.91 & 59.74   & 1\\
        \cline{2-8}
        &  FL-BAS-2-DP  & 0.57 & 0.59 & 100 & 11948.91 & 59.74  & 1\\
        \cline{2-8}
        &  FL-BAS-3-DP &  0.58  & 0.67 & 100 & 59.74 & 59.74 & 1\\
        \cline{2-8}
        &  FL-BAS-4-DP &  0.54  & 0.57 & 34 & 20.31 & 20.31 & 0.83\\
        \cline{2-8}
        &  FL-CS-DP &  0.61  & 0.68 & 100 & 11948.91 & 59.74 & 1\\
        \cline{2-8}
        &  FL-TOP-Bis-DP &  0.68  & 0.75 & 55 & 32.86 & 32.86 & 0.89\\
        \cline{2-8}
        &  FL-TOP-DP &  \textbf{0.69}  & \textbf{0.76} & 24 & \textbf{14.34} & \textbf{14.34} & \textbf{0.80}\\
        \hline
        
    \end{tabular}}
    \caption{Summary of results on Medical dataset (Part 1).}
    \label{tab:description_results_Medical_data_part_1}
\vspace{-.3cm}
\end{table*}

\begin{table*}[!ht]
    \centering
    \scalebox{0.7}{
    \begin{tabular}{|c|c|c|c|c|c|c|c|}
        \hline
         \multirow{2}{*}{\emph{Compression ratio ($r$)}} & \multirow{2}{*}{Algorithms} & \multicolumn{6}{c|}{\emph{Performance}} \\
         \cline{3-8}
         %\hline
         & &   \emph{Bal\_Acc} & \emph{AUROC}  & \emph{Round} & \emph{Downstream Cost} (Kilobyte) & \emph{Upstream Cost} (Kilobyte) & \emph{$\epsilon$} \\
         \hline
                \multirow{14}{*}{$1\%$} &  FL-BASIC  & 0.64 & 0.72 & 100 & 11948.91 & 119.49 & N/A \\
        \cline{2-8}
        &  FL-BAS-2  & 0.62 & 0.66 & 100 & 11948.91 & 119.49 &N/A  \\
        \cline{2-8}
        &  FL-BAS-3 &  0.62  & 0.66 & 85 & 101.57 & 101.57 &N/A \\
        \cline{2-8}
        &  FL-BAS-4 & 0.56 & 0.59 & 100 &  119.49 & 119.49 &N/A \\
        \cline{2-8}
        &  FL-CS &   0.68 & 0.75 & 100 & 11948.91 & 119.49 & N/A \\
        \cline{2-8}
        &  FL-TOP-Bis &  0.72  & 0.79 & 100 & 119.49 & 119.49 &N/A \\
        \cline{2-8}
        &  FL-TOP & \textbf{0.72}  & \textbf{0.79} & 58 & \textbf{69.30} & \textbf{69.30} &N/A \\
        \cline{2-8}
        &  FL-BASIC-DP  & 0.64 & 0.70 & 100 & 11948.91 & 119.49   & 1\\
        \cline{2-8}
        &  FL-BAS-2-DP  & 0.62 & 0.67 & 100 & 11948.91 & 119.49  & 1\\
        \cline{2-8}
        &  FL-BAS-3-DP &  0.61  & 0.71 & 100 & 119.49 & 119.49 & 1\\
        \cline{2-8}
        &  FL-BAS-4-DP &  0.57  & 0.66 & 100 & 119.49 & 119.49 & 1\\
        \cline{2-8}
        &  FL-CS-DP &  0.66  & 0.72 & 100 & 11948.91 & 119.49 & 1\\
        \cline{2-8}
        &  FL-TOP-Bis-DP &  0.68  & 0.74 & 53 & 63.33 & 63.33 & 0.89\\
        \cline{2-8}
        &  FL-TOP-DP &  \textbf{0.69}  & \textbf{0.76} & 22 & \textbf{26.29} & \textbf{26.29} & \textbf{0.79}\\
        \hline 
        \hline
        \multirow{14}{*}{$5\%$} &  FL-BASIC  & 0.72 & 0.80 & 100 & 11948.91 & 597.45 &N/A\\
        \cline{2-8}
        &  FL-BAS-2  & 0.68 & 0.75 & 100 & 11948.91 & 597.45 &N/A  \\
        \cline{2-8}
        &  FL-BAS-3 & 0.69 & 0.76 & 98 & 585.5 & 585.5 &N/A \\
        \cline{2-8}
        &  FL-BAS-4 &  0.66  & 0.72 & 100 & 597.45 & 597.45 &N/A \\
        \cline{2-8}
        &  FL-CS &   0.73 & 0.81 & 98 & 11709.93 & 585.5 & N/A \\
        \cline{2-8}
        &  FL-TOP-Bis &  0.72 & 0.79 & 100 & 597.45 & 597.45 &N/A \\
        \cline{2-8}
        &  FL-TOP &  \textbf{0.72}  & \textbf{0.80} & 95 & \textbf{567.57} & \textbf{567.57} &N/A \\
        \cline{2-8}
        &  FL-BASIC-DP  & 0.69 & 0.76 & 100 & 11948.91 & 597.45 & 1 \\
        \cline{2-8}
        &  FL-BAS-2-DP  & 0.68 & 0.75 & 98 & 11709.93 & 585.5 & 1 \\
        \cline{2-8}
        &  FL-BAS-3-DP &  0.65  & 0.71 & 90 & 537.70 & 537.70 & 0.98\\
        \cline{2-8}
        &  FL-BAS-4-DP &  0.67  & 0.74 & 98 & 585.5 & 585.5 & 1\\
        \cline{2-8}
        &  FL-CS-DP &  0.69  & 0.76 & 100 & 11948.91 & 597.45 & 1\\
        \cline{2-8}
        &  FL-TOP-Bis-DP &  0.67  & 0.74 & 38 & 227.03 & 227.03 & 0.84 \\
        \cline{2-8}
        &  FL-TOP-DP & \textbf{0.68} & \textbf{0.75} & 23 & \textbf{137.41} & \textbf{137.41} & \textbf{0.79}\\
        \hline 
        \hline
        \multirow{14}{*}{$10\%$} &  FL-BASIC  & 0.74 & 0.81 & 100 & 11948.91 & 1194.89 &N/A \\
        \cline{2-8}
        &  FL-BAS-2  & 0.70 & 0.77 & 100 & 11948.91 & 1194.89 &N/A  \\
        \cline{2-8}
        &  FL-BAS-3 &  0.72  & 0.80 & 98 & 1170.99 & 1170.99 &N/A \\
        \cline{2-8}
        &  FL-BAS-4 &  0.70  & 0.77 & 99 & 1182.94 & 1182.94 & N/A \\
        \cline{2-8}
        &  FL-CS &  0.74  & 0.82 & 100 & 11948.91 & 1194.89 & N/A \\
        \cline{2-8}
        &  FL-TOP-Bis &  0.72  & 0.80 & 100 & 1194.89 & 1194.89 &N/A \\
        \cline{2-8}
        &  FL-TOP & \textbf{0.74}  & \textbf{0.82} & 90 & \textbf{1075.40} & \textbf{1075.40} &N/A \\
        \cline{2-8}
        &  FL-BASIC-DP  & 0.69 & 0.76 & 99 & 11829.42 & 1182.94 & 1 \\
        \cline{2-8}
        &  FL-BAS-2-DP  & 0.69 & 0.76 & 95 & 11351.46 & 1135.15 & 0.99\\
        \cline{2-8}
        &  FL-BAS-3-DP &  0.69  & 0.76 & 95 & 1135.15 & 1135.15 & 0.99\\
        \cline{2-8}
        &  FL-BAS-4-DP &  0.69  & 0.76 & 100 & 1194.89 & 1194.89 & 1\\
        \cline{2-8}
        &  FL-CS-DP &  0.69  & 0.76 & 96 & 11470.95 & 1147.09 & 0.99\\
        \cline{2-8}
        &  FL-TOP-Bis-DP &  0.67  & 0.73 & 37 & 442.11 & 442.11 & 0.84\\
        \cline{2-8}
        &  FL-TOP-DP &  \textbf{0.68}  & \textbf{0.74} & 23 & \textbf{274.82} & \textbf{274.82} & \textbf{0.79}\\
        \hline 
        \hline
        
        
        \multirow{2}{*}{$100\%$} &  FL-STD  & 0.74 & 0.82 & 99 & 11829.42 & 11829.42 &N/A \\
        \cline{2-8}
        &  FL-STD-DP   & 0.66 & 0.72 & 62 & 7408.32 & 7408.32 & 0.91 \\
        %\cline{2-9}
        %&  FL-STANDARD-DP + clip &    &  &  & & & & \\
        \hline
        
    \end{tabular}}
    \caption{Summary of results on Medical dataset (Part 2).}
    \label{tab:description_results_Medical_data_part_2}
\vspace{-.3cm}
\end{table*}


\end{document}

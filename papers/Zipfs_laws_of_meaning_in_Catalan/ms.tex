
\documentclass[10pt,letterpaper]{article}
\usepackage[top=0.85in,left=2.75in,footskip=0.75in]{geometry}

\pdfoutput=1

\newif\ifarxiv
\arxivtrue

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%% ELS NOSTRES INCLUDES %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{subcaption}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%% INCLUDE PLOS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{amsmath,amssymb}
\usepackage{changepage}
\usepackage[utf8x]{inputenc}
\usepackage{textcomp,marvosym}
\usepackage{cite}
\usepackage{nameref,hyperref}
\usepackage[right]{lineno}
\usepackage{microtype}
\DisableLigatures[f]{encoding = *, family = * }
\usepackage[table]{xcolor}
\usepackage{array}

\newcolumntype{+}{!{\vrule width 2pt}}

\newlength\savedwidth
\newcommand\thickcline[1]{%
  \noalign{\global\savedwidth\arrayrulewidth\global\arrayrulewidth 2pt}%
  \cline{#1}%
  \noalign{\vskip\arrayrulewidth}%
  \noalign{\global\arrayrulewidth\savedwidth}%
}

\newcommand\thickhline{\noalign{\global\savedwidth\arrayrulewidth\global\arrayrulewidth 2pt}%
\hline
\noalign{\global\arrayrulewidth\savedwidth}}

\raggedright
\setlength{\parindent}{0.5cm}
\textwidth 5.25in 
\textheight 8.75in

\usepackage[aboveskip=1pt,labelfont=bf,labelsep=period,justification=raggedright,singlelinecheck=off]{caption}
\renewcommand{\figurename}{Fig}

\bibliographystyle{plos2015}

\makeatletter
\renewcommand{\@biblabel}[1]{\quad#1.}
\makeatother

\usepackage{lastpage,fancyhdr,graphicx}
\usepackage{epstopdf}
\pagestyle{fancy}
\fancyhf{}
\rfoot{\thepage/\pageref{LastPage}}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrule}{\hrule height 2pt \vspace{2mm}}
\fancyheadoffset[L]{2.25in}
\fancyfootoffset[L]{2.25in}
\lfoot{\today}

%%%%%%%%%%%%%%%%%%%%%%%%%% END INCLUDE PLOS %%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%  TITOL; FILIACIO; ETC %%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\vspace*{0.2in}

\begin{flushleft}
{\Large
\textbf\newline{Zipf's laws of meaning in Catalan} 
}
\newline

\ifarxiv

Neus Català \textsuperscript{1},
Jaume Baixeries \textsuperscript{2},
Ramon Ferrer-Cancho \textsuperscript{2},
Lluís Padró \textsuperscript{1},
Antoni Hernández-Fernández \textsuperscript{2,3 *}

\else


Neus Català \textsuperscript{1\Yinyang},
Jaume Baixeries \textsuperscript{2\ddag},
Ramon Ferrer-Cancho \textsuperscript{2\Yinyang},
Lluís Padró \textsuperscript{1\ddag},
Antoni Hernández-Fernández \textsuperscript{2,3\Yinyang *}

\fi

\textbf{1} TALP Research Center, Computer Science Departament, 
Universitat Politècnica de Catalunya, Barcelona, Catalonia
\\
\textbf{2} LARCA Research Group, Complexity and Quantitative Linguistics Laboratory, Computer Science Departament, Universitat Politècnica de Catalunya, Barcelona, Catalonia
\\
\textbf{3} Societat Catalana de Tecnologia, Secció de Ciències i Tecnologia, Institut d’Estudis Catalans - Catalan Studies Institute, Barcelona, Catalonia
\\

\bigskip

\ifarxiv

\else

\Yinyang These authors contributed equally to this work.

\ddag These authors contributed equally to this work.

\fi

* Corresponding author e-mail: \href{mailto:antonio.hernandez@upc.edu}{antonio.hernandez@upc.edu}

\end{flushleft}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Abstract}

In his pioneering research, G. K. Zipf formulated a couple of statistical laws on the relationship between the frequency of a word with its number of meanings: the law of meaning distribution, relating the frequency of a word and its frequency rank, and the meaning-frequency law, relating the frequency of a word with its number of meanings. Although these laws were formulated more than half a century ago, they have been only investigated in a few languages. Here we present the first study of these laws in Catalan. 

We verify these laws in Catalan via the relationship among their exponents and that of the rank-frequency law. We present a new protocol for the analysis of these Zipfian laws that can be extended to other languages.
We report the first evidence of two marked regimes for these laws in written language and speech, paralleling the two regimes in Zipf's rank-frequency law in large multi-author corpora discovered in early 2000s. Finally, the implications of these two regimes will be discussed.

\textit{Keywords:}
Law of meaning distribution, meaning-frequency law, Zipf's rank-frequency law, Catalan, DIEC2, CTILC corpus, Glissando Corpus.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\ifarxiv
\else
\linenumbers
\fi

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%                    TEXT                %%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Introduction}
\label{S:1}

During the 1st half of the last century, G. K. Zipf carried out a vast investigation of statistical regularities of languages \cite{zipf1932selected,Zipf1935,Zipf1949}, that lead to the formulation of linguistic laws \cite{RSOS2019}. Among them, a subset has received very little attention: 
laws that relate the frequency of a word with its number of meanings in two ways. On the one hand, the law of meaning distribution, that relates the frequency rank of a word with its number of meanings (the most frequent word has rank 1, the 2nd most frequent word has rank 2,...). On the other hand, the meaning-frequency law, that relates the frequency of words to their number of meanings.

Both Zipfian laws of meaning indicate the more frequent words tend to have more meanings  and their mathematical definition takes the form of a power law ~\cite{Zipf1949, Zipf_MFL}. The relationship between the number of meanings of a word, $\mu$, and word frequency, $f$, Zipf's meaning-frequency law, follows approximately  

\begin{equation}
\mu \propto f^{\delta},
\label{eq:MFL_equation}
\end{equation}
where $\delta \approx 1/2$ \cite{Zipf_MFL, Ferrer2017, Baayen2005}. 
The law of meaning distribution that relates the meanings $\mu$ of a word with its frequency rank $i$ as
\begin{equation}
\mu \propto i^{-\gamma},
\label{eq:law_of_meaning_distribution_equation}
\end{equation}

where $\gamma \approx 1/2$ \cite{Ferrer2017, Ferrer2016}.

Interestingly, G. K. Zipf never investigated the meaning-frequency law empirically but deduced it from the law of meaning distribution \cite{Zipf_MFL, LC_2019} and the popular rank-frequency law, relating $f$ (the frequency of a word) with $i$ (its frequency rank) approximately as \cite{zipf1932selected,condon1928statistics} 

\begin{equation}
f \propto i^{-\alpha}.
\label{eq:word_frequency_law}
\end{equation}

Zipf deduced Eq. \ref{eq:MFL_equation} with $\delta = 1/2$ from $\alpha = 1$ (for Zipf's rank-frequency law), and $\gamma =1/2$ (for the law of meaning distribution) \cite{Zipf1949, Zipf_MFL}. Recently, it has been shown that the three exponents of the power laws are related by \cite{Ferrer2017, Ferrer2016}

\begin{equation}
\delta=\frac{\gamma}{\alpha}.
\label{eq:exponents}
\end{equation}

It should be noted that a \textit{weak} version of Zipf's meaning-frequency law simply indicates that there is a positive correlation between word frequency ($f$) and the number of meanings ($\mu$) what has been connected with a family of Zipfian optimization models of communication \cite{Carrera2021a}.
To date, experimental evidence has been accumulating for Zipf's law of meaning distribution, either fitting a power law function or computing the correlation between word frequency and meaning \cite{Baayen2005,bond2019testing, Casas2019, pilsen, Ilgen2007}.

Thus, there is new empirical evidence for the weak version of Zipf’s law
of meaning distribution on eight languages from
different language families (Indo-European,
Japonic, Sino-Tibetan and Austronesian), also retrieving exponents of Zipf's law of meaning distribution ($\gamma$) between $0.21$ and $0.51$ depending on the language (see \cite{bond2019testing} for details).
The results of Bond et al (2019) \cite{bond2019testing} are consistent with previous works that they review and that have verified the correlation between the frequency of words and their meanings \cite{Baayen2005, Ilgen2007} even in child language and language-directed speech \cite{Casas2019, pilsen}. In fact, Bond et al (2019) already noted the influence of both binning size and Zipf's law deviations on the predictive power of the Zipfian laws for the meaning although without considering Eq.~\ref{eq:exponents}.
Eq. \ref{eq:exponents} actually involves assuming the validity of Zipf's rank-frequency law, which has previously been seen not always happen, either due to the appearance of more than one regime in the distribution of words \cite{ferrer2001two, MONTEMURRO2001, Williams2015} or because the data fits better with other mathematical functions \cite{MONTEMURRO2001, mandelbrot1966information, li2010fitting}. 

This work is the first empirical study of Zipf's laws of meaning in Catalan and also the first one that considers two sources of different modality for word frequency: an speech corpus and a written one. Our study consists of investigating the exponents of Zipf's meaning-frequency law (Eq. \ref{eq:MFL_equation}) and meaning distribution (Eq.~\ref{eq:law_of_meaning_distribution_equation}) and then to test the validity of the relationship between the exponents (Eq. \ref{eq:exponents}) previously proposed \cite{Ferrer2017, Ferrer2016}. As far as we know this is the first time that the three Zipfian laws have been analyzed together empirically in one language: Catalan.

\subsection*{On Catalan}

Catalan is a Romance language spoken in the Western Mediterranean by more than ten million people. 
Catalan is considered a language between the Ibero-Romance (Spanish, Portuguese, Galician) and Gallo-Romance (French, Occitan, Franco-Provençal) languages \cite{kabatek2011romance}. 

Catalan can be considered a language of intermediate complexity from the quantitative perspective of information theory \cite{bentz2018adaptive}: Catalan has an intermediate level of 
entropy rate of $5.84$, with languages mean around $5.97 \pm 0.91$  \cite{Bentzetal2017} and morphological complexity (in terms of word complexity, with Catalan ranked in $202$ position over $520$ languages  \cite{bentz2016}). 
As it happens with other Romance languages Catalan does have a great inflectional variability \cite{kabatek2011romance}, especially in verbs but also in nouns and adjectives \cite{clua2002} with some lexical peculiarities \cite{Montermini2010}. Besides, derivation is a very productive procedure in the formation of new words in Catalan, suffixation being the most important (above the prefixation and infixation) \cite{domenech_estopa_2011}, as it is also usual in other Romance languages \cite{kabatek2011romance}. Despite the limited geographical extension of Catalan, there are local variations in suffixation processes that have been reviewed in detail (see \cite{domenech_estopa_2011} and references therein).

Catalan is also a language that has recently been studied in depth under the paradigm of quantitative linguistics \cite{kohler2008quantitative}, recovering the best-known linguistic laws in which meaning does not intervene (as is the case of Zipf's rank-frequency law, Herdan-Heaps' law, the brevity law or the Menzerath-Altmann law) in this speech corpus (Glissando) and in its transcripts \cite{entropy2019}. In addition, although the issue is still debated \cite{CorralSerra2020}, it has also been found the lognormal distribution of words, lately proposed as a new linguistic law \cite{RSOS2019, entropy2019} but, nevertheless, the statistical patterns of meaning in Catalan has not been addressed until the present study.

Since Zipf's pioneering research, one of the most remarkable discoveries on the rank-frequency law in large multi-author textual corpus is that the power law put forward by Zipf (Eq. \ref{eq:word_frequency_law}) has to be generalized, on a first approximation, as a double power law of the form \cite{ferrer2001two,MONTEMURRO2001, Williams2015, petersen2012languages, montemurro2002new, GerlachAltmann2013},

\begin{equation}
f \sim \left\{ 
     \begin{array}{lll}
     i^{-\alpha_1} & \mbox{~for~} i \leq i^* \\
     i^{-\alpha_2} & \mbox{~for~} i \geq i^*,
     \end{array} 
    \right.   
\label{eq:word_frequency_law_2_regimes}
\end{equation}

where $\alpha_1$ is the exponent for the low rank (high frequency) power-law regime corresponding to Eq. \ref{eq:word_frequency_law}, $\alpha_2$ is that of the high rank (low frequency) regime, and $i^*$ is the breakpoint rank. In the British National Corpus it was found that $\alpha_1 = 1$ and $\alpha_2 = 2$ \cite{ferrer2001two}. Precisely, these two scaling regimes in Zipf's rank-frequency law were referred to as the \textit{kernel lexicon}, for the most frequent words usually shared by the majority of speakers of the language, while the rarer words would be part of the so-called \textit{unlimited lexicon}, formed by less common, more specialized or technical words or, in the case of more extensive diachronic corpus, that have fallen into disuse \cite{ferrer2001two,petersen2012languages}.

Here we will provide evidence, in a novel way, that such a double power-law regime also applies to Zipf's laws of meaning.
First, the law of meaning distribution becomes

\begin{equation}
\mu \sim \left\{ 
     \begin{array}{lll}
     i^{-\gamma_1} & \mbox{~for~} i \leq i^* \\
     i^{-\gamma_2} & \mbox{~for~} i \geq i^*,
     \end{array} 
    \right.   
\label{eq:law_of_meaning_distribution_equation_2_regimes}
\end{equation}

where $\gamma_1$ is the exponent for high frequency regime, corresponding to $\delta$ in Eq \ref{eq:MFL_equation}, and $\gamma_2$ is the exponent for the low frequency regime. 
Second, the meaning-frequency law becomes

\begin{equation}
\mu \sim \left\{ 
     \begin{array}{lll}
     f^{\delta_2} & \mbox{~for~} f \leq f(i^*) \\
     f^{\delta_1} & \mbox{~for~} f \geq f(i^*),
     \end{array} 
    \right.   
\label{eq:MFL_equation_2_regimes}
\end{equation}

where $f(i^*)$ is the frequency of the word of rank $i^*$, $\delta_2$ is the exponent for the low frequency regime and $\delta_1$ is the exponent for the high frequency regime (Eq. \ref{eq:MFL_equation}).
Notice that, according to our convention, 
the subindex $1$ (in $\alpha_1$, $\gamma_1$ and $\delta_1$) is used to refer to high frequencies (low ranks) while
the subindex $2$  (in $\alpha_2$, $\gamma_2$ and $\delta_2$) is used to refer to low frequencies (high ranks). 

The remainder of the article is organized as follows. In Section~\ref{S:2}, we introduce the materials used, i.e. two Catalan corpora, one based on written texts (CTILC) and the other based on transcribed speech (Glissando), as well as the DIEC2 normative dictionary \cite{DIEC2}, from which the number of meanings (or polysemy of words) were obtained. We also present the lemmatization process with FreeLing \cite{Padro2012} and the binning method used, following Zipf \cite{Zipf_MFL}. In Section~\ref{S:3}, we first present an empirical exploration of the three Zipfian laws outlined above 
assuming a single regime followed by and analysis assuming two regimes.
We will show that Eq. \ref{eq:exponents} offers a poor prediction of $\delta$ when a single power-law regime as in Zipf's classic work for the multi-author corpora described above. In contrast, the assumption of two regimes, namely

\begin{eqnarray}
\delta_1=\frac{\gamma_1}{\alpha_1} \label{eq:exponents2} \\
\delta_2=\frac{\gamma_2}{\alpha_2}, \label{eq:exponents1}
\end{eqnarray}

improves the quality of predictions. 
Finally, in Section~\ref{S:4}, we discuss these results for Catalan in the context of previous studies \cite{bond2019testing, Casas2019, pilsen, Ilgen2007} 
and revisit the hypothesis of the existence of a core vocabulary and a peripheral vocabulary \cite{ferrer2001two,Williams2015,petersen2012languages}. 

\section*{Materials and methods}
\label{S:2}

\subsection*{Materials}

One of the most important institutional contributions to Catalan corpus linguistics is the \textit{Corpus Textual Informatitzat de la Llengua Catalana} (CTILC), a corpus that covers Catalan written language in texts from 1833 to 1988 (available at \url{https://ctilc.iec.cat/}). Based on this corpus, of which an expanded and updated version is in progress, the eminent linguist Joaquim Rafel i Fontanals was able to create a frequency dictionary of Catalan words \cite{diccionari_1998}. By way of example, this implies that a trendy word at present (unfortunately) such as \textit{coronavirus} does not appear in CTILC corpus and, however, there are words that have fallen into disuse from the 19th century such as \textit{coquessa} (a cooker who is hired to make meals on holidays).

This frequency dictionary contains more than 160,000 distinct lemmas, with about 52 million word tokens in total: about 29 million tokens from non-literary texts ($56\%$) and 23 million tokens from literary texts (the remaining $44\%$) \cite{diccionari_1998}. A more recent corpus is the Glissando corpus recorded in 2010, that contains more than 12 hours of read speech — news — and 12 more hours of studio recordings of dialogues which have been transcribed and aligned to the voice signal \cite{garrido2013}. In fact, Glissando is an annotated speech corpus, that is bilingual (Spanish and Catalan) and consisting of the recordings of twenty eight speakers per language, with about 93,000 word tokens and more than 5,000 types in Catalan \cite{entropy2019, garrido2013}.

\subsection*{Methods}

\subsubsection*{Preprocessing}

The empirical study of meaning, from the experimental perspective of quantitative and corpus linguistics, has several methodological challenges that were already pointed out by Zipf in his seminal study \cite{Zipf_MFL}. 
In fact, Zipf devoted the first pages of \cite{Zipf_MFL} to the reflection and justification of the corpus he chose in his analysis. Zipf's pioneering work assumed the concept of corpus lemmatization, although without explicitly citing it \cite{Zipf1949, Zipf_MFL}. Zipf refers to a "dictionary forms" and concludes, interestingly, that "\textit{...we  have  no  reason  to  suppose  that  any  ”law  of  meanings”  would be seriously distorted if we concentrated our attention upon lexical units and simply ignored variations in number, case, or tense.}" (see in \cite[p. 29]{Zipf1949}).  

In general, this type of  approach usually starts from a \textit{study corpus} (either written or transcribed from orality) that is not lemmatized. Lemmatization is the process of grouping together the different forms of a word (inflectional forms or derivationally related) in a single linguistic element, identified by the word's \textit{lemma} or \textit{dictionary form}, since it is the form that is usually found in dictionaries \cite{manning2008_introduction}.

This process of lemmatization is necessary to compare the study corpus with the dictionary corpus in order to establish which subset of words from the study corpus are present in the dictionary. In general, not all the words from a study corpus will be in the dictionary although the dictionary will be responsible for indicating the number of meanings of each word. The situation is depicted in Figure \ref{fig1}, where the corpora (the spoken corpus and written corpus) and the dictionary used in this work are displayed as a Venn diagram.

\begin{figure}[!h]
\ifarxiv
\begin{center}
\centering\includegraphics[width=0.9 \linewidth]{New_Venn_diagram}
\end{center}
\fi
\caption{\textbf{Graphical representation of the different sources used.} Venn diagram where the sources used in the present study are displayed as a sets: the normative dictionary of the Catalan language (DIEC2), providing  the number of meanings of each word; the written corpus CTILC, providing the basis for the descriptive dictionary and the dictionary of word frequencies of Catalan; and the speech corpus Glissando, that is not initially lemmatized, but that has been lemmatized here with FreeLing~\cite{Padro2012}.}
\label{fig1}
\end{figure}

Our analysis of the relationship between the number of meanings of a lemma and its frequency consists in combining information about the number of meanings from the official dictionary of the Catalan language (\textit{Diccionari de la llengua catalana}, DIEC2 \cite{DIEC2}) with two sources for the frequency: written language (\textit{Corpus Textual Informatitzat de la Llengua Catalana}, CTILC) and speech (\textit{Glissando Corpus}). As shown  in Figure~\ref{fig1}, we work with a subset of each corpus, that is defined by the intersection of the study corpus (spoken or written) with the dictionary, which implies necessarily a decrease in the number of lemmas with respect to the initial corpus.
Finally, the total number of different lemmas of each corpus is specified in Table~\ref{table_lemmas}. The intersection of the CTILC corpus with DIEC2 yields $52,578$ lemmas, while the intersection of the Glissando corpus with DIEC2 yields $3,083$ lemmas.\\

\begin{table}[!ht]
\centering
\small
\begin{tabular}{l r r l}
\hline
\textbf{Corpus} & \textbf{Tokens} & \textbf{Lemmas} & \textbf{Available (website link)}\\
\hline
CTILC & 52 million & 167,079 & \href{https://ctilc.iec.cat/}{https://ctilc.iec.cat/} \\
Glissando & 93,069 & 4,510 & \href{http://catalog.elra.info/en-us/repository/browse/ELRA-S0407/}{Glissando at ELRA catalog} \\
\hline
DIEC2 & ---  & 70,170 & \href{https://dlc.iec.cat}{https://dlc.iec.cat}/ \\
CTILC $\cap$ DIEC2 & ---  & 52,578 & \href{https://zenodo.org/record/4120887/files/DIEC2_CTILC_senseCG.zip?download=1}{CTILC and DIEC2} \\
Glissando $\cap$ DIEC2 & ---  & 3,083 & \href{https://zenodo.org/record/4120887/files/DIEC2_GLISSANDO_senseCG.zip?download=1}{Glissando and DIEC2}\\
\hline
\end{tabular}
\caption{\textbf{Summary of the data.} Number of tokens, different lemmas and availability details of the different sources used in the present study. The lemmas of the Glissando corpus were obtained after lemmatization with Freeling \cite{Padro2012}. For the DIEC2 dictionary, and its intersection with the respective corpora, the number of tokens is not applicable because the dictionary only includes lemmas.} 
\label{table_lemmas}
\end{table}

CTILC is manually lemmatized and annotated with Parts-of-Speech (PoS) tags and Glissando contains the direct transcriptions of spoken dialogues. 
In order to be able to perform the same analysis in both corpora, we resorted to FreeLing\footnote{\href{http://nlp.cs.upc.edu/freeling}{http://nlp.cs.upc.edu/freeling}}  to lemmatize the Glissando corpus  \cite{Padro2012}.
FreeLing is an open-source library offering a variety of linguistic analysis functionalities for more than 12 languages, including Catalan. More specifically, the natural language processing layers used in this work were:
\begin{description}
\item[Tokenization \& sentence splitting:] Given a text, split the basic lexical terms (words, punctuation signs, numbers, etc.), and group these tokens into sentences.
\item[Morphological analysis:] Find out all possible Parts-of-Speech (PoS) for each token.
\item[PoS-Tagging and Lemmatization:] Determine the right PoS for each word in its context. Determining the right PoS allows inferring the right lemma in almost all cases.
\item[Named Entity Recognition:] Detect proper nouns in the text, which may be formed by one or more tokens. We used only pattern-matching based detection relying mainly on capitalization.
\end{description}

We used FreeLing \cite{Padro2012} to perform PoS-tagging, lemmatization, and proper noun detection on Glissando corpus. We then filtered out all tokens marked as punctuation, number, or proper noun, before proceeding to count occurrences of each lemma and cross them with DIEC2. 

Of the $93,069$ tokens remaining after the filtering, $82,838$ ($89\%$) were lemmatized by FreeLing, producing $4,510$ different lemmas. The remaining 11\% tokens correspond to interjections, hesitations, half-words, foreign words (Spanish or English), colloquial expressions, non-capitalized proper nouns, or transcription errors (where the transcription was made phonetically, and not with the right form of the intended word) and were left out of the study.

\subsubsection*{Fitting method}

After intersecting each corpus with DIEC2 (Figure \ref{fig1}), we analized the resulting data sets and fitted the power law functions of the three Zipfian laws, using linear Least Squares (LS) on a logarithmic transoformation of both axes: the rank-frequency law, the law of meaning distribution and the meaning-frequency law, as
defined in Eq.~\ref{eq:word_frequency_law}, Eq.~\ref{eq:law_of_meaning_distribution_equation} and Eq.~\ref{eq:MFL_equation}, respectively. 

Following Baayen's method~\cite{baayen2008ald}, we calculated the most likely breakpoint, $i^*$ (the data point where the two regimes cross) in both corpora. The method consists of scanning all possible breakpoints and compute, for each, the deviation (sum of squared errors) or deviance, as Baayen's refers to it, between the real points and Eq.~\ref{eq:word_frequency_law_2_regimes}.
This breakpoint is the rank that minimizes the deviance. Some care is required in this method because there might be more than one local optimum, as we will see. 

Since we are studying three interrelated Zipfian laws (rank-frequency law, law of meaning distribution and meaning-frequency law), we decided, for simplicity, to transfer the breakpoint obtained for the rank-frequency law to the other double regime laws. The translation of the breakpoint to the double regime law of meaning distribution (Eq. \ref{eq:law_of_meaning_distribution_equation_2_regimes}) is immediate: the breakpoint, $i^*$, is the same as in the rank-frequency law. The translation of the $i^*$ to the breakpoint of the double regime meaning-frequency law (Eq. \ref{eq:MFL_equation_2_regimes}) requires computing $f(i^*)$. The value of $f(i^*)$ is calculated from the mean of the frequencies of the data in the bin where $i^*$ is located. $i^*$ and $f(i^*)$ are used to complete the fitting and retrieve the exponents of the double regime laws. Accordingly, for the law of meaning distribution, we fit Eq. \ref{eq:law_of_meaning_distribution_equation_2_regimes},
where the relevant parameters are $\gamma_1$ and $\gamma_2$. 
For the meaning frequency law, we fit Eq. \ref{eq:MFL_equation_2_regimes}
where the relevant parameters are $\delta_1$ and $\delta_2$.\\ 

\subsubsection*{Curve smoothing}

The fitting method described above is applied to two kinds of data: the raw data and the smoothed data. In the raw data approach, every point of the curve corresponds to a ``word''. No bucketing or binning was applied. The smoothed data approach follows from Zipf, who applied a linear binning technique to reduce noise in 
his analysis of the law of meaning distribution
\cite{Zipf1949, Zipf_MFL}. In previous work~\cite{Casas2019}, Zipf's analysis of the law in English \cite{Zipf1949} was revisited and values for exponents very close to those already obtained by Zipf were retrieved but, surprisingly, with sources of data differing from Zipf's work: in the case of the law of meaning distribution, $\gamma$ achieving a value of $0.5$ as in Zipf's pioneering research \cite{Zipf_MFL}.\\ 
Given the robustness of this method, the data smoothing approach consisted of estimating the exponents of the three Zipfian laws after applying a linear binning on the data sets. In particular, we applied equal-size binning ($K$ bins, each with $n/K$ data points), in the sense of having the same number of data points in each bin, considering $n$ the total number of lemmas of each subcorpus studied (Table \ref{table_lemmas}). In equal-size binning, resulting bins have an equal number of observations in each group. Bin sizes have been chosen from divisors of the number of data points (lemmas) in each corpus to warrant that every bin has the same number of points and that no data point is lost. CTILC $\cap$ DIEC2 contains $53,578$ lemmas and Glissando $\cap$ DIEC2 contains $3,083$ lemmas.

\section*{Results}
\label{S:3}

\subsection*{One regime analysis}

Fig.~\ref{fig2} and \ref{fig3} show Zipf's rank-frequency law for the CTILC corpus and the Glissando corpus, respectively. Similarly, Fig.~\ref{fig4} and \ref{fig5} show the meaning distribution law for CTILC and Glissando, respectively, and Fig.~\ref{fig6} and \ref{fig7} show the meaning-frequency law for CTILC and Glissando, respectively. The values of the exponents of each law are summarized in Table~\ref{exponents_table}, both in the case of equal-size binning and also when no smoothing is performed. 
Interestingly, $\gamma$ approaches $0.5$ in CTILC as the bin size increases and the difference between 
$\delta$ and $\delta'$ (the predicted value of $\delta$ from $\alpha$ and $\gamma$ in Eq. \ref{eq:exponents}), is slightly reduced when binning is used in both corpora.

\begin{figure}[!h]
\ifarxiv
\begin{minipage}{0.32\textwidth}
\centering
\includegraphics[width=1.1\linewidth]{DIEC2_CTILC_senseCG_zipf_grup_1_one_plot_nou_LS.png}
\end{minipage}
\hspace*{\fill}
\begin{minipage}{0.32\textwidth}
\centering
\includegraphics[width=1.1\linewidth]{DIEC2_CTILC_senseCG_zipf_grup_5_one_plot_nou_LS.png}
\end{minipage}
\hspace*{\fill}
\begin{minipage}{0.32\textwidth}
\centering
\includegraphics[width=1.1\linewidth]{DIEC2_CTILC_senseCG_zipf_grup_10_one_plot_nou_LS.png}
\end{minipage}
\fi
\caption{\textbf{Zipf's rank-frequency law in CTILC Corpus.} Average frequency ($f$) as a function of rank ($i$) after applying equal-size binning (blue). The best fit of a power law is also shown (red). Left: bin size of 127 words. Center: bins size of 414 words. Right: bin size of 762 words.}
\label{fig2}
\end{figure}

\begin{figure}[!h]
\ifarxiv
\begin{minipage}{0.32\textwidth}
\centering
\includegraphics[width=1.1\linewidth]{DIEC2_GLISSANDO_senseCG_zipf_grup_1_one_plot_nou_LS.png}
\end{minipage}
\hspace*{\fill}
\begin{minipage}{0.32\textwidth}
\centering
\includegraphics[width=1.1\linewidth]{DIEC2_GLISSANDO_senseCG_zipf_grup_5_one_plot_nou_LS.png}
\end{minipage}
\hspace*{\fill}
\begin{minipage}{0.32\textwidth}
\centering
\includegraphics[width=1.1\linewidth]{DIEC2_GLISSANDO_senseCG_zipf_grup_10_one_plot_nou_LS.png}
\end{minipage}
\fi
\caption{\textbf{Zipf's rank-frequency law in Glissando Corpus.} Average frequency ($f$) as a function of rank ($i$) after  applying equal-size binning (blue). The best fit of a power law is also shown (red). Left: bin size of 23 words. Center: bins size of 46 words. Right: bin size of 67 words.
}
\label{fig3}
\end{figure}


\begin{figure}[!h]
\ifarxiv
\begin{minipage}{0.32\textwidth}
\centering
\includegraphics[width=1.1\linewidth]{DIEC2_CTILC_senseCG_rank_grup_1_one_plot_nou_LS.png}
\end{minipage}
\hspace*{\fill}
\begin{minipage}{0.32\textwidth}
\centering
\includegraphics[width=1.1\linewidth]{DIEC2_CTILC_senseCG_rank_grup_5_one_plot_nou_LS.png}
\end{minipage}
\hspace*{\fill}
\begin{minipage}{0.32\textwidth}
\centering
\includegraphics[width=1.1\linewidth]{DIEC2_CTILC_senseCG_rank_grup_10_one_plot_nou_LS.png}
\end{minipage}
\fi
\caption{\textbf{Zipf's law of meaning distribution in CTILC corpus}. Average number of meanings ($\mu$) as a function of frequency rank ($i$) after applying equal-size binning (blue). The best fit of a power law is also shown (red).
Left: bin size of 127 words. Center: bin size of 414 words. Right: bin size of 762 words. Sources: Catalan words in CTILC, using DIEC2 meanings and CTILC frequencies.}
\label{fig4}
\end{figure}

\begin{figure}[!h]
\ifarxiv
\centering
\begin{minipage}{0.32\textwidth}
\centering
\includegraphics[width=\linewidth]{DIEC2_GLISSANDO_senseCG_rank_grup_1_one_plot_nou_LS.png}
\end{minipage}
\hspace*{\fill}
\begin{minipage}{0.32\textwidth}
\centering
\includegraphics[width=\linewidth]{DIEC2_GLISSANDO_senseCG_rank_grup_5_one_plot_nou_LS.png}
\end{minipage}
\hspace*{\fill}
\begin{minipage}{0.32\textwidth}
\centering
\includegraphics[width=\linewidth]{DIEC2_GLISSANDO_senseCG_rank_grup_10_one_plot_nou_LS.png}
\end{minipage}
\fi
\caption{\textbf{Zipf's law of meaning distribution in Glissando corpus. } 
Average number of meanings ($\mu$) as a function of frequency rank ($i$) after applying equal-size binning (blue). The best fit of a power law is also shown (red).
Left: bin size of 23 words. Center: bin-size of 46 words. Right: bin-size of 67 words. Sources: Catalan words in Glissando, using DIEC2 meanings and Glissando frequencies.}
\label{fig5}
\end{figure}

\begin{figure}[!h]
\ifarxiv
\begin{minipage}{0.32\textwidth}
\centering
\includegraphics[width=1.1\linewidth]{DIEC2_CTILC_senseCG_freq_grup_1_one_plot_nou_LS.png}
\end{minipage}
\hspace*{\fill}
\begin{minipage}{0.32\textwidth}
\centering
\includegraphics[width=1.1\linewidth]{DIEC2_CTILC_senseCG_freq_grup_5_one_plot_nou_LS.png}
\end{minipage}
\hspace*{\fill}
\begin{minipage}{0.32\textwidth}
\centering
\includegraphics[width=1.1\linewidth]{DIEC2_CTILC_senseCG_freq_grup_10_one_plot_nou_LS.png}
\end{minipage}
\fi
\caption{\textbf{Zipf's meaning-frequency law in CTILC corpus}. Average number of meanings ($\mu$) as a function of frequency ($f$) after applying equal-size binning (blue). The best fit of a power law is also shown (red).
Left: bin size of 127 words. Center: bin size of 414 words. Right: bin size of 762 words. Sources: Catalan words in CTILC, using DIEC2 meanings and CTILC frequencies.}
\label{fig6}
\end{figure}

\begin{figure}[!h]
\ifarxiv
\centering
\begin{minipage}{0.32\textwidth}
\centering
\includegraphics[width=\linewidth]{DIEC2_GLISSANDO_senseCG_freq_grup_1_one_plot_nou_LS.png}
\end{minipage}
\hspace*{\fill}
\begin{minipage}{0.32\textwidth}
\centering
\includegraphics[width=\linewidth]{DIEC2_GLISSANDO_senseCG_freq_grup_5_one_plot_nou_LS.png}
\end{minipage}
\hspace*{\fill}
\begin{minipage}{0.32\textwidth}
\centering
\includegraphics[width=\linewidth]{DIEC2_GLISSANDO_senseCG_freq_grup_10_one_plot_nou_LS.png}
\end{minipage}
\fi
\caption{\textbf{Zipf's meaning-frequency law in Glissando corpus. } 
Average number of meanings ($\mu$) as a function of frequency ($f$) after applying equal-size binning (blue). The best fit of a power law is also shown (red). Left: bin size of 23 words. Center: bin-size of 46 words. Right: bin-size of 67 words. Sources: Catalan words in Glissando, using DIEC2 meanings and Glissando frequencies.}
\label{fig7}
\end{figure}

\definecolor{Gray}{gray}{0.85}
\begin{table}[!ht]
\centering
\small
\begin{tabular}{l l l l l l l}
\hline
Binning & \textbf{Corpus} & bin size & $\alpha$ & $\gamma$ & $\delta$ & $\delta'$ \\
\hline
No binning  & CTILC $\cap$ DIEC2 & -  & 2.199 & 0.388 & \cellcolor{Gray}0.154 & \cellcolor{Gray}0.176 \\
            & Glissando $\cap$ DIEC2 & - & 1.459 & 0.261 & \cellcolor{Gray}0.184 & \cellcolor{Gray}0.178 \\
\hline
Equal-size  & CTILC $\cap$ DIEC2 & 127  & 2.228 & 0.471 & \cellcolor{Gray}0.187 & \cellcolor{Gray}0.211 \\
            &                    & 414  & 2.286 & 0.478 & \cellcolor{Gray}0.187 & \cellcolor{Gray}0.209 \\
            &                    & 762  & 2.347 & 0.484 & \cellcolor{Gray}0.187 & \cellcolor{Gray}0.206 \\ \\
            & Glissando $\cap$ DIEC2 & 23 & 1.483 & 0.304 & \cellcolor{Gray}0.210 & \cellcolor{Gray}0.205 \\
            &                    & 46  & 1.513 & 0.306 & \cellcolor{Gray}0.206 & \cellcolor{Gray}0.202 \\
            &                    & 67  & 1.542 & 0.312 & \cellcolor{Gray}0.205 & \cellcolor{Gray}0.202 \\
\hline
\end{tabular}
\caption{\textbf{One regime analysis (CTILC and Glissando corpora).} The exponents of the Zipfian laws: the rank-frequency law ($\alpha$, Eq.~\ref{eq:word_frequency_law}), the law of meaning distribution ($\gamma$, Eq.~\ref{eq:law_of_meaning_distribution_equation}) and meaning-frequency law ($\delta$, Eq.~\ref{eq:MFL_equation}). $\delta'$ is the exponent $\delta$ predicted by Eq.~\ref{eq:exponents}, obtained from $\alpha$ and $\gamma$. For estimating the values of the parameters, we have used Least Squares (LS) on a logarithmic transformation of both axes. Concerning equal-size binning, see the Methods section for the rationale behind the choice of the bin sizes.
}
\label{exponents_table}
\end{table}

\subsection*{Two regime analysis}

After visual inspection of the rank-frequency law (Fig.~\ref{fig2} and \ref{fig3}), the appearance of at least two regimes, i.e. straight lines in log-log scale with different slopes, is suggested in the CTILC written corpus (Fig.~\ref{fig2}). That is a well-known feature arising in large multi-author corpora \cite{ferrer2001two,MONTEMURRO2001, Williams2015, petersen2012languages, montemurro2002new, GerlachAltmann2013}. However, interestingly, these two regimes  are apparently not visually observed in the Glissando speech corpus  (Fig. \ref{fig3}) but they might be hidden in the greater dispersion of the points in meaning distribution, despite the linear binning, that can be seen in the speech corpus (Fig.~\ref{fig5}) with respect to CTILC (Fig.~\ref{fig4}).\\  

To confirm the presence of two regimes in the CTILC corpus and shed light on the possible presence of two regimes in the Glissando corpus, we perform a careful analysis using Baayen's method of breakpoint detection \cite{baayen2008ald}. 
As can be seen in Fig.~\ref{fig8}, 
the deviance has only a single minimum in the case of CTILC corpus,
which allows to determine a breakpoint easily.
Besides, a global minimum and a and and additional local minimum are found in the Glissando corpus (Fig.~\ref{fig9}): in the first binning (23 words per bin), the global minimum does correspond to a meaningful two-regime breakpoint but, in the other two binnings (46 and 67 words per bin), the global mininum corresponds to a spurious result due to the abundance of hapax legomena in the tail of the rank distribution, a phenomenon that can also be observed in the first binning (Fig.~\ref{fig9}). This spurious minimum in deviance can be explained by an artifact of the deviance minimization procedure for breakpoint detection, that becomes too sensitive to the concentration of points in the tail and the scarcity of points in other parts of the curve when bin size increases \cite{baayen2008ald}. As a result it is observed that when bin size increases, the local minima in deviance decreases (see right panels in Fig.~\ref{fig9}).

\ifarxiv
\newpage\vspace*{-1.55cm}
\fi

\begin{figure}[!h]
\ifarxiv
\begin{subfigure}[t]{0.03\textwidth}
    \textbf{A}
  \end{subfigure}
\begin{subfigure}{0.97\textwidth}
\includegraphics[width=1.1\linewidth]{DIEC2_CTILC_senseCG_zipf_grup_1_two_regime10.pdf}
\end{subfigure}
\begin{subfigure}[t]{0.03\textwidth}
    \textbf{B}
  \end{subfigure}
\begin{subfigure}{0.97\textwidth}
\includegraphics[width=1.1\linewidth]{DIEC2_CTILC_senseCG_zipf_grup_5_two_regime10.pdf}
\end{subfigure}
\begin{subfigure}[t]{0.03\textwidth}
    \textbf{C}
  \end{subfigure}
\begin{subfigure}{0.97\textwidth}
\includegraphics[width=1.1\linewidth]{DIEC2_CTILC_senseCG_zipf_grup_10_two_regime10.pdf}
\end{subfigure}
\fi
\caption{\textbf{Breakpoint analysis for Zipf's rank-frequency law in CTILC corpus.}  Breakpoints ($i^*$) are depicted as blue dashed lines. Left: frequency ($f$) as a function of rank ($i$). The best fit of a two-regime power law is also shown (red). Right: Baayen's deviance as a function of rank ($i$).
The choice of the bin sizes is the same as in Table~\ref{exponents_tworegime} and influences the breakpoint. Row A) 127 words per bin and breakpoint $20,606$, row B) 414 words per bin and breakpoint $22,149$, and row C) 762 words per bin and breakpoint $23,241$.}
\label{fig8}
\end{figure}

\ifarxiv
\newpage\vspace*{-1.55cm}
\fi

\begin{figure}[!h]
\ifarxiv
\begin{subfigure}[t]{0.03\textwidth}
    \textbf{A}
  \end{subfigure}
\begin{subfigure}{0.97\textwidth}
\includegraphics[width=1.1\linewidth]{DIEC2_GLISSANDO_senseCG_zipf_grup_1_two_regime10.pdf}
\end{subfigure}
\begin{subfigure}[t]{0.03\textwidth}
    \textbf{B}
  \end{subfigure}
\begin{subfigure}{0.97\textwidth}
\includegraphics[width=1.1\linewidth]{DIEC2_GLISSANDO_senseCG_zipf_grup_5_two_regime10.pdf}
\end{subfigure}
\begin{subfigure}[t]{0.03\textwidth}
    \textbf{C}
  \end{subfigure}
\begin{subfigure}{0.97\textwidth}
\includegraphics[width=1.1\linewidth]{DIEC2_GLISSANDO_senseCG_zipf_grup_10_two_regime10.pdf}
\end{subfigure}
\fi
\caption{\textbf{Breakpoint analysis for Zipf's rank-frequency law in Glissando corpus.}
Blue dashed lines and gray dashed lines are used to indicate, respectively, the first and the second local minimum of deviance. The 1st local minimum is taken as the meaningful breakpoint ($i^*$).
Left: frequency ($f$) as a function of rank ($i$). The best fit of a two-regime power law is also shown (red). Right: Baayen's deviance as a function of rank ($i$). The choice of the bin sizes is the same as in Table~\ref{exponents_tworegime} and influences the first non-spurious breakpoint. Row A) 23 words per bin and breakpoint $333.5$, row B) 46 words per bin and breakpoint $437.0$, and row C) 67 words per bin and breakpoint $502.5$.
}
\label{fig9}
\end{figure}

The value of the breakpoint increases with the size of the bin. This value is approximately $20,606$ (127 words per bin), $22,149$ (414 words per bin) and $23,241$ (762 words per bin)
in the CTILC corpus (Fig. \ref{fig8}).
In the Glissando corpus (Fig.~\ref{fig9}), the non-spurious breakpoint is found at $333,5$ (23 words per bin), $437,0$  (46 words per bin) and $502,5$ (67 words per bin). Evidently, the size of the corpus influences the the values of these breakpoints.\\

Figure~\ref{fig10} shows the meaning-frequency law with this two regime analysis in CTILC and Glissando corpora, and Figure~\ref{fig11} shows the two-regime in law of meaning distribution. In both cases, by varying the bin size, the fitting curve for the CTILC corpus has a clear breakpoint that divides the two regimes, while for the Glissando corpus this breakpoint is not so clear visually, as there is greater dispersion of data in the speech corpus and, consequently, a weaker correlation.\\

\begin{figure}[!h]
\ifarxiv
\begin{subfigure}[t]{0.02\textwidth}
    \textbf{A}
  \end{subfigure}
\begin{subfigure}{0.32\textwidth}
\includegraphics[width=1.1\linewidth]{DIEC2_CTILC_senseCG_freq_grup_1_two_regime10_set_bp.png}
\end{subfigure}\hspace*{\fill}
\begin{subfigure}{0.32\textwidth}
\includegraphics[width=1.1\linewidth]{DIEC2_CTILC_senseCG_freq_grup_5_two_regime10_set_bp.png}
\end{subfigure}\hspace*{\fill}
\begin{subfigure}{0.32\textwidth}
\includegraphics[width=1.1\linewidth]{DIEC2_CTILC_senseCG_freq_grup_10_two_regime10_set_bp.png}
\end{subfigure}

\vspace{0.5cm}

\begin{subfigure}[t]{0.02\textwidth}
    \textbf{B}
  \end{subfigure}
\begin{subfigure}{0.32\textwidth}
\includegraphics[width=1.1\linewidth]{DIEC2_GLISSANDO_senseCG_freq_grup_1_two_regime10_set_bp.png}
\end{subfigure}\hspace*{\fill}
\begin{subfigure}{0.32\textwidth}
\includegraphics[width=1.1\linewidth]{DIEC2_GLISSANDO_senseCG_freq_grup_5_two_regime10_set_bp.png}
\end{subfigure}\hspace*{\fill}
\begin{subfigure}{0.32\textwidth}
\includegraphics[width=1.1\linewidth]{DIEC2_GLISSANDO_senseCG_freq_grup_10_two_regime10_set_bp.png}
\end{subfigure}
\fi
\caption{\textbf{The meaning-frequency law in the CTILC and Glissando corpora.} Row A) CTILC corpus and row B) Glissando corpus. The choice of the bin sizes is the same as in Table~\ref{exponents_tworegime}. Breakpoints ($i^*$) are depicted as dashed blue lines.}
\label{fig10}
\end{figure}


\begin{figure}[!h]
\ifarxiv
\begin{subfigure}[t]{0.02\textwidth}
    \textbf{A}
  \end{subfigure}
\begin{subfigure}{0.32\textwidth}
\includegraphics[width=1.1\linewidth]{DIEC2_CTILC_senseCG_rank_grup_1_two_regime10_set_bp.png}
\end{subfigure}\hspace*{\fill}
\begin{subfigure}{0.32\textwidth}
\includegraphics[width=1.1\linewidth]{DIEC2_CTILC_senseCG_rank_grup_5_two_regime10_set_bp.png}
\end{subfigure}\hspace*{\fill}
\begin{subfigure}{0.32\textwidth}
\includegraphics[width=1.1\linewidth]{DIEC2_CTILC_senseCG_rank_grup_10_two_regime10_set_bp.png}
\end{subfigure}

\vspace{0.5cm}

\begin{subfigure}[t]{0.02\textwidth}
    \textbf{B}
  \end{subfigure}
\begin{subfigure}{0.32\textwidth}
\includegraphics[width=1.1\linewidth]{DIEC2_GLISSANDO_senseCG_rank_grup_1_two_regime10_set_bp.png}
\end{subfigure}\hspace*{\fill}
\begin{subfigure}{0.32\textwidth}
\includegraphics[width=1.1\linewidth]{DIEC2_GLISSANDO_senseCG_rank_grup_5_two_regime10_set_bp.png}
\end{subfigure}\hspace*{\fill}
\begin{subfigure}{0.32\textwidth}
\includegraphics[width=1.1\linewidth]{DIEC2_GLISSANDO_senseCG_rank_grup_10_two_regime10_set_bp.png}
\end{subfigure}
\fi
\caption{\textbf{The law of meaning distribution in the CTILC and Glissando corpora.} Row A) CTILC corpus and row B) Glissando corpus. The choice of the bin sizes is the same as in Table~\ref{exponents_tworegime}. Breakpoints ($i^*$) are depicted as dashed blue lines.}
\label{fig11}
\end{figure}
 
Table~\ref{exponents_tworegime} summarizes the  exponents of the Zipfian laws obtained in each of the two regimes for the CTILC and Glissando corpora. The difference between $\delta_1$ and its predicted value $\delta_1'$ from Eq.~\ref{eq:exponents2}, and the difference between $\delta_2$ and its predicted value $\delta_2'$ from Eq.~\ref{eq:exponents1}, are, in general, smaller than when a single regime was assumed in Table~\ref{exponents_table}, providing support for the reality of two-regime structure.

\definecolor{LGray}{gray}{0.95}
\begin{table}[!ht]
\centering
\small
\begin{tabular}{l l l l l l l l l l}
\hline
\hline
\textbf{CTILC}  &  &  &  &  &   &  &  &  &  \\
\hline
Binning & bin & $\alpha_1$ & $\alpha_2$ & $\gamma_1$ & $\gamma_2$ & $\delta_1$ & $\delta'_1$ & $\delta_2$ & $\delta'_2$  \\
 & size &  &  &  &  &  &  &  &  \\
\hline
No binning  & --  & 1.414 & 4.483 & 0.419 & 0.298 & \cellcolor{Gray}0.275 & \cellcolor{Gray}0.296 & \cellcolor{LGray}0.052 & \cellcolor{LGray}0.066  \\
\hline
Equal-size  & 127  & 1.480 & 4.560 & 0.494 & 0.402 & \cellcolor{Gray}0.312 & \cellcolor{Gray}0.334 & \cellcolor{LGray}0.073 & \cellcolor{LGray}0.088  \\
            & 414  & 1.600 & 4.707 & 0.503 & 0.388 & \cellcolor{Gray}0.297 & \cellcolor{Gray}0.314 & \cellcolor{LGray}0.068 & \cellcolor{LGray}0.082 \\
            & 762  & 1.707 & 4.800 & 0.512 & 0.375 & \cellcolor{Gray}0.286 & \cellcolor{Gray}0.300 & \cellcolor{LGray}0.065 & \cellcolor{LGray}0.078 \\
\hline
\hline
\textbf{Glissando} &  &  &  &  &   &  &  &  &  \\
\hline
No binning  & --  & 0.853 & 1.537 & 0.065 & 0.287 & \cellcolor{Gray}0.059 & \cellcolor{Gray}0.076 & \cellcolor{LGray}0.194 & \cellcolor{LGray}0.187  \\
\hline
Equal-size  & 23  & 1.281  & 1.583 & 0.098 & 0.405 & \cellcolor{Gray}0.071 &  \cellcolor{Gray}0.076 & \cellcolor{LGray}0.262 & \cellcolor{LGray}0.256  \\
            & 46  & 1.404  & 1.583 & 0.102 & 0.436 & \cellcolor{Gray}0.069 & \cellcolor{Gray}0.073 & \cellcolor{LGray}0.275 & \cellcolor{LGray}0.275  \\
            & 67  & 1.495  & 1.577 & 0.110 & 0.459 & \cellcolor{Gray}0.072 & \cellcolor{Gray}0.074 & \cellcolor{LGray}0.291 & \cellcolor{LGray}0.291  \\
\hline
\end{tabular}

\caption{\textbf{Two regime analysis (CTILC and Glissando corpora).} The exponents of each regime of the Zipfian laws: the rank-frequency law ($\alpha_1$ and $\alpha_2$), the law of meaning distribution ($\gamma_1$ and $\gamma_2$) and meaning-frequency law ($\delta_1$ and $\delta_2$). $\delta_1'$ is the exponent $\delta_1$ predicted by Eq.~\ref{eq:exponents1} while 
$\delta_2'$ is the exponent $\delta_2$ predicted by Eq.~\ref{eq:exponents2}. To obtain the exponents, we used LS following Baayen's method \cite{baayen2008ald}. Concerning equal-size binning, see the Methods section for the rationale behind the choice of the bin sizes.
Subindexes of the exponents correspond to the regimes according to Eq.~\ref{eq:word_frequency_law_2_regimes}, Eq.~\ref{eq:law_of_meaning_distribution_equation_2_regimes} and Eq.~\ref{eq:MFL_equation_2_regimes}.}
\label{exponents_tworegime}
\end{table}


\section*{Discussion}
\label{S:4}

\subsection*{Zipf's laws of meaning and robustness of the equation between exponents}

Zipf’s laws of meaning have been verified in Catalan. Assuming a single regime and applying equal-size binning to the CTILC corpus, the $\gamma$ exponent of the law of meaning distribution that Zipf found for the word meaning distribution law in English \cite{Zipf1949, Zipf_MFL} was recovered approximately, $\gamma \approx 1/2$, (Table \ref{exponents_table}), consistently with previous work \cite{Ferrer2017, Ferrer2016}. This is not the case of the Glissando speech corpus  where $\gamma \approx 0.304-0.312$. Nonetheless, considering the results for the fitting of a single slope ($\gamma$) for the law of meaning distribution, the $\gamma$ values obtained here are consistent with previous works \cite{Casas2019, Ilgen2007} that extended the fitting of this law to non-Indo-European languages \cite{bond2019testing}. As shown in previous research, verified here again for Catalan, there is a certain variability in the exponents of the Zipfian laws according to the size of the binning \cite{bond2019testing, Casas2019, Ilgen2007}.\\

However, there were clear deviations in Zipf's rank-frequency law exponent, i.e. $\alpha$, with respect to Catalan ($\alpha=1.42$ in \cite{entropy2019} using different methods) and other languages in normal conditions \cite{Ferrer2005variation, Baixeries2013}.  Consequently, this fact affected the exponent $\delta'$ obtained indirectly with Eq.~\ref{eq:exponents} (see Table \ref{exponents_table}). These considerations notwithstanding, $\delta'$ gives approximately a similar value as the $\delta$ obtained directly from the meaning-frequency law ($\delta'= 0.187-0.21$ (CTILC corpus) and $\delta'= 0.20-0.21$ (Glissando corpus)) but deviates in both cases from the previously estimated for English \cite{Zipf_MFL, Ferrer2017}. The well-known deviations in Zipf's rank-frequency law (Eq.~\ref{eq:word_frequency_law}) imply that it cannot be assumed that $\alpha = 1$ in general \cite{Ferrer2005variation,Baixeries2013}, therefore, according to Eq. \ref{eq:exponents}, it cannot be expected that $\gamma = \delta$ as in Zipf's early work \cite{Zipf_MFL,bond2019testing}.\\

Nevertheless, the Equation \ref{eq:exponents} to obtain $\delta'$ indirectly is even robust in the case of the analysis of one regime without binning in both corpus (Table \ref{exponents_table}). This is especially interesting given that, in this case, both in the CTILC corpus ($\alpha \approx 2.20$, $\gamma \approx 0.39$) and in Glissando ($\alpha \approx 1.46$, $\gamma \approx 0.26$) the Zipfian exponents are far from the usual ones but $\delta \approx \delta'$. On the other hand, the minimal differences found in $\alpha$ with respect to the previous study of the Glissando corpus \cite{entropy2019} (where $\alpha \approx 1.42$) may be due to the fact that here we have worked with a subcorpus of Glissando (Glissando $\cap$ DIEC2) and with different methods. \\

On the other hand, after verifying the existence of two regimes in Zipf's rank-frequency law in CTILC corpus (Fig.~\ref{fig2} and \ref{fig8}) and in Glissando corpus (Fig.~\ref{fig3} and \ref{fig9}), as previous works pointed out in big corpora \cite{ferrer2001two, Williams2015, petersen2012languages}, we have seen that this affects the meaning-frequency law (Fig.~\ref{fig10}). Then, the analysis of the two regimes in the CTILC corpus allowed us to obtain in the first regime $\gamma_1 \approx 1/2$ and $\delta_1 \approx 0.30$ (with $\delta_1 \approx \delta'_1$), and in the second regime $\gamma_2 = 0.37-0.40$ and $\delta_2 \approx 0.06-0.07$ (and again $\delta'_2 \approx 0.08$). In the case of the Glissando corpus in the first regime (binning size 23) $\gamma_1 \approx 0.1$ and $\delta_1 \approx 0.07$ (with $\delta_1 \approx \delta'_1$), and in the second regime $\gamma_2 = 0.405$ and $\delta_2 \approx 0.26$, and again $\delta_2 \approx \delta'_2 $. Results are similar for other bin sizes, as can be seen in Table \ref{exponents_tworegime}.\\

Finally, our experimental results show that the relationship (Eq.~\ref{eq:exponents}) between the three Zipfian exponents  \cite{Ferrer2017, Ferrer2016} is specially robust when we two regimes are assumed as expected from the higher precision in the estimation of the exponents. Again, $\delta$ and $\delta'$ deviate from previously reported for English, $\delta \approx 0.5$ \cite{Zipf_MFL,Ferrer2017, Ferrer2016}. $\delta'$ may deviate from the expected value because of the value of  $\alpha$ retrieved here for Catalan. Besides, $\delta$ may deviate from the expected value because of the two regime structure of the data.
Therefore, as a hypothesis to corroborate in future research employing  more languages, the variations in $\gamma$ or $\delta$ could be explained by deviations in Zipf's rank-frequency law or the underlying two regime structure reported here. \\

\subsection*{Two regimes in Zipfian laws: core vocabulary?}

In sum, although we have verified Zipf's meaning-frequency law (Eq.~\ref{eq:MFL_equation}) between the number of meanings and the frequency of words in Catalan employing Zipf's binning technique \cite{Zipf_MFL}, data is better-described when two regimes are assumed. 
These two scaling regimes could be explained simply as the outcome of aggregating texts: previous work indicate that scaling breaks in rank-frequency distributions are a consequence of the mixing and composition of texts and corpora \cite{Williams2015}.\\ 

Previous works showed that some variability was found in the breakpoints in the case of corpus of English, Spanish and Portuguese, depending on the size of the corpus \cite{Williams2015}. Here, for both corpora, we have seen that the breakpoint tends to increase with the size of the corpus and also with the size of the bin, and in the case of CTILC corpus ($167,079$ lemmas) the breakpoint varies from $20,606$ to $23,241$, and in Glissando corpus (4510 lemmas) from $333.5$ to $502.5$. Therefore, in the case of Catalan we have also seen this dependence with the size of the corpus. \\

In our opinion, as seen, the effects of corpus size, composition and he\-te\-ro\-ge\-neity previously suggested \cite{MONTEMURRO2001,Williams2015, Ferrer2005variation, baayen2001word} are not incompatible with the existence of a core and a peripheral vocabulary or "unlimited lexicon" \cite{ferrer2001two, GerlachAltmann2013}, but this dichotomy is not necessarily be an observable property of Zipfian distributions by means of the breakpoint as \cite{Williams2015} pointed out. Besides, if we understand the core vocabulary as the real basic vocabulary of a linguistic community at a given time, then Glissando turns out to be a better source than CTILC to capture that subset of the vocabulary, because CTILC corpus mixed sources from different time periods.\\

One the one hand, the CTILC written corpus includes from literary and journalistic texts to scientific ones, in a time interval of more than a century, with the diachronic variations that this implies. The sum of the size effect and the greater linguistic varia\-bi\-li\-ty of combining heterogeneous texts in the CTILC corpus could explain the appearance of two regimes in Zipf's rank-frequency law \cite{MONTEMURRO2001, Williams2015, montemurro2002new} and, as we have seen, consequently, of two regimes in the Zipf's meaning-frequency law. On the other hand, Glissando is a synchronous speech corpus in which the interlocutors cooperate and circumscribe themselves to a single communicative context, as is often promoted in the systematic \textit{design} of speech corpora \cite{garrido2013}. That is, to the usual reduction in the use of rare words that occurs in oral communication, in a pragmatic context with broad Gricean implications (see\cite{grice1975logic} and \cite{DAVIES2007} for a review), 
it must be added that in the construction of speech corpus like Glissando, literally communicative scenarios are 'designed' \cite{garrido2013}. This fact causes that we are not really facing a spontaneous speech corpus, causing a tendency to unify the vocabulary used by the different informants involved in or, at least, reducing the use of infrequent words. Infrequent words are typical of the peripheral vocabulary of multi-author corpus that deal with diverse topics. However, in the speech corpus a greater dispersion of the points in the meaning-frequency distribution is appreciated, but the two regimes are still found.\\

Lexical diversity is defined as the variety of vocabulary deployed in a text or transcript by either a speaker or a writer \cite{mccarthy2010}. In speech one expects to find a smaller lexical diversity and core vocabulary given the stronger cognitive constraints of spontaneous oral language (Glissando) with respect to written language (CTILC), to which the effects of the lemmatization are added here (see next subsection). Size effects have been shown to influence lexical diversity, even in small corpus \cite{koizumi2012effects}.\\

Therefore, other speech corpora of different size and spontaneous speech should be analysed in the future
to corroborate these two regimes observed,
exploring the size limits that had previously been considered for the appearance of a kernel vocabulary \cite{ferrer2001two}.  It also remains as future work to verify if these  effects are present in the comparison of spoken and written corpora of other languages and, in addition, if these two regimes appear in other languages, analogously to Catalan, in multi-author texts or whether they appear just as a consequence of text mixing \cite{Williams2015, petersen2012languages}, given the influence of semantics on Zipfian distributions \cite{piantadosi2014zipf,Carrera2021a}.\\

\subsection*{Lemmatization and binning effects}

Glissando is a corpus smaller in size than CTILC and with less thematic variability. However, the effect of binning seems to be added to the effect of corpus size. As Table~\ref{table_lemmas} shows, only the lemmas for which we had their meanings have been analyzed (intersection of each corpus with the DIEC2 dictionary). Thus, there is eventually an order of magnitude difference between the number of lemmas in both corpora (the intersection of CTILC corpus with DIEC2 has $52,578$ lemmas and the intersection of Glissando corpus with DIEC2 only $3,083$ lemmas). The quantitative effects of corpus size have been related to variations of Zipf's law and other linguistic laws in such a way that a larger size in a corpus implies increasing the probability of rare words, so that word frequency distributions are Large Number of Rare Events (LNRE) as \cite{baayen2001word} explain clearly. Thus, in the case of the speech corpus such as Glissando, smaller in size, also there is a smaller number of rare words, since fewer technical words and jargon are used in orality than in written corpus \cite{johansson2008lexical}, but the two regimes are nevertheless observed. The lemmatization process implies a decrease in the LNRE by including under the same lemma inflected words, of special importance in Catalan \cite{diccionari_1998}, as in other Romance languages \cite{kabatek2011romance, Montermini2010}.  \\ 

Regarding the deviations observed in the exponents of Zipf's rank-frequency law (Eq.~\ref{eq:word_frequency_law}) also found in other languages \cite{yu2018zipfs}, notice that by lemmatizing the corpus the morphological complexity and, by extension, the diversity of the vocabulary, is reduced. As explained in the introduction, Catalan is a Romance language with a rich inflection and derivation \cite{kabatek2011romance,clua2002,domenech_estopa_2011}, that, however, it does not stand out typologically compared to other languages in terms of indicators of entropy rate or phonological and morphological richness \cite{bentz2018adaptive,bentz2016, Bentzetal2017}. 

The robustness of Zipf’s law under lemmatization for single-author written texts was already checked in previous work studying Spanish, French and English with different methods \cite{Corral2015}. The exponent of lemmas and word forms may vary but both are correlated in texts \cite{Corral2015} and the same could happen in speech corpora. However, one could consider an opposite hypotheses that should be confirmed in future works, including more languages: that the lemmatization, as a source of reduction of morphological richness, should vary the exponent of Zipf's rank-frequency law \cite{Corral2015}, and this variation would depend on the inflectional and derivational complexity of the language (in the sense of Bentz's works \cite{bentz2018adaptive, Bentzetal2017, bentz2016}), that is, it will affect the languages with more morphological variability to a greater extent.\\ 

Following \cite{Chand2017} the $\alpha$ exponent of Zipf's rank-frequency law "reflects changes in morphological marking"\cite{Chand2017}, so that more inflection is correlated to a higher $\alpha$ and longer tail of hapax legomena \cite{bentz2018adaptive, Chand2017}. Comparing modalities, in our case orality shows a lower $\alpha$ than writing, contrary to \cite{Chand2017} but consider that here we follow different methods. Besides, it has been shown that there is variability in $\alpha$ related to both the text genre and the linguistic typology for languages of different linguistic families \cite{yu2018zipfs}. Future research should control for both effects (modality and morphological complexity) with corpora that are closer and employing   uniform methods.

Future work should clarify how factors such as corpus size, binning and linguistic variability, influence Zipf's meaning-frequency law.
The relationship between the exponents of the laws confirmed here for Catalan should be investigated for other languages. Our findings call for a revision of previous research of these laws assuming one regime.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%              FINAL DEL TEXT            %%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\ifarxiv	%%%% Si no és arxiv
\else
\section*{Supporting information}

\paragraph*{S1 Fig.}
\label{S1_Fig}

\textbf{Graphical representation of the different sources used.} % fig1

\paragraph*{S2 Fig.}
\label{S2_Fig}

\textbf{Zipf's rank-frequency law in CTILC Corpus.} % fig2

\paragraph*{S3 Fig.}
\label{S3_Fig}

\textbf{Zipf's rank-frequency law in Glissando Corpus.} % fig3

\paragraph*{S4 Fig.}
\label{S4_Fig}

\textbf{Zipf's law of meaning distribution in CTILC corpus.} % fig4

\paragraph*{S5 Fig.}
\label{S5_Fig}

\textbf{Zipf's law of meaning distribution in Glissando corpus.} % fig5

\paragraph*{S6 Fig.}
\label{S6_Fig}

\textbf{Zipf's meaning-frequency law in CTILC corpus.} % fig6

\paragraph*{S7 Fig.}
\label{S7_Fig}

\textbf{Zipf's meaning-frequency law in Glissando corpus.} % fig7

\paragraph*{S8 Fig.}
\label{S8_Fig}

\textbf{Breakpoint analysis for Zipf's rank-frequency law in CTILC corpus.} % fig8

\paragraph*{S9 Fig.}
\label{S9_Fig}

\textbf{Breakpoint analysis for Zipf's rank-frequency law in Glissando corpus.} % fig9

\paragraph*{S10 Fig.}
\label{S10_Fig}

\textbf{The meaning-frequency law in the CTILC and Glissando corpora.} % fig10

\paragraph*{S11 Fig.}
\label{S11_Fig}

\textbf{The law of meaning distribution in the CTILC and Glissando corpora.} % fig11

\fi	

\section*{Acknowledgements}

We are grateful to C. Bentz, J. M. Garrido, C. Santamaria, J. Rafel
and the technicians of Oficines Lexicogràfiques de 
l'Institut d'Estudis Catalans (Institute of Catalan Studies) for providing us with the data 
and helpful comments. This work has been funded by the projects PRO2020-S03 (RCO03080 Lin\-güís\-ti\-ca Quantitativa) and PRO2021-S03 HERNANDEZ from Institut d'Estudis Catalans. JB, RFC and AHF are also funded by the grant TIN2017-89244-R from Ministerio de Economia, Industria y Competitividad (Gobierno de España) and supported by the recognition 2017SGR-856 (MACDA) from AGAUR
(Generalitat de Catalunya).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{thebibliography}{51}

%\expandafter\ifx\csname natexlab\endcsname\relax\def\natexlab#1{#1}\fi
%\providecommand{\url}[1]{\texttt{#1}}
%\providecommand{\href}[2]{#2}
%\providecommand{\path}[1]{#1}
\providecommand{\DOIprefix}{doi:}
%\providecommand{\ArXivprefix}{arXiv:}
\providecommand{\URLprefix}{URL: }
\providecommand{\Pubmedprefix}{pmid:}
\providecommand{\doi}[1]{\href{http://dx.doi.org/#1}{\path{#1}}}
\providecommand{\Pubmed}[1]{\href{pmid:#1}{\path{#1}}}
\providecommand{\bibinfo}[2]{#2}
%\ifx\xfnm\relax \def\xfnm[#1]{\unskip,\space#1}\fi

%Type = Book
\bibitem{zipf1932selected}
\bibinfo{author}{G.~K. Zipf}, \bibinfo{title}{Selected studies of the principle
  of relative frequency in language}, \bibinfo{publisher}{Harvard University
  Press}, \bibinfo{year}{1932}.
  
%Type = Book
\bibitem{Zipf1935}
\bibinfo{author}{G.~K. Zipf}, \bibinfo{title}{The Psychobiology of Language, an
  Introduction to Dynamic Philology}, \bibinfo{publisher}{Houghton--Mifflin},
  \bibinfo{address}{Boston}, \bibinfo{year}{1935}.
  
%Type = Book
\bibitem{Zipf1949}
\bibinfo{author}{G.~K. Zipf}, \bibinfo{title}{Human Behavior and the Principle
  of Least Effort}, \bibinfo{publisher}{Addison--Wesley},
  \bibinfo{address}{Cambridge, MA}, \bibinfo{year}{1949}.
  
%Type = Article
\bibitem{RSOS2019}
\bibinfo{author}{I.~G. Torre}, \bibinfo{author}{B.~Luque},
  \bibinfo{author}{L.~Lacasa}, \bibinfo{author}{C.~T. Kello},
  \bibinfo{author}{A.~Hernández-Fernández},
\newblock \bibinfo{title}{On the physical origin of linguistic laws and
  lognormality in speech},
\newblock \bibinfo{journal}{Royal Society Open Science} \bibinfo{volume}{6}
  (\bibinfo{year}{2019}) \bibinfo{pages}{191023}.
  \DOIprefix\doi{10.1098/rsos.191023}.
  
%Type = Article
\bibitem{Zipf_MFL}
\bibinfo{author}{G.~K. Zipf},
\newblock \bibinfo{title}{The meaning-frequency relationship of words},
\newblock \bibinfo{journal}{Journal of General Psychology} \bibinfo{volume}{33}
  (\bibinfo{year}{1945}) \bibinfo{pages}{251--256}.
  \DOIprefix\doi{10.1080/00221309.1945.10544509}.
  
%Type = Article
\bibitem{Ferrer2017}
\bibinfo{author}{R.~{Ferrer-i-Cancho}}, \bibinfo{author}{M.~Vitevitch},
\newblock \bibinfo{title}{The origins of {Zipf's} meaning-frequency law},
\newblock \bibinfo{journal}{Journal of the American Association for Information
  Science and Technology} \bibinfo{volume}{69} (\bibinfo{year}{2018})
  \bibinfo{pages}{1369--1379}. \DOIprefix\doi{/10.1002/asi.24057}.
  
%Type = Article
\bibitem{Baayen2005}
\bibinfo{author}{R.~H. Baayen}, \bibinfo{author}{F.~M. del Prado~Martín},
\newblock \bibinfo{title}{Semantic density and past-tense formation in three
  {Germanic} languages},
\newblock \bibinfo{journal}{Language} \bibinfo{volume}{81}
  (\bibinfo{year}{2005}) \bibinfo{pages}{666--698}. \URLprefix
  \url{http://www.jstor.org/stable/4489969}.
  
%Type = Article
\bibitem{Ferrer2016}
\bibinfo{author}{R.~{Ferrer-i-Cancho}},
\newblock \bibinfo{title}{The optimality of attaching unlinked labels to
  unlinked meanings},
\newblock \bibinfo{journal}{Glottometrics} \bibinfo{volume}{36}
  (\bibinfo{year}{2016}) \bibinfo{pages}{1--16}. \URLprefix
  \url{http://hdl.handle.net/2117/102539}.
  
%Type = Book
\bibitem{LC_2019}
\bibinfo{author}{A.~{Hernandez Fernandez}},
  \bibinfo{author}{R.~{Ferrer-i-Cancho}}, \bibinfo{title}{Lingüística
  cuantitativa: la estadística de las palabras}, \bibinfo{publisher}{EMSE
  EDAPP / Prisanoticias}, \bibinfo{year}{2019}. \URLprefix
  \url{https://colecciones.elpais.com/literatura/118-grandes-ideas-de-las-matematicas.html}.
  
%Type = Article
\bibitem{condon1928statistics}
\bibinfo{author}{E.~U. Condon},
\newblock \bibinfo{title}{Statistics of vocabulary},
\newblock \bibinfo{journal}{Science} \bibinfo{volume}{67}
  (\bibinfo{year}{1928}) \bibinfo{pages}{300}.
  
%Type = Article
\bibitem{Carrera2021a}
\bibinfo{author}{D.~Carrera-Casado}, \bibinfo{author}{R.~F. i~Cancho},
\newblock \bibinfo{title}{The advent and fall of a vocabulary learning bias
  from communicative efficiency},
\newblock \bibinfo{journal}{https://arxiv.org/abs/2105.11519}
  (\bibinfo{year}{2021}).
  
%Type = Inproceedings
\bibitem{bond2019testing}
\bibinfo{author}{F.~Bond}, \bibinfo{author}{A.~Janz},
  \bibinfo{author}{M.~Maziarz}, \bibinfo{author}{E.~Rudnicka},
\newblock \bibinfo{title}{Testing {Zipf’s} meaning-frequency law with
  wordnets as sense inventories},
\newblock in: \bibinfo{booktitle}{Wordnet Conference}, \bibinfo{year}{2019}, p.
  \bibinfo{pages}{342}.
  
%Type = Article
\bibitem{Casas2019}
\bibinfo{author}{B.~Casas}, \bibinfo{author}{A.~Hernández-Fernández},
  \bibinfo{author}{N.~Català}, \bibinfo{author}{R.~{Ferrer-i-Cancho}},
  \bibinfo{author}{J.~Baixeries},
\newblock \bibinfo{title}{Polysemy and brevity versus frequency in language},
\newblock \bibinfo{journal}{Computer Speech and Language} \bibinfo{volume}{58}
  (\bibinfo{year}{2019}) \bibinfo{pages}{19 -- 50}.
  \DOIprefix\doi{10.1016/j.csl.2019.03.007}.
  
%Type = Inproceedings
\bibitem{pilsen}
\bibinfo{author}{A.~Hern{\'a}ndez-Fern{\'a}ndez}, \bibinfo{author}{B.~Casas},
  \bibinfo{author}{R.~{Ferrer-i-Cancho}}, \bibinfo{author}{J.~Baixeries},
\newblock \bibinfo{title}{Testing the robustness of laws of polysemy and
  brevity versus frequency},
\newblock in: \bibinfo{editor}{P.~Kr{\'a}l},
  \bibinfo{editor}{C.~Mart{\'i}n-Vide} (Eds.), \bibinfo{booktitle}{Statistical
  Language and Speech Processing}, \bibinfo{publisher}{Springer International
  Publishing}, \bibinfo{address}{Cham}, \bibinfo{year}{2016}, pp.
  \bibinfo{pages}{19--29}.
  
%Type = Inproceedings
\bibitem{Ilgen2007}
\bibinfo{author}{B.~Ilgen}, \bibinfo{author}{B.~Karaoglan},
\newblock \bibinfo{title}{Investigation of {Zipf’s} ‘law-of-meaning’ on
  {Turkish} corpora},
\newblock in: \bibinfo{booktitle}{22nd International Symposium on Computer and
  Information Sciences}, \bibinfo{year}{2007}, pp. \bibinfo{pages}{1--6}.
  \URLprefix \url{https://ieeexplore.ieee.org/document/4456846}.
  
%Type = Article
\bibitem{ferrer2001two}
\bibinfo{author}{R.~{Ferrer-i-Cancho}}, \bibinfo{author}{R.~Solé},
\newblock \bibinfo{title}{Two regimes in the frequency of words and the origins
  of complex lexicons: {Zipf’s} law revisited},
\newblock \bibinfo{journal}{Journal of Quantitative Linguistics}
  \bibinfo{volume}{8} (\bibinfo{year}{2001}) \bibinfo{pages}{165--173}.
  
%Type = Article
\bibitem{MONTEMURRO2001}
\bibinfo{author}{M.~A. Montemurro},
\newblock \bibinfo{title}{Beyond the {Zipf–Mandelbrot} law in quantitative
  linguistics},
\newblock \bibinfo{journal}{Physica A: Statistical Mechanics and its
  Applications} \bibinfo{volume}{300} (\bibinfo{year}{2001})
  \bibinfo{pages}{567 -- 578}.
  \DOIprefix\doi{https://doi.org/10.1016/S0378-4371(01)00355-7}.
  
%Type = Article
\bibitem{Williams2015}
\bibinfo{author}{J.~R. Williams}, \bibinfo{author}{J.~P. Bagrow},
  \bibinfo{author}{C.~M. Danforth}, \bibinfo{author}{P.~S. Dodds},
\newblock \bibinfo{title}{Text mixing shapes the anatomy of rank-frequency
  distributions},
\newblock \bibinfo{journal}{Phys. Rev. E} \bibinfo{volume}{91}
  (\bibinfo{year}{2015}) \bibinfo{pages}{052811}.
  \DOIprefix\doi{10.1103/PhysRevE.91.052811}.
  
%Type = Incollection
\bibitem{mandelbrot1966information}
\bibinfo{author}{B.~Mandelbrot},
\newblock \bibinfo{title}{Information theory and psycholinguistics: A theory of
  word frequencies},
\newblock in: \bibinfo{editor}{P.~F. Lazarsfield}, \bibinfo{editor}{N.~Henry}
  (Eds.), \bibinfo{booktitle}{Readings in mathematical social sciences},
  \bibinfo{publisher}{Cambridge: MIT Press}, \bibinfo{year}{1966}, pp.
  \bibinfo{pages}{550--562}.
  
%Type = Article
\bibitem{li2010fitting}
\bibinfo{author}{W.~Li}, \bibinfo{author}{P.~Miramontes},
  \bibinfo{author}{G.~Cocho},
\newblock \bibinfo{title}{Fitting ranked linguistic data with two-parameter
  functions},
\newblock \bibinfo{journal}{Entropy} \bibinfo{volume}{12}
  (\bibinfo{year}{2010}) \bibinfo{pages}{1743--1764}.
  
%Type = Incollection
\bibitem{kabatek2011romance}
\bibinfo{author}{J.~Kabatek}, \bibinfo{author}{C.~D. Pusch},
\newblock \bibinfo{title}{The {Romance} languages},
\newblock in: \bibinfo{editor}{B.~Kortmann}, \bibinfo{editor}{J.~Van~der
  Auwera} (Eds.), \bibinfo{booktitle}{The languages and linguistics of Europe:
  A comprehensive guide}, volume~\bibinfo{volume}{1},
  \bibinfo{publisher}{Walter de Gruyter}, \bibinfo{address}{Berlin},
  \bibinfo{year}{2011}, pp. \bibinfo{pages}{69--96}.
  
%Type = Book
\bibitem{bentz2018adaptive}
\bibinfo{author}{C.~Bentz}, \bibinfo{title}{Adaptive languages: An
  information-theoretic account of linguistic diversity}, volume
  \bibinfo{volume}{316}, \bibinfo{publisher}{Walter de Gruyter GmbH \& Co KG},
  \bibinfo{year}{2018}.
  
%Type = Article
\bibitem{Bentzetal2017}
\bibinfo{author}{C.~Bentz}, \bibinfo{author}{D.~Alikaniotis},
  \bibinfo{author}{M.~Cysouw}, \bibinfo{author}{R.~{Ferrer-i-Cancho}},
\newblock \bibinfo{title}{The entropy of words—learnability and expressivity
  across more than 1000 languages},
\newblock \bibinfo{journal}{Entropy} \bibinfo{volume}{19}
  (\bibinfo{year}{2017}). \URLprefix
  \url{https://www.mdpi.com/1099-4300/19/6/275}.
  \DOIprefix\doi{10.3390/e19060275}.
  
%Type = Inproceedings
\bibitem{bentz2016}
\bibinfo{author}{C.~Bentz}, \bibinfo{author}{T.~Ruzsics},
  \bibinfo{author}{A.~Koplenig}, \bibinfo{author}{T.~Samard{\v{z}}i{\'c}},
\newblock \bibinfo{title}{A comparison between morphological complexity
  measures: Typological data vs. language corpora},
\newblock in: \bibinfo{booktitle}{Proceedings of the Workshop on Computational
  Linguistics for Linguistic Complexity ({CL}4{LC})}, \bibinfo{publisher}{The
  COLING 2016 Organizing Committee}, \bibinfo{address}{Osaka, Japan},
  \bibinfo{year}{2016}, pp. \bibinfo{pages}{142--153}. \URLprefix
  \url{https://www.aclweb.org/anthology/W16-4117}.
  
%Type = Incollection
\bibitem{clua2002}
\bibinfo{author}{E.~Clua~Julve},
\newblock \bibinfo{title}{Gènere i nombre en els noms i en els adjectius},
\newblock in: \bibinfo{editor}{J.~Solà}, \bibinfo{editor}{M.~R. Lloret},
  \bibinfo{editor}{J.~Mascaró}, \bibinfo{editor}{M.~P. Saldanya} (Eds.),
  \bibinfo{booktitle}{Gramàtica del català contemporani (1)},
  \bibinfo{publisher}{Editorial Empúries}, \bibinfo{address}{Barcelona},
  \bibinfo{year}{2002}, pp. \bibinfo{pages}{485--534}.

%Type = Article
\bibitem{Montermini2010}
\bibinfo{author}{F.~Montermini},
\newblock \bibinfo{title}{The lexical representation of nouns and adjectives in
  {Romance} languages},
\newblock \bibinfo{journal}{Recherches linguistiques de Vincennes}
  \bibinfo{volume}{39} (\bibinfo{year}{2010}) \bibinfo{pages}{135--162}.
  \URLprefix \url{http://journals.openedition.org/rlv/1869}.
  \DOIprefix\doi{10.4000/rlv.1869}.
  
%Type = Article
\bibitem{domenech_estopa_2011}
\bibinfo{author}{O.~Domènech}, \bibinfo{author}{R.~Estopà},
\newblock \bibinfo{title}{La neologia per sufixació: anàlisi contrastiva
  entre varietats diatòpiques de la llengua catalana},
\newblock \bibinfo{journal}{Caplletra. Revista Internacional de Filologia}
  \bibinfo{volume}{51} (\bibinfo{year}{2011}) \bibinfo{pages}{9--33}.
  
%Type = Book
\bibitem{kohler2008quantitative}
\bibinfo{author}{R.~K{\"o}hler}, \bibinfo{author}{G.~Altmann},
  \bibinfo{author}{R.~G. Piotrowski}, \bibinfo{title}{Quantitative
  Linguistik/Quantitative Linguistics: ein internationales Handbuch/an
  international handbook}, volume~\bibinfo{volume}{27},
  \bibinfo{publisher}{Walter de Gruyter}, \bibinfo{year}{2008}.
  
%Type = Article
\bibitem{entropy2019}
\bibinfo{author}{A.~Hernández-Fernández},
  \bibinfo{author}{I.~González-Torre}, \bibinfo{author}{J.~Garrido},
  \bibinfo{author}{L.~Lacasa},
\newblock \bibinfo{title}{Linguistic laws in speech: the case of {Catalan} and
  {Spanish}},
\newblock \bibinfo{journal}{Entropy} \bibinfo{volume}{21}
  (\bibinfo{year}{2019}) \bibinfo{pages}{e21121153:1--e21121153:16}.
  \DOIprefix\doi{10.3390/e21121153}.
  
%Type = Article
\bibitem{CorralSerra2020}
\bibinfo{author}{A.~Corral}, \bibinfo{author}{I.~Serra},
\newblock \bibinfo{title}{The brevity law as a scaling law, and a possible
  origin of {Zipf’s} law for word frequencies},
\newblock \bibinfo{journal}{Entropy} \bibinfo{volume}{22}
  (\bibinfo{year}{2020}). \DOIprefix\doi{10.3390/e22020224}.
  
%Type = Article
\bibitem{petersen2012languages}
\bibinfo{author}{A.~M. Petersen}, \bibinfo{author}{J.~N. Tenenbaum},
  \bibinfo{author}{S.~Havlin}, \bibinfo{author}{H.~E. Stanley},
  \bibinfo{author}{M.~Perc},
\newblock \bibinfo{title}{Languages cool as they expand: Allometric scaling and
  the decreasing need for new words},
\newblock \bibinfo{journal}{Scientific reports} \bibinfo{volume}{2}
  (\bibinfo{year}{2012}) \bibinfo{pages}{943}.
  
%Type = Article
\bibitem{montemurro2002new}
\bibinfo{author}{M.~A. Montemurro}, \bibinfo{author}{D.~H. Zanette},
\newblock \bibinfo{title}{New perspectives on {Zipf’s} law in linguistics:
  from single texts to large corpora},
\newblock \bibinfo{journal}{Glottometrics} \bibinfo{volume}{4}
  (\bibinfo{year}{2002}) \bibinfo{pages}{87--99}.
  
%Type = Article
\bibitem{GerlachAltmann2013}
\bibinfo{author}{M.~Gerlach}, \bibinfo{author}{E.~G. Altmann},
\newblock \bibinfo{title}{Stochastic model for the vocabulary growth in natural
  languages},
\newblock \bibinfo{journal}{Phys. Rev. X} \bibinfo{volume}{3}
  (\bibinfo{year}{2013}) \bibinfo{pages}{021006}.
  \DOIprefix\doi{10.1103/PhysRevX.3.021006}.
  
%Type = Book
\bibitem{DIEC2}
\bibinfo{author}{I.~Institut~d’Estudis Catalans}, \bibinfo{title}{Diccionari
  de la llengua catalana}, \bibinfo{publisher}{Edicions 62: Enciclopèdia
  Catalana [1st ed. 1995], on line version in: http://dcc.iec.cat},
  \bibinfo{year}{2020}.
  
%Type = Inproceedings
\bibitem{Padro2012}
\bibinfo{author}{L.~Padr{\'{o}}}, \bibinfo{author}{E.~Stanilovsky},
\newblock \bibinfo{title}{Freeling 3.0: Towards wider multilinguality},
\newblock in: \bibinfo{booktitle}{Proceedings of the Eight International
  Conference on Language Resources and Evaluation (LREC)},
  \bibinfo{year}{2012}, pp. \bibinfo{pages}{2473--2479}. \URLprefix
  \url{http://www.lrec-conf.org/proceedings/lrec2012/summaries/430.html}.
  
%Type = Book
\bibitem{diccionari_1998}
\bibinfo{author}{J.~Rafel~i Fontanals}, \bibinfo{title}{Diccionari de
  freq{\"u}{\`e}ncies}, volume~\bibinfo{volume}{3},
  \bibinfo{publisher}{Institut d'Estudis Catalans},
  \bibinfo{address}{Barcelona}, \bibinfo{year}{1998}.
  
%Type = Article
\bibitem{garrido2013}
\bibinfo{author}{J.~M. Garrido}, \bibinfo{author}{D.~Escudero},
  \bibinfo{author}{L.~Aguila}, \bibinfo{author}{V.~Cardeñoso},
  \bibinfo{author}{E.~Rodero}, \bibinfo{author}{C.~de-la Mota},
  \bibinfo{author}{C.~González}, \bibinfo{author}{S.~Rustullet},
  \bibinfo{author}{O.~Larrea}, \bibinfo{author}{Y.~Laplaza},
  \bibinfo{author}{F.~Vizcaíno}, \bibinfo{author}{M.~Cabrera},
  \bibinfo{author}{A.~Bonafonte},
\newblock \bibinfo{title}{Glissando: a corpus for multidisciplinary prosodic
  studies in {Spanish} and {Catalan}},
\newblock \bibinfo{journal}{Language Resources and Evaluation}
  \bibinfo{volume}{47} (\bibinfo{year}{2013}) \bibinfo{pages}{945--971}.
  
%Type = Book
\bibitem{manning2008_introduction}
\bibinfo{author}{C.~D. Manning}, \bibinfo{author}{P.~Raghavan},
  \bibinfo{author}{H.~Sch\"{u}tze}, \bibinfo{title}{Introduction to information
  retrieval}, volume~\bibinfo{volume}{20}, \bibinfo{publisher}{Cambridge
  University Press}, \bibinfo{year}{2008}.
  
%Type = Book
\bibitem{baayen2008ald}
\bibinfo{author}{H.~Baayen}, \bibinfo{title}{{Analyzing linguistic data: A
  practical introduction to statistics using R}}, \bibinfo{publisher}{Cambridge
  University Press}, \bibinfo{year}{2008}.
  
%Type = Article
\bibitem{Ferrer2005variation}
\bibinfo{author}{R.~{Ferrer-i-Cancho}},
\newblock \bibinfo{title}{The variation of {Zipf’s} law in human language},
\newblock \bibinfo{journal}{The European Physical Journal B-Condensed Matter
  and Complex Systems} \bibinfo{volume}{44} (\bibinfo{year}{2005})
  \bibinfo{pages}{249--257}.
  
%Type = Article
\bibitem{Baixeries2013}
\bibinfo{author}{J.~Baixeries}, \bibinfo{author}{B.~Elvevåg},
  \bibinfo{author}{R.~{Ferrer-i-Cancho}},
\newblock \bibinfo{title}{The evolution of the exponent of {Zipf's} law in
  language ontogeny},
\newblock \bibinfo{journal}{PLOS ONE} \bibinfo{volume}{8}
  (\bibinfo{year}{2013}) \bibinfo{pages}{1--14}.
  \DOIprefix\doi{10.1371/journal.pone.0053227}.
  
%Type = Book
\bibitem{baayen2001word}
\bibinfo{author}{R.~Baayen}, \bibinfo{title}{Word Frequency Distributions},
  Text, Speech and Language Technology, \bibinfo{publisher}{Springer
  Netherlands}, \bibinfo{year}{2001}. \URLprefix
  \url{https://books.google.es/books?id=FWicxYWJP9sC}.
  
%Type = Incollection
\bibitem{grice1975logic}
\bibinfo{author}{H.~P. Grice},
\newblock \bibinfo{title}{Logic and conversation},
\newblock in: \bibinfo{booktitle}{Speech acts}, \bibinfo{publisher}{Brill},
  \bibinfo{year}{1975}, pp. \bibinfo{pages}{41--58}.
  
%Type = Article
\bibitem{DAVIES2007}
\bibinfo{author}{B.~L. Davies},
\newblock \bibinfo{title}{Grice's cooperative principle: Meaning and
  rationality},
\newblock \bibinfo{journal}{Journal of Pragmatics} \bibinfo{volume}{39}
  (\bibinfo{year}{2007}) \bibinfo{pages}{2308 -- 2331}.
  \DOIprefix\doi{https://doi.org/10.1016/j.pragma.2007.09.002}.
  
%Type = Article
\bibitem{mccarthy2010}
\bibinfo{author}{P.~M. McCarthy}, \bibinfo{author}{S.~Jarvis},
\newblock \bibinfo{title}{Mtld, vocd-d, and hd-d: A validation study of
  sophisticated approaches to lexical diversity assessment},
\newblock \bibinfo{journal}{Behavior research methods} \bibinfo{volume}{42}
  (\bibinfo{year}{2010}) \bibinfo{pages}{381--392}.
  
%Type = Article
\bibitem{koizumi2012effects}
\bibinfo{author}{R.~Koizumi}, \bibinfo{author}{Y.~In'nami},
\newblock \bibinfo{title}{Effects of text length on lexical diversity measures:
  Using short texts with less than 200 tokens},
\newblock \bibinfo{journal}{System} \bibinfo{volume}{40} (\bibinfo{year}{2012})
  \bibinfo{pages}{554--564}.
  
%Type = Article
\bibitem{piantadosi2014zipf}
\bibinfo{author}{S.~T. Piantadosi},
\newblock \bibinfo{title}{Zipf’s word frequency law in natural language: A
  critical review and future directions},
\newblock \bibinfo{journal}{Psychonomic Bulletin \& Review}
  \bibinfo{volume}{21} (\bibinfo{year}{2014}) \bibinfo{pages}{1112--1130}.
  
%Type = Article
\bibitem{johansson2008lexical}
\bibinfo{author}{V.~Johansson},
\newblock \bibinfo{title}{Lexical diversity and lexical density in speech and
  writing},
\newblock \bibinfo{journal}{Lund University, Department of Linguistics and
  Phonetics}  (\bibinfo{year}{2008}).
  
%Type = Misc
\bibitem{yu2018zipfs}
\bibinfo{author}{S.~Yu}, \bibinfo{author}{C.~Xu}, \bibinfo{author}{H.~Liu},
  \bibinfo{title}{Zipf's law in 50 languages: its structural pattern,
  linguistic interpretation, and cognitive motivation}, \bibinfo{year}{2018}.
  \href{http://arxiv.org/abs/1807.01855}{{\tt arXiv:1807.01855}}.
  
%Type = Article
\bibitem{Corral2015}
\bibinfo{author}{A.~Corral}, \bibinfo{author}{G.~Boleda},
  \bibinfo{author}{R.~{Ferrer-i-Cancho}},
\newblock \bibinfo{title}{Zipf’s law for word frequencies: Word forms versus
  lemmas in long texts},
\newblock \bibinfo{journal}{PLOS ONE} \bibinfo{volume}{10}
  (\bibinfo{year}{2015}) \bibinfo{pages}{1--23}.
  \DOIprefix\doi{10.1371/journal.pone.0129031}.
  
%Type = Article
\bibitem{Chand2017}
\bibinfo{author}{V.~Chand}, \bibinfo{author}{D.~Kapper},
  \bibinfo{author}{S.~Mondal}, \bibinfo{author}{S.~Sur}, \bibinfo{author}{R.~D.
  Parshad},
\newblock \bibinfo{title}{{Indian English} evolution and focusing visible
  through power laws},
\newblock \bibinfo{journal}{Languages} \bibinfo{volume}{2}
  (\bibinfo{year}{2017}). \URLprefix
  \url{https://www.mdpi.com/2226-471X/2/4/26}.
  \DOIprefix\doi{10.3390/languages2040026}.

\end{thebibliography}

\end{document}

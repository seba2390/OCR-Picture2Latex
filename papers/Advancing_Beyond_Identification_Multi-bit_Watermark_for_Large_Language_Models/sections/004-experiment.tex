
\subsection{Experimental Settings}
We use LLaMA-2-7B \citep{touvron2023llama} to generate sequences on the newslike subset of the Colossal Common Crawl Cleaned corpus (C4) dataset~\citep{raffel2020exploring} as the prompt for our main experiments following previous work~\citep{kirchenbauer2023watermark}. For watermarking and generation, we follow the configurations used in \citet{kirchenbauer2023reliability} unless otherwise denoted: bias $\delta=2.0$, greenlist ratio $\gamma=0.25$, which have shown a good trade-off between the detection performance and generation quality. Since $\gamma=0.25$, the number of colors $r$ is 4. We embed a random $b$-bit message onto $>$500 samples and report the mean metrics across samples.
When using the term `bit' or `bit-width', this denotes the initial message length and the effective message length is determined by $r$. When necessary, we also show the three standard error ranges. For list decoding, we compute a list size of 16 (in addition to the best prediction) unless otherwise noted, which corresponds to $6\mathrm{e}^{-2}$, $2\mathrm{e}^{-4}$, and $4\mathrm{e}^{-9}$ of the output space for 8-bit, 16-bit, and 32-bit, respectively. More details are in Appendix \ref{appendix:imp}.



\noindent\textbf{Metrics} To measure the performance of multi-bit watermarking, we use bit accuracy to measure how much of the embedded bits can be extracted without error. To compute the performance of list decoding, we take the closest message out of the candidates. We use area under the ROC curve (AUROC) for zero bit watermark detection using the z-statistics of the watermarked texts and human texts. For text quality, we use the automatic metrics used in \citet{kirchenbauer2023reliability} such as perplexity (PPL) using a larger oracle model (LLaMA-2-13B) and semantic similarity based on a paraphraser model \citep[P-SP]{wieting2022paraphrastic}. We further discuss the validity of the metrics in Appendix \ref{appendix:bit-acc-as-metric}.

\begin{wrapfigure}{R}{0.40\textwidth}
    \includegraphics{fig/quality-vs-bit.pdf}
    \caption{Text quality (PPL, P-SP) and encoding latency across bit widths. 3 standard errors are shown.}\label{fig:quality-vs-bit}
\end{wrapfigure}

% \begin{figure}
% \begin{minipage}[t]{.48\textwidth}
%     \centering
%     \includegraphics[width=\textwidth]{fig/quality-vs-bit.pdf}
%     % \includegraphics{fig/radix.pdf}
%     \subcaption{Text quality and latency (sec.) across Bit width@T=250,$\delta$=2}\label{fig:quality-vs-bit}

% \end{minipage}
% \hfill
% \begin{minipage}[t]{.48\textwidth}
%     \centering
%     \includegraphics[width=\textwidth]{fig/delta-vs-quality.pdf}
%     \subcaption{Text quality across bias@T=100,b=8}\label{fig:delta}
% \end{minipage}
% \caption{(a) Our multi-bit watermark affects text quality (measured by PPL and P-SP ) and latency only to an extent zero-bit watermarking does. Three standard error ranges are shown. (b) Analysis of text quality shows $\delta=2$ lies at a good trade-off point, and  In \ref{fig:delta}, the size indicates the magnitude of bias ($\{$1, 1.5 2, 3, 4, 5$\}$) and horizontal dashed lines indicate non-watermarked counterparts.}
% \end{figure}



\subsection{Results} \label{subsec:results}
\begin{comment}
We first discuss the impact of bit width on the text quality and latency. Then, we show the effectiveness of using multiple colorlists and list decoding. Next, we show how our watermark fares in the presence of corruption. Last, we demonstrate the real-world applicability of MPAC by showing its feasibility in embedding large message ($\geq$ 32 bits).
\end{comment}

We visualize the results as graphs in the main paper. Tables are in Appendix \ref{appendix:misc-results}.
    



% \begin{figure}[t]
%     \centering
%     \includegraphics{fig/main-clean.pdf}
%     \caption{Clean multi-bit performance for a fixed number of tokens (left) and fixed BPT (right).}
%     \vspace{-5mm}
%     \label{fig:main-clean}
% \end{figure}

\begin{figure}
    \centering
    \includegraphics{fig/main-clean.pdf}
    \caption{Clean multi-bit performance for a fixed number of tokens (left) and fixed BPT (right). 3 standard errors are shown.}\label{fig:main-clean}
    
    
\begin{minipage}[h]{0.79\textwidth}
    \centering
    \includegraphics[width=\textwidth]{fig/robustness.pdf}
    \vspace{-8mm}
    \subcaption{}\label{fig:robust-cp}
\end{minipage}
\hfill
\begin{minipage}[h]{0.2\textwidth}
    \centering
    \includegraphics[width=\textwidth]{fig/robustness-gpt.pdf}
    \vspace{-8mm}
    \subcaption{}\label{fig:robust-gpt}   
\end{minipage}
\vspace{-3mm}
\caption{Robust multi-bit performance for (a) copy-paste attack controlled by the human text percentage at T-250 and (b) paraphrasing attack using GPT-3.5 embedding 8-bit messages at varying token lengths. For (b), we show multiple sizes of list ($|L|\in$\{2, 4, 8, 16\}) by color gradation as 8-bit has relatively small output space.}
\label{fig:robust}
\vspace{-3mm}
\end{figure}

\noindent\textbf{Text quality is not affected by bit-width}. MPAC extends zero-bit watermarking by allocating tokens to message positions and partitioning vocabularies, which would otherwise be allocated to a single position and a single vocabulary partition. Consequently, given the same $\delta$ and $\gamma$, it only alters the text distribution to an extent that zero-bit watermarking does regardless of the bit-width. Indeed, our empirical results in Fig. \ref{fig:quality-vs-bit} demonstrate that the text quality is statistically indistinguishable across bit-widths. We also show that the encoding latency, which directly experiences user experience, does not increase with bit-width. Three standard error ranges are shown.

\noindent\textbf{Colorlisting improves multibit performance}. Through colorlisting, we can take advantage of the surplus vocabulary partitions. Fig. \ref{fig:main-clean} Left demonstrates the gain in the load capacity by using $r$=$4$ colorlists as opposed to $r$=$2$ given a fixed $\gamma$. We also show the results for $\gamma=.5$ and $r$=$2$. Besides the 8-bit case, which already achieves high accuracy, the performance of $\gamma$=$.25$, $r$=$4$ is statistically significant at p=$1\mathrm{e}^{-2}$ than the second runner-up. We further discuss the implications of varying $\gamma,r$ in Section \ref{sec:discussion}. For all bit-widths, the AUC's are $>.99$.

Next, we increase the number of tokens (T) and bit width accordingly to verify the effectiveness of embedding longer messages at a fixed bits per token. This resembles the scenario where the users generate longer sequences such as news articles or essays. While the message can be extracted up to 90\% accuracy up to 32-bit, the performance considerably falls for 64-bit. However, this can be partially compensated for by using list decoding as shown by the transparent bars. This boosts the bit accuracy to more than 95\% up to 32-bit. For 64-bit, the absolute performance gain is 3.0\% by generating merely 16 more candidate messages, which corresponds to roughly $1\mathrm{e}^{-20}$ of the total possible messages. Excluding the 8-bit case, whose AUC=$.988$, all the others have AUC $>.99$. 


\noindent\textbf{MPAC can maintain the watermark under corruption}. In the real world, a user may edit the generated text for better quality or in an attempt to evade the watermark. We study two types of attacks studied in the past work~\citep{kirchenbauer2023reliability}: \textit{copy-paste} mixes the watermarked text and human text and \textit{paraphrasing} uses another language model to paraphrase the watermarked text. Both attacks are realistic in that they do not maintain the start and end tokens of the watermarked text. The results in Fig. \ref{fig:robust}a demonstrate that for the copy-paste attack, the bit accuracy can be maintained to 90\%(80\%) for 8-bit (16-bit). Once again, list decoding is particularly effective, increasing the bit accuracy by 6.1\% absolute for the corrupted case. We also observed that longer messages tend to be more fragile against corruption, suffering more degradation in bit accuracy.


For paraphrasing, we use GPT-3.5.\footnote{We use the most challenging prompt found for zero-bit watermarking (shown in Table \ref{tab:robustness-gpt})} We found paraphrasing to be much more challenging than the copy-paste attack and thus, experimented with only 8-bit messages and increasing the token lengths (Fig. \ref{fig:robust}b). With T=$500$, the bit accuracy reaches nearly 80\% and with 16-list decoding, we are able to attain 90\% bit accuracy across all token lengths. More attacks are considered in Appendix \ref{appendix:dipper}.


\noindent\textbf{Detection performance is affected by bit-width.} 
To get a clearer picture of the detection performance, we compute AUC vs. the number of tokens observed in Fig. \ref{fig:detection} following \citet{kirchenbauer2023reliability}. We see that the detection performance decreases as the message bit is increased. This phenomenon is similarly observed in other works as the increase in the number of ``hypotheses" required to check leads to an increase in the false positive rate~\citep{fernandez2023stable}. We further discuss the reasons behind this in the subsequent section. Note, however, that a watermarked text with 32-bit message reaches AUC over 0.99 once observing 200 tokens. The true positive rates are shown in Appendix Table \ref{tab:tpr}.

\noindent\textbf{Across Model Scales, Datasets, Hash Schemes.} The results for larger models (13B, 70B) and other datasets are in Appendix \ref{appendix:misc-results}. To summarize, we found that text distributions with low entropy inherently have lower load capacity as observed similarly in \citet{lee2023wrote, kirchenbauer2023reliability}. We also present results for using another hash scheme with a longer context width in Appendix Table \ref{tab:fixedT} and \ref{tab:bpt}, which shows a similar level of performance.

% \begin{wrapfigure}{R}{0.4\textwidth}
%     \centering
%     \vspace{-3mm}
%     \includegraphics[width=0.4\textwidth]{fig/auc-at-t.pdf}
%     \caption{AUC@number of tokens observed for $b$=$\{0,8,16,24,32\}$. Darker colors denote larger bit-widths.}
%     \label{fig:detection}
%     \vspace{-8mm}
% \end{wrapfigure}



\begin{figure}
\begin{minipage}[t]{.32\textwidth}
    \centering
    \includegraphics[width=\textwidth]{fig/auc-at-t.pdf}
    % \includegraphics{fig/radix.pdf}
    \subcaption{}\label{fig:detection}
\end{minipage}
\begin{minipage}[t]{.32\textwidth}
    \centering
    \includegraphics[width=\textwidth]{fig/gamma-radix.pdf}
    \subcaption{}\label{fig:gamma-radix}
\end{minipage}
\begin{minipage}[t]{.32\textwidth}
    \centering
    \includegraphics[width=\textwidth]{fig/confidence-vs-error.pdf}
    \subcaption{}\label{fig:confidence-vs-error}
\end{minipage}
\vspace{-1mm}
\caption{(a) AUC@number of tokens observed for $b$=$\{0,8,16,24,32\}$. Darker colors denote larger bit-widths. (b) Zero-bit and multi-bit watermark performance for varying $\gamma$ and $r$ for 1000 samples at T=100,b=8. (c) Error rate as a function of confidence.}
\vspace{-4mm}
\end{figure}


\section{Discussions}\label{sec:discussion}
\vspace{-3mm}
\textbf{Load capacity and detection performance trade-off.} As noted above, embedding a longer message degrades the watermark detection performance. This is because computing the statistics involved finding the maximum cell value for each position. This overestimates the statistics of the non-watermarked human texts when assuming longer messages (Appendix Fig. \ref{fig:z-at-t}). One natural solution is to use a better statistic that models the maximum cell value of a multinomial distribution. Empirically, we found that this performed on par or even slightly worse compared to the current approach, which may be due to the approximation error when using a small sample size. We give a more detailed discussion on this in Appendix \ref{appendix:detection-analysis}. In practice, this limitation can be mitigated by using multi-bit watermarking in conjunction with other detection methods.  

% \begin{wrapfigure}{t}{0.4\textwidth}
%     \centering
%     \includegraphics[width=0.4\textwidth]{fig/gamma-radix.pdf}
%     \vspace{-5mm}
%     \caption{Zero-bit and multi-bit watermark performance for varying $\gamma$ and $r$ for 1000 samples at T=100,b=8.}
%     \label{fig:gamma-radix}
% \end{wrapfigure}

\noindent\textbf{Radix and Colorlist proportion} 
How does radix and colorlist proportion $\gamma$ influence multi-bit watermark performance? For $\gamma$=.125, the benefits of enlarging $r$ to 8 are saturated and show no statistical significance to $r$=4. While larger $r$ allows more tokens to be assigned to each position by reducing the effective length of the message, it challenges the problem by increasing the number of possible answers (digits) per position. Additionally, we observed that increasing radix trade-offs zero-bit performance for multi-bit performance. The observations are illustrated in Fig. \ref{fig:gamma-radix}. This tradeoff is further analyzed in Appendix \ref{appendix:detection-analysis}.

\noindent\textbf{List Decoding Ablation}
%Our list decoding algorithm outputs candidate messages in descending order of confidence starting from the most confident message. 
In Fig. \ref{fig:confidence-vs-error} we show a plot of bit error rate stratified by confidence. While not properly calibrated (over-estimation), having higher confidence definitely shows the error rate is lower. 
We also highlight the effectiveness of this technique by comparing it with randomly outputting candidate messages from scratch in Table \ref{tab:mic} in Appendix. We also observed that randomly altering a single position provides a good list as the best candidate message is already a good starting point. 
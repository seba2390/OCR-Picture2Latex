Watermarking has been studied in various types of multimedia such as image~\citep{potdar2005survey}, video~\citep{asikuzzaman2017overview}, audio~\citep{hua2016twenty}, and natural language~\citep{topkara2005natural}.
Following previous works~\citep{zhu2018hidden, luo2020distortion}, we use the term watermarking to denote embedding information into natural language in a manner that is robust against possible attacks given a watermarked text -- in our case, this is the output generated by a language model given the prompt. This differs from steganography, which focuses more on the undetectability of a secret message that is embedded in a multimedia~\citep{cheddad2010digital, tao2014robust}, which may be a completely arbitrary generated text for the purpose of carrying a secret message~\citep{fang2017generating}.  

Recently, methods relying on neural networks have shown progress in natural language watermarking, outperforming traditional methods that rely on rule-based watermarks~\citep{topkara2006hiding, topkara2006natural, atallah2001natural}. \citet{abdelnabi2021adversarial} proposed an end-to-end framework where a decoder network predicts the encoded message. \citet{yang2022tracing} improved upon the quality of the watermarked text by using an algorithmic approach. \citet{yoo2023robust} focused on robustness and capacity, outperforming previous works on the two aspects. However, since the proposed method works at the sentence-level, any addition or removal of a sentence will fail to extract the watermark. Moreover, these works cannot distinguish non-watermarked texts, making them unsuitable for distinguishing between machine text and human text.


Meanwhile, directly watermarking language models in a zero-bit manner during token generation has emerged as a promising approach for distinguishing language model outputs from human text~\citep{kirchenbauer2023watermark, openai-watermark} while achieving robustness against realistic attacks as it can reinforce the watermark every token~\citep{kirchenbauer2023reliability}. Several works have improved upon~\citet{kirchenbauer2023watermark}, e.g., in low entropy generation tasks such as code generation~\citep{lee2023wrote}, undetectability of the watermark~\citep{christ2023undetectable}, and its robustness~\citep{munyer2023deeptextmark}. We focus on extending the prior work for a more proactive counteraction towards identifying malicious users of language models by embedding \textit{any} information while maintaining the key advantages.


Concurrent to our work, \citet{fernandez2023three} propose a technique for encoding a multi-bit message by providing a message-specific greenlist through shifting the vocabulary list dependent on the message. Similarly, \citet{wang2023towards} use the message content as the hashing key before selecting the greenlist and further utilizes an auxiliary language model for enhancing text quality. Crucially, both works use the entire message content directly during embedding as input to the random seed generator, which requires computing through the exponential number of possible messages during decoding. This restricts the length of the message due to computational and/or memory limitations. To give a rough estimate of the required message length for encoding a user ID,  consider the POSIX \citep{posix} standard used when creating usernames in operating systems. 65 characters ($\sim$7 bits) are permitted by POSIX, meaning at least 35 bits are required to encode a username of 5 characters. Accordingly, works in image watermarking embeds messages easily over 32-bits~\citep{zhu2018hidden, zhao2023recipe, fernandez2023stable}. Our method differs from this in that each bit position is encoded independently, allowing the embedding of long messages without any added latency. 
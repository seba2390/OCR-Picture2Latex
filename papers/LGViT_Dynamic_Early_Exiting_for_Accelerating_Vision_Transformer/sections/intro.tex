\section{Introduction}
\label{sc:intro}

\begin{figure}
    \begin{center}
      \includegraphics[width=0.42\textwidth]{src/trade_off.pdf}
    \end{center}
    \vspace{-8pt}
    \caption{The comparison of performance and efficiency trade-off for the ViT backbone in CIFAR-100. LGViT significantly outperforms other early exiting methods. 
    In particular, LGViT achieves new state-of-the-art 89.1 \% accuracy but faster than ViT-EE \cite{ViT-EE}. Details are in Table \ref{tb:performance} and Section \ref{sc:peformance}. }
    \Description{Trade-off.}
    \vspace{-12pt}
    \label{fig:trade-off}
  \end{figure}

During the past few years, vision transformers (ViTs) have become fundamental backbones for various multimedia tasks due to their powerful performance and universal structures \cite{vit, DBLP:conf/mm/WuRWW022, tvformer}. 
With the development of 5G wireless networks and the artificial intelligence of things (AIoT), 
deploying ViTs on resource-constrained edge devices to enable real-time multimedia applications has become an appealing prospect. 
However, the high computational complexity of ViTs poses a significant challenge to deploy them on edge devices. 
For example, ViT-L/16 \cite{deit}, a typical ViT architecture for computer vision, 
requires over 180 giga FLOPs for inference and takes 56.79 milliseconds on an NVIDIA Jetson TX2 device to classify an image with $224\times 224$ resolution. 
Given that performance and quality-of-service (QoS) are critical for real-time multimedia systems, deploying such latency-greedy ViTs on resource-constrained edge devices is a challenging task.

Early exiting provides a feasible solution for accelerating the inference of neural networks by terminating forward propagation once the prediction from internal classifiers satisfies a certain criterion. 
While early exiting has been extensively studied for CNNs and transformer models in NLP, its application to ViTs remains an open problem. 
The main challenges in developing an efficient early exiting framework for ViTs can be condensed into three key aspects. 
Firstly, directly applying early exiting strategies on ViTs leads to substantial performance degradation. 
However, there has been no systematic investigation into what limits the performance. %of early exiting in ViTs. 
Secondly, minimizing the accuracy drop and further accelerating the inference of early exiting ViTs on edge devices is challenging. 
Lastly, in the training phase, internal classifiers lose considerable information from the final classifier, resulting in poor performance. 


Regarding the first challenge,
Kaya \textit{et al.} \cite{SDN} discovered CNNs can reach correct predictions before their final layer, 
and they introduced internal classifiers to mitigate the overthinking problem. 
Sajjad \textit{et al.} \cite{DBLP:journals/csl/SajjadDDN23} examined the impact of dropping layers in transformer models and found that lower layers are more critical for task performance. 
However, their analyses were limited to CNNs or transformer models and did not consider the constraints of early exiting methods in ViTs. 
Concerning the second challenge, a series of studies have introduced exiting criteria to determine when to terminate forward propagation \cite{PCEE, hash} or 
designed advanced backbone networks to balance performance and efficiency \cite{branchynet, ztw}. 
Although Bakhtiarnia \textit{et al.} \cite{ViT-EE} proposed an early exiting framework for ViT by incorporating additional backbone blocks as exiting heads, 
a considerable speed-up gap remains between these methods and the constraints imposed by mobile and edge platforms. 
It is advantageous to design efficient exiting heads for constructing early exiting ViTs with rich feature representations. 
In relation to the third challenge, 
distillation-based \cite{fastbert,self-distill} approaches provide a promising solution to help internal classifiers imitate the final classifiers. 
However, these methods are only available to the same early exiting head architectures. 


To remedy these limitations, we initially conduct probing experiments to examine the direct application of early exiting methods in ViTs. 
We discover that the performance of early exiting is constrained by: 
\textit{i)} inadequate feature representations in shallow internal classifiers; 
\textit{ii)} the weak ability to capture target semantic information in deep internal classifiers. 
Building on these insights, we then propose an efficient early exiting framework for general ViTs, termed LGViT, which accelerates inference while maintaining almost the same accuracy.
In LGViT, we incorporate heterogeneous exiting heads, specifically, the local perception head and global aggregation head, 
to generate early exiting ViT networks. 
The local perception head is attached to shallow exiting points to capture local information and learn sufficient feature representations. 
Conversely, the global aggregation head is connected to deep exiting points to extract global information, thereby enhancing the capture of target semantic feature. 
To the best of our knowledge, this is the first work to employ heterogeneous exiting heads for early exiting ViTs. 
Subsequently, we propose a novel two-stage training strategy for early exiting ViTs. 
During the first stage, we utilize an end-to-end method to help the backbone ViT achieve its full potential. 
In the second stage, we froze the parameters of backbone and solely update the exiting heads. 
Self-distillation between exiting heads is employed to minimize information loss. 
Lastly, we perform extensive experiments to validate the superiority of our proposed framework for accelerating ViT inference, 
achieving a good efficiency-accuracy trade-off for three ViT backbones on three datasets. 
For example, as shown in Figure \ref{fig:trade-off}, when ViT serves as the backbone, our method can accelerate the inference by 1.72 $\times$ with only 1.7 \% accuracy drop on the CIFAR-100 dataset. 

Our main contributions are summarized as follows:
\begin{itemize}
    \item We conduct a systematic investigation into the effectiveness of early exiting in ViTs and analyze the issues arising from the vanilla early exiting.
    \item We propose an efficient early exiting framework termed LGViT for general ViTs, incorporating heterogeneous exiting heads, \textit{i.e.}, 
    local perception head and global aggregation head, to achieve an efficiency-accuracy trade-off. 
    \item We develop a novel two-stage training strategy that facilitates learning among multiple heterogeneous exiting heads and significantly minimizes information loss.
    \item We perform extensive experiments on three widely-used datasets and representative ViT backbones, demonstrating the superiority of our proposed framework, 
    which achieves an average speed-up of 1.8 $\times$ with only 2\% accuracy sacrifice. 
\end{itemize}
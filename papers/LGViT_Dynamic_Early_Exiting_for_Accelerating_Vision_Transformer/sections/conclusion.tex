\section{Conclusion}
\label{sc:conclusion}

In this paper, we point out that naively applying early exiting in ViTs results in performance bottleneck due to insufficient feature representations in shallow internal classifiers and limited ability to capture target semantic information in deep internal classifiers. 
Based on this analysis, we propose an early exiting framework for general ViTs which combines heterogeneous exiting heads to enhance feature exploration. 
We also develop a novel two-stage training strategy to reduce information loss between heterogeneous exiting heads. 
We conduct extensive experiments for three ViT backbones on three vision datasets, 
demonstrating that our methods outperform other competitive counterparts. 
The limitation of our methods is to manually choose the exiting position and optimal exiting path. 
In the future, we intend to utilize Bayesian optimization to automatically perform the optimal exiting decision. 
\begin{figure}[t]
\vspace{-1em}
\begin{small}
\[\!\!\!\!\!
  \begin{array}{r@{~}c@{~}l@{}}
    \tau  & ::= & \kw{int} \mid \kw{unit} \mid \{\ls{\fd=\tau}\} \mid \kw{buf}~\tau \mid \alpha\\
    \lv   & ::= & x \mid n \mid () \mid \{\ls{\fd=\lv}\} \mid (b, n, \ls{\fd}) \\
    \lexp & ::= & \elet{x:\tau}{\ereadbuf {\lexp_1}{\lexp_2}}{\lexp} \mid \elet{\_}{\ewritebuf{\lexp_1}{\lexp_2}{\lexp_3}}{\lexp} \\
          & \mid &\elet{x}{\enewbuf{n}{(\lexp_1:\tau)}}{\lexp_2} \mid \esubbuf{\lexp_1}{\lexp_2}  \\
          & \mid & \elet{x:\tau}{\ereadstruct {\lexp_1}}{\lexp} \mid \elet{\_}{\ewritestruct{\lexp_1}{\lexp_2}}{\lexp} \\
          & \mid &\elet{x}{\enewstruct{(\lexp_1:\tau)}}{\lexp_2} \mid \estructfield{\lexp_1}{\fd}  \\
          & \mid &\withframe\;\lexp \mid \epop\;\lexp \mid \eif {\lexp_1}{\lexp_2}{\lexp_3} \\
          & \mid &\elet{x:\tau}{d\;\lexp_1}{\lexp_2} \mid \elet{x:\tau}{\lexp_1}{\lexp_2} \mid \{\ls{\fd=\lexp}\} \mid \lexp.\fd  \mid \lv \\
    \lp   & ::= &\cdot \mid \etlet{d}{\lambda y:\tau_1. \; \lexp : \tau_2}, \lp \\
\end{array} 
\]
\end{small}
\caption{\lamstar syntax}
\label{fig:lamstar-syntax}
\end{figure}

The meat of our formalization of \lowstar begins with \lamstar, a
first-order, stateful language, whose state is structured as a stack
of memory regions. It has a simple calling convention using a
traditional, substitutive $\beta$-reduction rule. Its small-step
operational semantics is instrumented to produce traces that record
branching and the accessed memory addresses. As such, our traces
account for side-channel vulnerabilities in programs based on the
program counter model~\cite{molnar05pcmodel} augmented to track
potential leaks through cache behavior~\cite{barthe-ccs2014}. We
define a simple type system for \lamstar and prove that programs
well-typed with respect to some values at an abstract type produce
traces independent of those values, e.g., our bigint library when
translated to \lamstar is well-typed with respect to an abstract type
of \lst$limb$s and leaks no information about them via their traces.

\paragraph{Syntax} Figure~\ref{fig:lamstar-syntax} shows the syntax
of \lamstar. A program $P$ is a sequence of top-level function
definitions, $d$. We omit loops but allow recursive function definitions.
%
Values $v$ include constants, immutable records, and buffers $(b, n, [])$ and mutable structures $(b, n, \ls{\fd})$
passed by reference, where $b$ is the address of the buffer or structure, $n$ is the
offset in the buffer, and $\ls{\fd}$ designates the path to the structure field to take a reference of (this path, as a list, can be longer than 1 in the case of nested mutable structures.)
%
Stack allocated buffers (\kw{readbuf}, \kw{writebuf}, \kw{newbuf}, and
\kw{subbuf}), and their mutable structure counterparts (\kw{readstruct}, \kw{writestruct}, \kw{newstruct}, $\structfield$), are the main feature of the expression language, along
with $\withframe\;\lexp$, which pushes a new frame on the stack for
the evaluation of $\lexp$, after which it is popped (using
$\epop\;\lexp$, an administrative form internal to the calculus).
%
Once a frame is popped, all its local buffers and mutable structures become inaccessible.

Mutable structures can be nested, and stored into buffers, in both cases without extra indirection. However, the converse is not true, as \lamstar currently does not allow arbitrary nesting of arrays within mutable structures without explicit indirection via separately allocated buffers. We leave such generalization as future work.

%% We expect function applications $d e$ to
%% be explicitly let-bound.


%% and immutable records
%% ($\{\ls{\fd=\lexp}\}$ and $\lexp.\fd$).

%% $\withframe\;\lexp$ models a C
%% block -- it pushes a new frame on the stack, and once $\lexp$ reduces
%% to a value, the frame is popped. More importantly, once a frame is
%% popped, all its local buffers also become inaccessible.


%% The \lamstar expression form $e$ is closer to the C
%% statement form with explicit \kw{let}-bindings.\ch{C has no explicit
%%   let bindings, but that's probably not what you mean}

%% We model stack
%% allocated buffers (\kw{readbuf}, \kw{writebuf}, \kw{newbuf}, and
%% \kw{subbuf}) and immutable records ($\{\ls{\fd=\lexp}\}$ and
%% $\lexp.\fd$). $\withframe\;\lexp$ models a C block -- it pushes a new
%% frame on the stack, and once $\lexp$ reduces to a value, the frame is
%% popped. More importantly, once a frame is popped, all its local
%% buffers also become inaccessible.\ch{Even more importantly should
%%   relate this to push\_frame and pop\_frame from the previous
%%   section. I guess that the Stack effect enforces that push\_frame and
%%   pop\_frame are balanced, thus you can replace them with
%%   with\_frame?}  


\paragraph{Type system} \lamstar types include the base
types \kw{int} and \kw{unit}, record types $\{\ls{\fd=\tau}\}$, buffer
types $\kw{buf}\;\tau$, mutable structure types $\kw{struct}\;\tau$, and abstract types $\alpha$.  The typing
judgment has the form, $\Gamma_P; \Sigma; \Gamma \vdash e : \tau$,
where $\Gamma_P$ includes the function signatures; $\Sigma$ is the
store typing; and $\Gamma$ is the usual context of variables. We elide
the rules, as it is a standard, simply-typed type system. The type
system guarantees preservation, but not progress, since it does not
attempt to account for bounds checks or buffer/mutable structure lifetime. However,
memory safety (and progress) is a consequence of \lowstar typing
and its semantics-preserving erasure to \lamstar.

\paragraph{Semantics} We define evaluation contexts $E$
for standard call-by-value, left-to-right evaluation order. The memory
$H$ is a stack of frames, where each frame maps addresses $b$ to a
sequence of values $\ls{v}$. The \lamstar small-step semantics
judgment has the form $P \vdash (H, \lexp) \rightarrow_{\trace}
(H', \lexp')$, meaning that under the program $P$, configuration $(H,
e)$ steps to $(H', e')$ emitting a trace $\trace$, including
reads and writes to buffer references or mutable structure references, and branching behavior, as
shown below.

\vspace{-0.5cm}
\[
\small
\begin{array}{rl}
\trace ::= \cdot \mid \kw{read}(b, n, \ls{\fd}) \mid \kw{write}(b,
n, \ls{\fd}) \mid \kw{brT} \mid \kw{brF} \mid \trace_1, \trace_2
\end{array}
\]

\begin{figure*}
  \small
  \begin{mathpar}
  \inferrule* [Right=WF]
  {
    %% H_1 = H; \{\} \quad e_1 = \epop\;\lexp
  }
  {
    \lp \vdash (H, \withframe\;\lexp) \rightarrow_{\cdot} (H;\{\}, \epop\;\lexp)
  }

\inferrule* [Right=Pop]
{
}
{
  \lp \vdash (H;\_, \epop\;\lv) \rightarrow_{\cdot} (H, \lv)
}

\inferrule* [Right=LIfF]
{
\;
}
{
  \lp \vdash (H, \eif{0}{\lexp_1}{\lexp_2}) \rightarrow_\brf (H, \lexp_2)
}

\inferrule* [Right=App]
{
  \lp(f)=\lambda y:\tau_1.\;\lexp_1:\tau_2
}
{
  \lp \vdash (H, \elet{x:\tau}{f\;v}{\lexp}) \rightarrow (H, \elet{x:\tau}{\lexp_1[v/y]}{e})
}

\inferrule* [Right=LRd]
{
  H(b, n+n_1, []) = \lv \\
  \trace = \kw{read}(b, n + n_1, [])
}
{
  \lp \vdash (H, \elet{x}{\ereadbuf{(b,n,[])}{n_1}}{\lexp}) \rightarrow_{\trace} (H, \lexp[\lv/x])
}

\inferrule* [Right=New]
{
  b \notin \kw{dom}(H;h) \quad   h_1 = h[b\mapsto \lv^n] \quad \lexp_1 = \lexp[(b, 0)/x] \\
 \trace = \kw{write}(b, 0), \dots, \kw{write}(b, n - 1)
}
{
  \lp \vdash (H;h, \elet{x}{\enewbuf{n}{(\lv:\tau)}}{\lexp}) \rightarrow_{\trace} (H;h_1, \lexp_1)
}

\end{mathpar}

\caption{Selected semantic rules from \lamstar}
\label{fig:lamstar-sem}
\end{figure*}

Figure~\ref{fig:lamstar-sem} shows selected reduction rules from
\lamstar.
%
Rule {\sc{WF}} pushes an empty frame on the stack, and rule {\sc{Pop}}
pops the topmost frame once the expression has been evaluated.
%
Rule {\sc{LIfF}} is standard, except for the trace $\kw{brF}$ recorded
on the transition.
%
Rule {\sc{App}} is a standard, substitutive $\beta$-reduction.
%
Rule {\sc{LRd}} returns the value at the $(n + n_1)$ offset in the
buffer at address $b$, and emits a $\kw{read}(b, n + n_1, [])$ event.
%
Rule {\sc{New}} initializes the new buffer, and emits write events
corresponding to each offset in the buffer.

\paragraph{Secret independence}
A \lamstar program can be written against an interface providing
secrets at an abstract type.
%
For example, for the abstract type \lst$limb$, one might augment the
function signatures $\Gamma_P$ of a program with an interface for the
abstract type $\Gamma_{\kw{limb}} =$
%
\lst@eq_mask : limb$^2$ -> limb@, and typecheck a source program
with free \lst$limb$ variables ($\Gamma =$ \lst$secret:limb$),
and empty store typing, using the judgment
%
$\Gamma_{\kw{limb}}, \Gamma_p; \cdot; \Gamma \vdash \lexp : \tau$.
%
Given any representation $\tau$ for \lst$limb$, an implementation for
\lst$eq_mask$ whose trace is input independent, and any pair of values
$v_0:\tau, v_1:\tau$, we prove that running $e[v_0/\text{\lst{secret}}]$ and $e[v_1/\text{\lst{secret}}]$
produces identical traces, i.e., the traces reveal no information
about the secret $v_i$. We sketch the formal development next, leaving
details to the appendix.

Given a derivation
%
$\Gamma_s, \Gamma_P; \Sigma; \Gamma \vdash e : \tau$, let $\Delta$ map
type variables in the interface $\Gamma_s$ to concrete types and let $P_s$ contain
the implementations of the functions (from $\Gamma_s$) that operate on
secrets.
%
To capture the secret independence of $P_s$, we define a notion of an
\emph{equivalence modulo secrets}, a type-indexed relation for values
($v_1 \equiv_{\tau} v_2$) and memories ($\Sigma \vdash H_1 \equiv
H_2$). Intuitively two values (resp. memories) are equivalent modulo
secrets if they only differ in subterms that have abstract types in
the domain of the $\Delta$ map---we abbreviate ``equivalent modulo
secrets'' as ``related'' below.
%
We then require that each function $f \in P_s$, when applied in
related stores to related values, always returns related results, while
producing \emph{identical} traces.
%
Practically, $P_s$ is a (small) library written carefully to ensure
secret independence.

Our secret-independence theorem is then as follows:

\begin{theorem}[Secret independence]
  Given
  \begin{enumerate}
  \item a program well-typed against a secret interface, $\Gamma_s$,
    i.e, $\Gamma_s, \Gamma_P; \Sigma; \Gamma \vdash (H, e) : \tau$,
    
  \item a well-typed implementation of the $\Gamma_s$ interface,
    $\Gamma_s; \Sigma; \cdot \vdash_{\Delta} P_s$, such that $P_s$ is
    equivalent modulo secrets,

  \item a pair $(\rho_1, \rho_2)$ of well-typed substitutions for $\Gamma$,
  \end{enumerate}
  
  then either:
  \begin{enumerate}
    \item 
      both programs cannot reduce further, i.e.
      $P_s, P \vdash (H, e)[\rho_1] \nrightarrow$
      and
      $P_s, P \vdash (H, e)[\rho_2] \nrightarrow$, or
    \item 
      both programs make progress with the same trace, i.e.
      there exists $\Sigma' \supseteq \Sigma, \Gamma' \supseteq \Gamma,
      H', e'$, a pair $(\rho_1', \rho_2')$ of well-typed substitutions
      for $\Gamma'$, and a trace $\trace$ such that

  \begin{enumerate}[i)]
  \item
         $P_s, P \vdash (H, e)[\rho_1] \rightarrow^{+}_{\trace} (H', e')[\rho'_1]$
         and
         $P_s, P \vdash (H, e)[\rho_2] \rightarrow^{+}_{\trace} (H', e')[\rho'_2]$, and
  \item  $\Gamma_s, \Gamma_P; \Sigma'; \Gamma' \vdash (H', e') : \tau$
  \end{enumerate}
  \end{enumerate}
\end{theorem}  
         
%% \Gamma'_f \vdash_{\Delta} \rho'_i$.
   

%%     , $i \in \{1, 2\}$. (2)
%% $\Sigma; \Gamma_s, \Gamma_f \vdash_{\Delta}
%% \rho_i$, (3) $P; \Sigma; G_s \vdash_{\Delta} P_s$, then 
%% \end{theorem}

%% It states that for any two substitutions of secret variables, $\rho_1$
%% and $\rho_2$, the output trace $\trace$ is the same, thereby
%% establishing the absence of secret-dependent side channels.


%% functions
%% who can ensure the \emph{fixed trace} property by manual audit.


%% We define a typed notion of \emph{secret independence} for $P_s$
%% relation means that the two values
%% (resp. memories) only differ in secrets.

%% We
%% provide the complete defintions in the appendix, but intuitively the
%% relation means that the two values (resp. memories) only differ in
%% secrets.

%% Then, we require that, $\forall d_s \in P_s$ s.t. $d_s:\tau_1
%% \rightarrow \tau_2 \in \Gamma_s$, if $(H_1, d_s~v_1)$ and $(H_2,
%% d_s~v_2)$ are well-typed, and $v_1 \equiv_{\tau_1} v_2$, $\Sigma
%% \vdash H_1 \equiv H_2$, then $\exists m, n, \trace, H'_1, v'_1, H'_2,
%% v'_2, \Sigma'$ s.t. $P, P_s \vdash (H_1, d_s~v_1)
%% \rightarrow^{m}_{\trace} (H'_1, v_1')$, $P, P_s \vdash (H_2, d_s~v_2)
%% \rightarrow^{n}_{\trace} (H'_2, v_2')$, $v'_1 \equiv_{\tau_2} v'_2$
%% and $\Sigma' \vdash H'_1 \equiv H'_2$.



%% In addition to the standard well-formedness conditions on each of
%% these, our theorem for secret-independent traces relies on a
%% \emph{fixed trace} property of the functions in $P_s$. We first define
%% an \emph{equivalent-modulo-secrets} relation for values ($v_1
%% \equiv_{\tau} v_2$) and memories ($\Sigma \vdash H_1 \equiv H_2$). We
%% provide the complete defintions in the appendix, but intuitively the
%% relation means that the two values (resp. memories) only differ in
%% secrets. Then, we require that, $\forall d_s \in P_s$ s.t. $d_s:\tau_1
%% \rightarrow \tau_2 \in \Gamma_s$, if $(H_1, d_s~v_1)$ and $(H_2,
%% d_s~v_2)$ are well-typed, and $v_1 \equiv_{\tau_1} v_2$, $\Sigma
%% \vdash H_1 \equiv H_2$, then $\exists m, n, \trace, H'_1, v'_1, H'_2,
%% v'_2, \Sigma'$ s.t. $P, P_s \vdash (H_1, d_s~v_1)
%% \rightarrow^{m}_{\trace} (H'_1, v_1')$, $P, P_s \vdash (H_2, d_s~v_2)
%% \rightarrow^{n}_{\trace} (H'_2, v_2')$, $v'_1 \equiv_{\tau_2} v'_2$
%% and $\Sigma' \vdash H'_1 \equiv H'_2$. In other words, when the
%% functions in $P_s$ are applied to equivalent-modulo-secret inputs,
%% then they terminate and produce a \emph{fixed} trace $\trace$
%% alongwith equivalent-modulo-secrets outputs. Practically, $P_s$ is a
%% (small) library written carefully by the experts who can ensure the
%% \emph{fixed trace} property by manual audit.

%% ; and let $\rho$ be a well-typed substitution for the variables
%% in $\Gamma$.

%% Our secret-independent traces theorem is then as follows:


%% The interface exposes (a)
%% type variables, as uninterpreted types for the secret variables, (b)
%% signatures of functions that operate on secrets, and (c) free
%% variables for secret values:

%% \vspace{-0.5cm}
%% \[
%% \begin{small}
%% \begin{array}{rl}
%% \Gamma_s ::= \cdot \mid \alpha \mid
%% d_s:\tau_1 \rightarrow \tau_2 \mid \Gamma_s, \Gamma'_s\;\;\;\;\;\;\;\;\Gamma_f ::= \cdot \mid x:\alpha, \Gamma_f
%% \end{array}
%% \end{small}
%% \]

%% The judgment has the standard form,
%% $P; \Sigma; \Gamma_s, \Gamma_f, \Gamma \vdash e : \tau$, where $\Sigma$
%% is the stack typing, and $\Gamma$ is the typing for free variables in
%% $e$ that are not secrets.\ch{What's $\Gamma_f$?}
%% We elide the rules, as it is a standard, simply-typed type system.

%% Let $\Delta$ map type variables in $\Gamma_s$ to a
%% concrete types, $\rho$ map secret variables in $\Gamma_f$ to
%% concrete values, and $P_s$ contain the implementations of the
%% functions (from $\Gamma_s$) that operate on secrets.

%% In addition to the standard well-formedness conditions on each of
%% these, our theorem for secret-independent traces relies on a
%% \emph{fixed trace} property of the functions in $P_s$. We first define
%% an \emph{equivalent-modulo-secrets} relation for values ($v_1
%% \equiv_{\tau} v_2$) and memories ($\Sigma \vdash H_1 \equiv H_2$). We
%% provide the complete defintions in the appendix, but intuitively the
%% relation means that the two values (resp. memories) only differ in
%% secrets. Then, we require that, $\forall d_s \in P_s$ s.t. $d_s:\tau_1
%% \rightarrow \tau_2 \in \Gamma_s$, if $(H_1, d_s~v_1)$ and $(H_2,
%% d_s~v_2)$ are well-typed, and $v_1 \equiv_{\tau_1} v_2$, $\Sigma
%% \vdash H_1 \equiv H_2$, then $\exists m, n, \trace, H'_1, v'_1, H'_2,
%% v'_2, \Sigma'$ s.t. $P, P_s \vdash (H_1, d_s~v_1)
%% \rightarrow^{m}_{\trace} (H'_1, v_1')$, $P, P_s \vdash (H_2, d_s~v_2)
%% \rightarrow^{n}_{\trace} (H'_2, v_2')$, $v'_1 \equiv_{\tau_2} v'_2$
%% and $\Sigma' \vdash H'_1 \equiv H'_2$. In other words, when the
%% functions in $P_s$ are applied to equivalent-modulo-secret inputs,
%% then they terminate and produce a \emph{fixed} trace $\trace$
%% alongwith equivalent-modulo-secrets outputs. Practically, $P_s$ is a
%% (small) library written carefully by the experts who can ensure the
%% \emph{fixed trace} property by manual audit.


%% \begin{figure}
%% \begin{footnotesize}
%% \[
%% \begin{array}{rl}
%% ev & ::= \symread\;(loc, \tau) \mid \symwrite\;(loc, \tau) \mid \brt \mid \brf \\
%% t & ::= ev ; \dots ; ev   \\
%% T & ::= t \mid ev ; \dots \\
%% beh & ::= \mathsf{Terminates} (t, n) \mid \mathsf{Diverges}(T) \mid \mathsf{GoesWrong}(t)
%% \end{array}
%% \]
%% \end{footnotesize}
%% \caption{Observable behaviors}
%% \label{fig:behaviors}
%% \end{figure}


%%   \lowstar is a first-order subset of \fstar that uses explicit memory operations and
%%   let-bindings to mimic C statements.
%% \tr{TODO: strengthen the link with EM\fstar, etc.}

%% The syntax of \lowstar is presented in
%% \fref{lamstar-syntax}. A \lowstar program is a sequence of
%% top-level function declarations. A \lowstar expression may be an
%% integer constant, the unit value, a variable, a local structure, a
%% structure field projection, a local binding, a conditional expression,
%% a (first-order) function application, a buffer read, a buffer write,
%% a buffer allocation, or the $\withframe$ special construct.

%% $\withframe$ is designed to mimic a C block: local buffers allocated
%% within a $\withframe$ (or block) go out of scope and out of life at
%% the end of the current $\withframe$, meaning the \emph{lifetime} of a
%% local buffer may extend beyond its lexical scope. $\withframe$ can be thought as
%% a pair of $\epush$ and $\epop$. $\epop$ arises during evaluation, but not in the
%% surface program.

%% \paragraph{Events and observable behaviors}

%% \jp{First sentence un-necessary?. Also the two bullet points seem redundant with
%% 3.0 above.}
%% We design the semantics of \lamstar with safety, functional
%% correctness and security in mind, through the notion
%% of \emph{observable behaviors}. In addition to termination or
%% divergence, the semantics collects a sequence of \emph{observable
%% events} all along an execution to model security guarantees :
%% \begin{itemize}
%% \item
%% For memory access noninterference, we need to account for the sequence
%% of all memory accesses produced by an execution, so we record each
%% memory access as an observable event bearing the nature of the memory
%% access (read or write), the memory location, and the number of bytes
%% (or the type of the value) read or written.
%% \item
%% For control flow noninterference, we need to account for the sequences
%% of branchings, i.e. which branch the program takes at each conditional
%% statement. So we record each such decision as an observable event
%% bearing the boolean result of the corresponding conditional test.
%% \end{itemize}

%% Thus, in the small-step semantics of \lamstar and \cstar, each
%% transition step produces a finite event trace, empty except at memory
%% accesses and branchings. Then, following CompCert \cite[\S 3.5]{xav},
%% we big-step the small-step semantics to obtain an observable behavior,
%% as summarized in Figure~\ref{fig:behaviors}, collecting all events
%% generated by an execution.

%% \begin{figure}
%% \begin{footnotesize}
%% \[
%% \begin{array}{rl}
%% ev & ::= \symread\;(loc, \tau) \mid \symwrite\;(loc, \tau) \mid \brt \mid \brf \\
%% t & ::= ev ; \dots ; ev   \\
%% T & ::= t \mid ev ; \dots \\
%% beh & ::= \mathsf{Terminates} (t, n) \mid \mathsf{Diverges}(T) \mid \mathsf{GoesWrong}(t)
%% \end{array}
%% \]
%% \end{footnotesize}
%% \caption{Observable behaviors}
%% \label{fig:behaviors}
%% \end{figure}

%% Thanks to those event traces, we easily characterize both security
%% properties at once:
%% \begin{definition}[Security]
%% A program is secure if, and only if, two executions of the same program
%% starting with different secrets produce the same observable behavior.
%% \end{definition}

%% Then, we need to prove that each pass of our extraction from \lamstar
%% to C preserves security. In the special case where a pass does not
%% change the memory layout and pointer values between the source and the
%% compiled code, it is enough to prove that observable behaviors are
%% exactly preserved. This is the case for some but not all of our
%% passes.

%% \paragraph{Semantics}
%% \jp{The $le'$ variant of expressions comes out of nowhere and jumps at the
%% reader when looking at the figure\ldots I find it confusing. Also, what was
%% wrong with Perry's style of having just one $le$ and saying that $lv$ and $pop$
%% are used only when reducing?}

%% Selected rules of the \lamstar semantics are shown in
%% Figure~\ref{fig:lamstar-sem}. The small-step semantics of \lamstar is
%% based on a reduction context to ensure a strict call-by-value
%% semantics with left-to-right evaluation of construct arguments.

%% A value is either a numerical constant, the unit value, or a pointer
%% value $(b, n, \ls{fd})$ where $b$ is a memory block containing an
%% array of local structures, $n$ is the array cell index, and $\ls{fd}$
%% is the path of structure fields to follow. The configuration is of the
%% form $(H, le')$ where $H$ is a stack of memory frames, each memory
%% frames containing memory blocks.  Reading (resp. writing) a value to
%% the stack produces a $\symread$ (resp. $\symwrite$) event. Similarly,
%% a conditional produces a $\brt$ (resp. $\brf$) event if the
%% conditional is true (resp. false). $\enewbuf{}{}{}$ allocates a new
%% memory block within the current (top-most) memory frame, and
%% initializes each array cell, hence producing a $\symwrite$ event per
%% cell. $\withframe$ creates a new memory frame, while $\epop$ discards
%% the top-most frame, making any pointers to this frame dangling.

%% \paragraph{Abstraction}

%% \tr{
%%   Aseem 2/2: noninterference proof.
%% }

\section{Introduction}

Cloud service developers today have a choice: they may prefer to control the provisioning, maintenance, and recovery of servers explicitly, or they may prefer a \emph{serverless} architecture where applications are layered on top of services that manage servers automatically. 

The term \emph{serverless} is often considered synonymous with \textit{Functions-as-a-Service} (FaaS), which was pioneered by Amazon~\cite{aws-lambda} and is now ubiquitous \cite{google-cloud-functions,azure-functions,openwhisk,fission}. In FaaS, a function is a piece of application code designed to respond to an individual event. Compared to a virtual machine or a compute instance, a function is significantly more fine-grained and can be scheduled for execution much faster on a pool of compute resources. Furthermore, FaaS platforms support per-invocation billing. This means that a service built on FaaS is not only highly available, but is both (1) very cheap to operate under low load, and yet (2) can scale automatically to a high load, at a proportional cost. Given the potential developer productivity boost that the serverless paradigm provides, it is anticipated to become increasingly prominent for cloud applications \cite{DBLP:journals/corr/abs-1902-03383,revolution}. 

Developing complex stateful serverless applications with FaaS is not straightforward, however, as it provides limited execution guarantees \cite{jangda-et-al}. For example, a function may be restarted many times before completing, and must complete within strict time limits. 
% \kk{However here is a bit awkward. I would remove it.}

Workflows have been identified by many~\cite{sreekanti2020cloudburst,eismann2020predicting,azure-durable-functions,step-functions,scientific-workflows} to be the missing link to enable the development of full-featured serverless applications.
%\footnote{In fact, about \hl{one in two Azure Functions developers} use Durable Functions to create workflows.}. \seb{We don't have real confirmation for this, I asked Chris}
What differentiates workflows from simple function composition is that they provide stronger execution guarantees. Unfortunately, developing workflows for a serverless environment still poses significant performance and programmability challenges. We now discuss these challenges and how we address them.
% \str
% \kk{A thing that we don't do in this intro is that we don't motivate the "reliable" aspect of workflows. Could we add here that workflows now are popular but there are several challenges (including performance ones) that do not allow for their broader use. We can motivate that with chatroom applications, taxi applications, banking applications (that require both low latencies and reliability). Then we can say that our solution addresses these challenges by achieving the best of both worlds reliability and high performance) enabling developers by not forcing them to choose one of the two.}

% It is not the serverless functions by themselves that interest us here. Rather, it is the practice of composing such functions with other services, such as queues or storage, to create event-driven applications and workflows. Given the potential developer productivity boost of the serverless paradigm, it is widely anticipated to become increasingly prominent for cloud and edge applications \cite{DBLP:journals/corr/abs-1902-03383,revolution}. Yet, we are only at the beginning of this change, and much work remains to be done. We now discuss several challenges we identified, and how we solve them.

\paragraph{Workflows as Code.}
%
Workflows have been used for several decades, in various shapes and forms.
One approach is \emph{unstructured composition}, where all control flow is explicit. For example, \emph{triggers} are a common composition primitive for FaaS: to sequence two functions, the first function can write to a file or queue, which then triggers the execution of a second function. Two major drawbacks of unstructured composition are (i) that it doesn't support all forms of composition, such as value aggregation, and (ii) that the control flow is dispersed over many places, reminiscent of "spaghetti code". Another approach is \emph{structured composition}, where the system provides higher-level control flow abstractions, such as sequencing, sequential and parallel iteration, and error handling. Structured composition is often achieved through restricted declarative schemas, such as XML~\cite{shegalov2001xml}, JSON~\cite{step-functions}, or visual design tools~\cite{azure-logic-apps}.
% \str
% \kk{We need to do a better job explaining why this is a challenge. After all, as we mentioned before, here we describe challenges so we should make sure that the issues of the existing approaches come clear. I would say that the issue with unstructured composition is twofold: (i) it doesn't support arbitrary composition (fan-in is not possible(?)), and (ii) control flow is explicit, and the application logic is all over the place. Then the issue with declarative solutions for structured composition (XML, JSON) is that they are restricted and they ignore years of research and progress in programming languages.}

In contrast, Durable Functions (DF), our proposed programming model, achieves structured composition expressed \emph{as code}, in a standard programming language of choice (such as  JavaScript, Python, C\#, or PowerShell). The benefit over declarative approaches is that DF workflows can take advantage of all the familiar control flow abstractions and the ecosystem of libraries and tools of a mature host language. 
DF persists the intermediate state of a workflow using record and replay.
% \hide{
% \kk{I am not sure I like calling this a magic trick. Also I think that a better place to mention that would be in the paragraph below (after explaining the computation model).}
% \dajusto{That would make sense, but I don't feel strongly. If you do end up making this change, I suggest we mention at the start of the next section. It could read like: "To incorporate state, the programming model persists DF's intermediate workflow states indirectly, using record and replay. In order to keep the engine implementation separate from the programming model, we propose a ..."}
% \dajusto{Also, is this section about the computation model or the (Netherite) engine? I suppose that, if we squint our eyes, they can be one and the same}
% }
\hide{
Therefore, it does require developers to keep the orchestration code deterministic (to avoid divergence during replay) and of bounded length.
% \kk{Is this the right place to discuss this specific limitation? I would move it in the 3rd section.}
% \seb{I think it is needed since we are comparing approaches and calling out the weaknesses of the others.}
}

\paragraph{Serverless Computation Model.}

In order to keep the engine development separate from the programming model we propose a computation model that contains two simple "serverless primitives": \emph{stateless tasks} and \emph{stateful instances}. This acts as an interface between the programming model and the execution engine: DF is translated into the computation model by encoding workflows as stateful instances, and \sys implements it. This separation allows independent experimentation on the programming or the engine part---in fact, we benefited from this separation since \sys was built as a replacement for the existing Durable Functions implementation. The model is also designed to facilitate elasticity: tasks and instances are both fine-grained and communicate via messages, which makes it possible to dynamically load-balance them over an elastic cluster.

% To keep the execution engine lean, we internally break the application logic down into just two "serverless primitives": \emph{stateless tasks} and \emph{stateful instances}. This helps us to manage complexity and provides a clean separation of concerns: we can investigate, improve, or replace the engine implementation and the programming model independently. For example, it is possible to implement the Step Functions API on top of the Netherite engine. The computation model is designed to facilitate elasticity: tasks and instances are both fine-grained and communicate via messages, which makes it possible to dynamically load-balance them over an elastic cluster.
% \str
% \kk{I believe that the challenge is not clear in this paragraph. IMO the challenge lies in that several existing solutions try to implement workflows (or stateful Faas) by bolting them on top of an existing language front-end. This is not extensible and would require a reimplementation for all languages. To be honest, I am not even sure if this is a challenge that will convince Systems people so we might have to drop it and just name this as a contribution (or at the end of the introduction (before evaluation) where we could give a brief overview of our solution).}

\paragraph{Causally Consistent Commit.}

A common challenge for workflow systems is to articulate a reliability guarantee that is strong, easy to understand for programmers, and efficiently implementable. To this end, we define a guarantee called \emph{causally consistent commit} (CCC) using execution graphs. It is stronger than "at-least-once" or "effectively-once", and more realistic than "exactly-once". In essence, it guarantees atomicity: a step that fails is \emph{aborted}, along with all steps that causally depend on it. 
\hide
{
\kk{Maybe replace more concrete with more realistic? I guess that we want to argue that it is more efficiently implementable (in contrast to exactly once which is not implementable at all in general).} 
\seb{agreed.}
\kk{I think that calling them not sufficiently precise or comprehensive is not totally true. There must be more precise definitions of such terms. Instead I think that we need to focus on the fact that effectively once lies somewhere in between exactly once and at-least-once, being both strong, but also achievable in practice without huge overheads. Our contribution is essentially identifying this gap between the two, formulating a guarantee that strikes a nice balance.}
}

\paragraph{Batch Commit.}

In order to guarantee reliability, workflow solutions need to persist workflow steps in storage. This is commonly achieved by persisting the state and steps of each workflow individually\footnote{This is the case with unstructured composition, as well as the existing DF implementation.}, creating a throughput bottleneck due to the limited number of I/O operations storage can handle per second.
To avoid this problem, we designed \emph{\sys} so it can persist many steps, by different workflow instances, using a single storage update. This is achieved by grouping the fine-grained instances and tasks into partitions. Each partition can then persist a batch of steps efficiently by appending it to its commit log in cloud SSD storage.

\paragraph{Speculation Optimizations. } 

A conservative workflow execution engine would wait until a step is persisted before proceeding with the next step. This introduces a significant latency overhead since storage accesses are on the critical execution path. We show that with careful \emph{local} and \emph{global} speculation, \sys moves these storage accesses off the critical path, significantly reducing latency, while still providing the CCC guarantee.\str
% \kk{It might be a good idea to connect this too with the effectively once. A conservatice implementation has to wait exactly because it want to guarantee something closer to "exactly-once" while we argue that it is fine to aim for a slightly weaker guarantee for these dramatic performance improvements.}


\paragraph{Elastic Partition Balancing.} 

\sys uses a fixed number of partitions (32) that communicate via a reliable ordered queue service. It can move individual partitions between nodes, by persisting and then recovering their state on a different node. In particular, it can re-balance the partitions as needed. For example, on a one-node cluster, all 32 partitions are loaded on a single node. On a four-node cluster, each node has eight partitions, and so on, up to 32 nodes with one partition each. \sys can also scale to zero if the application is idle: on a zero-node cluster, all partitions reside in cloud storage.

\paragraph{Evaluation.} 

Our evaluation on five workflows, two of which are taken from real applications, indicate that the DF programming model offers significant benefits regarding development effort. 
% Our evaluation on three micro-benchmarks and two workflow case studies indicate that the DF programming model is more expressive than others. 
% \str
% \kk{I am not very fond of the name microbenchmarks. We could say that Our evaluation on 5 workflows (two of which are taken from real applications)...}
In particular, the availability of general loops, exception handling, and functional abstraction (provided by the host language) greatly improve the experience when dealing with complex workflows. 

Yet, the benefits are not limited to the developer experience: the execution performance with Netherite is better than with common serverless alternatives, \emph{across the board}. For instance, Netherite orchestrations outperform  trigger-based composition by orders of magnitude, both on AWS and Azure. They also exhibit better throughput and latency than the current Durable Functions production implementation, by an order of magnitude in some situations. Finally, a workflow composing AWS lambdas completes faster in \sys (deployed in Azure and invoking lambdas through HTTP) rather than in Step Functions (deployed in AWS and invoking lambdas directly). 
% \kk{I moved this sentence last as it hits the hardest!}

\subsection{Contributions}
 
We make the following contributions:

\begin{itemize}
\item We introduce the Durable Functions Programming Model, which allows code-based structured expression of workflows in multiple languages (\S\ref{sec:durablefunctions}).
\item We demonstrate how to break down complex workflows into just two serverless primitives, and define the causally-consistent-commit guarantee (\S\ref{sec:model}).
\item We provide an architecture and implementation that realize these concepts (\S\ref{sec:netherite}) and demonstrates the power of speculation optimizations (\S\ref{sec:optimizations}).
\item We evaluate the Durable Functions programming model and \sys implementation on several benchmarks and case studies, comparing it to commonly used serverless composition techniques (\S\ref{sec:evaluation}).
\end{itemize}
%
% \seb{put summary here: model & perf enable full-featured complex serverless applications.}
%
Overall, our contributions bring the development of complex full-fledged serverless applications within reach: providing cloud developers with (i) Durable Functions, a mature programming environment that allows them to have their application in one place; and (ii) \sys, an efficient execution engine that provides strong reliability guarantees.
% \str
% \kk{Maybe say that it is a step towards that direction and not that it \textbf{makes the development possible}.}
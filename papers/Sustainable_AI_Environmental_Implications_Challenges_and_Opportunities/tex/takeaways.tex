\section{Key Takeaways}
\label{sec:takeaways}

%Advances in AI are currently driven by AI research that seeks to improve accuracy (or related measures) through the use of massive computational power while disregarding physical resource requirements. 

\textbf{The Growth of AI:} Deep learning has witnessed an exponential growth in training data, model parameters, and system resources over the recent years (Figure~\ref{fig:data-model-system-growth}).
The amount of data for AI has grown by $2.4\times$, leading to $3.2\times$ increase in the data ingestion bandwidth demand at \fb.
%To learn valuable information from the data, model sizes for a variety of ML tasks have also increased to achieve higher model quality. 
\fb's recommendation model sizes have increased by $20\times$ between 2019 and 2021.
The explosive growth in AI use cases has driven $2.9\times$ and $2.5\times$ capacity increases for AI training and inference at Facebook over the recent 18 months, respectively.
The environmental footprint of AI is staggering (Figure~\ref{figure:cf-characterization}, Figure~\ref{figure:ops-vs-embodied}).

    
\textbf{A Holistic Approach:} To ensure an environmentally-sustainable growth of AI, we must consider the AI ecosystem holistically going forward.
We must look at the machine learning pipelines end-to-end --- data collection, model exploration and experimentation, model training, optimization and run-time inference (Section~\ref{sec:model-life-cycle-analysis}). 
The frequency of training and scale of each stage of the ML pipeline must be considered to understand salient bottlenecks to sustainable AI.
From the system's perspective, the life cycle of model development and system hardware, including \textit{manufacturing} and \textit{operational use}, must also be accounted for. 

\textbf{Efficiency Optimization:} 
%\textcolor{blue}{summarize Section 3. 
Optimization across the axes of algorithms, platforms, infrastructures, hardware can significantly reduce the operational carbon footprint for the Transformer-based universal translation model by $810\times$. Along with other efficiency optimization at-scale, this has translated into 25.8\% operational energy footprint reduction over the two-year period. 
%Optimization is an iterative process. 
\textit{More must be done to bend the environmental impact from the exponential growth of AI} (Figure~\ref{fig:jevon-paradox} and Figure~\ref{figure:server-utilization}).

\textbf{An Sustainability Mindset for AI:} Optimization beyond efficiency across the software and hardware stack at scale is crucial to enabling future sustainable AI systems.
To develop AI technologies responsibly, we must achieve competitive model accuracy at a fixed or even reduced computational and environmental cost. We chart out potentially high-impact research and development directions across the \textit{data}, \textit{algorithms and model}, \textit{experimentation} and \textit{system hardware}, and \textit{telemetry} dimensions for AI at datacenters and at the edge (Section~\ref{sec:optimization-opportunities}). 

We must take a deliberate approach when developing AI research and technologies, considering the environmental impact of innovations and taking a responsible approach to technology development~\cite{wu:arxiv:2021}. That is, we need AI to be green and environmentally-sustainable.

%\fb has the opportunity to lead the industry in creation of environmentally responsible AI. 
%We will drive towards this goal through: 
%\begin{enumerate}
%    \item transparent reporting of metrics of the broader energy and carbon %footprints of ML in both research and production settings
%    \item community building through external partnerships to drive organic shift towards efficiency mindset
%    \item incentive mechanisms to encourage reduction in resources
%    \item internal dogfooding to drive down cost and demonstrate benefits of developing AI in an environmentally responsible manner.
%\end{enumerate}

%---------------------------------------------------------------------------------------------------------------
% 1.) fast multipole method for the observation process
%---------------------------------------------------------------------------------------------------------------
% a) FMM efficiently approximated the action of the observation process or its adjoint on a suitable vector
% book:Gibson2014, Chapter 9: The Fast Multipole Method
% - The most classic example of the N-BODY PROBLEM is
%   the MOTION OF CELESTIAL OBJECTS INTERACTING WITH EACH OTHER GRAVITATIONALLY. (p. 329)
% - A SUCCESSFUL APPROACH IN REDUCING THE COMPLEXITY OF THE N-BODY PROBLEM was introduced by Greengard and Rokhlin in [1], and
%   IS CALLED THE FAST MULTIPOLE METHOD (FMM). (p. 329)
%   [1] article:Greengard1987: A fast algorithm for particle simulations
% - Thus, the FMM ALLOWS FOR GROUPING TOGETHER MANY NEARBY PARTICLES and TREATING THEM AS IF THEY ARE A SINGLE PARTICLE. (pp. 329, 330)
% book:Gibson2007, Chapter 8: The Fast Multipole Method
% - The fast multipole method (FMM) is a numerical algorithm introduced by Greengard and Rokhlin [1] for
%   reducing the computational complexity of this (N-body) problem. (p. 209)
% - When applied to vector electromagnetic problems, the interactions between well-separated groups of basis functions can
%   be evaluated very quickly. (p. 209)
% - This allows for a rapid calculation of the matrix-vector product in an iterative solver without
%   needing to store many of the matrix elements. (p. 209)
% - This increase in speed and reduction in memory allows us
%   to solve existing problems much faster, as well as
%   solve problems that could not have been attempted before. (p. 209)
% article:DongarraCompSE2000: Guest Editors Introduction to the top 10 algorithms
% - The Fast Multipole Algorithm was developed originally to calculate gravitational and electrostatic potentials.
% - The method utilizes techniques to quickly compute and combine the pair-wise approximation in O(N) operations.
% - This has led to a significant reduction in the computational complexity from O(N²) to O(N log N) to O(N) in certain important cases.
% article:ChewITAP1997: Fast solution methods in electromagnetics
% III. INTEGRAL EQUATION SOLVERS
% - Many researchers have attempted to reduce the complexity of the traditional MoM algorithm by reducing
%   the computational labor of the pertinent matrix–vector multiplies. (p. 535)
% - For surface scatterers, Rokhlin [44] proposed the fast-multipole method (FMM) to reduce
%   the computational complexity of matrix–vector multiplies in an iterative method. (p. 535)
%   [44] article:Rokhlin
% - For volumetric scatterers, several recursive and nesting algorithms have been developed to directly obtain
%   the solutions of integral equations for all right-hand sides [14]–[17]. (p. 535)
% VI. FAST MULTIPOLE METHOD
% - For surface structures, there exists no direct solver with
%   reduced computational complexity for efficiently solving the integral equation of scattering. (p. 538)
% - Therefore, one resorts to an iterative solver whereby the computational complexity of a matrix–vector multiply can be reduced. (p. 538)
% - Many methods for expediting matrix–vector multiplies have been proposed, but
%   the FMM and its variants [44], [45], [85]–[92] hold most promise in providing
%   a fast method that applies to scatterers of arbitrary geometry. (p. 538)
% article:CoifmanIAPM1993: The Fast Multipole Method for the Wave Equation: A Pedestrian Prescription
% 2. Basics / 2.2 Time-independent scattering and the Method of Moments
% - The FMM provides a prescription for the rapid computation of the matrix-vector product (4),
%   for an arbitrary vector I. (p. 8)
% - This rapid computation can then be used in an iterative (e.g., conjugate-gradient) solution of
%   the discretized integral equation Z * I = V, where, for an incident wave with wave vector k, (5). (p. 8)
The \ac{FMM}
(cf. e.g.
\cite[Chapt. 9]{book:Gibson2014},
\cite{article:CoifmanIAPM1993,article:RokhlinJCP1990}%
) efficiently approximated
the action of
% 1.) observation process (all pulse-echo measurements, multifrequent, all transducer elements)
the observation process
\eqref{eqn:recovery_sys_lin_eq_v_rx_born_all_f_all_in_mat} or
% 2.) adjoint of the observation process (all pulse-echo measurements, multifrequent, all transducer elements)
its adjoint on
a suitable vector.
% b) FMM substituted the spatially-shifted outgoing free-space Green's function by an error-regulated truncated multipole expansion
% book:Gibson2014, Chapter 9: The Fast Multipole Method / Sect. 9.1: Matrix-Vector Product
% book:Gibson2008: The MoM in EM, Chapter 8:
% - The FMM applies an error-controlled approximation to the system Green’s function allowing the force due to a group of
%   particles to be computed as if they were a single particle.
% article:ChewITAP1997: Fast solution methods in electromagnetics
% VII. RAY-PROPAGATION FAST MULTIPLE ALGORITHM (RPFMA)
% - If the GROUPS G_{l} and G_{l'} ARE FAR APART, it is clear that
%   not all plane waves on a sphere will participate in the interaction between
%   the elements of the two groups [87], [88]. (p. 539)
% - In fact, ray physics dictates that only a small fraction of the plane waves accounts for the interaction between the two groups. (p. 539)
% - A simplification of ray-propagation fast multiple algorithm (RPFMA) is the fast far-field approximation (FAFFA) [89]. (p. 539)
% XII. CONCLUSION
% - Even though a matrix–vector multiply for scattering problems only requires O( N log(N) ) operations both
%   for volume scattering and surface scattering problems, the number of iterations needed remains unpredictable. (p. 541)
% - Therefore, preconditioning techniques for reducing the required number of iterations in iterative methods are urgently needed in
%   solving electromagnetic wave scattering problems. (p. 541)
% article:CoifmanIAPM1993: The Fast Multipole Method for the Wave Equation: A Pedestrian Prescription
% 2. Basics / 2.4 Identities
% - The FMM, as presented here, rests on TWO ELEMENTARY IDENTITIES. (p. 8)
% - They, or formulas from which they may be easily derived, are found in many texts and handbooks on mathematical methods, such as
%   Arfken [11] and Abramowitz and Stegun [12] (p. 8)
%  [11] G. Arfken, Mathematical Methods for Physicists, secotid edition, New York, Academic Press, 1970.
%  [12] M. Abramowitz and I. A. Stegun, Handbook of Mathematical Functions, (Applied Mathematics Series), Cambridge, MA, National Bureau of Standards, 1972
%	1.) - The first, an expansion of the kernel in the integral, Equation (3), for the impedance-matrix elements, is a form of
%	      GEGENBAUER'S ADDITION THEOREM, (11), [...]. (p. 8)
%	    - When using this expansion to compute the field at x from a source at x’, X will be chosen to be close to x - x’, so that d will be small. (p. 8)
%	    - This relationship of the various vectors is sketched in Figure 1. The special functions are as defined in [12]. (p. 8)
%	2.) The second is an EXPANSION of the product j_{l}P_{j} IN PROPAGATING PLANE WAVES: (12). (p. 8)
% - Substituting Equation (12) [plane-wave expansion] into Equation (11) [Gegenbauer's add. thm.], we get (13),
%   where we have performed the ILLEGITIMATE BUT EXPEDIENT INTERCHANGE OF SUMMATION AND INTEGRATION. (pp. 8, 9)
% - The key point is that we intend to precompute the function (14), for
%   various values of \kappa. (p. 9)
% - This is not a function in the L \mapsto \infty, but that need not concern us,
%   as we obviously intend to TRUNCATE THE SUM IN NUMERICAL PRACTICE. (p. 9)
% - The number of kept terms, L + 1, will depend on
%   the MAXIMUM ALLOWED VALUE OF kd, as well as
%   the DESIRED ACCURACY. (p. 9)
It substituted
% 1.) outgoing free-space Green's functions (two- and three-dimensional Euclidean spaces)
the outgoing free-space \name{Green}'s functions
\eqref{eqn:app_helmholtz_green_free_space_2_3_dim} in
% 2.) entries of the observation process (single pulse-echo measurement, monofrequent, single transducer element)
the entries of
the observation process
\eqref{eqn:recovery_sys_lin_eq_v_rx_born_coef} by
% 3.) error-regulated truncated multipole expansions
error-regulated truncated multipole expansions if
the grid points
% 4.) discrete position of the point-like relative spatial fluctuation in the unperturbed compressibility
$\vect{r}_{\text{lat}, i} \in \mathcal{L}$ and
% 5.) discrete positions of the mathematical points
$\vect{r}_{\text{mat}, \nu}^{(m)} \in \mathcal{V}_{m}$, satisfied
% 6.) specific geometric relationship
a specific geometric relationship
\cite[Chapt. 9]{book:Gibson2014},
\cite{article:CoifmanIAPM1993}.
% c) substitution decomposed the observation process into the sum (far field + near field)
% book:Gibson2014, Chapter 9: The Fast Multipole Method / Sect. 9.1: Matrix-Vector Product
% - If WE NOW WRITE THE SYSTEM MATRIX AS
%   Z = Z^{near} + Z^{far}, where Z^{near} and Z^{far} are sparse,
%   the matrix-vector product can be written as
%   the sum of a near product and a far product, yielding
%   x = x^{near} + x^{far} = Z^{near} y + Z^{far} y. (p. 331)
% - In the fast multipole method, the matrix-vector product is performed in two steps:
%   a matrix-vector product involving Z^{near}, where the elements are stored explicitly and computed the usual way, and
%   a matrix-vector product involving Z^{far}, where individual elements are not computed or available explicitly. (p. 331)
% - As we will see, one the key benefits of this method is that
%   a large number of the matrix elements are located in Z^{far}, yielding
%   a very sparse Z^{near} and a tremendous savings in memory. (p. 331)
% article:CoifmanIAPM1993: The Fast Multipole Method for the Wave Equation: A Pedestrian Prescription
% 2. Basics / 2.3 Comparison with the Fast Fourier Transform
% - The SINGLE-STAGE FMM WORKS BY A SIMILAR DECOMPOSITION OF THE MATRIX Z: [ Z = Z' + V T V' ] (8),
%   where Z', V, and T are all sparse. (p. 8)
% - In contrast to the FFT, the FMM decomposition is made possible by analytic rather than algebraic properties of the linear operator. (p. 8)
% - Thus, while the FFT factorization is exact, the FMM decomposition is approximate. (p. 8)
% - However, this does not constitute a practical limitation, as it is easy to control the FMM to achieve any desired level of precision
%   (all the way to machine precision). (p. 8)
% 2. Basics / 2.4 Identities
% - Notice that Equation (16) gives the impedance-matrix element (for well-separated interactions) in terms of
%   the Fourier transforms with wave number k of the basis functions, i.e. the basis functions’ far fields. (p. 9)
% - The ACCELERATION PROVIDED BY THE FMM COMES FROM THE FACT THAT THESE FAR FIELDS CAN BE GROUPED TOGETHER before
%   the integral over \hat{k} is performed. (p. 9)
% 3. Algorithmic prescription / 3.2 Fast Matrix-Vector Multiplication
% - 3. Finally, compute (23). (p. 10)
% - The first term is the standard MoM computation of near interactions, and
%   the second term gives the far interactions, in terms of the far fields generated by each group. (p. 10)
% - This step requires O(KN ~ N^{2} / M) operations. (p. 10)
This substitution decomposed
% 1.) observation process (all pulse-echo measurements, multifrequent, all transducer elements)
the observation process
\eqref{eqn:recovery_sys_lin_eq_v_rx_born_all_f_all_in_mat} into
the sum
$\mat{\Phi}[ p^{(\text{in})} ] \approx \mat{\Phi}^{(\text{near})}[ p^{(\text{in})} ] + \mat{\Phi}^{(\text{far})}[ p^{(\text{in})} ]$, where
% 1.) point-like relative spatial fluctuations in the unperturbed compressibility located on the lattice points close to the planar transducer array
$\mat{\Phi}^{(\text{near})}[ p^{(\text{in})} ]$ accounted for
the grid points close to
the planar transducer array, and
% 2.) point-like relative spatial fluctuations in compressibility located on the lattice points exceeding a specified distance from the planar transducer array
$\mat{\Phi}^{(\text{far})}[ p^{(\text{in})} ]$ accounted for
those exceeding
a specified distance from
the planar transducer array
\cite[Sect. 9.1]{book:Gibson2014},
\cite[(8) and (23)]{article:CoifmanIAPM1993}.
% d) sparse population of the summand \mat{\Phi}^{(\text{near})}[ p^{(\text{in})} ] enabled both its explicit storage in the RAM and fast numerical evaluations of the associated matrix-vector products
The sparse population of
the summand
$\mat{\Phi}^{(\text{near})}[ p^{(\text{in})} ]$ enabled both
% 1.) explicit storage in the RAM
its explicit storage in
the \ac{RAM} and
% 2.) fast numerical evaluations of the associated matrix-vector products
fast numerical evaluations of
the associated matrix-vector products.
% e) additional blockwise decomposition of the summand \mat{\Phi}^{(\text{far})}[ p^{(\text{in})} ] into the products of only a few unique matrices provides similar benefits
The resulting block structure of
the summand
$\mat{\Phi}^{(\text{far})}[ p^{(\text{in})} ]$, which consisted of
the products of
only a few unique
% 1.) diagonal translation matrices
diagonal translation matrices and
% 2.) densely-populated aggregation and disaggregation matrices
densely-populated aggregation and
disaggregation matrices, provided
similar benefits.
% f) small number of unique matrices enabled their explicit storage in the RAM
% book:Gibson2014, Chapter 9: The Fast Multipole Method
% - As we will see in this chapter,
%   the FMM can be applied to vector Helmholtz problems,
%   [1] ALLOWING FOR A FAST COMPUTATION OF THE MATRIX-VECTOR PRODUCT IN AN ITERATIVE SOLVER, and
%   [2] ELIMINATING THE NEED TO STORE MANY OF THE MOM MATRIX ELEMENTS EXPLICITLY. (p. 330)
% - THIS RESULTS IN
%   [1] A SPEED INCREASE and
%   [2] A REDUCTION IN MEMORY REQUIREMENT, allowing us to solve
%   EXISTING PROBLEMS FASTER, as well as LARGER PROBLEMS THAT COULD NOT BE ATTEMPTED BEFORE. (p. 330)
The small number of
unique matrices enabled
their explicit storage in
the \ac{RAM}, whereas
% g) diagonal population of the translation matrices simultaneously reduced the computational costs
the diagonal population of
the translation matrices concurrently reduced
the computational costs.

% ill-conditioned sensing matrix can be approximated by a low-rank matrix
% TODO: move to description of FMM
\TODO{low-rank approximation of the matrix, accuracy of FMM?}

%---------------------------------------------------------------------------------------------------------------
% 2.) implementation details
%---------------------------------------------------------------------------------------------------------------
% a) two C programs based on CUDA implemented parallelized versions of the FMM for the observation process and its adjoint
Two \name{C} programs based on
\name{CUDA}
(NVIDIA Corp., Santa Clara, CA, USA) implemented
parallelized versions of
the \ac{FMM} for
% 1.) observation process (all pulse-echo measurements, multifrequent, all transducer elements)
the observation process
\eqref{eqn:recovery_sys_lin_eq_v_rx_born_all_f_all_in_mat} and
% 2.) adjoint of the observation process (all pulse-echo measurements, multifrequent, all transducer elements)
its adjoint.
% b) Tesla K40c performs all computations with 32 bit single precision
A \name{Tesla K40c} \ac{GPU} performed
all computations with
% TODO: single precision is redundant: 32 bit = single
$\SI{32}{\bit}$ single precision. %, which
%was found to be sufficiently accurate.
% c) MATLAB interface based on the MEX framework simplified the data transfers and the analysis of the results
A \name{Matlab}
(The MathWorks, Inc., Natick, MA, USA) interface, which used
% 1.) MEX framework
the \name{MEX} framework and
% 2.) double-precision (64 bit = 8 B) floating-point format for real-valued variables
the $\SI{8}{\byte}$ floating-point format for
real-valued variables, i.e.
% 3.) amount of memory allocated to a complex-valued variable
$w_{\text{c}} = \SI{16}{\byte}$, simplified
% 4.) data transfers
the data analyses. %and analyses
% 5.) data analyses

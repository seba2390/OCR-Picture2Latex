\section{Preliminaries}\label{sec:prelims}

\noindent{\bf Notation.}

 Throughout this paper, $[d]$ denotes the set $\{1,2,\dotsc, d\}$. For a random vector (or bit-string) $z$ in $\BR^n$, we will use $z_i$ or $z(i)$ to denote the $i$-th coordinate of $z$, depending on whether we need to use the subscript for another index. We shall use $\ui = (i_1,\ldots, i_d)$ for a $d$-tuple of indices.  For a $d$-tuple $\ui$, we write $|\ui|=d$ to denote the size of the tuple.

 
 For a matrix $M \in \C^{N \times N}$, we denote by $M^*$ its conjugate transpose.
 Given a string $x \in \R^N$, the $N \times N$ diagonal matrix with $x$ on the diagonal is denoted by $\Diag(x)$. The \emph{normalized trace} of an $N \times N$ matrix $M$ is defined as $\tr_N(M) = \frac{1}{N} \left(\sum_{i=1}^N M_{ii}\right)$. The operator norm of a matrix $M$ is denoted by $\|M\|_{\op}$. The left (resp.\ right) polar decomposition $(V, P)$ of a square matrix $M$ is a factorization of the form $M=VP$ (resp.\ $M=PV$) where $V$ is a unitary matrix and $P$ is a positive semidefinite matrix --- such a factorization always exists for any square matrix (it can be obtained easily from the singular-value decomposition of $M$). An $N \times N$ matrix $U$ is called a Haar random unitary if it is distributed according to the Haar measure on the Unitary group $\mathbb{U}(N)$.
 
 
 
Random variables are typically denoted by capital letters (e.g., $X$). We write $\BE[f(X)]$ and $\Var[f(X)]$ to denote the expectation and variance of the random variable $f(X)$ and if $f: \pmone^m \to \R$, we abbreviate it to $\E f$ and $\Var[f]$, where the expectation and variance are taken with respect to the uniform measure on the discrete cube $\pmone^m$. 
 



\paragraph{Fourier Analysis on the Discrete Cube.}
\label{sec:fourier}
We give some basic facts about Fourier analysis on the discrete cube and refer to the book \cite{OD14} for more details. Every function $f: \{\pm1\}^m \to \BR$ can be written uniquely as a sum of monomials $\chi_S(x) = \prod_{i \in S} x_i$,
\begin{align}\label{eqn:expansion}
    f(x) = \sum_{S \subseteq [m]} \fhat(S) \chi_S(x),
\end{align}
where $\fhat(S) = \BE[f(X)\chi_S(X)]$ is the Fourier coefficient with respect to the uniform $X \in \{\pm 1\}^m$. The monomials $\chi_S(x) = \prod_{i \in S} x_i$ form an orthonormal basis for real-valued functions on $\{\pm1\}^m$, called the \emph{Fourier basis}. Parseval's identity implies that for uniform $X \in \{\pm 1\}^m$,
\begin{align*}
    \ \BE f^2 = \sum_{S \subseteq [m]} \fhat(S)^2, \text{ and } \Var[f] = \sum_{S \subseteq [m]: S \neq \emptyset} \fhat(S)^2.
\end{align*}

For a function on the hypercube, we define $\|f\|^2_2 := \BE f^2$ which can also be viewed as the sum of squared Fourier coefficients because of Parseval's identity.



The discrete derivative of a function on the hypercube $\{\pm 1\}^m$ is given by  
\[ \partial_i f(x) = \frac{1}{2} (f(x^{i\to 1}) - f(x^{i\to -1})),\]
where $x^{i\to b}$ is the same as $x$ except that the $i$-th coordinate is set to $b$. It is easily checked that $\partial_i f(x)$ coincides with the real partial derivative $\dfrac{\del{}}{\del x_i}$ of the real multilinear polynomial given by \eqref{eqn:expansion}. 

For a real-valued function $f: \pmone^m \to \BR$, the influence of a variable $x_i$ on $f$ is defined as 
\[ \inf_i(f) = \BE| \partial_if|^2 = \sum_{S \subseteq [m] : i \in S} \fhat(S)^2. \]




\paragraph{Block-multilinear Forms.} 



A degree-$d$ block-multilinear form $f: \pmone^{n \times d} \to \BR$ is given by
\begin{equation}\label{eqn:tensor1}
    f(\x_1,\ldots, \x_d) =  \Ef + \sum_{m = 1}^d \sum_{\substack{|\bb|=m\\|\bi|=m}} \hf_{\bb, \bi} \cdot  ~x_{b_1}(i_1)x_{b_2}(i_2)\cdots x_{b_m}({i_m}),
\end{equation}
where the tuple $\bb  = (b_1, \ldots, b_m)$ satisfies $1 \le b_1 < \ldots < b_m \le d$ and $\bi \in [n]^m$ is an $m$-tuple. The expectation that yields the constant term is uniform over $\pmone^{n \times d}$. Note that $m$
 is determined from the size of the tuple $\bb$, so we just write $\hf_{\bb, \bi}$ above. 

From Parseval's identity, the variance of $f$ and the influence of $x_b(i)$ on $f$ (where $b \in [d]$ and $i \in [n]$) are respectively given by 
\[ \Var[f] =  \sum_{m=1}^d \sum_{\substack{|\bb|=m\\ |\bi|=m}} \hf_{\bb,\ui}^2 ~\text{ and }~ \inf_{b,i}(f) = \sum_{m=1}^d \sum_{\substack{|\bb|=m : b\in \bb \\|\bi|=m:i \in \bi}} \hf_{\bb,\ui}^2.\]

From the above, it follows that for any block $b \in [d]$, 
\begin{align}\label{eqn:inf-tensor}
  \  \sum_{i \in [n]} \inf_{b,i}(f)^2 \le \Var[f] \le \sum_{b \in [d], i \in [n]} \inf_{b,i}(f)^2 
\end{align}
where the first inequality is an equality if $f$ is a homogeneous degree-$d$ block-multilinear form. For any $b \in [d]$, we write $\maxinf_b(T) = \max \{ \inf_{b,i}(T)  \mid i \in [n]\}$ to denote the maximum influence of any variable in the block $\x_b$.


Note that if $f$ is a degree-$d$ block-multilinear form and if we fix some of the input bits to $\pm 1$, then the resulting function $g$ is also a degree-$d$ block-multilinear form with the same blocks $\x_1, \ldots, \x_d$, but it does not depend on the variables that were fixed. It is also easy to see that $\cbnorm{g} \le \cbnorm{f}$ because while computing $\|g\|_{\cb}$ we may restrict the matrix variables to $\pm I$ if that particular variable was set to $\pm 1$. In other words, completely bounded norm does not increase under restrictions.





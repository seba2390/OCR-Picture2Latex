\section{Introduction}

This paper is motivated by quantum query complexity and its relation to classical query complexity. Query complexity has been the context in which many of the main quantum algorithms have been developed, including Shor's \cite{Shor97} (building on \cite{Simon97}) and Grover's \cite{G96}. It has the added advantage that we actually know how to prove good lower bounds on query complexity, in contrast to a setting like circuit complexity. 

Quantum query complexity is closely connected to the study of bounded polynomials (or forms) on the Boolean hypercube. The key to this connection is that the amplitudes of the final state of a $d$-query quantum algorithm are polynomials of degree at most $d$ in the bits of the input~$x$, and therefore its acceptance probability $p(x)$ is a polynomial of degree at most $2d$. This observation was made by Beals, Buhrman, Cleve, Mosca and de Wolf~\cite{BBCMW01}, who used it to show that the bounded-error quantum query complexity and classical query complexity are polynomially related for any \emph{total} Boolean function. Since then a long line of research~\cite{ambainis:degreevsqueryj, ABK16, BHT17, ABBLSS17, T20, ABKRT20, BS21, SSW21} has tried to pinpoint the exact polynomial dependence as well as studied the relationship with other measures of complexity of a Boolean function (e.g., sensitivity, certificate complexity, and others~\cite{nisan&szegedy:degree,BdW02,BSS03}).

On the other hand, quantum algorithms can offer a huge (superexponential) advantage for partial functions, which are only defined on a subset of the Boolean hypercube; there are many known examples of partial functions whose classical query complexity is much larger than their quantum query complexity, for instance $k$-fold Forrelation and its variants \cite{AA:forrelation, T20, BS21, SSW21}. This means that the acceptance probability~$p(x)$ of a quantum algorithm cannot always be efficiently approximated  by a classical algorithm, since otherwise quantum algorithms could offer only a polynomial speedup for any function, be it total or partial. 





However, we can set our sights lower, and ask whether it is possible to classically efficiently approximate $p(x)$ on \emph{almost all} inputs. 
The following conjecture, which first appeared in \cite{AA14} and is  attributed there to folklore, says that we can.

\begin{conjecture}[Folklore]\label{conj:folklore}
     The acceptance probability of any $d$-query quantum algorithm on $n$-bit inputs can be estimated up to additive error $\eps$ on a $1-\delta$ fraction of the inputs by a classical query algorithm making $\poly(d, 1/\epsilon, 1/\delta)$ queries. 
\end{conjecture}

This conjecture is one expression of the general idea that quantum computers can only give significant speedup (in terms of queries, circuit complexity, or other things) on very structured problems, i.e., when the input to the problem has a particular structure, for instance some periodicity or specific correlations between different parts of the input. For generic unstructured inputs, the conjecture says that only a limited quantum speedup can be expected.
This conjecture motivates and is implied by the following conjecture due to Aaronson and Ambainis~\cite{AA14}:


\begin{conjecture}[Aaronson-Ambainis conjecture]\label{conj:aa-inf}
     Let $f: \pmone^n \to [0,1]$ be a degree-$d$ multilinear polynomial. Then, the maximum influence among all variables in $f$ is at least $\poly(\Var[f], 1/d)$.
\end{conjecture}

The above conjecture poses a fundamental structural question about bounded polynomials on the hypercube and is a notable open problem in the analysis of Boolean functions. \conjref{conj:aa-inf} is known to hold if the function is Boolean-valued (this follows from \cite{M05,OSS05}). For bounded polynomials, \cite{AA14} observed that the results of Dinur, Friedgut, Kindler and O'Donnell~\cite{DFKO06} imply that the conjecture holds with at least an exponential dependence in $d$. Montanaro \cite{M12} proved a special case of the conjecture for \emph{block-multilinear forms} where all coefficients have the same magnitude\footnote{This argument can be generalized to the case when $n^{\Omega(d)}$ coefficients have the same magnitude and the rest are zero, as noted in \cite{M12} where the observation is  attributed to Ambainis.}. Defant, Masty\l{}o and Perez \cite{DMP18} generalized this to bounded polynomials where all Fourier coefficients have the same magnitude and showed that the conjecture holds with an $\exp(\sqrt{d\log d})$ dependence. O'Donnell and Zhao \cite{OZ16} showed that it is sufficient to prove the conjecture for so-called \emph{one-block decoupled} polynomials. 


In this work, our motivation is to study \conjref{conj:aa-inf} for polynomials that represent the acceptance probability of quantum algorithms. Such polynomials have a lot more structure --- as shown by  Arunachalam, Bri\"et and Palazuelos~\cite{ABP18}, they can be represented in terms of \emph{completely bounded block-multilinear forms} (as described in the next section) and conversely, such forms even characterize quantum algorithms in a certain sense (see \secref{sec:open}). As such here we focus on understanding influences in such polynomials.



\subsection{Our results}

A degree-$d$ block-multilinear form $f(\x_1, \ldots, \x_d)$ mapping $\pmone^{n \times d}$ to $\BR$ is a polynomial where the variables are partitioned into $d$ blocks of $n$ variables each, and each monomial contains at most one variable from each block. Formally, $\x_b = (x_b(1), \ldots, x_b(n)) \in \pmone^n$ constitute the $b^\text{th}$ block of variables and 
\begin{equation}\label{eqn:tensor}
    f(\x_1,\ldots, \x_d) =  \E f +  \sum_{m = 1}^d \sum_{\substack{|\bb|=m\\|\bi|=m}} \hf_{\bb, \bi} \cdot  ~x_{b_1}(i_1)x_{b_2}(i_2)\cdots x_{b_m}({i_m}),
\end{equation}
where the tuple $\bb  = (b_1, \ldots, b_m)$ satisfies $1 \le b_1 < \ldots < b_m \le d$ and $\bi \in [n]^m$ is an $m$-tuple. Note that $m$
 is determined from the size of the tuple $\bb$, so we just write $\hf_{\bb, \bi}$ above.  

 Since each non-constant monomial contains at most one variable from each block and the ordering of the blocks is fixed, a degree-$d$ block-multilinear form $f: \pmone^{n \times d} \to \BR$ can be naturally viewed as a non-commutative polynomial in matrix variables with the constant term replaced with $\E f$ times the identity. Denoting the non-commutative polynomial as $f(\U_1, \ldots, \U_d)$ where each $\U_b = (U_b(1), \ldots, U_b(n))$ is a block of non-commutative variables, the completely bounded norm\footnote{The completely bounded norm originates in the theory of operator algebras. In the literature, this norm is sometimes defined for homogeneous block-multilinear forms only, but here we extend the definition to non-homogeneous block-multilinear forms.}  $\|f\|_{\cb}$ of the form $f$ is defined as
\[ 
\|f\|_{\cb} = \sup\Bigg\{\|f(\U_1, \ldots, \U_d)\|_{\op} ~\Bigg|~  N \in \N, U_b(i) \in \C^{N \times N}, \|U_b(i)\|_{\op} \le 1, b \in[d], i\in [n]\Bigg\}.
\]

 The supremum above is always attained and can be computed by solving a semidefinite program as shown by Gribling and Laurent~\cite{GL19}. One can also equivalently restrict the supremum in the definition above to unitary matrices since the convex hull of the set of unitary matrices is the unit operator norm ball. Moreover, $\|T\|_{\infty} \le \|T\|_{\cb}$ where $\|T\|_{\infty} = \max_{x \in \pmone^{n \times d}} |T(x)|$, so forms that are completely bounded  are also bounded on the hypercube. 

Our main result is a proof of the Aaronson-Ambainis conjecture for block-multilinear forms that are completely bounded. To state our result, we recall that the influence of a variable $x_b(i)$ on $f$ is
\[ \Inf_{b,i}(f) = \BE\left| \partial_{b,i} f(X)\right|^2, \]
where $X$ is uniform in $\pmone^{n \times d}$  and $\partial_{b,i}f(x)$ is the discrete derivative (see \secref{sec:prelims}). Denoting by $\maxinf(f) = \max_{b \in [d],i \in [n]} \inf_{b,i}(f)$ the maximum influence of any variable in $f$ and by $\Var[f]$ the variance of $f$ on the hypercube, we show: \\

\begin{theorem}\label{thm:aa}
     Let $f$ be a degree-$d$ block-multilinear form with $\|f\|_{\cb} \le 1$. Then, we have \[\maxinf(f)  \ge \dfrac{(\Var[f])^2}{e(d+1)^4}.\]
\end{theorem} 
    
The main technical ingredient in the proof of \thmref{thm:aa} is a new influence inequality for \emph{homogeneous} block-multilinear forms that relates the completely bounded norm to the influences. 



\begin{restatable}{theorem}{bh}  {\rm (Non-commutative root-influence inequality).}
\label{thm:bh-intro}
Let $f$ be a homogeneous degree-$d$ block-multilinear form. Then, for blocks $b \in \{1,d\}$,


    \[ \cbnorm{f}  \ge \frac{1}{\sqrt{e(d+1)}} \sum_{i=1}^n \sqrt{\Inf_{b,i}(f)}. \]
\end{restatable}

\noindent{\bf Remark.} In general, the completely bounded norm can change if we permute the blocks, and the theorem above only gives a bound in terms of the influences of the variables in the leftmost and rightmost blocks.\\

The  inequality also easily implies the special case of \thmref{thm:aa} for homogeneous forms, with a better dependence on~$d$,  as follows:
    \begin{align*}
         \ \cbnorm{f}  &\ge \frac{1}{\sqrt{e(d+1)}} \sum_{i=1}^n \sqrt{\Inf_{b,i}(f)} \\
         \ &\ge \frac{1}{\sqrt{e(d+1)}}  \sum_{i=1}^n \frac{\Inf_{b,i}(f)}{\sqrt{\maxinf(f)}} \ge  \frac{\Var[f]}{\sqrt{e(d+1)\cdot  \maxinf(f)}},
    \end{align*}
    where the last inequality follows  since for any homogeneous block-multilinear form the sum of influences of variables in \emph{any} one block equals $\Var[f]$ (see \eqref{eqn:inf-tensor} in the preliminaries). Then, if $\cbnorm{f} \le 1$, it follows that \[
    \maxinf(f) \ge \frac{(\Var[f])^2}{e(d+1)}.
    \]
    The non-homogeneous case (\thmref{thm:aa}) requires a bit more care and we use the inequality as an intermediate step to prove \thmref{thm:aa} with a worse polynomial dependence on~$d$.



Combined with the results of \cite{AA14}, we obtain that completely bounded forms can be well-approximated by classical query algorithms (decision trees) on most inputs.

\begin{restatable}{corollary}{simulation}
\label{cor:sim}
 Let $\epsilon, \delta > 0$ and let $f: \pmone^{n \times d} \to \BR$ be a degree-$d$ block-multilinear form with $\|f\|_{\cb} \le 1$. Then, there is a deterministic classical algorithm that makes $O(d^5\epsilon^{-8}\delta^{-5})$ queries and approximates $f(x)$ up to an additive error $\epsilon$ on $1-\delta$ fraction of the inputs $x \in \pmone^{n \times d}$.
\end{restatable}

\subsubsection{Application to quantum algorithms}
\label{sec:quantum}

We consider quantum query algorithms of the type shown in \figref{fig:quantum}.  Any such algorithm has black-box access to the inputs $\x_1, \ldots, \x_d$ where $\x_b \in \pmone^{n}$ for each $b \in [d]$, via a phase oracle.  In other words, the algorithm can apply the unitary $O_{\x_b} = \Diag(\x_b)$ for each $b \in [d]$.  Note that $n$ here is the dimension of the underlying Hilbert space, and the inputs can be represented with $\log n$ qubits.


\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{qcircuit.pdf}
    \caption{\footnotesize Quantum algorithms considered in \secref{sec:quantum}}
    \label{fig:quantum}
\end{figure}

The algorithm starts in some arbitrary quantum state\footnote{Throughout this paper, we will assume that all unitaries and states used in the quantum algorithm are real, which one may assume without loss of generality (see e.g.\ \cite{adh:qcomputability}).} $u \in \R^{n}$, makes $d$ quantum (phase) queries to oracles $O_{\x_b}$ for each $b \in [d]$, and succeeds according to a projective measurement that measures the projection of the final state onto some fixed state $v \in \R^n$. The algorithm is restricted to use each oracle $O_{\x_b}$ at most once. The inner product of the state $v$ with the final state at the end of the algorithm is given by the following degree-$d$ block-multilinear form $T : \pmone^{n \times d} \to \R$, 
\begin{equation}\label{eqn:q-tensor}
    T(\x_1,\ldots, \x_d) = u U_1(O_{\x_1} \otimes I_s)U_2 (O_{\x_2} \otimes I_s)U_3 \cdots (O_{\x_d} \otimes I_s) v,
\end{equation}
and the acceptance probability of the algorithm on input $x = (\x_1, \ldots, \x_d)$ is $T(x)^2$. 

The connection between such algorithms and completely bounded norm comes from the following  proposition in \cite{ABP18}.

\begin{proposition}[\cite{ABP18}, Theorem 3.2]
    Let $T : \pmone^{n \times d} \to \R$ be a degree-$d$ block-multilinear form given by \eqref{eqn:q-tensor}. Then, $\|T\|_{\cb} \le 1$. 
\end{proposition}

Using this connection, applying \corref{cor:sim} to $T$ implies the following almost-everywhere simulation result for quantum algorithms of the type mentioned above.

\begin{corollary}
     The acceptance probability of any $d$-query quantum algorithm of the type shown in \figref{fig:quantum} can be estimated up to an additive error $\eps$ on $1-\delta$ fraction of the inputs in $\pmone^{n \times d}$ by a classical query algorithm making $O(d^5\epsilon^{-8}\delta^{-5})$ queries. 
\end{corollary}

Note that quantum algorithms of the type considered in the above theorem can already exhibit super-exponential separation, in terms of the input size (which is $\log n$ qubits),  over classical algorithms in the query complexity model. For instance, problems like $k$-fold Forrelation (for $k= O(1)$) or its variants exhibit a $O(1)$ vs $n^{1-1/k}$ separation \cite{BS21, SSW21} between the quantum and classical query complexities. 




\subsection{Proof overview}
\label{sec:bh}
\newcommand{\bp}{\mathbf{p}}
\newcommand{\bits}{\{0,1\}}
\newcommand{\addr}[1]{\mathrm{addr}(#1)}





We first consider the case of homogeneous forms and explain the key ideas that go towards proving \thmref{thm:bh-intro}. We can write a homogeneous block-multilinear form in the following way,
 \begin{align*}
    f(\x_1,\ldots, \x_d) &= \sum_{i_1, \ldots, i_d \in [n]} \hf_{i_1, \ldots, i_d} ~x_1(i_1)x_2(i_2)\cdots x_d({i_d}) \\
    \ & = \sum_{i=1}^n  x_1(i) \underbrace{\left(\sum_{i_2, \ldots, i_d \in [n]} \hf_{i_1, \ldots, i_d} ~x_2(i_2)\cdots x_d({i_d})\right)}_{\textstyle := f_i(\x_2,\ldots, \x_d)}.
\end{align*}
    For a first attempt, let us try to show that $\cbnorm{f}$ must be large by picking $x$ from the discrete cube $\pmone^{n \times d}$ as follows: for each block $b$ except the first block, we choose $\x_b$ uniformly and independently from $\pmone^n$, and for the first block we take $x_1(i) = \mathrm{sign}(f_i(\x_2,\ldots, \x_d))$. Taking expectation, this gives us that
 \[ 
 \cbnorm{f} \ge \sum_{i=1}^n \E |f_i| \ge {2^{-d/2}} \sum_{i=1}^n \|f_i\|_2,
 \]
 where the second inequality follows from the multilinear Khintchine inequality\footnote{The multilinear Khintchine inequality states that $\BE|f| \ge 2^{-d/2} \|f\|_2$ for a homogeneous degree-$d$ block-multilinear form $f$. A similar conclusion $\BE|f| \ge 3^{-d} \|f\|_2$ holds for any degree-$d$ polynomial $f$ on the hypercube and can be derived from the $(4,2)$-hypercontractive inequality $(\BE f^4)^{1/4} \leq  3^{d/2}\|f\|_2$ and using that $\E[|S|] \geq {\E[S^2]^{3/2}}/{\E[S^4]^{1/2}}$ for any random variable $S$.} which gives us an exponential dependence in $d$. Note that $\|f_i\|_2^2 = \Inf_{1,i}(f)$ for each $i$, thus we get that 
  \begin{equation}\label{eq:cbnormvsinf} \cbnorm{f} \ge {2^{-d/2}} \sum_{i=1}^n  \sqrt{\Inf_{1,i}(f)}. 
  \end{equation}
The above also gives a lower bound on $\|f\|_{\infty}$ which is also a lower bound on $\cbnorm{f}$. However, the  exponential dependence in $d$ is necessary for the sup-norm as the following example shows. 


\begin{description}\item[Example.] Consider the following block-multilinear form closely related to the address function. Let $n=2^d$ and for $\ba = (a_1, \ldots, a_d) \in \bits^d$, let $\addr{\ba}$ denote the unique integer in $[n]$ whose binary expansion equals $\ba$. Define the degree-$(d+1)$ homogeneous block-multilinear form $f: \pmone^{n \times (d+1)} \to \{\pm1\}$ as follows,
\begin{align}\label{eqn:addr}
    \ f(\x_1, \ldots, \x_d, \x_{d+1}) &= \sum_{\ba \in \bits^d} g_{\ba}(\x_1,\ldots,\x_d) \cdot x_{d+1}(\addr{\ba}),
\end{align}
where $g_{\ba}(\x_1,\ldots, \x_d): \pmone^{n \times d} \to \{-1,0,1\}$ is defined as 
\[ g_{\ba}(\x_1,\ldots, \x_d) = \left(\frac{x_1(1) + (-1)^{a_1} x_1(2)}{2}\right)\cdot \cdots \left(\frac{x_d(1) + (-1)^{a_d} x_d(2)}{2}\right).\]

Note that $f$ only depends on the first two variables in the blocks $\x_1,\ldots, \x_d$ (which we refer to as the address blocks) and all the variables in the last block $\x_{d+1}$ (which we refer to as the data block). Moreover, $g_\ba(\x_1,\ldots,\x_d) \in \pmone$ iff the parity of bits in the address blocks matches with $\ba$, that is $x_b(1)x_b(2) = (-1)^{a_b}$ for every $b \in [d]$, and $g_\ba(\x_1,\ldots,\x_d) = 0$ otherwise. 

 It follows that $\|f\|_{\infty} = 1$, as for any setting of $\x_1, \ldots, \x_d$ exactly one term in the summation in \eqref{eqn:addr} survives. However, for $i = \addr{\ba} \in [n]$, 
\[ \inf_{d+1,i}(f) = \BE[|g_a|^2] = 2^{-d} = \frac1n,\] 
thus  $\sum_{i=1}^n \sqrt{\inf_{d+1,i}(f)} = \sqrt{n} = 2^{d/2}$. 
\end{description}

On the other hand, $\|f\|_{\cb} \ge 2^{d/2}$ in the example above --- this can be checked by plugging in the following values on the complex unit circle (one-dimensional unitaries): $x_b(1)=1,x_b(2)=i$ for each $b \in [d]$ and choosing the data block $\x_{d+1}$ so that all the magnitudes add up. Thus, one can hope that the freedom to choose large matrices can still allow us to show something like inequality~\eqref{eq:cbnormvsinf} for the completely bounded norm with a polynomial dependence on~$d$, instead of exponential.

\paragraph{Lower bounding $\cbnorm{f}$ using Haar random unitaries.} 
\begin{sloppypar}
Our key observation is that a non-commutative analog of the above strategy works very well. In particular, substituting $N \times N$ Haar random unitaries $U_2(1), \ldots, U_2(n), \ldots, U_d(1),\ldots, U_d(n)$ for the blocks $x_2, \ldots, x_d$ and choosing the block $x_1$ depending on the polar decomposition of $f_i(\U_2, \ldots, \U_d)$ allows one to obtain a much larger lower bound on the completely bounded norm $\cbnorm{f}$, losing only a polynomial rather than an exponential factor in~$d$. 
\end{sloppypar}

To obtain quantitative bounds, we need to understand the operator norm of low-degree polynomials of Haar random unitaries. A standard way to upper bound the expected operator norm of random matrices is via the trace method: computing the expected (normalized) trace of the matrix $(AA^*)^m$ for large enough $m$, and then taking $m$th root, gives a good control of the operator norm $\|A\|_{\op}$. Since the entries of a Haar random unitary are not independent of one another, it is hard to get a handle on the expected trace directly. A powerful method to understand such quantities is via free probability theory, which considers what happens when the dimension of the matrices $N \to \infty$. In this case, large random matrices behave like free operators, which live on an infinite-dimensional space with a corresponding ``trace''. We rely on a limiting theorem of Collins and Male \cite{CM11} who, by strengthening a result of Voiculescu \cite{V98}, show that the operator norm of a polynomial of Haar random unitaries converges to the operator norm of the polynomial of certain infinite-dimensional operators, called \emph{free Haar unitaries}; thus it suffices to study such free operators.



In free probability theory, such quantities have been studied for a long time (since the work of Haagerup \cite{H78}), and we rely on a result of Kemp and Speicher \cite{KS05} who generalized Haagerup's inequality  and showed that for free Haar unitaries one can obtain much better bounds for the operator norm using the usual trace method. In particular, one gets that almost surely as $N \to \infty$, we have
\[
\|f_i(\U_2,\ldots, \U_d)\|_{\op} \le \poly(d) \|f_i\|_2,
\]
in the non-commutative setting. Crucially, the improvement comes because free operators are much more constrained, and many terms that arise while looking at higher moments using the trace method in free probability are zero. One can keep close track of the non-zero terms by using careful combinatorial counting involving what are called \emph{non-crossing partitions}.  

Using the above, one can obtain \thmref{thm:bh-intro} with the strategy described above using the polar decomposition. The non-homogeneous case requires a bit more technical care, but the key underlying idea is the same.






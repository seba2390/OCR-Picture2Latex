%!TEX root = ms.tex
\begin{abstract}
%Recently, the problem of detecting and categorizing semantic relationship mentions from a given context has received a significant amount of attention.
% Extracting entity relationships for types of interests from text is important for understanding massive text corpora.
Relation extraction is a fundamental task in information extraction.
% Most existing systems for relation extraction heavily rely on manual labeling by human experts to create training data---a process that is costly, non-scalable, and hardly portable across different corpora.
% Most existing principles heavily rely on annotations given by human experts, which is costly and time-consuming.
Most existing methods have heavy reliance on annotations labeled by human experts, which are costly and time-consuming.
%To break the bottleneck of labeled data, knowledge bases like Freebase have been utilized to provide \ds. However, for many domain specific corpora, \ds is either non-existent or insufficient, while other related information like domain specific patterns is available and could be used. In this paper, we combined different types of information to provide \hs and perform relation extraction.
% To break this bottleneck, knowledge bases have been utilized to generate noisy annotations and provide \ds, while for many domain specific corpora, it's either non-existent or insufficient. 
% Therefore, we proposed a novel framework to supervise relation extraction model with knowledge bases and more,   combined different types of information to provide \hs and perform relation extraction.
% To reduce human labeling effort, two kinds of methods are studied by prior work: 
% (1) taking a small set of human-crafted patterns (instead of fully-annotated sentences) as ``\textit{weak}" supervision; and (2) leveraging freely available relation information from external knowledge bases as ``\textit{distant}" supervision. 
% However, both methodologies encounter challenges in dealing with domain-specific corpora. 
% On one hand, 
% Weak supervision, guided by domain knowledge, can generate high-quality but \textit{limited} amount of labeled data, due to its dependence on substantial human effort, 
% On the other hand, 
% whereas distant supervision can automatically produce a large amount of labeled data but the labels so generated may not be ``\textit{perfect}" for individual mentions.
% To overcome this drawback, we conduct relation extractor learning under annotations generated by heterogeneous information (e.g., knowledge base and domain heuristics), which are noisy but require l, and is referred as \hs. 
To overcome this drawback, we propose a novel framework, \our, to conduct relation extractor learning using annotations from heterogeneous information source, e.g., knowledge base and domain heuristics.
% In this paper, we study how to leverage \textit{heterogeneous supervision} (\ie, combining weak supervision and distant supervision) to perform relation extraction in an \textit{effecdtive} way. 
These annotations, referred as \hs, often conflict with each other, which brings a new challenge
 to the original relation extraction task: how to infer the true label from noisy labels for a given instance.
% And the challenges here are relation extraction task itself and more, resolving the conflicts among \hs.
% A key challenge is how to integrate the two kinds of sources while eliminating the conflicts among them in a trustworthy manner.
% In this paper, We propose a novel framework, \our, to jointly conducts relation extractor learning and context-aware truth discovery.
% Specifically, to resolve conflicts among \hs, true label discovery is conducted in a context-aware manner, while context information, or text feature, also serves as the backbone of relation extraction.
Identifying context information as the backbone of both relation extraction and true label discovery, we adopt embedding techniques to learn the distributed representations of context, which bridges all components with mutual enhancement in an iterative fashion.
% and allows them to enhance each other. 
%Specifically, we adopted an embedding method to learn distributed representations of text features, relation types and supervisions, which bridges the context-aware truth discovery module and the relation extraction module.
Extensive experimental results demonstrate the superiority of \our over the state-of-the-art.
\end{abstract} 
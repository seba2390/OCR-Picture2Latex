%!TEX root = ms.tex
\section{Conclusion and Future Work}
\label{sect:conclusion}


% In this paper, we propose a framework of relation extraction under heterogeneous supervision from the perspective of \emph{representation learning}. It leverages representation learning to represent labeling functions' proficient subsets in the same semantic space with relation mentions, and resolve conflicts based on this representation. Our model utilizes context information to infer the true label, and avoid the assumption of source consistency. Experimental evaluation fully justifies the effectiveness of proposed framework on two real-world datasets.

In this paper, we propose \our, an embedding framework to extract relation under heterogeneous supervision. 
When dealing with heterogeneous supervisions, one unique challenge is how to resolve conflicts generated by different labeling functions. 
Accordingly, we go beyond the ``source consistency assumption'' in prior works and leverage context-aware embeddings to induce proficient subsets.
The resulting framework bridges true label discovery and relation extraction with context representation, and allows them to mutually enhance each other. 
Experimental evaluation justifies the necessity of involving context-awareness, the quality of inferred true label, and the effectiveness of the proposed framework on two real-world datasets.

There exist several directions for future work. 
One is to apply transfer learning techniques to handle label distributions' difference between training set and test set. 
% On the other hand, modifying the calculation of relation mention representations by more complex models would likely lead to better representation and more precise relation extractor. 
Another is to incorporate OpenIE methods to automatically find domain-specific patterns and generate pattern-based labeling functions.
%!TEX root = ms.tex

\section{Preliminaries}
\label{sect:prelim}

In this section, we would formally define relation extraction and heterogeneous supervision, including the format of labeling functions.

\subsection{Relation Extraction}
\label{subsec:re}
% \smallskip
% \noindent
% \textsf{\textbf{\small Relation Extraction. }}
Here we conduct relation extraction in \textit{sentence-level}~\cite{bao2014knowledge}.
For a sentence $d$, an entity mention is a token span in $d$ which represents an entity, and a relation mention is a triple $(e_1, e_2, d)$ which consists of an ordered entity pair $(e_1, e_2)$ and $d$. And the relation extraction task is to categorize relation mentions into a given set of relation types $\R$, or Not-Target-Type (\texttt{None}) which means the type of the relation mention does not belong to $\R$.
% For example, in Fig.~\ref{fig:Framework}, we listed three relation mentions, and the first one's entity mention pair is $($\emph{Jesse James}, \emph{Missouri}$)$, which should be categorized into died\_in based on its context.

\subsection{Heterogeneous Supervision}
\label{subsec:hetersup}
% \smallskip
% \noindent
% \textsf{\textbf{\small Heterogeneous Supervision. }}
Similar to \cite{ratner2016data}, we employ labeling functions as basic units to encode supervision information and generate annotations. Since different supervision information may have different proficient subsets, we require each labeling function to encode only one elementary supervision information. Specifically, in the relation extraction scenario, we require each labeling function to only annotate one relation type based on one elementary piece of information, e.g., four examples are listed in Fig.~\ref{fig:Framework}.

Notice that knowledge-based labeling functions are also considered to be noisy because relation extraction is conducted in sentence-level, e.g. although \texttt{president\_of} (\emph{Obama}, \emph{USA}) exists in KB, it should not be assigned with ``\emph{Obama} was born in Honolulu, Hawaii, \emph{USA}'', since \texttt{president\_of} is irrelevant to the context.

% \vspace{-0.2cm}
% Heterogeneous supervision is a series of noisy, inconsistent and heterogeneous information which can be used as weak supervision, e.g. domain specific patterns and knowledge base. To fit our scenario of relation extraction, which requires multi-class classifier instead of binary classifier, we further generalize the concept of labeling function \cite{ratner2016data} to encode supervision information. To distinguish different sources for conducting truth discovery, we require each labeling function encoding only one elementary supervision information. And in the task of relation extraction, we identify the elementary supervision as a specific rule predicting one relation type based on one elementary kind of information. Accordingly, the labeling function here is constrained to be in the following form, where ri could be a relation type of interests, \texttt{None} or $\emptyset$.
% \begin{lstlisting}[basicstyle=\small,columns=fullflexible, language=Python, morekeywords={otherwise}]
% def labeling function i(m1, m2, s):
%   return ri if rules based one elementary kind of information satisfied:
% \end{lstlisting}
% And four labeling functions are listed as examples in Fig.~\ref{fig:Framework}.

% \smallskip
% \noindent
% \textsf{\textbf{\small Problem Definition. }}
\subsection{Problem Definition}
\label{subsec:pd}
For a POS-tagged corpus $\D$ with detected entities, we refer its relation mentions as $\C = \{c_i = (e_{i,1}, e_{i,2}, d), \forall d \in \D\}$. 
Our goal is to annotate entity mentions with relation types of interest ($\R = \{r_1, \dots, r_K\}$) or \texttt{None}. 
We require users to provide heterogeneous supervision in the form of labeling function $\Lambda = \{\lambda_1, \dots, \lambda_M\}$, and mark the annotations generated by $\Lambda$ as $\O = \{o_{c, i} | \lambda_i \text{ generate annotation }o_{c, i} \text{ for }c \in \C\}$. 
% For a given corpus $\D$ with POS-tagger and entity detector, our ultimate goal is to annotate entity pairs detected in $\D$, $\Z = \{<e_{d,1}, e_{d,2}, s_d> | d \in \D\}$, with \texttt{None} or relation types of interest, $\R = \{r_1, \dots, r_K\}$. To achieved this goal, heterogeneous supervision is utilized and encoded as a set of labeling function $\Lambda = \{\lambda_1, \dots, \lambda_M\}$. $\Lambda$ can annotate a part of instances in $\Z$, recorded as $\Z_l$. Now, our goal becomes to infer the true label for instances in $\Z_l$ and determine the relation type for instances in $\Z_u = \Z\setminus\Z_l$. Formally, we define our task as follows (see also Fig.~\ref{fig:graphicalModel}).
We record relation mentions annotated by $\Lambda$ as $\C_l$, and refer relation mentions without annotation as $\C_u$. 
Then, our task is to train a relation extractor based on $\C_l$ and categorize relation mentions in $\C_u$.
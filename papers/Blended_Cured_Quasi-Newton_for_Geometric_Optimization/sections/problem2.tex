\section{Problem Statement and Overview}

The geometry optimization problem we face is solving
\begin{equation}
    x^* = \argmin_{x\in \R^{dn}} E(x),
\end{equation}
for $n$ vertex locations in $d$-dimensional space stored in vector $x$,
where the energy $E(x)$ is a measure of the deformation, and $x$
is subject to boundary conditions.\footnote{We restrict our attention to
constraining a subset of vertex positions to given values, i.e.\ Dirichlet conditions,
for simplicity.} The energy is expressed as a sum over elements $t$ in a triangulation $T$
(triangles or tetrahedra depending on dimension),
\begin{equation}
\label{eq:obj}
E(x) = \sum_{t \in T} a_t W\big( F_t(x) \big),
\end{equation}
where $a_t>0$ is the area or volume of the rest shape of element $t$, $W$ is an energy
density function taking the deformation gradient as its argument, and $F_t$ computes the
deformation gradient for element $t$.
This problem may be given as is, or may be the result of a discretization of
a continuum problem with linear finite elements for example.


\subsection{Iterative solvers for nonlinear minimization}

Solution methods for the above generally apply an algorithmic strategy of iterated
approximation and stepping~\cite{Bertsekas:2016:NOP}, built
from three primary ingredients: an energy approximation, a
line search, and a termination criteria.\footnote{Alternatively, trust-region
methods are available, though not considered in the current work nor as
popular within the field.} \\

\bfi{Energy Approximation} At the current iterate $x_i$ we form a
local quadratic approximation of the energy, or \emph{proxy}:
\begin{align}
\label{eq:quad_approx}
E_i(x) = E(x_i) +   (x - x_i)^T \nabla E(x_i)  + \tfrac{1}{2}  (x - x_i) ^T H_i (x - x_i)
\end{align} where $H_i$ is a symmetric matrix.
Near the solution, if $H_i$ accurately approximates the Hessian we can achieve
fast convergence optimizing this proxy, but it is also critical that
it be stable --- symmetric positive definite (SPD) --- to ensure the proxy
optimization is well-posed everywhere; we also want $H_i$ to be cheap to solve with,
preferring sparser matrices and ideally not having to refactor at each iteration. \\

\bfi{Line Search} Quadratic models allow us to apply linear solvers
to find stationary points $x_i^* = \argmin_x E_i(x)$ of the local
energy approximation. A step
\begin{align}
\label{eq:descent_step_solve}
p_i = x_i^* - x_i = -H_i ^{-1} \nabla E(x_i) 
\end{align}
towards this stationary point then forms a direction for probable energy descent.
However, quadratic models are only locally accurate for nonlinear energies in general,
thus line-search is used to find an improved length $\alpha_i>0$ along $p_i$ to get a new iterate 
\begin{align}
\label{eq:vanilla_step}
x_{i+1} \leftarrow x_i + \alpha_i p_i,
\end{align}
for adequate decrease in nonlinear energy $E$. Of particular concern for
the geometric problems we face is energies which blow up to infinity for
degenerate (flattened) elements: in a given step, the elements where this
may come close to happening rapidly depart from the proxy, and the step size $\alpha_i$ may
have to be very small indeed, see Figure\ \ref{fig:blocked_line_search}, impeding progress globally. \\

\bfi{Termination} Iteration continues until we are able to stop with
a ``good enough'' solution -- but this requires a precise computational
definition. Typically we monitor some quantity which approaches zero
if and \emph{only if} the iterates are approaching a stationary point.
The standard in unconstrained optimization is to check the norm of the
gradient of the energy, which is zero only at a stationary point and
otherwise positive; however, the raw gradient norm depends on the mesh
size, scaling, and choice of energy, which makes finding an appropriate
tolerance to compare against highly problem-dependent and difficult
to automate. \\


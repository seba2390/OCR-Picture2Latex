\section{Importance sampling estimator}
\label{Sec3_Estimator}

We consider discrete output points $y$ that belong to a high-dimensional structured object space $\mathcal{S}$ (e.g., long sequences, large graphs), of cardinality $|\mathcal{S}|$. An exact estimation of the Mutual Information between outcomes $y$ and model parameters $\theta$ (equation ~\ref{Sec2_MI_equation}) is impractical because the expectation involves a sum over exponentially many possible outcomes for $y \in \mathcal{S}$. 
 
In lieu of the heuristics previously discussed, we obtain a principled approximation to the Mutual Information via Monte Carlo estimation using \emph{importance sampling}, with an adequately chosen importance distribution.

We denote $q(\theta) \approx P(\theta|\mathcal{D})$ the learnt approximation to the posterior, and assume we can approximate expectations over model parameters by sampling $M$ independent samples from $q(\theta)$.
We can then re-write the Mutual Information $\mathcal{M}$ in equation ~\ref{Sec2_MI_equation} as follows:
%\begin{subequations}
%\setlength{\abovedisplayskip}{7pt}
%\setlength{\belowdisplayskip}{7pt}
%\begin{align}
%\mathcal{M}(x)
% &\approx \left[- \sum_{s=1}^{|\mathcal{S}|}p_s \log p_s \right] + %\left[\frac{1}{M}\sum_{m=1}^M{\sum_{s=1}^{|\mathcal{S}|}{p_{s,m} \log p_{s,m}}} \right]  \\
% &=  \sum_{s=1}^{|\mathcal{S}|}\underbrace{(\left[\frac{1}{M}\sum_{m=1}^M{\left(p_{s,m} \log p_{s,m} \right)} - p_s \log p_s \right]}_{h(y_s)}.
% \label{Equation_MI_pre_IS}
%\end{align}
%\end{subequations}
\vspace{-2mm}
\begin{equation}
\mathcal{M}(x)
 \approx - \sum_{s=1}^{|\mathcal{S}|}p_s \log p_s + \frac{1}{M}\sum_{m=1}^M{\sum_{s=1}^{|\mathcal{S}|}{p_{s,m} \log p_{s,m}}}
 =  \sum_{s=1}^{|\mathcal{S}|}\underbrace{\left[\frac{1}{M}\sum_{m=1}^M{p_{s,m} \log p_{s,m}} - p_s \log p_s \right]}_{h(y_s)}
 \label{Equation_MI_pre_IS}
\end{equation}
\vspace{-3mm}
\\
where $p_s$ and $p_{s,m}$ are shorthands, respectively, for $P(y=y_s|x,\mathcal{D})$ --- the posterior predictive distribution --- and $P(y=y_s|x,\theta=\theta_m)$ --- the probability of a given output $y_s\in\mathcal{S}$ given $x$ and a sample $\theta_m$ from the approximate posterior distribution over model parameters $q(\theta)$. 

We can then obtain a tractable approximation to equation~\ref{Equation_MI_pre_IS} via importance sampling:
\vspace{-2mm}
\begin{equation}
\mathcal{M}(x) = \sum_{s=1}^{|\mathcal{S}|} h(y_s) \cdot \frac{1}{\bar{p}(y_s)} \cdot \bar{p}(y_s) = \mathbb{E}_{\bar{p}}{\left[h(y) \cdot \frac{1}{\bar{p}(y)}\right]}
\approx \frac{1}{N} \sum_{s=1}^N {\left[h(\tilde{y}_s) \cdot \frac{1}{\bar{p}(\tilde{y}_s)}\right]}
\end{equation}
\label{Sec3_Equation_IS_MI}
with $\tilde{y}_s \sim \bar{p}(.)$, where $\bar{p}$ is the importance distribution.

We choose the importance distribution to be the approximate posterior predictive defined over the outputs. We generate an outcome $\tilde{y}_s$ by first sampling a set of parameters $\tilde{\theta}_{0}$ from the approximate posterior, and then generating $\tilde{y}_s$ from a model defined by that set of parameters $\tilde{\theta}_{0}$.
This distribution will sample mostly from regions in $\mathcal{S}$ with high probability under the true posterior predictive for input $x$. This is in contrast to a naive sum over all possible outcomes $y$, many of which will have a negligible contribution to the sum. This gives rise to an estimator of Mutual information (obtained with Algorithm 1) with lower variance than its naive Monte Carlo counterpart (see Appendix~\ref{Appendix_Uncertainty_estimator}).

\begin{algorithm}[h]
\label{Sec3_Algorithm_IS-MI}
\begin{algorithmic}
\caption{Importance sampling estimator of MI} 
    \FOR{$s=1$ {\bfseries to} $N$}
	    \STATE Sample\ $\tilde{\theta}_{0} \sim q(\theta)$ ; $\tilde{y}_s \sim P(y|x,\theta=\tilde{\theta}_{0})$ ; 
	    \FOR{$m=1$ {\bfseries to} $M$}
	        \STATE Sample\ $\tilde{\theta}_m \sim q(\theta)$ ; Compute\ $p_{s,m}$ = $P(y=\tilde{y}_s|z,\theta=\tilde{\theta}_m)$ ;
		\ENDFOR
	    \STATE Compute $p_s = \frac{1}{M}\sum_{m=1}^M{p_{s,m}}$; $h_s = \frac{1}{M}\sum_{m=1}^M({p_{s,m} \log p_{s,m})} - p_s \log p_s$ ;
	\ENDFOR
	\STATE Return $\mathcal{M}(x)$ = $\frac{1}{N} \sum_{s=1}^{N} \left[h_s \cdot \frac{1}{p_s} \right]$ \\
\end{algorithmic}
\end{algorithm}
\section{Uncertainty-guided optimization in VAE latent space}
\label{Sec4_Uncertainty_guided_Optimization}

\textbf{Black box optimization in VAE latent space.} We want to optimize the black-box objective $\mathcal{O}$ over a high dimensional discrete object space $\mathcal{S}$. We train a VAE, with encoder $g$ and decoder $f$, to learn a continuous lower-dimensional embedding of objects in $\mathcal{S}$. The optimization of $\mathcal{O}$ is then performed in latent space and the best candidates are subsequently decoded into the original space. As discussed in \S~\ref{Sec2_Background_Optim}, this may lead to invalid or unrealistic decodings when the decoder $f$ operates in regions different from the ones seen during training. We propose to detect this regime by quantifying the epistemic uncertainty of the decoder: avoiding regions with high epistemic uncertainty for the decoder will make the overall optimization process more efficient by avoiding invalid decodings. 
We next cover two optimization approaches commonly used in latent space optimization settings and discuss how we can leverage the uncertainty of the decoder to guide the optimization process.

\textbf{Bayesian Optimization with an uncertainty-aware surrogate model or uncertainty censoring.} We first train a surrogate model, e.g., a Gaussian Process \citep{Mchutchon2011GP}, to predict $\mathcal{O}(x)$ based on its latent representation $z$. We then perform Bayesian Optimization using an appropriate acquisition function (e.g., Upper Confidence Bound or Expected Improvement heuristic). There are two main ways to incorporate the decoder uncertainty to guide this process. The first approach consists in training the surrogate model on an objective that penalizes points with high uncertainty (e.g., optimizing $\mathcal{O}(x) - \alpha \cdot \mathcal{M}(z)$). Another method is to censor proposal points $z$ that would have a Mututal Information $\mathcal{M}(z)$ above a predefined uncertainty threshold $\mathcal{T}$ (e.g., highest value observed on the training data) at each step of a batch Bayesian Optimization process. 

\textbf{Uncertainty-constrained gradient ascent.} A common architecture design when performing black-box optimization in latent space is to jointly train the VAE with an auxiliary network $h$ (Fig.\ref{Appendix_Figure_Joint_training_architecture}) that predicts the value of the black box objective $\mathcal{O}(x)$ from the encoding $z$ of $x$ in latent space \citep{Gomez_Bombarelli_2018,bradshaw2019model,jin2019junction}. This construct is particularly useful in constrained optimization settings in which we want to perform a local search in latent space to maximize $\mathcal{O}$ while remaining close to a known input object.
The joint training consists of optimizing the sum of the VAE loss (i.e., the ELBO) and the loss from the black-box objective prediction (e.g., MSE loss for a continuous output $\mathcal{O}$) via gradient descent, backpropagating gradients through the entire architecture.
To optimize objects under this framework, we start from a set of initial points in latent space $z$ --- either a random sample of latent points, or a subset of points $x$ that we encode in the latent space ($z = g(x)$). We then compute the gradient $\nabla_{z}{h}$ of the auxiliary network with respect to $z$ and perform gradient ascent $ z \leftarrow z + \alpha \cdot \nabla_{z}{h}$. We repeat this process a few times until satisfying a stopping criteria (e.g., threshold on predicted values $h(z)$ or after a fixed number of gradient updates). Finally, we decode the latest latent positions to obtain the set of candidates $\Tilde{x} = f(z)$ and measure their actual properties $\mathcal{O}(\Tilde{x})$.
We can further improve the quality of the candidate set by censoring the moves in latent during gradient ascent that would result in a value of uncertainty above a predefined threshold $\mathcal{T}$. 



\section{Conclusion}

In this work, we study the problem of predicting trustworthiness on a large-scale dataset.
We observe that the oracle, \ie trustworthiness predictor, trained with the cross entropy loss, focal loss, and TCP confidence loss lean towards viewing incorrect predictions to be trustworthy due to overfitting.
To improve the generalizability of the oracles, we propose the steep slope loss that encourages the features w.r.t. correct predictions and incorrect predictions to be separated from each other.
We evaluate the proposed loss on ImageNet through the lens of the trustworthiness metrics, selective classification metric, and separability of distributions, respectively. Experimental results show that the proposed loss is effective in improving the generalizability of trustworthiness predictors.

\section{Societal Impact}

\REVISION{
Learning high-accuracy models is a long-standing goal in machine learning. Nevertheless, due to the complexity of real-world data, there is still a gap between state-of-the-art classification models and a perfect one. Hence, there is a critical need to understand the trustworthiness of classification models, \ie differentiate correct predictions and incorrect predictions, in order to safely and effectively apply the models in real-world tasks. Models with the proposed loss achieve considerably better performance with various trustworthiness metrics. They also show generalizability with both in-distribution and out-of-distribution images at a large scale. In addition, while existing trustworthiness models focus on a high TPR and tend to view all incorrect predictions to be trustworthy (\ie TNR close to 0), false positives may lead to high consequent cost in some real-world scenarios such as critical applications in medicine (\eg a false positive leading to unnecessary and invasive tests or treatment such as biopsies or surgery, or harmful side effects in medicine) and security (\eg counter terrorism). It is thus of great importance for a trustworthiness model to flexibly trade off between TPR and TNR. To this end, the proposed loss allows the underlying distributions of positive and negative examples to be more separable, enabling a more effective trade-off between them. 
}
Just recall that somehow I thought as long as we convinced the reviewers that the other works are not as good as the TCP design, [2] is not relevant. But in fact, we did not rebut this one "Recent (parallel) work [2] has benchmarked these methods on large-scale datasets which indicates these scale well to larger datasets.", which may affect our claim on large-scale.

Yan Luo  10:52 PM
ref 2 is ood detection，in my view，2 is out of context and irrelevant. Lets say if relevant，this implies that all trustworthiness works should take ood models as baseline
10:53
I guess the reviewer is the author of 2 and feel the prob is super useful so recommend to us by showing that prob has many applications

Catherine Zhao  10:55 PM
could be
10:56
yeah, hard choice, we cannot say negative words about it (like not as good as us), so maybe leaving it is fine
10:56
though it may give the impression that we skipped this one [2]

Yan Luo  10:59 PM
We bury a bullet for this point by leaving a sentence which is not the goal of OOD detection. We are waiting for the reviewer rasing that question

Catherine Zhao  11:03 PM
ok, so the point is that [2] targets OOD, which should not be the goal for all trustworthy papers?
11:03
we did not convey any points though as we did not mention [2]
11:04
the sentence "However, we would like to point out that trustworthiness informs whether one can safely use the predictions yielded by AI for making decisions, which is not the goal of out-of-distribution detection." to me simply means that OOD has other goals and is different from trustworthy problems.

Yan Luo  11:25 PM
Let us look a an example，we train a model with real world cat image，and expect the model can detect cartoon cat as well. it could fail to detect a cartoon image. So ood image is a factor affecting trustworthiness，but that is not all the reasons. There are many facotrs affecting TW，like the deep learming models are not perfect to classify in diatribution images，and real world cat is semantically complicated to be perfectly classified
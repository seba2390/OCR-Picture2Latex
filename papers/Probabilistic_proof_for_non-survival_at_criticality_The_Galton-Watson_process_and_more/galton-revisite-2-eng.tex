\documentclass[svgnames]{amsart}

% version du 1er avril 2003

%\usepackage{typearea}
\usepackage[utf8]{inputenc}
%\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amsthm}
%\usepackage{showkeys}
\usepackage{graphicx}
\usepackage[english]{babel}
%\usepackage{macros}

%\usepackage{lscape}
\DeclareMathAlphabet{\mathbbo}{U}{bbold}{m}{n}
\usepackage{verbatim}
\newcommand{\ber}{\text{Ber}}
\newcommand{\floor}[1]{\lfloor #1 \rfloor}
\newcommand{\gestoch}{\succeq}
\newcommand{\lestoch}{\preceq}
\newcommand{\N}{\ensuremath{\mathbb{N}}}
\newcommand{\D}{\ensuremath{\mathbb{D}}}
\newcommand{\Z}{\ensuremath{\mathbb{Z}}}
\newcommand{\Zd}{\ensuremath{\mathbb{Z}^d}}
\newcommand{\Q}{\ensuremath{\mathbb{Q}}}
\newcommand{\R}{\ensuremath{\mathbb{R}}}
\newcommand{\Rd}{\ensuremath{\mathbb{R}^d}}
\newcommand{\Rn}{\ensuremath{\mathbb{R}^n}}
\newcommand{\K}{\ensuremath{\mathbb{K}}}
\newcommand{\C}{\ensuremath{\mathbb{C}}}
\newcommand{\T}{\ensuremath{\mathbb{T}}}
\newcommand{\U}{\ensuremath{\mathbb{U}}}
\newcommand{\B}{\ensuremath{\mathbb{B}}}
\newcommand{\E}{\ensuremath{\mathbb{E}}}
\newcommand{\X}{\ensuremath{\mathbb{X}}}
\newcommand{\G}{\ensuremath{\mathfrak{G}}}
\renewcommand{\H}{\ensuremath{\mathcal{H}}}
\newcommand{\tr}{\text{Tr }}
\newcommand{\cl}{\text{cl}}
\newcommand{\ie}{\emph{i.e. }}
\newcommand{\Cov}{\text{Cov}}
\newcommand{\Covar}{\text{Covar }}
\renewcommand{\P}{\ensuremath{\mathbb{P}}}
%{m\hspace{-0.3cm}\diagup}
\newcommand{\resp}{\emph{resp.}\ }
\newcommand{\Sn}{\ensuremath{\mathfrak{S}_{n}}}
\newcommand{\Kn}[1][K]{\ensuremath{K_{n}(\mathbb{#1})}}
\newcommand{\Gln}[1][K]{\ensuremath{Gl_{n}(\mathbb{#1})}}
\newcommand{\Gld}[1][K]{\ensuremath{Gl_{d}(\mathbb{#1})}}
\renewcommand{\epsilon}{\varepsilon}
\renewcommand{\limsup}{\overline{\lim}\quad}
\renewcommand{\liminf}{\underline{\lim}\quad}
\renewcommand{\Re}{\text{Re }}
\renewcommand{\Im}{\text{Im }}


\newcommand{\Remarque}[1][]{\textbf{Remarque#1 : }}
\newcommand{\Exemple}[1][]{\textbf{Exemple#1 : }}
\newcommand{\defi}[1][]{\textbf{Définition#1 : }}
\newcommand{\exo}[1][]{\textbf{Exercice#1 : }}

\newcommand{\miniop}[3]{%
\renewcommand{\arraystretch}{0.6}
\begin{array}{c}
{\scriptstyle #1}\\
#2\\
{\scriptstyle #3}
\end{array}
\renewcommand{\arraystretch}{1}}

\newcommand{\Card}[1]{\vert #1 \vert}
\newcommand{\grad}{\text{grad }}

%\newcommand{\1}{1\hspace{-2.7mm}1}
\newcommand{\1}{\mathbbo{1}}
\newcommand{\Var}{\text{Var }}
\newcommand{\Id}{\text{Id}}

%\newcommand{\Covar}{\text{Covar }}
\newcommand{\supp}{\text{supp }}
\newcommand{\spec}{\text{spec }}

\newtheorem{theo}{Theorem}
\newtheorem{lemme}{Lemma}
\newtheorem{coro}{Corollary}
\newtheorem{rem}{Remark}
\newtheorem{prop}{Proposition}

\setlength{\topmargin}{-0.5in} \setlength{\textheight}{9.25in}
%\setlength{\oddsidemargin}{0in} \setlength{\evensidemargin}{0in}
%\setlength{\textwidth}{6in}

\newcommand{\tribuf}{\mathcal{F}}
\newcommand{\tribubor}{\mathcal{B}(\R)}


\usepackage[most]{tcolorbox}
\tcbuselibrary{listingsutf8}
\input{lst-environnements} 


\author{Olivier \textsc{Garet}}
%\date{mai 2013}
\title[Probabilistic proof for non--survival at criticality]{Probabilistic proof for non--survival at criticality: the Galton--Watson process and more}%{The critical Galton--Watson process vanishes}
\begin{document}
\subjclass[2000]{60K35, 82B43.}
\keywords{Galton--Watson process, growth model,renormalization}


\maketitle
\begin{abstract}
In a famous paper, Bezuidenhout and Grimmett demonstrated that the contact process dies out at the critical point.Their proof technique has often been used to study the growth of population patterns.
The present text is intended as an introduction to their ideas, with examples of minimal technicality. In particular, we recover the basic theorem about 
Galton--Watson chains: except in a degenerate case, survival is possible only if the fertility rate exceeds $1$. The classical proof that is taught in classrooms is essentially analytic, based on generating functions and convexity arguments. Following the Bezuidenhout--Grimmett way, we propose a proof that is more consistent with probabilistic intuition.
We also study the survival problem for an original model, mixing sexual and asexual reproduction.
\end{abstract}


\section{Introduction}
Inspired by an article by Grimmett and Marstrand on supercritical  percolation in dimension $d\ge 3$, Bezuidenhout and Grimmett have shown in a famous article that the contact process vanishes at the critical point.
Their proof technique has often been used to study various growth  models.

The implementation of their proof technique is usually quite technical, as it relies on a renormalization procedure with quite complicated events as a basic brick.

The purpose of this article is therefore to introduce this technique with growth models for which the implementation is much simpler.


Among the growth models, the most famous is the Galton--Watson process.
The basic theorem concerns the probability of survival as a function of fertility: except in degenerate cases, survival is possible only if the fertility rate exceeds $1$.
The proof that is usually taught  -- see for example  Benaïm--El Karoui~\cite{BEK} or Durrett~\cite{Durrett} --  is essentially analytic. It relies on generating functions and convexity arguments, which may seem rather frustrating or at least quite miraculous.

We propose here, inspired by the work of Bezuidenhout and Grimmett, to give a proof that is more in line  with the probabilistic intuition.

This gives an introduction to the ideas of Bezuidenhout and Grimmett, with a model that is probably the simplest of the models that can be considered.
We then continue with the study of the survival problem on an original model, mixing sexual and asexual reproduction.

%It also gives  an introduction to their ideas, in the frame of the simple example of the Galton--Watson process.


In order to keep our text self-contained (maybe event suitable for a presentation to graduate students), the first section is devoted to the introduction of the Galton--Watson process with all the necessary results.
The new proof of the classical result comes in Section~2.
Section~3 is devoted to the introduction and the study of a new cooperative model, mixing sexual and asexual reproduction.
\section{Galton--Watson processes: definition and first properties}


Let $\nu,\mu$ be two distributions on $\N$.
The distribution $\nu$ is denoted as the offspring distribution, whereas $\mu$ 
is the distribution of the size of the initial population. 

We denote as  the 
Galton--Watson process with initial distribution $\mu$ and offspring distribution $\nu$
the Markov chain that starts with  $\mu$ as initial distribution, and whose transition matrix is given by
\begin{equation*}
p_{i,j}=
\begin{cases}
\nu^{*i}(j)\text{ if }i\ne 0\\
\delta_0(j)\text{ if }i=0
\end{cases}
\end{equation*}

One can build such a chain as follows:
Let $(X_i^n)_{i,j\ge 1}$, $Y_0$ be independent random variables with $Y_0\sim\mu$ and $X_i^n\sim\nu$ for every $i,n$.
Then, the sequence $(Y_n)_{n\ge 1}$ is recursively defined by

$$\forall n\ge 0\quad Y_{n+1}=\sum_{1\le i\le Y_n}X_i^n.$$
Then, $(Y_n)_{n\ge 0}$, is a Galton--Watson process with initial distribution $\mu$ and offspring distribution $\nu$.
The mean number of offspring  $m=\int_{\N} x\ d\nu(x)$ is denoted as the fertility.
If we define  $\mathcal{F}_n=\sigma(X_i^k,i\ge 1,k\le n)$, we have %facilement
%$$\E[Y_{n+1}|\mathcal{F}_n]=mY_n,$$ 
%d'où 
\begin{equation}
\label{puissance}
\E[Y_{n+1}|\mathcal{F}_n]=mY_n,\quad \E[Y_{n+1}]=m\E[Y_n]\text{ and }\E[Y_n]=m^n\E[Y_0]
\end{equation}
We define the time to extinction $\tau$ as follows: $\tau=\inf\{n\ge 0; Y_n=0\}$.


\begin{theo}
\label{mort}
If $m<1$, $\P(\tau>n)=O(m^n)$. Particularly, $\P(\tau<+\infty)=1$.
\end{theo}
\begin{proof}
With~\eqref{puissance}, we have $\P(\tau>n)\le\P(Y_n\ge 1)\le \E[Y_n]=m^n\E[Y_0]$.
\end{proof}


\begin{theo}
\label{galtonindep}
Let $(X_n)_{n\ge 0}$ and  $(Y_n)_{n\ge 0}$ be independent  Galton--Watson processes with the same offspring distribution  $\nu$. Then, 
 $(X_n+Y_n)_{n\ge 0}$ is also a  Galton--Watson process with $\nu$ as offspring distribution.
\end{theo}
\begin{proof}
Since $(X_n)_{n\ge 0}$ and  $(Y_n)_{n\ge 0}$ are independent Markov chains, $((X_n,Y_n))_{n\ge 0}$ is a Markov chain, with the transition matrix
$$p_{(x,a),(y,b)}=\nu^{* x}(a)\nu^{* y}(b).$$ Let us denote by 
$\P^{(x,y)}$ the distributions of the canonically associated Markov chains.
We must prove that if the function $f$ is defined by  $f(x,y)=x+y$, then $(f(X_n,Y_n))_{n\ge 0}$ is still a Markov Chain. To this aim, we apply the Dynkin criterion: it is sufficient to prove that whenever $x+y=r$, then
$\P^{(x,y)}(f(X_1,Y_1)=\ell)$ only depends on $r$ and $\ell$.
Also, under  $\P^{(x,y)}$, $X_1$ and $Y_1$ are independent random variables with  $\nu^{* x}$ and $\nu^{* y}$ as their respective distributions, so the distribution of
 $f(X_1,Y_1)$ is  $\nu^{* x}* \nu^{* y}=\nu^{* (x+y)}=\nu^{* r}$.
Finally, $\P^{(x,y)}(f(X_1,Y_1)=\ell)=\nu^{* r}(\{\ell\})$ and 
$(X_n+Y_n)_{n\ge 0}$ is a Galton--Watson process with $\nu$ as offspring distribution. Since the initial distribution is $\P_{X_0+Y_0}=\P_{X_0}*\P_{Y_0}=\mu_1*\mu_2$, we get the desired result.
\end{proof}


In the sequel, $\P^i$ denotes a probability measure under which
$(Y_n)_{n\ge 0}$ is a Galton--Watson process with initial distribution $\delta_{i}$ and offspring distribution $\nu$.


\begin{coro}
We have
\begin{itemize}
\item For each $n\ge 0$, $\P^n(\tau<+\infty)=\P^{1}(\tau<+\infty)^n$
\item For $n,\ell\ge 0$, $\P^n(\tau<+\infty|\mathcal{F}_{\ell})=\P^{1}(\tau<+\infty)^{Y_{\ell}}$.
\item For $n,\ell\ge 1$, we have $\P^n(\tau=+\infty)>0 \iff \P^{\ell}(\tau=+\infty)>0.$
\end{itemize}
\end{coro}

\begin{proof}
  Thanks to Theorem~\ref{galtonindep}, we have $$\P^{n+1}(\tau<+\infty)=\P^{n}(\tau<+\infty)\P^{1}(\tau<+\infty),$$ then  $\P^{n}(\tau<+\infty)=\P^{1}(\tau<+\infty)^n$ follows by natural induction. This gives the first item.
Then, the second item follows from the Markov property. The last point is obvious.
\end{proof}

\begin{coro}
\label{souschaine}
Let $T\ge 1$.  $(Y_{Tn})_{n\ge 0}$ is a Galton--Watson process with offspring distribution $\P^1_{Y_T}$.
\end{coro}
\begin{proof}
Since $(Y_n)$ is a Markov chain, it is well known that so does $(Y_{Tn})_{n\ge 0}$. Let us compute the transition probabilities.

Let $k\ge 1$.
Applying Theorem~\ref{galtonindep} ($k-1$ times), we see that if the processes $(Y^1_t)_{t\ge 0}$, $(Y^2_t)_{t\ge 0}, $\dots$ (Y^k_t)_{t\ge 0}$ are independent Galton--Watson processes with $\delta_1$ as their common initial distribution and $\nu$ as offspring distribution,
then $(Y^1_t+\dots Y^k_t)_{t\ge 0}$ is a  Galton--Watson process with  $\delta_{k}$ as initial distribution and $\nu$ as  offspring distribution.
Then,
$$\P^k(Y_T=\ell)=\P(Y^1_T+\dots Y^k_T=\ell)=\P_{Y^1_T}^{*k}(\ell).$$
Also, $\P^0(Y_T=\ell)=\delta_0(\ell)$: this gives the desired result.
\end{proof}

\section{A probabilistic proof}

In the first step of the proof, we show that a certain growth process may survive, with the idea that the process that we finally want to study will be compared to the surviving reference process.
In the present paper, the reference process is a Galton--Watson process too.
However in general, the reference process may belong to a related family.
For example, Bezuidenhout and Grimmett compared the contact process to a supercritical oriented percolation process.


\subsection{Survival in the supercritical phase}

\begin{theo}
\label{surcritique}
If $m>1$, then $\P^{1}(\tau=+\infty)>0$.
\end{theo}
\begin{proof}
Let $a$ with $1<a<m$. We have
$$\miniop{}{\lim}{M\to +\infty} \int x\wedge M \ d\nu= \int  x \ d\nu=m,$$ so there exists $M$ with  $\int x\wedge M \ d\nu>a$.  For $k\ge n$, we have

\begin{align*}
\P^k(Y_1<na)&=\P(X_1+\dots X_k<na)\\\le &\P(X_1\wedge M+\dots X_n\wedge M<na)\\& =\P(n\E[X_1\wedge M]-(X_1\wedge M+\dots X_n\wedge M))> (\E[X_1\wedge M]-a)n)\\& \le\frac{\Var X_1\wedge M}{(\E[X_1\wedge M]-a)n},
\end{align*}
by the  Tchebitchef inequality. 
Let us define $\phi(k,x)=\P^k(Y_1<x)$ and consider $n>c=\frac{\Var (X_1\wedge M)}{\E[X_1\wedge M]-a}$.\\
Let $t\ge 0$. By the Markov property, for each
 $A\in \mathcal{F}_t$ with $A\subset\{Y_t\ge n\}$, we can write
\begin{align*}
\P(A\cap \{Y_{t+1}<an\})&=
\E[\1_A  \1_{Y_{t+1}<an\}}]=\E[\1_A\E[\1_{Y_{t+1}<an\}}|\mathcal{F}_t]]\\
&=\E[\1_A \phi(Y_t,an)]\le \E [\1_A c/n]=c/n\P(A),
\end{align*}
so $\P(Y_{t+1}\ge an| A)\ge 1-\frac{c}n$.\\
By natural induction, it follows that for $A_t=\miniop{t}{\cap}{i=1}\{Y_{t}\ge na^t\}$, we have
$$\P^n(A_t)\ge\miniop{t-1}{\prod}{i=0}\left(1-\frac{c}{na^i}\right),$$
then
$\P^n(\tau=+\infty)\ge\P^n(\forall t\ge 0\quad Y_{t}\ge na^t)\ge\prod_{i=0}^{+\infty} \left(1-\frac{c}{na^i}\right)>0.$
\end{proof}

Some remarks:
\begin{itemize}
\item Obviously, the bound $1-\frac{c}n$ is very bad, coming from the Tchebitchev inequality. We were doing better with the Höffding inequality, but that is sufficient for our purpose.
\item  The same pattern can be applied to demonstrate that survival is possible for a multitype Galton--Watson process whose fertility matrix has a spectral radius strictly greater than~1 (see for example~\cite{Garet-livre}).
\end{itemize}
\subsection{Survival is a local property}

\begin{theo}
\label{equivalence}
Let $(Y_n)_{n\ge 0}$ be a  Galton--Watson process with offspring distribution~$\nu$.
Suppose that $\nu(0)>0$. Then there is an equivalence between:
\begin{itemize}
\item $\exists N,T\ge 1\quad \P^N(Y_T\ge 2N)>\frac12$.
\item $\P^1(\tau=+\infty)>0$.
\end{itemize}
\end{theo}

The event $\{Y_T\ge 2N\}$ only depends on what happens in a finite time box. Thus, it can be considered to be a local event, which will be useful to get some continuity with respect to the parameters of the model. \\

Before starting the proof, let us give the main ideas:
\begin{itemize}
\item For the direct implication, the idea is to compare the chain with a supercritical  Galton--Watson process, then conclude with the help of Theorem~\ref{surcritique}.
\item The reverse implication is quite simple, because one essentially has to prove that the number of particles explodes as soon as the process survives.
  However, it must be kept in mind that if the local event is more complicated, this part will actually be the most difficult one.
\end{itemize}

\begin{lemme}
 If there exist $a>0$ and $N\ge 1$ such that $a\P^N(Y_1\ge aN)>1$, then $\P^1(\tau=+\infty)>0$.
\end{lemme}
\begin{proof}
Let $X_i^n$ be i.i.d. with $\nu$ as common distribution.
Let $M_0=1$, $Y_0=N$, and then 
$$\forall n\ge 0\quad Y_{n+1}=\sum_{1\le i\le Y_n}X_i^n\text{ and }M_{n+1}=\sum_{i=1}^{M_n} aB_i^n,$$
with $B_i^n=\1_{\{X^n_{(i-1)N+1}+\dots X^n_{iN}\ge aN\}}$.\\
We prove by natural induction that $Y_n\ge NM_n$ for each $n\ge 0$. Indeed, if $Y_n\ge NM_n$, it follows that
\begin{align*}
  Y_{n+1}=\sum_{1\le i\le Y_n}X_i^n\ge \sum_{1\le i\le NM_n}X_i^n&=\sum_{i=1}^{M_n}(X^n_{(i-1)N+1}+\dots X^n_{iN})\\&\ge \sum_{i=1}^{M_n} aNB_i^n=NM_{n+1}.
  \end{align*}
We note that $(M_n)$ is a Galton--Watson process, and its fertility is given by\\ $m=\E[aB_i^n]=a\P^N(Y_1\ge aN)>1$, then it may survive by Theorem~\ref{surcritique}.
Since  $Y_n\ge NM_n$, the process $(Y_n)$ may survive too.
\end{proof}
Note that the proof of the lemma relies on a coupling argument: we make live on the same space $(Y_n)_{n\ge 0}$ and a Galton--Watson process with offspring distribution $(1-q)\delta_0+q\delta_{a}$, where $q=\P^N(Y_1\ge aN)$.\\
This step can be seen as a static renormalization: with the  help of the local events $\{X^n_{(i-1)N+1}+\dots X^n_{iN}\ge aN\}$, we build a growth process involving Bernoulli variables, in such a way that
\begin{itemize}
\item The process using Bernoulli variables is known to be able to survive;
\item  The process using Bernoulli variables is dominated by the process that we study.
  \end{itemize}
  


\begin{proof}[Proof of Theorem~\ref{equivalence}]
By corollary~\ref{souschaine}, $(Y_{nT})_{n\ge 0}$ is a Galton--Watson process. So we can apply the Lemma with $a=2$: $(Y_{nT})_{n\ge 0}$ may survive, thus  $(Y_{n})_{n\ge 0}$ may survive also.


Conversely, let us suppose that $\nu(0)>0$, and $\P^1(\tau<+\infty)<1$.\\
Since $\P^N(\tau<+\infty)=\P^1(\tau<+\infty)^N$, there exists $N$ with $\P^N(\tau<+\infty)<1/2$.


We have noted that $\P^N(\tau<+\infty|\mathcal{F}_t)=\P^1(\tau<+\infty)^{Y_t}$.\\
Since $\P^1(\tau<+\infty)\ge \P^1(Y_1=0)=\nu(0)>0$, we can write
$$Y_t=\frac{\log \P^N(\tau<+\infty|\mathcal{F}_t)}{\log \P^1(\tau<+\infty)}.$$
Now, the Martingale convergence Theorem ensures that
$$\E^N[\1_{\{\tau<+\infty\}}|\mathcal{F}_t]=\P^N(\tau<+\infty|\mathcal{F}_t)\to \1_{\{\tau<+\infty\}}\quad\P^N\text{ a.s.}$$ when $t$ tends to infinity. \\
Particularly, on the event $\{\tau=+\infty\}$, 
$\P^N(\tau<+\infty|\mathcal{F}_t)$ almost surely tends to  $0$ and
$Y_t$ almost surely tends to infinity. Therefore, the following inequality holds $\P^N$-almost surely:
$$\1_{\{\tau=+\infty\}}\le \miniop{}{\liminf}{t\to +\infty}\1_{\{Y_t\ge 2N\}}.$$
With the Fatou Lemma, it follows that
$$\P^N(\tau=+\infty)=\E^N(\1_{\{\tau=+\infty\}})\le \miniop{}{\liminf}{t\to +\infty}\E^N[\1_{\{Y_t\ge 2N\}}]= \miniop{}{\liminf}{t\to +\infty}\P^N(Y_t\ge 2N).$$
Since $\P^N(\tau=+\infty)>1/2$, there exists $T$ such that $\P^N(Y_T\ge 2N)>1/2$.
\end{proof}

\subsection{The critical case}

\begin{theo}
  If $\nu(0)>0$ and $m=1$, then $\P^1(\tau=+\infty)=0$.
\end{theo}

\begin{proof}[First proof]
It is sufficient to note that for every $N,T\ge 1$, we have $$\P^N(Y_T\ge 2N)\le\frac{\E^N(Y_T)}{2N}=\frac{N}{2N}=\frac12,$$
then apply the converse part in Theorem~\ref{equivalence}.
\end{proof}
We now present another line of proof, somewhat longer, but also more robust.
It was used in Garet--Marchand~\cite{GM-BRW} and Gantert--Junk~\cite{Gantert} for the study of some branching random walks.

The first proof is not robust because it exploits the fact that we exactly know how to characterize the critical parameter for survival.
However, in many growth models, the critical parameter can not be given explicitly.
The idea is then: having shown that survival is characterized by the fact that a local event has a fairly high probability, we reason by contradiction and suppose that there is survival at the critical point for a certain parameter.
Then, with a slight modification of the local event, we can, by continuity, exhibit a model of the same family that is a little weaker, for which the local event still has a probability that is large enough to ensure survival, but which must nevertheless die because its parameter has become subcritical.

\begin{proof}[Second proof]
By contradiction, let us assume that we have $\nu(0)>0$, $m=1$ and also $\P^1(\tau=+\infty)>0$.


By Theorem~\ref{equivalence} (converse implication), one can choose $n$ and $T$ such that  $\P^N(Y_T\ge 2N)>\frac12$.

The idea is to provide a coupling with a subcritical process.
Let $(X_i^n)_{i,j\ge 1}$, $(B_i^n)_{i,j\ge 1}$ be independent variables with $X_i^n\sim \nu$,  and the $(B_i^n)_{i,j\ge 1}$'s are  Bernoulli with parameter $p$. Define $Y_0=N$, $Y^p_0=N$, then 

$$\forall n\ge 0\quad Y_{n+1}=\sum_{1\le i\le Y_n}X_i^n\text{ and }Y^p_{n+1}=\sum_{1\le i\le Y^p_n}B_i^n X_i^n.$$

By monotonicity,
$$\miniop{}{\lim}{M\to +\infty}\P^N( \max(Y_i,0\le i\le T)\le M,Y_T\ge 2N)=\P^N( Y_T\ge 2N)>1/2,$$
so there exists $M$ such that $\P( \max(Y_i,0\le i\le T)\le M,Y_T\ge 2N)>1/2$.
We have then
\begin{align*}
\P(Y^p_T\ge 2N)&\ge \P(Y_T\ge 2N,\forall i\le T\quad Y^p_i=Y_i)\\
& \ge \P\left( \begin{array}{l}\max(Y_i,0\le i\le T)\le M,Y_T\ge 2N,\\\forall (t,i)\in\{0,\dots, T-1\}\times\{1,\dots,M\} \quad B_i^t=1\end{array}\right)\\&=\P( \max(Y_i,0\le i\le T)\le M,Y_T\ge 2N)p^{TM}
\end{align*}
Taking $p<1$ large enough, we have $$\P( \max(Y_i,0\le i\le T)\le M,Y_T\ge 2N)p^{TM}>1/2,$$ so $\P(Y^p_T\ge 2N)>1/2$.
But $(Y^p_t)$ is a Galton--Watson process with offspring distribution $B_1^1X_1^1$ and initial distribution $\delta_N$, so by Theorem~\ref{equivalence} (direct implication), this Galton--Watson process may survive.
However $$\E[B_1^1X_1^1]=\E[B_1^1]\E[X_1^1]=pm=p<1,$$ so by Theorem~\ref{mort}, the process can not survive. This is a contradiction.

\end{proof}

%\input{multi-eng}


\input{modele-eng}

\section*{Appendix: source code in Julia}

\begin{Julia}
using AbstractAlgebra

function compute_proba(p,q)
 ex=0
 for a=0:1,b=0:1,c=0:1,d=0:1,e=0:1,f=0:1
     s=a+b
     t=c+d+e+f
     z=p^s*(1-p)^(2-s)*q^t*(1-q)^(4-t)
     m=min(s,t)
     ex+=m*z
 end
 return(ex)
end
 
A,(p,q)=PolynomialRing(ZZ,["p"; "q"])
chaine="h(p,q)="*repr(compute_proba(p,q))
println(chaine)
eval(Meta.parse(chaine))

# from now on
# h(p,q)=4*p^2*q^4-12*p^2*q^3+12*p^2*q^2-
#   4*p^2*q-2*p*q^4+8*p*q^3-12*p*q^2+8*p*q

using Plots
using Distributed
using Distributions
using DistributedArrays

@everywhere using Distributions

println(workers())

@everywhere function montecarlo(N,survie,p,q=p/2)
    s=0
    for i=1:N
    a=Integer(1)
    b=Integer(1)
    while (a>0) && (b>0) && (b<survie) && (a<survie)
     distA=Binomial(2*(a+b),q)
     distB=Binomial(2*min(a,b),p)
     a=rand(distA,1)[1]
     b=rand(distB,1)[1]
    end
    s+=(a>0) && (b>0)
end
return(s/N)
end


pas=0.00125
NMC=1000
interv=0:pas:1
survie=@DArray [montecarlo(NMC,10^8,i,j) for i=interv,
  j=interv]
survie_simul=convert(Array,survie)
heatmap(interv,interv,survie_simul,ratio=1,xlabel="q",
ylabel="p",c=reverse(cgrad(:default)),size=(1200,800))
savefig("survival_both_species_without_dot.png")

function q_critique(pp)    
    qmin=0
    qmax=1
    milieu=0.5
    while ((qmax-qmin)>10^(-12))
        milieu=(qmin+qmax)/2
        if (h(pp,milieu)<1)
            qmin=milieu
        else
            qmax=milieu
        end
    end
    return(milieu)
end

y=0.5:0.01:1
plot!(q_critique.(y),y,linewidth=2,linestyle=:dash,
color=:green,label="h(p,q)=1")
savefig("survival_2_species_with_dot_and_legend.png")
\end{Julia}
%\nocite{*} 

\def\refname{References}
\bibliographystyle{plain}
\begin{thebibliography}{1}

\bibitem{BEK}
Michel Benaïm and Nicole El~Karoui.
\newblock {\em Promenade aléatoire: Chaines de Markov et simulations;
  martingales et stratégies}.
\newblock Ecole Polytechnique, 2004.

\bibitem{MR1071804}
Carol Bezuidenhout and Geoffrey Grimmett.
\newblock The critical contact process dies out.
\newblock {\em Ann. Probab.}, 18(4):1462--1482, 1990.

\bibitem{Durrett}
  Rick Durrett
  \newblock {\em Probability: theory and examples}.
  \newblock Cambridge Series in Statistical and Probabilistic Mathematics,
  \newblock Cambridge University Press, 2010.

\bibitem{Gantert}
  Gantert, Nina and Junk, Stefan
  \newblock A branching random walk among disasters.
  \newblock {\em Electron. J. Probab.}, Vol 22, 2017.
  
\bibitem{Garet-livre}
  Olivier Garet.
  \newblock Probabilités et Processus Stochastiques.
  \newblock distributed by Amazon, 2017, 508 p.
  
\bibitem{GM-BRW}
Olivier Garet and R\'egine Marchand.
\newblock The critical branching random walk in a random environment dies out.
\newblock {\em Electron. Comm. Probab.}, 18(9):1--15 (electronic), 2013.

\bibitem{Grimmett-Marstrand}
G.~R. Grimmett and J.~M. Marstrand.
\newblock The supercritical phase of percolation is well behaved.
\newblock {\em Proc. Roy. Soc. London Ser. A}, 430(1879):439--457, 1990.


\end{thebibliography}



\end{document}

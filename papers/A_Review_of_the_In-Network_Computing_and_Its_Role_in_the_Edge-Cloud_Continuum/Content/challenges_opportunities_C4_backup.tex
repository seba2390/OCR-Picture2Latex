\section{Challenges, Opportunities, and Future Research Directions}\label{Challenges}
\noindent The in-network computing concept is changing the way we perceive the next-generation networking infrastructure. We can now reevaluate where and when data is processed and cached, and how and what is communicated. This paradigm shift has its own challenges, from hardware implementation and architectural design to regulatory and commercial aspects; and its opportunities from autonomy to scalability and to applying AI within the network. In the following, we will review each challenge as well as the opportunities for future research. 

\subsection{Technical Challenges for INC}
\vspace{-3pt}
\subsubsection{Memory} \noindent Recently, the advances in programmable data plane devices open up many opportunities to offload operations or functionalities to the switches. However, the limited memory constraint of the switches remains a major challenge that many applications make struggles to deal with it. Besides, the applications mentioned in Section~\ref{sec:Usecases} face a clear trade-off between performance and memory usage. For instance, in the in-network cache scenario, the cache hit rate and the accuracy of sketches are directly determined by the memory size of the networking equipment~\cite{jin2017netcache, liu2016one}. Similarly, the memory exhaustion of the device directly leads to a slow down of the performance of applications such as load balancing~\cite{miao2017silkroad} and monitoring~\cite{narayana2017language}. Even the most basic function of switches, such as packet forwarding, can suffer from limited memory space. To tackle the memory constraint, one solution is the design of a switching ASIC with internal custom logic and wires for the external Dynamic Random Access Memory (DRAM) access. However, this proves to be costly due to the design of numerous parallel DRAM modules combined with a DRAM controller. Therefore, the on-switch external DRAM is not widely used by vendors in today’s single-chip switches. Another possible solution is to utilize the unused resources and DRAM of the data center networks. However, there are some technical challenges in terms of performance, fault tolerance, and load balancing, though the programmable switch memory can be extended in a cost-effective manner. For example, the work in \cite{kim2020unleashing} particularly explores the possibility of re-purposing the affordable DRAM installed on data center servers to expand the memory available on a switch’s data plane. Instead of building another switching ASIC with a custom external-DRAM-access capability, they simply reuse an existing programmable switching ASIC built only with on-chip memory. The proposed approach designs three remote memory primitives: remote packet buffer, remote lookup table, and remote state store, leveraging Remote Direct Memory Access (RDMA) operations. The experimental result shows that the proposed system achieves high performance in terms of bandwidth, causing a little latency cost and absolutely 0\%  CPU overhead.

\subsubsection{Power consumption} Power consumption of programmable devices is one of the key performance indicators that directly reflect the packet processing efficiency of the chip,  measured in million packets per second per Watt (Mpps/Watt)~\cite{pongracz2013cheap}.
%Therefore, it concerns the researchers in the field of INC. %
Unlike the traditional chips with a lower number of transistors and switching frequency, today’s chips are of smaller volume and embed a large number of transistors that allow them to leave a higher processing capacity. Hence, it leads to more power dissipation which directly reflects the computing time and generates additional cooling costs. To overcome this power dissipation, the work in \cite{yang2019switchagg} redesigned the routing switches. These switches operate in two modes: (i) sleep mode that reduces the leakage power, and (ii) low-power mode that reduces the dynamic power.


\subsection{Adding the control dimension to INC}
\noindent Even though a general theory of goal-oriented communication was put forward a decade ago~\cite{10.1145/2160158.2160161}, this has not been fully achieved yet. However, transitioning to goal-oriented communication is becoming more urgent since end-users have become \textbf{producers} and \textbf{consumers} of contents as their devices are now embedded with various sensors, which help in creating and collecting various types of data from different domains such as energy, agriculture, healthcare, transport, security, and smart homes, among others.  With the exponential growth of diverse IoT devices, as well as various applications (e.g., intelligent manufacturing, smart agriculture), the expectations for the performance, reliability, and security of networks are greater than ever. For example, an industrial control system requires a strict target of a 2 ms network delay and 1 ms jitter. While achieving a controllable and observable system with such target performance metrics has been studied over more than half a century, and various criteria have been developed, difficulties arise when they are straightforwardly applied to a networked system consisting of a large number of subsystems. To be more specific, it has been recognized that for large-scale networked systems, these criteria are usually computationally prohibitive.

To this end, INC has the potential to alleviate the complexities of networked control systems by recognizing that communication is not an end in itself but rather a means to achieve some goals of the communicating parties. 
%Focusing on goals provides a framework for addressing the problem of potential ``misunderstanding” during communication, where ``reliable communication” means overcoming any initial misunderstanding between parties towards achieving a given goal. Redefining the communication reliability also provides a new selection of data to be transported over the network.
%
% \begin{figure}
%     \centering
%     \includegraphics{}
%     \caption{A figure showing IoT network control together with goal-oriented networking.  Similar to Fig 1 of https://arxiv.org/abs/2103.05391}
%     \label{fig:my_label}
% \end{figure}
%

In this aspect, INC can enable 4C, which is the extension of 3C with the addition of physical controllers. The act of control, is the end result of a collection of functions that operate at the management plane, and includes the computing, caching, and communication (3C) functions and their coordination to ensure an efficient operation.  These controllers could be deployed as microservices and placed optimally within the infrastructure alongside the 3C functions. That's where INC can come into play. For instance, a lifecycle management function can be deployed close to a compute function to optimize the control and management of that function on the run, without the delay induced when having a remote management entity. 



%\subsection{Economic Aspects of INC in the NGNI}
\label{INC_business}
 \noindent 
 %Many promising and novel networking and communications technologies are not picked up by the industry due to the promised benefits not meeting the CAPEX and OPEX in the network.  The studies related to network expenditure can be mainly classified into two general categories: (1) identification of CAPEX and OPEX for a network in general, and (2) economic analysis of networks.
 
%First, INC will enable an enhanced distributed collaborative computing paradigm throughout the Cloud-Edge-Mist Continuum in the NGNI. Hence, in addition to supporting low latency applications, INC also has the potential to increase the network utilization. Network traffic often follows daily, hourly, weekly, and seasonal patterns. These patterns may require rapidly not only moving to but also the processing of traffic in less utilized links and INC-enabled routers. Since this rapid modification to the network is not trivial in traditional architectures, network administrators often overprovision their network resources, which increases the CAPEX in the network. For example, the bandwidth is selected to support the highest traffic across a single link. During nonpeak times, this bandwidth is not used and is, therefore, a cost that has no return on investment is incurred. Similarly, the main benefit of cloud computing has been the ability to access computing resources only when it is needed. In the NGNI, traffic can be engineered in near real-time to adjust the needs of the network traffic. This dynamic nature prevents network operators from unnecessary network capacity increases and, thus, produces CAPEX savings. Further studies are needed to quantify CAPEX/OPEX savings of INC in the NGNI. A study of this nature was performed for SDN in \cite{KARAKUS201881} and can be taken as a starting point.
 
 
%Second, as the owner of an INC device may be a single person, an institution, or a company providing other network services, the task of including them in a conventional centralized pricing system is not trivial. Considering the geographical dispersion of the nodes, their mobility, and potential flexibility in the QoS demands, a {\em dynamic} financial model is more suitable for the INC computing architecture. Note that in a simple dynamic pricing model, a computational node, which has processed an offloaded task, bills the edge device usually based on the processing time duration multiplied by a fixed cost per time processing unit. Depending on how far from the edge device the INC node is positioned, it may request an additional incentive that is proportionate to the reduction in latency provided by the shorter network propagation times.  
 

%An SDN with NFN can be considered in action in the pricing of INC with 3C/4C integration. 
%An interest request comprising of content and functions arrives at the first node in the data plane. Suppose both content and function exist at that node and there is enough available capacity. In that case, the task will be executed at that node if the node satisfies the controller’s incentive condition. A request message consisting of the bid for executing the task and obtaining 3C/4C resource status from the execution information base is sent from the node to the controller. Then, the controller computes the cost for the received task and compares it with the bid requested by the node. If the difference is not larger than a specific threshold, the controller sends a verifying message to the node to execute the task. Otherwise, the controller checks another node that satisfies the threshold value and computing capability and will rout the task to that node. Besides, the controller should assign tasks optimally to be executed at the nodes to minimize the overall network cost. 
 

%Additionally, nonmonetary incentives should also be considered for INC in the NGNI. Note that NGNI is expected to support AI applications by supporting their distributed computations. Consequently, INC devices can store these learned models for their future use. This is similar to the financial model used by mobile applications. Additionally, employing INC in the NGNI has indirect incentives to cloud providers and ISPs. Note that by offloading delay-sensitive control tasks from the cloud to local network elements that can perform the latency bounded processing in NGNI, the traffic will be reduced significantly in the cloud. As in-network processing is done within the network, it means that transactions are terminated within their path rather than reach an end-host, saving the latency introduced by the end-host. Throughput is another performance advantage of using INC, which is improved by increasing the packet processing rate using a class of switches, designed as pipelines, continuously moving data without stalls. Lower power consumption is another advantage of INC. Since the overhead of in-network computing is small, and network switches are part of a user’s network, knowing that most of the power consumption is already paid by packet forwarding causes INC to be power efficient. 


%Different dynamic incentive mechanisms, such as those based on deep learning and game theory, can be formulated and applied to incentivize computing nodes to collaborate on the computation of tasks. Tables~\ref{table:Challenges_Economics} presents a classification of some papers on the economics of INC in the Cloud-Edge-Mist Continuum according to regulatory, safety, and incentive mechanism aspects. Using Stackelberg game theory, the incentive mechanism for mobile crowdsensing is proposed in \cite{zhan2020incentive} by taking the mobile users’ own resource demand into the economic model. As different users will have different behavior, they will participate in the mobile crowdsensing on different levels. Moreover, a dynamic incentive mechanism based on a deep reinforcement learning approach is proposed without knowing the private information of the users. Thus, service providers can learn the optimal pricing strategy from game experience. In the NGNI, the controller, as the leader of a Stackelberg game, can split the caching and computational capacity for offloading data and content caching, as well as decide the price dynamically for these services.

  
%Based on Nash bargaining, \cite{tang2020communication} proposes an incentive mechanism for device-to-device communication with 3C resource sharing. In the incentive mechanism, users can reach an agreement that specifies how their devices perform the resource allocation and share the benefits. This mechanism always ensures fair payment by collecting the system information and solving a Nash bargaining problem in a centralized fashion. Such a mechanism may also be useful for INC in the NGNI where the controller can collect the information of the nodes to solve a Nash bargaining problem in a centralized way to assign fairness bids to computing nodes. 


%Finally, the incentives gained by INC should also be distributed in a trusted way throughout the Cloud-Edge-Mist Continuum. In this aspect, distributed ledger methods provide a trustworthy solution. Blockchains and distributed ledgers allow, in general, entities to issue payments directly to each other without requiring either party to be trustworthy. Blockchains have found applications in many domains, including networking. In \cite{9232928}, the authors proposed a blockchain radio access network (B-RAN) that aggregates wireless resources across different service providers and establishes a large network of subnetworks. Furthermore, B-RAN avoids the additional overhead of centralized resource allocation schemes, endorses economic incentives, and builds strong trust between service providers and clients.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{table*}[ht]
\centering
\captionsetup{format=hang}
\caption{Regulatory, Privacy, Safety, Commercial, Legal and Ethical Issues Classification}
\label{table:Challenges_RSE}
\begin{adjustbox}{width=\textwidth,center=\textwidth}
\resizebox{0.5\textwidth}{!}{
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|} 
\hline
\multirow{2}{*}{\textbf{Papers}} & \multicolumn{2}{c|}{\textbf{Regulatory }}             & 
\multicolumn{2}{c|}{\textbf{Privacy }}             &
\multicolumn{1}{c|}{\textbf{Safety }}                                             & \multicolumn{3}{c|}{\textbf{Legal} \And \textbf{Ethical Issues} }  &  \multicolumn{1}{c|}  {\textbf{Commercial} }   \\ 
\cline{2-9}
                                   & \textbf{Distributed Learning}      & \textbf{Knowledge Transfer}        & \textbf{Privacy Protection}        & \textbf{Differential Privacy}        & \textbf{Secure Computation}      & \textbf{Data Ethics}               & \textbf{Applied Ethics}            & \textbf{Business Ethics}      &    \\ 
\hline
\cite{gao2021sedml}                                 & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark &                           &                           &                           & \\ 
\hline
\cite{9629226}                                  &                           & \checkmark &                           &                           & \checkmark &                           &                           &                          &  \\ 
\hline
\cite{anahideh2021choice}                                  &                           & \checkmark &                           &           \checkmark                &  &                           &                           &                           & \\ 
\hline
\cite{8662743}                                &                           &                           &                           &                           &                           & \checkmark & \checkmark &       &                     \\ 
\hline
\cite{9293092}                                &  \checkmark                 &                           &                           &                           &     \checkmark                      &  &     &  &                          \\ 
\hline
\cite{8768490}                                 &                           &                           & \checkmark & \checkmark & \checkmark &                           &                           &            &                \\ 
\hline
\cite{8789542}                                &                           & \checkmark & \checkmark &                       \checkmark    &  &                           &                           &                      &      \\
\hline
\cite{zhan2020incentive}&                           &  &   &                          &  &                           &                           &                      &     \checkmark  \\
\hline
\cite{tang2020communication}                                &                           &   &   &                          &  &                           &                           &                      & \checkmark  \\
\hline
\end{tabular}
} 
 \end{adjustbox}
\end{table*}



\begin{table*}
    \centering
    \caption{Regulatory, Privacy, Safety,Legal and Ethical Issues Table of Acronyms}
    \begin{tabular}{|c|c|}
    \hline
    \textbf{Acronym} & \textbf{Term} \\
    \hline
        ISP & Internet Service Provider \\
        \hline
        INC & In-Network Computing \\
        \hline
        NGNI & Next Generation Network Initiative \\
        \hline
        CEP & Complex Event Processing \\
        \hline
        AI & Artificial Intelligence \\
        \hline
        DL & Deep Learning \\
        \hline
        SEDML & Securely and Efficiently Harnessing Distributed Knowledge in Machine Learning \\
        \hline
        SLA & Service-Level Agreement \\
        \hline
    \end{tabular}
    \label{tab:Acronyms_RSE}
\end{table*}
 \subsection{Regulatory, Privacy, Safety, Legal and Ethical Issues}
 
 \subsubsection{Regulatory}
%No one person, company, organization, or government runs the Internet. It is a globally distributed network comprising many voluntarily interconnected autonomous networks. It operates without a central governing body with each constituent network setting and enforcing its own policies. The central pillar in distributed governance of the Internet is net neutrality. Net neutrality is the concept that all data traffic on a network should be treated indiscriminately, and internet service providers would be restricted from blocking, slowing down, or speeding up the delivery of online content at their discretion. The current debate surrounding net neutrality is principally about how ISPs should be regulated and what role the government should play in overseeing their network management practices. Today, some countries have regulations about ``net neutrality” for networking, but not about cloud computing, which has (probably) been the key to enable the development of a plethora of cloud applications, but has disintermediated the telecommunications operators from the value chain.

INC has the potential to improve the overall system performance in Next Generation Networks Infrastructures (NGNI) by reducing processing time and increasing bandwidth efficiency. INC is steadily changing ``forward-only" routers into server-like devices capable of storing and/or processing incoming data. In other words, as storage and computing grow more affordable, in-network devices will be able to function as standalone servers more frequently. Hence, as computation and caching become new functionalities for ISPs, the network neutrality regulations will need to be reevaluated.  
Note that the regulations will affect the rules on which computing tasks should be transferred to INC devices and which should be retained. This can be handled by Complex Event Processing (CEP) ~\cite{9293092} by transforming the application-specific function into some simple ``match-action" processes for capturing and analyzing data streams to figure out what went wrong (i.e., complex events). Another example is a system created in \cite{9629226} that pools mid-path storage and connects resources to transport data across the end-to-end path. Along the way from the original server to the client, data can transfer from one hop to the next with this new system. It contains a set of mechanisms that ensures: (i) zero packet loss in intermediate network routers, (ii) network stability, and (iii) higher link utilization.
 
 \subsubsection{Privacy}
In cloud computing, the information from all originating nodes is unnecessarily provided to the final destination, which may also create a privacy concern. In this aspect, INC presents a practical trade-off by achieving a privacy-preserving delivery ratio that is near to the ideal. The permission of distributed learning can be provided by subnetworks. Because there are no protocol boundaries between devices when they are all part of the same broadcast domain, imposing security policies is difficult. By breaking up a single large broadcast domain into multiple smaller broadcast domains, a boundary between devices is created.
 
 \subsubsection{Legal and Ethics}
INC will be essential in the support of immersive experience services. Immersive services require even more personal data such as physical attributes of the person to be shared in order to provide a customized service.  Legal and ethical conundrum exits on how this information will be anonymized but it can still be used for customized services.  Although the technical issue of machines for resolving ethical quandaries in the real world is clarified, a society-wide dispute may be necessary to consider and accept the protocols and rules for such services~\cite{8662743}. 
%
%Efficient training of deep learning models necessitates rich data, which is often collected from many sources. This gives an advantage in INC that rich data can be combined in a centralized data center, but because of serious privacy concerns, transmitting sensitive data directly to a single centralized entity for training is not always possible. Furthermore, the data aggregator must adhere to strict data standards. This can be resolved by training the DL model over centralized and encrypted data. With the aim of creating a design for security and utility of distributed knowledge in machine learning, a new protocol called SEDML is introduced in \cite{gao2021sedml}. SEDML is structured on lightweight cryptography. This method is shown to guarantee strong protection for single label prediction while the data is aggregated securely. Throughout the secure gathering procedure, the cloud servers only learn if there is a consensus among the teacher models for a training example. Figure~\ref{fig:SEDML} shows the system architecture of SEDML, a dispensed knowledge in machine learning which is efficiently and securely harnessed.
%\begin{figure}[b]
%\includegraphics[scale=0.4]{Figures/SEDML.png}
%\caption{SEDML system architecture}
%\label{fig:SEDML}
%\end{figure}
%Some machine learning models may have concerns about social inequities and unfairness in the decision-making process. To address this, the designed model shall allow fairness-aware learning. A method is proposed in \cite{anahideh2021choice} for sampling models with varying fairness metrics that are both efficient and effective. Experiments are carried out utilizing real-world benchmark datasets and a variety of classifiers.
%
There are also detailed questions to be resolved, such as the appropriate legal framework when it may be necessary to reveal some of the data or its analysis. Examples include accident data for cars, medical malpractice, and criminal conspiracy.

\subsubsection{Safety and Trust}
An INC node must ensure that the service requests are generated from genuine end-user devices. At the same time, there must be a mechanism to measure the trust of a computing, caching, or control service as well as what are the primary attributes that define the trust of the service. Mainly, a two-way trust relationship is desirable to develop a trusted interaction between INC nodes and end-user devices. An opinion-based model is helpful to choose a computing, caching, or control service. However, the reliability will become an essential factor to be considered. 
%SLA between a cloud service and end-users is limited if the service is processed in the INC. A professional and licensed third-party should monitor SLA verification for end-users and small organizations who lack in technical capability. Although a service provider offers attributes to measure the trust of the service, at the same time, the verification and monitoring of these attributes are not yet studied in detail.


The integration of blockchain with the INC has the potential to enable end-to-end service delivery across the whole ecosystem. Without relying on an intermediary blockchain provides a distributed, unchangeable, single source of truth that everyone agrees with. When INC meets blockchain, two challenges of INC evolve with the advancement of NGNI because of geographically distributed edge nodes and those having limited capabilities. These two challenges that need to be handled are: (i) the assurance of multi-domain resource integration's trustworthiness, and (ii) the overall schedule of heterogeneous and geographically distributed edge and INC resources. For the first challenge, to assure reliability and traceability, blockchain has to be integrated with edge computing and INC. 
%However, most of the work for this focuses solely on the reliability of information, ignoring the trust difficulties that arise throughout the resource allocation process. For the second challenge, some research on the design of a blockchain-based resource management framework is still ongoing. These works, on the other hand, do not address the issue of trust. As a result, the deep aggregation of network resources may be realized compared with challenges. A modular and configurable framework for trusted data management is proposed in \cite{8789542}. The edge device layer, blockchain network layer, and edge nodes layer are all part of this architecture. The mutual authentication protocol, security-enhanced consensus, and smart contracts, as well as block and transaction data management, are all investigated. Blockchain can be adopted by INC to guarantee the information reliability as well as traceability  of transactions, and multidomain resource management is supported by virtual technology, which is widely referred to as network function virtualization. An architecture that addresses heterogeneous resource trust management can be the first one under the background of blockchain meeting INC.


%The degree to which a system is used by different levels of the community is characterized as accessibility. Accuracy, completeness at the point of creation, consistency, and objectivity are all characteristics of trust. Durability is a system attribute that allows software to be available for an extended period~\cite{8768490}. 
The use of INC and blockchain technology can effectively remove the requirement for trust in regulatory compliance. Removing the requirement for trust in regulatory compliance has a challenging technical-legal problem on top of a strong reliance on trust. It can be done by providing access to immutable data to both quality control authorities and enterprises. This will allow control authorities and enterprises to participate more fully in the process. 


\subsubsection{Commercial}\label{INC_business}
INC is an inherently heterogeneous and distributed system and it is possible that different components are governed by independent and competitive autonomous entities.  When in-network computing is performed the cost/benefit should be shared by the related parties.  Although incentive designs and cooperative games are used extensively in the literature for efficient distributed resource allocation in the networks \cite{zhan2020incentive, tang2020communication}, INC introduces additional challenges to be resolved.  These challenges mainly arise due to the scale of operations in INC and it includes efficient and scalable accounting, authentication of operations to be completed, sharing of the incentives (which can be non-monetary).  

Table~\ref{table:Challenges_RSE}, classifies the above discussed papers according to the keywords which they are all mentioned directly or indirectly in papers. Finally, Table~\ref{tab:Acronyms_RSE} gives the acronyms used this section.

%\subsection{NGNI Beyond Shannon Communications }
%\noindent In their seminal work, Shannon and Weaver~\cite{shannon_weaver_1949} categorized communication into three levels based on the purpose of communication; \textit{Level A: Technical}, \textit{Level B: Semantic}, and \textit{Level C: Effectiveness}. At the time, Shannon focused on the technical problem of communicating symbols accurately, and so did the researchers for the following seven decades. Recently, with the increasing differentiation of applications envisioned for 6G, and the soaring need for high bandwidth, there is an emerging interest in the other two types of communications. Semantic communications focus on transferring only the bits that are significant to convey the meaning. With effective communication, the focus is on delivering only the bits that are significant to ensure the receiver takes the action intended by the sender. 
%With both approaches, the core concern is context-specific rather than the error-free delivery of all information symbols, and it is possible to reduce the number of bits transferred by eliminating the bits that are redundant for the application.

%The INC paradigm establishes an opportunity to investigate the problem of semantic and goal-oriented communication in the NGNI. Eliminating the redundancy at the sender may be performed via {\em semantic encoding} at the sender, i.e., determining the next symbol based on the freshness, precision, timeliness and completeness attributes of the information \cite{9475174, uysal2021semantic}. With this approach, communication aims to ensure the sender and receiver are in the same state. 
%Another approach is to determine the next symbol for the sender, based on an estimate of the receiver's understanding of the message. This would be possible via constructing a knowledge base~\cite{CALVANESESTRINATI2021107930} or a knowledge graph~\cite{chein:lirmm-00355336} that is shared between the communicating entities. 
%Such a system typically consists of a computational ontology (providing symbolic representations), facts, rules, and constraints~\cite{chein:lirmm-00355336}, as well as a reasoning engine built on the rules and constraints associated with the given application domain~\cite{CALVANESESTRINATI2021107930}. %The goal of the reasoning engine is to answer questions posed within the application domain.

%The knowledge, which is available at the receiver to interpret the received symbols, is a dynamic notion. In \cite{9530497}, an AI model is used to represent this relationship, and it is trained via coordinated collaboration among edge servers that perform encoding and decoding based on the commonly shared knowledge base. In such architecture, different edge servers can establish and maintain shared AI models without exposing any of their local data uploaded by the users. 

%The cognition of the amount and type of knowledge available to the intended recipient, i.e., the interlocutor, is a determining factor in the message symbols that will be transmitted. In \cite{seo2021semanticsnative}, contextual reasoning is infused into semantics-native communication, such that each speaker agent runs internal simulations by locally and iteratively reasoning about the communication context of the target receiver. Measuring the communication reliability by the receiver's success of correctly recognizing and interpreting the intended message, the expected semantic representation (SR) bit length is derived, which quantifies the extracted effective semantics. Contextual reasoning, i.e., the collection, modeling, reasoning, and distribution of context in relation to sensor data, has also been shown to play a critical role for the Internet of Things (especially for machine-to-machine communications)~\cite{6512846}. In this study, it is argued that the functionalities need to be divided into layers and components in a meaningful manner, such that each component performs a limited subset of the task, and almost independently from the rest.

%Post-Shannon communications are one driving factor towards bringing machine learning together with semantics in network architecture design. Novel deep learning algorithms for knowledge representation in different fields, e.g., speech~\cite{ZeroShotLearn_speech}, image~\cite{CompositionalObverter}, etc., may need to be implemented in the core to reduce end-to-end latencies in communication. In return, the developments in deep learning are the key factor behind the success of post-Shannon communications as such algorithms enable identifying the relevant information at the sender or reducing ambiguity at the receiver, thus improving the goal effectiveness of the communications. Split learning techniques~\cite{gupta2018distributed} may be implemented for speeding up model convergence and improving communication success while preserving communications' confidentiality.


%\subsection{Computation-Caching oriented context-aware Communications } 
 
%\noindent Current and future applications such as federated learning and extended reality have unique requirements that contribute in shifting the focus of network infrastructure researchers from communication-only features to multiple services and functions. Authors of \cite{8869705} advocate that, starting from 6G, network infrastructures must deliver multiple services (i.e., communication, computing, control, and others). That means there must be a tight integration and management of these multiple services while reaching the target performance of each one of them (e.g., computing latency,  stability, etc.). 
%This shift from communication-focused networking has also been supported by the authors of \cite{8808168}, where they proposed a Computation Oriented Communication (COC) service type. This proposed service is supposed to provide an acceptable rate-latency-reliability balance on computation tasks to achieve a certain computational accuracy. The same authors also proposed a Contextually Agile eMBB (enhanced mobile broadband) Communication (CAeC) service type, which is supposed to adapt the provision of eMBB services based on the network context (i.e., link congestion, network topology, or even surrounding physical location and mobility).

%That said, we believe the requirements of NGNI will be even more stringent. By activating INC and the tight integration of 3C/4C, it would be possible for NGNI to offer 3C/4C services throughout the whole Cloud-Edge-Mist Continuum. The provision of these services must be managed according to the availability of 3C resources, but also according to other aspects related to the network and physical context (i.e., link congestion, network topology, mobility, etc.). Given that NGNI will be composed of many distributed and heterogeneous devices belonging to different stakeholders, these latter would also need to cooperate with each other to realize an optimal context-aware 4C service provision. Although this cooperation could be achieved with a compensation or reward-driven approach after solving the convention pricing system challenge discussed in Subsection~\ref{INC_business}, it still adds to the complexity of the problem in hand. That said, realizing a computation-caching oriented context-aware communication that offers 4C services throughout the whole continuum is still an open challenge that needs to be adequately tackled. 
 
%\subsection{Autonomous Networking}
%\noindent Autonomous network management is the holy grail for telecommunication operators. 
%Network autonomy (or automation) could help operators improve a network’s cost-efficiency, %(for reducing maintenance costs), as well as bring flexibility, resilience, ability to bring innovation to market faster, scalability (for different deployments and services), and enhanced security~\cite{NA:whitepaper}. In-network computing allows implementing network functions inside the network. This facilitates in-network control, where the control can be implemented directly inside the network. 
%This idea was proposed in \cite{10.11452740070.2626316}, where it has been argued that datacenter fabric load balancing is best done in the network instead of the transport layer. They have shown that the multipath transport protocol, MPTCP~\cite{10.11452043164.2018467}, is effective for load balancing, but it cannot be implemented in the data center as some applications (e.g., high-performance storage systems) bypass the kernel. In \cite{10.11452740070.2626316}, the authors then proposed a network-based distributed congestion-aware load balancing mechanism for data centers with a global scheme for handling asymmetry and demonstrated that it outperforms MPTCP on a data center testbed. 
%In \cite{10.55553154630.3154637}, the authors performed network resource allocation in hardware (referred to as ``{\em FlexSwitches}''). In \cite{10.11453185467.3185476}, a distributed heavy-hitter detection mechanism is proposed, providing 70\% savings in communication overhead compared to an existing scheme. In \cite{9387694}, the authors proposed an architecture for performing network control functions such as load balancing, congestion control, denial of service attack detection using in-network functions. % MORE DETAILS NEED TO BE ADDED HERE

%To serve traffic workloads efficiently, both service providers and researchers seek ways to enable flexible and demand-aware networking that can exploit the specific spatio-temporal structure of the demand. 
%Demand-aware transportation system has been studied in \cite{9537675}. In a setting with an evolving set of requests for transportation from an origin to a destination before a deadline, the authors study the spatial-temporal demand forecasting and competitive supply (SOUP) problem  and propose a solution that predicts future requests and assigns routes that take into account both the available spatial-temporal request information and the supply-demand state. 
%With the increasing ISP traffic being dominated by a small number of large CDNs connecting at multiple locations, a demand-aware CDN-ISP infrastructure has been proposed in \cite{9566292}. The study was carried out on a large European ISP data, and it revealed that the reconfigurable infrastructure has the potential to reduce backbone capacity by 15\% while reducing path lengths by 30\%, on average and during the critical peak hour. 
%As traffic in data centers grows significantly due to the extensive usage of cloud technologies, the data center network becomes a critical infrastructure for Internet traffic.
%For increased flexibility in the traffic pattern and load that can be serviced by the data center,  free-space optical communications~\cite{10.1145/2619239.2626328} and more recently, optical circuit switches~\cite{10.1145/3098822.3098838} have been utilized, and scalable performance has been demonstrated on proof-of-concept deployments. In \cite{10.1145/3310165.3310170}, the theoretical bounds of demand-aware, {\em self-adjusting} networks have been analyzed.
%The emerging paradigm of utilizing programmable switches in data centers to dynamically adjust their topology based on dynamic traffic demands is investigated in \cite{10.1145/3447868}. 




%\begin{figure}[tb]
%\includegraphics[width=\linewidth]{Figures/ZSM_reference.pdf}
%\caption{The reference architecture for the ZSM framework}
%\label{fig:ZSM_reference}
%\end{figure}

%Recently, due to its importance for %the forthcoming post-5G networks, this topic gained attention from both the research community and international standardization %and industry research organizations. TM Forum’s Zero-touch Orchestration, Operations, and Management (ZOOM)~\cite{TM}, ETSI ZSM (Zero-touch network and Service Management)~\cite{ZSM:intent}, ETSI ENI  ISG (Experiential Network Intelligence Industry Specification Group)~\cite{ETSI}, Open Network Automation Platform (ONAP)~\cite{ONAP}, ITU Focus Group on Autonomous Networks (FG-AN)~\cite{FGAN} bring together different market players to outline the architectures and mechanisms that can achieve the goal of autonomous networks. 

%The aim of network automation is to provide zero-touch network management that requires no human involvement. Artificial intelligence is a key enabler to facilitate self-management. As an example, at the heart of the ZSM framework reference architecture (Figure~\ref{fig:ZSM_reference}) lie intelligent and cognitive {\em closed-loops} (CLs) capable of learning the optimal behavior through interaction with the network~\cite{ZSM:intent}. 
%Machine learning methods allow these CLs to adapt to the changing conditions dynamically and thus help to maintain a robust and flexible network. Another pillar of autonomous networking via the ZSM architecture is modularity (comprising self-contained, loosely coupled services) and the use of {\em intent}-based interfaces. Intents are declarative policies that allow network operators to provide requirements at a high level to simplify and improve the agility of the operations. The intents comprise logical functions that implement data collection, processing, and analysis; these functions are connected to create a machine learning pipeline to provide policy-based network/service automation, thus constituting the Intent-Based Networking (IBN) and closed-loop automation solutions~\cite{9627829}. 

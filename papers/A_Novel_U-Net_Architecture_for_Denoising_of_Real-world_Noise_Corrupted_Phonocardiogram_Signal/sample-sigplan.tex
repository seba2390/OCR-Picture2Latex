%%
%% This is file `sample-sigplan.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `sigplan')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigplan.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass command.
\documentclass[sigconf,screen]{acmart}
%% NOTE that a single column version is required for 
%% submission and peer review. This can be done by changing
%% the \doucmentclass[...]{acmart} in this template to 
%% \documentclass[manuscript,screen,review]{acmart}
%% 
%% To ensure 100% compatibility, please check the white list of
%% approved LaTeX packages to be used with the Master Article Template at
%% https://www.acm.org/publications/taps/whitelist-of-latex-packages 
%% before creating your document. The white list page provides 
%% information on how to submit additional LaTeX packages for 
%% review and adoption.
%% Fonts used in the template cannot be substituted; margin 
%% adjustments are not allowed.
%%
%% \BibTeX command to typeset BibTeX logo in the docs
% \AtBeginDocument{%
%   \providecommand\BibTeX{{%
%     \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}
    \makeatletter
\def\@copyrightpermission{\relax}
\makeatother
\settopmatter{printacmref=false}
\acmDOI{}
\acmISBN{}
%\mycrnotice{}
%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
% \setcopyright{acmcopyright}
% \copyrightyear{2018}
% \acmYear{2018}
% \acmDOI{XXXXXXX.XXXXXXX}

%% These commands are for a PROCEEDINGS abstract or paper.
% \acmConference[Conference acronym 'XX]{Make sure to enter the correct
%   conference title from your rights confirmation emai}{June 03--05,
%   2018}{Woodstock, NY}
%
%  Uncomment \acmBooktitle if th title of the proceedings is different
%  from ``Proceedings of ...''!
%
%\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%  June 03--05, 2018, Woodstock, NY} 
% \acmPrice{15.00}
% \acmISBN{978-1-4503-XXXX-X/18/06}


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}
\usepackage{graphics}
\usepackage{epsfig} 
\usepackage{caption}
\usepackage{subcaption}
 % for pdf, bitmapped graphics files
% for postscript graphics files
%\usepackage{mathptmx} % assumes new font selection scheme installed
%\usepackage{times} % assumes new font selection scheme installed
%\usepackage{amsmath} % assumes amsmath package installed
%\usepackage{amssymb}  % assumes amsmath package installed

% \usepackage{cite}
%%

% \copyrightowner{}
%% end of the preamble, start of the body of the document source.
% \usepackage[number]{natbib}
% \usepackage{notoccite}
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{A Novel U-Net Architecture for Denoising of Real-world Noise Corrupted Phonocardiogram Signal}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Ayan Mukherjee}
% \authornote{Both authors contributed equally to this research.}

% \orcid{1234-5678-9012}
% \author{G.K.M. Tobin}
% \authornotemark[1]
% \email{webmaster@marysville-ohio.com}
\affiliation{
  \institution{TCS Research \\ Tata Consultancy Services}
   % \\ \institution{Tata Consultancy Services}
  % \streetaddress{P.O. Box 1212}
  \city{Kolkata}
  \state{West Bengal}
  \country{India}}
  \email{ayan.m4@tcs.com}
  
\author{Rohan Banerjee}
\affiliation{%
  \institution{TCS Research \\ Tata Consultancy Services}
     % \\ \institution{Tata Consultancy Services}
  % \streetaddress{1 Th{\o}rv{\"a}ld Circle}
  \city{Kolkata}
  \state{West Bengal}
  \country{India}}
\email{rohan.banerjee@tcs.com}

\author{Avik Ghose}
\affiliation{%
  \institution{TCS Research \\ Tata Consultancy Services}
     % \\ \institution{Tata Consultancy Services}
  % \streetaddress{1 Th{\o}rv{\"a}ld Circle}
  \city{Kolkata}
  \state{West Bengal}
  \country{India}}
\email{avik.ghose@tcs.com}

% \author{Aparna Patel}
% \affiliation{%
%  \institution{Rajiv Gandhi University}
%  \streetaddress{Rono-Hills}
%  \city{Doimukh}
%  \state{Arunachal Pradesh}
%  \country{India}}

% \author{Huifen Chan}
% \affiliation{%
%   \institution{Tsinghua University}
%   \streetaddress{30 Shuangqing Rd}
%   \city{Haidian Qu}
%   \state{Beijing Shi}
%   \country{China}}

% \author{Charles Palmer}
% \affiliation{%
%   \institution{Palmer Research Laboratories}
%   \streetaddress{8600 Datapoint Drive}
%   \city{San Antonio}
%   \state{Texas}
%   \country{USA}
%   \postcode{78229}}
% \email{cpalmer@prl.com}

% \author{John Smith}
% \affiliation{%
%   \institution{The Th{\o}rv{\"a}ld Group}
%   \streetaddress{1 Th{\o}rv{\"a}ld Circle}
%   \city{Hekla}
%   \country{Iceland}}
% \email{jsmith@affiliation.org}

% \author{Julius P. Kumquat}
% \affiliation{%
%   \institution{The Kumquat Consortium}
%   \city{New York}
%   \country{USA}}
% \email{jpkumquat@consortium.net}

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
% \renewcommand{\shortauthors}{Trovato and Tobin, et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
 The bio-acoustic information contained within heart sound signals are utilized by physicians world-wide for auscultation purpose. However, the heart sounds are inherently susceptible to noise contamination. Various sources of noises like lung sound, coughing, sneezing, and other background noises are involved in such contamination. Such corruption of the heart sound signal often leads to inconclusive or false diagnosis. To address this issue, we have proposed a novel U-Net based deep neural network architecture for denoising of phonocardiogram (PCG) signal in this paper. For the design, development and validation of the proposed architecture, a novel approach of synthesizing real-world noise corrupted PCG signals have been proposed. For the purpose, an open-access real-world noise sample dataset and an open-access PCG dataset has been utilized. The performance of the proposed denoising methodology has been evaluated on the synthesized noisy PCG dataset. The performance of the proposed algorithm has been compared with existing state-of-the-art (SoA) denoising algorithms qualitatively and quantitatively. The proposed denoising technique has shown improvement in performance as comparison to the SoAs.
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10010147</concept_id>
       <concept_desc>Computing methodologies</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10010147.10010257.10010293.10010294</concept_id>
       <concept_desc>Computing methodologies~Neural networks</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10010405</concept_id>
       <concept_desc>Applied computing</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10010405.10010444</concept_id>
       <concept_desc>Applied computing~Life and medical sciences</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10010405.10010444.10010449</concept_id>
       <concept_desc>Applied computing~Health informatics</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10010405</concept_id>
       <concept_desc>Applied computing</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10010405.10010444</concept_id>
       <concept_desc>Applied computing~Life and medical sciences</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10010405.10010444.10010449</concept_id>
       <concept_desc>Applied computing~Health informatics</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Computing methodologies}
\ccsdesc[500]{Computing methodologies~Neural networks}
\ccsdesc[500]{Applied computing}
\ccsdesc[500]{Applied computing~Life and medical sciences}
\ccsdesc[500]{Applied computing~Health informatics}



%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Heart sound, Deep learning, Real-world noise, Denoising architecture, Phonocardiogram, U-Net}

%% A "teaser" image appears between the author and affiliation
%% information and the body of the document, and typically spans the
%% page.
% \begin{teaserfigure}
%   \includegraphics[width=\textwidth]{sampleteaser}
%   \caption{Seattle Mariners at Spring Training, 2010.}
%   \Description{Enjoying the baseball game from the third-base
%   seats. Ichiro Suzuki preparing to bat.}
%   \label{fig:teaser}
% \end{teaserfigure}

% \received{20 February 2007}
% \received[revised]{12 March 2009}
% \received[accepted]{5 June 2009}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle
\section{introduction}

The pumping action of the heart circulates blood throughout the body. During the circulation the opening and closing of the heart valves gives rise to the heart sounds. The four fundamental heart sounds are: 1) first heart sound (S1), 2) second heart sound (S2), 3) systolic interval and 4) diastolic interval. The heart sound is heard by physician/clinician using stethoscope for auscultation purposes. However, owing to the characteristic low amplitude of the heart sound signal, it is naturally susceptible to ambient noises \cite{leal2018noise}. 
% Some of the sources of such noise are human speech in the background, breathing sound, frictional noise generated due to the movement of the chest-piece of the stethoscope on human body. 
Sample recordings of a noisy and a clean PCG signals are plotted in Fig. \ref{fig:clean_normal.png} and Fig.~\ref{fig:clean_murmur.png} respectively. 
\begin{figure}
	\begin{subfigure}{.48\textwidth}
		\centering
		% include second image
		\includegraphics[width=0.96\textwidth]{template/clean_normal.png}
		\caption{Plot of clean phonocardiogram signal}
		\label{fig:clean_normal.png}
	\end{subfigure}
	\begin{subfigure}{.48\textwidth}
		\centering
		% include first image
		\includegraphics[width=0.96\textwidth]{template/Final_pic.png}
		\caption{Plot of noisy phonocardiogram signal}
		\label{fig:clean_murmur.png}
	\end{subfigure}
	\caption{Plot of noisy and clean phonocardiogram signal}
	\label{fig:Typical real-world clean and noisy phonocardiogram signals}
\end{figure}
It can be surmised from the figures that in the case of the noisy heart sound recording, the significant features of the signal become obfuscated due to the noise corruption. Under such a scenario, reliable auscultation become difficult even for the experts at places like out patients departments and non-clinical environments.

Thanks to the recent advances in artificial intelligence and machine learning techniques, an automatic diagnosis of different pathological conditions is possible from a PCG.  However, noisy signals severely impact the performance of such algorithms as well. Hence, it can be concluded that denoising is an essential and practical pre-processing step required to ensure reliable auscultation/decision-making for human experts/machine driven algorithms. 

The research complexity of denoising PCG corrupted with real-world noise arises due to 1) the wide gamut of naturally occurring noise sources that can corrupt the heart sound, and 2) the significant spectral overlap that exists between the heart sound spectrum and the noise spectrum. 
% Some of the common non-stationary noises that corrupts PCG recordings are those of child cries and whispers, sound created due to the friction between the chest piece and the body surface (crumpling and crinkling, hiss), sneeze, cough, etc.  

\begin{figure}[]
	\centering
	\includegraphics[width=0.48\textwidth]{template/Frequency_overlap_HS_noise.png}
	\caption{Spectrum of PCG signal and typical real-world noises}
	\label{Frequency_overlap_HS_noise}
\end{figure}
In Fig.~\ref{Frequency_overlap_HS_noise} , the spectral plot of typical heart sound cycles, and other real-world noise samples like \textit{child speech}, \textit{sneeze}, \textit{cough}, \textit{crumpling and crinkling} are plotted. The significance of overlap between the spectrums as can be observed from the figure. 
% significant overlap between the spectrums of the heart sounds and the different noise samples.   

% A lot of phonocardiogram (PCG) de-noising algorithms has been published in literature. 
% The particular dataset used for the present study is the PhysioNet Challenge 2022 dataset. In each of the recordings, varying segments of it has been annotated by an expert. It is noted that for each of the recordings, only the relatively clean part of the recordings has been annotated. Almost $50\%$ of the recordings has been left un-annotated. The dataset consists of $3240$ PCG recordings collected primarily from four locations (mitral valve,pulmonary valve, etc.).

% The time series and corresponding spectrogram plots of clean and noisy PCG recording segments are plotted in Fig. ... .

% De-noising is extremely beneficial to the PCG classification task [ref]. 

% \begin{figure}[]
% 	\centering
% 	\includegraphics[width=0.48\textwidth]{template/clean_murmur.png}
% 	\caption{Plot of clean phonocardiogram signal with murmur}
% 	\label{clean_murmur}
% \end{figure}
% \begin{figure}[]
% 	\centering
% 	\includegraphics[width=0.48\textwidth]{template/clean_normal.png}
% 	\caption{Plot of clean phonocardiogram signal of normal subject}
% 	\label{clean_normal}
% \end{figure}
% \section{Literature review}
Two types of approaches for dealing with noisy heart sound signals exist in literature. In the first approach, the noisy part of the signal is identified and discarded. Such noisy segment identification is done based on signal quality metrics \cite{springer2014signal}. The other approaches modifies the noisy signal through some form of filtering like bandpass filtering \cite{de2007automated}, spectral subtraction \cite{ tosanguan2008modified, paul2006noise}, etc. to retrieve the clean signal. However, due to the spectral overlap between the signal and noise spectrum such methods are largely ineffective \cite{asmare2021can}. Wavelet transform is another widely used technique used for denoising of heart sound \cite{ agrawal2013wavelet, messer2001optimal}. However, the performances of such algorithms are highly sensitive to the setting of the thresholds \cite{asmare2021can}. 
% A detailed discussion on the efficacy of the existing heart sound denoising algorithms is reported in \cite{asmare2021can}. 
% In recent times deep learning based approaches like denoising autoencoders have been successfully utilised in noise removal. An autoencoder has two components. The encoder tries to learn the salient properties of the original signal under noise influence and represents it as a latent space in order to reconstruct the original signal using the decoder.

While all the existing state-of-the-art (SoA) heart sound denoising algorithms have reported effective denoising of  noisy heart sound signals, most of those have considered only additive white gaussian (AWG) signal as the noise component \cite{asmare2021can}. This makes the reliability of such PCG denoising algorithms uncertain under real-world noise corruptions. 
% Hence, a denoising architecture designed to mitigate the complex signal processing challenges of the real-world noise corrupted heart sound recordings is an immediate requirement that is yet to be addressed.

In order to address this research issue, the present research work proposes a deep learning architecture for denoising of PCG signals corrupted with real-world noise recordings.

The major contributions of the present research work are:
\begin{enumerate}
    \item Development of a noisy PCG signal dataset based on real-world noise samples (child speak, cough, sneeze, crumpling and crinkling, hiss).
    \item Development of a U-net based deep learning denoising architecture for reliable denoising of real-world noise corrupted heart sound signals.
    \item Thorough evaluation of the proposed denoising architecture with simulated real-world noise corrupted PCG signal dataset as well as performance comparison with the existing SoA denosing algorithms.
 
\end{enumerate}

The rest of the paper is organized as follows:

Section II presents the process for the synthesis of the real-world noise corrupted PCG signal dataset. Section III provides a detailed description of the proposed U-Net based denoising architecture. The evaluation of the proposed architecture and comparative analysis with existing SoA denosing techniques are presented in Section III followed by conclusion in Section IV.
\section{dataset description} 
%While a number of publicly available PCG datasets are there, non of those are suitable for development of PCG denoising algorithm. In order to fill the void, a new datset has been prepared that incorporates different types of common PCG artifacts and noises has been incorporated.
\subsection{Heart sound dataset}
For the present research work, a subset of the publicly available \textit{PASCAL} heart sound dataset (\textit{Btraining\_normal} subset) \cite{pascal-chsc-2011} has been utilized. The choice of the dataset was motivated by the availability of clean heart sound signals, which is the fundamental requirement of the present research endevour. The dataset consists of $200$ clean heart sound signals of varying lengths (between $1$ second and $30$ seconds). The signals are sampled at $4$ KHz and saved as audio files in \textit{wav} format.
\subsection{Real world noise sample dataset}
In order to generate the noisy PCG recordings portions of real-world noise recordings have been used. The publicly available \textit{ARCA23K} dataset \cite{Iqbal2021} provides labeled real-world sound events. It consists of $23727$ audio clips of varying lengths and along with annotations ($70$ class labels). All the \textit{ARCA23K} recordings are sampled at $44.1$ KHz and saved as audio files in \textit{wav} format.
\subsection{Noisy heart sound dataset synthesis}
Among the $70$ labels of the \textit{ARCA23K} dataset, only a subset of it has relevance (can be considered as noise) for heart sound corruption in a real-world setting. Hence, for the present work, we considered only those audio files that had one of the following labels as annotation: (1) \textit{Crumpling and crinkling}, (2) \textit{Child speech and kid speaking}, (3) \textit{hiss}, (4) \textit{sneeze}, and (5) \textit{cough}. 
%The details of the noise time series are given in table \ref{tab:noise recording details}. 
All such relevant noise recordings were resampled to $4$ KHz to match the sampling rate of the \textit{PASCAL} heart sound recording. Now, the steps followed for mixing the down-sampled noise recordings with the clean PCG signals are enumerated as follows: 
\begin{enumerate}
	\item Random number of segments of varying lengths are generated from noise audio samples.
	\item For each category of noise, the segments are randomly placed on a zero vector of length equal to the heart sound recording under consideration. This results in the generation of category-wise noise vectors.
	\item The noise vectors are normalized between $[-1,1]$.
	\item Now, the noise vectors are added sample-wise to the heart sound vector.
	\item The resultant vector is again normalized between $[-1,1]$ to generate the noisy heart sound vector.
\end{enumerate}
\begin{table}[]
	\caption{Noise statistics}
	\label{Noise_statistics}\centering
\begin{tabular}{p{3.7cm}p{1cm}p{0.75cm}p{0.75cm}p{0.75cm}}
Noise category & \# of segments & Mean (Sec) & Std (Sec) & Mode (Sec) \\ \hline
\textit{Child speech and kid speaking} & 5892           & 0.76       & 0.76                                                & 0.29       \\ \hline
\textit{Hiss}                     & 21719          & 0.64       & 0.68                                                & 0.37       \\ \hline
\textit{Crumpling and crinkling}        & 21569          & 0.62       & 0.66                                                & 0.11       \\ \hline
\textit{Cough}                     & 5910           & 0.84       & 0.73                                                & 0.45       \\ \hline
\textit{Sneeze}                      & 5892           & 0.84       & 0.73                                                & 0.25  \\ \hline 
\end{tabular}
\end{table}
Samples of the noise vectors generated following the above steps are shown in Fig.~\ref{fig:Noise_samples}.
\begin{figure}
	\begin{subfigure}{.48\textwidth}
		\centering
		% include second image
		\includegraphics[width=0.96\textwidth]{template/Child_speech.png}
		\caption{\textit{Child speech} noise vector}
		\label{fig:Child_speech}
	\end{subfigure}
	\begin{subfigure}{.48\textwidth}
		\centering
		% include second image
		\includegraphics[width=0.96\textwidth]{template/cough.png}
		\caption{\textit{Cough} noise vector}
		\label{fig:cough}
	\end{subfigure}
	\begin{subfigure}{.48\textwidth}
		\centering
		% include second image
		\includegraphics[width=0.96\textwidth]{template/Crinkling.png}
		\caption{\textit{Crinkling and crumpling} noise vector}
		\label{fig:Crinkling}
	\end{subfigure}
	\begin{subfigure}{.48\textwidth}
		\centering
		% include second image
		\includegraphics[width=0.96\textwidth]{template/Hiss.png}
		\caption{\textit{Hiss} noise vector}
		\label{fig:Hiss}
	\end{subfigure}
	\begin{subfigure}{.48\textwidth}
		\centering
		% include first image
		\includegraphics[width=0.96\textwidth]{template/Sneeze.png}
		\caption{\textit{Sneeze} noise vector}
		\label{fig:Sneeze}
	\end{subfigure}
	\caption{Samples of normalized noise vectors for different labels}
	\label{fig:Noise_samples}
\end{figure}
%\begin{table}[h!]
%	\caption{ Noise recording details}
%	\centering
%	\label{tab:noise recording details}
%	\begin{tabular}{|p{2.5cm}|p{2cm}|p{3cm}|}
%		\hline
%		\textbf{Noise type} & \textbf{number of files} & record duration \\ &&(mean \pm std) \\
%		\hline 
%		Crumpling and crinkling & &  \\
%		\hline 
%		Child speech and kid speaking &  &\\
%		\hline 
%		hiss &  &\\
%		\hline
%		sneeze &  &\\
%		\hline
%		cough &   &\\
%		\hline
%		Tap &   &\\
%		\hline
%		Tick &  & \\
%		\hline
%	\end{tabular} 
%	% }}
%\end{table}
\section{methodology}
\subsection{Pre-processing}
Taking cognizance of the limited spectral bandwidth of a typical heart sound cycles (Fig. \ref{Frequency_overlap_HS_noise}) each noisy PCG time series is down-sampled from $4$ KHz to $1500$ Hz. Next, from the down-sampled signal, non-overlapping data-frames are extracted (window length = 1.5 seconds, rectangular window). Now each such 1-D dataframe is transformed to the time-frequency domain using short time Fourier transform (STFT). The STFT parameters used for the present application (samples per segment = $64$, FFT points = $128$, window = $Hanning$, scaling  = $spectrum$, segment overlap= $50\%$). These are standard STFT parameters reported in research literature \cite{grais2017two}.  This transformation generates the spectrum matrix ($Z_{xx}$) with dimension $65\times72$. The typical STFT frames generated for clean and noisy dataframes are shown in Fig.~\ref{fig:clean_stft.png} and Fig.~\ref{fig:Noisy_stft.png} respectively. Clear reflection of the noise corruption can be observed in Fig.~\ref{fig:Noisy_stft.png}. $Z_{xx}$ is further split into its real and imaginary matrix components. The component matrices are resized to $64\times64$  and are concatenated along the third axis. The resulting $64\times64\times2$ matrix is fed into the deep neural network architecture discussed in the following section. 
\begin{figure}
	\begin{subfigure}{.45\textwidth}
		\centering
		% include second image
		\includegraphics[width=0.8\textwidth]{template/clean_stft.png}
		\caption{STFT plot for a dataframe of clean a PCG signal}
		\label{fig:clean_stft.png}
	\end{subfigure}
	\begin{subfigure}{.45\textwidth}
		\centering
		% include first image
		\includegraphics[width=0.8\textwidth]{template/Noisy_stft.png}
		\caption{STFT plot for a dataframe of a noisy PCG signal}
		\label{fig:Noisy_stft.png}
	\end{subfigure}
	\caption{STFT plots corresponding to dataframes ($1.5$ seconds) of clean and noisy PCG signals}
	\label{fig:typical clean and noisy STFT}
\end{figure}
\subsection{Proposed U-net based denoising approach }
U-Net is a widely used fully convolutional deep neural network architecture. It has been widely applied in image segmentation \cite{ronneberger2015u}, image denoising \cite{bao2020real} and restoration \cite{aghabiglou2021projection}. However, to the best of the knowledge of the authors, the present application of the U-Net architecture for the denoising of 1D physiological time series data is a novel application of U-Net. The U-Net has a similar architecture to that of the denoising autoencoder-decoder network. However, in U-Net, the presence of skip connections transfer the fine-grained information from the  analysis path to the synthesis path. Such information allows the network to recostruct signals with accurate finer morphological details. This property of the U-Net is the motivation behind its choice as the learning model for the present application. For the purpose, the architecture proposed in  \cite{ronneberger2015u} has been utilized with minor modifications. The architecture can be referred to in \cite{ronneberger2015u}.
The flow of the U-net architecture in the context of the present application is summarized as follows:
% The hyper-parameters used for running the U-net architecture are discussed as follows: 

 The $64\times64\times2$ input (as discussed in the preceeding subsection) is filtered by 2D convolution filters (number of filters are increased from $8$ to $128$ in steps) and downsampled using \textit{max-pooling}($2\times2$) in steps to $4\times4\times128$. This latent space is again filtered and upsampled for signal synthesis such that the output of the final layer dimension-wise matches the input. For the optimization of the tunable network parameters Nadam optimizer has been employed ($\beta_{1}$ = $0.9$,$\beta_{2}$ = $0.99$,$\epsilon$ = $1e-07$ , learning rate = $0.0005$). The optimized function is the mean-squared error (\textit{mse}). Further \textit{early-stopping criteria} has been imposed upon the training to mitigate the curse of over-fitting. The batchsize is set to 128 and maximum epoch is set to 100. Further, batch normalization has been employed to limit the effect of over-fitting. Rectified linear unit (ReLU) function has been used as the non-linear activation function across all the layers of the network.   
\subsection{Post-processing}
In the post-processing stage, the ouput spectrum frames are  resized to ($65\times72$) and then transformed back to the 1-D data frames using inverse STFT. Finally the frames are concatenated to obtain the denoised heart sound time series.
\section{Results and discussion}
The proposed architechture has been simulated in the Python environment using Pycharm IDE. The TensorFlow version used for the U-Net architecture realization is 2.7.4. From the $200$ clean \textit{PASCAL} heart sound recordings, following the process already discussed (\textit{section II}, \textit{subsection C}), 4000 noisy recordings has been generated. The noisy recordings is further split into training, validation and test partitions in the ratio of 64:16:20. The split has been done at the subject level in order to ensure that data of none of the subjects is present in more that one partion. The real-world noisy heart sound data simulation and the deep learning training and testing is done in a computing device with 16 GB RAM, i5 8 core processor and 256 GB disk capacity. 
In addition to the evaluation of the proposed heart sound denoising architecture, the performance of the proposed architecture has been compared with a wavelet-thresholding (WT) \cite{ghanbari2006new} based SoA technique and a baseline denoising auto-encoder (DAE) architecture \cite{banerjee2022noise},\cite{vincent2008extracting}.  respectively.
\begin{equation}\label{eq:RMSE}
RMSE = \sum_{n=1}^{K}\sqrt{(P_c[n]-P_p[n])^{2}}
\end{equation}

\begin{equation}\label{eq:ME}
    ME = median_{n=1}^{K}(|P_c[n]-P_p[n]|)
\end{equation}

\begin{equation}\label{eq:SNR}
SNR = 10log_{10}(\frac{\sum_{n=1}^{M}(P_c[n]-\mu_0)^{2}}{\sum_{n=1}^{M}(P_c[n]-P_p[n])^{2}})
\end{equation}
where $P_c$ is the clean PCG signal (target), $P_p$ is the noisy PCG signal and $\mu_{0}$ is the mean of $P_c$.

\begin{table}[]
	\caption{Comparative evaluation of the proposed denoising technique with existing state of the art denoising approaches}
	\label{performance}\centering
\begin{tabular}{p{3cm}p{1.25cm}p{1.25cm}p{1.25cm}}\hline
                               Method               & Mean RMSE & Mean MAE & Mean SNR      \\ \hline  
Proposed                    & 0.7588                            & 0.1063       & -2.4449  \\ \hline  
WT based            & 0.8772                            & 0.1232       & -3.6469  \\ \hline  
Baseline DAE based  & 1.8818                            & 0.2130       & -18.5644 \\ \hline  
\end{tabular}
\end{table}

% \begin{figure}[]
% 	\centering
% 	\includegraphics[width=0.4\textwidth]{template/train_vs_eval_loss.png}
% 	\caption{Plot of training and validation loss as obtained for the training of the proposed U-Net denoising architecture}
% 	\label{train_vs_eval_loss.png}
% \end{figure}
% The training loss and validation losses are plotted in Fig.~\ref{train_vs_eval_loss.png}. It can be observed that over the course of the epochs, the validation error has followed the training loss pattern closely, indicating a robust training.  

The quantitative evaluation of the proposed denoising algorithm is done based on three metrics: root mean square error (RMSE), median absolute error (MAE) and signal to noise ratio (SNR). The mathematical representations of the three metrics are given in (\ref{eq:RMSE}), (\ref{eq:ME}) and (\ref{eq:SNR}). 
The performance of the proposed algorithm and the two SoA techniques in terms of the three metrics are reported in Table \ref{performance}. From the reported metric values it can be observed that the proposed denoising architecture has performed better than the two SoAs comprehensively. 
In addition, for qualitative assessment, a sample of the test noisy heart sound signal  and clean heart sound signal (target) are plotted in Fig. \ref{fig:Result_Noisy} and Fig.~\ref{fig:Result_Clean} respectively. The de-noised heart sound signals as obtained from the proposed denoising architecture is plotted in Fig.~\ref{fig:Result_Proposed}. Further, the denoised time series as obtained from the SoAs (WT and DAE) are plotted in Fig.~\ref{fig:Result_WT} and Fig.~\ref{fig:Result_DAE} respectively. It can be observed that the proposed methodology is able to effectively remove the real-world noises from the noisy signal while preserving the S1 and S2 characteristics. The wavelet based approach has introduced a narrow band of noise along the time series as well as thinned out the S1, S2 peaks thereby impacting its audio characteristics. The DAE based method has failed to perform any effective noise cleaning. 
\begin{figure}
	\begin{subfigure}{.48\textwidth}
	\centering
	% include second image
	\includegraphics[width=0.96\textwidth]{template/Result_Clean.png}
	\caption{Reference clean heart sound signal}
	\label{fig:Result_Clean}
\end{subfigure}
	\begin{subfigure}{.48\textwidth}
	\centering
	% include second image
	\includegraphics[width=0.96\textwidth]{template/Result_Noisy.png}
	\caption{Noisy heart sound signal}
	\label{fig:Result_Noisy}
\end{subfigure}
	\begin{subfigure}{.48\textwidth}
		\centering
		% include second image
		\includegraphics[width=0.96\textwidth]{template/Result_Proposed.png}
		\caption{Heart sound signal denoised using the proposed denoising architecture}
		\label{fig:Result_Proposed}
	\end{subfigure}
	\begin{subfigure}{.48\textwidth}
	\centering
	% include second image
 	\includegraphics[width=0.96\textwidth]{template/Result_WT.png}
	\caption{Heart sound signal denoised using baseline Wavelet thresholding based approach }
	\label{fig:Result_WT}
	\includegraphics[width=0.96\textwidth]{template/Result_DAE.png}
	\caption{Heart sound signal denoised using baseline autoencoder-decoder architecture}
	\label{fig:Result_DAE}
\end{subfigure}
%	\begin{subfigure}{.48\textwidth}
%	\centering
%	% include first image
%	\includegraphics[width=0.96\textwidth]{template/Result_WT.png}
%	\caption{Heart sound signal denoised using baseline wavelet based denoising architecture}
%	\label{fig:Result_WT}
%\end{subfigure}
\caption{Performance plots of different noise cleaning architecture on a sample of heart sound recordings}
\label{fig:fig}
\end{figure}
\section{CONCLUSIONS}
Heart sounds signal are in general vulnerable to ambient noises and hence denoising is considered as a critical pre-processing step in the subsequent analysis for potential disease diagnosis. Simulating such noise-contaminated PCG signal is challenging and the existing denoising approaches use AWG as the noise source for data corruption. A machine learning model trained on such data is less likely to generalize in practical scenario. In this paper, we propose a novel pipeline for simulating realistic noisy PCG signals. Further, we propose a novel U-Net based PCG denoising algorithm that can reliably reconstruct both the amplitude and the phase information of the PCG data from realistic noisy PCG recordings. The realistic noisy PCG signals synthesized has been used to training the proposed deep learning model. Our experiments on publicly available dataset and subsequent quantitative and qualitative analysis and comparison with other existing SoA denoising algorithms clearly indicates the efficacy of the proposed approach. 
\newline Denoising is a critical application for any PCG recording device front-end. Therefore, our future works would be to optimize the model for effective deployment on low-powered embedded platforms. 
% We are also working on evaluating our model on other publicly available datasets covering PCG data corresponding to different types of heart diseases in order to widen the ambit of the proposed denoising architecture.
% \bibliographystyle{ACM-Reference-Format}
\bibliographystyle{unsrt}
\bibliography{ref_embc}
\end{document}
\endinput
%%
%% End of file `sample-sigplan.tex'.

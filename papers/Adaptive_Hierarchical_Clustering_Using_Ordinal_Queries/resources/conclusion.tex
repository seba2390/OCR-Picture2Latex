%% Conclusion and Open Problems

\section{Conclusion and Open Problems}\label{sec:conclusion}
\label{sec:generalized-hierarchical-clustering}

We presented adaptive algorithms for learning a hierarchical clustering
from $O(n \log n)$ ordinal queries when query responses are noisy.
In the absence of noise,
there is an upper bound of $n \log_2 n$ (Section~\ref{sec:insertion-clean}),
and we gave a lower bound of $n \log_3 n - O(n)$.
An immediate question is whether the constant in $n \log_2 n$ is
correct in the noiseless case, or could be improved.

For all our results, we assumed that the tree \Tree capturing
the hierarchical clustering is \emph{binary}.
When nodes can have larger degrees,
our analysis does not continue to hold.
One problem is that for an ordinal query, another response of \Null
may be required: when $\ElS, \ElSP, \ElSPP$ are leaves in three
distinct subtrees of the same internal node \Vertex, 
no pair of them is closer to each other than the third.
This issue also manifests itself in a higher query complexity,
as pointed out by~\cite{benson-kumar-tomkins:2016:nested-IIA}:
when \Tree is a star in which one leaf has been replaced with
an internal node with two new leaves, and the assignment of \elements
to leaves is uniformly random,
it is not difficult to show that
any non-adaptive or adaptive algorithm (even randomized)
requires $\Omega(n^2)$ ordinal queries to learn \Tree.

When the maximum degree \MaxChildren of \Tree is not a constant,
Pearl and Tarsi~\cite{pearl-tarsi:1986:strucuting}
pointed out that their \InsertionSort-based algorithm
can be generalized to obtain an upper bound of
$O(\MaxChildren \cdot n \log n)$ on the number of queries.
However, this generalized algorithm is not optimal:
in the context of discovering phylogeny trees,
Brodal et al.~%
\cite{brodal-fagerberg-pedersen-ostlin:2001:phylogeny-higher-degree}
present an algorithm that uses $O(\frac{d}{\log d} \log n)$ queries.
Their algorithm can be rederived
by adapting an algorithm of \cite{2016:binary-search}
for the \emph{edge query model}
(using techniques similar to the ones
in Section~\ref{sec:insertion-clean})
to insert a new \element \ElS into \Tree using
$O(\frac{d}{\log d} \cdot \log n)$ ordinal queries.
An interesting open question is whether
there is a matching lower bound
of $\Omega(\frac{d}{\log d} \cdot n \log n)$
for every \MaxChildren.
For $\MaxChildren = 2$ (and more generally $\MaxChildren = O(1)$),
our counting argument from Section~\ref{sec:quick-sort}
gives a matching lower bound
up to a constant factor, and for $\MaxChildren = n-1$
(and more generally $\MaxChildren = \Omega(n)$),
the example mentioned in the preceding paragraph does.
We do not have a matching lower bound for intermediate \MaxChildren.
Another natural question is whether the upper bound of
$O(\frac{\MaxChildren}{\log \MaxChildren} \cdot n \log n)$ ordinal queries
can be achieved in the noisy model.

A different interpretation of our result
is that we show how to learn
a (very restricted) ultrametric on the \elements in \AllElements
using ordinal queries.
This raises the natural question of how well more general metrics can
be learned using ordinal queries.
Indeed, as mentioned earlier,
some past work has considered this question,
with some assumption on the geometry of the metric
(e.g.,~\cite{jain-jamieson-nowak:2016:ordinal-embedding}).
Naturally, even for very simple metrics (such as points on a line),
we cannot hope to learn all distances accurately:
for example, if one \element is further from all other \elements
than any other pair is from each other, no algorithm can learn its distance
to other \elements to within any approximation guarantee.
Is there a natural ordinal approximation to
a (not necessarily Euclidean) metric that can be
obtained efficiently?
Could techniques such as
\cite{bartal:1996:probabilistic-approximations,%
bartal:1998:tree-metrics,%
fakcharoenphol-rao-talwar:2004:tree-metrics}
of probabilistic tree embeddings be useful in this context?

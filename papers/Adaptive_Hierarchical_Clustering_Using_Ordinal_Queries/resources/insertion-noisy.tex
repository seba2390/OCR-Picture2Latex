%% Dealing with Noisy Feedback

\section{Dealing with Noisy Feedback}
\label{sec:insertion-noisy}

In this section, we turn our attention to the noisy model:
the response to any ordinal query is correct independently
with probability $p > \Half$, and adversarially incorrect otherwise.
As discussed earlier, a very similar model has been studied in
\cite{brown-truszkowski:2011:phylogeny-quartet}
(see Section~\ref{sec:introduction}).
Our main result is the following theorem:

\begin{theorem} \label{thm:insertion-noisy}
When each query response is correct with constant probability $p > \Half$,
and adversarially incorrect with probability $1 - p$,
there is an algorithm that uses $O (n \log n + n \log (1/\Err))$ ordinal
queries, and learns the correct hierarchical clustering
with probability at least $1 - \Err$.
\end{theorem}

Since ordinal queries are only used in the call to \FindSibling
(in Line~\ref{line:vertex-search}) inside the algorithm
\InsertionClustering, it suffices to show how to find \Vertex[i]
in each iteration with high probability
using $O(\log n + \log(1/\delta))$ ordinal queries.
This is guaranteed by the following lemma, the focus of this section.

\begin{lemma} \label{lem:noisy-sibling}
Assume that each response to an ordinal query is correct
independently with probability $p > \Half$,
and adversarially incorrect with probability $1 - p$.
There exists an adaptive algorithm with the following property:
Given a hierarchical clustering \Tree
with $i$ leaves, an \element \ElS to insert,
and an error guarantee $\Err > 0$,
the algorithm finds the sibling \VertexBar of \ElS
using at most\footnote{The big-$O$ notation hides
constants depending on $p$, but not on any other parameter.}
$O(\log i + \log(1/\Err))$ ordinal queries.
\end{lemma}

\begin{emptyextraproof}{Theorem~\ref{thm:insertion-noisy}}
Using Lemma~\ref{lem:noisy-sibling},
the proof of Theorem~\ref{thm:insertion-noisy} is straightforward:
set $\Err' = \Err/n$ and apply Lemma~\ref{lem:noisy-sibling} to each
invocation of \FindSibling.
Then, by the union bound, all iterations will succeed with 
probability at least $1-\Err$.
The total number of ordinal queries will be at most
\Eat{\[
  \sum_{i=3}^n O(\log (2i-3) + \log(1/\Err'))
  \; \leq \; n \cdot O(\log n + \log (n/\Err))
  \; = \; O(n (\log n + \log(1/\Err))).
\]}
%% only for SODA18:
\begin{align*}
\sum_{i=3}^n O(\log (2i-3) + \log(1/\Err'))
\leq n \cdot O(\log n + \log (n/\Err))
= O(n (\log n + \log(1/\Err))). \QED
\end{align*}
\end{emptyextraproof}

\subsection{Simulating Vertex Queries with Ordinal Queries}

To avoid essentially repeating a large amount of prior analysis,
we begin by making the connection between ordinal queries
and vertex queries more explicit:
we show how to simulate one vertex query using a constant number of
ordinal queries.

To illustrate the reduction most easily, consider the case $p = 1$
in which all queries are answered correctly.
To simulate a vertex query to the root, simply make an ordinal 
query for \ElS with the root as pivot.
This one query suffices, since the response reveals the subtree that 
\ElS belongs to,
or otherwise that the root is the sibling of \ElS (if \ElS does not
belong to either of the subtrees rooted at the root's children).
To simulate a vertex query to a leaf node \Vertex,
instead make an ordinal query with the parent \VertexP of \Vertex as the pivot.
If the response points to \Vertex, then return \Vertex as the sibling;
otherwise, \ElS is not the sibling of \Vertex.

Finally, to simulate a vertex query to an internal vertex \Vertex
that is not the root,
let \VertexP be the parent of \Vertex in \Tree,
and make two ordinal queries for \ElS,
one with pivot \Vertex and the other with pivot \VertexP.
If in response to the ordinal query with pivot \Vertex,
a child of \Vertex is identified as containing \ElS in its subtree,
then this case directly corresponds to the corresponding vertex query
response at \Vertex.
If \Subtree{\Vertex} is known to contain \ElS,
then the response to the query with pivot \VertexP clarifies whether
the target is in fact \Vertex itself, or contained in
$\Subtree{\Vertex} \setminus \Set{\Vertex}$.
Thus, the responses to the two queries together contain (at least)
all the information obtained from the vertex query. 
(Notice that applying this reduction, we could have obtained the
result of Lemma~\ref{lem:clean-insertion} with a loss of a factor of 2
in the number of queries required.)

We now show how to generalize this idea to $p \in (\Half, 1)$.
The cases of the root vertex and a leaf node are handled exactly as in
the case $p = 1$; in particular, using only a single ordinal query.
To simulate a vertex query to an internal vertex \Vertex,
we choose a suitably large constant $k_p$ (determined below)
and make $k_p$ ordinal queries for \ElS with pivot \Vertex.
If a strict majority of these queries
places \ElS in one of the subtrees below \Vertex,
then that subtree is returned.
If a strict majority of the queries with pivot \Vertex places \ElS in
\Subtree{\Vertex}, then \Vertex's parent \VertexP 
is queried $k_p$ times to determine
if the desired target is equal to \Vertex or contained in
$\Subtree{\Vertex} \setminus \Set{\Vertex}$.
The former is returned as the answer if a strict majority of the responses
place \ElS in the subtree of \VertexP also containing \Vertex.
The latter is returned when a strict majority places \ElS in the other
subtree below \VertexP, or a strict majority place it in
\Subtree{\VertexP}.
Finally, in all other cases, the responses are inconclusive,
and the simulation algorithm returns an arbitrary response.
Formally, the algorithm
(which has a number of tedious case distinctions)
is given as Algorithm~\ref{alg:simulate}.
%in the appendix.

\InsertAlgorithmInOneColumn{\SimulateVertexQuery $(\Tree, \Vertex, \ElS)$}{alg:simulate}{
\IF{\Vertex is the root of \Tree}
	\STATE{Make one ordinal query for \ElS with pivot \Vertex,
	and return its result.\\
	(If $\Subtree{\Vertex} = \Set{\Vertex}$,
	the response reveals the root as the proposed answer.)}
\ELSIF{\Vertex is a leaf}
	\STATE{Let \VertexP be the parent of \Vertex in \Tree.}
	\STATE{Make one ordinal query for \ElS with pivot \VertexP.}
	\IF{the response places \ElS at \Vertex}
		\RETURN{the vertex \Vertex as a proposed answer.}
	\ELSE
	\RETURN{the direction towards \VertexP.}
\ENDIF
\ELSE
	\STATE{Let \VertexP be the parent of \Vertex
	and $k_p$ be an odd constant
	such that $1 - e^{-k_p(2p - 1)^2/2} \geq \sqrt{p}$.}
	\STATE{Make $k_p$ ordinal queries for \ElS with pivot \Vertex.}
	\IF{a strict majority of responses place \ElS in \Subtree[L]{\Vertex}}
		\RETURN{the direction towards the left child of \Vertex.}
	\ELSIF{a strict majority of responses place \ElS in \Subtree[R]{\Vertex}}
		\RETURN{the direction towards the right child of \Vertex.}
	\ELSIF{a strict majority of responses place \ElS in \Subtree{\Vertex}}
		\STATE{Make $k_p$ ordinal queries for \ElS with pivot \VertexP.}
		\IF{a strict majority of responses place \ElS in the subtree of
			\VertexP containing \Vertex}
			\RETURN{the vertex \Vertex as a proposed answer.}
		\ELSIF{a strict majority of responses place \ElS in
		the other subtree of \VertexP or \Subtree{\VertexP}}
			\RETURN{the direction towards \VertexP.}
		\ELSE
			\RETURN{an arbitrary response.}
		\ENDIF
	\ELSE
		\RETURN{an arbitrary response.}
\ENDIF
\ENDIF
}

\begin{lemma} \label{lem:simulation}
If each ordinal query is answered correctly independently
with probability $p$, then (for a suitable choice of $k_p$, specified below),
\SimulateVertexQuery $(\Tree, \Vertex, \ElS)$ returns the correct
response (either \Vertex or the direction in which to search)
to the vertex query for \Vertex, with probability at least $p$.
\end{lemma}

\begin{proof}
By the additive Hoeffding Bound \cite{hoeffding:1963:probability},
the probability that a majority out of $k$ query responses is correct
for every $p > \Half$
is at least $q(k) := 1- e^{-k(2p - 1)^2/2}$.
For odd $k$, any majority is strict.
For any $p > \Half$, we have that $e^{-(2p - 1)^2/2} < 1$,
so $q(k) \to 1$ as $k \to \infty$.
In particular, $q(k) \geq \sqrt{p}$ for $k$ sufficiently large.
Fixing such a $k_p$, the probability that a strict majority
of the queries both with pivots \Vertex, \VertexP are correct
is at least $(\sqrt{p})^2 = p$.
Whenever strict majorities of both sets of ordinal queries are correct,
the output of \SimulateVertexQuery is correct, completing the proof. 
\end{proof}

\subsection{Reanalyzing Binary Search with Noisy Vertex Queries}

In light of Lemma~\ref{lem:simulation},
for the purpose of analysis in this section,
we can ignore ordinal queries,
and instead focus on finding \ElS's sibling \VertexBar using vertex queries:
in response to querying \Vertex, the algorithm is told either that
$\Vertex = \VertexBar$ is the correct sibling of \ElS,
or is given a subtree
(rooted at one of the children of \Vertex,
or obtained by removing \Vertex and its subtrees)
that must contain \ElS.
This information is correct with probability (at least) $p$.

\cite{2016:binary-search} gave an algorithm for \binarysearch on
undirected graphs with noisy responses that solves this problem with
probability at least $1 - \Err$, using at most $O(\log n + \log^2 (1/\Err))$
vertex queries \cite[Theorem 8]{2016:binary-search}.
Since we need $\Err = O(1/n)$ to be able to take a Union Bound,
applying this result directly would only give us an overall guarantee of
$O(n \log^2 n)$.
Hence, in this section, we show how to combine algorithms of 
\cite[Algorithm 2]{2016:binary-search} and of
Feige et al.~\cite{feige-raghavan-peleg-upfal:1994:noisy}
(see also related algorithms for noisy \binarysearch on the line
\cite{BenOr-hassidim:2008:noisy-binary-search,%
karp-kleinberg:2007:noisy}) 
to obtain an algorithm finding \VertexBar in $O(\log n + \log (1/\Err))$ queries.
In contrast to \cite{2016:binary-search},
the dependence of this new algorithm's number of queries on $p$ is not
information-theoretically optimal, but it obtains an improved
dependence on \Err in return.

Algorithm~2 of \cite{2016:binary-search} is a
variant of a multiplicative weights algorithm which starts with
a candidate set $S$ of vertices, and within essentially $O(\log |S|)$ rounds
reduces it to only $O(\log |S|)$ ``likely'' remaining candidates. 
The overall algorithm in \cite{2016:binary-search} works by first
reducing the candidate set of \emph{all} nodes to just
$O(\log n)$ nodes, then reducing that further to $O(\log \log n)$
nodes with a second invocation of the multiplicative weights algorithm,
and finally querying each remaining candidate frequently enough to
identify the correct node with sufficiently high probability.
(Dependencies on \Err are omitted in our high-level overview.)
As part of our algorithm here, we just use a single invocation of
the Multiplicative Weights algorithm
(Algorithm 2 of \cite{2016:binary-search}),
with parameters modified to obtain a better dependence on \Err at the
cost of a worse dependence on $p$. 
The performance of of this algorithm (used as a Black Box here)
is summarized by Lemma~\ref{lem:multiplicative-weights},
which is obtained from Lemma~5 of \cite{2016:binary-search} by setting
$\lambda = \frac{1 + p \log p + (1-p) \log(1-p)}{2 \log(p / (1-p))}$.

\begin{lemma} \label{lem:multiplicative-weights}
There exists an algorithm which uses at most $O(\log n + \log(1/\Err))$ 
vertex queries and returns a set $S$ of $O(\log n + \log(1/\Err))$ nodes
such that the unknown target is contained in $S$
with probability at least $1-\Err$.
\end{lemma}

Once the number of candidate targets has been reduced to $O(\log n)$,
due to the $\log(1/\Err)$ dependence,
a further reduction using the techniques of \cite{2016:binary-search}
seems difficult.
However, at this point, we can apply a modification of a beautiful algorithm
of Feige et al.~\cite{feige-raghavan-peleg-upfal:1994:noisy}.
Translated into our nomenclature, Lemma~3.1 of 
\cite{feige-raghavan-peleg-upfal:1994:noisy} about noisy \binarysearch
can be phrased as follows:

\begin{lemma}[Lemma~3.1 of \cite{feige-raghavan-peleg-upfal:1994:noisy}, restated]
\label{lem:feige-restated}
Let \Tree be a binary tree, and assume that one of the leaves
of \Tree is the unknown target.
In response to a vertex query, assume that the algorithm is given the
correct answer with probability $p$,
and an adversarially incorrect one otherwise.
Then, there is an algorithm which finds the correct target
with probability at least $1-\Err$, 
using $O(\Diameter + \log (1/\Err))$ queries
where \Diameter is the diameter of \Tree.
\end{lemma}

Notice two minor inconveniences in applying
Lemma~\ref{lem:feige-restated} for our purposes:
\begin{enumerate}
\item In the specific application of \cite{feige-raghavan-peleg-upfal:1994:noisy},
the binary tree is complete and thus, \Diameter is logarithmic
in size of the tree.
In our application, on the other hand,
after invocation of the Multiplicative Weights algorithm,
the number of candidates (and hence diameter of the tree)
is bounded by $O(\log n)$.
\item \cite{feige-raghavan-peleg-upfal:1994:noisy}
assume that the target is always a leaf node,
whereas in our application, the unknown sibling \VertexBar may be
an internal node. It is very straightforward to modify the algorithm of
Feige et al.~to handle non-leaf targets.
\end{enumerate}

For completeness, we present the modified algorithm and corresponding
analysis in Appendix~\ref{sec:feige}.
Its guarantee is summarized by the following lemma:

\begin{lemma}\label{lem:feige}
Assume that each query response is correct
independently with probability $p > \Half$,
and adversarially incorrect with probability $1 - p$.
There exists an adaptive algorithm with the following property:
Given a tree \Tree of diameter \Diameter,
and error parameter $\Err > 0$,
the algorithm finds the target with probability at least $1-\Err$,
using at most $O(\Diameter + \log(1/\Err))$ vertex queries.
\end{lemma}

Using Lemmas~\ref{lem:multiplicative-weights} and \ref{lem:feige},
it is easy to see how to find a target in $O(\log n + \log(1/\Err))$ queries.
Set $\Err' = \Err/2$ and apply Lemma~\ref{lem:multiplicative-weights}.
Within $O(\log n + \log(1/\Err')) = O(\log n + \log(1/\Err))$ iterations,
we obtain a set $S$ of at most 
$O(\log n + \log(1/\Err))$ nodes that contains the target
with probability at least $1-\Err'$.
Then run the algorithm of Lemma~\ref{lem:feige} with parameter $\Err'$
on the tree \TreeI{S}.
If the target was in $S$, the algorithm will find it with probability
at least $1-\Err'$.
Since the height of \TreeI{S} is at most
$\SetCard{S} = O(\log n + \log(1/\Err))$, the number of queries
required in this phase is at most $O(\log n + \log(1/\Err))$.
Thus, the total number of queries is $O(\log n + \log(1/\Err))$,
and the failure probability is at most $2\Err' = \Err$.


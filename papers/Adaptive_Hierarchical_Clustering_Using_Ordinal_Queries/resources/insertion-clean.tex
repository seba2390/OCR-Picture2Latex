%% An \InsertionSort-like Algorithm without Noise

\section{An \InsertionSort-like Algorithm without Noise}
\label{sec:insertion-clean}

In this section, we present and analyze 
the algorithm of Pearl and Tarsi~\cite{pearl-tarsi:1986:strucuting}.
This algorithm is reminiscent of \InsertionSort.
It is also essentially the same as an algorithm proposed by
Kannan et al.~\cite{kannan-lawler-warnow:1996:phylogeny-triplet},
as well as Tamuz et al.~%
\cite{tamuz-liu-belongie-shamir-kalai:2011:learning-kernel}
(who only considered it when the ground-truth tree is balanced and thus
has logarithmic height).
We give a self-contained analysis
of this algorithm as it is the foundation
of our main result in Section~\ref{sec:insertion-noisy},
and the analysis allows us to introduce key concepts and abstractions.

Algorithm~\ref{alg:insertion-clustering}
considers the \elements in an arbitrary order
$\AllElements = \Set{\ElS[1], \ElS[2], \ldots, \ElS[n]}$.
In each iteration $i$, \element \ElS[i] is inserted into the hierarchy
\Tree[i-1] for the preceding $i-1$ \elements.
Proposition~\ref{prop:sibling}
(whose proof follows directly from Proposition~\ref{prop:induced}) 
shows that \ElS[i] will always be inserted as a leaf sibling of
an existing (leaf or internal) node \Vertex[i], 
by inserting a new common parent of \ElS[i] and \Vertex[i].

\begin{proposition} \label{prop:sibling}
Let $\Cluster \in \SetFam[\ElS[1], \ldots, \ElS[i-1]]$ be minimal
with the property that 
$\Cluster \cup \Set{\ElS[i]} \in \SetFam[\ElS[1], \ldots, \ElS[i]]$.
(Informally speaking,
$\Cluster \subseteq \Set{\ElS[1], \ldots, \ElS[i - 1]}$ is the cluster
corresponding to the sibling of \ElS[i] in \TreeI[*]{\ElS[1], \ldots, \ElS[i]}.)
In \TreeI[*]{\ElS[1], \ldots, \ElS[i-1]},
let \Vertex[i] be the root of the subtree corresponding to the cluster
\Cluster.
Then, \TreeI[*]{\ElS[1], \ldots, \ElS[i]} is obtained from
\TreeI[*]{\ElS[1], \ldots, \ElS[i-1]} by inserting a new
internal node \VertexP as the parent of \Vertex[i],
and making the leaf \ElS[i] its other child.
\end{proposition}

 
\InsertAlgorithmInOneColumn{\InsertionClustering $(\ElS[1], \ldots, \ElS[n])$}%
{alg:insertion-clustering}{
\STATE{Let $\Tree[2]$ be the unique (trivial) hierarchical clustering
of \elements $\ElS[1], \ElS[2]$.}
\FOR{$i = 3, \ldots, n$}
	\STATE{Let $\Vertex[i] = \text{\FindSibling}(\Tree[i-1], \ElS[i])$.
	\label{line:vertex-search}}
	\STATE{Let \VertexP[i] be the parent of \Vertex[i]
	(or $\emptyset$ if \Vertex[i] is the root)}
	\STATE{Let \Tree[i] be the tree obtained from \Tree[i - 1]
	by adding a new vertex \VertexP with children \Vertex[i] and
	\ElS[i] and parent \VertexP[i].}
\ENDFOR
\RETURN{\Tree[n]}
}

When \TreeOpt has logarithmic height,
\FindSibling can be simply implemented as a top-down
search similar to the \Merge algorithm in Section~\ref{sec:quick-sort}.
This approach can take linear time if the tree is not balanced,
and our main focus in this section is on improving the time
to $\log n$ for arbitrary trees.

Assuming that the function \FindSibling (to be specified below)
correctly identifies \Vertex[i],
the algorithm maintains the following invariants:
\begin{enumerate}
\item Each internal node of \Tree[i] has two children;
this holds because every time an internal node is added, it is explicitly given
two children.
\item \Tree[i] is always the correct hierarchy for
$\{\ElS[1], \ElS[2], \ldots, \ElS[i]\}$,
in the sense that $\Tree[i] \equiv \TreeI[*]{\ElS[1], \ldots, \ElS[i]}$; 
this follows inductively from Proposition~\ref{prop:sibling}.
\end{enumerate}

Thus, it remains to specify an efficient implementation
of the function \FindSibling and analyze
the overall number of ordinal queries.

\FindSibling is very similar to ``\binarysearch in Trees'' 
\cite{mozes-onak-weimann:2008:tree-edge-linear,%
onak-parys:2006:tree-vertex-linear,%
2016:binary-search}
in the \emph{vertex query} model.
Recall that in the vertex query model,
an unknown node \Target is to be located in a given and known tree \Tree.
When an algorithm queries node \Vertex which is not the target,
it learns the first edge of the unique \Vertex-\Target path
(equivalently, the connected component of $\Tree \setminus \Set{\Vertex}$
in which the target lies).
The ``\binarysearch'' algorithm is based on the following observation
of Jordan~\cite{jordan:1869:assemblages}:
each tree \Tree has a separator node \Vertex with the property
that each connected component of
$\Tree \setminus \Set{\Vertex}$ contains
at most half the nodes of \Tree.
Repeatedly querying such a separator node of the remaining subtree is
easily shown to find the target \Target in a tree of $n$ nodes using at most 
$\log_2 n$ vertex queries
\cite{onak-parys:2006:tree-vertex-linear}.

\FindSibling treats the (unknown) sibling \Vertex[i]
as the target to discover,
and uses ordinal queries with internal vertices as pivots
(see Section~\ref{sec:ordinal-def}) to essentially simulate vertex queries.
It maintains a set $S$ of candidate
vertices \Vertex that have not been ruled out from being \Vertex[i].

\InsertAlgorithmInOneColumn{\FindSibling $(\Tree, \ElS)$}{alg:findsibling}{
\STATE{Let $S = V(\Tree)$ be the set of all vertices of \Tree.}
\WHILE{$\SetCard{S} > 1$}
	\STATE{Let \Vertex be a \emph{pivot vertex} minimizing
	$\max(\SetCard{\Subtree[L]{\Vertex} \cap S},
	\SetCard{\Subtree[R]{\Vertex} \cap S},
	\SetCard{\Subtree{\Vertex} \cap S})$.}
	\STATE{Make an ordinal query for \ElS with pivot \Vertex.}
	\IF{the query returns the left subtree of \Vertex}
		\STATE{Let $S = S \cap \Subtree[L]{\Vertex}$.}
	\ELSIF{the query returns the right subtree of \Vertex}
		\STATE{Let $S = S \cap \Subtree[R]{\Vertex}$.}
	\ELSE 
		\STATE{Let $S = S \cap \Subtree{\Vertex}$.}
	\ENDIF
\ENDWHILE
\RETURN{the unique vertex \Vertex in $S$.}
}

\begin{lemma} \label{lem:clean-insertion}
When all answers to ordinal queries are correct,
$\text{\FindSibling}(\Tree, \ElS)$ finds \Vertex[i] in \Tree
using at most $\log \SetCard{\Tree}$ ordinal queries.
\end{lemma}

\begin{proof}
Inductively, the induced subgraph \TreeI{S} always forms a binary tree
in which each internal node has two children.
In verifying the correctness of the algorithm,
notice first that the pivot vertex \Vertex is indeed never a leaf.
That is because for any leaf \Vertex, we would have
$\Subtree{\Vertex} \cap S = S$,
whereas for \Vertex's parent \VertexP, we would have that
$\max(\SetCard{\Subtree[L]{\VertexP} \cap S},
	\SetCard{\Subtree[R]{\VertexP} \cap S},
	\SetCard{\Subtree{\VertexP} \cap S}) 
	< \SetCard{S} = \SetCard{\Subtree{\Vertex} \cap S}$.
The fact that the update of $S$ is correct follows from
Proposition~\ref{prop:pivot-query}.

% Now consider an ordinal query $\Set{\ElS, \ElSL, \ElSR}$
% with pivot vertex \Vertex, and the three possible responses:

% \begin{itemize}
% \item If \ElS and \ElSL are closer to each other than to \ElSR,
% then \ElS[i] must belong to the left subtree of \Vertex.
% Thus, eliminating all other vertices of \Tree is correct.
% \item Similarly, if \ElS and \ElSR are closer to each other than to \ElSL,
% then \ElS[i] must belong to the right subtree of \Vertex.
% Thus, eliminating all other vertices of \Tree is correct.
% \item If \ElSL and \ElSR are closer to each other than either is to \ElS,
% then \ElS does not belong to either subtree rooted below \Vertex.
% Thus, all descendants of \Vertex (but not \Vertex itself) are
% eliminated as candidates for \Vertex[i].
% Thus, eliminating all vertices of \Tree in subtrees below \Vertex is correct.
% \end{itemize}

Next, we analyze the number of ordinal queries made.
By the result of Jordan \cite{jordan:1869:assemblages},
\TreeI{S} has a separator node \Vertex with the property that each of 
$\Subtree[L]{\Vertex} \cap S, \Subtree[R]{\Vertex} \cap S,
(\Subtree{\Vertex} \cap S) \setminus \Set{\Vertex}$
contains at most $\SetCard{S}/2$ nodes.
Because in the third case (\ElSL and \ElSR are closest),
the node \Vertex remains in $S$,
the size of $S$ might change to $1 + \SetCard{S}/2$ instead of $\SetCard{S}/2$.
However, notice that this can only happen when $\SetCard{S}$ is odd.
For when $\SetCard{S}$ is even, if \Subtree{\Vertex} contained
$1 + \SetCard{S}/2$ nodes from $S$,
then choosing the parent \VertexP of \Vertex instead
would strictly decrease the size of \Subtree{\VertexP},
while the size of each of the subtrees of \VertexP is bounded by $\SetCard{S}/2$.
Thus, we obtain that the new size of $S$ is at most $\Ceil{\SetCard{S}/2}$.

When $\SetCard{S} = 3$, a single query suffices to identify \Vertex[i];
the case $\SetCard{S} = 4$ cannot arise, as there is no binary tree with 4
nodes in which all internal nodes have degree 2.
Thus, the number \QC{k} of required ordinal queries satisfies the
recurrence $\QC{k} \leq 1$ for $k \leq 4$ and
$\QC{k} \leq 1 + \QC{\Ceil{k/2}}$ for $k \geq 5$.
An easy induction proof shows that $\QC{k} \leq \log k$,
so the number of ordinal queries required to find \Vertex[i] in \Tree
is at most $\log \SetCard{\Tree}$.
\end{proof}

\begin{theorem} \label{thm:clean-insertion}
When the answers to all ordinal queries are correct,
Algorithm~\ref{alg:insertion-clustering}
learns the correct hierarchical clustering of $n$ \elements
using at most $n \log_2 n$ ordinal queries.
\end{theorem}

\begin{proof}
The correctness of the algorithm follows by repeatedly applying
Proposition~\ref{prop:sibling},
and using that by Lemma~\ref{lem:clean-insertion},
each iteration uses the correct \Vertex[i].

By Lemma~\ref{lem:clean-insertion}, because \Tree[i] has $2i - 1$ nodes
($i$ \element leaves and $i - 1$ internal nodes),
inserting \element \ElS[i] into \Tree[i-1] for
$i = 3, \ldots, n$ requires at most $\log_2(2i-3)$ ordinal queries.
Thus, the total number of ordinal queries is at most  
\Eat{\begin{align*}
\sum_{i = 3}^{n} \log_2 (2i - 3)
& < \; \sum_{i = 2}^{n - 1} (1 + \log_2 i)
\; < \; n + \log_2((n - 1)!)
\; \stackrel{(*)}{\leq} \;
   n + \left(n \log_2 n - n \log_2 e + O(\log n) \right)\\
& < n \log_2 n.
\end{align*}}
%% only for SODA18:
\begin{align*}
\sum_{i = 3}^{n} \log_2 (2i - 3)
< \; \sum_{i = 2}^{n - 1} (1 + \log_2 i)
< n + \log_2((n - 1)!) \\
\stackrel{(*)}{\leq}
n + \left(n \log_2 n - n \log_2 e + O(\log n) \right)
< n \log_2 n.
\end{align*}
The step labeled (*) used Stirling's inequality.
\end{proof}


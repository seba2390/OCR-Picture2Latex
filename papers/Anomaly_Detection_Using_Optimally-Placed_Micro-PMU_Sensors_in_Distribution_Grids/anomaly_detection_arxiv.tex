\documentclass[twocolumn]{IEEEtran}
\usepackage{graphicx,subfigure}
\usepackage{enumerate}
\usepackage{color}
\usepackage{pifont}
\usepackage{float}
\usepackage{epsfig}
\usepackage[makeroom]{cancel}
\usepackage{multirow}
\usepackage{pbox}
%\usepackage{dblfloatfix} 
%\usepackage{multicol}
\usepackage{lipsum}
\usepackage{cleveref}
\usepackage{cite,amssymb,amsthm}
\usepackage{tablefootnote}
\usepackage{amsmath}
\usepackage{arydshln}
\usepackage[ruled, vlined]{algorithm2e}
\renewcommand\IEEEkeywordsname{Index Terms}
\newcommand{\mup}{\mu \text{PMU}}
\newcommand{\bs}{\boldsymbol} 
\newcommand{\mr}{\mathrm}
\newcommand{\mb}{\mathbf}
\usepackage{color}
%\usepackage{ulem}
% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}
\newtheorem{lem}{Lemma}
\newtheorem{prop}{Proposition}
\begin{document}


\title{Anomaly Detection Using Optimally-Placed $\mup$ Sensors in Distribution Grids}

%\author{\IEEEauthorblockN{Mahdi Jamei\IEEEauthorrefmark{1},
%Anna Scaglione\IEEEauthorrefmark{1},
%Ciaran Roberts\IEEEauthorrefmark{2},
%Emma Stewart\IEEEauthorrefmark{2},}
%Sean Peisert\IEEEauthorrefmark{2},
%Chuck McParland\IEEEauthorrefmark{2},
%Alex McEachern\IEEEauthorrefmark{3}
%\vspace{0.1cm}
%\IEEEauthorblockA{\IEEEauthorrefmark{1}School of Electrical, Computer, and Energy Engineering, Arizona State University, Tempe, AZ, USA}
%\IEEEauthorblockA{\IEEEauthorrefmark{2}Lawrence Berkeley National Laboratory, Berkeley, CA, USA}
%\IEEEauthorblockA{\IEEEauthorrefmark{3}Power Standards Lab, Alameda, CA, USA}
%\thanks{ddvbcfhcf hc fhv dssd}
%}
\author{Mahdi Jamei, Anna Scaglione, Ciaran Roberts, Emma Stewart, \\ Sean Peisert, Chuck McParland, Alex McEachern   
    \thanks{This research was supported in part by the Director, Office of Electricity Delivery and Energy Reliability, Cybersecurity for Energy Delivery Systems program, of the U.S. Department of Energy, under contracts DE-AC02-05CH11231 and DEOE0000780. Any opinions, and findings expressed in this material are those of the authors and do not necessarily reflect those of the sponsors.). 
Preliminary version of this work has been accepted to be published in the proceedings of HICSS 2017, Hawaii, USA \cite{jamei2016automated}.}
        \thanks{M. Jamei and A. Scaglione are with the School of Electrical, Computer and Energy Engineering, Arizona State University, Tempe, AZ, USA. Emails: \texttt{\{mjamei, ascaglio\}@asu.edu}. C. Roberts, E. Stewart, S. Peisert, and C. McParland are with the Lawrence Berkeley National Laboratory, Berkeley, CA, USA. Emails: \texttt{\{cmroberts, estewart, sppeisert, cpmcparland\}@lbl.gov}. A. McEachern is the CEO of the Power Standards Lab, Alameda, CA, USA. Email: \texttt{Alex@McEachern.com}.}
         }
\maketitle


\begin{abstract}
As the distribution grid moves toward a tightly-monitored network, it is important to automate the analysis of the enormous amount of data produced by the sensors to increase the operators situational awareness about the system. 
In this paper, focusing on Micro-Phasor Measurement Unit ($\mup$) data, we propose a hierarchical architecture for monitoring the grid and establish a set of analytics and sensor fusion primitives for the detection of abnormal behavior in the control perimeter.    
Due to the key role of the $\mup$ devices in our architecture, a source-constrained optimal $\mup$ placement is also described that finds the best location of the devices with respect to our rules. The effectiveness of the proposed methods are tested through the synthetic and real $\mup$ data.
%Electric power distribution systems are undergoing many technological changes, and concerns are surfacing about vulnerabilities. Resilient Cyber-Physical Grid Systems (CPGSs) in general must leverage state measures and operational models that interlink the physical and the computational assets that compose them, to assess the global state.
%
%In this paper, we first describe a Grid Security System (GSS) architecture that enables the operators to bring the cyber and physical security rules together. Focusing on the data from Micro Phasor Measurement Units ($\mup$s), we establish event detection rules in a hierarchical and automated manner to identify any anomaly in the grid as the first required step of detecting and identifying the source of an attack. Due to the key role of the $\mup$ devices in our architecture, a source-constrained optimal $\mup$ placement is described that finds the best location of the devices with respect to our rules when the grid is not fully observable. The effectiveness of the methods that we describe are tested through the real and simulated $\mup$ data.           
\end{abstract}
\begin{IEEEkeywords}
 \normalfont\bfseries Distribution Grid, Micro-Phasor Measurement Unit ($\mup$), Anomaly Detection, Optimal Placement.
\end{IEEEkeywords}
\IEEEpeerreviewmaketitle
%%%%%%%%%%%%%%%%%%%%%---------------------------Introduction----------------------%%%%%%%%%%                                                   
\section{Introduction}
%The shift in the distribution grid operation paradigm from being a passive network to an automated and active system requires to fulfill the historical 
Historically, Distribution System Operators (DSOs) have lacked information about the real-time operation of the grid. However, this situation is changing. Similar to the Phasor Measurement Units (PMUs) at the transmission level, Micro-Phasor Measurement Units ($\mup$s) are designed to measure real-time voltage and current phasors in a synchronized manner at specific locations on the distribution system. These measurements can be utilized by the DSO, but useful translation from raw data to information is first required \cite{von2014micro, scoping_study}. This information can provide a level of insight that is not attainable by Distribution Supervisory Control and Data Acquisition (DSCADA) data. Visualizing and interpreting raw sensor streams can be overwhelming for DSOs, considering the large quantity of data that could flow in from different parts of the grid \cite{kezunovic2013role}. Therefore, it is essential to mine the data collected with analytic tools that can derive informative measurements and form automated reports.
\subsection{Literature Review} 
Recent work has focused on the PMU data utilization at the transmission level to improve the Wide-Area Monitoring, Protection, and Control \cite{phadke2008wide,terzija2011wide}. Distribution grids, however, are still lagging in that respect, since tools for the transmission grid may not be directly applicable to the distribution grid due to a different operation environment, such as load imbalances, untransposed lines, and the existence of single-phase and two-phase laterals. Transmission operations and system wide analysis are concerned with large imbalances in load and
generation, and as a result frequency, whereas distribution operations are concerned with localized, but
frequent events such as voltage imbalance, overloading, and outage management. The goal of this paper is to fill the distribution systems analysis gap by defining {\it physics-aware} algorithms that process $\mup$ data for the automatic detection of any grid behavior that does not comply with the (quasi) steady-state regime of operation, as well as the physical limits of the grid.       
%\subsection{Related Work}
Most of the prior research on sensor data analytics (including SCADA and PMU measurements) is concerned with detecting events on the grid transmission level. For example, Pan et al., \cite{pan2015developing} use data mining techniques on PMU measurements and audit logs for event classification. A linear basis expansion for the PMU data is described by Chen et al., \cite{chen2013dimensionality,xie2014dimensionality} for event detection application. A similar approach, based on Principal Component Analysis (PCA), is used in \cite{valenzuela2013real, ge2015power} for event detection and data archival.
Allen et al., \cite{allen2014pmu} describe the use of voltage phasor angle differences between different PMU readings to detect events. Biswal et al., \cite{biswalsupervisory} use the strongest signatures of event in PMU data for situational awareness enhancement. In our previous work \cite{jamei2016micro} we describe an architecture for a cyber-physical distribution grid, and show how event detection using $\mup$ measurements can help in reasoning about the security status of the grid.
%Many of the proposed approaches mentioned above are data driven that has its own advantages. 
A study by Brahma et al., \cite{brahmareal} describes the real-time dynamic event identification in power system using PMU data based on a data-driven and also physics-based method.
\subsection{Our Contribution}
Our approach for event detection is a combination of the data-driven methods, as well as criteria  resulting from analyzing the underlying physical model of the system.
We first define a hierarchical \textit{``anomaly detection architecture''} to host a set of anomaly detection rules that are proposed for the analysis and fusion of $\mup$ sensor measurements. Unlike model agnostic machine learning methods that look for statistical anomalies in a feature space that is often heuristic,
the \textit{anomalies} that algorithms in this paper identify are defined in the context of power quality and protection, in addition to what is imposed by the grid governing physical equations (i.e. Kirchhoff Voltage and Current Laws). This, in turn, gives a DSO much greater insight and help in the forensic analysis. Because of the important role played by $\mup$ data in the framework, a source-constrained $\mup$ placement optimization is described, to achieve the maximum sensitivity in detecting a change\footnote{Note that PMU placement methods studies for state estimation
are not applicable here since the state is not directly observable by solely depending on the $\mup$s due to the scarcity of sensors.}. 

\subsection{Notation}
The following notations are used throughout the paper:
\begin{tabular}{ll}
$j$&Imaginary unit.\\
$\mathcal{I}_N$& $N \times N$ identity matrix.\\
$\mb{A}^T, \mb{A}^*,$&Transpose, conjugate,\\
$\mb{A}^H$&and conjugate transpose of matrix $\mb{A}$.\\
$||\mb{A}||,||\mb{A}||_F$&2-norm and F-norm of matrix $\mb{A}$.\\ 
$\mb{1}_{m \times n}$&$m \times n$ size matrix with entries 1.\\
$\mb{A}^\dagger$&Pseudo-inverse of matrix $\mb{A}$.\\
$\otimes$&Kronecker product.  
\end{tabular} 

%According to U.S. Department of Homeland Security (DHS) reports, the sophistication and frequency of the attacks on the power grid are increasing \cite{tech_assess}. For example, a recent cyber attack was reported on the Ukrainian distribution grid \cite{cbc}. The report documented a failure in network security which led to significant power outages. The Stuxnet malware and the sewage spill incident at the Maroochy Water Station, due to wireless attacks, are other examples showcasing how a misinformed control system can lead to catastrophic consequences.
%
%Cyber security for energy delivery systems has, until now, focused primarily on the transmission grid and on securely transferring bits of information about the condition of power-grid elements, e.g., ``Is this switch open or closed?'', ``Which tap is selected on this transformer?'', and preventing unauthorized access to sensor and control packets. Once that access has been gained, there is little remediation action for the power grid, other than a communications blackout and manual fieldwork. Utility stakeholders and governments are seeking new approaches to this problem, and are particularly concerned with understanding security at the distribution level, in anticipation to a growth in automation.
%
%While transmission grids states have been tightly monitored, and their behavior at the physical level is reasonably well understood, the operators have been largely blind towards the real-time condition of the distribution grid. Hence, in tandem with the effort of gaining situational awareness on the security of the system,  there is a growing need and interest in the deployment of sensors, such as micro phasor measurement units ($\mup$s),  that can capture the state of the distribution grid\cite{scoping_study}. These devices, recently developed by Power Standards Laboratories (PSL) \cite{upmu_site}, address both the technical and economic barriers limiting the deployment of conventional PMUs, widely used on the transmission grid, for the distribution level\cite{von2014micro}. Note that the $\mup$s implement a proprietary filtering operation which is different from the options for the filter $h(t)$ given in the C.37.118 standard \cite{c37}. The proprietary filter helps to deal with working condition that are faced specifically in the distribution grid (inter-harmonics, tinier phase angle difference with much faster changes compared to transmission, etc.). In comparison to distribution supervisory control and data acquisition (DSCADA), $\mup$s provide significantly more information, including nuances that are often not present in DSCADA data, as illustrated in the example in Fig.~\ref{fig:pmu_scada}. In this example, the magnitude of the current measured by the DSCADA meter is missing an overcurrent event that a $\mup$ captured. In addition, the time delay or error between the SCADA measurement and the GPS time-synchronized $\mup$ is significant at around 6 seconds. A timeline in which critical events can be detected may prove critical in order to identify cyber-attacks that could otherwise easily be missed. 
%\begin{figure}
%\centering
%\includegraphics[width=0.5\textwidth]{figures/scada_pmu.png}
%\caption{Measurement Comparison of $\mup$ and DSCADA}
%\label{fig:pmu_scada}
%\end{figure}
%
%The first steps in adding security in operational environments are typically to deploy firewalls and device-level authentication. Encryption is often also added to enhance confidentiality and integrity of the message content.  Another common security mechanism on computer networks is intrusion detection, in which network traffic is monitored and analyzed to detect activities that either fit into a ``known bad'' category or deviate in a statistically significant way from ``normal.'' The Tofino Security Appliance, the Digital Bond Quickdraw SCADA intrusion detection system, the Radiflow Secure Gateway, and the Bro Security Framework \cite{paxson1999bro} are all examples of network intrusion detection systems (IDSs) that can be applied to control systems~\cite{berthier2010intrusion}.
%
%Numerous examples have shown that all of these methods leave significant gaps in security and safety \cite{slay2008lessons}. It has been recognized that one of the reasons for this is that most of these security methods are divorced from the knowledge of the physics of the system, its safe operations and limits, and its current physical operating point. This gap was recognized early on \cite{cardenas2011attacks}. Some of our own previous work for monitoring SCADA traffic expanded the notion of intrusion detection by leveraging the laws of physics governing the grid and imposing them as security constraints \cite{mcparland2014monitoring,koutsandria2015real}. 
%Nonetheless, these methods also remain blind to more sophisticated attacks. One reason is that the data coming from SCADA systems are not updated fast enough, so events causing many changes in a short period of time can be missed. In addition, attackers can inject false data at the device level, thus evading detection by the IDS.
%
%The $\mup$s that we use are placed in separate protection domains---including a separate communications network---from DSCADA systems.  Thus, a compromise of the DSCADA network will not by itself result in a compromise of the $\mup$s.  In addition, each $\mup$ may in fact be in a separate protection domain, due to the way in which the $\mup$s are frequently added to the network via wireless modems. Besides, the $\mup$s are not only designed to be read-only devices, but are both placed behind networked bastion hosts and also communicate over encrypted protocols.  Finally, even if a data injection attack can be launched against some $\mup$s, depending on level that is compromised (from field devices up to the control center), some $\mup$s and some of our rules may still be effective, due to the hierarchical way that they are defined.  Thus, in our threat model, we assume that our detection rules are less-vulnerable to data injection attacks than attacks against typical DSCADA networks.
%
%
%\subsection{Motivation and Contribution}
%The goal of this paper is to first describe a Grid Security System (GSS) leveraging $\mup$s to directly measure at many points, in real time, the actual physical state of the distribution network. Our architecture provides the framework to analyze data in both cyber and physical domains to give an independent, integrated picture of the distribution grid's state.
%
%Focusing on the $\mup$ data, we describe a set of rules that, in a  hierarchical and automated fashion, process $\mup$ measurements in order to spot any anomaly happening in the grid. The rules are motivated by what is referred as \textit{``abnormality''} in the context of power quality and protection, in addition to what is imposed by the grid governing physical equations (i.e. Kirchhoff Voltage and Current Laws). The security policies applied to $\mup$ data are a crucial component of the forensic analysis our GSS architecture. Because of the important role of the $\mup$ data in our framework, we describe a source-constrained $\mup$ placement optimization, to achieve the maximum sensitivity when the grid is not fully observable.
%
%The advantages of our new approach are: (1) it is robust due to its hierarchical nature; (2) it can be inexpensively deployed at existing utilities; (3) it analyzes the data close to real-time; %while the common logged data auditing; 
%(4) it employs three phase distribution grid equations rather than the more commonly-used positive sequence solution, thus avoiding the approximation errors that are common in other approaches that ignore the fact that the distribution grid is neither a balanced nor a transposed system.  
%
%\subsection{Related Work}
%There is a significant prior research on the applications of sensor data, including SCADA and PMUs measurements, to detect events and attacks on the grid, primarily focused at the transmission level. Generally, the approaches used in this context can be classified into two categories. The first class only deals with sensor traces, irrespective of the underlying model of the grid and the data source, to train a detection algorithm and, accordingly, track anomalies. For example, Pan et al., \cite{pan2015developing} use the so called {\it common path} data mining approach on PMUs measurements and audit logs at a central control server to classify between disturbances, cyber-attacks and normal operations. A linear basis expansion for the PMU data is described by Chen et al., \cite{chen2013dimensionality} to reduce the dimensionality of the observations. Using this basis, the study shows how an event that causes a change in the operating point of the grid can be detected through comparing the error of the projected data onto the subspace spanned by the basis and the actual values. Valenzuela et al.,  \cite{valenzuela2013real} use Principal Component Analysis (PCA) to classify the power flow results into regular and irregular subspace. Through the analysis of the irregular subspace data, the algorithm determines if the irregularity is due to a cyber attack or not. 
%
%The second class uses the underlying model of the data, along with the data themselves, to spot possible attacks and anomalies. 
%
%However, these methods may fail under the data injection attack. Kosut et al., \cite{kosut2011malicious} adopt a graph-theoretic model and studies the malicious data injection attack under strong and weak attack regimes. In the strong attack regime, the authors derive the smallest number of meters that can make the grid unobservable if their data is missing at the control center due to the attack. Furthermore, in the weak attack regime, a decision-theoretic method is used from the perspective of both the control center and the attacker.    
%
%Our framework leans towards the second category through the integration of $\mup$ information and grid models as part of the security architecture, in order to provide a clear image of the physical trail left by cyber-physical-attacks. The ideas we explore are also based the algebraic property of the measurements in a quasi-steady state condition. They also help interpret why some of the aforementioned techniques are successful in detecting anomalies. 
%      
%As mentioned earlier, the $\mup$s that we use are placed in separate protection domains---including a separate communications network---from DSCADA systems, and in our threat model, we assume that our detection rules are less-vulnerable to data injection attacks.  
    
\section{Anomaly Detection Architecture}
%Our ADA is a hierarchical model, in which the $\mup$ data are analyzed at two (or more) stages. 
As shown in Fig.~\ref{fig.anomaly_arch} the first stage of the  \textit{``anomaly detection architecture''} hierarchy is next to each $\mup$ sensor in the field and the second stage is at a central node that can be hosted in the Distribution System Operator (DSO) control room. The algorithms for anomaly detection applied next to each $\mup$ sensor are referred to as  
\textit{``local rules''} and those that aggregate readings of multiple $\mup$s as \textit{``central rules''}.         
\begin{figure}[ht]
\centering
\includegraphics[trim = 0mm 0mm 0mm 0mm,width=0.8\linewidth]{figures/anomaly_detection_architecture.pdf}
\caption{Anomaly Detection Architecture Using $\mup$ Measurements.}
\label{fig.anomaly_arch}
\end{figure}
For large grid sizes, the aggregation can occur in multiple steps, where mid-level stages analyze part of the data and forward them upward.

This design has the following benefits: (1) it is robust due to its distributed, redundant nature; (2) it can be inexpensively deployed at existing utilities; (3) it analyzes the data close to real-time; as opposed to the common practicing of post hoc auditing of logged data; (4) the employed $\mup$s are placed in separate protection domains---including a separate communications network---from the DSCADA systems, so that attacks against the DSCADA network will not compromise the operation of the architecture. In addition, $\mup$s can be seamlessly added to the network via wireless modems. Further addressing security, the $\mup$s are not only designed to be read-only  via the network, but are both placed behind networked ``bastion hosts'' and can communicate bi-directionally via encrypted protocols, thereby fortifying the devices against tampering without physical access; (5) finally, even if a data injection attack can be launched against some $\mup$s, depending on level that is compromised (from field devices up to the control center), some $\mup$s and some of our rules may still be effective, due to the fact that every device in a certain level processes information independently. Thus, in our threat model, it is assumed that our detection rules are less-vulnerable to data injection attacks than attacks against typical DSCADA networks. 

The suite of algorithms that are proposed for the \textit{anomaly detection architecture} layers have the following advantages in comparison to the present state of the art: (1) due to the near-real-time analysis, analytic results can be used to prioritize the traffic flow from the lower to higher layer, pushing forward reports of anomalies faster than data that do not raise a flag and need to simply be accrued for historical purposes;
(2) it employs three-phase distribution grid equations rather than the more commonly-used positive sequence solution, thus avoiding the errors arising due to poor modeling; (3) a quasi steady-state condition is considered as the {\it normal regime} of operation rather than the idealistic steady-state which assumes there is no frequency drift. 
These modeling aspects are clarified in our discussion next.
%Assuming normal conditions, the $\mup$s are designed to specifically capture samples of the three phase voltage phasor, which we denote as $\mb{v}[k]\in \mathbb{C}^{3\times 1}$, and of the current phasor $\mb{i}[k]\in \mathbb{C}^{3\times 1}$ in specific sites of a distribution grid. Each $\mup$ forwards the time-tagged voltage and current phasor to its corresponding local anomaly detection engine that is installed next to it. 
%The local rules are then checked to detect any deviation from the normal behavior in the data irrespective to what other $\mup$s. The data and analysis results from local engines are then forwarded to the central node where a set of other analysis occur to inspect for anomalies in the data, and to send all the results to the control center.   

      

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The $\mup$ Data in a Distribution Grid}\label{sec.model}       
Fig.~\ref{fig:dis_line} shows the $\pi$ model of a distribution line that connects bus $m$ to $n$.   
 \begin{figure}[ht]
 \centering
	\includegraphics[width=0.5\textwidth]{figures/dis_line_model_rev.pdf}
	\caption{\small $\pi$ Model of a Distribution Line}
	\vspace{-0.2cm}
	\label{fig:dis_line}
\end{figure} 
Assuming normal conditions, the $\mup$s are designed to capture samples of the three phase voltage phasor, which is denoted by $\mb{v}[k]\in \mathbb{C}^{3\times 1}$, and of the current phasor $\mb{i}[k]\in \mathbb{C}^{3\times 1}$ in specific sites of a distribution grid. Next we apply Kirchhoff's and Ohm's law for a three-phase line in a quasi steady-state condition. 

A well-known fact from signals and systems theory is that the relationship between voltage and current through a passive circuit with a certain admittance matrix can be represented as a multiplication in the frequency domain and as a convolution in the time domain. Because the circuit is three phase, these will be represented by a Multi-Input Multi-Output system. This fact also holds for the phasor of the signals. We first define $\bs{y}_{mn}(t)$ and $\bs{y}^{sh}_{mn}(t)$ to denote the time domain equivalents of the matrices $\bs{Y}_{mn}(f+f_0)$ and $\bs{Y}^{sh}_{mn}(f+f_0)$, respectively.  
In discrete time, the convolution relationship is as follows:
\begin{align}
 \mathbf{i}_{mn}[k]=\sum_{r=0}^{N-1} \overline{\bs y}_{mn}[r] \mathbf{v}_m[k-r]-\bs{y}_{mn}[r]\mathbf{v}_n[k-r]
\label{eq:basiceq}
\end{align}
where $\overline{\bs y}_{mn}[r]=\bs{y}_{mn}[r]+\bs{y}^{sh}_{mn}[r]$ and it is assumed that $\bs{y}^{sh}_{ij}[n]$ and $\bs{y}_{mn}[r]$ are the samples respectively of  $\bs{y}^{sh}_{mn}(t)\star h(t)$ and $\bs{y}_{mn}(t)\star h(t)$, have finite support $N$ and are causal\footnote{$h(t)$ denotes the low-pass filter implemented in the $\mup$ to extract the baseband signal and $H(f)$ is its corresponding frequency response.
It should be noted that the outputs of  $\mup$, and their corresponding functions, are not the exact phasors if the bandwidth of the signal (voltage/current) is greater than $2f_0$, and are aliased. However, what we are interested in is to track any data abnormality (instead of the exact grid state during the event). Therefore,  as long as it is not suppressing the anomaly, having aliasing is not an issue for our rules.    
}. 
%This well-know fact that the relationship between voltage and current is not in general in form of memory-less algebraic equations is often forgotten in power systems analysis which is primarily using steady state equations.

Next, the form of this relationship during the quasi steady-state is shown, since the steady-state in reality never happens, which in turn represents the governing equations during a regime of operation that is referred to as \textit{``normal''}. 

The fundamental frequency of the voltage and current signals are always varying, even in a normal state (although slowly and over a very small range), because of load-generation imbalances, active power demand interactions, large generators inertia, and the automatic speed controllers of the generators \cite{phadke2008synchronized}. The effect observable is a change of grid operation regime from steady-state to quasi steady-state. 
The off-nominal frequency therefore affects the phase angle captured by phasor measurement devices. To highlight that mathematically, the phasor readings are decomposed ${\mathbf{v}}_m[k]$ and $\mathbf{i}_{mn}[k]$ as follows:
\begin{align}
\mathbf{v}_m[k]=\hat{\mathbf{v}}_m[k] e^{j \beta_m[k]k}, 
~ \mathbf{i}_{mn}[k]=\hat{\mathbf{i}}_{mn}[k] e^{j \beta_m[k]k}
\label{eq:V_k_I_ij}
\end{align}
where $\hat{\mathbf{v}}_m[k]$ is the voltage phasor that is observed at nominal frequency, while $\hat{\mathbf{i}}_{mn}[k]$ is the current phasor after removing the exponential term due to the off-nominal frequency at bus $m$, $\beta_m[k]$, that represents the (time-varying) drift in the frequency induced by the above-mentioned reasons. 

Considering the Discrete Time Fourier Transform, we have:
\begin{align}
\bs{Y}_{mn}(f+f_0)H(f)=rect(T_sf)T_s\sum^{N-1}_{r=0}\bs{y}_{mn}[r]e^{-j2\pi rT_sf}
\end{align}
where $\frac{1}{T_s}=120$Hz is the $\mup$ output rate, and $H(f)$ is the frequency response of the filter $h(t)$. Introducing:
\begin{eqnarray}
%\overline{\bs Y}_{ij}(f_0,k)&\triangleq& \frac{1}{T} \overline{\bs{Y}}_{ij}\!\!\left(f_0+\frac{\beta_i[k]}{2\pi T}\right)H\!\left(\frac{\beta_i[k]}{2\pi T}\right),\nonumber\\
{\bs{Y}}_{mn}(f_0,k)&\triangleq& \frac{1}{T_s} \bs{Y}_{mn}\!\!\left(f_0+\frac{\beta_n[k]}{2\pi T_s}\right)H\!\left(\frac{\beta_n[k]}{2\pi T_s}\right),
\label{eq:modulated_Y}
\end{eqnarray}
we have that 
\begin{equation}
{\bs{Y}}_{mn}(f_0,k) =\sum_{r=0}^{N-1}\bs{y}_{ij}[r]e^{-j\beta_n[k] r},
\end{equation}
and similarly $\overline{\bs Y}_{mn}(f_0,k)=\sum_{r=0}^{N-1}\overline{\bs{y}}_{mn}[r]e^{-j\beta_m[k] r}$.


During the quasi steady-state the variations in $\hat{\mathbf{v}}_m[k]$ and $\beta_m[k]$ are negligible over a window of $N$ samples, which means $\hat{\mathbf{v}}_m[k-r]\approx \hat{\mathbf{v}}_m[k]$ and $\beta_m[k-r]\approx \beta_m[k]$. Using this approximation, \eqref{eq:basiceq} can be re-written as:
\begin{align}
\begin{split}
\mathbf{i}_{mn}[k]&
\approx 
\sum_{r=0}^{N-1}\!\overline{\bs{y}}_{mn}[r]\hat{\mathbf{v}}_m[k]e^{j\beta_m[k](k-r)} \\&-\bs{y}_{mn}[r]\hat{\mathbf{v}}_n[k]e^{j\beta_n[k] (k-r)} \\
&=\overline{\bs Y}_{mn}(f_0,k)\mathbf{v}_m[k] -{\bs{Y}}_{mn}(f_0,k) \mathbf{v}_n[k]
\end{split}
\label{eq.i[k]}
\end{align}
%\end{equation}
%we can write \eqref{eq.i[k]1} as follows:
%\begin{align}
%\mathbf{i}_{ij}[k] &=\overline{\bs Y}_{ij}(f_0,k)\mathbf{v}_i[k] -{\bs{Y}}_{ij}(f_0,k) \mathbf{v}_j[k]\label{eq.i[k]}
%\end{align} 
%\begin{align}
%\begin{split}
%\hat{\mathbf{i}}_{ij}[k] &=
%
%\end{split}
%\end{align}  
%From the Fourier transform properties, we can write:
%\begin{align}
%\hat{\mathbf{i}}_{ij}[k]&=\overline{\bs Y}_{ij}(f_0,\beta_k)\hat{\mathbf{v}}_{i}[k]-{\bs{Y}}_{ij}(f_0,\beta_k)\hat{\mathbf{v}}_{j}[k]
%\label{eq:final_LTI}
%\end{align}
%where:
%\begin{align}
%\begin{split}
%{\bs{Y}}^{sh}_{ij}(f_0,\beta_k)&=\bs{Y}^{sh}_{ij}(f_0+\frac{\beta_k}{2\pi})\\
%{\bs{Y}}_{ij}(f_0,\beta_k)&=\bs{Y}_{ij}(f_0+\frac{\beta_k}{2\pi})
%\end{split}
%\label{eq:modulated_Y}
%\end{align}
Equation \eqref{eq.i[k]} is Ohm's law in the phasor domain and is the cornerstone for our transients detection algorithm derived in the following section. 
The analysis above explains through \eqref{eq.i[k]} why in the phasor domain, the equivalent effect of the quasi-steady state conditions is that the admittances \eqref{eq:modulated_Y} fluctuate. The effect is usually modest, because $\beta[k]$ is small. However, during a severe transient or frequency in the order of 10Hz the relationship \eqref{eq.i[k]} with the matrices in \eqref{eq:modulated_Y} does not hold, due to the manifestation of the full dynamic behavior in \eqref{eq:basiceq}.  

In the following, the \textit{``local''} and \textit{``central''} rules are defined leveraging these insights and the knowledge about power system operation.
Note that our rules are set up in a way that all the local engines are agnostic about $\overline{\bs Y}_{mn}(f_0,k)$
and $ \bs Y_{mn}(f_0,k)$, and the sensor siting. However, it is assumed that the central engine knows $\bs{Y}^{sh}_{mn}(f_0,k)|_{\beta[k]=0}$ and $\bs{Y}_{mn}(f_0,k)|_{\beta[k]=0}$ for the lines within its monitoring region and the difference from \eqref{eq:modulated_Y} is treated as equivalent to noise in the observation model. Therefore, when dealing with central rules, we will simply use $\bs{Y}^{sh}_{mn}$ and $\bs{Y}_{mn}$ to refer to
$\bs{Y}^{sh}_{mn}(f_0,k)|_{\beta[k]=0}$ and $\bs{Y}_{mn}(f_0,k)|_{\beta[k]=0}$. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%     
\section{Data Analysis}
\label{sec:data} 
%The local and central rules are formulated to detect anomalies through the evaluation of functions of the voltage and current phasors from $\mup$s. 


Our rules monitor for abnormalities in the following quantities 1) voltage magnitude, 2) instantaneous frequency drift, 3) current magnitude, 4) active power, 5) reactive power, and 6) the validity of  quasi steady-state equations. 
The \textit{``local rules''} just require the stream of phasors from a single $\mup$, while the \textit{``central rules''} combine multiple streams across $\mup$s.     



%We introduce two types of rules: \textit{``static rules''} and \textit{``dynamic rules''}, respectively.  
%Static rules verify that the sensor readings lie in a certain {\it safe} region and are inspired by well established safety engineering practices in power systems. These rules are similar to those that activate
%safety mechanisms for protection in ADS, but in this context they are used to aid the GSS determine if the system is in a normal or abnormal state. 
%Since all criteria are valid irrespective of the loading conditions, the boundaries of the decision regions are static. 

%What we call dynamic rules are adaptive {\it change detection algorithms} that track sudden changes in 
%the statistics of quantities of interest.  They are dynamic, since what defines normal behavior is learned
%from past data. 
%As previously described, normally power systems are in a quasi-steady state condition and exhibits smooth fluctuations. Sudden changes are due to contingencies. While change detection is a standard technique that can be applied to any type of data (in fact, we describe the algorithm later in Section \ref{sec:change_det}) here we use the power systems  
%domain knowledge to define what measurements and functions of the measurements are suitable for an effective test.
%
%In Section \ref{sec.stage-1} we define the detection rules included in stage-1, and in Section \ref{sec.stage-i} the rules that are applied at higher stages, using multiple streams of $\mup$ data. 

\subsection{Local Rules}\label{sec.stage-1} 

The \textit{``local rules''} are applied at the lowest layer of the \textit{``anomaly detection architecture''}, and run on systems on or immediately adjacent to the $\mup$s. Their common feature is that they 
require no specific prior knowledge of the grid network parameters. 
\begin{table}[h]
\centering
\caption{Voltage Magnitude Anomalies}
\begin{tabular}{|l|l|}
\hline
\text{anomaly}& \text{signature \tablefootnote{The voltage magnitude is in p.u.}}\\ \hline \hline
\text{voltage sag} & $0.1 \leq |\mathrm{v}| \leq 0.9,~{T_0}/{2} \leq \tau \leq 60 s$\\ \hline
\text{voltage swell} & $1.1 \leq |\mathrm{v}| \leq 1.8 ,~{T_0}/{2} \leq \tau \leq 60 s$\\ \hline
\text{interruption} & $ |\mathrm{v}| < 0.1,~{T_0}/{2} \leq \tau \leq 60 s$\\ \hline
\text{sustained interruption} & $|\mathrm{v}| < 0.1,~\tau > 60 s$\\ \hline
\text{undervoltage} & $0.1 \leq |\mathrm{v}| \leq 0.9,~\tau > 60 s$\\ \hline
\text{overvoltage} & $1.1 \leq |\mathrm{v}| \leq 1.8,~\tau > 60 s$\\ \hline
\end{tabular}
\label{table:vol_event}
\end{table}

\subsubsection{Voltage Magnitude Changes} The magnitude of the voltage varies within a small range that power quality standards enforce during the normal operations \cite{5154067}. Therefore, any large deviation from that range indicates an abnormal condition. Table.~\ref{table:vol_event} lists the anomalies that can be observed in the voltage magnitude labeled by their severity and duration, denoted by $|\mathrm{v}|$ and $\tau$, respectively. 


%Fig.~\ref{fig:dec_region} depicts the intervals in Table.~\ref{table:vol_event} as decision regions. As it can be observed, the voltage magnitude decision region at each phase can be partitioned into sub-regions indicating the possible existence of the anomaly and the type of anomaly. The events are defined based on the deviation from the nominal voltage and the duration of the deviation, $\tau$. 
% \begin{figure}[h]
%	\begin{center}
%	\includegraphics[width=0.5\textwidth]{figures/decision_region.pdf}
%	\caption{\small Voltage Magnitude Decision Region}
%	\vspace{-0.2cm}
%	\label{fig:dec_region}
%	\end{center}
%\end{figure} 

%The start-time and the end-time of the anomaly are also computed. The cases of {\it sustained interruption, undervoltage} and {\it overvoltage} are flagged upon crossing $60s$, if the maximum allowed time that we expect from restorative actions to bring back the system in the normal state is less than $60s$. If the restorative action maximum allowed time is greater than $60s$, the anomalies are flagged 
%after the smaller between the maximum allowed \textcolor{magenta}{confusing sentence, needs revision} time or when the value crosses back to the normal range.

%Clearly, the voltage magnitude rule can be checked irrespective to the voltage phasors from other $\mup$s.    



\subsubsection{Current Magnitude, Active, and Reactive Power Changes} 
Suitable quantities to monitor for changes that can be computed locally from the $\mup$ voltage and current phasor measurements $\mathbf{v}_m[k]$ and $\mathbf{i}_{mn}[k]$ are current magnitude, active and reactive powers. 
%the apparent power at phase $l=a,b,c$ i.e. \textcolor{blue}{We explicitly use phase notation when discussing the current mag and active/reactive changes but we have not used this notation earlier when discussing the voltage. I think defining S, P, and K as vectors with each row corresponding to the phases and dropping the l subscript, similar to the voltage and current is a little cleaner notation. Just a suggestion.}:
%\begin{align}
%S_l[k]={P}_l[k]+j{Q}_l[k]=\mr{v}_l[k]\mr{i}^*_l[k]
%\label{eq:complex power}
%\end{align}
The three phase apparent power can simply be computed as: 
\begin{align}
\mb{S}_{mn}[k]=\mb{P}_{mn}[k]+j\mb{Q}_{mn}[k]=\text{diag}(\mathbf{v}_m[k])\mathbf{i}^*_{mn}[k]
\label{eq:complex power}
\end{align}
where $\mb{P}_{mn}[k]$ and $\mb{Q}_{mn}[k]$ are the three-phase active and reactive powers, respectively. Note that for the sake of tracking a power flow change in the distribution grid, tracking the active power and reactive power is preferable over monitoring the phase angle difference, since the resistance of the lines is not negligible, and therefore the angle difference does not necessarily indicate the direction of the power flow. We observed this fact in our partner utility grid, when the voltage phase angle at one end of the line was less than the angle at the other end, though the direction of the power flow was not from the higher angle to the lower one.

Even when the voltage magnitude is within the safe range discussed previously, changes in active and reactive power can still happen due to the change of the load, affecting current magnitude and the phase angle between current and voltage phasors. Therefore, it is also of interest to track fast-changes of these quantities using the method described in Section.~\ref{sec:change_det}.
%We seek two main goals in the event detection rules defined on the current phasor magnitude, active, and reactive power, i.e.:    
%\begin{itemize}
%\item to track the fast changes in the current phasor magnitude, and active/reactive power.
%\item to check if the expected maximum limit of current phasor magnitude (which is time-dependent) at the $\mup$ location is violated.   
%\end{itemize}

Because physical changes in this class of data on the distribution grid can be potentially indicative of negative behavior, it is important to determine the direction (upward trend, downward trend or oscillation) of the change.
% 
%the first order difference of the samples of ${Z}_l[k]=|\mr{i}_l[k]|/{P}_l[k]/{Q}_l[k]$ between the start time and the end time are then derived to extract the behavior of the signal during the anomaly as follows:
%\begin{align}
%\dot{Z}_l[k]={Z}_l[k]-{Z}_l[k-1],~~~k \in \text{anomaly}
%\end{align}       
The anomalies related to fast changes are labeled in this class of data with {\it  surge}, {\it drop}, and {\it oscillation} for increasing, decreasing, and swinging trends respectively by estimating the slope of the signal around the time of change.

%\subsubsection{Line Rated Current Limit}
While we have primarily introduced fast state changing events in both the dynamic and transient realms, we must also consider events in the steady state time frame, slower changing yet also potentially critical. An example of this could include a line rating or transformer load being slowly but consistently exceeded leading to accelerated failure. During the quasi steady-state, the three phase current phasor magnitude flowing in each line, i.e., $|\mb{i}_{mn}[k]|$, should be less than or equal the line rated current, $|\mb{i}_{mn}|_{\max}$. This constraint is imposed as feeder limit, and the violation is flagged as \textit{overcurrent}.
%\begin{align}
%|\mb{i}_{ij}[k]| > |\mb{i}_{ij}|_{\max} \rightarrow \textit{Overload} 
%\end{align}

%In the next rule, we also track the fast changes in the current magnitude so this rule would show its significance for cases that the load is slowly but increasingly varying, up to the point that crosses the feeder rated current.  

\subsubsection{Instantaneous Frequency Changes} For a $\mup$ at bus $m$, we propose to estimate adaptively the instantaneous local frequency deviation from the nominal frequency during the quasi-steady state, using the approach for instance in \cite{xia2012widely} that is tailored to three-phase distribution lines, to isolate abnormal changes in the estimated frequency. 
%
%%Newton's method by maximizing the sum of the phasors Short-Time Fourier Transform, as follows:
%%\begin{align}
%%\begin{split}
%%\hat{\beta}_i[k]&=\mbox{arg}\!\max_{\omega} \left
%%\|\sum_{n}  \mathbf{v}_i[k-n]e^{-j\omega n}\right\|^2
%%\!\!\! \\
%%\widehat{\delta f}_i[k]&=\hat{\beta}_i[k]/(2\pi)
%%\end{split}
%%\end{align}
%\begin{align}
%\begin{split}
%g_i(\hat{\beta}_i[k];k)&=\frac{1}{2}\left
%\|\sum_{n} \mathbf{v}_i[k-n]e^{-j\hat{\beta}_i[k] n}\right\|^2 \rightarrow \\
%\hat{\beta}^m_i[k]&=\hat{\beta}^{m-1}_i[k]-\frac{\nabla g_i(\hat{\beta}^{m-1}_i[k];k)}{\nabla^2 g_i(\hat{\beta}^{m-1}_i[k];k)}
%\end{split}
%\end{align}
%where the summation is over a relatively short range around the time instant
%$k$, such that it is reasonable to assume that in \eqref{eq:V_k_I_ij}
%$\hat{\mathbf{v}}_i[k-n]\approx \hat{\mathbf{v}}_i[k]$ and $
%\beta_i[k-n] \approx \beta_i[k]$, and $m$ is the iteration number of Newton's method that is bounded by a defined stopping criterion.
%Sudden large deviations from the nominal frequency can therefore be tracked in $\widehat{\delta f}_i[k]=\hat{\beta}_i[k]/(2\pi)$. 
 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Quasi Steady-State Regime Validity}
As previously noted, when the grid is not in the normal quasi steady-state conditions, the relationship between voltage and the current phasors represents its full dynamic behavior, i.e. the grid is no longer well-approximated by the set of memory-less algebraic equations. Therefore, it is proposed to check the validity of the quasi steady-state regime to flag the presence of transients in the grid. 
At the local engines, \eqref{eq.i[k]} provides the basis for our rule.
 
For the line in Fig.~\ref{fig:dis_line}, assuming that a $\mup$ is installed at bus $m$ means that $\mb{i}_{mn}[k]$, and $\mb{v}_m[k]$ are both available. 
%We first propose our criterion using the data from both $\mup$s assuming that their corresponding local engines can exchange information, and we then extend the formulation to use the data only from a single $\mup$. We can combine the two equations that hold 
%between the voltages and the currents at two ends of the line as follows:
%\begin{align}
%\begin{split}
%\underbrace{
%\begin{pmatrix}
%\mb{i}_{ij}[k]\\
%\mb{i}_{ji}[k]
%\end{pmatrix}}&=
%\underbrace{\begin{pmatrix}
%\overline{\bs Y}_{ij}(f_0,k)&-{\bs Y}_{ij}(f_0,k)\\
%-{\bs Y}_{ij}(f_0,k)&\overline{\bs Y}_{ij}(f_0,k)
%\end{pmatrix}}
%\underbrace{
%\begin{pmatrix}
%\mb{v}_{i}[k]\\
%\mb{v}_{j}[k]
%\end{pmatrix}}\\
%\mb{I}_{ij}[k]&~~~~~~~~~~~~~~~~\mb{H}_{ij}(f_0,k)~~~~~~~~~~~~~~\mb{V}_{ij}[k]
%\end{split}
%\label{eq.2mups}
%\end{align}
%The validity of Fig.~\ref{fig:dis_line} can be verified through the analysis of the algebraic properties of the following two matrices obtained by computing with $M\geq 6$ current and voltage phasors the following cross and auto-correlation samples matrices:
% \begin{align}
% \bs R_{IV}[k]&=\frac{1}{M-1}\sum_{m=0}^{M-1} \mb{I}_{ij}[k-m]\mb{V}^H_{ij}[k-m],\\
%  \bs R_{VV}[k]&=\frac{1}{M-1} \sum_{m=0}^{M-1} \mb{V}_{ij}[k-m]\mb{V}^H_{ij}[k-m].
% \end{align}
%Equation \eqref{eq.2mups} implies that the following homogeneous equation holds during the quasi-steady state since the variations of $\mb{H}_{ij}(f_0,k)$ is negligible over a window of $M$ samples:
% \begin{align}
%\left( \begin{array}{c:c}
%\mathcal{I}_6 &-\mb{H}_{ij}(f_0,k)
%\end{array}\right)
%\underbrace{
%    \begin{pmatrix}
%  \bs R_{ IV}[k]\\
%    \bs R_{ VV}[k]
% \end{pmatrix}}_{\bs R_k}
% =\mb 0
% \label{eq.homog2} 
%  \end{align}
%% \begin{prop}
%% \label{prop.Rk2}
%%Correlation matrix $\bs R_k$ is approximately rank-1 during the quasi steady-state. 
%% \end{prop}
%During the quasi-steady state over a distribution line, the following assumptions hold with a very good approximation for $n=0,1,...,M-1$:
%\begin{align}
%\hat{\mathbf{v}}_i[k-n]&\approx \hat{\mathbf{v}}_i[k],~~~\hat{\mathbf{v}}_j[k-n] \approx \hat{\mathbf{v}}_j[k]\\
%\beta_i[k-n]&\approx \beta_i[k],~~~\beta_j[k-n]\approx \beta_j[k],
%~~~\beta_i[k] \approx \beta_j[k] \nonumber
%\end{align}
%We proved in \cite{jamei2016automated} that
%these assumptions are sufficient to show that $\bs{R}_k$ is rank 1 in the quasi steady-state.  
%Therefore, we can write:
%\begin{align}
%\begin{split}
%\bs R_{VV}[k]&=\frac{1}{M-1}(\mathbf{V}_{ij}[k] \otimes \mb{E}[k])(\mathbf{V}^H_{ij}[k]\otimes \mb{E}^H[k])\\
%&=\frac{1}{M-1}(\mathbf{V}_{ij}[k]\mathbf{V}^H_{ij}[k])\otimes(\mb{E}[k]\mb{E}^H[k])
%\end{split}
%\end{align}
%where $\mb{E}[k]$ is defined as follows and represents the variations due to the off-nominal frequency:
%\begin{align}
%\mb{E}[k]=\mb{1}_{6\times 1}\otimes\begin{pmatrix}
%e^{-j\beta_i[k](M-1)}&\ldots&e^{-j\beta_i[k]}&1\\
%\end{pmatrix}
%\end{align}
%which we can then write:
%\begin{align}
%\mb{E}[k]\mb{E}^H[k]=(\mb{1}_{6\times 1}\mb{1}_{1\times 6})\otimes(M)=M\mb{1}_{6\times 6}
%\end{align}
%and therefore:
%\begin{align}
%\bs R_{VV}[k]=\frac{M}{M-1}(\mathbf{V}_{ij}[k]\mathbf{V}^H_{ij}[k])\otimes(\mb{1}_{6 \times 6})
%\end{align}
%which accordingly means that:
%\begin{align*}
%rank(\bs R_{VV}[k])=rank(\mathbf{V}_{ij}[k]\mathbf{V}^H_{ij}[k])\times rank(\mb{1}_{6 \times 6})=1 
%\end{align*}
%
%Because:
%\begin{align*}
%rank(\bs R_k)=rank(\bs R_k^H\bs R_k)
%\end{align*}
%we analyze the rank of $\bs R_k^H\bs R_k$ here, where:
%\begin{align}
%\bs R_k^H\bs R_k=\bs R_{IV}^H[k]\bs R_{IV}[k]+\bs R_{VV}^H[k]\bs R_{VV}[k]
%\label{eq.RhR2}
%\end{align}
%From the structure of \eqref{eq.homog2} during the quasi-steady state, we have:
%\begin{align}
%\begin{split}
%\bs R_{IV}[k]&=\mb{H}_{ij}(f_0,k)\bs R_{VV}[k]
%\end{split}
%\label{eq.Htilde}
%\end{align}
%Substituting \eqref{eq.Htilde} in \eqref{eq.RhR2}, we have:
%\begin{align}
%\bs R_k^H\bs R_k=\bs R^H_{VV}[k]\bs{\mathcal{G}}_{ij}(f_0,k)\bs R_{VV}[k]
%\end{align}
%where:
%\begin{align*}
%\bs{\mathcal{G}}_{ij}(f_0,k)=\mb{H}^H_{ij}(f_0,k)\mb{H}_{ij}(f_0,k)+\mathcal{I} 
%\end{align*}
%%that is a positive-semidefinite matrix, and therefore we can write:
%%\begin{align}
%%\bs{\mathcal{G}}_{ij}(f_0,k)=\mb{L}_{ij}^H(f_0,k)\mb{L}_{ij}(f_0,k)
%%\end{align}
%%where $\mb{L}_{ij}(f_0,k)$ is the square-root of $\bs{\mathcal{H}}_{ij}(f_0,k)$, and therefore:
%%\begin{align}
%%rank(\bs R^H_k\bs R_k)=rank(\mb{L}_{ij}(f_0,k) \bs R_{VV}[k])
%%\end{align} 
%Since the linear transformation of $\bs R_{VV}[k]$ does not increase its rank and since we have already shown that $\bs R_{VV}[k]$ is of rank-1 during the quasi-steady state, we can conclude that:
%\begin{align}
%\begin{split}
%&rank(\bs R_k)=rank(\bs R_k^H\bs R_k)=\\
%&rank(\mb{L}_{ij}(f_0,k) \bs R_{VV}[k]) \leq rank(\bs R_{VV}[k])=1 \rightarrow \\
% &rank(\bs R_k)=1
%\end{split}
%\end{align}  
%\end{proof}   
%%%%which, in turn, means that $\bs R_k$ must lose rank. Note that for a  balanced three-phase circuit
%%%%it is normal to have a  rank deficient correlation matrix $\bs R_k$ since $ \bs R_{ I V}[k]$ 
%%%%and $\bs R_{VV}[k]$ lose rank. But in quasi-steady state, because of \eqref{eq.homog2} and also because of the high temporal correlation of the data, the whole $\bs R_k$ has rank 1 or close to it, that is: 
%Hence:
%\begin{equation}
%\bs R_k\approx \sigma_1[k]\bs u_1[k]\bs \nu^H_1[k]\rightarrow\bs R_k\bs R^H_k\approx \sigma^2_1[k]\bs u_1[k]\bs u^H_1[k]
%\end{equation}
%where $\sigma_1$ is the largest singular value of $\bs R_k$, and $\bs{u}_1$ and $\bs{\nu}_1$ are the corresponding left and right singular vectors to that, respectively. Deviation from this subspace structure can indicate that the line is experiencing a transient. 
%We can automate the detection of anomaly using this criterion by computing the following cost minimization and tracking the fast changes in $x[k]$: %\footnote{$||.||_{F}$ denotes the Frobenius norm.}:
%\begin{equation}
%\begin{split}
%x[k]&=\min_{\bs u}||(\mathcal{I}_{12}-\bs u\bs u^H)\bs R_k\bs R_k^H||_{F}
%~\mbox{s.t.}~||\bs u||=1
%\end{split}
%\label{eq:cost_two_upmu}
%\end{equation}
%where $||.||_{F}$ denotes the Frobenius norm and $\bs u$ is the principal subspace of $\bs R_k$ and it is normally obtained by minimizing the orthogonal projection with respect to $\bs u$ that is expected to ideally go to zero in the steady-state and be close to this situation in the quasi steady-state regime. 
Let $\bs{\alpha}[k]$ be the diagonal matrix such that voltage phasors of bus $m$ and bus $n$, connected via a power line, are related through: 
\begin{align}
\mb{v}_n[k]= \bs{\alpha}[k]\mb{v}_m[k],
\end{align}
Defining:
 \begin{align}
 \bs R^{(mn)}_{\rm iv}[k]&=\frac{1}{M-1}\sum_{r=0}^{M-1} \mb{i}_{mn}[k-r]\mb{v}^H_{m}[k-r],\\
  \bs R^{(nm)}_{\rm vv}[k]&=\frac{1}{M-1}\sum_{r=0}^{M-1} \mb{v}_{n}[k-r]\mb{v}^H_{m}[k-r],
 \end{align}
Assuming that $\bs{\alpha}[k]$ remains constant over a window of $M$ samples in the quasi-steady state, one can write:
 \begin{align}
\bs R^{(nm)}_{\rm vv}[k]\approx \bs{\alpha}[k] \bs R^{(mm)}_{\rm vv}[k]
 \end{align}
It can be assumed that the variation of $\overline{\bs Y}_{mn}(f_0,k)$ is negligible over $M$ samples in normal operation and use \eqref{eq.i[k]} to write:
\begin{align}
\nonumber
\! \! \left( \begin{array}{c:c}
\mathcal{I}_3 &
-\overline{\bs Y}_{mn}(f_0,k)+{\bs Y}_{mn}(f_0,k)\bs{\alpha}[k] 
\end{array}\right)
\underbrace{
 \begin{pmatrix}
  \bs R^{(mn)}_{\rm iv}[k]\\
    \bs R^{(mm)}_{\rm vv}[k]
 \end{pmatrix}
 }_{\bs R^{(mn)}_k}
\approx\bs 0
\label{eq.homog1}
\end{align}
 \begin{prop}
 \label{prop.Rk1}
Correlation matrix $\bs R^{(mn)}_k$ is approximately rank-1 during the quasi steady-state. 
 \end{prop}
 \begin{proof}
%Similar to the case of $\bs R_k$  by assuming that $\hat{\mathbf{v}}_i[k-n]\approx \hat{\mathbf{v}}_i[k]$ and $\beta_i[k-n]\approx \beta_i[k]$ for $n=0,1,...,M-1$,  the correlation matrix $\bs R^{(i)}_k$ can be shown to be approximately rank-1 during the quasi steady-state.
During the quasi-steady state along a distribution line, the following assumptions hold with a very good approximation for $r=0,1,...,M-1$:
\begin{align}
\hat{\mathbf{v}}_m[k-r] \approx \hat{\mathbf{v}}_m[k],~~~\beta_m[k-r] \approx \beta_m[k]
\end{align}  
Therefore, we can write:
\begin{align}
\begin{split}
\bs R^{(mm)}_{\rm vv}[k]&=\frac{1}{M-1}(\mathbf{v}_m[k] \otimes \mb{E}_m[k])(\mathbf{v}^H_m[k]\otimes \mb{E}_m^H[k])\\
&=\frac{1}{M-1}(\mathbf{v}_m[k]\mathbf{v}^H_m[k])\otimes(\mb{E}_m[k]\mb{E}_m^H[k])
\end{split}
\end{align}
where $\mb{E}_m[k]$ is defined as follows and represents the variations due to the off-nominal frequency:
\begin{align}
\mb{E}_m[k]=\mb{1}_{3\times 1}\otimes\begin{pmatrix}
e^{-j\beta_m[k](M-1)}&\ldots&e^{-j\beta_m[k]}&1\\
\end{pmatrix}
\end{align}
which we can then write:
\begin{align}
\mb{E}_m[k]\mb{E}_m^H[k]=(\mb{1}_{3\times 1}\mb{1}_{1\times 3})\otimes(M)=M\mb{1}_{3\times 3}
\end{align}
and therefore:
\begin{align}
\bs R^{(mm)}_{\rm vv}[k]=\frac{M}{M-1}(\mathbf{v}_m[k]\mathbf{v}^H_m[k])\otimes(\mb{1}_{3 \times 3})
\end{align}
which accordingly means that:
\begin{align*}
rank(\bs R^{(mm)}_{\rm vv}[k])=rank(\mathbf{v}_m[k]\mathbf{v}^H_m[k])\times rank(\mb{1}_{3 \times 3})=1 
\end{align*}

Because:
\begin{align*}
rank(\bs R^{(mn)}_k)=rank((\bs R^{(mn)}_k)^H\bs R^{(mn)}_k)
\end{align*}
we analyze the rank of $(\bs R^{(mn)}_k)^H\bs R^{(mn)}_k$ here, where:
\begin{align}
\begin{split}
(\bs R^{(mn)}_k)^H\bs R^{(mn)}_k=&(\bs R^{(mn)}_{\rm iv}[k])^H\bs R^{(mn)}_{\rm iv}[k]+\\
&(\bs R^{(mm)}_{\rm vv}[k])^H\bs R^{(mm)}_{\rm vv}[k]
\end{split}
\label{eq.RhR1}
\end{align}
From the structure of \eqref{eq.homog1} during the quasi-steady state, we have:
\begin{align}
\begin{split}
\bs R^{(mn)}_{\rm iv}[k]&=\tilde{\mb{Y}}_{mn}(f_0,k)\bs R^{(mm)}_{\rm vv}[k]\\
\tilde{\mb{Y}}_{mn}(f_0,k)&=\overline{\bs Y}_{mn}(f_0,k)-{\bs Y}_{mn}(f_0,k)\text{diag}(\bs{\alpha}[k])
\end{split}
\label{eq.Ytilde}
\end{align}
Substituting \eqref{eq.Ytilde} in \eqref{eq.RhR1}, we have:
\begin{align}
(\bs R^{(mn)}_k)^H\bs R^{(mn)}_k=(\bs R^{(mm)}_{\rm vv}[k])^H\bs{\mathcal{Y}}_{mn}(f_0,k)\bs R^{(mm)}_{\rm vv}[k]
\end{align}
where:
\begin{align*}
\bs{\mathcal{Y}}_{mn}(f_0,k)=\tilde{\mb{Y}}^H_{mn}(f_0,k)\tilde{\mb{Y}}_{mn}(f_0,k)+\mathcal{I} 
\end{align*}
%that is a positive-semidefinite matrix, and therefore we can write:
%\begin{align}
%\bs{\mathcal{Y}}_{ij}(f_0,k)=\mb{B}_{ij}^H(f_0,k)\mb{B}_{ij}(f_0,k)
%\end{align}
%where $\mb{B}_{ij}(f_0,k)$ is the square-root of $\bs{\mathcal{Y}}_{ij}(f_0,k)$, and therefore:
%\begin{align}
%rank((\bs R^{(i)}_k)^H\bs R^{(i)}_k)=rank(\mb{B}_{ij}(f_0,k) \bs R^{(ii)}_{\rm vv}[k])
%\end{align} 
Since the linear transformation of $\bs R^{(mm)}_{\rm vv}[k]$ does not increase its rank and since it has already been shown that $\bs R^{(mm)}_{\rm vv}[k]$ is of rank-1 during the quasi-steady state, one can conclude that:
\begin{align}
\begin{split}
&rank(\bs R^{(mn)}_k)=rank((\bs R^{(mn)}_k)^H\bs R^{(mn)}_k)\leq 
 \\
 & rank(\bs R^{(mm)}_{\rm vv}[k]) \rightarrow  rank(\bs R^{(mn)}_k)=1
\end{split}
\end{align}   
\end{proof}
%This in fact suggests a similar criterion for a single $\mup$ to flag the exit from a quasi steady-state regime. 
%Therefore, the fast changes in $x[k]$ defined in the following can be checked for each individual incident line to that bus:
Hence:
\begin{align}
\begin{split}
&\bs R^{(mn)}_k \approx \sigma^{(mn)}_1[k]\bs u^{(mn)}_1[k] (\bs \nu^{(mn)}_1[k])^H\rightarrow \\
&\bs R^{(mn)}_k (\bs R_k ^{(mn)})^H\approx (\sigma^{(mn)}_1[k])^2\bs u^{(mn)}_1[k] (\bs u^{(mn)}_1[k])^H
\end{split}
\end{align}
where $\sigma^{(mn)}_1$ is the largest singular value of $\bs R^{(mn)}_k$, and $\bs{u}^{(mn)}_1$ and $\bs{\nu}^{(mn)}_1$ are the corresponding left and right singular vectors to that, respectively. Deviation from this subspace structure can indicate that the line is experiencing a transient. 
We can automate the detection of anomaly using this criterion by computing the following cost minimization and tracking the fast changes in $x[k]$ for each incidental line to a bus with $\mup$:
\begin{equation}
\begin{split}
x[k]=&\min_{\bs u} ||(\mathcal{I}_{6}-\bs u\bs u^H)\bs R^{(mn)}_k(\bs R^{(mn)}_k)^H||_{F}\\
&\mbox{s.t.}~||\bs u||=1
\end{split}
\label{eq:cost_one_upmu}
\end{equation}
In other words, $x[k]$ measures the size of the residual that $\bs R^{(mn)}_k$ has in the space orthogonal to the optimal $\bs u$, which should be zero in the quasi steady-state and non-zero otherwise. Since it has already been shown that $\bs R^{(mn)}_k$ is of rank-1 during the quasi steady-state, the left singular vector corresponding to the largest singular value of $\bs R^{(mn)}_k$ is the only  quantity of interest to compute the metric, instead of computing all the singular vectors. Therefore, also owing it to the small size of the matrix, the method is not computationally very expensive.

To conclude the local rules, a flowchart of the analysis performed at the local engine next to $\mup$ at bus $m$ is presented in Fig.~\ref{fig.local_flowchart}. At each instant of time, the phasor readings are received by the local engine and the introduced metrics above are calculated. The pre-processed data are then passed to the local rules to check for any violation. A violation could be trespassing pre-defined limits (e.g., the voltage magnitude rule, or maximum current magnitude limit) or fast changes in a metric with smooth behavior during the normal condition (e.g., quasi steady-state validity rule). Once a violation is found in one of the metrics, the start time is recorded. The search for anomaly continues until no new violation is found for a certain window of time ({\it{``Count1 $>T_1$''}}), and that specifies the end time of the anomaly. The type of anomaly is then determined based on the behavior of the data between the start time and the end time (e.g., active power surge, voltage interruption,...). The start time, end time and the anomaly label is then sent upstream for further analysis/visualization, and the parameters are reset for next event. If the number of detected violations related to a certain event passes a pre-defined threshold ({\it{``Count2 $>T_2$''}}), the end time is replaced with a \textit{``Persistent''} label, and the results are sent to the central engine, without waiting for the end of the event to arrive. The reason is to be able to inform the operator about the anomaly in time, and not waiting too long before something more damaging happens.               
\begin{figure}
\centering
\includegraphics[trim = 1mm 1mm 1mm 1mm,width=0.8\linewidth]{figures/flowchart_local_black.pdf}
\caption{Local Engine Analysis Flowchart Next to $\mup$ at Bus $m$.}
\label{fig.local_flowchart}
\end{figure}

\subsection{Central Rule}\label{sec.stage-i}
At higher levels of aggregation, the central engine in our case, the natural way to relate the measurements is through the grid interconnection. 
For a grid with $B$ buses, let $\mathbf{I}[k]$ denote the vector of three-phase current injection phasors with size $3B$, and $\mathbf{V}[k]$ represent the vector of three-phase voltage phasor at all the buses, which contains $3B$ elements. We define the measurement vector $\mathbf{d}[k]=(\mathbf{I}^T[k],\mathbf{V}^T[k])^T$.
%\begin{align}
%\mathbf{d}[k]=\begin{pmatrix}
%\mathbf{I}[k] \\ \mathbf{V}[k]
%\end{pmatrix}
%\end{align}
During the steady-state, the following algebraic equation should hold:
\begin{align}
\mathbf{H}\mathbf{d}[k]
=\mathbf{0},~~~ 
\mathbf{H}&=\left( \begin{array}{c|c}
\mathcal{I}_{3B}  &-\bs{Y}_{3(B \times B)}
\end{array} \right)
\label{eq:grid_homogen}
\end{align} 
where $\bs{Y}$ is the admittance matrix of the grid that connects the current injection to the bus voltages. During the quasi steady-state these equations are close to be homogeneous. Since the distribution grid is unbalanced, and the lines are not transposed the set of equations that should be dealt with are three phase instead of working with positive sequence \cite{kersting2012distribution}. In this framework, we are also able to include the laterals in the admittance matrix by putting the entries corresponding to the phases that do not exist equal to zero.  

It is assumed that $\mathbf{H}$ is known, $K$ denotes the number of $\mup$s that are available and that each device has enough channels to measure the voltage and all incidental current measurements of the bus on which it is placed. Therefore, having a $\mup$ at bus $m$ means that the entries in $\mb{V}[k]$ corresponding to $\mb{v}_m[k]$  and entries in $\mb{I}[k]$ corresponding to $\sum_{n:m \sim n} \mb{i}_{mn}[k]$ are both available, where $m \sim n$ denotes that bus $m$ and $n$ are connected through a line. % \footnote{$i \sim j$ denotes that bus $i$ and $j$ are connected through a line.}.
%\begin{align}
%[\mb{V}[k]]_i=\mb{v}_i[k],~~
%[\mb{I}[k]]_i=\sum_{j:i \sim j} \mb{i}_{ij}[k]
%\end{align}
Let ${\bf T}$ denote a matrix parsing the vector $\mathbf d[k]$ into two parts corresponding to the unavailable measurements, $\mathbf{d}_u[k]$, and the available measurements, $\mathbf{d}_a[k]$:
\begin{equation}
{\mathbf T}=
\begin{pmatrix}
{\mathbf T}_u\\
{\mathbf T}_a
\end{pmatrix}
~\rightarrow~ 
{\mathbf T}\mathbf d=\begin{pmatrix}
{\mathbf d}_u\\
{\mathbf d}_a
\end{pmatrix},
~\mathbf{H}{\mathbf T}^T=
\left(\!\!
\begin{array}{c|c}
{\mathbf H}_u&{\mathbf H}_a
\end{array}\!\!
\right)
\end{equation}
where $K'=B-K$ and
\begin{align}
 \mb{T}_u \in \{0,1\}^{6(K' \times B)},~~
 \mb{T}_a \in \{0,1\}^{6(K \times B)}
\end{align}
$\mb{T}_u$ and $\mb{T}_a$ here are block diagonal matrices of size $6(K' \times B)$ and $6(K \times B)$ with entries equal to 0 or 1. The former is supposed to select the unavailable current and voltage phasors by having entries equal to 1 at corresponding locations, and the latter is supposed to pick the available phasors. Since ${\mathbf T}^T{\mathbf T}={\cal I}$, we can rewrite \eqref{eq:grid_homogen} as follows:
\begin{subequations}
\begin{align}
\label{eq:split_grid_homogen_1}
\mathbf{H}_u\mathbf{d}_u[k]&+\mathbf{H}_a\mathbf{d}_a[k]=\mathbf{0} \rightarrow \\
\mathbf{H}_a\mathbf{d}_a[k]&=-\mathbf{H}_u\mathbf{d}_u[k].
\label{eq:split_grid_homogen_2}
\end{align}
\end{subequations}
Let first assume that we have enough $\mup$s that satisfy $K > \frac{B}{2}$. Therefore, the matrix $\mb{H}_u$ would be a tall matrix and has a left null-space. Premultiplying both sides of \eqref{eq:split_grid_homogen_2} by the projector on the left null-space of $\mb{H}_u$, we have:
\begin{align}
(\mathcal{I}-\mb{H}_u \mb{H}^\dagger_u)\mathbf{H}_a\mathbf{d}_a[k]=\mb{0}
\label{eq:central_proj}
\end{align}
because $(\mathcal{I}-\mb{H}_u \mb{H}^\dagger_u)\mathbf{H}_u$=$\mb{0}$. The equality in \eqref{eq:split_grid_homogen_2} only holds during the steady-state (and for quasi steady-state with a good approximation), which means that equation \eqref{eq:central_proj} is homogeneous only in the steady-state (nearly-homogeneous in the quasi steady-state), and non-homogeneous otherwise. The following metric should, therefore, be close to zero only during normal operation and if $\mathbf{H}$
is unchanged:
\begin{align}
x[k]=\frac{||(\mathcal{I}-\mathbf{H}_u\mathbf{H}_u^\dagger)\mathbf{H}_a\mathbf{d}_a[k]||_2^2}{||\mb{d}_a[k]||_2^2}
\end{align}
However, in reality, the number of available $\mup$s, $K \ll \frac{B}{2}$. In this case, $\mb{H}_u$ is a fat matrix and, in general, is of full row rank, which in turn means that $(\mathcal{I}-\mathbf{H}_u\mathbf{H}_u^\dagger)$=$\mb{0}$, and our criterion becomes trivial. However, $\mb{H}_u\mb{H}^H_u$ has generally a high condition number, due to the weak grid connectivity. Therefore, both sides of \eqref{eq:split_grid_homogen_2} can be projected on the subspace spanned by the left singular vector, denoted by $\mb{u}_{u,s}$ corresponding to the smallest singular value of $\mb{H}_u$ expecting that $\mb{u}^H_{u,s}\mathbf{H}_u\mathbf{d}_u[k]$ to be small.
%\begin{align}
%\mb{u}^H_{u,s}\mathbf{H}_a\mathbf{d}_a[k]=-\mb{u}^H_{u,s}\mathbf{H}_u\mathbf{d}_u[k]
%\label{eq:central_proj2}
%\end{align}
%The right term in \eqref{eq:central_proj2} should be pretty small. 
Accordingly, when the quasi steady-state is the regime of operation, i.e., when the equality in \eqref{eq:split_grid_homogen_2} holds, it is expected that the following function to be small and to vary smoothly:
\begin{align}
x[k]=\frac{|\mathbf{u}^H_{u,s}\mathbf{H}_a\mathbf{d}_a[k]|^2}{||\mathbf{d}_a[k]||^2}.
\label{eq:xopt2}
\end{align}
The exit from this behavior is then marked as an anomaly in the central engine 
%Even though the equation is not exactly homogeneous, primarily due to the frequency drift discussed in Section \ref{sec.model}, it suggests that an estimate of $\mb{d}_u$ can be found through the following minimization:
%\begin{align}
%x[k]=\underset{\mathbf{d}_u}{\min}~ {{||\mathbf{H}_u\mathbf{d}_u[k]+\mathbf{H}_a\mathbf{d}_a[k]||^2}}
%\label{eq:opt}
%\end{align}
%which is a simple least square problem, with well-known solution:
%\begin{align}
%\mathbf{d}^\text{opt}_o[k]=-\mathbf{H}_o^\dagger\mathbf{H}_a\mathbf{d}_a[k]
%\end{align}
%Consequently:
%\begin{align}\label{xopt}
%x[k]=||(\mathcal{I}-\mathbf{H}_o\mathbf{H}_o^\dagger)\mathbf{H}_a\mathbf{d}_a[k]||^2,
%\end{align}
%is what we use as the quantity to track to detect that a transient is present and apparent through the measurements $\mathbf{d}_a[k]$ due to the fact that \eqref{eq:split_grid_homogen_1} no longer holds. We can interpret \eqref{xopt} as follows. The matrix $(\mathcal{I}-\mathbf{H}_o\mathbf{H}_o^\dagger)$ is the projector on the orthogonal subspace with respect to the column space spanned by $\mathbf{H}_o$. Hence, by definition, for any $\mathbf{d}_o[k]$ we have:
%\begin{equation}
%(\mathcal{I}-\mathbf{H}_o\mathbf{H}_o^\dagger)\mathbf{H}_o\mathbf{d}_o[k]=\mathbf{0}
%\end{equation}
%and therefore, if \eqref{eq:split_grid_homogen_1} holds, it must also be that:
%\begin{equation}\label{eq.null}
%(\mathcal{I}-\mathbf{H}_o\mathbf{H}_o^\dagger)\mathbf{H}_a\mathbf{d}_a[k]=\mathbf{0}
%\end{equation}
%which explains why the cost in \eqref{xopt} should be small when the system is in quasi-steady state.
%However, \eqref{eq.null} becomes trivial if $(\mathcal{I}-\mathbf{H}_o\mathbf{H}_o^\dagger)={\mathbf 0}$, which happens when $\mathbf{H}_o$ is a full-rank square matrix or a fat matrix (i.e., $K < \frac{|\mathcal{V}^p|}{2}$) with full row rank. In this case, we rely on the fact that the matrix $\mathbf{H}_o$ has a high generalized condition number or in other words has $m_o < 3|\mathcal{V}^p|$ dominant singular values due to the weak grid connectivity of radial or weakly meshed networks and relative homogeneity of the line parameters. Having the singular value decomposition of $\mathbf{H}_o$ as follows:
%\begin{align}
%\mathbf{H}_o=\mathbf{U}_o\mathbf{S}_o\mathbf{V}^H_o
%\end{align}   
%we can partition $\mathbf{U}_o=(\mathbf{U}_{o,1}, \mathbf{U}_{o,2})$ where $\mathbf{U}_{o,1}$ corresponds to the $m_o$ most significant singular values. Therefore, $\mathbf{U}_{o,2}\mathbf{U}^H_{o,2}\mathbf{H}_o$ is close to zero and if \eqref{eq:split_grid_homogen_1} holds, it implies that $x[k]$ defined as follows should also be small:
%\begin{align}
%x[k]=||\mathbf{U}_{o,2}\mathbf{U}^H_{o,2}\mathbf{H}_a\mathbf{d}_a[k]||^2,
%\label{eq:xopt2}
%\end{align}  
and $x[k]$ is the quantity that is proposed to be tracked for fast changes for this purpose.

The flowchart for the central engine is similar to the one for local engine to some extent except that all the $\mup$ readings are required to form the central metric, and the results from the local analysis are received by the central engine, and the analysis results from this stage are not shipped anywhere, and are ready to be displayed for the operator. 
\subsection{Fast Change Detection Method}
\label{sec:change_det}
As explained above, some of the criteria defined in local and central rules require tracking fast changes in the quantities that are defined, because severe variations in $x[k]$ are signatures of an anomaly. From real data and simulations we have verified that variations in the mean value for these quantities during the quasi steady-state regime are extremely smooth. This observation prompted us to consider changes in their mean value as the common statistical trade-mark of anomalies in all of these quantities and to use the sequential two-sided Cumulative Sum (CUSUM) algorithm \cite{page1954continuous,basseville1993detection} as a heuristic. The use of this algorithm amounts to approximating the samples, for all the aforementioned quantities, as outcomes of a Gaussian non-zero mean process with independent observations. Although the observations are in fact temporally correlated, our objective (i.e. fast change detection in mean) justifies the relaxation that the random process has independent observation samples. The algorithm decides between two hypotheses $\mathcal{H}_0$: {\it no change in the mean}, or $\mathcal{H}_1$: {\it change in the mean}, at time $k$.% If the change is detected (hypothesis $\mathcal{H}_1$), it estimates when this change has happened.

We expect to see multiple change points during an event. Detection of multiple change points is achieved by resetting the decision functions and cumulative sums to zero after the change is detected, and continuing the inspection of upcoming samples. The fast change anomaly is completed if no new changes are detected for a defined window of time.
\section{Optimal $\mup$ Placement}
In tandem with the anomaly detection, the criterion that was described for the central engine can be the basis to determine an optimal placement for the $\mup$s. As it was mentioned, the challenge here is that we cannot feasibly nor practically deploy $\mup$s at all nodes in the distribution system, therefore we consider a limited deployment, where $K \ll \frac{B}{2}$.  

Ideally, we want the matrix $\mb{H}_u$ to have a left null-space, i.e., the criterion in \eqref{eq:xopt2} to be zero in the steady-sate. Considering the high condition number of $\mb{H}_u \mb{H}^\dagger_u$, a reasonable approach to find the optimal configuration is to minimize the norm in \eqref{eq:xopt2} over all the possible placement configurations. 
%However, the results of the placement should not be dependent on the value of the measurement. 
Let first rewrite the defined metric in \eqref{eq:xopt2}:
\begin{align}
x[k]=\frac{\mathbf{d}_a^H[k]\mathbf{H}^H_a \mb{u}_{u,s}\mb{u}^H_{u,s} \mathbf{H}_a\mathbf{d}_a[k]}{||\mb{d}_a||^2}.
\end{align} 
%Defining $\mb{W}$ as follows:
%\begin{align}
%\mb{W}=\mb{T}^T_a\mathbf{H}^H_a \mb{A} \mathbf{H}_a \mb{T}_a 
%\end{align}
%and noticing that:
%\begin{align}
%\mathbf{d}_a^H[k]\mathbf{H}^H_a \mb{A} \mathbf{H}_a\mathbf{d}_a[k]=\mb{d}^H[k] \mb{W} \mb{d}[k]
%\end{align}
We desire our formulation to be only topology-dependent. Therefore,  the optimal placement problem is formulated as a min-max optimization with the following structure:    
\begin{align}
\label{eq.optimization}
\begin{split}
\mathbf {\Pi}^\text{opt}=&~
\mbox{arg}\!\min_{\mathbf \Pi}~~ \lambda_{\max}(\mb{W}) 
%\mbox{arg}\!\min_{\mathbf \Pi}~\max_{\mb{d}_a[k]}\frac{1}{||\mb{d}_a[k]||^2}\mathbf{d}_a^H[k] \mb{W} \mathbf{d}_a[k] 
\\
\mbox{s.t.}
~~&\left(\!\!
\begin{array}{c|c}
{\mathbf H}_u&{\mathbf H}_a
\end{array}\!\!
\right)=\mathbf H \left(\!\!
\begin{array}{c|c}
{\mathbf T}^T_u&{\mathbf T}^T_a
\end{array}\!\!\right)
\\
&\mb{T}=\mathcal{I}_2 \otimes (\mb{\Pi} \otimes \mathcal{I}_3),
\\
&\mb{W}=\mathbf{H}^H_a \mb{u}_{u,s}\mb{u}^H_{u,s} \mathbf{H}_a
,~~~[\mathbf{\Pi}]_{i,j} \in \{0,1\}\\
&
\sum_{j} [\mathbf{\Pi}]_{i,j}=1,~~~\sum_{i} [\mathbf{\Pi}]_{i,j} = 1
\end{split}
\end{align} 
Since $\lambda_{\max}(\mb{W})=\max_{\mb{d}_a[k]}\frac{\mathbf{d}_a^H[k] \mb{W} \mathbf{d}_a[k]}{||\mb{d}_a[k]||^2}$, essentially we are choosing a placement that minimizes the maximum value that our objective function can take over possible set of available measurement vectors $\mb{d}_a[k]$.

An exhaustive search is required to find the global optimum of the optimization problem in  \eqref{eq.optimization}, which is exponentially complex, and therefore does not scale well. This becomes a barrier when the size of the grid is large, i.e., in most of the real grids. Therefore, we propose to employ a \textit{``Greedy Search''} as an alternative to reduce the time complexity to \textit{polylog}, while accepting to be near-optimal. The pseudo-code of the employed greedy search is illustrated in Algorithm.~\ref{alg.greedy}.
\SetKwBlock{Init}{Initialization}{end}
\begin{algorithm}
\Init{
$K$ := Number of $\mup$s\;
$\mathcal{P}:=\emptyset$, //~Set of selected placement locations\;
$\mathcal{L}:=$~Set of candidate placement buses\;
} 
\Begin {
\For{n=1..K}{
$Cost \leftarrow \inf$\;
\For{each $l \in \mathcal{L}$}{
$\mathcal{P}:=\mathcal{P} \cup \{l\}$\;
given $\mathcal{P},\text{ calculate } \lambda_{\max}(\mb{W})$\; 
\If{$\lambda_{\max}(\mb{W})<Cost$}{
$l_{opt} \leftarrow l$\;
$Cost \leftarrow \lambda_{\max}(\mb{W})$\;} 
$\mathcal{P}:=\mathcal{P} \setminus \{l\}$\;}
$\mathcal{P}:=\mathcal{P} \cup \{l_{opt}\}$\;
$\mathcal{L}:=\mathcal{L} \setminus \{l_{opt}\}$\;}
}
\caption{Greedy Search Pseudo-Code for Optimal $\mup$ Placement.}

\label{alg.greedy}
\end{algorithm}


%The optimal cost of the inner maximization is the maximum eigenvalue of matrix $\mb{W}$, denoted by $\lambda_{\max}(\mb{W})$.
%%\begin{align}
%%\mathcal{J}^\text{opt}=\lambda_{\max}(\mb{W}) 
%%\end{align}
%%where $\lambda_{\max}(\mb{W})$ is the maximum eigenvalue of matrix $\mb{W}$. 
%%The optimal solution $\mb{d}^\text{opt}[k]/||\mb{d}^\text{opt}[k]||$ is the eigenvector of $\mb W$ that corresponds to the largest eigenvalue.
%The outer optimization can now be written as:
%\begin{align}
%\begin{split}
%\mathbf {\Pi}^\text{opt}=~~&\mbox{arg}\!\min_{\mathbf \Pi}~~ \lambda_{\max}(\mb{W}) \\
%\mbox{s.t.}~~&\text{same constraints as in \eqref{eq.optimization}}
%\end{split}
%\label{eq.optimal}
%\end{align} 

\section{Numerical Results}
\label{sec:res}
In this section, we first find the optimal placement for our $\mup$s based on \eqref{eq.optimization} and then test the effectiveness of the proposed anomaly detection criteria through simulated data and real data, provided from the $\mup$s that are installed in our partner utility medium voltage (12.47 kV) grid.
\subsection{Synthetic Data}
The IEEE-34 bus test case \cite{ieee34} is simulated using the time-domain simulation environment of DIgSILENT \cite{manual2009version} that deals with differential equations rather than memory-less equations. The sampling rate is selected to be equal to the sampling rate of the Analog-to-Digital Converter (ADC) in a real $\mup$, which is 512 $\times$ 60 Hz =30720 samples per sec.. We then processed these time-domain data through our phasor estimation algorithm, that emulates a two-cycle, P-class algorithm based on the IEEE C37.118.1 \cite{c37} producing phasor samples at a rate of 120 Hz. The single-line diagram of the test case is shown in Fig.~\ref{fig.ieee34}. This case includes single-phase laterals, voltage regulators, and untransposed lines, which all are modeled exactly in our admittance matrix.    
\begin{figure}[ht]
\centering 
\includegraphics[trim = 2mm 2mm 2mm 2mm,width=0.5\textwidth]{figures/ieee34.pdf}
\caption{IEEE 34-Bus Test Feeder Single-Line Diagram}
\label{fig.ieee34}
\end{figure}

Table.~\ref{tab.opt} compares the objective value for a random placement, \textit{``Greedy Search''} and \textit{``Exhaustive Search''}, and the time complexity of each solver, assuming that $K=3$ $\mup$s are available. 
\begin{table}[htbp]
\caption{IEEE-34 Case Optimal $\mup$ Placement Result for $K=3$}
\label{tab.opt}
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
& \bf{Random} & \bf{Greedy} & \bf{Exhaustive}\\
\hline \hline
\bf{Optimum Cost} & 1.7085 &0.51477&0.51477 \\ \hline
\bf{Buses with $\mup$s} &\{1,3,9\} &\{7,19,31\}&\{9,19,31\}\\ \hline 
\bf{Run Time} & --&2.84 s&290.266 s\\ \hline 
\end{tabular}
\end{center}
\end{table}     
The objective value of the \textit{``Greedy Search''} and the \textit{``Exhaustive Search''}, and the set of the selected buses are close to each other, while the run time of the \textit{``Greedy Search''} is 102.206 times faster. Hence, the \textit{``Greedy Search''} can be a very good choice to solve our optimal placement problem.         

As expected, the placement rule tries to scatter the available $\mup$s all over the grid, in order to achieve the maximum possible coverage. 

In order to investigate how the time complexity grows, and also analyze the results of the placement criterion, the 123 standard test case in \cite{ieee34} was used, considering 20 $\mup$s available (i.e., $K=20$). Without loss of generality, the 123 test feeder was reduced to 70 buses to only include three-phase lines, and roll up all the laterals (single-phase and two-phase lines). The reasoning behind this reduction is that visibility on the main feeder is more important for us than the the visibility on the laterals, considering the limited number of $\mup$s. Using a  machine with 60 Intel(R) Xeon(R) CPU E7-4870 v2 @ 2.30GHz cores, it took 11.56 Sec for the algorithm to place 20 $\mup$s over 70 buses. Fig.~\ref{fig.placement123} illustrates the location of the optimally-placed $\mup$s in the reduced grid. It can be observed from the figure that the $\mup$s are scattered over the grid to achieve the maximum sensitivity with respect to different locations of anomalies. 
\begin{figure}[ht]
\centering 
\includegraphics[width=0.5\textwidth]{figures/placement123.png}
\caption{ Optimally-Placed $\mup$s on Reduced IEEE 123 Test Feeder.}
\label{fig.placement123}
\end{figure}      

\subsubsection{Single-Line to Ground Fault-IEEE 34 Bus} In this simulation, the rules are tested for detecting anomaly with respect to a
Single-Line to Ground Fault (SLGF), which is a very common type of short-circuit fault in the distribution grid. A SLGF was introduced on ``Phase a'' of line (25,26), which then caused the fuse placed on the phase a of this line near bus 25 to melt down. Our three $\mup$s are placed on buses, 7, 19, and 31 based on the ``greedy search'' result for the optimal placement criterion. 

The results of the \textit{``voltage magnitude change''} rule is shown in Fig.~\ref{fig.sim_vol_mag} for $\mup$s 7, and 19 for instance. Simply, the rule inspects the data for large deviations, label them accordingly, and find the start time and the end time of the event, marked with blue and red stars.
  
\begin{figure}[ht]
\centering 
\includegraphics[width=0.5\textwidth,height=4 cm]{figures/sim_vol_mag_rev.pdf}
\caption{ Voltage Magnitude Local Rule Result for SLGF.}
\label{fig.sim_vol_mag}
\end{figure}
Fig.~\ref{fig.sim_SS_local} illustrates the metric value in \eqref{eq:xopt2} for the specified lines that is inspected with $M=12$ to check whether the grid is in the quasi steady-state or not, where the voltage and current data are first converted to per-unit system assuming $S_b=1$ MVA. The start time of the detected changes are also marked, setting the CUSUM detector parameters fixed in all the three local engines corresponding to each $\mup$. As it can be observed, there are two periods in which the grid manifests its dynamic: the first one corresponds to the occurrence of the fault and the second matches with the fuse meltdown. In addition, based on the severity of the transient that each $\mup$ measures, the number of detected changes via CUSUM varies. In this case, considering the location of the $\mup$s and the location and type of the fault, the most severe change appears in the metric corresponding to measurements from line (19,20), while the changes in metric for line (31,32) is very small. Therefore, based on the defined parameters on the detector, CUSUM finds quite a large number of change points in the former, while it is not set to be sensitive to the changes in the order that appears in the latter. In fact, if the detector is set to be too sensitive, it can increase ``\textit{false alarms}'' in the system. 
Also note that due to the two-cycle calculation of the phasor, and use of $M$ samples to calculate the correlation matrix, the event appears and disappears with a systematic delay.      
%Fig.~\ref{fig.sim_SS_local} illustrates the metric value in \eqref{eq:xopt2} for the specified lines with $M=12$ to check whether the grid is in the quasi steady-state or not \footnote{The voltage and current data are first converted to per-unit system assuming $S_b=1$ MVA.}. The start time of the detected changes are also marked, setting the CUSUM detector parameters fixed in all the three local engines corresponding to each $\mup$. As it can be observed, there are two periods in which the grid manifests its dynamic: the first one corresponds to the occurrence of the fault and the second matches with the fuse meltdown. In addition, based on the severity of the transient that each $\mup$ experiences 
%and the sensitivity of the detector, 
%the number of detected changes via CUSUM, and the most number of changes in the metric is for line (19,20), while it is not set to be sensitive to the changes in the order of what the metric for line (31,32) sees. In fact, if the detector is set to be too sensitive, it can increase the number of %``\textit{false alarms}'' in the system.
%Note that due to the two-cycle calculation of the phasor, and use of $M$ samples to calculate the correlation matrix, the event appears and disappears with a systematic delay.      
\begin{figure}[ht]
\centering 
\includegraphics[width=0.5\textwidth]{figures/sim_SS_local_rev.pdf}
\caption{Quasi Steady-State Validity Checking for SLGF.}
\label{fig.sim_SS_local}
\end{figure} 
The other local rules also capture the anomaly, though with different severity and behavior (we just show some of the results here for lack of space). In fact, many of the local rules may detect the same event, though some rules are more informative than others depending on the cause. Each triggered rule reports a start and an end time for the event. Storing these time-tags for eventful segments of data helps understanding their relationship.

The metric defined for our central engine is also illustrated in Fig.~\ref{fig.sim_SS_cent}. The delay in appearing and disappearing of the event in here is solely due to the two-cycle phasor calculation.
\begin{figure}[ht]
\centering 
\includegraphics[trim = 2mm 2mm 2mm 2mm,width=0.75\linewidth,height=4 cm]{figures/sim_SS_central_rev.pdf}
\caption{Central Rule Inspection for SLGF.}
\label{fig.sim_SS_cent}
\end{figure} 

It should be noted that the value of the metric in \eqref{eq:xopt2} during the quasi steady-state is highly dependent on the number of $\mup$s and the topology of the grid that together determine the structure of $\mb{H}_u$ and $\mb{H}_a$. 
%This non-ideal condition (i.e., having non-zero value for $x[k]$ during the quasi steady-state) is imposed by the limited number of $\mup$s. 
However, the best placement of the $\mup$s for a certain topology and number of $\mup$s that makes the metric to be as close as possible to zero, returns a certain objective value that can be used as the baseline to determine what is a normal value for $x[k]$ and what would be an anomaly.   
\subsubsection{Discussion--Compromised Data} 
We illustrate here the resilience of the architecture to data injection attacks. 
%The hierarchical way of data analysis in our ADA makes our rules to be robust with respect to compromised $\mup$ data to some degree. The $\mup$ data can be compromised at the ``device level'' before the data are sent to local engines or at the ``network level'', when the data are sent from the local engines to the central engine. At the ``network level'', even when all of the $\mup$ data are compromised, which accordingly means that the central engine fails to detect the anomaly, the local rules can still spot the anomaly and at the same time indicate that the data are possibly compromised on the way to the central engine. However, for the ``device level'' case, although the local rules corresponding to the compromised $\mup$s fail, the central engine can possibly detect anomalies if enough number of $\mup$s are not manipulated. 
For this purpose, three data attack scenarios are investigated happening concurrently with the SLGF event discussed previously. We consider the case of the attacker manipulating the data of $\mup$ 7 in the first case, and $\mup$ 19 in the second case, and finally $\mup$ 7 and 19 at the same time in the third case on their way to the central engine. In all cases the data injected are a {\it replay} of the last available data set before the anomaly starts. Setting the change detector parameters fixed for all the three cases, Fig.~\ref{fig.sim_central_compromised} shows, for each case, the central rule and the start time of the detected changes. As can be seen, since $\mup$ 19 is playing an important role for this event, having $\mup$ 7 compromised will not affect our central rule significantly (case-1). However, when the $\mup$ 19 is compromised, the number of detected changes reduce significantly (case-2), and when both $\mup$ 7 and 19 are compromised and the only healthy data is coming from $\mup$ 31, the detector does not pick any fast changes based on the set parameters. This also reveals the importance of tuning the detector thresholds to have a certain ``false alarm,'' while maximizing the ``detection'' probability.   
\begin{figure}[ht]
\centering 
\includegraphics[trim = 0mm 0mm 0mm 0mm,width=0.5\textwidth]{figures/sim_central_compromised_rev.pdf}
\caption{Central Rule for SLGF with Manipulated $\mup$ Data.}
\label{fig.sim_central_compromised}
\end{figure}          
We wish to remark that in all the three cases, the local analytics that directly draw data from $\mup$s will still flag the alarm, so buffering locally at the site of the event these data can be an important way of helping understand what communications were compromised in an ex-post analysis.
\subsubsection{Discussion--Optimal vs Non-Optimal Placement} 
As it was mentioned, the placement criterion tries to scatter the available $\mup$s over the grid to achieve the maximum coverage, and therefore make the central rule more sensitive to anomalies. 

In order to compare the performance of an optimal versus non-optimal placement, a load loss event is created on bus 24 of IEEE-34 test case at $t=0.4$s. The $\mup$s are placed based on the random placement and greedy search result given in Table.~\ref{tab.opt}, corresponding to non-optimal and optimal placement, accordingly. Fig.~\ref{fig.greedyVSrandom} shows the central metric for these two cases. Since the relative change is what matters to our detector, the metrics corresponding to two placement are brought on the same scale. As it can be observed, since the $\mup$s in the random placement are concentrated at a certain area, events like this would not be very pronounceable in the central metric, which could possibly lead to a ``false-negative''.
\begin{figure}[ht]
\centering 
\includegraphics[trim = 2mm 2mm 2mm 2mm,width=0.75\linewidth]{figures/greedyVSrandom.pdf}
\caption{Central Metric Change of a Load Loss Event; Optimal versus Non-optimal Placement.}
\label{fig.greedyVSrandom}
\end{figure}   
\subsection{Real Data}
Fig.~\ref{fig.rpu} shows the abstract one-line diagram of the partner utility grid and the location of the installed $\mup$s. The installed $\mup$s sample the voltage and current with a rate of $512 \times 60$~Hz, and output the estimated phasors at 120 Hz rate. These devices achieve an accuracy of 0.001 deg resolution for phasor angle, 0.0002\% for phasor magnitude, and 0.01\% for Total Vector of Error (TVE) \cite{upmu_site}. The two feeders here are connected through the subtransmission grid. 
\begin{figure}[ht]
\centering 
\includegraphics[trim = 0mm 0mm 0mm 0mm,width=0.5\textwidth]{figures/rpu_two_feeder.pdf}
\caption{Location of Installed $\mup$s in Our Partner Utility Grid.}
\label{fig.rpu}
\end{figure}   

Fig.~\ref{fig.voltage_sag_05_jan} shows the voltage magnitude change rule inspected on the data from these $\mup$s over a certain time.  
\begin{figure}[ht]
\centering 
\includegraphics[width=0.5\textwidth,height=6 cm]{figures/voltage_sag_05_jan.pdf}
\caption{Voltage Magnitude Change Rule for Real Data.}
\label{fig.voltage_sag_05_jan}
\end{figure}
The results of the fast change inspection on the current magnitude of phase a and instantaneous local frequency at the substation bus of feeder 2 are also illustrated in Fig.~\ref{fig.freq_current_05_jan}(a) and Fig.~\ref{fig.freq_current_05_jan}(b), respectively. 
\begin{figure}[ht] 
\centering
    \includegraphics[width=0.5\textwidth,height=4 cm]{figures/freq_current.pdf}
    \caption{Fast Change Tracking of Current Phasor Magnitude and Bus Instantaneous Frequency Drift for Real Data.}
    \label{fig.freq_current_05_jan}
\end{figure} 
Observing the results of analysis, the DSO can deduce that the cause of the event is most probably located on feeder 2. Also, from the pre- and post-anomaly value of the current magnitude, the DSO can conclude that some of the loads on this feeder tripped due to the voltage sag. 
We just showed the results from some of the rules due to the space limit but other rules can also flag the existence of anomaly on feeder 2.

All the metrics introduced and tested above are designed considering the specifications of a distribution grid. It should be noted that not all the proposed methods in the literature for transmission grid are applicable in the distribution side. For example, the phase angle difference in the distribution grid is known to be much smaller than that in the transmission level. Therefore, as opposed to transmission grid that this metric would work well for event detection \cite{allen2014pmu}, it might not be a proper metric to look at in the distribution grid, since the signal to noise ratio might be small. The example next illustrates how the voltage angle difference metric could have failed if it was used as a ``local rule''. 
Using the data from two $\mup$s installed at two ends of a line at a second utility grid (not the one in Fig.~\ref{fig.rpu}), the voltage magnitude captured by the $\mup$ at one end of the line is shown in Fig.~\ref{fig.ang_diff}(a) and the voltage phasor angle difference between the two $\mup$s at two ends of the line is shown in Fig.~\ref{fig.ang_diff}(b). As it can be observed, the important event in this period corresponds to the two voltage sags. However, the angle difference shows a significant number of spikes without clearly marking these two events with the same significance. Passing this metric to our detector, we would pick too many fast changes that do not represent any specific event of interest, which therefore means an increase in the number of ``false positives''. All streams of interest were examined during this period, including both the active and reactive power, and all anomalies detected were in agreement with those visible in Fig.~\ref{fig.ang_diff}(a)

\begin{figure}[ht] 
\centering
\includegraphics[trim = 2mm 2mm 2mm 2mm,width=0.5\textwidth]{figures/lbl_ang_diff.pdf}\caption{Voltage Phasor Angle Difference Between Two $\mup$s at Distribution Grid.}
\label{fig.ang_diff}
\end{figure}  
\subsubsection{Case Study-Robustness Against Volatility}
The increasing presence of renewable resources, like wind and solar, in the distribution grid  may raise some concerns about the robustness of the proposed rules to ``false alarms'' due to their inherent volatility. However, our method is based on an adaptive estimation of the data mean using an exponential window and, as shown in the following numerical example, this makes the algorithm capable to only pick the fast changes over a very short period of time, while being insensitive to changes in the time order of normal renewable resources fluctuations. To show it numerically, we refer to two real events captured by $\mup$ 2 in the grid in Fig.\ref{fig.rpu}. Fig.~\ref{fig.active_power_PV}(a) shows a dramatic change of about -18.25\% over 9 seconds in the PV site active power injection due to the cloud effects, and Fig.~\ref{fig.active_power_PV}(b) shows a step change in the active power after the PV site went  out of service. Setting the detection parameters to be the same for both events, it can be seen that the detector flags no event for the first case and finds multiple of fast changes in the second. This is ideal since the events of our interest in the this context are of the second type, which should be discriminated from the normal quasi steady-state behavior in the first case.    
\begin{figure}[ht] 
\centering
    \includegraphics[width=0.5\textwidth,height=4 cm]{figures/active_power_PV.pdf}
	\caption{Fast Change Tracking of Injected Active Power in the PV Site.}
    \label{fig.active_power_PV}
\end{figure}

Considering the existence of different types of loads in the distribution grid, the detector should also be able to differentiate between possible normal fluctuations in the load profile and those that are caused by a rare event. To show the performance of CUSUM for this case, real data of a $\mup$ installed behind a building with a non-linear load is used. As it can be seen in Fig.~\ref{fig.current_bank514}, the fast change tracker of the current magnitude does not pick the fluctuations due to the non-linear load behavior as an event and only flags a segment of data that corresponds to a voltage sag in the grid as an eventful segment.
\begin{figure}[ht] 
\centering
    \includegraphics[width=0.5\textwidth,height=4 cm]{figures/cur_bank514.pdf}
	\caption{Fast Change Tracking of Current Magnitude for a Non-Linear Load.}
    \label{fig.current_bank514}
\end{figure}
%In this section, the effectiveness of the proposed criteria in detecting the anomalies is tested through real and simulated data, for the grid in Fig.~\ref{fig:test_case_comm}. The real data are provided from the $\mup$s that are installed in our partner utility medium voltage (12.47 KV) grid. In particular, the stage-1 rules are verified using real data. The results for the rule related to the change in impedance is still under investigation and will be added later. However, the central rule and the placement is only verified through simulations, since the line parameters of the utility grid were not accessible.
%\subsection{Real Data}
%The segment of data that we feed as an example to our detection rules contain a voltage sag event that happened in the utility grid. Fig.~\ref{fig:vol_sag} shows the detected voltage sag by checking the static rule on the voltage magnitude for phase a  (this sag was also detectable in the other phases).  
%\begin{figure}[h]
%\includegraphics[width=0.5\textwidth]{simulations/figures/voltage.pdf}
%\caption{Detected Voltage Sag in Phase a by Voltage Magnitude Rule}
%\label{fig:vol_sag}
%\end{figure}
%
%We should mention that, in this scenario, the feeder limit is not violated so the rule that imposes the constraint on the maximum current phasor magnitude is not indicating any anomaly.  
%
%Through the CUSUM algorithm, we can determine the start time and the end time of the event by simply assuming that changes that occur in a defined interval share the same cause, and therefore form an specific event. In the results shown in the following the red markers correspond to the samples within the event interval, i.e. all the samples between the start time and the end time computed through the CUSUM algorithm. Note that this does not necessarily mean that all of them are detected as a new mean change.
%  
%Fig.~\ref{fig:current} shows the inspected magnitude of the current phasor. As it can be observed, our fast change detector successfully tracked the anomaly in the data.
%\begin{figure}[h]
%\includegraphics[width=0.5\textwidth]{simulations/figures/current.pdf}
%\caption{Detected Current Swing in Phase a}
%\label{fig:current}
%\end{figure}
%
% The reactive power change detection, the result shown in Fig.~\ref{fig:reactive} also proves the success of our change detector in flagging anomalies. The active power tracking plot is similar to that of the current magnitude, and we do not report it for brevity.
%\begin{figure}[h]
%\includegraphics[width=0.5\textwidth]{simulations/figures/reactive.pdf}
%\caption{Detected reactive Power Swing in Phase a}
%\label{fig:reactive}
%\end{figure}
%
%As we can see in Fig.~\ref{fig:freq}, the estimated instantaneous frequency deviation from its nominal value also experiences fast changes during the voltage sag event, and therefore is flagged as a signature of an anomaly. It should be noted that the extracted frequency deviation does not necessarily reflect the exact frequency of the grid during the event but what matters for us is to capture the so called \textit{``abnormality''} in the data compared to the quasi-steady state.  
%\begin{figure}[h]
%\includegraphics[width=0.5\textwidth]{simulations/figures/frequency.pdf}
%\caption{Detected Over/Under Frequency Anomaly}
%\label{fig:freq}
%\end{figure}
%
%The steady-state stage-1 rules are also implemented and tested on the real data. The $\mup$s installed in our partner utility grid all are placed in pairs at the two ends of a line. Therefore, we first show the change detection of the optimum cost function defined in \eqref{eq:cost_two_upmu}, and then demonstrate that it would be possible to detect the changes with a single $\mup$ using \eqref{eq:cost_one_upmu}. The optimum cost functions in Fig.~\ref{fig:cost_two} and Fig.~\ref{fig:cost_one} that are computed with $M=32$ show that our steady-state stage-1 rule  is able to detect the anomaly as changes in the null subspace very effectively, even when there is only one $\mup$ installed.
%\begin{figure}[h]
%\includegraphics[width=0.5\textwidth]{simulations/figures/cost_two.pdf}
%\caption{Optimum Cost Function for Stage-1 Steady-State Rule Using Two $\mup$s}
%\label{fig:cost_two}
%\end{figure}
%\begin{figure}[h]
%\includegraphics[width=0.5\textwidth]{simulations/figures/cost_one.pdf}
%\caption{Optimum Cost Function for Stage-1 Steady-State Rule Using One $\mup$}
%\label{fig:cost_one}
%\end{figure}
%As it can be observed, Fig.~\ref{fig:cost_two} and Fig.~\ref{fig:cost_one} show the similar behavior and are approximately only different in scale. This in fact justifies that the approximation we made about the adjacent bus voltages, when we introduced the formulation for a single $\mup$ is good enough for spotting anomaly using only a single $\mup$.     
%
%It should be noted that since the value of the optimum cost function at time $k$ depends on the last $M$ phasor samples, the end time of the anomaly that is found using this rule is roughly $M$ samples ahead of the actual end time.    
%\subsection{Simulated Data}      
%For the grid in Fig.~\ref{fig:test_case_comm}, we first implement our $\mup$ placement algorithm in order to determine the optimal locations for our $\mup$s. We assume that the number of available $\mup$s is $K=4$. The solution of this optimization is obtained through an exhaustive search and a greedy search algorithm. The exhaustive search has an exponential complexity, that will be problematic for large cases. However, the greedy search reduces the complexity to \textit{polylog} but does not provide the global optimum solution, as illustrated in our example. In fact, the placement results of the two algorithms are as follows:
%\begin{align*}
%\begin{split}
%\text{\textit{Exhaustive Search}} \rightarrow \{1,6,8,11\} \\
%\text{\textit{Greedy Search}} \rightarrow \{1,3,7,10\} 
%\end{split}
%\end{align*}           
%As it can be noted from the results of the \textit{Exhaustive Search} algorithm, the solution set places two $\mup$s at each of the two feeders that are normally isolated from each other. This is expected, since the solution seeks to cover both feeders and the feeders are pretty comparable in size and structure. Furthermore, the two $\mup$s at each feeder are placed so that one of them is near the substation and the other one is at the leaf of the grid. This also can be justified because the placement tries to cover the grid as much as possible, when the observability is lacking. 
%
%For the \textit{Greedy Search}, it is true that the solution is not the global solution but as we can see, the selected buses through the \textit{Greedy Search} either exist in the global solution or they are adjacent/close to the buses in the global solution, which indicates that \textit{Greedy Search} is near optimum.
%
%            
%In order to validate the ability of the central GSS server rule in spotting the transient, the grid in Fig.~\ref{fig:test_case_comm} is first simulated in time-domain using DigSILENT software. A temporary single phase to ground short circuit (that is very common in the distribution grid) is introduced at $t=0.3 s$ and 50\% of line $(5,6)$ on phase-b that is cleared after 6 cycles before the protection gets activated. Fig.~\ref{fig:short_voltage_wave} and Fig.~\ref{fig:short_current_wave} show the behavior of the voltage and current waveforms at bus 1-phase b during the fault, respectively.   
%\begin{figure}[h]
%\includegraphics[width=0.5\textwidth]{simulations/figures/short_voltage_wave.pdf}
%\caption{Voltage Waveform of Bus 1-Phase b During the Fault}
%\label{fig:short_voltage_wave}
%\end{figure}
%\begin{figure}[h]
%\includegraphics[width=0.5\textwidth]{simulations/figures/short_current_wave.pdf}
%\caption{Voltage Waveform of Bus 1-Phase b During the Fault}
%\label{fig:short_current_wave}
%\end{figure}
%Note that often in the literature and in simulation software an FFT is applied to time domain data to emulate the extraction of the $\mup$/PMU phasor. Especially, when the grid is not at steady-state, this is a poor approximation of an actual $\mup$ output. Therefore, we implemented the exact algorithm of the complex envelope derivation in $\mup$ using as filter $h(t)$ the so called P-class filter in the C37.118 \cite{c37}, not having access to the proprietary filter used by the $\mup$ vendor, PSL. The time-domain data obtained from the simulation are processed with our phasor estimation algorithm and the results are used as the input of our IDS rules. In Fig.~\ref{fig:cost_global}, we show the normalized\footnote{The normalization is done over the average value of $x[k]$ in a window of time during steady-state} optimum cost function in \eqref{xopt} used for detecting the anomalies at the \textit{stage-i, $i>1$}. The figure proves our idea that the optimally-placed $\mup$s can spot effectively the transient at the global level from the change in $x[k]$. 
%\begin{figure}[ht]
%\includegraphics[width=0.5\textwidth]{simulations/figures/cost_global.pdf}
%\caption{Normalized Optimum Cost Function for Stage-i $i > 1$ Steady-State Rule}
%\label{fig:cost_global}
%\end{figure}  
%It should be noted that since the phasor is estimated at the center of a two-cycle window of data, the effect of the short circuit manifests itself a few samples before $t=0.3 s$ and disappears a few samples after $t=0.4 s$.   
    
\section{Conclusion and Future Direction}
In this paper, a hierarchical \textit{``anomaly detection architecture''} has been described that integrates high resolution, synchronous $\mup$ data to attain high accuracy in the detection of the physical effects of an event. 
A set of rules has been formulated to process the $\mup$s' data at the local and central level of our hierarchical architecture. Exiting from the quasi steady-state regime is a common signature of many anomalies, and this insight is exploited to design a key part of the proposed metrics. To ensure scalability of our architecture, the rules at the local stage are designed to be agnostic about the grid interconnection and physical location of the sensor. Depending on the type of event, the effects on different metrics has different severity and, therefore, inspecting different metrics at the local level reduces the miss-detection rate. The analysis in the higher stages is designed to bind the readings from different $\mup$s using the knowledge about the grid topology and sensor locations in search for eventful segments.    

Using real data and simulations, we have shown how processing real-time physical measurements from $\mup$s enables us to detect effectively anomalies in the system and inform the operator about the grid status. 
Having a limited number of $\mup$s, an optimal placement criterion is also designed with respect to the central rule that aims to scatter $\mup$s over the grid to achieve maximum coverage and therefore to increase the sensitivity of the rule to different event source locations.

Having an anomaly identified, our future efforts will focus on identifying and localizing the source of the anomaly using the underlying physical model when possible or, in general, at least confine the search region to a smaller set of components/lines. This include the identification of any change in the admittance matrix, due to loss of a line, reconfiguration of the grid, and etc.    
% In this paper, we have described the GSS architecture to analyze anomalies occurring in a distribution grid.  The GSS architecture integrates high resolution, synchronous $\mup$s measurements to attain high accuracy in the detection of the physical effects of a cyber attack. We then described a set of rules to process the $\mup$s data that leverage knowledge about the distribution system topology, electrical parameters and operations, and demonstrated with real data and simulations how processing real-time physical measurements from $\mup$s enables us to detect effectively anomalies in the system. The scalability of the GSS architecture is addressed by defining the rules hierarchically, so that the topology information and reliance of the detection rule on other sensors measurements decreases as we move downward in the GSS aggregation tree until stage-1, where the rules are agnostic with respect to the environment and all other sensors traces. The policies are set up based on the knowledge about the governing grid equations that define what can be considered as \textit{``normal''} by the power quality community. An optimal $\mup$ placement is also described, to achieve the maximum sensitivity with respect to our criteria, with limited number of $\mup$s.    

%\section*{Acknowledgments}
% 
%This research was supported in part by the Director, Office of Electricity Delivery and Energy Reliability, Cybersecurity for Energy Delivery Systems program, of the U.S. Department of Energy, under contracts DE-AC02-05CH11231 and DEOE0000780. Any opinions, and findings expressed in this material are those of the authors and do not necessarily reflect those of the sponsors.
\bibliography{bib}
\vspace{-0.1cm}
\bibliographystyle{IEEEtran}
%\footnotesize
\end{document}

%\textbf{- Estimated Line Parameter Change (Dynamic Rule):}
%We can use the $\mup$ measurements for on-line estimation of the distribution line parameters during the quasi-steady state using the governing equations in this regime. Therefore, the estimated line parameters variations will be only due to the frequency drift $\beta_k$ as long as the grid is in the quasi-steady state. However, if a transient happens, the estimated parameters would experience sudden changes that in turn signifies the violation of the normal operation regime since the equations are no longer valid.
%
%For simplicity, we first assume that two $\mup$s are installed at both ends of a transposed line with negligible shunt admittance. Although we did not make any assumption about the shunt admittance in the other sections, it is known that this parameter is relatively small in the distribution grid compared to the transmission \cite{kersting2012distribution}. Under these assumptions:
%\begin{align}
%\mb{H}_{ij}(f_0,\beta_k)=\begin{pmatrix}
%{\bs Y}_{ij}(f_0,\beta_k)&-{\bs Y}_{ij}(f_0,\beta_k)\\
%-{\bs Y}_{ij}(f_0,\beta_k)&{\bs Y}_{ij}(f_0,\beta_k)
%\end{pmatrix}
%\label{eq:simple_H}
%\end{align}
%in which ${\bs Y}_{ij}(f_0,\beta_k)$ has the following form:        
% \begin{equation*}
%{\bs Y}_{ij}(f_0,\beta_k)=\begin{pmatrix}
%      {Y}^s_{ij}(f_0,\beta_k)&{Y}^m_{ij}(f_0,\beta_k) & {Y}^m_{ij}(f_0,\beta_k) \\
%      & {Y}^s_{ij}(f_0,\beta_k) & {Y}^m_{ij}(f_0,\beta_k) \\
%      \multicolumn{2}{c}{\text{Sym.}} & {Y}^s_{ij}(f_0,\beta_k) 
%    \end{pmatrix}
%  \end{equation*}
%where ${Y}^s_{ij}(f_0,\beta_k)$ is the self admittance of the line and ${Y}^m_{ij}(f_0,\beta_k)$ denotes the mutual admittance. From \eqref{eq.homog} and also knowing that $\bs{R}_k$ is close to be a rank 1 matrix, one can conclude that:
%\begin{align}
%\left( \begin{array}{c:c}
%\mathcal{I}_6 &-\mb{H}_{ij}(f_0,\beta_k)
%\end{array}\right)\bs{u}_1[k]=\mb 0
%\label{eq:null_two}
%\end{align}     
%We can rearrange the terms in \eqref{eq:null_two} as follows:
%\begin{align}
%\bs{u}_{1,t}[k]=\mb{H}_{ij}(f_0,\beta_k)\bs{u}_{1,b}[k]
%\label{eq:two_est1}
%\end{align}
%where $\bs{u}_{1,t}[k]$ and $\bs{u}_{1,b}[k]$ denotes the top and bottom 6 rows of $\bs{u}_{1}[k]$, respectively. From the structure of $\mb{H}_{ij}(f_0,\beta_k)$ in \eqref{eq:simple_H}, we can write\footnote{$\otimes$ stands for Kronecker product.}$^{,}$\footnote{$\mb{1}_{n \times m}$ is a matrix with size $n \times m$ and entries 1.}:
%\begin{align}
%\mb{H}_{ij}=(2\mathcal{I}_2-\mb{1}_{2\times 2})\otimes({Y}^s_{ij}\mathcal{I}_3+{Y}^m_{ij}(\mb{1}_{3\times 3}-\mathcal{I}_3))
%\label{eq:two_est_H}
%\end{align}    
%where the argument $(f_0,\beta_k)$ is removed for simplicity. From \eqref{eq:two_est1} and \eqref{eq:two_est_H}, and using the Kronecker product properties, we can rearrange \eqref{eq:two_est1} in the following form:
%\begin{align}
%\bs{u}_{1,t}[k]=\big(\mb{B}\bs{u}_{1,b}[k]~~\mb{C}\bs{u}_{1,b}[k]\big)\begin{pmatrix}
%{Y}^s_{ij}(f_0,\beta_k)\\{Y}^m_{ij}(f_0,\beta_k)
%\end{pmatrix}
%\end{align} 
%where $\mb{B}$ and $\mb{C}$ are defined as:
%\begin{align*}
%\mb{B}&=2\mathcal{I}_6-(\mb{1}_{2\times 2}\otimes \mathcal{I}_3)\\
%\mb{C}&=2(\mathcal{I}_2 \otimes \mb{1}_{3\times 3})-2\mathcal{I}_6-\mb{1}_{6\times 6}+(\mb{1}_{2\times 2}\otimes \mathcal{I}_3)
%\end{align*}   
%The parameters are identifiable without ambiguity if the matrix $(\mb{B}\bs{u}_{1,b}[k]~~\mb{C}\bs{u}_{1,b}[k])$ is of full column rank that is the case here. Therefore, an estimation of the parameters can be obtained from:
%\begin{align}
%\begin{pmatrix}
%\hat{Y}^s_{ij}(f_0,\beta_k)\\ \hat{Y}^m_{ij}(f_0,\beta_k)
%\end{pmatrix}=\big(\mb{B}\bs{u}_{1,b}[k]~~\mb{C}\bs{u}_{1,b}[k]\big)^{\dagger}\bs{u}_{1,t}[k]
%\end{align}
%where $(.)^\dagger$ denotes the pseudo-inverse operator. The fast change inspection can now be performed on the real and imaginary part of the estimated parameters defined here as $x[k]$:
%\begin{align}
%x[k]=\Re / \Im \{\hat{Y}^s_{ij}(f_0,\beta_k)\} \text{ or } \Re / \Im \{\hat{Y}^m_{ij}(f_0,\beta_k)\}
%\end{align} 
%
%Therefore, we are not only estimating the line parameters on-line that counts in the modulation due to the frequency drift but also providing a criteria that can be inspected to spot anomalies.   
%
%In the next step, we wish to extend the formulation to the untransposed lines and to the case where only one $\mup$ is available on a line. This task is still under investigation and is not provided in this document.
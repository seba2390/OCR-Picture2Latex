\section{Introduction}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{imgs/ad_fig.pdf}
    \caption{
        \textbf{The illustration of biased scene graph generation and empirical study on Visual Genome.} As shown in (D), the baseline (MSDN~\cite{li_scene_2017}) performance is dominated by the head categories due to the imbalanced data. We estimate an upper-bound performance by ignoring negative predicate-entity connections during message propagation, as shown in (B). Its performance (shown in (D)) indicates a large room for improvement in context modeling.
    }
    \label{fig:ad}
\end{figure}

% intro 的提纲 见 imgs/intro_outline.jpg


%Introduce task, background
%Motivated by the success of structured representations in natural language processing [2, 34, 37], computer vision has started to adopt scene graphs to im- prove performance and explainability, in

Scene graph generation, which aims to detect visual objects and their relationships (or \textit{triplets: <subject, predicate, object>}) in an image, is a fundamental visual understanding task. Such a compact structural scene representation has potential applications in many vision tasks such as visual question answering~\cite{teney2017graph, shi2019explainable, hildebrandt2020scene}, image captioning~\cite{yang2019auto} and image retrieval~\cite{johnson2015image}. 
%It has attracted much attention recently due to the potential applications in
Tremendous progress has been made recently in scene graph generation~\cite{krishna2017visual, xu_scene_2017, li_scene_2017, zellers_neural_2017, yang_graph_2018, li_factorizable_2018, tang_learning_2018,chen_knowledge-embedded_2019, gu2019scene, zhang_graphical_2019, tang_unbiased_2020, lin_gps-net_2020, wang_sketching_2020}, thanks to learned visual representations and advances in object detection.  
%Thanks to learned feature representations based on convolutional neural networks and significant success on object detection, there has been tremendous progress in scene graph generation recently. 
% Most existing approaches adopt a hypothesize-and-classify framework, in which the objects(also called \textit{entity}) are first detected, then the pair-wise predicate proposals are constructed, followed by a classification head to output the structural representation of the scene. 
However, this task remains particularly challenging due to large variations in visual relationships, extremely imbalanced object and relation distribution and lack of sufficient annotations for many categories.  

One primary challenge, which causes \textit{biased relationship prediction}, is the intrinsic long-tail data distribution. A scene graph model has to simultaneously cope with imbalanced annotations among the head and medium-sized categories, and few-shot learning in the tail categories. A naively learned model will be largely dominated by those few head categories with much degraded performance for many tail categories (as shown in Fig.~\ref{fig:ad}-D). Early work~\cite{cao_learning_2019,cui_class-balanced_2019} on re-balancing data distribution focus on data re-sampling or loss re-weighting. However, it is non-trivial to directly apply the image-level re-balancing strategies for such instance-level tasks. Recent efforts try to introduce the re-balancing ideas into object detection~\cite{gupta_lvis:_2019,tan_equalization_2020} and scene graph generation~\cite{tang_unbiased_2020}, but it remains difficult to achieve a satisfactory trade-off between head and tail categories.

% (illustrated in bar plots of Fig \ref{fig:ad} ).
% In such a scenario,  because of 

% However, for large-scale vision recognition tasks, partially due to the non-uniform distribution of natural object classes and varying annotation costs, we typically learn from datasets with a \textit{long-tail} class label distribution. In such scenarios, the number of training instances per class varies significantly, from as few as one for tail classes to hundreds or thousands for head classes~\cite{zhou2017places, liu2019large, gupta2019lvis, zhu2014capturing, zhou2017scene,van2018inaturalist}.  


 
Moreover, those non-head predicate categories typically involve complex semantic meaning and large intra-class variations (\textit{e.g.} play, look) in images, which exacerbates the problems in their representation learning and classification. Many previous works~\cite{zellers_neural_2017, xu_scene_2017, li_scene_2017, tang_learning_2018,yang_graph_2018,lin_gps-net_2020} attempt to address this problem by developing context modeling mechanisms, but often suffer from noisy information propagation due to their use of fully connected graphs. 
More recent efforts~\cite{qi_attentive_2018,yang_graph_2018,tang_learning_2018,wang_sketching_2020} aim to improve context modeling by designing a sparse structure, which also limits the model flexibility. To illustrate the impact of noises in graph, we further conduct an empirical analysis, as shown in Fig.\ref{fig:ad}, which indicates that \textit{a baseline model can achieve notable performance improvement by removing the noisy subject-object associations}.


%to verify The empirical bound significantly outperform the baseline with \textit{a large margin}, especially on the body and tail classes, which indicates \textit{severe noise induced by the subject-object associations seems to be the performance bottleneck of the existing methods}.


%In this work, we first perform the ablative analysis on current scene graph generation method to shed the light on its performance bottleneck in Fig.\ref{fig:ad}.
% Secondly, the tail categories, which typically has more complicated semantic meaning and larger intra-class variations(\textit{e.g}. play, look), are more sensitive to the noise in the context modeling. Thus we investigate whether this issue is restrictive for the unbiased scene graph generation. 

%We adopt MSDN~\cite{li_scene_2017}, in which the message propagation is conducted between the entity and predicate, for empirical bound analysis. The experiments is conducted on Stanford split~\cite{xu_scene_2017} of Visual Genome~\cite{krishna2017visual}.
%, in which the message propagation is conducted between the entity proposals and predicate proposals. 
%For \textit{empirical context modeling upper-bound}, the message passing from negative predicate proposal to entity proposal will be ignored in our experiment, based on the true label of each predicate proposal, which reduces the noise in the message propagation.
% The empirical bound significantly outperform the baseline with \textit{a large margin}, especially on the body and tail classes, which indicates \textit{severe noise induced by the subject-object associations seems to be the performance bottleneck of the existing methods}.
% Consequently, a better strategy to address this problem would further improve the feature representation learning for unbiased scene graph generation.



%For the context modeling perspective, the previous methods proposed a graph based neural network with the fully connected structure\cite{li_scene_2017, li_factorizable_2018, dai_drnet_2017, xu_scene_2017, woo_linknet:_2018, wang_exploring_2019, lin_gps-net_2020} or other structure with strong constraint(e.g. linear\cite{zellers_neural_2017}, sparse-graph\cite{yang_graph_2018, qi_attentive_2018}, tree\cite{tang_learning_2018}). 
%The fully connected graph structure brings a lot of negative samples/noise for context modeling, due to the sparsity of correlation in the scene graph. 
%To this issue, the directed method is to design a policy to produce a new topology from an initial fully connected scene graph for context modeling\cite{zellers_neural_2017, yang_graph_2018, tang_learning_2018, qi_attentive_2018}.
%The\cite{tang_learning_2018} uses the downstream VQA tasks as additional information to estimate the adjacency for constructing the tree structure, the \cite{qi_attentive_2018,yang_graph_2018} use the geometry or classification prediction for estimating adjacency between the entities.
%However, those previous methods involve too strong assumptions, which limit the flexibility of encoding the context information of scene graph. 
%
% however due to the uncertainty and ambiguity of visual relationship, there are some positive visual relationship are pruned, which lead to performance drop.


% noise in the context modeling. Thus we investigate whether this issue is restrictive for the unbiased scene graph generation. 
 
 
% To address this issue and to improve performance across all classes, one can re-sample the data or design specific loss functions that better facilitate learning with imbalanced data (Chawla
 
% any other tail classes. Early work on re-balancing data distribution focuses on learning one-stage models, which achieve limited successes due to lack of principled design in their strategies [2, 35, 3, 9, 26, 43]. More recent efforts aims to improve the long-tail prediction by decoupling the representation learning and classi er learning [18, 28, 37, 40, 22]. H ow ever, such a two-stage strategy typically rely on heuristic design to adjust the decision boundary of initially learned classiers, which often requires tedious hyper-param eter tuning in practice. T his severely lim its its capacity to resolve the m ism atch between imbalanced training data distribution and balanced evaluation metrics

% Our focus is to address the challenge of intrinsic long-tail distribution of visual relations in a typical scene parsing dataset and large intra-class variation of the predicate categories. To this end, we introduce a novel unbiased scene graph generation approach that simultaneously learns a robust context-aware predicate representation and a more balanced predicate classifier via an efficient two-level data resampling strategy.
 

% 新的广告图 开发中 文字中还需要增加一些说明才行
% \begin{figure}
%     \centering
%     \includegraphics[width=\linewidth]{imgs/ad_fig.pdf}
%     \caption{The data frequency of Visual Genome training set and the per-class performance of baseline with/ without the upper bound assumption for the most frequent 40 predicates.}
%     \label{fig:ad}
% \end{figure}

%These methods\cite{zellers_neural_2017, xu_scene_2017, li_scene_2017, tang_learning_2018,yang_graph_2018,lin_gps-net_2020} typically introduce various context modeling strategy to improve the feature representation for entities and relation proposals, however, which rarely explore issue of performance decline phenomena on tail classes.


%In this work, we first perform the ablative analysis on current scene graph generation method to shed the light on its performance bottleneck in Fig.\ref{fig:ad}.
% Secondly, the tail categories, which typically has more complicated semantic meaning and larger intra-class variations(\textit{e.g}. play, look), are more sensitive to the noise in the context modeling. Thus we investigate whether this issue is restrictive for the unbiased scene graph generation. 

%We adopt MSDN~\cite{li_scene_2017}, in which the message propagation is conducted between the entity and predicate, for empirical bound analysis. The experiments is conducted on Stanford split~\cite{xu_scene_2017} of Visual Genome~\cite{krishna2017visual}.
%, in which the message propagation is conducted between the entity proposals and predicate proposals. 
%For \textit{empirical context modeling upper-bound}, the message passing from negative predicate proposal to entity proposal will be ignored in our experiment, based on the true label of each predicate proposal, which reduces the noise in the message propagation.

% Move to caption
% The empirical bound significantly outperform the baseline with \textit{a large margin}, especially on the body and tail classes, which indicates \textit{severe noise induced by the subject-object associations seems to be the performance bottleneck of the existing methods}.
% Consequently, a better strategy to address this problem would further improve the feature representation learning for unbiased scene graph generation.



Based on these findings, we propose a novel confidence-aware graph representation and its learning strategy for unbiased scene graph generation. To this end, we first develop a bipartite graph neural network (BGNN) with the adaptive message propagation for effective context modeling. 
Specifically, our method takes the hypothesize-and-classify strategy, which first generates a set of visual entity and predicate proposals from a proposal generation network. Then we compute a context-aware representation for those proposals by passing them through a multi-stage BGNN. 
Our graph network adopts directed edges to model different information flow between entity and relationship proposals as a bipartite graph, and an adaptive message propagation strategy based on relation confidence estimation to reduce the noise in the context modeling. Finally, we use the refined entity and predicate representations to predict their categories with linear classifiers. 

To train our multi-stage BGNN for unbiased prediction, we also design a bi-level data resampling strategy to alleviate the imbalanced data distribution problem. Our method combines the image-level over-sampling and instance-level under-sampling ideas~\cite{hu_learning_2020,gupta_lvis:_2019} for the structured prediction task. Equipped with this strategy, we can achieve a better trade-off between the head and tail categories and learn our bipartite graph neural network more effectively.

%we develop to explicitly incorporate the relationship prior to the message propagation process in an adaptive manner, reducing the error propagation and achieving effective context modeling. 


% It is non-trivial to apply a naive re-balancing strategy for scene graph generation task.
%Previous works try either the instance-level replay strategy~\cite{hu_learning_2020} or images-level resampling method~LVIS\cite{gupta_lvis:_2019} for object detection, however, which is sub-optimal for the scene graph generation due to the entity-pair association. 
%Inspired by recent data resampling methods, we further propose a 


We extensively validate our methods on three scene graph generation datasets, including Visual Genome, Open Images V4, and Open Images V6. 
The empirical results and ablative studies show our method consistently achieves competitive or state-of-the-art performance on all benchmarks. The main contributions of our works are three-folds.
\begin{itemize}[noitemsep,topsep=0pt]
	\item We introduce a bipartite graph neural network with adaptive message propagation to alleviate the error propagation and achieve effective context modeling.
	\item We propose a bi-level data resampling to achieve a better trade-off between head and tail categories for scene graph generation.
    \item Our method achieves competitive or state-of-the-art performance on various scene graph benchmarks.
%	\item Based on this graph structure, to handle with sparsity of scene graph, we proposed a novel adaptive message passing mechanism which explicitly estimating the relationship confidence between entities.
%	\item We proposed a new instance based resampling strategy that can provides a better balanced instances distribution for improving the performance of ou model on long-tailed scene graph generation.
%	\item The method is test by extensive experiments on Visual Genome and OpenImage dataset. Results shows that our method obtain a new SOTA on Visual Genome with the balanced metric and comparable performance on biased classic metric; The result on OpenImage Dataset shows our method obtain a comparable performance on OpenImage V4, and new SOTA on OpenImage V6 dataset.
\end{itemize}



%, for \textit{unbiased scene graph generation}. 

%which typically has  especially accounts for the performance degrade on the tail classes, which typi
%Nevertheless, it's non-trivial to apply a naive re-balancing strategy for such an instance-level tasks. 

%large intra-class variations during 

% for the severely imbalanced data distribution and large intra-class variations\cite{}. 

% which, despite recent successes of deep leaning, remains a challenging task for 
%
%The things do not exist independently in the real world, there are many interaction relationships between them. 
%The objects and their relationships of images can be represented by multiple triplets "subject, predicate, object", or let the instances(entities) as nodes, predicates as the edges, we can represent this set of relationships as a graph structure, which called Scene Graph\cite{scene_graph}. 
%Extract such structured high-level visual information from images, a.k.a Scene Graph Generation has gained more and more attention these years. 
%The scene graph can be strong and explicit support as mid-level information that bridging between the low-level visual elements to high-level visual understanding tasks, such as VQA, image caption, and image retrieval. 

%Current methods and issues

% longtail
%However, this task still remains challenging.
%The primary issue is the current methods archive a relatively poor performance for the relationships with limited training samples. Specifically, the current methods have poor performance on lower frequency categories and can't provide comprehensive representations for the scene.

%As refer in \cite{chen_knowledge-embedded_2019, tang_unbiased_2020}, 
%this issue has been the critical performance bottleneck for current scene graph generation methods.
%The reason that the current methods have this severe imbalance performance is the visual relationships are naturally long-tailed.
% For example, the geometry-based relationships(e.g. on, near) or strong semantic constrained relationships(e.g. person wear clothes), are more frequent than relationship categories which are complicated semantic (e.g. play, look). 
% Due to the strong imbalanced training data, the prediction of models is dominated by those high-frequency categories, and have a low performance for those low-frequency categories.
%  visual feature variance
%The high variance visual pattern of visual relationships is also aggravate this issue.
%The visual relationships are a combination of entities and predicates, which means there is another degree of compositional complexity for visual relationships as refer in \cite{lu_visual_2016, zellers_neural_2017}.
% For example, the predicate categories "carry", we could have two valid relationships "$\langle person,~carry,~bag \rangle$", "$\langle truck,~carry,~box \rangle$", but their visual pattern is totally different.  
%Furthermore, this challenge is coupled with the longtail distribution, the model needs to have an effective representative ability to obtain a sufficient generalized discriminative ability for recognition with fewer data points.

% along the issues, the insight they proposed previously and their limitation

% what they do

% longtail: 
    % issue: strong data imbalance lead to bisaed representation and decision boundary 
    % insight: adjust the biased representation/ parameters
        % more effective context modeling method generalize from few data. transfer knowledge from the frequent data to rare data.
        % adjust the feature by causality, obtain unbiased features
            %limitation: hurt performance on head categories

% visual appearance variation
    % utilize the context information: semantic constraints from the "neighborhood" objects and predicates, 
        % reason about the hard to recognized relationship/entities according to the context pattern of the confident neighborhood relationship(entities/predicates)
        % apply GNN on graph that built by the relationship proposals (entities proposals, predicate proposals)
            % topology: Linear, fully connected graph, reduced graph structure.
            % Node edges definition: entities to entities, entities to predicates 
            % different aggregation: LSTM aGCN, Gated GNN, Transformer
    % limitation:
        % large amount of negative connection in graph topology, which introduce massive noise, not explicitly indicate how the message passing, ineffective
        % naive edge pruning strategy cost performance, suboptimal Graph-RCNN. 



% how the current methods addressed those issues and their limitation.

%longtail
%The long-tailed distribution is a general issue in many machine learning-based classification tasks, which has been studied for a long time.
%The typical methods are intervening in the optimization process of training by resampling  \cite{chawla_smote_2002, mahajan_exploring_2018, hu_learning_2020,gupta_lvis:_2019}/re-weighting \cite{cao_learning_2019, cui_class-balanced_2019, khan_cost_2017, tan_equalization_2020}, or transfer the knowledge from the head to tail categories\cite{gidaris_dynamic_2018, hu_learning_2020,liu_largescale_2019}.
%However, those methods can not trivially apply to the scene graph, since there are many differences between scene graph generation and general image recognition.
%The causal inference based method\cite{tang_unbiased_2020} also provides a good solution, however it cost the performance on head categories.

% The typical approaches are: 
% (1)provide a more unbiased training supervision signal by recalibrating the biased loss during the training, or adjusting the imbalanced data distribution by resampling strategies;
% (2)adjust the prediction scores to canceling the biased prior distribution which introduced by imbalance datasets.
% Those methods can find a better trade-off on the performance of the high and low frequent categories. 
% The recalibrating methods are needed for adjustment for different datasets according to its distribution, otherwise, there will be a performance cost on frequent categories that will be large.
% The more effective features representation is necessary for achieve a better generalization ability for recognizing the on low frequency categories.


% The main difference between the visual relationships and general recognition task is, t
%The visual relationships has higher visual patterns variation than general recognition task, it brings more challenging to learn a good visual representation, especially for those low-frequency categories. 
%To tackle this challenge, the one of effective method is to encode the context of scene graph by utilizing the promising semantic correlations/constraint between entities and predicates, which first proposed by \cite{zellers_neural_2017,xu_scene_2017}.
% To tackle is challenge, the visual context is a powerful tool. The visual relationships have a promising semantic correlations/constraint between the entities and predicates of relationship in both statistical level and concept level \cite{zellers_neural_2017}.
% Therefore, a better feature representation for visual relationships is can be obtained by effectively encode the context information of scene graph.

%Due to most of previous work are focus on the biased classic evaluation metric(Recall@K), the longtail recognition issue in scene graph are just been attended recently by \cite{tang_learning_2018, chen_knowledge-embedded_2019,lin_gps-net_2020, tang_unbiased_2020}.
%For the context modeling perspective, the previous methods proposed a graph based neural network with the fully connected structure\cite{li_scene_2017, li_factorizable_2018, dai_drnet_2017, xu_scene_2017, woo_linknet:_2018, wang_exploring_2019, lin_gps-net_2020} or other structure with strong constraint(e.g. linear\cite{zellers_neural_2017}, sparse-graph\cite{yang_graph_2018, qi_attentive_2018}, tree\cite{tang_learning_2018}). 
%The fully connected graph structure brings a lot of negative samples/noise for context modeling, due to the sparsity of correlation in the scene graph. 
%To this issue, the directed method is to design a policy to produce a new topology from an initial fully connected scene graph for context modeling\cite{zellers_neural_2017, yang_graph_2018, tang_learning_2018, qi_attentive_2018}.
%The\cite{tang_learning_2018} uses the downstream VQA tasks as additional information to estimate the adjacency for constructing the tree structure, the \cite{qi_attentive_2018,yang_graph_2018} use the geometry or classification prediction for estimating adjacency between the entities.
%However, those previous methods involve too strong assumptions, which limit the flexibility of encoding the context information of scene graph. 

% however due to the uncertainty and ambiguity of visual relationship, there are some positive visual relationship are pruned, which lead to performance drop.



% should in related work, right?
% The generic pipeline of those methods is building a proposal scene graph by densely connect the objects, and apply the message passing process on this graph by different topology(linear\cite{zellers_neural_2017}, fully connected graph\cite{li_scene_2017, dai_drnet_2017, xu_scene_2017, woo_linknet:_2018, wang_exploring_2019, lin_gps-net_2020}, tree structure\cite{tang_learning_2018}) for encoding the context with the graph representation. 
% %limitation: ineffective context modeling due to the sparsity of scene graph
% However, existing methods has limitation for encoding the context.
% For the linear based model, such a linear or tree structure topology could have a too strong constraints that trim the many neighborhood connection, limit the flexibility of model to encode the context information.
% For the fully connected graph, due to the sparsity of the visual relationship, the most of pairs doesn't represent any valid relationship.
% During the message passing process for encoding the context, there could have much noises introduced into the system, which makes this graph representation task more difficult.
% % naively pruning, hurt performance
% For the handle the sparsity of scene graph, the previous methods\cite{yang_graph_2018}\cite{liao_explore_2019} are also proposed an RPN liked module that directly prune the relationship proposals for a more sparse scene graph topology, however, this hard edge pruning can hurt the performance.
% The proper graph structure that both meet the sparsity and flexibility for encoding the context of scene graph is needed 
 
% what we do,
    % more effective context modeling model
        % dynamic relationship confidence aware biparted graph network 
    % instance based resampling strategy
    % from challenge to insight
        % assumption: the neighbor context is represent by the neighbor that do have visual relationship 
        % proposed a new GNN mechanism for SGG, that utilize the relationship confidence of relationship proposals as proxy to dynamically build the graph topology for aggregating the context information.
    % Specifically
        % biparted graph for aggregate the context information between the entities and predicates.
        % explicitly relationship confidence aware for graph topology refinements for context aggregation
        % iterative dynamic refinement 
    % instance based re-sampling strategy
    

%Our main idea
% relatedness awareness graph
%To this end, instead of change the topology of scene, we proposed a adaptive message passing mechanism and formulate the context modeling process by bipartite graph.
%  which utilizes the relationship confidence between the entities as a additional gating mechanism to control the information flow of message passing on the bipartite graph.
%Specifically, the model we proposed is composed of three-part:
%First, we formulating the context modeling structure as a bipartite graph neural network that takes the representation of proposal entities and proposal predicates as two nodes set, and apply the multi-hop message passing between the two node sets. 
%Second, upon this graph structure, we design an adaptive message passing mechanism to handle the sparsity of semantic correlations in scene graph. 
%Specifically, we first estimate the relationship confidence of entities pairs for for perceiving the sparsity of scene graph.
%the relationship confidence is used by a novel gating function proposed by us for adaptive ly controlling the topology of message passing.
%In this way, we can obtain a sparse and higher quality information flow for feature aggregation.
% With the more clean information flow for message passing, the difficulty of GNN representation learning can be reduced in training time and the context modeling could be more effective in inference time.
%Furthermore, we proposed an iterative refinement process between relationship estimation and graph message passing, the system can gradually refine the relationship confidence estimation and for better context modeling. 
% which can provide more effective context modeling.
% With the more effective context modeling, our method obtains more  and generalization on the modeling context of low-frequency categories, which obtains the more balanced performance on whole categories set. 

% instance based resampling
%We design a instance based resampling strategy for directly tackle the severe imbalance in scene graph generation. 
%The traditional resampling methods \cite{chawla_smote_2002, gupta_lvis:_2019} are image based.
% The most widely used LVIS resampling strategy is to maintain a repeat factor for the whole dataset to control the repeat times of each image according to the lowest frequency categories within the images.
%Since the head categories has larger prior probability occur in image.
%% However, the high-frequency categories are more likely to be co-occurrence with low-frequency categories instances even they have no correlations. 
%The image-level repeating increases the instance number of high-frequency categories, which lead the instance distribution after resampling is still biased.
%To address this issue, we inspire the by the instance replay in continue learning\cite{hu_learning_2020}, we proposed a new resampling strategy composed by image-level over-sampling and instance level under-sampling.
% We extend the LVIS resampling by design an instance-based sampling strategy.
% Specifically, we proposed a sampling strategy with the instance drop policy, during the image repeating process, we dynamically drop the instance according to its categories frequency.
%In this way, we can obtain a more balanced categories frequency distribution after sampling.


%Conclusion
%Concretely, our contribution are composed by 3 folds. 
%\begin{itemize}
%	\item We reformulate the context modeling structure for scene graph generation between entities and previous by bipartite structure graph neural network.
%	\item Based on this graph structure, to handle with sparsity of scene graph, we proposed a novel adaptive message passing mechanism which explicitly estimating the relationship confidence between entities.
%	\item We proposed a new instance based resampling strategy that can provides a better balanced instances distribution for improving the performance of ou model on long-tailed scene graph generation.
%	\item The method is test by extensive experiments on Visual Genome and OpenImage dataset. Results shows that our method obtain a new SOTA on Visual Genome with the balanced metric and comparable performance on biased classic metric; The result on OpenImage Dataset shows our method obtain a comparable performance on OpenImage V4, and new SOTA on OpenImage V6 dataset.
%\end{itemize}





% Specifically, the model perceive the relatedness information for modify topology of message passing dynamically, by reduce the un-necessary connections by adjust the topology of graph by a course to fine manner(hard to soft). 
% In this way, the less search space during the training can provide more efficient parameters learning. In inference time, it also reduce the noise of system, which lead to more effective features augmenting. 
% Further more, the model is works iteratively as a closed loop system, the model will iteratively produce the better relatedness information on refined features. 

% In this work, we proposed a new relatedness aware graph neural network for the feature representation learning of proposal graph, for improve the quality of representation learning of relationships. 
% As as general assumption, during the message passing and aggregating process, the contribution of each relationship during the message passing should be different due to their quality and properties. 
% In previous methods, the determination process of each graph nodes contribution should be learned by the graph neural network itself. 
% However, with the massive amount of low quality potential relationship within graph, the GNN is struggled to learn a good knowledge for this message passing. 
% During the message passing, we assume that most of useful information should come from the high quality relationship proposals. 
% Instead of directly remove the relationship proposal directly by a hard threshold manner, we design a mechanism that explicitly utilities the "relatedness" information to guide the information flow of message passing on graph.
% An additional relatedness discrimination model is used for provide relatedness score as reference that guide how we control the information flow of graph message passing by decrease the amount of proposal set that GNN aggregate the message.
% In this way, we can reduce the difficulty of GNN representation learning with relatedness aware message passing flow controlling method. As result, the quality of representation learning of GNN has been considerable improved.

% instance level re-sampling with graph constraint
% Due to the coupling issues of intra-class categories representation difficulty and longtail, we also need to directly tackle the long-tail issue. 
% According to the current study progress on long-tail issue in general recognition tasks\cite{kang_decoupling_2019}, they formulate the general recognition model in two part: feature extraction part and classifier part. 
% By conducting sufficient experiments, it shows that the long-tail bias influence the classifier part more than feature extraction part. 
% The most of model design for scene graph generation are focus on the feature extraction part. For study how effective of design, such decoupling strategy are required for relieve the performance bottle neck.
% By following such decoupling strategy, we design a simple but effective instance based dynamic re-sampling method, that can balance between the rare and common instances, and foreground and background instances during training.
% Compare with the traditional re-sampling strategy, we can achieve better performance on rare categories with lower cost of common categories.

\section{Quantitative Studies}
We extend the quantitative studies as a supplement to the main paper.
In this section, we show the detail of long-tail parts partition, and performance comparison on each long-tail part in Sec~\ref{lcgp}.
For the fair comparison with the previous methods, we also show the per-class performance comparison on the PredCls subtask in Sec~\ref{ppc}.
In Sec~\ref{visualize}, we show the comparison of model prediction by visualizing the scene graph generated by BGNN and previous SOTA GPS-Net. 


\subsection{Long-tail Categories Groups Partition} \label{lcgp}

\begin{figure*}[hb]
	\centering
	\includegraphics[width=\linewidth]{imgs/vg_longtail_perf.png}
	\caption{
		 \textbf{The long-tail categories groups partition and the upper-bound comparison on Visual Genome dataset.} 
	}\label{fig:vg_longtail_part}
\end{figure*}

\paragraph{Visual Genome}
First, we report the data distribution and long-tail categories set partition detail of Visual Genome~\cite{krishna2017visual, xu_scene_2017} in figure \ref{fig:vg_longtail_part}. 
We divide the categories into three disjoint groups according to the instance number in training split: \textit{head}(more than 10k), \textit{body}(0.5k $\sim $ 10k), \textit{tail}(less than 0.5k)

We further present the performance comparison of the baseline model(MSDN) between our upper bound assumption referred to Sec. 1 of main paper. 
The result indicates reducing noise in context modeling improve the baseline model with a large margin especially on tail categories, which only have several data points.


\paragraph{Open Images}

\begin{figure*}
	\centering
	\includegraphics[width=\linewidth]{imgs/openimage_data_dist_perf_cmp.pdf}
	\caption{
		\textbf{The long-tail categories groups partition and per-class performance comparison of Open Images dataset}. Part (A) is the Open Images V4, part (A) is the Open Images V6 dataset. We compare with the two SOTA methods: Causal~\cite{tang_unbiased_2020}, and GPS-Net~\cite{lin_gps-net_2020}.
	}
	\label{fig:oi_dataset_alt}
\end{figure*}


The long-tail categories group partition and per-class performance comparison on Open Images dataset are reported in Fig. \ref{fig:oi_dataset_alt}. 
Similarly, we divide the categories of Open Images V6 into three groups according to the instance number in training split: \textit{head}(more than 12k), \textit{body}(0.2k $\sim $ 12k), \textit{tail}(less than 0.2k). 
For performance comparison with the SOTA method, our method achieves significant improvement on tail categories and achieves the comparable overall performance with the GPS-Net~\cite{lin_gps-net_2020} and Causal~\cite{tang_unbiased_2020}.



\begin{figure*}
	\centering
	\includegraphics[width=\linewidth]{imgs/pred_cls_per_cls.png}
	\caption{
		 \textbf{The Recall@100 on Predicate Classification(PredCls) of all categories.} We compare with the SOTA methods: Causal~\cite{tang_unbiased_2020}, and GPS-Net~\cite{lin_gps-net_2020}.
		 $*$ denotes the re-sampling~\cite{gupta_lvis:_2019} is applied for this model.
	}
	\label{fig:predcls_cmp}
\end{figure*}


\subsection{Per-class Performance Comparison with the Other Models} \label{ppc}

Following the previous works setting~\cite{chen_knowledge-embedded_2019,tang_learning_2018, lin_gps-net_2020, tang_unbiased_2020}, we show the comparison of Recall@100 on PredCls sub-task of each categories with the two SOTA methods~\cite{lin_gps-net_2020, tang_unbiased_2020}, as shown in fig \ref{fig:predcls_cmp}.

Instead of only comparing the top-35 frequency categories, we present all 50 categories of Visual Genome. Our model achieves a significant performance gain on low-frequency categories, which demonstrates the effectiveness of our BGNN. 



\subsection{Visualization of Model Prediction} \label{visualize}
To better understand the BGNN, we visualize scene graph generation prediction from the Visual Genome dataset.
As shown in Fig.~\ref{fig:qualitative}, our model has a significant improvement for \textit{body} and \textit{tail} categories group compared with GPS-Net.
With a more effective confidence-aware message propagation mechanism, our model has better context modeling capability of visual representations for low-frequency categories.  

% \subsection{Comparison with Two-stage Training}
% The two-stage training strategy is a powerful method for long-tail which proposed by \cite{kang2019decoupling}.
% This two-stage training strategy decouples the learning procedure of representation learning and classification of models, to obtain a more balanced performance for long-tail recognition.

% However, in our preliminary study, we find that this strategy provides little performance gain on long-tail scene graph generation task.
% As shown in Tab.~\ref{tab:two_stage}, we take the Motifs \cite{zellers_neural_2017} as baseline model to compare the 2-stage classifier retraining(2stg) and 1-stage joint training(1stg) on Visual Genome dataset.


% \begin{table}[]
% 	\begin{tabular}{l|ll|lll}
% 	\toprule
% 	\textbf{T} & \textbf{R@100} & \textbf{mR@100} & \textbf{head} & \textbf{body} & \textbf{tail} \\ \midrule
% 	1stg      & 36.5    & 7.3   & 34.9   & 5.8  & 0.0     \\
% 	% 1stg-cos  & 36.2    & 7.9   & 34.7   & 6.2  & 1.0     \\
% 	1stg*     & 36.0    & 9.5   & 34.0   & 9.0  & 2.3    \\
% 	2stg      & 36.3    & 9.5   & 34.7   & 8.6  & 2.3    \\
% 	% 2stg-cos  & 36.1    & 9.6   & 34.5   & 8.8  & 2.4    \\ 
% 	\bottomrule
% 	\end{tabular}
% 	\caption{\textbf{The comparison of the two-stage training on Motifs \cite{zellers_neural_2017}.}  
% 	$*$ denotes the resampling \cite{gupta_lvis:_2019} is applied for this experiment.}
% 	\label{tab:two_stage}
% \end{table}

% \begin{table}[]
%     \centering
%     \resizebox{0.44\textwidth}{!}{
%     \begin{tabular}{cc|cc|ccc}
%     \toprule
%        &        & \multicolumn{5}{c}{\textbf{SGGen}}                        \\ 
%     \midrule
%     $t$ & $\gamma_d$ &  \textbf{mR@100} & \textbf{R@100} & \textbf{Head} & \textbf{Body} & \textbf{Tail} \\
%     \midrule
%     0.01 & 0 &   10.0 & 35.3 &  33.5  &  9.3  &  4.0  \\
% 	0.07 & 0 &  10.5 & 35.5 &  34.0  &  9.4    &  4.2  \\
% 	0.1 & 0 &  10.5 & 35.5 &  34.0  &  9.4    &  4.2  \\
%     0.07 & 0.4 & 10.0 & 35.3 &  33.5  &  9.3  &  4.0  \\
% 	0.07 & 0.5 & 12.6 & 35.8 &  34.0  &  12.9  &  6.0    \\ 
% 	0.07 & 0.7 & 15.1 & 32.5 &  30.1  &  17.2    &  9.1 \\
%     % 6  & 3 & 4   &  10.7  &  12.5   &  34.4  &  12.2  &  5.7    \\ 
%     \bottomrule
% \end{tabular}
%     }
%     \caption{\textbf{The ablation for the different graph iteration parameters.} 
%     The ablation of different iteration number for iterative refinement models in our methods. }
%     \label{tab:iter_num} \vspace{-4mm}

% \end{table}



% \begin{figure*}
% 	\centering
% 	\includegraphics[width=\linewidth]{imgs/openimage_data_dist.pdf}
% 	\caption{
% 		 \textbf{The data distribution and per-class performance of Open Images dataset}. The part (a) is the Open Images V4, the part (b) is the Open Images V6 dataset.
% 	}
% 	\label{fig:oi_dataset}
% \end{figure*}





% \subsection{Comparison between 2-stage retraining strategies}


% \begin{table}[]
%     \centering
%     \resizebox{0.44\textwidth}{!}{
%     \begin{tabular}{cc|cc|ccc}
%     \toprule
%        &        & \multicolumn{5}{c}{\textbf{SGGen}}                        \\ 
%     \midrule
%     $t$ & $\gamma_d$ &  \textbf{mR@100} & \textbf{R@100} & \textbf{Head} & \textbf{Body} & \textbf{Tail} \\
%     \midrule
%     0.01 & 0 &   10.0 & 35.3 &  33.5  &  9.3  &  4.0  \\
% 	0.07 & 0 &  10.5 & 35.5 &  34.0  &  9.4    &  4.2  \\
% 	0.1 & 0 &  10.5 & 35.5 &  34.0  &  9.4    &  4.2  \\
%     0.07 & 0.4 & 10.0 & 35.3 &  33.5  &  9.3  &  4.0  \\
% 	0.07 & 0.5 & 12.6 & 35.8 &  34.0  &  12.9  &  6.0    \\ 
% 	0.07 & 0.7 & 15.1 & 32.5 &  30.1  &  17.2    &  9.1 \\
%     % 6  & 3 & 4   &  10.7  &  12.5   &  34.4  &  12.2  &  5.7    \\ 
%     \bottomrule
% \end{tabular}
%     }
%     \caption{\textbf{The ablation for the different graph iteration parameters.} 
%     The ablation of different iteration number for iterative refinement models in our methods. }
%     \label{tab:iter_num} \vspace{-4mm}

% \end{table}


% \begin{table}[]
%     \centering
%     \resizebox{0.44\textwidth}{!}{
%     \begin{tabular}{cc|cc|ccc}
%     \toprule
%        &        & \multicolumn{5}{c}{\textbf{SGGen}}                        \\ 
%     \midrule
%     $t$ & $\gamma_d$ &  \textbf{mR@100} & \textbf{R@100} & \textbf{Head} & \textbf{Body} & \textbf{Tail} \\
%     \midrule
%     0.01 & 0 &   10.0 & 35.3 &  33.5  &  9.3  &  4.0  \\
% 	0.07 & 0 &  10.5 & 35.5 &  34.0  &  9.4    &  4.2  \\
% 	0.1 & 0 &  10.5 & 35.5 &  34.0  &  9.4    &  4.2  \\
%     0.07 & 0.4 & 10.0 & 35.3 &  33.5  &  9.3  &  4.0  \\
% 	0.07 & 0.5 & 12.6 & 35.8 &  34.0  &  12.9  &  6.0    \\ 
% 	0.07 & 0.7 & 15.1 & 32.5 &  30.1  &  17.2    &  9.1 \\
%     % 6  & 3 & 4   &  10.7  &  12.5   &  34.4  &  12.2  &  5.7    \\ 
%     \bottomrule
% \end{tabular}
%     }
%     \caption{\textbf{The ablation for the different graph iteration parameters.} 
%     The ablation of different iteration number for iterative refinement models in our methods. }
%     \label{tab:iter_num} \vspace{-4mm}

% \end{table}


% {\small
% \bibliographystyle{ieee_fullname}
% \bibliography{egbib}
% }




A semi-infinitely constrained MDP (SICMDP) is defined by a tuple $M=\langle \gS,\gA,Y,P,r,c,u,\mu,\gamma\rangle$.
Here $\gS, \gA, P, r, \mu, \gamma$ are defined in a similar manner as in common infinite-horizon discounted MDPs.
Specifically, $\gS$ and $\gA$ are the finite sets of states and actions, respectively. 
$P$ is the transition dynamics and $P(s^\prime|s,a)$ represents the probability of transitioning to state $s^\prime$ when playing action $a$ at state $s$. And
$r\colon \gS\times \gA\to[0,1]$ is the reward function,  
$\mu$ is the fixed initial distribution, and $\gamma$ is the discount factor.
$Y$ is the set of constrains, which we define as a compact set in $\RB^m$, and $\mathrm{diam}(Y)<\infty$ denotes its diameter.
That is, $\mathrm{diam}(Y):=\sup_{y,y^\prime\in Y}{\|y-y^\prime\|_\infty}$.
In addition, $c\colon Y\times \gS\times \gA\to[0,1]$ is used to denote a continuum of cost functions and the value for constraints (bounds that must be satisfied) is determined by function $u\colon Y\to \RB$. 
Note that when $Y$ is finite, we get an ordinary constrained MDP, which is indeed a special case of SICMDP.


For a given policy $\pi$, we define the value function ${V^\pi_r(s)=\EB\left(\sum_{t=0}^\infty \gamma^tr(s_t,a_t)|s_0=s\right)}$, the state-action value function ${Q^\pi_r(s,a)=\EB\left(\sum_{t=0}^\infty \gamma^tr(s_t,a_t)|s_0=s,a_0=a\right)}$, and the advantage function ${A^\pi_r(s,a)=Q^\pi_r(s,a)-V^\pi_r(s)}$. Here
$V_{c_y}^\pi(s)$, $Q_{c_y}^\pi(s,a)$ and $A_{c_y}^\pi(s,a)$ are defined in a similar manner.
Let the occupancy measure on $\gS\times \gA$ introduced by policy $\pi$ be $\nu_\pi\in\Delta(\gS\times \gA)$ and ${\nu_\pi(s,a)=(1-\gamma)\sum_{t=0}^\infty\gamma^t \PB_\pi(s_t=s,a_t=a)}$.

The general SICMDP problem is to find a stationary policy $\pi\colon \gS\to \Delta(\gA)$, where $\Delta(\gA)$ is the set of probability measure supported on $\gA$, to maximize the value function while complying with a continuum of constraints. 
In other words, we  consider the following optimization problem:
\begin{equation}\label{Problem_SICMDP} \tag{M}
\begin{aligned}
\max_{\pi}\ V_r^\pi(\mu)\quad
\text{s.t.}\ V_{c_y}^\pi(\mu) \leq u_y,\ \forall y\in Y. 
\end{aligned}
\end{equation}

Let us see two concrete examples of SICMDPs.  
\begin{example}[Spatial-temporal Constraints]\label{Example_Time_Evolving}
Consider an ordinary CMDP problem with a single constraint:
\begin{equation}\label{Problem_CMDP_Single_Constraint}
\begin{aligned}
\max_{\pi}\ V_r^\pi(\mu)\quad
\text{s.t.}\ V_c^\pi(\mu) \leq u.
\end{aligned}
\end{equation}
In some cases the constraint would be spatial-temporal, i.e., the cost function $c(s,a)$ and the value for constraints $u$ are no longer constant functions and would change with time $\tau \in[0,T]$ or location $x\in \gX\subset\RB^3$.
Then we should use the SICMDP model with $Y=[0,T]$ or $Y=\gX$ rather than the ordinary CMDP framework to model such problems:
\begin{equation}\label{Problem_SICMDP_Time_Evolving}
\begin{aligned}
\max_{\pi}\ V_r^\pi(\mu)\quad
\text{s.t.}\ V_{c_\tau}^\pi(\mu) \leq u_\tau, \; \forall \tau \in [0,T],
\end{aligned}
\end{equation}
or
\begin{equation}\label{Problem_SICMDP_Space}
\begin{aligned}
\max_{\pi}\ V_r^\pi(\mu)\quad
\text{s.t.}\ V_{c_x}^\pi(\mu) \leq u_x, \; \forall x \in \gX.
\end{aligned}
\end{equation}
% Note that the time index $\tau$ are different from the time index $t$ in the definition of the value function or expected cumulative cost in the sense that they may represent different time scales. 

\textit{Load Balancing}: Suppose an RL agent needs to balance the load between multiple cell sites using some policy $\pi$.
The objective is to minimize the cost $V_r^\pi(\mu)$ and the constraint is that at every place $x$ in the region $\gX$ the cumulative communication capacity $V_{c_x}^\pi(\mu)$ is above some adaptive threshold $u_x$.

\textit{Ship Route Planning}: Suppose we need to navigate a ship using some policy $\pi$.
Our objective is to minimize the voyage.
The constraint is that at every place $x$ in the region $\gX$ the cumulative environmental pollution $V_{c_x}^\pi(\mu)$ is below some adaptive threshold $u_x$.
\end{example}


\begin{example}[Constraints with Uncertainty]\label{Example_Uncertain}
Again we consider a problem like Problem (\ref{Problem_CMDP_Single_Constraint}).
In many application scenarios the cost function $c(s,a)$ is handcrafted and the construction of $c(s,a)$ is not guaranteed to be correct.
Hence it may be helpful to include an additional parameter $\epsilon\in E$ representing our uncertainty in the construction of the cost function $c(s,a)$ as well as the value of constraints $u$.
Even if the constraint is not handcrafted and has clear physical meaning, it may still subject to uncertain parameters $\epsilon\in E$ that cannot be observed in advance.
% \liangyu{Not sure whether I make it clear here.}
Therefore, we should use the SICMDP model with $Y=E$ rather than the ordinary CMDP framework to model such problems:
\begin{equation}\label{Problem_SICMDP_Uncertain}
\begin{aligned}
\max_{\pi}\ V_r^\pi(\mu)\quad
\text{s.t.}\ V_{c_\epsilon}^\pi(\mu) \leq u_\epsilon, \forall \epsilon\in E.
\end{aligned}
\end{equation}

\textit{Underwater Drone}: Suppose an underwater drone needs to maximize $V_r^\pi(\mu)$ to accomplish some tasks.
When the unknown environment feature (salinity, temperature, ocean current, etc,) is $\epsilon\in E$, for state-action pair $(s,a)$ the energy consumption is $c_\epsilon(s,a)$, and the constraint is that total energy consumption $V_{c_\epsilon}^\pi(\mu)$ cannot be larger than its battery capacity $u_\epsilon$.
\end{example}

\begin{remark}\label{Remark_Baseline}
An alternative approach to solving problems such as Examples~\ref{Example_Time_Evolving} and ~\ref{Example_Uncertain} is to naively discretize the constraint set $Y$, and then the discretized problem can be fit into the conventional CMDP framework.
We call this strategy naive discretization.
The problem with this naive method is that the prior knowledge, i.e., the constraint function is continuous w.r.t.\ $y$, would be lost, which makes the method extremely inefficient.
In Section~\ref{Section_Experiment} we demonstrate this issue via numerical examples.


\end{remark}

When a SICMDP $M$ is known to us, we may do the planning by solving a linear semi-infinite programming (LSIP) problem.
Problem (\ref{Problem_SICMDP}) can be reformulated as the following LSIP problem:
\begingroup
\small
\begin{equation}\label{Problem_SICMDP_LSIP}
\begin{aligned}
\max_{\nu}\ &\nu^\top r \\
\text{s.t.}\ &\frac{1}{1-\gamma}\nu^\top c_y\leq u_y, \; \forall y\in Y, \\
& \sum_{s^\prime ,a}  \nu(s^\prime,a)(\mathbf{1}_{\{s^\prime=s\}} {-} \gamma P(s|s^\prime,a))=(1{-}\gamma)\mu(s), \; \forall s\in \gS, \\
&\nu \succeq 0.
\end{aligned}
\end{equation}
\endgroup
Here $\nu$ represents the occupancy measure on $\gS\times\gA$ induced by some policy $\pi$.
And ${\pi(a|s)=\frac{\nu_\pi(s,a)}{\sum_{a^\prime\in \gA}\nu_\pi(s,a^\prime)}}$.
Therefore, when $M$ is already known the optimal policy $\pi^*$ can be found by solving Problem (\ref{Problem_SICMDP_LSIP}).
And we always assume such a policy $\pi^*$ exists.
\begin{assumption}\label{Assumption_Feasible}
Problem (\ref{Problem_SICMDP}) is feasible with an optimal solution $\pi^*$, or equivalently, Problem (\ref{Problem_SICMDP_LSIP}) is feasible with an optimal solution $\nu^*$.
% \wenhao{Problem (\ref{Problem_SICMDP}) is feasible with an optimal solution $\pi^*$, or equivalently, Problem (\ref{Problem_SICMDP_LSIP}) is feasible with an optimal solution $q^*$.}
% \liangyu{Resolved.}
\end{assumption}
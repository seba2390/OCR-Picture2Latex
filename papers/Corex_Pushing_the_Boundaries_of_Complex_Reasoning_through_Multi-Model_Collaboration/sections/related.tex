\section{Related works}

\paragraph{Chain-of-Thought Prompting Elicits LLM Reasoning.}

Chain-of-Thought (CoT; \citealp{wei2022chain}) prompting, 
as one of the celebrated capabilities of recent LLMs, 
is a pivotal breakthrough for performing complex multi-step reasoning when provided with limited examples.
Further variants show that CoT can be improved by adding certain ``magic phrases''~\citep{kojima2022zscot}, 
automated demonstrations construction~\citep{zhang2022autocot}, 
reasoning in different modalities~\citep{zhang2023mmcot, yang2023mmreact, yao2023got},
and applying modular approaches~\citep{khot2023decomp}.
% To enhance robustness, 
For robustness, 
researchers transform problems into interleaved reasoning chains~\citep{zhou2023leasttomost, lyu2023faithful} or adopt ensembling~\citep{wang2022rationale}. 
Notably,
self-consistency methods~\citep{wang2023sc} select answers from multiple reasoning paths by majority voting,
have greatly elevated the performance of LLMs in complex reasoning.
This approach has been further optimized by utilizing prompts with higher complexity~\citep{fu2023complexcot}.
Lately, 
\citet{yao2023tree} employ heuristic-guided search on ``trees'' constructed from thoughts to assist LLMs in navigating the problem space.

\paragraph{External Knowledge \& Tool Utilization for LLM Reasoning.} 
While LLMs exhibit significant capabilities, 
they are limited by a lack of real-world grounded experience~\citep{petroni2020how} and an inability to grasp complex arithmetic reasoning, 
given that their training is exclusively based on written text.
Thus, 
researchers start utilizing external knowledge to assist models in accomplishing reasoning tasks~\citep{nakano2022webgpt, schick2023toolformer}.
For enhanced factuality and faithfulness, 
\citet{he2022rethinking} and \citet{wang2023cok} make use of external knowledge bases.
Lately, 
\citet{gao2023enabling} ensure the factual correctness and verifiability of generated text by providing cited passage. %from a retrieval corpus.

Another line is to delegate reasoning tasks to external tools~\citep{qin2023toolllm}, 
which are commonly used for addressing numerical problems.
One of the representatives is program-aided Language model~\citep{gao2022pal}, 
known as PAL\footnote{The idea of integrating LLMs with external PL interface was proposed by~\citet{gao2022pal} and \citet{chen2022program} within the same timeframe. 
We refer to this approach as ``PAL'' in this paper.}.
Such an approach utilizes LLMs to interpret NL problems, 
generating programs as intermediate reasoning steps~\citep{chen2022program} that will be offloaded to a Python interpreter for execution to get final solutions~\citep{ni2023lever}.
This method transforms reasoning into an NL2Code~\citep{zan2023large} task and has been demonstrated to excel when dealing with larger, non-integer numbers and enabling error corrections~\citep{olausson2023demystify}.
Beyond synthesizing programs, 
\citet{liu2023minds} integrate a computational physics engine into the language
modeling process for simulation.
Moreover,
\textit{Chameleon}~\citep{lu2023chameleon} augments LLMs by incorporating both tools and knowledge resources like web engines and image captioners.
% (e.g., web engines, image captioners, and specialized modules).

\paragraph{Multi-Model Synergy for Task Solving.}
Utilizing multiple LLMs collectively to solve problems is still in its preliminary stages,
with a wealth of opportunities awaiting exploration. 
The cornerstone of collaboration is constructing a human-like reasoning architecture~\citep{zhu2023solving} for LLMs under different environments~\citep{liu2023agentbench}. 
\citet{fu2023improving} investigate whether multiple LLMs can autonomously enhance their performance through mutual interactions.
\citet{du2023improving} and \citet{liang2023encouraging} explore enhancing the factuality of specific tasks, e.g., translation and arithmetic reasoning, by facilitating ``debates'' among multiple models.
LLMs' collaboration has also been applied to software development~\citep{qian2023communicative} and text evaluation~\citep{chan2023chateval}
by assigning identities to models to simulate the development process.
Furthermore, 
from the perspective of social intelligence, 
inducing cognitive synergy and having them take on different characters~\citep{wang2023unleashing} during task execution has been proven to have significant potential~\citep{sclar2023minding}.
Recently, 
the nascent exploration into artificial societies~\citep{park2023generativeagents} also seeks to harness collective intelligence to emulate the efficiency of human social structures~\citep{li2023camel, webb2023emergent}.

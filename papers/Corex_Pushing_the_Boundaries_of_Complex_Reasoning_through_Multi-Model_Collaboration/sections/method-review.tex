\subsection{Review}
Within the scope of reasoning, 
% both CoT and Program-Aided Learning (PAL; \citealp{gao2022pal,chen2022program}) are effective methods with distinct strengths.
both CoT and PAL are effective methods with distinct strengths.
% have proved to be effective.
% each embodying distinct strengths.
Grounded in natural language, 
CoT-based methods stand out for the generality and the clarity of explanations.
In contrast,
facilitated by programs, 
PAL guarantees computational accuracy~\citep{zhao2023automatic}. 
However, 
they both exhibit drawbacks due to the reliance on LLMs' internal representations. 
For CoT and its variants,
issues are twofold: 
% (1) Degeneration-of-thought~\citep{liang2023encouraging},
% once the LLMs has established confidence in answers, they struggle to generate novel thoughts upon later reflection; 
(1) Cumulative errors, where mistakes tend to amplify and propagate throughout the reasoning chain;
and (2) A plateau in text quality that cannot be substantially improved through prompting~\citep{xu2022learning, li2023contrastive}.
Alternatively, 
PAL faces its own challenges:
% (1) LLMs might misconstrue the key point of the question,
(1) LLMs might misinterpret questions,
which inadvertently results in technically correct yet misguided programs;
% inadvertently overlooking critical pieces of information,
% which results in technically correct yet misguided programs;
and (2) Generated codes are not always error-free:
% Despite a comprehensive understanding of the question, 
% LLMs may potentially write codes beset with syntax errors, 
LLMs may potentially write buggy codes,
such as referencing undefined variables or engaging in ``Division by Zero'' operations.
% Given the aforementioned challenges, 
% we are inspired by collaborative coding practices prevalent in software engineering, 
% where pairs of programmers work together on a project and engage in code reviews. 
% Drawing inspiration from collaborative coding practices commonly found in software engineering, 
% \citep{zheng2023judging} % Judging LLM-as-a-judge with MT-Bench and Chatbot Arena
Inspired by recent efforts of LLMs peer-rating~\citep{zheng2023judging} and collaborative coding practices prevalent in software engineering, 
we introduce the Review mode to address the aforementioned issues through collaboration.
\begin{wrapfigure}{r}{4.5cm}
\vspace{-0.5em}
    \centering
    \includegraphics[width=\linewidth]{figures/review-illustration.pdf}
    \caption{Illustration of reviewing erroneous code generated by other agents (first round).}
    \vspace{-2.75em}
    \label{fig:review-illustration}
\end{wrapfigure}
To be specific, 
a single agent \(A_p\) is randomly selected to act as the primary agent.
Initially, 
\(A_p\) takes the responsibility of formulating corresponding reasoning chains for $q$ along with the prediction,
and crafting codes if required. 
This initial collection of solutions is represented as \(S_{p}^{(0)} = \{a_p, c_p, m_p\}\), 
where \(a_p\), \(c_p\), and \(m_p\) signify the answer, 
reasoning chain, and codes respectively. 
\(S_{p}^{(0)}\) is then subjected to iterative reviews by the other agents that function as reviewers in a sequential manner, 
rigorously scrutinizing both the reasoning chain and the code formulated by \(A_p\) or modified by preceding reviewers. 
It is crucial to highlight that each reviewer receives input from its predecessors, 
signifying that each subsequent review is grounded on the outcomes and feedback of the preceding ones, 
fostering a progressively refined solution.

The reviewing process is formalized as \( S_{p}^{(i+1)} = R_i(S_{p}^{(i)}, F_i) \), 
where \( R_i \) encapsulates the review outcome at the \( i^{th} \) iteration and \( F_i \) represents the feedback received. 
In essence, the solution set \( S_{p}^{(i+1)} \) results from an enhancement of its preceding version \( S_{p}^{(i)} \), 
informed by the feedback \( F_i \).
Following the completion of all review iterations, the outcome is determined by the final iteration of the solution set \( S_{p}^{(n-1)} \).
Specifically, 
the final prediction \( a_{p}^{(n-1)} \) is chosen as the answer for $q$, 
and in instances where code is involved, 
the last revised version \( m_{p}^{(n-1)} \) is executed by a Python interpreter to produce the outcome.

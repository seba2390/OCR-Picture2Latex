\subsection{Debate}


In Debate mode, 
our agents are divided randomly into two groups, 
the Red Team and the Blue Team, with one reserved as a judge denoted as \(A_j\). 
The debate process within one team involves several rounds, limited to a maximum of \(T\) rounds of communications. 
In each round \( t \) (\( t=1, 2, \dots, T \)),
the agents engage in iterative discussions\footnote{Due to the context length limit of \turbon, only information from the previous round is stored during the debate process.} to refine their reasoning chains and predictions. 
This dynamic interaction \(g\), 
allows for the continual modification of viewpoints, 
as expressed by \(c_i^t = g(q, c_{i-1}^t, \dots, c_{i-k}^t)\) and predictions \(p_i^t\).

Each team then presents their refined predictions \(p_{\text{red}}^t\) and \(p_{\text{blue}}^t\) at the end of each round. 
If both teams consistently agree throughout the debate process, 
i.e., \(p_{\text{red}}^t = p_{\text{blue}}^t\), 
the debate concludes smoothly.
However, 
in the instance of a discrepancy between the teamsâ€™ predictions, 
every output from each round is presented to the judge \(A_j\).
The judge employs a decision-making process \(h\), 
evaluating the quality and reliability of the reasoning chains and predictions from each round of the debate. The final conclusion is determined by \(h(c_{\text{red}}^t, p_{\text{red}}^t, c_{\text{blue}}^t, p_{\text{blue}}^t)\) across all rounds, ensuring a comprehensive assessment and a more informed final decision.

\begin{wrapfigure}{r}{4.5cm}
\vspace{-1.5em}
    \centering
    \includegraphics[width=\linewidth]{figures/debate-illustration.pdf}
    \caption{Illustration of 2 rounds of debate, reasoning chains between agents omitted.}
    \vspace{-1.55em}
    \label{fig:debate-ill}
\end{wrapfigure}

Diverging from previous works~\citep{liang2023encouraging, du2023improving, xiong2023examining}, 
the debate mode of \ours adopts the concept of group discussions to enhance the factuality of reasoning chains.
We opt not to facilitate models in jointly debating their reasoning processes to converge on a single common answer for several reasons:
(1) The context length limitations inhibit the ability to fully hold the entire debate process,
% , potentially restraining the comprehensive engagement of LLMs.
(2) Despite the tendency of debates to converge to single final answers, 
these outcomes are not always correct due to incorrect consensus or prevalent biases~\citep{wang2023ieval}, 
% possibly being a product of incorrect consensus or prevalent biases.
(3) Given the performance gaps among various LLMs, 
there is a risk of strong models ``monopolizing'' the debate,
thereby overshadowing the insights from others.
Therefore, 
we aim to preserve both the factuality and the diversity of thoughts among agents 
and ensure stability throughout the debate process.

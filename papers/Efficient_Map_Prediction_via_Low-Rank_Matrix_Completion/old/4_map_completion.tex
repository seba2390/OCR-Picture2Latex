\section{MAP COMPLETION}
\label{sec:map_completion}

\begin{table*}%[h]
\caption{Matric properties of maze environments} %title of the table
\centering % centering table
\begin{tabular}{c rrrrrrr} % creating eight columns
\hline\hline %inserting double-line
% Properties&\multicolumn{7}{c}{Sum of Extracted Bits} \\ [0.5ex]
  & \vline & (a) & (b) & (c) & (d) & (e) & (f)\\
\hline % inserts single-line
Rank & \vline & 2 & 7 & 11 & 15 & 19 & 23\\ % Entering row contents
Coherence & \vline & 0.0200 & 0.0400 & 0.0625 & 0.0833 & 0.1000 & 0.1250\\ % [1ex] adds vertical space
\hline % inserts single-line
\end{tabular}
\label{tb:maze_prop}
\end{table*}

Map completion exhibits the same form as the matrix completion if the map is represented in a matrix. Typical forms of map encountered in coverage planning include occupancy map, elevation map~(terrain map), and certain interested value 2D distribution map~(e.g., temperature distribution, $CO_2$ distribution, etc.). A common property of those maps are that the values of interest are represented with real numbers that distribute in a 2D plane, for instance, occupancy values in occupancy maps; height values in elevation maps. If the values are discretely distributed in a 2D plane, then the map will become a matrix. In this paper, we call those maps as feature maps and address the prediction of a partially observed terrain map of urban environments, in which the places identified~(by an aerial vehicle from the air) as having buildings are treated as featured spaces, while other places as non-featured spaces. Following the definition of binary occupancy maps, we indicate the featured spaces as 1 while non-featured spaces as 0 such that the urban terrain map could be modeled as a maze map. In this section we show that a maze-like feature map satisfies the assumptions of the LRMC model and how LRMC model performs the prediction given a partially revealed maze map.

\begin{figure} \vspace{-3pt}
  \centering
%   \subfigure[]
  	{\label{fig:mazes_1}\includegraphics[width=0.9\linewidth]{figs/mazes_with_ranks.png}}
  \caption{\small Maze environments with different ranks. The value of 1.0 represents the featured space while 0.0 is the non-featured space.
  } \vspace{-10pt}
\label{fig:mazes_1}  
\end{figure}

\begin{figure}[t] \vspace{-3pt}
  \centering
%   \subfigure[]
  	{\label{fig:demo}\includegraphics[width=\linewidth]{figs/demo.png}}
  \caption{\small First row: Map completion with \textit{perfect local sensing}. (a)~Ground-truth maze map. (b)~Partially observed map. The missing parts are indicated with white blocks. (c)~The predicted map using LRMC model. Second row: Map completion with \textit{degraded local sensing}. The colors have the same meaning with the first row.
  } \vspace{-10pt}
\label{fig:demo}  
\end{figure}

Different maze maps with varying ranks are generated by Daedalus\footnote{\url{http://www.astrolog.org/labyrnth/daedalus.htm}} and are shown in Fig~\ref{fig:mazes_1}. Each map has a dimension of $20m \times 20m$ with a resolution of $0.1m$, which results in a matrix with dimension of $200\times 200$. The rank values are listed in Table~\ref{tb:maze_prop}. It is easy to observe that the value of rank basically reflects the complexity of the matrix. The higher the rank is, the more complex the environment is. A typical urban terrain (or building layout) map would be similar to the maze with rank of 11 (as shown in Fig.~\ref{fig:mazes_1}-(c)), which is also the rank parameter we adopt in this paper. Compared with the dimension of 200, 11 is a much smaller value and therefore enables the corresponding matrix to be called as a low-rank matrix. Even the maze environment becomes super complex, such as the one shown in Fig.~\ref{fig:mazes_1}-(f), the rank value is still relatively small compared with the matrix dimension. Along with the rank values, we also list the coherence value for each maze matrix using the Eq.~(\ref{eq:coherence}). Although the coherence increases proportionally to the rank, they all stay at a low-level where we can be convinced they all are incoherent. Hence we can conclude that maze environments generally possess the low-rank and low-coherence properties required by the LRMC model. 

The sensors used in coverage planning are usually interfered with exogenous factors~(such as wind disturbance, magnetic field, light conditions, etc.) and endogenous factors~(such as manufacturing limitations, installation error, etc.). Consequently, the raw measurements from sensors could be noisy and in many cases be sparse. In this section, we demonstrate the proposed LRMC based algorithm is robust to the degraded sensing measurements by considering two modes of local sensing: \textit{perfect local sensing}~(PLS) mode and \textit{degraded local sensing}~(DLS) mode when performing coverage tasks. The PLS mode assumes the local sensed map is in an ideal condition and the DLS mode assumes there always be some random parts are missed for each local sensory measurement. Throughout this paper, we adopt the  SoftImpute~\cite{mazumder2010spectral} for implementing the LRMC model and an example for map completion on a partially observed maze map with two local sense modes is shown in Fig.~\ref{fig:demo}. 

In this example, we randomly select near-half observations and apply the LRMC model to the partial matrix. We use two evaluation metrics here: \textit{pure prediction accuracy}~(PPA) and \textit{total prediction accuracy}~(TPA). The PPA represents the correct prediction on purely missing parts while TPA indicates the correct entry matches~(including the already observed parts) between the entire predicted maze and the ground-truth maze. TPA reflects the general completeness whereas PPA shows the pure prediction performance of the LRMC model on unexplored places. 
%the prediction performance by simultaneously considering the LRMC model and the already observed entries whereas PPA shows the pure prediction performance by only the LRMC model. 
The PPA and TPA results for two sensing modes are shown in Table~\ref{tb:exam_stat}. It is clear that even with less than half of revealed/observed entries, the LRMC model could achieve more than (or almost) $90\%$ correct predictions.



\begin{table}%[h]
\caption{Statistics for Fig.~\ref{fig:demo}} %title of the table
\centering % centering table
\begin{tabular}{c rrrr} % creating eight columns
\hline\hline %inserting double-line
% Properties&\multicolumn{7}{c}{Sum of Extracted Bits} \\ [0.5ex]
  & \vline & PLS & DLS\\
\hline % inserts single-line
Revealed percentage & \vline & 0.5132 & 0.4625\\ % Entering row contents
PPA & \vline & 0.8914 & 0.9326\\ % [1ex] adds vertical space
TPA & \vline & 0.9417 & 0.9638\\
\hline % inserts single-line
\end{tabular}
\label{tb:exam_stat}
\end{table}

Previous works have theoretically proven a partially observed low-rank matrix could be perfectly recovered if the number of sampled entries $m$ obeys the Eq.~(\ref{eq:sampled_cond})~\cite{candes2009exact}. Although the number of observation samples are theoretically lower bounded, it is still difficult to determine the exact value of the $m$ due to the existence of $C$. To determine a proper scale of the coefficient $C$, we generate 20 maze environments with the same rank of 11 and apply the LRMC model to different partially observed mazes and unveil the relationship between the coefficient $C$ and PPA/TPA. For each value of $C$ we compute a mean and standard deviation for TPA and PPA, respectively. The relation is shown in Fig.~\ref{fig:num_curves}.

We can think the coefficient $C$ is actually reflecting the number of observed entries according to Eq.~(\ref{eq:sampled_cond}). The higher the coefficient is, the more the observations are and the better the prediction is. From Fig.~\ref{fig:num_curves}, we can see that for PLS mode, the mean of both accuracies could reach above $80\%$ when $C> 2.0$ while for DLS mode when $C>2.0$, the accuracy level could arrive above $90\%$. Hence we come to a conclusion that a reference value for $C$ to achieve an acceptable prediction in the selected maze environment is 2.0. This will guide the later experiments in this paper.

Another interesting phenomenon in Fig.~\ref{fig:num_curves} is the accuracy for DLS mode has a faster convergence~(per coefficient $C$) comparing with the one for PLS mode even PLS mode has a perfect-sensing assumption. This implies that the LRMC model can have over-fitting issue if a perfect-sensing model is used and appropriate level of noise could relieve the problem and achieve a good accuracy with fewer observations. This characteristics is very important and useful since it implies the LRMC model is more suited to real-world scenarios. %, which is something we feel more interested in.

\begin{figure}%[h!]
  \centering
  \begin{subfigure}[b]{0.49\linewidth}
    \includegraphics[width=\linewidth]{figs/pc.png}
    \caption{}
  \end{subfigure}
  \begin{subfigure}[b]{0.49\linewidth}
    \includegraphics[width=\linewidth]{figs/dc.png}
    \caption{}
  \end{subfigure}
  \caption{Prediction accuracy vs. coefficient $C$. Curves for (a)~PLS mode and (b)~DLS mode.}
  \label{fig:num_curves}
\end{figure}
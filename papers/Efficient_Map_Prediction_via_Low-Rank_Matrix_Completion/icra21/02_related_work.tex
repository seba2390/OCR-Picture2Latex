\section{RELATED WORK}

\textbf{Map Prediction.} Map prediction aims to predict map structure based on already revealed regions and could be categorized into two classes: \textit{interpolation} and \textit{extrapolation}. Map interpolation means given some map samples, we want to predict the values in between the sampled places. This type of mapping methods are usually seen in occupancy mapping field, such as Occupancy Girds Mapping~(OGM)~\cite{elfes1989using}, Gaussian Process Occupancy Mapping~(GPOM)~\cite{o2012gaussian, wang2016fast}, Hilbert Mapping~(HM)~\cite{ramos2016hilbert} and Bayesian Hilbert Mapping~(BHM)~\cite{senanayake2017bayesian}. OGM divides the world into fixed-size grids and apply a Bayes filter to predict the occupancy values of the environment with an assumption that all the grids are independent with each other. To eliminate the requirement of pre-defining a discrete grid and the independent assumption in OGM, GPOM is proposed and used in many applications~\cite{jadidi2014exploration, jadidi2015mutual}. GPOM naturally captures the neighbouring information thanks to kernelization, but being a non-parametric model, it has a computation complexity of $O(n^3)$, where $n$ is the number of sampled data points. Bringing all the advantages of GPOM, a faster and simpler parametric model---HM and its Bayesian version, BHM, are proposed later. HM/BHM treats the map prediction as a kernelized logistic regression and has a linear time complexity. 

Map extrapolation indicates that given some map samples~(or structures), we want to predict the map values beyond the sampled places. This problem attracts increasing attention in recent years and almost all the current methods for map extrapolation are based on deep neural networks~(DNNs)~\cite{caley2019deep, pronobis2017learning, katyal2018occupancy, shrestha2019learned, saroya2020online, katyal2019uncertainty}. However, DNNs based methods require huge amount of data for training and hence still be very problematic. In this paper, we propose to use Low-Rank Matrix Completion to perform the map prediction. We claim here and will show in later experiments that our proposed LRMC based method fall in between the \textit{interpolation} and \textit{extrapolation} methods. Specifically, the LRMC method can not only well interpolate map values, but at the same time can weakly extrapolate the map structure beyond the explored areas in real-time. 

\textbf{Low-Rank Matrix Completion.} In the past two decades, the Low-Rank Matrix Completion~(LRMC) problem has been widely studied. The first theoretically guaranteed exact LRMC algorithm is proposed in~\cite{candes2009exact}, where any $n \times n$ incoherent matrices of rank r are proven to be exactly recovered from $C n^{1.2}r\log n$ uniformly randomly sampled entries with high probability through solving a convex problem of nuclear norm minimization~(NNM). Subsequent works~\cite{candes2010power, chen2015incoherence, gross2011recovering, recht2011simpler} refine the provable completion results following the NNM based method. However, since all of the algorithms mentioned above are based on second order methods~\cite{liu2010interior}, they can become extremely expensive if the matrix dimension is large~\cite{cai2010singular}. Some first order based methods~\cite{cai2010singular, ji2009accelerated, mazumder2010spectral} are developed to overcome the limitations of the second-order based methods. They solve the nuclear norm minimization problem in an iterative manner and rely on Singular Value Decomposition~(SVD) of matrices and are suited to large-scale matrix completion problems. Many other aspects of matrix completion could be found in~\cite{hastie2015matrix, liu2017new, eriksson2012high, bhojanapalli2014universal, chen2015completing, chen2014coherent, eftekhari2018mc2}.
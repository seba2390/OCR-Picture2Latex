\section{MAP PREDICTION}
\label{sec:map_completion}

\begin{table*}[t]
\caption{Matric properties of maze environments} %title of the table
\centering % centering table
\begin{tabular}{c rrrrrrr} % creating eight columns
\hline\hline %inserting double-line
% Properties&\multicolumn{7}{c}{Sum of Extracted Bits} \\ [0.5ex]
  & \vline & (a) & (b) & (c) & (d) & (e) & (f)\\
\hline % inserts single-line
Rank & \vline & 2 & 7 & 10 & 15 & 18 & 23\\ % Entering row contents
Coherence & \vline & 0.0200 & 0.0400 & 0.0625 & 0.0833 & 0.1000 & 0.1250\\ % [1ex] adds vertical space
\hline % inserts single-line
\end{tabular}
\label{tb:maze_prop}
\end{table*}

Map completion exhibits the same form as the matrix completion if the map is represented by a matrix. Typical forms of map encountered in environmental monitoring include occupancy map, elevation map~(terrain map), and certain interested value 2D distribution map~(e.g., temperature distribution, $CO_2$ distribution, etc.). If the values are discretely distributed in a 2D plane, then the map will become a matrix. In this paper, we call those maps as feature maps and address the real-time prediction of a partially observed urban buildings layout map, in which the places identified~(by an aerial vehicle from the air) as having buildings are treated as featured spaces, while other places as non-featured spaces. In this section we show that a maze-like feature map satisfies the assumptions of the LRMC model and how the LRMC model performs the prediction given a partially revealed maze map.

\begin{figure} \vspace{-3pt}
  \centering
%   \subfigure[]
  	{\label{fig:mazes_1}\includegraphics[width=0.9\linewidth]{figs/mazes_with_ranks.png}}
  \caption{\small Maze environments with different ranks. The value of 1.0 represents the featured space while 0.2 is the non-featured space~(the reason for using 0.2 is in LRMC model, we need to fill missing parts with 0, then to distinguish the known parts and missing parts, we use some non-zero value to represent the non-featured space).
  } \vspace{-10pt}
\label{fig:mazes_1}  
\end{figure}

\begin{figure} \vspace{-3pt}
  \centering
%   \subfigure[]
  	{\label{fig:demo}\includegraphics[width=\linewidth]{figs/new_demo.png}}
  \caption{\small First row: Map completion with \textit{Uniform Sampling}. (a)~Ground-truth maze map. (b)~Partially observed map. The missing parts are indicated by value of $0.5$~(indicated by green color). (c)~The predicted map using LRMC model. Second row: Map completion with \textit{Blocked Uniform Sampling}. The colors have the same meaning with the first row.
  } \vspace{-10pt}
\label{fig:demo}  
\end{figure}

Different maze maps with varying ranks are generated by Daedalus\footnote{\url{http://www.astrolog.org/labyrnth/daedalus.htm}} and are shown in Fig~\ref{fig:mazes_1}. Each map has a dimension of $20m \times 20m$ with a resolution of $0.1m$, which results in a matrix with dimension of $200\times 200$. The rank values are listed in Table~\ref{tb:maze_prop}. It is easy to observe that the value of rank basically reflects the complexity of the matrix. The higher the rank is, the more complex the environment is. A typical urban building layout map would be similar to the maze with rank of 7 (as shown in Fig.~\ref{fig:mazes_1}-(b)), which is also the rank parameter we adopt in this paper. Compared with the dimension of 200, 7 is a much smaller value and therefore enables the corresponding matrix to be called as a low-rank matrix. Even the maze environment becomes super complex, such as the one shown in Fig.~\ref{fig:mazes_1}-(f), the rank value is still relatively small compared with the matrix dimension. Along with the rank values, we also list the coherence value for each maze matrix using the Eq.~(\ref{eq:coherence}). Although the coherence increases proportionally to the rank, they all stay at a low-level where we can be convinced they all are incoherent. Hence we can conclude that maze environments generally possess the low-rank and low-coherence properties required by the LRMC model. 

The sensors used in environmental monitoring are usually interfered with exogenous factors~(such as wind disturbance, magnetic field, light conditions, etc.) and endogenous factors~(such as manufacturing limitations, installation error, etc.). Consequently, the raw measurements~(samples) from sensors could be noisy and in many cases be sparse. In this section, we demonstrate the proposed LRMC based algorithm is robust to the degraded sensing measurements by considering two sampling patterns in a static map prediction scenario: \textit{Uniform Sampling}~(US) and \textit{Blocked Uniform Sampling}~(BUS). US means the observations are uniformly sampled in the mapping space at random. On the other hand, in many real scenarios, there will be some blocks are missed by the robot due to the limited sensing capability and there will be multiple regions where no any data point is sampled and BUS models this situation. Examples for map completion on a partially observed maze map with two sampling patterns are shown in Fig.~\ref{fig:demo}. Note that throughout this paper, we adopt the  SoftImpute~\cite{mazumder2010spectral} for implementing the LRMC model.

In both examples, we randomly select less-half observations and apply the LRMC model to the partial matrix. The evaluation metric we use is called \textit{total prediction accuracy}~(TPA), which indicates the correct entry matches~(including the already observed parts) between the entire predicted maze and the ground-truth maze and reflects the entire prediction completeness. The TPA results for two sampling patterns are shown in Table~\ref{tb:exam_stat}. It is clear that even with less than half of revealed/observed entries, the LRMC model could achieve an exact~(or near-exact) correct predictions. However, it is still unclear at least exactly how many samples we need to achieve an exact recovery.

\begin{table}%[h]
\caption{Statistics for Fig.~\ref{fig:demo}} %title of the table
\centering % centering table
\begin{tabular}{c rrrr} % creating eight columns
\hline\hline %inserting double-line
% Properties&\multicolumn{7}{c}{Sum of Extracted Bits} \\ [0.5ex]
  & \vline & US & BUS\\
\hline % inserts single-line
Revealed percentage~(\%) & \vline & 40.67 & 40.67\\ % Entering row contents
TPA~(\%) & \vline & 100.0 & 95.72\\
\hline % inserts single-line
\end{tabular}
\label{tb:exam_stat}
\end{table}

\begin{figure} \vspace{-6pt}
  \centering
%   \subfigure[]
  	{\label{fig:mc_curves}\includegraphics[width=\linewidth]{figs/mc_curves.png}}
  \caption{\small TPA results with different values of coefficient $C$ under \textit{Left}: US pattern and \textit{Right}: BUS pattern.
  } \vspace{-10pt}
\label{fig:mc_curves}  
\end{figure}

Some of previous works~\cite{candes2009exact} has theoretically proven a partially observed low-rank matrix could be perfectly recovered if the number of sampled entries $m$ obeys the Eq.~(\ref{eq:sampled_cond}). Although it seems that the number of observation samples are theoretically lower bounded, it is still difficult to determine the exact value of the $m$ due to the existence of $C$. To determine a proper scale of the coefficient $C$, we generate 20 maze environments with the same rank of 7 and apply the LRMC model to different partially observed mazes under US and BUS patterns and unveil the relationship between the coefficient $C$ and TPA. For each value of $C$ we compute a mean and standard deviation for TPA and the results are shown in Fig.~\ref{fig:mc_curves}.

We can think the coefficient $C$ is actually reflecting the number of observed entries according to Eq.~(\ref{eq:sampled_cond}). The higher the coefficient is, the more the observations are and the better the prediction is. From Fig.~\ref{fig:mc_curves}, we can see that for both sampling patterns, the TPA could reach a high level and stay stable when $C\geq 1.5$. Since in real applications, the sampling shows undeterminitic patterns and to be robust to this randomness, we select a value that is bigger than 1.5, 2.0 as a reference value for $C$ to achieve a desired prediction in the selected maze environment. This reference value will guide the later experiments in this paper.


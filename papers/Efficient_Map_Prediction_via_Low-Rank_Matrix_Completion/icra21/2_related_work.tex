\section{RELATED WORK}

Map prediction has been studied in occupancy mapping problems.  
Prevalent methods include Occupancy Girds Mapping~(OGM)~\cite{elfes1989using}, Gaussian Process Occupancy Mapping~(GPOM)~\cite{o2012gaussian, wang2016fast}, Hilbert Mapping~(HM)~\cite{ramos2016hilbert} and Bayesian Hilbert Mapping~(BHM)~\cite{senanayake2017bayesian}. Specifically, OGM belongs to discrete mapping and all grids are independent with each other. To eliminate the requirement of pre-defining discrete grids and the independence assumption in OGM, GPOM is proposed and used in many applications~\cite{jadidi2014exploration, jadidi2015mutual}. GPOM naturally captures the neighbouring information thanks to kernelization, but being a non-parametric model, it has a computation complexity of $O(n^3)$, where $n$ is the number of sampled data points. Combining various advantages of GPOM, a faster and simpler parametric model---HM and its Bayesian version, BHM, is proposed later to eliminate the cubical time complexity in GPOM.

Map extrapolation 
attracts increasing attention in recent years and almost all the current methods for map extrapolation are based on deep neural networks~(DNNs)~\cite{caley2019deep, pronobis2017learning, katyal2018occupancy, shrestha2019learned, saroya2020online, katyal2019uncertainty}. However, DNNs based methods require huge amount of data for training and hence are still limited in general applications. In this paper, we propose to use Low-Rank Matrix Completion to perform the map prediction. 
Our proposed LRMC based method falls in between the {interpolation} and {extrapolation} methods. Specifically, the LRMC method can not only well interpolate map values, but at the same time can  extrapolate the map structure beyond the explored areas. 

In the past two decades, the Low-Rank Matrix Completion~(LRMC) problem has been well studied. The first theoretically guaranteed exact LRMC algorithm is proposed in~\cite{candes2009exact}, where any $n \times n$ incoherent matrices of rank $r$ are proven to be exactly recovered from $C n^{1.2}r\log n$ uniformly randomly sampled entries with high probability through solving a convex problem of nuclear norm minimization~(NNM). Subsequent works~\cite{candes2010power, chen2015incoherence, gross2011recovering, recht2011simpler} refine the provable completion results following the NNM based method. However, since all of the algorithms mentioned above are based on second order methods~\cite{liu2010interior}, they can become extremely expensive if the matrix dimension is large~\cite{cai2010singular}. Some first order based methods~\cite{cai2010singular, ji2009accelerated, mazumder2010spectral} are developed later. They solve the nuclear norm minimization problem in an iterative manner and rely on Singular Value Decomposition~(SVD) of matrices and are suited to large-scale matrix completion problems. In recent years, many other techniques are developed, such as coherent matrix completion~\cite{liu2017new, bhojanapalli2014universal, chen2014coherent}, non-linear matrix completion~\cite{eriksson2012high} and adaptive sampling~\cite{chen2015completing, eftekhari2018mc2}. {\color{black}A recent survey on LRMC could be found in \cite{nguyen2019low}.}
In this paper, we mainly employ the first order SVD based iterative method, such as~\cite{mazumder2010spectral} to solve the LRMC problem. {\color{black} The SVD based methods are able to achieve low prediction error and maintain a low time complexity if certain special problem structure is appropriately leveraged~\cite{mazumder2010spectral}.}

To validate the effectiveness of our proposed model ACCA, we will generate synthetic data with groundtruth $\mathbf{P}$ and investigate the performance of estimated $\mathbf{P}$ in terms of the matching accuracy between the entities in $\mathbf{X}$ and $\mathbf{Y}$. In all numerical tests, we set the hyperparameters $\gamma_1$ and $\gamma_2$ to be $0.0001$. The initial $\mathbf{P}$ is obtained by solving the optimal matching directly using $\mathbf{X}$ and $\mathbf{Y}$ without considering the canonical correlation between the two datasets, i.e., solving the following minimization problem 
\begin{align}
\min_{\mathbf{P}}   & \left \|{\mathbf{X}} -\mathbf{YP}\right\|_F^2 +\gamma_1\|\mathbf{P}\mathbf{P}^\top -\mathbf{I}\|_F^2+\gamma_2\|\mathbf{P}^\top\mathbf{P} -\mathbf{I}\|_F^2\label{eq:initialp}
\end{align}
\noindent under the constraints specified in Eqs.\eqref{eq:con1}, \eqref{eq:con2}, and \eqref{eq:acca}. We use the \emph{scipy.optimize.minimize}  solver to find the optimal $\mathbf{P}$.

\subsection{Synthetic Data Generation}
\label{sec-Datasets}
We first generate the groundtruth latent representation of the two datasets, namely $\mathbf{Z}\in\mathbb{R}^{\bar{d}\times N}$, where the columns of $\mathbf{Z}$ are  $N$  i.i.d. samples drawn from  multivariate normal distribution with zero mean and identity covariance  of size $\bar{d}\times\bar{d} $. Next, two aligned datasets $\mathbf{X}$ and $\bar{\mathbf{Y}}\in\mathbb{R}^{D_y\times N}$ are generated from their shared latent representation $\mathbf{Z}$ through two independent random projections: $\mathbf{X}=\mathbf{W} \mathbf{Z} $ and $\mathbf{Y}=\mathbf{Q}\mathbf{Z} $ where $\mathbf{W}\in\mathbb{R}^{D_x \times \bar{d}}$ and $\mathbf{Q}\in\mathbb{R}^{D_y \times \bar{d}}$. For each experiment, the groundtruth $\bar{\mathbf{P}}$ is a random permutation matrix with only one entry in each row and column to be $1$ and the rest to be $0$s. Next, we have two \emph{unaligned} datasets: $\mathbf{X}$ and $\mathbf{Y}=\bar{\mathbf{Y}}\bar{\mathbf{P}}$. The involved parameters are set as follows: $N=20$, $\bar{d}=2$, $d=7$, $D_x=15$, and $D_y=10$.


\subsection{Experimental Results}
\label{sec-Results}
\begin{figure}[!htp]
  \includegraphics[width=0.8\linewidth]{Images/Overall_loss.pdf}
  \caption{Loss as a function of iterations}
  \label{fig:loss}
\end{figure}

After setting the entropy upper bound hyperparameter $\lambda$ to be $0.1$, we run $10$ times of Monte Carlo experiments and report the loss of Eq. \eqref{eq:acca_loss} for each iteration in Figure \ref{fig:loss}. The curve in Figure 1 represents the average loss per iteration and the width of the shade stands for the standard derivation of the loss. Clearly, our proposed ACCA converges to a stable point using the generated synthetic data.

\begin{figure}[!htp]
  \includegraphics[width=0.8\linewidth]{Images/top-K_Accuracy_entropy=0.1.pdf}
  \caption{Top-k Accuracy of ACCA and Random guess} 
  \label{fig:topk}
\end{figure}

In Figure \ref{fig:topk}, we report the top-$k$ matching accuracy with mean and standard deviation, defined as the percentage of rows in the estimated permutation $\mathbf{P}$ whose top $k$ entries' index set includes the nonzero entry index of the true permutation  $\bar{\mathbf{P}}$, with $k=1,2,3,4,$ and $5$, in comparison with such accuracy from random guess which is $k/N$.  According to our experimental records as shown in  figure \ref{fig:topk}, it's obvious that our ACCA framework has significantly better performance in predicting the potential alignment between two datasets, than that obtained from the random guess. 

\begin{figure*}[!htp]
    \subfigure[True $\mathbf{P}$]{\includegraphics[width = 0.19\textwidth]{Images/True_PI.pdf}}
    \subfigure[Entropy = 0.1; top-3 acc.: 0.519]{\includegraphics[width = 0.19\textwidth]{Images/Estimate_PI_entropy0.1.pdf}}
    \subfigure[Entropy = 0.5; top-3 acc.: 0.59]{\includegraphics[width = 0.19\textwidth]{Images/Estimate_PI_entropy0.5.pdf}}
    \subfigure[Entropy = 1; top-3 acc.: 0.575]{\includegraphics[width = 0.19\textwidth]{Images/Estimate_PI_entropy1.0.pdf}}
    \subfigure[Entropy = 2;
    top-3 acc.: 0.31]{\includegraphics[width = 0.19\textwidth]{Images/Estimate_PI_entropy2.0.pdf}}
    \caption{Estimated alignment matrix for different Entropy bounds.}
    \label{fig:alignment_matrices}
\end{figure*}

Next, we visualize the alignment performance with respect to different values of the hyperparameter $\lambda$ in Figure \ref{fig:alignment_matrices} where we plot the real permutation matrix $\bar{\mathbf{P}}$ and the estimated $\mathbf{P}$ as gray-scale images with darker grid blocks representing higher values of the corresponding entries of $\bar{\mathbf{P}}$ or $\mathbf{P}$. As uniform distribution leads to the highest entropy, $\lambda$ can not exceed $log(N)$ (=$N \times 1/N \times log(1/N)$). With  $\lambda$ increasing, more nonzero entries are showing up in $\mathbf{P}$ as expected. With proper setup of entropy bound hyperparameter, the performance of ACCA will be further improved, with the comparison of prediction accuracies related to different entropy cases in Figure \ref{fig:alignment_matrices}. 
%($=N\times 1/N \times log(1\N)$). 



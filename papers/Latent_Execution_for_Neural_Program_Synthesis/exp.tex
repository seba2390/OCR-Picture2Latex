\section{Experiments}
\vspace{-0.1in}
\label{sec:exp}
In this section, we discuss our results on synthesizing programs in Karel and C languages. We first show that {\ours} achieves competitive performance on Karel benchmark. Then we present the results on our restricted C benchmark, and demonstrate that our approach significantly outperforms existing neural program synthesis models. Finally, we discuss the effect of iterative retraining.

\begin{table}[t]
\caption{\small The comparison between {\ours} and baseline neural program synthesis models in our evaluation.}
\label{tab:approach-comparison}
\scalebox{0.9}{
\begin{tabular}{lc|ccc|cc}
\toprule
& \multirow{2}{*}{\ours}  & Exec & Shin et al. & Bunel et al. & RobustFill & Property Signatures \\
& & \cite{chen2018execution} & \cite{shin2018improving} & \cite{bunel2018leveraging} & \cite{devlin2017robustfill} & \cite{odena2020learning}  \\
\midrule
$+$ Program execution & \cmark & \cmark & \cmark &  $-$  &  $-$  &  $-$   \\
No interpreter needed & \cmark  &  $-$  &  $-$  & \cmark & \cmark & \cmark  \\
\bottomrule
\end{tabular}}
\end{table}

\vspace{-0.1in}
\subsection{Karel Program Synthesis}
\subsubsection{Evaluation Setup}
\label{sec:exp-setup-karel}

\textbf{Karel domain.} Karel is an educational programming language~\cite{pattis1981karel}, and has been studied in recent works on neural program synthesis from input-output examples~\cite{devlin2017neural,bunel2018leveraging,chen2018execution,shin2018improving}. A Karel program controls a robot in a 2D grid world. There are instructions that control the robot, e.g., \texttt{move}, \texttt{turnLeft} and \texttt{PutMarker}, as well as conditionals and loops, i.e., \texttt{if}, \texttt{repeat} and \texttt{while}. See Appendix~\ref{app:karel-details} for grammar specification and the state representation. 

We train and evaluate all models on the Karel dataset introduced in~\cite{bunel2018leveraging}. The dataset contains randomly sampled programs from the Karel DSL ($1.1M$ training samples, $2.5K$ samples in the validation set and $2.5K$ samples in the test set). Each program includes 5 input-output pairs as the specification, and the sixth pair as the held-out test case. Following the prior work, we evaluate two metrics: (1) {\bf Exact Match}: the predicted program is the same as the ground truth; (2) {\bf Generalization}: the predicted program satisfies both the input-output pairs and the held-out input-output test case.

\textbf{Baselines.} \emph{Bunel et al.}~\cite{bunel2018leveraging} designed the first program synthesis model for the Karel benchmark with a similar high-level design as RobustFill, but they use convolutional neural networks (CNN) to encode the Karel grid maps. Compared to {\ours}, this model does not utilize any program execution information, and does not include our latent executor. Instead of directly synthesizing the program from input-output examples, the model in \emph{Shin et al.}~\cite{shin2018improving} first predicts the execution traces containing the robot actions from the input-output pairs, then decodes the program based on the execution traces. This model improves the prediction performance over Bunel et al., but it requires the full execution traces for model training and an interpreter for execution. \emph{Exec}~\cite{chen2018execution} leverages the execution states of partial generated programs to guide the subsequent synthesis process, but the execution states are obtained from the Karel interpreter rather than learned by the model, thus this approach represents the ideal scenario where the partial programs could be executable.

Our model architecture for Karel is largely similar to the model for C code synthesis, except that we employ the CNN encoder in Bunel et al.~\cite{bunel2018leveraging} in our program decoder and latent executor. The comparison with baseline models is shown in the middle block of Table~\ref{tab:approach-comparison}. All models use the beam search for decoding programs, with the beam size of 64.
%Specifically, we use 2 convolutional neural networks to encode the input and output grids respectively, then apply another convolutional block to produce the vectors for the program decoder and the latent executor. 

\vspace{-0.1in}
\subsubsection{Results}
\label{sec:karel-results}

\begin{table}[t]
\begin{minipage}{0.45\linewidth}
\caption{\small Results on Karel dataset. \textbf{Gen} and \textbf{Exact} denote generalization and exact match accuracies.}
\label{tab:karel}
\begin{tabular}{lcc}
\toprule
\textbf{Approach}  & \textbf{Gen} & \textbf{Exact} \\
\midrule
\ours{} & 83.68\% & 41.12\% \\
Exec~\cite{chen2018execution} & \textbf{86.04\%} & 39.40\% \\
Bunel et al.~\cite{bunel2018leveraging} & 77.12\% & 32.17\% \\
Shin et al.~\cite{shin2018improving} & 81.30\% & \textbf{42.80\%} \\
\bottomrule
\end{tabular}
\end{minipage}
\begin{minipage}{0.5\linewidth}
    \centering
    \includegraphics[width=\linewidth]{./fig/plot_retrain_karel.png}
    \captionof{figure}{\small Generalization accuracies with different training data sizes on Karel. With the full training set, the accuracies are $86.04\%$, $89.28\%$ and $89.36\%$ for training on random programs, retraining for 1 and 2 iterations. \yuandong{Make the line thicker.} \xinyun{Updated.} }
    \label{fig:retrain-karel-acc}
\end{minipage}
\vspace{-0.3in}
\end{table}

\begin{figure}[t]
    \centering
    \begin{subfigure}[t]{0.45\linewidth}
    \includegraphics[width=\linewidth]{./fig/plot_karel_dist.png}
    \caption{}
    \label{fig:retrain-karel-dist}
    \end{subfigure}
    \begin{subfigure}[t]{0.45\linewidth}
    \includegraphics[width=\linewidth]{./fig/plot-dist-len-karel.png}
    \caption{}
    \label{fig:karel-dist-len}
    \end{subfigure}
    \vspace{-0.1in}
    \caption{\small Program distributions after iterative retraining on Karel. (a) The distributions of different program types. \emph{Seq-only}: no control flows. \emph{If-only}: the program includes If statements but no loops. \emph{Repeat/While-only}: the program includes Repeat/While loops, but no other control flow constructs. \emph{Mixture}: the program includes at least two types of control flow constructs. (b) The distributions of programs with different token lengths. \yuandong{What's the difference between xxx-only and mixture?} \xinyun{Explained.}}
    \label{fig:retrain-karel}
    \vspace{-0.2in}
\end{figure}

We present the results of {\ours} and baseline model architectures in Table~\ref{tab:karel}. First, {\ours} outperforms all baselines that do not incorporate the partial program execution information, and achieves competitive performance compared with the Exec algorithm that requires an interpreter to obtain the partial program execution states. In particular, {\ours} achieves a higher generalization accuracy than Shin et al. with lower exact match accuracy, showing that decoded programs by \ours{} are more different from randomly generated programs. Although Shin et al. also model the program execution by predicting the robot actions, the prediction of the action traces does not take the program structure into account, resulting in the inferior performance.
\vspace{-0.1em}
\subsection{C Code Synthesis}
\subsubsection{Evaluation Setup}
\label{sec:exp-c-setup}
Given the variety of C programs, we observe that the exact match accuracies of models are mostly nearly 0. Therefore, we focus on evaluating the generalization accuracy, and we consider the predicted program to be correct when it satisfies both the 5 input-output examples and 5 held-out test cases.

\textbf{Baselines.} We compare the full {\ours} with its multiple ablated versions:
\begin{itemize}[noitemsep,topsep=0pt,parsep=0pt,partopsep=0pt]%,leftmargin=*]
    \item \texttt{NoExecutor}. The program decoder (Eqn.~\ref{eq:program-decoder}) always takes the initial input-output pairs as the input; i.e,. $\hat I_t = I_0$ for every $t$.
    \item \texttt{NoPartialExecutor}. $\hat I_t = I_0=I$ for every $t$ and additionally $h_T$ is regularized so that $\mathrm{LatentExecutor}(I_0, h_T)$ matches the output $O$ under loss $\cL_{Exec}$. Therefore, no partial latent execution. 
    \item \texttt{NoOpPredictor}. The max pooling layer only takes the vectors computed by the double attention as the input (Eqn.~\ref{eq:wo-operation-predictor}).
    \item \texttt{NoAttentionInDecoding}. There is no attention over decoded program tokens, and the output of the max pooling layer is directly fed into the output softmax layer; i.e., $\mathbb{P}[p_t]=\mathrm{Softmax}(Vm_t)_{p_t}$ (compared to Eqn.~\ref{eq:d-attention}).
\end{itemize}
We also compare with existing neural program synthesis models with good performance on related tasks, as shown in the rightmost block of Table~\ref{tab:approach-comparison}. \emph{RobustFill}~\cite{devlin2017robustfill} is the state-of-the-art neural network architecture on FlashFill benchmark, which synthesizes string manipulation programs in a domain-specific language. As described in Sec.~\ref{sec:model-architecture}, the input-output encoder and the program decoder architectures in RobustFill are similar to {\ours}, except that it does not include the latent executor, operation predictor, and the attention on the decoded program sequence. \yuandong{Why we don't use Bunel et al and Shin et al for C program? We want to explain a bit. If the conceptual tables of different methods can be shown, the reasoning would be easier.} \xinyun{I added some discussion in Karel baseline description, do we need more explanation here?}

\emph{Property Signatures}~\cite{odena2020learning} was designed for synthesizing list manipulation programs in domain-specific languages, but instead of taking the raw input and output lists as the neural network input, they design some properties that distinguish different programs, then take the values of these properties as the model input. A sample property could be whether the program output is the same as the input, and the property values could be ``All True'', ``All False'', or ``Mixed'', indicating that the property always holds for any input-output pair in the specification, never holds, and holds for some pairs but not others, respectively. We customize the original design~\cite{odena2020learning} for our setting. First, our property set takes the format of $O = C + I?$ and $O = C - I?$, where $C \in [-4, 4]$. For example, $O = 2 + I?$ means whether the output $O$ could be calculated by adding $2$ to the input $I$. These properties focus more on numerical calculation, similar to our operation predictor. Second, different from the task in~\cite{odena2020learning}, our C programs sometimes manipulate only a subset of the input lists, thus encoding the list with a single property value is inappropriate. Instead, we compute the property value per element in input-output pairs, use a bi-directional LSTM to encode the property values as a sequence, then take the outputs of the bi-LSTM for program prediction.

\subsubsection{Results}

\begin{figure}
\begin{minipage}{0.25\textwidth}
\begin{minted}[fontsize=\scriptsize]{c}
int * func_1(int a[])
{
    int p_0 = 0;
    int l_25 = 4;
    a[p_0] = 1;
    --a[l_25];
    return a;
}
\end{minted}
\end{minipage}
\begin{minipage}{0.33\textwidth}
\begin{minted}[fontsize=\scriptsize]{c}
int * func_1(int a[])
{
    int p_0 = 2;
    int l_12 = 3;
    for (p_0 = 1; p_0 <= 2; p_0++)
    {
        a[p_0]--;
    }
    a[l_12] = a[l_12] + 4;
    return a;
}
\end{minted}
\end{minipage}
\begin{minipage}{0.2\textwidth}
\begin{minted}[fontsize=\scriptsize]{c}
int * func_1(int a[])
{
    int p_0 = 0;
    int l_7 = 3;
    int l_8 = 1;
    a[l_8] = (a[l_7] - a[p_0]);
    for (p_0 = 3; p_0 <= 4; p_0++)
    {
        for (int p_1 = 1; p_1 <= 2; p_1++)
        {
            a[p_1] = a[p_1] + a[p_0];
            a[p_1] = a[p_1] + 2;
        }
    }
    return a;
}
\end{minted}
\end{minipage}
\caption{\small Sample programs that could be correctly predicted by {\ours}, but wrongly predicted by models without the latent executor. These programs require multiple different operations for different input list elements.\yuandong{Any explanation why?} \xinyun{Added.}}
\label{fig:ex-c-exec}
\vspace{-0.15in}
\end{figure}

\begin{table}[t]
\begin{minipage}{0.5\linewidth}
\caption{\small Results on C dataset.}
\label{tab:c}
\centering
\begin{tabular}{lc}
\toprule
\textbf{Approach}  & Accuracy \\
\midrule
\ours{} & \textbf{55.2\%} \\
\texttt{NoAttentionInDecoding} & 53.5\% \\
\texttt{NoOpPredictor} & 53.7\% \\
\texttt{NoPartialExecutor} &  42.9\% \\
\texttt{NoExecutor} &  38.6\% \\
RobustFill~\cite{devlin2017robustfill} & 37.6\% \\
Property Signatures~\cite{odena2020learning} & 34.5\% \\
\bottomrule
\end{tabular}
\end{minipage}
\begin{minipage}{0.45\linewidth}
    \includegraphics[width=\linewidth]{./fig/plot-dist-acc-c.png}
    \captionof{figure}{\small Accuracies of different program types on C dataset.}
    \label{fig:c-acc-dist}
\end{minipage}
\end{table}
    
\begin{figure}[t]
    \centering
    \vspace{-0.1in}
    \begin{subfigure}[t]{0.45\linewidth}
    \includegraphics[width=\linewidth]{./fig/plot_retrain_c.png}
    \caption{}
    \label{fig:retrain-c-acc}
    \end{subfigure}
    \begin{subfigure}[t]{0.45\linewidth}
    \includegraphics[width=\linewidth]{./fig/plot-dist-c.png}
    \caption{}
    \label{fig:retrain-c-dist}
    \end{subfigure}
    \vspace{-0.1in}
    \caption{\small Results of iterative retraining on the C dataset. (a) Accuracies with different training data sizes. With the full training set, the accuracies are $55.2\%$, $56.0\%$ and $56.5\%$ for training on random programs, retraining for 1 and 2 iterations, respectively. (b) The program distributions after each retraining iteration.}
    \label{fig:retrain-c}
    \vspace{-0.1in}
\end{figure}

\begin{figure}[t]
    \centering
    \begin{subfigure}[t]{0.45\linewidth}
    \includegraphics[width=\linewidth]{./fig/plot-dist-len-c.png}
    \caption{}
    \label{fig:c-dist-len}
    \end{subfigure}
    \begin{subfigure}[t]{0.45\linewidth}
    \includegraphics[width=\linewidth]{./fig/plot-len-acc-c.png}
    \caption{}
    \label{fig:c-len-acc}
    \end{subfigure}
    \vspace{-0.1in}
    \caption{\small Results on programs of different token lengths on the C dataset. (a) The program token length distributions after each retraining iteration. (b) The accuracies on programs of different token lengths.}
    \vspace{-0.2in}
    \label{fig:res-c-len}
\end{figure}

Table~\ref{tab:c} presents the results, where all models are trained on the initial random programs. The full {\ours} outperforms other variants, and improves the performance of RobustFill and Property Signatures by around $20\%$. We also increase the model size of RobustFill to see if the improvement comes from larger model size, but the results are not better. In particular, the latent executor significantly increases the prediction accuracy, and achieves better results than \texttt{NoPartialExecutor}, which shows that learning latent execution traces leads to better partial program representations. In Fig.~\ref{fig:ex-c-exec}, we present sample programs that could be correctly synthesized by {\ours}, but models without the latent executor provide the wrong prediction. We observe that the latent executor is beneficial when the program involves different manipulations for different list elements, e.g., more than one For loop and different mathematical calculations. Our breakdown results on programs of different complexity also justify this observation. We first present the results on programs with different control flow constructs in Fig.~\ref{fig:c-acc-dist}. Specifically, \emph{Seq-only} includes programs with no control flow constructs, \emph{For-only} includes programs with For loops but no If statements, and \emph{Mixture} includes programs with both For loops and If statements. Then we demonstrate the results on different program lengths in Fig.~\ref{fig:c-len-acc}. We show that {\ours} achieves decent performance on long and complicated programs, while the accuracies of baseline models drop dramatically.  \yuandong{One concrete program where Neural Executor works but ``no Neural Executor'' doesn't work would be very interesting to the audience.} \xinyun{Added some examples in Fig.~\ref{fig:ex-c-exec}.}

\vspace{-0.1em}
\subsection{Discussion of Iterative Retraining}
In Fig.~\ref{fig:retrain-karel-acc}, we show the effectiveness of retraining on decoded Karel programs (Sec.~\ref{sec:iterative-retraining}). We observe that retraining for one iteration is sufficient, and it significantly improves the generalization accuracy by over $3\%$. To understand the differences between predicted programs and randomly generated programs, we demonstrate the changes of dataset distributions after each retraining iteration in Fig.~\ref{fig:retrain-karel-dist} and~\ref{fig:karel-dist-len}. We observe that the model learns to predict more concise programs than the ground truth for a large proportion of input-output examples, and considerably alters the dataset distribution so that it becomes more concentrated on short programs with simplified control flow structures. Specifically, from Fig.~\ref{fig:retrain-karel-dist}, although the initial Karel dataset seems to include a large proportion of complicated programs with different control flow constructs, our model synthesizes straight-line programs for nearly half of the samples, which means that many loops and branches in the annotated ground truth programs are unnecessary. This distribution shift also explains the gap between the exact match and generalization accuracies. The program distribution after the second retraining iteration is largely similar to the first iteration, thus retraining for more iterations does not considerably improve the performance. Note that in the second iteration, the synthesizer tends to generate slightly more complicated programs than the first iteration, in order to deal with the cases when the input-output examples oversimplify the intended program functionality. For example, sometimes the input-output examples do not cover the edge cases that the robot may encounter, thus adding additional \texttt{If} branches could avoid the crashes when testing on held-out cases.

Fig.~\ref{fig:retrain-c-acc} presents the results of retraining on decoded C programs. Similarly, retraining improves the prediction accuracy, especially when the training set is small. From Fig.~\ref{fig:retrain-c-dist} and~\ref{fig:c-dist-len}, we again observe that the model tends to predict shorter programs than the random code, and it eliminates unnecessary control flows to simplify the programs. We present more examples in Appendix~\ref{app:retrain}.





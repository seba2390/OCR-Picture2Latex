%\vspace*{0.6cm}
\section{Conclusions}
\label{sect:conclusions}

In this article we  proposed an architecture for integer approximation of the
reservoir computing, which is based on the  mathematics of  hyperdimensional
computing. The neurons in the reservoir are described by integers in the limited range and the
update operations include only addition, permutation (cyclic shift), and clipping.  Therefore, the integer Echo State Network
has substantially smaller memory footprint and higher computational efficiency
compared to the conventional Echo State Network with the same number of neurons in
the reservoir. The actual number of bits for representing a neuron depends on
the clipping threshold $\kappa$, but can be significantly lower than 32-bit floats in Echo State Network. For example, in our experiments the results were
obtained with $\kappa=3$ and $\kappa=7$, which effectively makes it sufficient to represent a
neuron with only three or four bits respectively. We demonstrated that the performance of the integer Echo State Network is
comparable to the conventional Echo State Network in terms of memory capacity, potential capabilities for classification of time-series and modeling dynamic systems. 
The better performance was observed when the memory footprint of reservoir of the integer Echo State Network was set to that of the conventional Echo State Network.
%{\color{red}
The experiment on the digital hardware have validated the amenability of the integer Echo State Network for significantly improving the energy efficiency of computations. 
%}
Further improvements can be made by optimization of the parameters and better quantization schemes for handling continuous values.
 Naturally, due to the
peculiarity of input data projection into the integer Echo State Network, the performance of the
network 
in tasks for modeling dynamic systems
is to a certain degree lower than that of the  conventional Echo State Network. This,
however, does not undermine the importance of integer Echo State Networks,  which are  extremely
attractive for memory and power savings, and in the general
area of approximate computing,  where errors and  approximations are becoming
acceptable as  long as the outcomes have a well-defined statistical behavior. 
%\cite{HDNP17}.


%\textbf{Acknowledgements.} This study  is  supported in part  by the Swedish
%Research Council (grant no. 2015-04677).
%The authors thank Ozgur Yilmaz for fruitful discussions during BICA2016 on the
%usage of cellular automata in the scope of hyperdimensional computing, which
%inspired the current work and Niklas Karvonen  for general discussions on
%cellular automata.

\subsection{Speedup over Cholesky Decomposition}
\label{sec:experiments-whitened}
We examine the speedup of HIP-GP's whitening strategy over the
Cholesky whitening strategy in standard SVGP,
by comparing the time for solving the correlation term $\bk_n$.
We generate 200 random 1D observations, and
evenly-spaced inducing grids of size $M$ ranging from $10^3$ to $10^6$.
We apply a set of kernels including the Matérn kernels with $\nu = 0.5, 1.5, 2.5$ and the
squared exponential kernel. The marginal variance is fixed to $0.1$ for all $M$.
The length scale is set to $L/M$ where $L$ is the range of the data domain to utilize the inducing points efficiently.
The PCG within the HIP-GP algorithm is run to convergence at tolerence 1e-10.
The Cholesky decomposition is only available up to $M=10^4$ due to the memory limit.
All experiments are run on a NVIDIA Tesla V100 GPU with 32GB memory.

We report the wall clock time of computations applied to Matérn ($2.5$) kernel in Tabel~\ref{tab:whitened-time}.
The full report for all settings is presented in appendix.
HIP-GP's whitening strategy is consistently  faster than the 
 Cholesky whitening strategy across all experiments, and scales to larger $M$.

\begin{table}[t!]%{\columnwidth}
  \centering
  \scalebox{.8}{\input{figures/whitening/Mat52-wallclock.tex}}
  \caption{Whitening time comparison (second) of HIP-GP v.s. SVGP with Matérn($2.5$) kernel.}
  \label{tab:whitened-time}
\end{table}

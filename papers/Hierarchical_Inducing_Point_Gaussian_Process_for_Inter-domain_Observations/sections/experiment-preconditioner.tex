\subsection{Effect of the Preconditioner}
\label{sec:experiments-preconditioner}
We first examine the effect of the preconditioner developed in Section
~\ref{sec:toeplitz-preconditioner}.
We run CG and PCG with the preconditioner for systems
of size $M=625~(25\times25)$, $M=2{,}500~ (50\times50)$, and $M=10{,}000~(100
\times 100)$ determined by a two-dimensional grid applied to the Mat\'ern
kernel.  We run the algorithm to convergence (at tolerance 1e-10) for $25$
randomly initialized vectors of size $M$.  We record the error at each
iteration --- the norm of the distance between the current solution and the
converged solution.

We report the RMSE at each iteration in Figure~\ref{fig:preconditioner}.
We rescale the $x$-axis to run from 0 to 1 for each system of size $M$.
%--- each PCG-to-CG error curve is comparable for a fixed $M$.
From this experiment we see two results: the Toeplitz
preconditioner is extremely effective and the preconditioner seems to be more
effective as the system size \emph{becomes larger}.
%(which is theoretically sensible but a discussion of which is beyond the scope of this paper).
The fraction of CG iterations required for PCG to converge for
$M=10{,}000$ ($<4.5\%$) is much smaller than the fraction of iterations
required for $M=625$ ($<18\%$) to converge.
Without this preconditioner, we would expect each HIP-GP iteration
to take over twenty times longer to achieve similar precision.

\begin{figure}[t!]
  \centering
  \includegraphics[width=.8\columnwidth]{figures/preconditioner/cg-pcg-comparison-mse.png}
  \caption{Convergence result of PCG v.s. CG.
  %The circulant inverse preconditioner improves PCG convergence.
	  We compare PCG to standard CG for systems of size $M=625, 2{,}500$
    and $10{},000$ over 25 independent runs.  We report RMSE as a
	  function of the fraction of \emph{total CG iterations} (to converge).
    PCG converges faster than CG, and for larger $M$ fewer
	  iterations are required.
	}
  \label{fig:preconditioner}
  %\vspace{-1em}
\end{figure}


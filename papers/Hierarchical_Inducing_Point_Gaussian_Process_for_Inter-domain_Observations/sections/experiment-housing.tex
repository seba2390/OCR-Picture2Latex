%\subsubsection{Spatial analysis: UK housing prices}
\subsection{Spatial Analysis: UK Housing Prices}
Now we test HIP-GP on a standard GP problem,
i.e., the transformation $\mathcal{L}$ is an identity map.
We apply HIP-GP to (log) prices of apartments as a function of latitude and
longitude in England and Wales\footnote{HM land registry price paid data
available
\href{https://ckan.publishing.service.gov.uk/dataset/land-registry-monthly-price-paid-data}
{here}.}.  The data include 180{,}947 prices from 2018, and we train on
160{,}947 observations and hold out 20{,}000 to report test error.
We use the standard SVGP as baseline.


\paragraph{Scaling Inducing Points}
We run HIP-GP on an increasingly dense grid of inducing points $M$.
In all experiments, we use the Mat√©rn ($2.5$) kernel
 and apply the block-independent variational family with
neighboring block size $M_b = 100~(10\times10)$  for HIP-GP and SVGP.
The maximum number of PCG iterations within HIP-GP is set to 20 and 50
for training and evaluation.
The predictive performance measured by RMSE and the training time are 
displayed in Figure~\ref{tab:housing-table}.
From this result, we conclude that
(i) increasing $M$ improves prediction quality;
(ii) the performance of HIP-GP is almost indistinguishable to that of
SVGP given the same $M$. (iii) Again, HIP-GP runs faster than SVGP and scales to larger $M$. 
The best prediction of HIP-GP is
depicted in Figure~\ref{fig:housing-mu} and \ref{fig:housing-sig}.


\begin{figure}
\centering
\begin{subfigure}{.48\columnwidth}
  \includegraphics[width=\textwidth]{figures/uk-housing/uk-fmu.png}
  \caption{Posterior mean}
	\label{fig:housing-mu}
\end{subfigure}
~
\begin{subfigure}{.48\columnwidth}
  \includegraphics[width=\textwidth]{figures/uk-housing/uk-fsig.png}
  \caption{Posterior st.~dev.}
  \label{fig:housing-sig}
\end{subfigure}

%\begin{subfigure}{\columnwidth}
%  \centering
%  \scalebox{.8}{
%  \input{figures/uk-housing/M-RMSE-func=hard.tex}
%  }
%	\caption{Predictive RMSE for 20{,}000 test data.}
%	\label{tab:housing-table}
%\end{subfigure}
%\caption{UK Housing Analysis}
%\label{fig:uk-housing}

\begin{subfigure}{\columnwidth}
  \centering
  \scalebox{.7}{
  \input{figures/uk-housing/uk-more-inducing-point.tex}
  }
	\caption{Top row: predictive RMSE. Bottom row: average training time (second) per epoch.}
	\label{tab:housing-table}
\end{subfigure}
\caption{UK Housing Analysis}
\label{fig:uk-housing}
\end{figure}

\paragraph{PCG Iteration Early Stopping}
Additionally, we examine the effect of the maximum number of PCG iterations
when computing $\bk_n$ on approximation
quality.  Figure~\ref{fig:pcg-iter} depicts test
RMSE as a function of PCG iteration for $M = 14{,}400$
on the test dataset of size $N=20{,}000$.
The final approximation quality is robust to the number of PCG iterations used.
The upshot is that HIP-GP needs only a small number of PCG iterations
to be effective. %This early stopping advantage is consistent with conventional
%wisdom in the optimization literature.

\begin{figure}[t!]
  \centering
  \includegraphics[width=.9\columnwidth]{figures/uk-housing/uk-pcg-earlystopping.png}
  \caption{Stochastic optimization is robust to early stopping
     of PCG iterations.
     %Because of this, we can stop after only 5 to 10 iterations, saving on
     %computation time per iteration.
  }
  \label{fig:pcg-iter}
  %\vspace{-1em}
\end{figure}

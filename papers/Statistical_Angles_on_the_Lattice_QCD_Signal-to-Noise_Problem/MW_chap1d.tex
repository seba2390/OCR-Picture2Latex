\section{Probability Distributions of Correlation Functions}

Parisi-Lepage

Log-normal


%
%Modern nuclear physics research relies upon large-scale high-performance computing  (HPC) to predict the 
%properties of a diverse array of many-body systems, ranging from the properties of hadrons computed 
%from the dynamics of quarks and gluons, 
%through to the form of gravitational waves emitted from inspiraling binary neutron star systems.
%In many cases,
%the entangled quantum nature of these systems and the nonlinear dynamics that
%define them, preclude analytic calculation of their properties. 
%In these cases, precise numerical evaluations of high-dimensional integrations 
%that systematically approach the quantum path integral are required.
%Typically, it is average quantities that are determined by Monte Carlo (MC) path integral evaluations.
%These average values are 
%to be used subsequently in direct comparison with experiment, 
%as input to analytic frameworks with outputs that can then be compared with experiment, 
%or as predictions for critical components of systems that are inaccessible to experiment 
%such as the equation of state of dense matter in explosive astrophysical environments.
%Enormous amounts of HPC resources are used in such MC calculations to determine average values of quantities and their uncertainties.
%The central limit theorem, and in particular the 
%$1/\sqrt{N}$ scaling anticipated for the uncertainties associated with average values, are used to make estimates of projected resource requirements.
%When a system has  a ``sign problem'',  for which the average value of a quantity of interest results from cancellations of (relatively) 
%large contributions, such as found when averaging $e^{i\theta}$, the HPC resources required for accurate numerical estimates of the average(s) 
%are prohibitively large.  
%This is the case for numerical evaluations of the path integrals describing strongly interacting systems with even a modest 
%non-zero net baryon number.
%
%
%While the quantum fluctuations (noise) 
%of many-body systems contain a wealth of information beyond average values, only a relatively small amount of 
%attention has been paid to refining calculations based upon the structure of the noise.
%This statement, of course, does not do justice to the fact that all observables (S-matrix elements)
%in quantum field theory calculations can be determined from vacuum expectation values of products of quantum fields.
%However, in numerical calculations, it is generally the case that  noise is treated as a nuisance,
%something to reduce as much as needed, 
%as opposed to a feature that may reveal aspects of systems that are obscured through distribution 
%among many expectation values.
%In the area of Lattice Quantum Chromodynamics (LQCD), 
%which is the numerical technique used to evaluate the quantum path integral associated with Quantum Chromodynamics (QCD) that 
%defines the dynamics of quarks and gluons, 
%limited progress has been made toward understanding the structure of the noise in correlation functions and the physics that it contains.
%
%
%
%Strongly interacting quantum systems can be described through path integral representations of correlation functions. In principle, MC evaluation of lattice regularized path integrals can solve QCD as well as many strongly interacting atomic and condensed matter theories. In practice, conceptual obstacles remain and large nuclei and nuclear matter are presently inaccessible to LQCD. 
%In the grand canonical formulation, LQCD calculations with non-zero chemical potential face a sign problem where MC 
%sampling weights are complex and cannot be interpreted as probabilities. In the canonical formulation, calculations with non-zero baryon number face a Signal-to-Noise (StN) problem where statistical uncertainties in MC results grow exponentially at late times. 
%Like the sign problem, the StN problem arises when the sign of a correlation function can fluctuate, at which point cancellations allow for a mean correlation function of much smaller magnitude than a typical MC contribution.
%
%
%The nucleon provides a relatively simple and well-studied example of a complex correlation function with a StN problem. The zero-momentum Euclidean nucleon correlation function $C(t)$ is guaranteed to have a real mean value by existence of a Hermitian, bounded transfer matrix and the spectral representation
%%
%\begin{equation}
%  \avg{ C(t) } = \sum_{\v{x}} \avg{ N(\v{x},t) \bar{N}(0) } = \sum_{n=0}^\infty \tilde{Z}_n Z^\dagger_n e^{-E_n t} \sim e^{- m_N t}
%     \ \ \ ,
%  \label{Cdef}
%\end{equation}
%%
%where $\bar{N}$ and $N$ are nucleon creation and annihilation interpolating operators, $\tilde{Z}_n^\dagger$ 
%and $Z_n$ represent the overlap of these interpolating operators onto the $n$-th QCD eigenstates with 
%quantum numbers of the nucleon, $E_n$ is the energy of the corresponding eigenstate, $t$ is Euclidean time, 
%$m_N$ is the nucleon mass, and  
%throughout this work $\sim$ denotes proportionality in the limit $t\rightarrow \infty$. A phase convention for creation and annihilation operators is assumed so that $C(0)$ is real for all correlation functions in a statistical ensemble. At early times $C(t)$ is approximately real, but at late times it must be treated as a complex quantity. 
%The equilibrium probability distribution for $C(t)$ can be formally defined as
%%
%\begin{equation}
%  \mathcal{P}\left( C(t) \right) = Z^{-1}\  \int \mathcal{D}U\; e^{-S(U)}\delta(C(t;U) - C(t))
% \qquad  \ \ {\rm with} \ \  \qquad
%  Z\ =\  \int \mathcal{D}U\; e^{-S(U)}
%   \ \ \ ,
%  \label{correlation functionprobdef}
%\end{equation}
%%
%where $U$ is a gauge field, $C(U;t)$ is the nucleon correlation function in the presence of a background gauge field 
%$U$, $\mathcal{D}U$ is the Haar measure for the gauge group, and $S(U)$ is the gauge action arising after all 
%dynamical matter fields have been integrated out. 
%For convenient comparison with LQCD results, a lattice regulator 
% with a lattice spacing equal to unity will be assumed throughout. 
%Unless specified, results will not depend on details of the ultraviolet regulation of $\mathcal{P}(C(t))$.
%
%
%
%MC integration of the path integral representation of a partition function, as performed in LQCD calculations, provides a 
%statistical ensemble of background quantum fields. 
%Calculation of $C(U;t)$ in each background field provides a statistical ensemble of correlation functions distributed according to $\mathcal{P}(C(t))$. Understanding the statistical properties of this ensemble is essential for efficient MC calculations, 
%and  significant progress has been achieved in this direction since the early days of lattice field theory. 
%Following Parisi~\cite{Parisi:1983ae}, Lepage~\cite{Lepage:1989hd} argued that $C(t)$ has a StN problem 
%where the noise, or square root of the variance of $C(t)$, becomes exponentially larger than the signal, 
%or average of $C(t)$, at late times. 
%It is helpful to review the pertinent details of Parisi-Lepage scaling of the StN ratio.
%
%
%
%Higher moments of $C(t)$ are themselves field theory correlation functions with well-defined spectral 
%representations.~\footnote{
%The $n$-th moment $\avg{C(t)^n}$ represents the $n$-nucleon nuclear correlation function in the absence of 
%Pauli exchange between quarks in different nucleons. 
%This is formally a correlation function in a partially-quenched theory with $nN_f$ valence quarks and $N_f$ sea quarks. 
%In general, such a theory is guaranteed to have a bounded, but not necessarily Hermitian, transfer matrix~\cite{Bernard:2013kwa}. 
%}
%Their late-time behavior is a single decaying exponential whose scale is set by the lowest energy state with appropriate quantum numbers. Assuming that matter fields have been integrated out exactly rather than stochastically, $C(t)^\dagger C(t)$ will contain three valence quarks and three valence antiquarks whose net quark numbers are separately conserved. 
%This does not imply that $|C(t)|^2$ will only contain nucleon-antinucleon states, as nothing prevents these distinct valence quarks and antiquarks from forming lower energy configurations such as three pions. 
%Quadratic moments of the correlation function, therefore, have the asymptotic behavior
%%
%\begin{equation}
%  \begin{split}
%    \avg{C(t)^2} \sim e^{-2m_N t}\ \ \ ,
%    \hspace{20pt}
%     \avg{|C(t)|^2} \sim e^{-3m_\pi t}
%    \ \ \ \ .
%  \end{split}\label{C2Lepage}
%\end{equation}
%%
%At late times, the nucleon StN ratio is determined by the slowest-decaying moments at late times, taking the form,
%%
%\begin{equation}
%  \begin{split}
%    \frac{\avg{C(t)}}{\sqrt{\avg{|C(t)|^2}}} \sim e^{-\left( m_N - \frac{3}{2}m_\pi \right)t}
%    \ \ \  .
%  \end{split}\label{Lepage}
%\end{equation}
%%
%and is therefore exponentially small.~\footnote{
%A generalization of the Weingarten-Witten QCD mass inequalities~\cite{Weingarten:1983uj,Witten:1983ut} 
%by Detmold~\cite{Detmold:2014iha} proves that $m_N \geq \frac{3}{2}m_\pi$. 
%Assuming that interaction 
%energy shifts in the three-pion states contributing to the variance correlation function are negligible,
%the nucleon StN ratio is therefore exponentially small for all quark masses. 
%}
%The quantitative behavior of the variance of baryon correlation function  in 
%LQCD calculations was investigated in high-statistics studies by the NPLQCD collaboration~\cite{Beane:2009kya,Beane:2010em,Beane:2014oea} and more recently by Detmold and Endres~\cite{Detmold:2014rfa,Detmold:2014hla}, and was 
%found to be roughly consistent with Parisi-Lepage scaling. 
% One of us~\cite{Savage:2010misc} 
% extended Parisi-Lepage scaling to higher moments of $C(t)$ and showed that all odd moments 
% of $C(t)$ are exponentially suppressed compared to even moments at late times. 
% Nucleon correlation function distributions are increasingly broad and symmetric with exponentially 
% small StN ratios at late times, as seen, for example, in histograms of the real parts of LQCD 
% correlation functions in Ref.~\cite{Beane:2014oea}.
%
%Beyond moments, the general form of correlation function distributions has also been investigated. 
%Endres, Kaplan, Lee, and Nicholson~\cite{Endres:2011jm} found that correlation functions in the 
%nonrelativistic quantum field theory describing unitary fermions possess approximately log-normal distributions. 
%They presented general arguments, that are discussed below, suggesting that this behavior might be a generic feature of 
%quantum field theories. 
%Knowledge of the approximate form of the correlation function distribution was exploited to construct an improved estimator, the cumulant expansion, that was productively applied to subsequent studies of unitary 
%fermions~\cite{Endres:2011er,Endres:2011mm,Lee:2011sm,Endres:2012cw}. 
%Correlation function distributions have been studied analytically in the Nambu-Jona-Lasinio 
%model~\cite{Grabowska:2012ik,Nicholson:2012xt}, where it was found that real correlation functions were approximately log-normal but complex correlation functions in a physically equivalent formulation of the theory were broad and symmetric at late times with qualitative similarities to the QCD nucleon distribution. 
%DeGrand~\cite{DeGrand:2012ik} observed that meson, baryon, and gauge-field correlation functions in 
%$SU(N_c)$ gauge theories with several choices of $N_c$ are also approximately log-normal at early times where 
%imaginary parts of correlation functions can be neglected. 
%These various observations provide strong empirical evidence that the distributions of real correlation functions in 
%generic quantum field theories are approximately log-normal. 
%
%
%A generalization of the log-normal distribution for complex random variables that approximately 
%describes the QCD nucleon correlation function at late times is presented in this work. 
%To study the logarithm of a complex correlation function, it is useful to introduce the magnitude-phase decomposition 
%%
%\begin{equation}
%  \begin{split}
%    C(t) = |C(t)|e^{i\theta(t)} = e^{R(t) + i\theta(t)}
%    \ \ \ \ .
%  \end{split}\label{RThdef}
%\end{equation}
%%
%At early times where the imaginary part of $C(t)$ is negligible, previous observations of log-normal correlation 
%functions~\cite{DeGrand:2012ik} demonstrate that $R(t)$ is approximately normally distributed. It is shown below that 
%$R(t)$ is approximately normal at all times, and that $\theta(t)$ is approximately normal at early times. 
%Statistical analysis of $\theta(t)$ is complicated by the fact that it is defined modulo $2\pi$. 
%In particular, the sample mean of a phase defined on $-\pi < \theta(t) \leq \pi$ does not necessarily provide a faithful 
%description of the intuitive average phase (consider a symmetric distribution peaked around 
%$\pm\pi$ with a sample mean close to zero). 
%Suitable statistical tools for analyzing $\theta(t)$ are found in the theory of circular statistics and as will 
%be seen below that $\theta(t)$ is described by an approximately wrapped normal distribution.~\footnote{
%See Refs.~\cite{Fisher:1995,Borradaile:2003,Mardia:2009} for 
%textbook introductions to circular statistics.
%} 
%This work is based on a high-statistics analysis of 500,000 nucleon correlation functions 
%generated on a single ensemble of gauge-field configurations by the NPLQCD collaboration~\cite{Orginos:2015aya} with LQCD.
%This ensemble has a pion mass of $m_\pi \sim 450\text{ MeV}$, physical strange quark mass, 
%lattice spacing $\sim 0.12$ fm, and spacetime volume $32^3\times 96$. 
%The L{\"u}scher-Weisz gauge action~\cite{Luscher:1984xn} and $N_f = 2+1$ clover-improved 
%Wilson quark actions~\cite{Sheikholeslami:1985ij} were used to generate these ensembles,
%details of which can be found in Ref.~\cite{Orginos:2015aya}.
%Exploratory data analysis of this high-statistics ensemble plays a central role below.
%
%
%
%Sec.~\ref{sec:standard} discusses standard statistical analysis methods in LQCD that introduce concepts used below.
%In Section~\ref{sec:decomposition}, 
%the magnitude-phase decomposition of the nucleon correlation function and connections to the StN problem are discussed. 
%Section~\ref{sec:magnitude} describes the distributions of the log-magnitude and its time derivative in more detail,
%while Section~\ref{sec:phase} describes the distribution of the complex phase and its time derivative and explains how their features lead to systematic bias in standard estimators during a late-time  region that is dominated by noise. 
%Section~\ref{sec:estimator} draws on these observations to propose an estimator for the nucleon mass in which this 
%systematic bias can be controlled and the associated statistical uncertainties are constant at late times instead of exponentially increasing. 
%Section~\ref{sec:conclusion} conjectures about applications to the spectra of generic complex correlation functions and concludes.
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\section{Relevant Aspects of Standard Analysis Methods of Correlation Functions}\label{sec:standard}
%
%Typically, in calculations of meson and baryon masses and  their interactions, 
% correlation functions are generated  from combinations of quark- and gluon-level  
%sources and sinks with the appropriate hadron-level quantum numbers.  
%Linear combinations of these correlation functions are formed, 
%either using Variational-Method type techniques~\cite{Luscher:1990ck}, 
%or Matrix-Prony~\cite{Beane:2009kya},
%or other less automated methods,
%in order to optimize overlap onto the lowest lying states in the spectrum 
%and establish extended plateaus in 
%relevant effective mass plots (EMPs).
%In the limit of an infinite number of independent measurements, 
%the expectation value of the correlation function is a real number at all times, and 
%the imaginary part can be discarded as it is known to average to zero. 
%The late time behavior of such correlation functions 
%becomes a single exponential (for an infinite time-direction) with an argument determined by the ground-state energy associated with the particular quantum numbers, or more generally the energy of the lowest-lying state with non-negligible overlap.
%
%The structure of the source and sink play a crucial role in determining the utility of sets of correlation functions.
%For many observables of interest, it is desirable to optimize the overlap onto the ground state of the system, and to minimize the overlap onto the correlation function dictating the variance of the ground state.
%In the case of the single nucleon, the sources and sinks, ${\cal O}$,  
%are tuned in an effort to have maximal overlap onto the ground-state nucleon, while minimizing overlap 
%of ${\cal O}{\cal O}^\dagger$ onto the three-pion ground state~\cite{Detmold:2014rfa}.
%NPLQCD uses  momentum projected hadronic blocks generated from quark propagators 
%originating from localized smeared sources to suppress the overlap into the three-pion ground state by a factor of 
%$1/\sqrt{V}$ where $V$ is the lattice volume, e.g. Ref.~\cite{Beane:2009kya}.  
%For such constructions, the variance of the average scales as
%$\sim  e^{- 3 m_\pi t}/(V N)$ at large times, 
%where $N$ is the number of statistically independent correlation functions,
%while the nucleon correlation function scales as $\sim e^{- M_N t}$.
%For this set up, the StN ratio scales as $\sim \sqrt{V N} e^{ - (M_N - 3 m_\pi/2) t}$, from which it is clear that 
%exponentially large numbers of correlation functions or volumes are required to overcome the StN problem at large times.
%However, the situation is quite different at short and intermediate times in which the variance correlation function is dominated, not by the three-pion ground state, but by the nucleon-antinucleon excited state, which provides a variance contribution that scales as $\sim  e^{- 2 m_N t}/N$.  
%There is a time interval where the StN ratio is not degrading exponentially, and it is in this interval, which has been dubbed the ``Golden Window''~\cite{Beane:2009kya}, where calculations of the lowest-lying states of the nucleon 
%and light nuclei have been  performed. 
%The variance in this time interval is generated, in part, by the distribution of overlaps of the source and sink onto the ground state, that differs at each lattice site due to variations in the gluon fields.
%
%
%
%%
%\begin{figure}[!ht]
%	\includegraphics[width=0.45\columnwidth]{xiemp.pdf}\ \ \ \ \ \ 
%	\includegraphics[width=0.45\columnwidth]{StNplot.pdf}
%	\caption{
%	\label{fig:xiemp} 
%	The EMP associated with the $\Xi$-baryon correlation function with $\Delta t=2$ (left panel)
%	and the energy scale associated with the standard deviation of the ground state energy (right panel).
%	This correlation function  is a tuned linear combination 
%	of those resulting from localized smeared and 
%	point sinks and from a localized smeared source at a pion mass of $m_\pi\sim 450~{\rm MeV}$
%	calculated  from 96 sources per configuration on 3538 statistically independent isotropic clover gauge-field 
%	configurations~\protect\cite{Orginos:2015aya}.	  
%	They have been blocked together to form 100 independent samplings of the combined correlation function.
%	The red dashed line in the right panel corresponds to the lowest energy contributing to the StN ratio that is expected to dominate at large times.
%	}		
%\end{figure}
%%
%EMPs, such as that associated with the $\Xi$-baryon shown in Fig.~\ref{fig:xiemp},
% are formed from ratios of correlation functions, which become constant when only 
%a single exponential is contributing to the correlation function,
%%
%\begin{eqnarray}
%\ln\left[ {\langle C_i(t) \rangle \over \langle C_i(t+\delta t) \rangle}  \right] & \rightarrow & E_i \delta t
%\label{eq:emdef}
%\ \ \ ,
%\end{eqnarray}
%%
%where $E_i$ is the ground state energy in the channel with quantum numbers denoted by ``$i$'',
%and $\langle C_i(t) \rangle$ is the average  of the correlation function at time $t$ away from the source.
%The average is over  correlation functions derived from multiple source points on multiple gauge-field configurations.
%This is well-known technology and is a ``workhorse'' in the analysis of LQCD calculations.
%Typically, $\delta t $ corresponds to one temporal lattice spacing, and the jackknife and bootstrap resampling techniques are used to generate covariance matrices in the plateau interval used to extract the 
%ground-state energy from a correlated $\chi^2$-minimization~\cite{DeGrand:1990ss,Beane:2010em,Beane:2014oea}.~\footnote{
%For pedagogical introductions to LQCD uncertainty quantification with resampling methods, 
%see Refs.~\cite{Young,DeGrand:1990,Luscher:2010ae,Beane:2014oea}.
%}
%The energy can be extracted from an exponential fit to the correlation function or by a direct fit to the effective mass itself.
%Because correlation functions generated from the same, and nearby, gauge-field configuration are correlated,
%typically they are blocked to form one average correlation function 
%per configuration, and  blocked further over multiple configurations, to create an smaller ensemble 
%containing (approximately) statistically independent samplings of the correlation function.    
%
%
%
%
%It is known that  baryon correlation functions contain outliers over $\sim m_\pi^{-1}$ time scales, 
%as shown in the Fig.~\ref{fig:ReCdist}, which
%contribute significantly to off-diagonal elements in covariance matrices generated 
%from averages  through either jackknife or bootstrap resampling.  
%%
%\begin{figure}[!ht]
%	\includegraphics[width=0.3\columnwidth]{cdist6.pdf}\ \ \ 
%	\includegraphics[width=0.3\columnwidth]{cdist16.pdf}\ \ \ 
%	\includegraphics[width=0.3\columnwidth]{cdist24.pdf}
%	\caption{
%	\label{fig:ReCdist} 
%	The distribution of the real part of
%	$10^3$ nucleon correlation functions at time slices $t=6$ (left panel), $t=16$ (middle panel) and $t=24$ (right panel).
%	}		
%\end{figure}
%%
%As $\delta t $ is increased  beyond 
%$\sim m_\pi^{-1}$, covariance matrices become increasingly diagonal as 
%the values of correlation functions on separated time slices 
%become  de-correlated, as shown in Fig.~\ref{fig:jugemean}.
%%
%\begin{figure}[!ht]
%	\includegraphics[width=0.9\columnwidth]{tJplotMeanCombo.png}
%	\caption{
%	\label{fig:jugemean} 
%	The inverse covariance matrix in the plateau region of the $\Xi$-baryon EMP,
%	starting at time-slice $t_0$, 
%	for $\delta t=1,2,3,4$ (from left to right).  
%	The correlation function is the same as that described in the caption of Fig.~\protect\ref{fig:xiemp}.
%	In each case, a plateau length of 10 time-slices results in an acceptable value of $\chi^2$/dof from a correlated fit.
%	The matrix was determined using Jackknife resampling with the average of  sampled functions to determine each element.
%	}		
%\end{figure}
%%
%The utility of robust estimators, such as the median and the Hodges-Lehmann estimator, with reduced sensitivity to outliers, 
%has been explored in Ref.~\cite{Beane:2014oea}.  
%When the median and  average of a function are known to coincide,   
%there are advantages to using 
%the median or Hodges-Lehmann estimator
% to determine the average of a distribution. 
% The associated uncertainty can be estimated with the ``median absolute deviation'' (MAD), and be related to the 
% standard deviation with a well-known scaling factor.
%%
%\begin{figure}[!ht]
%	\includegraphics[width=0.9\columnwidth]{tJplotHLCombo.png}
%	\caption{
%	\label{fig:jugeHL} 
%	The inverse covariance matrix in the plateau region of the $\Xi$-baryon EMP,
%		starting at time-slice $t_0$,  for $\delta t=1,2,3,4$ (from left to right).  
%	The correlation function is the same as that described in the caption of Fig.~\protect\ref{fig:xiemp}.
%	In each case, a plateau length of 10 time-slices results in an acceptable value of $\chi^2$/dof from a correlated fit. The matrix was determined with the Hodges-Lehmann estimator and the median.
%	}		
%\end{figure}
%%
%The inverse covariance matrix associated with the Hodges-Lehmann estimator is shown in Fig.~\ref{fig:jugeHL}.
%Importantly, 
%it has been shown by David Kaplan, using a set of NPLQCD baryon correlation functions,
%that the distribution of late time correlation functions is consistent with a 
%stable distribution~\cite{davidkaplanLuschertalk}.
%
%
%
%
%
%
%
%
%
%

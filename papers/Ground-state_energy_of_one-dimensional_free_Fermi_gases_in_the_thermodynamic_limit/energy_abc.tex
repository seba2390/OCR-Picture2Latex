In order to define a self-adjoint differential operator on an interval one has to ensure
that the boundary terms obtained via integration by parts vanish. That is to say one has to impose
boundary conditions. We reformulate that in an abstract framework. Let 
\begin{equation}\label{abc_H_tilde}
  \tilde H:\dom(\tilde H)\to\hilbert,\   \dom(\tilde H)\subset\hilbert
\end{equation}
be a densely defined linear operator and let $\Gamma_{1,2}:\dom(\tilde H)\to\C^n$, $n\in\N$, be surjective linear maps
such that
\begin{equation*}
  (\varphi,\tilde H\psi) - (\tilde H\varphi,\psi)
    = (\Gamma_1\varphi,\Gamma_2\psi) - (\Gamma_2\varphi,\Gamma_1\psi),\ \varphi,\psi\in\dom(\tilde H) .
\end{equation*}
We study restrictions $H$ of $\tilde H$ given by boundary conditions
\begin{equation}\label{abc_H}
  \dom(H) \coloneqq \{\varphi\in\dom(\tilde H)\mid (A\Gamma_1-B\Gamma_2)\varphi=0 \},\
    H \coloneqq \tilde H|_{\dom(H)}
\end{equation}
with $n\times n$ matrices $A,B:\C^n\to\C^n$. 
For $H$ to be self-adjoint it is necessary that $A$ and $B$ satisfy
\begin{equation}\label{abc_condition}
  AB^* = BA^*,\ \rank(A\mid B)=n
\end{equation}
where $(A\mid B)$ is the $n\times 2n$-matrix formed by the columns of $A$ and $B$.
The matrices $A$ and $B$ are not uniquely determined since we can multiply them on the left by an invertible matrix
without altering \eqref{abc_H} and \eqref{abc_condition}.
It is shown in \cite{BehrndtLanger2010}, that all self-adjoint restrictions of $\tilde H$ are given in this way
if at least one operator $H$ is self-adjoint (for ordinary differential operators \eqref{abc_condition} already
appeared in \cite[9.4]{Ince1926}, and \cite[II.2.2]{Hellwig1964}).
From this one can deduce that
\begin{gather}\label{abc_deficiency_index}
  \dim\ker(z\id-\tilde H) = n\in\N, z\in\C\setminus\R \\
  \label{abc_deficiency_subspace}
  \mathcal{N}_z \coloneqq \ker(z\id-\tilde H) = \mathspan\{ \varepsilon_1(z),\ldots, \varepsilon_n(z)\} .
\end{gather}
Actually, these are the deficiency subspaces of a certain symmetric operator which, however, is not
needed herein and therefore omitted. We note some simple properties.

\begin{lemma}\label{abc01t}
We have $\ker(A^*)\cap\ker(B^*)=\{0\}$. Furthermore, the operators
$\Gamma_{1,2}|_{\mathcal{N}_z}$ and $(A\Gamma_1-B\Gamma_2)|_{\mathcal{N}_z}$ are
injective for all $z\in\C\setminus\R$.
\end{lemma}
\begin{proof}
First note the general equality
\begin{equation*}
  \ker(A^*)\cap\ker(B^*) = (\ran(A))^\perp \cap (\ran(B))^\perp = ( \mathspan(\ran(A)\cup\ran(B)) )^\perp .
\end{equation*}
The rank condition implies that $\mathspan(\ran(A)\cup\ran(B))=\C^n$ and therefore
\begin{equation*}
  \ker(A^*)\cap\ker(B^*) = \{ 0 \} .
\end{equation*}
Let $\varphi\in\mathcal{N}_z$. Then,
\begin{equation*}
 (\Gamma_1\varphi,\Gamma_2\varphi)-(\Gamma_2\varphi,\Gamma_1\varphi)
    = (\varphi,\tilde H\varphi) - (\tilde H\varphi,\varphi)
    = (z-\bar z) \|\varphi\|^2
\end{equation*}
and thus
\begin{equation*}
  \im( (\Gamma_1\varphi,\Gamma_2\varphi) ) = \im(z) \|\varphi\|^2 .
\end{equation*}
Therefore, $\Gamma_{1,2}\varphi\neq 0$ for $\varphi\neq 0$.

By the above we may write
\begin{equation*}
  A\Gamma_1-B\Gamma_2 = (A-B\Gamma) \Gamma_1,\ \Gamma\coloneqq\Gamma_2\Gamma_1^{-1} .
\end{equation*}
It is therefore enough to show that $A-B\Gamma$ is injective which is equivalent to
$A^*-\Gamma^*B^*$ being injective. We have 
\begin{equation*}
  \im( (B^*\varphi,(A^*-\Gamma^* B^*)\varphi) ) = - \im( B^*\varphi, \Gamma^* B^*\varphi) .
\end{equation*}
Note that
\begin{equation*}
  2i \im \Gamma^*
   = \Gamma^*- \Gamma
   = (\Gamma_2\Gamma_1^{-1})^* -\Gamma_2\Gamma_1^{-1}
   = (\Gamma_1^{-1})^* ( \Gamma_2^*\Gamma_1 - \Gamma_1^*\Gamma_2 ) \Gamma_1^{-1}
   = - 2i \im(z) (\Gamma_1^{-1})^* \Gamma_1^{-1}
\end{equation*}
and thus
\begin{equation*}
  \im( (B^*\varphi,(A^*-\Gamma^* B^*)\varphi) ) = \im(z) (B^*\varphi, (\Gamma_1^{-1})^* \Gamma_1^{-1} B^*\varphi) .
\end{equation*}
Thereby, $(A^*-\Gamma^*B^*)\varphi=0$ implies that $B^*\varphi=0$ and this in turn implies that $A^*\varphi=0$.
From the above we conclude $\varphi=0$. That finishes the proof.
\end{proof}

The resolvent $R(z)\coloneqq(z\id-H)^{-1}$ of $H$ (cf. \eqref{abc_H}) is also a right inverse to $z\id-\tilde H$ (cf. \eqref{abc_H_tilde})
\begin{equation}\label{abc_right_inverse}
  (z\id-\tilde H)R(z) = (z\id - H)R(z) = \id .
\end{equation}
Note that generally it will be not a left inverse. We derive a formula that relates different right inverses.
This includes the Albeverio--Pankrashkin formula \cite{AlbeverioPankrashkin2005}, a specialization of
Kre\u\i{}n's resolvent formula, which relates resolvents corresponding to
different boundary conditions.

\begin{proposition}\label{abc02t}
For all $z\in\C\setminus\R$ let $\tilde R(z):\hilbert\to\dom(\tilde H)$ (with $\tilde H$ as in \eqref{abc_H_tilde}) 
be a bounded operator that has the resolvent properties
\begin{equation}\label{abc02t01}
  (z\id-\tilde H)\tilde R(z)=\id\ \text{and}\ \tilde R(z)^* = \tilde R(\bar z) .
\end{equation}
Then, the resolvent of $H$ in \eqref{abc_H} can be written (cf. \eqref{abc_deficiency_subspace})
\begin{equation}\label{abc02t02}
  R(z) = \tilde R(z) - D(z),\
  D(z) = \sum_{j,k=1}^n d_{jk}(z) (\varepsilon_k(\bar z),\cdot)\varepsilon_j(z)
\end{equation}
where the coefficient matrix $\hat D(z)\coloneqq(d_{jk}(z))_{j,k=1,\ldots,n}$ satisfies
\begin{equation}\label{abc02t03}
  (A\Gamma_1-B\Gamma_2)\tilde R(z)|_{\mathcal{N}_z} = (A\Gamma_1-B\Gamma_2)|_{\mathcal{N}_z} \hat D(z) E(z)
\end{equation}
with the generalized Gram matrix
\begin{equation}\label{abc02t04}
  E(z) \coloneqq ( (\varepsilon_j(\bar z), \varepsilon_k(z)) )_{j,k=1,\ldots,n} .
\end{equation}
\end{proposition}
\begin{proof}
We study the properties of the difference
\begin{equation*}
  D(z) = \tilde R(z) - R(z) .
\end{equation*}
From \eqref{abc_right_inverse} and the first equality in \eqref{abc02t01} we obtain
\begin{equation*}
  (z\id-\tilde H) D(z) = (z\id-\tilde H)\tilde R(z) - (z\id-\tilde H)R(z) = \id -\id = 0
\end{equation*}
which implies that
\begin{equation*}
  \ran D(z)\subset\mathcal{N}_z,\ z\in\C\setminus\R ,
\end{equation*}
and therefore
\begin{equation*}
  D(z) = \sum_{k=1}^n (\tilde\varepsilon_k(z),\cdot)\varepsilon_k(z),\ \tilde\varepsilon_k(z)\in\hilbert .
\end{equation*}
Furthermore, the second equality in \eqref{abc02t01} yields
\begin{equation*}
  D(z) = \tilde R(z) - R(z)
       = ( \tilde R(\bar z) - R(\bar z) )^*
       = D(\bar z)^*
       = \sum_{k=1}^n (\varepsilon_k(\bar z),\cdot)\tilde\varepsilon_k(\bar z)
\end{equation*}
which implies that $\tilde\varepsilon_k(\bar z)\in\mathcal{N}_z$ and thereby
\begin{equation*}
  \tilde\varepsilon_k(\bar z) = \sum_{l=1}^n \overline{d_{kl}(\bar z)} \varepsilon_l(z) .
\end{equation*}
The special form of the coefficients has been chosen for convenience.
To determine the coefficient matrix $\hat D(z)$ we use the boundary conditions, i.e. $(A\Gamma_1-B\Gamma_2)R(z)=0$,
\begin{equation*}
  (A\Gamma_1-B\Gamma_2) D(z)
    = (A\Gamma_1-B\Gamma_2)\tilde R(z)
    = \sum_{k,l=1}^n d_{kl}(z)(\varepsilon_l(\bar z),\cdot)(A\Gamma_1-B\Gamma_2)\varepsilon_k(z) .
\end{equation*}
We evaluate this on the vector $\varepsilon_j(z)$ thereby obtaining
\begin{equation*}
  (A\Gamma_1-B\Gamma_2)\tilde R(z)|_{\mathcal{N}_z} = (A\Gamma_1-B\Gamma_2)|_{\mathcal{N}_z} \hat D(z) E(z)
\end{equation*}
where $E(z)$ has the entries $(\varepsilon_l(\bar z), \varepsilon_j(z))$. This finishes the proof.
\end{proof}

We have not shown that the operator $D(z)$ is uniquely determined which would require to solve
for $\hat D(z)$ in \eqref{abc02t03}. Although that sounds reasonable since $(A\Gamma_1-B\Gamma_2)|_{\mathcal{N}_z}$ is injective
we would have to study the matrix $E(z)$. It is easier to do that in the concrete case 
considered in Section \ref{fr}.

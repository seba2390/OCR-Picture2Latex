\section{Statistical MC Evaluation of V-Formation Games}
\label{sec:results}
\newcommand{\majExp}{{2,000}}

As discussed in Section~\ref{sec:problem}, the
stochastic-game verification problem we address in the context of the V-formation-AMPC algorithm is formulated as follows.  Given a flock MDP $\M$ (we consider the case of $B\,{=}\,7$ birds), acceleration actions $\va$ of the controller, displacement actions $\vd$ of the attacker, the randomized strategy $\sigma_C: S\,{\mapsto}\,PD(C)$ of the controller (the AMPC algorithm), and a randomized strategy
$\sigma_D: S\,{\mapsto}\,PD(D)$ for the attacker,
determine the probability of reaching a state $s$ where the fitness function $J(s)\,{<}\,\varphi$ (V-formation in a 7-bird flock), starting from an initial state (in this case this is a V-formation), in the underlying Markov chain induced by strategies $\sigma_C$, $\sigma_D$ on $\M$.

Since the exact solution to this reachability is intractable due to the infinite/continuous space of states and actions, we solve it approximately with classical statistical model-checking (SMC).  The particular SMC procedure we use is described in~\cite{grosu2014isola} and based on an {\em additive} or {\em absolute-error $(\varepsilon,\delta)$-Monte-Carlo-approximation scheme}. This technique requires running $N$ i.i.d. game executions, each for a given maximum time horizon, computing if these executions reach a V-formation, and returning the average number of times this occurs.

The $N$ i.i.d. experiments determine the random variables $Z_1, ...,Z_N$, where the sample mean $\mu_Z\,{=}\,(Z_1\,{+}\,{\ldots}\,{+}\,Z_N)/N$ is assumed to be sufficiently greater than 0. In this case, one can exploit the Bernstein's inequality and fix $N$ to $\Upsilon\,{\propto}\,ln(1/\delta)/\varepsilon^2$. This results in an additive-error $(\varepsilon,\delta)$-approximation scheme:
\[
\Pr\left[\mu_Z\,{-}\,\varepsilon\leqslant\widetilde{\mu}_Z\leqslant\mu_Z\,{+}\,\varepsilon)\right]\geqslant{}1-\delta,
\]
where $\widetilde{\mu}_Z$ approximates $\mu_Z$ with absolute error $\varepsilon$ and probability $1-\delta$. In our case, each $Z_i$ is a Bernoulli random variable, where~1 means that the execution ends in a V-formation, and~0 means the opposite:
 
 \[Z=\left\{
\begin{array}{ll}
1, & \text{if}\:\:\exists t \in [0, m], J(s(t)) < \varphi,\\
0, & \text{otherwise}.
\end{array}\right.\]

This allows us to use the Chernoff-Hoeffding instantiation of the Bernstein's inequality, and fix the proportionality constant to $\Upsilon\,{=}\,4\,ln(2/\delta)/\varepsilon^2$, as in~\cite{HLMP04}. 

Each of the games described in Section~\ref{sec:sgv} is executed 2,000 times. For a confidence ratio $\delta\,{=}\,0.01$, we thus obtain an additive error of $\varepsilon\,{=}\, 0.1$.

We use the following parameters in the game executions: number of birds $B\,{=}\,7$, threshold on the fitness $\varphi\,{=}\,10^{-3}$, maximum horizon $h_{\mathit{max}}\,{=}\,5$, number of particles in PSO $p\,{=}\,20\,B\,h$. In RBG, the controller is allowed to run for a maximum of $30$ steps. In RDG and AMPC game, the attacker and the controller run in parallel for $20$ steps, after which the displacement becomes $0$, and the controller has a maximum of $20$ more steps to restore the flock to a V-formation.

To perform SMC evaluation of our AMPC approach we designed the above experiments in C and ran them on the Intel Core i7-5820K CPU with 3.30 GHz and with 32GB RAM available.\\
%\todo[inline]{We then present our experimental results and end with conclusions.}

\begin{figure}[t]
 \vspace*{-3ex}
 \centering
  \includegraphics[width=.495\textwidth]{figures/numbering}
  \includegraphics[width=.495\textwidth]{figures/remove2and5}
  \vspace*{-5ex} 
  \caption{Left: numbering of the birds. Right: configuration after removing Bird 2 and 5. The red-filled circle and two protruding line segments represent a bird's body and wings. Arrows represent bird velocities. Dotted lines illustrate clear-view cones. A brighter/darker background color indicates a higher upwash/downwash.}
  \label{fig:numbering}
  \vspace{-3ex}
 \end{figure}

\begin{table}[h]
\centering
\vspace*{-4ex}
\caption {Results of 2,000 game executions for removing 1 bird with $h_{\mathit{max}}\,{=}\,5$,  $m\,{=}\,40$}
\vspace*{-1ex}
    \begin{tabular}{lcccccccccc}
    \toprule
		&&& Ctrl. success rate, \% &&& Avg. convergence duration &&& Avg. horizon\\ \midrule
    Bird 4  && & $99.9$           && & $12.75$  &&& $3.64$                            \\
    Bird 3  && & $99.8$           && & $18.98$  &&& $4.25$                            \\
    Bird 2  && & $100$           && & $10.82$  &&& $3.45$                            \\ \bottomrule
    \end{tabular}
\label{tab:resRemoveOne}
%\vspace*{-3ex}
\end{table}

%\vspace*{-4ex}
\begin{table}[ht]
%\vspace*{-3mm}
% 	\scriptsize
	\centering
	\caption{Results of 2,000 game executions for removing 2 birds with $h_{\mathit{max}} \,{=}\,5$, $m\,{=}\,30$}
	\begin{tabular}{lccccccccccc}
		\toprule
		&&& Ctrl. success rate, \% &&& Avg. convergence duration &&& Avg. horizon\\
      	\midrule
        Birds 2 and 3 & & &$0.8$ & & &$25.18$&&&$4.30$\\
        Birds 2 and 4 & & &$83.1$ & & &$11.11$ &&&$2.94$\\
        Birds 2 and 5 & & &$80.3$ & & &$9.59$ &&&$2.83$\\
        Birds 2 and 6 & & &$98.6$ & & &$7.02$ &&&$2.27$\\
        Birds 3 and 4 & & &$2.0$ & & &$22.86$ &&&$4.30$\\
        Birds 3 and 5 & & &$92.8$ & & &$11.8$ &&&$3.43$\\
		\bottomrule
\end{tabular}
\label{tab:resRemoveTwo}
%\vspace*{-3ex}
\end{table}

\begin{table}[t]
%\vspace*{-3mm}
% 	\scriptsize
	\centering
	\caption{Results of 2,000 game executions for random displacement and AMPC attacks with $h_{\mathit{max}}\,{=}\,5$ and $m\,{=}\,40$ (attacker runs for 20 steps)}
	\begin{tabular}{cccccccccccc}  
		\toprule
		Range of noise &&& Ctrl. success rate, \% &&& Avg. convergence duration &&& Avg. horizon\\
      	\midrule
        &&&\multicolumn{7}{c}{Random displacement game}\\
        \cmidrule(l){3-10}
        $[0,0.50]\times[0,2\pi]$ & & &$99.9$ & & &$3.33$ &&&$1.07$\\
        $[0,0.75]\times[0,2\pi]$ & & &$97.9$ & & &$3.61$ &&&$1.11$\\
        $[0,1.00]\times[0,2\pi]$ & & &$92.3$ & & &$4.14$ &&&$1.18$\\
 		\cmidrule(l){3-10}
        &&&\multicolumn{7}{c}{AMPC game}\\
        \cmidrule(l){3-10}
        $[0,0.50]\times[0,2\pi]$  && & $97.5$    &&& $4.29$ &&& $1.09$\\
        $[0,0.75]\times[0,2\pi]$  && & $63.4$    &&& $5.17$ &&& $1.23$\\
        $[0,1.00]\times[0,2\pi]$  && & $20.0$    &&& $7.30$ &&& $1.47$\\
		\bottomrule
\end{tabular}
\label{tab:resRandomNoise}
%\vspace*{-3ex}
\end{table}

\subsection{Discussion of the Results}
To demonstrate the resilience of our adaptive controller, for each game introduced in Section~\ref{sec:sgv}, we performed a number of experiments to estimate the probability of the controller winning.  Moreover, for the runs where the controller wins, the average number of steps required by the controller to bring the flock to a V-formation is reported as {\em{average convergence duration}}, and the average length of the horizon used by AMPC is reported as {\em{average horizon}}.

The numbering of the birds in Tables~\ref{tab:resRemoveOne} and~\ref{tab:resRemoveTwo} is given in Figure~\ref{fig:numbering}. Bird-removal scenarios that are symmetric with the ones in the tables are omitted. The results presented in Table~\ref{tab:resRemoveOne} are for the RBG game with $R\,{=}\,1$.
% The experiments clearly demonstrate the resilience of our adaptive controller. In the case where the attacker removes one bird, 
In this case, the controller is {\em{almost always}} able to bring the flock back to a V-formation, as is evident from Table~\ref{tab:resRemoveOne}. Note that removing Bird $1$ (or $7$) is a trivial case that results in a V-formation.
%The number of steps required to bring the flock back to a V-formation is reported as the {\em{convergence rate}}, and the average length of the horizon used by the AMPC is reported as {\em{average horizon}}.  

In the case when $R\,{=}\,2$, shown in Table~\ref{tab:resRemoveTwo}, the success rate of the controller depends on {\em{which two birds are removed}}. Naturally, there are cases where dropping two birds does not break the V-formation; for example, after dropping Birds~1 and~2, the remaining birds continue to be in a V-formation.  Such trivial cases are not shown in Table~\ref{tab:resRemoveTwo}. Note that the scenario of removing Bird~$1$ (or~$7$) and one other bird can be viewed as removing one bird in flock of $6$ birds, thus not considered in this table. Among the other nontrivial cases, the success rate of controller drops slightly in four cases, and drops drastically in remaining two cases. 
This suggests that attacker of a CPS system can incur more damage by being prudent in the choice of the attack. 
%when two birds are removed, but the adaptive controller is still able to reach a V-formation on $80$-$90$\% cases, as reported in Table~\ref{tab:resRemoveTwo}. 

Impressively, whenever the controller wins, the controller needs about the same number of steps to get back to V-formation (as in the one-bird removal case). On average, removal of two birds results in a configuration that has worse fitness compared to an RBG with $R\,{=}\,1$. %than a one-removed configuration. 
Hence, the adaptive controller is able to make bigger improvements (in each step) when challenged by worse configurations. Furthermore, among the four cases where the controller win rate is high, experimental results demonstrate that removing two birds positioned asymmetrically with respect to the leader poses a stronger, however, still manageable threat to the formation. For instance, the scenarios of removing birds~2 and~6 or 3 and~5 give the controller a significantly higher chance to recover from the attack, $98.6\%$ and $92.8\%$, respectively.

Table~\ref{tab:resRandomNoise} explores the effect of making the attacker smarter. Compared to an attacker that makes random changes in displacement, an attacker that uses AMPC to pick its action is able to win more often. This again shows that an attacker of a CPS system can improve its chances by cleverly choosing the attack. For example, the probability of success for the controller to recover drops from $92.3\%$ to $20.0\%$ when the attacker uses AMPC to pick displacements with magnitude in $[0,1]$ and direction in $[0,2\pi]$. The entries in the other two columns in Table~\ref{tab:resRandomNoise} reveal two even more interesting facts.

First, in the cases when the controller wins, we clearly see that the controller uses a longer look-ahead when facing a more challenging attack. This follows from the observation that the average horizon value increases with the strength of attack. This gives evidence for the fact that the adaptive component of our AMPC plays a pivotal role in providing resilience against sophisticated attacks.
Second, the average horizon still being in the range $1$-$1.5$, means that the adaptation in our AMPC procedure also helps it perform better than a fixed-horizon MPC procedure, where usually the horizon is fixed to $h\,{\geqslant}\,2$.
When a low value of $h$ (say $h\,{=}\,1$) suffices, the AMPC procedure avoids unnecessary calculation that using a fixed $h$ might incur.

In the cases where success rate was low (Row~5 in Table~\ref{tab:resRemoveTwo} and Row~6 in Table~\ref{tab:resRandomNoise}), we observed improved success rate ($9\%$ and $30.8\%$ respectively across $500$ runs) when we increased $h_{\mathit{max}}$ to~$10$ and $m$ to~$40$. This shows that success rate of AMPC improves as it is given more resources, as predicted by Theorem~\ref{thm:ampc}.




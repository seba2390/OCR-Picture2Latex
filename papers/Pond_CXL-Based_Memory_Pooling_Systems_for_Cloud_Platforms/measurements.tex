

%\section{Cloud Measurements}
\section{Memory Stranding \& Workload Sensitivity to Memory Latency}
\label{sec:measurements}

\subsection{Stranding at \azure}
\label{sec-strand}

This section quantifies the severity of memory stranding
% , VM memory performance, and VM memory utilization
and untouched memory at \azure using production data.

\myparagraph{Dataset} We measure stranding in 100 cloud clusters over a
75-day period.  These clusters host mainstream first-party and third-party VM workloads.
They are representative of the majority of the server fleet.
We select clusters with similar deployment years, but spanning all major
regions on the planet. A trace from each cluster contains millions of per-VM
arrival/departure events, with the time, duration, resource demands, and
server-id.

\input{fig-poolsize-impact}

%\input{tab-cores}
\input{fig-cxl}
\input{fig-l0n-cdf}

\myparagraph{Memory stranding} Figure~\ref{fig-stranding-bars}a shows the
daily average amount of stranded
%  for daily resource timestamps
DRAM across clusters, bucketed by the percentage of scheduled CPU cores.
In clusters where 75\% of CPU cores are scheduled for VMs, 6\%
of memory is stranded. This grows to over 10\% when $\sim$85\% of CPU
cores are allocated to VMs. This makes sense since stranding is an
artifact of highly utilized nodes, which correlates with highly utilized
clusters.
%
Outliers are shown by the error bars, representing 5\th\ and 95\th\
percentiles. At 95\th, stranding reaches 25\% during high utilization
periods. Individual outliers even reach 30\% stranding.
%As shown in Table~\ref{tab-cores}, only 13-23\% of VMs use a single CPU
%core.  When considering 2-core and 4-core stranding, stranding grows to
%12.5\% and 15\%, respectively.

% This is gone.
Figure~\ref{fig-stranding-bars}b shows stranding over time across 8
racks. A workload change (around day 36)
suddenly increased stranding significantly.  Furthermore, stranding can
affect many racks concurrently (\eg, racks 2, 4--7) and it is generally
hard to predict which clusters\slash racks will have stranded memory.
%

\myparagraph{NUMA spanning} Many VMs are small and can fit on a
single socket.  On two-socket systems, the hypervisor at \azure seeks to
schedule such that VMs fit entirely (cores and memory) on a single NUMA node.  In
rare cases, we see \emph{NUMA spanning} where a VM has all of its
cores on one socket and a small amount of memory from
another socket.
% This can happen due to memory fragmentation.
We find that spanning occurs for about 2-3\% of VMs and fewer than
1\% of memory pages, on average.

\myparagraph{Savings from pooling}
% Fig~\ref{fig-stranding-all}.}
\azure currently does not pool memory.  However, by analyzing
its VM-to-server traces, we can estimate the amount of DRAM that could
be saved via pooling.  Figure~\ref{fig-stranding-pooling} presents
average reductions from pooling DRAM when VMs are scheduled with a
fixed percentage of either 10\%, 30\%, or 50\% of pool DRAM. The pool
size refers to the number of sockets that can access the same DRAM
pool. As the pool size increases, the figure shows that required
overall DRAM decreases.  However, this effect diminishes for larger
pools.  For example, with a fixed 50\% pool DRAM, a
pool with 32 sockets saves 12\% of DRAM while a pool with 64 sockets
saves 13\% of DRAM.
Note that
allocating a fixed 50\% of memory to pool DRAM leads to significant
performance loss compared to socket-local DRAM (\sec\ref{sec-eval}).
\sys overcomes this challenge with multiple techniques (\sec\ref{sec-des}).

\myparagraph{Summary and implications}  From this analysis, we draw a
few important observations and implications for \sys:

\begin{itemize}

\item We observe 3-27\% of stranded memory in production at the 95\th\ percentile, with
    some outliers at 36\%.

\item Almost all VMs fit into one NUMA node.

\item Pooling memory across 16-32 sockets can reduce cluster memory
    demand by 10\%.  This suggests that memory pooling can
        produce significant cost reductions but assumes that a high
        percentage of DRAM can be allocated on memory pools.  When
        implementing DRAM pools with cross-NUMA latencies, providers
        must carefully mitigate potential performance impacts. \border{}

\end{itemize}


\subsection{VM Memory Usage at \azure}
\label{sec-utilization-frigid}

% The key to realizing reduced memory spend through disaggregated memory
% is to be able to extract the flexibility of the pool while minimizing
% the latency effects of the pool. The exploitable observation here is
% that many VMs touch only a fraction of their provisioned capacity.
We use \sys's telemetry on opaque VMs (\sec\ref{sec:design:systemsw}) to characterize the percentage of
untouched memory across our cloud clusters.
Generally, we find that while VM memory usage varies across clusters,
all clusters have a significant fraction of VMs with untouched memory.
Overall, the 50\th\ percentile is 50\% untouched memory.
% RB: Removing this sentence because I don't know what it means.
% However, even in cluster C, aggregate utilization is less than 30\%.

%Individual clusters see between 1\% and 10\% of VMs with such cross-NUMA placement.

%Cloud providers generally seek to offer memory performance similar to bare-metal deployments.
%For most VMs, this means that memory performance should correspond to local DRAM on a single-socket system.
%In some cases, VMs see different performance in the cloud today.
%Specifically, this is because two-socket systems are currently widely deployed.
%Our distributed VM scheduler is not aware of individual sockets and makes decisions based on a server's %aggregate CPU core count and memory.
%In some cases, VMs are scheduled with CPU cores on one socket and with some amount of DRAM on the second %core.
%This happens when there is insufficient socket-local DRAM.
%We measure that this case occurs for about 2\% of VMs.
%Individual clusters see between 1\% and 10\% of VMs with such cross-NUMA placement.
%In the context of memory disaggregation, we conclude that scheduling all VMs with one-NUMA-hop latency %would be a significant performance degradation compared to today's cloud.
%However, a small subset of VMs, effectively chosen at random, see one-NUMA-hop performance today and thus similar numbers might be acceptable in the future as well.

\myparagraph{Summary and implications}  From this analysis, we draw key
observations and implications for \sys:

\begin{itemize}

\item VM memory usage varies widely.
\item In the cluster with the least amount of untouched memory, still over
    50\% of VMs have more than 20\% untouched memory.  Thus, there is
        plenty of untouched memory that can be disaggregated at no
        performance penalty.
\item The challenges are (1) predicting how much untouched
        memory a VM is likely to have and (2) confining the VM's accesses
        to local memory. \sys addresses both. \border{}

\end{itemize}
% \sys exploits this observation by designing the system and distributed system software stacks to funnel memory activity to local memory and ensuring untouched memory is mapped to CXL memory. Details on the full system design are provided in the next section.


%\input{fig-memutil}


\subsection{Workload Sensitivity to Memory Latency}
\label{sec-mot-cxl}

\newtxt{To characterize the performance impact of CXL latency for typical workloads in \azure's datacenters,
%without our mitigation techniques (\sec\ref{sec-des}),
we evaluate \numTotalApps\ workloads under two scenarios of emulated CXL access latencies: 182\% and 222\% increase in memory latency, respectively.
We then compare the workload performance to NUMA-local memory placement.
% and workload characteristics are described in Table \ref{tab-apps}
Experimental details are in \sec\ref{sec-eval-setup}.
%We ensure that the \cvn node is always large enough to hold the entire working set to prevent swapping.
%In addition to measuring workload slowdowns we also measure a workload's working set size, memory bandwidth, and other hardware counters.
%The working set size for each workload is profiled offline beforehand.
Figures~\ref{fig-cxl} and~\ref{fig-cxl-cdf} show workload slowdowns relative to NUMA-local performance for both scenarios.}
%and Figure~\ref{fig-cxl-cdf} correlates slowdown with other metrics.

% CXL results: overall
%-----------------------------------------------------------------------
%\myfinding{}

\input{fig-contactcount-revised}



\newtxt{Under a 182\% increase in memory latency, we find that 26\% of the \numTotalApps\ workloads
experience less than 1\% slowdown under CXL.
An additional 17\% of workloads see less than 5\% slowdowns.
At the same time, some workloads are severely affected with 21\% of the workloads facing $>$25\% slowdowns.}

\newtxt{Different workload classes are affected differently, \eg, GAPBS (graph processing) workloads generally see higher slowdowns.
However, the variability within each workload class is typically much higher than across workload classes.
For example, within GAPBS even the same graph kernel reacts very differently to CXL latency, based on different graph datasets.
Overall, every workload class has at least one workload with less than 5\% slowdown and one workload with more than 25\% slowdown (except SPLASH2x).}

\newtxt{\azure's proprietary workloads are less impacted than the overall workload set.
Of the 13 production workloads, 6 do not see noticeable impact ($<$1\%);
2 see $\sim$5\% slowdown;
and the remaining half are impacted by 10--28\%.
This is in part because these production workloads are NUMA-aware and often include data placement optimizations.}

\newtxt{Under a 222\% increase in memory latency, we find that 23\% of the \numTotalApps\ workloads
experience less than 1\% slowdown under CXL.
An additional 14\% of workloads see less than 5\% slowdowns.
More than 37\% of workloads face $>$25\% slowdowns.
Generally, we find that higher latency magnifies the effects seen under lower latency: workloads performing well under 182\% latency also tend to perform well under 222\% latency; workloads severely affected by 182\% are even more affected by 222\%.}

%\myfinding{}

\myparagraph{Summary and implications}
%\myparagraph{Implications}
While the performance of some workloads is insensitive to disaggregated memory latency, some are heavily impacted.
%Even low-latency memory disaggregation systems will bring significant performance impact for a large portion of the workloads.
This motivates our design decision to include socket-local DRAM alongside pool DRAM to mitigate CXL latency impact for those latency-sensitive workloads.
Memory pooling solutions can be effective if they're are effective at identifiying sensitive workloads.
%Further, knowing the workload class of a VM is not enough to predict whether that particular workload will see a small or a large slowdown.
%This invalidates ideas to allocate local/pool DRAM by deducing workload classes from the VM's given name or customer.
%\myparagraph{Implications}
%The fact that complex production workloads perform better than other workloads means that our evaluation is likely somewhat pessimistic.
%This is in part because these production workloads are NUMA aware and likely include some data placement optimizations.

%\input{fig-cxl-cdf}



% File tacl2018v2.tex
% Sep 20, 2018

% The English content of this file was modified from various *ACL instructions
% by Lillian Lee and Kristina Toutanova
%
% LaTeXery is mostly all adapted from acl2018.sty.

\documentclass[11pt,a4paper]{article}
\usepackage{times,latexsym}
\usepackage{url}
\usepackage[T1]{fontenc}
%% Package options:
%% Short version: "hyperref" and "submission" are the defaults.
%% More verbose version:
%% Most compact command to produce a submission version with hyperref enabled
%%    \usepackage[]{tacl2018v2}
%% Most compact command to produce a "camera-ready" version
%    \usepackage[acceptedWithA]{tacl2018v2}
%% Most compact command to produce a double-spaced copy-editor's version
%%    \usepackage[acceptedWithA,copyedit]{tacl2018v2}
%
%% If you need to disable hyperref in any of the above settings (see Section
%% "LaTeX files") in the TACL instructions), add ",nohyperref" in the square
%% brackets. (The comma is a delimiter in case there are multiple options specified.)

\usepackage[acceptedWithA]{tacl2018v2}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{bbm}
\usepackage{tabularx,ragged2e}
\usepackage{multicol,multirow}
\usepackage[labelformat=simple]{subcaption}
\usepackage[ruled,vlined]{algorithm2e}

%%%% Material in this block is specific to generating TACL instructions
\usepackage{xspace,mfirstuc,tabulary}
\newcommand{\dateOfLastUpdate}{Sept. 20, 2018}
\newcommand{\styleFileVersion}{tacl2018v2}

\newcommand{\ex}[1]{{\sf #1}}

% \newif\iftaclinstructions
% \taclinstructionsfalse % AUTHORS: do NOT set this to true
% \iftaclinstructions
% \renewcommand{\confidential}{}
% \renewcommand{\anonsubtext}{(No author info supplied here, for consistency with
% TACL-submission anonymization requirements)}
% \newcommand{\instr}
% \fi
\newif\iftaclinstructions
\taclinstructionstrue % AUTHORS: do NOT set this to true
\iftaclinstructions
\renewcommand{\confidential}{}
\renewcommand{\anonsubtext}{Neeraj Varshney, Swaroop Mishra, Chitta Baral \\Arizona State University \\
    \texttt\{nvarshn2, srmishr1, chitta\}@asu.edu}
\newcommand{\instr}
\fi

%
\iftaclpubformat % this "if" is set by the choice of options
\newcommand{\taclpaper}{final version\xspace}
\newcommand{\taclpapers}{final versions\xspace}
\newcommand{\Taclpaper}{Final version\xspace}
\newcommand{\Taclpapers}{Final versions\xspace}
\newcommand{\TaclPapers}{Final Versions\xspace}
\else
\newcommand{\taclpaper}{submission\xspace}
\newcommand{\taclpapers}{{\taclpaper}s\xspace}
\newcommand{\Taclpaper}{Submission\xspace}
\newcommand{\Taclpapers}{{\Taclpaper}s\xspace}
\newcommand{\TaclPapers}{Submissions\xspace}
\fi

%%%% End TACL-instructions-specific macro block
%%%%

% "How will an AI system perform in an interview?"
% Evaluating model's interview skills
% 

% We should help ML Model just like an interviewer helps candidates during an interview.
% \title{Towards Real World NLP Systems leveraging Interviewer-Candidate Role play.}
% \title{Interviewer-Candidate Role Play to Build a Real World NLP System}
% \title{Interviewer-Candidate Role Play: Towards Building a Real-World NLP System}
\title{Interviewer-Candidate Role Play: Towards Developing Real-World NLP Systems}
% Towards Real World NLP Systems: Assisting Models just like an an interviewer helps candidates

%Human-Machine interaction


% Author information does not appear in the pdf unless the "acceptedWithA" option is given
% See tacl2018v2.sty for other ways to format author information
\providecommand{\Swaroop}[1]{
    {\protect\color{red}{[Swaroop: #1]}}
}
\newcommand{\Neeraj}[1]{{\small \color{red} [Neeraj: #1]}}


\author{
        Neeraj Varshney, 
        Swaroop Mishra, 
        Chitta Baral 
\\Arizona State University \\
    \texttt\{nvarshn2, srmishr1, chitta\}@asu.edu
}

\date{}

\begin{document}
\maketitle
\begin{abstract}

Standard NLP tasks do not incorporate several common real-world scenarios such as seeking clarifications about the question, taking advantage of clues, abstaining in order to avoid incorrect answers, etc. 
This difference in task formulation hinders the adoption of NLP systems in real-world settings.
In this work, we take a step towards bridging this gap and present a multi-stage task that simulates a typical human-human questioner-responder interaction such as an interview.
Specifically, the system is provided with question simplifications, knowledge statements, examples, etc. at various stages to improve its prediction when it is not sufficiently confident.
We instantiate the proposed task in Natural Language Inference setting where a system is evaluated on both in-domain and out-of-domain (OOD) inputs.
We conduct comprehensive experiments and find that the multi-stage formulation of our task leads to OOD generalization performance improvement up to 2.29\% in Stage 1, 1.91\% in Stage 2, 54.88\% in Stage 3, and 72.02\% in Stage 4 over the standard unguided prediction.
However, our task leaves a significant challenge for NLP researchers to further improve OOD performance at each stage.
% Furthermore, we present a baseline approach to solve this novel task and conduct comprehensive experiments to establish its performance.
\footnote{Code and datasets for our task are available at  \href{https://github.com/nrjvarshney/interviewer-candidate-role-play}{https://github.com/nrjvarshney/interviewer-candidate-role-play}}

% AI systems when employed in real-world applications often encounter difficult and Out-of-Domain inputs, on which these systems usually make incorrect predictions. This renders the ability to output ``I Don't Know'' essential for their reliable adoption in such applications. Existing ``Selective Prediction'' task presents a limited challenge as it just requires the system to abstain where it is not sufficiently confident. In this work, we formulate the selective prediction task in a realistic and multi-stage setup where the system is provided with information related to the test instance in case of abstention.
\end{abstract}

\section{Introduction}
\label{introduction}
% \Swaroop{What is missing in Existing Tasks? and why they dont align with real world? Now Zeroshot and Fewshot is prevalent, but are we not being too harsh on models? }

% \begin{enumerate}
%     \item Standard Tasks have issues because model is forced to answer all questions and not given a chance to skip questions for which it has low confidence.
%     \item Selective Answering brings the evaluation closer to real-world (as it provides an option to abstain in case you are not sufficiently confident) setup but has limitations.
%     % One of the key limitation is that model gets only one chance to answer, however humans usually get multiple opportunity to answer by learning from diverse source of information. Are we being too harsh and expecting something from model which we may not need in a real world set up? Can we develop an evaluation setup that aligns with how humans evaluate each other?
% \end{enumerate}
% \Neeraj{What do the existing tasks lag?}
Despite impressive progress made in Natural Language Processing (NLP), we are far from employing these systems reliably in real-world tasks. 
This can be partially attributed to the misalignment between formulations of real-world and standard NLP tasks.
Specifically, real-world tasks present several scenarios that are often not included in the standard task formulations such as 
(1) seeking clarifications about the question
(2) taking advantage of clues provided at inference time
(3) learning from a few examples similar to the given question
(4) abstaining in order to avoid incorrect predictions, etc.
% \Swaroop{Clearly real world setup is much more than these 3 points, we can not cover all, but may be you can add a few more points e.g. prompting which involves transforming the question to human-friendly format. But I am not too strong on this, its also ok if you don't add this. }

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{Pictures/intro.png}
    \caption{Illustration of the proposed task simulating an interviewer-candidate interaction for NLI.
    }
    \label{fig:intro_figure}
\end{figure}

% \Neeraj{Existing works, their limitations, and transition to interview setup}
In order to bridge this alignment gap, prior work in NLP has investigated few tasks that are closer to the real-world settings such as Selective Prediction \cite{kamath-etal-2020-selective,jones2020selective,varshney2020s}, Few-Shot Learning \cite{NEURIPS2020_1457c0d6, schick-schutze-2021-just, Ye2021CrossFitAF, Tam2021ImprovingAS}, Prompting \cite{shin-etal-2020-autoprompt,jiang-etal-2020-know,le-scao-rush-2021-many, Mishra2021NaturalIB}, etc.
% Open-book Question Answering \cite{mihaylov-etal-2018-suit}, etc.
Selective Prediction enables a system to maintain high accuracy by abstaining on instances where it is likely to be incorrect.
Few-Shot Learning challenges a system to learn from a limited number of training examples.
Prompts provide task/instance related guidance in order to improve model's predictions.
% Open-book QA challenges a system to retrieve relevant information from a large knowledge corpus.
Though these works are a step in the right direction, they have several limitations. 
First, all these tasks give only a single opportunity to the system to either make a correct prediction or abstain. Whereas, in a typical human-human interaction, the questioner often gives hints, clarifications, examples, etc. in cases where the responder is not confident of their answer. 
Second, evaluation on these tasks is limited to specific aspects of system performance.
This motivates research into designing a realistic task that simulates a questioner-responder interaction and provides a unified evaluation of multiple aspects.

% \Neeraj{Motivate the Interview Setup}
An interview is a prototypical example of questioner-responder interaction.
In an interview, when the candidate is not confident in their answer, the interviewer first tries to simplify the question in order to help them understand it better.
If the simplification doesn't help then they usually give some hints.
Next, they typically provide some similar examples as further assistance to improve their answer.
Finally, the interviewer may give a worksheet that has a number of similar unsolved questions and allow some more time for the candidate to strengthen their concepts and reattempt the question.

% \Neeraj{Proposed Task transitioning from interview setup}
In this work, we present a multi-stage task that simulates the above-mentioned interviewer-candidate interaction as illustrated in Figure \ref{fig:intro_figure}.
Prior work has shown that model's confidence of prediction is often positively correlated with correctness similar to humans \cite{hendrycks17baseline,NIPS2017_9ef2ed4b} i.e a prediction is more likely to be correct if the confidence is high and more likely to be incorrect if the confidence is low.
Hence, we assist the system with input simplifications, clues, examples, etc. at various stages when it is not sufficiently confident in its prediction (Section \ref{proposed_task}). 
We organize our task into four sequential stages as shown in Figure \ref{fig:formalization}.
Initially, the model makes a prediction on the given test instance.
If the prediction confidence is below a certain threshold then it enters the first stage where a few semantic preserving simplifications of the test instance are provided.
The system is expected to utilize this help and better its prediction. 
If it enters Stage 2 then it is provided with some knowledge statements about the test instance.
Similarly, in the third stage, a few similar labeled examples are provided.
Finally, a number of unlabeled examples are given as further assistance in the fourth stage.
This task not only simulates a real-world scenario but also integrates a number of paradigms such as Selective Prediction, Prompting, Few-Shot Learning, and Unsupervised Learning.

We instantiate the proposed task in Natural Language Inference (NLI) setting (Section \ref{instantiation}) and evaluate on both in-domain and out-of-domain inputs.
We conduct comprehensive experiments on several NLI datasets and show that it improves OOD generalization performance up to 2.29\% in Stage 1, 1.91\% in Stage 2, 54.88\% in Stage 3, and 72.02\% in Stage 4 over the standard unguided prediction. 
% present an approach that serves as a strong baseline for this novel task (Section \ref{proposed_approach}).
% In order to evaluate the efficacy of this approach, we conduct comprehensive experiments on several NLI datasets and 

In summary, our contributions are as follows:\\
(1) Addressing limitations of the standard NLP tasks, we propose a novel multi-stage task that is closer to the real-world setting and simulates an interviewer-candidate interaction.\\
(2) To the best of our knowledge, we are the first to study post-abstention scenarios where a model is assisted with guidance in various forms to answer the originally abstained questions. \\
(3) Our task improves OOD generalization performance up to 2.29\% in Stage 1, 1.91\% in Stage 2, 54.88\% in Stage 3, and 72.02\% in Stage 4 on the evaluation metric of the proposed task. There exists a noteworthy headroom for performance improvement on our task, which hopefully will motivate further work in this direction of developing NLP systems that align well with the real-world tasks. \\



% \begin{enumerate}
%     \item Current modes of model evaluation does not align with their real world capability. One of the key limitation is that model gets only one chance to answer, however humans usually get multiple opportunity to answer by learning from diverse source of information. Are we being too harsh and expecting something from model which we may not need in a real world set up? Can we develop an evaluation setup that aligns with how humans evaluate each other?
%     \item Interview is the most prevalant form of human evaluation.

    
% For reliable evaluation of models, we take inspiration from a common 
% \end{enumerate}

% Despite impressive progress made in Natural Language Processing (NLP), it is unreasonable to expect models to be absolutely perfect in making predictions, especially in real-world tasks that often involve difficult and Out-of-Domain (OOD) inputs.
% For instance, users in interaction-based systems often pose queries that differ from the model's training data, making errors more likely.
% Furthermore, incorrect predictions can have serious consequences in safety-critical application domains like medicine and autonomous robots. 
% Thus, making abstention certainly better than incorrect answering in such cases.
% % Thus, it is certainly better to abstain than to answer incorrectly in such cases. 
% \Swaroop{Existing Approaches involve Human intervention (prompting), selective answering, knowledge addition. They are limited and do not span over real world human-human interaction that consists of many other mediums of assistance during question-answering.
% But they don't cover various intricacies of interviewer-candidate interaction where interviewer tries several ways to assist a candidate do well during the interview.}
% \Swaroop{How our task mimics interviewer-candidate setup, this should be in line with the previous paragraph}

    
\section{Related Work}
\subsection{Selective Prediction}
Selective Prediction task expects a system to answer when it likely to be correct and abstain otherwise.
There exists a large body of work on selective prediction in machine learning \cite{chow1957optimum,el2010foundations,geifman2017selective}.
Typically, the prediction confidence is used to decide when to answer and when to abstain.
In NLP, selective prediction has mostly been studied in connection with Calibration \cite{platt1999probabilistic} i.e aligning a model's output probability with the true probability of its predictions. 
\citet{desai-durrett-2020-calibration} study calibration of recently introduced pre-trained transformer models.
\citet{kamath-etal-2020-selective} train a calibrator leveraging softmax probabilities and instance-specific features such as input lengths for Question Answering (QA) models. 
\citet{varshney2020s} propose to transform calibration from classification to a regression problem incorporating difficulty scores of the instances.
\citet{zhang2021knowing} incorporate input example embedding from a pre-trained language model as additional features for the calibrator.
Unlike prior work, we also focus on post-abstention scenarios where a system is provided guidance in various forms to answer the originally abstained questions.

\subsection{Few-shot Learning}
Standard supervised learning approaches require a huge amount of labeled training data.
Inspired by human learning from just a few examples, few-shot learning presents a challenge of learning from a limited number of labeled training examples \cite{NEURIPS2020_1457c0d6, schick-schutze-2021-just, Ye2021CrossFitAF, Tam2021ImprovingAS}. Several works have shown that models can achieve comparable performance just by using a few representative samples \cite{wang2018dataset, nachum2018data, Mishra2020DoWN,sucholutsky2021less}.
Stage 3 in our task presents a few-shot learning challenge where a few labeled examples similar to the test instance are provided.
% Our task is different from Few-shot learning as it presents a multi-stage setup where the system is guided in the form of input simplifications, knowledge statements, labeled and unlabeled examples at various stages when it is not sufficiently confident in its prediction.

\subsection{Knowledge Addition}
Incorporating knowledge in models has been a long-standing research area in NLP.
Researchers leverage large knowledge banks such as COMET-ATOMIC \cite{hwang2020comet}, ConceptNet \cite{speer2017conceptnet}, etc. to solve commonsense reasoning tasks \cite{Mitra2019ExploringWT,chang-etal-2020-incorporating,shen-etal-2020-exploiting,Mishra2020TowardsQF} like CommonsenseQA \cite{talmor-etal-2019-commonsenseqa}, QUOREF \cite{dasigi-etal-2019-quoref}, etc.
Recently, prompting where additional task-related information is provided gained attention especially for regimes where only a small labeled dataset is available for training \cite{shin-etal-2020-autoprompt,schick-schutze-2021-exploiting,le-scao-rush-2021-many,Mishra2021NaturalIB}.
In our task, we provide instance-specific knowledge in Stage 2 when the system's confidence in its prediction is below a certain threshold.
\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{Pictures/formalization.png}
    \caption{Illustration of various branches of the proposed task. Given an input, the model makes a prediction $pred$ with confidence $c$ sequentially in each stage leveraging the provided guidance until $c$ surpasses the threshold $th$. Note that $pred$ and $c$ vary with the stage but the threshold $th$ remains the same across stages.}
    \label{fig:formalization}
\end{figure}
\subsection{Unsupervised Learning}
Unsupervised Learning pertains to learning from unlabeled data \cite{lewis-etal-2019-unsupervised}.
This field is gaining interest as obtaining labeled data is both time consuming and expensive. In contrast, unlabeled data can be collected cheaply.
For downstream tasks, it has mostly been explored for Question Answering task ~\cite{chung-etal-2018-supervised,yang-etal-2017-semi, dhingra-etal-2018-simple,wang-jiang-2019-explicit,alberti-etal-2019-synthetic} where it is modeled as a data augmentation or a domain adaptation problem.
In this work, we provide unlabeled examples to the system in the final stage of our task.


\section{The Proposed Task}
\label{proposed_task}
In this section, we detail our proposed multi-stage task, its mathematical formulation, and evaluation metric.


\paragraph{Task Description:}
Prior work has shown that the model's confidence is often positively correlated with its correctness \cite{hendrycks17baseline,NIPS2017_9ef2ed4b} i.e its prediction is more likely to be correct if the confidence is high and more likely to be incorrect if the confidence is low.
Following this, we design our task in four sequential stages where a system goes from one stage to the next if it is not sufficiently confident in its prediction. Figure \ref{fig:formalization} illustrates the flow of the task. 
Each stage provides instance-specific guidance in various forms to assist the model in improving its prediction. 
If the prediction confidence in a stage exceeds a certain threshold then it attempts the test instance and skips the subsequent stages.

The stages are organized based on the steps that a typical interviewer follows in an interaction with a candidate (Section \ref{introduction}).
Initially, the model makes a prediction on the given input and the overall system outputs the prediction if the confidence is above a certain threshold and enters Stage 1 otherwise.
In Stage 1, it is provided with several semantic-preserving simplifications of the test instance.
The system is expected to leverage these input simplifications and improve its prediction on the given test instance.
Prior work has shown that even state-of-the-art models are sensitive to the input and simplifying the input can significantly boost model's performance \cite{jiang-etal-2020-know,Elazar2021MeasuringAI,anantha-etal-2021-open}.
In Stage 2, it is given some knowledge statements relevant to the test instance. 
A few similar labeled examples are provided in Stage 3.
In the final stage, it is further given a number of similar unlabeled examples. 
If the system fails to surpass the confidence threshold even after the final stage then it abstains from answering on that test instance in order to avoid incorrect prediction.

\paragraph{Mathematical Formulation:}
Algorithm \ref{algo:algo} shows the general structure of the proposed task.
\newcommand{\pluseq}{\mathrel{+}=}
\begin{algorithm}
\SetAlgoLined
\textbf{Given:} \\
$i$: Test Instance, \\ 
$th$: Confidence Threshold, \\
$M_0$: Trained Model, \\
$\mathcal{T}_s$: Stage-specific Guidance Function \\
\textbf{Initialization:} stage: $s \leftarrow  0$\\
% , $T_0 \leftarrow \emptyset$\\
\While {$s \leq 4 $}
{
    $M_s \leftarrow$ Update $M_{s-1}$ using $\mathcal{T}_s(i)$ if $s > 0$\\
    % $pred_{i_s}$, $conf_{i_s}$ = M($i + \sum_{j=0}^{j=s} \mathcal{T}_j(i)$)\\
    $pred_{i_s}, conf_{i_s} = M_s(i)$\\
    \uIf{$conf_{i_s} > th$}
    {
        \textbf{return} $pred_{i_s}$
    }
    $s += 1$
}
\textbf{return} ``Abstain''
 \caption{Task Structure}
 \label{algo:algo}
\end{algorithm}
The system continues to make the prediction on the given test instance leveraging the provided guidance until its confidence exceeds a certain threshold.
\citet{hendrycks17baseline} showed that $MaxProb$ (maximum softmax probability) is a simple yet strong estimate of prediction confidence.
Formally, $MaxProb$ estimates confidence on input $i$ as:
\begin{equation*}
    conf_{MaxProb} = \max_{y'\in Y(i)} Model(y'|i)
\end{equation*}
where $Y(i)$ denotes the possible output classes.

Calibration using a held-out dataset can further align the model's output probabilities \cite{lee2017training, kamath-etal-2020-selective} and give better confidence estimates.
The function $\mathcal{T}_s$ provides guidance to the system in Stage $s$ for an instance $i$ and is defined as:
\begin{equation*}
        \mathcal{T}_s(i) =
            \begin{cases}
              \emptyset, & \text{if $s = 0$} \\
              Simplified\ Inputs, & \text{if $s = 1$} \\
              Knowledge\ Stmts., & \text{if $s = 2$} \\
              Similar\ Labeled\ Ex., & \text{if $s = 3$} \\
              Similar\ Unlabeled\ Ex. & \text{if $s = 4$} \\
              
            \end{cases}
\end{equation*}

% $\mathcal{T}_s$ is further detailed in Section \ref{instantiation} where we instantiate the task in Natural Language Inference setting.

\paragraph{Evaluation Metric:}
\label{evaluation_metric}
In Selective Prediction, ``Coverage" is defined as the fraction of examples answered by the system while accuracy on covered examples is the fraction answered correctly. 
Furthermore, risk pertains to the error on the covered examples.
Selection of confidence threshold above which the system answers is application dependent i.e for tolerant applications like movie recommendation, a low threshold can be selected but for intolerant applications like medical diagnosis, a high threshold is selected to minimize risk. 
Hence, instead of evaluating a system at a particular threshold value, coverage and its associated risk is computed for every threshold value $th$ in order to estimate its overall performance.
As $th$ decreases, coverage will increase, but the risk will usually also increase. 
We plot risk versus coverage for all values of $th$ and calculate the area under this curve (AUC). AUC represents the overall performance of a method as it combines performance across all $th$ values. 
Lower AUC is preferred as it represents lower average risk across all thresholds.
We compute AUC for each stage as described below:
% We now describe the computation mathematically.

Let the model's initial prediction on instance $i$ be $pred_{i_0}$ with a confidence of $conf_{i_0}$ and prediction in stage $s = 1..4$ be $pred_{i_s}$ with a confidence of $conf_{i_s}$.
Note that the system gets to make a prediction in a stage only if the confidence in the previous stage was below the threshold $th$.
For every $th$ and stage $s$, we compute two values $c_{i_s}$ and $p_{i_s}$ as:
\begin{equation*}
        c_{i_s} =
            \begin{cases}
              c_{i_{s-1}}, & \text{if $conf_{i_{s-1}}$ > th} \\
              conf_{i_s} & \text{otherwise}
            \end{cases}
\end{equation*}
\begin{equation*}
        p_{i_s} =
            \begin{cases}
              p_{i_{s-1}}, & \text{if $conf_{i_{s-1}}$ > th} \\
              pred_{i_s} & \text{otherwise}
            \end{cases}
\end{equation*}
We use $c_{i_s}$ and $p_{i_s}$ to compute Coverage $C$ and Accuracy $A$ on covered examples in stage $s$ as:
\begin{equation*}
    C_s = \frac{\sum_{i=1}^n \mathbbm{1}(c_{i_s} \ge th)}{n} 
\end{equation*}
\begin{equation*}
    A_s =\frac{ \frac{1}{n}\sum_{i=1}^n (\mathbbm{1}(c_{i_s} \ge th)*v_{i_s})}{C_s} 
\end{equation*}

where, $\mathbbm{1}$ is the indicator function, $n$ is size of test dataset and parameter $v_{i_s}$ is $1$ when prediction $p_{i_s}$ is correct and 0 otherwise.  \\
We then plot risk-coverage curves and compute AUC to evaluate a system's performance.

\section{Task Instantiation}
\label{instantiation}
While our framework is general, we instantiate the proposed task in Natural Language Inference (NLI) that pertains to the task of identifying the relationship between a ``premise'' and a ``hypothesis'' sentence.
This relationship can be classified as either \textit{Entailment} (hypothesis must be true if the premise is true), \textit{Contradiction} (hypothesis can never be true if the premise is true), or \textit{Neutral} (hypothesis can be both true and false as the premise does not provide enough information to make a decision).
Table ~\ref{tab:nli_examples} shows examples of the NLI task.
We include the standard NLI datasets in our setup and consider SNLI \cite{bowman-etal-2015-large} as in-domain dataset with Multi-NLI \cite{williams-etal-2018-broad} and Dialogue NLI \cite{welleck-etal-2019-dialogue} as Out-of-Domain (OOD) datasets. 
We include the OOD datasets in our setup as the inputs often diverge from the model's training data in a real-world task.
Figure \ref{fig:task_instantiation} illustrates the method we followed to create various stages in our task instantiation.
\begin{figure*}[t]
    \centering
    \includegraphics[width=0.8\textwidth]{Pictures/task_instantiation.png}
    \caption{Steps involved at every stage during instantiation of the proposed task for NLI.}
    \label{fig:task_instantiation}
\end{figure*}
We detail the four stages of the proposed task for NLI below:

\paragraph{Stage 1:}
The first stage requires the input to be simplified in case of abstention. 
We compile simplified versions of the premise-hypothesis tuples in an automated way using the paraphrasing tool introduced in \cite{zhang2020pegasus}.
We conduct a small user study in order to find the best strategy of employing this tool to compile semantic preserving variations of the original input.
We provide three sets of examples where we paraphrase only premise, only hypothesis, and both premise and hypothesis for the three labels (Entailment, Contradiction, and Neutral) separately.
We also provide the original PH tuple to the participants and ask them to annotate whether the transformation is label preserving.
We find that for Entailment and Contradiction PH tuples, paraphrasing the hypothesis is label preserving in most cases, whereas it is paraphrasing the premise for Neutral. 
Using these findings, we compile $10$ semantic preserving variations of the test instances and provide them to the system in case of abstention in the first stage.
% We expect it to be helpful because prior work has shown that transformer models are sensitive to the input [--cite] and providing multiple variants of the input can result in better predictions. 
Table ~\ref{tab:stage1_examples} shows examples of the transformed PH tuples provided to the system in Stage 1.
% We note that a very small portion of the transformations lead to noise but we can safely ignore that as we provide $10$ such transformations.
\input{tables/nli_examples}
\input{tables/stage1_examples}

\paragraph{Stage 2:}
In Stage 2, some knowledge statements relevant to the test instance are provided.
\input{tables/stage2_examples}
We collect these knowledge statements from ConceptNet~\cite{speer2017conceptnet} by querying for nouns and verbs present in the sentence and ranking based on the similarity. 
Table \ref{tab:stage2_examples} shows examples of knowledge statements fetched for SNLI test instances in Stage 2.

\paragraph{Stage 3:}
In Stage 3, we provide a few labeled examples similar to the test instance in case of abstention. We use POS tagger of spacy library \cite{spacy} and find examples with matching subjects and nouns. 
For each instance, we find similar examples from its corresponding training dataset.
% i.e for OOD instances, we find similar examples from their corresponding training dataset. 
Note that we sample equal number of examples for each label to avoid label imbalance.
We experiment varying the number of similar examples in this stage from $8$ to $128$.
\input{tables/stage3_examples}
Table \ref{tab:stage3_examples} shows examples found for an SNLI test instance from the SNLI training dataset in Stage 3.

\paragraph{Stage 4:}
In Stage 4, we provide a number of unlabeled examples compiled from the corresponding training dataset of the test instance. 
We experiment varying the number of unlabeled examples in this stage from $5000$ to $20000$.
We expect this stage to be particularly beneficial for the OOD inputs as this provides exposure to instances that have not been observed during training performed prior to Stage 1.

\section{Experiments and Results}
In this section, we provide experimental details and analyse performance of our baseline approach.

\subsection{Approach}

% \newcommand{\pluseq}{\mathrel{+}=}
% \begin{algorithm}
% \SetAlgoLined
% \textbf{Given:} \\
% $i$: Test Instance, \\ 
% $th$: Confidence Threshold, \\
% $M_0$: Trained Model, \\
% $\mathcal{T}_s$: Stage-specific Guidance Function \\
% \textbf{Initialization:} stage: $s \leftarrow  0$\\
% % , $T_0 \leftarrow \emptyset$\\
% \While {$s \leq 4 $}
% {
%     $M_s \leftarrow$ Update $M_{s-1}$ using $\mathcal{T}_s(i)$ if $s > 0$\\
%     % $pred_{i_s}$, $conf_{i_s}$ = M($i + \sum_{j=0}^{j=s} \mathcal{T}_j(i)$)\\
%     $pred_{i_s}, conf_{i_s} = M_s(i)$\\
%     \uIf{$conf_{i_s} > th$}
%     {
%         \textbf{return} $pred_{i_s}$
%     }
%     $s += 1$
% }
% \textbf{return} ``Abstain''
%  \caption{Task Structure}
%  \label{algo:algo}
% \end{algorithm}

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{Pictures/approach.png}
    \caption{Our baseline approach for each stage of the proposed task.}
    \label{fig:approach}
    \end{figure}
We train a 3-way classification model on the training dataset and use $MaxProb$ i.e maximum softmax probability across the three classes as the confidence measure.
Initially, we make inference on the given test instance and proceed to Stage 1 if the confidence is below the threshold.
For the first stage, we further make inference on the provided simplifications of the test instance and find the most frequent prediction among those.
Then, we use \textbf{ensembling} techniques to find the final prediction i.e we compare the prediction on the original input with this most frequent prediction and if that prediction matches then we take the maximum prediction confidence among the variants where the system predicts the most frequent label otherwise we take the average of those prediction confidences.
For the second stage, we \textbf{concatenate the knowledge statement(s)} with the premise and make inference on the concatenated input.
For the third stage, we further \textbf{fine-tune} the model on the provided labeled instances and reattempt the original test instance using the fine-tuned model. 
For the final stage, we \textbf{pseudo-label} the provided unlabeled examples using the finetuned model obtained in Stage 3, fine-tune the model using those pseudo-labeled examples, and make inference on the test instance again. Figure \ref{fig:approach} illustrate our baseline approach for each stage of the proposed task.
% Our future work will focus on improving the approach and utilizing the guidance provided in Stage 1 and 2.
\input{tables/auc_results}
\begin{figure*}[t]
\centering

    \begin{subfigure}{.46\textwidth}
        \includegraphics[width=\linewidth,height=46mm]{Pictures/risk_cov_curves/snli.png}
        \caption{SNLI}
    \end{subfigure}
    \begin{subfigure}{.46\textwidth}
        \includegraphics[width=\linewidth,height=46mm]{Pictures/risk_cov_curves/mnli_matched.png}
        \caption{MNLI matched}
    \end{subfigure}
    \newline
    \begin{subfigure}{.46\textwidth}
        \includegraphics[width=\linewidth,height=46mm]{Pictures/risk_cov_curves/mnli_mismatched.png}
        \caption{MNLI mismatched}
    \end{subfigure}
    \begin{subfigure}{.46\textwidth}
        \includegraphics[width=\linewidth,height=46mm]{Pictures/risk_cov_curves/dnli.png}
        \caption{DNLI}
    \end{subfigure}
    \caption{Risk coverage curves for all datasets in Stages 0, 1, 2, and 3.}
    \label{fig:risk_coverage_curves}    
\end{figure*}
Table \ref{tab:stage0_results} shows the performance of the SNLI-trained model on all the evaluation datasets before Stage 1. We refer this stage as Stage 0 in our analysis.
As expected, the in-domain accuracy is high and AUC of risk-coverage curve is low. Whereas, the out-of-domain accuracy is low and AUC is high.
\subsection{Experimental Details}
Since NLI is a 3-way classification task, we use BERT-BASE model \cite{devlin-etal-2019-bert} with a linear layer on top of [CLS] token representation for training the model.  We use batch sizes of 32 and a learning rate ranging in $\{1{-}5\}e{-}5$. All experiments are done in Nvidia V100 16GB GPUs.
We train the model using 10k examples of the SNLI training dataset and evaluate on SNLI, MNLI (matched and mismatched), and DNLI datasets. 
\input{tables/stage0_results}
\subsection{MaxProb as a confidence Measure}
We plot $MaxProb$ vs $Accuracy$ achieved by the SNLI trained model for all the datasets in Figure \ref{fig:conf_vs_acc}.
It shows that $MaxProb$ is positively correlated with correctness i.e with increase in $MaxProb$, the accuracy also increases. 
This justifies the use of $MaxProb$ as a confidence measure for our task.

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{Pictures/conf_vs_acc.png}
    \caption{MaxProb Vs Accuracy plot for the SNLI trained model on all evaluation datasets.}
    \label{fig:conf_vs_acc}
\end{figure}


\subsection{Performance Prior to Stage 1}



\subsection{Performance Analysis}
Figure \ref{fig:risk_coverage_curves} shows the risk-coverage curves for all the evaluation datasets obtained in various stages of our task.
We find that Stage 3 leads to a significant improvement for OOD datasets.
In contrast, there is a marginal drop in performance for in-domain dataset (SNLI). 
This is expected as the model is already trained on the training dataset of the in-domain dataset and fine-tuning on a few examples in Stage 3 leads to overfitting and hence drop in performance. 
Furthermore, we find that their is not a significant improvement in performance in Stage 1 and Stage 2. This leaves scope for better ways to leverage the input simplifications and knowledge statements in Stage 1 and 2 respectively.
% Due to limited computational budget we perform Stage 4 for only 200 test instances of all datasets and show the risk-coverage curves for those 200 instances in Figure \ref{}.




% \subsection{Variation of AUC with Stage}
% We plot the variation of AUC of risk-coverage curve with the stage for all the evaluation datasets in Figure \ref{fig:auc_figure}.
% We find that the maximum performance improvement is observed in OOD datasets as the AUC changes from x in Stage 0 to y in Stage 4.

% \begin{figure}[t]
%     \centering
%     \includegraphics[width=\linewidth]{Pictures/auc.png}
%     \caption{[dummy]Figure depicting how the AUC of risk-coverage curve varies with the stage.}
%     \label{fig:auc_figure}
%     \end{figure}

% \subsection{Varying number of labeled examples in stage 2}
% In order to study the impact of number of labeled examples provided in Stage 3, we vary this number and plot its effect on AUC of risk-coverage curve for all datasets in Figure \ref{fig:stage3_variation}.

% \begin{figure}[t]
%     \centering
%     \includegraphics[width=\linewidth]{Pictures/stage3_variation.png}
%     \caption{[dummy]Figure showing the variation of AUC with the number of labeled examples provided on abstention in Stage 3.}
%     \label{fig:stage3_variation}
%     \end{figure}

% \subsection{Varying number of unlabeled examples in stage 3}
% In order to study the impact of number of unlabeled examples provided in Stage 4, we vary this number and plot its effect on AUC of risk-coverage curve for all datasets in Figure \ref{fig:stage4_variation}.

% \begin{figure}[t]
%     \centering
%     \includegraphics[width=\linewidth]{Pictures/stage4_variation.png}
%     \caption{[dummy]Figure showing the variation of AUC with the number of unlabeled examples provided on abstention in Stage 4.}
%     \label{fig:stage4_variation}
%     \end{figure}



\section{Conclusion}
We introduced a multi-stage task in order to bridge the gap between real-world and standard NLP task formulations. 
Inspired by human-human interaction such as an interview,
we designed our task by incorporating various forms of guidance to help a system improve its prediction and learn the underlying concept to achieve generalization.
We instantiated the proposed task in Natural Language Inference setting and demonstrated that each of the stages improve OOD generalization performance of systems.
However, there still exists significant room to improve OOD generalization at each stage (especially Stage 1 and 2). 
We hope this work will bring more attention to developing NLP systems that align more closely with the real-world tasks.

% We hope this work will bring more attention to building stronger models that can generalize to a wider range of tasks

% \iftaclpubformat
% \section{Courtesy warning: Common violations of \taclpaper rules that have
% resulted in papers being returned to authors for corrections}

% Avoid publication delays by avoiding these.
% \begin{enumerate}
% \item Violation: incorrect parentheses for in-text citations.  See \S
% \ref{sec:in-text-cite} and Table \ref{tab:cite-commands}.
% \item Violation: URLs that, when clicked, yield an error such as a 404 or go
% to the wrong page.
%   \begin{itemize}
%      \item Advice: best scholarly practice for referencing URLS would be to also
%      include the date last accessed.
%   \end{itemize}
% \item Violation: non-fulfillment of promise from submission to provide access
% instructions (such as a URL) for code or data.
% \item Violation: References incorrectly formatted (see \S\ref{sec:references}).
% Specifically:
% \begin{enumerate}
%   \item Violation: initials instead of full first/given names in references.
%   \item Violation: missing periods after middle initials.
%   \item Violation: incorrect capitalization.  For example, change ``lstm'' to
%   LSTM and ``glove'' to GloVe.
%   \begin{itemize}
%     \item Advice: if using BibTex, apply curly braces within the title field to
%     preserve intended capitalization.
%   \end{itemize}
%   \item Violation: using ``et al.'' in a reference instead of listing all
%   authors of a work.
%   \begin{itemize}
%     \item Advice: List all authors and check accents on author names even when
%     dozens of authors are involved.
%   \end{itemize}
%   \item Violation: not giving a complete arXiv citation number.
%   \begin{itemize}
%      \item Advice: best scholarly practice would be to give not only the full
%      arXiv number, but also the version number, even if one is citing version 1.
%   \end{itemize}
%   \item Violation: not citing an existing peer-reviewed version in addition to
%   or instead of a preprints
%     \begin{itemize}
%      \item Advice: When preparing the camera-ready, perform an additional check
%      of preprints cited to see whether a peer-reviewed version has appeared
%      in the meantime.
%   \end{itemize}
%   \item Violation: book titles do not have the first initial of all main words
%   capitalized.
%   \item Violation: In a title, not capitalizing the first letter of the first word
%   after a colon or similar punctuation mark.
% \end{enumerate}
% \end{enumerate}
% \else
% % Submission-specific rules
% \section{Courtesy warning: Common violations of \taclpaper rules that have
% resulted in desk
% rejects}
% \begin{enumerate}
%   \item Violation: wrong paper format.
%   \emph{As of the September 2018 submission round and beyond, TACL requires A4
%   format.  This is a change from the prior paper size.}

%   \item Violation: main document text smaller than 11pt, or table or figure
%   captions in a font smaller than 10pt. See Table \ref{tab:font-table}.

%   \item Violation: fewer than seven pages of content or more than ten pages of
%   content, {\em including} any appendices. (Exceptions are made for
%   re-submissions where a TACL Action Editor explicitly granted a set number of
%   extra pages to address reviewer comments.) See
%   Section \ref{sec:length}.
%   \item Violation: Author-identifying information in the document content or
%   embedded in the file itself.
%     \begin{itemize}
%       \item Advice: Make sure the submitted PDF does \emph{not} embed within it
%       any author info: check the document properties before submitting.
%       Useful tools include Adobe Reader and {\tt pdfinfo}.
%       \item Advice: Check that no URLs (or corresponding websites) inadvertently
%       disclose any author information. If software or data is to be distributed,
%       mention so in {\em anonymized} fashion.
%       \item Advice: Make sure that author names have been omitted
%       from the author block. (It's OK to include some sort of anonymous
%       placeholder.)
%       \item Advice: Do not include acknowledgments in a submission.
%       \item Advice: While citation of one's own relevant prior work is as
%       encouraged as the citation of any other relevant prior work,
%       self-citations should be made in the third, not first, person.
%       No citations should be attributed to ``anonymous'' or the like.
%       See Section \ref{sec:self-cite}.
%     \end{itemize}
% \end{enumerate}
% \fi


% \section{General instructions}

% \Taclpapers that do not comply with this document's instructions
% risk
% \iftaclpubformat
% publication delays until the camera-ready is brought into compliance.
% \else
% rejection without review.
% \fi


% \Taclpapers should consist of a Portable Document Format (PDF) file formatted
% for  \textbf{A4 paper}.\footnote{Prior to the September 2018 submission round, a
% different paper size was used.} All necessary fonts should be
% included in the  file.

% \iftaclpubformat
% Note that you will need to provide both a single-spaced and a double-spaced
% version; see \S \ref{ssec:layout}.

% If you promised to provide code or data at submission, specific instructions for
% how to access such resources must be provided.  (Typically, a URL to a stable,
% resource-specific site suffices.)

% All URLs should be manually checked to verify that they
% lead to a valid webpage, and to the site that was intended.
% \fi


% \section{\LaTeX\ files}

% \LaTeX\ files compliant with these instructions are available at the
% Author Guidelines section of the
% TACL website, \href{https://www.transacl.org/}
% {https://www.transacl.org}.\footnote{Last accessed \dateOfLastUpdate.} Use of the
% TACL \LaTeX\ files is highly recommended: \emph{MIT Press requires authors to
% supply \LaTeX\ source files as part of the publication process}; and
% use of the recommended \LaTeX\ files makes conversion to the
% required camera-ready format simple.
% \iftaclpubformat
% Specifically, the conversion can be accomplished by as little as: (1) add
% ``acceptedWithA'' in the square brackets in the line invoking the TACL package,
% like so:
% {\footnotesize {\tt {\textbackslash usepackage}[acceptedWithA]\{\styleFileVersion\}}} (2) add author information;
% (3) add acknowledgments.
% \fi

% \subsection{Workarounds for problems with the hyperref package}

% The provided files use the hyperref package by default. The TACL files
% employs the hyperref package to make clickable links for URLs and other references,
% and to make titles of bibliographic items into clickable links to their DOIs
% in the generated pdf.\footnote{Indeed, for some versions of acl\_natbib.sty,
% DOIs and URLs are not printed out or included in the bibliography in any form
% if the hyperref package is not used.}

% However, it is known that citations or URLs that cross pages can trigger the
% compilation error ``{\tt {\textbackslash}pdfendlink ended up in different nesting
% level than {\textbackslash}pdfstartlink}''.  In such cases, you may temporarily
% disable the hyperref package and then compile to locate the offending portion of
% the tex file; edit to avoid a pagebreak within a link;\footnote{If the problematic
% link is part of a reference in the bibliography and you do not wish to
% directly edit the corresponding .bbl file, a heavy-handed approach is to
% add the line
% {\tt \textbackslash interlinepenalty=10000}
% just after the line
% {\tt \textbackslash sloppy\textbackslash clubpenalty4000\textbackslash widowpenalty4000} in the
% ``{\tt \textbackslash def\textbackslash thebibliography}'' portion
% of the file \styleFileVersion.sty.  This penalty means that LaTex will not allow
% individual bibliography items to cross a page break.
% }
%  and then re-enable the
% hyperref package.

% To disable it,
% add {\tt nohyperref} in the square brackets to pass that option to the TACL package.
% For example, change
% \iftaclpubformat
% \verb+[acceptedWithA]+ in
% {\footnotesize {\tt {\textbackslash usepackage}[acceptedWithA]\{\styleFileVersion\}}}
% to
% \verb+[acceptedWithA,nohyperref]+.
% \else
% {\tt {\textbackslash usepackage}[]\{\styleFileVersion\}}
% to
% {\tt {\textbackslash usepackage}[nohyperref]\{\styleFileVersion\}}.
% \fi



% \section{Length limits}
% \label{sec:length}

% \iftaclpubformat
% Camera-ready documents may consist of as many pages of content as allowed by
% the Action Editor in their final acceptance letter.
% \else
% Submissions may consist of seven to ten (7-10) A4 format (not letter) pages of
% content.
% \fi

% The page limit \emph{includes} any appendices. However, references
% \iftaclpubformat
% and acknowledgments
% \fi
% do not count
% toward the page limit.

% \iftaclpubformat
% \else
% Exception: Revisions of (b) or (c) submissions may have been allowed
% additional pages of content by the prior Action Editor, as specified in their
% decision letter.
% \fi

% \section{Fonts and text size}

% Adobe's {Times Roman} font should be used. In \LaTeX2e{} this is accomplished by
% putting \verb+\usepackage{times,latexsym}+ in the preamble.\footnote{Should
% Times Roman be unavailable to you, use
% {Computer Modern Roman} (\LaTeX2e{}'s default).  Note that the latter is about
% 10\% less dense than Adobe's Times Roman font.}

% Font size requirements are listed in Table \ref{tab:font-table}. In addition to
% those requirements, the content of figures, tables, equations, etc. must be
% of reasonable size and readability.
% \begin{table}[t]
% \begin{center}
% \begin{tabular}{|l|rl|}
% \hline \bf Type of Text & \bf Size & \bf Style \\ \hline
% paper title & 15 pt & bold \\
% \iftaclpubformat
% author names & 12 pt & bold \\
% author affiliation & 12 pt & \\
% \else
% \fi
% the word ``Abstract'' as header & 12 pt & bold \\
% abstract text & 10 pt & \\
% section titles & 12 pt & bold \\
% document text & 11 pt  &\\
% captions & 10 pt & \\
% %bibliography & 10 pt & \\
% footnotes & 9 pt & \\
% \hline
% \end{tabular}
% \end{center}
% \caption{\label{tab:font-table} Font requirements}
% \end{table}




% \section{Page Layout}
% \label{ssec:layout}


% The margin dimensions for a page in A4 format (21 cm $\times$ 29.7 cm) are given
% in Table \ref{tab:margin-table}.  Start the content of all pages directly under
% the top margin.
% \iftaclpubformat
% \else
% (The confidentiality header (\S\ref{sec:ruler-and-header}) for submissions is an
% exception.)
% \fi


% \begin{table}[ht]
% \begin{center}
% \begin{tabular}{|l|}  \hline
% Left and right margins: 2.5 cm \\
% Top margin: 2.5 cm \\
% Bottom margin: 2.5 cm \\
% Column width: 7.7 cm \\
% Column height: 24.7 cm \\
% Gap between columns: 0.6 cm \\ \hline
% \end{tabular}
% \end{center}
% \caption{\label{tab:margin-table} Margin requirements}
% \end{table}


% \Taclpapers must be in two-column format.
% Allowed exceptions to the two-column format are the title, which must be
% centered at the top of the first page;
% \iftaclpubformat
% the author block containing author names and affiliations and addresses, which
% must be centered on the top of the first page and placed after the title;
% \else
% the  confidentiality header (see \S\ref{sec:ruler-and-header}) on submissions;
% \fi
% and any full-width figures or tables.

% Should the pages be numbered?  Yes, for submissions (to facilitate review); but
% no, for camera-readies (page numbers will be added at publication time).

% \Taclpapers should be single-spaced.
% \iftaclpubformat
% But, {\em an additional double-spaced version must also be provided, together with the
% single-spaced version, for the use of the copy-editors.}  A double-spaced version can
% be created by adding the ``copyedit'' option: Change \verb+[acceptedWithA]+ in
% {\footnotesize {\tt {\textbackslash usepackage}[acceptedWithA]\{\styleFileVersion\}}}
% to \verb+[acceptedWithA,copyedit]+.
% \fi

% {Indent} by about 0.4cm when starting a new paragraph that is not the first in a
% section or subsection.

% \subsection{The confidentiality header and line-number ruler}
% \label{sec:ruler-and-header}
% \iftaclpubformat
% Camera-readies should not include the left- and right-margin line-number rulers
% or headers from the submission version.
% \else
% Each page of the submission should have the header ``\confidentialtext''
% centered across both columns in the top margin.

% Submissions must include line numbers in the left and right
% margins, as demonstrated in the TACL submission-formatting
% instructions pdf file, because the line numbering allows reviewers to be very
% specific in their comments.\footnote{Authors using Word to prepare their
% submissions can create the marginal line numbers by inserting text
% boxes containing the line numbers.}
% Note that the numbers on the ruler need not line up exactly with the text lines
% of the paper. (Indeed, the line numbers generated by the recommended \LaTeX\
% files typically do not correspond exactly to the text lines.)
% \fi

% The presence or absence of the ruler or header should not change the appearance
% of any other content on the page.



% \begin{table*}[t]
% \centering
% \begin{tabular}{p{7.8cm}@{\hskip .5cm}p{7.8cm}}
% \multicolumn{1}{c}{{\bf Incorrect}} & \multicolumn{1}{c}{{\bf Correct}} \\  \hline
% ``\ex{(Cardie, 1992) employed learning.}'' &
% ``\ex{Cardie (1992) employed learning.}'' \\
% {The problem}:  ``employed learning.'' is not a sentence.  & Create by
% \verb+\citet{+\ldots\verb+}+  or \verb+\newcite{+\ldots\verb+}+. \\
% \\  \hline
% ``\ex{The method of (Cardie, 1992) works.}'' &
% ``\ex{The method of Cardie (1992) works.}''  \\
% {The problem}:  ``The method of was used.'' is not a sentence.  & Create as
% above.\\ \\\hline
% ``\ex{Use the method of (Cardie, 1992).}'' &
% ``\ex{Use the method of Cardie (1992).}''  \\
% {The problem}:  ``Use the method of.'' is not a sentence.  & Create as
% above.\\ \\\hline
% \ex{Related work exists Lee (1997).} & \ex{Related work exists (Lee,
% 1997).} \\
% {The problem}:  ``Related work exists Lee.'' is not a sentence (unless one
% is scolding a Lee). & Create by
% \verb+\citep{+\ldots\verb+}+  or \verb+\cite{+\ldots\verb+}+. \\
% \\  \hline
% \end{tabular}
% \caption{\label{tab:cite-commands} Examples of incorrect and correct citation
%   format.  Also depicted are citation commands supported by the
%   tacl2018.sty file, which is based on the natbib package and
%   supports all natbib citation commands.
%   The tacl2018.sty file also supports commands defined in previous ACL style
%   files
%   for compatibility.
%   }
% \end{table*}





% \section{The First Page}
% \label{ssec:first}

% Center the title, which should be placed 2.5cm from the top of the page,
% \iftaclpubformat
% and author names and affiliations
% \fi
% across both columns of the first page. Long titles should be typed on two lines
% without a blank line intervening.
% \iftaclpubformat
% After the title, include a blank line before the author block.
% Do not use only initials for given names, although middle initials are allowed.
% Do not put surnames in all capitals.\footnote{Correct: ``Lillian Lee'';
% incorrect: ``Lillian LEE''.} Affiliations should include authors' email
% addresses. Do not use footnotes for affiliations.
% \else
% Do not include the paper ID number assigned during the submission process.
% \fi

% \iftaclpubformat
% \else
% Although submissions should not include any author information, maintain space
% for names and affiliations/addresses so that they will fit in the final
% (camera-ready)
% version.
% \fi


% Start the abstract at the beginning of the first
% column, about 8 cm from the top of the page, with the centered header
% ``Abstract'' as specified in Table \ref{tab:font-table}.
% The width of the abstract text
% should be narrower than the width of the columns for the text in the body of the
% paper by about 0.6cm on each side.

% \section{Section headings}

% Use numbered section headings (Arabic numerals) in order to facilitate cross
% references. Number subsections with the section number and the subsection number
% separated by a dot.



% \section{Figures and Tables}

% Place figures and tables in the paper near where they are first discussed.

% Provide a caption for every illustration. Number each one
% sequentially in the form:  ``Figure 1: Caption of the Figure.'' or ``Table 1:
% Caption of the Table.''

% Authors should ensure that tables and figures do not rely solely on color to
% convey critical distinctions and are, in general,  accessible to the
% color-blind.



% \section{Citations and references}
% \label{sec:cite}


% \subsection{In-text citations}
% \label{sec:in-text-cite}
% Use correctly parenthesized author-date citations
% (not numbers) in the text. To understand correct parenthesization, obey the
% principle that \emph{a sentence containing parenthetical items should remain
% grammatical when the parenthesized material is omitted.} Consult Table
% \ref{tab:cite-commands} for usage examples.


% \iftaclpubformat
% \else
% \subsection{Self-citations}
% \label{sec:self-cite}

% Citing one's own relevant prior work should be done,  but use the third
% person instead of the first person, to preserve anonymity:
% \begin{tabular}{l}
% Correct: \ex{Zhang (2000) showed ...} \\
% Correct: \ex{It has been shown (Zhang, 2000)...} \\
% Incorrect: \ex{We (Zhang, 2000) showed ...} \\
% Incorrect: \ex{We (Anonymous, 2000) showed ...}
% \end{tabular}
% \fi

% \subsection{References}
% \label{sec:references}
% Gather the full set of references together under
% the boldface heading ``References''. Arrange the references alphabetically
% by first author's last/family name, rather than by order of occurrence in the
% text.

% References to peer-reviewed publications should be given in addition to or
% instead of preprint versions. When giving a reference to a preprint, including
% arXiv preprints, include the number.

% List all authors of a given reference, even if there are dozens; do not
% truncate the author list with an ``et al.''  Use full first/given names for
% authors, not initials.  Include periods after middle initials.

% Titles should have correct capitalization.  For example, change change
% ``lstm'' or ``Lstm'' to ``LSTM''.\footnote{If using BibTex, apply curly braces
% within the title field to preserve intended capitalization.}   Capitalize the
% first letter of the first word after a colon or similar punctuation mark.  For
% book titles, capitalize the first letter of all main words.  See the
% reference entry for \citet{Jurafsky+Martin:2009a} for an example.


% We strongly encourage the following, but do not absolutely mandate them:
% \begin{itemize}
% \item Include DOIs.\footnote{The supplied \LaTeX\ files will
% automatically add hyperlinks to the DOI when BibTeX or
% BibLateX are invoked if the hyperref package is used and
% the doi field is employed in the corresponding bib entries.
% The DOI itself will not be separately printed out in that case.}
% \item Include the version number when citing arXiv preprints, even if only one
% version exists at the time of writing.
% For example,\footnote{Bibtex entries for \citet{DBLP:journals/corr/cs-CL-0108005} and
% \citet{DBLP:journals/corr/cs-CL-9905001} corresponding to the depicted output
% can be found in the supplied sample file {\tt tacl.bib}.  We also cite
% the peer-reviewed versions \cite{GOODMAN2001403,P99-1010}, as required.}
% note the ``v1'' in the following.
% \begin{quote}
% Joshua Goodman.  2001.  A bit of progress in language modeling. {\it CoRR},
% cs.CL/0108005v1.
% \end{quote}
% An alternative format is:
% \begin{quote}
% Rebecca Hwa. 1999. Supervised grammar induction using training data with limited constituent
% information. {cs.CL/9905001}. Version 1.
% \end{quote}
% \end{itemize}

% \section{Appendices} Appendices, if any, directly follow the text and the
% references.  Recall from Section \ref{sec:length} that {\em appendices count
% towards the page
% limit.}


% \iftaclpubformat

% \section{Including acknowledgments}
% Acknowledgments appear immediately before the references.  Do not number this
% section.\footnote{In \LaTeX, one can use {\tt {\textbackslash}section*} instead
% of {\tt {\textbackslash}section}.} If you found the reviewers' or Action
% Editor's comments helpful, consider acknowledging them.
% \else
% \fi

% \section{Contributors to this document}
% \label{sec:contributors}

% This document was adapted by Lillian Lee and Kristina Toutanova
% from the instructions and files for ACL 2018, by Shay Cohen, Kevin Gimpel, and
% Wei Lu. Those files were drawn from earlier *ACL proceedings, including those
% for ACL 2017 by Dan Gildea and Min-Yen Kan, NAACL 2017 by Margaret Mitchell,
% ACL 2012 by Maggie Li and Michael White, those from ACL 2010 by Jing-Shing
% Chang and Philipp Koehn, those for ACL 2008 by Johanna D. Moore, Simone
% Teufel, James Allan, and Sadaoki Furui, those for ACL 2005 by Hwee Tou Ng and
% Kemal Oflazer, those for ACL 2002 by Eugene Charniak and Dekang Lin, and
% earlier ACL and EACL formats,  which were written by several people,
% including John Chen, Henry S. Thompson and Donald Walker. Additional elements
% were taken from the formatting instructions of the {\em International Joint
% Conference on Artificial   Intelligence} and the \emph{Conference on Computer
% Vision and Pattern Recognition}.


\bibliography{tacl2018}
\bibliographystyle{acl_natbib}

\end{document}



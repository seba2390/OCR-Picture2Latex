\section{User study}
\label{sec:user_study}

We conduct an exploratory user study to better understand the needs of BLV scientists when reading papers, and to assess whether our prototype supports these needs. The study consists of a preliminary questionnaire and semi-structured video interview. Interviews are conducted remotely on Zoom.\footnote{\href{https://zoom.us/}{https://zoom.us/}} All recruitment materials, questionnaires, and the interview plan are reviewed and approved by the internal review board at \allenai. We recruit and interview \numusers users, with a pilot involving two users, and a main study involving four users. Modifications to the prototype between pilots and the main study can be found in Section~\ref{sec:pdf2html}. We report results from all \numusers participants in any analysis that does not involve the prototype, and for analysis that directly involves the prototype, we denote all cases where prototype modifications between the pilot and main study may impact our results.

The inclusion criteria for participants are:

\begin{itemize}
    \item The participant is over 18 years of age;
    \item The participant identifies as blind or low vision;
    \item The participant reads scientific papers regularly (more than 5 per year);
    \item The participant must have used a screen reader to read a paper in the last year; and
    \item The participant must complete the pre-interview questionnaire.
\end{itemize}

Participants were
%\jonathan{i think past tense is a little more clear for things we did} 
recruited through mailing lists, word-of-mouth, and snowball sampling. Prior to each interview, the participant was asked to provide several keywords corresponding to their subject areas of interest, and between 3--5 papers where they experienced difficulty reading the PDF. Among the 3--5 papers, we selected one paper to use for the study, based on the availability of an HTML render, and maximizing the features that would be seen during the user study (e.g., given a choice between a paper with figures and a paper without figures but where both otherwise demonstrate the same paper components, we would select the paper with figures). Each study session was 75 minutes, consisting of three phases:

\begin{itemize}[itemsep=5pt]
    \item[] \textbf{Phase I: Capturing challenges with current work flow} \newline
    The primary research questions we investigate in this phase are: 
    \begin{itemize}[noitemsep, leftmargin=0.4in]
        \item[--] What methods and/or tools do BLV researchers use to assist in reading the literature?
        \item[--] What main accessibility challenges do BLV researchers face?
        \item[--] How do BLV researchers cope with these challenges?
    \end{itemize}
    We first asked the participant to describe their current workflow and the challenges they face when reading papers, clarifying how the user copes with challenges when their workflow does not adequately address the problem. We then asked the participant to demonstrate how they currently read a paper, by opening a paper PDF and walking us through the usage of their tools (PDF viewer, screen reader, magnifier, speech-to-text, etc). Participants kept their computer audio on so we could hear the output of their reader tools. The participant was asked to think aloud and describe their actions when reading the paper. We asked the participant to demonstrate any reading challenges they described in their pre-interview questionnaire. At the end of this phase, we asked the participant to assess how easy or difficult it was to read the paper with their current reading pipeline.
    \item[] \textbf{Phase II: Interaction with prototype} \newline 
    The primary research questions we investigate in this phase are: 
    \begin{itemize}[noitemsep, leftmargin=0.4in]
        \item[--] What features of the HTML render resonated positively with the participant?
        \item[--] What problems can be identified in the HTML render?
    \end{itemize}
    The goal of this phase was to understand how helpful or not helpful the HTML render is to the participant. The participant was asked to interact with an HTML render of the same paper they read in Phase I in the \scially prototype. We first provided an introduction to the prototype, then allowed the participant to proceed uninterrupted for several minutes interacting with the render. The participant was asked to think aloud during their interactions. Towards the end of this phase, we prompted the participant to interact with any features in the HTML render they may have skipped over. At the end of this phase, we asked the participant to assess how easy or difficult it was to read the paper with the HTML render.
    \item[] \textbf{Phase III: Q\&A and discussion} \newline 
    The primary objectives of this phase are to answer the questions:
    \begin{itemize}[noitemsep, leftmargin=0.4in]
        \item[--] How likely is the participant to use the HTML render in the future?
        \item[--] How can the HTML render be improved to best meet the participant's needs moving forward?
    \end{itemize}
    The participant was given further opportunities to ask questions or discuss the prototype. The participant was asked to describe their perceived pros and cons of the prototype, and to provide suggestions of missing features, ordered by priority. We asked the participant whether they would use this prototype if it were available, and if not, what features would need to be implemented to change that decision. 
\end{itemize}

\noindent The interviews were conducted by one author, with two other authors observing and participating during Phase III. All interviews were recorded for followup analysis, and participants were compensated with a \$150 USD gift card for their time. The questions used to guide the semi-structured interview are provided in Appendix~\ref{app:interview_questions}. 

We follow a grounded theory approach to identify themes and concepts from the participant interviews. We first perform open coding to identify relevant concepts, then axial coding to group these concepts under broad themes. These themes are 1) the technologies employed by users, 2) challenges in their current reading pipeline, and 3) mitigation or coping strategies, and in relation to the \scially prototype: 4) positive features, 5) negative features or issues with the prototype, and 6) suggestions for improvement. 
Interviews are selectively coded a second time to identify all concepts falling under each theme. We also employ the same method to code issues raised by participants in the pre-interview questionnaire. 

Themes and concepts are arrived upon by two authors following detailed reading of the interviews. In several cases, we further define attributes associated with some concepts, such as defining whether the technologies used were in relation to opening PDFs, screen reading, or other tasks; or whether the challenges identified affect the whole document, navigation, text, or a particular in-paper element. These delineations are described further in their respective results sections.

\subsection{Study participants}

Participants are graduate students, PhD students, and faculty members from predominantly English-speaking countries, whose primary research areas are in computer science, though also spanning neuroscience and mathematics. We interviewed two participants during the pilot phase and four participants during the main phase of our study. We report findings from all six participants for all themes captured in Phase I of the study. Since only minor changes were made to the prototype between the pilot and main study, we report findings from all participants for Phase II and III as well, making note of features that changed following the pilots. Three of six participants
study human-computer interaction and accessibility, which may be due in part to our sampling methodology, but may also reflect the relevance of accessibility research to BLV researchers. Other study participants conduct research in the areas of machine learning, neuroscience, software engineering, and blockchain. All but one participant reported having more than one year of experience using screen readers. The tools employed by participants are summarized in Table~\ref{tab:user_summary} along with the version of the \scially prototype with which they interacted.

\begin{table}[t!]
    \small
    \centering
    \begin{tabularx}{0.8\linewidth}{lllL{70mm}}
        \toprule
        \textbf{ID} & \textbf{Study} & \textbf{Prototype Version} & \textbf{Current Tools} \\
        \midrule
        P1 & Pilot & v0.1 & NVDA Screen Reader, Adobe Acrobat Reader \\
        \midrule
        P2* & Pilot & v0.2 & Mac Text-to-speech, Mac Magnifying Glass (sighted navigation), Mac Preview \\
        \midrule
        P3 & Main & v0.3 & Braille display, Mac VoiceOver, JAWS/NVDA on Windows, Mac Preview, Adobe Acrobat Reader \\
        \midrule
        P4 & Main & v0.3 & Mac VoiceOver, Mac Preview or Adobe Acrobat Reader \\
        \midrule
        P5 & Main & v0.3 & Microsoft Narrator, Adobe Acrobat Reader \\
        \midrule
        P6 & Main & v0.3 & Braille display, InftyReader, Mac VoiceOver, Mac Preview  \\
        \bottomrule
    \end{tabularx}
    \caption{User study participants, the prototype versions they interacted with, and the tools they currently use for reading papers. *P2 is low vision and uses sighted navigation tools in conjunction with a screen reader.
    }
    \label{tab:user_summary}
%     \Description{
% ID; Study; Prototype Version; Current Tools 
% P1; Pilot; v0.1; NVDA Screen Reader, Adobe Acrobat Reader 
% P2*; Pilot; v0.2; Mac Text-to-speech, Mac Magnifying Glass (sighted navigation), Mac Preview 
% P3; Main; v0.3; Braille display, Mac VoiceOver, JAWS/NVDA on Windows, Mac Preview, Adobe Acrobat Reader 
% P4; Main; v0.3; Mac VoiceOver, Mac Preview or Adobe Acrobat Reader 
% P5; Main; v0.3; Microsoft Narrator, Adobe Acrobat Reader 
% P6; Main; v0.3; Braille display, InftyReader, Mac VoiceOver, Mac Preview  
%     }
\end{table}

\subsection{Study findings}

\subsubsection*{Summary of current experience} 

Of the \numusers participants, three users have experience with screen readers on the Windows OS, such as NVDA, JAWS, and Microsoft Narrator, and three users use VoiceOver on MacOS. Two users use braille display in conjunction with their screen reader. One participant (P2) is low vision and uses a combination of text-to-speech and a magnifying glass to perform sighted navigation; P2's primary reading interaction involves selecting blocks of text in the PDF and using text-to-speech. Adobe Acrobat Reader is the most common software for opening PDFs; though several participants use Preview in MacOS, with one participant (P4) explicitly stating a preference for Preview over Acrobat. One participant uses a proprietary tool called InftyReader, which converts PDFs into ASCII text and math formulas into MathML, which is accessible.

\subsubsection*{Challenges of current PDF reading pipeline}

Table~\ref{tab:current_challenges} lists the challenges recognized by all participants in their current PDF reading pipeline. Some of these challenges affect the entire document, e.g., when a document lacks heading markup, it affects the ability to navigate the whole document. Others pertain to specific elements in PDFs, like inaccessible math formulas or lack of figure alt-text. All six users discussed the inaccessibility of math formulas. Unfortunately, document elements like math, figures, tables, and algorithm blocks are used to convey a significant amount of the information content of a paper, and the inability to access their content can produce negative impacts on the reader's ability to understand the paper.

\begin{table}[t!]
    \centering
    \begin{tabular}{lll}
        \toprule
        \textbf{Issue description} & \textbf{Affects} & \textbf{Raised by user} \\
        \midrule
        Scanned PDFs cannot be read without remediation & Document & P3, P4, P5* \\
        \midrule
        No headings/sub-headings for navigation & Navigation & P1, P3, P5 \\
        Figures are not annotated as figures & Navigation & P1, P5 \\
        Losing cursor focus when switching away from the PDF & Navigation & P1 \\
        Headings are not hierarchical (no sub-headings) & Navigation & P5 \\
        \midrule
        Text is read as single string (no spaces or punctuation) & Text & P1, P4, P5 \\
        Headers/footers/footnotes mixed into text & Text & P1, P4, P5 \\
        Words with ligatures are mispronounced & Text & P1, P3 \\
        Words split at line breaks are mispronounced & Text & P2, P3 \\
        Reading order is incorrect & Text & P3, P5 \\
        Text before and after figures sometimes skipped & Text & P4 \\
        Text on some pages not recognized at all & Text & P4 \\
        \midrule
        Math content is inaccessible & Element & P1, P2, P3, P4, P5, P6 \\
        Tables are inaccessible & Element & P1, P2*, P3, P5, P6 \\
        Figures lack alt-text & Element & P1, P3, P5, P6 \\
        Figure captions are not associated with figures & Element & P1, P5 \\
        Characters or words in figures are read and do not make sense & Element & P4, P5 \\
        Figure alt-text (when provided) is not descriptive & Element & P5 \\
        Code blocks are inaccessible & Element & P2, P4 \\
        \bottomrule
    \end{tabular}
    \caption{Challenges to PDF reading identified by participants during interviews. *Only identified as an issue during pre-interview questionnaire.}
    \label{tab:current_challenges}
%     \Description{
% Issue description; Affects; Raised by user 
% Scanned PDFs cannot be read without remediation; Document; P3, P4, P5* 
% No headings/sub-headings for navigation; Navigation; P1, P3, P5 
% Figures are not annotated as figures; Navigation; P1, P5 
% Losing cursor focus when switching away from the PDF; Navigation; P1 
% Headings are not hierarchical (no sub-headings); Navigation; P5 
% Text is read as single string (no spaces or punctuation); Text; P1, P4, P5 
% Headers/footers/footnotes mixed into text; Text; P1, P4, P5 
% Words with ligatures are mispronounced; Text; P1, P3 
% Words split at line breaks are mispronounced; Text; P2, P3 
% Reading order is incorrect; Text; P3, P5 
% Text before and after figures sometimes skipped; Text; P4 
% Text on some pages not recognized at all; Text; P4 
% Math content is inaccessible; Element; P1, P2, P3, P4, P5, P6 
% Tables are inaccessible; Element; P1, P2*, P3, P5, P6 
% Figures lack alt-text; Element; P1, P3, P5, P6 
% Figure captions are not associated with figures; Element; P1, P5 
% Characters or words in figures are read and do not make sense; Element; P4, P5 
% Figure alt-text (when provided) is not descriptive; Element; P5 
% Code blocks are inaccessible; Element; P2, P4 
%     }
\end{table}

\subsubsection*{Coping mechanisms}

The coping mechanisms employed by BLV researchers to read inaccessible PDFs are wide-ranging, often involving trying tools outside of their primary workflow, soliciting help from others, or in the worst case, giving up and moving on. We describe these in Table~\ref{tab:coping_mechanisms}. Several users reported trying certain tools like alternate PDF readers, browsers, or optical character recognition (OCR), even though the tools usually do not result in a significant improvement over their standard pipeline; when asked why, several participants reported feeling ``hopeful'' that a tool might work (P1) or hoping to get lucky (P3).

Several of these coping mechanisms involved other people. For example, three participants reported needing to ask sighted colleagues or family members to copy text, or to explain select paper content, especially figures and equations. Asking for PDF remediation was also a possibility for several participants; in this process, workers at the researcher's host institution convert a PDF into an accessible format, manually correcting equation representation and writing descriptions for figures. The output of the remediation process is seen as ``ideal'' (P4), but the process takes significant time (several weeks for any PDF) and may not fit into a researcher's schedule and timeline. Additionally, this process may only be available to researchers affiliated with a significantly large and resourced institution, and as P6 discusses, may no longer be a viable option for those who work outside of academia. In some cases, BLV researchers may also message authors directly to gain access to the source documents (P3 and P4). Both LaTeX source and Word documents are more accessible than PDFs, and access to these source documents can greatly improve the ability to read these papers.

Perhaps most disheartening is how often BLV researchers may simply give up in the face of an inaccessible paper. P1 says that by the time he has spent several hours making a paper readable, he may have already lost interest and motivation to read it. When asked how often papers are abandoned, P3 responds 60--70\% of the time. Though P4 does not discuss abandonment directly, P4 shares the following relevant sentiment: ``reading papers is the hardest part of research'' for a BLV researcher, and if papers were more accessible, there would be more blind researchers.

\begin{table}[t!]
    \small
    \centering
    \begin{tabular}{llp{60mm}}
        \toprule
        \textbf{Coping mechanism} & \textbf{Raised by user} & \textbf{What users said} \\
        \midrule
        Give up, abandon the paper & P1, P3, P5 & P3: when asked how often they abandon papers, answers ``60--70\% of the time'' \newline P5: sometimes the only option is to ``sit down and start crying'' (jokingly, though the sentiment is true) \\
        \midrule
        Try other conversion tools & P1, P3, P6 & \\
        \midrule
        Download LaTeX source or Word document if available & P3, P4, P6 & \\
        \midrule
        Ask sighted colleagues or family members to read & P3, P5, P6 & \\
        \midrule
        Ask for remediation / convert to braille & P4, P5, P6 & P4: 10 day turnaround is on the quick side, which is not good enough for research \newline P5: process takes a long time, around 1-2 weeks \\
        \midrule
        Try other PDF readers or browsers & P1, P6 & P1: may try Microsoft Edge browser even though it usually does not help, but he feels ``hopeful'' \\
        \midrule
        Message authors to get source document & P3, P4 & P4: sometimes the author manuscript is accessible but the camera-ready version is not; fault of the conferences and publishers, not the authors \\
        \bottomrule
    \end{tabular}
    \caption{Coping mechanisms discussed by users for dealing with challenging papers.}
    \label{tab:coping_mechanisms}
    \Description{
% Coping mechanism; Raised by user; What users said 
% Give up, abandon the paper; P1, P3, P5; P3: when asked how often they abandon papers, answers "60--70\% of the time", P5: sometimes the only option is to "sit down and start crying" (jokingly, though the sentiment is true) 
% Try other conversion tools; P1, P3, P6; 
% Download LaTeX source or Word document if available; P3, P4, P6; 
% Ask sighted colleagues or family members to read; P3, P5, P6; 
% Ask for remediation / convert to braille; P4, P5, P6; P4: 10 day turnaround is on the quick side, which is not good enough for research, P5: process takes a long time, around 1-2 weeks 
% Try other PDF readers or browsers; P1, P6; P1: may try Microsoft Edge browser even though it usually does not help, but he feels "hopeful" 
% Message authors to get source document; P3, P4; P4: sometimes the author manuscript is accessible but the camera-ready version is not; fault of the conferences and publishers, not the authors 
    }
\end{table}

\subsubsection*{Response to HTML render}

All user interviews were analyzed to extract positive and negative responses to various features or flaws of the prototype. We summarize these features and flaws in Table~\ref{tab:prototype_features}. Among the participants' favorite features are links between inline citations and references (all 6 participants), section headings for navigation (5 participants), the table of contents (4 participants), and figures tagged as figures with associated figure captions (3 participants). Regarding links between inline citations and references, several participants were especially supportive of the return links that allow the reader to return back to their reading context after following a citation link. P3 said that the links acted as external memory, allowing BLV users to essentially ``glance'' at the bibliography and back, like a sighted user might. Similar sentiments were shared by P5 and P6, although P5 also proposed the possibility of preserving the context even further by providing bibliography information inline rather than navigating back and forth between the main text and references section.

Among the negative features observed by participants, most have to do with imperfect extraction, for example, incorrectly extracted headings (3 participants), missed headings (2 participants), and various extraction issues with code blocks, tables, equations, and more. Many of these issues are known and quantified in Section~\ref{sec:evaluation}. Of these issues, problems with heading extraction were most notable, likely because the heading structure is the first element of the document with which the participants interact, and it provides a mental model of the overall document structure. Mistakes in heading extraction are obvious and erode trust in our overall system. As P5 says, ``it's really important that I trust it,'' and errors of this nature, both false positive and false negative extractions, can reduce trust. Similarly, though we describe in our introductory material that our system currently does not extract equations, P6 points out that it is unclear whether the system extracts equations because occasionally math can be found in the body text. This type of conflict between what is described and what is seen can also reduce trust. However, one may be able to build trust even in the face of extraction errors by indicating to the user when content is not extracted; as P4 says regarding the placeholders for not extracted items, ``at least I know there was an equation here.''

\begin{table}[t!]
    \footnotesize
    \centering
    \begin{tabularx}{\linewidth}{llp{60mm}}
        \toprule
        \textbf{Feature} & \textbf{Raised by user} & \textbf{What users said} \\
        \midrule
        \textsc{Positive} & & \\
        \midrule
        Bidirectional links between inline citations and references & P1, P2, P3, P4, P5, P6 & P3: ``very few research teams actually get this and get this right, so well done''; ``crucial piece of the puzzle'' \\
        Headings for easy navigation & P1, P2, P3, P4, P6 & P4: ``Headings are the best thing ever''; makes it very clear what section you are in \\
        Table of contents* & P2, P3, P5, P6 & \\
        Figures are tagged as figures, and captions are associated & P4, P5, P6 & \\
        Can use browser and OS features like find/copy/paste  & P1, P4 & \\
        Simple typography for reading & P2 & \\
        Can interact with headings word-by-word or letter-by-letter & P4 & \\
        Not extracted items are noted as missing & P4 & P4: ``at least I know there was an equation here'' \\
        \midrule
        \textsc{Negative} & & \\
        \midrule
        Some headings extracted incorrectly & P1, P3, P5 & \\
        Some headings missed in extraction & P3, P5 & P5: ``it's really important that i trust it''; ``there [should be] *no* false negatives'' \\
        Code block not extracted & P2, P4 & \\
        Tables are extracted as figures & P2, P6 & \\
        Equations not extracted & P4, P6 & P6: Not sure if this system extracts equations because sometimes there is some math in the body text \\
        Figures placed away from text* & P1 & \\
        No alt-text extracted & P1 & \\
        URLs missing from bibliography entries** & P2 & \\
        Some information not surfaced (keywords, footnotes) & P3 & \\
        Some headers/footers/footnotes mixed in text & P4 & \\
        Headings are not hierarchical & P5 & \\
        \bottomrule
    \end{tabularx}
    \caption{Positive and negative features identified in the prototype. *The feature was implemented or the issue addressed in v0.2 following P1 pilot. **The issue was addressed in v0.3 following P2 pilot.}
    \label{tab:prototype_features}
%     \Description{
% Feature; Raised by user; What users said 
% Positive; 
% Bidirectional links between inline citations and references; P1, P2, P3, P4, P5, P6; P3: "very few research teams actually get this and get this right, so well done"; "crucial piece of the puzzle" 
% Headings for easy navigation; P1, P2, P3, P4, P6; P4: "Headings are the best thing ever"; makes it very clear what section you are in 
% Table of contents*; P2, P3, P5, P6; 
% Figures are tagged as figures, and captions are associated; P4, P5, P6; 
% Can use browser and OS features like find/copy/paste ; P1, P4; 
% Simple typography for reading; P2; 
% Can interact with headings word-by-word or letter-by-letter; P4; 
% Not extracted items are noted as missing; P4; P4: "at least I know there was an equation here" 
% Negative; 
% Some headings extracted incorrectly; P1, P3, P5; 
% Some headings missed in extraction; P3, P5; P5: "it's really important that i trust it"; "there [should be] *no* false negatives" 
% Code block not extracted; P2, P4; 
% Tables are extracted as figures; P2, P6; 
% Equations not extracted; P4, P6; P6: Not sure if this system extracts equations because sometimes there is some math in the body text 
% Figures placed away from text*; P1; 
% No alt-text extracted; P1; 
% URLs missing from bibliography entries**; P2; 
% Some information not surfaced (keywords, footnotes); P3; 
% Some headers/footers/footnotes mixed in text; P4; 
% Headings are not hierarchical; P5; 
%     }
\end{table}



\subsubsection*{Difficulty scale} 

The responses of the users to the difficulty of their current pipeline versus the HTML render are shown in Table~\ref{tab:taskload}. We ask the following question: \textit{On a scale of 1 to 5, how easy or difficult was it to read this paper with the HTML render, and why? (Answers: 1 = Very easy; 2 = Easy; 3 = Neutral; 4 = Difficult; 5 = Very difficult)}

All participants in the main study reported that the HTML render is easier for reading than their current pipeline. Reductions in difficulty rating ranged from 0.5 to 3.0. Most of our participants rated their current pipeline as difficult (4 participants) or neutral (1 participant), with one participant who is low vision (P2) reporting that their current pipeline is easy. During our pilot sessions, users reported that the HTML render was difficult to use. For the main study, users reported the HTML render as neutral or easy to use.

P2 is the only participant to report the HTML render as being more difficult to use than their current pipeline; we note that P2 is sighted and did not engage with most of the navigation features we designed and implemented for screen reader-based navigation. Because P2 primarily interacted with papers through sighted navigation, text highlighting, and text-to-speech, they were able to interact with section headers, figures, tables, and equations in the original PDF using the magnifier tool, and found any missing content in the HTML render to be significantly detrimental to their reading experience.

The overall median difference in difficulty scores between the PDF and HTML render is modest, at 0.75. This modest change may be due to the conflation of interface design and system errors when asking participants to rate the difficulty of use. In general, all users responded very positively to the interface design, especially around the navigational features we introduce. Issues were raised around extraction accuracy and the propagation of these errors to the interface. We may be able to offset some of the latter issues by detecting and removing papers that suffer from more extraction errors, though we leave this to future work.

\begin{table}[tb!]
    \centering
    \begin{tabular}{llp{12mm}p{12mm}lp{15mm}}
    \toprule
        \textbf{ID} & \textbf{Study} & \textbf{Current pipeline} & \textbf{HTML render} & \textbf{Difference} & \textbf{Would use in future} \\
    \midrule
        P1 & Pilot & 4.0 & 4.0 & 0.0 & Yes \\
        P2 & Pilot & 2.0 & 4.0 & \color{red}{-2.0} & Yes \\
    \midrule
        P3 & Main & 3.0 & 2.0 & \color{darkgreen}{1.0} & Yes \\
        P4 & Main & 4.0 & 1.0 & \color{darkgreen}{3.0} & Yes \\
        P5 & Main & 4.0 & 3.0 & \color{darkgreen}{1.0} & Yes* \\
        P6 & Main &4.0 & 3.5 & \color{darkgreen}{0.5} & Yes \\
    \bottomrule
    \end{tabular}
    \caption{Participant ratings on the difficulty scale (1 = very easy, 2 = easy, 3 = neutral, 4 = difficult, 5 = very difficult) and whether they would use the tool in the future. All participants reported a change from more difficult to more easy when moving from their current pipeline to the HTML render except P2, who uses sighted navigation. The median reduction in difficulty score for all participants is 0.75. All participants reported that they would be very likely to use the system in the future were it to be available; P5's response is contingent on improvements in section heading extraction.
    }
    \label{tab:taskload}
%     \Description{
% ID; Study; Current pipeline; HTML render; Difference; Would use in future 
% P1; Pilot; 4.0; 4.0; 0.0; Yes 
% P2; Pilot; 2.0; 4.0; -2.0; Yes 
% P3; Main; 3.0; 2.0; 1.0; Yes 
% P4; Main; 4.0; 1.0; 3.0; Yes 
% P5; Main; 4.0; 3.0; 1.0; Yes* 
% P6; Main &4.0; 3.5; 0.5; Yes 
%     }
\end{table}

\subsubsection*{Future usage}

At the end of each session, we ask users whether they would be likely to use the prototype in the future if it were made publicly available on a range of papers. We ask specifically: \textit{On a scale of 1 to 5, how likely are you to use the HTML render, if it is available to you in the future? (Answers: 1 = Very unlikely, 2 = Unlikely, 3 = Neutral, 4 = Likely, 5 = Very likely)} If the answer is unlikely or neutral, we ask what changes would need to be made to the tool such that they would use it.

All users reported that they would use the prototype in the future.
Five users responded 5, that they would be very likely to use it; one user (P5) responded 3 to the prototype as it currently is, and 5 if some of the issues for heading extraction were addressed. P1, who participated in an early pilot with fewer implemented features, said that this would become a tool in the toolbox, but he would not be able to rely solely on it due to incomplete extractions. P5 expressed a similar sentiment, that in its current state, he may try the prototype system when his current workflow fails, but if issues around heading extraction were addressed, he would be very likely to use it. P3 replies when asked how the system might be integrated into their workflow, ``I think it would become the workflow.'' P4 says ``for unaccessible PDFs, this is life-changing.''


\subsection{Design recommendations}
\label{sec:designrecs}

\begin{figure}[t!]
    \centering
    \includegraphics[width=0.8\linewidth]{figures/designrecs.png}
    \caption{Design recommendations for screen reader friendly paper reading systems. A system should aim to provide the document structure in a way that matches the mental model of the user, and to tag all elements appropriately. These aspects are achievable through proper tagging of a paper, including in PDF format. Additionally, a system should aim to act as external memory for the user, minimizing the amount of cognitive load needed to return to their reading context. To improve trust, a system should indicate when there is known missing data in the extraction or a possibility of missing or incorrect data. Finally, a system should reduce verbosity, ensuring that as few keystrokes as possible are necessary for the user to perform their desired task. 
    }
    \label{fig:design_recs}
    \Description{Five design recommendations. 1. A picture of a building on a circular dark blue background. Text that reads "Document structure should match the mental model of the user; headings should be annotated and hierarchical; reading order should be specified; reading order should match expectations, e.g. starts with title, authors, abstract, introduction and so on." 2. A picture of the word <tag/> on a circular blue background. Text that reads "Objects in the document should be tagged appropriately; headings should be tagged heading 1 through heading 6 as appropriate; figures and tables should be tagged as such; in HTML, lists should be tagged as unordered or ordered lists (<ul> or <ol>) as appropriate." 3. A picture of a brain on a circular yellow background. Text that reads "The system should act as external memory for the user; in-document links can be bidirectional to imitate 'glancing' behavior; bookmarks can be useful for returning to notable passages." 4. A picture of a no entry sign on a circular light gray background. Text that reads "Indicate known missing data and potential errors; some amount of error is tolerable, but these should be indicated to the user; builds user trust in the system." 5. A picture of a pair of lips on a circular dark gray background. Text that reads "Reduce verbosity; remove unnecessary text around links and other introduced text elements or features; minimize key strokes necessary for navigation."}
\end{figure}

We distill our learnings into a set of five design recommendations for BLV user-friendly paper reading systems. Figure~\ref{fig:design_recs} summarizes the following recommendations:

\begin{enumerate}[itemsep=4pt]
    \item[1.] \textbf{Document structure should match the mental model of the user.} Structure is necessary for providing an overview of a document and is essential to navigation. Headings in a paper should be tagged as such and the hierarchy of the headings should match the mental model of the user, i.e., top level headings should be tagged \texttt{<h1>} or \texttt{<h2>}, and lower level headings \texttt{<h3>} through \texttt{<h6>} accordingly. Reading order should be specified, as to not interject non-body text objects into the body text, e.g., headers, footers, and footnotes often disrupt the main flow of text because they visually break paragraphs. Similarly, a user expects a natural flow to a paper, beginning with the title, authors, abstract, introduction etc, and ending with conclusions and references. Papers with various elements interspersed are disruptive of this mental model and can interfere with the reader's understanding of the document.

    \item[2.] \textbf{Objects in the paper should be tagged appropriately.} Self-explanatory. Headings should be tagged as headings, figures as figures, tables as tables, lists as lists and so on. Appropriate tagging allows a user to take advantage of the screen reader's capabilities for navigating to specific types of objects, e.g., most screen readers have shortcuts for navigating headings, and to figures or lists. Proper tagging emulates a sighted user's ability to detect visually distinct objects such as headings, figures, and tables. When objects are not appropriately tagged, a screen reader user must scroll through the whole document each time to identify the desired sections.

    \item[3.] \textbf{The system should act as external memory for the user.} 
    Visual layout can act as a source of external memory for sighted users, who can quickly derive reading context and object types from visual cues. For BLV users, strategies for emulating such external memory can be beneficial. For example, bi-directional navigation for all in-document links are a type of ``glancing'' feature. With this feature, a user no longer needs to commit text to memory in order to rediscover their previous reading context after navigating away. P3, in particular, emphasizes that these features are a ``crucial piece of the puzzle.'' Other memory features like bookmarking or note-taking may also be helpful for returning the user to their reading context.

    \item[4.] \textbf{Indicate known missing data and potential errors.} To facilitate trust in the system, the system should indicate the presence of missing and erroneous data to users. Some degree of fault tolerance is permitted, as long as the overall benefit to the user is greater. However, as these systems rely on statistical methods, extraction quality is rarely perfect. Most users indicate a preference for knowing when the system fails, rather than dealing with the uncertainty of figuring out whether the issue is with the underlying paper, or with the extraction and reading interface.

    \item[5.] \textbf{Reduce verbosity.} Any minimization of unnecessary text and spaces between links can simplify navigation for BLV users. Though these extra commas and spaces may seem innocuous for sighted users, they require extra keystrokes for screen readers. Reduction of unnecessary verbosity around links and introduced features can save time for screen reader users.

\end{enumerate}

The overarching themes of these recommendations are to reduce user cognitive load and improve trust in the system. Regarding cognitive load, interruptions to reading flow for BLV users are especially disruptive, since there are no visual markers to help identify reading context. Paper reading systems for BLV users should therefore attempt to mitigate cognitive load caused by loss of context, by allowing users to quickly navigate back to their reading context when following any links, and by avoiding any disruption of reading flow. Regarding this latter point, properly labeled reading order, headings for navigation, and appropriately tagged objects all contribute to mitigating disruptions. Further, it is also important to remove interjections from headers, footers, footnotes, figure and table captions, and other text, all of which interrupt the natural flow of reading.

Regarding user trust in the system: this should a priority of any system builder. Because PDF extraction and document rendering are imperfect processes, some degree of error is expected. Though all participants in our user study expressed that some degree of error is tolerable, one can mitigate the conversion of errors to distrust by clearly indicating known errors and missing content in the system. For example, in some cases our system is unable to extract a figure caption; if the caption for Figure 3 is not extracted, rather than skipping from Figure 2 to Figure 4 and causing confusion for the reader, it is better to indicate that Figure 3 is missing in the extraction.

A system that responds quickly to user requests is obviously more desirable. However, several participants indicated that some wait time is acceptable, especially if a longer wait time corresponds to a higher quality reading experience. Though we report this finding, we ask readers to take it with a grain of salt. This point may not hold for all or even a majority of users, since several users also remark on the PDF remediation process (which usually takes 1--2 weeks) as being too long to adequately support their research workflow.

Though we derive these design recommendations in the scope of paper reading, they are generalizable to other classes of documents. In fact, several of these design principles echo available guidelines for human-AI interaction \citep{Amershi2019GuidelinesFH}, especially in indicating the capabilities and limitations of the system (recommendation 4). A number of our recommendations are simply good practice, such as exposing the structure of a document and tagging document objects appropriately, and are covered by current guidelines for creating accessible documents. Other recommendations focus on emulating the types of advantages that sighted users derive from layout and visual information, but to implement them in such a way that BLV users can benefit, e.g. using the system as a source of external memory.

\section{Analysis of academic PDF accessibility}
\label{sec:sos}

To capture and better characterize the scope and depth of the problems around academic PDF accessibility, we perform a broad meta-scientific analysis. We aim to measure the extent of the problem (e.g., what proportion of papers have accessible PDFs?), whether the state of PDF accessibility is improving over time (e.g., are papers published in 2019 more likely to be accessible than those published in 2010?), and whether the typesetting software used to create a paper is associated with the accessibility of its PDF (e.g., are papers created using Microsoft Word more or less accessible than papers created with other software?).

Prior studies on PDF accessibility have been limited to papers from specific publication venues such as CHI, ASSETS, W4A, DSAI, and journals in disability research. Notably, these venues are closer to the field of accessible computing, and are consequently more invested in accessibility.\footnote{See submission and accessibility guidelines for ASSETS (\href{https://assets19.sigaccess.org/creating_accessible_pdfs.html}{https://assets19.sigaccess.org/creating\_accessible\_pdfs.html}), CHI (\href{https://chi2021.acm.org/for-authors/presenting/papers/guide-to-an-accessible-submission}{https://chi2021.acm.org/ for-authors/presenting/papers/guide-to-an-accessible-submission}), W4A (\href{http://www.w4a.info/2021/submissions/technical-papers/}{http://www.w4a.info/2021/submissions/technical-papers/}) and DSAI (\href{http://dsai.ws/2020/submissions/}{http://dsai.ws/2020/submissions/}).}  We expand upon this work by investigating accessibility trends across various fields of study and publication venues. Our goal is to characterize the overall state of paper PDF accessibility and identify ongoing challenges to accessibility going forward.

\subsection{Data \& methods}\label{subsec:data-methods}

We sample PDFs from the Semantic Scholar literature corpus \citep{Ammar2018ConstructionOT} for analysis. We construct a dataset of papers by sampling PDFs published in the years of 2010--2019 stratified across the 19 top level fields of study defined by Microsoft Academic Graph \citep{msr:mag1, Shen2018AWS}. Examples of fields include Biology, Computer Science, Physics, Sociology, and others. This dataset allows us to investigate the overall state of PDF accessibility for academic papers, and to study the relationship between field of study and PDF accessibility. 

For each field of study, we sample papers from the top venues by total citation count, along with some documents without venue information, which include things like books and book chapters. The resulting papers come from 1058 unique publication venues; for each field of study, between 29 and 110 publication venues are represented, with Art on the minimum end, and Economics and Computer Science on the maximum end. Each field is represented by an average of 65 different publication venues. The vast majority of documents sampled into our dataset are published papers, rather than preprints or other non-peer-reviewed manuscripts. Publication venues represented in our sample are generally highly reputable journals, for example, \textit{The Lancet} or \textit{Neurology} for Medicine, \textit{The Astrophysical Journal} and \textit{Physical Review Letters} for Physics, or various IEEE publications for Computer Science and Engineering. In some cases, the mapping between publication venue and field of study can be unclear; for example, the publication venue \textit{Mathematical Problems in Engineering} is associated with Mathematics in our sample rather than Engineering. From an examination of the data, classifications seem reasonable and could be justified. We estimate that around 2.2\% of the sample are conference papers, 6.1\% are book chapters, reports, or lecture notes, less than 0.5\% are preprints, and the remaining majority are journal publications. We believe this is a reasonably representative sample of paper-like documents available to scholars and researchers.

We analyze the PDFs in our dataset using the Adobe Acrobat Pro DC PDF accessibility checker.\footnote{\href{https://www.adobe.com/accessibility/products/acrobat/using-acrobat-pro-accessibility-checker.html}{https://www.adobe.com/accessibility/products/acrobat/using-acrobat-pro-accessibility-checker.html}} Though this checker is proprietary and requires a paid license, it is the most comprehensive accessibility checker available and has been used in prior work on accessibility \citep{Lazar2017MakingTF, Ribera2019PublishingAP, Nganji2015ThePD}. Alternatively, non-proprietary PDF parsers such as PDFBox\footnote{\url{https://github.com/apache/pdfbox}} do not consistently extract accessibility criteria from sample PDFs, even when the criteria are met. We also prefer Adobe's checker to PDFA Inspector, used by \citet{Brady2015CreatingAP}, because PDFA Inspector only analyzes three criteria, whereas we are interested in other accessibility attributes as well, like the presence of alt-text.

For each PDF, the Adobe accessibility checker generates a report that includes whether or not the PDF passes or fails tests for certain accessibility features, such as the inclusion of figure alt-text or properly tagged headings for navigation. Because there is no API or standalone application for the Adobe accessibility checker, it can only be accessed through the user interface of a licensed version of Adobe Acrobat Pro. We develop an AppleScript program that enables us to automatically process papers through the Adobe checker. Our program requires a dedicated computer running MacOS and a licensed version of Adobe Acrobat Pro. It takes 10 seconds on average to download and process each PDF, which enables us to scale up our analysis to tens of thousands of papers. Accessibility reports from the checker are saved in HTML format for subsequent analysis.

Each report contains a total of 32 accessibility criteria, marked as ``Passed,'' ``Failed,'' or ``Needs manual check.''\footnote{Please see \href{https://helpx.adobe.com/acrobat/using/create-verify-pdf-accessibility.html}{https://helpx.adobe.com/acrobat/using/create-verify-pdf-accessibility.html} for a description of the accessibility report.}
Following \citet{Lazar2017MakingTF}, we analyze the following five criteria\footnote{For papers containing no tables and/or no figures, the Adobe checker can still return both pass or fail for the Table header and Alt-text criteria respectively. When objects in the PDF are \textit{not} tagged, the checker will fail these criteria even when the paper has no tables and/or no figures. When objects in the PDF \textit{are} tagged and the PDF is accessible, the checker will pass these criteria even when the paper has no tables or no figures.}:

\begin{itemize}
    \item Alt-text: Figures have alternate text.
    \item Table headers: Tables have headers.
    \item Tagged PDF: The document is tagged to specify the correct reading order.
    \item Default language: The document has a specified reading language.
    \item Tab order: The document is tagged with correct reading order, used for navigation with the \texttt{tab} key.
\end{itemize}

\noindent 
% We provide the full dataset with all 32 criteria at \githublink. 
For our analysis, we also report \textit{Total Compliance}, which refers to the sum number of accessibility criteria met (e.g. if a paper has met 3 out of the 5 criteria we specify, then Total Compliance is 3). In some cases, we report the \textit{Normalized Total Compliance}, which is computed as the Total Compliance divided by 5, and can be interpreted as the proportion of the 5 criteria which are satisfied. We also report \textit{\xcompliance{5}}, a binary value of whether a paper has met all 5 criteria we specify (1 if all 5 criteria are met, 0 if any are not met), and the rate of \xcompliance{5} for papers in our dataset.

In addition to running the accessibility checker, we also extract metadata for each PDF, focusing on metadata related to the PDF creation process. PDF metadata are generated by the software used to create each file, and we analyze the associations between different PDF creation software and the accessibility of the resulting PDF document. Our hypothesis is that some classes of software (such as Microsoft Word) produce more accessible PDFs.

\subsection{Accuracy of our automated accessibility checker}
\label{sec:sos_chi}

\begin{table}[t!]
\begin{tabular}{lccc}
    \toprule
    \textbf{Criterion} & \textbf{CHI 2010\citep{Lazar2017MakingTF}} & \textbf{Ours-CHI 2010} & \textbf{Ours-All (\numpdfs)} \\ 
    \midrule
    Alt-text & 3.6\% & 4.0\% & 7.5\%  \\
    Table headers & 0.7\% & 1.0\% & 13.3\% \\
    Tagged PDF & 6.3\% & 7.4\% & 13.4\% \\
    Default language & 2.3\% & 3.0\% & 17.2\% \\
    Tab order & 0.3\% & 1.0\% & 9.3\% \\
    \midrule
    \xcompliance{5} & - & - & 2.4\% \\
    \bottomrule
\end{tabular}
\caption{We reproduce the analysis conducted by \citet{Lazar2017MakingTF} on PDFs of papers published in CHI, showing the percentage of papers that satisfy each of the five accessibility criteria. We find similar compliance rates, indicating that our automated accessibility checker pipeline is comparable to previous analysis methods. We also show the percentage of papers in our full dataset of \numpdfs PDFs that satisfy each criterion, along with the percent that satisfy \xcompliance{5}.
}
\label{tab:chi-results}
% \Description{
% Criterion; CHI 2010 [23]; Ours-CHI 2010; Ours-All (11,397)
% Alt-text; 3.6%; 4.0%; 7.5%
% Table headers; 0.7%; 1.0%; 13.3%
% Tagged PDF; 6.3%; 7.4%; 13.4%
% Default language; 2.3%; 3.0%; 17.2%
% Tab order; 0.3%; 1.0%; 9.3%
% Adobe-5 Compliance; -; -; 2.4
% }
\end{table}

Previous work employed different versions of the Adobe Accessibility Checker to generate paper accessibility reports. To confirm the accuracy of our checker, as well as the automated script we create to perform the analysis, we run our checker on CHI 2010 papers to reproduce the results of \citet{Lazar2017MakingTF}. We identify CHI papers using DOIs reported by the ACM, and resolve these to PDFs in the Semantic Scholar corpus \citep{Ammar2018ConstructionOT}. We identify \numchi CHI papers in the corpus, and generate accessibility reports for these using our automated checker.

Our results shows similar rates of compliance compared to what was measured by \citet{Lazar2017MakingTF} (see Table~\ref{tab:chi-results} for results). This indicates that our automated accessibility checker produces comparable results to previous studies.

\subsection{Proportion of papers with accessible PDFs}
\label{sec:sos_fos}

\begin{figure}[tb!]
  \centering
    \includegraphics[width=0.55\linewidth]{figures/total_compliance_all.png}
  \caption{The distribution of numbers of PDFs in our dataset that meet our defined accessibility compliance criteria. A large majority (8519) of PDFs in our sample meet 0 out of 5 accessibility criteria. Of those meeting 1 criterion (Total Compliance = 1), the most commonly met criterion is Default Language (793 of 1010, 78.5\%). Of those meeting 4 criteria (Total Compliance = 4), the most common missing criterion is Alt-text (396 of 494, 80.2\%).
  } 
  \label{fig:fos-total-compliance}
  \Description{A histogram showing the distribution of total compliance score for our dataset. The majority of PDFs (8519 of 11397) in our sample meet 0 compliance criteria. Small numbers of PDFs meet some criteria, with lower numbers meeting more criteria.}
\end{figure}

\begin{figure}[t!]
  \centering
    \includegraphics[width=0.9\linewidth]{figures/complete_compliance_by_fos.png}
  \caption{Percent of papers per field of study that meet all 5 accessibility criteria defined in \xcompliance{5}. Philosophy, Art, and Psychology have the highest rates of \xcompliance{5} satisfaction while Biology, Mathematics, and Geology have the lowest rates. 
  None of the fields had more than $6.5\%$ of PDFs satisfying \xcompliance{5}. 
  }
  \label{fig:fos-complete-compliance}
  \Description{A bar plot showing the proportion of PDFs in each field of study that satisfy Adobe-5 Compliance (meets all five accessibility criteria we define). Compliance percentage ranges from 6.3\% at the high end to 0.2\% at the low end. At the high end are fields such as philosophy, art, business, and psychology. At the low end are fields like biology, mathematics, and geology.}
\end{figure}

Around 1.6\% of PDFs we attempted to process failed in the Adobe checker (i.e., we could not generate an accessibility report). The accessibility checker most commonly fails because the PDF file is password protected, or the PDF file is corrupt. In both of these cases, the PDF is inaccessible to the user. We exclude these PDFs from subsequent analysis.

Accessibility compliance over all papers is low. Table~\ref{tab:chi-results} shows the percent of papers meeting each of the five criteria, as well as the Adobe-5 Compliance rate associated with this sample of papers. Figure~\ref{fig:fos-total-compliance} shows that the vast majority of papers do not meet any of the five accessibility criteria (8519 papers, 74.7\% do not meet any criteria) and very few (275 papers, 2.4\%) meet all five. Of those PDFs meeting 1 criterion, the most commonly met criterion is Default Language (793 of 1010, 78.5\%). Of those PDFs meeting 4 criteria, the most common \textit{missing} criterion is Alt-text (396 of 494, 80.2\%). In fact, only 854 PDFs (7.5\%) in the whole dataset have alt-text for figures. This is intuitive as Alt-text is the only criterion that \textit{always} requires author input to achieve, while the other four criteria can be derived from the document or automatically inferred, depending on the software used to generate the PDF.
    
As shown in Figure~\ref{fig:fos-complete-compliance}, all fields have an \xcompliance{5} of less than 7\%. The fields with the highest rates of compliance are Philosophy (6.3\%), Art (6.2\%), Business (5.7\%), Psychology (5.7\%), and History (5.3\%) while the fields with the lowest rates of compliance are Geology (0.2\%), Mathematics (0.3\%), and Biology (0.6\%). Fields associated with higher compliance tend to be closer to the humanities, and those with lower levels of compliance tend to be science and engineering fields. The prevalence of different document editing and typesetting software by field of study may explain some of these differences, and we explore these associations in Section~\ref{sec:sos_pdf_headers}.

\subsection{Trends in paper accessibility over time}

\begin{figure}[t!]
  \centering
    \includegraphics[width=0.6\linewidth]{figures/compliance_over_time.png}
  \caption{Accessibility compliance over time (2010-2019). The rate of \xcompliance{5} has remained relatively stable over the last decade, at around 2--3\%. Compliance along several criteria have improved over time, though the largest improvements have been in Default Language, the simplistic criteria to meet. Modest improvements are seen for Table headers, Tagged PDFs, and Tab order. The presence of alt-text has remained stable and lower, around 5--10\%. 
  }
  \label{fig:fos-over-time}
  \Description{A line plot shows changes in compliance rates over time. Adobe-5 Compliance has stayed consistently around 0.02-0.03 since 2010. The proportion of PDFs satisfying the Default language criteria has increased the most over time, from 0.10 in 2010 to 0.27 in 2019. Tagged PDF, Tab order, and Table headers also show improvements. The proportion of PDFs with alt-text has remained fairly consistent over time, between 0.05 and 0.1.}
\end{figure}

We show changes in compliance for all fields of study over time in Figure~\ref{fig:fos-over-time}. With the exception of Default Language, all accessibility criteria demonstrate slowly increasing or stable compliance rates over the past decade, with increases seen in Tagged PDFs and Tab order over time. Default language compliance is increasing most rapidly, from around 10\% compliance in 2010 to more than 25\% in 2019. This may be due to changes in PDF generation defaults in various typesetting software. Though this improvement is good, Default Language is the easiest of the five criteria to bring into compliance, and arguably the least valuable in terms of improving the accessible reading experience. The criterion with the lowest rate of compliance is Alt-text, which has remained stable between 5--10\% and has been lower in recent years. Since Alt-text is the only criterion of the five which always necessitates author intervention, we believe this is a sign that authors have not become more attuned to accessibility needs, and that at least some of the improvements we see over time can be attributed to typesetting software or publisher-level changes. 


\begin{table}[t!]
\begin{tabular}{ll}
    \toprule
        \textbf{Typesetting Software} & \textbf{Count (\%)} \\ 
    \midrule
        Adobe InDesign       & 1591 (14.0\%) \\
        LaTeX                & 1431 (12.6\%) \\
        Arbortext APP        & 1374 (12.1\%) \\
        Microsoft Word       & 1318 (11.6\%) \\
        Printer              & 1021 (9.0\%) \\
    \midrule
        Other                & 4662 (40.9\%) \\
    \bottomrule
\end{tabular}
\caption{Count of papers per Typesetting Software. ``Other'' includes PDFs created with an additional 24 unique software programs, each with counts of less than 350, as well as those created with an unknown typesetting software.}
\label{tab:dist-of-headers}
% \Description{
% Typesetting Software; Count (%)
% Adobe InDesign; 1591 (14.0%)
% LaTeX; 1431 (12.6%)
% Arbortext APP; 1374 (12.1%)
% Microsoft Word; 1318 (11.6%)
% Printer; 1021 (9.0%)
% Other; 4662 (40.9%)
% }
\end{table}

\subsection{Association between typesetting software and paper accessibility}
\label{sec:sos_pdf_headers}

Typesetting software is extracted from PDF metadata and manually canonicalized. We extract values for three metadata fields: \texttt{xmp:CreatorTool}, \texttt{pdf:docinfo:creator\_tool}, and \texttt{producer}. All unique PDF creation tools associated with more than 20 PDFs in our dataset are reviewed and mapped to a canonical typesetting software. For example, the values (\texttt{latex}, \texttt{pdftex}, \texttt{tex live}, \texttt{tex}, \texttt{vtex pdf}, \texttt{xetex}) are mapped to the LaTeX cluster, while the values (\texttt{microsoft}, \texttt{for word}, \texttt{word}) and other variants are mapped to the Microsoft Word cluster. We realize that not all Microsoft Word versions, LaTeX distributions, or other versions of typesetting software within a cluster are equal, but this normalization allows us to generalize over these software clusters. For analysis, we compare the five most commonly observed typesetting software clusters in our dataset, grouping all others into a cluster called \texttt{Other}.

\begin{figure}[t!]
  \centering
    \includegraphics[width=0.5\linewidth]{figures/total_compliance_by_typesetting_software_categories.png}
  \caption{Histograms showing the distribution of Total Compliance scores for each of the top 5 typesetting software, ordered by decreasing mean Total Compliance. Microsoft Word stands out as producing PDFs with significantly higher Total Compliance than other typesetting software. Three of the top five PDF typesetting software clusters, Arbortext APP, Printer, and LaTeX, produce PDFs with low Total Compliance, with the majority of PDFs at 0 compliance. 
  }
  \Description{Five histograms show the distribution of Total Compliance scores for the five most common typesetting software clusters. These are sorted from most compliant to least compliant, in order: Microsoft Word, Adobe InDesign, Arbortext APP, Printer, and LaTeX. Microsoft Word produces many PDFs that satisfy 2 or more criteria, with a peak at Total Compliance = 4. Most PDFs produced by Adobe InDesign satisfy no accessibility criteria, but many satisfy 1 or 2. Arbortext APP, Printer, and LaTeX all produce inaccessible PDFs, with the vast majority of PDFs produced by these software satisfying no accessibility criteria.}
  \label{fig:fos-total-compliance-headers}
\end{figure}

We report the distribution of typesetting software in Table~\ref{tab:dist-of-headers}. The most popular PDF creators are Adobe InDesign, LaTeX, Arbortext APP, Microsoft Word, and Printer. ``Printer'' refers to PDFs generated by a printer driver (by selecting ``Print'' $\rightarrow$ ``Save as PDF'' in most operating systems); unfortunately, creating a PDF through printing provides no indicator of what software was used to typeset the document, and is generally associated with very low accessibility compliance. The ``Other'' category aggregates papers created by all other clusters of typesetting software; each of these clusters is associated with less than 350 PDFs, i.e., the falloff is steep after the Printer cluster. For the following analysis, we present a comparison between the five most common PDF creator clusters.

Figure~\ref{fig:fos-total-compliance-headers} shows histograms of the Total Compliance score for PDFs in the five most common typesetting software clusters. While the vast majority of papers do not meet any accessibility criteria, it is clear that Microsoft Word produces the most accessible PDFs, followed by Adobe InDesign. 
To determine the significance of this difference, we compute the ANOVA and Kruskal-Wallace \citep{Kruskal1952UseOR} statistics with the PDF typesetting software clusters as the sample groups and the Total Compliance as the measurements for the groups. We compute an ANOVA statistic of 2587.1 ($p$ < 0.001) and a Kruskal-Wallace $H$ statistic of 4422.0 ($p$ < 0.001). This indicates a significant difference in the distribution of Total Compliance scores between the five most common PDF typesetting software.

\begin{figure}[t!]
  \centering
    \includegraphics[width=0.64\linewidth]{figures/prop_word_vs_compliance_by_fos.png}
  \caption{There is a strong correlation ($r = 0.89$, $p < 0.001$, 95\% CI shown) between the proportion of PDFs typeset using Microsoft Word and the mean normalized Total Compliance of papers by field of study. Fields such as Business, Philosophy, Sociology, Materials science, and Psychology use Microsoft Word around or over 20\% of the time, and have correspondingly higher mean accessibility compliance. On the other end of the spectrum are fields like Mathematics, Physics, and Medicine, where Microsoft Word is rarely used, and which have very low levels of mean compliance.}
  \label{fig:prop_word_by_fos}
  \Description{A scatter plot shows a positive correlation between the proportion of PDFs typeset using Microsoft Word and the mean normalized total compliance score by field of study. Fields that typeset more using Word have higher Total Compliance scores. The correlation coefficient r is 0.89, and p is less than 0.001. Fields that use Word more and have higher compliance rates include Business, Materials science, Geography, Philosophy, and Sociology. Fields that use Word very little and have low compliance rates include Mathematics, Physics, and Medicine.}
\end{figure}

In Figure~\ref{fig:prop_word_by_fos}, we observe again that usage of Microsoft Word is highly correlated with accessibility compliance. Here, we plot the proportion of Microsoft Word usage per field of study and the corresponding mean normalized Total Compliance rates for those fields. Higher rates of Microsoft Word usage are statistically correlated with higher mean normalized Total Compliance ($r = 0.89$, $p < 0.001$). 

\begin{figure}[t!]
  \centering
    \includegraphics[width=0.6\linewidth]{figures/typesetting_software_over_time.png}
  \caption{The proportion of PDFs typeset by the five most common typesetting software over time. Software such as Adobe InDesign, LaTeX, and Microsoft Word are increasing in popularity over time.}
  \label{fig:software_over_time}
  \Description{A line plot shows the proportion of different typesetting software in our sample between 2010-2019. Microsoft Word, Adobe InDesign, and LaTeX have all increased in proportional usage (all starting at a proportion of 0.07-0.08 in 2010 to 0.15 or above in 2019. The usage of printer drivers to create PDFs has declined from a proportion of 0.12 in 2010 to around 0.05 in 2019. Arbortext APP also shows a modest decline in recent years to below a proportion 0.10.}
\end{figure}

In Figure~\ref{fig:software_over_time}, we show the proportion of usage of each of the five typesetting software over time. In recent years, Adobe InDesign, LaTeX, and Microsoft Word usage are proportionally increasing, while the proportion of Printer-created PDFs is declining. The increase in Adobe InDesign and Microsoft Word have likely driven the increase in rates of Total Compliance over time, since these typesetting software are the most associated with higher accessibility compliance. 


\subsection{Summary of analyses}
\label{sec:sos_summary}

Overall, accessibility compliance over the past decade and across all fields of study have slowly improved. Full compliance based on \xcompliance{5}, however, has remained around 2.4\% on average and does not show trends towards improving. Improvements in several compliance criteria are observed, with Default Language being the most improved, nearing 30\% coverage in 2019. However, Default Language is the easiest criteria to meet, and arguably produces the least amount of accessibility improvement in user experience. Criteria such as Tagged PDFs, Tab order, and Headers show modest improvements over time, though only between 10--15\% of papers in our sample meet any one of these individual criteria. Alt-text compliance is the lowest of our measured criteria, and as the only criterion of the five requiring author intervention in all cases, the lack of alt-text may be indicative of the general lack of author awareness and contribution to accessibility efforts for scientific papers. 

Based on our analysis, typesetting software plays a large role in document accessibility. Of the most common PDF creator software, Microsoft Word appears to produce the most accessibility-compliant PDFs, while LaTeX produces PDFs with the lowest compliance. Microsoft has recently made investments in the accessibility of their Office 365 Suite.\footnote{\href{https://www.microsoft.com/en-us/accessibility/microsoft-365}{https://www.microsoft.com/en-us/accessibility/microsoft-365}} It is clear that software can help increase accessibility compliance by prioritizing accessibility concerns during document creation, and we encourage other developers of typesetting and publishing software to priotize accessibility concerns in their development process. 

Improvements in accessibility compliance have stalled over the past decade, likely because accessibility concerns are considered marginal, and are outside of the awareness of most publishing authors and researchers. Significant changes in the authorial and publication processes are needed to change this status quo, and to increase the accessibility of scientific papers for BLV users going forward. Though we believe and encourage change in the academic paper authorial and publication process in relation to accessibility, the likelihood of rapid improvement is low and these changes will not impact the many millions of academic PDFs that have already been published. Therefore, we introduce a technological solution that may mitigate some of the accessibility challenges of existing paper PDFs, and aim to understand how this solution and others like it could serve the immediate needs of the BLV research community.


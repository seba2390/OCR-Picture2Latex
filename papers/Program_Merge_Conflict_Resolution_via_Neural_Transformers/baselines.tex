\section{Baseline Models}
\label{sec:baselines}

\subsection{Language Model Baseline}

Neural language models (LMs) have shown great performance in natural language generation~\citep{gpt2, sellam-etal-2020-bleurt}, and have been successfully applied to the domain of source code~\citep{10.5555/2337223.2337322, gptc, feng-etal-2020-codebert}. We consider the generative pretrained transformer language model for code (GPT-C) and appeal to the naturalness of software~\citep{naturalness} to construct our baseline approach for the merge resolution synthesis task. We establish the following baseline:
given an unstructured line-level conflict produced by \texttt{diff3}, we take the common source code prefix acting as user intent for program merge. We attempt to generate an entire resolution region token-by-token using beam search. As an ablation experiment, we repeat this for the conflicts produced with the token-level differencing algorithm (Fig.~\ref{fig:word1} shows details about prefix and conflicting regions).



\subsection{DeepMerge: Neural Model for Interleavings}

Next, we consider \textsc{DeepMerge}~\citep{Dinella2021}: a sequence-to-sequence model based on the bidirectional GRU summarized in section~\ref{sec:background}. It learns to generate a resolution region by choosing from line segments present in the input (line interleavings) with a pointer mechanism. We retrain the \textsc{DeepMerge} model on our TypeScript dataset.


\subsection{JDIME}
Looking for a stronger baseline, we consider \textsc{JDime}, a Java-specific merge tool that automatically tunes the merging process by switching between structured and unstructured merge algorithms \citep{apel2012structured}. Structured merge is abstract syntax tree (AST) aware and leverages syntactic information to improve matching precision of conflicting nodes. 
To compare the accuracy of \textsc{JDime} to that of \thistool{}, we use the Java test and complete the following evaluation steps: first, we identify the set of merge conflict scenarios where \textsc{JDime} did not report a merge conflict, and the standard \texttt{diff3} algorithm did. Second, we compare the \textsc{JDime} output to the version of the code where the merge conflict is resolved. Third, we calculate\textsc{JDime} accuracy by identifying the number of merges where \textsc{JDime} output file correctly matches the resolved conflict file.

As a result of its AST matching approach, code generated by \jdime{} is reformatted, and the original order of statements is not always preserved. In addition, source code comments that are part of conflicting code chunks are not merged. 

A simple syntactic comparison is too restrictive, and \jdime{} merge output can still be semantically correct. To accurately identify semantically equivalent merges, we use GumTree \cite{FalleriMBMM14}, an AST differencing tool, to compute fine grained edit scripts between the two merge files. By ignoring semantically equivalent differences computed by GumTree (such as moved method declarations) we have a more accurate baseline comparison between the number of semantically equivalent merges generated by \jdime{} and \thistool{}.

\subsection{jsFSTMerge}
\citet{apel2012fstmerge} introduced \fstmerge{}, a semi-structured merge engine using an approach similar to \textsc{JDime}, but that that allows a user to provide an annotated language grammar specification for any language. 
\citet{tavares2019javascript} implemented \jsfstmerge{} by adapting an off-the-shelf grammar for JavaScript to address shortcomings of \fstmerge{} and also modifying the \fstmerge{} algorithm itself.  
For example, statements can be intermingled with function declarations at the same syntactic level, and statement order must be preserved while function order does not.  
\jsfstmerge{} allows for certain types of nodes to maintain their relative order (\emph{e.g.}, statements) while others may be order independent (\emph{e.g.}, function declarations) even if they share the same parent node.

For cases where \jsfstmerge{} produces a resolution that does not match the user resolution, we manually inspect the output for semantic equivalence (e.g., reordered import statements).


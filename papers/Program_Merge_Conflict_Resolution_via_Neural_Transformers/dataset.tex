\section{Dataset}
\label{sec:dataset}
%\sarah{add statistics about distribution of merge patterns}
%\alexey{I added some numbers in the section 4 (around line 270). Detailed numbers are in Appendix. We can move it up here if needed...}
%To create a dataset for self-supervised pretraining, we clone all non-fork repositories with more than 20 stars in GitHub that have C, C++, C\#, Python, Java, JavaScript, TypeScript, PHP, Go, and Ruby as their top language. The resulting dataset comprises over 64 million source code files. 
%\chris{why do we list languages here that we don't ever evaluate on?  A reviewer will find this confusing and ask about it.  We found that language specific models work better than multi-lingual models, right?}

The finetuning dataset is mined from over 100,000 open source software repositories in multiple programming languages with merge conflicts. It contains commits from git histories with exactly two parents, which resulted in a merge conflict.  We replay \texttt{git merge} on the two parents to see if it generates any conflicts. Otherwise, we ignore the merge from our dataset. We use the approach introduced by~\citet{Dinella2021} to extract resolution regions---however, we do not restrict ourselves to conflicts with less than 30 lines only.  Lastly, we extract token-level conflicts and conflict resolution classification labels (introduced in Section \ref{formulation}) from line-level conflicts and resolutions. Tab.~\ref{tab:fintuning_dataset} provides a summary of the finetuning dataset.

\begin{table}[htb]
\centering
\caption{Number of merge conflicts in the dataset.}
\begin{tabular}{llllllllllll} \toprule
\textbf{Programming language} & \textbf{Development set}  & \textbf{Test set} \\ \midrule
C\# & 27874 & 6969 \\ 
JavaScript & 66573 & 16644\\ 
TypeScript & 22422 & 5606\\ 
Java & 103065 & 25767 \\ 
\bottomrule
\end{tabular}
\label{tab:fintuning_dataset}
\end{table}
The finetuning dataset is split into development and test sets in the proportion 80/20 at random at the file-level. The development set is further split into training and validation sets in 80/20 proportion at the merge conflict level.    

\section{User Evaluation}
\begin{figure}[h] %!th
   \includegraphics[width=0.46\textwidth, angle=0]{images/method.png}
  \caption{Methodology to identify candidate conflicts for the user study.}
  \label{fig:methodology}
  \vspace{-12pt}
\end{figure}

\begin{table}[t!]
\small
\centering
\caption{Summary of projects in user study, total number of conflicts per project, number of conflicts evaluated in the study, and the survey participants.}
\label{tab:projects}
\begin{tabular}{llcccl} \toprule
Language & Project & Conflicts & Survey & Participants \\
 &  &  &  Conflicts &  \\\midrule
\multirow{3}{*}{Java} & Azure-Cosmosdb  & 341 & 6 & P1 \\
 & Azure-SDK  & 997 & 14 & P2-4 \\
 & ApplicationInsights&  313 & 10 & P5-6 \\ \midrule
\multirow{2}{*}{TS} & MakeCode & 106 & 12 & P7-8 \\
 & VSCode  & 2256 & 48 & \begin{tabular}[c]{@{}l@{}}P9-17\end{tabular} \\ \midrule
\multirow{3}{*}{C\#} & AspNetCore  & 567 & 11 & P18-19 \\
 & EFCore  & 397 & 7 & P20-21 \\
 & Roslyn  & 1894 & 14 & P22-25 \\ \midrule
 Total & 8 projects  & 6871 & 122 & 25 \\ \bottomrule
\end{tabular}
\end{table} 

\subsection{User Study Design}

To better understand how \thistool{} performs in practice, we ask developers about conflicts that \thistool{} is unable to correctly resolve. Since \thistool{}'s resolution suggestions are evaluated against user resolutions using a verbatim string match (modulo whitespace), asking study participants to confirm identical resolutions predicted by \thistool{} is not informative. Therefore, we extract conflicts where \thistool{} suggestions are not a direct match to the user resolution to determine what the limitations of the suggestions are, and how they might be perceived in practice.

To build an oracle of merge conflicts and resolutions we identify 8 open source projects hosted on GitHub. The selected projects are active, with multiple contributors, and contain a large number of conflict scenarios in one of the languages supported by \thistool{}.
Tab.~\ref{tab:projects} contains a list of projects chosen.
% EFCore\footnote{https://github.com/dotnet/efcore}
% Roslyn\footnote{https://github.com/dotnet/roslyn}
% AspNetCore\footnote{https://github.com/dotnet/aspnetcore}  
% VSCode\footnote{https://github.com/microsoft/vscode}
% MakeCode\footnote{https://github.com/microsoft/pxt} 
% Azure-SDK-Java\footnote{https://github.com/Azure/azure-sdk-for-java} 
% Azure-Cosmosdb-Java\footnote{https://github.com/Azure/azure-cosmosdb-java}
For each project, we follow the same steps outlined in Section~\ref{sec:dataset} to extract candidate conflicts and user resolutions to use in the survey.



Fig.~\ref{fig:methodology} explains the methodology used to identify candidate merge conflicts. We identify the set of conflicts \thistool{} is unable to correctly merge (within the top-3 suggestions). From this set of conflicts, we identify candidate conflicts to use as part of the user study. We filter candidate files with the following criteria:
\begin{enumerate}
  \item Conflicts should have been recently resolved i.e., at most within the past 12 months. Participants may not retain the context needed to evaluate suggestions for older conflicts. 
    \item Files must have at most 4 conflicts. Participants evaluate up to 3 suggestions per conflict. More conflicts may be too complex to evaluate within the interview time slot. 
    \item Conflicts should be non-trivial.  Trivial conflicts, such as those that only involve formatting changes or renames, are manually excluded. The determination of if a conflict was non-trivial was manual and subjective, informed by our belief that more substantive conflicts would lead to more insights in the user study.
\end{enumerate}

%\sarah{this might be the place to add discussion of subsumptive merge conflicts?}
For each candidate conflict identified, we use the GitHub API to identify authors for each of the conflicting branches and the resolved file. Authors with at least 3 candidate merge conflicts are identified as potential survey participants. Our final pool of candidate participants consists of 52 unique authors. We recruit participants via email, using contact information on GitHub. Out of the 52 contacted developers, 25 agreed to participate in the study. All participants were professional software developers with at least 2-8 years of experience working at large technology companies. We asked participants to evaluate \thistool{} resolution suggestions for their own merge conflicts.  Tab.~\ref{tab:projects} contains the final number of participants and conflicts evaluated in our study. 122 conflicts were evaluated: 32 C\# conflicts, 30 Java, and 60 Typescript. 

\subsubsection{\thistool{} Interface}
We designed an online interface where participants can view their own conflicts and explore \thistool{}'s resolution suggestions. Participants are asked to evaluate their own recently resolved merge conflicts, and the corresponding generated resolution suggestions by \thistool{}. The interface is customized based on the signed-in participant and displays a list of their recently encountered merge conflicts. Participants can click through different resolution suggestions to evaluate if they are acceptable ways to resolve the merge conflict. They can view their original resolution on the same page, and if needed, participants can navigate to the conflicting commit on GitHub using a link if they need additional context. They can also view a diff between the conflict file and any of the selected options (resolution suggestion or user resolution). Participants use this interface to select one or more of the suggested resolutions, indicate if the suggested resolution is acceptable, and explain the reasons why or why not.  Our online data package~\cite{ICSE22Replication} and appendix~\cite{FSE22Appendix} contain the questions, images of the interface, and participant responses.  

% \begin{figure}[h!] %!th
%  \includegraphics[width=0.5\textwidth, angle=0]{images/survey.png}
%  \caption{Interface used by participants to interact with \thistool{} resolution suggestions and answer survey questions.}
%  \label{fig:survey}
% \end{figure}


\subsubsection{Protocol}
The user study was conducted as 30 minute interviews remotely over Microsoft Teams using the interface we built. First, participants watched a video explaining \thistool{} and how to navigate conflicts and evaluate resolution suggestions using the interface. Then, the participants evaluated a set of conflicts and submitted their responses. One of the authors was on the teams call to help participants navigate the interface and ask any clarifying questions based on their evaluation of the \thistool{} resolution suggestions.
% Then participants were asked a list of questions on the following topics: (i) Their existing process to resolve merge conflicts, and obstacles faced, (ii) trust of existing merging algorithms and proposed approaches, and (iii) utility of suggestion-based merge conflict resolution tools.
Questions were iteratively developed based on two pilot interviews. Each interview was recorded for transcription and analysis. 
%Direct quotes used in the results were manually validated by the authors.

% \subsubsection{Analysis}
% \sarah{update to only describe survey result analysis}
% We analyzed the submitted survey responses, video recordings and generated transcripts of the semi-structured interviews. We divided the transcripts into different sections reflecting the semi-structured interview questions and then used open coding for each topic, looking for similarities and differences between the intervieweesâ€™ responses. 




\subsection{User Study Results}


\noindent \textbf{RQ\scriptsize{4}: }\textbf{\rqFour}


Using the interface participants evaluate the conflict resolution suggestions generated by \thistool{} and indicate if any of the suggestions were acceptable, and explain why or why not. There were no noticeable differences in the participants' responses across different languages or projects so we do not break down our results by those dimensions.
Participant's evaluations of the merge suggestions generally fall into three categories: 1) the merge suggestion is correct and would be used to resolve the conflict 2) the merge is incorrect but the correct resolution would require an understanding of external context and 3) the merge is incorrect and no external context is needed.  

\subsubsection{Acceptable Merge Suggestions}

Surprisingly, of the 122 conflicts included in the study, participants indicated that at least one of the 3 suggestions generated by \thistool{} was correct for 54\% (66/122) of the examples. By design, the suggestions presented in the study are not syntactically equivalent to the participant's original resolution, however, they still indicated that the suggestion was a correct merge. Using participant responses, we identify a few reasons why merge suggestions may be acceptable to a developer, even if it is not syntactically equivalent to their original resolution:

\vspace{6pt}
\noindent{}\textbf{Semantically Equivalent Resolution} (54 of 122 conflicts) \\
    Semantically equivalent resolutions include scenarios where the statements are re-ordered, equivalent changes made to naming or documentation, and unneeded import statements or commented out code is  preserved or removed. 
   
      One example in the study of conflicting changes that are both equally acceptable, and one is arbitrarily accepted by the resolving author is when authors of conflicting branches renamed the same variable with a slight variation:\\ \ic{SPAN\_TARGET\_ATTRIBUTE\_NAME} and \\ \ic{SPAN\_TARGET\_APP\_ID\_ATTRIBUTE\_NAME}. In these cases, either version selected by the merging algorithm might still be acceptable to the developer. \textsc{MergeBert} generated a suggestion to keep the variable name \ic{SPAN\_TARGET\_ATTRIBUTE\_NAME} whereas the user resolution originally kept the other. Participant P5 marked this resolution as acceptable and semantically equivalent, explaining that in this scenario they had `no preference as to which one is better'.
%\sarah{add more examples if we have room}      

\mybox{Takeaway 1}{grey!20}{grey!7}{Evaluating the performance of \thistool{} using strict syntactic approaches estimates a lower bound of performance. Survey results show  almost 45\% of \thistool{} suggestions are acceptable merges that are semantically equivalent to the participant's original resolution. \thistool{}'s performance could be improved by considering semantic information, for example, to identify how changes related to naming or documentation should be merged.}
\noindent{}\textbf{Tangled Code Changes in Oracle} (10/122) \\
Resolutions for 10 of the conflicts contained additional ``tangled'' changes~\cite{Herzig:msr13:ImpactOfTangledCodeChanges,Kirinuki:icpc14:TangledChanges} that were unrelated to the resolution. Examples include renaming a method and adding a variable in the conflict region that is then used later outside the conflict region.
In all 10 instances, \textsc{MergeBert} generates a suggestion that does not include the additional tangled code, but is acceptable to the participant as a resolution of the conflict. 
Participants indicated that if they had access to the \textsc{MergeBert} suggestions, they would select the correct resolution and then manually add the additional code. 

\mybox{Takeaway 2}{grey!20}{grey!7}{When committing merged code, developers may introduce changes unrelated to the conflict which are inadvertently included in conflict resolution oracles. These changes can negatively impact model performance estimated with automatic metrics.}




\subsubsection{Merge Requires External Context}
 \textsc{MergeBert} did not generate an acceptable suggestion for 46\% (56/122) of examples shown to survey participants. Participants were asked to indicate whether they resolved these examples using external context that cannot be inferred from the conflicting code regions and to explain what the external context was.  
Results indicate that 16\% (20/122) of conflicts in the survey sample require external information not found in either conflicting file, in order to be correctly resolved. 
One example of external context is knowledge of linter rules enabled at a project level. Projects often require linter checks before code can be committed to the repository, as a step towards improving the quality and maintainability of the source code. One example is a merge conflict from Roslyn where the correct resolution was to remove a null check from the code. Participant P23 explained the decision to remove the check: \emph{"The previousResults parameter is non-nullable because C\# nullability checking is now enabled at the project level. The null check is unnecessary"}. In this scenario, without specific knowledge of linter checks, an automatic approach is unable to predict an accurate merge. 
 
 Another example of external context is updates to languages rules that have cascading effects on existing code. Participant P22 from the Roslyn project explained one such conflict:  "Changes were due to updates in '\ic{using}' rules for the C\# language".  Language updates in C\# version 8.0 introduced an alternative syntax for the \ic{using} statement and P22's team had made to adopt this syntax.  P22 therefore updated this code (involved in the conflict) during the merge. Other examples of external context identified through the survey include: removal of global dependencies from non-conflicting files within a project, rolling back features that shouldn't be included in a release branch, and project-level decisions to remove \ic{'final'} modifiers for variables. 

\mybox{Takeaway 3}{grey!20}{grey!7}{The local view of a conflict is sufficient to merge a majority of conflicts. Around 16\% of the conflicts  require external information to correctly resolve. One direction to improve \thistool{} is to consider external context as an additional information source for resolving conflicts.}

\subsubsection{Unacceptable Merge Suggestions}
Survey results show that \textsc{MergeBert} suggestions were incorrect for 29\% (36/122) of the conflicts. Participants indicated that none of the 36 conflicts required external context to be resolved. We manually analyze the conflicts looking to identify patterns that may explain the incorrect merges, for example, affected language construct~\cite{pan2021ProgramSynthesis} and type of conflict~\cite{shen2021automatic}, but do not identify any consistent patterns. 
% \Shuvendu{Is this really true? Wasn't extraneous and subsumptive merges came here?} \sarah{subsumptive conflicts are filtered out before the survey since they have obvious resolutions. These unacceptable suggestions are for other conflicts where MergeBert is suggesting something that really didn't make sense.}
In summary, existing automatic evaluation strategies estimate a lower bound of approach performance: \thistool{} suggestions are correct for 54\% of conflicts included in our sample, despite not being syntactically equivalent to the user resolution.  Further, suggestions from \thistool{} helped two participants find bugs in their own recent merge conflict resolutions!  This is in addition to those resolutions where \thistool{} does provide an exact match.  This finding suggests that automatic evaluation techniques that rely on a strict syntactic comparison between the user resolution and merge suggestion might be estimating a much lower bound of performance. This highlights a discrepancy between how approaches are typically automatically evaluated, and how developers may evaluate an approach in practice.  Researchers should consider conducting user studies to more accurately evaluate approaches when feasible. 
 Tools like \thistool{} can reduce effort and bug proneness involved in manually merging conflicts. Future studies should investigate these potential benefits. 
%\chris{definitely include that we found bugs in two developer resolutions.  In addition, we should reiterate that the 54\% of correct merges resolutions is out of the percentage that \thistool{} didn't already match exactly correctly.  We don't want the reader to think that we learned that \thistool{} is correct only 54\% of the time.}
% \sarah{subsumptive conflicts are one way MergeBert can significantly improve. We need to find a place to introduce them, explain how they are filtered out of the survey questions, their proportion.}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
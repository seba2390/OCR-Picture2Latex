\begin{abstract}
The single-speaker singing voice synthesis (SVS) usually underperforms at pitch values that are out of the singer's vocal range or associated with limited training samples.
Based on our previous work, this work proposes a melody-unsupervised multi-speaker pre-training method conducted on a multi-singer dataset to enhance the vocal range of the single-speaker, while not degrading the timbre similarity.
This pre-training method can be deployed to a large-scale multi-singer dataset, which only contains audio-and-lyrics pairs without phonemic timing information and pitch annotation.
Specifically, in the pre-training step, we design a phoneme predictor to produce the frame-level phoneme probability vectors as the phonemic timing information and a speaker encoder to model the timbre variations of different singers, and directly estimate the frame-level f0 values from the audio to provide the pitch information. These pre-trained model parameters are delivered into the fine-tuning step as prior knowledge to enhance the single speaker's vocal range.
Moreover, this work also contributes to improving the sound quality and rhythm naturalness of the synthesized singing voices. It is the first to introduce a differentiable duration regulator to improve the rhythm naturalness of the synthesized voice, and a bi-directional flow model to improve the sound quality.
Experimental results verify that the proposed SVS system outperforms the baseline on both sound quality and naturalness.

% This paper presents an end-to-end high-quality singing voice synthesis (SVS) system that uses melody-unsupervision method pre-train on a large-scale multi-singer dataset to improve vocal range. Based on the main architecture of previous work, we put forward several specific designs for high-quality singing voice synthesis. First, aiming to improve the pitch robustness of SVS model, we propose a pre-training strategy that can be used for a large-scale multi-singer dataset containing only audio-and-lyrics pairs, without temporal alignment information. To model the different timbre information of the multi-singer dataset, we adopt one of the state-of-the-art speaker recognition models, i.e. ECAPA-TDNN, as the speaker encoder. Second, aims to alleviate the rhyme problems, we further introduce a differentiable upsampling layer in place of the simple copy operation used by length-regulator to extend phoneme-level features to frame-level features. Last but not the least, to attenuate the training-inference mismatch problem, the bi-directional flow model is proposed to improve the quality of synthesized singing voice. Both objective and subjective experimental results indicate that the proposed SVS system can produce singing voice with higher-quality outperforming baseline model\footnote{Samples:\href{https://thuhcsi.github.io/melody-unsupervised-pretraining-svs/}{https://thuhcsi.github.io/melody-unsupervised-pretraining-svs/}}.

\end{abstract}
%

\begin{keywords}
singing voice synthesis, vocal range, melody-unsupervision, differentiable up-sampling layer, bi-directional flow 
\end{keywords}
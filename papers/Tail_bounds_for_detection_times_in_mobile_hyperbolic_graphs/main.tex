\documentclass[12pt]{article}

\usepackage{fullpage}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{enumerate}
\usepackage{paralist}
\usepackage{xcolor}
\usepackage{changes}
\usepackage{authblk}
\usepackage{lineno}
\linenumbers

\usepackage{comment}
\usepackage{authblk}
\definechangesauthor[color=blue]{mk}
\definechangesauthor[color=red]{dm}
\definechangesauthor[color=magenta]{al}

\usepackage{biblatex} 
\addbibresource{References.bib}
\usepackage{hyperref}

\newcommand{\EE}{\mathbb{E}}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\Var}{\mathbb{V}}
\newcommand{\HH}{\mathbb{H}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\VV}{\mathbb{V}}
\newcommand{\ZZ}{\mathbb{Z}}
\renewcommand{\P}{\mathbb{P}}
\renewcommand{\ss}{\mathfrak{z}}
\newcommand{\dt}{\mathcal{D}^{(\ss)}}
\newcommand{\cdt}{(c\mathcal{D})^{(\ss)}}
\newcommand{\ndt}{\overline{\mathcal{D}}^{(\ss)}}
\newcommand{\cndt}{\overline{c\mathcal{D}}^{(\ss)}}
\newcommand{\mkomit}[1]{{\color{orange}#1}}
\newcommand{\mkor}[2]{#2}
\newcommand{\nnu}{n_{\mkomit{\nu}}}
\newcommand{\mint}[1]{I^r(s)}
\newcommand{\fr}{\mathfrak{r}}
\newcommand{\rabs}{\mathfrak{r}}
\newcommand{\auxuno}{c_{a1}}
\newcommand{\auxdos}{c_{a2}}
\newcommand{\auxy}{y}
\newcommand{\auxY}{Y}
\newcommand{\yabs}{{\bf y}}
\newcommand{\babs}{\mathfrak{b}}
\newcommand{\trad}{T^{rad}_0}
\newcommand{\tang}{T^{ang}_0}
\newcommand{\phis}{\phi^{(\ss)}}
\newcommand{\hatr}{\widehat{r}_0}
\newcommand{\hatt}{\widehat{\theta}_0}
\newcommand{\JJ}{J}
\newcommand{\II}[1]{I(#1)}
\newcommand{\tII}[1]{\widetilde{I}(#1)}
\newcommand{\tI}{\widetilde{I}}
\newcommand{\ed}{\stackrel{(d)}{=}}
\newcommand{\ld}{\stackrel{(d)}{\leq}}
\newcommand{\KA}{\kappa_A}
\newcommand{\KR}{\kappa_R}
\newcommand{\auxc}{\mathfrak{C}}
\newcommand{\auxl}{\mathfrak{L}}
\newcommand{\const}{\mathbf{C}}



\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{observation}[theorem]{Observation}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{remark}[theorem]{Remark}
\DeclareMathOperator{\sech}{sech}
\DeclareMathOperator{\cosech}{cosech}
\DeclareMathOperator{\cotanh}{coth}

%\newcommand{\cmk}[1]{{\color{blue}\textbf{*MK:} #1\textbf{*}}}
%\newcommand{\dmc}[1]{{\color{red}\textbf{*DM:} #1\textbf{*}}}
%\newcommand{\cml}[1]{{\color{magenta}\textbf{*AL:} #1\textbf{*}}}
%\newcommand{\AL}[1]{\textcolor{magenta}{#1}}
%\newcommand{\dm}[1]{{\color{red} #1}}
%\newcommand{\mk}[1]{{\color{blue} #1}}

% Tikz stuff
\usepackage{tikz}
  \usetikzlibrary{calc}
  \usetikzlibrary{patterns}
  \usetikzlibrary{arrows,decorations.markings}
\usepackage{pgfplots}
  \pgfplotsset{compat=1.9}
  \usepgfplotslibrary{polar}

% Custom labeling command
\makeatletter
\usepackage{hyperref}
\newcommand{\mycom}[2]{\hypertarget{#1}{#2}\global\@namedef{mycom@#1}{#2}}
\newcommand{\linktomycom}[1]{%
\@ifundefined{mycom@#1}{\textbf{??}\@latex@warning{Reference `#1' on page \thepage \space undefined}}%
{\hyperlink{#1}{\@nameuse{mycom@#1}}}%
}
\makeatother


\begin{document}
\nolinenumbers
\title{Tail bounds for detection times in mobile hyperbolic graphs}

\author[1]{Marcos Kiwi\thanks{Depto.~de Ingenier\'ia Matem\'atica and Centro de Modelamiento Matem\'atico (CNRS IRL2807), Univ.~Chile, (\texttt{mkiwi@dim.uchile.cl}). Gratefully acknowledges support by ACE210010 and FB210005, BASAL funds for centers of excellence from ANID-Chile, and by GrHyDy ANR-20-CE40-0002.}}
\author[2]{Amitai Linker\thanks{Depto.~de Matem\'aticas, Facultad de Ciencias Exactas, Univ.\ Andr\'es Bello, (\texttt{amitai.linker@unab.cl}). Gratefully acknowledges support by IDEXLYON of Univ.\ de Lyon (Programme Investissements d'Avenir ANR16-IDEX-0005), and by DFG project number 425842117.}} 
\author[3]{Dieter Mitsche\thanks{Institut Camille Jordan, Univ.\ Jean Monnet, Univ.\ de Lyon and IMC, Pontif\'{i}cia Univ.\ Cat\'{o}lica de Chile, (\texttt{dmitsche@gmail.com}). Gratefully acknowledges support by grant GrHyDy ANR-20-CE40-0002 and by IDEXLYON of Univ.\} de Lyon (Programme Investissements d'Avenir ANR16-IDEX-0005).}}
\affil[1]{Univ.\ Chile}
\affil[2]{Univ.\ Andres Bello}
\affil[3]{Univ.\ de Lyon and PUC Chile}
\maketitle 

\begin{abstract}
Motivated by Krioukov et al.'s model of random hyperbolic graphs~\cite{KPKVB10} for real-world networks, and inspired by the analysis of a dynamic model of graphs in Euclidean space by Peres et al.~\cite{Peres2010}, we introduce a dynamic model of hyperbolic graphs in which vertices are allowed to move according to a Brownian motion maintaining the distribution of vertices in hyperbolic space invariant. For different parameters of the speed of angular and radial motion, we analyze tail bounds for detection times of a fixed target and obtain a complete picture, for very different regimes, of how and when the target is detected: as a function of the time passed, we characterize the subset of the hyperbolic space where particles typically detecting the target are initially located. Our analysis shows that our dynamic model exhibits a phase transition as a function of the relation of angular and radial speed.

We overcome several substantial technical difficulties not present in Euclidean space, and provide a complete picture on tail bounds. On the way, moreover, we obtain results for a class of one-dimensional continuous processes with drift and reflecting barrier, concerning the time they spend within a certain interval. We also derive improved bounds for the tail of independent sums of Pareto random variables.
\end{abstract}

\section{Introduction}\label{intro}
%\input{secIntro.tex}
\input{NewIntroResults.tex}

\subsection{Structure and strategy of proof}\label{sec:strategy}
%
Recall that in our mobile hyperbolic graph model
we consider an initial configuration $\mathcal{P}$ of the Poissonized model in $B_O(R)$ and then associate to each $x_0:=(r_0,\theta_0)\in\mathcal{P}$ a particle that evolves independently of other particles according to the generator $\Delta_h$ with a reflecting barrier at $\partial B_0(R)$.
Denote by $\mathcal{P}_{\ss}$ the Poisson point process obtained from $\mathcal{P}$ by retaining only particles having detected the target by time $\ss$.
Since points move independently of each other, each particle initially placed at $x_0\in B_O(R)$ belongs to $\mathcal{P}_{\ss}$ independently with probability $\P_{x_0}(T_{det}\leq \ss)$ and hence $\mathcal{P}_{\ss}$ is a thinned Poisson point process on $B_O(R)$ with intensity measure
\[d\mu_{\ss}(x)\;=\;\P_{x_0}(T_{det}\leq \ss)d\mu(x).\]
Noticing that the event $\{T_{det}\geq \ss\}$ is equivalent to $\{\mathcal{P}_{\ss}=\emptyset\}$, we have
\begin{equation}\label{eqn:main}
    \P(T_{det}\geq \ss)=\exp\Big(-\int_{B_O(R)}\P_{x_0}(T_{det}\leq \ss)d\mu(x_0)\Big)
\end{equation}
and hence in order to obtain lower and upper bounds on $\P(T_{det}\geq \ss)$ we will compute the dependence of this integral as a function of $\ss$.
In fact, we can say a bit more on the way we go about determining the value of the said integral. Specifically, we partition the range of integration $B_O(R)$ into $\dt(\kappa)$ and 
$\ndt(\kappa)$ and observe that the three parts of Theorem~\ref{thm:intro-Dt} together immediately imply that
\[
\int_{B_O(R)}\P_{x_0}(T_{det}\leq \ss)d\mu(x_0) = \Theta(\mu(\dt(\kappa)))
\]
thus reducing, via~\eqref{eqn:main}, the computation of tail bounds for detection times to fixing the parameter $\kappa$ equal to a constant and determining the expected number of particles initially in $\dt(\kappa)$, that is, computing $\mu(\dt(\kappa))$. 
So, the structure of the proof of our main results is the following: we determine a suitable candidate set $\dt(\kappa)$, compute $\mu(\dt(\kappa))$, and establish an adequate version of Theorem~\ref{thm:intro-Dt} for the specific type of movement of particles considered (angular, radial or a combination of both).

\subsection{Related work}\label{sec:relatedWork}
%
After the introduction of random hyperbolic graphs by Krioukov et al.~\cite{KPKVB10}, the model was then first analyzed in a mathematically rigorous way by Gugelmann et al.~\cite{GPP12}: they proved that for the case $\alpha > \frac12$ the distribution of the degrees follows a power law, they showed that the clustering coefficient is bounded away from $0$, and they also obtained the average degree and maximum degree in such networks. The restriction $\alpha>\frac12$ guarantees that the resulting graph has bounded average degree (depending on $\alpha$ and $\nu$ only): if $\alpha<\frac12$, then the degree sequence is so heavy tailed that this is impossible (the graph is with high probability connected in this case, as shown in~\cite{BFM13b}). 
The power-law degree distribution of random hyperbolic graphs is equal to $2\alpha+1$ (see~\cite[Theorem 2.2]{GPP12}) which, for $\alpha\in (\frac12, 1]$, belongs to the interval $(2,3]$, and this is the interval where the best fit power-law exponent of social networks typically falls into (see~\cite[p.~69]{barabasiLinked}).
If $\alpha>1$, then as the number of vertices grows, the largest component of a random hyperbolic graph has sublinear size (more precisely, its order is $n^{1/(2\alpha)+o(1)}$, see~\cite[Theorem~1.4]{BFM13} and~\cite{Diel}). On the other hand, it is known that for $\frac12 < \alpha < 1$, with high probability 
a hyperbolic random graph of expected order~$n$ has a connected component whose order is also linear in $n$~\cite[Theorem~1.4]{BFM13} and the second largest component has size $\Theta(\log^{\frac{1}{1-\alpha}} n)$~\cite{km19},  which justifies referring to the linear size component as \emph{the giant component}. 
More precise results including a law of large numbers for the largest component in these networks were established in~\cite{FMLaw}. Further results on the static version of this model include results on the diameter~\cite{km15, fk15, MS19}, on the spectral gap~\cite{KM18}, on typical distances~\cite{ABF}, on the clustering coefficient~\cite{CF16, Clustering}, on bootstrap percolation~\cite{KL} and on the contact process~\cite{Contact}.

No dynamic model of random hyperbolic graphs has been proposed so far. In the \emph{Boolean model} (that is similar to random geometric graphs but now the underlying metric space is~$\RR^d$ and, almost surely, there is an infinite number of vertices)
%On random geometric graphs, \cmk{Doesn't Peres et al.~work on the Boolean model? For me, a graph is a finite object.}\dmc{yes, true. Let's then say "In Euclidean space, in the dynamic Boolean model," or just "in Euclidean space", without mentioning Boolean model} %--- that is graphs, where two nodes/particles in $\mathbb{R}^d$ can communicate if they are at most at Euclidean distances $r=r(n)$ from each other,
the same question  of the tail probability of detection time, as well as the questions of coverage time (the time to detect a certain region of $\mathbb{R}^d$), percolation time (the time a certain particle needs to join particle of the infinite component) and broadcast time (the time it takes to broadcast a message to all particles) were studied by Peres et al.~\cite{Peres2010}: the authors therein show that for a Poisson process of intensity $\lambda$, and a target performing independent Brownian motion, as $t \to \infty$, 
%\cmk{Wouldn't it be better to remove "as $t\to\infty$ and say the asymptotics below is with respect to $t$?}\dmc{We explain below at several times this $t \to \infty$. We could add in the line of the formula at the end as alternative}
$$
\P{(T_{det} \ge t)} = \exp\Big(- 2\pi \lambda\frac{t}{\log t}(1+o(1))\Big),
$$
where a target is detected if a particle is at Euclidean distance at most $r$, for some arbitrary but fixed $r$ (in the three other mentioned contexts the interpretations are similar: we say that an interval is covered if each point of the interval has been at distance at most $r$ from some particle at some time instant before $t$; we say that a particle joins a component if it is at distance at most $r$ from another particle of the component, and we say that a message can be sent between two particles if they are at distance $r$). Note that the probability holds only as $t \to \infty$, and in this case the main order term of the tail probability does not depend on $r$, as shown in~\cite{Peres2010}. Stauffer~\cite{Stauffer} generalized detection of a mobile target moving according to any continuous function and showed that for a Poisson process of sufficiently high intensity $\lambda$ over $\mathbb{R}^d$ (with the same detection setup) the target will eventually be detected almost surely, whereas for small enough $\lambda$, with positive probability the target can avoid detection forever. The somewhat inverse question of isolation of the target, that is, the time it takes for a (possibly) moving target (again for a Poisson process of intensity $\lambda$ in $\mathbb{R}^d$) until no other vertex is at distance $r$ anymore and the target becomes isolated, was then studied by Peres et al.~\cite{Isolation}: it was shown therein that the best strategy for the target to stay isolated as long as possible in fact is to stay put (again with the same setup for being isolated).

%\cmk{In this paragraph, does it make sense to speak of "nodes" and "networks", it seems the results refer simply to "particles" where communication (edges) between them play no role, right?}\dmc{adapted it}
Also for the Boolean model, the question of detection time was already addressed by Liu et al.~\cite{Liu} when each particle moves continuously in a fixed randomly chosen direction: they showed that the time it takes for the set of particles to detect a target is exponentially distributed with expectation depending on the intensity $\lambda$ (where detection again means entering the sensing area of the target). For the case of a stationary target as discussed here, as observed in Kesidis et al.~\cite{Kesidis} and in Konstantopoulos~\cite{Konstant} the detection time can be deduced
from classical results on continuum percolation: namely, in this case it follows from Stoyan et al.~\cite{Stoyan} that
$$
\P{(T_{det} \ge t)} = e^{-\lambda \EE(vol(W_r(t)))},
$$
where $vol(W_r(t))$ is the volume of the Wiener sausage of radius $r$ up to time $t$ (equivalent to being able to detect at distance at most $r$), and which in the case of Euclidean space is known quite precisely~\cite{Spitzer, Bere}. %\cmk{I will conclude the last phrase simply with "in contrast to the case of Brownian motion in hyperbolic space" and move the remaining part of this paragraph to the end of our Main Contribution section. It is in that section that we need to "sell" our work.}\dmc{I put what was here before}


A study of dynamic random geometric graphs prior to the paper of Peres et al.~was undertaken by D\'{i}az et al.~\cite{DMP09}: the authors therein consider a random geometric graph whose radius is close to the threshold of connectivity and analyze in this setup the lengths of time intervals of connectivity and disconnectivity. Even earlier, the model of Brownian motion in infinite random geometric graphs (in the "dynamic Boolean model") was studied by van den Berg et al.~\cite{vdBerg} who showed that for a Poisson intensity above the critical intensity for the existence of an infinite component, almost surely an infinite component exists at all times (here the radii of particles are not fixed to $r$, but rather i.i.d.~random variables following a certain distribution).
More generally, the question of detecting an immobile target (or escaping from a set of immobile traps) when performing random walks on a square lattice is well studied (here, in contrast to the previous papers, detecting means to be exactly at the same position in the lattice); escaping from a set of mobile traps was recently analyzed as well, for both questions we refer to Athreya et al.~\cite{Athreya} and the references therein.



\subsection{Organization}
%
Section~\ref{preliminaries} gathers facts and observations that will be used throughout the paper. Section~\ref{sec:angular} then analyzes the simplified model where the particles' movement is restricted to angular movement only, at the same time illustrating in the simplest possible setting our general proof strategy. Section~\ref{sec:radial} then considers the model where the particles' movement is restricted to radial movement only. In Section~\ref{sec:mix} we finally address the mixed case, that is, the combined case of both radial and angular movement of particles. Specifically, in Section~\ref{sec:Lower}, we look at quick detection mechanisms and, in Section~\ref{sec:Upper}, we show that the detection mechanisms found  are asymptotically optimal in all cases, that is, no other strategy can detect the target asymptotically faster.
In Section~\ref{sec:conclusion} we briefly comment on future work.


\subsection{Global conventions}
%
Throughout all of this paper $\alpha$ is a fixed constant such that $\frac12<\alpha\le 1$
(the reason to consider only this range is that only therein hyperbolic random graphs are deemed to be reasonable models of real-world networks -- see the discussion in Section~\ref{sec:relatedWork}). 
Furthermore, in this article both $\beta$ and $\nu$ are strictly positive constants. In order to avoid tedious repetitions and lengthy statements, we will not reiterate these facts. 
Also, wherever appropriate, we will hide $\alpha$, $\beta$, and $\nu$ within asymptotic notation.
Moreover, throughout the paper, we let~$\ss:=\ss(n)$ be a non-negative function depending on $n$.

In order to avoid using ceiling and floors, we will always assume $R:=2\ln(n/\nu)$ is an integer. Since all our claims hold asymptotically, doing so has no impact on the stated results. 
All asymptotic expressions are with respect to $n$, and wherever it makes sense, inequalities should be understood as valid asymptotically.

\section{Preliminaries}\label{preliminaries}
%
%\input{prelim.tex}
\input{NewPrelim.tex}

\section{Angular movement}\label{sec:angular}
%
\input{secAngularMod.tex}

\section{Radial movement}\label{sec:radial}
%
\input{secRadialMod.tex}
\input{secRadialMod2.tex}

\section{General case: strategies for detection}\label{sec:mix}
%
%Argument for the mixed case with discussion based on the following
%results from previous part:
%\begin{itemize}
%  \item Lemma ParaDieter, items~\eqref{it:secApprox} and~\eqref{it:funApprox}.
%\end{itemize}

\input{secMixto.tex}

\subsection{Upper bounds}\label{sec:Upper}

\input{secUpMixto.tex}

%\input{thebox.tex}

%\newpage\input{sec1b.tex}

%\newpage\input{sec2b.tex}

%\newpage\input{sec3b.tex}

%\newpage\input{sec4.tex}

\section{Conclusion and outlook}\label{sec:conclusion}
We studied a movement of particles in the random hyperbolic graph model introduced by~\cite{KPKVB10} and analyzed the tail of detection times of a fixed target in this model. To the best of our knowledge, the current paper is the first one in analyzing dynamic hyperbolic graphs. It is natural to ask similar questions to the ones addressed in~\cite{Peres2010} in the model of random geometric graphs: how long does it take to detect a target that is mobile itself? How long does it take to detect all (fixed or mobile) targets in a certain sector? How long does it take in order for a given vertex initially outside the giant component at some fixed location needs to connect to some vertex of the giant component (percolation time)? How long does it take to broadcast a message in a mobile graph? We think that the detection of a mobile target, using the same proof ideas as presented here, should accelerate the detection time by a constant factor (presumably by a factor $2$ in the angular case and perhaps by a different factor in general), and also the deletion time of all targets in a certain sector can presumably be done with similar techniques to the ones used in this paper. On the other hand, new proof ingredients might be needed for analyzing the percolation time and the broadcast time. We think that the same observation as the one made by Moreau et al.~\cite{Moreau} which show that for the continuous random walk on the square lattice the best strategy to detect (to end up right at the same location) is to stay put, holds in our model as well.

\appendix
\section{Appendix: on the sums of Pareto variables}
\input{appendix2.tex}

\small
%\bibliographystyle{plain}
%\bibliography{References}
\printbibliography

\end{document}


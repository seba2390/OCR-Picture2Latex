In this section we will show the corresponding upper bounds of Theorems~\ref{thm:mixedSmall} and~\ref{thm:mixedLarge}: that is, we show that particles initially placed outside $\dt$, with $\dt$ as in the corresponding theorems, have only a small chance of detecting the target by time $\ss$. For all values of $\ss$, we will show that
\[\int_{\ndt}\PP_{x_0}(T_{det}\leq \ss)d\mu(x_0)=O(\mu(\dt)),\]
thus establishing that the significant contribution %\dmc{either add: "for $\KA$ large enough" or replace by "a significant contribution"} 
to the tail probabilities comes from particles inside $\dt$, and for large values of $\ss$ we will show uniform upper bounds for the detection probability of every point outside $\dt$. %\cmk{I find very odd to say that "particles" have strategies. This notion is something that we came up to talk about how a particle that has significant chance of detecting behaves. Either we need to explain clearly what we mean by strategy or stop using it.}\cml{I think that the intuition of particles having optimal strategies for detection is interesting so maybe it could be good to discuss it somewhere. I will delete all mentions of strategies for now} 
In order to analyze the trajectory of a particle we will make use of the fact that the generator driving its motion can be separated into its radial and angular component, given respectively by
\[\Delta_{rad} = \frac{1}{2}\frac{\partial^2}{\partial r^2}+\frac{\alpha}{2}\frac{1}{\tanh(\alpha r)}\frac{\partial}{\partial r}\quad\text{and}\quad \Delta_{ang}=\frac{1}{2\sinh^2(\beta r)}\frac{\partial^2}{\partial\theta^2}.\]
Since the generator driving the radial part of the motion does not depend on $\theta$, our approach consists in sampling the radial component $\{r_s\}_{s\geq0}$ of the trajectories first and then, conditional under a given radial trajectory, sampling the angular component $\{\theta_s\}_{s\geq0}$. With this approach we can make use of the results obtained in Section~\ref{sec:radial} in order to study $\{r_s\}_{s\geq 0}$, while the angular component is distributed according to a time-changed Brownian motion $\theta_s=B_{\II{s}}$, where
%\cmk{Double check that in the lower bound section we got rid of the $h(\cdot)$'s and replaced them by $I(\cdot)$.}\dmc{I can see it still in Section 3 in the proof of the main theorem there. Equation (12) and before, it should be changed there, right?}\cmk{Yes!}\cml{If solved, please remove}
\[\II{s}:=\int_0^s\cosech^{2}(\beta r_u)du\]
relates the radial trajectory to the angular variance of $\{\theta_s\}_{s\geq 0}$, as already seen in Section~\ref{sec:angular}. To be able to apply the insight obtained by studying each component separately, we will need to replace the hitting time of the target (which translates into hitting $B_Q(R)$ whose boundary defines a curve relating $r$ and $\theta$) by the exit time of a simpler set: let $x_0\in\ndt$ be any fixed initial location with $\theta_0\in(0,\pi)$  and define a box $\mathcal{B}(x_0)$ containing~$x_0$, of the form 
\begin{equation}\label{eqn:up:box}
\mathcal{B}(x_0):=[\hatr,R]\times[\theta_0-\hatt,\theta_0+\hatt]\subseteq \overline{B}_Q(R)
\end{equation}
where $\hatt$ and $\hatr$ will be defined later on. %\cmk{Can't both consitions be satisfied, how is $\ss$ defined then?}\dmc{At this point we could just say depending on whether $\ss$ is small or large}\cml{when $\ss=\Theta(1)$ the definitions are of the same order (and we could use either proof to obtain the bounds). How would you write this fact? Maybe just not mention it now and say that $\hatt$ and $\hatr$ will be defined later?}
Since $\mathcal{B}(x_0)\subseteq\overline{B}_Q(R)$, it follows that in order for a particle starting at $x_0$ to detect the target, it must first exit the box through either its upper boundary or its side boundaries. Denoting by $\trad$ and $\tang$ the respective hitting times of said boundaries, this implies that $\trad\wedge \tang\leq T_{det}$, and we can obtain the bound
\begin{equation}\label{boxboundsNew}\PP_{x_0}(T_{det}\leq \ss)\,\leq\,\PP_{x_0}(\trad\leq \ss)+\PP_{x_0}(\tang\leq \ss<\trad).\end{equation}
The advantage of addressing the exit time of $\mathcal{B}(x_0)$ instead of $T_{det}$ is straightforward; the first event $\{T_0^{rad}\le \ss\}$ is independent of the angular component of the trajectory, allowing us to bound from above its probability with the tools developed in Section~\ref{sec:radial}, while the treatment of the second event $\{T_0^{ang}\le \ss<T_0^{rad}\}$ will follow from standard results on Brownian motion and the control of~$\II{\ss}$. The following result allows us to bound the second term on the right-hand side of~\eqref{boxboundsNew}:
\begin{proposition}\label{prop:mainuppermixed}
Define $J(r):=\cosech^{-2}(\beta r)$. Then,
\[\PP_{x_0}(\tang\leq \ss\leq\trad)\,\leq\,4\Phi\Big({-}\frac{\hatt}{\sqrt{\ss\JJ(\hatr)}}\Big).\]
where $\Phi$ stands for the error function. Furthermore, %\deleted[id=al]{if $\frac18\hatt^2\in[\ss\JJ(R),\ss]$, then}
\[\PP_{x_0}(\tang\leq \ss)\leq \sqrt{\frac{2}{\pi}}\int_{0}^{\infty}\frac{\hatt}{\sigma^{3/2}}e^{-\frac{\hatt^2}{2\sigma}}\PP_{x_0}\big(\II{\ss}\geq\sigma\big)d\sigma.
\]
%\cml{Notice that there is a big change for this term, will have to redo more than a few computations}\dmc{Agree with the new result. Left the colors in the proof below for Marcos}
\end{proposition}
\begin{proof}
Denote by $\PP_{x_0}(\cdot\mid\{r_u\}_{u\geq0})$ the law of the angular process given a realization of its radial component. Given such a realization we already know that the trajectory $\{\theta_u\}_{u\geq0}$ is equal in law to that of the time-changed Brownian motion $\{B_{\II{u}}+\theta_0\}_{u\geq0}$, for which $\tang$ is equal to the exit time of $B_{\II{u}}$ from $[-\hatt,\hatt]$. Since the exit time of a Brownian motion is well known, we proceed as in Section~\ref{sec:angular} using the reflection principle to obtain 
\[\PP_{x_0}(\tang\leq \ss\,|\{r_u\}_{u\geq0})\leq 4\PP_{x_0}(B_{\II{\ss}}\leq -\hatt\mid\{r_u\}_{u\geq 0})=4\Phi\Big({-}\frac{\hatt}{\sqrt{\II{\ss}}}\Big)\]
where the factor 4 is obtained since the probability of exiting by hitting one of the angles is twice the probability of hitting any of the two angles, which is twice the probability of hitting one fixed angle. Taking expectations with respect to the law of $\{r_u\}_{u\geq 0}$ we obtain
\[\PP_{x_0}(\tang\leq \ss\leq\trad)\leq 4\EE_{x_0}\Big(\Phi\Big({-}\frac{\hatt}{\sqrt{\II{\ss}}}\Big){\bf 1}_{\{\ss\leq\trad\}}\Big),\]
where the expression within the expectation depends on the radial movement alone. To apply this last bound observe that for any realization of $\{r_u\}_{u\geq0}$ such that $\trad\geq\ss$ we have that $\inf_{0\leq u\leq\ss}r_u\geq \hatr$, so $\II{\ss}\leq \ss\JJ(\hatr)$, which gives the first part of the proposition's statement. For the second part of the proposition we can make the same computation as before without taking into account the event $\{\trad\geq\ss\}$, giving 
\[\PP_{x_0}(\tang\leq \ss)\,\leq\,4\EE_{x_0}\Big(\Phi\Big({-}\frac{\hatt}{\sqrt{\II{\ss}}}\Big)\Big)\,=\,-4\int_{0}^\infty\Phi\Big({-}\frac{\hatt}{\sqrt{\sigma}}\Big)d\PP_{x_0}\big(\II{\ss}\geq\sigma\big),\]
and the result follows after using integration by parts, since $\frac{d}{d\sigma}\Phi(-\frac{\hatt}{\sqrt{\sigma}})=\frac{1}{2\sqrt{2\pi}}\frac{\hatt}{\sigma^{3/2}}e^{-\frac{\hatt^2}{2\sigma}}$.
 \end{proof}
 
 \smallskip
 
On a high level, in the proposition above, the bound for $\PP_{x_0}(\tang\leq \ss<\trad)$ will be useful as long as $\ss=O(1)$ since in this case the inequality $\ss \JJ(\hatr)\leq \II{\ss}$ is not too loose. However, when $\ss=\omega(1)$ we need to control this term using the second part of Proposition~\ref{prop:mainuppermixed}, which relies heavily on bounding probabilities of the form $\PP(\II{\ss}\geq\sigma)$. To provide these bounds observe that when $\inf_{0\leq u\leq\ss}r_u$ is not too close to zero the drift function is almost constant so the trajectories of $\{r_u\}_{u\geq0}$ resemble those of a Brownian motion with drift $\tfrac{\alpha}{2}$ (with a reflecting boundary at $R$). Even further, on the event where $\inf_{0\leq u\leq\ss}r_u$ is not too close to zero we also have
\begin{equation}\label{eq:approximation}\II{\ss}\approx\int_0^\ss e^{-2\beta r_u}du,\end{equation}
where  %and we also have that the drift is almost constant and the trajectories of $\{r_u\}_{u\geq0}$ resemble those of a Brownian motion with constant drift $\tfrac{\alpha}{2}$ (with a reflecting boundary at $R$),  and we can also perform the following approximation
%\begin{equation}\label{eq:approximation}\II{\ss}\approx\int_0^\ss e^{-2\beta r_u}du.\end{equation}
%The behavior of random variables such as
the integral appearing above on the right-hand side has been widely studied in the case when $\{r_u\}_{u\geq 0}$ is an (unbounded) Brownian motion with drift (see~\cite{matsumoto2005,Yor1992,Feng2020,dufresne}), revealing that their distributions are heavy-tailed with the tail exponent given analytically in terms of $\beta$ and the drift of $\{r_u\}_{u\geq 0}$. In order to make use of known results  we must first address the change in behavior arising from the reflecting boundary of our process. To do so, we consider an auxiliary process $\{\widetilde{r}_u\}_{u\geq 0}$ akin to the one introduced in the proof of Proposition~\ref{prop:rad-upperBnd}:
    \begin{itemize}
	\item $\{\widetilde{r}_u\}_{u\geq 0}$ begins at $r_0$ and evolves according to $\Delta_{rad}$ up until hitting $R$.
	\item Every time $\{\widetilde{r}_u\}_{u\geq 0}$ hits $R$, it is immediately restarted at $R-1$ and continues to evolve as before.
\end{itemize}
It is not hard to see that $\{\widetilde{r}_u\}_{u\geq 0}$
 is stochastically dominated by $\{r_u\}_{u\geq 0}$, in the sense that the radius of the auxiliary process is always smaller. Thus, in particular, $\II{\ss}\leq \tII{\ss} := \int_0^s\cosech^{2}(\beta \widetilde{r}_u)du$, and hence it will be enough to bound probabilities of the form $\PP(\tII{\ss}\geq\sigma)$ from above. Now, from the definition of $\widetilde{r}_u$, it is natural to use the subsequent hitting times of $R$, say $0<T_R^{(1)}<T_R^{(2)}<\ldots$, to divide the trajectory of $\{\widetilde{r}_u\}_{u\geq 0}$ into excursions from $R-1$ to $R$ (or from $r_0$ to $R$, in the case of the first one), giving
\[\tII{\ss}\,\leq\,\int_0^{T^{(1)}_R}\cosech^{2}(\beta\widetilde{r}_u)du\,+\,\sum_{i=1}^{M(\ss)}\int_{T^{(i)}_R}^{T^{(i+1)}_R}\cosech^{2}(\beta\widetilde{r}_u)du,\]
where $M(\ss)$ is a random variable equal to the amount of times $\{\widetilde{r}_u\}_{u\geq 0}$ has hit $R$ by time~$\ss$. Let $\{\widetilde{r}^{(0)}_u\}_{u\geq0},\{\widetilde{r}^{(1)}_u\}_{u\geq0},\{\widetilde{r}^{(2)}_u\}_{u\geq0},\ldots$ be independent random diffusion processes (that will correspond to the different excursions), each evolving on $(0,\infty)$ according to the generator $\Delta_{rad}$ without the reflecting boundary at $R$, and such that $\{\widetilde{r}^{(0)}_u\}_{u\geq0}$ starts at $r_0$ while the rest of the $\{\widetilde{r}^{(i)}_u\}_{u\geq0}$ start at $R-1$. From the definition of the auxiliary process it follows that within each time interval of the form $[T^{(i)}_R,T^{(i+1)}_R]$ (or $[0,T^{(1)}_R]$ in the case of the first excursion) the trajectory of $\{\widetilde{r}_u\}_{u\geq0}$ is equal to the one of $\{\widetilde{r}^{(i)}_{u'}\}_{u'\geq0}$ for $u'\leq T^{(i+1)}_R-T^{(i)}_R$. Hence,%\dmc{Why separate at the right hand side the term for $i=0$? Aha, perhaps below }\cml{it is not necessary at this point, now all the terms are in the same sum}
\[\tII{\ss}\,\leq\,\int_0^{T^{(1)}_R}\cosech^{2}(\beta\widetilde{r}^{(0)}_u)du\,+\,\sum_{i=1}^{M(\ss)}\int_{0}^{T^{(i+1)}_R-T^{(i)}_R}\cosech^{2}(\beta\widetilde{r}^{(i)}_u)du\,\leq\,\sum_{i=0}^{M(\ss)}\tI^{(i)},\]
where for $i=0, \ldots, M(\ss)$
\[\tI^{(i)}:=\int_{0}^{\infty}\cosech^{2}(\beta\widetilde{r}^{(i)}_u)du.\]
Observe that the bound on $\tII{\ss}$ involves a sum of $M(\ss)+1$ random variables. Intuitively speaking the number of times the process hits $R$ should be proportional to $\ss$, so we introduce an auxiliary parameter $v_0>0$ depending on $x_0$, to be fixed later, so that the event $M(\ss)>\lceil v_0\ss\rceil$ occurs with a very small probability. Using this new parameter we obtain
\begin{equation}\label{eq:division}\PP_{x_0}(\II{\ss}\geq\sigma)\,\leq\,\PP_{x_0}\big(M(\ss)>\lceil v_0\ss\rceil \big)+\PP_{x_0}\big(\tI^{(0)}\geq\tfrac12\sigma\big)+ \PP_{x_0}\Big(\sum_{i=1}^{\lceil v_0\ss\rceil}\tI^{(i)}\geq\tfrac12\sigma\Big).\end{equation}
The advantage of the bound above is that it involves the sum of independent random variables~$\tI^{(i)}$ which, aside from $\tI^{(0)}$, are also identically distributed. The bound also gives valuable intuition regarding the detection of the target: roughly speaking, in order for detection to take place either $x_0$ must be sufficiently close to the origin so that the angular variance coming from $\tI^{(0)}$ becomes significant, or $\ss$ must be large enough so that many excursions starting near the boundary occur, allowing for the contribution $\sum_{i=1}^{M(\ss)}\tI^{(i)}$ to be large enough. As mentioned above (the discussion following~\eqref{eq:approximation}), the distributions of the $\tI^{(i)}$ variables are heavy-tailed. In order to control their sum we make use of the following lemma, whose proof mimics closely what was done in \cite{Omelchenko2019}: since our result is slightly more precise than the one in~\cite{Omelchenko2019}, we provide it in the appendix for the sake of completeness. 

\begin{lemma}\label{lem:cotapower}
Let $S_m:=\sum_{i=1}^m Z_i$ where $\{Z_i\}_{i\in\NN}$  is a sequence of i.i.d.~absolutely continuous random variables taking values in $[1,\infty)$ such that there are $V,\gamma>0$ for which for all $x\geq 0$
\[1-F_{Z_i}(x)=\PP(Z_i\geq x)\leq Vx^{-\gamma}.\]
Then, there are $\auxc,\auxl>0$ depending on $V$, $\gamma$ and $\EE(Z_1)$  (if it exists) alone such that:
\begin{itemize}
    \item If $\gamma<1$ and $L>\auxl$, then
    $\displaystyle\PP(S_m\geq Lm^{\frac{1}{\gamma}})\leq \auxc L^{-\gamma}$.
    \item If $\gamma=1$ and $L>\auxl$, then $\displaystyle\PP(S_m\geq Lm\log(m))\leq \Big(\frac{\auxc}{L\log(m)}\Big)^{1-\frac{\auxl}{L}}$.
    \item If $\gamma>1$ and  $L>\auxl$, then
    $\displaystyle\PP(S_m\geq Lm)\,\leq\,\auxc L^{-\gamma}m^{-((\gamma-1)\wedge\frac{\gamma}{2})}$.
\end{itemize}
\end{lemma}
We can now prove the following result, which will allow us to control $\PP_{x_0}(\II{\ss}\ge\sigma)$:
\begin{proposition}\label{prop:merged-varianza}
For any $0<c<1$ there are $\auxc',\auxl'$ large depending on $\alpha$ and $\beta$ alone, such that for any $\ss\geq c$, $v_0>\frac{4}{c}$, and $x_0\in B_O(R)$ with $r_0>1$, defining $\sigma_0$ as
\[
\sigma_0 := \begin{cases}
\auxl'e^{-2\beta R}(v_0\ss)^{1\vee\frac{2\beta}{\alpha}}, &
\text{if $\alpha \neq 2\beta$,} \\
\auxl'e^{-2\beta R}v_0\ss\log(v_0\ss), &
\text{if $\alpha=2\beta$,}
\end{cases}
\]
the following statements hold for all $\sigma>\sigma_0$ and all $R$ sufficiently large:
\begin{enumerate}[(i)]
\item\label{prop:merged-varianza:itm1} $\PP_{x_0}(M(\ss)>\lceil v_0\ss\rceil )\leq e^{-\frac{1}{16} v_0^2\ss}$,
\item\label{prop:merged-varianza:itm2} $\PP_{x_0}(\tI^{(0)}\geq\tfrac12\sigma)\leq \frac{\log(\tanh(\alpha r_0/2))}{\log(\tanh(\alpha/2))}+\auxc'\sigma^{-\frac{\alpha}{2\beta}} e^{-\alpha r_0}$, and 
\item\label{prop:merged-varianza:itm3} $\PP_{x_0}\big(\sum_{i=1}^{\lceil v_0\ss\rceil}\tI^{(i)}\geq\tfrac12\sigma\big)\leq 2v_0\ss\frac{\log(\tanh(\alpha ((R-1)/2))}{\log(\tanh(\alpha/2))}+\big(\auxc'(v_0\ss)^{1\vee\frac{\alpha}{4\beta}}\sigma^{-\frac{\alpha}{2\beta}}e^{-\alpha R}\big)^{1-\mathfrak{e}}$
where
\[\mathfrak{e}:=\begin{cases}
0, &\mbox{ if }\alpha\neq 2\beta, \\[3pt]\frac{1}{\sigma e^{2\beta R}}\auxl'v_0\ss\log(v_0\ss), &\mbox{ if }\alpha=2\beta.
\end{cases}\]
\end{enumerate}
\end{proposition}
\begin{proof}
We begin with the upper bound for the term $\PP_{x_0}(M(\ss)>\lceil v_0\ss\rceil)$. By definition, the event $\{M(\ss)>  \lceil v_0\ss \rceil\}$ is equal to $\{T^{(\lceil v_0\ss\rceil)}_R\leq\ss\}$. Writing $T^{(\lceil v_0\ss\rceil)}_R=T^{(1)}_R+\sum_{i=2}^{\lceil v_0\ss\rceil}(T^{(i)}_R-T^{(i-1)}_R)$,  by Markov's inequality, for any $\lambda>0$ we deduce
\[\PP_{x_0}\big(M(\ss)>\lceil v_0\ss\rceil\big)\,\leq\,\PP_{x_0}\Big(\sum_{i=2}^{\lceil v_0\ss\rceil}(T^{(i)}_R-T^{(i-1)}_R)\leq\ss\Big)\,\leq\,e^{\lambda \ss}\EE_{x_0}\Big(\exp\big({-}\lambda\sum_{i=2}^{\lceil v_0\ss\rceil}(T^{(i)}_R-T^{(i-1)}_R)\big)\Big)\]
where the differences $T^{(i)}_R-T^{(i-1)}_R$ are i.i.d.~random variables which indicate the time it takes for excursion $\widetilde{r}^{(i-1)}$ starting at $R-1$ to reach $R$. Since each $\{\widetilde{r}^{(i)}_u\}_{u\geq 0}$ is stochastically bounded from below by a Brownian motion with constant drift $\tfrac{\alpha}{2}$, we can use Formula 2.0.1 in~\cite{Borodin2002} to obtain
\[\PP_{x_0}\big(M(\ss)>\lceil v_0\ss\rceil\big)\,\leq\,e^{\lambda \ss}\EE\big(e^{-\lambda(T^{(2)}_R-T^{(1)}_R)}\big)^{\lceil v_0\ss\rceil-1}\,\leq\,e^{\lambda \ss}\big( e^{\frac{\alpha}{2}-\sqrt{\frac{\alpha^2}{4}+2\lambda}}\big)^{\lceil v_0\ss\rceil-1}.\]
The exponent $\lambda\ss+(\lceil v_0\ss\rceil-1)(\frac{\alpha}{2}-\sqrt{\frac{\alpha^2}{4}+2\lambda})$ appearing in the last term is minimized as a function of $\lambda$ when $\ss\sqrt{\tfrac{\alpha^2}{4}+2\lambda}=\lceil v_0\ss\rceil-1$, which defines a positive $\lambda$ since $v_0\ss>4$ and $\alpha,c<1$, giving an expression for the exponent of the right-hand side of the form %\dmc{now it seems ok}
\[-\frac{1}{2\ss}(\lceil v_0\ss\rceil-1)^2-\frac{1}{8}\alpha^2\ss+\frac{1}{2}\alpha(\lceil v_0\ss\rceil-1)\leq\frac12(\lceil v_0\ss\rceil-1)\Big(\alpha-\frac{1}{\ss}(\lceil v_0\ss\rceil-1)\Big)\,\leq\,-\frac{1}{16}\,v_0^2\ss\]
where in the last inequality we used that $\lceil v_0\ss\rceil-1\geq \frac12v_0\ss$ and that $\alpha-\frac12v_0\leq -\frac14 v_0$. This proves the bound in~\eqref{prop:merged-varianza:itm1}. In order to control the probabilities appearing in~\eqref{prop:merged-varianza:itm2} and~\eqref{prop:merged-varianza:itm3} it is convenient from the point of view of computations to work under the assumption that the $\widetilde{r}^{(i)}$ processes never get too close to $0$. To do so observe that by our assumption of $r_0>1$, all the $\widetilde{r}^{(i)}$ start in $(1,\infty)$, and denote by $\tau^{(i)}_1$ the hitting time of radius $1$ by $\widetilde{r}^{(i)}$. Observe that \[\PP_{x_0}(\tI^{(0)}\geq\tfrac12\sigma)\,\leq\,\PP_{x_0}(\tau_{1}^{(0)}<\infty)+\PP_{x_0}(\tI^{(0)}\geq\tfrac12\sigma, \tau^{(0)}_{1}=\infty).\]
Using Part~\eqref{radial:itm:phi3} from Lemma~\ref{lemmaradial}, with $\yabs_0:=1$ and $\auxY:=R$,  we obtain 
\[\PP_{x_0}(\tau_{1}^{(0)}<\infty)=\lim_{R \to \infty}\PP_{x_0}(\tau_{1}^{(0)}<T_R)=\frac{\log(\tanh(\alpha r_0/2))}{\log(\tanh(\alpha/2))},\]
which gives the first term of the bound for $R$ (and thus $n$) sufficiently large. For the second term, observe that on the event $\tau^{(0)}_1=\infty$ we have $\widetilde{r}^{(0)}_u>1$ for all $u\geq0$ so there is some constant $C$ depending on $\beta$ alone such that for all $u\geq 0$, we have $\cosech^2(\beta \widetilde{r}^{(0)}_u)\leq Ce^{-2\beta \widetilde{r}^{(0)}_u}$ and hence
\[\PP_{x_0}(\tI^{(0)}\geq\tfrac12\sigma,\tau^{(0)}_{1}=\infty)\,\leq\,\PP_{x_0}\Big(C\int_0^{\infty}e^{-2\beta\widetilde{r}^{(0)}_u}du\geq\tfrac12\sigma\Big).\]
Now, notice that $\{\widetilde{r}_u^{(0)}-r_0\}_{u\geq0}$ %\dmc{Ok with brackets, but $r_0$ is always larger, right? so I would put $\{r_0-\widetilde{r}_u^{(0)}\}_{u\geq0}$}%\cml{$r_0$ is not the process $r$, but the initial condition, we subtract to get a brownian motion} 
is stochastically bounded from below by $X_u$, a Brownian motion with constant drift $\tfrac{\alpha}{2}$ so we can bound the integral within the last term from above by $\int_0^{\infty}e^{-2\beta(X_u+r_0)}du$. This particular functional of Brownian motion was studied in~\cite[Proposition~4.4.4]{dufresne}, where it was shown that
\[\int_0^\infty e^{-2\beta X_u}du\,=\,W,\quad\text{where }W\text{ is a positive r.v.~with }\quad f_{W}(x):=\frac{(2\beta^2)^\frac{\alpha}{2\beta}}{\Gamma(\frac{\alpha}{2\beta})}x^{-\frac{\alpha}{2\beta}-1}e^{-\frac{2\beta^2}{x}}\]
that is, $W$ is distributed according to an inverse gamma distribution with parameters $\frac{\alpha}{2\beta}$ and~$2\beta^2$. From the density of the variable $W$ above the only relevant feature for our purposes is its heavy tail: in order to ease calculations we will bound $W$ stochastically from above by a random variable $Z$ following a Pareto distribution with a sufficiently large scale $\omega$ depending on $\alpha$ and $\beta$ alone (in particular we will assume $\omega>1$), and shape $\frac{\alpha}{2\beta}$. That is, $W \preccurlyeq Z$ with
\[f_{Z}(x)\,=\,\frac{2\beta}{\alpha\omega}\Big(\frac{\omega}{x}\Big)^{\frac{\alpha}{2\beta}+1}{\bf 1}_{(\omega,\infty)}(x).\]
Using this auxiliary variable we readily obtain 
\[\PP_{x_0}\Big(C\int_0^{\infty}e^{-2\beta\widetilde{r}^{(0)}_u}du\geq\tfrac12\sigma\Big)\leq\PP\big(Z\geq\tfrac{\sigma}{2C}e^{2\beta r_0}\big)\leq\Big(\frac{\sigma e^{2\beta r_0}}{2C\omega}\Big)^{-\frac{\alpha}{2\beta}},\]
%\cmk{For the last equality above, don't we need that $\omega\leq \frac{\sigma}{2C}e^{2\beta r_0}$?}\cml{I changed to an inequality, which always holds}
giving the last term of~\eqref{prop:merged-varianza:itm2}. To obtain the bound in~\eqref{prop:merged-varianza:itm3}, define the event $\mathcal{E}:=\{\exists 1\leq i\leq \lceil v_0\ss\rceil,\,\tau_1^{(i)}<\infty\}$ where $\tau_1^{(i)}$ was defined previously as the hitting time of $r=1$ on the $i$-th excursion. By the same analysis as in the previous paragraph, we get 
\begin{align*}\PP_{x_0}\Big(\sum_{i=1}^{\lceil v_0\ss\rceil}\tI^{(i)}\geq\tfrac12\sigma\Big)&\leq\,\PP_{x_0}(\mathcal{E})+\PP_{x_0}\Big(\sum_{i=1}^{\lceil v_0\ss\rceil}\tI^{(i)}\geq\tfrac12\sigma,\,\overline{\mathcal{E}}\Big)\\&\leq\,\lceil v_0\ss\rceil\PP_{x_0}(\tau_{1}^{(1)}<\infty)+\PP_{x_0}\Big(C\sum_{i=1}^{\lceil v_0\ss\rceil}\int_0^{\infty}e^{-2\beta\widetilde{r}^{(i)}_u}du\geq\tfrac12\sigma\Big)\\&\leq\,\lceil v_0\ss\rceil\PP_{x_0}(\tau_{1}^{(1)}<\infty)+\PP_{x_0}\Big(\sum_{i=1}^{\lceil v_0\ss\rceil}Z^{(i)}\geq\tfrac{\sigma}{2C}e^{2\beta(R-1)}\Big)\end{align*}
where in this case we have used that each $\widetilde{r}^{(i)}$ begins at $R-1$ and the $Z^{(i)}$'s stand for i.i.d.~Pareto random variables with scale $\omega$ and shape $\frac{\alpha}{2\beta}$ as in the previous case. For the first term we use the same treatment as with $\PP_{x_0}(\tau_{1}^{(0)}<\infty)$ to obtain
\[\lceil v_0\ss\rceil\PP_{x_0}(\tau_{1}^{(1)}<\infty)\,\leq\,2v_0\ss\frac{\log(\tanh(\alpha (R-1)/2))}{\log(\tanh(\alpha/2))}\]
where we have used that in the first excursion the starting radius is $R-1$, and that $v_0\ss\geq 4$. For the second term recall that the $Z^{(i)}$ variables are bounded from below by $\omega\geq 1$, and that $1-F_Z(x)=(\frac{\omega}{x})^{\frac{\alpha}{2\beta}}$ for any $x\geq\omega$. Hence, we can apply Lemma~\ref{lem:cotapower} with $m:=\lceil v_0\ss\rceil$ and $S_m:=\sum_{i=1}^{\lceil v_0\ss\rceil} Z^{(i)}$ depending on the value of $\gamma:=\frac{\alpha}{2\beta}$ as follows:
\begin{itemize}
\item If $\frac{\alpha}{2\beta}<1$, then we can take $L:=\tfrac{\sigma}{2C}\lceil v_0\ss\rceil^{-\frac{2\beta}{\alpha}}e^{2\beta(R-1)}$ in the lemma so that 
\[\PP_{x_0}\Big(\sum_{i=1}^{\lceil v_0\ss\rceil}Z^{(i)}\ge\tfrac{\sigma}{2C}e^{2\beta(R-1)}\Big)=\PP_{x_0}\Big(S_{\lceil v_0\ss\rceil}\ge L \lceil v_0\ss\rceil^{\frac{2\beta}{\alpha}}\Big)\leq \auxc L^{-\frac{\alpha}{2\beta}}\]
as soon as $L> \auxl$ for some $\auxl$ and $\auxc$ depending on $\alpha,\beta$ and $\omega$ alone. Observing that $L^{-\frac{\alpha}{2\beta}}=(2C)^{\frac{\alpha}{2\beta}}\lceil v_0\ss\rceil\sigma^{-\frac{\alpha}{2\beta}}e^{-\alpha (R-1)}$ and that the condition $L> \auxl$ is equivalent to
$\sigma > 2\auxl C\lceil v_0\ss\rceil^{\frac{2\beta}{\alpha}}e^{-2\beta (R-1)}$, the result follows by defining $\auxl'$ and $\auxc'$ accordingly.
\item If $\frac{\alpha}{2\beta}=1$ we can take $L:=\tfrac{\sigma}{2C}(\lceil v_0\ss\rceil\log \lceil v_0\ss\rceil)^{-1} e^{2\beta(R-1)}$ in the lemma so that
\[\PP_{x_0}\Big(\sum_{i=1}^{\lceil v_0\ss\rceil}Z^{(i)}\ge\tfrac{\sigma}{2C}e^{2\beta(R-1)}\Big)=\PP_{x_0}\big(S_{\lceil v_0\ss\rceil}\ge L \lceil v_0\ss\rceil\log \lceil v_0\ss\rceil\big)\leq \Big(\frac{\auxc}{L\log \lceil v_0\ss\rceil}\Big)^{1-\frac{\auxl}{L}}\]
as soon as $L>\auxl$ for some $\auxl$ and $\auxc$ depending on $\alpha,\beta$ and $\omega$ alone, which is satisfied since by hypothesis $\sigma > \auxl'e^{-2\beta R}v_0\ss\log(v_0\ss)$ and we can choose $\auxl'>2Ce^{2\beta}\auxl$. Since $\alpha=2\beta$, we have $\tfrac{\auxc}{L\log\lceil v_0\ss\rceil}=\frac{\auxc'}{\sigma}e^{-\alpha R}\lceil v_0\ss\rceil $ for $\auxc':=2C\auxc e^{\alpha}$, giving the result.
\item Finally, assume that $\frac{\alpha}{2\beta}>1$ and take $L:=\tfrac{\sigma}{2C\lceil v_0\ss\rceil} e^{2\beta(R-1)}$ in the lemma so that
\[\PP_{x_0}\Big(\sum_{i=1}^{\lceil v_0\ss\rceil}Z^{(i)}\ge\tfrac{\sigma}{2C}e^{2\beta(R-1)}\Big)=\PP_{x_0}\big(S_{\lceil v_0\ss\rceil}\ge L \lceil v_0\ss\rceil\big)\leq \auxc L^{-\frac{\alpha}{2\beta}}\lceil v_0\ss\rceil^{-(\frac{\alpha}{2\beta}-1\wedge\frac{\alpha}{4\beta})}\]
as soon as $L> \auxl$ for some $\auxl$ and $\auxc$ depending on $\alpha,\beta$ and $\omega$ alone. The condition follows directly from the hypothesis $\sigma>\auxl' e^{-2\beta R}(v_0\ss)$ for $\auxl'$ adequately chosen, and the bound in~\eqref{prop:merged-varianza:itm3} is obtained from the previous inequality by noticing that $L^{-\frac{\alpha}{2\beta}}=(2C\lceil v_0\ss\rceil)^{\frac{\alpha}{2\beta}}\sigma^{-\frac{\alpha}{2\beta}}e^{-\alpha (R-1)}$ and defining $\auxc'$ accordingly.
\end{itemize}
\end{proof}

\subsubsection{The case $\ss$ small}
In this subsection we obtain upper bound for $\int_{\ndt}\PP_{x_0}(T_{det}\leq \ss)d\mu(x_0)$ under the assumption of $\beta\leq1/2$ and $\ss=O(1)$ as required by Theorem~\ref{thm:mixedSmall}. Since for $\beta=1/2$ we always have $\ss=\Omega(1)$ and the next subsection deals with all such values, here we even assume $\beta < 1/2$. The main result in this section is the following:
\begin{proposition}\label{generalschico}
Let $\beta<\frac{1}{2}$. If $\dt$ is as defined in Theorem~\ref{thm:mixedSmall} and $\ss=\Omega((e^{\beta R}/n)^{2})\cap O(1)$, then
\[\int_{\ndt}\P_{x_0}(T_{det}\leq \ss)d\mu(x_0) 
\;=\;O\big(ne^{-\beta R}\sqrt{\ss}\big).\]
\end{proposition}
\begin{proof}
Notice first that for any $C'>0$, Lemma~\ref{lem:muBall} gives $\mu(B_O(C'))=O(ne^{-\alpha R})=o(1)$ so the contribution of points in $\ndt\cap B_O(C')$ to the upper bound is $o(ne^{-\beta R}\sqrt{\ss})$ from our assumption $\ss=\Omega((e^{2\beta R}/n)^{2})$, and hence such points can be neglected. Take then $C'>0$ large (to be fixed later) so we only need to consider particles initially located at points with radial component in $[C',R]$. For such points we follow the proof argument described in the previous section, where we bound the detection time of the target by the exit time of the box
$\mathcal{B}(x_0)$ for $\hatt$ and $\hatr$ given in the next sentence, allowing us to bound $\PP_{x_0}(T_{det}\leq\ss)$ as in~\eqref{boxboundsNew}. More in detail, given $x_0\in\ndt$ we construct the box $\mathcal{B}(x_0)$ by choosing 
\[\hatt:=\tfrac{1}{3}(|\theta_0|-\phi(r_0))\qquad\text{and}\qquad\hatr:=r_0-\log\big(1+(|\theta_0|-\phi(r_0))e^{\beta r_0}\big).\]
Notice first that $\hatt>0$, $\hatr<r_0$, and assuming $C'>13$ we also have $\hatr>\frac13 r_0$: indeed, this last statement is equivalent to 
$e^{\frac23 r_0}>1+(|\theta_0|-\phi(r_0))e^{\beta r_0}$
which is satisfied for $r_0>2/(\frac{2}{3}-\beta)+1\geq 13$ since $\beta\leq1/2$ and $|\theta_0|\leq\pi$. The previous inequalities show that the box is well defined and contain the point $(r_0,\theta_0)$, but we still need to prove that $\mathcal{B}(x_0)\subseteq \overline{B}_Q(R)$. To do so 
assume, without loss of generality, that $\theta_0>0$  and 
observe that it is enough to show that the upper-left corner of the box, $(\hatr,\theta_0-\hatt)$ is in $\overline{B}_Q(R)$, or equivalently, that $\phi(\hatr)<\theta_0-\hatt=\frac{2}{3}(\theta_0-\phi(r_0))+\phi(r_0)$. Using that $\hatr<r_0$ and Part~\eqref{itm:phi1} of Lemma~\ref{lem:phi} we obtain that 
\begin{align*}\cos(\phi(r_0))-\cos(\phi(\hatr))&=(\tanh(\tfrac{r_0}{2})-\tanh(\tfrac{\hatr}{2}))\coth(R)=\coth (R)\frac{2(e^{r_0}-e^{\hatr})}{(e^{r_0}+1)(e^{\hatr}+1)}\\[3pt]&\leq4(e^{-\hatr}-e^{-r_0})=4e^{(\beta-1)r_0}(|\theta_0|-\phi(r_0)). 
\end{align*}
Moreover, for $C'$ sufficiently large, since $\cos(x)-\cos(x')=2\sin(\frac12(x+x'))\sin(\frac12(x-x'))$, 
\[\cos(\phi(r_0))-\cos(\phi(\hatr))\ge 2\sin(\tfrac12\phi(r_0))\sin(\tfrac12(\phi(\hatr)-\phi(r_0)))\geq\tfrac18\phi(r_0)(\phi(\hatr)-\phi(r_0)).\]
Using Part~\eqref{itm:phi4} of Lemma~\ref{lem:phi} we have $\phi(r_0)\geq e^{-\frac{r_0}{2}}$ for $r_0>C'$ so we conclude that 
\[\phi(\hatr)-\phi(r_0)\,\leq\,32e^{(\beta-\frac{1}{2})r_0}(|\theta_0|-\phi(r_0))\]
and since $\beta<\frac{1}{2}$, taking $C'$ sufficiently large the last term is bounded by $\frac{2}{3}(\theta_0-\phi(r_0))$ which proves that  $\mathcal{B}(x_0)\subseteq \overline{B}_Q(R)$ for all such $r_0$. 

Now, we follow the proof strategy presented in the previous section by splitting the detection probability as in~\eqref{boxboundsNew} and using the first bound in Proposition~\ref{prop:mainuppermixed}, which by setting $\Omega:=\ndt\cap\overline{B}_O(C')$ and recalling that $\JJ(\hatr):=\cosech^{2}(\beta\hatr)$, gives
\begin{equation}\label{eq:mainosmall}
    \int_{\Omega}\P_{x_0}(T_{det}\leq\ss)d\mu(x_0) \leq \int_{\Omega} \PP_{x_0}(T_{0}^{rad}\leq \ss)d\mu(x_0) +\int_{\Omega}4\Phi\Big({-}\frac{\hatt}{\sqrt{\ss \JJ(\hatr)}}\Big)d\mu(x_0)
\end{equation}
where $T_0^{rad}$ is the hitting time of $\hatr$. For the first term on the right of~\eqref{eq:mainosmall} we can stochastically dominate from above the trajectory of $\{r_s\}_{s\geq0}$ by that of a simple Brownian motion with a reflecting barrier at $R$ (thus removing the drift towards the boundary) which decreases the hitting time of $\hatr$. Since hitting $\hatr$ implies moving outside of an interval of length $2(r_0-\hatr)$, by the reflection principle, we obtain
\[\PP_{x_0}(T_{0}^{rad}\leq \ss)\,\leq\,4\Phi\Big({-}\frac{1}{\sqrt{\ss}}(r_0-\hatr)\Big)\,=\,4\Phi\Big({-}\frac{1}{\sqrt{\ss}}\log\Big(1+\frac{|\theta_0|-\phi(r_0)}{e^{-\beta r_0}}\Big)\Big).\]
For the term on the right we have
\[\int_{\phi(r_0)+\sqrt{\ss}e^{-\beta r_0}}^\infty\PP_{x_0}(T_{0}^{rad}\le\ss)d\theta_0=
%\Phi\Big({-}\frac{1}{\sqrt{\ss}}\log\Big(1+\frac{|\theta_0|-\phi(r_0)}{e^{-\beta r_0}}\Big)\Big)d\theta_0=
4\sqrt{\ss}e^{-\beta r_0}\int_1^\infty \Phi\Big({-}\frac{1}{\sqrt{\ss}}\log(1+\sqrt{\ss}w)\Big)dw\]
but since the function $x\to\frac{1}{\sqrt{x}}\log(1+\sqrt{x}w)$ is decreasing and $\ss=O(1)$ we deduce that the term on the right-hand side is $O(\sqrt{\ss}e^{-\beta R})$, so
\begin{align*}
\int_{\Omega} \PP_{x_0}(T_{0}^{rad}\leq \ss)d\mu(x_0)&=\;O\Big(n\int_{C'}^R\int_{\phi(r_0)+\sqrt{\ss}e^{-\beta r_0}}^\infty\PP_{x_0}(T_{0}^{rad}\leq \ss)d\theta_0e^{-\alpha(R-r_0)}dr_0\Big)\\&=\;O\Big(n\int_{C'}^R\sqrt{\ss}e^{-\beta r_0}e^{-\alpha(R-r_0)}dr_0\Big)=O\big(n\sqrt{\ss}e^{-\beta R}\big)
\end{align*}
where in the last equality we have used that $\beta<\frac{1}{2}<\alpha$. Next, we must bound the second term on the right of~\eqref{eq:mainosmall}, for which we observe first that since $\hatr>\frac13 r_0$ and assuming that $C'>0$ is large we have $\sinh(\beta \hatr)>\frac{1}{4}e^{\beta\hatr}$ so that 
\[{-}\frac{\hatt}{\sqrt{\ss \JJ(\hatr)}}=\frac{\theta_0-\phi(r_0)}{3\sqrt{\ss J(\hatr)}}\leq {-}\frac{4(\theta_0-\phi(r_0))}{3\sqrt{\ss} e^{-\beta r_0}}\Big(1+\frac{\theta_0-\phi(r_0)}{e^{-\beta r_0}}\Big)^{-\beta}.\]
Evaluating at $\Phi(\cdot)$, integrating over $\Omega$ and using the change of variables $w:=\frac{\theta_0-\phi(r_0)}{\sqrt{\ss}e^{-\beta r_0}}$ gives
\[\int_{\Omega}\Phi\Big({-}\frac{\hatt}{\sqrt{\ss \JJ(\hatr)}}\Big)d\mu(x_0)\;=\;O\Big(n\int_{C'}^R\sqrt{\ss}e^{-\beta r_0}\Big(\int_{1}^\infty\Phi\Big({-}\frac{4w}{3(1+\sqrt{\ss}w)^{\beta}}\Big)dw\Big)e^{-\alpha(R-r_0)}dr_0\Big)\]
but since $\ss=O(1)$ we have $\int_{1}^\infty\Phi(-\tfrac{4w}{3(1+\sqrt{\ss}w)^{\beta}})dw=O(1)$ (it is finite since $\beta<1/2$) and hence
\[\int_{\Omega}\Phi\Big({-}\frac{\hatt}{\sqrt{\ss \JJ(\hatr)}}\Big)d\mu(x_0)\,=\,O\Big(n\sqrt{\ss}\int_{C'}^Re^{-\beta r_0+\alpha(R-r_0)}dr_0\Big)\,=\,O\big(n\sqrt{\ss}e^{-\beta R}\big)\]
where again we used that $\beta<\frac{1}{2}<\alpha$ in the last equality. %\cml{made small changes here, the main one being that I eliminated $\const$}
\end{proof}


\subsubsection{The case $\ss$ large}
%
%\dmc{Would suggest case $\ss$ small and large to make clear they are disjoint? }\cml{I don't understand this}
 In this subsection we will prove the upper bounds in Theorem~\ref{thm:mixedLarge} for both $\int_{\ndt}\PP_{x_0}(T_{det}\leq \ss)d\mu(x_0)$ as well as for $\sup_{x_0\in\ndt}\PP_{x_0}(T_{det}\leq \ss)$, where for convenience we use the shorthand notation $\ndt=\ndt(\KA)$ that will be used throughout this section. Recall that we may assume $\ss=\Omega(1)$ for this theorem. We handle this case with the help of Propositions~\ref{prop:mainuppermixed} and~\ref{prop:merged-varianza}, as well as with the results obtained in Section~\ref{sec:radial}.
The main result in this section is the following, which directly implies the corresponding upper bounds of Theorem~\ref{thm:mixedLarge}:
%\dmc{General comment: should we make bounds of $\ss$ for the bounds in terms of $\KA$ as well in the theorem, something like: Assume $\ss =O((\KA n)^{2\beta})$ for example? It is needed below anyway, and we don't have to rejustify at any time, but rather say at the beginning why this is natural, namely because $\KA \phis +\phi(R) \le \pi$ has to hold}\cml{It would be nice but $\ss$ does not depend on our particular choice of $\dt$ so imposing such a condition would not be natural}
\begin{proposition}\label{generalsgrande}
    Let $\dt$ be as in Theorem~\ref{thm:mixedLarge}. Then there is a $C>0$ independent of $\ss$ and $n$ such that for $\ss=\Omega(1)$ satisfying the conditions of Theorem~\ref{thm:mixedLarge}, fixing $\KA:=C$ gives  
\[\int_{\ndt}\P_{x_0}(T_{det}\leq \ss)d\mu(x_0) 
\;=\;O(n\phis).\]
Furthermore, for $\KA\geq C$ and under the additional assumption $\ss=\omega(1)$ we have
\[
\sup_{x_0\in\ndt}\P_{x_0}(T_{det}\leq \ss) =
\begin{cases}
e^{-\Omega(\KA^2)},
& \text{ if $\alpha\geq2\beta$,} \\[2pt]
O(\KA^{-\alpha(\frac{1}{\beta}\vee 2)}),
& \text{ if $\alpha<2\beta$.} 
\end{cases}
\]
\end{proposition}
We begin by introducing some notation and deriving a few facts that will come in handy throughout this section. The points in $\partial \ndt$ with a positive angle define a curve in polar coordinates which can be parameterized by the radius as $(r,\gamma(r))$ with $\gamma(r):=\max\{\phi(R)+\KA\phis,\phi(r)+\KR e^{-(\beta\wedge\frac12) r}\}$, and where $r$ takes values between $r'$ and $R$, for $r'$ being the solution of (see Figure~\ref{fig:mixto}(b) for a depiction of $r'$)
\begin{equation}\label{eq:def:rprime}
\phi(r')+\KR e^{-(\beta\wedge\frac12) r'}=\pi.
\end{equation}
Observing that $\gamma$ is the maximum between two functions, a major role will be played by the intersecting point $(r'',\gamma(r''))$ which satisfies (see Figure~\ref{fig:mixto}(b) for a depiction of $r''$)
\begin{equation}\label{eq:def:r2prime}
\phi(R)+\KA\phis=\phi(r'')+\KR e^{-(\beta\wedge\frac12) r''}.
\end{equation}
\smallskip

Next we derive several inequalities that will be useful in the proof of Proposition~\ref{generalsgrande}:
\begin{fact}\label{fact:uppermix}
If the constant $C>0$ appearing in the statement of Proposition~\ref{generalsgrande} is sufficiently large, then under the assumption $\ss=\Omega(1)$ the following hold:
\begin{enumerate}[(i)]
\item\label{itm:upp1} $\phis=\Omega(\phi(R))$ and for all $0<r_0\leq R$, $e^{-(\beta\wedge\frac12) r_0}=\Omega(\phi(r_0))$. In particular, for any $C'>0$ by taking $C$ large we have $\KA\phis\geq C'\phi(R)$ and $\KR e^{-(\beta\wedge\frac12) r_0}\geq C'\phi(r_0)$.
\item\label{itm:upp2} $(\beta\wedge\frac12)^{-1}\log(\frac{1}{\pi} \KR)\leq r'\leq (\beta\wedge\frac12)^{-1}\log(\frac{2}{\pi}\KR)$.
\item\label{itm:upp3} $e^{-(\beta\wedge\frac12) r''}=\Theta(\tfrac{\KA}{\KR}\phis)$.
\item\label{itm:upp4} $\gamma(r)-\phi(r)$ is minimized at $r''$, and in particular %\[\gamma(r)-\phi(r)\;\geq\;\begin{cases}
%\KR e^{-(\beta\wedge \frac{1}{2})r}, &\text{ if }r'\leq r\leq r'',\\[2pt]\tfrac{1}{2}\KA \phis,&\text{ if }r''\leq r\leq R,
%\end{cases}\]
%and in particular we 
$\gamma(r)-\phi(r)\geq(\KR e^{-(\beta\wedge \frac{1}{2})r}\vee\tfrac{1}{2}\KA\phis)$ for all $r'\leq r\leq R$.
\item\label{itm:upp5} For any fixed value of $\KA$ and $\KR$,  $\displaystyle\int_{r'}^R(\gamma(r)-\phi(r))e^{-\alpha(R-r)}dr=O(\phis).$
\end{enumerate}
\end{fact}
\begin{proof}
The first part follows directly from Part~\eqref{itm:phi4} of Lemma~\ref{lem:phi}, 
the second one from the definition of $r'$ and the fact that $0\leq\phi(\cdot)\leq\frac{\pi}{2}$, and 
the third part follows from~\eqref{itm:upp1} and the definition of $r''$. To prove part~\eqref{itm:upp4} observe that in $[r',r'']$ the function $\gamma(r)-\phi(r)=\KR e^{-(\beta\wedge \frac{1}{2})r}$ is decreasing while in $[r'',R]$ it is increasing (since $\gamma$ is constant and $\phi$ is decreasing) so the function is minimized at $r''$. The inequality $\gamma(r)-\phi(r)\geq(\KR e^{-(\beta\wedge \frac{1}{2})r}\vee\tfrac{1}{2}\KA\phis)$ follows from%the case $r'\leq r\leq r''$ follows directly from the definition of $\gamma$, while for the case $r''\leq r\leq R$ we have $\gamma(r)-\phi(r)\geq \gamma(r'')-\phi(r'')$ since the function $\gamma$ is independent of $r$ in this interval and since from Part~\eqref{itm:phi2} of Lemma~\ref{lem:phi} the function $\phi(\cdot)$ is decreasing. Now, it follows from~\eqref{itm:upp1} and the definition of $r''$ that 
%\cmk{The two $=$'s below should be $\geq$, right?}\cml{these are both equalities, the first one comes directly from the definition of $\gamma$ between $r'$ and $r''$, and the second one comes from the definition of $r''$}
\[\gamma(r'')-\phi(r'')=\KR e^{-(\beta\wedge \frac{1}{2})r''}\geq\tfrac{1}{2}(\KR e^{-(\beta\wedge \frac{1}{2})r''}+\phi(r''))=\tfrac{1}{2}(\KA\phis+\phi(R))\geq \tfrac{1}{2}\KA\phis.\]
To prove~\eqref{itm:upp5} we fix $\KA=C_A$ and $\KR=C_R$ equal to some constants and split the range of integration into two intervals, specifically $[r',r'']$ and $[r'',R]$. For the first one we have $\gamma(r)=\phi(r)+C_R e^{-(\beta\wedge\frac{1}{2})r}$ and since $\alpha>\frac{1}{2}$, using~\eqref{itm:upp3}, we get
\[\int_{r'}^{r''}(\gamma(r)-\phi(r))e^{-\alpha(R-r)}dr=O\big(e^{-\alpha R}e^{(\alpha-(\beta\wedge\frac{1}{2})r'')}\big)=O\big(\phis e^{-\alpha (R-r'')}\big)=O(\phis).
\]
To conclude the proof of~\eqref{itm:upp5} observe that for the second interval~\eqref{itm:upp1} gives
\[\int_{r''}^{R}(\gamma(r)-\phi(r))e^{-\alpha(R-r)}dr=O(\phis).
\]
\end{proof}



%and since $\phi\leq\pi/2$, it equals $(2\vee\tfrac{1}{\beta})\log \KR\AL{-}O(1)$\cmk{Maybe "of order" is redundant. I am not sure. Maybe "and thus equals ..."}\cml{changed}\AL{ which is $\Omega(1)$ if the constant $C>0$ in the statement of Proposition~\ref{generalschico} is large enough}. Observing that \AL{$\gamma$ is the maximum between two functions, a major role will be played by the intersecting point} $(r'',\gamma(r''))$ which satisfies
%\begin{equation}\label{eq:def:r2prime}\KA\phis+\phi(R)=\KR e^{-(\beta\wedge\frac12) r''}+\phi(r'')\end{equation}
%\AL{so in particular $r''=-\frac{\log\phis}{\beta\wedge\frac{1}{2}}\pm O(1)$.}\cml{added this to be used later}
%Now, an expression that will appear several times is $\gamma(r_0)-\phi(r_0)$, for which it will be convenient to use the lower bound
%\begin{equation}\label{eq:lowergamma}
%\gamma(r_0)-\phi(r_0)\;\geq\;\begin{cases}
%\KR e^{-(\beta\wedge \frac{1}{2})r_0}, &\text{ if }r'\leq r_0\leq r'',\\[2ex]\tfrac{1}{2}\KA \phis,&\text{ if }r''\leq r_0\leq R.
%\end{cases}
%\end{equation}
%The case $r'\leq r_0\leq r''$ follows directly from the definition of $\gamma$, while for the case $r''\leq r_0\leq R$ we have $\gamma(r_0)-\phi(r_0)\geq \gamma(r'')-\phi(r'')$ since the function $\gamma$ is independent of $r_0$ in this interval \dmc{I would say: independent of $r_0$. It is not really constant, depends also on $\ss$)}\cml{changed it} and from Part~\eqref{itm:phi2} of Lemma~\ref{lem:phi} the function $\phi(\cdot)$ is decreasing\cmk{We could refer here to the prelim section result where we prove this.}\cml{done}. Now,\cmk{The two $=$'s below should be $\geq$, right?}\cml{these are both equalities, the first one comes directly from the definition of $\gamma$ between $r'$ and $r''$, and the second one comes from the definition of $r''$}
%\[\gamma(r'')-\phi(r'')=\KR e^{-(\beta\wedge \frac{1}{2})r''}\geq\tfrac{1}{2}(\KR e^{-(\beta\wedge \frac{1}{2})r''}+\phi(r''))=\tfrac{1}{2}(\KA\phis+\phi(R))\geq \tfrac{1}{2}\KA\phis\]
%where in the first inequality we have used that $e^{-(\beta\wedge \frac{1}{2})r''}=\Omega(\phi(r''))$ and that $\KR\geq C$. %On a similar note we present the following proposition which will ease subsequent computations, and whose proof follows from a straightforward computation so we omit it.\dmc{check where we need it. But if so, needs at least an idea of proof}\cml{I think I will eliminate this. Pending}
%\begin{proposition}\label{prop:merged-indepIntg}Consider a function $F$ that depends on $x_0$ only through $\theta_0$, say $F(x_0):=f(\theta_0)$. Then there is $R_0>0$ and a constant $C$ depending on $\alpha$ and $\beta$ alone such that for $R\geq R_0$\cmk{Since $R_0$ does not show up in any rsult, we should write $R_0=\Omega(1)$.},
%\begin{equation}\label{eqn:merged-indepIntg}
%\int_{\overline{\mathcal{D}}^{(t)}} F(x_0)d\mu(x_0)
   %\leq Cn\int_{\phi(R)+\KA\phis}^{\infty}f(\theta_0)d\theta_0,
%\end{equation}
%and \dmc{This second inequality needs a bit of explanation, I think. If you don't want to give a proof, at least saying that all layers are important or some informal idea}\cmk{In all integrals below replace $\kappa$ by $\KA$.}
%\begin{equation}\label{eqn:merged-depIntg-a}
%\int_{\overline{\mathcal{D}}^{(t)}} F(x_0)e^{-\alpha r_0}d\mu(x_0)
%\leq Cne^{-\alpha R}\int_{\phi(R)+\kappa\phis}^{\infty}f(\theta_0)\log(\nnu^{1\wedge 2\beta}\theta_0)d\theta_0.
%\end{equation}
%Moreover, \dmc{Same here. If you don't want to provide a proof, at least some comment before the proposition, I'd suggest. For $\alpha=2\beta$ we have the previous only, right? So perhaps we could merge these last 3 inequalities and put the "Moreover" before the second?}
%\begin{equation}\label{eqn:merged-depIntg-b}
%\int_{\overline{\mathcal{D}}^{(t)}} F(x_0)e^{-2\beta r_0}d\mu(x_0)
%\leq \begin{cases}
%\displaystyle
%Cne^{-\alpha R}\int_{\phi(R)+\kappa\phis}^{\infty}f(\theta_0)\theta_0^{\frac{4\beta-2\alpha}{1\wedge 2\beta}}d\theta_0, & \text{if $\alpha < 2\beta$}, \\[12pt]
%\displaystyle
%O(ne^{-\alpha R})\int_{\kappa\phi^{(t)}}^{\infty}f(\theta_0)\log(\tfrac{1}{\kappa}\nnu^{2\beta}\theta_0)d\theta_0,
%& \text{if $\alpha=2\beta$,} \\[12pt]
%\displaystyle
%Cne^{-2\beta R}\int_{\phi(R)+\kappa\phis}^{\infty}f(\theta_0)d\theta_0,
%& \text{if $\alpha>2\beta$.}
%\end{cases}
%\end{equation}
%\end{proposition}
%\cml{made a few changes, specially on the exponent in one of the cases}

Following the strategy presented at the beginning of Section~\ref{sec:Upper}, for each $x_0\in\ndt$ with $\theta_0>0$ (the case $\theta_0<0$ is analogous) we define a box $\mathcal{B}(x_0)\subseteq \overline{B}_Q(R)$ where this time we set (see Figure~\ref{fig:mixto}(c) for an illustration of $\mathcal{B}(x_0)$)
\begin{equation}\label{def:hatthatr}
\hatt=\tfrac{2}{3}(\theta_0-\phi(r_0))\qquad\text{ and }\qquad \phi(\hatr)=\theta_0-\hatt.
\end{equation}
Since by Part~\eqref{itm:phi2} of Lemma~\ref{lem:phi} the function $\phi(\cdot)$ is decreasing, it can be easily checked that $x_0\in\mathcal{B}(x_0)\subseteq \overline{B}_Q(R)$ so in order to detect the target, a particle must first exit its respective box.
%\cml{Explanation of $\hatr$ pending}\dmc{leave out the comment then if nothing is added} 
In particular, by~\eqref{boxboundsNew} and the second bound in Proposition~\ref{prop:mainuppermixed}, we obtain
\begin{equation}\label{eq:mainupper1}\PP_{x_0}(T_{det}\leq \ss)\,\leq\,\PP_{x_0}(\trad\leq \ss)+\sqrt{\frac{2}{\pi}}\int_{0}^{\infty}\frac{\hatt}{\sigma^{3/2}}e^{-\frac{\hatt^2}{2\sigma}}\PP_{x_0}(\II{\ss}\geq\sigma)d\sigma.\end{equation}
It suffices thus to bound the right-hand side. We first address the term $\PP_{x_0}(\trad\leq \ss)$, which depends on the radial trajectory of the particle alone, and hence we can make use of the results obtained in Section~\ref{sec:radial}. 
\begin{proposition}\label{generalschicorad}
Under the conditions of Proposition~\ref{generalsgrande} we have:
\begin{itemize}
    \item If $\KA=C$, then
    $\displaystyle\int_{\ndt}\P_{x_0}(\trad\leq \ss)d\mu(x_0) 
=O(n\phis)$.
\item If $\KA\geq C$ and $\ss=\omega(1)$, then
\[
\sup_{x_0\in\ndt}\P_{x_0}(\trad\leq \ss) =
\begin{cases}
e^{-\Omega(\KA^2)},
& \text{ if $\alpha\geq2\beta$,} \\[2pt]
O(\KA^{-\alpha(\frac{1}{\beta}\vee 2)}),
& \text{ if $\alpha<2\beta$.} 
\end{cases}
\]
\end{itemize}
\end{proposition}
\begin{proof}
Throughout this proof, let $x_0\in\ndt$ be such that $\theta_0>0$ (the case $\theta_0<0$ can be dealt with analogously).
As defined in Part~\eqref{radial:itm:phi3} of Lemma~\ref{lemmaradial},  with $\auxy=r_0$, $\yabs_0=\hatr$ and $\auxY=R$, let
\[
G_{\hatr}(r_0)
    := \frac{g(r_0)}{g(\hatr)}, \qquad \text{where}\qquad g(r):=\log(\tanh(\tfrac12\alpha R)/\tanh(\tfrac12\alpha r))
\]
Using the same arguments as in the proof of Proposition~\ref{prop:rad-lowerBnd} in Section~\ref{sec:radial}, bounding the term $\P_{R}(T_{\hatr}\leq\ss)$ analogously to what was done in~\eqref{eqn:radial-upper-aux2}, we have
\begin{equation}\label{eq:bound1radmix}\PP_{x_0}(\trad\leq \ss)\;\leq\;\P_{r_0}(T_{\hatr}<T_R)+\P_{R}(T_{\hatr}\leq\ss) \; = \; G_{\hatr}(r_0)+O(\ss e^{-\alpha(R-\hatr)}).
\end{equation}
To bound from above the numerator of $G_{\hatr}(r_0)$, note that the largest possible value of $\hatr$ among points in $\ndt$ is obtained at $r_0=R$ and $\theta_0=\phi(R)+\KA\phis$ so it follows from the definition of $\hatr$, $\hatt$, $\phi(\cdot)$, and Part~\eqref{itm:phi1} in Fact~\ref{fact:uppermix}, that
\[\phi(\hatr)\ge\phi(R)+\tfrac{1}{3}(\theta_0-\phi(R))=\phi(R)+\tfrac{1}{3}\KA\phis=\Omega(\KA e^{-R/2}).\]
Also note that $\phi(\hatr)=O(e^{-\hatr/2})$, so taking $\KA$ larger than a fixed constant gives $R-\hatr=\Omega(1)$, and hence
\[\log\Big(\frac{\tanh(\alpha R/2)}{\tanh(\alpha \hatr/2)}\Big)\;=\;\log\Big(1+\frac{2-2e^{\alpha(\hatr-R)}}{(e^{-\alpha R}+1)(e^{\alpha \hatr}-1)}\Big)\,=\,\log\big(1+O(e^{-\alpha\hatr})\big)=O(e^{-\alpha\hatr}).\]
%\dmc{part (v) or which one? Isn't it $\KA$ instead of $\KR$ below? Otherwise I don't understand. Also, is it clear that $\hatr$ is so close to $R$ so that the approximation is good (I agree it is the case because for the threshold angle the value is close to the boundary, but it should be said before)? We obtain it a posteriori after doing this, but we should put it before. Can you put this before? Also, why is $1/2$ to the left and $1$ to the right, this depends on $\nu$, and the term $e^{-R}$ should be $e^{-R/2}$, since it is also multiplied by $n$, no?}\cmk{I don't get the identity below either.} that
%\[\tfrac{1}{2}e^{R/2}\phi(\hatr)=\tfrac13\KR n\phis+1\pm O(e^{-R})\]
%but from our assumption $\ss>c$ and the definition of $\phis$\cmk{You mean that by definition $\phis$ and said assumption we have $\phis=\Omega(e^{-\frac12 R})$? If so, say it explicitly}, the right-hand side is at least a constant larger than $1$. \cmk{I would replace the following phrase and the next displayed equation by "So, as shown in the proof of Fact 19, we have 
%$g(\hatr)=e^{-\alpha r_0}-O(e^{-\alpha R})=\Omega(e^{-\alpha r_0})$."} In particular, using again Part~\eqref{itm:phi4} of Lemma~\ref{lem:phi} we conclude that $R-\hatr=\Omega(1)$, and hence
%\[\frac{\tanh(\alpha R/2)}{\tanh(\alpha \hatr/2)}\;=\;1+\frac{2-2e^{\alpha(\hatr-R)}}{(e^{-\alpha R}+1)(e^{\alpha \hatr}-1)}\,=\,1+O(e^{-\alpha\hatr}).\]
From Part~\eqref{itm:phi2} in Fact~\ref{fact:uppermix} it follows that $r'=\Omega(\log\KR)=\Omega(1)$, and since $r_0\ge r'$ (because $x_0\in\ndt$) we can argue as in the proof of Fact~\ref{fct:radial-varphi2} that $g(r_0)=O(e^{-\alpha r_0})$, and hence combining with the previous bound we get $G_{\hatr}(r_0)=O(e^{-\alpha(r_0-\hatr)})$. %and hence it follows from Part~\eqref{itm:phi2} of Lemma~\ref{lem:phi} that $\hatr$ is \dm{bounded from below} by some positive constant\cmk{Just say $\widehat{r}_0=\Omega(1)$}.
%\cmk{I think the next phrase is unnecessary and also the following displayed equation. We could replace by "So, as argued in the proof of Fact 19, $g(r_0)=O(e^{-\alpha r_0})$. Hence, we get that $G_{\hatr}(r_0)=O(e^{-\alpha(r_0-\hatr)})$."}. Now, since $r_0\in\ndt$, it must satisfy $r_0>r'>1$, so we have $\cotanh(\frac12\alpha r_0)\leq 1+\frac{2e^{-\alpha r_0}}{1-e^{-\alpha r_0}}=1+O(e^{-\alpha r_0})$, and thus
%\[G_{\hatr}(r_0)=\frac{O(e^{-\alpha r_0})}{\log(1+O(e^{-\alpha\hatr}))}\;=\;O(e^{-\alpha(r_0-\hatr)}),\]
%where the constant appearing in the $O(\cdot)$ notation depends on $\alpha$ alone. 
Notice that both terms bounding $\PP_{x_0}(\trad\leq \ss)$ in~\eqref{eq:bound1radmix} involve a factor $e^{\alpha\hatr}$, which by definition of $\hatr$ and Part~\eqref{itm:phi4} of Lemma~\ref{lem:phi} is $O((\theta_0-\hatt)^{-2\alpha})$, giving
\begin{equation}\label{eq:mixradialuppermain}\PP_{x_0}(\trad\leq \ss)\;=\;O\big((\theta_0-\hatt)^{-2\alpha}e^{-\alpha r_0}+\ss(\theta_0-\hatt)^{-2\alpha}e^{-\alpha R}\big).\end{equation}
To obtain a uniform upper bound for $\PP_{x_0}(\trad\leq \ss)$ on $\ndt$, observe that for any fixed $r_0$, since $x_0\in\ndt$, we have $\theta_0\ge\gamma(r_0)$, where $\gamma$ was defined at the beginning of this section, giving
\begin{equation}\label{eq:diffangle}
\theta_0-\hatt=\tfrac13\theta_0-\tfrac23\phi(r_0)\ge\tfrac13\gamma(r_0)+\tfrac23\phi(r_0)\geq \tfrac13\KR e^{-(\beta\wedge\frac12) r_0}+\phi(r_0)\geq\tfrac13\KR e^{-(\beta\wedge\frac12) r_0}\end{equation}
and hence $(\theta_0-\hatt)^{-2\alpha}e^{-\alpha r_0}=O((\KR^{2}e^{(1-2(\beta\wedge\frac12))r_0})^{-\alpha})$.
%\cml{reshaped this a bit, there was a typo before}
%$\theta_0-\hatt=\frac{1}{3}\gamma(r_0)+\frac{2}{3}\phi(r_0)$. Since $\gamma(r_0)\geq\phi(r_0)+\KR e^{-(\beta\wedge\frac12) r_0}$ we have $\frac{1}{3}\gamma(r_0)+\frac{2}{3}\phi(r_0)\geq\tfrac13\KR e^{-(\beta\wedge\frac12) r_0}$ \dmc{true. In fact room to spare here, another $\phi(r_0)/3$ on the rhs can be added. Maybe put on the left hand side that this is also $\theta_0-\hatt > 0$ implies that $\theta_0-\hatt =\frac{1}{3}\gamma(r_0)+\frac{2}{3}\phi(r_0)
%= \frac{1}{3}\gamma(r_0)+\frac{2}{3}\theta_0
%\ge \frac{1}{3}\gamma(r_0)+\frac{2}{3}\hatt$ in an align, since here and below we use the lower bound for $\theta_0-\hatt$ as well}\cmk{You can even get $\geg\frac13\gamma(r_0)+2\hatt$, right?}, so that 
%\[(\theta_0-\hatt)^{-2\alpha}e^{-\alpha r_0}\leq(\tfrac13\KR)^{-2\alpha}e^{\alpha(2\beta-1\wedge 0)r_0}\]
For the case $\beta\geq\frac{1}{2}$ this bound is $O(\KR^{-2\alpha})$, while for the case $\beta<\frac{1}{2}$ the exponential term is equal to $e^{(1-2\beta)r_0}$ which is at least $e^{(1-2\beta)r'}$ since as already observed $r_0\ge r'$. By Part~\eqref{itm:upp2} in Fact~\ref{fact:uppermix} we have $r'=\frac{1}{\beta}\log(\KR)-O(1)$. Thus,
\[\KR^{-2\alpha}e^{-\alpha(1-2\beta)r_0}\leq \KR^{-2\alpha}e^{-\alpha(1-2\beta)r'}=O\big(\KR^{-2\alpha}\KR^{-\frac{\alpha}{\beta}(1-2\beta)}\big)=O\big(\KR^{-\frac{\alpha}{\beta}}\big)\]
so putting both cases together we obtain a bound of the form $O(\KR^{-\alpha/(\beta\wedge\frac12)})$. 
Next we address the term $\ss(\theta_0-\hatt)^{-2\alpha}e^{-\alpha R}$ appearing in~\eqref{eq:mixradialuppermain}. For $r'\le r_0\le r''$, by~\eqref{eq:diffangle}, we have
\[\ss(\theta_0-\hatt)^{-2\alpha}e^{-\alpha R}=O\big(\ss\KR^{-2\alpha}e^{2\alpha(\beta\wedge \frac12)r_0}e^{-\alpha R}\big)\]
which is an increasing function of $r_0$ and hence within $[r',r'']$ the bound is maximized at $r''$. Thus, it is enough to deal with points with radial component $r_0$ in $[r'',R]$. Now, for said points a similar argument to the one in~\eqref{eq:diffangle} gives $\theta_0-\hatt\geq\tfrac{1}{3}\KA \phis$ and hence
\[\ss(\theta_0-\hatt)^{-2\alpha}e^{-\alpha R}=O\big(\ss\KA^{-2\alpha}\big(e^{\frac{R}{2}}\phis\big)^{-2\alpha}\big).\]
The analysis of this term depends on $\alpha$ and $\beta$, and we begin addressing the case $\beta<\frac{1}{2}$ and $\alpha<2\beta$ since it is the most delicate. Notice that in this case $\phis=e^{-\beta R}\ss^{\frac{\beta}{\alpha}}$ so in particular $\ss(e^{\frac{R}{2}}\phis)^{-2\alpha}=(\ss e^{-\alpha R})^{1-2\beta}$ and hence the upper bound is an increasing function of $\ss$. Now, in order for $\ndt$ to be non-empty we need $\phi(R)+\KA\phis\leq\pi$ we deduce that $\ss e^{-\alpha R}=O(\KA^{-\frac{\alpha}{\beta}})$, which gives 
\[
\ss\KA^{-2\alpha}(e^{\frac{R}{2}}\phis)^{-2\alpha}=O\big(\KA^{-2\alpha}\big(\ss e^{-\alpha R}\big)^{1-2\beta}\big)=O\big(\KA^{-2\alpha}\KA^{-\frac{\alpha}{\beta}(1-2\beta)}\big)=O(\KA^{-\frac{\alpha}{\beta}}).\]
The remaining cases are easier: If $\beta\geq\frac{1}{2}$, then $e^{\frac{R}{2}}\phis=\ss^{\frac{1}{2\alpha}}$ so the term $\ss\KA^{-2\alpha}(e^{\frac{R}{2}}\phis)^{-2\alpha}$ is $O(\KA^{-2\alpha})$, while for the cases $\alpha=2\beta$ and $\alpha>2\beta$ it can be easily checked that since $\ss= O(e^{2\beta R})$ and $\ss= O(e^{2\beta R}/\log(e^{2\beta R}))$ respectively, we obtain $\ss(e^{\frac{R}{2}}\phis)^{-2\alpha}=o(1)$. Since $\KR=\KA$ whenever $\alpha<2\beta$, putting together the bounds for both terms in~\eqref{eq:mixradialuppermain} we finally obtain the sought after bound:
\[\PP_{x_0}(\trad\leq \ss)\;=\;O(\KR^{-\alpha/(\beta\wedge\frac12)})\;=\;\begin{cases}
e^{-\Omega(\KA^2)},
& \text{ if $\alpha\geq2\beta$,} \\[2pt]
O(\KA^{-\alpha/(\beta\wedge\frac12)}),
& \text{ if $\alpha<2\beta$.}
\end{cases}\]

Next, we show that for $\KA=C$ we have $\int_{\ndt}\PP_{x_0}(\trad\leq \ss)d\mu(x_0)=O(n\phis)$ by integrating both terms in~\eqref{eq:mixradialuppermain} over $\ndt$.
For the first one we use that $\theta_0-\hatt\geq\frac{1}{3}\theta_0$ to obtain 
\[
\int_{\ndt}(\theta_0-\hatt)^{-2\alpha}e^{-\alpha r_0}d\mu(x_0)= O(ne^{-\alpha R})\int_{r'}^R\int_{\gamma(r_0)}^{\infty}\theta_0^{-2\alpha}d\theta_0dr_0 =O(ne^{-\alpha R})\int_{r'}^{R}\frac{1}{\gamma(r_0)^{2\alpha-1}}dr_0.
\]
Splitting the range of integration of the last integral into $[r',r'']$ and $[r'',R]$ we obtain
\begin{align*}
\int_{\ndt}(\theta_0-\hatt)^{-2\alpha}e^{-\alpha r_0}d\mu(x_0)
& = O\big(ne^{-\alpha R}\big(e^{(2\alpha-1)(\beta\wedge\frac{1}{2})r''}+(R-r'')(\phis)^{-(2\alpha-1)}\big)\big) \\[2pt]
& = O\big(ne^{-\alpha R}(\phis)^{-(2\alpha-1)}\log(e^{(\beta\wedge\frac12)R}\phis)\big)
\end{align*}
where the last equality is by definition of $r''$ and since $e^{(\beta\wedge\frac{1}{2})R}\phis=\Omega(1)$ implies that $R-r''=\Omega(\log(e^{(\beta\wedge\frac{1}{2})R}\phis))$. To address this last bound suppose first that $\beta<\frac{1}{2}$ and observe that since $\phis=\Omega(e^{-\beta R})\cap O(1)$ we have
$e^{-\alpha R}(\phis)^{-2\alpha}\log(e^{(\beta\wedge\frac12)R}\phis)=O\big(Re^{-2\alpha(\frac{1}{2}-\beta)R}\big)=O(1)$,
while for $\beta\geq\frac{1}{2}$ we have $\alpha<2\beta$, hence $\phis=e^{-\frac{R}{2}}\ss^{\frac{1}{2\alpha}}$ so $e^{-\alpha R}(\phis)^{-2\alpha}\log(e^{(\beta\wedge\frac12)R}\phis)=O\left(\ss^{-1}\log\ss\right)=O(1)$ (since $\ss=\Omega(1)$) and we conclude that in any case scenario
\[\int_{\ndt}(\theta_0-\hatt)^{-2\alpha}e^{-\alpha r_0}d\mu(x_0)=O(n\phis).\]
For the second term in~\eqref{eq:mixradialuppermain} we use $\theta_0-\hatt\geq\frac{1}{3}\theta_0$ again, together with $\gamma(r_0)\geq C\phis$ to obtain 
\begin{align*}
\int_{\ndt}\ss (\theta_0-\hatt)^{-2\alpha}e^{-\alpha R}d\mu(x_0)&= O(\ss ne^{-\alpha R})\int_{r'}^R\int_{C\phis}^{\infty}\theta_0^{-2\alpha}d\theta_0e^{-\alpha(R-r_0)}dr_0
\\[2pt]&= O\big(\ss ne^{-\alpha R}(\phis)^{-(2\alpha-1)}\big),
\end{align*}
and it can be checked directly from the definition of $\phis$ and our assumption $\ss=\Omega(1)$ that this last expression is also $O(n\phis)$.
\end{proof}

\medskip

The previous proposition gave the uniform bound for the first term appearing in~\eqref{eq:mainupper1}, as well as a bound for its integral over $\ndt$. The following proposition allows us to bound from above the second term in~\eqref{eq:mainupper1} with the use of Proposition~\ref{prop:merged-varianza} to handle the function $\PP_{x_0}(\II{\ss}\geq\sigma)$. Recall that in order to apply said proposition we require $\sigma$ to be larger than $\sigma_0$ with
\begin{equation}\label{def:sigma0}
\sigma_0 := \begin{cases}
\auxl'e^{-2\beta R}(v_0\ss)^{1\vee\frac{2\beta}{\alpha}}, &
\text{if $\alpha \neq 2\beta$,} \\[2pt]
\auxl'e^{-2\beta R}v_0\ss\log(v_0\ss), &
\text{if $\alpha=2\beta$,}
\end{cases}
\end{equation}
where $\auxl'$ is a large constant that depends on $\alpha$ and $\beta$, and where $v_0$ is some function of $x_0$ for which we only ask to satisfy $v_0>\frac{4}{c}$ for $0<c< 1$ being a constant lower bound for $\ss$ (which exists since $\ss=\Omega(1)$).

\begin{proposition}\label{prop:splitterms}
Let $v_0:=v_0(x_0)$ be a function satisfying $v_0>\frac{4}{c}$, and let $\sigma_0$ and $\hatt$ be as in~\eqref{def:hatthatr} and~\eqref{def:sigma0}, respectively. Assume that $\KA\geq C$ where $C>0$ is as in the statement of Proposition~\ref{generalsgrande} and $\hatt^2=\Omega(\sigma_0)$, then
\begin{equation}\label{eq:mainterms}
\int_{0}^{\infty}\tfrac{\hatt}{\sigma^{3/2}}e^{-\frac{\hatt^2}{2\sigma}}\PP_{x_0}(\II{\ss}\geq\sigma)d\sigma=O\big(e^{-\frac{\hatt^2}{2\sigma_0}}+e^{-\frac{1}{16}v_0^2\ss}+\hatt^{-\frac{\alpha}{\beta}}e^{-\alpha r_0}+v_0\ss e^{-\alpha R}+\mathfrak{t}_5\big),
\end{equation}
where
\[\mathfrak{t}_5=\begin{cases}(v_0\ss)^{1\vee\frac{\alpha}{4\beta}}e^{-\alpha R}\hatt^{-\frac{\alpha}{\beta}}, &\text{ if $\alpha\neq2\beta$,} \\[2pt]
\int_{0}^{1}\sqrt{\tfrac{w\hatt^2}{\sigma_0}}e^{-\frac{w\hatt^2}{2\sigma_0}}\left(\auxl'\log(v_0\ss)\right)^{w-1}dw, &\text{ if $\alpha=2\beta$}.\end{cases}\]
\end{proposition}


%\AL{ It follows from the definition of $\phis$ and our assumption on $v_0$ that taking the constant $C$ appearing in the statement of Proposition~\ref{generalschico} sufficiently large, we get $\sigma_0\leq (C\phis)^{2\vee4\beta}\leq\overline{C}\hatt^{2}$ for some $\overline{C}$ large, where the second inequality follows from Part~\ref{itm:phi4} in Fact~\ref{fact:uppermix}. We will use this fact repeatedly throughout the rest of our proof.}
\begin{proof}
Fix any given $x_0\in\ndt$ and split $\int_{0}^{\infty}\frac{\hatt}{\sigma^{3/2}}e^{-\frac{\hatt^2}{2\sigma}}\PP_{x_0}(\II{\ss}\geq\sigma)d\sigma$ into
\begin{equation}\label{eq:splitted}\int_{0}^{\sigma_0}\frac{\hatt}{\sigma^{3/2}}e^{-\frac{\hatt^2}{2\sigma}}\PP_{x_0}\big(\II{\ss}\geq\sigma\big)d\sigma+\int_{\sigma_0}^{\infty}\frac{\hatt}{\sigma^{3/2}}e^{-\frac{\hatt^2}{2\sigma}}\PP_{x_0}(\II{\ss}\geq\sigma)d\sigma.\end{equation}
For the first integral, we can bound the probability inside it by $1$, which using that $\hatt^2/\sigma_0=\Omega(1)$
and the change of variables $w:=\hatt^2/\sigma$ gives a bound
\[\int_{0}^{\sigma_0}\frac{\hatt}{\sigma^{3/2}}e^{-\frac{\hatt^2}{2\sigma}}d\sigma\,=\,\int_{\frac{\hatt^2}{\sigma_0}}^\infty\frac{1}{\sqrt{w}}e^{-\frac{w}{2}}dw\,=\,O\big(e^{-\frac{\hatt^2}{2\sigma_0}}\big)\]
 For the second integral in~\eqref{eq:splitted}, we use~\eqref{eq:division} to bound the probability within   together with Proposition~\ref{prop:merged-varianza} (since $\sigma>\sigma_0$) and obtain
\begin{equation}\label{eq:boundPI}\PP_{x_0}(\II{\ss}\geq\sigma)\,=\,O\big(e^{-\frac{1}{16}v_0^2\ss}+e^{-\alpha r_0}+\sigma^{-\frac{\alpha}{2\beta}} e^{-\alpha r_0}+v_0\ss e^{-\alpha R}+
\big((v_0\ss)^{1\vee\frac{\alpha}{4\beta}}\sigma^{-\frac{\alpha}{2\beta}}e^{-\alpha R}\big)^{1-\mathfrak{e}}\big)\end{equation}
where $\mathfrak{e}:=\frac{1}{\sigma e^{2\beta R}}\auxl'v_0\ss\log (v_0\ss)=\frac{\sigma_0}{\sigma}$ if $\alpha=2\beta$, and $\mathfrak{e}=0$ otherwise. Grouping the first, second and fourth terms in~\eqref{eq:boundPI}, the assumption $\hatt^2/\sigma_0= \Omega(1)$ gives
\[\int_{\sigma_0}^{\infty}\frac{\hatt}{\sigma^{3/2}}e^{-\frac{\hatt^2}{2\sigma}}\big(e^{-\frac{1}{16}v_0^2\ss}+e^{-\alpha r_0}+v_0\ss e^{-\alpha R}\big)d\sigma=O\big(e^{-\frac{1}{16}v_0^2\ss}+e^{-\alpha r_0}+v_0\ss e^{-\alpha R}\big)\]
since the terms are independent of $\sigma$ and $\int_{\sigma_0}^{\infty}\frac{\hatt}{\sigma^{3/2}}e^{-\frac{\hatt^2}{2\sigma}}d\sigma=\int_0^{\hatt^2/\sigma_0}\frac{1}{\sqrt{w}}e^{-\frac{w}{2}}dw=O(1)$. For the term $\sigma^{-\frac{\alpha}{2\beta}} e^{-\alpha r_0}$ analogous computations give 
\[\int_{\sigma_0}^\infty\frac{\hatt}{\sigma^{3/2}}e^{-\frac{\hatt^2}{2\sigma}}\sigma^{-\frac{\alpha}{2\beta}} e^{-\alpha r_0}d\sigma\,=\,e^{-\alpha r_0}\hatt^{-\frac{\alpha}{\beta}}\int_0^{\frac{\hatt^2}{\sigma_0}} w^{\frac{\alpha}{2\beta}-\frac{1}{2}}e^{-\frac{w}{2}}dw\,=\,O\big(e^{-\alpha r_0}\hatt^{-\frac{\alpha}{\beta}}\big).\]
The final term in~\eqref{eq:boundPI} is a bit more delicate, and must be treated differently according to whether $\alpha= 2\beta$ or $\alpha\neq 2\beta$. In the latter case we can repeat the computations used in the previous term, giving
\[\int_{\sigma_0}^{\infty}\frac{\hatt}{\sigma^{3/2}}e^{-\frac{\hatt^2}{2\sigma}}(v_0\ss)^{1\vee\frac{\alpha}{4\beta}}\sigma^{-\frac{\alpha}{2\beta}}e^{-\alpha R}d\sigma=O\big((v_0\ss)^{1\vee\frac{\alpha}{4\beta}}e^{-\alpha R}\hatt^{-\frac{\alpha}{\beta}}\big),\]
whereas if $\alpha=2\beta$, we use the change of variables $w:=\frac{\sigma_0}{\sigma}$ and the fact that $v_0\ss\sigma^{-\frac{\alpha}{2\beta}}e^{-\alpha R}
= \sigma_0/(\sigma\auxl'\log(v_0\ss))=w/(\auxl'\log(v_0\ss))$ so that
\begin{align*}\int_{\sigma_0}^{\infty}\frac{\hatt}{\sigma^{3/2}}e^{-\frac{\hatt^2}{2\sigma}}\big((v_0\ss)^{1\vee\frac{\alpha}{4\beta}}\sigma^{-\frac{\alpha}{2\beta}}e^{-\alpha R}\big)^{1-\frac{\sigma_0}{\sigma}}d\sigma
&=\int_{0}^{1}\frac{\hatt}{\sqrt{\sigma_0 w}}e^{-\frac{w\hatt^2}{2\sigma_0}}\Big(\frac{w}{\auxl'\log(v_0\ss)}\Big)^{1-w}dw\\[2pt]
&=O\Big(\int_{0}^{1}\sqrt{\tfrac{w\hatt^2}{\sigma_0}}e^{-\frac{w\hatt^2}{2\sigma_0}}\Big(\auxl'\log(v_0\ss)\Big)^{w-1}dw\Big).\end{align*}
%\[\mathfrak{f}(\hatt,\sigma_0):=\int_{\sigma_0}^{\infty}\tfrac{\hatt^2}{2\sigma^2}e^{-\frac{\hatt^2}{2\sigma}}\sigma^{-\frac{\alpha}{2\beta}}d\sigma\;=\;(\tfrac{\hatt}{2})^{-\frac{\alpha}{\beta}}\int_0^{\frac{\hatt^2}{2\sigma_0}}e^{-x}x^{\frac{\alpha}{2\beta}}dx\;=\;\begin{cases}
%\Theta(\hatt^2/\sigma_0^{\frac{\alpha}{2\beta}+1}),&\text{ if }\frac{\hatt^2}{\sigma_0}=O(1),\\[2ex]\Theta(\hatt^{-\frac{\alpha}{\beta}}),&\text{ if }\frac{\hatt^2}{\sigma_0}=\Omega(1).
%\end{cases}\]
The result then follows by adding all the bounds and noticing that $e^{-\alpha r_0}=O(\hatt^{-\frac{\alpha}{\beta}}e^{-\alpha r_0})$.
\end{proof}

We are now ready to prove the main result of this section.

\begin{proof}[Proof of Proposition~\ref{generalsgrande}]
Using~\eqref{eq:mainupper1} and Proposition~\ref{generalschicorad} it will be enough to obtain a uniform bound for $\int_{0}^{\infty}\frac{\hatt}{\sigma^{3/2}}e^{-\frac{\hatt^2}{2\sigma}}\PP_{x_0}(\II{\ss}\geq\sigma)d\sigma$ on $\ndt$ as well as an upper bound for the integral of this term over this set. We will address the uniform bounds first, since calculations are easier, and then turn to the upper bound for the integrals over $\ndt$, whose analysis is similar.

%from above each of these terms separately. In doing so, our choice of $v_0$ will depend on whether we are trying to obtain uniform upper bounds over all elements of $\ndt$ or an upper bound for the integral over $\ndt$. We will address the uniform bounds first, since calculations are easier, and then turn to the upper bound for the integrals over $\ndt$, whose analysis follows the same direction.

\medskip

\noindent\textit{Uniform upper bound:} Our goal is to show that under the hypothesis $\ss=\omega(1)$, 
\begin{equation}\label{eq:targetuniform}
\sup_{x_0\in\ndt}\int_{0}^{\infty}\tfrac{\hatt}{\sigma^{3/2}}e^{-\frac{\hatt^2}{2\sigma}}\PP_{x_0}(\II{\ss}\geq\sigma)d\sigma =
\begin{cases}
e^{-\Omega(\KA^2)},
& \text{ if $\alpha\geq2\beta$,} \\[2pt]
O(\KA^{-\alpha/(\beta\wedge\frac12)}),
& \text{ if $\alpha<2\beta$}. 
\end{cases}
\end{equation}
Throughout this analysis, we take $v_0$ constant and equal to $\frac{4}{c}$. With this choice of $v_0$ we deduce from Part~\eqref{itm:upp4} in Fact~\ref{fact:uppermix} that $\sigma_0=\Theta((\phis)^{2\vee4\beta})=O((\gamma(r_0)-\phi(r_0))^2)=O(\hatt^2)$ and hence we have~\eqref{eq:mainterms} as in Proposition~\ref{prop:splitterms}, so we address each term appearing in the bound as follows:

We assume throughout the uniform upper bound proof that $x_0=(r_0,\theta_0)\in\ndt$, and hence this set is non empty so in particular we must have $\KA\phis+\phi(R)\leq\pi$.
\begin{itemize}\setlength\itemsep{1ex}
    \item For the term $e^{-\frac{\hatt^2}{2\sigma_0}}$ it follows from the definition of $\hatt$ that it is equal to $e^{-\frac{2}{9\sigma_0}(|\theta_0|-\phi(r_0))^2}$ and since $|\theta_0|\ge \gamma(r_0)$ by Part~\eqref{itm:upp4} in Fact~\ref{fact:uppermix} we deduce $(|\theta_0|-\phi(r_0))^2=\Omega(\KA^2(\phis)^2)$.
    Recalling that $\sigma_0=\Theta((\phis)^{2\vee4\beta})$ the term $e^{-\frac{\hatt^2}{2\sigma_0}}$ equals $e^{-\Omega(\KA^2)}$, which is at most of the same order than the one claimed in~\eqref{eq:targetuniform}.
    \item The term $e^{-\frac{1}{16}v_0^2\ss}$ appearing in~\eqref{eq:mainterms}  does not depend on $x_0$ and since we are assuming $\ss=\omega(1)$, it becomes $o(1)$, so it is negligible.
    \item Now, we consider the term $\hatt^{-\frac{\alpha}{\beta}}e^{-\alpha r_0}$. By definition $\hatt=\Theta(|\theta_0|-\phi(r_0))$.
    Since $|\theta_0|\ge\gamma(r_0)\ge\phi(r_0)$ for $x_0\in\ndt$, by 
    Part~\eqref{itm:upp4} in Fact~\ref{fact:uppermix}, we have
%    Using the definition of $\hatt$ we have \AL{that $\hatt^{-\frac{\alpha}{\beta}}e^{-\alpha r_0}$ is}\cml{the equation was too big, removed the $\hatt^{-\frac{\alpha}{\beta}}e^{-\alpha r_0}$ you had added}
    \[
    \big((|\theta_0|-\phi(r_0))^{-\frac{\alpha}{\beta}}e^{-\alpha r_0}=O\big(\KR^{-\frac{\alpha}{\beta}}e^{\alpha((1\wedge\frac{1}{2\beta})-1)r_0}\big),\]
    If $\beta\leq\frac{1}{2}$, this bound is $O(\KR^{-\frac{\alpha}{\beta}})$ independently of $r_0$, whilst if $\beta>\frac{1}{2}$, using that $r_0\ge r'$, the bound is $O(\KR^{-\frac{\alpha}{\beta}}/e^{\frac{\alpha}{2\beta}(2\beta-1)r_0})=O(\KR^{-\frac{\alpha}{\beta}}/e^{\frac{\alpha}{2\beta}(2\beta-1)r'})$. Recalling that, by Part~\eqref{itm:upp2} in Fact~\ref{fact:uppermix}, we know that $r'=2\log\KR-O(1)$, replacing this value in the previous bound we obtain a term of order $\KR^{-2\alpha}$. Summarizing, we have shown that $\hatt^{-\frac{\alpha}{\beta}}e^{-\alpha r_0}=O(\KR^{-\alpha(2\vee\frac{1}{\beta})})$ and the result then follows by our choice of $\KR$.
    \item For the term $v_0\ss e^{-\alpha R}$ we observe that it is independent of $x_0$, and under the assumptions $\ss=O(e^{\alpha R}/R)$ if $\alpha=2\beta$ and $\ss=O(e^{2\beta R})$ if $\alpha>2\beta$ in the statement of Proposition~\ref{prop:mainuppermixed} we obtain that $\ss e^{-\alpha R}=o(1)$ and hence the term is negligible. In the case $\alpha<2\beta$, since $\KA\phis+\phi(R)\leq\pi$ we obtain $\ss e^{-\alpha R}=O(\KA^{-\alpha/(\beta\wedge\frac12)})$ by definition of $\phis$.
    \item To address the term $\mathfrak{t}_5$ we first treat the case $\alpha\neq2\beta$. Using the definition of $\hatt$ and the fact that $\theta_0\geq\gamma(r_0)\ge \phi(r_0)$ this term is of order 
    \[\ss^{1\vee\frac{\alpha}{4\beta}}\hatt^{-\frac{\alpha}{\beta}}e^{-\alpha R}=O\big(\ss^{1\vee\frac{\alpha}{4\beta}}(\gamma(r_0)-\phi(r_0))^{-\frac{\alpha}{\beta}}e^{-\alpha R}\big)\]
    and using Part~\eqref{itm:upp4} in Fact~\ref{fact:uppermix} we deduce%, for points with $r'\leq r_0\leq r''$ the right-hand term is of order $\ss^{1\vee\frac{\alpha}{4\beta}}\KR^{-\frac{\alpha}{\beta}}e^{\frac{\alpha}{\beta}(\beta\wedge\frac12)r_0}e^{-\alpha R}$ which is increasing in $r_0$ and hence it is maximized at $r''$, and so we need only to address the case $r''\leq r_0\leq R$. In this range, using again Part~\eqref{itm:upp4} in Fact~\ref{fact:uppermix} we get 
    \begin{equation}\label{eq:boundforlater}\ss^{1\vee\frac{\alpha}{4\beta}}\hatt^{-\frac{\alpha}{\beta}}e^{-\alpha R}=O\big(\ss^{1\vee\frac{\alpha}{4\beta}}(\KA\phis)^{-\frac{\alpha}{\beta}}e^{-\alpha R}\big)=O((\KA\ss^{-(\frac{\beta}{\alpha}\vee\frac14)}e^{\beta R}\phis)^{-\frac{\alpha}{\beta}}).\end{equation}    From the definition of $\phis$ we have
    \[
\ss^{-(\frac{\beta}{\alpha}\vee\frac{1}{4})}e^{\beta R}\phis =
\begin{cases}
(e^{\frac{R}{2} }\ss^{-\frac{1}{2\alpha}})^{0\vee (2\beta-1)},
& \text{ if $\alpha<2\beta$,}\\[2pt]
%\sqrt{\log \ss},
%& \text{ if $\alpha=2\beta$,} \\[2pt]
\ss^{(\frac12-\frac{\beta}{\alpha})\vee\frac{1}{4}},
& \text{ if $\alpha>2\beta$,}
\end{cases}
\]
where we directly observe that if $\alpha>2\beta$ this expression is $\omega(1)$ (since $\ss=\omega(1)$), and hence the upper bound is $o(1)$ so in particular it has the form $e^{-\Omega(\KA^2)}$ as desired. For the case $\alpha<2\beta$ we distinguish between the cases $\beta\leq\frac{1}{2}$ and $\beta>\frac{1}{2}$: In the former we directly obtain that $\ss^{1\vee\frac{\alpha}{4\beta}}(\KA\phis)^{-\frac{\alpha}{\beta}}e^{-\alpha R}=O(\KA^{-\frac{\alpha}{\beta}})$, whereas if $\beta>\frac12$, since $\phi(R)+\KA\phis\leq\pi$ and by definition of $\phis$, we have
$\ss^{-(\frac{\beta}{\alpha}\vee\frac14)}e^{\beta R}\phis=(1/\phis)^{2\beta-1}=\Omega(\KA^{-(2\beta-1)})$ and obtain an upper bound of $O\big(\KA^{-\frac{\alpha}{\beta}}\KA^{-\frac{\alpha}{\beta}(2\beta-1)}\big)=O(\KA^{-2\alpha})$. 

Assume now that $\alpha=2\beta$ so that $\mathfrak{t}_5=\int_{0}^{1}\sqrt{\tfrac{w\hatt^2}{\sigma_0}}e^{-\frac{w\hatt^2}{2\sigma_0}}\left(\auxl'\log(v_0\ss)\right)^{w-1}dw$ and notice that since the function $x\to xe^{-x^2}$ is $O(1)$ on $\RR^+$, and using that $\ss=\omega(1)$ we obtain
\[\mathfrak{t}_5=O\Big(\int_{0}^{1}(\auxl'\log(v_0\ss))^{w-1}dw\Big)=o(1)\]
and hence the term is negligible in this case.
\end{itemize}

\medskip

\noindent\textit{Integral upper bound:} Our goal is to show that under the hypothesis $\KA= C$ for $C$ large and $\ss=\Omega(1)$,
\[\int_{\ndt}\int_0^\infty\tfrac{\hatt}{\sigma^{3/2}}e^{-\frac{\hatt^2}{2\sigma}}\PP_{x_0}\big(\II{\ss}\geq\sigma\big)d\sigma dx_0 = O(n\phis).\]
In contrast to the choice in the uniform upper bound analysis, we will now choose 
\[v_0(x_0)\;:=\;\frac{4}{c}\Big(\frac{|\theta_0|-\phi(r_0)}{\gamma(r_0)-\phi(r_0)}\Big)^{\varepsilon}\]
for some fixed $\varepsilon>0$ satisfying $\varepsilon<(2\alpha-1)(1\wedge\frac{\alpha}{2\beta})$ (this is possible since $\alpha>\frac{1}{2}$) and where $0<c<1$ is a lower bound for $\ss$. It will be convenient to define $\varepsilon'=\varepsilon/(1\wedge\frac{\alpha}{2\beta})< 1$ since it will appear many times in subsequent computations. %\cmk{I think it is enough if you ask for $\varepsilon<2\vee\frac{\alpha}{\beta}$}\cml{will check this, there will be another condition that must be satisfied by $\varepsilon$} 
In order to apply Proposition~\ref{prop:splitterms} we need to show that $\hatt^2=\Omega(\sigma_0)$, which is less straightforward than the uniform bound case since $\sigma_0$ is also increasing with $\theta_0$. In the case $\alpha\neq2\beta$, observe that $|\theta_0|-\phi(r_0)=\Omega(v_0^{1/\varepsilon}(\gamma(r_0)-\phi(r_0)))$ while at the same time $\gamma(r_0)-\phi(r_0)=\Omega(\phis)=\Omega(e^{-\beta R}\ss^{\frac{1}{2}\vee\frac{\beta}{\alpha}})=\Omega(v_0^{-\frac{\varepsilon'}{2\varepsilon}}\sqrt{\sigma_0})$. We conclude that
\begin{equation}\label{eq:mixfracneq}
\frac{\hatt^2}{\sigma_0} = \frac{4}{9\sigma_0}(|\theta_0|-\phi(r_0))^2=\Omega(v_0^{\frac{2-\varepsilon'}{\varepsilon}}),
\end{equation}
which is $\Omega(1)$ since $v_0=\Omega(1)$ and $\varepsilon'<2$. Analogously, if $\alpha=2\beta$ we still have $|\theta_0|-\phi(r_0)=\Omega(v_0^{1/\varepsilon}(\gamma(r_0)-\phi(r_0)))$ whereas this time $\gamma(r_0)-\phi(r_0)=\Omega(\sqrt{\frac{\sigma_0\log\ss}{v_0\log(v_0\ss)}})$ so that 
\begin{equation}\label{eq:mixfraceq}\frac{\hatt^2}{\sigma_0}= \frac{4}{9\sigma_0}(|\theta_0|-\phi(r_0))^2=\Omega(v_0^{\frac{2-\varepsilon}{\varepsilon}}\tfrac{\log\ss}{\log(v_0\ss)}),\end{equation}
which is again $\Omega(1)$ since both $\ss=\Omega(1)$ and $v_0=\Omega(1)$. We have proved that in either case $\hatt^2=\Omega(\sigma_0)$. As a result we have~\eqref{eq:mainterms} where we address each term appearing in the upper bound as follows:

\medskip
\begin{itemize}\setlength\itemsep{1ex}
    \item 
    For the term $e^{-\frac{\hatt^2}{2\sigma_0}}$ assume first that $\alpha\neq2\beta$ and use \eqref{eq:mixfracneq} to obtain %recall that by definition $\hatt=\frac{4}{9}(|\theta_0|-\phi(r_0))^2$ so that
\[\int_{\ndt}\exp\Big({-}\frac{\hatt^2}{2\sigma_0}\Big)d\mu(x_0)=n\int_{r'}^R\int_{\gamma(r_0)}^\infty \exp\Big({-}\Omega\big(v_0^{\frac{2-\varepsilon'}{\varepsilon}}(\theta_0)\big)\Big)d\theta_0 e^{-\alpha(R-r_0)}dr_0,\]
so using the change of variable $w:=\frac{\theta_0-\phi(r_0)}{\gamma(r_0)-\phi(r_0)}$ we obtain 
\[\int_{\gamma(r_0)}^\infty \exp\Big({-}\Omega\big(v_0^{\frac{2-\varepsilon'}{\varepsilon}}(\theta_0)\big)\Big)d\theta_0=(\gamma(r_0)-\phi(r_0))\int_{1}^\infty e^{-\Omega(w^{2-\varepsilon'})}dw=O(\gamma(r_0)-\phi(r_0)),\]
and hence
\[\int_{\ndt}\exp\Big(-\frac{\hatt^2}{2\sigma_0}\Big)d\mu(x_0)=O\Big(n\int_{r'}^R(\gamma(r_0)-\phi(r_0))e^{-\alpha(R-r_0)}dr_0\Big)=O(n\phis),\]
where the last equality follows from Part~\eqref{itm:upp5} in Fact~\ref{fact:uppermix}.

\medskip

For the case $\alpha=2\beta$ we follow the same reasoning using \eqref{eq:mixfraceq} to deduce
\begin{align*}\int_{\ndt}\exp\Big({-}\frac{\hatt^2}{2\sigma_0}\Big)d\mu(x_0)&=n\int_{r'}^R\int_{\gamma(r_0)}^\infty \exp\left(-\Omega\left(v_0^{\frac{2-\varepsilon}{\varepsilon}}(\theta_0)\tfrac{\log(\ss)}{\log(v_0(\theta_0)\ss)}\right)\right)d\theta_0 e^{-\alpha(R-r_0)}dr_0\\[3pt]&=n\int_{r'}^R(\gamma(r_0)-\phi(r_0))\int_{1}^\infty \exp\left(-\Omega(w^{2-\varepsilon'}\tfrac{\log(\ss)}{\log(w^{\varepsilon}\ss)})\right)dwe^{-\alpha(R-r_0)}dr_0,\end{align*}
which is $O(n\phis)$ as before.

\item 
For the term $e^{-\frac{1}{16}v_0^2\ss}$ appearing in~\eqref{eq:mainterms} we use the change of variable $w=(v_0\sqrt{\ss})^{1/\varepsilon}$ so that 
\[\int_{\gamma(r_0)}^\infty e^{-\frac{1}{16}v_0^2\ss}d\theta_0=\ss^{-\frac{1}{2\varepsilon}}(\gamma(r_0)-\phi(r_0))\int_{\Omega(\ss^{\frac{1}{2\varepsilon}})}^{\infty}e^{-\Omega(w^{2\varepsilon})}dw=O(\gamma(r_0)-\phi(r_0)),\]
where the last equality follows from $\ss=\Omega(1)$. Hence,
\[
\int_{\ndt}e^{-\frac{1}{16}v_0^2\ss}d\mu(x_0)
=O\Big(n\int_{r'}^R (\gamma(r_0)-\phi(r_0))e^{-\alpha(R-r_0)}dr_0\Big)=O(n\phis),
\]
where the last equality follows from Part~\eqref{itm:upp5} in Fact~\ref{fact:uppermix}.
\item 
For the term $\hatt^{-\frac{\alpha}{\beta}}e^{-\alpha r_0}$, by definition of $\hatt$ we obtain  %As in the uniform bound analysis, the term $e^{-\alpha r_0}$\cmk{It would better tu enumerate the items in the analysis of the uniform bound and refer to a specific item of the list.} appearing in~\eqref{eq:mainterms} \dm{is at most of the same order as the term} $\mathfrak{f}(\hatt,\sigma_0) e^{-\alpha r_0}=\Theta(\hatt^{-\frac{\alpha}{\beta}}e^{-\alpha r_0})$, so we only treat the latter. 
\[
\int_{\ndt}\hatt^{-\frac{\alpha}{\beta}}e^{-\alpha r_0}d\mu(x_0)\,=\,O\Big(ne^{-\alpha R}\int_{r'}^R\int_{\gamma(r_0)}^\pi (\theta_0-\phi(r_0))^{-\frac{\alpha}{\beta}}d\theta_0dr_0\Big).\]
We treat first the case $\beta\leq\frac{1}{2}$, which implies in particular $\frac{\alpha}{\beta}>1$ and hence the right-hand side is of order
\[ne^{-\alpha R}\int_{r'}^R(\gamma(r_0)-\phi(r_0))^{1-\frac{\alpha}{\beta}}dr_0\,=\,O\big(ne^{-\alpha R}(e^{-(\beta\wedge\frac{1}{2})r''})^{1-\frac{\alpha}{\beta}}+ne^{-\alpha R}(R-r'')(\phis)^{1-\frac{\alpha}{\beta}}\big)\]
where we first integrate from $r'$ to $r''$, and then from $r''$ to $R$, and then used Part~\eqref{itm:upp4} in Fact~\ref{fact:uppermix} to bound $\gamma(r_0)-\phi(r_0)$ from below. Using Part~\eqref{itm:upp3} of Fact~\ref{fact:uppermix} in the first term on the right-hand side, we obtain a term of order $ne^{-\alpha R}(\phis)^{1-\frac{\alpha}{\beta}}=O(n\phis)$, while for the second term using that $\beta\leq\frac{1}{2}$ we have by definition that $r''=-\frac{1}{\beta}\log\phis+\Theta(1)=R-\Theta(\log\ss)$ so in particular $ne^{-\alpha R}(R-r'')(\phis)^{1-\frac{\alpha}{\beta}}=O(n\phis\ss^{-\delta}\log\ss)=O(n\phis)$ for some $\delta>0$ depending on $\alpha$ and $\beta$, giving the result in this case.
For the case $\alpha>\beta>\frac12$ we can repeat the calculations in the previous case to again obtain a bound of order $n\phis$.

\smallskip
For the case $\beta>\frac{1}{2}$ we have $\phis=e^{-\frac12 R}\ss^{\frac{1}{2\alpha}}$ and we still need to handle the case $\frac{\alpha}{\beta}\le 1$. If $\frac{\alpha}{\beta}<1$, we have
\[ne^{-\alpha R}\int_{r'}^R\int_{\gamma(r_0)}^\pi (\theta_0-\phi(r_0))^{-\frac{\alpha}{\beta}}d\theta_0dr_0\,=\,O\big(ne^{-\alpha R}R\big),\]
and in it is easily checked that since $\alpha>\frac12$ and by the definition of $\phis$  we have $ne^{-\alpha R}R=O(n\phis e^{(\frac{1}{2}-\alpha)R}R)=O(n\phis)$. Finally, if $\frac{\alpha}{\beta}=1$ we have
\[ne^{-\alpha R}\int_{r'}^R\int_{\gamma(r_0)}^\pi (\theta_0-\phi(r_0))^{-\frac{\alpha}{\beta}}d\theta_0dr_0\,=\,O\Big(ne^{-\alpha R}\int_{r'}^R\log\big(\tfrac{\pi}{\gamma(r_0){-}\phi(r_0)}\big)dr_0\Big)\]
%=O(ne^{-\alpha R}R^2);
where using Part~\eqref{itm:upp1} in Fact~\ref{fact:uppermix} we conclude that the right-hand term is at most of order $ne^{-\alpha R}R\log(1/\phis)=O(ne^{-\alpha R}R^2)=O(n\phis)$.
%\dmc{For the integral you get $O(r'\log(\gamma(r')))$, and you bound it by $R^2$? I am not sure if this bound is best possible, but perhaps yes.}\cml{I think it is clearer now?}

\item For the term $v_0\ss e^{-\alpha R}$ we observe that, using the change of variable
  $w:=v_0^{1/\varepsilon}$ together with Part~\eqref{itm:upp4} in Fact~\ref{fact:uppermix}, we get
\[
\int_{\gamma(r_0)}^{\pi} v_0\ss e^{-\alpha R}d\theta_0 
= O(\ss e^{-\alpha R}(\gamma(r_0)-\phi(r_0))^{-\varepsilon})\int_{0}^{\pi} w dw
= O(\ss e^{-\alpha R}(\phis)^{-\varepsilon}).
\]
Now, suppose first that $\beta>\frac{1}{2}$ so that $e^{-\alpha R}=\ss^{-1}(\phis)^{2\alpha}$ and hence $\ss e^{-\alpha R}(\phis)^{-\varepsilon}=(\phis)^{2\alpha-\varepsilon}=O(\phis)$ where the last equality 
is by our assumption of $\varepsilon<2\alpha-1$. Suppose now that $\beta\leq \frac{1}{2}$ and observe that in this case $e^{-\alpha R}=O((\phis)^{\frac{\alpha}{\beta}}\ss^{-(1\vee\frac{\alpha}{2\beta})})$ 
and $\frac{\alpha}{2\beta}\leq\alpha<1$ so using that $\ss=\Omega(1)$ we deduce again that
$\ss e^{-\alpha R}(\phis)^{-\varepsilon}=O\left((\phis)^{2\alpha-\varepsilon}\right)=O(\phis)$.
Summarizing, independent of the value taken by $\beta$ we have
\[
\int_{\ndt}v_0\ss e^{-\alpha R}d\mu(x_0) = O(n\phis)\int_{r'}^R e^{-\alpha(R-r_0)}dr_0 = O(n\phis).
\]

\item For the term $\mathfrak{t}_5$ it will be useful to notice from Part~\ref{itm:upp4} in Fact~\ref{fact:uppermix} that \begin{equation}\label{eq:mixaux}\left(\gamma(r_0)-\phi(r_0)\right)^{-\delta}=O((\phis)^{-\delta})\end{equation} for any $\delta>0$. We assume first that $\alpha\neq2\beta$ so that
\begin{equation}\label{eq:lastterm}\int_{\ndt}\mathfrak{t}_5(x_0)d\mu(x_0)\,=\,O\Big(ne^{-\alpha R}\int_{r'}^R\int_{\gamma(r_0)}^\pi (v_0\ss)^{1\vee\frac{\alpha}{4\beta}}\hatt^{-\frac{\alpha}{\beta}}d\theta_0e^{-\alpha(R-r_0)}dr_0\Big)\end{equation}
We analyze this expression first when $\alpha\leq 4\beta$ so using \eqref{eq:mixaux} the term on the right-hand side is of order
\begin{equation}\label{eq:mix:termfinal}ne^{-\alpha R}\ss(\phis)^{-\varepsilon}\int_{r'}^R\int_{\gamma(r_0)}^\pi (\theta_0-\phi(r_0))^{\varepsilon-\frac{\alpha}{\beta}}d\theta_0e^{-\alpha(R-r_0)}dr_0,\end{equation}
where the integral with respect to $\theta_0$ behaves differently according to whether $\varepsilon-\frac{\alpha}{\beta}$ is smaller, equal, or larger than ${-}1$. Suppose first that $\varepsilon-\frac{\alpha}{\beta}<{-}1$ so that the above term is of order
\[ne^{-\alpha R}\ss(\phis)^{-\varepsilon}\int_{r'}^R (\gamma(r_0)-\phi(r_0))^{1-\frac{\alpha}{\beta}+\varepsilon}e^{-\alpha(R-r_0)}dr_0\,=\,O\big(ne^{-\alpha R}\ss(\phis)^{1-\frac{\alpha}{\beta}}\big),\]
where the right hand side follows from \eqref{eq:mixaux}. Proceeding as in~\eqref{eq:boundforlater} we deduce that the bound is $O(n\phis)$. Suppose now that $\varepsilon-\frac{\alpha}{\beta}\geq-1$, which in particular implies $\beta\geq\frac{\alpha}{1+\varepsilon}\geq\frac{\alpha}{1+(2\alpha-1)}=\frac{1}{2}$ so in this case $\phis=e^{-\frac12 R}\ss^{\frac{1}{2\alpha}}$. Now, if $\varepsilon-\frac{\alpha}{\beta}>-1$ then the integral with respect to $\theta_0$ in~\eqref{eq:mix:termfinal} is $O(1)$, and thus the bound is of order
\[ne^{-\alpha R}\ss(\phis)^{-\varepsilon}\int_{r'}^Re^{-\alpha(R-r_0)}dr_0=O\big(ne^{-\alpha R}\ss(\phis)^{-\varepsilon}\big)=O\big(n(\phis)^{2\alpha-\varepsilon}\big)\]
where we have used the particular form of $\phis$. Since $\varepsilon$ satisfies $\varepsilon<2\alpha-1$ and also $\phis\le\pi=O(1)$, we conclude that the bound is $O(n\phis)$. Similarly, if $\varepsilon-\frac{\alpha}{\beta}=-1$ then~\eqref{eq:mix:termfinal} is of order 
\[ne^{-\alpha R}\ss(\phis)^{-\varepsilon}\int_{r'}^R\log\big(\tfrac{1}{\gamma(r_0)-\phi(r_0)}\big)e^{-\alpha(R-r_0)}dr_0=O\big(ne^{-\alpha R}\ss(\phis)^{-\varepsilon}\log\big(\tfrac{1}{\phis}\big)\big),\]
which is of order $n(\phis)^{2\alpha-\varepsilon}\log(\frac{1}{\phis})$ and again using that $\varepsilon<2\alpha-1$ and $\phis=O(1)$ we conclude that the bound is $O(n\phis)$.

\medskip

We now turn to the analysis of the right-hand side of~\eqref{eq:lastterm} when $\alpha>4\beta$, in which case we obtain a term of order
\begin{equation}\label{eq:mix:termfinal2}ne^{-\alpha R}\ss^{\frac{\alpha}{4\beta}}(\phis)^{-\frac{\alpha\varepsilon}{4\beta}}\int_{r'}^R\int_{\gamma(r_0)}^\pi (\theta_0-\phi(r_0))^{\frac{\alpha\varepsilon}{4\beta}-\frac{\alpha}{\beta}}d\theta_0e^{-\alpha(R-r_0)}dr_0.\end{equation}
Observe that the condition $\alpha>4\beta$ implies that $\phis=e^{-\beta R}\sqrt{\ss}$. Assume first that $\frac{\alpha\varepsilon}{4\beta}-\frac{\alpha}{\beta}<-1$ in which case~\eqref{eq:mix:termfinal2} is of order 
\[ne^{-\alpha R}\ss^{\frac{\alpha}{4\beta}}(\phis)^{-\frac{\alpha\varepsilon}{4\beta}}\int_{r'}^R (\gamma(r_0)-\phi(r_0))^{1-\frac{\alpha}{\beta}+\frac{\alpha\varepsilon}{4\beta}}e^{-\alpha(R-r_0)}dr_0=O\big(ne^{-\alpha R}\ss^{\frac{\alpha}{4\beta}}(\phis)^{1-\frac{\alpha}{\beta}}\big),\]
and from the particular form of $\phis$ we have $e^{-\alpha R}\ss^{\frac{\alpha}{4\beta}}(\phis)^{-\frac{\alpha}{\beta}}=\ss^{-\frac{\alpha}{4\beta}}=O(1)$ and hence the bound is $O(n\phis)$. Suppose next that $\frac{\alpha\varepsilon}{4\beta}-\frac{\alpha}{\beta}>-1$, in which case~\eqref{eq:mix:termfinal2} is of order 
\[ne^{-\alpha R}\ss^{\frac{\alpha}{4\beta}}(\phis)^{-\frac{\alpha\varepsilon}{4\beta}}\int_{r'}^R e^{-\alpha(R-r_0)}dr_0=O\big(ne^{-\alpha R}\ss^{\frac{\alpha}{4\beta}}(\phis)^{-\frac{\alpha\varepsilon}{4\beta}}\big),\]
and in order to show that the bound is $O(n\phis)$ it will be enough to prove that $e^{-\alpha R}\ss^{\frac{\alpha}{4\beta}}(\phis)^{-1-\frac{\alpha\varepsilon}{4\beta}}=O(1)$. It can be checked that using the particular form of $\phis$, we have $e^{-\alpha R}\ss^{\frac{\alpha}{4\beta}}(\phis)^{-1-\frac{\alpha\varepsilon}{4\beta}}=e^{-\alpha\frac{R}{2}}(\phis)^{\frac{\alpha}{2\beta}-1-\frac{\alpha\varepsilon}{4\beta}}$, and the result will follow as soon as the exponent of $\phis$ is positive. However, this is equivalent to $2-\varepsilon>\frac{4\beta}{\alpha}$ which holds since by definition $\varepsilon<1$, and we are assuming $\frac{4\beta}{\alpha}<1$. Finally, suppose that $\frac{\alpha\varepsilon}{4\beta}-\frac{\alpha}{\beta}=-1$, in which case~\eqref{eq:mix:termfinal2} is of order
$ne^{-\alpha R}\ss^{\frac{\alpha}{4\beta}}(\phis)^{-\frac{\alpha\varepsilon}{4\beta}}\log(1/\phis)$
and using the same analysis as in the case $\frac{\alpha\varepsilon}{4\beta}-\frac{\alpha}{\beta}>-1$ (with strict inequalities) we deduce that it is $O(n\phis)$.

\medskip
We now bound the integral of the term $\mathfrak{t}_5$ in the special case $\alpha=2\beta$ where
\begin{align*}\int_{\ndt}\mathfrak{t}_5(x_0)d\mu(x_0)&=\,O\Big(n\int_{r'}^R \int_{\gamma(r_0)}^\infty\int_{0}^{1}\sqrt{\tfrac{w\hatt^2}{\sigma_0}}e^{-\frac{w\hatt^2}{2\sigma_0}}(\auxl'\log(v_0\ss))^{w-1}dwd\theta_0e^{-\alpha(R-r_0)}dr_0\Big)\\[2pt]&=O\Big(n\int_{r'}^R \int_{0}^{1}\int_{\gamma(r_0)}^\infty\sqrt{\tfrac{w\hatt^2}{\sigma_0}}e^{-\frac{w\hatt^2}{2\sigma_0}}d\theta_0dwe^{-\alpha(R-r_0)}dr_0\Big).\end{align*}
Now, for any fixed $w\in(0,1)$, we can use the change of variables $u:=\frac{\theta_0-\phi(r_0)}{\gamma(r_0)-\phi(r_0)}$ in the inner integral, which gives
\[\int_{\gamma(r_0)}^\infty\sqrt{\tfrac{w\hatt^2}{\sigma_0}}e^{-\frac{w\hatt^2}{2\sigma_0}}d\theta_0=(\gamma(r_0)-\phi(r_0))\int_{1}^\infty\sqrt{\frac{wuy_0\log\ss}{\log(u\ss)}}\exp\Big({-}\Omega\left(\frac{wuy_0\log(\ss)}{2\log(u\ss)}\right)\Big)du\]
for $y_0:=\frac{(\gamma(r_0)-\phi(r_0))^2}{e^{-2\beta R}\ss\log(\ss)}$ which is $\Omega(1)$ since $\gamma(r_0)-\phi(r_0)=\Omega(\phis)$. On the other hand $\frac{\log(\ss)}{\log(u\ss)}=\Omega(\frac{1}{\log(u)})$ which allows us to conclude that
\[\int_0^1\int_{1}^\infty\sqrt{\frac{wuy_0\log\ss}{\log(u\ss)}}\exp\Big({-}\Omega\left(\frac{wuy_0\log(\ss)}{2\log(u\ss)}\right)\Big)dudw=O(1)\]
Therefore,
\[\int_{\ndt}\mathfrak{t}_5(x_0)d\mu(x_0)=O\Big(n\int_{r'}^R(\gamma(r_0)-\phi(r_0))e^{-\alpha(R-r_0)}dr_0\Big)=O(n\phis)\]
where the last equality follows directly from Part~\eqref{itm:upp5} in Fact~\ref{fact:uppermix}.
\end{itemize}
\end{proof}








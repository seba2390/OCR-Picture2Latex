% Comment out to revert to include line numbers
\newcommand*{\ARXIV}{}%

\documentclass[10.5pt]{article}
%%%%%%%%%%%%%%%%%%%% Line numbers, and patch for ams math environs
\usepackage[displaymath, mathlines]{lineno}

\ifdefined\ARXIV
  \pdfoutput=1
\else
  \linenumbers
\fi

\usepackage{benstyle}

\geometry{margin=1.05in}
\newcommand*{\pbk}{\vspace{1pc}\noindent}

\newcommand*\patchAmsMathEnvironmentForLineno[1]{%
  \expandafter\let\csname old#1\expandafter\endcsname\csname #1\endcsname
  \expandafter\let\csname oldend#1\expandafter\endcsname\csname end#1\endcsname
  \renewenvironment{#1}%
     {\linenomath\csname old#1\endcsname}%
     {\csname oldend#1\endcsname\endlinenomath}}% 
\newcommand*\patchBothAmsMathEnvironmentsForLineno[1]{%
  \patchAmsMathEnvironmentForLineno{#1}%
  \patchAmsMathEnvironmentForLineno{#1*}}%
\AtBeginDocument{%
\patchBothAmsMathEnvironmentsForLineno{equation}%
\patchBothAmsMathEnvironmentsForLineno{align}%
\patchBothAmsMathEnvironmentsForLineno{flalign}%
\patchBothAmsMathEnvironmentsForLineno{alignat}%
\patchBothAmsMathEnvironmentsForLineno{gather}%
\patchBothAmsMathEnvironmentsForLineno{multline}%
}
%%%%%%%%%%%%%%%%%%%%

\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
\usepackage{mathtools,ifthen}
\usepackage{array,multirow,booktabs} % for fancier tables
%\usepackage{showkeys}
\usepackage{lipsum}
\usepackage{bbm}

\newcommand{\annote}[1]{{\leavevmode\color{RoyalBlue}{#1}}}
\newcommand{\anrev}[1]{{\leavevmode\color{BrickRed}{#1}}}
\renewcommand{\anrev}[1]{#1}
\newcommand{\com}[1]{{\color{red}#1}}
\newcommand{\V}[1]{\boldsymbol{#1}}
\newcommand{\mathd}{\mathrm{d}}
\newcommand{\dx}[1]{\mathd #1}

\newcommand{\edits}[1]{{\leavevmode\color{BrickRed}{#1}}}
\renewcommand{\edits}[1]{#1}

%
%\setlength{\parindent}{0pt}
%\setlength{\parskip}{1ex plus 0.5ex minus 0.2ex}
%

% For leftstackrel
\newlength{\leftstackrelawd}
\newlength{\leftstackrelbwd}
\def\leftstackrel#1#2{\settowidth{\leftstackrelawd}%
{${{}^{#1}}$}\settowidth{\leftstackrelbwd}{$#2$}%
\addtolength{\leftstackrelawd}{-\leftstackrelbwd}%
\leavevmode\ifthenelse{\lengthtest{\leftstackrelawd>0pt}}%
{\kern-.5\leftstackrelawd}{}\mathrel{\mathop{#2}\limits^{#1}}}

\newcommand{\naive}{na\"{\i}ve}

% Hackity-hack for condensed spacing of bibliography
\let\oldbibliography\thebibliography
\renewcommand{\thebibliography}[1]{%
  \oldbibliography{#1}%
  \setlength{\itemsep}{0pt}%
}

\begin{document}

\title{Compressed sensing with sparse corruptions: Fault-tolerant sparse collocation approximations}
\author{
  Ben Adcock\footnote{B. Adcock and A. Bao acknowledge the support of the Alfred P. Sloan Foundation and the Natural Sciences and Engineering Research Council of Canada through grant 611675.} \\ Department of Mathematics \\ Simon Fraser University \\ Burnaby, BC, Canada 
  \and 
  Anyi Bao\footnotemark[1] \\ Department of Mathematics \\ Simon Fraser University \\ Burnaby, BC, Canada \\[20pt]
  \and 
  John D.\ Jakeman\footnote{J.D.Jakeman's work was supported by DARPA EQUiPS.} \\ Computer Science Research Institute \\ Sandia National Laboratories \\ Albuquerque, NM, USA\\[10pt]
  %\hspace*{40pt} Undisclosed author\footnote{This author's institution requires internal approval of authorship for publicly released documents. This approval is pending and proper authorship will be credited in future versions of this manuscript.}\hspace*{40pt}\\[20pt]
  \and 
  Akil Narayan\footnote{A. Narayan is partially supported by NSF DMS-1720416, AFOSR FA9550-15-1-0467, and DARPA EQUiPS N660011524053} \\ Department of Mathematics and \\ Scientific Computing and Imaging (SCI) Institute \\ University of Utah \\ Salt Lake City, UT, USA
}

\maketitle
\begin{abstract}
  The recovery of approximately sparse or compressible coefficients in a polynomial chaos expansion is a common goal in many modern parametric uncertainty quantification (UQ) problems. However, relatively little effort in UQ has been directed toward theoretical and computational strategies for addressing the sparse \textit{corruptions} problem, where a small number of measurements are highly corrupted. Such a situation has become pertinent today since modern computational frameworks are sufficiently complex with many interdependent components that may introduce hardware and software failures, some of which can be difficult to detect and result in a highly polluted simulation result. 
  
  In this paper we present a novel compressive sampling-based theoretical analysis for a regularized $\ell^1$ minimization algorithm that aims to recover sparse expansion coefficients in the presence of measurement corruptions. Our recovery results are uniform (the theoretical guarantees hold for all compressible signals and compressible corruptions vectors), and prescribe algorithmic regularization parameters in terms of a user-defined \textit{a priori} estimate on the ratio of measurements that are believed to be corrupted. We also propose an iteratively reweighted optimization algorithm that automatically refines the value of the regularization parameter, and empirically produces superior results. Our numerical results test our framework on several medium-to-high dimensional examples of solutions to parameterized differential equations, and demonstrate the effectiveness of our approach.
\end{abstract}

%\tableofcontents

\input{introduction}
\input{notation}

\section{Theory for the sparse corruptions problem}\label{sec:theory}

%\subsection{Notation}
%\bull{
%\item $m$ -- number of measurements
%\item $N$ -- length of sparse vector
%\item $x$ -- sparse vector in $\bbC^N$
%\item $c$ -- corruptions vector in $\bbC^m$
%\item $A$ -- $m \times N$ measurement matrix
%\item $n$ -- noise vector in $\bbC^m$
%\item $\epsilon$ -- noise bound
%\item $\lambda$ -- nonnegative weighting parameter for the corruptions vector
%\item $\hat{x}$, $\hat{c}$ -- solutions of the optimization problem
%\item $S$ -- subset of indices corresponding to $x$
%\item $T$ -- subset of indices corresponding to $c$
%\item $s$ -- sparsity of $x$
%\item $k$ -- sparsity of $c$
%\item $\Sigma_{s}$ -- set of $s$-sparse vectors in $\bbC^N$
%\item $\Sigma_{k}$ -- set of $k$-sparse vectors in $\bbC^m$
%\item $\sigma_{s}(x)_1$ -- best $s$-term approximation error, measured in the $\ell^1$ norm
%\item $\sigma_{k}(c)_1$ -- best $k$-term approximation error, measured in the $\ell^1$ norm
%}

\begin{table}
  \begin{center}
  \resizebox{\textwidth}{!}{
    \renewcommand{\tabcolsep}{0.4cm}
    \renewcommand{\arraystretch}{1.3}
    {\scriptsize
    \begin{tabular}{@{}cp{0.8\textwidth}@{}}
      \toprule
      $m$ & number of measurements \\
      $N$ & length of sparse vector \\
      $x$ & sparse vector in $\bbC^N$ \\
      $c$ & corruptions vector in $\bbC^m$\\
      $A$ & $m \times N$ measurement matrix \\
      $n$ & noise vector in $\bbC^m$ \\
      $\epsilon$ & noise bound \\
      $\lambda$ & non-negative weighting parameter for the corruptions vector \\
      $\hat{x}$, $\hat{c}$ & solutions of the optimization problem \\
      $S$ & subset of $\left\{1, \ldots, N \right\}$, indices corresponding to $x$ \\
      $T$ & subset of $\left\{1, \ldots, m \right\}$, indices corresponding to $c$ \\
      $s$ & sparsity of $x$ \\
      $k$ & sparsity of $c$ \\
      $\Sigma_{s}$ & set of $s$-sparse vectors in $\bbC^N$ \\
      $\Sigma_{k}$ & set of $k$-sparse vectors in $\bbC^m$ \\
      $\sigma_{s}(x)_1$ & best $s$-term approximation error, measured in the $\ell^1$ norm \\
      $\sigma_{k}(c)_1$ & best $k$-term approximation error, measured in the $\ell^1$ norm \\
    \bottomrule
    \end{tabular}
  }
    \renewcommand{\arraystretch}{1}
    \renewcommand{\tabcolsep}{12pt}
  }
  \end{center}
  \caption{Notation used throughout this article.}\label{tab:notation}
\end{table}

We recall and summarize our notation for the sparse corruptions problem in Table \ref{tab:notation}. Our previous discussion was framed for real-valued signals $x$ and measurements $y$, but we now generalize to the complex-valued setting. This adds generality with no additional mathematical difficulty.

We follow a familiar path for deriving conditions on $m$ such that $\ell^1$ optimization problems recover sparse solutions (see, for example, \cite{FoucartRauhutCSbook}). Section \ref{sec:robust-nsp} defines an appropriate robust Null Space Property (NSP) for the matrix $A$ in the sparse corruptions setting. Under this property, we show that the recovery estimates \eqref{eq:recovery-summary} hold. In order to construct matrices $A$ that satisfy the robust NSP, Section \ref{sec:rip} generalizes the concept of the Restricted Isometry Property (RIP) for matrices to the sparse corruptions setting. That section shows that matrices satisfying the RIP for the sparse corruptions problem also satisfy the robust NSP.  Sections \ref{sec:rip-2} and \ref{sec:bos} show that if the dictionary elements $\phi_j$ form a bounded orthonormal system, then under the condition \eqref{eq:m-bound}, the matrix $A$ satisfies the RIP with high probability.  Finally, using these various results, we discuss a theoretically-optimal choice for $\lambda$ in Section \ref{ss:lambda-strategy}.

\subsection{The Robust Null Space Property for the sparse corruptions problem}\label{sec:robust-nsp}

%\GR{I have removed the first paragraph here (essentially a repeat of what's written above).  Also, I removed the subsubsection headings, which I felt were unnecessary.}

%In this section we show that a certain \textit{robust null space property} (robust NSP) is sufficient for stable and robust recovery.  Note that the robust NSP was originally introduced by Rauhut [] for the recovery of sparse vectors.  Below we introduce a generalization that allows for (i) the incorporation of a sparse corruptions term $c$, and (ii) the weighting parameter $\lambda$ used in the optimization problem \R{l1_lambda_recovery}.

%\subsubsection{Definitions}

The following two definitions are generalizations of robust null space properties (cf. \cite[Definition 4.17]{FoucartRauhutCSbook} and \cite[Definition 4.21]{FoucartRauhutCSbook}, respectively), and prescribe classes of matrices whose kernels do not contain sparse vectors.

\defn{
Let $1 \leq s \leq N$, $1 \leq k \leq m$ and $\lambda > 0$.  A matrix $A \in \bbC^{m \times N}$ satisfies the $\ell^1$-robust null space property of order $(s,k)$ with weight $\lambda$ if there exist constants $0 < \rho <1$ and $\tau > 0$ such that
\bes{
\| x_{S} \|_{1} + \lambda \| c_{T} \|_{1} \leq \rho \left ( \| x_{S^c} \|_{1} + \lambda \| c_{T^c} \|_{1} \right ) + \tau \| A x + c \|_{2},\quad \forall x \in \bbC^N,\ c \in \bbC^m,
}
for all sets $S \subseteq \{1,\ldots,N\}$ and $T \subseteq \{1,\ldots,m\}$ with $| S | \leq s$ and $|T| \leq k$. Above, $S^c$ is the complement of $S$ in $\{1, \ldots, N\}$, and similarly for $T^c$.
}

\defn{
Let $1 \leq s \leq N$, $1 \leq k \leq m$ and $\lambda > 0$.  A matrix $A \in \bbC^{m \times N}$ satisfies the $\ell^2$-robust null space property of order $(s,k)$ with weight $\lambda$ if there exist constants $0 < \rho <1$ and $\tau > 0$ such that
\be{
\label{l2_rNSP_def}
\sqrt{\| x_{S} \|^2_{2} + \| c_{T} \|^2_{2}} \leq \frac{\rho}{\sqrt{s+\lambda^2 k}} \left ( \| x_{S^c} \|_{1} + \lambda \| c_{T^c} \|_{1} \right ) + \tau \| A x + c \|_{2},\quad \forall x \in \bbC^N,\ c \in \bbC^m,
}
for all sets $S \subseteq \{1,\ldots,N\}$ and $T \subseteq \{1,\ldots,m\}$ with $| S | \leq s$ and $|T| \leq k$.
}

%\rem{
%This can be generalized to an $\ell^p$-robust NSP for $1 \leq p \leq 2$.  This would add some generality to the error bounds below.
%}
%\GR{Remark removed here.  I think I wrote this mainly for our own benefit as a reminder.  I don't have the time now to work out the $\ell^p$-robust NSP, but can do this for the journal version.}


%\subsubsection{The $\ell^2$-robust null space property implies stable and robust recovery}

These definitions yield the following two results:
%With this in hand, we now have the following two results:

\lem{
\label{l:21_RNSP}
If $A \in \bbC^{m \times N}$ satisfies the $\ell^2$-robust null space property of order $(s,k)$ with weight $\lambda >0$ and constants $0 < \rho <1$, $\tau >0$ then it satisfies the $\ell^1$-robust null space property of order $(s,k)$ with weight $\lambda >0$ and constants $\rho$, $ \tau\sqrt{s+\lambda^2 k}$.
}
\prf{
Observe that
\bes{
\| x_{S} \|_{1} + \lambda \| c_{T} \|_{1} \leq \sqrt{s} \| x_{S} \|_{2} + \lambda \sqrt{k} \| c_{T} \|_{2} \leq \sqrt{s+\lambda^2 k} \sqrt{\| x_{S} \|^2_{2} + \| c_{T} \|^2_{2} }.
}
We now use the definition of the $\ell^2$-robust null space property.
}



\thm{
\label{t:rNSP_stable_robust}
Let $1 \leq s \leq N$, $1 \leq k \leq m$ and $\lambda > 0$ and suppose that $A \in \bbC^{m \times N}$ satisfies the $\ell^2$-robust null space property of order $(s,k)$ with weight $\lambda$.  Let $x \in \bbC^N$, $c \in \bbC^m$, $y \in \bbC^m$ and $\epsilon > 0$ be such that $\| A x + c - y \|_{2} \leq \epsilon$, and suppose that  $(\hat{x},\hat{c})$ is a minimizer of
\bes{
\min_{z \in \bbC^N, d \in \bbC^m} \| z \|_{1} + \lambda \| d \|_{1}\ \mbox{subject to $\| A z + d - y \|_{2} \leq \epsilon$}.
}
%where $y \in \bbC^m$ satisfies $\| A x + c - y \|_{2} \leq \eta$ for some $\epsilon > 0$.
Then
\be{
\label{l1_err_bound}
\| x - \hat{x} \|_{1} + \lambda \| c - \hat{c} \|_{1} \leq C_1 \left( \sigma_{s}(x)_1 + \lambda \sigma_{k}(c)_1 \right) + C_2\sqrt{s+\lambda^2 k} \epsilon,
}
and
\be{
\label{l2_err_bound}
\| x - \hat{x} \|_{2} + \| c - \hat{c} \|_{2} \leq C_3 \left ( 1 + \eta^{1/4} \right )\left( \frac{\sigma_{s}(x)_1}{\sqrt{s}} + \frac{\sigma_{k}(c)_1}{\sqrt{k}} \right) + C_4 \left ( 1 + \eta^{1/4} \right ) \epsilon,
}
where the constants $C_1,C_2,C_3,C_4$ depend on $\rho$ and $\tau$ only and $\eta$ is given by
\be{
\label{eta_def}
\eta = \eta_{s,k}(\lambda) = \frac{s+\lambda^2k}{\min \{ s , \lambda^2 k \} }.
}
}
%
%This theorem suggests that the choice $\lambda = \sqrt{s/k}$ is a good one, at least from the view of the theory.  We will see further evidence for this below when we look at the RIP.
%\GR{Removed comment here (a leftover from the notes).  All discussion on $\eta$ is now placed later in the Discussion subsubsection.}


\prf{
We first prove \R{l1_err_bound}.
Lemma \ref{l:21_RNSP} implies that $A$ satisfies the $\ell^1$-robust null space property.  Let $S \subseteq \{1,\ldots,N\}$, $|S| \leq s$ and $T \subseteq \{1,\ldots,m\}$, $|T| \leq k$ be such that $\| x_{S^c} \|_{1} = \sigma_{s}(x)_1$ and $\| c_{T^c} \|_{1} = \sigma_{k}(c)_1$.  Then, if $v = x - \hat{x}$ and $e = c - \hat{c}$ we have
\eas{
\| x \|_{1} +\lambda \| c \|_{1} + \| v_{S^c} \|_{1} + \lambda \| e_{T^c} \|_{1} &\leq 2 \| x_{S^c} \|_{1} + \| x_{S} \|_{1} + \lambda \left ( 2 \| c_{T^c} \|_{1} + \| c_{T} \|_1 \right ) + \| \hat{x}_{S^c} \|_{1} + \lambda \| \hat{c}_{T^c} \|_{1}
\\
& \leq 2 \| x_{S^c} \|_{1} + \| v_{S} \|_{1} + \| \hat{x} \|_{1} + \lambda \left ( 2 \| c_{T^c} \|_{1} + \| e_{T} \|_{1} + \| \hat{c} \|_{1} \right ).
}
Rearranging now gives
\eas{
\| v_{S^c} \|_{1} + \lambda \| e_{T^c} \|_{1} \leq & \left ( 2 \| x_{S^c} \|_{1} + \| v_{S} \|_{1} \right ) + \lambda \left ( 2 \| c_{T^c} \|_{1} + \| e_{T} \|_{1} \right )
\\
& + \left ( \| \hat{x} \|_{1} + \lambda \| \hat{c} \|_{1} \right ) - \left ( \| x \|_{1} + \lambda \| c \|_{1} \right )
\\
& \leq 2 \left ( \| x_{S^c} \|_{1} + \lambda \| c_{T^c} \|_{1} \right ) + \left ( \| v_{S} \|_{1} + \lambda \| e_{T} \|_{1} \right ),
}
where in the second inequality we note that $\| x \|_{1} + \lambda \| c \|_{1} \geq \| \hat{x} \|_{1} + \lambda \| \hat{c} \|_{1}$ since $(x,c)$ is feasible and $(\hat{x},\hat{c})$ is a minimizer.    The $\ell^1$-robust null space property now implies that
\bes{
\| v_{S^c} \|_{1} + \lambda \| e_{T^c} \|_{1} \leq \frac{2}{1-\rho} \left ( \| x_{S^c} \|_{1} + \lambda \| c_{T^c} \|_{1} \right ) + \frac{\tau\sqrt{s+\lambda^2 k}}{1-\rho} \| A v + e \|_{2},
}
and since $\| x_{S^c} \|_{1} = \sigma_{s}(x)_1$, $\| c_{T^c} \|_{1} = \sigma_{k}(c)_1$ and
\be{
\label{Ave_eps_bound}
\| A v + e \|_{2} \leq \| A \hat{x} + \hat{c} - y \|_{2} + \| A x + c - y \|_{2} \leq 2 \epsilon,
}
we deduce that
\be{
\label{ve_ST_comp_bound}
\| v_{S^c} \|_{1} + \lambda \| e_{T^c} \|_{1} \leq\frac{2}{1-\rho} \left ( \sigma_{s}(x)_1+ \lambda \sigma_{k}(c)_1 \right ) + \frac{2 \tau}{1-\rho} \sqrt{s+\lambda^2 k}\epsilon.
}
Finally, to complete the proof of \R{l1_err_bound} we argue as follows:
\eas{
\| v \|_{1} + \lambda \| e\|_{1} & \leq \| v_{S} \|_{1} + \lambda \| e_{T} \|_{1} + \| v_{S^c} \|_{1} + \lambda \| e_{T^c} \|_{1}
\\
& \leq (1+\rho) \left ( \| v_{S^c} \|_{1} + \lambda \| e_{T^c} \|_{1} \right ) + \tau \sqrt{s+\lambda^2 k} \| A v + e \|_{2}
\\
& \leq 2 \frac{1+\rho}{1-\rho} \left (  \sigma_{s}(x)_1+ \lambda \sigma_{k}(c)_1 \right ) + \frac{4}{1-\rho} \tau \sqrt{s+\lambda^2 k} \epsilon.
}
Here, we use the $\ell^1$-robust null space property in the second step, and \R{Ave_eps_bound} and \R{ve_ST_comp_bound} in the third step.

We now consider \R{l2_err_bound}.  Writing $v = x - \hat{x}$ and $e = c - \hat{c}$ as before, let $S$ be the index of the largest $s$ elements of $v$ in absolute value and $T$ be the index set of the largest $k$ elements of $e$ in absolute value.  Define
\bes{
\theta_{v} = \min_{i \in S} | v_i|,\quad \theta_{e} = \min_{j \in T} |e_j |,\qquad \theta = \max \{ \theta_v , \theta_e / \lambda \}.
}
Then
\bes{
\| v_{S^c} \|^2_{2} + \| e_{T^c} \|^2_2 = \sum_{i \notin S} | v_i |^2 + \sum_{j \notin T } |e_j |^2 \leq \theta_v \sum_{i \notin S} | v_i | + \theta_e \sum_{j \notin T } |e_j | \leq \theta \left ( \| v_{S^c} \|_{1} + \lambda \| e_{T^c} \|_{1} \right ).
}
Now observe that $\theta_{v} \leq \| v_{S} \|_{2} / \sqrt{s}$ and $\theta_{e} \leq \| e_{T} \|_{2} / \sqrt{k}$, and therefore
\bes{
\theta \leq \frac{\sqrt{\|v_S\|^2_2+\|e_T\|^2_2}}{\min \{ \sqrt{s} , \lambda \sqrt{k} \}} \leq \frac{1}{\min \{ \sqrt{s} , \lambda \sqrt{k} \}} \left ( \frac{\rho}{\sqrt{s+\lambda^2 k}} \left ( \| v_{S^c} \|_{1} + \lambda \| e_{T^c} \|_1 \right ) + 2 \tau \epsilon \right ),
}
where in the second step we use the $\ell^2$-robust null space property and \R{Ave_eps_bound}.  Combining this with the previous estimate and using the definition of $\eta$ gives
\eas{
\| v_{S^c} \|^2_{2} + \| e_{T^c} \|^2_2  \leq &  \frac{1}{\min \{ \sqrt{s} , \lambda \sqrt{k} \}} \left ( \frac{\rho}{\sqrt{s+\lambda^2 k}} \left ( \| v_{S^c} \|_{1} + \lambda \| e_{T^c} \|_1 \right )^2 + 2 \tau \epsilon \left ( \| v_{S^c} \|_{1} + \lambda \| e_{T^c} \|_1 \right ) \right )
\\
= &
  \sqrt{\eta} \left[ \rho w^2 + 2 \tau \epsilon w \right],
% \leq & \frac{1}{\min \{ \sqrt{s} , \lambda \sqrt{k} \}} \left ( \frac{\rho+1/2}{\sqrt{s+\lambda^2 k}} \left ( \| v_{S^c} \|_{1} + \lambda \| e_{T^c} \|_1 \right )^2 + 2  \tau^2 \sqrt{s+\lambda^2 k} \epsilon^2 \right ),
}
where we have defined the non-negative scalar $w$ as
  \begin{align*}
    w \coloneqq \frac{\left\| v_{S^c} \right\|_1 + \lambda \left\| e_{T^c} \right\|_1}{\sqrt{s + \lambda^2 k}}
  \end{align*}
  Completing the square with respect to $w$ under the brackets yields
  \begin{align*}
    \| v_{S^c} \|^2_{2} + \| e_{T^c} \|^2_2 \leq \rho \sqrt{\eta} \left[ \left(w + \frac{\tau \epsilon}{\sqrt{\rho}} \right)^2 - \frac{\tau^2 \epsilon^2}{\rho} \right] 
                                            \leq \rho \sqrt{\eta} \left(w + \frac{\tau \epsilon}{\sqrt{\rho}}\right)^2
  \end{align*}
Using the $\ell^2$-robust NSP on the pair $(v,e)$ along with the above estimate, we have
\begin{align}\nonumber
  \frac{1}{\sqrt{2}} \left( \| v\|_2 + \|e\|_2 \right) \leq \sqrt{\| v \|^2_{2} + \| e \|^2_{2}} &= \sqrt{\| v_S \|^2_2 + \| e_T \|^2_2 + \| v_{S^c} \|^2_2 + \| e_{T^c} \|^2_2}
\\\nonumber
&\leq \sqrt{\| v_S \|^2_2 + \| e_T \|^2_2} + \sqrt{\| v_{S^c} \|^2_2 + \| e_{T^c} \|^2_2}
\\\nonumber
&\leq \rho w + 2 \tau \epsilon + \sqrt{\rho} \eta^{1/4} \left(w + \frac{\tau \epsilon}{\sqrt{\rho}}\right) \\\label{eq:rNSP_stable_robust-temp}
&= \sqrt{\rho} \left( \sqrt{\rho} + \eta^{1/4}\right) w + \tau \left(2 + \eta^{1/4} \right) \epsilon
\end{align}
We note that
\begin{align*}
  w &= \frac{ \left\| v_{S^c} \right\|_1 + \lambda \left\| e_{T^c} \right\|_1}{\sqrt{s + \lambda^2 k}} \leq \frac{ \left\| v \right\|_1 + \lambda \left\| e \right\|_1}{\sqrt{s + \lambda^2 k}} \\
    &\leftstackrel{\eqref{l1_err_bound}}{\leq} C_1 \left[ \frac{\sigma_s(x)_1}{\sqrt{s + \lambda^2 k}} + \lambda \frac{\sigma_k(c)_1}{\sqrt{s + \lambda^2 k}} \right] + C_2 \epsilon
  \leq C_1 \left[ \frac{\sigma_s(x)_1}{\sqrt{s}} + \frac{\sigma_k(c)_1}{\sqrt{k}} \right] + C_2 \epsilon
\end{align*}
Combining the above with \eqref{eq:rNSP_stable_robust-temp} proves \eqref{l2_err_bound}.
%where in the second step we use the inequality $a b \leq a^2/2+b^2/2$.  Since $\sqrt{a+b} \leq \sqrt{a} + \sqrt{b}$, we deduce that
%\bes{
%\sqrt{\| v_{S^c} \|^2_{2} + \| e_{T^c} \|^2_2} \leq \frac{1}{\sqrt{\min \{ \sqrt{s} , \lambda \sqrt{k} \}}} \left ( \frac{\sqrt{\rho+1/2}}{(s+\lambda^2 k)^{1/4}} \left ( \| v_{S^c} \|_{1} + \lambda \| e_{T^c} \|_1 \right ) + \sqrt{2} \tau (s+\lambda^2 k)^{1/4} \epsilon \right ).
%}
%Now applying the $\ell^2$-robust null space property once more we deduce that
%\eas{
%\sqrt{\| v \|^2_{2} + \| e \|^2_{2}} =& \sqrt{\| v_S \|^2_2 + \| e_T \|^2_2 + \| v_{S^c} \|^2_2 + \| e_{T^c} \|^2_2}
%\\
%\leq & \sqrt{\| v_S \|^2_2 + \| e_T \|^2_2} + \sqrt{\| v_{S^c} \|^2_2 + \| e_{T^c} \|^2_2}
%\\
%\leq & \left ( \frac{\rho}{\sqrt{s+\lambda^2 k}} \left ( \| v_{S^c} \|_{1} + \lambda \| e_{T^c} \|_1 \right ) + 2 \tau \epsilon \right )
%\\
%& + \frac{1}{\sqrt{\min \{ \sqrt{s} , \lambda \sqrt{k} \}}} \left ( \frac{\sqrt{\rho+1/2}}{(s+\lambda^2 k)^{1/4}} \left ( \| v_{S^c} \|_{1} + \lambda \| e_{T^c} \|_1 \right ) + \sqrt{2} \tau (s+\lambda^2 k)^{1/4} \epsilon \right )
%\\
% = & \left ( \frac{\rho}{\sqrt{s+\lambda^2 k}}  + \frac{1}{\sqrt{\min \{ \sqrt{s} , \lambda \sqrt{k} \}}}  \frac{\sqrt{\rho+1/2}}{(s+\lambda^2 k)^{1/4}} \right ) \left ( \| v_{S^c} \|_{1} + \lambda \| e_{T^c} \|_1 \right )
%\\
%& +  \tau \left ( 2 + \frac{\sqrt{2}  (s+\lambda^2 k)^{1/4}}{\sqrt{\min \{ \sqrt{s} , \lambda \sqrt{k} \}}} \right ) \epsilon
%}
%Using the definition of $\eta$ now gives
%\bes{
%  \sqrt{\| v \|^2_{2} + \| e \|^2_{2}} \leq \left ( \rho + \sqrt{\rho+1/2} \eta^{1/4} \right ) \frac{\| v \|_{1} + \lambda \| e \|_1}{\sqrt{s+\lambda^2k}} + \left ( 2 + \sqrt{2} \eta^{1/4} \right ) \epsilon \annote{\tau}.
%}
%To get the result we now use \R{l1_err_bound} to notice that
%\bes{
% \frac{\| v \|_{1} + \lambda \| e \|_1}{\sqrt{s+\lambda^2k}} \leq C_1 \frac{\sigma_{s}(x)_1 + \lambda \sigma_k(c)_1 }{\sqrt{s+\lambda^2 k}} + C_2 \epsilon \leq C_1 \left ( \frac{\sigma_s(x)_1}{\sqrt{s}} + \frac{\sigma_k(c)_1}{\sqrt{k}} \right ) + C_2 \epsilon,
%}
%as required.
}
%\annote{(The new computation above makes the constants a bit sharper, which is pretty irrelevant, but it also does something qualitatively satisfying: in the previous estimates, $C_3\sim 1$ when $\rho \downarrow 0$. However, the new computation has $C_3 \sim \sqrt{\rho}$ for small $\rho$. Thus there is some consistency of the constants $\rho$ and $\tau$ defined in \eqref{l2_rNSP_def} and $C_3$ and $C_4$ above.)}


\subsection{The Restricted Isometry Property for the sparse corruptions problem}\label{sec:rip}


The robust NSP is typically difficult to prove directly.  Hence we now introduce the Restricted Isometry Property (RIP) for the sparse corruptions problem, and show that it implies the robust NSP.  Note that this has been defined previously in \cite[Defn.\ 2.1]{LiCorruptionsConstrApprox}.

\defn{
\label{d:RIPcorruptions}
Let $1 \leq s \leq N$, $1 \leq k \leq m \leq N$ and $A \in \bbC^{m \times N}$.  The $(s,k)^{\rth}$ Restricted Isometry Constant (RIC) $\delta = \delta_{s,k}$ of the matrix $A$ is the smallest constant such that
\bes{
(1-\delta) \left ( \| x \|^2_{2} + \| c \|^2_{2} \right ) \leq \| A x  + c \|^2_{2} \leq (1+\delta) \left ( \| x \|^2_{2} + \| c \|^2_{2} \right )
}
for all $x \in \Sigma_{s}$ and $c \in \Sigma_{k}$.  If $0 < \delta_{s,k} < 1$ then we say that $A$ has the Restricted Isometry Property (RIP) of order $(s,k)$.
}


%\subsubsection{Main result}
Our first result is the following:

\lem{
\label{l:RIP_implies_rNSP}
Let $1 \leq s \leq N$, $1 \leq k \leq m \leq N$, $\lambda > 0$ and $A \in \bbC^{m \times N}$.  If $A$ satisfies the RIP of order $(2s,2k)$ with constant
\be{
\label{delta_cond}
\delta_{2s,2k} < \frac{1}{\sqrt{1 + \left ( \frac{1}{2 \sqrt{2}} + \sqrt{\eta} \right )^2 }},
}
where $\eta$ is as in \R{eta_def}, then $A$ satisfies the $\ell^2$-robust NSP of order $(s,k)$ with weight $\lambda$ and constants $0 < \rho < 1$ and $\tau > 0$ depending only on $\delta_{2s,2k}$.
}
The proof of this result is given next. Combining this lemma with Theorem \ref{t:rNSP_stable_robust} now yields our main result:
\thm{
\label{t:RIP_stable_robust}
Let $1 \leq s \leq N$, $1 \leq k \leq m$ and $\lambda > 0$ and suppose that $A \in \bbC^{m \times N}$ satisfies the RIP of order $(2s,2k)$ with constant $\delta_{2s, 2k}$ satisfying \eqref{delta_cond}
%\be{
%\label{delta_cond2}
%\delta_{2s,2k} < \frac{1}{\sqrt{1 + \left ( \frac{1}{2 \sqrt{2}} + \sqrt{\eta} \right )^2 }},
%}
and $\eta$ as in \eqref{eta_def}.
%\bes{
%\eta = \eta_{s,k}(\lambda) = \frac{s+\lambda^2k}{\min \{ s , \lambda^2 k \} }.
%}
Let $x \in \bbC^N$, $c \in \bbC^m$, $y \in \bbC^m$ and $\epsilon > 0$ be such that $\| A x + c - y \|_{2} \leq \epsilon$, and suppose that  $(\hat{x},\hat{c})$ is a minimizer of
\bes{
\min_{z \in \bbC^N, d \in \bbC^m} \| z \|_{1} + \lambda \| d \|_{1}\ \mbox{subject to $\| A z + d - y \|_{2} \leq \epsilon$},
}
%where $y \in \bbC^m$ satisfies $\| A x + c - y \|_{2} \leq \eta$ for some $\epsilon > 0$.  
Then
\begin{align*}
  \| x - \hat{x} \|_{1} + \lambda \| c - \hat{c} \|_{1} &\leq C_1 \left( \sigma_{s}(x)_1 + \lambda \sigma_{k}(c)_1 \right) + C_2\sqrt{s+\lambda^2 k} \epsilon,\\ 
  \| x - \hat{x} \|_{2} + \| c - \hat{c} \|_{2} &\leq C_3 \left ( 1 + \eta^{1/4} \right )\left( \frac{\sigma_{s}(x)_1}{\sqrt{s}} + \frac{\sigma_{k}(c)_1}{\sqrt{k}} \right) + C_4 \left ( 1 + \eta^{1/4} \right ) \epsilon,
\end{align*}
where the constants $C_1,C_2,C_3,C_4$ depend on $\delta_{2s,2k}$ only.%, and
%\bes{
%%\label{eta_def}
%\eta = \eta_{s,k}(\lambda) = \frac{s+\lambda^2k}{\min \{ s , \lambda^2 k \} }.
%}
}










%\subsubsection{Proof of Lemma \ref{l:RIP_implies_rNSP}}\label{sec:lemma-proof}


We now prove Lemma \ref{l:RIP_implies_rNSP}.  We first require the following:
\lem{
\label{l:disjoint_inner_product_RIP}
Let $1 \leq s \leq N$, $1 \leq k \leq m \leq N$, and let $A \in \bbC^{m \times N}$ satisfy the RIP of order $(2s, 2k)$ with constant $\delta_{2s, 2k}$.  Suppose that $x \in \Sigma_{s}$ and $c \in \Sigma_{k}$ are such that
\bes{
\nm{A x + c}^2_{2} - \left ( \| x \|^2_{2} + \| c \|^2_{2} \right ) = t  \left ( \| x \|^2_{2} + \| c \|^2_{2} \right ),
}
for some $t$ with $0 \leq |t| \leq \delta_{2s,2k}$. If $z \in \Sigma_s$ and $d \in \Sigma_k$ are orthogonal to $x$ and $c$, respectively, then
\bes{
\left | \ip{A x + c}{A z + d} \right | \leq \sqrt{\delta^2_{2s,2k} - t^2} \sqrt{\| x \|^2_{2} + \| c \|^2_{2}} \sqrt{\| z \|^2_{2} + \| d\|^2_{2}}.
}
}
\prf{
Assume that $\| x \|^2_{2} + \| c \|^2_{2} = \| z \|^2_{2} + \| d\|^2_{2} = 1$ without loss of generality.  Let $\alpha,\beta \in \bbR$ and $\gamma \in \bbC$ and notice that $\alpha x + \gamma z, \beta x - \gamma z \in \Sigma_{2s}$ and $\alpha c + \gamma d , \beta c - \gamma d \in \Sigma_{2k}$.  Therefore
\eas{
\nm{A (\alpha x + \gamma z ) +( \alpha c + \gamma d) }^2_{2} &\leq \left ( 1 + \delta_{2s,2k} \right ) \left ( \nm{\alpha x + \gamma z }^2_2 + \nm{\alpha c + \gamma d }^2_{2} \right )
\\
& = \left ( 1 + \delta_{2s,2k} \right ) \left (  \alpha^2 \left ( \nm{x}^2_2 + \nm{c}^2_2 \right ) + |\gamma|^2 \left ( \nm{z}^2_2 + \nm{d}^2_2 \right ) \right )
\\
& = \left ( 1 + \delta_{2s,2k} \right )  \left ( \alpha^2 + | \gamma |^2 \right ).
}
Note that in the second step we use orthogonality of the vectors $x$ and $z$ and $c$ and $d$.  Similarly,
\bes{
\nm{A (\beta x - \gamma z ) +( \beta c - \gamma d) }^2_{2} \geq \left ( 1 - \delta_{2s,2k} \right ) \left ( \beta^2 + |\gamma|^2 \right ).
}
Subtracting the second equation from the first gives
\ea{
\nm{A (\alpha x + \gamma z ) +( \alpha c + \gamma d) }^2_{2} -& \nm{A (\beta x - \gamma z ) +( \beta c - \gamma d) }^2_{2} \nn
\\
& \leq \left ( 1 + \delta_{2s,2k} \right )  \left ( \alpha^2 + | \gamma |^2 \right ) - \left ( 1 - \delta_{2s,2k} \right ) \left ( \beta^2 + |\gamma|^2 \right ) \nn
\\
& = \delta_{2s,2k} \left ( \alpha^2 + \beta^2 + 2 | \gamma |^2 \right ) + \alpha^2 - \beta^2. \label{diff_upper_bd}
}
On the other hand
\eas{
\nm{A (\alpha x + \gamma z ) +( \alpha c + \gamma d) }^2_{2} - &\nm{A (\beta x - \gamma z ) +( \beta c - \gamma d) }^2_{2}
\\
=& \ \alpha^2 \nm{A x + c }^2_{2} + | \gamma |^2 \nm{A z + d }^2_{2} + 2 \Re \ip{\alpha(Ax+c)}{\gamma(A z + d ) }
\\
& \ - \beta^2 \nm{A x + c }^2_{2} - | \gamma |^2 \nm{A z + d }^2_{2} + 2 \Re \ip{\beta(Ax+c)}{\gamma(Az+d)}
\\
=& \left ( \alpha^2 - \beta^2 \right ) \nm{A x + c }^2_{2} + 2 (\alpha+\beta) \Re \left ( \bar{\gamma} \ip{Ax+c}{Az+d} \right )
\\
= & \left ( \alpha^2 - \beta^2 \right ) (1+t)  +  2 (\alpha+\beta) \Re \left ( \bar{\gamma} \ip{Ax+c}{Az+d} \right ).
}
Combining this with \R{diff_upper_bd} gives
\bes{
\left ( \alpha^2 - \beta^2 \right ) (1+t)  +  2 (\alpha+\beta) \Re \left ( \bar{\gamma} \ip{Ax+c}{Az+d} \right ) \leq \delta_{2s,2k} \left ( \alpha^2 + \beta^2 + 2 | \gamma |^2 \right ) + \alpha^2 - \beta^2.
}
Now let $\gamma$ be such that $| \gamma | = 1$ and $\Re \left ( \bar{\gamma} \ip{Ax+c}{Az+d} \right ) = | \ip{Ax+c}{Az+d}|$.  Then, after rearranging, we get
\bes{
| \ip{Ax+c}{Az+d}| \leq \frac{\left ( \delta_{2s,2k} - t\right ) \alpha^2 +\left ( \delta_{2s,2k} +t\right ) \beta^2 + 2 \delta_{2s,2k} }{2(\alpha+\beta)} .
}
We now seek values $\alpha$ and $\beta$ which minimize the right-hand side of this expression.  If $t = \delta_{2s,2k}$ then the minimal value $0$ is attained by setting $\beta =0 $ and letting $\alpha \rightarrow \infty$.  Conversely, if $t < \delta_{2s,2k}$ the minimal value is attained when $\alpha = \sqrt{\frac{\delta_{2s,2k}+t}{\delta_{2s,2k}-t}}$ and $\beta = \frac{1}{\alpha}$.  This gives
\bes{
| \ip{Ax+c}{Az+d}| \leq \sqrt{\delta^2_{2s,2k} - t^2},
}
which completes the proof.
}


\prf{[Proof of Lemma \ref{l:RIP_implies_rNSP}]
Let $x \in \bbC^N$ and $c \in \bbC^m$.  To prove the $\ell^2$-robust NSP for $A$ it is enough to show that \R{l2_rNSP_def} holds when $S = S_0$ is the index set of the $s$ largest coefficients of $x$ in absolute value and $T = T_0$ is the set of the $k$ largest values of $c$ in absolute value.  Given $S_0$, let $S_1$ be the index set of the next $s$ largest coefficients of $x$ in absolute value, $S_2$ be the index set of the next $s$ largest coefficients and so on.  Define $T_1,T_2,\ldots$ in a similar way.  We now have the following:
\ea{
\nm{A x_{S_0} + c_{T_0}}^2 &= \ip{A x_{S_0} + c_{T_0} }{A x_{S_0} + c_{T_0} } \nn
\\
& = \ip{A x_{S_0} + c_{T_0} }{A x + c} - \sum_{j \geq 1} \ip{A x_{S_0} + c_{T_0} }{A x_{S_j} + c_{T_j}}.\label{RIP_sum_split}
}
Let $0 \leq |t| \leq \delta_{2s,2k}$ be such that
\be{
\label{t_def}
\nm{A x_{S_0} + c_{T_0}}^2_2 = (1+t) \left ( \nm{x_{S_0}}^2_2 + \nm{c_{T_0}}^2_2 \right ),
}
and note that this gives
\be{
\label{RIP_sum_split_term1}
\left | \ip{A x_{S_0} + c_{T_0} }{A x + c} \right | \leq \sqrt{1+t} \sqrt{ \nm{x_{S_0}}^2_2 + \nm{c_{T_0}}^2_2 } \nm{A x + c}_{2}.
}
For the second term of \R{RIP_sum_split}, we use the disjointness of $S_0$ and $S_j$ and $T_0$ and $T_j$ for $j \geq 1$ in combination with Lemma \ref{l:disjoint_inner_product_RIP} to get
\ea{
\left | \sum_{j \geq 1} \ip{A x_{S_0} + c_{T_0} }{A x_{S_j} + c_{T_j}} \right | &\leq \sqrt{\delta^2_{2s,2k} - t^2} \sqrt{ \nm{x_{S_0}}^2_2 + \nm{c_{T_0}}^2_2 }  \sum_{j \geq 1}  \sqrt{ \nm{x_{S_j}}^2_2 + \nm{c_{T_j}}^2_2 } \nn
\\
& \leq \sqrt{\delta^2_{2s,2k} - t^2} \sqrt{ \nm{x_{S_0}}^2_2 + \nm{c_{T_0}}^2_2 }  \left ( \sum_{j \geq 1} \| x_{S_j} \|_{2} + \sum_{j \geq 1} \nm{c_{T_j}}_2 \right ). \label{RIP_sum_split_term2}
}
Let $x^{+}_{j}$ and $x^{-}_{j}$ be the largest entries of $x_{S_j}$ in absolute value.  Then, by \cite[Lem.\ 6.14]{FoucartRauhutCSbook}, we have
\eas{
\sum_{j \geq 1} \| x_{S_j} \|_{2} & \leq \sum_{j \geq 1} \left ( \frac{\nm{x_{S_j}}_1}{\sqrt{s}} + \frac{\sqrt{s}}{4} \left ( x^{+}_{j} - x^{-}_{j} \right ) \right )
\\
& \leq \frac{\nm{x_{S^c_0}}_1}{\sqrt{s}} + \frac{\sqrt{s}}{4} \sum_{j \geq 1} \left ( x^{+}_{j} - x^{+}_{j+1} \right )
%\\
%& 
\leq \frac{\nm{x_{S^c_0}}_1}{\sqrt{s}} + \frac{\sqrt{s}}{4} x^{+}_{1}
%\\
%& 
\leq \frac{\nm{x_{S^c_0}}_1}{\sqrt{s}} + \frac{1}{4} \| x_{S_0} \|_{2}.
}
Similarly,
\bes{
\sum_{j \geq 1} \nm{c_{T_j}}_2 \leq \frac{\nm{c_{T^c_0}}_1}{\sqrt{k}} + \frac{1}{4} \nm{c_{T_0}}_2 \leq  \frac{\lambda \nm{c_{T^c_0}}_1}{\lambda \sqrt{k}} + \frac{1}{4} \nm{c_{T_0}}_2 ,
}
which gives
\bes{
\sum_{j \geq 1} \| x_{S_j} \|_{2} + \sum_{j \geq 1} \nm{c_{T_j}}_2 \leq \frac{1}{\min \left \{ \sqrt{s} , \lambda \sqrt{k} \right \} } \left ( \nm{x_{S^c_0}}_1 + \lambda \nm{c_{T^c_0}}_1 \right ) + \frac14 \left ( \| x_{S_0} \|_{2} + \nm{c_{T_0}}_2 \right ).
}
Therefore, combining this with \R{RIP_sum_split}, \R{t_def}, \R{RIP_sum_split_term1} and \R{RIP_sum_split_term2} yields
\eas{
(1+t) &\sqrt{\nm{x_{S_0}}^2_2 + \nm{c_{T_0}}^2_2} \leq  \sqrt{1+t} \nm{A x + c}_{2}
\\
& + \sqrt{\delta^2_{2s,2k} - t^2} \left ( \frac{1}{\min \left \{ \sqrt{s} , \lambda \sqrt{k} \right \} } \left ( \nm{x_{S^c_0}}_1 + \lambda \nm{c_{T^c_0}}_1 \right ) + \frac14 \left ( \| x_{S_0} \|_{2} + \nm{c_{T_0}}_2 \right ) \right ).
}
Consider the function $g(t) = \frac{\delta^2_{2s,2k} - t^2}{(1+t)^2}$, where $0 \leq t \leq \delta_{2s,2k}$.  This function attains its maximum value at $t = - \delta^2_{2s,2k}$ and takes value $\frac{\delta^2_{2s,2k}}{1-\delta^2_{2s,2k}}$ there.  Additionally $\frac{1}{\sqrt{1+t}} \leq \frac{1}{\sqrt{1-\delta_{2s,2k}}}$.  Hence we get
\eas{
\sqrt{\nm{x_{S_0}}^2_2 + \nm{c_{T_0}}^2_2} &\leq \frac{1}{\sqrt{1-\delta_{2s,2k}}} \nm{Ax+c}_2
\\
 +& \frac{\delta_{2s,2k}}{\sqrt{1-\delta^2_{2s,2k}}} \left ( \frac{1}{\min \left \{ \sqrt{s} , \lambda \sqrt{k} \right \} } \left ( \nm{x_{S^c_0}}_1 + \nm{c_{T^c_0}}_1 \right ) + \frac14 \left ( \| x_{S_0} \|_{2} + \nm{c_{T_0}}_2 \right ) \right ).
}
After noting that $\| x_{S_0} \|_{2} + \nm{c_{T_0}}_2 \leq \sqrt{2} \sqrt{\nm{x_{S_0}}^2_2 + \nm{c_{T_0}}^2_2}$ and rearranging, we obtain
\bes{
  \sqrt{\nm{x_{S_0}}^2_2 + \nm{c_{T_0}}^2_2} \leq \frac{\rho}{\sqrt{s + \lambda^2 k}} \left ( \nm{x_{S^c_0}}_1 + \nm{c_{T^c_0}}_1 \right ) + \tau \nm{A x + c}_{2},
}
where
\be{\label{eq:rho-tau-def}
\rho = \frac{2 \sqrt{2} \delta_{2s,2k}}{2\sqrt{2} \sqrt{1-\delta^2_{2s,2k}} - \delta_{2s,2k}} \sqrt{\eta} ,\quad \tau = \frac{2 \sqrt{2} \sqrt{1+\delta_{2s,2k}} }{2\sqrt{2} \sqrt{1-\delta^2_{2s,2k}} - \delta_{2s,2k}}.
}
To complete the proof we note that $\rho, \tau > 0$ provided $\delta_{2s,2k} < \sqrt{8/9}$.  This holds by assumption, since $\eta \geq 2$ and therefore the condition \R{delta_cond} implies that $\delta_{2s,2k} < \sqrt{8/33} < \sqrt{8/9}$.  Also, after rearranging we see that $\rho < 1$ if
\bes{
\left ( 1 + \left ( \frac{1}{2 \sqrt{2}} + \sqrt{\eta} \right )^2 \right ) \delta^2_{2s,2k} < 1,
}
which again holds by assumption.
}

%\annote{Here is an alternative derivation of a different version of the above. We essentially seek to show an improved version of \eqref{eq:delta-condition-1}. The punch line is that if we choose $\lambda \geq \sqrt{\frac{s}{k}}$, then we only need 
%  \begin{align}\label{eq:delta-condition-2}
%    \delta_{2s, 2k} < \sqrt{\frac{8}{17 + 4\sqrt{2}}} \approx 0.59,
%  \end{align}
%  which is even better than \eqref{eq:delta-condition-1}.
%  
%  Consider a sharper definition of $\rho$, 
%  \begin{align*}
%  \rho = \frac{2 \sqrt{2} \delta_{2s,2k}}{2\sqrt{2} \sqrt{1-\delta^2_{2s,2k}} - \delta_{2s,2k}} \sqrt{\nu} ,\quad \tau = \frac{2 \sqrt{2} \sqrt{1+\delta_{2s,2k}} }{2\sqrt{2} \sqrt{1-\delta^2_{2s,2k}} - \delta_{2s,2k}},
%  \end{align*}
%  where $\nu \coloneqq \frac{1}{\min \left\{s, \lambda^2 k \right\}}$. The only difference between the above and \eqref{eq:rho-tau-def} is that $\eta$ has been replaced by $\nu$. Most of the same conclusions hold: since $\rho = \frac{\delta_{2s,2k}}{\sqrt{1 + \delta_{2s,2k}}} \sqrt{\nu} \tau$, then both $\rho, \tau > 0$ when $2\sqrt{2} \sqrt{1-\delta^2_{2s,2k}} - \delta_{2s,2k} > 0$, i.e., when 
%  \begin{align*}
%    \delta_{2s,2k} < \sqrt{\frac{8}{9}}.
%  \end{align*}
%  Under this condition, we can ensure $\rho < 1$ if in addition
%  \begin{align}\label{eq:delta-nu-condition}
%    \delta_{2s,2k} < \frac{1}{\sqrt{1 + \left(\frac{1}{2\sqrt{2}} + \sqrt{\nu}\right)^2}}.
%  \end{align}
%  This condition on $\delta_{2s,2k}$ is strictly better (looser) than \eqref{delta_cond} since $\nu < \eta$. Since the ultimate goal is to allow $\delta$ to be as large as possible, we seek to minimize $\nu$. Thus, we seek to choose $\lambda$ such that 
%  \begin{align*}
%    \max \left\{ \frac{1}{s}, \frac{1}{\lambda^2 k} \right\}
%  \end{align*}
%  is minimized. This happens when $\lambda \geq \sqrt{\frac{s}{k}}$, and this ensures that $\nu = \frac{1}{s} \leq 1$. The condition \eqref{eq:delta-condition-2} is equivalent to 
%  \begin{align*}
%    \delta_{2s,2k} < \frac{1}{\sqrt{1 + \left(\frac{1}{2\sqrt{2}} + 1\right)^2}} \leq \frac{1}{\sqrt{1 + \left(\frac{1}{2\sqrt{2}} + \frac{1}{\sqrt{s}} \right)^2}} = \frac{1}{\sqrt{1 + \left(\frac{1}{2\sqrt{2}} + \sqrt{\nu} \right)^2}}
%  \end{align*}
%  Thus, assuming \eqref{eq:delta-condition-1} ensures \eqref{eq:delta-nu-condition} and hence the $\ell^2$-robust NSP.
%}


\rem{
\label{r:RIPinlevels}
The RIP for the sparse corruptions problem is a special case of the RIP in levels (RIPL), introduced in \cite{BastounisHansen}.  The RIPL applies to vectors that are sparse in levels; namely, having different amounts of sparsity in different (but fixed) sections of the vector.  In the context of the sparse corruptions problem, this corresponds to the concatenated vector $z = [ x ; c ]$, which is $s$-sparse in its first $N$ entries and $k$-sparse in its remaining $m$ entries.  As a general tool, sparsity in levels has been used in the context of compressive imaging \cite{AHPRBreaking,OptimalSamplingQuest,AsymptoticCS}, radar \cite{Dorsch2016} and multi-sensor acquisition \cite{AdcockChunParallel}.  It is interesting that the same model also occurs naturally in the, seemingly unrelated, sparse corruptions problem.  We note in passing that Theorems \ref{t:rNSP_stable_robust} and \ref{t:RIP_stable_robust} follow a similar approach to that of \cite{BastounisHansen} with some changes made to incorporate the weighted optimization problem.  
}


\subsection{Matrices that satisfy the RIP for sparse corruptions}\label{sec:rip-2}

We first recall the classical RIP for sparse vectors:

\defn{
Let $1 \leq s \leq N$ and $A \in \bbC^{m \times N}$.  The $s^{\rth}$ Restricted Isometry Constant (RIC) $\delta = \delta_{s}$ of the matrix $A$ is the smallest constant such that
\bes{
(1-\delta)\nm{x}^2_2 \leq \| A x \|^2_{2} \leq (1+\delta) \nm{x}^2_2,
}
for all $x \in \Sigma_{s}$.  If $0 < \delta_{s} < 1$ then we say that $A$ has the Restricted Isometry Property (RIP) of order $s$.
}

To distinguish it from the RIP for the sparse corruptions problem (Definition \ref{d:RIPcorruptions}), we shall refer to this as the \textit{RIP for sparse vectors}.

\lem{
\label{l:deltask_deltas_sigmask}
Let $1 \leq s \leq N$, $1 \leq k \leq m$, $A \in \bbC^{m \times N}$ and define
\be{
\label{sigma_def}
\sigma_{s,k} = \max_{\substack{S \subseteq \{1,\ldots,N\}, |S| = s \\ T \subseteq \{1,\ldots,m \}, |T| = k }} \| A_{S,T} \|_{2},
}
where $A_{S,T} \in \bbC^{|T| \times |S|}$ is the submatrix of $A$ with entries $\{ A_{ij} \}_{i \in T, j \in S}$.  Suppose that $A$ has the RIP for sparse vectors with constant $\delta_s$ and that $\sigma_{s,k} < \sqrt{1-\delta_{s}}$.  Then $A$ has the RIP of order $(s,k)$ for the sparse corruptions problem with constant
\bes{
\delta_{s,k} =  \frac{\delta_s + \sqrt{\delta^2_s+4 \sigma^2_{s,k}}}{2}.
}
In other words,
\bes{
\left ( 1 - \delta_{s,k} \right ) \left ( \nm{x}^2_{2} + \nm{c}^2_2 \right ) \leq \nm{A x + c}^2_{2} \leq \left ( 1 + \delta_{s,k} \right ) \left ( \nm{x}^2_{2} + \nm{c}^2_2 \right )
}
for all $x \in \Sigma_{s}$ and $c \in \Sigma_k$.
}
\prf{
Let $x \in \Sigma_{s}$ and $c \in \Sigma_k$ and write $S = \supp(x)$ and $T = \supp(c)$.  Then
\bes{
\nm{A x + c}^2_{2} = \nm{A x}^2_{2} + \nm{c}^2_{2} + 2 \Re \ip{A_{S,T} x}{c}.
}
By Young's inequality
\bes{
2\left | \ip{A_{S,T} x}{c} \right | \leq 2 \| A_{S,T} \|_{2} \nm{x}_2 \nm{c}_2 \leq \| A_{S,T} \|_{2} \left ( \nm{x}^2_2 / \epsilon + \epsilon \nm{c}^2_2 \right ),
}
for any $\epsilon > 0$.  Hence
\bes{
\left ( 1 - \delta_s - \sigma_{s,k}/\epsilon \right ) \nm{x}^2_2 + \left ( 1 - \sigma \epsilon \right ) \nm{c}^2_{2} \leq \nm{A x + c }^2_{2} \leq \left ( 1 + \delta_s + \sigma_{s,k}/\epsilon \right ) \nm{x}^2_2 + \left ( 1 + \sigma \epsilon \right ) \nm{c}^2_{2}.
}
Solving the equation $\delta_s + \sigma_{s,k}/\epsilon = \sigma_{s,k} \epsilon$ yields the value $\epsilon = \frac{\delta_s + \sqrt{\delta^2_s + 4 \sigma^2_{s,k}}}{2 \sigma}$, and substituting this value of $\epsilon$ into the previous expression yields the proof.
}

This result shows that any matrix satisfying the RIP for sparse vectors also satisfies the RIP for the sparse corruptions problem, provided the all $k \times s$ submatrices have small spectral norm.

\subsubsection{Gaussian random matrices}
Gaussian random matrices in the context of the sparse corruptions problem were considered in \cite{LiCorruptionsConstrApprox}.  The following result essentially recaps the main result for this case given therein.  We include a short proof for completeness:

\thm{
\label{t:GaussCorruption}
Let $0 < \delta , \epsilon < 1$, $1 \leq s \leq$, $1 \leq k \leq m$ and suppose that
\ea{
m &\gtrsim \delta^{-2} \left ( s \cdot \log(2N/s) + \log(2 \epsilon^{-1}) \right ), \label{mGaussRIP}
\\
m &\gtrsim \delta^{-2} \cdot k \cdot \log(\delta^{-1}). \label{mGaussSigma}
}
Let $A \in \bbC^{m \times N}$ be a matrix whose entries are independent Gaussian random variables with mean zero and variance $1$.  Then with probability at least $1-\epsilon$, the matrix $\frac{1}{\sqrt{m}} A$ has the RIP for the sparse corruptions problem of order $(s,k)$ with constant $\delta_{s,k} \leq \delta$.
}
\prf{
Lemma \ref{l:deltask_deltas_sigmask} asserts that $A$ has the RIP of order $(s,k)$ for the sparse corruptions problem with constant $\delta_{s,k} \leq \delta$ provided (i) $A$ has the RIP of order $s$ with $\delta_{s} \leq \delta/\sqrt{2}$ and (ii) the constant $\sigma_{s,k}$ defined in \R{sigma_def} satisfies $\sigma_{s,k} \leq \delta/(2 \sqrt{2})$.  Hence, by the union bound it suffices to show that \R{mGaussRIP} and \R{mGaussSigma} imply both (i) and (ii) separately with probabilities at least $1-\epsilon/2$.  Due to a standard result in compressed sensing (see, for example, \cite[Thm.\ 9.2]{FoucartRauhutCSbook}), property (i) holds with probability at least $1-\epsilon/2$ whenever the condition \R{mGaussRIP} is satisfied.  We now consider property (ii).  First, notice that $\sigma_{s,k}$ is increasing in $k$.  Therefore, we may assume that $ k \asymp \delta^2 \cdot m$, i.e.\ $k \gtrsim \delta^{2} \cdot m$ and $k \lesssim \delta^{2} \cdot m$.  Fix subsets $S \subseteq \{1,\ldots,N\}$ and $T \subseteq \{1,\ldots,m\}$ with $|S| = s$ and $|T|  =k$.  Then, due to a known result for singular values of random Gaussian matrices (see, for example, \cite[Cor.\ 5.35]{Vershynin:bookCh}), we have
\bes{
\bbP \left ( \nm{A_{S,T}}_2 \geq \sqrt{s} + \sqrt{k} + t \right ) \leq 2 \exp(-t^2/2).
}
The conditions \R{mGaussRIP} and \R{mGaussSigma} imply that $\sqrt{s/m} \leq \delta  /(6\sqrt{2})$ and $\sqrt{k/m} \leq \delta  /(6\sqrt{2})$.  Hence, by the union bound
\eas{
\bbP \left ( \sigma_{s,k} > \delta / (2 \sqrt{2}) \right )  \leq \left ( \begin{array}{c} N \\ s \end{array} \right ) \left ( \begin{array}{c} m \\ k \end{array} \right ) \exp(-m\delta^2/48) \leq \left ( \frac{\E N}{s} \right )^s \left ( \frac{\E m}{k} \right )^k \exp(-m\delta^2/48).
}
In particular, $\bbP \left ( \sigma_{s,k} > \delta / (2 \sqrt{2}) \right )  \leq \epsilon/2$ provided
\bes{
m \geq 48 \cdot \delta^{-2} \left ( s \log(\E N/s) + k \log(\E m/k) + \log(2 \epsilon^{-1}) \right ).
}
Since $k \asymp \delta^2 \cdot m$, we have $\log(\E m / k) \lesssim \log(2 \delta^{-1})$.  Hence this condition is implied by \R{mGaussRIP} and \R{mGaussSigma}.  This establishes property (ii) and completes the proof.
}

This result asserts that Gaussian random matrices can recover a fixed fraction $k/m \leq c$ of corruptions (see \R{mGaussSigma}) and (up to constants) the same level of sparsity $s$ as in the uncorrupted case (see \R{mGaussRIP}).




\subsubsection{Bounded orthonormal systems}\label{sec:bos}

Gaussian random matrices, while mathematically appealing, are of little relevance to multivariate approximation using Polynomial Chaos expansions.  In this case, a more suitable framework is that of bounded orthonormal systems (see, for example, \cite[Chpt.\ 12]{FoucartRauhutCSbook}):

Let $D$ be a domain with a probability measure $\nu$ and $\phi_1,\ldots,\phi_N$ be an orthonormal system of complex-value functions in $L^2(D)$.  Recall that this system is bounded if
\bes{
\nm{\phi_i }_{L^\infty} = \sup_{\xi \in D} | \phi_i(\xi) | \leq K
}
Given such a system, we construct the measurement matrix $A$ as
\be{
\label{ABOS}
A = \frac{1}{\sqrt{m}} \left \{ \phi_j(\xi_i) \right \}^{m,N}_{i=1,j=1} \in \bbC^{m \times N},
}
where $t_i$ are drawn independently at random according to the probability measure $\nu$.  

\thm{
\label{t:RIP_BOS}
Let $A \in \bbC^{m \times N}$ be the matrix of a bounded orthonormal system, $1 \leq s \leq N$ and $0 < \delta , \epsilon < 1$.  If
\bes{
m \gtrsim \delta^{-2} \cdot s \cdot \left ( \log^3(2s) \cdot \log(2N) + \log(\epsilon^{-1}) \right ),
}
then $A$ satisfies the RIP for sparse vectors with probability at least $1-\epsilon$.
}

We remark in passing that the logarithmic dependence in $s$ can be improved by one power, at the expense of a larger factor in $\delta^{-1}$ \cite{ChkifaDownwardsCS}.  However, this may not be best for the purposes of this paper, since in view of Theorem \ref{t:RIP_stable_robust}, $\delta^{-2}$ scales linearly in the parameter $\eta$ (see next).   

The following lemma estimates the constant $\sigma_{s,k}$ for matrices of the form \R{ABOS}:
\lem{
\label{l:BOSsigmaEst}
Let $A \in \bbC^{m \times N}$ be the matrix of a bounded orthonormal system, $1 \leq s,k \leq N$ and $\sigma_{s,k}$ be as in \R{sigma_def}.  Then
\bes{
\sigma_{s,k} \leq \sqrt{\frac{K^2 s k}{m}}.
}
}
\prf{
Fix subsets $S \subseteq \{1,\ldots,N\}$, $|S|=s$ and $T \subseteq \{1,\ldots,m\}$, $|T|=k$ and let $x \in \bbC^N$ and $c \in \bbC^m$ with $\supp(x) = S$ and $\supp(c) = T$.  Then
\eas{
\left | c^* A x \right |^2 &= \frac{1}{\sqrt{m}} \left | \sum_{i \in T} \overline{c_i} \sum_{j \in S} \phi_j(t_i) x_j \right | 
\\
& \leq \frac{1}{\sqrt{m}} \max_{i =1,\ldots,m} \left | \sum_{j \in S} \phi_j(t_i) x_j \right | \sum_{i \in T} | c_i | 
%\\
%& 
\leq \frac{K}{\sqrt{m}}  \| x \|_{1} \| c \|_{1}
%\\
%& 
\leq \sqrt{\frac{K^2 s k}{m}} \| x \|_{2} \| c \|_{2}.
}
Hence $\| P_{T} A P_{S} \|_{2} \leq \sqrt{\frac{K^2 s k}{m}}$.  This now gives the result.
}

With this in hand, we now deduce the following result:
\thm{
\label{t:BOS-RIP}
Let $1 \leq s \leq N$, $1 \leq k \leq m$, $0 < \delta,\epsilon < 1$ and suppose that
\be{
\label{mRIP1}
m \gtrsim \delta^{-2} \cdot K^2 \cdot s \cdot \left ( \log^3(2s) \cdot \log(2N) + \log(\epsilon^{-1}) \right ),
}
and 
\bes{
\label{mRIP2}
m \geq 8 \cdot \delta^{-2} \cdot K^2 \cdot s \cdot k.
}
Then, with probability at least $1-\epsilon$, $A$ has the RIP of order $(s,k)$ for the sparse corruptions problem with constant $\delta_{s,k} \leq \delta$.
}
\prf{
Theorem \ref{t:RIP_BOS} and \R{mRIP1} imply that $A$ has the RIP of order $s$ with $\delta_{s} \leq \delta/\sqrt{2}$ with probability at least $1-\epsilon$.  Moreover, Lemma \ref{l:BOSsigmaEst} and \R{mRIP2} imply that $\sigma_{s,k} \leq \delta/(2 \sqrt{2})$.  We now apply Lemma \ref{l:deltask_deltas_sigmask}.
%
%Lemma \ref{l:deltask_deltas_sigmask} asserts that $A$ has the RIP of order $(s,k)$ for the sparse corruptions problem with constant $\delta_{s,k} \leq \delta$ provided (i) $A$ has the RIP of order $s$ with $\delta_{s} \leq \delta/\sqrt{2}$ and (ii) the constant $\sigma_{s,k}$ defined in \R{sigma_def} satisfies $\sigma_{s,k} \leq \delta/(2 \sqrt{2})$.  Property (i) follows immediately from Theorem \ref{t:RIP_BOS} and \R{mRIP1}, and property (ii) follows from Lemma \ref{l:BOSsigmaEst} and \R{mRIP2}.
}

\rem{
This result asserts that the number of corruptions that can be tolerated is a fraction of $m/s$.  This is inferior to the case of Gaussian random measurements, where Theorem \ref{t:GaussCorruption} gives that a fraction of $m$ corruptions are permitted.  We conjecture, however, that a similar estimate can be proved for the bounded orthonormal systems case -- indeed, a nonuniform recovery result of this form was proved in \cite{LiCorruptionsConstrApprox} for the case of exactly sparse coefficients $x$ and corruptions $c$ with random sign sequences -- albeit with a substantially more sophisticated argument than the proof of Theorem \ref{t:GaussCorruption}.  In particular, while estimates for the singular values of matrices of bounded orthonormal systems are known \cite{Vershynin:bookCh}, they are more stringent than those for Gaussian random matrices.  Using these estimates and arguing via the union bound (as in the proof of Theorem \ref{t:GaussCorruption}) unfortunately results in an estimate similar to \R{mRIP2}.  We also note in passing that while there exist RIP estimates for quite general matrices under the sparsity in levels model \cite{LiAdcockRIP} (see Remark \ref{r:RIPinlevels}), these unfortunately do not apply to the setup of the sparse corruptions problem.
We therefore leave the problem of improving \R{mRIP2} for future work.  
}
%\GR{
%For your information: I have tried to derive a better estimate for $\sigma_{s,k}$ by using arguments similar to those used in the proof of the standard RIP for bounded orthonormal systems.  On a high-level, these types of proofs proceed as follows: i) show that $\bbE(\sigma_{s,k}) \lesssim 1$, ii) given (i), show that $\sigma_{s,k} \leq \sigma$ with high probability.  Right now I'm stuck in one key technical detail within part (i).  Part (ii) goes through without a problem.  If you're interested I can share my notes with you.
%}


%\subsubsection{Case studies: high-dimensional polynomial approximation}
%\GR{
%We suggestion here is we give the overall results in the context of Legendre/Chebyshev polynomial approximations.
%}


%\subsubsection{Discussion}
%Unfortunately, this lemma gives that the sufficient condition for recovery in the corruptions problem of the form
%\bes{
%m \gtrsim s(s+k) \times \mbox{log factors}
%}
%which is obviously suboptimal.  The aim is to improve this to just $s+k$.  An idea is to setup a similar approach as is used to prove the RIP for BOS.


\subsection{Strategy for choosing $\lambda$}\label{ss:lambda-strategy}
Regardless of the matrix $A$, our main theorems (Theorems \ref{t:RIP_stable_robust} and \ref{t:RIP_BOS}) suggest an optimal strategy for choosing the parameter $\lambda$.  Notice that the restricted isometry constant $\delta$ enters into the measurement condition in Theorem \ref{t:RIP_BOS} as $\delta^{-2}$.  Since Theorem \ref{t:RIP_stable_robust} requires that \R{delta_cond} holds, the measurement condition contains a factor that is at least as large as 
\bes{
 1 + \left ( \frac{1}{2 \sqrt{2}} + \sqrt{\eta} \right )^2.
}
We wish to minimize this factor so as to reduce the measurement condition as much as possible.
This can be done by minimizing $\eta$, which in turn yields the theoretically-optimal scaling
\be{
\label{eq:lambda-opt}
\lambda = \sqrt{\frac{s}{k}}.
}
Notice that this gives the value $\eta = 2$.  In particular, the condition \R{delta_cond} becomes
\be{\label{eq:delta-condition-1}
\delta_{2s,2k} < \sqrt{8/33} \approx 0.492,
}
with right-hand side independent of $s$ and $k$.  We remark in passing that the choice \R{eq:lambda-opt} is implicitly made in \cite{LiCorruptionsConstrApprox}.  However, the condition given in \cite[Lem.\ 2.3]{LiCorruptionsConstrApprox} is $\delta_{2s,2k} < 1/18 \approx 0.056$  which is significantly more stringent than \R{eq:lambda-opt}.  Moreover, \cite{LiCorruptionsConstrApprox} only considers exact sparsity, whereas Theorem \ref{t:RIP_stable_robust} also treats the case of stable recovery of inexactly sparse coefficients and corruptions.

%
%We will see later that for a typical matrix $A$ to satisfy the RIP with constant $\delta$ we require $m$ to scale like $\delta^{-2}$ in terms of $\delta$.  In other words, the measurement condition contains a factor
%\bes{
% 1 + \left ( \frac{1}{2 \sqrt{2}} + \sqrt{\eta} \right )^2.
%}
%Hence, the larger $\eta$ is the worse the measurement condition.  Seeking to minimize $\eta$, we therefore set $\lambda = \sqrt{s/k}$ which gives $\eta = 2$.  In this case, we note that the condition \R{delta_cond} becomes
%\be{\label{eq:delta-condition-1}
%\delta_{2s,2k} < \sqrt{8/33} \approx 0.492.
%}
%Note that this better than Li's result, which is $\delta_{2s,2k} < 1/18 \approx 0.056$ (see Lemma 2.3 of \cite{LiCorruptionsConstrApprox}).  Moreover, Theorem \ref{t:RIP_stable_robust} applies to all values of $\lambda$, unlike Li's result, and treats inexact sparsity.

\input{results}
\input{conclusion}

\subsubsection*{Acknowledgments}
B. Adcock thanks Simone Brugiapaglia and Xiaodong Li for helpful discussions.  The authors acknowledge an anonymous referee whose report led to the investigations outlined in Remark \ref{rem:weights}.%\BLUE{I need to add my grants somewhere (possibly here), as I suspect do you as well.  For me, can you please add: ``BA and AB acknowledge the support of the Alfred P. Sloan Foundation and the Natural Sciences and Engineering Research Council of Canada through grant 611675.''.}

Sandia National Laboratories is a multimission laboratory managed and
operated by National Technology and Engineering Solutions of Sandia, LLC., a
wholly owned subsidiary of Honeywell International, Inc., for the
U.S. Department of Energy's National Nuclear Security Administration
under contract DE-NA-0003525. The views expressed in the article do not necessarily represent the views of the U.S. Department of Energy or the United States Government.

\bibliographystyle{abbrv}
\bibliography{CSCorruptionsBib}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: CSCorruptionsv1
%%% End:

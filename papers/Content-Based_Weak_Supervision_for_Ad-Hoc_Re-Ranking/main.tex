\documentclass[sigconf]{acmart}

\usepackage{booktabs} % For formal tables
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{eqnarray}
\usepackage{mathtools}
\usepackage{balance} 
\usepackage{mathrsfs}
\usepackage{multirow}
\usepackage{csquotes}
\usepackage{bbm}
\usepackage{enumitem} 
\usepackage{amsmath}
\usepackage{colortbl}
%\usepackage{arydshln}

% \usepackage{algorithmicx}
% \usepackage{algpseudocode}
% \usepackage{algorithm}
\usepackage[]{algorithm2e}
\usepackage{graphics}
\usepackage{subfigure}
\usepackage{units}
\usepackage{csquotes}
\usepackage{todonotes}

\newcommand{\paragraphHdNospace}[1] {\noindent\textbf{#1.}} % for initial headings (no extra spacing)
\newcommand{\paragraphHd}[1] {\vspace{1.2mm}\noindent\textbf{#1.}} % for subsequent headings (small space added)
\newcommand{\ra}{\renewcommand{\arraystretch}{1.2}}

\DeclareMathOperator*{\argmax}{arg\!\max}
\DeclareMathOperator*{\argmin}{arg\!\min}
\DeclareMathOperator{\Tr}{\mathit{Tr}}
\makeatletter
\def\@fnsymbol#1{\ensuremath{\ifcase#1\or *\or \dagger\or \ddagger\or
   \mathsection\or \mathparagraph\or \|\or **\or \dagger\dagger
   \or \ddagger\ddagger \else\@ctrerr\fi}}
\makeatother
 
\newcommand{\specialcell}[2][c]{%
  \begin{tabular}[#1]{@{}c@{}}#2\end{tabular}}
\newcommand{\up}{$^\blacktriangle$}
\newcommand{\dn}{$^\blacktriangledown$}
\newcommand{\greyrule}{\arrayrulecolor{black!30}\midrule\arrayrulecolor{black}}

\makeatletter
\renewcommand*\env@matrix[1][*\c@MaxMatrixCols c]{%
  \hskip -\arraycolsep
  \let\@ifnextchar\new@ifnextchar
  \array{#1}}
\makeatother

% Copyright
\copyrightyear{2019}
\acmYear{2019}
\setcopyright{acmcopyright}
\acmConference[SIGIR '19]{Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval}{July 21--25, 2019}{Paris, France}
\acmBooktitle{Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '19), July 21--25, 2019, Paris, France}
\acmPrice{15.00}
\acmDOI{10.1145/3331184.3331316}
\acmISBN{978-1-4503-6172-9/19/07}
\fancyhead{}

% \settopmatter{printacmref=false}

% These commands are optional
%\acmBooktitle{Transactions of the ACM Woodstock conference}

\begin{document}

% TODO title
% or? Improving Weak Supervision of Neural Information Retrieval Models by Modeling Query-Document Interactions
% ? Enabling the use of content-based weak supervision through interaction filtering [needs to mention NIR though?]
% ? Filtering Interactions to Improve Content-Based Weak Supervision for Neural Information Retrieval Models
% ? Improving Content-Based Weak Supervision for Neural Models through Interaction Filtering
\title{Content-Based Weak Supervision for Ad-Hoc Re-Ranking}

\author{Sean MacAvaney}
\affiliation{%
  \institution{IRLab, Georgetown University}
}
\email{sean@ir.cs.georgetown.edu}

\author{Andrew Yates}
\affiliation{%
  \institution{Max Planck Institute for Informatics}
}
\email{ayates@mpi-inf.mpg.de}

\author{Kai Hui}
\authornote{Work conducted while the author was at the Max Planck Institute for Informatics.}
\affiliation{%
  \institution{Amazon}
}
\email{kaihuibj@amazon.com}

\author{Ophir Frieder}
\affiliation{%
  \institution{IRLab, Georgetown University}
}
\email{ophir@ir.cs.georgetown.edu}

% The default list of authors is too long for headers.
% \renewcommand{\shortauthors}{S. MacAvaney et al.}

\begin{abstract}
One challenge with neural ranking is the need for a large amount of manually-labeled relevance judgments for training. In contrast with prior work, we examine the use of weak supervision sources for training that yield pseudo query-document \textit{pairs} that already exhibit relevance (e.g., newswire headline-content pairs and encyclopedic heading-paragraph pairs). We also propose filtering techniques to eliminate training samples that are too far out of domain using two techniques: a heuristic-based approach and novel supervised filter that re-purposes a neural ranker. Using several leading neural ranking architectures and multiple weak supervision datasets, we show that these sources of training pairs are effective on their own (outperforming prior weak supervision techniques), and that filtering can further improve performance.
\end{abstract}







%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below. 
%
%\begin{CCSXML}
%<ccs2012>
%<concept>
%<concept_id>10002951.10003317</concept_id>
%<concept_desc>Information systems~Information retrieval</concept_desc>
%<concept_significance>500</concept_significance>
%</concept>
%<concept>
%<concept_id>10002951.10003317.10003338.10003342</concept_id>
%<concept_desc>Information systems~Similarity measures</concept_desc>
%<concept_significance>500</concept_significance>
%</concept>
%<concept>
%<concept_id>10010147.10010257.10010258.10010260</concept_id>
%<concept_desc>Computing methodologies~Unsupervised learning</concept_desc>
%<concept_significance>500</concept_significance>
%</concept>
%</ccs2012>
%\end{CCSXML}

%\ccsdesc[500]{Information systems~Information retrieval}
%\ccsdesc[500]{Information systems~Similarity measures}
%\ccsdesc[500]{Computing methodologies~Unsupervised learning}


%\keywords{, Weak supervision}


\maketitle

% Introduction
\input{Introduction}

% Background
\input{Background}

% Method
\input{Method}
% % 
%Evaluation
\input{Evaluation}

%Related Work
%\input{Relatedwork}

% %  
%Conclusion
\input{Conclusion}

\bibliographystyle{ACM-Reference-Format}
\bibliography{main}

\end{document}

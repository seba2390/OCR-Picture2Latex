\section{Method} 
\label{sec.method}

\subsection{Ranking- and content-based sources}\label{sec.source}

Recall that pairwise training consists of a set of training triples, each consisting of a query $q$, relevant document $d^+$, and non-relevant document $d^-$. We describe two sources of weak supervision training data that replace human-generated relevance judgments: ranking-based and content-based training sources.

\textbf{Ranking-based training sources}, first proposed by \cite{dehghani2017neural}, are defined by a collection of texts $T$, a collection of documents $D$, and an unsupervised ranking function $R(q,d)$ (e.g., BM25). Training triples are generated as follows. Each text is treated as a query $q\in T$. All documents in $D$ are ranked using $R(\cdot)$, giving $D^q$. Relevant documents are sampled using a cutoff $c^+$, and non-relevant documents are sampled using cutoff $c^-$, such that $d^+\in D^q[0:c^+]$ and $d^-\in D^q[c^+:c^-]$. This source is referred to as ranking-based because the unsupervised ranker is the source of relevance.\footnote{Our formulation of ranking-based sources is slightly different than what was proposed by \citet{dehghani2017neural}: we use cutoff thresholds for positive and negative training samples, whereas they suggest using random pairs. Pilot studies we conducted showed that the threshold technique usually performs better.}

\textbf{Content-based training sources} are defined as a collection of text pairs $P=\{(a_1,b_1),(a_2,b_2),...,(a_{|P|},b_{|P|})\}$ and an unsupervised ranking function $R(q,d)$ (e.g., BM25). The text pairs should be semantically related pairs of text, where the first element is similar to a query, and the second element is similar to a document in the target domain. For instance, they could be heading-content pairs of news articles (the headline describes the content of the article content). For a given text pair, a query and relevant document are selected $(q,d^+)\in P$. The non-relevant document is selected from the collection of documents in $B=\{b_1,b_2,...,b_{|P|}\}$. We employ $R(\cdot)$ to select challenging negative samples from $B^q$. A negative cutoff $c^-$ is employed, yielding negative document $d^-\in B^q[0:c^-]-\{d^+\}$. We discard positive samples where $d^+$ is not within this range to eliminate overtly non-relevant documents. This approach can yield documents relevant to $q$, but we assert that $d^+$ is \textit{more} relevant.

Although ranking-based and content-based training sources bear some similarities, important differences remain. Content-based sources use text pairs as a source of positive relevance, whereas ranking-based sources use the unsupervised ranking. Furthermore, content-based sources use documents from the pair's domain, not the target domain. We hypothesize that the enhanced notion of relevance that content-based sources gain from text pairs will improve ranking performance across domains, and show this in Section~\ref{sec.evaluation}.






\subsection{Filter framework}\label{sec.method.filters}
We propose a filtering framework to overcome domain mismatch that can exist between data found in a weak supervision training source and data found in the target dataset. The framework consists of a filter function $F_D(q,d)$ that determines the suitability of a given weak supervision query-document pair $(q,d)$ to the domain $D$. All relevant training pairs $(q,d^+)\in S$ for a weak supervision source $S$ are ranked using $F_D(q,d^+)$ and the $c_{max}$ maximum pairs are chosen: $
S_D=\max^{c_{max}}_{(q,d^+)\in S}F_D(q,d^+)
$. To tune $F_D(\cdot)$ to domain $D$, a set of \textit{template pairs} from the target domain are employed. The set of pairs $T_D$ % =\{(q^D_1,d^D_1),(q^D_2,d^D_2),...,(q^D_{|T_D|},d^D_{|T_D|})\}
is assumed to be relevant in the given domain.\footnote{Templates do not require human judgments. We use sample queries and an unsupervised ranker to generate $T_D$. Manual judgments can be used when available.} We assert that these filters are easy to design and can have broad coverage of ranking architectures. We present two implementations of the filter framework: the $k$max filter, and the Discriminator filter.

\textbf{$k$-Maximum Similarity ($k$max) filter.}
This heuristic-based filter consists of two components: a \textit{representation function} $\mathit{rep}(q,d)$ and a \textit{distance function} $\mathit{dist}(r_1,r_2)$.
The representation function captures some matching signal between query $q$ and document $d$ as a vector. Since many neural ranking models consider similarity scores between terms in the query and document to perform soft term matching~\cite{hui2017pacrr,convknrm,xiong2017end,guo2016deep}, this filter selects the $k$ maximum cosine similarity scores between the word vectors of each query term and all terms in the document:
$\max_{d_j\in d}^ksim(q_i, d_j) : \forall q_i \in q$.

Since neural models can capture local patterns (e.g., n-grams), we use an aligned mean square error. The aligned MSE iterates over possible configurations of elements in the representation by shifting the position to find the alignment that yields the smallest distance. In other words, it represents the minimum mean squared error given all rotated configurations of the query.
Based on the shift operation and given two interaction representation matrices $r_1$ and $r_2$,
the aligned $\mathit{dist}_{kmax}(r_1,r_2)$ is defined as 
the minimum distance when shifting $r_1$ for $s\in [1, |r_1|)$.
More formally: $\mathit{dist}_{kmax}(r_1,r_2) = \min_{s=1}^{|r_1|}{\mathit{MSE}\big(\mathit{shift}(r_1, s),r_2\big)}$.

Using these two functions, the filter is simply defined as the minimum distance between the representations of it and any template pair from the target domain:

\vspace{-1.2em}\begin{equation}\label{eq.dist.drmm}
F_D(q,d)=\min_{(q',d')\in T_D}dist(rep(q,d),rep(q',d'))
\end{equation}\vspace{-0.8em}

\textbf{Discriminator filter.}
A second approach to interaction filtering is to use the ranking architecture $R$ itself. Rather than training $R$ to distinguish different degrees of relevance, here we use $R$ to train a model to distinguish between samples found in the weak supervision source and $T_D$. This technique employs the same pairwise loss approach used for relevance training and is akin to the discriminator found in generative adversarial networks. Pairs are sampled uniformly from both templates and the weak supervision source. Once $R_D$ is trained, all weak supervision training samples are ranked with this model acting as $F_D(\cdot)=R_D(\cdot)$.

The intuition behind this approach is that the model should learn characteristics that distinguish in-domain pairs from out-of-domain pairs, but it will have difficulty distinguishing between cases where the two are similar. One advantage of this approach is that it allows for training an interaction filter for any arbitrary ranking architecture, although it requires a sufficiently large $T_D$ to avoid overfitting.

















% Description/Definition/Formulation
%   1. interface human understanding
%   2. No gradient update v.s. Finetuning
%   3. 从context learning
%   4. strengths, reasoning zero-shot human readable
%   5. weakness (a)unstable(order，distribution，token) (b)need large model (3)inference efficiency with long context ， (4) limited training data（max\_seq\_len）

% 第一段 写一下 背景
% Prompt 那个是从 superivised -> pre-training finetuning -> prompt engineering 切入的
% ICL ability emerges from pretraining of large LM. 
% First proposed in GPT-3
With the scaling of model size and corpus size~\citep{bert,gpt2,gpt3,chowdhery2022palm}, large language models (LLMs) demonstrate an in-context learning (ICL) ability, that is, learning from a few examples in the context. 
% (in-context learning for short). 
Many studies have shown that LLMs can perform a series of complex tasks through ICL, such as solving mathematical reasoning problems~\citep{cot}. These strong abilities have been widely verified as emerging abilities for large language models~\citep{wei2022emergent}. 

%Figure~\ref{fig:icl} gives an example describing how language models make decisions under ICL. 

 %These strong abilities have been widely verified as the emerging abilities for large language models~\citep{wei2022emergent}. 
 
 %It shows that the model learns from the demonstration consisting of a few examples in the context
% For example, by feeding the model with translation text pair from the source language to the target and a sentence that needs to be translated, the model could accurately produce a translation for the given query.



% sec1. lei增加general 定义，当前主要问题和研究现状 contribution insight 
% sec2. lei补充formulation inference的各种变种的formulatioin 加table

% The development of pre-trained language models, such as BERT~\citep{bert} and GPT-2~\citep{gpt2} leads to a widely-adopted paradigm where the model is first trained on the general corpus, then finetuned on task-specific datasets for improving the in-domain performance, such as the classification accuracy.
% The idea behind this is to learn rich contextual representations of languages from free text.
% Further explorations in this direction scale up the number of causal language model parameters and tokens of training corpus, resulting in surprising few-shot learning abilities, i.e., the model can learn from the demonstration with a few examples in the context to perform a series of complex tasks, such as solving mathematical reasoning problems. 
% This ability is called in-context learning~(ICL) by \citet{gpt3} and shows great potential in a wide range of tasks, attracting great attention from the community~\citep{metaicl}.

% Informal definition, acutally, illustrate the process of ICL 
The key idea of in-context learning is to learn from analogy. Figure~\ref{fig:icl} gives an example describing how language models make decisions with ICL.  %and we illustrate the whole process in Figure~\ref{fig:icl}. 
First, ICL requires a few examples to form a demonstration context. These examples are usually written in natural language templates. 
%a few examples are first picked and represented in natural language tokens according to specific templates and order to form a demonstration context. 
%Second, the question of interest is also converted in a similar way after the demonstration text 
Then, ICL concatenates a query question and a piece of demonstration context together to form a prompt,  which is then fed into the language model for prediction.
Different from supervised learning requiring a training stage that uses backward gradients to update model parameters, ICL does not conduct parameter updates and directly performs predictions on the pretrained language models. The model is expected to learn the pattern hidden in the demonstration and accordingly make the right prediction. % The inference is performed in the form of text completion by reusing the language model head learned during the large-scale pretraining.
%If required, the predictions are transformed into an answer according to a pre-defined rule. \zy{the last sentence is kinda too detailed and unnecessary?}%, where the model performance is evaluated on. 
% We summarize the key characteristics of ICL and comparison with traditional finetuning in Figure~\ref{fig:my_label}.
% http://ai.stanford.edu/blog/in-context-learning : What is in-context learning? Informally, in-context learning describes a different paradigm of “learning” where the model is fed input normally as if it were a black box, and the input to the model describes a new task with some possible examples while the resulting output of the model reflects that new task as if the model had “learned”. While imprecise, the term is meant to capture common behavior that was noted in the GPT-3 paper by OpenAI as a phenomenon that GPT-3 displayed with surprising consistency.


% \section{Definition of In-Context Learning~(ICL)}
% Definition of ICL 


\begin{figure}[t]
    \centering
    \includegraphics[width=0.45\textwidth]{fig/icl.pdf}
    \caption{Illustration of in-context learning. ICL requires a piece of demonstration context containing a few examples written in  natural language templates. Taking the demonstration and a query as the input, large language models are responsible for making predictions.}
    \label{fig:icl}
\end{figure}

\input{arxiv/taxonomy.tex}
% Pros & Cons  of ICL 
% Understandable
% \leiModify{Emphasize importance, e.g., difference with finetuning}
% The characteristics of ICL have obvious advantages. 
As a new paradigm, ICL has multiple attractive advantages. %ICL opens new directions for natural language processing research.
First, since the demonstration is written in natural language, it provides an interpretable interface to communicate with LLMs~\citep{gpt3}.
This paradigm makes it much easier to incorporate human knowledge into LLMs by changing the demonstration and templates~\citep{liu2022close,lu2022order,Wu2022SelfadaptiveIL,cot}. Second, in-context learning is similar to the decision process of human beings by learning from analogy~\citep{winston1980learningByAnalogy}. %, i.e., a human makes a prediction based on a few instructions and utilizes the experience from the past to generalize to new tasks.\zy{learning by analogy (ju yi fan san)} 
Third, compared with supervised training, ICL is a training-free learning framework. %ICL is data-efficient This high data efficiency of ICL makes this paradigm more ideal than previous data-hungry tuning methods for low-resource applications and scenarios~\citep{calibrate}. 
% Computation Efficiency 
%Finally, unlike the traditional supervised learning paradigm, which requires parameter updates on the model, there is no gradient computation in ICL. 
This could not only greatly reduce the computation costs for adapting the model to new tasks, but also make language-model-as-a-service~\citep{sun2022black} possible and can be easily applied to large-scale real-world tasks. % and can be easily applied to large-scale real-world tasks
% LMasA


% Directions and limitations?
% Advantage ->  Importance  
% Previous paradigm cannot solve. 
Despite being promising, there are also interesting questions and intriguing properties that require further investigation in ICL.
While the vanilla GPT-3 model itself shows promising ICL abilities, several studies  observed that the ability could be significantly boosted via adaption during pretraining~\citep{metaicl,chen2022sensitivity}.
In addition, the performance of ICL is sensitive to specific settings, including the prompting template, the selection of in-context examples, and order of examples, and so on~\citep{calibrate}. Furthermore, while intuitively reasonable, the working mechanism of the ICL remains unclear, and few studies have provided preliminary explanations~\citep{dai2022iclft,icl_gd}.
% Why we need this in-context learning survey 

% Our paper aims to sensitize the NLP community
% towards this growing area of work

With the rapid growth of studies in ICL, our survey aims to sensitize the community toward the current progress.
Specifically, we present a detailed paper survey with a paper list that will be continuously updated, and make an in-depth discussion on related studies of ICL. We highlight the challenges and potential directions and hope our work may provide a useful roadmap for beginners interested in this area and shed light on future research.

% \leiModify{this part seems too short? maybe elaborate more on the importance of this survey paper for the rapidly developing field, and the resource we could provide for the community.}
% % Directions current 
% \begin{figure}[t]
%     \centering
%     \includegraphics[width=0.9\linewidth]{fig/icl_process.pdf}
%     \caption{Main procedures of in-context learning. Pretraining is significant for developing the ICL ability of LLMs and the optional warmup stage can further improve it. For the demonstrations, the most important procedure is demonstration designing. With a pretrained LLM and a well-designed demonstration, a proper scoring strategy finally yield the task output.}
%     \label{fig:icl_process}
% \end{figure}

\section{Overview}
% \qingxiu{Modifying...}
%As illustrated in Figure~\ref{taxo_of_icl}, 
The strong performance of ICL relies on two stages: (1) the training stage that cultivates the ICL ability of LLMs, and (2) the inference stage where LLMs predict according to task-specific demonstrations.
%In terms of the training stage, pretraining is significant for bringing up the ICL ability and the optional warmup can further improve the ICL ability.
%In terms of the training stage, the language models are pre-trained with 
In terms of the training stage, LLMs are directly trained on language modeling objectives, such as left-to-right generation. Although the models are not specifically optimized for in-context learning, they still exhibit the ICL ability.
% \leiModify{the logic here seems not very clear?} 
Existing studies on ICL basically take a well-trained LLM as the backbone, and thus this survey will not cover the details of pretraining language models. 
Towards the inference stage, as the input and output labels are all represented in interpretable natural language templates, there are multiple directions for improving ICL performance. This paper will give a detailed description and comparison, such as selecting suitable examples for demonstrations and designing specific scoring methods for different tasks.
%Given a pretrained LLM and a well-designed demonstration, various scoring methods can be adopted for particular tasks.
% As illustrated in Fig.~\ref{fig:icl_process}, the LLM and the demonstration are two crucial components of ICL.
% In terms of the LLM, the pretraining stage is significant for bringing up the ICL ability and the optional warmup stage can further improve the ICL ability.
% Towards the demonstrations, as the input and output labels are all represented in interpretable language tokens, humans could design better promptings strategies such as selecting suitable examples for demonstrations and decomposing the reasoning procedure in text for hinting the model.
% Given a pretrained LLM and a well-designed demonstration, various scoring methods can be adopted for particular tasks.
% ICL consists of four main stages: (1) LLMs pretraining that ; (2) optional model warm-up that; (3) demonstration designing that (4) scoring. The main procedures are 
% detection to identify claims that require verification; (ii) evidence retrieval to find sources
% supporting or refuting the claim; and (iii) claim
% verification to assess the veracity of the claim
% based on the retrieved evidence. 
%With the formulation, 
% We notice that there are important components in the framework. 
% First, the core of in-context learning is the model itself, whose model scale and pretraining corpus have a great influence on the final prediction performance.
% % We discuss various model training techniques for improving the ICL ability of the model proposed in \S~\ref{sec:warmup}.
% Besides, as the input and output labels are all represented in interpretable language tokens, humans could design better promptings strategies such as selecting suitable examples for demonstrations and decomposing the reasoning procedure in text for hinting the model.
% % which we provide an overview of current progress in \S\ref{sec:prompt_designing}. 

% \leiModify{How to connect to the rest parts of this paper?}

% Structure of this paper
% With the rapid development of ICL,
We organize the current progress in ICL following the taxonomy above (as shown in Figure~\ref{taxo_of_icl}). 
With a formal definition of ICL~(\S\ref{sec:formulation}), 
% by providing a comprehensive
% birds-eye view of the area and formal definition of in-context learning methods~(\S\ref{sec:formulation}).
we provide a detailed discussion of the warmup approaches~(\S\ref{sec:warmup}), the demonstration designing strategies (\S\ref{sec:prompt_tuning}), and the main scoring functions(\S\ref{sec:scoring}). \S\ref{sec:analysis} provides in-depth discussions of current explorations on unveiling the secrets behind the ICL. 
We further provide useful evaluation and resources for ICL~(\S\ref{sec:evaluation}) and introduce potential application scenarios where ICL shows its effectiveness~(\S\ref{sec:application}).
Finally, we summarize the challenges and potential directions~(\S\ref{sec:challege_future}) and hope this could pave the way for researchers in this field.
% In this paper, we present a curated survey on the related studies of in-context learning, to give a comprehensive
% birds-eye view of the area.

% Remove Structure 
% The paper is structured as follows:
% We discuss the related work in 
% \S\ref{sec:related}, by categorising the ICL methods into three types. 
% Furthermore, we introduce the prompting strategies of ICL in \S\ref{sec:approach}, as the the design of in-context demonstrations has a great impact on the model performance. Finally, we point out several challenges and future directions to facilitate the community in \S\ref{sec:impact}.

% Rosy
In this section, we review some of the existing challenges and propose possible directions for future research on ICL.
\subsection{New Pretraining Strategies}
As investigated by~\citet{corpusscale}, language model objectives are not equal to   ICL abilities. Researchers have proposed to bridge the gap between pretraining objectives and ICL through intermediate tuning before inference (Section~\ref{sec:warmup}), which shows promising performance improvements. To take it further, tailored pretraining objectives and metrics for ICL have the potential to raise LLMs with superior ICl capabilities.
% \subsection{New Evaluation Paradigm}
% \label{challenge: evaluation}
% As ICL is a new paradigm varies from traditional finetuning paradigm in many aspects,
% %such as training data scale and model parameter updating, 
% the evaluation of ICL presents a new set of challenges and opportunities.

% Towards the challenges, the results of existing evaluation methods are sensitive. \citet{chen2022relation} observed that existing evaluations by accuracy underestimate the sensitivity towards instruction perturbation of ICL.
% It is still an open question to conduct consistent ICL evaluation.
% Apart from that, traditional evaluation benchmarks such as SuperGLUE~\cite{superglue} are less challenging for LLMs with billions of parameters, and even the sophisticated designed new benchmark, BigBench~\cite{beyond} can be readily surpassed.
% How to construct a challenging evaluation with long-term vitality is crucial for ICL evaluation.
% %A dangerous phenomenon for ICL evaluation is that pretraining data leakage, that is, the test data is difficult to circumvent data leakage during pretraining.
% %This pose new challenges to trustworthy evaluation on ICL.

% Towards the opportunities for evaluation, as ICL only requires a few instances for the demonstration, it lowers the cost for evaluation data construction. On the one hand, this makes it possible to evaluate on some tasks whose data is tedious to construct or needs experts to annotate. On the other hand, the test set is still supposed to faithfully reflect the world distribution. 
% Instead of the i.i.d. assumption with the training set, the test set requires new constraints.
% \leiModify{But the evaluation set is still supposed to faithfully reflect the world distribution.}


\subsection{ICL Ability Distillation}
Previous studies have shown that in-context learning for reasoning tasks emerges as the scale of computation and parameter exceed a certain threshold~\citep{wei2022emergent}. Transferring the ICL ability to smaller models could facilitate the model deployment greatly.
\citet{distill2smallmodel} showed that it is possible to distill the reasoning ability to small language models such as T5-XXL. The distillation is achieved by finetuning the small model on the chain-of-thought data~\citep{cot} generated by a large teacher model. 
%, with the question as input and the CoT process along with the answer as the target
Although promising performance is achieved, %for example, the accuracy
%of T5-XXL on GSM8K improves from 8.11\%
%to 21.99\%, 
the improvements are likely task-dependent.
Further investigation on improving the reasoning ability by learning from larger LLMs could be an interesting direction.
% \subsection{Instance-level Selection}
% % \leiModify{TODO: ce\&zhiyong}
% Preliminary exploration~\cite{Wu2022SelfadaptiveIL} has shown the enormous promise of instance-level ICL, which has the potential to bridge the performance gap between ICL and finetuning. However, the search for the best demonstration organization at the instance-level is essentially an NP-hard combinatorial optimization problem. To tackle the problem of massive search space, we need specialized yet efficient algorithms (e.g., a learned example retriever) that can quickly rule out large parts of the search space. The designing of such algorithms is difficult since they require sequential decision-making, which makes applying reinforcement learning in the design attractive.
\subsection{ICL Robustness}
Previous studies have shown that ICL performance is extremely unstable, from random guess to SOTA, and can be sensitive to many factors, including demonstration permutation, demonstration format, etc.~\citep{calibrate, lu2022order}. 
The robustness of ICL is a critical yet challenging problem. 

However, most of the existing methods fall into the dilemma of accuracy and robustness~\cite{chen2022sensitivity}, or even at the cost of sacrificing inference efficiency. To effectively improve the robustness of ICL, we need deeper analysis of the working mechanism of the ICL. We believe that the analysis of the robustness of the ICL from a more theoretical perspective rather than an empirical perspective can highlight future research on more robust ICL.

\subsection{ICL Efficiency and Scalability}
ICL necessitates prepending a significant number of demonstrations within the context. However, it presents two challenges: (1) the quantity of demonstrations is constrained by the maximum input length of LMs, which is significantly fewer compared to fine-tuning (scalability); (2) as the number of demonstrations increases, the computation cost becomes higher due to the quadratic complexity of attention mechanism (efficiency). Previous work in \S\ref{sec:demo} focused on exploring how to achieve better ICL performance using a limited number of demonstrations and proposed several demonstration designing strategies. Scaling ICL to more demonstrations and improving its efficiency remains a challenging task.


Recently, some works have been proposed to address the issues of scalability and efficiency of ICL. Efforts were made to optimize prompting strategies with structured prompting~\citep{hao2022structured}, demonstration ensembling~\citep{khalifa2023exploring}, dynamic prompting~\citep{zhou2023efficient}, and iterative forward tuning~\citep{yang2023iterative}. Additionally, \citet{li2023context} proposed EVaLM with longer context length and enhanced long-range language modeling capabilities. This model-level improvement aims to improve the scalability and efficiency of ICL. As LMs continue to scale up, exploring ways to effectively and efficiently utilize a larger number of demonstrations in ICL remains an ongoing area of research.



%To address this problem, \citet{chen2022sensitivity} defined a metric for ICL called prediction sensitivity, which measures the changes in the model output in response to small input perturbations. 
%They found an obvious negative correlation between prediction sensitivity and ICL accuracy. Motivated by this finding, they proposed a selective prediction method based on prediction sensitivity. Unlike this study, \citet{Chang2022CarefulDC} focused on selecting stable demonstrations.
%, which means the ICL performance on different orderings of these demonstrations has a low variance and a high worst-case and average performance. 
%They assigned training examples with scores about stability and proposed two scoring methods. The first scoring combines an example with random training examples and gets the average ICL performance as its score. Another method learns a linear proxy model to estimate how an example influences ICL performance.

%We hope to see more stable and robust ICL methods in the future because stable and robust ICL makes it easier to construct demonstrations without being overly concerned with influencing factors such as order. 
% \subsection{Working Mechanism}
% Understanding the working mechanism of ICL is an inevitable step to trust ICL and further improve it. 
% Although some analytical work has taken a preliminary step to explain ICL, most of them is limited to simple tasks and small models. 
% Extending analysis on extensive tasks and real large models may be the next step to be considered. 
% In addition, among existing work, understanding ICL as a process of meta-optimization seems to be a reasonable and promising direction for future research. 
% If we build clear connections between ICL and meta-optimization, we can improve ICL with a purpose by learning from the history of finetuning and optimization. 

% \subsection{ICL for Data Engineering}
% %Cost and quality have been two conflicting aspects of data engineering. 
% ICL has manifested the potential to be widely applied in data engineering. 
% Benefiting from the strong ICL ability,  it costs 50\% to 96\% less to use labels from GPT-3 than using labels from humans for data annotation. Combining pseudo labels from GPT-3 with human labels leads to even better performance at a small cost~\cite{want}.
% In more complex scenarios, such as knowledge graph construction, \citet{khorashadizadeh2023exploring} has demonstrated that ICL has the potential to significantly improve the state of the art of automatic construction and completion of knowledge graphs, resulting in a reduction in manual costs with minimal engineering effort. Therefore, leveraging the capabilities of ICL in various data engineering applications can yield significant benefits.
% Compared to human annotation (e.g., crowd-sourcing) or noisy automatic annotation (e.g., distant supervision), ICL generates relatively high quality data at a low cost. 
% First, ICL takes only a few examples to learn the data engineering objective, which saves the cost of annotating training data. Second, the strong reasoning ability and text-generating ability of LLM show great potential to generate high-quality data.

% However, how to use ICL for data annotation remains an open question. For example, ~\citet{annotation} performed a comprehensive analysis and found that generation-based methods are more cost-effective in using GPT-3 than annotating unlabeled data via ICL.
% We believe that improving ICL for data annotation is a direction with practical value, and ICL will be a new paradigm in data annotation, data augmentation, data pruning, as well as adversarial data generation.

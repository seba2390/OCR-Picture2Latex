% ICL for traditional NLP tasks (dialogue)
\label{app}
%Due to the human-friendly interface lightweight prompting advantages, ICL has been widely applied in various scenarios recently.

ICL manifests excellent performance on traditional NLP tasks and methods~\cite{kim2022self,metaicl}, such as machine translation~\cite{zhu2023multilingual,sia2023context}, information extraction~\cite{wan2023gpt,he2023icl} and text-to-SQL~\cite{pourreza2023din}.
% tasks
%And ICL manifests excellent performance in various task
%, such as sentiment classification natural language inference~\cite{kim2022self}. 
Especially, through demonstrations that explicitly guide the process of reasoning, ICL manifests remarkable effects on tasks that require complexity reasoning~\cite{cot,li2023code,teachalgo} and compositional generalization~\cite{least}. 
% methods
% ~\citet{chen2021meta} applies ICL for meta-learning. 

Moreover, ICL offers potential for popular methods such as meta-learning and instruction-tuning. \citet{chen2021meta} applied ICL to meta-learning, adapting to new tasks with frozen model parameters, thus addressing the complex nested optimization issue. \cite{ye2023context} enhanced zero-shot task generalization performance for both pretrained and instruction-finetuned models by applying in-context learning to instruction learning. 

Specifically, we explore several emerging and prevalent applications of ICL, showcasing their potential in the following paragraphs.
% ICL for model editing.


% ICL for data engineering
% \paragraph{Data Engineering} What's more, ICL has manifested the potential to be widely applied in data engineering. 
% Benefiting from the strong ICL ability,  it costs 50\% to 96\% less to use labels from GPT-3 than using labels from humans for data annotation. Combining pseudo labels from GPT-3 with human labels leads to even better performance at a small cost~\cite{want}.
% In more complex scenarios, such as knowledge graph construction, \citet{khorashadizadeh2023exploring} has demonstrated that ICL has the potential to significantly improve the state of the art of automatic construction and completion of knowledge graphs, resulting in a reduction in manual costs with minimal engineering effort. Therefore, leveraging the capabilities of ICL in various data engineering applications can yield significant benefits.
\paragraph{Data Engineering}
ICL has manifested the potential to be widely applied in data engineering. 
Benefiting from the strong ICL ability,  it costs 50\% to 96\% less to use labels from GPT-3 than using labels from humans for data annotation. Combining pseudo labels from GPT-3 with human labels leads to even better performance at a small cost~\cite{want}.
In more complex scenarios, such as knowledge graph construction, \citet{khorashadizadeh2023exploring} has demonstrated that ICL has the potential to significantly improve the state of the art of automatic construction and completion of knowledge graphs, resulting in a reduction in manual costs with minimal engineering effort. Therefore, leveraging the capabilities of ICL in various data engineering applications can yield significant benefits.
Compared to human annotation (e.g., crowd-sourcing) or noisy automatic annotation (e.g., distant supervision), ICL generates relatively high quality data at a low cost. 
% First, ICL takes only a few examples to learn the data engineering objective, which saves the cost of annotating training data. Second, the strong reasoning ability and text-generating ability of LLM show great potential to generate high-quality data.
However, how to use ICL for data annotation remains an open question. For example, ~\citet{annotation} performed a comprehensive analysis and found that generation-based methods are more cost-effective in using GPT-3 than annotating unlabeled data via ICL.

% \paragraph{Model Probing} 
% Apart from ICL, linear probing is another way of black-box tuning~\citep{sun2022black} for LLMs, which learns a linear classifier based on final representations of LLMs and is suitable for full-data settings. \citet{cho2022prompt} propose prompt-augmented linear probing, a hybrid of linear probing and ICL. They train a linear classifier based on representations enhanced with prepend additional demonstrations. The hybrid of ICL and linear probing can cover the weakness of each other and scale the ICL to the full-data setting.

% \paragraph{Retrieval-Augmented Models} 
\paragraph{Model Augmentating} The context-flexible nature of ICL demonstrates significant potential to enhance retrieval-augmented methods. By keeping the LM architecture unchanged and prepending grounding documents to the input, in-context RALM\citet{ram2023context} effectively utilizes off-the-shelf general-purpose retrievers, resulting in substantial LM gains across various model sizes and diverse corpora. Furthermore, ICL for retrieval also exhibits the potential to improve safety. In addition to efficiency and flexibility, ICL also shows potential in safety~\cite{dpicl}, \cite{meade2023using} use ICL for retrieved demonstrations to steer a model towards safer generations, reducing bias and toxicity in the model.

\paragraph{Knowledge Updating}
LLMs may contain outdated or incorrect knowledge, but ICL demonstrates the potential for effectively editing and updating this information. In an initial trial, \citet{reliable} found that GPT-3 updated its answers 85\% of the time when provided with counterfactual examples, with larger models performing better at in-context knowledge updating. However, this approach may impact other correct knowledge in LLMs.
Compared to knowledge editing for fine-tuned models~\cite{editingfact}, ICL has proven effective for lightweight model editing. \citet{reliable} explored the possibility of editing LLMs' memorized knowledge through in-context demonstrations, discovering that a larger model scale and a mix of demonstration examples improved ICL-based knowledge editing success rates. In a comprehensive study, \citet{ike} investigated ICL strategies for editing factual knowledge, finding that well-designed demonstrations enabled competitive success rates compared to gradient-based methods, with significantly fewer side effects. This underlines the potential of ICL for knowledge editing.
% \subsection{Knowledge Augmentation and Updating}
 % ICL presents new issues for enhancing and updating knowledge in LLMs.
% knowledge augmentation
% The knowledge of LLMs is entirely derived from the pretrained corpus. Therefore, LLMs may lack certain knowledge and generate hallucinations during ICL inference, especially towards long-tailed factual knowledge or commonsense knowledge rarely described in texts.
% Therefore, it is essential to augment knowledge for ICL.
% Different from traditional work, which adds knowledge adapters~\cite{kadapter} or provides structured knowledge during pretraining~\cite{zhang_2019_ernie,peters_2019_knowledge},
% retrieving correct knowledge and integrating the correct knowledge with the context in a lightweight manner is possibly promissing for ICL.
% knowledge updating or calibration
% Although LLMs can serve as knowledge bases, 
% The knowledge in LLMs could be wrong or out-of-date, and ICL can be applied to edit or update the knowledge for more factual generations.
% ~\citet{reliable} made an initial trial on in-context knowledge updating. By providing counterfactual examples in the demonstration, they found that GPT-3 updates its answers around 85\% of the time and larger models are better at in-context knowledge updating. 
% However, this approach may affect other correct knowledge in LLMs. Compared with knowledge editing for finetuned models~\cite{editingfact},  
% ICL has shown effectiveness for lightweight model editing. \citet{reliable} analyzed whether it is possible to edit or adapt memorized knowledge in LLMs to new information through in-context demonstrations. They found that a large model scale and a mixture of all types of demonstration examples strengthen the knowledge editing success rate of ICL. In a comprehensive empirical study, \citet{ike} examined ICL strategies for editing factual knowledge and found that well-designed demonstrations enabled in-context knowledge editing to achieve a competitive success rate compared to gradient-based methods, but with significantly fewer side effects. This highlights the potential of ICL for knowledge editing.
% the impact of in-context knowledge updating on paraphrased facts and irrelevant facts has not been rigorously evaluated. 
% However, ICL for knowledge editing still faces challenges such as over-editing or multihop editing, which require further exploration.


%  template.tex for Biometrics papers
%
%  This file provides a template for Biometrics authors.  Use this
%  template as the starting point for creating your manuscript document.
%  See the file biomsample.tex for an example of a full-blown manuscript.

%  ALWAYS USE THE referee OPTION WITH PAPERS SUBMITTED TO BIOMETRICS!!!
%  You can see what your paper would look like typeset by removing
%  the referee option.  Because the typeset version will be in two
%  columns, however, some of your equations may be too long. DO NOT
%  use the \longequation option discussed in the user guide!!!  This option
%  is reserved ONLY for equations that are impossible to split across 
%  multiple lines; e.g., a very wide matrix.  Instead, type your equations 
%  so that they stay in one column and are split across several lines, 
%  as are almost all equations in the journal.  Use a recent version of the
%  journal as a guide. 
%  
\documentclass[useAMS,usenatbib,referee]{biom}
%documentclass[useAMS]{biom}
%
%  If your system does not have the AMS fonts version 2.0 installed, then
%  remove the useAMS option.
%
%  useAMS allows you to obtain upright Greek characters.
%  e.g. \umu, \upi etc.  See the section on "Upright Greek characters" in
%  this guide for further information.
%
%  If you are using AMS 2.0 fonts, bold math letters/symbols are available
%  at a larger range of sizes for NFSS release 1 and 2 (using \boldmath or
%  preferably \bmath).
% 
%  Other options are described in the user guide. Here are a few:
% 
%  -  If you use Patrick Daly's natbib  to cross-reference your 
%     bibliography entries, use the usenatbib option
%
%  -  If you use \includegraphics (graphicx package) for importing graphics
%     into your figures, use the usegraphicx option
% 
%  If you wish to typeset the paper in Times font (if you do not have the
%  PostScript Type 1 Computer Modern fonts you will need to do this to get
%  smoother fonts in a PDF file) then uncomment the next line
%  \usepackage{Times}

%%%%% PLACE YOUR OWN MACROS HERE %%%%%

\def\bSig\mathbf{\Sigma}
\newcommand{\VS}{V\&S}
\newcommand{\tr}{\mbox{tr}}

%  The rotating package allows you to have tables displayed in landscape
%  mode.  The rotating package is NOT included in this distribution, but
%  can be obtained from the CTAN archive.  USE OF LANDSCAPE TABLES IS
%  STRONGLY DISCOURAGED -- create landscape tables only as a last resort if
%  you see no other way to display the information.  If you do do this,
%  then you need the following command.

%\usepackage[figuresright]{rotating}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{threeparttable}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%  Here, place your title and author information.  Note that in 
%  use of the \author command, you create your own footnotes.  Follow
%  the examples below in creating your author and affiliation information.
%  Also consult a recent issue of the journal for examples of formatting.

\title[Utilizing a Capture-Recapture Strategy to Accelerate Infectious Disease Surveillance]{Utilizing a Capture-Recapture Strategy to Accelerate Infectious Disease Surveillance}

%  Here are examples of different configurations of author/affiliation
%  displays.  According to the Biometrics style, in some instances,
%  the convention is to have superscript *, **, etc footnotes to indicate 
%  which of multiple email addresses belong to which author.  In this case,
%  use the \email{ } command to produce the emails in the display.

%  In other cases, such as a single author or two authors from 
%  different institutions, there should be no footnoting.  Here, use
%  the \emailx{ } command instead. 

%  The examples below corrspond to almost every possible configuration
%  of authors and may be used as a guide.  For other configurations, consult
%  a recent issue of the the journal.

%  Single author -- USE \emailx{ } here so that no asterisk footnoting
%  for the email address will be produced.

%\author{John Author\emailx{email@address.edu} \\
%Department of Statistics, University of Warwick, Coventry CV4 7AL, U.K.}

%  Two authors from the same institution, with both emails -- use
%  \email{ } here to produce the asterisk footnoting for each email address

%\author{John Author$^{*}$\email{author@address.edu} and
%Kathy Authoress$^{**}$\email{email2@address.edu} \\
%Department of Statistics, University of Warwick, Coventry CV4 7AL, U.K.}

%  Exactly two authors from different institutions, with both emails  
%  USE \emailx{ } here so that no asterisk footnoting for the email address
%  is produced.

% \author
% {John Author\emailx{author@address.edu} \\
% Department of Statistics, University of Warwick, Coventry CV4 7AL, U.K. 
% \and
% Kathy Author\emailx{anotherauthor@address.edu} \\
% Department of Biostatistics, University of North Carolina at Chapel Hill, 
% Chapel Hill, North Carolina, U.S.A.}

%  Three or more authors from same institution with all emails displayed
%  and footnoted using asterisks -- use \email{ } 

%\author{John Author$^*$\email{author@address.edu}, 
%Jane Author$^{**}$\email{jane@address.edu}, and 
%Dick Author$^{***}$\email{dick@address.edu} \\
%Department of Statistics, University of Warwick, Coventry CV4 7AL, U.K}

%  Three or more authors from same institution with one corresponding email
%  displayed

\author{Lin Ge$^*$\email{lge\_biostat@outlook.com}, 
Yuzi Zhang, Lance A. Waller, and Robert H. Lyles \\
Department of Biostatistics and Bioinformatics, Emory University, Atlanta, Georgia, U.S.A}

%  Three or more authors, with at least two different institutions,
%  more than one email displayed 

%\author{John Author$^{1,*}$\email{author@address.edu}, 
%Kathy Author$^{2,**}$\email{anotherauthor@address.edu}, and 
%Wilma Flinstone$^{3,***}$\email{wilma@bedrock.edu} \\
%$^{1}$Department of Statistics, University of Warwick, Coventry CV4 7AL, U.K \\
%$^{2}$Department of Biostatistics, University of North Carolina at 
%Chapel Hill, Chapel Hill, North Carolina, U.S.A. \\
%$^{3}$Department of Geology, University of Bedrock, Bedrock, Kansas, U.S.A.}

%  Three or more authors with at least two different institutions and only
%  one email displayed

%\author{John Author$^{1,*}$\email{author@address.edu}, 
%Wilma Flinstone$^{2}$, and Barney Rubble$^{2}$ \\
%$^{1}$Department of Statistics, University of Warwick, Coventry CV4 7AL, U.K \\
%$^{2}$Department of Geology, University of Bedrock, Bedrock, Kansas, U.S.A.}


\begin{document}

%  This will produce the submission and review information that appears
%  right after the reference section.  Of course, it will be unknown when
%  you submit your paper, so you can either leave this out or put in 
%  sample dates (these will have no effect on the fate of your paper in the
%  review process!)

\date{{\it Received October} 2007. {\it Revised February} 2008.  {\it
Accepted March} 2008.}

%  These options will count the number of pages and provide volume
%  and date information in the upper left hand corner of the top of the 
%  first page as in published papers.  The \pagerange command will only
%  work if you place the command \label{firstpage} near the beginning
%  of the document and \label{lastpage} at the end of the document, as we
%  have done in this template.

%  Again, putting a volume number and date is for your own amusement and
%  has no bearing on what actually happens to your paper!  

\pagerange{\pageref{firstpage}--\pageref{lastpage}} 
\volume{64}
\pubyear{2023}
\artmonth{June}

%  The \doi command is where the DOI for your paper would be placed should it
%  be published.  Again, if you make one up and stick it here, it means 
%  nothing!

\doi{10.1111/j.1541-0420.2005.00454.x}

%  This label and the label ``lastpage'' are used by the \pagerange
%  command above to give the page range for the article.  You may have 
%  to process the document twice to get this to match up with what you 
%  expect.  When using the referee option, this will not count the pages
%  with tables and figures.  

\label{firstpage}

%  put the summary for your paper here

\begin{abstract}
Monitoring key elements of disease dynamics (e.g., prevalence, case counts) is of great importance in infectious disease prevention and control, as emphasized during the COVID-19 pandemic. To facilitate this effort, we propose a new capture-recapture (CRC) analysis strategy that takes misclassification into account from easily-administered, imperfect diagnostic test kits, such as the Rapid Antigen Test-kits or saliva tests. Our method is based on a recently proposed “anchor stream” design, whereby an existing voluntary surveillance data stream is augmented by a smaller and judiciously drawn random sample. It incorporates manufacturer-specified sensitivity and specificity parameters to account for imperfect diagnostic results in one or both data streams. For inference to accompany case count estimation, we improve upon traditional Wald-type confidence intervals by developing an adapted Bayesian credible interval for the CRC estimator that yields favorable frequentist coverage properties. When feasible, the proposed design and analytic strategy provides a more efficient solution than traditional CRC methods or random sampling-based biased-corrected estimation to monitor disease prevalence while accounting for misclassification. We demonstrate the benefits of this approach through simulation studies that underscore its potential utility in practice for economical disease monitoring among a registered closed population.
\end{abstract}

%  Please place your key words in alphabetical order, separated
%  by semicolons, with the first letter of the first word capitalized,
%  and a period at the end of the list.
%

\begin{keywords}
Credible Interval; Misclassification; Non-representative Sampling; Sensitivity; Specificity.
\end{keywords}

%  As usual, the \maketitle command creates the title and author/affiliations
%  display 

\maketitle

%  If you are using the referee option, a new page, numbered page 1, will
%  start after the summary and keywords.  The page numbers thus count the
%  number of pages of your manuscript in the preferred submission style.
%  Remember, ``Normally, regular papers exceeding 25 pages and Reader Reaction 
%  papers exceeding 12 pages in (the preferred style) will be returned to 
%  the authors without review. The page limit includes acknowledgements, 
%  references, and appendices, but not tables and figures. The page count does 
%  not include the title page and abstract. A maximum of six (6) tables or 
%  figures combined is often required.''

%  You may now place the substance of your manuscript here.  Please use
%  the \section, \subsection, etc commands as described in the user guide.
%  Please use \label and \ref commands to cross-reference sections, equations,
%  tables, figures, etc.
%
%  Please DO NOT attempt to reformat the style of equation numbering!
%  For that matter, please do not attempt to redefine anything!

\section{Introduction}
Spurred by the COVID-19 pandemic, healthcare experts, policy makers, and government administrators have become increasingly aware of the importance of infectious disease monitoring in a particular geographic region, densely populated district, or vulnerable community. Applying regular disease surveillance efforts among such populations can help assess the prevalence and alert policy makers of the need to address an emerging or worsening crisis. However, many voluntary-based epidemiological surveillance programs produce biased data, as they often oversample positive cases \citep{Menni2020}. A common example arose during voluntary testing programs on university campuses during the recent pandemic, as students, staff and faculty were more likely to seek testing if they were feeling sick or had recent contact with active cases. That is, people with symptoms or health concerns may be more likely to participate in passive surveillance surveys, leading to overestimation of true disease prevalence in a closed community. 

In epidemiology or public health-related surveillance research, the capture-recapture (CRC) approach, which was borrowed from ecology studies to estimate the size of wildlife populations, is now commonly advocated for estimating case counts and prevalences. Applications of CRC have been directed toward many infectious diseases, such as HIV \citep{Poorolajal2017}, Hepatitis C \citep{Wu2005} and tuberculosis \citep{Dunbar2011,Carvalho2020,PerezDuque2020}. For accurate estimation, one key assumption that is often made is that there are no population-level associations between disease status and probability of observation; this is known as the Lincoln-Petersen, or “LP” condition in two-stream CRC analysis. Classic tools such as the Lincoln-Petersen \citep{Lincoln1930,Petersen1986} and Chapman estimators \citep{Chapman1951} are built on this assumption. However, it is often questionable in practice, and violating it may lead to biased estimation of the prevalence or population size \citep{Brenner1995}. While great effort has been directed toward relaxation of such assumptions, many sources \citep{Agresti1994,Hook1995,Cormack1999} point out that applying popular CRC estimation strategies in practice is almost always fraught with pitfalls; this includes significant drawbacks to the popular log-linear modeling paradigm \citep{Fienberg1972,Baillargeon2007,Jones2014,Zhang2023b}. To better explore relationships between multiple CRC data sources, some researchers \citep{Chatterjee2016,Zhang2020,Zhang2023} have proposed sensitivity analysis to evaluate the uncertainty caused by different levels of association. However, it is generally recognized that a design-based approach would be the only sure-fire way to ensure the LP condition in practice \citep{Seber1982,Chao2008,Lyles2022a, Lyles2022b}. When feasible, this approach achieves the crucial requirement by introducing a second random sampling-based surveillance effort implemented carefully so as to ensure a case identification process that is independent of the existing non-representative disease surveillance data stream \citep{Lyles2022a}. When it can be appropriately implemented in a closed and enumerable population, this sampling strategy leads to an unbiased maximum likelihood (ML) estimator of the case count, which is typically far more precise than classical CRC estimators derived under the LP condition. This comes about on the strength of a so-called “anchor stream” design, which precisely identifies a crucial conditional sampling probability parameter associated with the random sampling-based data stream \citep{Lyles2022a,Lyles2022b}.

A common challenge when analyzing epidemiological surveillance data is that the diagnostic method for ascertaining disease status may be prone to error. That is, the diagnostic results observed in disease surveillance programs may rely on imperfect tests or diagnostic devices,  which can lead to misclassification errors. Although an imperfect test result can lead to biased estimation, it is often the case that no gold standard is available to assess presence or absence of a particular disease \citep{Glasziou2008,Walter2012}. On the other hand, even when an accurate diagnostic test exists, some common but imperfect tests offer benefits such as ease of application, lower cost, and immediacy of results during the epidemiological disease screening process. However, these tests will generally suffer from a lack of gold-standard accuracy and sensitivity \citep{Soh2012}. Regarding imperfect disease status indications obtained from a single random sampling-based data source observed with error, numerous studies \citep{Levy1970,Rogan1978,Gastwirth1987} have offered feasible solutions by incorporating known or estimated misclassification parameters, such as the sensitivity ($Se$) and specificity ($Sp$). Yet, few researchers have discussed this issue under the CRC paradigm, particularly when dealing with disease surveillance data. When assuming the false-positive and false-negative rates are known,  \cite{Brenner1996} and \cite{Ramos2020} developed methods to adjust the error-prone surveillance data streams. More recently, \cite{Ge2023} proposed a generalized anchor stream design to account for misclassification errors, incorporating the CRC paradigm to identify an estimable positive predictive value ($PPV$) parameter to facilitate estimation of the cumulative incidence of breast cancer recurrence among a select population subsetted from the Georgia Cancer Registry-based Cancer Recurrence Information and Surveillance Program (CRISP). 

In this article, we propose a CRC strategy to leverage an existing general disease surveillance effort, supplemented by what can be a relatively small random sample. Our approach is based on an extension and generalization of previously proposed methods rooted in the anchor stream design \citep{Lyles2022a,Lyles2022b,Ge2023}, in order to target unbiased estimation of  disease prevalence while accounting for imperfect disease diagnoses based, for example, on the Rapid Antigen test-kits or saliva-based tests commonly applied during the COVID-19 pandemic. The proposed strategy allows for the estimation of disease case counts within a closed population region or community. The approach justifies fallible diagnostic status indications obtained via both data streams by leveraging manufacturer-reported sensitivity and specificity information, while preserving the independence and random sampling properties of the anchor stream. Importantly, we thus relax the strict stipulation requiring accurate test results in prior proposals of the anchor stream design \citep{Lyles2022a,Lyles2022b,Ge2023} in such disease monitoring settings, and accommodate imperfect diagnostic results via both data streams. In turn, this extension allows for the potential acceleration of epidemiological surveillance programs during an infectious disease season or pandemic. 

\section{Methods}

\subsection{Misclassification Parameters}

The two misclassification parameters $Se$ (sensitivity) and $Sp$ (specificity) are very commonly measured in assessing diagnostic tests, as they quantify the proportion of the test’s positive and negative results that are true positives and true negatives. Sensitivity is the conditional probability of a positive test result given the tested individual is truly diseased, i.e., $Se$ = Pr(Test positive $|$ diseased). Specificity is the conditional probability of a negative test result given the tested individual is truly non-diseased, i.e., $Sp$ = Pr(Test negative $|$ non-diseased). Conversely, false positive results are defined as Pr(Test positive $|$ non-diseased) = 1-$Sp$, and false negative results as Pr(Test negative $|$ diseased) = 1-$Se$. In this article, we use these definitions for the misclassification parameters to adjust for misclassified disease status in our estimates.

\subsection{Anchor Stream Design}

We build on prior considerations of the anchor stream design without misclassification \citep{Lyles2022a,Lyles2022b} along with extensions that proposed a justified CRC estimator based on an estimable PPV for targeting cumulatively incident case counts \citep{Ge2023}. Here, we leverage the same design strategy to surveil disease within an enumerated registry population without the stipulation that the anchor stream must employ a perfect diagnostic testing method. The existing surveillance effort, referred to as Stream 1, typically selects those at high risk of disease preferentially and is also likely to use an error-prone testing method. We subsequently obtain a random sample of individuals from the registered target population as the “anchor stream”, or Stream 2, which is carefully designed to be agnostic (independent) of Stream 1 \citep{Lyles2022a,Lyles2022b}. Importantly, we allow each of the two surveillance efforts to be based on its own error-prone diagnostic method characterized by known values of $Se$ and $Sp$ as provided by the manufacturer of the diagnostic device or test-kit. 

Benefiting from this design, the anchor stream alone provides its own valid and defensible sampling-based estimator based on known manufacturer-specified $Se$ and $Sp$ \citep{Ge2023b}. However, Stream 2 is typically expected to include a relatively small sample size, and is likely to identify far fewer potential cases relative to Stream 1. Assuming the total population size ($N_{tot}$) of the closed community or registry is known in advance, the bias-corrected true prevalence estimator $\pi_c$ and the corresponding case count estimator ($\hat{N}_{RS}$) based on the Stream 2 random sample with size ($n$) and known sensitivity ($Se_2$) and specificity ($Sp_2$) are given by the following formulae \citep{Rogan1978,Gastwirth1987,Levy1970,Ge2023b}: 
\begin{align}
    \hat{\pi}_c = \frac{\hat{\pi}+Sp_2-1}{Se_2+Sp_2-1}, ~~ \hat{N}_{RS}=N_{tot}\hat{\pi}_c, ~~ \hat{Var}(\hat{N}_{RS}) = N_{tot}^2\hat{Var}(\hat{\pi}_c) \label{eq_3.1}
\end{align}
where $\hat{\pi}=n^+/n$, and $n^+$ denotes the number of individuals identified as test positives in the random sample. When calculating the bias-corrected prevalence estimator $\hat{\pi}_c$, one needs to consider a threshold justification as follows \citep{Ge2023b} in light of the natural constraint $1-Sp_2\leq \hat{\pi}\leq Se_2$ that exists in the general error-prone testing problem:
\begin{align}
    \hat{\pi}_c = 
     \begin{cases}
      0 & \hat{\pi}\leq 1-Sp_2 \\
      1 & \hat{\pi}\geq Se_2   \\
      \hat{\pi}_c & \text{else}
    \end{cases}     
\end{align}

Given that the total population is closed and finite, a recently developed variance estimator $\hat{Var}(\hat{\pi}_c)$ \citep{Ge2023b} incorporates a finite population correction (FPC) given by Cochran \citep{Cochran1977} together with an elusive but necessary second term, i.e.,
\begin{align}\label{eq_3}
    \hat{Var}(\hat{\pi}_c) =& \frac{1}{(Se_2+Sp_2-1)^2}\big\{ \big[\frac{n(N_{tot}-n)}{N_{tot}(n-1)} \big] \frac{\hat{\pi}(1-\hat{\pi})}{n} \nonumber\\
    &+ \frac{1}{N_{tot}}[\hat{\pi}_c Se_2(1-Se_2)+(1-\hat{\pi}_c)Sp_2(1-Sp_2)]\big\}
\end{align}

When the anchor stream applies a perfect test (i.e., $Se_2=Sp_2=1$), the variance estimator in equation (\ref{eq_3}) reduces to the standard FPC-corrected sampling-based variance estimator, i.e., $\hat{Var}(\hat{\pi}_c) = \big[\frac{n(N_{tot}-n)}{N_{tot}(n-1)} \big] \frac{\hat{\pi}(1-\hat{\pi})}{n}$. Moreover, when the total population size $N_{tot}$ is relatively small and the anchor stream sample size $n$ is large in comparison to $N_{tot}$, the finite population effect leads to a substantial reduction in variance.

\subsection{A Novel Capture-Recapture (CRC) Estimator}

We now assume that the disease assessment methods applied via the anchor stream design are fallible in both data streams, with known Sensitivity ($Se_1$, $Se_2$) and Specificity ($Sp_1$,$Sp_2$). A novel CRC estimator using all available data is justified using maximum likelihood (ML) based on a general multinomial model for the nine cell counts defined in Table \ref{table_1}.

\begin{table}
\centering
\caption{Cell Counts and Likelihood Contributions}
\label{table_1}
\begin{threeparttable}[b]
 \begin{tabular}{cll} 
 \hline
  Cell & \multicolumn{1}{c}{Observation Type\tnote{a}} & \multicolumn{1}{c}{Likelihood} \\ 
 \hline
 $n_1$ & Sampled in S1 and S2, Test +   & $p_1 = \psi[Se_2 Se_1 \pi_{1} + (1-Sp_2)(1-Sp_1) (1-\pi_{1})]\phi$\\ 
 $n_2$ & Sampled in S1 and S2, Test $-$  & $p_2 = \psi[(1-Se_2) (1-Se_1)\pi_{1} + Sp_2 Sp_1 (1-\pi_{1})]\phi$\\
 \multirow{2}{*}{$n_3$} & Sampled in S1 and S2, & \multirow{2}{*}{$p_3 = \psi[(1-Se_2) Se_1\pi_{1} + Sp_2 (1-Sp_1)(1-\pi_{1})]\phi$}\\
  & Test + in S1, Test $-$ in S2  &\\ 
 \multirow{2}{*}{$n_4$} & Sampled in S1 and S2, & \multirow{2}{*}{$p_4 = \psi[Se_2 (1-Se_1)\pi_{1} + (1-Sp_2) Sp_1(1-\pi_{1})]\phi$}\\
  & Test $-$ in S1, Test + in S2  \\ 
 $n_5$ & Sampled in S1, not S2, Test +  & $p_5 = (1-\psi) [Se_1\pi_{1} + (1-Sp_1)(1-\pi_{1})]\phi$\\ 
 $n_6$ & Sampled in S1, not S2, Test $-$  & $p_6 = (1-\psi) [(1-Se_1)\pi_{1} + Sp_1(1-\pi_{1})]\phi$\\
 $n_7$ & Sampled in S2, not S1, Test +  & $p_7 =  \psi[Se_2\pi_{01} + (1-Sp_2)(1-\pi_{01})](1-\phi)$\\ 
 $n_8$ & Sampled in S2, not S1, Test $-$  & $p_8 =  \psi[(1-Se_2)\pi_{01} + Sp_2 (1-\pi_{01})](1-\phi)$\\
 $n_9$ & Not Sampled in S1 or S2  &
 $p_9 = (1-\psi)(1-\phi)$\\
 \hline
 \end{tabular}
 \begin{tablenotes}
        \item[a] \footnotesize S1: Stream 1, S2: Stream 2
  \end{tablenotes}
    \end{threeparttable}
\end{table}

The likelihood contributions presented in Table \ref{table_1} are based on defining the parameters, $\phi=$Pr(sampled in Stream 1), $\pi_{1}=$Pr(true + $|$ sampled in Stream 1 ), $\pi_{01}=$Pr(true + $|$ sampled not in Stream 1). In addition, we have a known parameter $\psi=$ Pr(sampled in Stream 2), which is under the investigator’s control and can be fixed as the proportion of the $N_{tot}$ individuals represented in Stream 2. While it is assumed that the sensitivity and specificity parameters are known, the subscripts reflect the fact that both can differ across surveillance efforts (i.e., different testing methods can be applied in Stream 1 and Stream 2). When both disease assessments are accurate, meaning that all 4 $Se$/$Sp$ parameters can be assumed equal to 1, cell counts $n_3$ and $n_4$ and their likelihood contributions in Table \ref{table_1} will be zero. In that case, the estimators previously proposed by \cite{Lyles2022b} can be applied directly for case count estimation.

For the purpose of point estimation of the true prevalence or case count, the vector of nine cell counts in Table \ref{table_1} can be modeled as a multinomial sample with likelihood proportional to $\prod_{j=1}^9 p_j^{n_j}$, where $p_j$ denotes the likelihood contribution corresponding to the $j$th cell. That is, for point estimation one can assume
\begin{align}
    (n_{1},n_{2}, \cdots, n_{9})\sim~multinominal(N_{tot}, p_{1},p_{2}, \cdots, p_{9})
\end{align}

The MLE for the unknown parameters in Table \ref{table_1} can be obtained numerically, and we find that two of them are available in closed form. The exception is the parameter $\pi_1$, for which we offer an approximation ($\hat{\pi}_1^*$) in order to facilitate in turn a closed-form approximation to the MLE of the true disease prevalence. The MLE for the other parameters in Table \ref{table_1}, along with $\hat{\pi}_1^*$, are as follows.
\begin{align*}
    \hat{\phi} &= \frac{n_1+n_2+n_3+n_4+n_5+n_6}{N_{tot}} \\
    \hat{\pi}_1^* &= \frac{\frac{n_1+n_3+n_5}{n_1+n_2+n_3+n_4+n_5+n_6}+Sp_1-1}{Se_1+Sp_1-1} \\
    \hat{\pi}_{01} &= \frac{\frac{n_7}{n_7+n_8}+Sp_2-1}{Se_2+Sp_2-1}
\end{align*}


The overall disease prevalence is a function of these parameters, and thus an initial closed-form CRC estimator for disease case counts is derived accordingly:
\begin{align}
    \hat{N}_{CRC} = N_{tot}[\hat{\pi}_{1}^*\hat{\phi} + \pi_{01}(1 - \hat{\phi})].
    \label{eq_5}
\end{align}

Importantly, however, the variance-covariance matrix implied by a multinomial model for the cell counts in Table \ref{table_1} ignores standard and non-standard FPC effects that are in play under the anchor stream design. For this reason, a traditional multivariate delta method approach applied to the estimator in equation (\ref{eq_5}) while assuming the multinomial covariance structure will tend to overestimate the variance unless both data streams sample only a small proportion of the $N_{tot}$ individuals in the finite target population. Nevertheless, we find empirically that the covariances among the MLEs for the unknown parameters in Table \ref{table_1} are negligible, as they would be theoretically if the multinomial covariance structure applied.

In order to accommodate FPC adjustments, we first tailor the estimator of $\pi_1$ by approximating it via $\psi\hat{\pi}_{11}+(1-\psi)\hat{\pi}_{10}$, where $\hat{\pi}_{11}= \frac{\frac{n_1+n_4}{n_1+n_2+n_3+n_4}+Sp_2-1}{Se_2+Sp_2-1}$ and $\hat{\pi}_{10}=\frac{\frac{n_5}{n_5+n_6}+Sp_1-1}{Se_1+Sp_1-1}$ are estimates of the prevalence among individuals sampled by both data streams, and individuals only sampled by Stream 1, respectively. This leads to a second closed-form estimator, which compares well empirically with equation (\ref{eq_5}) across a broad range of conditions:
\begin{align}
     \hat{N}_{CRC} = N_{tot}[\psi\hat{\pi}_{11}\hat{\phi}+(1-\psi)\hat{\pi}_{10}\hat{\phi} + \pi_{01}(1 - \hat{\phi})]
    \label{eq_6}   
\end{align}

We subsequently make use of two variance approximations for the CRC estimator in (\ref{eq_6}), as follows:
\begin{align}
    \hat{V}_{k}(\hat{N}_{CRC}) = N_{tot}^2[\hat{d}_{11}^2\hat{V}_k(\hat{\pi}_{11})+\hat{d}_{10}^2\hat{V}_k(\hat{\pi}_{10})+\hat{d}_{01}^2\hat{V}_k(\hat{\pi}_{01})],~k = 1,2\label{eq_7}
\end{align}
where $\hat{d}_{11}=\psi\hat{\phi}$, $\hat{d}_{10}=(1-\psi)\hat{\phi}$, $\hat{d}_{01}(1-\hat{\phi})$. For $k=1$, the approximate variance incorporates no FPC adjustments, i.e., $\hat{V}_1(\hat{\pi}_{11}) = \frac{1}{(Se_2+Sp_2-1)^2}\frac{\Tilde{\pi}_{11}(1-\Tilde{\pi}_{11})}{n_1+n_2+n_3+n_4}$, $\Tilde{\pi}_{11} = \frac{n_1+n_4}{n_1+n_2+n_3+n_4}$; $\hat{V}_1(\hat{\pi}_{10})=\frac{1}{(Se_1+Sp_1-1)^2}\frac{\Tilde{\pi}_{10}(1-\Tilde{\pi}_{10})}{n_5+n_6}$, $\Tilde{\pi}_{10}=\frac{n_5}{n_5+n_6}$; $\hat{V}_1(\hat{\pi}_{01})=\frac{1}{(Se_2+Sp_2-1)^2}\frac{\Tilde{\pi}_{01}(1-\Tilde{\pi}_{01})}{n_7+n_8}$, $\Tilde{\pi}_{01}=\frac{n_7}{n_7+n_8}$.

As a result, the variance estimator $\hat{V}_{1}(\hat{N}_{CRC})$ is a conservative approximation for the variance of (\ref{eq_6}) based on a tailored version of the multivariate delta method (\ref{eq_5}) that assumes a standard multinomial covariance structure applies to Table \ref{table_1}. In contrast, the scenario where $k=2$ incorporates FPC adjustments \citep{Cochran1977} together with the misclassification effect adjustments in (\ref{eq_3}), applying them to $\hat{V}_1(\hat{\pi}_{11})$, $\hat{V}_1(\hat{\pi}_{10})$ and $\hat{V}_1(\hat{\pi}_{01})$ in (\ref{eq_7}). That is,
\begin{align}
    \hat{V}_2(\hat{\pi}_{ij}) = FPC_{ij}\hat{V}_1(\hat{\pi}_{ij}) + \hat{V}_{extra}^{ij}, ~~ i,j=0,1 \label{eq_8}
\end{align}
where $FPC_{11}=\frac{N_{11}(N_1-N_{11})}{N_1(N_{11}-1)}$, $FPC_{10}=\frac{(N_1-N_{11})N_{11}}{N_1(N_1-N_{11}-1)}$, $FPC_{01}=\frac{N_{01}(N_{tot}-N_1-N_{01})}{(N_{tot}-N_1)(N_{01}-1)}$, $N_1=n_1+n_2+n_3+n_4+n_5+n_6$, $N_{11}=n_1+n_2+n_3+n_4$, $N_{01}=n_7+n_8$. The details of the extra variance terms ($\hat{V}_{extra}^{ij}$) are available in Appendix. This provides an alternative FPC-adjusted variance estimator, $\hat{V}_{2}(\hat{N}_{CRC})$, which we recommend for use in conjunction with the CRC estimator in (\ref{eq_6}).

\subsection{An Adapted Bayesian Credible Interval Approach for Inference}

Many references have pointed out that Wald-type confidence intervals (CIs) often show poor performance when proportions are extreme and/or the sample size is limited \citep{Ghosh1979,Blyth1983,Agresti1998,Brown2001}. To potentially improve the frequentist coverage properties of the intervals accompanying the CRC estimator (\ref{eq_6}) for disease case counts while adjusting the variance for finite population effects, we adopt a Bayesian credible interval based on a weakly informative Dirichlet prior on a multinomial model.

Our approach is similar in spirit to a recent proposal for the case of no misclassification \citep{Lyles2022b}. Specifically, we implement a scale and shift adjustment to a typical posterior credible interval for $\hat{N}_{CRC}$ based on a Jeffreys' Dirichlet(1/2,~1/2,~$\cdots$,1/2) prior for the cell probabilities in Table \ref{table_1}, which yields the corresponding posterior distribution in (\ref{eq_3.16}):
\begin{align}
    Dirichlet(n_1+1/2, n_2+1/2, \cdots, n_9+1/2) \label{eq_3.16}
\end{align}

The traditional 95\% credible interval is defined using 2.5th and 97.5th percentiles of the target estimand in (\ref{eq_6}) based on this posterior distribution via posterior samples, i.e., $\hat{N}_{CRC}^{(s)}$, $s=1,2,\cdots,S$. To adjust the variance for finite population effects, we define a new \textit{scale} parameter $a$ and a \textit{shift} parameter $b$ as follows:
\begin{align}
    a^{(s)} = \sqrt{\hat{V}_{2}(\hat{N}_{CRC}^{(s)})/\hat{V}_{1}(\hat{N}_{CRC}^{(s)})}, ~~b^{(s)}=\hat{N}_{CRC}(1-a^{(s)}) \label{eq_3.17}
\end{align}
where $\hat{V}_{1}(\hat{N}_{CRC}^{(s)})$ and $\hat{V}_{2}(\hat{N}_{CRC}^{(s)})$ are the estimated unadjusted variance and FPC-adjusted variance for $\hat{N}_{CRC}^{(s)}$ based on applying equation (\ref{eq_7}) to the $s$-th set of posterior-sampled cell counts. Posterior draws $\hat{N}_{CRC}^{(s)}$ are then scaled and shifted, i.e.,
\begin{align}
    \Tilde{N}_{CRC}^{(s)} = a^{(s)}\hat{N}_{CRC}^{(s)} + b^{(s)} \label{eq_11}
\end{align}

This adjusts the posterior distribution to have a mean equal to $\hat{N}_{CRC}$ and incorporates adjustments to the variance for finite population and misclassification effects. We refer to the interval ($LL_{ab}, LL_{ab}$) as the proposed Bayesian credible interval for $\hat{N}_{CRC}$ by taking the 2.5\% and 97.5\% percentiles from the posterior draws in (\ref{eq_11}).

While the proposed Bayesian credible interval will typically be narrower than alternatives based on Stream 2 only, it can be conservative under certain conditions (e.g., if the Stream 2 sampling rate is large). As a comparator, we recommend examining the Bayesian credible interval proposed by \cite{Ge2023} for accompanying the Stream 2 only random sampling-based estimator $\hat{\pi}_c$ in (\ref{eq_3.1}) under finite sampling conditions; we refer to the corresponding interval for the case count as $N_{tot}\times (LL_{RS}, UL_{RS})$. In practice, we promote the use of the narrower of this interval and the interval based on eqn.(\ref{eq_11}); this approach is evaluated in our subsequent simulation studies. 

\section{Simulation Study}\label{section_3}

We conducted simulations to assess the properties of the case count estimators of $N$ along with the proposed credible interval approach. The first simulation is designed to study performance across a wide range of parameter settings. The population size of $N_{tot}$ was set to 200, 500 and 1,000, while the true disease prevalence was also examined over a range ($p$=0.1, 0.3, 0.5). Data were generated in such a way that among those with disease, 50\% of individuals exhibited symptoms. In contrast, only 10\% of those without disease showed symptoms. The Stream 1 sample was drawn to reflect voluntary-based non-representative surveillance data, selecting 80\% of individuals with symptoms for testing as opposed to 10\% of those without symptoms. Stream 2 was generated as the anchor stream independently of Stream 1, with the sampling rate varied over a wide range ($\psi$=0.1, 0.3, 0.5). Both streams included misclassified diagnostic results, controlled by known parameters ($Se_1$, $Sp_1$) and ($Se_2$, $Sp_2$) to produce a range of high, moderate and low levels of misclassification (e.g., $Se$, $Sp$=0.95, 0.9, 0.85). We conducted 5,000 simulations for each setting, and we report results for the proposed Bayesian credible intervals for inference based on 1,000 Dirichlet posterior draws.   

\begin{table}
    \centering
    \caption{Comparing the Performance of Estimators with $N$=1,000 and Low Misclassification Level $^a$ }
    \label{table_2}
    \begin{threeparttable}[b]
    \begin{tabular}{cccccccccc}
    \hline
    Prevalence & 
    Sampling &  \multirow{2}{*}{Estimator \tnote{b}} & \multirow{2}{*}{Mean} & \multirow{2}{*}{SD} & \multirow{2}{*}{Avg. SE} & \multirow{2}{*}{Avg. width \tnote{c}} & CI Coverage  \\
    $p$ & Rate $\psi$ & &&&&& (\%)  \\ \hline
     & \multirow{3}{*}{0.1} & $\hat{N}_{RS}$ & 100.2 & 38.2 & 37.2 & 145.8 & 93.3  \\ \cline{3-8}
     & ~ & $\hat{N}_{CRC}$ & 100.3 & 31.0 & 30.8 & 120.7 \textbf{(116.6)} & 92.8 \textbf{(94.1)}  \\ \cline{3-8}
     & ~ & $\hat{N}_{CRC}^*$ & 100.3 & 31.0 & - & - & -   \\ \cline{2-8}
    
    0.1 & \multirow{3}{*}{0.3}  & $\hat{N}_{RS}$ & 100.4 & 20.1 & 20.1 & 79.0 & 94.3  \\ \cline{3-8}
     & ~ & $\hat{N}_{CRC}$ & 100.3 & 17.1 & 17.7 & 69.5 \textbf{(69.5)} & 95.4 \textbf{(95.6)}  \\ \cline{3-8}
    $N_{true}=100$ & ~ & $\hat{N}_{CRC}^*$ & 100.3 & 17.0 & - & - & -   \\  \cline{2-8}
    
     & \multirow{3}{*}{0.5}  & $\hat{N}_{RS}$ & 99.8 & 14.5 & 14.4 & 56.4 & 95.4   \\ \cline{3-8}
     & ~ & $\hat{N}_{CRC}$ & 99.8 & 12.8 & 13.5 & 52.9 \textbf{(53.2)} & 95.8 \textbf{(95.6)}   \\ \cline{3-8}
    ~ & ~ & $\hat{N}_{CRC}^*$ & 99.8 & 12.6 & - & - & -   \\ \hline
    
    & \multirow{3}{*}{0.1} & $\hat{N}_{RS}$ & 298.4 & 49.6 & 49.7 & 194.8 & 95.3  \\ \cline{3-8}
     & ~ & $\hat{N}_{CRC}$ &  298.5 & 39.8 & 40.4 & 158.2 \textbf{(156.6)} & 94.4 \textbf{(95.0)}  \\ \cline{3-8}
    ~ & ~ & $\hat{N}_{CRC}^*$ & 298.5 & 39.8 & - & - & -   \\ \cline{2-8}
    
    0.3 & \multirow{3}{*}{0.3}  & $\hat{N}_{RS}$ & 300.6 & 26.4 & 26.2 & 102.7 & 95.2  \\ \cline{3-8}
     & ~ & $\hat{N}_{CRC}$ & 300.1 & 21.6 & 22.4 & 87.9 \textbf{(88.3)} & 95.6 \textbf{(95.7)}  \\ \cline{3-8}
     $N_{true}=300$ & ~ & $\hat{N}_{CRC}^*$ & 300.2 & 21.6 & - & - & -   \\ \cline{2-8}
    
     & \multirow{3}{*}{0.5}  & $\hat{N}_{RS}$ & 299.9 & 18.1 & 18.1 & 70.9 & 94.9    \\ \cline{3-8}
     & ~ & $\hat{N}_{CRC}$ & 299.8 & 15.5 & 16.5 & 64.8 \textbf{(65.7)} & 96.1 \textbf{(96.6)}   \\ \cline{3-8}
    ~ & ~ & $\hat{N}_{CRC}^*$ &  299.9 & 15.3  & - & - & -   \\ \hline
    
    & \multirow{3}{*}{0.1} & $\hat{N}_{RS}$ & 499.3 & 53.6 & 53.3 & 208.8 & 95.3  \\ \cline{3-8}
     & ~ & $\hat{N}_{CRC}$ &  499.3 & 44.5 & 44.1 & 173.0 \textbf{(170.3)} & 94.5 \textbf{(95.0)}  \\ \cline{3-8}
    ~ & ~ & $\hat{N}_{CRC}^*$ & 499.4 & 44.5 & - & - & -   \\ \cline{2-8}
    
    0.5 & \multirow{3}{*}{0.3}  & $\hat{N}_{RS}$ & 500.6 & 27.9 & 27.9 & 109.4 & 94.5  \\ \cline{3-8}
     & ~ & $\hat{N}_{CRC}$ & 500.3 & 23.4 & 24.2 & 94.7 \textbf{(95.1)} & 95.8 \textbf{(96.0)} \\ \cline{3-8}
     $N_{true}=500$ & ~ & $\hat{N}_{CRC}^*$ & 500.3 & 23.3 & - & - & -   \\ \cline{2-8}
    
     & \multirow{3}{*}{0.5}  & $\hat{N}_{RS}$ & 499.8 & 19.2 & 19.2 & 75.2 & 94.6   \\ \cline{3-8}
     & ~ & $\hat{N}_{CRC}$ & 500.0 & 16.6 & 17.6 & 68.8 \textbf{(69.9)} & 96.2 \textbf{(96.3)}   \\ \cline{3-8}
    ~ & ~ & $\hat{N}_{CRC}^*$ &  500.0 & 16.4   & - & - & -   \\ \hline
    \end{tabular}
    \begin{tablenotes}
        \item[$a$] \footnotesize $Se_1, Sp_1=0.9$, $Se_2, Sp_2=0.95$
        \item[b] \footnotesize $\hat{N}_{CRC}$ shows results calculated based on closed-form estimator in equation (\ref{eq_6}) and $\hat{N}_{CRC}^*$ refers to the numerical MLE
        \item[c] The Wald-based CI for $\hat{N}_{RS}$ is evaluated by multiplying equation (\ref{eq_3}) by $N_{tot}^2$. The Wald-based CI for $\hat{N}_{CRC}$ is determined using equation (\ref{eq_8}), along with a proposed FPC-adjusted Bayesian credible interval \textbf{(Bold)}
  \end{tablenotes}
   \end{threeparttable}
\end{table}

Table \ref{table_2} summarizes the simulation results with $N$=1,000 and low misclassification level (e.g., $Se_1,Sp_1=0.9$; $Se_2,Sp_2=0.95$). In this simulation setting, we compare the CRC estimators with the random sampling-based estimator $\hat{N}_{RS}$ justified by the corresponding pre-specified sensitivity and specificity parameters. For the CRC estimators, we report the results for the numerical MLE $\hat{N}_{CRC}^*$ for $N$ along with the closed-form estimator $\hat{N}_{CRC}$ based on equation (\ref{eq_6}). As mentioned previously, a standard error to accompany the numerical $\hat{N}_{CRC}^*$ is not directly available and thus we only report the average point estimate as well as its empirical standard deviation (SD) in the table. While the numerical estimator $\hat{N}_{CRC}^*$ provides better precision in some cases, the difference is slight and the closed-form estimator $\hat{N}_{CRC}$ is much more convenient for use in practice.

The simulation results in Table \ref{table_2} indicate that all three estimators are virtually unbiased, while the CRC estimators show a clear improvement in estimation precision. Furthermore, the proposed FPC-adjusted Bayesian credible interval provides better coverage properties compared to the Wald-type confidence interval and its mean width is narrower than that of the Wald-type interval in most settings, especially when the sampling rate  ($\psi$) is low.

Comparing the low misclassification setting in Table \ref{table_2} with the moderate and high misclassification levels in Table \ref{table_3} and Table \ref{table_4} respectively, it is clear that as the misclassification level increases, the estimated standard errors and the widths of the interval become larger. While the point estimate of $\hat{N}_{CRC}$ exhibits slight bias for the low prevalence and sampling rate scenario ($p=0.1$, $\psi=0.1$) at high misclassification level (Table \ref{table_4}) due to thresholding the negative prevalence estimation to zero, the proposed Bayesian credible interval approach still provides reliable interval estimation for the disease case count estimation. 

\begin{table}
    \centering
    \caption{Comparing the Performance of Estimators with $N$=1,000 and Moderate Misclassification Level $^a$  }   \label{table_3}
    \begin{threeparttable}[b]
    \begin{tabular}{|c|c|c|c|c|c|c|c|}
    \hline
    Prevalence & 
    Sampling &  \multirow{2}{*}{Estimator \tnote{b}} & \multirow{2}{*}{Mean} & \multirow{2}{*}{SD} & \multirow{2}{*}{Avg. SE} & \multirow{2}{*}{Avg. width \tnote{c}} & CI Coverage  \\
    $p$ & Rate $\psi$ & &&&&& (\%)  \\ \hline
     & \multirow{3}{*}{0.1} & $\hat{N}_{RS}$ & 100.2 & 47.2 & 46.9 & 184.0 & 94.7   \\ \cline{3-8}
     & ~ & $\hat{N}_{CRC}$ & 101.5 & 38.2 & 40.4 & 158.4 \textbf{(142.2)} & 97.4 \textbf{(94.4)}  \\ \cline{3-8}
     & ~ & $\hat{N}_{CRC}^*$ & 101.4 & 38.3  & - & - & -   \\ \cline{2-8}
    
    0.1 & \multirow{3}{*}{0.3}  & $\hat{N}_{RS}$ & 100.0 & 26.1 & 26.0 & 102.1 & 95.3   \\ \cline{3-8}
     & ~ & $\hat{N}_{CRC}$ & 100.2 & 23.2 & 23.5 & 92.3 \textbf{(89.9)} & 95.2 \textbf{(95.0)}  \\ \cline{3-8}
    $N_{true}=100$ & ~ & $\hat{N}_{CRC}^*$ & 100.2 & 23.1 & - & - & -   \\  \cline{2-8}
    
     & \multirow{3}{*}{0.5}  & $\hat{N}_{RS}$ & 100.1 & 19.1 & 19.3 & 75.5 & 95.1   \\ \cline{3-8}
     & ~ & $\hat{N}_{CRC}$ & 100.1 & 17.6 & 18.3 & 71.7 \textbf{(71.2)} & 95.3 \textbf{(95.3)}   \\ \cline{3-8}
    ~ & ~ & $\hat{N}_{CRC}^*$ & 100.1 & 17.3 & - & - & -   \\ \hline
    
    & \multirow{3}{*}{0.1} & $\hat{N}_{RS}$ & 300.0 & 57.9 & 57.4 & 225.0 & 94.8  \\ \cline{3-8}
     & ~ & $\hat{N}_{CRC}$ &   299.5 & 48.2 & 47.7 & 187.0 \textbf{(184.5)} & 94.0 \textbf{(94.8)}  \\ \cline{3-8}
    ~ & ~ & $\hat{N}_{CRC}^*$ & 299.5 & 48.1 & - & - & -   \\ \cline{2-8}
    
    0.3 & \multirow{3}{*}{0.3}  & $\hat{N}_{RS}$ & 300.0 & 31.2 & 31.0 & 121.4 & 95.0  \\ \cline{3-8}
     & ~ & $\hat{N}_{CRC}$ & 299.9 & 26.8 & 27.1 & 106.2 \textbf{(106.4)} & 94.8 \textbf{(95.2)}   \\ \cline{3-8}
     $N_{true}=300$ & ~ & $\hat{N}_{CRC}^*$ &  299.8 & 26.7 & - & - & -   \\ \cline{2-8}
    
     & \multirow{3}{*}{0.5}  & $\hat{N}_{RS}$ & 299.8 & 22.4 & 22.2 & 86.9 & 94.6    \\ \cline{3-8}
     & ~ & $\hat{N}_{CRC}$ & 299.9 & 19.8 & 20.5 & 80.5 \textbf{(81.2)} & 95.7 \textbf{(95.9)}   \\ \cline{3-8}
    ~ & ~ & $\hat{N}_{CRC}^*$ & 299.8 & 19.5  & - & - & -   \\ \hline
    
    & \multirow{3}{*}{0.1} & $\hat{N}_{RS}$ & 500.2 & 61.7 & 60.5 & 237.1 & 94.7  \\ \cline{3-8}
     & ~ & $\hat{N}_{CRC}$ &  501.3 & 51.3 & 50.5 & 198.1 \textbf{(194.9)} & 94.6 \textbf{(94.9)}  \\ \cline{3-8}
    ~ & ~ & $\hat{N}_{CRC}^*$ & 501.3 & 51.3 & - & - & -   \\ \cline{2-8}
    
    0.5 & \multirow{3}{*}{0.3}  & $\hat{N}_{RS}$ & 500.4 & 32.6 & 32.4 & 127.2 & 95.2  \\ \cline{3-8}
     & ~ & $\hat{N}_{CRC}$ &  499.9 & 27.6 & 28.4 & 111.3 \textbf{(111.6)} & 95.5 \textbf{(95.7)}  \\ \cline{3-8}
     $N_{true}=500$ & ~ & $\hat{N}_{CRC}^*$ & 499.9 & 27.5 & - & - & -   \\ \cline{2-8}
    
     & \multirow{3}{*}{0.5}  & $\hat{N}_{RS}$ & 500.0 & 23.1 & 23.0 & 90.4 & 95.7   \\ \cline{3-8}
     & ~ & $\hat{N}_{CRC}$ & 500.1 & 20.3 & 21.3 & 83.4 \textbf{(84.3)} & 95.9 \textbf{(96.0)}   \\ \cline{3-8}
    ~ & ~ & $\hat{N}_{CRC}^*$ &  500.0 & 20.0   & - & - & -   \\ \hline
    \end{tabular}
    \begin{tablenotes}
        \item[$^a$] \footnotesize $Se_1, Sp_1=0.85$, $Se_2, Sp_2=0.9$
        \item[b] \footnotesize $\hat{N}_{CRC}$ shows results calculated based on closed-form estimator in equation (\ref{eq_6}) and $\hat{N}_{CRC}^*$ refers to the numerical MLE
        \item[c] The Wald-based CI for $\hat{N}_{RS}$ is evaluated by multiplying equation (\ref{eq_3}) by $N_{tot}^2$. The Wald-based CI for $\hat{N}_{CRC}$ is determined using equation (\ref{eq_8}), along with a proposed FPC-adjusted Bayesian credible interval \textbf{(Bold)}
  \end{tablenotes}
    \end{threeparttable}
\end{table}


\begin{table}
    \centering
    \caption{Comparing the Performance of Estimators with $N$=1,000 and High Misclassification Level $^a$  }
    \label{table_4}
    \begin{threeparttable}[b]
    \begin{tabular}{|c|c|c|c|c|c|c|c|}
    \hline
    Prevalence & 
    Sampling &  \multirow{2}{*}{Estimator \tnote{b}} & \multirow{2}{*}{Mean} & \multirow{2}{*}{SD} & \multirow{2}{*}{Avg. SE} & \multirow{2}{*}{Avg. width \tnote{c}} & CI Coverage  \\
    $p$ & Rate $\psi$ & &&&&& (\%)  \\ \hline
     & \multirow{3}{*}{0.1} & $\hat{N}_{RS}$ & 101.0 & 55.9 & 58.3 & 228.7 & 95.3   \\ \cline{3-8}
     & ~ & $\hat{N}_{CRC}$ & 103.7 & 46.1 & 51.3 & 201.1 \textbf{(168.3)} & 98.5 \textbf{(94.3)}  \\ \cline{3-8}
     & ~ & $\hat{N}_{CRC}^*$ & 103.6 & 46.1  & - & - & -   \\ \cline{2-8}
    
    0.1 & \multirow{3}{*}{0.3}  & $\hat{N}_{RS}$ & 99.9 & 33.4 & 32.8 & 128.6 & 94.5    \\ \cline{3-8}
     & ~ & $\hat{N}_{CRC}$ & 100.1 & 29.6 & 30.1 & 118.0 \textbf{(110.0)} & 95.4 \textbf{(94.5)}  \\ \cline{3-8}
    $N_{true}=100$ & ~ & $\hat{N}_{CRC}^*$ & 100.0 & 29.5 & - & - & -   \\  \cline{2-8}
    
     & \multirow{3}{*}{0.5}  & $\hat{N}_{RS}$ & 99.8 & 24.6 & 24.7 & 96.8 & 95.4   \\ \cline{3-8}
     & ~ & $\hat{N}_{CRC}$ & 99.8 & 22.9 & 23.6 & 92.4 \textbf{(89.7)} & 95.7 \textbf{(95.6)}   \\ \cline{3-8}
    ~ & ~ & $\hat{N}_{CRC}^*$ & 99.8 & 22.4 & - & - & -   \\ \hline
    
    & \multirow{3}{*}{0.1} & $\hat{N}_{RS}$ & 302.2 & 67.1 & 67.1 & 262.9 & 94.9  \\ \cline{3-8}
     & ~ & $\hat{N}_{CRC}$ &   301.1 & 56.5 & 56.8 & 222.6 \textbf{(217.8)} & 95.1 \textbf{(95.3)}  \\ \cline{3-8}
    ~ & ~ & $\hat{N}_{CRC}^*$ & 301.1 & 56.5 & - & - & -   \\ \cline{2-8}
    
    0.3 & \multirow{3}{*}{0.3}  & $\hat{N}_{RS}$ & 300.6 & 37.0 & 36.9 & 144.5 & 94.4  \\ \cline{3-8}
     & ~ & $\hat{N}_{CRC}$ &  300.7 & 32.6 & 32.8 & 128.5 \textbf{(128.4)} & 94.9 \textbf{(95.0)}   \\ \cline{3-8}
     $N_{true}=300$ & ~ & $\hat{N}_{CRC}^*$ &  300.7 & 32.4 & - & - & -   \\ \cline{2-8}
    
     & \multirow{3}{*}{0.5}  & $\hat{N}_{RS}$ & 300.1 & 27.4 & 27.0 & 106.0 & 94.5    \\ \cline{3-8}
     & ~ & $\hat{N}_{CRC}$ & 300.1 & 25.0 & 25.3 & 99.0 \textbf{(99.5)} & 95.2 \textbf{(95.2)}   \\ \cline{3-8}
    ~ & ~ & $\hat{N}_{CRC}^*$ & 300.1 & 24.6  & - & - & -   \\ \hline
    
    & \multirow{3}{*}{0.1} & $\hat{N}_{RS}$ & 500.0 & 70.0 & 69.7 & 273.1 & 94.9  \\ \cline{3-8}
     & ~ & $\hat{N}_{CRC}$ &  499.3 & 59.2 & 58.6 & 229.7 \textbf{(225.9)} & 94.4 \textbf{(94.9)}   \\ \cline{3-8}
    ~ & ~ & $\hat{N}_{CRC}^*$ & 499.4 & 59.1 & - & - & -   \\ \cline{2-8}
    
    0.5 & \multirow{3}{*}{0.3} & $\hat{N}_{RS}$ & 500.0 & 38.3 & 38.1 & 149.3 & 94.6   \\ \cline{3-8}
     & ~ & $\hat{N}_{CRC}$ &  500.2 & 33.2 & 33.6 & 131.9 \textbf{(131.9)} & 95.2 \textbf{(95.2)}  \\ \cline{3-8}
    $N_{true}=500$ & ~ & $\hat{N}_{CRC}^*$ & 500.3 & 32.9 & - & - & -   \\ \cline{2-8}
    
     & \multirow{3}{*}{0.5}  & $\hat{N}_{RS}$ & 500.0 & 27.2 & 27.8 & 108.8 & 96.2  \\ \cline{3-8}
     & ~ & $\hat{N}_{CRC}$ &  499.9 & 24.8 & 25.8 & 101.1 \textbf{(101.7)} & 95.6 \textbf{(95.8)}   \\ \cline{3-8}
    ~ & ~ & $\hat{N}_{CRC}^*$ &  500.0 & 24.2   & - & - & -   \\ \hline
    \end{tabular}
    \begin{tablenotes}
        \item[a] \footnotesize $Se_1, Sp_1=0.8$, $Se_2, Sp_2=0.85$
        \item[b] \footnotesize $\hat{N}_{CRC}$ shows results calculated based on closed-form estimator in equation (\ref{eq_6}) and $\hat{N}_{CRC}^*$ refers to the numerical MLE
        \item[c] The Wald-based CI for $\hat{N}_{RS}$ is evaluated by multiplying equation (\ref{eq_3}) by $N_{tot}^2$. The Wald-based CI for $\hat{N}_{CRC}$ is determined using equation (\ref{eq_8}), along with a proposed FPC-adjusted Bayesian credible interval \textbf{(Bold)}
  \end{tablenotes}
    \end{threeparttable}
\end{table}

The improvement in estimation precision and reduced interval widths are achieved on the basis of the anchor stream design, even though only 10\% anchor stream samples were collected from the target population. A more expanded set of simulation scenarios for the population sizes $N_{tot}=$(200, 500) can be found in the Web Appendix A in \textit{Supporting Information} (Web Tables 1-6).

\section{Discussion}

In this article, we propose a more flexible capture-recapture strategy for accelerating infectious disease monitoring, accounting for imperfect diagnostic or test results. We believe that this work is timely and well-motivated for monitoring the prevalence or case counts of infectious diseases such as COVID-19 or measles among a registered population, e.g. schools, communities, and geographic regions, when a diagnostic device or test-kit leverages an imperfect test for rapid results. To adjust for misclassified diagnostic signals, we extend recently proposed anchor stream design and methods \citep{Lyles2022a,Lyles2022b} for CRC analysis in epidemiological disease surveillance without misclassification by incorporating pre-specified sensitivity and specificity information from manufactured test kits. Our empirical studies demonstrate valid case count estimation accounting for misclassification errors, and show an apparent and expected precision improvement compared to estimation via the random sampling-based estimator alone.	

When focusing on disease monitoring in a closed and registered population from which a representative random sample can be drawn and misclassification parameters associated with the diagnostic device or test-kit are available from the manufacturer, the proposed method for anchor stream-based CRC analysis is relatively easy to implement in practice. It is important to note, however, that the anchor stream sample must be drawn carefully to assure not only its representativeness but also its independence relative to the voluntary testing stream \citep{Lyles2022a}. Our empirical studies indicate that leveraging a relatively small anchor stream sample together with arbitrarily non-representative voluntary test results can unlock a much more precise estimator of the true case count or prevalence in the target population than could be achieved through either sample alone. Along with existing disease surveillance data streams, this method can provide accurate and timely results. 

During the COVID-19 pandemic or in other infectious disease monitoring efforts, the proposed CRC strategy may be useful for application among registered populations for periodic  monitoring of infectious disease prevalence in a robust and economical way. The key is to have reliable information about the misclassification parameters (sensitivity and specificity) for each surveillance effort. In this article, we assume that the sensitivity and specificity parameters utilized in the analysis are provided by the manufacturer and are correct. As a first extension, it would be straightforward to account for uncertainty in the values provided by the manufacturer via an imputation step in the event that the data upon which they are based could be obtained. A second extension could be to consider the possible issue of transportability. That is, the actual sensitivity and specificity parameters operating in practical settings may be lower than those determined through professional examination in the laboratory, due to improper or inconsistent implementation of the diagnostic device or test-kit. In future work, it could be useful to seek the incorporation of external or internal validation data to estimate these operational parameters. Leveraging this extra information would lead to additional uncertainty in the estimation, but could also further expand the practical uses of this CRC strategy in solving real-world problems.


\section*{Acknowledgements}

This work was supported by the National Institute of Health (NIH)/National Institute of Allergy and Infectious Diseases (P30AI050409; Del Rio PI), the NIH/National Center for Advancing Translational Sciences (UL1TR002378; Taylor PI), the NIH/National Cancer Institute  (R01CA234538; Ward/Lash MPIs), and the NIH/National Cancer Institute (R01CA266574; Lyles/Waller MPIs).\vspace*{-8pt}



%  Here, we create the bibliographic entries manually, following the
%  journal style.  If you use this method or use natbib, PLEASE PAY
%  CAREFUL ATTENTION TO THE BIBLIOGRAPHIC STYLE IN A RECENT ISSUE OF
%  THE JOURNAL AND FOLLOW IT!  Failure to follow stylistic conventions
%  just lengthens the time spend copyediting your paper and hence its
%  position in the publication queue should it be accepted.

%  We greatly prefer that you incorporate the references for your
%  article into the body of the article as we have done here 
%  (you can use natbib or not as you choose) than use BiBTeX,
%  so that your article is self-contained in one file.
%  If you do use BiBTeX, please use the .bst file that comes with 
%  the distribution.  In this case, replace the thebibliography
%  environment below by 
%
\bibliographystyle{biom} 
\bibliography{references.bib}

% \begin{thebibliography}{}

% \bibitem{ } Cox, D. R. (1972). Regression models and life tables (with
% discussion).  \textit{Journal of the Royal Statistical Society, Series B}
% \textbf{34,} 187--200.

% \bibitem{ }  Hastie, T., Tibshirani, R., and Friedman, J. (2001). \textit{The 
% Elements of Statistical Learning: Data Mining, Inference, and Prediction}.
% New York: Springer.

% \end{thebibliography}

%  If your paper refers to supporting web material, then you MUST
%  include this section!!  See Instructions for Authors at the journal
%  website http://www.biometrics.tibs.org


\section*{Supporting Information}

Web Appendix A, referenced in Section \ref{section_3}, is available with
this paper at the Biometrics website on Wiley Online
Library.\vspace*{-8pt}

\appendix

%  To get the journal style of heading for an appendix, mimic the following.

\section{}
\subsection{Details for Extra Variance in the FPC-adjusted variance estimator}\label{Apendix_1}

The FPC-adjusted variance estimator is derived following the same strategy as the variance estimator for the bias-corrected prevalence estimator in (\ref{eq_3}) \citep{Ge2023b} and each such variance estimator has the following form.  
\begin{align*}
    \hat{V}_2(\hat{\pi}_{ij}) = FPC_{ij}\hat{V}_1(\hat{\pi}_{ij}) + \hat{V}_{extra}^{ij}, ~~ i,j=0,1 
\end{align*}
where $\hat{V}_{extra}^{ij}$ is derived as follows:
\begin{align}
    \hat{V}_{extra}^{11} &= \frac{1}{(Se_2+Sp_2-1)^2}\frac{1}{N_{1}}[\hat{\pi}_{11} Se_2(1-Se_2)+(1-\hat{\pi}_{11})Sp_2(1-Sp_2)] \\
    \hat{V}_{extra}^{10} &= \frac{1}{(Se_1+Sp_1-1)^2}\frac{1}{N_{1}}[\hat{\pi}_{10} Se_1(1-Se_1)+(1-\hat{\pi}_{10})Sp_1(1-Sp_1)] \\
    \hat{V}_{extra}^{01} &= \frac{1}{(Se_2+Sp_2-1)^2}\frac{1}{N_{tot}-N_{1}}[\hat{\pi}_{01} Se_2(1-Se_2)+(1-\hat{\pi}_{01})Sp_2(1-Sp_2)] 
\end{align}

\label{lastpage}

\end{document}

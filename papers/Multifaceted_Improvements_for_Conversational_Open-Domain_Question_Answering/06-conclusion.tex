\section{Conclusion}\label{sec:conclusion}
This paper proposes multifaceted improvements for the conversational OpenQA task. Concretely, a KL-divergence based regularization is proposed in pre-training for a better question understanding. A post-ranker module is added to realize the joint training of question and passage representations to generate a better passage ranking. A semi-automatic curriculum learning strategy is designed to encourage the reader to find the answer without manually adding golden passages.
The experimental evaluation demonstrates the effectiveness of our {\modelname}.
% As future work, we plan to try some more flexible and effective neural network to improve the post-ranker.
\section{\uppercase{Related Work}}
\label{sec:related_work}

In this section, we first present  concisely recent works on \gls*{lp} recognition.
Then, we situate the current state of \gls*{alpr} research in terms of cross-dataset experiments, Mercosur \glspl*{lp}, and motorcycle~\glspl*{lp}.

The good speed/accuracy trade-off provided by YOLO networks~\citep{redmon2016yolo,bochkovskiy2020yolov4} inspired many authors to explore similar architectures targeting real-time performance for \gls*{lp} recognition.
For example, \cite{silva2020realtime} proposed a YOLO-based model to simultaneously detect and recognize all characters within a cropped \gls*{lp}. This model, called \crnet, consists of the first eleven layers of YOLO and four other convolutional layers added to improve non-linearity.
Impressive results were achieved through \crnet both in the original work and in more recent ones~\citep{laroca2021efficient,oliveira2021vehicle,silva2022flexible}.

While \cite{kessentini2019twostage} applied the YOLOv2 model without any change or refinement to this task, \cite{henry2020multinational} used a modified version of YOLOv3 that includes spatial pyramid pooling.
Although these two models achieved high recognition rates in multiple datasets, they are very deep for \glspl*{lp} recognition, making it difficult to meet the real-time requirements of \gls*{alpr}~applications.

Rather than exploring object detectors, \cite{zou2020robust} adopted a bi-directional \gls*{lstm} network to implicitly locate the characters on the \gls*{lp}.
They explored a $1$-D attention module to extract useful features of the character regions, improving the accuracy of \gls*{lp} recognition.
In a similar way, \cite{zhang2021robust_attentional} used a $2$-D attention mechanism to optimize their recognition model, which uses a 30-layer \gls*{cnn} based on \xception for feature~extraction.
An \gls*{lstm} model was adopted to decode the extracted features into \gls*{lp} characters.

There are also several works where multi-task networks were designed to holistically process the entire \gls*{lp} image and, thus, avoid character segmentation, such as~\citep{spanhel2017holistic,goncalves2019multitask}.
As these networks employ fully connected layers as classifiers to recognize the characters on the predefined positions of the \glspl*{lp}, they may not generalize well with small-scale training sets since the probability of a specific character appearing in a specific position is low.
To deal with this, \cite{wang2022rethinking} proposed a weight-sharing classifier, which is able to spot instances of each character across all positions.

Considering that the recognition rates achieved under the traditional-split protocol have significantly increased in recent years, some authors began to conduct small cross-dataset experiments to analyze the generalization ability of the proposed methods.
For example, \cite{silva2020realtime,laroca2021efficient} used all $108$ images from the \openalpreu dataset for testing, rather than using some for training/validation.
Nevertheless, the results achieved in so few test images are susceptible to tricks, especially considering that heuristic rules were explored to improve the \gls*{lp} recognition results in both~works.

As another example, \cite{zou2020robust,zhang2021robust_attentional,wang2022rethinking} trained their recognition models specifically for Chinese \glspl*{lp} on approximately $200$K images from the \ccpd dataset~\citep{xu2018towards} and tested them on images from other datasets that also contain only Chinese \glspl*{lp}.
In this case, it is not clear whether the proposed models perform well on \glspl*{lp} from other regions.
In fact, the authors trained another instance of the respective models to evaluate them in the \aolp dataset~\citep{hsu2013application}, which contains \glspl*{lp} from the Taiwan~region.

Recently, Mercosur countries adopted a unified standard of \glspl*{lp} for newly purchased vehicles, inspired by the integrated system adopted by European Union countries many years ago.
Although the new standard has been implemented in all countries in the bloc, there is still no public dataset for \gls*{alpr} with images of Mercosur \glspl*{lp} as far as we~know.

In this sense, \cite{silvano2021synthetic} presented a methodology that couples synthetic images of Mercosur \glspl*{lp} with real-world images containing vehicles with other \gls*{lp} layouts.
A model trained exclusively with synthetic images achieved promising results on $1{,}000$ real images from various sources; however, it is difficult to assess these results accurately since the test images were not made available to the research~community. 
The \gls*{lp} recognition stage was not~addressed.

Despite the fact that motorcycles are one of the most popular transportation means in metropolitan areas~\citep{hsu2015comparison}, they have been largely overlooked in \gls*{alpr} research.
There are even works where images of motorcycles were excluded from the experiments~\citep{goncalves2018realtime,silva2020realtime}, mainly because \glspl*{lp} of motorcycles usually have two rows of characters, 
which are challenging to sequential/recurrent-based methods~\citep{kessentini2019twostage,silva2022flexible}, and also because they are generally smaller in size (having less space between characters) and are often~tilted.

In this regard, there is a great demand for a public dataset for end-to-end \gls*{alpr} with the same number of images of cars and motorcycles to give equal importance to \glspl*{lp} with one or two rows of characters in the assessment of \gls*{alpr}~systems.
\section{\uppercase{Introduction}}
\label{sec:introduction}

\glsresetall

The global automotive industry expects to produce more than $82$ million light vehicles in 2022 alone, despite the ongoing coronavirus pandemic and chip supply issues~\citep{news2021forbes,news2021ihsmarkit}.
In addition to bringing convenience to owners, vehicles also significantly modify the urban environment, posing challenges concerning pollution, privacy and security --~especially in large urban centers.
The constant monitoring of vehicles through computational techniques is of paramount importance and, therefore, it has been a frequent research topic.
In this context, \gls*{alpr} systems~\citep{weihong2020research,lubna2021automatic} stand out.%
\ifscitepress
\else
\blfootnote{\scriptsize This is an author-prepared version of a paper accepted for presentation at the International Conference on Computer Vision Theory and Applications (VISAPP) 2022. The published version is available at the \emph{SciTePress Digital Library} (DOI: \href{https://doi.org/10.5220/0010846800003124}{\textcolor{blue}{10.5220/0010846800003124}}).}
\fi


\gls*{alpr} systems exploit image processing and pattern recognition techniques to detect and recognize the characters on \glspl*{lp} from images or videos.
Some practical applications for an \gls*{alpr} system are road traffic monitoring, toll collection, and vehicle access control in restricted areas~\citep{spanhel2017holistic,henry2020multinational,wang2022rethinking}.

Deep \gls*{alpr} systems have shown remarkable performance on \glspl*{lp} from multiple regions due to advances in deep learning and the increasing availability of datasets~\citep{henry2020multinational,silva2022flexible}.
In the past, the evaluation of \gls*{alpr} systems used to be done within each of the chosen datasets, i.e., the proposed methods were trained and evaluated on different subsets from the same dataset.
Such an evaluation was carried out independently for each dataset.
Recently, considering that deep models can take considerable time to be trained (especially on low- or mid-end GPUs), the authors have adopted a protocol where the proposed models are trained once on the union of the training images from the chosen datasets and evaluated individually on the respective test sets~\citep{selmi2020delpdar,laroca2021efficient}.
Although the images for training and testing belong to disjoint subsets, these protocols do not make it clear whether the evaluated models have good generalization ability, i.e., whether they perform well on images from other scenarios, mainly due to domain divergence and data selection bias~\citep{torralba2011unbiased,tommasi2017deeper,zhang2019recent}.

In this regard, many computer vision researchers have carried out cross-dataset experiments --~where training and testing data come from different sources~-- to assess whether the proposed models perform well on data from an unknown domain~\citep{ashraf2018learning,zhang2019recent,estevam2021tell}.
However, as far as we know, there is no work focused on such experimental settings in the \gls*{alpr} context.

Considering the above discussion, in this work we evaluate for the first time various \gls*{ocr} models for \gls*{lp} recognition in a leave-one-dataset-out experimental setup over nine public datasets with different characteristics.
The results obtained are compared with those achieved when training the models in the same way as in recent works, that is, using the union of the training set images from all datasets (hereinafter, this protocol is referred to as traditional-split). 

Deep learning-based \gls*{alpr} systems have often achieved recognition rates above $99$\% in existing datasets under the traditional-split protocol (some examples are provided in Section~\ref{sec:related_work}). However, in real-world applications, new cameras are regularly being installed in new locations without existing systems being retrained as often, which can dramatically decrease the performance of those models.
A leave-one-dataset-out protocol enables simulating this specific scenario and providing an adequate evaluation of the generalizability of the models.

\gls*{alpr} is commonly divided into two tasks: \gls*{lp} detection and \gls*{lp} recognition.
The former refers to locating the \gls*{lp} region in the input image, while the latter refers to extracting the string related to the \gls*{lp}.
In this work, we focus on the \gls*{lp} recognition stage since it is the current bottleneck of \gls*{alpr} systems~\citep{laroca2021efficient}.
Thus, we simply train the off-the-shelf YOLOv4 model~\citep{bochkovskiy2020yolov4} to detect the \glspl*{lp} in the input images.
For completeness, we also report the results achieved in this stage on both of the aforementioned~protocols.

As part of this work, we introduce a publicly available dataset, called \dataset\footnote{The \dataset dataset is publicly available to the research community at \supplementary}, that contains $\numimages$ images captured at toll booths installed on a Brazilian highway.
It has images of two different \gls*{lp} layouts: Brazilian and Mercosur\footnote{Mercosur (\textit{Mercado Com\'{u}n del Sur}, i.e., Southern Common Market in Castilian) is an economic and political bloc
comprising Argentina, Brazil, Paraguay and Uruguay.}, with half of the vehicles being motorcycles (see details in Section~\ref{sec:dataset}).
To the best of our knowledge, this is the first public dataset for \gls*{alpr} with images of Mercosur \glspl*{lp} and the largest in the number of motorcycle images.
This last information is relevant because motorcycle \glspl*{lp} have two rows of characters, which is a challenge for sequential/recurrent-based methods~\citep{silva2022flexible}, and therefore have been overlooked in the evaluation of \gls*{lp} recognition models (see Section~\ref{sec:related_work}).

Our paper has two main contributions:
\begin{itemize}
    \item A traditional-split \textit{versus} leave-one-dataset-out experimental setup that can be considered a valid testbed for cross-dataset generalization methods proposed in future works on \gls*{alpr}.
    We present a comparative assessment of $\numbaselines$ \gls*{ocr} models for \gls*{lp} recognition on nine publicly available datasets.
    The main findings were that
    (i)~there are significant drops in performance for most datasets when training and testing the recognition models in a leave-one-dataset-out fashion, especially when there are different fonts of characters in the training and test images;
    (ii)~no model achieved the best result in all experiments, with $6$ different models reaching the best result in at least one dataset under the leave-one-dataset-out protocol; 
    and (iii)~the proposed dataset proved very challenging, as both the models trained by us and two commercial systems failed to reach recognition rates above $70$\% on its test set~images.
    \item A public dataset with $\numimages$ images acquired in real-world scenarios, being half of them of vehicles with Mercosur \glspl*{lp}.
    Indeed, one of the objectives of this work is to provide a reliable source of information about Mercosur \glspl*{lp}, as much news --~often outdated~-- has been used as~references.
\end{itemize}

The remainder of this paper is organized in the following manner. 
In Section~\ref{sec:related_work}, we briefly review related works.
The \dataset dataset is introduced in Section~\ref{sec:dataset}.
The setup adopted in our experiments is thoroughly described in Section~\ref{sec:experiments}.
Section~\ref{sec:results} presents the results achieved.
Finally, Section~\ref{sec:conclusions} concludes the paper and outlines future directions of~research.
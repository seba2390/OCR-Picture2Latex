\section{\uppercase{Conclusions}}
\label{sec:conclusions}

As the performance of traditional-split \gls*{lp} recognition is rapidly improving, researchers should pay more attention to cross-dataset \gls*{lp} recognition since it better simulates real-world \gls*{alpr} applications, where new cameras are regularly being installed in new locations without existing systems being retrained every~time.

As a first step towards that direction, in this work we evaluated $\numbaselines$ \gls*{ocr} models for \gls*{lp} recognition on $9$ public datasets with a great variety in several aspects (e.g., acquisition settings, image resolution, and \gls*{lp} layouts).
We adopted a traditional-split \textit{versus} leave-one-dataset-out experimental setup to empirically assess the cross-dataset generalization of the chosen models.
It is noteworthy that we are not aware of any work in the \gls*{alpr} context where so many methods were implemented and compared or where so many datasets were explored in the~experiments.

As expected, the experimental results showed significant drops in performance for most datasets when training and testing the recognition models in a leave-one-dataset-out fashion.
The fact that very low recognition rates (around $63$\%) were reported in the \englishlp and \aolp datasets underscored the importance of carrying out cross-dataset experiments, as very high recognition rates (above $95$\% and $99$\%, respectively) are frequently achieved on these datasets under the traditional-split~protocol.

The importance of exploring various datasets in the evaluation was also demonstrated, as no model performed better than the others in all experiments.
It was quite unexpected for us that six different models reached the best result in at least one dataset under the leave-one-dataset-out protocol.
In this sense, we draw attention to the fact that most works in the literature used three or fewer datasets in the experiments, although this has been gradually changing in recent years~\citep{selmi2020delpdar,laroca2021efficient}.

We also introduced a publicly available dataset for \gls*{alpr} that, to the best of our knowledge, is the first to contain images of vehicles with Mercosur \glspl*{lp}.
We expect it will assist in developing new approaches for this \gls*{lp} layout and the fair comparison between methods proposed in different~works.
Additionally, the proposed dataset includes $10{,}000$ motorcycle images, being by far the largest in this regard.
\dataset has proved challenging in our experiments, as both the models trained by us and two commercial systems reached recognition rates below $70$\% on its test~set.

As future work, we plan to gather images from the internet to build a novel dataset for end-to-end \gls*{alpr} with images acquired in various countries/regions, by many different cameras, both static or mobile, with a well-defined evaluation protocol for both within- and cross-dataset \gls*{lp} detection and \gls*{lp} recognition.
In addition, we intend to leverage the potential of \glspl*{gan} to generate hundreds of thousands of synthetic \gls*{lp} images with different transformations and balanced character classes in order to improve the generalization ability of deep models.
Finally, we would like to carry out more experiments to quantify the influence of each dataset, especially \dataset, on the performance of the models under the leave-one-dataset-out~protocol.
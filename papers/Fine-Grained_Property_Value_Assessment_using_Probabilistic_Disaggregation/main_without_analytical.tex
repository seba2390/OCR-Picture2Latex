\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage[review]{cvpr}  
%\usepackage{cvpr}              % To produce the CAMERA-READY version
%\usepackage[pagenumbers]{cvpr} % To force page numbers, e.g. for an arXiv version

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}

\DeclareMathOperator*{\argmin}{arg\,min} 

\input{mvrl_macros.tex}

\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}

\def\cvprPaperID{35} % *** Enter the CVPR Paper ID here
\def\confName{EARTHVISION}
\def\confYear{2022}

\begin{document}

%%%%%%%%% TITLE
\title{Fine-Grained Property Value Assessment using Probabilistic Disaggregation}

% Cohen, Ben, Jacob?, Usman?, Aram?, Nathan

\author{First Author\\
Institution1\\
Institution1 address\\
{\tt\small firstauthor@i1.org}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
\and
Second Author\\
Institution2\\
First line of institution2 address\\
{\tt\small secondauthor@i2.org}
}

\maketitle
%\thispagestyle{empty}

%%%%%%%%% ABSTRACT
\begin{abstract}

We present a probabilistic method for creating pixel-level estimates of values using only labels given at a coarse region level. The method extends previous work by estimating value with probability distributions, which include a quantification of uncertainty in the prediction. We provide theoretical insight for why this method is effective as well as demonstrations of the value disaggregation on a property value dataset as well as on a simulated experiment of interpolating values from low resolution bands.

\end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}

In many scenarios, we are interested in making estimates at a finer resolution than the labels available. In this work, we focus on regression/counting tasks, which are important for a variety of tasks, including estimating population and housing densities, property values, and species distributions.

We address the task of per-pixel regression of values where the only labels available during training are aggregated values over spatial regions. Previous work on this topic~\cite{jacobs2018weakly} used a region aggregation layer to estimate population density at the pixel level based on satellite imagery and census data. A key limitation of this method is that it provides a direct point estimate without providing any information about uncertainty or confidence of predictions. We incorporate a probabilistic representation for pixel and region values that provides both a value and uncertainty estimate at every pixel. 

We provide the theoretical motivation and demonstrate the effectiveness of value disaggregation using a probabilistic representations of the learned values. Probability distributions for pixel-level values are sampled from using the reparameterization trick~\cite{Kingma2014AutoEncodingVB}. Samples are then aggregated to compare to coarse labels. The method uses a convolutional neural network (CNN) as a backbone to produce the probabilistic pixel-level outputs from overhead imagery. This probabilistic approach to disaggregation gives estimates of values at the pixel level, as well as uncertainty estimates for those measurements through the estimated variances of the value distributions. 

\begin{figure}[t]
    \centering
    \includegraphics[width=1\linewidth]{CS612/figures/main_figure_3.jpg}
    \caption{Property value estimation via probabilistic disaggregation. Provided overhead imagery (left), we estimate the contribution to the property value of each pixel from a per-pixel Gaussian distribution (right). The aggregate value forms our value predictions per region (below).}
    \label{fig:overview_image}
\end{figure}

The primary application of the probabilistic disaggregation method that we consider is to identify visual features from overhead imagery that contribute and detract the most from the monetary value of a parcel. To facilitate this, we have collected a dataset consisting of publicly accessible aerial imagery and property values from Hennepin County, Minnesota. We demonstrate that we are able to accurately predict parcel values based on a pixel-level prediction of contributions to value. Furthermore, predictions are more accurate with the sampling approach to disaggregation than with deterministic baselines. We also present a toy experiment on Sentinel-2 satellite imagery that uses the disaggregation method to upsample artificially low-resolution bands, given information from high-resolution bands.

The key contributions of this work include:
\begin{itemize}
    \item Providing the theoretical motivation for a probabilistic disaggregation method for fine-grained estimation from coarse labels.
    \item Formulating a probabilistic setting for disaggregation and demonstrating both quantitative and qualitative value.
    \item Showing how the method works in a controlled simulated experiment using Sentinel-2 imagery. 
    \item Showing how the method works on property value estimation from overhead imagery.
\end{itemize}

\section{Background}

Our work produces fine-grained, pixel-level labels from labels that are aggregated over large image regions. We describe related work in the area of weakly supervised image segmentation and object density estimation, which is the most closely related pixel-level labeling task.

\subsection{Weakly Supervised Segmentation}

The goal of semantic image segmentation is to predict class labels for each pixel of an image. In areas where image annotations are limited, it is useful to use weak labels for supervision. Less expensive image labels, such as bounding boxes, are coarser resolution and potentially noisy.

Weakly-supervised semantic segmentation presents a different problem for overhead imagery compared to natural scene imagery. For instance, in overhead images, the boundaries among the objects are usually unclear and they contain fine-grained objects while the natural scene images have more coarse-grained objects~\cite{Chan_2020}. We focus on overhead imagery in this work.

In \cite{Nivaggioli2019WeaklySS}, the authors use image level annotations as weak supervision for semantic segmentation on satellite images. To generate pixel-level labels from image labels, they used a method introduced in \cite{Ahn_2018_CVPR}. They first train a classification network consisting of global average pooling (GAP) and a fully connected layer with image level labels. Then, they train an affinity network which learns the relationship between a pixel and its neighbourhood, using a random walk to generate the segmentation labels.
In \cite{7414501}, the authors use weakly supervised learning to fine tune a pre-trained auto-encoder to produce annotations for land-cover segmentation on satellite images.

For this work, we focus on using weak labels for regression or counting tasks, rather than segmentation, in overhead imagery. For this, we extend the work \cite{jacobs2018weakly} which uses coarse-grained labels to predict density functions at pixel-level. 

However, the works mentioned above do not consider the uncertainty of the predictions. In this work, we extend these ideas to a probabilistic setting which provides both estimations and uncertainty.

% Another technique that is used in weakly supervised segmentation of satellite images is labels comprised of single geotagged points. In \cite{wang2020weakly}, other than the image level labels, they use sparse pixel labels in which one pixel is only labeled and the other pixels are masked out. 



\subsection{Object Counting}

Another related task is counting the number of object instances within imagery. This task is commonly associated with crowd counting. Recently, many powerful CNN-based object detectors such as YOLO ~\cite{yolo} and R-CNN~\cite{Girshick2014RichFH} present high detection accuracy on objects in sparse scenes. However, these methods have difficulty in more noisy scenes and denser crowds. Regression based counting has proved a more effective method for crowd density estimation in noisier and denser crowds ~\cite{gao2020cnnbased}. Typically these methods learn a combination of global and local features, and learn a mapping from features to crowd estimates.

For instance, in \cite{chan2008privacy}, after doing motion segmentation of the crowds moving in different directions, features are normalized to account for perspective and extracted. Then the Gaussian process regression is used to estimate the number of people. However, the spatial information of the annotations have not been taken in to account in this work. 

Another method which is used in crowd counting is density estimation which uses the spatial information\cite{gao2020cnnbased, lempitsky2010learning}. With this method, density is estimated and a count is obtained by integrating over the region. Our method follows this last approach, in which we estimate a pixel-level contributions to value and sum to create estimates over wider regions.

\subsection{Probabilistic Representation}

Probabilistic representation of internal features and/or model outputs has proven effective in a variety of machine learning tasks. For example, Variational Autoencoders (VAE)~\cite{Kingma2014AutoEncodingVB}, embed features in a probabilistic latent space. Samples from the distribution are then passed through a decoder to reconstruct the original input. In contrast, a metric learning approach to probabilistic representation is presented in \cite{shi2019probabilistic}, in output features are represented by a probability distribution to allow for lower quality samples to cover a wider selection of possibilities in feature space.

A key development that allows probabilistic features to be used in machine learning applications is the reparameterization trick\cite{Kingma2014AutoEncodingVB}, which allows us to sample from a variety of classes of probability distributions in a differentiable way. For example, suppose we are given a Gaussian distribution $\varphi \sim \mathcal{N}(\mu, \sigma^2)$, where the mean $\mu$ and variance $\sigma^2$ are learnable parameters. 
We note that sampling from $\varphi$ is equivalent to sampling from $\tilde{\varphi} = \mu + \sigma^2 \mathcal{N}(0, 1)$. This removes sources of randomness from the parameters $\mu$ and $\sigma^2$, and so we are free to backpropagate through the expression.

\section{Problem Statement}


We address the task of estimating spatially pixel-level property values using high-resolution aerial imagery and parcel-level property values. We have property value labels at the parcel-level, but seek to quantify contribution to the overall value of each square meter that is visible from overhead imagery. Since property values are often used in downstream processing tasks, such as insurance risk adjustment, it is critical to also provide a quantification of the uncertainty in these estimates.

We model this as the problem of estimating a geospatial function, $v(l)\in\mathcal{R}^+$, for a location, $l\in\mathcal{R}^2$, from overhead imagery, $I$, of the location. This function, $v$, reflects the value of the property, including the land and building value, at a particular location. We redefine this as a gridded geospatial function, $v(p_i)$, where the value corresponds to the value in the area imaged by a pixel, $p_i\in l$. Therefore, the problem reduces to making pixel-level predictions of $v$ from the input imagery.

The key challenge is that we do not have samples from the function, $v$.  We only have a set of spatially aggregated values, $Y=\left\{ y_1\ldots y_n\right\}$, where each value, $y_i \in \mathbb{R}^+$, represents the value of the corresponding parcel/regions, $R=\left\{ r_1\ldots r_n\right\}$. Specifically, we define $y_i = V(r_i) = \sum _{p_j\in r_i}v\left( p_j\right)$. These regions could have arbitrary topology and be overlapping, but in practice will typically be simply connected and disjoint.

As discussed above, the labels are provided at the parcel/region level. To generate the estimated values for each parcel, we assume the value of the region $r_i$ is distributed according to:
\begin{equation}
    y_i \sim \int w_i(l) P(v(l)|I(l); \Theta) dl 
\end{equation}
where $w_i(l)$ is the proportion of location $l$ that belongs to region $r_i$ and $P(v(l)|I(l); \Theta)$ is a distribution we estimate for the value of location $l$ given image of location $l$ and the parameters $\Theta$. Since the locations are discrete pixels in our formulation of the problem, the above becomes:
\begin{equation}
\label{eq:prob_formulation}
    y_i \sim \sum _{p_j \in r_i}w_i(p_j) P(v(p_j)|I(p_j); \Theta) 
\end{equation}
Previous work has shown that it is possible to train the model, in a weakly supervised fashion, to make pixel-level predictions using only these aggregated labels~\cite{jacobs2018weakly}. The key observation was that since the aggregation process is linear, it is possible to propagate derivatives through the operation, enabling end-to-end optimization of a neural network that predicts $v$. 

The main limitation of the previous work is that it does not capture the uncertainty in the underlying distributions, which limits its practical usefulness. We represent pixel-level and parcel-level values as Gaussian probability distributions for the estimated value of a the underlying location with a learned mean and variance.

\subsection{The Linear-Gaussian Case}

Suppose we assume that the probability distributions $P(v(p_j)|I(p_j); \Theta)$ of the value contribution of the pixel $p_j$ are linear-Gaussian. Then there is a vector $f$ such that this value distribution is given by
\begin{equation}
    P(v(p_j)|I(p_j); \Theta) = p_j^T f + \mathcal{N},
\end{equation} where $\mathcal{N}$ is Gaussian noise. We can write this for all pixels $\{p_j\}_{j=1}^N$ in the dataset as the single matrix multiplication $\mathbf{P}^{\mathsf{T}} f + \mathcal{N}$, where $\mathbf{P} = [p_1,p_2, \ldots, p_n]$.

The summation of contributions over individual regions $\{r_i\}_{i=1}^M$ is a linear operation that can be represented as an $M\times N$ matrix $\mathbf{R}$. Therefore, the value of the set of observations of the system in Equation \ref{eq:prob_formulation} becomes:
\begin{equation}
    Y \approx \mathbf{R}\mathbf{P}^{\mathsf{T}} f.
\end{equation}
We can thus estimate the parameters of the transformation $f$ by $ \hat{f} = \left(\mathbf{R}\mathbf{P}^{\mathsf{T}}\right)^\dagger Y,$ where $\dagger$ denotes the pseudo-inverse. We can then estimate the value contribution of each pixel using the forward model $\hat{f}^T p_j.$

In actuality, the pixel value model is not linear-Gaussian. The transformation $F(p_j) = P(v(p_j)|I(p_j); \Theta)$ is highly non-linear and dependent on the values of neighboring pixels. In this case, we replace the above process of solving for parameters of $f$ such that $F(p_j)={p_j}^T f$, we use a convolutional neural network (CNN) to approximate the parameters of the more complicated function.

% Starting with our approximation $\sum_{p_j\in r_i}\hat{f}\left( p_j\right)$, let's assume that each pixel is represented by a column vector and that $\hat{f}$ is a linear function, $\hat{f}(p_i) = f^{\mathsf{T}}p_i$. We can then write this, for all pixels, as a single matrix multiplication: $\mathbf{P}^{\mathsf{T}} f$, where $\mathbf{P} = [p_1,p_2, \ldots, p_n]$.  Since the summation over regions, $\sum_{p_j\in r_i}$, is a linear operation, we can define the set of observations as linear system, $Y \approx \mathbf{R}\mathbf{P}^{\mathsf{T}} f$.  It then becomes clear that we can estimate the parameters, $f$, as a linear system $(\mathbf{R}\mathbf{P}^{\mathsf{T}})^\dagger Y.$ %^\mathsf{T} 

% Once we have $\hat{f}$ then we can estimate the values for each pixel using the forward model $f^{\mathsf{T}}p_i$.

\section{Approach}

We use a CNN, which takes overhead imagery as input, to generate a pixel-level probabilistic value map. We model pixel-level values as Gaussian distributions with the mean representing the most likely value of for the corresponding piece of land and variance modeling uncertainty in the estimation. For simplicity, we assume the output pixel-value distributions are independent and allow the CNN to reflect dependencies between nearby pixels. By aggregating pixel-level distributions for each pixel in a parcel, we obtain an estimate for the overall value of the parcel, for which we have labels.

\subsection{Optimization}

Given this model, and the assumption of independent Gaussian distributions at each pixel, we define a sampling-based approach to go from pixel-level value distributions to parcel-level predictions.

\subsubsection{Probabilistic Representation}
\label{sec:sampling}

The value distribution at a pixel $p_i$ is given by:

\begin{equation}
    \hat{y}(p_i) \sim \mathsf{\mathcal{N}}({{\mu}_i}, {\sigma^{2}}_i),
\end{equation}
where $\mu_i$ and $\sigma^{2}_i$ are the outputs of the backbone network.
We can then take a random sample of each per-pixel distribution following the reparameterization trick, and optimize our network by the Mean Squared Error (MSE), as we do for the deterministic baseline:
\begin{equation}
   \mathcal{L}_{MSE}=\argmin_\Theta \sum_{i=1}^{N}(y_i -\sum_{p_j\in r_i} v( p_j; \Theta) )^2
\end{equation}
This allows us to optimize directly for error in value estimation, while still utilizing the probabilistic uncertainty in the property value estimation.

In addition to MSE, we incorporate entropy regularization in order to avoid the variance of the predicted distributions collapsing to 0 \cite{Kingma2014AutoEncodingVB}. This is accomplished by subtracting a constant times the sum of the entropies of each pixel distribution in a given input image. That is, the total loss is given by
\begin{align}
    \mathcal{L}_{\mathrm{Total}} &= \mathcal{L}_{MSE} - \lambda\sum_{i=1}^N \sum_{p_j \in r_i} \mathbb{H}\left(\hat{y}(p_j)\right) \\
    &= \mathcal{L}_{MSE} - \lambda \sum_{i=1}^N \sum_{p_j \in r_i} \frac{1}{2} \log\left(2\pi e \sigma_j^2\right).
\end{align}

\subsubsection{Baselines}
\label{sec:baselines}
We compare the results of the probabilistic disaggregation method against two deep learning baselines: a uniform-value assumption and a linear aggregation method.

With the uniform-value assumption, we assume that the value of each parcel is evenly distributed among the pixels included in the parcel. This results in strong pixel-level labels for all viable pixels in the dataset, although these strong labels may not be the best representation of the data. Using these labels, we train a deterministic backbone to predict values matching the pixel-level labels.

We also use a deterministic linear aggregation as a baseline for comparison to the probabilistic method. This method treats the input as a per pixel value-estimation, and sums the pixel values over the regions using a single linear layer. We then optimize the baseline with the MSE for the pixel value estimate $\hat{y}(p_j, \Theta)$ corresponding to network weights $\Theta$:
\begin{equation}
\mathcal{J}(\theta) = \sum_{i=1}^{N}\left|y_i -\sum_{p_j\in r_i}\hat{y}( p_j; \Theta) \right|^2.
\end{equation}
% where $\{p_j\}$ are the set of pixels in region $r_i$, with ground truth value $y_i$.
This method is essentially the method presented in~\cite{jacobs2018weakly}, which was applied to the similar problem of population density estimation.

In evaluation, we compare against two other simple baselines non-deep learning baselines: use the best fit Gaussian distribution on the training set, and use the average pixel value on the training set, along with parcel size, to estimate value.


\section{Evaluation}
\label{sec:evaluation}

\subsection{Backbone Architecture}
    For these experiments we used a UNet~\cite{ronneberger2015u} as a backbone, which provides an output map at the same resolution as the input image. We configured the network to output a Gaussian probability distribution for each input pixel by generating a two channel output. The first channel corresponds to the means of the Gaussian distributions and the second channel corresponds to the variances. We apply the Softplus function, $f(x) = \log(1+ \exp{(x)})$, to the variances $\sigma^2$ before constructing Gaussian distributions with the resulting means and variances.


% \subsection{Synthetic Data Experiments}

% \todo{Shashank to show it working on CIFAR?}

% What we hope to show:
% \begin{itemize}
%     \item that we can accurately recover the underlying distributions (something like EMD between true and recovered distributions)
%     \item how this ability depends on properties of the data
% \end{itemize}

\subsection{Property Value Estimation Experiments}

The primary evaluation of the probabilistic disaggregation method is carried out in the following section. We estimate the contribution to overall property value of each square meter visible from overhead imagery.

\subsubsection{Hennepin County Dataset}
The Hennepin County Dataset was collected using GIS Open Data for Hennepin County, Minnesota. For each sample, a sub-region of high-resolution aerial imagery from the year 2020 was cropped. 1085 images of size 512x512 were collected with a Ground Sample Distance (GSD) of 1 meter. 

Geometries were extracted from the GIS Open Data for parcels. For each chip, corresponding parcels fully contained within each chip were extracted. We also collected the parcels' market value, which was accurate as of 2020. In order to effectively use the dataset for a regression task, we needed to clean the outliers and defects from the collected dataset. For instance, many parcels in the Hennepin dataset include a market value of zero. These regions are often either unlabeled or public parcels. We also remove parcels with disproportionately high value from downtown Minneapolis. Each sample of the dataset contains the information: region image, parcel masks, and corresponding market values. We collected over 90,000 parcels with an average area of 936 pixels and an average value of \$ 312,000. The average value of a pixel on the training set is approximately \$ 336.22. We hold out 20\% of the dataset for testing and validation sets, with 10\% used for validation and 10\% used for testing. 

% \begin{figure}[h]
%         \centering
%         \includegraphics[width=1\linewidth]{CS612/figures/value_dist.jpg}
%         \caption{ Parcel values plotted by the size in pixels of the region. }
%         \label{fig:value_vs_size}
% \end{figure}

\begin{figure}[t]
        \centering
        \includegraphics[width=1\linewidth]{CS612/figures/hennepin_example.jpg}
        \caption{ An example of the regions $R$ and their associated values $Y$ for image $I$  described by the Hennepin County Dataset.}
        \label{fig:dataset_examples}
\end{figure}


\subsubsection{Segmentation Pre-training}
We leverage weights from segmentation pre-training for initializing the model parameters. Microsoft's Open US Building Footprints were used to generate building labels. We train the weights of the backbone UNet on the binary task of building segmentation. We then use weights of network trained on building segmentation up to the classification layer to initialize the backbone of the disaggregation network. We find that using pre-trained weights reduces convergences time and improved performance. Mean Absolute Error reduces from $\$ 92,606$ per parcel with random initialization to $\$78,258$ per parcel with pre-training.

% as shown in Table \ref{tab:pretrain_results}.

% \begin{table}[ht]
% \centering
%  \begin{tabular}{||l | p{2.4cm} | p{3cm}||} 
%  \hline
%  Method  & Mean \newline Absolute Error & Mean Absolute \newline Percentage Error  \\ 
%  \hline\hline
%  Random & $ \$ 92,606$ & $29.54\% $ \\ 
%  \hline
%  Pre-trained & $ \$78,258$ & $25.07\% $ \\ 
%  \hline
%  \hline
% \end{tabular}
% \caption{Comparison of two models trained with sampling-based disaggregation. Models were trained for 200 epochs. }
% \label{tab:pretrain_results}
% \end{table}

\subsubsection{Property Value Estimation Results}
We show results of the pixel-level property value estimation for the probabilistic disaggregation method compared to three baselines in Table \ref{tab:results}. Two deep learning baselines are described in Section \ref{sec:baselines}. We also compare to a prediction based solely on the value the size of the parcel and average value of pixels in training set. We find that the probabilistic methods significantly outperform this simple baseline. In addition, they outperform or are on par with the deterministic deep learning baselines, while providing the additional benefit of quantitative uncertainty estimation. We also compare against the metrics obtained by estimating with the best fit Gaussian on the training set.

In Figure \ref{fig:qualitative_results}, we can see the value prediction maps corresponding to the different methods and examples of uncertainty maps for the probabilistic methods are given in Figure \ref{fig:qualitative_uncertainty}. The prediction maps generated with disaggregation provide fine detail about contributions to value as opposed to the less detailed estimates generated by the Uniform Label method. Another example of this fine detail is shown in Figure \ref{fig:pool_image}, where swimming pools are singled out as contributing significantly to the value of the corresponding parcel.



\subsubsection{Spatial Region Combination Experiment}
    \label{sec:merged}
    A major challenge of the experiments on parcel value is the lack of pixel-level ground truth labels. Because pixel-level labels do not exist for parcel values, we propose an experiment to evaluate the ability of a model trained on coarse labels to predict on fine labels. To accomplish this, we modify the training set to combine neighboring parcels for each region. Corresponding parcel values for joined regions are summed. An example is shown in Figure~\ref{fig:basic_results}. We watch for outliers in the training set, and skip combining any regions that would exceed $\$1000/m^2$. At inference, we evaluate on single parcels as in the standard experiment. 
    
    We demonstrate that the disaggregation method is able to accurately estimate pixel-level values by showing that we are able to effectively estimate single parcel values, as shown in Table ~\ref{tab:merged_results}. That is, we are able to predict on finer-grained labels than the set of labels that we trained on. The probabilistic methods perform on par with the deterministic disaggregation baselines, while again providing uncertainty estimations. In all cases, the deep learning baselines outperform the size-based estimation shown in Table \ref{tab:results}.
    
    \begin{figure}[ht]
        \centering
        \includegraphics[width=.45\linewidth]{CS612/figures/before_combined.png}
        \includegraphics[width=.45\linewidth]{CS612/figures/combined.png}
        \caption{We train on a version of the dataset where neighboring parcels are merged and values combined. For each image, the original parcels (left) are randomly combined (right) into super-parcels containing two or more of the original parcels. We use the same (non-merged) validation and test sets at inference.}
        \label{fig:basic_results}
    \end{figure}
    
    % \begin{figure}[ht]
    %     \centering
    %     \includegraphics[width=1\linewidth]{CS612/figures/value_dist_combined.jpg}
    %     \caption{Parcel values plotted by the size in pixels of the combined regions. }
    %     \label{fig:combined_size_vs_value}
    % \end{figure}
    
\subsubsection{Training and Evaluation Parameters}

    We train each model for 300 epochs using the  Adam optimization algorithm. We select the best checkpoint based on performance on the validation set, and present results on the test set. For the experiments with combined parcels described in Section \ref{sec:merged}, more training time was allotted as models take longer to converge in this scenario. At test-time, we take the means $\mu$ of the probabilistic models as the per-pixel value estimation. We aggregate the $\hat{y}$ of the respective methods and compare to the true value.   

%   \begin{figure*}[h]
%         \centering
%         \includegraphics[width=1\linewidth]{CS612/figures/Prediction_Example.png}
%         \caption{Row 1: Examples of aerial imagery from the Hennepin County Dataset. Row 2: Segmentation of valid parcels for the given overhead image. Row 3: Pixel-level property value predictions. Row 4: Aggregated parcel value prediction \todo{or is this ground truth? it would be good to have both in either case}.}
%         \label{fig:my_label}
%     \end{figure*}


\begin{figure}[t]
        \centering
        \includegraphics[width=1\linewidth]{CS612/figures/features.jpg}
        \caption{A zoomed in view of value predictions. We observe that high values are assigned to non-building objects such as pools and driveways.}
        \label{fig:pool_image}
    \end{figure}

\begin{figure*}[ht]
        \centering
        \includegraphics[width=1\linewidth]{CS612/figures/prob_nogauss.jpg}
        \caption{Means and variances of predictions on the test set. We observe high correlation between the means and variances.}
        \label{fig:qualitative_uncertainty}
    \end{figure*}
    
\begin{figure*}[ht]
        \centering
        \includegraphics[width=1\linewidth]{CS612/figures/value_pred_nogauss.jpg}
        \caption{ Qualitative examples of mean value predictions of the baselines and disaggregation model performing on the Hennepin county dataset. We observe that building pixels are valued highly in the linear and probabilistic methods. }
        \label{fig:qualitative_results}
    \end{figure*}


\begin{table}[ht]
\centering
 \begin{tabular}{||l |c|c|c||} 
 \hline
 Method  & MAE & MAPE & $\mathcal{P}_\pm(10^4)$ \\ [0.5ex] 
 \hline\hline
 Train Set Best Fit & $\$ 93,607$ & $32.86\% $ & $5.15\%$ \\
 \hline
   Size Estimation & $\$ 134,432$ & $43.13\%$ & NA
 \\
\hline
Uniform Labels & $ \$ 114,382$ & $33.44\% $ &  NA \\ 
 \hline
 Linear Baseline & $ \$86,427$ & $26.77\% $ & NA \\ 
 \hline
 Sampling Method & $\$78,258$ & $25.07\%$  &  $9.67\%$ \\ 
% \\https://www.overleaf.com/project/5c5cc37c6c4e656b198e26a4
 \hline
\end{tabular}
\caption{Results of evaluation on the Hennepin County Dataset. We show Mean Absolute Error (MAE) and Mean Absolute Percentage Error (MAPE) of predictions with ground truth parcel values. Results are compared across the best fit Gaussian on training set, as well as several baselines as described in Section \ref{sec:baselines}. For the probabilistic method, we also show the probability of being within $\$10,000$ of the ground truth value according to the predicted Gaussian distribution.}
\label{tab:results}
\end{table}

\begin{table}[ht]
\centering
\begin{tabular}{||l | c | c | c ||}
 \hline
 Method  & MAE & MAPE & $\mathcal{P}_\pm(10^4)$ \\ [0.5ex] 
 \hline\hline

  Size Estimation & $\$ 134,432$ & $43.13\%$ & NA
 \\
\hline
 Uniform Labels & $\$96,453$  & $30.11\%$ & NA \\
 \hline 
 Linear Baseline & $\$85,114$  & $26.90\%$ & NA \\ 
 \hline
 Sampling Method & $\$83,222$ & $26.25\%$ & $8.80\%$ \\ 
 \hline
\end{tabular}
\caption{Results of evaluation on the Hennepin County Dataset with random merging of neighboring parcels during training. We show Mean Absolute Error (MAE) and Mean Absolute Percentage Error (MAPE) of predictions with ground truth parcel values. Results of the probabilistic approach to disaggregation are compared to the baselines described in Section \ref{sec:baselines}. We also present the probability of being within $\$10,000$ of the ground truth value according to the predicted Gaussian distribution. Results for the training set best fit Gaussian as in Table \ref{tab:results} are not shown, as this now represents a completely different distribution of data than the test set.}
\label{tab:merged_results}
\end{table}

\subsection{Simulated Sentinel-2 Band Interpolation}
As another application of the method, we set up an experiment using high resolution Sentinel-2 bands to estimate simulated lower resolution band values. This toy experiment allows us to perform disaggregation on coarse labels in a setting in which high resolution pixel-level labels are available.

\subsubsection{EuroSAT Dataset}
The EuroSAT dataset~\cite{helber2019eurosat} is composed of 27000 Sentinel-2 images over a variety of European locations. Images have been cropped to $64 \times 64$ pixels and are assigned to one of 10 land-cover classes. In our experiments, we ignore land-cover classifications, and focus on how the bands relate to each other. We use a 90\%/10\% train/test split.

\subsubsection{Experiment Set Up}
We use the Red, Green, and Blue channels of EuroSAT, which are available at 10 meter resolution, to approximate the values of the NIR band. The NIR band is also available at 10 meter resolution, but in this experiment, we average the values of the NIR band on windows of $16 \times 16$ pixels to simulate a much lower resolution band. We then treat this aggregated low-resolution band as weak labels for the ground truth NIR, and train a network on RGB bands to predict the values of the NIR band at full resolution. Pixel values for each image are normalized to a minimum value of 0 and a maximum value of 1.

\subsubsection{Results}
We tested the probabilistic disaggregation method using RGB bands to predict high-resolution NIR values on the test set of EuroSAT, while training using a simulated low-resolution NIR band as labels. Results are presented in Table \ref{tab:eurosat}. We also present two simple baselines for comparison. In one, we use a bicubic spline interpolation to re-upsample the low-resolution NIR data to its original resolution. In another, we train a network with full information to use RGB to predict NIR values. That is, we use the full high-resolution NIR band as a label during training. In each case, we present the Mean Absolute Error.


\begin{table}[ht]
\centering
 \begin{tabular}{||p{3cm} | c||} 
 \hline
 {\bf EuroSat}  & MAE \\ 
 \hline\hline
 Bicubic Interpolation \newline (Gaussian loss) & 0.088\\ 
 \hline
 Disaggregation \newline (Sampling) & 0.068\\
 \hline
 Full Resolution \newline (Gaussian loss) & 0.089\\
 \hline
\end{tabular}
\caption{Results of predicting the NIR band using RGB bands. In the second line of the table, we downsample the NIR band by a factor of 16 during training, and apply our probabilistic disaggregation method. In the first and last, we train on pixel-level labels.}
\label{tab:eurosat}
\end{table}

\section{Conclusion}

We present a method for creating pixel-level probabilistic value predictions given coarse labels. We demonstrate the ability to produce plausible estimations of the dollar value of each pixel in an overhead image of parcel of land. This method of probabilistic disaggregation outperforms two deterministic baseline methods when re-aggregating the predictions back to the parcel level. This result holds true when going from merged parcel to single parcel estimation as well.
Although we focused on property value estimation, the method naturally extends to many applications where fine-grained estimates are desirable but difficult or impossible to get, such as population density estimation and species distribution.

\newpage

{\small
\bibliographystyle{ieee_fullname}
\bibliography{biblio}
}


\end{document}

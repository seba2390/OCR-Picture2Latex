% \documentclass[10pt,twocolumn,letterpaper]{article}
\documentclass[10pt,twocolumn,a4paper]{article}

\usepackage{spconf}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}

\usepackage{enumitem}

\input{mvrl_macros.tex}

\def\wacvPaperID{1152} 

\usepackage{siunitx}
\sisetup{group-separator = {\,}}

\DeclareMathOperator*{\argmin}{arg\,min} 
\newcommand{\cash}[1]{\SI{#1}[\$]{}}


\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}
\pagestyle{empty}


\begin{document}

%%%%%%%%% TITLE
\title{Fine-Grained Property Value Assessment using Probabilistic Disaggregation}

% Cohen, Ben, Jacob?, Usman?, Aram?, Nathan
% Pages are numbered in submission mode, and unnumbered in camera-ready
%\pagestyle{empty}\fi
                \name{
                Cohen Archbold$^1$
                \hspace{1cm}
                Benjamin Brodie$^2$
                \hspace{1cm}
                Aram Ansary Ogholbake$^1$
                \hspace{1cm}
                Nathan Jacobs$^3$}
                \address{$^1$University of Kentucky
                \hspace{1cm}
                $^2$BlueHalo
                \hspace{1cm}
                $^3$Washington University in St. Louis}

\maketitle
\thispagestyle{empty}



% %%%%%%%%% ABSTRACTs
\begin{abstract}

The monetary value of a given piece of real estate, a parcel, is often readily available from a geographic information system. However, for many applications, such as insurance and urban planning, it is useful to have estimates of property value at much higher spatial resolutions.~We propose a method to estimate the distribution over property value at the pixel level from remote sensing imagery.~We evaluate on a real-world dataset of a major urban area. Our results show that the proposed approaches are capable of generating %well-calibrated,% 
fine-level estimates of property values, significantly improving upon a diverse collection of baseline approaches.

%This is the first work that addresses the tasks of (1) pixel-level property value estimation given only parcel-level labels and (2) probabilistic dissaggregation, which estimates pixel-level distributions given only region-level labels.
%improves upon the most similar previous work which only provided a point estimate of property value.
%Using neural networks, we present a probabilistic method that creates pixel-level estimates of values and their uncertainties while being trained on coarse region-level labels.
%The method extends previous work~\cite{jacobs2018weakly} by providing probabilistic estimates of value, which include an inherent quantification of uncertainty in the prediction.
%Theoretical insight for why probabilistic methods are effective is provided.
%Our results show that using the proposed approaches outperform baselines while providing uncertainties in the estimations at each pixel

\end{abstract}


%%%%%%%%% BODY TEXT
\section{Introduction}

Many remote-sensing applications often consist of estimating the value of a quantity at a high spatial resolution. This includes quantities such as population density estimation or species distribution modeling~\cite{jacobs2018weakly}. While not true for every application, it is often the case that labeled training data is only available at a lower spatial resolution than the resolution at which we would like to obtain estimates. This makes training a model to make high spatial resolution predictions challenging. We propose an approach to overcoming this challenge in a way that is useful across a broad range of applications.

We address the task of per-pixel regression of values where the labels available are aggregated over spatial regions. Previous work on this topic~\cite{jacobs2018weakly} used a region aggregation layer to estimate population density at the pixel level based on satellite imagery and census data. A key limitation of this method is that it provides a direct point estimate without information about uncertainty or confidence of predictions. We quantify pixel and region values with probability distributions. 

We provide the theoretical motivation and demonstrate the effectiveness of value disaggregation using an analytic approach, where fine-level distributions are grouped to create a coarse-level distribution.

% two different probabilistic representations of the learned values: an analytic approach, where fine-level distributions are grouped to create a coarse-level distribution, and a sampling approach, in which fine-level distributions are sampled from directly using the reparameterization trick~\cite{Kingma2014AutoEncodingVB}. The samples are then aggregated to create a distribution for estimation of the coarse labels. 
%This approach to disaggregation gives estimates of values at the pixel level, as well as uncertainty estimates for those measurements through the estimated variances of the value distributions. 

% \begin{figure}
%     \centering
%     \includegraphics[width=0.6\linewidth]{CS612/figures/main_figure.jpg}
%     \caption{Property value estimation via probabilistic disaggregation. Provided overhead imagery (left), we estimate the contribution to the property value of each pixel with a Gaussian distribution (right). The aggregate value forms our value predictions per region (below).}
%     \label{fig:overview_image}
% \end{figure}

The main application of the probabilistic disaggregation method that we consider is identification of the visual features from overhead imagery that contribute and detract the most from the monetary value of a parcel. To facilitate this, we have collected a dataset consisting of publicly accessible aerial imagery and property values from Hennepin County, Minnesota, which includes the urban area of Minneapolis and the surrounding mix of industrial, suburban, and rural areas. We demonstrate the ability to accurately predict parcel values based on a pixel-level prediction of contributions to value. 
% Furthermore, predictions using probabilistic approaches to disaggregation are more accurate than baselines. 
% Figure \ref{fig:dataset_examples}  shows an example image from this dataset with the regions and their associated values provided.
% We also present a toy experiment on Sentinel-2 satellite imagery that uses the disaggregation method to predict pixel-level values u  sing artificially low-resolution bands. 
% This experiment allows us to test the performance of our proposed probabilistic method on pixel-wise predictions since the pixel-wise labels are accessible. 

The key contributions of this work include: (1) providing the theoretical motivation for a probabilistic disaggregation method for fine-level estimation from coarse labels; (2) formulating a method for probabilistic disaggregation and demonstrating its quantitative and qualitative value; and (3) Showing how the method works on property value estimation from overhead imagery.


% The key contributions of this work include:
% \begin{itemize}[noitemsep]
%     \item Providing the theoretical motivation for a probabilistic disaggregation method for fine-level estimation from coarse labels.
%     \item Formulating a method for probabilistic disaggregation and demonstrating its quantitative and qualitative value.
%     % \item Showing how the method works in controlled simulated experiments using Sentinel-2 imagery. 
%     \item Showing how the method works on property value estimation from overhead imagery.
%     % \item Evaluating the predicted uncertainties of property value estimation.
% \end{itemize}

% \begin{figure}[h]
%         \centering
%         \includegraphics[width=1\linewidth]{CS612/figures/value_dist.jpg}
%         \caption{ Parcel values plotted by the size in pixels of the region. }
%         \label{fig:value_vs_size}
% \end{figure}

% \begin{figure}
%         \centering
%         \includegraphics[width=0.6\linewidth]{CS612/figures/hennepin_example.jpg}
%         \caption{ An example of the regions $R$ and their associated values $Y$ for image $I$  described by the Hennepin County Dataset~\ref{sec:hennepin}.}
%         \label{fig:dataset_examples}
% \end{figure}

\section{Related Work}

\textbf{Weakly Supervised Segmentation \& Object Counting:} Our work produces pixel-level value distribution predictions from labels that are aggregated over large image regions and is closely related to works in image segmentation and object counting. Recently, many powerful CNN-based object detectors such as YOLO~\cite{yolo} and R-CNN~\cite{Girshick2014RichFH} present high detection accuracy on objects in sparse scenes. 

Regression-based counting has proved a more effective method for crowd density estimation in noisier and denser crowds~\cite{gao2020cnnbased}. Gao et al.~\cite{gao2020cnnbased} estimates pixel-level density and a count is obtained by integrating over the region.  Our method follows this last approach, in which we estimate the pixel-level contributions to property value and sum them to create estimates over wider regions.
%
In remote sensing, there is a scarcity of data for object-counting tasks. One approach is generating pseudo pixel-level labels~\cite{Gao2020remotesensing}.
%
For this work, we focus on using weak labels for regression or counting tasks, rather than segmentation, in overhead imagery. 
%
We extend previous work~\cite{jacobs2018weakly} which uses coarse-grained labels to predict density functions at pixel level. 

\textbf{Probabilistic Representation:}
  Probabilistic representation of internal features and/or model outputs has proven effective in a variety of machine learning tasks. For example, Variational Autoencoders (VAE)~\cite{Kingma2014AutoEncodingVB}, embed features in a probabilistic latent space. Samples from the distribution are then passed through a decoder to reconstruct the original input. A key development that allows probabilistic features to be used in machine learning applications is the reparameterization trick~\cite{Kingma2014AutoEncodingVB}, which provides a differentiable way of sampling from a variety of probability distributions.
 
 % In contrast, a metric learning approach to probabilistic representation is presented in~\cite{shi2019probabilistic}, in which output features are represented by a probability distribution to allow for lower quality samples to cover a wider selection of possibilities in feature space.

% Our work produces pixel-level value distribution predictions from labels that are aggregated over large image regions.

% Our work produces pixel-level value distribution predictions from labels that are aggregated over large image regions. We describe related work in the area of weakly supervised image segmentation, object density estimation and probabilistic representation, which is the most closely related to our proposed probabilistic method for pixel-level predictions.
% %which is the most closely related pixel-level labeling task.

% \subsection{Weakly Supervised Segmentation}

% The goal of semantic image segmentation is to predict class labels for each pixel of an image. In areas where image annotations are limited, it is useful to use weak labels for supervision. Less expensive image labels, such as bounding boxes, are coarser resolution and potentially noisy.

% Weakly-supervised semantic segmentation presents a different problem for overhead imagery compared to natural scene imagery. For instance, in overhead images, the boundaries among the objects are usually unclear. Moreover, these images contain fine-grained objects where both inter-class and intra-class variations are high while the natural scene images have more coarse-grained objects~\cite{Chan_2020}. We focus on overhead imagery in this work.

% In~\cite{Nivaggioli2019WeaklySS}, the authors use image level annotations as weak supervision for semantic segmentation on satellite images. To generate pixel-level labels from image labels, they used a method introduced in~\cite{Ahn_2018_CVPR}. They first train a classification network whose output layers include a global average pool (GAP) and a fully connected layer with image level labels. Then, they train an affinity network which learns the relationship between a pixel and its neighbourhood, using a random walk to generate the segmentation labels.
% In~\cite{7414501}, the authors use weakly supervised learning to fine tune a pretrained auto-encoder to produce annotations for land-cover segmentation on satellite images.

% For this work, we focus on using weak labels for regression or counting tasks, rather than segmentation, in overhead imagery. We extend the work~\cite{jacobs2018weakly} which uses coarse-grained labels to predict density functions at pixel-level. 

% In this work, we extend these ideas to a probabilistic setting which provides both value estimates and a quantification the uncertainty in those estimates.

% % Another technique that is used in weakly supervised segmentation of satellite images is labels comprised of single geotagged points. In \cite{wang2020weakly}, other than the image level labels, they use sparse pixel labels in which one pixel is only labeled and the other pixels are masked out.

% \subsection{Object Counting}

% Another related task is counting the number of object instances within an image. This task is commonly associated with crowd counting. Recently, many powerful CNN-based object detectors such as YOLO~\cite{yolo} and R-CNN~\cite{Girshick2014RichFH} present high detection accuracy on objects in sparse scenes. However, these methods have difficulty in more noisy scenes and denser crowds. Regression based counting has proved a more effective method for crowd density estimation in noisier and denser crowds ~\cite{gao2020cnnbased}. Typically these methods learn a combination of global and local features, and learn a mapping from features to crowd estimates.

% For instance, in~\cite{chan2008privacy}, after doing motion segmentation of the crowds moving in different directions, features are normalized to account for perspective and extracted. Then the Gaussian process regression is used to estimate the number of people. However, the spatial information of the annotations have not been taken in to account in this work. 

% Another method which is used in crowd counting is density estimation which uses the spatial information~\cite{gao2020cnnbased, lempitsky2010learning}. With this method, density is estimated and a count is obtained by integrating over the region. Our method follows this last approach, in which we estimate a pixel-level contributions to value and sum to create estimates over wider regions.

% \subsection{Probabilistic Representation}

% Probabilistic representation of internal features and/or model outputs has proven effective in a variety of machine learning tasks. For example, Variational Autoencoders (VAE)~\cite{Kingma2014AutoEncodingVB}, embed features in a probabilistic latent space. Samples from the distribution are then passed through a decoder to reconstruct the original input. In contrast, a metric learning approach to probabilistic representation is presented in~\cite{shi2019probabilistic}, in which output features are represented by a probability distribution to allow for lower quality samples to cover a wider selection of possibilities in feature space.

% A key development that allows probabilistic features to be used in machine learning applications is the reparameterization trick~\cite{Kingma2014AutoEncodingVB}, which provides a differentiable way of sampling from a variety of classes of probability distributions. %For example, suppose we are given a Gaussian distribution $\varphi \sim \mathcal{N}(\mu, \sigma^2)$, where the mean $\mu$ and variance $\sigma^2$ are learnable parameters. 
% %We note that sampling from $\varphi$ is equivalent to sampling from $\tilde{\varphi} = \mu + \sigma^2 \mathcal{N}(0, 1)$. This removes sources of randomness from the parameters $\mu$ and $\sigma^2$, and so we are free to backpropagate through the expression.

\section{Problem Statement}

We address the task of estimating pixel-level property values using fine-level aerial imagery and parcel-level property values. Property value labels exist at the parcel-level, but we seek to quantify the contribution to the overall value of each pixel. Since property values are often used in downstream processing tasks, such as insurance risk adjustment, it is critical to also provide a quantification of the uncertainty in these estimates.

We model this as the problem of estimating a geospatial function, $v(l)\in\mathbb{R}^+$, for a location, $l$ on the surface of the earth, from overhead imagery, $I$, of the location. This function, $v$, reflects the value of the property, including the land and building value, at a particular location. We redefine this as a gridded geospatial function, $v(p_i)$, where the value corresponds to the value in the area imaged by a pixel, $p_i$. Therefore, the problem reduces to making pixel-level predictions of $v$ from the input imagery.

The key challenge is that we do not have samples from the function, $v$.  We only have a set of spatially aggregated values, $Y=\left\{ y_1\ldots y_n\right\}$, where each value, $y_i \in \mathbb{R}^+$, represents the value of the corresponding parcel/regions, $R=\left\{ r_1\ldots r_n\right\}$. Specifically, we define $y_i = V(r_i) = \sum _{p_j\in r_i}v\left( p_j\right)$. These regions could have arbitrary topology and be overlapping, but in practice will typically be simply connected and disjoint.

As discussed above, the labels are provided at the parcel/region level. To generate the estimated values for each parcel, we assume the value $y_i$ of the region $r_i$ is distributed according to:
\begin{equation}
\label{eq:prob_formulation}
    y_i \sim \sum _{p_j \in r_i}w_i(p_j) P(v(p_j)|I(p_j); \Theta) 
\end{equation}
where $w_i(p_j)$ is value at pixel $p_j$ that belongs to region $r_i$ and $P(v(p_j)|I(p_j);  \Theta)$ is a distribution for the value of pixel $p_j$ given image of location $p_j$ and the parameters $\Theta$.

Previous work has shown that it is possible to train a model, in a weakly supervised fashion, to make pixel-level predictions using only these aggregated labels~\cite{jacobs2018weakly}. The key observation was that since the aggregation process is linear, it is possible to propagate derivatives through the operation, enabling end-to-end optimization of a neural network that predicts $v$. 

The previous work does not capture uncertainty in the underlying predictions, which limits its practical usefulness. We estimate pixel-level and parcel-level Gaussian probability distributions for the value of the underlying location.



% As discussed above, the labels are provided at the parcel/region level. To generate the estimated values for each parcel, we assume the value of the region $r_i$ is distributed according to:
% \begin{equation}
%     y_i \sim \int w_i(l) P(v(l)|I(l); \Theta) dl 
% \end{equation}
% where $w_i(l)$ is the proportion of location $l$ that belongs to region $r_i$ and $P(v(l)|I(l); \Theta)$ is a distribution for the value of location $l$ given image of location $l$ and the parameters $\Theta$. Since the locations are discrete pixels in our formulation of the problem, the above becomes:
% \begin{equation}
% \label{eq:prob_formulation}
%     y_i \sim \sum _{p_j \in r_i}w_i(p_j) P(v(p_j)|I(p_j); \Theta) 
% \end{equation}


% \subsection{The Linear-Gaussian Case}

% %As a motivating example, 
% Before introducing our approach, we consider a simple scenario to provide some intuition for why it works. We assume that the probability distributions $P(v(p_j)|I(p_j); \Theta)$
% %of the value contribution of the pixel $p_j$ 
% are linear and Gaussian. This means there is a vector $f$ such that the value distribution can be defined as:
% \begin{equation}
%     P(v(p_j)|I(p_j); \Theta) = p_j^\mathsf{T} f + \mathcal{N},
% \end{equation} where $p_j$ is a latent vector that represents a pixel and $\mathcal{N}$ is Gaussian noise. We can represent this relationship for all pixels $\{p_j\}_{j=1}^N$ in the dataset as the single matrix multiplication $\mathbf{P}^{\mathsf{T}} f + \mathcal{N}$, where $\mathbf{P} = [p_1,p_2, \ldots, p_N]$.

% The contribution of pixels to regions $\{r_i\}_{i=1}^M$ is a linear operation that can be represented as a given $M\times N$ matrix $\mathbf{R}$. Therefore, the value of the set of observations of the system in Equation~\ref{eq:prob_formulation} becomes:
% \begin{equation}
%     Y \approx \mathbf{R}\mathbf{P}^{\mathsf{T}} f.
% \end{equation}
% We can estimate the parameters of the transformation $f$ by $ \hat{f} = \left(\mathbf{R}\mathbf{P}^{\mathsf{T}}\right)^\dagger Y,$ where $\dagger$ denotes the pseudo-inverse. We can then estimate the mean value of each pixel using the forward model $p_j^{\mathsf{T}} \hat{f}$. We can then easily estimate the covariance of the noise, thus estimating all the parameters of our model and providing pixel-level distribution estimates.

% However, in most real-world scenarios, the pixel value model is unlikely to be linear-Gaussian. The transformation $F(p_j) = P(v(p_j)|I(p_j); \Theta)$ is often highly nonlinear and dependent on the values of neighboring pixels. Therefore, we replace the above process of solving for $\hat{f}$

% and use a convolutional neural network (CNN) to approximate the parameters of the more complicated function. Instead of using the pseudo-inverse to solve for the parameters, we use standard neural network optimization techniques.

%parameters of $f$
%such that $F(p_j)={p_j}^T f$ 

% Starting with our approximation $\sum_{p_j\in r_i}\hat{f}\left( p_j\right)$, let's assume that each pixel is represented by a column vector and that $\hat{f}$ is a linear function, $\hat{f}(p_i) = f^{\mathsf{T}}p_i$. We can then write this, for all pixels, as a single matrix multiplication: $\mathbf{P}^{\mathsf{T}} f$, where $\mathbf{P} = [p_1,p_2, \ldots, p_n]$.  Since the summation over regions, $\sum_{p_j\in r_i}$, is a linear operation, we can define the set of observations as linear system, $Y \approx \mathbf{R}\mathbf{P}^{\mathsf{T}} f$.  It then becomes clear that we can estimate the parameters, $f$, as a linear system $(\mathbf{R}\mathbf{P}^{\mathsf{T}})^\dagger Y.$ %^\mathsf{T} 

% Once we have $\hat{f}$ then we can estimate the values for each pixel using the forward model $f^{\mathsf{T}}p_i$.



\section{Approach}

We propose to use a CNN, which takes the overhead imagery as input, to generate a pixel-level probabilistic value map. We model pixel-level values as Gaussian distributions with the mean representing the most likely value of for the corresponding piece of land and variance modeling uncertainty in the estimation. For simplicity, we model the output pixel-value distributions as independent and allow the CNN to capture dependencies between pixel distributions. By aggregating pixel-level distributions for each pixel in a parcel, we obtain an estimate for the overall value of the parcel, for which we have labels.

% \subsection{Optimization}

% Given this model, and the assumption of independent Gaussian distributions at each pixel, we consider two different methods of optimization: an analytical and a sampling-based approach to go from pixel-level distributions to parcel-level predictions.

The sum of independent Gaussian distributions can be written analytically as follows: given $X_1 \sim \mathcal{N}(\mu_1,\,\sigma^{2}_1)\,$ and $X_2 \sim \mathcal{N}(\mu_2,\,\sigma^{2}_2)\,$, then $X_1+X_2 \sim \mathcal{N}(\mu_1+\mu_2,\,\sigma^{2}_1+\sigma^{2}_2)\,$. 

Therefore, given a mean $\mu$ and and variance $\sigma^{2}$ for the value prediction at each pixel, the aggregated observation on a region $r_i$ is: 
\begin{equation}\label{eq:aggregated_gaussian}
    \hat{y_i}(\Theta) \sim \mathsf{\mathcal{N}}\left(\sum_{p_j\in r_i}\hat{\mu}( p_j; \Theta),\sum_{p_j\in r_i}\hat{\sigma^{2}}( p_j; \Theta)\right).
\end{equation}

We optimize the system by minimizing the negative log-likelihood of the the parcel value label according the aggregated estimate distribution $\hat{y_i}(\Theta)$. That is, given $\mu_i^\star = \sum_{p_j\in r_i}\hat{\mu}( p_j; \Theta)$ and ${\sigma_i^\star}^2 = \sum_{p_j\in r_i}\hat{\sigma^{2}}( p_j; \Theta)$ for each region $r_i$, we find the parameters $\Theta$ that minimize the negative log-likelihood of the resulting Gaussian:
\begin{equation}\label{eq:nll}
    \argmin_\Theta \sum_{i} -\log\left( 
     \frac{1}{\sqrt{2\pi}\sigma_i^\star} \exp\left(-\frac{1}{2} \frac{\left(y_i - \mu_i^\star\right)^2}{{\sigma_i^\star}^2} \right)\right),
\end{equation}
given the ground truth value $y_i$.

% \subsubsection{Sample-Based Approach to Disaggregation}

% As an alternative to directly constructing an aggregated Gaussian distribution using the approach outlined in Section~\ref{sec:analytical}, we can use the reparameterization trick~\cite{Kingma2014AutoEncodingVB} to work with samples from the pixel-level distributions. These samples are then used to approximate the overall value distribution of each parcel.

% The value distribution at a pixel $p_i$ is given by:
% \begin{equation}\label{eq:pixel-distribution}
%     \hat{x}(p_i) \sim \mathsf{\mathcal{N}}\left(\mu(p_j), {\sigma^2}(p_j)\right),
% \end{equation}
% where $\mu(p_j)$ and $\sigma^{2}(p_j)$ are the outputs of the backbone network at the pixel $p_j$.

% For each pixel-level distribution in a parcel $r$, we generate a sample $\hat{x}^{(r)}(p_i)$. Under the assumption of independent Gaussian distributions, the sum of these values, $\mathrm{est(r)}$ will be distributed according to
% \begin{equation}\label{eq:composite_distribution}
%     \sum_{p_j \in r} \hat{x}^{(r)}(p_j) \sim \mathsf{\mathcal{N}}\left(\sum_{p_j \in r} \mu(p_j), \sum_{p_j \in r} {\sigma^2}(p_j)\right),
% \end{equation}
% which matches the analytical distribution derived in Equation~\ref{eq:aggregated_gaussian}.

% We generate samples $K$ times to create a collection of $K$ parcel value estimates $C^{r}(K) = \{\mathrm{est(r)}_1, \dots, \mathrm{est(r)}_K\}$. We then approximate the parcel-level distribution by computing the mean and variance of the set $C^{r}(K)$. As $K$ approaches infinity, the Gaussian $\mathsf{\mathcal{N}}\left(\mu\left(C^{r}(K)\right),\sigma^2\left(C^{r}(K)\right)\right)$ converges to the analytical distribution.

% The network is optimized by through the negative log-likelihood of the reconstructed aggregated distribution at the ground truth parcel value, as in Equation~\ref{eq:nll}. We collect results of this optimization at different values of the parameter $K$, see Table~\ref{tab:results}.
% %For $k=1$, we include an extra parameter to represent the variance of the parcel value distribution, so that we are still able to optimize with log-likelihood.

% This approach allows us to employ any distribution that allows the reparameterization trick for the pixel-level distributions. According to the Central Limit Theorem, given the assumption of independence of the pixel-level distributions, the parcel value distribution will be approximately distributed according to Equation~\ref{eq:composite_distribution} as the number of samples goes to infinity, regardless of the underlying distribution.

\subsection{Baselines}
\label{sec:baselines}
We compare the results of the probabilistic disaggregation method against two deep learning baselines: a uniform value assumption and a linear aggregation method.

With the uniform value assumption, we assume that the value of each parcel is evenly distributed among the pixels included in the parcel. This results in strong pixel-level labels for all viable pixels in the dataset, although these strong labels may not be the best representation of the data. Using these labels, we train a probabilistic backbone to predict pixel-level distributions matching the pixel-level labels.

\begin{figure*}
        \centering
        % \includegraphics[clip, viewport=0 0 2600 1700, width=0.8\linewidth]
        \includegraphics[width=0.88\linewidth]{CS612/figures/value_predictions_extended.jpg}
        \caption{Qualitative examples of mean value predictions of the baselines described in Section~\ref{sec:baselines} and disaggregation model performing on the Hennepin County Dataset~\ref{sec:hennepin}. We show the original input imagery $I$ and parcel regions $Y$ shaded by corresponding value(Columns 1-2). We observe that building pixels are valued more highly than lawn pixels using the disaggregation methods (Columns 3-5). As well, we show the standard deviation predictions of the dissaggregation model (Column 6).}
        \label{fig:qualitative_results}
    \end{figure*}

We also use a deterministic linear aggregation as a baseline for comparison to the probabilistic method. This method treats the input as a per pixel value-estimation, and sums the pixel values over the regions using a single linear layer. We then optimize the baseline with Mean Squared Error (MSE) for the pixel value estimate. This method is essentially the method presented in~\cite{jacobs2018weakly}, which was applied to the similar problem of population density estimation.

As well, in Table \ref{tab:merged_results} we compare the methods against a Gaussian fit of the training set labels. We expect performance in this case to be trivially attainable.

% \begin{figure*}
%         \centering
%         \includegraphics[width=0.8\linewidth]{CS612/figures/fig5.png}
%         \caption{Means and standard deviations of predictions on the Hennepin County Dataset~\ref{sec:hennepin} from the two different methods. Qualitatively, we observe high correlation between the means and standard deviations. As well, $\hat{\sigma}$ is distributed more over the individual region's area.}
%         \label{fig:qualitative_uncertainty}
%     \end{figure*}

% \begin{table*}
% \centering
% {
% \setlength{\tabcolsep}{1em}
% \renewcommand{\arraystretch}{1.2}
%  \begin{tabular}{lllllll} 
%  \toprule
%  Method  & MAE & MAPE & $\mathcal{P}_\pm(10^4)$ & $\mathcal{P}_\pm(10^5)$ & Average $\hat{\sigma}$ & Log Prob (avg) \\ [0.5ex] 
%  \midrule
%  Gaussian Fit & \cash{118959} & $42.45\% $  & $5.7\%$ & $52.35\%$ & \cash{101381} & $-13.42$ \\ 

%  Uniform Value & \cash{160418} & $77.62\% $  & $11.90\% $  & $80.77\% $ & \cash{2714} & $-1676.31$ \\ 

%  Deterministic & \cash{54517} & $22.17\% $  & NA & NA & NA & NA\\ 

%  \midrule
%  %Sampling (k=1) (MSE) & \cash{54843} & $22.21\%$  &  $14.29\%$ & $87.20\%$ & \cash{279} \\
%  %Sampling (k=1) (learnable param) & \cash{57699} & $24.75\%$  &  $13.08\%$ & $84.98\%$ & \cash{5051} \\
%  % Sampling (k=10)  & \cash{55364} & $22.45\%$  &  $13.11\%$ & $85.80\%$ & \cash{5269} & $-121.65$ \\ 
%  % Sampling (k=50) & \cash{52249} & $21.95\%$  &  $13.37\%$ & $85.64\%$ & \cash{4358} & $-151.33$  \\ 
%  % Sampling (k=100) & \cash{52245} & $22.01\%$  &  $13.9\%$ & $87.46\%$ & \cash{5449} & $-92.70$  \\
 
%  Analytical & \cash{49309} & $20.79\%$ & $15.53\%$ & $88.42\%$ & \cash{3435} & $-200.52$ \\
% % \\https://www.overleaf.com/project/5c5cc37c6c4e656b198e26a4
%  \bottomrule
% \end{tabular}
% }

% \caption{Results of disaggregation on the Hennepin County Dataset. We show Mean Absolute Error (MAE) and Mean Absolute Percentage Error (MAPE) of predictions with ground truth parcel values. Results are compared across the best fit Gaussian on the training set, as well as the baselines described in Section~\ref{sec:baselines}. For the probabilistic method, we also show the probability of being within \cash{10000} and \cash{100000} of the ground truth value according to the predicted Gaussian distribution, along with the average predicted standard deviation. }
% \label{tab:results}
% \end{table*}

\section{Evaluation}
\label{sec:evaluation}
 We estimate the contribution to overall property value of each pixel(square meter) that is visible from overhead imagery in the Hennepin County Dataset. At test-time, we take the means $\mu$ of the probabilistic models as the per-pixel value estimation. We aggregate the $\hat{y}$ of the respective methods and compare to the true value.

\begin{table*}
\centering
{
\setlength{\tabcolsep}{1em}
\renewcommand{\arraystretch}{1.2}
 \begin{tabular}{lllllll} 
 \toprule
 Method  & MAE & MAPE & $\mathcal{P}_\pm(10^4)$ & $\mathcal{P}_\pm(10^5)$ & Average $\hat{\sigma}$ & Log Prob (avg) \\ [0.5ex]
 \midrule
 Gaussian Fit & \cash{271280} & $126.15\% $  & $1.48\%$ & $14.74\%$ & \cash{436840} & $-14.12$ \\ 
 
 Uniform Value & \cash{177574}  & $81.59\%$ & $11.11\%$  & $79.44\%$  & \cash{2588} & $-2062.19$ \\
  
 Deterministic & \cash{61093}  & $25.66\%$ & NA & NA & NA & NA\\ 
 
 \midrule
 
 %Sampling (k=1) (MSE) & \cash{60786} & $26.57\%$  &  $12.78\%$ & $83.10\%$ & \cash{282} \\
 
 %Sampling (k=1) (learnable param) & \cash{66205} & $28.95\%$ & $12.41\%$ & $82.27\%$ & #\cash{5026} \\
 
 % Sampling (k=10) & \cash{59201} & $24.54\%$ & $14.02\%$ & $84.15\%$ & \cash{4725} & $-181.77$ \\ 
 % Sampling (k=50)& \cash{64278} & $28.60\%$ & $13.21\%$ & $81.59\%$ & \cash{4068} & $-228.49$ \\ 
 % Sampling (k=100) & \cash{60164} & $25.92\%$ & $13.88\%$ & $83.92\%$ & \cash{3675} & $-242.20$  \\ 
 
 Analytical & \cash{63311} & $27.14\%$ & $14.5\%$ & $84.38\%$ & \cash{3547} & $-317.70$ \\
 
 \bottomrule
\end{tabular}
}
\caption{Results of disaggregation on the Hennepin County Dataset with random merging of neighboring parcels during training. We show Mean Absolute Error (MAE) and Mean Absolute Percentage Error (MAPE) of predictions with ground truth parcel values. Results of the analytical approach to probabilistic disaggregation are compared to the two baselines described in Section~\ref{sec:baselines} as well as Gaussian Fit. We also present the probability of being within \cash{10000} and \cash{100000} of the ground truth value according to the predicted Gaussian distribution, along with the average predicted standard deviation.}
\label{tab:merged_results}
\end{table*}
 
\subsection{Hennepin County Dataset}
\label{sec:hennepin}

We built an evaluation dataset using the imagery and parcel information made available by Hennepin County, Minnesota. We randomly selected 1915 sub-regions and extracted $302 \times 302$ chips with a ground-sample distance of \SI{1}{\meter} from the 2020 aerial imagery. The corresponding parcel geometries and values (accurate as of 2020) were extracted from GIS Open Data. For each chip, only parcels fully contained within the chip were retained. In addition, we removed outliers and other defects from the collected dataset. For instance, many of the original parcels included a market value of zero, often for either unlabeled or public land. As well, we remove parcels with disproportionately high values from downtown Minneapolis. 

Each sample of the dataset contains the information: region image, parcel masks, and corresponding market values. We hold out 10\% of the dataset for validation and 10\% of the dataset for testing.

% We collected over 65\,000 parcels with an average area of 984 pixels and an average value of \cash{286346}. The average value of a pixel on the training set is \cash{379.74}.

\subsection{Implementation Details}

We implemented the proposed approach in PyTorch and trained each model on an NVIDIA A6000 GPU. We use UNet~\cite{ronneberger2015u} as a backbone, which provides an output map at the same resolution as the input image. The network produces a Gaussian probability distribution for each input pixel by generating a two channel output with the first channel corresponding to the means and the second channel corresponding to the variances. We apply the softplus function, $f(x) = \log(1+ \exp{(x)})$, to the output of the second channel to ensure positivity of the predicted variances, $\hat{\sigma}^2$. To compute the aggregation of parcel pixels, we model the computation after \cite{jacobs2018weakly} using a region aggregation layer. This computation necessitates memory sufficient to represent a matrix $M \in \mathbb{R}^{n \times HW}$, where $n$ is the number of regions and $HW$ is the flattened image size. Due to this, we are limited to a batch size of 8. We train each model for \num{300} epochs with a learning rate of \num{1e-3} under the Adam optimization algorithm. We select the best checkpoint based on performance on the validation set, and present results on the test set

    % For the Sentinel-2 experiment, we train each model for~\num{150} epochs, with a learning rate of~\num{1e-2} and a batch size of~\num{128}.


% \subsection{Simulated Experiment on Sentinel-2 Imagery }
% We first set up an experiment using fine-level Sentinel-2 bands to estimate simulated coarser-level band values. This toy experiment allows us to perform disaggregation on coarse labels in a setting where pixel-level labels are available which is not true for the real-data experiment. 


% \subsubsection{EuroSAT Dataset}
% The EuroSAT dataset~\cite{helber2019eurosat} is composed of 27000 Sentinel-2 images over a variety of European locations. Images have been cropped to $64 \times 64$ pixels and are assigned to one of 10 land-cover classes. In our experiments, we ignore land-cover classifications, and focus on how the bands relate to each other. We use a 90\%/10\% train/test split.

% %\subsubsection{Experiment Set Up}
% We use the Red, Green, and Blue channels of EuroSAT, which are available at \SI{10}{\meter} resolution, to approximate the values of the NIR band. The NIR band is also available at \SI{10}{\meter} resolution, but in this experiment, we aggregate the values of the NIR band on kernel sizes of 16, 8 , 4 and 1 pixels to simulate different resolutions of this band. We then treat this aggregated low-resolution band as weak labels for the ground truth NIR, and train a network on RGB bands to predict full resolution values of the NIR band. Pixel values for each image are normalized to a mean of 0 and standard deviation of 1 in each input channel.

% \subsubsection{NIR Prediction Results}
% We tested the probabilistic disaggregation method using RGB bands to predict fine-level NIR values on the test set of EuroSAT. During training, simulated coarse-level NIR bands are used as weak labels. Results are presented in Table~\ref{tab:eurosat}. Two deep learning baselines, a deterministic baseline and a uniform value baseline, are described in Section~\ref{sec:baselines}. We also compare to a prediction based solely on fitting a Gaussian to the values in the training set. The analytical method outperforms the baseline methods of Gaussian fit and uniform value in both MAE and log probability. It also achieves a lower MAE than the deterministic baseline. This assures us that the proposed probabilistic method successfully predicts pixel-level labels with associated uncertainties while being trained on coarser-level labels. 

% \begin{table}
% \centering
% {
% \setlength{\tabcolsep}{0.35em}
% \renewcommand{\arraystretch}{}
%  \begin{tabular}{lcccccccc} 
%  \toprule
%  Method  & Kern.\ Size & MAE & Log Prob (avg)\\ [0.5ex] 
%  \midrule
%  Gaussian Fit           & NA &.78 &-1.42 \\ \hline
 
%                         & 16  & 0.65 & -10.39\\
% Uniform Value & 8 & 0.61 & -4.18 \\
%                         & 4 & 0.48 & -1.89\\
%                         & 1 & 0.33 & - 0.67\\ \hline
                        
%                         & 16 &0.44 & NA \\
% Deterministic  & 8 & 0.41 & NA \\
%                         & 4 & 0.40 & NA \\
%                         & 1 & 0.38 & NA \\ 
% \midrule
%                    &16 &0.43 &  -1.99  \\
% Analytical  &8  &0.34 &  -1.61  \\
%                    &4  &0.32  & -1.18  \\
%                    &1  &0.33 &  -0.66  \\ \hline
% %                   &16 &0.42 & 0.03 & 0.06 & 0.11 & 0.23 & 4.6 & -2.30\\ 
% %Sampling Method    &8  &0.37  & 0.05 & 0.09 & 0.17 & 0.33 &2.88  &-1.86 \\ 
% %                   &4  &0.34 & 0.09 & 0.15 & 0.28 & 0.5 & 1.68 &-1.36 \\ 
% %                   &1  &0.32 & 0.21 & 0.33 & 0.56 & 0.82 &0.53  & -0.63\\ \hline
% %New Method          & 16 & .434 & .218 & .345 & .598 & .863 & .254 & -7.256 \\

%     % \\https://www.overleaf.com/project/5c5cc37c6c4e656b198e26a4
%  \bottomrule
% \end{tabular}
% }
% \caption{Results of predicting the NIR band using RGB bands. NIR labels were provided as the sum of ground truth values over patch sizes of 16,8,4 and 1. Results are presented for the disaggregated predictions against the ground truth values on the test set.}
% \label{tab:eurosat}
% \end{table}


% while for the simulated Sentinel-2 experiment, we compare the pixel-wise estimations with pixel-wise labels.


% \subsection{Segmentation Pretraining}

% We leverage weights from supervised segmentation pretraining for initializing the model parameters. Microsoft's Open US Building Footprints were used to generate building labels. We train the weights of the backbone UNet on the binary task of building segmentation. We then use weights of network trained on building segmentation up to the classification layer to initialize the backbone of the disaggregation network. We find that using pretrained weights reduces convergence time and improves performance. 

% Training the Linear Aggregation Baseline for 300 epochs, Mean Absolute Error reduces from \cash{65112} per parcel with random initialization to \cash{54517} per parcel with pretraining.

% as shown in Table \ref{tab:pretrain_results}.

% \begin{table}[ht]
% \centering
%  \begin{tabular}{||l | p{2.4cm} | p{3cm}||} 
%  \hline
%  Method  & Mean \newline Absolute Error & Mean Absolute \newline Percentage Error  \\ 
%  \hline\hline
%  Random & $ \$ 92,606$ & $29.54\% $ \\ 
%  \hline
%  Pre-trained & $ \$78,258$ & $25.07\% $ \\ 
%  \hline
%  \hline
% \end{tabular}
% \caption{Comparison of two models trained with sampling-based disaggregation. Models were trained for 200 epochs. }
% \label{tab:pretrain_results}
% \end{table}

% \subsection{Property Value Estimation Results}
% We show results of the property value estimation for the probabilistic disaggregation method compared to three baselines in Table~\ref{tab:results}. We find that the probabilistic method significantly outperforms the baselines provided by the uniform value and Gaussian Fit in terms of both Mean Absolute Error as well as the probability of being within $X$ of the ground truth value for various values of $X$. In addition, it performs on par with the deterministic deep learning baseline, while providing the additional benefit of quantitative uncertainty estimation. For a detailed look at the metrics, see Table~\ref{tab:results}.

% In Figure~\ref{fig:qualitative_results}, we show value prediction maps corresponding to the different methods and examples of uncertainty maps for the probabilistic methods are given in Figure~\ref{fig:qualitative_uncertainty}. The prediction maps generated with disaggregation provide fine detail about contributions to value as opposed to the less detailed estimates generated by the uniform value assumption method. 

%Another example of this fine detail is shown in Figure~\ref{fig:pool_image}, where swimming pools are singled out as contributing significantly to the value of the corresponding parcel.

% \subsubsection{Evaluating and Calibrating Uncertainty}
% Deep neural networks often yield overconfident predictions. We see evidence of this in our experimental results (Table~\ref{tab:results}) because the predicted standard deviations are low compared to the test set standard deviation. It has been shown that model overconfidence can be overcome with careful model calibration~\cite{DBLP:journals/corr/GuoPSW17}. We find that by calibrating our model, we can scale the predicted errors to their true values in the dataset.

% While it is much more explored for classification, calibration of a model's learned probabilities is a necessary step to match the true probabilities of the dataset. There are many ways to accomplish this, such as temperature scaling or optimizing probabilities over a held out calibration set~\cite{DBLP:journals/corr/abs-1905-11659}. For regression, it is common to take confidence intervals and judge predictions through their respective probabilities. We asses model reliability through the expected probabilities of confidence intervals for our predicted distributions.

% We find that a simple linear transformation can adjust our predicted standard deviations to minimize total squared error between predicted and observed probabilities in the test set. We conduct a search to find the optimal transformation parameters on the analytical model's predicted standard deviations. For comparison, we also search for the best possible fixed standard deviation, in combination with the analytical model's predicted means. In Figure~\ref{fig:reliability} we compare the predicted probabilities to the true probabilities by computing confidence intervals. In Table~\ref{tab:reliability}, we demonstrate the mean squared error of the calibrated versus un-calibrated methods probability estimates.
  
% While our calibration method is simple, it shows that our per-pixel predictions significantly out-perform those from a fixed-value standard deviation. 

% % Calibration can likely be accounted for in optimization, and we recommend that further work be done to investigate calibration methods for probabilistic regression tasks such as this. 

% \begin{table}[ht]
%     \centering
%     \begin{tabular}{ll} 
%     \hline Method  & MSE  \\ 
%     \hline\hline
%     Analytical Calibrated & $ \num{1.969e-4}  $  \\ 
%     \hline
%     Analytical Fixed $\hat{\sigma}$ & $ \num{4.439e-4} $ \\ 
%     \hline
%     Gaussian Fit &  $ \num{5.064e-2} $ \\
%     \hline
%     Uniform &  $ \num{6.484e-1} $ \\
%     \hline
%     Sampling N=10 &  $ \num{4.95e-1} $ \\
%     \hline
%     Analytical &  $ \num{5.47e-1} $ \\
%     \hline
%     \hline
%     \end{tabular}
%     \caption{ The mean squared error of predicted probabilities versus observed probabilities of our calibrated and un-calibrated models on the test set. We observe that our calibrated method out-preforms the optimal fixed value standard deviation by a factor of 2. }
%     \label{tab:reliability}
% \end{table}

%  \begin{figure}
%      \centering
%      \includegraphics[scale=0.32]{CS612/figures/reliability.jpg}
%      \caption{Reliability diagram. The x-axis is the fraction of probability mass, centered on the mean, that is contained within a given confidence interval. The y-axis reflects the percentage of parcels for which the true value was within the predicted confidence interval.}
%      %  Computed by taking confidence intervals at different probability levels and comparing the true probability in the test set.
%      \label{fig:reliability}
%  \end{figure}

\subsection{Spatial Region Combination Experiment}

% \label{sec:merged}
% \begin{figure}
%     \centering
%     \includegraphics[width=0.77\linewidth]{CS612/figures/combined.jpg}
%     \caption{We train on a version of the dataset where neighboring parcels are merged and values combined. For each image, the original parcels (left) are randomly combined (right) into super-parcels containing two or more of the original parcels. We use the same (non-merged) validation and test sets at inference.}
%     \label{fig:basic_results}
% \end{figure}


A major challenge of the experiments on parcel value is the lack of pixel-level ground truth labels. We propose an experiment to evaluate the ability of a model trained on coarse labels to predict on fine labels. To accomplish this, we modify the training and validation set to combine neighboring parcels for each region. Corresponding parcel values for joined regions are summed and we skip any region combinations that exceed \SI{1000}[\$] per $m^2$. At inference, we evaluate on single parcels as in the standard experiment. 
 % An example is shown in Figure~\ref{fig:basic_results}.
We indicate that the disaggregation method is able to accurately estimate pixel-level values by demonstrating that we effectively estimate single parcel values from merged parcel labels, as shown in Table~\ref{tab:merged_results}. That is, we are able to predict on finer-level labels than the set of labels that we trained on. The probabilistic method performs on par with the deterministic baselines, while again providing uncertainty estimations.
% In all cases, the deep learning baselines strongly outperform the size-based estimation shown in Table~\ref{tab:results}.
    


% \begin{figure}
%     \centering
%     \includegraphics[width=1\linewidth]{CS612/figures/value_dist_combined.jpg}
%     \caption{Parcel values plotted by the size in pixels of the combined regions. }
%     \label{fig:combined_size_vs_value}
% \end{figure}
    

%   \begin{figure*}[h]
%         \centering
%         \includegraphics[width=1\linewidth]{CS612/figures/Prediction_Example.png}
%         \caption{Row 1: Examples of aerial imagery from the Hennepin County Dataset. Row 2: Segmentation of valid parcels for the given overhead image. Row 3: Pixel-level property value predictions. Row 4: Aggregated parcel value prediction \todo{or is this ground truth? it would be good to have both in either case}.}
%         \label{fig:my_label}
%     \end{figure*}


%\begin{figure}
 %       \centering
  %      \includegraphics[width=1\linewidth]{CS612/figures/features.jpg}
   %     \caption{A zoomed in view of value predictions. We observe that high values are assigned to non-building objects such as pools and driveways.}
    %    \label{fig:pool_image}
%    \end{figure}

\section{Conclusion}
 
We presented a method for estimating pixel-level distributions of property values from remote sensing imagery. This is a challenging task to evaluate because pixel-level ground truth is infeasible to collect. We addressed this by training on datasets with artificially merged parcels and evaluating on the unmerged parcels. While this doesn't directly evaluate the pixel-level distributions, it does show that our method is able to determine the spatial distribution of property values more accurately than baseline approaches. These results demonstrate that our approach significantly improves upon several strong baseline approaches. While not demonstrated in this work, we believe probabilistic disaggregation can be applied to numerous applications where fine-level, probabilistic estimates are needed but fine-level training data is difficult to obtain, such as population density estimation and species distribution modeling.

\section*{Acknowledgements}

This research is based upon work supported in part by the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via Contract Number 2021-20111000005. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of ODNI, IARPA, or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright annotation therein.


{\small
\bibliographystyle{ieee_fullname}
\bibliography{biblio}
}

\end{document}

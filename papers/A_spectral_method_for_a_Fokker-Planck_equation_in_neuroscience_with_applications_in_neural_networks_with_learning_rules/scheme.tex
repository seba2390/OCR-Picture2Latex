
\section{Numerical scheme and analysis}\label{sec:scheme}
In this section, we present a spectral approximation for the weak solution to the Fokker-Planck equation \eqref{eq:problem2} and construct a fully discrete numerical scheme. Numerical solutions are sought in a specific function space in which the functions satisfy the boundary conditions and can be determined by solving the derived equation system after specifying the test function space.
\subsection{A fully discrete numerical scheme based on Legendre spectral method}\label{sec:fully_discrete_scheme}
In this part, we construct the numerical scheme of the Fokker-Planck equation \eqref{eq:problem2}, which is implemented in two steps. First, the spectral approximation is used for space discretization, resulting in a system of ordinary differential equations; second, a semi-implicit scheme is applied for time discretization. The spectral method is established such that the numerical solution inherently satisfies the boundary conditions. Formally, the approximate variational problem is
\begin{equation}
    \label{var_problem}
    \begin{cases}
        \text{Find } p\in \mathrm{W} \text{ such that}\\
        \int_{V_{\min}}^{V_{F}} \left(
    \partial_{t}p+\partial_{v}(hp)-a\partial_{v v}p\right)\phi =0,\quad \forall \phi \in \mathrm{V},
    \end{cases}
\end{equation}
where $\mathrm{W}$ is the trial function space and $\mathrm{V}$ is the test function space. Compared to Definition \ref{weak_solution}, the variational problem \eqref{var_problem} requires a more complex trial function space, which will be further described below. The specific form of the test function space will be introduced in Section \ref{sec:stability}.
\subsubsection{Construction of trial function space and space discretization}
A challenging aspect of the spectral method is constructing the trial function space $\mathrm{W}$ so as to satisfy the complex boundary conditions, including the discontinuous derivative of the density function and the dynamic boundary. To that end, the trial function space should be a subset of $\mathbb{H}^1_0$ wherein strong boundary derivatives can be defined. Specifically, the polynomial space that fulfills the boundary conditions in \eqref{eq:problem2} and \eqref{eq:leftd} can be used as the trial function space. That is $\mathrm{W} \subseteq \mathrm{P}_{\infty}(V_{\min}, V_R) + \mathrm{P}_{\infty}(V_{R}, V_F)$ and for all $ p\in \mathrm{W}$, it holds that
\begin{equation}
    \label{boudary_condition}
    \begin{cases}
        p(V_{\min})=\partial _vp(V_{\min})=0,\\
        p(V_F)=0,\\
        p(V^-_R)=p(V^+_R),\\
        \partial _vp(V^-_R)=\partial _vp(V^+_R)+\partial _vp(V_F),
    \end{cases}
\end{equation}
where $\mathrm{P}_{\infty}(a,b)$ is the set of all real polynomials defined on the interval $(a, b)$. 
With integration by parts and the boundary conditions \eqref{boudary_condition} in the trial function space, the solution to the above variational problem \eqref{var_problem} agrees with the weak solution specified in Definition \ref{weak_solution}. 


Let $\{\psi_k\}_{k=0}^{\infty}$ be a set of basis functions of $\mathrm{W}$. The approximate solution of problem \eqref{eq:problem2} can be expanded as
\begin{equation}
    \label{eq:approximate_solution1}
    p(v,t)=\sum_{k=0}^{\infty}\hat{u}_k(t)\psi_k(v).
\end{equation}
The essence of constructing the trial function space $\mathrm{W}$ is to determine the specific form of its basis functions $\{\psi_k\}_{k=0}^{\infty}$. This is accomplished by dividing the interval into two segments by the discontinuity point $V_R$, utilizing a fixed number of basis functions to meet the dynamic boundary conditions, and employing basis functions with homogeneous boundary conditions for each segment to improve accuracy. That is
\begin{equation}
    \mathrm{W}=\mathrm{W}_1+\mathrm{W}_2,
\end{equation}
where $\mathrm{W}_1$ is a finite-dimensional space that handles the conditions in \eqref{boudary_condition}, and $\mathrm{W}_2$ enhances accuracy within the interval and satisfies the homogeneous conditions of points $V_{\min}$, $V_R$, and $V_F$, which is
\begin{equation}
    \label{eq:W2condition}
    \begin{cases}
        p(V_{\min})=\partial _vp(V_{\min})=0,\\
         p(V_R^-)=\partial _vp(V_R^-)=0,\\
         p(V_R^+)=\partial _vp(V_R^+)=0,\\
        p(V_F)=\partial _vp(V_F)=0,\\
    \end{cases}\qquad \forall p \in \mathrm{W}_2,
\end{equation}

For simplicity, it is preferable to keep the dimension of $\mathrm{W}_1$ as low as possible. In the case of taking into account the function value and first derivative value, there are eight degrees of freedom at the boundary, comprising of the function value and derivative value at $V_{\min}$, $V_F$, and both sides of $V_R$. Since the five conditions in \eqref{boudary_condition} have to be satisfied, there are three degrees of freedom remaining. Therefore, $\mathrm{W}_1$ can be spanned by three basis functions
\begin{equation}
    \mathrm{W}_1=\text{span}\{g_1,g_2,g_3\},
\end{equation}
where
\begin{equation}
    g_1\Rightarrow
    \begin{gathered}
        \begin{cases}
            g_1(V_{\min})=0,\\
            g_1(V_R)=1,\\
            \partial_v g_1(V_{\min})=0,\\
            \partial_v g_1(V_R)=0,
        \end{cases}\quad v\in(V_{\min},V_R),\qquad
        \begin{cases}
            g_1(V_R)=1,\\
            g_1(V_F)=0,\\
            \partial_v g_1(V_R)=0,\\
            \partial_v g_1(V_F)=0,
        \end{cases}\quad v\in(V_R,V_F).
    \end{gathered}
\end{equation}
\begin{equation}
    g_2\Rightarrow
    \begin{gathered}
        \begin{cases}
            g_2(V_{\min})=0,\\
            g_2(V_R)=0,\\
            \partial_v g_2(V_{\min})=0,\\
            \partial_v g_2(V_R)=1,
        \end{cases}\quad v\in(V_{\min},V_R), \qquad
        \begin{cases}
            g_2(V_R)=0,\\
            g_2(V_F)=0,\\
            \partial_v g_2(V_R)=1,\\
            \partial_v g_2(V_F)=0,
        \end{cases}\quad v\in(V_R,V_F).
    \end{gathered}
\end{equation}
\begin{equation}
    g_3\Rightarrow
    \begin{gathered}
    \begin{cases}
            g_3(V_{\min})=0,\\
            g_3(V_R)=0,\\
            \partial_v g_3(V_{\min})=0,\\
            \partial_v g_3(V_R)=0,
        \end{cases}\quad v\in(V_{\min},V_R), \qquad
    \begin{cases}
        g_3(V_R)=0,\\
        g_3(V_F)=0,\\
        \partial_v g_3(V_R)=1,\\
        \partial_v g_3(V_F)=1,
    \end{cases}\qquad v\in(V_R,V_F).\\
    \end{gathered}
\end{equation}
 The specific form of the basis functions in $\mathrm{W}_1$ are presented in Appendix \ref{app:basis}.

\begin{figure}[!htb]
    \centering
        \begin{minipage}[c]{0.8\textwidth}
            \centering
            \includegraphics[width=1\textwidth]{g.eps}
        \end{minipage}
         \caption{The basis functions of $p_3$ with Equation parameters $V_{\min}=-1,V_R=0,V_F=1$. Here, $g_1$ and $g_2$ are measured using the left axis, while $g_3$ is measured with the right axis.}
        \label{fig:g}
\end{figure}
The specific illustration of $g_1,g_2,g_3$ are shown in Figure \ref{fig:g}. After the basis function of $\mathrm{W}_1$ is determined in this way, we set
\begin{equation}
    \label{eq:w1_expansion}
    p_3=\sum_{k=1}^3 \lambda_kg_k \quad \in \mathrm{W}_1.
\end{equation}
The boundary conditions can be well satisfied by adjusting the coefficients of $g_1,g_2,g_3$ in the following way,
\begin{equation}
    \label{eq:lambda}
    \begin{gathered}
        \begin{cases}
            p(V_R^-)=p_3(V_R^-)=\lambda_1,\\
            p(V_R^-)=p_3(V_R^+)=\lambda_1,
        \end{cases}\qquad
        \begin{cases}
            \partial_vp(V_R^-)=\partial_vp_3(V_R^-)=\lambda_2,\\
            \partial_vp(V_R^-)=\partial_vp_3(V_R^+)=\lambda_2+\lambda_3,\\
            \partial_vp(V_R^-)=\partial_vp_3(V_F^-)=\lambda_3,
        \end{cases}
    \end{gathered}
\end{equation}
where $p$ denotes the numerical solution mentioned in \eqref{eq:approximate_solution1}. 

The construction of the $\mathrm{W}_2$ space is motivated by spectral methods for solving general homogeneous boundary value problems.  According to \eqref{eq:W2condition}, the interval $(V_{\min},V_F) $ is divided into two segments by $V_R$ naturally. Assuming $I_L=(V_{\min},V_R)$ and $I_R=(V_R,V_F)$, we further denote
\begin{equation}
    \label{eq:X_ab}
        \mathrm{X}_{(a,b)}=\left\{\varphi \in P_{\infty}(a,b) : \varphi(a)=\varphi(b)=\varphi'(a)=\varphi'(b)=0   \right\}.\\
\end{equation}
$\mathrm{X}_{(a,b)}$ represents the set of real polynomials defined on the interval $(a, b)$, where the function value and derivative are zero at boundary points. So we can divide $\mathrm{W}_2$ into two parts 
\begin{equation}
    \mathrm{W}_2=\mathrm{X}_{(V_{\min},V_R)}+ \mathrm{X}_{(V_R,V_F)}.
\end{equation}

In the spectral methods, in order to minimize the interaction of basis functions in the frequency space, the basis functions should take the form of adjacent orthogonal polynomials \cite{shen1994efficient}. Therefore, it is reasonable to use a compact combination of Legendre polynomials as basis functions of $\mathrm{X}_{(a,b)}$, namely,
\begin{equation}
    \hat{h}_k=\mathcal{H}_k+\alpha_k\mathcal{H}_{k+1}+\beta_k\mathcal{H}_{k+2}+\gamma_k\mathcal{H}_{k+3}+\eta_k\mathcal{H}_{k+4},\quad k=0,1,2,...,
\end{equation}
where $\mathcal{H}_k$ is the scaling of the kth-degree Legendre polynomial $L_k$
\begin{equation}
    \mathcal{H}_k(v)=L_k(x),\qquad x=\frac{v-\left(\frac{a+b}{2}\right)}{\frac{b-a}{2}},
\end{equation}
and the parameter $\{\alpha_k,\beta_k,\gamma_k,\eta_k\}$ are chosen to satisfy the boundary conditions in \eqref{eq:X_ab}
\begin{equation}
    \alpha_k=0,\, \beta_k=-\frac{4k+10}{2k+7},\,\gamma_k=0,\,\eta_k=\frac{2k+3}{2k+7}.
\end{equation}




After constructing the trial function space, spatial discretization will be discussed, yielding the system of ordinary differential equations for the coefficients. Let $\{h_k\}_{k=0}^{\infty}$ be the basis functions of $\mathrm{W}_2$. Then the approximate solution \eqref{eq:approximate_solution1} can be rewritten as
\begin{equation}
    \label{eq:approximate_solution2}
    p(v,t)=\sum_{k=0}^{\infty}u_k(t)h_k(v)+\sum_{k=1}^3\lambda_k(t)g_k(v).
\end{equation}
The basal functions in \eqref{eq:approximate_solution2} correspond to ones in \eqref{eq:approximate_solution1} in the following way
\begin{equation}
    \{\psi_k\}_{k=0}^{\infty}=\{g_k\}_{k=1}^{3}+\{h_k\}_{k=0}^{\infty}.
\end{equation}
And the expansion coefficients $\{u_k(t)\}_{k=0}^{\infty},\{\lambda_k(t)\}_{k=1}^3$ are to be determined.
Assuming the initial value is to satisfy the boundary conditions \eqref{boudary_condition}, the initial expansion coefficients $\{u_k(0)\}_{k=0}^{\infty},\{\lambda_k(0)\}_{k=1}^3$ can be obtained by the best squares approximation,
\begin{equation}
    \label{eq:initial_vector}
    \int_{V_{\min}}^{V_F} \left(\sum_{k=0}^{\infty}u_k(0)h_k(v)+\sum_{k=1}^3\lambda_k(t)g_k(v)\right) \phi_j dv=\int_{V_{\min}}^{V_F} p^0(v)\phi_j dv, \qquad \forall \phi_j \in \mathrm{V}.
\end{equation}
For a properly defined test function space, the solvability of the \eqref{eq:initial_vector} is guaranteed by the Gram-Schmidt orthogonalization of the basis functions. Note again that the specific form of the test function space is discussed in Section \ref{sec:stability}. We denote the initial value vector as
\begin{equation}
    \label{eq:initial_value}
    \mathbf{P^0}=(\lambda_1(0),\lambda_2(0),\lambda_3(0),u_1(0),u_2(0),...)^T.
\end{equation}

It should be noted that while constructing the basis functions, we assume that the value of $N(t)$ is already known. In fact, $N(t)$ is self-consistently determined in the dynamic process, and $N(t)$ is part of the degrees of freedom of the solution. It follows from \eqref{eq:lambda} that
\begin{equation}
    \partial_vp(V_F,t)=\lambda_3(t).
\end{equation}
One can rewrite the mean firing rate using \eqref{eq:ha} and \eqref{eq:Nt}
\begin{equation}
    \label{Nt1}
    N(t)=-\frac{a_0\lambda_3(t)}{1+a_1\lambda_3(t)}.
\end{equation}
Define
\begin{equation}
    \label{eq:operator}
    \mathcal{L}p(v,t)=\partial_{t}p-\partial_v(vp)-\left(b\frac{a_0\lambda_3(t)}{1+a_1\lambda_3(t)}\right)\partial_{v}p-\left(a_0-a_1\frac{a_0\lambda_3(t)}{1+a_1\lambda_3(t)}\right)\partial_{v v}p.
\end{equation}
The expansion coefficients $\{u_k(t)\}_{k=0}^{\infty},\,\{\lambda_k(t)\}_{k=1}^{3}(t>0)$ in \eqref{eq:approximate_solution2} can be determined by variational problem \eqref{var_problem} with using the mean firing rate $N(t)$ in \eqref{Nt1}:
\begin{equation}
    \label{eq:nonlinear_system1}
    \begin{cases}
        \text{Find } p\in  \mathrm{W} \text{ such that}\\
        (\mathcal{L}p,\phi_j)=0,\quad \forall \phi_j \in \mathrm{V},
    \end{cases}
\end{equation}
where $(\cdot,\cdot)$ is the inner product of the usual $L^2$ space.

The nonlinear system of ordinary differential equations of the above scheme is obtained by substituting \eqref{eq:approximate_solution2} into \eqref{eq:nonlinear_system1}. More precisely, setting
\begin{equation}
    \begin{aligned}
        &\mathbf{P}=(\lambda_1(t),\lambda_2(t),\lambda_3(t),u_1(t),u_2(t),...)^T,\\
        &s_{jk}=\begin{cases}
            (g_k,\phi_j),\qquad &1\leq k \leq3,\\
            (h_{k-4},\phi_j),& k\geq4.
        \end{cases}, &S=(s_{jk})_{j,k=1,2,...},\\
        &a_{jk}=\begin{cases}
            (\partial_v(vg_k),\phi_j),\qquad &1\leq k \leq3,\\
            (\partial_v(vh_{k-4}),\phi_j),& k\geq4.
        \end{cases}, &A=(a_{jk})_{j,k=1,2,...},\\
        &b_{jk}=\begin{cases}
            (\partial_vg_k,\phi_j),\qquad &1\leq k \leq3,\\
            (\partial_vh_{k-4},\phi_j),& k\geq4.
        \end{cases}, &B=(b_{jk})_{j,k=1,2,...},\\
        &c_{jk}=\begin{cases}
            (\partial_{vv}g_k,\phi_j),\qquad &1\leq k \leq3,\\
            (\partial_{vv}h_{k-4},\phi_j),& k\geq4.
        \end{cases}, &C=(c_{jk})_{j,k=1,2,...}.\\
    \end{aligned}
\end{equation}
The nonlinear system \eqref{eq:nonlinear_system1} becomes
\begin{equation}
    \label{eq:nonlinear_sde}
    S\partial_t\mathbf{P}=\left(A+\left(b\frac{a_0\lambda_3(t)}{1+a_1\lambda_3(t)}\right)B+\left(a_0-a_1\frac{a_0\lambda_3(t)}{1+a_1\lambda_3(t)}\right)C\right)\mathbf{P}.
\end{equation}
After the spatial discretization, the solution of problem \eqref{eq:problem2} converts into the solution of the nonlinear ordinary differential equation system of initial value problem \eqref{eq:nonlinear_sde}\eqref{eq:initial_value}.

\subsubsection{Fully discrete numerical scheme}

To finish the construction of the numerical scheme, we need to truncate the approximate solution \eqref{eq:approximate_solution2} to a finite-dimensional one and perform time discretization. The finite-dimensional form of \eqref{eq:X_ab} is denoted as
\begin{equation}
\label{eq:X_N}
    \mathrm{X}_{N(a,b)}=\left\{\varphi \in P_{N+3}(a,b) : \varphi(a)=\varphi(b)=\varphi'(a)=\varphi'(b)=0   \right\},
\end{equation}
where $P_N(a,b)$ is the set of all real polynomials of degree no more than $N$ and the dimension of $P_N{(a,b)}$ is $N+1$. It is evident that a  non-trivial polynomial with the homogeneous boundary conditions in \eqref{eq:X_N} must be of at least fourth degree, thus leading to a reduced dimension of the set in \eqref{eq:X_N}. The polynomial space in \eqref{eq:X_N} is selected as $P_{N+3}(a,b)$ so that the dimension of the $\mathrm{X}_{N(a,b)}$ space is $N$. Then the trial function space can be truncated as

\begin{equation}
    \label{eq:trial_function}
    \mathrm{W}_N=\mathrm{X}_{N(V_{\min},V_R)} + \mathrm{X}_{N(V_R,V_F)} + \mathrm{W}_1.
\end{equation}
Assuming $\{h^L_k\}_{k=0}^{N-1}$ is a set
of basis functions of $X_{N(V_{\min},V_R)}$ and $\{h^R_k\}_{k=0}^{N-1}$ is a set
of basis functions of $X_{N(V_R,V_F)}$. $\{\psi_k\}_{k=1}^{2N+3}=\{h^L_0,...,h^L_{N-1},h^R_0,...,h^R_{N-1},g_1,g_2,g_3\}$ is a basis of $\mathrm{W}_N$. Then the numerical solution $p_N(v,t)$ can be expressed as
\begin{equation}
    \label{eq:approximate_solution3}
    p_N(v,t)=\sum_{k=0}^{N-1} u_k^L(t)h^L_k(v)+\sum_{k=0}^{N-1} u_k^R(t)h^R_k(v)+\sum_{k=1}^3 \lambda_k(t)g_k(v)=\sum_{k=1}^{2N+3}\hat{u}_k(t)\psi_k(v).
\end{equation}
 The initial condition for the expansion coefficients $\{\hat{u}_{k}(0)\}_{k=0}^{2N+3}$ can be obtained by the least square approximation,
\begin{equation}
    \label{eq:initial_vector2}
    \int_{V_{\min}}^{V_F} \sum_{k=1}^{2N+3}\hat{u}_k(0)\psi_k(v) \phi_j dv=\int_{V_{\min}}^{V_F} p^0(v)\phi_j dv, \qquad \forall \phi_j \in \mathrm{V}_N.
\end{equation}

Suppose the truncated test function space is denoted by $\mathrm{V}_N$, which shall be specified later. The expansion coefficients $\{\hat{u}_k(t)\}_{k=0}^{2N+3}(t>0)$ can be determined by the semi-discrete variational formulation
\begin{equation}
    \label{eq:variational_form2}
    \begin{cases}
        \text{Find } p_N\in \mathrm{W}_{N} \text{ such that}\\
        (\mathcal{L}p_N,\phi_j)=0,\quad \forall \phi_j \in \mathrm{V}_N.
    \end{cases}
\end{equation}


For time discretization, we use a semi-implicit method. The interval $[0,T_{\text{max}}]$ is divided  into $n_t$ equal sub-intervals with size
\begin{equation}
    \Delta t=\frac{T_{\text{max}}}{n_t},
\end{equation}
and the grid points can be represented as follows
\begin{equation}
    t^{n}=n \Delta t, \qquad n=0,1,2, \cdots, n_{t}.
\end{equation}


The semi-implicit scheme of \eqref{eq:operator} is denoted by
\begin{equation}
    \label{eq:semi_implicit}
\begin{aligned}
    \tilde{\mathcal{L}}p_N(v,t^{n+1})&=\frac{p_N(v,t^{n+1})-p_N(v,t^{n})}{\Delta t}-\partial_v(vp_N(v,t^{n+1}))+bN(t^n)\partial_vp_N(v,t^{n+1})\\
    &-a(N(t^n))\partial_{vv}p_N(v,t^{n+1})=0,\qquad\qquad\qquad n=1,2,...,n_t.
\end{aligned}
\end{equation}
Note that, the mean firing rate $N(t^n)$ is treated explicitly, but the rest of the terms are implicit. Such a time discretization naturally avoids the use of a nonlinear solver. Then we can obtain the fully discrete scheme of the variational formulation \eqref{eq:variational_form2}: for each time step
\begin{equation}
    \label{eq:variational_form3}
    \begin{cases}
       \text{Find } p_N\in \mathrm{W}_{N} \text{ such that}\\
        (\tilde{\mathcal{L}}p_N,\phi_j)=0,\quad \forall \phi_j \in \mathrm{V}_N.
    \end{cases}
\end{equation}

More precisely, setting
\begin{equation}
    \label{eq:Matrix2}
    \begin{aligned}
        &\hat{\mathbf{P}}^n=(\hat{u}_1(t^n),\hat{u}_2(t^n),...,\hat{u}_{2N+3}(t^n))^T,\\
        &\hat{s}_{jk}=(\psi_k,\phi_j),\quad \hat{S}=(\hat{s}_{jk})_{k=1,...,2N+3}\\
        &\hat{a}_{jk}=(\partial_v(v\psi_k),\phi_j),\quad \hat{A}=(\hat{a}_{jk})_{k=1,...,2N+3}\\
        &\hat{b}_{jk}=(\partial_{v}\psi_k,\phi_j),\quad \hat{B}=(\hat{b}_{jk})_{k=1,...,2N+3}\\
        &\hat{c}_{jk}=(\partial_{vv}\psi_k,\phi_j),\quad \hat{C}=(\hat{c}_{jk})_{k=1,...,2N+3},
    \end{aligned}
\end{equation}
the  variational formulation \eqref{eq:variational_form3} reduces to
\begin{equation}
\label{eq:system2}
    \left(\frac{\hat{S}}{\Delta t}-\hat{A}+bN(t^n)\hat{B}-a(N(t^n))\hat{C}\right)\hat{\mathbf{P}}^{n+1}=\frac{\hat{S}}{\Delta t}\hat{\mathbf{P}}^n.
\end{equation}











\subsection{Stability and the choice of test functions} \label{sec:stability}

The dynamic boundary conditions also give rise to challenges in choosing proper finite-dimensional test function spaces.  As we shall elaborate below, the construction of the trial function is so delicate that we can not simply choose the test functions only out of accuracy. Our goal is to find test functions that result in a stable evolution system in the discrete setting, and we hope the total mass is conserved with satisfactory accuracy. 


%The conservation property is the basic property of the model, and stability is an essential factor in ensuring the success of the numerical scheme. Having proposed the fully discrete numerical scheme in Section \ref{sec:fully_discrete_scheme}, it is necessary to determine an appropriate test function space, as it affects the properties of the numerical solution. 

To this end, two propositions are introduced that relate the test functions to the conservation and stability of the semi-discrete scheme \eqref{eq:variational_form2} in the linear case. However, the spectral method is often not able to completely ensure the conservation of mass, therefore it is not serving as a rigid criterion. The stability of the numerical solution is instead analyzed through its long-term asymptotic behavior in the linear regime, which will be discussed in greater detail below. Following this, three different test function spaces are analyzed respectively.


When analyzing the impact of the test function space, we are to consider the semi-discrete system \eqref{eq:variational_form2}. Thanks to the definition in \eqref{eq:Matrix2}, the system can reduce to
\begin{equation}
    \label{eq:SDE_system2}
    \hat{S}\partial_t\hat{\mathbf{P}}=\left(\hat{A}-\left(bN(t)\right)\hat{B}+\left(a(N(t))\right)\hat{C}\right)\hat{\mathbf{P}},\quad \hat{\mathbf{P}}(0)=\hat{\mathbf{P}}^0,
\end{equation}
where $\hat{\mathbf{P}}=(\hat{u}_1(t),\hat{u}_2(t),...,\hat{u}_{2N+3}(t))^T,\,\hat{\mathbf{P}}^0=(\hat{u}_1(0),\hat{u}_2(0),...,\hat{u}_{2N+3}(0))^T$. For simplicity, we study the case of a linear equation that is $b=0$ and $a(N)=1$. Then the nonlinear system \eqref{eq:SDE_system2} becomes a linear system
\begin{equation}
    \label{eq:linear_system2}
    \hat{S}\partial_t \hat{\mathbf{P}}=(\hat{A}+\hat{C})\hat{\mathbf{P}}, \quad \hat{\mathbf{P}}(0)=\hat{\mathbf{P}}^0.
\end{equation}
Considering the unique solvability of ordinary differential equations, we assume that the matrices $\hat{S}$, $\hat{A}$, and $\hat{C}$ are square matrices of order $2N+3$ and the matrix $\hat{S}$ is invertible. Let $\hat{K}=\hat{S}^{-1}(\hat{A}+\hat{C})$, then the system \eqref{eq:linear_system2} can be rewritten as
\begin{equation}
\label{eq:linear_system3}
    \hat{\mathbf{P}}_t=\hat{K}\hat{\mathbf{P}}.
\end{equation}
Let $\hat{\mathbf{P}}^{\infty}=(\hat{u}_1^{\infty},\hat{u}_2^{\infty},...,\hat{u}_{2N+3}^{\infty})^T$ be the steady-state solution of the equation. It holds that
\begin{equation}
    \label{eq:steady}
    \hat{K}\hat{\mathbf{P}}^{\infty}=0.
\end{equation}
The steady-state equation \eqref{eq:steady} has a nonzero solution if and only if the matrix $\hat{K}$ has at least one zero eigenvalue. With a prescribed test function space, the properties of the scheme can be assessed by inspecting the elements of matrix $\hat{K}$, allowing us to fully characterize the system's behavior. The following propositions serve to elucidate this connection.

\begin{proposition}[mass conservation]\label{prop1}
    Consider the Fokker-Planck equation \eqref{eq:problem2} with $a=1, b=0$ and the semi-discrete scheme \eqref{eq:linear_system3} where the dimension of test function space $V_N$ is $2N+3$. The following relations hold:
\begin{enumerate}
    \item Matrix $\hat{K}$ has zero eigenvalue if and only if the test function space $\mathrm{V}_N$ contains constant functions.
    \item If the matrix $\hat{K}$ has zero eigenvalue, then the total mass of the numerical solution solved by system \eqref{eq:linear_system2} does not change with time. That is
    \begin{equation}
        \int_{V_{\min}}^{V_F}\partial_tp_N(v,t) dv=0,
    \end{equation}
    where $p_N(v,t)$ is defined in \eqref{eq:approximate_solution3}.
\end{enumerate}
\end{proposition}
\begin{proof}
\textbf{Proof of (1)}. 
If the test function space $\mathrm{V}_N$ contains constants, without loss of generality, let $\phi_j=1$. Using the definition in \eqref{eq:Matrix2}, $\forall \varphi_i \in \mathrm{W}_N$, we can derive that
\begin{equation}
    \label{eq:integral}
    \begin{aligned}
        &\int_{V_{\min}}^{V_F}\partial_v(v\varphi_i) dv=v\varphi_i |_{V_{\min}}^{V_R^-}+v\varphi_i |_{V_R^+}^{V_F}=0,\\
        &\int_{V_{\min}}^{V_F}\partial_{vv}\varphi_i dv=\partial_v\varphi_i |_{V_{\min}}^{V_R^-}+\partial_v\varphi_i |_{V_R^+}^{V_F}=0.
    \end{aligned}
\end{equation}
So the elements of the $j$th row of the matrices $A$ and $C$ are all zeros. Since $\hat{S}$ is invertible, $S^{-1}$ is a full-rank matrix. Then
\begin{equation}
    \text{rank}(\hat{K})=\text{rank}(\hat{S}^{-1}(\hat{A}+\hat{C}))=\text{rank}(\hat{A}+\hat{C})<2N+3.
\end{equation}
So $\hat{K}$ has a zero eigenvalue.


If matrix $\hat{K}$ has a zero eigenvalue, then matrix $(\hat{A}+\hat{C})$ has zero eigenvalue for $\hat{S}$ is invertible. Therefore, the matrix $(\hat{A}+\hat{C})$ can make the elements in the jth row all zero through the matrix transformation. Notice that, performing matrix row transformation on matrix $(\hat{A}+\hat{C})$ corresponds to replacing the test function in linear system \eqref{eq:linear_system2}  with the linear combination of the original test function. Without loss of generality, we assume that the elements in the jth row of matrix $(\hat{A}+\hat{C})$ are all zeros and the corresponding test function is $\phi$. Using the definition in \eqref{eq:Matrix2}, $\forall \varphi_i \in \mathrm{W}_N$,  it holds that
\begin{equation}
    \begin{aligned}
        \int_{V_{\min}}^{V_F}\partial_v(v\varphi_i) +\partial_{vv}\varphi_i dv=-\int_{V_{\min}}^{V_F} (v\varphi_i+\partial_v\varphi_i)\partial_v\phi dv=0.
    \end{aligned}
\end{equation}
Since the above formula holds for all $\varphi_i \in \mathrm{W}_N$, so $\partial_v\phi=0$, that is $\phi= \text{constant}$.

\textbf{Proof of (2)}.
From (1), we know that when the matrix $\hat{K}$ has a zero eigenvalue,  the constant function $C_1 \in V_N$. Substituting $\phi_j=1$ into \eqref{eq:variational_form2} with $a=1,b=0$,
\begin{equation}
    \int_{V_{\min}}^{V_F} \partial_t p_N dv-\int_{V_{\min}}^{V_F}(\partial(vp_N)+\partial_{vv}p_N) dv\overset{\eqref{eq:integral}}{=}\partial_t \int_{V_{\min}}^{V_F} p_N dv=0.
\end{equation}
So the total mass does not change over time.
\end{proof}

\begin{proposition}[Stability]\label{prop2}
    Consider the Fokker-Planck equation \eqref{eq:problem2} with $a=1, b=0$ and the semi-discrete scheme \eqref{eq:linear_system3} . A necessary condition for the stability of the method is that all the eigenvalues of the matrix $\hat{K}$ are non-positive.
\end{proposition}
Note that a modified stability criterion is proposed here because the traditional stability conclusion cannot be applied due to the complexity of the equation. In the linear case, the equation has a unique steady state \cite{caceres2011analysis}, and the solution of the equation will converge exponentially to the steady state, so the discretized kinetic equation can only have non-positive eigenvalues. When there are positive eigenvalues, it means that the numerical scheme is unstable.

Following the theoretical analysis, we can now discuss the specific test function space. Our goal is to select suitable test function spaces such that the constructed numerical scheme is stable and preserves the original properties of the Fokker-Planck equation \eqref{eq:problem2} to the greatest extent, such as mass conservation. The Galerkin method is widely used in spectral methods \cite{shen2011spectral}. Consequently, Legendre-Galerkin Method is proposed below.
\paragraph{Legendre-Galerkin Method (LGM)}
The test function space is chosen to be the same as the trial function space. Applied to the semi-discrete method \eqref{eq:variational_form2} or its fully discrete version \eqref{eq:variational_form3} as 
\begin{equation}
    \mathrm{V}_N=\mathrm{W}_N,
\end{equation}
where $\mathrm{V}_N$ is test function space, and $\mathrm{W}_N$ is trial function space defined in \eqref{eq:trial_function}, we obtain a Legendre-Galerkin Method (LGM for short) for the model \eqref{eq:problem1}. 

The LGM method is numerically stable but total mass is not well conserved in dynamics. When constructing the trial function space, some low-order polynomials, especially constants, are discarded in order to satisfy the boundary conditions. For the LGM, the test function space does not contain constants, which fails to ensure mass conservation as stated in Proposition \ref{prop1}. Hence, this method can be used for  finite-time simulations, yet it is unsuitable for capturing long-time behavior or multiscale problems.


 According to Proposition \ref{prop1}, to improve the mass conservation property of the LGM, it seems that we may replace one of the basis functions in  the test function space with the constant function $1$. Say, we may consider the modified test function space
\begin{equation} \label{tildeV}
    \tilde{\mathrm{V}}_N=\mathrm{W}_N-\{\psi_k\} +\{1\},
\end{equation}
where $\{\psi_k\}(k=1,...,2N+3)$ is the basis function of the $\mathrm{W}_N$ space.

In this case, the mass of the numerical solution appears invariant. However, as shown in Figure \ref{fig:stable}, the matrix $\hat{K}$ in \eqref{eq:linear_system3} has positive eigenvalues for some $N$, which makes the method unstable, which agrees with Proposition \ref{prop2}. In fact, Figure \ref{fig:stable} shows that the maximum eigenvalue of the matrix $\hat{K}$ is significantly positive large  for when $N$ is odd and when the modified test function space $\tilde{\mathrm{V}}_N$ is used. Hence, we need to resort to other strategies for enhancing mass conservation. 
\begin{figure}[!htb]
    \centering
        \begin{minipage}[c]{0.49\textwidth}
            \centering
            \includegraphics[width=1\textwidth]{Eig.eps}
        \end{minipage}
        \begin{minipage}[c]{0.49\textwidth}
            \centering
            \includegraphics[width=1\textwidth]{3step.eps}
        \end{minipage}
        \caption{When the test function space is $\tilde{\mathrm{V}}_N$ \eqref{tildeV}, the numerical method might be unstable. Left: The maximum eigenvalue of matrix $\hat{K}$ at different $N$. Right: A typical unstable solution. Equation parameters $a=1, b=0$ with Gaussian initial condition $v_0=-1, \sigma_0^2=0.5$ and $N=11,\Delta t=0.001$.}
        \label{fig:stable}
\end{figure}



\paragraph{Modified Petrov-Galerkin Method (MPGM)} We propose an alternative formulation of the test function space by extending the test function space with one additional basis function $1$. As a consequence, the dimension of the test function space is larger than that of the trial function space, which results in an overdetermined system, and we solve such a system using the Least-Squares method. 

More precisely,  for the semi-discrete method \eqref{eq:variational_form2} or its fully discrete version \eqref{eq:approximate_solution3}, constants are added to  form an augmented test function space
\begin{equation}
    \mathrm{V}_N=\mathrm{W}_N +\{1\}.
\end{equation}
where $\mathrm{W}_N$ is trial function space defined in \eqref{eq:trial_function}, and we thus obtain the modified Petrov-Galerkin Method (MPGM for short).

Note that, the dimension of the test function space is higher than that of the trial function space by $1$. Multiplying \eqref{eq:linear_system2} from the left by $\hat{S}^T$ , the least square solution satisfies
\begin{equation}
    \hat{S}^T\hat{S}\partial_t \hat{\mathbf{P}}=\hat{S}^T(\hat{A}+\hat{C})\hat{\mathbf{P}}.
\end{equation}
The matrix $\hat{K}$ in \eqref{eq:linear_system3} can be written as
\begin{equation}
    \hat{K}=(\hat{S}^T\hat{S})^{-1}(\hat{S}^T(\hat{A}+\hat{C})).
\end{equation}
The numerical solution is not completely mass-conserving due to the use of the least-squares method. But compared with the LGM, the mass of the numerical solution of the MPGM changes very little over time, as shown in Figure \ref{mass}. With extensive tests, the matrix $\hat{K}$ has no positive eigenvalues, and the MPGM is numerically stable.
\begin{figure}[!htb]
    \centering
        \begin{minipage}[c]{0.49\textwidth}
            \centering
            \includegraphics[width=7cm]{mass1.eps}
        \end{minipage}
        \begin{minipage}[c]{0.49\textwidth}
            \centering
            \includegraphics[width=7cm]{mass2.eps}
        \end{minipage}
        \caption{Equation parameters $a=1, b=0$ with Gaussian initial condition $v_0=-1, \sigma_0^2=0.5$ and $N=10,\Delta t=0.001,T_\text{max}=5$. Left: Variation of total mass with time by the LGM. Right: Variation of total mass with time by the MPGM.}
        \label{mass}
\end{figure}



In conclusion, we have proposed two methods, i.e. the LGM and the MPGM, for the model problem \eqref{eq:problem1},  each possessing different advantages and therefore should be used in a flexible manner. The MPGM is preferred for simulating long-time behavior and testing the asymptotic preserving properties of the model, as the mass of the numerical solution from the LGM is significantly diminished in a long time. On the other hand, the LGM can be utilized for $\mathcal O(1)$ time simulations with verifiable order of convergence, and it does not involve the error due to the least square approximation.





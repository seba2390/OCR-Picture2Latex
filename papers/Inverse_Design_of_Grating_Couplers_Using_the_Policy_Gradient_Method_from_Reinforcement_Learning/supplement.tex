\documentclass{article}



\usepackage{arxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}		% Can be removed after putting your text content
\usepackage{graphicx}
%\usepackage{natbib}
\usepackage[style=ieee, citestyle=numeric-comp, backend=biber, dashed=false]{biblatex}
\addbibresource{rlrefs_v2.bib}
\usepackage{doi}
\usepackage{bm}

\usepackage{amsmath,amssymb}
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}

\DeclareRobustCommand{\bbone}{\text{\usefont{U}{bbold}{m}{n}1}}
\DeclareMathOperator*{\EX}{\mathbb{E}}% expected value

\title{Inverse Design of Grating Couplers Using the Policy Gradient Method from Reinforcement Learning}


%\date{September 9, 1985}	% Here you can change the date presented in the paper title
%\date{} 					% Or removing it

\author{ \href{https://orcid.org/0000-0003-1260-412X}{\includegraphics[scale=0.06]{orcid.pdf}\hspace{1mm}Sean~Hooten}\thanks{Also affiliated with Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, Berkeley, CA 94709, USA.}
		\\
	Hewlett Packard Labs \\
	Hewlett Packard Enterprise \\
	Milpitas, CA 95035, USA \\
	\texttt{sean.hooten@hpe.com} \\
	%% examples of more authors
	\And
	%\href{https://orcid.org/0000-0002-7301-8610}{\includegraphics[scale=0.06]{orcid.pdf}
    Raymond G. Beausoleil \\
	Hewlett Packard Labs\\
	Hewlett Packard Enterprise \\
	Milpitas, CA 95035, USA \\
	\texttt{ray.beausoleil@hpe.com} \\
	\And
	\href{https://orcid.org/0000-0002-7301-8610}{\includegraphics[scale=0.06]{orcid.pdf}\hspace{1mm}Thomas~Van Vaerenbergh} \\
	Hewlett Packard Labs\\
	HPE Belgium\\
	B-1831 Diegem, Belgium \\
	\texttt{thomas.van-vaerenbergh@hpe.com}
	%%\AND
	%%Sri Krishna Vadlamani \\
	%%Department of Electrical Engineering and Computer Sciences \\
	%%University of California, Berkeley \\
	%%Berkeley, CA 94720 \\
	%%\texttt{srikv@eecs.berkeley.edu} \\
	%% \And
	%% Coauthor \\
	%% Affiliation \\
	%% Address \\
	%% \texttt{email} \\
	%% \And
	%% Coauthor \\
	%% Affiliation \\
	%% Address \\
	%% \texttt{email} \\
}


% Uncomment to remove the date
\date{}

% Uncomment to override  the `A preprint' in the header
\renewcommand{\headeright}{Supplementary Material}
\renewcommand{\undertitle}{Supplementary Material}
\renewcommand{\shorttitle}{Inverse Design of Grating Couplers with PHORCED}

%%% Add PDF metadata to help others organize their library
%%% Once the PDF is generated, you can check the metadata with
%%% $ pdfinfo template.pdf
\hypersetup{
pdftitle={one-step policy gradient method for inverse electromagnetic design},
pdfsubject={physics, electromagnetics},
pdfauthor={Sean~Hooten, Thomas~Van Vaerenbergh},
pdfkeywords={physics, electromagnetics, optimization, adjoint method},
}

\begin{document}
\maketitle


\renewcommand{\theequation}{S.\arabic{equation}}
\renewcommand\thefigure{S\arabic{figure}}
% keywords can be removed

\section{Theory of GLOnet and PHORCED Optimization Algorithms}
Below we will explain and derive the formulae presented in Fig. 1 of the main manuscript, particularly the gradient/backpropagation terms. The primary intention of this section is to justify the claim that PHORCED does not require an adjoint simulation. This section will assume the reader has a basic understanding of gradient-based optimization and the adjoint method. The reader is recommended to consult Refs.\,\cite{michaels_inverse_2018, su_fully-automated_2017, hooten_adjoint_2020, sun_adjoint-method-inspired_2020, dezfouli_design_2021} for more detailed explanation of these topics.

In the following, let $\mathbf{p}=[p_1, p_2,...,p_{n-1},p_n]^T$ be a vector of $n$ geometrical degrees-of-freedom (parameters) that we wish to vary in our device. Furthermore, the time-harmonic Maxwell's Equations may be written as a matrix equation:
\begin{align}
    \text{Maxwell's Equations: }\mathbf{A}\mathbf{x}=\mathbf{b}\label{eq:ax_b}
\end{align}
with:
\begin{align}
        \mathbf{A}=\begin{bmatrix}
            j\omega\varepsilon(\mathbf{p}) &  \nabla \times \\
            \nabla \times & -j\omega \mu(\mathbf{p})
        \end{bmatrix}, \quad
        \mathbf{x}=\begin{bmatrix}
            \mathbf{E} \\
            \mathbf{H}
        \end{bmatrix}, \quad
        \mathbf{b}=\begin{bmatrix}
            \mathbf{J}_e \\
            \mathbf{J}_m
        \end{bmatrix} 
\end{align}
where $j$ is the imaginary unit, $\omega$ is the frequency, $\mathbf{A}$ is the Maxwell Operator, $\mathbf{x}$ is a vector of electric and magnetic fields $\mathbf{E}$ and $\mathbf{H}$, and $\mathbf{b}$ is a vector of electric and magnetic current sources $\mathbf{J}_e$ and $\mathbf{J}_m$. Notice that $\mathbf{A}$ includes the permittivity and permeability $\varepsilon$ and $\mu$ which are explicitly parameterized by the geometrical degrees-of-freedom $\mathbf{p}$. We will assume that the electric and magnetic field vectors each have dimension $k$, which might be the total number of Yee cells in an FDTD simulation. Note also that the electric and magnetic fields are, in general, complex-valued.

A solution to Maxwell's Equations (e.g. a simulation), can be regarded as solving Eq.\,\eqref{eq:ax_b} for $\mathbf{x}$ given $\mathbf{A}$ and $\mathbf{b}$. A shorthand way to write this is:
\begin{align}
    \mathbf{x} = \mathbf{A}^{-1}\mathbf{b}\label{eq:ax_b_solve}
\end{align}
Though, it should be emphasized that taking an explicit inverse of $\mathbf{A}$ is rarely done in practice (and not to mention, not well-defined on a continuous domain). Since $\mathbf{A}$ is a function of $\mathbf{p}$, we will rewrite Eq.\,\eqref{eq:ax_b_solve} in a more convenient form. Without loss of generality, let $g:\mathcal{R}^n\rightarrow \mathcal{C}^{2k}$ be a function that maps geometrical degrees-of-freedom to electric and magnetic field quantities. Then, we can write:
\begin{align}
    \boxed{\text{Forward Simulation: } \mathbf{x} = g(\mathbf{p})}\label{eq:x_gp}
\end{align}
which represents the operation given above in Eq.\,\eqref{eq:ax_b_solve}, but with explicit dependence on $\mathbf{p}$. Please note that $g$ is specific to a particular electromagnetic solution of Maxwell's equations with implicitly-defined boundary conditions and geometrical mapping of the permittivity and permeability; one should always refer back to Eq.\,\eqref{eq:ax_b} for the most general solution to Maxwell's Equations.

The last requirement for a well-defined inverse design optimization problem is a merit function, which defines the performance or success of a given electromagnetic device. Let $f:\mathcal{C}^{2k}\rightarrow\mathcal{R}$ be a function that maps electric and magnetic field quantities to a performance metric (figure-of-merit). Then, given $\mathbf{x}=g(\mathbf{p})$ for given parameters $\mathbf{p}$ we may write:
\begin{align}
    \text{Figure-of-Merit}&=f(\mathbf{x}) \\
    \text{Figure-of-Merit}&=(f\circ g)(\mathbf{p})\label{eq:fom_f_g_p}
\end{align}
where in Eq.\,\eqref{eq:fom_f_g_p} we made use of Eq.\,\eqref{eq:x_gp} to write the total figure-of-merit as a function composition of the electromagnetic merit function and the solution to Maxwell's Equations given well-defined $\mathbf{p}$. The intention of an inverse design optimization is to finding the best set of geometrical degrees-of-freedom that improve the figure-of-merit. Assuming that we intend to maximize the figure-of-merit, we may write a generalized electromagnetic inverse design problem in optimization notation as the following:
\begin{align}
    \boxed{\text{Inverse Design Optimization: } \mathbf{p}^* = \argmax_{\mathbf{p}}{(f\circ g)(\mathbf{p})}}\label{eq:p_inv}
\end{align}
where $\mathbf{p}^*$ is the global optimum of $(f\circ g)$. Using optimization methods such as gradient-descent, GLOnet, and PHORCED, we hope to attain $\mathbf{p}^*$ in a computationally efficient way.

Given the convenient notation in Eqs.\,\eqref{eq:x_gp}-\eqref{eq:p_inv}%(\ref{eq:x_gp},~\ref{eq:p_inv}),
we are now prepared to explain the three optimization algorithms given in Fig.\,1 of the main text. We begin with simple gradient-based optimization.

\subsection{Gradient-Based Optimization}
In gradient-based optimization we intend to use the gradient of a function to inform an optimization update step. In terms of our inverse design optimization problem Eq.\,\eqref{eq:p_inv}, we take the gradient of the figure-of-merit with respect to the geometrical variable $\mathbf{p}$ defined at some given $\mathbf{p}'$. For convenience we write this gradient in a slightly shorthand way:
\begin{align}
    \text{Figure-of-Merit Gradient: }\frac{\partial(f\circ g)}{\partial \mathbf{p}'} \equiv \nabla_{\mathbf{p}} \left[(f\circ g)(\mathbf{p})\right]_{\mathbf{p}=\mathbf{p}'}\label{eq:gradient}
\end{align}
In electromagnetic problems, the gradient is most efficiently calculated using the adjoint method. An exact derivation of the adjoint method may be found in Refs.\,\cite{michaels_inverse_2018, su_fully-automated_2017, hooten_adjoint_2020, sun_adjoint-method-inspired_2020, dezfouli_design_2021}. For our purposes, we require only the qualitative understanding that for any given $\mathbf{p}'$, we may solve Eq.\,\eqref{eq:gradient} using just 2 simulations (the forward and adjoint simulations respectively), regardless of the dimension of the parameter vector, $n=\text{dim}(\mathbf{p}')$. Using this gradient, we can then update the parameter vector that will be used in the subsequent iteration of our gradient-based optimization algorithm. In this work we used the Broyden–Fletcher–Goldfarb–Shanno (BFGS) algorithm for our baseline gradient-based optimization comparisons. This algorithm was implemented out-of-the-box from the scipy.optimize python module, where forward/adjoint simulations and gradient calculations were performed in the open-source electromagnetic optimization package EMopt \cite{michaels_emopt_2019}.

\subsection{GLOnet}
In this section we will derive the backpropagation term from Fig.\,1 of the main manuscript. Note that this derivation differs from that originally given by Jiang and Fan \cite{jiang_global_2019,jiang_simulator-based_2020}, we refer the reader there for more detail and a for a different perspective from that discussed here.  Let $\mathbf{z}\sim \mathcal{D}$ be a random vector drawn from a ($d$-dimensional) distribution $\mathcal{D}$. Importantly, this noise vector serves as an input for a neural network that deterministically generates geometrical parameter vectors for simulation, based on programmable weights denoted by $\theta$. Specifically, let $h_{\boldsymbol{\theta}}: \mathcal{R}^d\rightarrow\mathcal{R}^n$ represent this function such that for given $\boldsymbol{\theta}$ and sampled $\mathbf{z}\sim\mathcal{D}$ we have:
\begin{align}
    \mathbf{p} = h_{\boldsymbol{\theta}} (\mathbf{z})
\end{align}
By virtue of $\mathbf{z}$ being a random variable, $\mathbf{p}$ is also random but drawn from an unknown distribution parameterized by $\boldsymbol{\theta}$. Consequently, the objective function for inverse design optimization via GLOnet becomes:
\begin{align}
    (f\circ g)(\mathbf{p}) \rightarrow \EX_{\mathbf{p}=h_{\boldsymbol{\theta}} (\mathbf{z})} [(f\circ g)(\mathbf{p})] = \EX_{\mathbf{z}\sim \mathcal{D}} [(f\circ g \circ h_{\boldsymbol{\theta}})(\mathbf{z})]
\end{align}
where $\EX[\cdot]$ is the expected value operator. In the right-hand side we simplified the expression by replacing $\mathbf{p}=h_{\boldsymbol{\theta}} (\mathbf{z})$. Intuitively our intention is to optimize the average value of the electromagnetic merit function generated by the neural network. Note that because of this exchange, the variable(s) that may be explicitly controlled by the user or optimization algorithm are the programmable weights, $\boldsymbol{\theta}$. Consequently, the optimization problem for GLOnet may be written:
\begin{align}
    \boxed{\text{GLOnet Optimization: } \boldsymbol{\theta}^* = \argmax_{\boldsymbol{\theta}} \EX_{\mathbf{z}} [(f\circ g \circ h_{\boldsymbol{\theta}})(\mathbf{z})]}\label{eq:glonet}
\end{align}
where we wrote $\mathbf{z}$ as the variable of the expected value with the understanding that it is sampled from user-defined distribution $\mathcal{D}$. To optimize $\boldsymbol{\theta}$ for this objective, we will leverage the powerful neural network optimization package called PyTorch \cite{paszke2017automatic}. This tool allows one to invoke state-of-the-art gradient-based algorithms for the optimization of neural network weights. This will require the partial derivatives of the GLOnet objective with respect to the neural networks weights. 

Let the probability density function of $\mathbf{z}$ be denoted $\text{pdf}(\mathbf{z})$, then we may write:
\begin{align}
    \EX_{\mathbf{z}} [(f\circ g \circ h_{\boldsymbol{\theta}})(\mathbf{z})] = \int (f\circ g \circ h_{\boldsymbol{\theta}})(\mathbf{z}) \text{pdf}(\mathbf{z})d\mathbf{z}
\end{align}
Then for scalar weight $\theta_j\in\boldsymbol{\theta}$ in our neural network, the partial derivative of the objective is given by:
\begin{align}
    \frac{\partial}{\partial \theta_j}\EX_{\mathbf{z}} [(f\circ g \circ h_{\boldsymbol{\theta}})(\mathbf{z})] = \int \frac{\partial (f\circ g \circ h_{\boldsymbol{\theta}})(\mathbf{z})}{\partial \theta_j} \text{pdf}(\mathbf{z})d\mathbf{z}
\end{align}
where we invoked the Leibniz integral rule for the exchange of the integral and partial derivative operators. Let $\mathbf{p}=h_{\boldsymbol{\theta}}(\mathbf{z})$ be the output of the neural network for input $\mathbf{z}$. Then we may apply the chain rule to the derivative term:
\begin{align}
    \frac{\partial}{\partial \theta_j}\EX_{\mathbf{z}} [(f\circ g \circ h_{\boldsymbol{\theta}})(\mathbf{z})] &= \int \frac{\partial (f\circ g)}{\partial \mathbf{p}}\cdot\frac{\partial \mathbf{p}}{\partial \theta_j} \text{pdf}(\mathbf{z})d\mathbf{z} \\
    &= \EX_\mathbf{z}\left[\frac{\partial (f\circ g)}{\partial \mathbf{p}}\cdot\frac{\partial \mathbf{p}}{\partial \theta_j} \bigg|_{\mathbf{p}=h_{\boldsymbol{\theta}}(\mathbf{z})}\right]
\end{align}
where in the second step we re-wrote the integral as an expected value. Note that the ``$\cdot$'' operator is the vector dot product. Abusing notation slightly, we may write the full gradient as:
\begin{align}
   \frac{\partial}{\partial \boldsymbol{\theta}}\EX_{\mathbf{z}} [(f\circ g \circ h_{\boldsymbol{\theta}})(\mathbf{z})]&= \EX_\mathbf{z}\left[\frac{\partial (f\circ g)}{\partial \mathbf{p}}\cdot\frac{\partial \mathbf{p}}{\partial \boldsymbol{\theta}} \bigg|_{\mathbf{p}=h_{\boldsymbol{\theta}}(\mathbf{z})}\right]\label{eq:glonet_deriv}
\end{align}
which concludes the proof. Observe that the first expression within the expected value is simply the adjoint method gradient described previously in Eq.\,\eqref{eq:gradient}, and therefore requires two simulations per output vector $\mathbf{p}$ of the neural network. The additional term $\partial \mathbf{p}/\partial \boldsymbol{\theta}$ may be evaluated using automatic differentiation.  

Note that in the original paper by Jiang and Fan \cite{jiang_global_2019,jiang_simulator-based_2020}, the authors emphasized taking the exponential value of the electromagnetic merit function, $f\rightarrow \exp\{f/\sigma\}$, where $\sigma$ is a hyperparameter. We can include this additional contribution explicitly in Eq.\,\eqref{eq:glonet} and Eq.\,\eqref{eq:glonet_deriv} through an application of the chain rule:
\begin{align}
    \boxed{
    \text{GLOnet Objective: }\EX_{\mathbf{z}}\left[\exp \left\{\frac{(f\circ g \circ h_{\boldsymbol{\theta}})(\mathbf{z})}{\sigma}\right\}\right]}\label{eq:glonet_obj_summ}
\end{align}

\begin{align}
    \boxed{
    \text{Backpropagation Gradient: }\EX_\mathbf{z}\left[\frac{1}{\sigma}\exp\left\{\frac{(f\circ g)(\mathbf{p})}{\sigma}\right\}\frac{\partial (f\circ g)}{\partial \mathbf{p}}\cdot\frac{\partial \mathbf{p}}{\partial {\boldsymbol{\theta}}} \bigg|_{\mathbf{p}=h_{\boldsymbol{\theta}}(\mathbf{z})}\right]}
    \label{eq:glonet_deriv_summ}
\end{align}

In the main text the exponential term was excluded for clarity, but for the GLOnet results in Fig.\,2 this is the form of the objective that was used, where we chose hyperparameter $\sigma=0.6$.

\subsection{PHORCED}
As mentioned the main text, PHORCED is qualitatively similar to GLOnet in the sense that we wish to use a generative neural network to suggest geometrical degrees-of-freedom. However, by contrast to GLOnet where $\mathbf{p}$ is provided deterministically from the neural network, in PHORCED we treat $\mathbf{p}$ as a random vector sampled from a conditional probability distribution, $\pi_{\boldsymbol{\theta}}$:
\begin{align}
    \mathbf{p}\sim\pi_{\boldsymbol{\theta}}(\mathbf{p}|\mathbf{z})
\end{align}
where $\mathbf{z}\sim \mathcal{D}$ is once again an input vector, which in this case conditions the distribution. Note that, for given $\mathbf{z}$, the distribution defined by $\pi_{\boldsymbol{\theta}}$ is not static and is in fact programmable by virtue of the neural network weights ${\boldsymbol{\theta}}$ that determine its statistical parameters. In the main text of this paper we chose $\pi_{\boldsymbol{\theta}}(\mathbf{p}|\mathbf{z})$ to be a multivariate Gaussian, with mean and covariance matrix defined by a generative neural network with weights ${\boldsymbol{\theta}}$. 

Because $\mathbf{p}$ is now explicitly a random vector (not random just by virtue of $\mathbf{z}$ being random) the objective of PHORCED is modified relative to GLOnet (from Eq.\,\eqref{eq:glonet}):
\begin{align}
    \boxed{\text{PHORCED Optimization: } {\boldsymbol{\theta}}^* = \argmax_{\boldsymbol{\theta}} \EX_{(\mathbf{p},\mathbf{z})}[(f\circ g)(\mathbf{p})]}
\end{align}
where the subtle difference is we now wish to improve the expected value of the electromagnetic merit function under the joint probability of sampling random vectors $\mathbf{p}$ and $\mathbf{z}$ \footnote{In the general reinforcement learning literature, the merit function within the expected value may be a function of both $\mathbf{p}$ and $\mathbf{z}$, but this situation was excluded because it is non-applicable here.}. As a consequence of this, we note that we may write the joint probability density function of $(\mathbf{p},\mathbf{z})$ as:
\begin{align}
    \text{pdf}(\mathbf{p},\mathbf{z})=\pi_{\boldsymbol{\theta}} (\mathbf{p}|\mathbf{z})\text{pdf}(\mathbf{z})
\end{align}
Hence,
\begin{align}
    \EX_{(\mathbf{p},\mathbf{z})}[(f\circ g)(\mathbf{p})]&=\iint (f\circ g)(\mathbf{p}) \text{pdf}(\mathbf{p},\mathbf{z})d\mathbf{p}d\mathbf{z} \\
    &=\iint (f\circ g)(\mathbf{p}) \pi_{\boldsymbol{\theta}}(\mathbf{p}|\mathbf{z})\text{pdf}(\mathbf{z})d\mathbf{p}d\mathbf{z}
\end{align}
Then for scalar weight $\theta_j\in \boldsymbol{\theta}$ in our neural network, the partial derivatives of this expected value are given by:
\begin{align}
    \frac{\partial}{\partial \theta_j}\EX_{(\mathbf{p},\mathbf{z})}[(f\circ g)(\mathbf{p})]&=\iint (f\circ g)(\mathbf{p}) \frac{\partial \pi_{\boldsymbol{\theta}}(\mathbf{p}|\mathbf{z})}{\partial \theta_j}\text{pdf}(\mathbf{z})d\mathbf{p}d\mathbf{z}\label{eq:phorced_pre_log}
\end{align}
where we applied the Leibniz integral rule followed by the product rule. Observe the very important fact that neither $\mathbf{p}$ nor $(f\circ g)$ are explicitly related to $\theta_j$, and therefore a term of the form $\frac{\partial(f\circ g)(\mathbf{p})}{\partial \theta_j}$ is zero in the product rule derivative. Indeed, only the policy distribution, $\pi_{\boldsymbol{\theta}}$, is modeled by the neural network, and therefore is the only quantity subject to the derivative. Moreover, we note that by the ''log trick'' we may write:
\begin{align}
    \frac{\partial \pi_{\boldsymbol{\theta}}(\mathbf{p}|\mathbf{\mathbf{z})}}{\partial \theta_j} = \pi_{\boldsymbol{\theta}}(\mathbf{p}|\mathbf{z})\frac{\partial}{\partial \theta_j} \log \pi_{\boldsymbol{\theta}}(\mathbf{p}|\mathbf{z})\label{eq:log_trick}
\end{align}
to which Eq.\,\eqref{eq:phorced_pre_log} becomes:
\begin{align}
    \frac{\partial}{\partial \theta_j}\EX_{(\mathbf{p},\mathbf{z})}[(f\circ g)(\mathbf{p})]&=\iint (f\circ g)(\mathbf{p}) \frac{\partial \log \pi_{\boldsymbol{\theta}}(\mathbf{p}|\mathbf{z})}{\partial \theta_j}\pi_{\boldsymbol{\theta}}(\mathbf{p}|\mathbf{z})\text{pdf}(\mathbf{z})d\mathbf{p}d\mathbf{z} \\
    &=\EX_{(\mathbf{p},\mathbf{z})}\left[(f\circ g)(\mathbf{p})  \frac{\partial \log \pi_{\boldsymbol{\theta}}(\mathbf{p}|\mathbf{z})}{\partial \theta_j}\right]\label{eq:phorced_post_log_trick}
\end{align}
where in the second step we used Eq.\,\eqref{eq:log_trick} and the definition of the expected value. Eq.\,\eqref{eq:phorced_post_log_trick} was reported in the main text as the quantity used for backpropagation. In our implementation we also included a ``baseline subtraction'' term, where we subtract the sample average of the electromagnetic merit function, $\text{average}_{\mathbf{p}}[(f\circ g)(\mathbf{p})]$, from the electromagnetic merit function each iteration of the optimization routine. This heuristic is well-known in the reinforcement learning to reduce model variance without affecting bias in expectation (Ref.\,\cite{sutton2018reinforcement}).

To summarize, the objective and backprogation terms for PHORCED are given by,
\begin{align}
    \boxed{\text{PHORCED Objective: } \EX_{(\mathbf{p},\mathbf{z})}\left[(f\circ g)(\mathbf{p})\right]}
\end{align}


\begin{align}
    \boxed{\text{Backpropagation Gradient: } \EX_{(\mathbf{p},\mathbf{z})}\left[\big((f\circ g)(\mathbf{p})-b \big)  \frac{\partial \log \pi_{\boldsymbol{\theta}}(\mathbf{p}|\mathbf{z})}{\partial \boldsymbol{\theta}}\right]}
\end{align}
\begin{align}
    \boxed{b\approx \EX_{(\mathbf{p},\mathbf{z})}\left[(f\circ g)(\mathbf{p})\right]}
\end{align}
Observe that PHORCED requires no evaluation of the gradient of the electromagnetic figure of merit: $\frac{\partial (f\circ g)}{\partial \mathbf{p}}$. Indeed, the foremost term within the gradient expression requires only ``forward simulation'' evaluations. Meanwhile, the latter term $\partial \log \pi_{\boldsymbol{\theta}}/\partial \boldsymbol{\theta}$ may be computed using pytorch's automatic differentiation feature. These features of PHORCED should be contrasted with the similar equations from GLOnet (Eqs.\,\eqref{eq:glonet_obj_summ}-\eqref{eq:glonet_deriv_summ}), where we note that the optimization objective is identical but the gradient required for backpropagation changes drastically by our representation of the neural network model.

\section{Neural Network Model Specifications}
In Fig.\,\ref{fig:nets} we illustrate the architectures and hyperparameters for the implementation of the generative neural network models used to obtain the results in Figs. 2-4 from the main text. Both PHORCED and GLOnet are used to output design vectors of dimension 60, representing the width and spacing between 30 grating etches. Note that there are better performing choices of grating coupler etch parameterization \cite{michaels_inverse_2018, hooten_adjoint_2020}, but this parameterization was chosen to illustrate how the algorithm would behave in high-dimensional situations where less physical intuition is available. Both models were implemented in PyTorch and electromagnetic simulations were performed in EMopt \cite{michaels_emopt_2019}. Hyperparameter definitions are provided in Fig.\,\ref{fig:defs}. Note that we were unable to perform exhaustive hyperparameter testing in this work due to the prohibitively slow speed of electromagnetic simulations of this size. Training with PHORCED and GLOnet required \textasciitilde 12 and \textasciitilde 36 hours on a high-performance server.

\begin{figure}[h!]
    \centering
    \includegraphics[width=13cm]{Figures/neuralnets_v2.png}
    \caption{Neural network models used for optimization with (a) PHORCED and (b) GLOnet. Note that ``Reward'' is the objective of interest, whereas the ``Pseudoreward'' is the objective value actually seen by the neural network. This allows us to conveniently invoke automatic differentiation despite performing electromagnetic simulations and gradient calculations outside of PyTorch's autograd framework. Other definitions and hyperparameters may be found in Fig.\,\ref{fig:defs}.}
    \label{fig:nets}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=8cm]{Figures/neuralnet_defs_v2.png}
    \caption{Definitions and hyperparameter specifications.}
    \label{fig:defs}
\end{figure}
\newpage

\printbibliography
%\bibliographystyle{IEEEtran}%unsrtnat}
%\bibliography{references}  %%% Uncomment this line and comment out the ``thebibliography'' section below to use the external .bib file (using bibtex) .


%\subsection{Citations}
%Citations use \verb+natbib+. The documentation may be found at
%\begin{center}
%	\url{http://mirrors.ctan.org/macros/latex/contrib/natbib/natnotes.pdf}
%\end{center}
%
%Here is an example usage of the two main commands (\verb+citet+ and \verb+citep+): Some people thought a thing \citep{kour2014real, hadash2018estimate} but other people thought something else \citep{kour2014fast}. Many people have speculated that if we knew exactly why \citet{kour2014fast} thought this\dots
%

%\begin{figure}
%	\centering
%	\fbox{\rule[-.5cm]{4cm}{4cm} \rule[-.5cm]{4cm}{0cm}}
%	\caption{Sample figure caption.}
%	\label{fig:fig1}
%\end{figure}


%\begin{table}
%	\caption{Sample table title}
%	\centering
%	\begin{tabular}{lll}
%		\toprule
%		\multicolumn{2}{c}{Part}                   \\
%		\cmidrule(r){1-2}
%		Name     & Description     & Size ($\mu$m) \\
%		\midrule
%		Dendrite & Input terminal  & $\sim$100     \\
%		Axon     & Output terminal & $\sim$10      \\
%		Soma     & Cell body       & up to $10^6$  \\
%		\bottomrule
%	\end{tabular}
%	\label{tab:table}
%\end{table}




\end{document}

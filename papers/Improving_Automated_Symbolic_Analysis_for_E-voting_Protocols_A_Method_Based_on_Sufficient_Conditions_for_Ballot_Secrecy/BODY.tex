\renewcommand{\refer}{\!\mapsto\!}

% LUCCA:
% Consider adding somewhere the citation cortier2017machine (machine-checked crypto proofs of Helios and variants).
% It required 1 full person-year to get the proof done (they sell it as modular that could be used for other variants though)
% while the proof only focus on the core protocol, assuming all channels secure !
% It has already been used by Cortier et al. to make the point that symbolic methods are
% important in this field as well.

\section{Introduction}
%%%%%%%%%%%%%%%%%%%%%% REVIEWS CCS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% TODO (takes comments below into account)
% > This paper is concerned with symbolic analysis. I am wondering how valuable such an analysis is in the context of e-voting. Some discussion would be useful. I would think that mostly the purpose would be to get a first assessments of the security of an e-voting system, and possibly find some attacks. Showing an e-voting system secure in a symbolic setting, probably doesn't say much about its (cryptographic) security.
% >> - Also: The paper should provide some basic motivation. Why are e-voting
% >   protocols important? Are any in use? Are there likely applications in
% >   the reasonably near future? Should we care greatly about ballot
% >   secrecy in the protocol (particularly smaller leaks) if voting is
% >   conducted using personal computers that are not very secure end
% >   points?
% >> Also: Lastly, why symbolic analysis and e-voting? What makes symbolic analysis suitable for this class of protocols? I really think the paper needs some serious work to properly motivate it and to justify many of the claims it makes.

%%%%%%%%%%%%%%%%%%%%%% RESPONSE CCS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Review: value of symbolic analysis?
% In general, symbolic proofs do not imply cryptographic proofs (in the
% classical model). However, we believe that no method can claim absolute
% security. At best, we can increase confidence by proving the absence of
% large classes of attacks. Symbolic analysis is in a sweet spot where
% this can be done quickly (thanks to automation) while providing strong
% enough guarantees whose corresponding classes of attacks it captures are
% well-understood. This approach is especially suitable for e-voting
% protocols that form complex systems. We see cryptographic proofs as a
% complementary approach that often focuses on smaller parts of systems.

% Stress the fact that all our models are available to reviewers and readers at [3]
% RC questions the motivations of analysing e-voting protocols. 
% Since we were short on space, we choose to drop this, but we are happy
% to reintroduce an explanatory paragraph and suitable pointers, and there
% are many existing works that discuss the motivation.  Very briefly, the
% motivation is the hope for more efficient, reliable and faster e-voting
% processes, not restricted to nation-wide elections but also for less
% critical applications. Furthermore, such systems are already in use in
% various contexts.


% RC also questions whether ballot secrecy would not be too strong (small
% leak may be acceptable).
% We strongly believe that ballot secrecy expresses the minimal privacy
% requirement we should expect for (privacy-preserving) elections. Small
% leaks are not acceptable as they can often be exploited to perform more
% critical attacks. E.g., in [16] it is shown that a small bias can be
% exploited to break voter privacy.


% Review: importance of threat model? honest voters performed by
% environment?
% To explain why threat models considering no dishonest voter is actually
% challenging we shall first reply to another RB's concern: "<<honest are
% played by the environment...>>. What? Honest voters are *never* played
% by the environment, right?".
% As classically done [10,26,21,20], corrupted actors do not necessarily
% have to be explicitly modelled since they can be played by the attacker
% (provided that all key material are given to him). For threat models
% considering unbounded number of dishonest voters, any honest voter is a
% special case of a dishonest voter. Therefore, one does not loose any
% behaviours when considering all honest and dishonest voters to be played
% by the attacker (except, obviously, the ones for which we swap votes).
% We will clarify this reasoning in the final version of the paper.
% Considering dishonest voters therefore simplifies the verification
% problem.
% Finally, we argue that the threat model is important. It's all about the
% property you want and the use case you consider. For example, take the
% IACR use case (Helios was used to elect board members), you may consider
% members honest and an attacker on the network who would like to break
% privacy. You may also consider a curious-but-cautious attacker who can
% vote (but following the rules) but still want to learn somebody else
% vote.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 


%%% CC: Commented out the below, probably too detailed here. Needs to go at the
%%% start of the conditions to provide intuition.
% I have an example (depiced in Figure~\ref{fig:ex-intro}) that could be used in the intro to illustrate: ballot-secrecy$=$ link id-vote;
% invisible links given to the attacker when using diff-equivalence, the three conditions.
% \begin{figure}[ht]
%   \centering
%     \includegraphics[width=1.1\textwidth]{./img/genericEx.png}
%   \caption{Generic Example}
%   \label{fig:ex-intro}
% \end{figure}

\toRM{Gray text: to be removed (comments or parts that we may remove). When removing
all grey texts (uncomment a line at the end of header\_com.tex then we obtain
13.5 pages.}

\toRM{Make sure it is clear that:
1. main contrib is extended scope; extended scope $=$ more protocols can be analysed $+$
already analysed protocols can be analyses more precisely, faithfully (\ie
more threat models)
2. theorem is very generic (any crypto primitives, proto in our large
class), but then conditions have to be verified so we inherit limitations
from those tools}

%\textbf{(Context)}
\looseness=-1
There have been substantial advances during the last years in the
field of e-voting protocols. Many new approaches have been developed,
and the relevant security properties have become better
understood and agreed upon~\cite{bernhard2015sok,cortier2016sok,cortier2013attacking,cortier2018voting}.
One of the main properties is that voters'
votes remain private, which is known as {\em ballot secrecy}. Designing
protocols that achieve this has proven subtle: many
vulnerabilities have been found in previously proposed
protocols~\cite{cortier2013attacking,KR-eurosp16},
motivating the need for improved analysis techniques to support the
development of e-voting systems. Unfortunately, the complexity of
e-voting systems makes {\em computational proofs} hard, e.g., the
computational proof of Helios from~\cite{cortier2017machine} required
one person-year. 

For classical security protocols, there is mature tool
support in the {\em symbolic model}~\cite{Tamarin,avantssar-tacas12,BlanchetCSFW01,Cr2008Scyther},
% (cite E.g., ProVerif, Scyther, Tamarin, Avantssar),
which enables detecting many
flaws during the protocol design phase, or later, as new threat models are
considered.
Verification in this more abstract model allows for a high level of automation.
This notably enables security analyses exploring various threat models in order to provide
more fine-grained guarantees (see \eg~\cite{basin2014know,basin2018formal,bhargavan2017verified}).
However, these tools traditionally did not handle e-voting
protocols~\cite{surveyJLAMP16}.
Recently, new symbolic methods have been proposed~\cite{vote-CSF08-maffei,vote-CSF16,vote-ESO16,dreier2017beyond,cortier2017type}
to analyse e-voting protocols. 
%While symbolic formal verification methods do not provide a computational
%guarantee, they
%have proven to be very effective because they can offer a high level of
%automation. 
However, the applicability of these methods is still extremely limited
both in the type of protocols that they can deal with and the type of security
properties (including threat models) that they analyse (as acknowledged by~\cite{vote-ijcar,vote-ESO16,surveyJLAMP16}).

%\textbf{(State of the art)}
The reasons for these limitations interact in a complex way
with existing approaches. One of the main reason though
is that ballot secrecy is a behavioural equivalence-based property which is
notoriously more difficult to analyse than the more classical reachability properties.
% , and
% (b) most proposed
% e-voting protocols use less standard primitives that are not covered by
% all tools.
% This naturally restricts the set of tools that can be applied,
% .
%
Two effective tools that can prove such equivalence properties for an unbounded number of sessions
are ProVerif~\cite{BlanchetCSFW01} and Tamarin~\cite{Tamarin}.
% \footnote{While Maude-NPA~\cite{santiago2014formal}
% also supports some equivalence properties, it currently rarely terminates in positive cases.}.
% COMMENT:
% - Proofs of e-voting in tamarin not really autoamtic (non-trivial typing lemmas) 
% - instead of explicitely swap votes at sync. barriers, Dreier et al. put voters in multisets, allowing Tamarin to
%   check if the equivalence holds for at least one swap. In the end, this is really close to the swapping
%   approach in ProVerif and thus suffer from the similar limitation. Notably, what happens in presence of dishonest voters
%   and authorities 'crossing phases' ? Then, one should allow a swap of authorities but 'unbounded swap' -> same problem...
% - use of primitives like blind signature is extremely limited, as soon, as one wants to consider dishonest voters,
%   then some open chains cannot be removed with typing lemmas (essentially, attacker can get sign on any number of blind
%   and I belive that no typing lemma can state that message attaker can thus learn cannot be coerced to nonces, keys, etc.)
These tools can deal with many typical primitives that are used in e-voting protocols~\cite{vote-CSF08-maffei,vote-CSF16,dreier2017beyond,basin2018alethea}.
% Recent results~\cite{dreier2017beyond} have enabled both
% these tools to deal with typical primitives
% that are used in e-voting protocols, such as zero knowledge proofs, 
% blind signatures, trapdoor commitments, designated verifier proofs~\cite{vote-CSF08-maffei,vote-CSF16,dreier2017beyond}.
  %
%ProVerif handles equivalence properties by checking for so-called
However, they check for an abstraction of equivalence (\ie~{\em
diff-equivalence}) that is rarely met by typical encodings of e-voting
protocols and ballot secrecy.  Thus, in most cases, the analysis
results in a \emph{spurious attack} (i.e., an attack that is an
artefact of the abstraction and not a real attack on the protocol), and
no conclusion can be drawn about the protocol.

Despite recent efforts to improve the accuracy of the equivalence being checked
(\eg, the swapping technique~\cite{vote-CSF16,dreier2017beyond} and the small-attack property~\cite{vote-ESO16}),
this still effectively limits the class of e-voting protocols and the threat models
to which existing tools can be successfully applied.
More precisely, 
we have identified the following limitations from analysing several case
studies and threat models:
\begin{itemize}
\item[(a)] Spurious attacks when {\em honest authorities are present in
	different phases} of the voting process.
%    gives rise to spurious attacks under many threat models.
For many threat models, this excludes modelling a registrar that distributes credentials
in a registration phase and then commits credentials of eligible voters
to the ballot box in a later phase, as in JCJ~\cite{juels2005coercion}
and Belenios~\cite{cortier2014election}.
%\lum{is it necessary to give examples here? I think it's clear we need those}
%    In practice, this happens \eg for JCJ and Belenios.    
    % This is needed for instance when a Registrar authority communicates
    % with voters in the registration phase and then commits
    % all created credentials to the tally in a later phase (\eg, JCJ and Belenios).

\item[(b)] Spurious attacks with ProVerif when ballot secrecy notably relies on the {\em freshness of some data coming from previous phases}.
    For example, such data can be credentials created during a registration
    phase, as in JCJ and Belenios.

  \item[(c)]
    Spurious attacks for threat models in which {\em no dishonest voter} is assumed
    (we will explain later why this is a more complex case than
    with dishonest voters that we handle as well).
    % Again, we encountered this limitation for JCJ and Belenios.
    % For example, this is often the case for credentials distributed during registration phase and used in later phases
    % (\eg, JCJ, Belenios, and for threat models of LEE).
  % \item Protocols in which {\em revoting} is allowed. \lum{we need to discuss revoting; not sure we can claim that}.
%

\item[(d)] The current techniques have {\em scalability issues} (for reasons explained later).
For instance, we were not able to obtain results in less than 2 days for the simple protocol LEE~\cite{DKR-jcs09}.
\end{itemize}
% \lum{\cas{Point (d) is a bit vague. I propose to make it a non-itemized
% paragraph and clarify.}}

%\textbf{(Scope, goal)}

%  \cam{The next paragraph doesn't belong here, because it is too
% 	 technical, and doesn't flow from the previous.}
%   E-Voting protocols share common features:
%   they are organised in different phases (\eg setup, registration, voting, tally);
%   they involve different roles (\eg voter, registar) and often use less standard primitives.
%   Intuitively, ballot secrecy holds when the attacker is never able to meaningfully relate a voter's identity
%   to a voter's vote. A meaningful relation means: the relation would not hold if voters were voting differently.
%   This is why ballot secrecy is an equivalence-based property: we change the way voters vote and see if the attacker
%   can observe any difference. Because of the presence of the tally, we actually swap votes (in order to get the same tally's outcome).
%   The attacker can try to establish such relations thanks to active, malicious behaviours, relying on different
%   sub-relations between messages (see example).
%   The problem we are interested in is the automatic, symbolic verification of ballot secrecy for eVoting protocols.
% \smallskip{}

\noindent
\textbf{\em Contributions.}
In this work, we advance the state-of-the art in automated
symbolic verification of ballot secrecy in e-voting protocols.
%
Our key idea is to soundly modularize ballot secrecy verification.
% Our approach established sufficient conditions for ballot
% secrecy that are each easier to analyse than directly the
% problem.
%
We develop three tight conditions on e-voting protocols
and prove that, together, they imply ballot secrecy. The three
conditions in our theorem are inspired by our analysis of the
different types of attacks on ballot secrecy.  Since each condition
focuses on one specific aspect of ballot secrecy, it is typically
simpler to analyse the combination of the three conditions than to verify
ballot secrecy directly, as was done in prior works.
%\lum{is ``sub-conditions  approach'' known? give ref?}
%\luccaN{We also provide an algorithm for automatically verifying all conditions.}
Our conditions and our analysis algorithm 
give rise to a new method to verify ballot secrecy, improving the
state of the art in several aspects.

%\item
First, our approach expands the class of protocols
and threat models that can be automatically analysed.
We notably address the limitations of the state-of-the-art (a-c) mentioned above.
% Notably, unlike prior
% 	work,
% we can deal with the following features:
% %\lum{Explanations on why it
% %  was not possible before goes to Section~\ref{sec:background}. I give
% %  essential ideas of such explanations there.}
%
As demonstrated by our case studies,
providing support for such features is essential for considering 
flexible threat models and for establishing more precise security
guarantees that also take important practical aspects of
protocols into account, such as authentication or registration phases,
which are often not considered in the literature.

  
\looseness=-1
Second, our approach can significantly improve verification efficiency (d).
  The increased efficiency can occur for two main reasons.
  First, because each of our conditions focus on one aspect of the problem and simplifies parts 
  not related to that aspect, it involves smaller processes that are
  typically easier to verify.
  Second, previous techniques such as the swapping technique suffer from an exponential blow up
  related to the number of processes in each phase.
  % \lum{Not sure this explanation on swaps and explosion
  %   can be understood at this point. Still, it might be important...}
  In practice, we typically observe a speedup of over two orders of magnitude
  and even cause the analysis to terminate in cases where it did not do
  so before.
  
%  For example, for the LEE protocol, .... 
% \item It brings new insights and a \textbf{better understanding} about the problem itself.
%   First, splitting up the problem into 3 conditions focusing each on a different aspect allows to clearly
%   identify those aspects as key ingredients of the problem.
%   Second, each of this condition and aspect identifies one design principle that should be ensured in order to avoid one of the three
%   pitfalls we pinned out corresponding to three generic classes of attacks.
% \lum{consider merging 4th into 1-2-3 to strengthen 3thd.}

  \looseness=-1
  Third, we use our approach to analyse several new case studies.
  Thanks to the flexibility and the large class of protocols we can deal with,
  we are able to analyse a multitude of different threat models allowing comprehensive
  comparisons.
%  This allows us to perform a full comparison of threat models for each case study.
  Moreover, thanks to the aforementioned advantages,
  our approach is able to systematically take the registration phase
  into account, whereas prior works often consider registrars as fully honest and not
  model them.
  We successfully automatically analysed the FOO, Lee, JCJ, and Belenios
  protocols with respect to various threat models.
  %\luccaN{(based on Helios).}
  We show that our theorem also applies to the Okamoto protocol.
  % Case studies: FOO, Okamoto (at least theorem applies), LEE, JCJ, Belenios.
  % Our analyses are novel and also illustrate
  % the previous points well: we are able to analyse more phases, more threat models
  % and the analysis is efficient.
%\end{enumerate}

%We compare our approach to related work in \Cref{sec:back:stateArt}
%and provide support for the above claims.
\looseness=-1
  We also revisit the state-of-the-art definition of ballot secrecy~\cite{KremerRyan2005,DKR-jcs09}
and propose a more accurate variant (\ie sound, with less spurious attacks) of ballot secrecy whose automated verification
does not rely on synchronisation barriers~\cite{KremerRyan2005,DKR-jcs09,vote-CSF16,dreier2017beyond,vote-ifip},
which was one of the cause of limitations (a) and (c).

While we present our work in the ProVerif framework, our results
are applicable beyond this specific tool. % and could be used with other tools or methods.
Indeed, our conditions and our Main Theorem are stated in a standard applied $\pi$-calculus framework.
We also believe that our conditions shed light on three crucial aspects that
e-voting protocols should enforce; thus improving our understanding of the complex notion
ballot secrecy.
Finally, the fact that our approach is effective for the analysis of
ballot secrecy also suggests that it may be possible to improve the analysis of other e-voting
requirements by adopting a similar strategy.
% \lucca{ maybe ? add a few words on the fact that each condition identifies one key, necessary ingredient
%   for ballot secrecy giving rise to a better understanding of this crucial notion and maybe guidelines/design principles.}
%   \cas{Maybe depending on space; and related to how well we explain it later.}
%
%
%\smallskip{}  


\noindent
\textbf{\em Outline.}
We first provide intuition for our approach in~\Cref{sec:intuition}.
In \Cref{sec:background}, we present the symbolic model we use to represent
protocols and security properties.
We then describe our framework in \Cref{sec:class}, notably defining
ballot secrecy and the class
of e-voting protocols that we deal with.
Next, we formally define our conditions and state our Main Theorem in \Cref{sec:conditions}.
We show the practicality of our approach in \Cref{sec:caseStudies} by explaining how to verify
our conditions and presenting case studies.
Finally, we discuss related work in \Cref{sec:back:stateArt} and conclude
in \Cref{sec:conclusion}.
%\smallskip{}

% \noindent
% % \textbf{\em For reviewers of the previous version of this paper.}
% % \looseness=-1
% % In~\cite{long}, Appendix A, we describe the main changes we made to this
% % paper based on earlier reviews and discussions with experts; this may
% % be useful to readers who reviewed the previous version of this paper.
% \textbf{\em For reviewers of the previous version of this paper.}
% In~\Cref{sec:app:reviews} we describe the main changes we made to this
% paper based on earlier reviews and discussions with experts; this may
% be useful to readers who reviewed the previous version of this paper.

\noindent
% \textbf{\em Extended version with Supplementary Material.}
% \cite{long} also contains supplementary materiel, notably
% full proofs, additional examples, and, further detail on case studies.
\textbf{\em Appendix with Supplementary Material.}
In~\Cref{subsec:term} -- \ref{ap:model:diff}, we describe the formal model in detail.
\Cref{sec:app:conditions} describes the conditions in detail, and
\Cref{sec:ap:proofs-thm} contains the full proofs.
Some further detail on case studies is described
in~\Cref{ap:caseStudies}, and~\Cref{sec:app:swapping}
and~\ref{sec:app:swaprestr} provides further
explanations and examples for the swapping technique.


% \textbf{(Outline)}
  % \begin{enumerate}
  % \item (Intro) Ideas from above
% \item (Background\slash Related Work)
%   high-level applied-pi in the ProVerif style;
%   full state of the art;
%   explanations on the problems of state of the art (mainly to support claims on our contrib from the intro).
% \item (Framework) class of eVoting protocols we deal with (phases, roles, tally, honest trace), definition of ballot secrecy (whole system,
% fairness assumption, def of ballot sec.). Some preliminaries definitions (annotated actions, ``follow an honest trace'').
% \item (Conditions)
%   \begin{itemize}
%   \item A. Let's Gear up: identity vs vote-leaking phases\slash names, Divide \& Conquer.
%   \item B. Dishonest condition
%   \item C. Rel-Honest condition
%   \item D. Tally condition
%   \item E. Main theorem \& proof sketchs
%   \end{itemize}
% \item (Case Studies) FOO, Okamoto (at least theorem applies), LEE, JCJ, Belenios ?, deSelect (?).
%   Benchmarks.
% \end{enumerate}


% \paragraph*{Old arguments (maybe still interesting things here, remove afterwards)}
% 
% \textbf{ (Problem \& State of the art (methods))}
%   We are left with ProVerif. Problem is ProVerif verifies a more fine-grained equivalence: diff-equivalence.
%   Diff equivalence can be seen as the behavioural equivalence notion \lucca{where attacker is given the structure of the
%     processes to be verified along the execution}. When using diff-equivalence, we thus give more relations since
%   the attacker can relate all actions coming from the same voter\slash authority.
%   In the case of ballot secrecy for eVoting protocols, this is a problem because the attacker can then almost always
%   relate id to vote using those new links. See example: the protocol features a registration phase (leaking the voter's identity)
%   followed by a voting phase (leaking the vote). If the attacker is given a relation between actions of Alice leaking its identity
%   in the first phase and actions of Alice leaking its vote in the second one, it can obviously link id to vote relying on this
%   new spurious relation.
%   This problem is well-known (Maffei CSF'08, Smyth CSF'16, Cortier ESORICS-16, \etc).
%   Ideas in the literature so far:
%   (i) modify the tool to allow swaps between phases and thus hiding the structural links (IFIPTM'08, formally proved and
%       introduced in the tool in CSF'16): they verified FOO, Okamoto, LEE for one threat model each time;
%   (ii) on a case-by-case basis, for simple protocol, it is sometimes possible to
%       ``encode the proof strategy in the biprocess'' (quote from Maffei CSF'08) (proof strategy=swaps making the whole think work):
%       they verified JCJ for a specific threat model without registration;
%   (iii) prove a small-attack property in order to only consider finite-scenario,
%   encode proof strategy into tally (Cortier ESORICS'16): verified Helios, Belenios and Prêt à voter without registration for one threat
%   model only each time.
% 
% \textbf{ (What need to be improved)}
%   (iii) typically does not take into account registration phase because before the tally, only one phase that should be
%   action-determinate;
%   moreover it does not scale well (JCJ without registration
%   is already too much) (because their focus was more on tally and revoting mechanisms);
%   (ii) is voting protocol-specific thus not systematic, does it work for other protocols at all?;
%   (i) cannot deal with arbitrary number of revotes (because constrained use of replication under phases);
%       state space explosion problem (compiler produces $\Pi_j (n_j!)$ processes where $n_i$ is the number of processes active at
%       phase $i$ (ex. 3 phases, $n_i=3$ lead to 216 processes to verify); ProVerif specific.
% 
% 
% \textbf{ (Contribution)}
% Our approach: instead of tweaking the tool and improving the notion of diff-equivalence it can verify
% or the way we model the protocol, we
% rather study the property to verify and how it can be enforced using simpler sub-conditions. We use known attacks
% to guide our research: by regrouping them into classes of attacks we are able to identify three main reasons
% for having privacy breaches corresponding to three kinds of links. 
% We then devise a condition per class of attacks checking the absence of corresponding links.
% Our main theorem states that all conditions together imply ballot secrecy.
% Each condition can be verified even using diff-equivalence and does not suffer from the
% above problem.
% The conditions we devised are a contribution in themselves as they well illustrate three different pitfalls
% that must be avoided for preserving voter's privacy. They also help to understand better the notion
% of ballot secrecy itself.


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:

\section{Intuition behind our approach}
\label{sec:intuition}

%\noindent
\paragraph{\textbf{Links \& Ballot Secrecy}}
% We now provide intuition for our underlying ideas and resulting conditions, for
% which we will formal arguments later in the paper.
% \lucca{I'm trying to explain the idea of links below and then give intuitions on problems of diff-equivalence
% in terms of links. I'm not very happy with the organization and level of details though :(}
% \cas{I tried to rewrite it a bit.}
Ballot secrecy boils down to ensuring that an attacker cannot establish a
meaningful link between a specific
voter and a specific vote (that this voter is willing to cast).
For instance, a naive example of such a link occurs when
a voter outputs a signed vote in the clear, explicitly linking
his vote to his identity.
However, in more realistic e-voting protocols, such links can be very
complex, possibly relying on long transitive chains
of different pieces of data from different outputs. For example,
if an attacker is able to link
a credential with the identity of the recipient voter during a registration
phase,
and then the voter anonymously sends
his vote along with the credential during a casting phase,
then the attacker may be able to link the vote to the voter.
% Secure protocols typically prevent establishing either the link between the
% credential and the identity or the link between the vote and the credential.

% \cas{I also rewrote the below, but it is a tricky argument to argue precisely. Maybe only
% for journal version?}
% \lucca{I think that, at some point in the paper and before Section 4, we need to
% make that point (\ie diff-equivalence not enough precise for ballot secrecy) and explain
% why (structural links given to the attacker almost systematically breaks diff-equi).
% Indeed, we builds on this problem when explaining our approach (\ie divide \& conquer).}
\looseness=-1 As noted before, diff-equivalence (as an under-approximation of behavioural
equivalence) is rarely appropriate to directly verify ballot secrecy~\cite{vote-CSF16,surveyJLAMP16}.
An underlying reason for this is that considering diff-equivalence gives the
attacker more additional structural links than when considering the intended
behavioural equivalence. This often leads to spurious attacks.
% negative results even for secure
% e-voting protocols, which manifest themselves as false attacks.
% In the previous example, diff-equivalence considers an attacker who always knows the sender of
% an output, making the link between the output of the registration phase
% with the one of the casting phase explicit, even for secure protocols.
%\smallskip{}


%\noindent
\paragraph{\textbf{Informal Presentation of the Conditions}}
We %systematically 
analysed typical attacks and the underlying links. We classified them
and identified three classes of links leading to privacy breaches.
% to devise our three sufficient conditions. In particular, we classify the attacks and
% identify the main reasons for privacy breaches, which turn out
% to be based on three kinds of links.
The purpose of each of our conditions is to guarantee the absence of links from the corresponding class.
% We then devise, for each attack class, a condition that guarantees that
% there is no link in the protocol that enables attacks from the class.
Our Main Theorem states that together, the three conditions suffice to
ensure ballot secrecy.
% \cam{At this point, ``link'' is not so clear to the reader yet. If we
% want the reader to understand the below, this notion needs
% explaining. What is a link? Between what things?}

\noindent
\textit{(Dishonest Condition)}
\looseness=-1
By adopting a malicious behaviour, the attacker may be able to link messages that would not be linkable in 
the intended, honest execution.
For instance, if the attacker sends tampered data to a voter, the
attacker may be able to later observe the tampered part in different
messages, and conclude that it comes from the same voter, which allows
the attacker to establish possibly harmful links.
% (similar to tainting
% data in the registration phase and exploiting this in the voting phase).
Our first condition essentially requires that a voting system is indistinguishable for the attacker from a voting system
in which at the beginning of each phase, all agents forget everything
about the past phases
and pretend that everything happened
as expected, \ie, as in an honest execution.
The previous example would violate the condition, because in the second system, the attacker
would not be able to observe the tainted data.
\luccaN{Interestingly, this condition is mostly a reachability property that does not suffer from
the lack of precision of diff-equivalence.}

\noindent
\textit{(Honest Relations Condition)}
Even in the expected honest execution, the attacker may be able to
exploit useful links. % an identity with a vote.
Thanks to the previous condition, 
we can focus on a system where each role is split into sub-roles for
each phase.
This allows us to verify the absence of the former relations using
diff-equivalence, without giving the attacker
spurious structural links, as mentioned above.

\noindent
\textit{(Tally Condition)}
We take into account the tally outcome, which enables establishing 
more links. Typically, the attacker may
link an identity to a vote if it can 
forge valid ballots related to (\ie, containing the same vote)
data that can be linked to an identity.
This introduces a bias in the tally outcome that can reveal 
the vote in the forged ballot.
This attack class strictly 
extends {\em ballot independence attacks}~\cite{cortier2013attacking}.
The Tally Condition requires that when a valid ballot was forged by the attacker
then it must have been forged without meaningfully using voter's data already
linked to an identity.
%\\[-2mm]
%\smallskip{}

\section{Model}
\label{sec:background}
\label{sec:background:model}

% \lucca{I re-used presentation from past papers (so I think rewordings are needed), adapt some parts and chose FOO
% as a running example.
% I'm sure we can save a lot of space by not formally defining some notions (\ie formal def of
% diff-equ can be moved to appendix, intuitions should suffice.
% }


We model security protocols using the standard process algebra in the style of the
dialect of Blanchet \emph{et al.}~\cite{BlanchetAbadiFournetJLAP08}
(used in the ProVerif tool),
that is inspired by the applied $\pi$-calculus~\cite{AbadiFournet2001}.
% and in particular which is used in the \proverif~tool.
Participants %in  a protocol 
are modelled as processes, and the
%communication between them is modeled by means of the
exchanged messages are modelled using a term algebra.

\looseness=-1
Since most of the e-voting protocols are structured in a sequence of {\em phases}
(\eg {\em registration phase}, {\em voting phase}, {\em tallying
phase}), our model includes explicit phases.
% % (\eg Okamoto,FOO, LEE, JCJ, Norwegian, sElect (CSF'16)).
% For example, each voter often starts a {\em registration phase} followed by a {\em voting phase}.
% When this is done, a {\em counting} or {\em tallying} phase occurs producing the
% result of the voting process.
% %Finally, a {\em verification phase} allows voters to ensure their votes have been taken into account.
% Hence, the notion of phase is a central feature in e-voting protocols
% and we thus consider a symbolic model featuring phases.
We briefly present this model in this section; a detailed presentation can be found
in Appendix~\ref{sec:app:model}.

%%
%% Term algebra
%%

\paragraph{\textbf{Term algebra}}
\label{subsec:term}
We use a term algebra to model messages
built and manipulated using various cryptographic primitives.
We assume an infinite set $\N$ of \emph{names}, used to represent
keys and nonces; and two infinite and disjoint sets of \emph{variables}
$\X$ (to refer to unknown parts of messages expected
by participants) and $\W$ (called {\em handles}, used to store messages learned by the attacker).
%  Variables in~$\X$ are used to
% refer to unknown parts of messages expected by participants,
% while variables in~$\W$ \luccaN{(called {\em handles})}
% are used to store messages learned by the 
% attacker.
%
We consider a \emph{signature}~$\Sigma$ (\ie a set of function
symbols with their arity). $\Sigma$ is the union
of two disjoint sets:
the \emph{constructor} $\Sigma_c$ and \emph{destructor} $\Sigma_d$ symbols.
% , \ie, $\Sigma =
% \Sigma_c \cup \Sigma_d$.
%
Given a signature $\mathcal{F}$, and a set of atoms 
$\mathsf{A}$, we denote by $\T(\mathcal{F},\mathsf{A})$ the set of terms built
using atoms from $\mathsf{A}$ and function symbols from $\mathcal{F}$.
% A {\em constructor term} is a term in $\T(\Sigma_c, \N \cup \X)$.
% We denote by $\vars(u)$ the set of variables that occur in a term $u$
The terms in $\T(\Sigma_c, \N)$ are called {\em messages}.
% terms that are \emph{ground} (\ie, $\vars(u) = \emptyset$).
Sequences of elements are shown bold (\eg $\vect{x},\vect{n}$).
% We denote by $\vect x$, $\vect n$, $\vect u$ a
% (possibly empty) sequence of variables, names, and terms respectively.
The application of a substitution $\sigma$ to a term $u$ is written
$u\sigma$, and $\dom(\sigma)$ denotes its \emph{domain}.
% {The \emph{positions} of a term are defined as usual.}

As in the process calculus presented in~\cite{BlanchetAbadiFournetJLAP08}, 
messages are subject to an equational theory
used for
%this has proved very useful
for modelling algebraic properties of cryptographic primitives.
%(see \emph{e.g.}~\cite{CDL05-survey} for a survey).
Formally, we consider a congruence~$\theo$ on $\T(\Sigma_c,\N \cup \X)$,
generated from a set of equations $\E$ over $\T(\Sigma_c,\X)$.
%Thus, $\theo$ is closed  under substitutions and bijective renaming.
We say that a function symbol is {\em free} when it does not occur
in $\E$.
We assume the existence of a \emph{computation relation}
$\redc : \T(\Sigma,\N)\times\T(\Sigma_c,\N)$
that gives a meaning to destructor symbols.
In \Cref{sec:app:comp}
we describe how this relation can be obtained from \emph{rewriting systems} and
give a full example.
%  such that
% for any term $t$, $(t\redc u\iff t\redc u')$ if, and only if, $u\theo u'$.
%
For modelling purposes, we also split the signature $\Sigma$ into two
parts, namely $\Sigma_\pub$ (public function symbols, known
by the attacker) and $\Sigma_\priv$ (private function symbols).
%We let be all the symbols from our running example be in $\Sigma_\pub$.
An attacker builds his own messages by applying public function symbols to
terms he already knows and that are available through variables
in~$\W$. Formally, a computation done by the attacker is a
\emph{recipe} (noted $R$), \ie, a term in $\T(\Sigma_\pub,\W)$.
%Recipes will be denoted by $R$, $M$, $N$.
% Note that although we do not give the attacker the ability to generate
% fresh names to use in recipes, we obtain essentially the same capability
% by assuming an infinite supply of public constants in
% $\Sigma_c \cap \Sigma_\pub$.
%

\begin{example}
\label{ex:term}
Consider the signature\\[0.0mm]
\null\hfill
$\begin{array}{rl}
   \Sigma_c =& \{\eq,\; \langle \, \rangle,\; \sign,\;\pkv,\; \bl,\;\unbl,\;\com,\; \ok\}\\
   \Sigma_d =& \{\versign,\;\open,\; \projl, \; \projr, \; \eq\}.
 \end{array}$
\hfill\null\\
The symbols $\eq,\langle\rangle, \sign,\versign,\bl,\unbl,\com$ and
	$\open$ have
arity 2 and represent equality test, pairing, signature, signature verification, blind signature, unblind, commitment and
commitment opening. % Pairing is modelled using $\langle \rangle$ of arity 2,
The symbols $\projl,\projr$ and $\pkv$ have arity 1 and represent projections
	and the agents' verification keys.
% Projection functions are denoted $\projl$ and $\projr$, both of arity 1.
Finally, $\ok$ is a constant symbol (\ie arity 0).
% we consider the symbol $\eq$ of arity 2 to model
% equality tests, as well as the constant symbol $\ok$.
% This signature is
% split into two parts: $\Sigma_d = \{\versign,\;\open,\;\projl, \; \projr, \; \eq\}$
% and $\Sigma_c = \Sigma\slash\Sigma_d$.
% $
% \Sigma_c = \{\sign,\;\pkv,\;\bl,\;\unbl,\;\com,\;\langle \, \rangle, \;\ok\}$ and
% $\Sigma_d = \{\versign,\;\open,\;\projl, \; \projr, \; \eq\}$.
%
To reflect the algebraic properties of the blind signature, we may
consider $\theo$ generated by the following equations:\\[0.5mm]
\null\hfill$
\begin{array}{rcl}
\unbl(\sign(\bl(x_m,y),z_k),y) &=& \sign(x_m,z_k)\\
\unbl(\bl(x_m,y),y) &=& x_m. \\
\end{array}$\hfill\null\\[0mm]
%
%
%Pursuing Example \ref{ex:signature}, 
\looseness=-1
Symbols in $\Sigma_d$ 
can be given a semantics through the following rewriting rules: %\\[-1mm]
% \null\hfill
% $\begin{array}{c}
$\versign(\sign(x_m,z_k),\pkv(z_k)) \! \to\! x_m$, 
$\open(\com(x_m,y),y)\! \to\! x_m, 
%\;\;\;
\proj_i(\langle x_1,x_2\rangle) \to x_i,\linebreak[4]  %\\
\eq(x,x) \!\to\! \ok$.
     %
     %      
     %      \linebreak[4]
% \ \;\;\;
% \end{array}$
% \hfill\null
% The straightforward computation relation one obtains from them
% satisfies for instance:
% $\open(
%   \versign( 
%     t,
%      \pkv(\mathrm{sk_A})
%   ),
%   k_c)\redc v
% $
% where $t=     \unbl(
%         \sign(
%            \bl(
%               \com(v,k_c),
%                k_b
%            ),
%            \mathrm{sk_A}
%         ),
%         k_b)
%      )$
% because 
% $t\theo \sign(\com(v,k_c),\mathrm{sk_A}).$
\end{example}


%%
%% Process algebra
%%
 \begin{figure}[t]
   \null\hfill$
%   $\scalemath{0.8}{
  \begin{array}{rclcl}
    P,Q &:=&  0 & & \mbox{null}\\[0.5mm]
    &\mid & \In(c, x).P && \mbox{input}\\[0.5mm]
    &\mid&\Out(c, u).P &&\mbox{output} \\[0.5mm]
    &\mid& \Let \; x = v \;\In \; P \; \Else \; Q&&
    \mbox{evaluation}\\[0.5mm]
    &\; \mid \; & P \mid Q&&\mbox{parallel}\\[0.5mm]
    &\mid& \new n. P && \mbox{restriction} \\[0.5mm]
    &\mid&  !P && \mbox{replication} \\[0.5mm]
    &\mid&  \phase{i} P && \mbox{phase} \\[0.5mm]
  \end{array} 
%}
$\hfill\null\\
  \begin{small}
    where $c \in \Ch$, $x \in \X$, $n \in \N$,
    $u \in \T(\Sigma_c, \N \cup \X)$, $i\in\mathbb{N}$, and
    $v\in\T(\Sigma, \N\cup\X)$.
  \end{small}
\vspace{-5pt}
  \caption{Syntax of processes}
 \label{fig:syntax}
 \end{figure}

\paragraph{\textbf{Process algebra}}
%%% START: interesting discussion about sync. barriers
% For some phases, a public deadline is announced allowing all agents to terminate properly
% what they need to do during that phase before the new one starts. Such phases shall be
% modeled using {\em synchronisation barriers}. With such barriers, a new phase cannot start
% while any agent is still executing the previous phase.
% Voting phases are often of this kind. We come back to this modeling choice 
% in Section~\ref{sec:condi:tools}.\cam{Reference of ``this modeling
% 	choice'' not completely clear.}
% In the following, we use {\em phase} to refer to {\em synchronisation barrriers}.
%%%% END

We assume $\Ch_\pub$ and $\Ch_\priv$ are disjoint sets of public and private channel
names and note $\Ch=\Ch_\pub\cup\Ch_\priv$. % as the set of all channel names.
Protocols are specified using the syntax
in Figure~\ref{fig:syntax}.
%
% \lu{\footnotesize
% Concernant sequential replication: dans la litérature, recursive process veut dire $\mathrm{rec}X.P$ avec $X\in P$.
% Et on a une règle d'unfold. Ce n'est pas le comportement que l'on veut ici, sauf si on remplace TOUS les $0$ de $P$ par des $X$
% pour que ``quand on a fini d'exécuter une copie de $P$ par n'importe quel moyen, une nouvelle copie de $P$ apparait.''. Quand je
% googlise ``sequential replication'', je trouve un article TGC'2012 de Lili Xu qui introduit une notion très similaire.
% \normalsize}
%
Most of the constructions are standard.
The construct  $\Let \; x = v \;\In \;P \; \Else \; Q$
tries to evaluate the term $v$ and in case of success, 
\ie when $v \redc u$ for some message $u$, the process $P$ 
in which $x$ is substituted by~$u$ is executed;
otherwise the process $Q$ is executed.
Note also that the $\Let$ instruction together with the
$\eq$ theory (see Example~\ref{ex:term}) can encode the usual
conditional construction.
% Indeed, the process $\Let \;x = \eq(u,v) \;\In
% \; P \; \Else \; Q$  executes~$P$ only if the computation succeeds
% on $\eq(u,v)$, that is only if $u\redc u'$, $v\redc v'$, and $u' \theo v'$ for some
% messages $u'$ and $v'$.
% We note that $\If\;u=v\;\Then\; P\; \Else\; Q$ is such a process.
The replication $!P$ behaves like an infinite parallel composition
$P|P|P|\ldots$.
The construct $\phase{i} P$ indicates that the process
$P$ may only be executed when the current phase is $i$.
%
% We can't define sync. phase for replicated processes (see ex. below
% so we just define simple 'phases'.
% [ phase1. ! phase2.out(ok) ]
% never can go to phase2 because always a [ ! phase2.out(ok) ]
%
The construct $\nu n.P$ allows to create a new, fresh name $n$;
it binds $n$ in $P$ which is subject to $\alpha$-renaming.
For a sequence of names $\vect{n}$, we may note $\nu\vect{n}.P$
to denote the sequence of creation of names in $\vect{n}$ followed by $P$.
For brevity, we sometimes omit ``$\Else\;0$''
and null processes at the end of processes.
% We write~$\fv(P)$ for %and $\bv(P)$,
% the set of \emph{free variables} of~$P$, \ie the set
% of variables that are not in the scope of an input or a $\Let$
% construct.
A process $P$ is {\em ground} if it has no free variable 
(\ie, a variable not in the scope of an input or a $\Let$ construct).
%$\fv(P) = \emptyset$.
A process is {\em guarded} if it is of the form $\phase{i} P$.


\looseness=-1
The operational semantics of processes is given by a labelled transition
system over \emph{configurations} (denoted by $K$) $(\p;\phi;i$)
made of a multiset $\p$ of guarded ground processes,
$i\in\mathbb{N}$ the current phase, and
a {\em frame} $\phi = \{w_j \refer u_j\}_{j\in\C J}$
(\ie a substitution where $\forall j\in\C J, w_j\in\W,\ u_j\in\T(\Sigma_c,\N)$).
The frame~$\phi$ represents the messages known to the attacker.
Given a configuration~$K$, $\phi(K)$ denotes its frame.
We often write $P \cup \p$  instead of $\{P\} \cup \p$
and implicitly remove null processes from configurations.
% Sometimes, we consider processes as configurations, in such cases, the corresponding
% frame is~$\emptyset$.

%We first give an example before explaining the transition rules of the system.
\renewcommand{\key}{\mathsf{key}}


\input{semantics}
%%
%% Semantics
%%
The operational semantics of a process 
is given by the relation
$\lrstep{\alpha}$
%\lum{note: semantics is closed to the one in Esorcis'16}
defined as the least relation over configurations satisfying the rules
in Figure~\ref{fig:semantics}.
%
For all constructs, phases are just handed over to continuation processes.
% Except for the phases,
The rules are quite standard and correspond to the
intuitive meaning of the syntax given above. %in the previous section. 
\toRM{The first rule \textsc{In} % ($\inc$)
allows the attacker to send a message on a public channel as long as it is
the result of a computation done by applying a recipe to
%public function symbols on messages that are in
his current knowledge.
The second rule \textsc{Out} corresponds to the output of a term on a public channel:
the corresponding term is added to the frame
of the current configuration.
% which means that the attacker gains access to it.
The rule \textsc{Com} corresponds to an internal communication on a private channel
that the attacker cannot eavesdrop on nor tamper with.
% The fourth and fifth rules correspond to term evaluation.
% The next three rules allow one to execute a restriction, 
% unfold a replication, and  split a parallel composition.
Finally, the rule \textsc{Phase} allows a process to progress 
to its next phase
and the rule \textsc{Next} allows to drop the current phase and
progress irreversibly to a greater phase.}
%% Proposition:
% Intuitively, when \textsc{Next} is triggered to move to a phase $j$,
% only processes of the form $\phase j Q$ can execute actions. If possible,
% \textsc{Phase} can be used to make processes progress until reaching phase $j$.
% \cam{Can we give intuition how \textsc{Phase} and \textsc{Next} together model
% he right thing?}
%
The rules \textsc{In,Out,Next} are the only rules that produce observable
actions (\ie, non $\tau$-actions).
% \toRM{However, for reasons that will become clear
% later on (notably for \Cref{def:honest-trace}),
% we make a distinction when a process evolves using $\textsc{Let}$ or
% $\textsc{Let-Fail}$.}
%
The relation $\lrstep{\alpha_1 \ldots \alpha_n}$ between
configurations (where~$\alpha_i$ are actions) 
is defined as the transitive closure of~$\lrstep{\alpha}$. 

%%%%%%%%%% [DONE]:
% Review: Semantics of '!'? How can Registrar act in two phases?
% First, note that processes which can "never be completed" do not block
% the progression but are simply discarded by the configuration when
% moving to next phases.
% Next, the Registrar example from actually occurs when modelling JCJ with
% registration. This is simply done by defining a process of the following
% form (see [3] for exact ProVerif models for JCJ):
% `Registrar = ! (1:Registrar_1; 2:Registrar_2)`.
% At phase 1, all necessary sessions of Registrar can be created producing
% processes `1:Registrar_1; 2:Registrar_2`. Some of them may be executed
% leading to processes of the form `1:2:Registrar_2`. Just before the
% configuration moves to phase 2 (rule Next for j=2), all those processes
% can also move (rule Phase) resulting in `2:Registrar_2`.
% Remark that he fact that all sessions must be anticipated in phase 1 is
% unproblematic because of the forall-there-exists structure of trace
% equivalence.
%%%% >>> Semantics of '!'" is clear to me know. Again, a detailed example would have been helpful.
%%% [DONE]:
% RB is concerned with our modelling choice of our phase.
% Our modelling of phases (called stages or weak phase in the literature
% [9, 20]) is actually standard and reflect phases as implemented in the
% tool ProVerif. Hence, we exactly followed [28] and are very close to
% [9,6,20].
% <!-- (the only difference being that we used ProVerif dialect instead of proper applied-pi calculus). -->

\begin{example}
\label{ex:execution}
We use the FOO protocol~\cite{fujioka1992practical}
(modelled as in~\cite{vote-CSF16})
 as a running example.
FOO involves voters and a registrar role.
In the first phase, a voter commits and then blinds its vote and
sends this blinded commit signed with his own signing key $\key(\id)$
to the registrar.
The function symbol $\key(\cdot)$ is a free
private function symbol associating a secret key to each identity.
The registrar then blindly signs the committed vote
with his own signing key $k_R\in\Sigma_c\cap\Sigma_\priv$ and sends
this to the voter.
In the voting phase, voters anonymously output their committed
vote signed by the registrar and, on request, anonymously send
the opening for their committed vote.
The process corresponding to a voter session
(depending on some constants
$\id, v$) is depicted below, where $c\in\Ch_\pub$,
$M = \com(v,k)$, 
$ e = \bl(M,k')$ and
$s=\sign(e,\key(\id))$:\\[0.5mm]
\null\hfill
$
	\begin{array}[h]{r@{$\;$}c@{$\;$}lr}
    V(\id,v) &=&\phase{1}
                 \new k.\new k'.\Out(c, \langle \pk(\key(\id)); s\rangle). 
              \In(c, x). \\   %&\text{expected: } \sign(e,k_R)\\    
             && \If\, \versign(x,\pk(k_R))=e &\\
             && \Then\, \phase{2} \Out(c,\unbl(x,k')). 
%               &\\  && 
             \In(c, y). \\   %&\text{expected: } \langle \_;M\rangle\\    
             && \If\, y=\langle y_1 ; M\rangle \\
             && \Then\;\Out(c,\pair{y_1}{\pair{M}{k}}) &\\
  \end{array}
  $\hfill\null\\
% The first three equations should be understood as syntactic sugar, to write processes in a more compact way.
A configuration corresponding to a voter $A$ ready to vote $v_1$
with an environment knowing the registrar's key is
$K_1=(\{V(A,v_1)\};\{w_R\refer k_R\};1)$.
It notably has an execution
%configuration $K_1$:
$K_1\sint{\tr_h}(\emptyset;\phi;2)$, where:\\[0.0mm]
\null
\hfill
$
\begin{array}{rl}
\tr_h= & \tau.\tau.\Out(c,w_1).\In(c,R).\taut.\tau.\Phase{2}. \\
       & \Out(c,w_2).\In(c,\pair{C}{w_2}).\taut.\Out(c,w_3)  \\
\end{array}
$\hfill
\null\\[0.0mm]
and where $C$ is any constant in $\Sigma_c\cap\Sigma_\pub$,
$\phi=\{
w_R\refer k_R,
w_1\refer\pair{\pk(k_\id)}{s}, 
w_2\refer \sign(M,k_R), 
w_3\refer \langle n; M; k\rangle
\}$,
$s,M$ are as specified above and
$R=\sign(\versign(\projr(w_1), \projl(w_1)),w_R)$.
This corresponds to a normal, expected execution of one protocol
session.
\end{example}


\paragraph{\textbf{Discussion on Phases}}
\label{subsec:discu-phase}
Our notion of phases, also known as {\em stages} or {\em weak
phase}~\cite{vote-ifip,BlanchetAbadiFournetJLAP08},
faithfully model the notion of phases with deadlines in the context of e-voting protocols.
Once the deadline of a phase $i$ has passed (\ie the action $\mathtt{phase}(j)$ has been triggered for
$j>i$) then, no remaining actions from phase $i$ can be executed. It also can be modelled in ProVerif
(see~\cite{BlanchetAbadiFournetJLAP08,PVmanual,vote-ifip,vote-CSF08-maffei}).
Note that in the literature, phases are often modelled with {\em synchronisation barriers}~\cite{vote-ifip,vote-CSF16}
(also called {\em strong phases}). The latter are a much
stronger notion of phases that require all initial processes to reach
the next phase before the system can progress to the next phase (i.e.,
no processes can be dropped). In our view, synchronisation barriers
model phases in e-voting protocols less faithfully than our (weak)
phases, and come with limitations that we discuss in
\Cref{sec:frame:ballotsec}.
We note that {\em stages} can be combined with replication without restriction
while {\em strong phases} cannot be put under replication~\cite{PVmanual,vote-CSF16}.

%%
%% Trace equivalence
%%
\paragraph{\textbf{Trace equivalence}}
\label{subsec:trace-equiv}
\looseness=-1
Trace equivalence is commonly used~\cite{surveyJLAMP16}
 to express many privacy-type properties such as ballot secrecy.
 Intuitively, two configurations are trace equivalent if an attacker
 cannot tell whether he is interacting with one or the other.
 % Before formally defining this notion, we first introduce
 Such a definition is based on a notion of indistinguishability
 between  frames, called \emph{static equivalence}.
 Intuitively, two frames are statically equivalent,
% (\ie an attacker cannot distinguish them),
 if there is no computation (nor equality test) that succeeds in
 one frame and fails in the other one.
% ~$\phi$ and fails in~$\phi'$ (and the converse).
Then, \emph{trace equivalence} is the active counterpart
% of static equivalence 
taking into account the fact that the attacker may
interfere during the execution of the process in order to distinguish
between the two situations.
We define $\obs(\tr)$ to be the subsequence of $\tr$
obtained by erasing all the $\tau,\taut,\taue$ actions.
Intuitively, trace equivalence holds when any execution of one
configuration can be mimicked by an execution of the other configuration
having same observable actions and leading to statically equivalent frames.
We give a formal definition 
in \Cref{ap:model:eint}.

\begin{example}%[Continuing Example~\ref{ex:process}]
\label{ex:eint}
Consider the frame $\phi$ from Example~\ref{ex:execution}.
The fact that the attacker cannot {\em statically} distinguish the
resulting frame from a frame obtained after the same execution
but starting with $V(A,v_2)$ instead of $V(A,v_1)$ is modelled by the following
static equivalence:
$\phi\estat^? \phi'$ where $\phi'=\phi \{v_1\refer v_2\}$
% \ie the frame one obtains from $\phi$ by replacing the constant
%  $v_1$ by the constant $v_2$ 
% \lumF{can be compress here}
which in fact does not hold (see witness given in
Appendix~\ref{sec:app:comp}).
Consider $K_i=(\{V(A,v_i)\};\{w_R\refer k_R\};1)$ for $i\in\{1,2\}$.
% Consider now, $K_2=(\{V(A,v_2)\};\{w_R\refer k_R\};1)$.
We may be interested whether $K_1\eint^? K_2$.
This equivalence does not hold because there is only
one execution starting with $K_1$ (resp. $K_2$) following the trace $\obs(tr_h)$ (see Example~\ref{ex:execution})
and the resulting frame is $\phi$
(resp. $\phi'$).
But, as shown above, $\phi\not\estat \phi'$.
% [DONE]: We agree with RB about the property naming in Example 2.3.
Therefore, $K_1\not\eint K_2$. However, ballot secrecy is not defined
by such an equivalence % defined differently
(see \Cref{sec:frame:ballotsec}) and we will see that
the FOO protocol actually satisfies it.
\end{example}


\paragraph{\textbf{Diff-Equivalence}}
Trace equivalence is hard to verify, in particular because of its
forall-exists structure: for any execution on one side, one has to find
a matching execution on the other side.
One approach is to consider
under-approximations of trace equivalence by over-approximating the 
attacker's capabilities.
% \cam{Confused here: surely we need a property that \emph{implies} trace
% equivalence - so I guess diff-equivalence, in that sense, over-approximates
% trace equivalence?}
%% True, I saw thos equivalence as formal (mathematical) relations (configurations x configurations)
% in that sense, diff-equivalence \subseteq trace equivalence. But your view's better.
\emph{Diff-equivalence} is such an under-approximation. It
was originally introduced to enable \proverif to analyse some form of
behavioural equivalence, and was later also implemented in \tamarin
and Maude-NPA.

Such a notion is defined on bi-processes, which are pairs of processes
with the same structure that only differ in the terms
they use.
The syntax is similar to above,
but each term $u$ has to be replaced by
a bi-term written $\choice{u_1}{u_2}$ (using \proverif syntax).
Given a bi-process $P$, the process $\fst(P)$ is obtained by replacing
all occurrences of $\choice{u_1}{u_2}$ with $u_1$; similarly with $\snd(P)$.
% is obtained by replacing $\choice{u_1}{u_2}$ with $u_2$.
% These notations are also used for bi-frames.
%
The semantics of bi-processes is defined as expected via a relation
that expresses when  and how a bi-configuration may evolve.
A bi-process reduces if, and only if,
both sides of the bi-process 
reduce in the same way triggering the same rule: \eg,
a conditional has to be evaluated in the same way on both sides.
%(see the formal rule in \Cref{ap:model:diff}).
%See \Cref{ap:model:diff} for an example of rule.
% When the two sides of the bi-process reduce in different ways,
% the bi-process blocks.
The relation $\sint{\tr}_{\mathsf{bi}}$
on bi-processes is therefore defined as for processes.
Finally, diff-equivalence of a biprocess intuitively holds
when for any execution, the
resulting frames on both sides are statically equivalent and
resulting configurations  on both sides are able to perform the same kind of actions.
A formal definition is given in~\Cref{ap:model:diff}.



As expected, this notion of diff-equivalence is stronger than
trace equivalence.
It may be the case that the 
two sides of the bi-process reduce in different
ways (\eg, taking two different branches in a conditional) but still
produce the same observable actions.
Phrased differently: diff-equivalence gives the attacker the ability to
see not only
the observable actions, but also the processes' structures.
% \lum{we may need to define vote-privacy first to make that point (\ie
% \Cref{sec:back:stateArt})}
This strong notion of diff-equivalence is sufficient to establish 
some properties % such as strong secrecy and anonymity.
but is too strong to be useful for
establishing ballot secrecy off-the-shelf
(we discuss this at greater length in Section~\ref{sec:back:stateArt}).



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:

\section{Framework}
\label{sec:class}

\looseness=-1
In this section we present our framework that we need to establish our
results, including definitions for
e-voting protocols and ballot secrecy.
%\smallskip{}

\paragraph{\textbf{Preliminaries}}
We first define {\em symbolic traces} which are traces
whose recipes are symbolic; \ie, they are from $\T(\Sigma_\pub,\W\cup\xi)$,
where $\xi$ is a new set of second-order variables.
Intuitively, a symbolic recipe is a partial computation
containing unknown parts symbolised by second-order variables.
Symbolic traces represent attacker behaviours with non-fully specified
recipes.
A symbolic trace can be instantiated to a concrete trace by replacing
the second-order variables by recipes (\ie, in $\T(\Sigma_\pub,\W)$).
To an honest trace $\th$, we associate a distinguished instantiation
called the {\em idealised trace of $\th$} 
%We now consider the trace $\tr^h$ built
that can be obtained from $\th$ by replacing each variable $Y\in\xi$ by a fixed free, public
constant $C_Y$ that we add to $\Sigma_c\cap\Sigma_\pub$.
%of the honest trace

\begin{example}[Resuming Example~\ref{ex:execution}]
\label{ex:symbolic}
The recipe of the last input of $\tr_h$
$\pair{C}{w_2}$ % the constant $C$
        could be replaced
% by any recipe without altering the subsequent execution. We may
% 	therefore use
        by the symbolic recipe
$\pair{X}{w_2}$ with $X\in\xi$
(\ie, reflecting that the choice of $C$ is unimportant) resulting
in a symbolic trace $\th$.
% : the choice of the recipe
% to replace $X$ with is unimportant.
  The idealised trace is $\th\{X\mapsto C_X\}$, where $C_X\in\Sigma_c\cap\Sigma_{\pub}$.
% \begin{example}[Continuing Example~\ref{ex:foo-ht}]
%   \label{ex:foo-ideal}
% \end{example}
\end{example}



\subsection{Class of e-voting protocols}
\label{sec:class:proto}
\looseness=-1
We explain in this section how we model e-voting protocols and the
considered scenarios.  Essentially, we may consider an arbitrary
number of honest voters plus all necessary authorities (\eg, ballot box,
registrar, tally),
which can perform an unbounded number of sessions.
Depending on the threat model, we also consider an arbitrary number of dishonest voters.
We use {\em role} to refer to a specific role of the protocol, such as voter, authority, \etc
Together, the agents performing the roles are able to produce a public bulletin board of ballots from which the
tally computes the final result (\ie, multisets of accepted votes).

First, the protocol should specify a fixed finite set of possible votes
as a set of free, public constants
$\mathcal{V}$
% , which is a set of public constants
(\eg, $\mathcal{V}=\{\mathtt{yes},\mathtt{no}\}$ for a referendum).
We also distinguish a specific free, public constant $\bot$
modelling the result of an invalid ballot.
% We require constants in $\V\cup\{\bot\}$ to be {\em free} (\ie they no dot appear in $\E$).


\paragraph{\textbf{Roles}}
E-voting protocols specify a process for each honest role
(in particular, the voter role).
Dishonest roles can be left unspecified because they will be played by
the environment.
Those processes may use \eg phases, private data, private channels
%but no internal communication (should be modeled using other channels, see threat model)
but no replication nor parallel composition, as a role specifies how a {\em single} agent behaves during
{\em one} session.
%(we will put ourself replications for modeling unbounded many sessions of each role).

\begin{definition}
\label{def:roles}
An honest role is specified by a process of the form
$\phase{i} \nu\vect{n}.A$, where $A$ is a process without parallel composition, replication
nor creation of names. %(\ie $\nu$-construct).
There should be at least a process for the voter role and one for the ballot box role (noted $A_b$).
Moreover, for the specific case of voter role, the corresponding process
noted $V(\id,v)$ should be parameterized by $\id$ (modelling an identity) and $v$ (modelling
the vote this voter is willing to cast).
Finally, initial attacker's knowledge is specified through a frame $\phi_0$.
\end{definition}
% \cam{Can we replace
%   ``authority'' here by ``role''? If not, what is the difference?
%   Is it ``honest role that outputs the result?''.
% \lucca{Ok, I'll stick with roles. No I didn't mean ``Is it [...]''}}

\noindent
% There should be at least two honest roles:
% the voter role and the bulletin board box role whose
\looseness=-1
The process $A_b$
shall contain (at least) one output on the distinguished public channel $c_b\in\Ch_\pub$.
Intuitively, each session of the ballot box processes input data
and may output a ballot on channel $c_b$
(this may depend on private checks).
We eventually define the bulletin board itself as the set of messages
output on channel $c_b$.
%
W.l.o.g., we assume that role processes do not feature creation of names,
since one can always create the required names at the top level.
% to the
% beginning.
 % (remember that $A$ does not feature replication).

In threat models with dishonest
voters, honest voters
% (except the two distinguished ones whose votes
% will be swapped)
are played by the environment and we let $\roles_V=\emptyset$.
If the considered threat model does not consider dishonest voters, then 
% \cam{the \emph{remaining} honest voters? (but we define voters $A$ and $B$ later only)}
the honest voters cannot be played by the environment.
For such threat models, we model  honest voters explicitly using the following set of processes:
$\roles_V=\{\nu\id.\; \nu\vect n\; V(\id,v)\ |\ v\in\mathcal{V}\}$,
where $\vect{n}$ are all the free names in $V(\id,v)$.
% \lum{comment on this in source}
% \lum{Note that, in such cases, it makes sense to make the input channel of the ballot box private
% in order to forbid the attacker to cast ballots.}
We write $\roles_o$ for the set of all processes of honest roles
except the voter role and let $\roles$ be the set
%, but including processes
$\roles_V\cup\roles_o$.
% be the same set but excluding $\roles_V$.

\begin{example}
\label{ex:foo-role}
\looseness=-1
The process $V(v,\id)$ defined in Example~\ref{ex:execution}
is the voter role one could define for the FOO protocol.
We consider the ballot box as untrusted, and we
therefore model it by the process
$A_b=\phase{2}\In(u,x).\Out(c_b,x)$, where $u\in\Ch_\pub$. % is a public channel.
In contrast, we leave the registrar unspecified for the moment
because we consider it corrupted and thus played by the
environment.% We thus consider $\sk_R$ as a public key.
We thus have $\roles_V=\emptyset$ and $\roles=\roles_o=\{A_b\}$.
Finally, the initial frame contains the registrar's key:
$\phi_0=\{w_0\refer k_R\}$.
\end{example}


\paragraph{\textbf{Bulletin Board \& Tally}}
%We assume that the tallying phase is reasonably designed.
We assume a public test $\Psi_b$ that everyone can execute on
the bulletin board to know if a ballot is well-formed or not.
Formally $\Psi_b[]$ is a term with a hole.
For instance, $\Psi_b$ can be a combination of a signature and ZK proof verification.
The protocol should also specify a term with hole
$\mathrm{Extract}[]$ that models the extraction of the vote from a
valid ballot.
% For instance, for a ballot $\aenc(\pk_C,v,r)$, the extraction
% term would be $\adec(\sk_C,[])$ using the key $\sk_C$.
As defined below, we require that this operator only computes votes or
$\bot$.
% For a set $S$, we denote by $S_{\E}$ the set of elements of $S$ quotiented by $\theo$.
\begin{definition}
\label{def:bb}
The bulletin board and the tally are specified through
a public term $\Psi_b[]\in\T(\Sigma_\pub,[])$ and
a term $\Extract[]\in\T(\Sigma,[])$ such that:
for any message $t$, it holds that
$\Extract[t]\redc u$ for some $u\in\mathcal{V}\cup\{\bot\}$.

Given a trace $\tr$ and a frame $\phi$, we define respectively the bulletin board and
the tally's outcome:\\[0.5mm]
\begin{small}
  \null\hfill$
  \begin{array}[]{r@{$\;$}l@{$\;$}l@{}r@{}l}
    \BB(\tr,\phi)&=& \{w\phi\ & |\ & \exists\Out(c_b,w)\in\tr,\ \Psi_b[w\phi]\redc\}^\#\\
    \Res(\tr,\phi)&=& \{v\ & |\ & \exists \mathrm{ba}\in\BB(\tr,\phi), \Extract(\mathrm{ba})\redc v\in\mathcal{V}\}^\#.
  \end{array}
  $\hfill\null
\end{small}
\end{definition}

The bulletin board is the {multiset} of messages %modulo $\theo$
that pass the $\Psi_b$ condition and
channel $c_b$.
Then, the tally's outcome is the {multiset} of votes obtained by applying
$\Extract(\cdot)$ on the % ballots in the
bulletin board.
\luccaN{While our notion of tally seems very restrictive, note that many operations can be performed by roles (\eg $A_b$) such as
% our notion of roles is flexible enough to model
mixnets as done \eg in~\cite{vote-CSF16} where the shuffling is done between two phases.}

\begin{example}[Continuing Example~\ref{ex:foo-role}]
\label{ex:foo-tally}
The public test $\Psi_b$ is defined as the following term with hole:\\[0.5mm]
\null\hfill
$
\begin{small}
  \begin{array}{rl}
    \Psi_b[]=&\AND(\versign(\projl(\projr([])),\pk(\sk_R)), \\
             &\ \ \ \open(\getMess(\projl(\projr([]))), \projr(\projr([]))))\\
  \end{array}
\end{small}
$\hfill\null\\[0.5mm]
where the destructor $\AND$ is such that $\AND(t_1,t_2){\redc}$ if and only if
$t_1{\redc}$ and $t_2{\redc}$ (formal definition in \Cref{sec:app:comp}).
% \cam{I find this redefinition of 'and' a bit weird. Why don't we just
% 	expand the formula to include the bit that is now in text below
% 	it?}
Indeed, expected ballots are of the form
$\pair{X}{\pair{\sign(\com(k,v),k_R)}{k}}$.
The evaluation of $\Psi_b[b]$ may fail %(\ie $\Psi_b[b]\redcb$)
if
%at least one of the two terms does not reduce;
either the signature verification fails or the commit opening fails.
Finally, the extraction function is
$\Extract[]=
\mathsf{wrapVote}(\open(\getMess(\projr(\projl([]))),\projr(\projr([]))))$
where $\mathsf{wrapVote}(\cdot)$ corresponds to the identity function on
$\mathcal{V}$ and maps all values not in $\mathcal{V}$ (modulo $\theo$) to $\bot$.
\end{example}


\paragraph{\textbf{Honest Trace}}
As said before, no process is given for dishonest roles.
However, we require a notion of honest trace that itself
specifies what behaviour should be expected from dishonest roles.
\toRM{
Intuitively, it is an abstraction of the trace obtained by executing one session
of the voter role, possibly involving other roles in the honest, expected way.}

\begin{definition}
\label{def:honest-trace}
The protocol shall specify a symbolic trace $\th=\th^0.\Out(c_b,w_b)$
(\ie, the last action corresponds to the casting of a ballot) and
a distinguished execution, called the {\em honest execution}, of the form: %\\[1mm]
% \lum{compression possible}
% \null\hfill
$(\{V(\id,v)\}\uplus\roles_o; \phi_0; 1) 
\sint{\tr_h} (\p;\phi_h;k_f)$
%\hfill\null\\[1mm]
for some $v\in\mathcal{V}$ and a free constant $\id$,
with $\tr_h$ the idealised trace associated to $\th$.
Additionally, we assume that $\th$ contains the action $\Phase{k}$ for all $2 \le k\le k_f$ (no phase is skipped).
\end{definition}
%
 The honest trace describes the honest expected execution of one voter completing the voting process until casting a ballot
 possibly through an interaction  with different roles. 
 Here, the notion  captures the fact that some corrupted roles are played by the attacker.
 Hence the fact that the honest trace is a symbolic trace with sub-messages that are unknown and not specified because chosen
 by the attacker.
 Note that the honest trace specifies how conditionals are expected to evaluate thanks to
 the $\taut\slash\taue$ dichotomy.

% We note $\mathcal{A}_h$ the subset of $\mathcal{A}$ of honest authorities taking part to the honest execution (at least one action
% in $\th$ is executed by those authorities).
% Intuitively, by replacing variables of $\th$ by any recipe, one obtains a trace that can be fully played by the system $!\,\mathcal{A}_h\cup\{V(\id,v)\}$
% finishing with the casting of a ballot containing $v$.
% \lum{We could define honest trace differently: from the expected {\em execution} of one voter with authorities,
%   we extract the trace and abstract away some parts of recipes by variables forming the honest trace.}
%
 % Intuitively, all instantiations of such an honest trace into a trace is a complete honest interaction of one voter
 % and authorities (essentially $\{V(A,v)\}\cup(\mathcal{A}\backslash A_V)$)
 % leading to the casting of a totally honest ballot in the BB (\ie Bulletin Board).


\begin{example}[Resuming Example~\ref{ex:foo-role}]
  \label{ex:foo-ht}
  % Honest trace associated to Example~\ref{ex:foo} 'see below)).
  We consider the following extension of the symbolic trace described in Example~\ref{ex:symbolic}, where $X\in\xi$ and
  $R_1=\sign(\versign(\projr(w_1),\projl(w_1)),w_R)$:\\[0.5mm]
    \null\hfill
  \begin{small}
$ \begin{array}{c}
      \th=\tau.\tau.\Out(c,w_1).\In(c,R_1).\taut.\tau.\Phase{2}.
           \Out(c,w_2).\\
           \phantom{\th=\ }\In(c,\pair{X}{w_2}).\taut.\Out(c,w_3). \tau.
           \In(u,w_3).\Out(c_b,w_3)
    \end{array}$
  \end{small}
    \hfill\null
\end{example}
%% SAVESPACE

% \begin{example}
%   (Honest trace associated to the LEE protocol (see Example~\ref{ex:lee} below)).
%   The honest trace (for an honest $R$) would be:
%   \[
%     \Out(p,w_1).\In(p,w_1).\Out(p,w_2).\In(p,w_2).\mathrm{phase}_1.\Out(a,w_3).
%   \]
%   While, in the threat model where $R$ is dishonest, the honest trace is as follows
%   (where $M'=\renc(\pk_C,\mathrm{getMess}(\proj_2(w_1)),X_r$):
%   \[
%     \Out(u,w_1).\In(u,\langle \sign(\sk(R),M'); \ZK(M',\pk_C,X_r,\mathrm{getMess}(\proj_1(w_1))) \rangle).\mathrm{phase}_1.\Out(a,w_3).
%   \]
%   Indeed, in that case, the environment is palying the role of $R$.
% \end{example}


\begin{definition}[E-voting Protocols]
\label{def:evoting}
  An e-voting protocol is given by a tuple
%\null\hfill
$
(\mathcal{V};
\phi_0;
V(\id,v);
\roles;
(\Psi_b[],\Extract[]);
\th)
$
%\hfill\null\\[1mm]
where $\mathcal{V}$ are
the allowed votes (\ie free, public constants),
$V(\id,V)$ and $\roles$ are the processes modelling honest roles and $\phi_0$ is the attacker's initial knowledge
as in Definition~\ref{def:roles},
$\Psi_b[]$ and $\Extract[]$ model the bulletin board and the tally as in Definition~\ref{def:bb}, and
$\th$ describes the intended, honest execution as in Definition~\ref{def:honest-trace}.
\end{definition}


\paragraph{\textbf{Flexible threat models}}
\looseness=-1
Our generic definition of e-voting protocols allows to model many different threat models.
First, the processes that model roles may use different kinds of channels. For instance,
by using private channels for some inputs and outputs, we model communication channels that prevent
the attacker to eavesdrop on or tamper with those exchanged messages.
By using public channels and adding the identity of voter in exchanged data, we model an insecure,
non-anonymous communication channel. In contrast, by using only a single public channel, we model an anonymous
communication channel, since all voters will use the same channel.
% \footnote{However, the attacker may have
% other ways to break anonymity, but this will be part of our security analysis.}.
Moreover, some roles can be considered dishonest or honest yielding different threat models.
Finally, different frames $\phi_0$ allow modelling different initial attacker knowledge
(\eg, secret keys of some roles).
% If the bulletin board is corrupted (or the ballot is implicitly assumed to accept
% any ballot from anyone) then $A_b = \mathrm{phase}_p.\In(u_b, x).\Out(b,x)$,
% $b$ is an unsecure channel only used there and $p$ some phase).
% In the case the threat models does not consider dishonest voter, it is natural to let $u_b$
% be a private or an authenticated channel forbidding the attacker to cast ballot himself.


%%%%%%%% DISCU MIXNETS
 % Valid ballots %(that is, ciphertexts associated with valid signatures) 
 % are input to a mixnet and
 % the mixnet's output is published.
% Note that mixnets as a collection of parallel processes
%  that each input a ballot, verify the signatures, synchronise with the other processes, and
%  nally output the ciphertext on an anonymous channel.



%  \begin{example}[Continuing Example~\ref{ex:foo-tally}]
%    \label{ex:foo-threat}   
%    We consider both honest and dishonest voters, and we assume the registrar and the ballot box are corrupted.
%    Hence, $\sk_R$ is considered to be a public constant making it
%    available to the attacker.
%    % the initial knowledge of the attacker is $\phi_0=\{w_0\mapsto \sk(R)\}$.
%    The messages of the first phase are exchanged on an unsecure
%    channels, as reflected by the fact that identity of voters ($\pk(\id)$) are disclosed
%    on a public channel name $c$ (notably they do not ensure anonymity) while the messages of the 
%    second phase are exchanged on an anonymous channel $a$ (that is uniform for all voters).
% %   For the considered threat model, $\mathcal{A}=\emptyset$.
%    \lum{Ok, currently we always need to model the bulletin board ($A_b$). To ease the presentation, we could
%    say that when the BB is dishonest, let's use a channel $c_b$ in voter role and do not model the BB explicitly.}
%  \end{example}



\paragraph{\textbf{Annotated Processes}}
Finally, we equip the semantics with annotations that will help subsequent developments.
We assume a notion of annotations over processes so that we can keep track of 
{\em role sessions} and {\em specific voters} throughout executions. Each action can then be labelled 
by this information. For a voter process $V(\id,v)$, we note $[\id,v]$ the annotation given to actions produced by this process.
Formally we may define such annotations by giving explicit annotations to processes
in the initial multiset and modify the semantics so that it keeps annotations on processes as one could
expect. Those notations notably allow to define when a specific voter casts a ballot as shown next.
\begin{definition}
  Consider an e-voting protocol
  $(\mathcal{V}; 
  \phi_0; 
  V(\id,v);
  \roles; 
  (\Psi_b[],\Extract[]);
  \th)$.
  We say that a voter $V(\id,v)$ {\em casts a ballot} $w$ in an execution
  $(\p\uplus\{V(\id,v),!A_b\};\phi_0;1)\sint{\tr}K$ 
  when there exists an output $\Out(c,w_b)\in\tr$ annotated $[\id,v]$ 
  and a ballot box (\ie $A_b$) session $s_b$ such that actions from $\tr$ annotated $s_b$ are
  $\In(c,w_b'),\Out(c_b,w)$ such that $w_b\phi(K)\theo w_b'\phi(K)$.
  We say that $V(\id,v)$ {\em casts a valid ballot} $w$ when, in addition, $\Psi_b[w\phi(K)]\redc$\;.
\end{definition}

\newcommand{\Tally}{\mathrm{Tally}}


\subsection{Ballot Secrecy}
\label{sec:frame:ballotsec}
% 1: Intuition on Ballot secrecy: change of votes --> actually swap of votes.
% 2. but also Tally
% 3. but then attacker can kill B to learn A's vote -> use of sync barrier usually
% 4. that's bad because limitations of what can be modelled with preision
% 5. we prefer weak pahses but then need a counterpart: that is fairness
Next, we define the notion of ballot secrecy that we aim to analyse.
Intuitively, ballot secrecy holds when the attacker is not able to observe any difference
between two situations where voters are wiling to cast different votes.
% change the votes they are willing to cast.
However, we cannot achieve such a property by modifying
just one vote, since the attacker will always be able to observe the difference on the final
tally outcome. 
Example~\ref{ex:eint} illustrates this problem: one has that $K_1\not\eint K_2$ while the FOO protocol
actually ensures ballot secrecy.
Instead, we shall consider a {\em swap} of votes that preserves the tally's outcome as usually done~\cite{KremerRyan2005,DKR-jcs09}.
More formally, we are interested in comparing
$\mathcal{S} = (!\;\roles) \uplus \{V(A,v_0),V(B,v_1)\}$ and
$\mathcal{S}_r = (!\;\roles) \uplus \{V(A,v_1),V(B,v_0)\}$,
where $v_0,v_1$ are two distinct votes in $\V$ and $A,B$ are two
distinct free, public constants, and, 
$! \mathcal{Q}$ refers to $\{!P\ |\ P\in\mathcal{Q}\}^\#$
for a multiset of processes $\mathcal{Q}$.
Because the attacker should neither be able to distinguish $\S$ and $\S_r$
when having access to the tally's outcome,
we are actually interested in the {\em trace equivalence} between $\S\cup\{\Tally\}$
and $\S_r\cup\{\Tally\}$ where
the $\Tally$ is a process computing the e-voting protocol's outcome;
\eg
$\Tally = !\In(c_b,x).\Let\;z=\Psi_b[x]\;\In\;\Out(c,\Extract(x))$.
% \lumN{warning: just intuitions, this Tally process will not exactly capture $\Res$}
This is the most well-established definition of ballot secrecy in symbolic model
introduced in~\cite{KremerRyan2005}.

%(\ie in $\T(\Sigma_c\cap\Sigma_\pub,\emptyset)$ that do not occur in $\E$).

% A first approximation of ballot secrecy we eventually define is the trace equivalence between the configurations
% $(\S;  \phi_0; 1)$ and
% $(\S_r;\phi_0; 1)$.
\looseness=-1
However, many e-voting protocols in our class would not satisfy such a property because the attacker
may force\footnote{This attack is captured by the model but is
unrealistic in practice. Indeed, in practical scenarios, to break the
ballot secrecy of a particular voter,
it would require the attacker to prevent all other voters from casting a
vote or, in case of dishonest tally, from performing their individual verifiability checks (as observed in~\cite{cortier2018voting}).}
 a particular voter (\eg $A$) to not cast any ballot in order to infer, from the tally's outcome,
the vote that the other voter (\eg $B$) has cast.
This is well-known and usually addressed by modelling phases as {\em synchronisation barriers}
as already acknowledged in~\cite{KremerRyan2005}:
``when we omit the synchronization [...]
% after the registration phase with the administrator,
privacy is violated.'' With such synchronisation barriers, all participants shall reach the same barrier in order
to move to the next phase preventing the previous scenario from
happening.
However, the use of barriers (as done \eg
in~\cite{KremerRyan2005,DKR-jcs09,vote-CSF16,dreier2017beyond,vote-ifip})
also limits the range of e-voting protocols one can model and analyse.
For instance, no synchronisation barrier can be put under a replication,
which forbids modelling authorities that act during several phases or
threat models with no dishonest voter.
% threat models in which no dishonest voter is considered.


% CC: Join makes better reading here, to show where the "This" is coming
% from.
\looseness=-1
In contrast, we choose to model e-voting phases as {\em weak phases} to avoid those limitations
and thus need an extra assumption
as a counterpart to synchronisation barriers.
We shall restrict our analysis to {\em fair executions}\footnote{This
should not be confused with
the {\em fairness property}~\cite{vote-ESO16,cortier2013attacking} that is one of the security property often required from e-voting protocols.}
where, at each beginning of phase, the voter $A$ and $B$ are still present and $A$ casts a ballot,
if and only if, $B$ does so. Note that all executions
of protocols modelled with synchronisation barriers are necessarily fair. We are thus conservative over
prior definitions.
Our fairness assumption can also be seen as an extension of the tally's assumption in~\cite{vote-ESO16}
that process the bulletin boards only if they contain both Alice and Bob's ballots.

%  {\em fairness assumption} (a similar assumption is
% made, \eg, in~\cite{vote-ESO16,vote-CSF16}) to limit our
% analysis to executions where both $A$ and $B$ actually cast a valid vote.
% \lucca{Big problem of terminology here.
% Fairness as described in~\cite{cortier2013attacking} (see below)
% refers to a different notion !!!
% Our fairness condition is in line with the \texttt{Check} notion from~\cite{vote-ESO16}
% and is a stronger counterpart of sync. barrier~\cite{vote-CSF16} of previous swapping approach (note that
% phase does not enforce this sync. aspect; our phases
% are weak phases and sync. barriers are strong phases according to terminology from~\cite{vote-ifip}).
% }
\begin{definition}
\label{def:fairness}
\looseness=-1
Consider an e-voting protocol
  $(\mathcal{V};
  \phi_0;
  V(\id,v); 
  \roles;
  (\Psi_b[],\Extract[]);
  \th)$.
  An execution
  $(\p;\phi_0;1)\sint{\tr}K$ for $\p\in\{\S,\S_r\}$ is said to be
  {\em fair for voter $[\id,v]$}
  when at each beginning of phase $i$, there is a a process annotated $[\id,v]$ at phase $i$.
  Such an execution is said to be {\em fair} when, for some $v,v'\in\mathcal{V}$,
  (i) it is fair for $[A,v]$ and $[B,v']$ and
  (ii) $[A,v]$ casts a ballot if, and only if, so does $[B,v']$.
% the two voter processes of identity $A$ and $B$ in $\p$
%   are equally present in the configuration.
%  cast a valid ballot.\toRM{ in that execution.}
%   one of the output action produced by that process is given to
%     the ballot box which produces itself a valid ballot; \ie 
%     for some channels $c,c'$ and handles $w,w'$,
%     there is an action $\Out(c,w)\in\tr$ performed by the voter process under scrutiny
%     and two actions $\In(c,w),\Out(c_b,w')\in\tr$ performed by the same session of $A_b$
%     such that $\Psi_b[w'\Phi(K)]\redc u$ for some $u$.
% \lum{if that's too informal, we may make use of annotations that we currently introduce just below.}
%   Such an execution is said to be {\em fair} when it is fair for the two voter processes in $\p$
%   of identity $A$ and $B$.
\end{definition}
% Note that a slightly weaker assumption consists in considering {\em strong phases} (or {\em synchronisation
% barriers}) \---while we consider {\em weak phases}\--- as done in~\cite{vote-ifip,vote-CSF16}.
% Intuitively, one may progress to the next strong phase only when all current processes agree on this decision.
% Since we consider weak phases, we need this assumption as a counterpart (as in \cite{vote-ESO16}).

Finally, we give below the definition of {\em ballot secrecy}. We could have defined it
as the trace equivalence (by symmetry) between $\S\cup\{\Tally\}$ and $\S_r\cup\{\Tally\}$
with a restriction over the explored traces (\ie the ones that are fair) but we prefer
our equivalent formulation in the interest of clarity. Note that the fairness assumptions get rid of strictly less
behaviours than the use of synchronisation barriers, and are therefore more precise from that point of view.
% \lumN{\luccaN{this is somewhat informal claim.  have the feeling we can be attacked on this. Shall we make a more formal
% claim (\eg in Appendices) ?}}

\begin{definition}[Ballot Secrecy]
\label{def:ballot-sec}
  An e-voting protocol
  $(\mathcal{V};
  \phi_0; 
  V(\id,v);
  \roles;
  (\Psi_b[],\Extract[]);
  \th)$ ensures {\em ballot secrecy} when 
  for any fair execution $(\S;\phi_0;1)\sint{\tr}K$,
  there exists a fair execution $(\S_r;\phi_0;1)\sint{\tr'}K_r$ such that:
  \begin{itemize}
  \item the attacker observes the same actions: $\obs(\tr) = \obs(\tr')$;
  \item the attacker observes the same data: $\phi(K) \estat \phi(K_r)$;
  \item the attacker observes the same tally outcome: 
    $\Res(\tr,\phi(K))= \Res(\tr',\phi(K_r))$.
  \end{itemize}
\end{definition}

% The problem explained in the above paragraphs reappear if the attacker can kill (\ie having an interaction making him go
% to an else branch and stop the execution)
% the voter-process of a specific voter
% during an id-leaking phase. A minimal concrete example is $V(\id,v)=\Out(\id).\In(x).\If\,x=\id\,\Then\,\mathrm{phase}.\Out(c,v)$.
% The attacker can execute the trace $\Out(c,w).\In(c,\id_A).\mathrm{phase}.\Out(c,w_v)$ and be sure that $w_v$ refers to
% the $A$'s vote breaking ballot secrecy.
% This attack cannot be avoided by any e-voting protocol and should be considered {\em unfair}.
% \lum{Make clear two distinct points. 1:.}
% Indeed, this is a targeted attack where the attacker prevents Bob to vote in order to learn Alice's vote.
% In real election, the attacker would have to prevent a significant amount of voters to vote in order
% to learn the vote of a specific voter (if he wants to learn his vote with proba 1 then he must
% prevent all voters to vote except the targeted voter). I believe this is not harmful in practice because each phase corresponds
% to a real synchronisation barrier where the voting system
% is waiting for everyone to finish  so if many voters cannot reach one phase, they know that something went wrong
% and will complain and the election system should stop the process at this step so that the attacker cannot perform its attack.
%
% The idea then consists in restricting our analysis to executions where, at each synchronisation barrier, $A$ and $B$ are either:
% both dead (no corresponding process in the current multiset)
% or both alive.
% I think that it is important to consider executions where $A$ and $B$ are both ``killed'' because it corresponds to non-targeted
% attacks where the attacker may exploit leaks during the ``killing'' phase\footnote{I'm no longer sure about that. Don't know if that's so important:
% it seems that error messages are not well specified in schemes or are sent on a different, secure channel.}.
% For instance, $V(\id,v)=\In(c,\_).\If\,\Psi\,\Then\,P\,\Else\,\Out(c,v).0$ assuming
% $P$ secure. You have to ``kill'' the voter's process to explore the $\Else$ branch in order to get the vote leaked.
% I've modified the notion of ballot secrecy we target accordingly.
%
% In (M2,ESORICS'16), they restrict their analysis to executions where $A$ and $B$ actually cast a ballot (hence they are never killed).
% I think that they may miss attacks by doing so; typically the attack just above.
%
%
% \lucca{(old) Update:} In all our case studies, no ``error'' message is specified in the specification. It seems reasonnable to
% make the same assumption as in (M2,ESORICS'16) and only consider executions where $A$ and $B$ both cast a vote.
% This fairness assumption is fine for protocols for which after each input, a conditional check that the received
% message is as  expected  and that have no message in {\sc Else} branch, or messages that are not harmful
% (\eg constants, or uniform messages which do not depend on vote \& identity) which is the case in our case studies.
% If that's not the case, this stronger notion of fairness condition could make us miss attacks.
% For instance, maybe the attacker can distinguish $A$ willing to vote $0$ from $A$ willing to vote $1$ by adopting a malicious behavior
% that makes $A$ goes to an else branch at some point (and thus cannot continue until casting a vote).
% On the other hand, it helps a lot in the proofs.
% \lucca{Currently}, we deal with the strong version of fairness which is as follows:
% $A$ and $B$ cast a vote.


\section{Conditions}
\label{sec:conditions}
We introduce three conditions and prove that
together, they imply ballot secrecy. In \Cref{sec:condi:tools} we
provide intuition for our approach and formally define the support notions.
%in~\Cref{sec:condi:tools}.
We then define the conditions
(\ie,  {\em Dishonest, Honest Relations, Tally Condition}) in
\cref{sec:condi:honest,sec:condi:tally,sec:condi:dishonest}.
We state  in \Cref{sec:proofs} that our conditions are
sufficient.


\newcommand{\ba}{\mathrm{ba}}
\newcommand{\openBal}{\mathrm{OpenHonBal}}
\newcommand{\openAllBal}{\mathrm{OpenBal}}



\subsection{Protocol phases and their links}
\label{sec:condi:tools}

\paragraph{\textbf{Identity-leaking vs.~Vote-leaking Phases}}
In a nutshell, ballot secrecy boils down to the absence of link between an identity and the vote this identity
is willing to cast. However, as illustrated by the next example, the attacker is able to link different actions
performed by the same voter as long as they take part in the same phase.
Thus, each phase of the e-voting protocol must hide and protect either the identity of voters
or the votes voters are willing to cast.
It is thus natural to associate to each phase, a {\em leaking label}:
either the phase (possibly) leaks identity (we call such phases {\em id-leaking})
or it (possibly) leaks vote (we call such phases {\em vote-leaking}).
In order to ensure ballot secrecy, the {\em Honest Relations Condition},
which we define later,
will enforce that the attacker cannot establish meaningful links
(\ie links that would hold for $\S$ but not for $\S_r$)
between id-leaking phase outputs and vote-leaking phase outputs.

\begin{example}
\label{ex:leaking-phases}
Consider a voter's role process $V(\id,v)=
  \phase 1 \Out(a,\id). \Out(a,v)$
  (other components are unimportant here).
  % where $a$ is an anonymous channel.
  This trivial protocol is an abstraction of a registration phase
  (voter sends its identity) followed by a voting phase (voter sends
  its vote).  We show this does not ensure ballot secrecy (see also the full witness
  in \Cref{sec:app:conditions}).
  Consider the (fair) execution starting with $(\S;\emptyset;1)$
  and producing the trace $\tr=\Out(a,w_\id).\Out(a,w_v).\Out(a,w_\id').
  \Out(a,w_v')$
  whose the two first (resp. two last) actions are performed by the voter
  $A$ (resp. $B$).
  This execution has no indistinguishable counterpart in $\S_r$.
  Indeed, because the first message {\em reveals the identity} of the voter, 
  the attacker can test that the first output is performed by $A$.
  After the first output $A$, the $\S_r$ side can only output either $B$ or $v_1$
  % (because $A$ votes $v_1$ in $\S_r$)
  but not $v_0$.
  However, because the second message {\em reveals the vote}, the attacker
  can make sure the output vote is $v_0$ and not $v_1$.
  % To summarise, the only executions of $(\S_r;\emptyset;1)$ following $\obs(\tr)$
  % produce frames that are never statically equivalent to the ones $\S$ would produce.
  Thus, this  protocol does not ensure ballot secrecy because %  The main reason is
  in a single phase (\ie, phase 1), there is one output revealing the identity
  of the voter and one output revealing the voter's vote.
  % and hence the  attacker can link an identity to a vote, thereby
  % breaking ballot secrecy.
%
  However, the process $V(\id,v)=\phase 1 \Out(a,\id).\ \phase 2 \Out(a,v)$ ensures
  ballot secrecy and does not suffer from the above problem.  
  The attacker cannot force $A$ to execute its first message leaking
  identity and then immediately its second message leaking its vote,
  because doing so would {\em kill} the process $V(B,v_1)$ (which is still in phase 1)
  preventing the whole execution from being fair.
  Thus, the attacker has to trigger all
  possible first-phase actions of $A$ and $B$ before moving to
  the second phase.
%  reflecting deadline in practice.
  After the first phase, we end up with
  the processes $\{\Out(a,v_0), \Out(a,v_1)\}$ on the $\S$ side and
  $\{\Out(a,v_1),\Out(a,v_0)\}$ on the $\S_r$ side, which are indistinguishable.
  % because those two outputs are on the same channel and do not reveal any identity.
  
  Thus,
  in this first iteration, we split
  outputs revealing identity and outputs revealing votes in distinct
  phases. This enables breaking links between identity and vote.
%  (which is the core reason of attacks on ballot secrecy).
\end{example}

% It is thus natural
% We shall associate to each phase of the protocol a leaking labels:
% In practice, this can be done very easily using following heuristics:
% \lum{when none of following criteria is met, we can also enumerate all possibilities.}
% \begin{itemize}
% \item if one input or output of the voting process is on a non-anonymous channel,
%   then the whole corresponding phase must be {\em id-leaking};
% \item if one output of the voting process contains signature from the voter or
%   any data related to the voter's identity (asymmetric public key, public signing key, \etc)
%   whose the presence can be checked by the attacker then the whole corresponding phase must be {\em id-leaking};
% \item if one output contains a message from which the attacker can deduce the vote
%   then the whole corresponding phase must be {\em vote-leaking};
% \item casting phase are often {\em vote-leaking}.
% \end{itemize}
% Obviously those are just heuristics but in practice, one easily figures out what is each phase.
% For instance, registration phases are often {\em id-leaking} because voters often has to reveal their identities
% for authentication purpose while voting phases are often {\em vote-leaking}.


As we will later see, our approach requires that we associate a
\emph{leaking label} to each phase which is a binary label indicating
whether we consider the phase to be {\em vote-leaking} or {\em id-leaking}.
Our only goal is not find such a labelling for which our conditions hold, implying
ballot secrecy. 
In practice and on a case-by-case basis, we can 
immediately associate the appropriate leaking label to a phase.
However, we explain in \Cref{sec:case:verif} how those labels can be automatically guessed.
% Since a protocol typically only has a few phases, we could simply try
% each possible assignment, and we would still be more efficient than
% current approaches.

% In practice and on a case-by-case basis, we can 
% immediately associate the appropriate leaking labels to a phase.
% For instance, if a phase includes an output from which the attacker can
% extract an identity or anything that can be related to the voter's
% identity (\eg, the voter's public signature key), then the phase
% can be considered id-leaking.



\begin{example}[Continuing Example~\ref{ex:foo-ht}]
  \label{ex:foo-phase}
  We consider phase 1 (resp. phase 2) as id-leaking (resp. vote-leaking).
% since it contains the output $\Out(c,\pair{\pk(\key(\id))}{s})$
%   and $\pk(\key(\id))$ is bijectly related to the identity $\id$.
%   The last output of phase 2 leaks the vote, we thus consider it vote-leaking.
\end{example}


\paragraph{\textbf{Id-leaking vs.~Vote-leaking Names}}
As illustrated by the next example, a name presents in different outputs can also be exploited 
 to link those outputs. This is problematic when phases of
 those outputs have different leaking labels
since it would enable linking those phases and thus maybe an identity with a vote.
That is why, similarly to phases, we associate a {\em leaking label} to each name created by role processes.
Note that the phase in which the name is created is irrelevant. What really matters is where the name
is used and to what kind of data it can be linked.
Again this classification is easily done on a case-by-case basis in practice
but we present simple heuristics to automatically infer it
in \Cref{sec:case:verif}.
% (\eg, if the name can be extracted by the attacker from an output then it inherits the leaking labels
% of this output's phase)
% but the different possibilities can all be tested separately.

% For revote, we need to make sure that there is no link
% between vote-leaking messages labelled by the same voter (\eg $[\id_A;v_A]$)
% but coming from two different sessions (\ie one of them corresponds to a revote).

\begin{example}
\label{ex:leaking-names}
  We continue Example~\ref{ex:leaking-phases} and consider
  $V(\id,v) =
  \phase 1 \new r.\Out(a, \id\oplus r).\phase 2 \Out(a, v\oplus r)$
  where $\oplus$ denotes the exclusive or operator.
  % , and $r$ is a new, fresh
  % random coin.
  This new protocol seems similar to the previous
  iteration. However, it does not satisfy ballot secrecy.
  Now, the attacker can use the
  name $r$ to link the action of the {\em id-leaking} phase
  with the action of the {\em vote-leaking} phase (see witness in Example~\ref{ex:xorEx:honestRel}),
  defeating the role
  of the phase which previously broke this link. %  A more minimal
  % \lum{is it clear how it can link ?
  %   The idea is that the attacker can xor the two outputs
  %   and check if it is $\theo$ to $A\oplus v_0$ or $B\oplus v_1$.}
  % example would be
  % $V(\id,v)=\new r.\Out(a,\langle
  % \id;r\rangle).\mathrm{phase}.\Out(a,\langle v;r\rangle)$.
  Note that only names can lead to the this issue: all other kinds of data
  (\eg, public constants) are uniform and do not depend on a
  specific voter session (\eg, replace $r$ by a constant $\ok\in\Sigma_c$ and the
  resulting protocol ensures ballot secrecy).
% Finally, similar issues
%   may occur with names created by other roles, because a voter may use
%   them wrongly as before.
\end{example}

\begin{example}[Continuing Example~\ref{ex:foo-phase}]
  \label{ex:foo-phase-name}
  % [DONE]:
  % Review: Example 4.4?
  % Example 4.4 does not continue the previous Example 4.3 but our running
  % example (FOO, starting in Example 2.2). The names k,k' thus refer to the
  % two fresh names created by the voter role shown in Example 2.2. We will
  % add a clarifying sentence.
  We consider the names $k,k'$ (created by the voter as shown in \Cref{ex:execution})
  to be vote-leaking. % is leaked in the last output of phase 2, which
  % is vote-leaking, and $k$ is
  % thus vote-leaking.
  % We consider $k'$ vote-leaking
  % Moreover, considering $k'$ id-leaking
  % also allows verification
  % (\ie the conditions hold in both situations).
\lumN{removed '$k$' id-leaking would work as well}
\end{example}



\paragraph{\textbf{``Divide \& Conquer%\footnote{With quotes, because in our case, it does not really refer to the common divide \& conquer technique in computer science}
''}}
One reason that ballot secrecy is hard to verify using existing
techniques, is the fact that diff-equivalence
is too rigid w.r.t.~phases: it does not allow any flexibility at
the beginning of phases.
We should be able to stop there, and start again with a new pairing
left-right, a new biprocess\footnote{We would like to achieve this even
for roles that can perform an unbounded number of sessions.}.
A core ingredient of our technique is to split each role
into independent, standalone sub-roles (each sub-role playing one phase of the initial role), which allows us 
to consider many more pairings including ones (left-right)
that are not consistent over phases.
% (this is what we need for FOO and LEE for instance).
% The {\em Dishonest Condition} we ecentually define allows us
% to consider sub-parts instead of complete roles.
% \luccaN{One of our conditions will require that the attacker cannot distinguish real roles from
% roles split into sub-roles.
\luccaN{One of our conditions will require that %, once all random data are chosen and fixed,
the attacker cannot distinguish the voter and other roles processes from standalone sub-role processes that do not
need to know the execution of past phases. This is also important to ensure
ballot secrecy, because otherwise 
the attacker might link two actions coming from two different
phases and then learn that they came from the same voter.}

\looseness=-1
We now formally define the sub-roles.
Let $\nV{i}$ be the vector made of the constant $v_i$ and all vote-leaking names (with indices $i$).
Let $\nID{i}$ be the vector made of the constant $\id_i$ and all id-leaking names (with indices $i$).
The pair $(\nV{i},\nID{j})$ (deterministically) describes the initial data needed to start one full honest interaction of one voter with
all necessary role sessions.


\begin{definition}
\label{def:sub-parts}
Recall that the voter process is of the form
$V(\id,v)=\phase k \nu\vect{n}.V'(\id,v)$
where $V'$ is without creation of names.
We define $V(\nID{i},\nV{j})$ as the process $\phase k V'(\id_i,v_j)\sigma$
where $\sigma$ maps names in $\vect{n}$ to corresponding names in $\nV{i}\cup\nID{j}$.
We similarly define $A(\nID{i},\nV{j})$ for $A\in\roles_o$.
% Consider $A=\phase k \nu\vect{n}.A'\in\roles$ where $A'$ is without creation of names.
% We note $A(\nID{i},\nV{j})$ the process $\phase k A'\sigma$
% where $\sigma$ maps names in $\vect{n}$ to corresponding names in $\nV{i}\cup\nID{j}$.
Finally, we define $\roles_o(\nID{i},\nV{j})=\{A(\nID{i},\nV{j})\ |\ A\in\roles_o\}^\#$.
\end{definition}

\begin{example}[Resuming Example~\ref{ex:leaking-names}]
  \label{ex:leaking-names-two}
  Assuming $r$ is said to be vote-leaking, one has $\nID{i}=\id_i$ and
  $\nV{j}=v_j,r_j$, and,
  $V(\nID{i},\nV{j})= \phase 1 \Out(a, \id_i\oplus r_j).\phase 2 \Out(a, v_j\oplus r_j)$
\end{example}

\looseness=-1
Intuitively, the process $V(\nID{i},\nV{j})$ corresponds to the voter role process of identity $\id_i$ and vote
$v_i$ that will use all given names instead of creating fresh ones.
Similarly for authorities.
Note that in the vectors $\nID{i},\nV{j}$,
there may be names that are never used in some roles;
we still give the full vectors as arguments though.
% For instance, for the protocol
% $V(\id,v)=\phase 1 \new r.\Out(a,\langle \id;r\rangle).\phase 2 \Out(a,\langle v,r\rangle)$
% and $r$ considered id-leaking,
% we would have $V({\mathbf \id_i}, ({{v_i,r_i,k_i}}))=
% \Out(a,\langle \id_i;r_i\rangle).\phase 2 \Out(a,\langle v_i,r_i\rangle)$.
%
%
We remark that given names $\nV{i},\nID{j}$, there is a unique (modulo $\theo$) execution of
$(\{V(\nID{i},\nV{j})\}\uplus\roles_o(\nID{i},\nV{j});\phi_0;1)$
following the idealised trace that is
(up to some $\tau$-actions) the bijective renaming of the honest execution (see Definition~\ref{def:honest-trace})
from names used in the honest execution to names in $\nV{i},\nID{j}$.
% : everything is deterministic once an instance
% of the honest trace and all fresh names are chosen.
We call that execution the {\em idealised execution for $\nV{i},\nID{j}$}.


\begin{definition}[Phase Roles]
\label{def:phaseRoles}
Given $\nV{i},\nID{j}$, consider the unique idealised execution for $\nV{i},\nID{j}$:
% \null\hfill
$(\{V(\nID{i},\nV{j})\}\uplus\roles_o(\nID{i},\nV{j});\phi_0;1) \sint{\tr^h}
(\emptyset;\phi;n).$
% \hfill\null\\[1mm]
% \lumN{better now (idealised execution is given by user). We could have defined this as bijective renaming of the idealised execution.}
For some $A(\nID{i},\nV{j})\in\roles(\nID{i},\nV{j})$ and some phase number $k\in[1;n]$,
we note $A^k_f(\nID{i},\nV{j})$ the first process resulting from $A(\nID{i},\nV{j})$ of the form
$\phase k P$ for some $P$ if it exists; and $0$ otherwise.
Finally, the {\em phase role} of $A$ for $k$, noted $A^k(\nID{i},\nV{j})$, is the process one obtains from
$A^k_f(\nID{i},\nV{j})$ by replacing by $0$ each sub-process of the form $\phase{l} P'$ for some $P'$ and $l> k$.
Further, the process $A^{\forall}(\nID{i},\nV{j})$ is the sequential composition of all $A^i(\nID{i},\nV{j})$.
%\cam{``recomposition'' sounds weird to me. Can we just say composition?}
Finally, $V^k(\nID{i},\nV{j})$ and $V^{\forall}(\nID{i},\nV{j})$ 
are defined similarly.
\end{definition}
%\lum{formal def is kind of awful, more informal def is commented}
% Then, to each phase $k$ of the protocol, we associate the closed process $V^k(\nID{i},\nV{j})=\phase k P$ where $P$
% is obtained by considering the part of the process $V(\nID{i},\nV{j})$ corresponding to that phase
% (which is an {\em open process}\footnote{Because some variables may be bound by inputs in previous phases.})
% where all free variables
% are instantiated as they would be in {\em the idealized execution} for names $\nID{i},\nV{j}$.

% \begin{example}
% \label{ex:min:subroles}
%   Continuing Example~\ref{ex:leaking-names-two}, we would have
%   $V^1(\nID{i},\nV{j}) = 
%   \phase 1 \Out(a, \id_i\oplus r_j)$,
%   $V^2(\nID{i},\nV{j}) = 
%   \phase 2 \Out(a, v_j\oplus r_j)$, and, 
%   $V^{\forall}(\nID{i},\nV{j})=
%   \phase 1 \Out(a, \id_i\oplus r_j).
%   \phase 2 \Out(a, v_j\oplus r_j)$.
% \end{example}

% We do the same for authorities taking part to the honest trace (\ie those in $\mathcal{A}_h$)
% and define processes $A^k_l(\nID{i},\nV{j})$ for all authorities $A_l\in\mathcal{A}_h$.
% %  but we do not have to instantiate variables because by (our) definition, an authority cannot
% % ``cross'' phases.
\looseness=-1
In a nutshell, phase roles describe how roles behave in each phase, assuming that
previous phases followed the idealised executions for the given names.
A crucial property we eventually deduce from our conditions % the {\em Dishonest Condition}
is that
it is sufficient (\ie, we do not lose behaviours and hence neither attacks)
to analyse the phase roles in parallel
% $V^1(\cdot)\ |\ A^1(\cdot)\ |\ V^2(\cdot)\ |\ A^2(\cdot)\ |\ \ldots$ %(where $p_i$ denotes $\mathrm{phase}_i$)
instead of the whole e-voting system.
Note that, by doing so, we do not only put processes in parallel that were
in sequence, we also make them forget the execution of past phases
cutting out some potential links that rely on that aspect.
Indeed, the voter process in a phase $i$ may use data received in a phase $j<i$ creating links between those two
(\eg via malicious tainted data).
When put in parallel, all parts are standalone processes that are no longer linked by past execution.
Note also that we put standalone processes in parallel that behave as if previous phases followed
one specific instantiation of the honest trace (\ie, the idealised trace) thus reducing a lot possible behaviours.
This will be crucial for defining {\em Honest Relations Condition} via
biprocesses that could not be defined 
otherwise.

\begin{definition}
The {\em id-leaking sub-roles} (respectively {\em vote-leaking sub-roles})
are as follow:\\[0.5mm]
\null\hfill$
  \begin{array}[]{l}
  \roles^\id(\nID{i},\nV{j}) =\{A^k(\nID{i},\nV{j})\ |\  A\in\roles_o\cup\{V\}, k\text{ id-leak.}\} \\
  \roles^v(\nID{i},\nV{j}) =\{A^k(\nID{i},\nV{j})\ |\ A\in\roles_o\cup\{V\}, k\text{ vote-leak.}\} \\
  \end{array}
$\hfill\null
\end{definition}
% Finally, we note $P^\id(\nID{i},\nV{j})$ the parallel composition of all processes corresponding
% to an id-leaking phase: \ie voter processes
% $V^k(\nID{i},\nV{j})$ where $k$ is an id-leaking phase
% and authorities $A^k_l(\nID{i},\nV{j})$ where $k$ is id-leaking phase and $A_l\in\mathcal{A}_h$ is an authority taking part
% to the honest trace.
% We define similarly the process $P^v(\nID{i},\nV{j})$.

% \lum{avoid semi-formal formulae}
% $$V\ |\ !\,\mathcal{A}_V
% \eint
% \{\new \nID{}.\new \nV{}.(
% P^\id(\nID{},\nV{})\ |\ 
% P^v(\nID{},\nV{}))\}\cup !\,\mathcal{A}_V
% $$

\begin{example}[Continuing Example~\ref{ex:foo-phase-name}]
\label{ex:foo-divide}  
% The vector $\nID{\id}$ only contains $\id$ while the vector
% $\nV{i}$ contains the vote $v_i$ and names $k_i,k_i'$.
The {\em phase roles} are:\\[0.5mm]
\null\hfill$
% Figure~\ref{fig:foo-phase-roles} and
  \begin{array}[h]{rclr}
    V^1(\nID{\id},\nV{i}) &=& \phase 1
                M = \com(v_i,k_i),&\\
             && e = \bl(M,k'_i),\ s=\sign(e,\key(\id)), &\\
             && \Out(c, \langle \pk(\key(\id)); s\rangle).\ \In(c, x); &\\
             && \If\, \versign(x,\pk(k_R))=e\; \Then\, 0&\\[0.7mm]
    V^2(\nID{\id},\nV{i}) &=&
                \phase 2 
                M = \com(v_i,k_i),&\\
             && \Out(c,\sign(M,k_R)).\ \In(c, y).  &\\
             && \If\, y=\langle y_1 ; M\rangle \;
              \Then\, \Out(c,\pair{y_1}{\pair{M}{k_i}} &\\
  \end{array}$\hfill\null\\[0.5mm]
The sub-roles are
$\roles^\id=\{V^1\}$, $\roles^v=\{V^2,A_b\}$.
\end{example}

% \begin{figure}[]
%   \centering $

%   $
%   \caption{Phase roles of FOO}
%   \label{fig:foo-phase-roles}
% \end{figure}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:


\paragraph{\textbf{Honest Interactions}}
We will show that under our conditions,
$\S$ is indistinguishable from an e-voting system based on
the reunion of id-leaking and vote-leaking sub-roles. 
To achieve this property we eventually require that when a voter
reaches a phase $k$ then it must be the case that it had an honest
interaction so far. This notion of honest interaction is captured
by the honest trace $\th$ as formally defined next.

\looseness=-1
%\paragraph{\textbf{Honest interactions}} % (formal definitions in \Cref{sec:ap:honest-exe})}
For two traces $\tr_1,\tr_2$ and a frame $\phi$,
we note $\tr_1 \equiv_\phi \tr_2$ if $\tr_1$ and $\tr_2$ are equal up to recipes
and for all recipes $M_1$ of $\tr_1$
we have that $M_1\phi\redc{\theo}M_2\phi\redc$,
$M_2$ being the corresponding recipe in $\tr_2$.
For some $1 < j \le k_f$,
we say that a trace $\tr_1$ and a frame $\phi$ {\em follow a trace $\tr_2$ up to phase $j$} (resp. {\em follow $\tr_2$})
if $\tr_1\equiv_\phi (\tr_2'\rho)$ where
$\tr_2'$ is such that $\tr_2=\tr_2'.\mathtt{phase}(j).\tr_2''$ for some $\tr_2''$
(resp. $\tr_2'=\tr_2$)
and $\rho$ is some bijection of handles (so that the notion is insensitive to choices of handles).
The above ensures that $\tr_1$ and $\tr_2$ compute messages
having the same relations w.r.t.~outputs (handles).
For instance, if $\tr=\Out(c,w).\In(c,w)$ is some trace, we would like
to capture the fact that for a frame $\phi$,
any trace $\Out(c,w).\In(c,M)$ follows $\tr$
as long as $M$ computes the same message as $w$ (\ie $w\phi\theo M\phi\redc$).
% We say that $\tr,\phi$ {\em follow the honest trace up to phase $j$} when it follows an instance of the honest trace up to phase $j$.
% (one obtains an instance by replacing variables in $\xi$ by recipes).
Finally, given an execution,
we say that a voter {\em had an honest interaction up to phase $j$} (resp. {\em had an honest interaction})
when there exist role session annotations $s_1,\ldots, s_n$ such that
the sub-trace made of all actions labelled by this voter or $s_i$ with the resulting frame
follow an instance of the honest trace up to phase $j$ (resp. follow an instance of the honest trace).

Recall that the trace $\tr^h$ from the honest execution is an instance of the honest trace $\th$ and are equal when $\th$ has no
unknown part (\ie second-order variable).
The purpose of the idealised trace in subsequent developments
is to consider an arbitrary, fixed, instantiation that is uniform for all voters and sessions.


% We also assume that when a voter $V(\id_1,v_1)$ had an honest interaction
% then we must be able to annotate all those actions by $[\id_1,v_1]$.
% Note that if even only one action does not follow the honest trace, we can't add meaningful annotation
% (think of the attacker combining two outputs from two voters and injecting
% this combination into one authority: how to label the output of the authority ?).

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:



\subsection{Honest Relations Condition}
\label{sec:condi:honest}
% Remind that  $\Extract_\sk(\cdot)$ returns either
% $\bot$ or a vote that should be in a fixed set $\mathcal{V}$ of public constants.
This condition aims at ensuring the absence of id-vote relations in honest executions.
Let $\nID{A}$ (resp. $\nID{B}$) be the public identity $\id_A$ (resp. $\id_B$) and as many as necessary (depending on the protocol) fresh names.
We may use $A$ (resp. $B$) to refer to $\id_A$ (resp. $\id_B$).
Let $\nV{0}$ (resp. $\nV{1}$) be the public vote $v_0$ (resp. $v_1$)
and fresh names. We require these names to be pairwise distinct.
We define the biprocess $\biproc$ at the core of the
{\em Honest Relations Condition}:\\[1mm]
\null\hfill$
\begin{small}
  \begin{array}{rl}
    \biproc = 
    &(\{
      \roles^{\id}(\nID{A},\choice{\nV{0}}{\nV{1}}),
      \roles^v(\choice{\nID{A}}{\nID{B}},\nV{0}),\\
    &\  \ \ \roles^{\id}(\nID{B},\choice{\nV{1}}{\nV{0}}),
      \roles^v(\choice{\nID{B}}{\nID{A}},\nV{1}) \}\\
    &\ \ \ \biguplus\ !\roles; \phi_0;1)\\
  \end{array}
\end{small}
$\hfill\null\\[1mm]
The biprocess $\biproc$ represents a system where votes (and vote-leaking names)
are swapped in
id-leaking phase and identities (and id-leaking names)
are swapped in vote-leaking phase.
The attacker should not be able to observe any difference in the absence of
relation between identity plus id-leaking names and vote plus
vote-leaking names.

  Note that the swaps are inconsistent across phases
  (\ie we do not swap same things in all phases).
  We could not have defined such non-uniform swaps by relying on the roles'
  processes. Instead, this has been made possible thanks to our divide \& conquer approach.
%  (see \Cref{sec:condi:tools})
 % and the Dishonest Condition.

\begin{example}[Resuming Example~\ref{ex:leaking-names-two}]
\label{ex:xorEx:honestRel}
  One has
$\biproc = (
\{
  \phase 1 \Out(a, \id_A\oplus\choice{r_0}{r_1}),
  \phase 2 \Out(a, v_0\oplus r_0), 
  A_b,\linebreak[4]
  \phase 1 \Out(a, \id_B\oplus \choice{r_1}{r_0}), 
  \phase 2 \Out(a, v_1\oplus r_1),
  A_b,
  !A_b
\};\emptyset;1)$.
We argue that this biprocess is not diff-equivalent. Indeed, 
the attacker can xor $\id_A,v_0$, an output of phase 1, and an output of phase 2. For one
choice of the outputs, the attacker may obtain $0$ on the left. This cannot happen on the right.
The same interaction is also an attack trace for ballot secrecy.
\end{example}

One requirement of the {\em Honest Relations Condition}
is the diff-equivalence of $\biproc$.
However, this alone does not prevent the honest trace to make
explicit links between outputs of id-leaking phases and inputs of
vote-leaking phase (or the converse). This happens
when the honest trace is not {\em phase-oblivious} as defined next.
\begin{definition}
  The honest trace is {\em phase-oblivious} when:
  \begin{itemize}
  \item in all input $\In(c,M)$ of $\th$ in a phase $i$, handles in
    $M$ must not come from phases with a different leaking labels (\ie,
    vote or id-leaking) than that of phase $i$, and
  \item a variable $X\in\xi$ of $\th$ must not occur in two phases having
    different leaking labels.
  \end{itemize}
\end{definition}
% When an honest trace is not phase-oblivious, the attacker can link two phases
% of different leaking labels when following the honest, expected execution. 
%
% This is not a severe restriction in practice; indeed the honest trace describes the expected
% honest behavior of the environment possibly playing the role of some dishonest authorities.
% The phase-oblivious condition is thus in line with our restriction over authorities (\ie 
% their role processes should not cross phases).
% \vspace{-5pt}                  %because ACM env for def are more compressed

\begin{condi}[Honest Relations]
  The Honest Relations Condition is satisfied if $\biproc$ is diff-equivalent
  and the honest trace is phase-oblivious.
\end{condi}
%\lucca{Relation Condition $=$ Diff-equivalence of $\biproc$}
% \lumN{requring trace equ of lef and right side of $\biproc$ would be fine as well but the point
% is we made everything in order to make this $\biproc$ (often) diff-equivaalent}
% \vspace{-5pt}                  %because ACM env for def are more compressed

% This condition could be defined as follows:
% for any execution of $\biproc$, the two frames produced on the two sides must be statically equivalent.
% The fact that conditonals evaluate the same way should come from control-flow condition.



% \paragraph*{Ideas for the Definition}
% \lucca{Warning: for the moment, I have formal definition for FOO and LEE but not yet formal definition for the general case.}
% As said before we want to verify the absence of relations between messages of the two categories.
% In the final proof, considering a given execution, we will need to be able to replace $V(A,v_0)$ playing a session
% in a vote-leaking phase by $V(B,v_0)$ playing that same session and we will also need to replace
% the vote $v_0$ cast by $V(A,v_0)$ in an id-leaking phase by the vote $v_1$. The idea of this condition is to
% be able to prove that if we can do so then the resulting frames are statically equivalent.
% In a sense, this condition should verify strong secrecy of the vote (and other vote-leaking data) in id-leaking messages
% and strong secrecy of the id (and other id-leaking data) in vote-leaking messages.


% Challenges we have to face:
% \begin{itemize}
% \item we should be able to verify the absence of such relations even among messages coming from authorities
% \item we should be able to verify this even for messages that do not come from honest executions (\ie following an honest trace)
% \item the property we want to verify is about resulting frames and should not interfer with possible mismatches in control-flow
% \end{itemize}


% I suggest the following idea.
% We will prove (1) that id-leaking messages and data are ``observably independent'' from actual votes
% and (2) that vote-leaking messages and ata are ``observably independent'' from actual identities.
% To prove (1) for all id-leaking messages of a phase $p$ for instance,
% we build from the process $V(\id,v)$ a process
% $V'(\id,v)$ by adding a $\new v'$ at the beginning of the phase $p$
% and by replacing all  syntactical outputs $\Out(c,u)$ in the phase $p$ by
% $\Out(c,\mathrm{diff}[u,\mathrm{ideal}(u,v')])$ where $\mathrm{ideal}(\_,\_)$ is defined next.
% $\mathrm{ideal}(u,n)$ is built by looking at the honest execution: if $m[v]$ is the the ground message
% that is outputted by the syntactical output $u$ with the vote $v$ inside, we let
% $\mathrm{ideal}(u,n)$ be $m[n]$.
% Finally, we verify the diff-equivalence of $V'$ with all authorities in parallel.

% The challenge n.3 is solved using the same trick as for S\&P'16: we actually over-approximate executions of $V'$
% (by putting $\Then$ and $\Else$ branches in parallel) because the goal is to produce at least all frames of $V$ and compare
% them with the one that $V'$ would have produced on the right.
% I think that even though it seems not to be the case, the challenge n.1 is actually addressed.
% \lum{Note: this is a difficulty I encountered with LEE.}
% Indeed, if an authority creates a leak via a complex interaction then thanks to the Control-Flow Condition
% (assumed here) this complex interaction can also be done on the right process of $V'$. There will be no
% leak on the right because the vote is a fresh nonce. This mismatch leads to a non-diff-equivalence case.
% The challenge n.2 might still be a problem.

% \lucca{At this point, I've applied this general idea to pratical examples (FOO and LEE) in Section~\ref{sec:complete}.
%   The biprocesses used to verify this condition are formally defined there. It works for FOO and I'm still
%   working on the proof for LEE.}



\subsection{Tally Condition}
\label{sec:condi:tally}
The {\em Tally Condition} prevents ballot secrecy attacks that exploit the tally's outcome.
Intuitively, the Condition requires that for any valid
ballot produced by $\S$,
either
(i) the ballot stems from an honest execution
of $A$ or $B$, or
(ii) it is a dishonest ballot and in that case, it must be that the vote the Tally would extract from that ballot
is the same before or after the swap $A\leftrightarrow B$. Formally, we deal with the case (ii) by considering
executions of $\biproc$ so that we can always compare ballots before or after the swap $A\leftrightarrow B$
(\ie intuitively in $\S$ or in $\S_r$).

\begin{condi}[Tally]
\label{condi:tally}
We assume that $\biproc$ is diff-equivalent.
The {\em Tally Condition} holds if for any execution
$\biproc\sint{\tr}\biproc'$ leading to two frames $\phi_l,\phi_r$
such that the corresponding execution on the left is fair, it holds that
for any ballot $\ba\in\BB(\tr,\phi_l)$ (with $w$ as the handle) then either:
\begin{enumerate}
\item there exists a voter $V(\id,v)$ which had an honest interaction and cast a valid ballot $w$
  (it stems from an honest voter);
%  $w\phi_l\theo \ba$;
%   and had an honest interaction
% the ballot $\ba=w\phi_l$ is equal (modulo $\theo$) to the cast ballot stemming from an honest interaction of some voter $V(\id,v)$ on the left
%   (\ie %there exists an honest voter $V(\id,v)$ in $\S$ such that
%   $V(\id,v)$ cast a valid ballot $w'$ and follows
%   the trace obtained by only keeping actions annotated $[\id,v]$ from $\tr$ follows an instantiation of the honest trace for $\phi_l$ and its last
%   output $\Out(c_b,w')$ is such that $w'\phi_l\theo\ba$).
  % $\underbrace{\tr_h^0\phi_l.\Out(c,w_c\phi_l)}_{\text{honest trace}}.\underbrace{\In(c',ba).\Out(b,ba)}_{\text{casting messages}}$
  % for some $c,c',w_c$ such that $\tr_h^0.\Out(c,w_c)$ is an instantiation of the honest trace,
  % $w_c\phi_l\theo ba$,  and, $\In(c',ba).\Out(b,ba)$ are performed by one bulletin-board session).
\item or there exists some $v\in\V\cup\{\bot\}$ such that
  $\Extract(w\phi_l)\redc v$ and $\Extract(w\phi_r)\redc v$
  (it may correspond to a dishonest ballot that should not depend on A's or B's vote).
\end{enumerate}
\end{condi}
% In the first case, we accept to consider another equal (modulo $\theo$)
% ballot to fulfil the condition because the attacker can often copy
% ballots that are equal to existing honest ballots. However, those
% repeated ballots will not be taken into account with multiplicity because
% the tally considers the bulletin board as a {\em set} 
% of ballots quotiented by $\theo$.
% Hence, those copies made by the attacker won't introduce any bias
% in the tally's outcome and are thus not harmful \wrt ballot secrecy.

%\lumN{consider remove remark env}
%\begin{remark}%[Blind Copy]\
%  \lum{drop remark env. to save space if needed}
  The Tally Condition does not forbid making
  copies of a ballot completely ``blindly''
  (\ie, without being able to link this ballot to a specific
  voter\slash identity).
  Indeed, votes in vote-leaking phases are identical
  on both sides of $\biproc$ and the second case (2) will
  thus trivially hold.
  This actually improves the precision of the condition since
  such copies are not harmful \wrt
  ballot secrecy.  In fact,
	\toRM{in such a case,} the attacker may observe a bias that he might exploit
  to learn the vote contained in a specific ballot, but the attacker would be
  unable to link this ballot (and its vote) to a specific voter.
Therefore, our condition captures a refined notion of
{\em ballot independence attacks}~\cite{cortier2013attacking}.
%Indeed, a dishonest ballot may depend on honest interations


  % the vote of a specific voter\slash identity.  In practice, we
  % encouter this case with the Lee protocol variant DKR (described in
  % Example~\ref{ex:lee} and in the dedicated
  % Section~\ref{sec:complete:lee}).
%\end{remark}



\subsection{Dishonest Condition}
\label{sec:condi:dishonest}
%\lum{maybe add a sentence on the attacks this condition prevent}
\looseness=-1
This condition prevents attacks based on actively dishonest interactions where
the attacker deliberately deviates from the honest trace in order to exploit possibly
more links (\eg see tainted data example from Introduction).
The idea of the condition is to be able to reduce the behaviours of the voter
system to the parallel composition of all {\em phase roles} that are based on
{\em the idealised execution} for some names chosen non-deterministically.
% (data from precedent phases are replaced by data the idealized execution would
% have produced).
The condition requires that if a voter process moves to the next phase in an execution of the e-voting system
then it must be the case
that it had an honest interaction up to that phase and all agents involved in that honest
interaction are not involved in others.
When $\th=\tr^h$ (no unknown part in the honest execution), this is sufficient to show that
roles are indistinguishable from the parallel composition of phase roles. However, when
$\th\neq\tr^h$, some attacker choices for second second-order variables of $\th$ may break the latter.
For that case, the condition thus requires an additional diff-equivalence between the system based on roles
and the system based on the sequential composition of the phase roles (\ie processes $A^{\forall}$).
% that when all id-leaking and vote-leaking names are fixed,
% the e-voting system and the sequential composition of the phase roles (\ie processes $A^{\forall}$)
% are indistinguishable.
To make sure that the tally's outcome
could not break this equivalence, we test the former in presence of an oracle
opening {\em all} ballots.
% Altogether, we are able to reduce any execution of a voter casting a ballot to
% an execution following the honest trace played by the phase roles.

 
%This second requirement is defined by the diff-equivalence of a specific biprocess.
\looseness=-1
Formally, we let $V^D(\nID{\id},\nV{i})$ be the biprocess obtained by the (straightforward) merge of the two following processes:
(1) $V(\nID{\id},\nV{i})$ and (2) $V^\forall(\nID{\id},\nV{i})$ (\ie see Definition~\ref{def:phaseRoles}).
Recall that the process $V^\forall$ forgets the past execution at the beginning
of each phase 
and behaves as if the past execution followed the idealised trace.
In particular, it forgets previous (possibly malicious) input messages.
We similarly define biprocesses $A^D$ for $A\in\roles_o$.
Given an identity $\id$ and a vote $v$, we define a process:\\[1mm]
\null\hfill
$S_f(\id,v)=\new \nID{0}.\new \nV{0}.(\Pi_{A\in\roles_o\cup\{V\}}
A^D((\id,\nID{0}),(v,\nV{0})))$
\hfill\null\\[1mm]
where $\Pi$ denotes a parallel composition and
$\nID{0}$ (resp. $\nV{0}$) is made of all id-leaking names except the identity
(resp. vote).
% $\nID{}$ (resp. $\nV{}$) is composed of $\nID{0}$ (resp. $\nV{0}$) and $\id$ (resp. $v$)
% and $\{A_1,\ldots A_n\}=\mathcal{A}_h$ are all authorities involved in the honest trace.
Intuitively, $S_f$ starts by creating all necessary names and is then ready
to complete one voter session (according to processes $V$ and $A\in\roles$ on the left and $V^{\forall},A^\forall$ on the right)
using those names. Next, the oracle opening all valid ballots is as follows:
$\openAllBal=\phase {k_f} \In(c_u,x).\Let\, z=\Psi[x]\,\In\,\Let\,v=\Extract[x]\,\In\,\Out(c_u,v))$
where $c_u$ is some public channel and
$k_f$ is the last phase that occurs in the honest trace $\th$.
Finally, we define:
% \null\hfill
$\biproc^D=(\{S_f(A,v_0),S_f(B,v_1),!\openAllBal\}\;\cup\;!\,\roles;\phi_0)$.
% $\hfill\null

\begin{example}[Continuing Example~\ref{ex:foo-divide}]
\label{ex:foo-cf}
The process $V^D$ associated to the FOO protocol is shown below:\\[0mm]
\null\hfill$
  \begin{array}[h]{lr}
    \phase{1} M = \com(v_i,k_i),&\\
              e = \bl(M,k'_i),\ s=\sign(e_i,\key(\id)), &\\
              \Out(c, \langle \pk(\key(\id)); s\rangle).\ 
              \In(c, x). \\   %&\text{expected: } \sign(e,k_R)\\    
              \If\, \versign(x,\pk(k_R))=e &\\
              \Then\, \phase{2} \Out(a,\choice{\unbl(x,k'_i)}{\sign(M,k_R)}). &\\
              \In(c, y). \   %&\text{expected: } \langle \_;M\rangle
              \If\, y=\langle y_1 ; M\rangle 
%                                                        &\\
 \;             \Then\, \Out(c,\pair{y_1}{\pair{M}{k_i}}) &\\
  \end{array}
  $\hfill\null
\end{example}

\begin{condi}[Dishonest]
The {\em Dishonest Condition} holds when:
  % \begin{enumerate}
  % \item 
\begin{enumerate}
\item 
  For any fair execution $(\S;\phi_0;1)\sint{\tr.\mathtt{phase}(j)}(\p;\phi;j)$, if a process at phase $j$
  annotated $[\id,v]$ for
  $\id\in\{A,B\}$ and $v\in\mathcal{V}$ is present in $\p$ then it had an honest interaction in $\tr,\phi$ up to phase $j$.
  % voter process $V(\id,v),\id\in\{A,B\}$
  % casts a vote then $V(\id,v)$ had an honest interaction. % (\ie there exist authority session annotations $a_i$
  % such that all actions labeled by voter $V(\id,v)$ or $a_i$ follows the honest trace $\th$).
  Moreover, authority sessions $a_i$ involved in this honest interaction
  are not involved in other honest interactions.
% \item If $\th$ has some unknown part
%   (\ie $\th\neq\tr^h$), then the biprocess $\biproc^D$ must be diff-equivalent.
% \end{enumerate}
\item If $\th$ has some unknown part (\ie $\th\neq\tr^h$), then
  the biprocess $\biproc^D$ is diff-equivalent.
\end{enumerate}
\end{condi}


%
% \toRM{proposition for moving a lot of the following content to appendices:
% 1. describe here the dishonest condition only for the case $\th=\tr^h$, so we only have to discuss here Item 1 of Cond 3. Say that in the other case we have
% to make sure the protocol behavior is insensible to the choice
% of the chosen instance of the honest trace. This additional condition is 
% realised by an additional bi-process given in appendix.
% 2. Move the rest below to appendices.
% We want this reduction to be invisible for the attacker even when he can learn
% the tally outcome.
% The condition requires that if a voter process casts a ballot in an execution of the e-voting system
% then it must be the case
% that it had an honest interaction and all agents involved in that honest
% interaction are not involved in others.
% The condition then requires that when all id-leaking and vote-leaking names are fixed,
% the e-voting system and the sequential composition of the phase roles (\ie processes $A^{\forall}$)
% are indistinguishable. To make sure that the tally's outcome
% could not break this equivalence, we test the former in presence of an oracle
% opening {\em all} ballots.}
% % Altogether, we are able to reduce any execution of a voter casting a ballot to
% % an execution following the honest trace played by the phase roles.

 
% \toRM{This second requirement is defined by the diff-equivalence of a specific biprocess.
% We let $V^D(\nID{\id},\nV{i})$ be the biprocess obtained by the (straightforward) merge of the two following processes:
% (1) $V(\nID{\id},\nV{i})$ and (2) $V^\forall(\nID{\id},\nV{i})$ (\ie see \Cref{def:phaseRoles}).
% Recall that the process $V^\forall$ forgets the past execution at the beginning
% of each phase 
% and behaves as if the past execution followed the idealised trace.
% In particular, it forgets previous (possibly malicious) input messages.
% We similarly define biprocesses $A^D$ for $A\in\roles_o$.
% Given an identity $\id$ and a vote $v$, we define a process:\\[1mm]
% \null\hfill
% $S_f(\id,v)=\new \nID{0}.\new \nV{0}.(\Pi_{A\in\roles\cup\{V\}}
% A^D((\id,\nID{0}),(v,\nV{0})))$
% \hfill\null\\[1mm]
% where $\Pi$ denotes a parallel composition and
% $\nID{0}$ (resp. $\nV{0}$) is made of all id-leaking names except the identity
% (resp. vote).
% % $\nID{}$ (resp. $\nV{}$) is composed of $\nID{0}$ (resp. $\nV{0}$) and $\id$ (resp. $v$)
% % and $\{A_1,\ldots A_n\}=\mathcal{A}_h$ are all authorities involved in the honest trace.
% Intuitively, $S_f$ starts by creating all necessary names and is then ready
% to complete one voter session (according to processes $V$ and $A\in\roles$ on the left and $V^{\forall},A^\forall$ on the right)
% using those names. Next, the oracle opening all valid ballots is as follows:
% $\openAllBal=\phase {k_f} \In(c_u,x).\Let\, z=\Psi[x]\,\In\,\Let\,v=\Extract[x]\,\In\,\Out(c_u,v))$
% where $c_u$ is some public channel and
% $k_f$ is the last phase that occurs in the honest trace $\th$.
% Finally, we define:\\[1mm]
% \null\hfill
% $\biproc^D=(\{S_f(A,v_0),S_f(B,v_1),!\openAllBal\}\;\cup\;!\,\roles;\phi_0).
% $\hfill\null}

% \toRM{\begin{example}[Continuing Example~\ref{ex:foo-divide}]
% \label{ex:foo-cf}
% The process $V^D$ associated to the FOO protocol is shown below:
% \[
%   \begin{array}[h]{lr}
%     \phase{1} M = \com(v_i,k_i),&\\
%               e = \bl(M,k'_i),\ s=\sign(e_i,\key(\id)), &\\
%               \Out(c, \langle \pk(\key(\id)); s\rangle).\ 
%               \In(c, x). \\   %&\text{expected: } \sign(e,k_R)\\    
%               \If\, \versign(x,\pk(k_R))=e &\\
%               \Then\, \phase{2} \Out(a,\choice{\unbl(x,k'_i)}{\sign(M,k_R)}). &\\
%               \In(c, y). \   %&\text{expected: } \langle \_;M\rangle
%               \If\, y=\langle y_1 ; M\rangle 
% %                                                        &\\
%  \;             \Then\, \Out(c,\pair{y_1}{\pair{M}{k_i}}) &\\
%   \end{array}
%   \]
% \end{example}
% }

% \begin{condi}[Dishonest]
%   When $\th=\tr^h$,
%   the {\em Dishonest Condition} holds when
%   % \begin{enumerate}
%   % \item 
%   for any fair execution $(\S;\phi_0;1)\sint{\tr.\mathtt{phase}(j)}(\p;\phi;j)$, if a process annotated $[\id,v]$ for
%   $\id\in\{A,B\}$ and $v\in\mathcal{V}$ is present in $\p$ then it had an honest interaction in $\tr,\phi$.
%   % voter process $V(\id,v),\id\in\{A,B\}$
%   % casts a vote then $V(\id,v)$ had an honest interaction. % (\ie there exist authority session annotations $a_i$
%   % such that all actions labeled by voter $V(\id,v)$ or $a_i$ follows the honest trace $\th$).
%   Moreover, authority sessions $a_i$ involved in this honest interaction
%   are not involved in other honest interactions.
% % \item If $\th$ has some unknown part
% %   (\ie $\th\neq\tr^h$), then the biprocess $\biproc^D$ must be diff-equivalent.
% % \end{enumerate}
% \end{condi}

% \lucca{Discussion on the second part of Iterm 1 of the condition.}
% It is important that authority sessions cannot be involved in two different honest executions. Indeed, otherwise,
% we cannot re-organize the execution as in the conclusion of Lemma~\ref{lem:cf} which is mandatory to apply our 
% idea of swapping differently depending on the leaking-labels.
% \lucca{Problem:} it seems hard to verify that in ProVerif in the general case. In our case studies it is easy though because
% the honest trace almost forward outputs to inputs \lucca{and} all those output are pairwise distinct modulo $\theo$.
% The second point is important because the notion of honest execution just requires that the induced input messages 
% are the same than when using the recipe in the honest trace.
% \lucca{I'm still thinking about that...}


\subsection{Main Theorem}
\label{sec:proofs}
Our main theorem states that our three conditions together imply ballot secrecy.
%Before stating and proving it,
It is based on the following Lemma that states  the essential property we deduce from the Dishonest Condition.
Note that the definition of having honest interactions is straightforwardly extended to executions
performed by phase sub-roles. For instance, $V^1(\vect{n^{\id}_{\id_A}},\vect{n}^v_{i})$ would be annotated $[\id_A,v_i]$.
We give full proofs of the lemma and our Main Theorem
in Appendix~\ref{sec:ap:proofs-thm}.
% This is the only interface between the latter on one hand and
% other conditions and the Main Theorem on the other hand.

\begin{restatable}{lemma}{dishoLemma}
\label{lem:cf}
Let $v_i,v_j$ be some distinct votes in $\V$ and $\tr$ a trace
of the form
$\tr_0.\mathtt{phase}(k).\tr_1$ for some $1\le k\le k_f$
where no $\mathtt{phase}(\cdot)$ action occurs in
$\tr_1$.
If the dishonest condition holds then
there exists a fair execution
$$(\{V(\id_A,v_i),V(\id_B,v_j)\}\cup\,!\roles;\phi_0;1)\sint{\tr}(\p;\phi;k),$$
if, and only if,
there exist pairwise distinct names $\nID{A},\nID{B},\nV{i},\nV{j}$ (not including vote or identity),
a trace $\tr'=\tr_0'.\mathtt{phase}(k).\tr_1'$ and a fair execution
$$
\begin{small}
  \begin{array}{ll}
    (\{
    \roles^\id((\id_A,\nID{A}),(v_i,\nV{i})),
    \roles^v((\id_A,\nID{A}),(v_i,\nV{i})),&\\
    \ \ \>\roles^\id((\id_B,\nID{B}),(v_j,\nV{j})),
    \roles^v((\id_B,\nID{B}),(v_j,\nV{j}))
    \}\uplus\;!\roles;
    \phi_0;1)\\
    \sint{\tr'}
    (\q;\psi;k).
  \end{array}
\end{small}
$$
% $A$ and $B$ execute the idealized trace for respectively $\nID{A},\nV{0}$ and
% $\nID{B},\nV{1}$
% (\ie $\tr'_{(A,v_0)}=\tr^h$ and $\tr'_{(B,v_1)}=\tr^h$),
% we just modified some recipes but not underlying messages
% (\ie $\tr'\equiv_\phi \tr$),
where  $[\id_A,v_i]$ and $[\id_B,v_j]$ had an honest interaction in $\tr_0'.\mathtt{phase}(k)$ up to phase $k$.
$\psi$. % and cast a vote.
In both directions, we additionally have that $\obs(\tr')=\obs(\tr)$, $\phi\estat\psi$
and $\Res(\tr,\phi)=\Res(\tr',\psi)$.
\end{restatable}
\toRM{
\begin{proof}[Proof sketch, full proof in Appendix~\ref{sec:ap:proofs-thm}]
We prove the direction $(\Rightarrow)$, the other one can be proven similarly.
The first item of the Dishonest condition allows us to define names
%\cam{"define properly names?" Perhaps just: "define proper names"?}
$\nID{A},\nID{B},\nV{0},\nV{1}$ pertaining to the two disjoint honest interactions.
By moving some $\tau$-actions backwards in the given execution, we explore the same
execution (up to $\tau$-actions) starting with the left-side of $\biproc^D$.
If $\th=\tr^h$ then there is only one instantiation of the honest trace.
Therefore, voters $A$ and $B$ followed the idealised trace and thus
their executions can be exactly mimicked by executions
of processes $A^\forall$ for $A\in\roles_o\cup\{V\}$ with appropriate names.
Otherwise (\ie $\tr^h\neq\th$), the diff-equivalence of $\biproc^D$
implies that one can replace $V$ (resp. role process $A$) by
$V^\forall$ (resp. $A^\forall$) in the latter execution whilst preserving the executability
of the same observable actions (\ie $\obs(\tr')$), leading to statically equivalent frames.
Due to the constraint on phases, putting
$A^i$ in parallel instead of in sequence (as done in $A^\forall$)
allows completion of the same execution.
This yields the desired execution with the appropriate multiset of processes at
the beginning.

Finally,
we show that the tally outcome is the same in both executions.
If $\th=\tr^h$, this follows from the equality of the frames
and equality (up to $\tau$ actions) of traces.
Otherwise, we prove this by contradiction: We note that the bulletin
boards are the same in both executions (by static equivalence of frames
and preservation of observable actions).  Hence, there must be a ballot
yielding two different votes on both sides.  Next, we consider an
extension of the above execution of $\biproc^D$ where this ballot is
given to the opening oracle. The output of this session of the oracle
corresponds to the vote in the respective sides. By hypothesis, the
output message is thus different on both sides.  Since those are
constants, it contradicts the static equivalence of the resulting
frames.
\end{proof}
}

\begin{restatable}{theorem}{mainTheorem}
\label{thm:main}
If an e-voting protocol ensures the Dishonest Condition, the Tally Condition, and, the Relation Condition
% the diff-equivalence of $\biproc$
then it ensures ballot secrecy.
\end{restatable}
\toRM{\begin{proof}[Proof sketch, full proof in Appendix~\ref{sec:ap:proofs-thm}]
Consider a fair execution $(\S;\phi_0;1)\sint{\tr}(\p;\phi;k_f)$.
% Since $\th=\tr^h$, we also have that $A$ and $B$ follow the trace $\tr^h$.
We apply Lemma~\ref{lem:cf} (using the Dishonest Condition) and obtain
an execution with a simpler structure,
starting with phase roles. The latter execution starts with a configuration
matching the left part of $\biproc$, and hence we can use the diff-equivalence of $\biproc$
(from the Honest Relations Condition)
to build an indistinguishable execution where $\id_A$ and $\id_B$ have swapped their votes.
In the latter execution,
processes corresponding to voters $\id_A$ and $\id_B$ still have an honest interaction.
The latter follows from the fact that the honest trace is {\em phase-oblivious}
(implied by the Honest Relations Condition).
Applying Lemma~\ref{lem:cf} again, we deduce the existence of an execution
$(\S_r;\phi_0;1)\sint{\tr'}(\q;\psi;k_f)$
where $\id_A$ and $\id_B$ follow the honest trace and cast a ballot,
and such that $\obs(tr')=\obs(\tr)$,
$\psi\estat\phi$.

It remains to show that $\Res(\tr,\phi)=\Res(\tr',\psi)$.
When invoking Lemma~\ref{lem:cf} twice, we obtained executions
that have the same tally outcome. Thus, it suffices to prove that
when applying the diff-equivalence of $\biproc$, we obtained an
execution that has the same
tally outcome.
First, we note that the bulletin boards are the same in the two executions
(\ie corresponding to the executions
before and after the vote swap). This is a consequence of static equivalence over frames and
preservation of observable actions.
Next, we split the bulletin boards into ballots of $\id_A$ and $\id_B$ (yielding together the same multiset of
votes on both sides; \ie $\{v_0,v_1\}^\#$) and other ballots.
Finally, we show that the Tally Condition implies that the part of bulletin boards containing the other ballots yield the same multiset of votes
in both executions.
\end{proof}
}


% % We now iteratively transform this execution until reaching an execution starting with
% % $\S_r$. Remark that we can allow ourselves to modify recipes of the given execution
% % \lum{This remark is standard but I recall why we can make such transformations. Ideally, we should make
% % all those modifications more explicit from the beginning.}
% % as long as resulting messages are the same. Indeed, if a recipe $M$ is replaced by a recipe $M'$ such that
% % $M\psi\theo M'\psi$. Then, once we finally obtain the execution starting from $\S_r$ resulting in a frame $\psi'\estat\psi$,
% % we can change back the recipe from $M'$ to $M$ because $M\psi'\theo M\psi'$ is a consequence of $\psi\estat\psi'$.
% % Similarly, we allow ourselves to move $\tau$ actions forward or backward in the execution if executability is preserved.

% By the fairness condition,
% processes $V(A,v_0),V(B,v_1)$ in $\S$ passes all phases until casting a vote.
% By the control-flow condition, those two processes have a full honest interaction with
% all authorities. We let be $\nID{A}$ (resp. $\nID{B}$) the constant $A$ (resp. $B$) and all id-leaking
% names that are created by the different agents in this honest interaction of $A$ (resp. $B$).
% We define similarly $\nV{0}$ and $\nV{1}$.
% One can then show that because the two voter processes have two honest interactions,
% when a phase $i$ starts (\ie action $\mathrm{phase}_i$ is executed),
% then the processes labeled $[A,v_0]$ and $[B,v_1]$ are respectively 
% syntactically equal modulo $\theo$ to
% $V^i(\nID{A},\nV{0})$ and $V^i(\nID{B},\nV{1})$. The same can be established for authorities
% (simpler because an authority cannot cross phases).
% From Execution~\ref{ex:init}, one can thus build an execution:

% \begin{equation}
% (\{ P^{\id}(\nID{A},\nV{0}),
%   P^v(\nID{A},\nV{0}),
%   P^{\id}(\nID{B},\nV{1}),
%   P^v(\nID{B},\nV{1})
% \}\cup\q;\emptyset)
% \sint{\tr_0}(\p_0;\phi_0)\sint{\mathrm{phase}_t.\Out(c,w_t)}
%   (\p_1;\phi_0\cup\{w\mapsto \mathrm{res}\}).
% \label{ex:init-sub}  
% \end{equation}



% \paragraph*{Extentions}
% \lucca{I'm trying to drop the two critical assumptions $\th=\tr^h$ and strong fairness condition.}
% Here are some insights I have gathered so far.

% \textbf{(Dropping $\th=\tr^h$)}
% \lucca{This has been implemented in the present version.}
% One example is the procol FOO where the label of the ballot is chosen by the environment ($y_1$ in the voter process of FOO).
% With that modelization, the honest trace has an uknown part ($y_1$ which refers to the label).

% We need to make sure that Lemma~\ref{lem:cf} gives a transformed execution having the same
%   tally result (for both directions). We thus need to streghten the Control-flow conditon a bit. Basically, we need to
%   add a simplified OpenBallot oracle to $\biproc^D$ (simplified means: conditional just test that the ballot is valid).
%   Then, Lemma~\ref{lem:interm} can be proved similarly. We still have a problem with Lemma~\ref{lem:direct} when
%   we prove that Tally condition is implied by the diff-equivalence of $\biproc^D$.
%   The problem is: the ballot of $A$ and $B$ hard-coded in $\openBal$ does not necessarily matches
%   the ballot that will be actually cast at runtime by $A$ and $B$ because even though they have to follow the honest execution,
%   the can follow a different instantaition of $\th$ than $\tr^h$.
%   On the other hand, the test $x\neq$ ballot cast by $A$ or $B$ is necessary to avoid trivial false attacks for protocols
%   where ballot are cast in an id-leaking phase (\eg JCJ); indeed in that case, votes will be swapped for $A$ and $B$
%   in $\biproc^D$. To sum up, it's quite hard to cope with both features: ballot cast in id-leaking phase (we need
%   to avoid $\openBal$ open ballots cast by $A$ and $B$) $+$ unknown parts in $\th$ (we cannot statically predict
%   what will be the ballots cast by $A$ and $B$).

% The solution I preffer so far consists in doing an under-approximation of possible ballots $A$ and $B$ could cast
% and use that for the test in $\openBal$. The property we need is: if a valid ballot is not cast by $A$ and $B$
% then it must pass the conditional of $\openBal$ (the other direction is not required but if badly chosen then it can lead
% to false attacks). If we can achieve that such that the diff-equivablence of $\biproc^D$
% can be proved in practice then we're done.
% For the case of FOO with the label $y_1$, we can safely under-approximate possible ballots by just looking at the second projection:
% a ballot is of the form $\langle y_1; \com(k,v);k\rangle$, it suffices to test that $\proj_2(\ba)=\com(k,v)$.
% Indeed, the second projection does not depend on the specific instantiation of the honest trace.


% \textbf{(Dropping the strong fairness assumption and use the old weaker one)}
% \lucca{This is not implemented.}
% Remind that the older fairness assumptions requires that $A$ passes a phase $i$ (resp. cast a vote) if,
% and only if, $B$ passes a phase $i$ (resp. cast a vote).
% This might be more involved. I would tend to still assume that else branches are trivial (null processes
% or uniform error messages that does not depend on the vote\slash id).
% Lemma~\ref{lem:cf} is as before.
% Lemma~\ref{lem:interm} works as before  if $A$ casts a vote then $B$ as well and previous work applies.
% Otherwise, $A$ nor $B$ cast a vote. In that case, we do not need the tally condition and just perform the execution transformations
% and exploit the fairness condition to prove that after swapping, we still have two honest executions satisfying the fairness
% condition. The fairness condition is crucial here.
% Indeed, if there are two phases as in FOO and we start with $A$ passing the second phase while $B$ is not
% then after swapping we get $V^1(A,1),V^1(B,0),V^2(B,0)$ and no $V^2(A,1)$ (or at least it is not executed at all in the execution).
% But before applying the diff-equivalence, the process $V^1(B,1)$ was killed (\ie goes to an else branch reaching
% the null process or a final error output) so does $V^1(B,0)$ after swapping, we thus cannot consider the execution of all processes labeled
% $B$ and prove that it forms an honest execution. We can't glue together the different sub-process in each phase.
% Finally, Lemma~\ref{lem:direct} does not pose any problem.


% \textbf{(Allowing authorities to cross phases $+$ relaxed phase-oblivious).}
% \lucca{This has been implemented in the present version.}
% In order to be able to model protocols like JCJ \& Belenios, we need to
% consider authorities crossing phases. We also need
% to relax the phase-obblivious condition over honest traces. The new 
% condition being:
%  \begin{itemize}
%  \item for all input $\in(c,M)$ of $\th$ in a phase $i$, handles in $M$ must not come from phase having a different leaking labels from the one of $i$
%  \item a variable $X$ of $\th$ must not occur in two phases having
%    different leaking labels.
%  \end{itemize}
% I look though definitions and proofs and here are what we need to change (but it should work):
% \begin{itemize}
% \item in Dishonest Condition, we need to define $A^D$ in a similar way
% we defined $V^D$. And put $A^D$ instead of $A^i$ in $V_f$
% \item in proof of the main theorem: the glue between phase processes after swaps
% (Execution 4) can still be done with the relaxed version of phase-oblivious.
% \end{itemize}
% Remark: authorities can now cross phases. However, authorities like
% $A=\In(u,x);\mathrm{phase}_i;\Out(a,x)$ (\ie inputting on unsecure channel
% and outputting on anonymous channel; hence having a role of mixing)
% always break Dishonest condition. Because $A$ does not behave like $A^D$ at all.
% Still, this additional flexibility allows us to define Registar of JCJ
% for instance.
% First, we have to strengthen the control-flow condition:
% item 1 has to require that each time a voter process passes a conditional, a phase or the final cast then it must be the case 
% that it had an honest interaction so far involving actions not present in other honest interactions. So that's a strict extention of
% the present condition.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:


\section{Mechanisation and Case Studies}
\label{sec:caseStudies}
%%%%%%%%%%%%%%%%%%%%%% REVIEWS CCS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% [DONE]: I think that JCJ now makes clear the point about registration phase.
% Thank you very much for your clarifications. The rebuttal makes very clear that one of the main practical outcomes of the result is the fact that the authors can model the registration phase more accurately. I believe that this discussion is really missing in the paper. I would strongly suggest that the authors develop in detail one case study (Belenios or FOO for example), explaining why the registration phase is an issue and why they can cover it. For example, why ProVerif would fail if we simply add the registration phase to an existing model?
% >> Also: One thing that came out in discussion and might not be in another review -- to get more detail, you might focus deeply on one case study and have a second case study in light detail, relegating a third one to an appendix (or removing it).

%%%% TODO: Do we really need to add Helios ? The problem being that with the common abstraction of mixnet, the protocol becomes almost trivial...
% ``RB claims that ``[our] approach cannot cover a simple and key protocol like Helios (as acknowledged by the authors)''. We disagree. In Conclusion, we wrote: ``[...] we conjecture that considering revoting policies (e.g. ballot weeding in Helios as analysed in [28]) is a more intricate challenge.''. `` Well, it is still true that your approach cannot cover a simple and key protocol like Helios for the moment. I guess there are real issues otherwise you would have added it to the case studies.

%%%% [DONE] I think everything's clear for JCJ now and for Belenios, I've added the comparison to Swapping technique. Otehr citations are not relevant here.
% > As for the case studies, the paper does not explain in what detail the protocols in the case study have been analyzed. I understand that the main purpose of the paper is not the analysis of specific protocols, but understanding the modeling seems important to assess the usefulness of the overall approach.
% > - The experimentation section needs a serious discussion, and more examples
% > - Experimentation: please explain why do you consider that [16,26,28] do not provide a ProVerif proof for Helios/Belenios and why [6] is not a ProVerif proof for JCJ.

% Review: Claims about [6,16,26,28]?

% It is not the case that all symbolic analyses of a single protocol are
% equally precise and provide the same guarantees. Modellers choose to
% simplify some parts, cover only a subset of mechanisms, or adjust the
% threat model. In other words, having one symbolic model of some protocol
% does not mean that this protocol has been fully symbolically analysed,
% no further work on it is required or no further attack may be found.
	
% This is especially true for e-voting protocols that are highly complex
% systems. For instance, to the best of our knowledge, there is no
% symbolic analysis of some e-voting protocol that covers all of its
% aspects ((untrusted) registration, voting, tallying, revote policies,
% unbounded number of sessions). Therefore, when one claims to have
% symbolically analysed some protocol, one needs to precisely describe for
% which threat model and covering which aspects of the protocol (we tried
% to do so in Section 5.2 and 5.3).

% That being said, we now compare our treatment of our case studies with
% prior works.

% ### Comparing [6]
% Essentially, contrary to [6],
% (i) we fully take the registration phase into account instead of considering it
% perfect and completely hidden for the attacker (from [6]: "registration phase is
% trusted") and
% (ii) we establish security automatically instead of using manually and cleverly
% designed protocol-specific encodings.
% For more details, we refer to the corresponding paragraph in Section 5.2.

% ### Comparing [28]
% As explained in Section 5.2: "Again, contrary to [28], we took the
% registration phase into account." Importantly, [28] would not be able to
% do the same since their framework allows only one phase before the tally
% (i.e., the voting phase). Therefore, this is a real limitation and not a
% simple divergence of modelling choices.

% ### Comparing [16]
% [16] does not provide an automatic proof for Helios or Belenios but
% provide a *fully manual* proof while we aim at automated analyses
% (however they deal with the homomorphic version). Note that, as
% explained in Section 5.2, we model Belenios in its mixnet version rather
% than in its homomorphic version. This modelling choice is in line with
% [28] for instance (no automatic proof is provided for the homomorphic
% version).

% ### Comparing [26]
% Quoting [26]:
% "[ballot secrecy] is more delicate [...] ProVerif cannot prove this
% observational equivalence automatically. Therefore we proved it
% manually". Note that the swapping approach [20] (formally proved and
% implemented in [10]) has been devised to overcome this issue. We
% extensively compare ourselves to this swapping approach in sections 5,6.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\looseness=-1
We now apply our technique to several case studies, illustrating its
scope and effectiveness.
We show in Section~\ref{sec:case:verif} how \proverif can be used to automatically verify the three conditions.
In Section~\ref{sec:case:proto}, we present and benchmark several
e-voting protocols within our class, and explore several threat models.

\subsection{\luccaN{Verifying the conditions}}
\label{sec:case:verif}
\looseness=-1
We explain in this section how to leverage \proverif to
verify the three conditions via systematic encodings producing ProVerif models.
At the end of this section we present an algorithm that shows that
writing those encodings can be automated, but leave its implementation
as future work. 
We show that the time spent by the algorithm computing those encodings is negligible compared
to the time ProVerif spends to verify the produced models.
% writing these encodings is a straightforward systematic task that we
% will fully automate in the future.
%it would be possible to mechanize this verification as well.

\paragraph{\textbf{Guessing leaking labels}}
While it would be reasonable to require from users leaking labels for given e-voting protocols,
very simple heuristics to guess them allow to conclude on all our case studies.
First, the registration phase is often the first phase. Hence, guessing that the first phase is the only
id-leaking phase always allows to conclude on our examples.
Similarly, the following heuristic for guessing leaking labels of names proved to be precise enough:
if the name is output then it takes the leaking label of the corresponding phase,
if the name is used as signature key then it is id-leaking and
otherwise it takes the leaking label of the phase of its first use. 

%\noindent
\paragraph{\textbf{Sound Verification of The Tally Condition}}
It is possible to verify the Tally Condition by analysing the diff-equivalence
of the biprocess $\biproc$ in presence of an oracle opening all ballots
(\ie $\openAllBal$ defined in Section~\ref{sec:condi:dishonest}).
The diff-equivalence of $\biproc^T = \biproc\uplus\{!\openAllBal\}$ implies the diff-equivalence
of $\biproc$ and
for all executions and valid ballots, item 2 of the Tally Condition.
We formally state and prove the former
in Appendix~\ref{ap:caseStudies}. We also describe in Appendix~\ref{ap:caseStudies}
an independent way to establish the condition based on
trivial syntactical checks that always imply the Tally Condition but that is less tight.

%\noindent
\paragraph{\textbf{The Dishonest Condition}}
% \lucca{it was quite hard to try to explain this without going into too much details about \proverif and its events.
% Roughly it can be done as in the Oakland'16 paper but, in contrast,
% we don't have a full mechanized tool to verify the conditions. So maybe, we just need to show roughly how to do it
% as a methodology and refer to examples for more details?}
We explain how to verify item (1) of the 
Dishonest Condition using {\em correspondence properties of events} that \proverif can verify.
%
We can equip the e-voting system $\S$ with events that are fired with
each input and output, and that contain exchanged messages
and session annotations.
Then, the fact that a specific voter passes a phase or casts a valid
ballot can be expressed by such events.
Further, the fact that a specific voter had an honest interaction (up to a certain phase or not)
can be expressed as implications between events.
For instance, if $\th=\Out(c,w).\In(c,\langle X; w\rangle)$ then one would write
$
\mathtt{EventIn}(a,\langle x; y_w\rangle)\Rightarrow
\mathtt{EventOut}((\id,v),y_w)$ where $\id,v$ are voter annotations
and $a$ is a role session annotation, $x$ and $y_w$ are variables and open messages in
events must pattern-match with the exchanged messages.
Note that this technique has already been used in a different context
in the tool UKano~\cite{HBD-sp16}.
Next, the fact that such an honest interaction should be disjoint can be established
by verifying that outputs from honest executions should be different modulo $\theo$.
%\lumN{comment in the source}
% \lucca{todo: elaborate on that; to be honest this last item is completely trivial for all our case studies:
% it suffices to observe that an output of an honest interaction always contain a piece of data specific
% to that interaction (\eg vote, nonce, id of the voter) and cannot be fed to two inputs that take part
% to two disjoint honest interaction}
% same reason as the Honest Relations Condition.
% \smallskip{}

%\noindent
\paragraph{\textbf{Algorithm for verifying all conditions}}
The input format of our algorithm is a valid ProVerif file containing at least:
public constants modelling $\phi_0$ and $\mathcal{V}$,
function and reduction rules modelling $\Psi_b$ and $\Extract$
and a biprocess for each role describing $V,\roles_o$ and the idealised execution.
Formally, the left part of a biprocess associated to a role $A$ %$A\in\{V\}\cup\roles_o$
should model $A(\vect{n^\id},\vect{n}^v)$ while the right part should model
$A^{\forall}(\vect{n^\id},\vect{n}^v)$ where input messages are replaced by messages received in
the honest execution.
Moreover, constants in such messages corresponding to second-order
variables in the honest execution shall be given distinguished names. Therefore, the right part
of those biprocesses both specify the idealised execution and the honest trace.
Hence, the user is just required to specify an e-voting protocol according to Definition~\ref{def:evoting}.


\looseness=-1
As explained, from such a file, the honest trace $\th$ can be retrieved (by syntactical equality between inputs and parts of outputs)
and the fact that $\th$ is phase-oblivious can be checked via a linear-time syntactical check.
Exploiting the right part of the given biprocesses, the algorithm can compute $A^{\forall}(\vect{n^\id},\vect{n}^v)$
and thus $A^{k}(\vect{n^\id},\vect{n}^v)$ for all $1 \le k\le k_f$.
Using the aforementioned heuristic, the algorithm guesses leaking labels for names and phases
and deduce $\roles^v(\vect{n^\id},\vect{n}^v)$ and 
$\roles^\id(\vect{n^\id},\vect{n}^v)$.
The algorithm then deduces $\biproc$ and, using the two functions modelling $\Psi_b$ and $\Extract$,
it also deduces $\biproc^T$.
When $\th$ does contain second-order variables, the algorithm computes $\biproc^D$ from
the left part of the given biprocesses and roles $A^{\forall}(\vect{n^\id},\vect{n}^v)$.

Finally, the algorithm produces two or three files:
(a) a file containing $\biproc^T$, (b)
a file containing correspondence properties using encoding described
above for modelling the Dishonest Condition, item (1),
and, (c) if $\th\neq\tr^h$,
a file containing $\biproc^D$.
Then, ProVerif is used to verify the diff-equivalence
of $\biproc^T$, all the correspondence properties and, when necessary, diff-equivalence of $\biproc^D$.
If all checks hold then the algorithm deduces that the given e-voting protocol ensures ballot secrecy.

All the described tasks the algorithm should perform are linear-time syntactical manipulations of the given
input data. Therefore, the cost of computing the three ProVerif files is negligible compared to
the time spent by ProVerif for verifying the files. In our benchmarks, we thus only measured the latter.

% Along with the relation condition we eventually impose, we will obtain that there is no leak from
% identity to vote-leaking phase data. Altogether, we can deduce that there is no leak from identity
% to ``id-free'' pieces of data.
% A small picture of all possible leaks an how we can prevent them all is given if Figure~\ref{fig:leaks}.
% We will eventually requre that each valid ballot
% should be either: (i) id-free (\ie the ballot cannot be linked to any identity)
% or (ii) the result of a complete honest interaction of some voter.





% \lucca{Oldies below that are not of solution because they do not address challenge n. 1}
% We assume a notion of idealized vote-message: for each syntactical output of type (2), we associate
% a skeleton (and different skeletons may be related).
% For instance the second output of FOO is of type (2) and we associate $\com(k,x)$ and we associate $x$ to the third
% output.
% Then, the idea is to require that for any execution $\S\sint{\tr}(\p;\phi_i\cup\phi_v)$
% where $\phi_i$ contains only messages of type (1) and $\phi_v$ only messages of type (2)
% then $\phi_i\cup\phi_v\estat\phi_i\cup\phi_v^i$ where $\phi_v^i$ is obtained by filling holes
% of skeletons. The idea here is that, by design, the frame on the right has \textbf{no relation} between
% messages of type (1) and messages of type (2). If this one is $\estat$ with the real frame, we obtain what we wanted (avoiding
% attacks of type (1).(a)).
% The same argument works for attacks of type (1).(b) (we also avoid them) because we fill holes of skeletons
% with fresh identities (there is no revote by design).

% \lucca{Another idea that does not work:}
% We define a new process $V^\id(A,v_1,v_2)$ of identity $A$ that uses the vote $v_1$ in id-leaking phase but
% vote $v_2$ in vote-leaking phase and we verify that $V^\id(A,v_1,v_2)\ |\ A_i\eint V^\id(A,v_1,v_1)|\ A_i$.
% Problems are: how to compute messages of the vote-leaking phase? If we use the honest trace to build skeleton
% of such messages and filling holes we may miss potential harmful behaviors in $\Else$ branches.


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
\renewcommand{\check}{\cmark}
\newcommand{\nope}{\xmark}
\newcommand{\nonterm}{\ding{61}}


\subsection{Case Studies}
\label{sec:case:proto}
% \lucca{this is a first iteration. I just gather citations and quick description of the threat models.
% I see two options then:
% (i) either we give Alice \& Bob descriptions of each protocol and precisely describe threat models or
% (ii) we just give citation and quick summary. Other remarks:
% 1. do we talk about tightness ? a. no ``false attack'' b. when introducing error, a conditions does not hold and
% is quite explicit on the problem.}
We now describe the different e-voting systems we verified with our approach
and compare (when possible) with the current state of the art % the direct encoding approach
(see \Cref{fig:benchmarks}).
We first give in-depth descriptions of the JCJ and Lee case studies, and
then list other case studies for which we only give
high-level descriptions.

%
We benchmark the verification times of our approach vs.~the only 
comparable prior approach, \ie, the {\em swapping
technique}~\cite{vote-CSF16}. The swapping technique uses
a direct encoding of ballot secrecy in
\proverif with synchronisation barriers where processes can be swapped.
Other approaches are not automated \luccaN{(require non systematic manual efforts)},
or do not deal with the protocols and threat models we consider
(see discussions in~\Cref{sec:back:stateArt}).
\luccaN{Notably, while Tamarin is expressive enough to describe our case studies~\cite{dreier2017beyond},
it does not yet allow to automatically prove them%
%\footnote{One might tackle this by devising some non-trivial and
%non-systematic helping lemmas.}%
.}
%
We summarise our results in~\Cref{fig:benchmarks} and provide all our \proverif models at~\cite{pv-code}.
%
%  We compare verification times in seconds
% between our approach (\ie verification of all conditions) and the direct
% 	encoding (\ie using
% the swapping technique~\cite{vote-CSF16}).
% \smallskip{}

\begin{figure*}[t]
  \centering
	% \resizebox{\columnwidth}{!}{
          \begin{tabular}[h]{|l|c|r|r|}
          	  \hline
		& 
		  & \multicolumn{2}{c|}{Analysis time in seconds} \\
		  \cline{3-4}
		  Protocol & Ballot Secrecy & Swapping & Our approach \\
    \hline
    \hline
FOO     & verified & 0.26     & 0.04   \\
Lee 1   & verified & 46.00    & 0.04   \\
Lee 2   & verified & \nonterm & 0.05   \\
Lee 3   & verified & \nonterm & 0.01   \\
Lee 4   & attack   & 169.94   & 6.64   \\
JCJ     & verified & $\star$  & 18.79  \\
Belenios& verified & $\star$  & 0.02   \\
    \hline
          \end{tabular}
        %}
	\caption{Analysed protocols and results.
Tests were performed using \proverif 1.94 on a single 2.67GHz Xeon core with 48GB of RAM.
\nonterm\xspace indicates non-termination within 45 hours or consumption of more than 30GB of RAM.
We use $\star$ to indicate the approach yielded spurious attacks,
	which implies that the analysis is inconclusive.
All our \proverif models are available from~\cite{pv-code}.
	}
%\vspace{-10pt}}
  \label{fig:benchmarks}
\end{figure*}

\paragraph{\bf JCJ Protocol~\cite{juels2005coercion}}
\label{sec:caseStudies:JCJ}
% CONTEXT AND REF
We analysed the JCJ protocol~\cite{juels2005coercion} used in the Civitas system~\cite{civitas-SP08}.
It has been designed to achieve a strong notion of privacy (\ie coercion-resistance) but we limit our analysis to
ballot secrecy.

\newcommand{\cred}{\mathit{cred}}
\newcommand{\skr}{\sk_R}
\newcommand{\skt}{\sk_T}
\newcommand{\pkt}{\pk_T}
\newcommand{\pkr}{\pk_R}
\newcommand{\PET}{\mathsf{PET}}
\newcommand{\lab}[1]{\raisebox{-12pt}{#1}}

% DESCRIPTION IN MORE DETAILS
The JCJ protocol is depicted in Figure~\ref{fig:JCJ}.
In a first phase, the voter requests a credential by disclosing its identity to a registrar who replies on a secure channel
with a fresh credential $\cred$. In a second phase, the registrar sends to the tally the created credential randomised and encrypted
with the tally's public key and signed with the registrar's signing key. This will be used by the tally to authenticate
ballots from registered voters.
Then, in a third phase, the voter casts his ballot who takes the form of a complex Zero Knowledge (ZK) proof whose the public part
(first argument of $\mathsf{ZK}$) includes
(i) a randomised encryption of her vote and (ii) a randomised encryption of her credential and
whose the private part (second argument) contains the knowledge of the underlying credential and vote.
The tally can then verify the ZK proof and perform a Plaintext Equality Test (PET) between part (ii)
of the ZK proof and some encrypted credential that has been signed by and received from the registrar
(at this point, the ballot is verified and can be published on the bulletin board).
Finally, the encrypted vote can be opened, possibly after mixing, to reveal the vote.

\input{JCJ}


% OUR MODELING CHOICES AND THREAT MODEL
We adapted the modelling from~\cite{vote-CSF08-maffei} (including the modelling of the ZK proofs)
to consider a strictly stronger threat model (for ballot secrecy).
% We fully model the registration phase in which voters request and then
% obtain credentials from the registrar.
% We modelled the first part of the tally that should filter out ballots by verifying that they contain a credential that have been issued by the registrar.
% We model the second part of the tally that open such valid ballots.
We assumed that the registrar and the tally are honest, but that their secret keys $\skr$ and $\skt$ are compromised.
We let the tally output verified ballots on the public channel $c_b$
(thereby also taking the role of the ballot box).
A voter requests a credential by revealing its identity in the clear but receives its credential on a secure channel.
Voters send ballots on an anonymous channel.
Naturally, the first phase and $\cred$
are id-leaking, while the two last phases and $r_V^1,r_V^2,r_R$ can be considered vote-leaking (following the heuristic from Section~\ref{sec:case:verif}).
We were able to establish our three conditions automatically with ProVerif and therefore establish ballot secrecy.

% WHILE OUR METHOD OUTPERFORM PREVIOUS
In comparison, the direct encoding of ballot secrecy with the swapping technique~\cite{vote-CSF16} fails to establish ballot secrecy.
We have identified two main, independent reasons. 
First, when considering an unbounded number of honest voters, one also needs to consider an unbounded number of sessions of the registrar (this holds for the tallier as well).
This is incompatible with equipping the registrar with synchronisation
barriers %defeating the whole purpose of the swapping approach
yielding spurious attacks in practice (registrar sessions for A and B should be swapped after the first phase).
While it may be possible to manually apply the barriers elimination theorem~\cite{vote-CSF16}, an independent problem inherent to
the swapping technique still prevents us to conclude.
Indeed, even when considering the simplest scenario with only two honest voters and no dishonest voter,
the swapping technique on our model yields a spurious attack. This is caused by a systematic limitation of the latter technique when ballot secrecy relies
on the freshness of data produced in previous phases (here $\cred$).
We explain the underlying reason in Section~\ref{sec:rel:swapping}. Those two limitations are still problematic
when the two last phases are collapsed and removing all phases is not successful either.
% only two voters and two sessions of R
% 1: R crossing phases and unbounded of nb. of R so problem here,
% 2: so let's still try with bounded number of sessions: let's say two voters only: then sync barriers can be placed for R and Tally. Still a problem because the property relies on the freshness of $\cred$. But because of abstraction made by compiler of swapping method, this freshness is lost (ProVerif consider valid some replays that are were not considered before 'compilation') lead to systematic false attacks inherent to the swapping approach.

% COMPARISON WITH PRIOR WORK
We note that unlike the automatic analysis of JCJ from~\cite{vote-ESO16}, we took the registration
phase into account. Importantly,~\cite{vote-ESO16} would not be able to
do the same since their framework allows only one phase before the tally
(i.e., the voting phase). Therefore, this is a real limitation and not a
simple divergence of modelling choices.
%
Note also that~\cite{vote-CSF08-maffei} analyses JCJ
for coercion-resistance. % a stronger property than ballot secrecy.
However, they considered a simpler threat model in which the registration
phase is completely hidden from the attacker.  Moreover, their approach required
manually and cleverly designed protocol-specific encodings
since one has to ``explicitly encode in the biprocess the proof strategy'' according to~\cite{vote-CSF08-maffei}.

\paragraph{\bf Lee \textit{et al.} Protocol~\cite{DKR-jcs09}}
\label{sec:caseStudies:LEE}
We now support the claim that our class of e-voting protocols is expressive enough
to capture a large class of threat models
by analysis several threat models
for Lee \textit{et al.} (variant proposed in~\cite{DKR-jcs09}).
% DESCRIPTION WITH ENOUGH DETAILS (less than JCJ but sufficient to make our point on large class of threat models ??)?
This protocol contains two phases. In the registration phase,
each voter encrypts her vote with the tally's public key, signs the ciphertext and (output~i) sends both messages
to the registrar.
The registrar verifies the signature, re-encrypts the ciphertext using a fresh nonce
and (output~ii) sends to the voter this signed ciphertext along with a Designated Verifier Proof (DVP) of re-encryption.
The voter can then verify the signature and the DVP.
%\toRM{
Finally, in the voting phase, the voter (output~iii) sends its ballot,
which is the previously received signed re-encryption.
% Note that the registrar re-encrypts and builds this DVP to enforce coercion-resistance
% (the strongest privacy property for e-voting protocols); \ie even if the voter is actively coerced,
% the voter can pretend to have voted for a different candidate by modifying the DVP.
%}
We reused and adapted ProVerif models from~\cite{vote-CSF16}.

\noindent
\textit{Lee 1.}
The first threat model we consider is the only one analysed in~\cite{vote-CSF16}.
It considers the registrar's signature key and the tally's private key
corrupted, and considers infinitely dishonest voters.
The channel of outputs (i) and (ii) % (\ie between voters and registrar)
is assumed to be untappable
(\ie everything is completely invisible to the attacker)
% , even the fact that a communication happened
while the channel of output (iii) is anonymous.
% As already explained (see \Cref{sec:class:proto}), such an anonymous
% channel is modelled by an unsecure channel which is uniform for all voters
% (and by not including the identity of voters in the output).
Since the registrar's signing key is corrupted, the dishonest voters do not need to have access to
registrar sessions (they can be played by the environment).
Similarly, % since the tally's private key is known to the attacker,
there is no need to explicitly model the tally.
% when verifying ballot secrecy directly in \proverif.
This considerably simplifies the models one needs to consider, partly explaining
the effectiveness of the swapping technique~\cite{vote-CSF16}  (46s).

\noindent
\textit{Lee 2.}
\looseness=-1
In this scenario, we no longer consider the tally's key corrupted. When verifying ballot secrecy without our conditions, it is thus mandatory
to explicitly model the tally. This change to the model causes \proverif
to not terminate on the direct encoding of ballot secrecy with the swapping technique. 
%
We thus tried 
% We also considered a variant of the direct encoding approach, in
% which we
to approximate the model. We collapsed the two phases into one, which
enables \proverif to terminate in 45.33 seconds on the direct-encoding.
Unfortunately, this approximation does not always solve the problem: if the
security relies on the phases, one would obtain spurious attacks. For
instance, removing all phases causes
\proverif to return a spurious attack. More importantly, this approximation
is not sound in general (we may miss some attacks).
% \lumN{I have a concrete counter-example, I may add it in appendices.}
%
In contrast, the verification of our conditions
only takes a fraction of a second without the above approximation.

\noindent
\textit{Lee 3.} % Continuing {\it Lee 2.},
\looseness=-1
We additionally consider a
secure registrar signing key.  We now need to explicitly
model a registrar for dishonest voters.  As for the previous
% \toRM{threat}
model, \proverif is unable to directly conclude.  After
collapsing phases, it terminates in 269.06 seconds. In contrast, our
approach concludes in under 0.1 second.

\noindent
\textit{Lee 4.}
We modify the previous threat model and weaken the 
output channel's security (i) to be
insecure instead of untappable. In this case, ballot secrecy no longer holds.
\proverif returns an attack on the tally condition (verified using the ballot-opening oracle;
see \Cref{sec:case:verif}). Relying on the latter,
we can immediately infer the attack on ballot secrecy.
% When using \proverif on the direct-encoding, we obtained the attack in 169.94 seconds.
%
% \toRM{
% Indeed, 
% the attacker can eavesdrop the signed encrypted vote $v$ sent by a voter $\id$ at output (i),
% extract the ciphertext, signs it with the key of a dishonest voter and sends this
% to the registrar authority to get a re-encryption of the same vote signed by the registrar.
% The latter can be cast as a valid ballot.
% This ballot contains the same vote $v$ that $\id$ is willing
% to cast but is different (modulo $\theo$) from the ballot of $\id$ since based on different randoms.
% This interaction violates ballot secrecy because the tally's outcome
% will not be the same when starting with $\S$ or $\S_r$.
% When verifying our conditions, \proverif quickly returns an attack on the tally condition (verified using the ballot-opening oracle
% as explained in \Cref{sec:case:verif}). By looking at the attack trace,
% we can immediately infer the previous,
% real attack on ballot secrecy.
% When using \proverif on the direct-encoding, we obtained the attack in 169.94 seconds.}
% we are unable to obtain a result. And after collapsing phases, \proverif returns an attack in 18.89s.
%In this case, we observe a smaller gap between our approach and a direct verification. This is as expected since
% \lum{comment on the smaller gap? (easier to find attack than establish security)}
%
% \lum{discussion in the source}

% \noindent
% \textit{Discussion.}
% \lucca{if needed; possible discussions:
% how divide \& conquer geatly simplifies model in our approach (see below),
% comment the fact that very quickly, ProVerif does not terminate on the full models in teh direct encoding
% approach,
% gap is smaller when there is an attack
% }
% \bigskip{}
% \lucca{Remarks:}
% 1.it seems that by taking threat models of Lee and sligthly introducing erros (and thus attacks) also lead
% to big gap. Maybe something to add.

% 2. newt interesting threat models (todo when paper is in better shape):
% TM5 $=$ TM 4 but whith no dishonest voters: it ensures ballot secrecy. I think that the hack ``collapsed phases'' no longer works.
% Might be good for us. Moroever, it does not allow the drastic simplification when verifying honest relations conditions
% due to divide \& conquer.
% And more generally, look at all TM that are at the borders of the threat models hierarchy diagram of Lee.

% 3.Self-criticism (limitations?):
% \begin{itemize}
% \item first Lee threat models are ``subsumes'' by Lee 1. since Lee 1 considers a strictly stronger attacker and BS holds.
% However, one may consider those other threat models and add aspects that would break security for Lee 1. but not for them. It would
% be great to have that to avoid previous criticism
% \item comparisons are a bit unfair because: (i) (Lee) in this case divide \& conquer aspect of our approach is dramatically
% effective since the registration phase that is playing on private channels only will be simply cut out;
% (ii) we compare a fully automatic method with
% our approach which is more a methodology with ``recipes'' to verify conditions than a fully automatic method. For instance, point (i)
% above allows drastic simplification because a human look at the model...
% \end{itemize}

% \item JCJ$\slash$Civitas (max. coercion-resistance): quite interesting and simple scheme. Vote \& Go scheme. Civitas is just an extention of that scheme.
% \item Norwegian protcol: has been used in real election. Steve Kremer acknowledge that this is typically tke kind of 
%   non-{\em Vote\&Go}\footnote{This means that the voter should be active during only one phase. Then may just perform some checks on public data (\eg BB). Accoridng to Steve Kremer this is a necessary condition to consider the scheme practical. We could argue that asking for the voter to perform checks on public data or asking him to remain active is all the same...} protocol that does not lie in their class.
% \item Maybe Helios$\slash$Belenios, mixnet or homomorphic version. (max ballot secrecy).
%   One interesting difficulty here would be to be able to modelize ballot weeding 
%   (\ie solution proposed by Cortier \& Smyth to fix the ballot independence issue of Helios).
% \end{enumerate}
% See papers in Section~\ref{sec:refs} to find references of these protocols (and modelization in symbolic model)
% and examples given in Secion~\ref{}.


\paragraph{\bf Other Case Studies}
\label{sec:caseStudies:others}
% \noindent
% \textit{FOO.}
We verified the three conditions for FOO~\cite{fujioka1992practical} as described in our running example
(with a dishonest registrar and considering dishonest voters).
We use the same modelling and threat model as in~\cite{vote-CSF16}.

% \noindent
% \textbf{Lee \textit{et al.}.}
% We analyzed the variant of Lee first presented in~\cite{DKR-jcs09} and whose
% verification has been mechanised in~\cite{vote-CSF16}. We focus on this protocol in the next section
% and show that our approach allows to verify numerous threat models and thus conduct a comprehensive
% security comparison of threat models.
% \lum{todo: remove this or do it}


% We model the registration phase where voters obtain credentials from a registrar. We model the first part of the tally that should filter out ballots by verifying that they contain a credential that have been issued by the registrar. We model the second part of the tally that open such valid ballots.
% %
% Threat model 1: registrar (R) and Tally (T) are honest. Keys kT and kR are known by the attacker. First message from voter to registrar revealing ID is unsecure, the message R sends back to the voter (containing the credential) is private, and all other messages are sent on an anonymous channel.

% \noindent
% \textit{Belenios.}
We analysed the Belenios protocol~\cite{cortier2014election} (in its
mixnet version),
which builds on the Helios protocol~\cite{adida2008helios}, and considered the same threat model as for JCJ.
Again, contrary to~\cite{vote-ESO16}, we took the registration phase into account. Note that the swapping technique failed
to conclude because of spurious attacks for similar reasons as for JCJ.
% We model the registration phase where voters obtain credentials from a registrar. We model the first part of the tally that should filter out ballots by verifying that they contain a credential that have been issued by the registrar. We model the second part of the tally that open such valid ballots.
% %
% Threat model 1: registrar (R) and Tally (T) are honest. Key kR is known by the attacker. First message from voter to registrar revealing ID is unsecure, the message R sends back to the voter (containing the credential) is private, and all other messages are sent on an anonymous channel.


% \noindent
% \textit{Okamoto.}
We finally discuss the protocol due to Okamoto~\cite{okamoto1996electronic} as modelled in~\cite{DKR-jcs09}.
This protocol features trap-door commitments that ProVerif is currently
unable to deal with. % Therefore, it is currently impossible
% to automatically verify this protocol.
However, this protocol lies in
our class and our theorem thus applies. This 
could both ease manual verification and future automated verification
(\eg recent analysis~\cite{dreier2017beyond}).
% (support for trap-door commitments might be available soon for the
% Tamarin prover).


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:



\section{Related Work}
\label{sec:back:stateArt}
% \lum{I tend to cite journal versions when they exist:
% but \cite{cortier2013attacking} has first been published at CSF'11;
% \cite{DKR-jcs09} is a journal version of papers published at ESOP'05 and CSFW'06. }


As mentioned before, diff-equivalence is known to be too 
imprecise to analyse vote-privacy via a direct encoding
(acknowledged \eg in~\cite{DKR-jcs09,vote-CSF16,vote-ifip,vote-CSF08-maffei}).
%\lum{a quick reminder of why is that is commented in the source}
%So far, the main technique to address this problem has been the {\em swapping approach}.
%We first compare ourselves to this approach and then discuss
%other approaches.

%\medskip
%\noindent
\paragraph{\textbf{Swapping technique}}
\label{sec:rel:swapping}
 % Problem is ProVerif verifies a more fine-grained equivalence: diff-equivalence.
 %  Diff equivalence can be seen as the observational equivalence notion \lucca{where attacker is given the structure of the
 %    processes to be verified along the execution}. When using diff-equivalence, we thus give more relations since
 %  the attacker can relate all actions coming from the same voter\slash authority.
 %  In the case of ballot secrecy for eVoting protocols, this is a problem because the attacker can then almost always
 %  relate id to vote using those new links. See example from the intro: the protocol features a registration phase (leaking the voter's identity)
 %  followed by a voting phase (leaking the vote). If the attacker is given a relation between actions of Alice leaking its identity
 %  in the first phase and actions of Alice leaking its vote in the second one, it can obviously link id to vote relying on this
 %  new spurious relation.
 %  This problem is well-known and acknowledged (Maffei CSF'08, Smyth CSF'16, Cortier ESORICS-16 (hum check this one, not sure), \etc).
 % \smallskip{}
The swapping technique originates
from~\cite{vote-ifip}, and 8 years later, was formally proven and
implemented in 
\proverif~\cite{vote-CSF16}.
It aims to improve the precision of diff-equivalence for protocols with {\em synchronisation barriers}.
% which, intuitively, are phases in the e-voting
% context\footnote{Synchronisation barriers (or strong phases) need all
% 	processes \toRM{in the multiset} % CC: Clear from context, orisunderstood anyway
%         to be ready to move to the next phase while
% 	(weak) phases allow to ``drop'' processes that are not ready. In
% 	our context, those notions intuitively coincide since
% 	we consider fair executions whose voter processes are never
% 	dropped.}.
The main idea is to guess some process permutations 
at the beginning of each barrier and then verify a
modified protocol based on these permutations.
We give an example showing this mechanism in Appendix~\ref{sec:app:swapping}.
Theoretically, the permutations do not break trace equivalence since they transform configurations
into structurally equivalent configurations.
This approach is only compatible with replication in a very constrained way:
all barriers above and below a replication must be
removed\toRM{\footnote{Intuitively, this is necessary to consider
		finitely many permutations.}},
which reduces precision.
% \lumN{\luccaN{already in CSF sub. we pointed to appendix. Not really self-contained :(}}
%
%
% Def of phases, compilation into processes without phases, application to FOO (\& DAA). FIrst automatic proof for FOO (to check).
  % Because of that they cannot deal with (arbitrary number of) revotes. Another problem is the state space explosion.
  % If $n_1$, $n_2$, $n_3$, etc. are the number of parallel processes at phases $1$, $2$, $3$, etc. Then the set of processes the compiler produces is
  % $\Pi_j n_j!$ (\eg 3 phases, $n_i=3$ leads to 216 biprocesses to verify).
%
% \toRM{\noindent
% The permutations are implemented using private channels on
% which permuted processes exchange their data.}
Given a model with barriers, the front-end %\toRM{of ProVerif}
first generates several biprocesses without barriers,
each corresponding to a possible swap strategy (\ie the permutation
done at each barrier); note that the number of such strategies grows exponentially with the size of the system (number of phases or number of roles).
The equivalence holds if one of the produced biprocesses is diff-equivalent (proven in~\cite{vote-CSF16}).
\luccaN{Similar techniques~\cite{dreier2017beyond} have been used in the tool Tamarin relying on multisets. Essentially, all agents are
put in a multiset at synchronisation barriers and a rule allows to shuffle this multiset before moving to the next phase.
Therefore, the same limitations \wrt replications hold.
Moreover, Tamarin will also have to explore all possible swaps.
% Moreover, Tamarin has issues to deal with primitives such as 
}
\lumN{full arguments in comments}
% COMMENT:
% - Proofs of e-voting in tamarin not really autoamtic (non-trivial typing lemmas) 
% - instead of explicitely swap votes at sync. barriers, Dreier et al. put voters in multisets, allowing Tamarin to
%   check if the equivalence holds for at least one swap. In the end, this is really close to the swapping
%   approach in ProVerif and thus suffer from the similar limitation. Notably, what happens in presence of dishonest voters
%   and authorities 'crossing phases' ? Then, one should allow a swap of authorities but 'unbounded swap' -> same problem...
% - use of primitives like blind signature is extremely limited, as soon, as one wants to consider dishonest voters,
%   then some open chains cannot be removed with typing lemmas (essentially, attacker can get sign on any number of blind
%   and I belive that no typing lemma can state that message attaker can thus learn cannot be coerced to nonces, keys, etc.)
%
  % On the theoretical side:
  % Definitions of a applied-$\pi$ with phases (barriers). Formal definition
  % of a compiler removing phases and adding extra stuff (new processes in parallel) allowing permutations at beginning of phases.
  % This compiler heavily uses private channels.
  % Proof of soundness of the compiler: the compilation generates a set of processes, if one of them is diff-equ
  % then the original one was as well. Implem of the compiler into ProVerif. Case studies.
  % Thanks to that, analysis of eVoting schemes: FOO (ballot secrecy), Lee {\it et. al} ({\bf first} proofs of ballot secrecy \& receipt-freeness). 
%
  % Limitations: First: still a gap between trace equ. and diff-equ even with this extention. Second: They can deal with replication but in a very constrained
  % way. Basically, every phase underneath replications are removed by the compiler leading to a big loss of precision.
  % Because of that they cannot deal with (arbitrary number of) revotes. Another problem is the state space explosion.
  % If $n_1$, $n_2$, $n_3$, etc. are the number of parallel processes at phases $1$, $2$, $3$, etc. Then the set of processes the compiler produces is
  % $\Pi_j n_j!$ (\eg 3 phases, $n_i=3$ leads to 216 biprocesses to verify).
%
%
  % The main idea to tackle this problem is the swapping idea dating back to IFIPTM'08.
  % The idea consists in allowing swaps between processes at beginning of phases and thus hiding the structural links.
  % You need to test all possible permutations.
  % It has been formally defined (\ie synchronisation barrier notion)
  % and proved in (Smyth CSF'16) and is now fully implemented in ProVerif.
  % When given a model with sync. barrier, the front-end of ProVerif starts by generating several biprocesses without barrier
  % each one corresponding to one possible swap strategy (\ie the swaps to do at each barrier).
  % The equivalence holds if, and only if, one of the produced biprocess is diff-equivalent (that's the main theorem of (Smyth CSF'16)).
 % 
%
The fact that no replication can be put under a barrier notably forbids to model authorities crossing phases
(because one needs to consider unbounded number of sessions of them) as well as threat models
where no dishonest voter is considered for the same reason. %(since then $\roles_V$ would not comply with the above limitation).
The swapping approach also suffers from systematic precision issues when the security relies on the freshness of data created in previous phases.
Indeed, the compiler introduces many new internal communications in the produced biprocesses. %  that allow the different sub-processes
% to swap their internal data at synchroniwation barriers. 
However, the very abstract treatment of internal communication used by ProVerif
causes the tool to also explore the possibility of swapping
data with an old session whose data has already been swapped before. We
consider this to be a significant limitation,
which manifests itself as 
% This is a systematic caused the
spurious attacks \eg the ones for JCJ and Belenios (see Figure~\ref{fig:benchmarks}); the credential being
the fresh data coming from the registration phase and used during the voting
phase.
% We rely on the above remarks to provide support for
% the claims we made in the introduction about the different problems the
% swapping approach cannot tackle while our approach can.
We provide more details in Appendix~\ref{sec:app:swaprestr}.

%\medskip

%\noindent
\paragraph{\textbf{Small-attack property}}
\label{sec:rel:others}
%\noindent
%\textbf{Small-attack Property.}
A different line of work is to devise small attack properties, as
for example in~\cite{vote-ESO16}
for ballot secrecy. 
They show that proving ballot secrecy for some specific finite-scenarios implies ballot secrecy for the
general, unbounded case. 
The focus in~\cite{vote-ESO16} is on complex ballot weeding mechanisms,
as used for example in Helios~\cite{adida2008helios}.
%They are the first to propose automated verification for such mechanisms.
In contrast to our work, they require that the pre-tally part 
contains only
one voting phase % . Moreover, the single voting phase 
that must be action-determinate (same actions yield
statically equivalent frames). This approach is therefore unable to deal with e-voting protocol
models that involve more than one phase, like the ones we consider in \Cref{sec:caseStudies}.
Moreover, considering only one phase greatly simplifies the verification since
it hides the diff-equivalence problems mentioned
previously.
%reducing the problem to finite scenarios do not solve
Moreover, the finite-scenarios still lead to state space explosion problems.
Because of this, they were unable to automatically verify the JCJ
protocol, even without modelling the registration phase.
% \smallskip{}

% \noindent
% \toRM{\textbf{Case-by-case Analysis.}
% On a case-by-case basis, it is sometimes possible to
% %``encode the proof strategy in the biprocess''
% directly prove ballot secrecy using diff-equivalence and dedicated encodings as it is done in~\cite{vote-CSF08-maffei}.
% They verified a strictly stronger privacy property than ballot secrecy (\ie coercion-resistance)
% on JCJ for a specific threat model (simpler than the one we consider in \Cref{sec:caseStudies}).
% However, their approach is not systematic and requires non-negligible human efforts since one has to
% ``explicitly encode in the biprocess the proof strategy''. 
% }
%\lum{this is a quote from the paper}
% Very quickly: better def of coercion-resistance, {\textbf{first}} mechanized proof of coercion-resistance of JCJ in ProVerif
% (but this is not a generic method).
%\bigskip{}
%\smallskip{}


%\noindent
\paragraph{\textbf{Privacy via type-checking}}
\label{sec:rel:typeChecking}
A sound type system for proving trace equivalence has
been proposed~\cite{cortier2017type}, which seems a promising approach.
% for future work.  %% It gave the feeling the work is only preliminary
This work reuses diff-equivalence as an approximation of trace
equivalence and thus suffers from its limitations.
% we partly address. % is not the goal of this work that  the same kind of approximation.
% On diff-equivalence: this is tricky because their Helios case study focus only on the voting phase.
% There is only one phase so diff-equivalence limitations do not cause any problem. But as soon as one
% wants to model the full protocol including previous phases (where voters' identity may be disclosed),
% then one cannot use their method off-the-shelf because they do not address those limitations.
Moreover, it is limited to standard primitives ((a)symmetric encryption,
signatures, pairing, and hashing),
which means that it currently cannot deal with our case studies, since
the protocols in our case studies use primitives that are not supported
by this method yet.
% Finally, it does not deal with private channels nor non-fixed keys (\eg fresh keys) which limits
% the threat models and protocols that can be analysed.
% \lum{it seems fair to say that it also limits protocols (\eg quid
% protocols where registrar generate voters' keys ?) CC: I don't think we
% need to say more, and I wanted to be balanced too, so I would leave this
% out.}
%\smallskip{}

%\lum{Shall we mention this work rom which we took main inspiration ?}
%\lum{but then the submission is no longer double-blind ;)}
%Although not specifically related to e-voting,
The analysis method we develop in this paper borrows the
methodological approach of~\cite{HBD-sp16}: devise sufficient conditions implying a complex privacy
property hard to verify, via a careful analysis and categorisation of known attacks.
However, we target a different class of protocols and property and devise different conditions.
% the resulting
% sufficient conditions are different.
%
%\lum{commented in the source are some lines on \cite{vote-rf} but more computational}
% It's not proper symbolic verification (since based on rF$^*$)}
% Finally,  \cite{vote-rf}
% Type-based verif in rF$^*$. Not in the symbolic model, not automatic verif but a 
% (generic) framework. Application to Helios. They can deal with the homomorphic version of it!  
  % A \textbf{theorem} is claimed: Universal verifiablity $+$ individual verifiablity $+$ ballot independence $\Rightarrow$ End-to-End
  % verifiability.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:


\section{Conclusion}
\label{sec:conclusion}
% \lucca{Consider recall limitations of the swap approach we described in sections~\ref{sec:intro},\ref{sec:background} and 
%   recall\slash explain why our approach does not suffer from the same drawbacks.}
%
%%% Recall core contributions
We presented three conditions that together imply ballot secrecy. They
proved to be tight enough to be conclusive on
 several case studies. % we analyzed. 
Verifying ballot secrecy in a modular way via our conditions constitutes
a new approach which outperforms prior works:
we cover a greater class of e-voting protocols and threat models, and
the analysis is more efficient.
% \lum{maybe more aggressive, more meat on the ``positive'' paragraph? }

% TODO:  (maybe resolve TODOs in conclusion once intro is done?)
% More generally, RB wrote that "It is yet difficult to be convinced that
% the approach allows to cover a much wider class of protocols". We would
% like to recall our arguments.  Our approach tackles *theoretical*
% limitations of previous approaches that are described in Section 6 (with
% more detailed discussions in Appendix E). We also explain *practical
% implications* of having tackling those limitations in terms of modelling
% capabilities: registration phases can now be faithfully modelled, threat
% models with no dishonest voter can now be considered, false attacks
% stemming from random reuses are reduced. We also show how those
% improvements can be exploited to model more faithfully real-life case
% studies (sections 5.2, 5.3). As explained above, those protocols have
% already been studied before but we explain how our new approach enables
% us to study them much more precisely and for various threat models. In
% the end, resulting guarantees our approach can deliver are stronger.
% <!-- Comparing ourselves to [10] (swapping approach in PV): swapping approach is not tailored to e-voting protocols so their approach deals with "arbitrary" protocols. Moving on to e-voting protocols and restricting ourselves to our definition of what's an e-voting protocol (Def 3.8), I think that we can safely say that our class contains their class. Further, we have case studies that can be analysed with ours but cant be with their method. -->

% TODO:
% RB claims that "[our] approach cannot cover a simple and key protocol
% like Helios (as acknowledged by the authors)".
% We disagree. In Conclusion, we wrote: "[...] we conjecture that
% considering revoting policies (e.g.ballot weeding in Helios as analysed
% in [28]) is a more intricate challenge.". To the best of our knowledge,
% only [28] deals with such faithful modelling of Helios (i.e., taking
% into account revoting policies) and that's because they devised a small
% attack property. We do not acknowledge that Helios is out of the scope
% of our approach. For instance, we were able to analyse a mixnet version
% of Belenios without revote policies (Belenios is a strict extension of
% Helios).
% <!-- [lucca, OPTIONAL]: We actually added Proverif models at [3] showing that it can be analysed by our approach (todo, not done). If reviewers think it should be included, we wil reflect that in the final version. -->


% TODO: (theorem applies independently of crypto prinitives in use)
% RB is concerned with our modelling choice of our phase.
% Our modelling of phases (called stages or weak phase in the literature
% [9, 20]) is actually standard and reflect phases as implemented in the
% tool ProVerif. Hence, we exactly followed [28] and are very close to
% [9,6,20].
% <!-- (the only difference being that we used ProVerif dialect instead of proper applied-pi calculus). -->

%%% Future work
Our new approach has also opened
several avenues for future work.
%% no revote + no revote policy. Real challenge is revote policies (notably: we only can model local validity test over the BB)
First, our notion of tally is currently limited.
Hence, our method is currently unable to deal with revotes. While adding
revotes might be directly achievable,
we conjecture that considering revoting policies (\eg ballot weeding in Helios as analysed in~\cite{vote-ESO16})
is a more intricate challenge.
% Fairness could be relaxed (-> at each beginning of phase, A is killed iff B is killed)
% Second, we conjecture that our restriction to {\em fair} executions used in our definition of ballot secrecy
% (which is in line with \eg \cite{vote-ESO16})
% could possibly be relaxed. In prior works~\cite{vote-CSF16,vote-ifip} based on
% strong phases (\ie, synchronisation barriers),
% the corresponding assumption would be that, at each beginning of phase, processes $P_A,P_B$
% of voters $\id_A$ and $\id_B$ are non-null.
% One could target an even weaker assumption by requiring that, at the beginning
% of each phase,
% $P_A$ is null, if, and only if, $P_B$ is so.
% % We do not have a fully automatic method yet (as in \cite{HBD-sp16} (Oakland'16)
% even though our method is systematic and an algorithm has been presented, our method currently requires a
% minimal amount of manual pre-processing. This could be
% addressed, \eg, by developing a simple front-end of ProVerif taking an e-voting protocol as input and 
% returning models suitable for the verification of each of our conditions following
% encodings described in \Cref{sec:case:verif}.
% We may target more complex privacy properies for e-voting protocols
Furthermore, our notion of tally cannot deal with homomorphic tallying
and only produces a set of votes, while e-voting protocols satisfying {\em verifiability}
should also produce verification data (\eg ZK proofs of correct decryption). We would like to extend our class of e-voting protocols accordingly.
% todo add: our class of tally is rather weak (\eg for verifiable tally, the output is a set of votes $+$ some verification DATA (\eg ZK of correct mixnet, decryption, etc...) We do not deal with that. It seems, that's not possible with unbounded sesion/voters (that was the whole goal of ESORICS'16 but still).
Second, our notion of fairness and our Dishonest Condition currently lack
precision in the presence of certain mixnet roles.
For instance, a degenerated mixnet such as 
$M=\phase{1}\In(c,x).\phase{2}\Out(c,\sdec(x,k))$ (where $c$ is public)
% \lumN{if the first channel was private,  everything would be fine. So it is not that bad. Keep this limitation and
% future work?}
currently introduces spurious attacks that are not prevented by our fairness condition
and that are detected by our Dishonest Condition (note that the problem disappears
when $c$ is private).
% \lumN{More details in comments. I keep it short but maybe that makes this useless and too scary...}
% Indeed, the attacker is able to avoid that a specific voter correctly plays a full session by
% dropping the corresponding session of the mixnet. Hence, the initial problem we tackled with the fairness
% assumption arises again.
% To address this, we would need to sterngthen the fairness condition and impose thinghs on authority sessions
% and then weaken dishonest conditions to take that into account.
     %we would like to adapt our method so that it can fully deal with mixnets. Indeed, mixnets todo
Third, we believe that our conditions can be adapted to enforce more complex privacy-type 
properties in e-voting protocols such as {\em receipt-freeness} and {\em coercion-resistance}~\cite{DKR-jcs09,vote-CSF08-maffei}.
Fourth, we want to implement our algorithm for verifying all conditions as a ProVerif front-end.
\lumN{other limitations and future work in comments.}
% 1. When $\th\neq\tr^h$, the Dishonest Condition item (2): diff(B^D) is required. This is really strong and seems to be an overkill.
%    we would like to relaxed it a bit mainly reducing it to purely readhability properties as Dishonest item (1).
% 2. investigate applying our method to bounded verif coming from small attacks property (ESORICS'16


%%% Finish with a general, inspirational long-term goal ? ;)
We think that the modular {\em privacy via sufficient conditions}
methodology we presented advances the state-of-the-art for
the automated analysis of privacy-related properties, and paves the way for
further developments.

% \paragraph*{Limitations (=future work?)}
% Limitations of our class:
% \begin{itemize}
%%% Below is discussed in revote paragraph above
% \item we cannot deal with non-local validity tests over BB. For instance, the weeding technique of (M5,JCS'13) for Helios
% consists in verifying that, in all sub-messages of all ballots in BB, there is no cipher text appearing twice.
% This is important to avoid replay attack of the form: $\langle c_2; c_1\rangle$ built from $\langle c_1;c_2\rangle$.
% \end{itemize}

%%% Below is discussed in revote paragraph above
% \textbf{(Dropping the strong fairness assumption and use the old weaker one)}
% \lucca{This is not implemented.}
% Remind that the older fairness assumptions requires that $A$ passes a phase $i$ (resp. cast a vote) if,
% and only if, $B$ passes a phase $i$ (resp. cast a vote).
% This might be more involved. I would tend to still assume that else branches are trivial (null processes
% or uniform error messages that does not depend on the vote\slash id).
% Lemma~\ref{lem:cf} is as before.
% Lemma~\ref{lem:interm} works as before  if $A$ casts a vote then $B$ as well and previous work applies.
% Otherwise, $A$ nor $B$ cast a vote. In that case, we do not need the tally condition and just perform the execution transformations
% and exploit the fairness condition to prove that after swapping, we still have two honest executions satisfying the fairness
% condition. The fairness condition is crucial here.
% Indeed, if there are two phases as in FOO and we start with $A$ passing the second phase while $B$ is not
% then after swapping we get $V^1(A,1),V^1(B,0),V^2(B,0)$ and no $V^2(A,1)$ (or at least it is not executed at all in the execution).
% But before applying the diff-equivalence, the process $V^1(B,1)$ was killed (\ie goes to an else branch reaching
% the null process or a final error output) so does $V^1(B,0)$ after swapping, we thus cannot consider the execution of all processes labeled
% $B$ and prove that it forms an honest execution. We can't glue together the different sub-process in each phase.
% Finally, Lemma~\ref{lem:direct} does not pose any problem.



% \noindent
% \textit{(Refine the opening oracle)}
% \lum{todo: this is much too long; try to summarise and put details in appendix}
% When the final ballot cast by voters occurs in id-leaking phases, a valid,
% honest ballot of $A$ yields different votes when on the left or on the right of
% $\biproc$. % ($v_0$ on the left and $v_1$ on the right).
% Giving this ballot to an $\openAllBal$ instance allows distinguishing
% the left side from the right side.
% Nevertheless, the tally condition may hold because item 2 of the condition
% only concerns dishonest ballots (\ie that are not cast by $A$ or $B$).
% In this case, we need to ensure that the \toRM{opening} %% CC: Clear from context
% oracle does not open ballots
% resulting from an honest execution of $A$ or $B$. To define
% such an oracle, we would need to statically know which ballot $A$ or $B$
% will cast for fixed names $\nID{i},\nV{i}$ by following the honest trace.
% However, if $\th\neq\tr^h$
% then honest ballots may depend on the
% chosen instantiation of the honest trace. Therefore, the present refinement
% can only be used when $\th=\tr^h$.
% % be applied when $\th\neq\tr^h$.
% %
% % More formally, we now assume $\th=\tr^h$
% Assuming the former,
% we let $b_A^i$ %(resp. $b_B^i$)
% be the message corresponding to the
% ballot cast by $V(\nID{A},\nV{i})$ %(resp. $V(\nID{B},\nV{i})$)
% in the idealised execution for $(\nID{A},\nV{i})$; % (resp. $(\nID{B},\nV{i})$).
% and similarly for $b_B^i$.
% It suffices to let the oracle open valid ballots different from $\ba_A^0,\ba_B^1$
% on the right and $\ba_A^1,\ba_B^0$ on the left.
% We let $\Psi_{\lnot A}[x]$ be
% $\choice{\mathsf{neq}(x,\ba_A^0)}{\mathsf{neq}(x,\ba_A^1)}$  (\ie $\mathsf{neq}\in\Sigma_d$ is as expected)
% and symmetrically for
% $\Psi_{\lnot B}[x]$.
% We let $\Psi_{\lnot AB}[x]$ be $\AND(\Psi_{\lnot A}[x],\Psi_{\lnot B}[x])$.
% We can finally define the oracle decrypting ballots:
% $\openBal=\phase {k_f} \In(c_u,x).\Let\, z=\Psi[x]\,\In\,
% \Let\,z'=\Psi_{\lnot AB}[x]\,\In\,
% \Let\,v=\Extract[x]\,\In\,\Out(c_u,v)).$
% The diff-equivalence of $\biproc^D_r = \biproc\uplus\{!\openBal\}$
% still implies the Tally Condition (as shown in Appendix~\ref{ap:caseStudies})
% but this implication is now tighter.
%
%
% \textbf{(Explanations).}
% The additional oracle is to make sure that the attacker cannot forge ballots different from the ones $A$ and $B$
% cast that are meaningfully related to data from id-leaking phase. Meaningfully related means:
% the attacker observes a difference maybe using the oracle when on the left or when on the right
% of the biprocess. For instance, assume that the attacker is able to
% build a valid ballot $b$ from data produced by
% $P^1(A,\nV{0})$ such that $b$ contains the same vote $v_0$ and
% the first phase is id-leaking.
% Then he can use the oracle and test that it indeed answers $v_0$.
% This behavior leads to different observable data on the right because on this side,
% the ballot $b$ is built using data from
% $P^1(A,\nV{1})$ and thus contains the vote $v_1$. Hence the test ``outputs of the oracle on my ballot
% is $v_0$'' fails to hold on this side breaking the diff-equivalence of $\biproc^D$.
%
% On the contrary, we allow the attacker to build new ballots meaningfully related to
% data coming from vote-leaking phase. Indeed, those ballots correspond to ``blind copy'' and cannot be
% exploited by the attacker as explained above. This is reflected by the fact
% that votes are the same on both sides in vote-leaking phase.
%\lum{fourth way to verify tally commented}
%
% \noindent
% \textbf{Strong Secrecy of vote in presence of oracle.}
% \lucca{This is only prospective, drop this if not conclusive.}
% Maybe (?) it suffices to prove that the following biprocess is diff-equivalent:
% $$
% \{(\nu v_1.\nu v_2.
% P^\id(A,\choice{v_1}{v_2})\ |\ 
% P^v(A,v_1)\}\cup
% \{\openBal\}\cup
% \{!A\}_A
% .
% $$

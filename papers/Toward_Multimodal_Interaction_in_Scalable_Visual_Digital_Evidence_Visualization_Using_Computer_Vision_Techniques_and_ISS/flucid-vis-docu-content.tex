% -----------------------------------------------------------------------------
% ICPRAI'18: Serguei: DONE
% ICPRAI'18: Jash: DONE
\section{Introduction}

%%\marginpar
%%{
%%\teaser
%%{\\
%% XXX: softbody-opengl-slides-cisse09 / \shortcite{softbody-teaching-opengl-slides}
%\begin{figure*}[htpb!]
%%\begin{figure}%[htpb!]
%%\hrule\vskip4pt
%%\begin{center}
	%\subfigure
	%%{\includegraphics[width=\commonfigwidth]{images/nat42dfg-3d}
	%{\includegraphics[width=\commonfigwidth,height=1in]{images/ilucid-dfg-dot-yimin-enhanced}
	 %\label{fig:ilucid-dfg-dot-yimin-enhanced}}
	%%\subfigure
	%%{\includegraphics[width=\commonfigwidth]{images/nat42dfg}
	 %%\label{fig:2d-softbody-object}}
	%%\subfigure
	%%{\includegraphics[width=\commonfigwidth]{images/ilucid-dfg-dot-yimin}
	 %%\label{fig:3d-softbody-object}}
	%\subfigure
	%{\includegraphics[width=\commonfigwidth]{images/observation-3d}
	 %\label{fig:observation-3d}}
	%%\subfigure
	%%{\includegraphics[width=\commonfigwidth]{images/bubble-installation-1}
	 %%\label{fig:3d-softbody-object}}
	%\subfigure
	%{\includegraphics[width=\commonfigwidth]{images/tangible-kinect-2-white}
	 %\label{fig:tangible-kinect-2-white}}
	%%\subfigure
	%%{\includegraphics[width=\commonfigwidth]{images/sleuthid-slide}
	 %%\label{fig:sleuthid-slide}}
	%% ISS
	%%\siggraphpaper{
	%\subfigure
	%{\includegraphics[width=\commonfigwidth]{images/bubble-installation-1}
	 %\label{fig:bubble-installation-1}
	%}
	%%}
	%%\subfigure
	%%{\includegraphics[width=\commonfigwidth]{images/tangible-kinect-2-white}
	 %%\label{fig:tangible-kinect-2-white}}
	%\subfigure
	%{\includegraphics[width=\commonfigwidth]{images/bubble-installation-2}
	 %\label{fig:bubble-installation-2}}
	%\subfigure
	%{\includegraphics[width=\commonfigwidth]{images/bubble-installation-3}
	 %\label{fig:bubble-installation-3}}
%\caption{From data-flow graphs to scalable illimitable space visualization and management of digital forensics cases}
%\label{fig:dfg-to-iss-evolution}
%%\end{center}
%%\hrule\vskip4pt
%\end{figure*}
%%}
%%\siggraphpaper{\vspace{-15pt}}
%%}

We propose a scalable management, visualization, and evaluation of digital evidence using the 
modified interactive 3D documentary component of the Illimitable Space System (ISS) to represent,
semantically link, and provide a usable interface to digital investigators.
%
%Lucid programs are data-flow 
%programs and can be visually represented as data flow graphs (DFGs) and 
%composed visually.
%
%{\flucid}, a {\lucid} dialect, is a language to specify and
%reason about cyberforensic cases. It includes the encoding of the
%evidence (representing the context of evaluation) and the
%crime scene modeling in order to validate claims against the model
%and perform event reconstruction, potentially within large swaths
%of digital evidence. To aid investigators to model the scene and
%evaluate it, instead of typing a {\flucid} program, we propose
%to expand the design and implementation of the Lucid DFG programming
%onto {\flucid} case modeling and specification to enhance the
%usability of the language and the system. %and its behavior in 3D.

The cyberforensic analysis is one phase of the cybercrime investigation
where the investigators strive to produce credible inferences based on evidential
information. The source of this information is usually the phases that
precede the analysis such as evidence acquisition and encoding. Also, this
information can come from an esoteric set of resources that involves computers
but is not limited to that seem fit as an evidence by the
investigators~\cite{mokhov-phd-thesis-2013,flucid-dfg-viz-pst2011}.

{\lucid} programs are data-flow programs that can be visually composed
and illustrated as data-flow graphs as well. {\flucid} is one such {\lucid}
dialect that enables investigators to specify and reason about cyberforensic
cases. It represents the context of the evaluation of the evidences' by encoding
them along with witness stories, evidential statements and modeling the crime scene
to cross-validate claims against the model and perform event reconstruction,
potentially within large swaths of digital evidence~\cite{mokhov-phd-thesis-2013,flucid-dfg-viz-pst2011}.

% TODO: per Jash: smoothen out transition
% ------------------------**********----------------------

In 2004, Gladyshev~\cite{gladyshev-phd-2004} introduced the first formal approach to cybercrime investigation.
Their approach uses Finite State Automata to describe the digital system as a Finite State Machine
for event reconstruction. However, it has an associated learning curve and quite complex
for investigators without a formal background in computer science.
{\flucid} is designed to explicitly address these drawbacks and aims to be usable,
expressive, sound and complete. 

One of the many goals of {\flucid} is usability via scalable visualization of enormous data
under investigation. Recently, there have been significant improvements in the domain of modern
2D and 3D virtual reality environments, which can be easily navigated via a variety of
different multimodal interaction techniques.
{\flucid} aims to up the ante by providing such usability improvements by leveraging
modern multimodal techniques in virtual and augmented reality space for the investigators instead of writing
a {\flucid} program to navigate seamlessly. A combination of gestures, audio commands,
eye gaze and hardware controllers are potential candidates to provide navigational
and interaction abilities to the investigators. It will enable us to extend the
Lucid DFG programming onto {\flucid} case modeling and specification~\cite{mokhov-phd-thesis-2013,flucid-dfg-viz-pst2011}.

% TODO: per Jash: smoothen out transition
% ------------------------**********----------------------

%%(\xsp{sect:flucid-higher-order-context})
The purpose here is to determine the applicability of these findings to
{\flucid} and investigation case management. It is also natural to want a convenient
and usable evidence visualization, their semantic linkage and the appropriate
hardware for the same. The visualization requirements in the context of
{\flucid} revolve around the different levels of the case knowledge abstraction,
its representation, aggregation, and the operational aspects as the final long-term
goal of this proposal. It encompasses everything from the finer detailed representation
of hierarchical contexts to {\flucid} programs, to the documented evidence and
its management. It also includes its linkage to programs, to evaluation and
to the management of {\gipsy} software-defined networks along with an ability to
arbitrarily switch between those views combined with usable multimodal
interaction~\cite{mokhov-phd-thesis-2013,flucid-dfg-viz-pst2011}.

% -----------------------------------------------------------------------------
% ICPRAI'18: Jash: DONE
% ICPRAI'18: Serguei: DONE
\section{Related Work}

In the context of data-flow programming languages, there are quite a few 
research works and proposals that revolve around graph-based visualizations. 
The work of Faustini proved in particular a visualization of any {\ilucid} program as a
{\dfg}~\cite{denotational-operational-semantics-dataflow}.

In 1995, Jagannathan defined one of the first graph-based visualizations 
proposals for {\lucid} programs. He defined different graphic intensional and 
extensional models for {\glu} programming~\cite{glu-graphical-models-1995}. 
Further, in 1999 Paquet's doctoral work with multidimensional intensional programs 
extended on it, followed by the visual parallel programming idea of Stankovic, 
Orgun, \emph{et al}.~\cite{paquetThesis}~\cite{visual-parallel-programming-2002}.

In 2004, Ding provided practical implementation of 
Paquet's foundational work within {\gipsy} in the form of 2D
{\dfg}s~\cite{paquetThesis,yimin04}~\cite{yimin04}. Ding provided an automatic bidirectional 
translation of the intensional programs between their textual and graphical 
representations by employing  \tool{lefty}'s GUI ({\graphviz}'s) and \tool{dot}'s
%languages~\cite{flucid-dfg-viz-pst2011}.
languages~\cite{flucid-dfg-viz-pst2011,graphviz,dot-language}.
 
Mokhov proposed an idea of one such ``3D editor'' within
{\ripe}~\cite{mokhov-mcthesis-book-reprint10} to visualize, control
communication patterns and load balancing in {\gipsy}.
%
The editor's idea is to render graphs in a 3D space to allow its
users to redistribute demands visually in case of imbalance of
workload among the workers.
%
It can be thought of as a virtual 3D remote control accompanied by
a miniature expert system which can trigger the planning, 
caching and load balancing algorithms to learn and perform
efficiently every time a related {\gipsy} application is run.

Similarly, several authors put forward their works on visualizing the 
configuration, formal systems and load balancing with corresponding graph 
systems
\cite{%
sim-viz-resource-alloc-control,%
visual-config-representation,%
logical-reasoning-with-diagrams,%
graph-transform-visual-languages,%
diagramatic-formal-system-euclidean}.

These works defined key concepts that are consistent with
{\gipsy}~\cite{flucid-dfg-viz-pst2011} visual mechanisms especially, the General Manager 
Tier ({\gmt})~\cite{ji-yi-mcthesis-2011}. Rabah provided the initial 
configuration management and PoC visualization for {\gipsy} nodes and tiers 
via the above mentioned {\gmt}~\cite{graph-based-gmt}.

In 2012, Tao {\etal}.\ proposed another interesting work of 
relevance on the visual representation of event sequences, reasoning, and 
visualization of EHR data~\cite{event-seq-reasoning-vis-ehr-2012}.
%
Wang {\etal}.\ put forward a temporal search algorithm for event 
visualization of personal history~\cite{temporal-pattern-search-algo-vis-2012}.
Monroe {\etal}.\ noted the challenges of specifying intervals and absences 
in temporal queries and approach those with the use of a graphical
language \cite{spec-intervals-absence-temporal-vis-2013}. This could be of particular 
use for \emph{no-observations}~\cite{mokhov-phd-thesis-2013} in {\flucid} case.
%
A recent novel HCI concept of documentary knowledge visual representation and 
gesture- and speech-based interaction in the \emph{Illimitable Space System}
(ISS) was put forward by Song~\cite{msong-phdthesis-2012} in 2012. A multimodal 
case management interaction system was proposed for the German police called 
\emph{Vispol Tangible Interface: An Interactive Scenario Visualization}
\footnote{\url{http://www.youtube.com/watch?v=_2DywsIPNDQ}}.

Building upon the above-mentioned works, we propose to illustrate nested evidence, 
crime scene and the reconstructed event flow after revaluation in the form of a 2D or 3D {\dfg}.
The direct impact is to aid the forensic investigators by providing a scalable visualization, 
management of evidence modeling, encoding by {\flucid}~\cite{%
mokhov-phd-thesis-2013,%
%flucid-isabelle-techrep-tphols08,%
flucid-imf08,%
%flucid-blackmail-hsc09,%
%flucid-printer-case-hsc09,%
flucid-printer-case-icdf2c-2011,%
%flucid-raid2010,%
%self-forensics-jooip-flucid-assl,%
self-forensics-through-case-studies} and subsequently its evaluation by {\gipsy}~\cite{flucid-dfg-viz-pst2011}.

% -----------------------------------------------------------------------------
% ICPRAI'18: Jash: DONE
% ICPRAI'18: Serguei: DONE
%\section{Visualization Example Prototypes}
\subsection{Conceptual Visualization Design}

Deriving from the related research work in context to visualization of {\lucid} programs, 
a conceptual example of a 2D {\dfg} that corresponds to a simple {\lucid} program produced by
Paquet~\cite{paquetThesis}. Presently, the rendering of the same is by Ding in 2004~\cite{yimin04}  
within the {\gipsy} environment~\cite{flucid-dfg-viz-pst2011}.

%% DONE: gipsy-flucid-dfg / \cite{flucid-dfg-viz-pst2011}
%\begin{figure}[htpb]
%	\centering
%	%\includegraphics[width=\columnwidth]{images/nat42dfg}
%	\includegraphics[width=\fixedcolumnwidth]{images/nat42dfg}
%	%\caption{Canonical Example of a 2D Data Flow Graph-Based Program}
%	% DONE: John v11:
%	%\caption{Canonical example of a 2D data flow graph-based program \cite{paquetThesis}}
%	%\caption{Canonical example of a 2D dataflow graph-based program~\cite{paquetThesis}}
%	\caption{Canonical example of a 2D dataflow graph-based program}
%	\label{fig:nat42dfg}
%\end{figure}

In \xfp{fig:observation-3d} is the
conceptual model of hierarchical nesting of the evidential
%statement $es$ context elements, such as
observation sequences $os$, their individual observations $o$ (consisting
of the properties being observed $(P,min,max,w,t)$, details of which are discussed
in the referenced related works and in \cite[Chapter 7]{mokhov-phd-thesis-2013}).
%
These 2D conceptual visualizations are proposed
to be renderable at least in 2D or in 3D via an interactive interface to allow modeling complex
crime scenes and multidimensional evidence on demand. The end result is envisioned to look like
either expanding or ``cutting out'' nodes or complex-type results as
exemplified in \xf{fig:nat42dfg-3d}\footnote{cutout image credit is that of Europa found on Wikipedia
\url{http://en.wikipedia.org/wiki/File:PIA01130_Interior_of_Europa.jpg} from NASA}~\cite{flucid-dfg-viz-pst2011}.

%% DONE: gipsy-flucid-dfg / \cite{flucid-dfg-viz-pst2011}
%\begin{figure}[htpb]
%	\centering
%	%\includegraphics[width=\columnwidth]{images/ilucid-dfg-dot-yimin}
%	\includegraphics[width=\fixedcolumnwidth]{images/ilucid-dfg-dot-yimin}
%	%\caption{Example of an Actual Rendered 2D Data Flow Graph-Based Program with Graphviz \cite{yimin04}}
%	%\caption{Example of an actual rendered 2D data flow graph-based program with Graphviz \cite{yimin04}}
%	%\caption{Example of an actual rendered 2D dataflow graph-based program with Graphviz \cite{yimin04}}
%	%\caption{Example of an actual rendered 2D {\dfg}-based program with {\graphviz}~\cite{yimin04}}
%	\caption{Example of an actual rendered 2D {\dfg}-based program with {\graphviz}}
%	\label{fig:ilucid-dfg-dot-yimin}
%\end{figure}

%% DONE: gipsy-flucid-dfg / \cite{flucid-dfg-viz-pst2011}
\begin{figure}[htpb]
	\centering
	%\includegraphics[width=\columnwidth]{images/nat42dfg-3d}
	\includegraphics[width=\fixedcolumnwidth]{images/nat42dfg-3d}
	%\caption{Modified Example of a 2D Data Flow Graph-based Program with 3D Elements
	 %(cutout image credit is that of Europa found on Wikipedia
		%\url{http://en.wikipedia.org/wiki/File:PIA01130_Interior_of_Europa.jpg} from NASA)}
	%\caption{Modified example of a 2D data flow graph-based program with 3D elements~\cite{flucid-dfg-viz-pst2011}}
	%\caption{Modified example of a 2D dataflow graph-based program with 3D elements~\cite{flucid-dfg-viz-pst2011}}
	%\caption{Modified conceptual example of a 2D {\dfg} with 3D elements~\cite{flucid-dfg-viz-pst2011}}
	\caption{Modified conceptual example of a 2D {\dfg} with 3D elements}
	  %\footnote{(cutout image credit is that of Europa found on Wikipedia
		%\url{http://en.wikipedia.org/wiki/File:PIA01130_Interior_of_Europa.jpg} from NASA)}}
	\label{fig:nat42dfg-3d}
\end{figure}

% DONE: gipsy-flucid-dfg / \cite{flucid-dfg-viz-pst2011}
\begin{figure}[htpb]
	\centering
	%\includegraphics[width=\columnwidth]{images/observation-3d}
	\includegraphics[width=.5\columnwidth]{images/observation-3d}
	%\caption{Conceptual Example of a 3D Observation Node.
		%{Cutout image credit is that of Europa found on Wikipedia
		%\url{http://en.wikipedia.org/wiki/File:PIA01130_Interior_of_Europa.jpg} from NASA}}
	%\caption{Conceptual example of a 3D observation node.}
	%\caption{Conceptual example of linked 3D observation nodes~\cite{flucid-dfg-viz-pst2011}}
	\caption{Conceptual example of linked 3D observation nodes}
		%\footnote{Cutout image credit is that of Europa found on Wikipedia
		%\url{http://en.wikipedia.org/wiki/File:PIA01130_Interior_of_Europa.jpg} from NASA}}
	\label{fig:observation-3d}
\end{figure}

% XXX: gipsy-flucid-dfg / \cite{flucid-dfg-viz-pst2011}
%%BNOIEEE
%\begin{figure}[htpb]
	%\centering
	%%\includegraphics[width=\columnwidth]{images/bpel-example}
	%\includegraphics[width=\fixedcolumnwidth]{images/bpel-example}
	%%\caption{Example of a BPEL Graph with Asynchronous Flows \cite{bpelse}}
	%\caption{Example of a {\bpel} graph with asynchronous flows \cite{bpelse}}
	%\label{fig:bpel-example}
%\end{figure}
%%ENOIEEE

%% XXX: gipsy-flucid-dfg / \cite{flucid-dfg-viz-pst2011}
%\begin{figure}[htpb]
	%\centering
	%\includegraphics[width=\columnwidth]{images/nested-context-concept}
%%	\includegraphics[width=.74\textwidth]{nested-context-concept}
%%	\caption{Nested Context Hierarchy Example for Cyberforensic Investigation~\cite{flucid-isabelle-techrep-tphols08,flucid-imf08}}
	%%\caption{Nested Context Hierarchy Example for Cyberforensic Investigation~\cite{flucid-imf08}}
	%%\caption{Nested Context Hierarchy Example for Cyberforensic Investigation~\cite{flucid-imf08}}
	%%\caption{Nested Context Hierarchy Example \cite{flucid-imf08}}
	%\caption{Nested context hierarchy example \cite{flucid-imf08}}
	%\label{fig:nested-context-concept}
%\end{figure}

% -----------------------------------------------------------------------------
% ICPRAI'18: Jash: DONE
% ICPRAI'18: Serguei: DONE
%\section{3D Visualization of {\flucid}}
%\section{Visualization of {\flucid}}
\section{Multimodal Visual Encoding of {\flucid}-based Evidence}
\label{sect:3d-viz}

Data visualization, not only in the context of cybercrime investigation with 
{\flucid}, but in almost every other domain as well provides numerous 
advantages in terms of deducing inferences, spotting anomalies and 
recognizing patterns.  However, specifically in case of {\flucid} and 
investigating cybercrimes, it provides additional usability~\cite{interaction-design-3ed} enhancements to 
aid investigators to illustrate and define semantic links among the related 
evidence.

% -----------------------------------------------------------------------------
% ICPRAI'18: Jash: DONE
% ICPRAI'18: Serguei: DONE
% +++--: gipsy-flucid-dfg / \cite{flucid-dfg-viz-pst2011}
%\subsection{3 Dimensions}

Furthermore, the need to visualize forensic cases, 
digital evidence, and related specification components revolve around 
providing usability enhancements to aid the investigators. Additionally, putting the 
program (specification) in 3 dimensions, especially in the modern
and affordable augmented and virtual reality spaces (AR/VR) will help in structuring the program 
along with the case well arranged in a virtual environment with the digital 
evidence enclosed within 3D spheres. Moreover, navigable in depth to whatever 
levels of detail possibly via one of the multimodal interactions, although in 
the given example via clicking, issuing voice commands, gazing, or
gesturing~\cite{flucid-dfg-viz-pst2011}.
%(see \xf{fig:observation-3d})~\cite{flucid-dfg-viz-pst2011}.

In case of event reconstruction, 
in particular, the illustrations and comprehension of operational semantics 
and demand-driven models are much better along keeping in mind their depth 
and complexity. Ding's work provides navigational capabilities from a graph 
to subsequent subgraphs via extending complex nodes to their definitions as 
in \emph{whenever} (\api{wvr}) or \emph{advances upon}
(\api{upon}), their reverse operators, forensic operators, and others~\cite{flucid-dfg-viz-pst2011}
found in \cite[Chapter 7]{mokhov-phd-thesis-2013}.

% -----------------------------------------------------------------------------
% ICPRAI'18: Jash: DONE
% ICPRAI'18: Serguei: DONE
%\subsection*{Requirements Summary}
%\subsection{Requirements Summary}
\subsection{Augmented System Requirements}

In order to realize the envisage of {\dfg} visualization of {\flucid} 
programs and their evaluation by {\gipsy} some immediate considerations are 
discussed below~\cite{flucid-dfg-viz-pst2011}:

% DONE: gipsy-flucid-dfg / \cite{flucid-dfg-viz-pst2011}
\begin{itemize}
\item
Hierarchical evidential statements with deeply nested contexts should be 
visualized~\cite{flucid-dfg-viz-pst2011}.

\item
Intentional-imperative hybrid nodes need to be placed in {\dfg}s
combining fragments of {\lucid} and {\java} programs~\cite{flucid-dfg-viz-pst2011}.
%
Previous research works by {\gipsy} R\&D did not address the aspects to 
augment the \api{DFGAnalyzer} and \api{DFGGenerator} from Ding's work in some 
fashion to provide support for hybrid {\gipsy} programs. However, to address 
this one can think to add an ``unexpandable'' imperative {\dfg} node to the 
graph, but depth-wise it won't be just enough to click their way through.  
Thus, considering possibilities to make it usable hence expandable recent 
enhancements in {\graphviz} and {\gipsy} can be leveraged to generate {\flucid}
code from the {\dfg} and vice versa~\cite{flucid-dfg-viz-pst2011}.
%
%Recent {\graphviz} versions support 
%features that are consistent with our needs at present and with {\jooip}~\cite{aihuawu09},
%{\java}~5 {\AST}s can be made available with embedded {\lucid} fragments. 
%While generating the \tool{dot}'s code {\AST} these fragments can be tapped 
%into as well~\cite{flucid-dfg-viz-pst2011}.

%\item
%A {\java}-based wrapper is desired to enable native use of Ding's~\cite{yimin04}
%{\dfg} editor within {\gipsy} (also {\java} based) as well as within IDE 
%environments like Eclipse or Netbeans as a plug-in~\cite{flucid-dfg-viz-pst2011}.

\item
Rabah's work on visualizing load balancing and communication control patterns 
for tasks in Euclidean space may as well be leveraged via the GGMT~\cite{graph-based-gmt}.

\item
The ability to switch among views such as {\dfg}, evidence, and control, 
etc., is required as well.

\item
In flat-screen, touch-screen, augmented reality or projected environments, 3D DFG interactions
are to support click and touch or voice-based call-outs as well as gestures
to link or assemble some of the evidence~\cite{iss-multimodal-case-study-docu-vsmm2014}.

\item
In the virtual reality environment VR controllers and gaze-controlled interactions
are essential in addition to the voice and gesture recognition support~\cite{iss-v3-ar-vr-sa2016}.
\end{itemize}

% -----------------------------------------------------------------------------
% ICPRAI'18: Jash: DONE
% ICPRAI'18: Serguei: DONE
%\subsection{Selection of the Visualization Languages and Tools}
\subsection{Survey of the Visualization Languages and Tools}

% DONE: gipsy-flucid-dfg / \cite{flucid-dfg-viz-pst2011}
This work focuses on one of the goals of this research, which is to find the 
optimal technique with its formal specifications along with being feasible to 
implement using currently available HCI technologies and a usable one~\cite{flucid-dfg-viz-pst2011}.
%Our first step is to start accumulating knowledge 
%and requirements in choosing one or more techniques aggregated with the 
%desired outcome. Out of these, our design should allow any of the chosen 
%paths~\cite{flucid-dfg-viz-pst2011}.
%
% DONE: gipsy-flucid-dfg / \cite{flucid-dfg-viz-pst2011}
%The current design allows any of the implementation paths to be
%chosen~\cite{flucid-dfg-viz-pst2011}.

% -----------------------------------------------------------------------------
% ICPRAI'18: Jash: DONE
% ICPRAI'18: Serguei: DONE
%\subsubsection*{{\graphviz}}
\subsubsection{{\graphviz}}

Ding's~\cite{yimin04} basic bidirectional translation between {\gipl} and
{\dfg} within {\gipsy} is already a part of the project and exists for {\gipl} 
and {\ilucid}, the two {\lucid} dialect antecedents. Moreover, {\graphviz}
modern version now supports integration with Eclipse~\cite{eclipse}, thus
{\gipsy}'s IDE---{\ripe} (Run-time Interactive Programming Environment)---can be 
an Eclipse-based plug-in as well~\cite{flucid-dfg-viz-pst2011}.

% -----------------------------------------------------------------------------
% ICPRAI'18: Jash: DONE
% ICPRAI'18: Serguei: DONE
%\subsubsection*{{\puredata}}
\subsubsection{{\puredata}}

The {\puredata}~\cite{puredata} language by Puckette along with its 
commercial divisions namely ({\jitter}/{\maxmsp}~\cite{jitter}) apply a
{\dfg}-lie programming by graphically placing inlets and outlets of any data 
type connected in the form of so-called ``patches''. These inlets may have 
external implementations and sub-graphs in procedural languages. Originally, 
Puckett's work used signal processing to process electronic music and videos 
in order to produce interactive artistic and performative processes and was
extended beyond that domain. The notion of 
external plug-ins in {\puredata} allows deep visualization of media in {\opengl} which 
in turn enhances the overall aspect of the process. {\puredata} does draw 
influence from {\lucid} as a data flow language as well~\cite{flucid-dfg-viz-pst2011}.

% -----------------------------------------------------------------------------
% ICPRAI'18: Jash: DONE
% ICPRAI'18: Serguei: DONE
%\subsubsection*{BPEL}
\subsubsection{{\bpel}}

OpenESB IDE provides visual design capabilities to visually illustrate or 
create a {\bpel} (Business Process Execution Language) process along with 
composite applications in the context of Service Oriented Architectures and 
Web Services.~\cite{bpelse,koenig-ws-bpel-2007,ws-bpel-20}. These {\bpel} 
specifications are translatable to an executable web service composition code 
in {\java} language. Not only it provides capabilities in terms of designing 
flows between structures, parallel, asynchronous, sequential processes and 
fault realization, but more importantly, {\bpel} notations have a backing formalism 
modeled upon based on Petri nets.
%
%(See, e.g., visual {\bpel} graph in {\bpel} Designer (first came with the NetBeans IDE)
%%in \xf{fig:bpel-example}
%that illustrates two flows and three parallel
%activities in each flow as well asynchrony and timeouts modeling.)
{\bpel} specifications' composite applications actually translate to executable {\java}
web services composition code~\cite{flucid-dfg-viz-pst2011}.

% -----------------------------------------------------------------------------
% ICPRAI'18: Jash: DONE
% ICPRAI'18: Serguei: DONE
%\subsubsection{Illimitable Space System}
\subsubsection{Illimitable Space System (ISS)}

Original ISS's research-creation practices focused primarily on interactive multimodal 
installations and productions with the collaboration of local artistic 
troupes. It helped mobilizing traditional artists and makes them aware of the 
new technology in order to express themselves in the new form of artistic 
approach. It started off as a new HCI in the theatre concept and interactive 
documentaries and moved to performing arts and alternate realities. Various 
versions of Illimitable Space System exist for motion capture, signal 
processing, computer vision, projection mapping including LED control, real-time
reaction and control for stage and beyond
\cite{%
msong-phdthesis-2012,%
iss-v3-ar-vr-sa2016,%
multicamtk-siggraph2016,%
iss-v2-design-theory-journal,%
rapid-multimodal-apps-course-siggraph2017%
}.

ISS and its open-source backend core OpenISS~\cite{openiss} rely on computer vision techniques and machine learning
provided by OpenCV and {\marf}; motion capture libraries for Kinect depth cameras and 
others, sound control, input from voice and music, and augmented and virtual 
reality components to co-create either augmented performance or have an 
installation or film, or use as an education tool for artists \cite{rapid-multimodal-apps-course-siggraph2017} or children.

% -----------------------------------------------------------------------------
% ICPRAI'18: Jash: DONE
% ICPRAI'18: Serguei: DONE
\paragraph{``Projected Reality''}

We explore an idea of a scalable management, visualization,and evaluation of digital evidence in the context 
for cybercrime investigation with extensions to the interactive 3D documentary subsystem of the 
\emph{Illimitable Space System} (ISSv1)~\cite{msong-phdthesis-2012}.
These modifications would enable investigators to represent and create semantic links among digital evidence within an easy to 
use interface powered by multimodal interactions including but not limited to eye-gaze, gestures and navigational hardware.
That work may scale when properly re-engineered and enhanced to act as an interactive ``3D window” into the 
evidential knowledge base grouped into the semantically linked ``bubbles' visually representing the 
documented evidence. By moving such a contextual window, or rather, navigating within the 
theoretically illimitable space an investigator can sort out and reorganize the knowledge items as 
needed prior launching the reasoning computation. The interaction design aspect would be of a 
particular usefulness to open up the documented case knowledge and link the relevant witness accounts 
and group the related knowledge together. This is a proposed solution to the large-scale visualization 
problem of large volumes of ``scrollable'' evidence that does not need to be all visualized at once 
but behave like a snapshot of a storage depot~\cite{mokhov-phd-thesis-2013}.

As an example,
stills from the actual ISSv1 installation hosting multimedia data (documentary videos) users can 
call out by voice or gestures to examine the contents as in \xf{fig:iss-interactive-docu-bubbles}\footnote{http://vimeo.com/51329588}. 
We propose to reorganize the latter into more structured spaces so that the investigators can create semantic 
links to group the relevant evidences together and for subsequent evaluation by the distributed
{\gipsy}'s backend engine~\cite{mokhov-phd-thesis-2013}. As exemplified in ISSv1 the interactions
here are projected on a wall/screen or appear on a monitor.
%
Currently, the viewable scene/window is sequentially loaded and unloaded from the viewing 
device (PCs, laptops, or VR headsets) to prevent memory overload. The access is on demand 
by the device and the design is similar to RAM swapping by an operating system to support 
virtual memory and particularly in this case a distributed storage with evidential data. 
Available gesture-based interactions using Kinect and similar depth cameras with OpenCV 
are the enabling HCI aspects for the investigator to link the evidential items in the 3D space.
The gesture-based interactions provide optional assistance by 
the voice-based controls for speech processing and the corresponding
commands to view the evidence in detail. Modern availability of 
VR headsets and VR phone applications make this process even more accessible, 
although the storage, space and bandwidth requirements have higher constraints, 
to begin with.
%
In our general approach, we propose an architecture to enable interactive 
visual windowing into the digital evidence processing as an investigator aid tool. Thus, 
the preferred method of interaction during analysis and human insight phases prior to or after 
distributed processing of the evidence and event reconstruction algorithms.

% DONE: SA'13 poster
\begin{figure*}[htpb]
%\hrule\vskip4pt
\begin{center}
	%\subfigure
	%{\includegraphics[width=\commonfigwidth]{images/nat42dfg-3d}
	%{\includegraphics[width=\commonfigwidth,height=1in]{images/ilucid-dfg-dot-yimin-enhanced}
	 %\label{fig:2d-softbody-object}}
	%\subfigure
	%{\includegraphics[width=\commonfigwidth]{images/nat42dfg}
	 %\label{fig:2d-softbody-object}}
	%\subfigure
	%{\includegraphics[width=\commonfigwidth]{images/ilucid-dfg-dot-yimin}
	 %\label{fig:3d-softbody-object}}
	%\subfigure
	%{\includegraphics[width=\commonfigwidth]{images/observation-3d}
	 %\label{fig:3d-softbody-object}}
	\subfigure
	[Corner-projected interactive wall]
	{\includegraphics[width=.47\textwidth]{images/bubble-installation-1}
	 \label{fig:bubble-installation-1}}
	\subfigure
	[Monitor rendering of the interactive 3D window]
	{\includegraphics[width=.47\textwidth]{images/tangible-kinect-2-white}
	 \label{fig:tangible-kinect-2-white}}
	%\subfigure
	%{\includegraphics[width=.47\textwidth]{images/bubble-installation-2}
	 %\label{fig:bubble-installation-2}}
	\subfigure
	[Wall-projected interactive wall]
	{\includegraphics[width=.47\textwidth]{images/bubble-installation-3}
	 \label{fig:bubble-installation-3}}
	\subfigure
	[Conceptual 3D visualization and rendering (future)]
%	{\includegraphics[width=\commonfigwidth]{images/sleuthid-slide}
	{\includegraphics[width=.47\textwidth]{images/sleuthid-slide}
	 \label{fig:1d-elastic-object}}
%\caption{From data-flow graphs to scalable illimitable space visualization and management of digital forensics cases}
%\caption{Interactive documentary illimitable space visualization and management~\cite{msong-phdthesis-2012}}
%\caption{Interactive documentary illimitable space visualization and management}
\caption{Interactive documentary using Illimitable Space System (ISSv1) visualization and management \cite{msong-phdthesis-2012}}
%\label{fig:dfg-to-iss-evolution}
\label{fig:iss-interactive-docu-bubbles}
\end{center}
%\hrule\vskip4pt
\end{figure*}

% -----------------------------------------------------------------------------
% ICPRAI'18: Jash: DONE
% ICPRAI'18: Serguei: DONE
%\subsubsection{Virtual and Augmented Reality}
\paragraph{Virtual and Augmented Reality}

Virtual Reality (VR) \cite{the-vr-book-2016,vr-interactions-course-siggraph2017,course-context-aware-3d-gesture-vr-s2015}
is defined in \cite{mr-taxonomy-1994} as ``a three-dimensional simulation of 
the real world or an imaginary world allowing the user to have a sense of 
physical presence and to manipulate 3D objects,
in real-time, inside three-dimensional computer-generated environments.''
%Studies has shown that VR can be used to better comprehend abstract concepts as well \cite{education-hallucinations-vr-2006}.
In \cite{vr-educational-tool-1995}, authors point out the possibility of exhibiting concepts that a user might not be able to 
view otherwise and the immersive nature of VR can aid in education thus, can 
be inferred for investigators as well.

Augmented Reality (AR) has to do with overlaying virtual objects on top of the
real ones and a possibility with gesture or gaze based interaction with
these objects while maintaining a grasp on the real world without complete
immersion (avoiding nausea and other related VR issues).

The real benefit is when both techniques can be combined.
%
ISSv3 in our case was being developing incorporating augmented and virtual
reality techniques~\cite{iss-v3-ar-vr-sa2016,iss-v3-appy-hour-gem2015}.
We experimented in doing both mobile and desktop version of the mixed
reality documentary and recording functionality in Unity some of which
is visualized in \xf{fig:representative_image-smudge} and in \xf{fig:iss-v3-ar-vr-some-more}.

\begin{figure*}%
\includegraphics[width=\textwidth]{images/vr/representative_image-smudge}%
\caption{ISSv3 Examples of th VR environment and some digital content \cite{iss-v3-ar-vr-sa2016}}%
\label{fig:representative_image-smudge}%
\end{figure*}

\begin{figure*}[htpb]
%\hrule\vskip4pt
\begin{center}
	\subfigure
	[VR version of AR Concordia buildings; interactive]
	{\includegraphics[width=.47\textwidth]{images/vr/buildings_panel.jpg}
	 \label{fig:buildings_panel}}
	\subfigure
	[AR camera on for photograph images]
	{\includegraphics[width=.47\textwidth]{images/vr/intro_bubble.jpg}
	 \label{fig:intro_bubble}}
	%\subfigure
	%%[Wall-projected interactive wall]
	%{\includegraphics[width=.47\textwidth]{images/vr/media_bubble-smudge.jpg}
	 %\label{fig:media_bubble-smudge}}
	%\subfigure
	%%[Conceptual 3D visualization and rendering (future)]
	%{\includegraphics[width=.47\textwidth]{images/vr/play_video.jpg}
	 %\label{fig:play_video}}
	\subfigure
	[AR/VR lab]
	{\includegraphics[width=.47\textwidth]{images/vr/room2-smudge.jpg}
	 \label{fig:room2-smudge}}
	\subfigure
	[Bubbles with footage in them]
	{\includegraphics[width=.47\textwidth]{images/vr/two_bubbles.jpg}
	 \label{fig:two_bubbles}}
	%\subfigure
	%%[Conceptual 3D visualization and rendering (future)]
	%{\includegraphics[width=.47\textwidth]{images/vr/vr_mode-smudge.jpg}
	 %\label{fig:vr_mode-smudge}}
%\caption{Interactive documentary using Illimitable Space System (ISSv3) VR/AR}
\caption{Interactive documentary using Illimitable Space System (ISSv3) VR/AR \cite{iss-v3-ar-vr-sa2016}}
\label{fig:iss-v3-ar-vr-some-more}
\end{center}
%\hrule\vskip4pt
\end{figure*}

% -----------------------------------------------------------------------------
% ICPRAI'18: Jash: DONE
% ICPRAI'18: Serguei: DONE
%\section{Conclusion}
\section{Concluding Remarks}
%\subsection{Summary}
%\section{Summary}

Moving towards our goal to have a visual 3D {\dfg}-based tool that can model 
{\flucid} case specification, and above discussed choices that provide 
the abilities to do the same in their own ways we attempt to build upon 
related research work in this area. However, we do consider the potential of 
the recent work in virtual reality and augmented reality along with 
different multimodal interaction techniques that seem most consistent with 
our aim. So far, Ding's work on {\graphviz}, Puckette's {\puredata}, {\bpel} and the 
ISS have drawn our interest and all of them are sound and formally backed 
standards with some exposure in the industry. While the others may require 
additional work to specify the credibility and correctness of the 
bidirectional translation between 3D DFG visualization and {\flucid}~\cite{flucid-dfg-viz-pst2011}.

The drawbacks of {\puredata} and {\graphviz}s \tool{dot} are that their languages lack 
formal semantics specifications with a few semantic notes along with lexical 
and grammar related structures~\cite{dot-language}. Thus, employing any or all of these will 
require us to provide translation rules and their equivalent semantics to 
{\flucid} as in Jarraya work that provides translations between the UML2.0/SysML
state/activity diagrams and probabilities in~\cite{vv-uml-sysml-syseng-designs}
when translating to {\prism}~\cite{flucid-dfg-viz-pst2011}.
%
ISS is the most scalable approach that can aggregate all the others, but 
requires significant number of modifications. Given recent advancements
in ISSv2 and ISSv3 referenced above including both AR/VR interactions,
ISS makes this approach even more appealing and feasible than
previously stated~\cite{flucid-dfg-viz-pst2011}.
%As per authors' understanding of the above
%mentioned systems and languages the decision choice may as well be an intermediate form or 
%an aggregation of inter-translatable forms~\cite{flucid-dfg-viz-pst2011}.

% EOF

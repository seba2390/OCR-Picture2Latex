\section{Introduction}\label{sec:introduction}

With the rapid development of computer software and hardware, more and more physical \DIFdelbegin \DIFdel{system }\DIFdelend \DIFaddbegin \DIFadd{systems }\DIFaddend of different domains, such as smart grid, autonomous automobile systems, medical monitoring systems, are controlled by software.
This kind of system, formally called Cyber-Physical System (CPS), has software components controlling physical components\DIFdelbegin \DIFdel{and usually are connected through networks}\DIFdelend .

It is difficult to design a CPS system since complexities, such as simultaneous developing of physical components are involved.
Therefore, the common practice in industry is to use simulation models to represent both the physical and software components.
Physical components are replaced by simulated models and software components are explicitly modeled to abstract away unnecessary details and keep the key logic.
In this way, tests can be conducted on the models before starting the real implementation.
This method of development is called \emph{model-based development}\DIFaddbegin \DIFadd{.
}\DIFaddend % (Y.) Avoided using ``verification'' because it could cause confusion with formal verification.

Model-based development makes development of a CPS much easier.
However, developing a CPS correctly is still a challenge \DIFdelbegin \DIFdel{, }\DIFdelend because the state space of a CPS is infinite\DIFdelbegin \DIFdel{, and there are }\DIFdelend \DIFaddbegin \DIFadd{. Moreover, there would be }\DIFaddend many corner cases to consider because of interaction of physical and software components.
Testing is not an efficient way to find a defect in a CPS model, and it does not guarantee the correctness of the model since no full coverage can be achieved.
\DIFaddbegin \todo{I think testing is one of the most standard and effecient way to find a defect in the model. The problem is that testing with full coverage is sometimes impracticable when the input space for testing is too big (e.g, the input space is the set of all time-sequencial operations of the throttle and the brake).}
\DIFaddend % (Y.) Simulation -> Testing

To ease this problem, \emph{robustness guided falsification} of a CPS model is introduced~\cite{TLF_CPS_2013}.
In robustness guided falsification, typically a \emph{Metoric Temporal Logic (MTL)} formula is used to define a specification which must be satisfied by a CPS model.
Further, \emph{robustness} of a MTL formula, which is a numeric measure of how ``robust'' a specification holds in the given CPS model, is defined.
\DIFaddbegin \DIFadd{That means a trajectory of the system which has a minimal robustness value is a good candidate for testing.
}\DIFaddend Then, the robustness value is used to explore the state space of the CPS model and a trajectory which minimizes the robustness value will be identified as the counterexample.
To find a state which minimizes the robustness, different optimization techniques such as simulated annealing, are used \DIFaddbegin \DIFadd{\mbox{%DIFAUXCMD
\cite{}
}%DIFAUXCMD
}\DIFaddend .
In this way, tests are replaced to more efficient, yet automatic explorations of the state space.
% (Y.) random simulation -> tests
\DIFdelbegin \DIFdel{If the process does not terminate, it means
that the process cannot find a counterexample.
Although this does not guarantees }\DIFdelend %DIF >  If the process does not terminate, it means that the process cannot find a counterexample.
%DIF >  Although this does not guarantees the absence of a counterexample, it still strongly suggests the correctness of the CPS model.
\DIFaddbegin \DIFadd{Although the non-termination of robustness guided falsification does not means
}\DIFaddend the absence of \DIFdelbegin \DIFdel{a counterexample}\DIFdelend \DIFaddbegin \DIFadd{counterexamples}\DIFaddend , it still \DIFdelbegin \DIFdel{strongly }\DIFdelend suggests the correctness of the CPS model.
\DIFdelbegin \DIFdel{The system state which has a minimal robustness value is a good candidate for testing a real CPS system, because having a small robustness value means that the state may easily violate the specification by a small perturbation to the system.
}\DIFdelend %DIF >  , because having a small robustness value means that the state may easily violate the specification by a small perturbation to the system.

Unfortunately, robustness guided falsification of a CPS model usually requires thousands of simulation runs to falsify a CPS model \DIFdelbegin \DIFdel{, }\DIFdelend which comprises several dozen simple components~\cite{}.
The current work uses Monte-Carlo technique which performs a random walk over the state space or simple machine learning techniques such as Gaussian \DIFdelbegin \DIFdel{regression.
}\DIFdelend \DIFaddbegin \DIFadd{process regression.
}\todo{Most of the exsiting works of robustness guided falsification employ much more ``smart'' algorithm than Monte-Carlo techniques for example simulated annealing, cross entropy method, and so on.}
\DIFaddend Since a practical model of a CPS comprises several thousand of components and the state space can be tremendous, random sampling or simple machine learning cannot guarantee to find a counterexample in all cases.
A smarter, knowledge guided method is required to accelerate the findings on the counterexamples.
% (Y.)  mention the Gaussian regression method
\DIFaddbegin \todo{I think that the complexity of the learning algorithm does not mean the efficiency. We shouldn't try to defeat the conventional optimization methods but to investigate the applicability of the novel learning method.}
\DIFaddend 

In this paper, we apply an emerging technology called \emph{deep reinforcement learning}~\cite{} to the minimization problem of robustness of a MTL formula for a CPS model.
\emph{Reinforcement learning}~\cite{} is one of the machine learning techniques which maximizes \emph{rewards} by taking appropriate \emph{actions} while observing system states.
Deep reinforcement learning is an application of a \emph{deep neural network} to reinforcement learning.
Deep reinforcement learning is known to achieve super-human performance for Go~\cite{} and arcade games~\cite{}.
Deep reinforcement learning is also applied to physical control problems~\cite{}.
% (Y.) For physical control problems, human may still be better than DRL.
Our goal in this paper is to evaluate how this technology reduces the number of simulation runs required to find a counterexample that falsifies a CPS model.

(...Summary of Result...)

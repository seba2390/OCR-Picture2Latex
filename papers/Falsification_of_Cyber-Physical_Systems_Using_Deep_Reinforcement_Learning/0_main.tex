\documentclass{llncs}
\usepackage{times}
\usepackage[title]{appendix}
\usepackage{graphicx}
\usepackage{amsmath, amssymb}
\usepackage{multirow}
\usepackage{algpseudocode}
\usepackage{algorithmicx,algorithm}

\newcommand{\action}{$\mathcal A$\space}
\newcommand{\probkernal}{$\mathcal P_0$\space}
\newcommand{\state}{$\mathcal X$\space}
\newcommand{\status}{s\space}
\newcommand{\vspeed}{$\mathtt{v}$\space}
\newcommand{\ATmodel}{\mathbf{AT}}
\newcommand{\PTCmodel}{\mathbf{PTC}}
\newcommand{\STL}{\mathrm{STL}}
\newcommand{\SA}{\mathrm{SA}}
\newcommand{\CE}{\mathrm{CE}}
\newcommand{\AAAC}{\mathbf{A3C}}
\newcommand{\DQN}{\mathbf{DDQN}}

% \newcommand{\ytodo}[1]{\todo[inline,color=blue!30]{#1}}
% \newcommand{\stodo}[1]{\todo[inline,color=red!30]{#1}}
% \newcommand{\ttodo}[1]{\todo[color=red!30]{#1}}
% \newcommand{\ytodo}[1]{}
% \newcommand{\stodo}[1]{}
% \newcommand{\ttodo}[1]{}

\DeclareMathOperator{\rob}{\rho}
\DeclareMathOperator*{\minimize}{\mathsf{minimize}}
\DeclareMathOperator{\dist}{\mathsf{dist}}
\DeclareMathOperator{\hrz}{\mathsf{fr}}
\DeclareMathOperator{\reward}{\mathsf{reward}}
\DeclareMathOperator{\hst}{\mathsf{pr}}
\DeclareMathOperator{\sht}{\mathsf{shift}}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator{\UNTIL}{\mathcal{U}}
\DeclareMathOperator{\SINCE}{\mathcal{S}}

\algnewcommand\algorithmicinput{\textbf{input:}}
\algnewcommand\INPUT{\item[\algorithmicinput]}
\algnewcommand\algorithmicparameters{\textbf{parameters:}}
\algnewcommand\PARAMETERS{\item[\algorithmicparameters]}
\algnewcommand\algorithmicoutput{\textbf{output:}}
\algnewcommand\OUTPUT{\item[\algorithmicoutput]}

\title{Falsification of Cyber-Physical Systems Using Deep Reinforcement Learning}

\author{
Takumi Akazaki\inst{1}\inst{2} \and Shuang Liu\inst{3} \and Yoriyuki Yamagata\inst{4} \and Yihai Duan\inst{3} \and Jianye Hao\inst{3}
}

\institute{The University of Tokyo \\
\and
Japan Society for the Promotion of Science \\
\and
School of Software, Tianjin University \\
\and
National Institute of Advanced Industrial Science and Technology (AIST)
}


\begin{document}
\maketitle

\begin{abstract}
With the rapid development of software and distributed computing,  \emph{Cyber-Physical Systems} (CPS) are widely adopted in many application areas, e.g., smart grid, autonomous automobile. It is difficult to detect defects in CPS models due to the complexities involved in the software and physical systems. To find defects in CPS models efficiently, robustness guided falsification of CPS is introduced. Existing methods use several optimization techniques to generate counterexamples, which falsify the given properties of a CPS. However those methods may require a large number of simulation runs to find the counterexample and is far from practical. In this work, we explore state-of-the-art \emph{Deep Reinforcement Learning (DRL)} techniques
%, i.e., Asynchronous Advanced Acctor Critic (A3C) and Double Deep-Q Network (DDQN),
to reduce the number of simulation runs required to find such counterexamples. We %introduce our method and
report our method and the preliminary evaluation results.
\end{abstract}


\input{1_introduction}
\input{2_preliminary}
%\input{3_motivating_example}
\input{4_our_approach}
\input{5_evaluation}
%\input{6_related_work}
\input{7_conclusion}
\bibliographystyle{abbrv}
\bibliography{ref}

\begin{appendix}
\input{Appendix}
\end{appendix}
\end{document}

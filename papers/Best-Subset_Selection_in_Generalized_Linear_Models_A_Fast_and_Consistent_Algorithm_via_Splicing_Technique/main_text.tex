\documentclass[12pt]{article}
\renewcommand{\baselinestretch}{1.1}
\usepackage[left=2.7cm,bottom=2.7cm,right=2.7cm,top=2.7cm]{geometry}

%% Packages
\usepackage{enumerate}
\usepackage{tabularx}
\usepackage{subfigure}
\usepackage{multirow}
\usepackage{algorithm}
\usepackage{authblk}
\usepackage{algorithmic}
\usepackage{indentfirst}
\usepackage{setspace}
\usepackage{color}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}		% Can be removed after putting your text content
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{doi}
\usepackage[namelimits]{amsmath} 
\usepackage{amssymb}            
\usepackage{amsfonts}       
\usepackage{mathrsfs} 
\usepackage[resetlabels]{multibib}
\usepackage{bm}

\usepackage{graphicx}
\usepackage{epsfig}
\usepackage{enumitem}
\usepackage{url} % not crucial - just used below for the URL
\usepackage{multirow}
\usepackage{epstopdf}
\usepackage{mathtools}

% Convenient notations
\newcommand{\fullset}{\mathcal{F}}
\newcommand{\informsOR}{1}
\newcommand{\informsMOR}{0}

\graphicspath{{}}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{proof}{Proof}
\newtheorem{corollary}{Corollary}
\newtheorem{remark}{Remark}
\providecommand{\keywords}[1]{\textit{\quad Key words }:  #1}
\renewcommand\Affilfont{\small}
\newcommand{\qedsymbol}{\hfill $\blacksquare$}
\begin{document}

\title{Best-Subset Selection in Generalized Linear Models: A Fast and Consistent Algorithm via Splicing Technique}

% \author{Yanhang Zhang\thanks{School of Statistics,
% Renmin University of China,
% \texttt{zhangyh98@ruc.edu.cn}}\ ~~~~
% Junxian Zhu \thanks{Saw Swee Hock School of Public Health, National University of Singapore,
% \texttt{junxian@nus.edu.sg}}\~~~~
% Jin Zhu \thanks{Southern China Center for Statistical Science,
% Department of Statistical Science,
% School of Mathematics,
% Sun Yat-Sen University,
% \texttt{zhuj37@mail2.sysu.edu.cn} }~~~~
% Xueqin Wang\thanks{
% Department of Statistics and Finance/International Institute of Finance,
% 	School of Management,
% 	University of Science and Technology of China,
% 	\texttt{wangxq20@ustc.edu.cn} }}

\author[1]{Junxian Zhu\textsuperscript{*}}
\author[2]{Jin Zhu\textsuperscript{*}}
\author[4]{Borui Tang}
\author[2]{Xuanyu Chen}
\author[3]{Hongmei Lin\textsuperscript{$\dagger$}}
\author[4]{Xueqin Wang\textsuperscript{$\dagger$}}

\affil[1]{\footnotesize Saw Swee Hock School of Public Health, National University of Singapore}
\affil[2]{\footnotesize Southern China Center for Statistical Science, Department of Statistical Science, School of Mathematics, Sun Yat-Sen University}
\affil[3]{\footnotesize School of Statistics and Information, Shanghai University of International Business and Economics \\
  \texttt{hmlin@suibe.edu.cn}}
\affil[4]{\footnotesize Department of Statistics and Finance/International Institute of Finance, School of Management, University of Science and Technology of China \\
 	\texttt{wangxq20@ustc.edu.cn} }

\date{}
\maketitle \sloppy

\begin{abstract}
  In high-dimensional generalized linear models, it is crucial to identify a sparse model that adequately accounts for response variation. Although the best subset section has been widely regarded as the Holy Grail of problems of this type, achieving either computational efficiency or statistical guarantees is challenging. In this article, we intend to surmount this obstacle by utilizing a fast algorithm to select the best subset with high certainty. We proposed and illustrated an algorithm for best subset recovery in regularity conditions. Under mild conditions, the computational complexity of our algorithm scales polynomially with sample size and dimension. In addition to demonstrating the statistical properties of our method, extensive numerical experiments reveal that it outperforms existing methods for variable selection and coefficient estimation. The runtime analysis shows that our implementation achieves approximately a fourfold speedup compared to popular variable selection toolkits like \textsf{glmnet} and \textsf{ncvreg}.
\end{abstract}


\keywords{Best-Subset Selection, Generalized Linear Models, Splicing Technique, Support Recovery Consistency, Polynomial Complexity}

\begingroup\renewcommand\thefootnote{*}
\footnotetext{Equal contribution}
\begingroup\renewcommand\thefootnote{$\dagger$}
\footnotetext{Corresponding author}

\input{introduction}
\input{method}
\input{theory}
\input{fast-computing}
\input{simulation}
% \input{realdata}
\input{discussion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{unsrtnat}
\bibliography{ABESS}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}




\section{\TOOL design and testing}
\label{sec:metho}

We explicitly engineer \TOOL to fully automate the visit to websites and collect statistics. The key element of \TOOL is its ability to identify the presence of a Privacy Banner and automatically accept privacy policies. We aim at a practical and effective approach to accept privacy policies through the offered button. As previously said, most users will indeed be nudged in this direction, being the opt-out options often made cumbersome on purpose\cite{bauer2021you, hausner2021dark, CookieBenchmarkStudy}.

To illustrate \TOOL operation, consider again Figure~\ref{fig:cookie_accept_example}. A large Privacy Banner appears on the first-time-ever visit, and the user shall click on the ``Got it'' button to access the webpage content. \TOOL has to locate this button and click on it automatically. As a result, the website starts loading advertisements and contacting trackers in background. We refer to these two types of visits as \BEFORE and \AFTER in the remainder of the paper.

We implement \TOOL using the Selenium browser automation tool~\cite{avasarala2014selenium}, the de-facto standard for browser automation. We focus on Google Chrome, but we could easily extend it to other browsers.

Given a target URL, \TOOL carries out the following tasks:
\begin{enumerate}
    \item It navigates to the URL with a fresh browser profile, i.e., with an empty cache and cookie storage. This makes the visit the equivalent of a \BEFORE to the website.
    \item It inspects the Document Object Model (DOM) of the rendered webpage to find a possible \emph{Accept-button} in a Privacy Banner. For this, we match a list of keywords on the text of each node of the DOM. We identify an \emph{Accept-button} if we exactly match one of our keywords. For robustness, the match is case insensitive, and leading, trailing or repeated blank characters are removed.
    \item If \TOOL finds the \emph{Accept-button}, it tries to accept the default privacy policies by clicking on the corresponding DOM element (typically a \texttt{<button>}, \texttt{<href>} or \texttt{<span>} element).
    \item \TOOL then revisits the URL to collect statistics about the \AFTER experience.
\end{enumerate}

In the beginning, we built \TOOL to look for accept buttons through CSS selectors combined with keywords as done in~\cite{vallina2019tales} and popular add-ons. However, we soon observed that this methodology was too fragile as the use of selectors is strongly CMP-specific and highly customizable by webmasters. The keyword-based approach eases the generalization of the solution. Considering the complexity, \TOOL adds marginal overhead to the time required to visit a webpage. Only for very complex webpages, iterating through all DOM elements may require some time, but this is still much less than the time needed to load and render the webpage by the browser. 

During each visit, \TOOL stores metadata regarding the whole process in a JSON log file. It includes details on all HTTP transactions and installed cookies. Moreover, it optionally takes screenshots of the webpage during the various phases to allow manual verification.

\TOOL is highly customizable and offers the user various features. It lets the user customize the declared \texttt{User-Agent} and browser language (in the \texttt{Accept-Language} headers). Important to our analysis, it runs a:
\begin{itemize}
    \item \emph{Warm-up visit}: to populate the browser cache.
    \item \BEFORE: to collect statistics on the webpage before accepting the privacy policy, as a Naive Crawler would do.
    \item \AFTER: to collect statistics on the webpage as it appears after accepting the privacy policy (if an \emph{Accept-button} is found).
    \item \INTERNAL: to a number of webpages of the same website, randomly choosing among the internal links. This step runs regardless of the presence of the \emph{Accept-button}.
\end{itemize}

Among metadata \TOOL collects, we record the Page Load Time, or \emph{OnLoad} time, on all visits. It allows us to compare the performance with and without privacy acceptance. The \emph{OnLoad} time is a performance index often used as a proxy for Quality of Experience measurements~\cite{da2018narrowing}. We leave the measurements of more sophisticated QoE-related metrics such as the SpeedIndex~\cite{speedindex} as future work. Moreover, we neglect metrics that are not affected by the presence of a Privacy Banner, such as the Time-to-first-byte (TTFB). To avoid suffering the bias of the \AFTER that can only occur with a warm browser cache, we run a preliminary \emph{Warm-up visit}, then we perform another \BEFORE and take performance measurement only on the latter. This lets us fairly compare the \emph{OnLoad} on the two visits with hot cache in both cases. Alternatively, \TOOL can erase the HTTP cache and clean the socket pool upon each visit to measure webpage performance with a cold cache.

At last, to limit the impact of random delay due to webpage download and rendering, \TOOL uses quite conservative timeouts before eventually abort the visit. In detail, the DOM inspection starts 5 seconds after the \emph{OnLoad} event. While this clearly slows down the visit of multiple webpages, it maximizes the accept success rate.

To allow large-scale measurement campaigns, we containerize \TOOL using the Docker container engine~\cite{docker}. In the containerized version, we use Google Chrome version 89 in headless mode and force it to use a standard \texttt{User-Agent} instead of the pre-defined \texttt{ChromeHeadless}.

We offer \TOOL as open-source to foster its usage and allow the reproducibility of the results presented in this paper. For this, we also commit to releasing all the data we collected for this study.

\subsection{Keyword Selection and Validation}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.5\columnwidth]{figures/cookieaccept_validation_third_round.pdf}
    \caption{Validation results of \TOOL over 200 randomly picked websites per country.}
    \label{fig:validation}
\end{figure}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.5\columnwidth]{figures/cookieaccept_keywords_freq.pdf}
    \caption{Frequency of the \TOOL keywords, with some examples reported.}
    \label{fig:keywords}
\end{figure}

The core of \TOOL is the list of keywords to be matched against the webpage content to localize the clickable DOM element for accepting the privacy policy. We thoroughly build this list manually in an iterative way. To handle different languages, we build a list that includes keywords for each country we are interested in. For this work, we focus on 5 European countries, namely France, Germany, Italy, Spain, UK\footnote{Since January 2021 UK has enforced the UK GDPR - with practically identical requirements.}, plus the US -- which we use as an example of an extra-EU country. For each country, we pick the most popular websites according to the Similarweb lists~\cite{similarweb}, a website-ranking service analogous to Alexa.

\subsubsection{First Round - keyword extraction from top websites}

In the first round, for each of the $5$ countries, we consider the top-200 websites that have a Privacy Banner. We randomly choose half of these websites and manually visit them (from Europe) to extract the accept keyword. In total, we identify $186$ unique keywords. We next instruct \TOOL to visit the other half of websites and accept privacy policies. For those where it fails, we manually visit them and extract keywords. With this, we include $36$ new keywords, $222$ in total.

\subsubsection{Second Round - testing and keyword increase}

To evaluate the accuracy of \TOOL in the wild, we next consider 200 new random websites for each country from the Similarweb lists. We let \TOOL visit them and manually check the subset of websites for which \TOOL fails to accept the privacy policy. We depict the results in Figure~\ref{fig:validation}. \TOOL can accept the privacy policy in more than half of websites. In $6-14\%$ of cases, we find new keywords -- that we promptly add to our list. Interestingly, we find a non-negligible portion of websites ($26-30\%$) that do not present any Privacy Banner. At last, \TOOL fails to accept privacy in only $5-8\%$ of cases. Investigating further, this is due to non-standard behaviors of the webpage when accessed in headless mode. For instance, some websites present a CAPTCHA when they detect an automated visit; other websites return a blank webpage. This is a common problem for any crawler-based measurement study~\cite{vastel2020fp}. Note that cases of \emph{False Positives} -- i.e., \TOOL clicking on a wrong DOM element -- are possible, although we have not observed any during the development and testing phases. 

At the end of the keyword list building phases, we collect a total of $258$ keywords covering $6$ languages.\footnote{In Spain, some websites are in Catalan, rather than in Spanish.} The most frequent one is the simple ``Ok'' string. In Figure~\ref{fig:keywords} we show the cumulative distribution of keyword frequency on the whole set of Similarweb websites with some keyword examples. The top-50 keywords already cover $87\%$ of websites, while 100 are enough to cover $95\%$.  Interestingly, we find also complex strings like ``I'm fine with this'' or ``Alle auswählen, weiterlesen und unsere arbeit unterstützen''.\footnote{Which translates to ``Select all, keep reading and support our work''.}



\subsection{\TOOL vs. Consent-O-Matic}
\label{sec:ca_vs_com}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.5\columnwidth]{figures/cookieaccept_consentomatic_random.pdf}
    \caption{Privacy policy acceptance rate of \TOOL and Consent-O-Matic on 100 websites per country.}
    \label{fig:ca_vs_com}
\end{figure}

We compare the effectiveness of \TOOL with Consent-O-Matic, the most mature browser plugin designed to offer/deny consent to privacy policies automatically. Unlike our tool, Consent-O-Matic exploits the presence of popular Consent Management Providers (CMP), services that take care of the management of users' choices on behalf of the website. At the time of writing, Consent-O-Matic allows managing Privacy Banners for 35 CMPs. To gauge its performance, we visit the top-100 most popular websites with a Privacy Banner for the 5 countries using a Chrome browser with the Consent-O-Matic plugin enabled. Consent-O-Matic accepts the privacy policies in less than 35\% of websites with Privacy Banner, and as little as 17\% and 20\% for websites in Italy and UK, respectively. Here \TOOL accepts the privacy policies on all websites by construction.

We then run a second experiment considering another set of 100 websites randomly picked from the Similarweb per country lists. We visit each website with \TOOL and a Consent-O-Matic-enabled browser. Figure~\ref{fig:ca_vs_com} summarizes the comparison. \TOOL can accept the privacy policies in more than 50\% of websites, more than twice the success rate of Consent-O-Matic. These results are in line with those of Figure~\ref{fig:validation}. The remaining websites may not have a Privacy Banner, fail to load, or use an unknown keyword. This testifies that the customization of Privacy Banners makes it difficult to engineer a generic and simple solution. The keyword-based strategy results more robust than the CMP-based approach (with similar complexity in curating the lists).



\subsection{Dataset and Tracker list}
\label{sec:dataset}

In the following, we use \TOOL to run several measurement campaigns. Most of our analyses, unless otherwise indicated, targets a large set of websites popular in Europe, using a test server located in a European university campus. We also use the US as a representative of an extra-EU country. For each of the $6$ countries, we consider the top 100 websites from 25 different categories - see Figure~\ref{fig:ca_category}. In total, we include $12\,277$ unique websites to visit (as the lists in different countries partially overlap).

We run \TOOL on the target websites using a single high-end server running 16 parallel instances to speed up the crawl. We instrument it to run a \emph{test sequence}, which consists in a \emph{Warm-up visit}, \BEFORE, and \AFTER to the landing page, followed by \INTERNAL to 5 randomly chosen internal pages -- previous studies indeed show that internal and landing pages have different properties~\cite{aqeel2020on}. For each website, we repeat the test sequence $5$ times, randomizing the order of websites to visit in each repetition.  Our main experimental campaign took place for two weeks on April 2021.

We run additional measurement campaigns to investigate specific aspects. First, we repeat the above experiments using servers located in the US, Brazil and Japan. We use Amazon Web Services to deploy on-demand servers on the desired availability zone. Our goal is to understand whether Privacy Banners appear or have a different impact depending on the visitor location. Second, we visit the top-100\,000 websites according to the Tranco list~\cite{pochat2018tranco} to offer a view on a larger number of websites. Unfortunately, the Tranco list does not offer a per-category and per-country rank. We test these websites twice, with and without clearing the browser cache, to compare webpage performance on the \BEFORE and on the \AFTER both with a warm and a cold cache.

To observe how the presence of trackers changes from the \BEFORE to the \AFTER, we rely on publicly-available lists provided by Whotracksme~\cite{whotracksme} (a tracking-related open-data provider), EasyPrivacy~\cite{easyprivacy} (one of the lists at the core of AdBlock tracker-blocking strategy) and AdGuard~\cite{adguard} (another ad-blocking tool). For robustness, we merge the three lists and consider as potential trackers those third-party domains that appear in at least two lists. In total, we obtain $1\,497$ domains that we consider tracking services.\footnote{In the following, we identify them with their \emph{second-level domain name} -- i.e., a hostname truncated after the second label. We handle the case of two-label country code TLDs such as \texttt{co.uk}.} We then record the presence of a tracker during a visit if the webpage embeds an object from a tracking domain, and the latter installs a cookie with a lifetime longer than one month~\cite{trevisan20194} -- commonly referred to as \textit{profiling cookie}. As such, we divide the HTTP transactions carried out during a visit in: 
\begin{itemize}
    \item First-Party: objects from the same domain of the target webpage.
    \item Third-Party: objects from a different domain than the target webpage.
    \item Trackers: objects from a Third-Party that is a tracking domain and sets a profiling cookie.
\end{itemize}
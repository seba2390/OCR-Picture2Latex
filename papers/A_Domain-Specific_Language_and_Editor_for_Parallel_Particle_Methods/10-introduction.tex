\section{Introduction} The emergence of massively parallel hardware architectures, 
such as different kinds of multi- and many-cores, general-purpose GPUs, and FPGAs in
scientific high-performance computing (HPC) has led to the development of new (or the
renovation of old)  programming models, paradigms, languages, and standards.
Standardized interfaces such as the Message Passing Interface
(MPI)~\cite{MPI30}, OpenMP~\cite{openmp_standard},
OpenACC~\cite{openacc_standard}, or hardware-specific low-level programming languages
such as CUDA~\cite{cuda_standard} made their way into HPC programming as libraries,
language extensions, or compilers. However, using these tools efficiently in
scientific programming requires in-depth knowledge of the underlying HPC
architecture, the development of parallel applications, and numerical simulation
methods. Hence, the achievable level of abstraction remains rather low, which is a
well-known problem in scientific
programming~\cite{hannay_how_2009,wilson_wheres_2006}, causing the ``knowledge gap''
in program efficiency~\cite{Sbalzarini:2010}.

To address this gap, scientific libraries and domain-specific languages (DSLs)
have evolved into an important tool set in scientific HPC. However, most of the scientific DSLs are built on
rather conventional technology such as macros, templates, and/or parser generators. 
%
In recent years, more sophisticated tools have been proposed,
frequently referred to as \emph{language
workbenches}~\cite{fowler_language_workbenches_2005,erdweg_workbenches_2013}, which
enable developers to more easily create and integrate DSLs following a model-centric
approach. A main driver behind the rising interest in such tools is the paradigm of
\emph{language-oriented programming}~\cite{Ward1994}, where DSLs are created to
describe and solve software problems instead of using general-purpose languages, with
the goal of increased productivity and better maintainability through abstraction. 
%
Models are the central paradigm that is edited by users and automatically
transformed or interpreted by the workbench tooling. From this integrative idea,
major advantages over conventional approaches arise. Most language workbenches
provide configurable features known from professional programming environments, such
as automatic code completion, refactoring, and syntax highlighting.
Moreover, they typically provide a collection of internal, tailor-made specification
languages that address common concerns in language development, e.g., languages for
pretty-printing, rewriting, parsing, and code analysis or generation.

These tools were not used when designing the Parallel Particle Mesh library (PPM) and the Parallel Particle Mesh Language
(PPML) as a library and a DSL for large-scale scientific HPC using particle-mesh
abstractions~\cite{Sbalzarini2006a,Sbalzarini:2010,Awile:2013,Awile:2013a}. Instead, PPML was
implemented conventionally as an \emph{internal DSL}, embedded into Fortran 2003.
However, as PPML does not have a completely integrated language model, it is
\revii{difficult} to maintain, debug, extend, or optimize PPML
programs~\cite{Karol2015a}. To improve on these issues, we developed the PPM
Environment (PPME) as a\revii{n} Integrated Development Environment (IDE) for particle-mesh methods.
Based on the Meta Programming System (MPS)~\cite{Dmitriev2004,MPS32UsersGuide}, a language workbench that closely
follows the ideas of language-oriented programming, \revii{PPME provides an additional layer of abstraction on top of 
the PPML stack (cf. Figure~\ref{fig:ppme-access_layer} in Section~\ref{sec:implementation_use_cases})}. 
\revii{In contrast to text-based language workbenches, MPS relies on \emph{projectional editing} 
where users directly operate on a rendered, form-like ``projection'' of the program~\cite{feiler_incremental_1981}. This enables advanced rendering of tables and mathematical equations inlined with normal program code.}
\revii{Due to its underlying principles, we believe that MPS is an excellent 
platform to design languages that address the ``knowledge gap'' and raise the level of abstraction in scientific programming.}

In this paper, we present PPME as the first IDE for high-performance particle
simulations.  We introduce a complete language model that provides the corresponding
abstractions and paves the way for further domain-specific analyses. As an
important first analysis, we implement a static type-inference engine, supported
by a formal type system. Furthermore, we demonstrate the advantages of this 
approach and of using language workbenches for numerical optimizations by integrating a
mechanism for error-reduction in floating-point expressions. 

The remainder of this paper is structured as follows: Section~\ref{sec:particle_methods} briefly introduces the background of particle
methods. 
%Afterwards, in \jc{I'm not a friend of this time adverbs}
% SK: I like them, but feel free to remove them where you like.
Section~\ref{sec:ppml} provides a more detailed overview and analysis of the current
PPML implementation and tool flow. The language model and type system of PPME are 
discussed in Section~\ref{sec:model-and-type-system}. Section~\ref{sec:implementation_use_cases}
gives an overview of PPME's coarse-grained architecture and implementation, and 
presents three case studies. In Section~\ref{sec:analysis}, we show how optimizations
can be added by integrating an external analysis tool using domain-specific information.
A qualitative evaluation of our work is given in Section~\ref{sec:evaluation}.
Finally, we discuss related work in Section~\ref{sec:related_work}, and Section~\ref{sec:conclusions} 
concludes the paper.




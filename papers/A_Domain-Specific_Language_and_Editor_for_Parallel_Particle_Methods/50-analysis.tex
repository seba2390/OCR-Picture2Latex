% vim: set ts=2 sw=2 sts=2:
% vim: set wrap breakindent:
% !TEX root = paper_ppme_TOMS.tex

\section{Numerical Optimizations and Tool Integration}
\label{sec:analysis}
Applications in science and engineering often depend on floating-point
arithmetic in calculations to approximate real arithmetic. In this section, we
therefore introduce an \revii{accuracy} optimization for floating-point expressions that is
integrated into PPME. 
This serves as an example of how to extend PPME by existing tools, 
\revii{thereby demonstrating the possibilities offered by the high-level 
expressions of the language}. 
In a similar way, other common optimizations can be added in the future, 
for example loop transformations to improve data locality and 
performance~\cite{Lam1991,luporini_coffee_2015}.
\revii{Loop optimizations are orthogonal to the floating-point 
transformation described in this section}.

%As numerical operations are such an essential part of scientific computations they
%are a common target for analysis and optimization. Likewise, focus can be put on
%numerical optimizations based on transformations of floating-point expressions.
In the case of floating-point computations, a compiler can trade \emph{accuracy}
for \emph{performance}. Such optimizations often rely on
\emph{abstract interpretation} for preserving semantics. The abstract semantic can be
used to build program equivalent graphs, inspect them with regard to the desired
optimization target, and enable efficient detection of appropriate
rewrites~\cite{Ioualalen2012}. 
As an example of such optimizations, we adopt
\emph{Herbie}\footnote{\url{https://github.com/uwplse/herbie}} as a recent approach to 
automatically improve floating point expressions~\cite{Panchekha2015}. 
%
Herbie relies on heuristics to estimate and localize rounding errors at sample points. 
%
%To improve a given expression, it applies a
%database of rules, takes series expansions, and combines improvements for different
%input regions. After initialization, the tool localizes floating-point inaccuracies
%through sample point computations. 
%
Once low accuracy (e.g., numerical extinction) is detected, Herbie attempts to improve the program 
by rewriting inaccurate expressions using a rule database. 
%
%The error elimination is carried
%out by applying rewrite rules describing basic arithmetic artifacts. 
%
Thereafter, if possible without loss of accuracy, the expressions are simplified. 
%
Finally, Herbie may apply series expansions for inputs around zero or near infinity to better 
approximate the result.
%
%In case rounding errors are detected for
%inputs around zero or near infinity for which no better program could be found using
%rewrite rules, Herbie performs series expansions to approximate the result. This
%often helps to avoid over- and under-flows. 
%
This process is repeated iteratively so that new candidate expressions are yielded after
each iteration, keeping only the programs which achieve the best accuracy at least
at one sample point. Finally, Herbie uses one or more candidates to achieve an improvement
of accuracy over all sample points.
%As in most cases not a single candidate program is most
%accurate for all input points, Herbie assembles a final program in a regime-inference
%pass. Regimes correspond to input regions for which different expressions are most
%accurate. In order to prevent over-fitting, regime inference has to find a trade-off
%for the number of branches to apply. Hence, Herbie combines several candidate
%programs to achieve an improvement of accuracy over all input points.

\subsection{Tool Integration}
We integrated Herbie as a \revii{plugin into PPME. MPS provides convenient configuration languages to define \emph{plugin solutions} and to specify their behavior. The solution of our Herbie plugin comprises a preference page, an action object that executes Herbie in a separate process, and a \emph{mapping script} that collects references to expression nodes in the PPME program.}
%
Since the algorithms \revii{for accuracy optimization} are computationally expensive, expressions are not 
inspected automatically but must be flagged for evaluation by the user. Users can 
trigger the analysis and transformation process for the active PPME editor and the 
result is then annotated to the corresponding fragments in the code.

\begin{figure}
\begin{minipage}{.42\textwidth}
  \includegraphics[width=\textwidth]{img/ppme-herbie-seq}%
  \caption{Sequence diagram for the execution of a Herbie analysis for a single expression.}%
  \label{fig:ppme-herbie-seq}%
\end{minipage}
\hfill%
\begin{minipage}{.55\textwidth}
  \includegraphics{img/ppme-herbie-inspection}%
   \caption{Inspection view of an annotated expression with the results reported by Herbie.}%
   \label{fig:ppme-herbie-intention}%
\end{minipage}
\end{figure}

%Herbie requires its input to be in the form of a \inline{herbie-test} instance in
%the Racket language:
%%  %
%  \begin{lstlisting}[basicstyle=\small\ttfamily, numbers=none, framesep=0pt,
%  rulesep=0pt, frame=none, mathescape=true] (herbie-test (<variables>) <name>
%  <expression>) \end{lstlisting}
% %  %
%  Each test has an arbitrary name field (\inline{<name>}). Commonly, a combination
%  of filename and line number of the expression to test is used. Since simulations
%  written in PPME are no traditional text files using the node id of the root
%  expression to test is a sane choice. As a benefit, this allows to map a given test
%  case back to a specific node in the PPME program. Besides the name tag, all free
%  variables in the expression \inline{<expression>} are listed in the variables
%  block \inline{<variables>}. The free variables are the variables to test in the
%  Herbie execution, i.\,e., these variables are tested with a series of sample
%  points.
% 
Expression annotation works via the MPS intentions dialog (Alt + Enter). 
%The intention will always annotate the root of the expression the cursor is currently placed on. 
A small icon indicates that an expression is marked for analysis (cf. first line in 
Figure~\ref{fig:ppme-herbie-intention}). 
All marked expressions are transformed into a prefix notation that matches Herbie's 
input language \emph{Racket}, built-in operations and data types.
PPME maintains the translated expression as a string, a reference to 
the original expression node and its identifier, as well as a table of variables. 
For the expression highlighted in Figure~\ref{fig:ppme-herbie-intention} the following test case is
generated:
%
\begin{lstlisting}[basicstyle=\footnotesize\ttfamily, language=lisp,morekeywords={herbie-test},numbers=none, framesep=0pt, rulesep=0pt, frame=none, mathescape=true]
(herbie-test (p_pos p_a delta_t p_v) "2430378650379961582"
  (+ (+ p_pos (* p_v delta_t)) (* (* 0.5 p_a) (expt delta_t 2))))
\end{lstlisting}
%
where the \texttt{herbie-test} macro is called with a list of variables, a unique name, and
the actual translated expression.

Figure~\ref{fig:ppme-herbie-seq} illustrates the whole process (steered by 
\inline{HerbieAction}) responsible for fetching the nodes to test, analyze the node, 
and write the result back as a UML sequence diagram.
%
The result of a Herbie execution is summarized and displayed to the user in the
inspection view as shown in Figure~\ref{fig:ppme-herbie-intention}. The original
expression is annotated with additional information, i.e., the error of the input and output
expressions, and the optimized computation regime for the arithmetic expression. This
allows inspecting the result generated by Herbie, and it keeps the
original expression in place without modifying it. Instead, PPME users
are responsible for replacing the annotated node by the optimized one before the
text generation phase. This prevents unwanted expression rewriting. 
%
Note that the generic design of the
execution model and the result container allow reusing the same setup for other
tools by extending the existing framework.
%Instead of transforming the original
%node into target source code the annotated optimization has to be generated. 
Moreover, analysis and code generation remain separate
processes. 

\subsection{Accuracy \revii{Optimization}}
\label{par:accuracy_improvements}

\begin{figure}
\footnotesize
\improvementsFigure%
{7.1231523}%
{0.08203125}%
{%
\[
\frac{\partial c \to U}{\partial t} = D_u \cdot \nabla^2 c \to U - c \to U \cdot c \to V^2 + F \cdot (1.0 - c \to U)
\]
%
\vspace*{-8pt}
\lstinputlisting[language=diff, basicstyle=\scriptsize, linerange=135-137, numbers=none, nolol,frame=tblr]  % chkTeX 8
{img/diff_gs_orig_herbie_2.diff}%
}
\caption{Exemplary improvements for an expression taken from the Gray-Scott example.}
\label{fig:herbie-improvements:gs_dU} % chkTeX 24
\end{figure}
%
We investigate the improvements in accuracy for two of the case-studies presented 
in Section~\ref{sub:case_studies}, the Lennard-Jones
simulation (LJ) and the Gray-Scott reaction-diffusion system (GS). We annotate
several expressions in each program, and execute them with and without optimization.
%
Figure~\ref{fig:herbie-improvements:gs_dU} shows the analysis result for 
$\frac{\partial U}{\partial t}$ for the GS example, including
input and output error, the original expression, and the difference in the
generated source code. The input expression has an average error of
 seven bits (cf.~\cite{Panchekha2015}), 
and Herbie was able to nearly remove inaccuracies by 
expanding and redistributing terms. We compare the numerical results for
simulations with $t_{start}=0$, $t_{end} = 4000$ and $\Delta{t}=0.5$. 
%
The computed values for $U$ and $V$ differ in the last four to seven of seventeen significant digits, 
which confirms that the changes have an impact. In our visualization (cf. Figure~\ref{fig:grayscott-ppml-sim}), 
the differences are not noticeable. However, a longer simulation time may yield visible differences.

For the LJ case study, we investigate several expressions, this time with and 
without considering known restrictions on input values. \revii{For example,} consider 
Equation~\ref{eq:lj-03}.
%
\begin{align}\label{eq:lj-03}
	dF &= (24.0 \cdot \varepsilon \cdot r_{pq}) \left(2.0 \cdot \frac{\sigma^{12}}{r_{s_{pq}}^{7}} - \frac{\sigma^{6}}{r_{s_{pq}}^{4}}\right)
 \text{, \footnotesize where $r_{s_{pq}} > 0, \sigma \in [10^{-2}, 10^{-1}], \varepsilon \in [10^{-14}, 10^{-13}]$} 
\end{align}
%
In the case without value-range restrictions, the analysis found an improvement of 
${34.0}\mapsto{15.6}$ bits. However, this theoretical potential is
not reasonable when considering actual variable ranges, since the algorithm checks 
the whole domain of input values instead of optimizing over a small feasible interval only.
Consequently, only one of the analyzed expressions yielded 
an actual improvement after accounting for additional constraints using range annotations
(e.g., parameters with constant values) obtained from PPME's code analysis. 
As a consequence, the analysis did not find significant
improvements\footnote{In fact, the analysis increased the error from $5\mapsto{11}$ ($5\mapsto{20}$) bits 
on Racket version $6.4$ ($6.7$) using seeds $2808995595$, $415209655$, $1218262282$, $3135925998$, $2713258581$,
$1066853958$ and Herbie commit hash \texttt{f6ebaea}. In contrast, in version $1.0$ of the tool, input and output error
remained at around $4$ bits.}. 
Hence, additional information about variables may be required to generate reliable results. A DSL like ours
may help extract such information automatically.  

\subsection{\revii{Impact} on Runtime Performance}
\label{par:influence_on_runtime_performance}
Since the optimization modifies expressions and, in some cases, replaces a simple assignment
with a complex one containing several conditional branches, its influence on runtime
performance might be of concern. Therefore, we investigate the impact on execution time 
for the GS and LJ case studies. We compare the runtime of
the original program for each use case with the optimized versions. To factor out 
disk-I/O from the measurements, the
simulations are modified so that no output is generated. The tests
were run on a system with an Intel Core i3-4160 CPU, 16~GB random-access memory 
and Ubuntu Linux with kernel 4.2.0.
%\footnote{While this is not an HPC machine, we found this 
%setup sufficient for our experiments since we were not interested in showing absolute 
%performance numbers but what kind of impact can be expected from such kinds of 
%accuracy optimizations.}

\begin{figure}[tp]
	\begin{minipage}[b]{.45\textwidth}
		\centering
		\includegraphics[width=1\textwidth]{img/bench_gs_small.pdf}
		\caption%
		[Runtime comparison for the Gray-Scott case study.]
		{
		Runtime comparison for the Gray-Scott example with $t_\mathrm{end} = 2000$.
		The median runtime for both simulations is nearly identical, which indicates that Herbie's optimization have no impact on the program's runtime performance.
		}
		\label{fig:bench_gs}
	\end{minipage}
	\hfill
	\begin{minipage}[b]{.45\textwidth}
		\centering
                 \includegraphics[width=1\textwidth]{img/bench_lj_small.pdf}
		\caption%
		[Runtime comparison for the Lennard-Jones case study.]
		{
		Runtime comparison for the Lennard-Jones example.
		The execution of the program modified by Herbie was approximately $20\,\%$ faster than the original implementation.\newline
		}
		\label{fig:bench_lj}
	\end{minipage}
\end{figure}

We executed the GS use case $100$ times per variant with $4000$ steps 
($t_{start} = 0.0$, $t_{end} = 2000.0$, $\Delta{t} = 0.5$).  Figure~\ref{fig:bench_gs} 
shows the variation of the execution times as a box plot. The median of both 
variants is nearly identical while the data are less scattered for the original simulation
with a few outliers at approximately the minimal execution time of the modified 
program. For GS there is therefore no significant performance impact due to the accuracy 
optimizations.
%\sk{Note: to further verify this, we could rerun the experiments 1000 or 10000 
%times, this could also help to get rid of the outliners}

In the case of LJ, we compared the runtime of the original program 
to a variant with several transformed expressions, including Equation~\ref{eq:lj-03} 
without range restrictions. The simulation is  
executed for $n = 5000$ particles, end time $t_\mathrm{end} = 0.2$, and 
$\Delta{t} = 1.0 \cdot 10^{-6}$ ($200,000$ steps). The results are summarized in
Figure~\ref{fig:bench_lj}, both variants were run $25$ times.
%IFS: what was sigma and epsilon?
%
The accuracy-optimized version runs nearly $20\,\%$ faster than the
original implementation. However, this can be attributed to over-simplifications of
some of the expressions due to the missing range restrictions. Considering the actual numbers
produced by the simulation, the two variants visibly differ in their results, with the optimized version being less accurate, \revii{yielding force values that are two orders of magnitude lower. This is the result of Herbie removing a complete subterm from the force equation.}
%
When taking parameter value ranges into account, only one expression could be improved 
through a simple restructuring of its terms. In this case, we can not
detect any impact on the program's execution time, but the results remain correct.

\section{Introduction}
\label{sec:intro}

Markov chain Monte Carlo (MCMC) is a sampling algorithm that {in principle} can simulate any probability distribution. {In practice,} many MCMC algorithms are infeasible when target density evaluations are computationally intensive. In this paper, we present an algorithm that mitigates this issue, achieving two desirable properties:  (i) vastly reducing the number of target density evaluations per MCMC step, while (ii) \textit{provably} retaining a convergence rate roughly equal to that of the original expensive algorithm. 

Challenges associated with computationally intractable target densities are extremely well known in the Monte Carlo literature. We now give a short survey of approaches to the problem, emphasizing the contributions of the current paper.
%
Replacing the intractable target density with an approximation or  ``surrogate model'' is the simplest way to significantly reduce the computational cost of MCMC. Replacing the target density with a \textit{fixed} surrogate, however, introduces a non-vanishing bias \citep{MarzoukXiu2009, Cotteretal2010, Bliznyuketal2012, LiMarzouk2014, Cui2016etal, stuart2018posterior}. 
%
The obvious solution to the problem of non-vanishing bias is to iteratively refine the surrogate during sampling. This strategy introduces some non-trivial technical difficulties: continual surrogate refinement within MCMC results in a process that is not Markovian. Such non-Markovian processes can have surprising and terrible convergence properties even when the surrogate has very low pointwise error \citep{LatuszynskiRosenthal2014}, sometimes failing to converge at all. In our previous work \citep{Conradetal2016, Conradetal2018}, we presented an MCMC algorithm with a continually refined surrogate based on \textit{local approximations}. We showed that this algorithm avoided the worst of these convergence problems and produced asymptotically exact results under certain strong assumptions. 

These strong assumptions are symptoms of a practical problem with how local approximation and MCMC interact in the ``tails'' of the target distribution. \citet{Conradetal2016, Conradetal2018} built a piecewise polynomial approximation by solving a local regression problem, using a small number of nearby exact target density evaluations. Refinements triggered by a cross-validation heuristic on the acceptance ratio added new points to the set of target density evaluations. Ideally, this approach should avoid expensive density evaluations in regions of low probability---particularly the tails of the distribution. In practice, there is an important tension: the cross-validation heuristic requires many \textit{more} tail evaluations than a good global design would suggest, but gives many \textit{fewer} tail evaluations than are sometimes required for global convergence and stability of the MCMC algorithm. 

In \citet{Conradetal2016, Conradetal2018} we showed that this tension could be avoided under certain strong tail conditions, with the additional requirement of randomly triggered surrogate refinements to ensure convergence. 

In more general settings, the underlying tension remains and leads to two serious issues which we address in the present paper.
%
First is the behavior of the cross-validation heuristic noted above: % absent stability considerations, 
it demands more refinements in low probability regions than the goal of ``good'' approximation of the target density (in a natural sense that we will make precise later) would dictate. Second, and even worse, local polynomial approximations typically have very bad tail behavior, even failing to be integrable unless nearly every point in the tail has a density evaluation. 

To resolve the first issue, we introduce here a new surrogate refinement strategy that relaxes the acceptable error threshold in the tails of the distribution. The refinement strategy also \emph{balances} the rate of decay of the surrogate bias with that of Monte Carlo variance, using a local error indicator to characterize the bias. To resolve the second issue, we introduce a new correction term for the Metropolis-Hastings acceptance ratio that allows the algorithm to retain good convergence properties even under very weak assumptions about tail behavior, and without requiring integrability of the surrogate. 
%
The result is a local approximation MCMC (LA-MCMC) algorithm that tends to require far fewer density evaluations (resulting in faster runs) while delivering robust performance for a much broader class of target distributions. From a practical point of view, work such as \citet{Conradetal2016, Conradetal2018, Angelikopoulosetal2015} showed that the number of expensive target density evaluations can be reduced by orders of magnitude with minimal impact on the accuracy of target expectation estimates. Our new algorithm further reduces the number of density evaluations to nearly the rate-optimal number, without sacrificing MCMC stability.

From a theoretical point of view, we \textit{guarantee} that LA-MCMC converges quickly by providing useful bounds on the convergence of the algorithm after a \textit{finite} number of MCMC steps.  Our main result is that the mean-square error (MSE) of our LA-MCMC estimates decays at roughly the expected $1/T$ rate, where $T$ is the number of MCMC steps. We also show that LA-MCMC converges under very weak tail bounds that hold for many statistical examples. Comparatively, \citet{Conradetal2016} only established a law of large numbers that applied for special tail shapes. 

Using our optimal surrogate refinement strategy, the refinement rate (i.e., the rate at which new density evaluations are demanded) decreases with $T$. This implies that the decay of the MSE as the number of density evaluations $n$ increases is not only faster than the $1/n$ rate expected for standard geometrically ergodic MCMC, but also that this convergence rate (in $n$) may accelerate as the number of MCMC steps $T$ increases. 

\edits{
\paragraph{Other related work.}
There have been many attempts to accelerate MCMC for models that are expensive to compute. We have already discussed work based on the construction of surrogate models/approximations for the target density. This discussion was not exhaustive, and we point to the survey paper \citet{llorente2021survey} for a broader overview of various other techniques and when they are most useful. 
%
We also briefly describe several approaches that are quite different from ours.
%
The multi-level MCMC approach of \citet{Dodwelletal2015}, and related multi-index extensions \citep{jasra2018multi}, rely on predefined hierarchies of models---e.g., corresponding to different mesh refinements of an underlying differential equation model---that induce trade-offs between computational cost and accuracy. These approaches can drastically reduce the number of expensive model evaluations and total wallclock time of an MCMC run, but require a careful understanding of numerical approximation errors to achieve optimal convergence rates. Another part of the literature, including \citet{kaipio2007statistical,chkrebtii2016bayesian} and other related work, creates statistical models of numerical discretization error in ODE or PDE models. 
%
The delayed-acceptance MCMC method (e.g., \citet{ChristenFox2005, Cuietal2011}) can also exploit a hierarchy of models, but instead ``screens'' MCMC proposals through the approximate model(s) and evaluates the expensive target density at least once for each accepted sample, thus reducing cost by a constant factor. 

The MCMC method of \citet{doi:10.1080/10618600.2016.1231064} makes central use of delayed acceptance, but also builds surrogates through local approximation of the target density---and in that sense has many interesting links to the present approach. We summarize some of the similarities and differences as follows. First, rather than using a local polynomial approximation as we do here, \citet{doi:10.1080/10618600.2016.1231064} approximates the target density (or likelihood) with a simpler weighted average of its values at the $k$ nearest previous evaluation points. In principle, however, both algorithms can be run with a wide variety of local approximations. A more substantive distinction is that \citet{doi:10.1080/10618600.2016.1231064} fundamentally relies on the delayed-acceptance construction, and additionally on the presence of a standard non-adaptive Metropolis transition kernel employing the expensive target, to ensure ergodicity. 
%
The ratio of model evaluations to MCMC steps in the approximate MCMC algorithm is thus bounded below by a nonzero constant.
%
Moreover, to ensure diminishing adaptation, not all of the expensive target density evaluations are used to inform the surrogate, which reduces efficiency. 
%
In contrast, both \citet{Conradetal2016,Conradetal2018} and the new construction we propose here do not employ delayed acceptance, and instead carefully control the convergence of the local approximation to ensure ergodicity for the exact target.
%
All target density evaluations are used to build the surrogate, and we use a controlled, rather than opportunistic, design strategy to choose new evaluation points. 

A key improvement of the present work over both \citet{doi:10.1080/10618600.2016.1231064} and \citet{Conradetal2016,Conradetal2018} is that our new algorithm has much stronger theoretical convergence guarantees, and is applicable to a broader class of target distributions. For instance, earlier local approximation methods assume that the target distribution has tails that are very light or otherwise very special (\citet{doi:10.1080/10618600.2016.1231064} assume a uniform minorization condition; \citet{Conradetal2016} assumes either compact support or something very similar to a uniform minorization condition). Under such conditions, these efforts showed that their algorithms are ergodic (that is, Monte Carlo averages converge at some unspecified rate).
%
Our current effort substantially improves on all of these: we allow the ratio of model evaluations to MCMC steps to decay to zero quite quickly, we allow the target distribution to have quite general tails, and we give a nearly-optimal bound on the rate of convergence. We emphasize that these improvements are not merely theoretical; they represent real improvements in algorithm performance. For example, it is shockingly easy to write down an algorithm that looks quite a bit like the one in our present paper that \moreedits{\textit{does not}} converge at the correct rate or \textit{does} require the number of model evaluations to grow roughly linearly in the number of MCMC steps (see, e.g., Section~\ref{sec:example-banana}).

\paragraph{Scope.}
This paper focuses on the core problems of surrogate construction and refinement, tail correction, and convergence analysis, all in the context of a Metropolis--Hastings-type scheme. Many variations and extensions are possible, and indeed it is often fruitful to \emph{merge} the most important techniques presented in various papers. For instance, one could consider using gradient information from the surrogate within the Metropolis proposal, as in the MALA scheme of \citet{Conradetal2018}. \citet{doi:10.1080/10618600.2016.1231064} has an extensive discussion of $k$d-trees and their use in facilitating fast nearest neighbor searching; we use $k$d-trees in our implementation as well (see Section~\ref{sec:numerics}), but without some of the online point addition and re-balancing heuristics proposed in that paper. \citet{doi:10.1080/10618600.2016.1231064} also consider a pseudo-marginal version of their approximate MCMC algorithm, where only noisy unbiased evaluations of the expensive target density are available. An exhaustive evaluation and comparison of these methods is beyond the scope of the present work. A complete implementation of our algorithm is available within the software package MUQ (\url{https://muq.mit.edu}), so that users can combine our LA-MCMC scheme with more advanced transition kernels or other computational tools that improve performance. 

\moreedits{We also note that our emphasis here is on inference problems with expensive models (for instance, numerical discretizations of partial differential equations), but in \emph{moderate} parameter dimensions (for instance, $d=9$ in our last example, or $d=12$ in  \citet{Conradetal2018}). 
% \todo{YM: flag to check here before submission. AS: I just looked through quickly. Example 5.1 seems to be 2-dimensional, 5.2 seems to be 6-dimensional, and 5.3 seems to be 12-dimensional. So we can write $d=12$ but I couldn't quickly find $d=20$. YM: Good catch. Fixed!} 
Posterior sampling in higher dimensional settings presents an additional set of challenges, outside of the present scope. Moreover, function approximation (and hence surrogate modeling) in high dimensions is generically subject to the curse of dimensionality, unless one can exploit some special structure.} For example, \citet{Cui2016etal} combines parameter-space dimension reduction with intrusive model reduction methods for expensive likelihoods. It should be feasible to combine our LA-MCMC approach with dimension reduction methods for Bayesian inverse problems \citep{cui2014likelihood,constantine2016accelerating,zahm2018certified} in a similar way.

}

\paragraph{Organization of the paper.} In Section~\ref{sec:numerics} we present our new algorithm, including the refinement scheme, the bias-variance tradeoff, and the tail correction. Section~\ref{sec:theory} describes our main theoretical results. Section~\ref{sec:examples} provides a range of numerical examples, beginning with simple configurations intended to illustrate specific features and variations of the algorithm, and culminating in the inference of a spatially distributed coefficient in a set of nonlinear PDEs.

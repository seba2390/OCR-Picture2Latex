% \documentclass[twocolumn]{svjour3}
\documentclass{svjour3}

\usepackage{inputenc}

\usepackage[letterpaper,centering,margin=1in]{geometry}
%\usepackage[colorlinks=false]{hyperref}
\usepackage{natbib} % loaded by svjour3 with natbib option

\usepackage{amsfonts} 
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{bm}
\usepackage{url}

\usepackage[color=blue!30!white,textsize=tiny]{todonotes}
\setlength{\marginparwidth}{2.1cm}

\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
%\usepackage[linesnumbered,noend]{algorithmic}
%\usepackage{algorithmicx}

\usepackage{graphicx}
%\usepackage{subcaption}

\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\diag}{diag}
\DeclareMathOperator*{\var}{Var}
\DeclareMathOperator*{\vol}{Vol}
\DeclareMathOperator*{\E}{\mathbb{E}}
\DeclareMathOperator*{\sign}{sign}

\newtheorem{assumption}{Assumption}

\smartqed  % flush right qed marks, e.g. at end of proof

% \usepackage{mathptmx}      % use Times fonts if available on your TeX system
%
% insert here the call for the packages your document requires
%\usepackage{latexsym}
% etc.
%
% please place your own definitions here and don't use \def but
% \newcommand{}{}
%
% Insert the name of "your journal" with
% \journalname{myjournal}

% \newcommand{\edits}[1]{{\color{blue!80!black}{#1}}}
\newcommand{\edits}[1]{{\color{black}{#1}}}

\newcommand{\moreedits}[1]{{\color{black}{#1}}}

\DeclareUnicodeCharacter{2212}{\textendash}

\begin{document}

\title{Rate-optimal refinement strategies for local approximation MCMC
  \thanks{AS was supported by NSERC. AD and YM were supported by the SciDAC program of the DOE Office of Advanced Scientific Computing Research.}
% [Grants or other notes about the article that should go on the front page should be placed here. General acknowledgments should be placed at the end of the article.]}
}

\subtitle{}

\author{Andrew D. Davis \and Youssef Marzouk \and Aaron Smith \and Natesh Pillai}
\institute{A.~D.~Davis \at
                Courant Institute of Mathematical Sciences,
                New York, NY USA
              \email{davisad@alum.mit.edu}           %  \\
%             \emph{Present address:} of F. Author  %  if needed
           \and
          Y.~M.~Marzouk \at
            Massachusetts Institute of Technology,
            Cambridge, MA USA
            \email{ymarz@mit.edu}
          \and
          A.~M.~Smith \at
            University of Ottawa,
            Ottawa, Canada
            \email{asmi28@uottawa.ca}
            \and
          N.~Pillai \at
            Harvard University,
            Cambridge, MA USA
            \email{pillai@fas.harvard.edu}
}

\titlerunning{Rate-optimal refinement for local approximation MCMC}        % if too long for running head

\authorrunning{Davis et al.} % if too long for running head

\maketitle

\begin{abstract}
Many Bayesian inference problems involve target distributions whose density functions are computationally expensive to evaluate. Replacing the target density with a local approximation based on a small number of carefully chosen density evaluations can significantly reduce the computational expense of Markov chain Monte Carlo (MCMC) sampling. Moreover, continual refinement of the local approximation can guarantee asymptotically exact sampling. We devise a new strategy for balancing the decay rate of the bias due to the approximation with that of the MCMC variance. We prove that the error of the resulting local approximation MCMC (LA-MCMC) algorithm decays at roughly the expected $1/\sqrt{T}$ rate, and we demonstrate this rate numerically. We also introduce an algorithmic parameter that guarantees convergence given very weak tail bounds, significantly strengthening previous convergence results. Finally, we apply LA-MCMC to a computationally intensive Bayesian inverse problem arising in groundwater hydrology.

\keywords{Markov chain Monte Carlo \and local regression \and Bayesian inference \and surrogate models \and sampling methods}
\PACS{02.50.âˆ’r \and 02.50.Ng \and 02.50.Tt \and 02.70.Uu}
% \subclass{MSC code1 \and MSC code2 \and more}
\end{abstract}

\input{introduction}

\input{numerics}

\input{theory}

\section{Numerical examples}
\label{sec:examples}
We present three numerical experiments. The first focuses on understanding the convergence of the LA-MCMC algorithm and the impact of various algorithmic parameters controlling the approximation. The second experiment illustrates the tail correction approach described in Section~\ref{sec:tailcorrection}. The third then demonstrates the practical performance of LA-MCMC in a computationally challenging large-scale application: an inverse problem arising in groundwater hydrology.


\input{1d_example}

\input{banana}

\input{tracer-edited}

\input{conclusion}

\appendix

\input{theory_filtration}

% \begin{acknowledgements}
% If you'd like to thank anyone, place your comments here.
% \todo{Fill this in! I think we already acknowledged funding on the title page.}
% \end{acknowledgements}

% BibTeX users please use one of
%\bibliographystyle{spbasic}      % basic style, author-year citations
% \bibliographystyle{spmpsci}      % mathematics and physical sciences
% \bibliographystyle{spphys}       % APS-like style for physics
%\bibliography{workscited}   % name your BibTeX data base

\input{main.bbl}

\end{document}

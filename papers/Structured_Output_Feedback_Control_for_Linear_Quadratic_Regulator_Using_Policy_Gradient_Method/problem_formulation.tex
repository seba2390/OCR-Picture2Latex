% \documentclass[ex_article]{subfiles}
% \begin{document}
\section{Problem Formulation}\label{sec:problem}
%\subsection{Linear system}
We consider the linear time-invariant (LTI) system
\begin{align}
  \begin{aligned}
    \dot x(t) = Ax(t)+Bu(t), \quad
    y(t)     = C x(t),\quad
    x(0) \sim \mathcal D,
  \end{aligned}\label{eq:system}
\end{align}
where $x(t) \in \R^n$ is state, $u(t)\in \R^m$ is input,
$y(t)\in \R^p$ is output, $A\in \R^{n\times n}$,
$B\in \R^{n\times m}$, and $C \in \R^{p\times n}$ are constant matrices, and $\mathcal D$ is a probability distribution over $\R^n$.
In this paper, we assume that $B$ and $C$ are not zero matrices,
and
$(A, B, C, \mathcal {D})$
is unknown unlike the situation in \cite{fatkhullin2021optimizing}.
%\subsection{LQR problem with structured constraints} \label{Sec2-B}
The infinite-horizon continuous-time LQR problem is formulated as
\begin{align}
  \minimize  & E_{x(0)\sim \mathcal{D}}\qty[\int_0^\infty \qty(y^\top(t) Q y(t) + u^\top(t) R u(t))dt ] \label{eq:objectivefunction} \\
  \subjectto & ~\eqref{eq:system}
\end{align}
with constant positive definite matrices $Q \in \R^{p\times p}$ and $R\in \R^{m\times m}$.
The expectation is taken with respect to the initial state $x(0) \sim \mathcal{D}$.
For the static output feedback $u(t) = -Ky(t)$ with $K\in \R^{m\times p}$ to system~\eqref{eq:system},
the objective function~\eqref{eq:objectivefunction} becomes
$
  f(K) := E_{x(0)\sim \mathcal{D}}\qty[\tilde{f}(K;x(0))],
$
where 
\begin{align}
  \tilde f(K;v) & := \int_0^\infty \qty[v^* e^{A_K^\top t}C^\top(Q+ K^\top RK)Ce^{A_K t}v]dt\label{eq:cost}
\end{align}
for $v\in \C^n$.
Then, the closed-loop is given by
\begin{align}
    \dot x(t)  = A_Kx(t),\quad
    y(t)          = Cx(t), \label{eq:closedloop}
\end{align}
where 
\begin{align}
  A_K := A-BKC. \label{eq:AK}
\end{align}



In this paper, we consider the constraints $K\in \Omega$,
where $\Omega \subset \R^{m\times p}$ is a closed convex set
that specifies the structural information of feedback gains.
This is because a structured policy is often used in practical situations.
For example,
%\subsubsection{Decentralized control}
\begin{itemize}
    \item Decentralized control: In decentralized control, some components of $K$ need to be $0$~\cite{jovanovic2016controller}.
This implies that $\Omega$ should be a certain linear subspace of $\R^{m\times p}$.

\item Linear port-Hamiltonian system: For a linear port-Hamiltonian system~\cite{Jacob2012linear}, 
if the feedback gain is positive semi-definite, the closed loop system is also a port-Hamiltonian system and passive. To ensure passivity, $\Omega$ should be defined as the set of positive semi-definite matrices, which is closed and convex.

\end{itemize}
%\subsubsection{Linear port-Hamiltonian system}



%See Section~\ref{sec:examples}.


By using Bellman lemma~\cite{bellman1957notes}, the problem~\eqref{eq:objectivefunction} with structured constraints can be formulated as
\begin{align}
  \begin{aligned}
    \minimize_K & f(K) = \tr(X\Sigma) \\
    \subjectto  & K \in \Omega\,\, \text{and}\,\, A_K\text{ is \textit{Hurwitz}},
  \end{aligned}\label{eq:problem}
\end{align}
where
$
  \Sigma  := E[x(0)x^\top(0)]
$
and $X$ is the solution to
\begin{align}
  A_K^\top X + XA_K + C^\top \qty(K^\top RK + Q)C = 0.
\end{align}
It is difficult to solve \eqref{eq:problem}, since  $f(K)$ is non-convex and saddle points may exist~\cite{fatkhullin2021optimizing}.
Moreover,
 the feasible set may have exponentilally many disconnected components~\cite{feng2019exponential}. 
Although an iterative method was proposed in \cite{zhu2015adaptive} to obtain a suboptimal static output feedback gain in the model free setting,
it cannot be applied directly to problem \eqref{eq:problem} due to the constraint $K\in \Omega$.

% In this paper, we suppose that $(A, B, C, \mathcal {D})$ in \eqref{eq:system}
% is unknown unlike the situation in \cite{fatkhullin2021optimizing}.
% Thus, we develop a model free algorithm in Section \ref{sec:model-free} for solving the problem \eqref{eq:problem}.


To develop a model free algorithm with theoretical guarantees for solving problem \eqref{eq:problem}, we impose the following throughout this paper:
\begin{assumption}\label{assume:sigma-hurwitz}
  \indent
  \begin{enumerate}
    \item $\Sigma \succ 0$.
    \item The pair $(A, C)$ is observable.
    \item There exists $K_0 \in \Omega$
          such that $A_{K_0}$ is \textit{Hurwitz}
          and $K_0$ is known.
  \end{enumerate}
\end{assumption}


Since $A_{K_0}$ is \textit{Hurwitz},
there exist positive definite matrices $G, H$ and a skew-adjoint matrix $J$
such that
$
  A_{K_0} = (J-G)H.
$
The proof is found in~\cite{prajna2002lmi}.
Let $H = L^\top L$ be the Cholesky decomposition.
Using the coordinate transformation $x'(t) = Lx(t)$, the closed-loop system~\eqref{eq:closedloop} becomes
\begin{align}
  \dot{x'}(t)  = A'_{K_0}x'(t), \quad 
  y(t)         = C'x'(t),
\end{align}
where $A'_{K_0}  = LJL^\top-LGL^\top, C' = CL^{-1}$.
Since $LGL^\top\succ 0$ and $LJL^\top = -(LJL^\top)^\top$, we have
  $A'_{K_0}+{A'_{K_0}}^\top = -2LGL^\top \prec 0$.
In the following, we assume system \eqref{eq:closedloop} after the above coordinate transformation, because we consider a static output feedback that is invariant by the coordinate transformation. That is, without loss of generality, we can assume
$A_{K_0}+A_{K_0}^\top \prec 0$.

Under Assumption \ref{assume:sigma-hurwitz},
 $f(K)$ of \eqref{eq:problem} is defined only on the set $S$ of stabilizing controllers, which is defined as
\begin{align}
  S = \{K\in \R^{m\times p}\mid A_K\text{ is \textit{Hurwitz}}\}. \label{eq:S}
\end{align}
If $K\notin S$, there exists an eigenvalue $\mu$ of $A$ such that ${\rm Re}(\mu) \geq 0$ and $f(K)$ goes to infinity.

\begin{remark} \label{remark1}
The objective function of
 problem \eqref{eq:objectivefunction}
is not a
standard LQR cost
%is given by
% \begin{align}
%     \int_0^\infty \qty(x^\top(t) Q x(t) + u^\top(t) R u(t))dt,
% \end{align}
% where $Q \in \R^{n\times n}$ and $R\in \R^{m\times m}$ are positive definite matrices. However, in the model free and output feedback setting, this cost cannot be calculated in practice, because the information of the state $x(t)$ is not available. Therefore, we consider the problem \eqref{eq:objectivefunction} following
as in some previous researches~\cite{modares2016optimal, rizvi2018output}. While similar convergence properties to the standard LQR cost can be obtained for our formulation in the model based setting if $(A, C)$ is observable~\cite{fatkhullin2021optimizing}, more detailed studies of the objective function properties are necessary for model-free version of the convergence analysis.  
\end{remark}



%\subsection{Examples}\label{sec:examples}


% \end{document}
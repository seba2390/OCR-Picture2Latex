
The private information retrieval (PIR) problem was introduced by Chor et al. \cite{PIRfirst} as a privacy-preserving primitive for retrieving information in a private manner. In the canonical PIR setting, a user wishes to retrieve one of $K$ available messages, from $N$ non-communicating servers, each of which has a copy of these $K$ messages. User request privacy needs to be preserved during the retrieval process, i.e., the identity of the desired message remains unknown to any single server. A generic protocol to retrieve, e.g., message $k$, is as follows in this setting:
\begin{enumerate}
\item The user generates $N$ queries with a private random key and the message index $k$, one query per server, which are sent to the respective servers;
\item Each server, based on the query it receives and the content it stores, sends back an answer to the user;
\item The user collects the answers from $N$ databases, and reconstructs the message based on the answers, the private key, and the requested message index $k$.
\end{enumerate}

The privacy requirement can be either information-theoretic (e.g., \cite{Beimel_Ishai}) or computational (e.g., \cite{CPIR_log}). The former requires that each server cannot infer any information on the identity of the requested message, even if assuming the server has infinite computation power; in contrast, the latter assumes that each server has only limited computation power, and under such computational constraint, it is required that the server cannot learn anything on the identity of the requested message. In this article, we only consider information-theoretic privacy.

\begin{figure}[t]
\centering
\vspace{0.2cm}
\includegraphics[width=0.7\textwidth]{figures/Fig-1-Chor-Scheme.pdf}
\caption{The PIR scheme of Chor et al. \cite{PIRfirst} for $N=2$ databases which achieves a rate of $1/2$ for any number of messages $K$ (for the case shown in the figure, i.e., for $K=3$ messages, the capacity is $4/7$ \cite{sun2017PIRcapacity}). The main idea is to use the fact that since the databases cannot collude, one can send correlated queries across databases, allowing the user to leverage information retrieved across databases to increase the rate (download efficiency).  \label{fig:Chor-scheme} }
\end{figure}

Since the introduction of the PIR problem by Chor et al., tremendous advances have been made using the computer science theoretic approach, including on the canonical form and many variations; see the survey article \cite{William} and references therein. Within the context of this approach, the effort usually focuses on the scaling behavior of the communication costs, including both the query communication (upload) cost and the answer communication (download) cost, with respect to $N$ and $K$. Moreover, the messages are usually assumed to be very short, the most common of which is in fact a single bit per message. There have been many variations on the canonical setting, and it has been recognized that the PIR problem has deep connections to other coding or security primitives, such as locally decodable codes and oblivious transfer \cite{goldreich2002lower,YekhaninPhd,di2000single}. 

It was shown in Chor et al. that for a single database,  perfect information-theoretic privacy can only be achieved by downloading the entire database (of $K$ messages), i.e., the optimal rate defined as the ratio of the amount of desired information (one message)  and the total downloaded amount ($K$ messages) in this case is $1/K$. Thus, a natural question that was first explored by Chor et. al is the following: can one achieve a better rate than $1/K$ by exploiting $N>1$ databases? This question was answered in the affirmative, and it was shown that even with $N=2$ databases, one can achieve a rate of $1/2$ for any number of messages. We explain the main idea through a simple example as shown in Fig. \ref{fig:Chor-scheme} for $K=3$ messages. The main idea behind the scheme is as follows: assuming each message $W_k$ is one-bit, the user generates $K$ random bits $\{h_1, \ldots, h_K\}$
and  requests the linear combination (denoted by $\sum_{k=1}^{K}h_k W_k$) of the $K$ messages from database $1$, whereas requests $\sum_{k=1}^{K}h_k W_k + W_{\theta}$ from the other database whenever the user wants  to retrieve $W_\theta$. Since $\{h_k\}$'s are uniformly generated bits, the distribution of $\sum_{k=1}^{K}h_k W_k + W_{\theta}$ is identical for every $\theta \in \{1, 2,\ldots, K\}$, ensuring perfect privacy. 

\begin{figure}[t]
\centering
\vspace{0.2cm}
\includegraphics[width=0.7\textwidth]{figures/Fig-2-Shah-Scheme.pdf}
\caption{The PIR scheme of Shah et al. \cite{Shah_Rashmi_Kannan} for $N=3$ databases and $K=2$ messages which achieves a rate of $2/3$ (the capacity for this setting is $3/4$ \cite{sun2017PIRcapacity}). More generally, the scheme achieves a rate of $1-1/N$, irrespective of $K$. The new ingredient beyond Chor et al. \cite{PIRfirst} involved message sub-packetization.  \label{fig:Shah-scheme} }
\end{figure}

The PIR problem was recently reintroduced to the information theory and coding community \cite{Shah_Rashmi_Kannan,Chan_Ho_Yamamoto,Fazeli_Vardy_Yaakobi}, with initial effort focused on using advanced coding technique to improve the storage, upload, and download efficiency. Specifically, Shah et al. \cite{Shah_Rashmi_Kannan} generalized the Chor et al. scheme to any arbitrary number $(N>1)$ of databases. The key new idea herein was to \text{subpacketize} each message into $(N-1)$ parts, and then follow an approach similar to Chor et al. In Fig.  
\ref{fig:Shah-scheme}, we highlight this through an example when $N=3$ and for $K=2$ messages. Each message is partitioned into $(N-1)=2$ parts, following which the user then requests a random linear combination ($A_{1}$ from database $1$), followed by requesting $A_{1}$ XORed with the $(N-1)$ subpackets individually from the remaining $(N-1)$ databases. This leads to a rate of $\frac{N-1}{N}=1-\frac{1}{N}$, which is independent of $K$. 

A significant milestone of this renewed effort on the PIR problem is the result obtained in \cite{sun2017PIRcapacity}, where the optimal download cost of the PIR capacity of the canonical setting was fully characterized. A key new ingredient that leads to this breakthrough is the information-theoretic reformulation of the problem. In contrast to typical computer science theoretical formulation, here the number of bits in each message is allowed to approach infinity, and the capacity is defined as the supremum of the number of useful message bits that can be retrieved per total downloaded bits. 

\begin{figure}[t]
\centering
\vspace{0.2cm}
\includegraphics[width=0.7\textwidth]{figures/Fig-3-Sun-Jafar-Scheme.pdf}
\caption{The capacity-achieving PIR scheme of Sun and Jafar  \cite{sun2017PIRcapacity} for $N=2$ databases and $K=2$ messages which achieves a rate of $2/3$. The optimal scheme requires a combination of the following ideas: a) message sub-packetization, b) maintaining message symmetry for privacy and c) fully exploiting side information (from other databases) at each database.  \label{fig:Sun-Jafar-scheme} }
\end{figure}

A code construction was provided which relies on a few key code design principles. The scheme by Sun and Jafar for $N=2$ databases and $K=2$ messages is illustrated in Fig. \ref{fig:Sun-Jafar-scheme}. The key design principles behind the scheme include the following: a) sub-packetization of each message into $L= N^{K}$ symbols, followed by b) downloading parts of each message from every database (i.e., maintaining \textit{message symmetry}) for maintaining privacy of the desired message index, and c) fully exploiting side information at every database (from remaining $(N-1)$ databases). For the example in Fig. \ref{fig:Sun-Jafar-scheme}, this amounts to breaking the two messages into $L=4$ symbols. If the user wants to download message $W_1 = (a_1, a_2, a_3, a_4)$, it downloads one symbol from each message from both databases (namely, $(a_1, b_1)$ from database 1 and $(a_2, b_2)$ from database 2). Subsequently it downloads $a_3 + b_2$ from database 1 and $a_4+ b_1$ from database 2 (i.e., the remaining desired symbols together with the undesired symbols downloaded from the other database). A matching converse is proved using the conventional information theoretic approach. 

The surprising result inspired many subsequent works using such a capacity formulation and led to many new discoveries which will be surveyed in this part of the article. 

\subsection{The Canonical PIR System}

For the canonical PIR setting, shown in Fig. \ref{fig:PIR_diag}, a rigorous computer science theoretic problem definition of the problem was given in the seminal paper \cite{PIRfirst}, and a more explicit information theoretic translation was given in \cite{tian2019capacity}. 
The breakthrough work of Sun and Jafar \cite{sun2017PIRcapacity} instead directly represented the coding function relations using information measure relations, which we explain next.

The random query $Q^{[k]}_n$ intended for server-$n$ when requesting message $k$ is determined by the private random key $\mathsf{F}$, i.e.,
$H(Q^{[k]}_n|\mathsf{F})=0$, for $n=1,2,\ldots,N,\, k=1,2,\ldots,K$. The answers $A^{[k]}_n$ from server-$n$, in response to the query $Q^{[k]}_n$, is determined by the stored messages and the query, i.e.,
$H(A^{[k]}_n|W_{1:K},Q^{[k]}_n)=0$,  for $n=1,2,\ldots,N,\,  k= 1,2,\ldots,K$. Given the above, there are two key constraints/requirements from a PIR scheme: 
\begin{enumerate}
\item \textit{Decodability Constraint:} The reconstructed message $\hat{W}_k$, by the user for the requested message $k$, is determined from the answers $A^{[k]}_{1:N}$ and the random key $\mathsf{F}$, i.e., 
\begin{align}
H(\hat{W}_k|A^{[k]}_{1:N},\mathsf{F})=0, \, \text{for } k\in\{1,2,\ldots,K\}.
\end{align}
\item \textit{Privacy Constraint:} The privacy requirement is that the queries for any message pairs $k$ and $k'$ have an identical distribution
\begin{align}
\mathbf{Pr}(Q^{[k]}_n=q)=\mathbf{Pr}(Q^{[k']}_n=q),
\end{align}
which can be represented as $I(\theta;Q^{[\theta]}_n,A^{[\theta]}_n,W_{1:K})=0$, for $n\in \{1, 2, \ldots, N\}$, where $\theta$ is the random variable representing the index of the requested message. 
\end{enumerate}

In the information-theoretic setting, the download cost $D$ dominates the upload cost. The definition of the download cost $D$ requires some elaboration. Two obvious information-theoretic measures directly related to the download cost are $\sum_{i=1}^N H(A^{[k]}_n)$ and $\sum_{i=1}^N H(A^{[k]}_n|\mathsf{F})$. The latter is a lower bound of the expected number of total download bits, which is how we usually measure the download cost. The former is an upper bound of the latter, and can be viewed as a surrogate, particularly in asymptotic (large number of information bits in each message) settings.  

\begin{figure*}[t]
\centering
\vspace{0.2cm}
\includegraphics[width=0.98\textwidth]{figures/Fig-4-Canonical-PIR.pdf}
\caption{(a) The canonical PIR system; (b) extensions of the canonical system. \label{fig:PIR_diag} }
\end{figure*}


The efficiency of the download is then measured by the number of requested message bits obtained per downloaded bit, which leads to the following capacity notion, when error is not allowed. More precisely, a rate $R$ is said to be achievable for zero-error PIR, if there exists a PIR code of download cost $D$ such that $R=\frac{L}{D}$ with no decoding errors. The supremum of achievable rates for zero-error PIR is called the (zero-error) PIR capacity $C_0$. 

For zero-error PIR code, there is no need to explicitly specify the probability distribution for each message, and also no need to specify the message retrieval probability. However, when a more general capacity notion, the $\epsilon$-error capacity, is adopted, this is no longer the case,  since the error probability is not strictly zero. In this case, the convention is to assume that each message is distributed in its range uniformly at random, and the message is also being requested uniformly at random \cite{sun2017PIRcapacity}. Correspondingly, a rate $R$ is said to be $\epsilon$-error achievable if there exists a sequence of PIR codes, each of rate greater than or equal to $R$, for which $\frac{1}{K}\sum_{k=1}^K\mathbf{Pr}(\hat{W}_k\neq W_k)\rightarrow 0$ as $L\rightarrow \infty$. The supremum of $\epsilon$-error achievable rates is called the $\epsilon$-error capacity $C_\epsilon$. 

The download cost used above is the expected number of downloaded bits, and the capacities are defined accordingly, which is usually the notion adopted in subsequent works. However another slightly different notion of the download cost is the worst-case download cost, which was used in \cite{sun2017optimal} (and later adopted in \cite{zhang2018optimal,jingke2017subScienceChina}). The worst-case download cost is the largest number of downloaded bits over all query combinations that are used with non-zero probability. Using this notion, we can similarly define the zero-error worst-case PIR capacity $\bar{C}_0$, and $\epsilon$-error worst-case PIR capacity $\bar{C}_\epsilon$. The breakthrough work \cite{sun2017PIRcapacity} essentially established that
\begin{align}
C_0=\bar{C}_0=C_\epsilon=\bar{C}_\epsilon=\left(1+\frac{1}{N}+\cdots+\frac{1}{N^{K-1}}\right)^{-1}.
\end{align}
The capacity definition $C_0$ is the most straightforward, and often adopted in the literature for generalized PIR settings. When the problem setting deviates from the canonical setting, it is known that $C_\epsilon$ can be different from $C_0$ in certain cases, but it is not well understood when this is the case. It is not known whether $\bar{C}_0$ and $\bar{C}_\epsilon$ can in fact be different for any generalized PIR systems.

\begin{figure}[t]
\centering
\vspace{0.2cm}
\includegraphics[width=0.9\textwidth]{figures/Fig-5-low-sub-pack-schemes.pdf}
\caption{Low-subpacketization schemes for PIR for $(N,K)=(2,2)$. The scheme in (a) was given in \cite{tian2018capacity_ICC,tian2019capacity}, and the scheme in (b) in \cite{Samy_tandon_lazos_leakyPIR_2019, asymmetric_leaky_PIR-2021}. One achieves the minimum possible subpacketization for each message while achieving an expected download cost of $3/2$.}
\label{fig:low-sub-pack-PIR}
\end{figure}

The general code construction for the canonical PIR system turns out to be rather elegant, and plays an important role for subsequent works. The code construction to obtain the capacity result in \cite{sun2017PIRcapacity} relies on several important design principles, which are illustrated using the example of $N=K=2$ case in Fig.~\ref{fig:Sun-Jafar-scheme}. This original construction required sub-packetization of each message into $N^{K}$ parts (alternatively, a message length of $L=N^{K}$ symbols), followed by invoking the design principles of server/message symmetry and exploiting side information. 

An alternative code construction was provided in \cite{tian2018capacity_ICC,tian2019capacity}, which is illustrated in Fig. \ref{fig:low-sub-pack-PIR}(a). In this construction, the server symmetry and and message symmetry are not used on the per retrieval basis, but across all the retrieval patterns. The random key $F\in\{0,1\}$ is invoked with probability $1/2$ each, and thus the expected retrieval download cost is still the same $3/2$. The advantage of this alternative code construction is that it can be shown to have the minimum message length ($L=1$ in this example and $L=N-1$ in general), comparing to the exponential growth of message length for the code given in \cite{sun2017PIRcapacity}. A similar code construction was discovered by \cite{Samy_tandon_lazos_leakyPIR_2019} for special case of $N=2$, and was later extended to the  case of more general number of databases \cite{asymmetric_leaky_PIR-2021} as shown in Fig. \ref{fig:low-sub-pack-PIR}(b). The difference from that in  \cite{tian2018capacity_ICC,tian2019capacity} is additional layer of symmetrization enforced across the databases.  It is clear that both code constructions have the same download cost, however, the upload cost of the former is lower ($\log 2$ vs $\log 4$). The symmetry structure in the canonical PIR setting is quite sophisticated and plays an important role in constructing efficient code design. The overall symmetry is induced by the database symmetry, the message symmetry, and the (retrieval) variety symmetry; see \cite{tian2019capacity} for a detailed discussion.

\subsection{Relation to Computer Science Theoretic PIR}

For the canonical PIR system, the computer science theoretic description of the coding operations is exactly equivalent to the information-theoretic version we just provided. The main difference between them is in terms of the performance measure, i.e., regarding the definition of $C_0$ and $C_{\epsilon}$. Since in the computer science theoretic setting the messages are short, usually only one bit each, the upload cost, i.e., $\sum_{i=1}^N\log |\mathcal{Q}_n|$, plays an important role in the overall communication cost, and thus the total communication cost must consist of both components. In contrast, in the information-theoretic setting, since the message size is allowed to be very large, the download cost dominates and the upload cost can be essentially ignored, and only the normalized cost is meaningful, whose inverse is the PIR rate. 

Since in the computer science theoretic setting, the message length is fixed and not allowed to grow to infinity, it is not meaningful to consider the ratio between the message length and the communication cost. In contrast, in the information-theoretic setting, this ratio between the message length and the download cost is the key metric to consider. 

It is in fact rather difficult to fully characterize the sum of the upload cost and the download cost (for any fixed message length), and thus the optimal scaling laws are usually sought after in the computer science theoretic setting. In contrast, in the information-theoretic setting, the ratio between the message length and the download cost leads to the concept of capacity, and the problem in fact becomes much more tractable. Instead of the scaling law, the capacity of the PIR system can be fully identified. 

\subsection{Extended PIR Systems} 

The canonical PIR system given in the previous sub-section can be viewed as consisting of four key components: a single-round query-answer protocol, a set of independent messages of the same length, an absolute privacy requirement, and also inherently a star-shape communication network; see Fig. \ref{fig:PIR_diag}. The last item regarding the communication network may require some elaboration, since it is usually not explicitly introduced: the user communicates to each server through a dedicated link, and each server answers through a dedicated link, and as a consequence, the communication costs are measured in a straightforward manner on each link. 

Any of these components can be generalized: 
\begin{enumerate}
\item The query-answer protocol structure. The user sends a single round of queries, and the servers answer in a single round; this protocol can be generalized to allow multiple rounds. 
\item The message structure.  In more general systems, the messages can be dependent; in a less obvious variation, the user in fact requests a function of the messages.
\item The privacy (or security) requirement.  The user may wish to enforce the privacy requirements that even certain subsets of the servers collude, they still will not be able to infer any knowledge on the request. The server may place security constraint that the authors cannot learn about other messages than the one being requested. 
\item The communication network structure.  This communication models can be generalized in various way, for example, to allow a more complex communication network, or using additional communication module, such as caches, to facilitate the communication. In such general settings, the communication costs are measured in rather different manners.
\end{enumerate}

In the next subsections, we  survey various generalizations  of the canonical PIR problem. 

\subsubsection{Multi-round and Multi-message PIR Systems}
Sun and Jafar  \cite{Sun_Jafar_MPIR} considered the extended PIR system where the user and the servers are allowed multiple rounds of queries and answers. It was shown that the capacity of multiround PIR is in fact the same as single round PIR, when there is no constraint placed on the storage cost. This equality continues to hold even when $T$-colluding is allowed. However, when the storage is more constrained, this equality would indeed break. Yao et al. \cite{yao2019capacity} considered using multiround communication in the settings with Byzantine databases, and showed that multiround communication is also beneficial in this setting. In multi-message PIR, the user wishes to download multiple messages privately. The question that arises is whether downloading multiple messages one-by-one sequentially is optimum. \cite{MMPIR} shows that downloading multiple messages jointly is more efficient and beats the sequential use of single-message PIR. \cite{MMPIR} determines the PIR capacity when the number of desired messages is at least half of the total number of messages, while the multi-message PIR capacity in other cases remains open. 

\subsubsection{Cache or Side Information Aided PIR}
Cache aided private information retrieval (PIR) (e.g., \cite{tandon2017capacity, PrefetchingPIR, Cache-aided_PIR}) and side information aided PIR (e.g., \cite{heidarzadeh2018capacity, KadheRouayheb2, ZhenWangJafar, PartialPSI_PIR, StorageConstrainedPIR_Wei, shariatpanahi2018multi, HeidarzadehRouayheb, li2018single, li2020singlemult, HeidarzadehSprintson}) are both interesting extensions of the original information-theoretic PIR problem \cite{sun2017PIRcapacity} because they both lead to reduction in download costs due to the fact that, under both settings, the user possesses cache or side information, respectively. The PIR capacity and the corresponding PIR schemes with cache/side-information vary, depending on a) if the databases are aware or unaware of the side-information at the user; b) if the user wishes to only keep the message index private or both the message index and side-information private from the databases; and c) the type of side-information available at the user (e.g., subset of messages or fraction of some/all messages). Recently, the role of side information is investigated in the context of symmetric PIR (SPIR) where the side information is a subset of shared database common randomness; this work showed that with appropriate amount of user-side side information the capacity of SPIR can be increased to the capacity PIR, and single-database SPIR can be made possible \cite{SPIR_UserRandomness}.

\subsubsection{PIR from Databases with Limited Storage}
The assumption of fully replicated databases (all $N$ databases storing all $K$ messages) can be unrealistic in practice. However, the amount of redundancy across the databases has an impact on the capacity of PIR. Specifically, on one extreme for replicated databases, the capacity is the highest, whereas on the other extreme, if there is no redundant storage across databases, then the only feasible strategy is to download all $K$ messages. There have been several recent works which have explored the trade-off between the capacity and storage for PIR. The case when each message is encoded by a maximum distance separable (MDS) code and stored across the databases, referred to as the MDS-PIR code, was studied in \cite{PIR_coded, Tajeddine_Rouayheb} and the capacity was settled by Banawan and Ulukus \cite{PIR_coded}; also see recent results on MDS-PIR with minimum message size \cite{zhou2020capacity}. The problem of MDS-PIR with colluding databases turns out to be more challenging  and the capacity remains unknown for general parameters; see \cite{FREIJ_HOLLANTI, Sun_Jafar_MDSTPIR}. Several other variants have been studied including PIR from databases storing data using an arbitrary linear code \cite{kumar2019achieving, Lin_Kumar_Rosnes_Amat}, impact on capacity versus storage when using arbitrary (possibly, non-linear codes) \cite{guo_ruida_tian_storage_PIR_2021, efficient_storage_ITW2019, tian_2019_storage_cost_journal,tian2018shannon,sun2019breaking}, when databases only store fraction of uncoded messages \cite{attia2018capacity, HeteroPIR, PIR_decentralized}, and when data is not perfectly replicated across the databases, but rather partially replicated according to graph based structures \cite{raviv2019GPIR, Karim_nonreplicated, Jia_Jafar_GXSTPIR,Sadeh_Gu_Tamo}.

\subsubsection{PIR Under Additional Abilities and Constraints for the Databases}
The original setting in \cite{sun2017PIRcapacity} considers privacy against individual databases. In practice, a subset of databases may have the ability to collude; this may happen, for instance, if the databases belong to the same entity. \cite{Sun_Jafar_TPIR} considers the case where up to $T$ out of $N$ databases may collude, and finds the PIR capacity as a function of $T$. Further, \cite{BPIRjournal} considers the case where in addition to the $T$ colluding databases, up to $B$ databases may exhibit Byzantine behavior, meaning that they can return arbitrarily random or incorrect answers to the queries, and finds the PIR capacity as a function of $T$ and $B$. In addition, databases may require \emph{database privacy}. This means that the user does not learn anything further than the message it wished to download. The resulting setting is coined as symmetric PIR (SPIR) to emphasize the symmetry of privacy requirements of the user and the databases. The capacity of SPIR is found in  \cite{Sun_Jafar_SPIR}. The SPIR capacity is smaller than the PIR capacity, as SPIR is a more constrained problem than PIR. SPIR achievable scheme is similar to the schemes in \cite{PIRfirst, Shah_Rashmi_Kannan} but it requires a shared common randomness among the databases. Recent paper \cite{SPIR_UserRandomness} explores making some of that common randomness available (randomly) to the user to increase SPIR capacity. Further, SPIR proves to be an important privacy primitive that is a building block in many problems that involve symmetric privacy requirements among participating parties, such as in private set intersection \cite{PSI_journal, MP-PSI_journal}. 

Databases may be subject to a set of practical limitations due to the way that the databases are accessed or the way they need to return their answers. For instance, if the databases need to return their answers via noisy and/or multiple-access wireless channels, then the PIR schemes should be designed together with channel coding techniques to deal with the uncertainty in the channels as in \cite{NoisyPIR}. In another example setting, if the rate at which the user can download information from the databases is different for each database, then the user access to the databases and the PIR schemes across the databases may need to be asymmetric. This may happen, for instance, if the databases have different distances to the user (with a more distant database having a smaller bit-rate) or if they have different channel qualities (some channels from the databases being in deep fades). In this case, asymmetric access conditions need to be taken into consideration \cite{AsymmetryHurtsPIR}. An interesting observation in \cite{AsymmetryHurtsPIR} is that if the asymmetry is mild, the full unconstrained PIR capacity may still be maintained. Another set of practical constraints arise if the database-to-user channels are being eavesdropped by an external entity. This gives rise to a problem formulation at the intersection of information-theoretic privacy and information-theoretic security \cite{SecurePIR, securePIRcapacity, PIR_WTC_II, securestoragePIR}. Yet another practical constraint is that the messages stored at the databases do not have to be of equal length, and their apriori probabilities of retrieval (popularities) do not have to be the same. These give rise to message semantics that need to be taken into account during a PIR code design \cite{SemanticPIR}. An interesting observation in \cite{SemanticPIR} is that if longer messages have higher popularities then the semantic PIR capacity may be larger than classical PIR capacity.

\subsubsection{Relaxed Privacy Notions}
Perfect information-theoretic privacy requirements (either for the user as in PIR or for both the user and the databases as in SPIR) usually come at the expense of high download cost and do not allow tuning the PIR efficiency and privacy according to the application requirements. In applications which may require frequently retrieving messages, trading user or database privacy for communication efficiency could be desirable. Ideally, one would select a desired leakage level and then design a leakage-constrained retrieval scheme that guarantees such privacy while maximizing the download efficiency. Asonov et al. introduced the concept of repudiative information retrieval  \cite{asonov2002repudiative}. The repudiation property is achieved if the probability that the desired message index was $i$ given the query is non-zero for every index $i$, i.e., there is always some remaining uncertainty at the database about the desired message index. Recently, Toledo et al. \cite{toledo2016lower} adopted a game-based differential privacy definition to increase the PIR capacity at the expense of bounded privacy loss. With the goal of allowing bounded leakage for the information-theoretic PIR/SPIR formulations (as initiated in \cite{PIRfirstjournal}), there have been a series of recent works. In \cite{Samy_tandon_lazos_leakyPIR_2019}, the perfect privacy constraint was relaxed by requiring that the log likelihood of the posterior distribution for any two message indices given the query is bounded by $\epsilon$. When $\epsilon=0$, this recovers perfect privacy, and allows leakage for $\epsilon>0$. Lin et al. \cite{lin2019weakly,lin2020capacity} relaxed user privacy by allowing bounded 
mutual information between the queries and the corresponding requested message index. Unlike \cite{lin2019weakly,lin2020capacity}, which deal with the average leakage measured by mutual information, the model studied in \cite{Samy_tandon_lazos_leakyPIR_2019} provides stronger privacy guarantees. Zhou et al. \cite{zhou2020weakly} measured the leakage using the maximal leakage metric and argued this leakage measure is more applicable. Guo et al. \cite{guo2019information} considered the problem of SPIR with perfect user privacy and relaxed database privacy. Database privacy was relaxed by allowing a bounded mutual information (no more than $\delta$) between the undesired messages, the queries, and the answers received by the user. Similar to the original work on SPIR in \cite{sun2018capacitysymmetric}, SPIR with relaxed database privacy in \cite{guo2019information} requires sharing common randomness among databases and comes at the expense of a loss in the PIR capacity. Asymmetric leaky PIR was explored in \cite{asymmetric_leaky_PIR-2021} where bounded leakage is allowed in both directions. Recently, the model of latent-variable PIR was introduced and studied, where instead of requiring privacy for the message index, one may require privacy of data correlated with the message \cite{latent-variable-PIR}. 

\begin{figure}[t!]
\begingroup
\fontsize{10}{12}\selectfont
\begin{tabular}{>{\small}p{0.9in}>{\small}p{2.3in}>{\small}p{2.5in}>{\small}p{0.1in}}\hline

\multicolumn{3}{c}{Full capacity characterization}\\\hline

\multirow{3}{1.4in}{PIR\cite{sun2017PIRcapacity}\\
Multiround\cite{Sun_Jafar_MPIR}\\
Computation\cite{Sun_Jafar_PC, Mirmohseni_Maddah}\\
}&\multirow{3}{2.5in}{\hspace{1cm}$C=\Psi(N,K)$}&\multirow{3}{3in}{
Multiround: allows sequential queries\\
Computation:  retrieves arbitrary linear\\ combinations of messages}&\multirow{3}{*}{\checkmark}\\\\\hline
TPIR\cite{Sun_Jafar_TPIR}&$C=\Psi((N-U)/T,K)$&$U$  { u}nresponsive servers&\checkmark\\  \hline
\multirow{3}{1in}{PIR\cite{Yao_Liu_Kang_P} with \\  arbitrary collusion pattern}&\multirow{3}{1in}{$C=\Psi(S^*, K)$ }&\multirow{3}{3in}{Arbitrary collusion pattern $P$,\\$S^*=\max_y 1_N^T y$, s.t. $B_P^Ty\leq 1_M, y\geq 0_N$\\ $B_P$: incidence matrix of  $P$}&\multirow{2}{*}{\checkmark}\\ \\ \hline 
\multirow{2}{0.9in}{Cache-aided PIR\cite{Tandon_CachePIR}}&\multirow{2}{*}{$C=\Psi(N, K)/(1-S/K)$}& \multirow{2}{3in}{PIR aided by local {\bf c}ache at user of size $S\times$ message size} &\multirow{2}{*}{\checkmark}\\\hline
\multirow{2}{0.9in}{PIR-SI\cite{Kadhe_Garcia_Heidarzadeh_Rouayheb_Sprintson, Li_Gastpar}}&\multirow{2}{*}{$C=\Psi(N, \lceil\frac{K}{M+1}\rceil)$}& \multirow{2}{3in}{{\bf S}ide {\bf I}nformation of $M$ messages at User,\\ Privacy of SI not required}&\multirow{2}{*}{\checkmark} \\\hline
\multirow{2}{0.9in}{PIR-PSI\cite{Kadhe_Garcia_Heidarzadeh_Rouayheb_Sprintson, Chen_Wang_Jafar, PartialPSI_PIR}}&\multirow{2}{*}{$C=\Psi(N/T, K-M)$}& \multirow{2}{3in}{{\bf S}ide {\bf I}nformation of $M$ messages at User,\\ $\theta$ and SI jointly $T$-private}&\multirow{2}{*}{\checkmark} \\\hline

\multirow{3}{0.9in}{SPIR\cite{Sun_Jafar_SPIR, Wang_Skoglund_SPIRAd}}&\multirow{3}{3in}{$C=(1-\frac{2B+\max(T,E)}{N})$\\$\qquad\qquad\cdot\mathbb{I}_{\left(\rho\geq \frac{2B+\max(T,E)}{N-2B-\max(T,E)}\right)}$}& \multirow{3}{3in}{ {\bf S}ymmetric security, \\$B$-{\bf B}yzantine servers, $E$-{\bf E}avesdroppers,\\
 Common randomness $\rho$ shared among servers}\Tstrut &\multirow{2}{*}{\checkmark}\\  \\\hline
 
\multirow{3}{0.9in}{Q-PIR, Q-STPIR\cite{Song_Hayashi_QTPIR}}&\multirow{3}{2.5in}{${C}=\min\left\{1, \frac{2(N-T)}{N}\right\}$ }&\multirow{3}{3in}{Quantum PIR, \\
allows symmetric security,\\ Servers  share an entangled state}\Tstrut&\multirow{3}{*}{\checkmark}\\[0.3cm]\\
\hline

\multirow{2}{1in}{B-TPIR\cite{BPIRjournal}}&\multirow{2}{2.5in}{$C=\left(1-\frac{2B}{N}\right)\Psi(\frac{T}{N-2B},K)$, $\footnotesize{N>2B+T}$\\ $C=\frac{1}{(2B+1)K}\mathbb{I}_{(N>2B)}$, $N\leq 2B+T$}&\multirow{2}{3in}{\hspace{0.5cm}$B$-{\bf B}yzantine servers}\Tstrut&\multirow{2}{*}{\checkmark}\\[0.1cm]
\hline
\multirow{1}{0.9in}{MDS-PIR\cite{PIR_coded}}&$C=\Psi(N/K_c, K)$& $(N,K_c)$ MDS Coded Storage\\\hline
\multirow{2}{1.5in}{PIR with limited \\ storage \cite{attia2018capacity, HeteroPIR, PIR_decentralized}}&\multirow{2}{*}{\hspace{1cm}$C=\Psi(\mu N, K)$, $\mu=\frac{t}{N}, t\in[N]$}& \multirow{2}{3in}{Each server stores no more than $\mu$ fraction of \\
database; heterogeneous sizes $\mu_i$; decentralized.} \\\hline
  \hline
\end{tabular}  

\begin{tabular}{>{\small}p{0.9in}>{\small}p{2.3in}>{\small}p{2.5in}>{\small}p{0.1in}}\hline
\multicolumn{3}{c}{Partial capacity characterization}\\\hline

\multirow{2}{0.9in}{Multimessage PIR\cite{MMPIR}}&\multirow{2}{2in}{${C}=\Psi(N,\frac{K}{M})$ if $K/M\in\mathbb{N}$\\ $C=\frac{MN}{MN+K-M}$ if $M\geq\frac{K}{2}$}&\multirow{2}{3in}{{\bf M}ulti-{\bf m}essage Retrieval\\ Retrieves $M$ out of $K$ messages}&\multirow{2}{*}{\checkmark}  \\[0.1cm]\hline

\multirow{2}{0.9in}{MDS-TPIR\cite{Sun_Jafar_MDSTPIR, FREIJ_HOLLANTI}}&\multirow{2}{2in}{${C}_l=1-(K_c+T-1)/N$\\ $C=\frac{N^2-N}{2N^2-3N+T}$ if $K_c=N-1$}& \multirow{2}{*}{$(N,K_c)$ MDS Coded Storage}\\ 
\\[0.2cm]\hline

\multirow{3}{0.9in}{XS-TPIR\cite{Jia_Sun_Jafar_XSTPIR}}&\multirow{3}{2.5in}{${C}_l=\left(1-\frac{X+T}{N}\right)^+=C_\infty$\\ ${C}^u=\left(1-\frac{X}{N}\right)\Psi(\frac{N-X}{T},K)$\\  $=C$ if {\footnotesize $N\leq X+T$} or {\footnotesize $(N,X,T)=(3,1,1)$}}&\multirow{3}{3in}{$X$-secure storage }\Tstrut\\[0.2cm]
 \\\hline

\multirow{2}{0.9in}{U-B-XS-MDS-TPIR\cite{Tajeddine_Gnilke_Karpuk_Hollanti, Jia_Jafar_MDSXSTPIR}}&\multirow{2}{2.5in}{${C}_l=\left(1-\frac{K_c+X+T+2B-1}{N-U}\right)$\\ $=C_\infty$ if $K_c=1,X=0$}&\multirow{3}{3in}{$X$-secure,\\ $(N, K_c+X)$ MDS coded storage, \\ $U$-{\bf u}nresponsive, $B$-{\bf B}yzantine servers\\ }\Tstrut\\[0.3cm]
\\\hline
\end{tabular}

\endgroup
\caption{A sampling of  capacity results for various forms of PIR, where $N$ is the number of servers, $K$ is the number of messages, and $T$ is the privacy parameter with default value being $1$. For the rows with a check mark, the storage on server is simple message replication. 
$C$ represents capacity, $C_\infty$ is the asymptotic capacity for large number of messages $(K\rightarrow\infty)$, ${C}^u$ and ${C}_l$ are upper and lower bounds on $C$, respectively. $\Psi(A,B)\triangleq (1+1/A+1/A^2+\cdots+1/A^{(B-1)})^{-1}$.}\label{table:capacity}
\end{figure}
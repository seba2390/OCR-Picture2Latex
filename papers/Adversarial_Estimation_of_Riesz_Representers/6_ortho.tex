\section{Orthogonalizing Non-Linear Moment}

Suppose our goal is to estimate the solution $\theta_0$ to a non-linear moment problem that depends on a regression function $g_0$, i.e.:
\begin{equation}
    \E[m(Z; \theta_0, g_0)] := 0
\end{equation}
One way to construct a Neyman orthogonal moment that is robust to first-stage errors of the regression is to introduce a bias correction term that involves the Riesz representer of the functional derivative of the moment with respect to $g$, i.e.:
\begin{equation}
    m_{a}(Z; \theta, g) = m(Z; \theta, g) + a(X)'\, (Y - g(X))
\end{equation}
where $a_0(X)$ is the Riesz representer of the functional derivative of $m$ with respect to $g$, i.e.:
\begin{equation}
    f(g) := \frac{\partial}{\partial \tau} \E\left[m(Z; \theta, g_0 + \tau\, (g - g_{0}))\right] \bigg|_{\tau=0} = \E[a(X)' g(X)]
\end{equation}

The Riesz representer $a_0$ can be estimated in a first stage as follows:
\begin{itemize}
    \item Estimate the regression function $\hat{g}$
    \item Estimate a preliminary $\tilde{\theta}$ using the non-orthogonal moment condition
    \item Calculate algebraically, or through automatic differentiation, the Gateaux derivative function:
    \begin{equation}
        \hat{f}(g) = \frac{\partial}{\partial \tau}\E\left[m(Z; \tilde{\theta}, \hat{g} + \tau\, (g - \hat{g}))\right]\bigg|_{\tau=0}
    \end{equation}
    \item Apply the adversarial Riesz representer estimator for functional $\hat{f}(g)$, to estimate $a$
\end{itemize}

Following similar analysis as in Section~5 of \cite{chernozhukov2018learning}, one can show that the moment $m_{a}$ satisfies Neyman orthogonality. Moreover, assuming that the moment function is sufficiently smooth, the estimator outlined above will achieve faster than $n^{-1/4}$ rates. These two properties are sufficient to show that the estimator for $\theta$, based on the orthogonal moment and using cross-fitting, will be root-$n$ asymptotically normal.

One caveat of the approach outlined above is the burden of either calculating the Gateaux derivative algebraically or auto-differentiating the moment. One can bypass this difficult, and reduce to evaluation oracles of the moment, by taking arbitrarily small approximations of the Gateaux derivative. In particular, the third step could be replaced by defining:
\begin{equation}
    \hat{f}_{\epsilon}(g) = \frac{1}{\epsilon}\left(\E\left[m(Z;\tilde{\theta}, \hat{g} + \epsilon (g - g_0)) - m(Z;\tilde{\theta}, \hat{g})\right]\right)
\end{equation}
For sufficiently small $\epsilon$, the approximation error $\|\hat{f}_{\epsilon} - \hat{f}\|$ is negligible. Moreover, $\hat{f}_{\epsilon}$ only requires black-box access to evaluations of the moment function to be computed.
\section{Experiments}\label{sec:experiments}
We evaluate CFIL on the standard Mujoco benchmarks \cite{todorov2012mujoco}, first comparing it to state-of-the-art imitation methods, including ValueDICE \cite{kostrikov2019imitation} and their optimized implementation of DAC \cite{kostrikov2018discriminator}, along with a customary behavioral cloning (BC) baseline. We then move to evaluation on a variety of other settings described below. We use ValueDICE's original expert demonstrations, with exception to the Humanoid environment, for which we train our own expert, since they did not originally evaluate on it. We use ValueDICE's open-source implementation to comfortably run all three baselines. NDI \cite{kim2021imitation} would be the ideal candidate for comparison, given the similarities, however no code was available. Still, we reference some relevant results described in their paper.


For CFIL, our RL algorithm of choice is SpinningUps's \cite{SpinningUp2018} SAC \cite{haarnoja2018soft}. We leave all hyper-parameters unchanged, only reducing the start-steps down to 2000, matching that of the baselines above.
Our choice for both flows is a single layered MAF \cite{papamakarios2017masked}, amending no hyper-parameters from the following open-source implementation \cite{MAFcode}. This lack of tuning highlights the robustness of our method. 
Our density update rate is 10 batches of 100, every 1000 timesteps. We use the Adam optimizer \cite{kingma2014adam} with a learning rate of 0.001. For squashing we use $\sigma = 6 tanh(\frac{x}{15})$, while the smoothing and regularization coefficients are 0.5 and 1 respectively.


For all algorithms, we run 80 epochs, each consisting of 4000 timesteps, evaluating over 10 episodes after each.
We do this across 5 random seeds and plot means and standard deviations. The plots are smoothed by a rolling mean with window length 5. All results are using a single expert trajectory. Appendix \ref{appendix:CFIL_varying_traj} shows CFIL's performance with more expert trajectories.


%figure * helps be on one column
\begin{figure*}[t!]
\vskip 0.1in
\centering
\includegraphics[width=0.9\textwidth]{figures/final_plot1_tanh_15_6_reg1_smooth05_window5_cropped.PNG} % Reduce the figure size so that it is slightly narrower than the column. Don't use precise values for figure width.This setup will avoid overfull boxes.
\caption{Top: A comparison of CFIL to ValueDICE and DAC on a single expert trajectory in the standard state-action setting. Bottom: A comparison of two versions of CFIL to OPOLO on a single expert trajectory in the LFO setting, with one version limiting itself only to single states. CFIL uses identical hyperparameters on all environments in all three incarnations, showing outstanding results, particularly in the LFO setting where it far outperforms the highly tailored competitor OPOLO.}
\label{fig:CFILcompare}
\vskip -0.1in
\end{figure*}
The top of Figure \ref{fig:CFILcompare} shows a comparison to the baselines in the standard state-action setting. Clearly, CFIL achieves expert level performance on all tasks with merely a single expert trajectory—something the baselines fail to do. CFIL either outperforms or performs similarly to the competition in terms of asymptotic performance (though slight outperformace is not meaningful once all are at expert level), with a massive advantage in the Ant and Humanoid environments.


In terms of environment interactions required until reaching expert level: Our approach slightly lags behind the optimized DAC and largely lags behind ValueDICE. That is of course, only for the tasks they succeed on. ValueDICE—where it succeeds—clearly wins in terms of interactions needed to reach expert level, though its performance then occasionally degrades as seen in Figure \ref{fig:CFILcompare}. Being semi-offline (i.e. it can be instantiated fully offline), ValueDICE is difficult to compete with in terms of environment interactions. 
However, minimizing interactions was not the objective of this work, yet still we are on par. 

Despite not being our aim, we do note that CFIL far outperforms NDI which requires an order of magnitude more interactions (see their appendix), who in turn outperform GAIL \cite{ho2016generative} by another order of magnitude. Clearly, CFIL is still very impressive in terms of environment interactions and the lag between us and DAC may simply be due to a lack of tuning of CFIL's RL component. We deliberately avoid this tuning, preferring to keep the RL algorithm a black box, since too much tuning may jeopardize robustness and extendability to other settings: We aspire for robust competitiveness rather than a tailored, minor and frail improvement.



We now turn to the state-only and subsampled regimes. Settings in which ValueDICE finds no dice: By its very nature, ValueDICE is inapplicable to the state-only scenario (see Appendix 9.8 of \cite{zhu2020off}) and extensive experiments already showed its failure when demonstrations are subsampled \cite{li2022rethinking}. SparseDICE \cite{camacho2021sparsedice} attempted to remedy this by adding a series of regularizers. However, they require at least 10 demonstrations, each subsampled at a rate of 0.1, not nearly the sparsity of the settings we next describe.

First in the state-only regime, we compare against OPOLO \cite{zhu2020off}, a state-of-the-art LFO method. We avoid comparison with on-policy LFO methods, like GAIfO \cite{torabi2018generative}, due to the sheer number of interactions they require. We use OPOLO's open-source implementation, with the same setup described previously, once again using only a single expert trajectory. Importantly, CFIL uses identical hyperparameters to the previous setting.


The bottom of Figure \ref{fig:CFILcompare} shows two versions of CFIL compared with OPOLO. One estimating the state-next-state distribution ratio, while the other limiting itself to the single state distribution. As can be seen, both incarnations of CFIL once again achieve expert level performance on all environments. This is in sharp contrast to OPOLO which, despite being highly tailored towards the LFO setting, employing inverse action models, discriminators and a host of practical considerations, struggles immensely when provided with a single expert trajectory (they originally report success with 4 trajectories). All the while, CFIL requires no amendment whatsoever, extending simply and elegantly, while distinctly outdoing OPOLO on every imitation learning metric. CFIL's results in the LFO setting are nothing short of remarkable. We effectively set a new state-of-the-art for learning from observations alone, while our method was not originally designed for it.

We finally turn to the subsampled regime. Comparing again to DAC with a similar setup as before. Our comparison here involves four different subsampling rates, sampling every 10, 20, 50 and 100'th transition. Since we are still working with a single expert trajectory, the final rate implies learning from 10 state-action pairs alone. For this setting, we found the hyperparameters used above did not extend well enough. Specifically, the use of flow regularization seemed to hurt performance in some environments. We therefore drop the regularization to 0, leaving the smoothing at 0.5 and amending the squasher to be $\sigma = 3 tanh(\frac{x}{10})$. We use these parameters for all environments in all four new settings, with exception to cheetah who, when subsampled, actually struggles without the flow regularization.

Figure \ref{fig:subsample} shows the comparison in the subsampled setting, with CFIL once again demonstrating stellar performance. While DAC has the advantage in the Cheetah environment, where single crashing seeds significantly reduced the apparent performance of CFIL, CFIL still generally outperforms it, remarkably able to recover the expert behavior when only provided with a measly 10 state-action pairs.


\begin{figure}[t]
\vskip 0.1in
\centering
\includegraphics[width=0.9\columnwidth]{figures/final2_subsample2_window5_cropped.png} % Reduce the figure size so that it is slightly narrower than the column. Don't use precise values for figure width.This setup will avoid overfull boxes.
\caption{A comparison of CFIL and DAC on four subsampling rates with a single expert trajectory. Subsample$N$ refers to sampling every $N$'th transition in the trajectory.}
\label{fig:subsample}
\vskip -0.1in
\end{figure} 


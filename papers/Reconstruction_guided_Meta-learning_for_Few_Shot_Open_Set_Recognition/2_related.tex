\section{Related works}

\noindent \textbf{Few-shot learning.} Few-shot learning \cite{rohrbach2013transfer,raychaudhuri2020exploiting,guan2020zero} aims to learn representations that generalize well to novel classes with few examples. Meta-learning \cite{hospedales2020meta_survey} is the one of the most common approaches for addressing this problem and it is generally grouped into one of the following categories: \textit{gradient-based methods} \cite{maml,reptile} and \textit{metric learning methods} \cite{match_net,proto_net}. Typical gradient based methods, such as MAML \cite{maml} and Reptile \cite{reptile}, aim to learn a good representation that enables fast adaptation to a new task. On the other hand, metric-based techniques like Matching Networks \cite{match_net}, and Prototypical Networks \cite{proto_net} learn a task-specific kernel function to perform classification via a weighted nearest neighbor scheme. Our framework belongs to the latter class of methods, with the ability to work in the open-set scenario.\vspace{\baselineskip}

\noindent \textbf{Out-of-distribution detection.}
Also known as novelty or anomaly detection, the out-of-distribution task is commonly formulated as the detection of test samples that fall outside of the data distribution used in training. Hendrycks et. al. \cite{hendrycks17baseline} showed that softmax alone is not a good indicator of out-of-distribution probability but statistics drawn from softmax can be utilized to make assumptions of the "normalcy" of a test sample. Liang et. al. \cite{liang2020enhancing} re-calibrated output probabilities by applying temperature scaling and used virtual adversarial perturbations to the input to enhance the out-of-distribution capability of the model. Note that most out-of-distribution detection focuses on either detecting perturbed samples or out-of-dataset samples. In addition, these methodologies are not extendable to few shot settings. \vspace{\baselineskip}

\noindent \textbf{Open-set classification.} Open-set classification is slightly different from out-of-distribution detection in that it focuses on not only rejecting samples from unseen classes but also achieving proper classification of the seen categories. This is a much harder problem as opposed to just detecting perturbed/corrupted samples \cite{peeler}. Bendale et al. \cite{open_max} introduced OpenMax which uses extreme value statistics to re-calibrate the softmax scores of samples from unseen classes and reject out-of-distribution samples by thresholding their corresponding confidence score. G-OpenMax \cite{Gopenmax} combines OpenMax with a generative model to synthesize the distribution of all unseen classes. Recently, counterfactual image generation \cite{Neal_2018_ECCV} has been proposed to generate hard samples in an effort to build a more robust model. Kong et al. \cite{kong2021opengan} extends this idea by designing a generative adversarial network for the generation of out-of-distribution samples. Wang et al. \cite{wang2021energy} followed a similar strategy to OpenMax \cite{open_max} and introduced an energy-based classification loss for re-calibration of the softmax classification scores. Note that all these methods are in a fully supervised learning setting and are not directly applicable to few-shot learning. Liu et. al. \cite{peeler} first address open-set recognition under the few-shot setting. The proposed framework, titled PEELER, builds on top of prototypical networks \cite{proto_net} and uses episodic learning guided entropy maximization for regularizing the softmax classification scores. Unseen categories are detected by thresholding the maximum value of the softmax score of each out-of-distribution sample.
A more recent work SNATCHER \cite{snatcher} builds on top of PEELER \cite{peeler} and utilizes transformers \cite{vaswani2017attention} along with carefully crafted normalization schemes to improve feature level consistency of in-distribution samples. This enables SNATCHER to detect samples from open-set categories by simple distance thresholding in the embedding space. These methods are, however heavily dependent on the choice of the threshold. To eliminate this dependency, we propose to address few-shot open-set recognition by utilizing exemplar reconstruction as an auxiliary task in the meta-learning setup, such that model is imbibed with self-awareness regarding the openness of an input sample. Exemplars have been used in many computer vision tasks ranging from image recognition \cite{kim2019variational} to panoptic segmentation \cite{hwang2021exemplar}. Our work is the first to study there effectiveness on the FSOSR problem.

% Unlike the prior works used in large scale setting  \cite{novelty2014,open_max,Neal_2018_ECCV}, PEELER does not try to learn the class cluster of all open classes by clubbing them as a single unseen class, but instead learns the cluster of the seen classes and detects unseen class samples if they do not fall in any of those clusters. 


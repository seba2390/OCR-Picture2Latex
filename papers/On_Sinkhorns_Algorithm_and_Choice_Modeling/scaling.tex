\section{Preliminaries on Choice Modeling and Matrix Balancing}
\label{sec:formulations}
We start by providing brief but self-contained introductions to the two main subjects of this paper,
choice modeling and matrix balancing, including their respective underlying mathematical problems and assumptions. Then we formally establish their equivalence in \cref{sec:equivalence}.
\subsection{Maximum Likelihood Estimation of Luce Choice Models}
\label{subsec:Luce}
In the Luce choice modeling framework, we have $n$ observations $\{(j_i,S_i)\}_{i=1}^n$, each consisting of a choice set $S_{i}\subseteq \{1,\dots,m\}=[m]$ that is a subset
of the total $m$ alternatives/items/objects, and the alternative selected, denoted by $j_i \in S_i$.
 The choice probability is prescribed by Luce's axiom of choice given model parameter $s\in\mathbb{R}^m_{++}$
 in the interior of the probability simplex $\Delta_m$:
\begin{align*}
\Pr(j_i, S_i) & =\frac{s_{j_i}}{\sum_{k\in S_{i}}s_{k}},
\end{align*}
and the likelihood of the observed data is thus given by 
\begin{align}
\label{eq:model}
L(s;\{(j_i,S_i)\}_{i=1}^n):=& \prod_{i=1}^{n}\frac{s_{j_i}}{\sum_{k\in S_{i}}s_{k}}.
\end{align} 
 Importantly, the fact that \eqref{eq:model} has potentially different choice sets $S_i$ across observations have   structure-dependent implications for both the optimization and the statistical efficiencies of the model.

The log-likelihood of the choice model described by \eqref{eq:model} is 
\begin{align}
\label{eq:log-likelihood}
\ell(s):=\log L(s) & =\sum_{i=1}^{n}\log s_{j_i}-\log\sum_{k\in S_{i}}s_{k}.
\end{align}
To estimate $s = \{s_{1},\dots,s_m\}$, we focus on the maximum likelihood estimation approach, which maximizes \eqref{eq:log-likelihood} over the interior of the probability simplex. If we reparameterize $\exp(u_{j})=s_{j}$, it is obvious that \eqref{eq:log-likelihood} is concave in $u$. However, to ensure the log-likelihood  \eqref{eq:log-likelihood} has a unique maximizer in the \emph{interior} of the simplex, additional assumptions on the comparison structure of the dataset $\{(j_i,S_i)\}_{i=1}^n$ are needed. 
The following classic condition is necessary and sufficient for the maximum likelihood problem to be well-posed.
\begin{assumption}[\textbf{Strong Connectivity}]
\label{ass:strong-connected}
In any partition of $[m]$ into two nonempty subsets $S$ and its complement $S^C$,
some $j \in S$ is \emph{selected} at least once over some
$k \in S^C$. Equivalently, the {\it directed comparison graph}, with items as vertices and an edge $j\rightarrow k$ iff $k$ is selected in some $S_i$ for which $j,k\in S_i$, is strongly connected. 
\end{assumption}
\cref{ass:strong-connected} is standard in the literature \citep{hunter2004mm,noothigattu2020axioms} and appeared as early as the work of \citet{zermelo1929berechnung} and \citet{ford1957solution} for pairwise comparisons. \citet{hunter2004mm} shows that \cref{ass:strong-connected} is necessary and sufficient for the upper-compactness
of \eqref{eq:log-likelihood}, which guarantees the existence of a maximizer in the interior of the probability simplex. In fact, when an interior maximizer exists, it is also \emph{unique}, since \cref{ass:strong-connected} implies the following weaker condition, which guarantees the strict concavity of \eqref{eq:log-likelihood}.
\begin{assumption}[\textbf{Connectivity}]
\label{ass:weak-connected}
In any partition of $[m]$ into two nonempty subsets $S$ and $S^C$,
some $j\in S$ and and some $k\in S^C$ \emph{appear} in the same choice set $S_i$ for some $i$. 
\end{assumption}
The intuitions provided by \citet{ford1957solution} and \citet{hunter2004mm} are helpful for understanding Assumptions \ref{ass:strong-connected} and \ref{ass:weak-connected}. If items from some $S\subsetneq [m]$ are never compared with those in $S^C$, i.e., never appeared together in any choice set $S_i$, it is impossible to rank across the two subsets. In this case, we can rescale the relative weights of $S$ and $S^C$ of an interior maximizer and obtain another maximizer. On the other hand, if items in $S$ are always preferred to those in $S^C$, we can increase the likelihood by scaling $s_j$ for items $j\in S^C$ towards $0$, and no maximizer in the \emph{interior} of the probability simplex exists. 
Nevertheless, a boundary solution can still exist. This case turns out to be important in the present work: in the equivalent matrix balancing problem, it corresponds to the  \emph{slowdown} regime of Sinkhorn's algorithm, where scalings diverge but the scaled matrix converges (\cref{sec:linear-convergence}). 

\cref{ass:weak-connected} also has a concise graph-theoretic interpretation. Define the weighted \emph{undirected comparison graph} $G_c$ on $m$ vertices with adjacency matrix $A^c$ given by 
\begin{align*}
{A}^c_{jk} & =\begin{cases}
0 & j=k\\
|\{i\mid j,k\in S_i\}| & j\neq k,
\end{cases}
\end{align*}
In other words, there is an undirected edge between $j$ and $k$ if and only they are both in some choice set, with the edge weight equal to the number of their co-occurrences. We can verify that \cref{ass:weak-connected} requires $G_c$ to be connected.

Under these standard assumptions, previous works have studied the statistical efficiency of the MLE \citep{hajek2014minimax,shah2015estimation,seshadri2020learning} as well as the computational efficiency of the MM algorithm \citep{vojnovic2020convergence}. In both cases, the algebraic connectivity of $G_c$, quantified by the second smallest eigenvalue of the graph Laplacian of $G_c$, plays an important role. See \cref{subsec:graph-laplacian} for details.
In \cref{sec:linear-convergence}, we focus on the classic Sinkhorn's algorithm for matrix balancing, and show that its convergence is also characterized by the algebraic connectivity of a bipartite graph. In \cref{subsec:regularization}, we extend our framework to settings where \cref{ass:strong-connected} does not hold, by introducing Gamma priors on $s_j$, inspired by \citet{caron2012efficient} and \citet{maystre2017choicerank}. These priors regularize the maximum likelihood problem and guarantee that a unique solution in the interior of the probability simplex always exists. They also speed up the associated iterative algorithm.

\subsection{The Canonical Matrix Balancing Problem}
Matrix balancing is a classic problem that shows up in a wide range of disciplines. See \cref{app:related-works} for a short survey on some applications. 
The underlying mathematical problem can be stated concisely in matrix form as:
\begin{quote} 
Given positive vectors $p \in \mathbb{R}_{++}^n,q \in \mathbb{R}_{++}^m$with $\sum_i p_i=\sum_j q_j$ and non-negative matrix $A\in \mathbb{R}_+^{n\times m}$, find positive diagonal matrices 
$D^{1}$, $D^{0}$ satisfying the conditions $D^{1}AD^{0}\cdot\mathbf{1}_m=p$
and $D^{0}A^{T}D^{1}\cdot\mathbf{1}_n=q$.\end{quote}
We henceforth refer to the above as the ``canonical'' matrix balancing problem. It seeks positive row and column scalings of an (entry-wise) non-negative rectangular matrix $A$ such that the scaled matrix has positive target row and column sums $p$ and $q$. Other variants of the problem replace the row and column sums (the 1-norm) with other norms \citep{bauer1963optimally,ruiz2001scaling}. Note that for any $c>0$, $(D^0/c,cD^1)$ 
 is also a solution whenever $(D^0,D^1)$ is. A finite positive solution $(D^{0},D^{1})$ to the canonical matrix balancing problem is often called a \emph{direct scaling}.

 The structure of the matrix balancing problem suggests a simple iterative scheme: starting
from any initial positive diagonal $D^{0}$, invert $D^{1}AD^{0}\mathbf{1}_m = p$ using $p/(AD^{0}\mathbf{1}_m)$
 to update $D^{1}$. Then invert $D^{0}A^{T}D^{1}\mathbf{1}_n=q$ using  $q/(A^{T}D^{1}\mathbf{1}_n)$ to compute the new estimate of $D^{0}$, and repeat the procedure. Here divisions involving two vectors of the same length are \emph{entry-wise}. This simple scheme is precisely Sinkhorn's algorithm, described in \cref{alg:scaling}, where vectors $d^0,d^1$ are the diagonals of $D^0,D^1$.


An important dichotomy occurs depending on whether the entries of $A$ are strictly positive. If $A$ contains no zero entries, then direct scalings and a unique scaled matrix $D^1AD^0$ always exist \citep{sinkhorn1964relationship}. Moreover, Sinkhorn's algorithm converges linearly \citep{franklin1989scaling}. 
On the other hand, when $A$ contains zero entries, the canonical problem becomes more complicated. Additional conditions are needed to guarantee meaningful solutions, and the convergence behavior of Sinkhorn's algorithm is less understood.  Well-posedness of the matrix balancing problem has been studied by \citet{brualdi1968convex,sinkhorn1974diagonal,pukelsheim2009iterative}, among others, giving rise the following equivalent existence conditions.
\begin{assumption}[\textbf{Strong Existence}]
\label{ass:matrix-existence}
\textbf{(a)} There exists a non-negative matrix $A'\in \mathbb{R}_+^{n\times m}$ with the same zero patterns as $A$ and with row and column sums $p$ and $q$. Or, equivalently,

\textbf{(b)} For every pair of sets of indices $N \subsetneq [n]$ and $M \subsetneq [m]$ such that $A_{ij}=0$ for $i\notin N$ and $j\in M$, $\sum_{i\in N}p_i \geq \sum_{j\in M}q_j$, with equality iff $A_{ij}=0$ for all $i \in N$ and $j \notin M$ as well.
\end{assumption} 
It is well-known in the matrix balancing literature that the above two conditions are equivalent, and that a positive finite solution $(D^{0},D^{1})$ to the canonical problem exists iff they hold. See, for example, Theorem 6 in \citet{pukelsheim2009iterative}. Clearly, \cref{ass:matrix-existence}(a) is the minimal necessary condition when a solution to the matrix balancing problem exists. \cref{ass:matrix-existence}(b) is closely connected to conditions for perfect matchings in bipartite graphs \citep{hall1935representatives}. In flow networks \citep{gale1957theorem,ford1956maximal,ford1957simple}, it is a capacity constraint that
guarantees the maximum flow on a bipartite graph with source and sink is equal to $\sum_i p_i=\sum_j q_j$ and with positive flow on every edge \citep{idel2016review}.  The bipartite graph, denoted by $G_b$, is related to $A$ through its  adjacency matrix $A^b \in \mathbb{R}^{(n+m)\times(n+m)}$ given by
\begin{align*}
    A^b := \begin{bmatrix}\mathbf{0} & {A}\\
{A}^{T} & \mathbf{0}
\end{bmatrix}.	
\end{align*}
See \cref{subsec:graph-laplacian} for a detailed discussion. The structure of $G_b$ turns out to be important for the linear convergence rate of Sinkhorn's algorithm (\cref{sec:linear-convergence}).

On the other hand, the necessary and sufficient condition for uniqueness of finite scalings essentially requires that $A$ is not block-diagonal, and implies that $G_b$ is \emph{connected}.
\begin{assumption}[\textbf{Uniqueness}]
\label{ass:matrix-uniqueness}
 $D^{0}$ and $D^{1}$ are unique modulo normalization iff $A$ is indecomposable, i.e., there does not exist permutation matrices $P,Q$ such that $PAQ$ is block diagonal.
\end{assumption} 
\begin{algorithm}[tb]
\caption{Sinkhorn's Algorithm}
   \label{alg:scaling}
\begin{algorithmic}
   \STATE {\bfseries Input:}  $A, p, q,\epsilon_{\text{tol}}$.
   \STATE {\bfseries initialize} $d^{0}\in\mathbb{R}_{++}^{m}$
   \REPEAT
   \STATE $d^{1} \leftarrow  p/( A d^0)$ 
   \STATE $d^{0}\leftarrow  q/({A}^{T} d^{1})$
   \STATE 
$\epsilon\leftarrow$  update of $(d^{0},d^1)$
\UNTIL{$\epsilon<\epsilon_{\text{tol}}$}
\end{algorithmic}
\end{algorithm}
 
With a proper introduction to both problems, we are now ready to formally establish the equivalence between Luce choice model estimation and matrix balancing in the next section. In \cref{sec:linear-convergence}, we return to Sinkhorn's algorithm for the matrix balancing problem, and settle important open problems concerning its linear convergence for non-negative $A$.  In \cref{sec:connections}, we discuss further connections of matrix balancing and Sinkhorn's algorithm to choice modeling and optimization.

\section{Connecting Choice Modeling and Matrix Balancing}
\label{sec:equivalence}

In this section, we formally establish the connection between choice modeling and matrix balancing. We show that
maximizing the log-likelihood \eqref{eq:log-likelihood} is equivalent to solving a canonical matrix balancing problem. We also precisely describe the correspondence between the relevant conditions in the two problems. In view of this equivalence, we show that Sinkhorn's algorithm, when applied to estimate Luce choice models, is in fact a \emph{parallelized} generalization of the classic algorithm for choice models, dating back to \citet{zermelo1929berechnung,dykstra1956note,ford1957solution}, and studied extensively also by \citet{hunter2004mm,vojnovic2020convergence}. %We further reveal the ubiquity of Sinkhorn's algorithm in choice modeling in \cref{sec:connections}.

\subsection{Maximum Likelihood Estimation of Luce Choice Model as Matrix Balancing}
\label{subsec:reformulation}
The optimality conditions for maximizing the log-likelihood \eqref{eq:log-likelihood} for each $s_j$ are given by
\begin{align*}
\partial_{s_{j}}\ell(s)=\sum_{j\mid (j,S_i)}\frac{1}{s_{j}}-\sum_{i\mid j\in S_{i}}\frac{1}{\sum_{k\in S_{i}}s_{k}} & =0.
\end{align*}
 Multiplying by $s_{j}$ and dividing by $1/n$, we have 
\begin{align}
\label{eq:optimality-original}
\frac{W_j}{n} & = \frac{1}{n} \sum_{i\mid j\in S_{i}}\frac{s_{j}}{\sum_{k\in S_{i}}s_{k}},
\end{align}
where $W_j:=|\{i\mid (j,S_i)\}|$ is the number of observations where $j$ is selected.

\textbf{Remark.} Note that in the special case where $S_i\equiv [n]$, i.e., every choice set contains \emph{all} items, the MLE simply reduces to the familiar empirical frequencies $\hat s_j = {W_j}/{n}$. However, when the choice sets $S_i$ vary, no closed form solution to \eqref{eq:optimality-original} exists, which is the primary motivation behind the long line of works on the algorithmic problem of solving \eqref{eq:optimality-original}. 

With varying $S_i$, we can interpret the optimality condition as requiring the \emph{observed} frequency of $j$ being chosen (left hand side) be equal to the conditional \emph{expected} probability of $j$ being chosen among all observations $i$ where it is part of the choice set $S_i$ (right hand side). In addition, note that since the optimality condition in \eqref{eq:optimality-original} only involves the \emph{frequency} of selection, distinct datasets could yield the same optimality condition and hence the same MLEs. For example, suppose that two alternatives $j$ and $k$ both appear in choice sets
$S_{i}$ and $S_{i'}$, with $j$ selected in $S_{i}$ and  $k$ selected in $S_{i'}$. Then switching
the choices in $S_{i}$ and $S_{i'}$ does not alter the likelihood and optimality conditions. This feature holds more generally with longer cycles of items and choice sets, and can be viewed as a consequence of the context-independent nature of Luce's choice axiom. In some sense, it is also the underpinning of many works in economics that estimate choice models based on \emph{marginal} sufficient statistics. A famous example is  \citet{berry1995automobile}, which estimates consumer preferences using only \emph{aggregate} market shares of products.
% \textbf{This may be a point of departure from IIA, where the chosen alternative with a larger group weight $\sum_k s_k$ should be considered more important.} 
% However, as long as
% the comparison graph is strongly connected, one set of observations
% always corresponds to a unique set of parameters, up to normalization. \textbf{conjecture: can reduce the optimality condition to that of pairwise comparisons, which then gives a square matrix scaling problem.}

\textbf{Remark.} In practice, the choice sets $S_i$ of many observations may be identical to each other. Because \eqref{eq:optimality-original} only depends on the total winning counts of items, we may aggregate over observations with the same $S_i$:
\begin{align*}
\sum_{i\mid j\in S_{i}}\frac{s_{j}}{\sum_{k\in S_{i}}s_{k}} & = \sum_{i'\mid j\in S^\ast_{i'}} R_{i'} \cdot \frac{s_{j}}{\sum_{k\in S^\ast_{i'}}s_{k}},
\end{align*}
where each $S_{i'}^\ast$ is a unique choice set that appears in $R_{i'}\geq 1$ observations, for $i'=1,\dots,n^\ast \leq n$. By construction, $\sum_{i'=1}^{n^\ast}R_{i'} =n$. Note, however, that the selected item could vary across different appearances of $S_i^\ast$, but the optimality conditions only involve each item's winning count $W_j$. From now on, we assume this reduction and drop the notation with $^\ast$. In other words, we assume that we observe $n$ unique choice sets, and choice set $S_i$ has \emph{multiplicity} $R_i$. The resulting problem has optimality conditions
\begin{align}
\label{eq:optimality}
{W_j} & = \sum_{i\mid j\in S_{i}}{R_i} \cdot \frac{s_{j}}{\sum_{k\in S_{i}}s_{k}}.
\end{align}
We are now ready to reformulate \eqref{eq:optimality} as a canonical matrix balancing problem. Define $p\in\mathbb{R}^{n}$ as $p_i=R_i$, i.e., the number of times choice set $S_i$ appears in the data. Define
$q\in\mathbb{R}^{m}$ as $q_j={W_j}$,
i.e., the number of times item $j$ was \emph{selected} in the data. By construction we have $\sum_i p_i=\sum_j q_j$, and $p_i,q_j>0$ whenever \cref{ass:strong-connected} holds.

Now define the $n\times m$ binary matrix $A$ by
$A_{ij}=1\{j\in S_{i}\}$, so the $i$-th row of $A$
is the indicator of which items appear in the (unique) choice set $S_i$, and the $j$-th column of $A$ is the indicator of which choice sets
item $j$ appears in. We refer to this $A$ constructed from a choice dataset as the \emph{participation matrix}. By construction, $A$ has distinct rows, but may still have identical columns. If necessary, we can also remove repeated columns by ``merging'' items and their win counts. Their estimated scores can be computed from the score of the merged item proportional to their respective win counts.

Let $D^{0}\in\mathbb{R}^{m\times m}$ be the diagonal matrix with
$D_{j}^{0}=s_{j}$ and $D^{1}\in\mathbb{R}^{n\times n}$ be the
diagonal matrix with $D_{i}^{1}={R_i}/{\sum_{k\in S_{i}}s_{k}}$,
and define the scaled matrix
\begin{align}
\label{eq:scaled-matrix}
\hat{A} & :=D^{1}AD^{0}.
\end{align}
The matrices $D^{1}$ and $D^{0}$ are scalings of rows and columns
of $A$, respectively, and
\begin{align*}
    \hat{A}_{ij} = \frac{R_i}{\sum_{k\in S_{i}}s_{k}}\cdot1\{j\in S_{i}\}\cdot s_{j}.
\end{align*}
The key observation is that the optimality condition \eqref{eq:optimality} can be rewritten as
\begin{align}
\label{eq:bridge}
\hat{A}^T \mathbf{1}_n & = q.
\end{align}
Moreover, by construction $\hat{A}$ also satisfies
\begin{align}
\label{eq:marginal}
\hat{A}\mathbf{1}_m & = p.
\end{align}
 Therefore, if $s_j$'s satisfy the optimality conditions for maximizing \eqref{eq:log-likelihood}, then $D^0,D^1$  defined above solve the matrix balancing problem in \cref{eq:scaled-matrix,eq:bridge,eq:marginal}. Moreover, the converse is also true, and we thus establish the equivalence between choice maximum likelihood estimation and matrix balancing. All omitted proofs appear in \Cref{app:proofs}.
\begin{theorem}
\label{prop:mle-scaling}
Let $p\in\mathbb{R}^{n}$ with $p_{i}=R_i$, $q\in\mathbb{R}^{m}$ with $q_{j}=W_j$, and 
$A\in\mathbb{R}^{n\times m}$
with $A_{ij}=1\{j\in S_{i}\}$ be constructed from the choice dataset. Then  $D^{0},D^{1}>0$ with $\sum_j D_j^0=1$ solves the matrix balancing problem
\begin{align}
\label{eq:equation-system}
\begin{split}
\hat{A} & =D^{1}AD^{0}\\
\hat{A}\mathbf{1}_m & =p\\
\hat{A}^{T} \mathbf{1}_n & =q
\end{split}
\end{align}
if and only if $s \in \Delta_m$ with $s_j=D^0_j$ satisfies the optimality condition \eqref{eq:optimality} of the ML estimation problem.%, with $D_{j}^{0}=s_{j}$ and $D_{i}^{1} =\frac{R_i}{\sum_{k\in S_{i}}s_{k}}$.
\end{theorem}
In particular, \eqref{eq:log-likelihood} has a unique maximizer $s$ in the interior of the probability simplex if and only if \eqref{eq:equation-system} has a unique normalized solution $D^0$ as well. The next question, naturally, is then how \cref{ass:strong-connected} and \cref{ass:weak-connected} for choice modeling are connected to \cref{ass:matrix-existence} and \cref{ass:matrix-uniqueness} for matrix balancing. 
\begin{theorem}
\label{thm:necessary-and-sufficient}
Let (A,p,q) be constructed from the choice dataset as in \cref{prop:mle-scaling}, with $p,q>0$. \cref{ass:weak-connected} is equivalent to \cref{ass:matrix-uniqueness}. Furthermore, \cref{ass:strong-connected} holds if and only if $(A,p,q)$ satisfy \cref{ass:matrix-existence} and $A$ satisfies \cref{ass:matrix-uniqueness}.
\end{theorem} 
Thus when the ML estimation problem is cast as a matrix balancing problem, \cref{ass:matrix-existence} exactly characterizes the \emph{gap} between \cref{ass:weak-connected} and \cref{ass:strong-connected}. 
 We provide some intuition for \cref{thm:necessary-and-sufficient}. When we construct a triplet $(A,p,q)$ from a choice dataset, with $p$ the numbers of appearances of unique choice sets and $q$ the winning counts, \cref{ass:matrix-uniqueness} precludes the possibility of partitioning the items into two subsets that never get compared with each other, i.e., \cref{ass:weak-connected}. Then \cref{ass:matrix-existence} requires that whenever a strict subset $M\subsetneq [m]$ of objects only appear in a strict subset $N\subsetneq [n]$ of the observations, their total winning counts are \emph{strictly} smaller than the total number of these observations, i.e., there is some object $j\notin M$ that is selected in $S_i$ for some $i\in N$, which is required by \cref{ass:strong-connected}.

Interestingly, while \cref{ass:strong-connected} requires the directed comparison graph, defined by the $m\times m$ matrix of counts of item $j$ being chosen over item $k$, to be strongly connected, the corresponding conditions for the equivalent matrix balancing problem concern the $n\times m$ participation matrix $A$ and positive vectors $p,q$, which do not explicitly encode the specific \emph{choice} of each observation. This apparent discrepancy is due to the fact that $(A,p,q)$ form the \emph{sufficient statistics} of the Luce choice model, and for each valid triplet $(A,p,q)$, there can be more than one choice dataset with maximum likelihood optimality condition \eqref{eq:optimality}.

\textbf{Remark.} This feature where ``marginal'' quantities constitute the sufficient statistics of a parametric model is an important one that underlies many works in economics and statistics \citep{kullback1997information,stone1962multiple,good1963maximum,birch1963maximum,theil1967economics,fienberg1970iterative,berry1995automobile,fofana2002balancing,maystre2017choicerank}. It makes the task of estimating a \emph{joint} model from marginal quantities feasible. This is useful because in many applications, only marginal data is available due to high sampling cost or privacy reasons. %More importantly, it ensures the validity of the resulting estimator when the number of (marginal) observations is on the same order as the number of parameters. %Take the choice model \eqref{eq:log-likelihood} in this paper as an example. Suppose the number of choice observations $n=\mathcal{O}(m)$, where $m$ is the number of parameters, as $m,n \rightarrow \infty$. Although ``sample'' size $n$ only grows linearly with parameter dimension $m$, the resulting estimator will still be $\sqrt{n}$-consistent as long as the number of non-zero entries of $A$ is $\mathcal{O}(mn)$, i.e., items are included in choice sets often enough.

Having formulated a particular matrix balancing problem from the estimation problem given choice data, we may ask how one can go in the other direction. In other words, when/how can we construct a ``choice dataset'' whose sufficient statistics is a given triplet $(A,p,q)$? First off, for $(A,p,q)$ to be valid sufficient statistics of a Luce choice model, $p,q$ need to be positive integers. Moreover, $A$ has to be a binary matrix, with each row containing at least two non-zero elements (valid choice sets have at least two items). Given such a $(A,p,q)$ satisfying Assumptions \ref{ass:matrix-existence} and \ref{ass:matrix-uniqueness}, a choice dataset can be constructed efficiently. Such a procedure is described, for example, in \citet{kumar2015inverting}, where $A$ is motivated
by random walks on a graph instead of matrix balancing (\cref{sec:connections}). Their construction relies on finding the max flow on the bipartite graph $G_b$. For rational $p,q$, this maximum flow can be found efficiently in polynomial time \citep{balakrishnan2004polynomial,idel2016review}. Moreover, the maximum flow implies a matrix $A'$ satisfying \cref{ass:matrix-existence}(a), thus providing a feasibility certificate for the matrix balancing problem as well. 

%For large $A$, verifying \cref{ass:matrix-existence}(b) can be costly. Fortunately, the max flow algorithm used in \citet{kumar2015inverting,idel2016review} is also known to be an efficient method to check that the matrix balancing problem $(A,p,q)$ with rational $p,q$ has a solution \citep{balakrishnan2004polynomial,idel2016review}.

We have thus closed the loop and fully established the equivalence of the maximum likelihood estimation of Luce choice models and the canonical matrix balancing problem.
\begin{corollary}
    There is a one-to-one correspondence between classes of maximum likelihood estimation problems with the same optimality conditions \eqref{eq:optimality} and canonical matrix balancing problems with $(A,p,q)$, where $A$ is a valid participation matrix and $p,q>0$ have integer entries. 
\end{corollary}
We next turn our attention to the algorithmic connections between choice modeling and matrix balancing. %Given the equivalence between the two problems, we can naturally consider applying the classic algorithm for matrix balancing to choice modeling. 
\subsection{Algorithmic Connections between Matrix Balancing and Choice Modeling}
\label{subsec:IPF}
 Given the equivalence between matrix balancing and choice modeling, we can naturally consider applying Sinkhorn's algorithm to maximize \eqref{eq:log-likelihood}. In this case, one can verify that the updates in each full iteration of \cref{alg:scaling} reduce algebraically to
\begin{align}
\label{eq:scaling-iteration}
s_{j}^{(t+1)} & =W_{j}/\sum_{i\mid j\in S_{i}}\frac{R_i}{\sum_{k\in S_{i}}s_{k}^{(t)}}
\end{align}
 in the $t$-th iteration. 
 Comparing \eqref{eq:scaling-iteration} to the optimality condition in \eqref{eq:optimality}, which we recall is given by 
\begin{align*}
 W_j & =\sum_{i\mid j\in S_{i}} R_i\frac{s_{j}}{\sum_{k\in S_{i}}s_{k}}= s_{j} \cdot \sum_{i\mid j\in S_{i}}\frac{R_i}{\sum_{k\in S_{i}}s_{k}},
 \end{align*}
we can therefore interpret the iterations as simply dividing the winning count $W_j$ by the coefficient of $s_j$ on the right repeatedly, in the hope of converging to a \emph{fixed point}. A similar intuition was given by \citet{ford1957solution} in the special case of pairwise comparisons. Indeed, the algorithm proposed there is a cyclic variant of \eqref{eq:scaling-iteration} applied to pairwise comparisons. However, this connection is mainly algebraic, as the optimality condition in \citet{ford1957solution} does not admit a reformulation as the matrix balancing problem in \eqref{eq:equation-system}.

In \cref{sec:connections}, we provide further discussions on the connections of Sinkhorn's algorithm to existing frameworks and algorithms in the choice modeling literature, and connect it to distributed optimization as well. We demonstrate that many existing algorithms for Luce choice model estimation are in fact special cases or analogs of Sinkhorn's algorithm. However, Sinkhorn's algorithm applies to non-binary $A$ and non-integer $p,q$, and has the critical advantage of being paralellized and distributed, hence more efficient in practice. %Moreover, it also allows straightforward extensions to more general choice models, which we discuss in \cref{sec:extensions}.

The mathematical and algorithmic connections between matrix balancing and choice modeling we establish in this paper allow the transfusion of ideas in both directions. For example, inspired by regularized maximum likelihood estimation \citep{maystre2017choicerank}, we propose a regularized version of Sinkhorn's algorithm in \cref{subsec:regularization}, which is guaranteed to converge even when the original Sinkhorn's algorithm does not converge. Moreover, the importance of algebraic connectivity in quantifying estimation and computation efficiency in choice modeling motivates us to solve some important open problems on the convergence of Sinkhorn's algorithm. We turn to this topic next. 

%Importantly, the mathematical and algorithmic connections between matrix balancing and choice modeling motivate us to consider algebraic connectivity in the convergence analysis of Sinkhorn's algorithm. This and additional insights allow us to prove new quantitative linear convergence results. We turn to this topic next.

% In our work, we take a new perspective and recast the maximum likelihood estimation of Luce choice models as a matrix balancing problem. This results in several advantages. First, although algebraically reducing to \eqref{eq:scaling-iteration}, updates in Sinkhorn's algorithm are  \emph{parallelized}, and can be implemented distributedly, especially when there is a large number of observations or items. This means significant computational savings. Second, as we detail in \cref{sec:connections}, the matrix balancing perspective allows us to unify many existing frameworks and algorithms in the choice modeling literature,
% and connect to distributed optimization as well. Third, the matrix formulation allows straightforward extensions of Sinkhorn's algorithm to more general choice models, which we discuss in \cref{sec:extensions}. Last but not least, connecting choice modeling to matrix balancing allows us to borrow insights on the importance of algebraic connectivity in choice models to resolve important open problems on the convergence of Sinkhorn's algorithm.
%  More precisely, we prove quantitative global linear convergence of Sinkhorn's algorithm, and identify the sharp asymptotic rate of convergence for non-negative matrices and general marginals. We turn to this topic next.

\section{Linear Convergence of Sinkhorn's Algorithm for Non-negative Matrices}
\label{sec:linear-convergence}
In this section, we study the global and asymptotic linear convergence rates of Sinkhorn's algorithm for the matrix balancing problem $(A,p,q)$ with general non-negative matrices and positive marginals. We first discuss relevant quantities and important concepts before presenting the convergence results in \cref{subsec:global-linear-convergence} and \cref{subsec:sharp-rate}.
Throughout, we use superscript $\cdot^{(t)}$ to denote quantities after $t$ iterations of Sinkhorn's algorithm. %denote by $\hat A^{(t)}$ the scaled matrix $D^{1}AD^{0}$ using updated scalings $D^0,D^1$ after the $t$-th iteration of Sinkhorn's algorithm. Similarly for other quantities with superscript $(t)$.

\subsection{Preliminaries}
\begin{table*}
 \begin{adjustwidth}{-1.1cm}{}
\begin{centering}
\begin{tabular}{c|c|c|c|c}
 & convergence statement & $\lambda$ & $A$ & $p,q$\tabularnewline
\hline 
\citet{franklin1989scaling} & $d_{\text{Hilbert}}(r^{(t)},p)\leq\lambda^t d_{\text{Hilbert}}(r^{(0)},p)$ & $\kappa^{2}(A)$ & $A>0$, rectangular & uniform\tabularnewline
\hline 
\citet{luo1992convergence} & $g(u^{(t)},v^{(t)})-g^\ast\leq\lambda^t (g(u^{(0)},v^{(0)})-g^\ast)$ & \text{unknown} & $A\geq0$, rectangular & general\tabularnewline
\hline 
\citet{knight2008sinkhorn} & $\|D_{t+1}^{0}-D^{0}\|_{\ast}\leq(\lambda+\epsilon)\|D_{t}^{0}-D^{0}\|_{\ast}$ & $\sigma_{2}^{2}(\hat{A})$ & $A\geq0$, square  & uniform\tabularnewline
\hline 
\citet{pukelsheim2009iterative} & $\|r^{(t)}-p\|_{1}\rightarrow0$ & no rate & $A\geq0$, rectangular & general\tabularnewline
\hline 
\citet{altschuler2017near} & $\|r^{(t)}-p\|_{1}\leq c \sqrt{\frac{\lambda}{t}}$ & $\log(\frac{\sum_{ij}A_{ij}}{\min_{ij}A_{ij}})$ & $A>0$, rectangular & general\tabularnewline
\hline 
\citet{leger2021gradient} & $D_{\text{KL}}(r^{(t)}\| p) \leq\frac{\lambda}{t}$ & $D_{\text{KL}}(\hat{A}\| A)$ & $A\geq0$, continuous & general\tabularnewline
\hline 
current work, asymptotic & $\|\frac{r^{(t+1)}}{\sqrt{p}}-\sqrt{p}\|_{2}\leq(\lambda+\epsilon)\|\frac{r^{(t)}}{\sqrt{p}}-\sqrt{p}\|_{2}$ & $\lambda_{2}(\tilde{A}^T\tilde{A})$ & $A\geq0$, rectangular & general\tabularnewline
\hline 
current work, global & $g(u^{(t)},v^{(t)})-g^\ast\leq\lambda^t (g(u^{(0)},v^{(0)})-g^\ast)$ & $1-c_B\lambda_{-2}(\mathcal{L})/l$ & $A\geq0$, rectangular & general\tabularnewline
\end{tabular}
\par\end{centering}
\caption{Summary of some convergence results on Sinkhorn's algorithm. In \citet{franklin1989scaling}, $\kappa(A)=\frac{\theta(A)^{1/2}-1}{\theta(A)^{1/2}+1}$,
where $\theta(A)$ is the diameter of $A$ in the Hilbert metric.
The norm in \citet{knight2008sinkhorn} is not explicitly specified, and $\sigma_{2}(\hat{A})$
denotes the second largest singular value of the scaled
doubly stochastic matrix $\hat{A}$. The bound in \citet{altschuler2017near} was
originally stated as $\|r^{(t)}-p\|_{1}\protect\leq\epsilon'$
in $t=O(\epsilon'^{-2}\log(\frac{\sum_{ij}A_{ij}}{\min_{ij}A_{ij}}))$
iterations. The result in \citet{leger2021gradient} applies more generally to couplings
of probability distributions. In view of Pinsker's inequality, it implies the bound in \citet{altschuler2017near} but with a constant that is finite even when $A$ has zero entries. In the bound in \citet{knight2008sinkhorn} and our
asymptotic result, the $\lambda+\epsilon$ denotes an asymptotic rate, with the
bound valid for any $\epsilon>0$ and all $t$ sufficiently large. In our global bound, the linear rate $\lambda_{-2}(\mathcal{L})$ is the second \emph{smallest} eigenvalue of the Laplacian of the bipartite graph defined by $A$ (see \cref{subsec:graph-laplacian}), $ l=\min \{\max_j (A^T\mathbf{1}_n)_j, \max_i (A\mathbf{1}_m)_i\}$,
$c_B=\exp(-4B)$, and $B$ is a bound on the initial sub-level set, which is finite if and only if \cref{ass:matrix-existence} holds.
}
\label{tab:convergence-summary}
\end{adjustwidth}
\end{table*}
We start with the optimization principles associated with matrix balancing and Sinkhorn's algorithm. Consider the following KL divergence (relative entropy) minimization problem 
     \begin{align}
\label{eq:relative-entropy-minimization}
\begin{split}
  \min_{\hat A\in \mathbb{R}^{n\times m}_+} & D_{\text{KL}}(\hat{A}\| A)\\
\hat{A}\mathbf{1}_m & =p\\
\hat{A}^{T}\mathbf{1}_n & =q.
\end{split}
\end{align}
It is well-known that solutions $\hat{A}=D^1AD^0$ to the matrix balancing problem with $(A,p,q)$ are minimizers of \eqref{eq:relative-entropy-minimization} \citep{ireland1968contingency,bregman1967proof}. Moreover, Sinkhorn's algorithm can be interpreted as a block coordinate descent type algorithm applied to minimize the following dual problem of \eqref{eq:relative-entropy-minimization}:
 \begin{align}
 \label{eq:log-barrier}
     g(d^0,d^1)	:=(d^1)^{T}Ad^0-\sum_{i=1}^{n}p_{i}\log d^1_{i}-\sum_{j=1}^{m}q_{j}\log d^0_{j},
\end{align} 
\citet{luo1992convergence} study the linear convergence of block coordinate descent algorithms. Their result implies that the
convergence of Sinkhorn's algorithm, measured in terms of the optimality gap of $g$, is linear with some implicit rate $\lambda>0$,
 as long as finite positive scalings $D^0,D^1$ exist for the matrix balancing problem. Minimizers $d^0,d^1$ of \eqref{eq:log-barrier} precisely give the diagonals of $D^0,D^1$. The function $g$, known to be a \emph{potential function} of Sinkhorn's algorithm, also turns out to be crucial in quantifying the global linear convergence rate in this paper. 

\textbf{Remark.} Interestingly, minimizing \eqref{eq:log-barrier} is in fact equivalent to maximizing the log-likelihood function $\ell(s)$ in \eqref{eq:log-likelihood} for valid $(A,p,q)$, because $\min_{d^1}g(d^0,d^1)=-\ell(d^0)+c$ for some $c>0$. Moreover, the optimality condition of minimizing $g$ with respect to $d^0$ reduces to the optimality condition \eqref{eq:optimality}. A detailed discussion can be found in \cref{sec:sinkhorn-MM}. This connection relates choice modeling and matrix balancing from an optimization perspective.
     
      Although convergence results on Sinkhorn's algorithm are abundant, the recent work of \citet{leger2021gradient} stands out as the first \emph{explicit} global convergence result applicable to general non-negative matrices, with a sub-linear $\mathcal O(1/t)$ bound on the KL divergence with respect to target marginals. It implies the bounds in \citet{chakrabarty2021better,altschuler2017near} but with a constant that is finite even when $A$ has zero entries. The result in \citet{leger2021gradient} applies more generally to couplings of continuous probability distributions, but when restricted to the discrete matrix balancing problem, it 
     holds under the following equivalent conditions that are weaker than \cref{ass:matrix-existence}.
\begin{assumption}[\textbf{Weak Existence}]
    \label{ass:matrix-weak-existence}
    
    \textbf{(a)} There exists a non-negative matrix $A'\in \mathbb{R}_+^{n\times m}$ that inherits all zeros of $A$ and has row and column sums $p$ and $q$. Or, equivalently,
    
\textbf{(b)} For every pair of sets of indices $N \subsetneq [n]$ and $M \subsetneq [m]$ such that $A_{ij}=0$ for $i\notin N$ and $j\in M$, $\sum_{i\in N}p_i \geq \sum_{j\in M}q_j$.
\end{assumption}

The equivalence of these conditions follows from Theorem 4 in \citet{pukelsheim2009iterative}, which also shows that they are the minimal requirements for the convergence of Sinkhorn's algorithm. \cref{ass:matrix-weak-existence}(a) precisely guarantees 
that the optimization problem \eqref{eq:relative-entropy-minimization} is feasible and bounded. It relaxes \cref{ass:matrix-existence}(a) by allowing additional zeros in the matrix $A'$. Similarly, \cref{ass:matrix-weak-existence}(b) relaxes \cref{ass:matrix-existence}(b) by allowing equality between $\sum_{i\in N}p_i$ and $\sum_{j\in M}q_j$ even when $M,N$ do not correspond to a block-diagonal structure. 

\textbf{Remark.} The distinction between \cref{ass:matrix-existence} and \cref{ass:matrix-weak-existence} is crucial for the matrix balancing problem and Sinkhorn's algorithm. Recall that \cref{ass:matrix-existence} guarantees the matrix balancing problem has a solution $(D^0,D^1)$, and $D^1AD^0$ is always a solution to \eqref{eq:relative-entropy-minimization}. On the other hand, the weaker condition \cref{ass:matrix-weak-existence} guarantees that \eqref{eq:relative-entropy-minimization} has a solution $\hat A$.
If indeed $\hat A$ has additional zeros relative to $A$, then no direct (finite and positive) scaling $(D^{0},D^{1})$ exists such that $\hat A=D^1AD^0$. However, the sequence of scaled matrices $\hat A^{(t)}$ from Sinkhorn's algorithm still converges to $\hat A$. In this case, the matrix balancing problem is said to have a \emph{limit} scaling, where some entries of $d^{0},d^{1}$ in Sinkhorn iterations approach 0 or $\infty$, resulting in additional zeros in $\hat A$. Below we give an example adapted from \citet{pukelsheim2009iterative}, where $p,q=(3,3)$ and the scaled matrices $\hat A^{(t)}$ converge but no direct scaling exists:
\begin{align*}
{D^{1}}^{(t)}\begin{bmatrix}3&1\\
0 & 2
\end{bmatrix}{D^{0}}^{(t)} = \begin{bmatrix}1&0\\
0 & \frac{3t}{2}
\end{bmatrix}\begin{bmatrix}3&1\\
0 & 2
\end{bmatrix}\begin{bmatrix}1&0\\
0 & \frac{1}{t}
\end{bmatrix}	\rightarrow \begin{bmatrix}3&0\\
0 & 3
\end{bmatrix}.
\end{align*}

Given these discussions, it is therefore important to clarify the convergence behaviors of Sinkhorn's algorithm in different regimes. In particular, it remains to reconcile the gap between the implicit linear convergence result of \citet{luo1992convergence} under strong existence, and the quantitative sub-linear bound of \citet{leger2021gradient} under weak existence. Furthermore, it remains to provide explicit characterizations of both the global and asymptotic (local) rates when Sinkhorn's algorithm does converge linearly. 
% Moreover, we are interested in special structures of $A$ that would guarantee a \emph{linear} convergence, thereby filling the gap between $\mathcal O(1/t)$ for generic non-negative $A$ and $\mathcal O(\lambda^{-t})$ for positive $A$.

Our results in this section provide answers to these questions. We show that the $\mathcal O(1/t)$ rate can be sharpened to a global $\mathcal O(\lambda^t)$ bound if and only if the weak existence condition (\cref{ass:matrix-weak-existence}) is replaced by the strong existence condition (\cref{ass:matrix-existence}). Moreover, we provide an explicit global linear convergence rate $\lambda$ in terms of the \emph{algebraic connectivity}, revealing the structure-dependent nature of Sinkhorn's algorithm for problems with non-negative matrices. This generalizes the implicit result of \citet{luo1992convergence} and sheds light on how different assumptions impact Sinkhorn's convergence, which is explicitly reflected in the constants of the bound. Going further, we characterize the sharp asymptotic rate of linear convergence in terms of the second largest singular value of $\mathcal{D}(1/\sqrt{p})\cdot\hat{A}\cdot\mathcal{D}(1/\sqrt{q})$, where $\mathcal{D}$ denotes the diagonalization of a vector. This asymptotic rate reduces to that given by \citet{knight2008sinkhorn} for $m=n$ and uniform $p,q$.

%\ju{After getting through the above paragraph (which largely repeats things already said but now we've finally got precise language for the statements, so its ok), I feel myself wanting Table 1, but it's still two pages away. And I don't see any mention of Luo and Tseng (1992) in the table, or conversely, no discussion of differences in metrics from the table discussed here. I feel like Sec 5 should maybe open with Table 1? Or the very least, move it so it lands on an early page of Sec 5, even if it isn't discussed until the paragraph below? But also... like, we've given an overview in the introduction, 2.5 pages, then Sec 2 is 2.5 pages of related work, ... then Sec 3 is still very background for another page and a half... From a hlgh-level view, I feel like the ``related work'' parts of Section 5 should be out of the way by now..? Like, should Table 1 actually be covered in an earlier section? Or is that too much to ask, given that the connections haven't been made yet (made in Sec 4)? }

The choice of convergence measure is important, and previous works have used different convergence measures. First note that after each iteration in \cref{alg:scaling}, the column constraint is always satisfied: $\hat{A}^{(t)}\mathbf{1}_n=q$.
\citet{leger2021gradient} uses the KL divergence $D_{\text{KL}}(r^{(t)}\| p)$ between the row sum $r^{(t)}=\hat{A}^{(t)}\mathbf{1}_m$ of the scaled matrix $\hat{A}^{(t)}$ after $t$ iterations and the target row sum $p$ to measure convergence. \citet{franklin1989scaling} use the Hilbert projective metric between $r^{(t)}$ and $p$. \citet{pukelsheim2009iterative} and \citet{altschuler2017near} use the $\ell^1$ distance, which is upper bounded by the KL divergence via Pinsker's inequality. \citet{knight2008sinkhorn} focuses on the convergence of the scaling diagonal matrix $D^0=\mathcal{D}(d^0)$ to the optimal solution \emph{line}, but does not explicitly specify the norm.
Some bounds are \emph{a priori} and hold globally for all iterations, while others hold locally in a neighborhood of the optimum.
We summarize the relevant convergence results in \cref{tab:convergence-summary}. Here $\lambda_{-2}(S)$ denotes the second smallest eigenvalue of a real symmetric matrix $S$, and $\lambda_{2}(S)$ the second largest eigenvalue. In our work, we characterize the global linear convergence through the optimality gap of \eqref{eq:log-barrier}, which naturally leads to a bound on $\|r^{(t)}-p\|_1$. For the sharp asymptotic rate, we choose to use the $\ell^2$ distance $\|r^{(t)}/\sqrt{p}-\sqrt{p}\|_2$ in order to exploit an intrinsic orthogonality structure afforded by Sinkhorn's algorithm. This approach results in a novel analysis compared to \citet{knight2008sinkhorn} that most explicitly reveals the importance of spectral properties in  the rate of convergence.

\subsection{Global Linear Convergence}
\label{subsec:global-linear-convergence}
We first present the global linear convergence results. Our analysis starts with the following change of variables to transform the potential function \eqref{eq:log-barrier}:
\begin{align}
\label{eq:change-of-variables}
    u:=\log d^0,\quad v:=-\log d^1.
\end{align}
This results in the potential function $g(u,v)$ defined as
\begin{align}
\label{eq:transformed-potential}
  g(u,v)	:=\sum_{ij}A_{ij}e^{-v_{i}+u_{j}}+\sum_{i=1}^{n}p_{i}v_{i}-\sum_{j=1}^{m}q_{j}u_{j},
\end{align}
and we can verify that Sinkhorn's algorithm is equivalent to the alternating minimization algorithm \citep{bertsekas1997nonlinear,beck2013convergence} for \eqref{eq:transformed-potential}, which alternates between minimizing with respect to $u$ and $v$, holding the other block fixed:
\begin{align}
   \label{eq:alternating-minimization} u_j^{(t)}\leftarrow  \log \frac{q_j}{\sum_i A_{ij}e^{-v^{(t-1)}_i}},\quad v_i^{(t)}\leftarrow  \log \frac{p_i}{\sum_j A_{ij}e^{u^{(t)}_j}}.
\end{align}
The Hessian $\nabla^2g(u,v)$ always has $\mathbf{1}_{m+n}$ in its null space. On the surface, standard linear convergence results for first-order methods, which require strong convexity (or PL condition) of the objective function, do not apply to $g(u,v)$. However, we show that under strong existence and uniqueness conditions for the matrix balancing problem, $g(u,v)$ is in fact strongly convex when \emph{restricted} to the subspace 
\begin{align*}
   \mathbf{1}_{m+n}^\perp:= \{u\in \mathbb{R}^m,v\in \mathbb{R}^n:(u,v)^T\mathbf{1}_{m+n}=0\}.
\end{align*}
As a result, Sinkhorn's algorithm converges linearly with a rate that depends on the (restricted) condition number of its Hessian. %\zq{Now that we know the convergence depends on condition number of the graph Laplacian, we can consider \emph{precondtioning} Sinkhorn's algorithm (much like preconditioned gradient descent)! This will improve it especially for local graphs where the Laplacian is ill-conditioned.} 

\begin{algorithm}[tb]
\caption{Normalized Sinkhorn's Algorithm}
   \label{alg:scaling-normalized}
\begin{algorithmic}
   \STATE {\bfseries Input:}  $A, p, q,\epsilon_{\text{tol}}$.
   \STATE {\bfseries initialize} $d^{0}\in\mathbb{R}_{++}^{m}$
   \REPEAT
   \STATE $d^{1} \leftarrow  p/( A d^0)$ 
   \STATE 
  normalization  $(d^0,d^1) \leftarrow (d^0/c,c d^1),c>0$
   \STATE $d^{0}\leftarrow  q/({A}^{T} d^{1})$
   \STATE 
  normalization  $(d^0,d^1) \leftarrow (d^0/c,c d^1),c>0$ 
   \STATE 
$\epsilon\leftarrow$  update of $(d^{0},d^1)$
\UNTIL{$\epsilon<\epsilon_{\text{tol}}$}
\end{algorithmic}
\end{algorithm}

\textbf{Remark.} The ability of Sinkhorn's algorithm to exploit the strong convexity of $g(u,v)$ on $\mathbf{1}_{m+n}^\perp$ relies critically on the invariance of $g(u,v)$ under \emph{normalization}, which is an intrinsic feature of the problem that has been largely set aside in the convergence analysis so far. Recall that $u=\log d^0$ and $v=-\log d^1$, where $d^0,d^1$ are the diagonals of the scaling $(D^0,D^1)$. Scalings are only determined up to multiplication by $(1/c,c)$ for $c>0$, and the translation $(u,v)\rightarrow(u-\log c,v-\log c)$ does not alter the objective value in \eqref{eq:transformed-potential}. We may therefore impose an \emph{auxiliary} normalization $(u,v)^T\mathbf{1}_{m+n}=0$, or equivalently $\prod_j d^0_j = \prod_i d^1_i$. This normalization is easily achieved by requiring that after every update of Sinkhorn's algorithm, a normalization $(d^0/c,c d^1)$ is performed using the normalizing constant 
\begin{align}
\label{eq:normalization}
   c=\sqrt{\prod_j d^0_j /\prod_i d^1_i}.
\end{align}
See \cref{alg:scaling-normalized}. Note, however, that this normalization is only a supplementary construction in our analysis. The final convergence result applies to the original Sinkhorn's algorithm without normalization, since it does not alter the objective value. Normalization of Sinkhorn's algorithm is discussed in \citet{carlier2023sista}, although they use the asymmetric condition $u_0=0$, which does not guarantee that normalized Sinkhorn iterates stay in $\mathbf{1}_{m+n}^\perp$. 

Suppose that Sinkhorn's algorithm initializes with $u^{(0)}$, and $v^{(0)}$ is given by \eqref{eq:alternating-minimization}. Define the constant $B$ as 
\begin{align*}
   B:&= \sup_{(u,v)} \|(u,v)\|_\infty\\  \text{subject to } (u,v)^{T}&\mathbf{1}_{m+n}=0,\\
   g(u,v)&\leq g(u^{(0)},v^{(0)}).
\end{align*}
In other words, $B$ is the \emph{diameter} of the initial normalized sub-level set. We will show that $B$ is finite and that it bounds normalized Sinkhorn iterates by the \emph{coercivity} of $g(u,v)$ under \cref{ass:matrix-existence}.  

We similarly define the normalized optimal solution pair 
\begin{align}
\label{eq:normalized-optimum}
    (u^\ast,v^\ast):=\arg \min_{(u,v)\in \mathbf{1}_{m+n}^\perp} g(u,v),
\end{align}
and $g^\ast:=g(u^\ast,v^\ast)$.
Finally, define 
\begin{align*}
    l_0:= \max_j (A^T\mathbf{1}_n)_j, \quad l_1:= \max_i (A\mathbf{1}_m)_i,
\end{align*}
which are the Lipschitz constants of the two sub-blocks of $g(u,v)$.

Define the \emph{Laplcian} matrix $\mathcal{L}$ of the bipartite graph $G_b$ as 
\begin{align*}
\mathcal{L}:&=\begin{bmatrix}\mathcal{D}({A}\mathbf{1}_{m}) & -{A}\\
-{A}^{T} & \mathcal{D}({A}^{T}\mathbf{1}_{n})
\end{bmatrix}, 
\end{align*}
and refer to the second smallest eigenvalue $\lambda_{-2}(\mathcal{L})$ as the Fiedler eigenvalue. For details on the graph Laplacian and the Fielder eigenvalue, see \cref{subsec:graph-laplacian}.

Using the above notation, we can now state one of our main contributions to the study of Sinkhorn's algorithm. 
\begin{theorem}[\textbf{Global Linear Convergence}]
\label{thm:global-convergence}
Suppose \cref{ass:matrix-existence} and \cref{ass:matrix-uniqueness} hold. For all $t>0$,
\begin{align}
\label{eq:potential convergence}
g(u^{(t+1)},v^{(t+1)}) - g^\ast \leq (1-c_B \frac{\lambda_{-2}(\mathcal{L})} {l})\left( g(u^{(t)},v^{(t)})-g^\ast \right),
    \end{align}
    where $c_B=e^{-4B}$ and $l=\min\{l_0,l_1\}$.
      
    As a consequence, we have the following bound:
    \begin{align*}
       \|r^{(t)}-p\|_{1} &\leq c'_Be^{-c_{B}\frac{\lambda_{-2}(\mathcal{L})}{2\min\{l_{0},l_{1}\}}\cdot t},
    \end{align*} 
    where $(c'_B)^2=(8B\sum_{i}p_{i})$.
\end{theorem}
\cref{thm:global-convergence} immediately implies the following iteration complexity bound.
\begin{corollary}[\textbf{Iteration Complexity}]
Under \cref{ass:matrix-existence} and \cref{ass:matrix-uniqueness}, $\|r^{(t)}-p\|_1\leq \epsilon$ after
      \begin{align*}
          \mathcal{O} \left (\frac{\min\{l_{0},l_{1}\}}{\lambda_{-2}(\mathcal{L})} \cdot \log (1/\epsilon) \right )
      \end{align*}
       iterations of Sinkhorn's algorithm.
\end{corollary}
\textbf{Remark.} When $A$ is positive (not just non-negative), then the strong existence and uniqueness conditions are trivially satisfied, and our results continue to hold with the rate quantified by $\min\{l_{0},l_{1}\}/\lambda_{-2}(\mathcal{L})$, which can be interpreted as a ``condition number'' of the graph Laplacian $\mathcal{L}$.

The proof of \cref{thm:global-convergence} relies crucially on the observation that the Hessian of $g(u,v)$ at $(0,0)$ is precisely the \emph{Laplacian} $\mathcal{L}$ of the bipartite graph $G_b$. Therefore, when $(u,v)$ are \emph{bounded} throughout the iterations, the Fiedler eigenvalue of $\mathcal{L}$ quantifies the strong convexity on $\mathbf{1}_{m+n}^\perp$. The linear convergence then follows from standard results on block coordinate descent and alternating minimization methods for strongly convex and smooth functions \citep{beck2013convergence}. Typically, the leading eigenvalue of the Hessian quantifies the smoothness \citep{luenberger1984linear}. This is given by $2\max\{l_0,l_1\}$ for $\mathcal{L}$. However, for alternating minimization methods, the better smoothness constant $\min\{l_0,l_1\}$ is available. %\zq{Why is $\lambda_{-2}(\mathcal{L})$ still smaller than $l$?}

\textbf{Remark.}  
The importance of Assumptions \ref{ass:matrix-existence} and \ref{ass:matrix-uniqueness} are clearly reflected in the bound \eqref{eq:potential convergence}.
First, note that the Fiedler eigenvalue $\lambda_{-2}(\mathcal{L})>0$ iff \cref{ass:matrix-uniqueness} holds (see \cref{subsec:graph-laplacian}). On the other hand, \cref{ass:matrix-existence} guarantees the \emph{coercivity} of $g$ on $\mathbf{1}_{m+n}^\perp$. This property ensures that $B<\infty$, and consequently, that normalized iterates stay bounded by $B$. That \cref{ass:matrix-existence} guarantees  $g(u,v)$ is coercive should be compared to the observation by \citet{hunter2004mm} that \cref{ass:strong-connected} guarantees the upper compactness (a closely related concept) of the log-likelihood function \eqref{eq:log-likelihood}.
%upgrading the sub-linear convergence of \citet{altschuler2017near,leger2021gradient} to linear convergence. 
% More precisely, recall that a direct scaling exists iff \cref{ass:matrix-existence} holds \citep{bregman1967proof,pukelsheim2009iterative}. As the dual variables $(u,v)$ and the scalings $(D^0,D^1)$ are related through 
% \begin{align*}
%     u=\log d^0,\quad v=-\log d^1,
% \end{align*}
% the minimizer $(u^\ast,v^\ast)$ of the dual \eqref{eq:transformed-potential} is bounded. Strict convexity then guarantees that the updated $u,v$ always stay bounded by $B$, starting from the origin. 
In contrast, when only the weak existence condition (\cref{ass:matrix-weak-existence}) holds, no finite minimizer of $g(u,v)$ exists, so the diameter $B$ of the initial sub-level set no longer bounds normalized iterates, resulting in a slower $\mathcal O(1/t)$ convergence that corresponds precisely to the ``limit scaling'' regime of Sinkhorn's algorithm. In this case, no \emph{direct} scaling exists but the scaled matrices $\hat A^{(t)}$ still converge to a finite matrix $\hat A$ with the desired marginal distributions, and has additional zeros compared to $A$.

The regime of $\mathcal O(1/t)$ convergence also has an interpretation in the choice modeling framework. The weak existence condition \cref{ass:matrix-weak-existence}, when applied to $(A,p,q)$ constructed from a choice dataset, allows the case where some subset $S$ of items is always preferred over $[m]/S$, which implies, as observed already by the early work of \citet{ford1957solution}, that the log-likelihood function \eqref{eq:log-likelihood} is only maximized at the \emph{boundary} of the probability simplex, by shrinking  $s_j$ for $j\in S^C$ towards 0, i.e., $D^0_j \rightarrow 0$. Incidentally, \citet{bacharach1965estimating} also refers to the corresponding regime in matrix balancing as ``boundary solutions''. 

Comparing our result to previous works, we see that whenever a direct scaling exists for the canonical matrix balancing problem, Sinkhorn's algorithm converges linearly. If only a limit scaling exists, then convergence deteriorates to 
$\mathcal O(1/t)$.
\begin{corollary}
       For general non-negative matrices, Sinkhorn's algorithm converges linearly
iff $(A,p,q)$ satisfy \cref{ass:matrix-existence} and \cref{ass:matrix-uniqueness}. The convergence deteriorates to $\mathcal O(1/t)$ iff the weak existence condition \cref{ass:matrix-weak-existence} holds but \cref{ass:matrix-existence} fails.
   \end{corollary}

% Lastly, we discuss connections of our results to works in the choice modeling literature, where the Fiedler number $\lambda_{-2}(L)$ of the undirected comparison graph
% instead of $\lambda_{-2}(\mathcal{L})$ is the natural measure of algebraic connectivity. 
% In particular, we can recover the bound in \citet{vojnovic2020convergence} on the linear convergence of the MM algorithm for maximum likelihood estimation
% of Luce choice models. This is based on the following general inequality relating the Fiedler eigenvalues $\lambda_{-2}(\mathcal{L})$ and $\lambda_{-2}(L)$ of the bipartite graph $G_b$ and the comparison graph $G_c$ constructed from a non-negative matrix $A$, and may be of independent interest as well.
% \begin{proposition}
% \label{prop:Fiedler-lower-bound}

%    For any non-negative matrix $A$ with full rank,
%     \begin{align}
%     \label{eq:Fiedler-inequality}
%        \lambda_{-2}(\begin{bmatrix}\mathcal{D}({A}\mathbf{1}_{m}) & -{A}\\
% -{A}^{T} & \mathcal{D}({A}^{T}\mathbf{1}_{n})
% \end{bmatrix})/l&\geq  \frac{\lambda_{-2}(A^TA\mathbf{1}_m-A^TA)}{\max_{j}({A}^{T}{A}\mathbf{1}_{m})_{j}} 
%     \end{align}
% \end{proposition}
% This lower bound is a consequence of Cheeger's inequality. 

% In view of the reduction of minimizing the function \eqref{eq:log-barrier} to maximum likelihood estimation of the Luce choice model in \eqref{eq:log-likelihood}, our bound in \cref{thm:global-convergence}
% reduces to the same bound, modulo constants, on the convergence of MM algorithm for \eqref{eq:log-likelihood} obtained by \citet{vojnovic2020convergence}. %This also helps us analyze the computational-statistical tradeoff in \cref{sec:tradeoff}.\zq{Can also improve the analysis by directly taking the Hessian of \eqref{eq:log-likelihood}.}

\subsection{Sharp Asymptotic Rate}
\label{subsec:sharp-rate}
Having established the global convergence of Sinkhorn's algorithm when finite scalings exist, we now turn to the open problem of characterizing its asymptotic linear convergence rate. Our analysis relies on an \emph{intrinsic} orthogonality structure of Sinkhorn's algorithm instead of the auxiliary  normalization used to prove the global linear convergence. Note that unlike the global rate, which depends on $A$, the asymptotic rate now depends on the associated solution $\hat A$ (and $p,q$), as expected. 
\begin{theorem}[\textbf{Sharp Asymptotic Rate}]
\label{thm:convergence}
Suppose $(A,p,q)$ satisfy \cref{ass:matrix-existence} and \cref{ass:matrix-uniqueness}. Let $\hat{A}$
be the unique scaled matrix with marginals $p,q$. Then %for any $\epsilon>0$ there exists $T$ such that for all $t\geq T$, 
% \begin{align*}
% \|r^{(t+1)}/\sqrt{p}-\sqrt{p}\|_{2} & \leq(\lambda_\infty+\epsilon)\cdot\|r^{(t)}/\sqrt{p}-\sqrt{p}\|_{2},
% \end{align*}
\begin{align*}
\lim_{t\rightarrow \infty} \frac{\|r^{(t+1)}/\sqrt{p}-\sqrt{p}\|_{2} }{\|r^{(t)}/\sqrt{p}-\sqrt{p}\|_{2}} = \lambda_\infty,
\end{align*}
where the asymptotic linear rate of convergence $\lambda_\infty$ is
\begin{align*}
\lambda_\infty & :=\lambda_{2}(\tilde{A}\tilde{A}^{T})=\lambda_{2}(\tilde{A}^{T}\tilde{A})\\
\tilde{A} & :=\mathcal{D}(1/\sqrt{p})\cdot\hat{A}\cdot\mathcal{D}(1/\sqrt{q}),
\end{align*}
where $\lambda_{2}(\cdot)$ denotes the second largest eigenvalue. 
\end{theorem}

Intuitively, the dependence of the linear rate of convergence on the second largest eigenvalue of $\tilde{A}^T\tilde{A}$ (and $\tilde{A}\tilde{A}^T$) is due to the fact that near the optimum $\sqrt{p}$, $\tilde{A}\tilde{A}^T$ (which is the Jacobian at $\sqrt{p}$) approximates the first order change in $r^{(t)}/\sqrt{p}$. Normally, the \emph{leading} eigenvalue quantifies this change. The unique leading eigenvalue of $\tilde{A}\tilde{A}^T$ is equal to 1 with eigenvector $\sqrt{p}$, which does not imply contraction. Fortunately, using the quantity  $r^{(t)}/\sqrt{p}$
allows us to exploit the following orthogonality structure:
\begin{align*}
(r^{(t)}/\sqrt{p}-\sqrt{p})^{T}\sqrt{p} & =\sum_{i}(r_{i}^{(t)}-p_{i})=0
\end{align*}
by virtue of Sinkhorn's algorithm preserving the quantities $r^{(t)T}\mathbf{1}_{n}$
for all $t$. Thus, the residual $r^{(t)}/\sqrt{p}-\sqrt{p}$ is always \emph{orthogonal} to
$\sqrt{p}$, which is both the leading eigenvector and the fixed point of the iteration. The convergence is then controlled by the \emph{second} largest eigenvalue of $\tilde{A}\tilde{A}^T$. This proof approach echoes that of the global linear convergence result in \cref{thm:global-convergence}, where we also exploit an orthogonality condition to obtain a meaningful bound. There the bound is the second smallest eigenvalue of the Hessian, while here the bound is the second largest eigenvalue of the Jacobian. 

In the special case of $m=n$ and $p=q=\mathbf{1}$, the asymptotic rate in \cref{thm:convergence} reduces to that in \citet{knight2008sinkhorn}. Note, however, that the convergence metric is different: we use the $\ell^2$ norm $\|r^{(t)}/\sqrt{p}-\sqrt{p}\|_2$ while \citet{knight2008sinkhorn} uses an \emph{implicit} norm that measures the convergence of $D^0$ to the solution \emph{line} due to scale invariance. Our analysis exploits the orthogonality structure of Sinkhorn's algorithm and more explicitly reveals the dependence of the convergence rate on the spectral structure of the data. 

% Lastly, one may wonder how the asymptotic rate $\lambda_\infty=\lambda_{2}(\tilde{A}^T\tilde{A})$ relates to the Fiedler eigenvalue. Though one is the second largest eigenvalue while the other the second smallest, their connection becomes obvious when we define the limit Laplacian $L_\infty$ using $\tilde A$ by
% \begin{align}
% \label{eq:limit-Laplacian}
%    L_\infty:&= \mathcal D(\tilde{A}^T\tilde{A}\mathbf{1}_m)
%    - \tilde{A}^T\tilde{A}.
% \end{align}
% \begin{corollary}
% \label{cor:asymptotic-rate-fiedler} 
% The asymptotic linear rate of convergence $\lambda_\infty=\lambda_{2}(\tilde{A}^T\tilde{A})$ satisfies 
%   \begin{align*}
%      1- \lambda_\infty &= \lambda_{-2}(I-\tilde{A}^T\tilde{A})
%      \\&=\lambda_{-2}(I-\mathcal D(1/q)\hat A^T 
%   \mathcal D(1/p)
%    \hat A)
%      \\&=\lambda_{-2}(L_\infty). 
%   \end{align*}
% \end{corollary}

 % \subsection{$\tilde{\mathcal{O}}(n^2/\varepsilon)$ Runtime of Sinkhorn's Algorithm for Optimal Transport Distances}
 % In this section, we discuss an important implication of our results developed in this paper on the approximation of optimal transport distances. 

 % In recent years, Sinkhorn's algorithm has found important applications in machine learning and optimization, where it is used to approximate optimal transport (OT) distances via an entropic regularization \citep{cuturi2013sinkhorn}. Although it is practically very efficient, Sinkhorn's algorithm suffers from sub-optimal theoretical runtime of $\tilde{\mathcal{O}}(n^2/\varepsilon^2)$  for approximating OT distances \citep{dvurechensky2018computational}. A long line of recent works (see \cref{sec:related-works}) have attempted to address this by designing new algorithms that can achieve better complexities. Our results in this paper reveal that Sinkhorn's algorithm, with proper normalization, in fact \emph{already} achieves the sharp runtime complexity of $\tilde{\mathcal{O}}(n^2/\varepsilon)$ for first-order methods, thus closing the gap between theory and practice, and further justifying the use of Sinkhorn's algorithm in computational OT.

Our results in this section are relevant in several respects. First, we clarify the gap between the $\mathcal O(1/t)$ and $\mathcal O(\lambda^t)$ convergence of Sinkhorn's algorithm: the slowdown happens if and only if Sinkhorn's algorithm converges but the canonical matrix balancing problem does not have a \emph{finite} scaling $(D^0,D^1)$. This slowdown has been observed in the literature but not systematically studied. Second, 
 we settle open problems and establish the first quantitative global linear convergence result for Sinkhorn's algorithm applied to general non-negative matrices. We also characterize the asymptotic linear rate of convergence, generalizing the result of \citet{knight2008sinkhorn} but with a novel analysis. 
  Third, our analysis reveals the importance of algebraic connectivity for the convergence of Sinkhorn's algorithm. Although an important quantity in the choice modeling literature, algebraic connectivity has not been previously used to in the analysis of Sinkhorn's algorithm. The importance of algebraic connectivity for Sinkhorn's algorithm becomes less surprising once we connect it to the distributed optimization literature in \cref{sec:connections}, where it is well-known that the spectral gap of the \emph{gossip} matrix, which defines the decentralized communication network, governs the rates of convergence \citep{boyd2006randomized}.

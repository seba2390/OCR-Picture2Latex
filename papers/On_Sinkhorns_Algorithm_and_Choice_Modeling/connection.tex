\section{Graph Laplacians and Algebraic Connectivity}
\label{subsec:graph-laplacian}
In this section, we introduce the quantities central to our global linear convergence analysis, especially the \emph{graph Laplacian} matrices associated with the graphs defined by a non-negative matrix $A$ and the Fielder eigenvalues.

Given a non-negative matrix $A\in \mathbb{R}_+^{n\times m}$, we define the associated (weighted) bipartite graph $G_b$ on $V\cup U$ by the adjacency matrix $A^b \in \mathbb{R}^{(m+n)\times (m+n)}$ defined as
\begin{align*}
    A^b := \begin{bmatrix}\mathbf{0} & {A}\\
{A}^{T} & \mathbf{0}
\end{bmatrix}.	
\end{align*}
The rows of $A$ correspond to vertices in $V$
with $|V|=n$, while the columns of $A$ correspond to vertices in
$U$ with $|U|=m$, and $V\cap U=\emptyset$. The matrix $A$ here is sometimes called the \emph{biadjacency matrix} of the bipartite graph.

The matrix $A$ also defines
an \emph{undirected} ``comparison'' graph $G_c$ on $m$ items. This is most easily understood when $A$ is binary and we can associate it with the participation matrix of a choice dataset, but the definition below is more general. Define the adjacency matrix $A^c \in \mathbb{R}^{m\times m}$ by
\begin{align*}
{A^c}_{jj'} & =\begin{cases}
0 & j=j'\\
(A^{T}A)_{jj'} & j\neq j',
\end{cases}
\end{align*}
If $A$ is a binary participation matrix associated with a choice dataset, then there is a (weighted) edge in $G_{c}$ between items $j$ and $j'$
if and only the two appear in some choice set together, with the edge
weight equal to the number of times of their co-occurrence. This undirected comparison graph $G_c$ is not the same as the directed comparison graph in \cref{ass:strong-connected}, since it does not encode the \emph{choice} of each observation. However, it is also an important object in choice modeling. For example, the uniqueness condition in \cref{ass:weak-connected} for choice maximum likelihood estimation has a concise graph-theoretic interpretation as it is a requirement that $G_c$ be connected.

For a (generic) undirected graph $G$ with adjacency matrix $M$, the graph Laplacian matrix (or simply the Laplacian) is defined as $L(M):=\mathcal{D}(M\mathbf{1})-M$, where recall $\mathcal{D}$ is the diagonalization of a vector. The graph Laplacian $L(M)$ is always positive semidefinite as a result of the Gershgorin circle theorem, since $L(M)$ is diagonally dominant  with positive diagonal and non-positive off-diagonals. Moreover, the Laplacian always has $\mathbf{1}$ in its null space.

For the graphs $G_b,G_c$, their Laplacians are  given respectively by 
\begin{align}
    \label{eq:Laplacians}
\mathcal{L}:&=L(A^b)=\begin{bmatrix}\mathcal{D}({A}\mathbf{1}_{m}) & -{A}\\
-{A}^{T} & \mathcal{D}({A}^{T}\mathbf{1}_{n})
\end{bmatrix} \\L:&=L(A^c)=A^TA\mathbf{1}_m-A^TA,
\end{align}
where we can
verify that for the comparison graph $G_c$, its Laplacian $L$ satisfies
\begin{align*}
L=A^c\mathbf{1}_{m}-A^c & =A^{T}A\mathbf{1}_{m}-A^{T}A.
\end{align*}
The graph Laplacian $\mathcal{L}$ based on $A^b$ and $L$ based on $A^c$ are closely connected through the identity
\begin{align*} (A^{b})^{2}&=\begin{bmatrix}AA^{T} & 0\\
0 & A^{T}A
\end{bmatrix},
\end{align*}
which implies that $L$ is the lower right block of the graph Laplacian $\mathcal{D}((A^{b})^{2}\mathbf{1}_{m+n})-(A^{b})^{2}$. Moreover, $L$ plays a central role in works on the statistical and computational efficiency in choice modeling \citep{shah2015estimation,seshadri2020learning,vojnovic2020convergence}.

An important concept in spectral graph theory is the \emph{algebraic connectivity} of a graph, quantified by the second smallest eigenvalue $\lambda_{-2}$ of the graph Laplacian matrix, also called the Fiedler eigenvalue \citep{fiedler1973algebraic,spielman2007spectral}.
% The Fiedler eigenvalue $\lambda_{-2}$ features prominently in Cheeger's inequality,
% \begin{align}
% \label{eq:Cheeger}
%   \frac{h^2(G)}{2\max_j(M\mathbf{1})_j}   \leq \lambda_{-2}(\mathcal{D}(M\mathbf{1})-M) \leq  2h(G),
% \end{align}
% where $h(G)\geq0$ is the Cheeger constant, positive iff $G$ is connected.
Intuitively, Fiedler eigenvalue quantifies how well-connected a graph is in terms of how many edges need to be removed for the graph to become disconnected. It is well-known that the multiplicity of the smallest eigenvalue of the graph Laplacian, which is 0, describes the number of connected components of a graph. The uniqueness condition for matrix balancing in \cref{ass:matrix-uniqueness} therefore guarantees that the Fiedler eigenvalue of $G_b$ is positive: $\lambda_{-2}(\mathcal{L}) >0$. This property is important for our results, since $\lambda_{-2}(\mathcal{L})$ quantifies the \emph{strong} convexity of the potential function and hence the linear convergence rate of Sinkhorn's algorithm.

\section{Further Connections to Choice Modeling and Optimization}
\label{sec:connections}
In this section, we demonstrate that our matrix balancing formulation \eqref{eq:equation-system} of the maximum likelihood problem \eqref{eq:log-likelihood} provides a unifying perspective on many existing works on choice modeling, and establishes interesting connections to distributed optimization as well. Throughout, Sinkhorn's algorithm will serve as the connecting thread. In particular, it reduces algebraically to the algorithms in \citet{zermelo1929berechnung,dykstra1956note,ford1957solution,hunter2004mm,maystre2017choicerank} in their respective choice model settings. This motivates us to provide an interpretation of Sinkhorn's algorithm as a ``minorization-maximization'' (MM) algorithm \citep{lange2000optimization}. Moreover, Sinkhorn's Algorithm is also related to the ASR algorithm of \citet{agarwal2018accelerated} for choice modeling, as they can both be viewed as message passing algorithms in distributed optimization \citep{balakrishnan2004polynomial}. Last but not least, we establish a connection between Sinkhorn's algorithm and the well-known BLP algorithm of \citet{berry1995automobile}, widely used in economics to estimate consumer preferences from data on market shares. 

\subsection{Pairwise Comparisons}
The same algorithmic idea in many works on pairwise comparisons appeared as early as \citet{zermelo1929berechnung}. For example,
\citet{dykstra1956note} gives the following update formula: 
\begin{align}
\label{eq:pairwise}
s_{j}^{(t+1)} & =W_{j}/\sum_{j\neq k}\frac{C_{jk}}{s_{j}^{(t)}+s_{k}^{(t)}},
% s_{j}^{(t+1)} & =W_{j}\cdot\left[\sum_{j\neq k}\frac{C_{jk}}{s_{j}^{(t)}+s_{k}^{(t)}}\right]^{-1},
\end{align}
 where again $W_{j}=|\{i\mid (j,S_i)\}|$ is the number of times
item $j$ is chosen (or ``wins''), and $C_{jk}$ is the number of comparisons between $j$
and $k$. \cref{ass:strong-connected} guarantees $C_{jk}>0$ for any $j,k$.  \citet{zermelo1929berechnung}
proved that under this assumption
$s^{(1)},s^{(2)},\dots$ converge to the unique maximum likelihood estimator,
and the sequence of log-likelihoods $\ell(s^{(1)}),\ell(s^{(2)}),\dots$
is monotone increasing. A cyclic version of \eqref{eq:pairwise} appeared in \citet{ford1957solution} with an independent proof of convergence. One can verify that by aggregating choice sets $S_i$ in \eqref{eq:scaling-iteration} over pairs of objects, it reduces to \eqref{eq:pairwise}. However, \eqref{eq:pairwise} as is written does not admit a matrix balancing formulation. A generalization of the algorithm of \citet{zermelo1929berechnung,ford1957solution,dykstra1956note} for pairwise comparison to ranking data was not achieved until the influential works of \citet{lange2000optimization} and \citet{hunter2004mm}. 
\subsection{MM Algorithm of \citet{hunter2004mm} for Ranking
Data} 
Motivated by the observation in \citet{lange2000optimization} that \eqref{eq:pairwise} is an instance of an minorization-maximization (MM) algorithm, the seminal work of \citet{hunter2004mm} proposed the general approach of solving ML estimation of choice models via MM algorithms, which relies on the inequality 
\begin{align*}
-\log x & \geq1-\log y-(x/y)
\end{align*}
to construct a lower bound (minorization) on the log-likelihood that has an explicit maximizer (maximization), and iterates between the two steps. \citet{hunter2004mm} develops such an algorithm for the Plackett--Luce
model for ranking data and proves its monotonicity and convergence.

Given $n$ partial rankings, where the $i$-th partial ranking on $l_{i}$ objects is indexed by $a(i,1)\rightarrow a(i,2)\rightarrow \cdots \rightarrow a(i,l_{i})$, the MM algorithm of \citet{hunter2004mm} takes the form 
\begin{align}
\label{eq:mm}
s_{k}^{(t+1)} & =\frac{w_{k}}{\sum_{i=1}^{n}\sum_{j=1}^{l_{i}-1}\delta_{ijk}[\sum_{j'=j}^{l_{i}}s_{a(i,j')}^{(t)}]^{-1}},
\end{align}
 where $\delta_{ijk}$ is the indicator that item $k$ ranks no better
than the $j$-th ranked item in the $i$-th ranking, and $w_{k}$ is the number of
rankings in which $k$ appears but is not ranked last. 
\begin{proposition}
\label{lem:mm}
Sinkhorn's algorithm applied to the ML estimation of the Plackett--Luce model is algebraically equivalent to \eqref{eq:mm}. 
\end{proposition}
Therefore, Sinkhorn's algorithm applied to the ML estimation of the Plackett--Luce model reduces algebraically to the MM algorithm of \citet{hunter2004mm}. However, \cref{alg:scaling} applies to more general choice models with minimal or no change, while the approach in \citet{hunter2004mm} requires deriving the minorization-majorization step for every new optimization objective. This was carried out, for example, in \citet{maystre2017choicerank} for a network choice model. We show in \cref{prop:choicerank} that their ChoiceRank algorithm is also a special case of (regularized) Sinkhorn's algorithm. From a computational perspective, even when algorithms are equivalent algebraically, their empirical performance can vary drastically depending
on the particular implementation. Another advantage of Sinkhorn's algorithm is that it computes \emph{all}
entries simultaneously through vector and matrix operations, while
the analytical formula in \eqref{eq:mm} is hard to parallelize. This distinction is likely behind
the discrepancy in \cref{sec:empirics} between our experiments and those in \citet{maystre2015fast},
who conclude that the MM version \eqref{eq:mm} is slower in terms of wall clock time than their Iterative Luce Spectral Ranking (I-LSR) algorithm for the Plackett--Luce model on $k$-way partial ranking data. 

\subsection{Markov Steady State Inversion and Network Choice}
\label{subsec:steady-state}
Our work is related to the works of \citet{kumar2015inverting,maystre2017choicerank} on Markov chains on graphs, where transition matrices are parameterized by node-dependent scores prescribed by Luce's choice axiom. More precisely, given a directed graph $G=(V,E)$ and $N^\out_j, N^\inn_j \subseteq V$ the neighbors with edges going out from and into $j\in V$, and a target stationary distribution $\pi$, the (unweighted) steady state inversion problem of \citet{kumar2015inverting} seeks scores $s_j$ such that the transition matrix $T_{j,k}=\frac{s_k}{\sum_{k'\in N^\out_j}s_{k'}}$ has the desired stationary distribution $\pi$. Their Theorem 13 shows that a bipartite version of this problem is equivalent to solving the ML estimation conditions \eqref{eq:optimality} of the choice model. Furthermore, one can verify that their bipartite inversion problem has the same form as \eqref{eq:bridge} in our paper, with the bipartite graph defined using $A$. Their existence condition (termed ``consistency'') is equivalent to \cref{ass:matrix-weak-existence}(a) \citep{menon1968matrix} for the matrix balancing problem. Despite these connections, the key difference in our work is the reformulation of \eqref{eq:optimality} as one involving diagonal scalings of rows and columns of $A$, which was absent in \citet{kumar2015inverting}. Consequently, they proposed a different algorithm instead of applying Sinkhorn's algorithm. 

Building on \citet{kumar2015inverting}, \citet{maystre2017choicerank} consider a similar Markov chain on $(V,E)$, where now for each edge $(j,k) \in E$ one observes a finite \emph{number} $c_{jk}$ of transitions along it, and take a maximum likelihood approach to estimate the scores $s_j$.  They show that, as one might expect, the steady state inversion problem of \citet{kumar2015inverting} is the asymptotic version of the ML estimation problem in their network choice model. 

An additional contribution of \citet{maystre2017choicerank} is the regularization of the inference problem via a Gamma prior on $s_j$'s, which eliminates the necessity of any assumptions on the choice dataset such as \cref{ass:strong-connected}. They then follow the proposal of \citet{hunter2004mm} and develop an MM algorithm for maximum likelihood estimation called ChoiceRank, the unregularized version of which can be written as follows:
\begin{align}
    \label{eq:choicrank}
    s_j^{(t+1)} = \frac{c_j^\inn}{\sum_{k\in N_j^\inn} \gamma_k^{(t)}}, \gamma_j^{(t)}=\frac{c_j^\out}{\sum_{k\in N_j^\out}s_k^{(t)}},
\end{align}
where $c_j^\inn=\sum_{k\in N_j^\inn}c_{kj}$ and $c_j^\out=\sum_{k\in N_j^\out}c_{jk}$ are the total number of observed transitions into and out of $j\in V$. 
\begin{proposition}
    \label{prop:choicerank}
   The network choice model of \citet{maystre2017choicerank} is a special case of the choice model \eqref{eq:model}, and  Sinkhorn's algorithm applied to this case reduces to an iteration algebraically equivalent to \eqref{eq:choicrank}.
\end{proposition}
We also explore the regularization approach of \citet{maystre2017choicerank} in \cref{subsec:regularization} and demonstrate that Sinkhorn's algorithm can easily accommodate this extension, resulting in a regularized version of Sinkhorn's algorithm for matrix balancing that \emph{always} converges. This is given in \cref{alg:regularized}. Once again, insights from choice modeling yield useful improvements in matrix balancing.

\subsection{Sinkhorn's Algorithm as an MM Algorithm}
\label{sec:sinkhorn-MM}
That Sinkhorn's algorithm reduces to MM algorithms when applied to various choice models is not a coincidence. 
In this section, we establish the connection between choice modeling
and matrix balancing through an optimization perspective. This connection
provides an interesting interpretation of Sinkhorn's algorithm
as optimizing a dominating function, i.e., an MM algorithm. See \citet{lange2000optimization,lange2016mm} for a discussion of the general correspondence between block
coordinate descent algorithms and MM algorithms.

First, we discuss the connection between the log-likelihood function
\eqref{eq:log-likelihood} and the dual potential function \eqref{eq:log-barrier} when $(A,p,q)$ corresponds to a choice dataset. Consider maximizing the negative
dual potential function 
\begin{align*}
h(d^{0},d^{1}):=-g(d^{0},d^{1}) & =\sum_{j=1}^{m}q_{j}\log d_{j}^{0}+\sum_{i=1}^{n}p_{i}\log d_{i}^{1}-(d^{1})^{T}Ad^{0}.
\end{align*}
For each fixed $d^{0}$, the function is concave in $d^{1}$, and
maximization with respect to $d^{1}$ yields first order conditions
\begin{align*}
d^{1} & =p/(Ad^{0}).
\end{align*}
Substuting this back into $h(d^{0},d^{1})$, we obtain 
\begin{align*}
f(d^{0}):=h(d^{0},p/(Ad^{0})) & =\sum_{j=1}^{m}q_{j}\log d_{j}^{0}+\sum_{i=1}^{n}p_{i}\log(\frac{p_{i}}{(Ad^{0})_{i}})-\sum_{i}p_{i}\\
 & =\sum_{j=1}^{m}q_{j}\log d_{j}^{0}-\sum_{i=1}^{n}p_{i}\log(Ad^{0})_{i}+\sum_{i}p_{i}\log p_{i}-\sum_{i}p_{i}.
\end{align*}
If $A$ is a valid participation matrix for a choice dataset and $p,q$
are integers, we can identify $(A,p,q)$ with a choice dataset. Each
row of the participation matrix $A$ is the indicator vector of choice
set $S_{i}$, and $d_{j}^{0}$ is the quality score. In this
case $(Ad^{0})_{i}=\sum_{k\in S_{i}}d_{k}^{0}$, so that 
\begin{align*}
\sum_{j=1}^{m}q_{j}\log d_{j}^{0}-\sum_{i=1}^{n}p_{i}\log(Ad^{0})_{i} & =\sum_{j=1}^{m}q_{j}\log d_{j}^{0}-\sum_{i=1}^{n}p_{i}\sum_{k\in S_{i}}d_{k}^{0}=\ell(d^{0}).
\end{align*}

It then follows that
\begin{align*}
\min_{d^{0},d^{1}}g(d^{0},d^{1})\Leftrightarrow\max_{d^{0},d^{1}}h(d^{0},d^{1})\Leftrightarrow\max_{d^{0}}\max_{d^{1}}h(d^{0},d^{1})\Leftrightarrow\max_{d^{0}}f(d^{0})\Leftrightarrow\max_{d^{0}}\ell(d^{0}),
\end{align*}
so that minimizing the potential function $g$ is equivalent to maximizing
the log-likelihood function $\ell$. Moreover, the first order condition of maximizing $h$ with respect to $d^1$ is 
$d^0=q/(A^Td^1)$, which when $(A,p,q)$ is identified with a choice dataset reduces to 
\begin{align*}
    q_j =\sum_{i\mid j\in S_i}p_i \frac{d^0_j}{\sum_{k\in S_i}d^0_k},
\end{align*}
which is the optimality condition \eqref{eq:optimality} of the choice model.

Next, given $d^{0(t)}$ the estimate of $d^{0}$ after the
$t$-th iteration, define the function 
\begin{align*}
f(d^{0}\mid d^{0(t)}):=h(d^{0},p/(Ad^{0(t)})) & =\sum_{j=1}^{m}q_{j}\log d_{j}^{0}+\sum_{i=1}^{n}p_{i}\log\frac{p}{Ad^{0(t)}}-\frac{p_{i}}{(Ad^{0(t)})_{i}}(Ad^{0})_{i}.
\end{align*}
We can verify that 
\begin{align*}
f(d^{0(t)}\mid d^{0(t)}) & =f(d^{0(t)})\\
f(d^{0}\mid d^{0(t)}) & \leq f(d^{0}),
\end{align*}
 so that $f(d^{0}\mid d^{0(t)})$ is a valid minorizing function of
$f(d^{0})$ \citep{lange2000optimization} that guarantees the ascent property $f(d^{0(t+1)})\geq f(d^{0(t+1)}\mid d^{0(t)})=\max_{d^{0}}f(d^{0}\mid d^{0(t)})\geq f(d^{0(t)}\mid d^{0(t)})=f(d^{0(t)})$.
The update in the maximization step
\begin{align*}
d^{0(t+1)}=\arg\max_{d^{0}}f(d^{0}\mid d^{0(t)}) & =q/A^{T}\frac{p}{Ad^{0(t)}}
\end{align*}
 is precisely one full iteration of Sinkhorn's algorithm. Note that this interpretation of Sinkhorn's algorithm does not require $A$ to be binary, and $p,q$ to be integers.

On the other hand, using the property $-\ln x\geq1-\ln y-(x/y)$,
we can \emph{directly} construct a minorizing function of $\ell$
by 
\begin{align*}
\ell(d^{0})=\sum_{j=1}^{m}q_{j}\log d_{j}^{0}-\sum_{i=1}^{n}p_{i}\log(Ad^{0})_{i} & \geq\sum_{j=1}^{m}q_{j}\log d_{j}^{0}+\sum_{i=1}^{n}p_{i}(-\frac{(Ad^{0})_{i}}{(Ad^{0(t)})_{i}}-\log(Ad^{0(t)})_{i}+1)=\ell(d^{0}\mid d^{0(t)}),
\end{align*}
 where $\ell(d^{0}\mid d^{0(t)})$ is a valid minorizing function
of $\ell$. Maximizing $\ell(d^{0}\mid d^{0(t)})$ with respect to
$d^{0}$, the update in the maximization step is
\begin{align*}
d_{j}^{0(t+1)} & =q_{j}/\sum_{i\mid j\in S_i}\frac{p_{i}}{(Ad^{0(t)})_{i}}
\end{align*}
 which again is one full iteration of Sinkhorn's algorithm applied to the Luce choice model. Moreover,
\begin{align*}
\ell(d^{0}\mid d^{0(t)})+\sum_{i}p_{i}\log p_{i}-\sum_{i}p_{i} & =\sum_{j=1}^{m}q_{j}\log d_{j}^{0}+\sum_{i=1}^{n}p_{i}(-\frac{(Ad^{0})_{i}}{(Ad^{0(t)})_{i}}-\log(Ad^{0(t)})_{i}+1)+\sum_{i}p_{i}\log p_{i}-\sum_{i}p_{i}\\
 & =\sum_{j=1}^{m}q_{j}\log d_{j}^{0}+\sum_{i=1}^{n}p_{i}(-\frac{(Ad^{0})_{i}}{(Ad^{0(t)})_{i}}+\log\frac{p_{i}}{(Ad^{0(t)})_{i}})\\
 & =f(d^{0}\mid d^{0(t)}).
\end{align*}
 Therefore, the minorizing function $\ell(d^{0}\mid d^{0(t)})$ constructed
using $-\ln x\geq1-\ln y-(x/y)$ for the log-likelihood and the minorizing
function $f(d^{0}\mid d^{0(t)})$ constructed for $\max_{d^{1}}h(d^{0},d^{1})$
are identical modulo a constant $\sum_{i}p_{i}\log p_{i}-\sum_{i}p_{i}$.
Sinkhorn's algorithm is in fact the MM algorithm corresponding to both minorizations. However, the perspective using $f(d^{0}\mid d^{0(t)})$ is more general since it applies to general $(A,p,q)$ as long as they satisfy Assumptions \cref{ass:matrix-existence} and \cref{ass:matrix-uniqueness}, whereas the MM algorithm based on $\ell(d^{0}\mid d^{0(t)})$ is designed for choice dataset, so requires $A$ to be binary.

\subsection{ Sinkhorn's Algorithm and Distributed Optimization} 
We now shift our focus to algorithms in distributed optimization, where Sinkhorn's algorithm can be interpreted as a message passing/belief propagation algorithm \citep{balakrishnan2004polynomial}. We start by observing a connection to the ASR algorithm for estimating Luce choice models \citep{agarwal2018accelerated}, which returns the same approximate ML estimators as the RC \citep{negahban2012iterative} and LSR \citep{maystre2015fast} algorithms, but has provably faster convergence. 

Consider the bipartite graph $G_b$ defined by $A$ in \cref{subsec:graph-laplacian}, which consists of choice set nodes $V$ on one hand and item nodes $U$ on the other, where there is an edge between $i\in V$ and $j\in U$ if and only if $j\in S_i$. \citet{agarwal2018accelerated} provide the following message passing interpretation of ASR on the bipartite graph: at every iteration, the item nodes send a ``message'' to their
neighboring choice set nodes consisting of each item node's current estimate of their own $s_j$; the choice set nodes then aggregate the messages they receive by summing up these estimates, and then sending back the sums to their neighboring item nodes. The item nodes use these sums to update estimates of their own $s_j$. \citet{agarwal2018accelerated} show that since the ASR algorithm is an instance of the message passing algorithm, it can be implemented in a distributed manner.% similar to the parallelization capability of Sinkhorn's algorithm. 

We now explain how Sinkhorn's algorithm is another instance of the message passing algorithm described above. Recall that $d^0$ is identified with the $s_j$'s in the Luce choice model, so that $d^{1} \leftarrow p/(Ad^{0})$ precisely corresponds to item nodes ``passing'' their current estimates to set nodes, which then sum up the received estimates and then take the weighted \emph{inverse} of this sum. Similarly, $d^0 \leftarrow q/(A^{T} d^{1})$ corresponds to choice set nodes passing their current estimates of $d^1$ back to item nodes, which then sum up the received messages and take the weighted inverse as their updated estimates of $s_j$. The main difference with ASR lies in how each item node $j$ updates its estimate of $s_j$ based on the messages it receives from neighboring set nodes. In Sinkhorn's algorithm, the update to $s_j$ is achieved by dividing $p$ by a weighted average of the \emph{inverse} of summed messages $1/\sum_{k\in S_{i}}s_{k}^{(t)}$:
\begin{align*}
  s_j^{(t+1)} \leftarrow  q_j/(A^{T} d^{1})_j=W_j/\sum_{i\mid j\in S_{i}}\frac{R_i}{\sum_{k\in S_{i}}s_{k}^{(t)}},
\end{align*}
whereas in ASR, the update is an average of the summed messages $\sum_{k\in S_{i}}s_{k}^{(t)}$ without taking their inverses first: 
\begin{align*}
    s^{(t+1)}_j \leftarrow  \frac{1}{\sum_{i\mid j\in S_{i}} R_i} \sum_{i\mid j \in S_i}  W_{ji} \sum_{k\in S_{i}}s_{k}^{(t)},
\end{align*}
where $W_{ji}$ is the number of times item $j$ is selected from all observations having choice set $S_i$, with $\sum_i W_{ji} = W_j$.

From another perspective, the two algorithms arise from different \emph{moment} conditions. While Sinkhorn's algorithm is based on the optimality condition \eqref{eq:optimality}, ASR is based on the condition
\begin{align*}
    \sum_{i\mid j\in S_{i}} R_i = \sum_{i\mid j \in S_i}  W_{ji}/\frac{s_j}{\sum_{k\in S_{i}}s_{k}},
\end{align*}
which results in an approximate instead of exact MLE. 

The message passing interpretation also provides further insights on the importance of algebraic connectivity to the convergence rate of Sinkhorn's algorithm. Graph theoretic conditions like \cref{ass:strong-connected} are related to network flow and belief propagation, and characterize how fast information can be distributed across the bipartite network with the target distributions $p,q$. It is well-known that convergence of distributed algorithms on networks depends critically on the network topology through the spectral gap of the associated averaging matrix. We can understand \cref{thm:convergence} on the asymptotic convergence rate of Sinkhorn's algorithm as a result of this flavor, although a precise equivalence is left for future works. 

\subsection{The Berry--Levinsohn--Pakes Algorithm}
Last but not least, our work is also closely related to the economics literature that studies consumer behavior based on discrete choices \citep{mcfadden1973conditional,mcfadden1978modelling,mcfadden1981econometric,berry1995automobile}. Here we discuss the particular connection with the work of Berry,
Levinsohn, and Pakes \cite{berry1995automobile}, often referred to as BLP. To estimate consumer preferences over automobiles across different markets (e.g., geographical), they propose a random utility (RUM) model indexed by individual $i$, product
$j$, and market $t$:
\begin{align*}
U_{ijt} & =\beta_{i}^{T}X_{jt}+\theta_{jt}+\epsilon_{ijt},
\end{align*}
 where $\theta_{jt}$ is an unobserved product characteristic, such as the overall popularity of certain types of cars in different regions, and $\epsilon_{ijt}$
are \emph{i.i.d.} double exponential random variables.
% \begin{align*}
% f(\epsilon) & =\exp(-\epsilon-\exp(-\epsilon))
% \end{align*}
The individual-specific coefficient $\beta_{i}$ is random with 
\begin{align*}
\beta_{i} & =Z_{i}^T\Gamma+\eta_{i}\\
\eta_{i}\mid Z_{i} & \sim\mathcal{N}(\beta,\Sigma),
\end{align*}
and the observations consist of \emph{market shares} $\hat{p}_{jt}$ of each
product $j$ in market $t$ and observable population characteristics $Z_{i}$ in each
market. Given a model with fixed $\beta,\Gamma,\Sigma$ and observations, the task is to estimate $\theta_{jt}$. 

For every value of $\theta_{jt}$, we can compute, or simulate if necessary, the \emph{expected} market shares $p_{jt}$, which is the likelihood of product $j$ being chosen in market $t$. For example, in the special case that $\beta,\Gamma,\Sigma \equiv 0$ and $\exp(\theta_{jt})\equiv s_{j}$ for all
$j,t$, i.e., (perceived) product characteristic does not vary across
markets, the expected market share reduces to the familiar formula
\begin{align*}
p_{jt} & =\frac{\exp(\theta_{jt})}{\sum_{k}\exp(\theta_{kt})}=\frac{s_{j}}{\sum_{k}s_{k}}.
\end{align*}
The generalized method of moments (GMM) approach of \citet{berry1995automobile} is to find $\theta_{jt}$ such that $p_{jt}=\hat{p}_{jt}$, i.e., the implied expected market share equals the observed share. Recall the similarity to the optimality condition \eqref{eq:optimality} of the Luce choice model. BLP propose the iteration 
\begin{align}
\label{eq:blp}
\theta_{jt}^{(m+1)} & =\theta_{jt}^{(m)}+\log\hat{p}_{jt}-\log p_{jt}(\theta^{(m)},\beta,\Gamma,\Sigma),
\end{align}
 and show that it is a \emph{contraction mapping}, whose fixed point is the desired estimates of $\theta_{jt}$. 
\begin{proposition}
    \label{prop:BLP}
    When $\beta,\Gamma,\Sigma \equiv 0$ and $\exp(\theta_{jt})\equiv s_{j}$, the GMM condition of BLP on market shares is equivalent to the optimality condition \eqref{eq:optimality} for a Luce choice model where all alternatives are available in every observation. Furthermore, the BLP algorithm is equivalent to Sinkhorn's algorithm in this model.
\end{proposition}
For a more detailed correspondence, see \citet{bonnet2022yogurts}. Importantly, \cref{prop:BLP} does not imply that the Luce choice model and Sinkhorn's algorithm is a strict special case of the BLP framework. The key difference is that BLP, and most discrete choice models in econometrics, implicitly assumes that the entire set of alternatives is always available in each observation. This assumption translates to a participation matrix $A$ in \eqref{eq:equation-system} that has 1's in all entries. In this setting, the MLE of $s_j$ is simply the empirical winning frequencies. %Note that \cref{ass:strong-connected} may still be violated in this case, highlighting again the gap between what is required for the ML estimation problem and by the matrix scaling problem.
On the other hand, while the Luce choice model allows different choice sets $S_i$ across observations, they do not include covariate information on the alternatives or decision makers, which is important in discrete choice modeling. One can reconcile this difference by relabeling alternatives with different covariates as \emph{distinct} items, and we leave investigations on further connections in this direction to future works.
\section{Conclusion}\label{sec:con}
\setParDis
In this paper, we present an efficient approach for generating a specified person in new scenes with only one her/his facial image.
The novel $M^2$ ID encoder is proposed to project the identity into multiple word embeddings with multi-scale ID-aware features for the accurate representation of the human in one fast-forward pass with negligible time costs. Besides, the self-augmented editability learning mechanism endows the T2I model with the ability to achieve high editability.
Extensive quantitative and qualitative experiments demonstrate the effectiveness of the proposed methods.
\setParDef
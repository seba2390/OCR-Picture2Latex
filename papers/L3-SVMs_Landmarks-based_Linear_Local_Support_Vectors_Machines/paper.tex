\pdfoutput=1

\documentclass[10pt,letterpaper]{article}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{lmodern}
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xspace}
\usepackage{authblk}

\usepackage{graphicx}
\graphicspath{{pictures/}}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{bm}
\usepackage[margin=1in]{geometry}

\usepackage[font=small]{caption}
\usepackage{subcaption}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{fp}
\usetikzlibrary{bayesnet}

\theoremstyle{plain}
\newtheorem{thm}{Theorem}[section]
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem*{cor}{Corollary}

\theoremstyle{definition}
\newtheorem{defn}{Definition}[section]
\newtheorem{conj}{Conjecture}[section]
\newtheorem{exmp}{Example}[section]

\theoremstyle{remark}
\newtheorem*{rem}{Remark}
\newtheorem*{note}{Note}

\DeclareMathOperator*{\argmin}{arg\,min}
\newcommand{\normk}[1] {\left\| #1 \right\|_k}
\newcommand{\norm}[1] {\left\| #1 \right\|}
\newcommand{\abs}[1] {| #1 |}
\newcommand{\normtwo}[1] {\left\| #1 \right\|_2}
\newcommand{\normf}[1] {\left\| #1 \right\|_{\mathcal{F}}}
\newcommand{\frob}[1]{\|#1\|_\mathcal{F}}
\newcommand{\sumz}{\sum_{z=1}^Z}
\newcommand{\sumi}{\sum_{i=1}^m}
\newcommand{\sump}{\sum_{p=1}^L}
\newcommand{\sumiz}[1]{\sum_{#1=1 | z_{#1}=z}^m}
\newcommand{\sumik}[1]{\sum_{#1=1 | k_{#1}=k}^m}
\newcommand{\sumk}{\sum_{k=1}^L}
\newcommand{\mul}[1] {{\mu}_{\mkern-0.66\thinmuskip\mathcal{L}} (#1) }

\newcommand{\wrt}{w.r.t.\@\xspace}

\newcommand\todo[1]{\textcolor{red}{#1}}
\renewcommand\todo[1]{}

\newcommand{\twocol}[2]{
    \begin{tabular}{cc}
        #1 & #2 
    \end{tabular}
}

\newcommand{\landSVM}{L$^3$-SVMs\xspace}

\author[1]{Zantedeschi Valentina \\
\href{mailto:valentina.zantedeschi@univ-st-etienne.fr}{valentina.zantedeschi@univ-st-etienne.fr}}
\author[1]{\\Emonet R\'emi\\
\href{mailto:remi.emonet@univ-st-etienne.fr}{remi.emonet@univ-st-etienne.fr}}
\author[1]{\\Sebban Marc\\
\href{mailto:marc.sebban@univ-st-etienne.fr}{marc.sebban@univ-st-etienne.fr}}

\affil[1]{
Univ Lyon, UJM-Saint-Etienne, CNRS, Institut d Optique Graduate School, Laboratoire Hubert Curien UMR 5516, F-42023, SAINT-ETIENNE, France
}

\title{\landSVM: \\Landmarks-based Linear Local Support Vector Machines}
\date{}

\begin{document}

\maketitle


\begin{abstract}
For their ability to capture non-linearities in the data and to scale to large training sets, local Support Vector Machines (SVMs) have received a special attention during the past decade. 
In this paper, we introduce a new local SVM method, called \landSVM, which clusters the input space, carries out dimensionality reduction by projecting the data on landmarks, and jointly learns a linear combination of local  models. Simple and effective, our algorithm is also theoretically well-founded. Using the framework of Uniform Stability, we show that our SVM formulation comes with generalization guarantees on the true risk. 
The experiments based on the simplest configuration of our model (i.e. landmarks randomly selected, linear projection, linear kernel) show that \landSVM is very competitive \wrt the state of the art and opens the door to new exciting  lines of research.
\end{abstract}
\input{intro}
\input{method}
\input{stability}
\input{expe}
\input{concl}
\input{annexes}

\bibliographystyle{ieee}
\bibliography{paper}
\end{document}

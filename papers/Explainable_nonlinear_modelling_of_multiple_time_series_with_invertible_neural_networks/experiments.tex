\section{Experiments}

The experiments described in this section, intended to validate the proposed method, can be reproduced with the Python code which is available in GitHub at \url{https://github.com/uia-wisenet/NonlinearVAR}

A set of $N=10$ sensors is simulated, and an underlying VAR process of order $P = 2$. The VAR parameter matrices are generated by drawing each weight i.i.d from a standard Gaussian distribution. Matrices $\{A^{(p)}\}_{p=0}^P$ are  scaled down afterwards by a constant that ensures that the VAR process is stable \cite{lutkepohl2005}. 


\begin{figure}[h]
\vspace{-0.5cm}
\centering
\includegraphics[width=\textwidth]{figures/N10_40epochs.png}
\caption{Comparison of the proposed method (M=5, P=3) vs. a linear VAR model.% (in blue) 
}
\label{fig:nl_vs_linear4}
\end{figure}


The underlying process samples $\{y[t]\}_{t=1}^T$, where T = 1000, are generated as a realization of the aforementioned VAR process, and the simulated sensor observed values $\{z[t]\}_{t=1}^T$ are obtained as the output of nonlinear observation functions that are also randomly generated. %TODO: explain how

% The values of all parameters involved in the experiments are listed in the captions and legends of the figures.

%In the experiments throughout this section, unless otherwise stated, \revvv{in each MC iteration the following random variables are generated:
%\begin{myitemize}
	%\myitem i) a binary matrix (adjacency of a random graph), 
	%\myitem ii) a set of VAR parameters having the generated matrix as support, and	
	%\myitem iii) a realization of multivariate signals governed by the VAR parameters.
	%\myitem For each signal realization, the proposed algorithms are run and their output is assessed via the metrics defined above, and expectations in (\ref{eq:nmsd}--\,\ref{eq:NMSE}) are taken with respect to realizations of the
	%graph, VAR parameters, and innovation process $\bm u[t]$.
%\end{myitemize}


The proposed nonlinear VAR estimator is analyzed in a stationary setting, and compared to the VAR estimator of the same order. The training and test curves are shown in Fig. \ref{fig:nl_vs_linear4}. It can be observed that, despite the overfitting, the proposed nonlinear model can explain the time series data with significantly lower error.




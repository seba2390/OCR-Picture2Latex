\begin{abstract}
Most previous studies aim at extracting events from a single sentence, while document-level event extraction still remains under-explored.
In this paper, we focus on extracting event arguments from an entire document, which mainly faces two critical problems:
a) the long-distance dependency between trigger and arguments over sentences;
b) the distracting context towards an event in the document.
To address these issues, we propose a \textbf{T}wo-\textbf{S}tream \textbf{A}bstract meaning \textbf{R}epresentation enhanced extraction model (\textbf{\modelname}).
\modelname encodes the document from different perspectives by a two-stream encoding module, to utilize local and global information and lower the impact of distracting context.
Besides, \modelname introduces an AMR-guided interaction module to capture both intra-sentential and inter-sentential features, based on the locally and globally constructed AMR semantic graphs.
An auxiliary boundary loss is introduced to enhance the boundary information for text spans explicitly.
Extensive experiments illustrate that \modelname outperforms previous state-of-the-art by a large margin, with $2.54$ F1 and $5.13$ F1 performance gain on the public RAMS and WikiEvents datasets respectively, showing the superiority in the cross-sentence arguments extraction.
We release our code in \url{https://github.com/PKUnlp-icler/TSAR}.
\end{abstract}


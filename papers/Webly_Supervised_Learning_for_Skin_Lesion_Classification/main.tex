% This is based on the LLNCS.DEM the demonstration file of
% the LaTeX macro package from Springer-Verlag
% for Lecture Notes in Computer Science,
% version 2.4 for LaTeX2e as of 16. April 2010
%
% See http://www.springer.com/computer/lncs/lncs+authors?SGWID=0-40209-0-0-0
% for the full guidelines.
% 
\documentclass{llncs}
\input{settings/packages}
\usepackage{enumitem}
\usepackage{makecell}
\usepackage{url}
\usepackage{wasysym}
\usepackage{multirow}

\usepackage{tikz}
 
%% Macro for a bullet symbol with two mandatory arguments
%% #1: draw color
%% #2: fill color
%% for color names see the »xcolor« manual
\newcommand*{\tikzbullet}[2]{%
   \setbox0=\hbox{\strut}%
   \begin{tikzpicture}
     \useasboundingbox (-.25em,0) rectangle (.25em,\ht0);
     \filldraw[draw=#1,fill=#2] (0,0.5\ht0) circle[radius=.25em];
   \end{tikzpicture}%
}

\begin{document}

\title{Webly Supervised Learning for Skin Lesion Classification}
%
\titlerunning{Fernando Navarro et al.}
% \titlerunning{Anonymous}  % abbreviated title (for running head)
%                                     also used for the TOC unless
%                                     \toctitle is used
%
\author{Fernando Navarro\inst{1} \and Sailesh Conjeti\inst{1,2} \and
Federico Tombari\inst{1} \and Nassir Navab\inst{1,3}}
% \author{Paper \# 224}
%

%
%%%% list of authors for the TOC (use if author list has to be modified)
% \tocauthor{Anonymous}
%
% \institute{Under Review for MICCAI 2018}
\institute{Computer Aided Medical Procedures, Technische Universit\"at M\"unchen, Germany\\
%\email{fernando.navarro@tum.de}
\and
German Center for Neurodegenrative Diseases (DZNE), Bonn, Germany \\
\and
Computer Aided Medical Procedures, Johns Hopkins University, Baltimore,USA}

\maketitle              % typeset the title of the contribution

\begin{abstract}

Within medical imaging, manual curation of sufficient well-labeled samples is cost, time and scale-prohibitive. To improve the representativeness of the training dataset, for the first time, we present an approach to utilize large amounts of freely available web data through web-crawling. To handle noise and weak nature of web annotations, we propose a two-step transfer learning based training process with a robust loss function, termed as Webly Supervised Learning (WSL) to train deep models for the task. We also leverage \textit{search by image} to improve the search specificity of our web-crawling and reduce cross-domain noise. Within WSL, we explicitly model the noise structure between classes and incorporate it to selectively distill knowledge from the web data during model training. To demonstrate improved performance due to WSL, we benchmarked on a publicly available 10-class fine-grained skin lesion classification dataset and report a significant improvement of top-1 classification accuracy from 71.25 \% to 80.53 \% due to the incorporation of web-supervision. 



% The success of deep learning architectures in the classification task is mainly due to the availability of a large annotated dataset consisting of millions of images. In Medical applications, annotated data is limited and one must compensate for this issue in order to be able to use deep learning architecture. Webly supervised learning is proposed in this work to alleviate the lack of annotated medical data for the classification of skin lesions. We propose a novel methodology to retrieve images from the web along with its noisy labels and propose a novel loss function to deal with label noise. Our results demonstrate that the proposed approach improves the classification performance of skin lesion in a ten-class classification problem.
% Skin cancer is the most common type of cancer, being melanoma detection the focus of current state-of-the-art algorithms. Nevertheless, melanoma is not the only skin cancer case and the ability to detect precisely the type of skin lesion is crucial for treatment planning and prognosis. Compared to the existing methods, which classify skin lesion into two or three classes, we aim to classify skin lesion into ten classes. As it is well known, medical annotated data is hard to obtain. To overcome this problem, we propose a webly supervised learning approach, leveraging the free available data from the web together with a novel robust label noise loss function to alleviate for unreliable data obtained from the web. We also introduce a novel methodology to collect data from the web that consist of a search by image instate of the classical search by keyword in webly supervised learning, resulting in images that are more similar to the desired class in terms of visual features. Our results demonstrate that the proposed approach improves the classification performance of skin lesion in the ten-class classification problem. 
%\keywords{Skin lesions, Webly Supervised Learning, Robust Label Noise Loss}
\end{abstract}
\section{Introduction}



The success of deep learning in computer vision tasks such as image classification, object detection, segmentation \textit{etc.} is owed to the availability of a large corpus of annotated training data~\cite{resnet,inceptionv3,inceptionv4}. However, translating these developments to medical imaging applications is often challenging as curating a representative dataset is cost-, time- and scale-prohibitive. On the other hand, excessive reliance on a small-sized, well-curated dataset offers limited guarantees on the generalizability to unseen scenarios and could lead to potential overfit on the training data due to excessive over-parameterization of deep networks. In this paper, we propose to leverage freely available data crawled from the web to offset the need for a large dataset and introduce the concept of \textit{Webly Supervised Learning} (WSL) as a potential approach for training neural networks for medical imaging applications. We present a proof of concept for the task of fine-grained classification of skin lesions in dermatological images. 

\begin{figure}
\centering
\begin{minipage}{0.5\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{images/visualv3_clean.png}
\end{center}
% \caption*{\textbf{CleanNet}}
\end{minipage}\hfill
\begin{minipage}{0.5\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{images/visualv3_global.png}
\end{center}
% \caption*{\textbf{LocalWebNet}}
\end{minipage}
\vspace{-5pt}
\caption{\small{Comparison of t-SNE embedding space generated from networks trained on limited clean data (Left) against network trained with Webly Supervised Learning (Right) generating compact class clusters with improved separability especially for under-represented classes.}}
\label{fig:embedding}
\vspace{-15pt}
\end{figure}
% \vspace{-10pt}
The task of skin lesion classification is a representative example of a medical imaging application in which, annotated training data is limited in availability. However, there is an abundance of freely-available web data. We source our images from multiple publicly-accessible sites such as~\cite{webdata2}, where pictures of skin lesions are uploaded with the goal of getting feedback on the type of lesion with respect to visual features. Prior work on deep learning for skin lesion classification includes training networks that perform either a two or three-class classification (melanoma, non-cancerous and seborrheic keratosis)~\cite{tmi1,isicpaper1,isbi1}. Authors in~\cite{naturepaper} propose a deeply learned network for nine-class categorization using a large dataset of 130000 images extensively curated from hospital archives and from dermatological websites. The data used in this work underwent extensive manual quality control with 23 human experts and filtering prior to fine-tuning InceptionV3~\cite{inceptionv3}. In contrast to~\cite{naturepaper}, within this paper, we adopt a more unconstrained learning paradigm by focusing on learning in presence of extreme label noise by developing a dedicated robust loss function and employing transfer learning strategies to seamlessly leverage webly sourced data into training without employing any additional heuristics or expert knowledge.
% The work from~\cite{naturepaper} is closely related to our work in terms of the complexity of the problem, they have proposed a nine-class classification using a large dataset of images (130k). Our work aims a ten-class classification task for skin lesion, but using a 100 times smaller clean dataset and leveraging the free available web data.
% \begin{figure}[t]
% \begin{center}
% \includegraphics[width=0.24\linewidth]{images/noise1.png}
% \includegraphics[width=0.24\linewidth]{images/noise2.png}
% \includegraphics[width=0.24\linewidth]{images/noise3.png}
% \includegraphics[width=0.24\linewidth]{images/noise4.png}

% \includegraphics[width=0.24\linewidth]{images/noise5.png}
% \includegraphics[width=0.24\linewidth]{images/noise6.png}
% \includegraphics[width=0.24\linewidth]{images/noise7.png}
% \includegraphics[width=0.24\linewidth]{images/noise8.png}
% \end{center}
% \caption{Type of noise in webly supervised learning when searching for Melanoma class as keyword. The images in the first row represent examples of cross-domain noise. The second row represents the cross-category noise.}
% \label{fig:noisetype}
% \end{figure}
% To demonstrate the effectiveness of the proposed method, a ten-class skin lesion classification is proposed. This task is a representative example of an application where limited data is present. The number of images for skin lesion binary classification is at most 2,000, while in a ten-class classification is even smaller. We have realized that there exist many specialized websites \cite{webdata1,webdata2,webdata3}, where pictures of skin lesion can be uploaded, with the final goal to get feedback on the type of lesion according to the visual features. 
\begin{wrapfigure}[11]{l}{0.5\textwidth}
\vspace{-25pt}
\centering
\includegraphics[width=0.49\textwidth]{images/noise_type}
\caption{\footnotesize{Type of noise in WSL for Melanoma class as keyword. The images in the first row represent examples of cross-domain noise. The second row represents the cross-category noise.}}
\label{fig:noisetype}
\end{wrapfigure}Harvesting images from the web presents opportunities for abundant availability and the ability to encompass sufficient heterogeneity during training. However, learning from them is challenging due to the presence of different types of noise. These include \textit{cross-domain noise}: retrieved web images may include non-dermatoscopic images such as histology, artistic illustrations, icons \textit{etc.} and \textit{cross-category noise}: images that are visually similar to the query yet belong to a different class. Cross-domain noise is introduced by bias due to a specific search engine and associated search criterion (such as user tags).
\begin{figure}[ht]
\begin{center}
\includegraphics[width=\textwidth]{images/search_comparison2}
\end{center}
\vspace{-10pt}
\caption{\small{Comparison of crawled results. The left image shows an example of a search by keyword ``melanoma": the resulting images contain high cross-domain noise. The right image shows the results of a search by image, where the cross-domain noise is significantly reduced sharing strong visual similarity to the query image.}}
\label{fig:searchkeyword}
\vspace{-10pt}
\end{figure}
% \begin{wrapfigure}{r}{0.5\textwidth}
% \centering
% \includegraphics[width=0.5\textwidth]{images/search_comparison2}
% \caption{The left image shows an example of a search by keyword "melanoma": the resulting images contain high cross-domain noise. The right image shows the results of a search by image}
% \label{fig:searchkeyword}
% \end{wrapfigure}
Additionally, image-search engines are biased as they often operate in high-precision low-recall regimes and preferentially present objects centered with clean background and a canonical view-point. Fig.~\ref{fig:noisetype} illustrates different types of noise present in retrieved images upon web-crawling with "melanoma" as the search tag. Learning from web data is one approach for learning under extreme label noise. Methods within the computer vision community that leverage web supervision for training can be broadly categorized as: (1) \textit{Filtering}: approaches that aim to clean or filter the collected web images prior to training~\cite{clean1,clean2}; (2) \textit{Modeling Relationships}: approaches that model the relationship between web images and noisy labels with a small subset of clean images and utilize the discovered relationships to improve training~\cite{graphical1,graphical2} and (3) \textit{Robust Loss Functions}: approaches that learn in the presence of label noise by introducing robustness within their loss-function design \cite{robust1,robust2}. Our proposed approach encompasses the best of the aforementioned approaches with the following contributions: 
\begin{enumerate}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
\item \textbf{Reduction in Cross-domain Noise}: This is the first work to leverage \textit{search by image} to improve search specificity and reduce cross-domain noise by fetching images that share close visual features to the query image.
\item \textbf{Noise Modeling}: We model the noise as a class-transition matrix which is estimated from the bag of retrieved images. This noise modeling approach allows for distillation of knowledge from noisy web-images to train very-deep networks. 
\item  To the best of our knowledge, this is the first work within the medical image computing that leverages web-supervision to train deep neural networks and specifically targeted at fine-grained ten-class categorization of skin lesions.
\end{enumerate}





% Using a webly supervised learning approach, we first collect a training dataset of images for skin lesion classification and leverage that data along with noisy labels to train DNLs.  
% Being skin cancer the most common type of cancer \cite{cancerfacts}, it is of special interest to know whether a skin lesion is cancerous or not. Deep neural networks have found their way to improve the classification of skin lesion \cite{tmi1,isicpaper1,isbi1}. All these methods are powered by deep neural network or an ensemble of them to solve a two or three classification task, mainly focus on Melanoma detection. 


% The recent development of image classifiers is based on deep neural networks (DNL) \cite{resnet,inceptionv3,inceptionv4}. The success of such classifiers is powered in part by a large-scale well-labeled training dataset. In many applications, including the medical, it is quite hard to annotate an ImageNet-like training set. On the other hand, it is cheap, fast and convenient to collect training images from the Web to train DNLs. This approach, known as Webly Supervised Learning (WSL) has demonstrated that for learning DNL it is more relevant to have a large dataset with noisy labels than a small dataset with perfect labels \cite{webly1,webly2}. 

% When collecting images from the web to train DNLs we are likely to have noisy labels. The noisy labels can be categorized into two: (1) Cross-domain, which corresponds to those images that has nothing to be with the class we are aiming to search for and (2) Cross-category, which corresponds to the images that may have the wrong label, but we are unable to tell using only visual features. 




% Although collecting data from the web solves the limitation of annotated data, it imposes the problem of learning from noisy labels. Many works in this direction have been proposed and they can be categorized into three groups. (1) The first consist of methods that aims to clean or filter the collected web images before training DNLs \cite{clean1,clean2}. (2) Other works focus on developing graphical models that try to model the relationship between noisy labels, clean labels and type of noise \cite{graphical1,graphical2}.  (3) The last group aims to design robust loss functions to label noise \cite{robust1,robust2}. In these methods, the noise is  modeled or globally estimated from the web collected data. Our work is closely related to the last research line, here, all the methods in this category propose a global noise estimation with respect to the noisy dataset. We argue that a global noise estimation can lead to a wrong approximation of the noise and that a local noise estimation allow us to learn better DNLs under label noise settings which is specially suitable for fine-grained classification.



% The contributions of this paper are the following:
% (1) a search by image novel technique to collect data from the web, which has demonstrated to reduce cross-domain noise to learn deep neural networks under noisy labels, (2) a robust loss function to be able to learn under label noise and reduce cross-category noise, and (3) to our knowledge, this is the first work on webly supervised learning for medical imaging.
\section{Methodology}
% \begin{figure}[t]
% \begin{center}
% \includegraphics[width=0.49\textwidth]{images/search3}
% \includegraphics[width=0.49\textwidth]{images/searchimage}
% \end{center}
% \caption{The left image shows an example of a search by keyword "melanoma": the resulting images contain high cross-domain noise. The right image shows the results of a search by image}
% \label{fig:searchkeyword}
% \end{figure}
\begin{figure}[ht]
\begin{center}
\includegraphics[width=0.8\textwidth]{images/overview_latex_final}
\end{center}
\vspace{-10pt}
\caption{\small{Overview of the proposed WSL approach consisting of a two-step  training. First, training a network on web data, follow by fine-tuning a second network utilizing the latter as strong prior initialization. Noise correction is performed when training on web data.}}
\label{fig:overview}
\vspace{-0.68cm}
\end{figure}

% \subsection{Web-Crawling}
% \begin{wrapfigure}[16]{r}{0.5\textwidth}
% \centering
% \includegraphics[width=0.49\textwidth]{images/overview_latex_final}
% \caption{Overview of the proposed WSL approach.}
% \label{fig:overview}
% \end{wrapfigure}
\vspace{-10pt}
Given a small representative training dataset $\mathcal{C} = \left \{ \left ( \mathbf{x}_{c}^{n}, \mathbf{y}_{c}^{n} \right ) \right \}_{n=1}^{N}$ of dermatological images with expert annotations, we source web-images for WSL by utilizing the \textit{Search by Image} option within standard search engines (here, \url{https://images.google.com/}) by submitting each of the \textit{clean} images independently and crawling the top retrieved results. Let the bag of images (of size $M$) crawled from the web for a query image of $\mathbf{x}_{c}^{n}$ be represented as $\mathcal{W}^{n} = \left \{  \mathbf{x}_{w}^{m} \mid \text{Query: }\mathbf{x}^{n}_{c} \right \}_{m=1}^{M}$. The semantic label associated with the query clean image $\mathbf{y}_{c}^{n}$ is given to the corresponding web-crawled bag $\mathcal{W}_{n}$. Let the complete web-crawled images with their corresponding annotations be denoted as $\mathcal{W} = \left \{ \left ( \mathcal{W}^{n}, \mathbf{y}_{c}^{n} \right ) \right \}_{n=1}^{N}$. Contrasting with prior WSL approaches~\cite{webly1,webly2} that use search by keyword (such as \textit{melanoma}, \textit{keratosis} \textit{etc.}), we observe that our approach significantly reduces the cross-domain noise by fetching only images that share strong visual features with the query. Fig.~\ref{fig:searchkeyword} contrasts the proposed search by image approach against the search by keyword methodology for the construction of a web-dataset for WSL. It must be noted that the labels transferred from $\mathcal{C}$ to $\mathcal{W}$ are extremely noisy as the web-search relies on non-task specific solely visual features for ranking and carries no guarantees on the fetched results sharing the same semantic class as the query. Additionally, in such an uncontrolled setting, multiple queries could fetch the same images thus the web-images could carry potential cross-category noise. With per-image web-crawling, our training dataset is significantly augmented (with at most $M \times N$ unique images) and the resultant dataset is rich in representativeness and heterogeneity but fraught with extreme label noise which needs to be factored out in the subsequent training steps.  

\subsection{Model Learning}

\noindent
\textbf{Noise Correction}: Assuming that we have access to a perfect oracle network $\mathcal{F}_{\mathcal{O}}\left ( \cdot \right )$, we model the noise within the web images as a class-transition matrix $T$ that can be used to diffuse the predictions on web data across confusing classes. In na\"{i}ve terms, $T$ models the probability of each class being confused into one another. Considering three classes ($c_{1},c_{2}$ and $c_{3}$), if $c_{1}$ and $c_{2}$ are visually more similar than $c_{3}$, there is a higher probability for cross-category noise across $c_{1}$ and $c_{2}$ in comparison to $c_{1}$ and $c_{3}$ (or $c_{2}$ and $c_{3}$) and this reflects back in the estimated class-transition matrix as $T\left (c_{1},c_{2}  \right ) > T\left (c_{1},c_{3}  \right )$. From within the web crawled images $\mathcal{W}$, we use the predictions of oracle network  $\mathcal{F}_{\mathcal{O}}$ to mine the most representative sample $\hat{\mathbf{x}}_{w,c_{i}}$ of class $c_{i}$ from within $\mathcal{W}$ as: 
\begin{equation}
\hat{\mathbf{x}}_{w,c_{i}} = \text{argmax}_{\mathbf{x}_{w} \in \mathcal{W}}\text{ } p\left ( y = c_{i} \mid \mathbf{x}_{w}, \mathcal{F}_{O} \right ),
\end{equation}
where $p\left ( \cdot \right )$ is the class posterior probability. This is repeated for all target classes and the class transition matrix for the web-data is estimated as: 
% \begin{equation}
% T = \left [ t_{ij} \right ]_{i,j=1}^K \text{ where }t_{ij} = p\left ( y = c_{i} \mid \hat{\mathbf{x}}_{w,c_{i}}, \mathcal{F}_{O} \right ).
% \end{equation}

\begin{equation}
T_{ij} = p\left ( y = c_{j} \mid \hat{\mathbf{x}}_{w,c_{i}}, \mathcal{F}_{O} \right )
\end{equation}
The aforementioned approach globally estimates the noise transition matrix across the web-crawled images and allows for selective diffusion across confounding classes associated with that bag. As the availability of a perfect oracle network is highly unlikely in real-world, we use a deep network trained on the limited clean dataset $\mathcal{C}$ as a potential surrogate for $\mathcal{F}_{\mathcal{O}}$. 

\noindent
\textbf{Webly Supervised Learning}: We adopt a transfer-learning like paradigm to train our fine-grained classification network as shown in Fig. \ref{fig:overview}. From an overall perspective, the web-crawled dataset $\mathcal{W}$ is used to train an initial model $\mathcal{F}_{\mathcal{W}}\left ( \cdot \right )$ with weighted-cross entropy loss. Noise correction is modulated by changing the network predictions with the estimated noise transition matrix $T$ from the retrieved web-images $\mathcal{W}$, the modulated cross-entropy loss for training $\mathcal{F}_{\mathcal{W}}$ is estimated as: 

%$T = \left [ t_{ij} \right ]_{i,j=1}^K$
% \begin{equation}
% \mathcal{L} \left (y = c_{i}, p(y \mid x \right) = - \sum_{n=1}^{N}\sum_{\mathbf{x}_{w}^{n} \in \mathcal{W}^{n}} \sum_{c=1}^{K} w_{c}\text{ }y_{\mathbf{x}_{w}^{n},c} \text{ log}\left ( t_{c,\left ( \cdot \right )} \times p\left ( c \mid \mathbf{x}_{w}^{n} \right ) \right )
% \label{eq:crossentropy}
% \end{equation}

\begin{equation}
\mathcal{L} = - \sum_{\mathbf{x}_{c}^{n} \in \mathcal{W}} w(\mathbf{x}_{c}^{n}) \ y(\mathbf{x}_{c}^{n}) \ log(T \ \times \ p(\mathbf{x}_{c}^{n}))
% \mathcal{L} = - \sum_{n=1}^{N}\sum_{\mathbf{x}_{w}^{n} \in \mathcal{W}^{n}} \sum_{c=1}^{K} w_{c}\text{ }y_{\mathbf{x}_{w}^{n},c} \text{ log}\left ( t_{c,\left ( \cdot \right )} \times p\left ( c \mid \mathbf{x}_{w}^{n} \right ) \right )
\label{eq:crossentropy}
\end{equation}
% Notice that having  $T$ as the identity matrix, would be equivalent to disable the noise correction layer. 
where $w(\mathbf{x}_{c}^{n})$ is the weight associated with the class, estimated using median-frequency balancing, $y(\mathbf{x}_{c}^{n})$ is the ground truth of sample $\mathbf{x}_{c}^{n}$ and $p(\mathbf{x}_{c}^{n})$ provides the estimated probability of sample  $\mathbf{x}_{c}^{n}$ to belong to class $c$. The trained network $\mathcal{F}_{\mathcal{W}}$ is used an initialization for subsequent fine-tuning with clean data $\mathcal{C}$ to obtain the final target model $\mathcal{F}_{\mathcal{C}}\left ( \cdot \right )$. Such a training strategy ensures that all available rich information from web-supervision is transferred as a strong prior to $\mathcal{F}_{\mathcal{C}}$ and that only expert annotated data is used to train the final network. 


% The class weights $w_{c}$ in Eq.~\eqref{eq:crossentropy} are estimated using median-frequency balancing. 
% The trained network $\mathcal{F}_{\mathcal{W}}$ is used an initialization for subsequent fine-tuning with clean data $\mathcal{C}$ to obtain the final target model $\mathcal{F}_{\mathcal{C}}\left ( \cdot \right )$. Such a training strategy ensures that all available rich information from web-supervision is transferred as a strong prior to $\mathcal{F}_{\mathcal{C}}$ and that only expert annotated data is used to train the final network. 



%Having estimated the class-transition matrices across $\mathcal{W}$, we train a deep neural network $\mathcal{F}_{\mathcal{W}}$ with web-data 






%We train an initial oracle network $\mathcal{F}_{\mathcal{O}}\left ( \cdot \right )$ until convergence with clean-data $\mathcal{C}$ using weighted-cross entropy as a loss. 





% \subsection{Reducing Cross-domain noise}
% % Contrary to the webly supervised community, we propose a new technique to retrieve training images from the web. We observed that leveraging a search by keyword for a fine-grained classification task introduces high cross-domain noise. For instance, when searching for the keyword "Melanoma"; histological images, skin diagrams or images of doctors checking the skin can be found as shown in the left part of Fig.~\ref{fig:searchkeyword}. Due to this cross-domain noise, filtering techniques are essential before training a deep neural network with data acquired from the web. 

% % The method we propose to gather data from the web is utilizing the Google Search Engine, and specifically one of its features called "Search by Image". In this case, instead of requesting keyword matches that are based on text metadata and information, it allows us to request matches based on similar visual features. For every image of our dataset we retrieve similar images $X_n$ and assign them the same label as the original image, characterizing them, however, as noisy labels $Y_n$, since they have not been annotated by an expert. This method can increase the size of our training dataset by dozens of times and after it is combined with a suitable robust loss function to handle the label noise, it leads to the increase of the performance of our networks significantly.

% The proposed method consist of a two-step network, which is deep learning architecture independent. A first network is trained with the collected web dataset and its noisy labels denoted as $D_n ({x_n}_i, {y_n}_i)$ together with the proposed loss function to deal with label noise until convergence. Then a second network is fine-tuned using the first network as initialization using this time the dataset with perfectly annotated labels $D_c ({x_c}_i, {y_c}_i)$. In the following section we describe first the technique used to collect web images in a search by image fashion and then the propose loss function to learn under label noise settings.


% On the contrary, the proposed method enables us to directly train deep neural networks without any further step. The leveraged methodology to retrieve images from the web is called \textbf{Search by Image}. Goggle search engine has the possibility to look for similar images to the given input image based on the visual features. Every single image ${x_c}_i$ in the perfectly annotated dataset called clean data $D_c$ is uploaded to the Google search by image page. The resulting similar images $X_n$ are downloaded along with the same label as the searched picture, which correspond to the noisy labels $Y_n$. Using this technique, we can increase the size of the training set up to 100 times bigger than the original. Given that deep neural networks success depend on having a large and representative number of images. The proposed method would in theory allow us to train better CNNs.

% \subsection{Robust Local Loss Function}
% The basis of this paper is the work from Patrini \emph{et. al} \cite{robust2}. There, 
% they propose two procedures for loss correction called the forward and the backward correction, provided that the probability of each class being corrupted into another is known. In real scenarios, these probabilities are unknown. As a result,they show how one can estimate these probabilities,adapting a recent technique for noise estimation to the multi-class setting. The overall procedure consist on training a first network using web data $D_n$. Use a subset of $D_n$, called $X$ or the whole dataset if desire to compute a transition matrix $T$, telling the probability of each class to be confused to other. Train another network using this probability matrix $T$ and the proposed loss function. The general idea is that the last network diffuses the predictions across classes thought the transition matrix $T$, resulting in less confusion. We argue that the estimation of the transition matrix is crucial for the network to perform at its best. We believe that a global estimation of this transition matrix leads to a a wrong approximation.

% In this work we propose a novel method to estimated the transition matrix $T$. The methodology to retrieve images from the web allow us to compute local matrices for every search. In Fig. \ref{fig:ranking} we have a sample image ${x_c}_i$ and the corresponding resulted images ${x_n}_1, {x_n}_2, ..., {x_n}_m$,from the search by image technique. We can therefore compute one transition matrix $T_i$ which will correspond to all the images in this search. The process is repeated for every single image in our clean dataset $D_c$. Now we no longer have a single transition matrix $T$ but many transition matrices $T_i$. The final goal of the proposed methodology to estimate the transition matrix is to diffuse the confusion between classes more selectively. The proposed loss function is described in Equation \ref{eq:3}. We have used the cross-entropy loss, where $\hat{p_{i}}(y\mid x)$ are the network predictions, $\tilde{y_{i}}$ are the noisy labels and $T_i$ the corresponding probability matrix for sample $i$.
% \begin{equation}\label{eq:3}
% \ell (\tilde{y}, \ \hat{p}(\tilde{y} \mid x)) = -\sum_{x}^{} \ \tilde{y_{i}} \ log(T_{i} \ \hat{p_{i}}(y\mid x))
% \end{equation}
% \begin{figure}
% \begin{center}
% \includegraphics[width=\textwidth]{images/ranking1}
% \end{center}
% \caption{Example of our search by image retried system. On the left, a sample image from our clean dataset, in the blue squares, samples of retrieved images in ranking order.}
% \label{fig:ranking}
% \end{figure}


% $\star\star\star\star\star\star\star\star$Sailesh observations added $\star\star\star\star\star\star\star\star$

% \begin{algorithm}
% \caption{Patrini \emph{et. al} \cite{robust2} Method}\label{alg:patrini}
% \begin{algorithmic}[1]
% \textbf{Input:} the noisy training set $D_n$, any loss function $l$
% \Procedure{Euclid}{$a,b$}\Comment{The g.c.d. of a and b}
% \State $r\gets a\bmod b$
% \While{$r\not=0$}\Comment{We have the answer if r is 0}
% \State $a\gets b$
% \State $b\gets r$
% \State $r\gets a\bmod b$
% \EndWhile\label{euclidendwhile}
% \State \textbf{return} $b$\Comment{The gcd is b}
% \EndProcedure
% \end{algorithmic}
% \end{algorithm}

% \begin{algorithm}
% \caption{Patrini \emph{et. al} Method}\label{alg:patrini}
% \begin{algorithmic}[1]
% \Require  the noisy training set $D_n$, any loss function $l$
% \Ensure trained model on noisy labels $h(\cdot)$
% \State Train a network $h(x)$ on $D_n$ with loss function $l$
% \State Obtain an unlabeled dataset from $D_n$ and estimate $T$ by Equations 
% \State Train a network $h(x)$ on $D_n$ using the forward loss function
% \end{algorithmic}
% \end{algorithm}
% Formulas for the transition matrix: 
% In the first formula, given the predictions of a dataset X, we first look at the predictions of class one and save the index of the row containing the maximal argument. Given that index (second formula), we then take the row and use it as the first row of the transition matrix.
% \begin{equation}\label{eq:1}
% x^i= argmax_{x\in X} \ p(\tilde{y}=e^i \mid x)
% \end{equation}
% \begin{equation}\label{eq:2}
% T_{i,j}= p(\tilde{y}=e^i \mid x^i)
% \end{equation}

% To explain the meaning of those equations, an example is provided. First, We assume that we have access to a "perfect network", which can be the $CleanNet$. We assume that our $CleanNet$ only does mistakes because we intentionally fool it by flipping the true labels. Consider the example of classifying blouses and shirts, which can be two confusing classes. Let also our training set $X$ be a set of two blouses, two shirt  as depicted in Figure \ref{fig:noiseexample}. Suppose also that our "perfect network" outputs the predictions in Table \ref{tab:predictions}. From this table, we can see the probability distribution of samples to belong to each class. The samples marked in red correspond to those predictions we want to correct. Equation \ref{eq:1} tell us to find the index with maximal argument for all the scores in class $i$. For example, taking a look at the blouse column in Table \ref{tab:predictions}, we see that example $1$ is the index we look for. Then, equation \ref{eq:2} tell us to take row $i$ in $X$ as the first row of the transition matrix $T$. We repeat this process for every class. The overall idea is that a good estimation of this transition would enable us to diffuse the predictions to better fit the image features. The resulting computed transition matrix $T$ is depicted in Table \ref{tab:transition}.The last step is to perform the matrix multiplication of the network predictions and the transition matrix $T \ p(\tilde{y}\mid x)$ we can observe in Table \ref{tab:correctedpred} the effect of the noise correction layer. In this table, we have corrected the predictions from the third image, resulting in a corrected prediction. On the other hand, the predictions from the second image, the shirt, has changed from 0.5 to 0.475 reducing the probability of that image to belong to the wrong class. Deep neural networks change the network predictions based on the training stage, this means that the network together with the  noise correction layer can be used to train better networks under label noise settings.

% \begin{table}
% \begin{minipage}{\linewidth}
%       \centering
%       \begin{minipage}{0.9\linewidth}
%           \begin{figure}[H]
%               \includegraphics[width=\linewidth]{images/noiseest1}
%               \caption{Example of training set $X$ to illustrate the computation of the transition matrix $T$. Two images for class blouse and two for class shirt.}
%           \end{figure}
%       \end{minipage}
      
%       \begin{minipage}{0.4\linewidth}
%       \begin{center}
%       \resizebox{0.6\linewidth}{!}{%
%       \begin{tabular}{|l|l|l|l|}
%       \hline
%       \textbf{Image$\setminus$class} & \textbf{blouse} & \textbf{shirt} \\ \hline
%       \textbf{1}                & \textcolor{green}{0.65}             & 0.35 \\ \hline
%       \textbf{2}                & 0.45             & \textcolor{red}{0.55} \\ \hline
%       \textbf{3}                & \textcolor{red}{0.55}           & 0.45   \\ \hline
%       \textbf{4}                & 0.25             & \textcolor{green}{0.75} \\ \hline
%       \end{tabular}}
%       \caption{\small{$\ p(\tilde{y}\mid x)$}}
%       \label{tab:predictions}
%       \end{center}
%       \end{minipage}
%       \hspace{-1.5cm}
%       \begin{minipage}{0.2\linewidth}
%       \begin{center}
%       \resizebox{0.4\linewidth}{!}{%
%       \begin{tabular}{|l|l|l|}
%       \hline
%       0.65  & 0.35 \\ \hline
%       0.25  & 0.75  \\ \hline
%       \end{tabular}}
%       \caption{\small{$T$}}
%       \label{tab:transition}
%       \end{center}
%       \end{minipage}
%       \hspace{-1.5cm}
%       \begin{minipage}{0.4\linewidth}
%       \begin{center}
%       \resizebox{0.6\linewidth}{!}{%
%       \begin{tabular}{|l|l|l|l|}
%       \hline
%       \textbf{Image$\setminus$class} & \textbf{blouse} & \textbf{shirt} \\ \hline
%       \textbf{1}       & \textcolor{green}{0.51}           & 0.49 \\ \hline
%       \textbf{2}       & 0.43           & \textcolor{red}{0.57} \\ \hline
%       \textbf{3}       & 0.47           & \textcolor{green}{0.53} \\ \hline
%       \textbf{4}       & 0.35           & \textcolor{green}{0.65} \\ \hline
%       \end{tabular}}
%       \caption{\small{$T \ p(\tilde{y}\mid x)$}}
%       \label{tab:correctedpred}
%       \end{center}
%       \end{minipage}
%   \end{minipage}
%  \end{table}

% Figure for multiple Ts
% \begin{figure}[h!]
% \begin{center}
% \includegraphics[width=0.8\textwidth]{images/ranking3}
% \end{center}
% \caption{Illustration of local noise estimation using 3 images from the clean dataset. These images are shown in the center of the ellipses. The set of images used to computed the local noise are depicted around the clean image.}
% \label{fig:local}
% \end{figure}

\section{Experiments}

% \begin{table}[t] 
% \begin{center}
% \resizebox{\textwidth}{!}{
% \begin{tabular}{c|l|l|c|c|c|c}
%  & \multirow{ 3}{*}{\textbf{Name}}  &  \multicolumn{3}{c}{Model Learning} &  \multicolumn{2}{|c}{Performance} \\ 
% \cline{3-7}
% \textbf{\#} &  &  \makecell{Training \\ Data} & Initialization & \makecell{Noise \\Correction}  & \makecell{Average \\ Accuracy} & \makecell{Cohen's \\ Kappa} \\ \hline
% \textbf{1} & BL1 & Clean & ImageNet & -  & 0.7125                & 0.6504                \\ \hline
% \textbf{2} &  & Search by Keyword & ImageNet & \checkmark  \\ 
% \textbf{3} & BL2 & Clean & \#2 & -  \\ \hline
%  \textbf{4} &  & Search by Image & ImageNet & $\times$ & & \\
% \textbf{5} & BL3 & Clean & \#4 &    & 0.7991                & 0.7602                \\ \hline
% \textbf{6} &  & Search by Image & ImageNet & \checkmark & & \\
% \textbf{7} & Proposed & Clean & \#6 & clean & 0.8053                & 0.7677                \\ \hline
% \end{tabular}
% }
% \caption{Design parameters and average performance observed for incremental baselines designed to validate WSL for skin lesion classification.}
% \label{tab:settings}
% \end{center}
% \end{table}

\textbf{Dataset:} The limited manually annotated dataset was sourced from the Dermofit Image Library~\cite{dermofit}, which consists of 1300 high quality skin lesion images annotated by expert dermatologists. The lesions are categorized into ten fine-grained classes including melanomas, seborrhoeic keratosis, basal cell carcinomas, \textit{etc.} The dataset has an extreme class imbalance (\textit{e.g.} the melanocytic nevus (25.4 \%) \textit{vs.} pyogenic granuloma (1.8\%)). The under-representation of these classes further motivates the need for augmentation with web-crawled data. For our experiments, we performed a patient-level split and used 50\% of the data for training and the rest for testing. It must be noted that due to the proprietary nature of the Dermofit library, we do not expect any of our test-data to be freely accessible via the web and hence would not be duplicated within the web-data while training the networks. 


% The dataset used for our experiments is the Dermofit Image Library \cite{dermofit}, which consists of 1300 high quality skin lesion images annotated by expert dermatologists. The lesions are classified in ten different classes including melanomas, seborrhoeic keratosis, basal cell carcinomas, \textit{etc.}. A significant reason we need to increase the amount of training data we possess is that the dataset suffers from severe class imbalance. For our experiments we performed patient-level split and used 50\% of the data for training and 50\% for testing.

\noindent\textbf{Networks:} To demonstrate the contributions in terms of both the effectiveness of the proposed search by image as well as the introduction of noise correction while model learning, we established three baselines as presented in Table~\ref{tab:settings}. Specifically, BL1 is the \textit{vanilla} version of training exclusively with the clean training dataset, while contrasting with BL2 we can test the hypothesis that creating a web-dataset through \textit{search by image} induces higher search specificity and significantly reduces the cross-domain noise compared to the web data mined with keywords or user tags. We chose to use the Inception V3 deep architecture~\cite{inceptionv3} as the base model for this work. All the aforementioned models were trained with stochastic gradient descent with a decaying learning rate initialized at 0.01, momentum of 0.9 and dropout of 0.8 for regularization and the code was developed in TensorFlow \cite{tensorflow}.

% In all trained network, data augmentation is leveraged to further extend the variability in the dataset. Such augmentation include, cropping, rotation and other transformation, all randomly generated in training time.
% \begin{table}[t] 
% \begin{center}
% \resizebox{\textwidth}{!}{
% \begin{tabular}{c|l|l|c|c|c|c}
%  & \multirow{ 3}{*}{\textbf{Name}}  &  \multicolumn{3}{c}{Model Learning} &  \multicolumn{2}{|c}{Performance} \\ 
% \cline{3-7}
% \textbf{\#} &  &  \makecell{Training \\ Data} & Initialization & \makecell{Noise \\Correction}  & \makecell{Average \\ Accuracy} & \makecell{Cohen's \\ Kappa} \\ \hline
% \textbf{1} & BL1 & Clean & ImageNet & -  & 0.7125                & 0.6504                \\ \hline
% \textbf{2} &  & Search by Keyword & ImageNet & \checkmark  \\ 
% \textbf{3} & BL2 & Clean & \#2 & -  \\ \hline
%  \textbf{4} &  & Search by Image & ImageNet & $\times$ & & \\
% \textbf{5} & BL3 & Clean & \#4 &    & 0.7991                & 0.7602                \\ \hline
% \textbf{6} &  & Search by Image & ImageNet & \checkmark & & \\
% \textbf{7} & Proposed & Clean & \#6 & clean & 0.8053                & 0.7677                \\ \hline
% \end{tabular}
% }
% \caption{Design parameters and average performance observed for incremental baselines designed to validate WSL for skin lesion classification.}
% \label{tab:settings}
% \end{center}
% \end{table}
\begin{table}[t] 
\begin{center}
\resizebox{0.8\textwidth}{!}{
\begin{tabular}{c|l|l|c|c|c|c}
 & \multirow{ 3}{*}{\textbf{Name}}  &  \multicolumn{3}{c}{\textbf{Model Learning}} &  \multicolumn{2}{|c}{\textbf{Performance}} \\ 
\cline{3-7}
\textbf{\#} &  &  \makecell{Training \\ Data} & Initialization & \makecell{Noise \\Correction}  & \makecell{Average \\ Accuracy} & \makecell{Cohen's \\ Kappa} \\ \hline
\textbf{1} & BL1 & Clean & ImageNet & -  & 0.713                & 0.650                \\ \hline
 \textbf{2} &  & Web data & ImageNet & $\times$ & & \\
\textbf{3} & BL2 & Clean & \#4 &    & 0.799                & 0.760                \\ \hline
\textbf{4} &  & Web data & ImageNet & \checkmark & & \\
\textbf{5} & Proposed & Clean & \#6 &  & \textbf{0.805}                & \textbf{0.768}                \\ \hline
\end{tabular}
}
\caption{Design parameters and average performance observed for incremental baselines designed to validate WSL for skin lesion classification.}
\label{tab:settings}
\end{center}
\vspace{-32pt}
\end{table}


% \begin{table}[t] 
% \begin{wraptable}{r}{0.5\textwidth}
% \begin{center}
% \begin{tabular}{c|l|l|c|c|c|c}
%  & \multirow{ 3}{*}{\textbf{Name}}  &  \multicolumn{3}{c}{Model Learning} &  \multicolumn{2}{|c}{Performance} \\ 
% \cline{3-7}
% \textbf{\#} &  &  \makecell{Training \\ Data} & Initialization & \makecell{Noise \\Correction}  & \makecell{Average \\ Accuracy} & \makecell{Cohen's \\ Kappa} \\ \hline
% \textbf{1} & BL1 & Clean & ImageNet & -  & 0.7125                & 0.6504                \\ \hline
% \textbf{2} &  & Search by Keyword & ImageNet & \checkmark  \\ 
% \textbf{3} & BL2 & Clean & \#2 & -  \\ \hline
%  \textbf{4} &  & Search by Image & ImageNet & $\times$ & & \\
% \textbf{5} & BL3 & Clean & \#4 &    & 0.7991                & 0.7602                \\ \hline
% \textbf{6} &  & Search by Image & ImageNet & \checkmark & & \\
% \textbf{7} & Proposed & Clean & \#6 & clean & 0.8053                & 0.7677                \\ \hline
% \end{tabular}
% \caption{Design parameters and average performance observed for incremental baselines designed to validate WSL for skin lesion classification.}
% \label{tab:settings}
% \end{center}
% \end{wraptable} 
% \end{table}
% Table~\ref{tab:settings} summarizes the explored baselines. Initially, we trained a network on clean data without any web supervision (BL1). Afterwards we used the two-step approach explained earlier in the paper, where we first trained a network on the images retrieved from the web and then used it as initialization for a second network, trained on the original dataset. BL2 is trained without any noise correction. The last baseline BL3, follows the same two-step training described previously but leveraging the Global Noise Correction~\cite{robust2}. The loss function used to train the above networks was weighted cross entropy and the code was written in TensorFlow~\cite{tensorflow}.
% In the first step, a network is trained using the web data with its noisy labels. 
% In the second step, another network is trained on clean data using the network on step one as initialization.

% Baseline 1 corresponds to the case where we train a network using only the clean dataset, we call this network $CleanNet$. 

% In baseline 2, we perform the two-step training described before using the cross-entropy loss for both steps, we call this network $WebNet$. 

% Baseline 3 is the proposed forward method of Patrini \emph{et. al} \cite{robust2}. 
% In the first step, we train a network using forward method together with the global noise estimation matrix $T$. 
% In the second step, we train using cross-entropy loss, we call this network $GlobalWebNet$. 

% Finally, in baseline 4 we first train a network using the proposed local noise estimation loss and later train the second network using cross-entropy loss, this baseline is called $LocalWebNet$. 





% \begin{table}[H] 
% \begin{center}
% \resizebox{\textwidth}{!}{
% \begin{tabular}{llllll}
% \hline
% \textbf{\#} & \textbf{Name} & \textbf{Loss} & \textbf{Initialization} & \textbf{Training Data} & \textbf{Estimated Noise} \\ \hline
% \textbf{1} & CleanNet & cross-entropy & ImageNet & clean &  \\ \hline
% \textbf{2} &  & cross-entropy & ImageNet & web &  \\ 
% \textbf{3} & WebNet & cross-entropy & \#2 & clean &  \\ \hline
% \textbf{4} &  & global noise correction & ImageNet & web & \#1 \\
% \textbf{5} & GlobalWebNet & cross-entropy & \#4 & clean &  \\ \hline
% \textbf{6} &  & local noise correction & ImageNet & web & \#1 \\
% \textbf{7} & LocalWebNet & cross-entropy & \#6 & clean &  \\ \hline
% \end{tabular}
% }
% \caption{Baselines. Four different approaches were explored called $CleanNet$, $WebNet$ $GlobalWebNet$ and $LocalWebNet$}
% \label{tab:settings}
% \end{center}
% \end{table}
% magda is editing this section
\section{Results and Discussion}
To evaluate the effect of inclusion of WSL and the proposed noise correction, we report the average accuracy across all classes and the Cohens Kappa coefficient in Table~\ref{tab:settings}. The latter metric is particularly motivated due to the presence of significant class imbalance within our dataset. We also report the class-wise area under the curve (ROC) in Table~\ref{tab:resultsauc}. The confusion matrices are visualized in Fig.~\ref{fig:confinception}. To contrast the learned intermediate features, we embed them into a two-dimensional subspace using t-Stochastic Neighbor Embedding (t-SNE) illustrated in Fig.~\ref{fig:embedding}.  

% our method we report the area under the curve (AUC) for each class, along with the average accuracy across classes and the Cohens Kappa coefficient. The latter is particularly interesting in our case, since our dataset is characterized by significant class imbalance. 
\noindent
\textbf{Analyzing the embedding space}: Comparing the t-SNE embeddings of the test data generated by BL1 and the proposed approach in Fig.~\ref{fig:embedding}, we observe that the embeddings in WSL approach cluster examples from the same semantic class more compactly and maintain better class-separability. Within the embedding of BL1, we notice poor separability between the less-frequently occurring classes (represented with \tikzbullet{black}{black}, \tikzbullet{orange}{orange} and \tikzbullet{gray}{gray} bullets), which is significantly improved in the embedding of WSL. We also observe that the misclassification of Pyogenic Granuloma(benign) \tikzbullet{yellow}{yellow} class into Basal Cell Carcinoma (malignant) \tikzbullet{green}{green} in case of BL1 is not observed for WSL. This is quite critical as these classes are mutually exclusive. Meaning that, a vast malignant samples can be classified as benign, leading to a wrong diagnosis.


\noindent
\begin{wrapfigure}[16]{r}{0.4\textwidth}
\vspace{-32pt}
\begin{center}
\includegraphics[width=0.18\textwidth]{images/confusion_matrix.png}
% \caption{\small{Confusion matrices showing the effect of WSL approach compared to BL1. Significant performance is observed in WSL.}}
\caption{\small{Confusion matrices showing the effect of the proposed WSL approach compared to BL1.}}
\label{fig:confinception}
\end{center}
\end{wrapfigure}\textbf{Effect of Web Supervision}: 
Contrasting BL1 against the proposed method in Table~\ref{tab:settings} and Fig.~\ref{fig:confinception}, we clearly observe a significant improvement in the model performance across all classes, with a more pronounced diagonal in its confusion matrix. This is clearly attributed to a better network initialization derived through transfer learning with web-supervision. This also demonstrates that we are effective in factoring out the cross-domain and cross-category noise within the web-dataset and effectively use it for supervising deep models in the presence of limited manual annotations. In Table~\ref{tab:resultsauc}, contrasting the class-wise performance, we observe that the performance on under-represented classes is significantly improved upon WSL. This is clearly evident in Intraepithelial Carcinoma \tikzbullet{gray}{gray} (5.99 \% Clean data) and Pyogenic Granuloma \tikzbullet{yellow}{yellow} (1.17 \% Clean data) where the performance improves by 3.6 \% and 7.3\% respectively. 
Contrasting BL2 with the proposed approach in Table~\ref{tab:resultsauc}, we observe an overall improvement when performing noise correction. The AUC has a slight improvement across the majority of classes. With this observation, it can be concluded that the web-crawled images retrieved in a search by image proposed methodology are so rich in terms of visual features that the effect of noise correction is only marginal when comparing BL2 and the proposed approach.

% From our experimental results, it can be concluded that 




% We can observe that adding additional web data to the original dataset results in an improvement in the classification of skin lesions. Comparing the BL1 vs BL2 gives us an improvement in the overall accuracy. These results tell us that also in medical applications, in deep neural networks it is more important to have a large dataset with great variability rather than having a small annotated dataset with perfect labels. The effect of web data can be seen in Fig \ref{fig:confinception}. Here, it can be observed that, adding the web data gives us a more pronounced diagonal in the confusion matrix.
%% resutls table 1 and 2
% \begin{table}
% \centering
% \caption{Average performance for Inception V3 architecture}
% \label{my-label}
% \begin{tabular}{lll}
% \hline
% \textbf{Model} & \textbf{Avg-Accuracy} & \textbf{Cohens Kappa} \\ \hline
% CleanNet       & 0.7125                & 0.6504                \\ \hline
% WebNet         & 0.7991                & 0.7602                \\ \hline
% GlobalWebNet   & 0.8053                & 0.7677                \\ \hline
% LocalWebNet    & \textbf{0.8053}       & \textbf{0.7681}       \\ \hline
% \end{tabular}
% \end{table}
% \begin{table}[]
% \centering
% \resizebox{\textwidth}{!}{%
% \begin{tabular}{lccccccccccc}
% \rowcolor[HTML]{C0C0C0} 
% \textbf{Model/Class}                          & \textbf{C1}     & \textbf{C2}     & \textbf{C3}     & \textbf{C4} & \textbf{C4}     & \textbf{C5}     & \textbf{C6}     & \textbf{C7}     & \textbf{C8}     & \textbf{C9}     & \textbf{Avg} \\
% \cellcolor[HTML]{FFFFFF}\textbf{CleanNet}        & 0.897          & 0.942          & 0.975          & 0.982      & 0.936          & 0.954          & 0.979          & 0.926          & 0.933          & 0.872          & 0.712                \\
% \rowcolor[HTML]{EFEFEF} 
% \textbf{WebNet}                               & 0.872          & 0.955          & 0.994          & 0.966      & 0.967          & 0.984          & \textbf{0.987} & \textbf{0.991} & \textbf{0.974} & 0.934          & 0.799                \\
% \cellcolor[HTML]{FFFFFF}\textbf{GlobalWebNet} & \textbf{0.919} & \textbf{0.965} & \textbf{0.994} & 0.967      & \textbf{0.972} & 0.985          & 0.982          & 0.990          & 0.961          & \textbf{0.956} & \textbf{0.805}                \\
% \cellcolor[HTML]{FFFFFF}
% % \textbf{LocalWebNet}                          & 0.866          & 0.958          & 0.992          & 0.973      & 0.958          & \textbf{0.989} & 0.985          & 0.972          & 0.955         & 0.949          & \textbf{0.805}      
% \end{tabular}}
% \caption{\small{Results showing the AUC for each class and the average overall accuracy for every model}}
% \label{tab:resultsauc}
% \end{table}
\begin{table}[t]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{c|c|c|c|c|c|c|c|c|c|c|c}
                  & C1              & C2              & C3              & C4              & C5              & C6              & C7              & C8              & C9              & C10             & Avg AUC         \\ \hline
Class \% in train & 3.42            & 18.49           & 4.96            & 7.53            & 5.99            & 5.82            & 25.51           & 1.17            & 19.86           & 6.67            & -               \\ \hline
BL1               & 0.898          & 0.943          & 0.976          & \textbf{0.983}          & 0.936          & 0.955          & 0.979          & 0.927          & 0.933          & 0.872          & 0.940          \\ \hline
BL2               & 0.873         & 0.955          & 0.995         & 0.966          & 0.967          & 0.984          & \textbf{0.987} & 0.991 & \textbf{0.975} & 0.935         & 0.963         \\ \hline
Proposed               & \textbf{0.920} & \textbf{0.966} & \textbf{0.995} & 0.968 & \textbf{0.972} & \textbf{0.985} & 0.983          & \textbf{0.991}          & 0.961          & \textbf{0.957} & \textbf{0.970} \\ \hline
\end{tabular}}
\caption{\small{Results showing the AUC for each class and the average overall accuracy for every model.}}
\label{tab:resultsauc}
\vspace{-25pt}
\end{table}

% \begin{figure}[H]
%     \centering
%     \begin{minipage}{0.5\textwidth}
%         \centering
%         \includegraphics[width=0.9\textwidth]{images/cm_normv1}
%         \caption*{CleanNet}
%     \end{minipage}
% % 	\hspace{-0.9cm}
% %     \begin{minipage}{0.25\textwidth}
% %         \centering
% %         \includegraphics[width=0.9\textwidth]{images/cm_normv8}
% %         \caption*{WebNet}
% %     \end{minipage}
% 	\hspace{-0.9cm}
%     \begin{minipage}{0.5\textwidth}
%         \centering
%         \includegraphics[width=0.9\textwidth]{images/cm_normv6}
%         \caption*{GlobalWebNet}
%     \end{minipage}
% % 	\hspace{-0.9cm}
% %     \begin{minipage}{0.25\textwidth}
% %         \centering
% %         \includegraphics[width=0.9\textwidth]{images/cm_normv7}
% %         \caption*{LocalWebNet}
%     %\end{minipage}
    
%     \begin{minipage}{0.5\textwidth}
% \begin{center}
% \includegraphics[width=\textwidth]{images/visualv3_clean.png}
% \end{center}
% % \caption*{\textbf{CleanNet}}
% \end{minipage}\hfill
% \begin{minipage}{0.5\textwidth}
% \begin{center}
% \includegraphics[width=\textwidth]{images/visualv3_global.png}
% \end{center}
% % \caption*{\textbf{LocalWebNet}}
% \end{minipage}
%     \caption{Confusion Matrices for the four baselines in Inception V3}
%     \label{fig:confinception}
% \end{figure}

% \begin{table}
% \centering
% \caption{Average performance for MobileNet architecture}
% \label{asa}
% \begin{tabular}{lll}
% \hline
% \textbf{Model} & \textbf{Avg-Accuracy} & \textbf{Cohens Kappa} \\ \hline
% CleanNet       & 0.7944                & 0.7549                \\ \hline
% WebNet         & \textbf{0.8114}       & \textbf{0.7752}       \\ \hline
% GlobalWebNet   & 0.7805                & 0.7396                \\ \hline
% LocalWebNet    & 0.8053                & 0.7690                \\ \hline
% \end{tabular}
% \end{table}

% \noindent
% \textbf{Effect of Noise Correction}: 


% We also analyze the effect of the noise correction approach proposed by Patrini \emph{et. al}. It can observed that, BL3 outperform BL2 in the classification performance with a slight improvement. The experimental results tell us that having a noise correction approach to deal with noisy labels has a positive effect on deep neural networks in the skin lesion classification task. When we take a look at the Cohens Kappa measure we can observe that for high imbalance problems the noise correction works slightly better. 

% \begin{figure}[H]
%     \centering
%     \begin{minipage}{0.25\textwidth}
%         \centering
%         \includegraphics[width=0.9\textwidth]{images/cm_normm1}
%         \caption*{CleanNet}
%     \end{minipage}
%     \hspace{-0.9cm}
% % 	\hfill
%     \begin{minipage}{0.25\textwidth}
%         \centering
%         \includegraphics[width=0.9\textwidth]{images/cm_normm8}
%         \caption*{WebNet}
%     \end{minipage}
%     \hspace{-0.9cm}
% % 	\hfill
%     \begin{minipage}{0.25\textwidth}
%         \centering
%         \includegraphics[width=0.9\textwidth]{images/cm_normm6}
%         \caption*{GlobalWebNet}
%     \end{minipage}
%     \hspace{-0.9cm}
% % 	\hfill
%     \begin{minipage}{0.25\textwidth}
%         \centering
%         \includegraphics[width=0.9\textwidth]{images/cm_normm7}
%         \caption*{LocalWebNet}
%     \end{minipage}
%     \caption{Confusion Matrices for the four baselines in MobileNet architecture}
%     \label{fig:confmobile}
% \end{figure}
% Taking a look at the embedding space for the BL1 and the BL3. We can observe that when adding the web data into the network together with the proposed loss function results in a better clustering. It is  clearly seen that the class represented in yellow is incorrectly classified in the BL1 embedding space, while the samples are properly cluster in the BL3. We can also identify that the black and gray class are not properly cluster in the BL1 while in the proposed approach (BL3), these classes are well separated.  

\section{Conclusions}
In this work, we have demonstrated for the first time the effectiveness of webly supervised learning for the task of skin lesion classification. We demonstrate that WSL can be very effective for training in limited data regimens with high-class imbalance as web data can augment under-represented classes and boost the model performance. 
By crawling the web through search by image to generate the web-dataset, we induce high search specificity and effectively minimize the influence of cross-domain noise. The proposed noise correction approach by modeling cross-category noise helps in learning an effective network initialization from web data. 

\noindent
\textbf{Acknowledgements.} The authors gratefully acknowledge CONACYT for the financial support.
This research has been funded by the Bayerische Forschungsstiftung (BSF).


% in skin lesion classification. The proposed method to retrieve data from the web has shown to reduce cross-domain noise, which is a challenging problem in webly supervised learning. In the same manner,  leveraging a noise correction approach to learn under label noise settings has resulted in the best classification performance in the ten-class skin categorization task.
\begin{thebibliography}{50}
%

% \bibitem {cancerfacts}
% American Cancer Society.:
% Facts and Figures (2018)
%%%% 1
\bibitem {resnet}
He, K., Zhang, X., Ren, S. and Sun, J.:
Deep residual learning for image recognition. In CVPR, 2016
%%%% 2
\bibitem {inceptionv3}
Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J. and Wojna, Z.:
Rethinking the inception architecture for computer vision. In CVPR, 2017
%%%% 3
\bibitem {inceptionv4}
Szegedy, C., Ioffe, S., Vanhoucke, V. and Alemi, A.A.:
Inception-v4, inception-resnet and the impact of residual connections on learning. In AAAI, 2017
%%%% 4
\bibitem {webdata2}
DermQuest: https://www.dermquest.com/

%%%% 5
\bibitem {tmi1}
Yu, L., Chen, H., Dou, Q., Qin, J. and Heng, P.A.:
Automated melanoma recognition in dermoscopy images via very deep residual networks. IEEE TMI, 2017


%%%% 6
\bibitem{isicpaper1}
Matsunaga, K., Hamada, A., Minagawa, A. and Koga, H.:
Image classification of melanoma, nevus and seborrheic keratosis by deep neural network ensemble. arXiv:1703.03108 (2017)

%%%% 7
\bibitem {isbi1}
Codella, N.C., Gutman, D., Celebi, M.E., Helba, B., Marchetti, M.A., Dusza, S.W., Kalloo, A., Liopyris, K., Mishra, N., Kittler, H. and Halpern, A.:
Skin lesion analysis toward melanoma detection. arXiv:1710.05006 (2017)

%%%% 8
\bibitem {naturepaper}
Esteva, A., Kuprel, B., Novoa, R.A., Ko, J., Swetter, S.M., Blau, H.M. and Thrun, S.:
Dermatologist-level classification of skin cancer with deep neural networks. Nature, 2017
%%%% 9
\bibitem {clean1}
Krause, J., Sapp, B., Howard, A., Zhou, H., Toshev, A., Duerig, T., Philbin, J. and Fei-Fei, L.:
The unreasonable effectiveness of noisy data for fine-grained recognition. In ECCV, 2016.

%%%% 10
\bibitem {clean2}
Massouh, N., Babiloni, F., Tommasi, T., Young, J., Hawes, N. and Caputo, B.:
Learning deep visual object models from noisy web data: How to make it work. arXiv:1702.08513, 2017
%%%% 11
\bibitem {graphical1}
Xiao, T., Xia, T., Yang, Y., Huang, C. and Wang, X.: Learning from massive noisy labeled data for image classification. In CVPR, 2015.
%%%% 12
\bibitem {graphical2}
Vahdat, A.,. Toward robustness against label noise in training deep discriminative neural networks.In NIPS,2017
%%%% 13
\bibitem {robust1}
Sukhbaatar, S. and Fergus, R.:
Learning from noisy labels with deep neural networks. arXiv:1406.2080, 2(3), p.4., 2014
%%%% 14
\bibitem {robust2}
Patrini, G., Rozza, A., Menon, A., Nock, R. and Qu, L.:
Making neural networks robust to label noise: a loss correction approach. arXiv:1609.03683, 2016
%%%% 15
\bibitem {webly1}
Chen, X. and Gupta, A.:
Webly supervised learning of convolutional networks. In ICCV, 2015
%%%% 16
\bibitem {webly2}
Oquab, M., Bottou, L., Laptev, I. and Sivic, J.:
Is object localization for free?-weakly-supervised learning with convolutional neural networks. In CVPR, 2015
%%%% 17
\bibitem {dermofit}
Ballerini, L., Fisher, R.B., Aldridge, B. and Rees, J.:
A color and texture based hierarchical K-NN approach to the classification of non-melanoma skin lesions. In Color Medical Image Analysis, 2013
%%%% 18
\bibitem {tensorflow}
M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro \textit{et al.}:
TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems. CoRR abs/1603.04467 2016


% \bibitem {webdata1}
% DermNet New Zealand: https://www.dermnetnz.org/

% \bibitem {webdata3}
% Dermnet, Skin Disease Atlas: http://www.dermnet.com

% \bibitem {mobilenets}
% Howard, A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M. and Adam, H.:
% Mobilenets: Efficient convolutional neural networks for mobile vision applications. arXiv preprint arXiv:1704.04861, 2017


\end{thebibliography}

\end{document}

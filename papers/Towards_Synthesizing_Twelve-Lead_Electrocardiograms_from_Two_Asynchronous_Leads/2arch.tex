\begin{figure*}[h]
\centering
\includegraphics[width=0.75\textwidth]{fig/0523_arch.pdf}
\caption{ECGT2T model architecture. The model is comprised of style, mapping, generative, and discriminative networks. Each network is built with residual blocks. $L_{adv}$ is the adversarial objective, $L_{rec}$ is the reconstruction objective, $L_{con}$ is the lead consistency objective, and $L_{sty}$ is the style consistency objective.}
\label{fig:arch}
\end{figure*}

Figure~\ref{fig:arch} illustrates the ECGT2T architecture. The model consists of \textit{style} ($S(\cdot)$), \textit{mapping} ($M(\cdot)$), \textit{generative} ($G(\cdot)$), and \textit{discriminative} ($D(\cdot)$) networks. The style network represents the cardiac styles for ten output leads based on the styles of the two input leads. The mapping network, as seen in previous image style transfer models~\cite{kar2019}, generates latent codes for a random variable. The generative network takes any single lead, generates its respective latent code, and reconstructs the leads with a cardiac style. To improve the efficiency of this network, we use an adaptive instance normalization layer~\cite{hua17}. The discriminative network distinguishes whether its inputs are real or not. Each network is built by stacking multiple residual blocks~\cite{he16}.



% % This encodes two cardiac styles for given leads $c_{x_{i}}\in C$ for a corresponding lead using two leads (namely, $c_{x_{i}}=R(x_{I,II})$). 
% It consists of three modules where two reference, an encoding, and multiple lead-specific modules. Each reference network extracts features from I \& II, respectively. 
% The encoding network captures the heart condition representation for all leads from an input concatenated with two features. Each lead-specific network encodes a representation of the heart condition $c_{x_{i}}$ corresponding to lead $x_{i}$.

% \textit{Mapping network $M(\cdot)$}
% It is devised in \cite{kar2019,choi20} for the efficient style translation. We adopt another network to represent the cardiac styles $\Tilde{c}_{x_{i}}\in \Tilde{C}$ for ten respective leads from a random variable $z\in Z$, instead of two given leads ($\Tilde{c}_{x_{i}}=M(z, i)$). It represents the latent code using the multi-layer perceptron, and then conditionally generate $\Tilde{c}_{x_{i}}$ on the corresponding style encoding block. This network makes style network $S(\cdot)$ to be robust by influencing generated styles.


% 

% \textit{Discriminative network $D(\cdot)$} It is the network typically used in GAN~\cite{mir14} which distinguishes whether its inputs are real or not ($ y = D(\Tilde{x_{i}},x_{i})$). It is composed to multiple discriminators as many as the number of leads to be generated.








\subsection{Objectives}

The full objective for ECGT2T is expressed as follows :
\begin{align*}
    \min_{E,H,G} \max_{D} \lambda_{adv} L_{adv} + \lambda_{rec} L_{rec}
    + \lambda_{con} L_{con} + \lambda_{sty} L_{sty} 
\end{align*}
where $\lambda$ and $L$ are the are the hyperparameters and losses for the respective objective.


The \textit{adversarial} objective is the mean of the log probability for original leads $D(x_{i})$ and the mean of the log of the inverted probabilities of the generated samples $D(G(x_{I},c_{i}))$:
\begin{align*}
    L_{adv} = \mathbb{E}_{x_{i}}[\log{D(x_{i})}] + \mathbb{E}_{x_{I},c_{i}}[\log{(1-D(G(x_{I},c_{i})))}]
\end{align*}
where $i$ is randomly selected lead that isn't Lead I or Lead II.

The \textit{reconstruction} objective compares an alternatively chosen Lead I or Lead II with a randomly selected lead $j$ via mean squared error:
\begin{align*}
    L_{rec} = \mathbb{E}_{x_{i},x_{j},c_{j}}[(x_{j} - G(x_{i},c_{j}))^2]
\end{align*}

The \textit{lead consistency} objective ensures that generated leads are consistent regardless of whether Lead I or Lead II was used as input.  For any randomly selected lead $i$ from Lead III to V6, the lead consistency objective is the mean squared error of the generated Lead I $G(x_{I},c_{i})$ and generated Lead II $G(x_{II},c_{i})$:
\begin{align*}
    L_{con} = \mathbb{E}_{x_{I},x_{II},c_{i}}[(G(x_{I},c_{i}) - G(x_{II},c_{i}))^2]
\end{align*}

To account for the diversity in  cardiac rhythm and beat shapes, we include the \textit{style consistency} objective as a form of regularization. This objective is the mean absolute error of the derived style $S(x_{I,II}, i)$ and mapping network output $M(z, i)$:
\begin{align*}
    L_{sty} = \mathbb{E}_{i,z,x_{I,II}}[||(M(z, i) - S(x_{I,II}, i))||_{1}]
\end{align*}
where $z$ is a random variable and $i$ is randomly selected from Lead III to V6.

\subsection{Training Procedure}
Adam optimization~\cite{kin14} with the learning rate of style, mapping, generative, and discriminative networks set to $3e^{-4}$, $1e^{-4}$, $3e^{-4}$, and $1e^{-4}$, respectively, and weight decay for all networks set to $1e^{-4}$. $\lambda_{rec}$ is set to 2, while the $\lambda$s for the other objectives are set to 1. All style latent vectors were set to size 512. The models used in this study are implemented with PyTorch and executed on a server equipped with Intel Xeon Silver 4210, 256 GB memory, and four NVIDIA RTX 3090 GPUs with 24 GB VRAM. We trained generative models (ECGT2T and ECGS2E) over seven days, and selected the model with the lowest loss.



\begin{figure*}[h]
\centering
\begin{subfigure}{.49\textwidth}
    \includegraphics[width=0.99\textwidth]{fig/10072Norm.pdf}
    
    \caption{Normal sample from the PTB-XL dataset}\label{fig:ptb-norm}
\end{subfigure} 
\begin{subfigure}{.49\textwidth}
    \includegraphics[width=0.99\textwidth]{fig/6842CASE.pdf}
    
    \caption{Myocardial infarction sample from the PTB-XL dataset}\label{fig:ptb-case}
\end{subfigure} \\
\begin{subfigure}{.49\textwidth}
    \includegraphics[width=0.99\textwidth]{fig/5443Norm.pdf}
    
    \caption{Normal sample from the CUSPH dataset}\label{fig:chap-norm}
\end{subfigure}
\begin{subfigure}{.49\textwidth}
    \includegraphics[width=0.99\textwidth]{fig/1258CASE.pdf}
    \caption{Atrial fibrillation sample from the CUSPH dataset}\label{fig:chap-case}
\end{subfigure}
\caption{12-lead electrocardiogram samples over a two second window. For each subplot, the black line denotes the original signal while the \textcolor{blue}{blue} and \textcolor{red}{red} lines represent the signals generated by \textcolor{blue}{ECGT2T}, and \textcolor{red}{ECGS2E} respectively. ECGS2E takes in only Lead I as input and outputs 11 leads, while ECGT2T takes asynchronous Lead I and Lead II inputs and generates signals for 10 leads. Although ECGT2T uses two asynchronous leads, all leads are visualized synchronously for convenience.
}
\label{fig:gen-ptb}
\end{figure*}

\subsection{Detecting signals through hypothesis testing}
\label{s:detection}

\subsubsection{Monte Carlo envelope tests}
\label{s:alpha}
In Section~\ref{s:LAndK}, we reviewed some popular functional statistics for
stationary isotropic point processes. We focus here on $L$, the
variance-stabilized version of Ripley's $K$ function, and the empty space
function $F$, see Section~\ref{s:spatial}. We follow classical Monte Carlo testing methodology
based on functional statistics, which we now sketch, see e.g. \citep{BDHLMN14}
for a less concise introduction. 

The methodology is independent of the test statistic used, so we introduce it
for a general functional statistic $r\mapsto S(r)$, which we later instantiate
to be $L$ or $F$. Let $\hat S$ denote an
empirical estimate obtained from the spectrogram of data, possibly using edge corrections, see \citep{MoWa03}.
Let $S_0$ be the theoretical functional statistic corresponding to complex white noise. For
$S=L$, $L_0$ can be easily computed from \eqref{e:pairCorrelation}. Note that
our noise is real white noise in the applications, but we approximate the corresponding
2-point correlation function by that of complex white noise far from the real axis, as explained in Section~\ref{s:GAFapproxSYM}. Detection of
signal over white noise can be formulated as testing the hypothesis $H_0$ that
$\hat S$ was built from a realization of a real white noise, versus the
alternate hypothesis $H_1$ that it was not. To do this, we review Monte Carlo
envelope-based hypothesis tests, which are popular across applications. 

In a Monte Carlo envelope test, we define a test statistic $T\in\mathbb{R}$ that
summarizes the difference $r\mapsto S(r)-S_{0}(r)$ in a
single real number, for instance a norm 
\begin{equation}
\label{e:norms}
T_\infty= \sup_{r\in [r_{\min},r_{\max}]}\vert S(r)-S_0(r)\vert\qquad\text{  or
}\qquad T_2=\sqrt{\int_{r_{\min}}^{r_{\max}} \vert S-S_0\vert^2}.
\end{equation} 
Let $t_{\text{exp}}$ denote the realization of $T$ corresponding to the experimental data to be
analyzed. The test consists in simulating $m$ realizations of white noise,
obtaining the corresponding functional statistics estimates $S_1,\dots,S_m$,
computing the realizations $t_1,\dots,t_m$ of the test statistic, and rejecting $H_0$ whenever
the observed $t_{\text{exp}}$ is larger than the $k$-th largest value among
$t_1,\dots,t_m$. Without loss of generality, we assume $t_1,\dots,t_m$ are
in decreasing order, so that $t_k$ is the $k$-th largest. Symmetry
considerations show that this test has significance level $\alpha=k/(m+1)$. When
$S_0$ is not available in closed form, one can replace it by a pointwise average
\begin{equation}
\label{e:average}
\bar{S}_0(r) = \frac{1}{m+1}(S_1(r)+\dots+S_m(r)+\hat{S}(r))
\end{equation}
while preserving the significance level, see \citep{BDHLMN14}.

To see why this test is called an \emph{envelope test}, let $k=10$ and
$m=199$ so that $\alpha=0.05$. We use as a signal a synthetic chirp plus white
noise as in Figure~\ref{f:testPower}, with SNR$=20$. In Figure~\ref{f:envelope}, we take
$r_{\min}=0$ and let $r_{\max}$ vary, showing for each $r_{\max}$ the corresponding $t_{k}$ as the upper limit of the green
shaded envelope. The black line shows $t_{\text{exp}}$ at each $r_{\max}$, for the
same realizations of the tested signal and the white noise spectrograms. To
interpret this plot, imagine the user had fixed $r_{\max}$ to some value, then
he would have rejected $H_0$ if and only if the corresponding intersection of
the black line with $r=r_{\max}$ was above the green area. Note that the
significance of the test in only guaranteed if $r_{\max}$ is fixed prior to
observing data or simulations. Still, Figure~\ref{f:envelope} gives a heuristic
to identify characteristic \emph{scales of interaction} after $H_0$ is rejected.
For instance, characteristic scales could be values of $r_{\max}$ where the data
curve in black leaves the green envelope\footnote{Caveats have been issued against overinterpreting these scales of
  interaction, see \citep{BDHLMN14}.}. The user can thus identify regions of the
spectrogram that possibly correspond to signal (defined as "different from white
noise"). 
To illustrate this, consider again both plots of
Figure~\ref{f:envelope}. There is a hint of an interaction --~an excess or
deficit of pairs-- between
$r_{\max}=0.5$ and $r_{\max}=1$, and this interaction cannot be explained by
noise only. Although we do not delve further here and rather focus on how the
power of the test varies with parameters, this scale can be used to
filter out the noise, in the manner of the Delaunay-based filtering of \cite{Fla15}.
%In
%Figure~\ref{f:}, we plot the spectrogram of the signal\note[RB]{Here whe should
%  have a figure with red circles if it is easy to have one} and highlight the
%pairs of zeros that are at a distance between $0.5$ and $1$. Clearly, the chirp
%is located in the highlighted area. There are various ways to extend this
%procedure by locating the signal and make it a reconstruction algorithm, which
%we leave to future work. Note also that the whole procedure is just a spatial statistics-flavoured take on the Delaunay-based filtering of \cite{Fla15}.

\begin{figure}
\subfigure[$T_\infty$]{
\includegraphics[width=\twofig]{\figdir/envelopeRepTinfstat.pdf}
\label{e:envelpe:tinf}
}
\subfigure[$T_2$]{
\includegraphics[width=\twofig]{\figdir/envelopeRepT2stat.pdf}
\label{e:envelpe:t2}
}
\caption{Envelope plots for the detection test of Section~\ref{s:detection} for
  the supremum and 2-norm of the deviation of the $L$ functional statistic from
  its pointwise average \eqref{e:average}.}
\label{f:envelope}
\end{figure}

\subsubsection{Assessing the power of the test}
\label{s:beta}
The significance $\alpha$ of the test --~the probability of rejecting $H_0$
while $H_0$ is true~-- is fixed by the user as in Section~\ref{s:alpha}. It
remains to investigate the power $\beta$ of the test, that is, the probability
of rejecting $H_0$ when one should. Following Section~\ref{s:signalplusnoise},
we expect $\beta$ to increase with SNR, which should be large enough to ``push''
zeros away from the time-frequency support of the signal to be detected. We also
expect the power to be larger when the observation window is not too much larger
than the time-frequency support $A_S$ of the signal.

% SNR, so that to decrease when the 
% We expect $\beta$ to depend on the bias and variance of $\hat{S}$ under $H_0$:
% the green area in Figure~\ref{f:envelope} should be of small width. This width
% diminishes as the size $N$ of the observation window in Figure~\ref{f:} grows.
% Yet at the same time, if we are to detect deficits or excesses of pairs of
% points using cumulative statistics like the $L$ or $F$ function in
% Section~\ref{s:spatial}, then the number of pairs that contribute to departing
% from $H_0$ should be large enough when compared to the total number of pairs.
% In practice, SNR should thus be large enough to ``push'' zeros away
% from the time-frequency support of the signal to be detected. Also, the size of
% the observation window should not be too large compared to the characteristic
% size of this support.

We back these claims by the experiment in Figure~\ref{f:testPower}, where we
assume signals take the form of linear chirps. Still taking $m=199$ and $k=10$,
so that $\alpha=0.05$, we build each of the six panels as follows: we simulate a
mock signal made using a linear chirp plus noise, with SNR indicated on the
plot, growing from left to right. We then repeat $200$ times: 1) simulate $m$
white noise spectrograms, 2) check wether $H_0$ is rejected for each value
of $r_{\max}$. We can thus estimate the probability $\beta$ of rejecting $H_0$
for various choices of $r_{\max}$ the user could have made. We plot both the
power using $S=L$ or $S=F$, choosing the $2-$norm in \eqref{e:norms} and the
empirical average \eqref{e:average}. We estimate the functional statistics using the \texttt{spatstat} R
package\footnote{Version 1.51-0, see \url{http://spatstat.org/}}. To identify
the statistical significance of our estimated powers, we plot Clopper-Pearson
confidence intervals for $5$ values of $r_{\max}$, using a Bonferroni correction for the $10$ multiple tests involved
on each plot, see e.g. \cite{Was13}. Finally, the top row of
Figure~\ref{f:testPower} corresponds to a signal support that matches the size of
the observation window, while the bottom row is half that. On each panel, an inlaid plot
depicts the spectrogram for one realization of the signal corrupted by white
noise. Spectrogram zeros are in white.

\begin{figure}
%\includegraphics[width=\threefig]{\figdir/testpowerSNR2_spread05.pdf}
%\includegraphics[width=\threefig]{\figdir/testpowerSNR5_spread05.pdf}
%\includegraphics[width=\threefig]{\figdir/testpowerSNR20_spread05.pdf}\\
%\includegraphics[width=\threefig]{\figdir/testpowerSNR2_spread1.pdf}
%\includegraphics[width=\threefig]{\figdir/testpowerSNR5_spread1.pdf}
%\includegraphics[width=\threefig]{\figdir/testpowerSNR20_spread1.pdf}\\
\includegraphics[width=\threefig]{\figdir/testpowerSNR1_spread1.pdf}
\includegraphics[width=\threefig]{\figdir/testpowerSNR5_spread1.pdf}
\includegraphics[width=\threefig]{\figdir/testpowerSNR10_spread1.pdf}\\
\includegraphics[width=\threefig]{\figdir/testpowerSNR1_spread0p5.pdf}
\includegraphics[width=\threefig]{\figdir/testpowerSNR5_spread0p5.pdf}
\includegraphics[width=\threefig]{\figdir/testpowerSNR10_spread0p5.pdf}

\caption{
Assessing the power of the test on detecting a linear chirp with various SNRs
across columns. The top row corresponds to a larger support of the chirp
compared to the observation window.
\label{f:testPower}
}
\end{figure} 

The results confirm our intuitions: power increases with SNR, and decreases as
the size of the support of the signal diminishes with respect to the observation
window. In all experiments, the best power is obtained by taking $r_{\max}$ to
be as large as possible, which here means half of the observation window. This
makes sure that as many points/pairs as possible enter the estimation of the functional
statistic $S$. Concerning the choice of functional statistic, the empty space
function $F$ performs significantly better for high SNR and large enough
$r_{\max}$. The green peaks of power at low $r_{\max}$ for some combinations of
SNR and support are due to the excess of small pairwise distances introduced by
the chirp signal. The power vanishes quickly once larger pairwise distances are
considered, due to the cumulative nature of $L$. It is hard to rely on these
peaks as they do not appear systematically and would require a careful hand-tuning of
$r_{\max}$ that would likely defeat our purpose of automatizing detection. So overall, we would recommend using
$F$ and large $r_{\max}$, which appears to be a robust best choice. We also
found (not shown) first that $F$ is superior or equal to the other
functional statistics described in Section~\ref{s:spatial} for chirp detection. Second, we found that the tests using the average \eqref{e:average}
are consistently more powerful than those using the analytic form $L_0$ of
$L$. We believe this is due to the edge correction that is implicitly made in
\eqref{e:average}, while the analytic $L_0$ corresponds to an infinite
observation window. Third, we also observed the $2-$norm in \eqref{e:norms} to
be consistently more powerful than the supremum norm.


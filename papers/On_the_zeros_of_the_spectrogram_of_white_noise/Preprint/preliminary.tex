In this section, we survey the relevant notions
from signal processing, probability, and spatial statistics. 

\subsection{The short-time Fourier transform}
\label{s:stft}
Let $f,g\in L^2(\mathbb{R})$, the evaluation at $(u,v)\in\mathbb{R}^2$ of the
short-time Fourier transform (STFT) of $f$ with \emph{window} $g$ reads
\beq
 V_g f (u,v) = \int f(t) \overline{g(t-u)} e^{-2i\pi tv}dt = \langle f, M_v T_u g \rangle,
\label{e:stft}
\eeq
with $\langle \cdot,\cdot\rangle$ denoting the inner product in
$L^2(\mathbb{R})$, $M_vf =
e^{2i\pi v\cdot}f(\cdot)$ and $T_uf = f(\cdot-u)$. We copy our notation from \citep[Chapter 3]{Gro01}, to which
we refer for a thorough introduction. The squared modulus of the STFT
\eqref{e:stft} is called a
\emph{spectrogram}, and it is commonly interpreted as a measure of the
content of the signal $f$ around time $u$ and frequency $v$. In contrast, the
usual Fourier transform only provides the \emph{global} frequency content of
a signal, that is, not localized in time.

The right-hand side of \eqref{e:stft} allows a natural extension of the STFT to
tempered distributions, see \citep[Section 3.1]{Gro01}. This is relevant to us,
as white noise will be defined in Sections~\ref{s:real} and \ref{s:complex} as a random tempered
distribution.

\subsection{The Bargmann transform}
\label{s:bargmann}

Let $a>0$ and consider the Gaussian window $g_a(x) \propto \exp(-\pi a^2 x^2)$, normalized so
that $\Vert g_a\Vert_2=1$. When $a=1$, we drop the subscript and write $g(x) = g_1(x) = 2^{1/4}e^{-\pi x^2}$.

We closely follow the textbook by \cite{Gro01}, only introducing arbitrary window
width, and gather the important result in the following proposition.
\begin{prop}{\cite[Section 3.4]{Gro01}}
Let $f\in L^2(\mathbb{R})$, $u,v\in\mathbb{R}$ and $z=au+i\frac{v}{a}$, then
\begin{eqnarray}
V_{g_a}(f)(u,-v) &\propto&  e^{-i\pi uv}e^{-\frac{\pi}{2}\vert z\vert^2} B\left( f(\cdot/a)
          \right)(z),\label{e:bargmann}
\end{eqnarray}
where the Bargmann transform $B$ is defined by
$$
Bf(z) = 2^{1/4}\int f(t)e^{2\pi tz-\pi t^2-\frac{\pi}{2}z^2}dt.
$$
\end{prop}

\begin{proof}
The particular shape of the window allows us to write
\begin{eqnarray*}
V_{g_a}(f)(u,v) &\propto& \int f(t)e^{-\pi a^2(t-u)^2}e^{-2i\pi tv}dt\\
&=& \int f(t) e^{-\pi a^2t^2}e^{-\pi a^2u^2}e^{2a^2\pi tu}e^{-2i\pi vt}dt\\
&=& e^{-i\pi uv} e^{-\frac{\pi}{2}(a^2u^2+\frac{v^2}{a^2})}\int f(t) e^{-\pi a^2
    t^2}e^{2a\pi t(au-i\frac{v}{a})} e^{-\frac{\pi}{2}(au-i\frac{v}{a})^2}dt.
\end{eqnarray*}
Making the change of variables $s=at$ and denoting
\begin{equation}
z=au+i\frac{v}{a},
\label{e:complexTiling}
\end{equation}
 we obtain
\begin{eqnarray*}
V_{g_a}(f)(u,v) &\propto& e^{-i\pi uv}e^{-\frac{\pi}{2}\vert z\vert^2}\int
                          f\left(\frac{s}{a}\right)e^{-\pi s^2}e^{2\pi s \bar{z}}e^{-\frac{\pi}{2}\bar{z}^2}ds,
\end{eqnarray*}
or equivalently 
\begin{eqnarray}
V_{g_a}(f)(u,-v) &\propto& e^{-i\pi uv}e^{-\frac{\pi}{2}\vert z\vert^2}\int
                          f\left(\frac{s}{a}\right)e^{-\pi s^2}e^{2\pi s
                           z}e^{-\frac{\pi}{2}z^2}ds\nonumber\\
&\propto& e^{-i\pi uv}e^{-\frac{\pi}{2}\vert z\vert^2} B\left( f(\cdot/a)
          \right)(z),\label{e:bargmann}
\end{eqnarray}
where we have defined the Bargmann transform by
$$
Bf(z) = 2^{1/4}\int f(t)e^{2\pi tz-\pi t^2-\frac{\pi}{2}z^2}dt.
$$
\end{proof}
Equation \eqref{e:bargmann} tells us that the zeros of the spectrogram
$u,v\mapsto \vert V_{g_a}(f)(u,v)\vert^2$ are those of the Bargmann transform
of $s\mapsto f(s/a)$. Moreover, Equation~\eqref{e:bargmann} also readily extends
to tempered distributions.

\subsection{Hermite functions}
\label{s:hermite}
Some functions turn out to have a very simple closed-form Bargmann transform. Informally, if we had an
orthonormal basis of $L^2(\mathbb{R})$ formed by such functions, then we could
decompose a white noise onto this basis, and easily compute the STFT of white
noise using closed-form Bargmann transforms. We now introduce Hermite functions,
which will play this exact role in later sections.

Let $H_n$ be the orthonormal polynomials with respect to the Gaussian window $g$, usually called the Hermite
polynomials in the literature \citep{Gau04}. Then, making the change of variables $x'=ax$, it comes
$$
\int H_k(ax)H_\ell(ax)g_a(x)d x \propto \int H_k(x') H_\ell(x')
g(x') d x' =
\delta_{k\ell}.
$$
The Hermite functions $h_{a,k} \propto H_k(a\cdot) \sqrt{g_a(\cdot)}$, normed
so that $\Vert h_{a,k}\Vert_2 =1$, form an orthonormal basis of
$L^2(\mathbb{R})$ \citep{Gau04}. When
$a=1$, we again drop a subscript and denote $h_k=h_{1,k}$. To compute the STFT of
an Hermite function using \eqref{e:bargmann}, first note that for all $s$,
$h_{a,k}(s/a) \propto h_{k}(s)$,
so that
\begin{eqnarray*}
V_{g_a}(h_{a,k})(u,-v) &\propto& e^{-i\pi uv}e^{-\frac{\pi}{2}\vert z\vert^2} B(h_k)(z)\\
&=& e^{-i\pi uv}e^{-\frac{\pi}{2}\vert z\vert^2} \frac{\pi^{k/2}z^k}{\sqrt{k!}},
\end{eqnarray*}
see \cite[Section 3.4]{Gro01} for the last equality. 

\subsection{Point processes on $\mathbb{C}$}
\label{s:spatial}
The zeros of the spectrogram of a random signal form a \emph{point process}. Formally, a point process over $\mathbb{C}$ is a probability distribution over configurations of
points in $\mathbb{C}$, i.e., unordered sets of complex numbers. In particular,
the cardinality of a realization of a point process is random. In this section,
we introduce point processes and basic descriptive statistics.

\subsubsection{Generalities}
The simplest point process over $\mathbb{C}$ is the Poisson point process with constant rate
$\lambda\in\mathbb{R_+}$. It is defined as the unique point process
such that, for any $B\in\mathbb{C}$ with finite Lebesgue measure $\vert B\vert$,
$(i)$ the number of points in
$B$ is a Poisson random variable with mean $\lambda\vert B\vert$, and $(ii)$
conditionally on the number of points in $B$, the points are drawn independently
from the uniform measure on $B$. For existence and further properties, see e.g.
\cite[Chapter 3]{MoWa03}. 

More general point processes can be characterized by their $k$-point correlation functions
$\rho^{(k)}$ for $k\geq 1$, informally defined by
\begin{equation}
\rho^{(k)}(x_1,\dots,x_k)dx_1\dots dx_k = \mathbb{P}\begin{pmatrix}\text{There are at least $k$ points, one in each of the}\\
\text{infinitesimal balls $B(x_i, dx_i), i=1,\dots,k$}\end{pmatrix},
\label{e:correlationFunctions}
\end{equation}
for all $x_1,\dots,x_k$ in $\mathbb{C}$, see \cite[Section 5.4]{DaVe03} for a
rigorous treatment. Of particular interest to us will be the first and
second-order interaction between the points in a realization of a point process,
encoded by $\rho^{(1)}$ and $\rho^{(2)}$, respectively.

The first order correlation function $\rho^{(1)}$ is often called the intensity of the point process, for it yields, when
integrated over a Borel set $B\subset \mathbb{C}$, the average number of points
falling in $B$ under the point process distribution. For the Poisson point
process with constant rate $\lambda$, for instance, the intensity is precisely
$\lambda$, and thus constant over $\mathbb{C}$. 

The two-point correlation function $\rho^{(2)}$ is often renormalized to obtain
the so-called \emph{pair correlation function} $$ g(x,y) =
\frac{\rho^{(2)}(x,y)}{\rho^{(1)}(x)\rho^{(1)}(y)},$$ see \cite[Chapter
4]{MoWa03}. For a Poisson point process with constant rate, $g$ is
identically $1$. When $g(x,y)>1$, \eqref{e:correlationFunctions} indicates that
pairs are more likely to occur around $(x,y)$ than under a Poisson process with the same intensity
function. Similarly $g(x,y)<1$ indicates that pairs are less likely
to occur. Finally, when the point process is both stationary (i.e., invariant
to translations) and isotropic (i.e., invariant to rotations), then $g$ only
depends on the distance $r=\vert x-y\vert$, and we denote it by $g_0(r)=g(x,y)$.

\subsubsection{The Ginibre ensemble}
\label{e:ginibre}
We give here another example of a point process on $\mathbb{C}$, in
order to demonstrate a non-constant pair correlation function. If
there exists a function $\kappa:\mathbb{C}\times\mathbb{C}\rightarrow \mathbb{C}$
such that the correlation functions \eqref{e:correlationFunctions} with 
\begin{equation}
\rho^{(k)}(x_1,\dots,x_k) = \det \big[\kappa(x_i,x_j)\big]_{1\leq i,j\leq k}
\label{e:dppCorrelationFunctions}
\end{equation}
consistently define a point process, then this point process is called a
\emph{determinantal} point process (DPP) with kernel $\kappa$. DPPs were first
introduced by \cite{Mac75}, and we refer the reader to \citep{HKPV06,LaMoRu14}
for modern introductions and conditions of
existence. A classical example of DPP
over $\mathbb{C}$ is the infinite Ginibre ensemble. It is defined by its kernel
$$\kappa^{\text{Gin}}(z,w) = e^{-\frac{\pi}{2}\vert z\vert^2} e^{\pi z\bar w}
e^{-\frac{\pi}{2}\vert w\vert^2}.$$
The Ginibre ensemble is stationary
and isotropic, its intensity is constant equal to 1, and its pair correlation is
$$
g_0^{\text{Gin}}(r) = 1 - e^{-\pi r^2},
$$
see \cite[Section 4.3.7]{HKPV09} for these properties, noting that our version
is rescaled to have unit intensity. We also plot
$g_0^{\text{Gin}}$ in Figure~\ref{f:rho}. Importantly for us,
$g_0^{\text{Gin}}(r)<1$ for all $r>0$, which shows that Ginibre is a
\emph{repulsive} point process: pairs are less likely than Poisson at all
scales, which we can interpret as points in a realization repelling each other.
Finally, we note that by definition \eqref{e:dppCorrelationFunctions}, if a DPP
is stationary and isotropic, and if it has an Hermitian kernel, that is $\kappa(x,y)=\overline{\kappa(y,x)}$, then $g_0<1$. 

\subsubsection{Functional statistics}
\label{s:LAndK}
We will need to investigate how repulsive a stationary and isotropic point
process on $\mathbb{C}$ like Ginibre is, given one of its realizations over a compact
window of observation. While estimators of $g_0$ have been investigated
\cite[Section 4.3]{MoWa03}, practitioners usually prefer estimating Ripley's $K$
function
$$
K(r) = 2\pi\int_{0}^r t g_0(t)dt, \quad r>0,
$$
and then the so-called \emph{variance-stabilized} $L$ functional statistic
$$
L(r) = \sqrt{K(r)/\pi},
$$
which equals $r$ for a unit rate Poisson process. $K$ is proportional to the
expected number of pairs at distance smaller than $r$. Estimating $K$ from data
is thus relatively straightforward and involves counting pairs distant from a
collection of values of $r$. Furthermore, sophisticated edge corrections have
been proposed to take into account the fact that the observation window is
necessarily bounded \cite[Section 4.3]{MoWa03}. Estimating $L$ after one has
obtained an estimate of $K$ is then
straightforward. Plotting the estimated $K$ or $L$ as a
function of $r$ allows identification of scales at which the point process is
repulsive, in the sense that we can observe a lack of pairs within a given
distance compared to a Poisson process. For instance, we plot in
Figure~\ref{f:L} the function $r\mapsto L(r)-r$ for Ginibre: there is a clear
lack of pairs at small scales, compared to the constant zero of a Poisson
process. 

\cite[Section 4.2]{MoWa03} cover many more functional statistics for stationary point processes. In particular, we mention for future reference the
so-called \emph{empty space function} $F$ and the \emph{nearest neighbour}
function $G$. For $r>0$, $F(r)$ is
defined as the probability that a ball centered at $0$ and with radius $r$
contains at least one point. Stationarity implies that the center of the ball
can be chosen arbitrarily, and $F$ thus encodes the distribution of hole sizes
in the point process. Similarly, $G$ is the cumulative distribution function of
the distance from a typical random point of the point process to its nearest
neighbour in the point process. 

%%%%%
% Let $a>0$ and consider the Gaussian window $g_a(x) \propto \exp(-\pi a^2 x^2)$, normalized so
% that $\Vert g_a\Vert_2=1$. Let $g(x) = g_1(x) = 2^{1/4}e^{-\pi x^2}$. Let $H_n$
% be the orthonormal polynomials with respect to the Gaussian window $g$, usually called the Hermite
% polynomials in the literature \citep{Gau04}. Then, making the change of variables $x'=ax$, it comes
% $$
% \int H_k(ax)H_\ell(ax)g_a(x)d x \propto \int H_k(x') H_\ell(x')
% g(x') d x' =
% \delta_{k\ell}.
% $$
% The Hermite functions $h_{a,k} \propto H_k(a\cdot) \sqrt{g_a(\cdot)}$, normed
% so that $\Vert h_{a,k}\Vert_2 =1$, form an orthonormal basis of $L^2(\mathbb{R})$. When
% $a=1$, we again drop a subscript and denote $h_k=h_{1,k}$.  



% \subsection{The STFT and the Bargmann transform}
% \label{s:bargmann}
% We closely follow \cite[Section 3.4]{Gro01}, only introducing arbitrary window
% width. We have
% \begin{eqnarray*}
% V_{g_a}(f)(u,v) &\propto& \int f(t)e^{-\pi a^2(t-u)^2}e^{-2i\pi tv}dt\\
% &=& \int f(t) e^{-\pi a^2t^2}e^{-\pi a^2u^2}e^{2a^2\pi tu}e^{-2i\pi vt}dt\\
% &=& e^{-i\pi uv} e^{-\frac{\pi}{2}(a^2u^2+\frac{v^2}{a^2})}\int f(t) e^{-\pi a^2
%     t^2}e^{2a\pi t(au-i\frac{v}{a})} e^{-\frac{\pi}{2}(au-i\frac{v}{a})^2}dt.
% \end{eqnarray*}
% Making the change of variables $s=at$ and denoting
% $z=au+i\frac{v}{a}$, we obtain
% \begin{eqnarray*}
% V_{g_a}(f)(u,v) &\propto& e^{-i\pi uv}e^{-\frac{\pi}{2}\vert z\vert^2}\int
%                           f\left(\frac{s}{a}\right)e^{-\pi s^2}e^{2\pi s \bar{z}}e^{-\frac{\pi}{2}\bar{z}^2}dt,
% \end{eqnarray*}
% or equivalently 
% \begin{eqnarray*}
% V_{g_a}(f)(u,-v) &\propto& e^{-i\pi uv}e^{-\frac{\pi}{2}\vert z\vert^2}\int
%                           f\left(\frac{s}{a}\right)e^{-\pi s^2}e^{2\pi s
%                            z}e^{-\frac{\pi}{2}z^2}dt\\
% &\propto& e^{-i\pi uv}e^{-\frac{\pi}{2}\vert z\vert^2} B(s\mapsto f(s/a)),
% \end{eqnarray*}
% where the Bargmann transform is defined as in \citep{Gro01} by
% $$
% Bf(z) = 2^{1/4}\int f(t)e^{2\pi tz-\pi t^2-\frac{\pi}{2}z^2}dt.
% $$
% In particular, for $f=h_{a,k}$ a Hermite function defined in
% Section~\ref{s:hermite}, we have for all $s$ that $h_{a,k}(s/a) \propto h_{k}(s)$,
% so that
% \begin{eqnarray*}
% V_{g_a}(f)(u,-v) &\propto& e^{-i\pi uv}e^{-\frac{\pi}{2}\vert z\vert^2} B(h_k)(z)\\
% &=& e^{-i\pi uv}e^{-\frac{\pi}{2}\vert z\vert^2} \frac{\pi^{k/2}z^k}{\sqrt{k!}},
% \end{eqnarray*}
% see \cite[Section 3.4]{Gro01} for the last equality. 

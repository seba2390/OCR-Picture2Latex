\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.

\pagestyle{plain}

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}

\usepackage{listings}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{subfigure}
\usepackage{caption}

\newcommand{\customcomment}[3]{\textcolor{#1}{#3}}
\newcommand{\wen}[1]{\customcomment{orange}{w}{#1}}
\newcommand{\ygq}[1]{\customcomment{red}{ygq}{#1}}

\newcommand{\linebreakand}{%
  \end{@IEEEauthorhalign}
  \hfill\mbox{}\par
  \mbox{}\hfill\begin{@IEEEauthorhalign}
}



\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Billion-scale Pre-trained E-commerce Product Knowledge Graph Model}

\author{
\IEEEauthorblockN{ Wen Zhang\textsuperscript{*}}
\IEEEauthorblockA{
\textit{Zhejiang University}\\
Hangzhou, China \\
wenzhang2015@zju.edu.cn\\
}
\and
\IEEEauthorblockN{Chi-Man Wong\textsuperscript{*}}
\IEEEauthorblockA{
\textit{Alibaba Group,} \\
\textit{University of Macao} \\
chiman.wcm@alibaba-inc.com \\
}
\and
\IEEEauthorblockN{ Ganqiang Ye}
\IEEEauthorblockA{
\textit{Zhejiang University}\\
Hangzhou, China \\
yeganqiang@zju.edu.cn\\
}
\and 
\IEEEauthorblockN{ Bo Wen}
\IEEEauthorblockA{
\textit{Zhejiang University}\\
Hangzhou, China \\
wenbo1@zju.edu.cn \\
}
\and
% \linebreakand
\IEEEauthorblockN{ Wei Zhang}
\IEEEauthorblockA{
\textit{Alibaba Group}\\
Hangzhou, China \\
lantu.zw@alibaba-inc.com \\
}
\and 
\IEEEauthorblockN{ Huajun Chen\textsuperscript{\textsection}}
\IEEEauthorblockA{
\textit{College of Computer Science}\\
\textit{Hangzhou Innovation Center}\\
\textit{Zhejiang University} \\
\textit{AZFT Joint Lab for Knowledge Engine} \\
huajunsir@zju.edu.cn \\
}
}
\maketitle
\begingroup\renewcommand\thefootnote{*}
\footnotetext{Equal contribution.}
\begingroup\renewcommand\thefootnote{\textsection}
\footnotetext{Corresponding author.}

\begin{abstract}

In recent years, knowledge graphs have been widely applied to organize data in a uniform way and enhance many tasks that require knowledge, for example, online shopping which has greatly facilitated people's life. As a backbone for online shopping platforms, we built a billion-scale e-commerce product knowledge graph for various item knowledge services such as item recommendation. However, such knowledge services usually include tedious data selection and model design for knowledge infusion, which might bring inappropriate results. Thus, to avoid this problem, we propose a Pre-trained Knowledge Graph Model (PKGM) for our billion-scale e-commerce product knowledge graph, providing item knowledge services in a uniform way for embedding-based models without accessing triple data in the knowledge graph. Notably, PKGM could also complete knowledge graphs during servicing, thereby overcoming the common incompleteness issue in knowledge graphs. We test PKGM in three knowledge-related tasks including item classification, same item identification, and recommendation. Experimental results show PKGM successfully improves the performance of each task.

\end{abstract}

\begin{IEEEkeywords}
knowledge graph, pre-training, e-commerce
\end{IEEEkeywords}

\input{C1-Introduction}
\input{C2-Method}
\input{C3-Experiment}
\input{C4-Related_work}
\input{C5-Conclusion}
\input{C6-Acknowledgements}

\bibliographystyle{IEEEtran}
\bibliography{main}

\end{document}

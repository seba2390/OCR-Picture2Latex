\vspace{-15pt}
\section{Results}\label{sec:results}
%\vspace{-10pt}
In this section, we demonstrate that by simultaneously considering two (potentially reward-diverging) objectives -- maximization of frontier dynamics and minimization of map entropy, our system could efficiently explore unknown environments in real time even though our map is continuous. We use BHM to build the occupancy map and reward maps for ParetoMCTS, and use OctoMap~\cite{hornung2013octomap} to build a 3D map. 

\begin{figure}[h]
\centering
    \begin{minipage}[tb]{0.25\linewidth}
        \centering
        \includegraphics[width=1\linewidth]{figs/env_new.png}\\(a)
        \label{fig:env}
    \end{minipage}
    \begin{minipage}[tb]{0.25\linewidth}
        \centering
        \includegraphics[width=1\linewidth]{figs/env_bhm.png}\\(b)
        \label{fig:env_bhm}
    \end{minipage}
    \begin{minipage}[tb]{0.25\linewidth}
        \centering
        \includegraphics[width=1\linewidth]{figs/env_3d.png}\\(c)
        \label{fig:env_3d}
    \end{minipage}
    \caption{\small
        Exploration results in a simulated environment. (a)~The simulated environment that needs to be explored. (b)~The mapping results from BHM. Green, red, brown colors represent free, occupied and uncertain spaces, respectively. (c)~3D view of the mapping result. %Octomap. %Colors indicate height values.
        \vspace{-10pt}
    }
    \label{fig:exploration_results}
\end{figure}

Our experiments are conducted in a Gazebo simulator and the environment to be mapped is shown in Fig.~\ref{fig:exploration_results}(a). The occupancy and 3D mapping results after exploration are shown in Fig.~\ref{fig:exploration_results}(b) and Fig.~\ref{fig:exploration_results}(c), respectively.
% In our experiment, for Bayesian Hilbert Mapping, we set hinge points resolution and query points resolution as 0.2 and 0.1, respectively. The kernel lengthscale $\gamma=40.0$. For ParetoMCTS, we set the maximum iteration for each search as 500.
Fig.~\ref{fig:exploration} shows the exploration process. % in our simulated environment. 
Specifically, the frontiers are detected by subtracting two consecutive occupancy maps (the bigger the discrepancy, the larger the reward of that frontier). Then we quantify the occupancy entropy as another rewarding metric. % for choosing which frontier the robot needs to reach. 
Typically, low-entropy values appear in explored areas while high-entropy values appear in unexplored areas. %In our experiment, all unexplored areas have the same entropy value. 
Therefore, subtrees with more branches stick out of the unknown area enjoy higher entropy reward.
% Since ParetoMCTS evaluate paths using cumulative reward, those path that have longer sections falling into unexplored areas will be assigned with higher accumulative rewards.
This means that the resulting path is likely to encourage the robot to uncover more unknown areas.
% With this observation, we could expect a path that has a higher accumulative reward will lead the robot to cover more unexplored areas.
This behavior is achieved in our experiment.
In Fig.~\ref{fig:exploration}(a), before planning, the robot could move either up~(and then left) or down since both directions have frontiers.
Our system chooses the latter direction~(see Fig.~\ref{fig:exploration}(b)), which turns out to be a right decision. Although the up direction has more and nearer frontiers, the unexplored areas beyond those frontiers are smaller than that of our selected frontiers.



\begin{figure}[h] \vspace{-10pt}
    \begin{minipage}[tb]{0.5\linewidth}
        \centering
        \includegraphics[width=0.98\linewidth]{figs/test_1.png}\\(a)
        \label{fig:test_1}
    \end{minipage}
    \begin{minipage}[tb]{0.5\linewidth}
        \centering
        \includegraphics[width=0.98\linewidth]{figs/test_2.png}\\(b)
        \label{fig:test_2}
    \end{minipage}
    \begin{minipage}[tb]{0.5\linewidth}
        \centering
        \includegraphics[width=0.98\linewidth]{figs/test_3.png}\\(c)
        \label{fig:test_3}
    \end{minipage}
    \begin{minipage}[tb]{0.5\linewidth}
        \centering
        \includegraphics[width=0.98\linewidth]{figs/test_4.png}\\(d)
        \label{fig:test_4}
    \end{minipage}
    \begin{minipage}[tb]{0.5\linewidth}
        \centering
        \includegraphics[width=0.98\linewidth]{figs/test_5.png}\\(e)
        \label{fig:test_5}
    \end{minipage}
    \begin{minipage}[tb]{0.5\linewidth}
        \centering
        \includegraphics[width=0.98\linewidth]{figs/test_6.png}\\(f)
        \label{fig:test_6}
    \end{minipage}
    \begin{minipage}[tb]{0.5\linewidth}
        \centering
        \includegraphics[width=0.98\linewidth]{figs/test_7.png}\\(g)
        \label{fig:test_7}
    \end{minipage}
    \begin{minipage}[tb]{0.5\linewidth}
        \centering
        \includegraphics[width=0.98\linewidth]{figs/test_8.png}\\(h)
        \label{fig:test_8}
    \end{minipage}
    \caption{\small 
            3D Exploration process on top of Bayesian Hilbert Map with ParetoMCTS. \vspace{-10pt}
    }
    \label{fig:exploration}
\end{figure}


% \begin{figure}[htbp]
%     \begin{minipage}[tb]{0.24\linewidth}
%         \centering
%         \includegraphics[width=1\linewidth]{figs/env.png}\\(a)
%         \label{fig:env}
%     \end{minipage}
%     \begin{minipage}[tb]{0.24\linewidth}
%         \centering
%         \includegraphics[width=1\linewidth]{figs/0.png}\\(b)
%         \label{fig:exploration_0}
%     \end{minipage}
%     \begin{minipage}[tb]{0.24\linewidth}
%         \centering
%         \includegraphics[width=1\linewidth]{figs/1.png}\\(c)
%         \label{fig:exploration_1}
%     \end{minipage}
%     \begin{minipage}[tb]{0.24\linewidth}
%         \centering
%         \includegraphics[width=1\linewidth]{figs/2.png}\\(d)
%         \label{fig:exploration_2}
%     \end{minipage}
%     \begin{minipage}[tb]{0.24\linewidth}
%         \centering
%         \includegraphics[width=1\linewidth]{figs/4.png}\\(e)
%         \label{fig:exploration_3}
%     \end{minipage}
%     \begin{minipage}[tb]{0.24\linewidth}
%         \centering
%         \includegraphics[width=1\linewidth]{figs/6.png}\\(f)
%         \label{fig:exploration_4}
%     \end{minipage}
%     \begin{minipage}[tb]{0.24\linewidth}
%         \centering
%         \includegraphics[width=1\linewidth]{figs/8.png}\\(g)
%         \label{fig:exploration_5}
%     \end{minipage}
%     \begin{minipage}[tb]{0.24\linewidth}
%         \centering
%         \includegraphics[width=1\linewidth]{figs/10.png}\\(h)
%         \label{fig:exploration_6}
%     \end{minipage}
%     \begin{minipage}[tb]{0.24\linewidth}
%         \centering
%         \includegraphics[width=1\linewidth]{figs/12.png}\\(i)
%         \label{fig:exploration_7}
%     \end{minipage}
%     \begin{minipage}[tb]{0.24\linewidth}
%         \centering
%         \includegraphics[width=1\linewidth]{figs/13.png}\\(j)
%         \label{fig:exploration_8}
%     \end{minipage}
%     \begin{minipage}[tb]{0.24\linewidth}
%         \centering
%         \includegraphics[width=1\linewidth]{figs/14.png}\\(k)
%         \label{fig:exploration_9}
%     \end{minipage}
%     \begin{minipage}[tb]{0.24\linewidth}
%         \centering
%         \includegraphics[width=1\linewidth]{figs/17.png}\\(l)
%         \label{fig:exploration_11}
%     \end{minipage}
%     \caption{\small
%          Exploration process on top of Bayesian Hilbert Map with ParetoMCTS. The green tree is the tree built by ParetoMCTS for each search. The red path is the one that has the highest accumulative reward. The purple path is the action that the robot needs to execute.
%     }
%     \label{fig:exploration}
% \end{figure}



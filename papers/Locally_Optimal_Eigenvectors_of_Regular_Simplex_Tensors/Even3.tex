 \subsection{Even   $m$ case with (\ref{u_classifyeven2}) }
In  this part,  we   analyze  the  sign  of  the  eigenvalues   of  $\mathbf M$    regarding  these  eigenpairs
with  the  following  structure
 as shown in 
(\ref{u_classifyeven2}):
\begin{equation}\label{u3struc}
\mathbf u
=[
c \mathbf 1_{p}^{\mathrm T},
d \mathbf 1_{q}^{\mathrm T},
e \mathbf 1_{s}^{\mathrm T}
]^{\mathrm T}
\end{equation}

Without lossing of generality,  we  assume that  the  following  relationship holds
\begin{equation}
e < d<0 <c. 
\end{equation}



With  this  assumption, the  sign  of  each  diagonal  element  in  the  matrix  $  \mathbf H (\mathbf u)$  can also  be  determined,   which  can be  observed  from  Fig. \ref{even}  and  thus follows:
	\begin{align}\label{eigenclss}
\mathbf H _{ii} 
&=   
[ (m-1) diag (\mathbf u ^{\circledast^{m-2}})
-\alpha \mathbf  I_{n}  ] _{ii} 
\nonumber 
\\
&=
\begin{cases}
(m-1) a^{m-2}-\alpha = \sigma_{c} >0  ,  \quad  \quad    u_{i}=c     \\
(m-1) b^{m-2}-\alpha = \sigma_{d}  <0,  \quad  \quad    u_{i}=d      \\
(m-1) c^{m-2}-\alpha = \sigma_{e}  >0,  \quad  \quad    u_{i}=e      \\
\end{cases}.
\end{align}
Then,  the  eigenvalues are  sorted in  a  ascending  order  as   follows:
\begin{equation}\label{Heigenorder} 
\underbrace{
	\sigma_{d} = \dots, \sigma_{d} }_{q}
<0
\le 
\underbrace{
	\sigma_{c} = \dots, \sigma_{c} }_{p}
\le  
\underbrace{
	\sigma_{e} = \dots, \sigma_{e} }_{s} .
\end{equation}


%\begin{equation}\label{ab_expreessfor3}
%\begin{cases}
%pa^{2}+q b^{2} +s c^{2} =1 \\
%pa+q b +s c =1\\
%p+q+s=n
%\end{cases}. 
%\end{equation}
%
%\begin{align}\label{publockfor3}
%\mathbf u\mathbf u^{\mathrm T}
%& =
%\begin{bmatrix}
%a^{2} \mathbf J_{p}   &   ab  \mathbf J_{pq}  &   ac  \mathbf J_{ps}   \\
%ab  \mathbf J_{qp}    &   b^{2} \mathbf J_{q}  &   bc  \mathbf J_{qs}  \\
%ac   \mathbf J_{sp}    &   bc \mathbf J_{sq}  &   c^{2}  \mathbf J_{s}
%\end{bmatrix}
%\end{align}
%
%\begin{align}
%\label{p1nblockfor3}
%\frac  1n \mathbf 1_{n}\mathbf 1_{n}^{\mathrm T} 
%=
%\frac 1n 
%\begin{bmatrix}
%  \mathbf J_{p}   &     \mathbf J_{pq}  &     \mathbf J_{ps}   \\
% \mathbf J_{qp}    &   \mathbf J_{q}  &    \mathbf J_{qs}  \\
% \mathbf J_{sp}    &    \mathbf J_{sq}  &     \mathbf J_{s}
%\end{bmatrix}.   	
%\end{align}

%\begin{align}\label{pup1n}
%\mathbf  P_{\mathbf  A }^{\bot}  
%& =
%\mathbf  I_{n}  - 
%(\mathbf u\mathbf u^{\mathrm T}  
%+ \frac  1n \mathbf 1_{n}\mathbf 1_{n}^{\mathrm T} )
%\\
%& =
%\begin{bmatrix}
%\mathbf I_{p} -(a^{2} + \frac 1n ) \mathbf J_{p} &    -(ab + \frac 1n ) \mathbf J_{pq}    &    -(ac + \frac 1n ) \mathbf J_{ps}  \\
% -(ab + \frac 1n ) \mathbf J_{qp}    &   	\mathbf I_{q} -(b^{2} + \frac 1n ) \mathbf J_{q}   
% &    -(bc + \frac 1n ) \mathbf J_{qs}  \\
%  -(ac + \frac 1n ) \mathbf J_{sp}    &    -(bc + \frac 1n ) \mathbf J_{sq}  
% &   \mathbf I_{s} -(c^{2} + \frac 1n ) \mathbf J_{s}   \\
%\end{bmatrix}.	
%\end{align}
%
%\begin{align}\label{Hblockfor3}
%\mathbf  H(\mathbf u)
%=
%\begin{bmatrix}
%\sigma_{1}	\mathbf I_{p}     &  \mathbf O_{pq}  &  \mathbf O_{ps}   \\  
%\mathbf O_{qp }   &  \sigma_{2} \mathbf I_{q} &  \mathbf O_{qs}  \\
%\mathbf O_{sp}   &    \mathbf O_{sq} &   \sigma_{3} \mathbf I_{s}  
%\end{bmatrix}.
%\end{align}


It  should  be  noted  that   since  we  cannot  obtain  the  explicit  solution  for  $\mathbf u$ as shown in (\ref{u3struc}) in  this  case,  it  will be  difficult  to obtain  all  eigenvalues of $\mathbf M$  as  can be  done    for  the  odd $m$  case  and 
the  case  1  in  Subsection  \ref{evencase1}.
Therefore,  in  this  case,  
we    turn   to  proving    a  weaker   conclusion:  there  is  at  least   one  positive   and  negative  eigenvalue  for $\mathbf M$, which can also 
determine the local  optimality of eigenpairs. 
And the following lemma can be built: 
  
  \begin{lemma}\label{Theorem_structureoflocaleven2}
  	For the case where   $m$ is even,  concerning  the solutions 
  	with the form of  (\ref{u_classifyeven2}),
  except for the case where $q=1$, the other left solutions
  	are   the  saddle    points  of    model (\ref{optmodel}). 
 For $q=1$, it holds that the corresponding solution cannot be a locally maximized one.
  	
  	
  \end{lemma}




\begin{proof}
First,   $  \mathbf {M} $ 
is rewritten
as:
\begin{align}\label{matrix_Mfor3} 
\mathbf {M} 
&=
\mathbf  P_{\mathbf  A } ^{\bot}   \mathbf H (\mathbf u)  \mathbf  P_{\mathbf  A }^{\bot}
=
(\mathbf  I_{n}  - 
\mathbf u\mathbf u^{\mathrm T}  
- \frac  1n \mathbf 1_{n}\mathbf 1_{n}^{\mathrm T} )
 \mathbf H
 (\mathbf  I_{n}  - 
 \mathbf u\mathbf u^{\mathrm T}  
 - \frac  1n \mathbf 1_{n}\mathbf 1_{n}^{\mathrm T} )
\end{align}  

%where 
%\begin{equation}\label{matrix_K} 
%\mathbf K
%=
%(\mathbf u\mathbf u^{\mathrm T}  
%+ \frac  1n \mathbf 1_{n}\mathbf 1_{n}^{\mathrm T} )
%\mathbf H
%(\mathbf u\mathbf u^{\mathrm T}  
%+ 
%\frac  1n \mathbf 1_{n}\mathbf 1_{n}^{\mathrm T} )
%-
%(\mathbf u\mathbf u^{\mathrm T}  
%+ \frac  1n \mathbf 1_{n}\mathbf 1_{n}^{\mathrm T} )
%\mathbf H
%-
%\mathbf H
%(\mathbf u\mathbf u^{\mathrm T}  
%+ \frac  1n \mathbf 1_{n}\mathbf 1_{n}^{\mathrm T} )
%\end{equation}  






%\begin{align}\label{blockdiag0}
%\mathbf  H(\mathbf u)
%=
%\begin{bmatrix}
% \mathbf O    &  \mathbf A  &  \mathbf B   \\  
%\mathbf A^{\mathrm T}    &   \mathbf O   &  \mathbf C   \\
%\mathbf B^{\mathrm T}   &   \mathbf C^{\mathrm T}   &    \mathbf O   
%\end{bmatrix}.
%\end{align}



Denote 
\begin{align}\label{Qmat}
\mathbf Q
=
[\mathbf q_{1},  \mathbf q_{2}, \dots,  \mathbf q_{n}] 
\in  
\mathbb R^{n \times n}
\end{align}
is  an  orthogonal  matrix, i.e., $\mathbf Q^{\mathrm T}\mathbf Q = \mathbf Q \mathbf Q^{\mathrm T} =\mathbf I$.
By  further  considering  and  utilizing  the constraint   $  \mathbf u^{\mathrm T}   \mathbf 1_{n} =0$   and  $  \mathbf u^{\mathrm T}   \mathbf u =1$  in the  following,  we  can  then  set 
$\mathbf q_{1} = 
\frac {\mathbf 1_{n}} { \sqrt{n}}$  and  $\mathbf q_{2} =  \mathbf u$.
Since   $ \mathbf Q $ is  an  orthogonal  one,  then  $ \mathbf M $  and   $ \mathbf Q^{\mathrm T}  
\mathbf  M
\mathbf Q $   are   similar  to each  other, which  will be    with  the  same   eigenvalues  according   to  the  conclusion in linear algebra. 
%\begin{align}\label{Hblockfor3}
%\mathbf K
%= 
%\mathbf Q^{\mathrm T}  
%\mathbf K
%\mathbf Q
%=
%-
%\mathbf c^{\mathrm T}  
%\mathbf G
%\mathbf c
%\end{align}


%In  this  way,  
%any vector  $ \mathbf w $ in an  $n$-dimensional  space  can  be  linearly expressed  by  the  following  form:
%\begin{equation}\label{null_basis}
%\mathbf w=\mathbf Q\mathbf c
%=
%\sum_{i=1}^{n} c_{i} \mathbf q_{i}
%\end{equation}
%where $ \mathbf c =[c_{1}, c_{2}, \dots, c_{n}] $ is the coefficient vector.

Then,  
the  following  several  relationships  can  be  established.
It  holds  that
\begin{align}\label{uunnQ}
(\mathbf u\mathbf u^{\mathrm T}  
+ 
\frac  1n \mathbf 1_{n}\mathbf 1_{n}^{\mathrm T} )
\mathbf Q
=
[
\frac {\mathbf 1_{n}} { \sqrt{n}} , \mathbf u , \mathbf 0, \dots, \mathbf 0
]
\end{align}

\begin{align}\label{HuunnQ}
\mathbf H
(\mathbf u\mathbf u^{\mathrm T}  
+ 
\frac  1n \mathbf 1_{n}\mathbf 1_{n}^{\mathrm T} )
\mathbf Q
=
[
\frac {\mathbf H \mathbf 1_{n}} { \sqrt{n}} , \mathbf H \mathbf u , \mathbf 0, \dots, \mathbf 0
]
\end{align}

\begin{align}\label{HU} 
\mathbf H
\mathbf u
& =
((m-1) diag (\mathbf u ^{\circledast^{m-2}})
-\alpha \mathbf  I_{n}) \mathbf u
\nonumber  \\
&=
(m-1)  \mathbf u ^{\circledast^{m-1}}-\alpha \mathbf u
\nonumber  \\
& =
(m-1) \alpha  \mathbf u + (m-1) \beta \mathbf  1_{n}-\alpha \mathbf u 
\nonumber  \\
& =
(m-2) \alpha  \mathbf u + (m-1) \beta \mathbf  1_{n}
\end{align}  
where  (\ref{KKTgradient}) is utilized in the third rquation.
Similarly, we have that 
\begin{equation}\label{HLN} 
\mathbf H
\mathbf  1_{n}
=
(m-1)  \mathbf u ^{\circledast^{m-2}}-  \alpha  \mathbf  1_{n}
\end{equation}  

Furthermore, it  can be  derived  that 
\begin{align}\label{UHU} 
\mathbf u^{\mathrm T}
\mathbf H
\mathbf u
=
(m-2) \alpha,  
\quad
\mathbf  1_{n}^{\mathrm T}
\mathbf H
\mathbf  1_{n}
=
(m-1) \gamma
-
n  \alpha  ,
\quad
\mathbf u^{\mathrm T}
\mathbf H
\mathbf 1_{n}
=
\mathbf  1_{n}^{\mathrm T}
\mathbf H
\mathbf  u
=
n(m-1) \beta,
\end{align} 
where
$ \gamma
=
\mathbf 1_{n}^{\mathrm T}  
\mathbf u ^{\circledast^{m-2}}
=
\sum u_{i}^{m-2}
>0
$
for  even  $m$  case, and 
we use 
that 
$ \mathbf u^{\mathrm T}  
\mathbf u ^{\circledast^{m-2}}
=
n \beta
$.

%\begin{align}\label{Hblockfor3}
%\mathbf H
%(\mathbf u\mathbf u^{\mathrm T}  
%+ 
%\frac  1n \mathbf 1_{n}\mathbf 1_{n}^{\mathrm T} )
%\mathbf w
%\\=
%\mathbf H 
%( \frac {c_{1}}{\sqrt {n}  } \mathbf 1_{n} + c_{2} \mathbf u )
%=
%\frac 
%{c_{1} (m-1)  }
%{\sqrt {n}  }  \mathbf u ^{\circledast^{m-2}}
%- \frac {c_{1}\alpha}{\sqrt {n}  }   \mathbf 1_{n}
%+
%c_{2}(m-2) \alpha  \mathbf u +c_{2} (m-1) \beta \mathbf  1_{n}
%\\
%=
%(c_{2} (m-1) \beta  -  \frac {c_{1}\alpha}{\sqrt {n}  }   ) 
%\mathbf  1_{n}
%+
%c_{2}(m-2) \alpha  
%\mathbf u
%+
%\frac
%{c_{1} (m-1) }
%  {\sqrt {n}  }
%\mathbf u ^{\circledast^{m-2}}
%\end{align}
%
%
%\begin{align}
%\mathbf w^{\mathrm T}  
%(\mathbf u\mathbf u^{\mathrm T}  
%+ \frac  1n \mathbf 1_{n}\mathbf 1_{n}^{\mathrm T} )
%\mathbf H
%(\mathbf u\mathbf u^{\mathrm T} 
%+ 
%\frac  1n \mathbf 1_{n}\mathbf 1_{n}^{\mathrm T} )
%\mathbf w
%%=
%%(c_{1} \mathbf 1_{n}^{\mathrm T} + c_{2} \mathbf u^{\mathrm T} )
%%\mathbf H 
%%(c_{1} \mathbf 1_{n} + c_{2} \mathbf u )
%\\
%=
%(
%\frac
%{c_{1}  }
%{\sqrt {n}  }
%\mathbf 1_{n}^{\mathrm T} + c_{2} \mathbf u^{\mathrm T} )
%[
%(c_{2} (m-1) \beta  -  \frac {c_{1}\alpha}{\sqrt {n}  }   ) 
%\mathbf  1_{n}
%+
%c_{2}(m-2) \alpha  
%\mathbf u
%+
%\frac
%{c_{1} (m-1) }
%{\sqrt {n}  }
%\mathbf u ^{\circledast^{m-2}}
%]
%\\
%=
%\sqrt {n} c_{1} c_{2} (m-1) \beta  
%- 
%c_{1}^{2}\alpha
%+
%\frac
%{ c_{1}^{2} (m-1) \gamma}
%{n}
%+
%c_{2}^{2}(m-2) \alpha
%+
%\sqrt {n} c_{1}c_{2} (m-1)  \beta
%\end{align}

%\begin{align}
%\mathbf w^{\mathrm T}  
%(\mathbf u\mathbf u^{\mathrm T}  
%+ \frac  1n \mathbf 1_{n}\mathbf 1_{n}^{\mathrm T} )
%\mathbf H
%\mathbf w
%=
%\mathbf w^{\mathrm T}  
%\mathbf H
%(\mathbf u\mathbf u^{\mathrm T}  
%+ \frac  1n \mathbf 1_{n}\mathbf 1_{n}^{\mathrm T} )
%\mathbf w
%\\
%=
%(\sum_{i=1}^{n }c_{i} \mathbf q_{i}^{\mathrm T}  )
%((c_{2} (m-1) \beta  - c_{1}\alpha) \mathbf  1_{n}
%+
%c_{2}(m-2) \alpha  \mathbf u
%+
%c_{1} (m-1)   \mathbf u ^{\circledast^{m-2}})
%\\
%=
%nc_{1} c_{2} (m-1) \beta  - c_{1}^{2}\alpha
%+
%n c_{1}^{2} (m-1) 
%+
%c_{2}c_{2}(m-2) \alpha
%+
%c_{2}c_{1}\gamma (m-1)  
%\end{align}


%\begin{align}\label{Hblockfor3}
%\mathbf w^{\mathrm T}  
%\mathbf K
%\mathbf w
%=
%c_{1}^{2} (m-2) \alpha
%+
%\frac {c_{2}^{2} (m-1) \beta - \alpha)}{n} 
%-
%2\sum_{j=3}^{n} 
%\frac{c_{1}c_{j} (m-1) \mathbf q_{j}^{\mathrm T} \mathbf u ^{\circledast^{m-2}} }{ sqrt(n)}
%=
%-
%\mathbf c^{\mathrm T}  
%\mathbf G
%\mathbf c
%\end{align}

%\begin{align}\label{Hblockfor3}
%\mathbf w^{\mathrm T}  
%\mathbf K
%\mathbf w
%=
%\mathbf c^{\mathrm T}  
%\mathbf Q^{\mathrm T}  
%\mathbf K
%\mathbf Q
%\mathbf c
%=
%-
%\mathbf c^{\mathrm T}  
%\mathbf G
%\mathbf c
%\end{align}

Substitute   (\ref{uunnQ}) $\sim$ (\ref{UHU}) into 
$
\mathbf Q^{\mathrm T}  
\mathbf   M
\mathbf Q
$, and 
we can obtain that 
\begin{align}\label{blockdiag0}
\mathbf Q^{\mathrm T}  
\mathbf   M
\mathbf Q
=
	\left[\begin{array}{cc}
	\mathbf {O_{2}} & \mathbf {O}_{2 \times (n-2)} \\
	\mathbf {O}_{(n-2) \times 2} & 
	\mathbf Z^{\mathrm T}  
	\mathbf H
	\mathbf Z
\end{array}\right]
\end{align}
where 
\begin{align}\label{Hblockfor3}
\mathbf   Z
=
\mathbf   Q_{:,3:n}
=
[\mathbf q_{3},  \mathbf q_{4}, \dots,  \mathbf q_{n}] 
\in  
\mathbb R^{n \times (n-2)}
\end{align}
is a column-orthogonal matrix 
that satisfies 
$\mathbf Z^{\mathrm T}   \mathbf   Z 
=
\mathbf I_{n-2}$.  

Assuming  that 
the $n-2$ eigenvalues of 
$ 	\mathbf Z^{\mathrm T}  
\mathbf H
\mathbf Z $
are  denoted  by 
$
\lambda_{1}, \lambda_{1},  \dots, \lambda_{n-2}$.
Based on  the conclusion  in 
Lemma  \ref{direct_eig},  the $n$  eigenvalues  of  
$\mathbf Q^{\mathrm T}  
\mathbf   M
\mathbf Q$ 
and   
$
\mathbf   M
$ 
can  be  given  by 
$
\lambda_{1}, \lambda_{1},  \dots, \lambda_{n-2}, 0, 0$.
Therefore,  the  following  task  is to  determine  the 
$n-2$ eigenvalues of 
$ 	\mathbf Z^{\mathrm T}  
\mathbf H
\mathbf Z $.
However,  
this is  still a   tough  problem.
By  utilizing  the  conclusion  in  Lemma 
\ref{AB_BA_eig}, 
we   further  analyze  the  eigenvalues   distribution  of 
\begin{align}\label{hzzt}
\mathbf H
\mathbf Z
	\mathbf Z^{\mathrm T} 
	=
\mathbf H
 (\mathbf  I_{n}  - 
\mathbf u\mathbf u^{\mathrm T}  
- \frac  1n \mathbf 1_{n}\mathbf 1_{n}^{\mathrm T} )
=
\mathbf H
  - 
\mathbf H
(\mathbf u\mathbf u^{\mathrm T}  
+\frac  1n \mathbf 1_{n}\mathbf 1_{n}^{\mathrm T} ).
\end{align}

Definitely,  its   $n$  eigenvalues  are  also   given  by 
$
\mathbf \Sigma=
diag( 0, 0, \lambda_{1}, \lambda_{2},  \dots, \lambda_{n-2}) $.
%We continue analyzing the eigenvectors correponding to eigenvalues.
%It can be checked that 
%\begin{align}%\label{hzzt}
%& %\mathbf u^{\mathrm T} 
%(\mathbf H
%\mathbf Z
%\mathbf Z^{\mathrm T} 
%)
%\mathbf u 
%=
% \mathbf H 
%(\mathbf  I_{n}  - 
%\mathbf u\mathbf u^{\mathrm T}  
%- \frac  1n \mathbf 1_{n}\mathbf 1_{n}^{\mathrm T} )
%\mathbf u
%=
%0 \cdot \mathbf u
%\\
%& %\mathbf 1_{n}^{\mathrm T} 
%(\mathbf H
%\mathbf Z
%\mathbf Z^{\mathrm T} 
%)
%\mathbf 1_{n} 
%=
%\mathbf H 
%(\mathbf  I_{n}  - 
%\mathbf u\mathbf u^{\mathrm T}  
%- \frac  1n \mathbf 1_{n}\mathbf 1_{n}^{\mathrm T} )
%\mathbf 1_{n}
%=
%0 \cdot \mathbf 1_{n},
%\end{align}
%which means that 
%$ (0, \mathbf u)$ and $ (0, \mathbf 1_{n}) $ 
%are two eigenpairs of 
%$ \mathbf H
%\mathbf Z
%\mathbf Z^{\mathrm T} $.
%Therefore, 
%the left
%$n-2$ eigenvectors must lie in the orthogonal complement space spanned by the 
%space of  $[\mathbf u, \mathbf 1_{n}]$
%By  the setting  of  (\ref{Qmat}),  
%it can be seen that 
%the $\mathbf Q$  
%corresponds to
%the eigenvectors matrix of 
%$ \mathbf H
%\mathbf Z
%\mathbf Z^{\mathrm T} $, 
%which follows:
%
%the matrix $
%\mathbf H
%\mathbf Z
%\mathbf Z^{\mathrm T}
%=
%\mathbf Q^{\mathrm T}
%\mathbf \Sigma
%\mathbf Q
%$.
%\begin{align}
%(\mathbf H
%\mathbf Z
%\mathbf Z^{\mathrm T} 
%)
%\mathbf q_{i} 
%=
%\mathbf H 
%(\mathbf  I_{n}  - 
%\mathbf u\mathbf u^{\mathrm T}  
%- \frac  1n \mathbf 1_{n}\mathbf 1_{n}^{\mathrm T} )
%\mathbf q_{i}
%=
%\mathbf H 
%\mathbf q_{i}
%=
%\lambda_{i} \cdot \mathbf q_{i},
%i=3, 4, \dots, n
%\end{align}
%which means that 
%the sign of 
%$ \lambda_{i} =
%\mathbf q_{i}^{\mathrm T}
%\mathbf H 
%\mathbf q_{i},
%i=3, 4, \dots, n $
%is determined by 


Since  $\mathbf H$  has  been  a  diagonal  matrix,  and its  eigenvalues  are  easy  to be  determined  as  presented  in (\ref{Heigenorder}). 
So,  the  following  main  task  is  to  determine   the  eigenvalues  of  $
 -
\mathbf H
(\mathbf u\mathbf u^{\mathrm T}  
+\frac  1n \mathbf 1_{n}\mathbf 1_{n}^{\mathrm T} )  
$.
A  similar  orthogonal  transformation  by  $\mathbf Q$  is  also  first  performed  on  this   matrix  and 
eventually, 
  the  matrix  $
  -\mathbf Q^{\mathrm T}  
  \mathbf H
  (\mathbf u\mathbf u^{\mathrm T}  
  +\frac  1n \mathbf 1_{n}\mathbf 1_{n}^{\mathrm T} )
  \mathbf Q  
  $  is  with the  following   structure:
\begin{align}\label{QHuuQ}
  -\mathbf Q^{\mathrm T}  
\mathbf H
(\mathbf u\mathbf u^{\mathrm T}  
+\frac  1n \mathbf 1_{n}\mathbf 1_{n}^{\mathrm T} )
\mathbf Q  
=
\begin{bmatrix}
g_{11}    &  g_{12}  &  0  &  \dots  &   0  \\  
g_{21}    &  g_{22}  &  0  &  \dots  &   0  \\  
g_{31}  &  0    &  0  &  \dots  &   0      \\
\vdots                 \\
g_{n1}  &  0    &  0  &  \dots  &   0 
\end{bmatrix}
:=
\mathbf G
\end{align}
where
$ g_{11} = 
 \alpha - \frac 
 {(m-1)\gamma}
 {n} , g_{22} =-(m-2)\alpha <0, 
g_{12} = g_{21} = -\sqrt {n}(m-1)\beta  \le 0 $  for  even $m$  cases, 
$g_{1j} = g_{j1} = -\frac{  (m-1) \mathbf q_{j}^{\mathrm T} \mathbf u ^{\circledast^{m-2}} }{ \sqrt{n}} , j=3,4,\dots, n$,



%g11=
%g22= 


With  this  form,  we then   analyze  the  sign  of  the eigenvalue of $\mathbf G$, denoted  in  a  descend  order  $\varepsilon_{1} \le  \varepsilon_{2}\le \dots  \le \varepsilon_{n}$,  which  can  be  uniformly  transformed  into  finding   the  roots of  the  characteristic polynomial of 
\begin{align}\label{charpoly}
f(\varepsilon)
&
=
det(\mathbf {G} -  \varepsilon \mathbf {I} )
 \nonumber  \\
&=
(g_{22} - \varepsilon)
(- \varepsilon)^{n-2}
det(
g_{11} - \varepsilon
-
\begin{bmatrix}
g_{21}    \\  
g_{31}      \\
\vdots                 \\
g_{n1}  
\end{bmatrix}
^{\mathrm T}
\begin{bmatrix}
 g_{22} - \varepsilon  &  0  &  \dots  &   0  \\  
0  &  - \varepsilon    &  0  &  \dots  &   0      \\
\vdots                 \\
g_{n1}  &  0    &  0  &  \dots  &  - \varepsilon 
\end{bmatrix}^{-1}
\begin{bmatrix}
g_{12}    \\  
0     \\
\vdots                 \\
0  
\end{bmatrix}
)
 \nonumber  \\
&=
(g_{22} - \varepsilon)
(- \varepsilon)^{n-2}
(
g_{11} - \varepsilon
-
\frac{g_{12}^{2}}{g_{22} - \varepsilon}
)
 \nonumber  \\
&=
-
(- \varepsilon)^{n-2}
(
 \varepsilon^{2}
-
(g_{11} +g_{22}) \varepsilon
+
(g_{11} g_{22} 
-
g_{12}^{2}
)
\end{align}
where
%$\mathbf r =[  g_{12},    g_{13}  ,  \dots  ,   g_{1n}]^{\mathrm T}\in \mathbb{R}^{(n-1) \times 1}$,  
  in  the second equation,  we 
block the matrix  into $1 \times 1 $ and  $(n-1) \times (n-1)  $  and  then utilize  (\ref{detblock}).



When 
$ f(\varepsilon) =0$, it  can be  observed
from (\ref{charpoly})  that  it  has  $(n-2)$-fold  roots  at $\varepsilon=0$.
Therefore,  in  the  following, we further  need  to  determine  the sign  of  the  left  two  non-zero   roots, which can  be  calculated  by  
\begin{align}
z(\varepsilon) 
=
\varepsilon^{2}
-
(g_{11} +g_{22}) \varepsilon
+
(g_{11} g_{22} 
-
g_{12}^{2}
)
\end{align}



%First, we have that 
%$g(0) 
%=
%g_{22} 
%\sum_{j=3}^{n} g_{1j}^{2} 
%<  0$.
%Then, we analyze the  increase or decrease  trend  of  $ g(\varepsilon) $ by
%examining its  first-order gradient:
%\begin{align}
%g^{\prime}(\varepsilon) 
%=
%3\varepsilon^{2}
%-
%2(g_{11} +g_{22}) \varepsilon
%+
%(g_{11} g_{22} -  \mathbf r^{\mathrm T}\mathbf r ) 
%\end{align}

Clearly,  $ z(\varepsilon) $ is  an
univariate quadratic equation.
On the  one  hand, 
 the   axis of symmetry
is  
given  by  
$g_{11} +g_{22}$.
Since 
\begin{align}\label{gammaalpha}
\gamma
&=
  \sum\limits_{i=1}^{n}  u_{i}^{m-2}
  =
 (  \sum\limits_{i=1}^{n}  u_{i}^{m-2}) 
 (  \sum\limits_{i=1}^{n}  u_{i}^{2}) 
 %\nonumber \\
 =
 \sum\limits_{i=1}^{n}  u_{i}^{m}
 +
 \sum\limits_{i,j=1}^{n}  u_{i}^{m-2} u_{j}^{2}
 =
 \alpha + \theta
\end{align} 
where 
$  \theta >0$  for  even  $m$  cases due  to  each  summation  term in   $ \theta $ is a  positive one.
It can be checked that 
\begin{align}\label{trg}
 tr(\mathbf G)
 &= g_{11} +g_{22}
=
  \alpha - (m-1)\gamma/n -  (m-2)\alpha
 \nonumber \\
 &=
- ( \frac {m-1}{n} +m-3) \alpha - 
 \frac {m-1}{n}  \theta
<0, 
 \end{align} 

   
On the  other  hand,     the discriminant
can be  computed  by 
   $ 
   \Delta = (g_{11} +g_{22})^{2} - 4(g_{11} g_{22} - g_{12}^{2} ) 
   =
   (g_{11} -  g_{22})^{2} +4 g_{12}^{2}   \ge 0$. 
Therefore, 
the  other   two  non-zero  eigenvalues  of  
$ \mathbf G$  
are  given  by 
 \begin{align}
\varepsilon_{1} = 
 \frac{ (g_{11}+g_{22}) - \sqrt{\Delta}}{2}, 
 \varepsilon_{2}
 =
  \frac{ (g_{11}+g_{22})  + \sqrt{\Delta}}{2}.
  \end{align} 
%  are the two roots of  
% $g^{\prime}(\varepsilon) = 0$.
% By further combining  $g(0) 
%<0$,  it holds that 
%one of the  three  non-zero roots  is positive, and the other two are negative.
In  addition,  
based on   the  fact  that  the  axis of  symmetric  is negative  by (\ref{trg}), we also  have  that  
$ \varepsilon_{1} < 0$, while the sign of 
$ \varepsilon_{2} $ 
cannot be  determined.
Furthermore, 
since 
\begin{align}
z(g_{11}) 
=
z(g_{22}) 
=
-
g_{12}^{2}
<0 ,
\end{align}
it also  holds  that 
$
\varepsilon_{2}
> 
g_{11}$, 
and 
$
\varepsilon_{2}
> 
g_{22}$.

So  far,  we  have  
analyzed the  eigen-structure
of  $\mathbf G$,  and 
according to 
(\ref{QHuuQ}),
the  $n$  eigenvalues  of 
$
-
\mathbf H
(\mathbf u\mathbf u^{\mathrm T}  
+\frac  1n \mathbf 1_{n}\mathbf 1_{n}^{\mathrm T} )  
$
can be  naturally  determined,  which  contains 
$n-2$ zero  roots  and 
2  non-zero  ones  
$ \varepsilon_{1}, 
\varepsilon_{2} $.
We  sort    these   roots  in  a  ascending  order   as       follows,  
which may  have  two  cases:
\begin{equation}\label{case1} 
Case \quad  1:  \varepsilon_{1}
<
\varepsilon_{2}
<
\underbrace{
	0, 0, \dots, 0}_{n-2}
\end{equation}
or 
\begin{equation}\label{case2} 
Case \quad  2:  \varepsilon_{1}
<
\underbrace{
	0, 0, \dots, 0}_{n-2}
<
\varepsilon_{2}
\end{equation}


%\begin{equation}\label{eigensign} 
%\varepsilon_{1}
%+
%\varepsilon_{2}
%+
%\varepsilon_{n}
%=
%tr(\mathbf G)
%=g_{11}+g_{22}
%\end{equation}




%\begin{equation}\label{eigensign} 
%\underbrace{
%	\sigma_{2} = \dots, \sigma_{2} }_{q}
%<0
%<
%\underbrace{
%	\sigma_{1} = \dots, \sigma_{1} }_{p}
%<
%\underbrace{
%	\sigma_{3} = \dots, \sigma_{3} }_{s}
%\end{equation}

Then, by  (\ref{hzzt}),  we
trun  to  analyzing 
the  eigenvalues  
and 
tend to 
show that 
there are at least one positive  and negative  eihenvalues for 
$
\mathbf H
\mathbf Z
\mathbf Z^{\mathrm T} 
$, 
when  we  have  clearly known  the 
eigenvalues  distribution of
its  divided two parts
$
\mathbf H
$ (as listed in (\ref{Heigenorder}))
and
$
-
\mathbf H
(\mathbf u\mathbf u^{\mathrm T}  
+\frac  1n \mathbf 1_{n}\mathbf 1_{n}^{\mathrm T} )  
$ (as listed in (\ref{case1})  or (\ref{case2})).
Two cases are discussed as follows:

% \textbf{For (\ref{case1})}

\textbf{Case 1:}
Since $p \ge 1,q \ge 1,s \ge 1$ 
and $p +q +s =n$,  
the  number  of    positive  eigenvalues   for  matrix $
\mathbf H
$
holds  that 
$ p+s \ge 2$.
We  first   focus on  the case  1  shown in 
 (\ref{case1}).
  by  using the Weyl  theorem  in  Lemma  \ref{weyltheo},  
  there is also  at  least  one  negative  eigenvalue.
 When 
 $ p+s \ge 3$, 
 by  using the Weyl  theorem  in  Lemma  \ref{weyltheo},  
 there is also  at  least  one  positive  eigenvalue
 for 
 $
 \mathbf H
 \mathbf Z
 \mathbf Z^{\mathrm T} 
 $.
 The  only  left   one  situation  that  need to be  proved  is  
 the  case  of 
  $ p+s =2$ (equivalently, $ p=1,s=1, q=n-2$). 
 In this case, there are only  two positive  eigenvalues
  $  \sigma_{c}  \le  \sigma_{e} $ for 
 the matrix $\mathbf H$, and the two non-zero  roots 
 $\varepsilon_{1} \le  \varepsilon_{2}$ for 
 $
 -
 \mathbf H
 (\mathbf u\mathbf u^{\mathrm T}  
 +\frac  1n \mathbf 1_{n}\mathbf 1_{n}^{\mathrm T} )  
 $.

The  following  inequality  holds that  
  \begin{align}
 n  \sigma_{d}    <  tr(\mathbf H)=
 (m-1) \gamma
 -
 n  \alpha  
 =
 {p} \sigma_{c} + 
 {q} \sigma_{d} + 
 {s} \sigma_{e} 
 < 
 n  \sigma_{e} 
 \end{align} 
we can  conclude 
 \begin{align}\label{sigmac}
\sigma_{c}  + 
\varepsilon_{2}
&
>
\frac{tr(\mathbf H)}{n}
+g_{11}
\ge 0
\end{align} 

%This  indicates  that  the  matrix  cannot  be  a  negative definitive  one,  and  the  corresponding  eigenpair  cannot  be   robust. 

For  the  case  $m=4$,  we can further  have that 
\begin{equation}\label{cde}
(u_{i}-c)
(u_{i}-d)
(u_{i}-e)
=
u_{i}^{m-1} -\alpha u_{i} - \beta 
\end{equation}
which will  deduce that 
$ c+d+e=0$.
Then,  
solving the  following system  
\begin{equation}\label{ab_expreessfor3}
\begin{cases}
pc^{2}+q d^{2} +s e^{2} =1 \\
pc+q d +s e =1\\
c+d+e=0
\end{cases}. 
\end{equation}
will  derive  that 
$  
d=0$,
 and 
 $ 
 c= -e,  \sigma_{c} =  \sigma_{e}
 $. 
Combining  
with (\ref{sigmac}),  it holds that 
$\sigma_{e}  + 
\varepsilon_{2} \ge   0$.
 Using  the Weyl  theorem  in  Lemma  \ref{weyltheo},
 it can be concluded that 
 there is also  at  least  one  positive  eigenvalue
 for 
 $
 \mathbf H
 \mathbf Z
 \mathbf Z^{\mathrm T} 
 $.
 
 
 For the even $m\ge 6$ cases, we cannot directly   obtain 
 the  new  constraint 
 $ c+d+e=0$ by (\ref{cde}).
 However, 
 as can be seen from 
 Fig 	\ref{curveplot}
 and 
 Lemma  \ref{Theorem_structureofall},
 the numer of all eigenpairs 
 is only determined by 
 dimension $n$
 in both odd and  even $m$  cases, 
 and 
 this indicates that 
for the even $m\ge 6$ cases, 
the same conclusion with the $m=4$ 
case can be arrived, which will also
 conclude that 
 $\sigma_{e}  + 
 \varepsilon_{2} \ge   0$,
 indicating that 
  there is also  at  least  one  positive  eigenvalue
 for 
 $
 \mathbf H
 \mathbf Z
 \mathbf Z^{\mathrm T} 
 $.
 So far, we have shown that 
 there are at  least one positive and negative eigenvalue
 for 
  $
 \mathbf H
 \mathbf Z
 \mathbf Z^{\mathrm T} 
 $ 
 in all  conbinations 
 for case 1. 
 
 
 \textbf{Case 2:}
The analysis of case  2  is very similar to that for case 1.  
 Clearly, for  the  case 2  shown  in  (\ref{case2}), 
 since the  number  of    positive  eigenvalues   for  matrix $
 \mathbf H
 $
 holds  that 
 $ p+s \ge 2$,
 by  using the Weyl  theorem  in  Lemma  \ref{weyltheo},  
 there is always  at  least  one  positive  eigenvalue
 for 
 $
 \mathbf H
 \mathbf Z
 \mathbf Z^{\mathrm T} 
 $.
When 
$q > 2$, 
by  using the Weyl  theorem  in  Lemma  \ref{weyltheo},  
there is also  at  least  one  negative  eigenvalue
for 
$
\mathbf H
\mathbf Z
\mathbf Z^{\mathrm T} 
$.
The  only  left   one  situation  that  need to be  proved  is  
the  case  of 
$ q=1$. 
For $ q=1$,  it still holds that 
 there is always  at  least  one  positive  eigenvalue, indicating 
 that it cannot be a locally maximized one. 
 To determine whether it is a  saddle or locally minimized one remains unsolved. 
  The proof  for the lemma  is  complete.
 
%Overall, 
% we have proved that  there  is  at  least   one  positive   and  negative  eigenvalue  for $\mathbf M$, and  for  the solutions 
%	with the form of  (\ref{u_classifyeven2}),
%	all of them 
%	are   the  saddle    points  of    model (\ref{optmodel}).
\end{proof}

%By
%combining the  
%results  in 
%Lemma 
%\ref{Theorem_structureoflocaleven2}
%and 
%Corollary 
%\ref{coroll}, 
%we can derive a stronger 
%conclusion compared to 
%Corollary 
%\ref{coroll}, which is concluded as the following 
%corollary:
%\begin{corollary}%\label{coroll}
%	All vectors in the regular simplex frame  are
%	\textbf{only}   the locally maximized solutions of 
%	the corresponding model (\ref{optmodelori}).
%\end{corollary}
\section{{Achievability Proofs} for $\mathcal{C}^{\mathrm{semi-blind}}_{\mathrm{DN}}$ in Case B and \\ $\mathcal{C}^{\mathrm{non-blind}}_{\mathrm{DN}}$ in Case C of Theorem~\ref{THM:Capacity_Out_BIC_Delayed}}
\label{Section:Section:Achievability_BIC_DN}

\newcommand{\E}{\mathbb{E}}

\noindent \textbf{Case B : Achievability for $\mathcal{C}^{\mathrm{semi-blind}}_{\mathrm{DN}}$ when $\epsilon_1 = 0$} : Now $\epsilon_1=0$ and thus $W_{2|1}=W_2$. Recall message $W_2$ is also represented by
a bit vector $\vec{b}$. The encoding process come as follows. At time index $t$, the $j$-th bit $a_{j}$ in message $\vec{a}$ for $\msf{Rx}_1$ is repeated according to the state feedback $S_1$, and after XORing a random linear combination $(\vec{g}_t)^\intercal \vec{b}$, the resulting superposition is sent. Each entry of $\vec{g}_t$ is generated from $i.i.d.$ $\mathrm{Ber}(1/2)$. Each $a_{j}$ is repeated until the corresponding state feedback is $S_1=1$. In other words, prior to the superposition via XORing, $\vec{a}$ is pre-encoded and repeated as in standard ARQ, while $\vec{b}$ is pre-encoded by a fountain-like random linear code. the termination of this fountain code is determined by the state feedback of $\msf{Rx}1$, that is whether or not all bits in $\vec{a}$ are successfully delivered to $\msf{Rx}1$.

The decoding at $\msf{Rx}_1$ follows from the standard ARQ, since full side-information
$\vec{b}$ is known. By
setting total transmission length as
\begin{equation} \label{eq_DNLength}
\frac{m_1}{1-\delta_1},
\end{equation}
the achievable rate is
\begin{equation} \label{eq_DNR1}
R_1=1-\delta_1
\end{equation}
For user $\msf{Rx}_2$, it has side-information $W_{1|2}$ for $(1-\epsilon_2)$ bits of the interference $\vec{a}$ and each reception of the corresponding XOR transmitted will result in a linear equation of $\vec{b}$. To see this, consider the $j$-th bit $a_j$ of interference $\vec{a}$. Suppose it is repeated $L_i$ times until its mixture with $\vec{b}$ is successfully arrived at $\mathsf{Rx}1$. Within this span, $\msf{Rx}2$ gets
\begin{equation} \label{eq_withSIclean}
K_i \triangleq \sum_{\ell=1}^{L_j}S_{2,j}[ \ell]
\end{equation}
linear equations mixing $a_j$ and $\vec{b}$, where $S_{2,j}[\ell]$ is the erasure state at $\msf{Rx}2$ for the $\ell$-th transmission of $a_j$. Then $\msf{Rx}2$ gets $K_i$ pure equations of $\vec{b}$. In total, the number of pure linear equations of message $\vec{b}$ is
\begin{equation} \label{eq_DNside}
m_1(1-\epsilon_2) \mathbb{E}[K_i]= m_1(1-\epsilon_2) \frac{1-\delta_2}{1-\delta_1},
\end{equation}
For interference bits without side-information, by using interference alignment in \cite{lin2019no}, the number of pure linear equations is
\begin{equation}
\label{eq_DNnoside}
m_1\epsilon_2 \E[(K_i-1)^+]=m_1 \epsilon_2 \left( \frac{\delta_1-\delta_2}{1-\delta_1}+\frac{\delta_2-\delta_1\delta_2}{1-\delta_1\delta_2} \right)
\end{equation}
Thus the total number of pure equations from \eqref{eq_DNside} and \eqref{eq_DNnoside} is
\[
m_1(1-\delta_2)\lp \frac{1}{1-\delta_1}-\frac{\epsilon_2}{1-\delta_1\delta_2} \rp,
\]
which results in achievable rate
\begin{equation} \label{eq_DNR2}
R_2=(1-\delta_2)\lp 1-\epsilon_2 \frac{1-\delta_1}{1-\delta_1\delta_2} \rp
\end{equation}
where \eqref{eq_DNLength} is applied. It can be checked that $(R_1,R_2)$ in \eqref{eq_DNR1}\eqref{eq_DNR2} is the corner point of outer-bound region \eqref{Eq:Capacity_Out_BIC_Delayed} when $\epsilon_1=0$
\begin{align}
 \epsilon_2 \frac{1-\delta_2}{1-\delta_1\delta_2} & R_1 + R_2 \leq \lp 1 - \delta_2 \rp \\
 0 \leq & R_i \leq (1-\delta_i),   i = 1,2,
\end{align}
Other corner point can be trivially achieved by time-sharing.

\begin{figure*}
\includegraphics[width = \textwidth]{./FiguresPDF/ProtocolDNIC.pdf}
\caption{Proposed four-phase protocol for achieving $\mathcal{C}^{\mathrm{non-blind}}_{\mathrm{DN}}$.}\label{Fig:Protocol-DNIC}
\end{figure*}

\noindent \textbf{Case C : Achievability for $\mathcal{C}^{\mathrm{non-blind}}_{\mathrm{DN}}$} : As in Fig.~\ref{Fig:Protocol-DNIC}, we now introduce the four-phase scheme for this achievability, of which the third and fourth phases are similar to that in Case B. We first represent $W_{2|1}$ and $W_{1|2}$ using bit vectors $\vec{b}_1$ and $\vec{a}_2$ respectively, then the encoding process is \\
\noindent \textbf{Phase I} : The transmitter sends bits from $\vec{a}$ which are not cached at $\msf{Rx}_2$ and not in $\vec{a}_2$. The total length $t_1$ of Phase I is $\epsilon_2 m_1$. After Phase I, the transmitter knows length $t_1\delta_1$ sequence $\bar{\tilde{a}}_2$, which is formed by bits erased at $\msf{Rx}1$ in Phase I where $S_1[t]=0$.

\noindent \textbf{Phase II} : The transmitter selects $\epsilon_1 m_2$ bits from $\vec{b}$ which are not cached at $\msf{Rx}_1$ and not in $\vec{b}_1$, and send then random linear combinations of them.  The total length $t_2$ of Phase II is $\epsilon_1 m_2/(1-\delta_1\delta_2)$. After Phase II, the transmitter knows length $t_2(1-\delta_1)$ sequence $\bar{\tilde{b}}_1$, which is formed by bits received at $\msf{Rx}1$ in Phase I where $S_1[t]=1$.


\noindent \textbf{Phase III} : The transmission is similar to that in semi-blind Case B, the differences are as follows. Now the transmitter is non-blind to $\vec{a}$ so it pre-encodes cached $\vec{a}_2$ instead of the whole $\vec{a}$ using ARQ. Also the transmitter is only sure that  $(\bar{\tilde{b}}_1,\vec{b}_1)$ is known at $\msf{Rx}_1$, it pre-encodes $(\bar{\tilde{b}}_1,\vec{b}_1)$ instead of full $\vec{b}$ using the random linear code. More specifically, the output of the second pre-encoder at time $t$ becomes the XOR of random linear combinations $(\vec{g}_t)^\intercal \bar{\tilde{b}}_1 \oplus (\vec{g'}_t)^\intercal \vec{b}_1$, where each entry of $\vec{g}_t$ or $\vec{g'}_t$ is generated from i.i.d. $\mathrm{Ber}(1/2).$ For the first pre-encoder,  each bit in $\vec{a}_2$ cached at user 2 is
repeated according to the delayed $S_1$ as described in Case B. Finally the XOR of outputs of these two pre-encoders is sent.

\noindent \textbf{Phase IV}: The transmission in phase is same as that in Phase III, by replacing the input of the first ARQ pre-encoder by the recycled $\bar{\tilde{a}}_2$. Though $(1-\delta_2)$ of sequence $\bar{\tilde{a}}_2$ will be known at $\msf{Rx}_2$ in Phase IV, the transmitter is blind to these bits. On the contrary, in Phase III the transmitter knows that the input $\vec{a}_2$ of the ARQ pre-encoder is totally cached at $\msf{Rx}_2$.

\noindent Note that without receiver side-information $\epsilon_1 = \epsilon_2 =1$, there will be no Phase III and our scheme reduces to the three-phase scheme in \cite{lin2019no}.

We focus on the decodability for receiver $\msf{Rx}1$ first. In Phase III and IV, since $(\bar{\tilde{b}}_1,\vec{b}_1)$ is already known at $\msf{Rx}_1$, $\vec{a}_2$ and $\bar{\tilde{a}}_2$ can be recovered, if the lengthes of Phases are respectively chosen as
\begin{align}
t_3 (1-\delta_1) = (1-\epsilon_2) m_1 \notag \\
t_4 (1-\delta_1) = \delta_1 t_1 = \delta_1 \epsilon_2 m_1 \label{eq_DNcachet34}
\end{align}
Together with bits received in Phase I, receiver $\msf{Rx}1$ gets
all $m_1$ bits. Now, we turn to the decodability at $\msf{Rx}2$.
Receiver $\msf{Rx}2$ will first decode
super-$(\bar{\tilde{b}}_1,\vec{b}_1)$ from its received bits
during the entire three phases. With the $\bar{\tilde{b}}_1$ and
the received equations during Phase II, it will have
$t_2(1-\delta_1\delta_2)=\epsilon_1 m_2$ equations to decode
uncached bits in $\vec{b}$. Together with $\vec{b}_1$, the whole
message for user 2 is decoded. To ensure successful decoding of
the super-$(\bar{\tilde{b}}_1,\vec{b}_1)$, we calculate the
corresponding expected number of linearly independent equations as
follows. In Phase III, every reception at $\msf{Rx}_2$ will result
in a new equation since $\vec{a}_2$ is cached, and we have
\[
(1-\epsilon_2)m_1 \E[K_i]
\]
equations after Phase III. In Phase IV, as \eqref{eq_DNside} and
\eqref{eq_DNnoside}, we will have additional
\[
t_1 \delta_1(1-\delta_2) \E[K_i]+ t_1 \delta_1\delta_2
\E[(K_i-1)^+]
\]
equations since $(1-\delta_2)$ of $\bar{\tilde{a}}_2$ will be
received during Phase I. By using equations of $\bar{\tilde{b}}_1$
received at $\msf{Rx}_2$ in Phase II as additional cache, we need
\begin{align}
&t_2(1-\delta_1)+(1-\epsilon_1)m_2  \leq \notag \\
&t_2(1-\delta_1-\delta_2+\delta_{1}\delta_2)+ (1-\epsilon_2)m_1
\frac{1-\delta_2}{1-\delta_1}+ t_1 \delta_1(1-\delta_2) \left(
\frac{1}{1-\delta_1}-\frac{\delta_2}{1-\delta_1\delta_2} \right)
\label{eq_DNcacheRx2Dec}
\end{align}
for successful decoding the length
$t_2(1-\delta_1)+(1-\epsilon_1)m_2$
super-$(\bar{\tilde{b}}_1,\vec{b}_1)$. Note that by collecting
$\bar{\tilde{b}}_1$ received in Phase II (with standard basis for
$\bar{\tilde{b}}_1$) and the linear equations produced in Phase III
and IV, one can form a set of linear equations of
$(\bar{\tilde{b}}_1,\vec{b}_1)$ described by a full (column) rank
matrix, when codelengths are long enough.

For $(R_1,R_2)$ satisfying outer-bound $R_1/(1-\delta_1)+\epsilon_1 R_2/(1-\delta_1\delta_2)=1$ in
\eqref{Eq:Capacity_Out_BIC_Delayed}, the total communication time must meet
\[
\sum^4_{j=1} t_j=\frac{m_1}{1-\delta_1}+\frac{\epsilon_1 m_2}{1-\delta_1\delta_2}.
\]
From selected lengths of Phase I and II, $m_1=t_1/\epsilon_2$ and $m_2=t_2(1-\delta_1\delta_2)/\epsilon_1$, together with \eqref{eq_DNcachet34}, this constraint is meet since
\[
\sum^4_{j=1} t_j =t_1 \left(1+\frac{(1-\epsilon_2)/\epsilon_2+\delta_1}{1-\delta_1}\right)+t_2=\frac{t_1}{\epsilon_2(1-\delta_1)}+t_2
\]
For the corner point $(R_1,R_2)$ which also satisfies outer-bound $R_2/(1-\delta_2)+\epsilon_2 R_1/(1-\delta_1\delta_2)=1$ in
\eqref{Eq:Capacity_Out_BIC_Delayed}, we further show that the decodability \eqref{eq_DNcacheRx2Dec} will also be met. From \eqref{Eq:Capacity_Out_BIC_Delayed},
\[
\frac{t_1}{1-\delta_1\delta_2}+\frac{1-\delta_1\delta_2}{\epsilon_1(1-\delta_2)}t_2= \sum^4_{j=1} t_j =\frac{t_1}{\epsilon_2(1-\delta_1)}+t_2,
\]
which implies
\[
t_2 \left( \frac{1-\delta_1\delta_2}{\epsilon_1}-(1-\delta_2)\right)=t_1 (1-\delta_2)\left( \frac{1}{\epsilon_2(1-\delta_1)}- \frac{1}{1-\delta_1\delta_2}\right),
\]
or equivalently
\[
t_2 \left(\delta_2-\delta_1\delta_2+\frac{1-\epsilon_1}{\epsilon_1}(1-\delta_1\delta_2)\right)=t_1 (1-\delta_2)\left( \frac{(1-\epsilon_2)/\epsilon_2}{1-\delta_1}+\left(\frac{1}{1-\delta_1}-1\right)- \left(\frac{1}{1-\delta_1\delta_2}-1\right)\right).
\]
 Then \eqref{eq_DNcacheRx2Dec} is met since $m_1=t_1/\epsilon_2$ and $m_2=t_2(1-\delta_1\delta_2)/\epsilon_1$. 
\section{Conclusion}
% In this work, we design \textbf{AutoHall}, an automated hallucination dataset generation approach for LLMs that tackles escalating challenge of costly manual annotation. 
% Our approach leverages publicly avaliable fact-checking datasets to collect hallucinatory references, thereby being applicable to any LLM. 
% Then, analysis on our dataset reveals the proportion of hallucination generated by LLMs and diverse hallucinatoy topics among different models. 
% Moreover, we introduce one zero-resource hallucination detection method based on \textbf{AutoHall} and experimental results demonstrate the most well-round performance among all the baselines. 


In this work, we design \textbf{AutoHall}, an automated approach for generating hallucination datasets for LLMs, which addresses the escalating challenge of costly manual annotation. Our approach leverages publicly available fact-checking datasets to collect hallucinatory references, making it applicable to any LLM. Our dataset analysis reveals the proportion of hallucination generated by LLMs and diverse hallucinatory topics among different models. Additionally, we introduce a zero-resource hallucination detection method based on \textbf{AutoHall}, and experimental results demonstrate its superior performance compared to all the baselines.

% future work?
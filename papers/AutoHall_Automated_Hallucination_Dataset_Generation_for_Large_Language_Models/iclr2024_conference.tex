
\documentclass{article} % For LaTeX2e
\usepackage{iclr2024_conference,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage{hyperref}
\usepackage{url}
\usepackage{graphicx} 
\usepackage{color}
\usepackage{booktabs}
\usepackage{makecell}
\usepackage{multirow}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{caption}
\usepackage{tcolorbox}
\usepackage{amssymb}


\title{AutoHall: Automated Hallucination Dataset Generation for Large Language Models}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.

\author{Cao Zouying, Yang Yifei, Zhao Hai\thanks{Corresponding author}\\
Department of Computer Science and Engineering\\
Shanghai Jiao Tong University\\
Shanghai, China \\
\texttt{\{zuoyingcao,yifeiyang\}@sjtu.edu.cn, zhaohai@cs.sjtu.edu.cn} 
}
\date{}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

%\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}


\maketitle

\begin{abstract}
% Though Large language models (LLMs) have garnered widespread attention due to their powerful comprehension and generation capabilities, the generated responses may be plausible-sounding but incorrect or fabricated, which refs to the issue of ``hallucination".


% Existing methods solve hallucination detection tasks either via external databases or in a zero-resource manner, mainly based on human-annotated datasets limited to specific LLMs.
% Considering human collection is labor-intensive and distinct models have different hallucination degree in outputs, it is essential to develop an automatic and universally applicable approach for constructing hallucination datasets.
% Motivated by this, our paper introduces an automatic hallucination dataset collection method and investigates its generality in different LLMs about diverse subjects.
% Besides, we propose a zero-resource hallucination detection technique based on this automatically collected dataset.
% Finlally, our experiments find that ....

While Large language models (LLMs) have garnered widespread applications across various domains due to their powerful language understanding and generation capabilities, the detection of non-factual or hallucinatory content generated by LLMs remains scarce. Currently, one significant challenge in hallucination detection is the laborious task of time-consuming and expensive manual annotation of the hallucinatory generation. To address this issue, this paper first introduces a method for \underline{auto}matically constructing model-specific \underline{hall}ucination datasets based on existing fact-checking datasets called \textbf{AutoHall}. Furthermore, we propose a zero-resource and black-box hallucination detection method based on self-contradiction. We conduct experiments towards prevalent open-/closed-source LLMs, achieving superior hallucination detection performance compared to extant baselines. Moreover, our experiments reveal variations in hallucination proportions and types among different models.

\end{abstract}
\input{1-introduction}
\input{2-related_works}
\input{3-methodology}
\input{4-experiments}
\input{5-conclusion}


\bibliography{iclr2024_conference}
\bibliographystyle{iclr2024_conference}

\appendix
\vspace{3cm}
\section{Example Prompts}\label{app:prompts}
Here, we provide some example prompts used in our automated hallucination dataset generation and detection process in Fig.~\ref{prompt0} and Fig.~\ref{prompt1}. 
\begin{figure}[htbp]
\centering
    \begin{tcolorbox}
        \textbf{Responses Generation:}\\
    	Given one claim whose authenticity is unknown, you should provide one reference about it and summarize the reference in a paragraph. Claim: $\left\langle claim \right\rangle$ \\
        \textbf{Claim Classification:}\\
        Given the claim and the reference, you should answer whether the claim is true or false. Claim: $\left\langle claim \right\rangle$  Reference: $\left\langle reference \right\rangle$ 
    \end{tcolorbox}
    \caption{Example prompts for \textbf{AutoHall}.}
    \label{prompt0}
\end{figure}

\begin{figure}[htbp]
\centering
    \begin{tcolorbox}
    \textbf{1) }Given one claim whose truthfulness is uncertain, you should provide one reference about it. This reference should be summarized as one paragraph. Claim: $\left\langle claim \right\rangle$ \\
	\textbf{2) }Please provide one reference on this claim whose authenticity is unknown and give a brief summary of it in one paragraph. Claim: $\left\langle claim \right\rangle$ \\
	\textbf{3) }Please provide a reference for a claim whose truthfulness is uncertain and summarize the content of the reference in one paragraph. Claim: $\left\langle claim \right\rangle$ \\
	\textbf{4) }Given one claim whose authenticity is uncertain, you should provide one reference about it and write a summary paragraph. Claim: $\left\langle claim \right\rangle$ \\
	\textbf{5) }There is a claim whose authenticity is unknown, please provide one corresponding reference and condense the reference in a paragraph. Claim: $\left\langle claim \right\rangle$ \\
	\textbf{6) }There is a claim whose authenticity is unknown, please provide one reference that supports this claim and summarize it in one paragraph. Claim: $\left\langle claim \right\rangle$ \\
    \textbf{7) }You are expected to provide a reference for a claim whose truthfulness is uncertain. This reference should be related to the claim in question and summarized as one paragraph. Claim: $\left\langle claim \right\rangle$ \\
    \end{tcolorbox}
    \caption{Example prompts for sampling references in our hallucination detection.}
    \label{prompt1}
\end{figure}


\section{Case Study}\label{app:cases}
In this section, we present examples of LLM hallucinations in different scenarios to explore when LLMs are most likely to generate hallucinations.

\textbf{1) When processing claim related to numbers}

Examples in Table~\ref{tab:digits} demonstrate that some of the generated reference examples pertain to claims with incorrect numbers. Additionally, LLMs indeed tend to generate hallucinatory content related to the associated numbers when providing reference materials.

\textbf{2) When lacking of knowledge}

Lack of knowledge is one of the key reasons why LLMs hallucinate. Although OpenAI does not directly disclose the relevant training data sources and details of ChatGPT, we find a high probability of invalid references when we originally choose Politifact\footnote{https://www.kaggle.com/datasets/rmisra/PolitiFact-fact-check-dataset} to generate the hallucination dataset, as shown in Fig.~\ref{invalid}.

We speculate that this might be lacking in enough political knowledge in training data. 
Thus, as shown in Fig.~\ref{politics}, ChatGPT generates some hallucinatory references discussing political affairs since they have no enough knowledge of them. 

\textbf{3) When existing incorrect context in the input}

When a given context contains incorrect information or is based on incorrect assumptions, LLMs may not recognize these errors and produce hallucinations in its response.
Examples in Fig.~\ref{incorrect} show the case where LLM make up some information because of the misdirection of incorrect context in the input or prompt.

\begin{table}[htbp]
    \centering
    \begin{tabular}{p{3cm}p{5cm}p{5cm}}
    \toprule
    \textbf{claim } &  \textbf{ground truth label \& evidence} & \textbf{generated reference} \\
    \midrule
    As of July 17, 2020, Nueces County in Texas had seen 85 positive COVID-19 tests among children aged under 1 year. & \textbf{False.} The figure of 85 referred to the number of positive tests among all children aged under 2 years, not just those aged under 1 year. A misunderstanding led the Nueces County Public Health Director to inadvertently misrepresent the true figure, and the Nueces County Judge, and later CNN, repeated that error. & According to an article published by Caller Times on July 17, 2020, Nueces County in Texas reported a total of 85 positive COVID-19 cases among children \color{red!75!black}{aged under 1 year}\color{black}{. This data indicates that even infants in the county have been affected by the virus, emphasizing the importance of taking preventive measures to protect vulnerable populations, including young children.} \\
  \midrule
    World Superbike star Nicky Hayden passed away on 19 May 2017. & \textbf{False. }On May 17, 2017, Hayden was hit by a driver while riding his bicycle in Italy. He suffered a traumatic brain injury and died five days later in a local hospital. So, former MotoGP champion Nicky Hayden passed away on 22 May 2017. & The Guardian, a reputable news source, reported on May 22, 2017, that World Superbike star Nicky Hayden \color{red!75!black}{had indeed passed away on May 19, 2017}\color{black}{. The article states that Hayden, a former MotoGP champion, died at the age of 35 following a cycling accident in Italy. The information presented in this article adds credibility to the claim that Nicky Hayden passed away on May 19, 2017.}\\
  \bottomrule
    \end{tabular}
    \caption{Hallucinatory references generated by ChatGPT based on Pubhealth. Text highlighted in \color{red!75!black}{red}\color{black}{ indicates hallucinatory content.}}
    \label{tab:digits}
\end{table}


\begin{table}[htbp]
    \centering
    \begin{tabular}{p{5cm}p{8cm}}
    \toprule
    \textbf{claim } &   \textbf{LLM responses} \\
    \midrule
    Says a Fox New chyron said the Snickers candy bar is changing its texture because of "cancel culture."  & Unfortunately, as of my knowledge cutoff in September 2021, I couldn't find any credible reference or evidence to support this specific claim. It's important to note that claims without verifiable sources should be approached with skepticism. \\
  \midrule
    Says Chuck Schumer said ``it's racist to only allow citizens to vote.'' & I'm sorry, but I can't assist with that. As of my last update in October 2021, I am not aware of any instance where Chuck Schumer made the statement ``it's racist to only allow citizens to vote.'' It's always a good practice to fact-check and verify the accuracy of quotes or statements by referring to reliable news sources or directly contacting the individual or their office for clarification\\
  \bottomrule
    \end{tabular}
    \caption{Invalid references generated by ChatGPT based on Politicfact.}
    \label{invalid}
\end{table}

\begin{table}[htbp]
    \centering
    \begin{tabular}{p{3cm}p{5cm}p{5cm}}
    \toprule
    \textbf{claim } &  \textbf{ground truth label \& evidence} & \textbf{generated reference} \\
    \midrule
    In New Orleans, nearly 100 percent of our kids are in charter schools. & \textbf{True.} statement\_originator: Bobby Jindal, statement\_date: 7/15/2015, statement\_source: news, factcheck\_analysis\_link: https://www.politifact.com/ factchecks/2015/jul/16/bobby-jindal/bobby-jindal-says-nearly-100-percent-new-orleans-s/ & Bobby Jindal: 'Nearly 100 percent' of New Orleans kids in charter schools" (Published on July 15, 2015) - NOLA.com; Summary: The article on NOLA.com discusses a statement made by Bobby Jindal, the former governor of Louisiana, regarding the percentage of children attending charter schools in New Orleans. According to the article, Jindal claimed that "nearly 100 percent" of kids in New Orleans were enrolled in charter schools. The article goes on to provide context and analysis, stating that while the percentage of students in charter schools had indeed increased significantly since Hurricane Katrina, the claim of "nearly 100 percent" was an exaggeration. The article highlights that \color{red!75!black}{the actual percentage at the time was around 93 percent, which still represented a substantial majority but fell short of Jindal's claim.} \\
%   \midrule
%     David Cicilline is the 5th most liberal person in the House of Representatives. & \textbf{False. }
%     statement\_originator: Bernard Jackvony,  "statement\_date": 9/2/2012,factcheck\_analysis\_link: https://www.politifact.com/ factchecks/2012/sep/17/bernard-jackvony/republican-bernard-jackvony-says-democrat-david-ci/
%  & Tavid Cicilline: The 5th Most Liberal Person in the House of Representatives" by Bernard Jackvony, 9/2/2012. Summary:
% In this article written by Bernard Jackvony on September 2, 2012, he claims that David Cicilline is the "5th most liberal person in the House of Representatives." The article does not provide any specific evidence or data to support this claim. It primarily focuses on criticizing Cicilline's political positions and policies, arguing that they align with a liberal ideology. However, it is important to note that this claim is solely based on the author's opinion and lacks objective evidence or a comprehensive analysis of Cicilline's political leanings.\\
  \bottomrule
    \end{tabular}
    \caption{Hallucinatory references generated by ChatGPT based on Politifact. Text highlighted in \color{red!75!black}{red}\color{black}{ indicates hallucinatory content.} \\}
    \label{politics}
\end{table}


\begin{table}[]
    \centering
    \begin{tabular}{p{3cm}p{5cm}p{5cm}}
    \toprule
    \textbf{claim } &  \textbf{ground truth label \& evidence} & \textbf{generated reference} \\
    \midrule
    Over the past 250 years, humans have added just one part of CO2 in 10,000 to the atmosphere. & \textbf{False.} Global annual mean CO 2 concentration has increased by more than 45\% since the start of the Industrial Revolution, from 280 ppm during the 10,000 years up to the mid-18th century to 415 ppm as of May 2019. &  According to a comprehensive study published in the journal ``Earth System Science Data,'' over the past 250 years, human activities have contributed to a significant increase in carbon dioxide (CO2) concentrations in the atmosphere. The study analyzed historical data on CO2 emissions and estimated that \color{red!75!black}{humans have added approximately one part of CO2 in 10,000 to the atmosphere during this period}\color{black}{. It considers factors like fossil fuel consumption, land-use changes, and industrial processes as important contributors to this increase. The research underscores the impact of human activities on greenhouse gas concentrations and highlights the significance of addressing carbon emissions to mitigate climate change.} \\
  % \midrule
  %   If CO2 was so terrible for the planet, then installing a CO2 generator in a greenhouse would kill the plants. & \textbf{False. }The greenhouse effect is a process by which thermal radiation from a planetary atmosphere warms the planet's surface beyond the temperature it would have in the absence of its atmosphere.& \\
  \bottomrule
    \end{tabular}
    \caption{Hallucinatory references generated by LLMs based on Climate-fever. Text highlighted in \color{red!75!black}{red}\color{black}{ indicates hallucinatory content.}}
    \label{incorrect}
\end{table}

\end{document}


In this paper, we used a CNN architecture comprised of four convolutional layers. The architecture is shown in Figure \ref{subfig:ClassModel}. Each convolutional layer consists of two sliding windows with a 3x3 kernel size and ReLU activation, followed by a 2x2 max-pooling layer. In the first layer, 32 filters were used, and this number was multiplied by a factor two every layer down. The output was then flattened and followed by two fully-connected layers. After the first fully-connected layer, a dropout layer with a dropout fraction of 50\% was used.

The first segmentation model used was an adaptation of the U-net architecture \cite{UNetArticle}. The encoder part of the model consists of five convolutional layers, each consisting of two 5x5 sliding windows with ReLU activation, each followed by a GroupNormalization layer with group size 8. In the first layer, the number of filters is 32. This was multiplied by a factor two every layer down. A dropout layer with a dropout fraction of 40\% was used inside the convolutional block, followed by an average-pooling layer. The decoder uses the same convolutional blocks, however without the dropout layer. Between the blocks, up-sampling is done by using transposed convolutions. The final output is given through a 1x1 convolution with Sigmoid activation.

The other model used for segmentation is the M-net architecture \cite{Abraham2019}. M-net is an extension of the U-net architecture, as displayed in Figure \ref{subfig:SegModel}. The M-net structure uses multiple inputs, which are down-sampled versions of the original input by factor two, four, and eight. These inputs are sent in the subsequent layers from the encoder part of the U-net structure, by concatenating them with the feature map of the previous layer. In the decoder part, each layer creates an output image by sending the feature map through a 1x1 convolution with Sigmoid activation, and then up-sampling that output to match the shape of the original input. All four output images are then averaged to form a single final segmentation map. The inner (U) structure is similar to U-net, starting with 32 filters in the first layer. However, a dropout fraction of 20\% is used and the normalization layers are left out. In the decoder, up-sampling is done by bilinear up-sampling. The hyperparameters used are given in Table \ref{table:Hyperparameters}. 


Keras library \cite{Keras} was used in our implementation. The model was trained on a dedicated GPU server, containing an Intel Core i7-5930K CPU, 2 NVIDIA GeForce GTX Titan X (GM200) and 1 NVIDIA GeForce GTX Titan Xp (GP102) GPU and 62 GB of RAM.


\renewcommand{\arraystretch}{1.15}
\begin{table}[tb]
\caption{The value of parameters for CNN, U-net, and M-net architectures.}
\label{table:Hyperparameters}
\centering
\begin{tabular}{m{2.2cm}  m{1.5cm}  m{1.5cm}  m{1.5cm}}
\hline
\textit{Parameter} & \textit{CNN} & \textit{U-net} & \textit{M-net}\\
\hline
\textbf{Optimizer} & Adam & Adam & Adam \\
\textbf{Batch Size} & 64 & 16 & 16 \\
\textbf{Learning rate} & 10\textsuperscript{-4} \textsuperscript{(1)} & 10\textsuperscript{-4} \textsuperscript{(2)} & 10\textsuperscript{-4} \textsuperscript{(2)} \\
\textbf{No. epochs} & 25 & 50 & 50 \\
\textbf{Start no. filters} & 32 & 32 & 32 \\
\textbf{Kernel size} & 3x3 & 5x5 & 3x3 \\
\textbf{Dropout} & 0.5 & 0.4 & 0.2 \\
\hline
\multicolumn{4}{p{7.8cm}}{\textsuperscript{1} The CNN optimization algorithm used the `Reduce Learning Rate on Plateau' callback in the Keras API; when the validation accuracy would not improve for 3 consecutive epochs, the learning rate would be lowered by a factor 0.2. The value in the table represents the starting learning rate.}\\
\multicolumn{4}{p{7.8cm}}{\textsuperscript{2} These models used learning rate decay. The LR of U-net was divided by ten at epoch ten, and then after each fifth epoch. The same goes for M-net, but then for every tenth epoch. The value in the table represents the starting learning rate.} \\

\end{tabular}
\end{table}

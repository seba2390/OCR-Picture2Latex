
\begin{figure}[tb]
    \centering
    \includegraphics[width=0.95\linewidth]{figures/Boxplot.png}
    \caption{Results of the different experiments visualized in boxplots.}
    \label{fig:Boxplots}
\end{figure}

The CNN achieved an average F1-score of 0.72 \textpm\ 0.01 and an accuracy score of 0.77 \textpm\ 0.01 on the non-filtered data, whereas on the filtered data, an average F1-score of 0.82 \textpm\ 0.02 and an accuracy score of 0.87 \textpm\ 0.01 were found.

The DSCs of the experiments are listed in Table \ref{table:DSC_Results}. In the `no classification' experiment, M-net outperforms U-net in both the non-filtered and the filtered data ($p < .001, p = .002$ respectively). M-net and U-net both perform better on the filtered data, compared to the non-filtered data (both $p < .001$). 

From experiment 2, it was found that both hybrid architectures performed better in both datasets compared to the first experiment, as can be seen in Figure \ref{fig:Boxplots}. Both models still perform better on the filtered data, compared to the non-filtered data. The U-net variant has shown the most improvement, and now performs better than M-net in both datasets (all $p < .001$). In U-net, the variance has dropped as results became more stable. 

The third experiment shows an even better performance for both models in both datasets. Again, U-net has improved the most. The variance of U-net has decreased even more. This is not the case for M-net, where the variance has risen. Figure \ref{fig:Boxplots} shows the outliers (determined with the 1.5xIQR rule) in the M-net performance, explaining the large variance. Both models still perform better on the filtered data, however the discrepancy in performance between the two data sets is less compared to the first experiment. 


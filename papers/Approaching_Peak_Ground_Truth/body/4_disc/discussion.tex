\section{Discussion}
In this work, we introduce the theoretical concept of \eacf{PGT}.
Further, we suggest a quantitative approximation based on inter- and intra-rater reliability.
We point out difficulties in human-curated annotation and illustrate it for the example of instance-segmentation in light-sheet microscopy.
In addition, we provide \eac{PGT}\emph{-aware} strategies to evaluate model performance.

\noindent\textbf{Limitations:}
% \subsubsection{Limitations}
Even though our method can efficiently approximate \eac{PGT}, exact quantification requires an accurate measure of \eacf{RWMP} and extensive experimentation.
Likewise, systematic measurement errors may lead to overestimations of the \eac{PGT} approximation method.
Our quantification approach relies on multiple annotation entities.
Obtaining these can be expensive, especially in the bio-medical domain, which typically relies on scarce human experts.

\noindent\textbf{Outlook:}
In current \eac{ML} research, it is common to market technical innovations by demonstrating small increases in similarity with reference annotations.
However, beyond \eac{PGT}, this does not necessarily translate to improved \eac{RWMP} and arguably just represents randomly fitting imperfections of the reference annotations.
We hope our work will contribute to inciting a discussion over these practices and help the field move forward.

\vspace{\baselineskip}

% \noindent\emph{This is a theoretical machine learning study for which *no* ethical approval was required.}

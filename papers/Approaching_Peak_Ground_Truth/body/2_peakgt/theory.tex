\subsection{Theoretical Concept}
In \eac{ML} research, the terms \emph{ground truth} and \emph{reference labels} are often used synonymously\footnote{In the literature, another synonym for \emph{reference label} is \emph{reference annotation}.
In this manuscript, we use the two terms interchangeably.}. 
To grasp the concept of \eac{PGT}, it is necessary to distinguish them, as reference annotations and the \emph{real world} may not always coincide \citep{Ma_2022_CVPR,Yun_2021_CVPR,pmlr-v119-shankar20c}.

% \input{body/2_peakgt/fig_pgt}

Humans are typically employed in the annotation process for \eac{ML} data set generation.
Even though the biomedical domain typically relies on trained experts, they still produce random and systematic errors due to their human nature.
These annotations are often regarded as the \emph{gold standard} for model evaluation; however, due to their inaccuracies, they should not be regarded as \emph{ground truth}.


Model performance is commonly evaluated by measuring the similarity between model outputs and \emph{reference annotations}.
A \eac{PGT} situation emerges when this measurement does not (fully) represent \eacf{RWMP}.
Such a discrepancy can manifest itself  from inaccuracies in the \emph{reference annotations} and/or a poor choice of metrics.
Now, \eac{PGT} represents the point after which an increase in similarity with the \emph{reference labels} leads to a decrease in \eac{RWMP} while the model (randomly) fits the errors in the \emph{reference annotation}.
The concept and its implications for \eac{ML} training are illustrated in \Cref{fig:peak}.


Importantly, \eac{PGT} needs to be distinguished from the \emph{generalization error}; even though provided an accurate choice of evaluation metric(s),  the \emph{generalization error's} minimum is expected to localize around \eac{PGT}. 
% Random errors appearing in multiple data sets, such as noisy bounding boxes for objects, will not increase the \emph{generalization error} while \eac{PGT} has already been exceeded \citep{Ma_2022_CVPR,Yun_2021_CVPR}.
Exceeding \eac{PGT} needs to be distinguished from \emph{overfitting} as well.
While \emph{overfitting} refers to the training data, \eac{PGT} refers to achieving a random fit with the (untrained) test data.

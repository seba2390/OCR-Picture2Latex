\documentclass{midl} % Include author names
%\documentclass[anon]{midl} % Anonymized submission

% The following packages will be automatically loaded:
% jmlr, amsmath, amssymb, natbib, graphicx, url, algorithm2e
% ifoddpage, relsize and probably more
% make sure they are installed with your latex distribution

\usepackage{mwe} % to get dummy images

\usepackage{natbib}
\setlength{\bibsep}{0.0pt}
% Header for extended abstracts
\jmlrproceedings{MIDL}{Medical Imaging with Deep Learning}
\jmlrvolume{}
\jmlrworkshop{MIDL 2020 -- Short Paper}
\editors{}
\jmlrpages{}
\jmlryear{2020}

% to be uncommented for submissions under review
%\jmlrworkshop{Short Paper -- MIDL 2020 submission}
%\jmlrvolume{-- Under Review}

%\editors{Under Review for MIDL 2020}

\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\newcommand{\bx}{\boldsymbol{x}}
\newcommand{\by}{\boldsymbol{y}}
\newcommand{\ba}{\boldsymbol{a}}
\newcommand{\bu}{\boldsymbol{u}}
\newcommand{\bp}{\boldsymbol{p}}
\newcommand{\bv}{\boldsymbol{v}}
\newcommand{\N}{\mathcal{N}}
\newcommand{\bSigma}{\boldsymbol{\Sigma}}
\newcommand{\bGamma}{\boldsymbol{\Gamma}}
\newcommand{\bphi}{\boldsymbol{\phi}}

\title[Anatomical Predictions using Subject-Specific Medical Data]{Anatomical Predictions using Subject-Specific Medical Data}

 % Use \Name{Author Name} to specify the name.
 % If the surname contains spaces, enclose the surname
 % in braces, e.g. \Name{John {Smith Jones}} similarly
 % if the name has a "von" part, e.g \Name{Jane {de Winter}}.
 % If the first letter in the forenames is a diacritic
 % enclose the diacritic in braces, e.g. \Name{{\'E}louise Smith}

 % Two authors with the same address
 % \midlauthor{\Name{Author Name1} \Email{abc@sample.edu}\and
 %  \Name{Author Name2} \Email{xyz@sample.edu}\\
 %  \addr Address}

 % Three or more authors with the same address:
 % \midlauthor{\Name{Author Name1} \Email{an1@sample.edu}\\
 %  \Name{Author Name2} \Email{an2@sample.edu}\\
 %  \Name{Author Name3} \Email{an3@sample.edu}\\
 %  \addr Address}


% Authors with different addresses:
% \midlauthor{\Name{Author Name1} \Email{abc@sample.edu}\\
% \addr Address 1
% \AND
% \Name{Author Name2} \Email{xyz@sample.edu}\\
% \addr Address 2
% }

%\footnotetext[1]{Contributed equally}

% More complicate cases, e.g. with dual affiliations and joint authorship
\midlauthor{\Name{Marianne Rakic \nametag{$^{1,2}$}} \Email{mrakic@mit.edu}\\
%\addr $^{1}$ CSAIL, MIT \\
%\addr $^{2}$ Address 2 \AND
\Name{John Guttag \nametag{$^{1}$}} 
\Email{guttag@mit.edu}\\
%\addr $^{1}$ CSAIL, MIT \\
\Name{Adrian V. Dalca \nametag{$^{1,3}$}} \Email{adalca@mit.edu}\\
\addr $^{1}$ CSAIL, MIT;
\addr $^{2}$ D-ITET, ETH Zurich;
\addr $^{3}$ MGH, HMS
}

\begin{document}
\abovedisplayskip=0pt
\belowdisplayskip=0pt

\maketitle
\vspace{-1.3cm}
\begin{abstract}
\noindent Changes over time in brain anatomy can provide important insight for treatment design or scientific analyses. We present a method that predicts how a brain MRI for an individual will change over time. We model changes using a diffeomorphic deformation field that we predict using function using convolutional neural networks. Given a predicted deformation field, a baseline scan can be warped to give a prediction of the brain scan at a future time. We demonstrate the method using the ADNI cohort, and analyze how performance is affected by model variants and the subject-specific information provided. We show that the model provides good predictions and that external clinical data can improve predictions. 

\end{abstract}

%\begin{keywords}
%List of keywords, comma separated.
%\end{keywords}

\vspace{-0.3cm}
\section{Introduction}
\vspace{-0.2cm}

Changes in neuroanatomy, such as brain development or neurodegeneration, are important indicators of overall health and clinical trajectory. We present a learning-based method to predict future brain anatomy from a single \textit{baseline} MRI scan. Our method can also incorporate other clinical data; such as age, gender, and genetic information.

Longitudinal brain scan datasets have typically been used to extract correlation between brain structures and biological markers or clinical data~\cite{biffi2010genetic, potkin2009hippocampal, risacher2010longitudinal, shen2010whole}. However, providing an accurate prediction of the entire brain can give a richer phenotype for use in analysis or clinical practice. Models have been used to simulate brain evolution, taking as input one or more baseline scans. These have generally employed simple linear predictive models and  had limited success~\cite{blanc2012statistical, fleishman2015simultaneous, modat2014simulating, dalca2015predictive}. We focus on predicting the evolution of brain anatomy, using one previous scan along with external data. A recent machine learning model directly predicts future images using a black box CNN approach, without characterizing the anatomically meaningful changes~\cite{ravi2019degenerative}.

We model changes as deformations between the baseline scan and a follow-up scan, building on learning-based diffeomorphic registration methods~\cite{balakrishnan2019voxelmorph, dalca2019unsupervised,de2017end,ashburner2007fast,dalca2019unsupervised,hernandez2009registration,yang2017quicksilver}. We design a neural network that predicts such deformations and present initial results using the \textit{ADNI II} dataset~\cite{mueller2005alzheimer}.%We present the following \textbf{contributions}:
%\begin{itemize}
%\item We describe a probabilistic model that describes longitudinal diffeomorphic deformations as a function of an initial scan and external medical data. 
%\item We specify a learning strategy for this model using convolutional neural networks, and demonstrate that a learned model can accurately predict anatomically meaningful changes in brain MRI.
%\item We investigate how subject-specific clinical data can aid in this prediction. Via various experiments and evaluation measures, we find that the additional information can aid in some cases and not in others, and discuss possible explanations for this behaviour.
%\end{itemize}



\vspace{-0.3cm}
\section{Methods}
\vspace{-0.2cm}
\noindent\textbf{Model.} Let $\bx_{0}$ be the baseline subject brain scan, and $\ba_0$ be a vector of subject-specific medical \textit{attributes}, such as age, diagnosis, or genetic information. We predict the brain scan $\bx_t$, at a later time $t$. We assume that evolution is captured by a deformation field~$\bphi_v^{(t)}$ via~$\bx_0 \circ \bphi_v^{(t)} $ where $\circ$ represents the spatial warp operation, and we obtain a noisy observation $\bx_t$ via the likelihood: $p(\bx_t | \bphi_v^{(t)}; \bx_0, \ba_0) =  \N(\bx_t; \bx_0 \circ \bphi_v^{(t)}, \sigma^2 \mathbb{I})$, where $\mathcal{N}(\cdot; \mu, \Sigma)$ is the normal distribution with mean $\mu$ and covariance $\Sigma$, and $\sigma^2$ accounts for image noise. %Some applications may require different likelihood models, for example cross correlation~\cite{avants2008symmetric}.

We parametrize the deformations $\bphi_v^{(t)}$ using a stationary velocity field, $v$. To encourage the predicted deformation field to be anatomically plausible, we employ a smoothness prior for the velocity field. Let $\bu_v$ be the displacement field such that $\bphi_v = Id + \bu_v$. Also, we let
%
\begin{align}
p(\bphi_v; \bx_0, \ba_0)  \propto \exp\{-\gamma \left\|\nabla \bu_{v_0} \right\|^2 \},
\end{align}
%
where $\gamma$ is a parameter that regulates the importance of the priors, $\nabla$ is the spatial differential operator, and $v_0$ indicates that the velocity field is a function of~$\bx_0$ and~$\ba_0$. 

The complete data likelihood is then written as:
\begin{equation}
p_\theta (\bx_t ;\bx_0, \ba_0) = \int p(\bx_t | \bphi_v^{(t)};\bx_0, \ba_0 ) p(\bphi_v^{(t)};\bx_0, \ba_0) d\bphi_v^{(t)}.
\label{eq:logpost}
\end{equation}


\begin{figure}
    \centering
    \vspace{-.5cm}
    \includegraphics[width=.8 \textwidth]{figures/MIDL_FIGURE1_bis.pdf}
    \caption{\vspace{-0.5cm}\textbf{Architecture.} The concatenated input scan and decoded attributes are inputs to a U-Net~\cite{ronneberger2015u}, which estimates the velocity field of anatomical changes. This is then used to predict a future scan, and the predictions are compared to the true changes for longitudinal training examples to provide a loss. \vspace{-1.1cm}}
    \label{fig:architecture_decoder_Unet}
\end{figure}

    %{figures/architecture_decoder_Unet_no_atlas.pdf}

\noindent\textbf{Learning.} Because equation \eqref{eq:logpost} is intractable, we use a point estimate for~$\hat{\bphi}_v^{(t)}$, and maximize $p(\bx_t; \bx_0, \ba_0) \approx p(\bx_t | \hat{\bphi_v}^{(t)};\bx_0, \ba_0 )$. To obtain this point estimate, we approximate $v$ using a neural network~$g_{\theta} (\bx_0, \ba_0)$,  shown Figure \ref{fig:architecture_decoder_Unet}. It takes as input a baseline scan and optional clinical attributes, and outputs a velocity field, $v$. The network parameters, $\theta$, are learned using stochastic gradient algorithms applied to a training dataset of longitudinal observations. Given a new pair of baseline and follow-up images~$\bx_0, \bx_t$, we find optimal parameters $\theta$ by maximizing the posterior $\log p(\bphi_{v}^{(t)} |  \bx_{t};\bx_{0}, \ba_{0})$. For each sample~$\{\bx_t, \bx_0\}$ and predicted velocity field~$v$, we use the loss
%
\begin{equation*}
\mathcal{L}(\theta; \bphi_{v}^{(t)} , \bx_t,  \bx_0, \ba_0) =-  \log p(\bphi_{v}^{(t)} |  \bx_{t};\bx_{0}, \ba_{0})=  \frac{1}{2\sigma^2}\left\|\bx_t - \bx_0 \circ \bphi_{v}^{(t)} \right\|^2 + \gamma \left\|\nabla \bu_v \right\|^2 + cst.
\label{eq:loss}
\end{equation*}

\vspace{0.2cm}\noindent\textbf{Inference.} To predict future scans, given learned parameters $\theta^\ast$, we use the likelihood:
\begin{equation}
    \bx^\ast_t = \arg \max_{ \bx_t} p_{\theta^\ast} (\bx_t; \bx_0, \ba_0),\nonumber \approx \arg \max_{ \bx_t} p_{\theta^\ast} (\bx_t| \bphi_v^{(t)}; \bx_0, \ba_0),
\end{equation}
%
following \eqref{eq:logpost} and using a point estimate. We first compute $\bphi_v^{(t)} = \int_0^t v\, dt'$ for $v = g_{\theta^\ast}  (\bx_0, \ba_0)$, and then compute $\hat{\bx}_t = \bx_0 \circ \bphi_v^{(t)}$.



\vspace{-0.3cm}
\section{Experiments}
\vspace{-0.15cm}
\noindent\textbf{Data.}  We use the ADNI dataset~\cite{mueller2005ways} as pre-processed in~\cite{dalca2018anatomical}. For medical attributes, we select features often used in analysis: years of education, sex, APOE3, APOE4, diagnosis of the patient, and results of a Mini-Mental State Examination. Segmentation maps obtained via FreeSurfer including 29 anatomical structures are used in evaluating registration results using the Dice score and surface distance between the ground truth follow-up maps and the propagated segmentation labels.%~\cite{dice1945measures} and surface distance  between the ground truth follow-up maps and the propagated segmentation labels. 


\vspace{0.2cm}\noindent\textbf{Comparative Methods.} We consider three comparative methods. The first assumes no anatomical change between the baseline and follow-up scan. The second one gives the deformation field obtained by integration of the average registration velocity field (mean) in the training set~\cite{ashburner2007fast}. The third (oracle) is an upper bound that uses the follow-up scan and outputs the deformation field by registering the baseline~\textbf{and} the follow-up scan~\cite{balakrishnan2018unsupervised}. 

%, dalca2018unsupervised}. The third (oracle) is an upper bound which is given the follow-up scan and outputs the deformation field given the baseline~\textbf{and} the follow-up scan as given by registration~\cite{balakrishnan2018unsupervised}. 

\begin{figure}
    \centering
    \vspace{-.4cm}
    \includegraphics[width=0.85\textwidth]{figures/MIDL_MRAKIC_pic_DICE.pdf}
    \caption{\vspace{-0.5cm} 
    \textbf{Dice score evaluated for the test set.} The name of the model corresponds to the input of the network, with \texttt{ext} being the full set of external data.
    \vspace{-.3cm} }
    \label{fig:hist_results_no_atl}
\end{figure}


\begin{figure}
    \centering
    \vspace{-0.1cm}
    \includegraphics[width=.65\textwidth]{figures/dice_test_vent_pairwise_pres_SHORT.pdf}%figures/MIDL_MRAKIC_pic_VENT_PAIRWISE.pdf}
    \caption{\vspace{-0.6cm} 
    \textbf{Relative change of performance for the different subjects evaluated on ventricles.} The subjects are ordered by decreasing change of ventricle volume between the two scans.
    \vspace{-.7cm} }
    \label{fig:effect_decreases}
\end{figure}
%\begin{figure}[htbp]
%\floatconts
%    {fig:effect_decreases}
%    {\includegraphics[width=\textwidth]{figures/dice_test_vent_pairwise.pdf}}
%    {\caption{\textbf{Relative change of performance for the different subjects evaluated on ventricles.} The subjects are ordered by decreasing change of ventricle volume between the two scans.}}
%\end{figure}



\vspace{0.2cm}\noindent\textbf{Model Variants.} We train variants of the proposed model, with results given in \figureref{fig:hist_results_no_atl} and \figureref{fig:effect_decreases}.  We distinguish between subjects who experience large changes between the baseline and follow-up scans and the ones that don't. We observe that the proposed model is able to significantly improve on the baselines in some structures, such as the ventricles, and come close to the upper bound. Specifically, for ventricles, adding clinical information tends to further improve the results. 
For other structures not affected by external data, such as the hippocampi, we hypothesize that external information is instead captured in the medical scan itself and extracted by our network. Surface distance gives similar results.

\vspace{-0.3cm}
\section{Conclusion}
\vspace{-0.2cm}
We propose a deformation model and neural network architecture for predicting anatomical changes from a single baselines scan. In initial experiments, we show that the proposed architecture can extract meaningful information and lead to promising predictions. We limit our model to shape changes to focus on modelling neurodegeneration and atrophy. It would further be interesting to determine whether predictions could be enhanced by leveraging label maps during training and by incorporating intensity changes in the model.
\vspace{-0.3cm}


% Acknowledgments---Will not appear in anonymized version
%\midlacknowledgments{We thank a bunch of people.}

\vspace{-0.3cm}
\bibliography{bibliography}

\vspace{-0.3cm}
\appendix

%\section{Proof of Theorem 1}

%This is a boring technical proof of
%\begin{equation}\label{eq:example}
%\cos^2\theta + \sin^2\theta \equiv 1.
%\end{equation}

%\section{Proof of Theorem 2}

%This is a complete version of a proof sketched in the main text.

\end{document}

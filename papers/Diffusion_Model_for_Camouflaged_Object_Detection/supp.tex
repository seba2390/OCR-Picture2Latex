\documentclass{ecai}
\usepackage{subfigure}
\usepackage{graphicx}
\usepackage{latexsym}
\usepackage{multirow}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage[linesnumbered, ruled]{algorithm2e}
\ecaisubmission   % inserts page numbers. Use only for submission of paper.
                  % Do NOT use for camera-ready version of paper.


\usepackage{caption2}
% \usepackage[pagebackref,breaklinks,colorlinks]{hyperref}

% algorithm
% \usepackage{hyperref}
% \usepackage{stfloats}
% \usepackage{subfig}
\usepackage{xcolor}
% \usepackage{makecell}
\usepackage{xspace}
% \usepackage{url}
% \usepackage{wrapfig}
% \usepackage{makecell}
% \usepackage{booktabs, colortbl}
\usepackage{longtable}
\usepackage{hhline}
\usepackage{color}
% \usepackage{algpseudocode}
\usepackage{listings}
\usepackage[ruled]{algorithm2e}
\usepackage{hyperref}

\definecolor{myblue}{HTML}{0072C6}
\definecolor{myyellow}{HTML}{FFFADF}
\definecolor{myred}{HTML}{FF0000}


\hypersetup{hidelinks,
	colorlinks=true,
	allcolors=black,
	pdfstartview=Fit,
	breaklinks=true}
% listing
\lstset{
    language=Python,
    basicstyle=\ttfamily\footnotesize,
    keywordstyle=\color{myblue}\ttfamily\footnotesize,
    stringstyle=\color{myred}\ttfamily\footnotesize,
    commentstyle=\color{myyellow}\ttfamily\footnotesize,
    morecomment=[l][\color{myyellow}\ttfamily\footnotesize]{\#},
    backgroundcolor=\color{white},
    frame=none,
    rulecolor=\color{gray},
    showstringspaces=false
}

\begin{document}


\begin{frontmatter}

\title{Supplementary Material: \\Diffusion Model for Camouflaged Object Detection}
\author{Anonymous Submission}

% \author[A]{\fnms{First}~\snm{Author}\thanks{Corresponding Author. Email: somename@university.edu.}}
% \author[B]{\fnms{First}~\snm{Author}\thanks{Corresponding Author. Email: somename@university.edu.}}
% \author[C]{\fnms{First}~\snm{Author}\thanks{Corresponding Author. Email: somename@university.edu.}}
% \author[E]{\fnms{First}~\snm{Author}\thanks{Corresponding Author. Email: somename@university.edu.}}

% \author[A]{\fnms{First}~\snm{Author}\orcid{....-....-....-....}\thanks{Corresponding Author. Email: somename@university.edu.}}
%\author[B]{\fnms{Second}~\snm{Author}\orcid{....-....-....-....}}
%\author[B]{\fnms{Third}~\snm{Author}\orcid{....-....-....-....}} % use of \orcid{} is optional

% \address[A]{}
% \address[B]{}




% \begin{abstract}
% Camouflaged object detection is a challenging task that aims to identify objects that are highly similar to their background. Due to the powerful noise-to-image denoising capability of denoising diffusion models, in this paper, we propose a diffusion-based framework for camouflaged object detection, termed diffCOD, a new framework that considers the camouflaged object segmentation task as a denoising diffusion process from noisy masks to object masks. Specifically, the object mask diffuses from the ground-truth masks to a random distribution, and the designed model learns to reverse this noising process. To strengthen the denoising learning, the input image prior is encoded and integrated into the denoising diffusion model to guide the diffusion process. Furthermore, we design an injection attention module (IAM) to interact conditional semantic features extracted from the image with the diffusion noise embedding via the cross-attention mechanism to enhance denoising learning. Extensive experiments on four widely used COD benchmark datasets demonstrate that the proposed method achieves favorable performance compared to the existing 11 state-of-the-art methods, especially in the detailed texture segmentation of camouflaged objects. Our code will be made publicly available later. 


% % % Camouflaged object detection is a challenging task that aims to identify objects that are highly similar to their background. Due to the powerful noise-to-image denoising capability of denoising models, in this paper, we propose a diffusion framework for camouflaged object detection, termed diffCOD, a new framework that considers camouflaged object segmentation tasks as a denoising diffusion process from noisy images to object masks. Specifically, the object masks diffuse from ground-truth masks to random distribution, and the designed model learns to reverse this noising process. Furthermore, we design an injection attention module (IAM) that accurately guarantees the implicit correspondence between the original features and the target image through a cross-attention mechanism. Extensive experiments on four widely used COD benchmark datasets demonstrate that the proposed method achieves favorable performance compared to the existing 11 state-of-the-art methods. Our code will be made publicly available later. 
% \end{abstract}
\end{frontmatter}
% \section{Algorithm details}
% We followed improved-diffusion\footnote{https://github.com/openai/improved-diffusion} for the details about the $gamma$ in Algorithm 1 and the $p\_sample$ implementation of Algorithm 2.


\newpage
\bibliography{ecai}
\end{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Technical Notation} \label{appendix:notation}

For any event $\mathcal{E}$, we denote by $\event{\mathcal{E}} \in \{0,1\}$ the indicator variable such that $\event{\mathcal{E}} = 1$, if $\mathcal{E}$ occurs, and $\event{\mathcal{E}} = 0$, otherwise. For any non-negative integer $n \in \mathbb{N}$, we define $[n] = \{1,2, \dots, n\}$. For any vector $\mu \in \mathbb{R}^k$ and set $S \subseteq [k]$, we define $\mu(S) = \sum_{i \in S} \mu_i$. Moreover, we use the notation $t \in [a, b]$ (for $a \leq b$) for some time index $t$, in place of $t \in [T] \cap [a, \ldots , b\}$. Unless otherwise noted, we use the indices $i$, $j$ or $i'$ to refer to arms and $t$, $t'$ or $\tau$ to refer to time. Let $\A^{\pi}_t \in \I$ be the set of arms played by some algorithm $\pi \in \{\IS, \IG, \UCB\}$ at time $t$. Unless otherwise noted, all expectations are taken over the randomness of the offsets $\{r_i\}_{i \in [k]}$ and the reward realizations.

\section{Concentration inequalities}
\begin{theorem}[Hoeffding's Inequality \cite{Hoeffding}]\label{appendix:concentration:hoeffding}
Let $X_1, \dots, X_n$ be independent identically distributed random variables with common support in $[0,1]$ and mean $\mu$. Let $Y = X_1 + \dots + X_n$. Then for any $\delta \geq 0$,
\begin{align*}
    \Pro{Y-n\mu \geq \delta} \leq e^{-2\delta^2/n} \text{   and   }\Pro{Y-n\mu \leq -\delta} \leq e^{-2\delta^2/n}.
\end{align*}
\end{theorem}

\subsection{Detecting leakage through taint-analysis}\label{sec:taintanalysis}
Taint-analysis tracks the flow of ``tainted'' data, i.e., sensitive input that transforms over the course of execution to affect memory locations. This allows detecting the  information-leakage, clearing the sensitive data after their scope and also identifying the presence of malware. 

Hayes et al. \cite{hayes2017gpu} implement a GPU taint-tracking scheme which uses static binary instrumentation for performing dynamic taint tracking of GPU applications. They divide instruction operands into two types, viz., taintable and untaintable, based on whether  they can be tainted at runtime.  Examples of untaintable operands include built-in variables such as thread ID, block ID, block dimension, pointer-type kernel parameters, user-specified constants and loop-induction variables. Examples of taintable sources are image, plain-text, encryption key, etc.  Every thread tracks information-flow on its own. 

Their analysis proceeds iteratively and each iteration has two steps. In forward step, taintable/un-taintable operands are flagged at the points of taint state-transition, e.g., storing the constant value in a register switches it to the  untaintable type. In backward step, operands which can affect memory value are flagged. Remaining variables cannot flow to memory even if they are taintable, such as stack-frame pointers, loop-counters, etc. Then, only those operands which are flagged in both forward and backward steps are tracked, and this reduces the overhead of taint-tracking significantly.  

The taint record is stored in GPU registers, which reduces its access latency compared to storing it in LoM or GlM. Further, compared to CPUs, GPUs have much larger register file  \cite{mittal2016SurveyCPURF,mittal2016SurveyGPURF} and not all registers are used by most kernels. Since registers/ShM/LoM/GlM have different lifetimes, their scheme handles them differently and clears them at different times. LoM and GlM  taints are cleared at the completion of each kernel and program, respectively. The ShM is cleared after all threads of a block complete their work. Registers are cleared by each thread before exiting. 


Their scheme does not require VM emulation or a dynamic instrumentation framework which is generally unavailable on GPUs. Their approach enables  protection against the register-spilling based attack \cite{pietro2016cuda} and incurs only small performance overhead. Further, their approach allows tracking data transfers between CPU and GPU, which is especially useful in fused CPU-GPU systems. Furthermore, by using their approach, a suspicious program can be prevented from accessing uninitialized data left by other programs/users. 

\subsection{Protecting sensitive data using system management mode}\label{sec:kimSMM}

 
Kim et al. \cite{kim2016demand} present a booting scheme which uses SMM for isolating the GPU kernel and key of cryptographic algorithms.
Some works store the key in GPU registers \cite{vasiliadis2014pixelvault}.  
However, since registers are not shared between threads, every thread needs to reserve multiple (32b) registers to store the key, which degrades performance by limiting the maximum number of  kernels that can run concurrently. By comparison, storing the key in GPU cache is better since it cannot be accessed by any CPU application and its contents cannot be accessed after completion of GPU kernel. However, since the cache is hardware-managed, it is important to ensure that the key does not get evicted from the cache. To avoid this issue, they store the key in the constant cache before booting.  

  
However, by compromising the OS kernel, the adversary can launch code-injection attack to tamper GPU kernel code. To subvert this, they use SMM for isolating authenticated GPU kernel in instruction-cache. Thus, only SMI and trusted GPU kernel can access the key. Before the end of SMM, copies of kernel and key in GPU memory are cleared. After program completion, the results can be copied from GPU memory, but kernel-code and key are invalidated.  
The sensitive data is handled only in SMM, and thus, security is ensured.  
  
They note that the keys are always stored at a fixed address in GPU memory and based on this, the exact address for storing the keys in constant memory can be obtained.  The size of L1/L2/L3 constant caches are 1KB/8KB/32KB, respectively and the L2/L3 caches are shared with instruction memory. Hence, if the total key size exceeds L1 constant cache capacity, it may get evicted.  However, they note that keys are evicted only when total key size exceeds 47,520 bytes and thus up to 270 AES keys of 176 bytes each can be accommodated easily. During booting, security-unrelated and security-related tasks are performed in regular CPU mode and SMM, respectively. This reduces the overhead of SMI program and also allows leveraging the functionality of GPU driver and OS kernel which are suspended in SMM.  Their technique protects the key even when the kernel is compromised and its performance penalty is negligible. The limitation of their technique is that an adversary with physical access to the processor can subvert secure memory using a cold-boot attack. 


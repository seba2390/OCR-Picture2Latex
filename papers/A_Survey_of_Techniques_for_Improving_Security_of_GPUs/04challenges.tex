\subsection{Challenges and tradeoffs}\label{sec:challengesandtradeoffs}
Protecting GPUs, although important, presents several challenges, as we discuss below.  

\textbf{Limitations of CPU-based security solutions:} After launching the program on GPU (device), CPU (host) remains isolated and thus, it cannot monitor the execution of GPU. Hence, security mechanisms proposed on CPUs, such as a CPU taint-tracking scheme may not work for GPUs. For example, they may not detect a GPU-resident malware and thus, an attacker can use GPU as the polymorphic malware extractor whereby  the host can load the compressed/encrypted code on GPU and then call a GPU kernel to quickly unpack/decrypt the code \cite{patterson2013vulnerability}. Also, the GPU can be used for launching a brute force attack to crack the passwords. Similarly, since a sharp increase in GPU load is likely to go undetected more easily  compared to that in CPU load, a GPU malware is more stealthy. In fact, given the close interaction between GPU and the host, a compromised GPU also threatens the security of  host processor. 

\textbf{Lack of documentation and open-source tools:} Existing GPU vendors take ``security-through-obscurity approach'' for securing GPUs. As such they do not reveal complete information about GPU microarchitecture and thus, most of this information is obtained  through reverse engineering attempts only \cite{black2010cubar,envytools,naghibijouybari2017constructing}. Lack of official documentation allows GPU vendors to introduce architectural changes for boosting performance, even at the cost of jeopardizing GPU security. The scarcely-available documentation on GPU discusses only performance, and not security-related issues. 

For example, GPU binary utilizes closed-source assembly language which cannot be inspected by existing anti-virus tools. Similarly, GPU vendors do not define/document how the deallocated memory is handled  \cite{pietro2016cuda}.  Further, in GPUs, the separation of responsibilities between hardware/software is not clear and has been changing over GPU generations \cite{zhu2017understanding}. Due to this, reasoning about security guarantees becomes difficult. 


\textbf{Lack of data erasure:} GPU hardware/drivers do not erase their memories and thus, in ShM, LoM, GlM and registers, data persists after deallocation \cite{pietro2016cuda,patterson2013vulnerability}.  
Further, while most kinds of memories can be deleted by users, GPUs do not allow users to erase some kinds of memories which store sensitive data such as kernel codes, constant data and call-by-value arguments \cite{lee2014stealing}. Also, since the LoM and registers are compiler-managed, erasing them is not straightforward.  By exploiting this, an adversary can leak sensitive information.  For example, to leak information from the register file, an adversary can write a kernel with the same occupancy and thread-block size as the victim kernel. This ensures similar, predictable partitioning of register file. Then, the malicious kernel can be coded in a way to read the target registers.

 
\textbf{Increasing reliance on GPUs:} GPUs are increasingly being used for accelerating a wide variety of applications, such as browsers, document processors (e.g., Adobe reader, Microsoft Office, Libre Office), scientific computing (MATLAB) and image processing tools, etc. For instance, WebGL allows browsers to utilize GPUs for accelerating the rendering of webpages. In fact, Google Chrome provides an option for using GPU to render the  entire webpage and not merely WebGL content \cite{chromeGPU}. However, this can be leveraged to launch DoS attack remotely by somehow making a user open a malicious website which overloads users' GPUs.  Also notice that in these graphics applications, the ability to read/write GPU memory can allow an adversary to change the contents displayed on user's screen. 

Similarly, in mission-critical applications where GPUs store and process sensitive data, an attack on them can have huge financial and social consequences. For example, Zhou et al. \cite{zhou2017vulnerable} demonstrate extraction of credit card numbers and email contents from remanent data in GPU memory. Also, in companies, a malicious insider may access classified documents  which were opened on a shared GPU by an authorized user.

\textbf{Characteristics of GPU architecture and usage model:} In GPUs, the presence of multiple memories with different access rights and lifetimes complicates their security solutions and mandates individual security solutions for them. Also, since even non-privileged users can run GPU programs, a large number of users can attack or exploit GPU. Further, once the data is copied from the host memory to device memory, it is managed by the GPU driver and not the host processor/OS. However, GPU drivers may not be as rigorously evaluated from the security perspective as the existing operating systems. 


 
\textbf{Vulnerability in virtualization and cloud scenarios:} As the computational capabilities of GPU increase, a single GPU is increasingly being shared among  multiple users. As such, major cloud services provide GPU computing platforms such as Amazon web services, Google cloud platform and IBM cloud \cite{naghibijouybari2017constructing}.  However, different users in the cloud computing scenario may not trust other. For example, an adversary can rent a GPU-based VM and leak information of users using other VMs on the same system via GPU memory. Clearly, with GPU virtualization approach, the risks of information-leakage is even higher than that with native execution. 

    

\textbf{Vulnerability due to buffer overflows:} Conventionally, GPU and CPU memory were separated due to which corruption of CPU memory by GPU was difficult. Also, GPU applications did not typically perform tasks such as pointer-dereferencing, and hence, buffer corruption did not cause much harm \cite{erb2017dynamic}. Further, since GPU memory was sparsely allocated, buffer overflow did not lead to overwriting useful data. However, as recent GPUs share virtual and even physical memory with CPUs \cite{hsaRef}, buffer overflows in GPU can also lead to security and correctness problems \cite{erb2017dynamic}. Existing tools to detect GPU buffer overflow, such as Oclgrind may incur latency overheads of up to 300 times \cite{price2015oclgrind}. 

\textbf{Challenges in attacking GPUs: } While securing GPUs is challenging as mentioned above, attacking GPUs also presents challenges. By virtue of its massively parallel architecture, GPUs can simultaneously perform multiple encryptions and hence, the timing of individual encryptions cannot be measured. In fact, the encryption with the highest latency dominates the overall latency.  Further, since only one {\tt cudaContext} can run on GPU at any time, a data-leakage attack can obtain only the final snapshot of the previous process \cite{pietro2016cuda}. Similarly, in a cloud environment, both the cloud and GPU architectures offer layers of obscurity which makes it difficult to launch an attack on GPUs. 
    
The techniques discussed in the rest of this article propose strategies for overcoming these challenges. 
 
 


  

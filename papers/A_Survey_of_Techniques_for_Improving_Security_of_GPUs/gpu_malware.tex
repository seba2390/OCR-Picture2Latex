\section{Malware, Buffer-overflow and Denial-of-service Attacks}\label{sec:malwareOverflowDoS}
In this section, we discuss active attacks, viz. use of GPU malware (Section \ref{sec:malware}),  causing buffer-overflow (Section \ref{sec:bufferoverflow}) and denial-of-service (Section \ref{sec:denialofservice}).  

\subsection{Malware attack}\label{sec:malware}


   
Zhu et al. \cite{zhu2017understanding} demonstrate that discrete GPUs cannot be trusted as secure co-processors, rather, they may host stealthy malware. They study the limitations of PixelVault \cite{vasiliadis2014pixelvault} technique   which assumes  GPU hardware registers to be secure storage. PixelVault presents a GPU-accelerator for AES and RSA encryption. PixelVault assumes that after the kernel is launched, the attacker can control entire system and run the program with any privilege. Their work is based on assumptions shown in column 2 of Table \ref{tab:pvassumptionrefute} since these assumptions ensure certain properties (column 3). However, Zhu et al. refute these assumptions (column 4). 
 
 
\begin{table}[htbp]
  \centering
  \caption{PixelVault's \cite{vasiliadis2014pixelvault} assumptions and their security benefits and why they don't hold \cite{zhu2017understanding}}
    \begin{tabular}{|l|p{4.5cm}|p{5.0cm}|p{5.5cm}|}
    \hline
    No. & Assumptions & Benefits from assumption & Why assumption does not hold \\
    \hline
    1 & If the code of a running kernel is stored entirely in I-cache, it cannot be replaced. & It ensures that an attacker cannot substitute PixelVault GPU code without stopping it and hence, without losing the master key stored in GPU registers.  & The MMIO registers on NVIDIA GPUs can flush I-cache and thus, replace code of running kernels with malicious code  \\
    \hline
    2 & GPU register values cannot be obtained after the kernel terminates.  & This prohibits an attacker from obtaining a master key by stopping a running kernel. &     On launching two kernels on different CUDA streams, {\tt cuda-gdb} can leak keys stored in registers of the terminated kernel as long as the other kernel is running.    
    \\
    \hline
    3 & Unless compiled with debug support, a running kernel cannot be stopped and debugged. & It ensures that attacker cannot read registers by attaching a GPU debugger to the running PixelVault kernel. & Latest CUDA runtime allows attaching a debugger to a running kernel using root privileges.  \\
    \hline
    \end{tabular}%
  \label{tab:pvassumptionrefute}%
\end{table}%
   
They show that violation of these assumptions and unrestricted DMA access from GPU to CPU memory allow subverting the protection of IOMMU. Using this, an adversary can run stealthy malware on GPU and thus, systems based on PixelVault's approach are not secure. Note that IOMMU monitors devices' DMA to system memory for protecting them from illegitimate accesses. The IOMMU prohibits a device from accessing CPU pages which are not mentioned in its I/O page table. 
 
They further show two attacks. The first attack is on the in-kernel NVIDIA GPU driver. When the driver is being loaded and used by OS kernel, they binary-patch it. The patched driver maps sensitive CPU memory into address-space of an unprivileged GPU application. The second attack combines the microcode running on a microprocessor with malicious code to access any portion of CPU memory.


Balzarotti et al. \cite{balzarotti2015impact} divide the GPU malware into three categories based on the OS privileges required by them and the amount of knowledge they possess about internal details of the GPU driver. (1) \textit{User-space malware} have only normal privileges. They perform regular computations using standard GPU commands, without relying on any software bug. (2) \textit{Super-user malware} need elevated privileges and hence, can execute additional tasks which are not possible through user space. However, the adversary has no knowledge of the GPU driver/card. (3) \textit{Kernel-level malware} not only have elevated privileges but also know the internals of the graphic driver. Hence, they can tamper the data structures in the kernel.    
   

They further describe four strategies which the malware can adopt to avoid detection by forensic tools. (1): ``Unlimited code execution'': due to non-preemptive nature of GPU, a single task can occupy the GPU completely. To avoid this, GPU driver uses a timeout scheme (e.g.,  {\tt hangcheck} function), by which a long-lasting process can be killed. However, the malware can disable this to occupy the GPU indefinitely. (2) ``Process-less code execution'': a GPU kernel is usually always controlled by a host process. However, the malware may run a kernel without any controlling process on the host  by killing the host process right after the GPU kernel starts. 
 
 
(3) ``Context-less code execution'': The ``process-less execution'' still leaves traces in the GPU driver, e.g., the buffer objects and hardware context of the GPU kernel may still be present in the driver's memory. In ``context-less'' execution, the hardware context of GPU kernel is removed completely from the records of the driver. Thus, the kernel can hide its presence completely. Both process-less and context-less executions require that the kernel has super-user privileges and has already achieved ``unlimited code execution''. However, the latter additionally requires knowledge about driver internals. (4) ``Inconsistent memory mapping'': Generally, the list of accessible physical pages is kept both in the OS and GPU memories. However, the information kept in these two-page tables can be made to differ. Then, the OS page table points to the correct page, but the GPU address points to a random memory location. 

Table \ref{tab:antiforensic} summarizes the characteristics of these strategies along with the privileges and information needed by them. 
The last three columns show the results of memory forensic, whether it can find (1) the processes which are using GPU, (2) the code executed by them and (3) the memory regions accessible to these kernels. The \cmark sign shows that the forensic goal can be realized by inspecting only system memory. If so, the analysis may need information of only the OS data-structures or driver internals, and this is indicated as (OS) or (driver), respectively. The \xmark sign shows that the corresponding   forensic analysis is not possible.  They also recommend that checking the graphic page tables, hangcheck flag, list of buffer objects, contexts and register files can provide an insight into the type of malware present.



 
\begin{table}[htbp]
  \centering
  \caption{Characteristics of anti-forensic strategies \cite{balzarotti2015impact}}
    \begin{tabular}{|l|l|l|l|l|}
    \hline
    \multicolumn{1}{|c|}{\multirow{2}[4]{*}{Strategy}} & \multicolumn{1}{c|}{\multirow{2}[4]{*}{Privilege/knowledge requirement}} & \multicolumn{3}{c|}{Forensic objectives of listing} \\
\cline{3-5}          &       & processes & kernels & memory regions \\
    \hline
    Unlimited execution & Superuser & \cmark (OS) & \cmark (driver) & \cmark (OS) \\
    \hline
    Process-less execution & Superuser & \xmark & \cmark (driver) & \cmark (driver) \\
    \hline
    Inconsistent map & (Superuser, driver-internals) & \cmark (OS) & \cmark (driver) & \xmark \\
    \hline
    Context-less execution & (Superuser, driver-internals) & \xmark & \xmark & \xmark \\
    \hline
    \end{tabular}%
  \label{tab:antiforensic}%
\end{table}%

 
Danisevskis et al. \cite{danisevskis2013dark} demonstrate an attack whereby an adversary can exploit DMA to bypass GPU memory protection schemes  and gain access to privileged regions of the memory. They demonstrate these attacks on an Android smart-phone with sound memory isolation and security mechanisms. The adversary tricks a benign user into installing a malicious application which initially requests only normal access rights. This application seeks to escalate its privilege by patching the text section of the kernel. 
 
For this, the application patches the {\tt sys\_reboot} system-call which is called only on power-down, and thus, patching of this is likely to go unnoticed. Then,  the physical address for patching is determined and   the above system-call is attached to the session address space of the mobile-GPU. Then, they configure the GPU to change the caller's user ID to zero (or root) and write this to text section of the kernel. Based on this, they prepare a rendering job and submit it to the kernel driver. Their work confirms that DMA-based malware can pose security threats for mobile GPUs.  



Keyloggers are malware that stealthily log keyboard activity for stealing sensitive data. Ladakis et al. \cite{ladakis2013you} implement a keylogger malware on GPU which tracks the keyboard buffer directly from GPU through DMA without modifying kernel's code or data structures except for that page table. Their keylogger has two modules. A CPU-based module runs only once at the time of booting. It finds the address of keyboard buffer in physical memory, since this address may randomly change on every system boot. They implement a loadable kernel module which scans entire host memory to find this address, although its limitation is that the search time increases with increasing physical memory size. 
  
 
Then, a GPU-based module continuously tracks changes in this keyboard buffer. For this, the GPU needs to have access to the buffer. Since NVIDIA GPUs share an address space with the host process, the buffer must be mapped in the virtual address space of the host process. To achieve this, the pages where buffer resides can be included in the page table of the host process. A keystroke monitoring interval of 100ms incurs small overhead while still allowing  the capture of   keystrokes of even fast typists. Their keylogger can track all keystrokes, store this data in  the large GPU memory and process it in real-time using GPU's massive compute-power.  

 

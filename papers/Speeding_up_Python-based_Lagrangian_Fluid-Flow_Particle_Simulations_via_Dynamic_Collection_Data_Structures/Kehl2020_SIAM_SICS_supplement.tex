% SIAM Supplemental File Template
\documentclass[supplement,onefignum,onetabnum]{siamart190516} % review

\input{ex_shared}

\externaldocument{ex_article}

% Optional PDF information
\ifpdf
\hypersetup{
  pdftitle={Supplementary Materials: Speeding up Python-based Lagrangian Fluid-Flow Particle Simulations via Dynamic Collection Data Structures},
  pdfauthor={C. Kehl, E. van Sebille and A. Gibson}
}
\fi

\definecolor{newcolor}{rgb}{.8,.349,.1}

\RequirePackage[UKenglish]{babel}
\selectlanguage{UKenglish}

% declare the path(s) where your graphic files are
%\graphicspath{{./small/}{./original/}}
%\graphicspath{{./img/}}
\graphicspath{{./}}
% and their extensions so you won't have to specify these with
% every instance of \includegraphics
\DeclareGraphicsExtensions{.jpg,.jpeg,.png,.eps}
\RequirePackage[center,tight,footnotesize]{subfigure}
\RequirePackage[acronyms,shortcuts]{glossaries}
\RequirePackage[normalem]{ulem}
\input{acronyms}

\begin{document}

\maketitle


\section{Memory Access Patterns for Contiguous Arrays}
\label{sec:supplemental:memaccess}

$N x M$ arrays,  Arrays can be aligned in two patterns: in a usual and simple matter (1) the major axis represents the structure attributes aligned contiguously in memory, while the minor axis represents the multiple array items. Alternatively (2) the major axis can represent the array items contiguously aligned in memory, whereas the attributes follow the minor axis. Formally, with $N = |I|$, $I = \{x_{0}, x_{1}, ..., x_{n}\}$, and $M = |A|$ for $x(a)_{i} \forall a \in A$ (with $A$ representing or item structure \textit{attributes}), the arrays can structured as $N x M$ (1) or as (2) $M x N$. This has performance implications for the functional evaluation of the array, differing between a traditional sequential and a modern vectorized evaluation. This is shown in \cref{fig:appendix:memaccess:aos} for $N x M$ arrays (named \textit{Array of Structures (AoS)}, and in \cref{fig:appendix:memaccess:soa} for $M x N$ arrays (named \textit{Structure of Arrays (SoA)}.

\begin{figure}[htbp]
  \centering
  \includegraphics[keepaspectratio, width=0.90\columnwidth]{AoS_MemoryAccess}
  \caption{Memory access patterns related to a simple particle advection function on an $N x M$ array of structures, for sequential and vectorized evaluation (listed as assembly mnemonics).}
  \label{fig:appendix:memaccess:aos}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[keepaspectratio, width=0.90\columnwidth]{SoA_MemoryAccess}
  \caption{Memory access patterns related to a simple particle advection function on an $M x N$ structure of arrays, for sequential and vectorized evaluation (listed as assembly mnemonics).}
  \label{fig:appendix:memaccess:soa}
\end{figure}

Comparing the memory access patterns in terms of performance, we see that in traditional sequential processing the \textit{SoA} pattern is faster, as it only requires 1 cache update for each iteration whereas it requires 4 updates with an \textit{SoA} pattern. In modern computing architectures, each iteration actually executes between 2 (for multi-threaded CPUs) and 32 (for GPU warps) iterations simultaneously, thus a view on per-iteration (i.e. per-item) computations is invalid. This simultaneous computation is referred to as \textit{Vectorization} (on CPUs) or \textit{Simultaneous Multi-Processing (SMP)} (on general processors). Comparing the numbers for a 2-item evaluation, \textit{AoS} requires 2 cache updates and \textit{SoA} requires 8 cache updates when assuming a sequential processing. For vectorized processing though, evaluating 2 items requires 14 updates for \textit{AoS} and just 4 updates for \textit{SoA}. Furthermore, the number of cache changes is approximately $M \times \frac{N}{|PU|}$ (where $|PU|$ is the number of processing units), hence scaling favourably with the number of processing units and threads (in software). This naturally makes \textit{SoA} superior in performance for modern processors for $M << N$. Conversely, where $N \leq M$ one can just switch both array axes. Lastly, in practice, the layout change can be easily achieved by changing from FORTRAN-contiguous to C-contiguous order in Python arrays (or vice versa), which equally is achieved by matrix transposition. Obviously, establishing the correct item order on allocation and keeping the order static is vital, as a per-iteration matrix transposition consumes vastly more processing cycles than is saved by the \textit{SoA} evaluation.

%\begin{equation}
%  \label{eq:suppa}
%  a^2 + b^2 = c^2.
%\end{equation}
%You can also reference equations such as \cref{eq:matrices,eq:bb} 
%from the main article in this supplement.

%\begin{theorem}
%  An example theorem.
%\end{theorem}
 
%\begin{lemma}
%  An example lemma.
%\end{lemma}

%Here is an example citation: \cite{KoMa14}.

%\begin{table}[htbp]
%{\footnotesize
%  \caption{Example table}  \label{tab:foo}
%\begin{center}
%  \begin{tabular}{|c|c|c|} \hline
%   Species & \bf Mean & \bf Std.~Dev. \\ \hline
%    1 & 3.4 & 1.2 \\
%    2 & 5.4 & 0.6 \\ \hline
%  \end{tabular}
%\end{center}
%}
%\end{table}


\bibliographystyle{siamplain}
\bibliography{ParticlePerformance}


\end{document}

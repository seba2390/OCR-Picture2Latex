\documentclass[format=acmsmall, review=false, screen=true]{acmart}%{article}%

\pdfoutput=1

% Packages and macros go here
%\usepackage{lipsum}
%\usepackage{amsfonts}
\usepackage{graphicx}
%\usepackage{epstopdf}
%\usepackage[]{algorithm2e}
\usepackage{algorithmic}

%\usepackage{latexsym}
%\usepackage{mathptmx}

\usepackage{amsmath}
\usepackage{thmtools,thm-restate}
\usepackage{amssymb}
\usepackage{amsbsy}
%\let\proof\relax
%\let\endproof\relax
\usepackage{amsthm}

\usepackage{xcolor}
%\usepackage{empheq} 
%\usepackage{epsfig} % for postscript graphics files
%\usepackage{graphicx} % for pdf, bitmapped graphics files
%\usepackage{subcaption}
%\captionsetup{compatibility=false}
%\usepackage{times} % assumes new font selection scheme installed
%\usepackage{wrapfig}% embedding figures/tables in text (i.e., Galileo style)
%\usepackage{multicol}
\usepackage{bbm}
\usepackage{caption}
\usepackage{subfig}

\usepackage{amsopn}
\DeclareMathOperator{\diag}{diag}

\usepackage[capitalise]{cleveref}


%\graphicspath{{Media/}}

\DeclareMathOperator{\trace}{Tr}
\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\rank}{rank}

\renewcommand{\vec}[1]{\mathbf{#1}}
\newcommand\BlockIf[1]{\KwSty{Start If} \\ #1 \\ \KwSty{End If}}
\newcommand\BlockElseIf[1]{\KwSty{Start Else If} \\ #1 \\ \KwSty{End Else If}}
\newcommand\BlockElse[1]{\KwSty{Start Else} \\ #1 \\ \KwSty{End Else}}
\newcommand*\mean[1]{\overline{#1}}
%\newcolumntype{M}{>{\centering\arraybackslash}m{\dimexpr.25\linewidth-2\tabcolsep}}

%\def\ie{\latinabbrev{i.e}}

\usepackage{booktabs} % For formal tables
%\newtheorem{theorem}{Theorem}
%\newtheorem{proposition}{Proposition}
%\newtheorem{assumption}{Assumption}
\newtheorem{remark}{Remark}[section]
%\newtheorem{definition}{Definition}
%\newtheorem{lemma}{Lemma}
%%% Local Variables: 
%%% mode:latex
%%% TeX-master: "ex_article"
%%% End: 


\usepackage[ruled]{algorithm2e} % For algorithms
\renewcommand{\algorithmcfname}{ALGORITHM}
\SetAlFnt{\small}
\SetAlCapFnt{\small}
\SetAlCapNameFnt{\small}
\SetAlCapHSkip{0pt}
\IncMargin{-\parindent}


% Metadata Information
%\acmJournal{TOMACS}
%\acmVolume{9}
%\acmNumber{4}
%\acmArticle{39}
%\acmYear{2010}
%\acmMonth{3}
%\copyrightyear{2018}
%%\acmArticleSeq{9}
%
%% Copyright
%%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%%\setcopyright{rightsretained}
%%\setcopyright{usgov}
%%\setcopyright{usgovmixed}
%%\setcopyright{cagov}
%%\setcopyright{cagovmixed}
%
%% DOI
%\acmDOI{0000001.0000001}
%
%% Paper history
%\received{August 2018}
%\received[revised]{March 2009}
%\received[accepted]{June 2009}


% Document starts
\begin{document}
% Title portion. Note the short title for running heads
\title[Parallel Simultaneous Perturbation Optimization]{Parallel Simultaneous Perturbation Optimization}

\author{Atiye Alaeddini}
%\orcid{1234-5678-9012-3456}
%\affiliation{%
%  \institution{Institute for Disease Modeling}
%%  \streetaddress{104 Jamestown Rd}
%  \city{Bellevue}
%  \state{WA}
%  \postcode{98005}
%  \country{USA}}
%\email{aalaeddini@idmod.org}

\author{Daniel J.~Klein}
%\affiliation{%
%  \institution{Bill \& Melinda Gates Foundation}
%  \city{Seattle}
%  \state{WA}
%  \country{USA}}
%\email{daniel.klein@gatesfoundation.org}



\begin{abstract}
 Stochastic computer simulations enable users to gain new insights into complex physical systems. Optimization is a common problem in this context: users seek to find model inputs that maximize the expected value of an objective function. The objective function, however, is time-intensive to evaluate, and cannot be directly measured. Instead, the stochastic nature of the model means that individual realizations are corrupted by noise. More formally, we consider the problem of optimizing the expected value of an expensive black-box function with continuously-differentiable mean, from which observations are corrupted by Gaussian noise. We present Parallel Simultaneous Perturbation Optimization (PSPO), which extends a well-known stochastic optimization algorithm, simultaneous perturbation stochastic approximation, in several important ways. Our modifications allow the algorithm to fully take advantage of parallel computing resources, like high-performance cloud computing. The resulting PSPO algorithm takes fewer time-consuming iterations to converge, automatically chooses the step size, and can vary the error tolerance by step. Theoretical results are supported by a numerical example. To demonstrate the performance of the algorithm, we implemented the algorithm to maximize the pseudo-likelihood of a stochastic epidemiological model to data of a measles outbreak.
\end{abstract}


%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below.
%
%\begin{CCSXML}
%<ccs2012>
%<concept>
%<concept_id>10002950.10003714</concept_id>
%<concept_desc>Mathematics of computing~Mathematical analysis</concept_desc>
%<concept_significance>300</concept_significance>
%</concept>
%</ccs2012>
%\end{CCSXML}
%
%\ccsdesc[300]{Mathematics of computing~Mathematical analysis}

%
% End generated code
%


%\keywords{Stochastic Optimization, Simultaneous Perturbation, Parallel Computing, Second-Order Algorithm}




\maketitle

% The default list of authors is too long for headers.
%\renewcommand{\shortauthors}{A. Alaeddini and D. J. Klein}

\input{main}


\end{document}

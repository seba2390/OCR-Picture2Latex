\section{Conclusions}
\label{sec:conclusions}

We present SLM, a multitask, multilingual, and dual-modal speech-language model. SLM comprises a frozen pretrained speech encoder, a frozen pretrained LLM, and a light-weight adapter that maps the output of the speech encoder to the input of the LLM. Apart from the speech input, additional text input can be used as the prompts to specify the tasks that SLM needs to perform. 

In this work, we showcase the adaptation of output encodings from speech foundation model USM~\cite{zhang2023google} to input textual embeddings of large language model mT0-MT~\cite{muennighoff2022crosslingual}. Nevertheless, SLM can be easily applied as a plugin for any speech encoder and LLM pair. In future work, we will present a more comprehensive comparison across different speech encoders and both encoder-decoder and decoder-only LLMs. We will also compare different adaptation approaches, for example, residual~\cite{houlsby_etal-2019} adaptation or LoRA~\cite{hu2021lora}. 

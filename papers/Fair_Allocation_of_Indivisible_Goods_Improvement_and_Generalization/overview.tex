%\color{magenta}
\subsection{A Brief Overview of the Algorithm}\label{overview}
The purpose of this section is to present an abstract overview over the ideas behind our algorithm for finding a $3/4$-$\MMS$ allocation in the additive setting. For simplicity, we start with a simple $1/2$-$\MMS$ algorithm mentioned in Section \ref{results}. Recall that the $\bagfilling$ procedure guarantees a $1-\alpha$ approximation solution when the valuations of the agents for each item is smaller than $\alpha$. Furthermore, we know that in every $\alpha$-irreducible instance, all the agents have a value less than $\alpha$ for every items. Thus, the following simple procedure yields a $1/2$-$\MMS$ allocation:
\begin{enumerate}
\item Reduce the problem until no agent has a value more than $1/2$ for any item.
\item Allocate the items to the agents via a $\bagfilling$ procedure.
\end{enumerate} 

Figure \ref{fig:mms12} shows a flowchart for this algorithm. 
\begin{figure}[h]
\centerline{
\includegraphics[scale=0.4]{figs/12mms}
}
\caption{$1/2$-$\MMS$ Algorithm}
\label{fig:mms12}
\end{figure}

We can extend the idea in $1/2$-$\MMS$ algorithm to obtain a more efficient algorithm. Here is the sketch of the $2/3$-$\MMS$ algorithm:
consider a $2/3$-irreducible instance of the problem. In this instance, we have no item with a value more than or equal to $2/3$ to any agent. Nevertheless, the items are not yet small enough to run a $\bagfilling$ procedure. The idea here is to divide the agents into two clusters $\cone$ and $\ctwo$. Along this clustering, the items with a value  in range $[1/3,2/3)$ are given to the agents. In particular, one item is allocated to every agent in $\cone$ that is worth at least $1/3$ to him. 
Next, we refine Cluster $\cone$. In the refining procedure, if any remaining item could singly satisfy an agent in $\cone$, we do so. After building $\cone$ and $\ctwo$ and refining $\cone$, the remaining items preserve the following two invariants:
\begin{enumerate}
\item Value of every remaining item is less than $1/3$ to every remaining agent.
\item  No remaining item can singly satisfy an agent in $\cone$ (regarding the item that is already allocated to them)
\end{enumerate} 
These two invariants enable us to run a $\bagfilling$ procedure over the remaining items. For this case, the $\bagfilling$ procedure must be more intelligent: in the case that multiple agents are qualified to receive the items of the bag, we prioritize the agents. Roughly speaking, the priorities are determined by two factors: the cluster they belong to, and the cycle-envy-freeness property of the agents in $\cone$. In Figure \ref{23mms} you can see a flowchart for this algorithm. 


\begin{figure}[h]
\centerline{
\includegraphics[scale=0.4]{figs/23mms}
}
\caption{$2/3$-$\MMS$ Algorithm}
\label{23mms}
\end{figure}     

Our method for a $3/4$-$\MMS$ allocation takes one step further from the previous $2/3$-$\MMS$ algorithm.  Again, we assume that the input is $3/4$-Irreducible since otherwise it can be further simplified.  Via similar ideas, we build Cluster $\cone$ and refine it. Next, we build Clusters $\ctwo$ and $\cthree$ and refine $\ctwo$. After refining Cluster $\ctwo$, the following invariants are preserved for the remaining items:
\begin{enumerate}
\item Almost every remaining item has a value less than $1/4$ to every remaining agent. More precisely, for every remaining agent $\agent_i$, there is at most one remaining item $\ite_j$ with $\valu_i(\{\ite_j\}) \geq 1/4$.
\item  No remaining item can singly satisfy an agent in $\cone$ and $\ctwo$ (regarding the item that is already allocated to them).
\end{enumerate} 


Finally, we run a $\bagfilling$ procedure. Again, in the $\bagfilling$ procedure, the priorities of the agents are determined by the cluster they belong to, and the cycle-envy-freeness of the clusters. In Figure \ref{34mms} you can see the flowchart of the algorithm.


\begin{figure}[h]
\centerline{
\includegraphics[scale=0.4]{figs/34mms}
}
\caption{$3/4$-$\MMS$ Algorithm}
\label{34mms}
\end{figure}     

Our assumption is that the input is $3/4$-irreducible. Hence, we describe our algorithm in two phases: a clustering phase and the $\bagfilling$ phase, as shown in Figure \ref{34mms2}. 
\begin{figure}[h]
\centerline{
\includegraphics[scale=0.4]{figs/34mms2}
}
\caption{Algorithm Phases}
\label{34mms2}
\end{figure}     
In Section \ref{additive:algorithm} we show that all the steps of the algorithm can be implemented in polynomial time. Furthermore, we show that the assumption that the input is $3/4$-irreducible is without loss of generality. In fact, in Section \ref{additive:algorithm} we show that it suffices to check some invariants of irreducibility to be held in certain points of the algorithm. In Figure \ref{go}, these steps are specified with caption \emph{Reduction}. 

As a future work, one can consider a more generalized form of this algorithm, where the agents are divided into more than $3$ clusters (see Figure \ref{epsmms}). We believe that this generalization might yield a $(1-\epsilon)$-$\MMS$ allocation, where $\epsilon$ is a small value that depends on the number of agents. However, such a generalization is faced with two main barriers. First, In order to extend the idea to more than 3 clusters, we need a generalized form of Lemmas \ref{remove2} and \ref{remove3} for more than two items. Furthermore, a challenging part of our approximation proof is to show that the second cluster is empty at the end of the algorithm. For this, we define a graph on the items in the second cluster and prove some bounds on the number of edges in this graph. To extend the idea for more clusters, we need to define hypergraphs on the items in the clusters and show similar bounds, which requires deeper and more complicated techniques..   
%\color{black}
\begin{figure}[h]
\centerline{
\includegraphics[scale=0.55]{figs/epsmms}
}
\caption{Generalizing the algorithm into $k$ clusters}
\label{epsmms}
\end{figure}  

Before presenting the algorithm, in Section \ref{additive:observations} we discuss the consequences of irreducibility and  techniques to build the clusters and preserving cycle-envy-freeness in each cluster. Next, we describe the algorithm in more details. 

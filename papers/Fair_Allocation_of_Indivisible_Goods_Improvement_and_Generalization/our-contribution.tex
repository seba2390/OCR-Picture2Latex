\subsection{Our Results and Techniques}\label{results}
Throughout this paper, we study the fair allocation problem for additive and non-additive agents.
\procacciafirst~\cite{Procaccia:first} study the fair allocation problem and show a $2/3$-$\MMS$ allocation is guaranteed to exist for any number of additive agents. We improve this result in two different dimensions: (i) we improve the factor $2/3$ to a factor $3/4$ for additive agents. (ii) we provide similar guarantees for submodular, fractionally subadditive, and subadditive agents. Moreover, we provide algorithms that find such allocations in polynomial time. A brief summary of our results is illustrated in Tables \ref{resultstable} and \ref{resultstable2}.



\subsubsection{Additive Setting}

While the existence of a $1/2$-$\MMS$ allocation is trivial in additive setting (see the rest of this section for more details), obtaining a better bound is more complicated. As mentioned before, the pioneering work of \procacciafirst ~\cite{Procaccia:first} presented the first proof to the existence of a $2/3$-$\MMS$ allocation in the additive setting. 
On the negative side, they show that their analysis is tight, i.e. % for any $\epsilon > 0$, there exists an example, where $\rho \leq 2/3+\epsilon$. Hence, 
their method cannot be used to obtain a better approximation guarantee. However, whether or not a better bound could be achieved via a more efficient algorithm remains open as \procacciafirst~\cite{Procaccia:first} pose this question as an open problem.



We answer the above question in the affirmative. Our main contribution is a proof to the existence of a $3/4$-$\MMS$ allocation for additive agents. Furthermore, we show that such an allocation can be found in polynomial time. This result improves the work of \procacciafirst ~\cite{Procaccia:first} and \amanatidisapproximation ~\cite{amanatidis2015approximation} where the former gives a proof to the existence of a $2/3$-$\MMS$ allocation and the latter presents a PTAS algorithm for finding a $2/3$-$\MMS$ allocation.

\begin{table}[t]
	\caption{Summary of the results}
	\hspace{-1cm}\begin{tabular}{|l|c|c|c|c|}
		\hline
		& Additive & Submodular & XOS & Subadditive\\
		\hline
		Previous work (existential proof) & $2/3$-$\MMS$  ~\cite{Procaccia:first} & $1/10$-$\MMS$ \cite{barman2017approximation}\footnote{In a parallel work to ours, Barman and Murthy in \cite{barman2017approximation} (\textbf{EC'17}) considered the submodular case and proposed a $1/31$ approximation guarantee.}&- &-\\
		Previous work (polytime algorithm) &  $2/3-\epsilon$-$\MMS$  ~\cite{amanatidis2015approximation} & $1/31$-$\MMS$ ~\cite{barman2017approximation} & - & -\\
		Previous work (upper bound) & $1-\epsilon$-$\MMS$ ~\cite{Procaccia:first} & - & - & -\\
		\hline
		\color{magenta}Our results \color{black} (existential proof) & $3/4$-$\MMS$ & $1/3$-$\MMS$ & $1/5$-$\MMS$  & $1/10 \lceil\log m\rceil$-$\MMS$ \\
		& \color{magenta}Theorem \ref{34main}\color{black} & \color{magenta}Theorem \ref{submodulartheorem}\color{black}& \color{magenta} Theorem \ref{xosproof} \color{black}& \color{magenta} Theorem \ref{subadditiveproof} \color{black}\\
		\hline
		\color{magenta}Our results \color{black} (polytime algorithm) &  $3/4-\epsilon$-$\MMS$ & $1/3$-$\MMS$ & $1/8$-$\MMS$ & -\\
		
		& \color{magenta} Theorem \ref{addpoly} \color{black} & \color{magenta} Theorem \ref{subsubalg} \color{black} & \color{magenta} Theorem \ref{xa} \color{black} & \\
		
		\hline
		
		\color{magenta}Our results \color{black} (upper bound) & - & $3/4$-$\MMS$ & $1/2$-$\MMS$ & $1/2$-$\MMS$\\
		& & \color{magenta} Theorem \ref{xosupperbound} \color{black} & \color{magenta} Theorem \ref{subupperbound} \color{black} &  \color{magenta} Theorem \ref{subupperbound} \color{black} \\
 		\hline
	\end{tabular}
	
	
	
	\begin{tablenotes}
		\item
		\item
	\end{tablenotes}
	\label{resultstable}
\end{table}

\begin{table}[t]\centering
	\caption{Results for a limited number of agents in the additive setting}
	\begin{tabular}{|l|c|c|c|c|}
		\hline
		& $n=3$ & $n=4$\\
		\hline
		\procacciafirst ~\cite{Procaccia:first}  & $3/4$-$\MMS$  & $3/4$-$\MMS$\\
		\hline
		\amanatidisapproximation ~\cite{amanatidis2015approximation}  & $7/8$-$\MMS$  & -\\
		\hline
		\color{magenta}Our result \color{black} & - & $4/5$-$\MMS$\\
		& & \color{magenta} Theorem \ref{45main} \color{black}\\
		\hline
	\end{tabular}
	
	
	\begin{tablenotes}
		\item
		\item
		\item
	\end{tablenotes}
	
	\label{resultstable2}
\end{table}

\vspace{0.2cm}
{\noindent \textbf{Theorem} \ref{addpoly} [restated]. \textit{Any fair allocation problem with additive agents admits a $3/4$-$\MMS$ allocation. Moreover, a $(3/4-\epsilon)$-$\MMS$ allocation can be found in time $\poly(n,m)$ for any $\epsilon > 0$.\\}}

The result of Theorem \ref{addpoly} is surprising, since most of the previous methods provided for proving the existence of a $2/3$-$\MMS$ allocation were tight.  
This convinced many in the community that $2/3$ is the best that can be guaranteed. This shows that the current techniques and known structural properties of maxmin share are not powerful enough to prove the bounds better than $2/3$. In this paper, we provide a better understanding of this notion by demonstrating several new properties of maxmin share. For example, we introduce a generalized form of reducibility and develop double counting techniques that are closely related to the concept of maxmin-share.  


For a better understanding of our algorithm, we start with the case where valuations of the agents for all items are small enough. More precisely, let $0 < \alpha < 1$ be a constant number and assume for every agent $\agent_i$ and every item $\ite_j$, the value of agent $\agent_i$ for item $\ite_j$ is bounded by $\alpha \MMS_i$. In this case, we propose the following simple procedure to allocate the items to the agents.

\begin{itemize}
	\item Arrange the items in an arbitrary order.
	\item Start with an empty bag and add the items to the bag one by one with respect to their order.
	\item Every time the valuation of an agent $\agent_i$ for the set of items in the bag reaches $(1-\alpha)\MMS_i$, give all items of the bag to that agent, and continue with an empty bag.  In case many agents are qualified to receive the items, we choose one of them arbitrarily. From this point on, we exclude the agent who received the items from the process.
\end{itemize}
We call this procedure the $\bagfilling$ algorithm. One can see this algorithm as an extension of the famous moving knife algorithm for indivisible items.
It is not hard to show that the $\bagfilling$ algorithm guarantees a $(1-\alpha)$-$\MMS$ allocation to all of the agents. The crux of the argument is to show that every agent receives at least one bag of items. To this end, one could argue that every time a set of items is allocated to an agent $\agent_i$, no other agent $\agent_{j}$ loses a value more than $\MMS_j$. This, together with the fact that $\valu_i(\items) \geq n \MMS_i$, shows that at the end of the algorithm, every agent receives a fair share ($(1-\alpha)$-$\MMS$) of the items. 

This observation sheds light on the fact that low-value items can be distributed in a more efficient way. Therefore, the main hardness is to allocate the items with higher values to the agents. To overcome this hardness, we devise a clustering method.
Roughly speaking, we divide the agents into three clusters according to their valuation functions. We prove desirable properties for the agents of each cluster. Finally, via a procedure that is similar in spirit to the $\bagfilling$ algorithm but more complicated, we allocate the items to the agents. 

Our clustering method is based on three important principles: \textit{reducibility}, \textit{matching allocation}, and \textit{cycle-envy-freeness}. %\edit{As we discuss, these principles were partially used in the previouse works.} 
We give a brief description of each principle in the following.

\textbf{Reducibility:} The reducibility principle is very simple and elegant but plays an important role in the allocation process. Roughly speaking, consider a situation where for an agent $\agent_i$ and a set $S$ of items we have the following properties:
$$\valu_i(S) \geq \alpha \MMS_i$$
and $$ \forall \agent_j \neq \agent_i \qquad \MMS_j^{n-1}(\items \setminus S) \geq \MMS_j,$$ where $\valu_i(S)$ is the valuation of agent $\agent_i$ for subset $S$ of items. Intuitively, since the maxmin shares of all agents except $\agent_i$ for the all items other than set $S$ are at least as much as their current maxmin shares, allocating set $S$ to $\agent_i$ cannot hurt the guarantee. In other words, given that an $\alpha$-$\MMS$ allocation is possible for all agents except $\agent_i$ with items not in $S$, we can allocate set $S$ to agent $\agent_i$ and recursively solve the problem for the rest of the agents. Although the definition of reducibility is more general than what mentioned above, the key idea is that reducible instances of the problem can be transformed into irreducible instances. More precisely, we show that in order to prove the existence of an $\alpha$-$\MMS$ allocation, it only suffices to show this for $\alpha$-irreducible instances of the problem (see Observation \ref{reducibility}). This makes the problem substantially simpler, since $\alpha$-irreducible instances of the problem have many desirable properties. For example, in such instances, the value of every agent $\agent_i$ for each item is less than $\alpha \MMS_i$ (see Lemma \ref{remove1}). By setting $\alpha = 1/2$, this observation along with the analysis of the $\bagfilling$ algorithm, proves the existence of a $1/2$-$\MMS$ allocation. It is worth to mention that a special form of reducibility, where $|S|=1$ is used in the previouse works~\cite{amanatidis2015approximation,Procaccia:first}. %\edit{Moreover,  the method used in \cite{Procaccia:first} to obtain a $2/3$-$\MMS$ allocation can somehow be interpreted as approximately reducing the instances. }

%\edit{Furthermore, a simpler form of this principle  is used to bound the value of the items for the agetns in the previouse work by  \procacciafirst to obtain a $2/3$-$\MMS$ allocation. }


\textbf{Matching allocation:} At the core of the clustering part, we use a well-structured type of matching to allocate the items to the agents. Intuitively, we cluster the agents to deal with high-value or in other words \textit{heavy} items. %Considering a threshold $\beta$, by the term heavy, we mean items with value at least $\beta$ for at least one agent.  
In order to cluster a group of agents, we find a subset $T$ of agents and a subset $S$ of items, together with a matching $M$ from $S$ to $T$. We choose $T$, $S$, and $M$ in a way that (i) every item assigned to an agent has a value of at least $\beta$ to him, (ii) agents who do not receive any items have a value less than $\beta$ for each of the assigned items. Such an allocation requires careful application of several properties of maximal matchings in bipartite graphs described in Section \ref{additive:observations}.  A matching with similar structural properties is previousely used by Procaccia and Wang \cite{Procaccia:first} to allocate the bundles to the agents. In this paper, we reveal more details and precisely characterise the structure of such matchings. We use such matchings in two main steps: selecting the agents for the first and second clusters and merging the items. 


%We also show that after separating a cluster, the remaining items and agents have desirable properties.

%It's worth mentioning that in our algorithm, the threshold for assuming an item heavy, is $1/2 \MMS$. 

\textbf{Cycle-envy-freeness:} Envy-freeness is itself a well-known notion for fairness in the resource allocation problems. However, this notion is perhaps more applicable to the allocation of divisible goods. In our algorithm, we use a much weaker notion of envy-freeness, namely \textit{cycle-envy-freeness}. A cycle-envy-free allocation contains no cyclic permutation of agents, such that each agent envies the next agent in the cycle. In the clustering phase, we choose a matching $M$ in a way that preserves cycle-envy-freeness for the clustered agents. More details about this can be found in Section \ref{additive:clusters}. 

Cycle-envy-freeness plays a key role in the second phase of the algorithm. As aforementioned, our method in the assignment phase is closely related to the $\bagfilling$ procedure described above. The difference is that the efficiency of our method depends on the order of the agents who receive the items. Based on the notion of cycle-envy-freeness, we prioritize the agents and, as such, we show the allocation is fair. An analogous concept is previousely used in \cite{Saberi:first}, albeit with a different application than ours. 

As mentioned before, our algorithm consists of two phases: (i) clustering the agents and (ii) satisfying the agents. In the first phase, we cluster the agents into three sets namely $\cone$,$\ctwo$, and $\cthree$. In addition to this, for $\cone$ and $\ctwo$ we also have refinement procedures to make sure the rest of the unallocated items have a low value to the agents of these clusters. In the second phase, based on a method similar to the $\bagfilling$ algorithm described above, we allocate the rest of the items to the agents. A flowchart of our algorithm is depicted in Figure \ref{go}. The main steps along with brief descriptions of each step are highlighted in the flowchart. In section \ref{overview}, we present the ideas behind each of these steps and show how the entire algorithm leads to a proper allocation. 


In Appendix \ref{45}, we study the case where we only have four additive agents. \procacciafirst~\cite{Procaccia:first} showed that in this case a $3/4$-$\MMS$ allocation is possible. We improve this result by giving an algorithm that finds a $4/5$-$\MMS$ allocation in this restricted setting. Note that this also leads to an algorithm that finds a $4/5-\epsilon$-$\MMS$ allocation in polynomial time.  \amanatidisapproximation~\cite{amanatidis2015approximation} also show that a $7/8$-$\MMS$ allocation is possible when the number of agents is equal to 3. These results indicate that better bounds can be achieved for the additive setting. We believe our framework can be used as a building block to obtain better bounds (see Section \ref{overview} for more details).

\begin{figure}[!htbp]
\centerline{
\includegraphics[scale=0.8]{figs/go.pdf}
}
\caption{A flowchart of the $3/4$-$\MMS$ allocation algorithm}
\label{go}
\end{figure} 

\subsubsection{Submodular, XOS, and Subadditive Agents}
Although the problem was initially proposed for additive agents, it is very well-motivated to extend the definition to other classes of set functions. For instance, it is quite natural to expect an agent prefers to receive two items of value 400, rather than receiving 1000 items of value 1. Such a constraint cannot be imposed in the additive setting. However, submodular functions which encompass $k$-demand valuations are strong tools for modeling these constraints. Such generalizations have been made to many similar problems, including the \textit{Santa Claus max-min fair allocation}, \textit{welfare maximization}, and \textit{secretary} problems ~\cite{bateni2013submodular,feige2009maximizing,feige2011maximizing,golovin2005max}. The most common classes of set functions that have been studied before are submodular, XOS, and subadditive functions. We consider the fair allocation problem when the agents' valuations are in each of these classes. In contrast to the additive setting in which finding a constant $\MMS$ allocation is trivial, the problem becomes much more subtle even when the agents' valuations are \textit{monotone submodular}. For instance, the $\bagfilling$ algorithm does not promise any constant approximation factor for submodular agents, while it is straight-forward to show it guarantees a $(1-\alpha)$-$\MMS$ allocation for additive agents.


We begin with submodular set functions. In Section \ref{submodular}, we show that the fair allocation problem with submodular agents admits a $1/3$-$\MMS$ allocation. In addition, we show, given access to \textit{query oracles}, one can find such an allocation in polynomial time. We further complement our result by showing that a $3/4$-$\MMS$ is the best guarantee that one can hope to achieve in this setting. This is in contrast to the additive setting for which the only upper bound is that $1$-$\MMS$ allocation is not always possible. We begin by stating an existential proof.

\vspace{0.2cm}
{\noindent \textbf{Theorem} \ref{submodulartheorem} [restated]. \textit{The fair allocation problem with submodular agents admits a $1/3$-$\MMS$ allocation. 
 \\}}

Our proof for submodular agents is fundamentally different from that of the additive setting. First, without loss of generality, we assume $\MMS_i = 1$ for every agent $\agent_i \in \agents$. Moreover, we assume the problem is $1/3$-irreducible since otherwise we can reduce the problem. Next, given a function $f(.)$, we define the \textit{ceiling function} $f^x(.)$ as follows:
$$f^x(S) = \min\{x, f(S)\} \hspace{1cm}\forall S \subseteq \domp(f).$$
An important property of the ceiling functions is that they preserve submodularity, fractionally subadditivity, and subadditivity (see Lemma \ref{ceilingfunctions}). We define the bounded welfare of an allocation $\mathcal{A}$ as $\sum \valu_i^{2/3}(A_i)$. Given that, we show an allocation that maximizes the bounded welfare is $1/3$-$\MMS$. To this end, let $\mathcal{A}$ be an allocation with the maximum bounded welfare and suppose for the sake of contradiction that in such an allocation, an agent $\agent_i$ receives a bundle of worth less than $1/3$ to him. Since $\MMS_i = 1$, agent $\agent_i$ can divide the items into $n$ sets, where each set is of worth at least $1$ to him. Now, we randomly select an element $\ite_j$ which is \textit{not} allocated to $\agent_i$. By the properties of submodular functions, we show the expected contribution of $\ite_j$ to the valuation function of $\agent_i$ is more than the expected contribution of $\ite_j$ to the bounded welfare of the allocation. Therefore, there exists an item $\ite_j$ such that if we allocate that item to agent $\agent_i$, the total bounded welfare of the allocation will be increased. This contradicts the maximality of the allocation.

Notice that Theorem \ref{submodulartheorem} is only an existential proof. A natural approach to find such a solution is to start with an arbitrary allocation and iteratively increase its bounded welfare until it becomes $1/3$-$\MMS$. The main challenge though is that we do not even know what the $\MMS$ values are. Furthermore, unlike the additive setting, we do not have any PTAS algorithm that provides us a close estimate to these values. To overcome this challenge, we propose a combinatorial trick to guess these values without incurring any additional factor to our guarantee. The high level idea is to start with large numbers as estimates to the $\MMS$ values. Every time we run the algorithm on the estimated values, it either finds a desired allocation, or reports that the maxmin value of an agent is misrepresented by at least a multiplicative factor. Given this, we divide the maxmin value of that agent by that factor and continue on with the new estimates. Therefore, at every step of the algorithm, we are guaranteed that our estimates are not less than the actual $\MMS$ values. Based on this, we show that the running time of the algorithm is polynomial, and that the allocation it finds in the end has the desired properties. The reader can find a detailed discussion in Section \ref{latter}.

\vspace{0.2cm}
{\noindent \textbf{Theorem} \ref{subsubalg} [restated]. \textit{Given access to query oracles, one can find a $1/3$-$\MMS$ allocation to submodular agents in polynomial time.\\}}


Finally, we show that in some instances with submodular agents, no allocation is better than $3/4$-$\MMS$.

\vspace{0.2cm}
{\noindent \textbf{Theorem} \ref{subupperbound} [restated]. \textit{For any integer number $c > 0$, there exists an instance of the fair allocation problem with $n \geq c$  submodular agents for which no allocation is better than $3/4$-$\MMS$.
\\}}


We show Theorem \ref{subupperbound} by a counter-example. In this counter-example we have $n$ agents and $2n$ items. Moreover, the valuation functions of the first $n-1$ agents are the same, but the last agent has a slightly different valuation function that makes it impossible to find an allocation which is better than $3/4$-$\MMS$. The number of agents in this example can be arbitrarily large.


In Section \ref{xos}, we study the problem with fractionally subadditive (XOS) agents. We first give a $1/2$ upper bound on the quality of any allocation. In other words, we show that for some instances of the problem, no allocation can guarantee anything better than $1/2$-$\MMS$ when the agents valuations are XOS. This is followed by a proof to the existence of a $1/5$-$\MMS$ allocation for any instance of the problem with XOS agents.


Similar to the submodular setting, we also provide an upper bound on the quality of any allocation in the XOS setting. We show Theorem \ref{xosupperbound} by a counter-example.

\vspace{0.2cm}
{\noindent \textbf{Theorem} \ref{xosupperbound} [restated].\textit{ For any integer number $c$, there is an instance of the fair allocation problem with XOS agents where $n \geq c$ and no allocation is better than $1/2$-$\MMS$.\\}}

Next, we state the main theorem of this section.

\vspace{0.2cm}
{\noindent \textbf{Theorem} \ref{xosproof} [restated].\textit{ The fair allocation problem with XOS agents admits a $1/5$-$\MMS$ allocation.\\}}

Our approach for proving Theorem \ref{xosproof} is similar to the proof of Theorem \ref{submodulartheorem}. Again, we scale the valuations to make sure $\MMS_i = 1$ all agents and define the notion of bounded welfare, but this time as $\sum \valu_i^{2/5}(A_i)$. However, as XOS functions do not adhere to the nice structure of submodular functions, we use a different analysis to prove this theorem. Let $\mathcal{A}$ be an allocation with the maximum bounded welfare. In case all agents receive a value of at least $1/5$, the proof is complete. Otherwise, let $\agent_i$ be an agent that receives a set of items whose value to him is less than $1/5$. In contrast to the submodular setting, giving no item alone to $\agent_i$ can guarantee an increase in the bounded welfare of the allocation. However, this time, we show there exists a set $S$ of items such that if we take them back from their recipients and instead allocate them to agent $\agent_i$, the bounded welfare of the allocation increases. The reason this holds is the following: since $\MMS_i = 1$, agent $\agent_i$ can split the items into $2n$ sets where every set is worth at least $2/5$ to $\agent_i$, otherwise the problem is $1/5$-reducible (see Lemma \ref{2nsets}). Moreover, since the valuation functions are XOS, we show that giving one of these $2n$ sets to $\agent_i$ will increase the bounded welfare of the allocation. Therefore, if $\mathcal{A}$ is maximal, then $\mathcal{A}$ is also $1/5$-$\MMS$.

Finally, we show that a $1/8$-$\MMS$ allocation in the XOS setting can be found in polynomial time. Our algorithm only requires access to demand and XOS oracles. Note that this bound is slightly worse than our existential proof due to some computational hardnesses. However, the blueprint of the algorithm is based on the proof of Theorem \ref{xosproof}.

\vspace{0.2cm}
{\noindent \textbf{Theorem} \ref{xa} [restated]. \textit{ Given access to demand and XOS oracles, we can find a $1/8$-$\MMS$ allocation for the problem with XOS agents in polynomial time.
\\}}

We start with an arbitrary allocation and increase the bounded welfare until the allocation becomes $1/8$-$\MMS$. The catch is that if the allocation is not $1/8$-$\MMS$, then there exists an agent $\agent_i$ and a set $S$ of items such that if we take back these items from their current recipients and allocate them to agent $\agent_i$, the bounded welfare of the allocation increases. In order to increase the bounded welfare, there are two computational barriers that need to be lifted. First, similar to the submodular setting, we do not have any estimates to the $\MMS$ values. Analogously, we resolve the first issue by iteratively guessing the $\MMS$ values. The second issue is that in every step of the algorithm, we have to find a set $S$ of items to allocate to an agent $\agent_i$ that results in an increase in the bounded welfare. Such a set $S$ cannot be trivially found in polynomial time. That is where the demand and XOS oracles take part. In Section \ref{former} we show how to find such a set in polynomial time. The high-level idea is the following: first, by accessing the XOS oracles, we determine the contribution of every item to the bounded welfare of the allocation. Next, we set the price of every element equal to three times the contribution of that element to the bounded welfare and run the demand oracle to find which subset has the highest profit for agent $\agent_i$. We show this subset has a value of at least $1/4$ to $\agent_i$. Next, we sort the elements of this set based on the ratio of contribution to the overall value of the set over the price of the item, and select a prefix for them that has a value of at least $1/4$ to $\agent_i$. Finally, we argue that allocating this set to $\agent_i$ increases the bounded welfare of the allocation by at least some known lower bound. This, married with the combinatorial trick to guess the $\MMS$ values, gives us a polynomial time algorithm to find a $1/8$-$\MMS$ allocation.

Note that an immediate corollary of Theorems \ref{xa} and \ref{subsubalg} is a polynomial time algorithm for approximating the maxmin value of a submodular and an XOS function within factors $1/3$ and $1/8$, respectively. 
\begin{corollary}
Let $f$ be a submodular/XOS function on a set of ground elements $S$, and let $n$ be an integer number. Given access to query oracle/demand and XOS oracles of $f$, we can partition the elements of $S$ into $n$ disjoint subsets $S_1, S_2, \ldots, S_n$ such that 
$$\min_{i=1}^n f(S_i) \geq c\cdot\MMS_f^n$$
where $\MMS_f^n$ denotes the maxmin value for function $f$ on $n$ subsets. Constant $c$ equals $1/3$ if $f$ is submodular and is equal to $1/8$ for the XOS case.
\end{corollary}


Finally, we investigate the problem when the agents are subadditive and present an existential proof based on a reduction to the XOS setting. In Section \ref{subadditive}, we present a lemma that enables us to 
reduce the problem with subadditive agents to the case where agents are XOS.
\begin{lemma}\label{rr1}
	Given a subadditive set function $f(.)$ which is defined on a set $\domp(f)$ and an integer number $n$, there exists an XOS function $g(.)$ such that  
	$$\MMS_g^n \geq \MMS_f^n / \bigg( 2 \lceil \log |\domp(f)|\rceil \bigg)$$
	and $g(S) \leq f(S)$ for every set $S \subseteq \domp(f)$.
\end{lemma}
Proof of Lemma \ref{rr1} follows from the known techniques for reducing subadditive valuations to XOS. For the sake of completeness, we bring a formal proof in Section \ref{subadditive}.
%follows from a primal-dual argument. 
\begin{comment}
Consider the following problem: given a subadditive function $f$, we wish to find an additive function $g$ which is dominated by $f$ and $g(\domp(f))$ is maximal. This problem can be easily formulated by the following linear program:

\begin{alignat}{3}\label{oo1}
\text{maximize: }& \hspace{0.5cm} &  \sum_{\ite_i \in \domp(f)}g_i & &\\
\text{subject to: }& & \sum_{\ite_i \in S}g_i \leq f(S) & \hspace{1cm}&\forall S \subseteq \domp(f)\nonumber\\
& & g_i \geq 0 & &\forall \ite_i \in \domp(f)\nonumber
\end{alignat}
By the strong duality theorem, the optimal solution of LP \ref{oo1} is equal to the optimal solution of the following linear program.

\begin{alignat}{3}\label{oo2}
\text{minimize: }& \hspace{0.5cm}& \sum_{S \subseteq \domp(f)} \alpha_S f(S)   & &\\
\text{subject to: }& & \sum_{S \ni \ite_i} \alpha_S \geq 1 & \hspace{1cm}&\forall \ite_i \in \domp(f)\nonumber\\
& & \alpha_S \geq 0 & &\forall S \subseteq \domp(f)\nonumber
\end{alignat}

Next, via a probabilistic argument, we show that the objective function of LP \ref{oo2} is at least $f(\domp(f))/\lceil 2\log |\domp(f)|\rceil$. To this end, consider the following randomized procedure:
\begin{itemize}
	\item Let $S^*$ be an empty set.
	\item Iterate over all sets $S \subseteq \domp(f)$.
	\begin{itemize}
		\item For every set $S$, with probability $\alpha_S$ set $S^* = S^* \cup S$
	\end{itemize}
\end{itemize}
We show that every element $\ite_j$ appears in $S^*$ with probability at least $1/2$. Moreover, the expected value of $f(S^*)$ is no more than the objective value of LP \ref{oo2}. Based on this, we show that $$\mathbb{E}[f(S^*)] \geq f(\domp(f))/\lceil 2\log |\domp(f)|\rceil.$$ The crux of the argument is that if we use the same randomized procedure and generate $O(\log m)$ independent sets, the union of these sets contains all of the elements with a considerable probability. On the other hand, since the function is subadditive, its value for the union of the sets is no less than the total sum of the values for the sets. This proves $\mathbb{E}[f(S^*)] \geq f(\domp(f))/\lceil 2\log |\domp(f)|\rceil$ which implies the lemma.
 This lemma as a black box shows that every subadditive function $f$ can be approximated via an XOS function whose $\MMS$ is within a factor $1/2\lceil \log |\domp(f)|\rceil$ of its maxmin value. 
As an immediate corollary of Lemma \ref{rr1}, we show that the fair allocation problem with subadditive agents admits a $1/10 \lceil\log m\rceil$-$\MMS$ allocation.
\end{comment}

\vspace{0.2cm}
{\noindent \textbf{Theorem} \ref{subadditiveproof} [restated].\textit{ The fair allocation problem with subadditive agents admits a $1/10 \lceil\log m\rceil$-$\MMS$ allocation.\\}}


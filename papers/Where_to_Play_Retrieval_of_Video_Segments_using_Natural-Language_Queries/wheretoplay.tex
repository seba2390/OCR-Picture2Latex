\documentclass[sigconf]{acmart}

\usepackage{booktabs} % For formal tables
\usepackage{color}
\usepackage{multirow}
\usepackage{colortbl}
\usepackage{enumitem,kantlipsum}
\usepackage{diagbox}

% Copyright
%\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}


% DOI
\acmDOI{10.475/123_4}

% ISBN
\acmISBN{123-4567-24-567/08/06}

%Conference
%\acmConference[MM'17]{ACM Multimedia conference}{October 2017}{Mountain View, CA USA} 
\acmConference[UNDER REVIEW IN ACM MM]{20}{April}{2017} 
%\acmYear{2017}
%\copyrightyear{2017}

\acmPrice{15.00}


\begin{document}
\title{Where to Play: Retrieval of Video Segments using Natural-Language Queries}
% \titlenote{Produces the permission block, and
%  copyright information}
% \subtitle{Extended Abstract}
% \subtitlenote{The full version of the author's guide is available as
%  \texttt{acmart.pdf} document}


%\author{Anonymity}


%\iffalse
\author{Sangkuk Lee}
\affiliation{%
  \institution{Seoul National University}
  \streetaddress{1 Gwanak-ro, Gwanak-gu}
  \city{Seoul} 
  \state{Republic of Korea} 
  \postcode{151-742}
}
\email{sangkuklee@snu.ac.kr}

\author{Daesik Kim}
\affiliation{%
  \institution{Seoul National University}
  \streetaddress{1 Gwanak-ro, Gwanak-gu}
  \city{Seoul} 
  \state{Republic of Korea} 
  \postcode{151-742}
}
\email{daesik.kim@snu.ac.kr}

\author{Myunggi Lee}
\affiliation{%
  \institution{Seoul National University}
  \streetaddress{1 Gwanak-ro, Gwanak-gu}
  \city{Seoul} 
  \state{Republic of Korea} 
  \postcode{151-742}
}
\email{myunggi89@snu.ac.kr}

\author{Jihye Hwang}
\affiliation{%
  \institution{Seoul National University}
  \streetaddress{1 Gwanak-ro, Gwanak-gu}
  \city{Seoul} 
  \state{Republic of Korea} 
  \postcode{151-742}
}
\email{hjh881120@snu.ac.kr}

\author{Nojun Kwak}
\affiliation{%
  \institution{Seoul National University}
  \streetaddress{1 Gwanak-ro, Gwanak-gu}
  \city{Seoul} 
  \state{Republic of Korea} 
  \postcode{151-742}
}
\email{nojunk@snu.ac.kr}
%\fi

% The default list of authors is too long for headers}
\renewcommand{\shortauthors}{S. Lee et al.}
%\renewcommand{\shortauthors}{Anonymity}
\newcommand{\etal}{\textit{et al}. } 
\newcommand{\ie}{\textit{i}.\textit{e}. } 

\begin{abstract}
In this paper, we propose a new approach for retrieval of video segments using natural language queries. Unlike most previous approaches such as concept-based methods or rule-based structured models, the proposed method uses image captioning model to construct sentential queries for visual information. In detail, our approach exploits multiple captions generated by visual features in each image with `Densecap'. Then, the similarities between captions of adjacent images are calculated, which is used to track semantically similar captions over multiple frames. Besides introducing this novel idea of 'tracking by captioning', the proposed method is one of the first approaches that uses a language generation model learned by neural networks to construct semantic query describing the relations and properties of visual information. To evaluate the effectiveness of our approach, we have created a new evaluation dataset, which contains about 348 segments of scenes in 20 movie-trailers. Through quantitative and qualitative evaluation, we show that our method is effective for retrieval of video segments using natural language queries.

\iffalse
We show that our approach is able to locate a major portion of the objects described in the query with high accuracy, and improve the relevance in video retrieval.
\fi


%\footnote{This is an abstract footnote}
\end{abstract}

%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below. 
%
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10002951.10003317.10003371.10003386.10003388</concept_id>
<concept_desc>Information systems~Video search</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10010147.10010178.10010224.10010225.10010231</concept_id>
<concept_desc>Computing methodologies~Visual content-based indexing and retrieval</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10010147.10010257.10010293.10010294</concept_id>
<concept_desc>Computing methodologies~Neural networks</concept_desc>
<concept_significance>300</concept_significance>
</concept>
<concept>
<concept_id>10010147.10010178.10010224.10010245.10010253</concept_id>
<concept_desc>Computing methodologies~Tracking</concept_desc>
<concept_significance>500</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Information systems~Video search}
\ccsdesc[500]{Computing methodologies~Visual content-based indexing and retrieval}
\ccsdesc[300]{Computing methodologies~Neural networks}
\ccsdesc[300]{Computing methodologies~Tracking}

% We no longer use \terms command
%\terms{Theory}

\keywords{retrieval of video segments, neural language generation model, Densecap, tracking by captioning}


\maketitle

\input{wheretoplay_body}

%\bibliographystyle{ACM-Reference-Format}
%\bibliography{sigproc} 
\input{wheretoplay.bbl}

\end{document}

This section introduces a method to jointly tune privacy parameters (e.g., noise scale) along with parameters related only to the utility of an algorithm (e.g., learning rate or batch size in stochastic gradient descent) -- while avoiding the $\perp$ output.

Algorithm~\ref{alg: parameter_ptr} takes a list of parameters as input, runs generalized PTR with each of the parameters, and returns the output with the best utility. We show that the privacy guarantee with respect to $\epsilon$ is independent of the number of $\phi$ that we try.  

Formally, let $\phi_1, ..., \phi_k$ be a set of hyper-parameters and $\tilde{\theta}_i \in\{\perp, \text{Range}(\cM)\}$ denotes the output of running generalized PTR on a private dataset $X$ with $\phi_i$. 
Let $X_{val}$ be a public validation set and $q(\tilde{\theta}_i)$ be the score of evaluating $\tilde{\theta}_i$ with $X_{val}$ (e.g., validation accuracy). The goal is to select a pair $(\tilde{\theta}_i$, $\phi_i)$ such that DP model $\tilde{\theta}_i$ maximizes the validation score.

The generalized PTR framework with privacy calibration is described in Algorithm~\ref{alg: parameter_ptr}. The privacy guarantee of Algorithm~\ref{alg: parameter_ptr} is an application of \citet{liu2019private}.


\begin{algorithm}[H]
	\caption{PTR with hyper-parameter selection}
	\label{alg: parameter_ptr}
	\begin{algorithmic}[1]
	   \STATE {\textbf{Input}:  Privacy budget per PTR algorithm ($\epsilon^*, \delta^*$), cut-off $T$, parameters $\phi_{1:k}$, flipping probability $\tau$ and validation score function $q(\cdot)$. } 
		\STATE {Initialize the set $S=\varnothing$.}
		\STATE{Draw $G$ from a geometric distribution $\cD_\tau$ and let $\hat{T}=\text{min}(T, G)$.}
		\FOR{i = 1 ,..., $\hat{T}$}
		\STATE{ pick a random $\phi_i$ from $\phi_{1:k}$.}
		\STATE{evaluate $\phi_i$: $(\tilde{\theta}_i, q(\tilde{\theta}_i))\gets$ Algorithm~\ref{alg:gen_ptr}($\phi_i, (\epsilon^*, \delta^*)$).}
		\STATE {$S \gets S \cup \{\tilde{\theta}_i, q(\tilde{\theta}_i)\}$.}
		%\STATE{with probability $\gamma$, we output the highest scored candidate from $S$ and halt.}
		\ENDFOR %\vspace{-1mm}
	\STATE{Output the highest scored candidate from $S$.}
	\end{algorithmic}
	%\vspace{-1mm}
\end{algorithm}

\begin{theorem}[ Theorem 3.4 \citet{liu2019private} ]
Fix any $\tau \in [0, 1], \delta_2>0$ and let $T =\frac{1}{\tau} \log \frac{1}{\delta_2}$. If each oracle access to Algorithm~\ref{alg:gen_ptr} is $(\epsilon^*, \delta^*)$-DP, then
Algorithm~\ref{alg: parameter_ptr} is $(3\epsilon^* + 3\sqrt{2\delta^*}, \sqrt{2\delta^*} T +\delta_2 )$-DP.%\yw{What if it does not reach $T$? Also in the algorithm it has $k$ right?  Also, did you define which score it is?}
\end{theorem}
The theorem implies that one can try a random number of $\phi$ while paying a constant $\epsilon$.
In practice, we can roughly set $\tau = \frac{1}{10k}$ so that the algorithm is likely to test all $k$ parameters. We emphasize that the privacy and the utility guarantee (stated in the appendix) is not our contribution. But the idea of applying generalized PTR to enforce a uniform DP guarantee over all choices of parameters with a data-dependent analysis is new, and in our opinion, significantly broadens the applicability to generic hyper-parameter tuning machinery from \citet{liu2019private}.
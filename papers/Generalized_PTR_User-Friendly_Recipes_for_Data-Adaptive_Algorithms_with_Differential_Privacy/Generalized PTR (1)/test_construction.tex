
Classic PTR uses the Laplace mechanism to construct a differentially private upper bound of $\cD_{\beta}(X)$, the distance from input dataset $X$ to the closest dataset whose local sensitivity exceeds the proposed bound $\beta$. The tail bound of the Laplace distribution then ensures that if $\cD_{\beta}(X) = 0$ (i.e. if $\Delta_{LS}(X) > \beta$), then the output will be released with only a small probability $\delta$.

The following theorem shows that we could instead use a differentially private upper bound of the data-dependent DP $\epsilon_{\phi}(X)$ in order to test whether to run the mechanism $\cM_{\phi}$.

\begin{theorem}[Generalized PTR with private upper bound]\label{exp: upperbound}
Suppose we have a differentially private upper bound of $\epsilon_\phi(X)$ w.r.t. $\delta$ such that with probability at least $1-\delta'$, $\epsilon_{\phi }^P(X)>\epsilon_{\phi}(X)$. Further suppose we have an $(\hat{\epsilon}, \hat{\delta})$-DP test $\cT$ such that
\begin{align*}
    T(X) &= \begin{cases}
    1 & \text{ if } \epsilon_{\phi }^P(X) < \epsilon, \\
    0 & \text{ otherwise}.
    \end{cases}
    %\vspace{-1em}
\end{align*}
%\yw{Why do you need it to hold for all $\tilde{\delta}$? I thought we only need $\hat{\delta}$}

Then Algorithm~\ref{alg:gen_ptr} is $(\epsilon +\hat{\epsilon}, \delta +\hat{\delta} + \delta')$-DP. %\vspace{-0.5em}
\end{theorem}

%\vspace{-0.5em}

In Section~\ref{subsections:pate}, we demonstrate that one can upper bound the data-dependent DP through a modification of the smooth sensitivity framework applied on $\epsilon_\phi(X)$. Moreover, in Section~\ref{subsections:private_linear_regression} we provide a direct application of Theorem~\ref{exp: upperbound} with private linear regression by making use of the per-instance DP technique~\citep{wang2017per}.

The applications in Section~\ref{sections:applications} are illustrative of two distinct approaches to constructing the DP test for generalized PTR:

\begin{enumerate}
%\vspace{-0.5em}
    \item Private sufficient statistics release (used in the private linear regression example of Section~\ref{subsections:private_linear_regression}) specifies the data-dependent DP as a function of the dataset and privately releases each data-dependent component. %\vspace{-0.5em}
    \item The second approach (used in the PATE example of Section~\ref{subsections:pate}) uses the smooth sensitivity framework to privately release the data-dependent DP as a whole, and then construct a high-confidence test using the Gaussian mechanism. %\vspace{-0.5em}
    
\end{enumerate}
%\vspace{-0.5em}
These two approaches cover most of the scenarios arising in data-adaptive analysis. For example, in the appendix we demonstrate the merits of generalized PTR in handling data-adaptive private generalized linear models (GLMs)  using private sufficient statistics release. Moreover, sufficient statistics release together with our private hyper-parameter tuning (Algorithm~\ref{alg: parameter_ptr}) can be used to construct data-adaptive extensions of DP-PCA and Sparse-DP-ERM (see details in the future work section).




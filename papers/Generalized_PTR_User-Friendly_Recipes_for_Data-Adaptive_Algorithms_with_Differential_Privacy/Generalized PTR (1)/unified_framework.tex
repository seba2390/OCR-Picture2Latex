\section{A Unified Framework}

 In Section~\ref{subsection:reduction} we show how to reduce our generalization to classic PTR.

Why do we want to generalize PTR beyond noise-adding mechanisms? Compared to classic PTR, the generalized PTR framework allows us to be more flexible in both the type of test conducted and also the type of mechanism whose output we wish to release. For many mechanisms, the local sensitivity either does not exist or is only defined for specific data-dependent quantities (e.g., the sensitivity of the score function in the exponential mechanism) rather than the mechanism's output. We give a concrete example in Section~\ref{subsection:private_posterior_sampling}.

In other cases, the local sensitivity exists and can be tested efficiently -- \emph{but} isn't sufficiently descriptive to make full use of data-dependent properties. We give an example in Section~\ref{subsection:report_noisy_max} where considering only the local sensitivity leads to a loose privacy guarantee.
% \blue{private binary voting w/ tighter privacy analysis}
% Moreover, even in the cases of noise-adding mechanisms where PTR seems to be applicable, it does not lead to a tight privacy guarantee. Specifically, by an example of privacy amplification by post-processing (Example~\ref{exp: binary_vote} in the appendix), we demonstrate that the local sensitivity does not capture all sufficient statistics for data-dependent privacy analysis and thus is loose.


Lastly, both classic and generalized PTR could refuse to output anything useful when the test fails. In Section~\ref{subsection:testing_data_DP} we demonstrate how to construct a ``sanitized'' upper bound of the data-dependent DP $\epsilon_\phi(X)$ -- which, unlike local sensitivity, always exists. Furthermore, by deriving this upper bound we can obtain an explicit formula of how to choose the parameter $\phi$ in order to avoid the ``$\perp$'' output.


% \subsection{Reduction to classic PTR}
% \label{subsection:reduction}

% \begin{theorem}[Generalized PTR with distance test]\label{exp: dist_ptr}
% Let $\delta, \delta' > 0$ and define an algorithm $\cA: \cR^d \to \{\perp, \cR^d\}$ as follows.
% Let $\gamma(X)$ denote the distance to the nearest dataset $X''$ such that $\epsilon_{\phi, \hat{\delta}}(X'')>\hat{\epsilon}$, i.e.,
% $\gamma(X) = \min_{X''} \{dist(X, X''):\epsilon_{\phi, \hat{\delta}}(X'')>\hat{\epsilon}\}$. Let $\mathcal{T}$ test whether $ \gamma(X)+ Lap(1/\epsilon)>\frac{\log(1/\tilde{\delta})}{\epsilon}$.
%   $\cA$ returns $\cM_\phi(X)$ if $\mathcal{T}$ passes and otherwise returns $\perp$. Then $\cA$ is $(\epsilon+\hat{\epsilon}, \hat{\delta}+ \tilde{\delta})$-DP. 
% \end{theorem}
% % \blue{Look at this again! Are the deltas correct?}

% % \begin{proof}[Proof sketch]
% % \end{proof}

% Theorem~\ref{exp: dist_ptr} shows that generalized PTR is a \emph{strict} generalization of Propose-Test-Release. For noise-adding mechanisms such as the Laplace mechanism, the sensitivity is proportional to the privacy loss (in both the global and local sense, i.e. $\Delta_{GS} \propto \epsilon$ and $\Delta_{LS} \propto \epsilon(X)$). Therefore for these mechanisms the only difference between privately testing the local sensitivity (Algorithm~\ref{alg:classic_ptr}) and privately testing the data-dependent DP (Theorem~\ref{exp: dist_ptr}) is a change of parameterization.

\subsection{Private posterior sampling}
\label{subsection:private_posterior_sampling}


\begin{example}[Private posterior sampling]\label{exp: posterior}
Let $\cM: \cX\times \cY \to \Theta $ be a private posterior sampling   mechanism~\citep{minami2016differential,wang2015privacy,gopi2022private} for approximately minimizing $F_{X}(\theta)$.

$\cM$ samples $\theta \sim P(\theta)\propto e^{-\gamma(F_X(\theta)+ 0.5\lambda ||\theta||^2)}$ with parameters $\gamma, \lambda$. $\gamma,\lambda$ cannot be appropriately chosen for this mechanism to satisfy DP without going through a sensitivity calculation of $\arg\min F_X(\theta)$. In fact, the global and local sensitivity of the minimizer is unbounded even in linear regression problems, i.e., when $F_X(\theta) = \frac{1}{2}||y-X\theta||^2.$ 
%The local sensitivity $\Delta:=||P_{X,y}(\theta)-P_{X', y'}(\theta)||$ is not well-defined  for the sampling algorithm, thus the standard PTR is not applicable.  

\end{example}
Output perturbation algorithms do work for the above problem when we regularize, but they are known to be suboptimal in theory and in practice \cite{chaudhuri2011differentially}.
% do not achieve the level of utility in theory and in practice when comparing to posterior sampling. 
 



\subsection{Report Noisy-max}
\label{subsection:report_noisy_max}


\subsection{Testing data-dependent DP}
\label{subsection:testing_data_DP}

\begin{comment}
\begin{example}(\emph{Laplace Mechanism}) \label{examp:lap_mech}

Given a function $f: \mathcal{X} \rightarrow \mathbb{R}$, we will define
\begin{align*}
    \mathcal{M}_{\phi}(X) = f(X) + \text{Lap}\left(\phi\right).
\end{align*}
% We'll now derive the data-dependent DP function $\epsilon_{\phi}(X)$ associated with $\mathcal{M}_{\phi}$:
A rote calculation with the Laplace distribution tells us that
\begin{align*}
    \log \dfrac{\text{Pr}[\mathcal{M}_{\phi}(X) = y]}{\text{Pr}[\mathcal{M}_{\phi}(X') = y]} &\leq \dfrac{|f(X) - f(X')|}{\phi}.
\end{align*}
Using the above calculation and  Definition~\ref{def:data_dep_dp},
\begin{align*}
    \epsilon_{\phi}(X) = \max\limits_{X': X' \simeq X} \frac{|f(X) - f(X')|}{\phi} = \frac{\Delta_{LS}(X)}{\phi}.
\end{align*}
We can then verify that choosing $\phi = \beta/\hat{\epsilon}$ and $\hat{\epsilon} = \epsilon$ reduces Algorithm~\ref{alg:no_ls} exactly to Algorithm~\ref{alg:classic_ptr}.
\end{example}
\end{comment}

% Next, we provide another instantiation of generalized PTR through the construction of a high-probability upper bound of $\epsilon_{\phi}(X)$.

% \begin{theorem}[Generalized PTR with private upper bound]\label{exp: upperbound}
% Let $\cT$ first construct a differentially private upper bound of $\epsilon_\phi$ such that with probability at least $1-\tilde{\delta}$, $\epsilon_{\phi, \hat{\delta}}^P(X)>\epsilon_{\phi, \hat{\delta}}(X)$. 
% %\yw{Why do you need it to hold for all $\tilde{\delta}$? I thought we only need $\hat{\delta}$}
% Then $\cT$ %tests whether
% returns ``Pass'' if
% $\epsilon_{\phi, \hat{\delta}}^P(X)< \hat{\epsilon}$, otherwise ``not pass''. 
% %Algorithm $\cA$ returns $\cM_\phi(X)$ if $\cT$ passes else returns $\perp$.  % this is made clear in the alg block already?
% If $\cT$ is $(\epsilon,\delta)$-DP, then  $\cA$ is $(\epsilon +\hat{\epsilon}, \delta +\hat{\delta} + \tilde{\delta})$-DP.
% \end{theorem}
% \blue{Theorem~\ref{exp: upperbound} provides a systematic way of deriving data-dependent DP algorithms by deriving and releasing data-dependent DP losses.}


% In Section~\ref{sec: pate}, we demonstrate that one can upper bound the data-dependent DP through a modification of the smooth sensitivity framework applied on $\epsilon_\phi(X)$. Moreover, we provide a direct application of Example~\ref{exp: upperbound} with private linear regression by making use of the per-instance DP technique~\citep{wang2017per}.



\begin{comment}
Moreover, if $\epsilon_\phi(X)$ admits a global sensitivity $\triangle_\phi$, we can use the tail bound of Laplace distribution for such a construction. \todo{Shall we mention privately release sufficient statistics here?}


\begin{corollary}
Assume that $\epsilon_\phi(X)$ has a global $L_1$ sensitivity $\triangle_\phi$. Let $\cT$ privately test if $\epsilon_{\phi, \hat{\delta}}^P(X) \leq \hat{\epsilon}$, where $\epsilon_{\phi,\hat{\delta}}^P(X):= \epsilon_{\phi, \hat{\delta}}(X)+ \text{Lap}(\frac{\triangle_
\phi}{\epsilon}) + \frac{\triangle_\phi \log(1/\delta)}{\epsilon}$. Then an instantiation of Algorithm~\ref{alg:gen_ptr} with the test $\cT$ satisfies $(\epsilon+\hat{\epsilon}, \delta + \hat{\delta})$-DP.
\end{corollary}
\end{comment}

%\addcontentsline{toc}{section}{Appendix} % Add the appendix text to the document TOC
%\part{Appendix} % Start the appendix part
%\setcounter{parttocdepth}{1}
%\parttoc % Insert the appendix TOC

\tableofcontents
%\appendix
\section{Omitted examples in the main body}

In this appendix, we provide more examples to demonstrate the merits of generalized PTR. We focus on a simple example of post-processed Laplace mechanism in Section~\ref{sec:binary_vote} and then an example on differentially private learning of generalized linear models in Section~\ref{sec:gen_ptr}. In both cases, we observe that generalized PTR provides data-adaptive algorithms with formal DP guarantees, that are simple, effective and not previously proposed in the literature (to the best of our knowledge).

\subsection{Limits of the classic PTR in private binary voting}\label{sec:binary_vote}

The following example demonstrates that  classic PTR  does not capture sufficient data-dependent quantities
even when the local sensitivity exists and can be efficiently tested.
\begin{example}\label{exp: binary_vote}
Consider a binary class voting problem: $n$ users vote for a binary class $\{0, 1\}$ and the goal is to output the class that is supported by the majority. Let $n_i$ denote the number of people who vote for the class $i$. We consider the report-noisy-max mechanism: 
\begin{align*}
\cM(X): \text{argmax}_{i \in [0,1]} n_i(X)+ Lap(b),
\end{align*}
where $b=1/\epsilon$ denotes the scale of Laplace noise. 

\end{example}
In the example, we will (1) demonstrate the merit of data-dependent DP; and 
(2) empirically compare classic PTR with generalized PTR.

We first explicitly state the data-dependent DP.
\begin{theorem}\label{thm: binary_vote}
The data-dependent DP of the above example is 
\[\epsilon(X):= \max_{X'}\{ |\log\frac{p}{p'}|, |\log\frac{1-p}{1-p'}|\},\] where $p:=\Pr[n_0(X) + Lap(1/\epsilon)> n_1(X) +Lap(1/\epsilon)]$ and $p':= \Pr[n_0(X') + Lap(1/\epsilon)> n_1(X')+Lap(1/\epsilon)]$. There are four possible neighboring datasets $X': n_0(X')=\max(n_0(X)\pm 1,0), n_1(X')=n_1(X)$ or  $n_0(X')=n_0(X), n_1(X')=\max(n_1(X)\pm 1,0)$.
\end{theorem}
In Figure~\ref{fig:gap}, we empirically compare the above data-dependent DP with the Laplace mechanism by varying the gap between the two vote counts $|n_0(X)-n_1(X)|$.  The noise scale is fixed to $\epsilon=10$.
The data-dependent DP substantially improves over the standard DP if the gap is large. However, the data-dependent DP is a function of the dataset. We next demonstrate how to apply generalized PTR to exploit the data-dependent DP.


Notice that the probability $n_0(X) + Lap(1/\epsilon)> n_1(X) +Lap(1/\epsilon)$  is equal to the probability that a random variable $Z:= X-Y$ exceeds $\epsilon(n_1(X)- n_0(X))$, where $X, Y$ are two independent $\text{Lap}(1)$ distributions. We can compute the pdf of $Z$ through the convolution of two Laplace distributions, which implies $f_{X-Y}(z) = \dfrac{1+|z|}{4e^{|z|}}$.  Let $t$ denote the difference between $n_1(X)$ and $n_0(X)$, i.e., $t=n_1(X)-n_0(X)$. Then we have
\[  p = \pr[Z>\epsilon \cdot t] = \frac{2+\epsilon \cdot t}{4 \exp(\epsilon \cdot t)}\]
Similarly, $p' =\dfrac{2+\epsilon \cdot (t+ \ell)}{4 \exp(\epsilon \cdot (t+\ell))} $, where $\ell\in[-1,1]$ denotes adding or removing one data point to construct the neighboring dataset $X'$.
Therefore, we can upper bound $\log(p/{p'})$ by
\begin{align*}
\log\frac{p}{p'} &= \frac{2 +\epsilon \cdot t}{4\exp(\epsilon \cdot t)}\cdot \frac{4\exp(\epsilon(t+\ell))}{2+\epsilon\cdot ( t+\ell)} \\ &\leq \epsilon \cdot \log\bigg(\frac{2+\epsilon t}{2+\epsilon(t+1)}\bigg) \\ &=\epsilon \log\bigg(1- \frac{\epsilon}{2+\epsilon(t+1)} \bigg)
\end{align*}


Then we can apply  generalized PTR by privately lower-bounding $t$.
%Consider the case when $\log \frac{p}{p'}$ dominates $\epsilon(X)$, then $\epsilon(X) = \epsilon \bigg|\log\bigg(1- \frac{\epsilon}{2+\epsilon(t+1)}\bigg)\bigg|$ is a  function of both the privacy parameter $\epsilon$ and the data-dependent quantity $t$. To apply the generalized 


On the other hand, the local sensitivity $\Delta_{LS}(X)$ of this noise-adding mechanism is $0$ if $t>1$. Specifically,  if the gap is larger than one, adding or removing one user will not change the result. To apply  classic PTR, we let  $\gamma(X)$ denote the distance to the nearest dataset $X^{''}$ such that $\Delta_{LS}>0$ and test if $\gamma(X)+\text{Lap}(1/\epsilon)> \frac{\log(1/\delta)}{\epsilon}$.
 Notice in this example that $\gamma(X)=\max(t-1, 0)$ can be computed efficiently.  
We provide the detailed implementation of these approaches.
\begin{enumerate}
    \item Gen PTR: lower bound $t$ with $t^p = t - \frac{log(1/\delta)}{\tilde{\epsilon}} + \text{Lap}(1/\tilde{\epsilon})$.
    Calculate an upper bound of data-dependent DP $\epsilon^p$ using Theorem~\ref{thm: binary_vote} with $t^p$. The algorithm then tests if $\epsilon^p$ is within an predefined privacy budget $\epsilon'$. If the test passes, the algorithm
    returns $\text{argmax}_{i \in [0,1]} n_i(X)+ Lap(1/\epsilon)$ satisfies $(\tilde{\epsilon}+\epsilon', \delta)$-DP.
    \item classic PTR: lower bound $t$ with $t^p = t - \frac{log(1/\delta)}{\tilde{\epsilon}} + \text{Lap}(1/\tilde{\epsilon})$. If $t^p>1$,  classic PTR outputs the ground-truth result else returns a random class. This algorithm satisfies $(\tilde{\epsilon}, \delta)$-DP.
    \item Laplace mechanism. $\cM(X): \text{argmax}_{i \in [0,1]} n_i(X)+ Lap(1/\epsilon)$. $\cM$ is $(\epsilon, \delta)$-DP.
\end{enumerate}
\begin{figure*}[t]
	\centering		\subfigure[data-dependent DP vs Laplace mechanism ]{
	\includegraphics[width=0.47\textwidth]{img/gap.pdf}\label{fig:gap}}	\subfigure[ Privacy-utility tradeoff between three approaches. ]{
	\includegraphics[width=0.50\textwidth]{img/comp.pdf}\label{fig:comp}}
	\caption{In Figure~\ref{fig:gap}, we compare the privacy guarantee by varying the gap. In Figure~\ref{fig:comp} We fix $t=n_0(X)-n_1(X)=100$ and compare privacy cost when the accuracy is aligned. 
	 Gen-PTR with any choice of privacy budget ($\tilde{\epsilon}+\epsilon'$) chosen from the purple region would achieve the same utility as Laplace mechanism but with a smaller privacy cost. The curve of Gen-PTR is always below than that of the classic PTR, which implies that Gen-PTR can result a tighter privacy analysis when the utility is aligned. } 
\end{figure*}

We argue that though the Gen-PTR and the classic PTR are similar in privately lower-bounding the data-dependent quantity $t$, the latter does not capture sufficient information for data-adaptive analysis. That is to say, only testing the local sensitivity restricts us from learning helpful information to amplify the privacy guarantee if the test fails. In contrast, our generalized PTR, where privacy parameters and the  local sensitivity parameterize the data-dependent DP, can handle those failure cases nicely.

To confirm this conjecture, Figure~\ref{fig:comp} plots a privacy-utility trade-off curve between these three approaches.
We consider a voting example with $n_0(X)=n_1(X)+100$ and $t=100$, chosen such that the data-adaptive analysis is favorable. 

In Figure~\ref{fig:comp}, we vary the noise scale $b=1/\epsilon$ between $[0, 0.5]$. For each choice of $b$, we plot the privacy guarantee of three algorithms 
 when the error rate is aligned. For Gen-PTR, we set $\tilde{\epsilon} = \frac{1}{2b}$ and empirically calculate $\epsilon^p$ over $100000$ trials. 

In the plot, when $\epsilon \ll \frac{\log(1/\delta)}{t}$,  the classic PTR is even worse than the Laplace mechanism. This is because the classic PTR is likely to return $\perp$ while the Laplace mechanism returns $\text{argmax}_{i\in[0,1]} n_i(X) + \text{Lap}(1/\epsilon)$, which contains more useful information. 
Compared to the Laplace mechanism, Gen-PTR requires an extra privacy allocation $\tilde{\epsilon}$ to release the gap $t$. However, it still achieves an overall smaller privacy cost when the error rate $\leq 10^{-5}$ (the purple region).  
Meanwhile,  Gen-PTR dominates the classic PTR (i.e., the dashed black curve is always below the blue curve). Note that the classic PTR and the Gen-PTR utilize the gap information differently: the classic PTR outputs $\perp$ if the gap is not sufficiently large, while the Gen-PTR encodes the gap into the data-dependent DP function and tests the data-dependent DP in the end. This empirical result suggests that testing the local sensitivity can be loosely compared to testing the data-dependent DP. Thus, Gen-PTR could provide a better privacy-utility trade-off.
%\yw{The part in the main paper says that the example demonstrates that the local sensitivity does not capture the full information. You may wish to expand a bit here and explain the argument..}


\subsection{Self-concordant generalized linear model (GLM)}\label{sec:glm}


In this section, we demonstrate the effectiveness and flexibility of generalized PTR in handling a family of GLMs where the link function satisfies a self-concordance assumption.  This section is organized as follows:
\begin{itemize}
    \item Introduce a family of GLMs with the self-concordance property.
    \item Introduce a general output perturbation algorithm for private GLMs.
    \item Analyze the data-dependent DP of GLMs with the self-concordance property.
    \item Provide an example of applying our generalized PTR framework to logistic regression.
\end{itemize}


Consider the empirical risk minimization problem of the generalized linear model
\[
\theta^* = \argmin_\theta \sum_{i=1^n} l_i(\theta)+r(\theta),
\]

where  $l: \R\times \R \rightarrow \R$ belongs to a family of convex GLMs: $l_i (\theta) =  l(y, x_i^T\theta)$. Let $r: \R^d \rightarrow \R$ be a regularization function.

We now define the self-concordance property.
\begin{definition}[Generalized self-concordance {\citep{bach2010self}}]
	A convex and three-times differentiable function $f: \Theta \rightarrow \R$ is $R$-generalized-self-concordant on an open nonempty convex set $\Theta^*\subset \Theta$ with respect to norm $\|\cdot\|$ if for all $u\in \Theta^*$ and all $v\in \R^d$,
	$$
	\nabla^3 f(u)  [v,v,v]  \leq 2 R\|v\|(\nabla^2 f(u)[v,v]).
	$$
\end{definition}

The closer R is to 0, the ``nicer'' --- more self-concordant --- the function is.  A consequence of (generalized) self-concordance is the spectral (multiplicative) stability of Hessian to small perturbations of parameters.

\begin{lemma}[Stability of Hessian{\citep[Theorem~2.1.1]{nesterov1994interior}, \citep[Proposition~1]{bach2010self}}]\label{lem:selfconcordant-hessian}
	Let $H_\theta :=  \nabla^2F_s(\theta)$. If $F_s$ is $R$-self-concordant at $\theta$, then for any $v$ such that $R \|v\|_{H_\theta} < 1$, we have that
	\begin{align*}
	(1-R\|v\|_{H_\theta})^2 \nabla^2 F_s(\theta) 	&\prec	\nabla^2 F_s(\theta+v) \\ &\prec  \frac{1}{(1-R\|v\|_{H_\theta})^2}   \nabla^2 F_s(\theta)  .
	\end{align*}
	If instead we assume $F_s$ is $R$-generalized-self-concordant at $\theta$ with respect to norm $\|\cdot\|$, then
\begin{align*}
	e^{-R\|v\|} \nabla^2 F_s(\theta) \prec  \nabla^2 F_s(\theta+v)  \prec e^{R\|v\|}  \nabla^2 F_s(\theta) 
	\end{align*}
\end{lemma}\label{stability}
The two bounds are almost identical when  $R\|v\|$ and $R\|v\|_{\theta}$ are close to $0$. In particular, for $x\leq 1/2$, we have that $e^{-2x} \leq 1-x \leq e^{-x}$.


In particular, the loss function of binary logistic regression is $1$-generalized self-concordant.
\begin{example}[Binary logistic regression]
	Assume $\|x\|_2\leq 1$ for all $x\in \cX$ and $y\in\{-1,1\}$. Then  binary logistic regression with datasets in $\cX\times \cY$ has a  log-likelihood of 
	$
	F(\theta) = \sum_{i=1}^n \log(1+e^{-y_i x_i^T\theta}).
	$
	The univariate function $l :=  \log(1+\exp(\cdot))$ satisfies 
	$$|l'''|  =  \left|\frac{\exp{(\cdot)}  (1- \exp{(\cdot)})}{(1+\exp{(\cdot)})^3}\right| \leq  \frac{\exp{(\cdot)}}{(1+\exp{(\cdot)})^2} := l''.$$
\end{example}


We next apply the modified output perturbation algorithm to privately release $\theta^*$.
	The algorithm is simply:
	\begin{enumerate}
		\item Solve
			$$
		\theta^* = \argmin_{\theta}  \sum_{i=1}^n l_i(\theta) + r(\theta).
        $$
		\item Release$$
		\hat{\theta} =  \theta^*  +   Z,$$
		where $\gamma>0$ is a tuning parameter and $Z\sim \cN(0, \gamma^{-1} (\sum_{i=1}^n \nabla^2 l_i(\theta)+ \nabla^2 r(\theta))^{-1}).$

	\end{enumerate}


The data-dependent DP of the above procedure is stated as follows.






\begin{theorem}[Data-dependent DP of GLM]\label{thm: glm}
Denote the smooth part of the loss function $F_s=\sum_{i=1}^n l(y_i, <x_i, \cdot>) + r_s(\cdot)$.
 Assume the following:
	\begin{enumerate}
		\item The GLM loss function $l$ is convex, three-times continuously differentiable and $R$-generalized-self-concordant w.r.t. $\|\cdot\|_2$,
		\item $F_s$ is locally $\alpha$-strongly convex w.r.t. $\|\cdot\|_2$,

		\item and in addition, denote $L := \sup_{\theta\in [\theta^*,\tilde{\theta}^*]}|l'(y,x^T\theta)|$, $\beta := \sup_{\theta\in [\theta^*,\tilde{\theta}^*]}|l''(y,x^T\theta)|$. That is, $\ell(\cdot)$ is $L$-Lipschitz and $\beta$-smooth.
	\end{enumerate}
	We then have the data-dependent DP
	$$\epsilon(Z) \leq   \frac{R(L+\beta)}{\alpha} (1+\log(2/\delta))  +  \frac{\gamma L^2}{\alpha}  + \sqrt{\frac{\gamma L^2}{\alpha}\log(2/\delta)}.$$
\end{theorem}


The proof follows by taking an  upper bound of the per-instance DP loss (Theorem~\ref{thm: glm}) $\epsilon(Z,z)$ over $z=(x,y)\in (\cX, \cY)$. 



Notice that the Hessians can be arbitrarily singular and $\alpha$ could be $0$, which leads to an infinite privacy loss without additional assumptions. Thus, we will impose an additional regularization of form $\frac{\lambda}{2}||\theta||^2$, which ensures that for any dataset $F_S$ is $\lambda$-strongly convex.


 



This is not yet DP because it is still about a fixed  dataset. We also need a pre-specified privacy budget $(\epsilon,\delta)$.
We next demonstrate how to apply the generalized PTR to provide a general solution to the above GLM, using logistic regression as an example.

 
 \begin{remark}[Logistic regression]\label{remark: log}
 	For logistic regression, we know $L\leq 1$, $\beta \leq 1/4$ and if $\|x\|_2 \leq 1$, it is $1$-generalized self-concordant. For any dataset $Z=(X, y)$, the data-dependent DP $\epsilon(X)$ w.r.t. $\delta$ can be simplified to:
 	$$
 	\frac{1.25}{\alpha}(1+\log(2/\delta)) +\frac{\gamma}{\alpha} +   \sqrt{\frac{\gamma}{\alpha}\log(2/\delta)}
 	$$
 \end{remark}
Now, the data-dependent DP is a function of $\alpha$ and $\gamma$, where $\alpha$ denotes the local strong convexity at $\theta_\lambda^*$ and $\gamma$ controls the  noise scale. We next show how to select these two parameters adapted to the dataset. 

\begin{example}
We demonstrate here how we apply  generalized PTR to  output perturbation of the logistic regression problem.  
	\begin{enumerate}
		%\item First calculate $\alpha,\gamma$ using the conservative approach.
		\item Take an exponential grid of parameters $\{\lambda\}$ and propose each $\lambda$.
		\item Solve for $\theta_{\lambda}^*  = \argmin_{\theta} F(\theta) + \lambda \|\theta\|^2/2$
		\item Calculate the smallest eigenvalue $\lambda_{\min}(\nabla^2F(\theta_\lambda^*))$ (e.g., using power method).
		\item Differentially privately release $\lambda_{\min}$ with $\lambda_{\min}^p:= \max\{\lambda_{\min}+ \frac{\sqrt{\log(4/\delta)}}{\epsilon/2}\cdot \Delta_{GS}\cdot Z -\frac{\sqrt{2\log(4/\delta) \cdot \log(1/\delta)}\Delta_{GS}}{\epsilon/2},0\}$, where $\Delta_{GS}$ denote the global sensitivity of $\lambda_{\min}$
		using Theorem~\ref{thm: gs_lambda}.
		\item Let $\epsilon^p(\cdot)$ be instantiated with $\epsilon(X)$ w.r.t. $\delta$ from Remark~\ref{remark: log}, where $\alpha = \lambda_{\min}^p +\lambda$. 
		Then, conditioned on a high probability event, $\epsilon^p(\cdot)$ (a function of $\gamma$) is a valid DP bound that holds for all datasets and all parameters $\gamma$.
		\item  Calculate the maximum $\gamma$ such that $\epsilon_{\delta/2}^p(\gamma)\leq \epsilon/2$.
		%\item Calculate the maximum $\gamma$ that remains feasible to the privacy budget.
		\item Release  $\hat{\theta}  \sim \cN(\theta_\lambda^*, \gamma^{-1}\nabla^2 F_s(\theta_\lambda^*)^{-1})$.
		\item Evaluate the utility on the validation set and return the $(\lambda, \gamma)$ pair that leads to the highest utility.
	\end{enumerate}
\begin{theorem}
For each proposed $\lambda$, the algorithm that releases  $\hat{\theta}  \sim \cN(\theta_\lambda^*, \gamma^{-1}\nabla^2 F_s(\theta_\lambda^*)^{-1})$ is $(\epsilon, 2\delta)$-DP.
\end{theorem}
\begin{proof}
The proof  follows the recipe of generalized PTR with private upper bound (Example~\ref{exp: upperbound}). First, the release of $\lambda_{\min}(\nabla^2 F(\theta_\lambda^*))$ is $(\epsilon/2, \delta/2)$-DP. Then, with probability at least $1-\delta$, $\epsilon_\delta^p(\cdot)> \epsilon_\delta(X)$ holds for all $X$ and $\gamma$.  Finally, $\gamma$ is chosen such that the valid upper bound is $(\epsilon/2, \delta/2)$-DP.
\end{proof}

For the hyper-parameter tuning on $\lambda$ (Steps 1 and 8), we can use Algorithm~\ref{alg: parameter_ptr} to evaluate each $\lambda$.

Unlike Example~\ref{examp:ops}, the $\lambda_\text{min}(\nabla^2 F(\theta_\lambda^*))$ is a complicated data-dependent function of $\lambda$. Thus, we cannot privately release the data-dependent quantity $\lambda_\text{min}(\nabla^2 F(\theta_\lambda^*))$ without an input $\lambda$. The PTR approach allows us to test a number of different $\lambda$ and hence get a more favorable privacy-utility trade-off.
\end{example}
An interesting perspective of this algorithm for logistic regression is that increasing the regularization $\alpha$ is effectively increasing the number of data points within the soft ``margin''\footnote{If we think of logistic regression as a smoothed version of SVM, then increasing $\alpha$ leads to more support vectors. The ``margin'' is ``softer'' in logistic regression, but qualitatively the same.} of separation, hence a larger contribution to the Hessian from the loss function.

\begin{remark}
    The PTR solution for GLMs follows a similar recipe: propose a regularization strength $\lambda$; construct a lower bound of the strong convexity $\alpha$ at the optimal solution $\theta_\lambda^*$; and test the validity of data-dependent DP using Theorem~\ref{thm: glm}.
\end{remark}

Before moving on to other applications of generalized PTR, we will show how to differentially privately release $\lambda_{min}$ according to the requirements of the logistic regression example.

\subsection{Differentially privately release $\lambda_{min}\left(\nabla^2F(\theta)\right)$}

To privately release $\lambda_{min}{\nabla^2F(\theta)}$, we first need to compute its global sensitivity. Once we have that then we can release it differentially privately using either the Laplace mechanism or the Gaussian mechanism.

\begin{theorem}[Global sensitivity of the minimum eigenvalue at the optimal solution]\label{thm: gs_lambda}
	Let $F(\theta) = \sum_{i=1}^n f_i(\theta) +  r(\theta)$ and $\tilde{F}(\theta) = F(\theta) + f(\theta)$ where  $f_1,...,f_n$ are  loss functions corresponding to a particular datapoint $x$.  
	Let $\theta^* = \argmin_\theta F(\theta)$ and $\tilde{\theta}^* = \argmin_\theta \tilde{F}(\theta)$. Assume $f$ is $L$-Lipschitz and $\beta$-smooth, $r(\theta)$ is $\lambda$-strongly convex, and $F$ and $\tilde{F}$ are $R$-self-concordant. If in addition, $\lambda \geq  RL$, then we have
	$$
	\sup_{X,x} (\lambda_{min}(\nabla^2F(\theta_\lambda^*)) -\lambda_{min}(\nabla^2\tilde{F}(\tilde{\theta_\lambda^*})))   \leq   2RL + \beta.
	$$
\end{theorem}
\begin{proof}

\begin{equation}\label{eq:GS_lamb_min_deriv1}
    \begin{split}
 \lambda_{min}&(\nabla^2F(\theta_\lambda^*)) -\lambda_{min}(\nabla^2\tilde{F}(\tilde{\theta_\lambda^*})) \\
 &= (\lambda_{min}(\nabla^2F(\theta_\lambda^*)) -\lambda_{min}(\nabla^2\tilde{F}(\theta_\lambda^*)))  \\&+ (\lambda_{min}(\nabla^2\tilde{F}(\theta_\lambda^*)) -\lambda_{min}(\nabla^2\tilde{F}(\tilde{\theta_\lambda^*}))). 
    \end{split}
\end{equation}

We first bound the part on the left.
By applying Weyl's lemma $\lambda(X+E)-\lambda(X) \leq ||E||_2$,
we have 
\begin{equation}\label{eq:GS_lamb_min_deriv2}
 \sup_{x}||\nabla^2F(\theta_\lambda^*) - \nabla^2\tilde{F(\theta_\lambda^*})||_2 = ||\nabla^2 f(\theta_\lambda^*)||_2 \leq \beta
\end{equation}
In order to bound the part on the right, we apply the semidefinite ordering  using self-concordance, which gives 
$$
e^{-R\|\tilde{\theta_\lambda^*} - \theta_\lambda^*\|} \nabla^2\tilde{F}(\tilde{\theta_\lambda^*})\prec \nabla^2\tilde{F}(\theta_\lambda^*) \prec e^{R\|\tilde{\theta_\lambda^*} - \theta_\lambda^*\|} \nabla^2\tilde{F}(\tilde{\theta_\lambda^*}).
$$
By the Courant-Fischer Theorem and the monotonicity theorem, we also have that for the smallest eigenvalue
\begin{equation}
\label{eq:GS_lamb_min_deriv3}
\begin{split}
e^{-R\|\tilde{\theta_\lambda^*} - \theta_\lambda^*\|} &  \lambda_{\min}\left(\nabla^2\tilde{F}(\tilde{\theta_\lambda^*})\right)  \leq    \lambda_{\min}\left(\nabla^2\tilde{F}(\theta_\lambda^*) \right) \\&\leq e^{R\|\tilde{\theta_\lambda^*} - \theta_\lambda^*\|}   \lambda_{\min}\left(\nabla^2\tilde{F}(\tilde{\theta_\lambda^*})\right).
\end{split}
\end{equation}

Moreover by Proposition~\ref{prop:generalnorm}, we have that 
$$
\|\tilde{\theta_\lambda^*} - \theta_\lambda^*\|_2 \leq  \frac{\|\nabla f(\tilde{\theta^*}_\lambda)\| }{\lambda_{\min}\left(\nabla^2\tilde{F}(\tilde{\theta_\lambda^*})\right)}  \leq \frac{L}{\lambda_{\min}\left(\nabla^2\tilde{F}(\tilde{\theta_\lambda^*})\right)}.
$$

If $ \lambda_{\min}\left(\nabla^2\tilde{F}(\tilde{\theta_\lambda^*})\right) \geq RL$,  then use that $e^x-1 \leq 2x$ for $x\leq 1$. Substituting the above bound to \eqref{eq:GS_lamb_min_deriv3} then to \eqref{eq:GS_lamb_min_deriv1} together with \eqref{eq:GS_lamb_min_deriv2}, we get a data-independent global sensitivity bound of
$$\lambda_{min}(\nabla^2F(\theta_\lambda^*)) -\lambda_{min}(\nabla^2\tilde{F}(\tilde{\theta_\lambda^*}))  \leq 2RL + \beta$$
as stated.
\end{proof}

\begin{proposition}\label{prop:generalnorm}
	Let $\|\cdot\|$ be a norm and $\|\cdot\|_*$ be its dual norm. Let $F(\theta)$, $f(\theta)$ and $\tilde{F}(\theta) = F(\theta) + f(\theta)$ be proper convex functions and $\theta^*$ and $\tilde{theta}^*$ be their minimizers, i.e., $0\in \partial F(\theta^*)$ and $0\in \partial \tilde{F}(\tilde{theta}^*)$.  If in addition, $F,\tilde{F}$ is $\alpha,\tilde{\alpha}$-strongly convex with respect to $\|\cdot\|$ within the restricted domain 
	$\theta \in \{  t\theta^* + (1-t)\tilde{\theta}^*  \;|\;  t\in[0,1]  \}$. 	Then there exists $g \in \partial f(\theta^*)$ and $\tilde{g}\in \partial f(\tilde{\theta}^*)$ such that
	$$
	\|\theta^*-\tilde{\theta}^*\| \leq\min\left\{\frac{1}{\alpha}\| \tilde{g}\|_*,  \frac{1}{\tilde{\alpha}}\| g\|_*\right\}.
	$$
	 %continuously differentiable with Lipschitz gradient. Let $\theta^*$ and $\ttheta^*$ be such that $0\in \partial F(\theta^*)$ and $0\in \partial \tilde{F}(\ttheta^*)$. If in addition $F(\theta)$ is $\alpha$-strongly convex with respect to $\|\cdot\|$ for all 
	%$\theta \in \{  t\theta^* + (1-t)\ttheta^*  \;|\;  t\in[0,1]  \}$. 
\end{proposition}
\begin{proof}
	Apply the first order condition to $F$ restricted to the line segment between $\tilde{\theta}^*$ and $\theta^*$, we get
	\begin{align}
	F(\tilde{\theta}^*) \geq F(\theta^*)  +  \langle \partial F(\theta^*),  \tilde{\theta}^*-\theta^* \rangle  + \frac{\alpha}{2}\|\tilde{\theta}^*-\theta^*\|^2\label{eq:strongcvx1} \\
	F(\theta^*) \geq F(\tilde{\theta}^*)  +  \langle \partial F(\tilde{\theta}^*),  \theta^*-\tilde{\theta}^* \rangle  + \frac{\alpha}{2}\|\tilde{\theta}^*-\theta^*\|^2 \label{eq:strongcvx2}
	\end{align}
	Note by the convexity of $F$ and $f$, $\partial\tilde{F}=  \partial F + \partial f$, where $+$ is the Minkowski Sum. Therefore, $0\in \partial\tilde{F}(\tilde{\theta}^*)$ implies that there exists $\tilde{g}$ such that $\tilde{g}\in \partial f(\tilde{\theta}^*)$ and $-\tilde{g}\in\partial F(\tilde{\theta}^*)$.
	Take $-\tilde{g}\in\partial F(\tilde{\theta}^*)$ in Equation~\ref{eq:strongcvx2} and $0 \in \partial F(\theta^*)$ in Equation~\ref{eq:strongcvx1}  and add the two inequalities, we obtain
	\begin{align*}
		0&\geq \langle -\tilde{g},  \theta^*-\tilde{\theta}^* \rangle  + \alpha \|\tilde{\theta}^* - \theta^*\|^2 \\ &\geq - \|\tilde{g}\|_* \|\theta^*-\tilde{\theta}^*\|  +  \alpha\|\tilde{\theta}^* - \theta^*\|^2. 
	\end{align*}
	For $\|\tilde{\theta}^* - \theta^*\|=0$ the claim is trivially true; otherwise, we can divide  both sides of the above inequality by $\|\tilde{\theta}^* - \theta^*\|$ and get
	$	\|\theta^*-\tilde{\theta}^*\| \leq \frac{1}{\alpha}\| \tilde{g}\|_*$. 
	
	It remains to show that $\|\theta^*-\tilde{\theta}^*\| \leq \frac{1}{\tilde{\alpha}}\|g\|_*$. This can be obtained by exactly the same arguments above but applying strong convexity to $\tilde{F}$ instead. Note that we can actually get something slightly stronger than the statement because the inequality holds for all $g\in \partial f(\theta^*)$.
\end{proof}

%We next empirically evaluate the above algorithm on Adult dataset. Adult is a binary classification task with a non-private classification error about 0.15.
%We follow the preprocessing steps from~\citet{chaudhuri2011differentially} by converting each attribute into a binary feature, applying standard-z-zscoring and normalizing each data point with a Euclidean norm of 1. 


\subsection{Other applications of generalized PTR}

Besides one-posterior sampling for GLMs, there are plenty of examples that our generalized-PTR could be applied, e.g., DP-PCA~\citep{dwork2014analyze} and Sparse-DP-ERM~\citep{kifer2012private} (when the designed matrix is well-behaved).

\citep{dwork2014analyze} provides a PTR style privacy-preserving principle component analysis (PCA).
The key observation of \citep{dwork2014analyze} is that the local sensitivity is quite ``small'' if there is a large eigengap between the $k$-th and the $k+1$-th eigenvalues. Therefore, their approach (Algorithm 2) chooses to privately release a lower bound of the k-th eigengap ($k$ is fixed as an input) and use that to construct a high-confidence upper bound of the local sensitivity.

For noise-adding mechanisms, the local sensitivity is proportional to the data-dependent loss and generalized PTR is applicable. We can formulate the data-dependent DP of DP-PCA as follows:

\begin{theorem}~\label{thm: pca}
For a given matrix $A\in \cR^{m \times n}$, assume each row of $A$ has a bounded $\ell_2$ norm being $1$.  Let $V_k$ denotes the top $k$ eigenvectors of $A^TA$ and $d_k$ denotes the gap between the $k$-th and the $k+1$-th eigenvalue. Then releasing $V_k V_k^T + E$, where $E \in \cR^{n\times n}$ is a symmetric matrix with the upper triangle is i.i.d samples from $\cN(0, \sigma^2)$ satisfies $(\epsilon(A), \delta)$ data-dependent DP and $\epsilon(A) = \frac{2\sqrt{\log(1.25/\delta)}}{\sigma(d_k -2)} $. 
\end{theorem}
The proof is based on the local sensitivity result from \citep{dwork2014analyze} and the noise calibration of Gaussian mechanism.


We can combine Theorem~\ref{thm: pca} with our Algorithm~\ref{alg: parameter_ptr} to instantiate the generalized PTR framework. The improvement over \citet{dwork2014analyze} will be to allow joint tuning of the parameter $k$ and the noise variance (added to the spectral gap $d_k$). 







\section{Omitted proofs in Section~\ref{sec:gen_ptr}}\label{sec: omit_gen_ptr}

The utility of Algorithm~\ref{alg: parameter_ptr}
depends on how many rounds that Algorithm~\ref{alg:gen_ptr} is invoked. We next provide the utility guarantee of Algorithm~\ref{alg: parameter_ptr}, which follows a simplification of the result in the Section A.2 of~\citet{papernot2021hyperparameter}.
\begin{theorem}
 Suppose applying Algorithm~\ref{alg:gen_ptr} with each $\phi_i$ has an equal probability to achieve the highest validation score. Let $\hat{T}$ denotes the number of invocation of Algorithm~\ref{alg:gen_ptr}, where $\hat{T}$ follows a truncated geometric distribution. Then the expected quantile of the highest score candidate is given by $\mathbb{E}_{\hat{T}}\bigg[1 -\frac{1}{\hat{T}+1}\bigg]$.
\end{theorem}

In practice, we can roughly set $\tau = \frac{1}{10k}$ so that the algorithm is likely to test all $k$ parameters. 

%algorithm can return the best $\phi_i\in \phi_{[1:k]}$ in expectation.


\begin{proof}
 Suppose each oracle access to $Q(X)$ has a probability $1/k$ of achiving the best validation accuracy. Let $\beta$ denote the probability that $\cA$ (shorthand for Algorithm~\ref{alg: parameter_ptr}) outputs the best choice of $\phi_i$. 
 \begin{align*}
 \beta &= 1-\pr[\cA(X) \text{is not best}] \\ &=1- \mathbb{E}_{\hat{T}}\bigg[\pr[Q(X) \text{is not best}]^{\hat{T}}\bigg] \\ &= 1 -\mathbb{E}_{\hat{T}}\bigg[ (1-\frac{1}{k})^{\hat{T}}\bigg].
 \end{align*}
 Let $f(x)=\mathbb{E}[x^{\hat{T}}]$. Applying a first-order approximation on $f(1-\frac{1}{k})$, we have $f(1-\frac{1}{k})\approx f(1) -f'(1) \cdot \frac{1}{k}=1-\mathbb{E}[\hat{T}]/k$. Then, if $k$ is large and we choose $\tau=0.1/k$, $\cA$ can roughly return the best $\phi_i$.
\end{proof}

\section{Experimental details}

\subsection{Experimental details in private linear regression}

We start with the privacy calibration of the OPS-PTR algorithm.
% slightly different with Example 4.6

\begin{algorithm}[t]
	\caption{OPS-PTR: One-Posterior Sample with propose-test-release (no-``perp'' version)}
	\label{alg: ops_ptr}
	\begin{algorithmic}[1]
		\STATE {\textbf{Input}: Data $X, \bf{y}$. Private budget : $\epsilon, \delta$, proposed regularizer $\lambda$. }
		\STATE{Calculate the minimum eigenvalue $\lambda_{\text{min}}(X^TX)$.}
		\STATE{Sample $Z \sim \cN(0, 1)$ and privately release $\tilde{\lambda}_{\text{min}}=\text{max}\bigg\{
		\lambda_{\text{min}}+ \frac{\sqrt{\log(6/\delta)}}{\epsilon/4}Z -\frac{\sqrt{2\log(6/\delta)\cdot \log(2/\delta)}}{\epsilon/4},0\bigg\}$}
		\STATE{Calculate $\hat{\theta}=(X^TX+\lambda I)^{-1}X^Ty$.}
		\STATE{Sample $Z\sim \cN(0, 1)$ and privately release $\Delta = \log(||\cY||+||\cX||||\hat{\theta}||)+ \frac{\log(1+||\cX||^2/(\lambda +\tilde{\lambda}_{\text{min}}))}{\epsilon/(4\sqrt{6/\delta})}Z + \frac{\log(1+||\cX||^2/(\lambda +\tilde{\lambda}_{\text{min}}))}{\epsilon/(4\sqrt{2\log(6/\delta)\log(2/\delta)})}$.}
		\STATE{Set the local Lipschitz $\tilde{L}:=||X||e^\Delta.$}
		\STATE{ Calibrate $\gamma$ with Theorem~\ref{thm: per}($\delta/3, \epsilon/2$.) }
		\STATE{Output $\tilde{\theta}\sim p(\theta|X,\bf{y}) \propto e^{-\frac{\gamma}{2}||\bf{y}-X\theta||^2 + \lambda||\theta||^2}$}
	\end{algorithmic}
\end{algorithm}


Algorithm~\ref{alg: ops_ptr} provides the detailed privacy calibration of the private linear regression problem. 



\begin{theorem}
Algorithm~\ref{alg: ops_ptr} is $(\epsilon, 2\delta)$-DP.
\end{theorem}
\begin{proof}
There are three data-dependent quantities in Theorem~\ref{thm: per}: $\lambda_{
\text{min}}, ||\theta_\lambda^*||$ and $L$.
First, notice  that $\lambda_{\text{min}}$ has a global sensitivity of $||\cX||^2$ by Weyl's lemma. Under the assumption $||\cX||^2\leq 1$, we privately release $\lambda_{\text{min}}$ using $(\epsilon/4,\delta/3)$ in Step~3.
Notice that with probability at least $1-\delta/2$, $\tilde{\lambda}_{\min}$ is a lower bound of $\lambda_{\min}$. 

Then, we apply Lemma~\ref{lem: adaops_ls} from ~\citet{wang2018revisiting} to privately release $\log(||\cY||+||\cX||||\hat{\theta}||)$ using $(\epsilon/4, \delta/3)$. Note that both the local Lipschitz constant $L$ and the norm  $||\theta_\lambda^*||$ are functions of $\log(||\cY||+||\cX||||\hat{\theta}||)$. Thus, we can construct a private upper bound of these by post-processing of $\Delta$.

Then, with probability at least $1-\delta$ (by a union bound over $\tilde{\lambda}_{\min}$ and $\Delta$), instantiating Theorem~\ref{thm: per} with $\tilde{\lambda}_{\min}$ and $\tilde{L}$ provides a valid upper bound of the data-dependent DP.
We then tune the parameter $\gamma$ using the remaining privacy budget $(\epsilon/2, \delta/3)$.
\end{proof}

\begin{lemma}[Lemma 12~\citep{wang2018revisiting}]\label{lem: adaops_ls}
Let $\theta_\lambda^*$ be the ridge regression estimate with parameter $\lambda$ and the smallest eigenvalue of $X^TX$ be $\lambda_{\text{min}}$, then the function $\log(||\cY +||\cX||||\theta_\lambda^*||)$ has a local sensitivity of $\log(1+\frac{||\cX||^2}{\lambda_{\text{min}+\lambda}})$.
\end{lemma}
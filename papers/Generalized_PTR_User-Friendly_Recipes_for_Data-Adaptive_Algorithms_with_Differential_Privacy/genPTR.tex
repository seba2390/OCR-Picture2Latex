%\vspace{-1em}
\section{Generalized PTR}
%\vspace{-1em}
\label{sec:gen_ptr}
This section introduces the generalized PTR framework. We first formalize the notion of \emph{data-dependent} differential privacy that conditions on an input dataset $X$. 

\begin{definition}[Data-dependent privacy]
\label{def:data_dep_dp}
Suppose we have $\delta > 0$ and a function $\epsilon: \mathcal{X} \rightarrow \mathbb{R}$. We say that mechanism $\mathcal{M}$ satisfies ($\epsilon(X), \delta$) data-dependent DP\footnote{We will sometimes write that $\cM(X)$ satisfies $\epsilon(X)$ data-dependent DP with respect to $\delta$.} for dataset $X$ if for all possible output sets $S$ and neighboring datasets $X'$,
\begin{align*}
    \text{Pr}\big[\mathcal{M}(X) \in S\big] &\leq e^{\epsilon(X)}\text{Pr}\big[\mathcal{M}(X') \in S\big] + \delta, \\
       \text{Pr}\big[\mathcal{M}(X') \in S\big] &\leq e^{\epsilon(X)}\text{Pr}\big[\mathcal{M}(X) \in S\big] + \delta.
\end{align*}
\end{definition}

In generalized PTR, we propose a value $\phi$ for the randomized algorithm $\cM$, which could be a noise scale or regularization parameter -- or a set including both. For example, $\phi = (\lambda, \gamma)$ in Example~\ref{exp: posterior}. We then say that $\cM_{\phi}$ is the mechanism $\mathcal{M}$ parameterized by $\phi$, and $\epsilon_{\phi}(X)$ its data-dependent DP.

The following example illustrates how to derive the data-dependent DP for a familiar friend -- the Laplace mechanism.

\begin{example}(\emph{Data-dependent DP of Laplace Mechanism.}) \label{examp:lap_mech}
Given a function $f: \mathcal{X} \rightarrow \mathbb{R}$, we will define
\begin{align*}
    \mathcal{M}_{\phi}(X) = f(X) + \text{Lap}\left(\phi\right).
\end{align*}
We then have
\begin{align*}
    \log \dfrac{\emph{Pr}[\mathcal{M}_{\phi}(X) = y]}{\emph{Pr}[\mathcal{M}_{\phi}(X') = y]} &\leq \dfrac{|f(X) - f(X')|}{\phi}.
\end{align*}
Maximizing the above calculation over all possible outputs $y$ and using Definition~\ref{def:data_dep_dp},
\begin{align*}
    \epsilon_{\phi}(X) = \max\limits_{X': X' \simeq X} \frac{|f(X) - f(X')|}{\phi} = \frac{\Delta_{LS}(X)}{\phi}.
\end{align*}
% We can then verify that choosing $\phi = \beta/\hat{\epsilon}$ and $\hat{\epsilon} = \epsilon$ reduces Algorithm~\ref{alg:no_ls} exactly to Algorithm~\ref{alg:classic_ptr}.
\end{example}


The data-dependent DP $\epsilon_\phi(X)$ is a function of both the dataset $X$ and the parameter $\phi$. Maximizing $\epsilon_\phi(X)$ over $X$ recovers the standard DP guarantee of running $\cM$ with parameter $\phi$.


 %We take the functional view of $\epsilon_\phi(X)$ and use $\epsilon_{\phi, \delta}(X)$ to denote the $\epsilon$ as a function of $\delta$.
  % Add what is data-dependent dp, it's a function representation

 
%  Suppose we are given an $(\epsilon, \delta)$-DP test $\mathcal{T}$ that fails with probability $\Tilde{\delta}$ in order to determine whether or not $\mathcal{M}_{\phi}$ satisfies ($\hat{\epsilon}, \hat{\delta}$)-DP. Based on the outcome of $\mathcal{T}$,  we decide whether to run $\mathcal{M}_{\phi}$ or to halt and return $\perp$.
 
\begin{figure}[H]
%\vspace{-1em}
\centering
% \resizebox{0.95\columnwidth}{!}{%
% \begin{minipage}{0.54\textwidth}
\begin{algorithm}[H]
\caption{Generalized Propose-Test-Release}
\label{alg:gen_ptr}
\begin{algorithmic}[1]
\STATE{\textbf{Input}: Dataset $X$; mechanism $\cM_\phi: \mathcal{X} \rightarrow \cR$ and its privacy budget $\epsilon, \delta$; $(\hat{\epsilon}, \hat{\delta})$-DP test $\mathcal{T}$; false positive rate $\leq \delta'$; data-dependent DP function $\epsilon_\phi(\cdot)$ w.r.t. $\delta$}.
% \STATE{\blue{Run a test $\mathcal{T}$ to determine if $\cM_\phi$ is $(\hat{\epsilon}, \hat{\delta})$-DP at $X$.}}
% \STATE{\textbf{if} the test $\mathcal{T}$ passes \textbf{then} release $\theta = \mathcal{M}_{\phi}(X)$.}\vspace{-1pt}
\STATE{\textbf{if not} $\mathcal{T}(\cX)$ \textbf{then} output $\perp$,}\vspace{-1pt}
\STATE{\textbf{else} release $\theta = \mathcal{M}_{\phi}(X).$}%\vspace{-2pt}
\end{algorithmic}
\end{algorithm}
\end{figure}

 
\begin{theorem}[Privacy guarantee of generalized PTR]
\label{thm:gen_ptr}
Consider a proposal $\phi$ and a data-dependent DP function $\epsilon_{\phi}(X)$ w.r.t. $\delta$. Suppose that we have an ($\hat{\epsilon}, \hat{\delta}$)-DP test $\cT: \cX \rightarrow \{0, 1\}$ such that when $\epsilon_{\phi}(X) > \epsilon$, \end{theorem}
\vspace{-8mm}
\begin{align*}
    \cT(X) =
    \begin{cases}
        0  \text{ \:with probability } 1 - \delta', \\
        1  \text{\: with probability }  \delta'. %\vspace{-2mm}
    \end{cases}
\end{align*}
%\vspace{-2mm}
\textit{Then Algorithm~\ref{alg:gen_ptr} satisfies ($\epsilon + \hat{\epsilon}, \delta +  \hat{\delta} + \delta'$)-DP. }
% \vspace{-2mm}
%  \end{theorem}
 \begin{proof}[Proof sketch]
 There are three main cases to consider:
\begin{enumerate}
    %\vspace{-1em}
    \item We decide not to run $\mathcal{M}_{\phi}$.   % \vspace{-0.5em}
    \item We decide to run $\mathcal{M}_{\phi}$ and $\epsilon_{\phi}(X) > \epsilon$;    %\vspace{-0.5em}
    \item We decide to run $\mathcal{M}_{\phi}$ and $\epsilon_{\phi}(X) \leq \epsilon$.    %\vspace{-0.5em}
\end{enumerate}%\vspace{-2mm}
In the first case, the decision to output $\perp$ is post-processing of an $(\hat{\epsilon}, \hat{\delta})$-DP mechanism and inherits its privacy guarantees. The second case occurs when the $(\hat{\epsilon}, \hat{\delta})$-DP test "fails" (produces a false positive) and occurs with probability at most $\delta'$. The third case is a composition of an $(\hat{\epsilon}, \hat{\delta})$-DP algorithm and an ($\epsilon, \delta$)-DP algorithm.
 \end{proof}
 
% The construction of the test required by Theorem~\ref{thm: gen_ptr}
% can be flexibly adapted to any use case. We outline two  approaches to construct such a test in Sec~\ref{section:applications}. 

% \blue{Theorem~\ref{thm: gen_ptr} requires a private test $\mathcal{T}$ to be clear.   The data-dependent privacy loss might depend on the dataset in different ways, and thus the derivation of the test requires a case-specific study. We outline two approaches to construct such a test in Sec~\ref{section:applications}. }
% Before we reach that point, we first show that the classic PTR (Algorithm~\ref{alg:classic_ptr}) can be viewed under our framework as Algorithm~\ref{alg:gen_ptr} instantiated with a specific type of test.
% \begin{theorem}[Generalized PTR with distance test]\label{exp: dist_ptr}
% Let $\delta, \delta' > 0$ and define an algorithm $\cA: \cR^d \to \{\perp, \cR^d\}$ as follows.
% Let $\gamma(X)$ denote the distance to the nearest dataset $X''$ such that $\epsilon_{\phi, \hat{\delta}}(X'')>\hat{\epsilon}$, i.e.,
% $\gamma(X) = \min_{X''} \{dist(X, X''):\epsilon_{\phi, \hat{\delta}}(X'')>\hat{\epsilon}\}$. Let $\mathcal{T}$ test whether $ \gamma(X)+ Lap(1/\epsilon)>\frac{\log(1/\tilde{\delta})}{\epsilon}$.
%   $\cA$ returns $\cM_\phi(X)$ if $\mathcal{T}$ passes and otherwise returns $\perp$. Then $\cA$ is $(\epsilon+\hat{\epsilon}, \hat{\delta}+ \tilde{\delta})$-DP. 
% \end{theorem}
% \blue{Look at this again! Are the deltas correct?}



Generalized PTR is a \emph{strict} generalization of Propose-Test-Release. For some function $f$, define  $\cM_{\phi}$ and $\cT$ as follows:
\begin{align*}
&\mathcal{M}_{\phi}(X) = f(X) + \text{Lap}(\phi); \\
&\cT(X) = 
\begin{cases}
0 & \text{ if\:\: } \cD_{\beta}(X) + \text{Lap}\left(\frac{1}{\epsilon}\right) > \frac{\log(1/\delta)}{\epsilon},\\
1 & \text{ otherwise.} \\
\end{cases}
\end{align*}
Notice that our choice of parameterization is $\phi = \frac{\beta}{\epsilon}$, where $\phi$ is the scale of the Laplace noise. In other words, we know from Example~\ref{examp:lap_mech} that $\epsilon_{\phi}(X) > \epsilon$ exactly when $\Delta_{LS}(X) > \beta$.

For noise-adding mechanisms such as the Laplace mechanism, the sensitivity is proportional to the privacy loss (in both the global and local sense, i.e. $\Delta_{GS} \propto \epsilon$ and $\Delta_{LS} \propto \epsilon(X)$). Therefore for these mechanisms the only difference between privately testing the local sensitivity (Algorithm~\ref{alg:classic_ptr}) and privately testing the data-dependent DP (Theorem~\ref{thm:gen_ptr}) is a change of parameterization.
%\vspace{-0.5em}
\subsection{Limitations of local sensitivity}
%\vspace{-1em}
\input{local_sensitivity_examples}
\label{subsections:local_sensitivity}
%\vspace{-1em}
\subsection{Which $\phi$ to propose}
%\vspace{-0.5em}
% upper bound apporach and hyperparameter tuning
\input{which_phi}
\label{subsections:which_phi}

\input{hyperparameter_selection}
%\vspace{-0.5em}
\subsection{Construction of the DP test}
\input{test_construction}
\label{subsections:test_construction}

%  Next, we provide another instantiation of generalized PTR through the construction of a high-probability upper bound of $\epsilon_{\phi}(X)$.








% \blue{Compared to  classic PTR, the key idea of the procedure above is that we can construct a ``sanitized'' upper bound of $\epsilon_\phi(X)$ instead of local sensitivity, which always exists.  Moreover, the above framework allows us to be more flexible in both the type of test conducted and also the type of mechanism whose output we wish to release.}
% \blue{Put the above into the 'Unified Framework section?'}


%In particular, our result suggests that one can privately publish any mechanism $\cM$ with a data-dependfent analysis through publishing $\epsilon_\phi(X)$, which captures sufficient statistics of the dataset, and is less costly as it is a real-valued number rather than a $d$-dimensional model $\cM$.
% \begin{figure}[t]
% \vspace{-1em}
% \centering
% \resizebox{0.95\columnwidth}{!}{%
% \begin{minipage}{0.54\textwidth}
% \begin{algorithm}[H]
% \caption{Propose-Test-Release \cite{dwork2009differential}}
% \label{alg:classic_ptr}
% \begin{algorithmic}[1]
% \STATE{\textbf{Input}: Dataset $X$; privacy parameters $\epsilon,\delta$; proposed bound $\beta$ on $\Delta_{LS}(X)$; query function $f: \mathcal{X} \rightarrow \mathbb{R}$.}
% \STATE{\textbf{Output}: $f^P(X)$ or $\perp$.}
% \STATE{Compute the distance $\gamma(X)$ to the nearest dataset $X''$ such that $ \Delta_{LS}(X'')> \beta$:
% $\gamma(X) = \min\limits_{X''} \{ \text{dist}(X, X''): \Delta_{LS}(X'')> \beta \}$.}
% \STATE{Privately release $\gamma^P(X) = \gamma(X) + \text{Lap}\left(\frac{1}{\epsilon}\right)$.}
% \STATE{\textbf{if} $\gamma^P(X) \leq \dfrac{\log(1/\delta)}{\epsilon}$ \textbf{then} output $\perp$}\vspace{-1pt}
% \STATE{\textbf{else} release $f^P(X) = f(X) + \text{Lap}\left(\frac{\beta}{\epsilon}\right)$.}\vspace{-2pt}
% \end{algorithmic}
% \end{algorithm}
% \end{minipage}
% \quad
% \begin{minipage}{0.45\textwidth}
% \begin{algorithm}[H]
% \caption{Generalized PTR}
% \label{alg:gen_ptr}
% \begin{algorithmic}[1]
% \STATE{{Input}: Proposed~parameter~$\phi$;~privacy~parameters~$\epsilon,  \hat{\epsilon}, \hat{\delta}$; dataset $X$;\blue{an -$(\epsilon,\delta)$~DP test $\cT$ with false positive rate at most $\tilde{\delta}$; ~data-dependent~DP~function~$\epsilon_{\phi}(\cdot, \hat{\delta})$;~mechanism~$\mathcal{M}_{\phi}$.}}
% \STATE{\textbf{Output}: 
% $\mathcal{M}_{\phi}(X)$ or $\perp$.}
% \STATE{\blue{Run a test $\cT$ to determine if $\cM_{\phi}$ is $(\hat{\epsilon}, \hat{\delta})$-DP at $X$.}}% with privacy limit $(\hat{\epsilon}, \hat{\delta})$ }.
% \IF{the test $\cT$ passes}
% \vspace{1pt}
% \STATE{Run $\theta = \mathcal{M}_{\phi}(X)$ and output $\theta$.}%\vspace{2pt}
% \ELSE 
% \STATE{Output $\perp$.}%\vspace{2pt}

% \ENDIF
% \end{algorithmic}
% \end{algorithm}
% \end{minipage}
% }
% \vspace{-1em}
% \end{figure}







% \begin{comment}
% \begin{example}(\emph{Laplace Mechanism}) \label{examp:lap_mech}

% Given a function $f: \mathcal{X} \rightarrow \mathbb{R}$, we will define
% \begin{align*}
%     \mathcal{M}_{\phi}(X) = f(X) + \text{Lap}\left(\phi\right).
% \end{align*}
% % We'll now derive the data-dependent DP function $\epsilon_{\phi}(X)$ associated with $\mathcal{M}_{\phi}$:
% A rote calculation with the Laplace distribution tells us that
% \begin{align*}
%     \log \dfrac{\text{Pr}[\mathcal{M}_{\phi}(X) = y]}{\text{Pr}[\mathcal{M}_{\phi}(X') = y]} &\leq \dfrac{|f(X) - f(X')|}{\phi}.
% \end{align*}
% Using the above calculation and  Definition~\ref{def:data_dep_dp},
% \begin{align*}
%     \epsilon_{\phi}(X) = \max\limits_{X': X' \simeq X} \frac{|f(X) - f(X')|}{\phi} = \frac{\Delta_{LS}(X)}{\phi}.
% \end{align*}
% We can then verify that choosing $\phi = \beta/\hat{\epsilon}$ and $\hat{\epsilon} = \epsilon$ reduces Algorithm~\ref{alg:no_ls} exactly to Algorithm~\ref{alg:classic_ptr}.
% \end{example}
% \end{comment}



% \begin{remark}[Remove distance test]
% The distance test allows Example~\ref{exp: dist_ptr} to exploit properties of the local neighborhood of datasets close to the input dataset $X$. If $X$ is far away from the closest dataset whose local sensitivity or data-dependent DP exceeds the proposed bound, then $\gamma^P(X)$ will likely be quite large. The analogous condition in Example~\ref{exp: upperbound} to large distance $\gamma(X)$ is \emph{stable} data-dependent DP $\epsilon_{\phi, \hat{\delta}}(X)$. %Our caveat here is that
% % Example~\ref{exp: upperbound} works best for problems whose data-dependent DP has small sensitivity, or is parameterized by statistics  that have small sensitivity. 
% %-- a basic requirement (without which we would have zero utility) is $\Delta_{\phi} \leq \frac{\epsilon\hat{\epsilon}}{\log(1/\delta)}$. 
% \yw{I still don't understsand this remark. Remove?}
% \end{remark}

% Example~\ref{exp: upperbound} is more cautious than  Example~\ref{exp: dist_ptr} in the sense that if the data-dependent DP is at or just below the budget $\hat{\epsilon}$, then the test is more likely to produce a false negative which will cause the algorithm to output $\perp$. Fortunately, this downside is unlikely to manifest in the average case; the experimental results of \cite{redberg2021privately} indicate that instance-based privacy losses are often orders of magnitude smaller than the worst-case DP guarantee.
% \yw{The above paragraph confuses me more than it explains. If the data-dependent DP is at or just below, then the distance test will fail too?}
 



% In Section~\ref{sec: pate}, we demonstrate that one can upper bound the data-dependent DP through a modification of the smooth sensitivity framework applied on $\epsilon_\phi(X)$. Moreover, we provide a direct application of Example~\ref{exp: upperbound} with private linear regression by making use of the per-instance DP technique~\citep{wang2017per}. 



% \begin{comment}
% Moreover, if $\epsilon_\phi(X)$ admits a global sensitivity $\triangle_\phi$, we can use the tail bound of Laplace distribution for such a construction. \todo{Shall we mention privately release sufficient statistics here?}


% \begin{corollary}
% Assume that $\epsilon_\phi(X)$ has a global $L_1$ sensitivity $\triangle_\phi$. Let $\cT$ privately test if $\epsilon_{\phi, \hat{\delta}}^P(X) \leq \hat{\epsilon}$, where $\epsilon_{\phi,\hat{\delta}}^P(X):= \epsilon_{\phi, \hat{\delta}}(X)+ \text{Lap}(\frac{\triangle_
% \phi}{\epsilon}) + \frac{\triangle_\phi \log(1/\delta)}{\epsilon}$. Then an instantiation of Algorithm~\ref{alg:gen_ptr} with the test $\cT$ satisfies $(\epsilon+\hat{\epsilon}, \delta + \hat{\delta})$-DP.
% \end{corollary}
% \end{comment}



%\begin{theorem}
%Assume the data-dependent DP function of mechanism $\cM$
%satisfies $\epsilon_\phi(X)$ and its global $L_1$ sensitivity is bounded by $\triangle_\phi$. Then Algorithm~\ref{alg:no_dist} is $(\epsilon + \hat{\epsilon},\delta+\hat{\delta} )$-DP.
%\end{theorem}

 





% \begin{theorem}[\citep{wang2017per}]\label{thm: per}
% The algorithm used in Example~\ref{exp: posterior} with  parameter $(\lambda, \gamma)$ obeys $(\epsilon, \delta)$ data-dependent DP for each dataset $(X, \textbf{y})$  with 
% \[\epsilon = \sqrt{\frac{\gamma L^2 \log(2/\delta)}{\lambda + \lambda_{\min}}} + \frac{\gamma L^2}{2(\lambda + \lambda_{\min}+||\cX||^2)}+ \frac{1 + \log(2/\delta)||\cX||^2}{2(\lambda+\lambda_{\min})},
% \] where $L:=||\cX||(||\cX||||\theta_\lambda^*||+||\cY||)$ is the local Lipschitz constant, $\lambda_{\min}$ denotes the smallest eigenvalue of $X^TX$ and $||\theta_\lambda^*||$ is the magnitude of the solution $\theta_\lambda^* = (X^TX +\lambda I )^{-1}X^T \bf{y}$.
% \end{theorem}

% Notice that the data-dependent DP is a function of $(\lambda_{\min}, L, ||\theta_\lambda^*||, \lambda, \gamma)$, where $(\lambda_{\min}, L, ||\theta_\lambda^*||)$ are data-dependent quantities. One can apply the generalized PTR framework as in the following example.
% \begin{example} We demonstrate here how to apply generalized PTR to the one-posterior sample (OPS) algorithm, a differentially private mechanism which outputs one sample from the posterior distribution of a Bayesian model with bounded log-likelihood.
% \label{examp:ops}
% \begin{enumerate}\vspace{-1mm}
%     \item Propose $\phi=(\lambda, \gamma)$.\vspace{-1mm}
%     \item Based on $(\lambda, \gamma)$, differentially privately release $\lambda_{min}, ||\theta_\lambda^*||, L$ 
%     with privacy budget $(\epsilon, \delta/2)$.\vspace{-1mm}
%     \item Condition on a high probability event (with probability at least $1-\delta/2$) of $\lambda_{min}, ||\theta_\lambda^*||, L$, test if $\blue{\epsilon_{\phi}^P(X)}$  is smaller than the predefined privacy budget $(\hat{\epsilon}, \hat{\delta})$, where $\epsilon_\phi^P(X)$ denotes the sanitized data-dependent DP.\vspace{-1mm}
%     \item Based on the outcome of the test, decide whether to release $\theta \propto e^{-\frac{\gamma}{2}||\bf{y}-X\theta||^2 + \lambda||\theta||^2}$.\vspace{-1mm}
% \end{enumerate}
% \begin{theorem}
% The algorithm outlined in Example~\ref{examp:ops} satisfies $(\epsilon+ \hat{\epsilon}, \delta + \hat{\delta})$-DP. 
% \end{theorem}
% \end{example}


% The main idea of the above algorithm boils down to  privately releasing all data-dependent quantities in data-dependent DP, constructing high-probability confidence intervals of these quantities, and then deciding whether to run the mechanism $\cM$ with the proposed parameters. We defer the details of the privacy calibration of data-dependent quantities to the appendix. 

% One may ask why we cannot directly tune privacy parameters ($\lambda, \gamma$) based on the sanitized data-dependent DP. This is because, in many scenarios, data-dependent quantities depend on the choice of privacy parameters, e.g., $||\theta_\lambda^*||$ is a complicated function of $\lambda$. Thus, the optimization on $\lambda$ becomes a circular problem --- to solve $\lambda$, we need to sanitize $||\theta_
% \lambda^*||$, which needs to choose a $\lambda$ to begin with. Alternatively, generalized PTR provides a clear and flexible framework to test the validity of privacy parameters adapted to the dataset. 

% \begin{remark}
% The above ``circular'' issue is even more serious for generalized linear models (GLMs) beyond linear regression. The data-dependent DP there involves a local strong-convexity parameter, a complex function of the regularizer $\lambda$  and we only have zeroth-order access to. In the appendix, we demonstrate how to apply generalized PTR to provide a generic solution to a family of private GLMs where the link function satisfies a self-concordance assumption.
% \end{remark}
% \vspace{-2mm}

%we demonstrate that our generalized PTR provides a generic solution to private GLMs with data-adaptive analysis.
%In the appendix, we demonstrate that our generalized PTR can handle these cases effectively 
% in next selction, we demonstrate how we can combine the idea of privacy section for privacy calibration with the generalized PTR.




% remark it's close to sufficient statistic release. however, the data-dependent quantilties depends on the other parameters .


%We start by privately releasing $\lambda_{min}, L$ and $ ||\theta_\lambda^*||$ (condition on a high probability event). Then, the data-dependent DP is a function of $\phi = (\lambda, \gamma)$ with known global sensitivity $\triangle_\phi$. Next, we can apply Algorithm~\ref{alg:no_dist} to propose and test$(\lambda, \gamma)$ and decide whether to release $\theta \propto e^{-\frac{\gamma}{2}||\bf{y}-X\theta||^2 + \lambda||\theta||^2}$. We defer the full details to the appendix. 
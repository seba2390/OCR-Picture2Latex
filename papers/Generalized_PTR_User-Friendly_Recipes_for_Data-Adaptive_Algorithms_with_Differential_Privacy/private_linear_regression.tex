\begin{figure*}[t]
	\centering	
	\subfigure[Bike dataset]{
	\includegraphics[width=0.48\textwidth]{img/bike.pdf}\label{fig:bike}}
	\subfigure[Elevators dataset]{
	\includegraphics[width=0.46\textwidth]{img/elevator.pdf}\label{fig:ele}}
	%\vspace{-0.5em}
	\caption{Differentially private linear regression algorithms on UCI datasets. $y$-axis reports the MSE error with confidence intervals. $\epsilon$ is evaluated with $\delta = 1e-6$. }
	\label{fig:selection}%\vspace{-0.5em}
\end{figure*}



\begin{theorem}[\citep{wang2017per}]\label{thm: per}
For input data $X \in \mathcal{X}$ and $Y \in \mathcal{Y}$, define the following:
\begin{itemize}
    %\vspace{-1em}
    \item $\lambda_{\min}(X)$ denotes the smallest eigenvalue of $X^TX$; %\vspace{-1em}
    \item $||\theta_\lambda^*||$ is the magnitude of the solution $\theta_\lambda^* = (X^TX +\lambda I )^{-1}X^T Y$;%\vspace{-1em}
    \item and $L(X, \mathbf{y}):=||\cX||(||\cX||||\theta_\lambda^*||+||\cY||)$ is the local Lipschitz constant, denoted $L$ in brief.%\vspace{-1em}
\end{itemize}
For brevity, denote $\lambda^* = \lambda + \lambda_{\min}(X)$.
The algorithm used in Example~\ref{exp: posterior} with  parameter $\phi = (\lambda, \gamma)$ obeys $(\epsilon_{\phi}(Z), \delta)$ data-dependent DP for each dataset $ Z = (X, Y)$  with $\epsilon_{\phi}(Z)$ equal to
\[\sqrt{\frac{\gamma L^2 \log(2/\delta)}{\lambda^*}} + \frac{\gamma L^2}{2(\lambda^*  +||\cX||^2)}+ \frac{1 + \log(2/\delta)||\cX||^2}{2(\lambda^*)}.
\]
\end{theorem}

Notice that the data-dependent DP is a function of $(\lambda_{\min}, L, ||\theta_\lambda^*||, \lambda, \gamma)$, where $(\lambda_{\min}, L, ||\theta_\lambda^*||)$ are data-dependent quantities. One can apply the generalized PTR framework as in the following example.
\begin{example}[OPS with PTR] We demonstrate here how to apply generalized PTR to the one-posterior sample (OPS) algorithm, a differentially private mechanism which outputs one sample from the posterior distribution of a Bayesian model with bounded log-likelihood.
\label{examp:ops}
\begin{itemize}
    %\vspace{-1em}
    \item Propose $\phi=(\lambda, \gamma)$.    %\vspace{-0.5em}
    \item Based on $(\lambda, \gamma)$, differentially privately release $\lambda_{min}, ||\theta_\lambda^*||, L$ 
    with privacy budget $(\epsilon, \delta/2)$.    %\vspace{-0.5em}
    \item Condition on a high probability event (with probability at least $1-\delta/2$) of $\lambda_{min}, ||\theta_\lambda^*||, L$, test if $\blue{\epsilon_{\phi}^P(X)}$  is smaller than the predefined privacy budget $(\hat{\epsilon}, \hat{\delta})$, where $\epsilon_\phi^P(X)$ denotes the sanitized data-dependent DP.   % \vspace{-1em}
    \item Based on the outcome of the test, decide whether to release $\theta \propto e^{-\frac{\gamma}{2}||Y-X\theta||^2 + \lambda||\theta||^2}$.   % \vspace{-1em}
\end{itemize}
\begin{theorem}
The algorithm outlined in Example~\ref{examp:ops} satisfies $(\epsilon+ \hat{\epsilon}, \delta + \hat{\delta})$-DP. 
\end{theorem}
\end{example}

%\vspace{-0.5em}
The main idea of the above algorithm boils down to  privately releasing all data-dependent quantities in data-dependent DP, constructing high-probability confidence intervals of these quantities, and then deciding whether to run the mechanism $\cM$ with the proposed parameters. We defer the details of the privacy calibration of data-dependent quantities to the appendix. 

One may ask why we cannot directly tune privacy parameters ($\lambda, \gamma$) based on the sanitized data-dependent DP. This is because, in many scenarios, data-dependent quantities depend on the choice of privacy parameters, e.g., $||\theta_\lambda^*||$ is a complicated function of $\lambda$. Thus, the optimization on $\lambda$ becomes a circular problem --- to solve $\lambda$, we need to sanitize $||\theta_
\lambda^*||$, which needs to choose a $\lambda$ to begin with. Alternatively, generalized PTR provides a clear and flexible framework to test the validity of privacy parameters adapted to the dataset. 

\begin{remark}
The above ``circular'' issue is even more serious for generalized linear models (GLMs) beyond linear regression. The data-dependent DP there involves a local strong-convexity parameter, a complex function of the regularizer $\lambda$  and we only have zeroth-order access to. In the appendix, we demonstrate how to apply generalized PTR to provide a generic solution to a family of private GLMs where the link function satisfies a self-concordance assumption.
\end{remark}
%\vspace{-0.5em}

We next apply Algorithm~\ref{alg: parameter_ptr} for Example~\ref{examp:ops}  with UCI regression datasets. Standard z-scoring is applied and each data point is normalize with a Euclidean norm of 1.  We consider $(60\%,10\%,30\%)$ splits for training, validation and testing test.

\textbf{Baselines}
\begin{itemize}
%\vspace{-0.5em}
    \item Output Perturbation (Outpert)~\citep{chaudhuri2011differentially}: $\theta=(X^TX + \lambda I)^{-1}X^T\bf{y}$. Release $\hat{\theta} = \theta + \bf{b}$ with an appropriate $\lambda$, where $\bf{b}$ is a Gaussian random vector.%\vspace{-1em}
    \item Posterior sampling (OPS). Sample $\hat{\theta}\sim P(\theta)\propto e^{-\gamma(F(\theta)+ 0.5 \lambda ||\theta||^2)}$ with parameters $\gamma, \lambda$.%\vspace{-1em}
    \item Adaptive posterior sampling (AdaOPS)~\citep{wang2018revisiting}. Run OPS with $(\lambda, \gamma)$ chosen adaptively according to the dataset.%\vspace{-1em}
\end{itemize}
%\yw{\cite{gopi2022private} had a nice and clean Gaussian DP bound for OPS. I thought if we can privately test the strong convexity from the dataset, it should satisfy a stronger Gaussian DP. How are privacy accounted in the experiments now?} % use composition.  Each oracle call is (eps, delta). split (epsilon/2, delta/2) to release data dependent quantity, use the remaining to tune gamma for an input lambda.
Outpert and OPS serve as two non-adaptive baselines. In particular, we consider OPS-Balanced~\citep{wang2018revisiting}, which chooses $\lambda$ to minimize a data-independent upper bound of empirical risk and dominates other OPS variants. 
AdaOPS is one state-of-the-art algorithm for adaptive private regression, which  automatically chooses $\lambda$ by minimizing an upper bound of the data-dependent empirical risk.


We implement OPS-PTR as follows: 
propose a list of $\lambda$ through grid search (we choose $k=30$ and $\lambda$ ranges from $[2.5, 2.5^{10}]$ on a logarithmic scale); instantiate Algorithm~\ref{alg: parameter_ptr} with $\tau =0.1k$, $T=\frac{1}{\tau} \log(1/\delta_2)$ and  $\delta_2 = 1/2 \delta$;
calibrate $\gamma$ to meet the privacy requirement for each $\lambda$. sample $\hat{\theta}$ using $(\lambda,\gamma)$ and return the one with the best validation accuracy. Notice that we use a ``no $\perp$'' variant of Algorithm~\ref{alg:gen_ptr} as the calibration of $\gamma$ is clear given a fixed $\lambda$ and privacy budget (see more details in the appendix). We can propose various combinations of $(\lambda, \gamma)$ for more general applications.


 Figure~\ref{fig:selection}  demonstrates how the MSE error of the linear regression algorithms varies with the privacy budget $\epsilon$. OutPert suffers from the large global sensitivity of output $\theta$. OPS performs well but does not benefit from the data-dependent quantities. AdaOPS is able to adaptively choose $(\lambda, \gamma)$ based on the dataset, but suffers from the estimation error of the data-dependent empirical risk. On the other hand, OPS-PTR selects a  $(\lambda, \gamma)$ pair that minimizes the empirical error on the validation set directly, and the privacy parameter $\gamma$ adapts to the dataset thus achieving the best result.

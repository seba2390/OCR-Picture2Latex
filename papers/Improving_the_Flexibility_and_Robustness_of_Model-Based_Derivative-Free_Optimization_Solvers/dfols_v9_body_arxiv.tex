% NOTE: ABSTRACT IN WRAPPER DOCUMENTS

\section{Introduction}
%%\alert{[General NAG comment: cut down length of intro (don't want to be too repetitive with main text)]}

The ability to solve optimization problems in the absence of derivative information --- known as derivative-free optimization (DFO) --- is an important goal for optimization software.
The need for DFO software particularly arises when function evaluations are expensive (so finite differencing is too costly), or when evaluations are noisy (so the accurate evaluation of derivatives is impossible).
%Both of these features may be found, for instance, in parameter fitting for climate models \cite{Tett2013}.
A state-of-the-art  category of DFO algorithms are the so-called `model-based' methods.
These methods are similar to classical trust-region methods, which require the iterative minimization of local models for the objective over a trust-region ball, except the local models are constructed by interpolation instead of using derivative information.
Model-based DFO solvers are known to capture curvature in the objective well \cite{Custodio2017}, and have good practical performance \cite{More2009}.

In this paper, we focus on improving the flexibility and robustness of model-based DFO solvers for two regimes: 
\begin{description}
	\item[\normalfont\textit{Expensive:}] objectives which may be noiseless but expensive to evaluate. Here, the goal is to make reasonable progress, not necessarily reaching high accuracy in the
solution, using very few evaluations; and,
	\item[\normalfont\textit{Noisy:}] objectives which are cheap(er) to evaluate but whose evaluation may contain noise. We aim to improve the robustness of the solver --- maximizing the amount of progress the solver can make, and hence, the number of problems that can be solved despite the difficulties associated with inaccurate local models and objective evaluations.
%The ensuing difficulty comes from inaccurately constructed local models  (by interpolation to noisy data), and incorrectly measuring progress (namely, noise causes steps to be incorrectly classified %as (un)successful). 
\end{description}
Clearly, the two regimes may overlap, in which case we still aim and show that we can make reasonable progress in our proposed algorithms.
We are particularly interested in solving unconstrained (or possibly bound-constrained) nonlinear least-squares problems, but also consider general nonlinear objectives.

Regarding the `expensive' regime, model-based DFO solvers typically require at least $n+1$ objective evaluations (for an $n$-dimensional problem)   before they can begin the first iteration;
this evaluation cost represents the cost of setting up the first local model, from scratch, while subsequent iterations commonly
only update the interpolation set and the local model at a much lower evaluation cost.
However, in the `expensive' regime, this start-up cost may be prohibitive, and the user may wish to see decreases in the objective much sooner.
Direct search DFO solvers, such as BFO by Porcelli and Toint \cite{Porcelli2017}, can make progress with very few objective evaluations, but this flexibility is not generally found in model-based DFO
methods.

For the `noisy' regime, model-based DFO solvers can generally  make some progress on a problem, but often stagnate at incorrect solutions, without even  using  the full computational budget provided by the user; see \figref{fig_restarts_motivation}, for instance.
Two main methods have been suggested for robustly handling noisy objectives in a model-based DFO context.
%, namely sample averaging and regression.
Sample averaging is the most common approach for handling noisy evaluations; see  \cite{Deng2006,Deng2009,Shashaani2016,Chen2016}.
For theoretical convergence guarantees to hold, one must compute $\bigO(\Delta_k^{-4})$ samples of the objective at each point (e.g.~\cite{Chen2016}), where $\Delta_k$ is the trust region radius at iteration $k$.
However, this requirement rapidly becomes infeasible, so $\bigO(\Delta_k^{-1})$ samples is a more sensible choice in practice  \cite{Chen2016}.
The other main approach is to build regression models (i.e.~having more interpolation points than degrees of freedom in the model) rather than interpolation models \cite{Conn2008,Billups2013,Chen2016}.
We note in particular the STORM algorithm from Chen, Menickelly and Scheinberg \cite{Chen2016}, which uses $\bigO(\Delta_k^{-1})$ interpolation points at each iteration $k$, and determines whether a step gives sufficient objective decrease by averaging over $\bigO(\Delta_k^{-1})$ samples.
In both cases,  there is a tradeoff between robustness of the solver and performance in early phases, where the latter is very slow as sampling and regression require a large amount of problem information to accumulate before starting to generate substantial objective improvement. 
%the performance in early phases of the algorithms is (unnecessarily) very slow, until significant amount of problem information has been accumulated. 
%take significant build-up of problem information before they can start progressing.
%--- in many cases reasonable progress can be made for many iterations without needing averaging or regression.

%they take a lot of time to get going

An alternative approach for the `noisy' regime is used in SNOWPAC by Augustin and Marzouk \cite{Augustin2017}.
This solver extends a previous model-based DFO code for constrained nonlinear programs by the same authors, NOWPAC \cite{Augustin2014}, by constructing a Gaussian Process surrogate model for the noisy objective, from previously-seen objective values and standard errors.
%Then at each iteration, an interpolation model is constructed to pass through a weighted average of the (noisy) objective and the surrogate model evaluated at each point, where the weighting depends on the uncertainty in the surrogate.
This approach avoids the performance loss in early phases, however it requires the user to provide standard error estimates for each objective evaluation, and introduces potentially expensive surrogate model construction steps, especially when using a large set of observations.
Here, we are particularly interested in nonlinear least-squares problems, where we build local models for each residual separately.
In this context especially, building surrogate models may prohibitively expensive.

\paragraph{Algorithm development and software contributions}
In this paper we introduce a new model-based DFO package in Python for nonlinear least-squares problems with optional bound constraints, which we call DFO-LS (Derivative-Free Optimization for Least-Squares). It builds on our previous code for nonlinear least-squares, DFO-GN \cite{Cartis2017a}, in that it continues to use linear local models for each residual function (rather than quadratic), which reduces the computational cost of the interpolation step.
DFO-LS has a wide variety of additional default and optional features,  that can be used on their own or in combination, with defaults selected based on extensive testing. These features,
apart from averaging and regression sampling, are novel for model-based DFO solvers. 
%DFO-LS has a wide variety of additional default and optional features,  which, apart from sampling/regression, are novel for model-based DFO solvers. These features can be used on their own or in combination, with defaults selected based on extensive testing.
The most notable of these features are:
\begin{description}
	\item[\normalfont\textit{Reduced Initialization Cost:}] The ability to begin the main iteration after as few as 2 objective evaluations (as opposed to at least $n+1$ for an $n$-dimensional problem in other solvers);
	\item[\normalfont\textit{Multiple Default Parameter Choices:}] The modification of some algorithm parameters (such as trust-region parameters, termination criteria) to more appropriate values if the objective function is noisy;
	\item[\normalfont\textit{Sample Averaging \& Regression:}] The optional use of sample averaging (allowing an extensive range of sampling methodologies) and/or regression-based model construction; and,
	\item[\normalfont\textit{Multiple Restarts:}] The use of multiple restarts to allow greater exploration of the search space for noisy objectives. Although this feature is novel in the model-based DFO setting, similar techniques have been commonly used in numerical analysis, such as  multiple restarts of nonlinear conjugate gradient methods \cite[Chapter 5]{Nocedal2006} and GMRES \cite[Chapter 6]{Demmel1997},  multi-starting local solvers  in global optimization \cite{Locatelli2013}, as well as for  robustness improvement of the Nelder-Mead algorithm \cite{Kelley1999}. In our results, we find that multiple restarts greatly enhance the performance of DFO-LS for noisy problems, yielding superior performance even compared to DFO-LS with a high level of sample averaging. In particular, we note that the multiple restarts approach avoids the early loss of performance typical of sample averaging and regression, 
does not require extra user input common to  surrogate model approaches,	and is cheap to implement.	
\end{description}
%Although this feature is novel in the model-based DFO setting, similar methods have been used in other contexts: performing multiple runs of a local solver is common in global optimization \cite{Locatelli2013}, and multiple restarts are also a common feature of nonlinear conjugate gradient methods \cite[Chapter 5]{Nocedal2006} and GMRES \cite[Chapter 6]{Demmel1997}, and has been proposed to improve the robustness of the Nelder-Mead algorithm \cite{Kelley1999}.
The `reduced initialization cost' feature is designed for the `expensive' regime; the others are designed for the `noisy' regime.
We additionally demonstrate that these regimes are not mutually exclusive: using a reduced initialization cost works similarly well for noisy problems (as for noiseless problems), and multiple restarts can sometimes improve performance, including escaping local minima, for noiseless problems.

Some of the above features of DFO-LS are not closely tied to the least-squares problem structure.
Hence, in this paper we also introduce a package for general objective problems with optional bound constraints, Py-BOBYQA, so named as it is a Python implementation of Powell's BOBYQA \cite{Powell2009}.
In particular, Py-BOBYQA implements \textit{multiple default parameter choices}, \textit{sample averaging}, and \textit{multiple restarts}.

\paragraph{Testing Framework Contribution}
We also propose an improvement to the measurement standards of solver performance for noisy problems.
As detailed in \cite{More2009}, data and performance profiles are useful measures for comparing DFO solvers on a standard given test set, which measure the number of objective evaluations required to reach an objective value below a problem- and accuracy-dependent threshold. We assume that  a collection of deterministic test problems is used --- such as Mor\'e \& Wild or CUTEst ---
and that noisy variants of each problem are created by perturbing the objective or residual functions by multiplicative or additive stochastic noise. In this context, 
one can check decrease using either the value of the true (noiseless) objective, or the actual (noisy) objective seen by the solver; these two approaches are used, for instance, in \cite{Chen2016} and \cite{Billups2013} respectively.
In this paper, we show that these two measures produce similar results until a problem- and noise-specific accuracy level is reached; beyond this cut-off level, measured performance is better when the `noisy objective'  is used due, most commonly, to successful sampling (rather than optimization). 
As a result, we propose  showing profile results using an adaptive accuracy level; namely,
at the desired accuracy level whenever the latter is larger than the per-problem accuracy cut-off, and at the cut-off accuracy level, otherwise.
We illustrate that this approach is  a fairer approach for testing which focuses on genuine objective reductions rather than `lucky' sampling errors.
%We validate our approach compared to measuring noisy and noiseless objective progress

%but using a lower accuracy level for some problems based on this cut-off.
%%We show that this approach gives similar conclusions about solver performance for both measures (both in terms of comparing solvers against each other, and measuring their absolute performance %%level), and hence is a fairer approach for testing which focuses on genuine objective reductions rather than `lucky' sampling errors.
%, but using only information available to the solvers.

%\alert{[NAG comment: this section is unclear, should say the new method is fairer --- this version has tried to change this]}

\paragraph{Comparisons to Related Software}
%The DFO-LS algorithm is an extension of DFO-GN by Cartis and Roberts \cite{Cartis2017a}, which is also designed for nonlinear least-squares problems.
%The main change to the basic underlying algorithm is to use regression-based model construction, enabling the inclusion of the new features described above.
%Other model-based DFO solvers for nonlinear least-squares include DFBOLS by Zhang, Conn and Scheinberg \cite{Zhang2010} and POUNDERS by Wild \cite{Wild2017}.
In our numerical results, we compare DFO-LS to DFO-GN \cite{Cartis2017a} and DFBOLS \cite{Zhang2010}, also designed for nonlinear least-squares problems\footnote{There is only 
one other nonlinear least squares DFO solver that we are aware of, namely, POUNDERS \cite{Wild2017}. We have already compared it against DFO-GN
and DFBOLS in \cite{Cartis2017a}.}.
%%(see \cite{Cartis2017a} for a comparison of these two solvers with POUNDERS).
We find that using different default parameters for noisy problems, coupled with multiple restarts, makes DFO-LS have substantially improved robustness to noise over both DFO-GN and DFBOLS, without the early loss of performance associated with sample averaging and regression models.
We also find that using a reduced initialization cost for medium-scale problems ($n\approx 100$ dimensions) allows DFO-LS to make reasonable progress on some problems with fewer than $n$ objective evaluations, but with a slight performance penalty for medium-sized budgets.

As mentioned above, the general-objective solver Py-BOBYQA is based on the original package by Powell \cite{Powell2009,Zhang_URL}.
In our testing, we compare Py-BOBYQA with the original BOBYQA, together with (S)NOWPAC \cite{Augustin2014,Augustin2017}, and our own implementation\footnote{\:There are several versions of the STORM algorithm given for different noise settings. We use the version of STORM designed for unbiased noise, which builds regression models from independent samples at every iteration, because it showed better performance than other variants.} of STORM \cite{Chen2016}.
In our testing for noisy problems, we find that the different default parameters and multiple restarts in Py-BOBYQA means it substantially outperforms BOBYQA.
It achieves a similar or better level of robustness than SNOWPAC and STORM, but with a mechanism which is cheap to implement and does not penalize performance in early phases.

%\alert{[NAG comment: cut down by just saying ``we do these comparisons'' and leave results for main text]}

\paragraph{Software Availability}
The two Python packages in this paper, DFO-LS and Py-BOBYQA, are available on Github\footnote{\:See \url{https://github.com/numericalalgorithmsgroup/dfols} and \url{https://github.com/numericalalgorithmsgroup/pybobyqa} respectively. Versions 1.0.1 of both packages were used for all the testing below.}.
They are released under the GNU General Public License.

\paragraph{Paper Structure}
In \secref{sec_algo_framework}, we introduce the general DFO-LS algorithm.
Details about the new features of DFO-LS are given in \secref{sec_implementation}.
We summarize the testing framework, including the modification of testing criteria for noisy problems, in \secref{sec_testing_framework}.
Then, in \secref{sec_new_features_results}, we provide a collection of different studies, showing numerical results for the key new features in DFO-LS.
The final section on DFO-LS is \secref{sec_dfols_benchmarking}, where we compare its performance against other derivative-free nonlinear least-squares solvers.
Lastly, in \secref{sec_pybobyqa}, we introduce the Py-BOBYQA solver by summarizing the model construction process for general objective minimization and detailing the features from DFO-LS which Py-BOBYQA inherits.
This section also shows numerical results comparing Py-BOBYQA against other model-based derivative-free solvers for general objective problems.
We summarize our results and conclude in \secref{sec_conclusion}.

\section{General Algorithmic Framework} \label{sec_algo_framework}
The DFO-LS software is designed to solve the nonlinear least-squares problem\footnote{\:Note that in line with the implementation of DFO-LS, we do not have a constant $1/2$ factor in \eqref{eq_ls_definition}.}
\be \min_{\bx\in\R^n}\: f(\bx) \defeq \|\br(\bx)\|^2 = \sum_{i=1}^{m}r_i(\bx)^2, \label{eq_ls_definition} \ee
where $\br(\bx) \defeq [r_1(\bx) \: \cdots \: r_m(\bx)]^{\top}$ is a continuously differentiable function from $\R^n$ to $\R^m$, but its Jacobian matrix of first derivatives is unavailable. Both the case when $m\geq n$ (least-squares) and $m\leq n$ (inverse problems) are allowed.
%Although $m\geq n$ is common in practice, we do not require this here.
% The $m\times n$ Jacobian matrix of $\br$ is $J(\bx)$ with entries $[J(\bx)]_{i,j} = \pd{r_i(\bx)}{x_j}$. 
%We assume that the Jacobian matrix of first derivatives of $\br$ exists, but is unavailable.
Lastly, we use $\|\cdot\|$ for the 2-norm of vectors and matrices (i.e.~Euclidean norm and largest singular value respectively) unless otherwise specified, and for $\bx\in\R^n$ and $\Delta>0$, we define $B(\bx,\Delta):=\{\by\in\R^n : \|\by-\bx\|\leq\Delta\}$.

\subsection{Regression Interpolation Models} \label{sec_regression_models}
DFO-LS constructs a linear model for $\br(\bx)$ in a neighbourhood of the current iterate $\bx_k$ at every iteration.
To achieve this in a derivative-free way, we maintain a set of $p+1$ points $Y_k=\{\bx_k, \by_1, \ldots, \by_p\}\subset\R^n$, where we let $\by_0\defeq \bx_k$ for notational convenience.
The usual regime has $p\geq n$, but if needed, we also allow $p<n$ in early iterations in order to reduce the initial evaluation cost of DFO-LS; both constructions are described here. The default option in DFO-LS is to initialize with a full set of $n+1$ points (so $p=n$).




When $p\geq n$, we build a model
\be \br(\bx_k+\bs) \approx \bem_k(\bs) \defeq \br_k + J_k\bs, \label{eq_linear_models} \ee
by solving the regression problem
\be \min_{\br_k,J_k} \: \sum_{t=0}^{p} \|\bem_k(\by_t-\bx_k) - \br(\by_t)\|^2. \label{eq_interp_conditions} \ee
This corresponds to finding the least-squares solutions to the overdetermined linear systems
\be W_k \begin{bmatrix}r_{k,i} \\ \b{j}_{k,i}\end{bmatrix} \defeq \begin{bmatrix}1 & (\by_0-\bx_k)^{\top} \\ \vdots & \vdots \\ 1 & (\by_p-\bx_k)^{\top}\end{bmatrix}\begin{bmatrix}r_{k,i} \\ \b{j}_{k,i}\end{bmatrix} = \begin{bmatrix}r_i(\by_0) \\ \vdots \\ r_i(\by_p)\end{bmatrix}, \label{eq_linear_interp_system} \ee
for all $i=1,\ldots,m$, where $r_{k,i}$ and $\b{j}_{k,i}^{\top}$ are the $i$-th entry of $\br_k$ and row of $J_k$ respectively.
The matrix $W_k$ has full column rank whenever the set $\{\by_1-\bx_k, \ldots, \by_p-\bx_k\}$ spans $\R^n$; we ensure this in DFO-LS by calling procedures to improve the geometry of $Y_k$ (in a specific sense discussed below).
However, as the algorithm progresses, the points $\by_t$ get progressively closer to $\bx_k$, so $W_k$ becomes ill-conditioned.
To avoid this issue, we precondition \eqref{eq_linear_interp_system} by scaling the second through last columns of $W_k$ by $\alpha_k^{-1}$, where $\alpha_k \defeq \max_{t=1,\ldots,p} \|\by_t-\bx_k\|$.

Once we have built the vector model $\bem_k$ \eqref{eq_linear_models}, we construct a quadratic model $m_k$ for the full objective $f(\bx)$ in the obvious way, by defining
\be f(\bx_k+\bs) \approx m_k(\bs) \defeq \|\bem_k(\bs)\|^2 = \|\br_k\|^2 + \bg_k^{\top}\bs + \frac{1}{2}\bs^{\top}H_k\bs, \label{eq_gn_full_model_dfo} \ee
where $\bg_k\defeq 2 J_k^{\top}\br_k$ and $H_k\defeq 2 J_k^{\top}J_k$.

This approach is similar to the DFO-GN algorithm, but our slightly different formulation of the interpolation problem \eqref{eq_interp_conditions} is designed to allow improved robustness for noisy problems, and reduce the initialization cost of the algorithm.

\begin{remark}
	An alternative interpolation framework which we considered, inspired by a comment in \cite[Chapter 4]{Conn2009}, designed to balance accuracy of interpolation against large changes in the model between iterations, was to replace \eqref{eq_interp_conditions} with
	\be \min_{\br_k,J_k} \: \|J_k-J_{k-1}\|_F^2 + \lambda_k \sum_{t=0}^{p} \|\bem_k(\by_t-\bx_k) - \br(\by_t)\|^2, \ee
	where $\lambda_k>0$ is an algorithm parameter.
	This idea of allowing inexact interpolation was motivated by the case of noisy objective evaluation.
	However, our extensive testing showed that the best results for this framework, even for noisy objectives, required setting $\lambda_k$ very large (at least $10^{10}$), which means that we are essentially solving \eqref{eq_interp_conditions}.
\end{remark}

\paragraph{Reduced Initialization Cost for Expensive Objectives}
The interpolation problem \eqref{eq_interp_conditions} requires $p\geq n$, so that the system \eqref{eq_linear_interp_system} is square or overdetermined.
This means that before the first model can be constructed, we must evaluate the objective at $p+1$ points --- this is common in model-based DFO algorithms.
Although these evaluations may be parallelized, a user may not have the ability to do this, and the cost of these evaluations may be prohibitive.
In such settings, DFO-LS can proceed with a reduced initialization cost, constructing the model \eqref{eq_linear_models} using as few as 2 objective evaluations.

Suppose we have evaluated the objective at $p+1$ affinely-independent points $\{\by_0,\ldots,\by_p\}$ with $\by_0\defeq\bx_k$, where we now assume $1\leq p<n$.
We construct $\bem_k$ by solving the same interpolation system \eqref{eq_linear_interp_system}, which is now underdetermined, and for which we select the minimal (Euclidean) norm solution.
The resulting $\br_k$ and $J_k$ are solutions to\footnote{\:Note that because in this phase of the algorithm we never remove points from $Y_k$, provided $\{\by_t-\bx_k : t=1,\ldots,p\}$ is linearly independent, \eqref{eq_growing_min_norm} is equivalent to minimizing the change in the model, $\min_{\br_k,J_k}\|\br_k-\br_{k-1}\|^2 + \alpha_k \|J_k-J_{k-1}\|_F^2$.}
\be \min_{\br_k, J_k} \|\br_k\|^2 + \alpha_k \|J_k\|_F^2 \qquad \text{s.t.} \qquad \bem_k(\by_t-\bx_k) = \br(\by_t), \quad \forall t=0,\ldots,p, \label{eq_growing_min_norm} \ee
where $\alpha_k$, defined above, is the column scaling used to precondition \eqref{eq_linear_interp_system}.

However, the construction \eqref{eq_growing_min_norm} is not ideal, because, as proven in \lemref{lem_rank_deficient_model} below, the resulting $J_k$ is not full rank, so the models $\bem_k$ and $m_k$ are not full-dimensional; that is, there are directions along which these are constant, regardless of the objective.

\begin{lemma} \label{lem_rank_deficient_model}
	Suppose $\bem_k$ \eqref{eq_linear_models} is constructed  using \eqref{eq_growing_min_norm}
	 with $p<n$, and where $\{\by_0,\ldots,\by_p\}$ are affinely independent.
	Then $J_k$ has column rank $p$.
\end{lemma}
\begin{proof}
The solution of \eqref{eq_growing_min_norm} is the minimal norm solution for system \eqref{eq_linear_interp_system}.
	Using $\by_0=\bx_k$, we write $W_k$ in \eqref{eq_linear_interp_system} as
	\be W_k = \begin{bmatrix}1 & \b{0}^{\top} \\ \bee & L_k\end{bmatrix}, \qquad \text{where} \qquad L_k \defeq \begin{bmatrix}(\by_1-\bx_k) & \cdots & (\by_p-\bx_k)\end{bmatrix}^{\top} \in \R^{p\times n}, \ee
	and $\bee\in\R^{p}$ is the vector of ones.
	Since the interpolation points are affinely independent, $L_k^{\top}$ has full column rank $p$, so we have the QR factorization $L_k^{\top} = \widehat{Q}\widehat{R}$, where $\widehat{Q}\in\R^{n\times p}$ has columns which are an orthonormal basis for $\operatorname{col}(L_k^{\top})$ and $\widehat{R}\in\R^{p\times p}$ is invertible and upper triangular.
	Then the minimal-norm solution to \eqref{eq_linear_interp_system} is given by
	\be \begin{bmatrix}r_{k,i} \\ \b{j}_{k,i}\end{bmatrix} = \begin{bmatrix}1 & \b{0}^{\top} \\ \b{0} & \widehat{Q}\end{bmatrix}\begin{bmatrix}1 & \b{0}^{\top} \\ \bee & \widehat{R}^{\top}\end{bmatrix}^{-1}\begin{bmatrix}r_i(\by_0) \\ \vdots \\ r_i(\by_p)\end{bmatrix}. \ee
	That is, $\b{j}_{k,i}\in\operatorname{col}(\widehat{Q})$, so $J_k$ can be written as $J_k=\widehat{J}_k \widehat{Q}^{\top}$ for some $\widehat{J}_k\in\R^{m\times p}$, and thus $J_k$ has column rank $p$.
\end{proof}

Thus by using this model, we will not in general be able to find a solution.
A simple way to address this issue would be to, at each iteration, replace one point with the new iterate $\bx_{k+1}$ using standard methods, then add another point to the interpolation set, chosen to increase the dimension of the model (until a full-dimensional model is achieved).
However, this would require two objective evaluations per iteration, which may be wasteful when evaluations are expensive.


{\bf Making the Jacobian full rank in the expensive regime}
Instead, after calculating the rank-deficient $J_k$, DFO-LS makes it full rank --- and hence makes the model full-dimensional --- by increasing its $n-p$ smallest singular values $\sigma_{p+1}=\cdots=\sigma_n=0$ to the level of the smallest nonzero singular value $\sigma_p>0$; this requires the calculation of the SVD of $J_k$.


{\bf Alternative mechanism for expanding the search space}
DFO-LS has another optional mechanism for increasing the dimension of the model, instead of perturbing the singular values of $J_k$.
In this approach, after finding the trust region step $\bs_k$, we replace the new candidate point $\bx_k+\bs_k$ with the perturbed point $\bx_k+\bs_k+\b{d}_k$, where $\b{d}_k$ is a random direction orthogonal to our current set of search directions (with length a constant multiple of $\Delta_k$).
We compare these two approaches in \secref{sec_growing_testing}, and conclude that the SVD-based variant  has similar performance to the random direction extension for small budgets, but better performance for longer budgets.
%\alert{[in the earlier version, this comparison wasn't explicitly discussed in \secref{sec_growing_testing}, I have added it in]}; 
Thus the SVD approach is chosen as the default in DFO-LS when an initialization with less than $n$ interpolation points is used.

\subsection{Core Algorithmic Framework} \label{sec_main_algo}
% \subsection{Trust Region Framework} \label{sec_trust_region}
\paragraph{Trust Region Framework}
The general algorithmic framework of DFO-LS is that of trust region methods \cite{Conn2000}.
In these methods we maintain a radius parameter $\Delta_k>0$, and say that we expect $m_k$ \eqref{eq_gn_full_model_dfo} to be a good approximation for $f$ in $B(\bx_k,\Delta_k)$, the so-called `trust region'.

At each step in the algorithm, we construct $m_k$ and calculate a step by solving the trust region subproblem
\be \bs_k \approx \argmin_{\|\bs\|\leq\Delta_k} m_k(\bs). \label{eq_tr_subproblem} \ee
Efficient algorithms exist for solving \eqref{eq_tr_subproblem} approximately (e.g.~\cite{Conn2000,Powell2009}).
Having calculated a step $\bs_k$, we evaluate $f(\bx_k+\bs_k)$.
If this step produces a sufficient decrease in the objective, in the sense that
\be r_k \defeq \frac{f(\bx_k) - f(\bx_k+\bs_k)}{m_k(\b{0}) - m_k(\bs_k)}, \label{eq_tr_ratio} \ee
is sufficiently large, then we accept the step (i.e.~set $\bx_{k+1}=\bx_k+\bs_k$) and increase $\Delta_k$.
If the step does not produce sufficient decrease, then we reject the step (i.e.~$\bx_{k+1}=\bx_k$) and decrease $\Delta_k$.
In our derivative-free setting, we then need to update $Y_k$ to ensure it includes the (possibly new) point $\bx_{k+1}$, and where necessary, move points in $Y_k$ to improve its geometry.


% \subsection{Geometric Considerations} \label{sec_geometry}
\paragraph{Geometric Considerations}
When developing model-based DFO methods, it is well-known (e.g.~\cite{Scheinberg2010}) that one needs to take steps to keep the geometry of $Y_k$ `good', and prevent degeneracy.

For the linear regression models in DFO-LS, the notion of `good' was defined by Conn, Scheinberg and Vicente \cite{Conn2008}.
First, we define the regression Lagrange polynomials of $Y_k$, as the linear functions $\{\Lambda_0(\by), \ldots, \Lambda_p(\by)\}$ given by
\be \Lambda_t(\by) \defeq c_t + \bg_t^{\top}(\by-\bx_k), \quad \text{where $c_t$ and $\bg_t$ solve} \quad \min_{c_t,\bg_t} \: \sum_{s=0}^{p} \left(\Lambda_t(\by_s) - \delta_{s,t}\right)^2. \ee
These polynomials exist and are unique whenever $W_k$ \eqref{eq_linear_interp_system} has full column rank \cite{Conn2008}.
Given these Lagrange polynomials, the measure of the quality of $Y_k$ is given by the following definition.

\begin{definition}[$\Lambda$-poised, regression sense] \label{def_poised}
	For $B\subset\R^n$ and $\Lambda>0$, the set $Y_k$ with $|Y_k|=p+1$ is $\Lambda$-poised in $B$ in the regression sense if $p\geq n$ and
	\be \max_{t=0,\ldots,p}\: \max_{\by\in B} |\Lambda_t(\by)| \leq \Lambda, \ee
	for all $\by\in B$, where $\{\Lambda_0(\by), \ldots, \Lambda_p(\by)\}$ are the regression Lagrange polynomials for $Y_k$.
\end{definition}

A similar definition holds for exact (i.e.~non-regression) interpolation when $p=n$; see \cite{Cartis2017a} for details.
As in that case, a small value of $\Lambda$ indicates that the geometry of $Y_k$ is `good'.
%The reason we consider the $\Lambda$-poisedness of $Y_k$ is that it ensures our models $\bem_k$ \eqref{eq_linear_models} and $m_k$ \eqref{eq_gn_full_model_dfo} are good approximations for $\br$ and $f$ respectively.
The steps we use in DFO-LS to improve the $\Lambda$-poisedness of $Y_k$ are outlined in \secref{sec_implementation_general}, and the details of how $\Lambda$-poisedness leads to good regression models are given in \appref{sec_convergence}.

No geometry-improving steps are allowed in the early iterations of the expensive regime, while $p<n$.

\subsection{DFO-LS Algorithm}
\begin{algorithm}
	\small{
	\begin{algorithmic}[1]
		\Require Starting point $\bx_0\in\R^n$, initial trust region radius $\Delta_0>0$ and integers $p_{init}$ and $p$, the sizes of the initial and final interpolation sets, respectively,
where $1\leq p_{init}\leq p$ and   $p\geq n$. 
		\vspace{0.2em}
		\Statex Parameters: maximum trust region radius $\Delta_{max}\geq\Delta_0$, minimum trust region radius $0<\rho_{end}<\Delta_0$, trust region radius scalings $0<\gamma_{dec}<1<\gamma_{inc}\leq\overline{\gamma}_{inc}$ and $0<\alpha_1<\alpha_2<1$, acceptance thresholds $0 < \eta_1 \leq \eta_2 < 1$, safety reduction factor $0 < \omega_S < 1$, safety step threshold $0 < \gamma_S < 1$, and Boolean flag \texttt{NOISY} for the presence of noise in the objective.
		\vspace{0.5em}
		\State Build an initial interpolation set $Y_0\subset B(\bx_0,\Delta_0)$ of size $p_{init}+1$, with $\bx_0\in Y_0$. Set $\rho_0=\Delta_0$.
		\For{$k=0,1,2,\ldots$}
			\If{\texttt{NOISY} \textbf{and} \textit{all values $\{f(\by) : \by \in Y_k\}$ are within noise level of $f(\bx_k)$}}
				\State Call restart (set $\Delta_{k+1}=\rho_{k+1}=\Delta_0$ and build $Y_{k+1}$ as per \secref{sec_restarts_description}) and \textbf{goto} line \ref{ln_loop}.
			\EndIf
			\State Given $\bx_k$ and $Y_k$, construct the model $\bem_k(\bs)$ \eqref{eq_linear_models}
by solving the interpolation problem \eqref{eq_growing_min_norm} if $ |Y_k|<p+1$, otherwise \eqref{eq_linear_interp_system}.\label{ln_loop}
\State Form the full model $m_k$ \eqref{eq_gn_full_model_dfo}, and  
approximately solve the trust region subproblem \eqref{eq_tr_subproblem} to get a step $\bs_k$.\label{ln_trs}
			\If{$\|\bs_k\| < \gamma_S \rho_k$}
				\If{$|Y_k|<p+1$}
					\State \underline{Safety Phase (Growing)}: Form $Y_{k+1}=Y_k\cup\{\bx_k+\bs\}$ for some $\bs$ orthogonal to $\{\by-\bx_k : \by\in Y_k\}$ with $\|\bs\|=\Delta_k$.
					\State Set $(\rho_{k+1}, \Delta_{k+1}) = (\rho_k, \Delta_k)$.
				\Else
					\State \underline{Safety Phase}: Set $\bx_{k+1}=\bx_k$ and $\Delta_{k+1} = \max(\rho_k, \omega_S \Delta_k)$, and form $Y_{k+1}$ by improving the geometry of $Y_k$.
					\State If $\Delta_{k+1} = \rho_k$, set $(\rho_{k+1}, \Delta_{k+1}) = (\alpha_1\rho_k, \alpha_2\rho_k)$, otherwise set $\rho_{k+1}=\rho_k$.
					\State If $\rho_{k+1}\leq \rho_{end}$: call restart if \texttt{NOISY}, else \textbf{terminate}.
				\EndIf
				\State \textbf{goto} line \ref{ln_loop}.
			\EndIf
			\State Evaluate $\br(\bx_k+\bs_k)$ and calculate ratio $r_k$ \eqref{eq_tr_ratio}.
			\State Accept/reject step and update trust region radius: set
			\be \bx_{k+1} = \begin{cases}\bx_k + \bs_k, & r_k \geq \eta_1, \\ \bx_k, & r_k < \eta_1, \end{cases} \quad \text{and} \quad \Delta_{k+1} = \begin{cases}\min(\max(\gamma_{inc}\Delta_k, \overline{\gamma}_{inc}\|\bs_k\|), \Delta_{max}), & r_k \geq \eta_2, \\ \max(\gamma_{dec}\Delta_k, \|\bs_k\|, \rho_k), & \eta_1 \leq r_k < \eta_2, \\ \max(\min(\gamma_{dec}\Delta_k, \|\bs_k\|), \rho_k), & r_k < \eta_1. \end{cases} \ee
			\If{$|Y_k| < p+1$}
				\State \underline{Growing Phase}: Form $Y_{k+1}=Y_k\cup\{\bx_k+\bs_k\}$ and set $\rho_{k+1} = \rho_k$.
			\ElsIf{$r_k \geq \eta_1$}
				\State \underline{Successful Phase}: Form $Y_{k+1}=Y_k\cup\{\bx_{k+1}\}\setminus\{\by\}$ for some $\by\in Y_k$ and set $\rho_{k+1}=\rho_k$.
				\State If objective decrease is too slow: call  restart if \texttt{NOISY}, else \textbf{terminate}.
			\ElsIf{\texttt{NOISY} \textbf{and} \textit{restart auto-detected}}
				\State \underline{Restart Auto-Detection}: Call restart.
			\ElsIf{\textit{geometry of $Y_k$ is not good}}
				\State \underline{Model Improvement Phase}: Improve the geometry of $Y_{k+1}$ and set $\rho_{k+1}=\rho_k$.
			%\Else\:\:[$|Y_k|=p+1$ \textbf{and} $r_k < \eta_1$ \textbf{and} (\textbf{not} \texttt{NOISY} \textbf{or} \textit{restart not auto-detected}) \textbf{and} \textit{geometry of $Y_k$ is good}]
			\Else
				\State \underline{Unsuccessful Phase}: Set $Y_{k+1}=Y_k$, and if $\Delta_{k+1} = \rho_k$, set $(\rho_{k+1}, \Delta_{k+1}) = (\alpha_1\rho_k, \alpha_2\rho_k)$, otherwise set $\rho_{k+1}=\rho_k$. \label{ln_rho_redn}
				\State If $\rho_{k+1}\leq \rho_{end}$: call restart if \texttt{NOISY}, else \textbf{terminate}.
			\EndIf \label{ln_loop_end}
		\EndFor
	\end{algorithmic}
	} % end font size
	\caption{DFO-LS: Derivative-Free Optimization for Least-Squares.}
	\label{alg_dfols}
\end{algorithm}

% \paragraph{DFO-LS Algorithm}
% A full statement of the DFO-LS algorithm is given in \algref{alg_dfols}.
% The overall structure of DFO-LS is very similar to DFO-GN \cite{Cartis2017a}, with the main difference being the ability to use regression models, which allow us the flexibility to have a reduced initialization cost, or implement regression models\footnote{\:This feature is not used by default in DFO-LS; more details are given in \secref{sec_other_noisy_features}.}.
A full statement of the DFO-LS algorithm is given in \algref{alg_dfols}. 
The overall structure of DFO-LS builds upon that of DFO-GN \cite{Cartis2017a}, with a key difference being the ability to use regression models, which allows us the flexibility to have a reduced initialization cost when evaluations are expensive, and to implement regression models when the problem is noisy.
%\footnote{\:Regression models are not used by default in DFO-LS; more details are given in %\secref{sec_other_noisy_features}.}. 
For the latter regime, the most efficient contribution of DFO-LS is the multiple restarts feature described in \secref{sec_restarts_description}. 
Other key features of DFO-LS are described in \secref{sec_implementation_general}, and optional features for noisy problems (such as regression and sampling) are described in \secref{sec_other_noisy_features}.

We note that DFO-LS uses a standard trust region framework, but maintains two different measures of trust region radius: the usual $\Delta_k$ as described in \secref{sec_main_algo}, and a lower bound $\rho_k\leq\Delta_k$.
Originally a feature from Powell \cite{Powell2003}, this is used to ensure that we do not decrease $\Delta_k$ too much until we are confident that the geometry of $Y_k$ is sufficiently good; i.e.~that unsuccessful steps (where $r_k<\eta_1$) are not because of a poor quality model, but because the nature of the objective near $\bx_k$ requires a small trust region in order to make good progress.

A summary of the convergence guarantees of DFO-LS is given in \appref{sec_convergence}.

\section{New Algorithmic Features} \label{sec_implementation}
In this section, we describe  briefly the general features of DFO-LS 
 and, in greater detail, several new features for handling noisy objectives.

\subsection{General Features} \label{sec_implementation_general}
We summarize how some of the steps in \algref{alg_dfols} are performed in practice. 
The majority of these general features are inherited from DFO-GN \cite{Cartis2017a}, but DFO-LS includes variable scaling, two new termination criteria, different default trust region parameters for noisy problems, and a slightly different approach for determining the initial set $Y_0$.
A full outline of these general features is given in \appref{sec_general_features_appendix}.
The most important are:

\begin{description}
	\item[\normalfont\textit{Geometry-Improving Steps:}] Similar to BOBYQA \cite{Powell2009}, geometry-improving steps in DFO-LS do not guarantee the $\Lambda$-poisedness of $Y_k$ (as required for convergence theory; see \appref{sec_convergence}), but instead perform a simplified procedure: take the point furthest from $\bx_k$, and replace it with
	\be \by^+ = \argmax_{\by\in B(\bx_k,\Delta_k)} |\Lambda_t(\by)|, \label{eq_geom_improvement} \ee
	\item[\normalfont\textit{Model Updating:}] Unlike \algref{alg_dfols}, the new point $\bx_k+\bs_k$ is added to the interpolation set at all iterations, so the newest information about the objective is always used;
	\item[\normalfont\textit{Inclusion of Bound Constraints and Variable Scaling:}] Like DFO-GN, DFO-LS can solve \eqref{eq_ls_definition} with optional bound constraints $\b{a} \leq \bx \leq \b{b}$. To improve problem conditioning, users can optionally allow the variables to be internally shifted and scaled to be between $[0,1]$.
	\item[\normalfont\textit{Termination Criteria:}] In addition to the criteria from DFO-GN, in DFO-LS, termination can occur when the rate of objective decrease is slow (similar to the ``$f_i^{*\prime}$ test'' of Larson and Wild \cite{Larson2013}), or if all interpolation values $f(\by_t)$ are within some user-specified noise level of $f(\bx_k)$; and,
	\item[\normalfont\textit{Default Parameters for Noisy Problems:}] DFO-LS allows user to specify, via an input flag, if their objective is noisy. If so, DFO-LS uses different, and more appropriate, default values for $\gamma_{dec}$, $\alpha_1$ and $\alpha_2$ than the noiseless case.
\end{description}

\subsection{Multiple Restarts for Noisy Objectives} \label{sec_restarts_description}
To improve robustness to noisy objectives, DFO-LS uses a multiple restarts mechanism.
%Although this feature is novel in the model-based DFO setting, similar methods have been used in other contexts: performing multiple runs of a local solver is common in global optimization \cite{Locatelli2013}, and multiple restarts are also a common feature of nonlinear conjugate gradient methods \cite[Chapter 5]{Nocedal2006} and GMRES \cite[Chapter 6]{Demmel1997}, and has been proposed to improve the robustness of the Nelder-Mead algorithm \cite{Kelley1999}.
As motivation, note that, in  DFO trust-region methods, $\Delta_k$ tends to zero as a measure of convergence; see for example, \cite[Lemma 3.11]{Cartis2017a} and Theorem \ref{thm_lim} for the deterministic case. However, when the function is noisy, as $\Delta_k$ gets small, 
the interpolation points get very close together and the corresponding objective values are all within noise level.
As a result, $\Delta_k$ no longer reflects convergence and the solver can stagnate in a suboptimal region.
%As a result, differences in (true) objective values between them eventually become dominated by noise, and $\Delta_k$ no longer reflects convergence. Thus the solver can stagnate in a suboptimal region.

\begin{figure}[t]
	\centering
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/restarts_motivation_v2_bugfix/restarts_motivation_failure_obj_redn.eps}
		\includegraphics[width=\textwidth]{img_final/fig_1a.eps}
		\caption{Normalized objective decrease (no restarts)}
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/restarts_motivation_v2_bugfix/restarts_motivation_failure_conv_info.eps}
		\includegraphics[width=\textwidth]{img_final/fig_1b.eps}
		\caption{Convergence details (no restarts)}
	\end{subfigure}
	\\
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/restarts_motivation_v2_bugfix/restarts_motivation_noautodetect_obj_redn.eps}
		\includegraphics[width=\textwidth]{img_final/fig_1c.eps}
		\caption{Normalized objective decrease (with restarts)}
		\label{fig_restarts_motivation_with_restarts_obj_redn}
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/restarts_motivation_v2_bugfix/restarts_motivation_noautodetect_conv_info.eps}
		\includegraphics[width=\textwidth]{img_final/fig_1d.eps}
		\caption{Convergence details (with restarts)}
	\end{subfigure}
	\caption{Normalized objective decrease achieved by DFO-LS, measured in both the noisy and true objective, and convergence information for test problem `Osborne 1' with $(n,m)=(5,33)$ and unbiased multiplicative Gaussian noise of size $\sigma=10^{-2}$. 
	The vertical black lines indicate when restarts occurred. Restart type was `soft (moving $\bx_k$)', and the budget was $300(n+1)$ evaluations;  the (a) and (b) runs terminated early on small trust-region radius.
% 	The `gaps' in $\|J_k-J_{k-1}\|_F$ for (d) correspond to safety steps, where $J_k=J_{k-1}$. 
% 	The difference between the `noisy' and `true' objective reduction measures is discussed in \secref{sec_testing_methodology}.
	}
	\label{fig_restarts_motivation}
\end{figure}

{\it An illustrative example.} We may see this effect by considering a test problem.
In \figref{fig_restarts_motivation}, we compare two runs of DFO-LS --- with and without multiple restarts --- for the Osborne 1 test problem \cite[Problem 36]{More2009}, where we have added unbiased multiplicative Gaussian noise with $\sigma=10^{-2}$.
After making some initial progress, the run without restarts has many unsuccessful steps, and $\Delta_k$ shrinks as the solver attempts to find a descent direction.
When this happens, the interpolated Jacobian $J_k$ begins to change substantially at each iteration.
This indicates that the noise in the interpolation problem is dominating the true descent information.

When we introduce restarts, the stagnation can eventually be overcome. 
% we see the same stagnation occurring --- the objective does not reduce, $\Delta_k$ shrinks, and changes in $J_k$ increase.
When a restart occurs (and we increase $\Delta_k$ to its original level), the changes in $J_k$ reduce quickly, and so the interpolation is more likely to capture genuine information about changes in the objective.
As a result, the solver is able to progress, and ultimately finds a much higher accuracy solution. $\Box$

In DFO-LS, a restart may be triggered by all the termination criteria, except for small objective and maximum computational budget.
At its simplest, a restart involves increasing $\Delta_k$ to a much larger value, and possibly moving some of the points in $Y_k$.
There are two main types of restart which DFO-LS can perform:
\begin{description}
	\item[\normalfont\textit{Hard restart:}] Reset the trust region radius to $\Delta_k=\rho_k=\Delta_0$, and rebuild $Y_k$ in the new (larger) trust region $B(\bx_k,\Delta_k)$ from scratch using the same mechanism as how $Y_0$ was originally constructed in the case $p=n$ (see \secref{sec_implementation_general}); and,
	\item[\normalfont\textit{Soft restart (moving $\bx_k$):}] Reset the trust region radius to $\Delta_k=\rho_k=\Delta_0$, and save the current best point $\bx_k$ separately. Then, move $\bx_k$ to a geometry-improving point in the new trust region $B(\bx_k,\Delta_k)$, shifting the trust region to this new point. Finally, move the $N-1<p$ points in $Y_k$ which were closest to the old value of $\bx_k$ to geometry-improving points in the new (larger \& shifted) trust region $B(\bx_k,\Delta_k)$ as per \eqref{eq_geom_improvement}. The iteration then continues from whichever of these $N$ new points has the least objective value, which may be worse than the value from the end of the previous iteration. The final solution returned by the solver takes the optimal value seen so far, including the saved endpoints from previous restarts.
\end{description}
The soft restart approach with $N=\min(3,p)$ is the default approach in DFO-LS.

We see that soft restarts require the objective to be evaluated $N<p$ times, whereas hard restarts require a full $p$ objective evaluations (as we have changed all interpolation points except $\bx_k$).
We also note that the soft restart mechanism is intrinsically linked to the model-based DFO framework, and there is not a clear derivative-based equivalent of this procedure.

In DFO-LS, when restarts are used, we add an extra termination criterion: we terminate if the last $M$ consecutive restarts have not achieved any objective reduction (default $M=10$).

\paragraph{Auto-detection of restarts} 
As discussed above, we saw in \figref{fig_restarts_motivation} that the need for a restart can be determined by a series of unsuccessful iterations, coupled with large changes in $J_k$, with this change increasing rapidly with $k$.
By contrast, selecting an a priori value of $\rho_{end}$ which provides a timely trigger for restarts is not straightforward.
Thus, DFO-LS uses previous iteration information to auto-detect when a restart is needed.
A restart is triggered if, in the last $N$ iterations:
\begin{itemize}
	\item The trust region radius $\Delta_k$ has never been increased, and it has been decreased on at least twice as many iterations as it has been kept constant; and,
	\item The slope and correlation coefficient of a linear fit through the points $\{(k, \log\|J_k-J_{k-1}\|_F)\}$ exceed given thresholds; that is, $\|J_k-J_{k-1}\|_F$ is consistently increasing at a given exponential rate\footnote{\:This condition is similar to the noise detection mechanism from \cite{Augustin2014}, which we became aware of after the condition had been chosen.}.
\end{itemize}

{\it An illustrative example, revisited.}
In \figref{fig_restarts_autodetect_motivation}, we see the same results as in \figref{fig_restarts_motivation}, but with auto-detection of when to restart.
Because of the auto-detection, restarts are triggered much earlier (avoiding the iterations during which no progress was made), and we achieve accuracy $\tau=10^{-6}$ after approximately $15(n+1)$ evaluations, rather than approximately $80(n+1)$ evaluations without auto-detection. $\Box$

\begin{figure}
	\centering
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/restarts_motivation_v2_bugfix/restarts_motivation_autodetect_obj_redn.eps}
		\includegraphics[width=\textwidth]{img_final/fig_2a.eps}
		\caption{Normalized objective decrease}
		\label{fig_restarts_autodetect_motivation_obj_redn}
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/restarts_motivation_v2_bugfix/restarts_motivation_autodetect_conv_info.eps}
		\includegraphics[width=\textwidth]{img_final/fig_2b.eps}
		\caption{Convergence details}
	\end{subfigure}
	\caption{Normalized objective decrease achieved by DFO-LS, measured in both the noisy and true objective, and convergence information as per \figref{fig_restarts_motivation}, but allowing auto-detection of restarts. The budget was $100(n+1)$ objective evaluations. The difference between the `noisy' and `true' objective reduction measures is discussed in \secref{sec_testing_methodology}.}
	\label{fig_restarts_autodetect_motivation}
\end{figure}

\paragraph{Alternative Restart Mechanism}
DFO-LS has another approach available for performing soft restarts.
\begin{description}
	\item[\normalfont\textit{Soft restart (fixed $\bx_k$):}] Reset the trust region radius to $\Delta_k=\rho_k=\Delta_0$, and move the $N<p$ points $\by_t\neq\bx_k$ in $Y_k$ which are closest to $\bx_k$ to geometry-improving points in the new trust region $B(\bx_k,\Delta_k)$ as per \eqref{eq_geom_improvement}.  
	The iteration then continues from whichever of these $N$ new points has the least objective value.
\end{description}
As we will see in \secref{sec_new_features_results}, the soft restart (fixed $\bx_k$), with the default value $N=\min(3,p)$, performs noticeably worse than the `moving $\bx_k$' version of soft restarts.

\subsection{Optional Features for Noisy Objectives} \label{sec_other_noisy_features}
Aside from multiple restarts, DFO-LS also implements the two most common approaches for handling noisy objectives in model-based DFO: sample averaging and regression models.
In \secref{sec_new_features_results}, we show numerically that using multiple restarts gives better performance than averaging and regression. Therefore, the latter features are not used in DFO-LS by default.

\subsubsection{Sample Averaging} \label{sec_averaging_description}
%Perhaps the most common approach to handling noisy function values for model-based DFO is sample averaging; see for instance \cite{Deng2006,Deng2009,Shashaani2016,Chen2016}.
Sample averaging replaces evaluations of the noisy objective $f(\bx)$  with an average of $N$ samples. In the least-squares
case, we replace an evaluation of the noisy objective $\overline{\br}$ with the sample average
\be \overline{\br}_N(\bx) \defeq \frac{1}{N}\sum_{i=1}^{N}\br(\bx, \xi_i), \ee
where $\xi_1, \ldots, \xi_N$ are different realizations of the random variable $\xi$ defining the noise.
%More precisely, when we have noisy function evaluations, we have access to $\t{f}(\bx) = f(\bx, \xi)$, where $\xi$ is a random variable defined on some probability space defining the noise.
%Under this setting, the goal of the optimization is to minimize the expected value of the objective; i.e.~solve $\min_{\bx}f(\bx)\defeq \mathbb{E}_{\xi}[f(\bx, \xi)]$.
%In the least-squares setting, we have access to the noisy evaluations $\t{\br}(\bx) = \br(\bx, \xi)$, and wish to minimize $f(\bx)\defeq \|\mathbb{E}_{\xi}[\br(\bx, \xi)]\|^2$.
%Given this, we replace evaluation of the noisy objective $\t{\br}$ with the sample average
%\be \t{\br}_N(\bx) \defeq \frac{1}{N}\sum_{i=1}^{N}\br(\bx, \xi_i), \ee
%where $\xi_1, \ldots, \xi_N$ are different realizations of $\xi$.

For theoretical convergence guarantees to hold, one must choose $N=\bigO(\Delta_k^{-4})$ (e.g.~\cite{Chen2016}).
However, as $\Delta_k$ can easily be of size $10^{-2}$ or $10^{-3}$, this amount of averaging rapidly becomes impractical, so $N=\bigO(\Delta_k^{-1})$, for instance, is a more sensible choice in practice (e.g.~Algorithm TR-SAA in \cite{Chen2016}).
% In our implementation, DFO-LS can take an arbitrary function which returns the number of samples to use as a function of $\Delta_k$, in practice we test with $N=\text{constant}$.

In the implementation of DFO-LS, the use of sample averaging is governed by a user-specified function which allows for a wide range of sample averaging techniques:
\be N = \mathrm{nsamples}(\rho_k, \Delta_k, k, n_{\mathrm{restarts}}), \label{eq_nsamples} \ee
where $n_{\mathrm{restarts}}\in\{0,1,2,\ldots\}$ is the number of restarts that the solver has performed (see \secref{sec_restarts_description} for details) and $k\in\{0,1,2,\ldots\}$ is the iteration number since the most recent restart.
The default option for $\mathrm{nsamples}$ gives $N\equiv 1$ always; i.e.~no sample averaging.

\subsubsection{Regression Models for Noisy Objectives}

%Another principal approach for handling noisy problems in model-based DFO is to 
Building regression models rather than interpolation models requires having more interpolation points than degrees of freedom in the model \cite{Conn2008,Billups2013,Chen2016}. 
Our formulation of the DFO-LS model construction problem \eqref{eq_interp_conditions} allows regression models, 
when $p>n$. It remains to consider 
how to evolve the set $Y_k$ at each iteration.

%Suppose we have $|Y_k|=c(n+1)$ for some $c\in\{2,3,4,\ldots\}$.
%At each successful iteration, following \algref{alg_dfols}, we move one point in $Y_k$ to the new value %$\bx_{k+1}=\bx_k+\bs_k$.
%However, if we were using sample averaging with $c$ samples per point --- so the full interpolation set $Y_k$ also required %$c(n+1)$ objective evaluations --- moving one point in $Y_k$ corresponds to $c$ new objective evaluations.
%To match this with regression models, we would have to update $Y_k$ with $\bx_{k+1}$, and move $(c-1)$ other points.

DFO-LS has three mechanisms for moving multiple points on successful iterations, which can be used alongside regression models:
\begin{description}
	\item[\normalfont\textit{Nothing:}] Replace one point in $Y_k$ with $\bx_{k+1}$, and nothing else;
	\item[\normalfont\textit{Geometry-based:}] Replace one point in $Y_k$ with $\bx_{k+1}$, and then move the $N$ points in $Y_k$ which are furthest from $Y_{k+1}$ to geometry-improving locations in $B(\bx_{k+1},\Delta_{k+1})$, given by \eqref{eq_geom_improvement}; and
	\item[\normalfont\textit{Momentum-based:}] Replace one point in $Y_k$ with $\bx_{k+1}$, and then move the $N$ points in $Y_k$ which are furthest from $Y_{k+1}$ to $\bx_{k+1}+\Delta_{k+1}\b{d}$, where $\b{d}$ is a random unit vector with\footnote{\:When using bound constraints, if $\Delta_{k+1}\b{d}$ gives a point outside the bounds, we instead take $\alpha\b{d}$ for some $\alpha\in(0,\Delta_{k+1})$ such that the bounds are satisfied. If this requires $\alpha<10^{-3}$, we replace $\b{d}$ with $-\b{d}$, sacrificing the requirement that $\b{d}^{\top}\bs_k>0$.} $\b{d}^{\top}\bs_k>0$.
\end{description}
The last two mechanisms above, that replace multiple points,
 try to mimic/match the situation arising in sample averaging, where moving one point affects $c$ function values, where $c$ is the sampling rate.

The first mechanism (`nothing') is the default in DFO-LS, when regression models are used; they are compared with each other, and against sample averaging, in \secref{sec_regression_results}.

% \subsection{Default Settings for DFO-LS} \label{sec_default_settings}
% As we have seen, each of the new features in DFO-LS have several variants, each of which is available through the right choice of user settings.
% We also presented three methods for improving robustness to noise --- sample averaging, regression and multiple restarts.
% In both of these cases, we must select sensible default settings.
% 
% In \secref{sec_new_features_results}, we show the results of several studies where we compare these different features and their relative performance.
% Based on these results, the default settings in DFO-LS are to use, first in the case of noiseless objectives:
% \begin{itemize}
% 	\item Initialize with a full set of $p+1$ points --- this is because the default for DFO-LS should work for most typical use cases, which do not generally fall in the `expensive' regime; and
% 	\item No sample averaging, regression (i.e.~$p=n$) or restarts.
% \end{itemize}
% In the case of noisy objectives --- recall from \secref{sec_implementation_general} that there is an input flag to indicate a noisy problem --- the defaults are:
% \begin{itemize}
% 	\item Initialize with a full set of $p+1$ points --- this is because the default for DFO-LS should work for most typical use cases, which do not generally fall in the `expensive' regime;
% 	\item No sample averaging or regression (i.e.~$p=n$); and,
% 	\item Multiple restarts using the `soft (move $\bx_k$)' methodology, where we move $\min(3,p)$ points (including $\bx_k$) at every iteration.
% \end{itemize}
% If the user asks for an initialization with fewer than $n+1$ points, the default mechanism is to make $J_k$ full rank via an SVD calculation, and while growing to use a simplified safety step (add a new direction instead of improving geometry) and no model-improving steps.

\section{Testing Framework} \label{sec_testing_framework}


We outline the framework we used for testing and comparing DFO-LS to other solvers, which is similar to  Mor\'e and Wild \cite{More2009} and to \cite{Cartis2017a}, but designed to capture the two regimes of interest - expensive and/or noisy. We also introduce a new approach for measuring solver performance for noisy problems.



\subsection{Testing Methodology} \label{sec_testing_methodology}
When running each solver, we choose the maximum allowed budget in units of simplex gradients (i.e.~in multiples of $n+1$) to provide fair comparisons across problems of different dimensions.
The measure of solver performance  is the number of evaluations required to achieve a specified reduction in the objective. 
%We propose to use an adaptive accuracy level for measuring objective reduction for noisy problems, so that both the noisy and the underlying true objective behaviour can be captured reliably.


Suppose we have an underlying smooth objective $f$, but only see evaluations of the noisy objective $\t{f}\approx f$, where 
%\be f(\bx) \defeq \sum_{i=1}^{m}r_i(\bx)^2, \qquad \text{and} \qquad \t{f}(\bx) \defeq \sum_{i=1}^{m}\t{r}_i(\bx)^2. %\label{eq_noisy_f_defn} \ee
\be \t{f}(\bx) \defeq \alpha f(\bx) + \beta + \sigma(\bx)\epsilon, \label{eq_noise_model_assumption} \ee
for constants $\alpha>0$ and $\beta\in\R$, and where $\sigma(\bx)$ is the standard deviation of the noise.
The stochastic noise $\epsilon$ has zero mean and unit variance, and so $|\epsilon|\sim\bigO(1)$.
Under this assumption --- which holds for all the noise models we consider in \secref{sec_test_problems} --- minimizing $\mathbb{E}[\t{f}(\bx)]$ yields a minimizer of the true objective $f$.
Then, for a solver $\mathcal{S}$, problem $p$, and accuracy level $\tau\in(0,1)$, we define the number of evaluations required to solve the (smooth or noisy) problem as:
\begin{align}
	\left\{\begin{array}{c}N_p(\mathcal{S}; \tau) \\ \t{N}_p(\mathcal{S}; \tau)\end{array}\right\} &\defeq \text{\# objective evaluations taken to find a point $\bx$ satisfying} \nonumber \\
	&\qquad \left\{\begin{array}{rcl} f(\bx) &\leq & f(\bx^*) + \tau(f(\bx_0) - f(\bx^*))] \\ \t{f}(\bx) &\leq & \mathbb{E}[\t{f}(\bx^*) + \tau(\t{f}(\bx_0) - \t{f}(\bx^*))] \end{array}\right\}, \label{eq_solved_threshold}
\end{align}
where $\bx^*$ is an estimate of the true minimizer of the smooth objective $f$\footnote{For our two sets of test problems (Mor\'e \& Wild and CUTEst), values of $f(\bx^*)$ are given in \cite{Cartis2017a}.}.
If the required reduction \eqref{eq_solved_threshold} was never achieved in the maximum allowed budget, we define $N_p(\mathcal{S}; \tau)$ or $\t{N}_p(\mathcal{S}; \tau)=\infty$.

Following \cite{More2009}, we compare different solvers using data profiles.
These measure the proportion of test problems for which the required budget $N_p(\mathcal{S}; \tau)$ or $\t{N}_p(\mathcal{S}; \tau)$ is less than a given value (in units of simplex gradients), namely $\alpha(n_p+1)$, where $n_p$ is the dimension of problem $p$.
The data profiles are defined, for the solver $\mathcal{S}$ and set of test problems $\mathcal{P}$, to be the curves
\be \left\{\begin{array}{c} d_{\mathcal{S}}(\alpha) \\ \t{d}_{\mathcal{S}}(\alpha) \end{array}\right\} \defeq \frac{1}{|\mathcal{P}|} \cdot \left|\left\{p\in\mathcal{P} :  \left\{\begin{array}{c} N_p(\mathcal{S}; \tau_p) \\ \t{N}_p(\mathcal{S}; \tau_p)\end{array}\right\} \leq \alpha(n_p+1)\right\}\right|, \qquad \alpha\geq0, \label{eq_data_profile} \ee
where $n_p$ is the dimension of problem $p$. $N_p(\mathcal{S};\tau)$ measures genuine progress towards the minimizer, excluding any objective reductions from sampling errors, but $\t{N}_p(\mathcal{S};\tau)$ measures progress using information actually available to the solver. The two different performance measures \eqref{eq_solved_threshold} have each been used previously (e.g.~$N_p(\mathcal{S};\tau)$  in \cite{Chen2016} and  $\t{N}_p(\mathcal{S};\tau)$, in \cite{Billups2013}), but we are not aware of work where the two measures have been compared and combined. We propose to do so, in the accuracy level we choose.

We use throughout
a problem-specific accuracy level $\tau_p$ rather than a constant value for all problems, which we set based on the accuracy which is reasonable for a solver to attain given the noise level in the problem. By adapting $\tau_p$ to each problem, we can measure progress using $\t{N}_p$ but gain the benefit of $N_p$, thus capturing genuine progress in the objective.



% When showing results for noisy objectives, we will refer to profiles based on $N_p(\mathcal{S}; \tau)$ as being for `true $f$', and profiles based on $\t{N}_p(\mathcal{S}; \tau)$ as being for `noisy $\t{f}$'.
% For noiseless objectives, these measures are the same, so we make no such distinction.

%The two different performance measures \eqref{eq_solved_threshold} have each been used previously (e.g.~$N_p(\mathcal{S};%\tau)$ in \cite{Chen2016} and the $\t{N}_p(\mathcal{S};\tau)$, in \cite{Billups2013}), but we are not aware of work where the two measures have been compared. 
%There are advantages to each: $N_p(\mathcal{S};\tau)$ measures genuine progress towards the minimizer, excluding any %objective reductions from sampling errors, but $\t{N}_p(\mathcal{S};\tau)$ measures progress using information actually available to the solver.
%However, by adapting $\tau$ to each problem, we can measure progress using $\t{N}_p$ but gain the benefit of $N_p$, thus capturing genuine progress in the objective.

% We may think of the `noisy $\t{f}$' measure as being more `optimistic', as it allows some of the required reduction \eqref{eq_solved_threshold} to be achieved by a `lucky' realization of random noise in the evaluation of $\t{f}$.
% By contrast, the `true $f$' measure is more pessimistic, and measures the genuine progress in the true objective, but is measured using information not available to the solver (i.e.~the true underlying objective).
% In our testing, more problems are solved (for a given budget) in the `noisy $\t{f}$' measure than the `true $f$' measure; this difference can be explained by the choice of threshold $\tau$ for a given problem and noise model. %\appref{sec_performance_measures}

Note that throughout, for noisy problems, we performed 10 runs of each solver and below we always show average data profiles.
We also show average profiles over 10 runs for DFO-LS and Py-BOBYQA in the case of noiseless objectives, because the generation of the initial set $Y_0$ uses random orthogonal directions.

\paragraph{Choice of adaptive accuracy level $\tau_p$}
Given \eqref{eq_solved_threshold}, we would expect the two measures $N_p$ and $\t{N}_p$ to be similar, provided that our desired objective reduction was much larger than the noise level.
If $N_p$ and $\t{N}_p$ were similar, we could conclude that reductions in the observable $\t{f}$ correspond to genuine objective reductions, and not sampling error.
Specifically, suppose a solver has reached a point $\bx_k$, which corresponds to an accuracy of (exactly) $\tau$ based on $N_p$ and of $\t{\tau}$ based on $\t{N}_p$, 
\be f(\bx_k) = f(\bx^*) + \tau(f(\bx_0)-f(\bx^*)) \quad \text{and} \quad \t{f}(\bx_k) = \mathbb{E}[\t{f}(\bx^*) + \t{\tau}(\t{f}(\bx_0)-\t{f}(\bx^*))].\label{temp:ex-noise} \ee
Letting $\epsilon_k$ be the realization of $\epsilon$ for the given $\t{f}(\bx_k)$, we combine the expressions in \eqref{temp:ex-noise} using \eqref{eq_noise_model_assumption}, to get
% \be \t{\tau} = \tau + \frac{\sigma(\bx_k)}{\alpha(f(\bx_0)-f(\bx^*))}\epsilon_k = \tau + \frac{\sigma(\bx_k)}{\mathbb{E}\left[\t{f}(\bx_0)-\t{f}(\bx^*)\right]}\epsilon_k. \ee
\be \underbrace{\t{\tau}}_{\text{noisy progress}} = \underbrace{\tau}_{\text{true progress}} + \underbrace{\frac{\sigma(\bx_k)}{\mathbb{E}\left[\t{f}(\bx_0)-\t{f}(\bx^*)\right]}\epsilon_k}_{\text{sampling error}}. \ee
Since $|\epsilon_k|\sim\bigO(1)$, we can expect $\t{\tau}$ and $\tau$ to be similar in size whenever
\be \tau \: \text{and/or} \:\t{\tau} \:\gg\: \frac{\sigma(\bx_k)}{\mathbb{E}\left[\t{f}(\bx_0)-\t{f}(\bx^*)\right]}. \label{eq_tau_thresh} \ee
Effectively, \eqref{eq_tau_thresh} provides a limit on the accuracy we can reasonably expect a solver to achieve, given the noise level in a particular problem.
In our numerical results, we approximate \eqref{eq_tau_thresh} in a way that is independent of $\bx_k$, and say that the best accuracy we can expect a solver to achieve is $\tau_{crit}(p)$, where
\be  \tau_{crit}(p) \defeq 10^{\lceil \log_{10}\widehat{\tau}(p)\rceil}, \qquad \text{where} \qquad \widehat{\tau}(p) \defeq \frac{\sigma(\bx^*)}{\mathbb{E}\left[\t{f}(\bx_0)-\t{f}(\bx^*)\right]}. \label{eq_tau_thresh_used} \ee
%That is, we calculate $\widehat{\tau}(p)$ and round up to the next largest integer power of 10.

Finally, to construct our data profiles, we choose a desired level of accuracy $\tau$, usually $10^{-5}$, and set our problem-specific tolerance to be either $\tau$ if we can expect the solver to reach this accuracy, otherwise we choose $\tau_{crit}(p)$. Thus, in our data profiles \eqref{eq_data_profile}, we use the problem-specific accuracy level
\be \tau_p \defeq \min(\tau_{max}, \max(\tau_{crit}(p), \tau)), \label{eq_tau_modification} \ee
where $\tau_{max}\defeq 10^{-1}$ is an upper bound on $\tau_p$.
We note that for noiseless problems we have $\tau_{crit}(p)=0$, so $\tau_p=\tau$ is problem-independent.

% As shown in \appref{sec_performance_measures}, for a given problem $p$, there is a lower threshold $\tau_{crit}(p)$, given by \eqref{eq_tau_thresh_used}, below which progress in the `noisy $\t{f}$' measure is likely to be driven by sampling error in $\t{f}$ instead of genuine progress towards the minimizer.

% For the data profiles below, we usually use accuracy level $\tau=10^{-5}$.
% However, if we restricted the test set (MW) to the problems $\{p : \tau_{crit}(p) \leq \tau\}$, we would go from 53 problems to 30--39 problems (depending on the noise model).
% We would prefer to construct our data profiles using the full set of problems, for two main reasons.
% Firstly, the specific choice $\tau_{crit}(p)$ is only approximate, and does not provide a `definitive' cutoff point.
% Secondly, applying a restriction based on $\tau_{crit}(p)$ would mean using mostly problems where $f(\bx_0)$ is many orders of magnitude larger than $f(\bx^*)$, and so achieving a particular accuracy level $\tau$ is likely to be easier; we would prefer to include problems where this is not the case.
% To this end, when producing a data profile based on accuracy level $\tau$, for a given problem $p$, we either use $\tau$, or increase it to a more appropriate value given $\tau_{crit}(p)$:
% \be \tau_p \defeq \min(\tau_{max}, \max(\tau_{crit}(p), \tau)), \label{eq_tau_modification} \ee
% where $\tau_{max}=10^{-1}$ is an upper bound on $\tau_p$.
% The data profile we use for the solver $\mathcal{S}$ and set of test problems $\mathcal{P}$ is the curve
% \be d_{\mathcal{S}}(\alpha) \defeq \frac{|\{p\in\mathcal{P} : N_p(\mathcal{S}; \tau_p) \leq \alpha(n_p+1)\}|}{|\mathcal{P}|}, \qquad \alpha\geq0, \ee
% for plots with the `smooth $f$' measure, and using $\t{N}_p(\mathcal{S}; \tau_p)$ for the `noisy $\t{f}$' measure.
% For noisy problems, we performed 10 runs of each solver and below we always show average data profiles.
% For performance profiles, the budget normalization is taken as the minimum budget needed by any run of any solver.
% We also show average profiles over 10 runs for DFO-LS and Py-BOBYQA in the case of noiseless objectives, because the generation of the initial set $Y_0$ uses random orthogonal directions.

\paragraph{Impact of $\tau_p$}
We now illustrate that using the per-problem accuracy level $\tau_p$ for measuring noisy progress $\t{N}_p$ allows us to compare performance based on genuine objective decreases, not sampling errors.
We do this by verifying that the performance measures $N_p$ and $\t{N}_p$, and data profiles $d_{\mathcal{S}}$ and $\t{d}_{\mathcal{S}}$, give similar results.

First, we consider the problem and noise model used in Figures~\ref{fig_restarts_motivation} and \ref{fig_restarts_autodetect_motivation}, where $\tau_{crit}(p)=10^{-7}$.
% Here, we compute $\widehat{\tau}(p)\approx 2.9\times 10^{-8}$ in \eqref{eq_tau_thresh_used}, so $\tau_{crit}(p)=10^{-7}$ in \eqref{eq_tau_modification}.
In two runs\footnote{\:Although the same random seed was used in both runs for reproducibility, since they have a different sequence of restarts, the set of iterates is ultimately different.} of the same problem, shown in Figures~\ref{fig_restarts_motivation_with_restarts_obj_redn} and \ref{fig_restarts_autodetect_motivation_obj_redn}, we see that the decreases achieved under both measures are essentially identical until they reach accuracy level very close to $\tau_{crit}(p)$.

\begin{figure}
	\centering
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/dfols_comparison_bugfix/dfols_basic_with_restarts_bugfix_nf_addgsn2_noise2_from_noisy_evals_all_probs_tau_fixed_data5.eps}
		\includegraphics[width=\textwidth]{img_final/fig_3a.eps}
		\caption{Constant $\tau_p$, noisy $\t{d}_{\mathcal{S}}$ data profile}
		\label{fig_threshold_demonstration_tau_fixed_noisyf}
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/dfols_comparison_bugfix/dfols_basic_with_restarts_bugfix_nf_addgsn2_noise2_from_smooth_evals_all_probs_tau_fixed_data5.eps}
		\includegraphics[width=\textwidth]{img_final/fig_3b.eps}
		\caption{Constant $\tau_p$, true $d_{\mathcal{S}}$ data profile}
		\label{fig_threshold_demonstration_tao_fixed_truef}
	\end{subfigure}
	\\
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/dfols_comparison_bugfix/dfols_basic_with_restarts_bugfix_nf_addgsn2_noise2_from_noisy_evals_all_probs_tau_prob_adj_data5.eps}
		\includegraphics[width=\textwidth]{img_final/fig_3c.eps}
		\caption{Per-problem $\tau_p$, noisy $\t{d}_{\mathcal{S}}$ data profile}
		\label{fig_threshold_demonstration_tao_prob_adj_noisyf}
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/dfols_comparison_bugfix/dfols_basic_with_restarts_bugfix_nf_addgsn2_noise2_from_smooth_evals_all_probs_tau_prob_adj_data5.eps}
		\includegraphics[width=\textwidth]{img_final/fig_3d.eps}
		\caption{Per-problem $\tau_p$, true $d_{\mathcal{S}}$ data profile}
		\label{fig_threshold_demonstration_tau_prob_adj_truef}
	\end{subfigure}
	\caption{A comparison of the results in \figref{fig_basic_noise2} with additive Gaussian noise, using the data profiles $d_{\mathcal{S}}$ and $\t{d}_{\mathcal{S}}$ \eqref{eq_data_profile}, and either choosing $\tau_p=10^{-5}$ for all problems, or applying the per-problem threshold \eqref{eq_tau_modification}.}
	\label{fig_threshold_demonstration}
\end{figure}

Next, in \figref{fig_threshold_demonstration}, we show a set of data profiles which we will discuss\footnote{\:This figure compares DFO-LS to other solvers for objectives with additive Gaussian noise; see \figref{fig_basic_noise2_addgsn_noisyf}. The same conclusions may be drawn by using the other plots in this paper.} in \secref{sec_dfols_benchmarking}, but we compare the same solvers using both the `noisy $\t{f}$' and `true $f$' measures of objective reduction, and consider either a fixed $\tau=10^{-5}$ for all problems, or using the per-problem value $\tau_p$ \eqref{eq_tau_modification}. 
We see that when a constant value of $\tau_p$ is used, the two data profiles look very different, with the noisy $\t{d}_{\mathcal{S}}$ profile showing more problems solved than the true $d_{\mathcal{S}}$ profile.
When we switch to the per-problem threshold \eqref{eq_tau_modification}, the two profiles look much more consistent both in shape and magnitude.
Most importantly, conclusions about relative solver performance in both low-budget and long-budget regimes based on the $\t{d}_{\mathcal{S}}$ profile would be consistent with those based on the true $d_{\mathcal{S}}$ measure.

Thus, for the remainder of the paper, we present our numerical results  using the problem-adjusted $\tau_p$ with the noisy data profile $\t{d}_{\mathcal{S}}$ (e.g.~\figref{fig_threshold_demonstration_tao_prob_adj_noisyf}).
%As a result of this testing, we conclude that this approach captures solver performance corresponding to genuine objective reductions, while having the benefit of being based on information known to the solver during its run.

% As a result of this testing, we conclude that using a threshold adjusted on a per-problem (and per-noise model) basis is a sensible approach where the measured performance of a solver (in the `noisy $\t{f}$' measure, based on information available to the solver) provides a good indicator of genuine progress towards the objective, and not objective reductions from sampling errors.
% For the remainder of the paper, we show all results using the `noisy $\t{f}$' measure and per-problem thresholds $\tau_p$ (usually with $\tau=10^{-5}$). 
% As a reference, \figref{fig_basic_noise2_addgsn_noisyf} in the main text corresponds to \figref{fig_threshold_demonstration_tao_prob_adj_noisyf} here.

\subsection{Test Problems and Solver Settings} \label{sec_test_problems}
We test DFO-LS on the two collections used in \cite{Cartis2017a}:
\begin{description}
	\item[\rm \textit{(MW)}] The set of 53 nonlinear least-squares from Mor\'e and Wild \cite{More2009}. The problems are low-dimensional, with $2 \leq n \leq 12$ and $n \leq m \leq 65$, so this collection is used as the main test set for the `noisy' regime (see noise models below);
	\item[\rm \textit{(CR)}] The set of 60 nonlinear least-squares from \cite{Cartis2017a}, available via the CUTEst package \cite{Gould2015}. The problems are medium-sized, with $25 \leq n \leq 120$ and $n\leq m \leq 400$, so this collection is used as the main test set for the `expensive' regime.
\end{description}
Full details of both collections may be found in \cite{Cartis2017a}.

\paragraph{Noise Models}
For results robustness, we allow the evaluation of $\br(\bx)$ to include several types of stochastic noise.
%so we can be confident our conclusions are robust to the specific noise type of the user.
In the following sections, we show results for the following noise models, where $\t{f}(\bx)=\sum_{i=1}^m \t{r}_i(\bx)^2$, 
%\eqref{eq_noisy_f_defn}:
\begin{itemize}
	\item Smooth (noiseless) evaluations: $\t{r}_i(\bx) = r_i(\bx)$;
	\item Multiplicative Gaussian noise: $\t{r}_i(\bx) = (1+\epsilon)r_i(\bx)$, where $\epsilon\sim N(0,\sigma^2)$;
	\item Additive Gaussian noise: $\t{r}_i(\bx) = r_i(\bx) + \epsilon$, where $\epsilon\sim N(0,\sigma^2)$; and
	\item Additive $\chi^2$ noise: $\t{r}_i(\bx) = \sqrt{r_i(\bx)^2 + \epsilon^2}$, where $\epsilon\sim N(0,\sigma^2)$.
\end{itemize}
In each case, $\epsilon$ is drawn i.i.d.~for each $\bx$ and each $i=1,\ldots,m$; and  $\sigma=10^{-2}$.
For noisy problems, our goal is to minimize $\t{f}(\bx)$ in expectation --- note that $\mathbb{E}[\t{f}(\bx)]$ is an affine transformation of $f(\bx)$ for these noise models, so they have the same minimizer(s).

\paragraph{Solver Settings}
In the below, we compare DFO-LS v1.0.1 against DFO-GN v0.2 \cite{Cartis2017a} and DFBOLS \cite{Zhang2010}.
For DFBOLS, we show results using with $2n+1$ and $(n+1)(n+2)/2$ interpolation points.
% All Python codes, including DFO-LS, were run using Python 3.5.2 with NumPy 1.12.1 and SciPy 0.19.0. 
For all solvers, we choose trust region settings $\Delta_0=0.1\max(\|\bx_0\|_{\infty}, 1)$ and $\rho_{end}=10^{-8}$, and the default values for all other parameters (unless otherwise specified).

We used a maximum budget of $10^4 (n+1)$ evaluations for the Mor\'e and Wild problems (MW).
Particularly for noisy problems, we are interested in a regime where objective evaluations are cheap, and we are concerned with the robustness of each solver --- how many problems can it solve, if budget were not an issue.
Since this budget is much larger than is often used for testing (e.g.~\cite{Zhang2010,Cartis2017a}), we show data profiles with a log-scale for budget, so we can easily compare solvers both for large budgets (to check robustness) and for realistically small budgets.
For the CUTEst problems (CR), we used a much smaller budget of $50(n+1)$ evaluations, to represent the other regime, where objectives are expensive to evaluate.

\section{Numerical Studies of New DFO-LS Features} \label{sec_new_features_results}
We test the new  features of DFO-LS 
and showcase the successful ones which are chosen as defaults, with the remaining features available as options.
\secref{sec_dfols_benchmarking} then compares DFO-LS with its default settings against state-of-the-art  DFO least-squares solvers.


\subsection{Reduced Initialization Cost} \label{sec_growing_testing}
In \figref{fig_growing_smooth}, we consider the CUTEst problems (CR) with noiseless evaluations.
We compare the basic implementation of DFO-LS against DFO-LS with a reduced initialization cost of 2, $n/4$ and $n/2$ function evaluations (growing the direction space via both mechanisms described in \secref{sec_regression_models} above: modifying $J_k$ using its SVD, and perturbing the trust region step). 
Using our small budget of $50(n+1)$ evaluations, we show data profiles in two settings: for a small budget ($5(n+1)$ evaluations) with low accuracy $\tau=10^{-1}$, and the full budget with high accuracy $\tau=10^{-5}$.

In the short budget, low accuracy plots, we see the benefit of a reduced initialization cost --- we are able to solve a notable fraction of the problems to low accuracy with very few evaluations; less than the number required to perform a single gradient evaluation.
We also see the tradeoff of this benefit, which is a lower performance at small budgets (1--3 gradients).
The long budget, high accuracy plots show that, although the reduced initialization cost suffers a performance loss relative to the basic DFO-LS implementation for small budgets, this does not translate into a loss of performance for longer budgets; the robustness of DFO-LS is maintained even with this very small initialization cost.
The difference between initializing with 2, $n/4$ and $n/2$ points is not substantial.
Comparing the two mechanisms for increasing the model dimensionality, we find that the SVD approach performs similarly to the perturbed trust region approach for small budgets, but better matches DFO-LS with a full initialization set.

\begin{figure}
	\centering
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/dfols_cutest_bugfix/growing_init_1_bugfix_budget5_nf_smooth_data1.eps}
		\includegraphics[width=\textwidth]{img_final/fig_4a.eps}
		\caption{Short budget, 2 starting points, $\tau=10^{-1}$}
		\label{fig_growing_smooth_easy}
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/dfols_cutest_bugfix/growing_init_1_bugfix_budget50_nf_smooth_data5.eps}
		\includegraphics[width=\textwidth]{img_final/fig_4b.eps}
		\caption{Long budget, 2 starting points, $\tau=10^{-5}$}
		\label{fig_growing_smooth_hard}
	\end{subfigure}
	\\
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/dfols_cutest_bugfix/growing_init_qtrn_bugfix_budget5_nf_smooth_data1.eps}
		\includegraphics[width=\textwidth]{img_final/fig_4c.eps}
		\caption{Short budget, $n/4$ starting points, $\tau=10^{-1}$}
		\label{fig_growing_qtrn_smooth_easy}
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/dfols_cutest_bugfix/growing_init_qtrn_bugfix_budget50_nf_smooth_data5.eps}
		\includegraphics[width=\textwidth]{img_final/fig_4d.eps}
		\caption{Long budget, $n/4$ starting points, $\tau=10^{-5}$}
		\label{fig_growing_qtrn_smooth_hard}
	\end{subfigure}
	\\
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/dfols_cutest_bugfix/growing_init_halfn_bugfix_budget5_nf_smooth_data1.eps}
		\includegraphics[width=\textwidth]{img_final/fig_4e.eps}
		\caption{Short budget, $n/2$ starting points, $\tau=10^{-1}$}
		\label{fig_growing_halfn_smooth_easy}
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/dfols_cutest_bugfix/growing_init_halfn_bugfix_budget50_nf_smooth_data5.eps}
		\includegraphics[width=\textwidth]{img_final/fig_4f.eps}
		\caption{Long budget, $n/2$ starting points, $\tau=10^{-5}$}
		\label{fig_growing_halfn_smooth_hard}
	\end{subfigure}
	\caption{Data profiles showing the impact of the reduced initialization cost of DFO-LS (using $n+1$ interpolation points) against using the full initial set, for smooth objectives. Results an average of 10 runs in each case. The problem collection is (CR).}
	\label{fig_growing_smooth}
\end{figure}

\subsection{Sample Averaging} \label{sec_averaging}
To demonstrate the impact of using sample averaging, \figref{fig_avg_noise2} shows data profiles
 with averaging strategies $N\in\{1, 2, 5, 10, 30, \max(1,\lfloor\Delta_k^{-1}\rfloor)\}$.
Each of the $N$ samples for a given $\bx_k$ are counted towards the maximum computational budget of $10^4 (n+1)$ values.
% However, as sample averaging can be easily parallelized, we present results where the budget is measured in serial (i.e.~averaging $N$ samples counts as $N$ objective evaluations) and in parallel (where averaging $N$ samples for a single point counts as 1 objective evaluation).

Unsurprisingly, we see that using a larger number of samples can improve the robustness of DFO-LS.
Of course, to achieve this robustness, a proportionally larger number of evaluations are required, so for small-to-medium budgets (in serial) we lose in performance.
This does not take into account the benefits of parallelization that may be available when sample averaging is used. 
We also notice that using $N=\bigO(\Delta_k^{-1})$ can provide a compromise --- it still makes progress for small budgets, but manages to achieve a reasonable level of robustness overall.

\begin{figure}[t]
	\centering
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/dfols_avg_bugfix/dfols_avg_bugfix_nf_ubgsn_noise2_from_noisy_evals_all_probs_tau_prob_adj_data5.eps}
		\includegraphics[width=\textwidth]{img_final/fig_5a.eps}
		\caption{Multiplicative Gaussian noise}
		\label{fig_avg_noise2_ubgsn_noisyf}
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/dfols_avg_bugfix/dfols_avg_bugfix_nf_addgsn2_noise2_from_noisy_evals_all_probs_tau_prob_adj_data5.eps}
		\includegraphics[width=\textwidth]{img_final/fig_5b.eps}
		\caption{Additive Gaussian noise}
		\label{fig_avg_noise2_addgsn_noisyf}
	\end{subfigure}
	\\
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/dfols_avg_bugfix/dfols_avg_bugfix_nf_addgsn_noise2_from_noisy_evals_all_probs_tau_prob_adj_data5.eps}
		\includegraphics[width=\textwidth]{img_final/fig_5c.eps}
		\caption{Additive $\chi^2$ noise}
		\label{fig_avg_noise2_addchisq_noisyf}
	\end{subfigure}
	\caption{Comparison of different sample averaging methods for DFO-LS (using $n+1$ interpolation points). We are using noisy objective evaluations with $\sigma=10^{-2}$, high accuracy $\tau=10^{-5}$, and an average of 10 runs for each solver. The problem collection is (MW).}
	\label{fig_avg_noise2}
\end{figure}

\subsection{Regression Models} \label{sec_regression_results}
In practice, we find that the geometry-based moves perform similarly to or slightly better than momentum-based ones, so we do not show results for the latter mechanism. \figref{fig_regression_noise2} compares the remaining two techniques
 with varying numbers of regression points ($|Y_k|=c(n+1)$ for $c\in\{5,30\}$) against interpolation models ($|Y_k|=n+1$).
We see that using a larger sample set improves the robustness of DFO-LS, particularly for additive Gaussian noise, and this improvement (for $|Y_k|=c(n+1)$) is generally comparable to, or slightly worse than, the use of sample averaging (with $c$ samples at each point).
The geometry-based mechanism for moving multiple points makes the algorithm progress more slowly, as indicated by the performance profiles, while at times providing a slight improvement over the `basic' approach (moving one point per iteration).

%%We give a short argument that regression may be expected to give slightly worse robustness than sample averaging when %%considering large computational budgets in \appref{sec_regression_v_avg}.
In \appref{sec_regression_v_avg}, we argue, briefly and in a simplified framework, that regression and sample averaging generate similar model error;
thus, since sample averaging produces a better estimate of objective decrease 
for fixed noise level, we expect that overall, regression will be slightly less robust compared to sample averaging when
considering large computational budgets.  


%There are two places in \algref{alg_dfols} where noise in objective evaluations can have an impact: the construction of the %model \eqref{eq_linear_models}, and the measurement of objective decrease \eqref{eq_tr_ratio}. 
%We show below that the errors in model construction due to noise are likely comparable when using either sample averaging %or regression.
%However, for a fixed level of noise, sample averaging will produce a better estimate of objective decrease (compare %\cite[Lemma 9.1]{Nocedal2006}, for instance).
%Thus, overall, we would expect sample averaging to perform somewhat better than regression, when considering overall %robustness. 
%Since sample averaging may use more objective evaluations per iteration, this may not be the case when the computational %budget is limited.
%We conclude that, all else being equal (including the strong $\Lambda$-poisedness of $Y$), we would get the same model %error from using $|Y|=c(n+1)$ points with no sample averaging, or $|Y|=n+1$ points and using $c$ samples per point.
%This provides further support for the similar results for sample averaging and regression models observed in %\secref{sec_regression_results}.


\begin{figure}[t]
	\centering
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/dfols_regression_bugfix/dfols_regression_bugfix_nf_ubgsn_noise2_from_noisy_evals_all_probs_tau_prob_adj_data5.eps}
		\includegraphics[width=\textwidth]{img_final/fig_6a.eps}
		\caption{Multiplicative Gaussian noise}
		\label{fig_regression_noise2_ubgsn_noisyf}
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/dfols_regression_bugfix/dfols_regression_bugfix_nf_addgsn2_noise2_from_noisy_evals_all_probs_tau_prob_adj_data5.eps}
		\includegraphics[width=\textwidth]{img_final/fig_6b.eps}
		\caption{Additive Gaussian noise}
		\label{fig_regression_noise2_addgsn_noisyf}
	\end{subfigure}
	\\
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/dfols_regression_bugfix/dfols_regression_bugfix_nf_addgsn_noise2_from_noisy_evals_all_probs_tau_prob_adj_data5.eps}
		\includegraphics[width=\textwidth]{img_final/fig_6c.eps}
		\caption{Additive $\chi^2$ noise}
		\label{fig_regression_noise2_addchisq_noisyf}
	\end{subfigure}
	\caption{Impact of regression for DFO-LS. We are using noisy objective evaluations with $\sigma=10^{-2}$, high accuracy $\tau=10^{-5}$, and an average of 10 runs for each solver. The problem collection is (MW).}
	\label{fig_regression_noise2}
\end{figure}

\subsection{Multiple Restarts} \label{sec_restarts}
\figref{fig_restarts_noise2} compares the different restart methods against sample averaging (30 samples at every point).
All runs use auto-detection of restarts and
the optional noise-based termination criterion \eqref{eq_termination_noise}.

We see that soft restarts (moving $\bx_k$) is the most successful restarts mechanism, followed by hard restarts, then soft restarts (fixing $\bx_k$), and that all these mechanisms are better than DFO-LS without any noise-based features.
Compared to the case of using averaging with $\Delta_k^{-1}$ samples at every point, soft restarts (moving $\bx_k$) achieve a similar or better level of robustness with many fewer objective evaluations --- this is most clearly observed in the case of additive $\chi^2$ noise.

The improvements in robustness from using multiple restarts are obvious at the end of the full budget of $10^4$ simplex gradients, but there are still benefits to be found at much smaller budgets (e.g.~$\bigO(100)$ simplex gradients).
As a result of these benefits, the soft restarts (moving $\bx_k$) mechanism is activated by default in DFO-LS for noisy problems.

Next, we consider the impact of using increased levels of sample averaging with every restart.
The reason for this is that after every restart, we hope to be closer to the desired solution, so an increased amount of averaging may help distinguish points near to this optimum.
To achieve this, in \eqref{eq_nsamples} we use
\be N = \mathrm{nsamples}(\rho_k, \Delta_k, k, n_{\mathrm{restarts}}) = \min\{n_{\mathrm{restarts}} + 1, 30\}. \ee
\figref{fig_restarts_avg_noise2} shows that 
 augmenting multiple restarts with sample averaging improves the robustness of hard and soft restarts (fixing $\bx_k$), but not for the default mechanism (soft restarts moving $\bx_k$).
Ultimately, using soft restarts (moving $\bx_k$) is better than the other two restart mechanisms, with or without sample averaging.
Hence, we do not use any sample averaging in DFO-LS by default.

\begin{figure}[t]
	\centering
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/dfols_restarts_bugfix/dfols_restarts_bugfix_nf_ubgsn_noise2_from_noisy_evals_all_probs_tau_prob_adj_data5.eps}
		\includegraphics[width=\textwidth]{img_final/fig_7a.eps}
		\caption{Multiplicative Gaussian noise}
		\label{fig_restarts_noise2_ubgsn_noisyf}
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/dfols_restarts_bugfix/dfols_restarts_bugfix_nf_addgsn2_noise2_from_noisy_evals_all_probs_tau_prob_adj_data5.eps}
		\includegraphics[width=\textwidth]{img_final/fig_7b.eps}
		\caption{Additive Gaussian noise}
		\label{fig_restarts_noise2_addgsn_noisyf}
	\end{subfigure}
	\\
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/dfols_restarts_bugfix/dfols_restarts_bugfix_nf_addgsn_noise2_from_noisy_evals_all_probs_tau_prob_adj_data5.eps}
		\includegraphics[width=\textwidth]{img_final/fig_7c.eps}
		\caption{Additive $\chi^2$ noise}
		\label{fig_restarts_noise2_addchisq_noisyf}
	\end{subfigure}
	\caption{Impact of multiple restarts for DFO-LS (using $n+1$ interpolation points). We are using noisy objective evaluations with $\sigma=10^{-2}$, high accuracy $\tau=10^{-5}$, and an average of 10 runs for each solver. The problem collection is (MW).}
	\label{fig_restarts_noise2}
\end{figure}

\begin{figure}
	\centering
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/dfols_restarts_avg_bugfix/dfols_restarts_avg_bugfix_nf_ubgsn_noise2_from_noisy_evals_all_probs_tau_prob_adj_data5.eps}
		\includegraphics[width=\textwidth]{img_final/fig_8a.eps}
		\caption{Multiplicative Gaussian noise}
		\label{fig_restarts_avg_noise2_ubgsn_noisyf}
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/dfols_restarts_avg_bugfix/dfols_restarts_avg_bugfix_nf_addgsn2_noise2_from_noisy_evals_all_probs_tau_prob_adj_data5.eps}
		\includegraphics[width=\textwidth]{img_final/fig_8b.eps}
		\caption{Additive Gaussian noise}
		\label{fig_restarts_avg_noise2_addgsn_noisyf}
	\end{subfigure}
	\\
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/dfols_restarts_avg_bugfix/dfols_restarts_avg_bugfix_nf_addgsn_noise2_from_noisy_evals_all_probs_tau_prob_adj_data5.eps}
		\includegraphics[width=\textwidth]{img_final/fig_8c.eps}
		\caption{Additive $\chi^2$ noise}
		\label{fig_restarts_avg_noise2_addchisq_noisyf}
	\end{subfigure}
	\caption{Comparison of multiple restarts with and without sample averaging for DFO-LS (using $n+1$ interpolation points). We are using noisy objective evaluations with $\sigma=10^{-2}$, high accuracy $\tau=10^{-5}$, and an average of 10 runs for each solver. The problem collection is (MW).}
	\label{fig_restarts_avg_noise2}
\end{figure}

\section{Benchmark Comparisons of DFO-LS} \label{sec_dfols_benchmarking}

This section compares the performance of DFO-LS with other, state-of-the-art derivative-free solvers for nonlinear least-squares problems, namely, DFO-GN \cite{Cartis2017a}, and DFBOLS \cite{Zhang2010} with $2n+1$ and $(n+1)(n+2)/2$ points.
DFO-LS uses $p+1=n+1$ interpolation points and the default values for all other parameters, unless otherwise specified.
We use the computational budget, and initial and final trust region radii as in \secref{sec_testing_methodology}, with accuracy level $\tau=10^{-5}$.

\figref{fig_basic_smooth} shows results for smooth (noiseless) objective functions for both the (MW) and (CR) test sets.
Since DFO-LS uses randomized initial points, we show an average result over 10 runs.
For the (CR) set, we do not show DFBOLS with $(n+1)(n+2)/2$ points, as in most cases the initialization cost will use almost all of the available budget.
DFO-LS performs similarly to DFO-GN and DFBOLS, which is to be expected given the similarity of these algorithms.
Note that for (CR), initializing DFO-LS with only 2 evaluations yields only slightly worse performance, but gains the benefit of decreasing the objective at a very low cost (as shown in \secref{sec_growing_testing}).

Similarly, for noisy functions (from the (MW) set),
\figref{fig_basic_noise2} shows DFO-LS with and without restarts versus the same solvers as above. 
It is in this scenario that the flexibility of DFO-LS becomes evident --- its ability to adjust the default algorithm parameters in the presence of noisy evaluations allows it to solve a larger proportion of problems than both DFBOLS and DFO-GN, and this robustness is further improved, by a significant margin, by the use of multiple restarts.

\begin{figure}
	\centering
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/dfols_comparison_bugfix/dfols_basic_no_restarts_bugfix_nf_smooth_from_noisy_evals_all_probs_tau_prob_adj_data5.eps}
		\includegraphics[width=\textwidth]{img_final/fig_9a.eps}
		\caption{Problem collection (MW)}
		\label{fig_basic_smooth_data}
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/dfols_cutest_bugfix/no_growing_bugfix_budget50_nf_smooth_data5.eps}
		\includegraphics[width=\textwidth]{img_final/fig_9b.eps}
		\caption{Problem collection (CR)}
		\label{fig_basic_cutest_smooth_data}
	\end{subfigure}
	\caption{Comparison of the basic implementation of DFO-LS (using $n+1$ interpolation points) with DFBOLS and DFO-GN for smooth objective evaluations and high accuracy $\tau=10^{-5}$. For DFBOLS, $2n+1$ and $\bigO(n^2)=(n+1)(n+2)/2$ are the number of interpolation points. For DFO-LS, results are an average of 10 runs. In (b), we show results using the full initialization cost of $n+1$ evaluations, and a reduced cost of 2 evaluations (using the SVD method).}
	\label{fig_basic_smooth}
\end{figure}

\begin{figure}
	\centering
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/dfols_comparison_bugfix/dfols_basic_with_restarts_bugfix_nf_ubgsn_noise2_from_noisy_evals_all_probs_tau_prob_adj_data5.eps}
		\includegraphics[width=\textwidth]{img_final/fig_10a.eps}
		\caption{Multiplicative Gaussian noise}
		\label{fig_basic_noise2_ubgsn_noisyf}
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/dfols_comparison_bugfix/dfols_basic_with_restarts_bugfix_nf_addgsn2_noise2_from_noisy_evals_all_probs_tau_prob_adj_data5.eps}
		\includegraphics[width=\textwidth]{img_final/fig_10b.eps}
		\caption{Additive Gaussian noise}
		\label{fig_basic_noise2_addgsn_noisyf}
	\end{subfigure}
	\\
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/dfols_comparison_bugfix/dfols_basic_with_restarts_bugfix_nf_addgsn_noise2_from_noisy_evals_all_probs_tau_prob_adj_data5.eps}
		\includegraphics[width=\textwidth]{img_final/fig_10c.eps}
		\caption{Additive $\chi^2$ noise}
		\label{fig_basic_noise2_addchisq_noisyf}
	\end{subfigure}
	\caption{Comparison of the basic implementation of DFO-LS (using $n+1$ interpolation points) with DFBOLS and DFO-GN for noisy objective evaluations with $\sigma=10^{-2}$ and high accuracy $\tau=10^{-5}$. For DFBOLS, $2n+1$ and $\bigO(n^2)=(n+1)(n+2)/2$ are the number of interpolation points. Results shown are an average of 10 runs for each solver. The problem collection is (MW).}
	\label{fig_basic_noise2}
\end{figure}

\paragraph{Expensive \& Noisy Problems}
Next, we illustrate that the two regimes --- `expensive' and `noisy' --- are not mutually exclusive.
In \figref{fig_cutest_noisy}, we run DFO-LS, DFBOLS and DFO-GN on the (CR) problem set with additive Gaussian noise.
The DFO-LS runs use the default settings for noisy problems (i.e.~slower trust region decrease parameters, multiple restarts). The results are very similar to the smooth case (see Figures \ref{fig_growing_smooth} and \ref{fig_basic_cutest_smooth_data}): the reduced initialization cost allows progress to be made within $n+1$ objective evaluations for some problems, at the cost of reduced small-budget performance, but achieves similar overall robustness, with performance for long budgets at high accuracy levels.

\begin{figure}
	\centering
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/dfols_cutest_bugfix/noisy_growing_bugfix_budget5_nf_addgsn2_noise2_from_noisy_evals_all_probs_tau_prob_adj_data1.eps}
		\includegraphics[width=\textwidth]{img_final/fig_11a.eps}
		\caption{Short budget, $\tau=10^{-1}$}
		\label{fig_cutest_noisy_short}
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/dfols_cutest_bugfix/noisy_growing_bugfix_budget50_nf_addgsn2_noise2_from_noisy_evals_all_probs_tau_prob_adj_data5.eps}
		\includegraphics[width=\textwidth]{img_final/fig_11b.eps}
		\caption{Long budget, $\tau=10^{-5}$}
		\label{fig_cutest_noisy_long}
	\end{subfigure}
	\caption{Comparison of the reduced initialization cost of DFO-LS (using $n+1$ interpolation points, SVD method) against using the full initial set, DFBOLS and DFO-GN, for objectives with additive Gaussian noise, $\sigma=10^{-2}$. For DFBOLS, $2n+1$ is the number of interpolation points. Results are an average of 10 runs in each case. The problem collection is (CR).}
	\label{fig_cutest_noisy}
\end{figure}

\paragraph{Multiple Restarts for Noiseless Problems}
Although the multiple restarts feature is designed for noisy problems, it can also be useful for smooth objectives.
In \figref{fig_smooth_restarts_dfols_profiles}, we show \figref{fig_basic_smooth_data}, but including results for DFO-LS with soft (moving $\bx_k$) and hard restarts\footnote{\:For noiseless problems, we do not use the autodetection of restarts feature from \secref{sec_restarts_description}.}. 
Both restart mechanisms provide a slight improvement --- for most problems, the restarts give similar performance (although using the full computational budget allowed), but in some cases they are beneficial.

The first possible benefit of multiple restarts is being able to escape local minima.
In \figref{fig_smooth_restarts_dfols_prob14}, we show the objective value $f(\bx_k)$ for one run of DFO-LS with soft restarts for problem 14 in (MW); the vertical lines show where restarts occurred.
This problem has two local minima, with $f(\bx^*)\approx 48.98$ and $f(\bx^*)=0$ \cite{More1981}.
We see that when the first restart occurs, we have found the local minimum with higher objective value --- this is when DFO-LS would usually terminate.
However, if we allow DFO-LS to perform three soft restarts, it manages to find the other local minimum (which is also the global minimum).

The other possible benefit is a faster convergence rate.
In \figref{fig_smooth_restarts_dfols_prob18}, we consider problem 18 in (MW), and we again show $f(\bx_k)$ for DFO-LS without restarts, and with hard restarts.
For this problem, DFO-LS with the default settings terminates on the `slow progress' termination criterion (see \appref{sec_general_features_appendix}; the solid circle in the plot), but we show how DFO-LS without restarts continues to make progress when this criterion is disabled.
We also show DFO-LS with hard restarts; in this case, we keep the `slow progress' termination criterion, and this triggers a restart.
We can see that eventually, the run with multiple restarts finds better objective values, and seems to be converging at a faster asymptotic rate than DFO-LS without restarts.

\begin{figure}[t]
	\centering
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/smooth_restarts_dfols_profiles/dfols_basic_with_restarts_noautodetect_bugfix_nf_smooth_from_noisy_evals_all_probs_tau_prob_adj_data5.eps}
		\includegraphics[width=\textwidth]{img_final/fig_12a.eps}
		\caption{Data Profile, $\tau=10^{-5}$}
		\label{fig_smooth_restarts_dfols_profiles}
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/smooth_restarts_dfols_specific/smooth_soft_restarts_prob14_seed0_obj_redn.eps}
		\includegraphics[width=\textwidth]{img_final/fig_12b.eps}
		\caption{Objective reduction, problem 14 (soft restarts)}
		\label{fig_smooth_restarts_dfols_prob14}
	\end{subfigure}
	\\
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/smooth_restarts_dfols_specific/prob18_comparison_obj_redn.eps}
		\includegraphics[width=\textwidth]{img_final/fig_12c.eps}
		\caption{Objective reduction, problem 18}
		\label{fig_smooth_restarts_dfols_prob18}
	\end{subfigure}
	\caption{Illustration of the impacts of multiple restarts for noiseless problems. Figure (a) is the same as \figref{fig_basic_smooth_data}, but also showing DFO-LS with soft and hard restarts, without use of autodetection (problem collection (MW)). Figure (b) shows the objective value $f(\bx_k)$ using DFO-LS with soft restarts (moving $\bx_k$), for (MW) problem 14; the vertical lines indicate where restarts occurred. Figure (c) shows the objective value using DFO-LS with and without hard restarts, for (MW) problem 18. The dot indicates where the default `slow decrease' termination criterion is triggered; the rest of the results for the `no restarts' case are found by disabling this criterion.}
	\label{fig_smooth_restarts_dfols}
\end{figure}

\section{Py-BOBYQA: DFO for General Objective Problems} \label{sec_pybobyqa}
%The above work on DFO-LS for least-squares problems is made easier by the fact that linear approximations for each residual %\eqref{eq_linear_models} are sufficient to build a good local representation of the full objective \cite{Cartis2017a}.
In this section we consider the case of general objective problems; that is,
\be \min_{\bx\in\R^n} f(\bx), \ee
for some sufficiently smooth $f$ with unknown structure.
We call our solver Py-BOBYQA, as it is a Python-based solver which is very similar to Powell's (Fortran) BOBYQA \cite{Powell2009}.

The overall algorithmic structure of (Py-)BOBYQA is the same as \algref{alg_dfols}: we construct an interpolation-based model for $f$, calculate a step to minimize this model inside a trust region, and perform one of several phases (safety, successful, model-improving, unsuccessful) depending on the outcome.
The most important difference is that the model $m_k(\bs)\approx f(\bx_k+\bs)$ is built by directly interpolating $f(\by_t)$ for $\by_t\in Y_k$ and is typically quadratic.
Specifically, for an interpolation set of size $|Y_k|\in\{n+1,\ldots,(n+1)(n+2)/2\}$, we construct
\be m_k(\bs) = c_k + \bg_k^{\top}\bs + \frac{1}{2}\bs^{\top}H_k \bs, \ee
satisfying the interpolation (not regression) conditions
\be m_k(\by_t-\bx_k) = f(\by_t), \quad \text{for all $\by_t\in Y_k$.} \label{eq_bobyqa_interp_conditions} \ee
If $|Y_k|<(n+1)(n+2)/2$, the solution to \eqref{eq_bobyqa_interp_conditions} is non-unique; following \cite{Powell2009} we use the remaining degrees of freedom by choosing $H_k=0$ if $|Y_k|=n+1$, and solving
\be \min_{c_k,\bg_k,H_k} \|H_k-H_{k-1}\|_F^2 \quad \text{subject to \eqref{eq_bobyqa_interp_conditions}}, \label{eq_bobyqa_interp_problem} \ee
otherwise.
The value of $|Y_k|$ is a user-specified input, which defaults to $2n+1$ for smooth problems and $(n+1)(n+2)/2$ for noisy problems.

\paragraph{Simplifications from original BOBYQA}
For the purposes of a simplified code, and to be more closely aligned with DFO-LS, we simplify the model construction process in Py-BOBYQA as compared to its original implementation in \cite{Powell2009}.
Specifically, in \cite{Powell2004a}, it was noted that changing a single interpolation point yielded a low-rank update to the linear system corresponding to \eqref{eq_bobyqa_interp_problem}.
This, together with a well-chosen system for building $Y_0$, meant that the linear system for \eqref{eq_bobyqa_interp_problem} was never solved directly; instead, a factorization of the corresponding matrix inverse was maintained at all iterations, and updated using the Sherman-Morrison-Woodbury formula.
By contrast, in Py-BOBYQA, as in DFO-LS, we use random directions to build $Y_0$, and construct the model by solving the linear system resulting from \eqref{eq_bobyqa_interp_problem} at every iteration.

\paragraph{Improvements from original BOBYQA}
The goal of implementing Py-BOBYQA was to endow it with some of the key features from DFO-LS in order to improve its robustness to noise.
Given the extra complexity of managing quadratic rather than linear models, we transferred the features from DFO-LS which did not require a large redesign of the model construction routines.
Specifically, Py-BOBYQA contains the following new features:
\begin{itemize}
	\item The user can specify $|Y_k|=n+1$, compared to $|Y_k|\geq n+2$ as required by BOBYQA;
	\item Larger range of termination conditions, as per \appref{sec_general_features_appendix}. The changes are that the `small objective value' threshold is just $f(\bx_k) \leq \epsilon_{abs}$, as we no longer have $f\geq 0$ guaranteed, and for the same reason the slow decrease condition \eqref{eq_slow_termination_defn} in Py-BOBYQA uses $f(\bx_{k_{(i-K)}})-f(\bx_{k_i})$ rather than log-decrease;
	\item Flexible choice of algorithm parameters, including setting different default values for noisy problems, as per \appref{sec_general_features_appendix};
	\item Sample averaging using \eqref{eq_nsamples}, as per \secref{sec_restarts_description}; and
	\item Multiple restarts as per \secref{sec_restarts_description} (both soft and hard restarts). 
	However, the automatic detection of restarts uses linear fits for both $\{(k, \log\|\bg_k-\bg_{k-1}\|)\}$ and $\{(k, \log\|H_k-H_{k-1}\|_F)\}$ instead of $\{(k, \log\|J_k-J_{k-1}\|_F)\}$ in DFO-LS.
\end{itemize}

\paragraph{Numerical Results for Smooth Problems}
 \figref{fig_bobyqa_basic_smooth} compares the basic implementation of Py-BOBYQA v1.0.1 (no sample averaging or restarts) with the original BOBYQA \cite{Powell2009} and NOWPAC \cite{Augustin2014} for smooth problems. 
We use the (MW) problem set, and a third collection of test problems: 
\begin{description}
	\item[\rm \textit{(CFMR)}] The set of 60 nonlinear least-squares problems (CR), and the 30 general-objective problems from CUTEst listed in \appref{sec_genobj_problems}. These extra problems are also medium-sized, with $50 \leq n \leq 110$.
\end{description}
We also use the same budget and trust region radii settings as in \secref{sec_dfols_benchmarking}
(as described in \secref{sec_test_problems}), and our budget is $50(n+1)$ evaluations for (CFMR), like for the (CR) test problems.

For (Py-)BOBYQA applied to (MW), we show results for the default choice $|Y_k|=2n+1$, as well as the maximum value $|Y_k|=(n+1)(n+2)/2$, which is Py-BOBYQA's default choice for noisy problems.
We do not show the $|Y_k|=(n+1)(n+2)/2$ results for (CFMR), because the small budget and high dimension means that almost all of the budget would be used by the initialization phase.
We see that Py-BOBYQA has comparable performance with BOBYQA and NOWPAC for smooth problems, which we expect given the similarity of the algorithms.
Due to the size of the (CFMR) problems, we allowed Py-BOBYQA and NOWPAC to run for a maximum of 12 hours per problem.

\paragraph{Numerical Results for Noisy Problems} In \figref{fig_bobyqa_basic_noise2}, we compare Py-BOBYQA with BOBYQA, STORM for unbiased noise \cite{Chen2016}\footnote{\:As mentioned in the introduction, there are several variants of STORM proposed in \cite{Chen2016}. We chose this version because it showed better performance than other variants.} and SNOWPAC \cite{Augustin2017}.
Here, in line with the rest of the paper, we show results for the (MW) set only, and use Py-BOBYQA's noise default of $|Y_k|=(n+1)(n+2)/2$ for both Py-BOBYQA and BOBYQA.
As the slowest solver to run, we allowed SNOWPAC to run for a maximum of 12 hours per problem.
Since SNOWPAC uses points from the full history of observations of the objective to construct a Gaussian Process surrogate model, its performance can slow down rapidly as the computational budget is increased; as a result, we only update the surrogate model every $5n$ iterations.
Similar to our results for DFO-LS, we see that using multiple restarts gives a substantial improvement in the robustness of Py-BOBYQA, and it performs substantially better than BOBYQA.
In our experiments, Py-BOBYQA can solve more problems than STORM within the computational budget, and can solve many problems much more efficiently.
We note that STORM relies on constructing models which are entirely independent at each iteration, so it takes many more evaluations to begin seeing the desired objective reductions.
Compared to SNOWPAC, which uses both objective values and noise standard errors from each evaluation, Py-BOBYQA performs either comparably or better, with the difference most noticeable for multiplicative noise.
The multiple restarts approach in Py-BOBYQA has the advantage of not requiring extra user input, and being cheap to implement compared to constructing a surrogate model.

\begin{figure}
	\centering
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/pybobyqa_nsq_bugfix/pybobyqa_comparison_smooth_bugfix_nf_smooth_from_noisy_evals_all_probs_tau_prob_adj_data5.eps}
		\includegraphics[width=\textwidth]{img_final/fig_13a.eps}
		\caption{Problem collection (MW)}
		\label{fig_bobyqa_basic_smooth_mw}
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/pybobyqa_cutest_bugfix/no_growing_bugfix_budget50_nf_smooth_data5.eps}
		\includegraphics[width=\textwidth]{img_final/fig_13b.eps}
		\caption{Problem collection (CFMR)}
		\label{fig_bobyqa_basic_smooth_cutest}
	\end{subfigure}
	\caption{Comparison of the basic implementation of Py-BOBYQA with the original Fortran BOBYQA and NOWPAC for smooth objective evaluations and high accuracy $\tau=10^{-5}$. For (Py-)BOBYQA, $2n+1$ and $\bigO(n^2)=(n+1)(n+2)/2$ are the number of interpolation points. For Py-BOBYQA, results are an average of 10 runs.}
	\label{fig_bobyqa_basic_smooth}
\end{figure}

\begin{figure}
	\centering
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/pybobyqa_nsq_bugfix/pybobyqa_comparison_nsq_bugfix_nf_ubgsn_noise2_from_noisy_evals_all_probs_tau_prob_adj_data5.eps}
		\includegraphics[width=\textwidth]{img_final/fig_14a.eps}
		\caption{Multiplicative Gaussian noise}
		\label{fig_bobyqa_basic_noise2_ubgsn_noisyf}
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/pybobyqa_nsq_bugfix/pybobyqa_comparison_nsq_bugfix_nf_addgsn2_noise2_from_noisy_evals_all_probs_tau_prob_adj_data5.eps}
		\includegraphics[width=\textwidth]{img_final/fig_14b.eps}
		\caption{Additive Gaussian noise}
		\label{fig_bobyqa_basic_noise2_addgsn_noisyf}
	\end{subfigure}
	\\
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/pybobyqa_nsq_bugfix/pybobyqa_comparison_nsq_bugfix_nf_addgsn_noise2_from_noisy_evals_all_probs_tau_prob_adj_data5.eps}
		\includegraphics[width=\textwidth]{img_final/fig_14c.eps}
		\caption{Additive $\chi^2$ noise}
		\label{fig_bobyqa_basic_noise2_addchisq_noisyf}
	\end{subfigure}
	\caption{Comparison of the basic implementation of Py-BOBYQA with the original Fortran BOBYQA, STORM and SNOWPAC for noisy objective evaluations with $\sigma=10^{-2}$ and high accuracy $\tau=10^{-5}$. For (Py-)BOBYQA, $\bigO(n^2)=(n+1)(n+2)/2$ is the number of interpolation points. Results shown are an average of 10 runs for each solver. The problem collection is (MW).}
	\label{fig_bobyqa_basic_noise2}
\end{figure}

To illustrate the relative cost of multiple restarts compared to building surrogate models, \figref{fig_snowpac_timings} shows the runtime\footnote{\:CPU time, measured on a Lenovo ThinkCentre M900 (with one 64-bit Intel i5 processor, 8GB of RAM).} for Py-BOBYQA and SNOWPAC for two different noisy problems from (MW), using the large budget of $10^4 (n+1)$ objective evaluations and additive Gaussian noise.
For each problem, we imposed a timeout on each solver after 12 hours, and mark when each solver achieved the particular objective reduction $\tau_{crit}(p)$; see \eqref{eq_tau_modification}.
For both problems, the runtime of Py-BOBYQA grows linearly with the number of objective evaluations, after the initial setup cost of $\bigO(n^2)$ evaluations.
However SNOWPAC's runtime starts to grow much more quickly for large budgets.
In SNOWPAC, the number of points used to build the surrogate model --- which drives the cost of surrogate model construction --- depends on the number of evaluated points in the entire run which are sufficiently close to $\bx_k$.
In many cases, this means the rapid increase in runtime occurs in the asymptotic regime, when a good solution has already been found (i.e.~accuracy $\tau_{crit}(p)$ has been achieved), and SNOWPAC is trying to improve the quality of the solution using a more accurate surrogate.
This occurs in problem 1, for instance, where $\tau_{crit}(p)=10^{-2}$, and SNOWPAC achieves this accuracy well before the runtime starts to grow quickly.
However, problem 53 is an example where the increase in runtime comes before this high accuracy regime: we have $\tau_{crit}(p)=10^{-13}$, and SNOWPAC terminates (from the timeout) without achieving accuracy $10^{-4}$.
By comparison, on this problem, Py-BOBYQA terminates on maximum budget after reaching the much higher accuracy level $\tau=10^{-11}$ before terminating (on budget).
Overall, the use of a surrogate model is beneficial for achieving robustness to noise, but may result in reduced performance in order to realise this benefit.
%Overall, the use of a surrogate model is beneficial for achieving very high accuracy solutions (beyond what the noise level would otherwise allow), but suffers a performance penalty as a result. %\alert{[wording? Should we cite something about Bayesian optimization here?]}

% \alert{For reference (not for inclusion in paper): Py-BOBYQA achieves $\tau_{crit}(p)$ accuracy for problem 1 after 10--200 gradients, and terminates (on budget) for problem 53 after reaching accuracy level $\tau=10^{-11}$ --- i.e.~it achieves very high accuracy, but hasn't got to $\tau_{crit}(p)$ yet.}

\begin{figure}
	\centering
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/timing_comparison/timing_comparison_prob1_avg_timings.eps}
		%\includegraphics[width=\textwidth]{img_v2/timing_comparison_with_points/timing_comparison_prob1_avg_timings.eps}
		\includegraphics[width=\textwidth]{img_final/fig_15a.eps}
		\caption{Problem 1, $\tau_{crit}(p)=10^{-2}$}
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/timing_comparison/timing_comparison_prob53_avg_timings.eps}
		%\includegraphics[width=\textwidth]{img_v2/timing_comparison_with_points/timing_comparison_prob53_avg_timings.eps}
		\includegraphics[width=\textwidth]{img_final/fig_15b.eps}
		\caption{Problem 53, $\tau_{crit}(p)=10^{-13}$}
	\end{subfigure}
	\caption{Comparison of average runtimes --- up to a maximum of 12 hours (horizontal dot-dash line) --- for Py-BOBYQA (with $(n+1)(n+2)/2$ interpolation points and multiple restarts) and SNOWPAC, for two problems from (MW). The marked points are average budget/runtime when each solver achieved the labelled objective reduction $\tau$. Both problems had additive Gaussian noise with $\sigma=10^{-2}$. Results shown are an average of 10 runs for each solver.}
	\label{fig_snowpac_timings}
\end{figure}

\paragraph{Multiple Restarts for Noiseless Problems}
Similar to DFO-LS (see \secref{sec_dfols_benchmarking}), we conclude by illustrating that there may also be some benefit in using multiple restarts when running Py-BOBYQA on smooth problems\footnote{\:Unlike \secref{sec_dfols_benchmarking}, we do not consider reduced initialization cost for noisy problems, as Py-BOBYQA does not have this feature.}.
As before, since the first run of Py-BOBYQA with restarts is the same as the full solver run without restarts, there is no performance loss from using multiple restarts (although more of the computational budget is used).
In \figref{fig_smooth_restarts_pybobyqa_profiles}, we compare Py-BOBYQA without restarts against soft (moving $\bx_k$) and hard restarts for the (MW) collection.
As expected, at this accuracy level, multiple restarts either gives the same or slightly better robustness than no restarts --- the improvement is larger when using $(n+1)(n+2)/2$ interpolation points.

However, as for DFO-LS, we find that multiple restarts may help Py-BOBYQA to escape local minima.
In \figref{fig_smooth_restarts_pybobyqa_prob14}, we show the objective value $f(\bx_k)$ for one run of Py-BOBYQA with soft restarts and $2n+1$ interpolation points for problem 14 in (MW) --- this is the same as \figref{fig_smooth_restarts_dfols_prob14} for DFO-LS.
As before, we see that the first run of Py-BOBYQA finds the local minimum $f(\bx^*)\approx 48.98$, but after two restarts, it manages to escape and find the global minimum $f(\bx^*)=0$.

\begin{figure}
	\centering
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/smooth_restarts_pybobyqa_profiles/pybobyqa_comparison_smooth_restarts_bugfix_nf_smooth_from_noisy_evals_all_probs_tau_prob_adj_data5.eps}
		\includegraphics[width=\textwidth]{img_final/fig_16a.eps}
		\caption{Data Profile, $\tau=10^{-5}$}
		\label{fig_smooth_restarts_pybobyqa_profiles}
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.48\textwidth}
		%\includegraphics[width=\textwidth]{img_v2/smooth_restarts_pybobyqa_specific/smooth_soft_restarts_prob14_seed1_obj_redn.eps}
		\includegraphics[width=\textwidth]{img_final/fig_16b.eps}
		\caption{Objective reduction, problem 14 (soft restarts)}
		\label{fig_smooth_restarts_pybobyqa_prob14}
	\end{subfigure}
	\caption{Illustration of the impacts of multiple restarts for Py-BOBYQA on noiseless problems. Figure (a) is the same as \figref{fig_bobyqa_basic_smooth_mw}, but only showing Py-BOBYQA without restarts, and with soft (moving $\bx_k$) and hard restarts, without use of autodetection (problem collection (MW)). Figure (b) shows the objective value $f(\bx_k)$ using Py-BOBYQA with soft restarts and $2n+1$ interpolation points, for (MW) problem 14; the vertical lines indicate where restarts occurred.}
	\label{fig_smooth_restarts_pybobyqa}
\end{figure}

\section{Conclusion} \label{sec_conclusion}
We have presented two model-based DFO routines: DFO-LS for nonlinear least-squares problems, and Py-BOBYQA for general objective problems, both with optional bound constraints.
Both routines perform comparably to or better than state-of-the-art solvers on noisy problems with large, inexpensive budgets.
This is due to their ability to select different, more appropriate, algorithm parameters for noisy problems, and their use of multiple restarts.
Compared to other techniques for improving robustness to noise, such as sample averaging, regression models, and surrogate models, multiple restarts are cheap to implement and do not cause a deterioration in performance in the early phase of the algorithm.
However, both codes also allow the user to employ a wide family of sample averaging strategies, and DFO-LS additionally allows the use of regression models.
Although multiple restarts are designed for noisy problems, they do not disadvantage performance on smooth problems and can sometimes even improve it, such as when allowing the algorithm to escape local minima.

In addition, DFO-LS has the ability to start making progress using as few as 2 objective evaluations, rather than at least $n+1$ as in many model-based DFO codes (for an $n$-dimensional problem). 
This is a useful feature when objective evaluations are expensive, and can be used for noisy and noiseless objectives alike.
By reducing the initialization cost in this way, reasonable progress can be made on several problems even with fewer than $n$ objective evaluations (i.e.~less than the cost of evaluating the gradient of the objective at a single point).
This improvement has a tradeoff in performance for medium-sized budgets, but achieves the same long-term performance as having a full initialization cost.

Throughout, we have shown results for noisy problems using a problem- and noise-adjusted accuracy level.
This adjustment is chosen so that the progress defined by decreases in the noisy and underlying smooth objective produce similar results.
Therefore, this approach may be a useful way of benchmarking solvers for noisy problems, by focusing on a regime where progress as measured in the noisy objective (which is seen by the solver/user) corresponds to genuine optimization steps, and not luck in sampling errors.

\subsection{Acknowledgements}
This work was supported by the EPSRC Centre For Doctoral Training in Industrially Focused Mathematical Modelling (EP/L015803/1) in collaboration with the Numerical Algorithms Group Ltd.
We would like to thank Michael Ferris, Nick Gould, Raphael Hauser, Katya Scheinberg and Amy Willis for useful discussions regarding the DFO-LS algorithm, measuring solver performance, and comparing averaging and regression models.
We also acknowledge the use of the University of Oxford Advanced Research Computing (ARC) facility\footnote{\:\url{http://dx.doi.org/10.5281/zenodo.22558}} in carrying out this work. 
%\alert{[need to notify ARC after publication: publications@arc.ox.ac.uk]}

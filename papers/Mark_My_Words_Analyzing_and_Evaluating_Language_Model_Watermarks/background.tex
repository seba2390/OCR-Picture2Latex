\section{Background}
\label{sec:background}

In this paper, we consider watermarking schemes that can be applied to existing pretrained language models.
%
These schemes are the most convenient and practical as they can be added to any generative language model
without requiring fine-tuning.
%
We evaluated prior work up until August 2023.
%
We provide here a high-level overview of the schemes;
later we propose a unifying framework in which all prior schemes can be expressed (\cref{sec:taxonomy}).


\subsection{Related Work}
\label{ssec:relwork}

Watermarking of textual data has been extensively studied~\citep{kamaruddin18,rizzo17,ahvanooey19}.
It can be viewed as a form of steganography~\citep{cox_information_2005,majeed_review_2021} with a one-bit message.
Steganography imposes the strong requirement that, without knowledge of the secret key, the distribution of watermarked 
and unwatermarked outputs be indistinguishable.
Indistinguishability is beneficial for watermarking schemes too,
as it implies that the mark does not harm the quality of the generated text. However, we found that quality can 
be preserved without indistinguishability.
Watermarking the output of a large language model can be viewed as the problem of embedding a mark when we can 
sample from the output distribution with limited additional 
control~\citep{hopper2008stego,ziegler_neural_2019a,xiang_novel_2020,kang_generative_2020,cao_generative_2022}. 

Another approach to detecting AI-generated text is to train a binary classifier on LLM outputs.
This approach avoids the need to modify how text is generated by the LLM.
Many schemes can be found in the literature,
including OpenAI's classifiers~\citep{openai_gpt2outputdataset_2021,openai_new_2023}, GLTR~\citep{gehrmann_gltr_2019a}, DetectGPT~\citep{mitchell_detectgpt_2023},
and others~\citep{bakhtin_real_2019,zellers_defending_2019a,ippolito_automatic_2020,uchendu_authorship_2020,fagni_tweepfake_2021}.
Unfortunately current LLMs have gotten so good at generating natural-looking text that these detectors 
have become unreliable. These detectors will perform even worse as LLMs improve.

For proprietary LLMs, an alternative is for the vendor to keep a copy of all generated 
outputs from their LLM. Then, they can provide an API to look up any text and determine 
whether it was previously produced with their LLM~\citep{krishna_paraphrasing_2023}.


\subsection{Definition}
\label{ssec:watermark-definition}

A (digital) watermark is a pattern embedded in a signal (image, text, audio, etc.) for 
identifying the source of the signal.
%
%The name comes from traditional watermarks, used in currency to prevent counterfeiting.
%
%The most common use of digital watermarks is to enforce copyrights in images or audio 
%samples and track the source of illegal copies.
%
%It is closely related to steganography, the technique of hiding secret data in signals.
%\chawin{cut this if need space}
%
For generative language models, watermarks are useful
to detect machine-generated text, in contexts where using language models could be unethical, like phishing emails, fake news, 
or college essays.
%
We seek to build a watermark that is not easy for an adversary to remove.

Watermarks could conceivably also be used 
to \emph{prove} that text was indeed machine-generated, for instance, 
to guarantee the provenance of a generation, similar to copyrights.
%
That setting is out of scope for this paper.
%
%In this setting, an adversary 
%will want to add a counterfeit watermark to regular text.
%
%In this work, we focus on the first threat model as it is much more realistic and urgent given the current state of AI development.

Watermarking algorithms have two parts: a marking procedure $\mathcal{W}$ and a verification procedure $\mathcal{V}$.
%
At generation time, each new token invokes the marking procedure to embed a watermark into the generated output.
% 
The marking procedure has access to a secret key $k$, the previous tokens $T_0, \cdots, T_{n-1}$, and the language model's distribution $\mathcal{D}_n = p(T_n \mid T_0,\dots,T_{n-1})$ on the next token, and outputs the next token $T_n$.
%
Verification takes as input a secret key and a piece of text, and returns \texttt{True} if the text was generated using marking procedure $\mathcal{W}$.

Our work focuses on symmetric key watermarking algorithms published before August 2023. To our knowledge, 
the only asymmetric key scheme was proposed by~\citet{fairoze2023publicly} in October 2023. 
It embeds each bit of a public key signature into segments of text by using rejection sampling.

\begin{table*}[!t]
    \centering
    \caption{Randomness Sources}
    \label{tab:randomness-sources}
    \begin{tabular}{|l|r|l|l|}
        \hline
        \multicolumn{2}{|l|}{\bf Randomness Source} & \textbf{Description} & \textbf{Parameter}\\
        \hline
        \hline
        \multirow{2}{*}{text-dependent} & sliding window & Keyed hash of sliding window of previous tokens & \multirow{2}{*}{window size} \\
        \cline{2-3}
        & min hash & Minimum of keyed hash applied to each previous token in sliding window & \\
        \hline
        \multicolumn{2}{|l|}{fixed} & Expands secret key to pseudorandom sequence & key length \\
        \hline
    \end{tabular}
\end{table*}


\subsection{Evaluated watermarks}
\label{ssec:watermark-design}

Prior work has proposed four different marking procedures.
Each consists of a randomness source and a sampling strategy.
The randomness source provides a pseudorandom value for each token, which is used by the sampling strategy to select the next token.
We identify three randomness sources, summarized in~\cref{tab:randomness-sources}, each of which uses a keyed hash to generate pseudorandom values in a deterministic fashion, so that the verifier can reconstruct those pseudorandom values.
Text-dependent randomness sources rely on a fixed-size window of previous tokens.
Fixed randomness relies on a sequence of random values that is the same for every output.
Each marking procedure was initially proposed with a specific 
randomness source, however any of the sampling strategies can be combined with any randomness source. 
%
\begin{itemize}[leftmargin=*]
    \item {\bf \citet{aaronson_watermarking_2022}} mark text by selecting a token $T_n$ that 
    maximizes a score that depends on the probability $p(T_n|T_{0 \cdots n-1})$ and on a pseudorandom value $f_k(T_{n-H \cdots n-1})$ derived from a sliding window of $H$ prior tokens.
    %
    We'll call this the \emph{exponential} scheme.
    \item {\bf \citet{kirchenbauer_watermark_2023}} mark text by favoring tokens from a greenlist. 
    %
    Greenlists are derived from a pseudorandom value (computed either as $f_k(T_{n-1})$ or a min hash over a sliding window of prior tokens, $\min(f_k(T_{n-H}),\dots,f_k(T_{n-1}))$).
    %and contain $\gamma$ percent of the alphabet. 
    %
    Tokens in the greenlist are favored by adding a small bias $\delta$ to their logits, making them slightly more likely to be chosen.
    %
    We call this the \emph{distribution-shift} scheme.
    \item {\bf \citet{christ_undetectable_2023}} convert the tokens to bit-strings.
    Each random bit is chosen based on pseudorandom value (we use $f_k(T_{n-H \cdots n-1})$, derived from a sliding window of $H$ prior tokens, as explained in Section~\ref{sec:watermark-design}) and the LLM-induced distribution on bits.
    Finally, they convert the bit-string to a sequence of tokens.
    %Each token is set to 0 or 1 depending on whether the concatenation\footnotemark[1] pseudorandom value is below the probability of the token being 1. 
    We'll call this the \emph{binary} scheme.
    \item {\bf \citet{kuditipudi_robust_2023}} proposes using inverse transform sampling.
    They compute the CDF $F(t) = \sum_{T_n=0}^t p(T_n|T_{0 \cdots n-1})$ of the LLM's output distribution, where tokens are ordered pseudorandomly according to a secret key $k$; then they use a fixed pseudorandom value $f_k(n)$ to sample from this distribution, via the inverse transform $F^{-1}(f_k(n))$.
    We refer to this as the \emph{inverse transform} scheme.
\end{itemize}

%\footnotetext[1]{\citet{christ_undetectable_2023} uses a slightly modified version of concatenation-derived randomness to prove indistinguishability between their distribution and the original distribution. We find it more practical to use our own randomness source. More details in~\cref{ssec:binary}.}

% DONE: move the below to Section 7. I don't see it discussed there,
% so I think it needs to be included there.  It is too much detail
% for Section 2. --daw
%\citet{kuditipudi_robust_2023} randomly offsets the key sequence of fixed randomness for each generation, as to increase the diversity of outputs.
%We introduce a skip probability $p$ for the same effect on text-dependent randomness.
%Each token is selected without the marking strategy with probability $p$.  

% Did you mean the commented out section, or everything else in this section? --julien

All but the distribution-shift scheme can be made indistinguishable from the original distribution:
When using a random seed, they sample according to the original distribution. 
In practice, the better the randomness source mimics a true random value,
the harder these schemes are to distinguish from the original distribution.
%The higher the pseudorandom value's entropy --- meaning the entropy of the distribution of 
%pseudorandom values for a given secret key --- the harder it becomes to distinguish the 
%marked distribution from the original one.
The distribution-shift scheme is not indistinguishable,
since it alters the model's logits. 

All verification algorithms rely on computing a score $\mathcal{S}$ and computing its likelihood under the null hypothesis that the text was not watermarked.
Watermarked text is flagged as AI-generated if the likelihood is below a $p$-value threshold.
The score is designed to match the sampling strategy: we call \emph{sum score} the score used by text-dependent randomness, and 
the \emph{align score}\cite{kuditipudi_robust_2023} the score used by fixed randomness.
\citet{kuditipudi_robust_2023} propose a more sophisticated score --- the \emph{edit score} --- that considers all 
possible alignments between the text and the sequence of pseudorandom values.
This innovation improves robustness against attacks that insert or delete words when 
using fixed randomness, at the risk of more false positives. Because it is inefficient, we 
only analyzed it on a subset of the benchmark, detailed in~\cref{ssec:editscore}.

%We categorize the scores used into three types: the \emph{sum score}, the \emph{align score}
%and the \emph{edit score}. The last two, introduced in~\citet{kuditipudi_robust_2023},
%are designed to improve robustness of by considering all possible alignments 
%between the text and the sequence of pseudorandom values. Even though any score can be used 
%with any randomness source, we only consider using the sum score with text-dependent randomness, 
%and the others with fixed randomness. Other combinations are superfluous.

All schemes rely on the LLM's output distribution $p(T_n | T_{0 \cdots n-1})$ to have some entropy, so that there are multiple possibilities for $T_n$ that the sampling strategy can choose among.
The higher the entropy, the easier it is to watermark, as the marking strategy has more possibilities to choose from.


\begin{table*}[h]
    \centering
    \caption{Marking Algorithms}
    
    \label{tab:marking-algorithms}
    \begin{tabular}{|l|l|l|l|}
        \hline
        \textbf{Paper} & \textbf{Name} & \textbf{Description} & \textbf{Proposed Randomness}\\
        \hline
        \hline
        \textbf{\citet{aaronson_watermarking_2022}} & exponential & Selects tokens that maximize a hash-based score & sliding window \\
        \hline
        \textbf{\citet{kirchenbauer_watermark_2023}} & distribution-shift & Favors tokens from a greenlist & sliding window or min hash \\
        \hline
        \textbf{\citet{christ_undetectable_2023}} & binary & Converts token distribution to binary alphabet & sliding window \\
        \hline
        \textbf{\citet{kuditipudi_robust_2023}} & inverse transform & Selects tokens using inverse transform sampling & fixed \\
        \hline
    \end{tabular}
\end{table*}

\section{Introduction}
\label{intro}

Traditional unsupervised (bag-of-words -- BOWs) sparse retrieval models, such as BM25, use exact term matching to retrieve relevant results from the collection. Recent studies have shown that these models are more likely to retrieve results that partially match the query, i.e., with low relevance labels~\cite{wang2021bert}. Although unsupervised sparse models often fail to rank the most relevant results at the top, they often offer high recall. Combined with high efficiency, unsupervised bag-of-words sparse retrieval models like BM25 are still widely used within information retrieval pipelines, often as the initial retrieval stage of a more complex setup. 
To further enhance precision and push highly relevant results to the top, transformer-based dense retrievers (short for learned dense representations) strike a good balance between effectiveness and efficiency compared to traditional unsupervised sparse models and transformer-based deep language model re-rankers~\cite{xiong2020approximate,zhan2020repbert,lin2020distilling,lin2021batch,hofstatter2021efficiently,qu2021rocketqa,ren2021rocketqav2}.
Dense retrievers utilise dual BERT-style encoders to encode queries and passages separately~\cite{lin2020pretrained}; this allows the pre-encoding of passages into embeddings at indexing time and their offline storage. During query time, the query embeddings can be efficiently computed "on-the-fly"~\cite{zhuang2021tilde}, and relevance estimations measured with a simple similarity calculation. Thus, it becomes feasible to perform retrieval over the entire collection using deep language models with efficiency comparable to traditional unsupervised sparse models, but with much higher effectiveness. While dense retrievers are very effective at encoding passages characterised by high relevance labels (i.e. highly relevant passages), they are less effective at identifying passages of lower relevance value~\cite{wang2021bert}. On the other hand, learned sparse models~\cite{dai2019context,lin2021few,nogueira2019doc2query,mallia2021learning,formal2021splade,formal2021spladev1,dai2020context,bai2020sparterm,zhuang2021fast}, also strike a good balance between effectiveness and efficiency compared to traditional unsupervised sparse models and transformer-based deep language model re-rankers~\cite{nogueira2019passage}. They use transformer-based language models to learn term weights, and achieve comparable effectiveness to dense retrievers.

Interestingly, recent studies have found that interpolating sparse and dense retrieval~\footnote{Also known as hybrid models.} results can further enhance retrieval effectiveness~\cite{wang2021bert,lin2020distilling,lin2021few}, suggesting that both groups of retrievers tend to retrieve different relevant signals~\cite{lin2021few,lin2020pretrained}. An aspect that is still unclear in this context is what the contribution of PRF is with respect to the interpolation of sparse and dense models: this is the focus of our paper.

In this paper, we are interested in investigating the interpolation of dense and sparse retrieval results within the context of Pseudo-Relevance Feedback (PRF). Specifically, we adapt the interpolation approach on top of a recently proposed PRF method called Vector-PRF (VPRF)~\cite{li2021pseudo} that is designed for dense retrievers. This PRF method conducts the first round of dense retrieval to get the top retrieved passages' dense vectors and then uses these passage vectors to improve the original query's dense representation, which is then used to perform the second round of dense retrieval. In our experiments, we consider combining dense and sparse retrieval interpolation with VPRF in three different settings: \textbf{Before Vector-PRF (Pre-PRF), after Vector-PRF (Post-PRF)} and \textbf{both (Both-PRF)}. For Pre-PRF interpolation, we interpolate the sparse retriever with the dense retriever in the first round of retrieval, then apply Vector-PRF to generate the new query representation, and perform a second retrieval. For Post-PRF interpolation, we keep the two rounds of VPRF retrieval unchanged,  but perform the sparse interpolation to the second round retrieval results. For Both-PRF, we apply interpolation in both the first round of retrieval and on the final results of VPRF. The research questions that we aim to address in this paper are:

 %recent research has adopted two approaches. Interpolation of dense retrievers with traditional unsupervised sparse models such as BM25 can significantly improve recall and precision~\cite{wang2021bert,luan2021sparse,gao2021complement,ma2021replication,lin2021pyserini}. Applying Vector-PRF (VPRF), which uses dense representations of pseudo-relevant passages to improve query dense representation, to dense retrievers on the other hand improves early precision with minimal efficiency cost~\cite{li2021pseudo,yu2021improving}.

%approaches based on dense retrievers further improve the effectiveness of dense retrievers with minimal efficiency cost~\cite{li2021pseudo,yu2021improving}. These methods modified the original query representations by exploiting the top-$k$ initially retrieved passages, use different approaches to combine the information from these passages and the original query together to produce a new query representation. Then this new query representation will contain more relevant signals from the PRF passages hence leads to a better performance. From the empirical results of these studies, utilising PRF passages within dense retrievers can indeed help to improve the effectiveness across different evaluation metrics. However, these models also suffers from the issue with low relevance passages, similar to the dense retriever itself. But there is no previous research have done to investigate the interpolation of BM25 and Vector-based PRF with dense retrievers.

%In this paper we provide a thorough empirical investigation of the impacts of interpolating BM25 with dense retriever PRF models. \todo{[Give a brief summary of the findings here]}


%\section{Research Questions}
%\label{rq}
%
%To drive the empirical investigation, we formulated the following research questions:

\begin{enumerate}[leftmargin=25pt]
	\item[\textbf{RQ1:}] When is it better to do interpolation? \textbf{Before Vector-PRF (Pre-PRF), after Vector-PRF (Post-PRF) or both (Both-PRF)}?
	\item[\textbf{RQ2:}] For sparse retrievers, which representation is more effective, unsupervised (BOWs) or learned? To address this research question, we consider BM25 and uniCOIL~\cite{lin2021few}, respectively.
	
%	\item[\textbf{RQ2:}] Does the interpolation technique generalise to \textbf{other Vector-PRF approaches}? Previous Vector-PRF approaches can be categorized into zero-shot and trained models. To address this question, we consider both categories, including several state-of-the-art dense retrievers.
	
	%\item[\textbf{RQ3:}] How \textbf{sensitive} is the findings to interpolation parameter value $\lambda$?
\end{enumerate}

%For the second research question, we investigate if the interpolation technique also can be applied to other PRF approaches with dense retrievers, especially with the \todo{TAPRF} model proposed by~\citet{yu2021improving}. In this research question, since the \todo{TAPRF} model is a trained approach to perform PRF with dense retrievers, we are interested in investigating 1) What are the impacts of interpolation if we train \todo{TAPRF} with the interpolated results? 2) What are the impacts of interpolation if we use the interpolated results directly with \todo{TAPRF} with zero-shot to perform PRF? 3) What are the impacts of interpolation if we interpolate the BM25 scores with the resulting scores from \todo{TAPRF}?

%For the third research question, we investigate the sensitivity of the interpolation parameter $\lambda$. To do this, \todo{we vary the interpolation parameter $\lambda$ for all the models and methods, including Pre-PRF and Post-PRF approaches. With all the results, we can analyze the impact of different $\lambda$ to the effectiveness of each approach.}

%\begin{itemize}
%	\item When is it better to do interpolation Pre-PRF or Post-PRF?
%	\begin{itemize}
%		\item How does the PRF signal change?
%	\end{itemize}
%	\item Does this apply to other PRF approaches (ANCE-PRF)? 
%	\begin{itemize}
%		\item Pre-PRF with Trained model
%		\item Pre-PRF with Zero-shot model
%		\item Post-PRF with Zero-shot model
%	\end{itemize}
%% Just make sure to add the residual to the evaluation metrics
%%	\item What are the shortcomings of dense retrievers versus interpolation? The intuitions behind this are that dense retrievers retrieve relevant passages that are not judged (residual), and original relevance judgements of TREC DL datasets are not good.
%	\item How sensitive is the findings to interpolation parameter value ($\lambda$)?
%\end{itemize}
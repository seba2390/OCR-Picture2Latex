
\section{Results}

Next, we examine the results of our empirical investigation; for this we follow the research questions we put forward in Section~\ref{intro}. The main results are presented in Table~\ref{tab:rq12}. We note that all the models used in our experiments are provided by the original authors and we do not train a new model. The training of a new model may lead to variations in the effectiveness results because of e.g., the stochastic nature of the weight initialisation of the models. 
However, we observe that~\citet{li2022improving} have shown that the differences observed empirically in terms of model effectiveness across re-training of the same model are minor and not statistically significant. The use of the original model checkpoint for each model then appears a fair choice in the context of our work, and the variability that the retraining of these models would cause seems a non-critical direction to investigate in this short paper. 

\subsection{RQ1: When is it better to do interpolation? Pre-PRF, Post-PRF or Both-PRF?}

\begin{table*}[]
	\resizebox{7in}{!}{

		\begin{tabular}{ccc|ccc|ccc}
			\toprule
			&\textbf{Dataset} &               &               \multicolumn{3}{c|}{\textbf{DL19}}               &                              \multicolumn{3}{c}{\textbf{DL20}}                               \\ \midrule
			\textbf{Sparse Model} &\textbf{Dense Model} &\textbf{PRF-Interpolation}                  &     \textbf{MAP}     & \textbf{nDCG@10} &   \textbf{Recall@1000}    &         \textbf{MAP}          &   \textbf{nDCG@10}   &            \textbf{Recall@1000}            \\
			\midrule


			&ANCE&                   &        0.3710        &      0.6452      &        0.7554        &            0.4076             &        0.6458        &                0.7764                 \\
			&ANCE-VPRF&              &        0.3831        &      0.6512      &        0.7611        &            0.4118             &        0.6479        &                0.7800                 \\	\midrule
			\multirow{4}{*}{{BM25}}&\multirow{4}{*}{{ANCE}}&No-PRF               &        0.4264        &      0.6888      &   \textbf{0.8607}    &            0.4067             &        0.6264        &                0.8643                 \\
			&&Pre-PRF         &        0.3868        &      0.6620      & 0.7638${^\barwedge}$ &        \textbf{0.4175}        &   \textbf{0.6548}    &         0.7911${^\barwedge}$          \\
			&&Post-PRF         & 0.4322${^\barwedge}$ &      0.6885      &   0.8604${^\star}$   &            0.4140             &        0.6353        & \textbf{0.8666}${^{\barwedge\star}}$  \\
			&&Both-PRF  &   \textbf{0.4345}${^\barwedge}$    & \textbf{0.6895}  &   \textbf{0.8607}    &            0.4100${^\barwedge}$            &        0.6274        &                0.8662${^\barwedge}$                \\

			\midrule
			\multirow{4}{*}{{uniCOIL}}&\multirow{4}{*}{{ANCE}}&No-PRF&0.4587 &0.6908   &   0.8459 &0.4644&0.6984 &   0.8482    \\

			&&Pre-PRF   &0.3857${^\barwedge}$ & 0.6602${^\barwedge}$   & 0.7584${^\barwedge}$ &  0.4154${^\barwedge}$& 0.6545${^\barwedge}$ &0.7892${^\barwedge}$         \\
			&&Post-PRF   & 0.4617${^\star}$ &  0.6910${^\star}$   &    \textbf{0.8495}${^\star}$   &    0.4693${^{\barwedge\star}}$  & \textbf{0.7024}${^\star}$  & \textbf{0.8500}${^\star}$  \\
			&&Both-PRF  &   \textbf{0.4622} & \textbf{0.6917}  &   0.8458 &    \textbf{0.4699}${^\barwedge}$ & 0.7012 &   \textbf{0.8500}${^\barwedge}$ \\
			\midrule\midrule
			&TCTv2&                   &        0.4469        &      0.7204      &        0.8261        &            0.4754             &        0.6882        &                0.8429                 \\
			&TCTv2-VPRF&               &        0.4626        &      0.7219      &        0.8377        &            0.4863             &        0.6952        &                0.8462                 \\\midrule
			\multirow{4}{*}{{BM25}}&\multirow{4}{*}{{TCTv2}}&No-PRF              &        0.4474        &      0.7067      &        0.8753        &            0.4468             &        0.6696        &                0.8872                 \\
			&&Pre-PRF        &   \textbf{0.4698}    & \textbf{0.7268}  &        0.8436        & \textbf{0.4879}${^\barwedge}$ &  \textbf{0.6987}   &         0.8455${^\barwedge}$          \\
			&&Post-PRF        & 0.4547${^\barwedge}$ &      0.7045      &        0.8788        &  0.4511${^{\barwedge\star}}$  &        0.6683        & \textbf{0.8918}${^{\barwedge\star}}$ \\
			&&Both-PRF &        0.4574${^\barwedge}$        &      0.7061      &   \textbf{0.8820}${^\barwedge}$   &            0.4490             &        0.6659        &                0.8902${^\barwedge}$                \\\midrule
			\multirow{4}{*}{{uniCOIL}}&\multirow{4}{*}{{TCTv2}}&No-PRF  & 0.4771&0.7245&0.8557&0.4895&0.718&0.8683    \\
			&&Pre-PRF  & 0.4659&0.7246&0.8415&0.4897&0.7083&0.8484${^\barwedge}$         \\
			&&Post-PRF  & 0.4826${^{\barwedge\star}}$& \textbf{0.7347} & 0.8663${^\barwedge}$& \textbf{0.4926} & 0.7184&0.8718${^\star}$\\
			&&Both-PRF & \textbf{0.4831} & 0.7268 & \textbf{0.8606}${^\barwedge}$ & 0.4920${^\barwedge}$ & \textbf{0.7190} & \textbf{0.8723}${^\barwedge}$ \\
			\midrule\midrule
			&DBB&                     &        0.4590        &      0.7210      &        0.8406        &            0.4698             &        0.6854        &                0.8727                 \\
			&DBB-VPRF&                 &        0.4667        &      0.7285      &        0.8479        &            0.4804             &   \textbf{0.7027}    &                0.8767                 \\ \midrule
			\multirow{4}{*}{{BM25}}&\multirow{4}{*}{{DBB}}&No-PRF                &        0.4584        &      0.6993      &        0.8622        &            0.4417             &        0.6491        &                0.8948                 \\
			&&Pre-PRF          &   \textbf{0.4711}    & \textbf{0.7319}  &        0.8526        & \textbf{0.4812}${^\barwedge}$ & 0.6968${^\barwedge}$ &                0.8755                 \\
			&&Post-PRF          & 0.4652${^\barwedge}$ &      0.7053      &        0.8711        &       0.4509${^\star}$        &   0.6522${^\star}$   &                0.8974                 \\
			&&Both-PRF   &        0.4665${^\barwedge}$        &      0.7019      &   \textbf{0.8720}    &            0.4442             &        0.6474        &            \textbf{0.8977}            \\  \midrule

			\multirow{4}{*}{{uniCOIL}}&\multirow{4}{*}{{DBB}}& No-PRF&0.4779 & 0.7288 & 0.8542 & 0.4859 & 0.7041 & 0.8808    \\
			&&Pre-PRF &   0.4726&0.7255&0.8468&0.4815&0.7002&0.8760   \\
			&&Post-PRF& 0.4822 & 0.7298 & 0.8658 & \textbf{0.4915} & \textbf{0.7097} & \textbf{0.8836}   \\
			&&Both-PRF   & \textbf{0.4858}${^\barwedge}$ & \textbf{0.7334} & \textbf{0.8669} & 0.4880${^\barwedge}$ & 0.7062 & 0.8834 \\\midrule
			\bottomrule
		\end{tabular}
	}
\vspace{6pt}
	\caption{The results of all baseline runs and No-PRF, Pre-PRF, Post-PRF and Both-PRF interpolation runs of all models with the Rocchio Vector PRF approach proposed by~\citet{li2021pseudo}. Statistical significance tests are conducted between Pre- and Post-PRF models, significant difference are marked with $\star$. We also tested the statistical significance with Pre-PRF interpolation versus No-PRF interpolation, and Post-PRF interpolation versus No-PRF interpolation, and Both-PRF interpolation versus no-PRF interpolation, significant difference are marked with $\barwedge$. Best performance among each base sparse model is marked as Bold.}
	\label{tab:rq12}
	\vspace*{-15pt}
\end{table*}



%\begin{table*}[]
%	\caption{The results of all baseline runs and Pre-PRF, Post-PRF interpolation runs of all models with the Rocchio Vector PRF approach proposed by~\citet{li2021pseudo}. Where \textbf{+} indicates an interpolation operation, \textbf{-PRF} indicates the Rocchio Vector PRF. Parentheses indicates the operations' orders, the operations inside parentheses are executed first. For example, \textbf{(Unicoil+ANCE)-PRF} indicates interpolation first, then perform PRF (Pre-PRF). Statistical significance tests are conducted between Pre- and Post-PRF models, significant difference are marked with $\star$. We also tested the statistical significance with Pre-PRF interpolation versus No-PRF interpolation, and Post-PRF interpolation versus No-PRF interpolation, significant difference are marked with $\barwedge$. Best performance among each base model is marked as Bold.}
%	\label{tab:unicoil-rq12}
%	\input{unicoil-rq12-result_table.tex}
%\end{table*}

To answer the first research question, we perform Pre-PRF interpolation, Post-PRF interpolation, and Both-PRF interpolation. We do this across two sparse retrievers (one neural, uniCOIL, and one not, BM25), and three dense retrivers (ANCE, TCTV2 and DistillBERT).
%For this line of experiments, we fix the interpolation parameter $\lambda=0.5$, which indicates the sparse retriever score's contribution is exactly half, following the settings reported by~\citet{wang2021bert}. As for PRF method in this series of experiments, we adopt the Rocchio Vector PRF method reported by~\citet{li2021pseudo}, we fix the Rocchio parameter $\alpha=0.4$ and $\beta=0.6$, while keeping the PRF depth to be fixed at 3. The full results are presented in Table~\ref{tab:rq12} along with significant tests.


We first discuss the results among each dense retriever with only PRF or only interpolation involved. In this case, the interpolation with uniCOIL always gives the highest effectiveness compared to using PRF or using the dense retriever along: this is regardless of the dense retriever of choice and dataset. However, when BM25 is used for interpolation, the interpolated results are lower than those achieved by PRF for MAP and nDCG (but not recall@1000), regardless of dense retriever and dataset.


We now consider interpolation with BM25.
Unlike the findings obtained by comparing the use of the dense retriever with either only interpolation or only PRF, better effectiveness is achieved when both PRF and interpolation with BM25 are used. % interpolating BM25 with the PRF models.
The effectiveness of the Post-PRF interpolation condition is very close to that of Both-PRF interpolation; however, Both-PRF interpolation achieves the highest effectiveness most of the times and across all dense retrievers and datasets.
However, the difference between Post-PRF and Both-PRF interpolation is not significant, and Both-PRF interpolation requires some extra computations compared to Post-PRF.
Pre-PRF interpolation tends to enhance early precision, while Post-PRF interpolation tends to enhance deep recall. Overall, however, Pre-PRF interpolation is the least effective of the three interpolation conditions, regardless of dense retriever, metric and dataset.



%More specifically, except nDCG@10 with DBB-PRF Pre-PRF interpolation on DL20, the best performances are all recorded using PRF and interpolation together. When looking at Pre-PRF interpolation, Post-PRF interpolation, and Both-PRF interpolation separately, we can observe that the results from Post-PRF interpolation are very close to Both-PRF interpolation. However, Both-PRF interpolation achieves the best performance most of the time across all models and datasets.
%Still, the difference between these two interpolation approaches is not significant with a higher efficiency cos. By comparing Pre-PRF interpolation and Post-PRF interpolation, we can observe that except with ANCE as base model on DL19, all other models on both DL19 and DL20 datasets have the similar trends, that is, Pre-PRF interpolation enhances early precision measurements, similar to the PRF baselines, while Post-PRF interpolation enhances deep recall, similar to the interpolation baselines.

We now consider interpolation with uniCOIL. Here also we observe that PRF with uniCOIL interpolation can consistently achieve higher effectiveness than using the dense retrievers or sparse retrievers alone.
Furthermore, we also found that using Post-PRF interpolation or Both-PRF interpolation  outperforms results obtained with interpolation but not PRF, regardless of dense retriever and dataset. However, if Pre-PRF interpolation is used, then effectiveness is often similar or lower than when interpolation is used but no PRF. Indeed, Both-PRF can achieve the highest effectiveness most of the times.


%When looking at uniCOIL interpolation with PRF dense models, we found the same as the interpolation model, that PRF with uniCOIL interpolation can consistently achieve higher effectiveness than base models. Furthermore, we also found that using Post-PRF interpolation or Both-PRF interpolation can also outperform no-PRF interpolation models, shown as an increase in all evaluation measures across all datasets and Dense models used. For Pre-PRF interpolation, the model showed a similar or lower performance than No-PRF interpolation models. When looking at Pre-PRF interpolation, Post-PRF interpolation, and Both-PRF interpolation separately, we found that Both-PRF can achieve the highest effectiveness most of the time. At the same time, Pre-PRF obtains the lowest effectiveness for all evaluation measures on all datasets.

Overall, the condition with interpolation both before and after PRF (Both-PRF) showcased often high effectiveness regardless of dense and sparse retriever. The condition with interpolation performed after PRF (Post-PRF) showcased high effectiveness only with the uniCOIL sparse retriever, but not with BM25.


%when uniCOIL is used as the sparse representation of interpolation, interpolation should always be done after PRF (Post-PRF) or applied before PRF and after PRF (Both-PRF), when BM25 is used as the sparse representation, interpolation should be applied both before and after PRF.

\vspace{-10pt}
\subsection{RQ2: Which sparse retriever is more effective, unsupervised (BOWs) or learned?}

In our experiments we considered BM25 and uniCOIL as sparse retriever. The uniCOIL method is a typical neural sparse retriever trained with contrastive loss that uses BERT to predict impact scores for both query tokens and document tokens. Before performing predictions, uniCOIL uses docTquery-T5~\cite{nogueira2019doc2query} to expand all passages in the collection by adding potential relevant tokens that are not in the original passages. BM25 instead is a traditional BOWs sparse retriever, where the representation is not learnt. We now consider which of these sparse representation is best to combine with the signal from the dense retrievers; we do this bot in the context of PRF (Pre-PRF, Post-PRF, and Both-PRF interpolation) and when not considering PRF (No-PRF).

%When comparing with two sparse representations, we use BM25 as an unsupervised sparse representation and uniCOIL as a sparse learned representation. We specifically look at four situations: No-PRF, Pre-PRF, Post-PRF, and Both-PRF interpolation.

The results show that the use of uniCOIL guarantees an increase in MAP and nDCG@10 compared to BM25, but a lower recall@1000. This result is valid across all dense retrievers, datasets and for No-PRF, Post-PRF and Both-PRF interpolation conditions.


%Surprisingly, the same trend is found when analysis results from No-PRF, Post-PRF and Both-PRF. The results show that using uniCOIL can guarantee an increase in MAP and nDCG@10 compared to BM25, with a lower recall@1000 across all dense models and Datasets.

For the Pre-PRF interpolation method, however, no general trend is found when comparing the two sparse models.
On DL2019, uniCOIL consistently underperforms BM25 in the pre-PRF interpolation condition, with the only exception of MAP when DBB is used as dense retriever.
On DL2020, uniCOIL always outperforms BM25 when the dense retrievers are TCTV2 or DBB, but underperforms BM25 when ANCE is used as dense retriever.


%When using DL2019 as a test set, uniCOIL consistently underperforms BM25 when pre-PRF interpolation is used, with the only exception on MAP value when DBB is used for the dense model. When using DL2020 as a test set, using uniCOIL can always outperform BM25 when TCTV2 or DBB is used for the dense model but underperform BM25 when ANCE is used for the dense model.

Overall, we found that when performing PRF and interpolating with the Post-PRF and Both-PRF conditions, an unsupervised BOWs sparse retriever leads generally to high recall, while a neural, trained sparse retriever achieves higher MAP and nDCG@10. However, the Pre-PRF condition shows no stable trends in terms of which sparse retriever to use.

%
%in the PRF-interpolation task, an unsupervised retriever should always be used when a high recall is needed, and a sparse learned model can generally achieve higher effectiveness when high MAP or nDCG@10 is required. This is, however, not generalised to Pre-PRF models, which has no stable trend for which sparse model should be used for PRF interpolation.



%For PRF approach, there are two rounds of retrieval, the first retrievunal is a standard dense retrieval with the original query representations, the second round is with the PRF modified query representations. With interpolation, the top-ranked passages might be changed. Therefore, the PRF will be affected because of this change. We further investigate this top-ranked passages' change before and after the interpolation within the first round retrieval. To achieve this, we report nCG@3 and Jaccard Similarity scores, the results are presented in Table~\ref{tab:js}.

%From the results, we can observe that except the ANCE based models on DL19 and TCTV2 based models on DL20, all other dense retrievers' nCG@3 scores become lower after the interpolation, which indicates that the interpolation actually reduced the number of relevant passages in top 3 for TCTV2 and DBB based models. This finding aligns with the results in Table~\ref{tab:rq12}. However, the reduction of relevant passages might be due to interpolation includes more unjudged passages rather than irrelevant passages. As for Jaccard Similarity scores, all three pairs of comparison are very similar on both DL19 and DL20 datasets, the interpolated runs are very different from the original runs.

%\begin{table}[]
%\caption{The results of all models with no PRF but interpolation only. In this table we show the nCG@3 and Jaccard Similarity (JS) scores between the model itself and the model after interpolation. The \textbf{+} indicates the interpolation operation.}
%\label{tab:js}
%\begin{tabular}{l|cc|cc}
%\toprule
%\textbf{Dataset}    & \multicolumn{2}{c|}{\textbf{DL19}} & \multicolumn{2}{c}{\textbf{DL20}} \\ \midrule
%\textbf{Model} & \multicolumn{1}{c}{\textbf{nCG@3}} & \multicolumn{1}{c|}{\textbf{JS}} & \multicolumn{1}{c}{\textbf{nCG@3}} & \multicolumn{1}{c}{\textbf{JS}} \\ \midrule
%\textbf{ANCE}       & 0.6173  & \multirow{2}{*}{0.3721} & 0.6348  & \multirow{2}{*}{0.3963} \\
%\textbf{BM25+ANCE}  & 0.6458  &                         & 0.5856  &                         \\ \midrule
%\textbf{TCTV2}      & 0.6611  & \multirow{2}{*}{0.3860} & 0.6183  & \multirow{2}{*}{0.3926} \\
%\textbf{BM25+TCTV2} & 0.6557  &                         & 0.6195  &                         \\ \midrule
%\textbf{DBB}        & 0.6739  & \multirow{2}{*}{0.3512} & 0.6195  & \multirow{2}{*}{0.3667} \\
%\textbf{BM25+DBB}   & 0.6557  &                         & 0.6004  &                         \\ \midrule \bottomrule
%\end{tabular}
%\end{table}

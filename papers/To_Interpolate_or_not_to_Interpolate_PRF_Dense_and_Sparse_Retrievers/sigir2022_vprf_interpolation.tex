\documentclass[sigconf,natbib=true,anonymous=false]{acmart}

\usepackage{booktabs} % For formal tables
\usepackage{upgreek} % For uppercase greek
%\usepackage{amssymb}
\usepackage{tikz-cd}
\usepackage{tikz}
\usetikzlibrary{shapes,arrows}
\usepackage{hyperref}
\usepackage{graphicx,verbatimbox}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{subcaption}
\usepackage{mathtools}
\usepackage{color}
\usepackage{tabularx,ragged2e}
\usepackage{multirow}
\usepackage{mathtools}
\usepackage[british]{babel}
\usepackage{enumerate}
\usepackage{enumitem}
\setlist{leftmargin=0mm}

\makeatletter
\newcommand\footnoteref[1]{\protected@xdef\@thefnmark{\ref{#1}}\@footnotemark}
\makeatother

% TODO REMOVE IN CAMERA READY
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\usepackage[printwatermark]{xwatermark}
%\newsavebox\mybox
%\savebox\mybox{\tikz[opacity=0.1]\node{DRAFT};}
%\newwatermark*[
%allpages,
%angle=45,
%scale=15,
%xpos=-50,
%ypos=50
%]{\usebox\mybox}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\newcommand{\ubar}[1]{\text{\b{$#1$}}}

\copyrightyear{2022} 
\acmYear{2022} 
\setcopyright{acmlicensed}\acmConference[SIGIR '22]{Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval}{July 11--15, 2021}{Madrid, Spain}
\acmBooktitle{Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '22, July 11--15, 2022, Madrid, Spain}
\acmPrice{15.00}
\acmDOI{10.1145/3477495.3531884}
\acmISBN{978-1-4503-8037-9/21/07}
% Authors, replace the red X's with your assigned DOI string during the rightsreview eform process.

\settopmatter{printacmref=true}

% todo command
\newcommand{\todo}[1]{\textcolor{red}{#1}}

\begin{document}
\fancyhead{}
%\title{Vector-based PRF with Dense Retrievers Also Require Interpolation with BM25 for Effective Passage Retrieval}
%\title{How Effective is Combining Vector PRF with Dense Retrievers and Interpolation with BM25?}
\title{To Interpolate or not to Interpolate: \\ PRF, Dense and Sparse Retrievers}

\author{Hang Li}
\authornote{Both authors contributed equally to the paper.}
\affiliation{%
  \institution{The University of Queensland}
  \city{Brisbane}
  \country{Australia}
}
\email{hang.li@uq.edu.au}

\author{Shuai Wang}
\authornotemark[1]
\affiliation{%
  \institution{The University of Queensland}
  \city{Brisbane}
  \country{Australia}
}
\email{shuai.wang2@uq.edu.au}
\author{Shengyao Zhuang}
\affiliation{%
  \institution{The University of Queensland}
  \city{Brisbane}
  \country{Australia}
}
\email{s.zhuang@uq.edu.au}
\author{Ahmed Mourad}
\affiliation{%
  \institution{The University of Queensland}
  \city{Brisbane}
  \country{Australia}
}
\email{a.mourad@uq.edu.au}
\author{Xueguang Ma}
\affiliation{%
  \institution{University of Waterloo}
  \city{Waterloo}
  \country{Canada}
}
\email{x93ma@uwaterloo.ca}
\author{Jimmy Lin}
\affiliation{%
  \institution{University of Waterloo}
  \city{Waterloo}
  \country{Canada}
}
\email{jimmylin@uwaterloo.ca}
\author{Guido Zuccon}
\affiliation{%
  \institution{The University of Queensland}
  \city{Brisbane}
  \country{Australia}
}
\email{g.zuccon@uq.edu.au}
\settopmatter{authorsperrow=4}

% The default list of authors is too long for headers.
\renewcommand{\shortauthors}{Li, H and Wang, S and et al.}
%\settopmatter{printacmref=true}


\begin{abstract}
	
Current pre-trained language model approaches to information retrieval can be broadly divided into two categories: sparse retrievers (to which belong also non-neural approaches such as bag-of-words methods, e.g., BM25) and dense retrievers. Each of these categories appears to capture different characteristics of relevance. Previous work has investigated how relevance signals from sparse retrievers could be combined with those from dense retrievers via interpolation. Such interpolation would generally lead to higher retrieval effectiveness. 

In this paper we consider the problem of combining the relevance signals from sparse and dense retrievers in the context of Pseudo Relevance Feedback (PRF). This context poses two key challenges: (1) When should interpolation occur: before, after, or both before and after the PRF process? (2) Which sparse representation should be considered: a zero-shot bag-of-words model (BM25), or a learnt sparse representation? To answer these questions we perform a thorough empirical evaluation considering an effective and scalable neural PRF approach (Vector-PRF), three effective dense retrievers (ANCE, TCTv2, DistillBERT), and one state-of-the-art learnt sparse retriever (uniCOIL).
The empirical findings from our experiments suggest that, 
regardless of sparse representation and dense retriever, interpolation both before and after PRF achieves the highest effectiveness across most datasets and metrics.

%, (2)
%
%Post-PRF or Both-PRF interpolation should always be used to achieve the highest effectiveness
%%2) Performing interpolation with trained model and zero-shot model have different impacts to effectiveness; 
%2) BM25 with PRF interpolation can consistently achieve a higher recall, while uniCOIL with PRF interpolation can consistently achieve a higher nDCG and MAP
%	

%Recent research has demonstrated that Dense Retrievers (DRs) strike a good balance between effectiveness and efficiency compared to traditional bag-of-words (BOWs) models (such as BM25) and transformer-based deep language model re-rankers (such as monoBERT). While dense retrievers are more effective than BOWs models in terms of early precision metrics, they suffer from low recall because DRs cannot identify documents with low relevance signals. To address this issue, previous research has proposed interpolating dense retrievers with BM25, and this enhanced recall significantly. On the other hand, dense retrievers are less effective than monoBERT in terms of early precision although DRs are much more efficient. To reduce this gap in early precision, PRF methods on top of dense retrievers have proven effective.
%%previous research which applied Vector-based Pseudo Relevance Feedback (Vector-PRF) to dense retrievers has demonstrated its effectiveness. 
%Therefore, we consider combining Vector-PRF and interpolation with BM25 and uniCOIL, an advanced learned sparse retrieval model, to investigate if an effective pipeline can be created without sacrificing either recall or precision.

%Recently, dense retriever has been well-studied in the IR community for its good balance between effectiveness and efficiency compared to traditional bag-of-words models (such as BM25) and transformer-based deep language model re-rankers (such as BERT reranker). To further improve the effectiveness of dense retrievers, currently there are two lines of work: 1) Interpolating BM25 scores with dense retriever scores; 2) Utilising Pseudo-Relevance Feedback (PRF) to modify the original query representations with the initial retrieval results, then use the modified query representations to do a subsequent retrieval.

%Previous research have found that dense retrievers are not good at identifying passages with low relevance labels, because they are very effective at encoding the strong relevance signals in the passages, hence the low relevance signals are mostly ignores. but interpolate with BM25 score could significantly improve the effectiveness by bring in the low relevance passages.

%Recent work on PRF with dense retrievers also shown great promise in improving the effectiveness of dense retrievers with minimal efficiency cost. However, it also suffers from the issue with identifying the low relevance passages. Therefore, in this paper, we further investigate the topic of interpolating BM25 with dense retrievers. Unlike previous works that only consider the dense retriever itself, we instead consider dense retriever PRF models.

%The empirical findings from our experiments suggest that: 
%%\todo{[These are not the true findings, need to modify after analysis]} 
%1)  When using uniCOIL as sparse representation, Post-PRF or Both-PRF interpolation should always be used to achieve the highest effectiveness
%%2) Performing interpolation with trained model and zero-shot model have different impacts to effectiveness; 
%2) BM25 with PRF interpolation can consistently achieve a higher recall, while uniCOIL with PRF interpolation can consistently achieve a higher nDCG and MAP
%%And because BM25 can run in parallel with dense retriever PRF, the efficiency will be the same.

\end{abstract}

%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below.
%

\begin{CCSXML}
	<ccs2012>
	<concept>
	<concept_id>10002951.10003317.10003338</concept_id>
	<concept_desc>Information systems~Retrieval models and ranking</concept_desc>
	<concept_significance>500</concept_significance>
	</concept>
	</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Information systems~Retrieval models and ranking}


\keywords{Pseudo-Relevance Feedback, Dense and sparse retrieval interpolation, Neural IR}

\maketitle

\input{introduction}
\input{relatedwork}
\input{methods}
\input{experimental_setup}
\input{results}
%\input{discussion}
\input{conclusions}
%\input{future_work}



\section*{Acknowledgements.}
Hang Li is funded by the Grain Research and Development Corporation (GRDC), project AgAsk (UOQ2003-009RTX). Shuai Wang is supported by a UQ Earmarked PhD Scholarship and this research is funded by the Australian Research Council Discovery Projects program ARC DP210104043.



%\subsubsection*{Acknowledgements.} These will be included in the final version. The authors require 3 lines of text for the acknowledgements, as shown here. 
%\clearpage
%\vspace{-10pt}
\bibliographystyle{ACM-Reference-Format}
\bibliography{references.bib}

\end{document}

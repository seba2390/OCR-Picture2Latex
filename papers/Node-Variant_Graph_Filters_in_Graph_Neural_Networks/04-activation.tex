%!TEX root = 00-NVGF.tex

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%                                                                        %%%%
%%%%                   APPROXIMATING ACTIVATION FUNCTIONS                   %%%%
%%%%                                                                        %%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% sec:activation
%%%%%%%%%%%%%%%%%%%

One of the main roles of activation functions in neural networks is to create low-frequency content that can be processed in a stable manner \cite{Mallat2012-Scattering}. However, the way the nonlinearities create this frequency content is unknown and cannot be shaped. One alternative for tailoring the frequency creation process to the specific problem under study is to learn the NVGF filter taps (Sec.~\ref{sec:archit}). However, doing so, implies that the number of learnable parameters depend on $N$ which may lead to overfitting. In what follows we propose one method of designing, instead of learning, the NVGFs.

\textbf{Problem statement.} Assume that each data point $\vcx$ is a random graph signal with mean $\xp[\vcx] = \vcmu_{x}$, correlation matrix $\mtR_{x} = \xp[\vcx \vcx^{\Tr}]$, and covariance matrix $\mtC_{x} = \xp[(\vcx-\vcmu_{x})(\vcx-\vcmu_{x})^{\Tr}]$. The objective is to estimate a pointwise nonlinear function $\fnrho: \fdR \to \fdR$ such that $[\fnrho(\vcx)]_{i} = \fnrho([\vcx]_{i})$, using a NVGF-based estimator as $\vchy = \mtfnH^{\text{nv}}(\mtS) \vcx + \vcc$ for $\mtfnH^{\text{nv}}(\mtS)$ as in \eqref{eq:NVGF} and $\vcc \in \fdR^{N}$. Given the random variable $\vcy = \fnrho(\vcx)$, the aim is to find the filter taps $\mtH \in \fdR^{N \times (K+1)}$ that minimize the mean squared error (MSE)
% eq:Hopt
\begin{equation} \label{eq:Hopt}
    \mtH^{\opt} = \argmin_{\mtH \in \fdR^{N \times (K+1)}} \xp \big[ \| \vchy - \vcy \|_{2}^{2} \big].
\end{equation}
%
Our particular focus is set on obtaining unbiased estimators.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%               LEMMA            %%%%  l:unbiased
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
\begin{lemma}[Unbiased estimator] \label{l:unbiased}
Let $\vcmu_{\rho} = \xp[\fnrho(\vcx)]$. The NVGF-based estimator is unbiased if and only if $\vcc = \vcmu_{\rho} - \mtfnH^{\text{nv}}(\mtS) \vcmu_{x}$.
\end{lemma}
%%
%%%%          End of LEMMA          %%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

From Lemma~\ref{l:unbiased}, the unbiased estimator is now
%
\begin{equation}
    \vchy = \mtfnH^{\text{nv}}(\mtS) \big( \vcx - \vcmu_{x} \big) + \vcmu_{\rho}.
\end{equation}
%
Therefore, the objective becomes finding the filter tap matrix $\mtH \in \fdR^{N \times (K+1)}$ for some fixed value of $K$ that satisfies
% eq:approx
\begin{equation} \label{eq:approx}
    \mtH^{\opt} = \argmin_{\mtH \in \fdR^{N \times(K+1)}} \xp \Big[ \big\| \mtfnH^{\text{nv}}(\mtS) (\vcx-\vcmu_{x}) - \big(\fnrho(\vcx) - \vcmu_{\rho}\big) \big\|_{2}^{2} \Big].
\end{equation}
%
Note that, due to the orthogonal nature of the GFT, minimizing \eqref{eq:approx} is equivalent to minimizing the difference of the corresponding frequency responses.

The optimal filter taps for each node, i.e., the rows $\vch_{i}^{\opt} \in \fdR^{K+1}$ of $\mtH^{\opt}$ that solve \eqref{eq:approx}, can be obtained by solving a linear system of equations as follows.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%            PROPOSITION         %%%%  prop:NVGFoptimal
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
\begin{proposition}[Optimal NVGF] \label{prop:NVGFoptimal}
Let $\vcu_{i}$ denote the $i^{\text{th}}$ row of $\mtV$,  $\mtR_{i} = \mtLambda^{\Tr} \diag(\vcu_{i}) \vcV^{\Tr} \mtC_{x} \vcV \diag(\vcu_{i}) \mtLambda$ be the covariance matrix of the frequency response at node $\lmv_{i}$ for the input $\vcx$, and $\vcp_{i} = \mtLambda^{\Tr} \diag(\vcu_{i}) \vcV^{\Tr} \xp[(\fnrho(x_{i}) - \mu_{\rho i})(\vcx-\vcmu_{x})]$ denote the correlation between the filtered signal and the target nonlinearity. Then, a set of filter taps $\{\vch_{1}^{\opt},\ldots,\vch_{N}^{\opt}\}$ is optimal for \eqref{eq:approx} if and only if they solve the system of linear equations
% eq:NVGFoptimal
\begin{equation} \label{eq:NVGFoptimal}
    \mtR_{i} \vch_{i}^{\opt} = \vcp_{i}, \quad i\in\{1,\ldots,N\}.
\end{equation}
%
\end{proposition}
%%
%%%%       End of PROPOSITION       %%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

From Proposition~\ref{prop:NVGFoptimal}, it is immediate that only knowledge of the first and second moments of $\vcx$, and of the correlation between the input $\vcx$ and the output $\vcy = \fnrho(\vcx)$, is required to solve for the optimal NVGF. These moments can be estimated from training data. Also observed is that the optimal filter taps for each node can be computed separately at each node.

\ifundefined{arXiv}
\else
We now consider the specific case of random graph signals with zero-mean, independent, identically distributed (i.i.d.) entries, to illustrate the form of the optimal NVGF.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%               COROLLARY            %%%%  cor:unbiased
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
\begin{corollary}[Zero-mean, i.i.d., ReLU nonlinearity] \label{cor:ReLU}
Assume that the elements of $\vcx$ are i.i.d., and that $\vcmu_{x} = \vcZeros$ and $\mtR_{x} = \mtC_{x} = \sigma_{x}^{2} \mtI$ for some $\sigma_{x}^{2} > 0$. Consider an unbiased NVGF-based estimator of the form
\begin{equation} \label{eq:zero-meanEstimator}
    \schy_{i} = (\scxi^{2}/\sigma_{x}^{2}) x_{i} + \mu_{\rho}
\end{equation}
with $\scxi^{2} = \xp[\rho(x)x]$ and $\mu_{\rho} = \xp[\rho(x)]$, where $x$ is distributed as the elements of $\vcx$. Then, the estimator \eqref{eq:zero-meanEstimator} is optimal for \eqref{eq:approx}. If, additionally, $\rho(\cdot)=\ReLU(\cdot)$ and the distribution of $x$ is symmetric around $0$, then $\mu_{\rho}=0$ and $\scxi^{2} = \sigma_{x}^{2}/2$, so that \eqref{eq:zero-meanEstimator} reduces to $\schy_{i} = x_{i}/2$.
\end{corollary}
%%
%%%%          End of COROLLARY          %%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Corollary~\ref{cor:ReLU} shows that if the elements of the graph signal are zero-mean and i.i.d., then the NVGF boils down to a LSI graph filter. Hence, this optimal unbiased NVGF is not capable of generating frequencies. This is sensible since the elements of the graph signal $\vcx$ bare no relationship to the underlying graph support, and thus the NVGF does not leverage that support to create the appropriate frequencies. Furthermore, if the distribution of each element of $\vcx$ is symmetric around zero, then an optimal approximation of the $\ReLU$ nonlinearity amounts to a LSI graph filter that outputs half of the input, as one would expect.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%               COROLLARY            %%%%  cor:stationary
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
\begin{corollary}[Stationary graph processes] \label{cor:stationary}
Let $\vcx$ be a stationary graph process \cite{Perraudin2017-StationaryGSP, Marques2017-StationaryGSP}, so that $\vcmu_{x} = \vcZeros$ and $\mtR_{x} = \mtC_{x} = \mtV \diag(\vcq) \mtV^{\Tr}$ with power spectral density $\vcq \in \fdR^{N}$. Then, NVGF filter taps $\vch_i^{\opt}$ at node $\lmv_{i}$ solving the linear equations $\diag(\vcu_{i} \circ \vcq) \mtLambda \vch_{i}^{\opt} = \mtV^{\Tr} \xp [\rho(x_{i}) \vcx]$ are optimal.
\end{corollary}
%%
%%%%          End of COROLLARY          %%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

It is observed from Corollary~\ref{cor:stationary} that the effect of the contribution of each frequency component to node $\lmv_{i}$ gets modulated by the power spectral density $\vcq$. Also, the filter in this case is different for each node, and thus optimal unbiased NVGFs for processing stationary graph processes actually create frequencies.
\fi
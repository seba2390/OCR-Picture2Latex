% \vspace{3mm}
\section{Related Works}
\vspace{-1mm}

Deception detection has been explored on a wide range of applications, such as online dating services \cite{toma2010reading} \cite{guadagno2012dating}, social networks \cite{ho2013guess}, consumer reviews \cite{li2014towards} \cite{ott2011finding}, and court transcripts \cite{fornaciari2013automatic} \cite{perez2015deception}. Significant research findings have demonstrated a correlation between gender and deceit \cite{perez2015experiments}, as well as a connection between deception and cultural factors \cite{perez2014cross}. The majority of conducted experiments are predicated on a binary classification approach for analyzing input text, specifically distinguishing between deceptive and non-deceptive instances as explored by \cite{mbaziira2016text} and \cite{mihalcea2009lie}. To the best of our knowledge, there is currently no computational study that comprehensively defines and categorizes deception by drawing insights from psychology. In our paper, we introduce SEPSIS, which presents a novel definition and dataset aimed at tackling the issue of \emph{lies of omission} in language. We firmly believe that SEPSIS holds the potential for establishing a connection between deception and fake news, and we intend to explore this further.
%This research paper addresses the lack of attention given to defining deception detection. It takes a literary perspective to redefine deception detection and identifies the correlation with potential instances of fake news. Additionally, a dataset was created by scraping news tweets from Twitter and fake news sources, facilitating further exploration in this area.



%Despite the predominant emphasis on broadening the scope of Deception detection applications, there has been a notable lack of attention given to the fundamental concept of defining deception detection itself. In this study, we adopt a literary perspective to address this issue. Our research not only endeavors to redefine deception detection but also aids in the identification of potential instances of fake news. Based on these findings, we also prepared a dataset by scraping news tweets from Twitter and fake news data sources to promote further work in this domain.

\begin{comment}
For building NLP models for studying deception with multiple labels across different layers that are defined in previous sections, we have leveraged multi-task learning. In recent years, multitask learning has garnered significant attention from researchers across various domains, with numerous studies exploring its potential for enhancing performance, improving generalization, and promoting knowledge transfer in diverse tasks \cite{samghabadi2020aggression}, \cite{akhtar2019all}, \cite{akhtar2020multi}, \cite{collobert2008unified}, \cite{chauhan2020all}, \cite{kapil2020deep}, \cite{kumari2021multitask}. Specifically, in the realm of fact-verification, there are a couple of works that have used multitask learning \cite{kumari2021multitask}, \cite{li-etal-2018-end}. \cite{kumari2021multitask} used a deep multitask learning model to simultaneously addresses novelty detection, emotion recognition, sentiment prediction, and misinformation detection. Their approach utilized a combination of a BERT-based embedding layer and an LSTM-based encoder layer, which were connected to four task-specific heads. \cite{li-etal-2018-end} utilized multitask learning to classify statements as "supports," "refutes," or "not enough info" based on retrieved pages while also detecting evidence sentences. They employed a bi-directional LSTM and an attention mechanism in their encoder architecture.

\cite{da2019fine} proposed a new approach to analyzing texts at a fragment level to detect propaganda techniques and classify them into $18$ types. They also introduced a neural network model that outperforms existing BERT-based baselines to detect propaganda techniques. Other works by \cite{barron2019proppy} presented \emph{proppy}, the first publicly available real-world, real-time propaganda detection system for online news, which aimed at raising awareness, thus potentially limiting the impact of propaganda and helping fight disinformation. 

\end{comment}


%feedback from dr das - 
%1. classical work by rada
%2. nobody gave a formal definition for deception
%3. we are first to define deception and study omission through the presence of 5W
%4. Generate data using 5W masking technology

%5. MTL
%related work on prompt engineering and mask infilling- 2lines
% something is missing, we cant directly introduce propaganda here-2lines
%We are proposing a formal definition of deception \vjt{and establishes a connection between deception detection and propaganda theory in a subsequent section.}
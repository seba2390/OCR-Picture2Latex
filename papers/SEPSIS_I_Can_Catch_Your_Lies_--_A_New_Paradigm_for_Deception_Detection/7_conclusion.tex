\vspace{-1mm}
\section{Conclusion and Future Avenues}
\vspace{-1mm}

% New version


We have introduced SEPSIS, a novel multi-layered corpus focused on lies of omission. Furthermore, our MTL framework leverages recent advances in language model fine-tuning and dataless merging to optimize deception detection, achieving a 0.87 F1 score. Finally, we have uncovered compelling relationships between propaganda techniques and lies of omission through empirical analysis. The public release of our dataset and models will catalyze future research on this complex societal phenomenon.
\begin{comment}
The paper's contribution can be summarized as follows: \emph{(i) this paper presents a pioneering study on the phenomenon of \ul{lies of omission}}. \emph{(ii) it introduces the SEPSIS corpus and associated resources}, \emph{(iii) the SEPSIS corpus (876,784 data points) incorporates four layers of annotation, including type, color, intention, and topic}, \emph{(iv) the paper introduces an MTL pipeline for SEPSIS classification}, \emph{(v) the MTL pipeline leverages the dataless merging of fine-tuned Language Models (LMs)}, \emph{(vi) it incorporates a tailored loss function specific to each layer, addressing different subproblems}, \emph{(vii) finally, the paper reveals a significant correlation between deception and propaganda techniques.}
%\ac{all of this should be part of the contributions box. the conclusion should be re-written.}
\end{comment}

%In this paper, we presented our experiments for detecting and categorizing deception. We targeted detecting deception in headlines of tweets and fake news. In real settings, this can be useful to understand the intention behind any deceptive text and the reason for the lie. Apart from that these deceptive texts also propagate certain propaganda, especially during events like elections. We curated a new deception dataset called \emph{"SEPSIS"} which will help with this study.
%We firmly believe that SEPSIS will have a substantial impact on various domains. To highlight one, it emphasizes the critical need to enhance the precision and reliability of automated fact-checking systems, thereby improving the transparency of journalism in the future. 

%In our investigation, our introduction of an annotated corpus holds significant promise for the advancement of deception detection. To the best of our knowledge, we are the pioneering contributors to define this concept through the lens of psychology, proposing techniques such as paraphrasing and 5W mask infilling to augment the deceptive data. Moreover, the section correlating propaganda theory and deception provides additional evidence supporting behavioral cues indicative of lying through language. Our application towards merging fine-tuned LLMs for MTL, via tailoring sub-task specific loss functions proved innovative. We will make the generated datasets and resources, comprising  876,784 data points, publicly available for research purposes. This study underscores the imperative of improving precision and reliability for the future of journalism by enhancing the transparency of automated fact-checking systems.

% Original version
% In our investigation, the introduction of an annotated corpus focusing on lies of omission holds significant promise for the advancement of deception detection. To the best of our knowledge, we are the pioneering contributors to define this concept through the lens of psychology, proposing techniques such as paraphrasing and 5W mask infilling to augment the deceptive data. Moreover, the section on the correlation between propaganda and deception provides additional evidence supporting behavioral cues indicative of lying through language. Our application towards merging fine-tuned language models for MTL, tailoring sub-task specific loss function proved innovative. We will make the generated datasets and resources, comprising  876,784 data points, publicly available for research purposes. This study underscores the imperative of improving the precision and reliability for the future of journalism by enhancing the transparency of automated fact-checking systems.

% This study not only has far-reaching implications for the future of journalism and can enhance the transparency of automated fact-checking systems.

% It underscores the imperative for improved precision and reliability in detecting intentional omissions in various media domains, ultimately fostering accountability.
\section{Discussion and Limitations}
\vspace{-1mm}
In this section, we self-criticize a few aspects that could be improved and also detail how we (tentatively) plan to improve upon those specific aspects-
\subsection{Categorization of deception}
We have considered the four layers and categories based on our understanding of the psychological framework and going manually through multiple samples to understand the type, intent, topic, and colors of lie. However, this list may not be exhaustive. This is the reason for us to have put an \textit{others} category in the topic of lies. Categories could increase when categorizing deception in real life.

\subsection{Data Augmentation}
We used paraphrasing and mask infilling for building the sepsis corpus. However, we understand that a few generations might not be deceptive and could have generated non-deceptive texts. However, we have done extensive manual testing, and believe such cases are nominal. 

\subsection{SEPSIS Classifier}

One of the limitations of the SEPSIS Classifier is the computational heaviness associated with fine-tuning the T5 model for each specific layer. This process requires considerable computational resources and time. As the T5 models need to be finetuned for each task head, so total computational time increase significantly with an increase in the number of task head. It is important to consider these computational limitations when implementing multi-task learning architectures, as they can impact the feasibility and scalability of the approach, particularly in scenarios with limited computational resources or a large number of output tasks.



\section{Ethical Considerations}

%Through our experiments, we have uncovered the susceptibility of LLMs to hallucination. In developing HVI, we intend to provide a framework that can inform future research and policies in this domain. However, we must address the potential misuse of our findings by malicious entities who may exploit AI-generated text, such as creating indistinguishable fake news from human-written content. We vehemently discourage such misuse and strongly advise against it.

Through this framework, we propose models to classify deception. We also developed a large augmented deceptive dataset. However, we must address the potential misuse of the dataset and models by entities who may exploit the framework to generate deceptive texts such as creating fake news by manipulating the content. The deliberate dissemination of deceptive news, spreading propaganda techniques to shape public opinion, is also a significant concern. We vehemently discourage such misuse and strongly advise against it.





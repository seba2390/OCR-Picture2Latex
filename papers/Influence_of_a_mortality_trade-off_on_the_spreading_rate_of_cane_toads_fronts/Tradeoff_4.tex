\documentclass[11pt]{article}    % Specifies the document style.
\usepackage{amsmath, amssymb, amsthm,pdfsync}
\usepackage{fullpage}
\usepackage{verbatim}
%\usepackage{cite}
\usepackage{graphicx}
\usepackage{subfig, caption}
\usepackage{cancel}
%\usepackage{layouts}
\usepackage{enumitem}
\usepackage{wrapfig}
\usepackage{mathtools}
\usepackage{xcolor}
\usepackage{epigraph}
\usepackage{cleveref}
\usepackage{overpic}
\usepackage{esint}
\usepackage{dsfont}
\usepackage{color}

\newcommand{\pdr}[2]{\dfrac{\partial{#1}}{\partial{#2}}}
\newcommand{\pdrr}[2]{\dfrac{\partial^2{#1}}{\partial{#2^2}}}
\newcommand{\pdrt}[3]{\dfrac{\partial^2{#1}}{\partial{#2}{\partial{#3}}}}

%\usepackage[notref,notcite]{showkeys}

\tolerance = 1500
\hoffset = 0pt
\voffset = 0pt
\textwidth = 470pt
\textheight = 640pt
\topmargin = 0pt
\headheight = 0pt
\headsep = 0pt
\oddsidemargin = 0pt
\evensidemargin = 0pt
\marginparwidth = 10pt
\marginparsep = 10pt
\pagenumbering{arabic}
\newcommand{\EB}[1]{\textcolor{blue}{#1}}
\newcommand{\farc}{\frac}

% LABELS SHOWN IN MARGINS
%  \usepackage[notref,notcite]{showkeys}
%  \textwidth 5.5 in
 % \oddsidemargin .35 in


%\usepackage{xcolor}

\setlist[itemize]{itemsep=-1mm}

%\textheight 22.5cm
%\topmargin -1.5cm
%%\textwidth 18.8cm
%\hsize \textwidth
%\advance \hsize by -\marginparwidth
%%\oddsidemargin -20mm
%%\evensidemargin \oddsidemargin
%%\usepackage{amsmath}    % remove % for AMS-LaTeX
%%\usepackage{amssymb}
%%\advance\hoffset by 8mm

%\renewcommand{\baselinestretch}{1.0}

%\usepackage[T1]{fontenc}

%\usepackage{hyperref}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{lem}[theorem]{Lemma}
\newtheorem{prop}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{rem}[theorem]{Remark}
\newtheorem{notation}[theorem]{Notation}
\newtheorem{hypothesis}[theorem]{Hypothesis}


%\renewcommand{\thesection}{\arabic{part}.\arabic{section}}
\renewcommand\thesubsection{\thesection.\arabic{subsection}}
\renewcommand{\theequation}{\arabic{section}.\arabic{equation}}

% For nice indicator functions
\usepackage{dsfont}    \newcommand{\1}{\mathds{1}}

% Control of lists...
\usepackage{enumitem}
\setlist{nolistsep}


\newcommand{\PP}{\mathbb{P}}
\newcommand{\EE}{\mathbb{E}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\Sph}{\mathbb{S}}
\newcommand{\Id}{\mathrm{Id}}
\newcommand{\bP}{\mathbf{P}}
\newcommand{\bC}{\mathbf{C}}
%\newcommand{\supp}{\mathrm{supp}\,}
\newcommand{\dist}{\mathrm{dist}\,}
\newcommand{\trace}{\mathrm{trace}\,}
\newcommand{\sign}{\mathrm{sign}\,}
\newcommand{\ind}[1]{\mathbf{1}_{#1}\,}



\newcommand{\cG}{\mathcal{G}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\K}{\mathbb{K}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\grad}{\overrightarrow{\nabla}}
\newcommand{\rot}{\overrightarrow{\nabla}\wedge }
\newcommand{\dive}{\overrightarrow{\nabla}. }
\newcommand{\lapl}{\Delta}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\e}{\varepsilon}
\renewcommand{\epsilon}{\varepsilon}
\newcommand{\eps}{\varepsilon}

%%
%\setlength{\oddsidemargin}{0mm}
%\setlength{\evensidemargin}{0mm}
%\setlength{\topmargin}{15mm}
%\setlength{\textheight}{21cm}
%\setlength{\textwidth}{16cm}
%\renewcommand{\baselinestretch}{1.2}
%\parindent 10pt
%%
\newcommand {\al} {\alpha}
%\newcommand{\e}{\varepsilon}
\newcommand {\da} {\delta}
\newcommand {\sg} {\sigma}
\newcommand {\vp} {\varphi}
\newcommand {\lb} {\lambda}
\newcommand {\Chi} {{\bf \raise 2pt \hbox{$\chi$}} }
%
\newcommand {\f}   {\frac}
\newcommand {\p}   {\partial}
\newcommand {\dt}   {\Delta t}
\newcommand {\sgn} { {\rm sgn} }
\newcommand {\dv}  { {\rm div} }
%
\newcommand {\caa} { {\cal A} }
\newcommand {\cad} { {\cal D} }
\newcommand {\cas} { {\cal S} }
\newcommand {\dtx} {\cad ^\prime (\cR^+\times \cR^d)}
\newcommand {\cH}  {{\cal H}}

\DeclareMathOperator{\argmin}{argmin}
\DeclareMathOperator{\Real}{Re}
\DeclareMathOperator{\Imag}{Im}
\DeclareMathOperator{\Vol}{Vol}
\newcommand{\supp}{\mathrm{supp}\,}

%\numberwithin{equation}{section}
%\numberwithin{theorem}{section}



%Makes 'assumption' open to use with cleveref
\Crefname{assumption}{Assumption}{Assumptions}
\Crefname{theorem}{Theorem}{Theorems}
\Crefname{lemma}{Lemma}{Lemmas}
\Crefname{corollary}{Corollary}{Corollaries}
\Crefname{proposition}{Proposition}{Propositions}
\Crefname{theorem}{Theorem}{Theorems}
\Crefname{conjecture}{Conjecture}{Conjectures}
\Crefname{hypothesis}{Hypothesis}{Hypotheses}








\title{Influence of a mortality trade-off on the spreading rate of cane toads fronts}
\date\today                                           % Activate to display a given date or no date
\author{Emeric Bouin\,
\footnote{CEREMADE - Universit\'e Paris-Dauphine, UMR CNRS 7534, PSL Research University, Place du Mar\'echal de Lattre de Tassigny, 75775 Paris Cedex 16, France. E-mail: \texttt{bouin@ceremade.dauphine.fr}}\; 
\and
Matthew H. Chan\footnote{School of Mathematics and Statistics, 
University of Sydney, NSW 2006, Australia. E-mail:
\texttt{M.Chan@maths.usyd.edu.au}}\;
\and
Christopher Henderson\footnote{Corresponding author} \footnote{Department of Mathematics, the University of Chicago, Chicago, IL 60637, E-mail: \texttt{henderson@math.uchicago.edu}}\;
\and
Peter S. Kim \footnote{School of Mathematics and Statistics, University of Sydney, Australia. E-mail:
\texttt{peter.kim@sydney.edu.au}}\;
}






\begin{document}
\maketitle

\begin{abstract}
\noindent We study the influence of a mortality trade-off in a nonlocal reaction-diffusion-mutation equation that we introduce to model the invasion of cane toads in Australia. This model is built off of one that has attracted attention recently, in which the population of toads is structured by a phenotypical trait that governs the spatial diffusion. We are concerned with the case when the diffusivity can take unbounded values and the mortality trade-off depends only on the trait variable. Depending on the rate of increase of the penalization term, we obtain the rate of spreading of the population. We identify two regimes, an acceleration regime when the penalization is weak and a linear spreading regime when the penalization is strong. While the development of the model comes from biological principles, the bulk of the article is dedicated to the mathematical analysis of the model, which is very technical.  The upper and lower bounds are proved via the Li-Yau estimates of the fundamental solution of the heat equation with potential on Riemannian manifolds and a moving ball technique, respectively, and the travelling waves by a Leray-Schauder fixed point argument.  We also present a simple method for {\em a priori} $L^\infty$ bounds.
%In this paper, we study the influence of the mortality trade-off in a cane-toad equation, a nonlocal reaction-diffusion-mutation equation modelling the invasion of cane toads in Australia that has attracted attention recently. The population of toads is structured by a phenotypical trait that governs the spatial diffusion. We are concerned with the case when the diffusivity can take unbounded values and the mortality trade-off depends only on the trait variable. Depending on the rate of increase of the penalization from the trade-off as diffusivity approaches infinity, we obtain the rate of spreading of the population. We identify two regimes, an acceleration regime when the penalization is weak and a linear spreading regime when the penalization is strong.
\end{abstract}
%\begin{abstract}
%Cet article étudie l'influence d'une pénalisation sur la mortalité dans une equation de réaction-diffusion-mutation non locale, introduite pour modéliser l'invasion des crapauds buffles en Australie. Le modèle ci-étudié est construit à partir d'un modèle précédent qui a suscité beaucoup d'intérêt récemment, dans lequel la population de crapauds est structurée par un trait phénotypique: la diffusivité. Nous sommes intéressés ici par le cas ou les traits peuvent être non bornés, et ou la pénalisation ne dépend que du trait phénotypique. En fonction du taux de croissance à l'infini de cette pénalisation, nous caractérisons la loi d'expansion de la population. Deux régimes apparaissent : un régime d'accélération lorsque la pénalisation est faible, et un régime de propagation linéaire lorsque la pénalisation est forte. Après quelques rappels du contexte biologique aboutissant à la considération de ce modèle, nous nous focalisons sur son analyse mathématique. Les bornes par dessous et par dessus sont respectivement prouvées à l'aide d'une technique dite "de boule glissante" et d'estimations a priori de type Li-Yau pour la solution fondamentale d'une équation de la chaleur avec potentiel. Les ondes progressives sont construites par un argument de point fixe de type Leray-Schauder. Des estimations uniformes sur le problème de Cauchy sont aussi présentées. 
%\end{abstract}
%\section{}
%\subsection{}
\noindent{\bf Key-Words:} {Structured populations, reaction-diffusion equations, front acceleration}\\
\noindent{\bf AMS Class. No:} {35Q92, 45K05, 35C07}

%{\color{blue}  EMERIC -- Comments in blue are made independent of the referees (they are my own suggestions in order to clean things up, correct typos or errors that I found, or to save some space).  Comments in red are changes made that are due to the referees suggestions.}
%
\section{Introduction}
\subsection{Model and biological background}

The invasion of cane toads in Australia has singular features that are much different from standard spreading observed in most other
species. Data from field biologists \cite{phillips2006invasion, Shine} show that the invasion speed has steadily increased 
during the eighty years since the toads were introduced in Australia.  Moreover, they found that toads at the edge of the front have much longer legs.  This is just one example of a non-uniform space-trait 
distribution (see also the expansion of bush crickets in Britain~\cite{Thomas}). The current biological literature now states that this is due to "spatial sorting": the offspring produced at the edge of the front appear to have higher mean dispersal rate. 

It has been demonstrated by biologists that increased dispersal is often associated with reduced investment in reproduction, for example in populations of the peckled wood butterfly, \textit{Pararge aegeria} \cite{Hughes}. Some physiological description of this trade-off between dispersal and fecundity has been reported in \cite{Mole}. There, two morphs of the cricket \textit{Gryllus rubens} (Orthoptera, Gryllidae) are studied: a fully-winged (flight-capable morph) and a short-winged morph (that cannot fly).  It turns out that the short-winged morph is substantially more fecund than the fully-winged one. This widespread occurrence of dispersal polymorphisms among insects is consistent with the fact that fitness costs are associated with flight capability. It is now well documented that for both males and females (for example for the planthopper \textit{Prokelisia dolus}) there is a strong trade-off between flight capability and reproduction \cite{Langellotto}. See also \cite{Guerra} where the physiological differences between the male and female of two morphs of crickets that may lead to such a trade-off are discussed. We refer to \cite{Bonte} for an extensive review on the different cost types that occur during dispersal in a wide array of organisms, ranging from micro-organisms to plants and invertebrates to vertebrates.

%Several works have addressed the  front 
%invasions in ecology, where the trait is related to the
%dispersal ability \cite{ArnoldDesvillettesPrevost,ChampagnatMeleard}. It has been observed
%that selection of more mobile individuals can occur, even if they have no advantage 
%in their reproductive rate, due to the spatial sorting 
%\cite{Kokko,phillips2006invasion,Ronce,Simmons}.

In view of these biological issues, we are interested in the influence of a mortality trade-off on the rate of spreading of a structured population.  Namely, our goal is to estimate of the effect of this penalization; that is, depending on the strength of the trade-off, does the population go extinct or still propagate, and in the latter case, what is the effect on the acceleration seen in~\cite{BerestyckiMouhotRaoul,BHR_Acceleration}?

To answer these questions, we focus on a cane toads equation with mortality trade-off. This is a nonlocal reaction-diffusion-mutation equation that is a refinement of the now standard cane-toad equation proposed in~\cite{BenichouEtAl} and investigated in~\cite{BerestyckiMouhotRaoul,BouinCalvez,BHR_LogDelay,BHR_Acceleration,Turanova} (see also \cite{ArnoldDesvillettesPrevost, BouinMirrahimi, ChampagnatMeleard, LamLou, %MirrahimiPerthame,
PerthameSouganidis} for similar studies).  We now introduce this model. 
%The model is an equation of Fisher-KPP type \cite{Fisher,KPP}.  
The population density $n$ is structured by a spatial variable, $x\in \R$, and a 
motility variable $\theta\in \overline\Theta$, where $\Theta\stackrel{\rm def}{=}(\underline\theta, \infty)$, with a  fixed   $\underline\theta>0$. The spatial diffusivity is  exactly $\theta$, representing the effect of the variable motility on the spreading rates of the species.
This population may reproduce, with a free growth rate $r$, in such a way that a parent gives its trait to its offspring up to phenotypical mutations (that is, mutations on the motility variable), that are modelled here with a diffusion in the trait variable $\theta$, with a variance $\sigma^2$. In addition, each toad competes locally in space with all other individuals for resources. This introduces the nonlocality in the model. Finally, and this is the specificity of this paper, we take into account a mortality trade-off, denoted by $m$, that penalizes high traits for reproduction. We are thus led to considering the following problem:
%
\begin{equation*}
\begin{cases}
n_t = \theta n_{xx} + \alpha n_{\theta\theta} + r n \left( 1 - m(\theta) - \rho\right), &\qquad (t,x,\theta) \in \R^+ \times \R \times \Theta,\\
n_\theta(t,x,\underline\theta) = 0, & \qquad (t,x) \in \R^+ \times \R. 
\end{cases}
\end{equation*}
where the total population at time $t$ and position $x$ is
\begin{equation*}\label{eq:rho}
\rho(t,x)=\int_{\underline\theta}^\infty n(t,x,\theta)d\theta.
\end{equation*} 
The trait diffusivity is $\alpha = r \sigma^2$. The equation is complemented with Neumann boundary conditions at $\theta = \underline\theta$, since lower traits should not be reachable. After a suitable rescaling, one can reduce the problem to studying the equation with $\alpha = 1$ and $r=1$.  The resulting equations are
\begin{equation}\label{eq:main}
\begin{cases}
n_t = \theta n_{xx} + n_{\theta\theta} +  n \left( 1 - m(\theta) - \rho\right), &\qquad (t,x,\theta) \in \R^+ \times \R \times \Theta,\\
n_\theta(t,x,\underline\theta) = 0, & \qquad (t,x) \in \R^+ \times \R. 
\end{cases}
\end{equation}
We now describe the class of trade-off terms $m$ that we consider in this paper.
%
\begin{hypothesis}\label{hyp:m} We assume that $m$ depends only on $\theta$, that $m(\underline\theta) = 0$ and that $m \in \mathcal{C}^2(\overline \Theta)$ increases to $+\infty$ as $\theta$ tends to $\infty$. Moreover, we suppose that $\lim_{\theta\to\infty} m(\theta)/\theta$ exists and is an element of $\R^+\cup\{+\infty\}$ and that if $m(\theta)/\theta$ tends to zero as $\theta$ tends to $+\infty$, then $m'' \in L^\infty\left(\overline\Theta\right)$ and there exists $\theta_d > \underline\theta$ such that $m(\theta)/\theta$ is decreasing for all $\theta \geq \theta_d$.
%\begin{enumerate}
%\item $m \in \mathcal{C}^2(\overline\Theta)$,
%\item $m(\underline \theta) = 0$, 
%\item $m$ is increasing.
%\item $\lim_{\theta \to \infty} m(\theta) = +\infty$,
%\item If $\lim_{\theta \to \infty} m(\theta)/\theta = 0$, then $\theta \mapsto m(\theta)/\theta$ is decreasing.
%\end{enumerate}
\end{hypothesis}
Importantly, we point out that the fact that $m$ tends to infinity gives a positive growth rate to only small values of $\theta$. For the entirety of this work, we assume that $m$ always satisfies~\Cref{hyp:m}.  An important class of examples of $m$ satisfying~\Cref{hyp:m} are $m(\theta) = C(\theta^p - \underline\theta^p)$ for $C, p > 0$.

Our main question for the rest of this work is, if $n(0,\cdot) \equiv n_0$ is a nonzero, nonnegative initial condition such that there exists $C_0 > 0$ such that 
%\CH{EMERIC - SHOULD we just change $n_0$ to be nonzero and such that $n_0 \leq C_0 \1_{[-\infty,C_0]\times [\underline\theta,\underline\theta+C_0]}$?  Otherwise the condition~\eqref{eq:n_0} is in contradiction with the assumptions of \Cref{prop:extinction}...}
\begin{equation}\label{eq:n_0}
%	\frac{1}{C_0} \1_{[\underline\theta, \underline\theta+\frac{1}{C_0}]\times[-\infty, -C_0]}
%		\leq 
		n_0 \leq C_0 \1_{[\underline\theta, \underline\theta+C_0]\times[-\infty,C_0]},
\end{equation}
then at what speed does the population $n$ propagate?

A related model for a host-parasite system with mortality trade-off has been discussed numerically and formally by Chan \textit{et al.}~in \cite{Chan}. The results there confirm  observations made in empirical and agent-based studies that spatial sorting can still occur with a disadvantage in reproductivity and/or survival in more motile individuals. Moreover, we find that such a disadvantage in reproductivity and/or survival is unlikely to be large if spatial sorting is to have a noticeable effect on the rate of range expansion, as it has been observed to have over the last 60 years in northern Australia. The results of the present paper prove these findings and enlighten them quantitatively.   



\subsection{Heuristics and main results}

\subsubsection*{A condition for non extinction} 

In order to expect propagation at any speed, the average growth rate $\gamma_\infty$ in time should be positive. This is necessary to expect any positive steady state at the back of a traveling front. In other words, letting $Q$ and $\gamma_\infty$ be the principal eigenfunction and eigenvalue of the linearized equation
\begin{equation}\label{eq:specQ}
\begin{cases}
Q'' +  (1 - m) \, Q  = \gamma_\infty Q, \qquad \text{on } \Theta,\\
Q'\left(\underline \theta \right) = 0,~~~ Q > 0,
\end{cases}
\end{equation}
we expect propagation {\em only} in the case that $\gamma_\infty>0$.  Notice that, since $m \geq 0$ and $m\not\equiv 0$, $\gamma_\infty < 1$.  The sign of $\gamma_\infty$ does not depend strongly on the growth of $m$ at $\infty$, but on having sufficiently many traits with sufficiently large growth rates\footnote{Indeed, consider the following simple example.  When $m(\theta) = \sigma^2 (\theta-\underline\theta)^2$ for any $\sigma>0$, one can find the principal eigenfunction and eigenvalue explicitly: $Q(\theta) = \exp\{- \sigma(\theta-\underline\theta)^2/4\}$ and $\gamma_\infty = 1-\sigma$.  Though, for any value of $\sigma>0$, $m$ has quadratic growth, $\gamma_\infty$ can be positive or negative depending on $\sigma$.}.  Our expectation above is confirmed by the following:
%The pair $(Q,\gamma_\infty)$ is well-defined, and if $\gamma_\infty \leq 0$ then $n$ tends uniformly to zero.  

\begin{prop}\label{prop:extinction}
Suppose that $\gamma_\infty \leq 0$ and $\supp(n_0)$ is compact.  Then
\begin{equation*}
\lim_{t \to \infty} \sup_{(x,\theta)\in\R\times \Theta} n(t,x,\theta) = 0.
\end{equation*}
\end{prop}


We also note that, when $Q$ is normalized with $\int_{\Theta} Q(\theta) \, d\theta = \gamma_\infty$ and $\gamma_\infty > 0$, this eigenvector is expected to be the limit of the population density behind the front. 



\subsubsection*{The linear propagation regime}

In the case of non-extinction, i.e.~when $\gamma_\infty > 0$, one may expect propagation of the initial population.  A first attempt in this direction is to look for travelling waves. Since the problem is of Fisher-KPP type, we may expect at first glance that any travelling front is a pulled front. As a consequence, in order to compute the possible speed of propagation of such a front, we follow the classical strategy by linearizing \eqref{eq:main} around $0$ and looking for solutions of the form $e^{-\lambda(x-c_\lambda t)} Q_\lambda(\theta)$.  For any given $\lambda > 0$,  we apply the Krein-Rutman theorem to solve the spectral problem
\begin{equation}\label{eq:specQlambda}
\begin{cases}
		Q_\lambda'' + \left[  \lambda^2 \theta - \lambda c_\lambda + (1 -  m(\theta)) \right] Q_\lambda  = 0, &\qquad \theta \in \Theta, \\
Q_\lambda' \left( \underline \theta \right) = 0, \qquad Q_\lambda > 0&
\end{cases}
\end{equation}
when $m$ increases sufficiently quickly. 
%
%gives a solution $(c_\lambda,Q_\lambda)$ to the spectral problem
%
%
%where $Q_\lambda$ and $c_\lambda$ are unknowns, may be solved.  Since $Q_\lambda$ is positive, we expect it to be convex near $\infty$.  This may happen if and only if $m(\theta) - \lambda^2 \theta \to \infty$.  
This leads to the following theorem. 
%{\color{blue} I WANT TO UPGRADE THIS TO A THEOREM BECAUSE TAKIS WAS GIVING ME A HARD TIME ABOUT IT WASTING TOO MUCH TIME BUT NOT BEING IMPORTANT -- IF WE DO THIS, WE HAVE TO MAKE NOTE OF IT IN THE REFEREE REPORT}
\begin{theorem}\label{prop:tw}
Suppose that $m$ satisfies \Cref{hyp:m}, that $\gamma_\infty > 0$ and that $\lim_{\theta \to \infty} m(\theta)/\theta$ is positive. Then \eqref{eq:main} admits a travelling wave solution $(c^*,\mu)$, with $c^*$ defined in \Cref{sec:tw}.  In other words $n(t,x,\theta) = \mu(x-c^*t,\theta)$ solves~\eqref{eq:main}, with $c^* >0$, and
	\begin{equation}\label{eq:limits_of_wave}
		\liminf_{\xi\to-\infty} \mu(\xi,\underline\theta)
			> 0
			\qquad\text{ and }\qquad
			\lim_{\xi\to\infty} \sup_{\theta\in\Theta} \mu(\xi,\theta) = 0.
	\end{equation}
\end{theorem}

As with the standard Fisher-KPP equation, we expect this speed $c^*$ to be the minimal speed in the sense that if $c \geq c^*$, then there is a travelling wave of speed $c$.  Since this is not our main interest, we do not address it here.

Our main interest is in a spreading result for the Cauchy problem \eqref{eq:main}. We thus ask whether the travelling wave constructed in \Cref{prop:tw} is stable.  This is answered by the following theorem.
\begin{theorem}\label{thm:cauchy_finite}
	Suppose the conditions of \Cref{prop:tw} hold. Suppose that $n$ solves~\eqref{eq:main} with initial conditions satisfying~\eqref{eq:n_0}.  Then there exists $\underline n>0$ such that for every $\epsilon >0$, we have
	\[
		\liminf_{t\to\infty} \inf_{|x|\leq (c^*-\epsilon)t} n(t,x,\underline\theta) \geq \underline n,
			\qquad\text{ and }\qquad
			\lim_{t\to\infty}\sup_{x\geq (c^* + \epsilon)t} \sup_{\theta \in\Theta} n(t,x,\theta) = 0.
	\]
\end{theorem}
This type of result is standard going back to~\cite{AronsonWeinberger2} in the local Fisher-KPP setting. Since the dynamics of the solution are so complicated, it would be interesting to obtain more precise estimates on the propagation speed.  We expect a logarithmic delay {\em a la} Bramson, see~\cite{BHR_LogDelay} for the delay in the cane toads equation and references therein for more general settings.

We briefly outline the proofs of \Cref{prop:tw} and \Cref{thm:cauchy_finite} and the main difficulties that we have to face.  The construction of a travelling wave solution with minimal speed of \Cref{prop:tw} is done by building a solution to an approximate problem on a finite ``slab'' by a degree theory fixed point argument. This construction appears to be a non-trivial extension of the one for the cane toads equation with bounded traits \cite{BouinCalvez}. In particular, our proof differs from the usual procedure in \cite{BouinCalvez} because we have both unbounded diffusivity and unbounded growth rates. In this direction, we also point out connections to \cite{AlfaroBerestyckiRaoul,AlfaroCovilleRaoul,BerestyckiJinSilvestre},  where travelling waves for structured models were constructed.  The proof of the spreading result in \Cref{thm:cauchy_finite} proceeds as follows. We directly construct a super-solution of $n$ using~\eqref{eq:specQlambda}, which provides the upper bound. %After a slight modification, we use the above procedure to build a travelling wave solution to a related analogous local problem, which, using a local-in-time Harnack inequality, provides a super-solution, and thus an upper bound.
The lower bound follows by building a solution to a related problem on a moving ball to using the intermediate steps of the construction of the travelling wave and applying a local-in-time Harnack inequality to compare this to $n$. This is a simpler version of the kind of procedure described in greater length in the next section.


The proof of \Cref{prop:tw} is in \Cref{sec:tw} and the proof of \Cref{thm:cauchy_finite} is in \Cref{sec:cauchy_finite}.




\subsubsection*{The acceleration regime}

The condition for the existence of travelling waves may be roughly re-written as $m$ is at least linear. On the other hand, when $m$ is sub-linear and $\gamma_\infty>0$, we still expect propagation. Since the spectral problem \eqref{eq:specQlambda} is not solvable, we may expect an acceleration phenomenon exactly as for the cane toads equation \cite{BCMetal,BHR_Acceleration}.  Before stating our main result, we give some heuristics that make it appear naturally.  Returning to the linearized equation  
\begin{equation}\label{eq:linearized}
	\overline n_t = \theta \overline n_{xx} + \overline n_{\theta\theta} + \overline n(1 - m(\theta))
\end{equation}
and recalling the definition of the pair $(\gamma_\infty,Q)$, we see that a function of the form $\overline{n} \propto Q(\theta) e^{\gamma_\infty t}$ solves \eqref{eq:linearized}. This gives a first bound of spreading in the direction $\theta$. Indeed, by writing $\psi = -\log(Q)$, one may check that $\psi$ satisfies $-\psi'' + |\psi'|^2 + (1-m) = \gamma_\infty$ and hence%
%
%
%
\footnote{To see the lower bound: let $R = \psi'$. Then $R$ satisfies $R' = R^2 + \left( 1 - \gamma_\infty - m \right)$ for $\theta > \underline{\theta}$ and $R(\underline{\theta}) = 0$. For $\theta \leq m^{-1}(1-\gamma_\infty)$, $R$ is increasing, and thus positive. For $\theta > m^{-1}(1-\gamma_\infty)$, $R$ satisfies $R' = R^2 - R_0^2$, with $R_0 = \left(m - \left(1 - \gamma_\infty\right)\right)^\frac12$. One can see that $R$ can not cross the curve $R_0$. Indeed, if it did, $R$ would become decreasing with $R'$ tending to $-\infty$, and thus negative for sufficiently large $\theta$, which is impossible since $Q$ is integrable. We thus get that $\psi(\theta) \geq \int_{\underline{\theta}}^\theta \left[\max\left( 0 , m(s) - \left(1 - \gamma_\infty\right) \right) \right]^\frac12 \, ds$. %
%
%
To see the upper bound: fix $\epsilon>0$, write $R = \mu\sqrt{m}$, and observe $\mu' \sqrt m = (\mu^2 -1)m + 1- \gamma_\infty - \mu m'/(2\sqrt m)\geq (\mu^2-1)m + 1-\gamma_\infty - \epsilon \mu^2 - C_\epsilon(m'/\sqrt m)^2$.  Choose $\theta_\epsilon$ such that, if $\theta \geq \theta_\e$, then $C_\epsilon (m'/\sqrt m)^2 < 1-\gamma_\infty$ and $m > 2(1+\epsilon)$.  Then if, for any $\theta \geq \theta_\epsilon$, $\mu(\theta) \geq \sqrt{1+\epsilon}$, after some computation we see that $\mu' \geq \epsilon \mu^2 \sqrt{m} / (2(1+\epsilon))$ and $\mu$ blows up at a some $\theta_b> \theta_\epsilon$.  This implies that $Q$ has an interior zero at $\theta_b$.  This is a contradiction, implying that $\mu \leq \sqrt{1+\epsilon}$ for all $\theta \geq \theta_\e$.  The estimate follows.},
%
%
%
%
as $\theta\to\infty$,

%\footnote{To see this, let $R(\theta) = \psi(\theta) - \int_{\underline \theta}^\theta \sqrt{m(s)}ds$.  Letting $r = R'$, then $r' - r^2 - 2\sqrt m r = (1-\gamma_\infty) - m'/2\sqrt m$.  For $\theta$ sufficiently large and $A$ sufficiently large (resp.~small), $-A/\sqrt m$ is a sub-solution (resp.~super-solution) of $r$. Here we use that $1-\gamma_\infty > 0$.  Integrating these bounds on $r$ yields the error term in~\eqref{eq:Q_asymptotics}.}
%\begin{equation}\label{eq:psi}
%-\psi'' + |\psi'|^2 + (1-m) = 0, \qquad \theta \in \Theta,
%\end{equation}
%from which follows that, as $\theta$ tends to infinity,
\begin{equation}\label{eq:Q_asymptotics}
%	\psi(\theta) \geq \int_{\underline{\theta}}^\theta \left[\max\left( 0 , m(s) - \left(1 - \gamma_\infty\right) \right) \right]^\frac12 \, ds.
	\psi(\theta) = \int_{\underline{\theta}}^\theta \sqrt{m(s)}~ds + o(\theta \sqrt{m(\theta)}).%O\left(\frac{\theta}{\sqrt{m(\theta)}}\right).
\end{equation}
%
%\begin{equation}\label{eq:Q_asymptotics}
%	\psi(\theta) = \int_{\underline{\theta}}^\theta \sqrt{m(s)}ds + O\left( \frac{\theta}{\sqrt{m(\theta)}}\right).
%\end{equation}
It is thus natural to define what corresponds to a spreading rate in the direction $\theta$ as follows.

\begin{definition}
For $\theta \in \overline\Theta$, define $\Phi(\theta) = \int_{\underline{\theta}}^\theta \sqrt{m(s)}ds$.  Fix any time $t>0$, any constant $a>0$, and define $\eta_a(t) \in \overline{\Theta}$ to be the unique solution of $\Phi(\eta_a(t)) = at$. When $a=1$, we denote $\eta(t) = \eta_1(t)$.
\end{definition}

Returning to $\overline n$, above, we see that, heuristically, the spreading in $\theta$ should be at least $O(\eta(t))$ since this is where the decay in $Q$ balances the growth of $e^{\gamma_\infty t}$.

Importantly, when $m(\theta)/\theta$ tends to $0$, there exists $D_m$ such that if $\theta$ is sufficiently large then
\begin{equation}\label{eq:phi_to_m}
	\Phi(\theta)
		\leq  \theta \sqrt{m(\theta)}
		\leq D_m \Phi(\theta).
\end{equation}		
Due to~\eqref{eq:phi_to_m}, we find a constant $C_a$ such that when $t$ is sufficiently large then
\begin{equation}\label{eq:etaa_to_eta1}
		C_a^{-1} \eta(t)
			\leq \eta_a(t)
			\leq C_a \eta(t).
\end{equation}
We note that, in the proof of \Cref{thm:acceleration}, it is more convenient to deal with the family $\eta_a(t)$ than to look at the scalar multiples of $\eta(t)$.  Due to~\eqref{eq:etaa_to_eta1}, these approaches are equivalent.

Now, heuristically, knowing the natural scaling between space and trait variables for the standard cane toads equation, we expect a propagation in space to be $O(\eta(t)^\frac{3}{2})$ since we expect propagation in trait to be $O(\eta(t))$. Our next result, and the main focus of this work, confirms these heuristics.

\begin{theorem}\label{thm:acceleration}
	Suppose that $m$ satisfies \Cref{hyp:m}, $\gamma_\infty > 0$,  $m(\theta)/\theta$ tends to zero as $\theta$ tends to $+\infty$, and $n$ satisfies~\eqref{eq:main}-\eqref{eq:n_0}.  Then there exist positive constants $\underline n$, $\underline c$, and $\overline c$ such that
	\[
		\liminf_{t \to \infty} \inf_{|x| \leq \underline c\eta(t)^{3/2}} n(t,x,\underline\theta) \geq \underline n
			\qquad\text{ and }\qquad
			\lim_{t\to \infty} \sup_{x\geq \overline{c} \eta(t)^{3/2}} \sup_{\theta \in \Theta} \ n(t,x,\theta) = 0.
	\]
\end{theorem}

This result might be surprising at first glance, since populations with very high traits have a negative growth rate. It turns out that the spatial sorting still gives a strong propagation force to population with high traits at the edge of the invasion. 
%
%Before discussing the difficulties in proving \Cref{thm:acceleration}, we discuss the result.  First, the case when $m(\theta)$ is bounded can be handled by a mixture of the methods in this article and in~\cite{BHR_Acceleration}.  
%


%Third, the quantity $\eta_a(t)$ can be understood in the following way.  We have that $e^{\gamma_\infty t} Q(\eta_a(t))$ tends to either infinity or zero depending on the choice of $a$.  Since $Q$ is, in some sense, the invariant measure, this tells us that the population can be expected to be $O(1)$ at $\theta \sim \eta_a(t)$.  Using the standard cane toads scaling, i.e.~that the interesting behavior in $x$ is located at the interesting behavior in $\theta$ taken to the exponent $3/2$, we see that $x \sim \eta_a(t)$ for some $a$.

To illustrate the result, we discuss two concrete choices of $m$.  First, if $m(\theta) \sim \theta^p$ for $p\in(0,1)$, one can check that $\eta(t) \sim t^{2/(2+p)}$.  Hence the front is at $\eta^{3/2}(t) \sim t^{3/(2+p)}$.  We point out that this is an  interpolation between the cases $p=1$, when no acceleration occurs (see~\Cref{thm:cauchy_finite}), and $p=0$, when acceleration is of order $t^{3/2}$ (see~\cite{BerestyckiMouhotRaoul,BHR_Acceleration})\footnote{Strictly speaking~\cite{BerestyckiMouhotRaoul,BHR_Acceleration} does not deal with the general case when $m(\theta)$ converges to a constant, but instead with the case $m(\theta) = 0$.  This particular case corresponds to the growth rate at infinity with $p = 0$.}.  Second, if $m(\theta) \sim \log(\theta)^p$ then it is easy to check that $\eta(t) \sim t\log(t)^{-p/2}$.  Hence the front is at $\eta(t)^{3/2} = t^{3/2}\log(t)^{-3p/4}$.  Notice that with this weaker trade-off term, the acceleration is almost at the same order as with no trade-off.

Let us now comment on the difficulties of the proof of \Cref{thm:acceleration}. In order to obtain the lower bound, we follow a similar strategy as in~\cite{BouinHenderson,BHR_Acceleration}.  We build a sub-solution on a moving ball using the principal Dirichlet eigenvalue.  There are three main difficulties here.  First, the problem is nonlocal and thus does not have a comparison principle.  To overcome this, we relate it to a local problem by estimating the nonlocal term $\rho$ using two ingredients: when $\theta$ is small, we may use a local-in-time Harnack inequality and when $\theta$ is large, we may obtain a priori estimates on the tails in trait of the solution $n$.  Second, in contrast to~\cite{BHR_Acceleration}, the path of this moving ``bump'' sub-solution cannot be found explicitly since the ODE system for the optimal path given by the Euler-Lagrange equation is not explicitly solvable.  Instead, we must optimize over rectangular paths.  Thirdly, the trade-off term $m$ is large when $\theta$ is large.  Hence, when $\theta$ is large, we add a multiplicative factor to our super-solution, which exponentially decays in time at a large rate, in order to absorb the high mortality rate.  We make up for this at the end of the trajectory by letting our moving sub-solution remain unmoving in a favorable area for a long period of time.  This strategy, absorbing losses and then re-growing later while keeping a careful accounting of them, is new in the reaction-diffusion literature to our knowledge.  In contrast, classical results come from settings where an eigenvalue can be well-posed and $O(1)$ solutions can be built using it.

The strategy of the proof of the upper bound is related in spirit to~\cite{BHR_Acceleration} but is technically completely different. 
In order to avoid complications with the nonlocal term, we notice that solutions to the linearized equation \eqref{eq:linearized}
%\begin{equation}\label{eq:linearized}
%	\overline n_t = \theta \overline n_{xx} + \overline n_{\theta\theta} + \overline n(1 - m(\theta))
%\end{equation}
are super-solutions to $n$.  As such we seek bounds on $\overline n$.  Historically, there are two ways to obtain super-solutions to reaction-diffusion equations: with a travelling wave solution or with heat kernel estimates.  Since a travelling wave moves at a constant speed, it cannot be used to bound an accelerating front from above.  On the other hand, classical heat kernel estimates on $\R^2$ require the diffusion operator to be comparable to the Laplacian and require any zeroth order terms in the operator to be bounded.  This is not our setting as $\theta \partial_x^2 + \partial_\theta^2$ is not comparable to the Laplacian uniformly in $\theta$ and $m(\theta)$ is unbounded by assumption.  In any case, our goal is understanding the precise balance between these two terms, so, even if it were possible to bound these by constants, this would provide too rough of an estimate for our purposes.  As such, we proceed by considering $\R\times\Theta$ as a two dimensional Riemannian manifold with boundary with the appropriate metric $g$.  After removing an integrating factor, we may view the linearized operator~\eqref{eq:linearized} as the Laplace-Beltrami operator $\Delta_g$ with a potential $-m(\theta)$.  We may then appeal to the methods of~\cite{LiYau} to obtain bounds on the fundamental solution of~\eqref{eq:linearized}.  After some careful modification of this fundamental solution and after reinserting the integrating factor, this provides a super-solution to $n$. We note that these heat kernel estimates do not provide the propagation result immediately.  Indeed, the results in~\cite{LiYau} give heat kernel estimates in terms of a Lagrangian, and this Lagrangian is itself difficult to estimate precisely. 
The use of the estimates coming from~\cite{LiYau} is not common in works investigating propagation, and we believe that this is an important addition to the toolbox for these types of problems.



Finally, we should mention why two other more well-known methods do not work.  First, one might ask if we can construct an explicit super-solution.  For example, one might expect functions of the same form as the upper estimate of the heat kernel in~\cite{LiYau} to be super-solutions. We outline in~\Cref{sec:acceleration} why this is not necessarily the case. %First, for reasons outlined in \Cref{sec:acceleration}, functions of the same form as the upper estimate on the heat kernel are not necessarily super-solutions.
Second, one may ask why large deviations methods, e.g.~the probabilistic methods of Friedlin~\cite{Freidlin1, Freidlin2} or the thin front limit approach of Evans and Souganidis~\cite{EvansSouganidis}, do not work.  In the construction of the sub-solution, we see that there are two scales.  Indeed, in the case where $m(\theta) \sim \theta^p$, the population that {\em drives} the acceleration is at $t^{3/(2-p)}$ while the bulk of the population is at $t^{3/(2+p)}$.  Hence scaling $(x,\theta)$ in the appropriate way in order to see the front loses the information about the population which drives the acceleration as it is lost in the scaling.  We should point out that this is an interesting feature of the model: the population that drives the front is different from the population that is sustained behind the front.

The proof of \Cref{thm:acceleration} is in \Cref{sec:acceleration}.




%
%\EB{TRY A COMMENT ABOUT WHAT HAPPENS WHEN THE TRADEOFF ALSO DEPENDS ON SPACE}
%



\subsubsection*{A Harnack estimate and a uniform upper bound}

Two key tools in our analysis are a uniform-in-time upper bound of $n$ and a local-in-time Harnack inequality that we can deduce from it.  We state both now.

\begin{prop}\label{prop:uniform_upper_bound}
	Suppose that $m$ satisfies~\Cref{hyp:m}.  Suppose that $n$ satisfies~\eqref{eq:main} with initial condition satisfying~\eqref{eq:n_0}.  Then there exists a constant $M$, depending only on $m$, such that
	\[
		\|\rho\|_{L^\infty(\R^+\times \R)}, \|n \|_{L^\infty(\R^+\times \R \times \Theta)} \leq M.
	\]
\end{prop}


\begin{lemma}\label{lem:harnack}
Let $\epsilon > 0$, $t_0 > 0$, $R>0$ and any point $x_0 \in \R$.  There exists $C_{R,\epsilon,t_0}$, depending only on $\epsilon$, $t_0$, and $R$, such that a solution $n$ of~\eqref{eq:main}-\eqref{eq:n_0} satisfies
 \[
	\rho(t,x_0)
		\leq \epsilon + C_{R,\epsilon,t_0} \inf_{|x-x_0| <R , \theta-\underline\theta < R} n(t,x,\theta),
		\qquad \text{ for all } t \geq t_0.
 \]
\end{lemma}

In general, it is difficult to obtain a uniform upper bound because there is no maximum principle of~\eqref{eq:main} due to the nonlocal term.  The bound must then be obtained by a careful understanding of the regularity of $n$ given a particular bound on $\rho$.  Specifically, one must use parabolic regularity estimates to show that if $n$ is large then $\rho$ is greater than $1$ and no maximum may occur. 
% {\color{blue} We point out that, while we do not provide a full treatment of the question of well-posedness for~\eqref{eq:main}, it is not difficult to do so using classical techniques given the bound in \Cref{prop:uniform_upper_bound}. -- REMOVE?}

Our proof of Proposition~\ref{prop:uniform_upper_bound} is in the same spirit as the proofs in~\cite{BerestyckiMouhotRaoul, HamelRyzhik, Turanova} in that it relies on the natural scaling of the parabolic equation versus that of $\rho$, yet significantly simpler in presentation and technical details.  Indeed, by appealing to standard local regularity estimates in Sobolev spaces and the Gagliardo-Nirenberg interpolation inequality, we are able to avoid the involved technical details of~\cite{BerestyckiMouhotRaoul, Turanova} and obtain a succinct proof.

Lastly, we point out that the weak Harnack inequality referenced above allows us to compare $\rho$ and $n$ for bounded $\theta$, and thus, we can compare each solution of~\eqref{eq:main} to the solution of a related local problem.  In order to compare $\rho$ and $n$, there are two local-in-time Harnack inequalities which are useful for this,~\cite[Theorem~1.2]{BHR_LogDelay} and~\cite[Theorem~2.6]{AlfaroBerestyckiRaoul}.  We use the latter because, though less precise, it is sufficient for our purposes and it is significantly easier to prove.

Proposition~\ref{prop:uniform_upper_bound} and \Cref{lem:harnack} are used throughout this article.  Their proofs, which are independent of all other results, may be found in \Cref{sec:apriori}. %The proofs of \Cref{lem:harnack} and \Cref{prop:uniform_upper_bound} can be found in \Cref{sec:apriori}.


\subsection*{Numerical simulations}

We end this introduction by showing numerical simulations that illustrate the different propagation regimes. For this, we use our typical example where $m(\theta) \sim \theta^p$ when $\theta$ tends to $+\infty$.  We present, for four different values of $p$ ($p=1/3, 2/3, 1, 4/3$) some plots of the solutions "from above" in the phase space $\R\times\Theta$ for various values of time. In case of a linear propagation, it is clear from these plots. In the acceleration regime, we also provide a figure with $\rho$ for various values of time, which helps viewing the accelerated propagation. 


\begin{figure}[htbp]
\begin{center}
\includegraphics[width = .45\linewidth]{p1colorcode.pdf}\qquad~~
\includegraphics[width = .45\linewidth]{p43colorcode.pdf}
~~\includegraphics[width=.99\linewidth]{big_panel1.pdf}\\
%\includegraphics[width = .49\linewidth,natwidth=610,natheight=642]{p1-10.jpg}
%\includegraphics[width = .49\linewidth,natwidth=610,natheight=642]{p43-10.jpg}
%\includegraphics[width = .49\linewidth,natwidth=610,natheight=642]{p1-20.jpg}
%\includegraphics[width = .49\linewidth,natwidth=610,natheight=642]{p43-20.jpg}
%\includegraphics[width = .49\linewidth,natwidth=610,natheight=642]{p1-30.jpg}
%\includegraphics[width = .49\linewidth,natwidth=610,natheight=642]{p43-30.jpg} 
%\includegraphics[width = .49\linewidth,natwidth=610,natheight=642]{p1-40.jpg}
%\includegraphics[width = .49\linewidth,natwidth=610,natheight=642]{p43-40.jpg}
%\includegraphics[width = .49\linewidth,natwidth=610,natheight=642]{p1-50.jpg}
%\includegraphics[width = .49\linewidth,natwidth=610,natheight=642]{p43-50.jpg}
%\includegraphics[width = .49\linewidth,natwidth=610,natheight=642]{p1-60.jpg}
%\includegraphics[width = .49\linewidth,natwidth=610,natheight=642]{p43-60.jpg}
\caption{Numerical simulations of the Cauchy problem of equation \eqref{eq:main} at a fixed time, in the phase space $\R\times\Theta$ at times $t=10$, $t=20$, $t=30$, $t=40$, $t=50$, $t=60$ with the choice $\underline \theta = .01$. Left column: $p=1$. Right column: $p=4/3$. Both exhibit propagation at a linear rate.}
\label{fig:Shape}
\end{center}
\end{figure}

%\begin{figure}[htbp]
%\begin{center}
%\includegraphics[width = .45\linewidth]{p1colorcode.pdf}\qquad~~
%\includegraphics[width = .45\linewidth]{p43colorcode.pdf}
%~~\includegraphics[width=.99\linewidth,natwidth=610,natheight=642]{big_panel1.pdf}\\
%%\includegraphics[width = .49\linewidth,natwidth=610,natheight=642]{p1-10.jpg}
%%\includegraphics[width = .49\linewidth,natwidth=610,natheight=642]{p43-10.jpg}
%%\includegraphics[width = .49\linewidth,natwidth=610,natheight=642]{p1-20.jpg}
%%\includegraphics[width = .49\linewidth,natwidth=610,natheight=642]{p43-20.jpg}
%%\includegraphics[width = .49\linewidth,natwidth=610,natheight=642]{p1-30.jpg}
%%\includegraphics[width = .49\linewidth,natwidth=610,natheight=642]{p43-30.jpg} 
%%\includegraphics[width = .49\linewidth,natwidth=610,natheight=642]{p1-40.jpg}
%%\includegraphics[width = .49\linewidth,natwidth=610,natheight=642]{p43-40.jpg}
%%\includegraphics[width = .49\linewidth,natwidth=610,natheight=642]{p1-50.jpg}
%%\includegraphics[width = .49\linewidth,natwidth=610,natheight=642]{p43-50.jpg}
%%\includegraphics[width = .49\linewidth,natwidth=610,natheight=642]{p1-60.jpg}
%%\includegraphics[width = .49\linewidth,natwidth=610,natheight=642]{p43-60.jpg}
%\caption{Numerical simulations of the Cauchy problem of equation \eqref{eq:main} at a fixed time, in the phase space $\R\times\Theta$ at times $t=10$, $t=20$, $t=30$, $t=40$, $t=50$, $t=60$ with the choice $\underline \theta = .01$. Left column: $p=1$. Right column: $p=4/3$. Both exhibit propagation at a linear rate.}
%\label{fig:Shape}
%\end{center}
%\end{figure}
%
\begin{figure}[htbp]
\begin{center}
\includegraphics[width = .45\linewidth]{p13colorcode.pdf}\qquad~~
\includegraphics[width = .45\linewidth]{p23colorcode.pdf}
\includegraphics[width = .80\linewidth]{big_panel2.pdf}\\
%\includegraphics[width = .47\linewidth,natwidth=610,natheight=642]{p13-10.jpg}
%\includegraphics[width = .47\linewidth,natwidth=610,natheight=642]{p23-10.jpg}
%\includegraphics[width = .47\linewidth,natwidth=610,natheight=642]{p13-20.jpg}
%\includegraphics[width = .47\linewidth,natwidth=610,natheight=642]{p23-20.jpg}
%\includegraphics[width = .47\linewidth,natwidth=610,natheight=642]{p13-30.jpg}
%\includegraphics[width = .47\linewidth,natwidth=610,natheight=642]{p23-30.jpg} 
%\includegraphics[width = .47\linewidth,natwidth=610,natheight=642]{p13-40.jpg}
%\includegraphics[width = .47\linewidth,natwidth=610,natheight=642]{p23-40.jpg}
%\includegraphics[width = .47\linewidth,natwidth=610,natheight=642]{p13-50.jpg}
%\includegraphics[width = .47\linewidth,natwidth=610,natheight=642]{p23-50.jpg}
%\includegraphics[width = .47\linewidth,natwidth=610,natheight=642]{p13-rho.jpg}
%\includegraphics[width = .47\linewidth,natwidth=610,natheight=642]{p23-rho.jpg}
%%\includegraphics[width = .47\linewidth]{p13-60.jpg}
%%\includegraphics[width = .47\linewidth]{p23-60.jpg}
\caption{Numerical simulations of the Cauchy problem of equation \eqref{eq:main} at a fixed time, in the phase space $\R\times\Theta$ at times (from top to bottom) $t=10$, $t=20$, $t=30$, $t=40$, $t=50$. Left column: $p=1/3$. Right column: $p=2/3$. Last line: evolution of $\rho$ at times $t=10$, $t=20$, $t=30$, $t=40$, $t=50$. Both exhibit  propagation at a super-linear rate.  The transient dynamics driving the acceleration are seen in the ``head'' -- the light diagonal line moving and up and to the right of the front.  This can be observed, e.g., in Step 2 of the proof of Proposition~\ref{prop:lowerboundacc}.}
\label{fig:Shape2}
\end{center}
\end{figure}
%%From top left to bottom right: \textit{the initial data},  One can track the accelerated behavior, for example on the space axis. The invasion at the back in the $\theta$-direction is expected to be linear in time. This pattern is very similar as for the monostable cane toads equation, see also~\cite{BCMetal,BerestyckiMouhotRaoul,BHR_acceleration}.}








%
%
%\vspace{1 in}
%
%
%
%{\color{red}  TO BE DELETED:
%
%
%
%\subsection*{Heuristics and main theorem}
%
%First of all, far-field conditions should solve {\color{red} We have to come up with something other than $\gamma_\infty$, it looks too much like the initial population density...}
%\begin{equation}\label{eq:specQ}
%\begin{cases}
%Q'' +  (1 - m) \, Q  = \gamma_\infty Q, \qquad \text{on } \Theta,\medskip \\
%Q' \left(\underline \theta \right) = 0, \medskip \\
%Q > 0.
%\end{cases}
%\end{equation}
%Note that $\gamma_\infty$ is defined in a unique way and $Q$ up to a positive multiplicative constant only. When normalized with $\int_{\Theta} Q(\theta) \, d\theta = \gamma_\infty$, this eigenvector is expected to be the limit of the population density at the back of the propagation front when propagation happens (since in this case $\gamma_\infty$ is necessarily nonnegative, see Proposition \ref{prop:extinction}). 
%
%As pretty classical and informative in this kind of spreading-like questions for Fisher-KPP type problems, we investigate the linearized problem associated to \eqref{eq:main}. This problem is the following.
%\begin{equation}\label{eq:lintoads}
%\left\{\begin{array}{ll}
%u_t = \theta u_{xx} + u_{\theta\theta} + u \left( 1 - m\right), &\qquad (t,x,\theta) \in \R^+ \times \R \times \Theta, \medskip \\
%u_\theta(t,x,\underline\theta) = 0, & \qquad (t,x) \in \R^+ \times \R \times \Theta . 
%\end{array}
%\right.
%\end{equation}
%
%Exactly such as in \cite{BouinCalvez, Alfaro, Berestycki}, we look for exponential solutions to \eqref{eq:lintoads}, with separated variables,  travelling at finite speed $c_\lambda$, where $\lambda$ is a given spatial decay rate:
%\begin{equation*}
%u(t,x,\theta) = e^{- \lambda (x - c_\lambda t)}Q_\lambda(\theta), \qquad (t,x,\theta) \in \R^+ \times \R \times \Theta.
%\end{equation*}
%After plugging into \eqref{eq:lintoads}, we deduce that $(\lambda c_\lambda,Q_\lambda)$ should solve the following eigenvalue problem in the trait variable, 
%\begin{equation}\label{eq:eigenpb}
%\left\{\begin{array}{ll}
% Q_\lambda'' + \left[  \lambda^2 \theta - \lambda c_\lambda + (1 -  m(\theta)) \right] Q_\lambda  = 0, &\qquad \theta \in \Theta, \medskip \\
%Q_\lambda' \left( \underline \theta \right) = 0.
%\end{array}
%\right.
%\end{equation}
%We  have to wonder about the existence of solutions to this Schrödinger-like eigenvalue problem. A necessary and sufficient condition for existence and uniqueness of a positive eigenvector $Q_\lambda$ is \cite{}
%\begin{equation*}
%\lim_{\theta \to +\infty} \left( \lambda^2 \theta - \lambda c_\lambda +  (1 - m(\theta) \right) = - \infty.
%\end{equation*}
%
%\EB{WRITE HERE A CONDITION HERE THAT IS SUGGESTED}
%This is true if $p > 1$ or $p=1$ and $\lambda \leq r^{\frac12}$ or $\lambda = 0$. In light of \cite{}, this suggests an acceleration feature when $p<1$ and a linear spreading when $p \geq 1$.
%
%The case $\lambda = 0$ corresponds to the stationary (and space homogeneous) eigenelements $(\gamma_\infty,Q)$ defined by the following spectral problem
%
% The idea is the following: we will localize by working on a moving ball; we are work only on balls following straight vertical or straight horizontal lines; and given a speed $c = (c_x,c_\theta)$, a travel time $T$ and a maximum height $H$, the population will change by a multiplicative factor of
%\[
%	\exp\left\{ T\left(1  - \frac{c_\theta^2}{4} - \frac{c_x^2}{4H} - m(H)\right) \right\}.
%\]
%Hence, fixing a large time $T$, if we follow a path which moves vertically with speed $c_1$ for time $t$, then horizontally with speed $c_2$ for time $t$, then vertically with speed $-c_1$ for time $t$, and then stands still for $T - 3t$, we will have population
%\[
%	\sim \exp\left\{ T - \frac{2c_1^2t}{4} - \frac{c_2^2 t}{4c_1t} - 3t m(c_1t) \right\}
%		=\exp\left\{ T - \frac{c_1^2t}{2} - \frac{c_2^2}{4c_1} - 3tm(c_1t) \right\}
%\]
%at the point $x \sim c_2 t$.  We want to maximize $c_2 t$.  We see that we can make:
%\[
%	c_1^2t < O(T),
%	~~~ c_2^2/ c_1 < O(T),
%	~~~\text{ and }
%	~~~ tm(c_1 t) < O(T).
%\]
%Dropping the ``$O$'' notation and combining the first and the last relation, we obtain that
%\begin{equation*}
%c_1^2 = m\left(\frac{T}{c_1}\right)
%~~~\text{ and }~~~ t = \frac{T}{c_1^2}.
%\end{equation*}
%Finally, from the second condition above, we obtain that $c_2 = \sqrt{c_1 T}.$
%
%%Define $\phi(x) = xm(x)$, which is monotonic and thus has a well-defined inverse which is monotonic (and sub-linear).  Then the last condition we can re-write as
%%\[
%%	\phi(c_1 t) = T
%%\]
%%so we can define set $c_1 t =\phi^{-1}(c_1T)$.  
%%
%%The second condition then gives us that
%%\[
%%	T = c_1^2 t = c_1 \phi^{-1}(c_1 T)
%%\]
%%which then gives us that
%%\[
%%	c_1 T = \phi(T/c_1) = (T/c_1) m(T/c_1).
%%\]
%%In other words, $c_1^2 = m(T/c_1)$.  This uniquely defines $c_1$, which in turn, uniquely defines $t$ as
%%\[
%%	c_1^2 = m(T/c_1) ~~~\text{ and }~~~
%%	t = \frac{1}{c_1} \phi^{-1}(c_1 T).
%%\]
%%
%Then we have that the propagation distance in $x$ is
%\begin{equation*}
%	c_2t = \sqrt{c_1T} \frac{T}{c_1^2} = \left( \frac{T}{c_1} \right)^\frac32 %= \left( c_1 t\right)^\frac32 = \left( d_1(T)\right)^\frac32
%\end{equation*}
%This is consistent with the scaling of the cane toads operator {\color{red} CHRIS: Should probably be more clearly that you mean the case with $m=0$ and $c_1 = O(1)$}.
%
%{\color{blue}  I think we could make this simpler.  Define $\theta_{a,t}$ to be the unique number such that $\theta_{a,t} \sqrt{m(\theta_{a,t})} = a t$.  Then we have that there exists $a_l$ and $a_u$ such that the propagation is at least $\theta_{a_l,t}^{3/2}$ and at most $\theta_{a_u,t}^{3/2}$.  I'm 99\% sure that this is equivalent to the above and much easier to state.}
%
%%Comparing the propagation distances :
%%\begin{equation*}
%%\frac{c_2t}{\left(c_1t\right)^\frac32} = \frac{c_2}{c_1^\frac32 t^\frac12}=  \frac{c_2}{c_1^\frac32} \frac{c_1}{T^\frac12} = \frac{c_2}{(Tc_1)^\frac12} = \mathcal{O}(1).
%%\end{equation*}
%%
%%\[
%%	\sqrt{\frac{T}{c_1} }\phi^{-1}(c_1 T).
%%\]
%
%\subsubsection*{Examples}
%\begin{enumerate}
%\item When $m(x) = x^p$, then $c_1$ is the solution to $c_1^2 = \frac{T^p}{c_1^p}$ or $c_1 = T^{\frac{p}{2+p}}$. The travel time is $t=T^{\frac{2-p}{2+p}}$. 
%%In addition $\phi^{-1}(x) = x^{1/(1+p)}$ and so 
%The propagation distance is
%\[
%	\left( \frac{T}{c_1} \right)^\frac32 = \left( T^{1 - \frac{p}{2+p} } \right)^\frac32	
%%	\sqrt\frac{T}{T^{p/(2+p)}} \left( T^{p/(2+p)} T\right)^{1/(1+p)}
%		= T^\frac{3}{2+p}
%\]
% 
%\item If $m(x) = \log{x}$ then $c_1$ is the solution to $c_1^2 = \log{T} + \log{c_1}$ so $c_1 \sim \sqrt{\log{T}}$. Thus, $t \sim \frac{T}{\ln T}$. 
%%In addition, we have that $\phi(x) = x\log{x}$ so $\phi^{-1}(x) \sim x/\log{x}$.  
%%
%Hence we have that the propagation distance is
%\[
%\left( \frac{T}{c_1} \right)^\frac32
%%	\sqrt\frac{T}{\sqrt{\log{T}}} \frac{T\log{T}}{\log{T} + \log\log{T}}
%		\sim \frac{T^{3/2}}{(\log{T})^{3/4}}
%\]
%\end{enumerate}
%
%
%
%\begin{example}
%Our main typical cases are exponential rates $m(\theta) = e^{\alpha (\theta - \underline \theta)} - 1$, polynomial rates $m(\theta) = \left( \theta - \underline\theta \right)^p$ and logarithmic rates $m(\theta) = \ln\left( 1 + (\theta-\underline \theta)\right)$.
%\end{example}
%
%
%
%\begin{prop}\label{prop:unifbound}
%Suppose that $n$ is a non negative classical solution of \eqref{eq:main} with some bounded initial data $n_0$. Then there exists a universal constant $M$ such that 
%\begin{equation*}
%\forall \,T \geq 0, \qquad \sup_{t\in[0,T]} \|n(t,\cdot)\|_{L^\infty\left(\Gamma\right)} < M.
%\end{equation*}
%\end{prop}
%
%
%
%\begin{theorem}\label{thm:main}
%We have the following alternative
%
%\begin{enumerate}
%\item \label{case:extinct}If $\gamma_\infty \leq 0$, then the population gets extinct, that is, $\lim_{t \to \infty} n(t,\cdot) = 0$ uniformly in $\Gamma$. {\color{red} We have to come up with something other than $\gamma_\infty$, it looks too much like the initial population density...}
%\item \label{case:prop}Assume now that $\gamma_\infty > 0$. Then the population propagates. 
%\begin{enumerate}
%\item \label{case:proppos}If $\lim_{\theta \to + \infty} m(\theta)/\theta > 0$, then the speed of propagation is finite. In particular, 
%\begin{enumerate}
%\item \label{case:propposTW}there exists $c^*$ such that for any $c \geq c^*$, there exists travelling waves solutions of speed $c$,
%\item \label{case:propposspreading}any compactly supported initial data spreads with the minimal speed $c^*$.  
%\end{enumerate}
%\item If $\lim_{\theta \to + \infty} m(\theta)/\theta = 0$, then the population accelerates. In particular, 
%\begin{enumerate}
%\item \label{case:propzerolower}LOWER BOUND
%\item \label{case:propzeroupper} Assume that $\theta \mapsto m(\theta)/\theta$ is decreasing, then 
%\end{enumerate}
%\end{enumerate}
%\end{enumerate}
%\end{theorem}
%
%
%\begin{remark}
%In the case \ref{case:proppos}, the limit of $m'$ can be infinite. One can see that there is a EXPLAIN THAT THERE MIGHT BE OtHER CASES IF m IS TERRIBLE (bUT WE CHOOSE NOT TO CARE)
%WRITE HERE HOW THE THING WOULD BE CHANGES WITH A $D(\theta)$
%\end{remark}}
%

















\subsection*{Acknowledgements}

EB is very grateful to the University of Sydney, where the present work has been initiated, for its hospitality.  The authors thank the University of Cambridge for its hospitality.  The authors thank warmly Vincent Calvez for early discussions about this problem, and for a careful reading of the manuscript.  CH thanks Alessandro Carlotto, Boaz Haberman, and Otis Chodosh for discussions about geometry and heat kernel estimates, which, while meant for earlier projects, found an application in this manuscript. Part of this work was performed within the framework of the LABEX MILYON (ANR- 10-LABX-0070) of Universit\'e de Lyon, within the program ``Investissements d'Avenir'' (ANR-11- IDEX-0007) operated by the French National Research Agency (ANR). In addition, this project has received funding from the European Research Council (ERC) under the European Unions Horizon 2020 research and innovation programme (grant agreement No 639638) and under the MATKIT starting grant. MHC and PSK were funded in part by the Australian Research Council (ARC) Discovery Project (DP160101597). We thank the anonymous referees for a close reading of the manuscript and very helpful suggestions.






















\section{Proof of \Cref{thm:acceleration}: the acceleration regime}\label{sec:acceleration}

\subsection{The upper bound}

In this section, we present the proof of the upper bound in \Cref{thm:acceleration}, i.e. we show:
\begin{prop}\label{prop:upperboundacc}
	Under the assumptions of \Cref{thm:acceleration}, there exists $\overline a>0$ such that
%	Suppose that $m$ satisfies \Cref{hyp:m}, that $\gamma_\infty > 0$ and that $m(\theta)/\theta$ tends to zero as $\theta$ tends to $+\infty$.  Then there exists $\overline a >0$ such that for all $\theta \in \Theta$, 
	\[
			\lim_{t\to \infty}  \sup_{x\geq \eta_{\overline{a}}(t)^{3/2}} \sup_{\theta \in \Theta} n(t,x,\theta) = 0.
	\]
\end{prop}
We may then deduce the upper bound in \Cref{thm:acceleration} by recalling \eqref{eq:etaa_to_eta1}. To get an upper bound on the propagation, we use the linearization around zero of~\eqref{eq:main}:
\begin{equation*}
\begin{cases}
\overline n_t = \theta \overline n_{xx} + \overline n_{\theta\theta} + \left( 1 - m \right)  \overline n , &\qquad \text{on } \R^+ \times \R\times\Theta,\\
\overline n_\theta(\cdot,\underline\theta) = 0, & \qquad \text{on } \R^+ \times \R. 
\end{cases}
\end{equation*}


Indeed, solutions to~\eqref{eq:main} are sub-solutions to $\overline n$.  Hence, by the comparison principle, $n \leq \overline n$ and it suffices to prove Proposition~\ref{prop:upperboundacc} for $\overline n$. 
% Our goal in this section is to show that if $x \geq \eta_a(t)^{3/2}$ for $a$ and $t$ sufficiently large, then
%\begin{equation}\label{eq:key_upper_bound}
%	\overline n(t,x,\theta) \leq C e^{-t}
%\end{equation}
%for some constant $C$ and for all $\theta$.  Indeed, the upper bound in \Cref{thm:acceleration} follows from~\eqref{eq:key_upper_bound}.

%\hrule
%
%Since it is relatively straight-forward, we first show that~\eqref{eq:key_upper_bound} holds when $\theta \geq \eta_{\gamma_\infty + 2}(t)$.  Note that we have found before that $A Q(\theta)e^{\gamma_\infty t}$ solves this linear problem and is thus a sub-solution when $A$ is chosen sufficiently large so that $AQ \geq n_0$.  Further, by writing $\psi = -\log(Q)$, it is easy to check that $\psi$ satisfies
%\[
%	-\psi'' + |\psi'|^2 + (1-m) = 0,
%\]
%from which if follows that, as $\theta$ tends to infinity,
%\begin{equation}\label{eq:Q_asymptotics}
%	\psi(\theta) = \Phi(\theta) + O(\theta / \sqrt{m(\theta)}).
%\end{equation}
%This gives the preliminary bound that if $\theta \geq \eta_{\gamma_\infty+2}(t)$ then $\overline n(t,x,\theta) \leq Ae^{-t}$.  Hence~\eqref{eq:key_upper_bound} follows when $\theta \geq \eta_{\gamma_\infty+2}(t)$ by the definition of $\eta$.  Indeed, we have established the following lemma.
%
%
%
%
%\begin{lem}\label{lem:large_theta}
%If $\theta \geq \eta_{\gamma_\infty + 2}(t)$, there exists $C$ depending only on $m$ and $\overline n_0$ such that $\overline n(t,x,\theta) \leq C e^{-t}$.
%\end{lem}
%
%
%We may now restrict our attention to obtaining bounds only when $\theta \leq \eta_{\lambda+2}(t)$.  Bounding $\overline n$ for $\theta \leq \eta_{\gamma_\infty+2}(t)$ is more complicated.  As such, we first introduce and discuss the key quantity in the proof.  In particular, we mention why it is a natural quantity to consider and why more elementary methods fail.  This is followed by the somewhat technical proof.
%\hrule 
In order to bound $\overline n$, we now introduce a key quantity. It is the action associated to the Lagrangian corresponding to \eqref{eq:main}:
\[
	\zeta(t,x,\theta,y,\eta) = \inf\left\{
		\int_0^t \left(\frac{|\dot Z_1|^2}{4Z_2} + \frac{|\dot Z_2|^2}{4} + m(Z_2)\right)ds
			: Z(0) = (y,\eta), Z(t) = (x,\theta), Z\in C^{0,1}\left( [0,t] \right)
	 \right\}.
\]
In general, we simply write $\zeta(t,x,\theta)$ to mean $\zeta(t,x,\theta,0,\underline\theta)$. We seek a super-solution which asymptotically looks like $e^{t - \zeta}$.

%We note that our choice of notation and scaling differs from the usual one in the Hamilton-Jacobi community.  We choose this notation to follow the notation of Li and Yau and Wang since we apply their results in the sequel.  
%


\subsubsection*{A brief discussion of $\zeta$ and previous strategies}

We briefly describe why such a super-solution is expected and why the strategy from~\cite{BHR_Acceleration}, where we showed that $e^{t-\zeta}$ is a super-solution to the equation without trade-off, does not work in this setting.  When $m \equiv 0$, one may expect to follow the work of Evans and Souganidis~\cite{EvansSouganidis} to see that the front should follow the dynamics of the solution of $\zeta$ due to the fact that it is the solution to the equation 
\[
	\zeta_t + \theta|\zeta_x|^2 + |\zeta_\theta|^2 = 0.
\]
This is in the thin front limit with the scaling given in \cite{BCMetal} (also recalled in \cite{BHR_Acceleration}). In physical space, i.e.~without scaling, one can check that $e^{t-\zeta}$ is a super-solution to \eqref{eq:main} if and only if
\begin{equation}\label{eq:supersoln_condition}
0 \leq \theta \zeta_{xx} + \zeta_{\theta\theta}.
\end{equation}
When $m \equiv 0$, it can be checked that $\zeta$ satisfies this, see \cite{BHR_Acceleration}.

When the trade-off $m$ is present, it is much harder to check~\eqref{eq:supersoln_condition}.  Indeed, define the related Lagrangian by $L_m(Z,\dot Z) = \frac{1}{4} \left(\frac{|\dot Z_1|^2}{Z_2} + |\dot Z_2 |^2\right)  + m(Z_2)$ and let $Z$ be an optimal trajectory satisfying the Euler-Lagrange equations.  As mentioned above, it is well-known that $\zeta_t + \theta |\zeta_x|^2 + |\zeta_\theta|^2 = m(\theta)$.  On the other hand, a computation using the Euler-Lagrange equations for $Z$ yields
\[
	\zeta_{xx} = \int_0^1 (v_x(t) \cdot ((D^2 L)(v) v_x(t)) ds
		\qquad\text{ and }\qquad
	\zeta_{\theta\theta} = \int_0^1 (v_\theta(t) \cdot ((D^2L)(v)v_\theta(t)) ds,
\]
where $v(t) = (Z(t), \dot Z(t))$.  One can check that $D^2L_m = D^2L_0 + (\delta_{i2} \delta_{j2} m''(Z_2))_{ij}$, where $L_0$ is the Lagrangian with no trade-off term.  A straightforward computation shows that $L_0$ is nonnegative definite and hence, if $m'' \geq 0$ then $L_m$ is nonnegative definite; however, we expect that $m'' < 0$ holds for large $\theta$ since $m$ is sub-linear.  Even though $L_m$ may not be nonnegative definite, one may still hope that $\theta\zeta_{xx} + \zeta_{\theta\theta} \geq 0$.  However, the term involving $m''$ in $\theta \zeta_{xx} + \zeta_{xx}$ is
\[
	\int_0^1 m''(Z_2) \left[\theta |\partial_x Z_2|^2 + |\partial_\theta Z_2|^2 \right] ds.
\]
Since we cannot explicitly solve for $Z$, this integral is very difficult to estimate.  As such, we are unable to show that there are super-solutions of the form $e^{t - \zeta}$.  Similar difficulties arise when looking at $e^{at - b \zeta}$ for any choice of $a$ and $b$.


%%%%The condition for $e^{t-\zeta}$ to be a super-solution is, in this case,
%%%%\[
%%%%	\zeta_t + \theta|\zeta_x|^2 + |\zeta_\theta|^2 + m(\theta) \leq \theta \zeta_{xx} + \zeta_{\theta\theta}.
%%%%\]
%%%%
%%%%We start with the first order derivatives, in order to find again the Hamilton-Jacobi equation. 
%%%%\begin{equation*}
%%%%\partial_t \zeta = L\left(Z_1(t),Z_2(t),\dot Z_1(t),\dot Z_2(t)\right) = \frac{1}{4} \left(\frac{|\dot Z_1(t)|^2}{Z_2(t)} + |\dot Z_2 (t)|^2\right)  + m(Z_2(t)).
%%%%\end{equation*}
%%%%Define $V(s) = \left(Z_1,Z_2,\dot Z_1,\dot Z_2\right)(s)$.
%%%%For the spatial and trait derivatives, we have
%%%%\begin{equation*}
%%%%\begin{array}{lcl}
%%%%\partial_x \zeta & = & \displaystyle \int_0^t \left( L\left(Z_1,Z_2,\dot Z_1,\dot Z_2 \right) \right)_x \, ds, \\
%%%%& = & \displaystyle\int_0^t \left( \frac{\partial L}{\partial Z_1} \frac{\partial Z_1}{\partial x}+ \frac{\partial L}{\partial Z_2} \frac{\partial Z_2}{\partial x} + \frac{\partial L}{\partial \dot Z_1} \frac{\partial \dot Z_1}{\partial x} + \frac{\partial L}{\partial \dot Z_2} \frac{\partial \dot Z_2}{\partial x}\right) \, ds \\
%%%%\end{array}
%%%%\end{equation*}
%%%%By the Euler-Lagrange equations, 
%%%%\begin{equation*}
%%%%\frac{\partial}{\partial s} \left(  \frac{\partial L}{\partial \dot Z_1}\right) = \frac{\partial L}{\partial Z_1}, \qquad \frac{\partial}{\partial s} \left(  \frac{\partial L}{\partial \dot Z_2}\right) = \frac{\partial L}{\partial Z_2},
%%%%\end{equation*}
%%%%we find
%%%%\begin{equation*}
%%%%\begin{array}{lcl}
%%%%\partial_x \zeta & = & \displaystyle\int_0^t \left( \frac{\partial}{\partial s} \left(  \frac{\partial L}{\partial \dot Z_1}\right) \frac{\partial Z_1}{\partial x}+ \frac{\partial}{\partial s} \left(  \frac{\partial L}{\partial \dot Z_2}\right) \frac{\partial Z_2}{\partial x} + \frac{\partial L}{\partial \dot Z_1} \frac{\partial \dot Z_1}{\partial x} + \frac{\partial L}{\partial \dot Z_2} \frac{\partial \dot Z_2}{\partial x}\right) \, ds \\
%%%%& = & \displaystyle\int_0^t \left( \frac{\partial}{\partial s} \left(  \frac{\partial L}{\partial \dot Z_1} \frac{\partial Z_1}{\partial x}  + \frac{\partial L}{\partial \dot Z_2} \frac{\partial Z_2}{\partial x} \right) \right)\, ds \\
%%%%& = & \displaystyle\left[ \frac{\partial L}{\partial \dot Z_1} \frac{\partial Z_1}{\partial x}  + \frac{\partial L}{\partial \dot Z_2} \frac{\partial Z_2}{\partial x} \right]_{s=0}^{s=t} = \frac{\partial L}{\partial \dot Z_1}\left(Z_1(t),Z_2(t),\dot Z_1(t),\dot Z_2(t)\right).\\
%%%%\end{array}
%%%%\end{equation*}
%%%%Since 
%%%%\begin{equation*}
%%%%\frac{\partial Z_1}{\partial x}(s=t) = 1, \quad \frac{\partial Z_1}{\partial x}(s=0) = 0, \quad \frac{\partial Z_2}{\partial x}(s=t) = 0, \quad \frac{\partial Z_2}{\partial x}(s=0) = 0,
%%%%\end{equation*}
%%%%With same computations, we find
%%%%\begin{equation*}
%%%%\begin{array}{lcl}
%%%%\partial_\theta \zeta & = & \displaystyle\left[ \frac{\partial L}{\partial \dot Z_1} \frac{\partial Z_1}{\partial \theta}  + \frac{\partial L}{\partial \dot Z_2} \frac{\partial Z_2}{\partial \theta} \right]_{s=0}^{s=t} = \frac{\partial L}{\partial \dot Z_2}\left(Z_1(t),Z_2(t),\dot Z_1(t),\dot Z_2(t)\right).\\
%%%%\end{array}
%%%%\end{equation*}
%%%%Here, we have 
%%%%\begin{equation*}
%%%%\frac{\partial L}{\partial \dot Z_1} = \frac{\dot Z_1}{2 Z_2}, \qquad \frac{\partial L}{\partial \dot Z_2} = \frac{\dot Z_2}{2}
%%%%\end{equation*}
%%%%As a consequence, we recover the Hamilton-Jacobi equation
%%%%\begin{equation*}
%%%%\partial_t \zeta = \theta |\partial_x \zeta|^2 + | \partial_\theta \zeta|^2   + m(\theta)
%%%%\end{equation*}
%%%%\EB{CHECK THE SIGNS}
%%%%We are interested in whether we can find $r$ and $\alpha$ such that $\exp(rt - \alpha \zeta)$ is a super-solution to \eqref{eq:main}. This means checking if
%%%%\begin{equation*}
%%%%\partial_t \zeta + \alpha \theta |\partial_x \zeta|^2 + \alpha| \partial_\theta \zeta|^2   - \alpha^{-1} m(\theta) \leq \theta \zeta_{xx} + \zeta_{\theta \theta}
%%%%\end{equation*}
%%%%We now compute the second order derivatives
%%%%\begin{equation*}
%%%%\begin{array}{lcl}
%%%%\partial_{xx} \zeta & = & \displaystyle \int_0^t \left( L\left(Z_1,Z_2,\dot Z_1,\dot Z_2 \right) \right)_{xx} \, ds, \\
%%%%& = & \displaystyle\int_0^t \left( \frac{\partial L}{\partial Z_1} \frac{\partial Z_1}{\partial x}+ \frac{\partial L}{\partial Z_2} \frac{\partial Z_2}{\partial x} + \frac{\partial L}{\partial \dot Z_1} \frac{\partial \dot Z_1}{\partial x} + \frac{\partial L}{\partial \dot Z_2} \frac{\partial \dot Z_2}{\partial x}\right)_x \, ds \\
%%%%& = & \displaystyle\int_0^t \left( \frac{\partial L}{\partial Z_1} \frac{\partial Z_1}{\partial x}+ \frac{\partial L}{\partial Z_2} \frac{\partial Z_2}{\partial x} + \frac{\partial L}{\partial \dot Z_1} \frac{\partial \dot Z_1}{\partial x} + \frac{\partial L}{\partial \dot Z_2} \frac{\partial \dot Z_2}{\partial x}\right)_x \, ds \\
%%%%\end{array}
%%%%\end{equation*}
%%%%We reduce each term
%%%%\begin{equation*}
%%%%\left( \frac{\partial L}{\partial Z_1} \frac{\partial Z_1}{\partial x} \right)_x = \left( \frac{\partial L}{\partial Z_1} \right)_x \frac{\partial Z_1}{\partial x} + \frac{\partial L}{\partial Z_1} \frac{\partial^2 Z_1}{\partial x^2} 
%%%%\end{equation*}
%%%%\begin{equation*}
%%%%\left( \frac{\partial L}{\partial Z_2} \frac{\partial Z_2}{\partial x} \right)_x = \left( \frac{\partial L}{\partial Z_2} \right)_x \frac{\partial Z_2}{\partial x} + \frac{\partial L}{\partial Z_2} \frac{\partial^2 Z_2}{\partial x^2} 
%%%%\end{equation*}
%%%%\begin{equation*}
%%%%\left( \frac{\partial L}{\partial \dot Z_1} \frac{\partial \dot Z_1}{\partial x} \right)_x = \left( \frac{\partial L}{\partial \dot Z_1} \right)_x \frac{\partial \dot Z_1}{\partial x} + \frac{\partial L}{\partial \dot Z_1} \frac{\partial^2 \dot Z_1}{\partial x^2} 
%%%%\end{equation*}
%%%%\begin{equation*}
%%%%\left( \frac{\partial L}{\partial \dot Z_2} \frac{\partial \dot Z_2}{\partial x} \right)_x = \left( \frac{\partial L}{\partial \dot Z_2} \right)_x \frac{\partial \dot Z_2}{\partial x} + \frac{\partial L}{\partial \dot Z_2} \frac{\partial^2 \dot Z_2}{\partial x^2} 
%%%%\end{equation*}
%%%%By the Euler-Lagrange equations, we have
%%%%\begin{equation*}
%%%%\frac{\partial}{\partial s} \left(  \frac{\partial L}{\partial \dot Z_1} \frac{\partial^2 Z_1}{\partial x^2}  + \frac{\partial L}{\partial \dot Z_2} \frac{\partial^2 Z_2}{\partial x^2} \right) = \frac{\partial L}{\partial Z_1} \frac{\partial^2 Z_1}{\partial x^2} + \frac{\partial L}{\partial Z_2} \frac{\partial^2 Z_2}{\partial x^2} + \frac{\partial L}{\partial \dot Z_1} \frac{\partial^2 \dot Z_1}{\partial x^2} + \frac{\partial L}{\partial \dot Z_2} \frac{\partial^2 \dot Z_2}{\partial x^2}.
%%%%\end{equation*}
%%%%and thus
%%%%\begin{equation*}
%%%%\int_0^t \frac{\partial}{\partial s} \left(  \frac{\partial L}{\partial \dot Z_1} \frac{\partial^2 Z_1}{\partial x^2}  + \frac{\partial L}{\partial \dot Z_2} \frac{\partial^2 Z_2}{\partial x^2} \right) ds = \left[ \frac{\partial L}{\partial \dot Z_1} \frac{\partial^2 Z_1}{\partial x^2}  + \frac{\partial L}{\partial \dot Z_2} \frac{\partial^2 Z_2}{\partial x^2} \right]_{s=0}^{s=t} = 0.
%%%%\end{equation*}
%%%%We now introduce the Hessian of the Lagrangian 
%%%%\begin{equation*}
%%%%\text{Hess}(L) = 
%%%%\begin{pmatrix}
%%%%   0 & 0 & 0 & 0 \\
%%%%   0 & a & b & 0 \\
%%%%   0 & b & c & 0 \\
%%%%   0 & 0 & 0 & d 
%%%%\end{pmatrix}
%%%%\end{equation*}
%%%%where we have defined
%%%%\begin{equation*}
%%%%a = \frac{\partial^2 L}{\partial Z_2^2} = \frac{\vert\dot Z_1\vert^2}{2Z_2^3} + m''(Z_2), \qquad b = \frac{\partial^2 L}{\partial Z_2 \partial\dot Z_1} = - \frac12 \frac{\dot Z_1}{Z_2^2}, \qquad c = \frac{\partial^2 L}{\partial \dot Z_1^2} = \frac{1}{2 Z_2}, \qquad d =  \frac{\partial^2 L}{\partial \dot Z_2^2} = \frac12.
%%%%\end{equation*}                                         
%%%%Thus, we can rewrite $\partial_{xx} \zeta$ as follows
%%%%\begin{equation*}
%%%%\zeta_{xx} = \int_0^t \left\langle V_x \vert \text{Hess}(L) V_x \right\rangle ds =  \int_0^t \left( a \left( \frac{\partial Z_2}{\partial x}\right)^2 + 2 b \frac{\partial Z_2}{\partial x}\frac{\partial \dot Z_1}{\partial x} + c \left( \frac{\partial \dot Z_1}{\partial x} \right)^2 + d \left( \frac{\partial \dot Z_2}{\partial x}\right)^2 \right) ds
%%%%\end{equation*}
%%%%In the same way, we have
%%%%\begin{equation*}
%%%%\zeta_{\theta\theta} = \int_0^t \left\langle V_\theta \vert \text{Hess}(L) V_\theta \right\rangle ds = \int_0^t \left( a \left( \frac{\partial Z_2}{\partial \theta}\right)^2 + 2 b \frac{\partial Z_2}{\partial \theta}\frac{\partial \dot Z_1}{\partial \theta} + c \left( \frac{\partial \dot Z_1}{\partial \theta} \right)^2 + d \left( \frac{\partial \dot Z_2}{\partial \theta}\right)^2 \right) ds
%%%%\end{equation*}
%%%%
%%%%For the cane toads operator without trade-off, $\text{Hess}(L)$ is nonnegative. Then we obtain a true super-solution. When a trade-off is present, one eigenvalue of the Hessian can have a negative sign so that it is much harder to know the sign of $\theta \zeta_{xx} + \zeta_{\theta\theta}$ without computing explicitely the Lagrangian trajectories. 
%%%%\EB{CAN CHECK $AC-B^2$ IS ZERO WITHOUT TRADE-OFF. WITH A GENERAL TRADEOFF IT HAS ANEGATIVE SIGN DUE TO THE CONVEXITY. WITH A GENERAL D(THETA) IT CAN HAVE THE GOOD SIGN IF WE CHOOSE $D''$ NEGATIVE}
%%%%
%%%%{\color{red} Is there a good reason to keep this section given that we can't use it to get a super-solution?  If not, I think it needs to be sacrificed to the gods.}
%%%%
%%%%



















\subsubsection*{Relating $\overline n$ and $\zeta$}



We now explain how to relate $\overline n$ and $\zeta$. For this, we use results by Li and Yau~\cite[Corollary~3.2]{LiYau} on parabolic equations on Riemannian manifolds. In this paper, the authors derive bounds on the fundamental solutions of the heat equation with potential on general manifolds. In particular, they prove an upper bound after proving a suitable Harnack inequality.

We use their analysis to derive an upper bound on the fundamental solution of \eqref{eq:linearized}. To show that we can use their results, we view $\R\times\Theta$ as a Riemannian manifold with an appropriate metric $g$ so that the second order operator in \eqref{eq:linearized} is the Laplace-Beltrami operator on that manifold.

To this end, we need to remove an integrating factor of $\overline n$.  Let $r = 1+\underline \theta^{-2}$ and define $v = e^{-rt} \theta^{1/4} \overline n$. Notice that
\begin{equation}\label{eq:v_eqn}
	v_t = \theta v_{xx} + v_{\theta\theta} - \frac{1}{2\theta} v_\theta + v\left(1-m + \frac{5}{16 \theta^2} - r\right)
		\leq \theta v_{xx} + v_{\theta\theta} - \frac{1}{2\theta} v_\theta - mv.
\end{equation}

Let $G(t,x,y,\theta,\eta)$ be the fundamental solution to
\begin{equation}\label{eq:G_pde}
	G_t = \theta G_{xx} + G_{\theta\theta} - \frac{1}{2\theta} G_\theta - m G,
\end{equation}
on $\R\times \Theta$ with Neumann boundary conditions in $\theta$.  In order to obtain bounds on $G$, we wish to apply the bounds obtained in~\cite{LiYau}.  To this end, we define the metric
\begin{equation}\label{eq:metric}
	g = \begin{pmatrix}
		\frac{1}{\theta} & 0 \\ 0 & 1
		\end{pmatrix},
\end{equation}
and, denoting $\Delta_g$ as the Laplace-Beltrami operator associated to $g$, notice that $G$ satisfies
\[
	G_t = \Delta_g G - mG.
\]
In addition, one can check that the curvature of the manifold $(\R\times\Theta, g)$ is uniformly bounded. For the help of the reader, we include a discussion of all geometric issues in \Cref{sec:appendix}.






If $n_0$ were compactly supported, we would take $G(t+1,x,\theta,0,\underline\theta)$ as a super-solution.  Since $n_0$ is not compactly supported, we modify this and define $w$ as
\begin{equation}\label{eq:w}
	w(t,x,\theta)
		= C \sum_{\ell=0}^\infty G(t+1, x + \ell ,\theta,0,\underline\theta),
\end{equation}
where $C$ is chosen large enough that $w(0,\cdot) \geq \overline n_0$.  This is essentially the convolution of $G$ with the initial data, but this formulation is more convenient computationally in the sequel.  It follows that $e^{rt}\theta^{-1/4} w(t,x,\theta)$ is a super-solution to $\overline n$.  We point out that this super-solution is different from the one appearing in~\cite{BHR_Acceleration}.  In that article, because we had an explicit formula for the super-solution, we could extend the super-solution to the quadrant $\{x<0\}$ by ``forgetting'' the $x$-dependence in a way that the solution remained $\mathcal{C}^1$.  Here, we cannot do that since we have no way of verifying that such a construction is still a super-solution on the line $\{x = 0\}$.

With this set, we recall the following results by Li and Yau~\cite[Corollary~3.2]{LiYau}.

\begin{lemma}\label{lem:Li_Yau}
Let $t>t_0$ and $x \in \R$. For $\theta \leq \eta_{\gamma_\infty + 1}(t)$, there exists a constant $C$ such that
\[
	G(t,x,\theta,0,\underline\theta) \leq C \exp \left\{ C t - \frac{\zeta(t,x,\theta)}{2}\right\}.
\]
\end{lemma}
We refer to Appendix A for a discussion on how \Cref{lem:Li_Yau} follows from \cite[Corollary~3.2]{LiYau} as it is not immediate.  By~\eqref{eq:w} and \Cref{lem:Li_Yau}, a bound on $\overline n$ follows from a bound on $\zeta$.



\subsubsection*{A bound on $\zeta$ and the conclusion of the proof of the upper bound}

Our goal in this section is to derive a lower bound for $\zeta$ and then to use that to obtain a bound on $w$.  The first step is to prove the following lemma.
\begin{lemma}\label{lem:rho_bound}
Fix any $\overline a > 0$. Assume that $x \geq \eta_{\overline a}(t)^{3/2}$. There exists a constant $C>0$ such that
\[
	\zeta(t,x,\theta) \geq C^{-1}\min\left\{\overline a t\sqrt{ \frac{x}{\eta_{\overline a}(t)^{3/2}}}%x^{1/2} \eta_{\overline a}(t)^{1/4} m(\eta_{\overline a}(t))^{1/2}
		%, \overline a t \frac{x }{\eta_{\overline a}(t)^{3/2}}%\sqrt{m(\eta_{\overline a}(t))/\eta_{\overline a}}(t)
		,\frac{x^2}{t}\right\}.
\]
\end{lemma}
We point out that each term in the minimum above has the correct or super-critical scaling.  In other words, taking $x > \eta_{\overline a}(t)^{3/2}$ in each term yields a term which is at least linear in time.
\begin{proof}%[{\bf Proof of \Cref{lem:rho_bound}}]
Thanks to the Euler-Lagrange equations, we know that the infimum defining $\zeta$ is actually a minimum and the minimizer satisfies
\begin{equation*}
\frac{d}{ds} \left( \frac{\dot Z_1}{2 Z_2} \right) = 0,\qquad \frac{d}{ds} \left( \frac{\dot Z_2}{2}\right) = m'(Z_2) - \frac{\vert\dot  Z_1 \vert^2}{4 Z_2^2}.
\end{equation*}
Hence there exists $\alpha$ depending on $t,x,\theta$ such that $\dot Z_1 = 2\alpha Z_2$.
Integrating this, we find $\alpha = x/(2 \int_0^t Z_2(s) ds)$.
%\begin{equation*}
%\alpha = \frac{x}{2\int_0^t Z_2(s) ds}.
%\end{equation*}
Combining this with the identity $\dot Z_1 = 2\alpha Z_2$ and the definition of $\zeta$, we obtain
\begin{equation}\label{eq:rhosimple}
	\zeta(t,x,\theta) = \frac{x^2}{4 \int_0^t Z_2 \, ds}  + \int_0^t \left( \frac{|\dot Z_2 |^2}{4} + m(Z_2 ) \right) ds.
\end{equation}
We define $M_\theta = \max_{s \in [0,t]} Z_2(s)$. Set $B_+ = \{s: Z_2(s) \geq \theta_d\}$ and $B_- = [0,t]\setminus B_+$.  Recall that $m(\theta)/\theta$ is decreasing for $\theta\geq \theta_d$.    Define also $s_0$ such that $Z_2(s_0) = M_\theta$.  There are two cases.

\medskip

\noindent{\bf \# First case: $\int_{B_-} Z_2(s) ds \leq \int_{B_+} Z_2(s) ds$.}

\medskip

In this case, $M_\theta \geq \theta_d$. Indeed, if not, $B_+$ is an empty set which would yield a contradiction. Notice that $m(Z_2)/Z_2 \geq m(M_\theta)/M_\theta$ on $B_+$. Using this and applying Young's inequality gives
\begin{equation}\label{eq:zetabound}
\begin{split}
	\zeta(t,x,\theta) &\geq \frac{x^2}{4\int_0^t Z_2(s)ds} + \int_0^t m(Z_2(s))ds
		\geq \frac{x^2}{4\left(\int_{B_-} Z_2(s) ds + \int_{B_+} Z_2(s)ds\right)} + \int_{B_+} m(Z_2(s))ds\\
		&\geq \frac{x^2}{8 \int_{B_+} Z_2(s)ds} + \frac{m(M_\theta)}{M_\theta} \int_{B_+} Z_2(s)ds
		\geq x \left( \frac{m(M_\theta)}{2M_\theta} \right)^\frac{1}{2}.
%		&\qquad\geq x \sqrt\frac{\int_{B_+} m(Z_2(s))ds}{\theta_d|B_-| + \int_{B_+} Z_2(s)ds}
%		\geq x \sqrt{\frac{m(M_\theta)}{M_\theta} \frac{\int_{B_+} Z_2(s)ds}{\theta_d|B_-| + \int_{B_+} Z_2(s)ds}}
\end{split}
\end{equation}

We are now ready to bound $\zeta$ when $M_\theta$ is small, i.e. when $M_\theta \leq \eta_{\overline a}(t)$.
%\bigskip
%
%{\bf \# First sub-case: $M_\theta \leq \eta_{\overline a}(t)$.}
%
%\bigskip
Recall that when $\theta \geq \theta_d$, $m(\theta)/\theta$ is decreasing.  Due to this and \eqref{eq:phi_to_m}, together with the fact that $M_\theta \geq \theta_d$, we find 
%the fact that $x \geq \eta_{\overline a}(t)^{3/2}$,
\[
%	\frac{\overline a t}{C}\sqrt{\frac{x}{\eta_{\overline a}(t)^{3/2}}}
		\frac{\overline a t}{\sqrt2} \left(\frac{x}{\eta_{\overline a}(t)^{3/2}} \right)^\frac12
		\leq \frac{\overline a t}{\sqrt2} \frac{x}{\eta_{\overline a}(t)^{3/2}}
%		\leq x \sqrt{\frac{m(\eta_{\overline a}(t))}{\eta_{\overline a}(t)}}
		\leq x \left( \frac{m(\eta_{\overline a}(t))}{2\eta_{\overline a}(t)} \right)^\frac{1}{2}
		\leq x \left( \frac{m(M_\theta)}{2M_\theta} \right)^\frac{1}{2}
		\leq \zeta(t,x,\theta).
\]
This concludes the estimate of $\zeta$ is this sub-case.

%\bigskip
%
%{\bf \# Second sub-case: $M_\theta \geq \eta_{\overline a}(t)$.}
%
%\bigskip

Now consider the case when $M_\theta$ is large, i.e.~$M_\theta \geq \eta_{\overline a}(t)$.  Young's inequality implies that
\begin{equation}\label{eq:zetabound2}
\zeta(t,x,\theta) \geq \int_0^{s_0} \left( \frac{|\dot Z_2|^2}{4} +  m(Z_2) \right) ds
		\geq \int_0^{s_0} \dot Z_2 \sqrt{m(Z_2)} ds
		= \int_0^{s_0} \partial_s (\Phi(Z_2(s))) ds
		= \Phi(M_\theta).
\end{equation}
%We now recall that $\eta_{\overline a}(t) \leq M_\theta$ which implies that $\Phi(M_\theta) \geq \Phi(\eta_{\overline a}(t)) = \overline a t$. 
Combining \eqref{eq:zetabound} and~\eqref{eq:zetabound2} and Young's inequality, we obtain, recalling also \eqref{eq:phi_to_m},
\begin{equation*}
\begin{split}
	\zeta(t,x,\theta) &= \frac{\zeta(t,x,\theta)}{2} + \frac{\zeta(t,x,\theta)}{2}
		\geq \frac12 x \Big( \frac{m(M_\theta)}{2M_\theta} \Big)^\frac{1}{2} + \frac{\Phi(M_\theta)}{2}
		\\ &\geq \left( x \Big( \frac{m(M_\theta)}{2M_\theta} \Big)^\frac{1}{2} \Phi(M_\theta)\right)^\frac12
%		\geq \frac{1}{C} \left( x \sqrt\frac{m(M_\theta)}{M_\theta} + M_\theta \sqrt{m(M_\theta)}\right)
		\geq \Bigg( \frac{x M_\theta^\frac{1}{2} m(M_\theta)}{2^\frac12 D_m} \Bigg)^\frac12.
%		\geq \frac{1}{C} \sqrt{x m(M_\theta)} M_\theta^{1/4}.
\end{split}
\end{equation*}
From this and the fact that $M_\theta \geq \eta_{\overline a}(t)$, we conclude that
\begin{equation}
	\zeta(t,x,\theta)
		\geq \left( \frac{x \eta_{\overline a}(t)^\frac{1}{2} \frac{\Phi(\eta_{\overline a}(t))^2}{\eta_{\overline a}(t)^2} }{2^\frac12 D_m} \right)^\frac12 
		\geq \left( \frac{x \eta_{\overline a}(t)^{-\frac{3}{2}}}{2^\frac12 D_m} \right)^\frac12 \overline{a}t.
\end{equation}
%$ \leq C \sqrt{m(\eta_{\overline a}(t))}\eta_{\overline a}(t)$.

\medskip

\noindent{\bf \# Second case: $\int_{B_-} Z_2(s) ds > \int_{B_+} Z_2(s) ds$.}

\medskip

In this case, it follows that
\[
	\int_0^t Z_2(s)ds
		\leq \int_{B_-}Z_2(s)ds + \int_{B_+}Z_2(s)ds
		\leq 2 \int_{B_-} Z_2(s) ds
		\leq 2 \theta_d t.
\]
Hence, we finish by plugging this into~\eqref{eq:rhosimple} to obtain the bound $\zeta(t,x,\theta) \geq x^2/(8\theta_d t)$.
\end{proof}

With \Cref{lem:rho_bound} in hand, we are in a position to finish the proof of the upper bound of $\overline n$.
\begin{proof}[{\bf Proof of Proposition~\ref{prop:upperboundacc}}]

Assume first that $\theta \geq \eta_{\gamma_\infty + 1}(t)$. Proposition~\ref{prop:upperboundacc} follows by combining \eqref{eq:Q_asymptotics} with the fact that a function of the form $Q(\theta)e^{\gamma_\infty  t}$ is a super-solution to \eqref{eq:main}.

Thus, we may assume that $\theta \leq \eta_{\gamma_\infty + 1}(t)$.
%In addition, by \Cref{lem:large_theta}, we need only consider the case when   
Fix $x \geq \eta_{\overline a}(t)^{3/2}$ with $\overline a$ to be determined.  Using the definition of $w$ along with \Cref{lem:Li_Yau}, we have that
\[
	w(t,x,\theta)
		\leq C e^{Ct} \sum_{\ell=0}^\infty \exp\left\{ - \zeta(t,x+\ell,\theta)\right\}.
\]
We obtain a very rough bound on $w$ in the following way:
\begin{equation}\label{eq:upper_estimate}
\begin{split}
	w(t,&x,\theta) \leq \frac{Ce^{Ct}}{t} \sum_{\ell = 0}^\infty \exp\Big\{ - \frac{1}{2C} \min\Big(\overline{a} t\sqrt{ \frac{x+\ell}{\eta_{\overline a}(t)^{3/2}}},\frac{(x+\ell)^2}{t}\Big)\Big\} \\
		&\leq \displaystyle\frac{Ce^{Ct}}{t} \sum_{\ell = 0}^\infty 
		 \Big(e^{ - \frac{\overline a t}{2C}\sqrt{\frac{x+\ell}{\eta_{\overline a}(t)^{3/2}}}}
			+e^{-\frac{(x+\ell)^2}{2Ct}}\Big)
		\leq C e^{Ct} \Big(\frac{\eta_{\overline a}(t)^{3/2}}{\overline a^2 t^2} e^{ - \frac{\overline a t}{C}\sqrt{\frac{x}{\eta_{\overline a}(t)^{3/2}}}}
			+ \frac{e^{-\frac{x^2}{Ct}}}{\sqrt{t}}\Big).
\end{split}
\end{equation}
For $t\geq 1$, it is clear from its definition that $\eta_{\overline a}(t) \gg t^{2/3}$ and, hence, that $x^2/t \gg t$.  On the other hand, since $x \geq \eta_{\overline a}(t)^{3/2}$, the exponent of the first term may be bounded below by $\overline a t / C$.  Using this and choosing $\overline a$ big enough, we see that the right hand side of~\eqref{eq:upper_estimate} may be bounded by $C_{\overline a}e^{-(r+1) t}$.

We now apply this bound to finish the claim.  Recalling the definition of $v$ and recalling that $w$ is a super-solution to $v$, if $x \geq \eta_{\overline a}(t)^{3/2}$,
%and $\theta \leq \eta_{\gamma_\infty + 1}(t)$,
\[
	\overline n(t,x,\theta)
		= \theta^{-1/4} e^{rt} v(t,x,\theta)
		\leq \underline\theta^{-1/4} e^{rt} w(t,x,\theta)
		\leq C \underline\theta^{-1/4}e^{-t}.
\]
\end{proof}




%\subsection{The bound on $\rho$ and the proof of \Cref{thm:main}, case \ref{case:propzeroupper}.}
%
%Applying \Cref{prop:liyau}, we have constants $c_1, c_2, c_3$ such that for any $x\geq0$ and $\theta \in \Theta$, 
%\[
%	n(t,x,\theta) \leq \overline n(t,x,\theta)
%		\leq w(t,x,\theta)
%		\leq c_1 (\theta t)^n \exp \left\{c_2 t - c_3 \rho(t,x,\theta)\right\}
%\]
%As a consequence, we now estimate $\rho$ properly from below. To proceed with bounding $\rho$ from below, we recall that $\eta_a(t)$ is defined as the solution of
%\begin{equation*}
%\Phi( \eta_a(t) ) := \int_0^{\eta_a(t)} \sqrt{m(\theta)} \, d\theta = at.
%\end{equation*}
%
%\begin{remark}\label{rem:boundQ}
%Let us comment on this definition of $\eta_a(t)$. In fact, this comes naturally from the eigenvector $Q$ that arose previously in the paper.  Indeed, we saw before that a function of the from  $\overline n(t,x,\theta) = A Q(\theta)e^{\gamma_\infty t}$ could be taken as a super-solution to $n$. The decay of $Q$ thus provides an estimate on how the solution spreads in the trait variable $\theta$. Let us define $\Phi = - \ln Q$. Then, recalling \eqref{eq:specQ} $\Psi := \Phi'$ satisfies the following differential equation
%\begin{equation*}
%\begin{cases}
%\Psi' = \vert \Psi \vert^2 + (1 - \gamma_\infty - m), \qquad \theta \in \Theta, \medskip\\
%\Psi \left(  \theta  = \underline \theta \right) = 0.
%\end{cases}
%\end{equation*}
%We can formally guess from this that $\Psi \underset{\theta \to \infty}{\sim} \sqrt{m}$, so that $\Phi(\theta) \underset{\theta \to \infty}{\sim} \int_0^\theta \sqrt{m(\theta')} d \theta'$. It turns out that to quantify the spreading in the trait variable, one could compare $\Phi(\theta)$ to $\gamma_\infty t$ since
%\begin{equation*}
%\ln(n) \leq \ln(\overline n) = \ln(A) + \gamma_\infty t - \Phi(\theta), 
%\end{equation*}
%and it is exactly what $\eta_a(t)$ does. 
%%Now taking $\theta \geq \eta(t)$ with $\Phi(\eta(t)) = \left( \gamma_\infty + \eps \right) t$ we find what we want \EB{OR WITH A LOG}. 
%%\begin{remark}
%%Can we prove that $\int_0^\theta \sqrt{m(\theta')} d \theta' \sim \beta \theta \sqrt{m(\theta)}$ of give conditions ? The l'hopital rule gives a hint may be. 
%%
%%BTW we have to change the statement to use condtions like $m/\theta$ goes to blabla so that it is changeable to any $d(\theta)$.
%%\end{remark}
%\end{remark}
%
%\begin{lemma}\label{lem:metric_bound}
%Let $t \in \R^+$ and $x \geq \frac12 \eta_a(t)^{\frac32}$. Then
%\begin{equation}%\label{eq:metric_bound}
%	\rho(t,x,\theta) \geq \frac{a}{2} t + ????4rt + c_m^{-1} \theta \sqrt{m(\theta)}
%\end{equation} 
%holds for all $t$ sufficiently large.
%\end{lemma}
%
%We notice that the scaling in space matches the expected one for a cane toads operator. 
%%
%%Our strategy here is to separate into the case where $\theta$ is large and the case where $\theta$ is small.  When $\theta$ is large, we is finished by a general inequality due to Constantin, Kiselev, Oberman, and Ryzhik, which we refer to as the CKOR inequality.  On the other hand, when $\theta$ is small, we follow the characteristics given by the Euler-Lagrange equations for $\rho$ and obtain a lower bound on $\rho$ directly.
%
%\begin{proof}%[{\bf Proof of~\Cref{lem:metric_bound}}]
%
%Thanks to the Euler-Lagrange equations, we know that the infimum defining $\rho$ is actually a minimum and the minimizer is given by
%\begin{equation*}
%\forall s\in [0,t], \qquad \frac{d}{ds} \left( \frac{\dot x}{2 t \theta} \right) = 0,\qquad \frac{d}{ds} \left( \frac{\dot \theta}{2t}\right) = tm'(\theta(s)) - \frac{\vert\dot x(s) \vert^2}{4 t \theta(s)^2}
%\end{equation*}
%One can then find a constant (of $s$, but depending on $t,x,\theta$) $C$ such that 
%\begin{equation}\label{eq:traj1}
%\dot x = 2 C t \theta.
%\end{equation}
%Integrating \eqref{eq:traj1} on $(0,t)$, we find
%\begin{equation}\label{eq:traj2}
%C = -\frac{x}{2 t \int_{0}^t \theta(s) ds}.
%\end{equation}
%Combining \eqref{eq:traj1}, \eqref{eq:traj2} and the definition of $\rho$, we can now re-write $\rho$ as follows
%\begin{equation}\label{eq:rhosimple}
%	\rho(t,x,\theta) = \frac{x^2}{4 \int_{0}^t \theta(s) ds}  + \int_0^t \left( \frac{|\dot\theta(s)|^2}{4} +  m(\theta(s)) \right) ds .
%\end{equation}
%Now define $M_\theta = \max_{s \in [0,t]} \theta(s)$.  
%	
%\bigskip
%
%\noindent{\bf \# Step 1. $M_\theta$ is large : $M_\theta \geq \eta_a(t)$.}
%
%\bigskip
%
%Since $s \mapsto \theta(s)$ is a continuous trajectory, one can find $s_0 \in (0,t)$ such that $\theta(s_0) = M_\theta$. We may write, thanks to the Cauchy-Schwarz inequality
%\begin{multline*}
%\Phi(M_\theta)= \left\vert \Phi(\theta(t)) - \Phi(\theta(s_0)) \right\vert = \left\vert \int_{s_0}^t \frac{d}{ds} \left( \Phi(\theta(s)) \right) ds \right\vert \\= \left\vert \int_{s_0}^t \dot \theta(s) \sqrt{m\left( \theta(s) \right)} \,ds \right\vert \leq \int_{s_0}^t   \vert \dot \theta(s)\vert \sqrt{m\left( \theta(s) \right)} \,ds \leq \int_{0}^t   \vert \dot \theta(s)\vert \sqrt{m\left( \theta(s) \right)} \,ds \\ \leq \left( \int_0^t \dot \theta(s)^2 ds \int_0^t m(\theta(s))ds \right)^\frac12 \leq \frac12 \left( \int_0^t \dot \theta(s)^2 ds +  \int_0^t m(\theta(s))ds \right) \leq 2 \rho.
%\end{multline*}	
%Since $\Phi$ is increasing, we get that 
%\begin{equation*}
%\rho(t,x,\theta) \geq \frac12 \Phi(M_\theta) \geq \frac12 \Phi(\eta_a(t)) = \frac{a}2 t.
%\end{equation*}
%%	Then, we apply the CKOR inequality~\cite[Lemma ?]{CKOR} to obtain
%%	\[
%%		C M_\theta \sqrt{m(M_\theta)}
%%			\leq \sqrt{\int \dot \theta(s)^2 ds \int m(\theta(s))ds}
%%			\leq \int \frac{\dot \theta(s)^2}{t} ds + t\int m(\theta(s))ds
%%			\leq 4\rho(t,x,\theta).
%%	\]
%%	Clearly if $M_\theta \geq \theta_{a_u,t}$ with $a_u \geq 32r/C$ then $CM_\theta \sqrt{m(M_\theta)}/8 \geq 4rt$ by the definition of $\theta_{a_u,t}$~\eqref{?}.  Notice that $\theta = \theta(1) \leq M_\theta$, by definition.  Hence we conclude by noting that
%%	\[
%%		\rho(t,x,\theta) 
%%			\geq \frac{C M_\theta\sqrt{m(M_\theta)}}{8} + \frac{C M_\theta\sqrt{m(M_\theta)}}{8}
%%			\geq \frac{C \theta\sqrt{m(\theta)}}{8} + 4rt.
%%	\]
%%	
%%	
%%	Above we covered the case when $M_\theta \geq \theta_{a_u,t}$.  Hence, we now restrict ourselves to the case where $M_\theta \leq \theta_{a_u,t}$, i.e.~when $M_\theta \sqrt{m(M_\theta)} \leq 32rt/C$.  We point out that in this case $\theta \sqrt{m(\theta)} \leq 32rt/C$, and so it suffices to only prove that $\rho(t,x,\theta) \geq 5rt$ to finish the proof of the lemma.
%%
%%
%%Since $s\mapsto \theta(s)$ is continuous, one can find $s_0 \in [0,t]$ such that $\theta(s_0) = \theta$ and $\theta(s) \in [0,\theta]$ for all $s \geq s_0$. Since we seek a lower bound on $\rho$, we can assume for simplicity that $s_0 = 0$ \EB{ISSUE HERE}. 
%%
%We point out that in the large trait regime, one gets a bound independently of $x$, and this is reminiscent to \Cref{rem:boundQ} above. 
%
%\bigskip
%
%\noindent{\bf \# Step 2. $M_\theta$ is small : $M_\theta \leq \eta_a(t)$.}
%
%\bigskip
%
%Since $\theta \mapsto m(\theta)/\theta$ is decreasing and $\theta(s) \leq M_\theta$ on $(0,t)$, we may write $m(\theta(s))/\theta(s) \geq m(M_\theta)/M_\theta$ on $(0,t)$, and thus
%\[
%	\rho(t,x,\theta) \geq \frac{x^2}{4 \int_{0}^t \theta(s) ds} + \frac{m(M_\theta)}{M_\theta}\int_{0}^t \theta(s) ds \geq x \left( \frac{m(M_\theta)}{M_\theta} \right)^{\frac12}.
%\]
%We notice that we find the same kind of structure as when finding a speed of propagation for KPP problems.
%
%Now recalling $M_\theta \leq \eta_a(t)$ and the monotonicity of $\theta \mapsto m(\theta)/\theta$, we conclude that for any $(t,x,\theta) \in \R^+ \times \Gamma$,
%\[
%	\rho(t,x,\theta) \geq x \left( \frac{m(\eta_a(t))}{\eta_a(t)} \right)^{\frac12}.
%\]
%Since $m$ is increasing by \Cref{hyp:m}, we have that for any $t\in \R^+$,
%\begin{equation*}
%\sqrt{m(\eta_a(t))} \geq \frac{\Phi(\eta_a(t))}{\eta_a(t)}
%\end{equation*} 
%and thus for any $(t,x,\theta) \in \R^+ \times \Gamma$,
%\[
%	\rho(t,x,\theta) \geq x \left( \frac{\Phi(\eta_a(t))}{\eta_a(t)^{\frac32}} \right) = x \left( \frac{at}{\eta_a(t)^{\frac32}} \right) = \left( \frac{a x}{\eta_a(t)^{\frac32}} \right) t.
%\]
%The last step of the proof is to choose $x \geq \frac12 \eta_a(t)^{\frac32}$, which gives $\rho \geq \frac{a}{2} t$ in this case. 
%
%
%%\EB{WE CAN DIRECTLY USE $\sqrt{m(\eta(t))} \geq \frac{\Phi(\eta(t))}{\eta(t)}$ so that $x \geq \frac{1+\eps}{\gamma_\infty+\eps} \eta(t)^\frac32$}
%%
%%
%%Now choose $x(t)$ such that $x \left( \frac{m(\theta)}{\theta} \right)^{\frac12} \geq (1+ \eps) t$ and we are finished. 
%%
%%			
%%	We may take an optimal trajectory $(x(s),\theta(s))$ from $(0,0)$ to $(x,\theta)$ by compactness.  By the Euler-Lagrange equations, it is straightforward to compute that $(x(s),\theta(s))$ solves
%%	\[
%%		\dot x = A \theta(s) \qquad \text{ and } \qquad \ddot \theta = 2t^2 m'(\theta) - A^2/2,
%%	\]
%%	for some nonnegative constant $A$.  We do not use the second equation.  Now, we point out that
%%	\[
%%		x(1) = A \int_0^1 \theta(s) ds.
%%	\]
%%	Using this, we can also re-write $\rho$ as
%%	\[
%%		\rho(t,x,\theta) = \frac{A x(1)}{4t} + \int_0^1 \left[\frac{\dot\theta(s)^2}{4t} + t m(\theta(s)) ds \right] ds.
%%	\]
%%	
%%\hrule
%%
%%FORMER ELEMENTS
%%	We separate in two cases.  Fix $C_m > 0$ large enough that $\eta/m(\eta)$ is increasing for all $\eta \geq C_m$ and where $C_m / m(C_m) \geq \eta / m(\eta)$ for all $\eta \leq C_m$.  If $M_\theta \leq C_m$, independent of time, we have that
%%	\[
%%		x(1) = A \int_0^1 \theta(s) ds \leq A C_m.
%%	\]
%%	Hence, we have that
%%	\[
%%		\rho(t,x,\theta) \geq \frac{A x(1)}{4t} \geq \frac{x(1)^2}{4C_m t} \geq 5rt
%%	\]
%%	since $x(1)^2 \geq \theta_{a_u,t}^3 \gg t$.  That $\theta_{a_u,t}^3 \gg t$ is apparent from the definition of $\theta_{a_u,t}$ and the fact that $m$ is sub-linear.
%%	
%%	On the other hand, we consider the case where $M_\theta \geq C_m$.  If $A x(1) \geq 20rt^2$ or if $\int_0^1 m(\theta(s))ds \geq 5r$, we are finished.  We claim that one of the two must hold.  Arguing by contradiction, then we have that
%%	\[
%%		x(1)^2
%%			= A x(1) \int_0^1 \theta(s)ds
%%			\leq \left(20 rt^2\right) \left(\int_0^1 \left[\frac{M_\theta}{m(M_\theta)}\right] m(\theta(s)) ds\right)
%%			\leq \frac{100 r^2 t^2 M_\theta}{m(M_\theta)}.
%%	\]
%%	In the first inequality, we used that $M_\theta/m(M_\theta) \geq \eta / m(\eta)$ for all $\eta \leq M_\theta$ by the definition of $C_m$.  Then, by assumption we have that $M_\theta \leq \theta_{a_u,t}$ so, using monotonicity again, we have that
%%	\[
%%		x(1)^2
%%			\leq \frac{100 r^2 t^2 \theta_{a_u,t}}{m(\theta_{a_u,t})}
%%			= \frac{100 r^2 t^2 \theta_{a_u,t}^3}{\theta_{a_u,t}^2 m(\theta_{a_u,t})}
%%			\leq \frac{100 r^2 x(1)^2}{a_u^2}.
%%	\]
%%	The second inequality uses the definition of $\theta_{a_u,t}$ and also that $x(1) \geq \theta_{a_u,t}^{3/2}$.  Increasing $a_u$ if necessary, we may assume that $a_u > 10 r$.  This of course gives us a contradiction in the above inequality.  Hence it cannot be that both $Ax(1) \leq 20 rt^2$ and $\int_0^1 m(\theta(s))ds \leq 5r$ hold, finishing the proof.
%\end{proof}
%
%We have a bound on $\rho$ that we can now turn to a bound on $n$. 
%
%\begin{proof}%[{\bf Proof of Theorem \ref{thm:main}, case \ref{case:propzeroupper}}]
%
%Let $t > 0$ and $x \geq \frac12 \eta_a(t)^{\frac32}$. Then,
%
%\[
%	n(t,x,\theta) \leq \overline n(t,x,\theta)
%		\leq w(t,x,\theta)
%		\leq c_1 (\theta t)^n \exp \left\{c_2 t - c_3 \rho(t,x,\theta)\right\}
%		\leq c_1 (\theta t)^n \exp \left\{c_2 t - c_3 \frac{a}{2}t\right\}
%\]
%Choosing $a$ such that $c_2 - c_3 (a/2) < 0$ yields the result. 
%
%\end{proof}
%
%
%









%\subsection{A bound from above}
%
%We do this in a number of steps.  First, we note that it is enough to obtain an upper bound on the linearized equation since this forms a super-solution.  In light of that, we may write the solution
%\[
%	\overline n_t = \theta \overline n_{xx} + \overline n_{\theta\theta} + \overline n (1 - a(\theta))
%\]
%as
%\[
%	\overline n = e^{\lambda t} Q(\theta) \phi(t,x,\theta),
%\]
%where $Q$ is DEFINE IN EQREF and $\phi$ satisfies
%\begin{equation}\label{eq:phi}
%	\begin{cases}
%		\phi_t = \theta \phi_{xx} + \phi_{\theta\theta} + \frac{2 Q_\theta}{Q} \phi_\theta,\\
%		\phi_\theta(t,x,\underline \theta) = 0, \\
%		\phi(0,x,\theta) = N \ind{(-\infty,0]\times [\underline \theta, H]}
%			 \geq \frac{n_0(x,\theta)}{Q(\theta)}.
%	\end{cases}
%\end{equation}
%Here $N$ is chosen such that the inequality holds in the second line.  It depends only on $H$ and $Q$, and this is the only place where the dependence on $H$ appears.  We point out that $\phi$ is uniformly bounded in $N$ by the maximum principle.  We now seek a bound on all $x \geq \frac{1}{\epsilon_1} t^\frac{3}{2+p}$ for $\epsilon_1$ to be determined and for all $t$ sufficiently large.
%
%First we need a lemma on the decay of $Q$.
%\begin{lemma}\label{lemma:Q_asymptotics}
%	Exists $c_{p,\alpha} > 0$ ( <- Can compute) such that
%	\[
%		Q \sim \exp\left\{ - c_{p,\alpha} \theta^{1+p/2}\right\}.
%	\]
%\end{lemma}
%We restrict to two cases: the case when $\theta \geq t^\frac{2}{2+p}/\epsilon_2$ and when $t^\frac{2}{2+p}/\epsilon_2$ for some $\epsilon_2$ to be determined.  In the former case, we have that
%\[
%	Q(\theta) \leq \exp \left\{ - c_{p,\alpha} t / \epsilon_2^\frac{2+p}{2}\right\}.
%\]
%Hence, if $\epsilon_2$ is sufficiently small, depending only on $c_{p,\alpha}$ and on $\lambda$, we have that
%\[
%	\limsup_{t\to\infty} \overline n(t,x,\theta)
%		\leq \limsup_{t\to\infty} \exp\left\{\lambda t\right\}\exp \left\{ - c_{p,\alpha} t / \epsilon_2^\frac{2+p}{2}\right\} N
%		= 0.
%\]
%This fixes a choice of $\epsilon_2$.
%
%With this in mind, we need only consider the case when $\theta \leq t^\frac{2}{2+p}/ \epsilon_2$.  Here we switch to the probabilistic interpretation of the equation~\eqref{eq:phi}.  Then we have
%\begin{equation}\label{eq:probabilistic_representation}
%	\phi(t,x,\theta) = N \PP\left\{ X_t \leq 0, \Theta_t \leq H\right\}
%\end{equation}
%where $X_0 = x$, $\Theta_0 = \theta$, and 
%\begin{equation}\label{eq:stochastic_process}
%	\begin{cases}
%		dX_s = \sqrt{ 2 (\underline\theta,\underline\theta + s)} dW_s,\\
%		d(\underline\theta,\underline\theta + s) = \sqrt{2} dW_s - A((\underline\theta,\underline\theta + s)) ds,
%	\end{cases}
%\end{equation}
%where we have defined $A = - 2 Q_\theta / Q$.  Notice that $A \sim 2 c_{p,\alpha} \theta^{p/2}$.  We also stipulate that $(\underline\theta,\underline\theta + s)$ is a reflected process in order to satisfy the Neumann boundary conditions in~\eqref{eq:phi}.
%
%The main point here is that, if we can show that
%\begin{equation}\label{eq:main_upper_bound}
%	\PP(X_t \leq 0, \Theta_t \leq H) \leq Ce^{-2\lambda t},
%\end{equation}
%for some $C$, uniformly in $\theta \leq t^\frac{2}{2+p}/\epsilon_2$ and $x \geq t^\frac{3}{2+p}/\epsilon_1$ then $\phi$ tends to zero.  SAY MORE HERE.  BECAUSE
%\[
%	\overline n
%		= e^{\lambda t} Q \phi
%		\leq e^{\lambda t} \|Q\|_\infty N e^{-2\lambda t}.
%\]
%
%We separate our computations based on the event
%\[
%	B = \left\{ 2 \int_0^t (\underline\theta,\underline\theta + s) ds \leq \epsilon_3 t^\frac{4-p}{2+p}\right\},
%\]
%where $\epsilon_3$ is determined later.  We let $\cG_t = \sigma\left( (\underline\theta,\underline\theta + s) | s \in[0,t]\right)$, and we point out that when we condition on $\cG_s$, $X_t$ is a Gaussian random variable with variance $2 \int_0^t (\underline\theta,\underline\theta + s) ds$.  In order to compute the probability in~\eqref{eq:probabilistic_representation}, we decompose
%\[
%	\PP\left\{ X_t \leq 0, \Theta_t \leq H\right\}
%		= \PP\left( X_t \leq 0, \Theta_t \leq H, B\right) + \PP\left( X_t \leq 0, \Theta_t \leq H, B^c\right)
%		\leq \PP\left( X_t \leq 0, B\right) + \PP\left(B^c\right).
%\]
%We look at the event $X_t\leq 0$ and $B$ first.  Using our observation above, this is simply a computation about a Gaussian random variable.  Let $N$ be a mean zero, variance $1$ random variable and it follows that
%\[\begin{split}
%	\PP(X_t \leq 0, B)
%		&= \EE\left[ \ind{\{X_t \leq 0\}} \ind{B}\right]
%		= \EE\left[  \EE\left[ \ind{\{X_t \leq 0\}} \ind{B}| \cG_t\right] \right]\\
%		&= \EE\left[\ind{B}  \EE\left[ \ind{\{X_t \leq 0\}} | \cG_t\right] \right]
%		= \EE\left[\ind{B}  \PP\left( X_t \leq 0 | \cG_t\right) \right]
%		= \EE\left[\ind{B} \PP\left(N \geq x \left(2 \int_0^t (\underline\theta,\underline\theta + s)ds\right)^{-1/2}\right)\right]\\
%		&\leq \EE\left[  \PP\left(N \geq x t^{- \frac{4-p}{2+p}} / \epsilon_3\right)\right]
%%		\leq \exp\left\{- \epsilon_3 x^2 t^{-  \frac{4-p}{2+p}}\right\}.
%\end{split}\]
%Since we are considering here $x \geq t^\frac{3}{2+p}/ \epsilon_1$, the exponent simplifies to give us
%\begin{equation}\label{eq:first_prob_bound}
%		\PP\left( X_t \leq 0, B\right)
%			\leq \PP\left( X_t \leq 0 | B \right)
%			\leq \exp\left\{- \epsilon_3 \epsilon_1^{-2} t\right\}.
%\end{equation}
%Fixing the relationship between $\epsilon_3$ and $\epsilon_1$ as
%\begin{equation}\label{eq:eps_13}
%	\epsilon_3 = 2\lambda \epsilon_1^2,
%\end{equation}
%we have the claim~\eqref{eq:main_upper_bound} for the event $\{X_t\leq 0,B\}$.
%
%In view of the work above, we are finished if we can show that same upper bound for $\PP(B^c)$.  %Fix $C_0$ large enough such that if $\theta' \geq C_0$ then $A(\theta) \geq (\theta')^{p/2}/C_0$, and define the stopping time
%%\[
%%	\tau = \inf \left\{ s\geq 0 : (\underline\theta,\underline\theta + s) \leq C_0\right\}
%%\]
%To this end, we integrate \eqref{eq:stochastic_process} twice to obtain
%\[
%	\int_0^{t_0} (\underline\theta,\underline\theta + s) ds + \int_0^{t_0} (t_0-s) A((\underline\theta,\underline\theta + s)) ds
%		= \theta t_0 + \sqrt{2} \int_0^{t_0} W_s ds
%\]
%for any $t_0$.  Let $\cG^W_t = \left( W_s : 0 \leq s \leq t\right)$.  It is well know that $\int_0^{t_0} W_s ds$ is a normal random variable with mean 0 and variance $t_0^3/3$.  Define
%\begin{equation}\label{eq:B_W}
%	B_W = \left\{ \int_0^{t_0} W_s ds \geq \sqrt{\lambda t} t_0^{3/2}\right\}
%\end{equation}
%and it is easy to see that
%\[
%	\PP(B_W)
%		= \PP\left(N \geq \sqrt{3 \lambda t}  \right)
%		\leq  e^{ - 3 \lambda t}.
%\]
%Hence, we have bounded $\PP(B^c, B_W) \leq e^{-3 \lambda t}$.  It follows that we need only consider $\PP(B^c, B_W^c)$.
%


%\subsection{FIND A TITLE}
%
%Here we prove the non-sharp upper bound that propagation is no faster than
%\[
%	t^\frac{3 + p/2}{2 + p}.
%\]
%For technical reasons, we assume that $t \geq 2$.
%We do this in a number of steps.  First, we note that it is enough to obtain an upper bound on the linearized equation since this forms a super-solution.  In light of that, we may write the solution of 
%\[
%	\overline n_t = \theta \overline n_{xx} + \overline n_{\theta\theta} + \overline n (1 - m), \qquad \text{on } \Gamma,
%\]
%as
%\[
%	\overline n = e^{\gamma_\infty t} Q(\theta) p(t,x,\theta),
%\]
%where $Q$ is defined in \eqref{eq:specQ} and $p$ satisfies
%\begin{equation}\label{eq:phi}
%	\begin{cases}
%		p_t = \theta p_{xx} + p_{\theta\theta} -2 \Psi p_\theta,\medskip\\
%		p_\theta(\cdot,\underline \theta) = 0, \medskip\\
%		p(0,\cdot) = N \ind{\Gamma_{\infty,s}^-}
%			 \geq \frac{n_0(x,\theta)}{Q(\theta)}.
%	\end{cases}
%\end{equation}
%Here $N$ is chosen such that the inequality holds in the second line.  It depends only on $H$ and $Q$, and this is the only place where the dependence on $H$ appears.  We point out that $\phi$ is uniformly bounded in $N$ by the maximum principle.  We now seek a bound on all $x \geq \frac{1}{\epsilon_1} t^\frac{3}{2+p}$ for $\epsilon_1$ to be determined and for all $t$ sufficiently large.
%
%We restrict to two cases: the case when $\theta \geq t^\frac{2}{2+p}/\epsilon_2$ and when $t^\frac{2}{2+p}/\epsilon_2$ for some $\epsilon_2$ to be determined.  In the former case, we have that
%\[
%	Q(\theta) \leq \exp \left\{ - c_{p,\alpha} t / \epsilon_2^\frac{2+p}{2}\right\}.
%\]
%Hence, if $\epsilon_2$ is sufficiently small, depending only on $c_{p,\alpha}$ and on $\lambda$, we have that
%\[
%	\limsup_{t\to\infty} \overline n(t,x,\theta)
%		\leq \limsup_{t\to\infty} \exp\left\{\lambda t\right\}\exp \left\{ - c_{p,\alpha} t / \epsilon_2^\frac{2+p}{2}\right\} N
%		= 0.
%\]
%This fixes a choice of $\epsilon_2$.
%
%With this in mind, we need only consider the case when $\theta \leq t^\frac{2}{2+p}/ \epsilon_2$.  Here we switch to the probabilistic interpretation of the equation~\eqref{eq:phi}.  Then we have
%\begin{equation}\label{eq:probabilistic_representation}
%	\phi(t,x,\theta) = N \PP\left\{ X_t \leq 0, \Theta_t \leq H\right\}
%\end{equation}
%where $X_0 = x$, $\Theta_0 = \theta$, and 
%\begin{equation}\label{eq:stochastic_process}
%	\begin{cases}
%		dX_s = \sqrt{ 2 (\underline\theta,\underline\theta + s)} dW_s,\\
%		d(\underline\theta,\underline\theta + s) = \sqrt{2} dW_s - A((\underline\theta,\underline\theta + s)) ds,
%	\end{cases}
%\end{equation}
%where we have defined $A = - 2 Q_\theta / Q$.  Notice that $A \sim 2 c_{p,\alpha} \theta^{p/2}$.  We also stipulate that $(\underline\theta,\underline\theta + s)$ is a reflected process in order to satisfy the Neumann boundary conditions in~\eqref{eq:phi}.
%
%The main point here is that, if we can show that
%\begin{equation}\label{eq:main_upper_bound}
%	\PP(X_t \leq 0, \Theta_t \leq H) \leq Ce^{-2\lambda t},
%\end{equation}
%for some $C$, uniformly in $\theta \leq t^\frac{2}{2+p}/\epsilon_2$ and $x \geq t^\frac{3}{2+p}/\epsilon_1$ then $\phi$ tends to zero.  SAY MORE HERE.  BECAUSE
%\[
%	\overline n
%		= e^{\lambda t} Q \phi
%		\leq e^{\lambda t} \|Q\|_\infty N e^{-2\lambda t}.
%\]
%
%We separate our computations based on the event
%\[
%	B_I = \left\{ 2 \int_0^t (\underline\theta,\underline\theta + s) ds \leq t^\frac{4}{2+p}/\epsilon_3 \right\},
%\]
%where $\epsilon_3$ is determined later.  We let $\cG_t = \sigma\left( (\underline\theta,\underline\theta + s) | s \in[0,t]\right)$, and we point out that when we condition on $\cG_s$, $X_t$ is a Gaussian random variable with variance $2 \int_0^t (\underline\theta,\underline\theta + s) ds$.  In order to compute the probability in~\eqref{eq:probabilistic_representation}, we decompose
%\[
%	\PP\left\{ X_t \leq 0, \Theta_t \leq H\right\}
%		= \PP\left( X_t \leq 0, \Theta_t \leq H, B\right) + \PP\left( X_t \leq 0, \Theta_t \leq H, B^c\right)
%		\leq \PP\left( X_t \leq 0, B_I\right) + \PP\left(B_I^c\right).
%\]
%We look at the event $X_t\leq 0$ and $B_I$ first.  Using our observation above, this is simply a computation about a Gaussian random variable.  Let $N$ be a mean zero, variance $1$ random variable and it follows that
%\[\begin{split}
%	\PP(X_t \leq 0, B_I)
%		&= \EE\left[ \ind{\{X_t \leq 0\}} \ind{B_I}\right]
%		= \EE\left[  \EE\left[ \ind{\{X_t \leq 0\}} \ind{B_I}| \cG_t\right] \right]\\
%		&= \EE\left[\ind{B_I}  \EE\left[ \ind{\{X_t \leq 0\}} | \cG_t\right] \right]
%		= \EE\left[\ind{B_I}  \PP\left( X_t \leq 0 | \cG_t\right) \right]
%		= \EE\left[\ind{B_I} \PP\left(N \geq x \left(2 \int_0^t (\underline\theta,\underline\theta + s)ds\right)^{-1/2}\right)\right]\\
%		&\leq \EE\left[  \PP\left(N \geq x \epsilon_3^{1/2} / t^{- \frac{2}{2+p}}\right)\right]
%%		\leq \exp\left\{- \epsilon_3 x^2 t^{-  \frac{4-p}{2+p}}\right\}.
%\end{split}\]
%Since we are considering here $x \geq t^\frac{6 + p}{4+2p}/ \epsilon_1$, the exponent simplifies to give us
%\begin{equation}\label{eq:first_prob_bound}
%		\PP\left( X_t \leq 0, B_I\right)
%			\leq \PP\left( X_t \leq 0 | B_I \right)
%			\leq \exp\left\{- \epsilon_3 \epsilon_1^{-2} t\right\}.
%\end{equation}
%Fixing the relationship between $\epsilon_3$ and $\epsilon_1$ as
%\begin{equation}\label{eq:eps_13}
%	\epsilon_3 = 2\lambda \epsilon_1^2,
%\end{equation}
%we have the claim~\eqref{eq:main_upper_bound} for the event $\{X_t\leq 0,B_I\}$.
%
%In view of the work above, we are finished if we can show that same upper bound for $\PP(B_I^c)$ holds.  %Fix $C_0$ large enough such that if $\theta' \geq C_0$ then $A(\theta) \geq (\theta')^{p/2}/C_0$, and define the stopping time
%%\[
%%	\tau = \inf \left\{ s\geq 0 : (\underline\theta,\underline\theta + s) \leq C_0\right\}
%%\]
%To this end, we integrate \eqref{eq:stochastic_process} twice to obtain {\color{red} NEED TO DEAL WITHTHE FACT THAT THETA MIGHT CHANGE SIGNS.  I THINK CAN JUST ADD ABSOLUTE VALUES}
%\begin{equation}\label{eq:integral_eqn}
%	\int_0^{2t} (\underline\theta,\underline\theta + s) ds + \int_0^{2t} (2t-s) A((\underline\theta,\underline\theta + s)) ds
%		= 2\theta t + \sqrt{2} \int_0^{2t} W_s ds,
%\end{equation}
%where $A$ is the nonnegative function $-2Q_\theta/Q$.  Let $\cG^W_t = \left( W_s : 0 \leq s \leq t\right)$.  It is well know that $\int_0^{2t} W_s ds$ is a normal random variable with mean 0 and variance $8t^3/3$.  Define
%\begin{equation}\label{eq:B_W}
%	B_W = \left\{ \int_0^{2t} W_s ds \geq \sqrt{8\lambda} t^2\right\}
%\end{equation}
%and it is easy to see that
%\[
%	\PP(B_W)
%		= \PP\left(N \geq \sqrt{3 \lambda t}  \right)
%		\leq  e^{ - 3 \lambda t}.
%\]
%Hence, we have bounded $\PP(B_I^c, B_W) \leq e^{-3 \lambda t}$.  It follows that we need only consider $\PP(B_I^c, B_W^c)$.
%
%We separate $[0,t]$ into $S_t = \{ s \in [0,t] : (\underline\theta,\underline\theta + s) \geq C_0\}$ where $C_0$ is a constant chosen large enough that when $\theta \geq C_0$ we have that
%\begin{equation}\label{eq:A}
%	\theta^{p/2}/C_0 \leq A(\theta) \leq C_0 \theta^{p/2}.
%\end{equation}
%Define $M_t = \max_{0\leq s \leq t} (\underline\theta,\underline\theta + s)$.  Then~\eqref{eq:integral_eqn} gives us that
%\[
%	\left| \int_0^{2t} W_s ds\right| + 2\theta t
%		\geq t\int_0^t A((\underline\theta,\underline\theta + s)) ds
%		\geq \frac{t}{C_0}\int_{S_t} (\underline\theta,\underline\theta + s)^{p/2} ds
%		\geq \frac{t}{C_0}\int_{S_t} \frac{(\underline\theta,\underline\theta + s)}{M_t^{1 - p/2}} ds.
%\]
%We point out that this inequality is likely where the loss of sharpness occurs.  Indeed, we expect $(\underline\theta,\underline\theta + s) \sim M_t$ for a very small fraction of time; hence, the estimate above is quite poor for the majority of time $s\in[0,t]$.  This implies that
%\begin{equation}\label{eq:key_inequality}
%	\int_0^t (\underline\theta,\underline\theta + s) ds
%		= \int_{S_t^c} (\underline\theta,\underline\theta + s) ds + \int_{S_t} (\underline\theta,\underline\theta + s) ds
%		\leq \left(|S_t^c| C_0\right) + \frac{C_0 M_t^{1-p/2}}{t} \left( \left|\int_0^{2t} W_s ds\right| + 2\theta t \right).
%\end{equation}
%Define $B_M = \{ M_t \geq \epsilon^{-1}_4 t^{2/(2+p)}\}$ for $\epsilon_4 < \epsilon_2$ to be determined.  Using that $|S_t^c|\leq t$ and that $\theta \leq \epsilon_2^{-1} t^{2/(2+p)}$, then~\eqref{eq:key_inequality} implies that if $B_W^c\cap B_M^c$ occurs, we have that
%\[
%	\int_0^t (\underline\theta,\underline\theta + s) ds
%		\leq C_0t + \frac{C_0 (\epsilon_4^{-1}t^{2/(2+p)})^{1-p/2}}{t} \left( \sqrt{8\lambda} t^2 + \frac{2}{\epsilon_2} t^\frac{4+p}{2+p} \right)
%		\leq \frac{C_0}{\epsilon_4^\frac{2-p}{2}} \left( \epsilon_4^\frac{2-p}{2} t + \sqrt{8\lambda} t^\frac{4}{2+p} + \frac{2}{\epsilon_2} t^\frac{4-p}{2+p}\right)
%		\leq \frac{C}{\epsilon_4^\frac{2-p}{2}} t^\frac{4}{2+p}.
%\]
%In the last line, we simply used the assumption that $t \geq 2$ so that $t^\frac{4}{2+p}$ is the dominant term.  Choosing $\epsilon_3$ small enough depending on $\epsilon_4$, we see that $B_W^c \cap B_M^c \subset B_I^c$.  Hence we have that $\PP(B_W^c, B_I^c) = \PP(B_W^c, B_I^c, B_M) \leq \PP(B_M)$.
%
%The above reduces our claim to showing that $\PP(B_M) \leq e^{-2\lambda t}$.  Proving this claim with finish the proof of the upper bound.  We show this now.  To this end, we define the stopping times
%\[
%	\tau_{2i + 1} = \inf\left\{ s > \tau_{2i} : (\underline\theta,\underline\theta + s) = t^\frac{2}{2+p}/\epsilon_4 \text{ or } 2C_0 \right\}
%	~~ \text{ and } ~~
%	\tau_{2i} =\inf\left\{ s > \tau_{2i-1} : (\underline\theta,\underline\theta + s) = \theta \right\},
%\]
%where $i$ is a nonnegative integer.  We define also $\tau_0 = 0$.  It is easy to see that $\tau_j$ is almost surely finite for all $j$.  In addition, define the events
%\[
%	B_{M,2i-1} = \left\{ \Theta_{\tau_{2i+1}} = 2C_0\right\},
%	~~ \text{ and } ~~
%	B_{M,2i} = \left\{ \tau_{2i} - \tau_{2i-1} \geq T\right\}.
%\]
%where we define $T = \min\left\{ (2 C (3 C_0)^{p/2})^{-1}, C_0^2(12 \lambda t)^{-1}\right\}$.
%
%If we can show that
%\begin{equation}\label{eq:small_sequence}
%	\PP(B_{M,2i+1}), \PP(B_{M,2i}|B_{M,2i-1}) \geq 1 - Ce^{-3\lambda t}
%\end{equation}
%for some $C$ independent of time and for all $i$, then it is easy to check that
%\[
%	B_{M,1}\cap B_{M,2} \cap \cdots \cap B_{M,2N} \subset B_M^c,
%\]
%where $N = tT = O(t^2)$.  Hence we have that
%\[\begin{split}
%	\PP(B_M^c)
%		&\geq \PP(B_{M,1}\cap B_{M,2} \cap \cdots \cap B_{M,2N})
%			= \prod_{i=0}^{2N} \PP(B_{M,i} | B_{M,1}, \dots, B_{M,i-1})\\
%		&\geq \left(\prod_{i=0}^N \PP^\theta(B_{M,2i+1})\right)\left(\prod_{i=1}^N \PP(B_{M,2i}|B_{M,2i-1})\right)
%			\geq (1 - e^{-3\lambda t})^{2N}
%			\geq 1 - C e^{-2\lambda t}.
%\end{split}\]
%Hence we have that $\PP(B_M) \leq C e^{-2\lambda t}$.
%
%
%\subsubsection*{Understanding $B_{M,2i+1}$}
%
%Thus, to finish the proof, we need only prove~\cref{eq:small_sequence}.  We begin by applying It\^{o}'s lemma to a new process $\Tilde (\underline\theta,\underline\theta + s) = \phi((\underline\theta,\underline\theta + s))$ where $\phi$ is to be determined.  We obtain
%\[
%	d\tilde (\underline\theta,\underline\theta + s) = (-A((\underline\theta,\underline\theta + s)) \phi'((\underline\theta,\underline\theta + s)) + \phi''((\underline\theta,\underline\theta + s))) ds + \sqrt{2} \phi'((\underline\theta,\underline\theta + s)) dB_s.
%\]
%It is clear that if $\phi' = Q^{-2}$, then the above simplifies to
%\[
%	d\tilde (\underline\theta,\underline\theta + s) = \sqrt{2} \phi'((\underline\theta,\underline\theta + s)) dB_s,
%\]
%which is a martingale.  Hence, we obtain that
%\begin{equation}\label{eq:martingale}
%	\phi(\theta)
%		= \EE\left[ \tilde \Theta_{\tau_{2i}}\right]
%		= \EE\left[ \tilde \Theta_{\tau_{2i+1}}\right]
%		= \PP(\Theta_{\tau_{2i+1}} = C_0) \phi(C_0) + \PP(\Theta_{\tau_{2+1}} = t^{2/(2+p)}/\epsilon_4) \phi(t^{2/(2+p)}/\epsilon_4)
%\end{equation}
%Let $p = \PP(\Theta_{\tau_{2i+1}} = t^{2/(2+p)}/\epsilon_4) = \PP(B_{M,2i+1})$ and let
%\[
%	\phi(\theta') = \int_\theta^{\theta'} Q(\theta'')^{-2} d\theta''.
%\]
%It is straight-forward to deduce that there is a constant $C_p$, depending only on $p$ and the choice of $C_0$, such that
%\[
%	\frac{1}{C_p} e^{\theta^{1+p/2}/C_p}
%		\leq Q(\theta)^{-2}
%		\leq C_p e^{C_p \theta^{1+p/2}}
%\]
%for all $\theta \geq C_0$.  Hence we may easily deduce that
%\[
%	\phi(C_0) \geq - C e^{Ct / \epsilon^{2/(2+p)}}
%	~~ \text{ and } ~~
%	\phi(t^{2/(2+p)/\epsilon_4}) \geq C^{-1} e^{ t / (C\epsilon_4^{2/(2+p)})},
%\]
%for some constant $C$, depending only on $p$ and the choice of $C_0$.  With this in hand,~\eqref{eq:martingale} becomes
%\[
%	0 \geq -(1-p)C e^{Ct / \epsilon^{2/(2+p)}} + p C^{-1} e^{ t / (C\epsilon_4^{2/(2+p)})}.
%\]
%This, clearly, yields
%\[
%	1 \geq (1-p)C^2 \geq p e^{t \left(\frac{1}{C \epsilon_4^{2/(2+p)}} -\frac{C}{\epsilon_2^{2/(2+p)}} \right)}.
%\]
%Choosing $\epsilon_4$ small enough, depending only on $\epsilon_2$ and $C$, we obtain
%\[
%	p \leq e^{-3\lambda t}
%,\]
%finishing the proof for $B_{M,2i+1}$.
%
%\subsubsection*{Understanding $B_{M,2i}$}
%
%Now we consider the case of $B_{M,2i}$.  Define
%\[
%	\tau = \inf\{ s > 0 : \Theta_{s + \tau_{2i-1}} = C_0 \text{ or } 3C_0\}
%	~~ \text{ and } ~~
%	\tau_W = \inf\{ s > 0 : W_{s=0} = - C_0/2 \text{ or } C_0/2\}
%\]
%where $W_s$ is the Weiner process in the definition of $(\underline\theta,\underline\theta + s)$.  Also, define
%\[
%	T = \min\left\{ (2 C (3 C_0)^{p/2})^{-1}, C_0^2(12 \lambda t)^{-1}\right\}.
%\]
%
%
%Using~\eqref{eq:stochastic_process}, we see that
%\[
%	\Theta_{\tau + \tau_{2i-1}} + \int_0^s A(\Theta_{\tau + \tau_{2i-1}}) ds' = 2C_0\tau + W_\tau.
%\]
%If $\Theta_{\tau+\tau_{2i-1}} = 3 C_0$, we have that
%\[
%	3C_0 \leq 2C_0 + W_\tau.
%\]
%On the other hand, if $\Theta_{\tau+\tau_{2i-1}} = C_0$, we have that
%\[
%	C_0 + \tau C (3C_0)^{p/2} \geq 2 C_0 + B_\tau
%\]
%which, since $T \leq (2 C (3 C_0)^{p/2})^{-1}$, implies that
%\[
%	B_\tau \leq - C_0 + \tau C (3 C_0)^{p/2}
%		\leq - C_0 + C_0/2 = -C_0/2.
%\]
%Hence, we have that $\{\tau \leq T\} \subset \{\tau_W \leq T\}$.  This implies that
%\[
%	\PP(\tau \leq T)
%		= \PP(\tau_W \leq T)
%		= 4 \PP(|B_T| \geq C_0/2)
%		\leq 4 \exp\left( - \frac{C_0^2}{4T}\right)
%		\leq 4 \exp\left( - 3 \lambda t\right).
%\]
%
%
%
%%Set, for any $a > 0$, $\tau_{a} = \inf\{s > 0 : \Theta_{s+\tau_{2i-1}} = a\}$.Notice that $\min\{\tau_{C_0}, \tau_{3C_0}\} \leq \tau_{2i} - \tau_{2i-1}$, so a lower bound on this quantity gives a lower bound on $\tau_{2i}-\tau_{2i-1}$.
%
%%Using~\eqref{eq:stochastic_process}, we see that
%%\[
%%	\Theta_{s + \tau_{2i-1}} + \int_0^s A(\Theta_{s' + \tau_{2i-1}}) ds' = 2C_0s + B_s.
%%\]
%%Then we have that
%%\[
%%	\Theta_{s + \tau_{2i-1}} \leq 2C_0 + B_s.
%%\]
%%If $s \leq s_1 := (1 + 6C_0^2 \lambda t)^{-1}$, then we have that
%%\[
%%	\PP(\Theta_{s + \tau_{2i-1}} \geq 3 C_0)
%%		\leq \PP(B_s \geq C_0)
%%		\leq \PP\left(N \geq C_0 / \sqrt{6 C_0^2 \lambda t}\right)
%%		\leq \exp\left\{ - 3 \lambda t\right\}.
%%\]
%%Hence if $\tau < s_1$ and $\Theta_\tau = 3C_0$, then we have that CHANGE PRECEDING SENTENCE
%%\[\begin{split}
%%	\PP(\tau_{3C_0} < s_1)
%%		&= \PP(\tau_{3C_0} < s_1, \Theta_{s_1 + \tau_{2i-1}} < 3C_0)
%%			+ \PP(\tau_{3C_0} < s_1, \Theta_{s_1 + \tau_{2i-1}} \geq 3 C_0)\\
%%		&= \EE[ \ind{\tau_{3C_0} < s_1} \PP(\Theta_{s_1 - \tau_{3C_0}}^{3C_0} < 3C_0 | \tau_{3C_0} < s_1) ]
%%			+ \PP(\Theta_{s_1 + \tau_{2i-1}} \geq 3C_0)\\
%%		&\leq \frac{1}{2}\PP[
%%\end{split}\]
%%
%%
%%In addition, we have that
%%\[
%%	\Theta_{s + \tau_{2i-1}} + ???? \geq 2C_0s + B_s.
%%\]
%
%%Again we begin with It\^{o}'s Lemma.  Let $\phi(\theta') = (\theta')^{1-p/2}$ for all $\theta'$.  Then, letting $\tilde (\underline\theta,\underline\theta + s) = \phi((\underline\theta,\underline\theta + s))$, we have that
%%\[
%%	d\tilde (\underline\theta,\underline\theta + s) = \left(- (1-p/2)A((\underline\theta,\underline\theta + s))(\underline\theta,\underline\theta + s)^{-p/2} - \frac{p}{2}(1-p/2) (\underline\theta,\underline\theta + s)^{-(1+ p/2)}\right)ds + \sqrt{2}(1-p/2) (\underline\theta,\underline\theta + s)^{-p/2} dB_s.
%%\]
%%%Define the stopping times $\tilde \tau_0 = 0$ and
%%%\[
%%%	\tilde \tau_{2j+1} = \inf \left\{s >\tilde \tau_{2j} : \Theta_{s + \tau_{2i-1}} = C_0 \text{ or } t^{2/(2+p)}/\epsilon_2\right\}
%%%	~~\text{ and }~~
%%%	\tilde \tau_{2i} = \inf \left\{s >\tilde \tau_{2j-1} : \Theta_{s + \tau_{2i-1}} = 2C_0\right\}.
%%%\]
%%%Notice that $\tau_{2i} - \tau_{2i-1} = \min_j \{ \tilde \tau_{2j+1} : \Theta_{\tilde \tau_{2j+1} + \tau_{2i-1}} = t^{2/(2+p)}/\epsilon_4\}$.
%%%
%%%Fix $j$ Using~\eqref{eq:stochastic_process}, we see that
%%%\[
%%%	asdf
%%%\]
%
%
%
%
%%%
%%% there is a constant $C$ such that $\tilde \Theta_{s+\tau_{2i-1}} + C s$ is a sub-martingale  whenever $(\underline\theta,\underline\theta + s)  \geq C_0$.  Take $j$ which achieves the minimum above.  Then we have that
%%%\[
%%%	\EE[ \tilde \Theta_{\tilde\tau_{2j}+ \tau_{2i-1}}]
%%%		\leq \EE[\tilde \Theta_{\tilde\tau_{2j+1}+ \tau_{2i-1}} - C(\tau_{2j+1} - \tau_{2j})].
%%%\]
%%%Plugging in the values for 
%
%
%
%
%
%
%%\subsection{Let's try Girsanov}
%%
%%We start with the equation 
%%\begin{equation*}
%%u_t = \theta u_{xx} + u_{\theta \theta} + r(\theta) u
%%\end{equation*}
%%with $r(\theta) = 1 - \alpha \theta^p$.
%%As before, we define $X_t = X_0 + \int_{0}^t \sqrt{s} dB_s$, with $X_0 = x$ and $(\underline\theta,\underline\theta + s)$ is a Brownian motion starting from $\theta$. By the Feymann-Kac formula (or the many-to-one lemma), we have
%%\begin{equation*}
%%u(t,x,\theta) = \EE^{x,\theta}\left[ e^{\int_0^t r((\underline\theta,\underline\theta + s)) \, ds} u_0(X_t,\theta_t) \right] 
%%\end{equation*}
%%We start by conditioning on the filtration associated with $(\underline\theta,\underline\theta + s)$, to have full information for $X_t$. It yields
%%\begin{equation*}
%%\begin{array}{lcl}
%%u(t,x,\theta) = \EE\left[ \EE^{x,\theta}\left[ e^{\int_0^t r((\underline\theta,\underline\theta + s)) \, ds} u_0(X_t,\theta_t) \Big\vert \cG_t \right] \right] & = & \EE\left[ e^{\int_0^t r((\underline\theta,\underline\theta + s)) \, ds} \EE^{x,\theta}\left[ \ind{\{X_t \leq 0\}} \ind{\{\theta_t \leq 1\}}  \vert \cG_t \right] \right] \\
%%& = & \EE\left[ e^{\int_0^t r((\underline\theta,\underline\theta + s)) \, ds} \ind{\{\theta_t \leq 1\}}   \EE^{x,\theta}\left[ \ind{\{X_t \leq 0\}} \vert \cG_t \right] \right] \\
%%\end{array}
%%\end{equation*}
%%We now estimate $\EE^{x,\theta}\left[ \ind{\{X_t \leq 0\}} \vert \cG_t \right]$ as before, we find
%%\begin{equation*}
%%\EE^{x,\theta}\left[ \ind{\{X_t \leq 0\}} \vert \cG_t \right] = \PP\left(N \geq x \left(2 \int_0^t (\underline\theta,\underline\theta + s) ds\right)^{-1/2}\right)
%%\end{equation*}
%%with is explicitly estimable. Now, we have to compute 
%%\begin{equation*}
%%\EE^{\theta}\left[ e^{\int_0^t r((\underline\theta,\underline\theta + s)) \, ds} \ind{\{\theta_t \leq 1\}}   \PP\left(N \geq x \left(2 \int_0^t (\underline\theta,\underline\theta + s) ds\right)^{-1/2}\right)\right]
%%\end{equation*}
%%but in this formulation $(\underline\theta,\underline\theta + s)$ is a standard Brownian motion. We now change the measure to follow a given path, that compensates the growth term. By the Girsanov theorem (hopefully), we have
%%\begin{multline*}
%%\EE^{\theta}\left[ e^{\int_0^t r((\underline\theta,\underline\theta + s)) \, ds} \ind{\{\theta_t \leq 1\}}   \PP\left(N \geq x \left(2 \int_0^t (\underline\theta,\underline\theta + s) ds\right)^{-1/2}\right)\right] \\= 
%%\widetilde\EE^{\widetilde\theta_0}\left[ e^{\int_0^t r(\widetilde (\underline\theta,\underline\theta + s) + g(s)) \, ds - \int_0^t \frac12 \vert g'(s) \vert^2 ds } \ind{\{\widetilde\theta_t \leq 1\}} e^{- \int_0^t g'(s) d\widetilde(\underline\theta,\underline\theta + s)} \PP\left(N \geq x \left(2 \int_0^t \left\vert \widetilde(\underline\theta,\underline\theta + s) + g(s) \right\vert ds\right)^{-1/2}\right)\right]
%%\end{multline*}
%%where now $\widetilde \theta$ is a Brownian motion under $\widetilde\EE$, starting from $\widetilde\theta_0 = 0$. The drift $g$ should be defined accordingly. We should compute 
%%\begin{equation*}
%%\inf_{g \vert g(0) = \theta_0, g(t) = 0} \left( \int_0^t \left[ - r(g(s)) + \frac12 \vert g'(s) \vert^2 \right] ds \right)
%%\end{equation*}
%%which is as in Hamilton Jacobi for us. We can also choose it and then do some estimates like in Berestycki et al.
%%There is some hope since :
%%\begin{enumerate}
%%\item The drift is now given and deterministic.
%%\item In Berestycki and al and Harris and al they control easily the stochastic integral $\int_0^t g'(s) d\widetilde(\underline\theta,\underline\theta + s)$.
%%\item They say that the trajectoried being polynomial, the Brownian is negligible in their case. 
%%\item The process is now only a Brownian.
%%\end{enumerate}
%%Remains to find the equivalent of the event $B$ before. 
%%Can we conclude if we get rid of the Brownian ? That is :
%%\begin{equation*}
%%e^{\int_0^t r(g(s)) \, ds - \int_0^t \frac12 \vert g'(s) \vert^2 ds } \PP\left(N \geq x \left(2 \int_0^t \left\vert g(s) \right\vert ds\right)^{-1/2}\right)
%%\end{equation*}
%%has the good scaling ? 
%











\subsection{The lower bound}


In order to finish the proof of \Cref{thm:acceleration}, we now need to prove the lower bound, i.e.~ we show:

\begin{prop}\label{prop:lowerboundacc}
%	Suppose that $m$ satisfies \Cref{hyp:m}, that $\gamma_\infty > 0$ and that $m(\theta)/\theta$ tends to zero as $\theta$ tends to $+\infty$.  Then there exist positive constants $\underline n$, $\underline a$ such that
Under the assumptions of \Cref{thm:acceleration}, there exists $\underline n, \underline{a}>0$ such that
	\[
		\liminf_{t \to \infty} \inf_{|x| \leq \eta_{\underline{a}}(t)^{3/2}} n(t,x,\underline\theta) \geq \underline n.
	\]
\end{prop}

\subsubsection*{The moving Dirichlet ball sub-solution}

As we mentioned in the introduction, to prove spreading, the idea is to construct sub-solutions to the linearized problem with Dirichlet boundary conditions on a moving boundary of a growing domain $\mathcal{E}(t)$.  Then we use them to deduce a lower bound on the solution of the nonlinear problem.  

When building this solution, the growth/decay rate depends on the speed of $\mathcal{E}(t)$ -- the faster $\mathcal{E}$ moves, the smaller the growth rate with the growth rate tending to negative infinity as the speed of $\mathcal{E}$ tends to infinity.  Thus, the goal is to balance two competing forces: when $\mathcal{E}$ is in the large $\theta$ region the correlation between the speed of $\mathcal{E}$ and the growth rate of $\mathcal{E}$ is weakest, i.e.~in the large $\theta$ region, $\mathcal{E}$ can move at a much faster rate in the $x$ direction than if it were in the small $\theta$ region with the same effect on the growth rate; on the other hand, when $\mathcal{E}$ is in the large $\theta$ region, the trade-off term $m$ is extremely strong causing the growth rate to be very negative.  In view of this, our goal is to find a trajectory that takes advantage of both the fast movement when $\mathcal{E}$ is in the large $\theta$ region and the positive growth rate when $\mathcal{E}$ is in the small $\theta$ region.

We thus state a lemma regarding sub-solutions on moving, growing ellipses. This lemma is very similar to \cite[Lemma~4.1]{BHR_Acceleration}.  Before we state the lemma, we define a piece of notation.  For any given trajectory $t \mapsto \left( X(t) , \Theta(t) \right) \in \R\times\Theta$ and $\Lambda > 0$, we denote 
\begin{equation}\label{eq:ellipse_defn}
 	\mathcal{E}_{t,\Lambda}^{\left( X , \Theta \right)}
		\stackrel{\rm def}{=}
		\Big\{
			(x,\theta) \in \R \times \overline\Theta : \frac{\vert x - X(t) \vert^2}{\Theta(t)} + \vert \theta - \Theta(t) \vert^2 \leq \Lambda^2
		\Big\}.
\end{equation}

\begin{lemma}\label{lem:movement}
Let $T > T_0$ and let $(X_T(t), \Theta_T(t)) \in \mathcal{C}^2([T_0,T])$ be a trajectory.  Fix constants $\Lambda$, $r$, and $\delta$. There exists $\epsilon_\Lambda > 0$, depending only on $\Lambda$ and which is decreasing in $\Lambda$, $T_\delta$, depending only on $\delta$, and $\Lambda_0$ such that if $\Lambda \geq \Lambda_0$, $T - T_0 \geq T_\delta$ and
\begin{equation}\label{eq:lemma_condition}
\begin{split}
\forall t\in [T_0,T], \qquad	\left|\frac{1}{\Theta_{T}(t)}\right|  +  \left|\frac{1}{2} \frac{\dot\Theta_{T}(t)}{\Theta_{T}(t)}\right| + \left|\frac{\dot X_{T}(t)}{\Theta_{T}(t)^{3/2}}\right| \leq \epsilon_\Lambda,
\end{split}
\end{equation}
then there exists a function $\underline n$ which satisfies
\begin{equation}\label{eq:subsolE}
\begin{cases}
\underline n_t - \theta \underline n_{xx} - \underline n_{\theta\theta} \leq  (1 - r)\underline n, & \qquad \text{on } [T_0,T] \times \mathcal{E}_{t,\Lambda}^{\left( X_T , \Theta_T \right)}, \smallskip\\
\underline n = 0,  &\qquad \text{on } [T_0,T] \times \partial\mathcal{E}_{t,\Lambda}^{\left( X_T , \Theta_T \right)}, 
\end{cases}
\end{equation}
and such that $\underline n(T_0,\cdot) \leq \delta$ on  $\mathcal{E}_{T_0,\Lambda}^{\left( X , \Theta \right)}$ and
%\begin{equation*}
%\underline n(T_0,\cdot) \leq \delta \text{  on  } \mathcal{E}_{T_0,\Lambda}^{\left( X , \Theta \right)}, \qquad \underline n(T,\cdot) \geq M \delta \text{  on  } \mathcal{E}_{T,\Lambda/2}^{\left( X , \Theta \right)},  
%\end{equation*}
%where there is a constant $C_\Lambda$, depending only on $\Lambda$, such that
\begin{equation}\label{eq:constantsliding}
\begin{split}
	\underline n(T,\cdot) \geq &\delta C_\Lambda \exp\Big\{ - \frac{\Lambda}{2} \max_{t\in[0,T]} \Big( |\dot\Theta_{T}(t)| + \frac{|\dot X_{T}(t)|}{\sqrt{\Theta_{T}(t)}} \Big)\\
	&~~~~~ - \int_{T_0}^{T} \Big[ r + \frac{\dot{X}_{T}^2}{4\Theta_{T}} + \frac{\dot{\Theta}_{T}^2}{4} + 
			\frac{|\ddot{X}_{T}|\Lambda}{2} + \frac{|\dot{X}_{T}\dot{\Theta}_{T}|\Lambda}{4\Theta_{T}}  
			+ \frac{\dot{X}_{T}^2 \Lambda}{4\Theta_{T}^2} + \frac{\Lambda|\ddot{\Theta}_{T}|}{2} \Big] dt \Big\}.
\end{split}
\end{equation}
on $\mathcal{E}_{T,\Lambda/2}^{\left( X , \Theta \right)}$, where  $C_\Lambda$ is a positive constant depending only on $\Lambda$.
%\begin{equation}\label{eq:constantsliding}
%\begin{split}
%	M &= C_\Lambda \exp\Big\{ - \frac{\Lambda}{2} \max_{t\in[0,T]} \left( |\dot\Theta_{T}(t)| + \frac{|\dot X_{T}(t)|}{\sqrt{\Theta_{T}(t)}} \right)\\
%	&~~~~~ - \int_{T_0}^{T} \left[ r + \frac{\dot{X}_{T}^2}{4\Theta_{T}} + \frac{\dot{\Theta}_{T}^2}{4} + 
%			\frac{|\ddot{X}_{T}|\Lambda}{2} + \frac{|\dot{X}_{T}\dot{\Theta}_{T}|\Lambda}{4\Theta_{T}}  
%			+ \frac{\dot{X}_{T}^2 \Lambda}{4\Theta_{T}^2} + \frac{\Lambda|\ddot{\Theta}_{T}|}{2} \right] dt \Big\}.
%\end{split}
%\end{equation}
\end{lemma}

\begin{proof}%[{\bf Proof of Lemma \ref{lem:movement}}]
Since the lemma is very similar to the one in \cite{BHR_Acceleration}, we present a streamlined version of the proof. We recall that the idea of the proof is to suitably re-scale the equation and then use careful time-dependent spectral estimates.

First note that, without loss of generality, we may set $T_0 = 0$.  To construct the desired sub-solution $\underline n$, we first go into the moving frame, and rescale the spatial variable:
\begin{equation}\label{eq:v}
\underline{n}(t,x,\theta) = \underline{\tilde n}\left( t, \frac{x - X_T}{\sqrt{\Theta_T}}, \theta - \Theta_T\right),~~~
y = \frac{x - X_T}{\sqrt{\Theta_T}}, ~~\text{ and }~~ \eta = \theta - \Theta_T.
\end{equation}
Then plugging this into \eqref{eq:subsolE} yields  
\begin{equation}\label{eq:v_inequality}
\begin{cases}
	\displaystyle\underline{\tilde n}_t  - \Big(\frac{y}{2} \frac{\dot\Theta_T}{\Theta_T} + \frac{\dot{X}_T}{\sqrt{\Theta_T}} \Big)\underline{\tilde n}_y  - \dot\Theta_T \underline{\tilde n}_\eta \leq \Big(1 + \frac{\eta}{\Theta_T}\Big) \underline{\tilde n}_{yy} + \underline{\tilde n}_{\eta\eta} + (1 - r) \underline{\tilde n}, &\text{on } \mathcal{B}_\Lambda,\\
\underline{\tilde n}(t,\cdot) = 0, &\text{on } \partial\mathcal{B}_\Lambda.	
	\end{cases}
\end{equation}
Here, $\mathcal{B}_\Lambda\stackrel{\rm def}{=}B_\Lambda(0,0)$ is a ball of radius $\Lambda$ centered at $(y,\eta) = (0,0)$.   
%\EB{BELOW IS COPIED FROM THE ACCELERATION PAPER}
%In this subsection we prove  Lemma \ref{lem:trajectories} by   
%Recall that our goal is to show that 
%there exist constants $R_\eps$, $T_{\eps,\delta}$, and $H_\eps$ such that for all $R\geq R_\eps$, $T\geq T_{\eps,\delta}$, 
%and $H \geq H_\eps$, there is a function $v$  which satisfies
%\begin{equation}\label{eq:trajectories_sub-solutionbis}
%\begin{cases}
%v_t - \theta v_{xx} - v_{\theta\theta} \leq (1-\eps) v, ~~~~~&\text{ for all $t>0$,  and $(x,\theta) \in E_{X_T(t),\Theta_T(t),R}$},\medskip\\
%v(t,x,\theta) = 0, 		&\text{ for all  $0\le t\le T$ and } (x,\theta) \in \partial E_{X_T(t),\Theta_T(t),R},\medskip\\
%v(0,x,\theta) < \delta, 		&\text{ for all } (x,\theta) \in E_{X_T(0),\Theta_T(0), R},\medskip\\
%v(t,x,\theta) \leq 1,	&\text{ for all $0\le t\le T$ and } (x,\theta)\in E_{X_T(t),\Theta_T(t),R},
%\end{cases}
%\end{equation}
%and  such that $\|v(T,\cdot,\cdot)\|_{L^\infty} = 1$, and 
%$v(T,x,\theta) \geq C_R$ for all  $ (x,\theta) \in E_{X_T(T),\Theta_T(T),R/2},
%$
%with a constant $C_R>0$ that depends only on $R$ and $\delta>0$.
%
As in~\cite{BHR_Acceleration}, the next step is to remove a suitable exponential:
\[
w(t,y,\eta) = \exp\Big\{ \frac12\big(y\,\dot{X_T}\, \Theta_T^{-1/2} + \dot\Theta_T\, \eta \big) + g(t)\Big\} \underline{\tilde n}(t,y,\eta),
\]
where $g$ is defined below. Using~\eqref{eq:v_inequality}, we see that $w$ must satisfy the inequality
\begin{equation}\begin{split}
	w_t - &\underbrace{\Big(\frac{y}{2}\frac{\dot\Theta_T}{\Theta_T} - \frac{\dot{X_T}}{\Theta_T^{\frac32}}\eta\Big)}_{\stackrel{\text{def}}{=} A} w_y
		\leq \underbrace{\Big(1 + \frac{\eta}{\Theta_T}\Big)}_{\stackrel{\text{def}}{=} D} w_{yy} + w_{\eta\eta}\\
			& + w\Big( 1 - r - \frac{\dot{X}_T^2}{4\Theta_T} - \frac{\dot{\Theta}_T^2}{4} + 
			\Big( \frac{\ddot{X}_T}{2\sqrt{\Theta_T}} - \frac{\dot{X}_T\dot{\Theta}_T}{4\Theta_T^{\frac32}} \Big) y 
			+ \Big( \frac{\dot{X}_T^2}{4\Theta_T^2} + \frac{\ddot{\Theta}_T}{2} \Big) \eta + g' \Big).
\end{split}
\label{eq:trajectories}
\end{equation}

We point out that each of the perturbative terms $A$ and $D - 1$ tend to zero as $\Lambda$ tends to infinity by the hypothesis \eqref{eq:lemma_condition}. We get rid of the supplementary terms in the growth part, by setting
\begin{equation*}
g(t) := \int_0^{t} \left[r + \frac{\dot{X}_{T}^2}{4\Theta_{T}} + \frac{\dot{\Theta}_{T}^2}{4} + 
			\frac{|\ddot{X}_{T}|\Lambda}{2 \sqrt{\Theta_T}} + \frac{|\dot{X}_{T}\dot{\Theta}_{T}|\Lambda}{4\Theta_{T}^{\frac32}}  
			+ \frac{\dot{X}_{T}^2 \Lambda}{4\Theta_{T}^2} + \frac{\Lambda|\ddot{\Theta}_{T}|}{2} \right] dt'.
\end{equation*}

%
% {\bf I THINK THIS IS NOT QUITE TRUE for $G$ EVEN IF YOU CORRECT THE MISPRINTS SINCE YOU
%DO NOT HAVE OPTIMAL TRAJECTORIES, SO YOU MAY ONLY USE THE BOUND ON THE LARGANGIAN IN (\ref{dec406}) 
%not the exact identity you would need to make $G$ tend to zero. Do you mean rather that $G>-\eps$ (but can be positive)?}  
%Note that by choosing $T$ and $H$ large enough and using (\ref{dec406}) and (\ref{dec410}),
%we may ensure that
% \[
%G\ge 1 -\eps- \frac{\dot{X}_T^2}{4\Theta_T} - \frac{\dot{\Theta}_T^2}{4}-\frac{\eps}{4}\ge 1-\eps-(1-2\eps)-\frac{\eps}{4}=\frac{3\eps}{4}.
%\]
%Hence by choosing $H$ and $T$ large enough, depending only on $\eps$, $R$, 
%and the rate at which the terms in the limit in \eqref{eq:trajectories} tend to zero, we may arrange for $G < \eps / 4$ for all $t$.  

Returning to the original variables, if $w$ satisfies
\begin{equation}\label{eq:key_differential_inequality}
	w_t - A w_y \leq D w_{yy} + w_{\eta\eta} + w,
\end{equation}
then $v$ satisfies the desired differential inequality.  
With this in mind, we seek to construct $w$ satisfying~\eqref{eq:key_differential_inequality} that has the desired bounds.

We define $w$ using the principal eigenfunction of the operator
\begin{equation}\label{eq:L}
	\mathcal{L}_t \stackrel{\text{def}}{=} A \partial_y + D \partial_{yy} + \partial_{\eta\eta}.
\end{equation}
To this end, for each $t \in [0,T]$, define $(\lambda^t,\phi^t)$ to be the principal Dirichlet eigenelements of $\mathcal{L}_t$ (depending on $t$ as a parameter) in the ball $\mathcal{B}_\Lambda$,
with the normalization $\|\phi^t\|_{L^\infty \left(\mathcal{B}_\Lambda\right)} = 1.$
%\begin{equation*}
%\|\phi^t\|_{L^\infty \left(\mathcal{B}_\Lambda\right)} = 1.
%\end{equation*}
We define $w(t,y,\eta) = \delta \phi^t(y,\eta)$. 
%\begin{equation*}
%\forall t >0, \qquad w(t,\cdot) \stackrel{\rm def}{=} \delta \phi^t(\cdot) ,
%\end{equation*}
%where
%\begin{equation*}
%\beta \stackrel{\rm def}{=} \frac{1}{T} \log\left( \frac{1}{\delta}\right).
%\end{equation*}
Then, we  have
\begin{equation*}
\left( \partial_t - \mathcal{L}_t \right) w = \frac{\partial_t \phi^t}{\phi^t} w - \lambda_t w,% \leq w,
\end{equation*}
and
$w$ satisfies~\eqref{eq:key_differential_inequality} if we are able to ensure that 
\begin{equation*}
	\frac{\partial_t \phi^t}{\phi^t}  - \lambda_t \leq 1,
\end{equation*}
which follows from~\cite[Lemmas 5.1 and 5.2]{BHR_Acceleration} along with~\eqref{eq:lemma_condition}.% what we show now. First, for $\eps_\Lambda$ sufficiently small, $-\lambda^t$ becomes bounded by a constant multiple of $\Lambda^{-2}$ uniformly in $t$ (since the principal eigenvalue of $-\Delta$ on $\mathcal{B}_\Lambda$ is a constant multiple of $\Lambda^{-2}$). We now estimate $\partial_t \phi^t/\phi^t$. We recall the following 

%\begin{lemma}\label{lem:time_derivative}
%For any fixed time, $\partial_t \phi^t$ is a smooth function on $\mathcal{B}_\Lambda$, and
%\begin{equation*}
%\lim_{T,\Lambda \to \infty} \left\| \frac{\partial_t \phi^t}{\phi^t}\right\|_{L^\infty} = 0.
%\end{equation*}
%\end{lemma}

%\begin{lemma}\label{lem:eigenvalue}
%Consider the operator
%\[
%	L_{a,b} = - \nabla \cdot a \nabla - b \cdot \nabla
%,\]
%defined on a smooth, bounded domain $\Omega \subset \R^d$ with $a,b\in C^1(\Omega)$ and where 
%$a$ is a uniformly positive definite matrix.  Let $\lambda_{a,b,\Omega}$ be the principal Dirichlet eigenvalue of $L_{a,b}$ with eigenfunction $
%\phi_{a,b,\Omega}$ having $L^\infty$-norm one.  Then $\lambda_{a,b,\Omega}$ and $\phi_{a,b,\Omega}$ are continuous in $a$ and $b$, when 
%considered as maps from $(L^\infty)^{d^2}\times (L^\infty)^d$ to $\R$ and to $H^{1+s}$ for any $s \in (0,1)$, respectively.
%\end{lemma}
%\noindent The proof of Lemma~\ref{lem:eigenvalue} is rather standard and we omit it.
%below but for now continue with the proof of Lemma~\ref{lem:trajectories}.
%\Cref{lem:eigenvalue} implies that, as $T$ and $H$ tend to infinity, 
%$\lambda_{T,H}(t)$ becomes bounded above and below by a constant multiple 
%of $R^{-2}$, .  This convergence 
%is uniform in $t$.  Hence, choosing first $R$ sufficiently large, we may choose $H$ and $T$, depending only on 
%$\eps$, $R$, the convergence rate of the limit in \eqref{dec410}, such that 
%\begin{equation}\label{eq:small_eigenvalue}
%	\lambda_{T,H}(t) < \eps/4,~~~~\text{ for all } t.
%\end{equation} 
%We also need   the behavior of the time derivative of $\phi_{T,H}$.
%
%\Cref{lem:time_derivative} implies that for fixed $R$, we may choose $T$ and $H$, depending only on $\eps$ and the convergence rate of the limit in \eqref{dec410}, such that
%\begin{equation}\label{eq:small_derivative}
%	|\partial_t\phi_{T,H}| \leq \frac{\eps}{4} \phi_{T,H}, ~~~~ \text{ for all } (t,y,\eta) \in [0,T]\times B_R.
%\end{equation}
%Lastly, we note that classical elliptic regularity results assure us that there is a constant $C_R$, depending only on $R$ and the $L^\infty$-bound on $D$ and $A$, such that $\|\phi_{T,H}\|_{L^\infty} \leq C_R$ where the $L^\infty$ bound is taken in all variables.
%Note that if $T$ and $H$ are sufficiently large, there is a constant $M_R$, depending only on $R$, such that
%\begin{equation}\label{eq:comparability}
%	\frac{1}{M_R} w(t,y,\eta) \leq \tilde v(t,y,\eta) \leq M_R w(t,y,\eta)
%\end{equation}
%holds for all $t$, $y$, and $\eta$,because of the uniform bound (\ref{dec406}) on the Lagrangian. 

Again, due to~\cite[Lemma 5.1]{BHR_Acceleration}, $\phi^t$ converges uniformly to the principal Dirichlet eigenfunction of $B_\Lambda$ as $\epsilon_\Lambda$ tends to zero.  Hence, by choosing $\epsilon_\Lambda$ small enough, we obtain a constant $C_\Lambda$ such that
\[
	\delta C_\Lambda
		\leq \delta \min_{\mathcal{B}_{\Lambda/2}} \phi^T
		=  \min_{\mathcal{B}_{\Lambda/2}} w(T,\cdot).
\]
By undoing the change of variables and using the relationship between $u$ and $w$, we are finished.
%\[
%	 C_\Lambda \leq \min_{\mathcal{B}_{\Lambda/2}} w(T,\cdot) \leq M_\Lambda \min_{\mathcal{E}_{t,\Lambda/2}} u(T,\cdot),
%\]
%where $C_\Lambda$ is as in~\eqref{eq:constantsliding}, above.
\end{proof}


















\subsubsection*{The proof of Proposition~\ref{prop:lowerboundacc}: moving along a particular trajectory}

\begin{proof}[{\bf Proof of Proposition~\ref{prop:lowerboundacc}}]


Here, we describe the trajectory on which we apply \Cref{lem:movement}. It consists of three steps. First, we move mass upwards. Of course, this mass reaches a place where the death rate is highly negative due to the strength of the trade-off. This movement is justified by the second part of our trajectory, where we are able to move forward in space with a very high velocity, since the space diffusivity is very high in this zone. However, due to the strong trade-off, the mass at the end of this second step is extremely small. It is thus mandatory to move down to small traits again, to reach a zone where it is possible for the population to grow. Finally, in this region, we grow the population to order one in the last step. We show this trajectory in \cref{fig:trajectory}.



\begin{figure}[h]
\begin{center}
\includegraphics[width = .87\linewidth]{traj.pdf}
\caption{The trajectory and the different steps.}
\label{fig:trajectory}
\end{center}
\end{figure}


%%\begin{figure}[h]
%%\begin{center}
%%\begin{overpic}[scale=.85,natwidth=610,natheight=642]
%%	{Trajectory-eps-converted-to.pdf}
%%	\put(2,49){$(0,\eta_{\underline a}(T)+H)$}
%%	\put(80,49){$(\eta_{\underline a}(T)^{3/2},\eta_{\underline a}(T)+H)$}
%%\end{overpic}
%%\caption{The trajectory and the different steps.}
%%\label{fig:trajectory}
%%\end{center}
%%\end{figure}



%\begin{overpic}%[grid,tics=10]
%	{/Users/chen/Dropbox/Math/Talks/Pictures/domain.png}
%	 \put (35,80){$\Omega$}
%	 \put (40.5,41) {$u_0\equiv 1$}
%	 \put (60,65) {$u_0\equiv 0$}
%	 \put (48,55) {$\uparrow$}
%	 \put (60,41) {$\rightarrow$}
%	 \put (30,41) {$\leftarrow$}
%	 \put (48, 28) {$\downarrow$}
%%	 \put (50,50) {$\nearrow$}
%%	 \put (50,50) {$\nwarrow$}
%%	 \put (50,50) {$\swarrow$}
%%	 \put (50,50) {$\searrow$}
%	\end{overpic}



This strategy of moving along trajectories in the phase space $\R\times\Theta$ was used in \cite{BHR_Acceleration} to prove a precise estimate on acceleration in the case $m\equiv 0$. There, it is shown that taking trajectories that come from a related Hamilton-Jacobi equation gives a sharp bound for the local cane toads equation. Here, we are not able to explicitly solve the Euler-Lagrange equations to derive the expression of optimal Hamilton-Jacobi trajectories due to the presence of the trade-off.

Fix any large time $T>0$.  We now describe quantitatively the three steps mentioned earlier.

\smallskip

{\bf \# Step 0: Initialization}

\smallskip

By the maximum principle, $n$ must be positive everywhere at time $t=1$.  As such, we assume without loss of generality that $n$ is positive everywhere initially.

\smallskip

{\bf \# Step 1 : Moving up}

\smallskip

First, fix constants $\underline a$, $A$, $\Lambda_1$, and $H$ to be determined later, where we eventually choose $\underline{a}$ to be small and $A$, $\Lambda_1$, and $H$ to be large.  We move mass upwards.  To this end, define the trajectory 
\begin{equation}\label{eq:upward_trajectory}
	\left(X_1(t),\Theta_1(t)\right) \stackrel{\rm def}{=} \left( 0 ,  (c_1 t)^2 + H\right),
\end{equation}
for $t\in[0,T_1]$, where we have chosen $c_1 = T/A\eta_{\underline a}(T)^{3/2}$ and $T_1 = A \eta_{\underline a}(T)^2 / T$.
%\[
%	\beta = \frac{1}{r_1^{2} T^{\frac{2(1-p)}{2+p}}} \left( \overline L_1^2 - \frac{\Theta_1(0)}{T^{\frac{2}{2+p}}} \right).
%\]
%\[
%	c_1 = \frac{T}{A\eta_{\underline a}(T)^{3/2}}
%		\qquad\text{ and }\qquad
%	T_1 = \frac{A\eta_{\underline a}(T)^2}{T}.
%\]
We point out that \eqref{eq:phi_to_m} implies that $\lim_{T \to \infty}\eta_{\underline a}(T)/T =0$. Hence $T_1 \ll T$ when $T$ is large.  Notice that the definition of the trajectory \eqref{eq:upward_trajectory} implies that $\Theta_1(T_1) = \eta_{\underline a}(T) + H$.  By choosing $H$ sufficiently large, depending on $\Lambda_1$, we have 
\begin{equation}
\begin{split}
\forall t\in [0,T_1], \qquad	\Big|\frac{1}{\Theta_{1}}\Big|  +  \Big|\frac{1}{2} \frac{\dot\Theta_{1}}{\Theta_{1}}\Big| + \Big|\frac{\dot X_{1}}{\Theta_{1}^{3/2}}\Big| \leq \epsilon_\Lambda,
\end{split}
\end{equation}
and we have met the conditions of \Cref{lem:movement}, which we apply in the sequel.  

We emphasize two points coming from the definition of the trajectory.  First, it is crucial to make the trajectory start at $\theta = H$ in order to satisfy that $\Theta_1(t)^{-1} \leq \epsilon_\Lambda$ for all $t$.  Second, while trajectories that are linear in time would be simpler, this is not possible here as we require that $\dot\Theta_1(t)/(2\Theta_1(t)) \leq \epsilon_\Lambda$.  A linear-in-time trajectory which ends at $O(\eta_{\underline a}(T))$ would not satisfy this inequality for small times.

We seek a sub-solution of $n$ on the set $\mathcal{E}_{t,\Lambda_1}^{\left( X_1 , \Theta_1 \right)}$. To this end, first notice that from Proposition~\ref{prop:uniform_upper_bound}, we know that there exists $\overline\rho$ such that $\rho \leq \overline \rho$ on $\R^+ \times \R\times\Theta$.  In addition, since $m$ is monotonic by \Cref{hyp:m}, $m(\theta) \leq m(\eta_{\underline a}(T) + H + \Lambda_1)$ on $\mathcal{E}_{t,\Lambda_1}^{\left( X_1 , \Theta_1 \right)}$.  Hence, any $\underline n$ solving 
\[\begin{cases}
	\underline n_t - \theta \underline n_{xx} - \underline n_{\theta\theta} \leq  \left(1 - \overline \rho - m \left(\eta_{\underline a}(T) + H + \Lambda_1 \right) \right)\underline n, & \qquad \text{on } [0,T_1] \times \mathcal{E}_{t,\Lambda_1}^{\left( X_1 , \Theta_1 \right)},\smallskip\\
	\underline n = 0,  &\qquad \text{on } [0,T_1] \times \partial\mathcal{E}_{t,\Lambda_1}^{\left( X_1 , \Theta_1 \right)}, 
\end{cases}\]
is a sub-solution to $n$.  Define
\[
	\delta_1^{\Lambda_1,H} \stackrel{\rm def}{=} \inf_{\mathcal{E}_{0,\Lambda_1}^{\left( X_1 , \Theta_1 \right)}} n(0,\cdot).
\]
Then, applying \Cref{lem:movement} with starting time $T_0 = 0$ and final time $T_1$, $r = \overline \rho + m(\eta_{\underline a}(T) + H + \Lambda_1)$, $\Lambda = \Lambda_1$, and $\delta = \delta_1$, we obtain $\underline{n_1}$  such that $\underline{n_1}(0,\cdot) \leq n(0,\cdot)$ on $\mathcal{E}_{0,\Lambda}^{\left( X_1 , \Theta_1 \right)}$.  


We may then use the comparison principle to compare $\underline n_1$ and $n$ on $\mathcal{E}_{T_1,\Lambda_1/2}^{(X_1,\Theta_1)}$ at $t=T_1$.  Using~\eqref{eq:constantsliding}, we obtain
\begin{equation}\label{eq:size_after_sliding1}
\begin{split}
	n(T_1, x, \theta)
		&\geq \delta_1^{\Lambda_1,H}
			C_{\Lambda_1}
			\exp\left\{ - \Lambda_1 c_1^2 T_1 - \left( r T_1 + c_1^4 \frac{T_1^3}{3} + \Lambda_1 c_1^2 T_1 \right) \right\}\\
		&= \delta_1^{\Lambda_1,H}
			C_{\Lambda_1}
			\exp\left\{ -  2\Lambda_1 c_1^2 T_1 - r T_1 - \frac{c_1^4T_1^3}{3} \right\}\\
		&= \delta_1^{\Lambda_1,H}
			C_{\Lambda_1}
			\exp\left\{ - \frac{2\Lambda_1 T}{A \eta_{\underline a}(T)} - \frac{A \eta_{\underline a}(T)^2}{T} \left( \overline\rho + m(\eta_{\underline a}(T) + H + \Lambda_1) \right) - \frac{T}{3A}\right\}\\
		&= \delta_1^{\Lambda_1,H}
			C_{\Lambda_1}
			\exp\left\{ - T \left(\frac{1}{3A} + \frac{2\Lambda_1}{A \eta_{\underline a}(T)} + \frac{A \eta_{\underline a}(T)^2}{T^2} \left( \overline\rho + m(\eta_{\underline a}(T) + H + \Lambda_1) \right) \right)\right\}\\
		&\geq \delta_1^{\Lambda_1,H} C_{\Lambda_1} \exp\left\{ - T\left(\underline aA + \frac{2}{3A}\right)\right\}
		\geq \delta_1^{\Lambda_1,H} C_{\Lambda_1} \exp\left\{ - \frac{\gamma_\infty}{10}T\right\},
\end{split}
\end{equation}
for all $(x,\theta) \in \mathcal{E}_{T_1,\Lambda_1/2}^{(X_1,\Theta_1)}$. We comment on how we have obtained the second-to-last and last inequalities. 
The second-to-last is due to the following facts. First, since $\lim_{T \to \infty}\eta_{\underline a}(T) = + \infty$, one can take $T$ sufficiently large depending only on $\underline{a}$, and $\Lambda_1$, such that $2\Lambda_1/\eta_{\underline a}(T) \leq 1/3$. Second, since $\lim_{T \to \infty}\eta_{\underline a}(T)/T =0$, if $T$ is sufficiently large, depending only on $a$, then $\eta_{\underline a}(T)^2 \overline\rho /T^2 \leq \underline{a}/2$. Finally, if $T$ is taken sufficiently large so that $\eta_{\underline a}(T) \geq \Lambda_1 + H$, then we  have 
\begin{equation*}
	\frac{\eta_{\underline a}(T)^2}{T^2} m(\eta_{\underline a}(T) + H + \Lambda_1)
		\leq \frac{\eta_{\underline a}(T)^2}{T^2} m(2\eta_{\underline a}(T))
		\leq 2\frac{\eta_{\underline a}(T)^2}{T^2} D_m^2 \left( \frac{\Phi(\eta_{\underline a}(T))}{\eta_{\underline a}(T)} \right)^2
		= 2 D_m^2 \underline{a}^2 \leq \frac{\underline{a}}{2},
\end{equation*}
when $\underline{a}$ is taken sufficiently small, after using the monotonicity of $m$ and \eqref{eq:phi_to_m}.  The last inequality of \eqref{eq:size_after_sliding1} follows from choosing $A$ sufficiently large and then $\underline{a}$ sufficiently small.

%To understand $\underline n$, we first compute
%\[\begin{split}
%	\int_0^{r_1 T^{\frac{2-p}{2+p}}} \overline \rho + a(r_1 T^\frac{2-p}{2+p}) + \frac{\Theta_1(s)^2}{4} + R\beta ds
%		&\leq r_1 T^{\frac{2-p}{2+p}} (\overline \rho + a(r_1 T^\frac{2-p}{2+p}) + R \beta) + \frac{\overline L_1^3}{3 r_1} T\\
%		&\leq C_{r_1, p, \alpha, \overline L_1} T^{1 - \frac{p^2}{2+p}} + \frac{\overline L_1^3}{3 r_1} T.
%\end{split}\]
%The estimates involved above are simple computations using only definition of $\Theta_1$ and elementary calculus.
%
%Hence, by the comparison principle and the estimate above, we have that
%\begin{equation}\label{eq:estimate1}
%	C_{R_1,H_1} e^{- \frac{\overline L_1^3}{3 r_1} T - C_{r_1,p,\alpha,\overline L_1} T^{1 - \frac{p^2}{2+p}}}
%		\leq \underline n(r_1 T^{\frac{2-p}{2+p}},x, \theta)
%		\leq n(r_1 T^{\frac{2-p}{2+p}},x, \theta)
%\end{equation}
%for all $(x,\theta) \in E_{0, \overline L_1 T^{2/(2+p)},R_1/2}$ (note here that $\Theta_1(r_1T^{\frac{2-p}{2+p}}) = \overline L_1 T^{2/(2+p)}$).  Note that the lower bound of $\underline n$ comes from~\eqref{eq:principal_eigenfunction1}.




%With this notation set, we seek a sub-solution of $n$ on the set $E_{0,\Theta_1(t), R_1}$.  To this end, we note that since $\rho(t,x) \leq \overline \rho$ holds for all $t \in[0,r_1 T^{\frac{2-p}{2+p}}]$ and $x$, then any sub-solution to
%\begin{equation}\label{eq:sub-solution_eqn1}
%	\underline n_t \leq \theta \underline n_{xx} + \underline n_{\theta\theta} + \underline n ( 1 - \overline \rho - a(r_1 T^{\frac{2-p}{2+p}})),
%\end{equation}
%with Dirichlet boundary conditions $\underline n = 0$ on $\partial E_{0,\Theta_1(t),R_1}$, is a sub-solution to $n$.  To build such a sub-solution, we change variables and define
%\[
%	u(t,y, \eta) = \underline n\left( t, \sqrt\Theta_1(t) y, \eta + \Theta_1(t)\right).
%\]
%Changing variables in~\eqref{eq:sub-solution1} gives us
%\[
%	u_t
%		\leq \left(1 + \frac{\eta}{\Theta_1}\right) u_{yy} + u_{\eta\eta} + \frac{\dot\Theta_1}{2\Theta_1} u_y + \dot \Theta_1 u_\eta + u(1 - \overline \rho - a(r_1 T^{\frac{2-p}{2+p}})).
%\]
%%Here we have
%%\[\begin{split}
%%	&u_t = \underline n_t + \frac{\dot \Theta_1}{2 \sqrt{\Theta_1}} \underline n_x\\
%%	&u_y = \sqrt\Theta_1 \underline n_x,\\
%%	&\theta = (\eta + \Theta_1(t))
%%\end{split}\]
%First, notice that
%\[
%	\dot\Theta_1 / \Theta_1
%		= \frac{2 \beta t}{\beta t^2 + H_1}
%		\leq \frac{\beta t}{t\sqrt{H_1}}
%		=  \frac{1}{\sqrt{H_1} r_1^{2} T^{\frac{2-p}{2+p}}} \left( \overline L_1^2 - H_1 \right)
%	,
%\]
%which tends to zero as $T$ tends to infinity.  In addition, $\eta / \Theta_1$ tends to zero if we choose $R_1/H_1$ small.  Hence, these terms should not affect the behaviour of $u$.  Hence, we need only worry about the term $\dot\Theta_1 u_\eta$.  To remove this term, we define
%\[
%	u(t,y,\eta) = e^{- \frac{\dot\Theta_1}{2} \eta} v(t,y,\eta).
%\]
%Then $v$ must satisfy
%\[
%	v_t
%%		= \frac{\ddot\Theta_1}{2}\eta v + \left(1 + \frac{\eta}{\Theta_1}\right) v_{yy} + \left(v_{\eta\eta} - \dot\Theta_1 v_\eta + \frac{\dot\Theta_1^2}{4} v\right) + \frac{\dot\Theta_1}{2\Theta_1}v_y + \dot\Theta_1 \left(v_\eta - \frac{\dot\Theta_1}{2}v\right) + v(1 - \overline \rho - a(r_1 T^{\frac{2-p}{2+p}}))
%		\leq \left(1 + \frac{\eta}{\Theta_1}\right) v_{yy} + v_{\eta\eta} + \frac{\dot\Theta_1}{2\Theta_1}v_y + v\left(1 - \overline \rho - a(r_1 T^{\frac{2-p}{2+p}}) - \frac{\dot\Theta_1^2}{4} + \eta \beta\right).
%\]
%
%By the results in \cite{BHR_Acceleration}, we may choose $T$ to sufficiently large (depending only on $p$, $r_1$ and $\overline L_1$), $R_1$ and $H_1$ sufficiently large (depending on...) so that there exists $\phi_1(t)$ and $\lambda_1(t)$, both positive, which are the principal eigenfunction (with $L^\infty$-norm one) and eigenvalue to the operator $(1 + \eta/\Theta_1)\partial_y^2 + \partial_\eta^2 + (\dot\Theta_1/2\Theta_1)\partial_y$ and where
%\begin{equation}\label{eq:principal_eigenfunction1}
%	\phi_1 \sim  \text{ eigenfunction on } B_R(0), ~~~~~ \lambda(t) = O(1/R^2) \leq 1/2, ~~~~~ |\phi'(t)| \leq \phi(t)/2.
%\end{equation}
%Define
%\[
%	A = \inf_{E_{0,H_1,R_1}} n(0,\cdot,\cdot)
%\]
%and define
%\begin{equation}\label{eq:sub-solution1}
%	v(t,y,\eta) = A \exp\left\{ \int_0^t \left( - \overline \rho - a(r_1 T^{\frac{2-p}{2+p}}) - \frac{\dot\Theta_1^2}{4} - \beta \right)  ds \right\} \phi(t,y,\eta).
%\end{equation}
%First we notice that $v$ satisfies ??? so after changing variables back to ??, $\underline n$ is a sub-solution of $n$.  In addition, by the choice of $A$, we have that $\underline n(0,x,\theta) \leq n(0,x,\theta)$ for $(x,\theta) \in E_{0,H_1, R_1}$.

%We use the comparison principle to compare $\underline n$ and $n$ at time $r_1 T^{\frac{2-p}{2+p}}$.  To understand $\underline n$, we first compute
%\[\begin{split}
%	\int_0^{r_1 T^{\frac{2-p}{2+p}}} \overline \rho + a(r_1 T^\frac{2-p}{2+p}) + \frac{\Theta_1(s)^2}{4} + R\beta ds
%		&\leq r_1 T^{\frac{2-p}{2+p}} (\overline \rho + a(r_1 T^\frac{2-p}{2+p}) + R \beta) + \frac{\overline L_1^3}{3 r_1} T\\
%		&\leq C_{r_1, p, \alpha, \overline L_1} T^{1 - \frac{p^2}{2+p}} + \frac{\overline L_1^3}{3 r_1} T.
%\end{split}\]
%The estimates involved above are simple computations using only definition of $\Theta_1$ and elementary calculus.
%
%Hence, by the comparison principle and the estimate above, we have that
%\begin{equation}\label{eq:estimate1}
%	C_{R_1,H_1} e^{- \frac{\overline L_1^3}{3 r_1} T - C_{r_1,p,\alpha,\overline L_1} T^{1 - \frac{p^2}{2+p}}}
%		\leq \underline n(r_1 T^{\frac{2-p}{2+p}},x, \theta)
%		\leq n(r_1 T^{\frac{2-p}{2+p}},x, \theta)
%\end{equation}
%for all $(x,\theta) \in E_{0, \overline L_1 T^{2/(2+p)},R_1/2}$ (note here that $\Theta_1(r_1T^{\frac{2-p}{2+p}}) = \overline L_1 T^{2/(2+p)}$).  Note that the lower bound of $\underline n$ comes from~\eqref{eq:principal_eigenfunction1}.

















\smallskip

{\bf \# Step 2 : Moving right}

\smallskip

We now build a new moving bump sub-solution starting at $t = T_1$ and $(0,\eta_{\underline a}(T) + H)$ which moves mass to the right at a high speed.  It is important to note that $\underline{n_1}$ and $\underline{n_2}$ may not be concatenated to be a smooth sub-solution.  Instead, we ``fit'' our new sub-solution $\underline{n_2}$ underneath $n$ at time $T_1$ using the lower bound we obtained from $\underline{n_1}$.

For $t\in[T_1, 2T_1]$, we define the trajectory
\[
	(X_2(t), \Theta_2(t)) \stackrel{\rm def}{=} (c_2 (t-T_1), \eta_{\underline a}(T) + H),
\]
where $c_2$ is chosen so $A \sqrt{\eta_{\underline a}(T)} c_2 = T$.  We point out that $X_2(2T_1) = \eta_{\underline a}(T)^{3/2}$, by our choice of $c_2$ and $T_1$, and that $(X_2(T_1), \Theta_2(T_1)) = (X_1(T_1), \Theta_1(T_1))$.

Set $\Lambda_2 = \Lambda_1/2$.  It is easy to check that this trajectory satisfies~\eqref{eq:lemma_condition} for $T$ sufficiently large since $c_2 \eta_{\underline a}(T)^{-3/2} = T/ (A \eta_{\underline a}(T)^2)$ tends to zero.  Letting $r$ be as before, $\Lambda = \Lambda_2$, and $\delta_2 = C_{\Lambda_1} \delta_1^{\Lambda_1,H} \exp\left\{ - \gamma_\infty T/10\right\}$, we apply \Cref{lem:movement} again to obtain $\underline{n_2}$ satisfying~\eqref{eq:subsolE} with
\begin{equation}\label{eq:subsoln_sliding2}
	\underline{n_2}(T_1,x,\theta) \leq \delta_2 \leq n(T_1,x,\theta)
\end{equation}
for all $(x,\theta) \in \mathcal{E}_{T_1,\Lambda_2}^{(X_2,\Theta_2)}$.  The second inequality above comes from~\eqref{eq:size_after_sliding1} and the definition of $\delta_2$.  Since~\eqref{eq:subsoln_sliding2} and~\eqref{eq:subsolE} guarantee that $\underline{n_2} \leq n$, then~\eqref{eq:constantsliding} gives us that, for all $(x,\theta) \in \mathcal{E}_{2T_2,\Lambda_2/2}^{(X_2,\Theta_2)}$,
\[\begin{split}
	n(2T_1, x,\theta)
		&\geq \underline{n_2}(2T_1,x,\theta)
		\geq \left(C_{\Lambda_1} \delta_1^{\Lambda_1,H} e^{- \frac{\gamma_\infty T}{10}}\right) \times \\
		&\qquad \left(C_{\Lambda_2} \exp\left\{ - \frac{3\Lambda_2}{4}\frac{T}{A\eta_{\underline a}(T)} - \frac{A \overline \rho \eta_{\underline a}(T)^2}{T} - \frac{A m(\eta_{\underline a}(T) + H + \Lambda_1) \eta_{\underline a}(T)^2}{T}- \frac{T}{4A} \right\}\right).
\end{split}\]
Exactly as before, so long as $\underline{a}$ is sufficiently small and $A$ and $T$ are sufficiently large, we may estimate the the bottom line of the equation above exactly as in~\eqref{eq:size_after_sliding1} to obtain the bound
\[
	n(2T_1, x,\theta)
		\geq C_{\Lambda_1} \delta_1^{\Lambda_1,H}  e^{- \frac{\gamma_\infty T}{10}}e^{- \frac{\gamma_\infty T}{10}}
		\geq C_{\Lambda_1} \delta_1^{\Lambda_1,H} e^{- \frac{\gamma_\infty T}{5}}.
\]
Here we also used the relationship between $\Lambda_1$ and $\Lambda_2$.


\smallskip

{\bf \# Step 3: Moving down}

\smallskip

The argument here is almost exactly as in the last two steps so we only briefly outline it.  Define
\[
	(X_3(t), \Theta_3(t)) = (\eta_{\underline a}(T)^{3/2}, \Theta_1(3T_1 - t))
\]
for all $t\in[2T_1, 3T_1]$.  We notice a few things.  First, $(X_3(2T_1),\Theta_3(2T_1)) = (X_2(2T_1),\Theta_2(2T_1))$.  Second, up to translation, $\Theta_3$ is the time reversal of $\Theta_1$.  Third, $(X_3(3T_1), \Theta_3(3T_1)) = (\eta_{\underline a}(t)^{3/2}, H)$.  We recall that we must stop at $H$ because below $H$, the conditions of \Cref{lem:movement} are not met.

Hence, taking $\Lambda_3 = \Lambda_2/2$, we may argue as before to obtain the lower bound
\[
	n(3T_1,x,\theta) \geq C_{\Lambda_1} \delta_1^{\Lambda_1,H} e^{- \frac{3\gamma_\infty T}{10}},
\]
for all $(x,\theta) \in \mathcal{E}_{3T_1,\Lambda_3/2}^{X_3,\Theta_3}$.  To be clear, we note that 
\[
	 \mathcal{E}_{3T_1,\Lambda_3/2}^{X_3,\Theta_3}
		= \Big\{(x,\theta) \in \R\times\Theta: \frac{(x - \eta_{\underline a}(T)^{3/2})^2}{\eta_{\underline a}(T)} + (\theta - H)^2 \leq \frac{\Lambda_1}{16}
		\Big\}.
\]


\smallskip

{\bf \# Step 3bis: Moving to near $\underline \theta$ and growing larger}

\smallskip


At this point, we know that $n$ is bounded below by a small value far to the right at time $3T_1$.  Since $T_1 \ll T$ when $T$ is large, we have a large amount of time left for $n$ to grow to order one.

To begin, we obtain estimates on the growth by using the principal eigenvalue of the cane toads operator with trade-off on a large enough domain.  For $r,s>0$, consider the following spectral problem in both variables $(\xi,\theta)$:
\begin{equation*}
\begin{cases}
\theta \varphi_{\xi\xi}   +  \varphi_{\theta\theta}  + (1-m) \varphi   = \gamma_{r,s} \varphi \,, \qquad \text{ on } (\eta_{\underline a}(T)-r,\eta_{\underline a}(T)+r) \times (\underline\theta, \underline\theta + s),\\
\varphi_\theta (\cdot,\underline\theta) = 0\,, \quad \varphi (\cdot,\underline\theta + s) = 0\,, \quad \varphi(\eta_{\underline a}(T)\pm r,\cdot) = 0.
\end{cases}
\end{equation*}
The eigenvector (up to a multiplicative constant) $\varphi$ is given by 
\begin{equation*}
%\forall (\xi,\theta) \in (\eta_{\underline a}(T)-r,\eta_{\underline a}(T)+r) \times (\underline\theta, \underline\theta + s), \qquad
\varphi(\xi,\theta)= \cos\left( \frac{\pi}{2}\frac{\xi-\eta_{\underline a}(T)}{r}\right) V_{r,s}(\theta),
\end{equation*}
where we have introduced the eigenelements $(\gamma_{r,s},V_{r,s})$ with normalization $\|V_{r,s}\|_\infty = 1$ by
\begin{equation*}
\begin{cases}
V_{r,s}''  + \left( - \frac{\pi^2 \theta}{4r^2} - \gamma_{r,s} + (1-m) \right) V_{r,s}   = 0 \,, \quad \theta \in (\underline\theta, \underline\theta + s),\\
V_{r,s}'(\underline\theta) = 0, \quad V_{r,s}(\underline\theta + s) = 0, \quad V_{r,s} > 0.
\end{cases}
\end{equation*}
One can pass to the limit $\lim_{s\to\infty}\lim_{r\to\infty} \gamma_{r,s} = \gamma_\infty$ since $\lim_{s\to\infty}\lim_{r\to\infty} V_{r,s} = Q$.  Thus we may fix $r_0$ and $s_0$ sufficiently large so that $\gamma_{r_0,s_0} > 8\gamma_\infty/10$.
%One can pass to the limit $r\to +\infty$ so that $\lim_{r \to +\infty} \gamma_{r,s} = \gamma_s^{\delta=0}$ and $\lim_{r \to +\infty} V_{r,s} = Q_s^{\delta=0}$. Thus we may fix $r_0$ and $s_0$ sufficiently large such that %$\gamma_{s_0}^0 > \frac{8}{10} \gamma_\infty$ and then $r_0$ sufficiently large to have $\gamma_{r_0,s_0} >\frac{8}{10} \gamma_\infty$. 

Define $U_{r_0,s_0} = [\eta_{\underline a}(T)-r_0,\eta_{\underline a}(T)+r_0] \times [\underline\theta, \underline\theta + s_0]$.  We now apply the Harnack inequality on $[3T_1, 3T_1 + 1] \times U_{r_0,s_0}$ to obtain
\begin{equation}\label{eq:n_lower_bound_harnack}
	C e^{- \frac{3\gamma_\infty T}{10}}
		\leq \sup_{U_{r_0,s_0}} n(3T_1, \cdot, \cdot)
		\leq C_{r_0,s_0} \inf_{U_{r_0,s_0}} n(3T_1 + 1, \cdot, \cdot),
\end{equation}
where we combined $C_{\Lambda_1} \delta_1^{\Lambda_1,H}$ into one constant $C$ above.

We wish to use $\varphi$ and the bound above to create a sub-solution of $n$.
To deal with the nonlocal term, we use the Harnack inequality given by \Cref{lem:harnack}, to obtain,
\[
	\rho(t,x) \leq C_{s_0}' n(t,x,\theta) + \frac{\gamma_\infty}{10},
\]
for all $(x,\theta) \in U_{r_0,s_0}$.  Hence we have that
\begin{equation}\label{eq:n_diff_inequality}
n_t \geq \theta n_{xx} + n_{\theta\theta} + n \left(1 - \frac{\gamma_\infty}{10} - m - C_{r_0,s_0}' n \right).
\end{equation}
Now define
\[
	w(t,x,\theta) = \min\left(\frac{\gamma_\infty}{10C_{r_0,s_0}'},\frac{C}{C_{r_0,s_0} +1} \right) e^{-\frac{3\gamma_\infty T}{10}} e^{\lambda'(t - 3T_1 - 1)} \varphi(x,\theta),
\]
on $[3T_1 + 1, T]\times U_{r_0,s_0}$, where we set $\lambda' = (3\gamma_\infty T)/(10(T - 3T_1 - 1)).$ We point out that $\lambda' - \gamma_{r_0,s_0} + \gamma_\infty/10 \leq -\gamma_\infty/10$ for $T$ sufficiently large, since then $\lambda' \leq 4\gamma_\infty/10$ and $\gamma_{r_0,s_0} \geq 8\gamma_\infty/10$.  In addition, by the choice of $\lambda'$, we have that $C_{r_0,s_0}' w \leq \gamma_\infty/10$ for all $t \in [3T_1+1,T]$.  Our goal is to compare $w$ and $n$.  This is possible since $w$ satisfies the equation
\begin{equation}\label{eq:w2}
	w_t - \theta w_{xx} - w_{\theta\theta} - w\left(1 - \frac{\gamma_\infty}{10}- m\right)
		= \left(\lambda' - \gamma_{r_0,s_0} + \frac{\gamma_\infty}{10} \right)w \leq - \frac{\gamma_\infty}{10} w  \leq -C_{r_0,s_0}' w^2.
\end{equation}
Thus \eqref{eq:w2} and~\eqref{eq:n_diff_inequality} implies that $n$ is a super-solution to $w$.


In addition, due to~\eqref{eq:n_lower_bound_harnack}, we have that $w(3T_1+1,\cdot) \leq n(3T_1+1,\cdot)$ on $U_{r_0,s_0}$.  Hence, the maximum principle implies that $w \leq n$ on $[3T_1+1,T]\times U_{r_0,s_0}$.  

Evaluating this at time $t = T$ and position $(x,\theta) = (\eta_{\underline a}(T)^{3/2},\underline\theta)$ yields
\[
		{\frac{\gamma_\infty}{10C_{r_0,s_0} C_{r_0,s_0}'}V_{r,s}(\underline\theta)}
		=\frac{\gamma_\infty}{10C_{r_0,s_0} C_{r_0,s_0}'} \varphi(\eta_{\underline a}(T)^{3/2}, \underline\theta)
		= w(T, \eta_{\underline a}(T)^{3/2}, \underline\theta) \leq n(T,{\eta_{\underline a}(T)^{3/2}},\underline\theta).
\]
Since the left hand side does not depend on $T$ and {$V_{r,s}$ is positive due to the maximum principle}, this provides the desired uniform lower bound.  For any $x \leq \eta_{\underline a}(T)^{3/2}$, we may simply decrease $c_2$ appropriately and argue as above, thus finishing the proof of Proposition~\ref{prop:lowerboundacc}.
\end{proof}





%
%
%
%Let $\overline L_2$ be an undetermined positive constant. To do this, fix a positive $\overline L_2$, and then define the trajectory 
%\begin{equation}\label{eq:upward_trajectory}
%t \in [t(T),2t(T)] \mapsto \left(X_2,\Theta_2\right) := \left( L_2 c_2(T) \left( t - t(T) \right) ,  \Theta_1(0) + L_1 d_1(T) \right).
%\end{equation}
%%Define $\Theta_2(t) = \overline L_1 T^{2/(2+p)}$ and
%%\[
%%	X_2(t) = \overline L_2 T^{\frac{1+p}{2+p}} \left( t - \overline r_1 T^\frac{2-p}{2+p}\right)
%%\]
%%for all $t \in \left[ \overline r_1 T^\frac{2-p}{2+p}, (\overline r_1 + \overline r_2)T^\frac{2-p}{2+p}\right]$.  Notice that
%This is such that 
%\[
%	X_2(2t(T)) = L_2 d_2(T).
%%	\overline L_2 T^{3/(2+p)}.
%\]
%The trajectory satisfies 
%\begin{equation}\label{eq:lemma_condition}
%\begin{split}
%\forall t\in [t(T),2t(T)], \qquad	\left|\frac{1}{\Theta_{2}}\right|  +  \left|\frac{1}{2} \frac{\dot\Theta_{2}}{\Theta_{2}}\right| + \left|\frac{\dot X_{2}}{\Theta_{2}^{3/2}}\right| \leq \left|\frac{1}{\Theta_{1}(0)}\right| + \left|\frac{L_2 c_{2}(T)}{\left(\Theta_{1}(0) + L_1d_1\right)^{3/2}}\right| \leq \frac{\epsilon_\Lambda}{\Lambda},
%\end{split}
%\end{equation}
%
%To apply \cref{lem:movement}, we let $r = \overline \rho + a\left(\Theta_{1}(0) + L_1d_1(T)\right)$, $\delta = \delta_1C_1$, $R = \Lambda/2$ and with a final time $t(T)$. Notice that the condition~\eqref{eq:lemma_condition} is easy seen to be fulfilled.  Hence (up to a shift in time by $t(T)$) we have a new function, which in an abuse of notation we also call $\underline n$, with Dirichlet boundary conditions on $\mathcal{E}_{t,\Lambda/2}^{\left( X_2 , \Theta_2 \right)}$ and all $t \in [t(T),2t(T)]$ and which satisfies the upper bound
%\begin{equation}\label{eq:sub-solution2_upper}
%	\underline n(t(T),\cdot) \leq \delta_1C_1, \qquad \text{on } \mathcal{E}_{t(T),\Lambda/2}^{\left( X_2 , \Theta_2 \right)},
%%	\delta_0 C_{R_1} e^{- \frac{\overline L_1^3}{3\overline r_1}T - C_{\overline r_1,p,\alpha,\overline L_1,R_1} T^{1 - \frac{p^2}{2+p}}},
%\end{equation}
%and the lower bound
%\begin{equation*}
%	\underline n(2 t(T),\cdot)
%		\geq \delta_1 C_1 C_2, \qquad \text{on } \mathcal{E}_{2t(T),\Lambda/2}^{\left( X_2 , \Theta_2 \right)},		
%%		\delta_0 C_{R_1}e^{- \frac{\overline L_1^3}{3\overline r_1}T - C_{\overline r_1,p,\alpha,\overline L_1, R_1} T^{1 - \frac{p^2}{2+p}}} e^{ - \frac{\overline L_2^2}{4\overline r_2} T - C_{\overline L_2, \overline L_1, \overline r_2,R_1} T^{p/(2+p)}}
%\end{equation*}
%%for all  
%%\[
%%	(x,\theta) \in E_{\overline L_2 T^{3/(2+p)}, \overline L_1 T^{2/(2+p)}, R_2/2}.
%%\]
%If one follows the constants $C_1$ and $C_2$ by computing \eqref{eq:constantsliding}, one can see that
%\begin{equation*}
%C_1C_2 \geq C_\Lambda e^{- \left(L_1^3/3 + L_2^2/4 \right) T - C_{L_1,\Lambda} T^{1 - \frac{p^2}{2+p}}}.
%\end{equation*}
%%Using that $p/(2+p) \leq 1 - p^2/(2+p)$, this simplifies to
%%\begin{equation}\label{eq:sub-solution2_lower1}
%%	\underline n((\overline r_1 + \overline r_2) T^\frac{2-p}{2+p}, x,\theta)
%%		\geq \delta_0 C_{R_1} e^{- \left(\frac{\overline L^3_1}{3 \overline r_1} + \frac{\overline L_2^2}{4\overline r_2} \right) T - C_{\overline r_1, \overline r_2, \overline L_1, \overline L_2, p, \alpha, R_1} T^{1 - \frac{p^2}{2+p}}}.
%%\end{equation}
%%We note that the lower bound is again a straightforward computation using~\eqref{eq:sub-solution_lower_bound}-\eqref{eq:explicit_lower_bound} along with the definitions of $X_2$ and $\Theta_2$.
%
%Notice that~\eqref{eq:sub-solution2_upper} ensures that $\underline n \leq n$ at time $t(T)$.  This, along with the comparison principle, implies that $\underline n \leq n$ for all $t \in[ t(T),2t(T)]$.  This along with~\eqref{eq:sub-solution2_lower1}, gives us that
%\begin{equation}\label{eq:sub-solution2_lower1}
%	n\left(2t(T),\cdot\right) \geq \delta_1 C_1C_2, \qquad \text{on } \mathcal{E}_{2t(T),\Lambda/2}^{\left( X_2 , \Theta_2 \right)}.
%%		\delta_0 C_{R_1} e^{- \left(\frac{\overline L^3_1}{3 \overline r_1} + \frac{\overline L_2^2}{4\overline r_2} \right) T - C_{\overline r_1, \overline r_2, \overline L_1, \overline L_2, p, \alpha, R_1} T^{1 - \frac{p^2}{2+p}}}.
%\end{equation}
%
%
%
%\medskip
%
%{\bf \# Step 3 : Moving down.}
%
%\medskip
%
%Define the trajectory 
%\begin{equation}\label{eq:upward_trajectory}
%t \in [2t(T),3t(T)] \mapsto \left(X_3,\Theta_3\right) := \left( X_2(T),\Theta_1\left(3t(T) - t\right)\right)
%\end{equation}
%Arguing exactly as in \#Step 1, it is easy to see that
%\begin{equation}\label{eq:sub-solution2_lower1}
%	n\left(3t(T),\cdot\right) \geq \delta_1 C_1C_2C_3, \qquad \text{on } \mathcal{E}_{3t(T),\Lambda/4}^{\left( X_3 , \Theta_3 \right)},
%\end{equation}
%where
%\begin{equation*}
%C_1C_2C_3 \geq C_{\Lambda} e^{- \left(\frac{2 L_1^3}{3} + \frac{L_2^2}{4} \right) T - C_{L_1, L_2,\Lambda} T^{1 - \frac{p^2}{2+p}}}.
%\end{equation*}
%%\[
%%	n \left( ( 2\overline r_1 + \overline r_2) T^\frac{2-p}{2+p}, x, \theta\right)
%%		\geq \delta_0 C_{R_1} e^{- \left(\frac{2\overline L^3_1}{3 \overline r_1} + \frac{\overline L_2^2}{4\overline r_2} \right) T - C_{\overline r_1, \overline r_2, \overline L_1, \overline L_2, p, \alpha, R_1} T^{1 - \frac{p^2}{2+p}}}
%%,\]
%%for all
%%\[
%%	(x,\theta) \in E_{\overline L_2 T^{3/(2+p)}, H_1, R_1/4}.
%%\]
%
%\medskip
%
%{\bf \# Step 3bis : Moving to near $\underline\theta$.}
%
%\medskip
%
%
%
%Finally to go down from height $\Theta_1(0)$ to approximately $\underline\theta$, that we need to do to make sure that we can balloon up the solution at the next step, we use the parabolic Harnack inequality to get that
%\begin{equation*}
%	n \left( 3t(T) + 1, \cdot \right)
%		\geq \delta_1 C_1C_2C_3C_{\Lambda,\Theta_1(0)}, \qquad \text{on A BIG BALL}. 
%%\delta_0 C_{R_1, H_1} e^{- \left(\frac{2\overline L^3_1}{3 \overline r_1} + \frac{\overline L_2^2}{4\overline r_2} \right) T - C_{\overline r_1, \overline r_2, \overline L_1, \overline L_2, p, \alpha, R_1} T^{1 - \frac{p^2}{2+p}}}
%\end{equation*}
%%for all $x \in B_{H_1}(\overline L_2 T^{3/(2+p)}$ and all $\theta \leq 2H_1$.
%%
%%{\color{red} NOTE TO SELF : IN FINAL VERSION, CHOOSE r1 and r2 AHEAD OF TIME AND JUST KEEP THE L1 AND L2 GUYS.  OTHERWISE IT IS TOO MUCH NOTATION TO KEEP TRACK OF.  ALSO DO GENERAL ARGUMENT FOR ALL L1 LESS THAN OVERLINE L1 AND ALL L2 LESS THAN OVERLINE L2.}
%
%
%
%
%
%\subsection{Growing the sub-solution.}
%
%We now finish the procedure by growing up the sub-solution to make sure that it reaches a universal height (that only depends on physical parameters). 
%
%First, it is also easy to check that one can modify the previous argument by taking different choices $L_2 \in [0,\overline L_2]$ and $L_1 \in [0, \overline L_1]$ in \#Step 1 and \# Step 2 above to see that the is a computable constant $C_{\text{move}}$ such that 
%\begin{equation}
%	n \left( 3t(T) + 1, \cdot \right) \geq \delta_0 C_{\text{move}}, \qquad \text{on } (0,\overline L_2d_2(T)) \times \left( \underline\theta , \underline\theta + \overline L_1d_1(T) \right) 
%%		C_{R_1, H_1} e^{- \left(\frac{2\overline L^3_1}{3 \overline r_1} + \frac{\overline L_2^2}{4\overline r_2} \right) T - C_{\overline r_1, \overline r_2, \overline L_1, \overline L_2, p, \alpha, R_1} T^{1 - \frac{p^2}{2+p}}}
%\end{equation}
%%holds for all $x \leq \overline L_2 T^{3/(2+p)}$ and for all $\theta \leq \overline L_1 T^{2/(2+p)}$.
%
%We now state the ballooning lemma.
%
%\begin{lemma}\label{lem:balloon}
%% {\color{red} CHANGE LAMBDAS TO RS}
%	Fix $t_0 > 1$.  There exists $M_1 > 0$ such that there exists $(r,s) \in \left(\R_+^*\right)^2$, 
%	%depending only on $\lambda$, $p$, and $\alpha_0$, 
%such that if a solution $n$ to \eqref{eq:main} satisfies
%\begin{equation}\label{eq:lowert0}
%n(t_0,\cdot) \geq M_0 \qquad \text{on }(-r,r) \times (\underline\theta, \underline\theta + s),\end{equation}
%then
%\begin{equation}
%		\Vert n(t_0 + t, \cdot) \Vert_{L^\infty((-r,r) \times (\underline\theta, \underline\theta + s))} \geq M_1
%\end{equation}
%for all $t \geq \frac{2}{\lambda} \log\left(\frac{M_1}{M_0}\right)$.
%\end{lemma}
%
%To balloon up the solution, we make use of a suitably chosen bump-like sub-solution on a slab $(-r,r) \times (\underline\theta, \underline\theta + s)$. This is done in the next \cref{lem:eigenvalue_limit}. Once this lemma has been proved, we prove \cref{lem:balloon} and conclude the proof of \ref{thm:main}, case \ref{case:propzerolower}.
%
%\begin{lemma}\label{lem:eigenvalue_limit}
%For $r,s>0$, consider the following spectral problem in both variables $(\xi,\theta) \in (-r,r) \times (\underline\theta, \underline\theta + s)$:
%\begin{equation}\label{eq:evpb}
%\left\{\begin{array}{l}
%\theta \varphi_{\xi\xi}   +  \varphi_{\theta\theta}  + (1-m) \varphi   = \gamma_{r,s} \varphi \,, \quad \text{on } (-r,r) \times (\underline\theta, \underline\theta + s),\medskip\\
%\varphi_\theta (\cdot,\underline\theta) = 0\,,\medskip\\
%\varphi (\cdot,\underline\theta + s) = 0\,,\medskip\\
%\varphi(-r,\cdot) = 0 \, , \quad \varphi(r,\cdot)  = 0,
%\end{array}
%\right.
%\end{equation}
%with the renormalization $\Vert \varphi \Vert_{L^\infty\left(\overline{\Gamma}_{r,s}\right)} = 1$. Then $\gamma_{r,s}$ exists and is unique, and satisfies $\lim_{s\to+\infty} \lim_{r\to\infty} \gamma_{r,s} = \gamma_\infty$, where $\gamma_\infty$ is defined after \eqref{eq:specQ}.
%\end{lemma}
%
%
%\begin{proof}%[{\bf Proof of \Cref{lem:eigenvalue_limit}}]
%
%For $r,s>0$, consider the following spectral problem in both variables $(\xi,\theta)$:
%\begin{equation}\label{eq:evpb}
%\left\{\begin{array}{l}
%\theta \varphi_{\xi\xi}   +  \varphi_{\theta\theta}  + (1-m) \varphi   = \gamma_{r,s} \varphi \,, \quad \text{on } (-r,r) \times (\underline\theta, \underline\theta + s),\medskip\\
%\varphi_\theta (\cdot,\underline\theta) = 0\,,\medskip\\
%\varphi (\cdot,\underline\theta + s) = 0\,,\medskip\\
%\varphi(-r,\cdot) = 0 \, , \quad \varphi(r,\cdot)  = 0.
%\end{array}
%\right.
%\end{equation}
%
%By Krein-Rutman theory, $\gamma_{r,s}$ is the only eigenvalue such that there exists a positive eigenvector $\varphi$. One can rescale the problem in the space direction setting $\xi = r \zeta$:
%\begin{equation*}
%\left\{\begin{array}{ll}
%\dfrac{\theta}{r^2} \varphi_{\xi\xi}   +  \varphi_{\theta\theta}  + (1-m) \varphi   = \gamma_{r,s}\varphi, &\quad \text{on } \Gamma_{1,s},\medskip\\
%\varphi_\theta (\cdot,\underline\theta) = 0, &\medskip\\
%\varphi (\cdot,\underline\theta + s) = 0, &\medskip\\
%\varphi(-1,\theta) = 0, \quad \varphi(1,\theta)  = 0.
%\end{array}
%\right.
%\end{equation*}
%The eigenvector (up to a multiplicative constant) $\varphi$ is in fact given by 
%\begin{equation*}
%\forall (\zeta,\theta) \in \Gamma_{1,s}, \qquad \varphi(\zeta,\theta)= \sin\left( \frac{\pi}{2} (\zeta+1) \right) V_{r,s}(\theta),
%\end{equation*}
%where we have introduced the eigenvector $V_{r,s}$ through the following eigenproblem (which also defines $\gamma_{r,s}$):
%\begin{equation*}
%\left\{\begin{array}{l}
%V_{r,s}''  + \left( - \dfrac{\pi^2}{4} \dfrac{\theta}{r^2} + (1-m) \right) V_{r,s}   =  \gamma_{r,s} V_{r,s} \,, \quad \theta \in (\underline\theta,\underline\theta + s),\medskip\\
%V_{r,s}'(\underline\theta) = 0\,, \medskip\\
%V_{r,s}(\underline\theta + s) = 0\,, \medskip\\
%V_{r,s} > 0.
%\end{array}
%\right.
%\end{equation*}
%Let us now prove that $\lim_{r \to +\infty} \gamma_{r,s} = \nu_{Q_s}$. One has, after differentiating the above with respect to $r$ and testing on $V_{r,s}$, 
%\begin{equation*}
%\frac{d \gamma_{r,s}}{dr} = \frac{\pi^2}{2 r^3} \frac{\int_{(\underline\theta,\underline\theta + s)} \theta V_{r,s}^2 d \theta}{\int_{(\underline\theta,\underline\theta + s)} V_{r,s}^2 d \theta}
%\end{equation*}
%so that $\lim_{r \to +\infty} \gamma_{r,s}$ exists and solves necessarily
%\begin{equation*}
%\left\{\begin{array}{l}
%V''  + (1-m) V   = \left( \lim_{r \to +\infty} \gamma_{r,s} \right) V  \,, \qquad \theta \in (\underline\theta,\underline\theta + s) \, ,\medskip\\
%V'(\underline\theta) = 0\,, \medskip\\
%V(\underline\theta + s) = 0, \medskip\\
%V > 0.
%\end{array}
%\right.
%\end{equation*}
%and it yields necessarily that $V$ is parallel to $Q_s$ and $\lim_{r \to +\infty} \gamma_{r,s} = \nu_{Q_s}$. The lemma follows directly since $\lim_{s\to\infty} \nu_{Q_s} = \gamma_\infty$.
%
%
%
%
%
%%
%%Before we continue, we point out that the symmetry of the problem in $x$ implies that $\phi$ attains its maximum at $x = 0$.  % TO SEE THIS, SIMPLY REFLECT PHI OVER THE X=0 AND YOU HAVE ANOTHER PRINCIPAL EIGENFUNCTION, THEN UNIQUENESS DOES THE REST
%%
%%
%%{\color{red} NEED TO FORMULATE THIS AS A NEW LEMMA....}
%%The first step is to show that we may choose $N_1$ and $N_2$ such that $\lambda > 0$.  Since $\lambda$ is increasing in $N_1$ and $N_2$ by well-known variational characterizations of the principal eigenvalue, then either there exists such a positive $\lambda$ -or- $|\lambda|$ is bounded as $N_1$ and $N_2$ tend to infinity.  Since we are finished if $\lambda > 0$, then we assume that $\lambda$ is bounded.  {\color{red} lambda has to be bounded because it is less than the eigenvalue of Q}
%%
%%With this assumption in hand, we claim that $\phi$ and $\lambda$ converge to the principal eigenfunction $\overline \phi$ and principal eigenvalue $\overline \lambda$ of the problem: {\color{red} NEED TO DO THIS EARLIER SINCE NEED LAMBDA OVERLINE TO BE POSITIVE BELOW}
%%\begin{equation}\label{eq:eigenvalue_nox}
%%\begin{cases}
%%	\overline\phi_{\theta\theta} + \overline\phi(1- a(\theta)) = \overline\lambda \ \overline\phi, ~~~~&\text{ for all } \theta \in [\theta_0, N_2],\\
%%	\overline\phi(N_2) = 0,\\
%%	\overline\phi_\theta(\theta_0) = 0.
%%\end{cases}
%%\end{equation}
%%Suppose not.  Then we make find a sequence $N_1^n \to \infty$ such that the principal eigenvalue $\lambda^n$, with eigenfunction $\phi^n$, does not converge to $\lambda$.  Since $\|\phi^n\|_\infty =1$ and $\lambda^n$ is bounded, then elliptic regularity ensures that $\phi^n$ converges locally uniformly to a smooth, positive function $\phi^\infty$ defined on $\R \times [\theta_0, N_2]$ and $\lambda^n$ converges to $\lambda^\infty$.  Moreover, we have that $\phi^\infty$ is positive %nonnegative by the limit and positive by the max. principal
%%and nonzero and that
%%\[
%%	\theta\phi^\infty_{xx} + \phi^\infty_{\theta\theta} + \phi^\infty(1 - a(\theta)) = \lambda^\infty \phi^\infty.
%%\]
%%Either $\lambda^\infty < \overline \lambda$ or $\lambda^\infty > \overline \lambda$.  In the first case, let $A_0 = \inf \overline \phi$.  Then $A \phi^\infty$ is a sub-solution to $\overline \phi$.  Let $A = \sup\{ A' \geq A_0 : A' \phi^\infty \leq \overline \phi\}$.  Then, by the definition of $A$ and the fact that $\phi^\infty$ attains its maximum at $x=0$, we have that $A\phi^\infty(0, \theta_c) = \overline \phi(\theta_c)$ for some $\theta_c \in [\theta_0,N_2]$.  This cannot happen since $\phi^\infty$ is a strict sub-solution of $\overline \phi$.
%%
%%
%%  In the second case, define $v(x,\theta) = A\sin(\beta \pi x) \overline \phi$.  Notice that
%%\[
%%	\theta v_{xx} + v_{\theta\theta} + v(1-a(\theta))
%%		= \beta^2 \pi^2 v + \overline\lambda v.
%%\]
%%Hence, if $\beta$ is sufficiently small $v$ is a sub-solution to $\phi^\infty$, and if $A$ is sufficiently small, then we have that $v \leq \phi^\infty$.  By the technique of sliding~\cite{???}, it is easy to see that $\inf_x \phi^\infty(x,\theta) > 0$ for all $\theta < N_2$.  Hence, we can choose $A$ such that $A\overline\phi \leq \phi^\infty$.  Since $\overline \lambda < \lambda^\infty$, then we have that $\overline \phi$ is a sub-solution to $\phi^\infty$ as well.  Then we may proceed exactly as in the case when $\lambda^\infty < \overline \lambda$ to obtain a contradiction.  Hence, we have that $\lambda$ converges to $\overline \lambda$ as $N_1$ tends to infinity.
%%
%%Now, we claim that $\overline \lambda$ converges to the eigenvalue of
%%\[\begin{cases}
%%	Q_{\theta\theta} + Q(1 - a(\theta)) = \lambda_Q Q, ~~~\text{ for all } \theta \in [\theta_0, \infty),\\
%%	Q_\theta(\theta_0) = 0,\\
%%	Q > 0,
%%\end{cases}\]
%%which is positive by {\color{red} ADD REFERENCE TO LIMITING Q PROBLEM HERE}.  If this is not true, then we may find a sequence $\overline \lambda_n$ which converges along a subsequence to $\overline \lambda^\infty$ which is not equal to $\lambda_Q$.  It is easy to see that $\overline \lambda^\infty \leq \lambda_Q$ since, if not, we may use $\overline \phi$ as a sub-solution to $Q$ on $[\theta_0,N_2]$ as a sub-solution and then we may proceed as above.  OTHERWISE TAKE LIMIT AND IT WON'T BE PERPENDICULAR TO Q IN L2.
%%
%\end{proof}
%
%\begin{proof}%[{\bf Proof of \Cref{lem:balloon}}]
%%For notational ease, we assume that $x_0 = 0$.  We begin by examining the following eigenvalue problem:
%%\begin{equation}\label{eq:eigenvalue}
%%	\begin{cases}
%%		\theta \phi_{xx} + \phi_{\theta\theta} + \phi(1 - a(\theta)) = \lambda \phi, ~~~~&\text{ for all } (x,\theta) \in B_{N_1\times N_2},\\
%%		\phi(-N_1,\theta) = \phi(N_1, \theta) = \phi(x,N_2) = 0, ~~~~&\text{ for all } x \in [-N_1,N_1], ~\text{ and all } \theta \in [\theta_0, N_2],\\
%%		\phi_\theta(x,\theta_0) = 0, ~~~~&\text{ for all } x\in [-N_1,N_1].
%%	\end{cases}
%%\end{equation}
%%We choose $\phi$ to be the principal eigenvalue of this problem, where we also normalize $\phi$ to have $L^\infty$ mean one.   
%%
%
%After \cref{lem:eigenvalue_limit}, we may choose $r,s$ sufficiently large such that the solution $(\gamma_{r,s},\varphi_{r,s})$, to~\eqref{eq:evpb} satisfies $\Vert \varphi_{r,s} \Vert_{L^{\infty}\left((-r,r) \times (\underline\theta, \underline\theta + s)\right)} = 1$ and $\gamma_{r,s} > \gamma_\infty/2$. Though $(\gamma_{r,s},\varphi_{r,s})$ depends on $r,s$, we omit this notation for legibility of the proof.
%
%
%
%Given these $(r,s)$, assume now that \eqref{eq:lowert0} holds. We thus have $n(t_0,\cdot) \geq e^{-M} \varphi$ on $(-r,r) \times (\underline\theta, \underline\theta + s)$. We now make the latter r.h.s grow exponentially by defining 
%\begin{equation*}
%\forall (t,x,\theta) \in \R^+ \times \Gamma, \qquad \psi(t,x,\theta) = M_0e^{\frac{\lambda t}{2}} \phi(x,\theta).  
%\end{equation*}
%We make sure that $\psi$ stays below $n$ for a sufficiently long period of time. To this aim, we need to compare $n$ to the local equation that defines $\varphi$. We thus recall the following parabolic Harnack type inequality from \cite{Alfaro-Berestycki-Raoul} 
%\begin{prop}[{\bf \cite{Alfaro-Berestycki-Raoul}, Theorem 2.6 in our context}]
%Let $\delta > 0$. There exists $C_s>0$ such that
%\begin{equation*}
%\forall x \in \R, \qquad \max_{\theta \in (\underline\theta,\underline\theta + s)} n(t_0,x,\theta) \leq C_s \max_{\theta \in (\underline\theta,\underline\theta + s)} n(t_0,x,\theta) + \delta. 
%\end{equation*}
%\end{prop}
%Thus, enlarging $(r,s)$ if necessary, and recalling \cref{lem:tails}, we have
%\begin{equation*}
%n_t - \theta n_{xx} - n_{\theta\theta} \leq n \left(1 - \frac{\gamma_\infty}{4} - m - C_s n \right), \qquad \text{on } \R^+ \times (-r,r) \times (\underline\theta, \underline\theta + s),
%\end{equation*}
%But $\psi$ satisfies
%\begin{equation*} 
%\begin{split}
%	\psi_t - \theta \psi_{xx} - \psi_{\theta\theta} - \psi \left(1 -\frac{\gamma_\infty}{4} - m - C_s \psi \right)
%		&= \frac{\lambda}{2} \psi + \frac{\gamma_\infty}{4} \psi - \lambda \psi + C_s\psi^2, \medskip\\
%		&= \left(C_s \psi - \frac{\lambda}{2} \right) \psi \leq 0, \qquad \text{on } \R^+ \times (-r,r) \times (\underline\theta, \underline\theta + s).
%\end{split}
%\end{equation*}
%
%Then as long as $\psi \leq \frac{\lambda}{2C}$, the comparison principle (the boundaries are compatible with it) yields that $\psi \leq n$. This gives a maximal time of growth:
%\begin{equation*} 
%	t \leq \frac{2}{\lambda}\left(\ln\left(\frac{\lambda}{2C_s}\right) - \ln(M_0) \right) := t_1.
%\end{equation*} 
%Define $M_1 = \frac{\lambda}{2C_s}$ (independently from $T$). Then we see that
%\[
%	\Vert n(t_0 + t_1,\cdot)\Vert_{L^{\infty}\left((-r,r) \times (\underline\theta, \underline\theta + s)\right)}
%		\geq \|\psi(t_1,\cdot)\|_{L^{\infty}\left((-r,r) \times (\underline\theta, \underline\theta + s)\right)}
%		= m.
%\]
%
%\end{proof}
%
%\begin{proof}%[{\bf Proof of Theorem \ref{thm:main}, case \ref{case:propzerolower}}]
%
%Take $T$ large enough such that $(r,s)$ from \cref{lem:balloon} satisfy $r \leq (1/3) \overline L_2 d_2(T)$ and $s \leq \overline L_1 d_1(T)$. Applying \cref{lem:balloon} to our setting with $t_0 = 3t(T)$ and around the point $x_0 = \overline L_2 d_2(T)$, we see that
%\begin{equation*}
%	\|n(t_0 + t, \cdot)\|_{L^\infty((-r,r) \times (\underline\theta, \underline\theta + s))} \geq M_1
%\end{equation*}
%%with $x_0 = (2/3)\overline L_2 T^{3/(2+p)}$, and , 
%for any $t$ satisfying (we  have to recall the exact expression of $C_1C_2C_3$):
%\begin{equation*}
%	t \geq \left(\frac{2\overline L^3_1}{3 } + \frac{\overline L_2^2}{4} \right) T + C_{\overline L_1, \overline L_2,\Lambda} T^{1 - \frac{p^2}{2+p}} + \log(\delta_0 C_{\Lambda,\Theta_1(0)}) + \log(m) .
%\end{equation*}
%$\overline L_1 = (\lambda / 2)^{1/3}$, and $\overline L_2 = (\lambda / 2)^{1/2}$, we have that
%\[
%	\|n(t, \cdot)\|_{L^\infty((-r,r) \times (\underline\theta, \underline\theta + s))} \geq M_1
%\]
%for any $t$ satisfying
%\[
%	t \geq \frac{T}{2}.
%\]
%as long as $T$ is sufficiently large.  Hence, using the definition of $x_0$ and our assumption that $r \leq d_2(T)$, we have that
%\[
%	\max \left\lbrace x \in \R : \exists \theta \in \overline\Theta, n \left(\frac{T}{2},x,\theta\right) = M_1 \right\rbrace \geq d_2(T) - r.
%\]
%Up to changing $T$ with $2T$, we finally get, 
%
%\[
%	\lim_{T\to \infty}\frac{\max \{ x \in \R : \exists \theta \in \overline\Theta, n(T,x,\theta) = M_1 \}}{d_2(T)} \geq C .
%\]
%
%\end{proof}











 
 
%$L_1 = \overline L_1 T^{2/(2+p)}$.  We first create a sub-solution for~\eqref{nov1006} on the set $E_{0, H_1 + c_1t, R_1}$ all $t \in [0, L_1/c_1]$ where in general, we define
% \[
% 	E_{x(t),\theta(t), R}
%		\stackrel{\rm def}{=}
%		\left\{
%			(x,\theta) \in \R\times[\underline\theta,\infty) : \frac{(x - x(t))^2}{\theta(t)} + (\theta - \theta(t))^2 \leq R
%		\right\}.
% \]
%
%To this end, we note that since $\rho(t,x) \leq \overline \rho$ holds for all $t$ and $x$, then any sub-solution to
%\begin{equation}\label{eq:sub-solution1}
%	\underline n_t \leq \theta \underline n_{xx} + \underline n_{\theta\theta} + \underline n ( 1 - \overline \rho - a(L_1 + R)),
%\end{equation}
%with Dirichlet boundary conditions $\underline n = 0$ on $\partial E_{0,H_1 + c_1t,R_1}$, is a sub-solution to $n$.  To build such a sub-solution, we change variables and define
%\[
%	u(t,y,\eta) = \underline n\left(t, \sqrt{(c_1 t +H_1)} y, \eta + c_1 t + H \right)
%.\]
%Changing variables in \eqref{eq:sub-solution1}, we see that we need to define $u$ on $B_R(0) = \{(y,\eta): |y|^2 + |\eta|^2 \leq R\}$ which satisfies
%\begin{equation}\label{eq:sub-solution2}
%	u_t
%		\leq \left(1 + \frac{\eta}{c_1t + H_1} \right) u_{yy} + u_{\eta\eta} + \frac{yc_1}{2(c_1 t + H_1)} u_y + c_1 u_\eta + u(1 - \overline \rho - a(L_1 + R)).
%\end{equation}
%THE Y IN THE Y-ADVECTIVE TERM IS MISSING BELOW
%
%To understand the behaviour of $u$, we define
%\[
%	u(t,y,\eta) = e^{- \frac{c_1}{4(c_1t + H_1)} y - \frac{c_1}{2}\eta} v(t,y,\eta),
%\]
%NOTE : DONT PUT Y IN THE EXPONENTIAL ...   and we notice that we need $v$ to satisfy
%\[\begin{split}
%	\frac{c_1^2}{4(c_1 t + H_1)^2} y v + v_t
%		&\leq \left(1 + \frac{\eta}{c_1t + H_1}\right) \left(v_{yy} - \frac{c_1}{2(c_1 t + H_1)} v_y + \frac{c_1^2}{16(c_1 t + H_1)^2} v \right)\\
%		&~~~~	+ \left(v_{\eta\eta} - c_1 v_\eta + \frac{c_1^2}{4} v\right)
%			+ \frac{c_1}{2(c_1t + H_1)} \left(v_y - \frac{c_1}{4(c_1t + H_1)} v\right)\\
%		&~~~~	+ c_1\left( v_\eta - \frac{c_1}{2} v\right)
%			+ v (1 - \overline \rho - a(L_1 + R_1))\\
%		&= \left(1 + \frac{\eta}{c_1 t + H_1}\right) v_{yy} + v_{\eta\eta}
%			+ - \frac{\eta}{c_1t + H_1} \frac{c_1}{2(c_1t + H_1)} v_y\\
%		&~~~~+ \left( - \frac{c_1^2}{4} - \frac{c_1^2}{16(c_1t + H_1)^2} +1 - \overline \rho - a(L_1 + H_1) + \frac{\eta}{c_1t + H_1}\frac{c_1^2}{16(c_1t + H_1)^2} \right)v.
%\end{split}\]
%
%THE ADVECTIVE TERM IS Y IN A PROBLEM....
%
%
%



\section{Proof of \Cref{prop:tw}: construction of travelling waves}\label{sec:tw}

%This section proves \Cref{prop:tw}. We first construct travelling wave solutions for \eqref{eq:main}.
We now construct a travelling wave solution for~\eqref{eq:main} when $m$ is not sub-linear.  We use these travelling waves later to obtain the spreading results of \Cref{thm:cauchy_finite}.  We recall that a function $n$ solving~\eqref{eq:main} is a \textit{travelling wave} solution with speed $c^* \in \R^+$ if it can be written $n(t,x,\theta)= \mu \left( \xi:= x - c^* t , \theta \right)$
%\begin{equation*}
%\forall (t,x,\theta) \in \R^+ \times \R\times \overline\Theta, \qquad n(t,x,\theta)= \mu \left( \xi:= x - c^* t , \theta \right),
%\end{equation*}
%where {\textit{the profile}} $\mu \in \mathcal{C}_b^2 \left( \Gamma \right)$ is nonnegative and satisfies the locally uniform limits
%\begin{equation*}
%	\liminf_{\xi \to - \infty} \mu \left( \xi , \cdot \right) > 0,
%		\qquad\text{ and }\qquad
%	\lim_{\xi \to + \infty} \mu \left( \xi , \cdot \right) = 0, 
%\end{equation*}
%Notice that
where $\mu$ satisfies
\begin{equation}\label{eqkinwave}
\begin{cases}
- c^* \mu_{\xi} = \theta  \mu_{\xi \xi} + \mu_{\theta  \theta} + \mu  (1 - m - \nu),& \qquad \text{on } \R\times \Theta,\\
\mu_\theta (\cdot,\underline\theta) = 0.&
\end{cases}
\end{equation} 
where $\nu$ is the macroscopic density associated to $\mu$; that is $\nu = \int_\Theta \mu \left( \cdot, \theta \right) d \theta$.

We follow the standard strategy. First, we explain how to compute the minimal speed of propagation of possible solutions. Then, we solve an approximated problem in a bounded slab in both directions $\xi$ and $\theta$. The resolution of the slab problem is mainly a combination of \cite{AlfaroCovilleRaoul,BouinCalvez}. Finally, we let the slab tend to $\R \times \Theta$ to obtain a wave that we prove to have the minimal speed. 

We split the section into two parts.  First, we cover the case where $m(\theta)/\theta \to \infty$ as $\theta\to\infty$.  Second, we discuss the modifications necessary in the case where $m(\theta)/\theta$ tends to a positive constant.

\subsection{Case one: $\lim_{\theta \to + \infty} m(\theta)/\theta = +\infty$.}\label{sec:caseone}

\subsubsection{Spectral problems and minimal speeds}

We start the construction by defining speeds of propagation for the travelling waves. Recall that for any $\lambda >0$, the spectral problem defining $c_\lambda$ is written as follows
\begin{equation*}
%	\begin{cases}
		Q_\lambda'' + \left[  \lambda^2 \theta - \lambda c_\lambda + (1 -  m(\theta)) \right] Q_\lambda  = 0, \qquad \theta \in \Theta,
%Q_\lambda' \left( \underline \theta \right) = 0.
%	\end{cases}
\end{equation*}
accompanied by the Neumann condition $Q_\lambda'(\underline \theta) = 0$.  Since $\lim_{\theta \to + \infty} m(\theta)/\theta = +\infty$, this spectral problem may be solved. We then define $\lambda^* = \min\argmin\{c_\lambda: \lambda > 0\}$ and let $c^* = c_{\lambda^*}$ and $Q^* = Q_{\lambda^*}$.  We fix the normalization that $\|Q_\lambda\|_\infty = 1$.

For $\tau \in [0,1]$, define the spatial diffusivity function $d^\tau$ by $d^\tau(\theta) = \underline \theta  + \tau \left( \theta - \underline \theta \right).$
In general, we suppress the dependence on $\tau$ in this section except in \Cref{sec:homotopy} where the $\tau$ variable is the main concern.  Since we first construct a travelling wave solution on a bounded slab, for any spatial decay rate $\lambda > 0$ and any $b>0$, we also introduce the following approximate spectral problems:
\begin{equation}\label{eq:spectral_problem}
\begin{cases}
 Q_{\lambda,b} ''+ \left( - \lambda c_{\lambda,b} + d \lambda^2   + \left( 1 - m \right) \right) Q_{\lambda,b} = 0, \qquad \text{ on } (\underline\theta, \underline\theta + b),\\
Q_{\lambda,b}' \left( \underline\theta \right) = 0,\qquad 
Q_{\lambda,b}  \left( \underline\theta + b\right) = 0, \qquad
Q_{\lambda,b} > 0.
\end{cases}
\end{equation}
%In the sequel, $c_{\lambda,b}$ plays the role of the speed of the travelling wave.
%
By the Krein-Rutman theorem, there exists a positive solution $(c_{\lambda,b}, Q_{\lambda,b})$ to this problem. 
%Moreover, thanks to \Cref{hyp:m}, we have that
%\begin{equation*}
%\lim_{\theta \to + \infty} \left( - \lambda c_{\lambda,b} + d(\theta) \lambda^2   + \left( 1 - m(\theta) \right) \right) = - \infty.
%\end{equation*}
%As a consequence, \EB{FINISH HERE}
%
We now describe the function $\lambda \mapsto c_{\lambda,b}$.  By looking at the limit as $b$ tends to infinity, the principle eigenvalue of the operator $\partial_\theta^2 + (1-m)$ tends to $\gamma_\infty$.  Hence, when $b$ is sufficiently large, since $d^\tau \lambda^2 > 0$, we have $\lambda c_\lambda \geq \gamma_\infty/2 > 0$, so that $c_\lambda$ is uniformly bounded away from zero. Moreover, we  have that $\lambda c_\lambda \to \gamma_\infty$ as $\lambda$ tends to zero.  Using the Rayleigh quotient, it is easy to check that $\lambda c_\lambda = \mathcal{O}_{\lambda \to + \infty}\left(\lambda^2\right)$.  As a result, since $\lambda \mapsto c_\lambda$ is continuous, it admits a global minimum on $(0,\infty)$.  This minimum defines the minimal speed $c_{b}^{\tau*} := \min_{\lambda > 0} c_{\lambda,b}$. The smallest minimizer is denoted $\lambda_b^*$.



We also introduce the family of eigenvectors $Q_b^\delta$, that appears naturally as boundary conditions at the back for the slab problem below. For any $\delta \geq 0$ and $b\in (0,\infty]$, let us define $Q_b^\delta$ by solving the following eigenvalue problem  
\begin{equation}\label{eq:eigenpb}
\begin{cases} 
	\left( Q_b^\delta \right) '' + \left( 1 - (1-\delta) m \right)Q_b^\delta = \gamma_b^\delta Q_b^\delta, \qquad \text{ on }\theta\in (\underline\theta, \underline\theta + b),\\
	\left( Q_b^\delta \right)' \left( \underline\theta \right) = 0,
	\qquad Q_b^\delta \left(\underline\theta + b \right) = 0,
	\qquad \int_{(\underline\theta, \underline\theta + b)} Q_b^\delta(\theta)\, d\theta = \gamma_b^\delta,
	\qquad Q_b^\delta > 0.	
\end{cases}
\end{equation}
We denote by $Q_b$ the particular case of $Q_b^{\delta = 0}$. The positivity of the eigenvalue $\gamma_b^\delta$ is ensured when $b$ is sufficiently large as $\gamma_b^\delta \geq \gamma_b^0$. % and when $b \to \infty$, $\lim_{b \to \infty} \gamma_b^0 = \gamma_\infty$.
%
%we recover the problem
%\begin{equation*}
%\begin{cases} 
%	\left( Q_\infty^\delta \right) '' + \left( 1 - (1-\delta)m \right)Q_\infty^\delta = \gamma_\infty^\delta Q_\infty^\delta, \\
%	\left( Q_\infty^\delta \right) ' \left( \underline\theta \right) = 0, 
%	\qquad \int_{\Theta} Q_\infty^\delta(\theta)\, d\theta = \gamma_\infty,
%	\qquad Q_\infty^\delta > 0,
%\end{cases}
%\end{equation*}
%so that, by definition of $Q^0_\infty = Q$, the solution of \eqref{eq:specQ}.  Since $\gamma_\infty > 0$, the Rayleigh quotient for the above operator shows that $\gamma_b^\delta > 0$ for all $\delta$ when $b$ is sufficiently large.



\subsubsection{The problem in a slab}\label{sec:slab}

Given $a,b, \delta, \underline\epsilon >0$ and $\tau \in [0,1]$, we define the problems %$P_{a,b,\delta,\epsilon}^\tau$
on the slab $(-a,a) \times (\underline\theta, \underline\theta + b)$ as follows:
\begin{equation}\label{eq:slab}
\begin{cases}
		-c_{a,b}^\tau \big( \mu_{a,b}^\tau \big)_\xi  - d^\tau \big( \mu_{a,b}^\tau \big)_{\xi \xi} -  \big( \mu_{a,b}^\tau \big)_{\theta\theta} =\big[ \mu_{a,b}^\tau \big]_+ \big(1 - m - \nu_{a,b}^\tau \big),&\text{on } (-a,a) \times (\underline\theta, \underline\theta + b), \\
		\big( \mu_{a,b}^\tau \big)_{\theta}   (\cdot, \underline \theta ) = 0,
		\qquad \mu_{a,b}^\tau(\cdot, \underline \theta + b ) = 0,\\
		\mu_{a,b}^\tau(-a,\cdot) = Q_b  , \qquad \mu^a(a,\cdot)  = 0
		\qquad \mu_{a,b}^\tau(0,\underline\theta) = \underline\eps,
\end{cases}
\end{equation}
where $\nu_{a,b}^\tau := \int_{(\underline\theta, \underline\theta + b)} \mu_{a,b}^\tau(\cdot,\theta) d\theta$ and where we use the ``positive'' part notation $x_+ := x \1_{x\geq 0}$.  We are, momentarily, suppressing the dependence of $\mu$ on $\underline\epsilon$ and $\delta$.

We note that we seek {\em positive} travelling waves.  This is a consequence of the maximum principle. % as in similar works \cite{Alfaro,Berestycki-Nadin,BouinCalvez}.
Indeed, suppose that $\mu_{a,b}^\tau$ attains a negative minimum at some point $(\xi_0,\theta_0) \in [-a,a] \times [\underline\theta, \underline\theta + b]$. Necessarily, $\xi_0 \neq \pm a$ due to the Dirichlet boundary conditions and $\theta_0 \neq \underline \theta, \underline\theta+b$ due to the Neumann and Dirichlet boundary conditions, respectively. Hence, $(\xi_0,\theta_0) \in (-a,a) \times (\underline\theta, \underline\theta + b)$, so, by continuity, we can find an open set $\mathcal{V} \subset (-a,a) \times (\underline\theta, \underline\theta + b)$ containing $(\xi_0,\theta_0)$ such that we  have,  
\begin{equation*}
-c_{a,b}^\tau \left( \mu_{a,b}^\tau \right)_\xi  - d^\tau \left( \mu_{a,b}^\tau \right)_{\xi \xi} -  \left( \mu_{a,b}^\tau \right)_{\theta\theta} = 0, \qquad \text{on } \mathcal{V}.
\end{equation*}
By the maximum principle, this would imply that $\mu$ is a negative constant, which is impossible. 


We now comment on the problem \eqref{eq:slab}. The unknowns are the speed $c_{a,b}^\tau$ and the profile $\mu_{a,b}^\tau$. Without the supplementary renormalization condition $\mu_{a,b}^\tau(0,\underline\theta) = \underline\epsilon$, the problem is underdetermined. Indeed, this additional condition is needed to ensure compactness of the family $(c_{a,b}^\tau,\mu_{a,b}^\tau)$ when $a$ tends to $\infty$, since the limit problem is translationally invariant. The boundary condition in $-a$ is chosen this way since we heuristically expect that the distribution of the population converges towards $Q$ at the back of an invasion front.  Although we fix this boundary condition in the slab, let us recall again that in general the behavior at the back of the wave for the limit problem is not easy to determine due to possible Turing instabilities.   Lastly, we note that, due to the nonlocal term, the equation for $\mu$,~\eqref{eq:slab}, does not admit a comparison principle.

%Due to the nonlocal term, the equation for $\mu$,~\eqref{eq:slab}, does not admit a comparison principle. We follow the standard construction -- obtaining a priori bounds on the slab, using Leray-Schauder degree theory to obtain a solution on the slab, and then carefully taking the limit as the slab approximates $\R\times [\underline\theta,\infty)$.%We follow similar constructions for nonlocal problems \cite{Alfaro,Berestycki-Nadin,BouinCalvez} and use the Leray-Schauder theory. For this purpose, some uniform \textit{a priori} estimates on the solutions of the slab problem are required. To this end, we follow the same strategy as in earlier papers \cite{Alfaro,BouinCalvez}. We first prove in Lemma \ref{lem:upboundc} that the speed is uniformly bounded from above. Then, Lemma \ref{lem:bottom} shows that there are no solutions where $c_{a,b}^\tau = 0$, provided that the normalization $\eps$ is well chosen. Finally, when the speed is given and uniformly bounded, we can derive a uniform estimate on the solutions of the slab problem \eqref{eq:slab}. 

%Thanks to these \textit{a priori} estimates, we apply a Leray-Schauder topological degree argument with the parameter $\tau$ in Proposition \ref{slabsol}. This reduces the problem to the case when $\tau=0$, which is doable since it is similar to the problem considered in \cite{Alfaro}. 

We follow the standard construction -- obtaining a priori bounds on the slab, using Leray-Schauder degree theory to obtain a solution on the slab, and then carefully taking the limit as the slab approximates $\R\times [\underline\theta,\infty)$.
For notational convenience, we  omit the subscript $a,b$ and the superscript $\tau$ in $\mu_{a,b}^\tau$ and $c_{a,b}^\tau$.






\subsubsection*{An upper bound on $c$}

We first obtain a general upper bound on $c$, which comes from the linearized problem.

\begin{lemma}\label{lem:upboundc}
For any $\underline\epsilon > 0$, there exists $a_0(\underline\epsilon,b)$ such that if $a \geq a_0(\underline\eps,b)$, then any solution $(c,\mu)$ of the slab problem \eqref{eq:slab} satisfies $c \leq c_b^*$.
%$c \leq c_\infty^{\tau*} \leq c^*$.
\end{lemma}

\begin{proof}%[{\bf Proof of Lemma \ref{lem:upboundc}}]

We follow the classical approach: we find a super-solution for a related problem. Since $\mu \geq 0$, $\mu$ is a sub-solution to the linearized problem.  In other words,
\begin{equation}\label{eq:n}
-c \mu_{\xi}  \leq d \mu_{\xi\xi} + \mu_{\theta\theta}  + \left( 1 - m \right)\mu, \qquad \text{on } (-a,a) \times (\underline\theta, \underline\theta + b).
\end{equation}

Let us assume by contradiction that $c > c_b^*$, then the family of functions $\psi_A ( \xi, \theta ):= A e^{- \lambda_b^*\xi} Q_b^* ( \theta )$ is indeed a family of super-solutions to the linear problem:
\begin{align}\label{eq:psi_A}
- c \left(\psi_A\right)_{\xi} = c \lambda_b^*\psi_A > \lambda_b^* c_b^* \psi_A &= \theta  \left(\psi_A\right)_{\xi\xi}  + \left(\psi_A\right)_{\theta\theta}  + (1-m )\psi_A \\& \geq d  \left(\psi_A\right)_{\xi\xi}  + \left(\psi_A\right)_{\theta\theta}  + (1-m )\psi_A, \qquad \text{on } (-a,a) \times (\underline\theta, \underline\theta + b) \nonumber.
\end{align}
Since $Q_b^*$ is positive and $\mu$ is bounded and since both functions are $C^2$, we have $\mu \leq \psi_A$ for $A$ sufficiently large.  Hence, define
\begin{equation*}
A_0 = \inf \left\lbrace A \; \vert \; \psi_A \geq \mu \text{ on } [-a,a]\times[\underline\theta, \underline\theta+ b] \right\rbrace. 
\end{equation*}
Necessarily, $A_0 > 0$ and there exists a point $(\xi_0, \theta_0)$ in $[-a,a]\times[\underline\theta, \underline\theta+ b]$ where $\psi_{A_0}$ touches $\mu$: $\mu(\xi_0 , \theta_0) = \psi_{A_0}(\xi_0 , \theta_0).$  This point minimizes $\psi_{A_0} - \mu $ but {\em cannot} be in $(-a,a) \times (\underline\theta, \underline\theta + b)$ if the normalization $\underline\eps$ is well chosen.  Indeed, combining~\eqref{eq:n} and~\eqref{eq:psi_A}, we have
\begin{equation*}
- c \left(\psi_{A_0} - \mu \right)_{\xi} - d \left( \psi_{A_0} - \mu \right)_{\xi\xi} -  \left( \psi_{A_0} - \mu \right)_{\theta\theta} - (1-m) \left( \psi_{A_0} - \mu \right) > 0, \text{ on } (-a,a) \times (\underline\theta, \underline\theta + b).
\end{equation*}
But, if $(\xi_0,\theta_0)$ is in the interior, this inequality cannot hold since at $(\xi_0,\theta_0)$ we  have
\begin{equation*}
	\psi_{A_0} - \mu = 0,
	\quad  \left(\psi_{A_0} - \mu \right)_\xi = 0,
	\quad \text{ and }
	\quad d  \left( \psi_{A_0} - \mu \right)_{\xi\xi} +\left( \psi_{A_0} - \mu \right)_{\theta\theta} \geq 0.
\end{equation*}
Next we rule out the boundaries. First, $\xi_0 \neq a$ since $\psi_{A_0}(a,\theta_0) > 0$.  %$(\xi_0,\theta_0)$ cannot lie on a boundary where  $\mu = 0$ since either $\psi_{A_0}>0$ or $\psi_{A_0} = 0$ and we may apply the Hopf maximum principle.
 Moreover, $(\xi_0,\theta_0)$ cannot lie where both $\psi_{A_0}$ and $\mu$ satisfy Neumann boundary conditions thanks to the Hopf maximum principle.  Next, we exclude the left boundary $\{\xi=-a\}$ due to the normalization. Indeed, if $\xi_0 = -a$, then $\psi_{A_0} (\xi_0, \theta_0) = Q_b(\theta_0)$ and thus $A_0 = e^{- \lambda_b^* a} Q_b(\theta_0)/Q_b^*(\theta_0)$. Using the definition of $A_0$, we have 
\begin{equation*}
	\underline\epsilon = \mu(0,\underline\theta) < \frac{Q_b(\theta_0)}{Q_b^*(\theta_0)}e^{- \lambda_b^* a} Q_b^* (\underline \theta ).
\end{equation*}
We thus define $a_0(\underline\epsilon,b)$ to be sufficiently large that this inequality cannot hold when $ a > a_0(\underline\epsilon,b)$.

From above, it follows that $\theta_0 = b$ and $\xi_0 \neq \pm a$.  By our choice of $A_0$, we may assume without loss of generality that $(\psi_{A_0} - \mu)_\xi(\xi_0,b) = 0$ since otherwise we could lower $A_0$ further, contradicting its definition.  However, the Hopf maximum principle implies that $(\psi_{A_0} - \mu)_{\xi}(\xi_0,b) < 0$.  This is a contradiction, finishing the proof.
%and thus $\eps = \mu(0, \underline\theta) \leq \frac{Q_b}{Q^*}(\theta_0)e^{- \lambda^* a} Q^*(\underline\theta)$ which is smaller than $\epsilon$ for a sufficiently large $a$. We thus conclude that $c \leq c^*$.
%
%Finally, we should mention that for all $\tau \in [0,1]$, we  have $c_\tau^* \leq c^*$. The proof being the exact same one as in \cite[Lemma 9]{BouinCalvez}, we omit it. \EB{CHANGE THAT}
%
%
%We follow the classical approach, i.e.~finding a relevant super-solution for a related problem. Since any solution $\mu$ to $P_{a,b}^\tau$ is nonnegative, $\mu$ is a sub-solution to the linearized problem, that is 
%\begin{equation}\label{eq:n}
%-c \mu_{\xi}  \leq d \mu_{\xi\xi} + \mu_{\theta\theta}  + \left( 1 - m \right)\mu, \qquad \text{on } (-a,a) \times (\underline\theta, \underline\theta + b).
%\end{equation}
%
%Let us assume by contradiction that $c > c_\tau^*$, then the family of functions $\psi_A ( \xi, \theta ):= A e^{- \lambda_\tau^*\xi} Q_\tau^* ( \theta )$ is indeed a family of super-solutions to the linear problem:
%\begin{equation}\label{eq:psi}
%- c \left(\psi_A\right)_{\xi} > \lambda_\tau^* c_{\tau}^* \psi_A = d  \left(\psi_A\right)_{\xi\xi}  + \left(\psi_A\right)_{\theta\theta}  + (1-m )\psi_A, \qquad \text{on } (-a,a) \times (\underline\theta, \underline\theta + b).
%\end{equation}
%Since $Q_\tau^*$ is positive and $\mu$ is bounded, we  have $\mu \leq \psi_A$ for $A$ sufficiently large.  Hence, we may define
%\begin{equation*}
%A_0 = \inf \left\lbrace A \; \vert \; \psi_A > \mu \text{ on } [-a,a]\times[\underline\theta, \underline\theta+ b] \right\rbrace. 
%\end{equation*}
%Necessarily, $A_0 > 0$ and there exists a point $(\xi_0, \theta_0)$ in $[-a,a]\times[\underline\theta, \underline\theta+ b]$ where $\psi_{A_0}$ touches $\mu$: $\mu(\xi_0 , \theta_0) = \psi_{A_0}(\xi_0 , \theta_0).$ This point minimizes $\psi_{A_0} - \mu $ but {cannot} be in $(-a,a) \times (\underline\theta, \underline\theta + b)$ as soon as the normalization $\eps$ is well chosen. Here is the expected contradiction. Indeed, combining  \eqref{eq:n} and \eqref{eq:psi}, we  have (in the interior), 
%\begin{equation*}
%- c \left(\psi_{A_0} - \mu \right)_{\xi} - d \left( \psi_{A_0} - \mu \right)_{\xi\xi} -  \left( \psi_{A_0} - \mu \right)_{\theta\theta} - (1-m) \left( \psi_{A_0} - \mu \right) > 0, \text{ on } (-a,a) \times (\underline\theta, \underline\theta + b).
%\end{equation*}
%But, if $(\xi_0,\theta_0)$ is in the interior, this latter inequality cannot hold since at $(\xi_0,\theta_0)$, we  have
%\begin{equation*}
%	\psi_{A_0} - \mu = 0,
%	\quad  \left(\psi_{A_0} - \mu \right)_\xi = 0,
%	\quad \text{ and }
%	\quad d  \left( \psi_{A_0} - \mu \right)_{\xi\xi} +\left( \psi_{A_0} - \mu \right)_{\theta\theta} \geq 0.
%\end{equation*}
%{Next we} eliminate the boundaries. First, $(\xi_0,\theta_0)$ cannot lie in a boundary where  $\mu = 0$ since $\psi_{A_0} >0$. Moreover, $(\xi_0,\theta_0)$ cannot lie where both $\psi_{A_0}$ and $\mu$ satisfy Neumann boundary conditions thanks to the Hopf Lemma. We now exclude the left boundary by adjusting the normalization. If $\xi_0 = -a$, then $\psi_{A_0} (\xi_0, \theta_0) = Q_b^\delta(\theta_0)$ and thus $A_0 = \frac{Q_b^\delta(\theta_0) }{Q_\tau^* ( \theta_0 ) } e^{- \lambda_\tau^* a}$. Coming back to the definition of $A_0$, one finds 
%\begin{equation*}
%	\forall \theta \in \left[\underline\theta, \underline\theta + b\right], \qquad \; \mu(0,\theta) < \frac{Q_b(\theta_0) }{Q_\tau^* ( \theta_0 ) } e^{- \lambda_\tau^* a} Q_\tau^* ( \theta ), 
%\end{equation*}
%and thus $\eps = \mu(0, \underline\theta) \leq \frac{Q_b(\theta_0) }{Q_\tau^* ( \theta_0 ) } e^{- \lambda_\tau^* a} Q_\tau^* ( \underline\theta )$ which is smaller than $\epsilon$ for a sufficiently large $a$. We thus conclude that $c \leq c_\tau^*$. {\color{red}  NEED A UNIFORM BOUND FOR $\lambda_\tau$ FROM BELOW FOR THIS TO BE TRUE.}
%
%Finally, we should mention that for all $\tau \in [0,1]$, we  have $c_\tau^* \leq c^*$. The proof being the exact same one as in \cite[Lemma 9]{BouinCalvez}, we omit it. \EB{CHANGE THAT}
%
%Differentiating \eqref{eq:spectau} with respect to $\tau$ and testing against $Q_\tau^*$, one obtains, similarly as in Proof of Proposition \ref{propspec} (iii), 
%\begin{equation*}
%\int_{\Theta} \left[ \frac{d \lambda}{d \tau} \left( 2 \lambda_\tau^* g_\tau(\theta) - c_\tau^* \right) + \left(\lambda_\tau^*\right)^2 g_\tau'(\theta) - \lambda_\tau^* \frac{d c_\tau^*}{d \tau} \right] \left( Q_\tau^*  \right)^2 d\theta = 0.
%\end{equation*}
%But now recalling \eqref{rel3}, which writes as follows in the $\tau$-case:
%\begin{equation}\label{rel3'}
%c_\tau^* = 2 \lambda_\tau^* \frac{\int_{\Theta} g_\tau(\theta) \left( Q_\tau^* \right)^2 d \theta}{\int_{\Theta} \left( Q_\tau^* \right)^2 d \theta},
%\end{equation}
%one obtains 
%\begin{equation*}
%\frac{d c_\tau^*}{d \tau}    =  \lambda_\tau^* \frac{ \int_{\Theta}  g_\tau'(\theta) \left( Q_\tau^*  \right)^2 d\theta }{\int_{\Theta} \left( Q_\tau^*  \right)^2 d\theta}.
%\end{equation*}
%We deduce that $c_\tau^*$ is increasing with respect to $\tau$, so that $c_\tau^* \leq c_1^* = c^*$.

\end{proof}







\subsubsection*{A uniform bound on the trait tails, for $c \in [0,c^* +1]$.}

Since the trait space is unbounded, we must prove the following lemma about the tails of $n$ in $\theta$.

\begin{lemma}[The tails of $\mu$]\label{lem:tails}
Assume $c \in \left[ 0 , c^* + 1 \right]$, $\tau \in [0,1]$, $\delta > 0$, and recall that $Q_\infty^\delta$ is defined in \eqref{eq:eigenpb}. Then there exists a constant $C_{\text{tail}}$ depending on $\delta$ such that on $[-a,a]\times[\underline\theta, \underline\theta+ b]$ we have
\begin{equation*}
	\mu
		\leq C_{tail} \left(1 + \|\mu\|_{L^\infty([-a,a]\times[\underline\theta,\underline\theta+b])}\right) Q_\infty^\delta.
\end{equation*}
\end{lemma}

\begin{remark}
We point out that it is in this proof that we see the importance of modifying the trade-off function with the parameter $\delta$.  Without this, a uniform bound in $b$ would be impossible.
%This is where the important of modifying the trade-off function with a parameter $\delta$ appears: a uniform bound in $b$ is impossible without this. 
\end{remark}

\begin{proof}%[{\bf Proof of Lemma \ref{lem:tails}}]
Our strategy is to find a relevant super-solution using spectral problems.
%Since any solution $\mu$ to $P_{a,b}^\tau$ is nonnegative, $\mu$ is a sub-solution to the linearized problem, that is 
%\begin{equation}\label{eq:n}
%- c   \mu _\xi - d^\tau \mu_{\xi\xi} - \mu_{\theta\theta} - \left( 1 - m \right)\mu \leq 0, \qquad \text{on } (-a,a) \times (\underline\theta, \underline\theta + b).
%\end{equation}
To do this, define, for $\theta_\delta$ to be chosen later, the function 
\begin{equation*}
	\psi  := \max \left( 1 , \frac{\Vert \mu \Vert_{L^{\infty} ( [-a,a] \times [\underline\theta, \underline\theta + b] )}}{\min_{[\underline\theta,\theta_\delta]} Q_\infty^\delta}, \left\|\frac{Q_b}{Q_\infty^\delta}\right\|_{L^\infty} \right) \, Q_\infty^\delta,
	\quad\text{ on }  (-a,a) \times (\underline\theta, \underline\theta + b).
\end{equation*}
 We have $\mu \leq \psi$ on $[-a,a] \times [\underline\theta,\theta_\delta]$ by construction. It satisfies
\begin{equation*}
- c \psi_{\xi}  - d \psi_{\xi\xi} - \psi_{\theta\theta} - \left( 1 - m \right)\psi  = \big( - \gamma_\infty^\delta + \delta m \big) \psi, \quad \text{ on } (-a,a) \times (\underline\theta, \underline\theta + b).
\end{equation*}
Define $\theta_\delta := m^{-1}\left(\delta^{-1}  \gamma_\infty^\delta \right)$. This definition is possible by \Cref{hyp:m}. % since $m(\underline\theta)= 0$ and $\lim_{\theta \to +\infty} m(\theta) = \infty$ by \Cref{hyp:m}.
The function $\psi$ is then a super-solution of the linearized problem on $(-a,a) \times (\theta_\delta,\underline\theta+b)$. 
On $(-a,a) \times \left\lbrace \underline\theta + b \right\rbrace$ and $\left\lbrace a \right\rbrace \times (\theta_\delta,\underline\theta+b)$, we see that $\mu \leq \psi$ since $\mu$ satisfies Dirichlet boundary conditions and $\psi$ is positive there. The only boundary that remains to be checked is $\left\lbrace -a \right\rbrace \times (\theta_\delta,\underline\theta+b)$. There, it is true by construction.  %{\color{blue}We point out that, using similar reasoning, there exists $\theta_\delta'$, which is independent of $b$, such that $Q_b$ is a sub-solution of $Q_\infty^\delta$ on $[\theta_\delta',b]$, and thus, there exists $C$ that does not depend on $b$ such that $Q_b \leq C Q_\infty^\delta$ for all $\theta$ sufficiently large}.  {\color{red} Further, using elliptic regularity and the fact that $Q$ is the unique solution to the limiting equation as $b\to\infty$ of the equation that $Q_b$ solves, it follows that $Q_b$ converges to $Q$ uniformly on any set of the form $[\underline\theta, \overline \theta]$.  Taken together} this implies that that we may bound $\|Q_b/Q_\infty^\delta\|_\infty$ by a constant that is independent of $b$.

We point out that, using similar reasoning, there exists $\theta_\delta'$, independent of $b$, such that $Q_b$ is a sub-solution of $Q_\infty^\delta$ on $[\theta_\delta',b]$. Further, using elliptic regularity, $Q_b$ is uniformly bounded above independent of $b$, and, by the maximum principle $Q_\infty^\delta$ is uniformly bounded below on $[\underline\theta, \theta_\delta']$.  Taken together these  facts imply that we may bound $\|Q_b/Q_\infty^\delta\|_\infty$ by a constant that is independent of $b$.


%{\color{blue} I CHANGED ABOVE BECAUSE I DON'T THINK WE NEED TO USE THAT $Q_b$ CONVERGES TO $Q$ IN THE ARGUMENT.  (SEE NEW BLUE PARAGRAPH ABOVE)  IF YOU AGREE WITH THIS, WE SHOULD UPDATE THE REFEREE REPORT RESPONSE TO REFLECT THIS NEW THING}
\end{proof}



\subsubsection*{A uniform bound over the steady states, for $c \in \left[ 0 , c^* + 1 \right]$.}

We now come to the crucial part of the procedure, that is, deriving uniform bounds on steady states for \eqref{eq:slab}.  We assume \textit{a priori} that the speed is nonnegative, since we prove later that the problem \eqref{eq:slab} does not admit any solution with $c=0$. We extend a similar argument used in \cite{BouinCalvez} %{\color{blue} \sout{for the cane toads equation without mortality trade-off ($m=0$)}}. 

\begin{lemma}[A priori estimates for bounded $c$]\label{lem:nc}
Assume $c \in \left[ 0 , c^* + 1 \right]$, $\tau \in [0,1]$, $a\geq 1$ and $b$ is sufficiently large.
 Then there exists a constant $C_0$, depending only on $\underline\theta$ and $m$, such that any solution $(c,\mu)$ of \eqref{eq:slab} satisfies
\begin{equation*}
\Vert \mu \Vert_{L^\infty\left( [-a,a]\times[\underline\theta,\underline\theta+b] \right) }\leq C_0\,.
\end{equation*}
\end{lemma}

\begin{proof}%[{\bf Proof of Lemma \ref{lem:nc}}]
We define $M_{a,b} = \|\mu\|_{L^\infty([-a,a]\times[\underline\theta, \underline\theta + b])}$ and want to prove that $M_{a,b}$ is in fact bounded uniformly in $a$ and $b$.  We can assume that $M_{a,b} \geq 1$ because, if not, we are finished.  As $Q_\infty^\delta$ tends to zero as $\theta$ tends to infinity, choose $\overline \theta$ such that, if $\theta \geq \overline\theta$, $Q_\infty^\delta(\theta) < 1/(4C_{tail})$, where $C_{tail}$ is as in \Cref{lem:tails}.  As a consequence of this, along with the bound $M_{a,b} \geq 1$, we have, for all $\theta \geq \overline \theta$,
\[
	\mu(\cdot, \theta) \leq C_{tail}(1 + M_{a,b}) Q_\infty^\delta(\theta)
		\leq 2C_{tail} M_{a,b} Q_\infty^\delta(\theta)
		\leq M_{a,b}/2.
\]
Hence, the maximum of $\mu$ can only be attained by points $(x_{\max},\theta_{\max})$ with $\theta_{\max} < \overline \theta$.  Then we may interpret ``sufficiently large'' in the assumptions to mean $b \geq \overline \theta + 1$.  In addition, we assume that $\theta_{\max} + 1 > \underline\theta$ in order to avoid complications due to the boundary; however, such complications may be easily dealt with by a simple reflection procedure outlined in~\cite{BerestyckiMouhotRaoul,Turanova}.  Finally, we assume that $x_{\max} \neq \pm a$, since the maxima here are controlled independent of $a$ and $b$. % and we notice that the maximum cannot occur at $b$ since $\mu(x,b) \equiv 0$.

Fix any $p \in (1,\infty)$, and we use local elliptic regularity results to obtain a H\"older bound on $\mu$.  Indeed, by, e.g.~\cite[Theorem~9.13]{GilbargTrudinger},%There are two cases: either $a - x_{\max} \leq 2$ or not.  In the first case, we obtain
\begin{align*}
	\|\mu&\|_{W^{2}_p\left( B_1(x_{\max},\theta_{\max}) \right)}\\
		&\leq C_p\left( \|\mu\|_{L^p\left( B_2(x_{\max},\theta_{\max}) \right)} + \|\mu(1 - m -\nu)\|_{L^p\left( B_2(x_{\max},\theta_{\max}) \right)} + \|Q_b\|_{W^2_p\left( B_2(x_{\max},\theta_{\max}) \right)}\right)\\
		&\leq C_p\left(\|\mu\|_{L^p\left( B_2(x_{\max},\theta_{\max}) \right)} + \|\mu m\|_{L^p\left( B_2(x_{\max},\theta_{\max}) \right)} + \|\mu \nu\|_{L^p\left( B_2(x_{\max},\theta_{\max}) \right)} + 1\right)\\
		&\leq C_p\left( \|\mu\|_{L^\infty\left( B_2(x_{\max},\theta_{\max}) \right)} + \|\mu m\|_{L^\infty\left( B_2(x_{\max},\theta_{\max}) \right)} + \|\mu \nu\|_{L^\infty\left( B_2(x_{\max},\theta_{\max}) \right)} + 1\right).
		%&\leq C(1 + M_{a,b} + M_{a,b}^2),
\end{align*}
Above, the constant $C_p$ changes line-by-line but is uniform in $a$ and $b$.  Indeed, the operator in~\eqref{eq:slab} is bounded and coercive independently of $b$ on $B_2(x_{\max},\theta_{\max})$ since $\theta_{\max} \leq \overline \theta$.  Notice that
\[
	\|m\|_{L^\infty(B_2(x_{\max},\theta_{\max}))} = \|m\|_{L^\infty(\theta_{\max}-2,\theta_{\max}+2)} \leq \|m\|_{L^\infty(\underline \theta, \overline \theta + 2)} \leq C,
\]
since $\theta_{\max} \leq \overline \theta$.  In addition, \Cref{lem:tails} implies that $\|\nu\|_{L^\infty(-a,a)}\leq C(1 + M_{a,b})$.  These two bounds, along with the elliptic regularity bound above, imply that
\[
	\|\mu\|_{W^2_p(B_1(x_{\max}, \theta_{\max}))}
		\leq C(1 + M_{a,b} + M_{a,b}^2)
		\leq 3C M_{a,b}^2.
\]
where $C$ is a constant independent of $a$ and $b$ that will change line-by-line in the sequel.
%where we used~\Cref{lem:tails} to bound $\nu$ in terms of $M_{a,b}$.  It is important here that $\theta_{\max} \leq \overline \theta$ so that the coefficients of~\eqref{eq:slab} are bounded near $(x_{\max},\theta_{\max})$. %In the case where $a-x_{\max} > 2$, we obtain the same inequality without the $Q_b^\delta$ term.  Hence, the same inequality as above holds.
%We point out that the constant $C$ depends only on $p$ and $m$.  
%Using this, we have that
%\[
%	\|n\|_{W^{1,2}_p\left( \mathcal{C}_1(z_T) \right)} \leq C (M_T + M_T^2).
%\]
Choosing $p$ large enough, we obtain via Sobolev embedding that for any fixed $\alpha \in (0,1)$,
\begin{equation}\label{eq:lenya}
	[\mu]_{C^{1+\alpha}(B_1(x_{\max}, \theta_{\max}))} \leq C\|\mu\|_{W^2_p(B_1(x_{\max}, \theta_{\max}))}
		\leq C M_{a,b}^2.
\end{equation}
Applying the Gagliardo-Nirenberg interpolation inequality for the function $\theta \mapsto \mu \left( x_{\max}, \theta \right)$ yields
\begin{equation*}
	\| \mu \left( x_{\max}, \cdot \right) \|_{L^\infty_\theta\left((\theta_{\max}-1,\theta_{\max}+1)\right)}
		\leq C \| \mu \left( x_{\max}, \cdot \right) \|_{L^1_\theta\left((\theta_{\max}-1,\theta_{\max}+1)\right)}^{\frac{1+\alpha}{2+\alpha}}
			\left[ \mu \left( x_{\max}, \cdot \right) \right]_{C^{1+\alpha}_\theta\left((\theta_{\max}-1,\theta_{\max}+1)\right)}^{\frac{1}{2+\alpha}}.
\end{equation*}
Using~\eqref{eq:lenya}, $\| \mu \left(x_{\max}, \cdot \right) \|_{L^\infty_\theta\left((\theta_{\max}-1,\theta_{\max}+1)\right)} = M_{a,b}$, and $\| \mu \left( x_{\max}, \cdot \right) \|_{L^1_\theta\left((\theta_{\max}-1,\theta_{\max}+1\right)} \leq \nu(x_{\max})$, we obtain that
\begin{equation}\label{eq:lenya1}
	M_{a,b}
		\leq C \nu(x_{\max})^{\frac{1+\alpha}{2+\alpha}}
			M_{a,b}^{\frac{2}{2+\alpha}}.
\end{equation}
Since $(x_{\max}, \theta_{\max})$ is the location of a maximum, then at this point we have that
\begin{equation}\label{eq:maximum_principal}
	0 \leq -c\mu_x - d^\tau \mu_{xx} - \mu_{\theta\theta}
		= \mu(1 - m - \nu).
\end{equation}
Thus, $\nu(x_{\max}) \leq 1$.  Using this along with~\eqref{eq:lenya1}, we obtain $M_{a,b} \leq C M_{a,b}^{\frac{2}{2+\alpha}}$.
%\begin{equation*}
%	M_{a,b} \leq C \left(M_{a,b} + M_{a,b}^2 \right)^{\frac{1}{2+\alpha}}.
%\end{equation*}
This gives a bound on $M_{a,b}$ since $2/(2+\alpha) < 1$.
\end{proof}


%%
%%The proof of the lemma goes as follows. We define $K_0(a,b) = \max_{\overline{\Gamma}_{a,b}} \mu$ and want to prove that $K_0(a,b)$ is in fact bounded uniformly in $a$ and $b$. A first step is to prove successively that $\mu$ and $\partial_{\theta} \mu$ are bounded uniformly in $\mathrm{H}^1\left( (-a,a) \times (\underline\theta, \underline\theta + b) \right)$. In a second step, we use a suitable trace inequality to deduce a uniform $\mathrm{L}^\infty\left( (-a,a) \times (\underline\theta, \underline\theta + b) \right)$ estimate on $\mu$. 
%%
%%Let us recall that the maximum principle applied to \eqref{eq:slab} implies only that $\nu(\xi_0) \leq 1$ if $\left( \xi_0 , \theta_0 \right)$ is a maximum point for $\mu$, and this does not imply directly that $\max_{\overline{\Gamma}_{a,b}} \mu \leq 1$. However, we can control $\mu(\xi_0,\theta_0)$ by the non local term $\nu(\xi_0)$ provided some regularity of $\mu$ in the direction $\theta$.
%%
%%\quad
%%
%%{\bf \# Step 0: Preliminary observations.}
%%
%%\quad
%%
%%Denote by $(\xi_0,\theta_0) \in \overline{\Gamma}_{a,b}$ a point where the maximum of $\mu$ is reached. If the maximum is attained on the $\xi-$boundary $\xi_0 = a$ then $K_0(a,b) \leq \max_{(\underline\theta, \underline\theta + b)} Q_b$, the latter quantity begin uniformly bounded in $b$. Moreover, since since $\mu$ cannot be identically zero, $\theta_0$ cannot lie on a boundary where $\mu$ satisfies a Dirichlet boundary condition. If it is attained on a $\theta-$boundary where the first derivative $\partial_\theta \mu$ vanishes thanks to the boundary condition, since then tangential derivative $\partial_\xi \mu$ necessarily vanishes also, we have $\partial_{\theta\theta} \mu(\xi_0,\theta_0)\leq 0$ and $\partial_{\xi\xi} \mu(\xi_0,\theta_0)\leq 0$. The same holds true if $(\xi_0,\theta_0) \in (-a,a) \times (\underline\theta, \underline\theta + b)$ is an interior point. Evaluating equation \eqref{eq:slab} at $(\xi_0,\theta_0)$ implies
%%\begin{equation*}
%%K_0(a,b) \left(1 - m(\theta_0) - \int_{(\underline\theta, \underline\theta + b)} \mu(\xi_0,\theta) d\theta \right)\geq 0\,,
%%\end{equation*}
%%and therefore both $\int_{(\underline\theta, \underline\theta + b)} \mu(\xi_0,\theta) d\theta \leq 1$ and $m(\theta_0) \leq 1$. This bounds $\theta_0$ uniformly in $b$, by, say, $\hat \theta$. 
%%
%%\quad
%%
%%{\bf \# Step 1: Energy estimates on $\mu$.}
%%
%%\quad
%%
%%
%%We derive local energy estimates.
%%%The required estimate can be expressed, roughly speaking, as follows, 
%%%\[ K_0 \leq \dfrac{\nu(x_0)}{\text{regularity of $n_\theta$}}\, . \]
%%We introduce a smooth cut-off function $\chi: \R \times \Theta \to [0,1]$ such that
%%\begin{equation*}
%%\begin{cases}
%%\chi = 1 \qquad \text{on} \qquad J_1 = \left( \xi_0 - \frac12,\xi_0 + \frac12 \right) \times \left( \underline \theta , \hat \theta + \frac12\right),  \medskip\\
%%\chi = 0 \qquad \text{outside} \qquad  J_2 = \left[\xi_0 - 1,\xi_0 + 1\right] \times \left[ \underline \theta , \hat \theta + 1\right]. 
%%\end{cases}
%%\end{equation*} 
%%Notice that the support of the cut-off function does not necessarily avoid the $\xi-$boundary. We need to cut also in the direction $\theta$. We also introduce the following space linear corrector to deal with the non-homogeneous Dirichlet boundary condition in $x=-a$:
%%\begin{equation*}
%%\forall (\xi,\theta) \in \overline{\Gamma}_{a,b}, \qquad l(\xi,\theta) = \frac{a - \xi}{2a} Q_b(\theta) ,
%%\end{equation*}
%%which is defined such that $l(-a,\cdot) = Q_b$, $l(a) = 0$ and $0\leq l \leq Q_b$ on $(-a,a)$. 
%%
%%
%%Testing against $(\mu - l)\chi$ over $(-a,a) \times (\underline\theta, \underline\theta + b)$, we get
%%\begin{multline*}
%%- c \int_{(-a,a) \times (\underline\theta, \underline\theta + b)} (\mu - l) \chi \mu_{\xi} \; d\xi d\theta -\int_{(-a,a) \times (\underline\theta, \underline\theta + b)} d^\tau \chi  (\mu - l)(\mu - l)_{\xi\xi} \, d\xi d\theta \\- \int_{(-a,a) \times (\underline\theta, \underline\theta + b)} (\mu-l)\chi \mu_{\theta\theta} \, d\xi d\theta =\int_{(-a,a) \times (\underline\theta, \underline\theta + b)}   \mu ( 1 - m - \nu )( \mu-l)\chi\, d\xi d\theta.
%%\end{multline*}
%%We now transform each term of the l.h.s. by integration by parts. We emphasize that the corrections $m$ and $\chi$ ensure that all the boundary terms vanish. We get 
%%
%%\begin{multline*}
%%c \int_{(-a,a) \times (\underline\theta, \underline\theta + b)} \frac12 (\mu-l)^2 \chi_\xi  d\xi d\theta  +  \frac{c}{2a} \int_{(-a,a) \times (\underline\theta, \underline\theta + b)} (\mu-l) Q_b  \chi d\xi d\theta \\ + \int_{(-a,a) \times (\underline\theta, \underline\theta + b)} d^\tau \left|(\mu -l)_\xi\right|^2 \chi\, d\xi d\theta -  \frac12 \int_{(-a,a) \times (\underline\theta, \underline\theta + b)} d^\tau  \vert \mu-l \vert^2 \chi_{\xi \xi}\, d\xi d\theta \\ - \int_{(-a,a) \times (\underline\theta, \underline\theta + b)} (\mu - l) \chi l_{\theta \theta}  \, d\xi d\theta  
%%+ \int_{(-a,a) \times (\underline\theta, \underline\theta + b)} \left| \left( \mu - l \right)_{\theta} \right|^2 \chi  \, d\xi d\theta - \int_{(-a,a) \times (\underline\theta, \underline\theta + b)} \frac{1}{2} \left| \mu - l \right|^2 \chi_{\theta \theta}  \, d\xi d\theta  \\ \leq   \int_{(-a,a) \times (\underline\theta, \underline\theta + b)} (\mu-l)^2 ( 1 - m - \nu ) \chi\, d\xi d\theta + \int_{(-a,a) \times (\underline\theta, \underline\theta + b)}  ( 1 - m - \nu )( \mu- l ) l\chi\, d\xi d\theta .
%%\end{multline*}
%%To proceed further, we first use the following identity coming from the definition of $Q_b$ \eqref{eq:specQ} to simplify the latter:
%%\begin{equation*}
%%\int_{(-a,a) \times (\underline\theta, \underline\theta + b)} (\mu - l) \chi l_{\theta \theta}  \, d\xi d\theta + \int_{(-a,a) \times (\underline\theta, \underline\theta + b)}  ( \mu- l ) \chi ( 1 - m - \nu ) l\, d\xi d\theta = \int_{(-a,a) \times (\underline\theta, \underline\theta + b)}  ( \mu- l ) \chi ( \nu_{Q_b} - \nu ) l\, d\xi d\theta.
%%\end{equation*}
%%Then, we also gather the terms with $(\mu-l)^2$ and simplify a nonpositive term:
%%\begin{multline*}
%%-\int_{(-a,a) \times (\underline\theta, \underline\theta + b)} \frac{c}{2} \vert \mu-l\vert^2 \chi_\xi d\xi d\theta + \int_{(-a,a) \times (\underline\theta, \underline\theta + b)} \frac{d^\tau}2 \vert \mu-l\vert^2 \chi_{\xi \xi}\, d\xi d\theta \\+ \int_{(-a,a) \times (\underline\theta, \underline\theta + b)} \vert \mu-l\vert^2 ( 1 - m - \nu )\chi\, d\xi d\theta + \int_{(-a,a) \times (\underline\theta, \underline\theta + b)} \frac{1}{2} \left| \mu - l \right|^2 \chi_{\theta \theta}  \, d\xi d\theta \\ \leq    \int_{(-a,a) \times (\underline\theta, \underline\theta + b)} \vert \mu-l \vert^2 A(\xi,\theta) \, d\xi d\theta.
%%\end{multline*}
%%where 
%%\begin{equation*}
%%A(\xi,\theta) :=  - \frac{c}{2} \chi_\xi  + \frac{d^\tau}2  \chi_{\xi \xi} + \frac{1}{2} \chi_{\theta\theta } +   ( 1 - m ) \chi.
%%\end{equation*}
%%Thanks to the structure of the functions, we  have $\supp(A) \subset J_2$, and on $J_2$:
%%\begin{equation*}
%%A(\xi,\theta)  \leq C(c,\chi),  
%%\end{equation*}
%%uniformly in $\theta$. We now reorganize 
%%\begin{multline*}
%% \int_{(-a,a) \times (\underline\theta, \underline\theta + b)} \left| \left( \mu - l \right)_{\theta} \right|^2 \chi  \, d\xi d\theta  + \int_{(-a,a) \times (\underline\theta, \underline\theta + b)} d^\tau \left|(\mu -l)_\xi\right|^2 \chi\, d\xi d\theta \\ \leq  -  \frac{c}{2a} \int_{(-a,a) \times (\underline\theta, \underline\theta + b)} (\mu-l) Q_b  \chi d\xi d\theta + \int_{(-a,a) \times (\underline\theta, \underline\theta + b)} \left| \mu - l \right|^2 A(\xi,\theta) \, d\xi d\theta + \int_{(-a,a) \times (\underline\theta, \underline\theta + b)}  ( \nu_{Q_b} - \nu )( \mu- l ) l\chi\, d\xi d\theta .
%%\end{multline*}
%%In the l.h.s, we use the pointwise inequalities 
%%\begin{equation*}
%%|(\mu - l )_{\xi}|^2 \geq \frac12 \vert \mu_{\xi} \vert^2 - \vert l_\xi \vert^2, \qquad |(\mu - l )_{\theta}|^2 \geq \frac12 \vert \mu_\theta\vert^2 - \vert l_\xi \vert^2,
%%\end{equation*}
%%and we reshape the r.h.s using the pointwise inequality $\vert \mu - l \vert^2 \leq 2 \left( \mu^2 + l^2 \right)$, to get
%%\begin{multline*}
%%\int_{J_1} \frac{\underline \theta}{2}  \left|\mu_\xi\right|^2  \, d\xi d\theta + \int_{J_1} \frac{1}{2} \left|\mu_\theta\right|^2  \, d\xi d\theta \leq  \int_{J_2} 2 A  \left( \mu^2 + l^2 \right) d\xi d\theta  -  \frac{c}{2a} \int_{J_2} (\mu-l) Q_b d\xi d\theta \\ + \underline\theta \int_{J_1}  \left| l_\xi \right|^2 \, d\xi d\theta + \int_{J_1}  \left| l_\theta \right|^2 \, d\xi d\theta +\int_{J_2} l  \left(\nu_{Q_b} \mu + \nu l\right)  \, d\xi d\theta
%%\end{multline*}
%%%Now reshaping  $d^\tau(\theta) \geq d_{\text{min}}$, $\vert c \vert \leq c^*$, $\mu \leq K_0(a,b)$:
%%%\begin{multline*}
%%%\int_{J_1} \frac{d_{\text{min}}}{2}  \left|\partial_\xi\mu\right|^2  \, d\xi d\theta + \int_{J_1} \frac{\alpha}{2} \left|\partial_{\theta} \mu \right|^2  \, d\xi d\theta \leq  \int_{J_2} 2 \left( \frac{c}{2} \Vert \partial_\xi \chi \Vert_\infty + C(\chi) \right)  \left( \mu^2 + m^2 \right) d\xi d\theta  +  \frac{c^*}{2a} \int_{J_2} \Gamma_b(\theta)  K_0(a,b) d\xi d\theta \\ + d_{\min} \int_{J_1}  \left| \partial_\xi m \right|^2 \, d\xi d\theta + \alpha \int_{J_1}  \left| \partial_\theta m \right|^2 \, d\xi d\theta \\+ \int_{J_2} \alpha \left( \mu^2 + m^2 \right) \Vert \partial_{\theta \theta} \chi \Vert_\infty \, d\xi d\theta+ \int_{J_2}  r \Gamma_b(\theta)  \left(\rho_{\Gamma_b} K_0(a,b) + \Gamma_b(\theta) \rho_b \right)  \, d\xi d\theta
%%%\end{multline*}
%%We now use that $\mu \leq K_0(a,b)$, $\nu \leq \rho_{Q_b} K_0(a,b)$, $0 \leq c \leq c^* + 1$, $l_\xi = - Q_b/2a$, $l \leq Q_b$, $l_\theta = (\xi - a)Q_b'/2a$ to get
%%%\begin{multline*}
%%%\int_{J_1} \frac{\underline \theta}{2}  \left|\mu_\xi\right|^2  \, d\xi d\theta + \int_{J_1} \frac{1}{2} \left|\mu_\theta\right|^2  \, d\xi d\theta \leq  \int_{J_2} 2 A  \left( \mu^2 + l^2 \right) d\xi d\theta  -  \frac{c}{2a} \int_{J_2} (\mu-l) Q_b d\xi d\theta \\ + \underline\theta \int_{J_1}  \left| l_\xi \right|^2 \, d\xi d\theta + \int_{J_1}  \left| l_\theta \right|^2 \, d\xi d\theta +\int_{J_2} l  \left(\gamma_\infty \mu + \nu l\right)  \, d\xi d\theta
%%%\end{multline*}
%%%\begin{multline*}
%%%\theta_{\min}\int_{J_1 \times \Theta}  \left|\partial_{\xi} \mu-m'\right|^2 \, d\xi d\theta + \int_{J_1 \times \Theta} \alpha \left|\partial_{\theta} \mu\right|^2   \, d\xi d\theta \\ \leq c^* \frac{\vert \Theta \vert^{-1}}{2a} K_0 \vert J_2 \times \Theta \vert  - c \int_{[-a,a] \times \Theta} \frac12 (\mu-m)^2 \chi' d\xi d\theta \\+ \frac12\int_{(-a,a) \times \Theta} g_\tau(\theta) (\mu-m)^2    \chi''\, d\xi d\theta + \int_{J_2 \times \Theta}  r K_0^2 \, d\xi d\theta +   \int_{J_2 \times \Theta} r K_0^2 \, d\xi d\theta\,,
%%%\end{multline*}
%%%Then we use the pointwise inequality $| \partial_{\xi} \mu - m_\xi |^2 \geq \partial_{\xi} \mu^2/2 - m_\xi^2$ in the first integral of the l.h.s.:
%%%\begin{multline*}\label{testn2}
%%%\frac{\theta_{\min}}2\int_{J_1}  \left|\partial_{\xi} \mu\right|^2 \, d\xi d\theta + \int_{J_1} \alpha \left|\partial_{\theta} \mu\right|^2 \, d\xi d\theta   \leq \frac{K_0 c^*}{a}  + \theta_{\min} \int_{J_1}  \left|m'\right|^2 \, d\xi d\theta \\\ + \int g_{\tau}(\theta)\left( \mu^2 + m^2 \right)    \chi''\, d\xi d\theta + c^* \int  \left( \mu^2 + m^2 \right) \chi' d\xi d\theta +    4 r\vert \Theta \vert K_0^2. 
%%%\end{multline*}
%%%But, we  have, 
%%%\begin{equation*}
%%% \int g_{\tau}(\theta)\left( \mu^2 + m^2 \right)    \chi_{\xi\xi}\, d\xi d\theta + c^* \int  \left( \mu^2 + m^2 \right) \chi_\xi d\xi d\theta \leq 2 \vert \Theta \vert \left( \theta_{max} \Vert  \chi_{\xi\xi} \Vert_{\infty} + c^* \Vert  \chi_{\xi} \Vert_{\infty}\right) \left( \vert \Theta \vert^{-2} + K_0^2 \right).
%%% \end{equation*}
%%our first energy estimate: $\mu \in H^1\left( J_1 \right)$ with a bound of order $\mathcal{O}\left( K_0(a,b)^2 \right)$ as soon as $a >1$ and $b > \hat\theta +1$:
%%\begin{equation}\label{nH1}
%%\Vert \mu \Vert_{H_{x,\theta}^1\left( J_1 \right)} \leq    C(\chi)\left( 1 + K_0(a,b)^2\right)\,,
%%\end{equation}
%%%\begin{align*}\label{testn}
%%%\dfrac{\theta_{\min}}2\int_{J_1}  \left|n_{x}\right|^2 \, dxd\theta + \int_{J_1} \left|n_\theta\right|^2 \, dxd\theta  & \leq    4\Theta   K_0^2 + \theta_{\min} \int_{J_1}  \left|m_{x}\right|^2 \, dxd\theta + \dfrac12\int \theta\left( n^2 + m^2 \right)    \chi_{\xi\xi}\, dxd\theta     \\
%%%\dfrac{\theta_{\min}}2\int_{J_1}  \left|n_{x}\right|^2 \, dxd\theta + \int_{J_1} \left|n_\theta\right|^2 \, dxd\theta   \leq    4\Theta   K_0^2 + \theta_{\min} \int_{J_1}  \left|m_{x}\right|^2 \, dxd\theta + \dfrac12\int \theta\left( n^2 + m^2 \right)    \chi_{\xi\xi}\, dxd\theta \\ - c \int \chi_x \frac12 \left( n - m \right)^2 dx d\theta + c \frac{\Theta^{-1}}{2a} \int \chi (n-m) dx d\theta \\
%%%\min\left( \dfrac{\theta_{\min}}2 , 1\right)\int_{J_1}  \left(\left|n_{x}\right|^2 +   \left|n_\theta\right|^2\right) \, dxd\theta    & \leq    C(\Theta,\theta_{\min},\chi,a)\left( 1 + K_0^2\right)\, .
%%%\end{align*}
%%as soon as $a \geq \frac{1}{2}$. 
%%%Notice that the dependence upon the length of the slab is very weak, since it appears only through $m_x = \Theta^{-1}/2a \leq \Theta^{-1}$ for $a\geq 1/2$. 
%%
%%We now come to the proof that $\mu_\theta$ is also in $H^1$. We differentiate \eqref{eq:slab} with respect to $\theta$ for this purpose. Here, we use crucially that $\nu$ is a function of the variable $\xi$ only. 
%%\begin{equation} \label{eq:n_theta}
%%\forall (\xi,\theta) \in (-a,a) \times (\underline\theta, \underline\theta + b), \qquad - c \mu_{\xi\theta} - d^\tau' \mu_{\xi\xi} - d^\tau \mu_{\xi\xi\theta} - \mu_{\theta\theta\theta} = \mu_\theta (1 - m - \nu) - \mu m'(\theta)\, .
%%\end{equation}
%%We use the cut-off function $\widetilde \chi(\xi)$ defined by
%%\begin{equation*}
%%\begin{cases}
%%\widetilde \chi = 1 \qquad \text{on} \qquad J_3 = \left( \xi_0 - \frac14,\xi_0 + \frac14 \right) \times \left( \underline \theta , \hat \theta + \frac14\right),  \medskip\\
%%\widetilde \chi = 0 \qquad \text{outside} \qquad  J_2. 
%%\end{cases}
%%\end{equation*} 
%%Multiplying \eqref{eq:n_theta} by $ \widetilde \chi \left( \mu - l \right)_\theta $, we get after integration by parts
%%%\begin{multline*}
%%%\int n_x n_{\theta x} \widetilde \chi  \, dxd\theta + \int n_x n_{\theta } \widetilde \chi_x  \, dxd\theta + \int \theta n_{x\theta} n_\theta \widetilde \chi_x  \, dxd\theta \\ + \int \theta \left|n_{x\theta}\right|^2 \widetilde \chi  \, dxd\theta  +  \int   \left|n_{\theta\theta}\right|^2 \widetilde \chi  \, dxd\theta \leq \int   \left|n_{ \theta}\right|^2 \widetilde \chi  \, dxd\theta\, .
%%%\end{multline*}
%%\begin{multline*}\label{testntheta2}
%%\int_{(-a,a) \times (\underline\theta, \underline\theta + b)} \frac{c}{2} \widetilde \chi_\xi \vert (\mu - l)_\theta \vert^2  \, d\xi d\theta - \int_{(-a,a) \times (\underline\theta, \underline\theta + b)} c \,l_{\xi\theta} \widetilde \chi (\mu - l)_\theta \, d\xi d\theta \\+ \int_{(-a,a) \times (\underline\theta, \underline\theta + b)} d^\tau' \widetilde \chi \left( \mu  - l  \right)_\xi \left( \mu  - l \right)_{\xi \theta}  \, d\xi d\theta + \int_{(-a,a) \times (\underline\theta, \underline\theta + b)}  d^\tau' \widetilde \chi_\xi \left( \mu - l  \right)_\xi   \left( \mu - l \right)_{\theta}  \, \, d\xi d\theta 
%%\\+ \int_{(-a,a) \times (\underline\theta, \underline\theta + b)} d^\tau \widetilde \chi  \left\vert  \left( \mu - l \right)_{\xi \theta} \right\vert^2 \, d\xi d\theta - \int_{(-a,a) \times (\underline\theta, \underline\theta + b)} d^\tau \frac12 \left\vert (\mu - l )_\theta \right\vert^2 \widetilde \chi_{\xi \xi}    \, d\xi d\theta \\  
%%+  \int_{(-a,a) \times (\underline\theta, \underline\theta + b)}   \left|(\mu - l)_{\theta\theta} \right|^2 \widetilde \chi  \, d\xi d\theta -  \frac{1}{2} \int_{(-a,a) \times (\underline\theta, \underline\theta + b)}   \left|(\mu - l)_{\theta} \right|^2 \widetilde \chi_{\theta \theta}  \, d\xi d\theta
%%- \int_{(-a,a) \times (\underline\theta, \underline\theta + b)}  (\mu-l)_{\theta}  l_{\theta \theta \theta} \widetilde \chi \, d\xi d\theta \\ =  \int_{(-a,a) \times (\underline\theta, \underline\theta + b)} \left\vert \left( \mu  - l \right)_{\theta} \right\vert^2 ( 1 - m - \nu ) \widetilde \chi  \, d\xi d\theta + \int_{(-a,a) \times (\underline\theta, \underline\theta + b)} l_\theta \left( \mu  - l \right)_{\theta}  ( 1 - m -\nu ) \widetilde \chi   \, d\xi d\theta  \\ - \int_{(-a,a) \times (\underline\theta, \underline\theta + b)}  (\mu - l) \left( \mu - l \right)_{\theta}  m' \widetilde \chi    \, d\xi d\theta  - \int_{(-a,a) \times (\underline\theta, \underline\theta + b)} \left( \mu - l \right)_{\theta}  l m'  \widetilde \chi   \, d\xi d\theta 
%%\end{multline*}
%%Notice that all the boundary terms vanish since $\left(\mu - l \right)_\theta = 0$ on all segments of the boundary and $\widetilde \chi (\underline\theta + b) = \widetilde \chi_\theta (\underline\theta + b)  = 0$. We gather some terms again thanks to the definition of $Q$:
%%\begin{multline*}
%%- \int_{(-a,a) \times (\underline\theta, \underline\theta + b)}  \left( \mu - l  \right)_\theta  l m' \widetilde \chi   \, d\xi d\theta + \int_{(-a,a) \times (\underline\theta, \underline\theta + b)} (\mu - l)_{\theta} m''' \widetilde \chi \, d\xi d\theta + \int_{(-a,a) \times (\underline\theta, \underline\theta + b)}  \left( \mu  - l \right)_{\theta}  ( 1 - m - \nu ) \widetilde \chi  l_\theta  \, d\xi d\theta \\ = \int_{(-a,a) \times (\underline\theta, \underline\theta + b)}  \left( \mu - l \right)_{\theta} l_\theta ( \nu_{Q_b} - \nu)  \widetilde \chi  \, d\xi d\theta
%%\end{multline*}
%%We find
%%\begin{multline*}
%%\int_{(-a,a) \times (\underline\theta, \underline\theta + b)} d^\tau \widetilde \chi  \left\vert  \left( \mu - l \right)_{\xi \theta} \right\vert^2 \, d\xi d\theta +  \int_{(-a,a) \times (\underline\theta, \underline\theta + b)}   \left|(\mu - l)_{\theta\theta} \right|^2 \widetilde \chi  \, d\xi d\theta + \int_{(-a,a) \times (\underline\theta, \underline\theta + b)} d^\tau' \widetilde \chi \left( \mu  - l  \right)_\xi \left( \mu  - l \right)_{\xi \theta}  \, d\xi d\theta \\+ \int_{(-a,a) \times (\underline\theta, \underline\theta + b)}  d^\tau' \widetilde \chi_\xi \left( \mu - l  \right)_\xi   \left( \mu - l \right)_{\theta}  \, \, d\xi d\theta = \int_{(-a,a) \times (\underline\theta, \underline\theta + b)} d^\tau \frac12 \left\vert (\mu - l )_\theta \right\vert^2 \widetilde \chi_{\xi \xi}    \, d\xi d\theta + \frac{1}{2} \int_{(-a,a) \times (\underline\theta, \underline\theta + b)}   \left|(\mu - l)_{\theta} \right|^2 \widetilde \chi_{\theta \theta}  \, d\xi d\theta \\-\int_{(-a,a) \times (\underline\theta, \underline\theta + b)} \frac{c}{2} \widetilde \chi_\xi \vert (\mu - l)_\theta \vert^2  \, d\xi d\theta + \int_{(-a,a) \times (\underline\theta, \underline\theta + b)} c \,l_{\xi\theta} \widetilde \chi (\mu - l)_\theta \, d\xi d\theta +\int_{(-a,a) \times (\underline\theta, \underline\theta + b)} \left\vert \left( \mu  - l \right)_{\theta} \right\vert^2 ( 1 - m - \nu ) \widetilde \chi  \, d\xi d\theta\\ + \int_{(-a,a) \times (\underline\theta, \underline\theta + b)} l_\theta \left( \mu  - l \right)_{\theta}  ( \nu_{Q_b} -\nu ) \widetilde \chi   \, d\xi d\theta - \int_{(-a,a) \times (\underline\theta, \underline\theta + b)}  (\mu - l) \left( \mu - l \right)_{\theta}  m' \widetilde \chi    \, d\xi d\theta 
%%\end{multline*}
%%
%%One can split the third term of the l.h.s. to control it with the $H^1(J_2)$ bound on $\mu$ and the first term of the $l.h.s.$. All the other terms are estimable using the $H^1(J_2)$ estimate \eqref{nH1} obtained previously for $\mu$. 
%%%\begin{multline*}
%%%\int_{(-a,a) \times (\underline\theta, \underline\theta + b)} d(\theta) \widetilde \chi  \left\vert  \partial_{\xi \theta} \left( n - m \right) \right\vert^2 \, d\xi d\theta +  \alpha \int_{(-a,a) \times (\underline\theta, \underline\theta + b)}   \left|\partial_{\theta\theta} (\mu - m)\right|^2 \widetilde \chi  \, d\xi d\theta 
%%%+ \int_{(-a,a) \times (\underline\theta, \underline\theta + b)} d'(\theta) \widetilde \chi \partial_\xi \left( n  - m  \right) \partial_{\theta\xi} \left( n  - m \right)  \, d\xi d\theta   
%%%   \\ =  \frac{\alpha}{2} \int_{(-a,a) \times (\underline\theta, \underline\theta + b)}   \left|\partial_{\theta} (\mu - m)\right|^2 \widetilde \chi_{\theta \theta}  \, d\xi d\theta -\int_{(-a,a) \times (\underline\theta, \underline\theta + b)}  d'(\theta) \widetilde \chi_\xi \partial_\xi \left( n  - m  \right) \partial_{\theta} \left( n  - m \right)  \, \, d\xi d\theta \\+ \int_{(-a,a) \times (\underline\theta, \underline\theta + b)} \widetilde \chi_{\xi \xi} \frac12 \left( \partial_\theta (n - m ) \right)^2    \, d\xi d\theta - \int_{(-a,a) \times (\underline\theta, \underline\theta + b)} \frac{c}{2} \widetilde \chi_\xi \left( \partial_\theta (n - m ) \right)^2  \, d\xi d\theta \\- \int_{(-a,a) \times (\underline\theta, \underline\theta + b)} \frac{c}{2a} \widetilde \chi \Gamma_b(\theta) \partial_\theta (n - m ) \, d\xi d\theta + \int_{(-a,a) \times (\underline\theta, \underline\theta + b)} r  \widetilde \chi  \left( \partial_{\theta} \left( n  - m \right) \right)^2 ( a(\theta) - \rho ) \, d\xi d\theta \\+ \int_{(-a,a) \times (\underline\theta, \underline\theta + b)} r  \widetilde \chi  m_\theta  \partial_{\theta} \left( n  - m \right)  ( \rho_{\Gamma_b}- \rho ) \, d\xi d\theta  + \int_{(-a,a) \times (\underline\theta, \underline\theta + b)} r  \widetilde \chi  (n-m) \partial_{\theta} \left( n  - m \right)  a'(\theta)   \, d\xi d\theta
%%%\end{multline*}
%%%\EB{We have one remaining term to be careful with due to some $a'(\theta)$ which is not bounded:
%%%\begin{multline*}
%%%\int_{(-a,a) \times (\underline\theta, \underline\theta + b)}  (\mu - l) \left( \mu - l \right)_{\theta}  m' \widetilde \chi    \, d\xi d\theta =  \int_{(-a,a) \times (\underline\theta, \underline\theta + b)} \frac{r}{2}  \widetilde \chi  \partial_{\theta} \left( (n  - m)^2 \right)  a'(\theta)   \, d\xi d\theta \\ = \int_{\xi} \frac{r}{2} \left[ (n-m)^2 \widetilde \chi a'(\theta) \right]_{\partial \Theta} d \xi - \int_{(-a,a) \times (\underline\theta, \underline\theta + b)} \widetilde \chi_\theta (n-m)^2 a'(\theta)    \, d\xi d\theta   - \int_{(-a,a) \times (\underline\theta, \underline\theta + b)} \widetilde \chi (n-m)^2 a''(\theta)    \, d\xi d\theta 
%%%\end{multline*}
%%%The boundary term is negative thanks to the concavity of $a(\theta)$. To control the last two terms we recall more precisely the first estimate: 
%%%\begin{multline*}
%%%\int_{J_1} \frac{d_{\text{min}}}{2}  \left|\partial_\xi\mu\right|^2  \, d\xi d\theta + \int_{J_1} \frac{\alpha}{2} \left|\partial_{\theta} \mu \right|^2  \, d\xi d\theta \\ \leq  C(\vert \Theta \vert,\theta_{\min},\chi)\left( 1 + K_0(a)^2\right) + \int_{(-a,a) \times (\underline\theta, \underline\theta + b)} ( \mu-m)^2 \left( - \frac{c}{2} \partial_\xi \chi + \frac12 d^\tau(\theta) \partial_{\xi \xi}\chi + r a(\theta) \chi \right) \, d\xi d\theta, 
%%%\end{multline*}
%%%so that the last integral controls the last previous two terms thanks to assumptions on $a(\theta)$. 
%%We deduce again that $\mu_{\theta}$ also belongs to $H^1\left( J_3 \right)$ with a bound of order $K_0(a,b)^2$.
%%
%%%\begin{multline*}
%%%\frac{\theta_{\min}}{2} \int_{J_{1/2}} \left \vert  \partial_{\theta \xi} \mu\right\vert^2   \, d\xi d\theta  + \alpha \int_{J_{1/2}}   \left \vert \partial_{\theta\theta} \mu\right \vert^2   \, d\xi d\theta \leq \left( r + \frac{c^*}{2} \Vert \widetilde\chi' \Vert_\infty \right)\int_{J_1}   \left \vert \partial_\theta\mu\right \vert^2    \, d\xi d\theta + \frac{1}{2\theta_{\min}} \int_{J_{1}}   \left\vert \partial_{\xi} \mu \right\vert^2  d\xi d\theta \\ + \frac12 \int_{J_1}\left( \left|\partial_{\xi} \mu \right|^2 + \left|\partial_{\theta} \mu\right|^2 \right) \left|\widetilde \chi' \right|  \, d\xi d\theta 
%%% + \frac12 \int \theta \left|\partial_{\theta} \mu\right|^2  \widetilde \chi'' \, d\xi d\theta
%%%\end{multline*}
%%%from which we conclude
%%%\begin{equation}\label{nthetaH1}
%%%\min\left( \dfrac{\theta_{\min}}2 , 1\right)\int_{J_1}  \left(\left|\partial_{\xi \theta} \mu\right|^2 +   \left|\partial_{\theta\theta} \mu\right|^2\right) \, d\xi d\theta  \leq    \overline{C}(\Theta,\theta_{\min},\chi)\left( 1 + K_0(a)^2\right)\, .
%%%\end{equation}
%%%\begin{equation}
%%%\leq  C\left(1 + K_0^2\right) +  \frac12 \int \theta  \left|n_{\theta}\right|^2    \widetilde \chi_{\xi\xi}  \, dxd\theta \\
%%%\leq  C\left(1 + K_0^2\right) \, .
%%%\end{equation}
%%%This crucial computation proves that $\partial_{\theta} \mu$ also belongs to $H^1\left( (-a,a) \times \Theta \right)$.
%%
%%\quad 
%%
%%{\bf \# Step 2: Improved regularity of the trace $\mu(\xi, \cdot )$.}
%%
%%\quad
%%
%%
%%We aim to control the regularity of the partial function  $\theta \mapsto \mu(\xi_0,\theta)$. For this purpose we use a trace embedding inequality with higher derivatives, namely if both $\mu$ and $\mu_\theta$ belongs to $H^1\left( J_3 \right)$, then the trace function $\mu(\xi_0,\cdot)$ belongs to $H_\theta^{3/2}(J_3)$. More precisely, there exists a constant $C_{tr}$ such that 
%%\begin{equation*}
%%\Vert \mu(\xi_0,\cdot) \Vert_{H^{3/2}_\theta(J_3)}^2 \leq C_{tr} \left(  \Vert \mu_\theta \Vert_{H^{1}_{x,\theta}(J_3)}^2 +  \Vert \mu \Vert_{H^{1}_{x,\theta}(J_3)}^2 \right)\, .
%%\end{equation*}
%%Combining the previous inequality with  estimates \# Step 1, we deduce that 
%%\begin{equation*}
%%\Vert \mu(\xi_0,\cdot) \Vert_{H^{3/2}_\theta(J_3)}^2 \leq C \left(1 + K_0(a,b)^2 \right)\,.
%%\end{equation*}
%%On the other hand, the  interpolation inequality \cite[Theorem 5.9, p.141]{Adams} gives a constant $C_{\text{int}}$ such that
%%\begin{equation*}
%%\|\mu\left( \xi_0, \cdot \right) \|_{L^\infty_\theta(J_3)} \leq C_{int} \| \mu\left( \xi_0, \cdot \right) \|_{L^1_\theta(J_3)}^{1/2} \| \mu\left( \xi_0, \cdot \right) \|_{H^{3/2}_\theta(J_3)}^{1/2}
%%\end{equation*}
%%We also have from \# Step 0 that $\Vert \mu(\xi_0,\cdot) \Vert_{L^1_\theta(J_3)} \leq  \Vert \mu(\xi_0,\cdot) \Vert_{L^1_\theta((\underline\theta, \underline\theta + b))} = \nu(\xi_0) \leq 1$. As a consequence, we obtain, since $\theta \in J_3$:
%%\begin{equation*}
%%K_0(a,b)^4 = \|\mu\left( \xi_0, \cdot \right) \|_{L^\infty_\theta((\underline\theta, \underline\theta + b))}^4 = \|\mu\left( \xi_0, \cdot \right) \|_{L^\infty_\theta(J_3)}^4 \leq C \left(1 + K_0(a,b)^2 \right)\, ,
%%\end{equation*}
%%for some constant $C$, depending only on $\underline \theta$, $\hat \theta$ and $\chi$. Therefore, $K_0(a,b)$ is bounded uniformly with respect to $a,b$. This concludes the proof of Lemma \ref{lem:nc}.
%%
%%\end{proof}
%%
\subsubsection*{Non-existence of solutions of the slab problem when $c=0$.}

%{\color{red} Can we not conclude this in some slick way using the extinction results?  If $c = 0$ then we have that the eigenvalue of the linearized operator has to be negative (I think?) then we just apply our lemma...}

\begin{lemma}[Lower bound for $\mu(0,\underline\theta)$ when $c=0$]\label{lem:bottom}
There exists $\underline\epsilon_0 > 0$ such that if $a$ and $b$ are large enough and $\tau\in[0,1]$, then any nonnegative solution of the slab problem $(0,\mu)$ satisfies $\mu(0,\underline\theta) > \underline\epsilon_0$. 
\end{lemma}

\begin{proof}%[{\bf Proof of Lemma \ref{lem:bottom}}]
The idea of the proof is to build a sub-solution.  Since the full problem does not enjoy the comparison principle, we use the Harnack inequality to compare with a local equation. 

For $r,s>0$, consider the following spectral problem in both variables $(\xi,\theta)$:
\begin{equation}\label{eq:evpb}
\begin{cases}
d \varphi_{\xi\xi}   +  \varphi_{\theta\theta}  + (1-m) \varphi   = \gamma_{r,s} \varphi \,, \qquad \text{ on } (-r,r) \times (\underline\theta, \underline\theta + s),\\
\varphi_\theta (\cdot,\underline\theta) = 0\,, \quad \varphi (\cdot,\underline\theta + s) = 0\,, \quad \varphi(\pm r,\cdot) = 0.
\end{cases}
\end{equation}
%
%By Krein-Rutman theory, $\gamma_{r,s}$ is the only eigenvalue such that there exists a positive eigenvector $\varphi$. One can rescale the problem in the space direction setting $\xi = r \zeta$:
%\begin{equation*}
%\left\{\begin{array}{ll}
%\dfrac{d^\tau}{r^2} \varphi_{\xi\xi}   +  \varphi_{\theta\theta}  + (1-m) \varphi   = \gamma_{r,s}\varphi, &\quad \text{on } \Gamma_{1,s},\medskip\\
%\varphi_\theta (\cdot,\underline\theta) = 0, &\medskip\\
%\varphi (\cdot,\underline\theta + s) = 0, &\medskip\\
%\varphi(-1,\theta) = 0, \quad \varphi(1,\theta)  = 0.
%\end{array}
%\right.
%\end{equation*}
The eigenvector (up to a multiplicative constant) $\varphi$ is given by 
\begin{equation*}
\forall (\xi,\theta) \in (-r,r) \times (\underline\theta, \underline\theta + s), \qquad \varphi(\xi,\theta)= \cos\Big( \frac{\pi}{2}\frac{\xi}{r}\Big) V_{r,s}(\theta),
\end{equation*}
where we have introduced the eigenelements $(\gamma_{r,s},V_{r,s})$ with normalization $\|V_{r,s}\|_\infty = 1$ by
\begin{equation*}
\begin{cases}
V_{r,s}''  + \big( - \frac{\pi^2}{4r^2} d - \gamma_{r,s} + (1-m) \big) V_{r,s}   = 0 \,, \quad \theta \in (\underline\theta, \underline\theta + s),\\
V_{r,s}'(\underline\theta) = 0, \quad V_{r,s}(\underline\theta + s) = 0, \quad V_{r,s} > 0.
\end{cases}
\end{equation*}
%\EB{STOPPED}
%One can prove that $\lim_{r \to +\infty} \gamma_{r,s} = \nu_{Q_s}$. One has, after differentiating the above with respect to $r$ and testing on $V_{r,s}$, 
%\begin{equation*}
%\frac{d \gamma_{r,s}}{dr} = \frac{\pi^2}{2 r^3} \frac{\int_{(\underline\theta,\underline\theta + s)} d^\tau V_{r,s}^2 d \theta}{\int_{(\underline\theta,\underline\theta + s)} V_{r,s}^2 d \theta}
%\end{equation*}
Since $\lim_{r\to\infty} V_{r,s} = Q_s$, then  $\lim_{s\to\infty}\lim_{r\to\infty} \gamma_{r,s} = \gamma_\infty$.
% exists and solves necessarily
%\begin{equation*}
%\left\{\begin{array}{l}
%V''  + \left( - \lim_{r \to +\infty} \gamma_{r,s} + (1-m) \right) V   = 0 \,, \qquad \theta \in (\underline\theta,\underline\theta + s) \, ,\medskip\\
%V > 0, \medskip\\
%V'(\underline\theta) = 0\,, \medskip\\
%V(\underline\theta + s) = 0.
%\end{array}
%\right.
%\end{equation*}
%and it yields necessarily that $V = Q_s$ and $ \lim_{r \to +\infty} \gamma_{r,s} = \nu_{Q_s}$. 
Thus we may fix %(once for all, independently of $\mu$)
$s$ and $r$ sufficiently large so that $\gamma_{r,s} > \gamma_\infty/2$.  Notice that we require $r \leq a$ and $s \leq b$ for $\varphi$ to be a sub-solution.

In order to compare $\varphi$ and $\mu$, we must first estimate $\nu$. We decompose it as follows 
\begin{equation*}
\nu = \int_{(\underline\theta, \underline\theta + s)} \mu(\cdot,\theta) d\theta + \int_{(\underline\theta + s, \underline\theta + b)} \mu(\cdot,\theta) d\theta, 
\end{equation*} 
and then estimate the two terms separately. 
First, due to the Harnack inequality %up to the boundary (see \cite{BouinCalvez} for a justification),
there exists a constant $C_{r,s}$, depending only on $r$ and $s$, such that
\begin{equation*}
C_{r,s} \mu(0,\underline\theta)
	\geq \sup_{(-r,r) \times (\underline\theta, \underline\theta + s)} \mu(\xi , \theta).
	%\geq \|\mu\|_{L^\infty\left((-r,r) \times (\underline\theta, \underline\theta + s)\right)}.
\end{equation*}
Moreover, due to \Cref{lem:tails}, 
\begin{equation*}
\int_{(\underline\theta + s, \underline\theta + b)} \mu(\cdot,\theta) d\theta \leq C_{tail} (1 + \|\mu\|_\infty)  \int_{(\underline\theta + s, +\infty)} Q_\infty^\delta(\theta) d\theta \leq \frac{\gamma_\infty}{4},
\end{equation*}
when $s$ is chosen sufficiently large. To compare \eqref{eq:slab} to \eqref{eq:evpb} on $(-r,r) \times (\underline\theta, \underline\theta + s)$, we write
\begin{equation*}
d \mu_{\xi\xi} + \mu_{\theta\theta} + (1-m) \mu = \mu \nu \leq \mu \left( C_{r,s} s \mu(0,\underline\theta) + \gamma_\infty/4 \right).
\end{equation*}
We deduce from this computation that if $\mu(0,\underline\theta)  \leq \gamma_\infty/(4C_{r,s} s)$, we have \begin{equation*}
\left( C_{r,s}s  \mu(0,\underline\theta) + \gamma_\infty/4  \right) \mu(\xi,\theta) < (\gamma_\infty/2) \mu(\xi,\theta) < \gamma_{r,s} \mu(\xi,\theta), \qquad \text{on } (-r,r) \times (\underline\theta, \underline\theta + s).
\end{equation*}
Hence, if $\mu(0,\underline\theta) \leq \gamma_\infty/(4C_{r,s}s)$, then $\mu$ is a super-solution of \eqref{eq:evpb}.  If $\mu(0,\underline\theta) \leq \gamma_\infty/(4C_{r,s}s)$ does not hold, we are finished.  As such, we assume that it does not for the sake of contradiction.


We now use the same arguments as in the proof of \Cref{lem:upboundc}. Indeed, we define
\begin{equation*}
\alpha_0 = \max \left\lbrace \alpha \in \R^+ \, : \, \alpha \varphi < \mu \text{ on } [-r,r] \times [\underline\theta, \underline\theta + s]  \right\rbrace,
\end{equation*}
so that $u:= \mu - \alpha_0 \varphi$ has a zero minimum at some $(\xi_0,\theta_0) \in [-r,r] \times [\underline\theta, \underline\theta + s]$ and satisfies 
\begin{equation*}
\begin{cases}
d u_{\xi\xi} + u_{\theta\theta} + (1-m) u  < \gamma_{r,s} u,& \quad \text{on } (-r,r) \times (\underline\theta, \underline\theta + s),\\
u_\theta (\cdot,\underline\theta) = 0, \quad u(\cdot,\underline\theta + s) > 0, \quad u(-r,\cdot) > 0, \quad u(r,\cdot)  > 0. \\
\end{cases}
\end{equation*}
As in Lemma \ref{lem:upboundc} this cannot hold. This contradiction implies that $\mu(0,\underline\theta) > \frac{\gamma_\infty}{4 s C_{r,s}}$.

\end{proof}


\subsubsection{The homotopy argument}\label{sec:homotopy}


\begin{proposition}[Existence of a solution in the slab]\label{slabsol}
There are positive constants $\underline\eps_0$ and $b_0$ such that if $\underline \eps < \underline\eps_0$ and $b > b_0$ then there exists $a_0(b,\underline\eps)$ such that if $a > a_0(b,\underline\eps)$ then the slab problem~\eqref{eq:slab} with the normalization condition $\mu_0(0,\underline \theta) = \underline\epsilon$ has a solution $(c,\mu)$.
%There exists $\eps_0 > 0$ such that for any $\underline\epsilon < \eps_0$, there exists $b_0 > 0$ such that for any $b \geq b_0$ there exists $a_0(b,\underline\epsilon) > 0$ such that for all $b \geq b_0$ and $a \geq a_0$, the slab problem \eqref{eq:slab}
%\begin{equation}
%\left\{\begin{array}{l}
%-c n_{x}(x,\theta) - \theta n_{\xi\xi}(x,\theta) - \alpha n_{\theta\theta}(x,\theta) = r n(x,\theta) (1 - \nu(x))\, , \quad \nu(x) = \int n(x,\theta)\, d\theta \, ,\medskip\\
%n_\theta(x,\theta_{\min}) = n_\theta(x,\theta_{\max}) = 0,\, \\
%n(-a,\theta) = \Theta^{-1}, \quad n(a,\theta)  = 0,\, \medskip\\
%\end{array}
%\right.
%\end{equation}
%with the normalization condition $\nu(0) = \epsilon$ has a solution $(c,\mu)$.
%\begin{equation*}
%\Vert \mu \Vert_{L^\infty \left( \overline{\Gamma}_{a,b} \right)}\leq C_0, \qquad c \in \left] \, 0 , c^{*} \, \right]. 
%\end{equation*}
\end{proposition}

\begin{proof}%[{\bf Proof of Proposition \ref{slabsol}}]
%We are now ready to perform a Leray Schauder topological degree argument \cite{}. 
%Given a non negative function $\mu$ satisfying the boundary conditions 
%\begin{equation}\label{boundv}
%\mu_{\theta} (\cdot, \underline \theta ) = 0, \qquad
%\mu (\cdot, \underline \theta + b ) = 0,\qquad 
%\mu(-a,\cdot) = Q_b, \qquad \mu(a,\cdot)  = 0.
%\end{equation}
Fix $\beta \in (0,1)$.  Given $\mu \in \mathcal{C}^{1,\beta}((-a,a) \times (\underline\theta, \underline\theta + b))$, we consider the problem%one-parameter family of problems:

\begin{equation}\label{eq:tauslab}
\begin{cases}
-c Z_\xi^\tau - d^\tau Z_{\xi\xi}^\tau - Z_{\theta\theta}^\tau =  \mu_+ (1 - m -  \nu_\mu),\qquad \text{on }  (-a,a) \times (\underline\theta, \underline\theta + b), \\
Z_\theta^\tau(\cdot,\underline \theta) = 0, \quad Z^\tau(\cdot, \underline \theta + b) = 0, \quad
Z^\tau(-a,\cdot) = Q_b, \quad Z^\tau(a,\cdot)  = 0.
\end{cases}
\end{equation}


Here we have introduced the notation $\nu_\mu$ to emphasize that it corresponds to the density associated to $\mu$ (\textit{i.e.} $\nu_\mu(\cdot) := \int_{(\underline\theta,\underline\theta + s)} \mu(\cdot,\theta) d\theta$) and not to $Z^\tau$.  We introduce the map 
\begin{equation*}
\mathcal{K}_{\tau}: (c,\mu) \to \left(\underline \epsilon - \mu(0,\underline \theta) + c , Z^{\tau} \right), 
\end{equation*}
where $Z_{\tau}$ is the solution of the previous linear system \eqref{eq:tauslab}. 
Since~\eqref{eq:tauslab} is elliptic the map $\mathcal{K}_{\tau}: X \to X$ is a compact map where $X := \mathbb{R} \times \mathcal{C}^{1,{\beta}} \left( (-a,a) \times (\underline\theta, \underline\theta + b)\right)$ with the norm $\Vert (c , \mu) \Vert := \max \left( \vert c \vert, \Vert \mu \Vert_{ \mathcal{C}^{1,\beta}} \right)$. Moreover, it depends continuously on the parameter $\tau \in \left[ 0 , 1 \right]$. Solving the problem %$P_{a,b}^1$
%The ellipticity of the system \eqref{eq:tauslab} gives that the map $\mathcal{K}_{\tau}: X \to X$ is a compact map where $X := \mathbb{R} \times \mathcal{C}^{1,{\beta}} \left( (-a,a) \times (\underline\theta, \underline\theta + b)\right)$ with the norm $\Vert (c , \mu) \Vert := \max \left( \vert c \vert, \Vert \mu \Vert_{ \mathcal{C}^{1,\beta}} \right)$. Moreover, it depends continuously on the parameter $\tau \in \left[ 0 , 1 \right]$. Solving the problem %$P_{a,b}^1$
\eqref{eq:slab} is equivalent to proving that the kernel of $\text{Id} - \mathcal{K}_1$ is non-trivial. We can now apply the Leray-Schauder theory. 

Fix $C_0$ from \Cref{lem:nc}, $\underline\epsilon < \underline\epsilon_0$, and $a > a_0(\underline\epsilon,b)$.  We define the open set
\begin{equation*}
\mathcal{B} = \left \lbrace (c,\mu) \; \vert \; 0 < c < c^* + 1, \; \Vert \mu \Vert_{\mathcal{C}^{1,\beta}\left( (-a,a) \times (\underline\theta, \underline\theta + b)\right)} < C_0 + 1 \right\rbrace.
\end{equation*} 
The a priori estimates of Lemmas \ref{lem:upboundc} and \ref{lem:nc}, give that for all $\tau \in \left[ 0 , 1\right]$ and sufficiently large $a$, the operator $ \text{Id}  - \mathcal{K}_{\tau}$ cannot vanish on the boundary of $\mathcal{B}$. 
%Indeed, if it vanishes on $\partial \mathcal{B}$, there exists a solution $(c,\mu)$ of \eqref{eq:slab} which also satisfies $c \in \left\lbrace 0, c^{*} + 1 \right\rbrace$ or $\Vert \mu \Vert_{\mathcal{C}^{1,\beta}\left( (-a,a) \times (\underline\theta, \underline\theta + b) \right)} = C_0 + 1$ and $\mu(0,\underline\theta) = \eps$. But this is ruled out by the condition $\eps < \eps_0$, due to Lemmas \ref{lem:upboundc}, \ref{lem:nc} and \ref{lem:bottom}.
The Leray-Schauder degree theory yields the homotopy invariance
\begin{equation*}
%\forall \tau \in \left[ 0 ,1 \right], \quad
	\text{deg}\left( \text{Id} - \mathcal{K}_{1} , \mathcal{B} , 0 \right) 
		%= \text{deg}\left( \text{Id} - \mathcal{K}_{\tau} , \mathcal{B} , 0 \right)
		= \text{deg}\left(  \text{Id} - \mathcal{K}_{0} , \mathcal{B} , 0 \right).
\end{equation*}
To compute $\text{deg}\left(  \text{Id} - \mathcal{K}_{0} , \mathcal{B} , 0 \right)$, we investigate the problem corresponding to $\tau = 0$.
% This problem is 
%\begin{equation*}
% \left\{\begin{array}{ll}
%-c Z_\xi ^0 - \underline\theta Z_{\xi\xi}^0  - Z_{\theta\theta}^0 = \mu_+ \left(1 - m - \nu_\mu\right)\, , &\text{on } (-a,a) \times (\underline\theta, \underline\theta + b), \medskip \\
%Z_\theta^0(\cdot,\underline \theta) = 0, \qquad Z^0(\cdot, \underline \theta + b) = 0\, ,\medskip\\
%Z^0(-a,\cdot) = Q_b, \qquad Z^0(a,\cdot)  = 0.
%\end{array}
%\right.
%\end{equation*}
This problem is equivalent to solving the following symmetrized equation on $(-a,a)\times(-b,b)$:
\begin{equation*}
\begin{cases}
	-c \widetilde{Z}_\xi ^0 - \underline\theta \widetilde{Z}_{\xi\xi}^0  - \widetilde{Z}_{\theta\theta}^0 = \mu_+ (1 - m(|\theta-\underline\theta| + \underline\theta) - \frac12 \nu_\mu), \qquad \text{on }(-a,a)\times(-b,b), \\
	\widetilde{Z}^0(\cdot, - b) = \widetilde{Z}_\theta^0(\cdot,b) = 0,
	\quad \widetilde{Z}^0(-a,\cdot) = Q_b(\vert \cdot \vert + \underline\theta),
	\quad \widetilde{Z}^0(a,\cdot)  = 0.
\end{cases}
\end{equation*}
%We now naturally introduce the map 
%\begin{equation*}
%\mathcal{\widetilde{K}}: (c,\mu) \to \left( \epsilon - \nu_\mu(0) + c , \widetilde{Z}^{0} \right). 
%\end{equation*}
Using this formulation, that $-1 %= \text{deg}\left(  \text{Id} - \mathcal{\widetilde{K}}, \mathcal{B} , 0 \right)
= \deg\left(  \Id - \mathcal{K}_{0} , \mathcal{B} , 0 \right)$ is exactly the purpose of \cite[Proposition 3.9]{AlfaroCovilleRaoul}. %Indeed, it is proved there that there exists $\eps^*$ such that for any $\eps < \eps_1$, there exists $b_0 >0$ such that for any $b \geq b_0$ there exists $a_0 = a_0(b,\eps^*)$ such that for all $a \geq a_0$, $\text{deg}\left(  \text{Id} - \mathcal{\widetilde{K}}, \mathcal{B} , 0 \right) = -1$.
Since $ -1 = \deg(\Id - \mathcal{K}_0, \mathcal{B},0)$, then $\mathcal{K}_1$ has a fixed point.  This finishes the proof.% and, hence, the problem $\mathcal{P}_{a,b}^{\tau=1}$, \eqref{eq:slab}, is solvable.
\end{proof}







\subsubsection{Construction of a spatial travelling wave in $\R\times (\underline\theta,\underline\theta + b)$}

We now use the solution of the slab problem \eqref{eq:slab} given by Proposition~\ref{slabsol} to construct a travelling wave solution. For this purpose, we first pass to the limit $a \to \infty$ to obtain a profile in $\R\times(\underline\theta,\underline\theta+b)$. Then we prove that this profile has speed $c_b^*$ and the correct asymptotics as $\xi \to \pm\infty$.

\begin{lemma}\label{lem:convslab}
Let $\underline\eps < \underline\eps_0$. There exists $c \in \left[ 0 , c_b^* \right]$ such that the system
\begin{equation}\label{convslab2}
\begin{cases}
- c_0 \mu_{\xi} - \theta \mu_{\xi\xi} - \mu_{\theta\theta} = \mu (1 - m - \nu),  & \text{on } \R\times(\underline\theta,\underline\theta+b), \\
 \mu_\theta(\cdot,\underline\theta) = 0, \qquad \mu(\cdot, \underline\theta + b) = 0, \\
\end{cases}
\end{equation}
has a nonnegative solution $\mu \in \mathcal{C}_b^2\left( \R \times (\underline\theta,\underline\theta + b)\right)$ satisfying $\mu(0,\underline\theta) = \underline\eps$. 
\end{lemma}
\begin{proof}
Using the uniform bounds above, along with classical elliptic regularity theory, and applying the Arzela-Ascoli theorem, we take the limit $a\to \infty$ to obtain the lemma.
\end{proof}
%\begin{proof}%[{\bf Proof of Lemma \ref{lem:convslab}}]
%For sufficiently large $b \geq b_0$ and $a > a_0(b,\eps)$, \Cref{slabsol} gives a solution $(c_{a,b},\mu_{a,b})$ of \eqref{eq:slab} which satisfies $c_{a,b} \in \left[ 0 , c^* \right]$, $\Vert \mu_{a,b} \Vert_{L^\infty((-a,a) \times (\underline\theta, \underline\theta + b))} \leq K_0$ and $\mu_{a,b}(0,\underline\theta) = \eps$. As a consequence, $\nu_{a,b}$ is also uniformly bounded by Lemma \ref{lem:tails}.
%The elliptic regularity \cite{Gilbarg} implies that for all $\beta > 0$, $\mu_{a,b} \in \mathcal{C}^{1,\beta}(\Gamma)$ uniformly in $a,b$. Then, the Ascoli theorem gives that possibly after passing to a subsequence $a_n \to \infty$, $(c_{a,b},\mu_{a,b})$ converges towards some $(c_{b},\mu_{b})$ satisfying similar uniform bounds in $b$. Then, passing to the limit in $b$ with a subsequence $b_n$, $(c_{b},\mu_{b})$ converges towards $(c_0,\mu) \in \left[ 0 , c^* \right] \times \mathcal{C}^{1,\beta}(\Gamma)$ which satisfies \eqref{convslab2} and $\mu(0,\underline\theta) = \eps$.
%\end{proof}

\subsubsection*{The profile is travelling with the minimal speed $c_b^*$.}

In this section, we present the arguments showing that the constructed front has the minimal speed $c_b^*$. It roughly goes as follows.  First, any solution with $c \leq c^*_b$ that is bounded away from zero at $\{\theta = \underline\theta\}$ is, in fact, bounded from below on $\{\theta=\underline\theta\}$ by a constant $\omega>0$ that is independent of $\mu$.  Contrasting this lower bound with the choice of normalization, we argue that $\lim_{\xi\to \infty} \mu(\xi,\underline\theta) = 0$.  Finally, by building oscillating sub-solutions, we show that this limit holds only when $c \geq c^*_b$, which, in view of \Cref{lem:upboundc} implies that $c = c^*_b$. The ideas used here are similar to those in \cite{AlfaroCovilleRaoul,BouinCalvez}.




 %First, up to adjusting the normalization if necessary, the solution necessarily satisfies $\inf_{\R} \mu(\cdot,\underline\theta) = 0$. Since this infimum cannot be attained, we have necessarily $\liminf_{\xi \to + \infty} \mu(\xi,\underline\theta) = 0$. This enforces $c = c^*_b$ for our wave. Indeed, we first show that any solution with $c<c^*_b$ that is bounded away from zero at $\theta = \underline\theta$ must, in fact, be bounded below at $\theta = \underline\theta$ by a uniform constant $\omega>0$ independent of all parameters.  {\color{red} THIS ALL NEEDS TO BE RE-WORKED}  Later we show that if $\mu$ tends to zero at $\xi = \infty$ then $c \geq c^*_b$.  Finally, we show that  then, in the sequel, we use this bound to show that $c = c^*_b$. The proofs of these lemmas are similar to the work in \cite{AlfaroCovilleRaoul,BouinCalvez}.

\begin{lemma}\label{lem:inf}
There exists $\omega > 0$ such that any solution $(c,\mu)$ constructed in \Cref{slabsol}
%of
%\begin{equation*}
%\begin{cases}
%- c \mu_{\xi} - \theta \mu_{\xi\xi} - \mu_{\theta\theta} = \mu (1 - m - \nu) & \text{on } \R\times\Theta,\\
% \mu_\theta(\cdot,\underline\theta) = 0, \\
%\end{cases}
%\end{equation*}
%with $c \in \left[ 0 , c^*\right]$, $\nu$ bounded, and $\inf_{\xi \in \R} \mu(\xi,\underline\theta)  > 0$ satisfies $\inf_{\xi \in \R} \mu(\xi,\underline\theta) > \omega$.
with $c \in \left[ 0 , c_b^*\right]$ and $\inf_{\xi \in \R} \mu(\xi,\underline\theta)  > 0$ satisfies $\inf_{\xi \in \R} \mu(\xi,\underline\theta) > \omega$.
\end{lemma}



\begin{proof}%[{\bf Proof of Lemma \ref{lem:inf}}]
Fix $\varphi$ as in \Cref{lem:bottom} and fix any point $\xi_0$.  Let $\phi(\xi,\cdot) = \varphi(\xi - \xi_0, \cdot)$.  We construct a sub-solution of $\mu$ using $\phi$ to obtain a bound on $\mu$ at $\xi_0$ independent of $\xi_0$.  Recall that we fix $r$ and $s\leq b$ sufficiently large that $\gamma_{r,s} \geq \gamma_\infty/2$.

By the Harnack inequality, there exists $C_s$ sufficiently large that $\mu(\xi,\theta') \leq C_s \mu(\xi,\theta)$ for any $\theta, \theta'\in(\underline \theta, \underline\theta+s)$ and any $\xi$.  When $s$ is large enough, we may estimate $\nu$ as above to obtain,
\[
	\forall (\xi,\theta) \in \R\times (\underline\theta, \underline\theta + s), \qquad \nu(\xi) \leq C_s \mu(\xi,\theta) + \frac{\gamma_\infty}{4}.
\]



%We adapt an argument from \cite{Alfaro} to our context.  %There are only very few computational differences. 
%By the Harnack inequality on $(\underline\theta,\underline\theta + s)$, we  have, for any $s>0$, 
%\begin{equation}\label{Hn}
%\forall (\theta,\theta') \in (\underline\theta,\underline\theta + s)^2, \qquad \mu(\cdot,\theta') \leq C_s \mu(\cdot,\theta).
%\end{equation}
%Note that the constant $C_s$ can be taken independently of $\xi$ thanks to the translational invariance of the problem (the normalization is not used to prove the Harnack inequality). Moreover, Lemma \ref{lem:tails} tells that there exists a sufficiently large $s > 0$ such that we  have 
%\begin{equation*}
%\int_{(\underline\theta+s,+\infty)} \mu(\cdot,\theta) d\theta \leq \frac{\gamma_\infty}{4}.
%\end{equation*}
%We deduce from these two latter inequalities that $\nu$ can be estimated as follows : 
%\begin{equation*}
%\forall (\xi,\theta) \in \R \times (\underline\theta,\underline\theta + s), \qquad \nu(\xi) \leq s C_s  \mu(\xi,\theta) + \gamma_\infty/4,
%\end{equation*}
%and thus $\mu$ appears to be a super solution of some elliptic equation with local terms only :
%\begin{equation*}
%\forall (\xi,\theta) \in \R \times (\underline\theta,\underline\theta + s), \qquad - c \mu_{\xi}  - \theta \mu_{\xi\xi} - \mu_{\theta\theta} \geq \left(1 - m - s C_s \mu - \gamma_\infty/4\right)\mu.
%\end{equation*}
%We now introduce relevant bump-like sub-solutions on $\Gamma_{\infty,s}$. After the proof of Lemma \ref{lem:bottom},  let us re-introduce, for $r > 0$ arbitrarily given, 
%\begin{equation*}
%\forall (\xi,\theta) \in (-r,r) \times (\underline\theta, \underline\theta + s), \qquad \varphi(\xi,\theta)= \sin\left( \frac{\pi}{2} \left(\frac{\xi}{r}+1\right) \right) V_{r,s}(\theta),
%\end{equation*}
%so that 
%\begin{equation*}
%\begin{cases}
%\theta \varphi_{\xi\xi}   +  \varphi_{\theta\theta}  + (1-m) \varphi   = \gamma_{r,s} \varphi \,, \quad \text{on } (-r,r) \times (\underline\theta, \underline\theta + s),\medskip\\
%\varphi_\theta (\cdot,\underline\theta) = 0\,, \quad \varphi (\cdot,\underline\theta + s) = 0\,, \quad \varphi(-r,\cdot) = 0 \, , \quad \varphi(r,\cdot)  = 0.
%\end{cases}
%\end{equation*}
%We have specified $\tau = 0$ in the previous construction from Lemma \ref{lem:bottom}. One can extend $\varphi$ by zero outside $(-r,r) \times (\underline\theta, \underline\theta + s)$. We take $r_0,s_0$ sufficiently large such that $\gamma_{r,s} > \gamma_\infty/{2}$ for all $r,s$ larger than $r_0,s_0$.
%%To this end, define the following spectral problem on $(\underline\theta,\underline\theta + s)$:
%%\begin{equation*}
%%\begin{cases} 
%%Q_s^*\,''+ \left( - \lambda_s^* c_s^* + \theta \left(\lambda_s^*\right)^2   + \left( 1 - m \right) \right) Q_s^* = 0\,, \qquad \theta \in (\underline\theta,\underline\theta + s), \medskip\\
%%Q_s^*\,' \left( \underline\theta \right) = 0, \medskip\\
%%Q_s^*  \left( \underline\theta + s\right) = 0, \medskip\\
%%Q_s^* > 0,
%%\end{cases}
%%\end{equation*}
%%where, as previously done several times, $c_s^*$ is the minimal speed and $\lambda_s^*$ the associated decay rate. 
%
%%We now define the family of functions
%%\begin{equation*}
%%\forall \left( \xi , \theta \right) \in \Gamma_{\infty,s}, \qquad \psi_\alpha(\xi,\theta) = \alpha \left( 1 - \eta \xi^2 \right) Q_s^*(\theta). 
%%\end{equation*}
%%Notice that any $\psi_\alpha$ satisfies Dirichlet boundary conditions on $\left\lbrace \xi = \pm  \eta^{-1/2} \right\rbrace \cup \left\lbrace \theta = \underline\theta + s \right\rbrace$ and Neumann ones at $\left\lbrace \theta = \underline\theta \right\rbrace$. 

From the $L^\infty$ estimate on $\mu$ and the construction of $\varphi$, there exists $\overline\alpha$ such that $\overline\alpha \phi(\xi_0,\underline\theta) > \mu(\xi_0,\underline\theta)$. % on $(\underline\theta,\underline\theta + s)$.
On the other hand, by the Harnack inequality, we have $\underline\alpha \phi \leq \mu$ where $\underline\alpha := \frac{ \inf_\R \mu(\cdot,\underline\theta)}{ C_s} > 0$ where $V_{r,s}$ is defined in \Cref{lem:bottom} and $\|V_{r,s}\|_\infty = 1$. As a consequence, we can define 
\begin{equation*}
\alpha_0:= \sup \lbrace \alpha > 0 \, : \, \alpha \phi \leq \mu  \text{ on } [-r+\xi_0,r+\xi_0] \times [\underline\theta, \underline\theta + s] \rbrace.
\end{equation*}
As usual, %As in previous same ideas, see Lemmas \ref{lem:upboundc} and \ref{lem:bottom}
there exists $(\xi_{\max} , \theta_{\max})$ such that $\mu - \alpha_0 \phi$ has a minimum of zero at this point.  It is easy to check that this point must occur in the interior of $(-r+\xi_0,r+\xi_0)\times(\underline\theta,\underline\theta+s)$.  Hence,%ince $\mu$ is positive, we have clearly that $\xi_0 \in \left( - \eta^{-1/2}, \eta^{-1/2} \right)$ since $\phi$ is nonpositive elsewhere. Moreover, $\theta_0$ cannot lie on the upper boundary of $\Gamma_{\infty,s}$ since $\alpha_0 \phi$ vanishes there. Finally, $(\xi_0 , \theta_0)$ being a interior point or such that $\underline\theta$, we have:
\begin{equation}\label{eq:phi}
\begin{split}
0 & \geq  - \theta_{\max}( \mu - \alpha_0 \phi)_{\xi\xi} -    ( \mu - \alpha_0 \phi )_{\theta \theta} - c ( \mu - \alpha_0 \phi )_\xi, \\
& \geq  \big(1 - m - C_s \mu - \frac{\gamma_\infty}{4} \big)\mu + \alpha_0 ( \theta_{\max} \phi_{\xi\xi} + \phi_{\theta \theta} + c \phi_\xi ), \\
& \geq  \big(1 - m - C_s \mu - \frac{\gamma_\infty}{4} \big)\mu - \alpha_0 ( (1-m) \phi - \gamma_{r,s} \phi ) - \alpha_0 \frac{c\pi}{2r} \sin\Big( \frac{\pi}{2} \frac{\xi_{\max}-\xi_0}{r} \Big) V_{r,s}(\theta_{\max}),  \\
%& \geq & (1 - m - C_s s \mu - \frac{\gamma_\infty}{4} )\mu - 2 \eta \alpha_0 \theta_0 Q_s^*(\theta_0) -  \Big( -\lambda_s^* c_s^* + \theta_0 (\lambda_s^*)^2 + (1-m) \Big) \psi_{\alpha_0} - 2 c\eta \xi_0 \alpha_0 Q_s^*,  \medskip\\
& \geq  \big( \gamma_{r,s} -\frac{\gamma_\infty}{4}- C_s \mu  \big) \mu - \alpha_0 \frac{c\pi}{2r} \sin\Big( \frac{\pi}{2} \frac{\xi_{\max} - \xi_0}{r}\Big) V_{r,s}(\theta_{\max}).
\end{split}
\end{equation}
From the Harnack inequality, we deduce that $C_s \mu(\xi_{\max},\theta_{\max}) \geq \mu(\xi_{\max},\underline\theta) $.  Recalling also the inequalities $\inf_{\R} \mu(\cdot,\underline\theta) > 0$, $c \leq c_b^*$, $\alpha_0 \leq \overline\alpha$, $\gamma_{r,s} \geq \gamma_\infty/2$, we get
\begin{equation*}
\mu(\xi_{\max} , \theta_{\max}) \geq \displaystyle  \frac{ \gamma_\infty}{4C_s} - \frac{ \pi \overline \alpha c_b^*}{2 r s \mu(\xi_0,\underline\theta)}.
%&&\\
%&\geq& \displaystyle \frac{\theta_{\text{min}} \left(\lambda^* \right)^2}{C_s s } - \frac{2 \overline \alpha \Vert Q_s^* \Vert_{\infty}\left(\eta s +  \sqrt{\eta} c^* \right)}{s \,{ (\inf_{\xi \in \R} \mu(\cdot,\underline\theta))} }.\\
\end{equation*}
Taking $r$ sufficiently large we have that $\mu(\xi_{\max}, \theta_{\max}) \geq \gamma_\infty/(8C_s)$.  
%Now restricting to $r > r_0$ sufficiently small, we have necessarily $\mu(\xi_0, \theta_0) \geq \frac{\gamma_\infty}{8C_s s }$.
Since $\mu$ and $\alpha_0 \phi$ coincide at $(\xi_{\max},\theta_{\max})$, we have $\alpha_0 \geq \frac{\gamma_\infty }{8C_s}$. We are finished by noting that
\begin{equation*}
	\mu(\xi_0,\underline\theta) \geq \alpha_0 \phi(\xi_0,\underline\theta)
		\geq \frac{\gamma_\infty}{8 C_s } V_{r,s}(\underline\theta).
\end{equation*}
%Since $\eta$ is arbitrarily small, we have necessarily $\inf_{\R}\mu(\xi,\underline\theta) \geq \omega:= \frac{\gamma_\infty}{8 C_s s \Vert V_{r,s} \Vert_{\infty} } Q_s^*(\underline\theta)$. Note that $ \Vert V_{r,s} \Vert_{\infty}$ can be bounded independently of $r,s$. 
\end{proof}
















Next we show that the front has the required limits at infinity.  The second part of this proposition is crucial in the sequel in showing that our front moves with speed $c \geq c^*_b$.


\begin{proposition}\label{prop:limits}
Any solution $(c,\mu)$ of~\eqref{convslab2}
%\begin{equation*}
%\left\{\begin{array}{ll}
%- c \mu_{\xi} - \theta \mu_{\xi\xi} - \mu_{\theta\theta} = \mu (1 - m - \nu) & \text{on } \Gamma,\medskip \\
% \mu_\theta(\cdot,\underline\theta) = 0, \\
%\end{array}
%\right.
%\end{equation*}
with $c \in[0,c^*_b]$, and $\mu(0,\underline\theta) = \underline\eps$ satisfies\smallskip
\begin{enumerate}
	\item[(i)]\label{point:1} For all sufficiently large $s < b$, there exists $\alpha_s >0$ such that $\mu > \alpha_s Q_s$ on $(-\infty,0)\times(\underline\theta, \underline \theta + s)$;
%\begin{equation*}
%\mu > \alpha_s Q_s, \qquad \text{on } (-\infty,0) \times (\underline\theta,\underline\theta + s).
%\end{equation*}
%
	\item[(ii)]\label{point:2} $\lim_{\xi \to +\infty} \mu(\xi,\cdot) =0.$
\end{enumerate}
\end{proposition}
\begin{proof}%[{\bf Proof of Proposition \ref{prop:limits}}]
We start with the proof of (i).  Recall from the proof of Lemma \ref{lem:inf} that $\mu$ satisfies %appears to be a super solution of some elliptic equation with local terms only. More precisely, for $s > 0$ sufficiently large, we  have
\begin{equation}\label{eq:mu_local_eqn}
\forall \left( \xi , \theta \right) \in \R \times (\underline\theta,\underline\theta + s), \qquad - c \mu_{\xi}  - \theta \mu_{\xi\xi} - \mu_{\theta\theta} \geq \left(1 - m - C_s \mu - \frac{\gamma_\infty}{4}  \right)\mu.
\end{equation}
%{\color{blue} I THINK THERE WAS  SUBTLE ERROR HERE BEFORE.  WE USED R = 1 TO START THE PROCESS BUT THEN SAY THAT WE HAVE FIXED R LARGE ENOUGH SO THAT GAMMA (SUB R,S) IS LARGER THAN GAMMA/4.  I HAVE CORRECTED THAT BELOW.  OLD STUFF IN COMMENTS....}

Let $\underline r$ be sufficiently large so that, for $s$ sufficiently large, $\gamma_{\underline r,s}> \gamma_\infty/2$. For any $r\geq \underline r$,
 define $\varphi_r = \alpha \cos\left(\frac{\pi\xi}{2r}\right)V_{r,s}(\theta)$, as above,
%\begin{equation*}
%\forall (\xi,\theta) \in (-r,0) \times (\underline\theta, \underline\theta + s), \qquad \psi_r(\xi,\theta)= \alpha \sin\left( \frac{\pi}{2} \left(\frac{\xi}{r}+1\right) \right) V_{r,s}(\theta),
%\end{equation*}
with $\alpha = \min \left( \frac{\underline\eps}{2 \tilde C_s}, \frac{\gamma_\infty}{8 C_s s}  \right)$, where $\tilde C_s$ is defined below.  %Recall that $\|V_{r,s}\|_\infty = 1$.

We first show that $\varphi_{\underline r}\leq \mu$ on $[- \underline r , 0] \times \left[\underline\theta,\underline\theta + s\right]$. We have $\varphi_{\underline r}  = 0 < \mu$ on $\{-\underline r\} \times \left[\underline\theta,\underline\theta + s\right]$. 
The Harnack inequality, applied on $[-\underline r,0] \times \left[\underline\theta,\underline\theta + s\right]$, yields a postive constant $\widetilde C_s$ such that
\begin{equation}\label{eq:HHn}
\widetilde{C}_s \inf_{[-\underline r,0] \times \left[\underline\theta,\underline\theta + s\right]} \mu \geq  \mu(0,\underline\theta) = \underline\eps.
\end{equation}
Recall that $\|V_{r,s}\|_\infty = 1$.  Thus, on $[-\underline r , 0] \times \left[\underline\theta,\underline\theta + s\right]$, using \eqref{eq:HHn}, we have that $\varphi_{\underline r} \leq \mu$.
%\begin{equation*}
%\psi_1  \leq \alpha \Vert V_{r,s} \Vert_{\infty} \leq \frac{\eps}{\widetilde{C}_s}  \leq  \inf_{[-1,0] \times \left[\underline\theta,\underline\theta + s\right]} \mu(\xi,\theta) \leq \mu.
%\end{equation*}

%We first seek to compare $\varphi_1$ and $\mu$ on $\left] - \infty , 0\right] \times \left[\underline\theta,\underline\theta + s\right]$. We have $\varphi_1  = 0 < \mu$ on $\left(-\infty,-1\right] \times \left[\underline\theta,\underline\theta + s\right]$. 
%To complete the comparison, we use the Harnack inequality on $[-1,0] \times \left[\underline\theta,\underline\theta + s\right]$. There exists $\widetilde C_s$ such that we  have
%\begin{equation}\label{eq:HHn}
%\widetilde{C}_s \inf_{[-1,0] \times \left[\underline\theta,\underline\theta + s\right]} \mu \geq  \mu(0,\underline\theta) = \underline\eps.
%\end{equation}
%Recall that $\|V_{r,s}\|_\infty = 1$.  Thus, on $[-1 , 0] \times \left[\underline\theta,\underline\theta + s\right]$, using \eqref{eq:HHn}, we have that $\varphi_1 \leq \mu$.
%%\begin{equation*}
%%\psi_1  \leq \alpha \Vert V_{r,s} \Vert_{\infty} \leq \frac{\eps}{\widetilde{C}_s}  \leq  \inf_{[-1,0] \times \left[\underline\theta,\underline\theta + s\right]} \mu(\xi,\theta) \leq \mu.
%%\end{equation*}

As a consequence we can define 
\begin{equation*}
r_0:= \sup \lbrace r \geq \underline r \, : \, \varphi_r \leq \mu \text{ on }\left(- r , 0\right] \times \left[\underline\theta,\underline\theta + s\right]  \rbrace.
\end{equation*}
We now prove that $r_0 = \infty$ by contradiction. Suppose that $r_0 < \infty$. Then, as usual,
%We apply the same technique as in the proofs of Lemmas \ref{lem:upboundc} and \ref{lem:bottom}:
there exists $(\xi_0 , \theta_0) \in (-\infty,0] \times \left[\underline\theta,\underline\theta + s\right]$ such that $\mu - \varphi_{r_0}$ has a zero minimum at this point. Note that $\theta_0\neq \underline\theta + s$ and $\xi_0 \neq r_0$ since $\varphi_r$ vanishes at those points. %Due to the Neumann boundary condition and the Hopf lemma, $\theta_0 \neq \underline\theta$.
Moreover, $\xi_0$ cannot be $0$ since $\varphi_r(0,\theta) < \mu(0,\theta)$ on $(\underline\theta,\underline\theta+s)$, by our choice of $\alpha$ and by~\eqref{eq:HHn}.  % this would give $\mu(0,\theta_0) = \alpha Q_s^*(\theta_0) \leq \frac{\eps}{2\widetilde{C}_s } $ and this would contradict \eqref{eq:HHn}.
Thus, $(\xi_0 , \theta_0) \in (-r_0,0)\times(\underline\theta,\underline\theta+s)$ or $\theta_0 = \underline \theta$.  In either case, the maximum principle and Hopf maximum principle along with~\eqref{eq:phi} and~\eqref{eq:mu_local_eqn} imply that
% are to be on the the lower boundary $\theta = \underline\theta$ or to be an interior point, but in both of these cases we have, by \eqref{eq:phi}:
\begin{equation*}
0
	\geq \left( \frac{\gamma_\infty}{4}- C_s \mu  \right) \mu -  \alpha \frac{c\pi}{2r_0} \sin\left( \frac{\pi \xi_0}{2 r_0}\right) V_{r_0,s}(\theta_0)
	\geq \left( \frac{\gamma_\infty}{4}- C_s \mu  \right) \mu.
\end{equation*}
Above, we used that $s$ and $r$ are large enough that $\gamma_{r,s} > \gamma_\infty/2$.   Thus,
\begin{equation*}
\frac{\gamma_\infty}{4C_s s} \leq \mu(\xi_0,\theta_0) = \varphi_{r_0}(\xi_0,\theta_0) \leq \alpha,
\end{equation*}
which contradicts the definition of $\alpha$.
As a consequence, $r_0 = \infty$.  Since $V_{r,s} \to Q_s$ as $r$ tends to $\infty$, then we have that $\alpha Q_s \leq \mu$, as claimed.

We now prove (ii). By the Harnack inequality and Lemma \ref{lem:tails}, it is sufficient to prove that $\lim_{\xi \to \infty}\mu(\xi,\underline\theta) = 0$. Suppose that there exists $\delta>0$ and a sequence $\xi_n \to + \infty$ such that for all $n \in \N, \;\mu(\xi_n,\underline\theta)\geq \delta$. Adapting the proof of (i), we find $\alpha_{s,\delta}>0$ that for all $n \in \N$,
\begin{equation}\label{eq:last}
\mu(\xi,\underline\theta) \geq \alpha_{s,\delta} Q_s(\underline\theta), \qquad \forall (\xi,\theta) \in \left( -\infty , \xi_n \right] \times [\underline\theta,\underline\theta + s].
\end{equation}
Hence \eqref{eq:last} holds for all $\xi \in \R$.  This contradicts \Cref{lem:inf}, lowering $\underline\eps$ so that $\underline \eps < \omega$ if necessary.
%Hence \eqref{eq:last} is true for all $\xi \in \R$ and Lemma \ref{lem:inf} gives the contradiction since the normalization $\underline\eps$ is well-chosen.  
\end{proof}






















\begin{proposition}[The front speed is $c_b^*$]\label{prop:minspeed}
%Any nonzero solution $(c,\mu)$ of  
%\begin{equation}\label{eq:minspeed}
%\begin{cases}
%- c \mu_{\xi} - \theta \mu_{\xi\xi} - \mu_{\theta\theta} = \mu (1 - m - \nu) & \text{on } \R \times \Theta,\medskip \\
% \mu_\theta(\cdot,\underline\theta) = 0, \\
%\end{cases}
%\end{equation}
%with $c \geq 0$, $\inf_{\xi \in \R} \mu(\xi,\underline\theta) = 0$ satisfies necessarily $c \geq c^*$.
%
%
Any nonzero, nonnegative solution $(c,\mu)$ given by \Cref{lem:convslab} satisfying $\inf_{\xi\in\R} \mu(\xi,\underline\theta) = 0$ satisfies $c \geq c_b^*$.
%Any solution $(c,\mu)$ of the system 
%\begin{equation}\label{eq:minspeed}
%\left\{\begin{array}{l}
%- \theta \partial_{\xi\xi} \mu - \alpha \partial_{\theta\theta} \mu  - c \partial_{\xi} \mu = r \mu (1 - \nu), \qquad (\xi , \theta ) \in \R \times (\underline\theta, \underline\theta + b),\\
%\partial_{\theta} \mu(\xi,\underline\theta + b) = \mu(\xi,\underline\theta + b) = 0, \qquad \xi \in \R,\\
%\end{array}
%\right.
%\end{equation}
%with $c\geq0$ and \EB{$\inf_{\xi \in\R} \nu(\xi) = 0$} satisfies necessarily $c \geq c_b^*$. 
\end{proposition}

\noindent Note that, due to \Cref{lem:upboundc}, Proposition~\ref{prop:limits}, and Proposition~\ref{prop:minspeed}, the solution given by \Cref{lem:convslab} travels with the speed $c=c_b^*$.


\begin{proof}%[{\bf Proof of Proposition \ref{prop:minspeed}}]
%Returning to the stationary frame, i.e.~setting $n(t,x,\theta) = \mu(x-ct,\theta)$, we see that $n$ satisfies the equation~\eqref{eq:main}.  The proof is finished by applying \Cref{lem:finite_speed_lower_bd}.

Assume that $c<c_b^*$.  By analogy with the Fisher-KPP equation, we use oscillating fronts to ``push'' solutions of \eqref{convslab2} up to the speed $c_b^*$. %We now assume by contradiction that $c < c_b^*$ and take $c < \bar c < c_b^*$.

%
%
%To begin, we fix $r$ and $s$ to be large parameters.  Since $c_s^*$ is increasing in $s$ and since $c < c^*_b$, then we may choose $s< b$ sufficiently large so that $c^*_s \in (c,c^*_b)$.  We seek sub-solutions of the form $\varphi = e^{-\lambda_s^* \xi} \psi(x,\theta)$ on $(-r,r)\times(\underline\theta,\underline\theta + s)$ where $\psi$ and $\beta$ are the principal eigenfunction and principal eigenvalue satisfying $\|\psi\|_\infty = 1$ and 
%\begin{equation}\label{eq:psi_small_speed}
%\begin{cases}
%	(c-2\theta\lambda_s^*)\psi_\xi- \theta \psi_{\xi\xi} - \psi_{\theta\theta} - (\theta (\lambda_s^*)^2 - \lambda_s^* c + (1-m))\psi = \beta_{r,s} \psi,\\
%	\psi_\theta(\cdot,\underline\theta) = 0, \quad \psi(\pm r, \cdot) = 0, \quad \psi(\cdot, \underline\theta + s) = 0.
%\end{cases}
%\end{equation}
%We claim that $\beta_{r,s} < 0$ for $r$ sufficiently large.  Indeed, it is well understood that $\beta_{r,s}$ is decreasing in both $r$ and $s$, see~\cite{BerestyckiNirenbergVaradhan}.  Fixing $\xi_r \in (-r,r)$ so that there exists $\theta_r$ with $\phi(\xi_r,\theta_r) = 1$, we let $\phi_r(\xi,\theta) = \phi(\xi + \xi_r,\theta_r)$.  Taking the limit $r\to\infty$ along a sub-sequence if necessary, we have that $\phi_r \to \phi_\infty$ yields $\phi_\infty$ and $\beta_\infty$ which satisfy same eigenvalue problem with domain $(-\lim_{r\to\infty}( r+\xi_r), \lim_{r\to\infty (r -\xi_r))\times(\underline\theta,\underline\theta+s)$.  As usual we may, by multiplying by the appropriate constant, assume that $Q_{\lambda_s^*,s} - \psi_\infty$ have a minimum of zero.  Due to the 
%
%
% and, in addition, it is quite easy to see that $\psi$ is symmetric in $\xi$ and  thus have a maximum at $\xi = 0$.  Using these two facts, we may pass to the limit $r \to \infty$ to obtain a limiting equation, function, and eigenvalue $\beta_{\infty,s}$.  By the uniqueness of principle eigenfunctions and eigenvalues, it follows that $\psi$ must converge to $Q_{\lambda_s^*,s}$ and that $\beta_{r,s}$ must converge to $0$, as claimed.
%
%
%
%
%
%
%
%\vspace{2 in}



Fix $\epsilon_1 > 0$ to be determined.  By choosing $s = b - \epsilon_1/(1+\|\mu\|_\infty)$ and applying the Harnack inequality for any $\theta, \theta' \in [\underline\theta, \underline \theta+s]$, we have that $\mu(\xi,\theta') \leq C_s \mu(\xi,\theta)$.  Note that $C_s$ and $s$ depend only on $b$ and $\epsilon_1$.  Recall that $\|\mu\|_\infty$ is bounded above by \Cref{lem:nc}.  Hence, we have
\[
	\nu(\xi)
		= \int_{\underline\theta}^{\underline\theta + b} \mu(\xi,\theta')d\theta'
		\leq \int_{\underline\theta}^{\underline\theta + s} C_s \mu(\xi,\theta)d\theta' + \int_{\underline\theta+ s}^{\underline\theta + b} \|\mu\|_\infty d\theta'
		= C_s' \mu(\xi,\theta) + \epsilon_1,
\]
where $C_s' = s C_s$.
% we have that $\nu(\xi) \leq C_s \mu(\xi,\theta) + \epsilon$ for any $(\xi,\theta)\in\R\times[\underline\theta,\underline\theta+s]$.
As a result, $\mu$ satisfies
%Arguing as in the proof of \Cref{lem:inf} we see that, given $\epsilon >0$, take $s$ large enough that
\begin{equation*}
\forall \left( \xi , \theta \right) \in \R \times (\underline\theta,\underline\theta +s), \qquad - c \mu_{\xi}  - \theta \mu_{\xi\xi} - \mu_{\theta\theta} \geq \left(1 - m - C_s' \mu - \eps_1 \right)\mu.
\end{equation*}

We explain below how to construct a compactly supported sub-solution using a relevant spectral problem in the complex plane, see also \cite{BouinCalvez} for a related argument. 

Recall from~\eqref{eq:spectral_problem} that for any $\lambda, \eps \in \R^+$, $Q_{\lambda,s}$ solves the spectral problem
%Defining $c_{\lambda,b,\epsilon} = c_{\lambda,b} - (\epsilon_0+\epsilon)/\lambda$, we have that $Q_{\lambda,s}$, which is independent of $\epsilon$, solves the following the spectral problem
\begin{equation}\label{eq:spectral_problem_s}
\begin{cases} 
	Q_{\lambda,s}''+ \left( - \lambda c_{\lambda,s,\epsilon} + \theta \lambda^2   + \left( 1 - \epsilon_1 - \epsilon -  m \right) \right) Q_{\lambda,s} = 0\,, \qquad \theta \in (\underline\theta,\underline\theta + s), \\
	Q_{\lambda,s}'\left( \underline\theta \right) = 0, \quad Q_{\lambda,s}\left( \underline\theta + s\right) = 0, \quad Q_{\lambda,s} > 0,
\end{cases}
\end{equation}
with $c_{\lambda, s, \epsilon} = c_{\lambda, s} - (\epsilon_1 + \epsilon)/\lambda$. 
%Here, we  have $c_{\lambda,s,\eps} =  c_{\lambda,s} - (\eps_0 + \eps)/\lambda$ and $Q_{\lambda,s}$ does not depend on $\eps$.
%Then, by choosing $\epsilon$ and $\epsilon_0$ sufficiently small.  
Let $c^*_{s,\epsilon}$ be the minimum, occurring at $\lambda_{s,\epsilon}^*$, of $c_{\lambda,s,\epsilon}$ over all $\lambda \in \R^+$. From the explicit expression of  $c_{\lambda,s,\epsilon}$, we obtain $c^*_{s,\epsilon} < c^*_s <c^*_b$. By fixing $\eps_1$ sufficiently small, we can ensure $c < c^*_{s,\epsilon=0} < c^*_b$. Thus, there exists $\epsilon_c > 0$ such that
\[
	c = c_{s,\epsilon_c}^* = c_{\lambda_{s,\epsilon_c}^*,s,\epsilon_c} = c_{\lambda_{s,\epsilon_c}^*,s} - \frac{\epsilon_1 +\epsilon_c}{\lambda_{s,\epsilon_c}^*}.
\]

% Moreover, by adjusting $\epsilon$, we may choose $c^*_{s,\epsilon}$ as close to $c$ as we like.

%For any $\eps \geq 0$, we know that there exists a minimal speed $c_{s,\eps}^*$. Moreover, the minimal speed is decreasing with respect to $\eps$, so that one can choose $\eps(\bar c)$ such that 
%\begin{equation*}
%c < \bar c = c_{s,\eps(\bar c)}^* < c_{s,0}^* < c^*.
%\end{equation*}



%Differentiating \eqref{eq:eigenpb} with respect to $r$, we obtain
%\begin{equation*}
%\left( - \lambda \frac{\partial c_r}{\partial r} + 1 \right) Q_\lambda + \left( - \lambda c(\lambda) + \theta \lambda^2 + r \right) \frac{\partial Q_\lambda}{\partial r} + \alpha \partial_{\theta \theta} \left( \frac{\partial Q_\lambda}{\partial r} \right) = 0.
%\end{equation*}
%Testing again {against} $Q_\lambda$, we obtain, for $\lambda >0$:
%\begin{equation*}
%\frac{\partial c_r}{\partial r} = \frac{1}{\lambda}
%\end{equation*}
%As a consequence, $\frac{\partial c_r^*}{\partial r} = \frac{\partial c_r(\lambda_r^*)}{\partial r} = \frac{\partial c}{\partial r} + \frac{\partial c}{\partial \lambda} \frac{\partial \lambda_r^*}{\partial r} = \frac{1}{ \lambda_r^*} > 0$.

Now consider~\eqref{eq:spectral_problem_s} for complex values of $\lambda$. Perturbation theory, see \cite[Chapter 7, \S 1, \S 2, \S 3]{Kato}, yields that the map $\lambda \mapsto c_{\lambda,s,\epsilon}$ is analytic in $\lambda$ at least in a neighborhood of the real axis.

Our aim is now to  find $\epsilon$ and $\lambda_c := \lambda_{c,R} + i \lambda_{c,I}$ (with $\lambda_{c,I} \neq 0$) such that $c_{\lambda_c,s,\epsilon} = c$.  We note that $\lambda_{c,I}\neq 0$ allows us to construct compactly supported sub-solutions; see below.  We argue using Rouché's theorem (around $\lambda_{s,\epsilon_c}^*$).  


Define $f(\lambda) = c_{\lambda, s, \epsilon_c} - c$. From above, we have that $f(\lambda_{s,\epsilon_c}^*) = 0$. Since $\lambda \mapsto Q_{\lambda,s}$ is continuous, 
%as a map from $B_r(\lambda_{s,\epsilon_c}^*) \to C^1$, 
$\partial_\theta Q_{\lambda_{s,\epsilon_c}^*}(\underline\theta+s) < 0$ due to the Hopf lemma, and $Q_{\lambda_{s,\epsilon_c}^*} > 0$ in $(\underline\theta,\underline\theta+s)$, then $\Real(Q_{\lambda,s}) > 0$ for $\lambda$ sufficiently close to $\lambda_{s,\epsilon_c}^*$. 
%we may choose $\lambda_c$ close enough to $\lambda_{\epsilon_c}^*$ so that $\Real(Q_{\lambda_c}) > 0$.
Moreover, since the zeros of analytic functions are separated, for any sufficiently small $r \in (0,\lambda_{s,\epsilon_c}^*)$ there is $\delta>0$ such that $|f(\partial B_r(\lambda_{s,\epsilon_c}^*))| \geq \delta > 0$. Thus fix $r \in (0,\lambda_{s,\epsilon_c}^*)$ sufficiently small so that $|f(\partial B_r(\lambda_{s,\epsilon_c}^*))| \geq \delta > 0$ and $\Real(Q_{\lambda,s}) > 0$ for any $\lambda \in B_r(\lambda_{s,\epsilon_c}^*)$. 
%all previous requirements hold for any $\lambda \in B_r(\lambda_{s,\epsilon_c}^*)$. 

Define $g(\lambda) =  c_{\lambda, s, \epsilon}  - c$. Fix $\eps < \eps_c$ close enough to $\eps_c$ such that $0 < \vert \eps_c - \eps\vert/(\lambda_{s,\epsilon_c}^* - r) < \delta$.  Then, on $\partial B_r(\lambda_{s,\epsilon_c}^*)$, we have that
\[
	|f(\lambda) - g(\lambda)|
		= \frac{\vert \eps_c - \eps \vert}{|\lambda|}
		\leq \frac{\vert \eps_c - \eps \vert}{\lambda_{s,\epsilon_c}^* - r}
		< \delta
		\leq |f(\lambda)|
		\leq |f(\lambda)| + |g(\lambda)|.
\]
Hence the hypotheses of Rouch\'e's theorem are met.  Thus, $f$ and $g$ have the same number of zeros in $B_r(\lambda_{s,\epsilon_c}^*)$.  Since $f(\lambda_{s,\epsilon_c}^*) = 0$ then $g$ has at least one zero, $\lambda_c$.  Using the definition of $g$, we have that $c_{\lambda_c,s,\eps} = c$. Moreover, since $\eps < \eps_c$, we have necessarily $c_{s,\eps}^* > c_{s,\eps_c}^* = c$ and thus $\lambda_c \not\in \R$.
%
%Thus, %By our argument above,
%we may choose $r$ as small as we like by choosing $\epsilon$ closer to $\epsilon_c$.  Hence we may choose $\lambda_c$ as close to $\lambda_{s,\epsilon_c}^*$ as we like.  Since $Q_{\lambda,s}$ does not depend on $\epsilon$,   
%
%

We now let
\begin{equation*}
\psi(\xi,\theta):= \text{Re} \big( e^{- \lambda_c \xi} Q_{\lambda_c,s} \left( \theta \right)\big) = e^{-\lambda_{R} \xi}\left[ \text{Re} \left(Q_{\lambda_c,s}(\theta)\right) \cos (\lambda_{I} \xi) + \text{Im} \left(Q_{\lambda_c,s}(\theta)\right) \sin (\lambda_{I} \xi) \right].
\end{equation*} 
%For all $\theta \in (\underline\theta,\underline\theta + s)$, we  have $\psi\left( 0 , \theta \right) = \text{Re} \left( Q_{\lambda_c,s} \left( \theta \right)\right) > 0$ and $\psi ( \pm \lambda_I^{-1}\pi, \theta ) < 0$. As a consequence,
Notice that $\psi(0,\theta) > 0 > \psi(\pm \lambda_{c,I}^{-1} \pi, \theta)$ for all $\theta \in [\underline\theta, \underline\theta + s)$.
  Hence, by the continuity of $\psi$, there exists an open subdomain $\mathcal{D} \subset [-\lambda_{c,I}^{-1}\pi,\lambda_{c,I}^{-1}\pi]\times [\underline\theta, \underline\theta+s]$ such that $\psi>0$ on $\mathcal{D}$ and vanishes on $\partial \mathcal{D}$,
%\begin{equation*}
%\lbrace \xi = 0 \rbrace \times (\underline\theta,\underline\theta + s) \subset \mathcal{D} \subset \left[ - \lambda_I^{-1}\pi, \lambda_I^{-1}\pi \right] \times \left[\underline\theta,\underline\theta + s\right]
%\end{equation*}
%such that $\psi > 0$ on $\mathcal{D}$ and $\psi$ vanishes on the boundary $\partial \mathcal{D}$,
except possibly where $\mathcal{D}$ intersects $\lbrace \theta = \underline\theta \rbrace$ where $\psi$ satisfies Neumann boundary conditions.

By construction of $\psi$, we have
\begin{equation*}
- c \psi_\xi - \theta \psi_{\xi\xi} - \psi_{\theta \theta} - (1 - \eps_1 - m) \psi = - \eps \psi, \qquad \text{on } \mathcal{D}.
\end{equation*}
%\begin{equation*}
%- c \psi_\xi - \theta \psi_{\xi\xi} - \psi_{\theta \theta} - (1 - \eps_0 - m) \psi = - \eps(\bar c) \psi, \qquad \text{on } \mathcal{D}.
%\end{equation*}
Thus, for all $\alpha \geq 0$, the function $v:= \mu - \alpha \psi$ satisfies
%\begin{equation*}
%- c v_\xi - \theta v_{\xi\xi} - v_{\theta \theta} - (1 - \eps_0 -m)v \geq \alpha \eps( \bar c)\psi - \left( C_s s \mu\right) \mu.
%\end{equation*}
\begin{equation}\label{eq:chris}
- c v_\xi - \theta v_{\xi\xi} - v_{\theta \theta} - (1 - \eps_1 -m)v \geq \alpha \eps\psi - \left( C_s' \mu\right) \mu = \left( \eps - C_s' \mu\right) \mu - \eps v.
\end{equation}


Arguing as \Cref{lem:inf}, there exists $\alpha_0$ such that $v$ attains a zero minimum at $(\xi_0,\theta_0) \in \overline{\mathcal{D}}$. The minimum point is in the interior due to the boundary conditions. From \eqref{eq:chris} evaluated at $(\xi_0,\theta_0)$, we deduce $\mu(\xi_0,\theta_0) \geq \frac{\eps}{C_s'}$. Applying the Harnack inequality on $\mathcal{D}$, we conclude that $\mu(0,\underline\theta) \geq \frac{\eps}{C_s'}$ after possibly changing the constant $C_s'$. 
%there exists a constant $C$ depending only on $\lambda_{c,I}$ and $s$ such that $\mu(\xi_0,\theta_0) \leq C \mu(0,\underline\theta)$.
%\begin{equation*}
%\mu(z_0, \theta_0) \leq C \mu(0,\underline\theta)
%\end{equation*}

We emphasize that the renormalization $\mu(0,\underline\theta) = \underline\eps$, which is the only reason for which \eqref{eq:slab} is not invariant by translation in $\xi$, is not used here. Hence, we note that our argument did not depend on the spatial variable $\xi$.  As such, we can conclude that $\mu(\xi,\underline\theta) \geq \frac{\eps}{C_s'}$ for all $\xi$.  
%Now that we have a sub-solution, we want to translate the argument in space. For this purpose, we define, for $\zeta \in \R$, the function $h(\xi,\theta):= \mu(\xi + \zeta,\theta)$. $h$ also satisfies \eqref{eq:minspeed}. As a consequence, for all $\zeta \in \R$, $\mu(\zeta,\underline\theta) \geq \frac{\eps( \bar c)}{C C_s s}$.
We then obtain $\inf_{\xi \in \R} \mu(\xi,\underline\theta) \geq \frac{\eps}{C_s'}$. This contradicts the property $\inf_{\xi \in \R} \mu(\xi,\underline\theta)= 0$.
\end{proof}







































\subsubsection*{Taking the limit $b\to\infty$}

Since we have uniform bounds on $\mu_b$, we may take locally uniform limits $\mu_b \to \mu_\infty$ as $b$ tends to infinity.  Since the speed associated with $\mu_b$ is $c_b^*$ and since $c_b^* \to c^*$ then $\mu_\infty$ satisfies equation~\eqref{eqkinwave}.  We need only check that the limit is non-trivial.  Proposition~\ref{prop:limits}.(i) gives that $\liminf_{\xi\to-\infty} \nu_\infty(\xi) > 0$.  On the other hand, we may argue exactly as in Proposition~\ref{prop:limits}.(ii) in order to show that $\limsup_{\xi\to\infty} \mu_\infty(\xi,\underline\theta) = 0$.  Hence $\mu_\infty$ is our traveling wave with speed $c^*$, finishing the proof of Proposition~\ref{prop:tw} in the case when $m$ is super-linear.


\subsection{Case two (the critical case): $\lim_{\theta\to\infty} m(\theta)/\theta = \kappa^2 > 0$}

In this section, we show the differences appearing in the critical case. We now assume that the trade-off function takes the following form
\begin{equation*}
m(\theta) = \kappa^2 \theta + \widetilde m(\theta), 
\end{equation*}
where $\kappa > 0$ and $\widetilde m(\theta)/\theta \to 0$.

We start by constructing the speeds of propagation for the travelling waves. This is where the assumption on $m$ plays the main role. For any spatial decay rate $\lambda > 0$, we re-introduce the spectral problem on $[\underline\theta, \underline\theta + b]$ for $b$ sufficiently large and possibly infinite:
\begin{equation*}
\begin{cases} 
Q_{\lambda,b}''+ \left( - \lambda c_{\lambda,b} + \left( \lambda^2 - \kappa^2 \right) \theta  + 1 - \widetilde m(\theta)  \right) Q_{\lambda,b} = 0\,, \qquad \theta \in (\underline\theta, \underline\theta + b), \\
 Q_{\lambda,b} ' \left( \underline\theta \right)= Q_{\lambda,b}(\underline\theta + b) = 0, \quad Q_{\lambda,b} > 0.
\end{cases}
\end{equation*}

We may observe that as long as either $\lambda < \kappa$ or $b < \infty$, the previous spectral problem has a unique solution $c_{\lambda,b}$ as in the previous sub-section. Moreover, one can prove again that $\lim_{\lambda \to 0} \lambda c_{\lambda,b} = \gamma_b^{\delta=0} \leq \lambda c_{\lambda,b}$.  However, the unique issue of this case is that when $\lambda > \kappa$ and $b = \infty$ this spectral problem does not have any solution since, denoting $c_\lambda = c_{\lambda,\infty}$,
\begin{equation*}
\lim_{\theta \to + \infty} \left( - \lambda c_\lambda + \theta \lambda^2   + \left( 1 - m(\theta) \right) \right) = + \infty.
\end{equation*}
We point out that, the borderline case $\lambda = \kappa$ need not have a solution but it does if $\widetilde m(\theta) \to \infty$.

Hence, the function $\lambda \mapsto c_\lambda$ has an infimum on $(0,\kappa)$ but may not have a minimum. We define the minimal speeds $c^*_b := \inf_{\lambda\in\R^+} c_{\lambda,b}$, if $b < \infty$, and $c^* := \inf_{\lambda \in (0,\kappa)} c_\lambda$ otherwise. Note that
\begin{equation*}
c_{b}^* = \inf_{\lambda \in \R^+} c_{\lambda,b} \leq \inf_{\lambda \in (0,\mu)} c_{\lambda,b} < \inf_{\lambda \in (0,\mu)} c_{\lambda} = c^*. 
\end{equation*}
Moreover $\lim_{b \to +\infty} c_{b}^* = c^*$, since $\lim_{b \to +\infty} c_{\lambda,b} = + \infty$ when $\lambda > \kappa$. As a consequence, the entire proof of case one can be reproduced in this case to prove \Cref{prop:tw}.
%\begin{lemma}\label{lem:upboundccrit}
%For any $\underline\epsilon > 0$, there exists a sufficiently large $a_0(\underline\epsilon,b)$ such that any $(c,\mu)$ solution of the slab problem $\eqref{eq:slab}$ with $a \geq a_0(\underline\eps,b)$ satisfies $c \leq c^*$.
%\end{lemma}
%
%\begin{proof}%[{\bf Proof of Lemma \ref{lem:upboundccrit}}]
%The proof of this lemma in this case is very close to that of \Cref{lem:upboundc}. The only difference is that one must be careful in the definition of the family of super-solutions since $\lambda^*$ associated to $c^*$ does not necessarily exist (the infimum defining $c^*$ is not necessarily attained).  Let us assume by contradiction that $c > c^*$. By definition of $c^*$, one can find $\lambda_{0} \in (0,\kappa)$ such that $c > c_{\lambda_0} > c^*$. Then the family of functions $\psi_A ( \xi, \theta ):= A e^{- \lambda_0 \xi} Q_{\lambda_0}( \theta )$ is a family of super-solutions to the linear problem:
%\begin{equation*}
%- c \left(\psi_A\right)_{\xi} >  \lambda_0 c_{\lambda_0} \psi_A \geq d \left(\psi_A\right)_{\xi\xi}  + \left(\psi_A\right)_{\theta\theta}  + (1-m )\psi_A, \qquad \text{on } (-a,a) \times (\underline\theta, \underline\theta + b).
%\end{equation*}
%We conclude in the same way as in the proof of \Cref{lem:upboundc}.
%%The end of the proof of the lemma is the same as for \Cref{lem:upboundc}.
%\end{proof}
%
%Let us assume by contradiction that $c > c_\tau^*$. By definition of $c_\tau^*$, one can find $\lambda_{0,\tau} \in (0,\mu)$ such that $c > c_{\lambda_{0,\tau},\tau} > c_{\tau}^*$. Then the family of functions $\psi_A ( \xi, \theta ):= A e^{- \lambda_{0,\tau} \xi} Q_{\lambda_0,\tau}( \theta )$ is a family of super-solutions to the linear problem:
%\begin{equation}\label{eq:psi}
%- c \left(\psi_A\right)_{\xi} >  \lambda_{0,\tau} c_{\lambda_{0,\tau},\tau} \psi_A = d^\tau \left(\psi_A\right)_{\xi\xi}  + \left(\psi_A\right)_{\theta\theta}  + (1-m )\psi_A, \qquad \text{on } (-a,a) \times (\underline\theta, \underline\theta + b).
%\end{equation}
%The end of the proof of the lemma is the same as for \Cref{lem:upboundc}.
%\end{proof}
%
%The construction of the profile on $\R\times(\underline\theta,\underline\theta + b)$ that travels with speed $c\in[c^*_b,c^*]$ in this case is the same as with the construction in \Cref{sec:caseone} since the Leray-Schauder degree argument can be performed similarly.   \Cref{lem:convslab}, \Cref{lem:inf}, \Cref{prop:limits} and \Cref{prop:minspeed} also hold, proved with exactly the same methods. After, we take the limit $b\to\infty$, arguing exactly as above, to conclude the proof of \Cref{prop:tw}. The only thing we should quickly put forward is that also in this case $\lim_{b \to +\infty} c_{b}^* = c^*$, since $\lim_{b \to +\infty} c_{\lambda,b} = + \infty$ when $\lambda > \kappa$.  
%
%\begin{equation*}
%c_{b}^* = \inf_{\lambda \in \R^+} c_{\lambda,b} \leq \inf_{\lambda \in (0,\mu)} c_{\lambda,b} < \inf_{\lambda \in (0,\mu)} c_{\lambda} = c^*.
%\end{equation*}
%
%
%\begin{lemma}\label{lem:convslabcrit}
%For $\eps$ sufficiently small, there exists $c_0 \in \left[ 0 , c^* \right]$ such that the system
%\begin{equation}\label{convslab2}
%\left\{\begin{array}{ll}
%- c_0 \mu_{\xi} - \theta \mu_{\xi\xi} - \mu_{\theta\theta} = \mu (1 - m - \nu) & \text{on } \Gamma,\medskip \\
% \mu_\theta(\cdot,\underline\theta) = 0, \\
%\end{array}
%\right.
%\end{equation}
%has a nonnegative solution $\mu \in \mathcal{C}_b^2\left( \R \times \Theta \right)$ satisfying $\mu(0,\underline\theta) = \eps$. Moreover, any solution to that problem satisfies also $\inf_{\xi \in \R} \mu(\xi,\underline\theta) = 0$ as soon as $\eps$ is small enough. 
%\end{lemma}
%
%The last issue remaining is to prove  
%
%\begin{proposition}[The front propagates at the minimal speed $c_b^*$]\label{prop:minspeedcrit}
%If $b$ is sufficiently large, then any solution $(c,\mu)$ of
%\begin{equation*}
%\begin{cases}
%- c \mu_{\xi} - \theta \mu_{\xi\xi} - \mu_{\theta\theta} = \mu (1 - m - \nu) & \text{on } \R \times (\underline\theta, \underline\theta + b) \\
% \mu_\theta(\cdot,\underline\theta) = 0, \qquad \mu(\cdot, \underline\theta+b) = 0, \\
%\end{cases}
%\end{equation*}
%with $c \geq 0$, $\inf_{\xi \in \R} \mu(\xi,\underline\theta) = 0$ satisfies necessarily $c \geq c^*_b$.
%\end{proposition}
%
%\begin{proof}%[{\bf Proof of Proposition \ref{prop:minspeedcrit}}]
%We proceed exactly as for \Cref{prop:minspeed}. The only thing to be checked is the fact that for $s > 0$, we  have $c^* \geq c_{s,0}^*$, where the notation is the same as in the proof of \Cref{prop:minspeed}. Recall the definition of $c^*$ in that case, $c^* = \inf_{\lambda \in (0,\mu)} c_\lambda$.
%
%\begin{equation*}
%c_{b}^* = \inf_{\lambda \in \R^+} c_{\lambda,b} \leq \inf_{\lambda \in (0,\mu)} c_{\lambda,b} < \inf_{\lambda \in (0,\mu)} c_{\lambda} = c^*.
%\end{equation*}
%The rest is exactly as in \Cref{prop:minspeed} so we omit the proof.
%\end{proof}

 



%%%%In order to mitigate the unbounded diffusion, we make the following change of variables.  Define $\tilde n$ by
%%%%\begin{equation}\label{eq:n_tilde}
%%%%	\tilde n^{(z_1)}(t,y,\theta) \stackrel{\rm def}{=} n(t,y\sqrt{\theta_1}, \theta)
%%%%\end{equation}
%%%%and notice that $\tilde n$ satisfies
%%%%\[
%%%%	\tilde n^{(z_1)}_t = \frac{\theta}{\theta_1} \tilde n^{(z_1)}_{xx} + \tilde n^{(z_1)}_{\theta\theta} + \tilde n^{(z_1)} (1 - \alpha \theta^p - \tilde\rho^{(z_1)})
%%%%\]
%%%%on $\tilde Q_{z_1,3R} := (t_1 - (3R)^2, t_1) \times B_{3R}(x_1/\sqrt{\theta_1},\theta_1)$.  Here $\tilde \rho^{(z_1)}$ is defined analogously.  We point out that, since $\theta_1 \geq \underline\theta > 0$, any bounds on $\tilde n^{(z_1)}$ may be transferred to $n$, at the expense of a constant.
%%%%
%%%%Unfortunately, the equation satisfied by $\tilde n$ has an unbounded term $\alpha \theta^p$ in its reaction rate.  We, thus, define
%%%%\[
%%%%	w^{(z_1)} = e^{\alpha \theta_1^p (t- t_1 + 3R)} \tilde n
%%%%\]
%%%%and $w$ satisfies
%%%%\[
%%%%	w^{(z_1)}_t = \frac{\theta}{\theta_1} w^{(z_0)}_{xx} + w^{(z_0)}_{\theta\theta} + w^{(z_0)}(1 - \alpha(\theta^p - \theta_1)^p - \tilde\rho).
%%%%\]
%%%%It is clear that there is a constant depending only on $\alpha$, $p$, $\underline \theta$ and $R$ such that
%%%%\[
%%%%	\frac{1}{C} \leq \frac{\theta}{\theta_1} \leq C ~~~\text{ and }~~~
%%%%	|\alpha ( \theta^p - \theta_1^p)| \leq C.
%%%%\]
%%%%
%%%%
%%%%
%%%%
%%%%\subsubsection*{Bounds on w}
%%%%
%%%%Then, thanks to \cref{lem:krylov}, we have that
%%%%\[
%%%%	|w^{(z_1)}|_{1 + \delta/2, 2+ \delta, \tilde Q_R}
%%%%		\leq C( |w^{(z_1)}(1 - \alpha(\theta^p - \theta_1^p) - \rho)|_{\delta/2,\delta, \tilde Q_{2R}} + \|w^{(z_1)}\|_{L^\infty(\tilde Q_{2R})}).
%%%%\]
%%%%Using the bound $\tilde \rho \leq CM$, which comes from \cref{lem:rho_regularity} and a change of variables, we have that
%%%%\begin{equation}\label{eq:w_holder}
%%%%\begin{split}
%%%%	|w^{(z_1)}&|_{1 + \delta/2, 2+ \delta, \tilde Q_R}
%%%%		\leq C\left( |w^{(z_1)}(1 - \alpha(\theta^p - \theta_1^p) - \rho)|_{\delta/2,\delta, \tilde Q_{2R}} + \|w^{(z_1)}\|_{L^\infty(\tilde Q_{2R})}\right)\\
%%%%		&\leq C\big( \|w^{(z_1)}\|_{L^\infty(\tilde Q_{2R})} [ 1 - \alpha(\theta^p - \theta_1^p) - \rho)]_{\delta/2,\delta,\tilde Q_{2R}}\\
%%%%			&~~~~~+ [w^{(z_1)}]_{\delta/2,\delta, \tilde Q_{2R}}\| 1 - \alpha(\theta^p - \theta_1^p) - \rho\|_{L^\infty(\tilde Q_{2R})}
%%%%			+ \|w^{(z_1)}\|_{L^\infty(\tilde Q_{2R})}\big)\\
%%%%		&\leq C\left( \|w^{(z_1)}\|_{L^\infty(\tilde Q_{2R})} [ 1 - \alpha(\theta^p - \theta_1^p) - \rho)]_{\delta/2,\delta,\tilde Q_{2R}}
%%%%			+ M [w^{(z_1)}]_{\delta/2,\delta, \tilde Q_{2R}}
%%%%			+ \|w^{(z_1)}\|_{L^\infty(\tilde Q_{2R})}\right).
%%%%\end{split}\
%%%%\end{equation}
%%%%Now applying \cref{lem:rho_regularity} and then \cref{lem:krylov} to~\eqref{eq:w_holder}, we have
%%%%\begin{equation}\label{eq:w_holder2}
%%%%\begin{split}
%%%%	|w^{(z_1)}|_{1 + \delta/2, 2+ \delta, \tilde Q_R}
%%%%		&\leq C \big(\|w^{(z_1)}\|_{L^\infty(\tilde Q_{2R})}\|\tilde n\|_{\delta'/2,\delta'} \log(1+\|\tilde n\|_{\delta'/2,\delta'})\log(M)\\
%%%%			&~~~~~ + M [w^{(z_1)}]_{\delta/2,\delta, \tilde Q_{2R}} + \|w^{(z_1)}\|_{L^\infty(\tilde Q_{2R})}\big)\\
%%%%		&\leq C \big( \|w^{(z_1)}(1+\|_{L^\infty(\tilde Q_{2R})} \|\tilde n\|_{\delta'/2,\delta'} \log(1+\|\tilde n\|_{\delta'/2,\delta'})\log(M))\\
%%%%			&~~~~~ + \epsilon M [w^{(z_1)}]_{1+\delta/2,2+\delta,Q_{3R}} + \epsilon^{-\delta/2} M \|w^{(z_1)}\|_{L^\infty(\tilde Q_{2R})}\big).
%%%%\end{split}
%%%%\end{equation}
%%%%where $\delta' > \delta$ and $\epsilon > 0$ are constants to be chosen later.
%%%%
%%%%At the moment, we have the problem that the norm on the left hand side is defined on the set $\tilde Q_R$, while the norm on the right hand side is defined over the larger set $Q_{3R}$.  In order to relate the norm on the larger set back to the smaller set we use the following trick.  We point out that, similar to~\cite[eqn.~(7.13)]{BerestyckiMouhotRaoul}, we may, for any $z_1$, find constants $C$ and $N$ and points points $\tilde z_1, \dots, \tilde z_N$ such that
%%%%\begin{equation}\label{eq:large_to_small}
%%%%	|w^{(z_1)}|_{1+\delta/2,2+\delta,Q_{3R}}
%%%%		\leq Ce^{C \theta_1^p} \sum_{i = 1}^N [w^{(\tilde z_i)}]_{1+\delta/2,2+\delta,Q_{\tilde z_i,R}}.
%%%%\end{equation}
%%%%Since the proof of this fact is straightforward and virtually unchanged from the reference cited above, we omit it.  Fix $z_1$ where $|w^{(z_1)}|_{1+\delta/2,2+\delta,Q_{z_1,R}}$ is within a factor $2$ of its maximum.  We point out that the maximum is bounded due to~\cref{lem:apriori}.  Hence, we have that
%%%%\begin{equation}\label{eq:big_cylinder}
%%%%\begin{split}
%%%%	|w^{(z_1)}|_{1+\delta/2,2+\delta,Q_{3R}}
%%%%		&\leq C e^{C \theta_1^p} \sum_{i = 1}^N [w^{(\tilde z_i)}]_{1+\delta/2,2+\delta,Q_{\tilde z_i,R}}\\
%%%%		&\leq C e^{C \theta_1^p}N |w^{(z_1)}|_{1+\delta/2,2+\delta,Q_{z_1,R}}.
%%%%\end{split}
%%%%\end{equation}
%%%%
%%%%Plugging~\eqref{eq:big_cylinder} into~\eqref{eq:w_holder2}, gives us that
%%%%\[\begin{split}
%%%%	|w^{(z_1)}|_{1+\delta/2,2+\delta,Q_{z_1,R}}
%%%%		\leq C\big(&\|w^{(z_1)}\|_{L^\infty(\tilde Q_{z_1,2R})} (1+\|\tilde n\|_{\delta'/2,\delta'}\log(1+\|\tilde n\|_{\delta'/2,\delta'})\log(M))\\
%%%%			&~~~~ + \epsilon e^{C \theta_1^p} M |w^{(z_1)}|_{1+\delta/2,2+\delta,Q_{z_1,R}} + \epsilon^{-\delta/2} M \|w^{(z_1)}\|_{L^\infty(\tilde Q_{z_1,2R})}\big).
%%%%\end{split}\]
%%%%It is clear that we should choose $\epsilon^{-1} = 2C e^{C \theta_1^p}M$, allowing us to absorb the highest order term on the right hand side into the left hand side.  This gives us that
%%%%\[\begin{split}
%%%%	|w^{(z_1)}|_{1+\delta/2,2+\delta,Q_{z_1,R}}
%%%%		\leq C\big(&\|w^{(z_1)}\|_{L^\infty(\tilde Q_{z_1,2R})} (1+\|\tilde n\|_{\delta'/2,\delta'}\log(1+\|\tilde n\|_{\delta'/2,\delta'})\log(M))\\
%%%%			&~~~~ + e^{C \theta_1^p} M^{1+\delta/2}  \|w^{(z_1)}\|_{L^\infty(\tilde Q_{z_1,2R})}\big).
%%%%\end{split}\]
%%%%Unfortunately, we have a $\theta_1$ dependence on the right hand side.  However, due to \cref{lem:rho_regularity}, we have that $n \leq M e^{-(\theta-\theta_0)}=CMe^{-\theta}$ for a fixed $\theta_0$.  In particular, this implies that
%%%%\[
%%%%	e^{C \theta_1^p}\|w^{(z_1)}\|_{L^\infty(\tilde Q_{z_1,2R})}
%%%%		\leq CM e^{C \theta_1^p}\| e^{-\cdot} n\|_{L^\infty( Q_{z_1,2R})}
%%%%		\leq CMe^{C \theta_1^p} e^{-\theta_1}
%%%%		\leq CM.
%%%%\]
%%%%Applying this inequality gives us
%%%%\begin{equation}\label{eq:w_bound}
%%%%\begin{split}
%%%%	|w^{(z_1)}|_{1+\delta/2,2+\delta,Q_{z_1,R}}
%%%%		\leq C\big(M\log(M)(1+\|\tilde n\|_{\delta'/2,\delta'}\log(1+\|\tilde n\|_{\delta'/2,\delta'}))
%%%%			 + M^{2+\delta/2} \big).
%%%%\end{split}
%%%%\end{equation}
%%%%
%%%%
%%%%\subsubsection*{Pushing bound on $w$ to bounds on $\tilde n$}
%%%%
%%%%By our choice of $z_1$ as the location of an approximate maximum, then the inequality~\eqref{eq:w_bound} holds for any choice of $z$.  Since, by construction, we clearly have the inequality
%%%%\[
%%%%	|\tilde n^{(z)}|_{1+\delta/2,2+\delta, \tilde Q_{z,R}}
%%%%		\leq C( M + |w^{(z)}|_{1+\delta/2,2+\delta,Q_{z,R}})
%%%%\]
%%%%then it follows that, for all $z$,
%%%%\[
%%%%	|\tilde n^{(z)}|_{1+\delta/2,2+\delta,Q_{z,R}}
%%%%		\leq C\big(M\log(M)(1+\|\tilde n\|_{\delta'/2,\delta'}\log(1+\|\tilde n\|_{\delta'/2,\delta'}))
%%%%			 + M^{2+\delta/2} \big).
%%%%\]
%%%%Taking the maximum over all choices of $z$ gives us that
%%%%\[
%%%%	\|\tilde n\|_{1+\delta/2,2+\delta}
%%%%		\leq C\big(M\log(M)(1+\|\tilde n\|_{\delta'/2,\delta'}\log(1+\|\tilde n\|_{\delta'/2,\delta'}))
%%%%			 + M^{2+\delta/2} \big).
%%%%\]
%%%%We point out that the logarithm grows slower than any polynomial.  Hence, we fix a small parameter $\gamma > 0$ and we have that
%%%%\[
%%%%	\|\tilde n\|_{1+\delta/2,2+\delta}
%%%%		\leq C\big(M^{1+\gamma}(1+\|\tilde n\|_{\delta'/2,\delta'})^{1+\gamma}
%%%%			 + M^{2+\delta/2} \big).
%%%%\]
%%%%We note that the constant depends on $\gamma$.
%%%%
%%%%Using \cref{lem:krylov} to split $\|\tilde n\|_{\delta'/2,\delta'}$, we may bound
%%%%\[
%%%%	\|\tilde n\|_{\delta'/2,\delta'}^{1+\gamma}
%%%%		\leq C(\epsilon^{-\frac{\delta'}{2 + \delta-\delta'}} \|\tilde n\|_{\infty}^{1+\gamma} + \epsilon\|\tilde n\|^{1+\gamma}_{1+\delta/2, 2+\delta})
%%%%		\leq C(\epsilon^{-\frac{\delta'}{2 + \delta-\delta'}} M^{1+\gamma} + \epsilon\|\tilde n\|^{1+\gamma}_{1+\delta/2, 2+\delta}).
%%%%\]
%%%%Combining the above two inequalities gives us
%%%%\[\begin{split}
%%%%	\|\tilde n\|_{1+\delta/2,2+\delta}
%%%%		&\leq C\big(M^{1+\gamma}(\epsilon^{-\frac{\delta'}{2 + \delta-\delta'}} M^{1+\gamma} + \epsilon\|\tilde n\|^{1+\gamma}_{1+\delta/2, 2+\delta})
%%%%			 + M^{2+\delta/2} \big).
%%%%\end{split}\]
%%%%Making the choice $\epsilon = \|\tilde n\|^\gamma_{1+\delta/2,2+\delta}/(2CM^{1+\gamma})$, we may absorb the higher order term on the right hand side into the left hand side to obtain
%%%%\[
%%%%	\|\tilde n\|_{1+\delta/2,2+\delta}
%%%%		\leq C\big(M^{2+2\gamma + \frac{\delta'(1+\gamma)}{2+\delta-\delta'}} \|\tilde n\|_{1+\delta/2,2+\delta}^{-\gamma\frac{\delta'}{2+\delta-\delta'}}
%%%%			 + M^{2+\delta/2} \big).
%%%%\]
%%%%We have two cases: either
%%%%\[\begin{cases}
%%%%	\|\tilde n\|_{1+\delta/2,2+\delta} \leq C M^{2+\delta/2}\\
%%%%	~~~~\text{-or-}\\
%%%%	\|\tilde n\|_{1+\delta/2,2+\delta}\leq M^{2+2\gamma + \frac{\delta'(1+\gamma)}{2+\delta-\delta'}}\|\tilde n\|_{1+\delta/2,2+\delta}^{-\gamma\frac{\delta'}{2+\delta-\delta'}}.
%%%%\end{cases}
%%%%\]
%%%%Fix any $\delta'' > \delta$.  By adjusting $\delta'$ and $\gamma$, i.e.~choosing $\delta'$ close to $\delta$ and $\gamma$ close to zero, both of these inequalities imply
%%%%\[
%%%%	\|\tilde n\|_{1+\delta/2,2+\delta} \leq C M^{2+\delta''/2}.
%%%%\]
%%%%In view of the fact that $n$ and all its derivatives are comparable to $\tilde n$ and all its derivatives, this implies that
%%%%\[
%%%%	\|n\|_{1+\delta/2,2+\delta} \leq C M^{2+\delta''/2},
%%%%\]
%%%%finishing the proof.

%
%
%\subsubsection{Quarantined momentarily}
%
%
%We point out that taking maxima is well defined as a result of~\cref{lem:apriori}.  For notational ease, we define
%\[
%	W_0 \stackrel{\rm def}{=} |w^{(z_1)}|_{L^\infty(Q_{z_1,2R})}
%	~~~\text{ and }~~~
%	W_1 \stackrel{\rm def}{=} |w^{(z_1)}|_{1+\delta/2,2+\delta, Q_{z_1,R}}.
%\]
%Choosing $\epsilon = 1/(2CM)$, we may absorb the second term in the parentheses above back into the left hand side.  This gives us
%\begin{equation}\label{eq:max_w}
%	W_1
%		\leq CW_0 (1+\|\tilde n\|_{\delta'/2,\delta'}\log(1+\|\tilde n\|_{\delta'/2,\delta'})\log(M)) + CM^{1 + \delta/2}
%\end{equation}
%
%
%
%
%{\color{red} HERE BUG FIXING BEGAN}
%
%To finish, we need to relate the norms in $\tilde n$ back to the norms of $w^{(z_1)}$.  To do this, we calculate that, for any $z_2 = (t_2,y_2,\theta_2)$:
%\begin{equation*}\label{eq:n_to_w}
%\begin{split}
%	[\tilde n]_{\delta'/2,\delta', \tilde Q_{z_2,R}}
%		&\leq [e^{-\alpha\theta_2^p (t-t_2+3R)}/\theta_2^p]_{\delta'/2,\delta', \tilde Q_{z_2,R}} \|\theta_2^p w^{(z_2)}\|_{L^\infty(Q_{z_2,R})}
%			+ [w^{(z_2)}]_{\delta'/2,\delta', \tilde Q_{z_2,R}}\\
%		&\leq C (M + [w^{(z_2)}]_{\delta'/2,\delta', \tilde Q_{z_2,R}}).
%\end{split}
%\end{equation*}
%In the last inequality, we used the upper bound from~\cref{lem:super-solution} {\color{red} NEED TO ADD THIS BACK} to bound $\theta_1^p w$ in terms of $M$.  Of course, we may split $w^{(z_2)}$ using {\color{red} TO BE FORMULATED INTO A LEMMA} to obtain
%\[\begin{split}
%	[w^{(z_2)}]_{\delta'/2,\delta', \tilde Q_{z_2,R}}
%		&\leq \epsilon [w^{(z_2)}]_{1+\delta/2, 2+\delta, Q_{z_2, 2R}} + C \epsilon^{-\delta'/(2+\delta-\delta')} \|w^{(z_1)}\|_{L^\infty(Q_{z_2,2R})}\\
%		&\leq \epsilon CW_1 + C \epsilon^{-\delta'/(2+\delta-\delta')} M.
%\end{split}\]
%HERE WE USED THE BIGGER TO SMALL INEQUALITY AGAIN.  Maximizing over $z_2$ yields
%\begin{equation}\label{eq:n_w}
%	\|\tilde n\|_{\delta'/2,\delta'}
%		\leq C(\epsilon W_1 + C \epsilon^{-\delta'/(2+\delta-\delta')} M).
%\end{equation}
%(((Of course, as a result of~\eqref{eq:large_to_small} and \cite[Theorem 8.8.1]{Krylov_Holder} {\color{red} need to prove this}, we obtain, for any $\epsilon \in (0,1)$,
%\begin{equation}\label{eq:n_to_w}
%	\|\tilde n\|_{\delta'/2,\delta'}
%		\leq C(M + \epsilon W + \epsilon^{-\delta'/(2 + \delta - \delta')} M)
%		\leq C(\epsilon W + \epsilon^{-\delta'/(2 + \delta - \delta')} M).
%\end{equation}
%)))))
%
%Plugging this in to~\eqref{eq:max_w} and re-arranging yields
%\[\begin{split}
%	W
%		&\leq CM \left[(\epsilon W + \epsilon^{-\delta'/(2 + \delta - \delta')} M)\log(\epsilon W + \epsilon^{-\delta'/(2 + \delta - \delta')} M)\log(M) + M^{1 + \delta/2})\right]\\
%		&\leq CM \left[\epsilon W \log(1+\epsilon W) \log(1+M)^2 + \epsilon^{-\delta'/(2+\delta-\delta')} M \log(1+M)^2 \log(1+\epsilon W) + M^{1 + \delta/2}\right].
%\end{split}\]
%Choosing $\epsilon = M^{-1}$, we obtain
%\[
%	W
%		\leq CM \left[\log(1+ W/M) \log(M)^2/M + M^{\delta'/(2+\delta-\delta')} M \log(1+M)^2 \log(1+W/M) + M^{1 + \delta/2}\right].
%\]
%Reducing this to the dominant terms, we have
%\[
%	W
%		\leq CM^{2+\delta'/(2+\delta-\delta')} \log(1+M)^2 \log(1+W/M).
%\]
%This, of course, implies that, for any $\epsilon$, there is a constant such that
%\[
%	W \leq C M^{2 + (\delta' + \epsilon)/(2+\delta-\delta')}.
%\]
%Since $\epsilon$ and $\delta'>\delta$ are arbitrary, then we have that, if $\delta_2 > \delta_1 > \delta$, then
%\[
%	W \leq C M^{2 + \delta_2/(2+\delta-\delta_1)}.
%\]
%Then, arguing as in~\eqref{eq:n_w}, we easily obtain that
%\[
%	\|\tilde n\|_{1 + \delta/2, 2+\delta} \leq C M^{2 + \delta_2/(2 + \delta-\delta_1)}.
%\]
%
%In order to finish the proof, we need to return to the original coordinates and bound $n$.  This follows easily by noticing that, for any point $z_0$,
%\[
%	[n]_{1 + \delta/2, 2+\delta, Q_{z_0,R}}
%		\leq \frac{C}{\sqrt{\theta_0}}[\tilde n]_{1 + \delta/2, 2+\delta, \tilde Q_{z_0,R}}
%		\leq \|\tilde n\|_{1 + \delta/2, 2+\delta}
%		\leq C M^{2 + \delta_2/(2 + \delta-\delta_1)}.
%\]
%Since this holds for all choices of $R$ and $z_0$, then it follows that
%\[
%	\|n\|_{1+\delta/2,2+\delta}
%		\leq C M^{2 + \delta_2/(2 + \delta-\delta_1)},
%\]
%finishing the proof.
%\end{proof}


 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

%\subsection{The convolution problem}
%
%We consider the following problem where we have replaced the diffusion operator by a convolution operator: 
%\begin{equation*}
%- c \partial_x n - d(\theta) \partial_{xx} n - \alpha \left( K \star_\theta n - n \right)  = r\, n \left( a(\theta) - \rho \right),
%\end{equation*}
%We define the spectral problem
%\begin{equation}\label{eq:eigenpb}
%\begin{cases} 
%- \alpha \left( K \star_\theta Q_\lambda - Q_\lambda \right) + \left( \lambda c(\lambda) - d(\theta) \lambda^2 - r a(\theta) \right) Q_\lambda(\theta) = 0\,, \qquad \theta \in \R, \medskip\\
%Q_\lambda(\theta) > 0, \; \int_\Theta Q_\lambda(\theta)\, d\theta = 1\,. 
%\end{cases}
%\end{equation}
%We define the problem on a slab. We want uniform bounds on the fixed points, we define the problems on $(-a,a) \times (\underline\theta, \underline\theta + b) := (-a,a) \times (-b , b)$:
%\begin{equation}\label{eq:slab}
%[P_{\tau,a}]\left\{\begin{array}{l}
%-c \partial_{\xi} \mu^a - d^\tau(\theta) \partial_{\xi \xi} \mu^a - \alpha \left( \int_{-b}^b K(\theta - \theta') \mu^a(\xi,\theta') d\theta' - \mu^a \right)  = r \mu^a (1 - \nu^a)\, , \qquad \EB{\mu^a \geq 0},  \quad {(\xi,\theta)} \in (-a,a) \times (\underline\theta, \underline\theta + b), \medskip\\
%\mu^a(-a,\theta) = \Gamma_b(\theta) \, , \quad \mu^a(a,\theta)  = 0\, , \quad \theta \in (-b , b) .
%\end{array}
%\right.
%\end{equation}
%Where $\left( \rho_{\Gamma_b} , \Gamma_b \right)$ is defined as the principal eigenelements of 
%\begin{equation}\label{eq:eigenpb}
%\begin{cases} 
%- \alpha  \left( K \star_\theta \Gamma - \Gamma \right)  + \left( - r a(\theta) \right) \Gamma_b  = - r \rho_{\Gamma_b} \Gamma_b\,, \qquad \theta\in (-b , b), \medskip\\
%\Gamma_b(\theta) > 0, \; \int_{-b}^b \Gamma_b(\theta)\, d\theta = \rho_{\Gamma_b}\,. 
%\end{cases}
%\end{equation}
%When $b \to \infty$, we recover the problem
%\begin{equation}\label{eq:eigenpb1}
%\begin{cases} 
%- \alpha \left( K \star_\theta \Gamma - \Gamma \right)  + \left( - r a(\theta) \right) \Gamma   = - r \rho_{\Gamma } \Gamma \,, \qquad \theta\in \R, \medskip\\
%\Gamma(\theta) > 0, \; \int_\R \Gamma(\theta)\, d\theta = \rho_{\Gamma}\,. 
%\end{cases}
%\end{equation}
%





























%\subsection{A brief discussion of well-posedness}
%
%In order to address the question of the well-posedness of~\eqref{eq:main}, we show how to obtain a priori bounds on the derivatives of $n$.  
%We point out that, although we do not rigorously show the well-posedness of~\eqref{eq:main}, these a priori bounds should re-assure any skeptical reader that the equation is in fact well-posed.  The main goal of this section is the following lemma:
%\begin{lemma}\label{lem:apriori}
%	Fix any time $T>0$ and any nonnegative integers $j$, $k$, and $\ell$.  There is a constant $C_T$ depending on $T$, $j$, $k$, $\ell$, $\alpha$, $p$, $\underline \theta$, and $n_0$, such that
%	\[
%		\left|\partial_t^j \partial_x^k \partial_\theta^\ell n(t,x,\theta)\right| \leq C_{T,j,k,\ell} e^{-\theta} ???
%	\]
%	holds for all $(t,x,\theta) \in [0,T]\times\R\times \Theta$.
%\end{lemma} 
%
%
%In order to mitigate the unbounded diffusion term, %on a parabolic cylinder $Q_{R}(z_1)$, where we denote by $z_1 = (t_1,x_1,\theta_1)$,
%we change variables to obtain
%\begin{equation}\label{eq:n_tilde}
%	\tilde n^{(z_1)}(t,y,\theta) \stackrel{\rm def}{=} n(t,y\sqrt{\theta_1}, \theta),
%\end{equation}
%which, on $Q_R(z_0)$, satisfies the equation, for $\tilde \rho^{(z_1)}$ defined analogously,
%\[
%	\tilde n_{t} = \frac{\theta}{\theta_0}\tilde n_{xx} + \tilde n_{\theta\theta} + \tilde n (1 - m - \tilde \rho).
%\]
%%% and we may define
%%%\[
%%%	\|\tilde n\|_{\delta/2,\delta} = \max_{z} |\tilde n^{(z_1)}|_{\delta/2,\delta,Q_R(z)}.
%%%\]
%%%We have the following lemma relating $\rho$ and $\tilde \rho$ to $n$ and $\tilde n$.
%%%\begin{lemma}\label{lem:rho_regularity}
%%%	Fix any constants $0 < \delta < \delta' < 1$, any constant $R \geq 1$, and any point $z = (t,x,\theta)$.  Then there is a constant $C$ depending only on $\delta' - \delta$, $m$, $\alpha$, and $n_0$ such that
%%%	\[
%%%		[\rho]_{\delta/2,\delta, Q_R(z)} \leq C_T \theta^{\delta/2} \| n\|_{\delta'/2,\delta'}.
%%%	\]
%%%\end{lemma}
%% 
%% 
%% 
%% 
%%
%%
%%
%%
%%
%%
%%
%%
%%
%%
%%
%%
%%
%%
%%
%%\subsubsection*{A priori bounds on $\tilde n$ and its derivatives}
%%
%%
%We first prove the time dependent a priori bounds of \cref{lem:apriori}. 
%Our main strategy is to obtain a bound of $n$ using the comparison principle.  Then, using local regularity, we obtain some integral bounds of $\tilde n$.  %Here $\tilde n$ is $n$ in the appropriate variables for the diffusivity and it is given by~\eqref{eq:n_tilde}.%  In order to proceed, we remind the reader of the following standard notation.  For any domain $\Omega\subset[0,T]\times\R\times \Theta$ and any $q \in (1,\infty)$, we define
% %\[\begin{split}
%%	W^{1,2}_q \stackrel{\rm def}{=}
%%		\left\{ f: \Omega \to \R: \max_{2j + k + \ell \leq 2} \int_{\Omega} |\partial_t^j \partial_x^k \partial_\theta^\ell f|^q dtdxd\theta < \infty \right\}.
%% \end{split}\]
%% This Banach space is given the obvious norm.
% 
%% Our main tool is the following classical estimate regarding estimates in these spaces of solutions to parabolic equations with bounded co-efficients (see e.g.~\cite[Theorem 7.22]{Lieberman}).
%% \begin{lemma}\label{lem:kryloV_{r,s}obolev}
%% 	Suppose that $a_{ij}: \Omega \to \R$ is uniformly positive definite and bounded in $C^\delta$ for some $\delta$.  Suppose that $u\in W^{1,2}_q(\Omega)$ and $f \in L^q(\Omega)$ and that
%%	\[
%%		u_t - \sum_{ij} a_{ij} \partial_{x_i}\partial_{x_j} u = f.
%%	\]
%%	Then, for any $z_1$ such that $\tilde Q_{z_1,2R}\subset \Omega$, we have that
%%	\begin{equation}\label{eq:kryloV_{r,s}obolev}
%%	\|u\|_{W^{1,2}_q(\tilde Q_R(z_1))}
%%		\leq C \left( \|u\|_{L^q(\tilde Q_{z_1, 2R})} + \|f\|_{L_q(\tilde Q_{z_1,2R})} \right),
%%	\end{equation}
%%	for a constant $C$ independent of $z_1$, $u$, and $f$.
%% \end{lemma}
%% With this lemma in hand, we may begin the proof.
%
% \begin{proof}%[Proof of \cref{lem:apriori}]
%We start by noting two things.  Firstly, we do not deal with local estimates near the boundary since the diffusion and reaction terms are bounded here and, hence, the conclusion above is classical.  Thus, we always assume that $\theta_0 - \underline \theta > 4$.  Secondly, we show how to obtain this for $j=1$, $k = 0$, and $\ell = 0$.  However, iterating the procedure yields the general result.
%
%Our starting point is the following $L^\infty$ bound for $n$, which $\tilde n$ inherits.  By a straight-forward computation,
%\[
%	Ce^{\lambda t}Q(\theta)
%\]
%is a super-solution to $n$.  Thus, by choosing $C$ large enough, depending only on $n_0$, we have that
%\begin{equation}\label{eq:heat_kernel}
%	n(t,x,\theta) \leq Ce^{\lambda t} Q(\theta)
%		 \leq C_T Q(\theta),
%\end{equation}
%for all $(t,x,\theta) \in [0,T]\times \R\times \Theta$.  As noted in ????, $Q$ is decays faster than any exponential.  This finishes the claim for the specific case $j, k, \ell = 0$.  We also note that this implies that $\tilde \rho(t,x) \leq C_T$ for all $(t,x)\in [0,T]\times\R$.
%
%Fix any $q \in (1,\infty)$ and any $\epsilon>0$ ??????.  Using~\cite[Theorem 7.22]{Lieberman}, we have that
%\begin{equation}\label{eq:nt}
%\begin{split}
%	\|\tilde n\|_{W^{1,2}_q(E_{z_0,2})}
%		&\leq C\left( \|\tilde n\|_{L^q(E_{z_0,4})} + \|\tilde n(1 - m - \tilde \rho)\|_{L^q(E_{z_0,4})}\right)\\
%		&\leq C_T (1 + m(\theta_0+4)) Q(\theta_0-4)
%		\leq C_{T,\epsilon} Q(\theta_0-4)^{1-\epsilon}
%		%\leq C_{T,\epsilon} e^{-\theta_0/\epsilon}.
%\end{split}
%\end{equation}
%Here we used the fact that $\log Q(\theta) \sim \theta \sqrt{m(\theta)}$ - {\color{red} ADD REFERENCE}.  This gives us, in particular, an integral bound of $\partial_t \tilde n$ for any $q\in(1,\infty)$.  However, we want an $L^\infty$ bound.
%
%To pull this up to an $L^\infty$ bound, we notice that $\tilde n_t$ satisfies the equation
%\[
%	(\tilde n_t)_t = \frac{\theta}{\theta_1} (\tilde n_t)_{xx} + (\tilde n_t)_{\theta\theta} + \tilde n_t(1 - m - \tilde \rho) - \tilde n \tilde \rho_t.
%\]
%Applying~\cite[Theorem 7.22]{Lieberman} to $\tilde n_t$, we obtain
%\begin{equation}\label{eq:prelim_nt_strong}
%\begin{split}
%	\|\tilde n_t\|_{W^{1,2}_q(\tilde Q_{z_1,1})}
%		&\leq C \left( \|\tilde n_t\|_{L^q(\tilde Q_{z_1, 2})} + \|\tilde n_t (1 - \alpha \theta^p - \tilde \rho)\|_{L_q(\tilde Q_{z_1,2})} + \|\tilde n \tilde \rho_t\|_{L_q(\tilde Q_{z_1,2})} \right)\\
%		&\leq C \left(C_{T,\epsilon}Q(\theta_0-2)^{1-\epsilon} + \|\tilde n\|_{L^{2q}(\tilde Q_{z_1,2})}\|\tilde \rho_t\|_{L^{2q}(\tilde Q_{z_1,2})}\right)\\
%		&\leq C_T e^{-\frac{2\theta_1^2}{T+1}}\left(1 +\|\tilde \rho_t\|_{L^{2q}(\tilde Q_{z_1,2})}\right).
%\end{split}
%\end{equation}
%Here we used~\eqref{eq:nt} to bound $\|\tilde n_t\|_{L^q(\tilde Q_{z_1,2})}$.  Hence, we require a $L^{2q}$ bound on $\rho_t$.
%
%In order to obtain this, we make the following computation.  First we apply Jensen's inequality to a weighted integral to obtain the bound:
%\[\begin{split}
%	\int_{\tilde Q_{z_1,2}} |\tilde\rho_t(t,x)|^{2q} d\theta dx dt
%		&\leq \int_{t_1 - 4}^{t_1} \int_{x_1 - 2}^{x_1 + 2} \left| \int_{\underline\theta}^\infty \tilde n_t(t,x,\theta)d\theta\right|^{2q} dxdt,\\
%		&\leq \int_{t_1 - 4}^{t_1} \int_{x_1 - 2}^{x_1 + 2} \left| \int_{\underline\theta}^\infty e^{\theta}\tilde n_t(t,x,\theta)\frac{d\theta}{e^\theta}\right|^{2q} dxdt,\\
%		&\leq \int_{t_1 - 4}^{t_1} \int_{x_1 - 2}^{x_1 + 2} \left( \int_{\underline\theta}^\infty e^{2q\theta} |\tilde n_t(t,x,\theta)|^{2q} \frac{d\theta}{e^\theta}\right) dxdt.
%\end{split}\]
%Then we re-arrange the integral to be a sum of integrals over sets $\tilde Q_{z,2}$.
%\[\begin{split}
%	\int_{\tilde Q_{z_1,2}} |\tilde\rho_t(t,x)|^{2q} d\theta dx dt
%		&\leq \int_{t_1 - 4}^{t_1} \int_{x_1 - 2}^{x_1 + 2} \left( \int_{\underline\theta}^\infty e^{2q\theta} |\tilde n_t(t,x,\theta)|^{2q} \frac{d\theta}{e^\theta}\right) dxdt\\
%		&= \int_{t_1 - 4}^{t_1} \int_{x_1 - 2}^{x_1 + 2} \left(\sum_{m=1}^\infty \int_{\underline\theta + 2(m-1)}^{\underline \theta + 2m} e^{(2q-1)\theta} |\tilde n_t(t,x,\theta)|^{2q} d\theta\right) dxdt\\
%		&= \sum_{m=1}^\infty \int_{\tilde Q_{(t_1,x_1,\underline \theta + 2m),2}} e^{(2q-1)\theta} |\tilde n_t(t,x,\theta)|^{2q} d\theta dxdt
%%		&= \int_{t_1 - 4}^{t_1} \int_{x_1 - 2}^{x_1 + 2} \left(\sum_{m=1}^\infty e^{(2q-1)(\underline\theta + 2(m-1)} \int_{\underline\theta + 2(m-1)}^{\underline \theta + 2m} |\tilde n_t(t,x,\theta)|^{2q} d\theta\right) dxdt.
%\end{split}\]
%Now we apply our bound~\eqref{eq:nt} to conclude that
%\[\begin{split}
%	\int_{\tilde Q_{z_1,2}} |\tilde\rho_t(t,x)|^{2q} d\theta dx dt
%		&\leq \sum_{m=1}^\infty  e^{(2q-1)(\underline\theta + 2(m-1)} \int_{\tilde Q_{(t_1,x_1,\underline \theta + 2m),2}} |\tilde n_t(t,x,\theta)|^{2q} d\theta dxdt\\
%		&\leq \sum_{m=1}^\infty  e^{(2q-1)(\underline\theta + 2(m-1)} C_T e^{-\frac{(\underline \theta + 2m)^2}{T+1}}
%		\leq C_T. 
%\end{split}\]
%Plugging this bound back into~\eqref{eq:prelim_nt_strong}, yields
%\[
%	\|\tilde n_t\|_{W^{1,2}_q(\tilde Q_{z_1,1})} \leq C_T e^{-2\frac{\theta_1^2}{T+1}}.
%\]
%Choosing $q$ large enough and applying Morrey's inequality yields
%\[
%	\|\tilde n_t\|_{L^\infty(\tilde Q_{z_1,1})} \leq C_T e^{-2\frac{\theta_1^2}{T+1}}.
%\]
%Since $z_1$ is arbitrary, it is then straight-forward to deduce that
%\[
%	|\tilde n_t(t,x,\theta)| \leq C_T e^{-2\frac{\theta^2}{T+1}}
%\]
%holds for all $(t,x,\theta) \in [0,T]\times \R\times \Theta$, finishing the proof.
%\end{proof}
% 





\section{Proof of \Cref{thm:cauchy_finite}: linear spreading for the Cauchy problem}\label{sec:cauchy_finite}

We first prove the following lower bound on the propagation speed of any initial data.

\begin{lem}\label{lem:finite_speed_lower_bd}
	Under the assumptions of \Cref{thm:cauchy_finite}, there exists $\underline n>0$ such that if $c < c^*$ then %Suppose that $n_0$ is any nonzero initial data.  Let $n$ be the solution to~\eqref{eq:main} with initial data $n_0$.  Then there exists $\underline\rho>0$ such that, for any $c < c^*$, we have that
	\[
		\liminf_{t\to\infty} \inf_{|x| < ct} n(t,x,\underline\theta) \geq \underline n.
	\]
\end{lem}
\begin{proof}%[{\bf Proof of \Cref{lem:finite_speed_lower_bd}}]
Fix $c < c^*$, fix large constants $a,b>0$, and fix $\alpha< 1$ to be determined.  Let $\mu$ be the solution to the slab problem on $(-a,a)\times(\underline\theta,\underline\theta+b)$ given in \Cref{sec:slab} solving
\[
	- c_{a,b} \mu_x - \theta \mu_{\xi\xi} - \mu_{\theta\theta} = \mu(\alpha - m - \nu),
\]
with the boundary conditions used above.  We point out that while \Cref{sec:slab} only proves the existence of $\mu$ for $\alpha = 1$, the general case may obtained similarly.  From the work above, it follows that we may choose $a$ and $b$ sufficiently large and $1-\alpha$ sufficiently small that its speed $c_{a,b} \in (c,c^*]$.  Set $\underline n (t,x,\theta) = A^{-1}\mu(x - c_{a,b}t , \theta)$, where $A$ is a positive constant to be determined.

With this definition, using the elliptic Harnack inequality for $\mu$, we have that $\underline n$ satisfies
\[
	\underline n_t \leq \theta \underline n_{xx} + \underline n_{\theta\theta} + \underline n (\alpha - m - A C_b^{-1} \underline n).
\]
On the other hand, arguing as in the proof of \Cref{thm:acceleration}, we use \Cref{lem:harnack} along with the decay of $n$ to obtain that, for $t\geq 1$,
\[
	n_t \geq \theta n_{xx} + n_{\theta\theta} + n(1 -\epsilon_b - m - C_b n),
\]
where $\epsilon_b$ is a parameter which tends to zero as $b$ tends to $\infty$.  We take $b$ sufficiently large so that $1-\epsilon_b \geq \alpha$.  Choosing $A \geq C_b^2$, we see that $\underline n$ is a sub-solution to $n$ for all $t \geq 1$.  Since $n(1,x,\theta) > 0$ for all $(x,\theta)$, we may choose $A$ sufficiently large that $\underline n(0,x,\theta) \leq n(1,x,\theta)$.  As a result, the maximum principle implies that $\underline n(t,x,\theta) \leq n(t+1,x,\theta)$ for all $t\geq 0$ and all $(x,\theta)$.  Recalling the definition of $\underline n$, we have that, for all $(x,\theta) \in (-a,a)\times(\underline\theta,\underline\theta+b)$,
\[
	A^{-1} \mu(x, \theta) \leq n(t+1, x + c_{a,b}t, \theta).
\]

Arguing as in Step \#3bis in \Cref{thm:acceleration}, we may ``wait'' to remove the dependence on $n(1,\cdot,\cdot)$.  Namely, we may find a constant $\mu_0>0$, independent of $n(1,\cdot,\cdot)$, such that $\mu_0 \leq n(t + t_0, x + c_{a,b} t, \theta)$ for all $(x,\theta) \in (-1,1)\times (\underline\theta, \underline \theta+1)$and $t$ sufficiently large. Evaluating at $\theta = \underline\theta$ finishes the claim.\end{proof}




In addition, we obtain a matching upper bound.

\begin{lem}\label{lem:finite_speed_upper_bd}
	Under the assumptions of \Cref{thm:cauchy_finite}, if $c>c^*$ then
%	Suppose that $n_0$ is any initial data such that $\supp(n_0) \subset (-\infty, x_0)\times [\underline\theta,\theta_0)$ for some $(x_0,\theta_0)$.  Let $n$ be the solution to~\eqref{eq:main} with initial data $n_0$.  Then for any $c < c^*$, we have that
	\[
		\lim_{t\to\infty} \sup_{x > ct,~\theta\in\Theta} n(t,x,\theta) = 0.
	\]
\end{lem}
\begin{proof}%[{\bf Proof of \Cref{lem:finite_speed_upper_bd}}]
%	{\color{blue} I REALIZED WE COULD DO THIS IN A SIMPLER WAY SO I RE-WROTE IT.  OLD VERSION IN COMMENTS.  WE CAN DISCUSS I FYOU WANT TO REVERT TO EARLIER VERSION	
	Fix $c > c^*$ and $c_0 \in (c^*,c)$.  Then there exists $\lambda_0>0$ such that $c_{\lambda_0} = c_0$.  Let $Q_{\lambda_0}$ solve~\eqref{eq:specQlambda} with $c_0$ and $\lambda_0$ as above.  Let $\overline n(t,x,\theta) = C_0 e^{\lambda_0 C_0 - \lambda_0(x-c_0 t)	} Q_{\lambda_0}(\theta)$, where $C_0$ is the constant in~\eqref{eq:n_0}.  Then, by construction, $n_0 \leq \overline n(0,\cdot,\cdot)$ and $\overline n$ satisfies
	\[
		\overline n_t = \theta \overline n_{xx} + \overline n_{\theta\theta} + \overline n(1-m).
	\]
	The maximum principle implies that $n \leq \overline n$. Thus,
	\[
		\lim_{t\to\infty}\sup_{x\geq ct, \theta\in\Theta} n(t,x,\theta)
			\leq \lim_{t\to\infty}\sup_{x\geq ct, \theta\in\Theta} n(t,x,\theta)
			= \lim_{t\to\infty} C_0 e^{\lambda_0 C_0 - \lambda_0(c-c_0)t} \|Q_{\lambda_0}\|_\infty
			= 0,
	\]
	as desired.  This concludes the proof.

%	Fix $c > c^*$.  We may argue as in \Cref{lem:finite_speed_lower_bd}.  Set $\alpha > 1$, $a = b = \infty$ and obtain a travelling wave $\mu$ with speed $c^*_\alpha$.  Again, by taking $\alpha-1$ sufficiently small, we have that $c^*_\alpha \in [c^*,c)$ and define $\overline n(t,x,\theta) = A \mu(x - c^*_\alpha t, \theta)$.  Fix $A$ sufficiently large so that $\overline n(0,x,\theta) \geq n_0(x,\theta)$ for all $(x\theta)$.  Notice that
%	\[
%		n_t - \theta n_{xx} - n_{\theta\theta} \leq n(1-m).
%	\]
%Also notice that, by the Harnack inequality along with the decay in $\theta$, there is a parameter $s> 0$ such that
%	\[
%		\overline n_t - \theta \overline n_{xx} - \overline n_{\theta\theta}
%			\geq \overline n (\alpha - \epsilon_s -m - A^{-1} C_s \overline n),
%	\]
%where $\epsilon_s$ and $C_s$ tend to zero and infinity as $s$ tends to infinity.  Then we may choose $\alpha$, $s$, and $A$ such that $\overline n$ is a super-solution to $n$.  Hence $\overline n \geq n$.  The claim follows from the fact that $\overline n$ moves at a speed $c^*_\alpha < c$ and that $\mu(\xi,\theta) \to 0$ uniformly as $\xi \to \infty$.
\end{proof}

The combination of Lemma~\ref{lem:finite_speed_lower_bd} and Lemma~\ref{lem:finite_speed_upper_bd} yields Theorem~\ref{thm:cauchy_finite}.









\section{Proof of Proposition~\ref{prop:extinction}: Extinction of $n$ when $\gamma_\infty \leq 0$}


\begin{proof}[{\bf Proof of  Proposition~\ref{prop:extinction}}]
Recall that the eigenvector $Q$ is a natural super-solution for $n$. Indeed, let $\overline n(t,x,\theta) = A Q(\theta)e^{\gamma_\infty t}$, where the constant $A$ is chosen such that $n_0 \leq \overline n(0,\cdot,\cdot)$. Then %$\overline n$ satisfies the linear problem:
\begin{equation}\label{eq:lintoads}
\begin{cases}
	\overline n_t = \theta \overline n_{xx} + \overline n_{\theta\theta} + \left( 1 - m \right)  \overline n,\\
	\overline n_\theta(\cdot,\underline\theta) = 0.
	\end{cases}
\end{equation}
By the comparison principle, since $n$ is a sub-solution to  \eqref{eq:lintoads}, we have $n \leq \overline n$, and the conclusion of the proposition follows from the negativity of $\gamma_\infty$ when $\gamma_\infty<0$.

%{\color{red} NEED AN ARGUMENT WHEN RHO ZERO IS ZERO ? Limit in the distributianal sense ? -- the following argument works when u has compact support... probably we can extend it in some way}
When $\gamma_\infty$ is zero, we argue as follows.  Define $v = n/Q$ and notice that $v$ satisfies
\[
	v_t = \theta v_{xx} + \frac{1}{Q^2} (Q^2 v_\theta)_\theta - v\rho.
\]
%Then $\overline u$ is a super-solution to $u$.  By increasing the initial data, if necessary, we may assume that $v_0$ is independent of $x$.  The equation preserves this property for all time so $v$ satisfies
%\[
%	Q^2 v_t = (Q^2 v_\theta)_\theta.
%\]
Multiplying by $Q^2 v$ and integrating the equation above, we have that
\begin{equation}\label{eq:energy}
	\frac{1}{2}\frac{d}{dt}\int Q^2 v^2\, dxd\theta = -\int Q^2\left( \theta |v_x|^2 + |v_\theta|^2\right)\, dx d\theta - \int Q^2 v^2 \rho\, dx d\theta.
	%~~~\text{ and }~~~
	%\frac{d}{dt} \int Q^2 v d\theta = 0.
\end{equation}
It is enough to show that $v$ tends uniformly to zero for bounded $\theta$.  If not, then there are positive constants $\epsilon$ and $H$ and a sequence of times $t_n\to \infty$, places $x_n$, and traits $\theta_n\in(\underline \theta, H)$ such that
\[
	v(t_n,x_n,\theta_n) \geq 2\epsilon.
\]
Using parabolic regularity along with the uniform bound on $n$, Proposition~\ref{prop:uniform_upper_bound}, we can find a $\gamma$, depending only on $u_0$, $H$, and $m$, such that $v \geq \epsilon$ holds on $[t_n, t_n + \gamma]\times [x_n- \gamma, x_n + \gamma]\times [\theta_n - \gamma, \theta_n + \gamma].$ 
%\[
%	[t_n, t_n + \gamma]\times [x_n- \gamma, x_n + \gamma]\times [\theta_n - \gamma, \theta_n + \gamma].
%\]
%Hence, we have that for all $(t,x,\theta) \in [t_n , t_n + \gamma]\times [x_n - \gamma, x_n+\gamma]\times [\theta_n - \gamma, \theta_n + \gamma]$,
%\[
%	v(t,x,\theta)^2\rho(t, x) \geq \gamma \epsilon^3.
%\]
We point out that this clearly implies that $\rho(t,x) \geq 2\gamma \epsilon$ for $(t,x) \in [t_n, t_n + \gamma]\times[x_n - \gamma, x_n + \gamma]$.  The combination of these two facts gives us that
\[
	\int_{t_n}^{t_n+\gamma}\int Q^2 v^2 \rho\, dx d\theta ds
		\geq C_{H,\gamma,m} \gamma^2 \epsilon^3.
\]
Since this inequality is true for all $t\in[t_n,t_n + \gamma]$ for every $n$, we may conclude that
\[
	\lim_{t\to\infty} \int_0^t Q^2 v^2 \rho\, dxd\theta ds
		\geq \sum_{n=1}^\infty \int_{t_n}^{t_n+\gamma}\int Q^2 v^2 \rho\, dx d\theta ds = \infty.
\]
%
%
%BY PAPER OF LENYA'S (BULK BURNING RATE ONE), there is a constant $\delta$ depending on $H$, $\epsilon$, and $m$ such that
%\[
%	\left(\int_{\underline\theta}^H \int_{-\infty}^\infty \left( v_x^2 + v_\theta^2\right) dxd\theta \right)\left(\int_{\underline\theta}^H \int_{-\infty}^\infty v dxd\theta \right) \geq \delta.
%\]
%Using that the weighted $L^1$ norm of $v$ is conserved and that $H$ is finite, this gives us
%\[
%	\int_{\underline\theta}^\infty \int_{-\infty}^\infty Q^2\left(\theta v_x^2 + v_\theta^2\right) dxd\theta \geq C \delta,
%\]
%for all $t \in [t_n, t_n + \gamma]$ for any $n$.
Integrating~\eqref{eq:energy} in time and using the inequality above, we have that
\[
\lim_{t\to\infty}\int Q^2 v^2\, dxd\theta
		\leq \int Q^2 v_0^2\, dxd\theta
		- \lim_{t\to\infty}\int_0^t \int Q^2 v^2 \rho\, dxd\theta ds
		= -\infty.
%\lim_{t\to\infty}\int_{-\infty}^\infty\int_{\underline\theta}^\infty Q^2 v^2 dxd\theta
%		\leq \int_{-\infty}^\infty\int_{\underline\theta}^\infty Q^2 v_0^2 dxd\theta
%		- \lim_{t\to\infty}\int_0^t \int_{-\infty}^\infty\int_{\underline\theta}^\infty Q^2 v^2 \rho dxd\theta ds
%		= -\infty.
\]
This is clearly a contradiction since the left hand side is non negative.
\end{proof}

A natural way to obtain a more precise estimate of the rates of decay when $\gamma_\infty = 0$ is to derive a dedicated Nash-type inequality, as in the case for the heat equation.  %We note that we expect a polynomial decay to zero when $\gamma_\infty =0$ \CH{and with $\rho$ removed from the equation}. A natural way to get this would be to derive a dedicated Nash inequality.
This is out of the scope of the present paper, we do not go further in that direction.  
 
\section{A priori bounds for the Cauchy problem and a Harnack inequality}\label{sec:apriori}

\subsection{The uniform bound on $n$}

In this section, we prove a uniform upper bound of $n$ in $L^\infty$.  %As mentioned aboveThe proof is a significantly shorter and simpler version of the ones appearing in~\cite{BerestyckiMouhotRaoul,Turanova}.  By working in Sobolev spaces and taking advantage of the dependence on scaling in the constants appearing in the standard local parabolic regularity estimates, we are able to sidestep many of the technical difficulties encountered in~\cite{BerestyckiMouhotRaoul,Turanova}.
Before beginning the technical work, we set some notation that is necessary in the sequel.  First, we define the parabolic cylinder 
\[
	\mathcal{C}_R(z_0) \stackrel{\rm def}{:=} (t_0 - R^2,t_0)\times \left\{ (x,\theta): \vert x - x_0 \vert^2 \leq R^2, \vert \theta - \theta_0 \vert^2 \leq R^2  \right\},
\]
where $z_0 = (t_0,x_0,\theta_0)$ and $R$ is any positive constant.  %We point out that the cylinder is stretched in $x$ to accommodate the strength of the diffusion in $x$ of the differential operator.
In general, we may simply refer to $\mathcal{C}_R(z_0)$ as $\mathcal{C}_R$ when no confusion arises.  
Fixing $\delta > 0$, we recall, on this cylinder, the norms
\[\begin{split}
	& [n]_{\delta/2,\delta, \mathcal{C}_R} = \sup_{(t,x,\theta) \neq (s,y,\eta) \in \mathcal{C}_R} \frac{|n(t,x,\theta) - n(s,y,\eta)|}{(|x-y| + |\theta - \eta| + |t-s|^{1/2})^\delta},~~~~~~\text{ and }\\
	%& |n|_{\delta/2,\delta,E} = \|n\|_{L^\infty(Q)} + [n]_{\delta/2,\delta,E},\\
	& [n]_{1+\delta/2,2+\delta, \mathcal{C}_R} = [n_t]_{\delta/2,\delta, \mathcal{C}_R} + \sum_{k+\ell = 2} [\partial_x^k\partial_\theta^\ell n]_{\delta/2,\delta,\mathcal{C}_R}.\\
	%& |n|_{1+\delta/2,2+\delta, E} = \sum_{2j + k + \ell \leq 2} \|\partial_t^j \partial_x^k \partial_\theta^\ell n\|_{L^\infty(Q)} + [n]_{1 + \delta/2,2+\delta, E}.
\end{split}\]
%Finally, we recall the norms
%\[
%	\|n\|_{\delta/2,\delta}
%		= \max_{z} |n|_{\delta/2,\delta,E}
%	~~~ \text{ and } ~~~
%	\|n\|_{1+\delta/2,2+\delta}
%		= \max_{z} |n|_{1+\delta/2,2+\delta,E}.
%\]
We also define the parabolic Sobolev spaces: for any $p \in [1,\infty]$ and $\Omega \subset \R^+ \times \R\times \Theta$, let
\[\begin{split}
	W^{1,2}_p(\Omega) \stackrel{\rm def}{=}
		\left\{ f: \Omega \to \R: \max_{2j + k + \ell \leq 2} \int_{\Omega} |\partial_t^j \partial_x^k \partial_\theta^\ell f|^p dtdxd\theta < \infty \right\}.
\end{split}\]
We endow these with the obvious norm.

%%%%%%
Our starting point for obtaining an $L^\infty$ bound on $n$ is the following bound on the tails of the solution, which is very similar to \Cref{lem:tails} for the travelling waves.
\begin{lemma}\label{lem:tailsevol}
Denote, for any $T>0$, $M_T = \sup_{t\in[0,T]} \|n(t,\cdot,\cdot)\|_{L^\infty\left(\R\times\Theta\right)}$. For any $\delta > 0$, there exists $C_\delta$, depending only on $\delta$ such that $n(t,x,\theta) \leq C_\delta M_T Q_\infty^\delta$.  In addition, $\rho(t,x) \leq CM_T$.
\end{lemma}
\begin{proof}%[{\bf Proof of \Cref{lem:tailsevol}}]

To find a super-solution, define, for $\theta_\delta$ to be chosen later, the function 
\begin{equation*}
	\psi  := \max \left( 1 , \frac{M_T}{\min_{[\underline\theta,\theta_\delta]} Q_\infty^\delta}\right) \, Q_\infty^\delta,
	\quad\text{ on }  \R\times \Theta.
\end{equation*}
%, \left\Vert \frac{n_0}{Q_\infty^\delta} \right\Vert_{L^\infty} 
We have $n \leq \psi$ on $[0,T] \times \R \times [\underline\theta,\theta_\delta]$ by construction. It satisfies
\begin{equation*}
\psi_t  - \theta \psi_{\xi\xi} - \psi_{\theta\theta} - \left( 1 - m \right)\psi  = \left( - \gamma_\infty^\delta + \delta m \right) \psi, \quad \text{ on } [0,T] \times \R \times \Theta.
\end{equation*}
Define $\theta_\delta$ such that $\theta_\delta \geq m^{-1}\left(\delta^{-1}  \gamma_\infty^\delta \right)$ and $n_0(x,\theta) = 0$ for $\theta \geq \theta_\delta$. This definition is possible by \Cref{hyp:m}. The function $\psi$ is then a super-solution of the linearized problem on $[0,T] \times \R \times [\theta_\delta,+\infty)$. Hence the comparison principle implies that $\psi \geq n$ on $[0,T] \times \R \times \Theta$. This finishes the proof of the first claim.  The second claim follows by simply integrating the inequality in $\theta$.
\end{proof}

With \Cref{lem:tailsevol}, we are now in a position to prove the $L^\infty$ bound on $n$~(Proposition~\ref{prop:uniform_upper_bound}).

%\subsection{A uniform $L^\infty$ bound}

\begin{proof}%[{\bf Proof of \Cref{prop:uniform_upper_bound}}]
%In this section, we present a proof of a priori bounds for~\eqref{eq:main}.   
We recall the notation that $M_T = \sup_{t\in[0,T]} \|n(t,\cdot,\cdot)\|_{L^\infty\left(\R\times\Theta\right)}$ and point out that $M_T$ must be finite since a basic upper bound for the equation is given by the super-solution $e^t M_0$.  Hence, we have that, at worst, $M_T \leq e^T M_0$.  Our goal is to obtain a bound on $M_T$ independent of $T$.

A consequence of \Cref{lem:tailsevol} is that the supremum of $n$ can only be approached by points $(t,x,\theta)$ with $\theta$ sufficiently small.  Hence, by parabolic regularity and translation, we may assume that $M_T$ is achieved at some point $(t_T, x_T, \theta_T)$ with $t_T \in[0,T]$, similarly to~\cite[Section~2]{Turanova} and~\cite[Section~7]{BerestyckiMouhotRaoul}.  In addition, we assume that $\theta_T + 4 > \underline\theta$ in order to avoid complications due to the boundary; however, such complications may be easily dealt with by a simple reflection procedure outlined in~\cite{BerestyckiMouhotRaoul,Turanova}.

We assume without loss of generality that $t_T \geq 5$.  Then %Since $(t_T,x_T, \theta_T)$ is the location of a maximum, then
\begin{equation*}
	0 \leq n_t - \theta_T n_{xx} - n_{\theta\theta}
		= n(1 - m(\theta_T) - \rho) \leq n(1 - \rho).
\end{equation*}
at the point $(t_T,x_T,\theta_T)$, since this is the location of a maximum. Thus, $\rho(t_T,x_T) \leq 1$.

Fix any $p \in (1,\infty)$, and local parabolic regularity results, see e.g.~\cite[Theorem 7.22]{Lieberman}, give
\[
	\|n\|_{W^{1,2}_p\left( \mathcal{C}_1(z_T) \right)}
		\leq C\left( \|n\|_{L^p\left( \mathcal{C}_2(z_T) \right)} + \|n(1 - m -\rho)\|_{L^p\left( \mathcal{C}_2(z_T) \right)}\right)
		\leq C(M_T + M_T^2),
\]
where we used~\Cref{lem:tailsevol} to bound $\rho$.  We point out that the constant $C$, above, depends only on $p$ and $m$.  
%Using this, we have that
%\[
%	\|n\|_{W^{1,2}_p\left( \mathcal{C}_1(z_T) \right)} \leq C (M_T + M_T^2).
%\]
With $p$ large enough, we obtain via Sobolev embedding that for any $\delta > 0$,
\[
	[n]_{C^{(1+\delta)/2,1+\delta}(\mathcal{C}_1)} \leq C (M_T + M_T^2).
\]
Applying the Gagliardo-Nirenberg interpolation inequality to $\theta \mapsto n \left( t_T,x_T, \cdot \right)$, we obtain
\begin{equation*}
\| n \left( t_T,x_T, \cdot \right) \|_{L^\infty_\theta\left(\mathcal{C}_1(\theta_T)\right)} \leq C \| n \left( t_T,x_T, \cdot \right) \|_{L^1_\theta\left(\mathcal{C}_1(\theta_T)\right)}^{\frac{1+\delta}{2+\delta}} \left[ n \left( t_T,x_T, \cdot \right) \right]_{C^{1+\delta}_\theta\left(\mathcal{C}_1(\theta_T)\right)}^{\frac{1}{2+\delta}}.
\end{equation*}
Since $\| n \left( t_T,x_T, \cdot \right) \|_{L^\infty_\theta\left(\mathcal{C}_1(\theta_T)\right)} = M_T$ and $\| n \left( t_T,x_T, \cdot \right) \|_{L^1_\theta\left(\mathcal{C}_1(\theta_T)\right)} \leq \rho(t_T,x_T) \leq 1$, we obtain that
\begin{equation*}
M_T \leq C \left( M_T + M_T^2 \right)^{\frac{1}{2+\delta}}.
\end{equation*}
This clearly gives a bound on $M_T$ since $2/(2+\delta) < 1$.  The bound on $\rho$ follows from the combination of this bound and \Cref{lem:tailsevol}.
\end{proof}



\subsection{Comparing $\rho$ and $n$ via a local-in-time Harnack inequality}

With \Cref{lem:tailsevol} and Proposition~\ref{prop:uniform_upper_bound} in hand, we may now state the following Harnack inequality which allows us to compare solutions of the local and nonlocal problems.
\begin{proof}[{\bf Proof of \Cref{lem:harnack}}]
First, using~\Cref{lem:tailsevol} along with the uniform bound from Proposition~\ref{prop:uniform_upper_bound}, we note that $n \leq CMQ_\infty^\delta$.  Fix $R_1 \geq R$ such that $\int_{R_1}^\infty CMQ_\infty^\delta d\theta\leq \epsilon/2$.  Now, by arguing as in~\cite[Theorem~2.6]{AlfaroBerestyckiRaoul}, we may find $C_{R_1,\epsilon,t_0}$ such that, for all $t\geq t_0$,
\[
	\sup_{|x-x_0|, \theta-\underline\theta < R_1} n(t,x,\theta)
		\leq C_{R_1,\epsilon,t_0} \inf_{|x-x_0|, \theta-\underline\theta < R_1} n(t,x,\theta) + \epsilon/(2R_1).
\]
Since the proof in our setting is a straightforward adaptation, we omit it.  Then,
\[\begin{split}
	\rho(t,&x_0) \leq \int_{\underline\theta}^{R_1} \sup_{|x-x_0|, \theta - \underline\theta < R_1} n(t,x,\theta)d\theta + \int_{R_1}^\infty n(t,x,\theta) d\theta\\
		&\leq R_1 C_{R_1,\epsilon} \inf_{|x-x_0|, \theta-\underline\theta < R_1} n(t,x,\theta) + \frac{\epsilon}{2} + \int_{R_1}^\infty CMQ_\infty^\delta d\theta
		\leq R_1 C_{R_1,\epsilon} \inf_{|x-x_0|, \theta-\underline\theta < R} n(t,x,\theta) + \epsilon.
\end{split}\]
This concludes the proof.
\end{proof}






\appendix

\numberwithin{equation}{section}

\section{Appendix: Applying the results of Li-Yau}\label{sec:appendix}


\subsubsection*{Obtaining the bound used in~\Cref{lem:Li_Yau}}

In this section, we briefly describe how to apply the heat kernel bounds of Li-Yau.  To begin, we compute the scalar curvature of $\R\times \Theta$ endowed with the metric $g$ given by~\eqref{eq:metric}.  The scalar curvature, $R$, is defined to be
\[
	R = g^{ij} \left( \partial_k \Gamma_{ij}^k - \partial_j \Gamma_{ik}^j + \Gamma_{ij}^\ell\Gamma_{k\ell}^k - \Gamma_{ik}^\ell\Gamma_{j\ell}^k\right),
\]
where we use Einstein summation notation, i.e.~repeated indices are implicitly summed over.  Here $g^{ij}$ is the $(i,j)$ entry in $g^{-1}$ and $\Gamma_{ab}^c$ is the Christoffel symbol given by the formula
\[
	\Gamma_{ab}^c = \frac{1}{2} g^{ck} \left( \partial_b g_{ka} + \partial_a g_{kb} - \partial_k g_{ab}\right).
\]
It is straightforward to compute that $\Gamma_{11}^1 = \Gamma_{22}^i = \Gamma_{12}^2 = \Gamma_{21}^2 = 0$, that $\Gamma_{12}^1 = \Gamma_{21}^1 = - 1/2\theta$ and that $\Gamma_{11}^2 = 1/2\theta^2$.  Plugging this into the equation for $R$, we see that $R = -2/\theta^2$.  For surfaces, the Ricci and scalar curvatures are equivalent up to a multiplicative factor.  Hence, the above computations bound the Ricci curvature from below.
%we obtain
%\[
%	R = -\frac{2}{\theta^2} \geq - \frac{2}{\underline\theta^2}.
%\]
Hence, $R$ is bounded uniformly below by a constant $-\underline R$, where we set $\underline R = 2/\underline\theta^2$.

We now show how to obtain \Cref{lem:Li_Yau} from the results of \cite{LiYau}.  In our setting, the statement of~\cite[Corollary~3.2]{LiYau}\footnote{Strictly speaking, this result is only valid for a complete Riemannian manifold without boundary.  See below for a discussion of the adaptations to the proof to obtain the result in our setting.} %\footnote{{Strictly speaking, this result is valid only for a complete Riemannian manifold without boundary. However, slight changes to the proof of \cite[Lemma~3.1]{LiYau}, from which \cite[Corollary~3.2]{LiYau} follows, handles the case of a flat boundary with Neumann boundary conditions.}}
is that, for any $\bar a >0$, %since there is a constant $\gamma_0$ such that
%\[
%	|m'(\theta)|
%		\leq \gamma_0,
%		\qquad \text{ and }\qquad
%	m''(\theta) \leq \gamma_0,
%\]
%then
there exists a positive constant $C_0$, depending only on $\|m'\|_\infty$, $\|m''\|_\infty$, $\underline R$, and $\bar a$, such that
\begin{equation}\label{eq:prelim_heat_kernel_bound}
	G(t,x,\theta, 0, \underline\theta)
		\leq \frac{C_0}{\sqrt{\Vol(S_{\bar a t}(t,x,\theta)) \Vol(S_{\bar a t}(t,0,\underline\theta))}} \exp \left\{ C_0t - \frac{4}{5} \zeta(t,x,\theta) \right\}.
\end{equation}
Here, for any $z$, $\eta$, and $s$, $S_{a}(s,z,\eta) := \left\{(z',\eta') \in \R\times \overline{\Theta} : \zeta(s,z,\eta,z',\eta') \leq a \right\}$.  To arrive at this, we take, in their notation, $\epsilon = 1/4$, $\alpha = 2$, $\theta = \max\{\|m'\|_\infty, \|m''\|_\infty\}$, and $a = \bar at$. % and we absorb $\gamma_0$ into the constant $C_0$.
 In addition, what we refer to as $\zeta$, $G$, $\underline R$, and $m$, they refer to as $\rho$, $H$, $K$, and $q$, respectively.  To finish, we need only show that $\Vol(S_{\bar a t}(x,\theta,t))\Vol(S_{\bar a t}(0,\underline\theta,t))$ is uniformly bounded from below.

\begin{lemma}\label{lem:volume}
There exists $\bar a$ and $t_0 > 0$ such that for any $t>t_0$, $x\in\R$ and $\theta \leq \eta_{\gamma_\infty+1}(t)$, $
\Vol(S_{\bar a t}(t,x,\theta))$ and $\Vol(S_{\bar a t}(t, 0,\underline\theta))$
are bounded away from zero.
\end{lemma}

\begin{proof}%[{\bf Proof of \Cref{lem:volume}}]
Let $B_1(0,\underline \theta) = \{(x,\theta) \in \R\times\Theta: x^2 + (\theta-\underline\theta)^2 < 1\}$.  For any $\overline a \geq 1$ and any $t$ sufficiently large, we have that%
%
%
\footnote{To see this fix any $(x,\theta) \in B_1(0,\underline\theta)$ and define $Z(s) = (x\max\{1-s,0\}, \max\{\underline\theta, \theta(1-s) + s\underline\theta\})$.  Notice that $\int_0^t (\dot Z_1^2/4Z_2 + \dot Z_2^2/4 + m(Z_2)) ds \leq x^2/4\underline \theta + (\theta-\underline\theta)^2/4 + \max_{B_1(0,\underline\theta)}m \ll \overline a t$.}
%
 $B_1(0,\underline \theta) \subset S_{\bar a t} (t,0,\underline \theta)$.  Hence we have that $\Vol(S_{\bar a t}(t,0,\underline \theta)) \geq \Vol(B_1(0,\underline \theta))$. Since $\Vol(B_1(0,\underline \theta)) > 0$, $\Vol(S_{\bar a t}(t,0,\underline\theta))$ is uniformly bounded from below for all $t$ sufficiently large.% Clearly, the metric $g$ is bounded away from $0$ and $\infty$ on $B_1(0,\underline \theta)$.  This implies that $g$ and the Euclidean distance are comparable on $B_1(0,\underline \theta)$, which, in turn, implies that $\Vol(B_1(0,\underline\theta)) \geq 1/C$ for some constant $C>0$.  Hence, we have that $\Vol(S_{\bar a t}(0,\underline\theta, t)) \geq 1 / C$ for all $t$ sufficiently large.


% It is easy to check that the second inequality holds for sufficiently large $t$ since, clearly, $B_{1}(0,\underline\theta) \subset S_{\bar a t}(0,\underline\theta,t)$ and by observing that the metric $g$ is bounded away from $\infty$ and $0$ uniformly on any set that is bounded in $\theta$, which implies that the volume under the metric $g$ and the Lebesgue measure are comparable.
  

%We now choose $a = At$ with $A$ to be determined.  Recall that we restrict to the case when $\theta \leq \eta_{\gamma_\infty + 1}(t)$.  

We now obtain the bound on $\Vol(S_{\bar a t}(t,x,\theta))$.  Fix $\theta_1$ to be determined.  If $\theta \in [\underline\theta, \theta_1 + 1)$, then we argue as in the previous paragraph to obtain a lower bound on $\Vol(S_{\bar a t}(t,x,\theta))$.  Hence, we may assume that $\theta > \theta_1+1$.  The claim now follows by showing that $(x-t,x+t)\times (\theta_1,\theta_1+1) \subset S_{\bar a t}(t,x,\theta)$, for $\theta_1$ sufficiently large, though independent of $t$.

%In order to show the second inequality we first observe that it clearly follows if $\theta \leq \underline\theta+1$.  Hence, we may assume that $\theta > \underline\theta+1$.  The claim now follows by showing that $(x-t,x+t)\times (\theta_1,\theta_1+1) \subset S_{\bar a t}(x,\theta,t)$, for a sufficiently large $\theta_1 > 0$.  

Indeed, fix $(x',\theta')\in (x-t,x+t)\times(\theta_1,\theta_1+1)$, and let $Z(s) = (Z_1(s), Z_2(s))$ where 
\begin{equation*}
Z_1(s) = x' +\frac{s}{t}(x-x'),
\end{equation*}
and $Z_2$ solves 
\begin{equation*}
Z_2(s) = \theta', \quad \text{ if } s \in [0,s_t]
\qquad \text{and} \qquad
\begin{cases}
\dot Z_2 =  2 \sqrt{m(Z_2(s))},\\
Z_2(t)=\theta, \quad Z_2(s_t) = \theta',
\end{cases}
\text{ if } s\in[s_t,t].
\end{equation*}
%$$ for $$, where $Z_2(0) = \theta$ and $s_0$ is defined to be the unique time that $Z_2(s_t) = \theta'$.  First, notice that%we claim that $s_t \ll 1$ as $t$ tends to infinity.  This can be seen by the computation
Such a trajectory is reasonable since it solves the Euler-Lagrange equations on $[s_t,t]$. However, it is not the optimal trajectory in $\theta$ since we cannot ensure that $s_t = t$, but this is not a problem for our purposes. %Notice that the unique time $s_t$ such that $Z_2(s_t) = \theta'$ is given by
We note that $s_t\geq 0$ exists since
%\begin{align*}
%	s_t = \int_0^{s_t} \frac{-\dot Z_2}{2\sqrt{m(Z_2)}} ds 
%		= \int_{\theta'}^\theta \frac{d\eta}{2\sqrt{m(\eta)}}
%		&\leq \int_{\theta'}^{\tilde\theta} \frac{d\eta}{2\sqrt{m(\eta)}} +  \int_{\tilde\theta}^\theta \frac{\sqrt{m(s)} }{2m(\tilde\theta)} \, ds \\
%		&\leq C + \frac{\Phi(\eta_{\gamma_\infty+1}(t))}{2 m(\tilde\theta)} \leq t
%\end{align*} 
\begin{equation}
\begin{split}
	t-s_t = \int_{s_t}^t \frac{\dot Z_2}{2\sqrt{m(Z_2)}} ds 
		= \int_{\theta'}^\theta \frac{d\eta}{2\sqrt{m(\eta)}}
		\leq\int_{0}^\theta \frac{\sqrt{m(s)} }{2m(\theta_1)} \, ds
		\leq \frac{\Phi(\eta_{\gamma_\infty+1}(t))}{2 m(\theta_1)} \leq \frac{(\gamma_\infty+1)t}{2m(\theta_1)} \leq t,
\end{split}
\end{equation}
where we have used the restriction $\theta \leq \eta_{\gamma_\infty+1}(t)$ and where the last inequality follows by possibly increasing $\theta_1$.
%if $\tilde\theta$ is sufficiently large. 
We also used that $Z_2$ is increasing on $[s_t,t]$.
%\CH{Hence $s_t$ tends to zero as $t$ tends to infinity.} 
%We may then define
%\[
%	Z(s) = \left( \frac{(s-s_t) x'}{t-s_t} + \frac{(t-s) x}{t-s_t} ,\theta'\right)
%\]
%for $s\in[s_t, t]$.  

We now estimate $\zeta$ to show that $(x',\theta') \in S_{\overline a t}(t,x,\theta)$.  Indeed, 
\begin{equation}\label{eq:appendix1}
\begin{split}
\zeta&(t,x,\theta,x',\theta')
	\leq \int_0^t \left[\frac{\dot Z_1^2}{4 Z_2} + \frac{\dot Z_2^2}{4} + m(Z_2) \right] ds\\
	&\leq \int_{0}^t \frac{1}{4 \underline\theta} \left( \frac{x'-x}{t} \right)^2 ds + \int_0^{t} \left[ \frac{\dot Z_2^2}{4} + m(Z_2) \right] ds
	\leq \frac{t}{4 \underline\theta} + \int_0^{t} \left[ \frac{\dot Z_2^2}{4} + m(Z_2) \right] ds.
\end{split}
\end{equation}

It remains to estimate the second term in~\eqref{eq:appendix1}:
\begin{multline*}
\int_0^{t} \Big[ \frac{\dot Z_2^2}{4} + m(Z_2) \Big] ds
	= \int_0^{s_t} m(\theta') \, ds + 2\int_{s_t}^{t} m(Z_2) \,ds
	= \int_0^{s_t} m(\theta') \,ds + \int_0^{s_t} \dot Z_2 \sqrt{m(Z_2)} \, ds\\
	= s_t m(\theta') + \int_{\theta'}^{\theta} \sqrt{m(s)} ds
	\leq m(\theta_1 + 1) t + \Phi( \eta_{\gamma_\infty}(t))
	= \left( m(\theta_1 + 1) + \gamma_\infty + 1\right)t.
\end{multline*}
Choosing $\bar a = m(\theta_1+1) + \gamma_\infty + 1 + (4\underline \theta)^{-1}$,
%when $\theta_1$ is sufficiently small, since $m(\underline\theta)=0$ and $m$ is continuous on $\Theta$.
%
%\[
%	\zeta(t,x,\theta,x',\theta') \leq \int_0^t \left[\frac{\dot Z_1^2}{4 Z_2} + \frac{\dot Z_2^2}{4} + m(Z_2) \right] ds \leq \frac{1}{4(t-s_t)} + \Phi(\theta) \leq (\gamma_\infty + 3)t.
%\]
we conclude that $(x',\theta') \subset S_{\overline a t}(t,x,\theta)$.  Hence, $(x-t,x+t) \times (\theta_1, \theta_1 +1)\subset S_{\bar a t}(t,x,\theta)$, implying that $\Vol(S_{\bar a t}(t,x,\theta)) \geq O(1)$.
\end{proof}

Plugging this into~\eqref{eq:prelim_heat_kernel_bound} yields the bound in \Cref{lem:Li_Yau}.
%\[
%	G(t,x,\theta, 0, \underline\theta)
%		\leq \exp \left\{ Ct - \frac{4}{5} \zeta(t,x,\theta) \right\}.
%\].









\subsubsection*{Discussion of the role of the boundary in \cite[Corollary 3.2]{LiYau}}


While the effect of having a boundary is quite well-understood (see, for example, \cite{Wang}), since the analogue of  \cite[Corollary 3.2]{LiYau} is not explicitly stated in~\cite{Wang}, we briefly outline how to modify the arguments of Li and Yau to obtain it in our setting. In this discussion only, we adopt their notation (the notable changes are that $n$ is denoted $u$, $m$ is denoted $q$, and $\zeta$ is denoted $\rho$).

We begin by noticing that, since we are seeking an upper bound on the propagation in terms of $\int_{\underline\theta}^\theta q(s)ds$, we may assume, without loss of generality, that $q_\theta(\underline\theta) = 0$.  Indeed, if this is not the case, we may replace $q$ with $\tilde q = \chi q$ where $\chi$ is any smooth function satisfying $\chi(\theta) = 1$ if $\theta > \underline \theta + 1$, $\chi(\theta) \in(0,1]$ if $\theta > \underline\theta$, and $\chi(\underline\theta) = 0$.  Since this only {\em increases} the 0th order coefficient $(1-q)$, an upper bound for solutions of the equation with $\tilde q$ in place of $q$ provides an upper bound for solutions of the equation with $q$.  Further, $\tilde q_\theta(\underline\theta) = 0$ and $\int_{\underline\theta}^\theta \tilde q(s) ds = \int_{\underline\theta}^\theta q(s) ds + O(1)$.

The first step in obtaining their Corollary 3.2 in our setting is their Theorem 1.3, which gives a differential inequality for $u$ when there is no boundary.  The proof follows from the work in their Theorem 1.2, which we discuss now.  The key idea is to define a function $F$ in terms of $\log u$ and apply the maximum principle to it.  If the maximum of $F$ is in the interior of the manifold, their argument applies directly;  that is, after choosing a parameter $\alpha>0$ carefully, the upper bound comes directly from the fact that, at the maximum, $F_t - \Delta F \leq 0$, along with some computations.  On the other hand, we rule out the maximum occuring on the boundary with the following proof by contradiction.  The Hopf maximum principle implies that, if the maximum were on the boundary, $\partial_n F > 0$, where $n$ is the outward normal vector.  Then, following the computation in their Theorem 1.1, we obtain $\partial_n F = -2 II(\nabla \log u, \nabla \log u) - \alpha t\partial_n q$, where $II$ is the second fundamental form.  This is the equation below (1.6) in~\cite{LiYau}, where the $\partial_n q$ term is an additional term arising in our setting.   In view of paragraph above, $\partial_n q=0$.   Also, as in their setting, we observe that $II\geq 0$.  To see this, we point out that our domain is geodesically convex, i.e.~all geodesics remain within the domain.  This is a consequence of~\cite[Lemma A.2.(iii)]{HendersonPerthameSouganidis}, which shows that the geodesics, denoted $\gamma$, have positive second coordinate; heuristically, it is true since the metric $g$ rewards paths with large $\theta$.  A consequence of the geodesic convexity is that $II \geq 0$.  We conclude that $\partial_n F \leq 0$, which is a contradiction.  Hence, the conclusion of Theorem 1.3 holds in our setting.

The second step is in obtaining Theorem 2.2, a Harnack inequality, from Theorem 1.3.  Since the proof does not ``see'' the boundary and uses only Theorem 1.3, which we have outlined how to obtain in our setting, it follows that Theorem 2.2 holds in our setting as well.

The third step is to obtain Lemma 3.1, an equation for the action $\zeta$.  This is standard in the Hamilton-Jacobi and physics literature.  Since $q_\theta = 0$ and since the metric $g$ rewards paths with larger $\theta$, it is easy to check that any minimizing path of the action, $\zeta$, does not touch the boundary $\R\times\{\underline\theta\}$.  Hence, the standard arguments apply and the identity in Lemma 3.1 holds.

From here, they use Lemma 3.1 to obtain Lemma 3.2.  Then they apply all the above-mentioned results to obtain Theorem 3.1, from which the result that we use, Corollary 3.2, follows.  In each of these steps, the boundary plays no role.  Hence, the conclusion of Corollary 3.2 holds in our setting.














\bibliographystyle{abbrv}
\bibliography{refs-tradeoff}
%\bibliographystyle{plain}








%
%\begin{thebibliography}{100}
%
%%\bibitem{Adams} 
%%Adams, Robert A. and Fournier, John J. F., {\em Sobolev spaces}, Pure and Applied Mathematics (Amsterdam), Elsevier/Academic Press, Amsterdam, 2003.
%		
%%\bibitem{Alfaro} 
%%M. Alfaro, J. Coville, and G. Raoul. {\em travelling waves in a nonlocal equation as a model for a population structured by a space variable and a phenotypical trait}. To appear in Comm. Partial Differential Equations.
%
%%\bibitem{Arnold}
%%A. Arnold, L. Desvillettes and C. Prevost, {\em Existence of nontrivial steady states for populations
%%structured with respect to space and a continuous trait}, Comm. Pure Appl. Anal.
%%{\bf11} (2012), no. 1, 83–96.
%
%%\bibitem{Aronson}
%%D. G. Aronson and H. F. Weinberger, {\em Multidimensional nonlinear diffusion arising in
%%population genetics}, Adv. in Math. 30 (1978), no. 1, 33–76.
%%
%%\bibitem{Benichou}
%%O. Benichou, V. Calvez, N. Meunier and R. Voituriez, {\em Front acceleration by dynamic
%%selection in Fisher population waves}, Phys. Rev. E 86, 041908 (2012).
%
%%\bibitem{Berestycki-Chapuisat}
%%H. Berestycki and G. Chapuisat, {\em travelling fronts guided by the environment for reaction-diffusion equations}, preprint arXiv:1206.6575.
%
%%\bibitem{Berestycki-Hamel}
%%H. Berestycki and F. Hamel, {\em Generalized transition waves and their properties}, Comm. Pure Appl. Math. 65, (2012), no. 5, 592–648.
%
%%\bibitem{Bouin-Mirrahimi}
%%E. Bouin, S. Mirrahimi, {\em A Hamilton-Jacobi approach for a model of population structured by space and trait}, preprint arXiv:1307.8332, 2013.
%
%%\bibitem{BerestyckiMouhotRaoul}
%%N.~Berestycki, C.~Mouhot, G.~Raoul, {\em Existence of self-accelerating fronts for a nonlocal reaction-diffusion equations}, preprint arXiv:1512.00903, 2015.
%
%\bibitem{Berestycki-Nadin}
%H. Berestycki, G. Nadin, B. Perthame and L. Ryzhik, {\em The nonlocal Fisher-KPP equation:
%travelling waves and steady states}, Nonlinearity {\bf 22} (2009), no. 12, 2813–2844.
%
%%\bibitem{Bouin}
%%E. Bouin, V. Calvez, N. Meunier, S. Mirrahimi, B. Perthame, G. Raoul, and R. Voituriez. {\em Invasion fronts with variable motility: phenotype selection, spatial sorting and wave acceleration}. C. R. Math. Acad. Sci. Paris, 350(15-16):761–766, 2012.
%
%%\bibitem{Bouin-2}
%%E. Bouin, {\em Revisiting the WKB approach for front propagation in kinetic equations}. In preparation.
%
%\bibitem{BouinCalvez}
%E. Bouin, V. Calvez, {\em A kinetic eikonal equation}, C. R. Math. Acad. Sci. Paris {\bf 350} (2012), 243--248.
%
%\bibitem{BouinCalvez-Nadin}
%E. Bouin, V. Calvez, G. Nadin, {\em Front propagation in a kinetic reaction-transport equation}, preprint arXiv:1307.8325, 2013.
%
%\bibitem{BouinCalvez-Nadin-2}
%E. Bouin, V. Calvez, G. Nadin, {\em Hyperbolic travelling waves driven by growth}, To appear in M3AS, 2013.
%
%\bibitem{Bouin-Mirrahimi}
%E. Bouin, S. Mirrahimi, {\em A Hamilton-Jacobi approach for a model of population structured by space and trait}, preprint arXiv:1307.8332, 2013.
%
%\bibitem{Champagnat}
%N. Champagnat et S. Méléard, {\em Invasion and adaptive evolution for individual-based spatially structured populations}, J. Math. Biol. 55 (2007), no. 2, 147–188.
%
%\bibitem{Coville-Davila}
%J. Coville, J. Dávila and S. Martínez, {\em Pulsating fronts for nonlocal dispersion and KPP nonlinearity},  Ann. Inst. H. Poincaré Anal. Non Linéaire 30 (2013), no. 2, 179–223.
%
%\bibitem{Coville-Dupaigne}
%J. Coville and L. Dupaigne, {\em On a nonlocal reaction diffusion equation arising in population dynamics}, Proc. Roy. Soc. Edinburgh Sect. A 137 (2007), no. 4, 727–755.
%
%\bibitem{Desvillettes}
%L. Desvillettes, R. Ferrière et C. Prévost, {\em Infinite dimensional reaction-diffusion for
%population dynamics}, preprint CMLA (2004).
%
%\bibitem{Dockery}
%J. Dockery, V. Hutson, K. Mischaikow, M. Pernarowski, {\em The evolution of slow dispersal rates: a reaction diffusion model}, J. Math. Biol. 37 (1) (1998) 61–83.
%
%\bibitem{Ferriere} 
%N. Champagnat, R. Ferrière, S. Méléard, {\em From individual stochastic processes to macroscopic models in adaptive evolution}, Stoch. Models 24 (Suppl. 1)
%(2008) 2–44.
%
%\bibitem{Fisher}
%R.A. Fisher, {\em The advance of advantageous genes}, Ann. Eugenics {\bf 65} (1937), 335--369.
%
%\bibitem{Gilbarg}
%Gilbarg, David, and Trudinger, Neil S., {\em Elliptic partial differential equations of second order}, Springer Berlin ; New York, 1998.
%
%\bibitem{Hamel}
%F. Hamel, L. Ryzhik, {\em On the nonlocal Fisher-KPP equation: steady states, spreading speed and global bounds}, preprint  http://arxiv.org/abs/1307.3001.
%
%\bibitem{Kato} 
%T.~Kato, {\em Perturbation theory for linear operators}, {Classics in Mathematics}, {Reprint of the 1980 edition}, {Springer-Verlag, Berlin}, {1995}.
%      
%\bibitem{Kokko} 
%H. Kokko, A. López-Sepulcre, {\em From individual dispersal to species ranges: perspectives for a changing world}, Science 313 (5788) (2006) 789–791.
%
%\bibitem{Lieberman}
%G.~M.~Lieberman, {\em Second order parabolic differential equations}, World Scientific Publishing Co., Inc., River Edge, NJ, 1996.
%%     PAGES = {xii+439},
%
%
%\bibitem{Kolmogorov}
%A.N. Kolmogorov, I.G. Petrovsky,  N.S. Piskunov, {\em Etude de l'\'equation de la 
%diffusion avec croissance de la quantit\'e de mati\`ere et son application \`a un probl\`eme biologique}, Moskow Univ. Math. Bull. {\bf 1} (1937), 1--25.
%
%\bibitem{Krylov_Holder}
%N.~V.~Krylov, {\em Lectures on elliptic and parabolic equations in Sobolev spaces}. Graduate Studies in Mathematics, 96. American Mathematical Society, Providence, RI, 2008.
%
%\bibitem{Nadin}
%G. Nadin, {\em travelling fronts in space-time periodic media}, J. Math. Pures Appl. (9) 92 (2009), no. 3, 232–262.
%
%\bibitem{Nolen}
%J. Nolen and L. Ryzhik, {\em travelling waves in a one-dimensional heterogeneous medium}, Ann. Inst. H. Poincaré Anal. Non Linéaire 26 (2009), no. 3, 1021–1047.
%
%\bibitem{Perthame}
%B. Perthame, {\em Transport Equations in Biology}, Frontiers in Mathematics, Birkh{\"a}user Basel, 2007.
%
%\bibitem{Phillips} 
%B.L. Phillips, G.P. Brown, J.K. Webb, R. Shine, {\em Invasion and the evolution of speed in toads}, Nature 439 (7078) (2006) 803.
%
%\bibitem{Ronce}
%O. Ronce, {\em How does it feel to be like a rolling stone? Ten questions about dispersal evolution}, Annu. Rev. Ecol. Syst. 38 (2007) 231–253.
%
%\bibitem{Shen}
%W. Shen and A. Zhang, {\em travelling wave solutions of spatially periodic nonlocal monostable
%equations}, ArXiv e-prints, (2012). http://arxiv.org/abs/1202.2452
%
%\bibitem{Shine}
%R. Shine, G.P. Brown, B.L. Phillips, {\em An evolutionary process that assembles phenotypes through space rather than through time}, Proc. Natl. Acad. Sci. USA 108 (14) (2011) 5708–5711.
%
%\bibitem{Simmons}
%A.D. Simmons, C.D. Thomas, {\em Changes in dispersal during species’ range expansions}, Amer. Nat. 164 (2004) 378–395.
%
%\bibitem{Thomas}
%C.~D.~Thomas and E.~J.~Bodsworth and R.~J.~Wilson and A.~D.~Simmons and Z.~G.~Davies and M.~Musche and L.~Conradt, {\em Ecological and evolutionary processes at expanding range margins}, Nature {\bf 411}, 577-581 (2001).
%
%\bibitem{Turanova}
%O.~Turanova, {\em On a model of a population with variable motility}, Math.~Models Methods Appl.~Sci., {\bf 25}, (2015), no.~10, 1961-2014.
%
%\bibitem{Xin}
%J. Xin, {\em Front propagation in heterogeneous media}, SIAM Rev. 42, (2000), no. 2, 161–230.
%
%
%
%\end{thebibliography}








%
%\section*{Appendix B: Proof of the interpolation estimate.}
%
%We prove here the interpolation estimate which is needed in {\bf \# Step 2} of the proof of Lemma \ref{lem:nc}. Since $\theta$ is the only variable playing a role here, we denote $g(\theta) = n(t,x,\theta)$. Let $(\theta,\theta') \in \Theta^2$. For technical reason, we impose $|\theta-\theta'|^{-1}\geq e^4$. We set $K = |\theta-\theta'|^{-1}$. We first prove a H\"older-like estimate,
%\begin{equation*}
%\vert g(\theta) - g(\theta') \vert \leq \frac12 \|g\|_{H^{3/2}}|\theta - \theta'|\log\left(|\theta - \theta'|^{-1}\right)\, .
%\end{equation*}
%For this purpose, we use Fourier expansions. We recall the definition of the fractional Sobolev norm 
%\begin{equation*}
%\Vert f \Vert_{H^{\frac32}} = \left( \sum_{k\in\Z^*} |k|^3  |\hat f(k)|^2 \right)^{1/2},
%\end{equation*}
%where $\hat f$ is the Fourier transformation of $f$. We then have
%\begin{align*}
%|g(\theta) - g(\theta')| &  \leq \sum_{|k|\leq K} |\hat g(k)|\left|  e^{ik\theta} - e^{ik\theta'}\right| +  \sum_{|k|> K} |\hat g(k)|\left|  e^{ik\theta} - e^{ik\theta'}\right|  \\
%& \leq \sum_{|k|\leq K}   |k| |\hat g(k)| |\theta - \theta'| + 2 \sum_{|k|> K}|\hat g(k)|\\  
%& \leq |\theta - \theta'| \sum_{|k|\leq K}  |k|^{3/2}  |\hat g(k)| |k|^{-1/2} + 2 \sum_{|k|> K} |k|^{3/2}|\hat g(k)||k|^{-3/2} \\
%& \leq |\theta - \theta'| \left( \sum_{k\in\Z^*} |k|^3  |\hat g(k)|^2 \right)^{1/2} \left( \sum_{|k|\leq K} |k|^{-1}   \right)^{1/2} + 2 \left( \sum_{k\in\Z^*} |k|^3  |\hat g(k)|^2 \right)^{1/2} \left( \sum_{|k|> K} |k|^{-3}   \right)^{1/2}\\
%& \leq \|g\|_{H^{3/2}} \left( |\theta - \theta'| \left( \sum_{|k|\leq K} |k|^{-1}   \right)^{1/2} + 2\left( \sum_{|k|> K} |k|^{-3}   \right)^{1/2} \right)\\
%& \leq \|g\|_{H^{3/2}} \left(  |\theta - \theta'| \left( \log\left(|\theta - \theta'|^{-1}\right) \right)^{\frac12}+ 2  |\theta - \theta'| \right)\\
%& \leq \|g\|_{H^{3/2}} |\theta - \theta'| \left( 2 + \left( \log\left(|\theta - \theta'|^{-1}\right) \right)^{\frac12} \right) \\
%& \leq \EB{2} \|g\|_{H^{3/2}}|\theta - \theta'|   \left( \log\left(|\theta - \theta'|^{-1}\right) \right)^{\frac12}\, .
%\end{align*}
%Next we estimate
%\begin{equation*}
%g(\theta) = g(\theta) - g(\theta') + g(\theta')  \leq \EB{2}\|g\|_{H^{3/2}}|\theta - \theta'| \EB{\left( \log\left(|\theta - \theta'|^{-1}\right) \right)^{\frac12}}+ g(\theta').
%\end{equation*}
%We integrate \EB{in $\theta'$} for $|\theta - \theta'|\leq \delta/2$, and divide by $\delta$ where $\delta \leq e^{-4}$:
%\EB{\begin{equation*} 
%\forall \theta \in \Theta, \qquad g(\theta) \leq   \frac{2}{\delta} \|g\|_{H^{3/2}} \int_0^{\frac{\delta}{2}} u \left( \log( u^{-1}) \right)^\frac12 du +  \dfrac{\|g\|_{L^1}}\delta \leq \|g\|_{H^{3/2}}  \frac{\delta}{2} \left( \log\left( \frac{2}{\delta}\right) \right)^\frac12  +  \dfrac{\|g\|_{L^1}}\delta\, .
%\end{equation*}}
%Choosing  $\delta = \min\left( e^{-4}, \left( \frac{\|g\|_{L^1}}{\|g\|_{H^{3/2}}}\right)^{1/2}\right)$, we get eventually
%\[ 
%\begin{cases}
%\|g\|_{L^\infty} \leq \left(\|g\|_{L^1} \|g\|_{H^{3/2}}\right)^{1/2}\left( \dfrac12 \left(\log\left( \dfrac{2\|g\|_{H^{3/2}}}{\|g\|_{L^1}}\right) \right)^{\frac12}+ 1\right)  & \mathrm{if}\quad \dfrac{\|g\|_{L^1}}{\|g\|_{H^{3/2}}} \leq e^{-8} \medskip \\
%\|g\|_{L^\infty} \leq 3 e^4 \|g\|_{L ^1} & \mathrm{otherwise} 
%\end{cases} \]
%In order to simplify the computations, we use the simple estimate 
%$$\forall \delta<e^{-4}, \qquad\; \left( \log \delta^{-1} \right)^\frac12+ 2 \leq C \delta^{-1/3},$$ 
%for some constant $C$. We obtain finally 
%\[
%\begin{cases}
%\|g\|_{L^\infty}^3 \leq C \|g\|_{L^1} \|g\|_{H^{3/2}}^2 & \mathrm{if}\quad \dfrac{\|g\|_{L^1}}{\|g\|_{H^{3/2}}} \leq \dfrac1C \medskip, \\
%\|g\|_{L^\infty} \leq C \|g\|_{L ^1} & \mathrm{otherwise}. 
%\end{cases} \]
%


%We focus on the case 
%\begin{equation*}
%a(\theta) = \beta \left( \theta - \underline\theta \right)^p.
%\end{equation*}
%
%Both (\ref{nov1004}) and (\ref{nov1006}) are supplemented by the Neumann boundary condition at $\theta=\underline\theta$:
%\begin{equation}\label{nov1012}
%u_\theta(t,x,\underline\theta)=0,~~t>0,~x\in\Rm.
%\end{equation}
%The non-dimensional versions of (\ref{nov1004}) and (\ref{nov1006}) are, respectively,
%\begin{equation}\label{nov1014}
%u_t=\theta u_{xx}+ u_{\theta\theta}+u(1-u),~~~t>0,~x\in\Rm,~\theta\in\Theta,
%\end{equation}
%and 
%\begin{equation}\label{nov1016}
%n_t=\theta n_{xx}+ n_{\theta\theta}+n(1-\rho),~~~\rho(t,x)=\int_{\underline\theta}^\infty n(t,x,\theta)d\theta,
%~~~~~t>0,~x\in\Rm,~\theta\in\Theta.
%\end{equation}
%
%In general, the speed of propagation in the Fisher-KPP type equations is determined by the linearization  around zero, 
%that is, with the terms $u(1-u)$ in (\ref{nov1014}) and $n(1-\rho)$ in 
%(\ref{nov1016}) replaced by $u$ and $n$, respectively.
%Since the linearizations of~\eqref{nov1014} and~\eqref{nov1016} are identical, we expect both models to have the same propagation
%speed.
%
%Models involving nonlocal reaction terms have been the subject of intense study in recent years due to the complexity of the
%dynamics -- see, for
%example,~\cite{Hamel, FayeHolzer, NadinPerthameTang,NadinRossiRyzhikPerthame,AlfaroCovilleRaoul,BouinMirrahimi} 
%and references therein.  
%The cane toads equation has similarly attracted recent interest, mostly when the motility set $\Theta$ is a finite interval.
%An Hamilton-Jacobi framework has been formally applied to the nonlocal model 
%in~\cite{BCMetal},   and rigorously justified  in~\cite{Turanova}. 
%In these works, the authors obtain the speed of propagation and the expected repartition of traits at the edge of the front by solving a spectral 
%problem in the trait variable. The existence of travelling waves has been proved in
%\cite{BouinCalvez}. 
%The precise asymptotics of the front location for the Cauchy problem, 
%up to a constant shift has been obtained in \cite{BHR_Delay} 
%by using a Harnack-type inequality that allows one to compare 
%the solutions of the nonlocal 
%equation to those of a local equation, whose dynamics are well-understood~\cite{Bramson78}.   
%
%As far as unbounded traits are concerned, a formal argument 
%in~\cite{BCMetal} using a Hamilton-Jacobi framework predicted front acceleration and spreading rate of $O(t^{3/2})$.
%In this paper, we give a rigorous proof of this spreading rate  both in the local and nonlocal models. This is  an addition to 
%the growing list of ``accelerating fronts'' that have attracted some interest in recent years 
%\cite{BouinCalvezNadin, HamelRoques, HendersonFast, Garnier, MeleardMirrahimi, CoulonRoquejoffre, CCR, CabreRoquejoffre}.   
%
%
%
%\subsubsection*{The local case}
%
%Our first result concerns the local equation (\ref{nov1014}). 
%%In particular, we obtain the precise asymptotics for long-time propagation in this local analogue.
%%
%\begin{theorem}[{\bf Acceleration in the local cane toads model}]
%\label{thm:local_toads}
%Let $u(t,x)$ be the solution of the local equation (\ref{nov1014}), with the boundary condition (\ref{nov1012}),
%and the initial condition $u(0,x)=u_0(x)\ge 0$. Assume that  $u_0(x)$ is compactly supported, and
%% and let $u$ the unique solution of the following local cane toads equation:
%%\begin{equation}\label{eq:local_toads}
%%\begin{cases}
%%u_t - \theta u_{xx} - u_{\theta\theta} = u  (1 -  u), \qquad (t,x,\theta) \in \R^+ \times \R \times \Theta, \medskip\\
%%u_\theta (t,x,\underline\theta) = 0\, , \qquad \hfill (t,x) \in \R^+ \times \R, \medskip \\
%%u(0,x,\theta) = u_0(x,\theta), \qquad \hfill (x,\theta) \in \R \times \Theta.
%%\end{cases}
%%\end{equation}
%%
%%
%%\begin{equation}\label{eq:local_toads}
%%	\begin{cases}
%%		u_t = \theta u_{xx} + \alpha u_{\theta\theta} + ru(1-u),\\
%%		u(0,x,\theta) = u_0(x,\theta), &(x,\theta) \in \R \times [\underline\theta,\infty]\\
%%		\partial_\theta u(t,x,\underline\theta) = 0.
%%	\end{cases}
%%\end{equation}
%fix any constant $m \in (0,1)$, then
%\begin{equation}\label{eq:local_asymptotics}
%	\lim_{t\to\infty} \; \frac{\max\{ x \in \R : \exists \theta \in \Theta, u(t,x,\theta) = m\}}{t^{3/2}}
%		= \dfrac{4 }{ 3   },
%\end{equation}
%The limit is uniform in $m\in[\eps,1-\eps]$, for any $\eps>0$ fixed.
%\end{theorem}
%%
%%First, we point out that~\eqref{eq:local_toads} is the same as~\eqref{eq:nonlocal_toads} except that $u$ replaces the nonlocal term $\rho$ and 
%%is 
%%a Fisher-KPP type reaction-diffusion equation.  
%The assumption that $u_0$ is compactly supported is made purely for convenience, one could allow 
%more general   rapidly decaying or front-like initial conditions.
%
%


\end{document}  
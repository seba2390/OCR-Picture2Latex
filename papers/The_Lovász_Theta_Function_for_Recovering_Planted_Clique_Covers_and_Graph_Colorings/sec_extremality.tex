\section{Extremality of $(\ac,\ks)$} \label{sec:extremality}


The goal of this section is to provide a simple sufficient condition that guarantees when $(\ac,\ks)$ is an extreme point of the feasible region of \eqref{eq:lovasz_lambdamax}.  %We state the main result of this section in the following.
 As we noted in Section \ref{sec:outline}, we rely  on a  general result that describes extreme points of spectrahedra specified by a linear matrix inequality (LMI), stated in the form of Theorem \ref{thm:extremal_rg}.  We begin by expressing the feasible region of \eqref{eq:lovasz_lambdamax} as the following LMI
$$
\Big \{  (t, a_{i,j})_{(i,j) \in \E} \in \mathbb{R}^{|\E|+1} : - J + t I + \sum_{(i,j) \in \E} a_{i,j} E_{i,j} \succeq 0 \Big \}.
$$
This suggests we should take the matrices $\{I\} \cup \{ E_{i,j} : (i,j) \in \E \}$ to be $\{Q_i\}_{i=1}^{n}$, and to identify the matrix $\xc$ with $Q_0 +\sum_i x_i Q_i$ in Theorem \ref{thm:extremal_rg}.  Our next task is to characterize the kernel of~$\xc$.



\subsection{Computing the kernel of $\xc$}


\begin{proposition}\label{thm:jspace} Setting 
$$
\mathcal{J}:=\big \{ \bx \in \R^{|\V|} : \la \bx, \bone_{\ccs_1} \ra = \ldots = \la \bx,  \bone_{\ccs_{\ks}}\ra \big\},
$$
 we have that
$$\mathcal{J} = \lspan\{\bone_{\ccs_1} - \bone_{\ccs_l}:  2\le l\le \ks \}^\perp = \lspan\{ \ks \bone_{\ccs_l} -\be: l\in [\ks]\}^\perp.$$
\end{proposition}

\begin{proof}  The first equality follows immediately from definition since $\la \bx, \bone_{\ccs_1} \ra = \la \bx, \bone_{\ccs_l} \ra \Leftrightarrow \la \bx, \bone_{\ccs_1} - \bone_{\ccs_l} \ra$.  We focus on the second equality.  To do so, it suffices to show that every vector of the form $\ks \bone_{\ccs_l} -\be$, $l\in [\ks]$, is in the span of $\bone_{\ccs_1} - \bone_{\ccs_l}$, $2\le l\le \ks $, and vice versa.

First, we have $\bone_{\ccs_i} - \bone_{\ccs_j} = (\bone_{\ccs_1} - \bone_{\ccs_j}) - (\bone_{\ccs_1} - \bone_{\ccs_i})$.  Then, note that $\ks \bone_{\ccs_l} -\be = \sum_{i=1}^{\ks} (\bone_{\ccs_l} - \bone_{\ccs_i})$.  Hence the vectors $\ks \bone_{\ccs_l} -\be $ lies in the linear span of vectors of the form $\bone_{\ccs_1} - \bone_{\ccs_l}$, $2\le l\le \ks $.

In the reverse direction, note that $\bone_{\ccs_1} - \bone_{\ccs_l} = \frac{1}{\ks}(\ks \bone_{\ccs_1} -\be) - \frac{1}{\ks}(\ks \bone_{\ccs_l} -\be)$.  In other words, every vector of the form $\bone_{\ccs_1} - \bone_{\ccs_l}$, $2\le l\le \ks$, lies in the linear span of vectors of the form $\ks \bone_{\ccs_l} -\be$, $l\in [\ks]$.  This establishes the second equality.
%%We first focus on the first equality. %For this, 
%Finally, we show that 
%$$\lspan\{ \ks\bone_{\ccs_l} -\be: l\in [\ks]\}^\perp=\mathcal{J}$$ 
%\{\bx\in \R^n : \la \bx,   \bone_{\ccs_1}\ra =\ldots= \la \bx,  \bone_{\ccs_{\ks}} \ra \}.$$
%For this take $\bw\in \lspan\{ \ks \bone_{\ccs_l} -\be: l\in [\ks]\}^\perp$. Then for any $l,l'\in [\ks]$ we have 
%$$\la \bw, \ks\bone_{\ccs_l}-\be\ra =\la \bw, \ks\bone_{\ccs_{l'}}-\be\ra=0.$$
%In particular, we have that
%$$\la \bw, \bone_{\ccs_l}\ra=\la \bw, \bone_{\ccs_{l'}}\ra.$$
%Conversely, consider $\bw\in \{ \bx\in \R^{|\V|}:   \la \bx,   \bone_{\ccs_1}\ra =\ldots= \la \bx,  \bone_{\ccs_k} \ra \}$. Using that 
%$$k\bone_{\ccs_l}-\be=(\ks-1)\bone_{\ccs_l}-\sum_{l'\ne l}\bone_{\ccs_{l'}}=\sum_{l'\ne l}\left(\bone_{\ccs_l}- \bone_{\ccs_{l'}}\right)$$
%we immediately get that 
%$$\la \bw, \ks\bone_{\ccs_l}-\be\ra=\sum_{l'\ne l}\la \bw, \bone_{\ccs_l}- \bone_{\ccs_{l'}}\ra=0.$$
%
%Finally, the second characterization of $\mathcal{J}$ follows directly from  its definition.  
\end{proof} 

As an immediate consequence we have that:
%%In this section, we %discuss extremality of $\xc$ and 
%show
% that $\xc$ is the unique optimal solution to \eqref{eq:lovasz_lambdamax}  when $G$ is a disjoint union of cliques.  Our discussion corresponds to Step 1 and 2 of the proof outline.

\begin{proposition}\label{kernellemma}
The kernel  of $\xc$ is equal to  $ \mathcal{J}.$ 
%We proceed to establish our results concerning extremality.  
\end{proposition}

\begin{proof} By definition of $\xc$ we have that 
${\rm range}(\xc)={\rm span}\{ \ks \bone_{\mathcal{C}_l}-\be: l \in [k]\}.$
Thus,
$${\rm ker}(\xc) ={\rm span}\{ \ks \bone_{\mathcal{C}_l}-\be: l \in [k]\}^\perp.$$

\end{proof} 

%Our first step is to state a more convenient form of the complementary slackness condition.  First, we define the following subspace of $\mathbb{R}^{|\V|}$ corresponding to vectors that have constant inner product with the indicator vectors of cliques
%$$
%\mathcal{J} := 
%$$


\begin{proposition}\label{csexpnaded}
%Let $\xc= {1\over \ks}\sum_{l=1}^{\ks} (\ks \bone_{\mathcal{C}_l}-\be) (\ks \bone_{\mathcal{C}_l}-\be)^T$.
The following  statements are equivalent for a PSD matrix $Z \in \mathbb{R}^{|\V| \times |\V|}$:

\begin{itemize}
\item[(1)]  $  Z\in  {\rm span}( \xc)^\perp$.% $Z$  satisfies the complementary slackness condition \eqref{eq:complementaryslackness}. % i.e., 
\item[(2)] $Z(\ks\bone_{\ccs_l} -\be)=0,$ for all $ l \in [\ks].$

\item[(3)] $\range(Z) \subseteq \mathcal{J}$.
%\Big\{x\in \R^n:   \la x,   \bone_{\mathcal{C}_1^*} \ra=\ldots= \la x,  \bone_{\mathcal{C}_k^*}\ra \Big\}.$ 

\item[(4)] $\bz_i \in \mathcal{J}$ for all $i \in \V$ -- here, $\bz_i$ are rows of $Z$.
%For any $i\in [n]$,  the $i$-th row of $Z$, denoted by  $Z_i$  satisfies $Z_i\in \mathcal{J}$. 
% the following set of equalities
%\begin{equation} \label{eq:complementaryslackness}
%\la Z_i,  \bone_{\ccs_1}\ra = \ldots =\la  Z_i , \bone_{\mathcal{C}_k^\star}\ra  \tag{CS-2}.
%\end{equation}
\end{itemize} 
Moreover, we have that ${\rm rank}(\xc)+{\rm rank}(Z)=|\V|$ if and only if   $\range(Z) = \mathcal{J}$.

\end{proposition}



\begin{proof}$(1)\Longleftrightarrow (2)$ We have that 
$$\la Z, \xc\ra=0 \iff \sum_l(\ks\bone_{\ccs_l}-\be)^T Z (\ks\bone_{\ccs_l}-\be)=0\iff Z(\ks\bone_{\ccs_l} -\be)=0, \  \forall l \in [\ks]$$ 
 where the last equivalence holds as  $Z\succeq 0$. 

$(2)\Longleftrightarrow (3)$ Note that (2) is equivalent to  
$$\ker(Z)\supseteq  \range(\xc)=\lspan\{ \ks \bone_{\ccs_l} -\be: l\in [\ks]\}.$$ 
Taking orthogonal complements, this is in turn equivalent to 
$$\range(Z)\subseteq \lspan\{ \ks\bone_{\ccs_l} -\be: l\in [\ks]\}^\perp=\mathcal{J}.$$
Finally $(3) \iff (4)$ since $\range(Z)=\range(Z^T)$. 
\end{proof}


Our next result describes the spectrum of the matrix $\zz$ 
and  show that the columns of the matrix $\zz$ span the kernel of $\xc$. Recall that
%The dual certificate we will employ in the case of disjoint cliques is the following:
\begin{equation}\label{zfullmatrix}
\zz := \left(\begin{array}{ccc}
\frac{I}{|\ccs_1|} & \frac{1}{|\ccs_1||\ccs_2|} E & \ldots \\
\frac{1}{|\ccs_1||\ccs_2|} E & \frac{I}{|\ccs_2|} & \ldots \\
\vdots & \vdots & \ddots
 \end{array}\right),
\end{equation}
This matrix can be alternatively expressed in a more convenient form:
$$
\zz = \mathrm{diag}(\bg) + \bg\bg^T - \sum_{l} \frac{\bone_{\ccs_l}\bone_{\ccs_l}^T}{|\ccs_l|^2} \quad \text{where} \quad \bg = \Big(\underbrace{\frac{1}{|\ccs_1|}, \ldots }_{|\ccs_1|} , \ldots,  \underbrace{\ldots, \frac{1}{|\ccs_{\ks}|} }_{|\ccs_{\ks}|} \Big)^T.
$$
To be clear, this is precisely the same matrix \eqref{zmatrix} we use as our dual certificate whenever $G$ is a disjoint union of cliques.  However, we will not require any information about $\zz$ being a dual certificate at this juncture.  
\begin{proposition} \label{thm:Unequalsizecanonicalmatrix_spectrum}
The eigenvalues of $\zz$ are $\sum_{l=1}^{\ks} 1/|\ccs_l|$ (with multiplicity one), $0$ (with multiplicity $\ks-1$), and $1/|\ccs_l|$ with multiplicity $|\ccs_l|-1$. Moreover, we have that 
$\range(\zz)=\mathcal{J}$.
%$\alpha$ (with multiplicity $N-k$).
\end{proposition}

\begin{proof}
First, note that the $\bg$ is an eigenvector whose eigenvalue is $\sum_{i=1}^{\ks} 1/|\ccs_i|$.  Second, note that the vector $\bone_{\ccs_1} - \bone_{\ccs_l} $ is an eigenvector with eigenvalue $0$, for all $2 \leq l \leq \ks$.  Third, fix a subset $\ccs_l$.  Let $\bx \in \mathbb{R}^{|V|}$ be a vector with entries in the coordinates corresponding to $\ccs_l$ satisfying $\be^T \bx = 0$.  One can check that $(\bg\bg^T - \sum_{l} (\bone_{\ccs_l}\bone_{\ccs_l}^T)/|\ccs_l|^2) \bx = 0$, and hence $\zz\bx = \mathrm{diag}(\bg) \bx = \bx / |\ccs_l|$.  The dimension of this eigenspace is $|\ccs_l|-1$.  Finally, we have that 
$$\ker(\zz)=\lspan\{\bone_{\ccs_1} - \bone_{\ccs_l}:  2\le l\le \ks \}$$
and using Proposition \ref{thm:jspace} we get that 
$$\range(\zz)=\lspan\{\bone_{\ccs_1} - \bone_{\ccs_l}:  2\le l\le \ks \}^\perp=\mathcal{J}.$$

\end{proof}

\subsection{Establishing extremality}

\begin{lemma} \label{thm:non_degen_Z} Consider  a graph $G$ with a  clique cover $\{\ccs_l\}_{l=1}^{\ks}$.  Let $\mathcal{S} \subset \V$ be a subset of vertices such that, for all cliques except one, $ \mathcal{S}$ leaves out at least one vertex.  Then, the columns of $\zz$ corresponding to $\mathcal{S}$ are linearly independent.
\end{lemma}

\begin{proof} Without loss of generality, we assume that for all cliques except $ \ccs_1$, the set of vertices $\mathcal{S}$ contains at most $ |\ccs_{l}|-1$ vertices from clique $\ccs_{l}$, for all $l\ne 1$.

We index the columns of $\zz$ by $(l,j)$, where the index $1\leq l \leq \ks$ refers to the clique while the index $j\in \ccs_l$ refers to the vertex within the clique.  Let $\{\bv_{l,j}\}$ be the columns of the matrix $\zz$ and consider a linear~combination:
\begin{equation}\label{eq:non_degen_Z_1}
\sum_{(l,j) \in \mathcal{S}} \theta_{l,j} \bv_{l,j} = 0.
\end{equation}
%Without loss of generality, assume that for $l \in \{2,\ldots,\ks\}$ we leave out at least one column from~$\ccs_l$.  
Fix a cluster $\ccs_l$, and let $P_l$ be the projection of $\mathbb{R}^{|\V|}$ onto the coordinates corresponding to $\ccs_l$.  By applying $P_l$ to \eqref{eq:non_degen_Z_1} we get:
\begin{equation}\label{eq:non_degen_Z_2}
\sum_{j : (l,j)\in \mathcal{S}} \theta_{l,j} P_l(\bv_{l,j}) = - \sum_{(l',j) \in \mathcal{S}, 1\leq l' \neq l \leq \ks} \theta_{l',j} P_l(\bv_{l',j}) =  c (1,\ldots,1)^T.
\end{equation}
The rightmost equality follows by noting that $P_l(\bv_{l',j}) = \be \in \mathbb{R}^{|\ccs_l|}$ for all $j$.  On the other hand, $P_l(\bv_{l,j}) = \be_j  \in \mathbb{R}^{|\ccs_l|}$ are standard basis vectors.  Since $\mathcal{S}$ leaves out at least one vector in $\ccs_l$, the span of these vectors cannot include $\be$.  So it follows from \eqref{eq:non_degen_Z_1} that $c=0$, and in particular, $\theta_{l,j} = 0$ for all $j$.  We repeat this argument for all $2 \leq l \leq \ks$ and conclude that $\theta_{l,j} = 0$ for all $l \geq 2$, and all $j$.

Finally, we consider the vectors $\bv_{1,j}$ and project these to the rows in $\ccs_1$.  The vectors $\{P_l(\bv_{1,j})\}$ are standard basis vectors.  Since $\sum_{(1,j) \in \mathcal{S}} \theta_{1,j} P_l(\bv_{1,j}) = 0$, it must be that $\theta_{1,j} = 0$ for all $j$.  Hence all the coefficients are zero.  This proves that the columns in $\mathcal{S}$ are linearly independent.
\end{proof}


\begin{lemma} \label{thm:non_degen_alg} Let $G = (\V,\E)$ be a graph that satisfies the $\cscc$ property for some $c<1$.  Then the collection of matrices 
$
\{ E_{i,j} \zz : (i,j) \in \mathcal{E}\} \cup \{ \zz \}
$ 
are linearly independent.
\end{lemma}

\begin{proof}
Consider a linear combination  
$$
\sum_{(i,j) \in \mathcal{E}} \theta_{i,j} E_{i,j} \zz  + \theta \zz = 0.
$$
Fix a vertex $m \in \ccs_l$, and for all $l' \neq l$, we let $N_{l'}(m) \subset \ccs_{l'}$ denote the neighbors of vertex $m$ in $\ccs_{l'}$.  Then the $m$-th row of the above expression is given by:
$$
%\begin{equation}\label{eq:non_degen_alg_1}
\sum_{\substack{ j\in N_{l'}(m), l'\ne m}} \theta_{m,j} \bz^\star_j + \theta \bz^\star_m=0,
$$
%\end{equation}
where $\bz_j^\star$ denotes the $j$-th row of $\zz$. % Let $N_l(m)$ be the neighbors of vertex $m$ in the cluster $\ccs_l$. 
Now, since the vertex $m$ is not fully connected to clusters $\ccs_{l'}$ for all $l' \neq l$, the collection of vertices $\{N_{l'}(m)\}_{l' \neq m}\cup \{m\}$ satisfy the conditions of the subset $\mathcal{S}$ in Lemma \ref{thm:non_degen_Z}.  By Lemma \ref{thm:non_degen_Z}, the corresponding columns of $\zz$ are linearly independent, which means that $\theta = \theta_{m,j} = 0$ for all $j$.  The result follows by repeating this argument for all $m$.
\end{proof}



\begin{theorem} \label{thm:extremepoint}
Let $G = (\V, \E)$ be a graph, and let $\{\ccs_l\}_{l=1}^{k}$ be a clique cover for $G$.  Suppose $G$ satisfies the $\cscc$ property for some $c<1$.  Then $(\ac,\ks)$ is an extreme point of the feasible region of~\eqref{eq:lovasz_lambdamax}.
\end{theorem}

\begin{proof}[Proof of Theorem \ref{thm:extremepoint}]  Suppose $G$ satisfies the $\cscc$ property for some $c<1$.  By Lemma \ref{thm:non_degen_alg}, the collection of matrices $\{ E_{i,j} \zz : (i,j) \in \E \} \cup \{ \zz \}$ are linearly independent.  Hence the vectors in $\{ {\rm vec}( E_{i,j} \zz) : (i,j) \in \E \} \cup \{ {\rm vec}(\zz) \}$ are also linearly independent. % (note that vectorization is bijective). 
This means that the  following matrix formed by combining all the (vectorized) matrix product $E_{i,j} \zz$, ranging over all edges $(i,j) \in \E$, as well as $\zz$, has full column rank
$$
\left( \begin{array}{c|c|c|c}
\ldots & \mathrm{vec}( E_{i,j} \zz) & \ldots
& \mathrm{vec}(\zz)\end{array} \right)_{(i,j) \in \E}.
$$ 
Hence, by Theorem \ref{thm:constraintqualification}, $(\ac,\ks)$ is an extreme point of the feasible region of \eqref{eq:lovasz_lambdamax}.
\end{proof}


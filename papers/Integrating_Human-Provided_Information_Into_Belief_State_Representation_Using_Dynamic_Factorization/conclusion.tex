\section{Conclusion and Future Work}
We have considered the problem of belief state representation in an
open-domain planning problem where a human can give relational
information to the robot. We showed that a dynamically factored belief
is a good representational choice for efficient inference and planning
in this setting.

One future direction to explore is to approximately fold information
into the belief representation rather than compute a joint on every
update. We should seek a mechanism that allows the designer to trade
off between compactness of the belief and accuracy of
inference. Another direction to explore is a non-uniform observation
model: a robot given information $I$ can learn something not only from
$I$ but also from the fact that it was told $I$ as opposed to anything
else.

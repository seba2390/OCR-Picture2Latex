\label{sect:proposed_method}
\subsection{Method overview}

\begin{figure*}[h]
    \centering
    \includegraphics[width=0.75\linewidth]{nn_ik.png}
    \caption{High level overview of the generation setup. The target joint's positions (yellow) are matched as closely as possible, while the other joints (green) should be as close as possible to the starting pose (blue).}
    \label{fig:generation_setup}
\end{figure*}

We propose a method to solve a high level pose design problem in which a pose is modified to reach desired target positions for some of its joints. We leverage the modelling power of neural networks to implicitly learn skeleton constraints from a pre-existing pose database.
Our method, illustrated in Fig. \ref{fig:generation_setup}, relies on two models: an auto-encoder to build an alternative latent pose space, and a solver model operating on this space to solve the pose design problem. 
We also describe an optional post-processing step to smooth out the remaining errors, and \modify{}{outline} a methodology using multiple instances of the solver model at once to work with a varying amount of targets.

\subsection{Data}
\label{sect:materiel}
    
We train the models using a dataset of human poses, obtained by processing multiple available motion-capture datasets from the literature: Emilya \cite{fourati_emilya_2014}, CMU \cite{CMU_BVH}, and the clips from Edinburgh university \cite{holden_deep_2016}. Each animation clip is retargeted to a standard skeleton following the scheme proposed by \cite{HoldenAE2015}. The global translation is removed, and each joint's position is calculated relative to the root joint, which is the projection of the pelvis on the floor. The unified skeleton is composed of 21 joints; using the joints' positions in space, a pose is described by $ 3 \times 21 = 63 $ float values concatenated in a single vector. The dataset is then formed by the individual poses in each clip. Before feeding them to the network we also normalize each pose by subtracting the mean and dividing by the standard deviation of each feature. \modify{}{With a few jittery clips manually removed, the final dataset used in the following experiments is composed of about 1,5 million poses.}

\subsection{Models description}
\subsubsection{Autoencoder}
Auto-encoders are made up of two neural networks tasked to learn efficient encodings of complex data. The encoder maps real data points to a learned, usually more compact, latent space; and the \modify{encoder}{decoder} maps them back to the original data space.
We build such an auto-encoder of poses in order to build a common operating space for the following solvers. Generating points in the latent space allows us to ensure that the output is always a plausible pose, as the decoder is trained to turn any and all latent point into them.

The encoder network is composed of two fully connected layers with \modify{195}{200} neurons and ReLU \cite{relu_2010} activations, followed by an output layer with no activation. The output layer's size is based on the number of
dimensions $d$ in which the latent representations are encoded. We empirically find that $d=64$ yields a good balance of representation accuracy and inference speed. The decoder is the exact reversed replica and uses the same set of weights. 

% alex: 63, un peu étrange de ne pas avoir 64, les infos aiment bien les puissance de 2
%Saida : d'accord avec Alex
The autoencoder's weights are optimized by minimizing the mean squared error (MSE) between the input pose $x$ and its reconstructed equivalent $\hat x$ (Eq. \ref{eq:loss-ae}). In the following sections we refer to the encoder as $E$, the decoder as $D$ and a latent encoding as $z$, i.e. $z = E(x)$ and $\hat x = D(z)$. 

\begin{equation}
    \label{eq:loss-ae}
    L_{ae} = MSE(x, \hat x) = \frac{1}{d} \sum_{i=1}^{d}(x_i - \hat x_i)^2
\end{equation}

The autoencoder is trained for 20 epoch with batches of 256 poses, using the Adam optimizer \cite{kingma_adam_2017} with a learning rate of $0.0001$.

\subsubsection{Pose solver}

An instance of the solver model $S_t$ is specialized to solve the IK problem for $n$ specific targets $t$ and is trained to generate a new pose from an input pose and the desired targets locations. 
As it operates on the latent space built by the autoencoder, it more precisely accepts and outputs a latent pose vector, i.e. with $p_t$ the \modify{}{concatenated} target positions, $\hat z = S_t(z, p_t)$.

The network is composed of three fully connected layers with 126 neurons and ReLu activations, and an output layer with $d$ neurons.

During training, we randomly sample an input pose $x$ from the dataset and feed it to the network. \modify{The targets are generated by taking the positions of the considered joints on a random pose in the same animation clip as the input pose.}{We also sample a second pose $x'$ from the same source clip to use as target.} We found that this association helped the network learning by not relying on random (and possibly unreachable) target positions.

%alex: the loss function in Equation 2 (le 'in')
\modify{Its}{The network's} weights are optimized to minimize the loss function in Eq.\ref{eq:loss-ik} designed to represent its high level objective: \modify{reaching the targets with the associated joints while staying as close to the starting pose as possible}{reaching the targets with the associated joints while retaining a realistic pose}. We guide the network toward this objective by using a modified mean squared error function \modify{Eq.\ref{eq:loss-ik}}{, separating the poses ($x$ in this example) in two sets of joints: $x_{target}$ the joints associated to the targets $t$, and $x_{rest}$ the others} \modify{The generated pose's target joints $\hat x_{target}$ should be close to the input targets $p_t$, while its other joints $\hat x_{rest}$ should minimize their motion}{}.
We introduce a constant $k$ to give more relative importance to the target term of the function\modify{}{, so that the non-targets joints of $x'$ are only used to nudge the final result toward a plausible pose}. In our experiments $k$ is set to $0.01$.\modify{A side effect of our loss function is that the target positions are not an absolute truth to be reached at all cost. The solver is rather encouraged to use them as guides, only reaching them precisely when the starting pose would not require too much of a change.}{}
%alex: k is set to 0.01 => avec un chiffre aussi petit ca a de l'effet quand même ?

\begin{equation}
    \label{eq:loss-ik}
    L_{s} = MSE(\hat x_{target}, x'_{target}) + k \cdot MSE(\hat x _{rest}, x'_{rest})
\end{equation}



An instance of the solver model is trained for \modify{15}{5} epochs with the Adam optimizer using a learning rate of 0.0001 and a batch size of 256.

\subsection{Post processing}

It is a common observation with neural networks working with joints position that the generated positions can be jittery, and the resulting poses can suffer from slight variations in bone lengths. 
Our model is no exception, and while the variation is not visually detectable most of the time, computing the total bone length difference between the input skeleton and the generated pose shows that it is present. These variations are naturally undesirable and can result in visual discomfort on the spectator's end. In order to alleviate the problem we apply an optional post-processing step to the resulting poses to ensure constant bone lengths. We use the backward step from FABRIK as it is very lightweight computation-wise. Our experiments show that following this process  lends better results at a small cost in computing time (see table \ref{table:results}).

\subsection{Solving other targets configurations}
\label{sect:multi-solver}
Even though our solvers are designed to generate a pose considering one to two targets at once, it is possible to use multiple instances side by side and to switch to the correct one with regard to the selected targets. In cases where the user desires to use an arbitrary number of targets
(to suggest a position for a fixed joint for example) we can combine the multiple instances by running them in sequence, i.e. $\hat z = (S_{t3} \circ S_{t2} \circ S_{t1})(z)$ for $t1, t2, t3$ various targets and $S_{ti}$ the solvers trained to reach them.
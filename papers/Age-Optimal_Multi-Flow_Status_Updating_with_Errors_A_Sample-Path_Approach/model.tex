% !TEX root = ./Age_of_Info_multi_source.tex


\section{Related Work}\label{sec_related_work}

The age of information concept has attracted a significant surge of research interest; see, e.g., \cite{SunAoIWorkshop2018,Song1990,KaulYatesGruteser-Infocom2012,2012CISS-KaulYatesGruteser,2012ISIT-YatesKaul,LiInfocom2015,6875100,CostaCodreanuEphremides_TIT, KamKompellaEphremidesTIT,Icc2015Pappas,2015ISITHuangModiano,Suninfocom2016,AgeOfInfo2016,Bedewy2016,BedewyJournal2017,Bedewy2017,BedewyMultihop2017,SunBook,Yates2016, AliTCOM2022,IgorAllerton2016,HsuTWC2017,Vishrant2017,Arunabh2019,He2018,8822722,8812616,9137714,8406891,SunMutualInformation2018,SunNonlinear2019,shisher2021age,ShisherMobiHoc22, shisher2023learning0, shisher2023learning, pan2022age, pan2022optimal, bedewy2021low, ornee2021sampling, bedewy2021optimal, tang2022sampling, ornee2023whittle, Kosta2017Age} and a recent survey \cite{yates2021AgeSurvey}. 
Initially, research efforts were centered on analyzing and comparing the age performance of different queueing disciplines, such as First-Come, First-Served (FCFS) \cite{KaulYatesGruteser-Infocom2012,2012ISIT-YatesKaul,KamKompellaEphremidesTIT,2015ISITHuangModiano}, preemptive and non-preemptive Last-Come, First-Served (LCFS) \cite{2012CISS-KaulYatesGruteser,Yates2016}, and packet management \cite{CostaCodreanuEphremides_TIT, Icc2015Pappas}. In \cite{Bedewy2016,BedewyJournal2017,Bedewy2017,BedewyMultihop2017,SunBook}, a sample-path approach was developed to prove that Last-Generated, First-Served (LGFS)-type policies are optimal or near-optimal for minimizing a broad class of age metrics in multi-server and multi-hop queueing networks with a single packet flow. When packets arrive in the order of their generation times, the LGFS policy becomes the well-known Last Come, First Served (LCFS) policy. Hence, the LCFS policy is (near) age-optimal in these queueing networks. 

In recent years, researchers have expanded the aforementioned studies to consider age minimization in multi-flow discrete-time status updating systems  \cite{IgorAllerton2016,HsuTWC2017,Vishrant2017,Arunabh2019}. In \cite{IgorAllerton2016}, the authors utilized a sample-path method to establish the optimality of the Maximum Age First (MAF) policy in minimizing the time-averaged sum age of multiple flows. This investigation focused on discrete-time systems with periodic arrivals and a single broadcast channel, which is susceptible to \emph{i.i.d.} transmission errors.
Moreover, in \cite{HsuTWC2017}, a Markov decision process (MDP) approach was adopted to prove that the MAF policy minimizes the time-averaged sum age of multiple flows in discrete-time systems with Bernoulli arrivals, a single broadcast channel, and no buffer. In this bufferless setup, arriving packets are discarded if they cannot be transmitted immediately in the arriving time slot. In \cite{Vishrant2017}, the authors studied discrete-time systems with multiple flows and multiple ON/OFF channels, where the state of each channel (ON/OFF) is known for making scheduling decisions. It was demonstrated that a Max-Age Matching policy is asymptotically optimal for minimizing non-decreasing symmetric functions of the age of the flows as the numbers of flows and channels increase. In \cite{Arunabh2019}, it was shown that the MAF policy minimizes the Maximum Age of multiple flows in discrete-time systems with periodic arrivals and a single broadcast channel susceptible to \emph{i.i.d.} transmission errors, where the transmission error probability may vary across the flows. In \cite{Ruogu2013}, a sample-path method was employed to demonstrate that the round-robin policy minimizes a service regularity metric called \emph{time-since-last-service} in discrete-time systems with multiple flows and transmission errors. In the definition of time-since-last-service, a user can receive service even if its queue is empty. Consequently, time-since-last-service bears similarities to the age of information concept, albeit these two metrics are different. 
The present paper, alongside its conference version \cite{SunAoIWorkshop2018}, complements the aforementioned studies in several essential ways: (i) It considers general time-dependent, symmetric, and non-decreasing age penalty functions $p_t$. (ii) Both continuous-time and discrete-time systems with multiple flows, multiple channels (a.k.a. servers), and transmission errors are investigated. (iii) The paper establishes near age-optimal scheduling results in scenarios where achieving age-optimality is inherently challenging.












%In \cite{IgorAllerton2016}, the expected time-average of the weighted sum age of multiple sources was minimized in a broadcast network with an ON-OFF channel and periodic arrivals, where only one source is scheduled at a time and the scheduler does not know the current ON-OFF channel state. When the network is symmetric and the weights are equal, a sample-path method was used to show that the maximum age first (MAF)  policy is optimal. Further, a sub-optimal Whittle's index method was used to handle the general asymmetric cases. In \cite{HsuTWC2017}, for symmetric Bernoulli arrivals and an always-ON channel with no buffers, the MAF policy was shown to be optimal for minimizing  the expected time-average of the sum age of multiple sources. In addition, Markov decision process (MDP) methods were used to handle the general scenarios with asymmetric arrivals and a buffer, where the optimal policies are shown to be switch-type. 


\section{System Model}\label{sec:model}
\subsection{Notations and Definitions}\label{sec:def}
% %, with $|\mathcal{S}|$ denoting the cardinality of $\mathcal{S}$.
%%For any random variable ${X}$ and any event $\mathcal{A}$, let $[{X}|\mathcal{A}]$ denote a random variable with the conditional distribution of ${X}$ for given $\mathcal{A}$. 

%For any random variable $Z$ and event $\mathcal{A}$, let $[Z|\mathcal{A}]$ denote a random variable with the conditional distribution of $Z$ for given $\mathcal{A}$.
% and $\mathbb{E}[Z|\mathcal{A}]$ denote the conditional expectation of $Z$ for given $\mathcal{A}$. 
%Let $u$ and $1_A$ denote the unit step function and indicator function of event $A$, respectively, i.e.,
%\begin{align}
%u(t) = \left\{\begin{array}{l l} 1,& \text{if}~t\geq0;\\0,& \text{if}~t<0,\end{array}\right.~~~1_A(x) = \left\{\begin{array}{l l} 1,& \text{if}~x\in A;\\0,& \text{if}~x\notin A.\end{array}\right.\nonumber
%\end{align}
 

%Let $\bm{x} = (x_1, x_2,\ldots,$ $x_m)$ and $\bm{y} = (y_1, y_2,\ldots,y_m)$ be two vectors in $\mathbb{R}^m$, then we denote $\bm{x} \leq \bm{y}$ if $x_i \leq y_i$ for $i = 1,2,\ldots,m$. A set $U \subseteq \mathbb{R}^m$ is called \emph{upper}, if for all $\bm{x} \in U$ and $\bm{y}\geq \bm{x}$ it holds that $\bm{y} \in U$. 










We  use lower case letters such as $x$ and $\bm{x}$, respectively, to represent deterministic scalars and vectors. In the vector case, a subscript will index the components of a vector, such as $x_i$.
%We use $x_{[i]}$ %and $x_{(i)}$, respectively, 
%to denote the $i$-th largest %and the $i$-th smallest 
%component of $\bm{x}$. 
We use $x_{[i]}$ %and $x_{(i)}$, respectively, 
to denote the $i$-th largest %and the $i$-th smallest 
component of vector $\bm{x}$. Let $\bm 0$ denote   a vector with all 0 components.
%Let $\bm{x}_{\uparrow}=(x_{(1)},\ldots,x_{(n)})$ %and $\bm{x}_{\downarrow}=(x_{[1]},\ldots,x_{[n]})$, respectively,
%denote the increasing %and decreasing
%rearrangements of $\bm{x}$. 
A function $f: \mathbb{R}^n\rightarrow \mathbb{R}$ is termed \emph{symmetric} if $f(\bm{x})= f(x_{[1]},\ldots, x_{[n]})$ for all $\bm{x} \in \mathbb{R}^n$. A function $f: \mathbb{R}^n\rightarrow \mathbb{R}$ is termed \emph{separable} if there exists functions $f_1,\ldots,f_n$ of one variable such that $f(\bm{x}) = \sum_{i=1}^n f_i(x_i)$ for all $\bm{x} \in \mathbb{R}^n$. 
The composition of functions $f$ and $g$ is denoted by $f \circ g( x) = f(g ( x))$. 
 For any $n$-dimensional vectors $\bm{x}$ and $\bm{y}$, the elementwise vector ordering $x_i\leq y_i$, $i=1,\ldots,n$, is denoted by $\bm{x} \leq \bm{y}$. 
 %Further, $\bm{x}$ is said to be \emph{majorized} by $\bm{y}$, denoted by $\bm{x}\prec\bm{y}$, if (i) $\sum_{i=1}^j x_{[i]} \leq \sum_{i=1}^j y_{[i]}$, $j=1,\ldots,n-1$ and (ii) $\sum_{i=1}^n x_{[i]} = \sum_{i=1}^n y_{[i]}$ \cite{Marshall2011}. In addition, $\bm{x}$ is said to be  \emph{weakly majorized by $\bm{y}$ from below}, denoted by $\bm{x}\prec_{\text{w}}\bm{y}$, if $\sum_{i=1}^j x_{[i]} \leq \sum_{i=1}^j y_{[i]}$, $j=1,\ldots,n$; $\bm{x}$ is said to be  \emph{weakly majorized by $\bm{y}$ from above}, denoted by $\bm{x}\prec^{\text{w}}\bm{y}$, if $\sum_{i=1}^j x_{(i)} \geq \sum_{i=1}^j y_{(i)}$, $j=1,\ldots,n$ \cite{Marshall2011}.
%A function that preserves the majorization order is called a Schur convex function. Specifically, $f: \mathbb{R}^n\rightarrow \mathbb{R}$ is termed \emph{Schur convex} if $f(\bm{x})\leq f(\bm{y})$ for all $\bm{x}\prec\bm{y}$ \cite{Marshall2011}.
Let $\mathcal{A}$ 
and $\mathcal{U}$ 
denote sets and events. 
For all random variable ${X}$ and event $\mathcal{A}$, let $[{X}|\mathcal{A}]$ denote a random variable with the conditional distribution of ${X}$ for given $\mathcal{A}$. We will need the following definitions: 



%\begin{definition}\emph{Majorization \cite{Marshall2011}}: For any $n$-dimensional vectors $\bm{x}$ and $\bm{y}$, $\bm{x}$ is said to be \emph{majorized} by $\bm{y}$, denoted by $\bm{x}\prec\bm{y}$, if (i) $\sum_{i=1}^j x_{[i]} \leq \sum_{i=1}^j y_{[i]}$, $j=1,\ldots,n-1$ and (ii) $\sum_{i=1}^n x_{[i]} = \sum_{i=1}^n y_{[i]}$. In addition, $\bm{x}$ is said to be  \emph{weakly majorized by $\bm{y}$ from below}, denoted by $\bm{x}\prec_{\text{w}}\bm{y}$, if $\sum_{i=1}^j x_{[i]} \leq \sum_{i=1}^j y_{[i]}$, $j=1,\ldots,n$.
%% $\bm{x}$ is said to be  \emph{weakly majorized by $\bm{y}$ from above}, denoted by $\bm{x}\prec^{\text{w}}\bm{y}$, if $\sum_{i=1}^j x_{(i)} \geq \sum_{i=1}^j y_{(i)}$, $j=1,\ldots,n$ . 
%\end{definition}
%
%\begin{definition}\emph{Schur Convexity \cite{Marshall2011}}:  A function that preserves the majorization order is called a Schur convex function. Specifically, $f: \mathbb{R}^n\rightarrow \mathbb{R}$ is termed \emph{Schur convex} if $f(\bm{x})\leq f(\bm{y})$ for all $\bm{x}\prec\bm{y}$ \cite{Marshall2011}. 
%\end{definition}
% Define $x\wedge y=\min\{x,y\}$.


\begin{definition}\label{def_variable}
\emph{Stochastic Ordering of Random Variables \cite{StochasticOrderBook}}: 
A random variable ${X}$ is said to be \emph{stochastically smaller} than another random variable ${Y}$, denoted by ${X}\leq_{\text{st}}{Y}$, if 
\begin{align}
\Pr({X}>t) \leq \Pr({Y}>t),~\forall~t\in \mathbb{R}. 
\end{align}
\end{definition}
\begin{definition}\label{def_vector}
\emph{Stochastic Ordering of Random Vectors \cite{StochasticOrderBook}}: 
A set $\mathcal{U} \subseteq \mathbb{R}^n$ is called \emph{upper}, if $\bm{y} \in \mathcal{U}$ whenever $\bm{y}\geq \bm{x}$ and $\bm{x} \in \mathcal{U}$. 
Let $\bm{X}$ and $\bm{Y}$ be two $n$-dimensional random vectors, $\bm{X}$ is said to be \emph{stochastically smaller} than $\bm{Y}$, denoted by $\bm{X}\leq_{\text{st}}\bm{Y}$, if 
\begin{align}
\Pr(\bm{X}\in \mathcal{U}) \leq \Pr(\bm{Y}\in \mathcal{U})~\text{for all upper sets}~\mathcal{U}\subseteq \mathbb{R}^n.
\end{align}
\end{definition}
\begin{definition}\label{def_process}
\emph{Stochastic Ordering of Stochastic Processes \cite{StochasticOrderBook}}: 
Let $\{X(t),t\in [0,\infty) \}$ and $\{Y(t),t\in [0,\infty) \}$ be two stochastic processes, $\{X(t), t\in [0,\infty) \}$ is said to be \emph{stochastically smaller} than $\{Y(t),t\in [0,\infty) \}$, denoted by $\{X(t),t\in [0,\infty) \}\leq_{\text{st}}\{Y(t),t\in [0,\infty)\}$, if for all integer $n$ and $0\leq t_1< t_2<\ldots<t_n$, it holds that 
\begin{align}
\!\!\!(X(t_1),X(t_2),\ldots,X(t_n)) \!\leq_{\text{st}}\! (Y(t_1),Y(t_2),\ldots,Y(t_n)).\!\!\!
\end{align}
\end{definition}

\ignore{A random variable ${X}$ is said to be \emph{stochastically smaller} than another random variable ${Y}$, denoted by ${X}\leq_{\text{st}}{Y}$, if $\Pr({X}>x) \leq \Pr({Y}>x)$ for all~$x\in \mathbb{R}$.
A set $\mathcal{U} \subseteq \mathbb{R}^n$ is called \emph{upper}, if $\bm{y} \in \mathcal{U}$ whenever $\bm{y}\geq \bm{x}$ and $\bm{x} \in \mathcal{U}$. 
A random vector $\bm{X}$ is said to be \emph{stochastically smaller} than another random vector $\bm{Y}$, denoted by $\bm{X}\leq_{\text{st}}\bm{Y}$, if $\Pr(\bm{X}\in \mathcal{U}) \leq \Pr(\bm{Y}\in \mathcal{U})$ for all upper sets ~$\mathcal{U}\subseteq \mathbb{R}^n$. %If $\bm{X}\leq_{\text{st}}\bm{Y}$ and $\bm{X}\geq_{\text{st}}\bm{Y}$, then $\bm{X}$ and $\bm{Y}$ follow the same distribution, denoted by $\bm{X}=_{\text{st}}\bm{Y}$. 
A stochastic process $\{X(t), t\in [0,\infty) \}$ is said to be \emph{stochastically smaller} than another stochastic process $\{Y(t),t\in [0,\infty) \}$, denoted by $\{X(t),t\in [0,\infty) \}\leq_{\text{st}}\{Y(t),t\in [0,\infty)\}$, if for all integer $n$ and $0\leq t_1< t_2<\ldots<t_n$, it holds that $(X(t_1),X(t_2),\ldots,X(t_n)) \!\leq_{\text{st}}\! (Y(t_1),Y(t_2),\ldots,Y(t_n))$.}
%\begin{align}
%\!\!\!.\!\!\!\nonumber
%\end{align}




\ignore{
Let us use $\mathcal{U}$ % and $\mathcal{A}$ 
to denote sets. A set $\mathcal{U} \subseteq \mathbb{R}^n$ is called \emph{upper}, if $\bm{y} \in \mathcal{U}$ whenever $\bm{y}\geq \bm{x}$ and $\bm{x} \in \mathcal{U}$. % or events.


}

%Let $\mathbb{V}$ be the set of Lebesgue measurable functions on $[0,\infty)$, i.e.,
%\begin{align}\label{eq_functions}
%\mathbb{V} = \{f : [0,\infty) \mapsto \mathbb{R} \text{ is Lebesgue measurable}\}.
%\end{align}
A functional is a mapping from functions to real numbers. A functional $\phi$ is termed \emph{non-decreasing} if $\phi(\{X(t), t\in [0,\infty)\}) \leq \phi(\{Y(t), t\in [0,\infty)\})$ whenever $X(t)\leq Y(t)$ for $t\in [0,\infty)$.
We remark that $\{X(t),t\in [0,\infty) \}\leq_{\text{st}}\{Y(t),t\in [0,\infty)\}$  if, and only if,  \cite{StochasticOrderBook}
\begin{equation}\label{eq_order}
\mathbb{E}[\phi(\{X(t), t\in [0,\infty)\} )] \leq \mathbb{E}[\phi(\{Y(t), t\in [0,\infty)\} )]
\end{equation}
holds for all non-decreasing functional $\phi$, provided that the expectations in \eqref{eq_order} exist.

\subsection{Queueing System Model}\label{sec:queuemodel}
%{\red Can be generalized to multiple servers.}

Consider the status updating system illustrated in Fig. \ref{fig_model}, where $N$ flows of status update packets are sent through a queue with an infinite buffer and $M$ servers. Let $s_n$ and $d_n$ denote the source and destination nodes of flow $n$, respectively. It is possible for multiple flows to share either the same source node or the same destination node. 



A scheduler assigns packets from the transmitter's queue to servers over time. The queue contains packets from different flows, and each packet can be assigned to any available server. Each server is capable of transmitting only one packet at a time. Different servers are not allowed to simultaneously transmit packets from the same flow.
%Each of the servers can transmit any packet  to the associated destination, one packet at a time. %
The packet transmission times are independent and identically distributed (\emph{i.i.d.})~across both servers and packets, with a finite mean  $1/\mu$. The packet transmissions are susceptible to \emph{i.i.d.} errors with an error probability $q\in[0,1)$, 
occurring at the end of the packet transmission time intervals.
The scheduler is made aware of transmission errors once they occur. In the event of such a error, the packet is promptly returned to the queue, where it awaits the next transmission opportunity. if $q= 0$, then there is no transmission errors. 


%Hence, the packet service time distribution depends on the server, rather than the packet. 

%In practice, the servers can be TCP/HTTP connections or wireless communication channels that can be assigned to different flows. 
% {\red and a buffer size $B\geq N$}
% infinite buffer size.\footnote{It is easy to check that the results in this paper hold if the buffer size $B$ is finite and $B\geq N$.} 



% a transmitter sends update packets to $R$ receivers through $M$ communication servers, where a server could be a wireless communication channel, a TCP/HTTP connection, etc. 
The system starts to operate at time $t=0$.  The $i$-th packet of flow $n$ is generated  at the source node $s_n$ at time $S_{n,i}$, arrives at the queue at time $A_{n,i}$, and is delivered to the destination $d_n$ at time $D_{n,i}$ such that $0\leq S_{n,1} \leq S_{n,2}\leq\ldots$ and $S_{n,i}\leq A_{n,i}\leq D_{n,i}$.\footnote{This paper allows $S_{n,i}\leq A_{n,i}$, which is  more general than the conventional assumption $S_{n,i}= A_{n,i}$  adopted in  related literature.} 
We consider the following class of \emph{synchronized} packet generation and arrival processes:
%We assume that the packet generation and arrival times are \emph{synchronized} across the $N$ flows, as defined below:

\begin{definition} \emph{Synchronized Packet Generations and Arrivals:}
The packet generation and arrival processes are said to be \emph{synchronized} across  the $N$ flows, if there exist two sequences $\{S_1, S_2,\ldots\}$ and $\{A_1,A_2,\ldots\}$ such that for all $i=1,2,\ldots,$ and $n=1,\ldots,N$
\begin{align}\label{eq_synchronized}
S_{n,i} = S_i,~A_{n,i} = A_i.
\end{align}
\end{definition}
We note that the sequences $\{S_1, S_2,\ldots\}$ and $\{A_1,A_2,\ldots\}$ in  \eqref{eq_synchronized} are \emph{arbitrary}. Hence,
\emph{out-of-order arrivals}, e.g., $S_i < S_{i+1}$ but $A_i > A_{i+1}$, are allowed. In the special case that the system has a single flow ($N=1$), the packet generation times $S_{n,1}$ and arrival times $A_{n,1}$ of this flow are {arbitrarily} given without any constraint. Age-optimal scheduling in this special case has been previously studied in \cite{Bedewy2016,BedewyJournal2017,Bedewy2017,BedewyMultihop2017}. 

%synchronized sampling and arrivals mean that the packet generation and arrival processes of this flow can be arbitrary; 

%More general arrival processes will be studied later.

Let $\pi$ represent a scheduling policy that determines how to assign  packets from the  queue to servers over time. Let $\Pi$ denote the set of all \emph{causal} scheduling policies in which the scheduling decisions are made based on the history and current states of the system.
A scheduling policy is said to be \emph{preemptive} if a busy server can stop the transmission of the current packet and start sending another packet at any time; the preempted packet is stored back to the queue, waiting to be sent at a later time.
A scheduling policy is said to be \emph{non-preemptive} if each server must complete the transmission of the current packet before initiating the service of another packet. A scheduling policy is said to be \emph{work-conserving} if all servers remain busy whenever the queue contains packets waiting to be processed.  We use $\Pi_{np}$ to denote the set of non-preemptive and causal scheduling policies, where $\Pi_{np}\subset \Pi$. 
%and use $\Pi_{npwc}$ to denote the set of non-preemptive, work-conserving, and causal policies, such that $\Pi_{npwc} \subset\Pi_{np}\subset \Pi$.
Let 
\begin{align}
\mathcal{I}=\{S_{i}, A_{i},~ i=1,2,\ldots\} 
\end{align}
denote the synchronized packet generation and arrival times of the flows. 
We assume that the packet generation/arrival times $\mathcal{I}$, the packet transmission times, and the transmission errors are
governed  by three \emph{mutually independent}  stochastic processes, none of which are influenced by the  scheduling policy. 

%The Wiener process $W_t$ and the channel delay $Y_i$ 

   
%Let $p_{n,i}$ denote the $i$-th update packet of flow $n$, and $S_{n,i}$ denote the generation time of packet $p_{n,i}$ at its source node $s_n$, such that $0\leq S_{n1} \leq S_{n2}\leq\ldots$ The update packets arrive at the queue immediately after generation. 
% Let $D_{n,i}$ denote the delivery time of packet $p_{n,i}$ at its destination $d_n$ under policy $\pi$. 





%Our goal is to find the optimal scheduling policies that minimize a class of age of information metric of these $N$ flows.

%Let $p_{n,i}$ denote the $i$-th update packet of flow $n$, which is generated at time $S_{n,i}$ and delivered to flow $n$ at time $D_{n,i}$, such that $0\leq S_{n1} \leq S_{n2}\leq\ldots$ and $S_{n,i}\leq D_{n,i}$.  In order to save system bandwidth, we assume that at most one server can be assigned to one receiver at any time. We consider the class of \emph{causally feasible} scheduling policies, or simply \emph{causal} policies, in which the scheduling decisions are made based on the history and current state of the system. We use $\Pi$ to denote the set of causal policies. 


%A policy is said to be \emph{non-anticipative}, if the scheduling decisions are made without using any information about the future job arrivals; and is said to be \emph{anticipative}, if it has access to the parameters $(a_i,{k}_i,d_i)$ of future arriving jobs. For periodic and pre-planned services, future job arrivals can be predicted in advance. To cover these scenarios, we generalize the meaning of causal policies to include anticipative policies into the policy space $\Pi$. 
%, even when compared to the anticipative policies in $\Pi$.



%


%\subsection{Scheduling Policies}


%A causal policy can be either preemptive or non-preemptive. In a \emph{preemptive} policy, a server can switch to another update packet at any time; while in a \emph{non-preemptive} policy, a server must complete the current packet before switching to another packet. 
%Because a server must complete the current packet before admitting a new update packet, preemption of packet service is not allowed.






%For each receiver $l$, a stream of $N_l$ update messages $(\text{update}_{l,1},\text{update}_{l,2},\ldots, \text{update}_{l,N_l})$ arrives at the inf system and are stored in a central queue buffer, waiting to be sent out. Let $g_{l,n}$ and $a_{l,n}$ denote the generation time and arrival time of $\text{update}_{l,n}$, respectively.


%which sends updating messages --- such as news, tweets, coupons, emails, notifications and so on --- to its subscribing users. Suppose that the system is serving $L$ users. 


% and the messages are sent through $m$ communication links (e.g., TCP/HTTP connections). We assume that 


% a message is delivered   which can be assigned to one of the $m$ users at a time. 


% Let $f_s$ and $f_d$ represent the source and destination nodes of flow $f$, respectively. The source node $f_s$ generates a stream of update packets $(p_f(1),p_f(2),\ldots)$ and sends them to the destination node $f_d$ through the servers. %Each update packet can be transmitted through only one server. 
%The packet service times are assumed to be \emph{i.i.d.} across time and servers. 
%To save networking cost, no more than one server cannot be assigned to a flow at a time. 

%The system starts to operate at time $t=0$. The generation time of update packet $p_f(i)$ is $S_f(i)$, which is included in packet header of $p_f(i)$ as a time-stamp.~For any time $t\geq0$, let $I_f^s(t)\subseteq \mathbb{N}$ denote the indices of update packets that have been generated by source $f_s$ by time $t$ and $I_f^d(t)\subseteq I_f^s(t)$ denote the indices of update packets that have been delivered to destination $f_d$. Then, $U_f^s(t)=\max\{S_f(i): i\in I_f^s(t)\}$ is the time-stamp of the latest generated update at the source $f_s$, and 


%Let $I_n(t)$ denote the set of updates
%=\max\{S_n(i): p_i\in I_n(t)\}

\subsection{Age  Metrics}

Among the packets that have been delivered to the destination  $d_n$ of flow $n$ by time $t$, the freshest packet was generated at time  
\begin{align}
U_{n} (t) =\max_i \{S_{n,i}: D_{n,i} \leq t\}.
\end{align}
 \emph{Age of information}, or simply \emph{age}, for flow $n$ is defined as \cite{Song1990,KaulYatesGruteser-Infocom2012}
\begin{align}\label{eq_age}
\Delta_{n} (t) = t - U_{n} (t) = t - \max_i \{S_{n,i}: D_{n,i} \leq t\},
\end{align}
which is the time difference between  the current time $t$ and the generation time $U_{n} (t)$ of the freshest packet currently available at destination $d_n$. Because $S_{n,i}\leq D_{n,i}$,  one can get  $\Delta_{n} (t)\geq 0$ for all flow $n$ and time $t$. Let $\bm{\Delta}(t)=(\Delta_{1} (t),\ldots,\Delta_{N} (t)) \in [0,\infty)^N$ be the age vector of the $N$ flows at time $t$. 




%represents the staleness of the information available at node $d_n$.
%\begin{align}
%U_{n}(t) = \max\{S_{n,i}: D_{n,i} \leq t\}.
%\end{align}
%to denote the time-stamp of the freshest update packet received by  up to time $t$. 
%The \emph{age of information}, or simply the \emph{age}, of flow $n$ is defined as
%\begin{align}\label{eq_age}
%\Delta_{n} (t) = t - U_{n}(t),
%\end{align}
%which represents the staleness of the available information at  flow $n$. 


We introduce an \emph{age penalty function} $p(\bm{\Delta}) = p\circ \bm{\Delta}$  to represent the level of dissatisfaction for having aged information at the $N$ destinations, where $p: [0,\infty)^N\rightarrow \mathbb{R}$ can be any  \emph{non-decreasing} function of the $N$-dimensional age vector  $\bm{\Delta}$. Some  examples of the age penalty function are: %in $\mathcal{P}_{\text{Sch}}$ are:
\begin{itemize}
\item[1.] The \emph{average age} of the $N$ flows is
\begin{align}\label{eq_avgage}
p_{\text{avg}} (\bm{\Delta}) = \frac{1}{N}\sum_{n=1}^N \Delta_{n}. 
\end{align}

\item[2.] The \emph{maximum age} of the $N$ flows is
\begin{align}%\label{eq_maxage}
p_{\max} (\bm{\Delta}) = \max_{n=1,\ldots,N} \Delta_{n}.
\end{align}

\item[3.] The \emph{mean square age} of the $N$ flows is
\begin{align}%\label{eq_msage}
p_{\text{ms}} (\bm{\Delta}) = \frac{1}{N}\sum_{n=1}^N (\Delta_{n} )^2.
\end{align}

\item[4.] The \emph{$l$-norm of the age vector} of the $N$ flows is
\begin{align}%\label{eq_msage}
p_{\text{$l$-norm}} (\bm{\Delta}) = \left[\sum_{n=1}^N (\Delta_{n} )^l\right]^{\frac{1}{l}}, ~l\geq1.
\end{align}








%\item[5.] The \emph{proportional fair age utility} of the flows is
%\begin{align}%\label{eq_msage}
%\Delta_{\text{PF}} (t) = \sum_{n=1}^N \log[\Delta_{n} (t)+ \epsilon],\nonumber
%\end{align}
%where $\epsilon>0$ is any positive number.\footnote{We are }

\item[5.] The \emph{sum of per-flow age penalty functions} is
\begin{align}%\label{eq_msage}
p_{\text{sum-penalty}} (\bm{\Delta}) = \sum_{n=1}^N g(\Delta_{n}),
\end{align}
where $g: [0,\infty) \rightarrow \mathbb{R}$ is a \emph{non-decreasing} function. Practical applications of non-decreasing age functions can be found in \cite{SunNonlinear2019,yates2021AgeSurvey,shisher2021age,ShisherMobiHoc22,shisher2023learning}. 
% \cite{Suninfocom2016,AgeOfInfo2016}. 

%{\red revise later}

%For example, a stair-shape function $g_1(\Delta)=\lfloor a \Delta\rfloor$ with $a\geq 0$ can be used to characterize the dissatisfaction of data staleness when the information of interests is checked periodically, and an exponential function $g_2(\Delta) = e^{a \Delta}$ is appropriate for online learning and control applications where the desire for information refreshing grows quickly with respect to the age \cite{AgeOfInfo2016}. 
\end{itemize}

In this paper, we consider a class of \emph{symmetric} and \emph{non-decreasing} age penalty functions, i.e.,
\begin{align}%\label{eq_class}
\mathcal{P}_{\text{sym}}
\!=\!\{p: [0,\infty)^N\rightarrow \mathbb{R}  \text{ is symmetric and non-decreasing}\}.\nonumber
\end{align}
This is a fairly large class of age penalty functions, where the function $p$ can be discontinuous, non-convex, or non-separable.
It is easy to see 
\begin{align}
\{p_{\text{avg}},p_{\max}, p_{\text{ms}},p_{\text{$l$-norm}}, %\Delta_{\text{PF}}, 
p_{\text{sum-penalty}}\}\subset \mathcal{P}_{\text{sym}}.
\end{align}
%Notice that $p(\bm{\Delta})$ is a function of time $t$ and policy $\pi$. 

In this paper, we consider both continuous-time and discrete-time  status updating systems. In the continuous-time setting, time $t \in [0,\infty)$ can take any positive value and the packet transmission times are \emph{i.i.d.} continuous random variables. On the other hand, in the discrete-time setting, time is quantized into multiples of a fundamental time unit $T_s$, i.e., $t \in \{0, T_s, 2T_s, \ldots\}$, and each packet's transmission time is fixed and equal to $T_s$. Consequently, the variables $S_{n,i}, A_{n,i}, D_{n,i}, t, U_{n} (t), \Delta_{n} (t)$ are all multiples of $T_s$. In realistic discrete-time systems, service preemption is not allowed. 

%For convenience, we set $T_s = 1$ second, thereby making all the discrete-time variables integers. The results for other values of $T_s$ can be easily derived by time scaling.

Let ${\Delta}_{n,\pi}(t)$ denote the age of flow $n$ achieved by scheduling policy $\pi$ 
and $\bm{\Delta}_{\pi}(t) = (\Delta_{1,\pi} (t),\ldots,\Delta_{N,\pi} (t))$. 
In the continuous-time case, we assume that the initial age $\bm\Delta_{\pi}(0^-)$ at time $t=0^-$ remains the same for all scheduling policies $\pi\in\Pi$, where $t=0^-$ is the moment right before $t=0$. In the discrete-time case, we assume that the initial age $\bm\Delta_{\pi}(0)$ at time $t=0$ remains the same for all scheduling policies $\pi\in\Pi$. 

The results in this paper remain true even if the age penalty function $p_t$ varies over time $t$. For example, it is allowed  that $p_t = p_{\text{avg}}$ for $0\leq t \leq 100$ and $p_t = p_{\text{max}}$ for $100<t \leq 200$. 
In the continuous-time case, we use $\{p_t \circ \bm{\Delta}_\pi(t), t\in [0,\infty)\}$ to represent the age-penalty stochastic process formed by the \emph{time-dependent} penalty function $p_t$ of the age vector $\bm{\Delta}_{\pi}(t)$ under scheduling policy $\pi$. In the discrete-time case, the age-penalty stochastic process is denoted by $\{p_t \circ \bm{\Delta}_\pi(t), t=0,T_s,2 T_s,\ldots\}$. 

%{\red we have revised up to here}


%In this paper, we consider the following two classes of age penalty functions:
%\begin{align}%\label{eq_class}
%\mathcal{P}_{\text{sym}}&=\{p \circ\bm{\Delta} : p \text{ is symmetric and non-decreasing}\},\nonumber\\
%\mathcal{P}_{\text{Sch}} &= \{p \circ\bm{\Delta} :  p \text{ is Schur convex and non-decreasing}\}.\nonumber
%\end{align}
%%This is a fairly large class of age penalty functions, where the function   $p$ can be discontinuous, non-convex, or non-separable.
%Because  every convex and symmetric function is Schur convex and every Schur convex function is symmetric, one can get
%\begin{align}
%\{\Delta_{\text{avg}},\Delta_{\max}, \Delta_{\text{ms}},\Delta_{\text{$l$-norm}}\}\subset \mathcal{P}_{\text{Sch}},\nonumber\\
%\mathcal{P}_{\text{Sch}} \subset \mathcal{P}_{\text{sym}},~\Delta_{\text{sum-penalty}}\in \mathcal{P}_{\text{sym}}, \nonumber
%\end{align}
%Notice that $p \circ\bm{\Delta}$ is a function of time $t$. We  use $\{p \circ\bm{\Delta}(t), t\geq0\}$ to represent the stochastic process of the age penalty. 

%Notice that  the function $f$ in the definition of $\mathcal{P}_{\text{sym}}$ can be discontinuous, non-convex, or non-separable. Hence, the class  of age metrics $\mathcal{P}_{\text{sym}}$ is quite general.
%
%Each age metric is a function of the scheduling policy $\pi$ and time $t$, which is denoted as  $p \circ\bm{\Delta}_\pi(t)$ in the rest of this paper.


%

%Then, all these age metrics can be expressed as a function $f (\bm{\Delta}_{\pi} (t))$ of the age vector $\bm{\Delta}(t)$, where $f\in F_{\text{Sch}$ is an non-decreasing and Schur convex function.


%\subsection{Age Optimality}
%Let $I=(S_f(i): i=1,2,\ldots, f =1, 2,\ldots, F)$ denote the generation times of all updates, $\pi$ denote a scheduling policy, $\Delta_\pi (t)$ denote the average age of policy $\pi$, and $\Pi$ denote the set of causal policies. The update generation times $I$ are independent of the scheduling policy $\pi$.
%\begin{definition}\emph{Optimal Policy:}

%Each latency metric is a random variable (because the transmission times are random), which can be expressed as a non-decreasing function f(C()) of the vector C().

%Let us consider the stochastic process . 




%Our aim is to design a causal policy and show it is age-optimal in distribution for minimizing the age metrics in $\mathcal{P}_{\text{Sch}}$ among all policies in $\Pi$. We note that this definition of age optimality is quite strong. 
%From \eqref{eq_optimal}, it is easy to obtain 
%\begin{align}
%\lim_{T\rightarrow\infty}\!\mathbb{E}\!\left[\frac{1}{T} \!\int_0^T\!\!\! f (\bm{\Delta}_P(t)) dt \right] \!\!= \min_{\pi\in\Pi}\lim_{T\rightarrow\infty}\!\mathbb{E}\!\left[\frac{1}{T} \!\int_0^T\!\!\! f (\bm{\Delta}(t)) dt \right]\!.\nonumber
%\end{align}
%The policy proposed in this paper is {non-anticipative}, but it will be shown to be either age-optimal or close to age-optimal when compared with anticipative policies in $\Pi$.

%\end{definition}

%\begin{definition}\emph{Near Optimal Policy:}
%A causal policy $P\in\Pi$ is said to be \emph{near age-optimal in distribution}, if there exists a non-negative process $X(t)$, such that for all $I$ and $\pi\in\Pi$
%\begin{align}%\label{eq_nearoptimal}
%[\{\Delta_P (t\!+\!X(t)), t\!\in\![0,\infty)\}|I]\!\! \leq_{\text{st}}\!\! [\{\Delta_\pi (t)\!+\!X(t), t\!\in\![0,\infty)\}|I],\!\!\nonumber
%\end{align}
%$\mathbb{E}[X(t)]\leq M<\infty$ for all $t$, and $\{X(t),t\in[0,\infty)\}$ is independent of $\pi$ and $I$.
%\end{definition}

%The goal of this paper is to design an \emph{online} policy $P$ that is \emph{age-optimal} or \emph{near age-optimal in distribution}, even compared to the policies with knowledge about future updates.


%If all servers are busy at time $S_{n,i}$, the source cannot send $p_{n,i}$ until one server returns to an idle state at a later time $T_{n,i}$. Hence, $p_{n,i}$ has to wait for a time duration $T_{n,i} -S_{n,i} > 0$ before submitted to the servers, which will comprise the freshness of $p_{n,i}$. A better update policy is to postpone the generation time of each update packet until a server becomes idle, and submit the update packet to the server immediately. By this, each submitted update packet is timely, because the waiting time for server availability is zero.

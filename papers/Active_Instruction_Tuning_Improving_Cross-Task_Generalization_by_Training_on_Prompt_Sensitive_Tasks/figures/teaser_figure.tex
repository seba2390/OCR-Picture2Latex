% \begin{figure}
%     \centering
%     % \includegraphics[draft]{}
%     \includegraphics[width=0.5\textwidth]{../pdfs/Prompt-Uncertainty}
%     \vspace{-2em}
%     \caption{The concept of prompt uncertainty.}
%     \vspace{-1.5em}
%     \label{fig:teaser-figure}
% \end{figure} 

\begin{figure*}
    \centering
    % \includegraphics[draft]{}
    \includegraphics[width=\textwidth]{../pdfs/Prompt-Uncertainty-Full-Size}
    \vspace{-2em}
    \caption{\footnotesize
    We demonstrate how we measure the \textit{prompt uncertainty} of a model $W$ to a task. Given the original instruction $I_0$ and instance input $x_0$ of a task to the model, we first get prediction $y$ and its sentence probability $p_{0,0}$. Next, we randomly drop words (highlighted in red) from the original instructions to create $k$ perturbed instructions. We measure the model's prediction probability of $y$ given each of the perturbed instructions and input $x_0$. Finally, we calculate the average absolute difference (disagreement) between the prediction probability of using original and perturbed instructions, providing an estimate of the model's prompt uncertainty for $x_0$. We can further aggregate this prompt uncertainty scores across $n$ instances for a task. Further details can be found in \autoref{sec:method}.}
    \vspace{-1em}
    \label{fig:prompt-uncertainty}
\end{figure*} 
\section{Conclusion}

This paper aimed to improve recent voice conversion methods in terms of speed, the use of non-parallel training data, and zero-shot prediction capability.
To this end, we adapted the existing StarGAN-VC2 system by using a speaker encoder to generate speaker embeddings which are used to condition the generator and discriminator network on the desired source and target speakers.
The resulting model, StarGAN-ZSVC, can perform zero-shot inference and is trainable with non-parallel data.
In a series of experiments comparing StarGAN-ZSVC to the existing zero-shot voice conversion method AutoVC, we demonstrated that StarGAN-ZSVC is at least five times faster than AutoVC, while yielding better scores on objective and subjective metrics in a low-resource zero-shot voice conversion setting. 

For future work, we 
plan to investigate whether scaling StarGAN-ZSVC up to larger datasets yields similar performance to existing high-resource voice conversion
systems, and whether the system could be applied to other tasks aside from pure voice conversion (such as emotion or pronunciation conversion).



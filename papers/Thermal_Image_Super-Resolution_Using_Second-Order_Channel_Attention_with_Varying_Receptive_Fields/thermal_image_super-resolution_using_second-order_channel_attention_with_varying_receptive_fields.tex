\documentclass[runningheads]{llncs}
\usepackage{booktabs}
\usepackage{pgfplotstable}
\usepackage{adjustbox}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bm}
\usepackage{float}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{subfig}
\usepackage{calc}
\usepackage{forloop}
\usepackage{tikz}
\usetikzlibrary{math}
\usetikzlibrary{fpu}
\usepackage{tablecoms}

\usepackage[colorlinks]{hyperref}

\graphicspath{{images/}}

\newcommand{\argmin}[1]{\underset{#1}{\operatorname{arg}\,\operatorname{min}}\;}

\def\UrlBreaks{\do\/\do-}

\begin{document}

\title{
Thermal Image Super-Resolution Using Second-Order Channel Attention with Varying Receptive Fields
}

\titlerunning{Second-Order Channel Attention with Varying Receptive Fields}                                                                                                        
\author{Nolan B. Gutierrez \and William J. Beksi
\thanks{
The authors acknowledge the Texas Advanced Computing Center (TACC) at the
University of Texas at Austin for providing software, computational, and
storage resources that have contributed to the research results reported within
this paper.}
}
\authorrunning{N.B. Gutierrez and W.J. Beksi}
\institute{University of Texas at Arlington, Arlington TX, USA\\
\email{nolan.gutierrez@mavs.uta.edu, william.beksi@uta.edu
}\\
}

\maketitle
\pagestyle{plain}                                                                                                                                             

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
Thermal images model the long-infrared range of the electromagnetic spectrum and
provide meaningful information even when there is no visible illumination. Yet,
unlike imagery that represents radiation from the visible continuum, infrared
images are inherently low-resolution due to hardware constraints. The
restoration of thermal images is critical for applications that involve safety,
search and rescue, and military operations. In this paper, we introduce a system
to efficiently reconstruct thermal images. Specifically, we explore how to
effectively attend to contrasting receptive fields (RFs) where increasing the
RFs of a network can be computationally expensive. For this purpose, we
introduce a deep attention to varying receptive fields network (AVRFN). We
supply a gated convolutional layer with higher-order information extracted from
disparate RFs, whereby an RF is parameterized by a dilation rate. In this way,
the dilation rate can be tuned to use fewer parameters thus increasing the
efficacy of AVRFN. Our experimental results show an improvement over the state
of the art when compared against competing thermal image super-resolution (SR)
methods.
\end{abstract}

\begin{keywords}
Thermal Imaging, Super-Resolution, Compression via Dilations 
\end{keywords}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
\label{sec:introduction}
The purpose of single image super-resolution (SISR) restoration is to determine
the mapping between a possibly degraded low-resolution (LR) image and its
high-resolution (HR) counterpart. Finding this arrangement is difficult due to
the intractable nature of the problem. Techniques for discovering the mapping
can be divided into two areas: {\em interpolated} and {\em learning-based}.
Contemporary SISR has been dominated by deep learning which has demonstrated
superiority over hand-crafted methods such as bicubic and bilinear
interpolation.

%For example, Dong et al. \cite{dong2015image} introduced convolutional neural
%networks (CNNs) to the SISR domain by interpolating an LR image to a desired
%scale and then using supervised learning to find a mapping between the
%interpolated image and its HR counterpart. 

%Deeper CNNS:
%Researchers have since taken inspiration from the success of deeper CNNs in
%other domains \cite{he2016deep} to attain more accurate HR images
%\cite{kim2016accurate,kim2016deeply,lim2017enhanced,zhang2018image}.
%Nonetheless, a major difficulty in training deeper neural networks is
%stability.  Zhang et al. \cite{zhang2018image} proposed a very deep residual
%channel attention network that was stabilized by introducing residual in
%residual connections. Residual in residual connections allow gradients to take
%a shortcut when back-propagating through a network by the use of superficial
%recursion.  Other image restoration methods have carried this concept to its
%theoretical limits where varying levels of recursion must be supervised during
%the training process \cite{kim2016deeply}.

%Guided SISR:
%SR has a one-to-many mapping. As a result, there may be many solutions in the
%HR space. For example, while SR generative adversarial networks
%\cite{ledig2017photo} have attained impressive and highly-detailed results, the
%solutions produced with such methods often have a low-structural similarity
%with the ground truth. These guided techniques attempt to solve the one-to-many
%mapping by introducing HR images as a reference to the network. However, in
%practice, datasets do not always produce HR images and therefore it is
%necessary to continue to advance existing algorithms for SISR.

%Attention:
%CNNs have improved computational efficiency over multilayer perceptrons (MLP)
%primarily by parameter sharing. Normally, an MLP would introduce an unique
%parameter for each pixel in an image. In contrast, CNNs slide a kernel over the
%image thus requiring fewer parameters to learn. 

Convolutional neural networks (CNNs) have been shown to be successful at
attending to visual images on tasks such as SISR. This includes
squeeze-and-excitation methods for global excitation of feature maps
\cite{hu2018squeeze,li2019compressing}, and the use of weight excitations
\cite{quader2020weight,lin2020context}. Furthermore, ablation studies have
conclusively shown that excitation networks for feature maps bring performance
gains \cite{zhang2018image}. On another note, a variety of methods exist for
modifying the RF of a CNN either through concatenation \cite{li2018multi},
deformation \cite{dai2017deformable}, or dilation \cite{szegedy2015going}. In
this work, we study how dilated convolutions offer \emph{compression through
dilations}. Concretely, we show how they modify the effective receptive fields
(ERFs) of a CNN and how they interact with an existing enhancement known as
second-order channel attention (SOCA) \cite{dai2019second}.
 
The development of infrared thermographic cameras has spurred researchers to
carry out innovative research in the thermal image domain. Representing
traditional SR, Mandanici et al. \cite{mandanici2019multi} combined geometric
registration with projection and interpolation to produce HR thermal images.
Naturally, researchers have recently investigated color-guided thermal image SR
\cite{chen2016color,almasri2018rgb}. For example, a pyramidal network provided
by Gupta et al. \cite{gupta2020pyramidal} attains accurate results by extracting
edge-maps from RGB images at various levels of the network.  Chudasama et al.
\cite{chudasama2020therisurnet} present an efficient SR network for thermal
images by eliciting high-frequency details with a limited number of feature
extraction modules. Other works have introduced popular loss functions to the
field of thermal image SR \cite{almasri2018multimodal,kansal2020multi}.  

%Yet, there has been very little research on how these CNN enhancements affect
%effective receptive fields or whether there is an interaction between dilated
%convolutions and excitation networks. For instance, Hu et al.
%\cite{hu2018squeeze} have shown squeeze-and-excitation networks can enhance
%convolutional blocks at little cost. Inspired by squeeze-and-excitation
%methods, Zhang et al. \cite{zhang2018image} incorporated an attention mechanism
%that slides a kernel over a vector of channel-wise global statistics produced
%from an input image thus aiding the stabilization of very deep networks. In
%addition, Dai et al.  \cite{dai2019second} enhanced convolutional blocks with
%second-order statistics for the task of SISR. Yet, channel attention networks
%have not examined whether small amounts of contextual information can improve
%SISR results. Moreover, present systems have examined weight
%\cite{quader2020weight,lin2020context} and feature map excitations but have not
%studied how the reduction of CNN parameters via dilated convolutions
%\cite{li2019compressing} affects the performance of these excitation networks. 

%From our own visual system, we can intuitively see that we must attend to
%varying RFs. Likewise, with images of varying resolutions it can be beneficial
%to increase the RFs of CNNs used for extracting features. The most
%straightforward way to do this is to increase the size of the CNN's sliding
%kernel. On the other hand, dilated convolutions have shown to be a promising
%alternative \cite{shi2017single}. As an added benefit, dilated CNNs maintain
%resolution even when the dilation rate of the convolutions increase
%exponentially from layer to layer. 

%For image restoration, Li et al.  \cite{li2018multi} modified the `Inception'
%module proposed by \cite{szegedy2015going} to use dilated convolutions. On a
%related note, Dai et al. \cite{dai2017deformable} introduced deformable
%convolutions for object detection as a more generalized form of dilated
%convolutions. In comparison to changing the size of a RF by changing the size
%of the convolutional kernels, changing the size of RFs by changing the dilation
%rate uses much fewer parameters, increasing efficiency of the network. 

In this work we not only explore the use of efficient thermal SR, but we also
provide complete benchmarks on three thermal imagery datasets. Furthermore, we
compare the results of four architectural variants to assess performance gains
or losses due to the compression of parameters in our SR network. In contrast
to previous work on SISR, our proposed model applies SOCA to a concatenation of
features produced from convolutions with changing RFs. An intermediate
convolutional layer quantifies the importance of the values from each RF before
passing this information to SOCA. The key contributions of our work are the
following: (i) we show the effectiveness of SOCA for thermal image SR; (ii) we
present a novel approach to sample from a foveated RF; (iii) we demonstrate an
efficient network for multiple upscaling factors; (iv) we establish new
benchmarks on public thermal image datasets. Our source code is available at
\cite{attention_with_varying_receptive_fields_network}.

The rest of this paper is organized as follows. We provide a summary of related
thermal image SR work in Sec.~\ref{sec:related_work}, and the basics of SR in
Sec.~\ref{sec:preliminaries}. In
Sec.~\ref{sec:second-order_channel_attention_with_varying_receptive_fields}, we
propose an architecture for transforming LR input images to super-resolved
output images. In Sec.~\ref{sec:experimental_results}, we demonstrate our
dilation-rate driven deep attention to varying receptive fields network through
experimental results. Finally, we conclude in Sec.~\ref{sec:conclusion}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Related Work}
\label{sec:related_work}
Most recent developments in the image restoration domain focus on the visual
image space \cite{nasrollahi2014super,wang2020deep,anwar2020deep}. The known
importance of deeper CNNs in improving representational power has spurred the
development of architectures that improve stability and provide better
representations \cite{kim2016accurate,lim2017enhanced}. This is done not only
through more residual connections
\cite{kim2016deeply,anwar2020densely,liu2020residual}, but also through
structural preservation \cite{luo2016understanding,isobe2020video}, constrained
hypotheses spaces \cite{bahat2020explorable}, fast Fourier transform
\cite{reddy1996fft} and generative techniques \cite{saharia2021image}, and
student-teacher networks \cite{lee2020learning}. Additionally, SR works that
focus on improving contextual information have employed different attention
mechanisms \cite{mei2020image} and enhanced inception modules
\cite{muhammad2019multi}. 

%In this work, we discuss inception-related techniques \cite{szegedy2015going}
%and two global attention mechanisms \cite{zhang2018image,dai2019second} for the
%thermal imaging domain. Moreover, we offer interesting insights about which
%architectural enhancements offer the most performance gains by evaluating
%different architectural variants.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Preliminaries}
\label{sec:preliminaries}
The task of super-resolving an LR image to its HR counterpart may be summarized
by its image space and degradation model. Formally, the relationship can be
defined as 
\begin{equation}
  \bm{I}_x = D(\bm{I}_y;\bm{\theta}),
\end{equation}
where $D$ (known as the degradation function) maps an HR image $\textbf{I}_y$ to
an LR image $\textbf{I}_x$ with degradation parameters $\bm{\theta}$. Hence, SR
can be reduced to finding the parameters of $D$, however it is an intractable
process. Learning an SR model, $F$, can be formalized as 
\begin{equation}
  \bm{I}_y = F(\bm{I}_x;\bm{\theta}).
\end{equation}
Furthermore, any optimization algorithm can be applied to find these parameters
by minimizing an objective function,
\begin{equation}
  \hat{\bm{\theta}}= \argmin{\bm{\theta}} L(\hat{\bm{\theta}}_y,\bm{I}_y) + \lambda\psi(\bm{\theta}),
\end{equation}
where $\lambda$ is a small value that represents the importance of the
regularization term $\psi$. This term may aid a model's ability to generalize to
data never before seen. A common objective function to minimize is the mean
squared error (MSE) otherwise known as the 2-norm,
\begin{equation}
  \text{MSE}(\bm{I}_x,\bm{I}_y) =\frac{1}{N} \sum\limits_{i = 1}^{N}(\bm{I}_x(i) - \bm{I}_y(i))^2,
\end{equation}
where $N$ is the number of samples in a batch. 
 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Second-Order Channel Attention with Varying Receptive Fields}
\label{sec:second-order_channel_attention_with_varying_receptive_fields}
\begin{figure}
\centering
\includegraphics[scale=.38]{residual_body_2}
\caption{An overview of our thermal imaging SR model.}
\label{fig:residual_body_2}
\end{figure}
We establish a novel deep learning architecture for thermal image SR as
follows. First (Sec.~\ref{subsec:second-order_channel_attention}), we provide a
detailed description of SOCA. Second (Sec.~\ref{subsec:dilated_convolutions}),
we expound upon how dilated convolutions are computed. Third
(Sec.~\ref{subsec:compression_through_dilations}), we describe how CNNs can be
compressed with respect to an ERF via compression through dilations. Fourth
(Sec.~\ref{subsec:residual_in_residual}), we incorporate residual in residual to
aid in the stabilization of our network. Finally
(Sec.~\ref{subsec:model_overview}), we apply SOCA to separate RFs (by dilation
rates) within residual in residual to assist in the SR of LR images obtained
with a bicubic degradation model. 

\subsection{Second-Order Channel Attention}
\label{subsec:second-order_channel_attention}
We utilize an alternative SOCA network to enhance convolutional blocks by
supplying a covariance matrix that allows for more discriminative
representations. To produce these second-order statistics, the covariance
normalization is obtained through Newton-Schulz iteration
\cite{higham2008functions}. Additionally, this serves to speed up the
computation. First, a feature map of dimension $H \times W \times C$ is
reshaped into a feature map $\bm{X}$ of shape $HW \times C$.  Second, the
covariance matrix is calculated, 
\begin{equation}
  \bm{\Sigma} = \bm{X}\bm{I_f}\bm{X}^\top,
\end{equation}
where $\bm{I_f} = \frac{1}{s}(\bm{I} - \frac{1}{s}\bm{1})$ and $s=HW$. $\bm{I}$ and 
$\bm{1}$ are the $m \times m$ identity matrix and the matrix of all ones, 
respectively. Then, the covariance matrix is pre-normalized, 
\begin{equation}
  \bm{\hat{\Sigma}} = \frac{1}{\text{tr}(\bm{\Sigma})}\bm{\Sigma},
\end{equation}
where tr($\cdot$) denotes the matrix trace. Let $\bm{Y}_0 = \bm{\hat{\Sigma}}$ 
and $\bm{Z}_0 = \bm{I},$ then $\bm{Y_n}$ and $\bm{Z}_{n}$ are obtained by
\begin{align}
 \bm{Y}_n &= \frac{1}{2}\bm{Y}_{n-1}(3\bm{I} - 
                  \bm{Z}_{n-1}\bm{Y}_{n-1}),\\
  \bm{Z}_n &= \frac{1}{2}(3\bm{I} -
                      \bm{Z}_{n-1}\bm{Y}_{n-1})\bm{Z}_{n-1},
\end{align}
with $\bm{Y_n}$ and $\bm{Z}_{n}$ quadratically converging to $\bm{Y}$ and
$\bm{Y}^{-1}$, respectively. The final normalized matrix after five iterations
of Newton-Schulz is found by compensating the pre-normalization step with
\begin{equation}
  \bm{\hat{Y}} = \sqrt{tr(\bm{\Sigma})}\bm{Y}_N.
\end{equation}
Afterwards, global covariance pooling is applied to obtain a scalar-valued
statistic $z_i$ for each channel $i$, 
\begin{equation}
  \bm{z}_i = \frac{1}{C}\sum\limits_j^C \bm{\hat{Y}}_{ij}.
\end{equation}
This permits the channel attention to capture correlations higher than the
first order. In the next step, the sigmoid activation function serves as a
gating mechanism that entrusts the network to selectively choose what to add to
the incoming input features. To create this gating mechanism, we use two
convolutional layers, $\bm{W}_0$ and $\bm{W}_1$, with rectified linear unit
(ReLU) and sigmoid activation functions. Concretely, 
\begin{equation}
  G(\bm{z}) = \bm{W}_1 \ast (\bm{W}_0 \ast \bm{z}),
\end{equation}
where $\ast$ is the convolution operation and $G(\bm{z})$ is an attention map.

\subsection{Dilated Convolutions}
\label{subsec:dilated_convolutions}
A dilated convolution multiplies a rate $l$ by $\Delta$ during the convolution 
operation, i.e.,
\begin{equation}
  (F\ast_lk)(\textbf{p}) = \sum\limits_{\Delta \in \Omega_r} F(\textbf{p} - l \cdot \Delta)k(\Delta),
  \label{eq:dilated_convolution}
\end{equation}
where $\Omega_r = [-r,r]^2 \cap \mathbb{Z}^2$, $k: \Omega_r \to \mathbb{R}$,
$\bm{p} \in \mathbb{Z}^2$ is a location on $\bm{X}$, $F: \mathbb{Z}^2 \to
\mathbb{R}$, and $*_l$ is an $l$-dilated convolution. In
\eqref{eq:dilated_convolution}, $k$ is known as the kernel function which
slides over $\bm{X}$. This allows a convolutional network to sample pixel
values from a larger RF over the input features. 

In the case of SR, it is advantageous to sample from different sized RFs 
depending on a number of factors including depth, resolution, and the 
scaling factor. We use dilated convolutions to extract features within each 
residual block. Specifically, the feature sets of three convolutional layers 
with varying dilation rates are concatenated and passed to an intermediate layer 
which pools the information from contrasting RFs. This intermediate layer 
effectively pools information at each feature map's location from a foveated RF 
where more parameters are concentrated towards the center of the field.

\subsection{Compression through Dilations}
\label{subsec:compression_through_dilations}
We utilize dilated convolutions to artificially increase the ERFs of our CNN. An
ERF is defined as the area containing any input pixel with a non-negligible
impact on a particular output unit within a feature map
\cite{luo2016understanding}. In addition, we introduce the concept of
compression through dilations as the case in which a CNN uses fewer parameters
to increase an ERF with dilated convolutions compared to without dilated
convolutions. For example, assuming we are using bias, two single-layer CNNs
defined by $\text{Conv2D}(\text{Input\_Shape}= (32,32,3),64,(5,5))$ and
$\text{Conv2D}(\text{Input\_Shape}=(32,32,3), 64,(3,3),\text{Dilation\_Rate}=2)$
have an ERF area of 25. However, our CNN has 160,064 and 57,664 parameters,
respectively, giving a compression ratio of 2.776.

\subsection{Residual in Residual}
\label{subsec:residual_in_residual}
We stabilize our deep channel attention network by the addition of residual in
residual (RIR) connections \cite{zhang2018image}. RIR entails two
levels of connections with groups on the outer level and blocks on the inner
level. More precisely, 
\begin{equation}
\hat{{\bf Y}} = {\bf X} + {\bf W} \ast R_g(R_{g-1}(\ldots R_1({\bf X})\ldots)).
\end{equation}
$R_g$ is the $g$-th residual group and it is formulated as
\begin{equation}
R_g({\bf X}) = {\bf X} + {\bf W} \ast B_t(B_{t -1}(\ldots B_1({\bf X})\ldots)),
\label{eq:residual_groups}
\end{equation}
where $B_t$ is the $t$-th residual channel attention block. We apply SOCA to
the features extracted from the convolutional layers with unique RFs. To obtain
the individual RFs, we make the dilation rate of each convolutional layer
exclusive and not equal to one for two of the layers. For example, if $\bf
W_1$, $\bf W_2$, and $\bf W_3$ are the weight sets associated with three
convolutional layers, then the residual block is derived as
\begin{equation}
B_t({\bf X}) = {\bf X} + \text{SOCA}([{\bf W_1} \ast {\bf X}, {\bf W_2} \ast_2 {\bf X}, {\bf W_3} \ast_3 {\bf X}])
\label{eq:residual_block}
\end{equation}
where $[{\bf W_1}, {\bf W_2}, {\bf W_3}]$ constitutes the concatenation of $\bf
W_1$, $\bf W_2$, and $\bf W_3$ along the channel axis.

\subsection{Model Overview}
\label{subsec:model_overview}
Our overall model is shown in Fig.~\ref{fig:residual_body_2}. To upscale an
input image, features are extracted from a series of residual groups and blocks
within the RIR architecture similar to RCAN \cite{zhang2018image}. Pixel
shuffle \cite{shi2016real} is used to rearrange $\bm{X}$ of shape $(H,W,C\cdot
r^2)$ to $(H\cdot r,W\cdot r,C)$ by periodically building a new feature map
$PS(\bm{X})$ with pixel values from dissimilar channels according to the
equation 
\begin{equation}
  PS(\bm{X})_{x,y,c} = \bm{X}_{\lfloor x / r \rfloor, \lfloor y / r \rfloor, C \cdot r \cdot mod(y,r) + C \cdot mod(x,r) + c}.
\end{equation}
Finally, a single-channel convolutional layer reduces the number of channels to
the same number as in the LR image.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experimental Results}
\label{sec:experimental_results}
Our experiments model the downscaling of HR thermal images using a bicubic
degradation model with statistical noise.

\subsection{Datasets}
We use the Thermal Image Super-Resolution (TISR) 2020 Challenge dataset, the
FLIR Thermal Dataset for Algorithm Training (TDAT) \cite{flir2021}, and the
KAIST multispectral pedestrian detection benchmark dataset
\cite{hwang2015multispectral}. The TISR dataset consists of three sets of 1,021
images from three distinct cameras. These cameras include a Domo, Axis, and
FLIR with a resolution of ($160 \times 120$), ($320 \times 240$), and ($640
\times 480$), respectively. Of these images, 60 were kept private, leaving 951
in the training set and 50 in the test set for each camera. For TDAT, we
evaluate on only the first 100 images captured by a FLIR FC-6320 camera.
Lastly, for the KAIST dataset, we collect every 200-th image from the day and
night scenes and then evaluate on the set of 226 images. The images from the
KAIST dataset were captured by a FLIR-A35 thermal camera with a resolution of
$640 \times 480$.
%The resolutions of the images for each camera are displayed in
%Table~\ref{tab:TID951}.

The ground-truth dataset was created by first forming batches of 16
single-channel image patches where each patch is of size $scale \times 48$. The
LR images were then obtained by bicubicly interpolating these patches to a size
of $48 \times 48$. For both training and testing, the images were preprocessed
by adding Gaussian noise with a mean of 0 and a variance of 10 for the bicubic
with noise degradation model. Finally, all elements of each LR patch are
normalized and clipped to [0,1].

%\begin{table}
%\centering
%\begin{tabular}{|c|c|c|c|}
%\hline
%&{\bf Domo } & {\bf Axis} & {\bf Flir} \\
%\hline
%Resolution & 160 $\times$ 120 & 320 $\times$ 240 & 640 $\times$ 480 \\\cline{1-4}
%Training Images & 951 & 951 & 951 \\\cline{1-4}
%Testing Images & 50 & 50  & 50 \\\cline{1-4}
%\hline
%\end{tabular}
%\caption{The specifications used for training the SR model.}
%\label{tab:TID951}
%\end{table}

\subsection{Implementation}
Our final architecture uses three residual groups with six residual blocks per
group. Each convolutional layer has 64 filters resulting in a highly-efficient
network. During training, the Adam optimizer \cite{kingma2014adam},
parameterized by a learning rate of $10^{-4}, \beta_1 = 0.9, \beta_2 = 0.999$,
and $\epsilon = 10^{-7}$, is applied to minimize the MSE of each batch for 300
epochs. Training with four NVIDIA GeForce GTX 1080 Ti GPUs took less than three 
hours per model. 
 %The number of parameters for each model is presented in
%Table~\ref{tab:model_parameters}. 

%\begin{table}
%\centering
%\begin{tabular}{|c|c|}
%\hline
%{\bf Scale } & {\bf Parameters} \\
%\hline
%$\times$2 & 682305 \\\cline{1-2}
%$\times$3 & 703105 \\\cline{1-2}
%$\times$4 & 698945 \\\cline{1-2}
%\hline
%\end{tabular}
%\caption{The number of parameters for each model trained.}
%\label{tab:model_parameters}
%\end{table}

\subsection{Evaluation}
For the experiments, we tested four variants of our architecture to evaluate
the performance gains of the network. The variants are as follows.
\begin{itemize}
  \item Dilated residual in residual (DDRR): SOCA in the residual block of
  Fig.~\ref{fig:residual_body_2} is replaced by a convolutional layer with a $3
  \times 3$ kernel size and no activation function.
  \item Residual in residual with SOCA (RRSOCA): Our different dilation rate
  module in the residual block of Fig.~\ref{fig:residual_body_2} is replaced
  with a series of two convolutional layers each with a kernel size of $3
  \times 3$ and a ReLU activation function.
  \item Compressed RCAN (CRCAN) via dilated convolutions: This architecture is
  similar to RRSOCA, but the first and second convolutional layers have a
  dilation rate of 1 and 2, respectively.
  \item Attention to varying receptive fields network (AVRFN): This is our
  proposed model as shown in Fig.~\ref{fig:residual_body_2}.
\end{itemize}

\pgfplotstableread[col sep=comma]{data/thermal.csv}\data
\begin{table*}[ht]
 \centering
 \pgfplotstabletypeset[
 col sep=comma,
 columns={Test Set,Scale,Parameters,psnr,ssim},
 columns/Dataset/.style={column type={|c}, string type},
 columns/Test Set/.style={column type={|c}, string type},
 columns/Scale/.style={column type={|c}, string type},
 columns/Filters/.style={column type={|c}, string type},
 columns/Parameters/.style={column type={|c}, string type},
 columns/loss/.style={column type={|c}, string type},
 columns/psnr/.style={column name =PSNR,column type={|r},fixed zerofill, precision = 3},%fixed, dec sep align},
 columns/ssim/.style={column name =SSIM,column type={|r|},fixed zerofill, precision = 3},%, dec sep align},
 columns/lossstd/.style={column type={|c}, string type},
 columns/psnrstd/.style={column name =$\sigma (\text{PSNR})$,column type={|r},fixed zerofill, precision = 3},%fixed, dec sep align},
 columns/ssimstd/.style={column name =$\sigma (\text{SSIM})$,column type={|r|},fixed zerofill, precision = 3},%fixed, dec sep align},
% columns/model/.style={column name = Model, column type={|c}, string type},
% every nth row={2}/.style={after row/.add={expr  accum = {\pgfmathaccuma +
%\thisrow{psnr}}}},
% every nth row={2}/.style={after row/.add={\pgfmathaccuma}},
 every nth row={5}{before row = \bottomrule},
 every head row/.style={before row={\hline},after row=\hline},
 every last row/.style={after row=\hline},
%every odd row/.style={before row={\rowcolor{blue!40}}},
%highlight max row/.style={every row no #1/.style={before row={\rowcolor{red!40}}}},
 ]{\data}
\caption{The results of our AVRFN model on images captured by the TISR
\cite{rivadeneira2020thermal}, TDAT \cite{flir2021} and KAIST
\cite{hwang2015multispectral} datasets.}
\label{tab:thermal}
\end{table*}

\begin{figure}[ht]
\centering
\subfloat[]{
 \includegraphics[width=0.32\columnwidth]{Input10_domo_4x}
 \label{fig:Input32_axis_4x}
}
\subfloat[24.43/0.64]{
\includegraphics[width=0.32\columnwidth]{Output10_domo_4x}
\label{fig:Output32_axis_4x}
%\caption{PSNR: 24.4352, SSIM: .6425}
}
\subfloat[GT]{
\includegraphics[width=0.32\columnwidth]{10_domo_GT}
\label{fig:10_domo_GT}
%\caption{PSNR: 24.4352, SSIM: .6425}
}\\
\subfloat[]{
 \includegraphics[width=0.32\columnwidth]{Input32_axis_4x}
 \label{fig:Input10_domo_4x}
}
\subfloat[26.64/0.83]{
\includegraphics[width=0.32\columnwidth]{Output32_axis_4x}
\label{fig:Output10_domo_4x}
%\caption{PSNR: 26.6426, SSIM: .8324}
}
\subfloat[GT]{
\includegraphics[width=0.32\columnwidth]{32_axis_GT}
\label{fig:32_axis_GT}
%\caption{PSNR: 26.6426, SSIM: .8324}
}\\
\subfloat[]{
 \includegraphics[width=0.32\columnwidth]{Input33_flir_4x}
 \label{fig:Input33_flir_4x}
}
\subfloat[28.54/0.78]{
\includegraphics[width=0.32\columnwidth]{Output33_flir_4x}
\label{fig:Output33_flir_4x}
%\caption{PSNR: 28.5380, SSIM: .7829}
}
\subfloat[GT]{
\includegraphics[width=0.32\columnwidth]{33_flir_GT}
\label{fig:33_flir_GT}
%\caption{PSNR: 28.5380, SSIM: .7829}
}
\caption{Examples of (left column) downsampled images from (top row)
low-resolution, (middle row) medium-resolution, and (bottom row)
high-resolution thermal cameras, their $\times 4$ upscaled counterparts (middle
column), and the ground truth (GT) (right column). Additionally, (b), (e), and
(h) show the PSNR and SSIM scores, respectively, when evaluated against the
ground truth.}
\label{fig:upscaling_4x_inputs_and_outputs}
\end{figure}

Fig.~\ref{fig:upscaling_4x_inputs_and_outputs} highlights example inputs, SR
predictions, and the ground-truth images from the datasets. The added Gaussian
noise produces heavily pixelated input images which presents very difficult
conditions to evaluate our methods on. In all of our experiments, we use the
peak signal-to-noise ratio (PSNR) and structural similarity index (SSIM) to
evaluate each architectural variant. Table~\ref{tab:thermal} shows the
performance of our proposed AVRFN when evaluated on each of the datasets.
Additionally, Table~\ref{tab:thermal_ablation} provides an ablation study which
compares the performance of the various types of compression with different
channel attention networks. Note that we were unable to make a fair comparison
with related work found in \cite{chudasama2020therisurnet} since the
performance of our baseline method did not match. However, each of our variants
performed better than the baseline RCAN architecture. 

An interesting finding is that adding compression through dilations in the
residual block of RCAN leads to improved performance. After each residual
connection, the ERF resets to the kernel size of the succeeding CNN due to the
easy pass-through of low-level information found in residual networks
\cite{araujo2019computing}. Contemporary work has found a correlation between
larger ERFs and performance gains \cite{araujo2019computing}. We hypothesize
that by introducing compression through dilations in each residual block, we
increase the ERF at a faster rate thus allowing for performance gains. An
unexpected result is that DDRR, the only variant without any form of
channel-attention, performs significantly worse. This confirms previous
ablation studies \cite{zhang2018image}, but it also shows that most of the
performance gains arise from channel attention and not compression through
dilations. In addition, our varying dilation rate module (AVRFN) improves
performance over the baseline which shows that attending to different RFs can
improve performance. Nonetheless, our highest performance gains are obtained
when we simply add compression through dilations to the RCAN baseline. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}
\label{sec:conclusion}
In this work, we showed the advantage of attending to varying resolutions for
the reconstruction of thermal images by efficiently parametrizing a
convolutional layer with a dilation rate. Together with SOCA, our model achieves
state-of-the-art results on the task of thermal image SR and yields up-to-date
benchmarks for the research community.
%We achieved impressive results in comparison to contemporary methods in SR, 
%however, the very LR of thermal images leaves room for improvement in this 
%domain. During experiments, we noticed that attending to varying RFs can 
%destabilize a network. For instance, by simply increasing the number of 
%residual groups or blocks, the network fails to learn to accurately upsample LR 
%images. 
In the future, we intend to look at ways in which training may be further 
stabilized and how attention to uncertainty maps can improve the computational 
efficiency of thermal image SR. 

\pgfplotstableread[col sep=comma]{data/thermal_ablation.csv}\dataone
\begin{table*}[ht]
 \centering
 \pgfplotstabletypeset[
 col sep=comma,
 columns={Test Set,model,Scale,Parameters,psnr,ssim},
 columns/Dataset/.style={column type={|c}, string type},
 columns/Test Set/.style={column type={|c}, string type},
 columns/Scale/.style={column type={|c}, string type},
 columns/Filters/.style={column type={|c}, string type},
 columns/Parameters/.style={column type={|c}, string type},
 columns/loss/.style={column type={|c}, string type},
 columns/psnr/.style={column name =PSNR,column type={|r},fixed zerofill, precision = 3},%fixed, dec sep align},
 columns/ssim/.style={column name =SSIM,column type={|r|},fixed zerofill, precision = 3},%, dec sep align},
 columns/lossstd/.style={column type={|c}, string type},
 columns/psnrstd/.style={column name =$\sigma (\text{PSNR})$,column type={|r},fixed zerofill, precision = 3},%fixed, dec sep align},
 columns/ssimstd/.style={column name =$\sigma (\text{SSIM})$,column type={|r|},fixed zerofill, precision = 3},%fixed, dec sep align},
 columns/model/.style={column name = Model, column type={|c}, string type},
 every nth row={5}{before row = \bottomrule},
 every head row/.style={before row={\hline},after row=\hline},
 every last row/.style={after row=\hline},
    highlight col max={\dataone}{ssim},
   highlight col max1={\dataone}{ssim},
   highlight col max2={\dataone}{ssim},
   highlight col max3={\dataone}{ssim},
   highlight col max4={\dataone}{ssim},
    highlight col max={\dataone}{psnr},
   highlight col max1={\dataone}{psnr},
   highlight col max2={\dataone}{psnr},
   highlight col max3={\dataone}{psnr},
   highlight col max4={\dataone}{psnr},
 ]{data/thermal_ablation.csv}
\caption{The results of our $\times 4$ model variants on images captured by
the TISR \cite{rivadeneira2020thermal}, TDAT \cite{flir2021} and
KAIST \cite{hwang2015multispectral} datasets.}
\label{tab:thermal_ablation}
\end{table*}

% \tikzmath{\mathVal=0;}
% \tikzmath{\x=0;}
% \foreach \n[remember=\mathVal as \mathVal] in {0, ..., 4}{
%           \pgfplotstablegetelem{\n}{ssim}\of{\dataone}
% \tikzmath{\x=\pgfplotsretval;}
% \tikzmath{
%      if \x>\mathVal then {
%      \mathVal=\x;
%      };
%      } 
%}
%\begin{table}
%\centering
%\begin{adjustbox}{width=\columnwidth,center}
%\begin{tabular}{|c|c|c|c|c|c|c|c|}
%\hline
%{\bf \shortstack{Degradation\\Model}}&{\bf Metric} & {\bf Scale} & {\bf Domo} & {\bf Axis} & {\bf Flir} & {\bf Average}\\
%\hline
%\hline
%\multirow{5}{*}{Bicubic} 
%& PSNR & $\times 2$ & 32.7433 & 38.6015 & 41.2943 & 37.5463\\\cline{2-7}
%& SSIM & $\times 2$ & 0.9129 & 0.9733 & 0.9796 & 0.9553 \\\cline{2-7}
%& PSNR & $\times 3$ & 27.9577 & 31.4105 & 34.8680 & 31.4121 \\\cline{2-7}
%& SSIM & $\times 3$ & 0.8028 & 0.8859 & 0.9129 & 0.8672 \\\cline{2-7}
%& PSNR & $\times 4$ & 25.9636 & 28.9209 & 32.8057 & 29.2301 \\\cline{2-7}
%& SSIM & $\times 4$ & 0.7328 & 0.8419 & 0.8904 & 0.8216 \\\cline{2-7}
%\hline
%\multirow{5}{*}{\shortstack{Bicubic +\\ Noise}} 
%& PSNR & $\times 2$ & 27.7577 & 32.0474 & 33.3551 & 31.0534\\\cline{2-7}
%& SSIM & $\times 2$ & 0.8114 & 0.8868 & 0.9003 & 0.8661 \\\cline{2-7}
%& PSNR & $\times 3$ & 26.5613 & 28.9247 & 31.8594 & 29.1151\\\cline{2-7}
%& SSIM & $\times 3$ & 0.7381 & 0.8261 & 0.8703 & 0.8117 \\\cline{2-7}
%& PSNR & $\times 4$ & 24.8542 & 26.7681 & 30.1299 & 25.2507\\\cline{2-7}
%& SSIM & $\times 4$ & 0.6775 & 0.7805 & 0.8376 & 0.7652 \\\cline{2-7}
%\hline
%\end{tabular}
%\end{adjustbox}
%\caption{The results of our model for each thermal camera using the dataset 
%supplied by \cite{rivadeneira2020dataset}, TDAT \cite{flir2021}, and KAIST
%\cite{hwang2015multispectral} datasets.}
%\label{tab:TID951_test_results}
%\end{table}

%\begin{table}
%\centering
%\begin{adjustbox}{width=\columnwidth,center}
%\begin{tabular}{|c|c|c|c|c|c|c|}
%\hline
%\multirow{2}{*}{{\bf Team}} &\multicolumn{2}{c|}{{$\bf\times 2$, Domo}} &
%\multicolumn{2}{c|}{$\bf\times 3$, Axis} & \multicolumn{2}{c|}{$\bf\times 4$,
%Flir}\\\cline{2-7}
%& PSNR &SSIM & PSNR & SSIM & PSNR & SSIM\\
%\hline
%HPZ-OSU & 26.06 & 0.8686 & 26.11 & 0.8373 & 27.32 & 0.8589\\
%\hline
%MLCV-Lab\_SCNIT\_NTNU & 25.81 & {\bf 0.8858} & 26.35 & {\bf 0.8531} & 27.72 & {\bf 0.8758}\\
%\hline
%COUGER-AI & 25.45 & 0.8529 & 25.96 & 0.8271 & 27.31 & 0.8498\\
%\hline
%%Ours & {\bf 27.76} & {0.8114} & {\bf 28.92} & {0.8261} & {\bf 30.13} & 0.8376\\ 
%\hline
%\end{tabular}
%\end{adjustbox}
%\caption{A comparison of our average results against the top three contestants 
%of the 1st Thermal Image Super-Resolution Challenge 
%\cite{rivadeneira2020thermal}. }
%\label{tab:tisr_results}
%\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\newpage
\bibliographystyle{splncs04}
\bibliography{thermal_image_super-resolution_using_second-order_channel_attention_with_varying_receptive_fields}

\end{document}

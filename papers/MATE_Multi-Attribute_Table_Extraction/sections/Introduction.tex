
\section{Introduction} \label{sec:introduction}
There is an increasing interest in enriching existing datasets with additional relevant datasets from large data silos and data lakes.
In this context, efficient data discovery systems~\cite{fernandez2018aurum,miller2018open} become essential for many use cases, such as
feature extraction~\cite{nargesian2018table, esmailoghli2021cocoa, chepurko13arda, santos2021correlation}, data cleaning~\cite{yu2016string}, 
transformation discovery~\cite{DBLP:conf/btw/ozmenEA21, abedjan2015dataxformer}, and data ecosystems~\cite{agora}.

Given a dataset at hand, the most basic requirement of a table to be relevant for enrichment is its joinability~\cite{nargesian2020organizing, xiao2009top, zhu2019josie, chaudhuri2006primitive, yu2016string, fernandez2019lazo, esmailoghlicafe, esmailoghli2021cocoa, dong2021efficient, fernandez2018aurum, DBLP:journals/pvldb/ZhuNPM16, santos2021correlation}.
However, existing works on indexing and retrieving joinable tables from large corpora are limited to unary joins, i.e.,~where a single column is the join key. 
This limitation restricts the application and the efficiency of discovery systems for prevalent datasets with composite join keys,i.e.,~join keys composed of multiple columns~\cite{jiang2019holistic}.
For example, up to $37.5\%$ of the primary keys in the TPC-E and TPC-H benchmarks are composite keys.
Further, TPC-H and TPC-E benchmarks contain over $168M$ unique column combinations (UCCs)~\cite{heise2013scalable}, $99.9\%$ of which are  multi-column UCCs. The existence of such combinations is apriori unknown and unexpected for potential discovery tasks. In open data lakes primary key information and other metadata are generally not known. Most keys are often auto-generated columns that are not directly related to the table rows and their corresponding real-world entities. 
Therefore, a discovery task has to rely on undocumented key candidates. One could discover and index the UCCs, which is an exponentially expensive task w.r.t. both runtime and storage. Considering, our next example, we cannot even claim that join columns in web tables must have the uniqueness property.

Consider the following real-world example, where we explained the root cause of air  pollution measured in different European cities\footnote{\url{https://luftdaten.info/}}.
As the sensor data is limited to the three columns (timestamp, location, and pollution ratio)~\cite{meyerparticulate}., additional dimension tables on weather, public events, and road traffics, were needed to make sense of it. All of the relevant tables had to be discovered and joined based on the timestamp and location columns of the sensor dataset~\cite{meyerparticulate}

Using current single-column discovery systems, users have to either repeat the discovery process per key column or check the retrieved joinable tables to remove the false positive (FP) tables and rows, which is a daunting task.
According to our benchmark, users might encounter over $1000$ times more irrelevant table rows.
Thus, one would first find all tables that join with the timestamp and then filter those that have the correct location or vice versa.
In either case, there would be an overhead for removing irrelevant tables.
For example, searching for joinable tables in the Dresden Web Table Corpus\footnote{\url{https://wwwdb.inf.tu-dresden.de/misc/dwtc/}}) based on the location and timestamp leads to $700K$ and $4M$ candidate tables, respectively.
However, only $1,552$ of them contain the exact alignment of time and location that is useful to discover the pollution reasons.

Using a state-of-the-art system, such as JOSIE~\cite{zhu2019josie}, the runtime for verifying both columns for joins increases by an order of magnitude because discovering tables based on n-ary keys has a factorial time complexity in the number of attributes in each table. Besides, in contrast to the single column key scenario more candidate tables have to be scanned to identify the top-$k$ joinable tables as it is not guaranteed that the joinability of each join column is equally high in each candidate table. 
Leveraging an inverted index to achieve the efficient discovery of joinable tables is crucial, but building a multi-attribute inverted index requires factorial storage space, which is infeasible.

We propose \system, a data discovery system to efficiently find n-ary joinable tables from a large corpus with millions of tables for a given query table.
To the best of our knowledge, this is the first piece of work addressing the general dataset discovery problem for n-ary key joins at a large scale.
\system employs a pruning technique to detect the most promising table rows and apriori filter irrelevant tables.
It uses a new inverted index element called \emph{super key}, which is an order-independent and fixed-sized hash-value that merges all possible key values into a single index element.
This super key allows the system to check the existence of any given key value in the same spirit as a bloom filter.
To generate the super key, \system uses \hash a simple, yet effective, h\textbf{ASH} function for cheking the e\textbf{X}istance of arbitrary key values. It encodes all cell values based on distinctive properties to avoid collisions of similar join values. As a result, it significantly reduces the FP rate of joinable rows before searching for join attributes and exact matches within a row. 
% Let us illustrate this with an example: consider a data scientist that aims to discover the correlating features to the IMDB score of movies. She would like to explain why the \textit{director} and the \textit{actors} involved in movies impact the IMDB score and how. The key in this example could be the \textit{movie title}, where the name of the movie defines all the relevant information including the \textit{director} and the \textit{actors}. However, joining tables based on the \textit{movie title} will not help with the task at hand. The data scientist needs to find additional features about the \textit{actors} and the \textit{director} of the movie and see if the integrated columns can lead to a reasonable prediction power.
In addition to multi-column join discovery, other use cases and application can directly benefit from our approach to beat the exponential dimensionality of multi-column sets. The methods are readily adaptable for duplicate table discovery and union table discovery~\cite{lehmberg2017stitching, DBLP:journals/pvldb/CafarellaHK09, das2012finding, nargesian2018table, DBLP:conf/icde/BogatuFP020}, and spreadsheet transformation joins~\cite{DBLP:journals/pvldb/ZhuHC17}. For duplicate table detection, our hash function could serve as a prefilter for finding similar records. For table union search, the hash function could be applied in the same spirit as for joins.


In summary, our major contributions are as follows: 
% \vspace{-0.1cm}
\begin{packed_enum}
\item We formulate the general problem of table discovery with n-ary key joins and take the first step in solving this problem with a filter-based approach. 
\item We introduce \hash, which encodes the syntactic attributes of the key values to obtain hash results that optimally use a fixed bit space to avoid overlapping bits of similar join values. The hash function leads effectively filters non-joinable rows and fewer FP rates compared to the state-of-the-art hash functions and bloom filters.
Our super key simulates a multi-attribute inverted index with a fixed size hash.
We prove that our hash function does not cause any false negatives.
\item We introduce a two-tier filtering strategy that apriori prunes candidate tables that cannot be part of top-$k$ and candidate rows that are not joinable on all key columns without evaluating the actual row values.
\end{packed_enum}

%We conduct extensive experiments on two large corpora of open data datasets to evaluate our system. According to the experiments, our hash-based super key index leads to
%up to almost $20$ times faster discovery compared to the existing baseline. 
%The hash function used in \system is able to prune almost $500$ times more irrelevant rows than other state-of-the-art hash functions.

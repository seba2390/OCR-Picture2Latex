
%% bare_conf.tex
%% V1.4b
%% 2015/08/26
%% by Michael Shell
%% See:
%% http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.8b or later) with an IEEE
%% conference paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/pkg/ieeetran
%% and
%% http://www.ieee.org/

%%*************************************************************************
%% Legal Notice:
%% This code is offered as-is without any warranty either expressed or
%% implied; without even the implied warranty of MERCHANTABILITY or
%% FITNESS FOR A PARTICULAR PURPOSE! 
%% User assumes all risk.
%% In no event shall the IEEE or any contributor to this code be liable for
%% any damages or losses, including, but not limited to, incidental,
%% consequential, or any other damages, resulting from the use or misuse
%% of any information contained here.
%%
%% All comments are the opinions of their respective authors and are not
%% necessarily endorsed by the IEEE.
%%
%% This work is distributed under the LaTeX Project Public License (LPPL)
%% ( http://www.latex-project.org/ ) version 1.3, and may be freely used,
%% distributed and modified. A copy of the LPPL, version 1.3, is included
%% in the base LaTeX documentation of all distributions of LaTeX released
%% 2003/12/01 or later.
%% Retain all contribution notices and credits.
%% ** Modified files should be clearly indicated as such, including  **
%% ** renaming them and changing author support contact information. **
%%*************************************************************************


% *** Authors should verify (and, if needed, correct) their LaTeX system  ***
% *** with the testflow diagnostic prior to trusting their LaTeX platform ***
% *** with production work. The IEEE's font choices and paper sizes can   ***
% *** trigger bugs that do not appear when using other class files.       ***                          ***
% The testflow support page is at:
% http://www.michaelshell.org/tex/testflow/



\documentclass[conference]{IEEEtran}
% Some Computer Society conferences also require the compsoc mode option,
% but others use the standard conference format.
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[conference]{../sty/IEEEtran}





% Some very useful LaTeX packages include:
% (uncomment the ones you want to load)


% *** MISC UTILITY PACKAGES ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/pkg/ifpdf
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.






% *** CITATION PACKAGES ***
%
%\usepackage{cite}
% cite.sty was written by Donald Arseneau
% V1.6 and later of IEEEtran pre-defines the format of the cite.sty package
% \cite{} output to follow that of the IEEE. Loading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off
% such as if a citation ever needs to be enclosed in parenthesis.
% cite.sty is already installed on most LaTeX systems. Be sure and use
% version 5.0 (2009-03-20) and later if using hyperref.sty.
% The latest version can be obtained at:
% http://www.ctan.org/pkg/cite
% The documentation is contained in the cite.sty file itself.






% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
  \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation
% can be obtained at: 
% http://www.ctan.org/pkg/graphicx
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found at:
% http://www.ctan.org/pkg/epslatex
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). The IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex





% *** MATH PACKAGES ***
%
\usepackage{amsmath}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics.
%
% Note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/amsmath





% *** SPECIALIZED LIST PACKAGES ***
%
%\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as the IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/pkg/algorithms
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/pkg/algorithmicx




% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/array


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.




% *** SUBFIGURE PACKAGES ***
\ifCLASSOPTIONcompsoc
  \usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\else
  \usepackage[caption=false,font=footnotesize]{subfig}
\fi
% subfig.sty, written by Steven Douglas Cochran, is the modern replacement
% for subfigure.sty, the latter of which is no longer maintained and is
% incompatible with some LaTeX packages including fixltx2e. However,
% subfig.sty requires and automatically loads Axel Sommerfeldt's caption.sty
% which will override IEEEtran.cls' handling of captions and this will result
% in non-IEEE style figure/table captions. To prevent this problem, be sure
% and invoke subfig.sty's "caption=false" package option (available since
% subfig.sty version 1.3, 2005/06/28) as this is will preserve IEEEtran.cls
% handling of captions.
% Note that the Computer Society format requires a larger sans serif font
% than the serif footnote size font used in traditional IEEE formatting
% and thus the need to invoke different subfig.sty package options depending
% on whether compsoc mode has been enabled.
%
% The latest version and documentation of subfig.sty can be obtained at:
% http://www.ctan.org/pkg/subfig




% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure.
% Be aware that LaTeX2e kernels dated 2015 and later have fixltx2e.sty's
% corrections already built into the system in which case a warning will
% be issued if an attempt is made to load fixltx2e.sty as it is no longer
% needed.
% The latest version and documentation can be found at:
% http://www.ctan.org/pkg/fixltx2e


\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/stfloats
% Do not use the stfloats baselinefloat ability as the IEEE does not allow
% \baselineskip to stretch. Authors submitting work to the IEEE should note
% that the IEEE rarely uses double column equations and that authors should try
% to avoid such use. Do not be tempted to use the cuted.sty or midfloat.sty
% packages (also by Sigitas Tolusis) as the IEEE does not format its papers in
% such ways.
% Do not attempt to use stfloats with fixltx2e as they are incompatible.
% Instead, use Morten Hogholm'a dblfloatfix which combines the features
% of both fixltx2e and stfloats:
%
% \usepackage{dblfloatfix}
% The latest version can be found at:
% http://www.ctan.org/pkg/dblfloatfix




% *** PDF, URL AND HYPERLINK PACKAGES ***
%
\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/url
% Basically, \url{my_url_here}.
\usepackage{color}
\usepackage{gensymb}
\usepackage{comment}
\usepackage{multirow}


% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
%
% paper title
% Titles are generally capitalized except for words such as a, an, and, as,
% at, but, by, for, in, nor, of, on, or, the, to and up, which are usually
% not capitalized unless they are the first or last word of the title.
% Linebreaks \\ can be used within to get better formatting as desired.
% Do not put math or special symbols in the title.
\title{PointNet on FPGA for Real-Time LiDAR Point Cloud Processing}
%A FPGA-based LiDAR Processing Platform for Autonomous Driving


% author names and affiliations
% use a multiple column layout for up to three different
% affiliations
\author{
\IEEEauthorblockN{Lin Bai, Yecheng Lyu, Xin Xu and Xinming Huang}
\IEEEauthorblockA{Worcester Polytechnic Institute\\
Worcester, MA 01609, USA\\
\{lbai2, ylyu, xxu10, xhuang\}@wpi.edu}
%Author, Coauthor, Coauthor and Coauthor\\
%Affiliation 1\\
%Affiliation 2\\
%E-mail\\
}

% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}

% make the title area
\maketitle

% As a general rule, do not put math, special symbols or citations
% in the abstract
\begin{abstract}
LiDAR sensors have been widely used in many autonomous vehicle modalities, such as perception, mapping,  and localization. This paper presents an FPGA-based deep learning platform for real-time point cloud processing targeted on autonomous vehicles. The software driver for the Velodyne LiDAR sensor is modified and moved into the on-chip processor system, while the programmable logic is designed as a customized hardware accelerator. As the state-of-art deep learning algorithm for point cloud processing, PointNet is successfully implemented on the proposed FPGA platform. Targeted on a Xilinx Zynq UltraScale+ MPSoC ZCU104 development board, the FPGA implementations of PointNet achieve the computing performance of 182.1 GOPS and 280.0 GOPS for classification and segmentation respectively. The proposed design can support an input up to 4096 points per frame. The processing time is 19.8 ms for classification and 34.6 ms for segmentation, which meets the real-time requirement for most of the existing LiDAR sensors.
\end{abstract}

% no keywords




% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle



\section{Introduction}
% no \IEEEPARstart
% \hfill mds

% An example of a floating figure using the graphicx package.
% Note that \label must occur AFTER (or within) \caption.
% For figures, \caption should occur after the \includegraphics.
% Note that IEEEtran v1.7 and later has special internal code that
% is designed to preserve the operation of \label within \caption
% even when the captionsoff option is in effect. However, because
% of issues like this, it may be the safest practice to put all your
% \label just after \caption rather than within \caption{}.
%
% Reminder: the "draftcls" or "draftclsnofoot", not "draft", class
% option should be used if it is desired that the figures are to be
% displayed while in draft mode.
%
%\begin{figure}[!t]
%\centering
%\includegraphics[width=2.5in]{myfigure}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
%\caption{Simulation results for the network.}
%\label{fig_sim}
%\end{figure}

% Note that the IEEE typically puts floats only at the top, even when this
% results in a large percentage of a column being occupied by floats.


% An example of a double column floating figure using two subfigures.
% (The subfig.sty package must be loaded for this to work.)
% The subfigure \label commands are set within each subfloat command,
% and the \label for the overall figure must come after \caption.
% \hfil is used as a separator to get equal spacing.
% Watch out that the combined width of all the subfigures on a 
% line do not exceed the text width or a line break will occur.
%
%\begin{figure*}[!t]
%\centering
%\subfloat[Case I]{\includegraphics[width=2.5in]{box}%
%\label{fig_first_case}}
%\hfil
%\subfloat[Case II]{\includegraphics[width=2.5in]{box}%
%\label{fig_second_case}}
%\caption{Simulation results for the network.}
%\label{fig_sim}
%\end{figure*}
%
% Note that often IEEE papers with subfigures do not employ subfigure
% captions (using the optional argument to \subfloat[]), but instead will
% reference/describe all of them (a), (b), etc., within the main caption.
% Be aware that for subfig.sty to generate the (a), (b), etc., subfigure
% labels, the optional argument to \subfloat must be present. If a
% subcaption is not desired, just leave its contents blank,
% e.g., \subfloat[].


% An example of a floating table. Note that, for IEEE style tables, the
% \caption command should come BEFORE the table and, given that table
% captions serve much like titles, are usually capitalized except for words
% such as a, an, and, as, at, but, by, for, in, nor, of, on, or, the, to
% and up, which are usually not capitalized unless they are the first or
% last word of the caption. Table text will default to \footnotesize as
% the IEEE normally uses this smaller font for tables.
% The \label must come after \caption as always.
%
%\begin{table}[!t]
%% increase table row spacing, adjust to taste
%\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
%\caption{An Example of a Table}
%\label{table_example}
%\centering
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
%\begin{tabular}{|c||c|}
%\hline
%One & Two\\
%\hline
%Three & Four\\
%\hline
%\end{tabular}
%\end{table}


% Note that the IEEE does not put floats in the very first column
% - or typically anywhere on the first page for that matter. Also,
% in-text middle ("here") positioning is typically not used, but it
% is allowed and encouraged for Computer Society conferences (but
% not Computer Society journals). Most IEEE journals/conferences use
% top floats exclusively. 
% Note that, LaTeX2e, unlike IEEE journals/conferences, places
% footnotes above bottom floats. This can be corrected via the
% \fnbelowfloat command of the stfloats package.
Nowadays, LiDAR plays an important role in autonomous vehicle systems, due to its many advantages such as 3D information capturing capability, no environment light requirement, and etc. One or more LiDAR sensors are often installed on an autonomous vehicle for the modalities of perception\cite{zhou2018voxelnet}, mapping\cite{droeschel2018efficient}, and localization\cite{yin20193d}. One major challenge for a LiDAR system is real-time point cloud processing. 

% the power consumption problem
%The most commonly used point cloud processing unit is GPU (Graphic Processing Unit), which consumes in average 250W power per hour. Plus the power consumption of a PC, the minimum total power consumption is about 550W. Considering the maximum supply power of a 2017 Lincoln MKZ is 600W. Obviously, to support a PC on the car is not an optimal solution. Therefore, a low power LiDAR processing platform is much more suitable for autonomous vehicle application.

% why use point-based method
In general, point cloud neural networks can be divided into three subcategories: pixel-based approaches, voxel-based approaches and 3D point-based approaches. Pixel-based methods project the 3D point cloud into 2D, either Bird Eye View (BEV) \cite{ku2018joint} or front view\cite{chen2017multi}. Subsequently, deep neural networks for 2D images can be applied directly. The voxel-based methods partition the 3D space into voxel grid and utilize neural networks to extract features from this grid. Both aforementioned methods may lead to information loss. The 3D point-based method, however, directly takes the raw point cloud as input in the form of $(X,Y,Z,I)$. It does not need the complicated statistics operations when comparing to the voxel-based method. Meanwhile, it avoids too much information loss when comparing to the pixel-based method. The 3D point-based methods, such as PointNet\cite{qi2017pointnet}, can produce much higher accuracy and therefore have attracted lots of research attentions.

In the paper, we propose an FPGA platform for PointNet implementations. Because of the heterogeneous architecture, Xilinx Zynq SoC chip can run the software driver for LiDAR interface on its Processing System (PS) side, and put the customized hardware accelerator on the Programmable Logic (PL) side. Data transfer between PS and PL is via Direct Memory Access (DMA).

\section{Related Work}
Several previous works \cite{shen2018towards}\cite{wu2010high} were focused on accelerating matrix multiplication using one-dimension systolic array on FPGA, which achieved efficient resource usage and low bandwidth. Newly proposed architectures \cite{zhang2015optimizing}\cite{qiu2016going} for neural networks take advantage of Single Instruction Multiple Data (SIMD) structure for matrix multiplication.
Continental AG released Assisted \& Automated Driving Control Unit (ADCU)\cite{ADCU2018}, on which a Zynq UltraScale+ MPSoC chip was loaded. It supports LiDAR processing but no technical details were revealed. NVIDIA proposed DRIVE AGX self-driving computer platforms built on Xavier SoC chip, which is capable to process point cloud data received from a LiDAR. In \cite{lyu2018real} and \cite{lyu2018chipnet}, the LiDAR was connected to a PC via Ethernet, and after pre-processing on PC, feature maps were fed to a neural network accelerator in an FPGA.

%\textcolor{red}{more related works?}
%\textcolor{blue}{The reasons of using Zynq-based platform:
%1. extendability: with PL, more sensors with or without standard interface are easierto %connect to the platform.
%2. }
% Different from images who have fixed size, the number of points in point clouds especially in the region of interest varies.
% There are plenty MLP(Multi-Layer Perceptron) accelerators implemented on FPGA, but none of them was integrated into a platform for real application.

The contributions of this paper are summarized as follows:
\begin{enumerate}
    \item \textcolor{black}{To our knowledge, this is one of the first end-to-end FPGA-based platforms for point cloud deep learning}, via Ethernet. A LiDAR is connected to the PS side directly. After pre-processing by the LiDAR driver, point cloud is stored in DDR memory that is accessible to the hardware accelerator on PL side.
    \item More specifically, PointNet has been implemented on this platform as an example of point cloud deep learning algorithm. As the state-of-art deep neural network for point cloud processing, PointNet is the backbone of many latest works on 3D classifications and segmentation. Based on this, one can easily extend our implementation of PointNet accelerator to other neural networks.
    \item A scalable SIMD matrix multiplication architecture is proposed, which is capable of processing matrix in arbitrary size. This accelerator is able to process point cloud with arbitrary number of points and generate output in row order or column order. For an input of 4096 points per frame, the accelerator achieves the speed of 50.5 and 28.9 frames per second for classification and segmentation, respectively. Considering most of the LiDAR scans are at 10Hz, this accelerator fulfills the real time processing requirement.
    %\item \textcolor{blue}{A weights scheduler is proposed. By scheduling the weights storage pattern, the transpose of output matrix is an option. This make the max pooing operation more efficient.}
\end{enumerate}

The rest of the paper is organized as follows: The function of LiDAR driver is described in Section ~\ref{sec:driver}. After that, the structure of PointNet is introduced in Section ~\ref{sec:pointnet}. Section ~\ref{sec:optimize}-\ref{sec:hw_arch} states the hardware optimization techniques and architecture. The evaluation results and analysis are given in Section ~\ref{sec:result}. In the end, we conclude the paper in Section ~\ref{sec:conclude}.

\section{Point Cloud Pre-processing}\label{sec:driver}
Before fed into PointNet, the raw data from LiDAR need pre-processing. We modified the driver for the embedded ARM processor on our FPGA platform. Pre-processing includes the following operations:
\begin{enumerate}
    \item Coordinate Transformation: LiDAR scans the physical world in spherical coordinate, while the PointNet requires input data in Cartesian coordinate.
    \item Time Offset: The distance to an object is measured by the time difference between emitting and receiving optics after hitting the object. However, during this small round trip time, LiDAR rotates an angle. This leads to a time offset. LiDAR driver should compensate this time difference.
\end{enumerate}

\section{PointNet}\label{sec:pointnet}

\begin{figure*}
    \centering
    \includegraphics[width=0.8\textwidth]{fig/point_arch.png}
    \caption{PointNet for point cloud classification and segmentation}
    \label{fig:point_arch}
\end{figure*}

PointNet \cite{qi2017pointnet} is a state-of-art deep neural network algorithm that was developed for point cloud classification and segmentation. Unlike ordinary neural networks who adopt tensors as input, PointNet's input is a $n\times 3$ matrix where $n$ is the number of points and $3$ represents the position $(X,Y,Z)$ in Cartesian coordinate of one point. PointNet architecture is shown in Fig.~\ref{fig:point_arch}, where shared Multi-Layer Perceptron (MLP) is $1\times 1$ convolution mathematically. So PointNet can be realized by fully connected layers with branches. The transformation structures are illustrated in Fig.~\ref{fig:tnet} with input matrix $n\times M$, where $M=3$ in case of input transform and $M=64$ in feature transform.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\columnwidth]{fig/tnet.png}
    \caption{Transform structures in PointNet, where $n\times 3$ is for input transform and $n\times 64$ for feature transform}
    \label{fig:tnet}
\end{figure}

As one of the most well-known deep learning algorithms for point cloud processing, PointNet is widely used as the backbone of many state-of-the-art neural networks not only for classification and segmentation, but also for object detection. For instance, PointNet is used in PointFusion \cite{xu2018pointfusion} and Attentional PointNet \cite{paigwar2019attentional} to extract point-wise feature and global feature for object detection task. It also applies to STD \cite{yang2019std} and L3-Net \cite{lu2019l3}.

\section{Optimization Strategy}\label{sec:optimize}
\subsection{Loop optimization}
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\columnwidth]{fig/loop_opt.png}
    \caption{Loop optimization for matrix multiplication}
    \label{fig:loop_opt}
\end{figure}

From mathematical point of view, $1\times 1$ convolution is equivalent to matrix multiplication as shown in Fig.~\ref{fig:loop_opt}, which consists of 3 cascaded loops. To fully utilize the parallel processing capability of an FPGA, these loops needs to be optimized \cite{qiu2016going}\cite{ma2017optimizing} for balancing the process time and resource usage.

Loop-1: It depends on the storage of matrix. In PetaLinux or in C code, the matrix is stored in row orientation. In order to fetch data using DMA, it is not wise to unroll this loop.

Loop-2: Unrolling this loop determines how many times an accelerator has to read the input feature map. Together with loop-3, this is limited by the on-chip computation resources, i.e. DSP slices on the FPGA in our case.

Loop-3: Unrolling this loop increases the throughput of the accelerator. However, it is restricted by the communication bandwidth of HP (high performance) interface between PS and PL in Zynq. Partial unrolling of this loop leads to partial sum so that intermediate buffer becomes necessary, which can be merged into output buffer at the cost of high power consumption owning to on-chip memory access.

As for the weight matrix obtained from training, it can be pre-loaded into block RAM, so its storing and loading are flexible.

\subsection{Quantization}
A quantization during training method described in \cite{lyu2018chipnet} is adopted in this design. Avoiding the modification of TensorFlow source code, it supplies convenient solution for quantization. In this study, we quantizied PointNet parameters into 8-bit and 16-bit respectively.

\section{System Architecture of PointNet Hardware Accelerator}\label{sec:hw_arch}
Based on the description in Section~\ref{sec:pointnet}, all PointNet operations can be categorized into either matrix multiplication or max pooling. Therefore, the computing blocks involving in the PointNet accelerator (Fig.~\ref{fig:point_hw_arch}) are Process Element (PE) array for matrix multiplication, an adder array for partial sum, and a comparator array for max pooling and ReLU (Rectified Linear Unit). During inference, Batch Normalization (BN) is absorbed into the PE. Concerning to the feature map storage, double buffering technique is applied to both input buffer and weights buffer to boost the throughput. The output buffer is also designed as a two-stage buffer.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.95\columnwidth]{fig/point_hw_arch.png}
    \caption{Hardware architecture of PointNet accelerator}
    \label{fig:point_hw_arch}
\end{figure}

\subsection{PE Array and Buffers}
The PE consists of a multiplier array, an pipelined adder tree and an adder array. According to our loop unrolling method, loop 2 and 3 are both partially unrolled. Loop 2 partial unrolling determines the number of multipliers and the size of adder tree in each PE. Loop 3 partial unrolling factor is related to the size of weight buffer and number of PEs in the array.

As indicated as \textcircled{1} and \textcircled{2} in Fig.~\ref{fig:pe_arch}, the PE array supports both row-oriented output and column-oriented output by applying different reading patterns to the input and weight buffer.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.55\columnwidth]{fig/block_mmult.png}
    \caption{Matrix multiplication by block}
    \label{fig:pe_arch}
\end{figure}

Double buffering is designed for the input buffer and the weight buffer, so that the imbalance between processing throughput and HP port bandwidth is alleviated. Besides, a 2-stage output buffer is deployed right after the PE array. The first stage is for partial sum during matrix multiplication. It has wider bitwidth than the second stage. The second stage is for storing the final results and transferring data to DDR via DMA. This structure is designed for two reasons, one is to avoid the precision reduction introduced by matrix partitioning, the other one is to alleviate frequent reading of second stage output buffer, so partial sum accumulation and data sending to DDR can work simultaneously.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\columnwidth]{fig/pe_arch.png}
    \caption{Structure of the processing element and the buffers}
    \label{fig:block_mmult}
\end{figure}

\subsection{Max-pooling and ReLU}
In this PointNet accelerator, max-pooling and ReLU share one comparator array. Max-pooling is to find out the largest value in each feature that each column of the matrix. In order to merge max-pooling into matrix multiplication pipeline, the output pattern is charged from row-by-row to column-by-column for the PE array. The ReLU function compares the results with 0 to filter out the negative values. Besides ReLU, other similar function like ReLU6 is also supported.

\subsection{Operation Control}
Prior to run, ARM core sends configurations to register file block, including the number of points and its destination buffer. The matrix multiplication patterns are also pre-defined and loaded into register file, which determines how the result comes out (row oriented or column oriented) and whether the result will be sent to DDR or input buffer for the next operation. According to the configurations read from register file, a FSM (finite state machine) sends control signal to each block. Double buffering enables this accelerator to accept new weights or input during processing. The FSM also handles  the assignment of two buffers, one for receiving and the other for sending. The usage of register file speeds up the processing. By pre-loading all needed parameters into the accelerator, no interrupt based configuration mechanism is necessary, which avoids the slow down due to interrupt handling in PetaLinux. 

\begin{comment}
A multiplexer between buffers and PE array determines what data will be fed into PE array. The candidates are: 1) feature map from DDR, 2) feature map after max pooling and 3) partial sum from output/intermediate buffer during matrix multiplication. In case of partial sum, the accumulated sum in output buffer is read back to sum with partial sum in adder array after PE.  \textcolor{blue}{more descriptions on setting parameters} When working, Finite State Machine (FSM) reads these parameters from register file and determines the buffer read/write, output of multiplexers and so on. Using register file speeds up the processing speed because there is no need to configure accelerator via slow AXI-lite operation before reading stream data from DDR.
\end{comment}

\begin{comment}
\textcolor{blue}{In PointNet, max pooling is used to find out the largest value in each column, while the PE outputs matrix one row after another. More importantly, the number of point in input point clouds varies. All of these make the max pooling purely in Programmable Logic (PL) side inefficient. Therefore, a software/hardware co-design way is utilized, where max pooling is divided into two steps for PS side and PL side separately. First, ARM in PS side fetches the row oriented matrix and stores it back after doing transpose. And then, accelerator fetches this transposed matrix to the compactor array in Max Pooling block in Fig.~\ref{fig:point_hw_arch} in a stream way. The benefit this design are avoiding large on-chip resources consumed on matrix reforming or serial to parallel converter, and adapting to any size of input point cloud. The processing speed of matrix transpose in ARM versus matrix size is summarized in Tab.~\ref{tab:matrix_t}.}
\end{comment}

\section{Implementation Results}\label{sec:result}
The accelerator is designed using Simulink and the HDL Coder toolbox. The evaluation platform is Xilinx Zynq UltraScale+ MPSoC ZCU104 Development Kit. 
\begin{comment}
\textcolor{blue}{, whose PS is equipped with a quad-core ARM Cortex-A53 processor and a dual-core ARM Cortex-R5 processor. On the PL side, there are $460'800$ FFs (Flip-Flops), $230'400$ LUTs (Look-Up Tables), $38$Mbit on-chip RAMs and $1'728$ DSP slices.} 
\end{comment}
When operating in 64-bit mode, the maximum bandwidth of DDR is $102.4$Gbps at $800$MHz. The LiDAR mounted on this platform is Velodyne VLP-16.

Fig.~\ref{fig:sys_arch} presents the test setup of the LiDAR processing framework. PetaLinux operating system is running on the ARM core on PS side. The point cloud is received via Ethernet interface using UDP protocol. After processed by the Velodyne driver, point cloud in Cartesian coordinate ROI (region of interest) is transmitted into DDR memory. Then ARM loads setting parameters for the hardware accelerator through General Purpose (GP) port based on AXI-lite protocol. During execution, the accelerator loads or stores point cloud (or intermediate data) at DDR by DMA via High Performance (HP) port according to AXI Stream protocol.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\columnwidth]{fig/sys_arch.png}
    \caption{Overview of the LiDAR processing framework}
    \label{fig:sys_arch}
\end{figure}

As described in the previous sections, the matrix multiplication pattern is pre-loaded into configuration memory. Therefore, this design is able to implement the full PointNet or PointNet-vanilla, which is a simplified PointNet without transforms, for classification or segmentation task. The maximum number of points supported in this design is $4096$. Larger point cloud can be fed into this design after partitioning. For autonomous driving applications, a Velodyne VLP-16 LiDAR running at $10$Hz supplies around $360/0.2\times 16=28.8K$ points in each point cloud. Considering the normally used Region Of Interest (ROI) is a $20m\times 60m$ square in front of the vehicle (less than $1/6$), the points in ROI is less than $4096$. For high resolution LiDAR such as Velodyne HDL-64E, total number of poin
\begin{comment}
in each point cloud is $360/0.173\times 64=133.38K$. Even points
\end{comment}
in ROI is much larger than $4096$. To be fed into this accelerator, the point cloud can be sub-sampled or partitioned.

\begin{comment}
In order to compare the performance between quantized models and floating-point precision model, we reproduced the PointNet and PointNet-vanilla \cite{qi2017pointnet} and compared their classification accuracy using ModelNet40 dataset in Table~\ref{tab:quat_cmp}.

\begin{table}[htbp]
    \centering
    \caption{Comparison of accuracy after quantization}
    \begin{tabular}{|c|c|c|c|}
        \hline
        \multirow{2}{*}{Networks} & \multirow{2}{*}{Accuracy\cite{qi2017pointnet}} &
        \multicolumn{2}{c|}{Accuracy(reproduced)} \\
        \cline{3-4}
          & &  int8 & int16 \\
        \hline
        PointNet-vanilla   & \multirow{2}{*}{87.1\%} &  \multirow{2}{*}{85.8\%} & \multirow{2}{*}{86.7\%} \\
         classification  &  &  & \\
        \hline
        Point-classification & 89.2\% & 87.2\% & 87.5\%\\
        \hline
        %Point-segmentation & 83.7\% & & & \\
        %\hline
    \end{tabular}
    \label{tab:quat_cmp}
\end{table}
\end{comment}

\begin{comment}
The platform works as the procedural described bellow:\\
1. PS read the point cloud from LiDAR;\\
2. LiDAR driver processes the raw point cloud;\\
3. PS writes parameters for PointNet accelerator and triggers it;\\
4. PointNet accelerator reads point cloud from DDR and runs;\\
5. When finish, PointNet sends an interrupt signal to PS;\\
6. PS reads the result back for display.\\
\end{comment}

\begin{comment}
\textcolor{blue}{
When running on the Intel i7 7700K CPU, segmenting each point cloud costs around $187.6$ms. While in this accelerator(quantized to 12-bit), however, to process a point cloud with the same size, it takes XXXms, which is XX times faster. In case of classification task, CPU costs $XXX$ms and our accelerator is XXX times faster.
}
\end{comment}


Table~\ref{tab:bitwidth} summarizes the on-chip resources consumption when choosing matrix dimension size of $M=32$ and $N=32$ in Fig~\ref{fig:pe_arch}. In practical applications, users can choose the suitable bitwidth based on available FPGA resource and processing speed requirement.

\begin{table}[htbp]
    \centering
    \caption{FPGA resource consumption of PointNet}
    \begin{tabular}{ |c|c|c|c|c|c| } 
        \hline
        Width & LUT & FF & DSP & BRAM & URAM \\
        \hline
        \multirow{2}{*}{INT8} & 19530 & 36010 & 1026 & 114 & 48\\
                              & 8\%   & 8\%   & 60\% & 37\%& 50\%\\ 
        \hline
        \multirow{2}{*}{INT16} & 30933 & 60412 & 1026 & 123 & 96\\ 
                               & 13\%  & 13\%  & 60\% & 39\%& 100\%\\ 
        \hline
    \end{tabular}
    \label{tab:bitwidth}
\end{table}

Tab.~\ref{tab:perform} compares the throughput and processing speed in terms of different quantization bit width.
\begin{comment}
Considering the processing time of ARM (22.3ms in average), 
\end{comment}
The PointNet accelerator takes 19.8 ms and 34.6 ms to classify and segment a point cloud with 4096 points respectively when using INT8 quantization. Considering most of the LiDAR scans at 10Hz, this PointNet accelerator is able to work in real time.

\begin{table}[htbp]
    \centering
    \caption{Comparison of performance}
    \begin{tabular}{|c|c|c|c|c|}
        \hline
        \multirow{2}{*}{Networks} & \multicolumn{2}{c|}{Throughput(GOPS)} &
        \multicolumn{2}{c|}{Processing time(ms)} \\
        \cline{2-5}
          & int8 & int16 & int8 & int16 \\
        \hline
        PointNet-vanilla   & \multirow{2}{*}{112.5} & \multirow{2}{*}{64.9} & \multirow{2}{*}{10.9} & \multirow{2}{*}{18.9} \\
         classification      &  &  &  & \\
        \hline
        Point-classification & 182.1 & 130.0 & 19.8 & 27.8\\
        \hline
        Point-segmentation   & 280.0 & 227.4 & 34.6 & 42.6\\
        \hline
    \end{tabular}
    \label{tab:perform}
\end{table}


\section{Conclusions}\label{sec:conclude}
In this paper, a FPGA-based LiDAR processing platform is proposed to accelerate point cloud deep learning algorithms. More specifically, a scalable PointNet hardware accelerator has been implemented on the FPGA SoC platform. For classification of an input frame with 4096 points, it only takes 19.8 ms reaching an estimated performance of about 182.1 GOPS. For segmentation task, it takes 34.6 ms per frame at the performance of about 280 GOPS. In addition, the design leaves some resource margin, so one can easily extend it for more advanced detection neural networks such as PointFusion\cite{xu2018pointfusion} and Attentional PointNet\cite{paigwar2019attentional}, or other segmentation neural networks like STD\cite{yang2019std} and L3-Net\cite{lu2019l3}.

\begin{comment}
In our future work, the very first layer can be kept as floating-point operation using NEON floating and vector co-processors, which may improve the accuracy of the PointNet accelerator.
\end{comment}




% conference papers do not normally have an appendix


% use section* for acknowledgment
\section*{Acknowledgment}
% \textcolor{blue}{The authors would like to thank the support from Mathworks Inc.}.
% This work is supported b Mathworks Inc.
This work was supported by the Mathworks Inc.





% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://mirror.ctan.org/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
%\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)
%\begin{thebibliography}{1}

%\bibitem{IEEEhowto:kopka}
%PointFusion: [PointFusion: Deep Sensor Fusion for 3D Bounding Box Estimation]\\
%aPN3d: [Attentional PointNet for 3D-Object Detection in Point Clouds]\\
%std: [STD: Sparse-to-Dense 3D Object Detector for Point Cloud]\\
%l3: [L3-Net: Towards Learning based LiDAR Localization for Autonomous Driving]\\
%\end{thebibliography}

\bibliographystyle{ieeetr}
\bibliography{lidar_platform}


% that's all folks
\end{document}



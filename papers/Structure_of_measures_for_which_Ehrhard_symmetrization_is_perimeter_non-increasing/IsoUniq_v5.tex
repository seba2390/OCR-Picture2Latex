\documentclass[12pt]{amsart}
\usepackage{amsmath,amsthm,amsfonts,amssymb, wrapfig}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{mathrsfs}
\usepackage{enumitem}
\usepackage{wrapfig}
\usepackage{etoolbox}
\usepackage{comment}
\usepackage{xcolor}
\apptocmd{\sloppy}{\hbadness 10000\relax}{}{}
\apptocmd{\sloppy}{\vbadness 10000\relax}{}{}
\usepackage[pdfpagelabels]{hyperref}
\usepackage[letterpaper,margin=1.1in]{geometry}

%\graphicspath{{./images/}}


\setcounter{tocdepth}{1}

\newcommand{\alert}[1]{{\scriptsize\ \color{magenta}\textbf{ALERT:} #1 \color{black}\ \normalsize}}
\newcommand{\sean}[1]{{\scriptsize\ \color{blue}\textbf{Sean's note:} #1 \color{black}\ \normalsize}}
\newcommand{\kuanting}[1]{{\scriptsize\ \color{purple}\textbf{kuanting's note:} #1 \color{black}\ \normalsize}}



\numberwithin{equation}{section}
\theoremstyle{plain}
\newtheorem*{atst}{Analyst's Traveling Salesman Theorem}
\newtheorem*{ptst}{Parametric Traveling Salesman Theorem}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{porism}[theorem]{Porism}
\newtheorem{corollary}[theorem]{Corollary}

\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{conjecture}[theorem]{Conjecture}

\newtheorem*{convention}{Convention}


\theoremstyle{definition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{algorithm}[theorem]{Algorithm}
\newtheorem{characterizationproblem}[theorem]{A characterization problem}

\newtheorem{prob}{Problem}

\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\Span}{\mathop\mathrm{span}\nolimits}

\DeclareRobustCommand{\l2title}{\texorpdfstring{$\ell_2$}{l\_2}}
\DeclareRobustCommand{\lptitle}{\texorpdfstring{$\ell_p$}{l\_p}}
\DeclareRobustCommand{\latitle}{\texorpdfstring{$\ell_p^2$ }{l\_p\textasciicircum2 }}
\DeclareRobustCommand{\lbtitle}{\texorpdfstring{$\ell_p^3$}{l\_p\textasciicircum3}}

%\def\l{\lambda}
\def\L{\Lambda}
\def\RR{\mathbb{R}}
\def\ZZ{\mathbb{Z}}
\def\N{\mathbb{N}}
\def\B{\mathbb{B}}
\def\W{\mathcal{W}}
\def\J{\mathcal{J}}
\def\XX{\mathbb{X}}
\def\e{\varepsilon}
\def\g{\gamma}
\def\d{\delta}
\def\D{\Delta}
\def\z{\zeta}
\def\G{\Gamma}
\def\a{\alpha}


\def\Xint#1{\mathchoice
{\XXint\displaystyle\textstyle{#1}}%
{\XXint\textstyle\scriptstyle{#1}}%
{\XXint\scriptstyle\scriptscriptstyle{#1}}%
{\XXint\scriptscriptstyle\scriptscriptstyle{#1}}%
\!\int}
\def\XXint#1#2#3{{\setbox0=\hbox{$#1{#2#3}{\int}$ }
\vcenter{\hbox{$#2#3$ }}\kern-.6\wd0}}
\def\ddashint{\Xint=}
\def\dashint{\Xint-}

\renewcommand{\baselinestretch}{1.1}

\newcommand{\Flat}{\mathsf{Flat}}

\newcommand{\diam}{\mathop\mathrm{diam}\nolimits}
\newcommand{\dist}{\mathop\mathrm{dist}\nolimits}
\newcommand{\side}{\mathop\mathrm{side}\nolimits}

\newcommand{\loc}{\mathrm{loc}}

\newcommand{\cX}{\mathcal{X}}
\newcommand{\cS}{\mathcal{S}}
\newcommand{\cG}{\mathcal{G}}
\newcommand{\cC}{\mathcal{C}}
\newcommand{\cW}{\mathcal{W}}
\newcommand{\cM}{\mathcal{M}}
\newcommand{\cT}{\mathcal{T}}
\newcommand{\bH}{\mathbb{H}}

\newcommand{\Mod}{\operatorname{Mod}}
\newcommand{\Hold}{\mathop\mathrm{H\ddot{o}ld}\nolimits}
\newcommand{\Lip}{\mathop\mathrm{Lip}\nolimits}
\newcommand{\res}{\hbox{ {\vrule height .22cm}{\leaders\hrule\hskip.2cm} }}
\newcommand{\core}{\operatorname{Core}}
\newcommand{\Area}{\operatorname{Area}}
\newcommand{\card}{\operatorname{card}}
\newcommand{\Haus}{\mathcal{H}}
\newcommand{\Length}{\mathop\mathrm{length}\nolimits}

\newcommand{\excess}{\mathop\mathrm{excess}\nolimits}

\newcommand{\interior}{\mathrm{int}}

\newcommand{\fI}{\mathfrak{I}}
\newcommand{\Bd}{\mathrm{Bd}}
\newcommand{\Wh}{\mathrm{Wh}}

\newcommand{\sS}{\mathscr{S}}

\usepackage{alphalph}
%\def\theequation{\AlphAlph{\value{equation}}}      for labeling equations (A), (B), etc.

\title{Structure of Measures for which Ehrhard symmetrization is Perimeter non-increasing}
\author{Sean McCurdy and Kuan-Ting Yeh}

%\subjclass[2010]{Primary 28A75; Secondary 26A16, 28A80, 30L05, 65D10}
\keywords{Ehrhard symmetrization, log-concave measures}

\address{Department of Mathematics\\ National Taiwan Normal University\\ Taipei, Taiwan}
\email{smccurdy@ntnu.edu.tw}

\address{Department of Mathematics\\ University of Washington\\ Seattle, WA}
\email{kty1116@uw.edu}


\begin{document}

\maketitle

\begin{abstract}  
In this paper, we prove that isotropic Gaussian functions are \textit{characterized} by a rearrangement inequality for weighted perimeter in dimensions $n \ge 2$ within the class of non-negative weights in $L^1(\mathbb{R}^n) \cap W^{1,1}_{loc}(\mathbb{R}^n)$.  More specifically, we prove that within this class generalized Ehrhard symmetrization is perimeter non-increasing for all Borel sets $E$ in all directions $\vec{v}$ if and only if the distribution function is an isotropic Gaussian.
\end{abstract}

\tableofcontents

\section{Introduction}

The main result of this paper is the characterization of weight distributions that satisfy a symmetrization inequality for their weighted perimeter within the class of non-negative $L^1(\mathbb{R}^n) \cap W^{1, 1}_{loc}(\mathbb{R}^n)$ weights for $n \ge 2$.  

Symmetrization inequalities are a basic tool in the study of isoperimetric problems. In Euclidean space, Steiner symmetrization has played a fundamental role in the study of isoperimetric problems, shape optimization, and rearrangement inequalities  (see, for example, \cite{Steiner1838}\cite{Chlebk2005ThePI}\cite{Krahn25}\cite{PolyaSzego51}\cite{Talenti76} and the hundreds of papers they have inspired).  In Gauss space $(\mathbb{R}^n, \gamma_n)$, the underlying measure is not Lebesgue measure $\mathscr{L}^n$ but $\gamma_n$, defined by 
$$\gamma_n(E)=\frac{1}{(2\pi)^{n/2}}\int_Ee^{-|x|^2/2}\ dx$$
for any measurable set $E\subset \mathbb{R}^n$.
While the Gaussian isoperimetric problem was independently proved by \cite{Borell75_Gaussisoperi} and \cite{CirelsonSudakov74_Gisoperi} without symmetrization, Ehrhard introduced generalized Steiner symmetrization to the underlying measure $\gamma_n$ and used it to provide an elementary geometric proof of the Gaussian isoperimetric inequality via the Borell inequality, a Gaussian variation on the Brunn-Minkowski inequality \cite{Ehrhard82,Ehrhard83,Ehrhard84}. Since then, Erhard symmetrization has become an important tool in the study of the Gaussian isoperimetric problems, Gaussian analogs of Faber-Krahn inequalities, and related rearrangement inequalities (see, for example, \cite{Ehrhard84}\cite{CianchiFuscoMaggiPratelli11}\cite{CarlenKerce01}\cite{BrockChiacchioMercaldo12} among many, many others). Similar statements hold for Schwarz symmetrization, spherical symmetrization, etc. with similarly extensive bibliographies.

The fundamental role of symmetrization inequalities in all these areas leads to a general interest in measures $\mu$, which satisfy a symmetrization inequality for the perimeter.  Roughly speaking, the problem may be phrased as follows:
\begin{characterizationproblem}
    Given a class of measures $\mathscr{W}$ and a generalized symmetrization procedure such that for every $\mu \in \mathscr{W}$ one can define an appropriate notion of weighted $\mu$-perimeter and symmetrization with respect to $\mu$, \textit{characterize} all $\mu \in \mathscr{W}$ such that $\text{Per}_{\mu}(S(E)) \le \text{Per}_{\mu}(E)$
    for all measurable sets $E \subset \mathbb{R}^n$ and all symmetrizations $S$.
\end{characterizationproblem}
For want of a better term, we shall call measures $\mu$ which satisfy their respective perimeter symmetrization inequalities \textit{perimeter symmetrization measures} or PS measures.

Solutions to this ``characterization problem" are available in a variety of contexts.  For example, Bobkov proved that within the class of log-concave measures $\mu$ on $\mathbb{R}$, $\mu$ is a PS measure if and only if $\mu$ is symmetric, where it must be noted that Bobkov used the $\varepsilon$-enlargement definition of perimeter and a generalization of Ehrhard symmetrization (\cite{Bobkov96} Lemma 2.2).  Though not phrased in this way, Chambers's solution to the Log-convex Density Conjecture proves that, in fact, all smooth radial log-convex measures are PS measures for a generalization of Schwarz symmetrization (appropriately centered) and distributional perimeter \cite{Chambers19}.  Recently, the second author provided a characterization of the equality case in the isoperimetric inequality for \textit{anisotropic} Gaussian functions \cite{Yeh2023}.  As a part of this work, the second author has proved that isotropic Gaussian distributions are the unique PS measures within the class of Gaussian distributions on $\mathbb{R}^n$ for a generalized notion of Ehrhard symmetrization and distributional perimeter \cite{Yeh2023}.

To the best of the authors' knowledge, all cases in which the characterization problem has been solved, the class under consideration is very restrictive.  Of course, the geometry of the underlying measure $\mu$ plays a large role, and symmetrization inequalities are expected to be very rigid, at least for $n \ge 2$.  The known examples of PS measures and their symmetrization procedures are more or less expected to be unique.  Explicit computation shows that, for example, the weighted $\mu$-perimeter might not always decrease under generalized Ehrhard symmetrization if $\mu$ is an anisotropic Gaussian (see \cite{Yeh2023} Example 4.1).  However, expectation and the breakdown of known arguments does not constitute proof.  

The goal of this paper is to provide a characterization of PS measures for weighted distributional perimeter and a generalization of Ehrhard symmetrization for a large class $\mathscr{W}$.

\begin{definition}[The set up]
Let $\mathscr{W}(\mathbb{R}^n)$ be the class of measures $\mu$ whose distribution function $\frac{d\mu}{d\mathscr{L}^n} = f$ is non-negative and in $L^1(\mathbb{R}^n)\cap W^{1,1}_{loc}(\mathbb{R}^n)$.

Because such measures are finite, we will consider a generalized version of Ehrhard symmetrization.  See Section \ref{Generalized Ehrhard symmetrization} for definitions and basic properties. As our notion of the perimeter, we shall use the distributional perimeter, that is, the language of weighted BV functions and sets of finite $\mu$-perimeter. See Section \ref{Sets of Finite mu-perimeter and weighted BV functions} for definitions and basic properties.
\end{definition}

\begin{theorem}[Main Theorem]\label{Main Theorem}
Let $n \ge 2$ and $\mu \in \mathscr{W}(\mathbb{R}^n)$, as above.  Then, 
\begin{align} \label{e:main theorem symmetrization ineq}
\operatorname{Per}_{\mu}(E) \ge \operatorname{Per}_{\mu}(S(E))
\end{align}
for all Borel sets $E \subset \mathbb{R}^n$ and all generalized Ehrhard symmetrization rearrangements $S$ if and only if $\mu$ has a distribution function $f(x) = Ce^{-c|x-a|^2}$ for some $0<c<\infty$, $0 \le C <\infty$, and $a \in \mathbb{R}^n$.  
\end{theorem}

The proof that isotropic Gaussian functions satisfy \eqref{e:main theorem symmetrization ineq} is due to Ehrhard \cite{Ehrhard82} if we use the $\varepsilon$-enlargement definition of the perimeter. It is due to \cite{CianchiFuscoMaggiPratelli11} (Theorem 4.3) using the weighted distributional perimeter. As stated above, we shall follow \cite{CianchiFuscoMaggiPratelli11} and use distributional perimeters and the language of weighted BV functions. As such, the contribution of this paper is the following result.

\begin{theorem}[Isotropic Uniqueness]\label{t:main theorem 2}
    Suppose that $n \ge 2$ and $\mu \in \mathscr{W}(\mathbb{R}^n)$.  If $\vec{v}$-Ehrhard symmetrization is $\mu$-perimeter non-increasing for all sets $E \subset \mathbb{R}^n$ for all $\vec{v} \in \mathbb{S}^{n-1}$, then there exist constants $0<c<\infty$, $0\le C<\infty$, and $a \in \mathbb{R}^n$ such that
    \begin{align*}
        f(x) = Ce^{-c|x-a|^2}.
    \end{align*}
\end{theorem}


\begin{remark}
Theorem \ref{t:main theorem 2}, and therefore Theorem \ref{Main Theorem}, fails in $n=1$.  In fact, the characterization problem seems much more difficult in $\mathbb{R}$.  For example, it is easy to construct measures $\mu$ which are PS measures, but which are not even log-concave.  See Example \ref{ex:1}. To the best of the authors' knowledge, the question of characterizing PS measures on $\mathbb{R}$ for generalized Ehrhard symmetrization in the class $L^1(\mathbb{R}) \cap C(\mathbb{R})$ is open.
\end{remark}

The proof of Theorem \ref{t:main theorem 2} differs from the proofs of other solutions to the ``characterization problem," which rely heavily upon the assumed structure of their measures.  In \cite{Bobkov96}, the proof in the log-convex case essentially follows from the definition of log-convexity and an argument analogous to Lemma \ref{l:Ehrhard implies symmetric}.  The second author's solution for general Gaussian functions was accomplished by a detailed study of the relationship between generalized Ehrhard symmetrization and the eigenvectors of the symmetric positive definite matrix $A$ for distributions defined by $e^{-\langle Ax, x\rangle /2}$ \cite{Yeh2023}.  Our solution is most closely related to \cite{Chambers19}, whose proof employs spherical cap symmetrization and a careful study of the ODE one obtains for curves of spherically symmetric perimeter minimizers.  Symmetrization and variational techniques form the heart of our solution as well, but without relying upon smooth distributions or very strong structural assumptions like radial symmetry and log-convexity.

The proof of Theorem \ref{t:main theorem 2} has three steps. Assuming that $\mu$ is a PS measure, we first prove that all half-spaces are perimeter minimizers for the weighted $\mu$-perimeter (Lemma \ref{l:H are minimal}).  Our argument is a new one, following an intuitive ``see a hole, fill it in" strategy, which is distinct from previous proofs that half-spaces are minimizers for $\mu = \gamma_n$.  For the Gaussian $\gamma_n$, Ehrhard has a geometric proof that half-spaces are minimizers in \cite{Ehrhard83} (Proposition 1.5), though the interested reader should seek out  \cite{lifshits1995gaussian} Chapter 11``Convexity and the Isoperimetric Property" for a detailed English version of the proof. This geometric proof that half-spaces are $\gamma_n$-perimeter minimizers relies essentially upon several key properties of the Gaussian measure $\gamma_n$: it is isotropic, admits a product structure in all orthogonal bases, and is log-convex. Our proof does not rely upon these properties.  Broadly speaking, Theorem \ref{t:main theorem 2} shows that these properties are a consequence of the symmetrization inequality.  It is the fact that our perimeter minimizers are half-planes which allows us to avoid the more complicated ODE and regularity arguments in \cite{Chambers19}.

The next step is to prove that the distribution function $f$ admits a product structure in all orthogonal bases (Lemma \ref{l:product structure}).  To do this, we use variational techniques like those employed by \cite{Rosales14} in the study of isoperimetric sets for perturbations of log-concave measures and \cite{BrockChiacchioMercaldo12}\cite{BrockChiacchio16} in the study of the structure of measures with foliations by isoperimetric sets. We note, however, that allowing $f$ to vanish introduces several technical challenges.

The last step is to exploit the fact that PS measures in $1$ dimension must be symmetric.  This symmetry, combined with the product structure, forces the distribution function to be radial, which immediately leads to the proof of Theorem \ref{t:main theorem 2}.  We note that in order to prove that $f$ is radial, we must engage in a highly technical reflection argument. For ease of reading, this reflection argument has been pushed to Appendix A (Section \ref{The Reflection Argument}).

The organization of the rest of the paper is as follows.  Section 2 provides the background for weighted $BV$ functions for weights in $\mathscr{W}(\mathbb{R}^n)$.  This gives us the definition of $\text{Per}_{\mu}$ and some important compactness results, which will be essential to Section 3.  Section 2 also gives the definition of generalized Ehrhard symmetrization with respect to $\mu$ and some basic properties of PS measures. Section 3 contains the argument that half-spaces are $\mu$-perimeter minimizers. The proof that the distributions of PS measures in $\mathscr{W}(\mathbb{R}^n)$ admit product structures is contained in Section 4. Section 5 finishes off the proof of Theorem \ref{t:main theorem 2}.  The Appendices contain the reflection argument necessary to show that $f$ is radial and an example of a ``poorly behaved" PS measure on $\mathbb{R}$.

This work was inspired by recent interest in symmetrization within Geometric Measure Theory (see, for example, \cite{Chlebk2005ThePI},\cite{Barchiesi2013}, \cite{CianchiFuscoMaggiPratelli11},\cite{CagnettiColomboDePhilippis17}). It is hoped that this work adds to that interest.

\section{Definitions and Preliminaries}

We begin with some basic notation. For any sets $E, F \subset \mathbb{R}^n$ we will let $\chi_{E} \in L^{\infty}(\mathbb{R}^n)$ denote the characteristic function of $E$. We shall use the notation $E \setminus F:= \{x \in E: x\not \in F \}$ and $E \Delta F := (E \setminus F) \cup (E \setminus F)$. For a measure $\mu$ with distribution $f$  and an set $E \subset \mathbb{R}^n$ satisfying $\dim_{\mathcal{H}}(E) = m$, we let $\mu \res E$ be the measure defined by $(\mu \res E)(A) = \int_{E \cap A} f d\mathcal{H}^m$.  For a vector $\vec{v} \in \mathbb{R}^n$, we let $\vec{v}^{\perp}$ denote the space $\{\vec{w} \in \mathbb{R}^n: \vec{v} \cdot \vec{v} = 0 \}$.


\subsection{Sets of finite $\mu$-perimeter and weighted BV functions}\label{Sets of Finite mu-perimeter and weighted BV functions}

In this subsection, we recount the basic theory of weighted $BV$ functions for non-negative weights in $W^{1,1}(\mathbb{R}^n)$.  Such weights may be far from continuous, but the main result we need is the weak compactness in Lemma \ref{l:weak compactness}. While there are many excellent books and papers on BV theory, the authors were unable to find references for weighted BV functions which included non-negative $W^{1,1}$ weights.  Therefore, we include the full proofs of the basic theory in the interest of completeness.

\begin{definition}[Weighted $BV$ functions]\label{Weighted_BV}
Let $\mu \in \mathscr{W}(\mathbb{R}^n)$ with a distribution function $f$. We shall say a function $g: \mathbb{R}^n \rightarrow \mathbb{R}$ has {\bf bounded $\mu$-variation} in an open set $U \subset \mathbb{R}^n$ if and only if
\begin{align*}
    \sup \left\{\int_U g\Big(\text{div}(\phi)f +\phi \cdot \nabla f\Big)dx: \phi\in C^1_c(U; \mathbb{R}^n), |\phi|_{\infty} \le 1\right\}<\infty.\end{align*}
We shall denote the collection of all functions with bounded $\mu$-variation in $U$ by $BV_{\mu}(U)$. If $g \in BV_{\mu}(U)$ then we will use the notation
\begin{align*}
\norm{g}_{BV_\mu(U)} := \sup \left\{\int_{U}g\Big( f \text{div}(\phi) + \phi \cdot \nabla f\Big) dx: \phi \in C^1_c(U; \mathbb{R}^n), |\phi|_{\infty} \le 1\right\}
\end{align*}

For a Borel set $E \subset \mathbb{R}^n$, we shall say that $E$ is a {\bf set of finite $\mu$-perimeter} in an open set $U \subset \mathbb{R}^n$ if and only if $\chi_{E} \in BV_{\mu}(U)$. If $\chi_{E} \in BV_{\mu}(U)$, we shall use the notation
    \begin{align}\label{e:perimeter BV def}
       \operatorname{Per}_{\mu}(E; U):= \norm{\chi_{E}}_{BV_{\mu}(U)}.
    \end{align}
\end{definition}

\begin{lemma}[Riesz Representation Theorem]\label{RRT}
    Let $\mu \in \mathscr{W}(\mathbb{R}^n)$ with distribution function $f$.  For all open sets $U \subset \mathbb{R}^n$ and all $g \in BV_{\mu}(U)$ there exists a $\mu$-measurable function $\sigma: U \rightarrow \mathbb{R}^n$ and a Radon measure $\norm{Dg}$ such that 
    \begin{enumerate}
        \item $|\sigma(x)| = 1$ for $\norm{Dg}$-a.e. $x \in B$.
        \item For all $\phi \in C^1_c(B; \mathbb{R}^n)$ 
        \begin{align*}
            \int_{U}g\Big(f \operatorname{div}(\phi) + \phi \cdot \nabla f\Big) dx = - \int_U \phi \cdot \sigma d\norm{Dg}.
        \end{align*}
    \end{enumerate}
    Note that $\norm{Dg}(U) = \norm{g}_{BV_{\mu}(U)}$.
\end{lemma}

The proof follows the standard proof for $f \equiv 1$ in \cite{evansgariepy}, Section 5.1, Theorem 1.

\begin{lemma}[Lower Semicontinuity]\label{l:lsc}
Let $\mu \in \mathscr{W}(\mathbb{R}^n)$ with distribution function $f$, and let $U \subset \mathbb{R}^n$ be open.  Let $g_k \in BV_{\mu}(U)$ be a sequence that satisfies the following two conditions.
    \begin{enumerate}
        \item $\sup_k \norm{g_k}_{\infty}< \infty$.
        \item There exists a function $g \in L^1(\mu, U)$ such that \begin{align*}
        g_k \rightarrow g \quad \text{in  } L^1_{\text{loc}}(\mu, U).
    \end{align*}
    \end{enumerate}
    Then $\norm{Dg}(U) \le \liminf_{k \rightarrow \infty}\norm{Dg_k}(U)$.
\end{lemma}

\begin{proof}
First, we note that if $\sup_k \norm{g_k}_{\infty}< \infty$ then $\norm{g}_{\infty} \le \sup_k \norm{g_k}_{\infty}$. Now, let $0<R<\infty$ be fixed.  Note that since $f \ge 0$ we may write $f = \chi_{\text{spt}(f)}e^h$ for some function $h: \mathbb{R}^n \rightarrow \mathbb{R}$. Therefore, $\nabla f = (\nabla h) f$ and $\nabla h\in L^1_{loc}(\mu, \mathbb{R}^n)$.  Additionally, observe that for any $\phi \in C^1_c(U; \mathbb{R}^n)$ such that $\norm{\phi}_{\infty} \le 1$, $\text{div}(\phi)$ is bounded. Therefore,
$$\int_{B_R(0) \cap U} (g-g_k)\text{div}(\phi)fdx \le \norm{\text{div}(\phi)}_{\infty}\norm{g-g_k}_{L^1(\mu, B_R(0) \cap U)} \rightarrow 0$$
and
\begin{align*}
    \int_{B_R(0)\cap U} (g-g_k)(\phi \cdot \nabla f)dx & = \int_{B_R(0)\cap U} (g-g_k)(\phi \cdot \nabla h)fdx\\
    &
\le \norm{g-g_k}_{\infty}\int_{B_R(0) \cap U \cap \{|\nabla h|>K\}}|\nabla{h}|fdx + K \int_{B_R(0)\cap U}(g-g_k)fdx.
\end{align*}
Taking $K$ sufficiently large such that $\norm{\nabla h}_{L^1(\mu, B_R(0) \cap \{|\nabla h|>K\})} \le \varepsilon$, we obtain
\begin{align*}
    \lim_{k \rightarrow \infty} \int_{B_R(0) \cap U} (g-g_k)(\nabla h)fdx \le 2\sup_k \norm{g_k}_{\infty} \varepsilon.
\end{align*}
Letting $\varepsilon \rightarrow 0$, we see that 
\begin{align*}
    \int_{B_R(0) \cap U}g(f\text{div}(\phi) + \phi \cdot \nabla f)dx & = \lim_{k \rightarrow \infty} \int_{B_R(0) \cap U}g_k(f\text{div}(\phi) + \phi \cdot \nabla f )dx\\
    & = -\lim_{k \rightarrow \infty} \int_{B_R(0) \cap U}\phi \cdot \sigma_k d\norm{Dg_k} \\
    & \le \liminf_{k \rightarrow \infty} \norm{Dg_k}(B_{R}(0) \cap U),
\end{align*}
where we have applied Lemma \ref{RRT} on $g_k$. Taking the supremum in $\phi$ and letting $R \rightarrow \infty$, we obtain the claim.
\end{proof}

\begin{lemma}[Weak approximation by smooth functions has bounded weighted variation]\label{l:weak approx by smooth} Let $\mu \in \mathscr{W}(\mathbb{R}^n)$ with distribution function $f$.  If $U \subset \mathbb{R}^n$ is open and $g \in BV_{\mu}(U) \cap L^\infty(U)$, then there is a sequence of smooth functions $g_\varepsilon \in BV_{\mu}(U)$ such that 
    \begin{enumerate}
        \item $g_\varepsilon \rightarrow g$ in $L^1_{loc}(\mu, U)$ and $\sup_{\varepsilon>0}\norm{g_\varepsilon}_{\infty} \le \norm{g}_{\infty}$.
        \item $\lim_{\varepsilon \rightarrow 0}\norm{Dg_\varepsilon}(U) \le \norm{Dg}(U) + \norm{g}_{\infty}6C(n)\norm{\nabla f}_{L^1(U)}$.
    \end{enumerate}
\end{lemma}

\begin{proof}
    We follow Evans and Gariepy \cite{evansgariepy}, Section 5.2, Theorem 2.  Fix $\varepsilon>0$, and let $m \in \mathbb{N}$.  For $k = 1, 2, ...$ we define 
    \begin{align*}
        U_k:= \left\{x \in U: \dist(x, \partial U) \ge \frac{1}{m+k} \right\} \cap B_{m+k}(0).
    \end{align*}
Now, choose $m$ sufficiently large such that $\norm{Dg}(U \setminus U_1) \le \varepsilon$.  Letting $U_0 = \emptyset$, we inductively define 
\begin{align*}
    V_k = U_{k+1} \setminus U_{k-1}
\end{align*}
for $k \in \mathbb{N}$. Let $\xi_k$ be a partition of unity subordinate to $\{V_k\}_k$. Note that we may choose $|D\xi_k| \le C(m+k)$.  

Now, let $\eta$ be a standard smooth, radial mollifier with $\text{supp}(\eta) \subset B_1(0)$ and $|\eta|\le 1$.  Let $\eta_\varepsilon(x) = \epsilon^{-n}\eta(\varepsilon x)$ and choose $\varepsilon_k$ such that 
\begin{enumerate}
    \item $\text{supp}(\eta_{\varepsilon_k} \star \xi_k) \subset V_k$.
    \item For all $k \in \mathbb{N}$ 
    \begin{align}\label{e: POU 2}
    \int_U |\eta_{\varepsilon_k} \star (g\xi_k) - g\xi_k|dx \le \frac{\varepsilon}{2^k}
\end{align}
\item For all $k \in \mathbb{N}$ 
    \begin{align}\label{e:POU 3}
    \int_U |\eta_{\varepsilon_k} \star (fgD\xi_k) - fgD\xi_k|dx \le \frac{\varepsilon}{2^k}.
\end{align} 
\end{enumerate}
Now, we define
\begin{align}
    g_\varepsilon := \sum_{k=1}^{\infty}\eta_{\varepsilon_k}\star (g \xi_k).
\end{align}

Note that $g_{\varepsilon} \in C^\infty(U)$ and therefore $g_{\varepsilon} \in BV_{\mu}$ with $\norm{Dg_{\varepsilon}}(U) \le \norm{Dg_{\varepsilon}}_{L^1(\mu, U)}$. Moreover, by standard mollifier estimates, $\norm{g_{\varepsilon}}_{\infty} \le \norm{g}_{\infty}$. In order to see that $g_\varepsilon \rightarrow g$ in $L^1(\mu, U)$, for each $\delta>0$ we let $K(\delta)$ be such that $\int_{\{f\ge K\}}fdx \le \delta$.  Then, we may calculate using \eqref{e: POU 2} and the fact that $\sum_k \chi_{V_k} \le 3$
\begin{align*}
    \norm{g-g_{\varepsilon}}_{L^1(\mu, U)} & \le
    \int_{U}\sum_{k}|\eta_{\varepsilon_k}\star(g\xi_k) - g\xi_k|fdx\\
    & \le \int_{U \cap \{f < K(\delta) \}}\sum_{k}|\eta_{\varepsilon_k}\star(g\xi_k) - g\xi_k|fdx\\
    & \qquad + \int_{U \cap \{f \ge K(\delta) \}}\sum_{k}|\eta_{\varepsilon_k}\star(g\xi_k) - g\xi_k|fdx\\
    & \le 6\norm{g}_{\infty}\delta + K\sum_{k=1}^{\infty} \int_{V_k}|\eta_{\varepsilon_k}\star(g\xi_k) - g\xi_k|dx\\
    & \le 6\norm{g}_{\infty}\delta + K\varepsilon.
\end{align*}
Therefore, letting $\varepsilon \rightarrow 0$ and then $\delta \rightarrow 0$, the first claim of the lemma is proven.

To prove the second claim, assume that $g \ge 0$ and consider 
\begin{align}\label{e: variation of smoothed g} \nonumber
    \int_{U} g_{\varepsilon}(\text{div}(\phi)f + \phi \cdot \nabla f)dx & = \sum_{k}\int_U \eta_{\varepsilon_k}\star (g\xi_k)[\text{div}(\phi)f + \phi \cdot \nabla f]dx\\
    & = \sum_{k}\int_U g\xi_k[\eta_{\varepsilon_k}\star (\text{div}(\phi)f + \phi \cdot \nabla f)]dx.
\end{align}
Now, we focus upon the convolution.  
\begin{align}\label{e:convolution} \nonumber
& \eta_{\varepsilon_k}\star (\text{div}(\phi)f + \phi \cdot \nabla f)(x)\\ \nonumber
& \qquad = \int \eta_{\varepsilon_k}(y)(\text{div}(\phi)(x-y)f(x-y) + \phi(x-y) \cdot \nabla f(x-y))dy\\ 
& \qquad = (\eta_{\varepsilon_k}\star \text{div}(\phi))(x)f(x) + (\eta_{\varepsilon_k}\star \phi)(x) \cdot\nabla f(x)\\ \nonumber
& \qquad \qquad  + \int \eta_{\varepsilon_k}(y)\text{div}(\phi)(x-y)[f(x-y) -f(x)]dy\\ \nonumber
& \qquad \qquad + \int\eta_{\varepsilon_k}(y)\phi(x-y) \cdot [\nabla f(x-y)-\nabla f(x)]dy.
\end{align}
By integration by parts and estimates on the mollifier $\eta$, we may estimate the middle term in \eqref{e:convolution} as follows.
\begin{align*}
&\int \eta_{\varepsilon_k}(y)\text{div}(\phi)(x-y)[f(x-y) -f(x)]\\
& = \sum_{i=1}^n\int (\partial_{x_i}\eta_{\varepsilon_k}(y)\phi(x-y)(f(x-y)-f(x))dy - \sum_{i=1}^n\int \eta_{\varepsilon_k}(y)\phi(x-y)\partial_{x_i}f(x-y))\\
& \le \int |\nabla \eta_{\varepsilon_k}(y)||f(x-y) -f(x)|dy + \int \eta_{\varepsilon_k}(y)|\nabla f(x-y)|dy\\
& \le c(\eta)\varepsilon_k^{-n-1}\int_{B_{\varepsilon_{k}}(0)} |f(x-y) -f(x)|dy + \varepsilon_k^{-n}\int_{B_{\varepsilon_{k}}(0)} |\nabla f(x-y)|dy\\
& \le c(\eta)\varepsilon_k^{-n}\int_{B_{\varepsilon_{k}}(x)} |\nabla f(y)|dy + \varepsilon_k^{-n}\int_{B_{\varepsilon_{k}}(x)} |\nabla f(y)|dy.
\end{align*}
Estimating the last term in \eqref{e:convolution} by 
\begin{align*}
    \int \eta_{\varepsilon_k}(y)\phi(x-y) \cdot [\nabla f(x-y)-\nabla f(x)]dy & \le \varepsilon_k^{-n}\int_{B_{\varepsilon_k}(x)} |\nabla f(y)|dy + |\nabla f(x)|,
\end{align*}
we plug these estimates into \eqref{e: variation of smoothed g} to obtain the following. Recall that we are assuming $g \ge 0$ for the moment.
\begin{align*}
    & \int_{U} g_{\varepsilon}(\text{div}(\phi)f + \phi \cdot \nabla f)dx \le \sum_{k}\int_U g\xi_k[(\eta_{\varepsilon_k}\star (\text{div}(\phi))f + (\eta_{\varepsilon_k}\star \phi) \cdot \nabla f)]dx\\
    & \qquad + (c(\eta)+2) \sum_{k}\int_U g\xi_k\Big[\varepsilon_k^{-n}\int_{B_{\varepsilon_k}(x)} |\nabla f(y)|dy + |\nabla f(x)|\Big]dx\\
    & \le \sum_{k}\int_U g[(\text{div}(\xi_k (\eta_{\varepsilon_k}\star\phi))f + \xi_k(\eta_{\varepsilon_k}\star \phi) \cdot \nabla f)]dx\\
    & \qquad - \sum_{k}\int_U g D\xi_k \cdot (\eta_{\varepsilon_k} \star \phi)fdx\\
    & \qquad + (c(\eta)+2)\sum_{k}\int_U g\xi_k\Big[\varepsilon_k^{-n}\int_{B_{\varepsilon_k}(x)} |\nabla f(y)|dy + |\nabla f(x)|\Big]dx
\end{align*}
Now, we split the terms.  Because $\xi_k \eta_{\varepsilon_k} \star \phi \in C^{1}_c(U)$ and $|\phi|\le 1$ and $\sum_{k}\chi_{V_k}(x) \le 3$ we have
\begin{align*}
& \sum_{k}\int_U g[(\text{div}(\xi_k (\eta_{\varepsilon_k}\star\phi))f + \xi_k(\eta_{\varepsilon_k}\star \phi) \cdot \nabla f)]dx\\
    & \le \norm{Dg}(U_1) + 3\norm{Dg}(U-U_1) \le \norm{Dg}(U_1) + 3\varepsilon.
\end{align*}
Similarly, because $\sum_k D\xi_k(x) \equiv 0$ we may use \eqref{e:POU 3} to obtain
\begin{align*}
    & |\sum_{k}\int_U g D\xi_k \cdot (\eta_{\varepsilon_k} \star \phi)fdx| = |\sum_{k}\int_U \eta_{\varepsilon_k} \star (gf D\xi_k) \cdot \phi dx - \sum_{k}\int_U g fD\xi_k \cdot \phi dx|\\
    & \le  \int_U \sum_{k} |\eta_{\varepsilon_k} \star (gf D\xi_k) - gfD\xi_k| dx \le \varepsilon.
\end{align*}
Finally, using our assumption that $\text{supp}(\eta_{\varepsilon_k} \star \xi_k) \subset V_k$, $\sum_{k}\chi_{V_k}(x) \le 3$, and Fubini's theorem we estimate 
\begin{align*}
    & (c(\eta)+2)\sum_{k}\int_U g\xi_k\Big[\varepsilon_{k}^{-n}\int_{B_{\varepsilon_{k}}(x)}|\nabla f(y)|dy + |\nabla f(x)|\Big]dx\\
    & \le 2C(n)\norm{g}_{\infty} \sum_{k}\int_{V_k}|\nabla f|dx \le 6 C(n)\norm{g}_{\infty} \int_{U}|\nabla f|dx.
\end{align*}

Putting it all together, we obtain
\begin{align*}
    \int_{U} g_{\varepsilon}(\text{div}(\phi)f + \phi \cdot \nabla f)dx \le \norm{Dg}(U) + 4\varepsilon+ 6C(n)\norm{g}_{\infty}\int_{U}|\nabla f|dx.
\end{align*}

Letting $\varepsilon \rightarrow 0$ gives the desired result for $g \ge 0$.  Writing general $g$ as $g = g^+ - g^-$ and applying the argument to $g^-$ and $g^+$ gives the claim of the lemma.
\end{proof}


\begin{lemma}[Weak Compactness for $BV_{\mu}$]\label{l:weak compactness}
    Let $\mu \in \mathscr{W}(\mathbb{R}^n)$ with distribution function $f$. Let $U \subset \mathbb{R}^n$ be open. For any sequence of functions $h_j \in BV_{\mu}(U) \cap L^{\infty}(U)$ such that 
    \begin{align*}
        \sup_j \norm{Dh}(U) <\infty \qquad \sup_j \norm{h}_{\infty}<\infty
    \end{align*}
there is a subsequence $\{h_{j'}\}_{j'}$ and a function $h_{\infty} \in BV_{\mu}(U) \cap L^{\infty}(U)$ such that   
\begin{align*}
    h_{j'} \rightarrow h_{\infty} \text{  in  } L^1_{loc}(U),\\
    \norm{Dh_{\infty}}(U) \le \liminf_j \norm{Dh_j}(U).
\end{align*} 

In particular, if $h_j = \chi_{E_j}$  then there exists a subsequence $\{E_{j'}\}_{j'}$ and a set $E_{\infty}$ such that 
    \begin{align*}
\operatorname{Per}_{\mu}(E_{\infty}, U)\} \le \liminf_j \{\operatorname{Per}_{\mu}(E_j, U)\}.
    \end{align*}
\end{lemma}

\begin{proof}
    Let $U \subset \mathbb{R}^n$ be given.  For $i \in \mathbb{N}$ we consider the neighborhoods
    \begin{align*}
        U_i = U \cap B_i(0).
    \end{align*}
Let $\{h_{j'}\}$ be a subsequence such that $\lim_{j'}\norm{Dh_{j'}}(U) = \liminf_j \norm{Dh_j}(U)$.  Applying Lemma \ref{l:weak approx by smooth} to $\{h_{j'}\}_{j'}$ in $U_i$, we obtain smooth functions $g_{j'} \in BV_{\mu}(U_i)$ such that $\norm{g_{j'}}_{\infty} \le \norm{h_{j'}}_{\infty}$ and 
\begin{align}\label{e:smooth approx and strong convergence}
    \begin{cases}
\int_{U_i}|h_{j'} - g_{j'}|fdx \le 1/j'\\
\norm{Dg_j'}(U_i) \le \norm{Dh_{j'}}(U_i) + 3C(n)\norm{h_{j'}}_{\infty}\norm{\nabla f}_{L^1(U_i)}.
    \end{cases}
\end{align}
Since we are assuming $\sup_{j'}\norm{Dh_{j'}}(U_i)<\infty$, $\sup_{j'} \norm{h_{j'}}_{\infty}<\infty$, and $f \in W^{1,1}_{loc}(\mathbb{R}^n)$ we have $\sup_{j'} \norm{Dg_{j'}}(U_i)< \infty$.  That is, there exists some $0 < M <\infty$ such that \begin{align*}
    \sup_{j' \in \mathbb{N}} \sup_{\substack{\phi \in C^\infty_c(U_i, \mathbb{R}^n)\\|\phi|\le 1}} \int \nabla g_{j'} \cdot \phi fdx < M <\infty.
\end{align*}
For each $j'$ we may choosing a sequence of test functions $\phi \in C^\infty_c(U; \mathbb{R}^n)$ which approximate $\nabla g_{j'}/ |\nabla g_{j'}|$ in $U_i$ to obtain $\norm{\nabla g_{j'}}_{L^1(\mu, U_i)}< M$.
%Now, fix $i \in \mathbb{N}$ and for each integer $j' \ge i$ let $\tilde{U}_{j'} \subset U_i$ be open sets such that the following properties hold.
%\begin{enumerate}
%    \item There is a strictly increasing sequence $m_{j'} \in \mathbb{N}$ such that $\partial \tilde{U}_{j'} \subset \{x \in U_i: \dist(x, \partial U_i) > 1/m_{j'} \} \setminus \{x \in U_i: \dist(x, \partial U_i) > 1/(m_{j'}-1) \}$ and $\tilde{U}_{j'}$ has $C^{0,1}$ boundary. Note that because $U_i$ is bounded, $\tilde{U}_{j'}$ has at most finitely many components and is therefore uniformly $C^{0,1}$.
%    \item The $m_{j'}$ are chosen so that \begin{align*}
%    \int_{U_i \setminus \tilde{U}_{j'}} |\nabla g_{j'}|f dx \le 1.
%\end{align*}
%\end{enumerate}
%Note that for these choices $U_i = \cup_{j'} \tilde{U}_{j'}$. By approximating $g_{j'}/|g_{j'}|$ in $\tilde{U}_{j'}$ by smooth functions $\tilde{\phi}_{j',k} \in C^{\infty}_c(U_i, \mathbb{R}^n)$ with $|\tilde{\phi}_{j',k}|\le 1$ we observe that for any $\tilde{U}_{j'}$ we may estimate
%\begin{align*}\int_{U_i} |\nabla g_{j'}| f dx \le \lim_{k \rightarrow \infty} \int_{U_i} \nabla g_{j'} \cdot \tilde{\phi}_{j',k} fdx + 2\int_{U_i \setminus \tilde{U}_{j'}} |\nabla g_{j'}| f dx <  M +2 <\infty. \end{align*}

By Leibniz's rule $\nabla (g_{j'} f) = (\nabla g_{j'}) f + g_{j'} (\nabla f)$, and hence the assumptions that $f \in W^{1,1}_{loc}(\mathbb{R}^n)$ and $\sup_{j'}|g_{j'}|_{\infty} <\infty$ imply that the sequence $\{\nabla (g_{j'} f)\}_{j'}$ is uniformly bounded in $W^{1,1}_{loc}(U_i)$. Therefore, by the \textit{unweighted} Rellich-Kondrashov compactness theorem, there exists a function $h_{i, \infty} \in L^1(U_i)$ and a subsequence (also indexed $j'$) such that
\begin{align*}
    \nabla (g_{j'}f) \rightharpoonup \nabla h_{i,\infty} \text{ in } L^1_{\loc}(U_i, \mathbb{R}^n)\\
    g_{j'}f \rightarrow  h_{i,\infty} \text{ in } L^1_{\loc}(U_i).
\end{align*}

Now, we claim that we can write $h_{i, \infty} = g_{i,\infty}f$.  To see this, we note that if $E \subset U_i$ is a set of positive $\mathcal{H}^n$-measure and $f=0$ on $E$, then $\int_E h_{i,\infty} dx = 0$ by the strong convergence.  Therefore, we may define 
\begin{align*}
    g_{i, \infty}:= \begin{cases}
        h_{i, \infty}/f & \text{ where } f>0\\
        0 & \text{ where } f=0.
    \end{cases}
\end{align*}

Therefore, $g_{j'}f \rightarrow g_{i, \infty}f$ in $L^1(U_i)$ which is the definition of $g_{j'} \rightarrow g_{i,\infty}$ in $L^1(\mu, U_i)$.  Recalling \eqref{e:smooth approx and strong convergence} we also have $h_{j'} \rightarrow g_{i, \infty}$ in $L^1(\mu, U_i)$.  Thus, we may invoke Lemma \ref{l:lsc} to obtain $\norm{Dg_{i, \infty}}(U_i) \le \liminf_j \norm{Dh_j}(U_i)$ by our choice of $j'$.

Now, take a diagonalizing sequence subordinate to the exhaustion $\{U_i\}_i$ to obtain a subsequence (again indexed by $j'$) and a function $h_{\infty} \in BV_{\mu}(U) \cap L^{\infty}(U)$ such that 
the claim of the lemma holds by Lemma \ref{l:lsc}.

Now, it remains to show that if $h_{j'}= \chi_{E_j'}$ then the resulting $g_{i, \infty}$ guaranteed by the unweighted Rellich-Kondrashov compactness theorem is of the form $g_{i, \infty} = \chi_{E_{i, \infty}}$ for some $E_{i, \infty} \in BV_{\mu}(U_i)$ with $\operatorname{Per}_{\mu}(E_{i,\infty}, U_i) \le \liminf_{j'} \{\operatorname{Per}_{\mu}(E_{j}, U_i)\}$.  First, note that under these conditions the smooth approximation functions $g_{j'}$ satisfy $|g_{j'}| \le 1$ everywhere.  Hence, $h_{i, \infty}(x) \le f(x)$ for $\mathcal{H}^n$-a.e. $x \in U_i$ and $g_{i, \infty} \le 1$ $\mathcal{H}^n$-a.e.. Now, assume that there is a set $E \subset U_i$ such that $\mu(E)> 0$ and $g_{i, \infty}\res_{E_i} \in [\varepsilon, 1-\varepsilon]$.  Then, since $g_{j'} f \rightarrow g_{i, \infty}f$ in $L^1_{loc}(U_i)$, by definition $g_{j'} \rightarrow g_{i, \infty}$ in $L^1_{loc}(\mu, U_i)$. As above, combining this with \eqref{e:smooth approx and strong convergence} we obtain $\chi_{E_{j'}} \rightarrow g_{i, \infty}$ in $L^1_{loc}(\mu, U_i)$. Hence, we obtain the contradiction 
\begin{align*}
\liminf_{j' \rightarrow \infty} \int_E |\chi_{E_{j'}} - g_{i, \infty}|f dx >0.
\end{align*}
Since $0<\varepsilon$ was arbitrary, we obtain that up to sets of $\mu$-measure zero $g_{i, \infty}$ only takes the values $\{0,1\}$. Therefore, we may write $g_{i, \infty} = \chi_{E_{i, \infty}}$. To see that $E_{i, \infty}$ has bounded $\mu$-perimeter, we apply Lemma \ref{l:lsc}.  This gives the claim.
\end{proof}

\subsection{Generalized Ehrhard symmetrization}\label{Generalized Ehrhard symmetrization}

In this section, we generalize the notion of Ehrhard symmetrization from $\gamma_n$ to a large class of finite measures.

\begin{definition}[Generalized Ehrhard Symmetrization]
Let $\mu \in \mathcal{M}(\mathbb{R})$ with distribution function $f \in L^1(\mathbb{R})$. For a vector $\vec{v} \in \mathbb{S}^{0} = \{-\vec{e_1}, \vec{e_1}\}$ we define \textit{generalized $\vec{v}$-Ehrhard symmetrization with respect to $\mu$} to be the set-valued map $S_{\vec{v}}$ described below.  For any Borel-measurable $E \subset \mathbb{R}$ we define
\begin{align*}
S_{\vec{v}}(E):= \{x: \vec{v} \cdot x \ge c \}
\end{align*}
where $c \in \mathbb{R}$ is chosen to be the largest constant such that $\mu(E) = \mu(E^s_{\vec{v}})$. Sometimes we shall use the notation $E^s_{\vec{v}} = S_{\vec{v}}(E)$.

For $\mu \in \mathcal{M}(\mathbb{R}^n)$ with distribution function $f \in L^1(\mathbb{R}^n)$ and any vector vector $\vec{v} \in \mathbb{S}^{n-1}$, we define \textit{generalized $\vec{v}$-Ehrhard symmetrization with respect to $\mu$} to be the set-valued function $S_{\vec{v}}$ described below.  For any Borel-measurable $E \subset \mathbb{R}^n$ and $x \in \vec{v}^{\perp}$ we define $E_x = E \cap \pi_{\vec{v}^{\perp}}^{-1}(x)$ where $\pi_{\vec{v}^{\perp}}$ is the orthogonal projection onto $\vec{v}^{\perp}$.  We define
\begin{align*}
    S_{\vec{v}}(E) := \bigcup_{x \in \vec{v}^{\perp}}(E_x)^s_{\vec{v}},
\end{align*}
where we identify $\pi_{\vec{v}^{\perp}}^{-1}(x)$ with $\mathbb{R}$ and use $\mu_x := \mu\res \pi_{\vec{v}^{\perp}}^{-1}(x) \in \mathcal{M}(\mathbb{R})$ to define $(E_x)^s_{\vec{v}}$. For convenience, we shall often use the notation $E^s_{\vec{v}}:= S_{\vec{v}}(E)$.  

Because the underlying measure will always be clear from context we omitted it from the notation. For a sequence $\vec{v}_1, ..., \vec{v}_N \in \mathbb{S}^{n-1}$ we shall use the notation
\begin{align}
    E^s_{\vec{v}_1, ..., \vec{v}_N} := S_{\vec{v}_N} \circ ... \circ S_{\vec{v}_1}(E). 
\end{align}
Note that in $n \ge 2$, $E_{\vec{v}}^s$ is only defined $\mathcal{H}^{n}$-almost everywhere and hence only $\mu$-almost everywhere.
\end{definition}

Now that we have rigorous definitions of $\text{Per}_{\mu}$ and generalized Ehrhard symmetrization with respect to $\mu$ for all $\mu \in \mathscr{W}(\mathbb{R}^n)$, we can give a definition of PS measures with respect to these choices.  

\begin{definition}[Perimeter symmetrization measures]
Let $n \in \mathbb{N}$ and $\mu \in \mathscr{W}(\mathbb{R}^n)$.  We shall call $\mu$ a \textit{perimeter symmetrization measure} (or a PS measure) with respect to generalized Ehrhard symmetrization and $\text{Per}_{\mu}$ if for every $\vec{v} \in \mathbb{S}^{n-1}$ and every set of finite $\mu$-perimeter $E$,
\begin{align}
    \operatorname{Per}_{\mu}(E^s_{\vec{v}}) \le \operatorname{Per}_{\mu}(E).
\end{align}
\end{definition}

\begin{definition}(Half spaces)
    For a vector $\vec{v} \in \mathbb{S}^{n-1}$ and $r \in \mathbb{R}$ we define
    \begin{align*}
        H(\vec{v}, r) := \{x \in \mathbb{R}^n: x \cdot \vec{v} \ge r\}.
    \end{align*}
For a non-empty Borel set $E \subset \mathbb{R}^n$ we define 
    \begin{align}\label{e:half space of equal measure}
        H_m(E, \vec{v}):= H(\vec{v}, r(E, \vec{v})) 
    \end{align}
where $r(E, \vec{v})$ is chosen such that $\mu(H(\vec{v}, r)) = \mu(E)$.  Note that $H_{m}(E, \vec{v})$ only depends upon $\vec{v}, \mu(E)$ and that in particular $H_m(F, \vec{v}) = H_m(E, \vec{v})$ for all sets $F \subset \mathbb{R}^n$ such that $\mu(F) = \mu(E).$ 
\end{definition}

\begin{definition}\label{d: symmetric in measure}
Let $\nu \in \mathcal{M}(\mathbb{R})$ be defined by $d\nu = f d\mathcal{H}^1$ for $f\in L^1(\mathbb{R}) \cap C(\mathbb{R})$. We say that $\nu$ or $f$ is \textit{symmetric} about a point $x$ if for all $y_1<x<y_2$ such that $|y_1-x| = |x-y_2|$, $f(y_1) = f(y_2)$. Note that this forces $\nu([y_1, x]) = \nu([x, y_2])$. 

Let $P$ be a hyperplane in $\mathbb{R}^n$ and $T:\mathbb{R}^n \rightarrow \mathbb{R}^n$ be the reflection map across $P$. We shall say a function $f:\mathbb{R}^n \rightarrow \mathbb{R}$ is symmetric across the hyperplane $P$ if $f(x) = f(T(x))$ for all $x \in \mathbb{R}^{n}$.
\end{definition}

The connection between generalized Ehrhard symmetrization and symmetric measures is well-known.  For example, in Bobkov's solution to the characterization problem in $n=1$ for log-concave measures and generalized Ehrhard symmetrization he proves in this class, $\nu$ is a PS measure if and only if $\nu$ is symmetric   (\cite{Bobkov96} Proposition 2.2).  

Since we are not assuming that the distribution function is log-concave, we give the following, related statement.


\begin{lemma}\label{l:Ehrhard implies symmetric}
    Let $\nu \in \mathcal{M}(\mathbb{R})$ be a Radon measure with distribution $f \in C(\mathbb{R})$ satisfying $f>0$.  If $\nu$ is a PS measure with respect to generalized Ehrhard symmetrization then $\nu$ is symmetric. 
\end{lemma}

\begin{remark}
    We do not specify the notion of perimeter, here, as we shall only need to calculate the perimeter of sets of the form $(-\infty, y]$. The statement holds for any notion of weighted perimeter such that $\text{Per}_{\nu}((-\infty, y]) = f(y)$. 
    \end{remark}

\begin{proof}
    For any $y_1,y_2$ such that $\nu((-\infty, y_1]) = \nu([y_2, \infty))$, $(-\infty, y_1] = ([y_2, \infty))^s_{-\vec{e_1}}$ and $((-\infty, y_1])^s_{\vec{e_1}} = [y_2, \infty)$.  Therefore, if $\nu$ is an Ehrhard measure, then $\operatorname{Per}_{\nu}((-\infty, y_1]) = \operatorname{Per}_{\nu}([y_2,\infty))$ or, equivalently, $f(y_1)=f(y_2)$.

    Now, let $F: \mathbb{R} \rightarrow [0, \nu(\mathbb{R})]$ be defined by $x \mapsto \nu((-\infty, x])$.  Note that $F \in C^1(\mathbb{R})$ and $F^{-1}$ is well-defined since $f>0$.  Moreover, $(F^{-1})'(p) = \frac{1}{f(F^{-1}(p))}$ and the above paragraph implies that for any $p \in [0, \nu(\mathbb{R})]$, $f(F^{-1}(p)) = f(F^{-1}(\nu(\mathbb{R}) -p))$. Thus, $(F^{-1})'(p) = -(F^{-1})'(\nu(\mathbb{R})-p)$.  Integrating, we see that there must exist a constant $m$ such that for all $p \in [0, \nu(\mathbb{R})]$ 
    \begin{align*}
        F^{-1}(p) + F^{-1}(\nu(\mathbb{R})-p) = 2m.
    \end{align*}
    Therefore, $m$ is the median and $\nu$ is symmetric.
\end{proof}

\section{Half-planes are local isoperimetric sets}


For the remainder of the paper, when we say that $\mu \in \mathscr{W}(\mathbb{R}^n)$ is a PS measure we shall mean that it is a PS measure with respect to generalized Ehrhard symmetrization and weighted $\mu$-perimeter $\text{Per}_{\mu}$. 

The main result in this Section is the following lemma.

\begin{lemma}\label{l:H are minimal}
    Let $n \ge 2$, and let $\mu \in \mathscr{W}(\mathbb{R}^n)$ be a PS measure. For every $\vec{v} \in \mathbb{S}^{n-1}$ and every Borel set $E \subset \mathbb{R}^n$
    \begin{align*}
    \operatorname{Per}_{\mu}(H_m(E,\vec{v})) \le \operatorname{Per}_{\mu}(E).
    \end{align*}    
\end{lemma}

The main idea of the proof is that for any Borel set $E \subset \mathbb{R}^n$ if $\mu$ is a PS measure then generalized Ehrhard symmetrization allows us to move mass from $E \setminus H_{m}(E, \vec{v})$ to ``fill in" $H_m(E, \vec{v}) \setminus E$ while not increasing the perimeter.  As noted in the Introduction, Ehrhard provides a geometric proof of Lemma \ref{l:H are minimal} for $\mu = \gamma_n$ \cite{Ehrhard83} Proposition 1.5 (See Lifschits's book \cite{lifshits1995gaussian}, Chapter 11 for a detailed proof in English).  However, the core of Ehrhard's proof is to produce a sequence of symmetrizations and show that $C_N \subset E^s_{\vec{v_1}\vec{v_2}...\vec{v_N}}$ for a sequence $\{C_i\}_{i=1}^{\infty}$ of cones which widen to the half-space.  This proof relies essentially upon the measure $\mu$ having a product structure for any orthonormal frame. While this is obviously true for the isotropic Gaussian, we cannot assume this for general $\mu$.

We begin by studying the one-dimensional case. 

\begin{lemma}[One-Dimensional Behavior]\label{l:0}
    Let $\mu \in \mathcal{M}(\mathbb{R})$ and assume that $d\mu = fd\mathcal{H}^1$ for some $f \in L^1(\mathbb{R})$ such that $f\ge 0$. Suppose $E \subset \mathbb{R}$ is a Borel set and the interval $(a, b)$ satisfies 
    \begin{align*}
        \mu(E^c \cap (a, b)) = \alpha>0.
    \end{align*}
    Then 
    \begin{align}\label{e:symm shifts things down}
        \sup \left\{E^s_{-\vec{e_1}} \cap [a,\infty)\right\} < \sup \left\{E \cap [a, \infty)\right\}.
    \end{align}
    Moreover, if $\mu(E \cap [b, \infty)) = \beta>0$ then $\mu \left(E^s_{-\vec{e_1}} \cap [b,\infty)\right) \le \max\{ \beta - \alpha, 0\}$ or, equivalently, $\mu \left(E^s_{-\vec{e_1}} \setminus (-\infty,b]\right) \ge \mu \left(E \setminus (-\infty,b]\right) + \min \{  \beta, \alpha\}$.  In particular,
        \begin{align*}
        \mu \left(E^s_{-\vec{e_1}} \setminus (-\infty,b]\right) < \mu \left(E \setminus (-\infty,b]\right).
    \end{align*}
\end{lemma}
\begin{proof}
Without loss of generality, we may assume that 
$$E^s_{-\vec{e_1}} \cap [b,\infty)\not=\emptyset.$$
Since $E^s_{-\vec{e_1}}$ is an interval, 
$$E^s_{-\vec{e_1}}\cup [b,\infty)=\mathbb{R}.$$
Notice that
$$\left(E^c\cap (a,b)\right)\cap \left(E\cup [b,\infty)\right)=\emptyset,\quad \left(E^c\cap (a,b)\right)\cup \left(E\cup [b,\infty)\right)=E\cup (a,\infty).$$
Then
$$\mu\left(E^c\cap (a,b)\right)+\mu \left(E\cup [b,\infty)\right)=\mu\left(E\cup (a,\infty)\right)\leq 1=\mu\left(E^s_{-\vec{e_1}}\cup [b,\infty)\right)$$
and hence
\begin{align*}
\mu \left(E^s_{-\vec{e_1}} \cap [b,\infty)\right)&=\mu \left(E^s_{-\vec{e_1}}\right)+\mu \left( [b,\infty)\right)-\mu \left(E^s_{-\vec{e_1}} \cup [b,\infty)\right)\\
&=\mu \left(E\right)+\mu \left( [b,\infty)\right)-\mu \left(E^s_{-\vec{e_1}} \cup [b,\infty)\right)\\
&=\mu\left(E\cap [b,\infty)\right)+\mu \left(E\cup [b,\infty)\right)-\mu \left(E^s_{-\vec{e_1}} \cup [b,\infty)\right)\\
&\leq\mu\left(E\cap [b,\infty)\right)-\mu \left(E^c\cap (a,b)\right)=\beta-\alpha.
\end{align*}
\end{proof}

Lemma \ref{l:0} has the following, immediate corollary in higher dimensions.

\begin{lemma}\label{l:1}
Let $\mu \in \mathscr{W}(\mathbb{R}^n)$ with distribution function $f$.  Assume that $\mu$ a PS measure.  Let $E \subset \mathbb{R}^n$ be a Borel set, $\vec{v} \in \mathbb{S}^{n-1}$, and assume that 
\begin{align*}
    \mu(E \Delta H_m(E, \vec{v}))>0.
\end{align*}

Then for every $\vec{\eta} \in \mathbb{S}^1$ such that $\vec{v} \cdot \vec{\eta}>0$
\begin{align}
    \mu(E^s_{\vec{\eta}} \setminus H_{m}(E, \vec{v})) \le \mu(E \setminus H_{m}(E, \vec{v})) 
\end{align}
\end{lemma}

\begin{proof}
    This follows from Fubini's theorem and Lemma \ref{l:0} applied to each of the fibers $a + \text{span}(\vec{\eta})$ for $a \in \vec{\eta}^{\perp}$.
\end{proof}

However, Lemma \ref{l:1} is not strong enough to prove Lemma \ref{l:H are minimal}. Instead, we need the following improvement.

\begin{lemma}\label{l:measure reduction}
    Let $E, \mu, \vec{v}$ be as in Lemma \ref{l:1}.  There is a $\vec{\eta} \in \mathbb{S}^1$ such that 
\begin{align*}
    \vec{v} \cdot \vec{\eta}>0
\end{align*}
and 
\begin{align}
    \mu(E^s_{\vec{\eta}} \setminus H_{m}(E, \vec{v})) <  \mu(E \setminus H_{m}(E, \vec{v})). 
\end{align}
\end{lemma}

\begin{proof}
By the assumption that $\mu(E\Delta H_m(E, \vec{v}))>0$, we may find an $\varepsilon>0$ such that 
\begin{align*}
    \mathcal{H}^{n}(\{f \ge \varepsilon\} \cap \left(E \setminus H_m(E, \vec{v}))\right) & > 0\\
    \mathcal{H}^n(\{f \ge \varepsilon\} \cap \left(H_m(E, \vec{v}) \setminus E\right)) & > 0.
\end{align*}
Therefore, taking $x, y$ such that 
\begin{enumerate}
    \item $x \in \{f \ge \varepsilon\} \cap \left(E \setminus H_m(E, \vec{v})\right)$ and $x$ is a Lebesgue point of both $\{f \ge \varepsilon\}$ and $E \setminus H_m(E, \vec{v})$.
    \item $y \in \{f \ge \varepsilon\} \cap \left(H_m(E, \vec{v}) \setminus E\right)$ and $y$ is a Lebesgue point of both $\{f \ge \varepsilon\}$ and $H_m(E, \vec{v})\setminus E$.
    \item $\vec{v}\cdot (y-x)>0$.
\end{enumerate}
Let $\vec{\eta} = \frac{y-x}{|y-x|}$ and let $\vec{\eta}^\perp_x := x+ \vec{\eta}^\perp$. For $z \in \vec{\eta}^{\perp}_x$ we shall write $\mu_z$ for the restriction measure $f\mathcal{H}^{1}\res \pi_{\vec{\eta}_x^{\perp}}^{-1}(z)$, where $\pi_{\vec{\eta}_x^{\perp}}$ is the orthogonal projection onto $\vec{\eta}^{\perp}_x$.  Note that there exists a radius $r_0>0$ such that 
\begin{align*}
    \frac{\mathcal{H}^{n-1}(\{z \in \vec{\eta}^\perp_x \cap B_{r_0}(x): \mu_z(E \cap B_{r_0}(x))>0\})}{\mathcal{H}^{n-1}(\vec{\eta}^\perp_x \cap B_{r_0}(x))} & > 3/4\\
    \frac{\mathcal{H}^{n-1}(\{z \in \vec{\eta}^\perp_x \cap B_{r_0}(x): \mu_z(E^c \cap B_{r_0}(y))>0\})}{\mathcal{H}^{n-1}(\vec{\eta}^\perp_x \cap B_{r_0}(x))} & > 3/4.
\end{align*}
Therefore, for this $0<r_0$ the collection of $z \in \vec{\eta}^\perp_x \cap B_{r_0}(x)$ such that both $\mu_z(E \cap B_{r_0}(x))>0$ and $\mu_z(E^c \cap B_{r_0}(y))>0$ must have positive $\mathcal{H}^{n-1}$-measure.  Therefore, applying Lemma \ref{l:0} to each of these fibers gives the claim of the lemma.
\end{proof}


\begin{lemma}\label{l:filling all the holes}
Let $E, \mu, \vec{v}$ be as in Lemma \ref{l:1}. Let $\mathcal{S}(E)$ be the collection of all sets $F \subset \mathbb{R}^n$ such that 
\begin{align*}
    F = E^s_{\vec{\eta}_1, ..., \vec{\eta}_N}
\end{align*}
for some finite sequence of vectors $\{\vec{\eta}_i \}_{i=1}^N$ such that $\vec{v} \cdot \eta >0$.  Then
    \begin{align*}
        \inf_{F \in \mathcal{S}(E)} \mu(F \Delta H_m(E, \vec{v})) =0.
    \end{align*}
\end{lemma}

\begin{proof}
We argue by contradiction.  Suppose that $\inf_{F \in \mathcal{S}(E)} \mu(F \Delta H_m(E, \vec{v}))>0.
$ Then, for a minimizing sequence $F_j$ we may invoke Lemma \ref{l:weak compactness} to obtain a set $F_{\infty} \subset \mathbb{R}^n$ such that there exists a subsequence 
\begin{align*}
    F_{j'} \rightarrow F_{\infty} \qquad \text{ in } L^1_{loc}(\mu, \mathbb{R}^n)
\end{align*}
and $\norm{\chi_{F_{\infty}}}(\mathbb{R}^n) \le \liminf_{j} \norm{\chi_{F_{j}}}(\mathbb{R}^n)$. Because we are assuming that $\mu$ is an Ehrhard measure, we have $\norm{\chi_{F_{\infty}}}(\mathbb{R}^n) \le \norm{D\chi_{E}}(\mathbb{R}^n)$.  Moreover, by the strong convergence in $L^1_{loc}(\mu, \mathbb{R}^n)$, it also follows that 
\begin{align*}
    \mu(F_{\infty} \Delta H_m(E, \vec{v}))>0.
\end{align*}
Therefore, we may apply Lemma \ref{l:measure reduction} to $\mu, f, F, \vec{v}$ to obtain a vector $\vec{\eta} \in \mathbb{S}^{n-1}$ and a set of finite $\mu$-perimeter $F_{\infty}$ with
\begin{align*}
    \mu((F_{\infty})^s_{\vec{\eta}} \Delta H_m(E, \vec{v}))< \inf_{F \in \mathcal{S}(E)} \mu(F \Delta H_m(E, \vec{v})).
\end{align*}

Therefore, the proof of the lemma will be accomplished if we can show that for sufficiently large $j'$ we have $\mu((F_{j'})^s_{\vec{\eta}} \Delta H_m(E, \vec{v})) \rightarrow \mu((F_{\infty})^s_{\vec{\eta}} \Delta H_m(E, \vec{v}))$.  However, this is immediate from the strong $L^1_{loc}(\mu, \mathbb{R}^n)$ convergence.  That is, for the fixed $\vec{\eta}$ above $F_{j'} \rightarrow F_{\infty}$ in  $L^1_{loc}(\mu, \mathbb{R}^n)$ implies by Fubini's theorem that the marginal function $m_{F_{j'}}: \vec{\eta}^{\perp} \rightarrow \mathbb{R}$ defined by 
\begin{align*}
    m_{F_{j'}}(a) & = \int_{\pi_{\vec{\eta}}^{-1}(a) \cap F_{j'}} f d\mathcal{H}^1
\end{align*}
satisfies $m_{F_{j'}} \rightarrow m_{F_{\infty}}$ in $L^1_{loc}(\vec{\eta}^{\perp})$.  Since the symmetrizations $(F_{j'})^s_{\vec{\eta}}, (F_{\infty})^s_{\vec{\eta}}$ are uniquely determined by the functions $m_{F_{f'}}, m_{F_{\infty}}$ and 
\begin{align*}
    \mu((F_{j'})^s_{\vec{\eta}} \Delta H_m(E, \vec{v})) & = \int_{\vec{\eta}^\perp} |m_{F_{j'}}(a) - m_{H_m(E, \vec{v})}(a)| d\mathcal{H}^{n-1}(a)\\
    & \le \int_{\vec{\eta}^\perp} |m_{F_{j'}}(a) - m_{F_{\infty}}(a)| + |m_{F_{\infty}}(a) -  m_{H_m(E, \vec{v})}(a)| d\mathcal{H}^{n-1}(a)\\
    & \le \mu((F_{\infty})^s_{\vec{\eta}} \Delta H_m(E, \vec{v})) + \int_{\vec{\eta}^\perp} |m_{F_{j'}}(a) - m_{F_{\infty}}(a)|d\mathcal{H}^{n-1}(a).
\end{align*}
Therefore, as $j' \rightarrow \infty$ we obtain $\lim_{j' \rightarrow \infty} \mu((F_{j'})^s_{\vec{\eta}} \Delta H_m(E, \vec{v})) \le \mu((F_{\infty})^s_{\vec{\eta}} \Delta H_m(E, \vec{v}))$. Hence, for sufficiently large $j'$ there is a $F_{j'}$ such that 
\begin{align*}
    \mu((F_{j'})^s_{\vec{\eta}} \Delta H_m(E, \vec{v}))< \inf_{F \in \mathcal{S}(E)} \mu(F \Delta H_m(E, \vec{v})).
\end{align*}
But, since $(F_{j'})^s_{\vec{\eta}} = (E^s_{\vec{v}_1\vec{v}_2...\vec{v}_N})^s_{\vec{v}} \in \mathcal{S}(E)$ we obtain a contradiction.  Therefore, the lemma holds.
\end{proof}

\subsection{Proof of Lemma \ref{l:H are minimal}}
Let $E, \mu, \vec{v}$ be as in the hypotheses of Lemma \ref{l:H are minimal}. If $\operatorname{Per}_\mu(E) = \infty$ there is nothing to prove.  Therefore, we may assume that $E$ is a set of finite $\mu$-perimeter. By Lemma \ref{l:filling all the holes} we may take a minimizing sequence $F_{j} \in \mathcal{S}(E)$ such that 
\begin{align*}
    \lim_{j \rightarrow \infty} \mu((F_{j'})^s_{\vec{\eta}} \Delta H_m(E, \vec{v}))=0.
\end{align*}
Since $\sup_j \norm{\chi_{F_{j}}}_{\infty} \le 1$ and $\sup_j \operatorname{Per}_{\mu}(F_j, \mathbb{R}^n) \le \operatorname{Per}_{\mu}(E)<\infty$. By Lemma \ref{l:weak compactness} we may extract a subsequence such that $F_{j'} \rightarrow F_{\infty}$ in $L^1_{loc}(\mu, \mathbb{R}^n)$ for some Borel set $F_{\infty}$ with 
\begin{align*}
    \operatorname{Per}_{\mu}(F_{\infty}) \le \operatorname{Per}_\mu(E).
\end{align*}
Moreover, by the strong convergence we have $\mu(F_{\infty} \Delta H_m(E, \vec{v})) = 0$. This implies $\operatorname{Per}_{\mu}(F_{\infty}) = \operatorname{Per}_{\mu}(H_m(E, \vec{v}))$, which concludes the proof. \qed


\vspace{.5cm}
Lemma \ref{l:H are minimal} has the following trivial consequence.

\begin{lemma}\label{l:all half-spaces}
    Let $E, \mu, \vec{v}$ be as in Lemma \ref{l:H are minimal}.  Then for all $\vec{\eta} \in \mathbb{S}^1$,  
    \begin{align*}
        P_{\mu}(H_m(E, \vec{\eta})) = P_{\mu}(H_m(E, \vec{v}))
    \end{align*}
    and the half-spaces $\{H_m(E, \vec{\eta})\}_{\vec{\eta} \in \mathbb{S}^1}$ are minimal for $\mu$-perimeter among all sets $K$ of finite $\mu$-perimeter with $\mu(K) = \mu(E)$.
\end{lemma}

\begin{proof}
    Applying Lemma \ref{l:H are minimal} to $H_m(E, \vec{v})$ and $\vec{\eta}$ in place of $\vec{v}$ shows that 
    \begin{align*}
        \operatorname{Per}_{\mu}(H_m(E, \vec{\eta})) \le \operatorname{Per}_{\mu}(H_m(E, \vec{v})).
    \end{align*}
    Applying it again gives the reverse inequality.   
\end{proof}

\section{The density $f$ enjoys a product structure}

The main result in this section is to show that if $\mu \in \mathscr{W}(\mathbb{R}^n)$ with distribution function $f$ is a PS measure, then the function $f$ enjoys a product structure subordinate to all orthogonal frames $\{\vec{e_i}\}_i^n$ in $\mathbb{R}^n$. This is made rigorous in Corollary \ref{c:product structure in all directions}.

The key idea is to use variational techniques employed by \cite{Rosales14} in the study of isoperimetric sets for perturbations of log-concave measures and \cite{BrockChiacchioMercaldo12}\cite{BrockChiacchio16} in the study of the structure of measures with foliations by isoperimetric sets. See the following lemma.

\begin{lemma}\label{l:product structure}
    Let $\mu \in \mathscr{W}(\mathbb{R}^n)$ with distribution function $f$. Write $x \in \mathbb{R}^n$ as $x = (x', x_n) \in \mathbb{R}^{n-1}\times \mathbb{R}$.  If the sets $H(\vec{e_n}, c) =\{x \in \mathbb{R}^n: x_n \ge c\}$ are \emph{critical points} for $\mu$-perimeter for all $c \in (a, b) \subset \mathbb{R}$ then the following statements hold.
    \begin{enumerate}
        \item There is a disjoint collection of open intervals $I_j$ such that for $\mathcal{H}^{n-1}$-a.e. $x' \in \mathbb{R}^{n-1}$ the positivity set $\{f(x', \cdot)>0\} \subset \{I_j\}_j$.
        \item For each $I_k \in \{I_j \}_j$ there exist functions $A_k: \mathbb{R}^{n-1}\rightarrow \mathbb{R}$, $B_k:I_k\rightarrow \mathbb{R}$ such that for $\mathcal{H}^{n}$-a.e. $(x', x_n) \in \mathbb{R}^{n}$
    \begin{align}\label{e: product structure x' x n}
        f(x',x_n) = A_k(x')B_k(x_n).
    \end{align}
    \item For every $I_k \in \{I_j \}_j$, $B_k(x_n) \in W^{1, 1}(I_k) \subset C(I_k)$.
    \end{enumerate}
    \end{lemma}

\begin{proof}
    Let $c \in (a, b)$, and assume that $B_{\varepsilon_0}(c) \subset (a, b)$. Given a function $h \in C^1(\mathbb{R}^{n-1})$ we shall construct a corresponding family of measure-preserving perturbations of $H(\vec{e_n}, c)$ as follows. Let $s_h: (-\varepsilon_0, \varepsilon_0) \rightarrow \mathbb{R}$ be a ``shift" function defined to be the smallest real number such that the sets
    \begin{align*}
G_\varepsilon:= \{x\in \mathbb{R}^n: x_n \ge c+ \varepsilon h(x') + s_h(\varepsilon) \}\end{align*}
satisfies 
\begin{align}\label{e:measure preserving}
\mu(H(\vec{e_n}, c)) = \mu(G_{\varepsilon}).
\end{align}
Note that this forces $s_h(0)=0$.  Moreover, if we employ the notation 
$$g(x',\varepsilon):= c+ \varepsilon h(x') + s_h(\varepsilon)$$ 
then the condition \eqref{e:measure preserving} can be re-written as
\begin{align}\label{e:meas preserving formula}
\int_{\mathbb{R}^{n-1}}\int_{g(x', \varepsilon)}^{\infty}f(x', x_n)dx_n dx' = \mu(H(\vec{e_n}, c)).
\end{align}
Now, we consider the limit of the difference quotients.
\begin{align*}
0 & = \lim_{\varepsilon \rightarrow 0}\frac{\mu(G_{\varepsilon}) - \mu(H(\vec{e_n}, c))}{\varepsilon} \\
& = \lim_{\varepsilon \rightarrow 0}\frac{\int_{\mathbb{R}^{n-1}}\Big[\int_{g(x', \varepsilon)}^{\infty}f(x', x_n) - \int_{c}^{\infty}f(x', x_n)dx_n \Big] dx'}{\varepsilon}\\
& = \lim_{\varepsilon \rightarrow 0}\frac{\int_{\mathbb{R}^{n-1}}\int_{g(x', \varepsilon)}^{c}f(x', x_n)dx_ndx'}{\varepsilon}.
\end{align*}
Notice that for $\mathcal{H}^{n-1}$-a.e. $x' \in \mathbb{R}^{n-1}$ the function $x_n\mapsto f(x', x_n)$ is in $W^{1,1}_{loc}(\mathbb{R})$ and hence continuous (see, for example, \cite{brezis} Theorem 8.2). We may use the mean value theorem and find a $x_{n, \varepsilon} \in [\min\{c, g(x', \varepsilon)\}, \max\{c, g(x', \varepsilon)\}]$ such that
\begin{align*}
\lim_{\varepsilon \rightarrow 0}\frac{\int_{\mathbb{R}^{n-1}}\int_{g(x', \varepsilon)}^{c}f(x', x_n)dx_ndx'}{\varepsilon}
& = \lim_{\varepsilon \rightarrow 0}\frac{\int_{\mathbb{R}^{n-1}}(\varepsilon h(x') + s_h(\varepsilon))f(x', x_{n, \varepsilon})dx'}{\varepsilon}\\
& = \int_{\mathbb{R}^{n-1}} h(x') f(x', c)dx' + \lim_{\varepsilon \rightarrow 0} \frac{s_h(\varepsilon) -s_h(0)}{\varepsilon}\int_{\mathbb{R}^{n-1}}f(x', c)dx',
\end{align*}
where we have used $s_h(0)=0$ and the fact that if $\lim_{r\rightarrow a} A(r)B(r)$ exists and $\lim_{r\rightarrow a} A(r)$ exists, then $\lim_{r\rightarrow a} A(r)B(r) = \lim_{r\rightarrow a} A(r) \cdot \lim_{r\rightarrow a} B(r)$. Without loss of generality, we may assume that $\int_{\mathbb{R}^{n-1}}f(x', c)dx'\not=0$. Otherwise, we have $f(\cdot, c) \equiv 0$ on $\mathbb{R}^{n-1}$ then \eqref{e: product structure x' x n} holds trivially with $B(x_n) = 0$. In particular, if $\int_{\mathbb{R}^{n-1}}h(x')f(x', c)dx'=0$ then 
\begin{align}\label{s_prime}
s'_h(0)=\lim_{\varepsilon \rightarrow 0} \frac{s_h(\varepsilon) -s_h(0)}{\varepsilon}=0.
\end{align}
Moreover, by our assumption that $H(\vec{e_n}, c)$ is a critical point for the $\mu$-perimeter in its mass class
\begin{align}\label{e:minimizer}
    \operatorname{Per}_{\mu}(G_\varepsilon) = \int_{\mathbb{R}^{n-1}}f(x', g(x', \varepsilon))\sqrt{1+ |\nabla_{x'}(g(x', \varepsilon))|^2}dx'
\end{align}
satisfies 
\begin{align}\label{e:first variation}
    \lim_{\varepsilon\to 0}\frac{\operatorname{Per}_{\mu}(G_{\varepsilon})-\operatorname{Per}_{\mu}(H(\vec{e_n}, c))}{\varepsilon} & = 0.    
\end{align}
Therefore, 
\begin{align*}
0&=\lim_{\varepsilon\to 0}\frac{\operatorname{Per}_{\mu}(G_{\varepsilon})-\operatorname{Per}_{\mu}(H(\vec{e_n}, c))}{\varepsilon}\\
&=\lim_{\varepsilon\to 0}\frac{1}{\varepsilon}\left(\int_{\mathbb{R}^{n-1}}f(x', g(x', \varepsilon))\sqrt{1+ \varepsilon^2|\nabla_{x'}h(x')|^2}dx'-\int_{\mathbb{R}^{n-1}}f(x', c)dx'\right)\\
&=\lim_{\varepsilon\to 0}\frac{1}{\varepsilon}\int_{\mathbb{R}^{n-1}}\left(f(x', c+ \varepsilon h(x') + s_h(\varepsilon))-f(x',c)\right)\sqrt{1+ \varepsilon^2|\nabla_{x'}h(x')|^2}dx'\\
&\quad +\lim_{\varepsilon\to 0}\int_{\mathbb{R}^{n-1}}f(x', c)\left(\frac{\sqrt{1+ \varepsilon^2|\nabla_{x'}h(x')|^2}-1}{\varepsilon}\right)dx'\\
&=\lim_{\varepsilon\to 0}\frac{1}{\varepsilon}\int_{\mathbb{R}^{n-1}}\left(\int_c^{c+\varepsilon h(x')+s_h(\varepsilon)}\partial_{x_n}f(x',t)dt\right)\sqrt{1+ \varepsilon^2|\nabla_{x'}h(x')|^2}dx'\\
&=\lim_{\varepsilon\to 0}\int_{\mathbb{R}^{n-1}}\left(\frac{\varepsilon h(x')+s_h(\varepsilon)}{\varepsilon}\right)\left(\frac{\int_c^{c+\varepsilon h(x')+s_h(\varepsilon)}\partial_{x_n}f(x',t)dt}{\varepsilon h(x')+s_h(\varepsilon)}\right) \sqrt{1+ \varepsilon^2|\nabla_{x'}h(x')|^2}dx'\\
&=\lim_{\varepsilon \rightarrow 0} \frac{s_h(\varepsilon)}{\varepsilon}\int_{\mathbb{R}^{n-1}}\partial_{x_n}f(x',c)h(x') dx'
\end{align*}
for $\mathcal{H}^1$-a.e. $c\in (a,b)$ by the Lebesgue differentiation theorem (see \cite{evansgariepy}, Section 1.7, Corollary 2).

Therefore, if our original function $h \in C^1(\mathbb{R}^{n-1})$ satisfies $\int_{\mathbb{R}^{n-1}}f(x', c)h(x')dx' = 0$ then by \eqref{s_prime}
\begin{align*}
    \int_{\mathbb{R}^{n-1}}\partial_{x_n}f(x',c)h(x')dx' = 0.
\end{align*}
Therefore, if $f(\cdot, c)$ is not the zero function on $\mathbb{R}^{n-1}$ there must be a constant $K(c)$ such that for almost every $x' \in \mathbb{R}^{n-1}$,
\begin{align}\label{e:separation of variables}
\partial_{x_n}f(x',c) = K(c)f(x', c).
\end{align} 
 
Now, let $L_{x'} = \pi_{\mathbb{R}^{n-1}}^{-1}(x')$ and recall that for $\mathcal{H}^{n-1}$-a.e. $x'$ the function $f\res L_{x'} \in W^{1, 1}_{loc}(L_{x'}) \subset C(L_{x'})$. For such $x'$, $\{f \res L_{x'} >0\}$ is open in $\mathbb{R}$.  Thus, we may write 
$$\{f \res L_{x'}>0\} = \bigcup_{j=1}\{x'\} \times I_j(x')$$ for some disjoint collection of open intervals $I_j(x') = (a_j(x'), b_j(x'))$. In particular, the functions $\partial_{x_n}f(x',c)$, $f(x', c)$ are locally integrable in each $I_j(x')$, and hence $K(c)$ is measurable and locally integrable, as well. Therefore, for any $x_{n, 0}, x_n \in I_j(x')$ we may integrate \eqref{e:separation of variables} to see that 
\begin{align*}
\log f(x',c)\big|_{c=x_{n, 0}}^{c=x_n}=\int_{x_{n, 0}}^{x_n}K(c)dc\implies f(x',x_n) =f(x',x_{n, 0})e^{\int_{x_{n,0}}^{x_n}K(c)dc}.
\end{align*}
Fix such an $x', I_j(x')$, and letting $x_{n} \rightarrow b_j(x')$ we observe that $\int_{x_{n,0}}^{b_j(x')} K(c)dc = -\infty$ since $f(x',b_j(x'))=0$ and $f(x',x_{n, 0})>0$. Therefore, for $\mathcal{H}^{n-1}$-a.e. $x'' \in \mathbb{R}^{n-1}$, the point $b_j(x') \not \in \{f(x'', \cdot)>0\}$.  Indeed, if there were such an $x''$ and $b_j(x') \in I_k(x'') = (a_k(x''), b_k(x''))$ then $\int_{x_{n,0}}^{b_j(x')} K(c)dc = -\infty$ implies that $f(x'', b_j(x')) =0$.  This means that we may find a maximal collection of disjoint open intervals $\{I_j\}_j$ such that for $\mathcal{H}^{n-1}$-a.e. $x'' \in \mathbb{R}^{n-1}$
\begin{enumerate}
    \item $\{f(x'', \cdot)>0 \} \subset \{I_j\}$.
    \item If $I_k = (a_k, b_k) \in \{I_j\}$ then either $f(x'', \cdot)>0$ in $I_k$ and $f(x'', a_k) = f(x'', b_k)=0$ or $f(x'', \cdot)\equiv 0$ in $I_k$. 
\end{enumerate}

Therefore, for each $I_j$ we may choose $x_{n,0} = (a_j + b_j)/2$ and obtain that for every $I_j$ there exist functions $A_j(x')=f(x',(a_j(x')+b_j(x'))/2)$ and $B_j(x_n)=e^{\int_{x_{n,0}}^{x_n}K(c)dc}$ such that 
\begin{align*}
    f(x', x_n) = A_j(x')B_j(x_n)
\end{align*}
for $\mathcal{H}^n$-a.e. $(x', x_n) \in \mathbb{R}^{n-1} \times I_j$.  This proves the lemma.
\end{proof}

\begin{remark}
    Lemma \ref{l:product structure} is a generalization of \cite{BrockChiacchio16} Theorem 2.1, in which the authors prove (among other things) that in a Lipschitz domain $\Omega\subset \mathbb{R}^n$, if $d\nu = \phi d\mathcal{H}^{n}$ for $\phi \in C^1(\Omega)$ and $\phi>0$ and the relative half spaces $\Omega \cap H(\vec{e_n}, c)$ are minimizers of $\operatorname{Per}_{\nu}(\cdot, \Omega)$ in their mass class for all $c \in \mathbb{R}$ then $\phi(x', x_n) = \rho(x')s(x_n)$ for $\rho, s$ both $C^1$ functions.  The assumption that $\phi \in C^1$ and $\phi>0$ allows the authors to use the Implicit Function theorem to obtain $s \in C^2$, and to force $\{I_j\}_j = \mathbb{R}$.  However, under the more general assumptions of Lemma \ref{l:product structure} the possibility of multiple intervals $\{I_j\}$ is unavoidable. It is clear that Lemma \ref{l:product structure}, above, may be reformatted to handle such relative isoperimetric problems as well.
\end{remark}

Combining Lemma \ref{l:product structure} with Lemma \ref{l:all half-spaces} gives the following corollary.

\begin{corollary}\label{c:product structure in all directions}
Let $\mu \in \mathscr{W}(\mathbb{R}^n)$ with distribution function $f$.  Assume that $\mu$ a PS measure.  Then either $f \equiv 0$ or for every orthonormal frame $\{\vec{e_i} \}_i^n$ and coordinates $(x_1, ..., x_n)$ on $\mathbb{R}^n$ imposed by $\{\vec{e_i}\}_i^n$ \begin{align}\label{e:product formula}
        f(x_1, ..., x_n) = \prod_{i=1}^nf_i(x_i)
    \end{align} for some functions $f_i \in L^1(\mathbb{R}^n) \cap W^{1, 1}_{loc}(\mathbb{R})$ satisfying $f_i>0$, depending upon $\{\vec{e_i} \}_i^n$. In particular, we may choose the representative of $f$ defined by \eqref{e:product formula} everywhere and obtain that $f \in C(\mathbb{R}^n)$ and $f>0$. 
\end{corollary}

\begin{proof}
Fix an orthonormal frame $\{\vec{e_i}\}_{i=1}^n$.  Lemma \ref{l:all half-spaces} allows us to apply Lemma \ref{l:product structure} in each direction $\vec{e_i}$ to produce a countable collection of axis-parallel rectangles $\{R_{j_1, ..., j_n}\}$ where 
\begin{align*}
    R_{j_1, ..., j_n} = I_{j_1} \times ... \times I_{j_n}
\end{align*}
for $I_{j_k} \in \{I_j\}$ the collection of intervals guaranteed by Lemma \ref{l:product structure} with $x_k$ in place of $x_n$.  

Now, suppose that we have an axis-parallel rectangle $R$ in $\mathbb{R}^n$ and $n$ different decompositions of a function $f(x_1, ..., x_n) = A_i(x_i)B_i(x_1, ..., \hat{x_i}, ..., x_n)$ where we use the $\hat{x_i}$ notation to indicate that $B_i$ does not depend upon $x_i$. Then by induction on $n$ we may easily obtain that $f(x_1, ..., x_n) = \prod_{i=1}^n A_i(x_i)$.  Thus, within each $R_{j_1, ..., j_n}$ there exist $L^1(\mathbb{R}^n) \cap W^{1,1}_{loc}(\mathbb{R}^n)$ functions $f_{j_1}, ..., f_{j_n}$ such that for $\mathcal{H}^{n}$-a.e. $(x_1, ..., x_n) \in R_{j_1, ..., j_n}$ 
\begin{align*}
    f(x_1, ..., x_n) = \prod_{i=1}^n f_i(x_i).
\end{align*}

We claim that $\{I_{j_i}\} = \mathbb{R}$ for each $i =1, ..., n$ implying that there is only one rectangle, namely $\mathbb{R}^n$ itself.  To see the claim, observe that in general the zero set $\{f=0\}$ is of the form
\begin{align*}
    \{f=0\} = \bigcup_{i=1}^n\left(\mathbb{R}^{i-1} \times \{f_i=0\} \times \mathbb{R}^{n-i}\right).
\end{align*}
Note that this set is the union of axis-parallel slabs of the form
\begin{align*}
   K= \mathbb{R}^{j-1} \times V \times \mathbb{R}^{n-j}
\end{align*}
for some connected, closed sets $V \subset \mathbb{R}$. If $\{I_{j}\} \not = \mathbb{R}$ then $\{f=0\}$ is non-empty and there exists at least one set $K \subset \{f=0\} \not=\mathbb{R}^n$.  Hence, we may find a new orthonormal frame $(\varepsilon_1, ...,\varepsilon_{n})$ such that sets of the form $K$ are no longer axis-parallel.  But, because $f$ admits a product structure in this new basis, $\{f=0\}$ must have consist in a union of axis-parallel slabs in the new coordinate system.  If $f \not\equiv 0$, this provides a contradiction. Therefore, if $f\not \equiv 0$ we must have $\{f=0 \} = \emptyset$.  In particular, $R_{j_1, ..., j_n} = \mathbb{R}^n$ and the claim holds.

Thus, we may choose the function defined by \eqref{e:product formula} to be the representative of $f \in L^1(\mathbb{R}^n) \cap W^{1, 1}_{loc}(\mathbb{R}^n)$. The rest of the properties follow immediately from this choice and the fact that the $f_i \in W^{1,1}_{loc}(\mathbb{R}) \subset C(\mathbb{R})$.
\end{proof}

\section{Symmetry and the proof of Theorem \ref{t:main theorem 2}}

As the reader may expect, Corollary \ref{c:product structure in all directions} imposes many restrictions upon the structure of the weight function $f$. In this section, we elaborate the geometric consequences  of Corollary \ref{c:product structure in all directions}, which culminates in the proof of Theorem \ref{t:main theorem 2}.  The essential ingredient which allows us to exploit the product structure is the imposition of symmetry.  

In the interest of concision, we adopt the notation that for a measure $\nu$, a $\nu$-measurable function $g$, and a $\nu$-measurable set $A$, $(\nu \res g) (A) = \int_A g d\nu$. 

\begin{lemma}\label{l:restrictions are symmetric}
    Let $\mu \in \mathscr{W}(\mathbb{R}^n)$ with distribution function $f$.  Assume that $\mu$ a PS measure. For every line $L \subset \mathbb{R}^n$, the restriction measure $\mu \res L = fd\mathcal{H}^1\res L$ is symmetric.
\end{lemma}

\begin{proof}
We argue by contradiction.  Let $L$ be a line in $\mathbb{R}^n$ and choose an orthonormal basis $\{\vec{e}_i\}_i$ such that $L = \text{span}(\vec{e}_1)$. By Corollary \ref{c:product structure in all directions} we know that $f$ is defined pointwise, and so we may consider the following collection of restriction measures.  For any $y \in B_{r}^{n-1}(0)$ we define the measure $\nu_y$ defined by $d\nu_y:= fd\mathcal{H}^1\res (L+y)$.  If $\nu = \nu_0$ is not symmetric, then by Lemma \ref{l:Ehrhard implies symmetric} $\nu$ cannot is not a PS measure.  Therefore, there is a set $E \subset L$ such that 
\begin{align}\label{e: perimeter inequality}
    \operatorname{Per}_{\nu}(E) < \operatorname{Per}_{\nu}((E)^s_{\vec{v}}).
\end{align} 
for $\vec{v} \in \{\vec{e_1}, -\vec{e_1} \}$.  Note that because $f \in L^{\infty}$, strictly positive, and defined pointwise, $E$ is a set of finite, positive $\nu$-perimeter in $L$. 

\textbf{Claim 1:} We claim that there is a $0<r$ and a bounded set $E^t \subset \mathbb{R}$ such that for all $y \in B_r^{n-1}(0)$ the set $E^t \times \{y\} \subset L +y \subset \mathbb{R}^n$ is also a set for which generalized $\vec{v}$-Ehrhard symmetrization is $\nu_y$-perimeter increasing. We demonstrate the claim, below.

First, we note that by Corollary \ref{c:product structure in all directions}, $f$ is absolutely continuous on compact subsets.  That is, for all $0<R<\infty$ and for any $0<\varepsilon$ there is a $0<\delta(\varepsilon, R)$ such that for all $x, y \in B_{R}(0)$ if $|x-y| \le \delta$ then $|f(x) - f(y)|< \varepsilon$. Moreover, since $\operatorname{Per}_{\nu}(E)$, $\nu(E)<\infty$ for any $0<\varepsilon$ we may find a truncation of $E$ of the form
\begin{align*}
    E^{t} = E \cap \{|x|\le t\}
\end{align*}
such that $\nu(E) - \nu(E^{t}) \le \varepsilon$ and $|\operatorname{Per}_{\nu}(E) - \operatorname{Per}_{\nu}(E^t)| \le \varepsilon$.

Therefore, if we let $0<\alpha$ such that
\begin{align}
    \operatorname{Per}_{\nu}(E) + \alpha < \operatorname{Per}_{\nu}((E)^s_{\vec{v}})
\end{align} 
and let $0<\varepsilon \le \alpha/3$ above to produce a set $E^{t(\varepsilon)}$ as above.  Letting $\varepsilon$ be sufficiently small, it is clear that by the absolute continuity of $f$, we may assume that $|\operatorname{Per}_{\nu}((E^{t})^s_{\vec{v}}) - \operatorname{Per}_{\nu}((E)^s_{\vec{v}})| \le \alpha/3$. For such $0<\varepsilon$, $E^{t}$ is bounded and 
\begin{align}
    \operatorname{Per}_{\nu}(E^{t}) + \alpha/3 < \operatorname{Per}_{\nu}((E^{t})^s_{\vec{v}}).
\end{align}
This $E^t$ is the set which demonstrates the claim.  We argue by contradiction.  Suppose that there is a sequence of $y_i \in B_r^{n-1}(0)$ such that $y_i \rightarrow 0$ and $\operatorname{Per}_{\nu_{y_i}}((E^t \times \{y_i\})^s_{\vec{v}}) \le \operatorname{Per}_{\nu_{y_i}}((E^t \times \{y_i\})^s_{\vec{v}})$.  Since all these sets are compact, absolute continuity shows that $\nu_{y_i}(E^t \times \{y_i\}) \rightarrow \nu(E^{t})$ and hence $\operatorname{Per}_{\nu_{y_i}}((E^t \times \{y_i\})^s_{\vec{v}}) \rightarrow \operatorname{Per}_{\nu}((E^{t})^s_{\vec{v}})$. This is a contradiction.  Therefore, the claim holds.

\textbf{Claim 2:} We claim that the set $E^{t} \times B_r^{n-1}(0)$ contradicts the assumption that $\mu$ is an Ehrhard measure. 

Note that because $f>0$, $E^{t} \times B_r^{n-1}(0)$ has positive measure.  Moreover, because
\begin{align*}
\operatorname{Per}_{\mu}(E^{t} \times B_r^{n-1}(0)) = &  \int_{B_r^{n-1}(0)} \left(\sum_{a_1' \in \partial E^t} f_1(a_1') \right) \prod_{j=2}^nf_j(a_j)d\mathcal{H}^{n-1}\\
& + \int_{\partial B_r^{n-1}(0)} \int_{E^{t}\times \{y\}} f d\mathcal{H}^1d\mathcal{H}^{n-2}(y),
\end{align*}
the fact that $f$ is bounded, $\text{Per}_{\mu_x}(E^t)<\infty$, and $E^t$ is bounded implies $E^{t} \times B_r^{n-1}(0)$ has finite $\mu$-perimeter.  Moreover, we may calculate
\begin{align*}
\operatorname{Per}_{\mu}((E^{t} \times B_r^{n-1}(0))^s_{\vec{v}}) = &  (\mathcal{H}^{n-1}\res f)(\{\partial (E^t \times \{y\})^s_{\vec{v}} :y \in B_r^{n-1}(0) \})\\
& + \int_{\partial B_r^{n-1}(0)} \int_{(E^{t} \times \{y\})^s_{\vec{v}}} f d\mathcal{H}^1d\mathcal{H}^{n-2}(y).
\end{align*}
Since by definition of generalized Ehrhard symmetrization
\begin{align*}
\int_{\partial B_r^{n-1}(0)} \int_{E^{t} \times \{y\}} f d\mathcal{H}^1 d\mathcal{H}^{n-2}(y)=
\int_{\partial B_r^{n-1}(0)} \int_{(E^{t} \times \{y\})^s_{\vec{v}}} f d\mathcal{H}^1 d\mathcal{H}^{n-2}(y)
\end{align*}
We need only to calculate the remaining terms.  But, this is trivial, since by construction
\begin{align*} (\mathcal{H}^{n-1}\res f)&(\{\partial (E^t \times \{y\})^{s}_{\vec{v}}): y \in B_r^{n-1}(0) \})\\
& \ge \int_{B_{r}^{n-1}(0)} f(\partial (E^t \times \{y\})^{s}_{\vec{v}})d\mathcal{H}^{n-1}\\
& >  \int_{B_r^{n-1}(0)} \left(\sum_{a_1' \in \partial E_t} f_1(a_1') \right) \prod_{j=2}^nf_j(a_j)d\mathcal{H}^{n-1}\\
& = (\mathcal{H}^{n-1}\res f)(\{\partial (E^t \times \{y\}) :y \in B_r^{n-1}(0) \}).
\end{align*}

Thus, if the lemma is false, then $\mu$ is not a PS measure. This proves the lemma.
\end{proof}


\begin{lemma}\label{l:symmetric in Rn}
Let $\mu \in \mathscr{W}(\mathbb{R}^n)$ with distribution function $f$.  Assume that $\mu$ a PS measure.  Then there is a unique point $a \in \mathbb{R}^n$ such that $\mu$ is symmetric across all hyperplanes $P$ that contain $a$.
\end{lemma}

\begin{proof}
    By the previous lemma, we know that for every line, $L$, $f\res L$ is symmetric.  Therefore, for any orthonormal basis $(e_1, ..., e_n)$ and corresponding product structure $f = \prod_{i=1}^n f_i$, each $f_i$ is also symmetric.  Hence, there are $n$ axis-parallel $(n-1)$-planes defined by the point of symmetry for $f_i$ across which $f$ is symmetric in the sense of Definition \ref{d: symmetric in measure}.  Since these planes are orthogonal, they intersect at a unique point $a(e_1, ..., e_n)$. By Appendix A Lemma \ref{l:reflections break L1}, the point $a(e_1, ..., e_n)$ is independent of the choice of orthonormal basis $(e_1, ..., e_n)$.  Therefore, since any hyperplane $P$ containing $a = a(e_1, ..., e_n)$ is a hyperplane that comes from some choice of $(e_1, ..., e_n)$, $f$ is symmetric across $P$.
\end{proof}

Lemma \ref{l:symmetric in Rn} has the following quick corollary.

\begin{corollary}\label{l:radial}
Let $\mu \in \mathscr{W}(\mathbb{R}^n)$ with distribution function $f$ be a PS measure. Let $a \in \mathbb{R}^n$ be the unique point guaranteed by Lemma \ref{l:symmetric in Rn}.  Then there is a function $g:[0, \infty) \rightarrow (0, \infty)$ in $W^{1,1}([0, \infty))$ such that 
\begin{align}
    f(x) = g(|x-a|).
\end{align}
\end{corollary}

\begin{proof}
    Since $f$ is symmetric across all hyperplanes that contain $a$, the level sets must also satisfy this property.  Therefore, by rotating the hyperplanes we see that the level sets must be unions of spheres centered at $a$.   
\end{proof}

\subsection{Proof of Theorem \ref{t:main theorem 2}}\label{l:f is gaussian}
Let $a$ be the point of symmetry guaranteed by Corollary \ref{l:radial}.  We will show that there exist constants $0< c< \infty$, $0 \le C < \infty$ such that
\begin{align*}
    f(x) = Ce^{-c|x-a|^2}.
\end{align*}

If $f \equiv 0$ then we may choose $C = 0$.  If $f \not \equiv 0$, then by translation we may assume that $a=0$ in Corollary \ref{l:radial}. Then $f$ is rotation invariant, i.e., for any orthogonal matrix $O$, we have
\begin{align}\label{rotation_invariant}
f(Ox)=f(x).
\end{align}
Let $f(x) = \prod_{i=1}^nf_i(x_i)$ be a product structure as guaranteed by Corollary \ref{c:product structure in all directions}.  Note that in the case $f\not \equiv 0$, $f_i>0$ and $f_i \in C(\mathbb{R})$. Hence, each product function $f_i$ can be written as 
$$f_i(x_i)=f_i(0)\left(\frac{f_i(x_i)}{f_i(0)}\right)=c_ie^{g_i(x_i)}$$
for some continuous function $g_i$, where $c_i=f_i(0)$ and $g_i(0)=0$. Consider $(a,0,...,0)$ and $(0,a,...,0)$, by equation (\ref{rotation_invariant}), we have
$$\left(\prod_{i=1}^nc_i\right)e^{g_1(a)+g_2(0)+...+g_n(0)}=f(a,0,...,0)=f(0,a,0,...,0)=\left(\prod_{i=1}^nc_i\right)e^{g_1(0)+g_2(a)+...+g_n(0)}.$$
That is, $g_1(a)=g_2(a)$ for any $a\in \mathbb{R}$. By an identical argument, $g_i = g_j$ for all $1\le i, j \le n$ and $g_i(-a)= g_i(a)$ for all $1\leq i\leq n$. Thus, we may assume that $a> 0$ for the rest of the proof.

%Now, we compare $(a, a, 0, ..., 0)$ and its rotation $(\sqrt{2}a, 0, 0, ..., 0)$, by equation (\ref{rotation_invariant}), we obtain that $$\left(\prod_{i=1}^nc_i\right)e^{g_1(a)+g_2(a)}=f(a,a,...,0)=f(\sqrt{2}a,0,...,0)=\left(\prod_{i=1}^nc_i\right)e^{g_1(\sqrt{2}a)}.$$ Thus, $$e^{2g_1(a)}=e^{g_1(a) + g_2(a)}  =e^{g_1(\sqrt{2}a)}.$$ In other words, the $g_i$ function satisfies $g_1(\sqrt{2}a) = 2g_1(a)$, i.e., $g_1(2a)=2^2g_1(a)$.  By iterating this relationship we see that for any $N \in \mathbb{Z}$, \begin{align}\label{e:root 2 scaling} g_i(\sqrt{2^N}a) = 2^N g_i(a). \end{align} We claim that for any $N \in \mathbb{N}$, \begin{align}\label{e:1+root 2 relation}    g_i\left(\sqrt{1+\frac{1}{2^N}}\ a\right) = \left(1 + \frac{1}{2^N}\right)g_i(a).\end{align}

%Observe that $\sqrt{1+\frac{1}{2^N}} = \sqrt{1^2 + (\sqrt{\frac{1}{2^N}})^2}$ and consider \begin{align*}\mbox{$\left(\sqrt{1+\frac{1}{2^N}}\ a, 0, 0, ..., 0\right)$ and $\left(a, \sqrt{\frac{1}{2^N}}\ a, 0, ..., 0\right)$},\end{align*} by equation (\ref{rotation_invariant}), \begin{align*} g_i\left(\sqrt{1+\frac{1}{2^N}}\ a\right)=g_1\left(\sqrt{1+\frac{1}{2^N}}\ a\right) & = g_1(a) + g_2\left(\sqrt{\frac{1}{2^N}}\ a\right)\\ & = g_1(a) + \frac{1}{2^N}g_1(a) = \left(1 + \frac{1}{2^N}\right)g_i(a). \end{align*} That is, \begin{align*} g_i\left(\left(1+\frac{1}{2^N}\right) a\right) = \left(1 + \frac{1}{2^N}\right)^2g_i(a). \end{align*}
%Next, we claim that \eqref{e:root 2 scaling}, \eqref{e:1+root 2 relation}, and the continuity of $g_i$ imply that for any $1< \lambda < 2$, $$g_i(\lambda a) = \lambda^2 g_i(a).$$  Let $\lambda$ be given. We claim that there exists a sequence of positive integers $\{N_j\}$ with $N_j\geq j$ such that  \begin{align*} \lambda = \lim_{k \rightarrow \infty} \prod_{j=1}^k \left(1+\frac{1}{2^{N_j}}\right).\end{align*}
%\kuanting{I'm not sure how to use the density here.} \sean{This follows from the fact that if you choose $N_j=j$ then the product is greater that 2.  So for any $\lambda \in [1, 2]$ you only need some subset of the multiplicants. }\\
%Notice that the product converges since  $$\sum_{j=1}^{\infty}\frac{1}{2^{N_j}}\leq \sum_{j=1}^{\infty}\frac{1}{2^{j}}<\infty.$$ Now, for each $k$, we have \begin{align*} g_i\left( \prod_{j=1}^k  \left(1+\frac{1}{2^{N_j}}\right) a\right) = \prod_{j=1}^k \left(1 + \frac{1}{2^{N_j}}\right)^2 g_i(a). \end{align*} Hence,  $$g_i(\lambda a)=\lim_{k \rightarrow \infty} g_i\left( \prod_{j=1}^k  \left(1+\frac{1}{2^{N_j}}\right) a\right) = \lim_{k \rightarrow \infty}\prod_{j=1}^k \left(1 + \frac{1}{2^{N_j}}\right)^2 g_i(a)=\lambda^2g_i(a),$$  where we have used the fact that $g_i$ is continuous. Thus, $g_i$ is $2$-homogeneous, and hence $g_i(x_i) = cx_i^2$.\kuanting{I'm not sure how to justify this. I rewrite the above proof in the next paragraph.} \sean{Are you unclear why this proves that the function is $2$-homogeneous? Or, are you unsure how to justify that a $2$-homogeneous function has the claimed form?}\\

First, we claim that for all positive integers $k$, we have
\begin{align}\label{e: base relation sqrt}
    g_1(\sqrt{k}a)=kg_1(a).
\end{align}
Note that $k=1$ is trivial.  Assume that the claim holds for all integers less than or equal to $k$. For the case $k+1$, we consider $(\sqrt{k+1}a,0,...,0)\mbox{ and its rotation } (a,\sqrt{k}a,0,...,0).$  By equation (\ref{rotation_invariant}), we obtain that
$$\left(\prod_{i=1}^nc_i\right)e^{g_1(\sqrt{k+1}a)}=f(\sqrt{k+1}a,0,...,0)=f(a,\sqrt{k}a,...,0)=\left(\prod_{i=1}^nc_i\right)e^{g_1(a)+g_2(\sqrt{k}a)}.$$
Thus, $$g_1(\sqrt{k+1}a)=g_1(a)+g_1(\sqrt{k}a)=g_1(a)+kg_1(a)=(k+1)g_1(a),$$
where we have used the induction hypothesis on $k$. This proves the claim.  

Now, we define
$$h(a):=\frac{g_1(a)}{a^2}$$
for all $a>0$. By \eqref{e: base relation sqrt}, we know $g_1(ka)=k^2g_1(a)$ and hence $h(ka)=h(a)$ for any positive integer $k$. In particular,
$$h(1)=h(1/q)$$
for all positive integers $q$. For any positive rational number $p/q$, we have
$$h(p/q)=h\left(p\left(\frac{1}{q}\right)\right)=h(1/q)=h(1).$$
For any $a>0$, there exists a sequence of rational numbers $\{r_k\}$ such that $r_k\to a$. Since $h$ is continuous, we see that
$$h(1)=\lim_{k\to \infty}h(r_k)=h(a)$$ for all $a>0$. Letting $c=-h(1)$ and unwinding the definition of $h$, we have $g_1(a)=-ca^2$ for all $a>0$. By $g_1(a)=g_1(-a)$ and $g_1(0)=0$,
$$g_1(a)=-ca^2$$
for all $a\in \mathbb{R}$. To complete the proof, we only need to prove that the constant $c$ is positive. However, if $c\le 0$, then $f \not \in L^1(\mathbb{R}^n)$.  Therefore, $f$ is an isotropic Gaussian. \qed

\begin{remark}
That $c>0$ also follows from \cite{Chambers19}, in which Chambers proves that disks are the unique perimeter minimizers of measures with distributions that are log-convex, rotationally symmetric functions. Since by Lemma \ref{l:H are minimal} all half-spaces are $\mu$-perimeter minimizers, $c>0$.
\end{remark}

\section{Appendix A: The Reflection Argument}\label{The Reflection Argument}

The purpose of this Appendix is to justify the intuition that if $f \in C^0(\mathbb{R}^n)$ is a positive function and there exist two systems of orthogonal hyperplanes $\{P_i^0\}_{i=1}^n, \{P_i^1 \}_{i=1}^n$ in $\mathbb{R}^n$ such that $f$ is symmetric across each $P^j_i$ and the points $a_0 = \cap_{i=1}^n P^0_i$ and $a_1 = \cap_{i=1}^n P_i^1$ satisfy $a_0 \not = a_1$ then we can ``reflect mass \textit{ad absurdam}," which forces $f \not \in L^1(\mathbb{R}^n)$.

\begin{lemma}[A technical lemma in $\mathbb{R}^2$]\label{l:reflection arg n=2}
Let $n=2$, and suppose that there exist two systems of orthogonal hyperplanes $\{P_i^0\}_{i=1}^n, \{P_i^1 \}_{i=1}^n$ in $\mathbb{R}^n$ and points $a_0, a_1 \in \mathbb{R}^n$ such that $a_0 = \cap_{i=1}^n P^0_i$, $a_1 = \cap_{i=1}^n P_i^1$, and $a_0 \not = a_1$.  If $f \in C^0(\mathbb{R}^n)$ is symmetric across $P_i^0, P_i^1$ for each $i=1,..., n$ then there exists another system of orthogonal hyperplanes $\{P_i''\}_{i=1}^n$ such that $a' = \cap_{i=1}^nP_i'$, $f$ is symmetric across each $P_i'$, and 
\begin{align}\label{e:n=2 a' dist estimate}
\min\{\dist(a', a_0), \dist(a', a_1)\} > \dist(a_0, a_1).
\end{align}
\end{lemma}

\begin{remark}\label{r:reflections of reflections} Observe that if $f$ is symmetric across hyperplanes $P_i^0, P_j^1$ and $R_{i}^0$ is reflection across $P_i^0$, then $f$ is symmetric across $R_i^0(P_j^1)$.
\end{remark}

\textit{Proof.}
By Remark \ref{r:reflections of reflections}, it is sufficient to produce a point $a'$ which satisfies \eqref{e:n=2 a' dist estimate} by a series of reflections of $a_0, a_1$. 

Note that since we are assuming $a_0 \not=a_1$ it cannot happen that for each $1\le j \le 2$ there exists a $1\le j'\le 2$ such that $P_j^0 = P_{j'}^1$. We argue by cases.

\textbf{Case 1:} Suppose that there exist $1 \le j, j' \le 2$ such that $P_{j}^0, P_{j'}^1$ are parallel and $P_j^0 \not = P_{j'}^1$.  Let $R_j^1$ be reflection across $P_{j}^1$, and let $a_2:= R_{j}^1(a_0)$. Note that $|a_2 - a_0| = 2\dist(a_0, P_{j'}^1)>0$.  Now, inductively define 
\begin{align*}
    P_0:= P_j^0, \quad P_1:= P_j^1, \qquad R_1:= R_j^0\\
    P_i = R_{i-1}(P_0) \quad \text{for all } i \ge 2,
\end{align*}
where $R_{i-1}:\mathbb{R}^n \rightarrow \mathbb{R}^n$ is reflection across $P_{i-1}$. Let $a_i = R_{i-1}(a_0)$.  Note that $|a_0 - a_i| \ge 2^i \dist(a_0, P^1_{j'})$ and $|a_1 - a_i| \ge (2^i-1) \dist(a_0, P^1_{j'})$.  Since $\dist(a_0, P^1_{j'})>0$, there must exist some $i \in \mathbb{N}$ such that the claim of the lemma hold.

\textbf{Case 2:} Assume that for all $1\le j, j'\le 2$, either $P_j^0, P_{j'}^1$ are not parallel or $P_j^0 = P_{j'}^1$.  Since $n=2$, the case $P_j^0 = P_{j'}^1$ is covered by Case 1. Thus, we may assume, after recalling that $a_0 \not = a_1$, that $P_j^0, P_{j'}^1$ are not parallel for each choice of $1\le j, j'\le 2$.  

\begin{wrapfigure}{r}{0.25\textwidth}   \label{f:1}\includegraphics[width=0.25\textwidth]{IMG_0097}
\end{wrapfigure}

Now, consider the collection of intersections 
\begin{align*}
    P^0_j \cap P_{j'}^1 \qquad \text{for }1 \le j, j' \le 2. 
\end{align*}
Note that there are two possibilities.  Either these points lie upon a right triangle or they form a non-convex quadrilateral with interior angles $\alpha, \alpha, \beta, \pi + \beta$, where $0<\alpha,\beta \le \pi/2$.  See the Figure on the right.  In the former case, the interior angles sum to $\pi$, and hence we may find an interior angle less than or equal to $\pi/4$.  In the latter case, the interior angles must sum to $2\pi$ and therefore $\min\{\alpha, \beta\} \le \pi/4$.   For any three points in $x, y, z \in \mathbb{R}^2$, we shall let $\angle(x, y, z) \in [0, \pi]$ denote the non-oriented angle formed by the line segments $\overline{xy}$ and $\overline{yz}$. 

By relabeling if necessary, we may assume that 
\begin{align*}
    \angle(a_0, P^0_1 \cap P_{1}^1, a_1) & = \alpha \le \pi/4\\
\dist(a_0, P^0_1 \cap P_{1}^1) & \ge \dist(a_1, P^0_1 \cap P_{1}^1).    
\end{align*}
Label $v_0 := P^0_1 \cap P_{1}^1$. Consider the non-degenerate triangle formed by the points $a_0, v_0, a_1$. The Law of Sines and the assumption that $\angle(a_0, v_0, a_1)= \alpha \le \pi/4$ implies $|a_0-a_1| \le |a_0- v_0|$.

Now we inductively define a finite sequence of points $\{a_i\}$ and planes $\{P^i\}$.  Beginning with $a_0, a_1$ as defined already, we let $P^1 := P_1^1$ and $R^1$ be reflection across $P^1$.  Then, define
\begin{align*}
    a_{i} := R^{i-1}(a_{i-1}) \qquad \text{and } P^{i} = R^{i-1}(P^{i-2})
\end{align*}
where $R^i$ is reflection across $P^i$.  Let $j_0 \in \mathbb{N}$ be the unique even integer such that $j_0\angle(a_0,v_0,a_{1}) \le \pi$ and $(j_0 + 2)\angle(a_{0},v_0,a_{1}) > \pi$.  Note that $\angle(a_0,v_0,a_{j_0}) > 2\pi/3$.  In particular, $|a_0- a_{j_0}| > \sqrt{3}|a_0- v_0| \ge \sqrt{3}|a_0-a_1|$. Moreover, since $\angle(a_0,v_0,a_{1}) \le \pi/4 \le \pi/3$ and $a_1 \not = v_0$ we have $|a_1 - a_{j_0}| > |a_0 - a_1|$. This proves the lemma. \qed

\begin{remark}\label{r:reflections nbhd}
    Note that in this construction, there is a neighborhood (depending upon $\{P_i\}, \{P_{i}'\}, |a_0-a_1|$) such that $B_r(a_0), B_r(a')$ are disjoint and $B_r(a')$ is the image of $B_r(a_0)$ under the reflections described in the lemma.  Naively, this neighborhood may be obtained by choosing $0<r$ such that $B_r(a_0) \cap P_1 = \emptyset$. But, under this choice if we fix $|a_0 - a_1|$ then $r \rightarrow 0$ as $\dist_{\mathcal{G}}(P^0_j, P^1_j) \rightarrow 0$.  However, if $q \in \mathbb{N}$ is such that 
    \begin{align*}
        2q \angle(a_0, v_0, a_1) \le \pi/4 \qquad 2(q+1) \angle(a_0, O, a_1) > \pi/4
    \end{align*} then, after we construct $\{a_i\}$ we may simply take $r$ such that $B_r(a_0) \cap P_{2q} = \emptyset$.  Since $B_r(a')$ is the image of $B_r(a_0)$ under reflections and $B_r(a_0) \cap B_r(a') = \emptyset$, this allows us to take $r= r(|a-a'|)$.  By scaling, we see that $r(\lambda t) = \lambda r(t)$ for all $0<\lambda<\infty$.
\end{remark}

\begin{lemma}[The General Case]\label{l:reflection arg}
Suppose that $n\ge 2$ and there exist two systems of orthogonal hyperplanes $\{P_i\}_{i=1}^n, \{P_i' \}_{i=1}^n$ in $\mathbb{R}^n$ and points $a_0, a_1 \in \mathbb{R}^n$ such that $a_0 = \cap_{i=1}^n P^0_i$, $a_1 = \cap_{i=1}^n P_i^1$, and $a_0 \not = a_1$.  If $f \in C^0(\mathbb{R}^n)$ is symmetric across $P_i^0, P_i^1$ for each $i=1,..., n$ then there exists another system of orthogonal hyperplanes $\{P_i''\}_{i=1}^n$ such that $a' = \cap_{i=1}^nP_i'$, $f$ is symmetric across each $P_i'$, and 
\begin{align*}
\max\{\dist(a', a_0), \dist(a', a_1)\} > \dist(a_0, a_1).
\end{align*}
\end{lemma}

\begin{proof}
As in the proof of Lemma \ref{l:reflection arg n=2}, by Remark \ref{r:reflections of reflections} the lemma will be proven if we can produce a point $a'$ as the image of a sequence of reflections of $a_0, a_1$ which satisfies the distance claim.

We argue inductively.  Lemma \ref{l:reflection arg n=2} proves the $n=2$ case.  Now, assume that the claim holds in $n\le N-1$ dimensions.  We argue that it holds in $n=N$.  We may break into cases, just as in Lemma \ref{l:reflection arg n=2}.  Note that Case 1, when we have parallel planes which are not identical, goes through verbatim.  Now, we consider Case 2.  In this case, by assumption for all $1\le j, j'\le N$ either $P_j^0, P_{j'}^1$ are not parallel or $P_j^0 = P_{j'}^1$. If there exists a pair of hyperplanes such that $P_j^0 = P_{j'}^1$, then we may reduce to the case $n=N-1$.  Therefore, it only remains to treat the case that $P_j^0, P_{j'}^1$ are not parallel for all $1\le j, j'\le N$.  

But, in this case we may consider any pair $P_j^0, P_{j'}^1$ and observe that the non-empty intersection $P_j^0 \cap P_{j'}^1$ is a $(N-2)$-dimensional affine subspace.  Therefore, collapsing $P_j^0 \cap P_{j'}^1$ by projection, we see that the proof of Lemma \ref{l:reflection arg n=2} gives us a procedure by which we may produce a point $a''$ such that 
\begin{align*} 
\min\{|\pi^\perp_{P_j^0 \cap P_{j'}^1}(a_0 -a'')|, |\pi^{\perp}_{P_j^0 \cap P_{j'}^1}(a_1 - a'')|\} > |\pi^{\perp}_{P_j^0 \cap P_{j'}^1}(a_0-a_1)|.
\end{align*}
Since under this procedure $|\pi_{P_j^0 \cap P_{j'}^1}(a_1 - a_{j_0})| = |\pi_{P_j^0 \cap P_{j'}^1}(a_1 - a_{0})|$, we conclude that (using the notation adopted in Lemma \ref{l:reflection arg n=2}, which may involve some relabeling) $|a_1-a_{j_0}| > |a_0-a_1|$ . This proves the lemma.
\end{proof}

\begin{remark}\label{r: nbhds remark 2}
    By identical considerations as those outlined in Remark \ref{r:reflections nbhd}, we note that there is a $1$-homogeneous function $R(t)$ such that $B_{R(|a_0 - a_1|)}(a_0), B_{R(|a_0 - a_1|)}(a_1)$ are disjoint, $B_{R(|a_0 - a_1|)}(a_1), B_{R(|a_0 - a_1|)}(a')$ are disjoint, and $B_{R(|a_0 - a_1|)}(a')$ is the image of $B_{R(|a_0 - a_1|)}(a_0)$ under a finite series of reflections. 

    If $|\pi_{P^0_j \cap P^1_{j'}}(a_0 - a_1)|\ge  |\pi^{\perp}_{P^0_j \cap P^1_{j'}}(a_0 - a_1)|$, we may take $r_1(|a_0 - a_1|) = |a_0 - a_1|/4$.  If, on the other hand, $|\pi_{P^0_j \cap P^1_{j'}}(a_0 - a_1)| \le  |\pi^{\perp}_{P^0_j \cap P^1_{j'}}(a_0 - a_1)|$ we may let $r_2(|a_0 - a_1|) = r(|a_0 - a_1|/2)$, where $r$ is the function described in Remark \ref{r:reflections nbhd}.  Thus, we may take $R(t) = \min\{r_1(t), r_2(t)\}$.
\end{remark}

\begin{lemma}\label{l:reflections break L1}
    Suppose that $f \in C^0(\mathbb{R}^n)$ is a positive function such that there exist two systems of orthogonal hyperplanes $\{P_i^0\}_{i=1}^n, \{P_i^1 \}_{i=1}^n$ and points $a_0 = \cap_{i=1}^n P_i^0$ and $a_1 = \cap_{i=1}^n P_i^1$ such that $a_0 \not = a_1$.  If $f$ is symmetric across $P_i^0, P_i^1$ for each $i=1,..., n$ then $f \not \in L^1$.
\end{lemma}

\begin{proof}
Let $Y$ be the set of all points $y \in \mathbb{R}^n$ such that $y$ is a ``center of symmetry" with corresponding system of hyperplanes and for which $$\int_{B_{R(|a_0 - a_1|)}(y)}fdx \ge \min \left\{\int_{B_{R(|a_0 - a_1|)}(a_0)}fdx, \int_{B_{R(|a_0 - a_1|)}(a_1)}fdx\right\}>0.$$ Note that by assumption $a_0, a_1 \in Y$.  If $Y$ is unbounded, then by choosing an appropriately-spaced, unbounded subset, the claim and the lemma follow immediately.  Therefore, assume for the sake of contradiction that $Y$ is bounded. In this case, there is a sequence of pairs $\{(x^1_k, x^2_k)\} \subset Y\times Y$ such that  
\begin{align*}
    \lim_{k \rightarrow \infty} |x^1_k - x^2_k| = \sup_{y, y' \in Y} |y' - y| = M < \infty.
\end{align*} By the precompactness of bounded sets in $\mathbb{R}^n$ and the compactness of the Grassmanian $G(n, n-1)$ there exist a pair of points $x^1_{\infty}, x^2_{\infty}$ each with corresponding system of hyperplanes $\{P^{1,\infty}_i\}_{i=1}^n, \{P^{2,\infty}_i\}_{i=1}^n$ such that 
\begin{align*}
    \lim_{k \rightarrow \infty}|x^1_k - x^1_{\infty}| =0, \qquad \lim_{k \rightarrow \infty} \dist_{\mathcal{G}}(P^{1, k}_i - P^{1, \infty}_i) =0 \quad \text{for all }i=1, ..., n, 
\end{align*}
and similarly for $x^{2}_{\infty}$, and $|x^1_\infty - x^2_\infty| = \diam(Y)$.

Let $R^{1, k}_i$ be reflection across $P^{1,k}_i$ for any $i \in \{1, ..., n \}$ and any $k \in \mathbb{N} \cup \{\infty\}$. Note that for any $z \not \in P_i^{1, \infty}$, $R_i^{1, \infty}(z) = \lim_{k \rightarrow \infty} R_i^{1, k}(z)$.  Thus, by continuity of $f$ we obtain that for all $z \not \in P_i^{1, \infty}$, $f(z) = f(R_i^{1, \infty}(z))$.  In other words, $f$ is symmetric across $P_i^{1, \infty}$ for each $i \in \{1, ..., n \}$.  Identical statements hold for $P_i^{2, \infty}$ and $x^2_\infty$. Therefore, applying Lemma \ref{l:reflection arg} to the pair $x^1_{\infty}, x^2_{\infty}$ we obtain a new point $x'$ with $\max\{|x^1_{\infty}-x'|, |x^2_{\infty}- x'|\} > \diam(Y)$.  

Now, consider $\int_{B_{R(|a_0 - a_1|)}(x')}fdx$.  Since $x'$ is obtained by a finite sequence of reflections and $|a_0 -a_1|< \diam(Y)$, Remark \ref{r: nbhds remark 2} implies that $\int_{B_{R(|a_0 - a_1|)}(x')}fdx = \int_{B_{R(|a_0 - a_1|)}(x_{\infty})}fdx$.  Additionally, the fact that $f$ is continuous, $x^1_k \rightarrow x^1_{\infty}$, and $x^1_k \in Y$ implies that
\begin{align*}
    \int_{B_{R(|a_0 - a_1|)}(x^1_{\infty})}fdx \ge \min \left\{\int_{B_{R(|a_0 - a_1|)}(a_0)}fdx, \int_{B_{R(|a_0 - a_1|)}(a_1)}fdx\right\},
\end{align*}
with a symmetric statement for $x^2_{\infty}$. Thus, in particular, $x' \in Y$. But this contradicts $|x^1_\infty - x^2_\infty| = \diam(Y)$.  Thus, $Y$ must be unbounded, which gives the claim and the lemma.
\end{proof}


\section{Appendix B: An Example in One Dimension}

As mentioned in the introduction, Theorem \ref{t:main theorem 2} only works in dimensions $n \ge 2$.  Below, we construct a PS measure in $1$-dimension which not even log-concave.  We note that this example actually works (with only slightly modified proof) if we only assume $g \in L^{\infty}$ with the sale bounds and use the $\varepsilon$-enlargement definition of perimeter.

\begin{example}[An Example in $\mathbb{R}$]\label{ex:1}
Let $g \in C(\mathbb{R})$ be any function satisfying 
\begin{enumerate}
    \item $|g|_{\infty} \le 1$.
    \item $g(x)= g(-x)$ for all $x \in \mathbb{R}$.
\end{enumerate} 
Let $\mu \in \mathcal{M}(\mathbb{R})$ be defined by $d\mu = f dx$, where the distribution function $f$ is defined by
\begin{align*}
    f(x) = \begin{cases}
    g(x) + 5 & |x| \le 1\\
    0& \text{ otherwise.}
    \end{cases}
\end{align*}
Then sets of the form $[a, \infty)$ are minimal for $\mu$-perimeter among all sets $E$ with $\mu(E) = \mu([a,\infty))$. 
\end{example}

\begin{proof}
Our proof roughly follows \cite{Bobkov96} Lemma 3.2.  Let $\mathscr{I}_{m, \alpha}$ be the collection of sets $A' = \cup_{i=1}^m [a_i, b_i]$ which are the union of $m$ disjoint intervals such that $\mu(A') = \alpha$ and $\{[a_i, b_i]^h\}_i$ are pairwise disjoint.

By approximation, it suffices to show that if $x \in [-1, 1]$ is such that $\mu([-1, x]) = \alpha$ then $[-1, x]$  is $\mu$-perimeter minimizing all sets in $\mathscr{I}_{k, \alpha}$ for all $k \in \mathbb{N}$.

\textit{Base Step:} Let $m=1$.  Suppose that $A' \in \mathscr{I}_{1, \alpha}$.  Note that by the symmetry of $g$ and continuity of measures, there exists a unique $a \in \mathbb{R}$ such that $\mu([-1, a]) = \alpha = \mu([-a, 1])$.   Now, let $A' \in \mathscr{I}_{1, \alpha}$ be any set which is not $[-1, a]$ or $[-a, 1]$. Note that in this case $\operatorname{Per}_{\mu}(A') \ge 8$, whereas $\operatorname{Per}_{\mu}([-1, a]) \le 6$. 

\textit{Inductive Step:} Now, assume that $[-1, a]$ and $[-a, 1]$ are $\mu$-perimeter minimizers among all $A' \in \mathscr{I}_{m, \alpha}$ for all $1 \le m \le n$. Let $A'' \in \mathscr{I}_{n+1, \alpha}$.  Let us label the $n+1$ intervals of $A''$ by $\Delta_i = [a_i, b_i]$ for $i=1, ..., n+1$, ordered by the natural order on $\mathbb{R}$. Define a perturbation of $\Delta_1$, $\Delta_2$ by $\Delta_i(t) = [a_i(t), b_i(t)]$ such that 
\begin{align*}
    a_i(t) & = a_i - t\\
    b_i(t) & \text{ defined so that } \mu(\Delta_i(t)) = \mu(\Delta_i).
\end{align*}
There are two possibilities.  Either $a_1(t_1)= -1$ occurs first, in which case, we stop shifting $\Delta_1(t_1)$ and continue to shift $\Delta_2$ until it runs into $\Delta_1(t_1)$.  Or,  there is a $t_2$ such that $a_2(t_2) = b_1(t_2)$ occurs first, in which case we shift the combined interval $[a_1(t_2), b_2(t_2)]$ as above until it runs into $-1$.  In either case, we obtain an interval $[-1, x]$ such that $\mu([-1, x]) = \mu(\Delta_1\cup \Delta_2)$.  Observe that $\operatorname{Per}_{\mu}([-1, x]) \le 6$ and $\operatorname{Per}_{\mu}(\Delta_1 \cup \Delta_2) \ge 8$. Thus, the resulting set $[-1, x] \cup \Delta_3 \cup ... \cup \Delta_n$ has strictly smaller $\mu$-perimeter and is in $\mathscr{I}_{n, \alpha}$. By induction, then, the claim holds.  
\end{proof}


\bibliography{references}
\bibliographystyle{amsalpha}

\end{document} 
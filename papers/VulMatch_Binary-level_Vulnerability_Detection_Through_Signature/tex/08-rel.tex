\section{Related Work}
\label{sec:related}
We present the related work from the following threefold since they are closely related to this work: 1) code similarity detection, 2) patch analysis, and 3) vulnerability detection. 


\subsection{Code Similarity Detection}

\subsubsection{Binary-code-level similarity detection} 

Binary-code-level similarity works are categorized in two directions according to their methods.


\mypara{Learning-based methods} Binary code instructions are encoded into an embedding to compare the similarity. 
Gemini \cite{gemini}, Vulseeker \cite{VULSEEKER}, and Genius \cite{genius} use graph feature embeddings to determine vector similarity. 
Safe \cite{safe}, InnerEye \cite{innereye}, $\alpha$Diff \cite{aDiff}, Kam1n0 \cite{Kam1n0}, and Asm2Vec \cite{asm2vec} learn the instructions' embeddings and generate block embeddings or function embeddings. 


\mypara{Program-analysis based methods}
Instructions or blocks are regarded as sequences in Binsequence~\cite{binsequence} and Tracy~\cite{tracy} using sequences-alignment methods to compare the similarity.
Similarly, SIGMA~\cite{SIGMA}, FOSSIL~\cite{fossil}, and Beagle~\cite{BEAGLE} rely on the instruction semantic categorizations like data transfer, logic, or arithmetic. 
Bingo~\cite{bingo} and IMF-SIM~\cite{IMF-SIM} use input-output relations to measure binary code similarity. 
Expose~\cite{Expose}, Binhash~\cite{binhash}, Binhunt~\cite{binhunt}, CoP~\cite{COP}, ESH~\cite{esh}, GITZ~\cite{GITZ}, and XMATCH~\cite{xmatch} symbolically execute the binary code before the similarity comparison based on symbolic formulas. 


\mypara{Limitations} 
However, similarity-based methods match the whole function similarity. 
Vulnerable instructions only involve several lines of code in the function. 
Therefore, the similarity-based method can filter similar functions but cannot distinguish whether the function is vulnerable.

%Cesare et al.~\cite{cxz2014}, 
%SMIT~\cite{SMIT}, and Binslayer~\cite{binslayer} use the techniques of deciding the optimization solutions to find the mapping between two CFGs with minimum cost. 
%Ceasare et al.~\cite{cxz2014}, rendezous~\cite{rendezvous}, Beagle~\cite{BEAGLE}, and FOSSILE~\cite{fossil} use $k$ subgraphs matching methods. 
%Binsequence~\cite{binsequence}, SIGMA\cite{SIGMA}, and CoP~\cite{COP} use path similarity to decide the binary code similarity. 

%QBinDiff~\cite{qbindiff} combines network alignment methods and graph edit distance to decide graph features similarity.


%Binhunt~\cite{binhunt} uses a theorem prover to determine symbolic formulas similarity. 
%Binhash~\cite{binhash}, GITZ~\cite{GITZ}, and Binjuice~\cite{binjuice} hashes the symbolic formula to decide equivalence. 
%TEDEM~\cite{tedem} and XMATCH~\cite{xmatch} represents symbolic formula into tree/graph format and calculates the edit distances.

%\mypara{Source-code-level similarity detection} According to Novak et al.~\cite{source_survey}, source-code-leve similarity detection works are categorized based on the algorithms they use. 
%\cite{attr1,attr2} use Attribute Counting algorithm.  
%\cite{finger1, finger2, finger3} use fingerprint-based algorithm. 
%\cite{string1, string2, string3} match strings. 
%\cite{text1, text2} utilize text-based algorithm. \cite{structure1, structure2, structure3, structure4} use structure-based methods. 
%\cite{stylistic1, stylistic2, stylistic3} compares stylistic information. 
%\cite{attr2, semantic1} use semantic-based algorithm. 
%\cite{string1, text1, finger3} are nGram-based methods. 
%\cite{tree1, tree2, tree3, tree4} are tree-based methods. 
%\cite{structure3, graph1} are graph-based methods.  
%\cite{cluster1, cluster2, cluster3} are cluster-based methods. 
%Our work is still at binary-code-detection-level even we utilize some source code information. 
%Generally, binary-level detection is more challenging because binaries will change for different factors, including compiler versions, types, settings, architectures, and program updates. 

\subsection{Patch Identification and Analysis}
FIBER \cite{fiber} detects patch existence in Linux kernel binaries based on symbolic execution. 
Using symbolic execution and memory status, PDiff \cite{pdiff} detects Linux kernel binaries' patch existence when binaries are different due to patch customization, different build configuration, and other reasons.
Spain \cite{spain} uses binary-level semantic information to identify the patch before summarizing patch and vulnerability patterns. 
Patchscope \cite{patchscope} identifies patch existence based on memory-object-centric methods and dynamic execution.


\mypara{Limitations} 
This category of prior work assumes that the function names are provided or that some similar candidate functions have already been selected by the code-similarity-based method. 
Moreover, they focus on patch detection rather than vulnerability detection. 
The lack of a patch does not necessarily imply that the function is vulnerable.


\subsection{Vulnerability Detection}
VMPBL \cite{vmpbl} builds a database storing vulnerable and patched functions to distinguish the pre-patch and post-patched functions. 
VIVA \cite{viva} collects binary with versions before and after the patch and directly diff the pre-patch and post-patch functions to retrieve binary-level vulnerability signatures. 
VIVA further detects vulnerability existence based on pre-filtering and instruction clustering. 
BINXRAY \cite{binxray} requires pre-patch and post-patch version binaries to analyze the vulnerability-related instructions in both versions before storing instructions in the database as vulnerability and patch signatures. 
BINXRAY checks the vulnerability's existence in a query function based on its closest signature version.

\mypara{Limitations} 
This genre of work is most similar to our methods. 
However, they assume all the different binary codes between versions are related to the vulnerability, this often introduces many vulnerability-irrelevant instructions into signatures.
\section{Introduction}
\label{sec:intro}

Finding vulnerabilities or bugs in software is vital to improve its quality. 
Vulnerabilities and bugs tend to inherit in new software products due to the sluggishness of making up-to-date patches. 
A vulnerability detection paradigm is learning from existing vulnerable codes to find similar vulnerabilities and bugs. 
Human security analysts can learn from hundreds or thousands of existing vulnerabilities to gain experience and improve security awareness to manually find vulnerabilities or bugs by reviewing the code \cite{heffley2004can}. 
However, with an extremely large number of codes to review, there is an urgent call for automated methods to identify vulnerability codes directly or filter out potentially vulnerable codes for human experts to review later. 
Moreover, automatic vulnerability detection is in high demand due to replicated vulnerabilities spread by code reuse as a common practice in the software industry \cite{code_reuse,haefliger2008code}. 
Detecting the 1-day or N-day vulnerabilities in binary code is vital because of the unavailability of source code in many real-world scenarios.
This paper's research question is \textit{how to effectively and efficiently find similar vulnerabilities or bugs from existing ones}. 


Automated detection methods have great advantages over manual analysis because binary code is notoriously difficult for humans to read and understand.  
Mainstream research consists of three genres: binary code similarity detection, patch existence detection, and vulnerability signature detection. 
\begin{itemize}
 \item \textbf{Binary Code Similarity Detection.} 
 Given a set of query binary samples, code similarity detection tools \cite{spain, BINCLONE, SMIT, Kam1n0, MBC, IDEA, Expose, binsequence, tracy, exediff, genius, binslayer, cxz2014, rendezvous, BEAGLE, fossil, SIGMA, COP, gemini, VULSEEKER, qbindiff, safe, innereye, aDiff, asm2vec, multimh, binhash, ks2017, bingo, IMF-SIM, binhunt, esh, GITZ, binjuice, tedem, xmatch} identify the best matching code snippets stored in the database with known vulnerable binary codes. 
 % This genre of work finds similar codes using various techniques, including machine learning, symbolic execution, dynamic execution, and many more.  
 Code similarity-based vulnerability detection finds vulnerable binary code but introduces excessive false positives because patched binary codes usually have high similarity scores. 
 Furthermore, the similarity-based method is coarse-grained. They only output similar binary snippets at a large scale (e.g., function level). Since the function level binary code is usually large in scale and the vulnerability commonly only relates to several instructions, they can not explain specifically what instructions indicate the vulnerability.

 \item\textbf{Patch Existence Detection.} This genre of work \cite{fiber, pdiff, spain, patchscope} determines whether a patch exists in a query binary function. 
 This genre of work extracts patch code signatures and detects the existence of patch signatures in the query function. 
 However, it usually targets kernel binaries with debugging symbols like function names that are used to filter the query function and detect patch signatures. 
 % The binaries without debug information need to rely on orthogonal binary code similarity detection to filter out the function. 
 Moreover, this genre of work fails to address the existence of vulnerability because the lack of patches does not equal the vulnerability's existence. 
 In the National Vulnerability Database (NVD), some Common Vulnerabilities and Exposures (CVEs) are vulnerable from some versions in a series, suggesting that the versions before the consecutive vulnerable versions do not contain patched code. 
 For instance, a project contains ten versions, but the versions between the third and the sixth are vulnerable, so its first two versions are not considered vulnerable because of the absence of patches.  

 \item\textbf{Vulnerability Signature Detection.} This genre of work \cite{vmpbl, viva, binxray} detects fine-grained vulnerability-related signatures in the binary code. 
 Existing works extract different instructions between two binary reference versions (i.e., a vulnerable version and a patched version). 
 Then they normalize the instructions and generate traces (i.e., blocks of normalized instructions) to form the vulnerability or patch signature. 
 However, extracting signatures directly at the binary level could introduce instructions irrelevant to vulnerabilities because the compiler replaces instructions with the same semantic and inlines functions. 
 For example, the source code line \texttt{bool fromfile=FALSE;} could be compiled to \texttt{mov [rsp+48h+var\_39], 0} in one version and \texttt{xor r14d, r14d} in other versions even using the same optimization flags (options). 
 The same variable is stored on the stack in the former version and the register \texttt{r14d} in the latter version. 
 If two versions inline another non-vulnerable function, and the inlined function has changed in the patched version, directly diffing the binary codes will include the changed instruction in the inlined function. 
 We reproduced the methods to understand such inaccurate cases and manually analyzed the corresponding output binary signatures. 
 We found that their methods introduce approximately 40\% vulnerability-irrelevant instructions into the signatures.
\end{itemize}



We propose a novel approach to generate accurate and fine-grained vulnerability-related signatures to address those research gaps. 
Firstly, we spend significant manual efforts pre-processing the data to include all the CVEs' information, each vulnerable function, the source code file it lies in, the affected versions, and the corresponding source code versions. 
To generate accurate and fine-grained binary code signatures, we generate source-code-level signatures and align them to binary-level signatures with the help of debugging information. 
Unlike existing work \cite{vmpbl,viva, binxray} that directly diff different binary versions to extract vulnerability signatures, we utilize source code to guide us to locate vulnerable binary code more accurately. 
Hence, we exclude many vulnerability-irrelevant binary code contents. 
To utilize non-trivial source-code information, \name processes the source code to prevent vulnerable functions from being inlined.
\name locates binaries from source code by handling different situations as described in \autoref{sec:Vulnerability and patch signature generation}. 
Note that the source code is only required for generating the signature and not for matching a given binary.
\name aims to find vulnerabilities in the query binary, which should not contain any debugging information and source code. 
We combine the information of source code, binary code, and debugging information to generate (learn) the signature accurately.
To match the binary-level signatures, we propose three signature types (i.e., add, delete, and change). 
To match the existence of fine-grained binary signatures rather than the whole-function-level similarity as the similarity-based genre, we create the binary signature with local control-flow information. 
The local control-flow information refers to the context instructions. It enriches the signature with unique features.  
To assist humans in understanding the decision made by \name, a user interface interpreting the matched binary signatures shows the matched signatures and the match score in the binary.



To evaluate the utility of \name, we prepared seven popular open-source projects with well-documented vulnerability information. 
In total, there are 906 CVEs, including 1281 vulnerable functions.
Our results demonstrate that \name outperforms two state-of-the-art vulnerability detecting tools --- Asm2vec and Palmtree by approximately 9\% and 6\% more top-1 score, 80\% and 79\% less mismatch score, respectively.
We also demonstrate how \name assists humans in understanding its detection results in terms of interpretability. We experiment with commercial firmware to demonstrate \name is practical to find real-world vulnerabilities.
We perform in-depth research on the vulnerability and signature types and their distribution in the dataset.

This paper makes the following contributions:
\begin{itemize}
  \item We propose a novel approach to extract, store, and match the vulnerability-related signatures. 
  We have implemented the approach into a tool called \name that is open-source and publicly accessible on GitHub \footnote{{The source code is uploaded to Code Ocean as required}}.
  \item To facilitate the human to understand \name's results and the reason \name decides whether the query binary contains vulnerability or not, we provide interpretability functionality in \name.
  \item We perform in-depth analysis on vulnerability and signature types and their distribution across all datasets. 
  We inspect each dataset's top three vulnerability types and different signature types with the average signature size.
\end{itemize}

%The rest of this paper is organized as follows: In \autoref{sec:mot}, we present a motivating example to demonstrate our approach overview. 
%In \autoref{sec:methdlg} we describe the detailed steps of our approach. 
%In \autoref{sec:eval}, we compare \name with two state-of-the-art vulnerability detection tools. 
%We investigate the interpretability of \name. We test the ability of \name to find real-world vulnerabilities in firmware.
%We analyze the distribution of different vulnerability and signature types. 
%In \autoref{sec:dis} we discuss the limitation and future direction.
%In \autoref{sec:related} we present related works. 
%This paper is concluded in \autoref{sec:ccln}. 

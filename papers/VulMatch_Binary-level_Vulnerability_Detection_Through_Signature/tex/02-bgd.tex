\section{A Motivating Example}
\label{sec:mot}

\mypara{Terms definition} \textbf{Block} refers to a set of consecutive binary (assembly) instructions split by the control-flow-related instructions (e.g., jump instructions). 
An assembly function consists of various blocks connected to each other. 
Blocks are connected together to represent the assembly code's control-flow graph (CFG), as shown in \autoref{fig:mot}. 
Note that in this paper, we will use the terms `binary code' and `assembly code' interchangeably. 
\textbf{CVE} refers to the vulnerability in the function. 
One CVE may correspond to multiple vulnerability-related instructions and multiple signatures.

\begin{figure}[!t]
\centering
\includegraphics[width=0.47\textwidth]{graphs/motivate1.pdf}
\caption{An example vulnerable function \texttt{tftp\_connect} selected from CVE-2019-5482. (a) lists pre-patch source code, and (b) lists post-patch source code. Green lines are the patched source lines. Other lines remain intact across the two versions.}
\label{fig:mot1}
\end{figure}

\begin{figure}[!ht]
\centering
\includegraphics[width=0.35\textwidth]{graphs/motivate.pdf}
\caption{Corresponding binary code CFG of function \texttt{tftp\_connect} presented in \autoref{fig:mot1}. (a) refers to pre-patch version, and (b) refers to post-patch version. Block 1' is a modified block and blocks 3', 4', 5', and 6' are added blocks. Other blocks remain intact.}
\label{fig:mot}
\end{figure}



\autoref{fig:mot1} shows the source code snippets of the vulnerable function \texttt{tftp\_connect} from CVE-2019-5482 before and after the patch, where green lines are the patched instructions. 
\autoref{fig:mot} shows the corresponding binary code structure.
\autoref{fig:mot}(a) is the vulnerable version (before patch), and \autoref{fig:mot}(b) is the patched version. 
The binary code samples were built from the source code snippets using an identical compilation configuration with additional debugging information. 
Since the patch in the example comprises two kinds of changes through added and modified instructions, they are listed using different colors. 
Specifically, block 1' is a modified block of instructions, and blocks 3', 4', 5', and 6' are added blocks of instructions. 
Other blocks remain intact. 


 
Similarity-based lines of work compare the whole functions' similarities before identifying a potentially vulnerable function if the function is similar to the vulnerable function. 
They focus on the whole function similarity rather than vulnerability-related instructions, resulting in poor granularity. 
Furthermore, they fail to distinguish the vulnerable and the patched functions since they are regarded as similar. 
Patch-detection lines of work first use the similarity lines of work to filter potential similar functions. 
They assume to select a similar function by name to detect the existence of the patch, where the binaries are Linux kernel binaries. 
However, as mentioned in \autoref{sec:intro}, if the patch does not exist, it does not necessarily mean that the binary is vulnerable. 
Existing binary signature-based methods directly diff the vulnerable and the patched binary versions and assume the different binary instructions are all vulnerability-relevant. 
However, we reproduced their methods with a manual analysis of the results and found that up to 40\% vulnerability-irrelevant instructions were included.


After manually inspecting the source code snippets and the corresponding binary samples, we found that only blocks 3' and 6' are the actual patched blocks corresponding to green lines in \autoref{fig:mot1}. 
Other changed blocks (i.e., blocks 1', 4', and 5') are not aligned with any changed source lines, but they map to the unchanged source code lines.
The changes in blocks 1', 4', and 5' were due to replacing instructions with the same semantics, which is the indirect impact of the patched instructions. 
Existing work in \cite{vmpbl, binxray, viva} failed to identify these blocks as unchanged code.
To rectify this issue, \name generates and matches the vulnerable signature with the guidance of the source code. 
We introduce the three steps of \name as follows:


\mypara{Step1: Locating Signature Instructions.}
We use the \texttt{diff} tool to measure source-code-level differences. 
Diff can detect and output a list of changed sites, added sites, and deleted sites. 
In the example shown in \autoref{fig:mot}, diff scans the source code in \autoref{fig:mot1} and outputs one added site. 
Subsequently, we use the debugging information in the binary code (i.e., the source-binary lines mapping) to locate the patched binary lines. 
In the diff's output, the changed site contains the source code lines in both pre-patching and post-patching versions. 
However, the diff output for add site only contains the added source lines in the post-patching version (e.g., green lines in \autoref{fig:mot1} (b)). 
Since the added instructions do not exist in the pre-patching version, diff has no outputs for the pre-patching version.
Therefore, for add type signature, an additional process will take place later in step 2 to find vulnerability-related instructions in the pre-patch version. 
%Based on the located vulnerability-related source code lines, we further map them into binary instructions.
%Therefore, we have the changed binary lines in both versions but only have added binary lines for the patched version.

\begin{figure*}[!t]
\centering
\includegraphics[width=\textwidth]{graphs/methodology.pdf}
\caption{\name consists of four steps: Data Preparation, Locating Signature
Instructions, Constructing Context-aware
Binary-level Signatures, and Signature Matching. \textit{Src} is short for source code. \textit{Bin} is short for binary code. \textit{Insn} is short for instruction.} 
\label{fig:methodology}
\end{figure*}


\mypara{Step2: Constructing Binary-level Signatures.} 
%The inserted lines in the source code are mapped to the binary instructions in the patched binary code. 
In this step, we use the located binary instructions in step 1 to construct the binary signatures. We store both vulnerable and patched signatures in the database.
%In this example, the vulnerable signature is generated from the modified instructions in block 1 in a database as a  and store the changed instructions in block 1' in the database as the patch signature.
%Now we introduce why and how we address the added signature. 
For the added signature, we still need to generate its vulnerable binary signature even if diff outputs nothing at the source-code level. 
We cannot directly consider the absence of the added (patched) instructions to imply vulnerability because another random function does not necessarily have the added (patched) instructions. 
The random function needs to be not vulnerable. 
%We cannot use them to detect the absence of these instructions because the added instructions only implies the existence of a patch rather than vulnerability. 
%However, it does not imply that the random function is vulnerable because the random function also does not have the vulnerable code. 

Therefore, we need to use the vulnerability-related instructions in \autoref{fig:mot}(a) to construct a vulnerability signature. 
Note that the added instructions are inserted between block 2 and block 7. 
Therefore, in the vulnerable version \autoref{fig:mot}(a), the control flow from block 2 to block 7 implies the vulnerability. 
In the patched version \autoref{fig:mot}(b), the control flow from block 2' to block 3' and from block 3' to block 6' implies patch existence.  
Therefore, we store the control flow from block 2 to block 7 as the vulnerable signature. 
Additionally, we store the control flow from block 2' to block 3' as the patch signature.


\mypara{Step3: Matching Signatures.}
For a query (unknown) binary, we check whether the vulnerability is related to CVE-2019-5482 stored in the database. 
If we store multiple signatures in the database for one CVE, we will check each signature and aggregate an overall score. 
For the changed or deleted signatures, we detect the percentage of the matched vulnerability instructions with respect to the query binary.
For example, if the changed signature block contains 5 instructions and 3 of them exist in some block in the query function, then the score of the changed signature is 3/5=0.6. 
For the added signature, we check the existence of the control flow (e.g., the stored control flow from block 2 to block 7 in \autoref{fig:mot}(a)). 
We count how many matched instructions exist in the query function for each control flow. 
If there are 10 instructions in blocks 2 and 7, and we found a similar control flow in the query function with 8 instructions matched, then the score is 8/10=0.8. 
However, if we detect the existence of the patch signature in the query function, we directly consider the query function contains a patch and output that signature score as 0. 
Finally, we average all the signature scores according to their weights (instruction sizes) to derive the overall score.


To summarise, the input of our proposed method to produce the vulnerable binary signatures are: 1) CVE information, including the last vulnerable version, first patched version, and vulnerable function name. 2) Source code with different versions. 
Then, in the query phase, the input could be an unknown binary code without debugging information and source code. 
The output is a list of potentially matched CVEs with the similarity score. 
Compared to existing methods, \name yields more accurate binary signatures with less vulnerability-irrelevant instructions. \name is able to accurately predict the vulnerable sites in the query binary rather than only giving a similar code. \name is able to accurately match the real vulnerable binary code with fewer false positives among several similar binary code snippets.


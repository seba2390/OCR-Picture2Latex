We sincerely thank all reviewers for their valuable comments. We will provide a general and detailed reply to the concerns

## Response to Reviewer #1

Q1:Is the premise convincible and do we assume we cannot train on the deployment vendor/infrastructure?
A1: (1)The result in Table 2 shows that the results obtained by different libraries may look the same to human eyes, but they do have slightly different and can cause the accuracy drop of DNN.
(2)In practice, we usually train our model on x86 platform using PyTorch or TensorFlow framework, and for practical application, have to deploy this model on different lightweight platforms (such as phones) after model adaptation. In this case, it is difficult to match the implementation details of training and deployment because of software and constraints of deploying hardware.
(3)Due to software development and hardware limitations, some deployment platforms do not provide a model training process. Because most deployment platforms pay more attention to lightweight and fast model inference. So we can assume that sometimes we cannot train on the deployment vendor.

Q2:Other work on robustness against quantization changes.
A2:Thanks for the advice! We will add this in the revision.

Q3:What are the pre-processing steps for the natural language tasks?
A3:There are two pre-processing steps for the OPT language model:
(1)Lowercasing: Converting all text to lowercase can help reduce the number of unique tokens in the dataset.
(2)Tokenization: This step involves breaking the text into individual words or tokens. 

Q4:Algorithm 1...Or are there settings, where we want to be robust to multiple unknown deployment configurations and the cost of re-training is too high?
A4:Yes. Sometimes we cannot predict what kind of noise will encounter during deployment, or this noise during deployment cannot be reproduced during the training process because of hardware limitations. Mix training may relieve the problem. We will clarify this in the revision.

## Response to Reviewer #2

Q1:How frequently do the system-level differences occur in real-world ML pipelines?
A1:According to the actual situation of my colleagues and I, we added information about the frequency in Table 1 (https://www.linkpicture.com/q/table1_2.png). It is divided into three levels--medium, high, and very high. We are also making a survey to count the actual frequency. The final result will be in the revision.

Q2:Can you quantify the actual divergence instead of just the accuracy drop?
A2:Inspired by previous work, we use the cosine similarity of two images/feature maps as a new metric to quantify the actual divergence. The cosine similarity of images can measure the divergence caused by the noise directly and the cosine similarity of the model's last layer feature maps can measure the divergence after the influence of DNN. The final result will be provided in the revision due to time constraints.

Q3:Can you discuss the related work mentioned in my review?
A3:(1)In [1], they test the model instability on 5 kinds of phones and show their different results. And they introduce some mitigation strategies for instability. In my point of view, they mainly focus on the pre-processing noise on the specified device while we focus on the whole processing of model inference. And they experiment with noise macroscopically. For example, they mentioned the ISP as one kind of noise source, and it may include decoding, resizing, and color conversion operations mentioned in our work. Moreover, the mitigation strategies in [1] may be useful for us. We will carry out experiments and analyze the results.
(2)Work [2] does not study the impact of quantization but studies the impact of quantization models when they are attacked by adversarial noise. It inspires that system noise not only reduces the accuracy of the model but also reduces the robustness of the model in the face of natural and adversarial noise. We will cite and discuss these papers in the final revision.

[1]Characterizing and Taming Model Instability Across Edge Devices
[2]A Tale of Two Models: Constructing Evasive Attacks on Edge Models.

Q4:Other detailed comments
A4:Thank you for your thoughtful and constructive comments. We have carefully read those comments and will improve upon them.

## Response to Reviewer #3

Q1:SysNoise in other fields such as speech/audio processing
A1:Thank you for your constructive comments. We are interested in exploring the impact of system noise on more tasks and extending our models and benchmarks. We will try to explore system noise in speech and audio fields and add the results in the revision.

Q2:Related work
A2:(1)The noise in our work is coming from different training and deployment hardware/software, while the noise in [1] is coming from different training hardware and setup. So we focus on the inconsistency between training and deployment and [1] focus on the inconsistency inside the training process. We will cite and discuss this paper in the final revision
(2)Work [2] introduces a test-time adaptation method and shows it can improve the model's performance on natural noise. We have started experiments with this method on our model and dataset to find out whether it can improve the model's robustness against system noise. We will add the results and analysis in the revision.

[1]Randomness in Neural Network Training: Characterizing the Impact of Tooling
[2]Tent: Fully Test-time Adaptation by Entropy Minimization

## Response to Reviewer #4

Q1:Lack of novelty.
A1:(1)Works [1], [2] and [3] mainly focus on the influence of pre-processing noise on image classification task. In contrast, our work more comprehensively analyzes the noise in the whole process of model deployment including pre-processing, model inference and post-process on 4 different CV and NLP tasks. 
(2)Our work shows and analyzes the impact of multiple system noises and how commonly used robustness improvements make an effect on system noise. These contents are not included in the previous work.
(3)We will cite and discuss these papers in final revision.

Q2:What is the bonding of these noises?
A2:(1)In real-world ML pipelines, engineers may face issues deploying models on different hardware. In this case, system noise will occur in different stages together because of the difference between hardware and software during the whole model inference process. These noises will be Combined and cause a drop in accuracy together.
(2)The combined system noise is more like the actual situation than the single system noise. It can reveal the corruption of the model by system noise in real practice. We can also find how system noise adds up and interacts with each other by combined system noise, which may help to selectively remove some excessive noise in practice.

Q3:Data analysis problem.
A3:Very happy to see that you enjoyed our section on multiple system noises and made sound suggestions for the part of the analysis. We will improve our wording about this part. And experiments with more system noise combination types are carried out to analyze it more deeply. We will add the results and analysis in the revision.

Q4:Lack of comparison with SOTA works. 
A4:(1)The comparison we choose is now the most commonly used method in machine learning frameworks. The results obtained in this way can better reflect the actual situation in real ML pipelines.
(2)We compare some SOTA works in data augmentation and adversarial training which can help to improve model robustness in Sec.4.3.
(3)Thank you for providing us with some new solutions for some noises in Sysnoise. We will test and analyze these methods across our model in the revision.

Q5:What is the baseline?
A5:We declare our baseline in Sec.4.1. We train all the baseline models following the setting mentioned in Sec.4.1. and strictly control variables when doing the model inference process. We will explain this more explicitly.

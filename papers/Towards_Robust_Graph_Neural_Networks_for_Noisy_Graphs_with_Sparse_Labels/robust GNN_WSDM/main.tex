\documentclass[sigconf]{acmart}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{multirow}
\usepackage{tabularx}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{subcaption}
\usepackage{amsthm}
\usepackage{enumitem}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\newcolumntype{C}{>{\centering\arraybackslash}X} % centered version of 'X' col. type

\newcommand{\suhang}[1]{\textcolor{blue}{#1}}
\newcommand{\wei}[1]{\textcolor{orange}{#1}}

\copyrightyear{2022}
\acmYear{2022}
\setcopyright{acmcopyright}\acmConference[WSDM '22]{Proceedings of the Fifteenth
ACM International Conference on Web Search and Data Mining}{February 21--25,
2022}{Tempe, AZ, USA}
\acmBooktitle{Proceedings of the Fifteenth ACM International Conference on Web
Search and Data Mining (WSDM '22), February 21--25, 2022, Tempe, AZ, USA}
\acmPrice{15.00}
\acmDOI{10.1145/3488560.3498408}
\acmISBN{978-1-4503-9132-0/22/02}

\title{Towards Robust Graph Neural Networks for Noisy Graphs with Sparse Labels}

\author{Enyan Dai$^\dagger$, Wei Jin$^\ddagger$, Hui Liu$^\ddagger$, Suhang Wang$^\dagger$ }

\affiliation{$\dagger$ The Pennsylvania State University,
{${\ddagger}$} Michigan State University%\\
}

\email{{emd5759, szw494}@psu.edu, {jinwei2, liuhui7}@msu.edu}
\settopmatter{printacmref=True}


\begin{document}
\fancyhead{}
\begin{abstract}
Graph Neural Networks (GNNs) have shown their great ability in modeling graph structured data. However, real-world graphs usually contain structure noises and have limited labeled nodes. The performance of GNNs would drop significantly when trained on such graphs, which hinders the adoption of GNNs on many applications. Thus, it is important to develop noise-resistant GNNs with limited labeled nodes. However, the work on this is rather limited. Therefore, we study a novel problem of developing robust GNNs on noisy graphs with limited labeled nodes. Our analysis shows that both the noisy edges and limited labeled nodes could harm the message-passing mechanism of GNNs. To mitigate these issues, we propose a novel framework which adopts the noisy edges as supervision to learn a denoised and dense graph, which can down-weight or eliminate noisy edges and facilitate message passing of GNNs to alleviate the issue of limited labeled nodes. The generated edges are further used to 
regularize the predictions of unlabeled nodes with label smoothness to better train GNNs. Experimental results on real-world datasets demonstrate the robustness of the proposed framework on noisy graphs with limited labeled nodes. 




\end{abstract}

% \keywords{Robust Graph Neural Network; Noisy Graph}

\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10010147.10010257.10010282.10011305</concept_id>
<concept_desc>Computing methodologies~Semi-supervised learning settings</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10010147.10010257.10010293.10010294</concept_id>
<concept_desc>Computing methodologies~Neural networks</concept_desc>
<concept_significance>500</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Computing methodologies~Semi-supervised learning settings}
\ccsdesc[500]{Computing methodologies~Neural networks}

\keywords{Noisy Edges; Robustness; Graph Neural Networks}
% \vskip -4em
\maketitle

\input{1_intro_v1}
\input{2_related_work}
\input{3_preliminary_analysis}
\input{4_approach_v1}
\input{5_experiment}

\input{6_conclusion}



%% The file named.bst is a bibliography style file for BibTeX 0.99c
\bibliographystyle{ACM-Reference-Format}
\bibliography{ref}

\newpage
\input{Appendix}

\end{document}


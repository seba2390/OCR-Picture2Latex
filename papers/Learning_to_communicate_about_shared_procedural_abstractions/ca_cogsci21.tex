% 
% Annual Cognitive Science Conference
% Sample LaTeX Paper -- Proceedings Format
% 

% Original : Ashwin Ram (ashwin@cc.gatech.edu)       04/01/1994
% Modified : Johanna Moore (jmoore@cs.pitt.edu)      03/17/1995
% Modified : David Noelle (noelle@ucsd.edu)          03/15/1996
% Modified : Pat Langley (langley@cs.stanford.edu)   01/26/1997
% Latex2e corrections by Ramin Charles Nakisa        01/28/1997 
% Modified : Tina Eliassi-Rad (eliassi@cs.wisc.edu)  01/31/1998
% Modified : Trisha Yannuzzi (trisha@ircs.upenn.edu) 12/28/1999 (in process)
% Modified : Mary Ellen Foster (M.E.Foster@ed.ac.uk) 12/11/2000
% Modified : Ken Forbus                              01/23/2004
% Modified : Eli M. Silk (esilk@pitt.edu)            05/24/2005
% Modified : Niels Taatgen (taatgen@cmu.edu)         10/24/2006
% Modified : David Noelle (dnoelle@ucmerced.edu)     11/19/2014
% Modified : Roger Levy (rplevy@mit.edu)     12/31/2018


%% Change "letterpaper" in the following line to "a4paper" if you must.

\documentclass[10pt,letterpaper]{article}
%\usepackage{dblfloatfix}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{graphicx}
\usepackage{amssymb,amsmath}
\usepackage{mathtools}
\usepackage{cogsci}

%\cogscifinalcopy % Uncomment this line for the final submission 
\usepackage{todonotes}
\usepackage{pslatex}
\usepackage{apacite}
\usepackage{float}
% \cogscifinalcopy % Uncomment this line for the final submission 
\setlength\titlebox{5.5cm}

% \definecolor{Blue}{RGB}{50,50,200}
% \definecolor{Red}{RGB}{200,50,50}
% \definecolor{Black}{RGB}{0,0,0}
% \newcommand{\jefan}[1]{\textcolor{Red}{@jefan: #1}}
% \newcommand{\todo}[1]{\textcolor{Blue}{@TODO: #1}}
\usepackage{stmaryrd}

\graphicspath{ {./figures/} }

\title{Learning to communicate about shared procedural abstractions}

\cogscifinaltrue
\author{
  \large \bf William P. McCarthy\textsuperscript{*}\\
  Department of Cognitive Science\\
  UC San Diego\\
  %La Jolla, CA 92093 \\
  \texttt{wmccarthy@ucsd.edu} \\
  \And
  \large \bf Robert D. Hawkins\textsuperscript{*}\\
  Department of Psychology\\
  Princeton University\\
  %Princeton, NJ 08540 \\
  \texttt{rdhawkins@princeton.edu} \\
  \And
  \large \bf Haoliang Wang\\
  Department of Psychology\\
  UC San Diego\\
  %La Jolla, CA 92093 \\
  \texttt{haw027@ucsd.edu} \\
  \AND
  \large \bf Cameron Holdaway\\
  Department of Psychology\\
  UC San Diego\\
  %La Jolla, CA 92093 \\
  \texttt{choldawa@ucsd.edu} \\
  \And
  \large \bf Judith E. Fan\\
  Department of Psychology\\
  UC San Diego\\
 % La Jolla, CA 92093 \\
  \texttt{jefan@ucsd.edu} \\
}
% \author{{\large \bf Anonymous CogSci submission}}


\begin{document}

\maketitle

\begin{abstract}

Many real-world tasks require agents to coordinate their behavior to achieve shared goals.
Successful collaboration requires not only adopting the same communicative conventions, but also grounding these conventions in the same task-appropriate conceptual abstractions. 
We investigate how humans use natural language to collaboratively solve physical assembly problems more effectively over time.
% describe task
Human participants were paired up in an online environment to reconstruct scenes containing two block towers. 
%One participant, who could see the target towers, sent assembly instructions to the other participant, who aimed to reconstruct them as accurately as possible.
One participant could see the target towers, and sent assembly instructions for the other participant to reconstruct.
% Each participant was assigned either the role of Architect or Builder: the Architect provided assembly instructions to the Builder, who aimed to reconstruct each scene as accurately as possible.
% describe results and interpretation
% We found that Architects provided increasingly concise instructions to Builders across repeated attempts on each pair of towers, reflecting the use of more abstract referring expressions that captured the hierarchical structure of each scene (i.e., tower-level expressions subsuming block-level ones).
Participants provided increasingly concise instructions across repeated attempts on each pair of towers, using more abstract referring expressions that captured each scene's hierarchical structure.
To explain these findings, we extend recent probabilistic models of \emph{ad hoc} convention formation with an explicit perceptual learning mechanism. 
%Agents are initialized with a domain-specific language (DSL) containing simple perceptual primitives and extend their library with new abstractions based on the statistics of objects in the task.
These results shed light on the inductive biases that enable intelligent agents to coordinate upon shared procedural abstractions.

%\textbf{Keywords:} 
%abstraction; coordination physical reasoning
\end{abstract}
\let\thefootnote\relax\footnote{* denotes equal contribution}


From advanced manufacturing to food preparation, many real-world tasks require multiple agents to coordinate their behavior \cite{grosz1996collaborative,stone2010ad,wang2020too}. 
To coordinate effectively, collaborators benefit from sharing similar representations of relevant objects and procedures, specified at the appropriate level of abstraction for their joint goals.
For example, when a new cook is training in a kitchen, they may need to follow step-by-step instructions at the level of individual ingredients, like \emph{melt 30g butter in the small pan, then stir in 30g of flour}.
As they gain more experience, however, they may just \emph{make a roux}, efficiently executing the entire procedure as a single routine. 
When all cooks are using the same unified \emph{roux} abstraction, this simplifies coordination in the kitchen in several ways.
First, they are able to plan more efficiently when they expect other agents to follow chunked routines, since it is no longer necessary to consider all possible low-level executions.
Second, they no longer need to divide up sub-tasks (e.g. one agent melting the butter and the other agent stirring in the flour) when agents can be mutually expected to follow a unitized sub-routine to completion.

In many cases, however, these abstractions are not supplied to agents in advance, and achieving their collective benefits requires \textit{ad hoc} coordination between agents as they each learn about what is required for the task \cite{wang2017naturalizing}.
A powerful solution to the problem of coordinating abstractions is the ability to communicate using natural language \cite{suhr2019executing,tellex2020robots}.
Yet for communication protocols to be effective in novel task settings, where there may not yet be words to easily express the task-specific abstractions, these protocols must \emph{also} be able to update over the course of an interaction, a phenomenon that has been explored in both psycholinguistics \cite{clark1996using, hawkins2020characterizing} and natural language processing \cite{hawkins2019continual}. 
How, then, are intelligent, autonomous agents able to simultaneously coordinate on shared object representations \emph{and} the language for talking about them?


\begin{figure*}[ht]
\begin{center}
\includegraphics[width=0.99\linewidth]{./figures/ORLR_ca_task_display.pdf}
\vspace{-1em}
\caption{Collaborative assembly task. (A) The Architect was shown a target scene and provided assembly instructions to the Builder, who aimed to reconstruct it. (B) Each scene was composed of two towers, which were each composed of four domino-shaped blocks. (C) Example messages from earlier and later repetitions of a tower pair, showing the emergence of expressions referring to towers.}
\vspace{-1em}
\label{fig:task}
\end{center}
\end{figure*}


In this paper, we approach this question by integrating two distinct computational approaches into a unified model.
On one hand, we draw on probabilistic models of \emph{ad hoc} lexical convention formation \cite{hawkinsgeneralizing} through interaction.
These models provide an account of how agents are able to coordinate on ways of referring to \emph{existing} conceptual primitives, but do not explain where new conceptual primitives come from.
On the other hand, recent models of perceptual learning as program synthesis \cite{gulwani2017program} have provided a powerful account of human conceptual representations.
These models propose that concepts may be represented by structured \emph{programs} written in a domain-specific language (DSL). 
Agents are able to supplement their library of primitive concepts with new abstractions, or chunked sub-routines, as they learn more about a task \cite{ellis2020dreamcoder}.
Importantly, these abstractions are \emph{compositional}, allowing them to be combined into larger programs with other primitives.

We suggest that these structured library learning mechanisms may supply agents with the raw conceptual primitives that ground new \emph{ad hoc} conventions in new tasks, and conversely, that communication may be an important mechanism that allows agents to coordinate their abstractions.
Here we explore this hypothesis by examining how humans coordinate their behavior in a physical assembly domain \cite{bapst2019structured, mccarthy2020blocks} in which objects are hierarchically organized, and can thus be specified at different levels of abstraction.
Overall, our paper presents an empirical paradigm, human dataset, and set of evaluation metrics that can be used to guide ongoing development of artificial agents that emulate human-like compositionality and abstraction. 


% A key theme in this literature concerns the importance of compositionality in emergent communication protocols \cite{nowak2000evolution, kirby2014iterated, mordatch2017emergence}, specifically the ability to recombine language from different contexts to formulate new meanings \cite{lake2019human}.
% Rather than expressing each intended meaning with a distinct word, agents may produce multi-word utterances that derive their meanings from their component parts.
% Compositionality may be especially important in domains where the space of possible meanings is highly structured yet large, as in the case of providing instructions to assemble towers from blocks \cite{wang2016learning, zhang2019learning}.
% Our study departs from this prior work by emphasizing how agents develop linguistic conventions for objects defined at higher levels of visual abstraction over time as they acquire more evidence about the structure of these objects and their collaborator's behavior. %\cite{degen2019redundancy, hawkins2018emerging}.




% Agents that can flexibly manipulate real world environments

% 1. we need to be able to communicate with them
% 2. they need to grasp abstraction 

% Physical construction has become a staple test bed for AI and robotic systems.
% Recent approaches have had success with state abstractions, relying on relational \cite{bapst2019structured}, and object-based representation.
% but what about more complex objects?

% These methods are inspired by humans' (tendency to use objects as a primary level of abstraction) (Spelke etc.)...
% However while individual humans provide fair competition for state-of-the-art construction agents, they pale in comparison to human teams.
% On their own, humans build Jenga towers and tents; together they build pyramids and cathedrals. 
% Understanding the mechanisms by which humans collaborate in physical construction tasks is an essential step towards building machines that work with each other and with us.

% To investigate how people communicate in collaborative construction tasks, we paired human participants in an online environment, and had them work together to reconstruct scenes of block towers.
% What made this task challenging was that only one of the participants-- \textit{the Architect}-- could see the target scene, while the other participant-- \textit{the Builder}-- was the only one who could place blocks.
% The Architect was able to sent messages to the builder, however these were limited to 100 characters, providing a bottleneck that motivated Architects to be concise. This allowed us to measure the emergence of shared linguistic conventions and, in particular, how people collectively utilize the powerful tool of abstraction.
% We observed dyads form \textit{shared compositional abstractions}-- words referring to multiple block primitives.


% Minimally, our study clarifies how humans' procedural instructions evolve in shared contexts, providing valuable insight on how to build machines that understand us.
% It also gives insight into how humans use abstraction, which is unclear in the individual case and even less explored in collaboration. % weak I know, but not sure if no one has studied it before..


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Recent work in cognitive science has begun to chart the emergence of linguistic conventions during repeated communication.
% % Repeated reference, communicative efficiency, formation of conventions
% repeated reference leads to conventions
% 'omit redundant syntactic chunks of information'
% Increased arbitrariness and stability (we'd expect these here too)
% \cite{hawkins2020characterizing}
% \cite{hawkins2019continual}

% Researchers have looked at changes in language in XXXXX, XXXX, and XXXXX, but not yet construction. (fact-check this)
% (more discriminative,...)
% People have found that communication becomes more efficient in x,y, and z, but (Have people looked at anything like abstraction in these studies?)
% abstraction => 

% Abstraction
% AI research has leveraged two key kinds of abstraction \cite{Ho2019}:
% \textit{state abstractions}, that aggregate over environments or external features,
% and \textit{temporal abstractions}, macro-actions (for example options) that allow multiple primitive actions to be considered at once, and form the basis of hierarchical RL \cite{sutton1999between}.
% object-based representations as a kind of state-based abstraction

% Linguistic representations of objects (CAs) are genuinely beneficial to AI
% linguistic representations particularly useful for object manipulation due to compositionality
% Endowing machines with language provides more than just an interface with humans. \cite{Jiang2019} demonstrate that using linguistic instructions as a bridge between high-level and low-level policies in hierarchical RL can result in agents that are more sample efficient and generalizable, which they attribute to the inherent compositionality of language.

% Humans are already endowed with complex language.
% Machines need to be trained from scratch.
% \cite{zhang2019learning} use a similar task setup to observe emergent communication between RNNs.
% Speaker learns to emit sequences of discrete symbols from a pre-specified set.
% Here we look at the emergence of new symbols.

% \subsection{Hypotheses}

% We hypothesize that Architects will:
% Use more concise language (i.e. use fewer words and fewer total instructions) when providing instructions across repetitions of the same target tower, given positive feedback that Builders are correctly understanding their instructions.

% We hypothesize that Builders will:
% Place more blocks per instruction and reconstruct each target tower more accurately across repetitions.

\section{Collaborative assembly task}
% \subsection*{Collaborative assembly task} 
\paragraph{Design, stimuli, and procedure}
We recruited 98 human participants ($N=49$ dyads) from Amazon Mechanical Turk and automatically paired them up to perform a collaborative assembly task (Fig.~\ref{fig:task}A).
At the outset, each participant was assigned the role of \textit{Architect} or \textit{Builder} and proceeded with their partner through a series of twelve trials.
% On each trial, the Architect was presented with a target scene containing block towers and the Builder with an empty environment. 
% Critically, only the Architect was shown the target scenes, and only the Builder was able to place blocks.
% To succeed, the Architect needed to send step-by-step assembly instructions, which the Builder used to reconstruct the target scene as accurately as possible. 
At the start of each trial, the Architect was presented with a target scene containing block towers. 
The Builder could not see the target scene, and was presented with an empty grid world environment in which they could place blocks.
The Architect then sent step-by-step assembly instructions, which the Builder used to reconstruct the target scene as accurately as possible. 

Each scene was composed hierarchically from two block towers that appeared side by side; in turn, each tower consisted of four domino-shaped blocks-- two vertical and two horizontal (Fig.~\ref{fig:task}B).
To evaluate changes in behavior, we employed a \emph{repeated} design where each tower appeared multiple times. 
There were three unique towers. 
All three pairs of these towers appeared once in each of four repetition blocks in a randomized sequence, for a total of twelve trials. %, and the order of tower pairs within each block was randomized.
All towers appeared in both the left and right positions an equal number of times, such that there was no statistical association between a given tower and its position.



The Architect and Builder took as many turns as they needed to reconstruct each scene.
On the Architect's turn, they sent a single message containing a maximum of 100 characters; 
on the Builder's turn, they placed one or more blocks before awaiting further instructions (Fig.~\ref{fig:task}C). 
Blocks could be placed anywhere so long as they were supported from beneath, and could not be moved once placed.
The Architect could see the placement of each block in real time but the communication channel was otherwise unidirectional: the Builder was unable to send messages back to the Architect.
Once all eight blocks had been placed, both participants received feedback about the mismatch between the target scene and reconstruction before advancing to the next trial.


\begin{figure}[tbp]
\vspace{-1.5em}
\begin{center}
\includegraphics[width=0.8\linewidth]{CA_task_performance.pdf}
\vspace{-1.5em}
\caption{(A) Reconstruction accuracy improved across repetitions. (B) Mean number of words used on each trial decreased across repetitions.}
\label{fig:performance}
\vspace{-1em}
\end{center}
\end{figure}

\begin{figure*}[tp]%[31]{r}{0.55\textwidth}
\begin{center}
%\vspace{-2em}
\includegraphics[width=\linewidth]{CA_ORLR_refexp_individual_words_2.pdf}
\vspace{-2em}
\caption{(A) Words with largest positive and negative changes in frequency between first and final repetitions. (B) Change in number of block-level and tower-level references across repetitions. (C) The proportion of referring expressions in each trial that exclusively refer to blocks, towers, or scenes. (D) t-SNE visualization of similarity between messages from different dyads in the first and final repetitions.}
\label{fig:refexp}
\end{center}
\end{figure*}


% \paragraph{Participants}
% 98 participants (N=49 dyads) recruited from Amazon Mechanical Turk completed the experiment and met our pre-specified inclusion criterion of 75\% accuracy on 75\% or more of the trials. 
% Each session lasted approximately 30-50 minutes, and participants were provided with a minimum compensation of \$5.00 for task completion, plus a performance bonus of up to \$3.00.

\section{Behavioral Results}
Although each interaction only spanned twelve trials, we hypothesized that human dyads would be able to leverage this small amount of experience to rapidly develop shared task representations, manifesting in increasingly successful and efficient collaboration over time. 
\paragraph{Success across repetitions}
Given that the focus of our study was on how language produced by Architects changed over time, we sought to first verify that human dyads were able to successfully perform the assembly task. 
We found that even on their initial reconstructions, they were highly accurate (mean $F_1=0.876$; 95\%~CI:$[0.854, 0.898]$), which roughly corresponds to having just one block out of place.
Even so, we found that dyads reliably improved across repetitions ($b=3.38$, $t=7.90$, $p<0.001$; Fig.~\ref{fig:performance}A), estimated using a linear mixed-effects model that predicted accuracy from repetition number and included random intercepts for each dyad.  

% percent perfect trials: 
% rep 0: 0.4965986 [0.4069351 0.5670984]
% rep 3: 0.9183673 [0.8765000 0.9568301]
% To assess changes in accuracy over the course of the experiment, we fit a logistic mixed effects model predicting whether a scene was perfectly reconstructed in a trial, with a fixed effect of repetition block, and random intercepts for different dyads.

% Accuracy model
% Linear mixed model fit by REML. t-tests use Satterthwaite's method ['lmerModLmerTest']
% Formula: trialScore ~ repNum + (1 | gameid)
%   Data: df_trial

% REML criterion at convergence: 4577.9

% Random effects:
%  Groups   Name        Variance Std.Dev.
%  gameid   (Intercept)   8.904   2.984  
%  Residual             134.879  11.614  
% Number of obs: 588, groups:  gameid, 49

% Fixed effects:
%             Estimate Std. Error       df t value Pr(>|t|)    
% (Intercept)  86.0136     1.2482 406.8787  68.909  < 2e-16 ***
% repNum        3.3823     0.4284 538.0000   7.896 1.63e-14 ***

% 76.7\% (95\% CI:[73.2, 80.4]) of reconstructions were perfect.  

\paragraph{Communicative efficiency across repetitions}
% model specified with ||, forcing 0 correlation between random effects
Given that the same towers recurred throughout the interaction, we hypothesized that Architects would exploit these regularities to provide more concise instructions over time. 
To test this hypothesis, we analyzed both changes in the total number of words used and how many messages were sent within a trial.
We estimated changes using LME models containing repetition number as a predictor, as well as random intercepts and slopes for each dyad and random intercepts for each tower pair.
%... while enforcing an uncorrelated random effects structure to avoid singular model fits.
Consistent with our hypothesis, we found that Architects sent messages containing fewer words over time ($b=-10.8$, $t=-10.9$, $p<0.001$) (Fig.~\ref{fig:performance}B), which were themselves contained in fewer messages within each trial ($b=-0.67$, $t=-8.01$, $p<0.001$).

% , and characters ($b=-53.9$, $t=-11.3$, $p<0.0001$).

% look at logs of each of these

%%% Messages model %%%%
% Formula: n_messages ~ repNum + (1 + repNum || gameid) + (1 | towerSet)

% REML criterion at convergence: 1762.3

% Random effects:
%  Groups   Name        Variance Std.Dev.
%  gameid   (Intercept) 4.844123 2.20094 
%  gameid.1 repNum      0.297500 0.54544 
%  towerSet (Intercept) 0.006611 0.08131 
%  Residual             0.675430 0.82185 
% Number of obs: 588, groups:  gameid, 49; towerSet, 3

% Fixed effects:
%             Estimate Std. Error       df t value Pr(>|t|)    
% (Intercept)  5.31973    0.32857 49.39721  16.191  < 2e-16 ***
% repNum      -0.67007    0.08361 48.56330  -8.014 1.93e-10 ***

%%%% Word model %%%%
% Formula: word_count ~ repNum + (1 + repNum || gameid) + (1 | towerSet)
%   Data: df_trial

% REML criterion at convergence: 4850.2

% Random effects:
%  Groups   Name        Variance Std.Dev.
%  gameid   (Intercept) 586.262  24.213  
%  gameid.1 repNum       38.460   6.202  
%  towerSet (Intercept)   1.556   1.247  
%  Residual             141.443  11.893  
% Number of obs: 588, groups:  gameid, 49; towerSet, 3

% Fixed effects:
%             Estimate Std. Error       df t value Pr(>|t|)    
% (Intercept)  66.4082     3.7318  48.0906   17.80  < 2e-16 ***
% repNum      -10.7966     0.9886  48.0495  -10.92 1.29e-14 ***


%%%% Character model %%%%
% Formula: char_count ~ repNum + (1 + repNum || gameid) + (1 | towerSet)
%   Data: df_trial

% REML criterion at convergence: 6705.9

% Scaled residuals: 
%     Min      1Q  Median      3Q     Max 
% -2.8198 -0.5405 -0.0082  0.4861  4.7570 

% Random effects:
%  Groups   Name        Variance Std.Dev.
%  gameid   (Intercept) 13482.90 116.116 
%  gameid.1 repNum        882.98  29.715 
%  towerSet (Intercept)    47.39   6.884 
%  Residual              3371.52  58.065 
% Number of obs: 588, groups:  gameid, 49; towerSet, 3

% Fixed effects:
%             Estimate Std. Error      df t value Pr(>|t|)    
% (Intercept)  319.660     18.038  47.424   17.72  < 2e-16 ***
% repNum       -53.913      4.755  47.944  -11.34  3.6e-15 ***

% We used the $F_1$ score as our primary measure of reconstruction accuracy, which reflects the degree to which the shape of participants' reconstruction coincided with the target silhouette, and lies in the range $[0,1]$, where higher scores indicate higher accuracy.
% It is computed by taking the harmonic mean of the \emph{precision} (i.e., the proportion of participants' reconstruction that coincided with the target silhouette) and {\itshape recall} (i.e., the proportion of the target silhouette that coincided with the participants' reconstruction): $F_1 = \nicefrac{2}{(recall^{-1} + precision^{-1})}$.

\paragraph{Changes in words used across repetitions}
What explains these gains in communicative efficiency?
One possibility is that Architects increasingly omitted unnecessary, non-referential function words; another is that they changed which words they used to refer to objects. 
To distinguish these possibilities, we compared changes in the frequency of words used in the first and final repetitions. 
To ensure that our analyses reflected changes in the referring expression used to refer to components of each scene rather than in the use of function words, we recruited two human annotators who were blind to the source of each utterance to manually extract referring expressions from each message\footnote{Two dyads were excluded from this analysis because our annotators were unable to recover referring expressions from their language.}. 
For each dyad, we compared the word frequency distributions between the first and final repetitions using a permutation-based $\chi^2$ test \cite{beh2014correspondence}, which revealed a reliable difference between the two distributions ($p<0.001$, Bonferroni corrected for multiple comparisons).
To identify the words contributing most to this shift, we calculated the overall change in proportion from the first repetition to the final repetition.
We found that words such as ``block'' and ``horizontal'' were used less often while ``shape,'' and ``C'' were used more often (Fig.~\ref{fig:refexp}A).
These results suggest that increasingly concise instructions reflect shifts in \textit{referential} words.

% While section 4.2 analyzed the entire content of the messages, sections 4.3 -- 4.5 were conducted only on this subset of tagged referring expressions. Figure~\ref{fig:refexp}B shows the words with the largest change in proportion from the first tower repetition to the last. 

%We calculated the p-value of the permuted $\chi^2$ distribution for each of the included 47 dyads and compared the product of these p-values to a Bonferroni corrected significance level. We found XXX which indicates that distribution over words for the first repetition is significantly different than the distribution of words in the final repetition 

\paragraph{More abstract referring expressions across repetitions}
% Additionally, each referring expression was tagged with the object to which it referred (i.e. either blocks or towers).
A natural explanation for the shift in the words used is that Architects had learned to produce referring expressions at a higher level of abstraction, in particular ones that corresponded to entire towers rather than individual blocks.
To evaluate this possibility, the same human annotators additionally tagged each referring expression with the number of references to block-level and tower-level entities they contained.
Unsurprisingly, given that there were eight blocks in each scene and only two towers, we found that the number of references to blocks was greater overall than those made to towers ($b = -7.41$, $t(2344) = -20.98$, $p<0.001$), Fig.~\ref{fig:refexp}B). 
More importantly, we found that these proportions shifted across repetitions ($b = 1.35$, $t(2344) = 10.49$, $p<0.001$; interaction between repetition number and reference type). To measure this change in proportion, utterances in each trial were tagged as containing block-specific (e.g. ``horizontal blue block,'' ``vertical red block''), tower-specific (e.g. ``C shape,'' ``L shape''), or mixed expressions. Fig.~\ref{fig:refexp}C shows this change in proportion; reflecting both an increase in the number of tower-level references  and corresponding decrease in the number of block-level references. 

% \begin{figure}
% \begin{center}
% \includegraphics[width=\linewidth]{figures/referringExpression.png}
% \vspace{-2em}
% \caption{The proportion of referring expressions in each trial that exclusively refer to blocks (black), towers (grey), or both (blue).}
% \vspace{-1em}
% \label{fig:refExpComposition}
% \end{center}
% \end{figure}

% repetition number on the number of referring expressions ($b = -1.18$, $t(2344) = -12.97$, $p<0.001$); 
%  There was no significant effect of rater on the number of expressions ($b = 0.51$, $t(2344) = 1.45$, $p=0.149$).
% and a significant interaction between repetition number and reference type ($b = 1.35$, $t(2344) = 10.49$, $p<0.001$)
%  This suggests that across dyads, there is an emergence of tower-specific referents that gradually replace block-specific language.

% Are conventions a necessary (or potential) middle ground between low-level, primitive instructions and compositional abstractions?
% Or is it just an alternative strategy (which may be traversed or settled on, on the way to full CAs?

%Plot of relative frequency of words over time (divided into first instance of L/C/P and last). How do we know these are tower specific tokens? When we "factor" out the common tower, the most words with largest \% change are those that are specific to the second tower.
%Emergence of new tokens.
%Given that terms like 'C' and 'L' could correspond to many configurations of dominoes, how is it that Architects are able to use these terms to accurately refer to the towers used in this task? 
%This is partially enabled by shared experience constraining the meaning of those terms.


\paragraph{Consistency and variability in referring expressions across dyads}
% Given the overall increase in references to ``C'' and ``L'' shapes in the final repetition (tokens which resemble entire towers), the results so far suggest at least some degree of consistency between dyads with respect to the tower-level abstractions that emerged. 
The overall increase in tokens resembling entire towers (``C'' and ``L'' shapes) in the final repetition suggests some degree of consistency between dyads, with respect to the tower-level abstractions that emerged.
To what extent did different dyads converge on the same set of labels for each tower, rather than settle on distinct, but internally consistent ways of referring to them?
To explore this question, we estimated how dissimilar the language used by different dyads was within each repetition, by computing the Jensen-Shannon divergence (JSD) between their word frequency distributions, aggregating language from all trials in a repetition block. 
We found that the mean pairwise JSD increased significantly between the first and final repetitions ($d=0.080$, 95\% CI:$[0.041 , 0.118]$, $p=0.004$), consistent with divergence between dyads.
We visualized these distances using a t-SNE embedding of word count vectors (Fig.~\ref{fig:refexp}C), revealing that this divergence might be attributed to the formation of distinct ``clusters'' (denoted by different colors shown with representative words; gray dots belong to degenerate clusters with $<4$ members).
% Taken together, these observations suggest that groups of dyads uncovered a range of distinct solutions for mapping tokens of natural language to components of each scene.
Together, these findings suggest that even in this relatively simple task domain, human dyads manage to discover a diverse array of solutions for mapping tokens of natural language to components of each scene.

%\cite{scikit-learn}

\begin{figure*}[t]
\begin{center}
\includegraphics[width=0.6\textwidth]{./figures/ca_cogsci21_model_revised.pdf}
\caption{(A) Trajectory of new procedural primitives added to the agent's library over the course of the task, shown for library size penalty $w=1.5$ (low), $w=3.2$ (medium), and $w=9.6$ (high). Each row represents the proportion of fragments at the \emph{sub-tower} level (red), \emph{tower} level (green), or \emph{scene} level (blue). Values in each cell represent the proportion of the agent's abstractions at that level. (B). The Architect model's production preferences over repetition blocks, shown for varying levels of cost-sensitivity parameter $\beta$, where $\beta=0.3$ best matches human data.}
\label{fig:model}
\end{center}
\end{figure*}

\section{Computational model}

In the previous section we found that Architects shift to more abstract tower-level referring expressions over successive interactions.
But why did participants generally introduce new words referring to entire \emph{towers} as units, as opposed to sub-towers or entire scenes?
Furthermore, given that initial reconstruction accuracy was already so high, why did participants decide to introduce new words at all?
We hypothesized that Architects' use of abstract referring expressions was constrained by the procedural abstractions available to each agent at a given time, as well as a rational trade-off between efficiency and informativity.
In other words, the Architect must (1) have an underlying representation of the procedure they intend to communicate, (2) maintain uncertainty about whether the Builder is likely to share that representation, and (3) prefer shorter message over longer messages, all else being equal.

We formalize this hypothesis in a computational model that integrates a Bayesian program learning algorithm  \cite{ellis2020dreamcoder} with a probabilistic model of communication under uncertainty and verify that these mechanisms give rise to the behaviors observed in our empirical data.
% Repeated exposure to target towers increases the likelihood that chunked subroutines at the tower-level will be discovered by each agent, and as the speaker becomes more confident over the course of interaction that more abstracted referring expressions will be interpreted correctly, they increasingly prefer the more efficient descriptions.
Repeated exposure to target towers increases the likelihood that chunked subroutines at the tower-level will be discovered by each agent.
This means that over the course of interaction, as the Architect becomes more confident that their abstracted referring expressions will be interpreted correctly, they increasingly prefer more efficient descriptions.


\paragraph{Procedural abstraction as program learning}

%%% Library learning @haoliang %%%
\newcommand{\mdl}{\mathsf{MDL}}
\newcommand{\size}{\mathsf{size}}

We begin by specifying how each agent's procedural knowledge is represented and modified over the course of learning in the task.
Following \citeA{ellis2020dreamcoder}, we assume that each agent maintains a library $\mathcal{L}$ of primitives that can be combined to generate simple block structures in a domain-specific language (DSL).
We assume the library is initialized with the following primitives: \texttt{h} (place a horizontal block), \texttt{v} (place a vertical block), \texttt{l} (move hand to the left), \texttt{r} (move hand to the right) and digits \texttt{1}$\sim$\texttt{9}. 
This DSL is small but fully expressive: any possible tower can be written by combining together these basic commands.

In the Bayesian program learning framework, the DSL is updated over time by expanding the library with new primitives.
As an agent progresses through multiple trials of tower scenes $\{T_{n}\}_{1}^{N}$, they may extract common subroutines that would allow them to re-represent the data more efficiently.
Formally, the model proposes a set of candidate sub-routine fragments $f$ after each trial and updates a posterior distribution over possible ways of extending the library (including $f = \emptyset$, which would maintain the current library):

\begin{equation}
P(\mathcal{L} \cup \{f\}|\{T_{n}\}_{1}^{N}) \propto {\underbrace{P(\mathcal{L} \cup \{f\})}_{\mathclap{\text{description-length prior}}}} \quad \times {\underbrace{\prod_{n=1}^{N}P(T_{n}|\mathcal{L} \cup \{f\})}_{\mathclap{\text{likelihood}}}}
\label{eq:posterior}
\end{equation}

This posterior distribution weighs two competing criteria for a good library: the likelihood and the prior.
The \emph{likelihood} in \ref{eq:posterior} captures the ability of an extended library efficiently to explain previous towers:
\begin{equation*}
   P(T_n | \mathcal{L}\cup \{f\}) = \mathsf{exp}(- \mdl(T_{n}\mid \mathcal{L} \cup \{f\}))
\end{equation*}
where $\mdl$ is a function evaluating the \emph{minimum description length}.
Intuitively, the MDL is the most compact version of $T_{n}$
that can possibly be written in the updated library $\mathcal{L} \cup \{f\}$.
This term is therefore maximized by sets of fragments $\{f\}$ that allow the existing data to be expressed most efficiently. 

The \emph{prior}, on the other hand, captures a preference for smaller libraries:
\begin{equation*}
   P(\mathcal{L} \cup \{f\}) = \mathsf{exp}(- w \cdot \size(\mathcal{L} \cup \{f\}))
\end{equation*}
where $\size(\mathcal{L} \cup \{f\})$ represents the number of primitives in the updated library. 
The strength of this preference is controlled by a parameter $w$.
We explore several values of $w$ in our simulations. 
Intuitively, when $w=0$, there is no penalty for having a larger library, so the library that best explains the observations would simply be the exhaustive set of scenes $T_n$ observations themselves.
As $w \rightarrow \infty$, any expansion of the library is considered too costly, preventing library learning entirely. 
These two objectives balance out in the posterior distribution (Eq. \ref{eq:posterior}) such that the fragments $f$ with the highest posterior probability are those that provide maximal compression of input tower programs while minimizing expansion of the library.

%%% Program enumeration %%%
In practice, we selected the single highest posterior-probability set of fragments at each point in the task, conditioning on the previous trials (Fig.~\ref{fig:model}A).
The resulting DSL was supplied to both the Architect and Builder agent model as the set of primitives they are able to represent.
In other words, we assume that the Builder and Architect learn abstractions at the same rate throughout the experiment.
We further assume that when the Architect agent is presented with a scene, they are able to synthesize a set of 1 to 4 possible candidate programs for representing that scene in their current DSL. 
For example, the Architect agent may simultaneously recognize that a scene may be constructed by placing eight primitive blocks, \texttt{(h (l 1) v v (r 2) ...)}, or by combining two higher-level primitives \texttt{(chunk1 (r 2) chunk2)}. 
%from which we derived a set of candidate programs for that trial by replacing all combinations of any learned fragments with their base DSL translations, yielding 1-4 programs of varying length.

% In trials 1-3, prior to learning any abstractions, enumeration was unsuccessful, and so we used direct translations of the input programs. 
% Enumeration was also unsuccessful in trials 4 and 5.
% While abstractions were learned in these trials, these corresponded to substrings of the input programs, and so we found the minimum length program by replacing those substrings with their corresponding abstractions.

%%% Language inference @Robert %%%
%%% Two versions of model @Robert %%%
\paragraph{Communication as social reasoning}

In this section, we present a model of communication where each agent's DSL serves as a basis for grounding structured linguistic meanings.
We assume the Architect is a cooperative speaker agent who aims to produce utterances that will allow the Builder agent to re-produce the target tower. 
For simplicity, the Architect generates natural language instructions \emph{sequentially}, aiming to produce an utterance that convey each step $t_i$ of a full procedural sequence $T$ written in their current DSL.
Following recent probabilistic models of communication as social reasoning \cite<e.g.>{GoodmanFrank16_RSATiCS}, they choose an utterance proportional to its communicative utility, based on whether the Builder is expected to take the intended action after hearing the utterance: 
\begin{align}
P_S(u | t_i) & \propto \exp\{- \alpha \cdot U(u; t_i)\}\label{eq:rsa}
 \\
U(u; t_i)  & = \log P_L(t_i | u) \nonumber\\
P_L(t_i | u) & \propto \delta_{\llbracket u \rrbracket (t_i)}\nonumber
\end{align}
$\delta_{\llbracket u \rrbracket (t_i)}$ is the literal meaning function that the Builder agent is expected to use, evaluating to 1 when $u$ is true of the primitive $t_i$ in the agent's lexicon and 0 otherwise. 

The key behavioral phenomenon we aimed to explain with this model is the Architect's increasing preference for more abstract descriptions (i.e. Fig.~\ref{fig:refexp}B). 
We hypothesized that this behavior is a consequence of a rational trade-off between informativity and the cost of communication.
While Eq.~\ref{eq:rsa} gives the Architect's preferences for conveying each instruction of a fixed program $T$, we showed in the previous section that an Architect on later trials in fact has multiple ways of representing the raw scene $T^*$ available to them, using different primitives in their library.
We therefore extend our model to explicitly model the Architect's joint decision over which of these \emph{programs} $T^k$ to attempt to transmit in addition to what utterance they should use to transmit it:
\begin{align}
U(u, T^k; T^*) = (1-\beta) \cdot \sum_{i} \ln P_L(t_i^k | u) - \beta\cdot |T^k|
\end{align}
where $\beta$ is a parameter controlling the Architect agent's cost-sensitivity: when $\beta$ is high, the length of the required description dominates the Architect agent's decision-making; when it is low, the Architect's decisions are solely based on informativity to the Builder.

Finally, to account for the last condition of our hypothesis, that the Architect is sensitive to the risks of introducing novel descriptions, we must say what the meaning of a novel word should be in the Builder agent's lexicon: $\llbracket u \rrbracket$. 
Following recent models of convention and coordination \cite{hawkinsgeneralizing}, we assume that the Architect actually maintains uncertainty over the lexical mappings between words and primitives in the DSL $P(\llbracket u \rrbracket)$ and marginalizes over this distribution when evaluating their utility.
Some basic entries are deterministic, e.g. \texttt{\{h : ``place a horizontal block''\}}, but for learned abstractions (\texttt{chunk1}, \texttt{chunk2}), we assume a uniform distribution over an additional set of synthetic tokens (\texttt{``chunkA''}, \texttt{``chunkB''}) that can be emitted.
Over successive trials, the Architect agent can observe the Builder agent's actions (e.g. their placement of blocks) and update their beliefs about the lexicon \cite<see>[for additional details]{hawkinsgeneralizing}. 

\subsection{Simulation results}

\paragraph{The emergence of tower-level fragments}
Before presenting our Architect simulations, we first examine the trajectory of procedural abstractions that were acquired by the model over the 49 trial sequences presented to participants, while varying the penalty on library size, $w$ (Fig.~\ref{fig:model}A).
We manually categorized the resulting fragments based on their level of abstraction at the \emph{sub-tower} level (e.g. a routine producing a configuration of 2-3 blocks that co-occur within multiple towers), the \emph{tower} level (e.g. a routine generating four block placements that exactly reproduce one of the tower stimuli), or the \emph{scene} level (e.g. a routine generating eight block placements in the exact configuration that appeared on a trial).
First, we found that the statistical structure of the trial sequence did indeed allow our library learning algorithm to acquire full \emph{tower-level} primitives across a wide range of $w$, although higher (e.g. $w=9.6$) significantly delayed learning.
Surprisingly, the discovery of tower-level fragments was always preceded by sub-tower fragments.
For example, the pair of blocks forming the lower left of the 'L' and 'C' towers was frequently added, and many more such fragments were added at lower values of $w$.
There are several possible reason why these sub-tower abstractions were rare in our behavioral data, and additional work is required to determine whether Architects failed to represent them as perceptual configurations, or whether they simply suppressed the production of referring expressions for such structures. %potential reason being that Architects could not find ways to efficiently refer to sub-tower abstractions that the Builder would understand.

\vspace{1mm}
\subsubsection{Cost-sensitive Architects increasingly prefer abstract descriptions}
Next, we examine the results of a simple simulation exploring the dynamics of interaction between our Architect and Builder models.
We ran 2 iterations of each trial sequence, sampling an intended program and sequence of instructions from the Architect agent's distribution in Eq.~\ref{eq:rsa} and then sampling a set of resulting actions from the Builder agent's distribution conditioned on this utterance.
The agents updated their DSL and their beliefs about the lexicon after each trial. 
We found that Architects with strong cost-sensitivity (i.e. $\beta>0.5$) always used the most concise programs available to them -- by the third repetition nearly all block-level instructions were replaced by descriptions at higher levels of abstraction, even though these descriptions were more likely to result in Builder errors (Fig.~\ref{fig:model}B).
Meanwhile, in the absence of cost-sensitivity ($\beta=0$), Architects preferred a safer strategy, continuing to use longer but less ambiguous descriptions composed of block-level instructions even though more abstract representations were available to them (Fig.~\ref{fig:model}B, grey lines).
We found that intermediate values of $\beta$ roughly reproduced the qualitative Architect behavior observed in our behavioral data.

% \subsubsection{Builder agent actions increasingly match Architect agent intentions}

% We first measured the extend to which the programs inferred by the Builder agent matched the intended programs of the Builder.
% As our primary goal was to model the emergence of compositional abstractions in response to varying demands for efficiency and accuracy, we decided to initialise the Architect's and Builder's lexicons with deterministic mappings from DSL primitives to natural language expressions.
% This meant that before abstractions were learned and used by the Architect, the Builder would always perfectly interpret the Architect's language, and execute the program they had intended.
% When new abstractions are introduced, the Builder must guess the referent of the new expression, in this case by sampling from a uniform distribution over possible referring expressions.
% We thus expect, and see, a steep drop in accuracy following the inclusion of the first abstraction.
% In contrast, human participants often chose words such as 'C' or 'L-shape', for which likely have sharp priors about the possible programs they represent.
% After the initial drop in accuracy, the proportion of Builder actions that matched the intended program of the Architect steadily increased.


\section{Discussion}

% Implications?
% \todo[inline]{IMPLICATION 1: A window onto task decomposition? Perceptual organization? Insight into systematic shared biases governing the emergence of re-usable shape abstractions in physical assembly tasks. Cite Will's cogsci paper from last year. }

% \todo[inline]{IMPLICATION 2: A window onto flexibility of language use? And pressures to develop/adapt language to talk about new things. Cite Robert's many papers on this subject. }

%% PARA 1: SUMMARY (REMIND THEM WHAT UR STUDYING, WHAT RESULTS ARE)
Successful collaboration in many real-world tasks requires coordinating on shared abstractions and the language used to express them. 
This paper investigated how humans efficiently collaborate in a physical assembly task by developing shared abstractions for connecting language with object representations. 
We found that, across repeated interaction, dyads developed increasingly efficient communication by shifting language to more abstract referring expressions, without sacrificing communicative accuracy. 
We also implemented a computational model that integrates Bayesian program learning with a probabilistic model of communication to show how efficient abstract descriptions arise from a trade off between informativity and the cost of communication. 

%% PARA 2: IMPLICATIONS
% - HUMAN-FAST-LEARNING: Linguistics (How and why we come up with new words) // CogSci: Mechanisms that enable rapid generalization & few-shot learning in social interactions 
% - METHOD: beyond reference games, to procedural tasks that involve more complex representations
% - LANG/THOUGHT: functional constraints on the emergence of shared procedural/linguistic abstractions
% - PROGRAMS: formal specifications of procedure, allow for quantification of efficiency

% Our approach extends recent models of convention formation to a task in the physical construction domain that requires extended interactions at multiple levels of abstraction.


% Method: extending convention formation with abstract procedural knowledge
% Program: 
% Lang/ thought: 
% Social learning 
% => few shot-learning/ AI

%%%% Method: extending convention formation with abstract procedural knowledge
Our approach extends a recent framework for studying convention formation \cite{HawkinsFrankGoodman17_ConventionFormation} to a task that requires performing complex procedures.
% Lang/ thought: 
Communicating about these procedures is costly, making this task well suited to studying the emergence of abstractions under functional constraints such as informativity and efficiency.
% program
By representing procedures as learned program fragments, our model provides a natural quantification of communicative efficiency-- i.e. program length, as well as an explicit mechanism for abstraction learning.
Together, this approach sheds light on few-shot and one-shot learning exhibited by humans as they use language to coordinate on new tasks.

% Our approach extends recent models of convention formation \cite{HawkinsFrankGoodman17_ConventionFormation} to a task in the physical construction domain that benefits from complex representations of procedural knowledge at multiple levels of abstraction. [PROCEDURES->]
% The task required producing a set of sequential procedures that were constrained by the abstractions available to each agent at a given time. 
%%% Program: 

% Social learning 
    %In this way, communication reflects social reasoning\cite{GoodmanFrank16_RSATiCS}, where utterances are chosen proportional to their communicative utility, which is inferred from the past interactions.


%% PARA 3: LIMITATIONS / FUTURE WORK

% In future work, we plan to further investigate the sources of consistency and variability in the communication protocols that emerge during collaboration, as well as constraints on generalization of these protocols to novel tasks and collaboration partners.
In future work, we plan to further investigate the sources of consistency and variability in the communication protocols that emerge during collaboration and refine the program learning algorithm to fit our experimental results.
% 1. realistic priors
A currently unexploited source of consistency is in the choice of referring expressions used to refer to each tower (e.g.``C-shape'', ``upside-down U'').
An immediate next step will be to collect realistic priors for the expressions used to refer to entities in this stimulus set, in order to more precisely track uncertainty over the interpreted meaning of newly-formed conventions.
% 2. referencing previous interactions 
Another empirical observation our model does not capture is explicit reference to previous trials, which may be particularly relevant, as it appeared to frequently coincide with the emergence of expressions that refer to entire towers.

% 3. learning abstractions at same rate
Furthermore, we made the simplifying assumption that both participants learned internal representations of procedural abstractions at the same rate.
While this may be the case in our highly structured building experiment, people collaborating on tasks in the real world are likely to discover useful abstractions at different times, due to differences in prior knowledge and from approaching the task from different perspectives.
While our model architecture posited a clean separation between the discovery of conceptual abstractions and their subsequent communication, people may actually leverage language to discover new abstractions, a possibility we are currently exploring by extending the library-learning component of our model with a SOTA Bayesian program learning algorithm that incorporates language. % \cite{cathyicml}

%% PARA 4: CLOSER
We have studied how the emergence of effective communication protocols over very sparse interaction allows humans to coordinate to solve physical assembly problems. Fruitful extensions could probe more complex domains, include artificial agents, or explore other algorithmic approaches (e.g., program synthesis, reinforcement learning, \textit{seq2seq}, etc.) to explain the computational mechanisms that enable effective coordination.
% -- such as evaluating different algorithmic approaches emulate human behavior in both Architect and Builder roles (e.g., program synthesis, reinforcement learning, \textit{seq2seq}, etc.).
In the long term, such studies may shed light on the inductive biases that enable rapid coordination upon shared procedural abstractions during social interaction between intelligent, autonomous agents.
% Moreover, to probe the computational mechanisms that enable effective coordination, we plan to evaluate how well different algorithmic approaches emulate human behavior in both Architect and Builder roles (e.g., program synthesis, reinforcement learning, \textit{seq2seq}, etc.). 
% In the long term, such studies may shed light on the inductive biases that enable rapid coordination upon shared procedural abstractions during social interaction between intelligent, autonomous agents.




% \todo[inline]{IMPLICATION 1: A window onto task decomposition? Perceptual organization? Insight into systematic shared biases governing the emergence of re-usable shape abstractions in physical assembly tasks. Cite Will's cogsci paper from last year. }

% \todo[inline]{IMPLICATION 2: A window onto flexibility of language use? And pressures to develop/adapt language to talk about new things. Cite Robert's many papers on this subject. }

% \todo[inline]{ALTERNATIVE: While we focused on how people develop names for higher-order shape abstractions, other stuff people could be doing: e.g., referring to earlier trials (“do what you did two trials ago!”) and/or using spatial coordinates but still block-level referring expressions. Future work should handle these kinds of alternative strategies for coordinating on how to talk about these procedures. }

% \todo[inline]{LIMITATION 1 / FUTURE WORK OPPORTUNITY 1: relatively small set of simple towers that had highly nameable shapes. future work should scale this up to more heterogeneous, complex collaborative challenges, using towers that are not as easily nameable. Also should look at generalization to new, non-repeated towers as way of understanding how transferable the communication protocol developed is.}

% \todo[inline]{LIMITATION 2 / FUTURE WORK OPPORTUNITY 2: only looked at how single dyad developed communication protocols. future work should examine how people generalize to new collaborators. May require more sophisticated model of language learning. }

%% GRAND!




% mention more complex task structures? Test limits of abstraction?


% \subsubsection{Task Procedure}

% Participants will be paired online to perform a collaborative physical assembly task. One participant will be assigned the role of “Architect” and the other will be assigned the role of “Builder”. On each trial, the Architect is presented with a target configuration of towers that is not visible to the Builder. The Architect will type messages into a chat window to send instructions to the Builder about how to construct the towers. Once a message is sent, control shifts to the Builder, who must use the instructions to place dominoes in the grid environment. The Builder will not be able to use the chat window to reply, or change a block once it is placed. The Builder is allowed to place as many blocks as they wish before pressing the “done” button, including zero blocks. This button ends their turn and allows the Architect to type another message into the window. The Architect will be able to see the location of each block placed by the Builder in real-time. During each turn, there will be a timer counting down from 30 seconds to encourage the Architect and Builder to work quickly, though there is no penalty for exceeding this time limit. The trial ends when the Builder has placed eight blocks in the grid environment (all stimuli contain exactly eight blocks). 

% Following the successful completion of a practice trial with a simpler structure, subjects will complete 12 total trials. The trial sequence is designed such that each possible pair of the three towers (i.e. AB, BC, and AC) appears in randomized order in each block of three trials, such that each stimulus is repeated exactly four times. 

% Study Type:  This study will be an experiment with tower-hemified pairings manipulated between trials within a pair of subjects.

% \subsubsection{Study design: Behavioral experiment}

% Randomization: Roles are randomly assigned to participants as they enter the waiting room, towers are randomly assigned to the left and right sides, and the order of the stimuli is randomized within each block of three trials.

% Participants:
% We plan to recruit 100 English-speaking adults using Amazon Mechanical Turk. Participants will be paired for a total of 50 dyads. Each participant will provide informed consent and receive \$4.00 for their participation in our ~20 minute study, with the possibility of earning up to \$1.20 in performance bonus (approx. \$12-15.60/hr), in accordance with UCSD IRB. 

% Existing data: Preregistration prior to collection of data

% Stopping rule: Data collection will stop when 50 dyads (100 participants) have successfully completed the study.

% Data Validation / Exclusion Criteria

% We plan on manually validating the data for each of the 50 sessions run, rejecting sessions on the following criteria: 

% Dyads who do not complete all 12 trials
% Dyads who achieve below 75\% accuracy on 75\% or more of the trials
% Subjects whose exit survey indicates they did not understand the study (self-reported)
% Participants who report lack of fluency in English

% June 30, 2020: In our initial sample of N=20 dyads, we discovered wide variation in task performance, as well as apparent compliance with task instructions. Overall, we found that: 21/43 dyads who began a game were able to complete the session; that 14/21 dyads met our initial inclusion criterion of 75\% accuracy on 75\% or more of trials; XX/20 indicated comprehension of the study; and XX/20 affirming fluency in English. 

% Variables 
  
% Manipulated Variables

% This study manipulates the type of block tower and its position (left or right hemifield) within the experiment environment on each trial. 

% Measured Variables

% To measure the efficiency of the Architect’s instructions, we will count the number of words and characters used in each instruction given by the Architect. We will additionally measure the number of messages in each trial. 

% To measure the accuracy of the Builder’s reconstruction, we will use a bitmap representation of the 12x8 gridworld environment to compute the F1 score of each final reconstruction, which takes into account both recall (proportion of the target tower with blocks covering them) and precision (proportion of the reconstruction lying within the target tower). 

% Finally, we will also measure the time taken by each participant in each trial to complete their actions. We will measure how long Architects take to complete each turn, by measuring total time between the activation of the chat box until the submission of their instruction, summed across all instructions within trial. We will similarly measure the time the Builder spends placing blocks, by measuring the total time between receiving the Architect’s instructions and when they end their turn, summed across all turns within a trial.

% Natural Language Preprocessing

% We also have an opportunity to go beyond simple efficiency measures to characterize the content of the instructions sent by the Architect. For these analyses, which require stable estimates of which words are conventionalized across repetitions, which words are dropped, and which words are introduced on later repetitions, we will lemmatize and remove a list of common stop words. We may also run a spell checker and manually correct typos. 

% Analysis Plan

% Statistical Models
% We will use linear mixed-effects models to measure the effect of repeated trials  on language efficiency, block placing accuracy, and time taken to complete each action. Insofar as subjects develop efficient, yet accurate communication, we hypothesize that across repeated trials, subjects will: use fewer words per message, compose fewer messages per trial, reconstruct each tower increasingly accurately, and use less time to both compose messages and place blocks. Specifically, we will include a fixed effect of tower repetition block, and a maximal random-effects structure with intercepts and slopes for different dyads and towerIDs. If the maximal structure does not converge, we will simplify the random effects structure until we reach a converging model.

% $lmer(DV ~ tower\_repetition\_num + (1 + tower\_repetition\_num | gameID) + (1 + tower\_repetition\_num | towerID)$

% As a control analysis, we will additionally analyze any potential biases due to the side each tower appears on, by including it as an additional predictor in the above statistical model. 

\section{Acknowledgments}

Thanks to the members of the Cognitive Tools Lab at UC San Diego for helpful discussion. C.H. is supported by a DoD NDSEG Fellowship. This work was supported by NSF CAREER Award \#2047191 to J.E.F.


\vspace{2em}
\fbox{\parbox[b][][c]{7.3cm}{\centering {All code and materials available at: \\
\href{https://github.com/cogtoolslab/compositional-abstractions}{\url{https://github.com/cogtoolslab/compositional-abstractions}}
}}}
\vspace{2em} \noindent

\bibliographystyle{apacite}

\setlength{\bibleftmargin}{.125in}
\setlength{\bibindent}{-\bibleftmargin}

\bibliography{references.bib}


\end{document}

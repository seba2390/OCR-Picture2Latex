\section{Preliminary on \texorpdfstring{$\SubsetSelection$}{Subset Selection}}
\label{appendix:ss}

In this section, we briefly recap the $\SubsetSelection$ (SS) mechanism proposed in \cite{YB18}.
Let $\svbx = (x_1, x_2,...,x_d) \in \{0, 1\}^d$ be the one-hot representation of an input symbol in $\cX = [d] = \{1,\cdots, d\}$\footnote{With a slight abuse of notation, when context is clear, we sometime use $\svbx = i$ for some $ i \in [d]$ to indicate the one-hot representation of symbol $i$}. Let $\qSS(\svbz|\svbx)$ be the $\SubsetSelection$ mechanism defined in \cite{YB18} where the output alphabet is the set of all $d-$bit binary strings with Hamming weight $s \in [d]$, i.e.,
\begin{align}
\mcal{Z} = \lbp \svbz = (z_1, z_2,...,z_d) \in \{0, 1\}^d: \sum_{i=1}^d z_i = s \rbp. \label{eq:z_ss}    
\end{align}
% and the conditional probability $\qSS(\svbz|\svbx)$ is given by
% \begin{equation}\label{eq:q_ss_def}
%     \qSS(\svbz|\svbx = i) \coloneqq \frac{e^\varepsilon z_i+(1-z_i)}{{d-1 \choose s-1}e^\varepsilon+{d-1 \choose s}}.
% \end{equation}
Given $\svbx \in \cX$,  $\SubsetSelection$ maps it to $\svbz \in \cZ$ with the following conditional probability:
\begin{align}\label{eq:q_ss_app}
    \qSS(\svbz|\svbx = i) \coloneqq \begin{cases}
    \dfrac{e^{\varepsilon}}{{ \binom{d-1}{s-1} }e^{\varepsilon}+{ \binom{d-1}{s} }} & \text{if}\ \svbz \in \cZ_{i}
    \\[10pt]
    \dfrac{1}{{ \binom{d-1}{s-1} }e^{\varepsilon}+{ \binom{d-1}{s} }} & \text{if}\ \svbz \in \cZ \setminus \cZ_{i}
    \end{cases}
\end{align}
where $\cZ_{i} = \lbp \svbz = (z^{(1)}, \cdots ,z^{(d)}) \in \cZ : z^{(i)} = 1 \rbp$ is the set of elements in $\cZ$ with $1$ in the $i^{th}$ location.


\cite{YB18} show that the marginal distribution of $\svbz$ is a linear function of that of $\svbx$. In particular, if we define $p_i \coloneqq \Pr\lbp x_i = 1 \rbp$ for all $i \in [d]$ and let $\svbz \sim \qSS(\cdot |\svbx)$, then \eqref{eq:ss_eq5} is due to (5) in \cite{YB18},
\begin{align}
    \qSS_i \coloneqq \Pr\lbp z_i = 1 \rbp
    & = \frac{\binom{d-1}{s-1} e^\varepsilon p_i + \lp \binom{d-2}{s-2}e^\varepsilon + \binom{d-2}{s-1} \rp (1-p_i)}{\binom{d-1}{s-1} e^\varepsilon + \binom{d-1}{s}} \label{eq:ss_eq5}\\
    & = \frac{s(d  -  s)(e^{\varepsilon}-1)}{(d  -  1)(s(e^{\varepsilon}  -  1)+d)} p_i+  \frac{s((s  -  1)e^{\varepsilon} +(d  -  s))}{(d  -  1)(s(e^{\varepsilon}  -  1)+d)} \\
    & = m_{\texttt{ss}} \cdot p_i + b_{\texttt{ss}}, \label{eq:ss_marginal}
\end{align}
where 
\begin{align}
    m_{\texttt{ss}} \coloneqq \frac{s(d  -  s)(e^{\varepsilon}-1)}{(d  -  1)(s(e^{\varepsilon}  -  1)+d)}, \qquad  b_{\texttt{ss}} \coloneqq  \frac{s((s  -  1)e^{\varepsilon} +(d  -  s))}{(d  -  1)(s(e^{\varepsilon}  -  1)+d)}. \label{eq:scaling_factors_ss}
\end{align} 

The final estimator of $\svbx$ is denoted by $\hat{\svbx}^{\texttt{ss}}$ and is defined as $\frac{1}{m_{\texttt{ss}}} \cdot (\svbz-b_{\texttt{ss}}\cdot\mb{1}_d)$, where 
$\mb{1}_d \eqDef [1,\cdots,1]^\intercal \in \mbb{R}^d$. In other words, $m_{\texttt{ss}}$ and $b_{\texttt{ss}}$ are used de-bias the outcome $\svbz$. The scheme is summarized in Algorithm~\ref{alg:ss}.
\begin{algorithm}
\caption{Subset Selection}
\label{alg:ss}
\begin{algorithmic}
\Require $\svbx \in [d]$, $s \in [d]$.
\State Draw a $s$-hot random vector $\svbz$ according to the distribution $\qSS(\svbz|\svbx)$ in \eqref{eq:q_ss_app}.

\Return $\hat{\svbx}^{\texttt{ss}} = \frac{1}{m_{\texttt{ss}}} \cdot (\svbz-b_{\texttt{ss}}\cdot\mb{1}_d)$
\end{algorithmic}
\end{algorithm}

\subsection{\texorpdfstring{$\SubsetSelection$}{Subset Selection} is unbiased and order-optimal}
The following proposition borrowed from \cite{YB18} shows that the output of the $\SubsetSelection$ mechanism  (a) is unbiased and (b) has order-optimal utility.

\begin{proposition}
Let $\hat{\svbx}^{\texttt{ss}}$ = \emph{$\SubsetSelection(\svbx,s)$} for some $\svbx \in \cX$ and $s \in [d]$. Then, $\E[\hat{\svbx}^{\texttt{ss}}] = \svbx$. Further, the $\ell_2$ estimation error is 
\begin{equation*}
    \E\lb \lV \hat{\svbx}^{\texttt{ss}} -\svbx \rV^2_2\rb = \lp \frac{\lp s(d-2)+1 \rp e^{2\varepsilon}}{(d-s)\lp e^\varepsilon -1\rp^2}+\frac{2(d-2)}{\lp e^\varepsilon -1\rp^2}+ \frac{(d-2)(d-s)+1}{s\lp e^\varepsilon -1\rp^2} - \sum_i p_i^2\rp.
\end{equation*}
Moreover, if we pick $s \coloneqq \lceil \frac{d}{1+e^\varepsilon}\rceil$, then
$$\E\lb \lV \hat{\svbx}^{\texttt{ss}} -\svbx\rV^2_2\rb = \frac{d}{\min\lp e^\varepsilon, \lp e^\varepsilon-1 \rp^2, d \rp}, $$
which is order-optimal.
\end{proposition}

\subsection{\texorpdfstring{$\SubsetSelection$}{Subset Selection} is a cap-based mechanism}\label{appendix:ss_cap}
As discussed in Section \ref{sec:main_results}, $\qSS$ defined in \eqref{eq:q_ss} is a cap-based mechanism with $\msf{Cap}_{\svbx} = \cZ_{\svbx}$, $c_1(\varepsilon, d) = \dfrac{e^{\varepsilon}}{{ \binom{d-1}{s-1} }e^{\varepsilon}+{ \binom{d-1}{s} }}$, and $c_2(\varepsilon, d) = \dfrac{1}{{ \binom{d-1}{s-1} }e^{\varepsilon}+{ \binom{d-1}{s} }}$.

Further, $\Probability_{\svbz \sim \Unif(\cZ)}\lp \svbz \in \cZ_{\svbx} \rp = \dfrac{ \binom{d-1}{s-1}}{ \binom{d}{s}} = \frac{s}{d}$. Therefore,
\begin{align}
    \frac{c_1(\varepsilon, d)}{c_2(\varepsilon, d)} \times \Probability_{\svbz \sim \Unif(\cZ)}\lp \svbz \in \cZ_{\svbx} \rp = e^{\varepsilon} \times \frac{s}{d} \stackrel{(a)}{=}
    \frac{e^{\varepsilon}}{d} \times \lceil \frac{d}{1+e^\varepsilon}\rceil \geq \frac{e^{\varepsilon}}{d} \times \frac{d}{1+e^\varepsilon} \stackrel{(b)}{\geq} \frac{1}{2}
\end{align}
where $(a)$ follows by plugging in $s = \lceil \frac{d}{1+e^\varepsilon}\rceil$ and $(b)$ follows because $\varepsilon \geq 0$.
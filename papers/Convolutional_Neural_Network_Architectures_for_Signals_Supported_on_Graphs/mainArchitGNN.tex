\documentclass[journal]{IEEEtran}

%\\\\ PACKAGES

% Language
\usepackage[english]{babel}

% Utilities
\usepackage{ifpdf}

% Citation and Linking
\usepackage{cite} % Orders citations.
\usepackage{url}
\usepackage{hyperref}

% Graphics
\ifCLASSINFOpdf
	\usepackage[pdftex]{graphicx}
	\graphicspath{{./figures/}}
 	%\DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
	\usepackage[dvips]{graphicx}
	\graphicspath{./figures/}
	%\DeclareGraphicsExtensions{.eps}
\fi
\usepackage{color}
\usepackage{pgf, tikz, pgfplots}
\usetikzlibrary{shapes, arrows, automata}
\usetikzlibrary{calc,hobby,decorations}
%\usepackage[caption=false,font=footnotesize]{subfig}
%\usepackage{fixltx2e}
%\usepackage{stfloats}
%\usepackage{dblfloatfix}

% Math
\usepackage[cmex10]{amsmath}
\usepackage{amsfonts, amssymb, amsthm}
\usepackage{mathrsfs}
%\usepackage{upgreek}
% \usepackage{theorem} % OBS: "Enhance­ments to LATEX's theorem environments, giving more choice in theorem layout. This package is no longer recommended by its author; he suggests users should use the AMS LATEX amsthm package instead; another widely-used alternative is ntheoremq." https://www.ctan.org/pkg/theorem?lang=en 2015-08-04

% Lists
%\usepackage{algorithm,algorithmic}
%\usepackage[]{algorithm2e}
\usepackage{algorithm,algpseudocode}
	\algnewcommand{\LeftComment}[1]{\Statex \(\triangleright\) #1}

% Alignment
%\usepackage{array}
\usepackage{enumerate}
%\usepackage{caption}
\usepackage{multirow}
\usepackage{rotating}
\usepackage{subcaption}
	\captionsetup[sub]{font=footnotesize}
	\captionsetup[figure]{font=small,labelsep=period,subrefformat=parens}

% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}

\input{mySections.tex}
\input{mySymbol.sty}

% Definitions
\definecolor{penndarkestblue}{cmyk}{1,0.74,0,0.77}
	% RGB = (0,15,58); #000f3a
\definecolor{penndarkerblue}{cmyk}{1,0.74,0,0.70}
	% RGB = (0,20,77); #00144d
\definecolor{pennblue}{cmyk}{0.99,0.66,0,0.57} 
	% RGB = (1,37,110) ; #01256e
\definecolor{pennlighterblue}{cmyk}{0.98,0.44,0,0.35}
	% RGB = (4,94,167); #045ea7
\definecolor{pennlightestblue}{cmyk}{0.38,0.17,0,0.17} 
	% RGB = (130,175,211); #82afd3

\definecolor{penndarkestred}{cmyk}{0,1,0.89,0.66}
	% RGB = (87,0,10); #57000a
\definecolor{penndarkerred}{cmyk}{0,1,0.88,0.55}
	% RGB = (116,0,14); #74000e
\definecolor{pennred}{cmyk}{0,1,0.83,0.42} 
	% RGB = (149,0,26); #95001a
\definecolor{pennlighterred}{cmyk}{0,1,0.6,0.24}
	% RGB = (194,0,77); #c2004d
\definecolor{pennlightestred}{cmyk}{0,0.43,0.26,0.12} 
	% RGB = (225,128,166); #e180a6

\definecolor{penndarkestgreen}{cmyk}{1,0,1,0.68}
	% RGB = (0,82,0); #005200
\definecolor{penndarkergreen}{cmyk}{1,0,1,0.57}
	% RGB = (0,110,0); #006e00
\definecolor{penngreen}{cmyk}{1,0,1,0.44} 
	% RGB = (0,142,0); #008e00
\definecolor{pennlightergreen}{cmyk}{1,0,1,0.25}
	% RGB = (0,190,0); #00be00
\definecolor{pennlightestgreen}{cmyk}{0.43,0,0.43,0.13}
	% RGB = (128,223,128); #80df80

\definecolor{penndarkestorange}{cmyk}{0,0.65,1,0.49}
	% RGB = (129,45,0); #812d00
\definecolor{penndarkerorange}{cmyk}{0,0.65,1,0.33}
	% RGB = (172,60,0); #ac3c00
\definecolor{pennorange}{cmyk}{0,0.54,1,0.24} 
	% RGB = (195,90,0); #c35a00
\definecolor{pennlighterorange}{cmyk}{0,0.32,1,0.13}
	% RGB = (223,151,0); #df9700
\definecolor{pennlightestorange}{cmyk}{0,0.15,0.46,0.06}
	% RGB = (239,203,128); #efcb80
	
\definecolor{penndarkestpurple}{cmyk}{0,1,0.11,0.86}
	% RGB = (35,0,31); #23001f
\definecolor{penndarkerpurple}{cmyk}{0,1,0.13,0.82}
	% RGB = (47,0,41); #2f0029
\definecolor{pennpurple}{cmyk}{0,1,0.11,0.71} 
	% RGB = (74,0,66); #4a0042
\definecolor{pennlighterpurple}{cmyk}{0,1,0.05,0.46}
	% RGB= (137,0,130); #890082
\definecolor{pennlightestpurple}{cmyk}{0,0.35,0.02,0.23}
	% RGB = (196,128,193); #c480c1
	
\definecolor{pennyellow}{cmyk}{0,0.20,1,0.05} 
	% RGB = (242,193,0); #f2c100
\definecolor{pennlightgray1}{cmyk}{0,0,0,0.05}
	% RGB = (242,242,243); #f2f2f3
\definecolor{pennlightgray3}{cmyk}{0.01,0.01,0,0.18}
	% RGB = (207,208,210); #cfd0d2
\definecolor{pennmediumgray1}{cmyk}{0.04,0.03,0,0.31}
	% RGB = (168,170,175); #a8aaaf
\definecolor{pennmediumgray4}{cmyk}{0.08,0.06,0,0.54}
	% RGB = (108,111,118); #6c6f76
\definecolor{penndarkgray2}{cmyk}{0.09,0.07,0,0.71}
	% RGB = (68,70,75); #44464b
\definecolor{penndarkgray4}{cmyk}{0.1,0.1,0,0.92}
	% RGB = (19,19,21); #131315

\def\T{\mathsf{T}}
\def\Tr{\mathsf{T}}
\def\Hr{\mathsf{H}}
\def\nv{\textrm{nv}}
\def\hv{\textrm{hv}}
\def\dc{\text{dc}}


\newcommand*\mycirc[1]{%
	\begin{tikzpicture}
	\vspace{.4cm}
	\node[draw,circle,inner sep=1pt] {#1};
	\end{tikzpicture}}


\newtheorem{assumption}{\hspace{0pt}\bf AS\hspace{-0.15cm}}
\newtheorem{lemma}{\hspace{0pt}\bf Lemma}
\newtheorem{proposition}{\hspace{0pt}\bf Proposition}
\newtheorem{example}{\hspace{0pt}\bf Example}
\newtheorem{observation}{\hspace{0pt}\bf Observation}
\newtheorem{theorem}{\hspace{0pt}\bf Theorem}
\newtheorem{corollary}{\hspace{0pt}\bf Corollary}
\newtheorem{fact}{\hspace{0pt}\bf Fact}
\newtheorem{remark}{\hspace{0pt}\bf Remark}
\newtheorem{test}{\hspace{0pt}\it Test Case}
\newtheorem{definition}{\hspace{0pt}\bf Definition}

\begin{document}


\title{Convolutional Neural Network Architectures for Signals Supported on Graphs}

\author{Fernando~Gama,~%\IEEEmembership{Student~Member,~IEEE,}
        Antonio~G.~Marques,~%\IEEEmembership{Senior~Member,~IEEE,}
        Geert~Leus,~%\IEEEmembership{Fellow,~IEEE,}
        and~Alejandro~Ribeiro%,~\IEEEmembership{Member,~IEEE}% <-this % stops a space
\thanks{Supported by NSF CCF 1717120, ARO W911NF1710438, ARL DCIST CRA W911NF-17-2-0181, ISTC-WAS and Intel DevCloud; and Spain MINECO grants No TEC2013-41604-R and TEC2016-75361-R. F. Gama and A. Ribeiro are with the Dept. of Electrical and Systems Eng., Univ. of Pennsylvania., A. G. Marques is with the Dept. of Signal Theory and Comms., King Juan Carlos Univ., G. Leus is with the Dept. of Microelectronics, Delft Univ. of Technology.  Email: \{fgama,aribeiro\}@seas.upenn.edu, antonio.garcia.marques@urjc.es, and g.j.t.leus@tudelft.nl.
}
}


% Headers:
\markboth{IEEE TRANSACTIONS ON SIGNAL PROCESSING (ACCEPTED)}%
{Convolutional Neural Networks Architectures for Signals Supported on Graphs}

\maketitle

\begin{abstract}
Two architectures that generalize convolutional neural networks (CNNs) for the processing of signals supported on graphs are introduced. We start with the selection graph neural network (GNN), which replaces linear time invariant filters with linear shift invariant graph filters to generate convolutional features and reinterprets pooling as a possibly nonlinear subsampling stage where nearby nodes pool their information in a set of preselected sample nodes. A key component of the architecture is to remember the position of sampled nodes to permit computation of convolutional features at deeper layers. The second architecture, dubbed aggregation GNN, diffuses the signal through the graph and stores the sequence of diffused components observed by a designated node. This procedure effectively aggregates all components into a stream of information having temporal structure to which the convolution and pooling stages of regular CNNs can be applied. A multinode version of  aggregation GNNs is further introduced for operation in large scale graphs. An important property of selection and aggregation GNNs is that they reduce to conventional CNNs when particularized to time signals reinterpreted as graph signals in a circulant graph. Comparative numerical analyses are performed in a source localization application over synthetic and real-world networks. Performance is also evaluated for an authorship attribution problem and text category classification. Multinode aggregation GNNs are consistently the best performing GNN architecture.
% EDICS:
% 66. NEG-SPGR Signal processing over graphs (filtering, transforms, etc) < NEG SIGNAL PROCESSING FOR NETWORKS AND GRAPHS
% 39. MLR-DEEP Deep learning techniques < MLR MACHINE LEARNING
% Text-only abstract:
%Two architectures that generalize convolutional neural networks (CNNs) for the processing of signals supported on graphs are introduced. We start with the selection graph neural network (GNN), which replaces linear time invariant filters with linear shift invariant graph filters to generate convolutional features and reinterprets pooling as a possibly nonlinear subsampling stage where nearby nodes pool their information in a set of preselected sample nodes. A key component of the architecture is to remember the position of sampled nodes to permit computation of convolutional features at deeper layers. The second architecture, dubbed aggregation GNN, diffuses the signal through the graph and stores the sequence of diffused components observed by a designated node. This procedure effectively aggregates all components into a stream of information having temporal structure to which the convolution and pooling stages of regular CNNs can be applied. A multinode version of  aggregation GNNs is further introduced for operation in large scale graphs. An important property of selection and aggregation GNNs is that they reduce to conventional CNNs when particularized to time signals reinterpreted as graph signals in a circulant graph. Comparative numerical analyses are performed in a source localization application over synthetic and real-world networks. Performance is also evaluated for an authorship attribution problem and text category classification. Multinode aggregation GNNs are consistently the best performing GNN architecture.
\end{abstract}

\begin{IEEEkeywords}
deep learning, convolutional neural networks, graph signal processing, graph filters, pooling
\end{IEEEkeywords}

\IEEEpeerreviewmaketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% SECTION : Introduction  %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction} \label{sec_intro}

\input{introductionArchitGNN.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% SECTION : Regular CNNs  %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Convolutional Neural Networks} \label{sec:regular}

\input{regularGNN.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% SECTION : Selection   %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Selection Graph Neural Networks} \label{sec:selection}

\input{selectionGNN.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% SECTION : Aggregation   %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Aggregation Graph Neural Networks} \label{sec:aggregation}

\input{aggregationGNN.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% SECTION : Simulations   %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Numerical Experiments} \label{sec:sims}

\input{experimentsArchitGNN.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% SECTION : Conclusions   %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Conclusions} \label{sec_conclusions}

\input{conclusionsArchitGNN.tex}

\bibliographystyle{IEEEtran}
\bibliography{myIEEEabrv,biblioArchitGNN}

%\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{pictures/Gama.jpg}}]{Fernando Gama}
%	received the electronic engineer degree from the University of Buenos Aires, Argentina, in 2013, and the M.A. degree in statistics from the Wharton School, University of Pennsylvania, Philadelphia, PA, USA, in 2017. He is currently working towards the Ph.D. degree with the Department of Electrical and Systems Engineering, at the University of Pennsylvania. He has been a visiting researcher at TU Delft, the Netherlands, in 2017 and a research intern at Facebook Artificial Intelligence Research, Montreal, Canada, in 2018. His research interests are in the field of information processing and machine learning over network data. He has been awarded a Fulbright scholarship for international students.
%\end{IEEEbiography}
%
%\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{pictures/Marques.jpg}}]{Antonio G. Marques}
%	received the telecommunications engineering degree and the Doctorate degree, both with highest honors, from the Carlos III University of Madrid, Spain, in 2002 and 2007, respectively. In 2007, he became a faculty of the Department of Signal Theory and Communications, King Juan Carlos University, Madrid, Spain, where he currently develops his research and teaching activities as an Associate Professor. From 2005 to 2015, he held different visiting positions at the University of Minnesota, Minneapolis. In 2015 and 2016 he was a visitor scholar at the University of Pennsylvania, Philadelphia. 
%	
%	His current research focuses on nonlinear and stochastic optimization of wireless and power networks, signal processing for graphs, and data science for networks. Dr. Marques has served the IEEE in a number of posts (currently, he is an Associate Editor of the Signal Process. Letters, a member of the IEEE Signal Process. Theory and Methods Tech. Comm., a member of the IEEE Signal Process. Big Data Special Interest Group, and the General Co-chair of the 2019 IEEE Data Science Workshop). His work has been awarded in several conferences and workshops, with recent ones including IEEE SSP 2016, IEEE SAM 2016 and Asilomar 2015.
%\end{IEEEbiography}
%
%\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{pictures/Leus.jpg}}]{Geert Leus}
%	received the M.Sc. and Ph.D. degree in Electrical Engineering from the KU Leuven, Belgium, in June 1996 and May 2000, respectively. Geert Leus is now an "Antoni van Leeuwenhoek" Full Professor at the Faculty of Electrical Engineering, Mathematics and Computer Science of the Delft University of Technology, The Netherlands. His research interests are in the broad area of signal processing, with a specific focus on wireless communications, array processing, sensor networks, and graph signal processing. Geert Leus received a 2002 IEEE Signal Processing Society Young Author Best Paper Award and a 2005 IEEE Signal Processing Society Best Paper Award. He is a Fellow of the IEEE and a Fellow of EURASIP. Geert Leus was a Member-at-Large of the Board of Governors of the IEEE Signal Processing Society, the Chair of the IEEE Signal Processing for Communications and Networking Technical Committee, a Member of the IEEE Sensor Array and Multichannel Technical Committee, and the Editor in Chief of the EURASIP Journal on Advances in Signal Processing. He was also on the Editorial Boards of the IEEE Transactions on Signal Processing, the IEEE Transactions on Wireless Communications, the IEEE Signal Processing Letters, and the EURASIP Journal on Advances in Signal Processing. Currently, he is the Vice-Chair of the EURASIP Special Area Team on Signal Processing for Multisensor Systems, an Associate Editor of Foundations and Trends in Signal Processing, and the Editor in Chief of EURASIP Signal Processing.
%\end{IEEEbiography}
%
%\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{pictures/Ribeiro.jpg}}]{Alejandro Ribeiro}
%	received the B.Sc. degree in electrical engineering from the Universidad de la Republica Oriental del Uruguay, Montevideo, in 1998 and the M.Sc. and Ph.D. degree in electrical engineering from the Department of Electrical and Computer Engineering, the University of Minnesota, Minneapolis in 2005 and 2007. From 1998 to 2003, he was a member of the technical staff at Bellsouth Montevideo. After his M.Sc. and Ph.D studies, in 2008 he joined the University of Pennsylvania (Penn), Philadelphia, where he is currently the Rosenbluth Associate Professor at the Department of Electrical and Systems Engineering. His research interests are in the applications of statistical signal processing to the study of networks and networked phenomena. His focus is on structured representations of networked data structures, graph signal processing, network optimization, robot teams, and networked control. Dr. Ribeiro received the 2014 O. Hugo Schuck best paper award, and paper awards at CDC 2017, 2016 SSP Workshop, 2016 SAM Workshop, 2015 Asilomar SSC Conference, ACC 2013, ICASSP 2006, and ICASSP 2005. His teaching has been recognized with the 2017 Lindback award for distinguished teaching and the 2012 S. Reid Warren, Jr. Award presented by Penn's undergraduate student body for outstanding teaching. Dr. Ribeiro is a Fulbright scholar class of 2003 and a Penn Fellow class of 2015.
%\end{IEEEbiography}

\end{document}

% !TEX root = supplementary.tex

\section{Theory}\label{sec:theory}
Here, we examine the complexity of the inversion problem and prove the correctness of NaMI's graph inversion.

\subsection{Inversion complexity}\label{sec:problem-hardness}
To understand the theoretical gains we obtain, it is useful to compare it with a simpler, but suboptimal, alternate that uses the d-separation properties of a BN structure to form a minimally faithful inverse.
By the general product rule, any distribution over $\mathbf{y}=\{y_1,\ldots,y_n\}$ can be factored as
$p(\mathbf{y}) = \prod_{i=1}^np(y_i\mid y_1,\ldots,y_{i-1})$,
for any ordering of $\mathbf{y}$.
The conditioning sets, $\{y_1,\ldots,y_{i-1}\}$, can be restricted according to the conditional independence assertions made by $p$.
To produce a minimal I-map, they can be restricted as
$p(\mathbf{y}) = \prod_{i=1}^np(y_i\mid \tilde{\mathbf{y}_i}\subseteq\{y_1,\ldots,y_{i-1}\})$
where $\tilde{\mathbf{y}_i}$ is a minimal subset such that $y_i\perp(\{y_1,\ldots,y_{i-1}\}\setminus\tilde{\mathbf{y}_i})\mid\tilde{\mathbf{y}_i}$.

Consequently, one could instead produce a minimally faithful inverse for $p(\mathbf{z}\mid\mathbf{x})p(\mathbf{x})$ as follows.
Set $\mathbf{y}=(\mathbf{z},\mathbf{x})$ to have an arbitrary topological ordering on $\mathbf{z}$ and $\mathbf{x}$, separately.
Initialize $\tilde{\mathbf{y}_i}=\{y_1,\ldots,y_{i-1}\}$.
Scan through $y_j\in\tilde{\mathbf{y}_i}$, removing each one if $y_i\perp y_j\mid\tilde{\mathbf{y}_i}\setminus\{y_j\}$, repeating until none can be removed and $\tilde{\mathbf{y}_i}$ is a minimal subset.

In the worst case for this naive approach, we must scan through $O(n^2)$ variables $n$ times, and the cost of determining whether to remove a variable from $\tilde{\mathbf{y}_i}$ is $O(n)$ \citep[Algorithm 3.1]{KollerFriedman2009}.
Thus, this naive method has running time $O(n^4)$.
NaMI's graph reversal, in contrast has a running time of order $O(nc)$ where $n$ is the number of variables in the graph and $c<<n$ is the size of the largest clique in the induced graph.

\subsection{Proof of correctness}\vspace{3pt}
\begin{theorem}\label{theorem:correctness}
	The Natural Minimal I-Map Generator of Algorithm 1 produces inverse factorizations that are natural and minimally faithful.
\end{theorem}\vspace{-11pt}
\begin{proof}

As in the main paper, let $\tau$ denote the reverse of the order in which variables were selected for elimination
such that $\tau$ is a permutation of $1,\dots,n$ and $\tau(n)$ is the first variable eliminated.  

We first show that inverse structure $\mathcal{H}$ produced by Algorithm 1 is guaranteed to be a valid inverse factorization, that is, it factors as
\begin{align}
\label{eq:H-fact}
q_\psi(\mathbf{z}\mid\mathbf{x})=\prod^n_{i=1} q_{i}(z_{\tau(i)}\mid\text{Pa}_\mathcal{H}(z_{\tau(i)}))
=\prod^n_{i=1} q_{i}(z_{\tau(i)}\mid\text{Pa}_\mathcal{H}(z_{\tau(i)}),\mathbf{x})
\end{align}
where $\mathbf{z}$ and $\mathbf{x}$ are the observed and latent variables, and
$\text{Pa}_\mathcal{H}(z_{\tau(i)})\subseteq\left\{\mathbf{x},z_{\tau(1)},\dots,z_{\tau(i-1)}\right\}$ indicates the parents of $z_{\tau(i)}$ in $\mathcal{H}$.
There are two critical features this factorization encapsulates that we need to demonstrate to show
  $\mathcal{H}$ provides a valid  inverse factorization: $\mathbf{x}$ only appears in the conditioning variables (i.e. 
  there are no density terms over observations) and all terms can, if desired, be conditioned on the full
  set of observations.  
  
  The former of these straightforwardly always holds, since we only add edges \emph{into} latent variables when the inverse, $\mathcal{H}$, is constructed (Line 11 in Algorithm 1). Therefore, the algorithm can never add in edges \emph{to} an observed node.  
  
  The latter is more subtle, as NaMI may produce factors which are not explicitly
  conditioned on all the observations.  However, because, as we demonstrate later, the inversion is faithful, the
  corresponding $z_{\tau(i)}$ must be conditionally independent of the all observations which are not parent nodes, given
  the state of the parent nodes.  In other words, if the inversion is faithful, this ensures that 
  each $q_{i}(z_{\tau(i)}\mid\text{Pa}_\mathcal{H}(z_{\tau(i)}))=
  q_{i}(z_{\tau(i)}\mid\text{Pa}_\mathcal{H}(z_{\tau(i)}),\mathbf{x})$, and
  thus that we have a valid inverse factorization.

Next, we prove that Algorithm 1 produces natural inverses. A general observation is that if $z_i$ is eliminated after $z_j$, there cannot be an edge from $z_j$ to $z_i$ in $\mathcal{H}$.
When the algorithm is run in topological mode, variable elimination is simulated in a topological ordering, and so all of a variable's descendants are eliminated after it is.
Therefore there cannot be an edge from a variable to its descendant, and hence the factorization is natural. An equivalent argument applies when the algorithm is run in the reverse topological mode.

Finally, we prove that the inverse factorization is minimally faithful. At a high-level, our proof consists of
showing an equivalence to a process where we
start with a fully connected graph over the variables and sequentially prune edges in the graph according to
the independencies revealed by the clique tree generated from simulating variable elimination, 
terminating when no more edges can be pruned.  
By showing that
each individual pruning never induces an unfaithful independence, we are able to demonstrate that the graphs at
each iteration of this process---including the final inverse graph---is faithful, while minimality follows from 
the fact that the process terminates when it is not possible to prune any given edge.

More precisely, by the general product rule, 
$p(\mathbf{z}|\mathbf{x})=\prod^n_{i=1}p(z_{\tau(i)}|z_{\tau(<i)},\mathbf{x})$,
where $z_{\tau(<i)}=\{z_{\tau(1)},\ldots,z_{\tau(i-1)}\}$,
for any possible $\tau$,
and any graph with this factorization is an I-map for the posterior. Each term can be simplified according the conditional independencies encoded by the posterior and the corresponding graph will still be an I-map for the posterior. For instance, if $z_{\tau(i)}$ is independent of $\{z_{\tau(1)}, \ldots,z_{\tau(i-2)}\}$ given $\{z_{\tau(i-1)},\mathbf{x}\}$, then $p(z_{\tau(i)}|z_{\tau(<i)},\mathbf{x})=p(z_{\tau(i)}|z_{\tau(i-1)},\mathbf{x})$. %, which corresponds to removing the 
By definition, the variable elimination is run in the opposite order to $\tau$.
This produces a unique corresponding
clique tree (see Appendix A.5). Furthermore, because we introduce a new factor at each iteration, the
number of cliques in this clique tree matches the number of latent variables in the original BN, with each
clique being associated with the corresponding variable that was eliminated at that iteration (though the
clique itself may contain multiple variables).  We can thus define $C_{\tau(i)}$ as the unique clique
corresponding to the elimination of $z_{(\tau(i))}$.  Further, we can define $S_{\tau(i)}$ as the sepset between
$C_{\tau(i)}$ and $C_{\tau(i+1)}$, i.e. the set of variables shared between these two cliques.
By the correspondence between clique trees and induced graphs, $S_{\tau(i)}$ is exactly the unmarked neighbours of $z_{\tau(i)}$ in the partially constructed induced graph at step $n+1-i$.  
Therefore, setting the parents of $z_{\tau(i)}$ to be its unmarked neighbours in Line 11 of Algorithm 1 constructs $\mathcal{H}$ with the factorization
\begin{align}
\label{eq:qfact}
q_\psi(\mathbf{z}\mid\mathbf{x})=\prod_{i=1}^{n} q_{i}(z_{\tau(i)}\mid S_{\tau(i)}),
\end{align}
which is of the form of~\eqref{eq:H-fact} with $\text{Pa}_\mathcal{H}(z_{\tau(i)})=S_{\tau(i)}$.

By construction, all $z_{\tau(>i)}=\{z_{\tau(i+1)},\ldots,z_{\tau(n)}\}$ 
are upstream in the clique tree from $z_{\tau(i)}$ (and thus downstream in the factorization), meaning they
will never be included by $S_{\tau(i)}$ .  Furthermore, the sepset property of
clique trees \citep[Theorem 10.2]{KollerFriedman2009} guarantees that
 $z_{\tau(i)}$ is independent from $z_{\tau(<i)}\setminus S_{\tau(i)}$ given $S_{\tau(i)}$.
Therefore, we have that $p(z_{\tau(i)}\mid S_{\tau(i)})=p(z_{\tau(i)}\mid z_{\tau(<i)},\mathbf{x})$ for
each variable and so
\begin{align}
p(\mathbf{z}\mid\mathbf{x})=\prod^n_{i=1}p(z_{\tau(i)}\mid z_{\tau(<i)},\mathbf{x})=\prod^n_{i=1}p(z_{\tau(i)}\mid S_{\tau(i)}).
\end{align}
This is the same as the factorization produced by NaMI, as given in~\eqref{eq:qfact}, and so we conclude
that $\mathcal{H}$ is an I-Map of $\mathcal{G}$ and thus a faithful inverse.

The minimality now follows from the fact that the sepset $S_{\tau(i)}$ is also the minimal separating set (see, e.g., the proof of \citep[Theorem 4.12]{KollerFriedman2009}).  In other words, for each $i$, there is no $T_i\subsetneq S_{\tau(i)}$ such
that $p(z_{\tau(i)}\mid T_i) = p(z_{\tau(i)}\mid S_{\tau(i)})$. 
Suppose we were to remove an edge, $z_{\tau(i)}\leftarrow y_j$, from $\mathcal{H}$, where
$y_j \in \{\mathbf{x},z_{\tau(<i)}\}$ (remembering that by construction we have no edges from $z_{\tau(>i)}$ to $z_{\tau(i)}$). This edge would have been constructed due to sepset $S_{\tau(i)}$.
If removing the edge did not make $\mathcal{H}$ unfaithful to $\mathcal{G}$, then this would imply that
$p(z_{\tau(i)}\mid S_{\tau(i)}\setminus\{y_j\}) = p(z_{\tau(i)}\mid S_{\tau(i)})$ as none of the other
factors will change.  But we have already shown this is not possible.
Hence, by contradiction, $\mathcal{H}$ is minimally faithful.
\end{proof}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:

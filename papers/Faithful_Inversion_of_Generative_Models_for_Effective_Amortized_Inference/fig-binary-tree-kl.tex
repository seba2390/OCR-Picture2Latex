\begin{figure}[t]
  \centering
  \subcaptionbox{\label{fig:binary-tree-kl-train}}%
  {\includegraphics[width=0.33\textwidth]{binary_tree_d_5_train.pdf}}%
  \,%
  \subcaptionbox{\label{fig:binary-tree-kl-test}}%
  {\includegraphics[width=0.33\textwidth]{binary_tree_d_5_test.pdf}}%
  \,%
  \subcaptionbox{\label{fig:binary-tree-kl-posterior}}%
  {\includegraphics[width=0.33\textwidth]{binary_tree_d_5_posterior.pdf}}%
  \vspace{-1ex}
  \caption[Results for binary trees]{
    Results for binary tree Gaussian BNs with depth $d=5$, comparing inference network factorizations in the compiled inference setting.
    The KL divergence from the analytical posterior estimated to the inference network on the training and test sets are shown
    in (a) and (b) respectively.
    (c) shows the average negative log-likelihood of inference network samples under the analytical posterior, conditioning on five held-out data sets.
    The results are averaged over 10 runs and 0.75 standard deviations indicated.
		The drop at 100 epochs is due to decimating the learning rate.}
 \vspace{-2.5ex}
  \label{fig:binary-tree-kl}
\end{figure}

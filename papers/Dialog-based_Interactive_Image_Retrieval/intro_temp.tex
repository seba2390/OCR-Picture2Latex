\section{Introduction}

The volume of searchable media has grown tremendously in recent years, and has intensified the need for retrieval systems that can more effectively identify relevant information, with applications in domains such as e-commerce~\cite{huang2015cross,liuLQWTcvpr16DeepFashion}, video surveillance~\cite{vaquero2009attribute,shi2015transferring}, and internet search~\cite{gordo2016deep,jegou2012aggregating}. Despite significant progress made %in visual recognition and search
with deep learning methods~\cite{krizhevsky2012imagenet,wang2014learning,gordo2017end}, achieving high performance in such %image
search systems remains a challenge, due to the well-known {\em semantic gap} between feature representations and high-level semantic concepts, as well as the difficulty of fully understanding the user's search intent. 

A typical approach to improve search efficacy is to 
allow the user a constrained set of possible interactions with the system~\cite{zhou2003relevance,thomee2012interactive}. 
In particular, the user provides iterative feedback about retrieved media objects, so that the system can refine the results, 
allowing the user and system to engage in a ``conversation'' 
to resolve what the user wants to retrieve.
For example, as shown in Figure~\ref{fig:teaser},
feedback about relevance~\cite{rui1998relevance}
enables the user to indicate what media objects are ``similar'' or ``dissimilar'' to the user's 
desired object, while relative attribute feedback~\cite{kovashka2012} enables comparison of the desired object with candidate objects based on a fixed set of attributes. 
While these feedback paradigms are effective, the restricted forms of feedback may largely constrain the information that a user can convey to improve the retrieval process.

In this work, we propose a new approach to interactive media search by introducing a {\em novel form of user feedback based on natural language}, which we call dialog-based interactive retrieval.
%which enables users to provide feedback using natural language. 
The proposed approach enables users to directly express, in natural language, the most significant conceptual differences between their preferred object and the objects that have already been retrieved. 
%greatly advances the system's capability to exploit the rich information
%that users can provide, by allowing them 
We formulate learning the task of a retrieval agent as a reinforcement learning (RL) problem, and train
a dialog system that takes natural language responses as user input, and produces retrieved media objects as output. We train this system by directly optimizing the rank of the target object, which is a non-differentiable objective.
To avoid the cumbersome, inefficient, and costly process of collecting and annotating human-machine dialogs as the system learns, we utilize a model-based RL approach by training a user simulator based on a corpus of human-written relative descriptions. 
Specifically, to emulate a single dialog turn, where the user provides feedback regarding a candidate object relative to what the user has in mind, the simulated user generates a {\em relative caption} describing the differences between a retrieved candidate object and the user's desired object. 
\footnote{In this work, the user simulator is trained on single-turn data. This reduces the history of responses to a ``bag'' of responses, and implies that all sequences of a given set of actions (returned objects) are equivalent. Nevertheless, the process of localizing the target object still hinges on feedback from the user: while the object responses that maximize future reward (target image rank) are a set, the process of building an instance of the set naturally hinges on all previous feedback from the user, and so this set can be efficiently constructed sequentially.}
Whereas there is much prior work in image
captioning~\cite{kulkarni2011baby,vinyals2015show,rennie2016self}, to our knowledge we are the first to explore the problem of {\em relative %image 
captioning}, a general approach to more expressive and natural communication of relative preferences to machines, and use it as part of a user simulator to train a dialog system.
 
\begin{figure}[t]
\begin{center}
\includegraphics[width=\linewidth]{figs/teaser3.pdf}
\end{center}
\caption{In the context of interactive image retrieval, the agent incorporates the user's 
feedback to iteratively refine retrieval results. Unlike existing works based on relevance feedback or relative attribute feedback, our approach 
allows the user to provide feedback in natural language. 
\vspace{-0.05em}
}
\label{fig:teaser}
\end{figure}

The efficacy of our approach is evaluated in a real-world application
scenario of interactive footwear retrieval. Experimental results with both real and simulated users show that the proposed RL
framework achieves better accuracy than existing retrieval techniques. 
In particular, we show that feedback based on natural language is more effective than existing 
systems based on pre-defined relative attributes, and furthermore that our RL approach of 
directly optimizing the rank of the target image outperforms triplet loss by a large margin. 

The main contributions of this work are as follows:

% \begin{itemize}
% \item A novel approach to interactive media search, called dialog-based interactive media retrieval, %allowing users to give natural language feedback. %\textcolor{red}{Steve: we should name it.}
% guided by natural language feedback from users.
% \item An end-to-end deep dialog manager framework for interactive %image
% retrieval using natural language, which is learned via an efficient policy optimization strategy based on ``triplet loss'' and model-based policy improvement \cite{sutton1998reinforcement}.
% \item The introduction of a novel vision task, \emph{relative image captioning}, 
% where the generated captions can describe the visual differences between two images, 
% and the contribution of the first dataset which supports further research on the task
% of relative image captioning.
% % \item The use of a relative captioning system as a user simulator when training the dialog-based image retriever, which alleviates the need to collect human-machine conversations.
% \end{itemize}

\begin{itemize}
\item A novel machine learning problem setting, called \emph{learning dialog-based interactive media retrieval}.  In this setting, a dialog-manager agent learns how to interact with a human user over the course of several dialog rounds, where in each round, the user gives a request in natural language, and the agent returns a media object appropriate to the user request. 

\item A novel end-to-end deep-learning architecture which successfully addresses the above problem setting.  Training is based on an efficient policy optimization strategy, employing model-based policy
improvement~\cite{sutton1998reinforcement} and an appropriate loss function, e.g., ``triplet loss'' as used in computer vision.

\item The introduction of a novel multi-modal labeling task, which we call~\emph{relative captioning}, 
where the generated captions describe salient differences between two media objects.

\item A novel learning algorithm for the above task of relative captioning.

\item The contribution of the first dataset, to our knowledge, which is suitable and effective for learning the task of relative captioning.
% \item The use of a relative captioning system as a user simulator when training the dialog-based image retriever, which alleviates the need to collect human-machine conversations.
\end{itemize}




\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{fullpage}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{epsfig}
\usepackage{epstopdf}
\usepackage{mathtools}
\usepackage{relsize}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,     % false: boxed links; true: colored links
    linkcolor=blue,     % color of internal links (change box color with linkbordercolor)
    citecolor=blue,     % color of links to bibliography
}
\usepackage[numbers,sort&compress]{natbib}
\usepackage{enumitem}
\usepackage{algorithm,algpseudocode}
\usepackage{setspace}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{xspace}
\usepackage{authblk}
\usepackage{dsfont}
\usepackage{multicol}
\usepackage[export]{adjustbox}
\usepackage{thmtools,thm-restate}
\usepackage{xcolor}


\title{Optimality-Based Discretization Methods for the Global Optimization of Nonconvex Semi-Infinite Programs}

\date{February 28, 2023}

\author[1]{Evren M. Turan}
\author[1]{Johannes J\"aschke}
\author[2]{Rohit Kannan}
\affil[1]{Department of Chemical Engineering, Norwegian University of Science and Technology (NTNU), \protect\\ Trondheim, Norway. E-mail: evren.m.turan@ntnu.no, johannes.jaschke@ntnu.no}
\affil[2]{Center for Nonlinear Studies (T-CNLS) and Applied Mathematics \& Plasma Physics (T-5), \protect\\ Los Alamos National Laboratory, Los Alamos, NM, USA. E-mail: rohitk@alum.mit.edu}
\renewcommand\Affilfont{\small}
 
 


\newcounter{mycounter}

\renewcommand{\labelenumii}{\alph{enumii}.}
\setlength{\leftmarginii}{4mm}

 
\newcommand{\Set}[2]{\left\lbrace #1 : #2 \right\rbrace}
\newcommand{\minf}[1]{\min\left\lbrace #1 \right\rbrace}
 
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\DeclareMathOperator*{\esssup}{ess\,sup}

\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

\newcommand{\Mod}[1]{\ (\mathrm{mod}\ #1)}



\newcommand{\tr}[1]{\ensuremath{{#1}^\text{T}}}

\newcommand{\uset}[2]{\ensuremath{\underset{#1}{#2}}}

\newcommand{\ml}[1]{\ensuremath{\mathlarger{#1}}}


\DeclarePairedDelimiter\abs{\lvert}{\rvert}%
\DeclarePairedDelimiter\norm{\lVert}{\rVert}%


\newcommand{\prob}[1]{\mathbb{P}\left\lbrace{#1}\right\rbrace}
\newcommand{\pr}{\mathbb{P}}
\newcommand{\expect}[1]{\mathbb{E}\left[{#1}\right]}
\newcommand{\expv}{\mathbb{E}}
\newcommand{\expectation}[2]{\mathbb{E}_{#1}\hspace*{-0.02in}\left[{#2}\right]}
\newcommand{\lsc}{\text{l.s.c.}}
\newcommand{\dev}[2]{\mathbb{D}\left({#1},{#2}\right)}
\newcommand{\supp}[1]{\text{supp}\left( #1 \right)}
\newcommand{\convinprob}{\xrightarrow{p}}


\newcommand{\A}{\mathcal{A}}
\newcommand{\D}{\mathcal{D}}
\newcommand{\E}{\mathcal{E}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\I}{\mathcal{I}}
\newcommand{\J}{\mathcal{J}}
\newcommand{\Linf}{L^{\infty}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Otp}{\tilde{O}_p}
\newcommand{\otp}{\tilde{o}_p}
\newcommand{\Q}{\mathcal{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Rbar}{\overline{\mathbb{R}}}
\newcommand{\hS}{\hat{S}}
\newcommand{\X}{\mathcal{X}}
\newcommand{\Y}{\mathcal{Y}}
\newcommand{\Z}{\mathcal{Z}}

\newcommand{\hf}{\hat{f}}
\newcommand{\hg}{\hat{g}}
\newcommand{\hQ}{\hat{Q}}
\newcommand{\homega}{\hat{\omega}}
\newcommand{\heps}{\hat{\varepsilon}}
\newcommand{\teps}{\tilde{\varepsilon}}
\newcommand{\beps}{\bar{\varepsilon}}
\newcommand{\bth}{\bar{\theta}}
\newcommand{\hth}{\hat{\theta}}
\newcommand{\hpi}{\hat{\pi}}
\newcommand{\sth}{\theta^*}
\newcommand{\spi}{\pi^*}
\newcommand{\hv}{\hat{v}}
\newcommand{\hx}{\hat{x}}
\newcommand{\bx}{\bar{x}}
\newcommand{\by}{\bar{y}}
\newcommand{\bz}{\bar{z}}
\newcommand{\hz}{\hat{z}}
\newcommand{\tz}{\tilde{z}}

\newcommand{\dimx}{d_x}
\newcommand{\dimz}{d_z}
\newcommand{\dimt}{d_{\theta}}
\newcommand{\Nmi}{N\backslash i}





\newcommand{\proj}[2]{\operatorname{proj}_{#1}(#2)}
\newcommand{\1}[1]{\mathds{1}\left[#1\right]}


\providecommand{\keywords}[1]
{
  \small	
  \textbf{Key words:} #1
}



%%%%%%% THEOREMS %%%%%%%

\newtheorem{theorem}{Theorem}[]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{assumption}{Assumption}[]
\newtheorem{remark}{Remark}
\newtheorem{definition}{Definition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{example}{Example}
\newtheorem{conjecture}[theorem]{Conjecture}

\let\oldtheorem\theorem
\renewcommand{\theorem}{\oldtheorem\normalfont}

\let\oldlemma\lemma
\renewcommand{\lemma}{\oldlemma\normalfont}

\let\oldassumption\assumption
\renewcommand{\assumption}{\oldassumption\normalfont}

\let\oldremark\remark
\renewcommand{\remark}{\oldremark\normalfont}

\let\olddefinition\definition
\renewcommand{\definition}{\olddefinition\normalfont}

\let\oldcorollary\corollary
\renewcommand{\corollary}{\oldcorollary\normalfont}

\let\oldproposition\proposition
\renewcommand{\proposition}{\oldproposition\normalfont}

\let\oldexample\example
\renewcommand{\example}{\oldexample\normalfont}

\let\oldconjecture\conjecture
\renewcommand{\conjecture}{\oldconjecture\normalfont}

  
  


\setlength{\bibsep}{3pt}











\begin{document}



\maketitle


\begin{abstract}
We use sensitivity analysis to design \textit{optimality-based} discretization (cutting-plane) methods for the global optimization of nonconvex semi-infinite programs (SIPs).
We begin by formulating the optimal discretization of SIPs as a max-min problem and propose variants that are more computationally tractable.
We then use parametric sensitivity theory to design an efficient method for solving these max-min problems to local optimality and argue this yields valid discretizations without sacrificing global optimality guarantees.
Finally, we formulate optimality-based \textit{generalized} discretization of SIPs
as max-min problems and design efficient local optimization algorithms to solve them approximately.
Numerical experiments on test instances from the literature demonstrate that our new optimality-based discretization methods can significantly reduce the number of iterations for convergence relative to the classical feasibility-based method. \\[0.1in]
\keywords{Semi-infinite programming, Robust optimization, Discretization, Global optimization, Cutting-planes, Sensitivity analysis}
\end{abstract}




\section{Introduction}
\label{sec: intro}


Semi-infinite programs (SIPs) are mathematical optimization problems with a finite number of decision variables and an infinite number of constraints, with the infinite set of constraints in a SIP typically parametrized using a finite-dimensional parameter. 
They can be used to model several problems in science and engineering such as robust optimization, controller design, Chebyshev approximation, and design centering~\cite{grossmann1983optimization,turan2022design,lopez2007semi,djelassi2021recent}.
There are many surveys and books on semi-infinite programming, see, e.g.,~\cite{hettich1993semi,lopez2007semi,polak2012optimization,reemtsen1998semi,stein2012solve,djelassi2021recent,goberna2002linear,stein2003bi} for theory, algorithms, and applications.
Our focus in this paper is on the \textit{global} optimization of SIPs.


We consider the semi-infinite program
\begin{align}
\label{eqn:sip}
v^* := \min_{x \in X} \:\: & f(x) \tag{SIP} \\
\text{s.t.} \:\: & g(x,y) \leq 0, \quad \forall y \in Y, \label{eqn:sic}
\end{align}
where $X \subset \R^{d_x}$ and $Y \subset \R^{d_y}$ are nonempty compact sets, $\abs{Y} = \infty$, and functions $f: \R^{d_x} \to \R$ and $g: \R^{d_x} \times \R^{d_y} \to \R$ are continuous.
We assume \eqref{eqn:sip} is feasible for simplicity, but do not necessarily assume $X$, $Y$, $f$, or $g$ is convex.
While we only consider a scalar semi-infinite constraint~\eqref{eqn:sic} for ease of exposition, Section~\ref{sec:generalizations} details a generalization to multiple such constraints.
A key challenge in solving~\eqref{eqn:sip} is that even evaluating feasibility of a candidate solution $x \in X$ requires the \textit{global} solution of the following lower-level problem:
\begin{align}
\label{eqn:llp}
G(x) := \max_{y \in Y} \: g(x,y). \tag{LLP($x$)}
\end{align}
Clearly, $x \in X$ is feasible for~\eqref{eqn:sip} if and only if $G(x) \leq 0$.
Let $y^* : X \to Y$ be \textit{any} mapping such that $y^*(x)$ is an optimal solution to~\eqref{eqn:llp} for each $x \in X$.
Then $G(\cdot) \equiv g(\cdot,y^*(\cdot))$ on $X$ and~\eqref{eqn:sip} can be equivalently written as
\begin{align}
\label{eqn:bilevel_reform}
\min_{x \in X} \:\: & f(x) \\
\text{s.t.} \:\: & g(x,y^*(x)) \leq 0. \nonumber
\end{align}
The above reformulation highlights the fact that semi-infinite programming is a special case of bilevel optimization~\cite{dempe2002foundations,stein2003bi}.


Several papers in the last two decades propose algorithms for the \textit{global} minimization of nonconvex SIPs~\cite{bhattacharjee2005global,floudas2008adaptive,mitsos2008relaxation,mitsos2011global,tsoukalas2011feasible,stein2012adaptive,djelassi2017hybrid,marendet2020standard} (see Djelassi et al.\ \cite{djelassi2020discretization,djelassi2021recent} for a recent survey). 
Most of these approaches construct lower bounds for~\eqref{eqn:sip} by replacing the semi-infinite constraint~\eqref{eqn:sic} with a \textit{finite} discretization
\begin{align}
\label{eqn:disc-lbp}
\min_{x \in X} \:\: & f(x) \tag{LBP} \\
\text{s.t.} \:\: & g(x,y) \leq 0, \quad \forall y \in Y_d, \nonumber
\end{align}
where $Y_d \subsetneq Y$ with $\abs{Y_d} < \infty$.
The above lower bounding problem~\eqref{eqn:disc-lbp} is related to the classical cutting-plane method of Cheney and Goldstein~\cite{cheney1959newton} and Kelley~\cite{kelley1960cutting} in convex optimization.
A valid lower bound for the optimal value $v^*$ of~\eqref{eqn:sip} can be obtained by solving this (nonconvex) relaxation to {\it global} optimality.
Additionally, under mild conditions, the optimal value of a sequence of iteratively refined discretizations~\eqref{eqn:disc-lbp} converges to $v^*$~\cite{lopez2007semi}.


The choice of discretization $Y_d$ can greatly impact the tightness of the lower bound obtained by solving~\eqref{eqn:disc-lbp}.
Because na\"ive discretization approaches may require a large discretization $Y_d$ for the optimal value of~\eqref{eqn:disc-lbp} to approximate $v^*$ well~\cite{still2001discretization}, techniques for adaptively populating~$Y_d$ are of interest.
Most approaches for the global minimization of~\eqref{eqn:sip} rely on the adaptive \textit{feasibility-based} discretization method of Blankenship and Falk (BF, outlined in Algorithm~\ref{alg:bfdisc})~\cite{blankenship1976infinitely}, which populates $Y_d$ with points in $Y$ corresponding to the largest violation of constraint~\eqref{eqn:sic} at incumbent solutions of~\eqref{eqn:disc-lbp}.



\begin{algorithm}[t]
\caption{The Blankenship and Falk algorithm \cite{blankenship1976infinitely}}
\label{alg:bfdisc}
{
\begin{algorithmic}[1]
\State \textbf{Input} feasibility tolerance $\varepsilon_f \geq 0$.

\State \textbf{Initialize} $Y_d = \emptyset$.

\For{$k = 1, 2, \dots$}

\State Solve problem~\eqref{eqn:disc-lbp} globally to get solution $x^k$, lower bound $LBD^k$.

\State Solve problem~\eqref{eqn:llp} with $x = x^k$ globally to get solution $y^{BF,k} \in Y$.

\If{$G(x^k) \leq \varepsilon_f$}

\State \textbf{Terminate} with $\varepsilon_f$-feasible solution $x^k$ to~\eqref{eqn:sip}.

\Else

\State Set $Y_d \leftarrow Y_d \cup \{ y^{BF,k} \}$.

\EndIf

\EndFor

\end{algorithmic}
}
\end{algorithm}




The sequence of non-decreasing lower bounds $\{LBD^k\}$ generated by the BF algorithm converges to $v^*$ under our assumptions on~\eqref{eqn:sip} (see~\citep[Theorem~2.1]{blankenship1976infinitely}).
However, since the BF algorithm may not generate a feasible point for~\eqref{eqn:sip} finitely, global optimization algorithms supplement it with techniques for generating feasible points to guarantee finite convergence to a near-optimal solution of~\eqref{eqn:sip}~\cite{mitsos2011global}.
Moreover, although the BF algorithm typically determines good lower bounds in a few iterations, it may still require an excessively large discretization $Y_d$ before the sequence $\{LBD^k\}$ converges to within a specified tolerance of the optimal value $v^*$.
Example~\ref{exm:dp} below from Mitsos~\cite{mitsos2009test} illustrates the potentially slow convergence of the BF algorithm.

\begin{example}{\citep[Ex.\ (DP)]{mitsos2009test}}
\label{exm:dp}
Consider~\eqref{eqn:sip} with $d_x = 1$, $d_y = 1$, $X = [0,6]$, $Y = [2,6]$, $f(x) = 10 - x_1$, and $g(x,y) = \frac{y^2_1}{1 + \exp(-40(x_1-y_1))} + x_1 - y_1 - 2$.
The global solution is $x^* = 2$ with objective $v^* = 8$.
\end{example}


\begin{table}[t]
\centering
\begin{tabular}{l|c|c|c|c|c|c|c|c|c|c}
\hline
\textbf{Iteration No.} & 1 & 2    & 3    & 4    & 5    & 10   & 15   & 20   & 25   & 28 \\ \hline
\textbf{Lower Bound}     & 4 & 4.19 & 4.38 & 4.56 & 4.74 & 5.62 & 6.41 & 7.12 & 7.73 & 8  \\ \hline
\end{tabular}
\caption{Lower bounds generated by the BF Algorithm~\ref{alg:bfdisc} on Example~\ref{exm:dp}. The algorithm needs more than $20$ iterations to approximate $v^* = 8$ to within $10\%$.}
\label{tab:exdp}
\end{table}


Table~\ref{tab:exdp} notes the lower bounding iterates generated by the BF algorithm for Example~\ref{exm:dp}, and Figure~\ref{fig:plot_dp_bf} plots its discretizations of the semi-infinite constraint for this instance.
Clearly, solving~\eqref{eqn:disc-lbp} with the discretization $Y_d = \{2\}$ yields an optimal solution to~\eqref{eqn:sip} with lower bound equal to $v^*$.
However, the feasibility-based BF algorithm needs more than $20$ iterations for its sequence of lower bounds $\{LBD^k\}$ to converge to within $10\%$ of $v^*$.
This motivates our study of new optimality-based discretization methods for~\eqref{eqn:sip} that can mitigate this slow convergence of the BF algorithm (see Figure~\ref{fig:plot_dp_bf}).

Our main idea in this paper is to populate the discretization $Y_d$ with points in $Y$ such that the lower bound from~\eqref{eqn:disc-lbp} is maximized.
Since determining this \textit{optimal discretization} may be challenging, we consider more tractable variants and design efficient solution methods.
We also study how to optimally construct \textit{generalized discretizations} and analyze their theoretical guarantees.



\begin{figure}[t]
\centering
\begin{subfigure}{\textwidth}
\includegraphics[width=0.33\linewidth]{./figures/plot_dp_sampledisc.eps}%
\hfill
\includegraphics[width=0.33\linewidth]{./figures/plot_dp_bfdisc.eps}%
\hfill
\includegraphics[width=0.33\linewidth]{./figures/plot_dp_newdisc.eps}
\end{subfigure}
\caption{
Benefits of optimality-based discretization: 
Left: objective $f(x)$ and constraint $G(x)$ for Example~\ref{exm:dp} along with discretization $Y_d = \{2,3,4,5\}$ (cf.\ \citep[Figure~3.1]{djelassi2020discretization}). 
 Middle: BF method needs $27$ discretization points for its lower bounds to converge to $v^*$.
Right: our proposed optimality-based discretization method in Section~\ref{sec:accelerated_discretization} only requires a single discretization point ($\abs{Y_d} = 1$).
}
\label{fig:plot_dp_bf}
\end{figure}


This paper is organized as follows.
Section~\ref{sec:sensitivity_theory} reviews definitions and results from parametric sensitivity theory. 
Section~\ref{sec:accelerated_discretization} proposes new optimality-based discretization methods, designs efficient approaches for their solution, and presents theoretical guarantees.
Section~\ref{sec:generalized_discretization} introduces optimality-based generalized discretization methods for~\eqref{eqn:sip} and designs an efficient solution strategy.
We briefly explore some extensions in Section~\ref{sec:generalizations}.
Section~\ref{sec:numerical_results} presents detailed computational results demonstrating that our optimality-based discretization methods significantly reduce the number of iterations for convergence relative to the BF algorithm.
We conclude with avenues for future work in Section~\ref{sec:conclusion}.


\paragraph*{Notation.} Let $[n] := \{1,\dots,n\}$ and $\text{mid}(v^1,v^2,v^3)$ denote the componentwise median of vectors $v^1, v^2, v^3$. Given $\delta > 0$, $v \in \R^n$, $S \subset \R^n$, let $\norm{v}$ denote the Euclidean norm of $v$, $B_{\delta}(v)$ denote the open Euclidean ball of radius $\delta$ centered at $v$, $\text{proj}_S(v)$ denote (an element of) the Euclidean projection of $v$ onto $S$, and $\text{diam}(S)$ denote the diameter of~$S$ with respect to the Euclidean norm.




\section{Review of parametric sensitivity theory}
\label{sec:sensitivity_theory}

We begin by reviewing standard definitions and results from parametric sensitivity theory~\cite{fiacco1983,still2018lectures}.
Consider the parametric nonlinear program (NLP)
\begin{align}
\label{eqn: NLP}
    \min_{z \in \R^n}\:\: &F(z,p) \\
    \text{s.t. } & c_i(z,p) \le 0, \quad \forall i \in \I, \nonumber \\
    & c_i(z,p) = 0, \quad \forall i \in \E, \nonumber
\end{align}
where $z\in\mathbb{R}^{n}$ are decision variables, $p\in\mathbb{R}^{d}$ are parameters, $F: \mathbb{R}^{n}\times\mathbb{R}^{d} \rightarrow \mathbb{R}$ is the objective function, $\I = \{1,\dots,m_I\}$ and $\E = \{m_I+1,\dots,m_I + m_E\}$ are index sets for the inequality and equality constraints, and $c:\mathbb{R}^{n}\times\mathbb{R}^{d} \rightarrow \mathbb{R}^{m_I + m_E}$ are the constraint functions.
We write $z^*(p)$ and $\nu^*(p)$ to denote a local minimum of problem~\eqref{eqn: NLP} and the corresponding value function at this local minimum $\nu^*(p) := F(z^*(p),p)$, respectively.
Throughout this section, we omit dependence on $p$ whenever it is clear from the context.

The Lagrangian for problem~\eqref{eqn: NLP} is $L(z,\lambda,p) := F(z,p) + \tr{\lambda} c(z,p)$, where $\lambda \in \R^{m_I + m_E}$ are Lagrange multipliers corresponding to the constraints in~\eqref{eqn: NLP}. 
We recall the following definitions for a given parameter $p \in \R^d$.


\begin{definition}{(KKT point)}
A point $z \in \R^{n}$ is called a Karush–Kuhn–Tucker (KKT) point for problem~\eqref{eqn: NLP} if there exist Lagrange multipliers $\lambda \in \R^{m_I + m_E}$ such that 
\begin{align*}
    \nabla_z L(z,\lambda,p) &= 0, \qquad c_i(z,p) \leq 0, \:\: \forall i \in \I, \qquad c_i(z,p) = 0, \:\: \forall i \in \E \\
     \tr{\lambda} c(z,p) &= 0, \qquad\qquad\: \lambda_i \geq 0, \:\: \forall i \in \I.
\end{align*}
\end{definition}


Let $\Lambda^*(p)$ denote the set of Lagrange multipliers $\lambda$ satisfying the KKT conditions and $\A(z,p) := \{i \in \I : c_i(z,p) = 0\} \cup \E$ denote the index of active constraints at a feasible point $z$.
We write $\lambda^*(p)$ to denote an element of $\Lambda^*(p)$.


\begin{definition}{(Strict  complementarity)}
Suppose $z^*$ is a KKT point for problem~\eqref{eqn: NLP} with associated Lagrange multipliers $\lambda^*$. 
We say that strict complementarity (SC) holds at $(z^*, \lambda^*)$ if $\lambda^*_i - c_i(z^*,p) > 0$, $\forall i \in \I$.
\end{definition}




\begin{definition}{(LICQ)}
The linear independence constraint qualification (LICQ) holds at a feasible point $z$ to problem~\eqref{eqn: NLP} if $\nabla_z c_i(z,p)$, $i \in \A(z,p)$, are linearly independent. 
\end{definition}


\begin{definition}{(Strong second order sufficient conditions)}
Suppose $z^*$ is a KKT point for problem~\eqref{eqn: NLP} with associated multipliers $\lambda^*$. 
Let $\A^*_+ := \{i \in \I : \lambda^*_i > 0\}$. 
The strong second order sufficient condition (SSOSC) holds at $(z^*, \lambda^*)$ if
\begin{align*}
   \tr{q} \nabla^2_z L(z^*,\lambda^*,p) q &> 0, \quad \forall q \:\: \text{s.t.} \:\: q \neq 0 \text{  and  } \tr{\nabla_z c_i(z^*,p)} q = 0, \: \forall i \in \E \cup \A^*_+.
\end{align*}
\end{definition}


We now present sufficient conditions under which sensitivities of the value function $\nu^*(p)$ and the solution mapping $z^*(p)$ may be computed.


\begin{theorem}[Parametric sensitivities]
\label{thm:parametric_sens} 
Let $z^*(p)$ be a KKT point for problem~\eqref{eqn: NLP} with associated Lagrange multipliers $\lambda^*(p)$.
Suppose for some $\bar{p} \in \R^d$, functions $F$ and $c$ are twice continuously differentiable in a neighborhood of $(z^*(\bar{p}), \bar{p})$. 
Assume that the LICQ and SC conditions hold at $(z^*(\bar{p}), \lambda^*(\bar{p}))$.
Additionally, suppose either 
\begin{enumerate}[label=(\alph*)]
\item $\abs{\A(z^*(\bar{p}),\bar{p})} = n$, or
\item the SSOSC holds at $(z^*(\bar{p}), \lambda^*(\bar{p}))$.
\end{enumerate}
Then, $\exists \delta > 0$ such that $\forall p \in B_{\delta}(\bar{p})$, we can choose the mappings $z^*(p)$ and $\lambda^*(p)$ to be continuously differentiable on $B_{\delta}(\bar{p})$ and $z^*(p)$ to be a strict local minimizer of~\eqref{eqn: NLP}.
Additionally, for all $p \in B_{\delta}(\bar{p})$, the gradient of the value function~$\nu^*$ is given by 
\[
\nabla_p \nu^*(p) = \nabla_p L(z^*(p),\lambda^*(p),p),
\]
and the gradient of the solution mapping $z^*(p)$ may be computed for each $p \in B_{\delta}(\bar{p})$ as follows depending on whether condition (a) or (b) above holds:
\begin{enumerate}[label=(\alph*)]
\item Let $J_z(p) \in \R^{n \times n}$ and $J_p(p) \in \R^{n \times p}$ be matrices with rows $\tr{(\nabla_z c_i(z^*(p),p))}$, $i \in \A(z^*(p),p)$, and $\tr{(\nabla_p c_i(z^*(p),p))}$, $i \in \A(z^*(p),p)$, respectively. Then
\[
\nabla_p z^*(p) = -[J_z(p)]^{-1} J_p(p).
\]
\item 
Let $H_{z,\lambda}(p) := \begin{bmatrix}
\nabla^2_z L(z^*(p),\lambda^*(p),p) & J_z(p) \\
\tr{(J_z(p))} & 0 
\end{bmatrix}$, where $J_z(p)$ is a $\abs{\A(z^*(p),p)} \times n$ matrix with rows $\tr{(\nabla_z c_i(z^*(p),p))}$, $i \in \A(z^*(p),p)$.
Then
\[
\begin{bmatrix}
\nabla_p z^*(p) \\
\nabla_p \lambda^*_{\A}(p)
\end{bmatrix}  = - [H_{z,\lambda}(p)]^{-1}
\begin{bmatrix}
&\nabla_{pz} L(z^*(p),\lambda^*(p),p) \\
&\bigl(\nabla_p c_i(z^*(p),p)\bigr)_{i \in \A(z^*(p),p)}
\end{bmatrix},
\]
where $\lambda^*_{\A}(p)$ denotes the Lagrange multipliers of the active constraints at $z^*(p)$. 
\end{enumerate}
\end{theorem}%
\begin{proof}
See Chapter~3 of Fiacco~\cite{fiacco1983}, or the unified Theorem~4.4 in Still~\cite{still2018lectures}.
\end{proof}


Theorem~\ref{thm:parametric_sens} applies to parametric linear programs (LPs) whenever condition (a) therein holds.
Next, we present sufficient conditions for the value function $\nu^*(p)$ to be locally Lipschitz continuous.
We require the following definition.



\begin{definition}{(MFCQ)}
The Mangasarian-Fromovitz constraint qualification (MFCQ) holds at a feasible point $z$ if $\nabla_z c_i(z,p)$, $i \in \E$, are linearly independent and
$\exists q \in \R^n$ such that $\tr{\nabla_z c_i(z,p)} q = 0$, $\forall i \in \E$, and $\tr{\nabla_z c_i(z,p)} q < 0$, $\forall i \in \A(z,p) \backslash \E$.
\end{definition}


\begin{theorem}[Local Lipschitz continuity]
\label{thm:locally_lipschitz}
Suppose functions $F$ and $c$ are continuously differentiable and $\bar{p} \in \R^d$.
\begin{enumerate}[label=(\alph*)]
\item Let $z^*(\bar{p})$ be a strict local minimizer of problem~\eqref{eqn: NLP} at $p = \bar{p}$ and assume that the MFCQ holds at $z^*(\bar{p})$.
Then for some constants $\varepsilon, \delta > 0$ and any $p \in B_{\delta}(\bar{p})$, there exists a local minimizer $z^*(p) \in B_{\varepsilon}(z^*(\bar{p}))$ such that the corresponding value function $\nu^*(p) = F(z^*(p),p)$ is locally Lipschitz continuous at $\bar{p}$.

\item Suppose the MFCQ holds at every global minimizer $z^*(\bar{p})$ of problem~\eqref{eqn: NLP} at $p = \bar{p}$.
Assume that $\cup_{p \in B_{\varepsilon}(\bar{p})} \{z \in \R^n : c_i(z,p) \leq 0, \forall i \in \I, \: c_i(z,p) = 0, \forall i \in \E \}$ is bounded for some $\varepsilon > 0$.
Then the global minimum value function $\nu^*(p) = F(z^*(p),p)$ is locally Lipschitz continuous at $\bar{p}$.
\end{enumerate}
\end{theorem}
\begin{proof}
See Lemma~6.2 of Still~\cite{still2018lectures}.
\end{proof}

Theorem~1.12 of Dempe~\cite{dempe2017bilevel} and its surrounding discussion provides estimates of generalized gradients of $\nu^*$ in the above setting.
Additionally, conditions under which the solution mapping~$z^*$ is either H{\"o}lder continuous or locally Lipschitz continuous are presented in Theorems~6.2 to~6.5 of Still~\cite{still2018lectures}.


In the next two sections, we formulate optimality-based discretizations and generalized discretizations for~\eqref{eqn:sip} as max-min problems and use parametric sensitivity theory to design local optimization algorithms for solving them.




\section{Optimality-based discretization methods}
\label{sec:accelerated_discretization}



We propose new optimality-based discretization methods for~\eqref{eqn:sip} that can achieve faster convergence of lower bounds than the Blankenship and Falk algorithm. 
Similar to the BF algorithm, solving~\eqref{eqn:disc-lbp} with our new discretization strategies may not yield a feasible point for~\eqref{eqn:sip} finitely.
Therefore, our lower bounding approaches must also be supplemented with techniques for generating feasible points to provably solve~\eqref{eqn:sip} to global optimality in finite time. 
We only focus on constructing tighter lower bounds in this work and assume for simplicity that all subproblems solved to global optimality are solved \textit{exactly} in finite time; our approaches may be adapted to the setting where these subproblems are only solved to $\varepsilon$-global optimality for some $\varepsilon > 0$~\cite{djelassi2017hybrid,djelassi2020discretization,harwood2021note}. 


As introduced in Section~\ref{sec: intro}, the BF algorithm is a feasibility-based approach that iteratively populates the discretization $Y_d$ with points in $Y$ corresponding to the largest violation of the semi-infinite constraint~\eqref{eqn:sic} at incumbent solutions $x^k$ of~\eqref{eqn:disc-lbp}. 
The key idea of our optimality-based discretization methods is to instead populate $Y_d$ with points in $Y$ that yield the highest lower bound.
In the first iteration, instead of updating $Y_d$ with a solution $y^{BF,1}$ of~\eqref{eqn:llp} at $x = x^1$ as in Algorithm~\ref{alg:bfdisc}, we propose to solve the following max-min problem to determine a discretization $Y_d = \{\bar{y}^1\}$ that results in the highest lower bound:
\begin{align}
\label{eqn:max_min_iter1}
\bar{y}^1 \in \argmax_{y^1 \in Y} \:\: & \min_{x \in X} \:\: f(x) \\
& \:\:\:\text{s.t.} \:\: g(x,y^1) \leq 0. \nonumber
\end{align}
Techniques for solving problem~\eqref{eqn:max_min_iter1} are discussed in Section~\ref{subsec:solving_max_min}.
We consider two approaches for updating the discretization $Y_d$ at iteration $k > 1$.
The first approach discards the discretization from iteration $k-1$ and determines a fresh discretization $Y_d$ at iteration $k$ by solving the max-min problem
\begin{align}
\label{eqn:method-2}
(\bar{y}^1,\bar{y}^2,\dots,\bar{y}^k) \in \argmax_{(y^1,y^2,\dots,y^k) \in Y^k} \:\: & \min_{x \in X} \:\: f(x) \\
& \:\:\:\text{s.t.} \:\: g(x,y^i) \leq 0, \quad \forall i \in [k]. \nonumber
\end{align}
The resulting discretization $Y_d := \{\bar{y}^1,\bar{y}^2,\dots,\bar{y}^k\}$ yields the highest lower bound among all possible discretizations~\eqref{eqn:disc-lbp} with at most $k$ discretization points.
However, the outer-maximization in problem~\eqref{eqn:method-2} involves \mbox{$k \times d_y$} variables compared to only $d_y$ variables in problem~\eqref{eqn:max_min_iter1}.
To mitigate this computational burden, our second approach updates the discretization $Y_d := \{\bar{y}^1,\bar{y}^2,\dots,\bar{y}^{k-1}\}$ at iteration $k-1$ by adding a single best discretization point $\bar{y}^k \in Y$ for lower bound improvement.
This can be formulated as
\begin{align}
\label{eqn:method-1}
\bar{y}^k \in \argmax_{y^k \in Y} \:\: & \min_{x \in X} \:\: f(x) \\*
& \:\:\:\text{s.t.} \:\: g(x,\bar{y}^i) \leq 0, \quad \forall i \in [k-1], \nonumber \\*
& \quad\quad\:\: g(x,y^k) \leq 0. \nonumber
\end{align}
Problem~\eqref{eqn:method-1} is a greedy approximation of problem~\eqref{eqn:method-2}.
Formulations~\eqref{eqn:method-2} and~\eqref{eqn:method-1} are inspired by the idea of strong partitioning proposed by Kannan et al.\ \cite{kannan2022learning}.
We discuss two variants of these max-min problems in Section~\ref{subsec:algorithm_outlines}.


In contrast with Tsoukalas and Rustem~\cite{tsoukalas2011feasible} that treats the violation of the semi-infinite constraint~\eqref{eqn:sic} and the objective of~\eqref{eqn:sip} as two competing objectives, problems~\eqref{eqn:method-2} and~\eqref{eqn:method-1} directly optimize the discretization for the lower bound.
Baltean-Lugojan et al. \cite{baltean2019scoring} propose optimality-based cuts with a similar flavor but tailored for outer-approximating semidefinite programs, which can be viewed as a special case of~\eqref{eqn:sip}.
Paulus et al.\ \cite{paulus2022learning} also propose a similar formulation as problem~\eqref{eqn:method-1} in the context of cutting-plane selection for mixed-integer linear programs (MILPs), where they use explicit enumeration to choose the best optimality-based cut from a \textit{finite} list of candidate cuts.




\subsection{Solving the max-min problems}
\label{subsec:solving_max_min}

While solving the max-min problems~\eqref{eqn:method-2} or~\eqref{eqn:method-1} to global optimality is clearly desirable, this may be as difficult as solving~\eqref{eqn:sip} itself. 
Hence, we exploit the fact that solving these problems to local optimality is sufficient to obtain a valid discretization $Y_d$.
In Section~\ref{subsec:convergence_guarantees}, we outline how the sequences of discretizations~\eqref{eqn:disc-lbp} determined by solving~\eqref{eqn:method-2} and~\eqref{eqn:method-1} can be used to obtain sequences of lower bounds converging to $v^*$.
Numerical experiments in Section~\ref{sec:numerical_results} demonstrate that solving problems~\eqref{eqn:method-2} or~\eqref{eqn:method-1} to local optimality is almost always enough to determine good discretizations with faster convergence than the BF algorithm.
We begin with some useful notation.


Let $\phi_k: Y^k \to \mathbb{R}$ denote the value function of the inner-minimization in problem~\eqref{eqn:method-2} at iteration $k \in \N$: 
\begin{align}
\label{eqn:method-2_valuefn}
\phi_k(y^1,y^2,\dots,y^k) := \:\: & \min_{x \in X} \:\: f(x) \\
& \:\:\:\text{s.t.} \:\: g(x,y^i) \leq 0, \quad \forall i \in [k]. \nonumber
\end{align}
Assuming the maximum is attained\footnote{\label{foot:max_unattainable}If the maximum is not attained, then we pick any $\varepsilon$-optimal solution for some $\varepsilon > 0$.}, problem~\eqref{eqn:method-2} can be rewritten as
\begin{equation*} 
(\bar{y}^1,\bar{y}^2,\dots,\bar{y}^k) \in \argmax_{(y^1,y^2,\dots,y^k) \in Y^k} \phi_k(y^1,y^2,\dots,y^k).
\end{equation*}
Similarly, given a sequence $\{\tilde{y}^i\}_{i=1}^{\abs{\mathcal{I}_{k-1}}} \subset Y$ for some index set $\mathcal{I}_{k-1} \subset \N$, let $\psi_k: Y \to \mathbb{R}$ denote the value function 
\begin{align}
\label{eqn:method-1_valuefn}
\psi_k\bigl(y^k;\{\tilde{y}^i\}_{i=1}^{\abs{\mathcal{I}_{k-1}}}\bigr) := \:\: & \min_{x \in X} \:\: f(x) \\
& \:\:\:\text{s.t.} \:\: g(x,\tilde{y}^i) \leq 0, \quad \forall i \in \mathcal{I}_{k-1}, \nonumber \\
& \quad\quad\:\: g(x,y^k) \leq 0, \nonumber
\end{align}%
where $\{\tilde{y}^i\}_{i=1}^{\abs{\mathcal{I}_{k-1}}}$ are parameters in the above optimization.
Assuming again that the maximum is attained, problem~\eqref{eqn:method-1} can be equivalently written as
\begin{equation*} 
\bar{y}^k \in \argmax_{y^k \in Y} \psi_k\bigl(y^k;\{\bar{y}^i\}_{i=1}^{k-1}\bigr).
\end{equation*}
Note that the function $\phi_1(\cdot)$ is equivalent to $\psi_1(\cdot;\emptyset)$ on $Y$.

Before we outline our approach for solving problems~\eqref{eqn:method-2} and~\eqref{eqn:method-1}, we plot~$\phi_1$ for some examples from the literature.
We consider the following three examples in addition to Example~\ref{exm:dp} in the introduction.


\begin{example}{\citep[Ex.\ 2.1]{seidel2020adaptive}}
\label{exm:seidel}
Consider~\eqref{eqn:sip} with $d_x = 2$, $d_y = 1$, $X = [-1,1]^2$, $Y = [-1,1]$, $f(x) = -x_1 + 1.5x_2$, and $g(x,y) = -y^2_1 + 2y_1x_1 - x_2$.
The global solution is $x^* = \bigl( \frac{1}{3}, \frac{1}{9} \bigr)$ with $v^* = -\frac{1}{6}$.
\end{example}


\begin{example}{\citep[Ex.\ 2.1]{tsoukalas2011feasible}}
\label{exm:tsou}
Consider~\eqref{eqn:sip} with $d_x = 1$, $d_y = 1$, $X = [-6,6]$, $Y = [-6,6]$, $f(x) = 10 - x_1$, and $g(x,y) = -x^4_1 + x^2_1 - x^2_1y^2_1 + 2x^3_1y_1 - 4$ (note that~\citep[Ex.\ 2.1]{tsoukalas2011feasible} includes a typo in the description of $g$).
The global solution is $x^* = 2$ with $v^* = 8$.
\end{example}


\begin{example}{\citep[Ex.\ (H)]{mitsos2009test}}
\label{exm:wath}
Consider~\eqref{eqn:sip} with $d_x = 2$, $d_y = 1$, $X = [0,1] \times [-10^3, 10^3]$, $Y = [-1,1]$, $f(x) = x_2$, and $g(x,y) = -(x_1 - y_1)^2 - x_2$.
The global solution is $x^* = (\bar{x}_1, 0)$ for any $\bar{x}_1 \in [0,1]$ with $v^* = 0$.
\end{example}




\begin{figure}[t]
\centering
\begin{subfigure}{0.245\textwidth}
\includegraphics[width=0.98\columnwidth]{./figures/plot_dp_valuefn.eps}
    \caption{Example~\ref{exm:dp}}
\end{subfigure}%
\begin{subfigure}{0.245\textwidth}
\includegraphics[width=0.98\columnwidth]{./figures/plot_seidel_valuefn.eps}
\caption{Example~\ref{exm:seidel}}
\end{subfigure}%
\begin{subfigure}{0.245\textwidth}
\includegraphics[width=0.98\columnwidth]{./figures/plot_tsou_valuefn.eps}
    \caption{Example~\ref{exm:tsou}}
\end{subfigure}%
\begin{subfigure}{0.245\textwidth}
\includegraphics[width=0.98\columnwidth]{./figures/plot_wath_valuefn.eps}
    \caption{Example~\ref{exm:wath}}
\end{subfigure}
\caption{Value functions $\phi_1$ (note the discontinuity for Example~\ref{exm:tsou}). The red dot indicates $\phi_1$ at the point $y^{BF,1}$ determined by the BF algorithm at iteration~$1$.}
\label{fig:value-funcs}
\end{figure}



Figure~\ref{fig:value-funcs} plots the (global) value function~$\phi_1$ for Examples~\ref{exm:dp} to~\ref{exm:wath}.
It illustrates that $\phi_1$ may be nonconcave, nondifferentiable, or even discontinuous with large flat regions.
Additionally, the supremum in problem~\eqref{eqn:max_min_iter1} is unattainable for Example~\ref{exm:tsou}.
This is because under our assumptions on~\eqref{eqn:sip}, Lemma~5.3 of Still~\cite{still2018lectures} only guarantees that the functions~$\phi_k$ and $\psi_k$ are lower semicontinuous on their domains for each $k \in \N$ and does not eliminate the possibility that they may be discontinuous.
However, Theorem~\ref{thm:locally_lipschitz} implies that $\phi_k$ and $\psi_k$ are locally Lipschitz continuous under relatively mild assumptions, which along with Rademacher's theorem then implies that these value functions are differentiable almost everywhere.
Figure~\ref{fig:value-funcs} also illustrates that~$\phi_1$ is usually continuously differentiable at almost every point in its domain and that the BF point $y^{BF,1}$ provides a good initial guess for approximately solving~\eqref{eqn:max_min_iter1}.

Figure~\ref{fig:value-funcs_2} shows that the value functions $\psi_k$ may become increasingly challenging to optimize over as $k$ increases\footnote{We do not plot $\psi_2$ and $\psi_3$ for Examples~\ref{exm:dp} and~\ref{exm:seidel} as $\uset{y \in Y}{\max} \: \phi_1(y) = v^*$ for these instances.}; however, solving the lower-level problem~\eqref{eqn:llp} at incumbent (lower bounding) solutions continues to yield a good initial guess for Examples~\ref{exm:tsou} and~\ref{exm:wath}.
These observations open up the possibility of using (generalized) gradient information for solving the max-min problems~\eqref{eqn:method-2} and~\eqref{eqn:method-1} to local optimality.






\begin{figure}[t]
\centering
\begin{subfigure}{\textwidth}
\includegraphics[width=0.3\linewidth]{./figures/plot_tsou_iter1.eps}%
\hfill
\includegraphics[width=0.3\linewidth]{./figures/plot_tsou_iter2.eps}%
\hfill
\includegraphics[width=0.3\linewidth]{./figures/plot_tsou_iter3.eps}
\caption{Example~\ref{exm:tsou}}
\end{subfigure}\\
\begin{subfigure}{\textwidth}
\includegraphics[width=0.3\linewidth]{./figures/plot_wath_iter1.eps}%
\hfill
\includegraphics[width=0.3\linewidth]{./figures/plot_wath_iter2.eps}%
\hfill
\includegraphics[width=0.3\linewidth]{./figures/plot_wath_iter3.eps}
\caption{Example~\ref{exm:wath}}
\end{subfigure}
\caption{Value functions $\psi_k$, $k \in [3]$, in the first three iterations of problem~\eqref{eqn:method-1} for Examples~\ref{exm:tsou} and~\ref{exm:wath} (all three functions are discontinuous for Example~\ref{exm:tsou}). The red dot indicates the initial guess $\hat{y}^k$ (see line 5 of Algorithm~\ref{alg:prototype_disc}) for maximizing $\psi_k$ over $Y$ when the discretization is set using Algorithm~\texttt{GREEDY} in Section~\ref{subsec:algorithm_outlines}.
}
\label{fig:value-funcs_2}
\end{figure}




Due to the potentially nonsmooth and discontinuous nature of the functions $\phi_k$ and $\psi_k$, we propose to solve problems~\eqref{eqn:method-2} and~\eqref{eqn:method-1} using gradients (whenever they exist) of $\phi_k$ and $\psi_k$ within a bundle solver for nonsmooth nonconvex optimization~\cite{makela2003multiobjective}.
Each iteration of the bundle method requires function and generalized gradient evaluations.
We calculate function values by solving problem~\eqref{eqn:method-2_valuefn} and problem~\eqref{eqn:method-1_valuefn} to \textit{local} optimality.
We then use Theorem~\ref{thm:parametric_sens} to compute gradients of the local minimum value function $\phi_k$ or $\psi_k$ (this involves a linear solve) whenever its assumptions hold.

Before we outline our optimality-based discretization methods, we mention some alternatives for solving problems~\eqref{eqn:method-2} and~\eqref{eqn:method-1}.
If the inner-minimization problems~\eqref{eqn:method-2_valuefn} and~\eqref{eqn:method-1_valuefn} are convex and satisfy a constraint qualification (e.g., Slater's condition), then we may be able to use strong duality to reformulate problems~\eqref{eqn:method-2} and~\eqref{eqn:method-1} into single-level maximization problems.
The resulting problems can then be solved to local optimality to update the discretization~$Y_d$.
Alternatively, suppose problems~\eqref{eqn:method-2_valuefn} and~\eqref{eqn:method-1_valuefn} satisfy a constraint qualification for each feasible point of the outer-maximization problems~\eqref{eqn:method-2} and~\eqref{eqn:method-1} and the functions in problems~\eqref{eqn:method-2_valuefn} and~\eqref{eqn:method-1_valuefn} are continuously differentiable.
Then we can reformulate problems~\eqref{eqn:method-2} and~\eqref{eqn:method-1} into maximization problems with complementarity constraints using the KKT conditions for the inner-minimization problems, which can then be solved locally to update $Y_d$ (cf.\ \cite{stein2003solving}).


When the assumptions of Theorem~\ref{thm:parametric_sens} fail to hold, we may be able to either use (estimates of) generalized gradients~\cite{dempe2017bilevel,mordukhovich2009subgradients} of $\phi_k$ and $\psi_k$, or directional derivatives~\cite{ralph1995directional} of $\phi_k$ and $\psi_k$ and their generalizations~\cite{stechlinski2018generalized,stechlinski2019generalized} to solve problems~\eqref{eqn:method-2} and~\eqref{eqn:method-1} to local optimality~\cite{burke2020gradient}.
Finally, we mention that techniques for minimizing discontinuous functions (see, e.g., Ermoliev et al.\ \cite{ermoliev1995minimization}) may also be used to maximize $\phi_k$ and $\psi_k$ over their domains when none of the aforementioned approaches are applicable.





\subsection{Outline of optimality-based discretization methods}
\label{subsec:algorithm_outlines}


Algorithm~\ref{alg:prototype_disc} outlines a prototype optimality-based discretization method for~\eqref{eqn:sip}.
Similar to the BF algorithm~\ref{alg:bfdisc}, this prototype algorithm begins with an empty discretization $Y_d$.
At the start of each iteration, it solves~\eqref{eqn:disc-lbp} to \textit{global} optimality to determine a candidate solution $x^k$ and a corresponding lower bound $LBD^k$.
It then solves the lower-level problem~\eqref{eqn:llp} with $x = x^k$ to \textit{global} optimality to determine a point $\hat{y}^k$ to certify whether $x^k$ is $\varepsilon_f$-feasible for~\eqref{eqn:sip}.
The key difference with the BF algorithm (lines 9 to 11 of Algorithm~\ref{alg:prototype_disc}) is that if $x^k$ is not $\varepsilon_f$-feasible, Algorithm~\ref{alg:prototype_disc} solves a max-min problem (locally) to identify new points that may be used to update the discretization $Y_d$ if a sufficient bound increase condition holds, instead of simply adding $\hat{y}^k$ to the discretization as done in the BF algorithm.
Checking this sufficient bound increase condition requires the global solution of the inner-minimization problems~\eqref{eqn:method-2_valuefn} and~\eqref{eqn:method-1_valuefn} (i.e., the global solution of~\eqref{eqn:disc-lbp} with the new candidate discretization).
If problem~\eqref{eqn:disc-lbp} is not convex, we assume this additional global solve is performed \textit{only} to establish our theoretical results\footnote{An extra global solve is needed only if sufficient bound increase is violated \textit{after} running line 4.}.


We consider four realizations that only vary in lines 9 and 11 of Algorithm~\ref{alg:prototype_disc}:
 \texttt{OPT}, \texttt{GREEDY}, \texttt{2GREEDY}, and \texttt{HYBRID}. 



\begin{algorithm}[t]
\caption{Prototype optimality-based discretization algorithm}
\label{alg:prototype_disc}
{
\begin{algorithmic}[1]
\State \textbf{Input}: feasibility tolerance $\varepsilon_{f} \geq 0$, minimum bound improvement $\delta \geq 0$.

\State \textbf{Initialize} $Y_d = \emptyset$.

\For{$k = 1, 2, \dots$}


\State Solve problem~\eqref{eqn:disc-lbp} globally to get solution $x^k$, lower bound $LBD^k$.

\State Solve problem~\eqref{eqn:llp} with $x = x^k$ globally to get solution $\hat{y}^k \in Y$.

\If{$G(x^k) \leq \varepsilon_{f}$} 

\State \textbf{Terminate} with $\varepsilon_f$-feasible solution $x^k$ to~\eqref{eqn:sip}.

\Else

\State Solve a max-min problem to determine points $\{\bar{y}^{k,i}\}_{i=1}^{\abs{\I_k}}$.

\vspace*{0.03in}
\If{optimal value of max-min problem $\geq LBD^k + \delta$}

\State Update the discretization $Y_d$ using $\{\bar{y}^{k,i}\}_{i=1}^{\abs{\I_k}}$.

\Else

\State Set $Y_d \leftarrow Y_d \cup \{ \hat{y}^k \}$.

\EndIf

\vspace*{0.03in}
\EndIf


\EndFor

\end{algorithmic}
}
\end{algorithm}



\begin{itemize}
\item Algorithm \texttt{OPT} seeks to discard the discretization $Y_d$ at iteration \mbox{$k-1$} and replace it with a fresh discretization that is obtained by solving problem~\eqref{eqn:method-2} to local optimality\footnote{\label{note1}We use the term ``local optimality'' for the outer-maximization problems loosely because the inner-minimization problems are only solved locally.} (which in turn involves solving a sequence of inner problems~\eqref{eqn:method-2_valuefn} to local optimality).
It initializes the solution of this max-min problem using $\hat{y}^k$ and the discretization $Y_d$ at iteration $k-1$.

\item Algorithm \texttt{GREEDY} looks to add a single point to the discretization $Y_d := \{\bar{y}^1,\bar{y}^2,\dots,\bar{y}^{k-1}\}$ at iteration $k-1$ by solving problem~\eqref{eqn:method-1} to local optimality (which in turn involves solving a sequence of inner problems~\eqref{eqn:method-1_valuefn} to local optimality) with the initialization $\hat{y}^k$.

\item Algorithm \texttt{2GREEDY} first adds the point $\hat{y}^k$ to the discretization $Y_d$ at iteration $k-1$.
It then solves problem~\eqref{eqn:method-1} to local optimality with parameters $Y_d \cup \{\hat{y}^k\}$ to try and find a second point to add to the discretization that increases the lower bound by at least $\delta$ (this max-min problem is initialized with a random point in $Y$ so that LICQ may hold).

\item Algorithm \texttt{HYBRID} solves problem~\eqref{eqn:method-2} locally to try and determine a fresh discretization with sufficient lower bound improvement (similar to \texttt{OPT}) at each of the first $K$ iterations.
From iteration $K+1$, it then switches to the \texttt{GREEDY} strategy and solves problem~\eqref{eqn:method-1} to local optimality to try and find a single best point to add to the previous discretization $Y_d$.
\end{itemize}

\noindent 
All four realizations of Algorithm~\ref{alg:prototype_disc} use the freely available point $\hat{y}^k$ to either construct an initial guess, or to add to the discretization $Y_d$.
The motivation behind the \texttt{2GREEDY} scheme is that adding two discretization points per iteration (including the point $\hat{y}^k$) may reduce the number of~\eqref{eqn:disc-lbp} and~\eqref{eqn:llp} subproblems that are solved to global optimality before the sequence of lower bounds $\{LBD^k\}$ converges to $v^*$.
This may in turn reduce the overall time spent on computing lower bounds.
Algorithm~\texttt{HYBRID} relieves the increasing computational burden of solving problem~\eqref{eqn:method-2} as $k$ increases.



\paragraph*{Enhancements.} There are several ways in which Algorithms \texttt{OPT}, \texttt{GREEDY},  \texttt{2GREEDY}, and \texttt{HYBRID} may be enhanced in practice.
First, the local solution of the sequence of inner-minimization problems~\eqref{eqn:method-2_valuefn} or~\eqref{eqn:method-1_valuefn} can be effectively warm-started using active set methods.
Second, solving problems~\eqref{eqn:method-2_valuefn} or~\eqref{eqn:method-1_valuefn} using multi-start techniques can greatly increase the likelihood that we solve problems~\eqref{eqn:method-2} and~\eqref{eqn:method-1} with the global value functions $\phi_k$ and $\psi_k$.
Finally, as we saw in Examples~\ref{exm:seidel} to~\ref{exm:wath}, the assumptions of Theorem~\ref{thm:parametric_sens} may not hold at each point in the domain of the value functions $\phi_k$ and $\psi_k$.
In such situations, we may either return the best found solution to problems~\eqref{eqn:method-2} and~\eqref{eqn:method-1}, or randomly perturb the current iterate in an attempt to avoid points of nondifferentiability (cf.\ Theorem~\ref{thm:locally_lipschitz}).


 


\subsection{Convergence guarantees}
\label{subsec:convergence_guarantees}

We establish convergence of the sequence $\{LBD^k\}$ of lower bounds determined by Algorithms \texttt{OPT}, \texttt{GREEDY}, \texttt{2GREEDY}, and \texttt{HYBRID}.
We emphasize that Theorem~\ref{thm:conv_lbd_disc} below does \textit{not} assume the outer-maximization and inner-minimization problems in the above realizations of Algorithm~\ref{alg:prototype_disc} are solved to global optimality.
Instead, we assume \textit{only for its proof} that the sufficient bound increase check on line 10 of Algorithm~\ref{alg:prototype_disc} involves the \textit{global} solution of problem~\eqref{eqn:disc-lbp} with the candidate discretization.





\begin{theorem}
\label{thm:conv_lbd_disc}
Consider Algorithm~\ref{alg:prototype_disc} with $\varepsilon_f = 0$, $\delta > 0$. Suppose the discretization $Y_d$ is updated using Algorithm \texttt{OPT}, \texttt{GREEDY}, \texttt{2GREEDY}, or \texttt{HYBRID}.
Then $\uset{k \to \infty}{\lim} LBD^k = v^*$.
\end{theorem}
\begin{proof}
Since $f$ and $g$ are continuous, $X$ and $Y$ are compact, and~\eqref{eqn:sip} is assumed to be feasible, the optimal value $v^*$ is finite and bounded below by $\min_{x \in X} f(x) > -\infty$.
Line~11 of Algorithm~\ref{alg:prototype_disc} updates the discretization $Y_d$ using the points $\{\bar{y}^{k,i}\}_{i=1}^{\abs{\mathcal{I}_k}}$ only if this candidate discretization increases the lower bound in iteration $k+1$ by at least $\delta$. 
Since $v^* - LBD^0 := v^* - \min_{x \in X} f(x) < \infty$, line~11 of Algorithm~\ref{alg:prototype_disc} can be executed only a finite number of times before the lower bound converges to $v^*$.
Therefore, line 13 is executed for all $k$ large enough and the asymptotic behavior of Algorithm~\ref{alg:prototype_disc} is thus the same as that of the BF Algorithm~\ref{alg:bfdisc}.
The result that $LBD^k \rightarrow v^*$ then follows from Lemma~2.2 of Mitsos~\cite{mitsos2011global} (cf.\ Theorem~3.1 of Harwood et al.\ \cite{harwood2021note}).
\end{proof}




Our next result identifies favorable properties of Algorithm~\texttt{OPT} when the problem~\eqref{eqn:method-2} is solved to \textit{global} optimality.
We say that~\eqref{eqn:sip} is convex if the set $X$ is convex and functions $f$ and $g$ are convex with respect to~$x$ (on $X$).


\begin{proposition}
\label{prop:alg_opt}
Consider Algorithm~\texttt{OPT} with parameters $\varepsilon_f = \delta = 0$ and assume that problem~\eqref{eqn:method-2} is solved to \textit{global} optimality.
\begin{enumerate}
\item The sequence of lower bounds $\{LBD^k\}$ generated by Algorithm~\texttt{OPT} dominates any sequence of lower bounds generated by solving~\eqref{eqn:disc-lbp} with at most $k-1$ discretization points in iteration $k$.

\item Suppose~\eqref{eqn:sip} is convex and $\exists \bar{x} \in X$ such that $G(\bar{x}) < 0$. Then, there exists a discretization $Y_d := \{\hat{y}^1,\hat{y}^2,\dots,\hat{y}^m\} \subset Y$, with $m \leq d_x$, such that the optimal value of~\eqref{eqn:disc-lbp} equals $v^*$, i.e., Algorithm~\texttt{OPT} converges in at most $d_x$ iterations.
\end{enumerate}
\end{proposition}
\begin{proof}
The first part holds by the definition of problem~\eqref{eqn:method-2}, whereas the second part follows from Theorem~3.2 of Shapiro~\cite{shapiro2009semi}.
\end{proof}


Our next results establish rates of convergence of the BF and \texttt{OPT} lower bounds.


\begin{theorem}
\label{thm:convrate_bf}
Consider the BF Algorithm~\ref{alg:bfdisc} with $\varepsilon_f > 0$.
Suppose $\{g(\cdot,y)\}_{y \in Y}$ is uniformly Lipschitz continuous on $X$ with Lipschitz constant $L_{g,x} > 0$, i.e.,
\[
\abs{g(x,y) - g(\bar{x},y)} \leq L_{g,x} \norm{x - \bar{x}}, \quad \forall x, \bar{x} \in X, \: y \in Y.
\]
Then Algorithm~\ref{alg:bfdisc} terminates in at most $\left(\frac{\textup{diam}(X) L_{g,x}}{2\varepsilon_f} + 1\right)^{d_x}$ iterations.
\end{theorem}
\begin{proof}
Follows, e.g., from Section~5.2 of Mutapcic and Boyd~\cite{mutapcic2009cutting}.
\end{proof}


\begin{theorem}
\label{thm:convrate_opt}
Consider Algorithm~\texttt{OPT} with $\varepsilon_f > 0$ and $\delta = 0$.
Suppose $\{g(x,\cdot)\}_{x \in X}$ is uniformly Lipschitz continuous on $Y$ with Lipschitz constant $L_{g,y} > 0$, i.e.,
\[
\abs{g(x,y) - g(x,\bar{y})} \leq L_{g,y} \norm{y - \bar{y}}, \quad \forall y, \bar{y} \in Y, \: x \in X.
\]
If problem~\eqref{eqn:method-2} is solved to \textit{global} optimality, then Algorithm~\texttt{OPT} terminates with an $\varepsilon_f$-feasible point in at most $\left(\frac{\textup{diam}(Y) L_{g,y}}{2\varepsilon_f}\right)^{d_y}$ iterations.
Furthermore, if the assumptions of Theorem~\ref{thm:convrate_bf} hold, then Algorithm~\texttt{OPT} terminates in at most $\min\Big\{\left(\frac{\textup{diam}(Y) L_{g,y}}{2\varepsilon_f}\right)^{d_y}, \left(\frac{\textup{diam}(X) L_{g,x}}{2\varepsilon_f} + 1\right)^{d_x}\Big\}$ iterations.
\end{theorem}
\begin{proof}
Suppose Algorithm~\texttt{OPT} has not converged by iteration $k > 1$.
The candidate solution $x^k$ at iteration $k$ of Algorithm~\texttt{OPT} satisfies for each $1 \leq j < k$:
\begin{align*}
g(x^k,\hat{y}^k) > \varepsilon_f \:\: \text{and} \:\: g(x^k,\bar{y}^j) \leq 0 &\implies g(x^k, \hat{y}^k) - g(x^k, \bar{y}^j) > \varepsilon_f \\*
&\implies \norm{\hat{y}^k - \bar{y}^j} > \frac{\varepsilon_f}{L_{gy}},
\end{align*}
where $Y_d = \{\bar{y}^i\}_{i=1}^{k-1}$ denotes the discretization at the start of iteration $k$.
Therefore, an upper bound on the number of iterations for convergence can be obtained by calculating the number of Euclidean balls of radius $\frac{\varepsilon_f}{L_{gy}}$ needed to cover $Y$ (cf.\ \citep{mutapcic2009cutting}).
The second assertion follows from Theorem~\ref{thm:convrate_bf} and part 1 of Proposition~\ref{prop:alg_opt}.
\end{proof}


When $d_y \ll d_x$, as in many applications, the bound on the number of iterations for Algorithm~\texttt{OPT} can be much smaller than the bound on the BF algorithm (cf.\ \citep[Theorem~2]{still2001discretization}).
Theorem~\ref{thm:convrate_opt} can also be sharpened to estimate the number of balls needed to cover $\{y^*(x) : x \in X\}$ instead of $Y$.
We now link Theorems~\ref{thm:convrate_bf} and~\ref{thm:convrate_opt} to the rate of convergence of their sequence of lower bounds.


\begin{proposition}
\label{prop:calmness}
Suppose the value function $V(z) := \min_{\{x \in X \: : \: G(x) \leq z\}} f(x)$
is Lipschitz continuous on $[0,\bar{\varepsilon}]$ with a Lipschitz constant $L_V > 0$.
Additionally, suppose the assumptions of Theorems~\ref{thm:convrate_bf} and~\ref{thm:convrate_opt} hold.
Then for any $\varepsilon \in (0,\bar{\varepsilon})$:
\begin{enumerate}
\item Whenever $k \geq \left(\frac{\textup{diam}(X) L_{g,x} L_V}{2\varepsilon} + 1\right)^{d_x}$, the BF lower bound $LBD^k \geq v^* - \varepsilon$.

\item Whenever $k \geq \min\left\lbrace\left(\frac{\textup{diam}(Y) L_{g,y} L_V}{2\varepsilon_f}\right)^{d_y}, \left(\frac{\textup{diam}(X) L_{g,x} L_V}{2\varepsilon_f} + 1\right)^{d_x}\right\rbrace$, the \texttt{OPT} lower bound $LBD^k \geq v^* - \varepsilon$.
\end{enumerate}
\end{proposition}
\begin{proof}
Readily follows from Theorems~\ref{thm:convrate_bf} and~\ref{thm:convrate_opt} upon noting $V(\varepsilon) \geq v^* - L_V \varepsilon$.
\end{proof}



The Lipschitz assumption in Proposition~\ref{prop:calmness} is satisfied by convex SIPs when the objective $f$ is Lipschitz and Slater's condition holds (see Corollary~2 to Theorem~6.3.2 in Clarke~\cite{clarke1990optimization}).
Chapter~6 of Clarke~\cite{clarke1990optimization} also details other constraint qualifications under which this Lipschitz assumption holds.


The example below shows discretization-based lower bounding methods involving~\eqref{eqn:disc-lbp} (such as the BF algorithm and \textit{any} realization of Algorithm~\ref{alg:prototype_disc}) may take an exponential number of iterations in the problem dimensions to converge.
Although this behavior is expected, we are not aware of such an example in the SIP literature (similar examples are known for the classical cutting-plane method in convex optimization, see~\citep[Ex.\ 3.3.1]{nesterov2018lectures},~\citep[Ex.\ 1]{hijazi2014outer}).


\begin{example}{(Based on~\citep[Ex.\ 1]{hijazi2014outer})}
\label{exm:hijazi}
Consider the instance of~\eqref{eqn:sip} with $X = [-1,1]^{d_x}$, $Y = \{y \in \R^{d_x} : \norm{y}^2 = d_x-1\}$, $f(x) = -\norm{x}^2$, and $g(x,y) = \sum_{i=1}^{d_x} (x_i - y_i)y_i$.
Note that this semi-infinite constraint~\eqref{eqn:sic} may be reformulated as the convex constraint $\norm{x} \leq \sqrt{d_x-1}$.
Any $x \in X$ with $\norm{x} = \sqrt{d_x - 1}$ solves~\eqref{eqn:sip} with $v^* = 1 - d_x$.

Lemma~2.1 of Hijazi et al.\ \cite{hijazi2014outer} implies any discretization point $y \in Y$ can exclude at most one vertex of the cube $X$.
Because every vertex of $X$ is a solution to~\eqref{eqn:disc-lbp} with the discretization $Y_d = \emptyset$, \textit{any} discretization-based lower bounding algorithm that solves~\eqref{eqn:disc-lbp} requires exponentially many discretization points in the dimension $d_x$ for its sequence of lower bounds $\{LBD^k\}$ to converge to within $0.5$ of $v^*$.
\end{example}





\section{Generalized optimality-based discretizations}
\label{sec:generalized_discretization}


In this section, we propose generalized optimality-based discretization methods for~\eqref{eqn:sip} that can achieve faster convergence than \textit{any} traditional discretization method relying on~\eqref{eqn:disc-lbp}.
We assume in our proofs that all subproblems that are solved to global optimality are solved \textit{exactly}. 
Numerical results in Section~\ref{sec:numerical_results} show that our proposed algorithms work well when our subproblems are solved with finite precision and to a specified optimality tolerance. 


Consider the reformulation~\eqref{eqn:bilevel_reform} of~\eqref{eqn:sip}, where the semi-infinite constraint~\eqref{eqn:sic} is replaced with the constraint $g(x,y^*(x)) \leq 0$.
The BF Algorithm~\ref{alg:bfdisc} approximates $y^*(x)$ with solutions $\{y^*(x^k)\}$ of the lower-level problem~\eqref{eqn:llp} at incumbent solutions $\{x^k\}$ of problem~\eqref{eqn:disc-lbp}.
This zeroth-order approximation of $y^*$ can be crude as noted in Section~\ref{sec: intro}.
Assuming that the mapping $y^*$ is differentiable (cf.\
Theorem~\ref{thm:parametric_sens}), Seidel and K{\"u}fer~\cite{seidel2020adaptive} and Djelassi~\cite{djelassi2020discretization} instead propose to use the first-order approximation $y^*(x) \approx y^*(x^k) + J^*_y(x^k) (x - x^k)$ at incumbent solutions $\{x^k\}$, where $J^*_y(x^k)$ is the $d_y \times d_x$ Jacobian matrix with rows $\tr{(\nabla_x y^*_1(x^k))}, \dots, \tr{(\nabla_x y^*_{d_y}(x^k))}$.
In particular, Section~3.4 of Djelassi~\cite{djelassi2020discretization} suggests the following generalization of the BF lower bounding problem~\eqref{eqn:disc-lbp}:
\begin{align}
\label{eqn:higher-order-lbp}
\min_{x \in X} \:\: & f(x) \tag{G-LBP} \\
\text{s.t.} \:\: & g\bigl(x,\text{proj}_Y(\bar{A}^{k} x + \bar{b}^{k})\bigr) \leq 0, \quad \forall k \in [n], \nonumber
\end{align}
where constants $\bar{A}^{k} \in \R^{d_y \times d_x}$ and $\bar{b}^{k} \in \R^{d_y}$ are specified as $\bar{A}^{k} = J^*_y(x^k)$, $\bar{b}^{k} = y^*(x^k) - J^*_y(x^k) x^k$ at a sequence of candidate solutions $\{x^k\} \subset X$  to~\eqref{eqn:sip}.
The projection step ensures problem~\eqref{eqn:higher-order-lbp} is a relaxation of~\eqref{eqn:sip}, which implies solving~\eqref{eqn:higher-order-lbp} to \textit{global} optimality yields a valid lower bound on the optimal value $v^*$.
However, it also makes~\eqref{eqn:higher-order-lbp} nonsmooth and more challenging to solve than~\eqref{eqn:disc-lbp}.
Setting $\bar{A}^{k} = 0$ and $\bar{b}^{k} = y^{BF,k} = y^*(x^k)$ in problem~\eqref{eqn:higher-order-lbp} recovers the BF lower bounding problem.

In this work, we primarily consider the setting where $Y = [y^L, y^U]$ for some vectors $y^L, y^U \in \R^{d_y}$. 
The function $\text{proj}_Y(\cdot)$ can then be reformulated as the MILP-representable function $\text{mid}(y^L, \cdot, y^U)$, and problem~\eqref{eqn:higher-order-lbp} can in turn be reformulated as a mixed-integer nonlinear program (MINLP).
Section~3.4 of Djelassi~\cite{djelassi2020discretization} also considers more general settings for $Y$.


We construct optimality-based generalized discretizations of~\eqref{eqn:sip} in the form of~\eqref{eqn:higher-order-lbp} that can achieve faster convergence of lower bounds than the discretization methods in Section~\ref{sec:accelerated_discretization}.
As in Section~\ref{sec:accelerated_discretization}, our idea is to construct generalized discretizations~\eqref{eqn:higher-order-lbp} that yield the highest lower bound.
At the first iteration, we propose to solve the following max-min problem to determine constants $A^1$ and $b^1$ that result in the highest lower bound:
\begin{align}
\label{eqn:genl_max_min_iter1}
(\bar{A}^1, \bar{b}^1) \in \argmax_{A^1 \in \R^{d_y \times d_x}, b^1 \in \R^{d_y}} \:\: & \min_{x \in X} \:\: f(x) \\
& \:\:\:\text{s.t.} \:\: g\bigl(x,\text{proj}_Y(A^1 x + b^1)\bigr) \leq 0. \nonumber
\end{align}
We consider the following analogues of problems~\eqref{eqn:method-2} and~\eqref{eqn:method-1} for updating the generalized discretizations at iteration $k > 1$.
The first approach determines a fresh generalized discretization at iteration $k$ by solving the max-min problem
{
% \small
\begin{align}
\label{eqn:genl_method-2}
(\bar{A}^1,\bar{b}^1,\dots,\bar{A}^k,\bar{b}^k) \in \uset{b^1,\dots,b^k \in \R^{d_y}}{\argmax_{A^1,\dots,A^k \in \R^{d_y \times d_x}}} \:\: & \min_{x \in X} \:\: f(x) \\
& \:\:\:\text{s.t.} \:\: g\bigl(x,\text{proj}_Y(A^i x + b^i)\bigr) \leq 0, \quad \forall i \in [k]. \nonumber
\end{align}
}%
The resulting generalized discretization yields the highest lower bound among all possible generalized discretizations~\eqref{eqn:higher-order-lbp} with $k$ generalized discretization cuts.
To mitigate the computational burden of solving problem~\eqref{eqn:genl_method-2}, our second approach updates the generalized discretization at iteration $k-1$ by adding a single best generalized discretization cut with parameters $\bar{A}^k \in \R^{d_y \times d_x}$ and $\bar{b}^k \in \R^{d_y}$.
This can be formulated as the max-min problem
{
% \small
\begin{align}
\label{eqn:genl_method-1}
(\bar{A}^k, \bar{b}^k) \in \argmax_{A^k \in \R^{d_y \times d_x}, b^k \in \R^{d_y}} \:\: & \min_{x \in X} \:\: f(x) \\*
& \:\:\:\text{s.t.} \:\: g(x,\text{proj}_Y(\bar{A}^i x + \bar{b}^i)) \leq 0, \quad \forall i \in [k-1], \nonumber \\*
& \quad\quad\:\: g(x,\text{proj}_Y(A^k x + b^k)) \leq 0. \nonumber
\end{align}%
}%

Before outlining our proposal for solving problems~\eqref{eqn:genl_method-2} and~\eqref{eqn:genl_method-1}, we provide empirical motivation for why our optimality-based generalized discretization methods may perform well.
Figure~\ref{fig:optimal_soln} plots the optimal solution mapping $y^*$ for Examples~\ref{exm:dp} to~\ref{exm:wath}.
\begin{figure}[t]
\centering
\begin{subfigure}{0.245\textwidth}
\includegraphics[width=0.98\columnwidth]{./figures/plot_dp_soln.eps}
    \caption{Example~\ref{exm:dp}}
\end{subfigure}%
\begin{subfigure}{0.245\textwidth}
\includegraphics[width=0.98\columnwidth]{./figures/plot_seidel_soln.eps}
\caption{Example~\ref{exm:seidel}}
\end{subfigure}%
\begin{subfigure}{0.245\textwidth}
\includegraphics[width=0.98\columnwidth]{./figures/plot_tsou_soln.eps}
    \caption{Example~\ref{exm:tsou}}
\end{subfigure}%
\begin{subfigure}{0.245\textwidth}
\includegraphics[width=0.98\columnwidth]{./figures/plot_wath_soln.eps}
    \caption{Example~\ref{exm:wath}}
\end{subfigure}
\caption{Optimal solution mapping~$y^*$ (it only depends on $x_1$ for Examples~\ref{exm:seidel} and~\ref{exm:wath}). The red dot indicates $y^*(x^1)$ at $x^1 \in \argmin_{x \in X} f(x)$.}
\label{fig:optimal_soln}
\end{figure}
Interestingly, this mapping is well-behaved for all four examples (it is piecewise-linear for Example~\ref{exm:dp} and linear for Examples~\ref{exm:seidel} to~\ref{exm:wath}).
Moreover, using $\bar{A}^1 = J^*_y(x^1)$ and $\bar{b}^1 := y^*(x^1) - J^*_y(x^1) x^1$ in~\eqref{eqn:higher-order-lbp} at the point $(x^1, y^*(x^1))$ highlighted in these plots yields a lower bound equal to $v^*$ for all four examples.
However, this favorable situation may not always be the case, and the mapping $y^*$ may be nonconvex, nonsmooth, and even discontinuous in general.
For example, any~\eqref{eqn:sip} with $X = Y = [0,1]$ and $g(x,y) = (x - 0.5)y$ results in the optimal solution mapping $y^*(x) = \mathds{1}(x - 0.5)$, where $\mathds{1}(z) = 1$ if $z \geq 0$ and zero otherwise, which is discontinuous at $x = 0.5$.
Example~\ref{exm:hijazi} from Section~\ref{subsec:convergence_guarantees} provides another instance where $y^*$ is discontinuous.


\vspace*{0.1in}
\noindent Example~\ref{exm:hijazi}: 
Consider the optimal solution mapping $y^*(x) := \frac{x}{\norm{x}} \sqrt{d_x - 1}$ if $x \neq 0$ and $y^*(x) := \bar{y}$ if $x = 0$.
It is discontinuous at $x = 0$ irrespective of $\bar{y} \in Y$.
However, setting $\bar{A}^1 = I$ (the identity matrix) and $\bar{b}^1 = 0$ in~\eqref{eqn:higher-order-lbp} with $k = 1$ yields a lower bound equal to $v^*$ since $\text{proj}_{Y}(x) = y^*(x)$, $\forall x \in X$.
Therefore, a single generalized discretization cut is sufficient for convergence (this is in stark contrast with the discretization methods in Section~\ref{subsec:convergence_guarantees} that require exponentially many iterations in the dimension $d_x$ to converge).





















\subsection{Solving the max-min problems}

In addition to the challenges outlined in Section~\ref{sec:accelerated_discretization}, solving problems~\eqref{eqn:genl_method-2} and~\eqref{eqn:genl_method-1} to global optimality may also be challenging due to the non\-smooth projection step.
Therefore, we design local optimization methods for solving a smooth approximation of these max-min problems and empirically show in Section~\ref{sec:numerical_results} that this may be sufficient to determine good generalized discretizations that yield fast convergence of lower bounds.


Let $\phi^G_k: (\R^{d_y \times d_x} \times \R^{d_y})^k \to \mathbb{R}$ denote the value function of the inner-minimization in problem~\eqref{eqn:genl_method-2} at iteration $k \in \N$, i.e., 
\begin{align}
\label{eqn:genl_method-2_valuefn}
\phi^G_k(A^1,b^1,\dots,A^k,b^k) := \:\: & \min_{x \in X} \:\: f(x) \\
& \:\:\:\text{s.t.} \:\: g\bigl(x,\text{proj}_Y(A^i x + b^i)\bigr) \leq 0, \quad \forall i \in [k]. \nonumber
\end{align}
Assuming the maximum is attained, problem~\eqref{eqn:genl_method-2} can be rewritten as
\begin{equation*} 
(\bar{A}^1,\bar{b}^2,\dots,\bar{A}^k,\bar{b}^k) \in \uset{b^1,\dots,b^k \in \R^{d_y}}{\argmax_{A^1,\dots,A^k \in \R^{d_y \times d_x}}} \phi^G_k(A^1,b^1,\dots,A^k,b^k).
\end{equation*}
Similarly, given a sequence $\{(\tilde{A}^i, \tilde{b}^i)\}_{i=1}^{\abs{\mathcal{I}_{k-1}}} \subset Y$ for some index set $\mathcal{I}_{k-1} \subset \N$, let $\psi^G_k: Y \to \mathbb{R}$ denote the value function 
\begin{align}
\label{eqn:genl_method-1_valuefn}
\psi^G_k\bigl(A^k,b^k;\{(\tilde{A}^i, \tilde{b}^i)\}_{i=1}^{\abs{\mathcal{I}_{k-1}}}\bigr) := \:\: & \min_{x \in X} \:\: f(x) \\*
& \:\:\:\text{s.t.} \:\: g(x,\text{proj}_Y(\tilde{A}^i x + \tilde{b}^i)) \leq 0, \quad \forall i \in [k-1], \nonumber \\*
& \quad\quad\:\: g(x,\text{proj}_Y(A^k x + b^k)) \leq 0, \nonumber
\end{align}
where $\{(\tilde{A}^i,\tilde{b}^i)\}_{i=1}^{\abs{\mathcal{I}_{k-1}}}$ are parameters in the above problem.
Assuming again that the maximum is attained, problem~\eqref{eqn:genl_method-1} can be equivalently written as
\begin{equation*} 
(\bar{A}^k, \bar{b}^k) \in \argmax_{A^k \in \R^{d_y \times d_x}, b^k \in \R^{d_y}} \psi^G_k\bigl(A^k, b^k;\{(\bar{A}^i,\bar{b}^i)\}_{i=1}^{k-1}\bigr).
\end{equation*}
Note that the function $\phi^G_1(\cdot)$ is equivalent to $\psi^G_1(\cdot;\emptyset)$ on $\R^{d_y \times d_x} \times \R^{d_y}$.








\begin{algorithm}[t]
\caption{Prototype optimality-based generalized discretization algorithm}
\label{alg:prototype_genl_disc}
{
\begin{algorithmic}[1]
\State \textbf{Input}: feasibility tolerance $\varepsilon_{f} \geq 0$, minimum bound improvement $\delta \geq 0$.

\State \textbf{Initialize} $P^G_d = \emptyset$.

\For{$k = 1, 2, \dots$}


\State Solve problem~\eqref{eqn:higher-order-lbp} globally to get solution $x^k$, lower bound $LBD^k$.

\State Solve problem~\eqref{eqn:llp} with $x = x^k$ globally to get solution $y^*(x^k)$.

\State If assumptions of Theorem~\ref{thm:parametric_sens} hold for~\eqref{eqn:llp}, compute $J^*_y(x^k)$.

\If{$G(x^k) \leq \varepsilon_{f}$} 

\State \textbf{Terminate} with $\varepsilon_f$-feasible solution $x^k$ to~\eqref{eqn:sip}.

\Else

\State Solve a max-min problem to determine $\{(\bar{A}^{k,i},\bar{b}^{k,i})_{i=1}^{\abs{\mathcal{I}_k}}\}$.


\vspace*{0.03in}
\If{optimal value of max-min problem $\geq LBD^k + \delta$}

\State Update the discretization $P^G_d$ using $\{(\bar{A}^{k,i},\bar{b}^{k,i})_{i=1}^{\abs{\mathcal{I}_k}}\}$.

\Else

\State Set $P^G_d \leftarrow P^G_d \cup \{ (J^*_y(x^k), y^*(x^k) - J^*_y(x^k) x^k) \}$ if assumptions of Theorem~\ref{thm:parametric_sens} hold, and 

\Statex \hspace*{0.6in} $P^G_d \leftarrow P^G_d \cup \{ (0, y^*(x^k)) \}$ otherwise


\EndIf


\vspace*{0.03in}
\EndIf



\EndFor

\end{algorithmic}
}
\end{algorithm}






Similar to the value functions $\phi_k$ and $\psi_k$ in~\eqref{eqn:method-2_valuefn} and~\eqref{eqn:method-1_valuefn}, the functions $\phi^G_k$ and $\psi^G_k$ above may be nonconcave, nonsmooth, or discontinuous with large flat regions.
Furthermore, Theorems~\ref{thm:parametric_sens} and~\ref{thm:locally_lipschitz} do not apply because of the nonsmooth projection step in problems~\eqref{eqn:genl_method-2_valuefn} and~\eqref{eqn:genl_method-1_valuefn}.
In order to be able to use sensitivity information, we replace the projection operator with a smooth approximation.
For instance, when $Y := [y^L, y^U]$ is a compact interval, we can replace $\text{proj}_Y(\cdot) = \text{mid}(y^L, \cdot, y^U)$ with a sigmoid whose range equals $(y^L, y^U)$.
We then use gradients (whenever
they exist) of this smooth approximation of the value functions $\phi^G_k$ and $\psi^G_k$ within
a bundle solver for nonsmooth nonconvex optimization~\cite{makela2003multiobjective} to solve problems~\eqref{eqn:genl_method-2} and~\eqref{eqn:genl_method-1} to local optimality.
Function values for the bundle solver are obtained by solving the smooth approximation of problem~\eqref{eqn:genl_method-2_valuefn} or~\eqref{eqn:genl_method-1_valuefn} to local optimality, and gradients of the smooth approximation of $\phi^G_k$ and $\psi^G_k$ may be computed using Theorem~\ref{thm:parametric_sens} whenever its assumptions hold.
We initialize the variables $A^1$ and $b^1$ in problem~\eqref{eqn:genl_max_min_iter1} with $\bar{A}^1 = J^*_y(x^1)$ and $\bar{b}^1 = y^*(x^1) - J^*_y(x^1) x^1$ whenever $y^*$ is differentiable at the initial point $x^1 \in \argmin_{x \in X} f(x)$ (we consider similar initializations at later iterations).
Section~\ref{subsec:solving_max_min} outlines alternative approaches for solving problems~\eqref{eqn:genl_method-2} and~\eqref{eqn:genl_method-1}, and Section~\ref{subsec:algorithm_outlines} lists possible enhancements.



\subsection{Outline of the generalized discretization methods}
\label{subsec:genl_algorithm_outlines}




Algorithm~\ref{alg:prototype_genl_disc} outlines a prototype optimality-based generalized discretization method for~\eqref{eqn:sip}. 
We consider four realizations of Algorithm~\ref{alg:prototype_genl_disc} that only vary in lines 10 and 12:
\texttt{G-OPT}, \texttt{G-GREEDY}, \texttt{G-2GREEDY}, and \texttt{G-HYBRID}.
Algorithms~\texttt{G-OPT}, \texttt{G-GREEDY}, and \texttt{G-HYBRID} are direct analogues of \texttt{OPT}, \texttt{GREEDY}, and \texttt{HYBRID} that rely on problems~\eqref{eqn:genl_method-2} and~\eqref{eqn:genl_method-1} instead of problems~\eqref{eqn:method-2} and~\eqref{eqn:method-1}.
Algorithm~\texttt{G-2GREEDY} first adds $(\bar{A}^{k}, \bar{b}^k) = (J^*_y(x^k), y^*(x^k) - J^*_y(x^k) x^k)$ or $(\bar{A}^{k}, \bar{b}^k) = (0, y^*(x^k))$ to $P^G_d$ and then solves problem~\eqref{eqn:genl_method-1} to try and find another generalized discretization cut to add to the formulation.



\subsection{Convergence guarantees}


We begin by establishing convergence of the sequence of lower bounds generated by Algorithms \texttt{G-OPT}, \texttt{G-GREEDY}, \texttt{G-2GREEDY}, and \texttt{G-HYBRID} to $v^*$.
Like Theorem~\ref{thm:conv_lbd_disc}, this result also does \textit{not} assume the max-min problems~\eqref{eqn:genl_method-2} and~\eqref{eqn:genl_method-1} are solved to global optimality.



\begin{theorem}
\label{thm:conv_lbd_genl_disc}
Consider Algorithm~\ref{alg:prototype_genl_disc} with $\varepsilon_f = 0$, $\delta > 0$.
Suppose $Y$ is convex and the generalized discretization $P^G_d$ is updated using Algorithm \texttt{G-OPT}, \texttt{G-GREEDY}, \texttt{G-2GREEDY}, or \texttt{G-HYBRID}.
Then $\uset{k \to \infty}{\lim} LBD^k = v^*$.
\end{theorem}
\begin{proof}
The proof follows a similar outline as the proof of Theorem~\ref{thm:conv_lbd_disc} and Lemma 2.2 of Mitsos~\cite{mitsos2011global} (cf. Theorem 3.1 of Harwood et al.\ \cite{harwood2021note}).

Suppose each $x^k \in X$ is infeasible to~\eqref{eqn:sip} (otherwise, $LBD^k = v^*$ for all $k$ large enough).
Since $X$ is compact, we can assume (by moving to a subsequence) that $x^k \to x^* \in X$.
We show that $x^*$ is feasible to~\eqref{eqn:sip}, which implies $LBD^k \to v^*$.

Following arguments in Theorem~\ref{thm:conv_lbd_disc}, line 14 of Algorithm~\ref{alg:prototype_genl_disc} must be run infinitely often with $P^G_d \leftarrow P^G_d \cup \{ (J^*_y(x^k), y^*(x^k) - J^*_y(x^k) x^k) \}$ or $P^G_d \leftarrow P^G_d \cup \{ (0, y^*(x^k)) \}$.
Therefore, the asymptotic behavior of Algorithm~\ref{alg:prototype_genl_disc} is the same as the algorithm that adds at each iteration either $(J^*_y(x^k), y^*(x^k) - J^*_y(x^k) x^k)$ to $P^G_d$ if Theorem~\ref{thm:parametric_sens} holds, or $(0, y^*(x^k))$ to $P^G_d$ otherwise.
We show that $LBD^k \to v^*$ for the above algorithm.
Define the index sets $\mathcal{J}_k := \{j \in [k] : \text{Theorem~\ref{thm:parametric_sens} holds} \}$ and $\mathcal{L}_k := \{1,\dots,k\} \backslash \mathcal{J}_k$.

By construction of the above problem, we have $\forall l, k$ such that $l > k$:
\[
g(x^l, \text{proj}_Y(\tilde{A}^k x^l + \tilde{b}^k)) \leq 0, \:\: \textbf{if } k \in \mathcal{J}_k, \quad \text{and} \quad g(x^l, y^*(x^k)) \leq 0, \:\: \textbf{if } k \in \mathcal{L}_k,
\]
where $\tilde{A}^k := J^*_y(x^k)$, $\tilde{b}^k := y^*(x^k) - J^*_y(x^k) x^k$ if $k \in \mathcal{J}_k$. 
Continuity of $g$, $\text{proj}_Y(\cdot)$ and compactness of $X$, $Y$ ensure uniform continuity, which implies that for any $\varepsilon > 0$, there exists $\kappa > 0$ such that for all $x \in X$ with $\norm{x - x^l} < \kappa$ and $\forall l, k$ with $l > k$:
\begin{align}
\label{eqn:int_step}
&g(x, \text{proj}_Y(\tilde{A}^k x + \tilde{b}^k)) < \varepsilon, \:\: \textbf{if } k \in \mathcal{J}_k, \quad \text{and} \quad g(x, y^*(x^k)) < \varepsilon, \:\: \textbf{if } k \in \mathcal{L}_k.
\end{align}
Since $x^k \to x^*$, we have $\norm{x^l - x^k} < \kappa$, $\forall l, k$ with $l > k \geq \bar{K}$.
Plugging $x = x^k$ in \eqref{eqn:int_step} and noting $\tilde{A}^k x^k + \tilde{b}^k = y^*(x^k)$ if $k \in \mathcal{J}_k$ yields $0 < g(x^k, y^*(x^k)) < \varepsilon$, $\forall k \geq \bar{K}$. Therefore, $g(x^k, y^*(x^k)) = G(x^k) \to 0$ and continuity of $G$ implies $G(x^*) = 0$.
\end{proof}



By construction, Algorithms~\texttt{G-OPT} and~\texttt{G-GREEDY} generate tighter lower bounds than Algorithms~\texttt{OPT} and~\texttt{GREEDY}, respectively, since we can set $\bar{A}^k = 0$.
Our next result establishes rate of convergence of the \texttt{G-OPT} lower bounds when problem~\eqref{eqn:genl_method-2} is solved to \textit{global} optimality.
We require the following lemma, which is sharp for affine functions (cf.\ Figure~\ref{fig:optimal_soln}).


\begin{lemma}
\label{lem:pwlest}
Suppose $Z \subset \R^N$ is a compact convex set and $F: Z \to \mathbb{R}^M$ is continuously differentiable with a Lipschitz continuous gradient.
Let $L_{\nabla F}$ denote the Lipschitz constant of $\nabla F$ on $Z$.
Then $\forall \varepsilon > 0$, there exist $J = 1+\left(\frac{\text{diam}(Z)}{2}\sqrt{\frac{L_{\nabla F}}{2\varepsilon}}\right)^N$ affine functions $\{ \tr{(\alpha^j)} z + \beta^j \}_{j=1}^{J}$ such that $\uset{z \in Z}{\sup} \: \uset{j \in [J]}{\min} \: \big\lVert F(z) - \bigl(\tr{(\alpha^j)} z + \beta^j \bigr) \big\rVert < \varepsilon$.
\end{lemma}
\begin{proof}
The integral form of Taylor's theorem implies for any $z, \bar{z} \in Z$:
\begin{align*}
\norm{F(z) - F(\bar{z}) - \tr{\nabla F(\bar{z})} (z - \bar{z})} &\leq \frac{L_{\nabla F}}{2} \norm{z - \bar{z}}^2.
\end{align*}
Therefore, $\norm{F(z) - F(\bar{z}) - \tr{\nabla F(\bar{z})} (z - \bar{z})} < \varepsilon$ whenever $\Big\{z \in Z : \norm{z - \bar{z}} < \sqrt{\frac{2\varepsilon}{L_{\nabla F}}}\Big\}$.
The stated result follows by covering $Z$ using balls of radius $\sqrt{\frac{2\varepsilon}{L_{\nabla F}}}$, setting $z^j$ to be the center of the $j$th ball, and setting $\alpha^j = \nabla F(z^j)$, $\beta^j = F(z^j) - \tr{\nabla F(z^j)} z^j$.
\end{proof}


\begin{theorem}
\label{thm:convrate_gopt}
Consider Algorithm~\texttt{G-OPT} with $\varepsilon_f > 0$ and $\delta = 0$.
Suppose $X$ and $Y$ are convex sets and $\{g(x,\cdot)\}_{x \in X}$ is uniformly Lipschitz continuous on $Y$ with Lipschitz constant $L_{g,y} > 0$.
Assume additionally that $y^*$ is continuously differentiable on $X$ with a Lipschitz continuous gradient. Let $L_{\nabla y}$ denote the Lipschitz constant of $\nabla y^*$ on $X$.
If problem~\eqref{eqn:genl_method-2} is solved to \textit{global} optimality, then Algorithm~\texttt{G-OPT} terminates with an $\varepsilon_f$-feasible point in at most $1 + \left(\frac{\textup{diam}(X)}{2}\sqrt{\frac{L_{\nabla y} L_{gy}}{2\varepsilon_f}}\right)^{d_x}$ iterations.
Furthermore, if the assumptions of Theorem~\ref{thm:convrate_opt} also hold, then Algorithm~\texttt{G-OPT} terminates with an $\varepsilon_f$-feasible point in at most \mbox{$\min\Big\{1 + \left(\frac{\textup{diam}(X)}{2}\sqrt{\frac{L_{\nabla y} L_{gy}}{2\varepsilon_f}}\right)^{d_x}, \left(\frac{\textup{diam}(Y) L_{g,y}}{2\varepsilon_f}\right)^{d_y}\Big\}$} iterations.
\end{theorem}
\begin{proof}
Suppose Algorithm~\texttt{G-OPT} has not converged by iteration $k > 1$.
The candidate solution $x^k$ at iteration $k$ of Algorithm~\texttt{G-OPT} satisfies for each $1 \leq j < k$:
\begin{align*}
&g(x^k,y^*(x^k)) > \varepsilon_f \:\: \text{and} \:\: g(x^k,\text{proj}_Y(\bar{A}^j x^k + \bar{b}^j)) \leq 0 \\
\implies \: & g(x^k, y^*(x^k)) - g(x^k, \text{proj}_Y(\bar{A}^j x^k + \bar{b}^j)) > \varepsilon_f \\
\implies \: & L_{gy} \norm{y^*(x^k) - \text{proj}_Y(\bar{A}^j x^k + \bar{b}^j)} > \varepsilon_f, \\
\implies \: & \norm{y^*(x^k) - (\bar{A}^j x^k + \bar{b}^j)} > \frac{\varepsilon_f}{L_{gy}},
\end{align*}
where $P^G_d = \{(\bar{A}^i, \bar{b}^i)\}_{i=1}^{k-1}$ denotes the generalized discretization at the start of iteration $k$.
Therefore, an upper bound on the number of iterations for \texttt{G-OPT} to converge can be obtained by estimating the minimal number $k$ of generalized discretization cuts required for $\sup_{x \in X} \min_{j \in [k]} \norm{y^*(x) - (\bar{A}^j x + \bar{b}^j)} \leq \frac{\varepsilon}{L_{gy}}$.
The first result then follows from Lemma~\ref{lem:pwlest}, whereas the second result follows from Theorem~\ref{thm:convrate_opt}.
\end{proof}


Chapter~3 of Fiacco~\cite{fiacco1983} presents conditions when the assumption on $y^*$ holds.
The convexity assumption on the set $X$ may be relaxed by considering any convex superset of $X$.
Note that the bound on the number of iterations in Theorem~\ref{thm:convrate_gopt} scales like $\varepsilon_f^{-0.5d_x}$ compared to the $\varepsilon_f^{-d_x}$ scaling in Theorem~\ref{thm:convrate_bf}.
The rate at which $LBD^k \to v^*$ for \texttt{G-OPT} can be derived similar to Proposition~\ref{prop:calmness}.





\section{Generalizations}
\label{sec:generalizations}


We discuss some extensions of our optimality-based discretization methods.


\paragraph*{Multiple semi-infinite constraints.}
Suppose~\eqref{eqn:sip} includes $\abs{\mathcal{I}}$ semi-infinite constraints $g_i(x,y) \leq 0$, $\forall y \in Y$, $i \in \mathcal{I}$.
The formulation below generalizes the max-min problem~\eqref{eqn:max_min_iter1} for constructing optimality-based discretizations at the first iteration of Algorithm~\ref{alg:prototype_disc}.
\begin{align*}
(\bar{y}^1, \dots, \bar{y}^{\abs{\mathcal{I}}}) \in \argmax_{(y^1, \dots,y^{\abs{\mathcal{I}}}) \in Y^{\abs{\mathcal{I}}}} \:\: & \min_{x \in X} \:\: f(x) \\
& \:\:\:\text{s.t.} \:\: g_i(x,y^i) \leq 0, \quad \forall i \in \mathcal{I}. \nonumber
\end{align*}
Extensions of problems~\eqref{eqn:method-2} and~\eqref{eqn:method-1} and the generalized discretization methods in Section~\ref{sec:generalized_discretization} readily follow.




\paragraph*{Generalized discretizations based on higher-order cuts.}
Instead of restricting ourselves to optimality-based linear approximations of $y^*(x)$ as in Section~\ref{sec:generalized_discretization}, we can construct optimality-based \textit{nonlinear} approximations of $y^*$ for potentially faster convergence.
Let $\gamma : X \times \Theta \to \R^{d_y}$ be any family of functions.
We propose the following generalization of~\eqref{eqn:higher-order-lbp}:
\begin{align}
\label{eqn:genl_higher-order-lbp}
\min_{x \in X} \:\: & f(x) \\
\text{s.t.} \:\: & g\bigl(x,\text{proj}_Y(\gamma(x,\theta^k))\bigr) \leq 0, \quad \forall k \in [n]. \nonumber
\end{align}
Clearly,~\eqref{eqn:higher-order-lbp} is a special case of problem~\eqref{eqn:genl_higher-order-lbp} where $\gamma$ is the family of parametric affine (in $x$) functions.
Extensions of the max-min problems~\eqref{eqn:genl_method-2} and~\eqref{eqn:genl_method-1} to determine an optimal sequence of parameters $\{\theta^k\}$ readily follow.



\paragraph*{Mixed-integer SIPs.}
The presence of integer variables in~\eqref{eqn:sip} precludes the use of the sensitivity theory in Section~\ref{sec:sensitivity_theory} for solving the max-min problems~\eqref{eqn:method-2},~\eqref{eqn:method-1},~\eqref{eqn:genl_method-2}, and~\eqref{eqn:genl_method-1}.
Because we can heuristics to solve these max-min problems \textit{without} sacrificing convergence of our (generalized) discretization methods, one heuristic is to use sensitivities of the value functions of these inner-minimization problems with the integer variables fixed to an optimal solution.
An alternative is to use smoothing-based approaches~\cite{ermoliev1995minimization} for approximating sensitivity information. 





\section{Numerical results}
\label{sec:numerical_results}

We compare Algorithms \texttt{GREEDY}, \texttt{2GREEDY}, \texttt{HYBRID}, and \texttt{OPT} in Section~\ref{subsec:algorithm_outlines} and \texttt{G-GREEDY}, \texttt{G-2GREEDY}, \texttt{G-HYBRID}, and \texttt{G-OPT}
in Section~\ref{subsec:genl_algorithm_outlines} with the \texttt{BF} algorithm on instances from the literature. 
We only consider scalar semi-infinite constraints and $Y = [y^L, y^U]$, and omit instances with trigonometric functions. 


\subsection{Implementational details}
Our codes are compiled using Julia 1.7.3, JuMP 1.3.1 \cite{JuMP2017}, BARON 23.1.5~\cite{baron} or Gurobi 9.1.2 as the global solver, Knitro 13.1.0 as the local NLP solver, Gurobi 9.1.2 as the LP solver, and the bundle solver MPBNGC 2.0 \cite{makela2003multiobjective} for the max-min problems. 
They will be made available at the following URL: \\ \url{https://github.com/Process-Optimization-and-Control/Optimal-SIP-Discretizations}.


\paragraph*{Handling weakly active constraints.}
Theorem~\ref{thm:parametric_sens} requires strict complementarity.
When \textit{only} this condition does \textit{not} hold,
the value functions $\phi_k$, $\psi_k$, $\phi^G_k$, and $\psi^G_k$ are piecewise-differentiable with a kink at the evaluation point. 
We can compute a subgradient in this case by excluding a subset of the weakly active constraints from the set of active constraints before solving the linear system in Theorem~\ref{thm:parametric_sens}.
In general, we exclude weakly active bound constraints as including them causes the derivative of the variable at the bound to be zero. 
All other weakly active constraints are included for the discretization methods, but excluded for the generalized discretization methods due to observed numerical issues (these choices were found to perform well in our experiments). 
Alternatively, one may consider using generalized derivatives \cite{stechlinski2019generalized}, which come at a higher computational expense. 


\paragraph*{General algorithmic parameters.}
Since~\eqref{eqn:disc-lbp} and~\eqref{eqn:higher-order-lbp} may not yield a feasible point finitely, we run our algorithms until the lower bound converges absolutely or relatively to within $10^{-3}$ of $v^*$ (which is computed offline).
We use $\varepsilon_f = \delta = 10^{-8}$ in Algorithms~\ref{alg:bfdisc},~\ref{alg:prototype_disc}, and~\ref{alg:prototype_genl_disc}.
The feasibility and optimality tolerance of Gurobi is set to $10^{-8}$.
All of BARON's parameters, except $\texttt{MaxTime} = 7200$s, are kept to default. 
Knitro is used with the following parameters: $\texttt{algorithm}=5$,  $\texttt{ftol}=10^{-8}$, and $\texttt{feastol}=10^{-8}$.  

\begin{table}[t]
\centering
% \resizebox{1.\linewidth}{!}{
\begin{tabular}{rccccccc}
\hline
\textbf{Instance}     & $\mathbf{d_x}$ & $\mathbf{d_y}$ & \texttt{BF}            & \texttt{GREEDY}        & \texttt{2GREEDY}       & \texttt{HYBRID}    & \texttt{OPT}   \\
            &    &    &  \multicolumn{5}{c}{\textbf{number of iterations for convergence}} \\ \hline
Watson 2    & 2 & 1  & \textbf{2}                 & \textbf{2}            & \textbf{2}           & \textbf{2}             & \textbf{2}  \\
Watson 5    & 3  & 1  & 5            & 4            & \textbf{2}           & 3             & 3 \\
Watson 6    & 2  & 1  & 3             & \textbf{2}            & \textbf{2}           & \textbf{2}             & \textbf{2}  \\
Watson 7    & 3 & 2  & \textbf{2}                 & \textbf{2}            & \textbf{2}           & \textbf{2}             & \textbf{2}  \\
Watson 8    & 6  & 2  & 15            & 6            & \textbf{4}           & 9            & 9 \\
Watson 9    & 6  & 2  & 9            & 8   & \textbf{5}           & \textbf{5}          &   13 \\
Watson h    & 2  & 1  & \textbf{18}            & 29       & 19           & 29      &   26     \\
Watson n    & 2  & 1  & 3             & 3            & \textbf{2}           & 3 & 3             \\
Seidel \& K{\"u}fer 2.1      & 2  & 1  & 8            & \textbf{2}            & \textbf{2}           & \textbf{2}  & \textbf{2}             \\
Tsoukalas \& Rustem 2.1        & 1  & 1  & 8            & \textbf{5}            & 6           & \textbf{5}            & \textbf{5}   \\
Mitsos 4\_3 & 3  & 1  & 5            & 4            & \textbf{2}           & 6           & 5   \\
Mitsos 4\_6 & 6  & 1  & 7            & 8           & 6           & \textbf{5}             & \textbf{5}  \\
Mitsos DP   & 1  & 1  & 28            & \textbf{2}             & \textbf{2}            & \textbf{2}    & \textbf{2}              \\
Cerulli et al.\ PSD 1 &	21 &	5 &	\textbf{2} &	\textbf{2} &	\textbf{2} &	\textbf{2} &	\textbf{2} \\
Cerulli et al.\ PSD 2 &	21 &	5 &	\textbf{2} &	\textbf{2} &	\textbf{2} &	\textbf{2} &	\textbf{2} \\
Cerulli et al.\ PSD 3 &	21 &	5 &	\textbf{2} &	\textbf{2} &	\textbf{2} &	\textbf{2} &	\textbf{2} \\
Cerulli et al.\ PSD 4 &	21 &	5 &	\textbf{2} &	\textbf{2} &	\textbf{2} &	\textbf{2} &	\textbf{2} \\
Cerulli et al.\ PSD 5 &	66 &	10 &	5 &	\textbf{2} &	5 &	\textbf{2} &	\textbf{2} \\
Cerulli et al.\ PSD 6 &	66 &	10 &	6 &	\textbf{2} &	\textbf{2} &	\textbf{2}&	\textbf{2} \\
Cerulli et al.\ PSD 7 &	105 &	13 &	7 &	\textbf{2} &	5 &	\textbf{2} &	\textbf{2} \\
Cerulli et al.\ PSD 8 &	105 &	13 &	5 &	\textbf{2} &	5 &	\textbf{2} &	\textbf{2} \\
\hline
\end{tabular}
% }%
\caption{
Comparison of the \texttt{BF}, \texttt{GREEDY}, \texttt{2GREEDY}, \texttt{HYBRID}, and \texttt{OPT} algorithms. 
Bold entries correspond to the minimum number of iterations for each instance.
}
\label{tab:resul-simple-probs}
\end{table}



\paragraph*{Algorithm-specific parameters.}
The starting point for the max-min problem solved by the \texttt{2GREEDY} method is specified as $0.99 \hat{y}^k + 0.005 (y^L + y^U)$. Similarly, for the \texttt{G-2GREEDY} method, the elements of $A^k$ are initialized randomly from $[0,1)$ and $b^k$ is set to \mbox{$0.99 \hat{y}^k + 0.005 (y^L + y^U) - A^kx^k$}. 
For the generalized discretization methods, the projection function $\text{mid}\{y^L, y, y^U\}$ is reformulated using the ``lambda/convex combination formulation''~\cite{vielma2015mixed} to derive an MINLP reformulation of~\eqref{eqn:higher-order-lbp}, whereas the smooth approximation \mbox{$t^{-1}\log((\exp(ty^L)+\exp(ty))^{-1}+\exp(-ty^U))$} with smoothing parameter $t = 100$ is used in the max-min problems. 
If the solution of these smooth approximations terminate after a single iteration of the bundle method, we restart their solution with a random initialization for $(A^k, b^k)$.
We set the parameter $K = 3$ for Algorithms~\texttt{HYBRID} and~\texttt{G-HYBRID}.


\subsection{Optimality-based discretization methods}
\label{sec: disc-methods}

We test our discretization methods on small-scale SIPs ($d_x \in [1,6]$ and $d_y \in \{1,2\}$) from Watson~\cite{watson1983numerical}, Seidel and K{\"u}fer~\cite{seidel2020adaptive}, Tsoukalas and Rustem~\cite{tsoukalas2011feasible}, and Mitsos~\cite{mitsos2009test}.
We also test our discretization methods on larger SIPs ($d_x \in [21, 105]$ and $d_y \in [5, 13]$) from Cerulli et al.\ \cite{cerulli2022convergent} where~\eqref{eqn:disc-lbp} is a quadratically constrained quadratic program (QCQP) that is solved globally using Gurobi.


Table~\ref{tab:resul-simple-probs} details the instance, dimensions $d_x$ and $d_y$, and the number of iterations $k$ taken by the different methods for their lower bounds to converge to $v^*$ (note that the number of discretization points at termination is $2k-2$ for \texttt{2GREEDY} and $k-1$ for the other methods).
We do not report computational times since all methods take similar time (seconds) for their lower bounds to converge (any gains from a decrease in the number of global solves is offset by the time taken for solving the max-min problems).


On almost all instances, our proposed optimality-based discretization methods require fewer iterations for convergence than the \texttt{BF} algorithm (the main exception is ``Watson h'', where our proposed methods face numerical issues).
Notably, our new discretization methods require only two iterations (a single discretization point for \texttt{GREEDY}, \texttt{HYBRID}, and \texttt{OPT}, and two discretization points for \texttt{2GREEDY}) to converge for most instances.
Although \texttt{OPT} is theoretically expected to perform at least as well as the other discretization methods, Table~\ref{tab:resul-simple-probs} shows that this is not always the case in practice.
This is because the solution of the max-min problem~\eqref{eqn:method-2} can get stuck at poor local maxima.
Overall, Algorithm~\texttt{2GREEDY} performs the best on the small-scale instances whereas \texttt{GREEDY}, \texttt{HYBRID}, and \texttt{OPT} all perform extremely well on the larger instances.




Table~\ref{tab:resul-mpcc} notes the performance of our discretization methods on the small-scale instances when max-min problems~\eqref{eqn:method-2} and~\eqref{eqn:method-1} are reformulated and solved as mathematical programs with complementarity constraints (MPCCs), see Section~\ref{subsec:solving_max_min}.
These MPCCs are solved using Knitro's tailored algorithms.
Comparing Table~\ref{tab:resul-mpcc} with Table~\ref{tab:resul-simple-probs} reveals that the discretizations generated by the MPCC formulations sometimes converge in fewer iterations, but require more iterations in other cases.
The MPCC formulation performs poorly on ``Tsoukalas \& Rustem 2.1'' possibly because it does not satisfy MFCQ at $x^*$.



\begin{table}[t]
\centering
% \resizebox{1.\linewidth}{!}{
\begin{tabular}{rccccccc}
\hline
\textbf{Instance}     & $\mathbf{d_x}$ & $\mathbf{d_y}$ &  \texttt{BF}            & \texttt{GREEDY}        & \texttt{2GREEDY}       & \texttt{HYBRID}    & \texttt{OPT}   \\
            &    &    &  \multicolumn{5}{c}{\textbf{number of iterations for convergence}} \\ \hline
Watson 2    & 2 & 1  & \textbf{2}                 & \textbf{2}            & \textbf{2}           & \textbf{2}             & \textbf{2}  \\
Watson 5    & 3  & 1  & 5            & 6            & \textbf{2}           & 3             & 3 \\
Watson 6    & 2  & 1  & \textbf{3}             & \textbf{3}            & \textbf{3}           & \textbf{3}             & \textbf{3}  \\
Watson 7    & 3 & 2  & \textbf{2}                 & \textbf{2}            & \textbf{2}           & \textbf{2}             & \textbf{2}  \\
Watson 8    & 6  & 2  & 15            & 20            & \textbf{14}           & 16            & 15 \\
Watson 9    & 6  & 2  & 9            & 5   & \textbf{4}           & 19       &   7 \\
Watson h    & 2  & 1  & \textbf{18}            &  \textbf{18}         &  \textbf{18}             &  \textbf{18}        &    \textbf{18}       \\
Watson n    & 2  & 1  & {3}                &\textbf{2}                & \textbf{2}           & \textbf{2}     & \textbf{2}                 \\
Seidel \& K{\"u}fer 2.1      & 2  & 1  & 8            & \textbf{2}            & 6          & \textbf{2}  & \textbf{2}        \\
Tsoukalas \& Rustem 2.1        & 1  & 1  & 8            & {7}            & \textbf{6}           & {12}            & $>100$     \\
Mitsos 4\_3 & 3  & 1  & 5            & 3            & \textbf{2}           & 3
          & 3   \\
Mitsos 4\_6 & 6  & 1  & 7            & 6           & 5           & \textbf{4}             & \textbf{4}  \\
Mitsos DP   & 1  & 1  & 28            & \textbf{2}             & \textbf{2}            & \textbf{2}    & \textbf{2}              \\
\hline
\end{tabular}
% }%
\caption{Results with the MPCC reformulation of the max-min problems.
Bold entries correspond to the minimum number of iterations for each instance.
}
\label{tab:resul-mpcc}
\end{table}



\subsection{Optimality-based generalized discretization methods}



We test our generalized discretization methods on small-scale SIP instances.



Table~\ref{tab:resul-simple-probs-sens} summarizes the performance of our generalized discretization methods relative to the \texttt{BF} algorithm.
These new methods perform well on most instances, but BARON times out during the solution of the nonconvex MINLP~\eqref{eqn:higher-order-lbp} for ``Watson~8'', ``Watson~9'', and ``Mitsos~4\_6''.
BARON appears to ``stall'' while solving these MINLPs---this could potentially be due to weak relaxations of~\eqref{eqn:higher-order-lbp}.
In most cases, the bundle method also terminates after one iteration during the solution of problems~\eqref{eqn:method-2} and~\eqref{eqn:method-1}, which suggests our initial guess is either locally optimal or does not provide a clear direction for improvement (which could be due to the smooth approximation of the projection operator).
Apart from ``Watson~h'' and ``Tsoukalas \& Rustem~2.1'', the generalized discretization methods do not offer a significant advantage over the optimality-based discretization methods in Section~\ref{sec:accelerated_discretization}.




\begin{table}[t]
\centering
% \resizebox{1.\linewidth}{!}{
\begin{tabular}{rccccccc}
\hline
\textbf{Instance}     & $\mathbf{d_x}$ & $\mathbf{d_y}$ &  \texttt{BF}            & \texttt{G-GREEDY}        & \texttt{G-2GREEDY}       & \texttt{G-HYBRID}    & \texttt{G-OPT}   \\
            &    &    &  \multicolumn{5}{c}{\textbf{number of iterations for convergence}} \\ \hline
Watson 2    & 2 & 1  & \textbf{2}                 & \textbf{2}            & \textbf{2}           & \textbf{2}             & \textbf{2}  \\
Watson 5    &  3 &  1 &      5       &  4 &  \textbf{3}  &    4      & 4   \\
Watson 6    & 2  & 1  & 3             & \textbf{2}            & \textbf{2}           & \textbf{2}             & \textbf{2}  \\
Watson 7    & 3 & 2  & \textbf{2}                 & \textbf{2}            & \textbf{2}           & \textbf{2}             & \textbf{2}  \\
Watson 8    &  6 &  2 &      15       &   TLE   & \textbf{9} &    TLE  &  TLE \\
Watson 9    &  6 &  2 &      {9}       &  TLE   & TLE &  TLE    & \textbf{8}   \\
Watson h   & 2  & 1  & 18            & \textbf{2}    & \textbf{2} & \textbf{2} & \textbf{2}\\
Watson n    &  2&  1 &      \textbf{3}       &  \textbf{3}  &  \textbf{3}   &    \textbf{3}      & \textbf{3}  \\
Seidel \& K{\"u}fer 2.1      & 2  & 1  & 8            & \textbf{3}            & \textbf{3}           & \textbf{3}  & \textbf{3}             \\
Tsoukalas \& Rustem 2.1        & 1  & 1   & 8      &  \textbf{2} & 3   & \textbf{2}  & 3 \\
Mitsos DP   & 1  & 1  & 28            & \textbf{2}             & \textbf{2}            & \textbf{2}    & \textbf{2}              \\


Mitsos 4\_3 & 3  & 1  & 5            &      5   & 5    &  5 & \textbf{4} \\
Mitsos 4\_6 & 6  & 1  & 7            &         \textbf{6}    &  TLE   &  \textbf{6} & TLE \\

\hline
\end{tabular}
% }%
\caption{
Comparison of the \texttt{BF}, \texttt{G-GREEDY}, \texttt{G-2GREEDY}, \texttt{G-HYBRID}, and \texttt{G-OPT} algorithms.
Bold entries correspond to the minimum number of iterations for each instance, and TLE denotes the time limit of $2$ hours was exceeded.
}
\label{tab:resul-simple-probs-sens}
\end{table}


\paragraph*{Summary.} Tables~\ref{tab:resul-simple-probs} to~\ref{tab:resul-simple-probs-sens} show that our optimality-based (generalized) discretization methods have the potential to significantly reduce the number of iterations for convergence relative to the classical feasibility-based approach.
We expect our new discretization methods to be particularly advantageous when solving~\eqref{eqn:disc-lbp} to global optimality is expensive.
While our preliminary results are encouraging, designing more efficient and reliable algorithms for solving our max-min formulations (in particular, our generalized discretization formulations~\eqref{eqn:genl_method-2} and~\eqref{eqn:genl_method-1}) merits further investigation.




\section{Future work}
\label{sec:conclusion}


There are many interesting avenues for future work.
First, we would like to extend our optimality-based (generalized) discretization methods to generalized semi-infinite programs~\cite{djelassi2021recent,mitsos2015global}.
Second, our optimality-based discretization methods could be modified (cf.\ \cite{mitsos2011global}) to generate feasible points to~\eqref{eqn:sip}.
Third, extensions of our max-min formulations can enable the design of more efficient cutting-plane methods for a broader class of optimization problems (cf.\ \cite{paulus2022learning}).
Finally, using machine learning to learn a sequence of optimal discretizations (cf.\ \cite{paulus2022learning,kannan2022learning,deza2023machine}) can mitigate the computational burden of solving our max-min problems for larger dimensions.





\section*{Acknowledgments}
E.M.T.\ and J.J.\ acknowledge the support of the Norwegian Research Council through the AutoPRO project (RN: 309628).
R.K.\ acknowledges funding from the Center for Nonlinear Studies at LANL and the U.S.\ Department of Energy’s Laboratory Directed Research and Development program (projects 20210078DR and 20230091ER).
% ``20210078DR: The Optimization of Machine Learning: Imposing Requirements on Artificial Intelligence'' and ``20230091ER: Learning to Accelerate Global Solutions for Non-convex Optimization.'' 
R.K.\ also thanks Dr.\ Harsha Nagarajan (LANL) and Prof.\ Qi Zhang (UMN) for helpful discussions.



{
\footnotesize
\section*{References}
\begingroup
\renewcommand{\section}[2]{}%
\bibliographystyle{abbrvnat}
\bibliography{main}
\endgroup
}



\end{document}

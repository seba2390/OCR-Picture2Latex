% !TEX root = main.tex

\section{Introduction}
\subsection{The contact process}
The contact process $\{\xi_t\}_{t \ge 0}$ is a Feller process on the configuration space $\{0,1\}^\Zd$ with generator
\begin{equation}
	\mathcal Lf(\eta)=\sum_{x\in\Zd}c(x,\eta)\big[f(\eta_x)-f(\eta)\big],
	\qquad \eta\in\{0,1\}^\Zd, 
\end{equation}
where $f\colon\{0, 1\}^\Zd \to \R$ is a cylinder function and $\eta_x$ is the configuration $\eta$ ``flipped at $x$'', i.e., 
\[ \eta_x(y)=\begin{cases}\eta(y)\quad&\text{if }y\neq x,\\ 1-\eta(y)\quad&\text{if }y=x.\end{cases}\] 
The ``flip rate'' $c(x,\eta)$ of the contact process is defined by 
\begin{equation}\label{eqFlipRateDef}
	c(x,\eta)=
	\begin{cases} 
		1&\text{if }\eta(x) = 1;\\
		\lambda \#\{y\in\Zd\colon|x - y| = 1, \eta(y) = 1\}&\text{if }\eta(x) = 0,
	\end{cases}
\end{equation}
where $|\cdot|$ denotes the 1-norm on $\Zd$, $\#S$ denotes the cardinality of a set $S$ and $\lambda \ge 0$ is a parameter of the process. 
The corresponding probability measure is denoted $\P_\lambda$. 
We refer to Liggett \cite[Chapter VI]{Ligge85} or \cite[Part I]{Ligge99} for a formal description, and for further references to Durrett \cite{Durre91}. 

The contact process is one of the prime examples of an attractive interacting particle system. Considering this process as a model for the spread of an infection leads to an insightful interpretation: lattice sites $x\in\Zd$ represent individuals, and at any given time $t\ge0$ individuals are either \emph{healthy} (if in state 0) or \emph{infected} (if in state 1). Infected individuals become healthy at rate 1, but spread the infection to their neighbors at rate $\lambda$. The higher $\lambda$, the more contagious the infection. 

The occurrence of a phase transition in $\lambda$ has been one of the driving forces for intense research activities centered around the contact process.
In order to describe this phenomenon, let $o$ denote the origin of $\mathbb{Z}^d$ and $\{\xi^o_t\}_{t\ge0}$ denote the contact process started from the configuration with a single infected individual at $o$, that is $\xi_0=\mathds{1}_{\{o\}}$, where $\mathds{1}$ is the indicator function. Then write 
\[ \{o \rightsquigarrow \infty\} = \bigcap_{t\ge0}\big\{\exists y\in\Zd\colon \xi^o_t(y) = 1\big\} \]
for the event that the infection \emph{survives} (in the complementary event, the infection is said to \textit{die out}). 
Then, there exists $\lambda_c\in(0,\infty)$ such that $\{\xi^o_t\}_{t \ge 0}$ has positive probability of survival if $\lambda > \lambda_c$ and dies out almost surely if $\lambda \le \lambda_c$. In other words, letting 
$$\rho = \P_\lambda(o \rightsquigarrow \infty),$$
denote the survival probability, we have 		$\rho	=0\text{ if }\lambda\le\lambda_c$ and $		\rho	>0\text{ if }\lambda>\lambda_c$, cf.\ \cite{Durre91,BezuiGrimm90}. 
%\begin{align*}
%	\P_\lambda(o \rightsquigarrow \infty)
%	\begin{cases}
%		\rho	&=0\qquad\text{if }\lambda\le\lambda_c;\\
%		\rho	&>0\qquad\text{if }\lambda>\lambda_c,
%	\end{cases}
%\end{align*}
%cf.\ \cite{Durre91,BezuiGrimm90}. 




\subsection{Supercritical contact process conditioned on survival}
As is standard, we always assume that the contact process is defined through a graphical representation (a family of Poisson processes consisting of \textit{transmission arrows} and \textit{recovery marks}, which induce \textit{infection paths}). We refrain from giving the details of the construction; rather, we briefly describe the terminology and notation we use. Given $x, y \in \Zd$ and $0 < s < t$, we write $(x,s) \rightsquigarrow (y,t)$ if there is an infection path from $(x,s)$ to $(y,t)$. In case $s = 0$, we simply write $x \rightsquigarrow (y,t)$. If $B, B' \subset \Zd \times [0,\infty)$, we write $B \rightsquigarrow B'$ if there is an infection path from a point in $B$ to a point in $B'$. The expressions $\{(x,s) \rightsquigarrow \infty\}$ and $\{x \rightsquigarrow \infty\}$ represent the events that there exists an infinite infection path started from $(x,s)$ and $(x,0)$, respectively.

 The graphical representation allows for the definition of the contact process with all possible initial configurations in the same probability space; one simply sets
$$\xi^A_t(x) =  \mathds{1}\{A \times \{0\} \rightsquigarrow (x,t) \},\quad A \subset \Zd,\;x \in \Zd,\; t \geq 0$$
for the process with $\xi^A_0 = \mathds{1}_A$. 

We often abuse notation and associate a configuration $\eta \in \{0,1\}^\Zd$ with the set $\{x:\eta(x) = 1\}$.

Throughout the paper, we work in the \emph{supercritical} regime. That is, we fix $\lambda>\lambda_c$ and write $\P$ instead of $\P_{\lambda}$ in the following. For these values of $\lambda$, write 
\begin{equation}
	\oP(E) = \P(E\mid o \rightsquigarrow \infty)
\end{equation}
for any measurable event $E$ on graphical constructions. That is, $\oP$ denotes the conditional probability given survival of the infection starting from the origin at time 0. We denote by $\oE$ the corresponding expectation. 
%denote the conditional probability of $E$ under the condition that the super-critical contact process $\xi^o$ started at the origin survives; and this can be extended to a conditional measure $\oP$.
Mind that the Markov property, valid under the measure $\P$, fails under the conditional measure $\oP$. For this reason, in the proofs of our main results, we often need to switch back and forth between these two measures. 



\subsection{Results}
Let 
$$t(x) = \inf\{s \ge 0:\, \xi^o_s = x\}$$ 
denote the first time that the contact process starting with a single infection at the origin $o$ infects the site $x$. We call this the \emph{hitting time} of $x$. 
In particular, the random field $\{t(x)\}_{x\in\Zd}$ contains fine-grained information on the space-time evolution of the contact process. The most prominent result is the \emph{shape theorem} for hitting times \cite{BezuiGrimm90, Durre88, DurreGriff82} describing asymptotically the ``once infected area'' 
%\[H_t=\{x\in\Zd\colon t(x)\le t\}+[-1/2,1/2]^d.\] 
\[H_t=\{x\in\Zd\colon t(x)\le t\}.\] 
Indeed, the normalized expected asymptotic hitting times
$$\mu(x)= \lim_{n \to \infty} \frac{t(nx)}{n}$$
%define a norm on $\Rd$ satisfying that for all $\eps > 0$ there exists  $\oP$-a.s.\ a time $t_0 > 0$ such that for all $t\ge t_0$, 
define a norm on $\Rd$ satisfying that for all $\eps > 0$ $\oP$-a.s.\ for all $t\ge0$ large enough, \begin{equation}
%	\{x\in\Rd\colon \mu(x)\le 1-\eps\}
%	\subset \frac1tH_t
%	\subset \{x\in\Rd\colon \mu(x)\le 1+\eps\}
	\{x\in\Zd\colon \mu(x)\le (1-\eps)t\}
	\subset H_t
	\subset \{x\in\Zd\colon \mu(x)\le (1+\eps)t\}.
%	\qquad\text{ $\oP$-a.s.}
\end{equation}
Additionally,  the probability that this event fails to hold for a given large time exhibits large deviation behavior~\cite{GaretMarch14} and $\mu(x)$ is continuous in the infection rate $\lambda$ for every $x\in\Rd$~\cite{GaretMarchThere15}. 

The shape theorem and its variants describe the global picture of the infection, that is, how fast the infection is spreading through space macroscopically. What can be said about the evolution on a microscopic level is not covered. A priori, it is possible that certain branches of the infection grow very fast at times so that the set $H_t$ exhibits holes close to its boundary. Moreover, the shape theorem alone does not make predictions on how wildly hitting times fluctuate locally or to what degree of monotonicity sites are visited in the order of increasing distance to the origin. In this paper, we refine this analysis by zooming in on the boundary of the set $H_t$ and prove that $H_t$ grows in a highly uniform way. 
% However, we prove that such holes are uniformly small: 

First, we consider the order in which sites on a linear ray $\{nx\}_{n \ge 0}$ are hit by the contact process. We show that, after averaging over $n$, the probability that sites are visited in the correct order becomes arbitrarily close to 1 when choosing the step size $|x|$ sufficiently large. Moreover, also the points of increase of the expected hitting time function $\oE[t(kx)]$ are of density arbitrarily close to 1 when $|x|$ is sufficiently large.
\begin{theorem}[Uniformity of hitting times]
	\label{mainThm}
	For the supercritical contact process conditioned on survival, 
	$$\lim_{|x| \to \infty}\liminf_{n \to \infty} \frac1n \sum_{k=1}^n \oP\big(t({(k-1)x}) \le t({k x})\big) = 1,$$
	and 
	$$\lim_{|x| \to \infty}\liminf_{n \to \infty} \frac1n \#\{k \in \{1,\ldots ,n\}:\, \oE[t({(k-1)x})] \le \oE[t({kx})] \} = 1.$$
\end{theorem}

The Ces\`aro limit of Theorem \ref{mainThm} implies immediately that for every $\eps > 0$,
\begin{equation}\label{eq:limsup}
	\limsup_{n \to \infty} \oP\big(t({nx}) \le t({(n+1) x})\big)>1-\eps 
\end{equation}
provided $|x|$ is large enough. 

Our second result is a tightness result which shows that also locally, the fluctuations of $t(x) - t(y)$ are of linear order in $|x - y|$.  
\begin{theorem}[Tightness]\label{thmTightness}
For any $p>0$, 
	$$\sup_{\substack{x,y\in\Zd \\ x \ne y}} \frac{\oE\left[|t(x) - t(y)|^p \right]}{|x-y|^p}  < \infty.$$
	In particular, the family
	$$\left\{\frac{t(x) - t(y)}{|x-y|}\right\}_{x, y \in \Zd, x \ne y}$$
%	\[ \{(t(x)-t(y))/|x-y|\}_{x,y\in\Zd, x \ne y}\]
is {tight} under the measure $\oP$. 
\end{theorem} 

\subsection{Outline of proof and essential hitting times}
\label{essHitSec}
%NEED TO PROVIDE UPPER BDS ON t(x) - t(y)
%NAIVELY EXPECT SUB-ADDITIVITY BUT NOT USEFUL
%NO STOPPING TIME UNDER CONDITIONAL
On a high level, both Theorems~\ref{mainThm} and~\ref{thmTightness} deal with bounds on differences of the form $t(x) - t(y)$. The first reflex in this situation would be to use the inequalities
\begin{align*}&(t(x) - t(y)) \cdot \mathds{1}\{t(y)<t(x)\}  \leq \tilde t(y,x) \cdot \mathds{1}\{t(y)<t(x)\},\\ &(t(y) - t(x)) \cdot \mathds{1}\{t(x)<t(y)\}  \leq \tilde t(x,y) \cdot \mathds{1}\{t(x)<t(y)\},\end{align*}
where $\tilde t(y,x)$ is the amount of time it takes for the infection spreading from $(y,t(y))$ to reach $x$, and similarly for $\tilde t(x,y)$. One is tempted to combine these inequalities with a translation invariance property: under $\P$, conditioning on say $t(y) < t(x)$, and after a space-time shift, $\tilde t(y,x)$ is distributed as $t(x-y)$.

Although true, these observations are not as useful as it would seem. There are two problems. First, the time $\tilde t(y,x)$ could be infinite, as the infection first reaching $y$ could die out before reaching $x$; this renders the above inequalities less useful. Second, under the measure $\oP$, the aforementioned translation invariance property is lost.

%On a high level, both Theorems~\ref{mainThm} and~\ref{thmTightness} deal with bounds on differences of the form $t(x) - t(y)$. The first reflex in this situation would be to apply sub-additivity in a suitable coupling, since the time from an infection to reach a site $x$ is certainly at most the time that the contact process needs to infect $x$ by a path passing through $y$. Although true, this observation is not as useful as one could hope for, since the infection started from site at $x$ at time $t(x)$ could die out. In more mathematical terms, under the unconditional law $\P$, the hitting time $t(y)$ is a stopping time and it is therefore a highly flexible tool in renewal arguments involving the strong Markov property. However, under the conditional measure $\oP$, the hitting time $t(y)$ is unsuitable for renewal-type arguments.

%=> ESSENTIAL STOPPING TIMES TO THE RESCUE
%REQUIRE BOUNDS ON sigma(x) - t(x)
These problems illustrate why the shape theorem is substantially more difficult to establish for the contact process than for the related model of first-passage percolation (more about it below). It was only with the 
%ground-breaking idea of introducing 
introduction of 
\emph{essential hitting times}~\cite{GaretMarch12} that the supercritical contact process could be analyzed via
sub-additivity techniques. 
The essential hitting times exhibit highly useful invariance properties under the conditional law $\oP$, and are therefore a central quantity in our analysis.

Loosely speaking, the essential hitting time is the first time when the infection hits a site $x$ and this particular branch of the infection survives. These are obviously not stopping times (because we are conditioning on the future), but it is possible to set up the definitions in a neat way so that the times $\sigma(x)$ are renewal times. Birkner et al.\ \cite{BirknCernyDeppeGante13} applied a similar construction in the context of a genealogical model. 

Now, we represent the expression $t(x) - t(y)$ as
$$t(x) - t(y) = (t(x) - \sigma(y)) + (\sigma(y) - t(y)).$$
As we will see in Section~\ref{thmSec}, in the specific setting of Theorems~\ref{mainThm} and~\ref{thmTightness}, the first summand is indeed amenable to a renewal argument. However, this approach is bound to fail for the second summand, since $t(y)$ is at most as big as $\sigma(y)$. The proof of the shape theorem relies crucially on bounds for $\sigma(y) - t(y)$~\cite[Proposition 17]{GaretMarch12}. However, those bounds turn out to be unsuitable for the granularity that we are aiming for, since they depend on the location $y$. To remove this dependence, we present a conceptually novel argument forming the heart of the proof for our main results.


In order to define the essential hitting times precisely, we define for any site $x\in\Zd$ a sequence of stopping times $\{u_n(x)\}_{n \ge 0}$ and $\{v_n(x)\}_{n \ge 0}$. 
These are initialised as $u_0(x)=v_0(x)=0$. 
Given $v_k(x)$, we define 
\[u_{k+1}(x)=\inf\{t\ge v_k(x):x\in\xi^o_t\}\]
to be the first time that $x$ is infected after time $v_k(x)$ (with the usual convention $\inf\varnothing=+\infty$). 
Further, given $u_{k+1}(x)$, we define 
\[v_{k+1}(x)=\sup\{s\ge0:\; (x,u_{k+1}(x)) \rightsquigarrow \Zd \times \{s\}\} \]
to be the time at which the single infection present at $x$ at time $u_{k+1}(x)$ dies out again. 

With these definitions at hand, we let 
\[K(x)=\min\{n\ge0:v_n(x)=\infty\text{ or }u_n(x)=\infty\}.\]
Note that, under $\oP$, we almost surely have $K(x) < \infty$, $u_{K(x)} < \infty$ and $v_{K(x)} = \infty$. Then let 
\[\sigma(x)=u_{K(x)}(x).\]


Clearly, the essential hitting times are larger than the standard ones, i.e., $\sigma(x) - t(x) \ge 0$. Additionally, for a given site $x \in \Zd$ the deviation of $\sigma(x)$ from $t(x)$ has exponential tails~\cite[Proposition 17]{GaretMarch12}, where the rate of decay could still depend on $x$. As a key tool in the proof of our main results, we show that in situations where stretched exponential decay is sufficient, this dependence can be entirely eliminated. 

\begin{proposition}\label{propEssTightness}
	There exist $C,\gamma > 0$ such that, for all $x \in \mathbb{Z}^d$ and all $L > 0$,
$$\oP(\sigma(x) - t(x) > L) < C\exp\left\{-L^\gamma\right\}.$$
\end{proposition}
An immediate consequence is that the differences between hitting times and essential hitting times $\{\sigma(x)-t(x)\}_{x\in\Zd}$ is a tight family of random variables. 

\subsection{Discussion and open problems}
\subsubsection{First-passage percolation and coexistence for competition models} 
%Uniformity results in the spirit of Theorem 1.1 do not only apply to the contact process but also in the setting of \emph{first-passage percolation}~\cite{GaretMarch05, Hoffm05}. 

%A limit result similar to Theorem \ref{mainThm} in the context of \emph{first-passage percolation} has been established by Garet and Marchand \cite{GaretMarch05} and independently by Hoffmann \cite{Hoffm05}.

In first-passage percolation, every bond $\{x,y\}$ (with $|x-y|=1$) in $\Zd$ is assigned a non-negative value $\tau_{\{x,y\}}$. The family $\{\tau_{\{x,y\}}:x,y\in\Zd,\;|x-y|=1\}$  is typically sampled from some translation-invariant probability distribution on functions from the nearest-neighbor edges of $\Zd$ to $[0,\infty)$; most often, the times are independent, following some common law $\mu$ supported on $[0,\infty)$. For any two vertices $x$ and $y$, the \textit{passage time} from $x$ to $y$ is then defined as
\begin{equation}\label{eq:random_metric} d(x,y)=\inf\left\{\sum_{k=1}^{|\pi|}\tau_{\{\pi_{k-1},\pi_k\}}:\pi\text{ is a path from $x$ to $y$}\right\}, \end{equation} 
where a path $\pi$ from $x$ to $y$ is a finite sequence $\pi=(\pi_0,\pi_1,\dots,\pi_n)$ with $n\in\mathbb N$, $\pi_0=x$, $\pi_n=y$, and $|\pi_k-\pi_{k-1}|=1$ for $k=1,\dots,n$, and  $|\pi| = n$ is its length. Thus defined, $d(\cdot,\cdot)$ is a random (pseudo-)metric on $\Zd$.

A \textit{growth process} can be defined from $d$ by letting
\begin{equation}\label{eq:growth_process}
\zeta_t(x) = \mathds{1}\{d(o,x) \leq t \},\quad t \geq 0,\; x \in \Zd.
\end{equation}
Very general shape theorems have been obtained for this process; see for instance \cite{GaretMarch12}. In the particular case in which the random variables $\tau_{\{x,y\}}$ are i.i.d. and exponentially distributed, it can be shown that $(\zeta_t)_{t \geq 0}$ is a Markov process on $\{0,1\}^\Zd$; it is called the \textit{Richardson model}, and can be seen as the contact process with no recoveries. That is, transitions from state 1 to state 0 are suppressed.

In this context of first passage percolation, a statement analogous to our Theorem \ref{mainThm} is that, if $|x|$ is large enough, then
\begin{equation}
\label{eq:analogous_statement}
\limsup_{n\to\infty} \P\left(d(o,nx) < d(o,(n+1)x) \right) > \frac12.
\end{equation}
This has been proved in \cite{haggstrom1998first} for the Richardson model on $\mathbb{Z}^2$ and for much more general passage-time distributions on $\Zd$ in \cite{GaretMarch05} and \cite{Hoffm05}.

Apart from the growth process \eqref{eq:growth_process}, the random metric in \eqref{eq:random_metric} can be used to define a \textit{competition process}. For this, fix two distinct \textit{sources} $x_1, x_2 \in \Zd$, let $$d(\{x_1,x_2\},x) = \min(d(x_1,x),d(x_2,x))$$ and define a process $\eta_t \in \{0,1,2\}^\Zd$ by setting
\begin{equation}
\label{eq:competition_process}
\eta_t(x) = \begin{cases}0&\text{if } t > d(\{x_1,x_2\},x),\\1&\text{if } t \leq d(\{x_1,x_2\},x),\; d(x_1,x) \le d(x_2,x),\\
2&\text{if }   t \leq d(\{x_1,x_2\},x),\; d(x_1,x) > d(x_2,x) \end{cases} \quad\qquad t \geq 0,\; x \in \Zd.
\end{equation}
This can be interpreted as follows: at time 0, a particle of type 1 is placed at $x_1$ and a particle of type 2 is placed at $x_2$; each type then invades adjacent sites as in the growth process \eqref{eq:growth_process}, with the rule that once a site has been taken by one of the types, it stays that way permanently. Then, $\Zd$ is partitioned into the sets
$$C_i = \{x\in\Zd:\;\lim_{t\to\infty}\eta_t(x) = i\},\quad i = 1,2.$$
The event $\{\#C_1=\#C_2 = \infty\}$ is called the \textit{coexistence event}, and one then wonders if it has positive probability. Letting $x_1= o$ and $x_2 = \bar{x} \in \Zd$, if the probability of coexistence with these two sources was zero, then symmetry would give
$$\P( \#C_1 = \infty,\;\#C_2 < \infty) = \P(\#C_1 < \infty,\;\#C_2 = \infty) = \frac12,$$
from which \eqref{eq:competition_process}  would allow us to conclude that
\begin{equation} \label{eq:first_impli}\lim_{n \to \infty} \P(d(o,n\bar{x}) < d(\bar{x},n\bar{x})) = \frac12,\end{equation}
which is equivalent to
\begin{equation} \label{eq:second_impli}\lim_{n \to \infty} \P(d(o,n\bar{x}) < d(o,(n+1)\bar{x})) = \frac12,\end{equation}
contradicting \eqref{eq:analogous_statement}, at least if $|\bar{x}|$ is large enough. Hence, for first-passage percolation, proving \eqref{eq:analogous_statement} is the key step in proving that coexistence can occur (and indeed, the aforementioned references \cite{haggstrom1998first, GaretMarch05, Hoffm05} were all primarily concerned with the coexistence problem).

A natural question, then, is whether our Theorem \ref{mainThm} can be reinterpreted as a coexistence result. The competition model that corresponds to the contact process in the same way as model \eqref{eq:competition_process} corresponds to the growth model \eqref{eq:growth_process} is Neuhauser's \textit{multitype contact process}, introduced in \cite{Neuha92}. However, the equivalence between \eqref{eq:first_impli} and \eqref{eq:second_impli}, which stems from the fact that both the growth process $(\zeta_t)_{t\geq 0}$ and the competition model $(\eta_t)_{t\geq 0}$ are defined from the same random metric, has no evident analogue for the contact process. Proving that the coexistence event has positive probability for the multitype contact process on $\Zd$ is still an open problem, apart from the easiest case of $d=1$ (see \cite{andjel2010survival} and \cite{valesin2010multitype}).

\iffalse

In this context, the authors prove 
\begin{equation}\label{eqHittingFPP}
	\limsup_{n \to \infty} \P\big(t(o,{x}) \le t(o,{ x+1})\big)>\tfrac12, 
\end{equation}
which is very reminiscent of our Theorem \ref{mainThm}. 

\blue{In the proof of~\cite[Theorem 3.1]{GaretMarch05} the authors establish a variant of Theorem \ref{mainThm} in the setting of first-passage percolation.}

\todo[inline]{MH: Daniel, could you check whether it's true what that G-M prove the claim in (6), please? Or otherwise replace it with the blue text (or a similar formulation)? }

The result in \eqref{eqHittingFPP} has an interpretation in terms of coexistence in a two-type Richardson model. %~\cite{HaggsPeman98}.
To this end, we can think of two species, $A$ and $B$ that exclude each other. Initially, both species inhabit one single site each, say $x$ and $y$, and all other sites are vacant. As time progresses, species $A$ present at $x$ invades a neighbouring site $x+e$ (with $|e|=1$) after time $\tau_{\{x,x+e\}}$ provided that the $x+e$ is still vacant at that time, and then $x+e$ also tries to invade vacant neighbours. Species $B$ evolves in the same manner. We see that under this dynamics every site $z\in\Zd$ is invaded eventually by one of the two species, and it is invaded by species $A$ if and only if  $t(x,z) < t(y,z)$. 
Then, coexistence of the two species means that there are both infinitely many sites that $x$ infects before $y$ and infinitely many sites that $y$ infects before $x$. Formally, coexistence is described by the event
\begin{equation}\label{eqCoexistence}
	C(x,y)=\left\{\#\{z\in\Zd:t(x,z)<t(y,z)\} = \#\{z\in\Zd:t(x,z) > t(y,z)\} = \infty\right\}. 
\end{equation}
There is always positive probability of non-coexistence when one species ``surrounds'' the other and thereby blocks it from any vacant area. The quest is whether coexistence has positive probability or not. Indeed, a beautiful time-reversal argument due to H\"aggstr\"om and Pemantle~\cite{HaggsPeman98} shows that $\P(C(o,x))=0$ is possible only if $\limsup_{n \to \infty} \P\big(t(o,{nx}) \le t(o,(n+1)x)\big) = 1/2$.
%Indeed, H\"aggstr\"om and Pemantle use a time-reversal argument to show that $\P(C(x,y))=0$ implies that $\limsup_{n \to \infty} \P\big(t(o,{x}) \le t(o,{ x+1})\big)=1/2$, and therefore \eqref{eqHittingFPP} implies that $\P(C(x,y))>0$. 

We believe that coexistence in the form of \eqref{eqCoexistence} remains valid for the supercritical contact process. 
The reason why we cannot draw the analogy to a suitable competition model lies in the existence of the ``dead ends'' -- branches of the infection that do not survive even though the infection as a whole does. 

%Moreover, the contact process on $\Zd$, $d \ge 3$ with two different types of infection (that exclude each other) exhibits coexistence in the sense that there exist invariant measures with support on both infection types simultaneously~\cite{Neuha92}.
Note that this notion of coexistence is very different to the one considered by Neuhauser \cite{Neuha92}, who studied the  contact process on $\Zd$ with two different types of infection that exclude each other. She proved that there exist invariant measures with support on both infection types simultaneously if and only if $d\ge3$.  
\fi

\subsubsection{Contact process in random environment.}
In a series of papers, the shape theorem has been extended to the \emph{contact process in random environment} by Garet and Marchand~\cite{GaretMarch12, GaretMarch14}. In this setting, the infection rate $\lambda$ is not constant. Rather, in \eqref{eqFlipRateDef}, we replace $\lambda$ with a random variable $\lambda_{\{x,y\}}$, and these random variables form an i.i.d.\ family with support in $[\lambda_{\mathsf{min}},\lambda_{\mathsf{max}}]$ where $0<\lambda_c<\lambda_{\mathsf{min}}<\lambda_{\mathsf{max}}<\infty$. Indeed, following the setup in \cite{GaretMarch12}, our results extend in a straightforward manner to this random setting. 

\iffalse \subsubsection{Density of record times.} Theorem~\ref{mainThm} implies that the expected hitting times $\{h_x(k)\}_{k \ge 0} =  \{\oE[t(kx)]\}_{k \ge 0}$ exhibit infinitely many \emph{points of increase}, i.e. points where $\oE[h_x(k - 1)] \le \oE[h_x(k)]$. In fact, the density of points of increase becomes arbitrarily close to 1 as $x$ grows large. As we will see in the Section~\ref{thmSec}, Theorem~\ref{mainThm} can be strengthened in the sense that points of increase can be replaced by \emph{record points}. That is, integers $k \ge 0$ such that $\oE[h_x(k)] \ge \oE[h_x(\ell)]$ for all $\ell \le k$. \fi
\bigskip


\subsection{Organization of the paper}
In the forthcoming section, we first prove Proposition \ref{propEssTightness}. This result gives strong quantitative estimates on the relation of $t(x)$ and $\sigma(x)$, and is the key to our proofs of Theorems \ref{mainThm} and \ref{thmTightness}, both of which we defer to Section \ref{thmSec}. 

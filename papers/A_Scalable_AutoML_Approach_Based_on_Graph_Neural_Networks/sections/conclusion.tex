
\section{Conclusion}
\label{sec:con} 

This paper proposed a novel formulation for the AutoML problem as a graph generation problem, where we can pose learner and pre-processing selection as a generation of different graphs representing ML pipelines. Hence, we developed the {\sysname} system based on mining large repositories of scripts, and leveraging recent techniques for static code analysis. {\sysname} utilized embeddings generated based on dataset contents to predict and optimize a set of ML pipelines based on the most similar seen datasets. {\sysname} is designed to work with AutoML systems, such as Auto-Sklearn and FLAML, to utilize their hyperparameter optimizers. We conducted the most comprehensive evaluation of 121 datasets, including the datasets used by FLAML, VolcanoML, and AL. Our comprehensive evaluation shows that {\sysname} significantly improves the performance of FLAML and Auto-Sklearn in classification and regression tasks. Moreover, {\sysname} outperformed AL, which is based on a more costly meta-learning process, in 97\% of the datasets. This outstanding performance shows that the KGpip meta-learning approach is more effective and efficient. Finally, {\sysname} outperforms VolcanoML in 62\% of the datasets and ties with it in 22\%.   


%This paper proposed a novel formulation for the AutoML problem as a graph generation problem, where we can pose learner and pre-processing selection as a generation of different graphs representing ML pipelines. Following this approach, we developed the {\sysname} system based on mining large repositories of scripts, leveraging recent techniques for static code analysis.  {\sysname} utilized embeddings generated based on dataset contents to predict and optimize a set of ML pipelines based on the most similar seen datasets. We designed {\sysname} to work with existing AutoML systems, such as Auto-Sklearn and FLAML, to utilize their hyperparameter optimizers. Based on a comprehensive evaluation of 77 datasets from different ML portals, such as Kaggle and OpenML, our evaluation shows that {\sysname} manages to significantly outperform state-of-the-art AutoML systems in both regression and classification tasks. Moreover,  {\sysname} outperforms the AL system, which depends on dynamic code analysis. {\sysname} scales well based on static code analysis while providing the benefits of dynamic execution. 
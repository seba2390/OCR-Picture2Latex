
\section{Related Work}
\label{related_work}
% We review work related to each of our research questions; and we restrict our review to work related to processing tabular structured data; neural architecture search which is also a target of AutoML is not within the scope of what we cover here.

In this section, we summarize the related work and restrict our review to  meta-learning approaches for AutoML, dataset embeddings, and processing tabular structured data. 

\subsubsection*{Learner and preprocessing selection} 
 In most AutoML systems, learner and pre-processing selection for the cold start problem is driven by a database of actual executions of pipelines and data; e.g., \cite{al}, \cite{autosklearn}, \cite{NEURIPS2018_b59a51a3}.  This database often drives both learner selection and hyper parameter optimization (HPO), so we focus here more on how the database is collected or applied to either problem, since the actual application to learner selection or HPO is less relevant.  For HPO, some have cast the application of the database as a multi-task problem (see \cite{multitaskBO}), where the hyperparameters for cold start are chosen based on multiple related datasets. Others, for instance, \cite{autosklearn,Reif2012}, compute a database of dataset meta-features on a variety of OpenML \cite{OpenML} datasets, including dataset properties such as the number of numerical attributes, the number of samples or skewness of the features in each dataset.  
 
These systems measure similarity between datasets and use pipelines from the nearest datasets based on the distance between the datasets' feature vectors as we do, but the computation of these vectors is different, as we describe in detail below.  Auto-Sklearn 2.0 \cite{autosklearn2} defines instead a static portfolio of pipelines that work across a wide variety of datasets, and use these to cold-start the learner selection component - that is, every new dataset uses the same set of pipelines.  Others have created large matrices documenting the performance of candidate pipelines for different datasets and viewed the selection of related pipelines as a collaborative filtering problem \cite{NEURIPS2018_b59a51a3}.
 
\subsubsection*{Dataset embeddings}
The most used mechanism to capture dataset features rely on the use of meta-features for a dataset such as \cite{autosklearn,Reif2012}.  These dataset properties vary from simple, such as number of classes (see, e.g. \cite{Engels98usinga}), to complex and expensive, such as statistical features (see, e.g. \cite{Vilalta_usingmeta-learning}) or landmark features (see, e.g. \cite{Pfahringer00meta-learningby}).  As pointed out in Auto-Sklearn 2.0 \cite{autosklearn2}, these meta-features are not defined with respect to certain column types such as categorical columns, and they are also expensive to compute, within limited budgets.  The dataset embedding we adopt is builds individual column embeddings, and then pools these for a table level embedding.  Similar to our approach, \citet{drori2019automl} use pretrained language models to get dataset embeddings based on available dataset textual information, e.g. title, description and keywords. Given these embeddings, their approach tries to find the most similar datasets and their associated baselines. Unlike \cite{drori2019automl}, our approach relies on embedding the actual data inside the dataset and not just their overall textual description, which in many cases is not available. OBOE \cite{Yang_2019} uses the performance of a few inexpensive, informative models to compute features of a model.

\subsubsection*{Pipeline generation}
There is a significant amount of work viewing the selection of learners as well as hyperparameters as a bayesian optimization problem like \cite{multitaskBO,autoweka}.  Other systems have used evolutionary algorithms along with user defined templates or grammars for this purpose such as TPOT \cite{le2020scaling} or Recipe \cite{S2017RECIPEAG}.  Still, others have viewed the problem of pipeline generation as a probabilistic matrix factorization \cite{NEURIPS2018_b59a51a3}, an AI planning problem when combined with a user specified grammar \cite{ICAPS20paper208,Ml-plan}, a bayesian optimization problem combined with Monte Carlo Tree Search \cite{ijcai2019-457}, or an iterative alternating direction method of multipliers optimization (ADMM) problem \cite{liu2019admm}.  Systems like VolcanoML focus on an efficient decomposition of the search space ~\cite{VolcanoML}. To the best of our knowledge, %we do not know of any system that has
{\sysname} is the first system to cast the actual generation of pipelines as a neural graph generation problem.

Some recent AutoML systems have moved away from the fairly linear pipelines generated by most earlier systems to use ensembles or stacking extensively.  H2O for instance uses fast random search in combination with ensembling for the problem of generating pipelines \cite{LeDell2020H2OAS}.  Others rely on "stacking a bespoke set of models in a predefined order", where stacking and training is handled in a special manner to achieve strong performance \cite{erickson2020autogluontabular}. Similarly, PIPER \cite{piper} uses a greedy best-first search algorithm to traverse the space of partial pipelines guided over a grammar that defines complex pipelines such as Directed Acyclic Graphs (DAGs).  The pipelines produced by PIPER are more complex than the linear structures used in the current AutoML systems we use to test our ideas for historical pipeline modeling, and we do not use ensembling techniques yet in our approach.
Neither is precluded, however, because {\sysname} meta-learning model can generate any type of structures, including complex structures that mined pipelines may have. 








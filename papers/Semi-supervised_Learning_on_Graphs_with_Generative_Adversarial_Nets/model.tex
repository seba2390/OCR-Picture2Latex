\begin{figure}[t]
	\centering
	\includegraphics[width=\linewidth]{./img/example.png}% 1\linewidth
	\caption{A qualitative illustration of  working principles in \model. 
		The two labeled nodes are in solid blue and solid orange respectively and all the other nodes are unlabeled nodes.	
		The left figure is a bad case of vanilla Label Propagation algorithm. In this case, node $v_3$ is assigned a wrong label due to its direct link to  node $v_+$. 
		The right figure illustrates how \smodel works. It generates fake nodes (in black) in the density gap thus reduces the influence of nodes across the density gap.
}\label{example}
\end{figure}

 \begin{figure*}
 \centering
 \includegraphics[width=0.75\linewidth]{./img/classifier2.png}% 1\linewidth
 \caption{An overview of our model. Fake inputs are generated by generator and real inputs are acquired by concatenating original feature $\mathbf{w}_i$ and learned embedding $\mathbf{q}_i$. Both real inputs and fake samples generated by generator are fed into the classifier.}\label{overview}
 \end{figure*}
 
\section{Model Framework}
\label{sec:gen_fs}

\subsection{Motivation}
\label{sec:mot}
We now introduce how we leverage the power of GANs for semi-supervised learning over graphs. Directly applying GAN to graph learning is infeasible, as it does not consider the graph structure. To show how GANs help semi-supervised learning over graphs, we begin with one example. The left figure in Figure~\ref{example} shows a typical example in graph-based semi-supervised learning. The two labeled nodes are in blue and orange respectively. Traditional methods such as Label Propagation~\cite{zhu2002learning} does not consider the graph topology, thus cannot differentiate the propagations from node $v_+$ to nodes $v_1$, $v_2$, and $v_3$. 
Taking a closer look at the graph structure, we can see there are two subgraphs. We call the area between the two subgraphs as \textbf{density gap}.

Our idea is to use GAN to estimate the density subgraphs and then generate samples in the density gap area. We then request the classifier firstly to discriminate fake samples before classifying them into different classes.
In this way, discriminating \textit{fake} samples from \textit{real} samples will result in a higher curvature of the learned classification function around density gaps, which 
weakens the effect of propagation across density gaps (as shown in the right figure of Figure~\ref{example}).
Meanwhile inside each subgraph, confidence on correct labels will be gradually boosted because of supervised loss decreasing and general smoothing techniques for example stochastic layer. A more detailed analysis will be reported in \S~\ref{sec:verify}.



 
\subsection{Architecture}
\label{arch}
 	GAN-based models cannot be directly applied to graph data.
 	To this end, \smodel first uses network embedding methods (e.g., DeepWalk~\cite{Perozzi:14KDD}, LINE~\cite{tang2015line}, or NetMF~\cite{Qiu:2018WSDM}) to learn latent distributed representation $\mathbf{q}_i$ for each node, and then concatenates the latent distribution $\mathbf{q}_i$ with the original feature vector $\mathbf{w}_i$, i.e., $\mathbf{x}_i=(\mathbf{w}_i, \mathbf{q}_i)$. 
 	Finally, 
 	$\mathbf{x}_i$ is taken as input to our method.
 	
 	Figure~\ref{overview} shows the architecture of \model.
	Both classifier $D$ and generator $G$ in \smodel are multiple layer perceptrons.
	More specifically, the generator takes a Gaussian noise $\mathbf{z}$ as input and outputs fake samples having the similar shape as $\mathbf{x}_i$. In the generator, {\it batch normalization} ~\cite{ioffe2015batch} is used. 
 	Generator's output layer is constrained by {\it weight normalization} trick~\cite{salimans2016weight}  with a trainable weight scale.
 	%   
    Discriminator in GANs is substituted by a classifier, where stochastic layers(additive Gaussian noise) are added after input and full-connected layers for smoothing purpose. Noise is removed in prediction mode. Parameters in full-connected layers are constrained by weight normalization for regularization. 
    %
    Outputs of the last hidden layer in classifier $h^{(n)}(\mathbf{x})$\label{feature} are features extracted by non-linear transformation from input $\mathbf{x}$, which is essential for feature matching~\cite{salimans2016improved} when training generator. The classifier ends with a $(M+1)$-unit output layer and softmax activation. The outputs of unit $0$ to unit $M-1$ can be explained as probabilities of different classes and output of unit $M$ represents probability to be fake. In practice, we only consider the first $M$ units and assume the output for fake class $P_M$ is always 0 before softmax, because subtracting an identical number from all units before softmax does not change the softmax results.
 

 



\subsection{Learning Algorithm}
\subsubsection{Game and Equilibrium}
GANs try to generate samples similar to training data but we want to generate fake samples in density gaps. So, the optimization target must be different from original GANs in the proposed \smodel model. For better explanation, we revisit GANs from a more general perspective in game theory.

In a normal two-player game, $G$ and $D$ have their own loss functions and try to minimize them. Their losses are interdependent. We denote the loss functions $\mathcal{L}_G(G, D)$ and $\mathcal{L}_D(G, D)$. Utility functions $V_G(G,D)$ and $V_D(G, D)$ are negative loss functions.
	
GANs define a \emph{zero-sum game}, where $\mathcal{L}_G(G, D) = -\mathcal{L}_D(G, D)$. In this case, the only Nash Equilibrium can be reached by minimax strategies~\cite{von2007theory}. To find the equilibrium is equivalent to solve the optimization:
\beq{\nonumber\min\limits_G\max\limits_D V_D(G,D)}
    
Goodfellow et al. ~\cite{goodfellow2014generative} proved that if $V_D(G,D)$ was defined as that in equation \ref{gan_aim}, $G$ would generate samples subject to data distribution at the equilibrium. The distribution of generate samples $p_g(\mathbf{x})$ is an approximation of the distribution of real data $p_d(\mathbf{x})$. But we want to generate samples in density gaps instead of barely mimicking real data. So, original GANs cannot solve this task.



\begin{figure}[t]
\includegraphics[width=0.75\linewidth]{./img/script.png}
\caption{An illustration of the expected equilibrium in $h^{(n)}(\mathbf{x})$. The dotted areas are clusters of training data with different labels(colorful points). Unlabeled samples(white points) are mapped into a particular clusters. Distinct density gaps appear in the center, in which lie the generated samples(black points).}\label{expected}
\end{figure}

In the proposed \model, we modify $\mathcal{L}_D(G, D)$ and $\mathcal{L}_G(G, D)$ to design a new game, in which $G$ would generate samples in density gaps at the equilibrium. More precisely, we expect that the real and fake samples are mapped like Figure \ref{expected} in its final representative layer $h^{(n)}(\mathbf{x})$. Because the concept of ``density gap'' is more straightforward in a representative layer than in a graph, we define that a node lies in density gap if and only if it lies in density gap in $h^{(n)}(\mathbf{x})$ layer. How to map nodes into representative layer is explained in section \ref{arch}.

The intuition behind the design is based on the famous phenomenon known as ``curse of dimensionality'' ~\cite{donoho2000high}. In high-dimensional space like $h^{(n)}(\mathbf{x})$, the central area is far more narrow than outer areas. Training data in the central area are easy to become \emph{hubs}~\cite{radovanovic2010hubs}. Hubs frequently occurs in the nearest neighbors of samples from other classes, which might deeply affect semi-supervised learning and become a main difficulty. So, we want the central area become a density gap instead of one of clusters.

We define $\mathcal{L}_D(G, D)$ and $\mathcal{L}_G(G, D)$ as below to guarantee the expected equilibrium.

\beq{\begin{aligned}
\mathcal{L}_D =& loss_{sup} + \lambda_0 loss_{un} + 
\lambda_1 loss_{ent} + loss_{pt}\\
\mathcal{L}_G =& loss_{fm} + \lambda_2 loss_{pt}
\end{aligned}
}

\noindent Next, we explain these loss terms in $\mathcal{L}_D(G, D)$ and $\mathcal{L}_G(G, D)$ and how they take effect in details.

\subsubsection{Discriminative Losses}\label{LD} 
At equilibrium, no player can change their strategy to reduce his loss unilaterally. Supposing that $G$ generates samples in central areas at equilibrium, we put forward four conditions for $D$ to guarantee the expected equilibrium in $h^{(n)}(\mathbf{x})$:

\begin{enumerate}
\item Nodes from different classes should be mapped into different clusters.
\item Both labeled and unlabeled nodes should \textbf{not} be mapped into the central area so as to make it a density gap.
\item Every unlabeled node should be mapped into one cluster representing a particular label.
\item Different clusters should be far away enough.
\end{enumerate}

The most natural way to satisfy condition (1) is a supervised loss $loss_{sup}$. $loss_{sup}$ is defined as the cross entropy between predicted distribution over $M$ classes and one-hot representation for real label. 
    
%\begin{small}
\begin{equation}
	loss_{sup} = -\mathbb{E}_{\mathbf{x}_i\in X^L} \log P(y_i|\mathbf{x}_i, y_i < M)
\end{equation}
%\end{small}

\noindent where $X^L$ is the set of inputs for labeled nodes $V^L$.
	
Condition (2) is equivalent to the $D$'s aim in original GAN given that $G$ generates fake samples in central density gaps. Thus we still use the loss in equation \ref{gan_aim} and call it $loss_{un}$. The classifier $D$ incurs $loss_{un}$ when real-or-fake misclassification happens.  
    
\begin{equation}
\begin{aligned}
	loss_{un} =& -\mathbb{E}_{\mathbf{x}_i \in X^U} \log [1-P(M|\mathbf{x}_i)] \\&- \mathbb{E}_{\mathbf{x}_i \sim G(\mathbf{z})} \log P(M|\mathbf{x}_i)
\end{aligned}
\end{equation}

\noindent where $X^U$ is set of pretreated inputs for unlabeled nodes $V^U$; $G(\mathbf{z})$ is the distribution of generated samples; and $P(M|\mathbf{x}_i)$ denotes the predicted fake probability of $\mathbf{x}_i$. 

Condition (3) requests $D$ to assign an unambiguous label to every unlabeled node. We solve the problem by adding an entropy regularization term $loss_{ent}$, the entropy of distribution over $M$ labels. Entropy is a measurement of uncertainty of probability distributions. It has become a regularization term in semi-supervised learning for a long time~\cite{grandvalet2005semi} and is firstly combined with GANs in ~\cite{springenberg2015unsupervised}. Reducing entropy could encourage the classifier to determine a definite label for every node.

%\begin{small}
\begin{equation}
	loss_{ent} = -\mathbb{E}_{\mathbf{x}_i \in X^U} \sum\limits_{y=0}^{M-1} P(y|\mathbf{x}_i, y_i < M)\log P(y|\mathbf{x}_i, y_i < M) 
\end{equation}
%\end{small}

Condition (4) widens density gaps to help classification. We leverage pull-away term $loss_{pt}$~\cite{zhao2016energy} to satisfy it. $loss_{pt}$ is originally designed for generating diverse samples in ordinary GANs. It is the average cosine distance between vectors in a batch. It keeps representations in $h^{(n)}(\mathbf{x})$ layer as far from the others as possible. Hence, it also encourages clusters to be far from the others.

  %  \begin{small}
    \begin{equation}\label{loss_pt}
    loss_{pt} = \frac{1}{m(m-1)}\sum\limits_{i=1}^m\sum\limits_{j\neq i}\frac{h^{(n)}(\mathbf{x}_i)^\top h^{(n)}(\mathbf{x}_j)}{||h^{(n)}(\mathbf{x}_i)||||h^{(n)}(\mathbf{x}_j)||}^2
\end{equation}
        %\end{small}

\noindent where $\mathbf{x}_i,\mathbf{x}_j$ are in the same batch and $m$ is batch size.

\subsubsection{Generative Losses} Similarly, supposing that $D$ has satisfied the four conditions above, we also have two conditions for $G$ to guarantee the expected equilibrium in $h^{(n)}(\mathbf{x})$:

\begin{enumerate}
\item $G$ generates samples which are mapped into the central area.
\item Generated samples should \textbf{not} overfit at the only center point.
\end{enumerate}

For condition (1), we train $G$ using \emph{feature matching} loss~\cite{salimans2016improved}. It minimizes the distances between generated samples and the center point of real samples $\mathbb{E}_{\mathbf{x}_i \in X^U\cup X^L} h^{(n)}(\mathbf{x}_i)$. Actually, in training process the center point is replaced by center of samples in a real batch $\mathbb{E}_{\mathbf{x}_i \in X_{batch}} h^{(n)}(\mathbf{x}_i)$, which helps satisfy condition (2).
The distances are originally measured in $L2$ norm. (But, in practice, we found that $L1$ norm also works well, with even slightly better performance.)

\begin{equation}
	loss_{fm} = ||\mathbb{E}_{\mathbf{x}_i \in X_{batch}} h^{(n)}(\mathbf{x}_i) - \mathbb{E}_{\mathbf{x}_j \sim G(\mathbf{z})} h^{(n)}(\mathbf{x}_j)||_2^2
\end{equation}

Condition (2) requests generated samples to cover as much central areas as possible. We also use a pull-away loss term(Equation \ref{loss_pt}) to guarantee the satisfication of this condition, because it encourage $G$ to generate diverse samples. A trade-off is needed between centrality and diversity, thus we use a hyper-parameter $\lambda_2$ to balance $loss_{fm}$ and $loss_{pt}$. The stochastic layers in $D$ add noise to fake inputs, which not only improves robustness but also prevents fake samples from overfitting.


\begin{algorithm}[t]
\caption{Minibatch stochastic gradient descent training of \model}\label{algo}
\KwIn{
Node features $\{\mathbf{w}_i\}$, Labels $y^L$, Graph $G=(V,E)$, Embedding Algorithm $\mathcal{A}$, batch size $m$.}
Calculate $\{\mathbf{w}_i'\}$ according to Eq. (\ref{neighbor_fusion}) \\
Calculate $\{\mathbf{q}_i\}$ via $\mathcal{A}$\\
Concatenate $\{\mathbf{w}_i'\}$ with $\{\mathbf{q}_i\}$ for $X^L\cup X^U$ \\
\Repeat{Convergence}{
	Sample $m$ labeled samples $\{\mathbf{x}^L_1,..., \mathbf{x}^L_m\}$ from $X^L$\\
    Sample $m$ unlabeled samples $\{\mathbf{x}^U_1,..., \mathbf{x}^U_m\}$ from $X^U$\\
    Sample $m$ noise samples $\{\mathbf{z}_1,...,\mathbf{z}_m\}$ from $p_\mathbf{z}(\mathbf{z})$\\
    Update the classifier by descending gradients of losses:
    $$\nabla_{\theta_D} \frac{1}{m}\sum loss_{sup} + \lambda_0 loss_{un} + \lambda_1 loss_{ent} + loss_{pt}$$ 
    \For{t steps}{
		Sample $m$ unlabeled samples $\{\mathbf{x}^U_1,..., \mathbf{x}^U_m\}$ from $X^U$\\
    	Sample $m$ noise samples $\{\mathbf{z}_1,...,\mathbf{z}_m\}$ from $p_\mathbf{z}(\mathbf{z})$\\
        Update the generator by descending gradients of losses:
        $$\nabla_{\theta_G} \frac{1}{m} \sum loss_{fm} + \lambda_2 loss_{pt}$$
    }
}
\end{algorithm}

\subsubsection{Training} GANs train $D$ and $G$ by iteratively minimizing $D$ and $G$'s losses. In game theory, it is called \emph{myopic best response}~\cite{aumann1974subjectivity}, an effective heuristic method to find equilibriums. \smodel is also trained in this way. 

The first part of training is to turn nodes in the graph to vectors in feature space. We use LINE~\cite{tang2015line} for pretreatment of $\mathbf{q}$, which performs fast and stable on our dataset. We also test other network embedding algorithms and find similar performances in classification. To accelerate the convergence, nodes' features $\mathbf{w}$ are recalculated using \textit{neighbor fusion} technique. Let $Ne(v_i)$ be the set of neighbors of $v_i$, node $v_i$'s weights are recalculated by

%\begin{small}
\begin{equation}\label{neighbor_fusion}
\mathbf{w}_i' = \alpha \mathbf{w}_i + \frac{1-\alpha}{|Ne(v_i)|}\sum\limits_{v_j \in Ne(v_i)} \mathbf{w}_j.
\end{equation}
%\end{small}

The neighbor fusion idea is similar to the pretreatment tricks using attention mechanisms
~\cite{DBLP:journals/corr/abs-1710-10903}.

In the main training loop, we iteratively trains $D$ and $G$. 
To compute $\mathcal{L}_D$, we need three batches of labeled, unlabeled and generated samples respectively. $loss_{sup}$ needs labeled data. $loss_{un}$ is computed based on unlabeled and generated data. Theoretically, $loss_{un}$ should also take account of labeled data to make sure that they are classified as real. But $loss_{sup}$ has made labeled data classified correctly as its real label so that it is not necessary to consider labeled data in $loss_{un}$. $loss_{ent}$ only considers unlabeled data and $loss_{pt}$ should ``pull away'' both labeled and unlabeled data. 
Usually three hyperparameters are needed to balance the scales of four losses. We only use two parameters $\lambda_0$ and $\lambda_1$ in \smodel because $loss_{sup}$ will soon be optimized nearly to 0 due to few labeled samples under the semi-supervised setting.

Both real and generated batches of data are needed to train $G$. $loss_{fm}$ compares the batch center of real and generated data in $h^{(n)}(\mathbf{x})$ and $loss_{pt}$ measures the diversity of generated data. We always want $G$ to generate samples in central areas, which is an assumption when discussing $\mathcal{L}_D$ in section ~\ref{LD}. So, we train $G$ several steps to convergence after every time we train $D$. 
%
Detailed process is illustrated in Algorithm \ref{algo}.




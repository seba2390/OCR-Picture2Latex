

  \subsection{Old Text}
  To begin with, let us formalize the idea of \emph{interaction}. For \sys{} an interaction is an AST modification triggered by the user. More specficically, it is a \emph{tree substitution}:
  Suppose for instance that we wish to formalize the transformation between the following two pairs of queries:
  \begin{quote}
  \texttt{SELECT x FROM T;}\\
  \texttt{SELECT y FROM T;}
  \end{quote}
  Assume further that the branch of the AST that contains the modification is the following:
  \begin{quote}
  \texttt{/SELECT\_CLAUSE/TABLE\_NAMES/NAME/x}
  \end{quote}
  We can model the mofication as a tree substitution, where $\pi$ is the path \texttt{/SELECT\_CLAUSE/TABLE\_NAMES} and the new subtree $\tau$ is \texttt{/NAME/y}.

  The first challenge that \sys{} must tackle is to detect interactions. As we explained, \sys{} does not seek all possible transformations - only those allowed by the users, through the interaction query language PI-Lang. Formally a PI-Lang statements is a user defined filter:
  $$
  PI_k:(q, q') \mapsto   \begin{cases}
        \texttt{TRUE} & \text{if allowed}\\
        \texttt{FALSE} & \text{otherwise}
  \end{cases}
  $$
  With those definitions, we can define our first problem:
  \begin{problem}
  For each pair of queries $(q_i, q_j)$  such that $PI_k(q_{i},q_{j}) = \texttt{TRUE}$ for some $k$, return the set of interaction parameters $(\pi_{ij}, \tau_{ij})$:
  $$
  t(q_{i}, \pi_{ij},\tau_{ij}) = q_j
  $$
  \end{problem}
  The output of this problem is the interaction graph, which describes the interaction that maps every valid pair of queries from the log. In this graph, each edge is labelled by a triplet $(PI_k, \pi_{ij}, \tau_{ij})$ which uniquely defines the interaction.

  \subsection{Creating Interfaces}
  Once we created the interaction graph, the next step is to build the actual interface. The core idea is to select a set of interface component that can express the transformation described by the graph. The core challenge stems from the fact that there are many ways to do so. First, observe that the interaction graph is actually a \emph{multigraph} - each pair of queries may be connected with several competing interactions. Furthermore, each interaction may be mapped to several different widgets, based on the values that we want it to express. For instance, we may express a change in a  numeric value witha drowpdown list, a slider or a text box. We see that building an interaction involves solving two interdependent sub-problems: (1) chose interactions to connect the queries and (2) map interface components to those interactions. Because the best choice of interactions must ultimately lead to the best interface, we will solve both problems jointly.

  We define an \emph{interface component} as a mapping $w = (\Theta_w, \Omega_w, \pi)$ where $\Theta_w$ is a \emph{widget type}, $\Omega_w$ is a \emph{widget domain} and $\pi$ is a path. The widget type describes the widget's intrinsic nature, for instance a dropdown list or a text box. It defines the greater domain in which the widget takes its values, as well as a series of user-defined \emph{cost functions}, which map a widget's domain to a numeric cost. The domain is the set of values that the widget can produce. Those will be turned into a subtree $\tau$ and fed to an interaction using the path $\pi$.

  Our aim is to generate a minimum cost set of widgets that lets the users express all the queries in the log. To define an interface's expressiveness, let us first introduce the \emph{init widget}. The init widget is a special component, automatically triggered when the user launches the interactive application. It sets the first query $q_0$ to seed the exploration process. All subsequent widgets will modify this query $q_0$. To do so, they issue values from their domain $\Omega_w$, transform them into subtrees by filling an AST template and feed this subtree to an interaction. This produces a new value $q_i$, to be modified by the subsequent interactions. Let $I = \{w_i\}$ denote a user interface, e.g., a  set of widgets. We call the \emph{closure} of $I$, denoted $\mathcal{C}(I)$, the set of queries of that $I$ can express with this method.

   \begin{problem}
   Given a set of widget types $\{\Theta_m\}_{m \in 1..T}$ and a set of paths and parameters as described above, find a set of widgets $W = \{w_1, \ldots, w_N\}$ that solves:
   \begin{equation*}
   \begin{split}
   \text{Argmin}_{I} & \sum_{w \in I} \sum_{m \in 1..M_{\Theta_w}} \alpha_m \cdot C_m^w(\Omega_w)\\
   \text{s.t.~~}  &   \mathcal{C}(I) = Q^{LOG}
   \end{split}
   \end{equation*}
   \end{problem}


















% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% PILANG
%
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

We now describe each clause in further detail.

% Two \emph{from} clause examples are given below:
% \textbf{1. WhereClause///ValueExpression as a;} defines a variable a and assign it the value of all nodes with node type ``value expression'' that has a ancestor with node type ``WhereClause''. Nodes whose node type is not ``ValueExpression'' or do not have an ancestor with node type ``WhereClause'' are ignored. \\
% \textbf{2. ProjectClauses as b;} defines a variable b. The program traverses through the entire AST tree and assigns all nodes with the node type ``ProjectClauses'' to variable b.\\


% \noindent As shown in the above examples, each path expression can be mapped to several nodes in the AST trees. A///B specifies that A is an ancestor of B, A//B and A/B specifies that A is the parent or a sibling of B respectively. Parentheses can be used to specify precedence (\texttt{(A//B)/C}).  Finally, the nodes that match the path expression can be bound to a named variable using the \texttt{<pathexpr> AS <variable name>} expression. The expressive power of the from clause statements are equivalent to the full XPath language, as the allowed operations(i.e. parent/ancestor/sibling/parentheses) are exactly the name, and users are able to point to any node in the tree using these operations.\\\\
% Every path expression or from clause statement correspond to two sets of nodes, one for each AST tree. Consider the pair of query (Q1,Q2):
% \begin{verbatim}
% Q1: SELECT * FROM users WHERE age BETWEEN 18 and 25
% Q2: SELECT * FROM users WHERE age BETWEEN 40 and 50
% \end{verbatim}
%  The first set of nodes are all nodes in the AST representation of Q1 that matches the path expression, while the second set of nodes are all nodes in the AST representation of Q2 that matches the same path expression. Our program then returns a table with the following schema.
% \begin{verbatim}
% Table: (PI-Lang, Variable_name, Values_old, Values_new, Paths_old, Paths_new)
% \end{verbatim}
% The first two columns of this table will be explained in later sections. In all cases, the Path variable contains the path of the variable in the AST tree. It is a list of pairs [...[node type, index]...] where node type is the type of node encountered and index is its index in the traversal. For instance, consider the following PI-Lang statement and the two queries:
% \begin{verbatim}
% SELECT a, b, d from A
% SELECT a, b FROM A
% \end{verbatim}
% Then, the table will be:
% \begin{center}
%     \begin{tabular}{| l | l | l | l | l |}
%     \hline
%     ...& ValuesOld & ValuesNew& PathsOld & PathsNew \\ \hline
%     .. & a & a& [...,[result column, 0]] &[...,[result column, 0]] \\
%     ... & b & b& [...,[result column, 1]] &[...,[result column, 1]] \\
%     ... & d & null& [...,[result column, 2]] &null \\
%     \hline
%     \end{tabular}
% \end{center}
\subsubsection{Where Clause}
The \emph{where} clause is a boolean expression over the variables defined in the \emph{from} clause that specifies how they may differ. The statement generates a match when the expression evaluates to true. The suffixes @new and @old can be appended to a range variable to reference the corresponding nodes in two AST trees respectively. Finally, we support convenience expressions to help perform set comparisons between the two versions of the path expressions. For instance, T@old subset T@new specifies that new nodes were inserted into T, whereas $|T| = 1$ checks that there is only one matching node. To better illustrate the syntax, a \emph{from} and \emph{where} clause example is given below:
\begin{verbatim}
FROM ProjectClauses as b;
WHERE b@old subset b@new;
\end{verbatim}
The incremental changes in the AST level we want to identify is: if the project clauses of query 1 is a subset of query 2 while everything else is the same.
 % Besides the subset operations, other allowed operations are listed in the following tables:
% The operations supported in our language is listed in the following tables:
% \begin{table}[h]
% \centering
% \begin{tabular}{ |l|l|l| }
% \hline
% \multicolumn{3}{ |c| }{Supported Set Operations} \\
% \hline
% Syntax & Examples & Explanation \\ \hline
% union& a union b & the union of two sets \\ \hline
% intersect& a intersect b & the intersect of two sets \\ \hline
% difference& a difference b & the difference of two sets \\ \hline
% subset & a subset b&  returns true if $a \subseteq b$\\ \hline
% equal & a equal b&  returns true if $a = b$\\ \hline
% notequal & a notequal b&  returns true if $a \not= b$\\ \hline
% $|$ $|$ & $|a|$&  number of elements in a \\ \hline
% \end{tabular}
% \caption{Supported Set Operations}
% \end{table}
% \begin{table}[h]
% \centering
% \begin{tabular}{ |l| }
% \hline
% \multicolumn{1}{ |c| }{Supported Arithmetic Operations} \\
% \hline
% +, -, *, /, $>$, $>=$, $<$, $<=$, $==$, $!=$, ...\\
% \hline
% \end{tabular}
% \caption{Supported Arithmetic Operations}
% \end{table}















% match clause

% \begin{verbatim}
% SELECT a, b, d from A
% SELECT a, b FROM A

% FROM ProjectClauses as val
% WHERE val@old != val@new
% MATCH pc-diff(val)
% \end{verbatim}
% Then the match clause
% Then, the table will be:
% \begin{center}
%     \begin{tabular}{| l | l | l | l | l | l |}
%     \hline
%     PILang&VariableName& ValuesOld & ValuesNew& PathsOld & PathsNew \\ \hline
%     pc-diff & val&... & ...& ... &... \\
%     pc-diff & val&... & ...& ... &... \\
%     pc-diff & val&... & ...& ... &... \\
%     \hline
%     \end{tabular}
% \end{center}
% This table, along with the name chosen for the transformation will be used by the widget selector.



% \subsubsection{Syntactic Sugar}
% The \emph{from} clause is able to express tree structures and select a set of nodes that comply to it. However, the path expressions in the \emph{from} clause fail to express quantitative filters on the nodes. For example, they fail to return only all value expressions that are greater than 2. These filters can be incorporated in the \emph{where} clause, but often leads to very complicated \emph{where} clause expressions. To simplify PI-Lang programs, we allow quantitative filters in the \emph{from} clause. When the path expressions in the \emph{from} clause are executed, two tables are created for each variable, one for each tree, and the name of these tables correspond to the defined variable name. For example, if the pair of tree we are comparing is the tree representation of (Q1,Q2), and our path statement is ``ProjectClause//TableExpression as tables", then two tables(i.e. table@old and table@new) will be constructed. To allow quantitative filters, we allow SQL statements to define new variables on top of the path expressions(e.g. SELECT top 1 from tables as id).


% Users label PI-Lang statements in the where clause. First of all, users give a name for the transformation described in the from clause and the where clause. Secondly, out of all variables defined in the from clause, users pick one variable for the table construction process described in section 1.1. Consider the following example:


% Recall that the goal of PI-Lang programs is to express structural differences between AST trees, the \emph{from} clause specifies where the difference happens. It consists of several X-Path like expressions, enabling users to define variables and to bind them to nodes in the AST trees.












% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Optimizations
%
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{verbatim}
FROM +WhereClause as W;
WHERE W@old != W@new;
MATCH WhereClause-Different;

FROM +Projectclause as P;
WHERE |P@old| == |P@new| && |P@old - P@new| == 1;
MATCH ProjectClause-One-Element-Change;
\end{verbatim}

The bottleneck for this algorithm is that no optimization is done for non transitive PI-Lang programs, so the quadratic complexity is still not avoided. Also, the clustering process is independent for every transitive PI-Lang statement. The cliques that are generated by 1 PI-Lang statements are not very useful for other PI-Lang statements as there could be edges between some pairs of queries in the same clique, and there could also be edges between pairs of queries belonging to different cliques that correspond to different PI-Lang statements. Therefore, even when we have the cliques generated by 1 PI-Lang statement, we would have to do a pairwise comparison within each clique, compare queries in different cliques, and do a pairwise comparison on the queries that are not clustered. Comparing queries in different cliques can be accelerated by hashing and sorting methods, but the remaining two processes remain very slow. \\\\


% Our solution is to add a preprocessing clustering process. This process clusters the queries into several cliques, such that for all transitive or non-transitive statements, we would not need to do a pairwise comparison on queries in the same clique. In order to do this, we can make some assumptions on the AST trees ---they are composed of internal nodes and leaf nodes. Leaf nodes can be value nodes or other nodes. Under this assumption, the preprocessing step can be described as follows:\\\\

%Step 1: Add a preprocessing step to cluster queries. If only the value nodes of two queries are different, cluster them in a single cluster.\\\\
%\emph{Note:} If there are n cliques, the input to the program will be $n+1$, one corresponding to each clique(cliquei.csv) and one last file(queries.csv) that contains all the remaining queries. The format of all files should be (queryid, AST-representation).\\\\
%Step 2: For each clique, create a dummy query and put it in queries.csv. The dummy queries should not contain any specific values, but instead should use a general value.
% \\\\
% \emph{Example: (Clique 1)}\\
% Query 1: SELECT * FROM A WHERE a = 1 AND b = 2\\
% Query 2: SELECT * FROM A WHERE a = 2 AND b = 3\\
% Query 3: SELECT * FROM A WHERE a = 3 AND b = 4\\\\
% In this case, the dummy create should be \\Query 4: SELECT * FROM A WHERE a = X AND b = X\\\\
% Step 3: For every PI-Lang statement, run a pairwise comparison on all pairs of queries in queries.csv.\\\\
% Step 4: Sample two queries from each clique. Run all transitive PI-Lang statements on the two queries. If there is an edge between this pair of queries, this transformation can also be applied to any two queries in the same clique.\\\\
% Step 5: For every PI-Lang statement, check if there are any edges between cliques. This can be done by randomly sampling 1 query from each clique, and then checking if the PI-Lang statement applies.






















\iffalse
	\subsection{Algorithm}
	\subsubsection{Outline}
	To solve the problem, we introduce a bottom-up agglomerative heuristic. We start with a trivial page: for each $p$ in the program log, we create an interface $(p, \{\})$. Figure~\ref{fig:basepage} presents an example of such page. At each step, we find the ``best'' pair of interfaces and merge them, as shown in Figure~\ref{fig:merging}. We stop when one interface covers all the queries or when the objective function stops improving.

	To find the best interfaces to merge, we use the \emph{merge graph} a graph in which each vertex is an interface and each edge indicates 1) whether an interaction exists to connect the two interfaces and 2) the improvement in the cost function associated with the merge. The graph shrinks as the algorithm goes by: after each iteration, we collapse the nodes that represent the chosen interfaces and we update the adjacent edges - as shown in Figure~\ref{fig:graph}.

	We now present the algorithm in more detail.

	\subsubsection{Initialization}
	\begin{figure}[t]
		\centering
		\includegraphics[width=\columnwidth]{figures/baseUI}
		\caption{Base page - each UI expresses exactly one query. \ewu{Probably can cut this and just use the next figure.}}
		\label{fig:basepage}
	\end{figure}

	\begin{figure}[t]
		\centering
		\includegraphics[width=\columnwidth]{figures/merge_graph}
		\caption{Merging graph, before and after one iteration}
		\label{fig:graph}
	\end{figure}
	To initialize the merge graph, we create one node per interface. For each pair of interfaces, we check if there exists an interaction that maps their underlying queries. If so, we add an edge labeled with the name of that interaction and we compute the \emph{merge scores}. The merge scores tell us how much the objective function increases or decreases when we merge the interfaces for every possible widget that can express the transition.

	\subsubsection{Iterations}
	At each iteration, we perform three actions. First, we find the most promising edge in the merge graph. The most promising edge is the one that yields the best improvement in the objective function (we use the maximum merge score). Second, we merge the two interfaces connected by this edge. Technically, because the edges are oriented, the left interface ``absorbs'' the right one. This involves either adding new widgets or adding a value to existing widgets, depending on whether the interface supports the transition interaction or not. Third and finally, we update the graph: we collapse the relevant nodes and we update the adjacent edges.

\fi



\begin{figure*}[t]
\centering
\includegraphics[width=\textwidth]{figures/pipeline-horizontal.png}
\caption{\sys parses queries into canonicalized parse trees, performs tree alignment to generate an {\it interaction graph} that is filtered using the \lang domain specific language and  whose edges are mapped to interface widgets.}
\label{f:pipeline}
\end{figure*}


\section{Overview}
\label{sec:overview}

We give an overview of the precision interfaces setup and solution pipeline, as well as the technical challenges that we address in the subsequent sections.

\stitle{Query Logs as API} Interfaces are traditionally created by programmers or through a WYSIWYG application, so why mine interfaces from query logs?  The primary reason is that query logs encode the analyses that analysts {\it actually} perform, and therefore can be used to suggest candidate interfaces. As an API, logs are a flexible abstracton that can be generated from a variety of sources.  Modern program execution engines (e.g., DBMSs, Spark, Jupyter, RStudio) already track program logs for recovery and debugging purposes, while explicit provenance metadata systems are increasingly ubiquitous in industry~\cite{ground,mavlyutovdependency} and research~\cite{ives2008orchestra,muniswamy2006provenance,callahan2006vistrails}.  Any analysis that directly uses these systems, or uses them as a backend (e.g., Tableau) will naturally collect query logs.  Our hope is that if \sys is successful, then cleaning and finding query logs will be an interesting problem in its own right.


% This paper introduces the first step towards a general pipeline for generating interfaces and focuses on using only logs of program source code for analysis.  However, the above trends point towards the availability of richer program execution meta-data, including logs of user GUI interactions. Using this information to improve the pipeline is a promising direction for extending this work.






\subsection{Pipeline Overview}

We decompose the general problem of generating interfaces based on query logs in two sub-tasks: finding structural changes between queries and mapping those changes to interactions. The complexity and precision of the resulting interfaces depends on the types of structural changes that we can identify and the quality of the user interactions that we can map to arbitrary changes.

The problem is difficult because the scope of what a user interaction may express is theoretically unlimited---a button press could replace the current query with an arbitrary query string---and can easily lead to unusable interfaces.  We must bound the complexity of structural changes, and provide simple mechanisms to specify the types of changes that are meaningful.  Also, the system should easily adapt to new programming languages, as well as new types of interaction widgets (e.g., new modalities such as touch).

Based on these observations, we decompose the \sys process into three logical steps (Figure~\ref{f:pipeline}). The {\it Representation Canonicalizer} transforms the input sequence of query strings into a canonicalized parse tree structure (an AST) that makes query comparisons easier.

The {\it Interaction Miner and Distiller} logically identifies structural changes between the ASTs based on an ordered tree matching algorithm. These changes form an {\it interaction graph} where each node represents a query/AST and each directed edge is labeled by a corresponding structural transformation; it is a multi-graph because there may be multiple labeled edges between any two nodes.   To reduce the set of erroneous changes and preserve interesting changes, the developer can {\it distill} the graph by using a simple change specification language called \lang for specifying interesting structural changes.  We provide an interactive log analysis tool for suggesting potentially useful \lang statements, and use this tool in our experiment setup.

The {\it Interaction Mapper} maps sets of edges in the interaction graph to interaction components in interfaces.  Because this problem is NP-hard, we use a graph contraction heuristic to compute a best effort solution.  We then compile the resulting interfaces into an interactive web application.

\begin{figure}[ht]
\centering
\includegraphics[width=.4\columnwidth]{figures/DummyInterface}
\caption{An example interface.}
\label{f:dummy}
\end{figure}

% \subsubsection{A Simple Example}
%
% \ewu{Show a simple example with two or three queries, walk through each of the steps. Goal is to highlight why each step is challenging.  See Example 1 in Jag's NaLIR paper}
%

\subsection{Challenges and Assumptions}
Real-life query logs may contain much variability, and it is not obvious how to map  arbitrary AST tree differences to widgets automatically. This leads to three major technical challenges.
The first is to develop a unified model of queries, interactions, interfaces and interface components (widgets) that is restricted enough for analysis (Section~\ref{s:model}).
But even then, the number of structural changes in a query log is quadratic in the log size and the majority of those changes are irrelevant. The second challenge is to develop mechanisms to identify the subset of changes that are meaningful to translate to interfaces (Section~\ref{s:pilang}).
Finally, the third challenge is to map these changes to components in one or more interfaces.  We show that this problem is NP-hard and present an efficient heuristics to generate the interfaces (Section~\ref{s:interface}).

% The second is to design a language to specifying the types of structural changes that are semantically meaningful and interesting.  For instance, changing the table alas in a \texttt{FROM} clause does not change the semantics of a query, however changing the alias of a project cause may or may not be interesting and depends on the application domain.   In this paper, we rely on developers to write these statements, however we are investigating automatic means based on analyzing interaction widget definitions as future work.
% 3) interaction mapping is hard because there are multiple optimization objectives and the problem is NP-hard.  (describe a bit more.) Needs a flexible way support multiple objectives and tune preferences between these objectives, as well as a fast algorithm to generate the mappings.
% 4) Performance, since the results depend on specifing \lang statements, it is desirable for the end-to-end system to be fast so that developers can try different statements.  Clearly, computing all pair-wise query differences is unacceptable for logs containing millions of queries, and thus more efficient and approximate means are needed.



%\ewu{Have a better name than diff-tables.  Create a macro for the name.}


\stitle{Inputs and Assumptions: } We assume that we have access to the grammar for each language, a parser to map program source code to a parse tree, an unparser to translate parser trees into source code~\cite{unparse}, and annotations of AST node types to understand which nodes are literals, or collections.

A core assumption is that most syntactic changes in the query log are {\it incremental}, such that the changes can be mapped to interactive interface components. To test this property, we evaluated \sys on query logs generated by students analyzing a dataset using SQL. We found that a majority of the queries changes conform the the assumptions, as we will show in Section~\ref{sec:case_stud}. In addition, we do not assume deep semantic understanding about the queries beyond near-universal features such as primitive data types---the whole analysis is performed syntactically.

Another assumption on which \sys{} is built is that there exists no logical dependency between the entries in the log -- for instance, no query uses a view or a temporary table defined in another statement. One way to remove this limitation would be to detect clusters of queries using, e.g., pattern mining or source code analysis. We leave this line of study for future work.

Finally, we assume two functions $exec()$ and $render()$ for a given language that executes a query AST and renders the output, respectively.  $exec()$ is called on an interface's current query state and for SQL query logs, $render()$ either generates a simple visualization~\cite{mackinlay2007show,mackinlay1986automating} or renders a table.


%\ewu{Discuss that we want to make a minimal set of assumptions about the queries in the log.  For instance, we don't deal with the semantics.  We simply assume the existence of a grammar and some structure to language grammars---namely common data types, and AST nodes that represent lists of elements (argument lists, expression lists, from clause expressions etc.  Maybe show an example).  This minimal set of assumptions also dictate the system decisions we make in terms of looking for structural changes, and how we model interactions and interface components.}

%\ts{Perhaps talk about the fact that we care about inputs, not outputs.}




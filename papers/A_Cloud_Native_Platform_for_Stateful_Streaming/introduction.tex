\section{Introduction}

Stream processing enables fast analysis of a high volume of newly arriving data.
While industry and academia have produced many stream processing systems in 
the past two decades~\cite{stream-2003, borealis-2005, spade-2008,
                           millwheel-2013, naiad-2013, storm-2014,
                           heron-2015, flink-2015, dataflow-2015, 
                           flink-2017},
they all share three defining characteristics:

\begin{enumerate}
    \item A programming model that naturally exposes data, task and pipeline
    parallelism. Multiple levels of parallelism allow streaming applications to
    scale with the number of data sources and available hardware.

    \item Interesting streaming applications tend to be stateful. General 
    purpose stream processing can perform non-trivial computations, directly 
    providing answers to users. Such computations typically require
    maintaining state.

    \item A platform and runtime system capable of exploiting the available 
    parallelism while preserving application state.
\end{enumerate}

The kind of platform streaming systems require approaches general purpose
cluster management. Such a platform is responsible for distributing generic user
code across a cluster of compute nodes, arbitrating connections between parts of
the applications on different nodes and managing the life cycle of the
application as well as all component pieces. In the service of managing the
applications on the cluster, streaming platforms must also manage the cluster
itself: track nodes leaving and entering, allocate resources and schedule
applications.

Recently a new kind of technology has emerged for generic cluster management:
cloud platforms built on containers. They are a sweet-spot between clouds that
expose virtual machines and fully hosted single services. Container based cloud
environments are fully generic, but still remove the need for users to manage
an underlying system. Users build container images with programs, libraries and
files in the exact configuration they need.  Users specify how to deploy and
manage the containers that comprise their application through configuration
files understood by the cloud platform.

Because the user is not responsible for managing the cluster of systems in a
container based cloud platform, the cloud platform is. Unlike platforms
for streaming systems, cloud platforms do not \emph{approach} general purpose
cluster management, but \emph{are} general purpose cluster management. One of
the most popular such cloud platforms is Kubernetes~\cite{kube}, which grew out
of Google's experience managing containers for their infrastructure and
applications~\cite{borg-omega-kube-2016}.

Because general purpose cluster management is so valuable, Kubernetes has been
widely adopted by industry to manage their own internal workloads. The
convergence of public cloud platforms with on-premise cluster management is
called \emph{hybrid cloud}. Due to the shared underlying cloud platform,
workloads can migrate between public and private settings.

The ubiquity of cloud platforms like Kubernetes also means there is no escaping
them: they will be used to manage all kinds of software in all settings. For
simple workloads, migrating to cloud platforms simply requires building the
existing software into containers and deploying as needed. Scaling and fault
tolerance are also trivial for simple workloads: just start more containers. But
this approach is not appropriate for workloads such as stream processing that
already have their own management platform and stateful applications. Taking the
simple approach will create a platform-within-a-platform which is difficult to
manage, understand and maintain.

Instead, systems such as streaming platforms need to be rearchitected for cloud 
platforms such as Kubernetes. The new architectures need to be designed around 
the fact that cloud platforms already provide the basics of cluster management.

This paper presents the design of a cloud native version of IBM Streams,
targeting Kubernetes as the cloud platform. Cloud native Streams relies on
Kubernetes for job management, life cycle tracking, scheduling, address
translation and fault tolerance.  The resulting implementation reduces the
platform code base by 75\%. We achieved this reduction in code size by
starting from the question of what existing Streams applications need to
execute, rather than trying to reimplement the existing Streams platform in
Kubernetes. We believe our experience with this rearchitecture will apply to any
system which also required its own management platform. This paper makes the
follow contributions:

\begin{enumerate}
    \item The cloud native patterns used to build cloud native Streams
	(\S~\ref{sec:patterns}). Composing these patterns---controllers,
	conductors, coordinators and causal chains---enable us to construct a
	deterministic platform out of an asynchronous distributed
	system. These patterns are available as an open source library at 
    \url{http://www.github.com/ibm/cloud-native-patterns}.

    \item The architecture of cloud native Streams (\S~\ref{sec:arch}),
    deep-dives on specific features (\S~\ref{sec:features}), and lessons 
    learned (\S~\ref{sec:lessons}).

    \item Experimental results comparing the performance of cloud native
    Streams to a legacy version of Streams (\S~\ref{sec:results}). Network 
    latency, tolerance to oversubscription, garbage collection and pod recovery 
    are worse in the cloud native version. We present these results to help 
    improve Kubernetes.
\end{enumerate}

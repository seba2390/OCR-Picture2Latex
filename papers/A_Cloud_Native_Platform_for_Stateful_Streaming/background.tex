\section{Background and Motivation}

\subsection{IBM Streams}

IBM Streams is a general-purpose, distributed stream processing system. It
allows users to develop, deploy and manage long-running streaming applications
which require high-throughput and low-latency online processing.

The IBM Streams platform grew out of the research work on the Stream Processing
Core~\cite{spc-2006}.  While the platform has changed significantly since then,
that work established the general architecture that Streams still follows today:
job, resource and graph topology management in centralized services; processing
elements (PEs) which contain user code, distributed across all hosts,
communicating over typed input and output ports; brokers publish-subscribe
communication between jobs; and host controllers on each host which
launch PEs on behalf of the platform.

The modern Streams platform approaches general-purpose cluster management, as
shown in Figure~\ref{fig:streams_v4_v6}. The responsibilities of the platform
services include all job and PE life cycle management; domain name resolution
between the PEs; all metrics collection and reporting; host and resource
management; authentication and authorization; and all log collection. The
platform relies on ZooKeeper~\cite{zookeeper} for consistent, durable metadata
storage which it uses for fault tolerance.

Developers write Streams applications in SPL~\cite{spl-2017} which is a
programming language that presents streams, operators and tuples as
abstractions. Operators continuously consume and produce tuples over streams.
SPL allows programmers to write custom logic in their operators, and to invoke
operators from existing toolkits. Compiled SPL applications become archives that
contain: shared libraries for the operators; graph topology metadata which tells
both the platform and the SPL runtime how to connect those operators; and
external dependencies. At runtime, PEs contain one or more operators. Operators
inside of the same PE communicate through function calls or queues. Operators
that run in different PEs communicate over TCP connections that the PEs
establish at startup. PEs learn what operators they contain, and how to connect
to operators in other PEs, at startup from the graph topology metadata provided
by the platform.

We use ``legacy Streams'' to refer to the IBM Streams version 4 family. The
version 5 family is for Kubernetes, but is not cloud native. It uses the
lift-and-shift approach and creates a platform-within-a-platform: it deploys a
containerized version of the legacy Streams platform within Kubernetes.

\subsection{Kubernetes}

Borg~\cite{borg-2015} is a cluster management platform used internally at Google
to schedule, maintain and monitor the applications their internal infrastructure
and external applications depend on. Kubernetes~\cite{kube} is the open-source
successor to Borg that is an industry standard cloud orchestration platform.

From a user's perspective, Kubernetes abstracts running a distributed
application on a cluster of machines. Users package their applications into
containers and deploy those containers to Kubernetes, which runs those
containers in \emph{pods}. Kubernetes handles all life cycle management of pods,
including scheduling, restarting and migration in case of failures.

Internally, Kubernetes tracks all entities as \emph{objects}~\cite{kubeobjects}.
All objects have a name and a specification that describes its desired state.
Kubernetes stores objects in etcd~\cite{etcd}, making them persistent,
highly-available and reliably accessible across the cluster. Objects are exposed
to users through \emph{resources}. All resources can have
\emph{controllers}~\cite{kubecontrollers}, which react to changes in resources.
For example, when a user changes the number of replicas in a
\code{ReplicaSet}, it is the \code{ReplicaSet} controller which makes sure the
desired number of pods are running. Users can extend Kubernetes through
\emph{custom resource definitions} (CRDs)~\cite{kubecrd}. CRDs can contain
arbitrary content, and controllers for a CRD can take any kind of action.

Architecturally, a Kubernetes cluster consists of nodes. Each node runs a
\emph{kubelet} which receives pod creation requests and makes sure that the
requisite containers are running on that node. Nodes also run a
\emph{kube-proxy} which maintains the network rules for that node on behalf of
the pods. The \emph{kube-api-server} is the central point of contact: it
receives API requests, stores objects in etcd, asks the scheduler to schedule
pods, and talks to the kubelets and kube-proxies on each node. Finally,
\emph{namespaces} logically partition the cluster. Objects which should not know
about each other live in separate namespaces, which allows them to share the
same physical infrastructure without interference.

\subsection{Motivation}
\label{sec:motivation}

Systems like Kubernetes are commonly called ``container orchestration''
platforms. We find that characterization reductive to the point of being
misleading; no one would describe operating systems as ``binary executable
orchestration.'' We adopt the idea from Verma et al.~\cite{borg-2015} that
systems like Kubernetes are ``the kernel of a distributed system.'' Through CRDs
and their controllers, Kubernetes provides state-as-a-service in a distributed
system. Architectures like the one we propose are the result of taking that view 
seriously.

The Streams legacy platform has obvious parallels to the Kubernetes
architecture, and that is not a coincidence: they solve similar problems.
Both are designed to abstract running arbitrary user-code across a distributed
system.  We suspect that Streams is not unique, and that there are many
non-trivial platforms which have to provide similar levels of cluster
management.  The benefits to being cloud native and offloading the platform
to an existing cloud management system are: 
\begin{itemize}
    \item Significantly less platform code.
    \item Better scheduling and resource management, as all services on the cluster are 
        scheduled by one platform.
    \item Easier service integration.
    \item Standardized management, logging and metrics.
\end{itemize}
The rest of this paper presents the design of replacing the legacy Streams 
platform with Kubernetes itself.


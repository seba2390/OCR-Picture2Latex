\section{Prediction Results}\label{result}

\begin{figure}[htbp]
	\centering
		\vspace{-.2in}
	\includegraphics[width=0.48\textwidth]{Andy_Loss2}
		\vspace{-.4in}
	\caption{Behavior of train loss and test loss for predicting pulse rate.}
	\label{fig:HR_loss}
		\vspace{-.2in}
\end{figure}

\begin{figure}[htbp]
	\centering
		\vspace{-.2in}
	\includegraphics[ width=.45\textwidth]{HR_scatter.eps}
		\vspace{-.3in}
	\caption{Scatter plot of the predicted PR value vs. the ground truth PR value. The straight line is function \(y=x\). The closeness of the points to the line indicates the model accuracy. }
	\label{fig:scatter}
	\vspace{-.2in}
\end{figure}




%

The values of PR predicted by our model were compared with the true values calculated from the readings of a contact device and the errors were calculated accordingly. The mean absolute percentage errors were calculated using leave-one-out cross-validation. To be more specific, since we had 20 subjects in total, we chose nineteen out of the twenty subjects and picked out all observations from those nineteen subjects to make up our entire training set. All observations for the subject that was left out from the training set were considered as the test set. We iterated this procedure for each subject to make sure that we test our model on each individual. Since the data from the test set is completely new compared to the training set, this tells us how our model predicts subjects it has never seen before, regardless of skin tone, race, and facial features.


We then calculated the mean absolute percentage error (MAPE) and Root Mean Squared Error (RMSE) for our predictions. The mean of errors on all 20 subjects was found to be 4.6\%. Similarly, the RMSE value for our test set is found out to be 4.39.  The authors of \cite{osman2015supervised} reported an RMSE of 9.52 on the test set in predicting PR meaning that our model outperforms theirs and shows a reduction in RMSE by 53\% for predicting PR.
%







Figure \ref{fig:HR_loss} shows how the test and train loss varies with the number of iterations run by our network. For our computation, we used mean squared error as the loss function. The number of iterations was chosen based on the behavior of test and train loss. If the number of iterations was too low, it leads to under-fitting wherein both train and test errors were high and if the number of iterations was too many, it leads to over-fitting. To avoid these scenarios, we ran our model at 170 iterations. 
 

 
 
 %

Figure \ref{fig:scatter} shows a scatter plot between predicted and actual values of pulse rate. The straight line shown is a 45-degree line (\(y=x\)), and the closeness of the scatter points to the straight line indicates the high accuracy of our model.   

%









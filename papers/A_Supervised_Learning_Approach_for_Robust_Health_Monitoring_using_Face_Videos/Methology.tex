\section{Proposed Approach}\label{sec:method}
The methodology adopted for the estimation of health parameters is two-fold.
The videos of subjects captured under different conditions were processed to extract the face features as the first step. The next step involves training the deep learning model using the face features as predictors and actual values of PR as the response variables. The detailed steps are explained below.
\subsection{ Video Processing}
The video was recorded for 50 seconds for each subject under different activities. The entire video was broken into frames where each frame was composed of red, green, and blue color bands. We utilized the DeepFace \cite{taigman2014deepface} algorithm for the purpose of face recognition. DeepFace algorithm was developed by the researchers at Facebook and had an accuracy of 97.35 \% on the \textit{Labeled Faces in the Wild} (LFW) \textit{dataset}, which reduced the error of the current state of the art \cite{huang2012learning,sun2013deep,cao2013practical,chen2013blessing} by more than 27\%. DeepFace utilized a nine-layer deep neural network and was trained on a large facial dataset of four million facial images belonging to more than 4,000 identities.

The first step in video processing involved the detection of human faces in each frame of the video. The detected human face was then aligned automatically by DeepFace using the 3D alignment method \cite{taigman2014deepface}. The aligned face was cropped from the image using the landmark points on the face shown in Figure \ref{fig:process}. The image was cropped  to only facial features and removing extra pixel values from the images. We were careful in retaining the forehead since it contained the maximum information about blood perfusion inside the arteries \cite{kumar2015distanceppg}. %
  The cropped images were used for training the deep learning model. The stages of video processing are shown in Figure \ref{fig:process}.   
  %
  
  The extraction of ''right'' features is important as it plays a significant role in training a neural network.  Choosing the subset of features from the available data reduces redundancy in the input to the neural networks and subsequently improving the performance. Therefore, we down-sample each cropped image to 20x20 image and extract 400 pixels intensity values from each frame as shown in Figure \ref{fig:process} (d). 

 \subsection{Model Training}
 %
%

%
We trained a deep learning model using TensorFlow to estimate health metrics. The model was trained through a multi-layered neural network.   We used a fully connected neural network with three hidden layers. The detailed architecture of the network used in shown in Figure \ref{fig:arch} (in Appendix). The network consisted of rectified linear units (ReLU) and the rectifier activation was given  as $f(x)=max(0,x)$, where $x$ was the input to the neuron. The choice of network architecture and activation function was dependent on the minimum value of the loss function. The network was trained using a backpropagation algorithm with the mean squared error as the loss function.  Batch normalization was used in each hidden layer \cite{DBLP:journals/corr/IoffeS15}. The use of drop-out was one of the simplest ways to avoid over-fitting of the neural network \cite{srivastava2014dropout}. The drop-out rate was set to 30\% to avoid over-fitting in all the three hidden layers. This will help in better generalizing the network for unseen data. The green color band was shown to be the best source for extracting information about the health parameters \cite{verkruysse2008remote}. Hence, we utilized all the pixel values corresponding to the green channel of each frame to train our machine learning model. The image from each frame was downsampled to a 20x20 image. Hence, we used 400 features from each frame to train the model. The features were normalized to bring them in a range of [0,1] so that it was easier for the neural network to learn from the data. The downsampling was also done to reduce the computational expense of our model. The actual response value, i.e., PR was extracted from the PPG signal recorded during our experiment. In order to extract actual PR from PPG, we computed power spectral density (PSD) of the PPG signal using a fast fourier transform (FFT) algorithm. The PR was then estimated as the frequency corresponding to the maximum power in the PSD (PR= 60. $\mathit{f}$ bpm), where $\mathit{f}$ is the required frequency.



 %


%




%
%
%
    
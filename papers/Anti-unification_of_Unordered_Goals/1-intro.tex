\section{Motivation and Objectives}
%Anti-unification is an important topic in Logic Programming. It refers to the process of computing some expression $G$, called a generalization, that captures common structure amongst a set of syntactic expressions $E$. In this work, we study the anti-unification of logical \textit{goals}, a goal being a set of atomic structures. To simplify our approach the set $E$ will be composed \textit{two goals}, but our results can easily be extended to the more general case where any number of goals need to be generalized. 

Anti-unification refers to the process of generalizing two (or more) program objects $S$ into a single, more general, program object that captures some of the structure that is common to all the objects in $S$. In a classical logic programming context, the atom $p(X,Y)$ can thus be seen as a generalization of both the atoms $p(f(A), U)$ and $p(f(g(B)),h(C))$, thanks to the variables $X$ and $Y$. 

Anti-unification constitutes a useful tool in various contexts ranging from program analysis techniques (including partial evaluation, refactoring, automatic theorem proving, program transformation, formal verification and test-case generation~\cite{au-applications,calculus-constr,DESCHREYE1999231,lg-gs,under-implication}) to automated reasoning \cite{ilp-theory-and-methods,Muggleton90efficientinduction} or analogy making~\cite{analogy-making}, supercompilation~\cite{Sorensen95analgorithm} and even plagiarism detection~\cite{clones}. Many of these static techniques are executed on programs written in the form of (constraint) Horn clauses, a formalism that has been praised for its ability to capture a program's essence in a quite universal and straightforward manner~\cite{horn-clauses-intermediate-representation}. 

In the introductive example above, the presence of variables $X$ and $Y$ conceptually allows concrete instances (i.e. less general objects) to harbor any value at the positions corresponding to the variable positions. The generalization process is indeed usually achieved by ``forgetting'' parts of the objects to generalize (either by replacing sub-objects with variables or by dropping them altogether): the less syntactic information in an object, the more general it is. Most anti-unification methods are thus steered by a \textit{variabilization} algorithm determining how to ``forget'' object parts when necessary while keeping (common) parts in the generalization. Therefore, in general one is typically interested in computing what is often called a most specific generalization (or synonymously least general generalization), that is a generalization that captures a maximal amount of shared structure. With the atoms of the example above, the common generalization $p(f(X), Y)$ is in that regard a \textit{better} anti-unification result than $p(X,Y)$, as it exhibits more common structure (namely the use of functor $f$). As this example hints, ``better'' results are often obtained at the cost of more complex anti-unification algorithms. In that regard, computing more specific generalizations often boils down to performing some kind of optimization in the variabilization process. 

In a classical approach where goals are \textit{ordered} sequences of atoms, a goal $G$ is more general than some other goal $G'$ if $G'$ can be obtained by applying on $G$ some substitution $\theta$, being a mapping from variables to values. $G$ then typically harbors more variables than $G'$, making it a less instantiated, thus more general, version of $G'$. In that case, $G$ and $G'$ are related by the $\theta$-subsumption relation from~\cite{plotkin}, often considered to be a foundation of Inductive Logic Programming where anti-unification is used as a way to learn a general hypothesis from specific examples~\cite{ilp-theory-and-methods}. As the name may suggest, looking for a generalization that is common to a group of program artefacts (be it terms, atoms, goals or even predicates as a whole) is referred to as anti-unification due to it being the dual operation of unification. Both can, in fact, be applied in similar contexts. Such applications of (anti-)unification include program transformation techniques for partial deduction \cite{Gallagher:1993:TSL:154630.154640,DESCHREYE1999231}, fold/unfold routines \cite{DBLP:journals/csur/PettorossiP98}, invariant generation~\cite{DBLP:conf/synasc/KovacsJ05} and reuse of proofs~\cite{unranked-2-order-au,calculus-constr}. 

The study of anti-unification so far has mainly been focused on such ordered goals. However, many applications require goals to be defined as (\textit{unordered}) sets of atoms. It is the case, for instance, when considering the most declarative semantics of logic programs~\cite{lp-semantics,clp-semantics,horn-clauses-intermediate-representation}. Having a clear overview of anti-unification operators computing most specific generalizations for unordered goals (sometimes called \textit{linear} generalizations) in logic programs is necessary for generalization-driven semantic
% todo our own
clone detection with programs composed of constraint Horn clauses~\cite{clones,DBLP:conf/ppdp/MesnardPV16}. Indeed, generalization operators allow to quantify a certain amount of structural similarity between different predicate definitions by highlighting what parts these have in common. In~\cite{clones}, this quantitative similarity measurement is used as an indication of which semantic-preserving program transformation should be applied next in order to ultimately assess whether two programs (or predicates) are semantic clones. A quite similar approach has already been taken in the case of ordered goals in~\cite{au-applications}, an obvious application of this being plagiarism detection. 

Directing our interest towards unordered goals also has the advantage of broadening the traditional anti-unification theories usually rooted in a setting where logic programming is based on operational semantics, by extending the theories to the more general area of Constraint Logic Programming (CLP), unordered goals being a crucial ingredient of the CLP(X) framework. The fixpoint semantics of CLP programs are indeed typically defined with no regard to the order of appearance of the atoms in a clause's body~\cite{clp-semantics}. While CLP is interesting in its own right, it is also considered a serious candidate for representing abstract \textit{algorithmic knowledge}, rather than mere computations, in a quite universal manner~\cite{horn-clauses-intermediate-representation}. In that regard, focusing on unordered goals could pave the way for performing anti-unification at the algorithmic level rather than at the level of language-specific operations. 

The topic of anti-unification in the case of unordered goals has ocasionally come up in studies focussed on related fields such as \textit{equational} anti-unification, encompassing theories specified by commutativity or associative-commutativity axioms. The topic has been treated for first-order theories~\cite{order-sorted} as well as higher-order variants~\cite{kutsia_2020}. The latter work applies to the first-order case as well and provides polynomial algorithms for variants of anti-unification for unordered input. A grammar-based approach to equational anti-unification including commutative theories, called E-generalization, was introduced in~\cite{e-generalization} and refined with a working implementation in~\cite{e-generalization-improved}. The authors of~\cite{unranked-2-order-au} elaborate a \textit{rigid anti-unification} algorithm that can apply to unordered (and so-called \textit{unranked}) theories by instantiating a parameter called rigidity function, a direct application of which being the computation of longest common substrings. The algorithms described in all of these works can be used to compute what we will call $\sqsubseteq$-common generalizations below in the present paper. Although none of these works develop a general (non-equational) taxonomy allowing to extend the results beyond that simple setting, nor discusses variable- or injectivity-based variants of anti-unification operators, %-- both being concepts that will show central in the present paper -- 
their usages do point out other interesting (and recent) applications of anti-unification when focused on unordered goals, namely detection of recursion schemes in functional programs (as explained in~\cite{BARWELL2018669}) and techniques for learning bugfixes from software code repositories (an example being~\cite{rolim2018learning}). 

Anti-unification techniques that are adapted for CLP(X) have been defined in~\cite{gen}, but its focus is set on a polynomial abstraction procedure for a specific case where terms cannot be generalized (only variables can) and where generalization has to be carried out through injective substitutions. 
%
While~\cite{gen} provides useful insights and results, it lacks a more general and in-depth study of the used generalization operator. In this work we broaden, generalize and complete the latter work by providing a detailed and systematic study of generalization operators and their characteristics in the context of CLP. 
%

The main contributions of the present work are the following. In Section~\ref{section-preliminaries} we define relations close to the well-known $\theta$-subsumption in an effort of adapting this notion to the case of unordered goals. As will be illustrated throughout the paper, our adaption of anti-unification to unordered goals makes the usual subsumption techniques unusable. In Section~\ref{section-relation-1} we reframe the problem of looking for a most general/largest generalization as an optimization problem, parametrized by the \textit{generalization operator} (or anti-unification strategy) and \textit{variabilization function} (responsible for introducing variables in the resulting generalization) at hand.  We will see that given two unordered goals as input, searching for such generalizations can be done in polynomial time. The algorithms, as well as their worst-case time complexities, are detailed throughout the development of our anti-unification framework. 
%We study and characterize problem statements 
%and related algorithms, as well as their computability, 
%for several incarnations of the anti-unification problem in this setting. Indeed, 
%This new approach constitutes an in-depth study of anti-unification in the presence of unordered goals. 
%Its novelty comes from two main aspects. First, the definition of a general framework in which 
 In Section~\ref{section-relation-2} we provide an in-depth examination of several key variations of the anti-unification problem, namely variable generalization (where no terms are allowed to be generalized), injective generalization (where the generalizing substitutions need to be injective) and dataflow optimization (where the number of generalizing variables needs to be minimized) -- the latter of which is proved to make the anti-unification statement NP-hard. Finally, addressing this last problem more in depth in Section~\ref{section-relation-3} we revisit a tractable abstraction that was introduced in~\cite{gen} but we provide for the first time a formal proof of its worst-case complexity, showing that the approximation can effectively be computed in polynomially bounded time. With the exception of this last result, the proofs of propositions, lemmas and theorems are provided in the Appendices.


%In this work, we complete the work of~\cite{gen} by providing 
% -- a setting which corresponds to one of the few generalization contexts that we aim to further develop hereunder. The present work can, as such, be seen as a continuation of~\cite{gen}. To complete the claims of that related work we will also prove one of its results which, to our knowledge, has remained a conjecture so fa@r.



%The remainder of the paper is organized as follows. Some of the main concepts are formally introduced in Section~\ref{section-preliminaries}, where we provide a definition for most specific generalization and largest common generalization in our context. We then see in Section~\ref{section-relation-1} that given two unordered goals as input, searching for such generalizations can be done in polynomial time. The algorithms, as well as their worst-case time complexities, are detailed throughout the development of our anti-unification framework.
%Then, in Section~\ref{section-relation-2}, we will address \textit{dataflow optimization}, the process of minimizing the number of variables introduced in the anti-unification operation. We show this problem to be NP-hard, even when the generalization relation at hand is built upon injective substitutions rather than ordinary substitutions. 
%%
%In Section~\ref{section-relation-3} we  
%further study the injectivity-based anti-unification of unordered goals. 
% based on results that have been exposed in related work in that specific context~\cite{gen}. 
% as a continuation of related work 
%We revisit a tractable abstraction that was introduced  in~\cite{gen} but we provide for the first time a formal proof of its worst-case complexity, showing that the abstraction can effectively be computed in polynomially bounded time. We conclude in Section~\ref{section-conclusion}.
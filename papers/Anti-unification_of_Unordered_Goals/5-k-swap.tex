\section{The $k$-swap Stability Abstraction}\label{section-relation-3}
In what follows, we introduce an abstraction for the largest common generalization with respect to $\preceq^\iota$ that can be computed in polynomial time. The abstraction was already introduced in~\cite{gen} but no formal proof of its complexity was given. The abstraction is based on the \textit{$k$-swap stability} property, which is in turn defined in terms of \textit{pairing generalizations}. 

\begin{definition}
	Let $G_1$ and $G_2$ be two renamed apart goals and $G$ be a $\preceq^\iota$-common generalization of $G_1$ and $G_2$ such that $G\subseteq G_1$. Let $\rho$ be any renaming such that $G\rho\subseteq G_2$. The \emph{pairing generalization} of $G$, denoted $\pi(G)$, is the set of pairs $(A_1, A_2) \in G_1\times G_2$ such that $\forall(A_1, A_2)\in\pi(G):A_1\rho = A_2$. 
\end{definition}

\begin{example}
	Considering the goals $G_1 = \{p(A), p(B), q(A)\}$ and $G_2 = \{p(X), q(Y)\}$, it is easy to see that $G = \{p(\Phi(B,X)), q(\Phi(A,Y))\}$ is a $\preceq^\iota$-common generalization of them. The corresponding pairing generalization is $\pi(G) = \{(p(B), p(X)), (q(A), q(Y))\}$.
\end{example} 

The notion of a pairing generalization renders thus explicit the corresponding atoms from the generalized goals that contribute to the generalization.
As a slight abuse of language, given a pairing generalization $\pi$ of some generalization $G$ for goals $G_1$ and $G_2$, we will simply say that $\pi$ is a \textit{pairing for $G_1$ and $G_2$}. 
Pairings can be used to express a notion of goal \textit{stability} in the following sense.

\begin{definition}\label{def-k-swap-stable}
	Let $G_1$ and $G_2$ be two renamed apart goals and $G$ be a $\preceq^\iota$-common generalization of $G_1$ and $G_2$ such that $G\subseteq G_1$. $G$ is \emph{k-swap stable} if and only if there does not exist some generalizations $\hat{G}$ and $G'$ of $G_1$ and $G_2$ such that $\hat{G}\supset G'$ and $|\pi(G)\cap\pi(G')|\ge |\pi(G)|-k$ for some $k\in\mathtt{N}$.
\end{definition}

Intuitively, a generalization $G$ is $k$-swap stable if it is impossible to transform $G$ into a larger generalization $\hat{G}$ in spite of ``swapping'' at most $k$ pairs in $\pi(G)$.
%Intuitively, a generalization $G$ is $k$-swap stable if ``swapping'' at most $k$ pairs in $\pi(G)$ -- i.e. removing pairs or replacing them with other pairs in $G_1\times G_2$ -- would not make $G$ easily extensible into some greater generalization $\hat{G}$. 
%Put differently, $G$ is \textit{not} $k$-swap stable if $k$ editions, or swaps, in $\pi(G)$ suffice to consequently extend $G$ into some other common generalization $\hat{G}$. 
This stability notion gives a characterization of the quality of a computed generalization. If a generalization is 0-swap stable (the weakest characterization), it cannot be extended by adding another atom but this guarantees in no way that a larger generalization could not be found. If a generalization $G$ is $k$-swap stable (for $k>0$), it means that even if we exchange up to $k$ pairs in $\pi(G)$ by others, the generalization cannot be extended into a larger one. Consequently, if a generalization is $k$-swap stable for $k$ the number of atoms in the smallest of the two goals (denoted by $\infty$-swap stable), it means that the computed generalization is a largest common generalization. 
%
Operationally, when naively searching for a lcg by backtracking, the fact that a computed generalization is $k$-swap stable means that one should backtrack by \textit{more} than $k$ choice points in order have a chance of finding a larger generalization. 

%Operationally, each swap can be seen as a possible backtracking in a naive algorithm trying to compute a $\preceq^\iota$-lcg. When computing a 0-swap stable generalization
%Indeed, when $k$ grows, the outputted generalization gets higher accuracy as it reconsiders more choices that were made during the construction of $G$. If $k = \infty$, building a generalization through $k$-swaps will perform an exhaustive search, as all choices that are made will be reconsidered. 

\begin{example}\label{ex:k-swap-stable}
   	Consider the goals $G_1 = \{add(X,Y,Z), even(X), odd(Z), p(Z)\}$ and $
G_2 = \{add(A,B,C), add(C,B,A), even(C), odd(A), p(C)\}$. 
   	 $\pi_1= \{(add(X,Y,Z), add(A,B,C))\}$ is not $0$-swap stable. Indeed, we can enlarge $\pi_1$ by adding $(p(Z),p(C))$, in order to obtain 
   	$\pi_2 = \{(add(X,Y,Z),add(A,B,C)), (p(Z),p(C))\}.$
   	Note that $\pi_2$ is $0$-swap stable, it is impossible to add another pair to $\pi_2$ and still obtain a common generalization. 
   	It is also $1$-swap stable, seeing that replacing (or removing) one of the pairs doesn't lead to a pairing readily extensible to a pairing of size strictly greater than~$2$. However, $\pi_2$ is not $2$-swap stable. Indeed, replacing the pair $(add(X,Y,Z),add(A,B,C))$ by the pair $(add(X,Y,Z), add(C,B,A))$ in $\pi_2$ and removing the now incompatible pair $(prime(Z),prime(C))$ (i.e. choosing the renaming $[X\mapsto C, Y\mapsto B, Z\mapsto A]$ instead of $[X\mapsto A, Y\mapsto B, Z\mapsto C]$) gives rise to $\pi_2' = \{(add(X,Y,Z),add(C,B,A))$, which can readily be extended into
   	   		$\pi_3 = \{(add(X,Y,Z),add(C,B,A)), (even(X),even(C)), (odd(Z),odd(A))\}$
   	which is a pairing of size 3. The latter being $\infty$-swap stable, it represents a $\preceq^\iota$-lcg, namely
   		$\hat{G} = \{add(\Phi(X,C), \Phi(Y,B), \Phi(Z,A)), even(\Phi(X,C)), odd(\Phi(Z,A))\}$
\end{example}
An algorithm has been introduced in~\cite{gen} that builds up a $k$-swap stable generalization using the process suggested in Example~\ref{ex:k-swap-stable}. Its practical performance has been assessed on different test cases. The tests indicate that the $k$-swap stability property represents a well-suited approximation of the concept of $\preceq^\iota$-lcg. Indeed, in all test cases the size of the $k$-swap stable generalization was at least $90\%$ of the size of an lcg for the same anti-unification problem, while the computational time was radically reduced -- especially as the size of the input goals grows\footnote{For example, with $k$ fixed to 4, anti-unifying goals harboring 15 to 22 atoms, each of arity between 1 and 3, comes on average down from more than 7 minutes (using bruteforce) to 272 milliseconds (using the algorithms presented in this section), while the size of the computed generalization is on average $95\%$ of the size of a lcg. More detailed test results are exposed in~\cite{gen}.}. However, in~\cite{gen} only pragmatical aspects have been explored; the theoretical foundations of the $k$-swap technique were not detailed, and  no actual time complexity upper bound has been demonstrated. We fill this gap in the remainder of this section. First, we introduce the algorithm, then we formally prove that its time complexity is polynomially bounded. Before introducing the algorithm, which is essentially composed of two sub-algorithms, we give some notations that will facilitate their formulation. First, we define an operator that allows to combine two pairings into a single pairing.
	
\begin{definition}
	Let $G_1$ and $G_2$ be two renamed apart goals. The \emph{enforcement operator} is defined as the function $\enforce: (G_1\times G_2)^2 \mapsto (G_1\times G_2)$ such that for two pairing generalizations $\pi$ and $\pi'$ for $G_1$ and $G_2$, $\pi \enforce \pi' = \pi' \cup M$ where $M$ is the largest subset of $\pi$ such that $\pi'\cup M$ represents a $\preceq^\iota$-common generalization of $G_1$ and $G_2$. 
\end{definition}
	
In other words, $\pi\enforce\pi'$ is the mapping obtained from $\pi\cup\pi'$ by eliminating those pairs of atoms $(A,A')$ from $\pi$ that are \textit{incompatible} with some $(B,B')\in\pi'$ either because they concern the same atom(s) or because the involved renamings cannot be combined into a single injective renaming. 
	
\begin{example}
	Consider 
	$\pi = \{(p(X, Y), p(A, B)), (q(X), q(A))\}$ as a pairing for two goals $G_1$ and $G_2$. Suppose $\pi' = \{(r(Y), r(C))\}$ is also a pairing for $G_1$ and $G_2$. Enforcing $\pi'$ into $\pi$ gives $\pi\enforce\pi' = \{(q(X), q(A)), (r(Y), r(C))\}$. Indeed, this can be seen as forcing $Y$ to be mapped on $C$; therefore the resulting pairing generalization can no longer contain $(p(X, Y), p(A, B))$ as the latter maps $Y$ on $B$. 
\end{example}

For $\pi_1$ and $\pi_2$ pairings we will also denote by $\compatible_{\pi_1}(\pi_2)$ the subset of $\pi_2$ of which each element can be added to $\pi_1$ such that the result is a pairing (i.e. there is no injectivity conflict in the associated renaming). Finally, we use $\gen(G_1, G_2)$ to represent those atoms from $G_1$ and $G_2$ that are variants of each other, formally $\gen(G_1,G_2)=\{(A,A')\:|\:A\in G_1, A'\in G_2\mbox{ and }A\rho=A'\mbox{ for some renaming }\rho\}$. 
%
The first algorithm is depicted in Algorithm~\ref{alg:kswap}. The algorithm represents the construction of a $k$-swap stable generalization of goals $G_1$ and $G_2$. At each round, the process tries to transform the current generalization $\pi$ (which initially is empty) into a larger generalization by forcing a new pair of atoms $(A,A')$ from $\gen(G_1,G_2)$ in $\pi$, which is only accepted if doing so requires to swap no more than $k$ elements in $\pi$. More precisely, the algorithm selects a subset of $\pi$ (namely $\pi_s$) that can be swapped with a subset $\pi_c$ of the remaining mappings from $\gen(G_1,G_2)\setminus\pi$ such that the result of replacing $\pi_s$ by $\pi_c$ in $\pi$ and adding $(A,A')$ constitutes a pairing. Note how condition 1 in the algorithm expresses that $\pi_s$ must include at least those elements from $\pi$ that are not compatible with $(A,A')$.
The search continues until no such $(A,A')$ can be added.

\begin{algorithm}[hbtp]
	\caption{Computing a $k$-swap stable generalization $G$ for goals $G_1$ and $G_2$}
	\label{alg:kswap}
	\begin{algorithmic}
		\State $\pi\gets\emptyset$
		\Repeat
			\State $found\gets false$
			\ForAll{$(A,A')$ in $\gen(G_1, G_2)\setminus \pi$}
				\State select $\pi_s \subseteq \pi$ and $\pi_c\subseteq \gen(G_1, G_2)\setminus(\pi \cup\{(A,A')\})$ such that:
				\State \hspace*{3ex}(1) $\pi_s\supseteq \pi\setminus \pi\enforce\{(A,A')\}$
				\State \hspace*{3ex}(2) $|\pi_s| \le k$
				\State \hspace*{3ex}(3) $|\pi_c| = |\pi_s|$
				\State \hspace*{3ex}(4) $\pi\setminus \pi_s\cup \pi_c\cup\{A,A'\}$ is a pairing generalization of $G_1$ and $G_2$
				
				\If{such $\pi_c$ and $\pi_s$ are found}
					\State $\pi\gets \pi\setminus \pi_s\cup \pi_c \cup \{(A,A')\}$
					\State $found\gets true$
					\State \textbf{break} out of the \textbf{for} loop
				\EndIf
			\EndFor
		\Until $\neg found$
		\State $G \gets \dom(\pi)$
	\end{algorithmic}
\end{algorithm}	

The main operation of Algorithm~\ref{alg:kswap}, namely the selection of $\pi_s$ and $\pi_c$, is detailed in Algorithm~\ref{alg:selection} which aims to select the parts of the pairings to be swapped in order to enlarge the resulting pairing under construction ($\pi$) by the couple $(A,A')$.
To that purpose $\pi_s$ is initialized with the part of $\pi$ that is incompatible with the pair of atoms $(A,A')$ that we wish to enforce into the generalization. Its replacement mapping $\pi_c$ is initially empty and the algorithm subsequently searches to construct a sufficiently large $\pi_c$ (the inner while loop). During this search, $S$ represents the set of candidates, i.e. couples from $\gen(G_1,G_2)$ that are not (yet) associated to the generalization. In order to explore different possibilities with backtracking, the while loop manipulates a stack $GS$ that records alternatives for $\pi_c$ with the corresponding set $S$ for further exploration. 
\begin{algorithm}[hbtp]
\caption{Selecting $\pi_s$ and $\pi_c$ for a given $(A,A')$}
\label{alg:selection}
	\begin{algorithmic}
		\State $GS \gets \{\}$,  $BS \gets \{\}, \pi_c \gets\{\}$
		\State $\pi_s \gets \pi\setminus\pi\enforce\{(A,A')\}$
		\State $S \gets \gen(G_1, G_2) \setminus\pi\enforce\{(A,A')\}$
		\While{$|\pi_c| < |\pi_s| \mbox{ and } |\pi_s|\le k$}
			\While{$|\pi_c| < |\pi_s| \mbox{ and } \neg (\compatible_{\pi\setminus\pi_s\cup\pi_c}(S) = \{\} \mbox{ and } GS = \{\})$}
				\ForAll{$p$ in $\compatible_{\pi\setminus\pi_s\cup\pi_c}(S)$}	
					\State $push(GS, (\pi_c\cup p, S\setminus\{p\}))$
				\EndFor
				\State $(\pi_c, S)\gets pop(GS)$
			\EndWhile
			\If{$|\pi_c|<|\pi_s|$}
				\ForAll{$p$ in $\pi\setminus\pi_s$}
					\State $enter(BS, \pi_s\cup\{p\})$
				\EndFor
				\If{$BS\neq\{\}$}
					\State $\pi_s\gets exit(BS)$
					\State $\pi_c\gets\{\}$
					\State $S\gets \gen(G_1, G_2)\setminus(\pi\cup \{(A,A')\})$
				\Else
					\State \textbf{return} $\bot$
				\EndIf
			\EndIf
		\EndWhile
		\If{$|\pi_c|=|\pi_s|$}
			\State \textbf{return} $\pi_s, \pi_c$
		\EndIf
			\State r\textbf{return} $\bot$
	\end{algorithmic}
\end{algorithm}

If the search for $\pi_c$ was without a satisfying result (i.e. no $\pi_c$ is found equal in size to $\pi_s$), the algorithm continues by removing another couple from $\pi$ (thereby effectively enlarging $\pi_s$). The rationale behind this action is that there might be a couple in $\pi$ that is ``blocking'' the couples in $S$ from addition to $\pi$. In order to achieve the removal of such potentially blocking couples, an arbitrary couple from $\pi\setminus\pi_s$ is selected, and alternatives are recorded in a queue ($BS$). Note the use of a queue (and its associated operations \textit{enter} and \textit{exit}) as opposed to the stack $GS$.
%
The process is repeated until either $|\pi_c|=|\pi_s|$ in what case we have found a suitable $k$-swap, or until $|\pi_s|>k$ in what case we have not, and the algorithm returns $\bot$. %Note how Algorithm~\ref{alg:selection} behaves analogously to an $A*$ search.

While the algorithms have been proven to correctly compute a $k$-swap stable generalization~\cite{gen}, no result on their complexity has yet been formally established. 

\begin{theorem}\label{thm-k-swap-stable}
	For a given and constant value of $k$, the combination of Algorithms~\ref{alg:kswap} and~\ref{alg:selection} computes a $k$-swap stable common generalization of input goals $G_1$ and $G_2$ in polynomial time $\mathcal{O}((\alpha M)^{k+1})$, with $0 \le M \le |gen(G_1, G_2)|$ and $0 \le \alpha \le \textit{min}(|G_1|,|G_2|)$.
\end{theorem}
\begin{proof}
	In order to search for a suited $\pi_c$ to be swapped with a certain $\pi_s$, Algorithm~\ref{alg:selection} must try to add $|\pi_s|$ couples to $\pi\setminus\pi_s$ among the couples in $S$ that are compatible with it. To simplify notation, let $i = |\pi_s|$ and $n = |\compatible_{\pi\setminus\pi_s\cup\pi_c}(S)|$. Note that at any moment $i \le k$. The attempt of Algorithm~\ref{alg:selection} to find $\pi_c$ is essentially a search of a combination of $i$ couples among $n$; that is $\binom{n}{i}$ possibilities to explore. We have $\binom{n}{i} = \frac{n!}{i!(n-i)!}$ which reduces to a polynomial of degree $n^i$:
	\begin{gather*}
	\begin{array}{lll}
	\frac{n!}{i!(n-i)!} &=& \frac{n\cdot (n-1)\dots\cdot (n-(i+1) \cdot (n-i)\cdot (n-(i-1))\cdot\dots\cdot 1}{i!\cdot(n-i)\cdot (n-(i-1))\cdot\dots\cdot 1}
	= \frac{n\cdot (n-1)\dots\cdot (n-(i+1))}{i!}
	\approx \mathcal{O}(n^i)
	\end{array}
	\end{gather*}
	
	If no suiting $\pi_c$ is found during such a search, 
	%Algorithm~\ref{alg:selection} retries for all other potential $\pi_s$ pairings. If still no $\pi_c$ is found, 	
	then $\pi_s$ gets enlarged, having its size $m$ increased by (at least) one unit.
	%
	In the worst case, the size $i$ of $\pi_s$ is, at the start of Algorithm~\ref{alg:selection}, equal to $1$. It then gets incremented by one, until it reaches $k$ (each time more atoms from $\pi$ being considered to be part of $\pi_s$). 
	%
	Let $p$ denote the size of the pairing $\pi$ under construction, that is $p = |\pi|$. As $k$ is constant, if  backtracking is exhaustive there are $\sum\limits_{i=1}^{k} \binom{p}{i}$
%	\begin{gather*}
%	\begin{array}{lll}
%	\sum\limits_{i=1}^{k} \binom{p}{i} &=& \sum\limits_{i=1}^{k} \mathcal{O}(p^i) \\ &=& \mathcal{O}(p) + \mathcal{O}(p^2) + ... \mathcal{O}(p^k) \\
%	&=&  \mathcal{O}(p^k) 
%	\end{array}
%	\end{gather*}
	possibilities for $\pi_s$ pairings that are explored this way. Each of these $\pi_s$ pairings leads to the search for a corresponding $\pi_c$ pairing. As such, the overall search carried out by Algorithm~\ref{alg:selection} takes a number of iterations that is in the worst case represented by
	\[
	\begin{array}{lllll}
		\sum\limits_{i=1}^{k} \binom{p}{i}\cdot\binom{n}{i} & \approx & \sum\limits_{i=1}^{k} \mathcal{O}(p^i)\cdot\mathcal{O}(n^i) & \approx & \mathcal{O}((p\cdot n)^k)
	\end{array}
	\]
Given that $n$ is bound by the number of compatible couples of atoms from $G_1\times G_2$, we will denote the worst-case time complexity of Algorithm~\ref{alg:selection} by $\mathcal{O}((p\cdot M)^k)$ with $M \le |\gen(G_1,G_2)|$ and $p$ the length of the pairing under construction $\pi$.
		
%	\begin{gather*}
%	\begin{array}{lll}
%	\sum\limits_{i=1}^{k} p^i \cdot n^i&=&\sum\limits_{i=1}^{k} (p\cdot n)^i \\
%	&=& (p\cdot n) + (p\cdot n)^2 + (p\cdot n)^3 + \dots + (p\cdot n)^k  \\
%	&=& \mathcal{O}((p\cdot n)^k) \\
%	&=&  \mathcal{O}((p\cdot M)^{k}) \mbox{ with } M \le |\gen(G_1, G_2)|
%	\end{array}
%	\end{gather*}
%	\begin{gather*}
%	\begin{array}{lll}
%	\mathcal{O}(n^m) \cdot \mathcal{O}(p^k) &=& \mathcal{O}(M^{Mk}) \mbox{ with } M \le |\gen(G_1,G_2)|
%	\end{array}
%	\end{gather*}
	
	
	
	%The variable $n$ is majored by the total compatible couples $|\gen(G_1, G_2)|$, so that the overall search carried out by Algorithm~\ref{alg:selection} takes a number of iterations of amplitude
	% Note that $\pi$ being the pairing under construction, its size $p$ is majored by $\min(|G_1|,|G_2|)$. 
	
Turning our attention to Algorithm~\ref{alg:kswap} it is clear that the size of pairing $\pi$ is incremented by $1$ in each iteration of the \textit{repeat}-loop, since $found$ must be true for a new iteration to occur. As such, in the worst-case scenario there can be as many iterations as there are atoms in the smallest goal amongst $G_1$ and $G_2$, seeing that a generalization size cannot exceed that of the goals it generalizes. We will denote this number by $\alpha = \min(|G_1|, |G_2|)$.
%
As for the inner loop of Algorithm~\ref{alg:kswap}, it can browse through up to $|\gen(G_1, G_2)| - p$ candidates for choosing the couple $(A,A')$ that will be enforced in the pairing $\pi$. This gives us at most $
	%\begin{gather*}
	\begin{array}{lll}
	\sum\limits_{p=1}^{\alpha}(|\gen(G_1, G_2)| - p) &\approx &\sum\limits_{p=1}^{\alpha}\mathcal{O}(M - p)
	%\mathcal{O}(\min(|G_1|,|G_2|) \cdot |\gen(G_1,G_2)|) &=& \mathcal{O}(M^2) 	
	\end{array}
	$ %\end{gather*} 
	iterations of Algorithm~\ref{alg:kswap}.
%	Let us now focus on the search of the pairing $\pi_c$ to be swapped with $\pi_s$. At any moment there are as many potential couples to populate $\pi_c$ as there are pairs in the set $\compatible_{\pi\setminus\pi_s\cup\pi_c}(S)$. Let us denote by $l$ the maximal number of elements that this set beholds during the algorithm's execution, we have $l \le |\gen(G_1,G_2)|$. The search for a $\pi_c$ is then, similarly as for $\pi_s$ above, achieved in a time majored by $\binom{l}{k}$. For $\pi_c$ to suitably replace $\pi_s$ in $\pi$, there are indeed $k$ pairs to be chosen amongst all the potential compatible pairs in $S$ that are compatible with the version of $\pi$ under construction (namely $\pi\setminus\pi_s\cup\pi_c$). With a similar reasoning as above, this can be expressed as
%	\begin{gather*}
%	\sum\limits^{max}_{n=1}\binom{l}{k} = \sum\limits_{n=1}^{max}\mathcal{O}(l^k) = \mathcal{O}(l^{ck}) \mbox{ with } c \mbox{ a natural }
%	\end{gather*} 
	%$\mathcal{O}(M^{ck})$, where $c$ is a constant and $M$ is the maximal size of the set $\compatible_{\pi\setminus\pi_s\cup\pi_c}(S)$ during the algorithm's execution (this size being majored by $|gen(G_1,G_2)|$). 
	%The search of a $\pi_c$ being done for each considered $\pi_s$, the total complexity of Algorithm~\ref{alg:selection} can be expressed as the multiplication of both the complexities outlined above, i.e. $\mathcal{O}(max^{2k})\cdot \mathcal{O}(l^{ck})$. Because $l \le |\gen(G_1,G_2)|$ and $max\le max(|G_1|,|G_2|)$, both $l$ and $max$ are majored by $M = |G_1\times G_2|$, and the product can be written $\mathcal{O}(M^{(2+c)k}) = \mathcal{O}(M^{Ck})$ with $C$ a natural.
	%
	Algorithm~\ref{alg:selection} being called at each inner loop iteration of Algorithm~\ref{alg:kswap}, we can represent the time complexity of the combined algorithms by
	%\begin{gather*}
	%\begin{array}{lll}
	$\sum\limits_{p=1}^{\alpha}\mathcal{O}(M-p) \cdot \mathcal{O}((p\cdot M)^k) \approx \sum\limits_{p=1}^{\alpha} \left((M-p)\cdot p^k\cdot M^k\right)$
%\end{array}
%	\end{gather*}
	which can be rewritten as $
	M^{k+1}\cdot \left(\sum\limits_{p=1}^{\alpha} p^k\right) - M^k \cdot \left(\sum\limits_{p=1}^{\alpha} p^{k+1}\right)$.
	
	Since $\sum\limits_{p=1}^{\alpha} p^k \approx \mathcal{O}(\alpha^{k+1})$ and $\sum\limits_{p=1}^{\alpha} p^{k+1} \approx \mathcal{O}(\alpha^{k+2})$, we can conclude the total complexity to be of the order $\mathcal{O}((\alpha\cdot M)^{k+1}) - \mathcal{O}(\alpha^{k+2}\cdot M^k)$ which proves the result.
\end{proof}

Whenever there is a need to compute numerous anti-unifications of unordered goals with limited time resources, the $k$-swap stability abstraction allows to keep the search space tractable while outputting goals that are, on average, close in size to that of a lcg. Such situations can e.g. arise in static analysis techniques for large Horn clause programs, such as the assessment of structural similarity between algorithms expressed in CLP~\cite{clones}. 

%We have observed, through the implementation of a Prolog prototype built for the case of (unordered) Constraint Logic Programming goals, that Algorithms~\ref{alg:kswap} and~\ref{alg:selection} find a relatively good abstraction of a lcg (the outputted generalizations have 90\% to 100\% of a looked-upon lcg size in all our test cases) while significantly diminishing the amount of time required for finding such a common generalization (when each goal harbors 10 to 15 different variables and 15 to 20 atoms of arity between 1 and 3, the average execution of our test cases takes the execution time of 26 seconds with bruteforce mechanisms down to 91 milliseconds with the k-swap stability algorithm). Obviously the algorithm seems to run in polynomial time. 
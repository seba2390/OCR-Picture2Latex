

\par Relevant work related to this paper includes state-of-the-art PC geometry coding and learning-based methods in image and point cloud compression.

\subsection{MPEG G-PCC and Conventional Lossless Codecs}
\par Most existing methods that compress point cloud geometry, including MPEG G-PCC, use octree coding \cite{schnabel2006octree,7434610,6224647, garcia2017context, garcia2018intra, garcia2019geometry,huang2020octsqueeze, biswas2020muscle} and local approximations called ``triangle soups'' (trisoup)~\cite{schnabel2006octree,dricot2019adaptive}. 
\par In the G-PCC geometry coder, points are first transformed and voxelized into an axis-aligned bounding box before geometry analysis using trisoup or octree scheme. In the trisoup coder, geometry can be represented by a pruned octree plus a surface model. This model approximates the surface in each leaf of the pruned octree using 1 to 10 triangles. 
% This technique is known as triangle soup. 
In contrast, the octree coder partitions voxelized blocks until sub-cubes of dimension one are reached. First, the coordinates of isolated points are independently encoded to avoid "polluting" the octree coding (Direct Coding Mode - DCM) \cite{dcm}. To encode the occupancy pattern of each octree node, G-PCC introduces many methods to exploit local geometry information and obtain an accurate context for arithmetic coding, such as Neighbour-Dependent Entropy Context \cite{neighbor}, intra prediction \cite{intracodinggpcc}, planar/angular coding mode \cite{planarcodingmode,angularcodingmode}, etc. The lossless geometry coding mode of G-PCC is based on octree coding only.

\par In order to deal with the irregular point space, many octree-based lossless PCC methods have been proposed. In \cite{schnabel2006octree}, the authors proposed an octree-based method which aims at reducing entropy by employing prediction techniques based on local surface approximations to predict occupancy patterns. Recently, more context modeling based approaches are proposed \cite{garcia2017context, garcia2018intra, garcia2019geometry}. For example, the intra-frame compression method P(PNI) proposed in \cite{garcia2019geometry} builds a reference octree by propagating the parent octet to all children nodes, thus providing 255 contexts to encode the current octant. Octree coding allows for a progressive representation of point clouds since each level of the octree is a downsampled version of the point cloud. However, a drawback of octree representation is that, at the first levels of the tree, it produces ``blocky'' scenes, and geometry information of point clouds (i.e., curve, plane) is lost. The authors of \cite{8122226} proposed a binary tree based method which analyzes the point cloud geometry using binary tree structure and realizes an intra prediction via the extended Travelling Salesman Problem (TSP) within each leaf node. Instead, in this paper, we employ a hybrid octree/voxel representation to better exploit the geometry information. Besides,  the methods in \cite{garcia2017context, garcia2018intra, garcia2019geometry} produce frequency tables which are collected from the coarser level or the previous frame and must be transmitted to the decoder. Our method predicts voxel distributions in a sequential manner at the decoder side, thus avoiding the extra cost of transmitting large frequency tables.
%  The lossless geometry compression method of \cite{6224647} is based on predictive coding with inter-frame prediction
\subsection{Generative Models and Learning-based Compression}
\par 
% Learning probabilistic models that return explicit probability densities from training data is the central problem in unsupervised learning.
Estimating the data distribution from a training dataset is the main objective of generative models, and is a central problem in unsupervised learning.
It has a number of applications, from image generation \cite{theis2015generative,gregor2015draw, oord2016pixel,salimans2017pixelcnn++}, to image compression \cite{491334, balle2016end,mentzer2018conditional} and denoising \cite{chen2018image}. Among the several types of generative models proposed in the literature \cite{10.5555/2969033.2969125}, auto-regressive models such as PixelCNN \cite{oord2016pixel,salimans2017pixelcnn++} are particularly relevant for our purpose as they allow to compute the exact likelihood of the data and to generate realistic images, although with a high computational cost. Specifically, PixelCNN factorizes the likelihood of a picture by modeling the conditional distribution of a given pixel's color given all previously generated pixels. These conditional distributions only depend on the possible pixel values with respect to the scanned context, which imposes a \textit{causality} constraint. PixelCNN models the distribution using a neural network and the causality constraint is enforced using masked filters in each convolutional layer. Recently, this approach has also been employed in image compression to yield accurate and learnable entropy models~\cite{mentzer2018conditional}. Our paper explores the potential of this approach for point cloud geometry compression by adopting and extending conditional image modeling and masking filters into the 3D voxel domain.

\par Inspired by the success in learning-based image compression, deep learning has been widely adopted in point cloud coding  both in the octree domain \cite{huang2020octsqueeze,biswas2020muscle},  voxel domain \cite{8954537,9191021,quach2019learning,quach2020improved,wang2019learned,guarda2020point}  and point domain \cite{yan2019deep,huang20193d, wang2020multiscale}. Recently, the authors of \cite{huang2020octsqueeze} proposed an octree-based entropy model that models the probability distributions of the octree symbols based on the contextual information from octree structure. This method only targets static LiDAR point cloud compression. The extension version for intensity-valued LiDAR streaming data using spatio-temporal relations is proposed in \cite{biswas2020muscle}. However, these methods target dynamically acquired point clouds, while in this paper we mainly focus on dense static point clouds.
\par Working in the voxel domain enables to easily extend most 2D tools, such as convolutions, to the 3D space. 
Many recent 3D convolution based autoencoder approaches for lossy coding \cite{quach2019learning,quach2020improved,wang2019learned,guarda2020point} compress 3D voxelized blocks into latent representations and cast the reconstruction as a binary classification problem. The authors of \cite{yan2019deep} proposed a pointnet-based auto-encoder method which directly takes points as input rather than voxelized point cloud.  To handle sparse point clouds, recent methods leverage advances in sparse convolution \cite{choy20194d,graham2017submanifold} to allow point-based approaches  \cite{huang20193d, wang2020multiscale}. For example, the proposed lossy compression method in \cite{wang2020multiscale} progressively downscale the point cloud into multiple scales using sparse convolutional transforms. Then, at the bottleneck, the geometry of scaled point cloud is encoded using an octree codec and the attributes are compressed using a learning-based context model.  In contrast, in this paper, we focus on dense voxelized point clouds and losslessly encode each voxel using  the learned distribution from its 3D context. In addition, we apply this approach in a block-based fashion, which has been successfully employed in traditional image and video coding.
%and tackle the sparsity by representing point cloud in hybrid octree/voxel domain

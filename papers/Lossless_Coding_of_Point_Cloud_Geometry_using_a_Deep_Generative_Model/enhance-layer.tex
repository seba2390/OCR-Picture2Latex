\subsubsection{Context model} 
\label{subsub:context model}
\par In the enhancement layer, we also employ context-adaptive binary arithmetic-coding as in base layer. However, we extend the context to include the lower resolution of each block which is available in the base layer. Specifically, we estimate $p(v)$ by factorizing probability $p(v)$ as:
\begin{equation}
    p(v)= \underset{i=1 }{\overset{d^3}{\Pi}}p(v_i|v_{i-1},v_{i-2},\ldots,v_{1}, v^{lr}).
    \label{eq:pvlr}
\end{equation}
Each term $p(v_i|v_{i-1}, \ldots, v_1,v^{lr})$ is voxel occupancy distribution given all previous voxels and the lower resolution of block $v$ -  $v^{lr}$. We estimate each term using a neural network. Similar to VoxelDNN, as our target is to learn a good estimation of voxel occupancy distribution $p(v_i|v_{i-1}, \ldots, v_1,v^{lr})$ , we train the network using cross-entropy loss.
%
\begin{figure}[tb]
\captionsetup{singlelinecheck = false, format= hang, justification=raggedright, font=small, labelsep=space}
\centering
\includegraphics[width=0.9\linewidth]{figures_pcc/network_architec.png}
\caption{VoxelDNN architecture for block 64. A type A mask is applied in the first layer (dashed borders) and type B masks afterwards. `f64,k7,s1' stands for 64 filters, kernel size 7 and stride 1. }
\label{fig:Networkarchitecture2}
\end{figure}

\par Figure \ref{fig:Networkarchitecture2} shows our network architecture composes of two inputs. The branch from the first input to output is the causality preserved path where we try to predict the distribution of current voxel given the previous encoded voxels. On this path, we apply type A masks and type B masks as in VoxelDNN to enforce causality. In the second branch, we learn the probability distribution $p(v)$ from lower resolution. We apply 2 residual blocks without $ReLU$ and $BatchNormalization$ at the lower dimension before upsampling by 2 with the $TransposedConvolution$. And those two paths are merge in the addition layer. Note that a type B mask is applied in the last convolutional layer to enforce the causality. 
\subsubsection{Enhancement layer encoder}
\par When the base layer is successfully received, decoder can start decoding the higher resolution given lower resolution. Therefore, in the encoder side, we encode the enhancement layer given the lower resolution of point cloud. In the same manner as base layer, we use an arithmetic coder to encode voxels in this layer sequentially. That is, every time a voxel is encoded, we feed this voxel and lower resolution version of the current block into network to predict the probability of the next voxel. Then, we pass this probability to arithmetic coder to encode the next symbol. However, not all voxel in the higher resolution are encoded, we skip the empty voxels where its corresponding voxel in lower resolution is non-occupied.
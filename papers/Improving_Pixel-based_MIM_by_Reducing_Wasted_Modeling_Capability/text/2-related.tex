\section{Related Works}

\paragraph{Self-supervised Learning} reviously, many works\cite{ViT, DeiT} relied on abundant labeled datasets to achieve promising results. However, annotating this data requires a large number of human labors. Therefore, how to effectively capture useful semantics embedded in the abundance of data available on the Internet is currently a hot topic.
In recent times, self-supervised learning has witnessed tremendous growth in computer vision, following remarkable achievements in natural language processing. These methods cater to diverse inputs, including images\cite{simclr,BEiT,MAE,ibot}, videos\cite{2022MoQuad,hu2021contrast}, and multi-modality inputs\cite{CLIP,2021LearningTBP}. They capture rich semantic information by creating effective proxy tasks, such as contrastive learning and masked image modeling, in large amounts of unlabeled data. In comparison to supervised learning\cite{DeiT,DeiT-v2,DEiT-v3}, these self-supervised learning approaches have gradually outperformed them in numerous downstream tasks and possess immense potential to become the principal pre-training paradigm.

\paragraph{Feature Pyramid} Utilizing multi-level features has been extensively studied in previous years, and one of the most famous applications is the Feature Pyramid Network (FPN)\cite{FPN}. This technique has been widely used in many dense tasks such as object detection and semantic segmentation to improve the model's perception of objects of different scales. Incorporating FPN into existing designs in many works\cite{maskrcnn, upernet} has led to significant improvements. However, the multi-level feature fusion module only accepts features of different scales as input, limiting its adaptation to isotropic architectures such as ViT\cite{ViT}, in which features from different layers are of the same scale. In masked image modeling, most approaches choose ViT as their encoder due to the masked patch prediction task. Therefore, there are few works exploring multi-level feature fusion in this domain. Even though some works~\cite{ConvMAE,itpn} aim to explore multi-level fusion in masked image modeling, their applications are still limited to the traditional hierarchical architecture and do not address the issue of being biased toward low-level details for these pixel-based methods.

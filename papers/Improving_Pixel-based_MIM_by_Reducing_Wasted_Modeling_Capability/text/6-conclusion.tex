\section{Conclusion}
In this study, we take the first step to systematically explore multi-level feature fusion for the isotropic architecture, such as ViT, in masked image modeling. Initially, we recognize that pixel-based MIM approaches tend to excessively rely on low-level features from shallow layers to complete the pixel value reconstruction task by a pilot experiment. We then apply a simple and intuitive multi-level feature fusion to two pixel-based MIM approaches, MAE and PixMIM, and observe significant improvements in both, gradually closing the performance gap with these approaches by using an extra heavy tokenizer. Finally, we conduct an extensive analysis of multi-level feature fusion and find that it can suppress high-frequency information and flatten the loss landscape. We believe that this work can provide the community with a fresh perspective on these pixel-based MIM approaches and continue to rejuvenate this kind of simple and efficient self-supervised learning paradigm.
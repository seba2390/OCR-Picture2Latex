% \subsection{Biased toward low-level features only exists in pixel-based MIM}
\subsection{Feature Bias of Different Pre-training Methods}
\label{sec:proprietary}
\input{fig/weight_vs_layer}
In order to investigate whether being biased towards low-level features is the sole and inherent drawback of pixel-based MIM, we introduce multi-level feature fusion to EVA\cite{EVA} and supervised ViT\cite{MAE}. EVA is one of the representative works that focuses on regressing high-level features produced by CLIP\cite{CLIP}, while supervised ViT is one of the works that require the model to map the input image to a semantic label. Both EVA and supervised ViT target high-level features that contain rich semantic information describing the input image. As shown in \autoref{fig:weight_vs_layer}, unlike MAE, the weight of the last layer's feature for both EVA and supervised ViT is significantly higher than that of the shallow layers. This observation suggests that the bias towards low-level features exhibited by these pixel-based MIM approaches is primarily caused by the raw-pixel reconstruction task.


Multi-level feature fusion(MFF) can be incorporated into most existing pixel-based MIM approaches in a plug-and-play manner. \autoref{fig:main} gives an overview of the whole framework.
To keep the simplicity, we mainly focus on these steps relevant to MFF, leaving out other steps.  Given an image $\mathbf{I}\in \mathbb{R}^{H\times W\ \times3}$, we feed it into the encoder, $\mathbb{E}$, to get the latent representations:
\begin{equation}
    \label{eq:extract}
    \mathrm{X} = \mathbb{E}(\mathbf{I})
\end{equation}
The latent representations, denoted by $\mathrm{X} = \{x_0, x_1, ..., x_{N-2}, x_{N-1}\}$, correspond to the output feature from each transformer layer of the ViT, where $N$ represents the depth of the encoder. For the pilot experiment in \autoref{fig:teaser}, we fuse all-level features from each layer of the encoder. However, indiscriminately fusing all of them may introduce redundancy or even makes the model much harder to be optimized. But finding the most effective layers to fuse induces a large search space. To simplify the layer selection procedure, we follow the guidelines below:
\comment{To determine which level's and how many level's features should be used for fusion. We thoroughly investigate the layer selection strategy following those guidelines:}

\begin{enumerate}[label={\bf {{(\arabic*)}}},leftmargin=*,topsep=0.5ex,itemsep=-0.5ex,partopsep=0.75ex,parsep=0.75ex,partopsep=0pt,wide, labelwidth=0pt,labelindent=0pt]
    \item: We first conduct an ablation study to compare the results of fusing shallow layers or deep layers (as shown in  \autoref{fig:freq_ana}, shallow layers contain low-level features, and deep layers contain high-level features), and more details are presented in \autoref{sec:ablation}. The results show that utilizing the features of the shallow layers performed significantly better than deep ones. Thus intuitive analysis and the quantitative numbers both indicate that the shallow layer should be selected for fusion.
    \item: We then examine how many layers should be taken into consideration. In addition to the selected shallow layer and output layer, we also try to explore introducing different numbers of intermediate layers for fusion. We refer the reader to \autoref{sec:ablation} for more details of this experiment.
\end{enumerate}

We finally selected $M=5$ additional layers besides the last layer (6 layers in total) and the output features from those layers are used for fusion. We define the indices for these selected layers as $\mathcal{W}, |\mathcal{W}|=M$.
After that, we apply a projection layer, $\mathcal{P}_\text{i}$, to each of the additional $M$ layers before fusion. 
\begin{equation}
    \label{eq:proj}
    \Tilde{\mathrm{X}} = \{\mathcal{P}_\text{i}(x_i)\}_{i \in \mathcal{W}} + \{x_{N-1}\}
\end{equation}
Adding a projection layer to align the feature space between different levels' features is a common practice in self-supervised learning.

Finally, we introduce the fusion layer, $\mathcal{F}$,  to fuse multi-level features $\Tilde{\mathrm{X}}$:
\begin{equation}
    O = \mathcal{F}(\Tilde{\mathrm{X}})
\end{equation}
$O$ will be fed into the decoder for pixel reconstruction.
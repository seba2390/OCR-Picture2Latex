\begin{table*}[!ht]
\centering
\tabcolsep 7pt
\begin{tabular}{lcclllll}
 \multicolumn{3}{c}{Evaluation Protocol$\rightarrow$} & \multicolumn{2}{c}{ImageNet} & \multicolumn{2}{c}{Low-shot} & ADE20K \\
\cmidrule(lr){4-5}\cmidrule(lr){6-7}\cmidrule(lr){8-8}  
Method&Target&Epoch& ft(\%) & lin(\%) & 1\% & 10\% & mIOU \\
\midrule
\multicolumn{8}{@{\;}l}{\bf Supervised learning} \\
\quad DeiT III\cite{DEiT-v3} &- & 800 & 83.8 &- & - & - & 49.3 \\
\midrule
\multicolumn{7}{@{\;}l}{\bf Masked Image Modeling w/ pre-trained target generator} \\
\quad BEiT\cite{BEiT} &DALLE&800&83.2 & 56.7 & - & - & 45.6 \\
\quad CAE\cite{CAE} & DALLE&800&83.8&68.6& - & - & 49.7 \\
\quad MILAN$^{*}$\cite{MILAN} & CLIP-B&400&85.4&78.9&67.5 & 79.7 & 52.7\\
\quad BEiT-v2\cite{BEiTv2}& VQ-KD&1600&85.5& 80.1 &-&-&53.1\\
\quad MaskDistill\cite{MASKdistill} &CLIP-B&800&85.5&-&-&-&54.3\\
\midrule
\multicolumn{7}{@{\;}l}{\bf Masked Image Modeling w/o pre-trained target generator} \\
\quad MaskFeat$^{*}$\cite{MaskFeat}&HOG&1600&84.0&62.3&52.9&73.5 & 48.3\\
\quad SemMAE\cite{SemMAE} & RGB &800&83.4&65.0&- & - & 46.3\\
\quad SimMIM\cite{SimMIM}& RGB &800&83.8&56.7&-&- & -\\
\hdashline
\quad MAE$^{*}$\cite{MAE} & RGB & 300 & 82.8 & 61.5 & 41.4 & 70.5 & 43.9 \\
\quad \textbf{MFF}$_\text{\tt MAE}$ &RGB&300&{{83.3} \more{(+0.5)}}&{63.3} \more{(+1.8)} & 43.7 \more{(+2.3)} & 71.4 \more{(+0.9)} &{47.7} \more{(+3.6)}\\
\quad MAE$^{*}$\cite{MAE} & RGB & 800 & 83.3 & 65.6 & 45.4 & 71.2 & 46.1 \\
\quad \textbf{MFF}$_\text{\tt MAE}$ &RGB&800& 83.6 \more{(+0.3)} & 67.0 \more{(+1.4)} & 48.0 \more{(+2.6)}& 72.0 \more{(+0.8)}  & 47.9 \more{(+1.8)}\\
% \quad MAE$^{*}$\cite{MAE} & RGB & 1600 & 83.5 & 67.8 & 47.8 & 72.4 & 48.1 \\
% \quad \textbf{MFF}$_\text{\tt MAE}$ &RGB&1600& 83.7 \more{(+0.2)} & 69.6 \more{(+1.8)} & 51.9 \more{(+3.1)} & 73.4 \more{(+1.0)}  & 48.3 \more{(+0.2)}\\
\hdashline

\quad PixMIM\cite{pixmim} & RGB&800 & 83.5 & 67.2 & 47.9 & 72.2 & 47.3\\
\quad \textbf{MFF}$_\text{\tt PixMIM}$ &RGB&800&83.6 \more{(+0.1)}&68.2 \more{(+1.0)} & 49.0 \more{(+1.1)} & 73.0 \more{(+0.8)}  &48.6 \more{(+1.3)}\\
% \quad PixMIM\cite{pixmim} & RGB & 1600 & 83.6 & 69.3 & 50.9 & 72.9 & 48.7 \\
% \quad \textbf{MFF}$_\text{\tt PixMIM}$ &RGB&1600&83.9 \more{(+0.3)}&71.1 \more{(+1.8)}& 53.9 \more{(+3.0)} & 74.1 \more{(+1.2)}  &49.1 \more{(+0.4)}\\

\end{tabular}
\caption{\textbf{Performance comparison of MIM methods on various downstream tasks.} We report the results with fine-tuning (ft) and linear probing (lin) experiments on ImageNet-1K, objection detection on COCO, and semantic segmentation on ADE20K. The backbone of all experiments is ViT-B\cite{ViT}. $*$: numbers are reported by running the official code release. Low-shot: end-to-end fine-tuning with 1\% and 10\% of the training set.}
\label{tab:comparison}
\end{table*}

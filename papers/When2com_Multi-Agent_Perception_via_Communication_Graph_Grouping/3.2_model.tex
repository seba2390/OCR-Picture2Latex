\subsection{Communication Groups Construction}

% motviation
As demonstrated in Figure ~\ref{fig:com_diff}, previous works on learning to communicate applied fully-connected communication for information exchange across agents. This framework results in a large amount of bandwidth usage and is difficult to scale up when the number of agents increases. 

% our method
To reduce the network complexity and bandwidth usage, inspired by communication network protocol~\cite{kurose2005computer}, we propose a two-step group construction procedure: we first apply the handshake communication~\cite{liu2020who2com} to determine the weights of connections, and we further prune the less important connections with an activation function.  

To start constructing a communication group, we apply a three-stage handshake communication mechanism~\cite{liu2020who2com}, which consists of three stages: request, match, and select. Agent $i$ first compresses its local observations $\bm{x}_i$ into a compact query vector $\bm{\mu}_i$ and a key vector $\bm{\kappa}_i$:
\begin{equation}\label{eq:key_query_generator}
     \bm{\mu}_i = G_q(\bm{x}_i; \theta_q)\in\mathbb{R}^Q, \quad \bm{\kappa}_i = G_k(\bm{x}_i;\theta_k)\in\mathbb{R}^K,
\end{equation}
where $G_q$ is a query generator parameterized by $\theta_q$ and $G_k$ is a key generator parameterized by $\theta_k$. We further broadcast the query to all of other agents, and note that this only causes limited amount of bandwidth transmission as all queries are compact compared to the high-resolution images. To decide who to communicate with, we compute a matching score $\bm{m}_{i,j}$ between an agent $i$ (as a requester) and an agent $j$ (as a supporter),
\begin{equation}\label{eq:matching}
    \bm{m}_{i,j} = \Phi(\bm{\mu}_i, \bm{\kappa}_j), \quad \forall i\neq j,
\end{equation}
where $\Phi(\cdot,\cdot)$ is a learned similarity function which measures the correlation between two vectors. The matching score $\bm{m}_{i,j}$ implies correlation between agent $i$ and $j$, and intuitively this value also represents the amount of information the supporting agent $j$ can provide for the requesting agent $i$. 

% 
However, the above method does not learn ``when" to communicate, and it results in wasted bandwidth when an agent has sufficient information and the communication is not necessary. An ideal communication mechanism is to switch on transmission when the agent requires information from other agents to improve its perception ability, while it should also switch off the transmission when it has sufficient information for its own perception task. Toward this end, inspired by self-attention mechanism~\cite{cheng2016long}, we use the correlation between the key and query from the same agent to determine if the agent potentially requires more information and thus learn when to communicate,
% equtation for self-attention 
\begin{equation}\label{eq:matching}
    \bm{m}_{i,i} = \Phi(\bm{\mu}_i, \bm{\kappa}_i).
\end{equation}
Note that $\hat{\bm{m}}_{i,i}\approx1$ represents that the agent has sufficient information and does not need communication for perception tasks.

In order to minimize bandwidth usage during transmission, we further propose an asymmetric message method, which compresses the query into an extremely low-dimensional vector (which is transmitted) while keeping a larger size for the key vector (which is not transmitted). Once extremely compact queries are passed to receiver agents, we use a scaled general attention~\cite{luong2015effective,vaswani2017attention} to compute the correlation between agent $i$ and agent $j$:
\begin{equation}\label{eq:matching_detail}
   \Phi(\bm{\mu}_i, \bm{\kappa}_j)= \frac{\bm{\mu}_i^T \bm{W}_g \bm{\kappa}_j}{\sqrt{K}},
\end{equation}
where $W_g \in \mathbb{R}^{Q \times K}$ is a learnable parameter to match the size of query and key, and $Q$ and $K$ are dimension of query and key respectively. 


% MIMO
Based on the above self-attention and cross-attention mechanism across all queries and keys, we thus derive the matching matrix $\bm{M}$:
\begin{equation}\label{eq:matching}
\bm{M} = 
 \bm{\sigma}(\begin{pmatrix}
  \bm{m}_{1,1} & \bm{m}_{1,2} & \cdots & \bm{m}_{1,N} \\
  \bm{m}_{2,1} & \bm{m}_{2,2} & \cdots & \bm{m}_{2,N} \\
  \vdots  & \vdots  & \ddots & \vdots  \\
  \bm{m}_{N,1} & \bm{m}_{N,2} & \cdots & \bm{m}_{N,N} 
 \end{pmatrix})\in\mathbb{R}^{\bm{N}\times \bm{N}},
\end{equation}
where $\bm{\sigma}(\cdot)$ is a row-wise softmax function.

%
To construct the communication groups, we prune the less connections with an activation function:
\begin{equation}\label{eq:matching}
\bar{\bm{M}} = \bm{\Gamma}(
   \bm{M} ;\delta),
\end{equation}
where $\bm{\Gamma}(\cdot;\delta)$ is an element-wise function, which zeros out the elements smaller than $\delta$. (We set $\delta=\frac{1}{N}$ in our experiment.)

The derived matrix $\bar{\bm{M}}$ can be regarded as the adjacency matrix of a directed graph, where the entries of the matrix indicate when to communicate and non-entries represent who to communicate with as demonstrated in Figure~\ref{fig:graph_mat}. 
Each row of the matrix represents how a receiver agent collects information from different supporting agents, and each column of the matrix is how one supporter sends its own information to different requesting agents.  
\input{figure/graph_mat.tex}

As shown in Figure~\ref{fig:overview_model}, once a requesting agent collects the information from its linked supporting agents, the requesting agent $i$ integrates its local observation and the compressed visual feature maps from supporters based on the matching scores:
\begin{align}\label{eq:softmax}
        \bm{\hat{y}}_i=D([{\bm{f}}_i; \bm{f}_{i}^{inf}];\theta_d), \quad
        \bm{f}_{i}^{int} = \sum_{\substack{j=1 \\  \bm{\bar{m}}_{i,j}\neq 0 }}^{\bm{N}}\bm{\bar{m}}_{i,j}\bm{f}_j,
\end{align}
where $\bm{D}$ is an perception task decoder parameterized by $\theta_d$, $\bm{\bar{m}}_{i,j}$ is the element located in
$i$-th row and $j$-th of the matrix $\bm{\bar{M}}$, $\bm{f}_i=\bm{E}(x_i;\theta_e)$ is an feature map of agent $i$ encoded by an image encoder $\bm{E}$, $[\cdot;\cdot]$ is concatenation operation along channel dimension. It is worth noting that our perception task decoder is not limited for specific vision tasks, and we demonstrate our communication framework can be generalized to different visual tasks in our experiments. 

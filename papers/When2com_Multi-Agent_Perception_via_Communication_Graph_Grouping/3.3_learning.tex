\subsection{Learning of Communication}
Our learning strategy follows the centralized training and decentralized inference procedure~\cite{lowe2017multi}. 
Precisely, all agents are able to access all local observations of agents in the training stage, while each agent can only observe its own local observation in the inference stage. Our goal is to learn a bandwidth-efficient communication mechanism, so that in the inference stage, our proposed model is able to perform multi-agent collaborative perceptions in a bandwidth-limited and distributed manner. 

We follow the aforementioned handshake communication to compute the matching matrix $M$, and we weight the agents' feature maps based on the matching matrix $M$ and further integrate them as: 
\begin{align}\label{eq:training_softmax}
        \bm{f}_{i}^{all} = \sum_{j=1}^{\bm{N}}\bm{\tilde{m}}_{i,j}\bm{f}_j,
\end{align}
where $\bm{\tilde{m}}$ the element located in
$i$-th row and $j$-th of the matrix $\bm{M}$. 
Note that in the above equation $\bm{m}_{i,j}\bm{f}_j$ represents who to communicate with, and $\bm{m}_{i,i}\bm{f}_i$ indicates when to communicate.
Then, a client agent $i$ combines its own feature map $f_i$ and the integrated feature $\bm{f}_{i}^{all}$ to compute the prediction for downstream visual tasks,
\begin{align}\label{eq:training_softmax}
        \bm{\tilde{y}}_i=D([{\bm{f}}_i; \bm{f}_{i}^{all}];\theta_d), \quad
\end{align}

In order to train our model, we use the label for downstream tasks (\textit{e.g.,} segmentation masks) as supervision, we compute the loss as:
\begin{align}\label{eq:loss}
\mathcal{L} = \mathcal{H}(\bm{y}_j, \bm{\tilde{y}}_j),
\end{align}
where $\mathcal{H}(\cdot,\cdot)$ can be the objective function for any downstream visual tasks (\textit{e.g.} pixel-wise cross-entropy for segmentation tasks or cross-entropy for recognition tasks). We later update the weights of our model $\Theta=(\theta_k,\theta_q, \theta_e, \theta_d)$ using the above loss in an end-to-end manner. 

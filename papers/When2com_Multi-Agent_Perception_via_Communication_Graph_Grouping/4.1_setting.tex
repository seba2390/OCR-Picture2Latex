\subsection{Experimental Cases and Datasets}
\input{table/dataset.tex}
\subsubsection{Collaborative Semantic Segmentation}

Our first task is collaborative 2D semantic segmentation of a 3D scene. Given observations (an RGB image, aligned dense depth map, and pose) from several mobile agents, the objective of this task is to produce an accurate 2D semantic segmentation mask for each agent.

Since current semantic segmentation datasets~\cite{geiger2013vision,cordts2016cityscapes,RobotCarDatasetIJRR,hecker2018end} only provide RGB images and labels captured from the perspective of single agent, we thus use AirSim simulator~\cite{airsim2017fsr} to collect our AirSim-MAP (Multi-Agent Perception) dataset.
For this dataset, we fly a swarm of five to six drones with different yaw rates through a series of waypoints in the AirSim ``CityEnviron'' environment. 
We record pose, depth maps, and RGB images for each agent. Note that we also provide semantic segmentation masks for \textbf{all} drones.  

We consider three experimental cases within this task.  We refer to the agent attempting segmentation as the \textbf{requesting} agent, and all other agents as the \textbf{supporting} agents.  Details for each case are listed as follows: 

\noindent
\textbf{Single-Request Multiple-Support (SRMS)} 
This first case examines the effectiveness of communication for a single requesting agent under the assumption that if an agent is degraded, then its original, non-degraded information will be present in one of the supporting agents.  We include a total of five agents, of which only one is selected for possible degradation.  We add noise to a random selection of $50\%$ of this agent's frames, and we randomly replace one of the remaining agents with the \textit{non-degraded} frame of the original agent.  Note that only the segmentation mask of the original agent is used as supervision.  

\noindent
\textbf{Multiple-Request Multiple-Support (MRMS)}
The second case considers a more challenging problem, where multiple agents can suffer degradation.  Instead of requiring a single segmentation output, this case requires segmentation outputs for all agents, degraded and non-degraded.  We follow the setup of the previous case, and we ensure that each of the several degraded requesting agents has a corresponding non-degraded image among its supporting agents.  

\noindent
\textbf{Multiple-Request Multiple-Partial-Support (MRMPS)}
The third case removes the assumption that there exists a clean version of the degraded view among the supporting agents.  Instead, the degraded agent must select the most informative view(s) from the other agents, and these views might have a variable degree of relevance.  Specifically, as the drone group moves through the environment, the images from each drone periodically and partially overlap with those of other drones.  Intuitively, the segmentation output of the requesting drone is only aided from the supporting drones that have overlapping views. 

\input{table/MIMO_case1.tex}

\subsubsection{Multi-Agent 3D Shape Classification}
In addition to the semantic segmentation task, we also consider a multi-agent 3D shape classification task.  
For this experimental case, we construct a multi-agent variant of the \textbf{ModelNet 40} dataset~\cite{wu20153d}. 
The original dataset contains 40 common object categories from ModelNet with 100 unique CAD models per category and 12 different views of each model.  
However, our variant adds a communication group structure to the original dataset.  Specifically, we sample three sets of class-based image triplets.  
Each triplet corresponds to a randomly selected 3D object model and each triplet contains three randomly selected 2D views of its corresponding object model.  
To make this problem setting more challenging, we further degrade one image from each triplet. 
The objective of this task is to predict the corresponding object class for each agent by leveraging the information from all agents. 
Figure~\ref{fig:vis_graph} shows an example of the dataset in one trial with 9 agents.
This modified task is essentially a distributed version of the multi-view classification task~\cite{wu20153d}.


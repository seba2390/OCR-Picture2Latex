\subsection{Learning from scratch} \label{subsec: From_scratch}

Similarly to the methodology exposed in \cite{gomez2019automatic}, we propose in this paper the use of shallow CNNs from scratch to address the glaucoma detection, taking into account the significant differences between our grey-scale circumpapillary OCT images and other large databases containing natural images, which are widely used for transfer-learning techniques.

During the internal cross-validation (ICV) stage, an empirical exploration was carried out to determine the best hyper-parameter combination in terms of minimisation of the binary cross-entropy loss function. Different network architectures composed of diverse learning blocks were developed. In particular, convolutional, pooling, batch normalisation and dropout layers were considered to address the feature extraction stage. The variable components of each layer, such as the convolutional filters, pooling size, dropout coefficients, as well as the number of convolutional layers in each block were optimised during the experimental phase.  
Regarding the top model, the use of flatten, dropout and fully-connected layers with a different number of neurons was studied. Also, global max and global average pooling layers were analysed in order to reduce the number of trainable parameters.
Moreover, we implemented an optimal weighting factor of [1.35, 0.79] during the training of the models to alleviate the unbalanced problem between classes. 

After the ICV stage, the best CNN architecture was found using four convolutional blocks, as it is detailed in Table \ref{CNN_from_scratch}. It is remarkable the use of the global max-pooling (GMP) layer applied in the last block, which allows extracting the maximum activation of each convolutional filter before the classification layer. Also, note that batch normalization and dropout layers were not used because no improvement was reported during the validation phase. Only a dense layer with a \textit{softmax} activation and 2 neurons, corresponding to glaucoma and healthy classes, was defined. 

\begin{table}[htbp]
\caption{Proposed CNN architecture trained from scratch.}
\label{CNN_from_scratch}
\renewcommand{\arraystretch}{1.1} % rows
\setlength\tabcolsep{8 pt} % cols
\small
\begin{center}
\begin{tabular}{ccc}
\hline
 \textbf{Layer name} & \textbf{Output shape}                & \textbf{Filter size}            \\ \hline
Input layer         & 496 x 768 x 1                        & N/A                             \\
Conv1\_1            & 496 x 768 x 32                       & 3 x 3 x 32                      \\
MaxPooling          & 248 x 384 x 32                       & 2 x 2 x 32                      \\ 
Conv2\_1            & 248 x 384 x 64                       & 3 x 3 x 64                      \\ 
MaxPooling          & 124 x 192 x 64                       & 2 x 2 x 64                      \\ 
Conv3\_1            & 124 x 192 x 128                       & 3 x 3 x 128                      \\
MaxPooling          & 62  x 96  x 128                       & 2 x 2 x 128                      \\ 
Conv4\_1            & 62  x 96  x 256                      & 3 x 3 x 256                     \\
MaxGlobalPool       & 256                                  & N/A                             \\ 
Dense (softmax)     & 2                                    & N/A                             \\ \hline
\end{tabular}
\end{center}
\end{table}

The optimal hyper-parameters combination was achieved by training the CNNs during 150 epochs, using Adadelta optimizer with a learning rate of 0.05 and a batch size of 16. It should be noticed that we also proposed the use of data augmentation (DA) techniques \cite{wong2016} to elucidate how important is the creation of artificial samples when addressing small databases. Specifically, a factor ratio of 0.2 was applied here to perform random geometric and dense elastic transformations from the original images.




 

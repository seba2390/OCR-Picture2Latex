\section{Results and discussion} \label{sec: Results}

\subsection{Validation results}

In this stage, we present the results achieved during the ICV stage for each of the proposed CNNs. We expose in Table \ref{valRes_fromScratch} a comparison of the CNNs trained from scratch, in terms of mean $\pm$ standard deviation. Several figures of merit are calculated to evidence the differences between using or not data augmentation (DA) techniques. In particular, sensitivity (SN), specificity (SPC), positive predictive value (PPV), negative predictive value (NPV), F-score (FS), accuracy (ACC) and area under the ROC curve (AUC) are employed. 

\begin{table}[h]
\caption{Classification results reached during the ICV stage from the proposed CNNs trained from scratch.}
\label{valRes_fromScratch}
%\renewcommand{\arraystretch}{1.09}
\setlength\tabcolsep{8 pt}
\small
\begin{center}
\begin{tabular}{cccc}
\hline
\multicolumn{1}{l}{}{} & \textbf{Without DA}       & \textbf{With DA} \\
\hline
\textbf{SN}         & $0.7657 \pm 0.2032$         &                  $\textbf{0.8771}\pm\textbf{0.1281}$\\
\textbf{SPC}        & $\textbf{0.9270} \pm \textbf{0.1302}$  &      $0.8047 \pm 0.1514$ \\
\textbf{PPV}        & $\textbf{0.8721} \pm \textbf{0.0662}$  &      $0.7477\pm 0.14061$  \\
\textbf{NPV}        & $0.8808 \pm  0.0971$                   &      $\textbf{0.9224} \pm \textbf{0.0678}$ \\
\textbf{FS}         & $\textbf{0.8016} \pm \textbf{0.1309}$  &      $0.7980\pm 0.10745$   \\
\textbf{ACC}        & $\textbf{0.8679} \pm \textbf{0.0781}$  &      $0.8315 \pm 0.0985$ \\
\textbf{AUC}        & $0.9152 \pm 0.0490$     &                     $\textbf{0.9319} \pm \textbf{0.0386}$\\
\hline
\end{tabular}
\end{center}
\end{table}

Significant differences between CNNs trained with and without data augmentation techniques can be appreciated in Table \ref{valRes_fromScratch}, especially related to the sensitivity and specificity metrics. 
Worth noting that the learning curves relative to the CNN trained without implementing DA algorithms reported slight overfitting during the validation phase. This fact is evidenced in the high sensitivity standard deviation of the model.

Additionally, we also detail in Table \ref{valtResults_fineTuning} the validation results achieved from the fine-tuned VGG networks, since they provided a considerable outperforming with respect to the rest of state-of-the-art architectures during the ICV stage. Specifically, VGG16 reaches better results for all figures of merit, although both architectures report similar behaviour. In comparison to the CNNs trained from scratch, VGG16 provides the best model performance too. 

\begin{table}[h]
\caption{Results comparison between the best fine-tuned CNNs proposed during the validation phase.}
\label{valtResults_fineTuning}
%\renewcommand{\arraystretch}{1.09}
\setlength\tabcolsep{8 pt}
\small
\begin{center}
\begin{tabular}{cccc}
\hline
\multicolumn{1}{l}{}{} & \textbf{VGG16}       & \textbf{VGG19} \\
\hline
\textbf{SN}         & $\textbf{0.7800}   \pm \textbf{0.1302}$       & $0.7400 \pm 0.1462$ \\
\textbf{SPC}        & $\textbf{0.9677} \pm \textbf{0.0334}$         & $0.9597\pm 0.0283$\\
\textbf{PPV}        & $\textbf{0.9401} \pm  \textbf{0.0643}$      & $0.9180 \pm 0.0602$ \\
\textbf{NPV}        & $\textbf{0.8864} \pm \textbf{0.0662}$        & $0.8670\pm 0.0692$  \\
\textbf{FS}         & $\textbf{0.8466} \pm  \textbf{0.0720}$       & $0.8131\pm 0.0936$   \\
\textbf{ACC}        & $\textbf{0.8984} \pm  \textbf{0.0468}$      & $0.8786 \pm 0.0563$ \\
\textbf{AUC}        & $\textbf{0.9463} \pm  \textbf{0.0339}$     & $0.9416 \pm 0.0501$\\
\hline
\end{tabular}
\end{center}
\end{table}

%After comparing the validation results shown in Table \ref{valRes_fromScratch} and \ref{valtResults_fineTuning}, a significant improvement of the fine-tuned CNNs is demonstrated in relation to the CNNs trained from scratch. This fact evidences that the use of pre-trained architectures is a promising strategy when the amount of images annotated by experts is not enough to train a deep CNN from scratch.

\subsection{Test results}
 
In order to provide reliable results, an independent test set was used to carry out the prediction stage. Table \ref{testResults} shows a comparison between all proposed deep-learning models to evaluate their prediction ability by means of different figures of merit. Additionally, we expose in Fig. \ref{testROCs} the ROC curve relative to each proposed CNN to visualise the differences.

\begin{table}[h]
\caption{Classification results achieved during the prediction stage from the proposed CNNs trained from scratch (FS) and fine-tuning the VGGs network architectures.}
\label{testResults}
%\renewcommand{\arraystretch}{1.1}
%\setlength\tabcolsep{4 pt}
\small
\begin{center}
\begin{tabular}{ccccc}
\hline
\multicolumn{1}{l}{}{} & \textbf{FS without DA}       & \textbf{FS with DA}  & \textbf{VGG16}       & \textbf{VGG19}\\
\hline
\textbf{SN}          & 0.7632           & 0.7895    & \textbf{0.8510}       & \textbf{0.8510}  \\
\textbf{SPC}         & 0.7250           & 0.6750    & 0.9064                & \textbf{0.9688} \\
\textbf{PPV}         & 0.7250           & 0.6977    & 0.8490                & \textbf{0.9444}   \\
\textbf{NPV}         & 0.7632           & 0.7714    & 0.9063                & \textbf{0.9118}   \\
\textbf{FS}          & 0.7436           & 0.7407    & 0.8500                & \textbf{0.8947}    \\
\textbf{ACC}         & 0.7436           & 0.7308     & 0.8846               & \textbf{0.9230}   \\
\textbf{AUC}         & 0.8132           & 0.8230     & 0.9578               & \textbf{0.9594} \\
\hline
\end{tabular}
\end{center}
\end{table}


\begin{figure}[h]
\begin{center}
\includegraphics[height=3cm, width=7.25cm]{Figures/ROCs_test.pdf} \\
\end{center}
\caption{ROC curves corresponding to the prediction results reached from the different proposed CNNs.}
\label{testROCs}
\end{figure}


Test results exposed in Fig. \ref{testResults} are in line with those achieved during the validation phase. However, due to the randomness effect of the data partitioning (which is accentuated in small databases), significant differences may exist in the prediction of each subset. This fact mainly affects to the CNNs trained from scratch because all the weights of the network were trained with the images of a specific subset, whereas the proposed fine-tuned architectures keep most of the weights frozen. Regarding the ROC curves comparison, Fig. \ref{testROCs} shows that fine-tuned CNNs report a significant improvement in relation to the networks trained from scratch.


It is important to remark that an objective comparison with other state-of-the-art studies is difficult because there are no public databases of circumpapillary OCT images. Additionally, each group of researchers addresses glaucoma detection using a different kind of images. Notwithstanding, we detail a subjective comparison with other works based on similar methodologies applied to fundus images. In particular, \cite{gomez2019automatic} fine-tuned the VGG19 architecture and achieved an AUC of 0.94 predicting glaucoma. Also, \cite{christopher2018performance} reached an AUC of 0.91 applying transfer learning techniques to the ResNet architecture. Otherwise, authors in \cite{chen2015glaucoma} proposed a CNN from scratch obtaining AUC values of 0.83 and 0.89 from two independent databases. Basing on this, the proposed learning methodology exceeds the state-of-the-art results, achieving an AUC of 0.96 during the prediction of the test set. 



\BlankLine
\textbf{Class Activation Maps (CAMs)}

We compute the class activation maps to generate heat maps highlighting the interesting regions in which the proposed model is paying attention to determine the class of each specific circumpapillary OCT image. In Fig. \ref{Class_Activation}, we expose the CAMs relative to random specific glaucomatous and normal samples in order to elucidate what is VGG19 taking into account to discern between classes. 


\begin{figure}[h]
\begin{center}
\begin{tabular}{cc}
\includegraphics[height=4.2cm,width=4cm]{Figures/GlaucomaCAMs.pdf} &
\includegraphics[height=4.2cm, width=4cm]{Figures/NormalCAMs.pdf} \\
(a) &
(b) \\
\end{tabular}
\end{center}
\caption{Heat maps extracted from the CAMs computation for (a) glaucomatous and (b) healthy circumpapillary images.}
\label{Class_Activation}
\end{figure}

The findings from the CAMs are directly in line with the reported by expert clinicians, who claim that a thickening of the RNFL is intimately linked with healthy patients, whereas a thinning of the RNFL evidence a glaucomatous case. That is just what heat maps in Fig. \ref{Class_Activation} reveal. Therefore, the results suggest that the proposed circumpapillary OCT-based methodology can provide a great added value for glaucoma diagnosis taking into account that information similar to that of specialists is reported by the model without including any previous clinician knowledge. 


 



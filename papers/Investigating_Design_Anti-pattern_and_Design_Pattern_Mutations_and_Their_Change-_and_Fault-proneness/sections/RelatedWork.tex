\section{Related Work}
\label{sec:Related Works}

\subsection{Design Anti-pattern and Detection}

Webster \etal \cite{webster1995pitfalls} describes design anti-pattern as a solution to a problem that is used frequently but negatively affects software quality. Riel \etal \cite{riel1996object} proposed 61 heuristics of good object-oriented programming that can be used to manually assess a program quality for improving its design and implementation. These heuristics are similar to code smells. Later, Brown \etal \cite{brown1998antipatterns} introduced 40 types of design anti-patterns that form the basis of design anti-patterns detection approaches \cite{van2002java,marinescu2006object,moha2010decor,settas2012enhancing}. 

Several approaches have been proposed to detect design anti-patterns. Van Emden \etal \cite{van2002java} developed JCosmo to visualize the code layout and locate anti-patterns. JCosmo uses primitives and rules to detect design anti-patterns while parsing the source code into an abstract model (similar to the Famix meta-model \cite{tichelaar2000meta}). The goal is to evaluate code quality and help developers to do refactoring. Marinescu \etal \cite{ducasse2004using} combined detection strategies and additional information collected from the documentation of problematic structures in the histories of software systems to improve the detection results.

Settas \etal \cite{settas2012enhancing} proposed Bayesian network-based approach to improve the detection of design anti-patterns. Their approach leverages probabilistic knowledge, which contains the relationships of design anti-patterns regarding their causes, symptoms, and consequences. iPlasma \cite{marinescu2006object} detects design anti-patterns by calculating metrics on C++ or Java source code and by applying some rules that combine the metrics. 

In this paper, we use DECOR to specify and detect design anti-patterns because of its higher detection accuracy \cite{moha2010decor} and wider domain coverage. We present a detailed description of DECOR in Section \ref{ssec:section3.1}. 



\subsection{Design Pattern and Detection}

Design patterns in object-oriented software development and their detection have been well-studied in the past two decades \cite{gamma1995design,kramer1996design}. Kramer \etal \cite{kramer1996design} introduced an approach to detect design information directly from C++ header files. Design patterns are represented as Prolog rules that query this design information. Their approach detects five structural design patterns: Adapter, Bridge, Composite, Decorator, and Proxy. 

Voka\v{c} \etal \cite{vokavc2004defect} proposed an approach scoring the similarity between the graph of a design pattern and the graph of a system to identify classes participating in this design pattern. Iacob \etal \cite{iacob2011design} identified proven solutions for recurring design problems using design workshops and system analysis. During design workshops, teams of 3-5 developers designed systems while considering design issues. Then, they analysed a set of systems to recognize how developers should consider design problems in the implementation of existing solutions. 

In this paper, we use DeMIMA to specify and detect design patterns because of its higher detection accuracy \cite{gueheneuc2008demima}, which is described in Section \ref{ssec:section3.2}. 



\subsection{Design Anti-pattern and Design Pattern Evolution and their Impact}

Several studies investigated both design anti-pattern and design-pattern evolution. Bieman \etal \cite{bieman2003design} claimed that there is a relative stability in classes participating in design patterns compared to other classes. They showed that large classes are more change-prone than other classes. Voka\v{c} \etal \cite{vokavc2004defect} discussed how different design patterns have different impact on fault-proneness. They studied a large C++ industrial system to prove their claim. 
Gatrell \etal \cite{gatrell2009design} demonstrated that pattern-based classes are more change-prone than other classes. Olbrich \etal \cite{olbrich2009evolution} focused on the historical data of Lucene and Xerces over several years and showed that Blob classes and classes subject to Shotgun Surgery are more change-prone than other classes.

Khomh \etal \cite{khomh2012exploratory} investigated the impact of code smells on the change-proneness of classes. They also studied the influence of design anti-patterns on change- and fault-proneness. They considered 13 design anti-patterns in 54 releases of ArgoUML, Eclipse, Mylyn, and Rhino, and analyzed the probability of classes changing to fix a fault. Their results showed that classes participating in design anti-patterns were significantly more likely to be changed than other classes. This study also investigated two types of changes experienced by classes with design anti-patterns: structural and non-structural changes. Structural changes can modify the class interface while non-structural ones change method bodies. They concluded that structural changes were more likely to occur in classes participating in design anti-patterns.

Yamashita and Moonen \cite{yamashita2013developers} reported that developers cannot fully evaluate the overall maintainability of a software system with code smells alone. They argued that different approaches should be combined to achieve complete and accurate evaluations of software maintainability. Taba \etal \cite{taba2013predicting} claimed that information about design anti-patterns improves the accuracy of fault prediction models. Jaafar \etal \cite{jaafar2013analysing} empirically studied the relationships between design anti-patterns and design patterns. They showed that some design anti-patterns have relationships with design patterns while others do not.
\section{Methodology}
\label{sec:Methodology}

We now describe the general methodology of our study, shown in Figure \ref{fig:FigureMethod}, which includes the main steps of design (anti-)pattern detection, classification of change types, building Markov models, and detection of faulty classes.

We first extract the source code of the studied systems in snapshots taken every 500 commits in their Git repositories. Then, we detect design anti-patterns and design patterns in all the snapshots of the systems. We then create Markov models based on the detected design anti-patterns and design patterns to analyze their behaviors during evolution. We also identify change types and faulty classes throughout the period of evolution that we analyzed. We study all the changed types that lead to fault(s) during evolution. We explain each step in details in the following sub-sections.

\begin{figure}[ht]
\centering
\includegraphics[scale=0.35]{Images/StudyDesign.pdf}
\caption{Schematic diagram of the methodological steps of the study}
\label{fig:FigureMethod}
\end{figure}



\subsection{Detecting Anti-patterns}
\label{ssec:section3.1}

We use Defect DEtection for CORection Approach (DECOR) \cite{moha2010decor} to detect occurrences of design anti-patterns. DECOR offers a domain-specific language to automatically generate design-defect detection algorithms, including design anti-patterns. DECOR uses the Patterns and Abstract-level Description Language meta-model (PADL) \cite{gueheneuc2008demima} and the Primitive, Operators, and Metrics framework (POM) \cite{gueheneuc2004fingerprinting} to detect design anti-patterns in object-oriented systems. The output of DECOR is a list of classes and their roles (if any) in occurrences of design anti-patterns. Moha \etal \cite{moha2010decor} reported that DECOR achieves 100$\%$ recall while having 31$\%$ precision rate in the worst case with an average greater than 60$\%$.

A domain-specific language is more flexible than ad hoc algorithms \cite{moha2010decor} because domain experts (\ie{} developers) can modify the detection rules manually using high-level abstractions, considering the contexts, environments, and characteristics of the analyzed systems. PADL \cite{gueheneuc2008demima} is a meta-model to describe object-oriented systems at different abstraction levels while POM \cite{gueheneuc2004fingerprinting} is a PADL-based framework that implements more than 60 metrics.



\subsection{Detecting Design patterns}
\label{ssec:section3.2}

We use the Design Motif Identification Multilayered Approach (DeMIMA) \cite{gueheneuc2008demima} to detect occurrences of design patterns. DeMIMA traces design motifs (the micro-architecture describing the solutions of the design patterns) in the source code. It discovers idioms relevant to binary class relationships and then provide an idiomatic model of the source code. The model helps to identify design motifs to create a design model of the system. DeMIMA can recover idioms related to both the relationships among classes and design motifs.

DeMIMA uses explanation-based constraint programming to identify occurrences of design motifs using the roles and relationships describing the motifs in PADL models of systems. It reports the micro-architectures that are occurrences of the motifs, including approximations of the motifs. The output of DeMIMA is a list of classes and their roles (if any) in the  occurrences of design patterns. Gu\'{e}h\'{e}neuc and Antoniol \cite{gueheneuc2008demima} report that DeMIMA achieves 100$\%$ recall and 34$\%$ precision.



\subsection{Building Mutation Model}
\label{ssec:section3.4}

We build a Markov model \cite{meyn2012markov} for each studied system to show the mutations between design anti-patterns and design patterns during evolution. For each system, we consider all the patterns whose occurrences we found in its snapshots as nodes in its Markov model. A Markov model shows the set of all possible mutations for one pattern during the evolution of the system. 

First, we obtain two files from two consecutive snapshots of a system, $C_0$ and $C_1$, which contain all the occurrences of design patterns and design anti-patterns in each class of each snapshot. Then, the Markov transition matrix of these two files is a square matrix describing the probabilities of one design anti-pattern and--or design pattern mutating into another. Each row contain the probabilities of mutating from one pattern to all the others. Second, we compare the next two snapshots, $C_1$ and $C_2$, and repeat this algorithm up to snapshots $C_{n-1}$ and $C_n$. Then, we sum up all the mutation probabilities for one given pattern into all the others. We report the averaged summed mutation probabilities divided by the total number of each row. The sum of all the probabilities from any pattern to the others is equal to one. 

\begin{figure*}
\begin{center}
\scalebox{0.8}{
\begin{tikzpicture}[->, >=stealth', auto, semithick, node distance=2.5cm]
\tikzstyle{every state}=[fill=white,draw=black,thick,text=black,scale=1]
\node[state]    (A)                     {$Bu$};
%\node[state]    (B)[above right of=A]   {$AS$};
%\node[state]    (C)[above left of=B]    {$Bl$};
%\node[state]    (D)[left of=C]          {$CS$};
%\node[state]    (E)[below right of=A]   {$CC$};
%\node[state]    (F)[below left of=E]    {$LC$};
%\node[state]    (G)[below right of=B]   {$LZC$};
%\node[state]    (H)[below right of =G]  {$LM$};
\node[state]    (H)[below right of =A]  {$LM$};
%\node[state]    (R)[below right of =H]  {$LP$};
%\node[state]    (I)[below left of=H]    {$MCh$};
%\node[state]    (J)[above right of=B]   {$RP$};
%\node[state]    (K)[above right of=G]   {$SC$};
%\node[state]    (L)[above of=B]         {$SG$};
%\node[state]    (M)[below right of=K]   {$SA$};
%\node[state]    (N)[below left of=D]    {$Bu$};
%\node[state]    (O)[below left of=N]    {$Source$};
%\node[state]    (P)[below right of=O]   {$Cm$};
\node[state]    (P)[above right of=A]   {$Cm$};
%\node[state]    (Q)[below left of=P]   {$Cp$};
\node[state]    (Q)[below left of=A]   {$Cp$};
%\node[state]    (R)[below left of=A]    {$FM$};
%\node[state]    (S)[above right of=K]   {$Sink$};
\node[state]    (S)[above left of=A]   {$Sink$};
%\node[state]	(V)[right of=O]	        {$De$};
\node[state]	(V)[left of=A]	        {$De$};
%\node[state]    (U)[below right of=N]   {$Ob$};
%\node[state]    (Y)[above right of=O]   {$PT$};
%\node[state]    (Z)[above left of=O]    {$Si$};


\path
(A) edge[loop right]     node{$0.665$}   (A)
edge        node{$0.003$}       (H)
edge         node{$0.042$}      (P)
edge       node{$0.169$}        (Q)
edge        node{$0.076$}       (V)
edge         node{$0.042$}      (S);

\end{tikzpicture}
}
\caption{Builder (Bu) mutation among the different revisions of Matsim.}
\label{Figure:Bu-Mutations-Matsim2}
\end{center}
\end{figure*}

For an example, Figure \ref{Figure:Bu-Mutations-Matsim2} shows a Markov model whose nodes are design anti-patterns and design patterns and edges represent mutations from one pattern to another. Edges are labeled with the probabilities of the mutation from the source patterns to its mutated patterns. This Markov model shows the mutations of the Builder design pattern across the snapshots of Matsim.



\subsection{Analyzing Fault-proneness} \label{ssec:section3.5}

We use the SZZ algorithm \cite{sliwerski2005changes} to identify commits that introduce faults in the systems, \ie{} fault-inducing commits, and thus faulty classes in the system snapshots. For each system, we first apply heuristics \cite{fischer2003populating} to link commits to faults. We use regular expressions to detect fault-IDs in the commit logs. Developers use different conventions for these IDs in their systems so, to ensure accuracy, we tune our heuristics on our dataset incrementally and manually. 

Given a fault $F$ in a system, we extract from its history the files that fixed the fault (fault-fixing files) using \texttt{git diff}. Then, we retrieve the modified and deleted lines from the fault-fixing files. The SZZ algorithm assumes that prior commits that modified these lines are fault-inducing commits. 

To identify such prior commits, for each fault-fixing files, we apply \texttt{git blame} to retrieve a list of previous commits that modified these files. We filter commits whose submission date is later than the fault creation date. We consider the remaining commits as inducing the fault $B$. 

For any $F$, the SZZ algorithm returns a list of commit IDs and fault-inducing files pertaining to $F$. We then use regular expressions to map the object-oriented classes composing the systems with the fault-inducing files.



\subsection{Identifying Change Types}
\label{ssec:section3.6}

Different types of changes can affect software systems with different impacts on fault-proneness. For example, changes to comments are less likely to lead to faults than changes to method invocations. Table \ref{tab:Change_types} shows the change types that we consider, which were also considered in a previous work \cite{an2015empirical}.

\begin{table*}[ht]   
\caption{Change types identified from the source code of the systems studied}
\label{tab:Change_types}
\begin{center}
\scalebox{0.9}{
\begin{tabular}{|l|p{8cm}|} 
\hline
\textbf{Change type} & \textbf{srcML tag(s)}\\  
\hline
	Access & \emph{super, public, private, protected, extern} \\ \hline
 	Class & \emph{extends, class, interface, implements, class\_decl} \\ \hline
   	Code block & \emph{expr\_stmt, expr, block} \\ \hline
  	Comment & \emph{annonation, comment, @type, @format} \\ \hline
  	Control flow & \emph{while, do, if, else, elseif, break, goto, for, foreach, control, continue, then, switch, case, return, incr, default, condition} \\ \hline
 	Declaration & \emph{decl\_stmt, modifier, specifier, decl, function\_decl, literal, label, empty\_stmt, construction\_decl, annonation\_dfn} \\ \hline
 	Exception & \emph{assert, try, catch, throw, throws, finally} \\ \hline
	Import & \emph{import, package} \\ \hline
	Invocation &  \emph{call}\\ \hline
	Method &  \emph{constructor, default, static, type, lambda, function, function\_decl, unit}\\ \hline
	Operator &  \emph{index, synchronized, enum, operator, ternary} \\ \hline
  	Parameter &  \emph{argument, param, parameter\_list, argument\_list, parameter} \\ \hline
    Renaming &  \emph{renaming, name} \\ \hline
\end{tabular}
}
\end{center}
\end{table*} 

We use srcML \cite{srcml} to transform each file in the snapshots of a system into an XML document, in which code elements are tagged by type or function, \eg{} a class declaration, a parameter list, or a control flow statement. Then, we compare the srcML tags between each two subsequent snapshots and extract their differences. The removed tags from the older snapshot and the added tags in the newer snapshot are \emph{changed tags}. We manually group the unique changed tags into a series of \emph{change types}. Table \ref{tab:Change_types} shows the change types and their corresponding srcML (changed) tags. We group some change types together, which have similar impacts on source code. Changes in a same group are likely to have similar impacts on fault-proneness. 

For a given file $F$, in a specific snapshot $S$, our approach yields a list of change types listed in Table \ref{tab:Change_types}. Because we study design (anti-)patterns from commits; in each selected snapshots, we aggregate the change types related to $F$ in the commits \{$C_1$, $C_2$, ..., $C_n$\}, which form that snapshot. 

\subsection{Dataset extraction and approval}

The dataset used in this paper contains a total of 2905 echocardiogram studies\footnote{Our released TMED dataset contains 2773 studies, each guaranteed to be from a distinct patient. The experiments here use a slightly larger dataset including multiple studies from the same patient. We have ensured each patient in the released data has exactly one study for simplicity.}. 
We use transthoracic echocardiogram (TTE) imagery acquired in the course of routine care consistent with American Society of Echocardiography (ASE)   guidelines~\citep{mitchellGuidelinesPerformingComprehensive2019}.
Each patient study contains multiple cineloop video clips of the heart depicting various anatomical views.
To collect this imagery, a sonographer manipulates a handheld transducer over the patient's chest, manually choosing different acquisition angles in order to fully assess the heart’s complex anatomy.
For this study we focus on still images extracted from all available video clips.
While pulsed-wave Doppler (PW), continuous-wave Doppler (CW), and m-mode recordings are also available, we leave these for future work.


The echocardiograms originate from the last 5 years of records at Tufts Medical Center, a high-volume tertiary care center in Boston, MA.
Echocardiograms are generally performed to assess for structural heart disease. These studies are done for a variety of reasons, from evaluating symptoms (e.g. chest pain, shortness of breath), to caring for a patient experiencing a cardiac event (e.g. myocardial infarction or acute heart failure), to providing follow up care for a known condition (e.g. aortic stenosis or cardiomyopathy). Studies were sampled from archived image folders that were organized by month of acquisition.

The use of these \emph{deidentified} images for research has been approved by our Institutional Review Board (Tufts IRB \#MODCR-03-12678).
All images were acquired from The Cardiovascular Imaging \& Hemodynamic Laboratory, part of the Tufts CardioVascular Imaging Center. 
This lab is Intersocietal Accreditation Commission (IAC) accredited and performs roughly 10,000 ultrasound examinations per year using devices from major vendors (Philips®, Toshiba®, Siemens®).
By using standardized image formats, the released data and subsequent ML methods are intended to be vendor-independent. 
%All echocardiograms are linked to the patient's available electronic medical record (EMR).

\subsection{Image preprocessing.}
\label{sec:image_preprocessing}
Each study's raw imaging data contains multiple cineloop videos.
Typically there are around 100 - 200 videos per study.
From each cineloop file, we take one image to analyze.
Clinical collaborators suggested that any single frame could be used; in practice we took the first frame of each video.
The resulting data contains both color images and gray scale images with various resolutions. To prepare for neural network training, we convert each image to gray-scale, pad along its shorter axis to achieve a square aspect ratio, and then resize the image to 64x64 pixels. We filtered out Doppler recordings completely using aspect ratio since Doppler recordings have distinct aspect ratios. More data processing details are available in App.~\ref{sec:removing_doppler}.  
% We filtered out Doppler recordings completely, keeping only the video clips that had aspect ratio between \todo{FILL: XxY and ZxA}.


\subsection{Annotating each study with view and diagnostic labels}

As part of routine clinical care, there are no annotations applied to individual cineloops or still images for either view or diagnosis when imaging is collected.
Instead, images for a given study are reviewed in aggregate by an echocardiography-board-certified cardiologist to create a summary report that is merged into the electronic medical record.
This report contains diagnostic labels, including the presence or absence of AS and also the grade of AS, reliably collected for most patients.
All complete study reports produced in routine care have an assigned grade of aortic stenosis (range: no AS to severe AS).

However, while the diagnostic AS grade is available for all studies for which an expert reader has prepared a summary report, as implemented in our institution's current system it requires substantial manual effort to extract this label from the report into a form amenable to machine learning.
Furthermore, view labels are not available for any of the imagery we use.
Below, we detail how we obtain suitable annotations for a subset of patient-studies, which we call the \emph{labeled} set.
For the remaining studies in the \emph{unlabeled} set, we have only images: no view or diagnostic labels are easily available.

\paragraph{Diagnostic labels of AS disease severity.}
For this investigation, we were able to extract the AS grade from the relevant summary report in the EMR for a subset of all studies. We refer to this subset as the labeled set.
Each labeled patient in our study thus has an ordinal class label indicating one of 3 possible levels of severity: ``no AS'', ``mild/moderate AS'' and ``severe AS''. 
%We extracted these labels from the relevant summary report in the EMR.
These patient-level diagnostic labels were assigned in standard fashion during routine care, integrating information across all available views for a given patient by a cardiologist with specialty training in echocardiography. 

We chose a 3-level granularity\footnote{
The raw data contains 5-level labels (our ``mild/moderate AS'' category can be further distinguished into ``mild'', ``mild to moderate'' and ``moderate''). We leave these finer-grained levels to future work.
} for AS severity classification -- no AS, mild/moderate AS, and severe AS --
as a good balance between simplicity and clinical utility.
In Supplement Fig. \ref{fig:PatientSevereAS} and Fig. \ref{fig:PatientNoAS}, we show example images from a patient with severe AS and a patient without AS; distinguishing these two categories is difficult to an untrained eye.



\paragraph{View labels.}
Because view labels were not available for any imagery, we undertook a significant post-hoc annotation effort.
We used a novel view labeling tool that displays a grid of multiple study images and facilitates rapid expert annotation. 
A board certified cardiologist provided all view label annotations.
Our expert annotator provided a view label for each image in our labeled set, selecting one of 3 possible labels: parasternal long axis (PLAX), parasternal short axis (PSAX) and a final category (Other) indicating all other possible view types that are not PLAX or PSAX.
We chose to focus on PLAX and PSAX view labels because the aortic valve's structure and function is visible. PLAX and PSAX views are used in the routine clinical assessment of aortic valve disease.
Fig.~\ref{fig:VIEW_SAMPLES_MAIN} shows examples of each view type; more samples can be found in Supplement Fig.~\ref{fig:VIEW_SAMPLES_APPENDIX}.


\paragraph{Summary of available labeled and unlabeled data.}
Out of all 2905 studies,
260 studies were assigned both view and diagnosis labels; 174 additional studies were assigned diagnosis but not view labels (while still difficult to automate in our current system, extracting a diagnosis severity label is easier than assigning a view label). The remaining 2471 studies are \emph{truly unlabeled}, with neither diagnosis nor view annotations available.

This data is further processed into two versions for standardized evaluation of SSL classification. The full-size version -- \datasetName-156-52 -- is described in Sec.~\ref{sec:data_full} and smaller version -- \datasetName-18-18 -- in Sec.~\ref{sec:data_small}.

%\subsection{Data Preparation for Semi-supervised Learning}

%\paragraph{Creation of common labeled and unlabeled sets for SSL.}
%In order to evaluate semi-supervised learning methods for both view and diagnosis tasks on a common dataset, we treat the 260 studies with \emph{both} diagnosis labels and view labels as the \emph{labeled set}. This labeled set is further divided into training, validation, and test sets.
%
%2471 studies are \emph{truly unlabeled}, with neither diagnosis nor view labels available. 
%A further 174 studies have only the diagnosis labels but not the view labels.
%We included these 174 in the unlabeled set for all SSL methods by ignoring their labels, yielding a total unlabeled set of 2645 patient-studies.
%These 174 studies with diagnosis labels are later also used as a \emph{bonus heldout set} to see if the rankings of methods on the original test sets are repeatable.

%% FUTURE WORK IDEA
% 1. Align before mixing images.
% 2. For diagnosis, in the future, directly do patient level training instead of image level diagnosis classifier}

\subsection{Full dataset with authentic unlabeled examples: \datasetName-156-52.}
\label{sec:data_full}

The full-size dataset used in this investigation consists of a \emph{labeled set} of all 260 fully-labeled patient studies (both view and diagnosis labels), as well as a much larger \emph{unlabeled set}. We review the design of each labeled and unlabeled set below.
All methods using the labeled set have access to diagnosis labels for each patient and view labels for each image in that set. No such labels are available in the unlabeled set.

\paragraph{Labeled train/valid/test sets.}
To evaluate the performance of classifiers on heldout data, we divide the labeled set of 260 patients using a 3:1:1 ratio into a labeled train set of 156 patients and evaluation sets (validation and test) of 52 patients each.
We call our full-size dataset the \datasetName-156-52 dataset, so that the true number of patients used for training and evaluation is apparent.
We repeat this partitioning 4 separate times, resulting in 4 independently-chosen train/valid/test sets, with summary counts in Table \ref{tab:patient_counts_large}. 

\paragraph{Unlabeled set.}
To build the full-size unlabeled set used to train semi-supervised methods, we combine the 2471 truly unlabeled patient-studies together with the 174 patient-studies that only have diagnosis labels (we discard any labels and treat them as unlabeled).
This results in a combined full-size unlabeled set with data from 2645 total patients. We have $\sim18x$ more unlabeled images than we have labeled training images.

\paragraph{Bonus heldout set for diagnosis.}
Because our available fully-labeled data is limited, to further assess diagnosis classifiers, we use the 174 studies with diagnosis labels as a \emph{bonus heldout set}. This use lets us evaluate if the rankings of methods on the original labeled test sets (52 patients) are repeatable in the larger 174 patient corpus.



\subsection{Smaller dataset: \datasetName-18-18.}
\label{sec:data_small}

Our full-size dataset described above contains labeled data from hundreds of patients. To simulate the practical scenario where we have access to only a few dozen labeled patient studies (e.g. in early prototyping of a medical imaging ML pipeline), we also perform experiments comparing SSL methods on a \emph{smaller} version of our dataset, where both labeled and unlabeled sets are significantly smaller than the full-size data described above.
Because it is easier to train methods on smaller datasets, this smaller version also allows us to evaluate many more methods on a fixed computational budget than our full-size dataset.




\paragraph{Labeled train/valid/test sets for smaller version.}
We select 54 patients to comprise the smaller labeled set, from the entire full labeled dataset of 260 patients.
Within the selected labeled set, we do a 1:1:1 train/validation/test split, favoring larger heldout size ratios here than in the full-size dataset to be sure we can assess real differences between models.
Thus, the \emph{labeled training set} contains data from 18 patients and each \emph{labeled heldout set} (validation and test) contains data from 18 patients (each patient's data is exclusively used for either training, validation, or test).
We call our smaller dataset the \datasetName-18-18 dataset (again to signify that 18 patient studies are available for training, and 18 for evaluation).
We repeat this partitioning 3 times, resulting in 3 independently-chosen train/valid/test partitions that balance the frequencies of each view and diagnostic label.
Summaries of each label's frequency are shown in Table~\ref{tab:image_counts_small}.

\paragraph{Unlabeled set for smaller version.}
To build the unlabeled set for \datasetName-18-18, we combine the remaining 206 patients from the full-size labeled set with the 174 patients that only have diagnosis labels.
Together, these 380 patients form the unlabeled set; even though we technically have labels for these studies, they are not used at all in training or evaluation.
In \datasetName-18-18, our unlabeled set has $\sim21x$ more images than the labeled train set.


%The resulting final data split contains 18 patients in labeled training set, 380 patients in unlabeled set, 18 patients in validation set and 18 patients in test set.


\begin{table}[!t]
    \centering
    {\small %                                   <------ BEGIN SMALL FONT
    \begin{tabular}{l|r|rrr|r|rrr}
		& \multicolumn{4}{c}{Num. Patients}
		& \multicolumn{4}{c}{Num. Images}
	\\
    \textit{By Diagnosis}
    	& Total
    	& No AS  & Mild/Mod. & Severe    	
    	& Total
    	& No AS  & Mild/Mod. & Severe \\
    \hline
    Train (labeled) 
		& 18 & 6 & 6 & 6
    	& 1805, 1935
    	& 542, 635 & 634, 700 & 583, 647
	\\
    Valid. (labeled) 
    	& 18 & 6 & 6 & 6
    	& 1833, 2018
    	& 520, 663 & 586, 723 & 652, 704 
    \\
    Test (labeled) 
		& 18 & 6 & 6 & 6
    	& 1834, 1957
    	& 561 609 & 577, 668 & 691, 728
	\\ \hline
    \textit{By View}
		& & & &
    	& Total
    	& PLAX  & PSAX & Other
    \\ \hline
    Train (labeled) 
		& & & &
    	& 1805, 1935
    	& 208, 222 & 58, 72 & 1520, 1650
    \\
    Valid. (labeled) 
		& & & &
    	& 1833, 2018
    	& 212, 221 & 70, 81 & 1542, 1716
	\\
    Test (labeled) 
		& & & &
    	& 1834, 1957
    	& 215, 233 & 66, 77 & 1549, 1674
    \\
	\hline
    Unlabeled Train 
		& 380 & &  &
    	& 41183, 41428
    \end{tabular}
    }%                                         <------ END SMALL FONT
    \caption{\textbf{Smaller \datasetName-18-18 dataset} summary, showing patient (left) and image (right) counts by diagnosis (top) and view (bottom).
    We use 3 different train/valid./test splits of the labeled set, all with same patient counts by diagnosis. To count images, we report (min., max.) values across splits.
    }%endcaption
    \label{tab:patient_counts_small}
    \label{tab:image_counts_small}
% MCH merged these tables to allow easy reader side-by-side comparison
%\end{table}       
%\begin{table}[!h]
%    \centering
\bigskip
    {\small %                                   <------ BEGIN SMALL FONT
    \begin{tabular}{l|r|rrr|r|rrr}
		& \multicolumn{4}{c|}{Num. Patients}
		& \multicolumn{4}{c}{Num. Images}
	\\
    \textit{Diagnosis}
    	& Total
    	& No AS  & Mild/Mod. & Severe    	
    	& Total
    	& No AS  & Mild/Mod. & Severe \\
    \hline
    Train
        & 156 & 49 & 47 & 60
    	& 16463, 16852
    	& 4681, 4801 & 5072, 5102 & 6589, 7076
    \\
    Valid.
	    & 52 & 16 & 16 & 20
    	& 5470, 5617
    	& 1458, 1544 & 1769, 1859 & 2153, 2330
    \\
    Test
	    & 52 & 16 & 16 & 20
    	& 5377, 5855
    	& 1542, 1636 & 1781, 1901 & 1931, 2443
	%\\
    %unlabeled &  &  &  & [41411, 41656]
	\\ \hline
    \textit{View}
		& & & &
    	& Total
    	& PLAX  & PSAX & Other
    \\ \hline
    Train
		& & & &
    	& 16463, 16852
    	& 1883, 1918 & 595, 672 & 13908, 14297
    \\
    Valid.
		&  & &  &
    	& 5470, 5617
    	& 639, 652 & 184, 221 & 4644, 4749
	\\
    Test
		& & & &
    	& 5377, 5855
    	& 624, 646 & 172, 212 & 4559, 5027
    \\
    \hline
    Unlabeled & 2645 &  &  &  & 303498
    \end{tabular}
    }%                                         <------ END SMALL FONT
    \caption{\textbf{Full-size \datasetName-152-52 dataset} summary, showing patient (left) and image (right) counts by diagnosis (top) and view (bottom).
    We use 4 different train/valid/test splits of the labeled set, all with same patient counts by diagnosis. To count images, we report (min., max.) across splits.
    }    
    \label{tab:image_counts_large}
	\label{tab:patient_counts_large}
\end{table}


% DEPRECATED: merged with image counts into one table
%\begin{table}[!t]
%    \centering
%    \begin{tabular}{l|r|rrr}
%    & Total Patients & No AS  & Mild/Moderate AS & Severe AS \\
%    \hline \hline
%    Train (labeled) & 18 & 6 & 6 & 6 \\
%    Validation (labeled) & 18 & 6 & 6 & 6 \\
%    Test (labeled) & 18 & 6 & 6 & 6 \\
%    Unlabeled Train & 380 & &  &  
%    \end{tabular}
%    \caption{Patient counts in \textbf{\datasetName-18-18 small dataset} across splits by diagnosis. There is \emph{no patient overlap} between the train, validation and test set. We analyze \emph{3 independent folds} with these statistics, each drawn at random.}
%    \label{tab:patient_counts_small}
%\end{table}

% DEPRECATED
%\begin{table}[!t]
%    \centering
%    \begin{tabular}{l|r|rrr}
%    & Total Patients & No AS  & Mild/Moderate AS & Severe AS \\
%    \hline \hline
%    Train (labeled) & 156 & 49 & 47 & 60\\
%    Validation (labeled) & 52 & 16 & 16 & 20\\
%    Test (labeled) & 52 & 16 & 16 & 20 \\
%    Unlabeled Train & 2645 &  &  &
%    \end{tabular}
%\caption{Patient counts in \textbf{EchoForAS-156-52 full-size dataset} for SSL. There is \emph{no patient overlap} between the train, validation and test set.  We analyze \emph{4 independent folds} with these statistics, each drawn at random (each labeled patient will be assigned to either train, valid, or test in each fold; the set of unlabeled patients is always the same across folds).
%}%endcaption
%\label{tab:patient_counts_large}
%\end{table}


The challenges of automating traceability have been well documented over the past two decades \cite{traceability_vsm,cm1,DBLP:books/daglib/p/LuciaMOP12,rath2018traceability}; however, achieving satisfactory degrees of accuracy across diverse datasets has been an ongoing challenge \cite{DBLP:conf/icse/Cleland-HuangGHMZ14,traceability_nn} that has inhibited its adoption in industry. The release of the Google's BERT model \cite{BERT} in 2018 introduced new possibilities for the field, transforming the once far off dream of automatic traceability into a reality for projects in common domains  \cite{bert_pl,bert_nl}. However, despite these improvements,  challenges such as highly-technical domain-specific terminology, low data availability for training, and lack of interpretability meant that automated tracing continued to under-perform in many projects and domains where trace links were still delivered at low degrees of accuracy \cite{MARO201885, DBLP:journals/computer/Cleland-HuangBCSR07}. In the present day, large language models (LLMs), such as GPT3 and Claude \cite{gpt3, claude}, offer the promise of further transformation in automated traceability, eliminating many of these problems and introducing new possibilities for the field. However, as of yet, there is no clear direction on how best to utilize LLMs for automated traceability. 

When we began the work for this paper, our initial aspiration was to discover the ``silver bullet'' prompt for automated traceability. Similar to previous approaches \cite{traceability_vsm, bert_nl, bert_pl}, the ``silver bullet'' would discern true candidate links from false ones across all projects and circumstances. While we identified a prompting approach that performed well across multiple projects, we concluded that the optimal prompting strategy depends on factors like available resources, the model being used, and the targeted usage scenario. Different LLMs exhibit distinct strengths and weaknesses and may require different prompts to achieve desired outcomes on the same data sets; compounding this, variance across versions of the same base model can alter performance on the same task \cite{chen_how_2023}. Moreover, top-performing models can be cost-prohibitive to many engineers and researchers. Despite LLMsâ€™ capabilities, high variability persists across projects, prompts, and parameters. 

Therefore, by bringing attention to some of the obstacles we encountered while crafting out prompts, we hope to make researchers and practitioners aware of potential pitfalls when employing the models for traceability related tasks. Rather than merely showcase top results, we have chosen to elaborate on the process we followed to construct our prompts with the goal of inspiring other engineers who may wish to identify a prompt that best suits their needs.

In this paper, we seek to shed light on the following questions:
\begin{enumerate}
    \item Do LLMs possess knowledge necessary for tracing projects with technical domain-specific vocabularly?
    \item Can LLMs provide reasonable explanations for their decisions?
    \item If so, can these explanations be utilized to improve prompts?
    % \item How can different prompts be utilized for different goals?
    \item Can reasoning be used to improve responses?
    \item How can LLMs be leveraged to generate software traceability links?
    % \item What considerations need to be made when generating candidate links using LLMs?
\end{enumerate}

While much future work is needed in this area, we hope to aid future researchers and engineers by highlighting the process of constructing traceability prompts for leveraging LLMs effectively to advance automatic traceability. 
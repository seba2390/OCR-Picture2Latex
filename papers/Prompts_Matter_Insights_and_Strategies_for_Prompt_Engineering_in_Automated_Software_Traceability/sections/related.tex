Effective automated software traceability has many benefits for software engineering, and several approaches have therefore been proposed to address its challenges. In recent years, the emergence of LLMs, such as GPT-3 and Claude, has shown promise for automating software traceability and mitigating the limitations of previous methods. In this section, we discuss the relevant works that have explored the use of large language models and the subjectivity of trace establishment in the context of software traceability.

Early work in automated traceability relied on classical natural language processing (NLP) techniques such as the vector space model (VSM) and latent semantic indexing (LSI) to establish traceability links between software artifacts based on their textual similarity \cite{traceability_vsm, traceability_lsi}. In the 2010s, deep learning techniques such as long short-term memory networks (LSTMs) and gated recurrent units (GRUs) were applied to improve traceability performance. Researchers used these neural networks to learn distributed representations of software artifacts and match them based on semantic similarity \cite{traceability_nn}. Around 2018, pretrained language models and transformers revolutionized the field. Models like Google's BERT allowed researchers to generate contextualized embeddings of software artifacts and achieve state-of-the-art results in automated traceability tasks \cite{bert_pl, bert_nl}. Transformer language models then grew exponentially larger and more powerful, culminating in GPT-3 and models with hundreds of billions of parameters. GPT-3 demonstrated human-level language understanding with 175 billion parameters, achieving startling fluency and few-shot learning capabilities\cite{gpt2, gpt3, palm}. GPT-4 continues to push the limits of LLMs, scoring in the top 10\% of the BAR exam \cite{gpt4}.

In the domain of software engineering, efforts have been made to leverage large language models for various software engineering tasks including code generation, summarization, and enhancement \cite{DBLP:journals/corr/abs-2107-03374, Sridhara_G_Mazumdar_2023}. Although prompt-engineering is a relatively new area of exploration, some prior work has been done on how best to instruct models for various tasks. Researchers have identified different prompt patterns and techniques that tend to produce the best results - many of which are employed in this paper \cite{white_prompt_2023, ekin_prompt_2023}. Additionally, prompt engineers have crafted prompts for a variety of tasks, including classification \cite{mayer_prompt_2023, han_ptr_2021} and ranking \cite{qin_large_2023}, both of which we utilize in this paper.


However, there has not been extensive evaluation of the potential for large language models in automated software traceability. To address this gap, we conducted a preliminary investigation using Claude, an LLM developed by Anthropic, to predict trace links between software artifacts. We outlined our two approaches for trace link prediction: classification and ranking. The evaluation of our approaches will be discussed in the following section.
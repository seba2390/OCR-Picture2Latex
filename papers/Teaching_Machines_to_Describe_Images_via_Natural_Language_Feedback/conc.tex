
\vspace{-3mm}
\section{Conclusion}
\label{sec:conc}
\vspace{-2mm}

%In this paper, we bring a human in the loop to  facilitate the learning process of an image captioning model. 
In this paper, we enable a human teacher to provide feedback to the learning agent in the form of natural language. We focused on the problem of image captioning. 
We proposed a hierarchical phrase-based RNN as our captioning model, which allowed natural integration with human feedback. We crowd-sourced feedback for a snapshot of our model, and showed how to incorporate it in Policy Gradient optimization. We showed  that by exploiting descriptive feedback our model learns to perform better than when given independently written captions. %In the future, we aim to explicitly deal with the annotator 

%There are several exciting avenues for future work. In particular, when dealing with crowd-sourced human reward one needs to take into account annotator noise. We further plan to explore self-criticism, where the agent automatically decides when to seek human advice, possibly in a dialog-like setting. 

\vspace{-3mm}
\section*{Acknowledgment}
\vspace{-3mm}
\begin{small}
We gratefully acknowledge the support from NVIDIA for their donation of the GPUs used for this research. This work was partially  supported by NSERC. We also thank Relu Patrascu for infrastructure support. \end{small}


\section{Putting Systemization Into Practice}
\label{sec:themes}

Our systemization shows that to support the next generation of secure computing we must integrate knowledge across software, hardware, and security.
To do this, we need systematic rules of thumb to guide effective integration into the codesign process.
This section highlights several opportunities and focus areas to facilitate putting software-hardware-security codesign into practice.

\subsection{Security as a First-Order Design Principle}
Security is often treated as an afterthought in the software and hardware design process.
The Spectre~\cite{spectre} and Meltdown~\cite{meltdown} vulnerabilities exemplified the consequences of optimizing for performance first and fixing security issues in hardware afterwards.
The interconnected design considerations again make it more clear that security needs to become a first class constraint in design methodologies.
Understanding how software, hardware, and security interact is the first step towards unifying security to design methodologies.
This systemization provides the insights that can be translated into systematic rules of thumb to effectively guide the codesign process.
In other words, rules of thumb for security design considerations and their implications must be communicated to software and hardware experts that provide reasonable actionable steps when building a system.

There is already precedence in the hardware-software codesign space towards establishing systematic rules to guide codesign opportunities.
For instance, hardware designers often propagate design guidance to software designers that integer computation is preferred over floating point because it is more power and area efficient.
Thus, a good rule of thumb for software designers who are not aware of the underlying hardware implementation is to use integer math whenever possible.
Similar rules of thumb to guide hardware and software designers towards security-friendly designs are necessary to both establish this abstraction boundary and integrate security as a first class design consideration.

Our systemization study reveals that each technology needs to communicate unique design constraints and implementation challenges to the hardware and software.
For example, for TEEs and enclaves, a designer should minimize the amount of data transferred into and out of the enclave boundary in the application design to reduce the performance overhead.
For homomorphic encryption, an application designer should choose applications which are more amenable to vectorization and have limited control flow to minimize noise budget requirements.
For DP, selecting the right privacy budget to ensure that both application behaviors and any correlated information leakages at lower levels of the stack are sufficiently hidden.
Providing these succinct systematic guidelines between software, hardware, and security allows designers to translate the insights in one domain and effectively apply them to optimize design constraints in another.
More importantly, it provides understandable design rules of thumb to guide cross-stack optimization.

\subsection{Expose Usable Abstractions for Effective Codesign Interactions}

The second key theme that our study exposes is the trend towards interfacing primitives between software, hardware, and security.
In order to either automate or make the knowledge transfer between domains efficient, we need to provide a well-established vocabulary at the interface to collaborate effectively.
This is similar to how the instruction set architecture establishes a contract between what the software sees and what the hardware implements in modern architectures and accelerators (a hardware accelerator is essentially one large instruction).
The abstraction also serves as an interface between disciplines that allow experts in disparate fields to better communicate the challenges and systematic guidance towards co-optimizing solutions.

In the context of software-hardware-security codesign, a similar contract between security and software, and security and hardware remains an open question.
For some technologies, these abstraction boundaries and the primitives to leverage them are quickly maturing.
For instance, in DP, work in programming languages exposes a type system interface that guarantees DP of an application if properly leveraged and implemented against the API.
Work in verification and static analysis~\cite{near2019duet} augments this interface by providing a way for the application to verify that the DP security guarantees are properly implemented for the application.

Similarly, for secure enclave implementations like SGX, the security mechanism exposes an instruction set extension to provide the application developer an interface to leverage the security mechanisms provided by the enclave.
Homomorphic encryption also has a similar abstraction interface where a limited SIMD instruction set provides an interface for the application to reconcile constraints against the technology; there are several early proposals to provide compiler support to make the technology more accessible to programmers~\cite{eva, chet}.
These abstractions are all important because they help manage the complex design dependencies where designers can reason about the security guarantees.

\subsection{Uphold Abstraction Boundary Contracts}

Establishing clean abstraction boundaries and providing primitives to communicate across software, hardware, and security domains is useful to translate design-time requirements, but does not provide any guarantees on whether these requirements are fulfilled.
In other words, we need to verify that the contract between software and security or hardware and security is upheld.
For instance, a TEE is not useful if it provides an ISA but does not implement the hardware or software in a way that upholds the security guarantees that it claims.
As a result, it is also important to verify that the software, hardware, and security properties that are exchanged for complying with these abstraction interfaces are in fact implemented correctly.

For instance, an application can receive confidentiality guarantees (for data) and integrity guarantees (for code and data) via hardware support for properly partitioned programs in TEEs.
Here, software is responsible for providing a partitioning that properly leverages the TEE interface.
In the case of enclaves like SGX, contract between software, hardware, and security is verified via remote attestation in which the software verifies that the software verifies that the hardware system that is offering the secure execution guarantees is genuine.
The contract that the hardware implementation of the enclave is correct and implemented correctly is rooted in the manufacturer (i.e., security to hardware contract).

A similar set of contracts appears in the design considerations for homomorphic encryption.
In HE, the software interfaces with security through noise budget constraints and encryption parameters.
If the software implementation satisfies the noise budget constraints using the provided encryption parameters, HE guarantees computing a correct result; a violation of this contract (i.e., exceeding noise budget) results in the decryption failure scenario which is can be verified with testing.
In HE, an application also must conform to the restricted HE instruction set which is a canonical software-hardware contract but in this case the contract also includes restrictions from security.

Moving forward, it will be important to establish both the abstraction boundaries and verifiable guarantees.
Threat models and root of trust definitions provide these interfaces to some degree but still are missing the verification aspects.
Threat models provide the desired security requirements via adversary capability definitions but do not specifically address mechanisms for how threats are verified to be mitigated by software or hardware.
Many of these abstractions boundaries and contracts remain an open question as to what the correct verifiable manifestations is.
For instance, it is not clear what a contract may look like between DP and the hardware implementation of a DP software.
Establishing ways to verify these contracts thus remains an area of future work that can bolster the design of private and secure systems.

\section{Systemization of Secure Computing Technologies}
\label{sec:systemization}

\begin{table*}[]
\caption{Systemization of software-hardware-security codesign considerations for advanced encryption standard (AES), differential privacy (DP), trusted execution environments (TEEs), and homomorphic encryption (HE). Feedback between software, hardware, and security design considerations highlight the need for codesign for each secure computing technology.}
\label{tab:codesign_taxonomy}
    \begin{tabular}{@{}p{0.03\linewidth}p{0.3\linewidth}p{0.3\linewidth}p{0.3\linewidth}@{}}
    \toprule
        & Software $\leftrightarrows$ Hardware & Software $\leftrightarrows$ Security & Hardware $\leftrightarrows$ Security \\ \midrule
    AES &
      \begin{tabular}[c]{@{}l@{}} $\leftarrow$ Resource and performance results  \\ drives application selection \\ $\rightarrow$ Application selection determines \\ performance and resource needs\end{tabular} &
      \begin{tabular}[c]{@{}l@{}} $\leftarrow$ Security needs and specification drive \\ application design\\ $\leftarrow$ Cryptanalysis determines application \\ security strength\end{tabular} &
      \begin{tabular}[c]{@{}l@{}} $\leftarrow$ Encryption key size impacts hardware \\ efficiency \\ $\rightarrow$ Hardware implementation determines \\ timing and power side-channels\end{tabular} \\ \midrule
      DP &
      \begin{tabular}[c]{@{}l@{}} $\leftarrow$ Hardware support can facilitate or\\ enable DP in software\\ $\rightarrow$ Software drives correlated behavior\\ in hardware and lower levels of the \\ stack\end{tabular} &
      \begin{tabular}[c]{@{}l@{}} $\leftarrow$ DP requires integration of noise and\\ random decisions into application\\ $\rightarrow$ Application selection and behavior\\ defines DP privacy budget\end{tabular} &
      \begin{tabular}[c]{@{}l@{}} $\rightarrow$  Correlated hardware behavior \\ may not be DP and expose side channels\end{tabular} \\ \midrule
      TEE &
      \begin{tabular}[c]{@{}l@{}}$\leftarrow$ Exposes hardware security \\ primitives through ISA extensions\\ $\rightarrow$ Program optimized to leverage \\ hardware ISA extensions\end{tabular} &
      \begin{tabular}[c]{@{}l@{}}$\leftarrow$ Requires application modifications \\ to leverage security primitives\\ $\rightarrow$ Expose application-level threat \\ model requirements\end{tabular} &
      \begin{tabular}[c]{@{}l@{}}$\leftarrow$ Offload root of trust to hardware \\ support\\ $\rightarrow$ Hardware-based remote attestation to \\ enable root of trust\\ $\rightarrow$ Influences security interface to \\ leverage hardware\end{tabular} \\ \midrule
      HE &
      \begin{tabular}[c]{@{}l@{}} $\leftarrow$  Hardware architecture and speedups \\ depend on application parallelism\\ $\rightarrow$ High performance overheads mandates\\ hardware support and acceleration\end{tabular} &
      \begin{tabular}[c]{@{}l@{}} $\leftarrow$ HE constrains set of efficient\\ instructions and levels of logic\\  $\leftarrow$ Requires application quantization to \\ encodable HE values\\ $\rightarrow$ Application behavior determines \\ noise budget and encryption parameter \\ settings\end{tabular} &
      \begin{tabular}[c]{@{}l@{}} $\leftarrow$ Encryption parameter settings \\ determine datapath width and storage \\ size\\  $\leftarrow$ HE scheme determines useful \\ computational primitives for acceleration\end{tabular} \\ \bottomrule
    \end{tabular}
    \end{table*}

This section applies our systemization to three secure computing technologies and exposes the software-hardware-security codesign opportunities.
But first, we start with historical precedence to understand how the codesign process has manifested in the past and then look at emerging secure computing technologies.

\subsection{Historical Precedence: Design of the Advanced Encryption Standard}

The concept of software-hardware-security codesign is not without precedence and has been used in the past to build some of the hardware systems we use today.
A quintessential historical case study is the development and selection process of the Advanced Encryption Standard (AES) which is widely used and available in modern computing stacks.
The development of the AES dates back to 1997 and was motivated by the need for stronger end-to-end encryption protocols~\cite{aes_cfp}.
The algorithm for backing what we know as AES today originally consisted of several finalist proposals: MARS~\cite{mars}, RC6~\cite{rc6}, Rijndael~\cite{rijndael}, Serpent~\cite{serpent}, and Twofish~\cite{twofish}.
Ultimately, the NIST selected the Rijndael algorithm but the process through which they arrived at this conclusion provides valuable insights into the importance of the codesign process.

The algorithm that backs the AES was selected after three rounds of public comment based on software-hardware-security codesign considerations.
The selection process report~\cite{aes_selection} outlines the security, hardware, and software design considerations that were used to ultimately select the final standard.
The selection criteria was split into "1) Security, 2) Cost, and 3) Algorithm and Implementation Characteristics"; the latter two considerations manifested in the public comment periods where studies of the software and hardware implementation characteristics for the proposed algorithms were explicitly solicited.

The AES selection process as a software-hardware-security codesign exercise has many aspects summarized in \autoref{tab:codesign_taxonomy}.
The algorithm selection process was driven by both security considerations as well as software and hardware implementation costs.
Cryptanalysis of the security strength of the proposed algorithms contributed to but did not solely drive the selection of the final algorithm.
Over three years, hardware and software performance analyses were conducted to complement the security analyses; multiple case studies compared the resource efficiency as well as performance of these applications on CPU~\cite{aes_cpu_comparison}, FPGA~\cite{aes_fpga_comparison}, and ASIC platforms~\cite{aes_asic_comparison}.
The selection process also conducted a thorough analysis of aspects such as power and timing side-channel attacks when considering the security strength and viability of the proposed algorithms.
Finally, the process included architectural considerations such as impact of machine word size on security parameters like key size, as well as the impact of restricted computing environments (e.g., systems with limited memory) on the candidate encryption algorithms.

The selection process also contemplated a number of other considerations that go beyond software, hardware, and security.
These included simplicity of the application solution, flexibility, and intellectual property restrictions.
The selection process also examined a range of future-proofing measures such as larger machine word sizes (64-bit machines were not around then), whether to standardize two algorithms in case one was compromised, and ancestry of the algorithms to minimize risk of hidden backdoors.

The impact of the AES standardization and codesign efforts is clearly visible today where it is ubiquitous for securing communication lines and data assets.
Modern implementations of AES now have dedicated hardware acceleration units and instruction set customizations to make them highly optimized.
As a result, AES is a classical case study of how software-hardware-security codesign ultimately led to an efficient and secure computing solution.

\subsection{Differential Privacy}

Differential privacy (DP) is useful when one wants to answer questions about or analyze data in aggregate while protecting individual pieces of data.
DP~\cite{dwork2008differential} is originally a data information retrieval concept that was proposed to protect the privacy of individual entries in an aggregate database.
In a differentially private system, information about individuals is aggregated in a way that does not reveal information any individuals who contributed data to the database while still allowing some public information about the group as a whole.
More generally, we say DP is upheld when the observer of the computation output on the aggregated database does not reveal any individual entry.

DP is typically implemented by adding noise to data assets.
For example, canonical implementations use Laplace mechanisms~\cite{dwork2006calibrating, sarathy2011evaluating}, median mechanisms~\cite{roth2009median}, exponential mechanisms~\cite{mcsherry2007mechanism}, or randomized response mechanisms~\cite{erlingsson2014rappor}.
The addition of noise allows individual data entries to be protected from an adversary.
DP has two variants: local and global.
In global DP, a trusted central database aggregates individual data assets; in the local variant, noise is first added to individual data assets before communicating them to a potentially untrusted central database aggregator.
Local differential privacy (LDP) is more desirable in modern systems because it protects client data before it enters any potentially untrusted system.

For example, LDP is useful when collecting private sensor information from embedded Internet of Things (IoT) systems.
These embedded devices often run on limited compute and power resources.
The guarantees of differentially private algorithms change under such limited resources.
Prior work~\cite{choi2018guaranteeing} for LDP has shown that low-resolution and fixed-point implementations that are prevalent in IoT devices are counterproductive to and hinder private computation.
The authors present new resampling and thresholding techniques that they implement in hardware to continue to provide LDP privacy budget guarantees.
More importantly, this case study illustrates the need to consider hardware restrictions on the effective implementation of an LDP application.

DP also often requires modifying the application to integrate noise mechanisms.
However, DP considerations are not restricted to just the application behavior and applies more broadly to the remainder of the computing stack.
For instance, recent work has proposed differentially private type systems~\cite{reed2010distance, gaboardi2013linear, near2019duet} and programming language support~\cite{barthe2016programming, mcsherry2009privacy, roy2010airavat} which integrates differential privacy mechanisms into the compilation process.
There is also emerging work that exposes the need for DP for memory access patterns~\cite{chan2019foundations, kellaris2017accessing} when outsourcing private applications to an untrusted cloud platform to protect from side-channel attacks, even when running the application within a TEE.

DP is another opportunity for software-hardware-security codesign summarized in \autoref{tab:codesign_taxonomy}.
DP requires adjustment of the application to integrate the noise and random decisions to make the application private.
The application behavior in turn determines the privacy budget and configuration settings for DP to guarantee application privacy.
While an application implementation may be differentially private, the observable behavior across the remainder of the computing stack down to hardware may not be differentially private.
Thus, it is important to also consider hardware systems (ex., memory access) when determining whether the DP security guarantees are enforced as the presence of side channel or other vulnerabilities can defeat the efficacy of software-only DP.
Finally, recent work such as ~\cite{choi2018guaranteeing, maycock2015hardware} also shows that there is room for integrating or enhancing existing hardware support to better facilitate DP software such with thresholding and resampling techniques.

\subsection{Trusted Execution Environments}

Trusted execution environments (TEEs) serve as a proxy for encrypted computation.
Intuitively, TEEs provide an execution environment on a host processor to execute private computation\footnote{Some TEEs also guarantee integrity of the computation} that is protected from observation by others parties on the host processor.
For instance, a client system may request a TEE to set up and offload a private computation to the host processor via remote attestation.
TEEs operate by allocating an isolated hardware-protected memory region called an enclave where a protected application's code and data can reside.
Data within enclave memory can only be accessed by code that also resides within enclave memory and special instructions are provided for invoking enclave code.

Computation within an enclave is protected from inspection by other users and system software (with the exception of side-channel attacks).
Users can leverage the TEE's secure remote attestation protocol to ensure that their data is indeed being executed within the intended TEE and that the encrypted data that is sent to the server.
Memory management features also ensure that the host system cannot tamper with or observe the computation on the supplied data.
With TEEs, rather than placing trust solely in a cryptographic algorithm (as in multi-party computation or homomorphic encryption), clients place trust in the manufacturer's (Intel~\cite{mckeen2013innovative}, ARM~\cite{alves2004trustzone}, AMD~\cite{kaplan2016amd}, etc.) hardware to ensure that their private computations are only ever observed by the TEE compute units (i.e., not the unprotected host processors).

In TEEs, hardware considerations consist of instruction set extensions - a standard architecture software-hardware codesign technique - for facilitating secure remote attestation and secure entry to and exit from enclave code.
This ISA interface (e.g., via SGX ISA extensions) enables software to articulate security requirements at the function granularity.
These ISA extensions enable users to run applications on remote machines with confidentiality and in some cases integrity guarantees with respect to a third party adversary on the host machine.
In particular, these extensions (1) enable a user to send code to execute on a remote machine as an enclave application, (2) verify that their desired code is what is running on the remote TEE, and (3) establish a secure communication channel with the remote TEE to send secret data.
The application in exchange for programming against the ISA interface receives confidentiality and possibly integrity guarantees (for data) with the exception of side channels and integrity guarantees (for code and data) via hardware support for properly partitioned programs. \footnote{Some TEEs (e.g., MIT Sanctum~\cite{costan2016sanctum}) also consider side channels threats while other TEEs (e.g., Intel SGX) do not.}
In other words, software is responsible for providing a partitioning that properly leverages the TEE interface.

TEEs can impose restrictions and modifications to the software or application to fully leverage the advantages while minimizing performance overheads.
The application developer (or in compiler infrastructure) translates an application and its associated security requirements to leverage the software-exposed ISA security interface.
This requires refactoring sensitive application function calls which must be protected to interface with the enclave by annotating valid enclave entry and exit points.
This partitioning requires the application designer to be aware of and minimize the overheads associated with moving data into and out of the enclave.
Correctly partitioned software allows for preserving integrity (e.g., in the case of SGX) for code and data; it also enables data confidentiality guarantees (sometimes with the exception of side channels).
Unfortunately, such a partitioning of the code is currently left up to the user and is not guaranteed to produce a secure result~\cite{lind2017glamdring, SCONE, graphene}.

Given an application, fully offloading the entire computation to a TEE in Intel's SGX implementation can be expensive in terms of performance.
As a result, there have been some proposals to partially secure an application computing pipeline to only incur the overheads for a smaller fraction of the computation and execute the remaining computation in plaintext~\cite{ryffel2019partially, narra2019privacy}.
The high level intuition is that partially encrypted computation will yield intermediary results (unencrypted) which are less sensitive or meaningful.
However, there are no systematic methodologies for determining how to partially partition an application while still satisfying cryptographically strong guarantees which makes this an iterative process to balance performance and security levels.
Researchers are also exploring ways to produce such a portion automatically~\cite{lind2017glamdring}.

Combined, these design considerations illustrate how TEEs are another example of how software, hardware, and security must be co-optimized together as summarized in \autoref{tab:codesign_taxonomy}.
Hardware exposes a security interface in the form of ISA extensions for supporting secure remote enclave execution.
Software is refactored to express its security requirements and map this requirements onto the software-exposed ISA extensions.
In the case of SGX, as a specific example, code is partitioned into enclave code and native code using SGX ISA extensions.
The result is confidentiality (with the exception of side-channels) for enclave data and integrity for enclave code and data.
In other words, hardware and software are working together to provide a particular user-specified level of application security.

\subsection{Homomorphic Encryption}

Homomorphic encryption (HE) is an emerging secure computing technology that enables computation \textit{directly over ciphertexts without decrypting the contents} and was proposed by Gentry~\cite{gentry09, gentry10}.
In non-HE encryption, a client encrypts the plaintext data and sends it to a cloud service provider; the cloud provider then decrypts the data back into plaintext where functions can readily be applied.
Once computation completes, the service provider encrypts the result and sends it back to the client.
In this setting an honest-but-curious adversary (cloud service provider), such as those assumed by~\cite{gazelle, cryptonets}, can see the plaintext copy of sensitive user data.
HE is different because it allows for a cloud service provider to directly perform computation on ciphertexts; as a result, in HE a cloud provider never sees the plaintext version of the data it is performing computation on.
This provides cryptographically strong guarantees against adversaries for the data transmitted to the datacenter for computation as only the client is able to decrypt the data.
HE provides security guarantees while still allowing an untrusted third party to perform useful computation on the encrypted data.

HE comes with a number of severe computational restrictions and overheads which mandate the need for software-hardware-security codesign considerations to be practical.
First, the performance overheads for executing homomorphically encrypted kernels are generally four to five orders of magnitude~\cite{gentry2011implementing}.
In other words, executing a single multiplication or addition in HE over two encoded ciphertexts is 10000$\times$ to 100000$\times$ slower than a single plaintext addition using a CPU ALU.
As a result, to bring HE computation back down to practical speeds, HE will require significant codesign, hardware acceleration, and optimizations to reduce this overhead as much as possible.
Recent work has shown that certain applications containing abundant application parallelism which can be aggressively exploited by the underlying specialized hardware accelerator are preferable~\cite{heax, cheetah}.

Second, encrypted ciphertexts in HE are each associated with a noise budget that degrades monotonically with successive computations.
If the noise budget is exceeded for a given ciphertext the decryption procedure will fail which yields a random result and effectively losing the encoded value.
The noise budget is governed by parameters associated with the HE encryption scheme which can be increased to increase the noise budget.
These encryption parameters also determine the size of the ciphertext representation.
Increasing the encryption parameter sizes to increase noise budget directly increases the compute datapath width and storage requirements for ciphertexts.
As a result, these encryption parameters must be carefully balanced to avoid wasting noise margins but still allow correct decryption.
Methods like bootstrapping can reduce the noise for an intermediary ciphertext but the process is impractically slow (an additional 4-6 orders of magnitude overhead)~\cite{sgx-he}.
Therefore, practical implementations of HE computations effectively have a limited logical depth for computation (i.e., \textit{leveled} HE) that they can support bound by the noise budget.

Third, HE is severely limited in the types of computations that it can support efficiently.
Most modern constructions of HE such as BFV~\cite{bfv}, BGV~\cite{bgv}, and CKKS~\cite{ckks} pack and encrypt multiple plaintext values into a single ciphertext representation.
Each value is packed into a slot in the ciphertext the same way values are packed into vector registers.
Furthermore, values are constrained to fixed point or integer which require quantizing the target application.
Modern HE schemes only support single instruction multiple data (SIMD) add, SIMD multiply,
and slot rotation, which allows swapping the values between slots in the vectors of the ciphertext representations,
over the ciphertext vectors,
Each of these three operations as well as the order in which they are executed increase the noise budget differently.
In theory, arbitrary computation can be constructed out of addition and multiplication operations but they are not efficient in HE as they require many logical layers of computation to implement.
This means that application selection is a key design consideration; vectorizable computation with fewer logical layers with minimal control logic is more efficient in HE.
For instance, statically schedulable computation such as matrix multiplication is more amenable to HE than computation that requires data dependent control flow like sparse matrix algebra.

Putting it all together, HE presents a number of software-hardware-security codesign opportunities summarized in \autoref{tab:codesign_taxonomy}.
The high overhead of HE mandates the need for aggressive hardware specialization but the maximum speed ups a hardware architecture can achieve is determined by available application parallelism.
Similarly, application selection determines the underlying computational behavior such as instruction mix, control flow, and amenability to vectorization which impacts the noise budget requirements to prevent decryption from failing.
This ultimately dictates the noise budget requirements and encryption parameter settings which affect the compute datapath width and storage requirements on the target hardware platform.
All together, we find that reaching optimized design solutions with HE is another example of an opportunity for software-hardware-security codesign.

\subsection{Other Secure Computing Technologies}

There are other instances (in varying stages of maturity) of secure computing technologies that benefit from hardware-software-security codesign insights; for instance, one group of secure computing technologies specifically addresses information leakage through side channels.
Consider systems where multiple tenants share some key computing resources such as caches.
This is the case in cloud computing applications, which store and compute over private data.
In cloud service infrastructures, virtual machines share the underlying hardware resources and isolation is usually not provided by default.
Stealthy cache attacks such as
  FLUSH$+$RELOAD~\cite{gruss2016flush, gullasch2011cache, yarom2014flush}, PRIME$+$PROBE~\cite{irazoqui2015s, kayaalp2016high, liu2015last, osvik2006cache, percival2005cache},
  EVICT$+$TIME~\cite{osvik2006cache} and
  others~\cite{disselkoen2017prime} are considered practical; this allows adversaries to steal secret AES~\cite{kayaalp2016high}, RSA~\cite{yarom2014flush}, and ElGamal~\cite{liu2015last} cryptographic keys, spy over encrypted channels~\cite{irazoqui2015lucky}, and log keys~\cite{gruss2015cache}.
A similar scenario also occurs in smart phones, where a malicious application can learn side-channel information about the system through shared resources such as caches~\cite{lipp2016armageddon}.

There are ways to mitigate against these side-channel attacks but identifying the root causes and mitigating them requires insights into both hardware and software behaviors to codesign them to meet security requirements.
For example, software running on vulnerable systems should be written in such a way that it avoids behavior that enables information leakage.
This can be done by writing code such that control flow or memory access patterns eliminate observable side effects that leak information through hardware-induced side channels.
Software countermeasures such as page coloring can also be used.
Other hardware solutions such as Intel's cache allocation technology, and attack resistant caches~\cite{liu2016newcache, wang2008novel, liu2014random} can mitigate these vulnerabilities but still require codesigning the underlying hardware systems to be aware of and properly mitigate such vulnerabilities.

The post-quantum cryptography competition~\cite{nist-quantum, nist-quantum2} illustrates another relevant opportunity for software-hardware-security codesign similar to the standardization of AES.
The primary motivation for the post-quantum cryptography effort stems from application concerns that quantum computing will defeat the hardness guarantees of existing cryptographic techniques, i.e., there is a need to re-codesign the software or encryption algorithm to strengthen security properties.
This illustrates the ongoing design feedback between security needs and the algorithms that realize them.
The latest round of the standardization effort focus on the security and cryptanalysis but, as with prior efforts such as AES, there is an opportunity for hardware and software codesign considerations to ensure that theoretically strong cryptography can be put into practice.

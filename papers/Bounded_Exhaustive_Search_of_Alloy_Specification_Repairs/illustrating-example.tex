\section{An Illustrating Example}

In this section, we introduce both Alloy and our technique by means of a motivating example. Alloy is a formal specification language, with a simple syntax and a relational semantics. The syntax of the language is rather small, and is compatible with an intuitive reading of specifications, or \emph{models}, as they are typically called in the context of Alloy \cite{Jackson2006} (we will use \emph{specification} and \emph{model} interchangeably in this paper). Specifications can resemble object-oriented notions that are familiar to developers. The basic syntactic elements of Alloy specifications are: \emph{signatures}, which declare data domains; \emph{signature fields} (akin to class attributes), that give structure to specifications and declare \emph{relations} between signatures; \emph{predicates}, parameterized formulas that can be used to state properties, represent operations, etc.; \emph{facts}, formulas that constrain the specifications and represent assumptions; and \emph{assertions}, formulas that capture \emph{intended} properties of the specification, i.e., properties that the user would like to verify. Formulas in Alloy are expressed in \emph{relational logic}, a first-order logic extended with relational operators such as relational transpose, union, difference and intersection. Alloy supports various quantifiers (\texttt{all} and \texttt{some} are the usual universal and existential quantifiers, respectively, \texttt{one} and \texttt{lone} are for ``exists exactly one'' and ``exists at most one'', respectively). It also features additional important relational operators: \emph{relational join}, a generalization of  composition to $n$-ary relations, which can be used to express \emph{navigations} as in object orientation; and \emph{transitive closure}, which can be applied only to binary relations, and extends the expressiveness of Alloy beyond that of first-order logic. 

\begin{figure}[ht!]
%{\small
%\begin{verbatim}
\begin{lstlisting} []
abstract sig Boolean { }
one sig True, False extends Boolean { }

sig Node {
 link: set Node,
 elem: set Int
}

sig List {
 header: set Node
}

fact CardinalityConstraints {
 all l : List | lone l.header
 all n : Node | lone n.link
 all n : Node | one n.elem
}

fact IGNORE {
 one List && List.header.*link = Node
}

pred Loop[This: List] {
 no This.header || 
 one n : This.header.*link | n.^link = n.*link 
}

pred Sorted[This: List] { // buggy
 all n: This.header.*link | n.elem < n.link.elem 
}

pred RepOk[This: List] {
 Loop[This] && Sorted[This]
}

run RepOk for 1 but exactly 3 Node expect 1

// buggy
pred Contains[This: List, x: Int, res: Boolean]{ 
 RepOk[This] &&
 ((x !in This.header.*link.elem => res=False ) || 
 res = True) 
}

pred Count[This: List, x: Int, res: Int] {
 RepOk[This] &&
 res = #{ n:This.header.*link | n.elem = x }
}

assert ContainsCorrect {
 all l : List, i, j : Int | 
   (Count[l, i, j] && j > 0) iff Contains[l, i, True]
}

check ContainsCorrect for 10
\end{lstlisting}
\caption{A (faulty) sample Alloy specification.}
\label{alloy-model}
\end{figure}

Consider the Alloy model in Figure~\ref{alloy-model}, a modified version of an Alloy specification of linked lists, that is part of the benchmark used in \cite{Wang+2018}. This model declares domains for booleans (with its two constants captured via singleton relations), and signatures for nodes and lists. Nodes have a link (a set of nodes), and associated elements (a set of integers); lists have a header (a set of nodes). A \emph{fact} constrains the cardinalities of these signature fields: lists have at most one header, and nodes have at most one successor node, and exactly one element (when applied to expressions, \texttt{lone}, \texttt{one} and \texttt{no} constrain a given expression to have a cardinality of at most one, exactly one, and exactly zero, respectively). Notice the additional fact, which is there for analysis purposes: it states that exactly one \texttt{List} is going to be considered in each instance of the model, and that all nodes present in an instance will be those in the list (no unreachable ``heap'' objects). Predicate \texttt{Loop} captures lists with a loop in its last node, saying that a list satisfies the predicate if it either has no header, or for exactly one of its nodes, the elements reachable in one or more steps from \texttt{link} are exactly the same reachable in zero or more steps through \texttt{link}. Predicate \texttt{Sorted} attempts to capture that lists are non-decreasingly sorted (this predicate is buggy though, as the order constraint is strict). Predicate \texttt{RepOk} is simply defined as the conjunction of \texttt{Loop} and \texttt{Sorted}. Predicate \texttt{Contains} is used to model an \emph{operation} on lists, namely, the operation for querying membership of an integer as an element of a node of a list. The result of the operation is captured by an additional Boolean parameter. This predicate is \emph{buggy}, it does not correctly model the intended operation (e.g., it admits the predicate to return \texttt{True} despite the contents of the list). 

Alloy specifications can be automatically analyzed, by an analysis mechanism that resorts to SAT solving, and is implemented in a tool called \emph{Alloy Analyzer} \cite{Jackson2006}. Two kinds of analysis are possible: \emph{running} a predicate and \emph{checking} an assertion. Both are analyzed in \emph{bounded} scenarios. Running a predicate searches for instances (scenarios) that satisfy all the constraints (cardinalities, facts, etc.), including the predicate being run. Assertion checking looks for \emph{counterexamples} of the asserted properties. Analysis is performed up to a bound $k$ (typically referred to as the \emph{scope} of the analysis), meaning, e.g., that assertion checking will either find a counterexample within the given scope, or guarantee the validity of the formula within the bound (similarly, a predicate will be found to be satisfiable within the provided scope, or not to have a satisfying instance within the scope). This \emph{bounded exhaustive analysis}, of course, does not necessarily mean that the formula is valid (resp., satisfiable), as counterexamples (resp., instances) of greater size may exist if larger scopes are considered.

The Alloy language is the vehicle for defining abstract software models in a lightweight and incremental way, with immediate feedback via automated analysis \cite{Jackson2006}. Typically, the process of constructing an Alloy model, as the one in our example, starts very much in the same way one would proceed while eliciting requirements, or sketching an abstract software design: basic domains of the model are identified (signatures of the model), over which more structured components are organized (signatures equipped with fields). How these domains and components are constituted, the inherent constraints of the problem domain and the operations that represent the software model capacities, are all incrementally created, via a constant interaction with the Alloy Analyzer. This process eventually involves the use of \emph{assertions} and \emph{predicates}, that capture intended properties of the model, and that serve essentially as the \emph{oracle} of the specification, i.e., the properties that would convey the acceptance of the model. Sometimes these properties can help find surprising counterexamples, that lead to refinements of the properties themselves, but more often they help one in ``debugging'' the core of the model, i.e., in getting the model ``right'', adapting it until the intended properties result as expected. For instance, for the linked lists model, the developer would expect the representation invariant \texttt{RepOk} to be satisfiable, and the definition of \texttt{Contains} to have the relationship with \texttt{Count} captured in property \texttt{ContainsCorrect}.  

While the intended properties are subject to defects too, they are typically significantly shorter and clearer than the ``core'' of the specification. They capture high level properties of the model, so they are expected to be simpler to write and get right. So, once the intended properties are set, the user may perform the corresponding analyses and use the results as an acceptance criterion for the specification, and the corresponding design it conveys. That is, a model will be considered incorrect if any of the analyses of the intended properties fails, i.e., has a result that contradicts the user expectations. In Figure~\ref{alloy-model}, for instance, the user may consider the consistency of \texttt{RepOk}, the assertion \texttt{ContainsCorrect} and the auxiliary predicate \texttt{Count} as the oracle of the specification, meaning that when this intended property is found to be invalid, the user would start modifying the remainder of the specification, as an attempt to fix the error. \technique\ as well as other model repair techniques aim at reducing human intervention along this overall modeling process, by automatically fixing errors in incorrect models.

Let us describe how the technique works, assuming for the moment that the faulty locations in the model have been correctly identified. In order to attempt to repair the specification, and assuming that for the first location the syntactic mutation operators lead to $n$ different fix candidates (for that specific location), and for the second location we have $m$ different fix candidates, in the worst case we have to check $n \times m$ potential fixes, as we would want to consider \emph{all} combinations of candidate fixes for each repair location. The model expectations, in our example the satisfiability of \texttt{RepOk} and the bounded validity of \texttt{ContainsCorrect}, will be the \emph{acceptance criterion} fix repair, i.e., if a fix candidate ``passes'' these analyses, it will be considered a fix.

The automated repair process for the above faulty specification is then straightforward to describe: we have $n \times m$ repair candidates (the combinations of fix candidates for the suspicious locations), and since we aim at exhaustively exploring this candidate space, we would run the oracles on each candidate, stopping as soon as we find one that ``passes'' all predicates and assertions. 

Let us describe some situations that allow for sound pruning, i.e., pruning that only avoids invalid fix candidates. 

Notice that, in our case, we have two defective lines, but these are not \emph{symmetric}: the bugs in \texttt{Sorted} affect \texttt{Contains}, as \texttt{Contains} depends on \texttt{RepOk} which in turn depends on \texttt{Sorted}, but the latter does not depend (i.e., calls directly or indirectly) on \texttt{Contains}. Thus, when checking a specific candidate for \texttt{Sorted} that does not pass an oracle involving \texttt{Sorted} but not \texttt{Contains}, as for instance the satisfiability of \texttt{RepOK}, we can stop analyzing the fix candidate for \texttt{Sorted} altogether, and not consider it in combination with any further candidates for the other location. Consider, for instance, the following combination of fix candidates for \texttt{Sorted} and \texttt{Contains}:

% {\small
% \begin{verbatim}
\begin{lstlisting} []
pred Sorted[This: List] {
    all n: This.header.*link | n.elem != n.link.elem
}

pred Contains[This: List, x: Int, res: Boolean] {
  RepOk[This] &&
  (x !in This.header.*link.elem => res = False) && 
  res = True
}
\end{lstlisting}
% \end{verbatim}
% } 

\noindent
Assuming that we consider the above described oracles for the specification, this combination does not pass the oracles, it is an invalid fix candidate. Moreover, if we leave the current fix candidate for \texttt{Sorted} and iterate over other candidates for \texttt{Contains}, the property check requiring \texttt{RepOk} to be satisfiable will continue to fail, as the unsatisfiability of \texttt{RepOk} cannot be solved by changing the definition of \texttt{Contains}. Thus, if we are able to identify this situation (as we explain later on, our technique does so), we can safely consider a different mutation for \texttt{Sorted}, or equivalently, soundly skip all combinations of the current mutation to \texttt{Sorted} with all other mutations for \texttt{Contains}. 

Now let us look at another situation, that will also allow us to soundly prune parts of the fix candidate space, even in the presence of bidirectional (or multi-directional) dependencies between faulty locations. Consider the above fix candidate for predicate \texttt{Contains}, that replaced \texttt{||} by \texttt{\&\&}. This ``local'' candidate that fails to pass an oracle such as the assertion on \texttt{Contains} (in combination with a particular candidate for \texttt{Sorted}) does not allow us to discard it altogether, as the failing cannot in principle be blamed on \texttt{\&\&} on its own: it may be the case that this candidate ``works'' with a different candidate for \texttt{Sorted}. So in order to check the local feasibility of the candidate for \texttt{Contains}, we need to consider it in combination with \emph{any} other candidate for \texttt{Sorted}, of course, trying to avoid checking \emph{all} candidates for this predicate. Assuming that we identified the body of the quantification of \texttt{Sorted} as the problematic part in that predicate (fault localization techniques for Alloy, in particular the one we use in this paper, can identify fine grained faulty locations, such as particular subexpressions), what we would need to intuitively check is whether there exists a (boolean) value for that location, that in combination with \texttt{\&\&} would make the oracles pass:

% {\small
% \begin{verbatim}
\begin{lstlisting} []
pred Sorted[This: List] {
    all n: This.header.*link | (??)
}

pred Contains[This: List, x: Int, res: Boolean] {
 RepOk[This] && 
  (x !in This.header.*link.elem => res = False) && 
  res = True
}

\end{lstlisting}
% \end{verbatim}
% } 

\noindent
That is, can we replace the double question mark above by a value that would make oracles pass? If the answer is \emph{no}, then we can blame \texttt{\&\&}, and try another candidate for \texttt{Contains}, avoiding considering of \texttt{\&\&} with candidates for \texttt{Sorted}. If we are able to correctly identify these situations, as our technique does and we describe later on in this paper, we can again safely prune a large number of candidates, namely all combinations of \texttt{\&\&} with all the mutations for \texttt{Sorted}.

It is worth remarking that we do not assume any particular format or characteristic, neither from the specification itself, nor from the oracle. This is in contrast with previous work on repairing Alloy specifications \cite{Wang+2018}, which requires repair oracles to be provided as Alloy \emph{test cases}. Alloy test cases define \emph{scenario-based expectations}, similar to what one would capture with unit tests for source code. As an example, consider the evaluation of \texttt{Contains} on a particular concrete structure, and its corresponding expected outcome (the expected outcome represents a boolean, 1 for ``satisfiable'' and 0 for ``unsatisfiable''): 

\begin{lstlisting} []
pred ContainsFalseOnListTest[This: List] {
  some n0, n1: Node | {
    This.header = n0 &&
    n0.link = n1 && n0.elem = 0 &&
    n1.link = n1 && n1.elem = 0 &&
    Contains[This, 1, False]
  }
}

run ContainsFalseOnListTest expect 1
\end{lstlisting}

\noindent
While scenarios do participate in the Alloy modeling process, they typically do so as a result of analyzing \emph{properties}. That is, tests are not a common explicitly described part of Alloy specifications. Recent proposals, notably \cite{Sullivan+2018}, are starting to motivate the use of test cases in formal specification. As mentioned, our approach allows for \emph{any} kind of oracle, including test-based oracles. 


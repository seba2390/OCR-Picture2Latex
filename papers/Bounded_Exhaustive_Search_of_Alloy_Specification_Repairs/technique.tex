\section{The Technique}

Our approach to Alloy specification repair involves a series of tasks, for fault detection, fault localization, fix candidate generation, and fix candidate assessment. We describe these in more detail below. 

\subsection{Fault Detection and Fix Acceptance Criterion}

In general, given an Alloy specification, we may say that such specification is \emph{faulty} if at least one of the analysis commands in the specification has an outcome contrary to its corresponding expectation. This can be either a failing assertion (assertion with counterexamples), or a predicate that is unsatisfiable while the user expected it to be satisfiable, or vice versa. We may also allow for other flavors in commands, in particular Alloy test cases, in the spirit of AUnit \cite{Sullivan+2018}. The fault detection stage then resorts to SAT solving, the underlying analysis mechanism behind Alloy Analyzer, the tool for Alloy specification analysis \cite{Jackson2006}. Similarly, a fix candidate can be considered an acceptable patch when all the analysis commands in the specification have an outcome that coincides with the corresponding command's expectations. 

Our technique requires the user to identify the specification oracle, i.e., the assertions, predicates or tests that the technique will have to consider as fix acceptance criterion. The technique will then identify faults in the remainder of the specification (the oracle is left out of the analysis space for fault localization), and generate fix candidates for the faulty locations. Therefore, our repair approach cannot fix any faulty situation, but only those where the developer is certain about some part of it (the oracle), and wishes to alter the remainder of the specification to pass it. Looking for solutions that may modify the specification \emph{and} the criterion for acceptance would lead to fixes that may simply relax the acceptance criterion. Notice that, in this respect, we follow the same approach that ARepair and most test-based program repair techniques: the tests (the repair oracle) cannot be changed in the repair process. As described later on in this section, other trivial solutions such as changing a command's expectations or simply removing a command are prevented, due to how the fault localization is performed (which cannot be blamed on commands) and how fix candidates are generated (only by mutating the faulty locations). 

\subsection{Fault Localization}

Once a specification is deemed faulty, we need to identify the specific parts of the specification that are more likely to be blamed for the fault or faults. We do not deal with fault localization in this paper, and we assume an external technique/tool provides fault localization information. There exist techniques for fault localization that specifically target Alloy specifications, such as the spectrum-based fault localization mechanism behind ARepair \cite{Wang+2018}, and our fault localization technique presented in \cite{Zheng+2021}. While in principle any fault localization technique would fit our technique, as long as the employed fault localization can handle the oracles present in the faulty specification, it is worth to remark that the fault localization within ARepair inherently depends on having tests as oracles (acceptance criteria) for specifications \cite{Wang+2018}. Moreover, the fault localization in ARepair can dynamically change the identified faulty locations, as the specification is transformed during the repair process. Our technique, on the other hand, uses an \emph{offline} process for fault localization: the faulty program is fed to the fault localization tool, and a number of suspicious specification locations are returned. This is the input to our specification repair approach, and the space of \emph{all} possible patches for these locations, for a maximum depth in mutation application and a given set of mutation operators, will be considered. 

For our experiments in Section~IV, we use the FLACK fault localization technique \cite{Zheng+2021}. While we do not describe in detail the fault localization technique in this paper (we refer the reader to \cite{Zheng+2021}), let us remark a number of facts about FLACK: it supports arbitrary satisfiability checks and assertions, as well as tests, as specification oracles; it is based on the use of (partial) maximum satisfiability procedures, to process counterexamples of an Alloy model (witnessing the faulty status of the specification); and it can only identify faults within formulas and relational expressions, it cannot locate faults in data definitions, such as signature and field declarations, nor in commands (Alloy's runs and checks). 

\subsection{Generation of Fix Candidates}

Once the suspicious expressions are identified, syntactical variants of these expressions are produced. We consider an ample set of mutation operations, including the obvious logical and relational operator insertion, removal and replacement, quantification mutation (e.g., changing a quantifier), multiplicity constraint replacement, field/variable swap/replacement, etc., based on Alloy's grammar. Our tool processes the specification to obtain some typing information, so that some legal expressions that necessarily lead to empty relation/contradictory formulas are disregarded, as well as innocuous operation application (e.g., double transitive closure). Two elements are important to highlight here, namely the use of join to produce navigation chains, using fields, signatures, etc., and the possibility of \emph{combining} mutations, i.e., applying further mutations to an already mutated expression, akin the so called higher-order mutants \cite{DBLP:journals/infsof/JiaH09} in mutation testing.

Both the mutation operators and the maximum depth, i.e., the number of cumulative mutations (hence, the higher order nature of the generated mutants) that can be applied to a given faulty location, are configurable. These are bounded-exhaustively generated as the space of fix candidates is traversed (see below). In our experiments, we used 21 mutation operators in total, typically leading to roughly between 60 and 260 1-level mutants per location.  

\subsection{Fix Candidate Space Traversal}

Here we present our general repair approach. The two pruning techniques just introduced, are also described in more detail, and we argue about their soundness. The search space is organized as a search tree in a traditional search problem: the root is the original specification, with its faulty locations identified; and if a specification $s$ is in the tree and $s'$ can be obtained by applying a mutation to a faulty location, then $s'$ is also in the tree, with the same locations marked as faulty (so that the mutation process can be iterated). This in principle leads to an infinite fix candidate space, which we explore up to a maximum depth. While any search strategy may be applied, we explore the state space in a breadth-first fashion. 

\subsubsection{Partial repair checking}

Our first pruning strategy consists of identifying one of the suspicious locations for which a current repair candidate fails, as established by an analysis check that does not depend on the remainder of the faulty locations. We will describe it in more detail, assuming two faulty locations, without loss of generality. Let $\textit{Spec}$ be an Alloy specification, $\textit{Check}_1, \dots, \textit{Check}_k$ its analysis checks used as oracles, and $L_0, L_1$ the suspicious locations identified by the fault localization phase. Each analysis check $\textit{Check}_i$ refers to a specific part of $\textit{Spec}$, which can be determined by a straightforward syntactic analysis: $\textit{Check}_i$ refers to the formula it directly mentions (the body of the corresponding predicate or assertion), all the facts (axioms of the specification that are implicitly involved in every analysis check), and the symbols directly and indirectly referred syntactically to by these (predicates called, relations used, etc.). This syntactic analysis can determine then, for every $\textit{Check}_i$, which of the suspicious locations $L_0$ and $L_1$ it involves.

Most logics, and certainly Alloy's relational logic, have a sort of syntactic locality property, that guarantees that the validity/satisfiability of a formula depends only on the symbols it refers to. (In the case of Alloy, since validity/satisfiability is actually bounded validity/satisfiability, it can also depend on the scope, the bound, of analysis; but since the bound of analysis cannot be modified in the patch generation phase, we can disregard it). Moreover, the logic is monotonic, meaning that adding more assumptions to a formula can never reduce the conclusions drawn originally from it. These properties allow us to make the following observation. Let $m_0$ and $n_0$ constitute the modifications to locations $L_0$ and $L_1$, respectively, in the current fix candidate (i.e., be the expressions substituting the original expressions in locations $L_0$ and $L_1$ of $\textit{Spec}$). If a failing satisfiability check $\textit{Check}_i$ refers to only one of the suspicious locations, say $L_0$ and its current expression $m_0$, this means that the formula in $\textit{Check}_i$ is determined to be false independently of $n_0$. Then, for every alternative expression $n_i$ for location $L_1$, the corresponding fix candidate $(m_0, n_i)$ (the replacement expressions for locations $L_0$ and $L_1$) will still make $\textit{Check}_i$ to be false, due to the monotonicity of the logic. In other words, the specification cannot be repaired by modifying location $L_1$ if the current fix for location $L_0$ is maintained. We can therefore exclude (prune from the checking) all $(m_0, n_i)$ fix candidates as soon as we determine this situation, which in turn can be determined by a syntactic analysis of the specification, and the analysis outcome for fix candidate $(m_0, n_0)$. 

We refer to this analysis and the corresponding pruning it enables as \emph{partial repair checking}, due to the partiality of fix candidates when these do not involve all suspicious locations.

\subsubsection{Variabilization}

Our second pruning strategy is called \emph{variabilization}, due to the mechanism employed for prune checking, that requires introducing fresh variables to refer to fix candidates to specific locations, in a general way.

Let $\textit{Check}_i$ be a failing assertion (validity) check that refers to suspicious locations $L_0$ and $L_1$, and let $(m_0, n_0)$ be the current failing fix candidate. Notice that since $\textit{Check}_i$ is a failing validity check, we have a counterexample $\textit{CEX}_i$ as a result of the violation. That is, we have that:
\begin{displaymath}
    \textit{CEX}_i \not \models \textit{Spec}[m_0, n_0] \Rightarrow \textit{Check}_i,
\end{displaymath}
where $\textit{Spec}[m_0, n_0]$ denotes the fix candidate obtained by replacing $L_0$ and $L_1$ by $m_0$ and $n_0$, respectively, in $\textit{Spec}$. The purpose of variabilization is to check whether the current fix for $L_0$, i.e., $m_0$, \emph{may} work with \emph{some} candidate for $L_1$ (other than $n_0$, of course, which we already know it does not work). For technical reasons, we actually check whether some fix for $L_1$ may work in combination with $m_0$, for counterexample $\texttt{CEX}_i$. Let us describe the process for performing this check. 

Notice that fault locations can be subexpressions of a formula; let us refer by $F_1$ to the formula (predicate, fact, etc) containing $L_1$. Also, let $T$ be the most general type for $L_1$ in context $F_1$ (in Alloy, this most general type will depend on the arity required by $L_1$ in $F_1$, the context in which $L_1$ may depend upon, and will use the most general unary type, the universe \texttt{univ}). Let $\textit{Spec}_{L_1}$ be the specification obtained by replacing $F_1$ in $\textit{Spec}$ by 
\begin{displaymath}
\exists l_1: T \vert F_1[l_1/L_1] 
\end{displaymath}
i.e., we substitute $L_1$ by an existentially quantified variable of type $T$ (hence the name \emph{variabilization}). We now can check: 
\begin{displaymath}
    \textit{CEX}_i \models \textit{Spec}_{L_0}[m_0] \Rightarrow \textit{Check}_i,
\end{displaymath}
i.e., whether there exists a \emph{value} of type $T$ that can be put in place of location $L_1$, so that $\textit{CEX}_i$ ceases to be a counterexample. If this is the case, then local fix $m_0$ works as a fix for $L_0$, at least as far as $\textit{CEX}_i$ is concerned, and we may traverse the space of local candidates for $L_1$ to attempt to find a complete fix. But, on the other hand, if the above check fails, then there is no value that can be put in place of $L_1$ such that the local fix $m_0$ would work ($\textit{CEX}_i$ would still be a counterexample). Therefore, we can again exclude (prune from the checking) all $(m_0, n_i)$ fix candidates if the check fails. 

One may argue why not check the ``variabilized'' specification in the general case, instead of doing so \emph{only} for counterexample $\textit{CEX}_i$. The reason has to do with the type $T$ of location $L_1$. When this type is a relation of an arity greater than one, variabilization leads to a higher-order quantification, that Alloy cannot handle as a general analysis check, but it can do so for the specific counterexample $\textit{CEX}_i$. 

To clarify this variabilization process, and especially the reason why we typically have higher-order quantification, let us consider the example introduced in Section~II, where one local fix candidate is applied and the other was generalized with question marks. Assuming that assertion \texttt{ContainsCorrect} failed, a counterexample $\textit{CEX}$ was generated from this fix. To check whether variabilization pruning can be applied, we turn the question marks into existential quantifications. Intuitively, the corresponding variabilized specification would then be as follows (we are abusing the notation below, using Boolean for the type of the variabilized formula within \texttt{Sorted}):

%{\small
%\begin{verbatim}
\begin{lstlisting} []
pred Sorted[This: List] {
 some b: Boolean | all n: This.header.*link | b
}

pred Contains[This: List, x: Int, res: Boolean]{
 RepOk[This]
 (x !in This.header.*link.elem => res=False ) 
 && res = True
}
\end{lstlisting}
%{\end{verbatim}
%} }

\noindent
However, we need to take into account that the variabilization context, the place where the location being variabilized occurs, depends in this case both on \texttt{This} and \texttt{n}. Thus, the actual variabilization for the check is as follows (we are again abusing the notation for the sake of clarity):

%{\small
%\begin{verbatim}
\begin{lstlisting} []
pred Sorted[This: List] {
 some b: List -> Node -> Boolean | 
     all n: This.header.*link | b[This, n]
}

pred Contains[This: List, x: Int, res: Boolean]{
 RepOk[This]
 (x !in This.header.*link.elem => res=False ) 
 && res = True
 \end{lstlisting}
%\end{verbatim}
%} 

\noindent
We cannot check \texttt{ContainsCorrect} over this specification due to the higher-order quantification in \texttt{Sorted}; but we can check it for $\textit{CEX}$. 

It is worth remarking that the above check, if successful, will produce a \emph{relational value} for \texttt{b} that makes the variabilized specification work. It will \emph{not} produce an expression to put in place of the body of the quantification, as a local fix candidate. It would not even produce a relational value that can be ``hardwired'' as a local fix of the corresponding location, since it is in principle just a relational value that works for counterexample $\textit{CEX}$. But its existence is what enables us to decide that a local fix for $L_1$ (\texttt{Sorted}) may be possible, considering the current local fix for $L_0$ (the \texttt{\&\&} in \texttt{Contains}). Our check essentially corresponds to only checking for feasibility of a local fix with respect to other locations. 

An alternative to the above would be to attempt to turn the relational value bound to $b$ into a relational \emph{expression}, that can be considered a local fix candidate. Such a process would correspond to a \emph{synthesis procedure}, which would require a grammar for expressions, so that the solver can attempt to work out an instance (an actual expression) during the satisfiability process. While it is technically feasible, it is also significantly more costly than our simpler query for satisfiability, which we solely use for pruning. 

%Such queries are infeasible in the context of programs, but are realisable in specifications, especially in the context of Alloy and its automated analysis. It can actually be ``implemented'' in different ways. One approach, which is in a sense followed by ARepair \cite{XXX}, is to exploit a \emph{synthesis} mechanism, as \emph{sketching}. That is, not only query for satisfiability, but do so in a way that the satisfying valuation can be turned into a fix. The cost is however greater than solely querying for satisfiability, as one needs find a single expression that would make \emph{all} oracles to pass at the same time, and its feasibility needs to consider a limited set of expressions, to make it solvable by the underlying SAT solver. Unsatisfiability in this case means there is no expression, for the a given (limited) grammar, that would fix the specification. Thus, (un)satisfiability is relative both to the scope (as usual in the context of Alloy) and to the grammar used for candidate expressions. 

%When checking the oracles on this specification, satisfiability will \emph{not} produce an expression to put in place of the body of the quantification, but a \emph{relation}, i.e., an element of the semantics of the specification (not of Alloy's syntax), so we cannot use it, at least not directly, as a fix, but only as a generic check for repair candidate feasibility. 

%As we show in our evaluation section, these checks can have a significant impact in pruning, and lead to a technique for program repair that is complementary to that introduced by ARepair.

%checks that serve the purpose of checking whether a fix candidate is a feasible repair for the corresponding location. As no grammar for the expressions is involved, this check is bounded complete. We call our approach \emph{variabilisation}, as it is based on replacing the buggy location by a variable of the corresponding type. To make sound pruning, we need to make our variabilisations \emph{context sentitive}. That is, instead of turning the above specification into (we are abusing the notation below):  


\section{Related Work}

The problem of automatically repairing software defects has received great attention in the last decade, and a variety of techniques have been proposed to tackle it, including generate-and-validate techniques (e.g., based on evolutionary computation \cite{LeGoues+2012} or other forms of search in the space of candidates), techniques based on patch synthesis (e.g., techniques that gather constraints for correct program behavior and produce patches from these \cite{Mechtaev+2016}) and techniques driven by data (e.g., techniques based on learning \cite{LongRinard2016}). The emphasis is largely targeted at \emph{programs}, rather than \emph{specifications}. As explained earlier in this paper, the context of formal specification has some significant differences with programs (source code), that render many of these techniques not applicable, or at least difficult to adapt, to repairing specifications. The problem of dealing with the explosion of repair candidates has been dealt with in different ways, in the context of automated program repair. Some approaches attempt to bring down the branching factor in the search space by using a single mutation (e.g., \cite{DBLP:conf/tacas/GopinathMK11}); others consider a very small set of mutators (e.g., based on patterns of human-written fixes \cite{Kim+2013}), or consider coarse grained mutations (e.g., no intra-statement program modifications \cite{LeGoues+2012}). Most of these approaches perform non-exhaustive heuristic searches, as opposed to our technique, that proposes safely pruning the search space.

Our technique produces fine-grained repair candidates that are akin to \emph{mutations} \cite{AmmannOffutt2008}, such as operator and operand replacements, etc., or more generally, combinations of mutations (as in higher order mutations in the context of mutation testing \cite{JiaHarman2009}). The motivation for this decision is based on a number of issues, that seem to impact the effectiveness of larger-grained modifications (such as the copying, deletion and swapping of whole expressions) as operations to build repairs in the context of specification (for instance, for the case studies presented in \cite{Wang+2019}, our manual inspection showed no case where one may repair the specification by deleting, swapping or copying whole expressions within the specification). Firstly, specifications do not seem to feature the same level of reuse that programs have. For instance, in text books on formal specification with more traditional languages such as Z \cite{DBLP:books/daglib/0072139} or B \cite{Abrial2005}, one does not see modularization mechanisms (e.g., schema/machine composition) being used for reuse across different specifications, with the exception of the reuse of some general purpose specifications of sets, sequences, etc. Rather, modularization mechanisms seem to be exploited mainly for specification organization, with little impact in reuse. Secondly, most declarative specification languages are order-insensitive (the order of declarations and statements is irrelevant, as opposed to operational languages, making order-changing modifications ineffective). Thirdly, specifications are significantly shorter than source code, and therefore less redundancy that could be exploited for repairs is observed. 

While most work on automated repair applies to programs, there are some notable exceptions \cite{Pei+2014,Wang+2018,Wang+2019}. The tool AutoFix \cite{Pei+2014} targets contract-equipped programs, and can produce repairs that make the programs satisfy their contracts (at least as far as a test suite can determine). The technique can modify contracts as well as the code itself, and therefore can be considered as a specification repair technique. The approach differs from ours in many respects: it applies to specifications at the source-code level, as opposed to the more abstract specifications we target in this paper; it is not constrained to specifications, it can indistinguishably alter programs and specifications; and the specification is \emph{not} the oracle for repair, the tests are. An approach closely related to ours, as it applies to Alloy specifications too, is ARepair \cite{Wang+2018,Wang+2019}. ARepair repairs faulty Alloy specifications by combining a number of techniques, including a technique for synthesis known as \emph{sketching} \cite{DBLP:journals/sttt/Solar-Lezama13}, and mutation-based repairs, as in program repair. ARepair can fix specifications with multiple buggy locations, and is able to do so considering a manageable set of candidates, thanks to an effective fault localization approach (and resorting to sketching rather than arbitrary mutations). In effect, ARepair is guided by its own fault localization approach, and the whole process is supported by Alloy \emph{tests}. Our approach, on the other hand, is not coupled with fault localization, and can use different techniques (e.g., \cite{DBLP:journals/corr/abs-1807-08707,Zheng+2021}, as long as they can be used with the fault localization oracle at hand) for fault localization. Alloy tests are similar to unit tests for source code: they provide specific scenarios with an expected outcome when evaluating specific parts of an Alloy specification, e.g., a predicate. The tool has been successfully applied to repair specifications taken from a benchmark of Alloy models \cite{Nelson+2017} very efficiently, by being combined with techniques for automated Alloy test generation (as tests are necessary for repair). As for program repair techniques which use tests as acceptance criteria, they are subject to \emph{overfitting}, the problem that arises when a candidate passes all tests, but is not a true repair, i.e., there are situations in which the program (in this case, specification) fails to comply with the intended behavior. This, as usual, is strongly related to the quality of the provided test suite, and many of the cases from \cite{Nelson+2017} were repaired thanks to additionally, manually provided, test cases \cite{Wang+2018,Wang+2019}. ARepair inherently depends on test cases, while our technique works on arbitrary Alloy specification oracles. See the previous section for a more detailed comparison of \technique\ with ARepair, from a more experimental point of view. 

Our technique uses Alloy counterexamples to weakly check variabilization feasibility, since fully checking feasibility requires dealing with higher-order quantification. To perform this higher-order checking, one may use Alloy* \cite{DBLP:journals/fmsd/MilicevicNKJ19}. We experimented with this approach, but due to performance issues, we favored our current counterexample-based mechanism. Also in this line, one may profit from Alloy* to capture Alloy's grammar and semantics into Alloy*, and use the solver to encode the whole repair approach. In this way, Alloy* would function as a synthesis engine, with the solver doing the search for repairs, as in some semantic program repair approaches (e.g., \cite{Mechtaev+2016}). In our initial attempts we did not manage to obtain results, due to the available heap space being exceeded, for fragments of Alloy's grammar significantly smaller than what we are considering with our ad-hoc search approach. We plan however to further investigate this possibility. 


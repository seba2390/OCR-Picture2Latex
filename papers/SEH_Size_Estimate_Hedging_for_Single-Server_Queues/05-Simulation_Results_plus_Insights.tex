\section{Simulation Results} \label{SimulationResultsplusInsights}
In this section, we evaluate the performance of the policies in Section \ref{PoliciesUnderEvaluation} by running experiments on both synthetic and real workloads. We run different simulations by generating synthetic workloads based on different job processing time and error parameters and we analyze these parameters' effect on the performance of each of the policies. 


For evaluating our results in practical environments, we consider a real trace from a Facebook Hadoop cluster in 2010 \cite{chen2012interactive} and show that the policies' performance is consistent with the results we obtained with synthetic workloads.
The key observations, validated both on synthetic and real workloads, are highlighted as follows:

\begin{itemize}
\item	The Gittins’ Index policy outperforms SERPT for all the evaluated values of $k$ and $\sigma$. We show the same observation with our proposed SEH policy except for values of $k$ that correspond to very low job processing time variance.
\item The Gittins’ Index and SEH policies outperform SEPT with lower values of $\sigma$ (better estimated processing times) and have an MST near the optimal MST obtained without any estimation errors. 
\item SEH performs well in reducing both the MST of overestimated jobs and underestimated jobs. 
\item	The load parameter does not have a significant effect on the relative values of the MST obtained with the evaluated policies.
\item	The Gittins' Index, SEH and SEPT policies have a near-optimal mean slowdown of 1 when the estimated processing
times have high variance.
\item	The SEH performs best across all values of $k$ in terms of minimizing the mean slowdown.

\end{itemize} 

In what follows, we discuss the numerical results and how they support these key observations. \\


\textbf{Synthetic Workloads} --- We first note that the job processing time $k$ parameter and the estimation error $\sigma$ parameter have the greatest impact on the policies' performance. Thus, we focus on varying these parameters. We show that the Gittins' Index policy outperforms SERPT across all evaluated values of $k$ and $\sigma$ and our SEH policy outperforms SERPT except for the values of $k$ and $\sigma$ that correspond to distributions with extremely low variance. For the scenarios where we do not state the parameter values explicitly, the parameters in Table \ref{tab:1} (see Section \ref{SimulationParameters}) are considered. 

Fig. \ref{fig:5ShapeMST} captures the impact of job processing time variance and displays the MST of the Gittins' Index, SEH, SERPT, and SEPT policies normalized against the MST obtained with SRPT with $\sigma$ having the default value of $0.5$. We observe that for a high variance job processing time distribution ($k = 0.25$), SERPT performs very poorly compared to the other policies due to the presence of large, underestimated jobs. We note that the SERPT policy performs well if the variance of the processing times is sufficiently low. Based on Fig. \ref{fig:5ShapeMST}, we notice that the gap between SEPT and the Gittins' Index policy grows slightly when the job processing time variance is lower. The gap between SEH and the Gittins’ Index policy also grows but not to the same degree as SEPT. For $k > 0.75$, the performance of the Gittins' Index policy, SEH, and SERPT are quite close. In fact, we observe that our SEH policy performs very close to the Gittins' Index policy across all values of $k$. Furthermore, we notice that as the variance in processing times gets smaller, the gap between what is achievable by the policy under evaluation and what is achievable if there were no errors is larger than for the high variance scenarios. 

\begin{figure}[ht]

  \includegraphics[width=100mm,scale=0.5]{Fig2.pdf}
  \centering
    \caption{Impact of $k$ on the MST}
  \label{fig:5ShapeMST}

\end{figure}







 
The shape parameter $k$ affects the job processing time variance and the scheduling policies' performance the most, especially when the job processing time distribution has high variance. We can be optimistic about using estimates if the variance is low, but we have to be careful in choosing the scheduling policy if the job processing time variance is high. The literature focuses on high variance workloads, and we will continue evaluating the policies on such workloads. In Fig. \ref{fig:25SigmaMST}, we display the normalized MST of the policies against the MST of the SRPT policy under varying $\sigma$, $ \rho = 0.9$, and the default $ k = 0.25$. We notice that the Gittins' Index, SEH, and SEPT policies are relatively insensitive to the $\sigma$ value, while the gap between these three policies and SERPT increases with increasing $\sigma$. In fact, the Gittins' Index and SEH policies outperform SEPT with $\sigma \le 0.5$ and have an MST near the optimal MST obtained without any estimation errors. We conclude that the impact of the Gittins' Index policy and SEH becomes more prominent when the estimates improve.




In Fig. \ref{fig:25SigmaMST}, we observe that while choosing a more aggressive policy like the Gittins' Index and SEH policies is a good choice under lower values of $\sigma$, SEPT is preferred when $\sigma = 1$. The reason is that lower values of $k$ (here, $k=0.25$), cause more large jobs in the system. Furthermore, for values of ${\sigma \ge 1 }$, the estimation errors have high variance and thus the estimated processing
times can be very imprecise. We notice that both SEH and the Gittins' Index policy suffer from a slight promotion of severely underestimated jobs that leads to temporary blockage for the other jobs. What has happened in this case is that the estimates of the processing times have degraded to the point that they are not useful. In particular, one should instead base scheduling decisions on the processing time distribution, so for example in scenarios with high variance in both processing times and estimation errors, a policy which ignores the estimates, such as Least Attained Service (LAS) would be warranted. The LAS scheduling policy \cite {rai2003analysis}, also known as Shortest Elapsed Time \cite {coffman1973operating} and Foreground-Background \cite{kleinrock1975theory}, pre-emptively prioritizes the job(s) that have been processed the least. If more than one job has received the least amount of processing time, the jobs will share the processor in a processor-sharing mode. Analytic results in \cite{righter1989scheduling} and \cite {yashkov1987processor} show that LAS minimizes MST when the job processing time distribution has a decreasing hazard rate and there are no processing time estimates available.

\begin{figure}[ht]

  \includegraphics[width=100mm,scale=0.5]{Fig3.pdf}
  \centering
    \caption{Impact of $\sigma$ on the MST}
  \label{fig:25SigmaMST}

\end{figure} 

These observations are consistent with the results in Table \ref{tab:2} which considers the same settings as in Fig. \ref{fig:25SigmaMST} when $\sigma = 1$ and $\sigma = 2$. SERPT has poor performance compared the other policies under $\sigma \ge 1$ and thus is not included. Pastorelli et al.\ \cite{pastorelli2013hfsp} show that lower values of $\sigma$ ($\sigma < 1$) are what one sees in practice. It would be interesting to look at the optimal Gittins' Index policy that includes both the job processing time and estimation error distributions, as it would capture this effect. Although doing so can help develop policies that are effective even at high values of $\sigma$, deriving the Gittins' index would be quite complicated with this extra condition, but it could give insight into designing simpler policies. 


\begin{table}[t]
\centering
\caption{Policies evaluation under $\sigma=1$ and $\sigma=2$}
\begin{tabular}{|p{2cm}|p{2.30cm}|p{2.30cm}|p{2.30cm}|p{2.30cm}|} 
\hline 
\multirow{2}{*}{} & \multicolumn{2}{|p{1.2cm}|}{$\bm{\sigma=1}$}  & \multicolumn{2}{|p{1.2cm}|}{$\bm{\sigma=2}$}  \\ \cline{2-5} 
\textbf{Policy} & MST/ MST(SRPT) & Mean Slowdown & MST/ MST(SRPT) & Mean Slowdown \\ \hline 
Gittins' Index & 1.45 & 1.26 & 2.68 & 6.78 \\ 
SEH & 1.44 & 1.22 & 2.71 & 6.87 \\ 
SEPT & 1.41 & 1.16 & 2.54 & 4.71 \\  
LAS & 1.81 & 1.27 & 1.81 & 1.27 \\  
SRPT & 1 & 1.06 & 1 & 1.06 \\ 
\hline 
\end{tabular}

\label{tab:2}
\end{table}







Fig. \ref{fig:25Shape5SigmaMST}, Fig. \ref{fig:25Shape5SigmaMSTOV}, and Fig. \ref{fig:25Shape5SigmaMSTUN} show the result of simulations with the default values in Table \ref{tab:1} and varying the system load between $0.5$ and $0.99$ for all jobs, only the overestimated jobs, and only the underestimated jobs, respectively. If we concentrate only on one class of jobs (overestimated or underestimated), the policy that minimizes the MST the most can be different. We observe that the Gittins' Index and SEH policies perform best in minimizing the overall MST given different system loads. The Gittins' Index policy performs best in reducing the MST of underestimated jobs and the SEH policy has desirable performance in reducing the MST of all jobs, the overestimated jobs, and the underestimated jobs. Fig. \ref{fig:25Shape5SigmaMST} shows that the load parameter does not have a significant effect on the MST since the ratio between the MST of each policy and the MST of SRPT remains almost unchanged.





\begin{figure}[t]
\centering
\subfigure[All jobs]{
\includegraphics[width=0.90\textwidth]{Fig4a.pdf}\label{fig:25Shape5SigmaMST}
}
\subfigure[Overestimated jobs]{
\includegraphics[width=0.47\textwidth]{Fig4b.pdf}\label{fig:25Shape5SigmaMSTOV}
}
\subfigure[Underestimated jobs]{
\includegraphics[width=0.47\textwidth]{Fig4c.pdf} \label{fig:25Shape5SigmaMSTUN}
}
\caption{\label{fig:whole} Impact of $\rho$  on the MST} 
\end{figure}



The mean slowdown is the other metric we consider to evaluate the performance of the policies. High values of mean slowdown indicate that some jobs spend a disproportionate amount of time waiting. In Fig. \ref{fig:25SigmaMSD}, we show the mean slowdown for different values of $k$ with $\rho = 0.9$ and a $\sigma$ value of $0.5$. The mean slowdown of SERPT is not included since it is several orders of magnitude higher for $k \le 0.5$. We see that the Gittins' Index, SEH, and SEPT policies have similar performance. All policies have a near-optimal mean slowdown of 1 for high variance job processing time distributions (smaller $k$). The reason is that the very small jobs (that make up the majority of the jobs) are processed the moment they enter the system, and no large job blocks them. We also observe that SEH performs best across all values of $k$ in terms of minimizing the mean slowdown.



\begin{figure}[ht]

  \includegraphics[width=100mm,scale=0.5]{Fig5.pdf}
  \centering
    \caption{Impact of $k$ on the mean slowdown}
  \label{fig:25SigmaMSD}

\end{figure}



We conclude our experiments with synthetic workloads by indicating that the Gittins' Index and SEH policies perform better than SERPT under different parameter settings. The only exception is extreme situations like the low variance job processing time distributions (larger $k$) where SERPT outperforms SEH and works analogously to the Gittins' Index policy. \\



\textbf{Real Workloads} --- We consider a Facebook Hadoop cluster trace from $2010$ \cite{chen2012interactive} and show that the results with this workload look very similar to those with synthetic workloads generated with $ k = 0.25$. The trace consists of $24,443$ jobs. We assume each job's processing time is the sum of its input, intermediate output, and final output bytes. The job processing times of this workload have high variance, and thus, we run hundreds of simulations to reach the desired confidence interval (as described in Section \ref{SimulationParameters}). We vary the error estimation distribution's $\sigma$ parameter to evaluate different scenarios of estimated processing
time precision. To maintain the default settings in Table \ref{tab:1}, we define the processing speed in bytes per second. The arrival rate $\lambda$ is chosen to yield the desired $\rho = 0.9$. A simulation run ends when the last job in the workload arrives at the system and we calculate the MST of the jobs that are fully processed among the first $10,000$ jobs that entered the system. Fig. \ref{fig:HadoopMST} shows the MST normalized against the optimal MST obtained with SRPT with varying $\sigma$ between $0.25$ and $1$. We observe that the Gittins' Index and SEH policies perform best across all values of $\sigma$.
\begin{figure}[ht]

  \includegraphics[width=100mm,scale=0.5]{Fig6.pdf}
  \centering
    \caption{MST of the Facebook Hadoop workload}
  \label{fig:HadoopMST}

\end{figure} 

In Fig. \ref{fig:HadoopMSD}, we display the mean slowdown obtained with the policies under evaluation. Similar to Fig. \ref{fig:25SigmaMSD}, we have not included the mean slowdown of SERPT since it is several orders of magnitude higher. We observe that for $\sigma \le 0.5$, where the estimates are better, the SEH policy has lower mean slowdown than the Gittins' Index and SEPT policies, however, SEPT starts to outperform the Gittins' Index and SEH policies when $\sigma$ increases, consistent with our observations for synthetic workloads. 




\begin{figure}[ht]

  \includegraphics[width=100mm,scale=0.5]{Fig7.pdf}
  \centering
    \caption{Mean slowdown of the Facebook Hadoop workload}
  \label{fig:HadoopMSD}

\end{figure}


\documentclass{article}

\title{Quantum algorithm for the classification of supersymmetric top quark events}

\author{Pedrame Bargassa$^{1,2}$, Timoth\'ee Cabos$^3$, Samuele Cavinato$^{4,5}$, \\
Artur Cordeiro Oudot Choi$^3$, Timoth\'ee Hessel$^3$}
\date{
  $^1$Physics of Information and Quantum Technologies Group, Instituto de
  Telecomunica\c{c}\稞弩涕筲镱酗螋蹒犰苘ま菠提怙蜥糗э蜷溴深篝蝓礤铘彳沱泯荥犸栖ч箝汜砒疱蜷礤铘犰溴嗅螋堙殂蹯狍涕筲镱酗螋蹒犰苘ま长语蜮镱铄疹轹弪箝糗у嗅蜷蟋乞犷沐苘ま搐拈疳螋轫孱麸溟崎箝汜馏趄镱镯獒噜钱轻扉戾椐К疹轹弪箝糗噌溟嗅滹鲠婶犰苘ま丹湾溟汜需箝泱腻疳蝽孱衄皱铄麸深篝轸豸镦项泔祜琦上汁梢妹蝇嗅滹鲠婶犰苘鄄屮荃箦疳汶徵妍犴箧镱趔ボ躞屦徙脶珏犴箜狒椠荃箦疳汶徵妍珧狃栝泺荃箦疳汶徵妍扉铄铒荃箦疳汶徵妍泔祜螨ボ躞屦徙脶珏棂疱蝌彐荃箦疳汶徵遨泔祜蜢轭塍趄蹂扉铍泔祜忪蹂躜煦镬矧忪蹂汩翦泔祜忪蹂犷汨矧泔祜忪蹂蓰棂疱蝌彐ボ扉铄铛礅弪荇镳磲蜱轭江爱点茱滗箝溴磲蜱轭爱沩苠鲥铙殇屙狎玳畎沩荇屮赭殇翳奖兜眄荇屮翳彘玷艚膊淀茯徵珏溻雉麸荏祜痧苕蝈钽梵疳汩铉茴鬻泔眄犷潲茕骝徙鄄蓰苕蜥沱茕轶痨狴篝戾１茕轶痨狴篝戾２茯孱鬻泔眄犷滠麸疰蜥泗轱铥碑茯孱鬻泔眄犷滠怙趑镯骝徙糸镱碑茯孱鬻泔眄犷滠骒镝麴徵彐蜥泗轱铥爱茯孱鬻泔眄犷滠翦翩蜥泗轱铥爱茴鬻泔眄犷潲茗茯蹯遨稠磔绊睚疙睚茴鬻泔眄犷潲莛酏苠铙躜屙狒棼疬茼狒栩睇札
\newcommand{\ptl}{\ensuremath{p_{\mathrm{T}}(l)}}
\newcommand{\etl}{\ensuremath{\eta(l)}}
\newcommand{\chl}{\ensuremath{Q(l)}}
\newcommand{\met}{\ensuremath{E_\mathrm{T}^\mathrm{miss}}}
\newcommand{\mt}{\ensuremath{M_{\mathrm{T}}}}
\newcommand{\Ht}{\ensuremath{H_{\mathrm{T}}}}
\newcommand{\jeti}[1]{\ensuremath{j_{#1}}}
\newcommand{\ptisr}{\ensuremath{p_{\mathrm{T}}(\jeti{1})}}
\newcommand{\njet}{\ensuremath{N(\mathrm{jets})}}
\newcommand{\nbl}{\ensuremath{N(b)}}
\newcommand{\ptb}{\ensuremath{p_{\mathrm{T}}(b)}}
\newcommand{\bdisc}{\ensuremath{\mathrm{Disc(b)}}}
\newcommand{\drLB}{\ensuremath{\Delta R (l, b)}}
\newcommand{\wjets}{\ensuremath{W+}jets}
\newcommand{\ttbar}{\ensuremath{\mathrm{t}\bar{\mathrm{t}}}}
\newcommand{\stp}{\ensuremath{\tilde{t}_{1}}}
\newcommand{\lsp}{\ensuremath{\tilde{\chi}_{1}^{0}}}
\newcommand{\dm}{\ensuremath{\Delta m}}

\begin{document}

\maketitle

\begin{abstract}

The search for supersymmetric particles is one of the major goals of the 
Large Hadron Collider (LHC). Supersymmetric top (stop) searches play a 
very important role in this respect, but the unprecedented collision rate 
to be attained at the next high luminosity phase of the LHC poses new 
challenges for the separation between any new signal and the standard 
model background. The massive parallelism provided by quantum computing 
techniques may yield an efficient solution for this problem. In this paper 
we show a novel application of the zoomed quantum annealing machine 
learning approach to classify the stop signal versus the background, and 
implement it in a quantum annealer machine. We show that this approach 
together with the preprocessing of the data with principal component 
analysis may yield better results than conventional multivariate 
approaches.

\end{abstract}

\section{Introduction}
\label{s:intro}

After attaining its nominal energy, the Large Hadron Collider (LHC) will 
reach an unprecedented collision rate during its high luminosity phase, 
opening the stage to discoveries beyond the standard model (SM) of 
particle physics. One of the most challenging tasks in searches taking 
place at the LHC is the capacity to categorize events of new phenomena 
(signal) and those of SM processes (background) which mimic the signal. 
Machine learning (ML) tools are among the most powerful means for 
separating signal from background events, having been key to the discovery 
of, e.g., the Higgs boson \cite{HgDisc1,HgDisc2}. More recently, 
quantum annealing for machine learning (QAML) \cite{nature} and its 
zooming variant (QAML-Z) \cite{qamlz} represent the first examples of a 
quantum approach to a classification problem in high energy physics (HEP).

In this paper, we study the application of the QAML-Z algorithm to
the selection of supersymmetric top quark (stop) versus SM events. It is
important to test this algorithm on a new classification problem where
both the abundance of signal versus background events, and their overlap
in the experimental observables are different from\cite{qamlz},
therefore allowing us to have a better assessment of its classification
capability.
A result on the stop search based on the data accumulated by the LHC in 
2016 (35.9 fb$^{-1}$) has been published\cite{st4bd}. It is based on a 
classical ML tool which will serve as a reference for gauging the 
performance of the new classifiers. The variables discriminating between 
the stop signal and the SM background, which are used to train the QAML-Z 
algorithm, are based on the same ones as in the classical ML tool 
\cite{st4bd}. We present results of the QAML-Z algorithm for different 
schemes of zoomed quantum annealing, and various sets of variables used in 
the annealer. Also, we introduce a preprocessing of the data through a 
principal component analysis\cite{pca} (PCA) before feeding it to the 
annealer.

\section{Search for supersymmetric top quark}
\label{s:stop}

One of the main objectives of the physics program at the LHC are searches 
for supersymmetry (SUSY)\cite{SUSY0,SUSY1,SUSY2,SUSY3,SUSY4,Martin}, one 
of the most promising extensions of the SM. SUSY predicts superpartners of 
SM particles (sparticles) having the same gauge interactions, and whose 
spin differs by one-half unit with respect to their SM partners. The 
search for SUSY has special interest in view of the recent discovery of a 
Higgs boson \cite{HgDisc1,HgDisc2} as it naturally solves the problem of 
quadratically divergent loop corrections to the Higgs boson mass. In this 
study we describe the classification aspect of a search for the pair 
production of the lightest supersymmetric partner of the top quark \stp at 
the LHC machine at $\sqrt{s}$ = 13 TeV, where each stop decays in four 
objects, see Fig.\ref{fig:4bod}. The lightest neutralino \lsp is 
considered to be stable as the lightest supersymmetric particle. The final 
states considered contain jets, missing transverse energy (\met), and a 
lepton which can be either a muon or an electron.

\begin{figure}[!htbp]
\begin{center}
\includegraphics{plots/T24bd.pdf} 
\end{center}
\caption{Stop pair production at the LHC with four-body decays.}
\label{fig:4bod}
\end{figure}

The sensitivity of this type of search is dominated by the capacity to 
distinguish the stop signal from background events, whose production 
dominates the signal by several orders of magnitude, and whose observables 
overlap with the ones of the stop signal. In this search, the main 
background processes are the \ttbar and \wjets productions. In the search 
based on a classical ML tool\cite{st4bd}, a preselection is first 
applied to decrease the overwhelming background stemming from the SM. In a 
second stage, boosted decision trees (BDTs)\cite{RefBDT,tmva} are used to 
classify events as signal and background. To find which variables are the 
most discriminating and should be fed as input to the BDT, different sets 
of variables are tested as input to a BDT whose output is used to maximize 
a figure of merit (FOM)\cite{fom}:
\begin{eqnarray}
  \mathrm{FOM} & = & \sqrt{ 2 \Big( (S+B)\ln\Big[\frac{(S+B)\cdot(B+\sigma_B^2)}{B^2 + (S+B)\cdot\sigma_B^2}\Big] 
    - \frac{B^2}{\sigma_B^2}\ln\Big[1 + \frac{\sigma_B^2 \cdot S}{B \cdot (B+\sigma_B^2)}\Big] \Big) },
\label{eq:fom}
\end{eqnarray}
where $S$ and $B$ respectively stand for the expected signal and 
background yields for an integrated luminosity of 35.9 fb$^{-1}$ at the 
LHC. The term $\sigma_B = (f \cdot B)$ represents the expected systematic 
uncertainty on the background with $f$ being the relative uncertainty of 
the background yield, taken to be $f=20\%$ as in\cite{st4bd}. The set of 
variables which maximize the FOM is chosen as the final set of input
variables to the BDT. This metric captures the full information of the 
statistical and systematic uncertainties of a given selection, as it is
important to account for the actual conditions of a search.
The approach based on the maximization of this FOM has been very effective
to find the smallest and most efficient set of discriminating variables
in several searches\cite{st4bd,st8tev}. A description of the BDT parameters
as well as its development with a FOM maximization procedure as used
in\cite{st4bd} are provided in Appendix\ref{s:pb16}. The list of variables
is presented in Table\ref{tab:vars} and their distribution for signal and
background is provided in Fig.\ref{fig:vardm}. To render the results of
the classification based on the QAML-Z algorithm as comparable as possible
to the one of\cite{st4bd}, we use the same preselection of events before
training (see Appendix \ref{s:pb16}). Furthermore, since the FOM as defined
in Eq.\ref{eq:fom} represents a complete and single-number measure of the
power of a selection, we evaluate the performance of the QAML-Z algorithm
by a maximization of the FOM versus a cut on its output. Finally, for the
comparison of performances to reflect only the difference of a quantum based
versus a classical tool, we train the QAML-Z algorithm with different sets 
made of the same discriminating variables as in the BDT based search 
\cite{st4bd} (see Table\ref{tab:vars}).

\begin{table}[!htbp]
\begin{center}  
\begin{tabular}{|l|l|}
\hline
\hline
Variable & Description \\
\hline
 \ptl & \pt of the lepton $l$ \\
 \etl & Pseudorapidity of the lepton $l$ \\
 \chl & Charge of the lepton $l$ \\
 \met & Missing transverse energy \\
 \mt  & Transverse invariant mass of \\
      & the (\met,\ptl) system \\
 \njet & Multiplicity of selected jets \\
 \ptisr & \pt of the leading jet \\
 \Ht & $\sum_i p_\mathrm{T}(jet(i))$ \\
 \bdisc & Maximum b-quark tagging discriminant of the jets \\
 \nbl & Number of b-tagged jets \\
 \ptb & \pt of the jet with the highest \\
      & b-discriminant \\
 \drLB & Distance between the lepton and the \\
       & jet with the highest b-discriminant \\
\hline
\hline
\end{tabular}
\caption{List of discriminating variables used as input to a BDT in\cite{st4bd}.}
\label{tab:vars}
\end{center}
\end{table}

\begin{figure}[!htbp]
\begin{center}
\includegraphics[scale=0.21]{plots/DMv_LepPT.pdf}
\includegraphics[scale=0.21]{plots/DMv_LepETA.pdf}
\includegraphics[scale=0.21]{plots/DMv_LepCHG.pdf} \\
\includegraphics[scale=0.21]{plots/DMv_MET.pdf}
\includegraphics[scale=0.21]{plots/DMv_MT.pdf}
\includegraphics[scale=0.21]{plots/DMv_Njet.pdf} \\
\includegraphics[scale=0.21]{plots/DMv_Jet1PT.pdf}
\includegraphics[scale=0.21]{plots/DMv_HT.pdf}
\includegraphics[scale=0.21]{plots/DMv_CSVb.pdf} \\
\includegraphics[scale=0.21]{plots/DMv_Nbloose.pdf}
\includegraphics[scale=0.21]{plots/DMv_JetHBPT.pdf}
\includegraphics[scale=0.21]{plots/DMv_dRlb.pdf}
\end{center}
\caption{Distribution of the discriminating variables for the stop
  signal with $\Delta m = 30$, \wjets and \ttbar, used as input to a BDT in 
  \cite{st4bd}. From top-left to bottom-right: \ptl, \etl, \chl, \met, \mt,
  \njet, \ptisr, \Ht, \bdisc, \nbl, \ptb, \drLB. Distributions are normalized
  to the same area and shown at preselection.}
\label{fig:vardm}
\end{figure}

\section{Quantum annealing and zooming}
\label{s:qamlz}

From the distribution of each variable $i$ in signal and background events,
we construct a weak classifier $\chi_i$ as in\cite{nature} which retains
the discriminant character of each variable while adapting it to an annealing
process. We then construct an Ising problem as follows. For each training event
$\tau \in [1,S]$, we consider the vector $x_{\tau}$ of the values of each variable
of index $i$ we use, and a binary tag $y_{\tau}$ labeling the event $\tau$ as
either signal ($+1$) or background ($-1$). The value of the $i$th weak classifier
for the event $\tau$ is given by the sign of the corresponding weak classifier
$\chi_i$: $c_i(x_{\tau})=\mathrm{sgn}(\chi_i(x_{\tau}))/N=\pm1/N$, where $N$ is the number
of weak classifiers. In the QAML algorithm, the optimization of the signal-background 
classification problem is expressed in terms of the search for the set of spins
$s_i$ minimizing the Ising Hamiltonian:
\begin{eqnarray}
  H_{\mathrm{Ising}} & = & \sum\limits_{i=1}^{N} h_i s_i
  + \sum\limits_{i=1}^{N}\sum\limits_{j>i}^{N} J_{ij} s_i s_j \nonumber \\
  & = & \sum\limits_{i=1}^{N} \Big(\lambda - C_i + \frac{1}{2}\sum\limits_{j>i}^{N} C_{ij}\Big) s_i
  + \frac{1}{4}\sum\limits_{i=1}^{N}\sum\limits_{j>i}^{N} C_{ij} s_i s_j 
\label{eq:His}
\end{eqnarray}
where $h_i$ is the local field on spin $s_i$, and $J_{ij}$ is the coupling 
between spins $s_i$ and $s_j$. The factor $\lambda$ is a regularization constant, and 
the terms $C_i$ and $C_{ij}$ are defined as function of weak classifier 
values and event tags as:
\begin{eqnarray}
  C_{i} = \sum\limits_{\tau=1}^{S}c_i(x_{\tau})y_{\tau}, &
  C_{ij} = \sum\limits_{\tau=1}^{S}c_i(x_{\tau})c_j(x_{\tau}).
\label{eq:ci}
\end{eqnarray}
A strong classifier $R$ is then built as a linear combination of all weak 
classifiers and the spins, merging for each event the discriminating power 
provided by all $c_i$'s and the spins $s_i$ obtained from the quantum 
annealing process. The minimization of the classification error is 
performed by the minimization of the Euclidean distance between the binary 
tag of each event and its classification $R$ as obtained by the annealing:
\begin{eqnarray}
  || y - R ||^2 & = & \sum\limits_{\tau=1}^{S} |y_{\tau} - \sum\limits_{i=1}^{N} s_i c_i(x_{\tau})|^2.
\label{eq:norm}
\end{eqnarray}
In the QAML-Z approach, the quantum annealing is operated iteratively 
while a substitution is made to the spin $s_i$:
\begin{eqnarray}
s_i & \longrightarrow & \mu_i(t) + s_i \cdot \sigma(t) = \mu_i(t+1),
\label{eq:subs}
\end{eqnarray}
where:
\begin{itemize}
\item $\mu_i(t)$ is the mean value of qubit $i$ at time $t$. We have: 
$\forall i$ $\mu_i(0)=0$.
\item $\sigma(t)$ is the search width at each annealing iteration $t$. We 
have: $\sigma(t)=b^t$ where $b=\frac{1}{2}$ and $t \in [0,T-1]$.
\end{itemize}
This iterative procedure effectively shifts and narrows the region of 
search in the space of spins. It updates the vector $\mu_i$ which is 
collected at the final iteration to form the strong classifier:
\begin{eqnarray}
  R(x_{\tau}) & = & \sum\limits_{i=1}^{N} \mu_i(T - 1) c_i(x_{\tau}),
\label{eq:R}
\end{eqnarray}
where the use of the weak classifiers is not limited to the binary choice 
$\{0,1\}$, but is extended to the continuous interval $[-1,1]$ via the use 
of the vector $\mu_i$. The classification capacity of the QAML-Z algorithm is 
further enhanced by an augmentation scheme applied on the weak 
classifiers. For each $h_i$, several new classifiers $c_{il}$ are created:
\begin{eqnarray}
  c_{il}(x_{\tau}) & = & \frac{\mathrm{sgn}(h_i(x_{\tau}) + \delta l)}{N} ,
\label{eq:aug}
\end{eqnarray}
where $l \in \mathbb{Z}$ is the offset: $-A \leq l \leq A$, and $\delta$ 
is the step size. While the value $c_i$ of the old classifier has only a 
binary outcome for each $h_i$, the new classifiers $c_{il}$ have similar 
but $(2A+1)$ different outcomes depending on the very distribution of 
$h_i$. We therefore have a better discrimination because a more 
continuous, thus more precise representation of the spectrum of $h_i$ with 
$c_{il}$ than with $c_i$. Applying the substitution of Eq.\ref{eq:subs} 
in Eq.\ref{eq:norm}, omitting spin independent and quadratic self-spin 
interaction terms, and defining new indices $I$ as $\{il\}$ and $J$ as 
$\{jl'\}$, we obtain the Hamiltonian (see Appendix\ref{s:hder}):
\begin{eqnarray}
  H(t) = \sum_{I=1}^{N(2A+1)}\left( -C_I + \sum_{J=1}^{N(2A+1)}\mu_J(t) C_{IJ}\right)\sigma(t) s_I
  + \frac{1}{2}\sum_{I=1}^{N(2A+1)}\sum_{J\neq I}^{N(2A+1)} C_{IJ}\sigma^2(t)s_I s_J, 
\label{eq:Hta}
\end{eqnarray}
with:
\begin{eqnarray}
  C_{I} = \sum\limits_{\tau=1}^{S}c_{il}(x_{\tau})y_{\tau}, &
  C_{IJ} = \sum\limits_{\tau=1}^{S}c_{il}(x_{\tau})c_{jl'}(x_{\tau}).
\label{eq:cia}
\end{eqnarray}
The terms $C_I$ and $C_{IJ}$ are the input to the classification problem. 
The Hamiltonian $H(t)$ is iteratively optimized for $t$, with the vector 
$\mu_I$ updated similarly to Eq.\ref{eq:subs}. The information about the 
iterative quantum annealing, corresponding parameters, and control results 
are provided in Appendix \ref{s:qas}, where we ensure that the Ising model 
energy decreases and stabilizes for the chosen parameters. The output of 
the optimization procedure is a strong classifier built as in 
Eq.\ref{eq:R}, and whose distribution is used to discriminate signal from 
background.

\section{Classification of stop with the QAML-Z algorithm}
\label{s:qastop}

As in \cite{st4bd}, only the main background processes \wjets and \ttbar 
are used for training the QAML-Z algorithm. To realistically represent the 
SM in the training, a background sample is formed where events of these 
two processes are present proportionally to their production rate at the 
LHC. We divide this sample in two equal parts, one being used by the 
QAML-Z algorithm and one to assess the performance of the strong 
classifier through the maximization of the FOM: 
N(Sample)=N($QA$)+N(Assess). The $QA$ sample is further divided in two 
equal parts, one to train the annealer and another one to test for 
over-training in the annealer: N($QA$)=N(Train)+N(Test). It should be 
noted that only the Train sample is involved in the annealing process. 
Having shown \cite{st4bd} that the kinematic properties of all signal 
points $(m(\tilde{t}_{1}),m(\tilde{\chi}_{1}^{0}))$ are quasi identical 
along the line $\Delta m = m(\tilde{t}_{1}) - m(\tilde{\chi}_{1}^{0})$, we 
use all signal events with $\Delta m = 30$ except the signal point 
$(550,520)$ as $QA$ sample, while entirely using this latter signal as 
Assess sample. This organization of samples allows the usage of a maximal 
number of both signal and background events for assessing the performance 
of the classification as well as testing the annealing process.

The data is run on the $2000Q$ quantum annealer of D-Wave Systems Inc. 
\cite{dwave}, where the time to solution is $O(\mu s)$, 
\emph{ie.} the time of the annealing (see Appendix \ref{s:qas}). This 
computer is based on the Chimera graph which has 2048 qubits and 5600 
couplers. To embed the Ising Hamiltonian in the annealer, qubits of the 
graph are ferromagnetically coupled into a chain to represent a single 
spin of the Hamiltonian $H(t)$. While the Hamiltonian in Eq.\ref{eq:Hta} 
is fully connected, the Chimera graph is not, thus limiting the hardware 
implementation of the classification problem. The number of $J_{ij}$ 
couplers is given by: $N(J_{ij})=N_{\mathrm{v}}\cdot(N_{\mathrm{v}}-1)/2$ 
with $N_{\mathrm{v}}=N_{\mathrm{var}}\cdot(2A+1)$, where 
$N_{\mathrm{var}}$ is the number of variables used to train the QAML-Z 
algorithm, and $A$ is a parameter of the augmentation scheme (see 
Eq.\ref{eq:aug}). Given the number of variables and the augmentation 
schemes used, the limit of 5600 couplers can be exceeded by $N(J_{ij})$; 
typically, for $N_{\mathrm{v}}$=12 and for an augmentation with $A$=5, the 
needed number of couplers is 8646. We therefore prune the elements of the 
$J_{ij}$ matrix, retaining the largest $(1-C)$ elements, where $C$ is a 
cutoff percentage. Different cutoff values are expected to optimize the 
performance for different sets of variables and different augmentations 
schemes ($A, \delta$). As a further option to reduce the size of the Ising 
model to be encoded on the annealer, we use the polynomial-time variable 
fixing scheme of the D-Wave API. This scheme is a classical procedure to 
fix the value of a portion of the input variables to values that have a 
high probability of being optimal. An illustration of the effect of the 
cutoff $C$, the use of variable fixing, and the augmentation scheme is 
given in Appendix \ref{s:qas}.

In order to compare the performance of a quantum annealing with a 
classical ML counterpart, we explore various $settings$ of the QAML-Z 
algorithm, namely different augmentation schemes, cutoffs, and variable 
fixing options, reporting only the performance of the best setting for 
each tested set of variables (see Sec.\ref{s:res}). Despite averaging 
out the random errors on the annealing and mitigating the possible effects 
of overfitting due to zooming (see Sec.\ref{s:qamlz}), the outcome of 
the annealing (the vector $\mu_I$) can vary due to the probabilistic 
nature of these schemes and to the variations of the machine itself (e.g. 
low-frequency flux noise of the qubits), leading to an uncertainty on the 
performance. In order to estimate this uncertainty, we run the annealing 
ten times with the same input variables, in the very same setting, and on 
the same sample of events, and we consider the standard deviation of the 
corresponding maximal FOMs as uncertainty of the performance for a given 
set of variables and setting. In Fig.\ref{fig:fom15} we report the 
performance of the QAML-Z algorithm with the variables of 
Table\ref{tab:vars} as input and with a given augmentation scheme and 
cutoff as a function of the number of events used in the training. The 
performance of the annealer increases with N(Train), witnessing a clear 
rise for rather small number of events and a more moderate increase for 
larger numbers of events, confirming the results of\cite{nature} with 
another signal. Henceforth, we will present all results for 
N(Train)=N(Test)=50$\cdot$10$^3$ where signal and background events 
respectively represent 40\% and 60\% of these two samples. We therefore 
benefit from a large sample size to train the QAML-Z algorithm, while 
observing a quasi identical evolution of the Hamiltonian energy for the 
Train and Test samples (see Fig.\ref{fig:enwf15} in Appendix 
\ref{s:qas}). The Assess sample contains approximately 200$\cdot$10$^3$ 
background, and 7$\cdot$10$^3$ signal events. In Fig.\ref{fig:plots15} we 
present the distribution of the strong classifier for signal, and the two 
main background processes. As can be observed, there is no over-training 
of the QAML-Z algorithm because the response of the strong classifier is 
statistically very similar for events which are used to train the annealer 
and those not exposed to the training. Also shown in 
Fig.\ref{fig:plots15} is the evolution of the FOM in the Assess sample as 
function of the cut applied on the output of the strong classifier. 
Henceforth, all the reported values of maximal FOM are checked to 
correspond to a cut where there are enough events in both signal and 
background samples.

\begin{figure}[!htbp]
\begin{center}
\includegraphics[scale=0.28]{plots/FOMevt.png}
\end{center} 
\caption{Evolution of the FOM as a function of the number events used for
  training. The QAML-Z algorithm uses the variables of Table\ref{tab:vars} transformed
  in weak classifiers, with an augmentation scheme of ($\delta$,$A$)=(0.025,3),
  and with a cutoff $C$=85\%, without using a variable-fixing procedure.}
\label{fig:fom15}
\end{figure}

\begin{figure}[!htbp]
\begin{center}
\includegraphics[scale=0.5]{plots/StrgPred_WG14_50000_8_T2De.pdf}
\includegraphics[scale=0.5]{plots/StrgPred_WG14_50000_8_Wjet.pdf} \\
\includegraphics[scale=0.5]{plots/StrgPred_WG14_50000_8_TT.pdf}
\includegraphics[scale=0.5]{plots/fom_WF15_50000_8_fold1.pdf}
\end{center} 
\caption{The output of the strong classifier for the signal (top-left),
  \wjets (top-right) and \ttbar background (bottom-left) in the train
  (orange) and test (blue) events within the $QA$ sample. The evolution
  of the FOM as a function of the cut applied on the strong classifier's
  output is illustrated in the plot in the bottom-right. The QAML-Z algorithm uses
  the variables of Table\ref{tab:vars} transformed in weak classifiers,
  with an augmentation scheme of ($\delta$,$A$)=(0.025,3), and with a
  cutoff $C$=85\%, without using a variable-fixing procedure. The number
  of events used for training is N(Train)=50$\cdot$10$^3$.}
\label{fig:plots15}
\end{figure}

\section{Approaches and results}
\label{s:res}

We define the main sets of tested variables in Table\ref{tab:varset}. For each
set and the different approaches to test it, we perform an extensive study of
the performance of the QAML-Z algorithm for different augmentation schemes,
cutoffs, and the use (or not) of variable fixing, as illustrated for the sets
A and B respectively in Fig.\ref{fig:fomA} and\ref{fig:fomB} of Appendix
\ref{s:qas}. For each set and approach, we report the optimal setting and the
corresponding performance in Table\ref{tab:fomAll}.

The set $\alpha$ contains the variables defined in Table\ref{tab:vars} 
where the discriminating variables are not transformed into weak 
classifiers, being only normalized to the [$-1$,$+1$] interval. The set 
$\beta$ consists of the same variables where these are transformed into 
weak classifiers. As can be seen in Table\ref{tab:fomAll}, the 
performance of the set $\beta$ is expectedly higher than for the set 
$\alpha$, where the weak classifiers are scaled as a function of the 
initial distribution of the discriminating variables to better reflect the 
separation between signal and background. The transformation into weak 
classifiers is performed for all subsequent tests.

We explore in a second step the effect of additional discriminating 
variables built from the same initial set of Table\ref{tab:vars}. The 
methodology followed to built these new variables in explained in Appendix 
\ref{s:advar}, where the discriminating power of each variable is 
appraised via its maximal FOM. Two new sets of variables are constructed 
based on these new variables, as reported in Table\ref{tab:varset}: the 
set A including the variables of the Table\ref{tab:vars} and new 
variables with the highest FOMs, and the set B including those of set A 
and additional variables with the lower FOMs (see Table\ref{tab:varnew}). 
As can be observed in Table\ref{tab:fomAll}, the addition of variables 
with higher maximal FOMs in the set A increases the performance of the 
QAML-Z algorithm, while the further addition of variables with lower FOM in
the set B does not significantly improve the quality of the classification.

The results of the search\cite{st4bd} are based on the use of BDT where 
the discriminating variables are diagonalized before being fed to the 
training\cite{RefBDT,tmva}. This step better prepares the data for 
classification because the original discriminating variables do not 
necessarily constitute the optimal basis in which signal and background 
are optimally separated. In order to render our approach as comparable as 
possible to the one followed with a BDT\cite{st4bd}, we pass our data 
through the procedure of PCA\cite{pca} before feeding it to the QAML-Z
algorithm. It must be noted that the use of PCA is only one method for
diagonalizing the data, other methods also being applicable to this end.
The application of PCA on the data before the quantum annealing further
improves the results for the set of variables A, and to a lesser extent
for B, as can be seen in Table\ref{tab:fomAll}. We note a larger uncertainty
of the QAML-Z algorithm where the data is prepared with the PCA, this for
the same sets of variables. In the PCA basis, the weak classifiers are
more decorrelated from each other, rendering the corresponding weights
$\mu_I$ more independent from one another. When a $\mu_I$ fluctuates (e.g.
because of the state of the machine), the strong classifier $R$
(see Eq.\ref{eq:R}) is sensitive to the variations of a larger number of
$\mu_I$'s, hence a larger variation of its outcome. It is noticeable that
the QAML-Z algorithm, once put on a footing as similar as possible to the
BDT based approach\cite{st4bd}, can reach an equivalent, possibly better
performance. It is interesting to observe that the best result is achieved
without using the variable fixing scheme, where the annealing is put at
full use.

\begin{table}[!htbp]
\begin{center}  
\begin{tabular}{|l|l|l|}
\hline
\hline
Variable & List of   & Use of weak \\
set name & variables & classifiers \\
\hline
 $\alpha$ / $\beta$ & Table\ref{tab:vars} & No / Yes  \\
 A  & Table\ref{tab:vars} and:  & Yes  \\
    & \ptl/\met, \ptl/\ptisr, & \\
    & (\bdisc$-$1)\ptb,  & \\
    & $|$(\met$-$280)(\mt$-$80)$|$ , & \\
    & $|$(\met$-$280)(\Ht$-$400)$|$ & \\
 B  & Variables of set A and: & Yes \\
    & \drLB$-$ (\mt/40) , & \\
    & \Ht$^2$/\njet, \pt$+$ 3.5$\eta(l)^2$ , & \\
    & \pt/\Ht & \\
\hline
\hline
\end{tabular}
\caption{Definition of different variable sets as a function of the used 
  variables.}
\label{tab:varset}
\end{center}
\end{table}

\begin{table}[!htbp]
\begin{center}  
\begin{tabular}{|l|c|c|c|c|c|}
\hline
\hline
Variable  & Fixing   & $C$ [\%] & ($\delta$,$A$) & FOM \\
  set     & variable &          &                &     \\
\hline
 $\alpha$ & False & 85 & (2.50$\cdot$10$^{-2}$,3) &  0.48 $\pm$ 0.03 \\
 $\beta$  & False & 85 & (2.50$\cdot$10$^{-2}$,3) &  0.73 $\pm$ 0.03 \\
 A        & True  & 95 & (0.90$\cdot$10$^{-2}$,5) &  0.88 $\pm$ 0.04 \\
 B        & True  & 85 & (0.70$\cdot$10$^{-2}$,3) &  0.91 $\pm$ 0.05 \\
 PCA(A)   & False & 95 & (1.45$\cdot$10$^{-2}$,3) &  1.57 $\pm$ 0.24 \\
 PCA(B)   & True  & 95 & (0.70$\cdot$10$^{-2}$,5) &  1.09 $\pm$ 0.17 \\
\hline
 BDT      & NA    & NA & NA        &  1.44 $\pm$ 0.06 \\
\hline
\hline
\end{tabular}
\caption{Best performance obtained for different sets of variables as defined
  in Table\ref{tab:varset}, and for different approaches applied on some sets.
  The corresponding use (or not) of variable fixing, cutoff and augmentation
  scheme are reported. All results are provided for N(Train)=50000. For
  comparison, the performance of the BDT of\cite{st4bd} is also reported,
  where ``NA'' stands for nonapplicable.}
\label{tab:fomAll}
\end{center}
\end{table}

\section{Summary}
\label{s:conc}

We studied the capability of the quantum annealing, where the zoomed and
augmented QAML-Z approach is applied to a new classification problem, namely
the discrimination of stop versus SM background events. The classification
is based on well motivated variables whose discriminating power has been
tested with a FOM maximization procedure. The use of this latter metric
constitutes a novel and reliable assessment of the performance of a selection
as it includes its full statistical and systematic uncertainties. We
systematically tested each set of variables used by the QAML-Z algorithm
for different augmentation schemes and percentages of pruning on
the couplers of the annealer as to find the optimal setting. The performance
of different settings is assessed for large training samples which are
observed to yield the best performances, and are also more adapted to the
needs of experimental particle physics where very large data samples are
used. We observe an improvement of the classification performance when
adding variables with a high FOM. To put the annealing approach and the
classical BDT approach on the same footing, we pass the data through a PCA
procedure before feeding it to the quantum annealer. For the first time in
HEP, we show that for large training samples the QAML-Z approach running on
the Chimera graph reaches a performance which is at least comparable to the
best-known classical ML tool. With more recent graphs there is the prospect that the
larger number of connected qubits will yield a better correspondence between
the Ising Hamiltonian and the system of qubits of the annealer. The larger
number of available couplers in the machine will allow a more complete use
of the information contained in the couplers of the Hamiltonian; it will
render each chain more stable, thus less prone to be broken, where the
discriminating information of the classification will be more effectively used.

\section*{Acknowledgements}

We acknowledge the authors of \cite{nature,qamlz} for their help which has 
been key for this study. We specially thank the Center for Quantum 
Information Science \& Technology of the University of Southern California 
in Los Angeles for granting us access to the $2000Q$ quantum annealer of 
D-Wave Systems Inc. \cite{dwave}. P.B. thanks the support from 
Funda\c{c}\猃疳蜥瞄苻妪钽獒藻泐镬镧獒ㄐ矧趱玑飑钺礤禊翳蝻蹒痱镪邈丈穆蛋鞍腐舶舶狍麇祆狍骝镯痱镪邈ぱ踽铘扰肖ぱ踽铘蹴っ镯瘐糸铉び镬豸轱铙ゆ矧と殓瑜づ铄蜱ば棂箝泱が篚痧矧翦怡翳耪炔安氧犷襞伊乓廖旁蔑骢钿轭氧犷趱藻汨铒祜玳弩犷怡泼ㄇ蜥铘物氧犷襞伊鞍氨舶惫┊茆殁扉镧蜥痂篝戾痨衢铨茆彗轭翳邂殁扉镧蜥痂过茆殁轸屙如拈筱饼赢描狒蜚棂犷荑蝈纣梏麴蠛滹楫矧绡卑卑倍戤痂箪弭猱舶辈案安饼需螽体趑荇屮翕纣繁洱嘲ú氨博茆殁轸屙如拈筱昌钱玲洮荑蝈纣梏麴蠛滹楫矧绡卑卑倍戤痂箪弭猱舶辈案安褒需螽体趑荇屮翕纣繁洱ú氨博茆殁轸屙钺趱蝈廉惋趑荑蝈纣梏麴蠛滹楫矧绡卑卑掣钺趱蝈泊按俘吾趱蝈荇屮翕纣档褒撤ú氨珐茆殁轸屙襻盱廉陟镫狃岈荑蝈纣梏麴蠛滹楫矧绡卑北俺需笠弼廉卑伯岸泊暗需螽义霎荇屮翕纣卑昌岸泊暗ú安癌茆殁轸屙篝粹潺赢描狒蜚棂犷荑蝈纣梏麴蠛滹楫矧绡卑卑胺嗜判肮ú氨俯岸谍十乳玷蓬弪琦需螽荇屮翕纣肮岸ú氨俯茆殁轸屙疸猃十予戾铙荑蝈纣梏麴蠛狎轹矧绡徕蟑贝按北鞍狎亻龊贝按北鞍茆殁轸屙诱淤褒十族篌荑蝈纣梏麴蠛滹楫矧绡卑卑倍暗蛋巢背ǚ穿拱车淡饼熙沆遽需螽荇屮翕纣路褒彻ū狗穿茆殁轸屙诱淤饼耶箩蜮殄蜷荑蝈纣梏麴蠛滹楫矧绡卑卑倍俺钒捕钩ǜ博拱陡淡昌需螽体趑荇屮翕纣卤惫炒ū垢博炒钞茆殁轸屙诱淤昌犬袭伍祆弩荑蝈纣梏麴蠛滹楫矧绡卑卑倍俺钒钡烦ǜ穿拱鞍腑谍需螽义甬荇屮翕纣北褒ū垢穿茆殁轸屙诱淤除犬女柔忮颥荑蝈纣梏麴蠛滹楫矧绡卑卑倍俺钒钡烦ǜ旦拱暗杯饼需螽义甬荇屮翕纣北俘返ū垢旦茆殁轸屙诱淤待赢尼黧镱荑蝈纣梏麴蠛滹楫矧绡卑北俺需笠弼漠潮钡副需螽义霎荇屮翕纣潮钡副ū垢旦茆殁轸屙歪螋轭十挟歪螋轭荑蝈纣梏麴蠛滹楫矧绡卑北床狗腹副哺彻兜奋甙鞍饼狎亻龊狗肮车懂茆殁轸屙义媛脑坍绎脶汨犷袭歪祉镱つ狒幛ね轭轭绀鏖翳つ邈轶轱瞍ぴ蝈弩氦ぴ桢矧め钿ち痧扉汜糸镱螭ㄗ矧熹鱼殄铘殒殂娱铉狃矧瀣舶案┈捎挛狗腑垢杯卜翻狈杯碑茆殁轸屙繇鲠犬诛篌序镢鱼楫撩猎舶胺ú鞍珐按爱茆殁轸屙骘睚钱蔑麽瞵水抿犷礤颥女球矬蟋犷袭珠翦祆蟋荑蝈纣梏麴蠛滹楫矧绡卑北窗屦赉蟊鞍挡氨杯钡荡褒捧虍需螽十荇屮翕纣繁钡荡ú氨暴茆殁轸屙篝隔弼赢描狒蜚棂犷荑蝈纣梏麴蠛滹楫矧绡卑卑胺嗜判胺ú氨订安俘十乳玷蓬弪琦需螽荇屮翕纣胺安ú氨订茆殁轸屙澉狯妪挟僧迈铢氍荑蝈纣梏麴蠛滹楫矧绡卑北肮粤用舶贝渤备补待膳排则犷螽琉痨吁疱蜚镱洚荇屮翕纣泊待ú氨穿茆殁轸屙颓十领麽祆荑蝈纣梏麴蠛滹楫矧绡卑卑胺嗜判胺ú氨穿胺过十乳玷蓬弪琦需螽荇屮翕纣胺ú氨穿胺巩茆殁轸屙轩翳獒饼援雨堍稞篝蜥钿荑蝈纣梏麴蠛滹楫矧绡卑卑父北捕斗案舶岸暗安洱十乳玷蓬弪琦需螽荇屮翕纣暗ú鞍订安懂茆殁轸屙轩翳獒昌援雨堍稞篝蜥钿荑蝈纣梏麴蠛滹楫矧绡卑卑倍戤沭惝舶案氨俺洱蔑眇豸需螽蔑眄躅荇屮翕纣狈庚傅ú鞍俯茆殁轸屙呐十溴漆鲥蝈狨荑蝈纣梏麴蠛滹楫矧绡卑卑胺嗜判安ú氨穿暗俘十乳玷蓬弪琦需螽荇屮翕纣安ú氨穿捣茆殁轸屙玑蹒妪曙箬踽曙犷尼铋屐涕溽颥荑蝈纣梏麴蠛滹楫矧绡卑卑父舶蹈沟兜後怃光鱼楫藻汨铒飚荇屮翕纣钞除俺暗氨ú氨俯茆殁轸屙泱趄孱玺椠尼鲩溴皱铘躜屐扉荑蝈纣梏麴蠛滹楫矧绡卑北俺需笠弼禺诞俺卑窗需螽义霎荇屮翕纣谍俺卑窗ú氨旦苠钿翳邂殁扉镧蜥痂ボ铄黟徵茚痧孱溟荏邈糸镱俞眇戾犷箝珙犰箦戾泗轱铨莒徕屐蠛疴倍澡溽翎躞邃骘趄衢铋铉犷翦篝轭翳蚜吞犰顼蜷翳狎弼孱趔箝眭灬糸铉痱雉镱痱雉镱泔祆轶轱铙镦翳倘狒ぼ篑螋簖背藻之澡珏铄蜥糸镱镦翳箝珙犰犷忉汶珧秕钿痱镢弩箦轶疱蜴矧礤鏖翳翳荇屮趔沱歪溏蜥痂谍伯钞楚茔轸妍颓珏铄蜥麸虍领筢眇戾狎翳孱疳篌邃麸荇屮趔沱轩翳獒府脖猖茔轸妍轩翳獒爆轩翳獒昌骘栳潋镱辁狒轱犷箬秣弪轭绠澡溴翦泗矧蝈箴镱箦轶箝眭灬翦鏖翳翳荇屮趔沱腻祓桢簖楚茔轸妍呐骝犴鬻矧氘澡骈蝮篝屦轭翳箦狎汨轶翳痱弩屐邈糸镱麒殂轶泔眄镱麸翳箦狎汨茔轸妍篝粹潺犷麸翳痱弩孱篝蹁族蝈聃轵茼弭ぞ哺挨清麸箦戾泗痱彐弪孱糸犰禊箝珙犰狍翳痱镤蹉糸镱镦赭莒箴弩汜痖铉溴翦泗轱轭泸遽箦翳黹篌轭趄犷篥弪箦孱弪琦轭翳溴翦泗矧澡戾徜轭赍镦遽汨弼孱轶蝈聃轵邃麸骢戽殪莛簸颈卑清犷苠翎疾搐沲镦苋簸静鞍清轶轫痫箦洚澡轶沲溟黹铋箬弩翳泔铘蜷怩糸镱镦翳荀赍趔忉汶珧秕钿麒弪赍趔狎箫骠弪翳犷骘箝珙犰留戾狍镱殇孱糸骈邃眭镱ㄥ戾泗蝻瞟鏖翳莛ぞ钞丹え旦清犷苠翎疾搐à伯丹眭篝忮痱弩孱舢碰孱趔鏖翳徜溟糸镱犰戾痿镱鏖翳莛ぞ舶清狎蝈赍泗邃溟黹铋箬轭翳泔铘蜷怩糸镱镦翳荇翕狎忉汶珧秕钿鏖翳赭戾痿镱螽箩汶珧秕钿骝镯油溟赍犷眭祠殛弭痱镤蹉糸镱狎篚痧蝈篌邃怡蝈聃轵轭翳狷轫豸栳犷珈忮赭邋翳盹礤铘蹴鲥泗矧镦翳赭戾徜轭赍趔麸忮箜犰戾翳犷伯蜥骘犰弼孱趔鏖翳箦泔钿栳蜾赍镦莛簸径挨清之澡箦泔钿篝屦轭翳箦戾泗轱镦翳箝珙犰轶翳躞徵镦犷狃痱镝汨盹蝈徜鲠钽邃翳犷扉铄狎沲趔族溴筱蜷忮桢蝈翳疳蜥礤翦蝮镦翳履狍躞邃轭茔轸妍篝粹潺犷翳痱镢邃躜麸轭沆蹁溟骀弪孱溟筱蜷黹钺糸铉鲠蜷徕戾狍轸轭瘐趔族溴骈铄の咴犷ね吣蝈箴邈糸鲥禊狍翳铛礅弪镦趄邋轭翳履犷轸磲轫犰溴痿璁澡磲轫犰铒溴箝ね呶轶翳疱蜚孱翎珏镦翳铛礅弪镦箝珙犰矧忉汶珧秕钿弼孱趔狒麒殂翳箴扉趑轭镦溽翎篝镳轭翳趄邋犷徙趔狍篝镳痖铉泔钿轸轱镦翳趄衢铋铉澡弩疳蜥礤翦蝮狎镳糸黹邃怡磲轫辁轭翳葡镦溟骀弪孱履泽趄衢铄鏖翳鲠蜷秕疳蜥礤翦蝮澡箦趑轭殄熹轭翳忮篝疱蜴矧磲钽麒殪狯镩溟铉犷秭弪趄衢铋铉轶à芜预ね吣がね呶ぉ建窗艾超伯弟ォ崎钺祆翳箴徙镦轭瘐鲠蜷徕戾轶溟徵镱犰辁邃忮骘蝈忮轭驽麸翳趄衢铋铉馏骘翳痱镢邃躜麸轭沆蹁溟筱蜷黹钺糸铉鲠蜷徕戾狍轭瘐趔麸翳履袁麇篝狎骝镯蝈漉沐箦ぼ椁麒殂泔眇蜷箦翳忉箝鲠蜷徕戾镦翳箦狎汨铄鲠蜷徕戾訾轶轭泔蝠矧狒邃轭麸翳箦镦轭瘐鲠蜷徕戾镱禊殒轸箝珙殒殂犷綮轭泸遽箦翳葡彤吾礤禊麇趄衢履鏖翳翳箦ぼ椁犷犷雉桢鏖翳ぼ茱痨躞訾犷汜煦蹯狒翳葡镦篷茯彐羼烘镯狍骢钽糸镱镦翳沲狃痨殄镱翳履鸳秕麴豸涉翳磲轫犰葡蝈徙桢鏖翳翳灬趑弪箦轶栝玷弪翳犷翳镱鏖翳翳骘蝽弪翳鲠蜷徕戾訾轶轭泔蝠矧狒邃狍铄轭瘐鲠蜷徕戾殒翳疱蜴矧磲钽镦翳箦ぼ茱痨躞訾轶泔眇狒殁戾鏖翳翳镱镦ぼ椁轸轶铒舢澡轶痱镢邃躜轶蝈疱狒邃躅糸翳弪轶铒铄鲠蜷徕戾狒溟箴矬犰深矧溴麸磲脲翳泔眇狎轶镱鏖翳翳蝈篚祠镦聃犷趱犷铄犰轭狍鲠扉狍痫篌殁戾履轶蝈趄衢铄鏖翳翳荇屮趔沱腻祓桢簖箝眭灬糸镱澡疱蜴矧磲钽瀣骘翳筢礤箝珙犰轶泔眇狒殁戾忮赭邋翳轶铄箝眭灬糸镱犷翳骢祆箝眭灬糸镱镦翳猛溴翦泗矧荏邈糸镱腻蜷鲠糸镱镦翳柔黹祠镱獒铨莒徕屐蠛桎弪深翳轶箦泗轱瞵麇溴蜷鲥翳屮痱弩箝镱镦翳柔黹祠镱獒麸忮轸弪狒轹屐黹铋黹邃骈蝮骘翳镲黹铉犷翳孱骘翳狨珥孱翎糸镱篝屦涉麇屮疳钿翳捧沆殇遽溟篝犷沐镦篷茯彐羼侯矧睚麸忮黹铋黹邃麇镡翎轭茆彗轭羼踽糸镱荏蹴啕荇狨奖抻莒彐糅啕荇狨薏莒彐舁荏蹴啕榻饼尬筮氵檐戾骠ㄜ翦翕纣啕荇狨茯殓梏┸蜷玷舂薏铲啕荇狨莒彐舁荏蹴啕榻饼尬筮氵檐戾骠ㄜ翦翕纣啕荇狨茯殓梏┸蜷玷舂茯殓梏莓莒徕屐羼后屮瘕苠钿羼踽糸镱享轸糸铉翳骈蝮翦蝽麒殂轶泔铙翎铘犷轭箦螋轭翳镲黹铉篚怏糸趱糸镱镦篷茯彐羼后踱簖轭篷茯彐羼后屮瘕麇镡翎轭茆彗轭羼踽糸镱莒徕屐羼后屮瓠荏蹴啕荇狨奖抻莒彐糅莒彐舁荏蹴啕榻饼尬ㄜ箝珥屺舂筮茼踹楱舂氵楱荇屮翕纣啕荇狨┸蜷玷舂薏铲啕荇狨莒彐舁荏蹴啕榻饼尬ㄜ箝珥屺舂筮茼踹楱舂氵楱荇屮翕纣啕荇狨┸蜷玷舂茯殓梏莓苠钿羼踽糸镱契祆溴鲥祜痖铉翳篷茯彐羼后屮瓠麒殪铄珈邈糸铉泔铙翎铘箴轭轭溴疱钿孱衄犷聃徜蜥糸箦戽箴轭轭翦蜥泗轱翦蝽蟋麇珏艉茆彗轭羼踽糸镱荏蹴啕荇狨奖抻莒彐糅铲啕荇狨荏蹴啕榻饼尬荏殓磲舂氵楱荇屮翕纣啕荇狨筮曹篚磉榻饼摞锡莒彐舁荏蹴啕杲饼尬茼踹戗舂氵戗荇屮翕纣啕荇狨茯殓梏荏殓磲舂氵楱荇屮翕纣啕荇狨筮曹篚磉榻饼摞锡荏蹴啕昃辇摞锡ㄜ箝珥徂波舂氵楱荇屮翕纣啕荇狨┿哧ㄜ翦翕纣啕荇狨┅筮轶哧茯殓梏莓莒徕屐羼后痖瞽溴瓠翦蝽簖苠钿羼踽糸镱义汜祆轭翳溴骈铋糸镱镦翳翦蝽っ唛犷っ啕殛轭篷茯彐羼恒辇犷溟鲩溟铉翳屮痱弩箝镱茯彐羼后痖瞽溴瓠翦蝽簖怡赭铿麇镡翎轭翳屮痱弩箝镱镦翳柔黹祠镱獒鏖翳翳镲黹铉狃痱镝汨茆彗轭羼钺蝌狴权舂荏蹴莒轫轸筮榻饼摞锡苈殓ō眠辇荏蹴莒轫轸筮杲饼摞锡茼踹挲舂眠殛苈殓荏殓磲舂筮辇荏蹴莒轫轸筮榻饼摞锡荏蹴莒轫轸筮昃辇摞锡眠殛荏殓磲薏舂筮辇筮挲莒徕屐羼喝酊苠钿羼钺蝌狴物麇狨珥孱遽汨沆狍箝骈弪ら鏖翳え擦暴沆狍箝骈弪蠛茆彗轭羼钺蝌狴苕矧犰苠轶趔氵莒镱珧殓梏狎蝻氵殪莒徕屐羼后踱狨琮苠钿羼钺蝌狴麒弪れ荛茼狒桠恹邶轶翳镦骟弭き莒羼莒羼沥狍溴骈铄轭篷茯彐羼横蹒深箦螋轭翳狨珥孱翎糸镱篚怏糸趱糸镱茯彐羼后踱狨琮轭篷茯彐羼喝酊犷镯轸糸铉泔铙翎铘翦蝽蟋麇镡翎轭茆彗轭羼钺蝌狴权舂荏蹴啕旖笼摞笼荏蹴啕榻饼尬莒彐舁荏蹴啕荇狨奖摞育氵殪啕荇狨荏蹴啕歆江笼摞笼荏蹴啕杲饼尬茼踹觎舂荏蹴啕荇狨奖抻氵殪氵觎茯殓梏┸箝珥屺舂筮殪苕蜥沱饼昌荏蹴啕旖笼摞笼荏蹴啕榻饼尬荏蹴啕茺戡歆荦茴羼茺楝燔荏蹴啕荇狨奖抻氵殪氵觎荏殓磲薏舂筮殪筮觎茴镱蹴忮莒徕屐羼喝酊岚苠钿羼钺蝌狴阵轭翳羼蹰鲠戾钽搴茆彗轭羼钺蝌狴苕矧犰荏蹴莒轫轸筮榻饼摞锡荏蹴莒轫轸筮旖笼摞笼剡殪苠聃轹荏蹴莒轫轸筮山饼摞唯擦暴剡涩莒徕屐羼哄聃轹苠钿羼钺蝌狴犷溴骈铋铉翳铄轭溟沐ど犷な狍ぼ殪荦犷ぼ觎к蝈箴邈糸鲥禊麇镡翎轭翳屮痱弩箝镱镦翳骈钺柔黹祠镱獒麒殂轭沆蹁弩翳镲黹铉犷狨珥孱翎糸镱狃痱镝汨弩茆彗轭羼踽糸镱权舂荏蹴啕山饼摞唯擦暴莒彐舁眠荏蹴啕式饼摞唯擦暴茼踹狮舂眠墒茯殓梏┸箝珥屺舂筮苕蜥沱饼昌荏蹴啕山饼摞唯擦暴荏蹴啕受铄升摞唯擦暴眠墒荏殓磲薏舂筮筮尸莒徕屐羼喝酊猃苠钿羼踽糸镱鏖翳茆彗轭羼钺蝌狴眠升荏蹴莒轫轸筮荇狨奖摞育氵殪啕荇狨啕荇狨眠墒荏蹴莒轫轸筮荇狨奖摞育氵殪啕荇狨┿啕觎啕荇狨┊莒徕屐羼恒獒琮苠钿羼钺蝌狴婶栳麸忮铒翦翳狒翳柔黹祠镱獒铙镦怙翳羼踽糸镱茯彐羼喝酊犷茯彐羼喝酊猃狎骢祆泔铑邈翦洚荏邈糸镱氧犷趱犷铄犰轭绾疳蜥礤翦蝮犷泔铘蝻蝈篚祠簖莒徕屐蠛襻簖孽蜷铉翳轸弪狒轹镳糸黹狒轱镦翳柔黹祠镱獒瞵犷麸狯弪徵秕蜥钿镯弪蝻蝮镱翳祜汜骈屐潴犷泔躔扉铉蟋遽汨犷铄犰轭轶蝓犷狯弪徵邃秭弪ゎ哏玑蹒弩茔轸妍玑蹒妪犷ゎ咤磲轫犰铛礅弪镦屮汩翦篝狒弩麒弪ゎ哏犷ゎ咤汜忮磲溴麸盹铒麸铋汜祆溴泸遽箦鏖翳遽汨轸弪狒轱町燥黹糸玑翦翳轫疳泗镦秭弪骈趑轭漉麸翳镲黹铉麇骘祆秣赭锃篝屦蜥钿镯辁狒轱痱镢邃躜轭遽汨轸弪狒轱詈殒翳孱弪琦镦翳聃忾ら黠蝮孱蟋箝珙骒轲ん唛茯殓梏狎蝻筮椁轶狃痨殄鏖翳盹铒麸铋汜祆溴泸遽箝铉痱镡徕殪轸ゐ哝舂が骘祆秣邃怡蜥钿镯禊躅殒矧箴轭骒轲骘犰聃忾趔鏖翳痱镡徕殪轸ゑ哝舂疬妯舂ぼ骘蜥祆簸翳鲠祯弩镦翳赭痱镡徕殪轸殄疱轸弪狒轱狎脲痿翳筢礤狍轭茔轸妍襻盱迈殪溟铉镱翳蝈篚祠镦茔轸妍钺趱蝈襻盱麇箦翳铛礅弪镦轸弪狒轱铙麸脯麒殪箦趑轭翳犷铄犰轭糸礤麸舶ぼ眭螭孽蜷铉翳轶轸弪狒轹镳糸黹狒轱瞵翳犷铄犰轭轶蝓骘ゎ哏玑蹒弩狒遽汨轸弪狒轱麸蝈漉沐蜥钿镯弪蝻蝮镱翳祜汜骈屐潴よ唛犷泔躔戾蝮な啕殛ぎ骑遽汨玑蹒瀣翳犷铄犰轭蝈篚祠轶筢眇戾舶糸礤蟋犷翳箦镦箴轭戾徜轭麸翳祜麇篝孱弪琦轶泔祆邈翦洚澡箦戾泗轱镦翳屮汩翦篝狒弩轶忉箦镱溟篝犷沐や麸翳篝狒镦祜麇篝孱弪琦犷磲轫犰铛礅弪ゎ咤镦屮汩翦篝狒弩狍轭茔轸妍襻盱麒弪翳鲠祯镦ゎ哏がゎ咤犷や鲠蜷弩鏖翳翳轸弪狒轱町澡轶礤犷翳狒徭翦翳轸弪狒轱簸麇栳鲥箦镦ゎ哏舂溟骀弪孱ぼ眭呱ぇ蟋秕镦麒殂狒盹篝ゎ咤舂狎脲痿骘翳铄轸弪狒轱瞵泔蝌弩痫钿轭麸翳忮篝孱弪玳弩留轸弪狒轱臬堡麇栳鲥狒盹篝ゎ咤舂茔滹钸绋舂犷铄犰轭珞翳躞篝狒弩秕镦麒殂狒盹篝ゎ咤臬暴狎脲痿澡轶蝈痱弩孱趔祜镦泔眇豸轭糸礤骑翳痱镡戾镳糸黹邃轭翳轶疳疱颥犷骘玳鲥箦镦鲠蜷徕戾蟋麇泔眇狎邃蝈篚祠镡翎轭邃鏖翳ゎ哏杰蛋卑爆避犷ゎ咤杰倍船爆避狍轭茔轸妍襻盱镱镱栳钿鏖翳蝈篚祠镡翎轭邃鏖翳ゎ哏杰蛋卑卑荦犷ゎ咤杰爆避镱翳雉桢虍族镡箦蝣邃翳狒翳镡翎轭邃孱弪玳弩麇蝈聃狍榄殇孱糸汜骘灬蜱铛礅弪镦趄衢铋铉弼孱趔箬秣轭翳狒痖汶轭翳篝狒镦忮篝孱弪琦秕镦ゎ哏堡轶篚骀殂殄铘麸黹糸玑翦翳躅沐螋衢铘殄镦翳犷铄犰轭痱镢弩蟋麒殪筢鲩铉泔眇豸轭糸礤族翳弪彐矧蝈翎轭翳灬趑弪镳糸镱骘ゎ哏犷ゎ咤ぎ崎钺祆翳汨衢篝蝈铉翳を轶溴骈铄狍翳蜥糸镦翳泔躔扉铉鏖翳轭遽汨汨衢秭弪翳灬蜱弩泔躔扉铉轭柔黹祠镱獒町涉を轶鲥蝙灬蜱瀣翳汨衢铙鏖祆忮麸篝蝻铉麸犰祜眭祠轳踱轸骒轲痖铉麒殂轶铄沐篌狎麸屮痨矧翳箴徙镦箴轭螽涉镱翳泔铘蜥蝙を轶鲥蝙箜犰飕翳汨衢铙鏖祆忮怛镫孱怡翳翦铙轱轭漉沐怡翳痱镡戾矧怡翳弪磲屮汩翎糸镱澡汨衢篝蝈铉翳汜忮箦麸溴汜盹铒麸铋汜祆鏖翳遽汨轸弪狒轱狍麸犰祜と舂麸潋轹翳簌篝屙澌钺黹泱麒殪痱弼孱糸铉翳汨衢铙镦聃忾趔骝镯怛遽腴铉茔轸妍泱趄孱玺椠澡鲠祯镦を狒遽汨轸弪狒轱轶翳筢礤狍轭茔轸妍襻盱深翳汜箦麒弪翳汨衢轶怛镫孱翳礤狍躜镦翳聃忾汨衢铙轶疱蜴矧礤翳蝻蹒磲觑蜷豉鲲翦痫篌殁禊戾徜轭麸翳泔祆邈糸镱镦铒瞽镳糸磲箦趔镦箫祯糸镱箴轭蟋翳躞麸痫篌殁戾祜篌镦溟筱蜷黹钺糸铉轭骘蝽狒轱町深崎绠茯彐骈绾孱麈钡麇痱弩孱翳弼镬豸轱镦翳审轭柔黹祠镱獒孱弪琦狍骢钽糸镱镦翳镳糸黹狒轱轸弪狒轱骘溟骀弪孱铛礅弪镦弼孱趔躞邃麸趄衢翳蚜吞犰顼蜷翳懋项汜镡箦蝣翳狒翳孱弪琦溴泸遽箦鏖翳翳轸弪狒轱瞵犷翳狒翳溟骀弪孱沐镦孱弪琦忮赭邋弼孱趔躞邃麸趄衢犷翦篝翳犷铄犰弪溴泸遽箦骘栝玷弪唯则衢瞟深骈珲蝈茯彐骈绾骘砹犷茯彐骈绾骘砺麇蝈痫螋翳疱蜴矧磲钽镦翳蚜吞犰顼蜷翳骘鲠蜷徕戾箦趔犷狍溴骈铄轭葬忪妣茯彐翎夂鲠蝮弭犷骘溟骀弪孱狨珥孱翎糸镱筱桢礤蟋沲麸骀っ犷鲠蜷徕戾骈轭镳糸镱螽田麇鲠祯弩镦っ翳犷翳矬殪祯篝蜥翦轭翳弩骈珲蝈狎铒蝈痫螋邃忮汜躞铒屙忮滗轭麽骘躅玳鲥翳铛礅弪镦鲠蜷徕戾犷翦篝邃狨珥孱翎糸镱筱桢礤婶轶轭翦蝈篝轭麸铒翦翳狒翳祜麇篝怙躅骘っ轶栝玷弪骘翳箦麒弪翳铛礅弪镦鲠蜷徕戾轶栝玷弪犷骘栝玷弪狨珥孱翎糸镱蜥铉鲠蜷徕戾ちぉ麒殂戾徜麸灬蜱弪铛礅弪镦ゃ啕殪箦篷茯彐羼横蹒┈翳躞泔躔扉铉翦蝽っ啕墒箦篷茯彐羼恒獒┊腻疱钿轭镱翳箦镦鲠蜷徕戾犷翳狨珥孱翎糸镱筱桢礤溟骀弪孱鲠祯弩镦っ狎镳糸磲飚澡疱蜴矧磲钽轶珏铄蜥祆栝玷弪麒孱翳鲠蜷徕戾骈轭痱镢邃躜轶躞邃骑玳鲥箦镦鲠蜷徕戾蟋箜犰矧忾鲠祯弩镦翳镦骟弭ぼ溴祠幛箦篷茯彐羼横蹒黹玷戾徜麸溟筢漩犷翎珏秕狨珥孱翎糸镱镦翳麇犭沆狍箝骈弪蟋戾徜轭麸铒瞽镳糸磲疱蜴矧磲钽瀹澡轶轶殪祯篝蜥翦骘翳疱蜴矧磲钽弩镦翳箦轭崎绠茯彐骈绾骘砺麒弪翳葡蜥轶弩翳孱潋镳骘溴泸遽箝铉鲠祯弩镦ぼ溴祠幛翳轶骘犰盹篝犰鲠祯弩镦沲麸骀茆彗轭骈珲蝈邸梏怵茆彗轭沐铘弪荛钽祯溴珧狃栝泱垠汜戾桨摧痨雉蟑孱弪琦咦票颠卑爱痄纨荛钽祯溴珧狃栝泱垠汜戾桨摧痨雉蟑孱弪琦咦票颠卑鞍痄纨苘荛钽祯溴珧狃栝泱垠汜戾桨摧痨雉蟑孱弪琦咦票颠卑鞍爱痄纨荛钽祯溴珧狃栝泱垠汜戾桨摧痨雉蟑孱弪琦咦票颠蛋鞍爱痄纨苠钿沐铘弪茔狃糸镱碰镬豸轱镦翳审轭柔黹祠镱獒孱弪琦狍骢钽糸镱镦翳轸弪狒轱骘唯则衢瞟鲠蝙轭骝镯卑麸戾骠麸蛋鞍ㄢ雉麸蜷玷舂翳弩轭翳趄衢ㄢ祯濠犷翦篝矧犷珏筢眇戾螽澡蚜吞犰顼蜷翳躞弩翳鲠蜷徕戾镦葬忪妣茯彐翎夂鲠蝮趄犷箧矧礤轭麇犭沆狍箝骈弪蟋鏖翳犷狨珥孱翎糸镱筱桢礤镦à茕屐翎がちぉ建爱安惮畅犷沲麸骀镦傅堀鏖翳秕躞轭鲠蜷徕戾骈轭痱镢邃躜瀹莒徕屐骈绾孱麈钡苠钿骈珲蝈茆彗轭骈珲蝈邸梏怵茆彗轭沐铘弪荛钽祯溴珧狃栝泱垠汜戾桨惫蓰痨雉蟑葡土安诞痤琮荛钽祯溴珧狃栝泱垠汜戾桨惫蓰痨雉蟑葡土背串痤琮苠钿沐铘弪茔狃糸镱碰镬豸轱镦翳葡狍骢钽糸镱镦翳沲麸骀っ犷骘鲠蜷徕戾骈轭箦麸趄蹂ㄦ蹯汩蜚戾犷驷祗ㄦ蹯趄獒铉戾┊澡蚜吞犰顼蜷翳躞弩翳鲠蜷徕戾箦镦葬忪妣茯彐翎夂鲠蝮弭澡戾骠痨雉痱弩孱趔蝈篚祠骘犷狨珥孱翎糸镱筱桢礤镦à茕屐翎がちぉ建爱氨脯畅轭忪徙氍ò氨惮畅轭珧邋犷ò鞍宫畅轭蝈洚澡蜷玷痨雉箬秣蝈篚祠骘à茕屐翎がちぉ建爱氨爆旦轭忪徙氍ò鞍宫旦轭珧邋犷ò鞍冬旦轭蝈洚莒徕屐骈绾骘砹苠钿骈珲蝈茆彗轭骈珲蝈邸梏怵茆彗轭沐铘弪荛钽祯溴珧狃栝泱垠汜戾桨惫蓰痨雉蟑葡吐氨捕痤琮荛钽祯溴珧狃栝泱垠汜戾桨惫蓰痨雉蟑葡吐炒捣痤琮苠钿沐铘弪茔狃糸镱碰镬豸轱镦翳葡狍骢钽糸镱镦翳沲麸骀っ犷骘鲠蜷徕戾骈轭箦麸趄蹂ㄦ蹯汩蜚戾犷驷祗ㄦ蹯趄獒铉戾┊澡蚜吞犰顼蜷翳躞弩翳鲠蜷徕戾箦镦葬忪妣茯彐翎夂鲠蝮弭澡戾骠痨雉痱弩孱趔蝈篚祠骘犷狨珥孱翎糸镱筱桢礤镦à茕屐翎がちぉ建爱氨惮畅轭忪徙氍ò氨爆畅轭蝈洮ò鞍番畅轭珧邋瞵犷ò鞍超畅轭忪蹂澡蜷玷痨雉箬秣蝈篚祠骘à茕屐翎がちぉ建爱鞍宫旦轭忪徙氍ò鞍番旦轭蝈洮ò鞍惮旦轭珧邋瞵犷ò鞍船旦轭忪蹂莒徕屐骈绾骘砺苠钿骈珲蝈荏邈糸镱龄鲠钽邃鲠蜷徕戾簖莒徕屐蠛徜鲠螨族泔铙趄蹉铄鲠蜷徕戾怡疱蜴矧黹铉镳弪狒轱铙忮赭邋翳溟筱蜷黹钺糸铉鲠蜷徕戾镦葬忪妣茯彐翎夂鲠蝮麒弪遽汨铄鲠蜷徕戾轶怩殪骝镯赭鲠蜷徕戾镦翳轶扉篝赭锃溟礤铙轱钺溟篝蜷怩糸镱骘遽汨疳轵镦轭轸獒鲠蜷徕戾犰祜黧麸玑蹒翳箦疳蜥糸镱忮赭邋箝珙犰犷鲠蜷秕忉汶珧秕钿痱镢弩箦螽渝鲥蜥犷犰糸骢钽糸镱镦翳赭鲠蜷徕戾狎泔铙殇弪邃犷翳镱犰祜鏖铉麸蝈徙翳栝玷弩葡轶蝈翎轭邃疱疳轵镦鲠蜷徕戾螽渝鲥铘邋铄鲠蜷徕戾狎泔铙趄蹉翦鏖翳翳轶礤翳镤秕镦麒殂铋铄狎泔铙殇弪邃箦葬忪妣茯彐翎夂鲠蝾鬻箩箦镱翳溟筱蜷黹钺糸铉痫麇镦遽汨铄鲠蜷徕戾麇泔铙殇弪赭珧秕痼镦鲠蜷徕戾蟋镱磲溴镦翳骈鲥铄鲠蜷徕戾鏖翳翳栝玷弩葡腕犷箦泔钿鏖翳翳骘躜篚怏羼蹂铘镱弩茆彗轭翎忪妪邸梏怵茆彗轭沐铘弪茆彗轭翎怩灬螨禳禳荑扉铄荑扉铄轴蜷徕戾葡苘荑扉铄莛綮茼弭爱车苘莛綮莛糸篁爱膊苘ㄜ怃轶悚け┸痿爱舶苘え茼弭きげ赴┄茼簸じ癌爱舶苘え茼弭きげ赴┄苋簸ご鞍─爱备苘荑扉铄茕蛱陇ㄜ眙窗爱辈苘苋簸薏く茴赍爱肮苘莛酤か钞丹苠翎飑薏爱案苘莛舣苋爱俺苘荑扉铄荑扉铄苠钿翎怩灬螨茔狃糸镱五溟筱蜷黹钺糸铉鲠蜷徕戾泔铙趄蹉翦鲩镳弪狒轱铙镱翳镱弩镦葬忪妣茯彐翎夂鲠蝮骑遽汨铄鲠蜷徕戾翳磲轫犰鲠祯镦翳葡轶蝈痫螋邃麒弪翳泔蝌弩痫钿轭躅沐螋衢铘轶铄珈殓殁戾轴蜷徕戾镦葬忪妣茯彐翎夂鲠蝮犷翳矬鏖翳栝玷弪葡腕躔疱疳螋骘蝽翳箦连麒殪鲠蜷徕戾镦翳箦犷翳矬鏖翳祜麇葡腕祜麇疳螋骘蝽翳箦庐莒徕屐翎夂鲠蝾鬻苠钿沐铘弪苠钿翎忪妪苠钿滹沲礤铘
\section{Analysis}



\subsection{Oracle Quadformers}
To obtain a loose upper bound on the potential performance of ViTs with mixed-resolution tokenization, we train Quadformer models with a Grad-CAM oracle saliency scorer that has access to the true image label (\S\ref{paragraph:oracle_scorer}). Our oracle models greatly surpass the performance of vanilla ViT models with the same number of patches -- in some cases by about 4 absolute percentage points (Figure \ref{figure:oracle}). Oracle Quadformers with 64 patches even beat vanilla ViTs with 196 patches despite using $\times 3$ less patches, suggesting there is considerable redundancy in standard ViT tokenization.


\subsection{Runtime breakdown}
% The Quadformer tokenizer has a much higher runtime-to-GMACs ratio than the Transformer model due to the different operations they use (Table \ref{table:cost_breakdown}). Therefore, we find that measuring actual runtime instead of settling for GMACs as the sole cost indicator is especially important when comparing our models to vanilla ViT models.
The Transformer model and the saliency-based Quadtree tokenizer have very different runtime-to-GMACs ratios due to the different operations they use, with the tokenizer using a tiny number of GMACs compared to its runtime (Table \ref{table:cost_breakdown}). Therefore, we find that measuring actual runtime instead of settling for GMACs as the sole cost indicator is especially important when comparing our Quadformer models to vanilla ViT models.

The feature-based scorer requires 3 forward passes with a truncated ShuffleNetV2$\times0.5$, composed mainly of group convolutions, depthwise convolutions, BatchNorms, and a channel-shuffle operation that has no GMAC cost but has a non-negligible time cost.

The Quadtree algorithm itself is very fast, though it has an especially high runtime-to-GMACs ratio, as it mostly requires indexing and reshaping operations that have no GMAC cost. Even though different numbers of patches require different numbers of splits, the bulk of the Quadtree runtime is spent preparing the input to the splitting phase and processing its output, making the Quadtree cost almost constant with respect to the number of patches.

The Transformer model is composed mainly of Attention layers, fully-connected layers and LayerNorms. Its runtime and GMAC cost depend heavily on the number of patches and the size of the model.

Notice that the fraction of time taken by patch scoring and Quadtree calculation becomes less and less significant as the model and input length increase in size (Figure \ref{figure:runtime_breakdown}), ranging from 44\% for our lightest configuration to 4\% for our heaviest.



\begin{figure}[t!]
  \centering
  \vspace*{-5pt}
  \hspace*{-0.035\linewidth}
  \includegraphics[width=1.035\linewidth]{figures/runtime_breakdown.pdf}
  \caption{Quadformer forward pass runtime breakdown with a feature-based patch scorer. The fraction of time spent on tokenization changes drastically as the model and input length increase in size, from 44\% for ViT-Small with 64 patches to 4\% for ViT-Large with 196 patches.}
  \label{figure:runtime_breakdown}
\end{figure}



\begin{table}[t!]
% \vspace*{3pt}
\centering
\resizebox{1.0\linewidth}{!}{
\begingroup
\renewcommand{\arraystretch}{1.2}
\begin{tabular}{ c l c c c }
Component             &                             & $\mu$-secs     & GMACs      &    $\frac{\mu-secs}{GMAC}$   \\
\midrule
Quadtree              &                             & 19             & 0.0008     &     23,750                    \\
\midrule
                      &   Pixel-Blur                & 19             & 0.0024     &     7917                     \\
Patch Scorer          &   Feature-Based $256^2$     & 157            & 0.166      &     945                      \\
                      &   Feature-Based $192^2$     & 101            & 0.094      &     1074                      \\
\midrule
                      &   ViT-Small 64 patches      & 154            & 1.44       &     107                        \\
                      % &   ...                       & ...            & ...        &     ...                        \\
Transformer           &   ViT-Base 121 patches     & 821            & 10.8        &     76                        \\
                      % &   ...                       & ...            & ...        &     ...                        \\
                      &   ViT-Large 196 patches     & 3774           & 61.8       &     61                         \\
\midrule
\end{tabular}
\endgroup
}% close resizebox
\caption{Forward pass cost breakdown. Measuring actual runtime is especially important for comparison between Quadformers and vanilla ViTs since different components have very different runtime-to-GMACs ratios.}
\label{table:cost_breakdown}
\end{table}


\subsection{Patch scorer quality}
The main way in which we assess the quality of different patch scorers is by measuring their effect on the downstream task, ImageNet-1K classification. Alternatively, we can measure scoring quality more directly by comparing the patch ranking induced by a Grad-CAM oracle scorer to the rankings induced by different realistic patch scorers (Figure \ref{figure:importance_map_comparison}). The oracle scorer is aware of the true image label, and uses the Grad-CAM algorithm which was built with the express purpose of saliency estimation, making it a good golden standard for patch ranking, as reflected in the high accuracy of oracle-based Quadformers (Figure \ref{figure:oracle}).

For each image in the ImageNet-1K validation dataset, we calculate rank correlation coefficients between the oracle scores and the scores computed by the feature-based and pixel-blur patch scorers. We use rank correlations since the actual score values do not affect the Quadtree algorithm, only the relative ranking (see the $\arg\max$ operation in Algorithm \ref{algorithm:quadtree}). In Table \ref{table:scorer_similarity_to_oracle} we report average rank correlation values and the fraction of images in the dataset for which the feature-based scorer was a better estimator of the oracle than the pixel-blur scorer, demonstrating the superiority of semantic representations over surface details.


\subsection{Quadtree composition}
Quadtree composition changes with the number of splits. As the iterative splitting process progresses, large patches are split into medium patches, which are in turn split into small patches. While the exact frequency of different patch sizes depends on the image content, we can get a sense of the resolution distribution by constructing Quadtrees over the entire ImageNet-1K validation set and measuring the average percentage of image area covered by each patch size (Figure \ref{figure:patch_stats}). Note that the average resolution distribution depends on the ratio $\frac{\#Patches}{max(\#Patches)}$ and is almost invariant to the image size, which can help choose appropriate values for $\#Patches$ for different datasets, depending on the fraction of key information we expect the images to contain.


\begin{table}[t!]
\centering
\hspace*{-0.035\linewidth}
\resizebox{1.045\linewidth}{!}{
\begingroup
\renewcommand{\arraystretch}{1.2}
\begin{tabular}{ c c c c }
                                &  \multicolumn{2}{c}{Similarity to Oracle}    &         \\
Rank Correlation Coefficient    &  Feature-Based   & Pixel-Blur   &  \% Score$_{Feat}$ better   \\
\midrule
Kendall's $\tau$                &  0.51            & 0.31         & 81\%  \\
\midrule
Spearman                        &  0.52            & 0.26         & 81\%  \\
\midrule
\vspace*{0.001pt}
\end{tabular}
\endgroup
}% close resizebox
\caption{Average rank correlation between the patch rankings induced by the Grad-CAM oracle scorer and different realistic patch scorers, computed over the ImageNet-1K validation set.  ``\%~Score$_{Feat}$ better'' measures how frequently the oracle ranking is closer to the feature-based scorer than to the pixel-blur scorer.}
\label{table:scorer_similarity_to_oracle}
\end{table}


\begin{figure}[t!]
  \centering
  \hspace*{-0.035\linewidth}
  % \includegraphics[width=1.07\linewidth,height=0.5\linewidth]{figures/patch_stats.pdf}
  \includegraphics[width=1.07\linewidth]{figures/patch_stats.pdf}
  \caption{Quadtree composition changes with the number of splits. We measure the percentage of image area covered by each patch size to get a sense of the resolution distribution inside the image. The left plot shows the progression for our main image size. The right plot shows that this progression is almost invariant to the image size.}
  \label{figure:patch_stats}
\end{figure}

\section{Impact of Linguistic Features}
\label{sect:all}
In this section, we examine the effect of employing all linguistic features described in Section~\ref{sect:base_features} in a neural coreference resolver, i.e.\ deep-coref.
We use \emph{MUC} \cite{vilain95}, \emph{B}$^3$ \cite{bagga98b},
\emph{CEAF}$_e$ \cite{luoxiaoqiang05a}, \emph{LEA} \cite{moosavi16b},
and the \emph{CoNLL} score \cite{pradhan14}, i.e.\ the average F$_1$ value of \emph{MUC}, \emph{B}$^3$, and \emph{CEAF}$_e$, for evaluations.

The results of employing those features in deep-coref's ``ranking'' and ``top-pairs'' models on the CoNLL development set are reported in Table~\ref{tab:dev-linguistics}.

\begin{table}[htbp]
    \begin{center}\footnotesize
    \resizebox{\columnwidth}{!}{%
    \begin{tabular}{@{}l|@{\hskip3pt}r@{\hskip3pt}|@{\hskip3pt}r@{\hskip3pt}|@{\hskip3pt}r@{\hskip3pt}|@{\hskip3pt}r@{\hskip3pt}||@{\hskip3pt}r@{\hskip3pt}}
     \multicolumn{1}{c}{} & \multicolumn{1}{c}{MUC} &
     \multicolumn{1}{c}{$B^3$} & \multicolumn{1}{c}{CEAF$_e$} & \multicolumn{1}{c}{CoNLL} & \multicolumn{1}{c}{LEA} \\ \hline
     %\multicolumn{1}{c|}{}&R & P & F$_1$ & R & P & F$_1$ & R & P & F$_1$ &  & R & P & F$_1$\\ \hline
     %\multicolumn{6}{c}{\textbf{CoNLL development set}} \\ \hline
     \hline
     %\parbox[t]{2mm}{\multirow{3}{*}{\rotatebox[origin=c]{90}{\scriptsize  ranking}}} 
     ranking  & $74.31$  & $64.23$  & $59.73$ & $66.09$ & $60.47$  \\
	+linguistic  & $74.35$  & $63.96$  & $60.19$ & $66.17$ & $60.20$  \\
     %& {+EPM}  & $74.91$ & $65.07$ & $60.77$ & $66.92$ & $61.46$  \\
     \hline
     %\multicolumn{6}{c}{\textbf{top-pairs}} \\ \hline
     %\parbox[t]{2mm}{\multirow{3}{*}{\rotatebox[origin=c]{90}{\scriptsize  top-pairs}}} 
     top-pairs  & $73.95$ & $63.98$ & $59.52$  & $65.82$ & $60.07$ \\ 
     +linguistic & $74.32$ & $64.45$ & $60.19$ & $66.32$ & $60.62$ \\
     %& +EPM & $74.92$ & $65.03$& $60.88$ & $66.95$ & $61.34$ \\ 
    \end{tabular}
    }
    \end{center}
    \caption{Impact of linguistic features on deep-coref models on the CoNLL development set.
    %The F$_1$ gains of ``+EPM'' are all statistically significant.
	}
    \label{tab:dev-linguistics}
\end{table}
The rows ``ranking'' and ``top-pairs'' show the base results of deep-coref's ``ranking'' and ``top-pairs'' models, respectively. 
``+linguistic'' rows represents the results for each of the mention-ranking models in which the feature set of Section~\ref{sect:base_features} is employed.
The gender, number, animacy and mention type features, which have less than five values, 
are converted to binary features. 
%TODO i.e.\ each feature=value is considered as a binary feature.  
Named entity and POS tags, and dependency relations
are represented as learned embeddings.

We observe that incorporating all the linguistic features bridges the gap between the performance of 
``top-pairs'' and ``ranking''.
However, it does not improve significantly over ``ranking''.
Henceforth, 
we use the ``top-pairs'' model of deep-coref as the baseline model to incorporate linguistic features.

To assess the impact on generalization, 
we evaluate ``top-pairs'' and ``+linguistic''\footnote{i.e.\ ``top-pairs+linguistic''} models that are trained on CoNLL,
on WikiCoref (see Table~\ref{tab:out_of_domain_linguistics}).
We observe that
the impact on generalization is also not notable, i.e.\
the CoNLL score improves only by 0.5pp over ``ranking''.
  
\begin{table}[htbp]
    \begin{center}\footnotesize
    \resizebox{\columnwidth}{!}{%
    \begin{tabular}{@{}l|@{\hskip3pt}r@{\hskip3pt}|@{\hskip3pt}r@{\hskip3pt}|@{\hskip3pt}r@{\hskip3pt}|@{\hskip3pt}r@{\hskip3pt}||@{\hskip3pt}r@{\hskip3pt}}
     \multicolumn{1}{c}{} & \multicolumn{1}{c}{MUC} &
     \multicolumn{1}{c}{$B^3$} & \multicolumn{1}{c}{CEAF$_e$} & \multicolumn{1}{c}{CoNLL} & \multicolumn{1}{c}{LEA} \\ \hline
     %\multicolumn{1}{c|}{}&R & P & F$_1$ & R & P & F$_1$ & R & P & F$_1$ &  & R & P & F$_1$\\ \hline
     %\multicolumn{6}{c}{\textbf{CoNLL test set}} \\ \hline
     %\hline
	 %top-pairs & $74.29$ & $63.16$ & $58.72$ & $65.39$ &  $59.41$\\
	 %+linguistic & $74.33$  & $63.11$ & $58.59$ & $65.34$ & $59.34$ \\ \hline
     %\multicolumn{6}{c}{\textbf{WikiCoref}} \\ \hline
	 ranking & $63.10$ & $48.43$ &  $47.18$ & $52.90$ & $44.40$  \\ 
	 top-pairs  & $63.09$ & $48.42$ & $46.05$ & $52.52$ &  $44.21$\\
	 +linguistic & $63.99$ & $49.63$ & $46.60$ & $53.40$ & $45.66$\\
    \end{tabular}
    }
    \end{center}
    \caption{Out-of-domain evaluation of deep-coref models on the WikiCoref dataset.
    %The F$_1$ gains of ``+EPM'' are all statistically significant.
	}
    \label{tab:out_of_domain_linguistics}
\end{table}


Based on an ablation study, while our feature set contains numerous features, the resulting improvements of ``linguistic'' over ``top-pairs'' mainly comes from the last four pairwise features in Section~\ref{sect:base_features},
which are carefully designed features.

%
\begin{table}[htbp]
    \begin{center}\footnotesize
    \begin{tabular}{@{}l@{\hskip3pt}|@{\hskip3pt}l@{\hskip3pt}|@{\hskip3pt}r@{\hskip3pt}|@{\hskip3pt}r@{\hskip3pt}||@{\hskip3pt}r@{\hskip3pt}|@{\hskip3pt}r@{}}
         \multicolumn{2}{c}{} & \multicolumn{2}{c}{in-domain} & \multicolumn{2}{c}{out-of-domain} \\ \hline
     %\multicolumn{2}{c|}{} & \multicolumn{1}{c}{CoNLL} & \multicolumn{1}{c||}{LEA} & \multicolumn{1}{c}{CoNLL} & \multicolumn{1}{c}{LEA}  \\ \hline
	 \multicolumn{2}{c}{} & CoNLL & LEA & CoNLL & LEA \\ \hline
          \multicolumn{2}{c}{} & \multicolumn{4}{c}{{pt (Bible)} } \\ \hline
     %top-pairs & $74.48$ & $65.61$ & $74.58$ & $69.81$ & $66.04$ & $51.03$ & $67.73$ & $58.20$\\
	 \multirow{2}{*}{{ deep-coref}}
     &ranking & $75.61$ & $71.00$ & $66.06$ & $57.58$  \\ 
     & +EPM & $76.08$ & $71.13$ & $\boldsymbol{68.14}$ & $\boldsymbol{60.74}$ \\ \hline
     \multirow{2}{*}{{ e2e-coref}} 
     & single& ${77.80}$ & ${73.73}$ & $65.22$ & $58.26$\\ 
	 & ensemble & $\boldsymbol{78.88}$ & $\boldsymbol{74.88}$ & $65.45$ & $59.71$\\
	 \hline 
     \hline
     \multicolumn{2}{c}{} & \multicolumn{4}{c}{{wb (weblog)} } \\ \hline
     %top-pairs & $61.51$ & $48.22$ & $61.58$ & $54.09$ & $58.66$ & $49.65$ & $51.05$ & $50.34$\\
	 \multirow{2}{*}{{ deep-coref}}
     &ranking & $61.46$ & $53.75$ & $57.17$ & $48.74$ \\ 
     &+EPM & $61.97$ & ${53.93}$ & $\boldsymbol{61.52}$ & $\boldsymbol{53.78}$ \\ \hline
     \multirow{2}{*}{{ e2e-coref}}
     &single & ${62.02}$ & $53.09$ & $60.69$ & $52.69$\\ 
	 &ensemble & $\boldsymbol{64.76}$ & $\boldsymbol{57.54}$ & $60.99$ & $52.99$\\
	 
     \hline
    \end{tabular}
    \end{center}
    \caption{In-domain and out-of-domain evaluations for the pt and wb genres of the CoNLL test set.
    The highest scores are boldfaced.
    }
    \label{tab:cross_genre_enhanced_1}
\end{table}
\subsection{Impact on Generalization}
\label{ch:improvements:generalization}
We use the same setup as that of \newcite{moosavi17b} for evaluating generalization 
including (1) training on the CoNLL data and testing on WikiCoref\footnote{WikiCoref only contains 30 documents, which is not enough for training neural coreference resolvers.}
and (2) excluding a genre of the CoNLL data from training and development sets 
and testing on the excluded genre. Similar to \newcite{moosavi17b}, we use the \emph{pt} and \emph{wb} genres for the latter evaluation setup.  
%Following \newcite{moosavi17b}, we use WikiCoref because it has compatible annotation guidelines with CoNLL. 

The results of the first evaluation setup are shown in Table~\ref{tab:out-domain-deep-coref}.
The best performance on WikiCoref is achieved by \newcite{ghaddar16a} (``G\&L'' in Table~\ref{tab:out-domain-deep-coref})
who introduced WikiCoref and design a domain-specific coreference resolver that makes use of 
the Wikipedia markups of a document as well as links to Freebase, which are annotated in WikiCoref.

Incorporating EPM feature-values improves the performance by about three points.
While ``+EPM'' does not use the WikiCoref data during training, and unlike ``G\&L'', it does not employ any domain-specific features,
it achieves on-par performance with that of ``G\&L''.
%We also observe that ``+EPM'' performance is about two point better than ``+linguistic'' (Table~\ref{tab:out_of_domain_linguistics}) on WikiCoref.
This indeed shows the effectiveness of informative feature-values in improving generalization.

%In order to show that the improved generalization is due to incorporating 
%informative feature-values, and not any additional linguistic feature, we also report the performance of ``+all'', 
%i.e.\ ``top-pairs'' in which the feature set of Section~\ref{sect:base_features} is employed.
%As we see, ``+all'' performance is slightly better than ``top-pairs''.
%However, the improvements are not as substantial as those of ``+EPM''. 

%The results of e2e-coref ``single'' vs.\ ``ensemble'' show the effectiveness of ensemble methods for improving generalization.
%By combining ensemble methods, e.g.\ \cite{leekenton17,uryupina-moschitti:2017:CoNLL}, 
%and informative feature-values we can further improve the generalization.
%using an ensemble of ``+EPM'' models is a possible way to further improve the results.

The second set of generalization experiments is reported in Table~\ref{tab:cross_genre_enhanced_1}. 
``in-domain'' columns show the results when the evaluation genres were included in training and development sets 
while the ``out-of-domain'' columns show the results when the evaluation genres were excluded.
As we can see, ``+EPM'' generalizes best, and in out-of-domain evaluations, it considerably outperforms the ensemble model of e2e-coref, which has the best performance on the CoNLL test set. 
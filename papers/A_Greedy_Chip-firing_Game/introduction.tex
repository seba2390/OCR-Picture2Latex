\section{Introduction}\label{section: introduction}
In the 1970s, Arthur Engel \cite{engel1975probabilistic,engel1976does} 
introduced a ``stochastic abacus''
that deterministically mimics many aspects of the behavior
of finite-state Markov chains with rational probabilities.
Unaware of Engel's work, various mathematicians and physicists
invented and studied the abelian sandpile model \cite{dhar1990self} 
and the chip-firing game \cite{bjorner1991chip}
which in many respects embody the same core idea as Engel's abacus
but with different motivations.
For books surveying chip-firing we refer readers to 
\cite{klivans2018mathematics,corry2018divisors}.

In the 2010s, inspired by Engel's work, the second author of this paper 
in collaboration with Ander Holroyd 
\cite{holroyd2010rotor} 
introduced a different way to deterministically mimic Markov chains
via ``rotor-routing'' (unaware that physicists were already studying
the process under the name ``the Eulerian walkers model'' 
\cite{priezzhev1996eulerian}).
The emphasis of much of this work on the rotor-router model,
inspired by discrepancy theory and quasi-Monte Carlo methods,
was on the fidelity of the deterministic process to the associated Markov chain.
Specifically, it was shown that for certain 
asymptotically-defined quantities associated with Markov chains
(e.g., the proportion of the time that the chain spends in a specific state),
rotor-router simulation has the same limiting behavior as the Markov chain,
typically with faster convergence than 
the Markov chain itself would typically exhibit.
For a comprehensive background on chip-firing and rotor-routing and 
the relationship between them, we refer readers to \cite{holroyd2008chip}.

Here we discuss another way to derandomize Markov chains
which we call the {\em hunger game}.
It can be applied to any discrete-state discrete-time Markov chain,
whether or not the transition probabilities are rational.
(Rotor-routing can be extended to this regime --- 
see the discussion of stack walks in \cite{holroyd2010rotor} ---
though we know of no way to extend chip-firing in this direction.)
A key difference between rotor-routing and the hunger game
is that the frequency with which state $i$ is followed by $j$
in rotor-router simulation converges to the transition probability $P_{ij}$;
this is not the case for the hunger game.
That is, the hunger game does not exhibit fidelity 
with regard to transition-frequencies. 
However, we believe this may be a virtue rather than a vice,
as we will explain in the concluding section.

In \cref{section: preliminaries} we define the hunger game
and the chip addition operators associated with it.
In \cref{section: boundedness hunger}
we prove fundamental results on the boundedness of hunger,
and in \cref{section: termination} we prove basic results 
on the behavior of chip addition operators.
In \cref{section: stationary distributions} we prove 
the main result of this paper, demonstrating that 
the normalized firing vector of a hunger game process converges 
to the unique stationary distribution of an irreducible Markov 
chain with a discrepancy bound inversely proportional 
to the number of time steps.
We apply this result to show how the hunger game process 
can calculate hitting probability distributions, escape probabilities, 
expected absorption times, and expected return times 
in \cref{section: hitting probabilities and hitting times}\,.
In \cref{section: recurrence} we focus on finite Markov chains
with rational transition probabilities.
We introduce the notion of a recurrent hunger vector 
(a vector that returns to itself under the hunger game) 
and study the properties of the basin of attraction
(the set of recurrent vectors).
In the case where all transition probabilities are rational,
we prove the zero vector is always recurrent and determine its period, 
and conjecture that all the periods for a given Markov chain are the same.
We conclude with \cref{section: conclusion}\,,
comparing the discrepancies of 
the rotor-router model and the hunger game.

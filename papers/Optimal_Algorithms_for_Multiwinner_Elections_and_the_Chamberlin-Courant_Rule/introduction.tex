\section{Introduction}
Multiwinner elections are a classical problem in social choice. In this problem, the goal is to find a set of candidates (or winning committee) of fixed size from voter preferences over the candidates. Indeed, some of the earliest work on the design of voting rules that map individual preferences to a winning committee dates back at least a century~\cite{Thiele}. 

Multiwinner elections clearly arise in choosing a winning parliament in representative democracies. They have also recently found applications in design of systems for making procurement or hiring decisions~\cite{LuB,SkworonFL}, and in participatory budgeting~\cite{goel2019knapsack,pb2}. In these settings, the candidates are products or public projects that provide shared utility to individuals. An entity such as a company or a city government has to decide, based on individual preferences, which of these projects or products to produce subject to a cardinality constraint. 

Much of the work on multiwinner elections has focused on the question of \emph{proportional} or \emph{diverse representation}: How can we choose a winning committee where every voter feels they have some representation? Indeed, classic voting rules such as Proportional Approval Voting (PAV)~\cite{Thiele} or Single Transferable Voting (STV)~\cite{Tideman} explicitly attempt to enforce such representation. %For instance, the Parliaments of Australia and Puerto Rico use variants of STV to ensure proportionality.

%\medskip \kn{Can we not use this command?}
In this paper, we consider the question of choosing a committee of fixed cardinality $k$ from a set $\C$ of $m$ candidates, when voters express \emph{ordinal rankings} over these candidates. In many applications, including parliamentary democracies or participatory budgeting, it is reasonable to assume voters can compare candidates or projects and hence can rank them ordinally, while they may not be able to articulate cardinal utilities for the same. 

A classic set of objectives for ensuring diverse representation~\cite{BrillFST19} based on ordinal preferences uses the so-called \emph{Borda score}. In the minimization (or dissatisfaction) version, the Borda score of candidate $c$ for voter $v$, denoted $r_v(c)$, is the ordinal rank of $c$ in $v$'s ranking. Here, the top-ranked candidate has Borda score $1$, and the bottom-ranked candidate has score $m$.\footnote{Existing literature also uses a score of $0$ for the best ranked and $m-1$ for the worst ranked candidates. Since our results concern absolute scores, they carry over to this setting by simply subtracting $1$ from the bounds. We use a minimum score of $1$ since it is the more challenging setting for showing hardness results.}  Let $\V$ denote the set of all voters, with $n = |\V|$. Given a committee (that is, a set of candidates) $T$ of size $k$, the $s$-Borda score of this committee (for $s \le k$) is given by
\begin{equation}
\label{eq:sborda}
r_{\V}(T) = \frac{1}{n} \sum_{v \in \V} \left(\min_{Q \subseteq T, |Q| = s} \sum_{c \in Q} r_v(c)\right).
\end{equation}
Throughout the paper, we will denote the minimum possible score as $\opt = \min_{T \subseteq \C, |T| = k} r_{\V}(T)$.

To interpret the above score, for each voter, consider the $s$ candidates in $T$ whose Borda score is the smallest. Now, take the sum of these scores, and average it over all the voters. Therefore, the $s$-Borda score assumes each voter is represented by the $s$ best candidates in $T$ according to her ranking, so that optimizing this score implies a form of proportional representation, where each voter on average has $s$ ``good'' candidates representing her. %Naturally, $1$-Borda score is equivalent to Borda score.

Our goal in this paper is to study the computational complexity (in $m, n$) of finding good committees according to the $s$-Borda score function. In particular (though not exclusively), we focus on the analysis of greedy algorithms, which are appealing for their simplicity and ease of use, especially in settings involving human decision making, such as parliamentary elections or participatory budgeting with ordinal preferences. 

%The extant work on the Borda score has also considered the maximization version where the score of a candidate $c$ for voter $v$ is $m + 1 - r_v(c)$, so that the score of a committee $T$ is $m + 1 - r_{\V}(T)$. Clearly, maximizing this new objective is equivalent to minimizing the $1$-Borda objective, though they are very different from an approximation perspective.

\subsection{Results for $1$-Borda Score (Chamberlin-Courant Rule)}
Our main results focus on the canonical case where $s = 1$. This case has been extensively studied in computational social choice~\cite{LuB,SkworonFL,SkworonFS15,Heuristics,Elkind17,BrillFST19}, starting with the work of Chamberlin and Courant~\cite{CC}.  Here, each voter $v$ is represented by candidate $\argmin_{c \in T} r_v(c)$, that is, the most preferred candidate from $T$ in $v$'s ordering. The score of the voter is the rank of its representative, and the goal is to minimize the average of this score over the voters. This rule is also called the {\em Chamberlin-Courant} voting rule, though we will henceforth call it the $1$-Borda score for consistency with the generalizations we study later.

The $1$-Borda score is an ordinal version of the celebrated $k$-medians problem~\cite{AryaGKMMP04}. Unfortunately, for the ordinal version, it is not possible to approximate the minimum  score, $\opt$, to any constant factor in polynomial time unless $\p = \np$~\cite{SkworonFS15}.

\paragraph{The \g{} Algorithm.} A natural algorithm for the $1$-Borda score is the \g{} algorithm that iteratively adds the candidate that decreases the $1$-Borda score the most. This algorithm was analyzed in~\cite{LuB} as follows. Consider the maximization (or satisfaction) version where the score of a candidate $c$ for voter $v$ is $m + 1 - r_v(c)$, so that the score of a committee $T$ is $m + 1 - r_{\V}(T)$. Clearly, the maximization and minimization versions have the same optimum solutions, though they are very different from an approximation perspective. It is easy to check that the maximization objective is submodular~\cite{LuB}, so that \g{} is a $\left(1 - \frac{1}{e}\right)$-approximation by the classic result of~\cite{NWF}. However, this analysis only shows that \g{} yields a solution of score at most $m/e$ for the minimization objective.

Our first, and technically most challenging, contribution is an almost-tight analysis of this \g{} heuristic for the minimization version. In Section~\ref{sec:greedy}, we show that it achieves a score (given by Eq.~(\ref{eq:sborda})) of at most $2 \cdot\frac{m+1}{k+1}$ for any instance with $m$ candidates from which we need to choose a committee of size $k$. We complement this analysis by exhibiting an instance where \g{} has score at least $1.962 \cdot\frac{m+1}{k+1}$. 

For the maximization (or satisfaction) version, since the maximum possible score is $m$, the above result directly implies the following theorem.
\begin{theorem}
\label{thm:greedymax}
\g{} is a $\left(1 - \frac{2}{k+1}\right)$-approximation for the maximization version of $1$-Borda score.
\end{theorem} 
For $k$ larger than a small constant, this {\em significantly improves} the submodularity-based analysis~\cite{LuB} that only yields a $(1-1/e)$-approximation. Furthermore, it also improves on the best known approximation algorithm for this problem, Algorithm P in~\cite{SkworonFS15}, which achieves an approximation factor of $\left(1 - O\left(\frac{\ln k}{k}\right)\right)$.
%This  %In particular, it shows that  for the maximization objective.

At a technical level, the standard analysis of \g{} for maximizing submodular functions shows that the next candidate yields an improvement in objective that is at least $1/k$ fraction of the gap between the current solution and the optimum. We use Cauchy-Schwarz inequality on per-voter improvements to show an overall improvement per step that has a {\em quadratic} dependence on the gap. This yields a significant improvement when the gap is large, and is the crux of why we are able to improve the upper-bound analysis of the maximization version significantly. Our lower bound instance works by carefully choosing per-voter improvements that make Cauchy-Schwarz inequality almost tight. This requires a non-trivial construction where the candidates chosen by \g{} have ranks that lie on a carefully chosen spiral, and these are interspersed with candidates for whom voters' preferences are random. The ranks in each subsequent layer of the spiral decrease by a factor equal to the golden ratio.

\paragraph{A Benchmark and an Optimal Algorithm.} The next natural question we ask is: How much better can we do in polynomial time? In Section~\ref{sec:lower}, we show some hardness results for the minimization version (Eq~(\ref{eq:sborda})). %It is easy to show that there exist instances where the best possible (optimal) score $\opt$ is at least $\frac{m+1}{k+1}$. 
Our main result {\em significantly improves} the constant factor hardness of approximation result of~\cite{SkworonFS15} and shows the following: 

\begin{theorem}
\label{thm:main_lb}
\label{thm:hardness}
Unless $\zpp = \np$, no polynomial-time algorithm can distinguish between instances with $\opt \ge (1 - o(1)) \cdot \frac{m+1}{k+1}$ from those with either:
\begin{enumerate}
    \item $\opt \le \left(\frac{m+1}{k+1}\right)^{\delta}$, where $\delta \in (0,1)$ is a constant; or
    \item $\opt \le \frac{1}{k^{\alpha}} \cdot \frac{m+1}{k+1}$, where $\alpha > 0$ is a constant.
\end{enumerate}
\end{theorem}
%Unless $\zpp = \np$, no polynomial-time algorithm can distinguish between instances with $\opt \ge (1 - \varepsilon) \cdot \frac{m+1}{k+1}$ from those with  $\opt < \varepsilon \cdot \frac{m+1}{k+1}$, where $\varepsilon > 0$ is any constant.
%Unless $\np = \zpp$, for any constant $\varepsilon > 0$, there is no polynomial-time algorithm that can distinguish between instances where $\opt = 1$\kn{not exactly $1$... Let me figure it out.} and where $\opt > (1 - \varepsilon) \frac{m+1}{k+1}$. In other words, no polynomial-time algorithm can always output a solution of score at most $(1 - \varepsilon) \frac{m+1}{k+1}$ when $\opt = 1$.
This construction yielding this theorem is delicate. We require the full power of Feige's hardness proof of {\sc Max Cover}~\cite{Feige}, in particular, that it works on ``regular'' instances where each set has the same size, and where a collection of disjoint sets cover the instance completely in the ``YES'' case.

Theorem~\ref{thm:main_lb} motivates us to define the score $\frac{m+1}{k+1}$ as a reasonable benchmark for this problem, and we call any efficient algorithm achieving this score as an ``optimal algorithm''. Such a benchmark is appealing in that it helps us analyze other simple and natural algorithms that have been proposed in literature, and perform a more fine-grained comparison. As we have already seen, the \g{} algorithm is always within a factor of $2$ of this benchmark. 

We now observe that if we pick a subset of $k$ candidates at random from $\C$, the expected score is exactly the benchmark $\frac{m+1}{k+1}$. We therefore denote the score $\frac{m+1}{k+1}$ as $\rand$. Now, we can design a deterministic optimal algorithm via derandomizing this randomized algorithm. Interestingly, we show that this derandomization yields a greedy algorithm that is exactly the same as the \b{} algorithm proposed in~\cite{Heuristics} as a polynomial time heuristic for this problem. In that work, the \b{} algorithm was derived by viewing the problem as a cooperative game where players are candidates, and coalitions are committees, and adapting the notion of Banzhaf score of coalitions~\cite{Banzhaf,dubeyS}. It was emprically shown to be a very effective heuristic for this problem, beating \g{} on most instances. We justify this empirical observation by viewing the \b{} algorithm instead as a derandomization of an optimal randomized algorithm. 

In summary, we show the following theorem. 
\begin{theorem}
\label{thm:main_banzhaf}
The \b{} algorithm achieves a minimization objective of at most $\rand = \frac{m+1}{k+1}$ in polynomial time, and is a $\left(1 - \frac{1}{k+1}\right)$-approximation to the maximization objective of $1$-Borda.
\end{theorem}
To complete the picture, we show that an easy consequence of Theorem~\ref{thm:main_lb} is that the approximation factor of $\left(1 - \frac{1}{k+1}\right)$ is best possible for the maximization version unless $\np = \zpp$.

\paragraph{Committee Monotonicity.} One appealing property of \g{} is that it is \emph{committee-monotone}~\cite{Elkind17}: The committee found for a smaller $k$ is always a subset of a committee found for larger $k$'s. This is immediate because \g{} adds the next candidate to the committee based on the improvement in the $1$-Borda score, and this improvement does not depend on $k$. On the other hand, the \b{} algorithm requires knowledge of $k$ at each greedy step, and is therefore not committee-monotone. We therefore ask: Is there a committee-monotone algorithm that can achieve the benchmark $\rand$? In Section~\ref{sec:monotone}, we answer this question in the negative: There exist instances where any committee-monotone algorithm has score at least $1.015 \cdot \rand$. This shows a separation between committee-monotone algorithms and an optimal algorithm such as the \b{} algorithm.

\paragraph{Connection to the Core.} The notion of core from cooperative game theory is appealing as a notion of fairness, and provides a strong notion of proportionality. Informally, in a core solution, every reasonably large subgroup of voters is happy in the sense that they do not all prefer the same candidate outside the chosen committee. Formally, the work of~\cite{JiangMW20,ChengJMW20} defines an $\alpha$-approximate core as follows. Fix some $\alpha \ge 1$. Given a committee $T$ of size $k$, a candidate $c$ is blocking if at least $\alpha \cdot \frac{n}{k}$ voters prefer $c$ to any candidate in $T$, that is,
\begin{equation}
    \label{eq:core}
\left| \Big\{v \in \V \ \Big| \ r_v(c) < \min_{c' \in T} r_v(c') \Big\} \right| \ge \alpha \cdot \frac{n}{k}.
\end{equation}
A committee $T$ is in the $\alpha$-approximate core if it does not admit  a blocking candidate. The work of~\cite{ChengJMW20,JiangMW20} shows that a $16$-approximate core always exists and can be computed in polynomial time, while a $(2-\varepsilon)$-approximate core is not guaranteed to exist for any constant $\varepsilon > 0$.

In Section~\ref{sec:core}, we show that the core indeed achieves a stronger notion of proportionality than the $1$-Borda score in the following sense: Any $\alpha$-approximate core solution has $1$-Borda score at most $\alpha (1+1/k) \cdot \rand$. The converse of this statement is however false: None of \opt{}, \g{}, or \b{} lies in an $\alpha$-approximate core for any constant $\alpha$. 

\subsection{Results for $s$-Borda Score}
We next consider the $s$-Borda score for $1 < s \le k$. We start with an analysis of the natural extensions to the greedy algorithms considered above for $s = 1$. It is easy to show that choosing a random committee of size $k$ yields expected score $\frac{s(s+1)}{2} \cdot \rand$, where as before, $\rand = \frac{m+1}{k+1}$. This implies its derandomization -- the \b{} algorithm -- has score at most $\frac{s(s+1)}{2} \cdot \rand$. Furthermore, there are instances where the best possible score $\opt \ge \frac{s(s+1)}{2} \cdot \rand$.

\paragraph{Analysis of \g{}.}
The \g{} algorithm extends naturally to this setting. In Section~\ref{sec:sborda_greedy} and Appendix~\ref{app:sborda}, we extend the result in Section~\ref{sec:greedy} to show that \g{} achieves an $s$-Borda score of at most $2s^2 \cdot \rand$, which is within a factor of $\frac{4s}{s + 1}$ of the upper bound for the \b{} algorithm.  

For the maximization version, recall that the score of candidate $c$ for voter $v$ is $m + 1 - r_c(v)$, and the voter's score for a committee is the sum of top $s$ candidate scores. Since the maximum possible score at most $ms$, this directly implies the following theorem.  For $s = o(k)$, this again {\em significantly improves} on the classic submodularity-based analysis that only shows a $\left(1 - \frac{1}{e}\right)$-approximation.
\begin{theorem}
\g{} is a  $\left(1-\frac{2s}{k+1}\right)$-approximation for the maximization version of $s$-Borda.
\end{theorem}
Note that for the related maximum multi-cover problem~\cite{Barman}, the approximation factor of $(1-1/e)$ is actually tight for \g{}. Therefore, our analysis of \g{} points to fundamental algorithmic differences between {\sc Max Multi-Cover} (resp. {\sc Max Cover}~\cite{Feige}) and $s$-Borda (resp. $1$-Borda), since we obtain significantly better factors for the latter.

\paragraph{Improved Algorithm.}
In contrast with the $s=1$ case, for larger values of $s$, we can obtain a non-trivial improvement over these greedy algorithms (for the minimization version of $s$-Borda) by using the natural LP relaxation for this problem~\cite{Byrka}. In Section~\ref{sec:lp}, we devise a randomized algorithm that is based on carefully combining dependent rounding of this LP solution with choosing a committee by uniform random sampling. We show that this  algorithm achieves expected score 
\[
\alg \le 3 \cdot \opt + O\left(s^{3/2} \log s \right) \cdot \rand,
\]
where $\opt = \min_{T \subseteq \C, |T| = k} r_{\V}(T)$ is the minimum possible $s$-Borda score of any committee. 

This result improves on the aforementioned bounds for greedy algorithms when $\opt$ is small. For instance, if $\opt = O(s^{3/2}) \cdot \rand$, the improvement is $\tilde{\Omega}(\sqrt{s})$.  We note that such an improved bound cannot be achieved by \g{} when $\opt$ is small: In Section~\ref{sec:sborda_g_lb}, we show instances where $\opt = o(1) \cdot \rand$, while the score of \g{} is $\Omega(s^2)\cdot \rand$. On the flip side, our improved bound is based on solving and rounding an LP, and is therefore not as simple or intuitive as the \g{} or \b{} algorithms.

%\km{Hardness result here. Should we assume $s$ is a constant?}
%\km{Can we devise an improved algorithm not based on solving the LP?}

\subsection{Related Work}
The literature on multiwinner elections is too vast to survey here. We present a survey of computational results in this space to place our work in context.

Suppose the candidates and voters are embedded in a metric space, and suppose  the score $r_v(c)$ is not the Borda score, but instead the metric distance between voter $v$ and candidate $c$. Then the objective for the $s = 1$ case is precisely the celebrated $k$-medians objective~\cite{AryaGKMMP04,JainV,LinV,CharikarGTS}, while the general-$s$ case has been studied as fault-tolerant $k$-medians~\cite{fault}. For both these problems, constant-factor approximation algorithms are known. The versions we consider can therefore be viewed as ordinal versions of $k$-medians and fault tolerant $k$-medians respectively. Towards showing better bounds for the ordinal versions, it is tempting to impose a condition such as the ordinal preferences of voters should correspond to distances in some underlying metric space. However, it is easy to show that given any set of ordinal preferences, there is a metric space that can realize these preferences, which means this assumption does not help. Nevertheless, the LP relaxation we use to derive improved bounds for the $s$-Borda score is the same as the standard LP relaxation for the (fault-tolerant) $k$-medians objective~\cite{fault}. It is an interesting open question to explore what other natural assumptions on voter preferences will lead to improved upper bounds for the $1$-Borda and $s$-Borda objectives.

The work of~\cite{Elkind17} considers generalizations of the $1$-Borda and $s$-Borda scores to \emph{committee scoring rules}. A committee scoring rule is a function that for each voter $v$ and committee $T$ of size $k$, maps the set of ordinal ranks $\{r_v(c), c \in T\}$ to a score. The $s$-Borda score we consider is an example of a decomposable rule, meaning that the score can be written as a sum of contributions from the committee members. The work of~\cite{SkworonFL,SkworonFS15} defines a special case of committee scoring rules where the score is a weighted sum of ranks of the committee members. They call these Ordered Weighted Average (OWA) rules. Again, it is easy to see that the $s$-Borda rule is an OWA rule. For the maximization version of committee scoring rules, the \g{} algorithm continues to be a $\left(1 - \frac{1}{e}\right)$-approximation via submodularity. It is an interesting open question to extend the results in this paper to other rules that achieve diverse or proportional representation~\cite{BrillFST19,AzizB20}.

Finally, the work of~\cite{Byrka} considers the variant where the score $r_v(c)$ is an arbitrary cardinal value, which is different from our focus on ordinal preferences. They consider the ``harmonic'' OWA rule where a voter assigns weight $1$ to candidate in the committee with lowest score, weight $\frac{1}{2}$ to the candidate with second lowest score, and so on, till weight $\frac{1}{k}$ to the candidate with highest score. They show this version has a constant-factor approximation algorithm by randomized rounding of the natural LP relaxation, first used in~\cite{cornuejols1983}. The difficulty with the $s$-Borda rule is that the weight jumps discretely from $1$ to $0$ when we move from the top $s$ candidates for a voter to the $(s+1)^{\text{st}}$ candidate. This discontinuity is most pronounced for $s = 1$, and leads to our strong impossibility result. In essence, this discontinuity is what motivates us to consider an alternate benchmark to analyse the performance of natural greedy algorithms assuming ordinal preferences.

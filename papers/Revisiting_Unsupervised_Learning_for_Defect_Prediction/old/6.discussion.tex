\section{Discussion}
\subsection{ Is a Low Precision {\it OneWay} Learner Useful}
\wei{DO we need to use precision? how to explain. feel struggled here.}


In last section, we notice that {\it OneWay} learner does not 
perform well in terms of {\it Precision} compared to the supervised learners
in RQ3. However, it is still a quite useful learner and the reason is as follows.

First of all, for effort-ware defect prediction like this study, we only set 
 $20\%$ efforts(measured in code churn) as our budget, which is quite small amount
 of effort compared with the total. 




 






\subsection{Threats to Validity}
In this section, we discuss the potential factors that might threat our results.

\textbf{Internal Validity}. The internal validity is related to uncontrolled
aspects that may affect the experimental results. One threat to the interval
is how well our implementation of unsupervised learners could represent 
the Yang et al.'s method. To mitigate this thread, we strictly follow 
the approach described in Yang et al's work and test our implementation on the
same data sets as in \cite{yang2016effort}. By comparing the performance
scores, we find that our implementation can generate the same results. Therefore,
we believe we can avoid this threat.

\textbf{External Validity}. The external validity is related to the
possibility to generalize our results. Our observations and conclusions
from this study may not be generalized to other software projects. In this study,
we use six widely used open source software project data as the subject.
As all these software projects are written in java, we can't  guarantee that
our findings can be directly generalized to other projects,
specifically to the software that implemented in other programming
languages. Therefore, the future work might include verify our findings on 
other software project.

In this work, we used the data sets from~\cite{yang2016effort,kamei2013large}, where
totally 14 features were extracted from the software projects.  We build and test the
{\it OneWay} learner on those features as well. However, there might be some other features
that not measured in these data sets that work well as indicators for defect prediction.
For example, the role of the developer who committed the change(e.g., owner of the files,or not),
functionality of the the files modified in this change(e.g., core functionality or not).
Those new features that not explored in this study might improve the performance of 
our {\it OneWay} learner.

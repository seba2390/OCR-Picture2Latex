To evaluate the performance of ensemble fuzzing, we run \toolOne, \toolTwo ~and \toolThree ~separately. To additionally evaluate the effectiveness of seed synchronization, we also run \toolFour ~with the intuitive ensemble of the same base fuzzers, but without seed synchronization mechanism.
However, all ensemble fuzzers use 4 times the computing resources of base fuzzers, to eliminate the unfairness, we need to allocate the same computing resources to these base fuzzers. 
Luckily, most fuzzers support parallel mode which allows using multiple CPU cores to fuzz one target application in parallel. 
In industry practice, fuzzers generally work in parallel mode.
Therefore, we run each base fuzzer in parallel mode with four CPU cores respectively. %In this way, the computing resources usages of these base fuzzers are the same as ensemble fuzzers. 
The results are presented in Table \ref{tab:ensemble_path},  \ref{tab:ensemble_branch} and  \ref{tab:ensemble_crash}, which show the number of paths executed, branches covered and unique crashes detected by AFL, AFLFast, FairFuzz, libFuzzer, Radamsa, \toolFour, \toolOne, \toolTwo ~and \toolThree. 



\newcolumntype{C}{>{\arraybackslash}p{1.1cm}}
\NewEnviron{mytable_ensemble}[2]{
  \begin{table}[tp]
    \caption{#1}
    \scalebox{0.55}[0.8]{%
      \label{tab:#2}
      \begin{tabular}{l|CCCCCCCCC}
        \toprule
        {\mysize Project}
        & {\mysize AFL }
        & {\mysize AFLFast }
        & {\mysize FairFuzz }
        & {\mysize libFuzzer }
        & {\mysize Radamsa }
        & {\mysize Enfuzz$^{-}$}
        & {\mysize Enfuzz-A}
        & {\mysize Enfuzz-L}
        & {\mysize Enfuzz}\\
        \midrule
        \BODY
        \bottomrule
      \end{tabular}
    }
  \end{table}%
}

\begin{mytable_ensemble}{Number of paths for parallel mode with four CPU cores. The variation of each case and the total improvement.}{ensemble_path} 
boringssl   & 3286   & 2816     & 3393     & 5525     & 3430     & 2590     & 4058     & 6782     & 7136     \\
c-ares-CVE  & 146    & 116      & 146      & 191      & 146      & 149      & 167      & 251      & 253      \\
guetzli     & 3248   & 2550     & 1818     & 3844     & 3342     & 2066     & 3501     & 4314     & 4508     \\
lcms        & 1682   & 1393     & 1491     & 1121     & 1416     & 1056     & 1846     & 2253     & 2433     \\
libarchive  & 12842  & 10111    & 12594    & 22597    & 12953    & 4823     & 14563    & 28531    & 31778    \\
libssh      & 110    & 102      & 110      & 362      & 110      & 109      & 140      & 377      & 377      \\
libxml2     & 14888  & 13804    & 14498    & 28797    & 17360    & 11412    & 19928    & 33940    & 35983    \\
openssl     & 4090   & 3425     & 3956     & 2304     & 3328     & 3949     & 4976     & 4983     & 4991     \\
pcre2       & 79581  & 66894    & 71671    & 59616    & 78347    & 57721    & 81830    & 84681    & 85386    \\
proj4       & 342    & 302      & 322      & 509      & 341      & 362      & 393      & 708      & 709      \\
re2         & 12093  & 10863    & 12085    & 15682    & 12182    & 9053     & 13019    & 17056    & 17155    \\
woff2       & 23     & 16       & 20       & 447      & 22       & 19       & 25       & 1314     & 1324     \\
\midrule  
Total       & 132331 & 105138   & 122104   & 140995   & 132977   & 93309    & 144446   & 185190   & 192033   \\
\midrule  
\textbf{Improvement} &  \textbf{-}     & \textbf{21\% $\downarrow$} & \textbf{-8\% $\downarrow$} & \textbf{7\% $\uparrow$} & \textbf{1\% $\uparrow$} & \textbf{-29\%$\downarrow$} & \textbf{9\% $\uparrow$} & \textbf{40\% $\uparrow$} & \textbf{45\% $\uparrow$} \\
\midrule  
\textbf{variation}	&  \textbf{-} & \textbf{[-30\%, -7\%]}	& \textbf{[-44\%, +3\%]}		& \textbf{[-43\%, +184\%]}		& \textbf{[-18\%, +16\%]}		& \textbf{[-62\%, +2\%]}		& \textbf{[+3\%, +34\%]} 		& \textbf{[+6\%, +5613\%]}		& \textbf{[+7\%, +5657\%]}	\\ 
\end{mytable_ensemble}

\begin{mytable_ensemble}{Number of branches for parallel mode with 4 CPU cores. The variation of each case and the total improvement.}{ensemble_branch}
boringssl   & 3834   & 3635     & 3894     & 3863     & 3880     & 3210     & 3996     & 4016     & 4108     \\
c-ares-CVE  & 285    & 276      & 285      & 202      & 285      & 285      & 285      & 285      & 285      \\
guetzli     & 3022   & 2723     & 1514     & 4016     & 3177     & 2074     & 3316     & 3531     & 3644     \\
lcms        & 3985   & 3681     & 3642     & 3015     & 2857     & 2872     & 4054     & 4098     & 4169     \\
libarchive  & 10580  & 9267     & 8646     & 8635     & 11415    & 6092     & 12689    & 13267    & 13949    \\
libssh      & 614    & 614      & 614      & 573      & 614      & 613      & 614      & 614      & 614      \\
libxml2     & 15204  & 14845    & 14298    & 13346    & 19865    & 14428    & 17657    & 21664    & 21899    \\
openssl     & 4079   & 4004     & 4021     & 3923     & 4074     & 4037     & 4176     & 4202     & 4216     \\
pcre2       & 50558  & 48004    & 49430    & 36539    & 51881    & 32471    & 51801    & 52267    & 53912    \\
proj4       & 267    & 267      & 267      & 798      & 267      & 267      & 267      & 907      & 907      \\
re2         & 17918  & 17069    & 17360    & 16001    & 17312    & 16300    & 18070    & 19323    & 19688    \\
woff2       & 120    & 120      & 120      & 2785     & 120      & 120      & 120      & 3939     & 3945     \\
\midrule 
Total       & 110466 & 104505   & 104091   & 93696    & 115747   & 82769    & 117045   & 128113   & 131336   \\
\midrule 
\textbf{Improvement} &  \textbf{-}     & \textbf{-5\% $\downarrow$} & \textbf{-6\% $\downarrow$} & \textbf{-15\%$\downarrow$} & \textbf{5\% $\uparrow$} & \textbf{-25\%$\downarrow$} &\textbf{6\% $\uparrow$} & \textbf{16\% $\uparrow$} & \textbf{19\% $\uparrow$} \\
\midrule  
\textbf{variation}	& \textbf{-}		& \textbf{[-10\%, 0\%]}		& \textbf{[-50\%, +2\%]}		& \textbf{[-29\%, +2221\%]}			& \textbf{[-28\%, +31\%]}			& \textbf{[-42\%, 0\%]} 		& \textbf{[0\%, +20\%]}		& \textbf{[0\%, +3182\%]}		& \textbf{[0\%, +3188\%]}		\\ 
\end{mytable_ensemble}



\textit{1) Performance of Our Ensemble Fuzzers.}
%9. diverisity越大，提升越明显，enfuzz1的diversity很小，但却能够有效提升。enfuzz2和enfuzz3的diversity提高了，最终集成效果也提高了。
For \toolOne ~which integrates AFL, AFLFast and FairFuzz as base fuzzers and implements the seed synchronization with global coverage map, compared with AFL, AFLFast and FairFuzz running in parallel mode with four CPU cores used, it always executes more paths and covers more branches on all applications. In total, it covers 9.16\%, 39.2\% and 20.0\% more paths and achieves 5.96\%, 12.0\% and 11.1\% more covered branches respectively.
Benefiting from the increased coverage, \toolOne ~triggers 26.8\%, 117\% and 39.5\% more unique crashes in total.
It reveals that the robustness and performance can be improved even when the base fuzzers chosen are not massively diverse.

Compared with \toolOne, ~\toolFour ~which integrates the same base fuzzers --- AFL, AFLFast and FairFuzz, but does not implement seed synchronization mechanism. 
%There is no doubt that 
\toolFour ~performs much worse on all applications. It even performs worse than each base fuzzer in parallel mode. In total, it only executes 64.5\% paths, covers 70.7\% branches and triggers 16.8\% unique crashes of \toolOne. Especially for unique crashes, seed synchronization effectively increases the probability of detecting vulnerabilities of target applications. \textbf{The results reveal that the seed synchronization helps improve performance of ensemble fuzzing greatly, acquires significant improvement over the existing industry practice of simply running many different types of fuzzers in parallel without seed sharing. }
%in both paths coverage and branches coverage greatly. Especially for unique crashes, it effectively increases the probability of detecting vulnerabilities of target applications.

For the \toolTwo ~which integrates AFL, AFLFast, FairFuzz and libFuzzer as base fuzzers, the results are presented in the seventh columns of table \ref{tab:ensemble_path},  \ref{tab:ensemble_branch} and  \ref{tab:ensemble_crash}.
As mentioned in section \ref{diversity}, the diversity among these base fuzzers are much larger than \toolOne. It contains both the seed selection as well as mutation diversity and the coverage information granularity diversity. 
Compared with \toolOne, \toolTwo ~always performs better on all target applications. In total, it covers 28.2\% more paths, executes 9.46\% more branches and triggers 9.95\% more crashes than \toolOne.




\begin{mytable_ensemble}{Number of crashes for parallel mode with four CPU cores. The variation of each case and the total improvement.}{ensemble_crash}
boringssl   & 0    & 0        & 0        & 9        & 0        & 0        & 0        & 4        & 4        \\
c-ares-CVE  & 15   & 12       & 14       & 16       & 15       & 12       & 18       & 23       & 25       \\
guetzli     & 0    & 0        & 0        & 1        & 0        & 0        & 0        & 1        & 1        \\
lcms        & 6    & 5        & 6        & 0        & 5        & 0        & 7        & 12       & 16       \\
libarchive  & 0    & 0        & 0        & 6        & 0        & 0        & 27       & 51       & 52       \\
libssh      & 0    & 0        & 0        & 5        & 0        & 0        & 4        & 6        & 6        \\
libxml2     & 11   & 7        & 9        & 15       & 16       & 7        & 13       & 22       & 30       \\
openssl     & 68   & 8        & 66       & 67       & 65       & 21       & 86       & 92       & 101      \\
pcre2       & 3360 & 2001     & 3078     & 2986     & 3120     & 702      & 4234     & 4593     & 4803     \\
proj4       & 14   & 0        & 4        & 15       & 13       & 0        & 15       & 16       & 22       \\
re2         & 3    & 0        & 1        & 7        & 2        & 0        & 5        & 8        & 13       \\
woff2       & 2    & 0        & 0        & 8        & 2        & 0        & 3        & 23       & 27       \\
\midrule  
Total       & 3479 & 2033     & 3178     & 3135     & 3238     & 742      & 4412     & 4851     & 5100     \\
\midrule  
\textbf{Improvement} &  \textbf{-}   & \textbf{-42\%$\downarrow$} & \textbf{-9\% $\downarrow$} & \textbf{-10\%$\downarrow$} & \textbf{-7\% $\downarrow$} & \textbf{-79\%$\downarrow$} & \textbf{27\% $\uparrow$} & \textbf{40\% $\uparrow$} & \textbf{47\% $\uparrow$} \\
\midrule  
\textbf{variation}	& \textbf{-}		& \textbf{[-88\%, -17\%]}		& \textbf{[-71\%, -2\%]}		& \textbf{[-11\%, +300\%]}			& \textbf{[-33\%, +45\%]}		& \textbf{[-79\%, 0\%]} 		& \textbf{[+17\%, +67\%]}		& \textbf{[+14\%, +1050\%]}		& \textbf{[+43\%, +1250\%]}		\\ 
\end{mytable_ensemble}

For the \toolThree ~which integrates AFL, AFLFast, libFuzzer and Radamsa as base fuzzers, the diversity is the largest. Compared with \toolTwo, it always performs better and covers 3.7\% more paths, executes 2.5\% more branches and triggers 5.1\% more crashes. 
In total, compared with all these base fuzzers --- AFL, AFLFast, FairFuzz, libFuzzer and Radamsa, \toolThree ~shows the best robustness and performance. It discovers 46.59\%, 150\%, 60.47\%, 62.67\%, 57.50\% more unique crashes, executes 45.11\%, 82.64\%, 57.27\%, 36.19\% and 44.41\% more paths and covers 18.89\%, 25.67\%, 26.17\%, 40.17\% and 13.47\% more branches respectively. 
\textbf{These statistics demonstrate that the more diversity among these base fuzzers, the better the ensemble fuzzer performs with the global asynchronous and local synchronous based seed synchronization mechanism.} %and the seed synchronization mechanism contributes high improvements.}
%If we run those base fuzzers and \toolThree ~with more CPU cores, e.g. 8 or 12, the performance improvements will remain.

Same as the illustration for the motivation example of section \ref{Motivating Example}, there are two main reasons for the high performance. 
The first is the diversity of base fuzzers. Fuzzers with different fuzzing strategies cover different paths and branches. When combined together, the ensemble results are better than the constituent base fuzzers. 
The second is the effective seed synchronization mechanism. With the help of this strategy, all interesting but hard-to-hit seeds are asynchronously pushed to the global seed pool and synchronouly dispatched to the local queue of each base fuzzer, enabling effective communication and corporation among base fuzzers.

\textit{2) Performance of Base Fuzzers in Parallel Mode}
The first five columns of Table \ref{tab:ensemble_path} reveal the issue of the performance variation in those base fuzzers, as they perform variously on different applications in parallel mode. Comparing AFL family tools, AFL performs better than the other two optimized fuzzers on 10 applications, FairFuzz performs the best on the other 2 applications, AFLFast fails to perform the best on any application.
Compared with AFL, libFuzzer performs better on 9 applications, but worse on 3 applications;
Radamsa performs better on 6 applications, but also worse on 6 applications.
Table \ref{tab:ensemble_branch} and Table \ref{tab:ensemble_crash} show similar results on branch coverage and unique crashes.



%% 7. 与AFL相比，AFL的优化（aflfast，fairfuzz）在单线程下表现比afl好，在多线程情况下不如afl ： 解释原因
First three columns of Table \ref{tab:ensemble_path} and Table \ref{tab:single_path} show that the performance of base fuzzers in parallel mode is quite different from that in single mode. Compared with the optimized fuzzers, original AFL performs the best on 10 applications in parallel mode with 4 CPU cores. For the total number of paths executed, AFL performs the best and AFLFast performs the worst in parallel mode. While in single mode with one CPU core used, the situation is exactly the opposite, and the original AFL only performs the best on 4 applications. 


%In fact, according to the experiments, compared with AFLFast and FairFuzz, AFL generally performs better than the other two optimized fuzzers in parallel mode.
The reason for performance degradation of these optimizations in parallel mode is that their studies lack the consideration for synchronizing the  additional guiding information.
Take AFLFast for example, it models coverage-based fuzzing as Markov Chain, and the times of random mutation for each seed will be computed by a power scheduler. This strategy works well in single mode, %as their evaluation presented, 
but it would fail in parallel mode because the statistics of each fuzzer's scheduler are limited in current thread. %This is critical, because fuzzers generally work in parallel on practical industry applications. 
\textbf{Our evaluation demonstrates that many optimized fuzzing strategies could be useful in single mode, but fail in the parallel mode which is widely used in industry practice. This experiment setting has been missed by many previous literature studies.} 
%when they conclude that the optimization performs better than the traditional AFL




%8. 在多线程场景，radamsa的提升比单线程下要低： （1）radamsa生成的大量无用input会影响afl多线程之间的通信。 （2）afl多线程之间通过共享种子，能够有效自己的性能，这和radamsa所能提供的提升重合了
From the fifth columns of Table \ref{tab:ensemble_path} and Table \ref{tab:single_path}, we find that compared with Radamsa in single mode, the improvement achieved by Radamsa is limited in parallel mode. There are two main reasons:
(1) Too many useless inputs generated by Radamsa slow down the seed-sharing efficiency among all instances of AFL. This seed-shared mechanism does not exist in single mode.
(2) Some interesting seeds can be created in parallel mode and shared among all instances of AFL. 
These seeds overlap with the inputs generated by Radamsa. So this improvement is limited in parallel mode.


As for the performance of ensemble fuzzing versus those base fuzzers running in parallel mode, the last three columns of Table \ref{tab:ensemble_path},  \ref{tab:ensemble_branch} and  \ref{tab:ensemble_crash} show the performance of three prototypes: \toolOne, \toolTwo ~and \toolThree. 
Compared with AFL, AFLFast, FairFuzz libFuzzer and Radamsa in parallel mode with four CPU cores used, the generalization ability and performance of these ensemble fuzzers are better than individual base fuzzers, they always perform better on all target applications.
%
%10. enfuzzer2 和 enfuzzer3 相对于enfuzz1 或者afl 来说，在某些项目上提升不大：（pcre）， 因为libfuzzer在这个项目上的效果本来就比afl差不少，集成了libfuzzer后，效果提升不明显 （branch提升没有path提升明显的原因类似）
In addition, we notice that comparing \toolThree ~with AFL, there is significant deviation of improvements among different applications, ranging from 7\% to 566\%. Take the pcre2 for example, \toolThree ~only covers 7\% more paths than AFL. However, when compared with libFuzzer, \toolThree ~covers 42.04\% more paths. The basic idea of ensemble is to learn from others' strong points to offset one's weaknesses.
For pcre2, libFuzzer performs worse and AFL performs better; the improvement is little when compared with AFL, but much larger when compared with libFuzzer.
The reason why improvement is much less in branch coverage than in path coverage when compared with AFL is the same.

\vspace{0.2cm}
%\subsubsection{Ensemble Statics Conclusion}
\noindent\textbf{From these experiment comparisons and real CVE mining described in the appendix section, we conclude that 
(1) the issue of performance variation exists in both the single mode and parallel mode of most existing popular fuzzers;
(2) the optimization of fuzzing strategy works in single mode on certain situations can not be applied to parallel mode directly, and in most cases the performance of the optimization is worse in parallel mode;
(3) ensemble fuzzing can help mitigate performance variation and improve the performance of base fuzzers with the same resources usage, and the more diversity among these base fuzzers, the better the ensemble fuzzer performs.}
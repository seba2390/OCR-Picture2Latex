Here below, we introduce the work related to generation-based fuzzing, mutation-based fuzzing, fuzzing in practice and the main differences between these projects. After that we summarize the inspirations and introduce our work.

\subsection{Generation-based Fuzzing}
Generation-based fuzzing generates a massive number of test cases according to  the specification of input format, e.g. a grammar. To fuzz the target applications that require inputs in complex format, the specifications used are crucial.
There are many types of specifications. Input model and context-free grammar are the two most common types.
Model-based fuzzers \cite{peach,skyfire,spike} follow a model of protocol. Hence, they are able to find more complex bugs by creating complex interactions with the target applications.
Peach \cite{peach} is one of the most popular model-based fuzzers with both generation and mutation abilities.
It develops two key models:
the data model determines the format of complex inputs and the state model describes the concrete method for cooperating with fuzzing targets.
By integrating fuzzing with models of data and state, Peach works effectively. 
Skyfire \cite{skyfire} first learns a context-sensitive grammar model, and then it generates massive inputs based on this model.

Some other popular fuzzers \cite{godefroid2008grammar,csmith,lava,ifuzzer,holler2012fuzzing} generate inputs based on context free grammar. 
P Godefroid \cite{godefroid2008grammar} enhances the whitebox fuzzing of complex structured-input applications by using symbolic execution, which directly generates grammar-based constraints whose satisfiability is examined using a custom grammar-based constraint solver.
Csmith \cite{csmith} is designed for fuzzing C-compilers. It generates plenty of random C programs in the C99 standard as the inputs. 
This tool can be used to generate C programs exploring a typical combination of C-language features while being free of undefined and unspecified behaviors. 
LAVA \cite{lava} generates effective test suites for the Java virtual machine by specifying production grammars.
IFuzzer \cite{ifuzzer} first constructs parse trees based on a language's context-free grammar, then it generates new code fragments according to these parse trees.
Radamsa \cite{helin2016radamsa} is a widely used generation-based fuzzer. It works by reading sample files of valid data and generating interestingly different outputs from them. Radamsa is an extreme "black-box" fuzzer, it needs no information about the program nor the format of the data. One can pair it with coverage analysis during testing to improve the quality of the sample set during a continuous fuzzing test.

\subsection{Mutation-based Fuzzing}
Mutation-based fuzzers \cite{zzuf,symfuzz,bff} mutate existing test cases to generate new test cases without any input grammar or input model specification.
Traditional mutation-based fuzzers such as zzuf \cite{zzuf} mutate the test cases by flipping random bits with a predefined ratio.
In contrast, the mutation ratio of SYMFUZZ \cite{symfuzz} is assigned dynamically. To detect bit dependencies of the input,
it leverages white-box symbolic analysis on an execution trace, then it dynamically computes an optimal mutation ratio according to these dependencies. Furthermore, BFF \cite{bff} integrates machine learning with evolutionary computation techniques to reassign the mutation ratio dynamically. 

Other popular AFL family tools \cite{afl,aflfast,aflgo,FairFuzz} apply various strategies to boost the fuzzing process. AFLFast \cite{aflfast} regards the process of target application as a Markov chain. A path-frequency based power schedule is responsible for computing the times of random mutation for each seed.
As with AFLFast, AFLGo \cite{aflgo} also proposes a simulated annealing-based power schedule, which helps fuzz the target code. %Especially, it describes a method to measure the distance between the seeds and the targets.
FairFuzz \cite{FairFuzz} mainly focuses on the mutation algorithm. It only mutates seeds that hit rare branches and it strives to ensure that the mutant seeds hit the rarest one.
(Wen Xu et.al.)\cite{xu2017designing} propose several new primitives ,
speeding up AFL by 6.1 to 28.9 times.
Unlike AFL family tools which track the hit count of each edge, libFuzzer \cite{libFuzzer} and honggfuzz \cite{Honggfuzz} utilize the SanitizerCoverage instrumentation method provided by the Clang compiler. To track block coverage, they track the hit count of each block as a guide to mutate the seeds during fuzzing.
SlowFuzz \cite{petsios2017slowfuzz} prioritizes seeds
that use more computer resources (e.g., CPU, memory and energy), increasing the probability of triggering algorithmic complexity
vulnerabilities. Furthermore, some fuzzers use concolic executors for hybrid fuzzing. Both Driller \cite{driller} and QSYM use mutation-based fuzzers to avoid path exploration of symbolic execution, while concolic execution is selectively used to drive execution across the paths that are guarded by narrow-ranged constraints.



\subsection{Cluster and Parallel Fuzzing in Industry}
Fuzzing has become a popular vulnerability discovery solution in industry \cite{liang2018fuzz} and has already found a large number of dangerous bugs and security vulnerabilities across a wide range of systems so far. For example, Google's OSS-Fuzz \cite{OSS-Fuzz} platform has found more than 1000 bugs in 5 months with thousands of virtual machines \cite{bug-report}.
% by using several popular fuzzers, including libFuzzer, honggfuzz \cite{Honggfuzz} and AFL. 
%In fact, the OSS-Fuzz platform is closely-related to the idea behind ensemble fuzzing to use multiple different fuzzers together. 
%However, it uses these fuzzers independently and does not combine them together effectively. In this way, the OSS-Fuzz platform can not improve the performance of these fuzzers themselves and has the additional problem of consuming significant computing resources. 
ClusterFuzz is the distributed fuzzing infrastructure behind OSS-Fuzz, and automatically executes libFuzzer powered fuzzer tests on scale \cite{ClusterFuzz,ClusterFuzz_two}. Initially built for fuzzing Chrome at scale, ClusterFuzz integrates multiple distributed libFuzzer processes, and performs effectively with corpus synchronization. 
ClusterFuzz mainly runs multiple identical instances of libFuzzer on distributed system for one target application. There is no diversity between these fuzzing instances.

%% 加一小段fuzzer的多线程说明，差异性不够
In industrial practice, many existing fuzzers also provide a parallel mode, and they work well with some synchronization mechisms.
%which allows fuzzing one target application with multiple parallel fuzzers across multiple cores. 
For example, each instance of AFL in parallel mode will periodically re-scan the top-level sync directory for any test cases found by other fuzzers\cite{AFLP1, AFLP2}. libFuzzer in parallel will also use multiple fuzzing engines to exchange the corpora\cite{libFuzzerP}.
These parallel mode can effectively improve the performance of fuzzer. 
%The more fuzzing jobs that are used, the better they perform. 
In fact, the parallel mode can be seen as a special example of ensemble fuzzing which uses multiple same base fuzzers. However, all these base fuzzers have a lack of diversity when using the same fuzzing strategy. %Consequently, only minor performance improvements are observed.


\begin{comment}
\subsubsection{Ensemble Learning}
Ensemble learning is a machine learning paradigm where multiple learners are trained to solve the same problem \cite{alpaydin2009introduction}. In contrast to ordinary machine learning approaches which try to learn one hypothesis from training data, ensemble methods try to construct a set of hypotheses and combine them for precision.
The diversity of base learners \cite{galar2012review} and the concrete ensemble methods \cite{zhou2012ensemble} are the two cores of ensemble learning. How to select base learners with great diversity and how to combine these base learners together are critical to the performance of ensemble learners. Many researches focus on these two parts to improve the generalization ability and the prediction accuracy of ensemble learners \cite{schapire1990strength, bauer1999empirical, ting1999issues, ting1999issues}. A number of diversity measures have been designed in ensemble learning \cite{krogh1995neural, kuncheva2003measures}. In addition, there are many effective ensemble methods, such as Boosting \cite{breiman1996bagging}, Bagging \cite{krogh1995neural, freund1997decision} and Stacking \cite{wolpert1992stacked}.
Ensemble learning has achieved a great success in most machine learning areas, contributing to better generalization ability.
\end{comment}


%% 总结一下
\subsubsection{Main Differences} Unlike the previous works, we are not proposing a new concrete generation-based or mutation-based fuzzing strategy. 
%or run different fuzzers on different machines, 
Nor do we run multiple identical fuzzers with multiple cores or machines. Instead, inspired by the seed synchronization of ClusterFuzz and AFL in parallel mode, we systematically study the possibility of the ensemble fuzzing of diverse fuzzers mentioned in the earlier works. Referred to the kernel descriptions of the evaluating fuzzing guidelines\cite{klees2018evaluating}, we empirically evaluate most state-of-the-art fuzzers, and identify some valuable results, especially for their performance variation across different real applications. To generate a stronger ensemble fuzzer, we choose multiple base fuzzers that are as diverse as possible based on three heuristics. We then implement an ensemble approach with global asynchronous and local synchronous based seed synchronization. 

\begin{comment}
%%加一小段learning 和 fuzzing 的不同，说明learning的一些ensemble method 不能直接用， 需要根据fuzzing的特点，设计适合fuzz的ensemble method
Furthermore, %when fuzzing general real-world applications, 
there are many differences between ensemble learning and ensemble fuzzing. 
Firstly, ensemble classifiers can vote in final predictions, and ensemble regression can take an average or mode of outputs. Each base learner will provide an answer for any instance and we can ensemble them by averaging or voting in the overall  results. However, in ensemble fuzzing, the goal is totally different: we do not want some average or vote results of fuzzers, but want the union of interesting outputs (bugs, coverage, etc.) throughout the fuzzing process.
Secondly, ensemble learning usually wants ``wisdom of crowds'' in the sense that the outliers are removed -- they usually increase individual bias but get rid of overall variance in training. But in ensemble fuzzing we want all the outliers, and always prefer to get more outliers.
Consequently, the concrete ensemble methods of ensemble fuzzing is quite different from ensemble learning. 
Another critical difference between fuzzing and learning is the computing resources usage.
For ensemble learning, multiple learners are trained to solve the same problem, which means it uses multiple computing resources. 
It is insensitive to computing resources usage.
However, for ensemble fuzzing, in general, 
more computing resources usage means more coverage and more crashes. %Therefore, different from ensemble learning, it is unfair to compare ensemble fuzzer with any single base fuzzer alone. 
To solve this unfairness, we should compare the ensemble fuzzer with the base fuzzers in industry widely used parallel mode with the same resources usage. 
\end{comment}
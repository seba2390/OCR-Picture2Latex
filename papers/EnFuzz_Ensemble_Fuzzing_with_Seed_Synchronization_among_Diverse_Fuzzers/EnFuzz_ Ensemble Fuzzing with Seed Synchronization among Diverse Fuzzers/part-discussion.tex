
%% base fuzzers 的差异性 和 ensemble method 是集成fuzzer的核心， 这里我们只给出了几种差异性的定义，未来有更多的研究点。 此外， 集成的方法也 过于简单， 研究的点也很多
Based on benchmarks such as LAVA-M and Google's fuzzer-test-suite, and several real projects, we demonstrate that this ensemble fuzzing approach outperforms any base fuzzers. However, some limitations still threaten the performance of ensemble fuzzing. The representative limitations and the workarounds are discussed below.



The first potential threat is the insufficient and imprecise diversity of base fuzzers. Section \ref{Base Fuzzer Selection} describes our base fuzzer selection, we propose three different heuristics  to indicate  diversity of base fuzzers, including diversity of coverage information granularity, diversity of input genera-tion strategy, and diversity of seed mutation selection strategy.
According to these three heuristics, we select AFL, AFLFast, FairFuzz, libFuzzer, Radamsa and QSYM as the base fuzzers. %They are open-source and demonstrate the issue of performance variation.
Furthermore, we implement four prototypes of ensemble fuzzing and demonstrate that the greater the diversity of base fuzzers, the better the ensemble fuzzer performs. However, these three different heuristics of diversity may be insufficient. More diversity measures need to be proposed in future work. For example, initial seeds determine the initial direction of fuzzing and, thus, are significantly important for fuzzing, especially for mutation-based fuzzers. Some fuzzers utilize initial seeds generated by symbolic execution \cite{wang2018safl, ognawala2018improving} while some other fuzzers utilize initial seeds constructed by domain experts or grammar specifications. However, we select base fuzzers manually according to the initial diversity heuristic, which is also not accurate enough. 
%the quantification of diversity value is based on the benchmark for preliminary reference, which is also not accurate enough. 
%It could be improved by accumulated evaluation of more projects and integration of variation results on more types of metrics. With fuzzing statics on more projects and more dimensions, we can get a more accurate diversity quantification based on the evaluation formula 1 and 2 described in the section 4.1.  %Different initial seed generation strategies may have critical influences on the diversity of fuzzers. In ensemble learning, a number of diversity measures have been designed,
%we could also get inspiration from them and propose more diversity measures.

A possible solution to this threat is to quantify the initial diversity value among different fuzzers for more accurate selection. 
As defined in \cite{benjamin2014probability}, the variance or diversity is a measure of the distance of the data in relation to the average. The average standard deviation of a data set is a percentage that indicates how much, on average, each measurement differs from the other. 
%Take path coverage for example, as shown in Table \ref{tab:single_path}, 
To evaluate the diversity of different base fuzzers, we can choose the most widely used AFL and its path coverage as a baseline and then calculate standard deviation of each tool from this baseline on the Google fuzzing-test-suite. Then we can calculate the standard deviation of these values as the initial measure of diversity for each base fuzzer, as presented in formula (\ref{eq:diversity}) and (\ref{eq:mean}),  
where \(n\) means the number of applications fuzzed by these base fuzzers, \(p_i\) means the number of paths covered by the current fuzzer of the target application \(i\) and \(p_{A_i}\) means the number of paths covered by AFL of the application \(i\).

\begin{equation}\label{eq:mean}
mean = \frac{1}{n} \sum_{i=1}^{n}{ \frac{p_i - p_{A_i}}{p_{A_i}} }
\end{equation}

\begin{equation}\label{eq:diversity}
diversity = \frac{1}{n} \sum_{i=1}^{n}{ {( \frac{p_i - p_{A_i}}{p_{A_i}} - mean )} ^{ 2 }  }
\end{equation}

Take the diversity of AFLFast, FairFuzz, Radamsa, QSYM, and libFuzzer for example, as shown in the statistics presented in Table \ref{tab:single_path} of the appendix, compared with AFL on different applications, 
the diversity of AFLFast is 0.040; 
the diversity of FairFuzz is 0.062; 
the diversity of Radamsa is 0.197; 
the diversity of QSYM is 0.271; 
the diversity of libFuzzer is 11.929. 
In the same way, the deviation on branches covered and the bugs detected can be calculated. We can add these three values together with different weight for the final diversity quantification. For example, the bug deviation should be assigned with more weights, because from prior research, coverage metrics (the number of paths or branches) are not necessarily correlated well with bugs found.  A more advanced way to evaluate the amount of diversity would be to count how many paths/branches/bugs were found by one fuzzer and not by any of the others. 


The second potential threat is the mechanism scalability of the ensemble architecture. 
Section \ref{Ensemble Architecture Design} describes the ensemble architecture design, and proposes the globally asynchronous and locally synchronous based seed synchronization mechanism.
The seed synchronization mechanism focuses on enhancing cooperation among these base fuzzers during their fuzzing processes.
With the help of seeds sharing, the performance of ensemble fuzzing is much improved and is better than any of the constituent base fuzzers with the same computing resources usage.
However, this mechanism can still be improved for better scalability on different applications and fuzzing tasks. \EnFuzz ~only synchronizes the coarse-grained information -- interesting seeds, rather than the fine-grained information.
For example, we could synchronize the execution trace and array index values of each base fuzzer to improve their effectiveness in cooperation. 
Furthermore, we currently select and mix base fuzzers manually according to three heuristics. When scaled to arbitrary number of cores, it should be carefully investigated with huge number of empirical evaluations. A possible solution is that the base fuzzers will be dynamically selected and initiated with different number of cores according to the real-time number of paths/branches/bugs found individually by each fuzzer. In the beginning, we have a set of different base fuzzers; then Enfuzz selects n (this number can be configured) base fuzzers randomly. If one fuzzer cannot contribute to coverage for a long time, then it will be terminated, and one new base fuzzer from the sets will be setup for fuzzing or the existing live base fuzzer with better coverage will be allocated with more CPU cores. 

%The base fuzzers should be selected dynamically according to the real-time number of paths/branches/bugs found individually by each fuzzer. For example, if one fuzzer can not contribute to coverage for a long time, then it should be terminated, and one new base fuzzers should be setup for fuzzing.


We can also apply some effective ensemble mechanisms in ensemble learning such as Boosting to ensemble fuzzing to improve the scalability.
Boosting is a widely used ensemble mechanism which will reweigh the base learner dynamically to improve the performance of the ensemble learner: examples that are misclassified gain weight and examples that are classified correctly lose weight.
To implement this idea in ensemble fuzzing, we could start up a \textit{master} thread to monitor the execution statuses of all base fuzzers and record more precise information of each base fuzzer, then reassign each base fuzzer some interesting seeds accordingly.

%% 根据review1 关于集成参数的意见，加了以下两段说明（不知道要不要加）
For the number of base fuzzers and parameters in ensemble fuzzing implementation, it is scalable for integration of most fuzzers. Theoretically, the more base fuzzers with diversity, the better ensemble fuzzing performs. We only use four base fuzzers in our evaluation with four CPU cores. The more computing resources we get, higher performance the fuzzing practice acquires. %The influence of the number of base fuzzers can be explored in the future. 
Furthermore, in our implementation, 
we have tried different values of period time, and the results are very sensitive to the specific setting of this value. It only affects the performance in the beginning, but affects little in the end.
%the time period of synchronously seed sharing is 120 seconds. 
%This parameter is closely related to the size of the target applications. A shorter period consumes too many resources, which leads to a decrease in fuzzing performance. 
%A longer period results in untimely seed synchronization, which also affects fuzzing performance. We can use the global seed pool status sampling of early fuzzing stages for period optimization. 
Furthermore, refering to the GALS system design, we can also allocate a different synchronization frequency for each local fuzzer dynamically. %How to find a more suitable balance point dynamically need to be explored in the future.



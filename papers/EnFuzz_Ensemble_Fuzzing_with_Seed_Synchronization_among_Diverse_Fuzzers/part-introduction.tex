%Vulnerabilities of memory security are increasing risks in software, which hackers can exploit to cause many severe threats to programs such as confidential information leakage. 
Fuzzing is one of the most popular software testing techniques for bug and vulnerability detection. There are many fuzzers for academic and industrial usage. The key idea of fuzzing is to generate plenty of inputs to execute the target application and monitor for any anomalies.
%As the kernel of a fuzzer, 
While each fuzzer develops its own specific fuzzing strategy to generate inputs,
there are in general two main types of strategies. One is a generation-based strategy which uses the specification of input format, e.g. grammar, to generate complex inputs. For example, IFuzzer \cite{ifuzzer} takes a context-free grammar as specification to generate parse trees for code fragments.
Radamsa \cite{helin2016radamsa} reads sample files of valid data and generates interesting different outputs from them.
The other main strategy is a mutation-based strategy. This approach generates new inputs by mutating the existing seeds (good inputs contributing to improving the coverage).
Recently, mutation-based fuzzers are proposed to use coverage information of target programs to further improve effectiveness for bug detection. For example, libFuzzer \cite{libFuzzer} mutates seeds by utilizing the SanitizerCoverage \cite{SanitizerCoverage} instrumentation to track block coverage, while AFL \cite{afl} mutates seeds by using static instrumentation to track edge coverage. 

Based on the above mentioned two fuzzers, researchers have performed many optimizations. For example, AFLFast \cite{aflfast} improves the fuzzing strategy of AFL by selecting seeds that exercise low-frequency paths for additional mutations, and FairFuzz \cite{FairFuzz} optimizes AFL's mutation algorithm to prioritize seeds that hit rare branches. AFLGo \cite{aflgo} assigns more mutation times to the seeds closer to target locations. QSYM \cite{qsym} uses a practical concolic execution engine to solve complex branches of AFL.
All of these optimized fuzzers outperform AFL on their target applications and have already detected a large number of software bugs and security vulnerabilities. 

However, when we apply these optimized fuzzers to some real-world applications, these fuzzing strategies are inconsistent in their performance, their effectiveness on different applications varies accordingly. For example, in our evaluation on 24 real-world applications, AFLFast and FairFuzz perform better than AFL on 19 applications, while AFL performs better on the other 5 applications. Compared with AFL, libFuzzer performs better on 17 applications but worse on the other 7 applications.
%For parallel mode which is widely used in industry, FairFuzz and AFLFast only execute 80\% and 92\% paths, cover 95\% and 94\% branches of AFL. 
For the parallel mode of fuzzing which is widely-used in industry, AFLFast and FairFuzz  only detected  73.5\%  and 88.2\% of the unique bugs of AFL. 
These results show that the performance of existing fuzzers is challenged by the complexity and diversity of real-world applications. For a given real-world application, we cannot evaluate which fuzzer is better unless we spend significant time analyzing them or running each of these fuzzers one by one. This would waste a lot of human and computing resources \cite{klees2018evaluating}. 
This indicates that many of the current fuzzing strategies have a lack of robustness --- the property of being strong and stable consistently in constitution.  For industrial practice, more robust fuzzing strategies are desired when applied across different applications. 
%When it is applied into different applications, the term “robustness” refers to the consistent performance of fuzzers.
%Therefore, we need a fuzzer with the ability to provide more robust fuzzing across different applications.


\begin{comment}
The theory of ensemble learning \cite{zhou2015ensemble} proves that the generalization ability of an ensemble learner is usually much stronger than that of base learners \cite{hansen1990neural, schapire1990strength}. Similarly, we propose the idea of ensemble fuzzing, 
which intuitively helps in the following two aspects: \textit{robustness}, i.e. the consistent advantage on any application in the evaluation setup; \textit{performance}, i.e. achieving better metrics than any other fuzzers under the same resources constraint.

To demonstrate the effectiveness of an ensemble fuzzing, we need to deal with two main challenges before implementation:

\begin{itemize}
   \item [1.] \emph{Base Fuzzer Selection.} Base fuzzers are the underlying basics, and the diversity of base fuzzers is crucial to an ensemble fuzzer. The more diversity of these base fuzzers, the better the ensemble fuzzer performs. 
   \item [2.] \emph{Ensemble Architecture Design.} The architecture determines the effectiveness of ensemble fuzzing. The concrete ensemble architecture should be well designed, because a ensemble method should effectively combines these existing base fuzzers into a stronger ensemble fuzzer. 
\end{itemize}

To our best knowledge, we are the first to propose an ensemble fuzzing approach which we refer as \EnFuzz. 

\end{comment}

In this paper, we systematically study the performance of an ensemble fuzzing approach.
%inspired by the theory of ensemble learning which proves that the performance of an ensemble learner is usually much better than that of base learners \cite{zhou2015ensemble,hansen1990neural, schapire1990strength} and the global asynchronous and local synchronous(GALS) system design \cite{muttersbach2000practical}, we propose ensemble fuzzing.
First, we define the diversity of base fuzzers focusing on three heuristics: diversity of coverage information granularity, diversity of input generation strategy, as well as diversity of seed mutation and selection strategy. 
Then, we implement an ensemble architecture with a global asynchronous and local synchronous(GALS) based seed synchronization mechanism to integrate these base fuzzers effectively.
To enhance cooperation among different base fuzzers, the mechanism synchronizes interesting seeds(i.e., test cases covering new paths or triggering new crashes) periodically to all fuzzers running on the same target application. At the same time, it maintains a global coverage map to help collect those interesting seeds asynchronously from each base fuzzer. %In the meantime, i
%The second is the result integration mechanism, which completes the fuzzing session by collecting,de-duplicating and triaging results from all base fuzzers. 

For evaluation, we implement a prototype of \EnFuzz , based on several high-performance base fuzzers, including AFL, AFLFast, FairFuzz, QSYM, libFuzzer and Radamsa.
All fuzzers are repeatedly tested on two widely used benchmarks --- LAVA-M and Google's fuzzer-test-suite, following the kernel rules of evaluating fuzzing guideline\cite{klees2018evaluating}. %We follow the guidelines \cite{klees2018evaluating} for evaluation, except for the unique crash. We keep it for evaluation because although it is not the same as the unique bug, but demonstrates the path and probability to detect a bug. 
The average number of paths executed, branches covered and unique crashes discovered are used as metrics. The results demonstrate that, with the same resource usage, the base fuzzers perform differently on different applications, 
while \EnFuzz ~consistently and effectively improves the fuzzing performance. 
%For example, FairFuzz and AFLFast are evaluated to be fuzzers that always perform better than AFL in their test cases \cite{FairFuzz,aflfast}, but there are many cases that AFL performs better than those two fuzzers on those real-world applications. 
%The generalization limitations certainly exist in these base fuzzers, 
For example, there are many cases where the original AFL performs better on some real-world applications than the two optimized fuzzers FairFuzz and AFLFast. 
In all cases, the ensemble fuzzing always outperforms all other base fuzzers. 
%Even with little diversity, the ensemble approach achieves huge improvements, and the more diversity among these base fuzzers, the better ensemble fuzzing performs.

Specifically, on Google's fuzzer-test-suite consisting of real-world applications with a code base of 80K-220K LOCs, compared with AFL, AFLFast, FairFuzz, QSYM, libFuzzer and Radamsa, \EnFuzz ~discovers 76.4\%, 140\%, 100\%, 81.8\%, 66.7\% and 93.5\% more unique bugs, executes 42.4\%, 61.2\%, 45.8\%, 66.4\%, 29.5\% and 44.2\% more paths and covers 15.5\%, 17.8\%, 12.9\%, 26.1\%, 19.9\% and 14.8\% more branches respectively.
For the result on LAVA-M consisting of applications with a code base of 2K-4K LOCs, it outperforms each base fuzzer as well. For further evaluation on more widely used and several well-fuzzed open-source projects such as Libpng and jpeg, \EnFuzz ~finds \bugnum new real vulnerabilities, \cvenum of which are security-critical vulnerabilities and registered as new CVEs. However, other base fuzzers only detect 35 new vulnerabilities at most. %in the US National Vulnerability Database.

This paper makes the following main contributions:
\vspace{0.03in}
\begin{itemize}

	 \item [1.] While many earlier works have mentioned the possibility of using ensemble fuzzing, we are among the first to systematically investigate the practical ensemble fuzzing strategies and the effectiveness of ensemble fuzzing of various fuzzers. We evaluate the performance of typical fuzzers through a detailed empirical study. %following the kernel rules of the evaluating fuzzing guideline \cite{klees2018evaluating}. %We, thus, identify several valuable results, especially for their performance variation 
	 %We found that no base fuzzer consistently perform better than another on most real diverse applications, even as in most previous literature studies, one optimized fuzzer is usually evaluated to perform better than another on almost all applications or benchmarks such as LAVA-M.
	 We define the diversity of base fuzzers and study the effects of diversity on their performance. %of these base fuzzers.
% on large set of real-world applications

	 \item [2.] We implement a concrete ensemble approach with seed synchronization to improve the performance of existing fuzzers. \EnFuzz ~shows a more robust fuzzing practice across diverse real world applications. The prototype\footnote{\url{https://github.com/enfuzz/enfuzz}\label{footnote1}} is also scalable and open-source so as to integrate other fuzzers. %Furthremore, we implement an \EnFuzz ~server with a website interface\footnote{\url{http://wingtecher.com/Enfuzz/} ~~for free usage.} for free use.  

	 %\item [3.] We evaluate \EnFuzz ~on a widely used third-party benchmark consisting of real-world applications. The empirical results reveal the performance variation of existing fuzzers on different applications and demonstrate that the variation can be alleviated effectively by our ensemble approach. %It also demonstrates that the more diversity of base fuzzers, the better ensemble fuzzing performs.
	 
	 \item [3.] We apply \EnFuzz ~to fuzz several well-fuzzed projects such as libpng and libjpeg from GitHub, and several commercial products such as \texttt{libiec61850} from Cisco. Within 24 hours, \bugnum new security vulnerabilities were found and \cvenum new CVEs were assigned, while other base fuzzers only detected 35 new vulnerabilities at most. \EnFuzz~ has already been deployed in industrial practice, and more new CVEs are being reported$^{1}$.
 %So far, many people have signed up for trials, many new vulnerabilities have been discovered, and more CVEs are being applied for. 
\end{itemize}

\vspace{0.03in}
The rest of this paper is organized as follows:
Section \ref{Related Work} introduces related work. 
Section \ref{Motivating Example} illustrates ensemble fuzzing by a simple example.
Section \ref{Ensemble Fuzzing Approach EnFuzz} elaborates ensemble fuzzing, including the base fuzzer selection and ensemble architecture design.
Section \ref{Evaluation} presents the implementation and evaluation of \EnFuzz.
Section \ref{Discussion} discusses the potential threats of \EnFuzz, and we conclude in section \ref{Conclusion}. The appendix shows some empirical evaluations and observations. %about parallel fuzzing.

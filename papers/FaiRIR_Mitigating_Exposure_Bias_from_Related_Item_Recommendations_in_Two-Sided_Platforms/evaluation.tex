\vspace{-2mm}
\section{Experimental Evaluation} \label{sec:evaluation}
We evaluate our interventions (FaiRIR algorithms) on %two real-world datasets -- 
MovieLens and Amazon Cell Phone and Accesories datasets. 
The algorithms are evaluated based on: (1)~their effectiveness in mitigating exposure bias (Sec~\ref{sub:expt-mitigate-bias}), (2)~the relatedness of their recommendations (Sec~\ref{sub:expt-reco-relatedness}), and (3)~the overall utility  of the recommendations to the end-users (Sec~\ref{sec: user_survey}). 

\begin{table}[tb]
	\noindent
	\scriptsize
	\centering
	\begin{tabular}{|p{0.85cm}|p{1.2cm}||p{1.0cm}|p{1.0 cm}|p{1.0cm}||p{1.0 cm}| }
		\hline
		Algorithm &  & Over & Adequate & Under & $ExpBias$ \\
		\hline
		& Vanilla 	& 25.89 \% & 10.95 \% & 63.16 \% & 0.71\\ \cline{2-6}
		& FaiRIR$_{concat}$	& 19.77 \% & 9.71 \% & 70.52 \% & 0.67\\ \cline{2-6}
		rating-& FaiRIR$_{rl}$	& 34.69 \% & 27.4 \% & 37.91 \% & 0.15\\ \cline{2-6}
		 -SVD& FaiRIR$_{sim}$	& 24.3 \% & 15.00 \% & 60.7 \% & 0.39\\ \cline{2-6}
		& FaiRIR$_{nbr}$	& 0.07 \% & 98.9 \% & 0.03 \% & 0.003\\ \cline{2-6}
		\hline \hline
		& Vanilla 		& 26.75 \%& 12.38 \% & 60.87 \% & 0.56  \\ \cline{2-6}
		& FaiRIR$_{concat}$	& 22.95 \%& 19.65 \% & 57.4 \% & 0.35  \\ \cline{2-6}
		item2vec & FaiRIR$_{rl}$	& 31.06 \%& 34.19 \% & 34.75 \% & 0.10  \\ \cline{2-6}
		& FaiRIR$_{sim}$	& 31.74 \%& 23.43 \% & 44.83 \% & 0.21  \\ \cline{2-6}
		& FaiRIR$_{nbr}$	& 0.04 \% & 99.94 \% & 0.02 \% & 0.002  \\ \cline{2-6}
		\hline %\hline
	\end{tabular}
	\caption{{\bf \% of movies that are over, adequately and under-exposed in MovieLens dataset (vanilla and %fair 
			intervened rating-SVD \& item2vec) with desired distribution proportional to quality of the movies (i.e., $\beta = 0.0$).}}
	\label{Tab: ML-10M}
	\vspace{-2mm}
\end{table}

\vspace{-2 mm}
\subsection{Mitigation of exposure bias} \label{sub:expt-mitigate-bias}

%First, we focus on the effectiveness of the proposed methodologies in mitigating exposure bias.

%\vspace{2 mm}
\noindent
\textbf{FaiRIR$_{rl}$}: We applied FaiRIR$_{rl}$ on the learnt representations of items (from the vanilla rating-SVD and item2vec algorithms) over the MovieLens and Amazon datasets, with the following parameter settings.

\noindent
\underline{Parameter setting}: We initialize the prototype vectors $v_j$ to random values from uniform distribution in $(0, 1)$. To account for the variations due to the initialization, we report the results obtained from the best of three runs. 
For the hyperparameters $\lambda, \mu$ in Eqn.~\ref{eqn: optimize}, we performed a grid search over the set \{0.01, 0.1, 1.0, 10, 100\}. For $K$, we performed a grid search over the set \{10, 20, 30\}. 
We found the best performance (argmin for the loss function in eqn~\ref{eqn: optimize}) for $\lambda = 1, \mu = 0.01$ and $K = 20$. 


%We performed intervention with the quality aware representation learning algorithm. 
\noindent
\underline{Results}: The effectiveness of FaiRIR$_{rl}$ is shown in Table~\ref{Tab: ML-10M} (for Movielens) and Table~\ref{Tab: Amazon} (for Amazon) over both rating-SVD and item2vec algorithms.  
Compared to the original algorithms, the exposure bias has decreased significantly, with an increase in fraction of items being adequately exposed. E.g., for rating-SVD, percentage of items adequately exposed has increased from $06.62\%$ to $23.71\%$, and the exposure bias has reduced from $1.28$ to $0.18$ for the Amazon dataset. 

\noindent
\textbf{FaiRIR$_{rl}$ outperforms FaiRIR$_{concat}$}: Recall in Section~\ref{sec: mitigation}, we discussed two potential ways for fair representation learning. While one was the aforementioned optimization framework, the other was simple concatenation of representations learnt from vanilla RIR ($x_i$) algorithm and desiredness graph ($x^*_i$). In Tables~\ref{Tab: ML-10M} and~\ref{Tab: Amazon}, we show the efficacy of the approach in mitigating exposure bias for $\beta = 0.0$. While using FaiRIR$_{concat}$ we see reasonable improvement on both the datasets for representations learnt from Item2Vec approach; the performance was not so great for representations learnt from SVD approach. In either case, the proposed optimization based representation learning (FaiRIR$_{rl}$) outperforms the concatenation approach and its performance is more robust across datasets and across RIR algorithms. Hence, in the remainder of the paper, we shall consider FaiRIR$_{rl}$ to be the fair representation learning based mitigation approach and compare it with interventions at other stages of the pipeline.


%\vspace{1 mm}
\noindent
\textbf{FaiRIR$_{sim}$}: The effect of FaiRIR$_{sim}$ is also shown in Tables~\ref{Tab: ML-10M} and~\ref{Tab: Amazon}. % and~\ref{Tab: ML-10M}. 
In all cases, the $ExpBias$ has decreased, with an increase in percentage of items being adequately exposed.  


%\vspace{1 mm}
\noindent
\textbf{FaiRIR$_{nbr}$}: The effect of FaiRIR$_{nbr}$ is also shown in Tables~\ref{Tab: ML-10M} and~\ref{Tab: Amazon}. %and~\ref{Tab: ML-10M}. 
In all cases, the exposure bias has decreased substantially (almost reduced to zero), with a significant increase in percentage of items being adequately exposed. 






\begin{table}[tb]
	\noindent
	\scriptsize
	\centering
	\begin{tabular}{|p{1cm}|p{1.2cm}||p{1.0cm}|p{1.0 cm}|p{1.0cm}||p{1.0 cm}| }
		\hline
		Algorithm &  & Over & Adequate & Under & $ExpBia$s \\
		\hline
		\multicolumn{6}{|c|}{\bf $\beta = 0.0$}\\
		\hline \hline
		& Vanilla 		& 18.04 \% & 06.62 \% & 75.34 \% & 1.28\\ \cline{2-6}
		& FaiRIR$_{concat}$	& 20.14 \% & 12.78 \% & 67.1 \% & 0.75\\ \cline{2-6}
		& FaiRIR$_{rl}$ 	& 33.01 \% & 23.71 \% & 43.28 \% & 0.18\\ \cline{2-6}
		rating-& FaiRIR$_{sim}$	& 14.60 \% & 8.70 \% & 76.70 \% & 1.2\\ \cline{2-6}
		-SVD& FaiRIR$_{nbr}$	& 0.0 \% & 100.0 \% & 0.0 \% & 0.002\\ \cline{2-6}
		\hline \hline
		& Vanilla 		& 15.73 \%& 05.67 \% & 78.60 \% & 1.22  \\ \cline{2-6}
		& FaiRIR$_{concat}$	& 31.26 \%& 19.41 \% & 49.33 \% & 0.32  \\ \cline{2-6}
		& FaiRIR$_{rl}$ 	& 35.17 \%& 26.71 \% & 38.12 \% & 0.14  \\ \cline{2-6}
		item2vec & FaiRIR$_{sim}$	& 20.65 \%& 16.77 \% & 62.57 \% & 0.81  \\ \cline{2-6}
		& FaiRIR$_{nbr}$	& 0.0 \% & 100.0 \% & 0.0 \% & 0.002  \\ 
		\hline \hline
		\multicolumn{6}{|c|}{\bf $\beta = 0.25$}\\
		\hline 
		& Vanilla 		& 15.66 \%& 05.66 \% & 78.68 \% & 1.21  \\ \cline{2-6}
		item2vec& FaiRIR$_{rl}$ 	& 32.43 \%& 22.66 \% & 44.91 \% & 0.18  \\ \cline{2-6}
		& FaiRIR$_{sim}$	& 18.90 \%& 7.67 \% & 73.43 \% & 0.91  \\ \cline{2-6}
		& FaiRIR$_{nbr}$	& 0.0 \% & 100.0 \% & 0.0 \% & 0.001  \\ 
		\hline
		\multicolumn{6}{|c|}{\bf $\beta = 0.75$}\\
		\hline 
		& Vanilla 		& 15.46 \%& 05.68 \% & 78.86 \% & 1.21  \\ \cline{2-6}
		item2vec& FaiRIR$_{rl}$ 	& 32.89 \%& 24.28 \% & 42.83 \% & 0.16  \\ \cline{2-6}
		& FaiRIR$_{sim}$	& 15.96 \%& 6.67 \% & 77.57 \% & 1.14  \\ \cline{2-6}
		& FaiRIR$_{nbr}$	& 0.0 \% & 100.0 \% & 0.0 \% & 0.0002  \\ 
		\hline
		\multicolumn{6}{|c|}{\bf $\beta = 1.00$}\\
		\hline 
		& Vanilla 		& 15.41 \%& 05.78 \% & 78.81 \% & 1.21  \\ \cline{2-6}
		item2vec& FaiRIR$_{rl}$ 	& 32.12 \%& 30.37 \% & 37.51 \% & 0.12  \\ \cline{2-6}
		& FaiRIR$_{sim}$	& 15.41 \%& 05.78 \% & 78.81 \% & 1.21  \\ \cline{2-6}
		& FaiRIR$_{nbr}$	& 0.0 \% & 100.0 \% & 0.0 \% & 0.0  \\ 
		\hline
	\end{tabular}
	\caption{{\bf \% of items that are over, adequately and under-exposed in Amazon review dataset (vanilla and intervened item2vec. For rating-SVD representative results shown for $\beta=0.0$; other results are similar to item2vec and omitted).}}
	\label{Tab: Amazon}
	\vspace{-6 mm}
\end{table}

%\vspace{1mm}
\noindent Figure~\ref{fig: FairExp} shows scatter plots for the three interventions on the MovieLens dataset; each plot shows log of observed exposure on $y$-axis and desired exposure ($\beta = 0.0$) on $x$-axis. From these figures as well, it is evident that the distribution of observed exposure is closest to that of desired exposure for FaiRIR$_{nbr}$ (Figure~\ref{fig: FairExp}(c)).

%\vspace{1mm}
\noindent
\textbf{Analysis on multiple desired exposure distribution}: We also analyze our proposed interventions with different desired exposure distributions, by varying $\beta$ in the range $[0,1]$. The results for Amazon dataset are shown in Table~\ref{Tab: Amazon} (similar results are obtained for the MovieLens dataset, not shown for brevity). We see that irrespective of the $\beta$ values, FaiRIR$_{rl}$ and FaiRIR$_{nbr}$ are very effective in mitigating the exposure bias. However, with increase in $\beta$, the effectiveness of FaiRIR$_{sim}$ reduces. %The reason for this limitation of Intervention II is due to the fact that 
The reason being, as $\beta$ approaches $1.0$ (i.e., uniform desired exposure distribution), the \textit{`desired exposure based similarity'} part in equation~\ref{eqn: p2} reduces to $1.0$ and $sim(x_i, x_j)$ becomes only the relatedness similarity (cosine similarity).

Overall, FaiRIR$_{nbr}$ is seen to be most effective in reducing exposure bias, probably due to the following reason. 
While FaiRIR$_{rl}$ and FaiRIR$_{sim}$ attempt to reduce exposure bias indirectly by altering the representation learning / similarity computation in the latent space, FaiRIR$_{nbr}$ directly controls the number of other items from which a particular item $i$ is recommended (the desired number of recommendations for $i$), which specifically ensures that $i$ gets an exposure close to its desired exposure.

\noindent
\textbf{Summary:} We have shown that the proposed methods %(especially FaiRIR$_{rl}$ and FaiRIR$_{nbr}$) 
are successful in mitigating the induced exposure bias significantly. While the performance of  FaiRIR$_{rl}$ and FaiRIR$_{nbr}$ show significant improvement across both the datasets and RIR algorithms, the improvement is less stable for FaiRIR$_{sim}$.


The next natural question to investigate is whether this control of exposure bias comes at a cost of loss in relatedness of the recommendations.


\begin{figure}[tb]
	\centering
	\begin{subfigure}{0.32\columnwidth}
		\centering
		\includegraphics[width=\textwidth, height=2.75cm]{figures/Phase1SVD.pdf}
		\caption{FaiRIR$_{rl}$}
		\label{fig: Phase1Exp}
	\end{subfigure}%
	\begin{subfigure}{0.32\columnwidth}
		\centering
		\includegraphics[width=\textwidth, height=2.75cm]{figures/Phase2SVD.pdf}
		\caption{FaiRIR$_{sim}$}
		\label{fig: Phase2Exp}
	\end{subfigure}
	\begin{subfigure}{0.32\columnwidth}
		\centering
		\includegraphics[width=\textwidth, height=2.75cm]{figures/Phase3SVD.pdf}
		\caption{FaiRIR$_{nbr}$}
		\label{fig: Phase3Exp}
	\end{subfigure}
	\vspace*{-2 mm}
	\caption{{\bf (color online) Scatter plot of log of observed exposure and average user rating of movies in MovieLens dataset after different interventions on the rating-SVD. The red scatter shows their desired exposure with $\beta = 0.0$.} %\todo{adjust figures}
	}
	\label{fig: FairExp}
	\vspace*{-3 mm}
\end{figure}



%\vspace*{-10mm}
\subsection{Preserving recommendation relatedness} \label{sub:expt-reco-relatedness}

%Incorporating fairness in an algorithm usually 
Mitigating bias due to algorithms usually
incur an associated cost in terms of drop in performance (e.g., drop in accuracy in fair classifiers 
%\todo{cite a relevant paper}
\cite{zafar2017fairness})
. 
In the context of RIRs, the relatedness of the recommendation is the prime objective of the algorithm. 
Hence, in this experiment we check the incurred loss in relatedness due to our proposed FaiRIR interventions.


\noindent \textbf{Genre / Category based similarity}: Intuitively, relatedness of recommendations will be high if the recommended items are `similar'/`related' to the source item. The measure of relatedness is often domain-dependent. For instance, in the domain of movies, every movie has a set of one or more genres.
We measure the similarity of a source movie and a recommended movie by their {\it genre overlap} with respect to the source movie, i.e., by the fraction of genres preserved by the recommended movie as compared to that of the source movie.
For instance, let the movie {\it Gladiator} be recommended from the movie {\it Avatar} by an algorithm. As per the IMDb website, {\it Avatar} has genres \{Action, Adventure, Fantasy\} and {\it Gladiator} has genres \{Action, Adventure, Drama\}. Thus, the similarity between the movies is $\frac{2}{3}$.
Similarly, every item in the Amazon dataset has an associated set of {\it categories}, which we used in an identical fashion to compute relatedness of two Amazon items.
Now, we compute the relatedness of RIRs generated by an algorithm as follows. 
For each pair of items $(i,j)$ where $j$ has been recommended for $i$ by the algorithm, we compute the genre (category) overlap between $i$ and $j$, and then take the mean across all such pairs.

\begin{table}[tb]
	\noindent
	\scriptsize
	\centering
	\begin{tabular}{|p{1cm}|p{1cm}|c|c|c|}
		\hline
		Algorithm &  & Genre overlap & Like overlap & Relevance score \\
		\hline
		& Vanilla 		& 0.53 & 0.64 & 3.73\\ \cline{2-5}
		& FaiRIR$_{rl}$	& 0.34 & 0.56 & 2.69\\ \cline{2-5}
		rating-	  & FaiRIR$_{sim}$	& 0.44 & 0.64 & 3.63\\ \cline{2-5}
		-SVD& FaiRIR$_{nbr}$	& 0.44 & 0.63 & 3.62\\
		\hline \hline
		& Vanilla 		& 0.37 & 0.56 & 2.79\\ \cline{2-5}
		& FaiRIR$_{rl}$	& 0.27 & 0.52 & 2.54\\ \cline{2-5}
		item2vec & FaiRIR$_{sim}$	& 0.35 & 0.59 & 2.77 \\ \cline{2-5}
		& FaiRIR$_{nbr}$	& 0.34 & 0.59 & 2.76\\
		\hline
		
	\end{tabular}	
	\caption{{\bf Relatedness of recommendations generated %by different algorithms 
			over the MovieLens dataset: (i)~mean genre overlap of recommended \& source item, (ii)~Like overlap between users who liked the source \& recommended items, (iii)~relevance score according to AMT survey.}}
	\label{Tab:relatedness-of-recs}
	\vspace{-4 mm}
\end{table}

\begin{table}[tb]
	\noindent
	\scriptsize
	\centering
	\begin{tabular}{|p{0.85cm}|p{1 cm}|c|c|c|c| }
		\hline
		%Algorithm &  \multicolumn{4}{c}{Category overlap}  & \\
		%\hline
		Algorithm & & $\beta = 0.0$ & $\beta = 0.25$ & $\beta = 0.75$ & $\beta = 1.0$ \\
		\hline
		& Vanilla 		& 0.46 & 0.46 & 0.46 & 0.46 \\ \cline{2-6}
		& FaiRIR$_{rl}$	& 0.41 & 0.40 & 0.41 & 0.40\\ 
		\cline{2-6}
		rating-& FaiRIR$_{sim}$	& 0.45 & 0.45 & 0.46 & 0.46\\ \cline{2-6}
		-SVD & FaiRIR$_{nbr}$	& 0.44 & 0.44 & 0.45 & 0.45 \\
		\hline \hline
		& Vanilla 		& 0.50 & 0.50 & 0.50 & 0.50 \\ \cline{2-6}
		item2vec & FaiRIR$_{rl}$ 	& 0.41 & 0.41 & 0.41 & 0.40  \\ \cline{2-6}
		& FaiRIR$_{sim}$	& 0.48 & 0.48 & 0.49 & 0.50\\ \cline{2-6}
		& FaiRIR$_{nbr}$	& 0.46 & 0.46 & 0.47 & 0.47 \\
		\hline
	\end{tabular}	
	\caption{{\bf Relatedness of recommendations (mean category overlap between source and recommended items) over Amazon dataset, shown for different desired %exposure 
			distributions.}}
	\label{Tab:relatedness-of-recs-Amazon}
	\vspace{-6 mm}
\end{table}

%\vspace{1 mm}
\noindent \textbf{Results:} The `Genre overlap' column of Table~\ref{Tab:relatedness-of-recs} and Table~\ref{Tab:relatedness-of-recs-Amazon} show the genre/category overlap for the various RIR algorithms, for the MovieLens and Amazon datasets respectively. 
We observe decrements in the average genre overlap for all the interventions (as compared to the original algorithms), which is the expected cost of minimizing exposure bias. 
The reduction is severe in case of FaiRIR$_{rl}$ only, whereas it is not so severe in case of FaiRIR$_{sim}$ and FaiRIR$_{nbr}$. 
Note that, FaiRIR$_{rl}$ is an \textit{application-agnostic} methodology, where the main objective is to learn fair representations, while the other two interventions are \textit{application-specific}. 
Hence, the foregoing observation is in line with the findings in fairness literature, wherein application-agnostic approaches tend to incur higher losses in performance~\cite{lahoti2019ifair}.
%than application-specific ones~\cite{lahoti2019ifair}. 

%\vspace{1mm}
\noindent
\textbf{Analysis on multiple desired exposure distribution}: Table~\ref{Tab:relatedness-of-recs-Amazon} shows the category overlap for various desired exposure distributions (various values of $\beta$) for the Amazon product review dataset. The interpretation of the results is the same as discussed above. The performance of all the FaiRIR algorithms in preserving relatedness is pretty much stable. 
However, since FaiRIR$_{sim}$ reduces to vanilla RIR algorithms as $\beta$ approaches $1.0$, it does not incur any additional loss in %terms of 
relatedness.
%Similar results are obtained for the MovieLens dataset (omitted for brevity).

%\noindent
%\textbf{Summary:} So, the proposed approaches both minimize exposure bias while preserving relatedness of recommendations in terms of the genre / category overlap. 



\vspace{-1 mm}
%\noindent \textbf{(2) 
\subsection{Judging overall utility of recommendations} % through a user survey}
\label{sec: user_survey}
Considering that the ultimate objective of RIR algorithms is to satisfy human users, we conduct the following two evaluations for the proposed algorithms -- 
(1)~We measure the mean overlap of common users who liked both a source item and a recommended item, and 
(2)~We conduct a user survey for judging the utility (relevance) of the recommendations generated by various algorithms on the MovieLens dataset.

\input{liking.tex}

\vspace{2mm}
\noindent \textbf{(2) A user survey to judge recommendations}: 
We recruited human workers to assess the relevance of recommendations, via the Amazon Mechanical Turk (AMT) platform. 
We used `AMT master workers' who are known to perform such tasks meticulously. 
To ensure reliable judgments, it is important that the annotators are likely to be familiar with the items whose recommendations they are being tasked to judge.
Hence, we chose to perform this survey with the MovieLens dataset, since workers are much more likely to be familiar with popular movies, than with cellphones and accessories available on Amazon.
We considered movies in the top 5\% most popular movies (based on the number of ratings) in MovieLens dataset as our source movies. 
%Note that, this set of movies account for upward of 80\% of all user-ratings. 
To further guarantee the reliability of the judgments, we also provided the annotators with the link to the IMDb information page of each movie, which contains all metadata about the movie along with a snippet and its trailer. 
%of the same that would assist the AMT workers in their task.
The annotators were asked to browse through the IMDb page for a movie if they were not familiar with it.

For a particular source movie $x$, we generated top-$5$ recommendations using various algorithms on the MovieLens dataset.
%, including vanilla rating-SVD, vanilla item2vec, and the various fairness interventions. 
For each movie $y$ recommended for $x$ (in top-$5$) by some algorithm, we asked a worker -- ``If your friend likes the movie $x$, how likely are you to recommend movie $y$?''. 
A worker could answer this question on a Likert scale of $[1,5]$ with response $1$ representing ``very unlikely'' and response $5$ representing ``very likely''.
The recommendations were anonymized, i.e., the workers were {\it not} mentioned 
about the source algorithm of each recommendations.


We collected responses for $100$ different source movies and approximately $1,550$ distinct pairs of source and recommended pairs of movies. Each pair was evaluated by at least $10$ AMT workers, and we considered the average score over all these AMT workers as the utility/relevance score for this pair. 
The mean relevance for a RIR algorithm is computed as the average relevance over all the recommended pairs generated by it that were evaluated.



\noindent
\textbf{Results:} 
%We have at least 10 judgments %(from AMT workers) 
%on the relevance of each recommendation. 
Each of the RIR algorithms scored based on the mean of the relevance scores of different items it recommended %(in top-$5$) 
for a given item. 
Table~\ref{Tab:relatedness-of-recs} (Relevance Score column) shows the mean relevance scores for different RIR algorithms.

For both rating-SVD and item2vec, FaiRIR$_{sim}$ and FaiRIR$_{nbr}$ preserve a high degree of relevance in their recommendations. For instance, the mean relevance score of the original rating-SVD algorithm is $3.73$ (out of $5.0$), while that of FaiRIR$_{sim}$ and FaiRIR$_{nbr}$ are $3.63$ and $3.62$ respectively. The drop in mean relevance score is even lesser in case of item2vec.
To further substantiate the results, we 
performed {\it Student's T-test} on the samples of mean relevance scores, as obtained from the user survey. 
%We considered the following null hypothesis: \textit{the two independent samples have identical means}. 
We found the drop in mean relevance score to be statistically significant only for FaiRIR$_{rl}$ (as compared to the original algorithm); for FaiRIR$_{sim}$ and FaiRIR$_{nbr}$, the drop 
was {\it not} statistically significant. 
In fact, for almost 40\% of the recommendations, the %fair 
FaiRIR variants have {\it higher} relevance scores than the vanilla algorithms. 
%The results are qualitatively similar for item2vec algorithm (see Table~\ref{Tab:relatedness-of-recs}).








\begin{table}[tb]
	\noindent
	\scriptsize
	\centering
	\begin{tabular}{|p{1cm}|p{1 cm}|c|c|c|c| }
		\hline
		%Algorithm &  \multicolumn{4}{c}{Category overlap}  & \\
		%\hline
		Algorithm & & $\beta = 0.0$ & $\beta = 0.25$ & $\beta = 0.75$ & $\beta = 1.0$ \\
		\hline
		& Vanilla 		& 0.91 & 0.91 & 0.91 & 0.91 \\ \cline{2-6}
		& FaiRIR$_{rl}$ 	& 0.90 & 0.89 & 0.90 & 0.89\\ 
		\cline{2-6}
		rating-& FaiRIR$_{sim}$ 	& 0.91 & 0.91 & 0.91 & 0.91\\ \cline{2-6}
		-SVD & FaiRIR$_{nbr}$	& 0.92 & 0.91 & 0.91 & 0.91 \\
		\hline \hline
		& Vanilla 		& 0.81 & 0.81 & 0.81 & 0.81 \\ \cline{2-6}
		item2vec & FaiRIR$_{rl}$ 	& 0.87 & 0.84 & 0.83 & 0.86  \\ \cline{2-6}
		& FaiRIR$_{sim}$ & 0.85 & 0.84 & 0.82 & 0.81\\ \cline{2-6}
		& FaiRIR$_{nbr}$& 0.82 & 0.81 & 0.81 & 0.81 \\
		\hline
		
	\end{tabular}	
	\caption{{\bf Mean like overlap (overlap of users who liked the recommended \& source item) of the recommendations generated by different algorithms over Amazon dataset, shown for different desired exposure distributions.}}
	\label{Tab:UserSatisfaction-of-recs-Amazon}
	\vspace{-6 mm}
\end{table}


%\vspace{1mm}
%\noindent 
Note that, we also attempted to combine all the interventions, i.e., first learn fair representations, then fairly 
compute similarity, and finally select the neighbors as shown in Algorithm~\ref{Algo}. The results for the combined approach were dominated by the effects of FaiRIR$_{nbr}$.
% and did not show any significant improvement over those of Intervention III alone. 
Hence, we have not reported results of the combined approach for brevity.


\vspace{1mm}
\noindent
{\bf Summary:}  
We investigated whether the mitigation of exposure bias by FairIR comes at the cost of degradation in the relatedness of the recommendations.
Specifically we evaluated -- 
(i)~the preservation of relatedness of the recommendation through \textit{genre / category overlap}, and 
(ii)~the utility of the recommendation through {\it liking overlap} metric and a user-survey on AMT. 
Across all evaluations, we consistently observe that our proposed mechanisms (especially FaiRIR$_{sim}$ and FaiRIR$_{nbr}$) successfully mitigate exposure bias without sacrificing much on the relatedness of recommendations. 


\vspace{-2 mm}
\section{Mitigating Exposure Bias}
\label{sec: mitigation}

%\if 0
\begin{figure}[tb]
	%\centering
	\begin{subfigure}{\columnwidth}
		\centering
		\includegraphics[width=\textwidth, height=3.25cm]{figures/Fair-Reco-Pipeline.pdf}
		\label{fig:pipeline}
	\end{subfigure}%
	\vspace*{-5mm}
	\caption{{\bf Recommendation pipeline shown earlier in Figure~\ref{fig:recopipeline}, now shown with FaiRIR suit of fairness interventions.}}
	\label{fig:Fairecopipeline}
	\vspace*{-5mm}
\end{figure}
%\fi 

In this section, %such a scenario, the following can be few of the many probable 
we propose multiple interventions (\textbf{FaiRIR}) in the recommendation pipeline (shown in Figure~\ref{fig:Fairecopipeline}), that can %induce meritocratic fairness (or equivalently 
reduce exposure bias, 
by making exposure of item $i$ proportional to its desired exposure %. Let us consider 
$E_d(i)$, while maintaining the relatedness of recommendations. \\  %as the  of the item $i$. For the rest of this section we will be using this notation.
(I)~{\bf FaiRIR$_{rl}$ (Fair representation learning)}: Change the latent space representation of items such that %representations of 
items with similar desired exposure come closer in the latent space. \\ %to each other 
%with minimal transformations in the latent space (to preserve the relatedness). \\
(II)~{\bf FaiRIR$_{sim}$ (Fair similarity computation)}: Introduce desired exposure based similarity into the metric to compute similarity of items.\\
(III)~{\bf FaiRIR$_{nbr}$ (Fair neighbor selection)}: For a particular source item, instead of selecting the most similar items, % based on some similarity metric (e.g. cosine similarity), 
select items considering both similarity and desired exposure. \\
%In the %remaining part 
%rest of this section, 
Next, we will elaborate these three procedures. 


%\vspace{-3mm}
\subsection{\textbf{FaiRIR$_{rl}$}: Fair representation learning} \label{sec: Phase 1}

Our first approach tries to learn fair representations of the items from the %original 
latent space representations obtained from %the
vanilla rating-SVD or item2vec, to mitigate the induced exposure bias.
This approach is inspired by %some prior works that have attempted 
recent works attempting to incorporate individual fairness in various algorithms~\cite{zemel2013learning, lahoti2019ifair, lahoti2019operationalizing}.
Similar to~\cite{lahoti2019ifair}, we learn %data 
representation that preserves the similarity of desired exposure between items while minimizing the loss in relatedness, and, thereby, reconciling both desired exposure and relatedness. 

\vspace{1 mm}
\noindent
\textbf{Input}: Let us assume there are $M$ items, and for each item, we have $N$ latent attributes from the representations learned by the existing %related item recommendation 
RIR algorithms (e.g., rating-SVD, item2vec), resulting in %. These attributes are represented as an 
a $M \times N$ matrix $X$. We denote the record for the $i$-th item %(i.e., the $i$-th row of $X$) %consisting of all attributes 
as vector $x_i$ and the value $x_{ir}$ denotes the $r$-th attribute of $x_i$. % is denoted as . 
Note that, this representation space only captures % captures the %notion of 
the relatedness between %of each item with other 
items.

\vspace{1 mm}
\noindent
%\textbf{Desired fair representations:} 
\textbf{Considering desired exposure}:  
We design a \textit{desiredness graph} $D_G(V, E)$, where every node represents an item, i.e., $V=\mathbf{I}$, and every item is connected to $k$ other items who have similar desired exposure, i.e., $E = \{(i,j) : E_d(i)\simeq E_d(j)\}$. 
We obtain the node representation ${x}_{i}^{*}$ by using a network representation learning algorithm node2vec~\cite{grover2016node2vec} for each item $i$. Note that, representation ${x}_{i}^{*}$ of an item captures similarity of the items based on their desired exposure only.%(without considering any relatedness).

\vspace{1 mm}
\noindent
\textbf{Goal}: Our goal is to learn fair representation $\tilde{x}_i$ for item $i$, which %not only preserves the relatedness of $i$ with other items but also 
preserves both relatedness and similarity in desired exposure.
Analogous to the input, the output is again a matrix $\tilde{X}$ with dimension $M \times N$ where $i$-th row represents the fair representation of item $i$.

\vspace{1 mm}
\noindent
\textbf{A simple approach to achieve fair representations:}
Given the two sets of representations $x_i$ and $x^*_i$, the most intuitive way to generate a fair representation is to concatenate both the sets of representations. We denote such an approach as FaiRIR$_{concat}$. 
Such a simple approach may be effective because while $x_i$ encodes the information regarding relatedness, $x^*_i$ encodes the information regarding desiredness. 
However, as we shall show later in Section~\ref{sub:expt-mitigate-bias}, the performance of such a simple approach is not stable across different datasets and vanilla RIR algorithms. Hence, we proceed to learn the fair representations by optimizing a loss function which reconciles between relatedness loss and desiredness loss in the final learnt representations (described next). 



\vspace{1 mm}
\noindent
\textbf{Probabilistic clustering}: Following prior works~\cite{zemel2013learning, lahoti2019ifair}, our framework treats the goal of computing fair representation as the formal problem of probabilistic clustering. The aim is to learn $\mathbb{K}$ prototype vectors $v_h$ $ (\forall h \in \{1, 2, ..., \mathbb{K}\})$, such that item $i$ $(\forall i \in \{1, 2, ..., M\})$ is 
assigned to clusters in a probabilistic manner, such that the probabilities encode the distance between item $i$ and the prototype $v_h$. 
Given the distance function $d$ in an $N$-dimensional latent space, the probability that item $i$ belongs to cluster with prototype $v_h$ is given as: 
%\begin{align}
%\nonumber
$
\label{eqn: softmax}
u_{i h} = \frac{exp(-d(x_i, v_h))}{\sum_{t=1}^{\mathbb{K}}exp(-d(x_i, v_t))}
$.
%\end{align}
Notice such probabilistic clustering based set up can be viewed as a low-rank representation of the input matrix $X$ with $\mathbb{K} < M$, so that we are able to reduce the attribute values into a more compact form. 

\noindent
\textbf{Output representation}: The fair representation $\tilde{X}$, a matrix of dimension  $M \times N$ of fair output vectors $\tilde{x}_i$ ordered row-wise, includes
(a)~$\mathbb{K}<M$ prototype vectors $v_h$ of $N$ dimensions.
(b)~A probability distribution $u_i$, of $\mathbb{K}$ dimensions, for each item $i$. $u_{ih}$ represents the probability that item $i$ belongs to the cluster with %item $j$ as its 
prototype $v_h$. Mathematically,
%\begin{align}
%\nonumber
$
\tilde{x}_i = \sum_{h \in \{1,...\mathbb{K}\}}{u_{ih}*x_{j}}
$, 
%\end{align}
where $u_{ih}$ is as defined earlier. 

\vspace{1 mm}
\noindent
\textbf{Loss function}: Next, we present the loss function which optimizes for the reconstruction loss between the input representation $X$ and the fair output representation $\tilde{X}$ while preserving the desiredness of the products.
\scriptsize
\begin{align}
%\nonumber
\label{eqn: optimize}
L = \underbrace{\lambda * \sum_{i=1}^{M}\sum_{r=1}^{N} (x_{ir}-\tilde{x}_{ir})^2}_{\textrm{Relatedness loss}} + \overbrace{\mu * \sum_{i, j \in \{1,..., M\}}[d(\tilde{x}_i, \tilde{x}_j)-d(x_i^*, x_j^*)]^2}^{\textrm{Desired exposure based similarity loss}}
\end{align}
\normalsize
%For the clarity in understanding, we divide 
This loss $L$ has two separate parts:
(i)~\textbf{Relatedness loss:} the sum of the squared errors between the input representation matrix $X$ and the (low dimensional) output representation matrix $\tilde{X}$, and
(ii)~\textbf{Desired exposure based similarity loss:} 
$d()$ captures the distance between desired exposure of two items, computed as \textbf{Euclidean distance} between their vector representations.
Hyper-parameters $\lambda$ and $\mu$ decide the importance we want to associate with these two losses. %while minimizing the objective function.  




\subsection{\textbf{FaiRIR$_{sim}$}: Fair similarity computation} \label{sec: Phase 2}

As discussed in section~\ref{sec: motivation}, the existing cosine similarity between two item representations, 
$
sim(x_i, x_j) = \frac{x_i.x_j}{\lvert\lvert x_i \rvert\rvert\lvert\lvert x_j \rvert\rvert}
$,
%\end{align}
%This similarity measure 
accounts for relatedness; however, it does {\it not} account for the relative gap between their desired exposure. % $i$ and $j$. 
In %the second
this intervention, we propose to incorporate similarity of desired exposure between items along with relatedness. %while computing the similarity of the items for recommendation (so that the items recommended for an item $i$ are similar in desiredness to $i$). 
If $E_d(i)$ and $E_d(j)$ denote the desired exposure of items $i$ and $j$ respectively, then the new similarity measure is defined as:
%\scriptsize
\begin{align}
%\nonumber
\label{eqn: p2}
sim(x_i, x_j) = \underbrace{exp(-\lvert E_d(i)-E_d(j)\rvert)}_{\textrm{Desired exposure based similarity}}*\overbrace{\frac{x_i.x_j}{\lvert\lvert x_i \rvert\rvert\lvert\lvert x_j \rvert\rvert}}^{\textrm{Relatedness similarity}}
\end{align}
\normalsize
\noindent %By incorporating 
Using the similarity metric mentioned in equation~\ref{eqn: p2}, we promote items having higher desired exposure based similarity and relatedness
%(to the source item) 
by giving them higher similarity score. %This ensures, the recommendation of more deserving items than it used to be with similarity metric in equation~\ref{eqn: vanillap2}.


\subsection{\textbf{FaiRIR$_{nbr}$}: Fair neighbour selection}  \label{sec: Phase 3}

Next, instead of changing the representation or the similarity metric, 
we change the way %final set of 
the items are selected for recommendation. %to be recommended from a source item are selected. 
In practice, against every item, an equal number (say, $k$) of items are recommended; these $k$ items are usually most similar to the source item, based on some similarity metric. 
However, %we argue that by always recommending the top-$k$ items we may induce exposure bias, 
the number of recommendations each item will end up receiving is not controlled. 
We propose a fair way of %recommending items and, thereby, reducing the exposure bias can be to select the nearest 
selecting the $k$ neighbours %in a way 
such that the likelihood of an item being selected is proportional to its desired exposure.
%A related item recommendation algorithm $R$ is considered fair, 
That is, the recommendation would be fair if the likelihood of a highly desired item being recommended % in a system 
is greater than that of a less desirable item. If $R_t$ denotes the list of items recommended for item $t$, then for all item-pairs $(i, j)$,
%\small
%\begin{align}
%\nonumber
%\label{eqn: likelihood}
$\forall t \in \{1,2,..., M\}, P(i\in R_t) \geq P(j\in R_t) | E_d(i) \geq E_d(j)
%\end{align}
$
\normalsize
If an RIR algorithm follows the above equation%~\ref{eqn: likelihood}
, while preserving the notion of relatedness, it is likely to 
%do away with any kind of exposure bias. Next, we propose one such fair recommendation procedure for 
mitigate exposure bias.

\begin{algorithm}[t]
	%\SetKwInOut{Input}{Input}
	%\SetKwInOut{Output}{Output}
	\scriptsize
	\begin{algorithmic}
		\Require $Desired$: number of recommendations desired by each item, $k$: number of recommendations per item and similarities among all items $Sim$
		\Ensure $Recommendation$
		
		\Function{Find\_Neighbor}{$u, k, Desired, Sim$}
		\State {$Similarity$ = Ranked list of items based on their similarity to item $u$} 
		\State {$Desiredness$ = Ranked list of items based on their Desired number of recommendations} 
		\State {$Final$ = Aggregated ranked list using $Similarity$ and $Desiredness$}
		\State {Return top-$k$ items based on $Final$ ranked list}
		\EndFunction
		\\
		\Procedure {Recommendation}{$k, Desired, Sim$}
		\State {$Recommendation = \phi$}
		\ForAll{item $u$ in the item space}
		\State {RelatedItems = \Call {Find\_Neighbor}{$u, k, Desired, Sim$}}
		\ForAll{item $v$ in RelatedItems}
		\State {$Recommendation = Recommendation \cup {(u, v)}$}
		\State {$Desired[v] = Desired[v]-1$}
		\If {$Desired[v] = 0$}
		\State {remove $v$ from $Desired$}
		\EndIf
		\EndFor
		\EndFor
		\State {Return $Recommendation$}
		\EndProcedure
		\caption{Fair neighbor selection}
		\label{Algo}
		\vspace{-1mm}
	\end{algorithmic}
\end{algorithm}

Algorithm~\ref{Algo} details our proposed algorithm. 
%The deserved number of recommendation of each item is proportional to its desiredness.
%Therefore, 
Through the $Desired$ dictionary, it ensures that the likelihood of recommendation among different items follow the similar distribution as defined by their desired exposure. Effectively, for any source item, we have two ranked list of items according to their relatedness and desired exposure. In order to reconcile between these two rankings, % of items based on desiredness and relatedness to the source item, 
% of each item to its source item, one can use any 
we use a well known rank aggregation method, based on borda count~\cite{borda1784memoire}. Intuitively, any item having higher rank in both the ranked lists will be considered the most suitable related item to be recommended. 
%For our experiments, we have performed the rank aggregations by using the borda count~\cite{borda1784memoire} preference aggregation technique.

\vspace{1 mm}
\noindent
\textbf{Practical applicability of FaiRIR}:
There are two key questions regarding the practical applicability of FaiRIR algorithms in real-world setting -- 
(i)~does the deployment need a knowledge of the internal details of the RIR algorithm being used?, and
(ii)~can the FaiRIR algorithms adapt to a dynamic setting, e.g., when new items emerge intermittently.



FaiRIR$_{rl}$ and FaiRIR$_{sim}$ can be used only when internal details of the RIR algorithm are known %(e.g., the learned representations for all items, how similarity between the items is computed).
(e.g., user-item logs, similarity metric etc.). Also, given that these interventions are applied in the earlier stage of the recommendation pipeline, they are more suitable to adapt to a dynamic setting.
FaiRIR$_{nbr}$, on the other hand, can be used even by considering the related item recommendation
algorithm as a black box, provided we have the recommendation outputs and the desired exposure of all items. 
For example, in case of an existing online platform, we do not exactly know the %precise details about the 
RIR algorithm that is used. However, since we can capture the recommendation outputs in the form of an RIN, we can use any network level similarity as a proxy for relatedness and rewire the RIN to reduce the exposure bias.


To adapt to the dynamic setting, in case of FaiRIR$_{nbr}$, one can start recommending the newly emerging items from items which already exist in the network and are similar to them (where the similarity can be 
based on some metadata or content-based measures, such as the genre or actors of movies); thereby mitigating the requirement of re-wiring the entire RIN. 

\vspace{-2mm}
\section{Introduction} 
\label{sec:intro}
Recommendations are major drivers of traffic (and revenue) on two-sided market platforms, 
including e-commerce sites like Amazon or
Flipkart, and multimedia sites like YouTube, Spotify or 
Netflix~\cite{gomez2016netflix,smith2017two,AmazonRINSale}. 
There are two primary stakeholders in two-sided platforms: 
(1)~{\bf producers} (or sellers) of items (goods, contents or services) listed on the platforms, 
and (2)~their {\bf consumers} (or users). % in the platforms. 
A few recent works have focused on the {\it fairness of recommendations} in such platforms, but mostly from the perspective of consumers~\cite{yao2017beyond,zhu2018fairness,edizel2019fairecsys,geyik2019fairness},  %These works are primarily concerned with ensuring that different consumer 
such as, whether different groups of consumers experience similar %or equally satisfied from the recommendations. 
quality of recommendations.


However, as the recommendations help consumers efficiently explore the item space, 
they also implicitly determine the amount of {\it exposure} different items get, 
affecting the revenues of their producers. For example, %It is reported that  
$30\%$ of Amazon's traffic originates from 
%RIRs
recommendations~\cite{sharma2015estimating}. Similarly, $80\%$ of movies 
watched on Netflix are driven by recommendations~\cite{gomez2016netflix}. 
With a large number of businesses and individuals depending on two-sided platforms %like multimedia and e-commerce sites 
to earn their livelihood~\cite{chakraborty2017fair}, there are growing concerns about 
%is a growing effort
the {\it fairness of these recommendations from the perspective of the producers or sellers}~\cite{patro2020fairrec,edizel2019fairecsys,yao2017beyond}.  
%For instance, 
Even on the legislation front, a recent Indian regulation mandates e-commerce sites to treat their sellers fairly~\cite{pib2018ecommerce}. In this paper, we focus on the producer-side fairness considerations raised by recommendations.

\begin{figure}[tb]
	%\centering
	\begin{subfigure}{\columnwidth}
		\centering
		\includegraphics[width=\textwidth, height=3.25cm]{figures/Recommendation_Pipeline.pdf}
		\label{fig:pipeline}
	\end{subfigure}%
	\vspace*{-5mm}
	\caption{{\bf A generic block diagram explaining item-based recommendation methods. Item models generated in these methods can be utilized for both related item recommendations and personalized recommendations. The latter, enclosed in broken rectangles in the diagram, is beyond the scope of the current work.}}
	\label{fig:recopipeline}
	\vspace*{-6mm}
\end{figure}


Recommendations in two-sided platforms are primarily of two types (see Figure~\ref{fig:recopipeline}): 
	(i)~item-specific {\bf Related Item Recommendations} (RIR),  
	e.g., `customers who viewed this item also viewed the following items'
	recommendations on Amazon, or `Up next' video recommendations on YouTube, and 
	(ii)~user-specific {\bf Personalized Recommendations},  
	e.g., `Related to items you've viewed', `Inspired by your shopping trends' recommendations on Amazon, `Because you watched X' on Netflix. 
	Notice while personalized recommendations are centered around the past interactions of a specific customer (to whom the recommendations will be shown), related item recommendations are centered in the context of a particular item~\cite{yao2018judging}. The underlying notion of relatedness can be of different types which will be discussed in detail in Section~\ref{sec:fairness}.
	Two recent works lately have looked at fairness for the producers~\cite{patro2020fairrec,patro2020incremental}, but they only consider the user-specific personalized recommendations. %(and treat the related item generation as a black box. 
	To our knowledge, our work here is the first to investigate fairness issues in Related Item Recommendations (RIRs).


\vspace{1 mm} 
\noindent\textbf{Item exposure bias in RIRs}: 
As RIR algorithms recommend new items that are `related' or `similar' to the item currently being viewed by a user, there may arise situations where an item gets much more (or less) exposure than what it deserves.
For example, a poor-quality item may be recommended as related from a popular good-quality item (say, by virtue of being produced by the same manufacturer) and hence
% (e.g., since the two items have the same brand), 
the poor-quality item may end up getting much more exposure than it deserves. 
%by virtue of being related to the good-quality item.
On the other hand, a good-quality item may fail to get
the desired exposure, simply because it is not recommended as directly related
%on the pages of
to other popular items by a RIR algorithm. 
%In this paper, 
In fact, our investigation over real-world datasets (Section~\ref{sec: motivation}) shows that the relative exposure of items that would be induced by state-of-the-art 
%Related Item Recommendation (RIR) 
RIR algorithms is often uncorrelated or disproportionate to the relative quality of the items. 
We term this discrepancy between the {\it observed} item exposure (as induced by RIRs) and the {\it desired} item exposure (e.g., based on item quality) as {\it exposure bias}. 

In this paper, we posit that by solely focusing on `relatedness' between items, RIRs may implicitly bias the exposure distribution of items in a manner that does not reflect a desired producer-fair exposure distribution.\footnote{Note that, exposure bias may get induced due to multiple explicit factors too, such as special relationship of certain items with the platform~\cite{dash2021umpire}; however such concerns are beyond the scope of the current work.}
We propose mechanisms to quantify and mitigate the exposure bias of RIRs. To formalise the concept of exposure bias, apart from the `observed' exposure of an item, we also need to have a notion of what is the `desired' exposure of that item. 
Since the notion of desired exposure is highly contextual, it cannot be riveted to a single operational definition. Therefore, we operationalize this notion of `desired' exposure in multiple ways allowing for multiple contextual assumptions. In fact, we develop the rest of our pipeline in such a way that {\it any new operationalization of the `desired' exposure can be seamlessly plugged in.}
We show that our proposed mechanisms can improve producer-side fairness of RIRs, with little or no impact on the utility of the recommendations to consumers.


\vspace{1mm}
\noindent
\textbf{Contributions}: We make the following contributions. 
\begin{itemize}[noitemsep,topsep=0pt,parsep=0pt,partopsep=0pt,leftmargin=*]
	\item We demonstrate the exposure bias induced due to two popular RIR algorithms -- rating-SVD and item2vec -- on two real-world datasets -- the MovieLens and Amazon product review datasets~\cite{harper2016movielens,he2016ups}. The choice of these two datasets is motivated by the two large businesses they represent -- the entertainment industry and the e-commerce industry.
	\item To counter the exposure bias, we propose {\bf FaiRIR}, a novel suit of three algorithms %three types of interventions 
	applied at different stages in the RIR pipeline, that can minimize exposure bias
	while preserving the underlying relatedness of the recommended items to the best possible extent.
	\begin{compactitem}
		%\item Intervention I: \textit{Fair representation learning}.
		\item FaiRIR$_{rl}$, based on \textit{fair representation learning} 
		\item FaiRIR$_{sim}$, based on \textit{fair similarity computation} 
		\item FaiRIR$_{nbr}$, based on \textit{fair neighbor selection} 
	\end{compactitem}
	\item Extensive offline evaluations on the real-world datasets show that %our proposed mechanisms 
	FaiRIR can significantly reduce exposure bias, while preserving the underlying relatedness and utility of the recommendations toward the end-user.
	\item Finally, we conducted %an evaluation based on 
	a user survey on Amazon Mechanical Turk, which 
	further demonstrates the efficacy and utility of the proposed FaiRIR algorithms. %methodologies.
\end{itemize}


\noindent We believe that the methodologies discussed in this paper are generic enough to be extended to different setups where related item recommendation algorithms are deployed. For better understandability and reproducibility, we have released our source codes at: \url{https://github.com/ad93/FaiRIR}.

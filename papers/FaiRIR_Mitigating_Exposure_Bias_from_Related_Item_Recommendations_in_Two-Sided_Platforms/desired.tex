\section{Desired Exposure and Exposure bias}
%In this section, we %elaborate on
Next, we discuss how exposure can be % justly 
{\it fairly distributed} among a set of items, by motivating it through the lens of distributive justice~\cite{yaari1984dividing}. We %end this section by defining 
then define `Exposure bias', given the desired and observed distributions of exposure. 

\vspace{-2 mm}
\subsection{Desired exposure of items}
\label{sec:desired}
%There can be multiple notions of what is desired
Exposure in an online platform is a beneficial commodity, %it is convenient to think that individuals (items) 
hence the producers of items would prefer having more of it (than having less). In such a scenario, an intuitive notion of  fairness would be \textbf{equality of exposure}, i.e., the exposure should be uniformly distributed among all the items (by recommended them uniformly). 
%This strategy advocates for  (or attention) for all items such that they all are recommended to users uniformly. %Put differently, the desired objective is equality of opportunity.
However, the characteristics of the %individuals (
items %among whom the exposure is to be distributed are to be understood, 
should also be taken into account, since these characteristics may provide prima facie grounds for a departure from equality~\cite{yaari1984dividing}. 
For instance, all items are probably {\it not} of similar merit or intrinsic quality. This difference in `merit' or `quality' can be a justified reason for departure from equality. Thereby, the `desired exposure' of an individual (item) can be determined by its `deservingness' (merit)\footnote{Desiredness should not be confused with deservingness, i.e., desiredness $\ne$ deservingness in general. Deservingness, in contrast, is an extreme case of desiredness.}. This departure from equality is well established through the notion of \textbf{meritocratic fairness} and the related literature on meritocracy~\cite{joseph2018meritocratic,joseph2016fairness}. For instance, a high-quality item is considered more deserving of %popularity / 
user attention than a low-quality item. 

%Again, not all items have equal contribution to the society. In such cases, 
Alternatively, the desired exposures of various items can also be driven by a broader idea of societal welfare. %the welfare of the society. 
For instance, YouTube `Up next' related video recommendation has recently been criticised for leading users to far-right echo chamber and extremist content~\cite{youtubeRadical}, potentially influencing elections (e.g., the Brazilian presidential election~\cite{youtubeBrazil}). In response, YouTube tweaked its `Up next' algorithm, and started recommending Fox News videos from far-right conspiracy theory videos, instead of other videos from the same channels~\cite{youtubeFoxnews}. Clearly, YouTube deemed some videos {\it unworthy} of the exposure they were getting earlier and decided to nudge users to follow other videos. 
In some scenarios, %since there is a need for exposure of the items and their producers (providers) alike, it can be preferred 
it might be legally required to provide each item with some minimum amount of exposure, regardless of the item attributes~\cite{patro2020incremental,patro2020fairrec}. 


\vspace{1 mm}
\noindent
\textbf{Desiredness as a control knob for fairness: }Note that, we do {\it not} argue for any particular notion of desired exposure distribution; rather, the formulation and algorithms given in the subsequent sections are \textit{\textbf{agnostic}} to any measure of desiredness. 
Rather than advocating for any specific desired exposure, we perceive desiredness as a necessary {\it controllable knob} in our framework to ensure fairness in the final outcomes. 
Hence, if some legislation or a particular platform has a sacrosanct quantification of the desiredness of each item, the same can be easily plugged into our proposed fairness interventions.

\vspace{-2mm}
\subsection{Estimating desired exposure}
We denote the desired exposure of item $i$ as $E_d(i)$, and the desired exposure distribution over all items as $E_d$.
%For the purpose of 
In this work, as a proof of concept, we consider a generic formulation to accommodate multiple types of desired exposure distributions. We consider, a fraction $\beta \in [0, 1]$ of the total exposure is equally distributed among all items. This fraction of the exposure takes care of the minimum exposure of all items (and their producers). It is meant to provide all items with some minimum exposure to satisfy the basic needs of the items and their producers (as argued in~\cite{patro2020incremental}). The remaining ($1-\beta$) fraction of the total exposure is distributed proportional to the quality or merit of individual items, thus advocating \textit{meritocratic fairness}~\cite{joseph2018meritocratic,joseph2016fairness}. Notice, the above formulation of $E_d$ reduces to purely meritocratic distribution of exposure for $\beta = 0$, and to uniform distribution of exposure for $\beta = 1$. The exposure distributions are normalized so that the total exposure of all items in the item-set sum up to 1, i.e., $\sum_{i \in \mathbf{I}}^{}{E_d(i)} = 1$. 


As mentioned earlier, in this work, we assume the {\it average user-rating} of an item as the quantification of its merit / quality. The importance that we attach to an item's merit to obtain its desired exposure is controlled by the parameter $\beta$.


\vspace{1mm}
\noindent
{\bf A potential limitation of user-ratings:} One potential concern about using average user-ratings as a quality metric, might be that the number of ratings an item gets is partly driven by the %recommendations produced by 
existing recommendation algorithms. 
However, we believe that, although a user may have been led to an item via some recommendation, her rating would reflect the inherent quality of the item as perceived by her. 
Further, we also considered a slightly different quality measure -- average user-rating of an item, weighted by its number of ratings. The qualitative results of the analyses remained similar
in this setting too. %as for the simple user-rating measure. 
Hence, for simplicity and completeness we 
consider the average user-rating score to be the indicator of quality throughout this paper. 
%The extent of importance that is attached to this quality is regulated by the parameter $\beta$ to generate various desired exposure distributions.

\vspace{-1mm}
\subsection{Defining exposure bias}  \label{sub:exp-bias}
According to our formulation, a RIR system would be fair (unbiased), if it gives every item an observed exposure that is proportional to its desired exposure. 
Since $E_o(i)$ and $E_d(i)$ denotes the {\it observed and desired exposures} of item $i$, mathematically, a RIR system is fair if $\frac{E_o(i)}{E_d(i)} = \frac{E_o(j)}{E_d(j)} \hspace{2mm}  \forall {i, j} \in \mathbf{I}$.
%\begin{equation}
%\label{eq:merit-fairness-2}
%\frac{E_o(i)}{E_d(i)} = \frac{E_o(j)}{E_d(j)} \hspace{2mm}  %\forall {i, j} \in \mathbf{I}
%\end{equation}
%The above equations are agnostic of any desired exposure distribution.
As discussed in the previous section, a RIR system $R$ may lead to items getting different observed exposures than what is desired. 
{\it Exposure Bias} ($ExpBias$) is the %as a measure of 
deviation caused due to $R$ between the desired and observed exposure of items.
Following the set up in our prior work~\cite{dash2021umpire}, we measure $ExpBias$ by KL divergence~\cite{cha2007comprehensive} between the observed exposure distribution $E_o = \{E_o(i) \; \forall i \in \mathbf{I}\}$ and the desired exposure distribution $E_d = \{E_d(i) \; \forall i \in \mathbf{I}\}$: 
%\vspace{1mm}
\setlength{\belowdisplayskip}{0pt} 
\setlength{\abovedisplayskip}{0pt} 
%\scriptsize
\small
\begin{align}
%\nonumber
ExpBias(R) = D_{KL} (E_o||E_d)= \sum_{i }{E_o(i) \hspace{1mm} log \hspace{1mm} \Big(\frac{E_o(i)}{E_d(i)}\Big)}
\end{align}\normalsize


\vspace{1mm}
\noindent
\textbf{Categorization of items}:
Based on the observed and desired exposure of items, we categorize items in three different classes based on how closely the observed exposure replicates their desired exposure.\\
(a) {\bf Under-exposed:} item $i$ is \textit{under-exposed} if $1-\epsilon \leq \frac{E_o(i)}{E_d(i)}$, \\
(b) {\bf Over-exposed:} item $i$ is \textit{over-exposed} if $\frac{E_o(i)}{E_d(i)} \geq 1+\epsilon$, \\
(c) {\bf Adequately-exposed:} item $i$ is \textit{Adequately-exposed} if $1-\epsilon \leq \frac{E_o(i)}{E_d(i)} \leq 1+\epsilon$, \\
While this threshold ($\epsilon$) can be chosen based on prier context and established regulations, in this paper, we use $\epsilon=0.2$. Note that similar thresholds have been used in multiple prior works too~\cite{chakraborty2017who, dash2018beyond, dash2021umpire}. 

\clearpage
\appendix
\renewcommand{\thesection}{\Alph{section}}

\DeclareRobustCommand{\highlight}[1]{{\sethlcolor{greycol}\hl{#1}}}
\newcommand{\mathcolorbox}[2]{\colorbox{#1}{$\displaystyle #2$}}

% \hl{TODO: move to supplementary matrial}

\section*{Appendix}

\section{Worst-case memory for \textit{Co}X3D-M}
In this section, we provide a detailed overview of the memory consumption incurred by the internal state in a Continual X3D-M (\textit{Co}X3D-M) model.
For Continual 3D CNNs, there is no need to store input frames between time steps, though this is the case for regular 3D CNNs applied in an online processing scenario. 
Intermediary computations from prior frames are kept in the continual layers as state if a layer has a temporal receptive field larger than 1. 
A continual $k_T \times k_H \times k_W = 1 \times 3 \times 3$ convolution is equivalent to a regular convolution, while a $3 \times 1 \times 1$ is not. 
The same principle holds for pooling layers. 
As a design decision, the temporal component of the average pooling of Squeeze-and-Excitation (SE) blocks is discarded. Hence, SE blocks do not incur a memory overhead or delay. 
Keeping the temporal pooling of the SE block would have increased memory consumption by a modest $85.050$ ($+1.4\%$).
We can compute the total state overhead using \cref{eq:conv-mem-store-frames}, \cref{eq:residual-mem}, and \cref{eq:pooling-mem} by adding up the state size of each applicable layer shown in \cref{tab:x3d-mem}.
%
An overview of the resulting computations can be found in \cref{tab:cox3dm-mem-calc}. 
The total memory overhead for the network state is $4{,}771{,}632$ floating point operations.
In addition to the state memory, the worst-case transient memory must be taken into account. 
The largest intermediary feature-map is produced after the first convolution in conv$_1$ and has a size of $24 \times 112 \times 112 = 301{,}056$ floats.
The total worst-case memory consumption for \textit{Co}X3D-M (excluding models weights) is thus \textbf{5,072,688} floats.

If we were to reduce the model clip size from 16 to 4, this would result in a memory reduction of $5{,}184$ floats (only $\text{pool}_5$ is affected) for a total worst-case memory of $5{,}067{,}504$ floats ($-0.1\%$). 
Increasing the clip size to 64 would yield an increased state memory of $20{,}736$ floats giving a total worst-case memory of $5{,}093{,}424$ floats ($+0.4\%$).

\begin{table}
\begin{center}
% \resizebox{0.48\textwidth}{!}{
\begin{tabular}{llrr}
    \toprule
    \textbf{Stage}  & \textbf{Layer}        &                                                               & \textbf{Mem.} (floats) \\ 
    \midrule
    conv$_1$        & conv$_{\text{T}}$     & $(5-1) \times 24 \times 112 \times 112 =$                     & $1{,}204{,}224$ \\
    \midrule
    res$_2$         & residual$_1$          & $(3-1-1) \times 24 \times 112 \times 112 =$                     & $301{,}056$ \\
                    & residual$_{2-3}$      & $\left[(3-1-1) \times 24 \times 56 \times 56\right] \times 2 =$ & $150{,}528$ \\
                    & conv$_{1-3}$          & $\left[(3-1-1) \times 54 \times 56 \times 56\right] \times 3 =$ & $508{,}032$ \\
                    % & SE-pool$_{1-3}$       & $\left[(16-1) \times 54 \right] \times 3 =$                   & $2.430$ \\
    \midrule
    res$_3$         & residual$_1$          & $(3-1-1) \times 24 \times 56 \times 56 =$                       & $75{,}264$ \\
                    & residual$_{2-5}$      & $\left[(3-1-1) \times 48 \times 28 \times 28\right] \times 4 =$ & $150{,}528$ \\
                    & conv$_{1-5}$          & $\left[(3-1) \times 108 \times 28 \times 28\right] \times 5 =$  & $846{,}720$ \\
                    % & SE-pool$_{1-5}$       & $\left[(16-1) \times 108 \right] \times 5 =$                   & $1.620$ \\
    \midrule
    res$_4$         & residual$_1$          & $(3-1-1) \times 48 \times 28 \times 28 =$                        & $37{,}632$ \\
                    & residual$_{2-11}$     & $\left[(3-1-1) \times 96 \times 14 \times 14\right] \times 10 =$ & $188{,}160$ \\
                    & conv$_{1-11}$         & $\left[(3-1) \times 216 \times 14 \times 14\right] \times 11=$  & $931{,}392$ \\
                    % & SE-pool$_{1-11}$      & $\left[(16-1) \times 216 \right] \times 11 =$                  & $35.640$ \\
    \midrule
    res$_5$         & residual$_1$          & $(3-1-1) \times 96 \times 14 \times 14 =$                       & $18{,}816$ \\
                    & residual$_{2-3}$      & $\left[(3-1-1) \times 192 \times 7 \times 7\right] \times 6 =$  & $56{,}448$ \\
                    & conv$_{1-3}$          & $\left[(3-1) \times 432 \times 7 \times 7\right] \times 7 =$  & $296{,}352$ \\
                    % & SE-pool$_{1-3}$       & $\left[(16-1) \times 432 \right] \times 7 =$                  & $45.360$ \\
    \midrule
    pool$_5$        & -                     & $(16-1) \times 432 =$                                         & $6{,}480$ \\
    \bottomrule
    \textbf{Total}  &                       &                                                               & \textbf{4,771,632} \\ %\textbf{6.192.618} \\
    \bottomrule
\end{tabular}
% }
\end{center}
\caption{\textbf{\textit{Co}X3D-M} state memory consumption by layer. }
\label{tab:cox3dm-mem-calc}
\end{table}

\begin{table}[!htbp]
\begin{center}
% \resizebox{0.42\textwidth}{!}{
\begin{tabular}{lcc}
    \toprule
    \multirow{2}{*}{\textbf{Stage}} & \multirow{2}{*}{\textbf{Filters}}   & \textbf{Output size} \\ 
                                    &                                     & ($T \times H \times W$) \\
    \midrule
    input           & -                         & $16 \times 224 \times 224$ \\
    \midrule
    conv$_1$        & $\begin{matrix} 
                      1 \times 3^2, 24 \\
                      \mathcolorbox{greycol}{5^{*} \times 1^2, 24}
                      \end{matrix}$             & $16 \times 112 \times 112 $ \\
    \midrule
    res$_2$         & \highlight{res}
                      $\begin{bmatrix} 
                      1 \times 1^2, 54 \\
                      \mathcolorbox{greycol}{\ 3 \times 3^2, 54 \ } \\
                      \text{SE} \\
                      %\mathcolorbox{greycol}{\quad \ \ \ \text{SE} \ \ \ \quad} \\
                      1 \times 1^2, 24 \\
                      \end{bmatrix} \times 3$   &$16 \times 56 \times 56 $ \\
    \midrule
    res$_3$         & \highlight{res}
                      $\begin{bmatrix} 
                      1 \times 1^2, 108 \\
                      \mathcolorbox{greycol}{3 \times 3^2, 108} \\
                      \text{SE} \\
                      %\mathcolorbox{greycol}{\quad \ \ \ \text{SE} \ \ \ \quad} \\
                      1 \times 1^2, 48 \\
                      \end{bmatrix} \times 5$   &$16 \times 28 \times 28 $ \\
    \midrule
    res$_4$         & \highlight{res}
                      $\begin{bmatrix} 
                      1 \times 1^2, 216 \\
                      \mathcolorbox{greycol}{3 \times 3^2, 216} \\
                      \text{SE} \\
                      %\mathcolorbox{greycol}{\quad \ \ \ \text{SE} \ \ \ \quad} \\
                      1 \times 1^2, 96 \\
                      \end{bmatrix} \times 11$   &$16 \times 14 \times 14 $ \\
    \midrule
    res$_5$         & \highlight{res}
                      $\begin{bmatrix} 
                      1 \times 1^2, 432 \\
                      \mathcolorbox{greycol}{3 \times 3^2, 432} \\
                      \text{SE} \\
                      %\mathcolorbox{greycol}{\quad \ \ \ \text{SE} \ \ \ \quad} \\
                      1 \times 1^2, 192 \\
                      \end{bmatrix} \times 7$   &$16 \times 7 \times 7 $ \\
    \midrule
    conv$_5$        & $1 \times 1^2, 432 $      & $16 \times 7 \times 7 $ \\
    % \midrule
    pool$_5$        & $\mathcolorbox{greycol}{16 \times 7^2}$  & $1 \times 1 \times 1$ \\
    % \midrule
    fc$_1$          & $1 \times 1^2, 2048 $     & $1 \times 1 \times 1 $ \\
    % \midrule
    fc$_2$          & $1 \times 1^2, \text{\#classes} $ & $1 \times 1 \times 1 $ \\
    \bottomrule
\end{tabular}
% }
\end{center}
\caption{\textbf{X3D-M model architecture}. When converted to a continual CNN, the \highlight{highlighted} components carry an internal state which results in a memory overhead. *Temporal kernel size in conv$_1$ is set to 5 as found in the official X3D source code~\cite{feichtenhofer2020x3d}.}
\label{tab:x3d-mem}
\end{table}




\clearpage
\section{Benchmarking details} \label{apx:benchmark-details}
This section should be read in conjunction with \cref{sec:inference-benchmarks} of the main paper.
To gauge the achievable on-hardware speeds of clip and frame predictions, a benchmark was performed on the following four system:
A CPU core of a MacBook Pro (16-inch 2019 2.6 GHz Intel Core i7); 
Nvidia Jetson TX2;
Nvidia Jetson Xavier;
and a Nvidia RTX 2080 Ti GPU (on server with Intel XEON Gold processors).
%
A batch size of 1 was used for testing on CPU, while the largest fitting multiple of $2^\mathbb{N}$ up to 64 was used for the other hardware platforms which have GPUs and lend themselves better to parallelisation. 
Thus, the speeds noted for GPU platforms in \cref{tab:benchmark-kinetics400} of the main paper should not be interpreted as the number of processed clips/frames from a single (high-speed) video stream, but rather as the aggregated number of clips/frames from multiple streams using the available hardware.
The exact batch size and input resolutions can be found in \cref{tab:benchmark-config}. 
In conducting the measurements, we assume the input data is readily available on the CPU and measure the time it takes for it to transfer from the CPU to GPU (if applicable), process, and transfer back to the CPU.
A precision of 16 bits was used for the embedded platforms TX2 and Xavier, while a 32 bit precision was employed for CPU and RTX 2080 Ti. 
All networks were implemented and tested using PyTorch, and neither Nvidia TensorRT nor ONNX Runtime were used to speed up inference.

% \newpage

\begin{table}[!htbp]
\begin{center}
% \resizebox{\linewidth}{!}{
\begin{tabular}{lrrrrr}
    \toprule
    \textbf{Model} %\multirow{2}{*}{\textbf{Model}} 
    &\textbf{Input shape} %\multirow{2}{*}{\textbf{Input shape}}  
    &\multicolumn{4}{c}{\textbf{Batch size}}
        \\ \cline{3-6}
        &($T \times S^2$) &\textbf{CPU} & \textbf{TX2}  &\textbf{Xavier} &\textbf{RTX}
    \\
    \midrule
    
    I3D-R50                       & $8  \times 224^2 $      & 1       & 16      & 16       & 32     \\
    R(2+1)D-18$_8$                & $8  \times 112^2 $      & 1       & 16      & 16       & 32     \\
    R(2+1)D-18$_{16}$             & $16 \times 112^2 $      & 1       & 8       & 16       & 32     \\
    Slow-8×8-R50                  & $8  \times 256^2 $      & 1       & 8       & 8        & 8     \\ 
    SlowFast-8×8-R50              & $8  \times 256^2 $      & 1       & 8       & 32       & 32     \\ 
    SlowFast-4×16-R50             & $16 \times 256^2 $      & 1       & 16      & 32       & 32     \\ %\cline{2-9}
    X3D-L                         & $16 \times 312^2 $      & 1       & 16       & 32       & 32     \\
    X3D-M                         & $16 \times 224^2 $      & 1       & 32      & 64       & 64     \\
    X3D-S                         & $13 \times 160^2 $      & 1       & 64      & 64       & 64     \\
    X3D-XS                        & $4  \times 160^2 $      & 1       & 64      & 64       & 64     \\
    \textit{Co}I3D                & $1  \times 224^2 $      & 1       & 8       & 8        & 8     \\
    \textit{Co}Slow                & $1  \times 224^2 $      & 1       & 8       & 8        & 8     \\
    \textit{Co}X3D-L              & $1  \times 312^2 $      & 1       & 8       & 16       & 32     \\
    \textit{Co}X3D-M              & $1  \times 224^2 $      & 1       & 32      & 64       & 64     \\
    \textit{Co}X3D-S              & $1  \times 160^2 $      & 1       & 32      & 64       & 64     \\
    \bottomrule
\end{tabular}
% }
\end{center}
\caption{
    \textbf{Benchmark model configurations}. For each model, the input shape is noted as $T \times S^2$, where $T$ and $S$ are the temporal and spatial input shape. 
    % The largest fitting multiple of $2^\mathbb{N}$ up to 64 was used as batch size for Nvidia Jetson TX2, Nvidia Jetson Xavier, and Nvidia RTX 2080 Ti.
}
\label{tab:benchmark-config}
\end{table}


% \vspace{-12pt}
\begin{table}
\begin{center}
% \resizebox{\linewidth}{!}{
\begin{tabular}{llccccccc}
    \toprule
    \multirow{2}{*}{\textbf{Model}} 
    &\multirow{2}{*}{\textbf{FLOPs}}  
    &\multicolumn{4}{c}{\textbf{Throughput (evaluations/s)}}
        \\ \cline{3-6}
        &&CPU & TX2  &Xavier &RTX
    \\
    \midrule             %FLOPS          CPU             TX2             XAVIER          RTX
    (\textit{Co})I3D     &5.04$\times$   & 3.39$\times$  & 0.95$\times$  & 1.62$\times$  & 1.64$\times$ \\
    (\textit{Co})Slow    &7.95$\times$   & 7.68$\times$  & 1.19$\times$  & 1.44$\times$  & 1.65$\times$ \\
    (\textit{Co})X3D-L   &15.34$\times$  & 9.20$\times$  & 5.21$\times$  & 5.77$\times$  & 5.98$\times$ \\
    (\textit{Co})X3D-M   &15.06$\times$  & 9.05$\times$  & 4.79$\times$  & 4.95$\times$  & 6.86$\times$ \\
    (\textit{Co})X3D-S   &12.11$\times$  & 5.91$\times$  & 4.15$\times$  & 4.98$\times$  & 3.41$\times$ \\
    \bottomrule
\end{tabular}
% }
\end{center}
% \vspace{-13pt}
\caption{\textbf{Relative improvements} in frame-by-frame inference in Continual 3D CNN relative to regular 3D CNN counterparts. The improvements ($\times$ lower for FLOPs and $\times$ higher for throughput) correspond to the results in \cref{tab:benchmark-kinetics400} of the main paper.}
\label{tab:relative-results}
\end{table}
% \vspace{-13pt}

% \newpage

\section{A note on RCU FLOPs} \label{apx:rcu}
In \cref{tab:benchmark-kinetics400} of the main paper, we have approximated the FLOPs for RCU~\cite{singh2019recurrent} as follows:
We use a different measure of FLOPs (the one from the \texttt{ptflops}~\cite{sovrasov2020ptflops}) than the RCU authors and therefore employ a translation factor of $28.6 / 41.0$, which is our measured FLOPs for I3D ($28.6$) divided by theirs ($41.0$), multiplied with their reported $54.0$ for RCU. Considering that their method used 8 frames and can be applied per frame, we also divide by 8. 
Note that the this approximation lacks the repeat classification layer and may thus be considered on the low side. The resulting computation becomes 
$28.6 / 41.0 \cdot 54.0 / 8 = 4.71$. 


% \clearpage

\section{Supplemental visualisations of benchmark}
As a supplement to the results presented in the main paper, this appendix supplies additional views of the benchmarking results in \cref{tab:benchmark-kinetics400}.
Accordingly, graphical representations of the accuracy versus speed trade-offs from \cref{tab:benchmark-kinetics400} are shown in Figures \ref{fig:acc-vs-speed-cpu}-\ref{fig:acc-vs-speed-rtx}.
As in \cref{fig:test-acc-vs-flops} of the main paper, the noted accuracies on Kinetics-400 were achieved using 1-clip/frame testing on publicly available pretrained models, the \textit{Co}X3D models utilised X3D weights without further fine-tuning, and the numbers noted in each point represent the size of the global average pooling layer.
Likewise, \cref{tab:relative-results} shows the improvements in continual inference relative to the regular models.
In general, the FLOPs improvements are higher than on-hardware speed evaluations, with relatively lower improvements on hardware platforms with GPUs. 
We attribute these differences to a memory operations overhead, which does not enjoy the same computational improvement as multiply-accumulate operations do on massively parallel hardware.

% \vspace{-10pt}
\begin{figure}[b]
    \centering
    \includegraphics[width=0.8\linewidth]{figures/acc-vs-cpu-log.pdf}
    % \vspace{-20pt}
    \caption{\textbf{CPU} inference throughput versus top-1 accuracy on Kinetics-400. } 
    \label{fig:acc-vs-speed-cpu}
\end{figure}


\begin{figure}[b]
    \centering
    \includegraphics[width=0.8\linewidth]{figures/acc-vs-tx2-log.pdf}
    % \vspace{-20pt}
    \caption{\textbf{TX2} inference throughput versus top-1 accuracy on Kinetics-400. }
    \label{fig:acc-vs-speed-tx2}
\end{figure}

% \newpage
% \vfill\null


% \begin{table}
% 	\begin{center}
% 	\begin{tabular}{lccc}
% 		\toprule
% 		                        \textbf{S} & \textbf{M} & \textbf{L} \\
% 		\midrule
% 		\textbf{FLOPs} \\
% 		\textbf{CPU} \\
% 		\textbf{TX2} \\
% 		\textbf{Xavier} \\
% 		\textbf{RTX 2080 Ti} \\
% 		\bottomrule
% 	\end{tabular}
% 	\caption{\textbf{Relative improvements} in frame-by-frame prediction in \textit{Co}X3D networks compared with regular X3D.}
% 	\label{tab:relative-results}
% 	\end{center}
% \end{table}

From Figures \ref{fig:acc-vs-speed-cpu}-\ref{fig:acc-vs-speed-rtx} we likewise observe, that the I3D, R(2+1)D and SlowFast models perform relatively better on hardware compared to the X3D and \textit{Co}X3D models, which utilise computation-saving approaches such as 1D-convolutions and grouped 3D-convolutions at the price of increasing memory access cost.


\begin{figure}[b]
    \centering
    \includegraphics[width=0.8\linewidth]{figures/acc-vs-xavier-log.pdf}
    % \vspace{-20pt}
    \caption{\textbf{Xavier} inference throughput versus top-1 accuracy on Kinetics-400.}
    \label{fig:acc-vs-speed-xavier}
\end{figure}

\begin{figure}[!b]
    \centering
    \includegraphics[width=0.8\linewidth]{figures/acc-vs-rtx2080ti-log.pdf}
    % \vspace{-20pt}
    \caption{\textbf{RTX2080Ti} inference throughput versus top-1 acc. on Kinetics-400.}
    \label{fig:acc-vs-speed-rtx}
\end{figure}


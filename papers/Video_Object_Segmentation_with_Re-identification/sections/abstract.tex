\begin{abstract}

Conventional video segmentation methods often rely on temporal continuity to propagate masks.
Such an assumption suffers from issues like drifting and inability to handle large displacement.
To overcome these issues, we formulate an effective mechanism to prevent the target from being lost via adaptive object re-identification.
Specifically, our Video Object Segmentation with Re-identification (VS-ReID) model includes a mask propagation module and a ReID module.
The former module produces an initial probability map by flow warping while the latter module retrieves missing instances by adaptive matching.
With these two modules iteratively applied, our VS-ReID records a global mean (Region Jaccard and Boundary F measure) of 0.699, the best performance in 2017 DAVIS Challenge.



%Video object segmentation in 2017 DAVIS Challenge \cite{Pont-Tuset_arXiv_2017} is non-trivial -- a video typically consists of more than one annotated object, with many distractors, small objects and fine structures. The complexity of the problem increases with severe inter-object occlusions and fast motion.
%	
%Conventional approaches that rely on temporal continuity suffer from issues like drifting and inability to handle large displacement. To overcome these issues, we formulate an effective mechanism to prevent the target from being lost via adaptive object re-identification. Specifically, our Video Object Segmentation with Re-identification (VS-ReID) model includes a mask propagation module and a ReID module. The mask propagation module is a two-stream convolutional neural network, inspired by \cite{Perazzi2017}. The RGB branch of the mask propagation module accepts a bounding box and a guided probability map as input, and produces a segmentation mask for the main instance in it as output. The guided probability map is obtained from adjacent frames' predictions by flow warping. In addition to the RGB branch, we also train an optical flow branch to incorporate the temporal information. The final segmentation mask of the image patch is obtained by averaging the predictions of these two branches. 
%
%To cope with frequent occlusions and large pose variations in dynamic scenes, we leverage object re-identification module to retrieve missing instances. Specifically, when previously missing instances are re-identified with a high confidence, they are assigned with a higher priority to be recovered during the mask propagation process. For each retrieved instance, we take its frame as the starting point and use the mask propagation module to bi-directionally generate the probability maps in its adjacent frames. 
%
%With the updated probability maps, the mask propagation module and ReID module of VS-ReID are alternatively applied to the whole video sequence until no more high confidence instances can be found.  Finally, for each frame, the instance segmentation results  are obtained by merging the probability maps of all the instances. With both flow warping to ensure temporal continuity and object re-identification to recover missing objects, VS-ReID records a global mean (Region Jaccard and Boundary F measure) of 0.699, the best performance in 2017 DAVIS Challenge.

\end{abstract}

\section{Experiments}
%
We evaluate our VS-ReID on the DAVIS 2017~\cite{Pont-Tuset_arXiv_2017} dataset.
%
DAVIS 2017 dataset contains 150 video sequences with all frames annotated with high-quality object masks.
%
There are 60 videos in the \emph{train set}, 30 videos in the \emph{val set}, 30 videos in the \emph{test-dev set} and 30 videos in the \emph{test-challenge set}.
%
In our experiments, we employ both \emph{train set} and \emph{val set} for training, and all performances are reported on the \emph{test-dev set}.
%
Followed~\cite{Perazzi2016}, we adopt region($\mathcal{J}$) and boundary($\mathcal{F}$) measures to evaluate the performance. 

\subsection{Ablation Study}
\begin{table}[t]
	\small
	\caption{Ablation study of each module in VS-ReID.}
	\centering
	\begin{tabular}{@{}l@{\,}|@{}c@{\,}|@{}c@{\,}|@{}c@{\,}|@{}c@{\,}}
		\hline
		&~$\mathcal{J}$-mean&~$\mathcal{F}$-mean~&~global-mean~&~boost~\\
		\hline\hline
		baseline\cite{Perazzi2017}~&0.509&0.526&0.517&-\\
		+~full-image to bbox~&0.532&0.577&0.555&~+~0.038\\
		+~flow-stream~&0.568&0.600&0.584&~+~0.007\\
		+~re-id module~&0.633&0.670&0.652&~+~0.068\\
		+~multi-scale testing~&0.644&0.678&\textbf{0.661}&~+~0.009\\
		\hline
	\end{tabular}
	\label{tab:ablation}
\end{table}
In this section, we investigate the effects of each component in VS-ReID model. 
%
Table~\ref{tab:ablation} summarizes how performance gets improved by adding each component step-by-step into our VS-ReID model.

We choose \cite{Perazzi2017} as our baseline model. 
%
After modified the input from full-image to bounding box, global-mean increases by $3.8\%$ and the boundary ($\mathcal{F}$) measure achieves a significant improvement of $5.1\%$.
%
It demonstrates that bounding box input overcomes large scale variations and contributes to capture the boundary details.
%
As mentioned in Sec.~\ref{sec:mask_propagation_module}, to incorporate the temporal information, we train an optical flow branch and joint fine-tuning it with the RGB branch.
%
This two-stream architecture also slightly improves the performance.
%
Employing the iterative refinement we introduced in Sec.~\ref{sec:VS-ReID} greatly improves the global-mean by $6.8\%$, which shows that the re-identification module and iterative refinement are essential.
%
We also visualize the example videos which are improved by this iterative refinement in Fig.~\ref{fig:visualization}.
%
Once an instance is recovered, it will benefit adjacent frames' prediction.
%
Finally, multi-scale testing further improves the results.

\begin{figure}
	\centering
	\includegraphics[width=0.48\textwidth]{figures/reid.pdf}
	\caption{\small{Missing instances are retrieved by re-identification module. We annotate the retrieved instances by blue bounding boxes. \textbf{Best viewed in color.}}}
	\label{fig:reid}
	\vspace{-12pt}
\end{figure}

\begin{table*}[t]
	\caption{Results on 2017 DAVIS Challenge \textit{test-challenge set}.}
	\scriptsize
	\centering
	\begin{tabular}{@{}l@{\,}|@{\,}c@{ \,}@{\,}c@{ \,}@{\,}c@{ \,}@{\,}c@{ \,}@{\,}c@{ \,}@{\,}c@{ \,}@{\,}c@{ \,}@{\,}c@{ \,}@{\,}c@{ \,}@{\,}c@{ \,}@{\,}c@{ \,}@{\,}c@{ \,}@{\,}c@{ \,}@{\,}c@{ \,}@{\,}c@{ \,}@{\,}c@{ \,}@{\,}c@{ \,}@{\,}c@{ \,}@{\,}c@{ \,}@{\,}c@{ \,}@{\,}c@{ \,}@{\,}c@{ \,}}
		\hline
		Measure & Ours & Apata & Vanta & Haamo & Voigt & Lalal & Cjc & YXLKJ & Wasid & Froma & Zwrq0 & Drbea & Anews & Ilanv & Koh & Make & Kozab & Xn881 & Zpd & Griff & Nitin & Team5 \\
		\hline\hline
		Ranking & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 & 16 & 17 & 18 & 19 & 20 & 21 & 22 \\
		\hline
		Global Mean$\uparrow$ & \textbf{69.9} & 67.8 & 63.8 & 61.5 & 57.7 & 56.9 & 56.9 & 55.8 & 54.8 & 53.9 & 53.6 & 51.9 & 50.9 & 49.7 & 49.1 & 48.0 & 47.8 & 47.6 & 47.1 & 42.0 & 25.6 & 11.2\\
		\hline\hline
		$\mathcal{J}$ Mean$\uparrow$ & \textbf{67.9} & 65.1 & 61.5 & 59.8 & 54.8 & 54.8 & 53.6 & 53.8 & 51.6 & 50.7 & 50.5 & 50.5 & 49.0 & 46.0 & 45.9 & 46.3 & 43.9 & 47.8 & 44.9 & 40.6 & 24.9 & 11.8\\
		$\mathcal{J}$ Recall$\uparrow$ & \textbf{74.6} & 72.5 & 68.6 & 71.0 & 60.8 & 60.7 & 59.5 & 60.1 & 56.3 & 54.9 & 54.9 & 56.4 & 55.1 & 49.3 & 50.2 & 50.0 & 45.8 & 56.3 & 48.0 & 42.1 & 12.3 & 7.3\\
		$\mathcal{J}$ Decay $\downarrow$ & 22.5 & 27.7 & 17.1 & 21.9 & 31.0 & 34.4 & 25.3 & 37.7 & 26.8 & 32.5 & 28.0 & 34.1 & 21.3 & 33.1 & 36.1 & 40.2 & 33.0 & 16.7 & 31.8 & 37.4 & 13.1 & 14.0\\
		\hline
		$\mathcal{F}$ Mean$\uparrow$ & \textbf{71.9} & 70.6 & 66.2 & 63.2 & 60.5 & 59.1 & 60.2 & 57.8 & 57.9 & 57.1 & 56.7 & 53.3 & 52.8 & 53.3 & 52.3 & 49.7 & 51.6 & 47.3 & 49.3 & 43.3 & 26.3 & 10.6\\
		$\mathcal{F}$ Recall$\uparrow$ & 79.1 & \textbf{79.8} & 79.0 & 74.6 & 67.2 & 66.7 & 67.9 & 62.1 & 64.8 & 63.2 & 63.5 & 57.9 & 58.3 & 58.4 & 57.1 & 52.8 & 56.0 & 53.0 & 54.4 & 43.2 & 9.1 & 3.0\\
		$\mathcal{F}$ Decay$\downarrow$ & 24.1 & 30.2 & 17.6 & 23.7 & 34.7 & 36.1 & 27.6 & 42.9 & 28.8 & 33.7 & 30.4 & 39.5 & 23.7 & 36.4 & 39.2 & 44.8 & 36.3 & 21.6 & 36.2 & 40.2 & 13.0 & 12.6\\
		\hline
	\end{tabular}
	\label{tab:leader_board}
\end{table*}

\subsection{Benchmark}
As shown in Table~\ref{tab:leader_board}, VS-ReID achieves a global mean of 0.699 on \emph{test-challenge set}, the best performance in 2017 DAVIS Challenge. 
%
By inspecting closer, we observe that VS-ReID wins both $\mathcal{J}$-Mean and $\mathcal{F}$-Mean measures and outperforms the second place method by more than $2\%$.
%
Thanks to the re-identification module that incorporates the long-term memory, our $\mathcal{J}$-Decay and $\mathcal{F}$-Decay are also relatively small.
%
In Fig.~\ref{fig:visualization}, we demonstrate some examples of VS-ReID prediction on DAVIS \emph{test-dev set} and \emph{test-challenge set}.

\begin{figure*}[t]
	\centering
	\includegraphics[width=1.0\textwidth]{figures/visualization.pdf}
	\caption{\small{Qualitative results of our VS-ReID model on DAVIS 2017 \textit{test-dev set} and \textit{test-challenge set}.}}
	\label{fig:visualization}
	\vspace{-12pt}
\end{figure*}

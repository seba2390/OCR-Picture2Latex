The presence of cycles in the directed league network will always appear and cause problems, regardless of what method is used for ranking.  
However, it is possible to use additional information in order to break the ``gridlock'' in these situations.  
In particular, we propose to utilize tensor theory in order to account for multiple attributes simultaneously.  
More specifically, we have the following definition: 

\begin{lemma}[{\tt League Tensor} definition]
The league tensor $\tensor{T}(i,j,t)$, captures the temporal evolution of the win-loss relationships between the league teams. In particular, the entry $\tensor{T}(i,j,t)=\delta > 0$ if team $j$ won against team $i$ during game $t$ by $\delta$ points differential. 
\label{def:tens}
\end{lemma}  

One way to identify latent patterns in the data modeled by the tensor - which can then be used to rank entities in the dataset - is the PARAFAC decomposition \cite{parafac}.  
In particular, PARAFAC decomposes $\tensor{T}$ to a sum of $F$ components (see Figure \ref{fig:tensor}), such that: 
\begin{equation}
\tensor{T} \approx \displaystyle {\sum_{f=1}^F  \mathbf{a}_f \circ \mathbf{b}_f \circ \mathbf{c}_f },
\label{eq:tesor_dec}
\end{equation}
where $ \mathbf{a}_f \circ \mathbf{b}_f \circ \mathbf{c}_f (i,j,k) = \mathbf{a}_f(i) \mathbf{b}_f (j) \mathbf{c}_f (k) $. 
In other words, each component, i.e., triplet of vectors, of the decomposition is a rank one tensor.
Each vector in the triplet corresponds to one of the three modes of the tensor: $\mathbf{a}$ corresponds to the losing teams, $\mathbf{b}$ corresponds to the winning teams, and $\mathbf{c}$ corresponds to the time (game week/day).
Each of these $F$ components can be considered as a cluster, and the corresponding vector elements as soft clustering coefficients. 
We can then process the components that correspond to the teams (i.e., $\mathbf{a}$ and $\mathbf{b}$) in order to obtain a final ranking of the teams.   
%For notational simplicity, we denote as matrix $\mathbf{A}$ (and matrices $\mathbf{B}$ and $\mathbf{C}$ accordingly) the factor matrix that contains the $\mathbf{a}_f$ vectors as columns.
%Note that for the purposes of this work, we use the, highly optimized, Tensor Toolbox for Matlab \cite{tensortoolbox}.

\begin{figure}[t]
\begin{center}
\vspace{-0.35in}
\includegraphics[scale=0.25,angle=270]{plots/tensor.pdf}%\vspacecap
\vspace{-0.4in}
 \caption{The PARAFAC decomposition of the league tensor can capture latent patterns in the win-lose interactions of the teams that can facilitate power ranking.}
 \label{fig:tensor}
\end{center}
\vspace{-0.2in}
\end{figure}

The above decomposition is the central building block of {\methodt}.  
We can further enhance the ranking by utilizing non-network elements for the teams. 
In particular, every team is associated with a variety of performance indices (e.g., for the case of NFL these can include offensive/defensing yards per game, turnovers per game etc.).  
This information can be represented by a matrix $\bm{Y}$, where each row corresponds to a team and the columns correspond to the external attributes.  
Matrix $\bf{Y}$ is said to be coupled with league tensor $\tensor{T}$ at the team dimension, since they share this dimension in common.  
If we want to differentiate the performance of a team during the wins and the loses, we can create two matrices $\bm{Y}_w$ and $\bm{Y}_l$ that correspond to the performance metrics of the teams only during the winning and losing games respectively.  
Both of these matrices are coupled with the league tensor ($\bm{Y}_w$ is coupled with the winning team dimension while $\bm{Y}_l$ is coupled with the losing team dimension). 
%
In general an $n$-dimensional tensor can be coupled with at most $n$ matrices $\mat{Y_i}$, $i\in\{1,~2,...,~n\}$.  
The coupled matrix-tensor factorization is given as the solution to the following optimization problem:

\begin{equation}
\displaystyle \min_{\mat{A_i},\mat{D_i}} \|\tensor{T} - \displaystyle {\sum_{k}  \mathbf{a_1}_k \circ \mathbf{a_2}_k \circ...\circ \mathbf{a_n}_k }\|_{F}^{2} +\sum_{i=1}^n\|\mat{Y_i}-\mat{A_i}\mat{D_i}^T\|_{F}^{2} %+...+\|\mat{Y_n}-\mat{A_n}\mat{D_n}^T\|_{F}^{2}
\label{eq:factorization}
\end{equation}

\noindent where $\mathbf{a_i}_k$ is the %$i^{th}$ dimension vector of the $f^{th}$ component of the PARAFAC decomposition of $\tensor{T}$ and forms the 
$k^{th}$ column of $\mat{A_i}$.  
The idea behind the coupled matrix-tensor decomposition is that we decompose $\tensor{T}$ and $\mat{Y_i}$ to latent factors that are coupled in the shared dimension.  
This joint factorization essentially provides a low dimensional embedding of the data in a common contextual subspace that can enable a variety of tasks including ranking.    



% you can have two matrices - one for the indices during the loses and one for the indices during the wins
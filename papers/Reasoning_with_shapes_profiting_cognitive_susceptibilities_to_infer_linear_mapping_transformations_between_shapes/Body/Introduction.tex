\IEEEraisesectionheading{\section{Introduction}}

\IEEEPARstart{V}{ision} system is studied in orthogonal disciplines spanning from neurophysiology and psychophysics to computer science all with uniform objective: understand the vision system and develop it into an integrated theory of vision. In general, vision or visual perception is the ability of information acquisition from environment, and it's interpretation. According to Gestalt theory, visual elements are perceived as patterns of wholes rather than the sum of constituent parts~\cite{koffka2013principles}. The Gestalt theory through \textit{emergence}, \textit{invariance}, \textit{multistability}, and \textit{reification} properties (aka Gestalt principles), describes how vision recognizes an object as a \textit{whole} from constituent parts. There is an increasing interested to model the cognitive aptitude of visual perception; however, the process is challenging. In the following, a challenge (as an example) per object and motion perception is discussed. 



\subsection{Why do things look as they do?}
In addition to Gestalt principles, an object is characterized with its spatial parameters and material properties. Despite of the novel approaches proposed for material recognition (e.g.,~\cite{sharan2013recognizing}), objects tend to get the attention. Leveraging on an object's spatial properties, material, illumination, and background; the mapping from real world 3D patterns (distal stimulus) to 2D patterns onto retina (proximal stimulus) is many-to-one non-uniquely-invertible mapping~\cite{dicarlo2007untangling,horn1986robot}. There have been novel biology-driven studies for constructing computational models to emulate anatomy and physiology of the brain for real world object recognition (e.g.,~\cite{lowe2004distinctive,serre2007robust,zhang2006svm}), and some studies lead to impressive accuracy. For instance, testing such computational models on gold standard controlled shape sets such as Caltech101 and Caltech256, some methods resulted $<$60\% true-positives~\cite{zhang2006svm,lazebnik2006beyond,mutch2006multiclass,wang2006using}. However, Pinto et al.~\cite{pinto2008real} raised a caution against the pervasiveness of such shape sets by highlighting the unsystematic variations in objects features such as spatial aspects, both between and within object categories. For instance, using a V1-like model (a neuroscientist's null model) with two categories of systematically variant objects, a rapid derogate of performance to 50\% (chance level) is observed~\cite{zhang2006svm}. This observation accentuates the challenges that the infinite number of 2D shapes casted on retina from 3D objects introduces to object recognition. 

Material recognition of an object requires in-depth features to be determined. A mineralogist may describe the luster (i.e., optical quality of the surface) with a vocabulary like greasy, pearly, vitreous, resinous or submetallic; he may describe rocks and minerals with their typical forms such as acicular, dendritic, porous, nodular, or oolitic. We perceive materials from early age even though many of us lack such a rich visual vocabulary as formalized as the mineralogists~\cite{adelson2001seeing}. However, methodizing material perception can be far from trivial. For instance, consider a chrome sphere with every pixel having a correspondence in the environment; hence, the material of the sphere is hidden and shall be inferred implicitly~\cite{shafer2000color,adelson2001seeing}. Therefore, considering object material, object recognition requires surface reflectance, various light sources, and observer's point-of-view to be taken into consideration.


\subsection{What went where?}
Motion is an important aspect in interpreting the interaction with subjects, making the visual perception of movement a critical cognitive ability that helps us with complex tasks such as discriminating moving objects from background, or depth perception by motion parallax. Cognitive susceptibility enables the inference of 2D/3D motion from a sequence of 2D shapes (e.g., movies~\cite{niyogi1994analyzing,little1998recognizing,hayfron2003automatic}), or from a single image frame (e.g., the pose of an athlete runner~\cite{wang2013learning,ramanan2006learning}). However, its challenging to model the susceptibility because of many-to-one relation between distal and proximal stimulus, which makes the local measurements of proximal stimulus inadequate to reason the proper global interpretation. One of the various challenges is called \textit{motion correspondence problem}~\cite{attneave1974apparent,ullman1979interpretation,ramachandran1986perception,dawson1991and}, which refers to recognition of any individual component of proximal stimulus in frame-1 and another component in frame-2 as constituting different glimpses of the same moving component. If one-to-one mapping is intended, $n!$ correspondence matches between $n$ components of two frames exist, which is increased to $2^n$  for one-to-any mappings. To address the challenge, Ullman~\cite{ullman1979interpretation} proposed a method based on nearest neighbor principle, and Dawson~\cite{dawson1991and} introduced an auto associative network model. Dawson's network model~\cite{dawson1991and} iteratively modifies the activation pattern of local measurements to achieve a stable global interpretation. In general, his model applies three constraints as it follows
\begin{inlinelist}
	\item \textit{nearest neighbor principle} (shorter motion correspondence matches are assigned lower costs)
	\item \textit{relative velocity principle} (differences between two motion correspondence matches)
	\item \textit{element integrity principle} (physical coherence of surfaces)
\end{inlinelist}.
According to experimental evaluations (e.g.,~\cite{ullman1979interpretation,ramachandran1986perception,cutting1982minimum}), these three constraints are the aspects of how human visual system solves the motion correspondence problem. Eom et al.~\cite{eom2012heuristic} tackled the motion correspondence problem by considering the relative velocity and the element integrity principles. They studied one-to-any mapping between elements of corresponding fuzzy clusters of two consecutive frames. They have obtained a ranked list of all possible mappings by performing a state-space search. 



\subsection{How a stimuli is recognized in the environment?}

Human subjects are often able to recognize a 3D object from its 2D projections in different orientations~\cite{bartoshuk1960mental}. A common hypothesis for this \textit{spatial ability} is that, an object is represented in memory in its canonical orientation, and a \textit{mental rotation} transformation is applied on the input image, and the transformed image is compared with the object in its canonical orientation~\cite{bartoshuk1960mental}. The time to determine whether two projections portray the same 3D object
\begin{inlinelist}
	\item increase linearly with respect to the angular disparity~\cite{bartoshuk1960mental,cooperau1973time,cooper1976demonstration}
	\item is independent from the complexity of the 3D object~\cite{cooper1973chronometric}
\end{inlinelist}.
Shepard and Metzler~\cite{shepard1971mental} interpreted this finding as it follows: \textit{human subjects mentally rotate one portray at a constant speed until it is aligned with the other portray.}



\subsection{State of the Art}

The linear mapping transformation determination between two objects is generalized as determining optimal linear transformation matrix for a set of observed vectors, which is first proposed by Grace Wahba in 1965~\cite{wahba1965least} as it follows. 
\textit{Given two sets of $n$ points $\{v_1, v_2, \dots v_n\}$, and $\{v_1^*, v_2^* \dots v_n^*\}$, where $n \geq 2$, find the rotation matrix $M$ (i.e., the orthogonal matrix with determinant +1) which brings the first set into the best least squares coincidence with the second. That is, find $M$ matrix which minimizes}
\begin{equation}
	\sum_{j=1}^{n} \vert v_j^* - Mv_j \vert^2
\end{equation}

Multiple solutions for the \textit{Wahba's problem} have been published, such as Paul Davenport's q-method. Some notable algorithms after Davenport's q-method were published; of that QUaternion ESTimator (QU\-EST)~\cite{shuster2012three}, Fast Optimal Attitude Matrix \-(FOAM)~\cite{markley1993attitude} and Slower Optimal Matrix Algorithm (SOMA)~\cite{markley1993attitude}, and singular value decomposition (SVD) based algorithms, such as Markley’s SVD-based method~\cite{markley1988attitude}. 

In statistical shape analysis, the linear mapping transformation determination challenge is studied as Procrustes problem. Procrustes analysis finds a transformation matrix that maps two input shapes closest possible on each other. Solutions for Procrustes problem are reviewed in~\cite{gower2004procrustes,viklands2006algorithms}. For orthogonal Procrustes problem, Wolfgang Kabsch proposed a SVD-based method~\cite{kabsch1976solution} by minimizing the root mean squared deviation of two input sets when the determinant of rotation matrix is $1$. In addition to Kabsch’s partial Procrustes superimposition (covers translation and rotation), other full Procrustes superimpositions (covers translation, uniform scaling, rotation/reflection) have been proposed~\cite{gower2004procrustes,viklands2006algorithms}. The determination of optimal linear mapping transformation matrix using different approaches of Procrustes analysis has wide range of applications, spanning from forging human hand mimics in anthropomorphic robotic hand~\cite{xu2012design}, to the assessment of two-dimensional perimeter spread models such as fire~\cite{duff2012procrustes}, and the analysis of MRI scans in brain morphology studies~\cite{martin2013correlation}.

\subsection{Our Contribution}

The present study methodizes the aforementioned mentioned cognitive susceptibilities into a cognitive-driven linear mapping transformation determination algorithm. The method leverages on mental rotation cognitive stages~\cite{johnson1990speed} which are defined as it follows
\begin{inlinelist}
	\item a mental image of the object is created
	\item object is mentally rotated until a comparison is made
	\item objects are assessed whether they are the same
	\item the decision is reported
\end{inlinelist}.
Accordingly, the proposed method creates hierarchical abstractions of shapes~\cite{greene2009briefest} with increasing level of details~\cite{konkle2010scene}. The abstractions are presented in a vector space. A graph of linear transformations is created by circular-shift permutations (i.e., rotation superimposition) of vectors. The graph is then hierarchically traversed for closest mapping linear transformation determination. 

Despite of numerous novel algorithms to calculate linear mapping transformation, such as those proposed for Procrustes analysis, the novelty of the presented method is being a cognitive-driven approach. This method augments promising discoveries on motion/object perception into a linear mapping transformation determination algorithm.



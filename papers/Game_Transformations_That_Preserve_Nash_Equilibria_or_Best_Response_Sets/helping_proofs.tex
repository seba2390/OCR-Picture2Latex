%\documentclass[main.tex]{subfiles}

\begin{document}

\section{Helping Lemmas}
\label{sec:helpinglemmas}

%Some further notes on notation: 
For player $i$ with pure strategy set $S^i = [m_i]$ in a game $G$, we will also refer to pure strategy $k \in [m_i]$ as the $k$-th standard basis vector $e_k \in \R^{m_i}$ (with a $1$ in its $k$-th entry and $0$'s anywhere else) because that is its corresponding mixed strategy vector in $\Delta(S^i)$.

Denote the restriction of a best response set to its pure strategies as $\PBR_{u_i}(\strats^{-i}) :=  \BR_{u_i}(\strats^{-i}) \cap \{e_1, \ldots, e_{m_i}\}$. Then, we have that best responses are always convex combinations of pure best responses:
\begin{lemma*}
\label{app:BR charact}
Take a game $G = \{u_i\}_{i \in [N]}$, fix a player~$i \in [N]$ and a strategy profile $\strats^{-i} \in \Delta(S^{-i})$ of the opponents. Then, we have for $t^i \in \Delta(S^i)$:
\begin{align}
    t^i \in \BR_{u_i}(\strats^{-i}) \iff \forall k \in [m_i] : \,  t_k^i = 0 \, \, \, \textup{or} \, \, \, e_k \in \PBR_{u_i}(\strats^{-i})  \, .
\end{align}
\end{lemma*}
\begin{proof}
We can observe
\begin{align}
\label{convex payoff combi}
\begin{aligned}
    u_i(t^i, \strats^{-i}) &= \sum_{\ks \in S} s_{k_1}^1 \cdot \ldots \cdot s_{k_{i-1}}^{i-1} \cdot t_{k_i}^i \cdot s_{k_{i+1}}^{i+1} \cdot \ldots \cdot s_{k_N}^N \cdot u_i(\ks) 
    \\
    &= \sum_{k_i=1}^{m_i} t_{k_i}^i \cdot \sum_{\ks_{-i} \in S^{-i}} s_{k_1}^1 \cdot \ldots \cdot s_{k_{i-1}}^{i-1} \cdot s_{k_{i+1}}^{i+1} \cdot \ldots \cdot s_{k_N}^N \cdot u_i(\ks) 
    \\
    &= \sum_{k_i=1}^{m_i} t_{k_i}^i \cdot u_i(e_{k_i}, \strats^{-i}) = \sum_{k=1}^{m_i} t_{k}^i \cdot u_i(e_k, \strats^{-i}) \, .
\end{aligned}
\end{align}
Thus, the mixed strategy $t^i$ of player $i$ only determines the convex combination of the attainable utility values $\Big( u_i(e_k, \strats^{-i}) \Big)_k$. Therefore, any best response strategy $t^i$ must only randomize over maximal values within $\Big( u_i(e_k, \strats^{-i}) \Big)_k$, that is, over pure best response strategies.
\end{proof}

\begin{cor}
\label{app:BR equal through PBR}
Two best response sets (of possibly different games) are equal if and only if they contain the same pure best responses.
\end{cor}

\begin{lemma*}
\label{app:multiplayer PAT preserves}
Take a PAT $H_{\textnormal{PAT}} = \big\{ \alpha^i, C^i \big\}_{i \in [N]}$ and any game $G = \{u_i\}_{i \in [N]}$. Then, the transformed game $H_{\textnormal{PAT}}(G) = \{u_i'\}_{i \in [N]}$ has the same best response sets as the input game $G$. Consequently, $H_{\textnormal{PAT}}(G)$ also has the same \NE{} set as $G$.
\end{lemma*}
\begin{proof}
The proof is an appropriate generalization of the known proof for Lemma~\ref{PAT preserves lemma}.

Take a game $\{u_i\}_{i \in [N]}$, fix a player~$i$ and the opponents' strategy choices $\strats^{-i}$. Then, we have
\begin{align*}
    \BR&_{u_i'}(\strats^{-i}) = \argmax_{t^i \in \Delta(S^i)} \Big\{ \, u_i'(t^i,\strats^{-i}) \, \Big\} \\
    &= \argmax_{t^i \in \Delta(S^i)} \Big\{ \, \sum_{\ks \in S} s_{k_1}^1 \cdot \ldots \cdot s_{k_{i-1}}^{i-1} \cdot t_{k_i}^i \cdot s_{k_{i+1}}^{i+1} \cdot \ldots \cdot s_{k_N}^N \cdot u_i'(\ks) \, \Big\} \\
    \overset{(\ref{PAT transformed utilities})}&=\argmax_{t^i \in \Delta(S^i)} \Big\{ \sum_{\ks \in S} s_{k_1}^1 \cdot \ldots \cdot s_{k_{i-1}}^{i-1} \cdot t_{k_i}^i \cdot s_{k_{i+1}}^{i+1} \cdot \ldots \cdot s_{k_N}^N \cdot  \big( \alpha^i \cdot u_i(\ks) +  c_{\ks_{-i}}^i \big) \Big\} \\
    \overset{(*)}&{=} \argmax_{t^i \in \Delta(S^i)} \Big\{ \, \alpha^i \cdot \sum_{\ks \in S} s_{k_1}^1 \cdot \ldots \cdot s_{k_{i-1}}^{i-1} \cdot t_{k_i}^i \cdot s_{k_{i+1}}^{i+1} \cdot \ldots \cdot s_{k_N}^N \cdot u_i(\ks)  \\
    &\quad \quad \quad \quad \quad \quad + \sum_{\ks_{-i} \in S^{-i}} s_{k_1}^1 \cdot \ldots \cdot s_{k_{i-1}}^{i-1} \cdot s_{k_{i+1}}^{i+1} \cdot \ldots \cdot s_{k_N}^N \cdot c_{\ks_{-i}}^i  \cdot 1\Big\} \\
    \overset{(\dagger)}&{=} \argmax_{t^i \in \Delta(S^i)} \Big\{ \, \sum_{\ks \in S} s_{k_1}^1 \cdot \ldots \cdot s_{k_{i-1}}^{i-1} \cdot t_{k_i}^i \cdot s_{k_{i+1}}^{i+1} \cdot \ldots \cdot s_{k_N}^N \cdot u_i(\ks) \Big\} \\
    &= \argmax_{t^i \in \Delta(S^i)} \Big\{ \, u_i(t^i,\strats^{-i}) \, \Big\} = \BR_{u_i}(\strats^{-i}) 
\end{align*}
We obtain the second summand in $(*)$ by changing the order of summation and multiplication such that $\sum_{k_i = 1}^{m_i} t_i$ remains as the most inner sum. Since $\sum_{k_i = 1}^{m_i} t_i = 1$, this factor can be dropped. We get line $(\dagger)$ because the argmax operator is neither affected by a constant in $t_i$ (such as the secoond summand) nor by rescaling with a positive factor (such as $\alpha_i$).

Finally, the definition of a \NE{} immediately implies that strategy profile $s$ is a \NE{} for the PAT transformed game $\{u_i'\}_{i \in [N]}$ if and only if it was one for the original game $\{u_i\}_{i \in [N]}$.
\end{proof}


\section{Monotone and additive implies linear}
\label{sec:analysislemma}
The proof of the following lemma is taken from \cite{monadd1, monadd2}:
\begin{lemma*}
Take a map $h: \R \longrightarrow \R$ which is monotone and additive. Then:
\begin{enumerate}

\item $ h(0) = 0 $ .
\item \label{hihi} $ \forall x \in \R \, : \quad -h(-x) = h(x) $ .
\item $ \forall n \in \N, x \in \R \, : \quad h(n \cdot x) = n \cdot h(x) $ .
\item $ \forall p \in \Z, x \in \R \, : \quad h(p \cdot x) = p \cdot h(x) $ .
\item $ \forall r \in \Q, x \in \R \, : \quad h(r \cdot x) = r \cdot h(x) $ .
\item $ \forall x \in \R \, : \quad h(x) = x \cdot h(1) $ .
\end{enumerate}
In particular, the last conclusion yields that $h$ is linear.
\end{lemma*}
\begin{proof}
The first three conclusions follow from $h$ being additive. 

\paragraph{1} 
\[ h(0) = h(0) + h(x) - h(x) = h(0 + x) - h(x) = 0 \, .\]

\paragraph{2} 
\[ \forall x \in \R \, : \quad -h(-x) = - \Big( h(-x) + h(x) \Big) + h(x) = - h( -x + x ) + h(x) = - h(0) + h(x) = h(x) \, . \]

\paragraph{3} 
Proof by induction. The induction start $n=1$ is clear, so assume it to be true for $n \in \N$. 
\\
Then, for all $x \in \R$:
\[ h\Big( (n+1) \cdot x \Big) = h(n\cdot x + x) = h(n \cdot x) + h(x) = n \cdot h(x) + h(x) = (n+1)\cdot h(x) \, . \]

\paragraph{4} 
The statement for the case $p \in \Z \, \cap \, \{ z \geq 0 \}$ follows from the first and third conclusion. If $p \in  \Z \, \cap \, \{ z < 0 \}$, we can use the second and third conclusion to obtain for all $x \in \R$:
\[h(p \cdot x) = h\Big( (-p) \cdot (-x) \Big) = (-p) \cdot h(-x) = (-p) \cdot \Big( -h(x) \Big) = p \cdot h(x) \, .\]

\paragraph{5} 
Write $r = \frac{p}{q}$ where $p \in \Z, q \in \N$. Then, by the fourth conclusion:
\[ h(r \cdot x) = \frac{1}{q} \cdot q \cdot h\Big( \frac{p}{q} \cdot x \big) = \frac{1}{q} h\Big( q \cdot \frac{p}{q} \cdot x \big) = \frac{1}{q} h(p \cdot x ) =\frac{1}{q} \cdot p \cdot h(x) = r \cdot h(x) \, . \]

\paragraph{6} 
Suppose $x \in \Q$. Then, the fifth conclusion yields
\[ h(x) = h(x \cdot 1) = x \cdot h(1) \, .\]
Therefore, suppose $x \in \R \setminus \Q$.

Since $\Q$ is dense in $\R$, we can take an increasing sequence $(r_n)_{n \in \N} \subset \Q$ that converges to $x$ (from below) and a decreasing sequence $(s_n)_{n \in \N} \subset \Q$ that converges to $x$ (from above). In the case where $h$ is an increasing function, we have for all $n \in \N$:
\[ r_n \leq x \leq s_n \implies h(r_n) \leq h(x) \leq h(s_n) \implies r_n \cdot h(1) \leq h(x) \leq s_n \cdot h(1) \, .\]
Taking the limit $n \rightarrow \infty$ in the last inequality chain yields
\[ x \cdot h(1) \leq h(x) \leq x \cdot h(1) \, .\]
If $h$ is a decreasing function instead of an increasing one, we get the same implications but with reverse inequalities in the second and last inequality chains. The end result, however, will be the same. Putting everything together yields the sixth conclusion.

\end{proof}

\begin{cor*}
\label{app:affine linearity corollary}
Let $h: \R \longrightarrow \R$ be monotone and satisfy for all $z,z',\lambda \in \R$:
\begin{equation}
\label{distance preserving}
h(z+\lambda) - h(z) = h(z' + \lambda) - h(z') \, .
\end{equation} 
Then h is affine linear, i.e., there exist some $a,c \in \R$ such that for all $z \in \R\, : \, h(z) = az + c$.
\end{cor*}
\begin{proof} 
Define $h'(z):=h(z) - h(0)$, which is still a monotone function. By our assumption on $h$, we have for all $x,y \in \R$:
\begin{align*}
h'(x+y) &= h(x+y)-h(0) = h(x+y) - h(y) + h(y) - h(0) \\
&= h(x) - h(0) + h(y) - h(0) = h'(x) + h'(y) \, .
\end{align*}
Therefore, we can apply Lemma~\ref{helping analysis lemma} to $h'$ to get $a \in \R$ such that for all $z \in \R$ 
\[h(z) = h(z) - h(0) + h(0) = h'(z) + h(0) = az + h(0) =: az + c \, .\]
\end{proof}

\end{document}
\section{Related Work}
\vspace{-5pt}
\label{secc:related}
% In this section we review the relevant methods Self-Supervised and contrastive learning methods. We will also discuss the methods that discuss the importance of data augmentations in SSL methods.  
Recent progress in self-supervised learning, based on contrastive and non-contrastive approaches, has achieved excellent performance on various domains, datasets and tasks \citep{he2019momentum,chen2020improved,chen2020simple,Oord2018RepresentationLW,tian2019contrastive,gidaris2020learning,misra2019selfsupervised,NEURIPS2020_4c2e5eaa,8578491,grill2020bootstrap,Gidaris2018UnsupervisedRL,Larsson2017ColorizationAA,Noroozi_2018_CVPR,Pathak2016ContextEF}. The top-performing methods have all used related ideas of pulling together ``views" of a sample in representation space. Some of these approaches, in addition, use negative samples to add a ``push" factor, and this is termed contrastive self-supervised learning. Theoretical and empirical studies have been published to better understand the behavior and limitations of these approaches  \citep{arora2019theoretical,xiao2021contrastive,purushwalkam2020demystifying,tosh2021contrastive,wang2020understanding,yang2020xlnet,NEURIPS2020_63c3ddcc,liu2021selfsupervised,kalantidis2020hard,Newell_2020,cai2020negatives}. 

A number of papers have observed that the default SSL approaches above (whether contrastive or not) perform poorly on uncurated datasets such as OpenImages \citep{kuznetsova2020open}. To address this, recent works have used different workarounds such as knowledge distillation \citep{tian2021divide}, clustering \citep{goyal2021selfsupervised}, localization \citep{selvaraju2020casting}, unsupervised semantic segmentation masks \citep{henaff2021efficient}, pixel-level pretext tasks\citep{xie2021propagate}, Instance localization \citep{yang2021instance} and local contrastive learning \citep{liu2021selfemd}. The common element among top-performing image-based SSL approaches, regardless of dataset, task or architecture, is their reliance on strong data augmentations such as random cropping, gaussian blurring, color jittering or rotations. These augmentations create meaningful positive views, and other randomly sampled images in the dataset are used to create negative views in the case of contrastive SSL methods. SSL data augmentation pipelines are adapted from the supervised learning literature \citep{cubuk2019autoaugment,zoph2020rethinking,NIPS2012_c399862d,2003aug,devries2017dataset,cubuk2019autoaugment,zhang2018mixup,cubuk2019randaugment,wu2019detectron2,yun2019cutmix,lim2019fast,hataya2019faster}.

The closest work to our object cropping work is \citep{selvaraju2020casting}, which introduces a technique to choose crops around objects based on saliency maps \citep{Selvaraju2016GradCAMVE}, showing good improvements over the baseline of random crops for COCO datasets (see Table \ref{tab:coco_detection}). As shown in our results, Obj-Obj+Dilate crop consistently performs better than \citep{selvaraju2020casting} (Table \ref{tab:coco_detection}). Our approach is also significantly simpler to incorporate into existing pipelines, requiring no change to the training, architecture or loss. \citet{vangansbeke2021revisiting} show that constrained multi-cropping improves performance of SSL methods: our approach can be incorporated into their pipeline to further improve performance. 

%A fundamental underlying assumption in these methods is the fact that these datasets are object centred, i.e a single object occupies most of the image. This assumption holds true for ImageNet but it doesn't hold true for OpenImages dataset \citep{Kuznetsova_2020}. In our work we show that by using BING crops we can focus more on object centric features which transfer well. Another recently famous line of work that has gained lot of popularity in the recent times doesn't use negative samples \citep{grill2020bootstrap,caron2021unsupervised,Caron2020UnsupervisedLO,chen2020exploring}. We show the efficacy of our method on both of these types of contrastive learning approaches and significantly improve  upon the baseline methods.



% Divide and Contrast \citep{tian2021divide} firstly uses clustering to build semantically  meaningful clusters from the uncurated datasets and then uses teacher network using knowledge distillation to further improve the representations.
% CASTing model \citep{selvaraju2020casting} uses Grad-CAM to detect objects and improve performane on "non-iconoic" datasets. DetCon \citep{henaff2021efficient} uses unsupervised semantic segmentation masks to localize objects and uses object from the same mask as positive samples. However unlike DetCon \citep{henaff2021efficient}  we use Objectness predicting algorithms and also entanglement of object and scene crops. Sel-EMD \citep{liu2021selfemd} uses Earth Mover's Distance between the features of an image and tries to learn features from relevant and overlapping image region between two crops.  

% Learning from uncurated datasets is one of the most fundamental problems in SSL. Many recent works have tried to address and solve the problem of leaning from uncurated datasets. Divide and Contrast \citep{tian2021divide} firstly uses clustering to build semantically  meaningful clusters from the uncurated datasets and then uses teacher network using knowledge distillation to further improve the representations.
% CASTing model \citep{selvaraju2020casting} uses Grad-CAM to detect objects and improve performane on "non-iconoic" datasets. DetCon \citep{henaff2021efficient} uses unsupervised semantic segmentation masks to localize objects and uses object from the same mask as positive samples. However unlike DetCon \citep{henaff2021efficient}  we use Objectness predicting algorithms and also entanglement of object and scene crops. Sel-EMD \citep{liu2021selfemd} uses Earth Mover's Distance between the features of an image and tries to learn features from relevant and overlapping image region between two crops. Our proposed method however is complementary to these approaches and can potentially be augmented with any of these methods. 

% These methods show improved results across various datasets like ImageNet \citep{imagenet_cvpr09}, Stanford Cars \citep{KrauseStarkDengFei-Fei_3DRR2013}, CIFAR \citep{cifar}, SVHN \citep{goodfellow2014multidigit}.  MixUp \citep{zhang2018mixup}. 
 
% AutoAugment  \citep{cubuk2019autoaugment} uses Reinforcement Learning to search for improved data augmentations policies. They show improved results across various datasets like ImageNet \citep{imagenet_cvpr09}, Stanford Cars \citep{KrauseStarkDengFei-Fei_3DRR2013}, CIFAR \citep{cifar}, SVHN \citep{goodfellow2014multidigit}.  MixUp \citep{zhang2018mixup} trains a neural network on convex combinations of examples and their labels. MixUp forces the neural networks to behave linearly between training samples. RandAug \citep{cubuk2019randaugment} is another data augmentation similar to AutoAugement which uses significantly less search space and can achieves state-of-art results across various datasets. However one of the issues in these methods is use of Random Cropping which we have shown doesn't work well in case of multi-object datasets. 

% \textbf{Importance of cropping vs other data augmentations:} Random Crop augmentation has been central to achieving state-of-the art results in SSL \citep{chen2020simple}(see Fig5). GLOM \citep{Hinton2021HowTR} also discusses the importance of having scene level representations vs object level representations for building all purpose models such as GLOM \citep{Hinton2021HowTR}. GLOM touches upon the idea that contrastive learning on non-iconic datasets will not work well due to the presence of multiple objects. To solve this problem we have proposed using both object level and scene level representations in conjunction with each other. We also analyze various other possibilities such as using object-object, object-scene and scene-scene representations and discuss the various other factors that could impact the performance. However we find that simple object-scene level cropping shows best performance for non-iconic datasets.    
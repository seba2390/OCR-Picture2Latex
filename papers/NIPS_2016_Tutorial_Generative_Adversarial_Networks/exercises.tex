\section{Exercises}

This tutorial includes three exercises to check your understanding.
The solutions are given in \secref{sec:solutions}.

\subsection{The optimal discriminator strategy}
\label{sec:opt_d}

As described in \eqref{eq:discriminator_cost}, the goal of the discriminator is to minimize
\begin{equation}
  J^{(D)}(\vtheta^{(D)}, \vtheta^{(G)}) = -\frac{1}{2} \E_{\vx \sim \pdata} \log D(\vx) - \frac{1}{2} \E_{\vz} \log \left(1 - D\left( G(z) \right) \right)
\end{equation}
with respect to $\vtheta^{(D)}$.
Imagine that the discriminator can be optimized in function space, so the value of
$D(\vx)$ is specified independently for every value of $\vx$.
What is the optimal strategy for $D$?
What assumptions need to be made to obtain this result?

\subsection{Gradient descent for games}
\label{sec:xy_exercise}

Consider a minimax game with two players that each control a single scalar value.
The minimizing player controls scalar $x$ and the maximizing player controls
scalar $y$.
The value function for this game is
\[ V(x, y) = x y .\]

\begin{itemize}
  \item Does this game have an equilibrium? If so, where is it?
  \item Consider the learning dynamics of simultaneous gradient descent.
        To simplify the problem, treat gradient descent as a continuous time
        process.
        With an infinitesimal learning rate, gradient descent is described by a system of partial differential equations:
        \begin{align}
          \frac{\partial x}{\partial t} &= - \frac{\partial}{\partial x} V\left( x(t), y(t) \right) \\
          \frac{\partial y}{\partial t} &= \frac{\partial}{\partial y} V\left( x(t), y(t) \right).
        \end{align}
        Solve for the trajectory followed by these dynamics.
\end{itemize}



\subsection{Maximum likelihood in the GAN framework}
\label{sec:mle_exercise}

In this exercise, we will derive a cost that yields (approximate) maximum likelihood learning within the GAN framework.
Our goal is to design $J^{(G)}$ so that, if we assume the discriminator is optimal, the expected gradient of $J^{(G)}$
will match the expected gradient of $\KL(\pdata \Vert \pmodel)$.

The solution will take the form of:
\[
  J^{(G)} = \E_{\vx \sim p_g} f(\vx) .
\]

The exercise consists of determining the form of $f$.


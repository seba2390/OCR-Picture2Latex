%!TEX root = ../main-arxiv.tex



\section{Proofs of Hallucination Properties \label{sec:proofs_for_hhh}}


\subsection{Proof of \Cref{lem:data_hygiene} \label{proof:lem_data_hygiene}}
	Here, we prove the data-hygiene principle. We begin with the following general fact, which clarifies the essential properties of the hidden hallucination algorithm required for $\ledhonl$ and $\ledcensl$ to be hygenic. Throughout, we abbreviate sequences of variable $(x_1,\dots,x_{\ell})$ as $x_{1:\ell}$.
	\begin{fact}\label{fact:conditional_fact} Consider a collection of random `model' variable $\modvar$, `trajectory' random variables $\hat{\bm{x}}_1,\dots,\hat{\bm{x}}_{\ell} \in \mathcal{X}$, and `policy' random variables $\hat{\bm{y}}_1,\dots,\hat{\bm{y}}_{\ell} \in \mathcal{Y}$. Assume that $\mathcal{X}$ and $\mathcal{Y}$ are countable, and that the above random variables have joint law $\Pr$. Suppose that
	\begin{itemize}
	\item[(a)] There is function $\Pr_0[\cdot \mid \model,y]$ whose values are probability distributions of $\calX$ such that %(a) that there is a family of measures  $\Pr_{x}[\cdot \mid \model , y]$ such that, for $\calX' \subset \calX$, the conditional expectations factor as
	\begin{align*}
	\Pr[\hat{\bm{x}}_{i} \in \cdot \mid \hat{\bm{x}}_{1:i-1},\hat{\bm{y}}_{1:i}, \modvar]  \quad=\quad \Pr_0[\hat{\bm{x}}_{i}  \in \cdot \mid \modvar, \hat{\bm{y}}_i]
	\end{align*}
	\item[(b)] the ``policy'' variable  $\hat{\bm{y}}_{i}$ and ``model'' variable $\modvar$ are conditionally independent  given the past ``trajectory'' variables $\hat{\bm{x}}_{1:i-1}$.
\end{itemize}
	Now, for a given sequence $y_{1:\ell} \in \mathcal{Y}^\ell$, define a distribution  $\tilde{\Pr}$ over random variables, $(\tilde{\modvar}, \tilde{\bm{x}}_{1:\ell})$ by lettting $\tilde{\modvar}$ have the same marginal distribution as $\modvar$, and letting $\tilde{\bm{x}}_{i} \sim \Pr_0[\cdot \mid \tilde{\modvar},y_i]$ are drawn independent from the law $\Pr_0$, under the fixed $y_i$ and $\tilde{\modvar}$. Then, we have the following equality of distributions:
	\begin{align}
	\Pr[\modvar \in \cdot \mid \hat{\bm{x}}_{1:\ell} = x_{1:\ell}, \hat{\bm{y}}_{1:\ell}= y_{1:\ell}] = \tilde{\Pr}[\tilde{\modvar} \in \cdot \mid \tilde{\bm{x}}_{1:\ell} = x_{1:\ell}] \label{eq:useful_fact}
	\end{align}
	\end{fact}
 \Cref{fact:conditional_fact} can be verified directly by writing out the relevant conditionals.

Let us now apply above the fact to the proof of \Cref{lem:data_hygiene}, beginning with the censored ledger $\ledcens$. We take $\modvar$  to be $\modst$, and in phases $i$, let $\hat{\bm{x}}_i := \cens(\traj_{\kexpl[i]})$ denote the random variable corresponding to the total censoring of the trajectory recieved on the (random) $i$-th hallucination episode, and $\hat{\bm{y}}_i := \pi_{\kexpl[i]}$ the random variable for the corresponding policy; we take $\Pr$ be the measure yielding their joint distribution. Then,
\begin{itemize}
	\item Condition (a) in  \Cref{fact:conditional_fact} satisfied since $\traj_{\kexpl[i]} \sim \sfP^{\pi}_{\modelst}$ for $\pi = \pi_{\kexpl[i]}$, even when conditioning on all past policies and trajectories.
	\item Condition (b) also holds. This is for because the choice of policy on a hallucination episode $i$ is generated purely based on the hallucination mechanism, which (1) only uses information from past hallucination episodes $1:i-1$ and (2) the only information from those past episodes are transition information (not rewards), and these are specificed by the totally censored trajectories $\hat{\bm{x}}_j := \cens(\traj_{\kexpl[j]})$, $j < i$.
\end{itemize}
  Thus, \Cref{eq:useful_fact} holds. The left-hand side of \Cref{eq:useful_fact} is precisely $\Pr[\modst \in \cdot \mid \ledcensl]$, since $\ledcensl$ comprises of precisely the trajectories and policies on past hallucination episodes. And, the right hand side of \Cref{eq:useful_fact} is precisely the canonical probability $\Prcan[\modst \in \cdot \mid \ledcensl]$ which regards the policies as fixed and non-random; hence, $\ledcensl$ is hygenic.

  The proof that $\ledhonl$ is hygenic is nearly identical. Here, we take $\hat{\bm{x}}_i := \cens(\traj_{\kexpl[i]};\calU_i)$ to be the $\calU_i$-censored trajectories, and $\hat{\bm{y}}_i = (\calU_i,\pi_{\kexpl[i]})$ to be the pair consisting of the hallucination policy at phase $i$, and the censoring set $\calU_i$ for that phase. Again, condition (a) follows directly, and condition (b) follows since both the policy on the hallucination episodes $\pi_{\kexpl[i]}$ and the censoring set $\calU_i$ are determined by algorithmic randomness and past totally censored ledgers from hallucination episodes, $\cens(\traj_{\kexpl[j]})$, $j < i$. Since $\hat{\bm{x}}_i := \cens(\traj_{\kexpl[i]};\calU_i)$ only censors triples in $\calU_i$, $\hat{\bm{x}}_{1:i-1}$ uniquely determines $\cens(\traj_{\kexpl[j]}), ~j < i$. Thus, given $\hat{\bm{x}}_{1:i-1}$, , $\hat{\bm{y}}_i = (\calU_i,\pi_{\kexpl[i]})$ is independent of the model $\modst$. The desired conclusion follows.
	\qed

\subsection{Proof of \Cref{prop:mdp_hh} \label{proof:prop_mdp_hh}}

\newcommand{\ledvarhat}{\hat{\ledvar}}
\newcommand{\Zhal}{Z_{\mathrm{hal}}}
\newcommand{\phal}{p_{\mathrm{hal}}}
\newcommand{\Bernoulli}{\mathrm{Bernoulli}}
\newcommand{\khatexpl}{\widehat{\bm{k}}_{\ell}^{\mathrm{\ell}}}

Thourought, we fix an episode $k \in \Phase_{\ell}$ for a given phase $\ell \in \N$. Recall that $\Pi \subset \Pitotal$ is our target set of policies. We have to show that, given that if the revealed ledger $\ledger_k$ satisfies
\begin{align}
\frac{1}{\nphase} \le \frac{\gapcan[\Pi \mid \ledger_k] \cdot \Prcan[\EvPun\mid \ledcensl]}{3H},
\label{eq:hh_condition}
\end{align}
it holds that any maximizer of $\Exp[\valuef{\pi}{\modst} \mid \ledvarhat_k = \ledger_k]$ lies in $\Pi$.


The central objects in our analysis is the following $\Prmech$-measurable random variable $\Zhal$ and its conditional expectation:
\begin{align}
\Zhal = \ind_{\{k = \kexpl\}}, \quad \phal := \Pr[\Zhal = 1\mid \ledger_k]
\end{align}
In words, $\phal$ captures the  agent's suspicion that the ledger $\ledger_k$ they are shown at episode $k$ was hallucinated, and not the honest ledger with the true rewards. First we show that if this probability is sufficiently small, then any Bayes-Greedy policy lies in $\Pi$:
\begin{claim}\label{claim:phal_gap} Fix a ledger $\ledger$ satisfying $\phal < \gapcan[\Pi \mid \ledger_k ]/2H$. Then any maximizer of $\Exp[\valuef{\pi}{\modst} \mid  \ledger_k = \ledger]$ lies in $\Pi$.
\end{claim}
\begin{proof}[Proof of \Cref{claim:phal_gap}] Fix two policies $\pi_1 \in \Pi,\pi_2 \in \Pitotal \setminus \Pi$. Fix an abitrary ledger $\ledger$ in the support of $\ledger_k$; it will be clearner to reason about conditionals $\{\ledger_k = \ledger\}$. It suffices to show that for arbitrary $\ledger$, if $\phal(\ledger) := \Pr[\Zhal = 1\mid \ledger_k = \ledger] <  \gapcan[\Pi \mid \ledger]/2H$, then
\begin{align*}
\Exp[\valuef{\pi_1}{\modst} - \valuef{\pi_2}{\modst} \mid \ledger_k = \ledger] > 0.
\end{align*}
To this end, we lower bound the above difference
\begin{align*}
&\Exp[\valuef{\pi_1}{\modst} - \valuef{\pi_2}{\modst} \mid \ledger_k = \ledger]\\
&\quad= \Exp[\ind_{\{\Zhal = 1\}} \left(\valuef{\pi_1}{\modst} - \valuef{\pi_2}{\modst}\right) \mid \ledger_k = \ledger]\\
&\qquad+ \Exp[\ind_{\{\Zhal = 0\}} \left(\valuef{\pi_1}{\modst} - \valuef{\pi_2}{\modst}\right) \mid \ledger_k = \ledger]\\
&\overset{(i)}{\ge}  \Exp[\ind_{\{\Zhal = 0\}} \left(\valuef{\pi_1}{\modst} - \valuef{\pi_2}{\modst}\right) \mid  \ledger_k = \ledger] - H\phal(\ledger)\\
&\overset{(ii)}{=}   (1-\phal)\Exp[ \valuef{\pi_1}{\modst} - \valuef{\pi_2}{\modst} \mid \ledhonl = \ledger] - H\phal(\ledger)\\
&\overset{(iii)}{=}   (1-\phal)\gapcan[ \Pi \mid \ledger] - H\phal(\ledger),
\end{align*}
where $(i)$ uses that values are upper bounded by $H$, and $(ii)$ uses that $\Zhal$ is selected using independent randomness, and when $\Zhal = 0$, the revealed ledger is the honest ledger: $\ledger_k= \ledhonl$. Equality $(iii)$ is precisely the definition of the canonical gap, \Cref{defn:canonical_gap}
Now, since the honest ledger satisfies the data hygiene guarantee (\Cref{lem:data_hygiene}), we obtain
\begin{align*}
\Exp[\valuef{\pi_1}{\modst} - \valuef{\pi_2}{\modst}\mid \ledhonl = \ledger] &= \Expcan[\valuef{\pi_1}{\modst} - \valuef{\pi_2}{\modst} \mid \ledger],
\end{align*}
 Hence, combining the two displays, and using $\gapcan \le H$ (since all values are bounded by $H$),
\begin{align*}
\Exp[\valuef{\pi_1}{\modst} - \valuef{\pi_2}{\modst} \mid  \ledger_k = \ledger] &\ge (1 - \phal)\gapcan[ \Pi \mid \ledger] - \phal(\ledger) H \\
&\ge \gapcan[ \Pi \mid \ledger] - 2\phal(\ledger) H. \qquad\qedhere
\end{align*}
\end{proof}
To apply \Cref{claim:phal_gap}, we need to further analyze the term $\phal$. To do so, we need the following intermediate claim, which says that the conditional distribution of the honest ledger on the event that model is in the punishing set coincides with the distribution of the conditional ledger:
\newcommand{\ledcs}{\ledger_{\mathrm{cens}}}



\begin{claim}\label{claim:ledhonl_cannonical} The following equality of distributions holds:
\begin{align*}
\Pr[\ledhonl = \cdot \mid \EvPun, \ledcensl ] = \Pr[\ledhall = \cdot \mid \ledcensl ]
\end{align*}
\end{claim}
\begin{proof}
Let $\calD_{1}$ denote the joint distribution of $(\ledhonl,\modst)$ conditioned on $ \EvPun $ and $\ledcensl$, and let $\calD_{2}$ denote the joint distribution of $(\ledhall,\modhall)$ conditioned on $\ledcensl$. By marginalizing, it suffices to show that $\calD_{1} = \calD_{2}$.

First, observe that since $\modhall \sim \Pr[ \modst \in \cdot \mid \ledhall,  \EvPun]$, $\modst$ and $\modhall$ have the same marginal distribution under $\calD_1$ and $\calD_2$. Now, consider the distribution of $\ledhonl \mid \modst$ and $\ledhall \mid \modhall $ under $\calD_1,\calD_2$, respectively. The first conditional is equal to the distribution of $\ledhonl \mid \modst, \ledcensl$, and the second $\ledhonl \mid \modhall, \ledcensl$. Since all transition data in $\ledhonl$ and $\ledhall$ are determined by $\ledcensl$, it suffices to show that the rewards in both ledgers have the same distribution.

Similar to the proof of the hygiene guarantee (\Cref{lem:data_hygiene}), we observe that the data in the censored ledger $\ledcensl$ are independent of the rewards in $\ledhonl$. Hence, the rewards $r\kh$ for each triple $(x\kh,a\kh,h)$ that appears in each constituent trajectory $\traj_k$ in $\ledcensl$ are independent draws from the corresponding reward distribution under $\modst$ - namely, $r\kh\sim \mathcal{R}_{\modst}(x\kh,a\kh,h)$. Moreover \begin{comment}, recall from \Cref{eq:hallucinate_rewards}, that\end{comment} the rewards in the hallucinated ledger are constructed in the same way, but with $\mathcal{R}_{\modst}$ replaced with $\mathcal{R}_{\modhall}$. Hence, equality of distribution follows.
\end{proof}
\Cref{claim:ledhonl_cannonical} forms the corner cornerstone of our upper bound on $\phal$ (that is, upper bound on the agents belief that the revealed ledger arose from hallucination):
\begin{claim}\label{claim:phal_claim} Setting  $p_0 := 1/\nphase$, the following holds for any realization of $\ledger_k$:
\begin{align*}
\phal \le \frac{1 }{1 + \frac{(1-p_0)}{p_0}\Prcan[ \EvPun \mid \ledcensl] }.
\end{align*}
\end{claim}
\begin{proof}[Proof of \Cref{claim:phal_claim}] With $p_0 := 1/\nphase$, the marginal of $\Zhal$ satisfies $\Pr[\Zhal = 1] = p_0$. Fix a ledger $\ledger$ in the support of $\ledger_k$, and again set $\phal(\ledger) := \Pr[\Zhal = 1\mid \ledger_k = \ledger]$.
\begin{align}
\phal(\ledger) &= \Pr[\Zhal = 1 \mid  \ledger_k = \ledger ]\\
&= \frac{\Pr[\Zhal = 1 \text{ and }  \ledger_k = \ledger ]}{\Pr[\ledger_k = \ledger]} \nonumber\\
&= \frac{\Pr[\ledger_k  = \ledger \text{ and } \Zhal = 1 \mid  ]}{\Pr[\ledger_k = \ledger \text{ and } \Zhal = 1] + \Pr[\ledger_k = \ledger \text{ and } \Zhal = 0 ] } \nonumber\\
&\overset{(i)}{=} \frac{p_0\Pr[\ledhall = \ledger] }{p_0\Pr[\ledhall = \ledger] + (1-p_0)\Pr[\ledhonl = \ledger] }, \nonumber\\
&\overset{(ii)}{=} \frac{1 }{1 + \frac{(1-p_0)}{p_0}\cdot \frac{\Pr[\ledhonl = \ledger]}{\Pr[\ledhall = \ledger]} }, \label{eq:phal_first_bound}
\end{align}
whre $(i)$ uses that $\Pr[\ledger_k  = \ledger \text{ and } \Zhal = 1 \mid  ] = \Pr[\ledger_k  = \ledger \mid \Zhal = 1 ] \Pr[\Zhal = 1] = p_0 \Pr[\ledger_k  = \ledger \mid \Zhal = 1 ] = \Pr[\ledhall = \ledger]$, since $\Zhal$ is independent of all observed trajectories and determines whether the revealed trajectoried $\ledger_k$ is hallucinated or honest (and a similar computation for when $\Zhal = 0$). In $(ii)$, we have assumed $\Pr[\ledhall = \ledger]  > 0$, for otherwise the upper bound on $\phal$ is immediate from the previous line.


It remains to lower bound the ratio $\frac{\Pr[\ledhonl = \ledger]}{\Pr[\ledhall = \ledger]}$, again assuming the denominator is non-zero.
We bound bound
\begin{align*}
\frac{\Pr[\ledhonl = \ledger]}{\Pr[\ledhall = \ledger]} &= \frac{\Pr[\ledhonl = \ledger, \ledcensl = \ledcs]}{\Pr[\ledhall = \ledger, \ledcensl = \ledcs]}\\
&= \frac{\Pr[\ledhonl = \ledger \mid \ledcensl = \ledcs]}{\Pr[\ledhall = \ledger \mid \ledcensl = \ledcs]}\\
&\ge \frac{\Pr[\ledhonl = \ledger, \EvPun \mid \ledcensl = \ledcs]}{\Pr[\ledhall = \ledger \mid \ledcensl = \ledcs]}\\
&= \Pr[  \EvPun \mid \ledcensl = \ledcs] \cdot  \frac{\Pr[\ledhonl = \ledger \mid \EvPun, \ledcensl = \ledcs]}{\Pr[\ledhall = \ledger \mid \ledcensl = \ledcs]}
\end{align*}

 From \Cref{claim:ledhonl_cannonical}, it follows that $\Pr[  \EvPun \mid \ledcensl = \ledcs]  = \Prcan[ \EvPun \mid \ledcensl = \ledcs]$, and that
\begin{align*}
\frac{\Pr[\ledhonl = \ledger \mid \EvPun, \ledcensl = \ledcs]}{\Pr[\ledhall = \ledger \mid \ledcensl = \ledcs]} = 1.
\end{align*}
Thus, $\frac{\Pr[\ledhonl = \ledger]}{\Pr[\ledhall = \ledger]} \ge \Pr[ \EvPun \mid \ledcensl = \ledcs]$. The desired bound follows.
\end{proof}
\Cref{prop:mdp_hh} now follows from combining the above claims.
\begin{proof}[Proof of \Cref{prop:mdp_hh}]
Introduce the shorthand $q:= \Prcan[ \EvPun \mid \ledcensl]$, and recall $p_0 = 1/\nphase$. From \Cref{eq:hh_condition}, $p_0 \le p_{\star} := q \cdot \gapcan[\Pi \mid \ledger_k]/3H$.  From \Cref{claim:phal_claim}, we have the upper bound
\begin{align}
\phal \le \frac{1}{1 + q(1-p_0)/p_0} \label{eq:phal_fin_bound}.
\end{align}
Hence, \Cref{claim:phal_gap} ensures that all Bayes-greedy policies $\pi_k$ lie in $\Pi$ as soon as we can ensure that the RHS of \Cref{eq:phal_fin_bound} is strictly less than $\gapcan[\Pi \mid \ledger_k]/2H$. To this end, note that for $p_0 \le p_{\star}$ for $p_{\star}$ above, the bounds $\gapcan \le H$ and $q \le 1$ entail $p_0 \le 1/3$. Moreover, $p_0 \mapsto \frac{1}{1 + q(1-p_0)/p_0}$ is decreasing in $p_0$. Thus,
\begin{align*}
\frac{1}{1 + q(1-p_0)/p_0} \le \frac{1}{1 + q(1-p_\star)/p_\star} = \frac{1}{1 + \frac{2q}{3 q  \gapcan[\Pi \mid \ledger_k]/3H}} = \frac{1}{1 + \frac{2H}{\gapcan}} < \frac{\gapcan[\Pi \mid \ledger_k]}{2H}. \quad\qedhere
\end{align*}
\end{proof}




\subsection{Proof of \Cref{cor:mdp_hh}}
By assuming \Cref{eq:HH-stronger-condition},
\begin{align*}
\frac{1}{\nphase} \le \frac{(\Delta/2) \cdot \Prcan[ \EvPun \mid \ledcensl]}{3H}.
\end{align*}
Hence, by \Cref{prop:mdp_hh}, it holds that, whenever $\gapcan[\Pi \mid \ledhall] \ge \Delta/2$, $\pi_k \in \Pi$ for $k = \kexpl$. Thus, it suffices to show that  $\Prsimhh\left[\gapcan[\Pi \mid \ledhall] \ge \Delta/2 \mid \ledcensl\right] \ge \frac{\Delta}{2H}$. To this end, we observe that $\gapcan[\Pi \mid \ledhall] \in [-H,H]$ with probability $1$ over the draw of $\ledhall$. Hence,
\begin{align*}
\Delta &\le \Expsimhh\left[\gapcan[\Pi \mid \ledhall] \mid \ledcensl\right]\\
&\le \frac{\Delta}{2} +  H \Prsimhh\left[\gapcan[\Pi \mid \ledhall] \ge \Delta/2 \mid \ledcensl\right]. \qquad\qed
\end{align*}



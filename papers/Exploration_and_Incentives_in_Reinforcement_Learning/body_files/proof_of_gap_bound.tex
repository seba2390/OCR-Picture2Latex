%!TEX root = ../main-arxiv.tex

Throughout, we define
\begin{align}
&\calU_{\ell} := \{(x,a,h) \in [S] \times [A] \times [H] : N_{\ell}(x,a,h) < \nlearn\}, ~ \label{eq:calU_def}\\
&\text{ where } N_{\ell}(x,a,h) := \textstyle\sum_{k \in \calK_{\ell}}^{\ell-1} \I\{(x,a,h) \in \traj_{k}\} \nn.
\end{align}

\subsection{Proof of \Cref{lemma:gap_bound_prob} \label{sec:lemma:gap_bound_prob}}

Recall from \Cref{ssec:sketch:lemma:gap_bound_prob} the following notation:
\begin{itemize}
\item $\Prmucan[\cdot \mid \cdot]$ and $\Expmucan[\cdot \mid \cdot]$ to denote cannonical expectation distribution, which is viewed as measure over an abstract model random variable $\modvarhat$; e.g. $\Prmucan[\modvarhat \in \cdot \mid \ledger] = \Prcan[\modst \in \cdot  \mid \ledger]$.
\end{itemize}
Further, we define the \emph{random measures} $\Exphall$ and $\Prhall$:
\begin{align}
\Exphall\sbr{f(\modvarhat)}
    &:= \Expop\left[\Expmucan[f(\modvarhat) \mid \ledhall] \mid \ledcensl\right],\nonumber\\
\Prhall\sbr{\modvarhat \in \cdot}
    &:= \Expop\left[\Prmucan[\modvarhat \in \cdot \mid \ledhall] \mid \ledcensl\right]   \label{eq:hallucination_expectations},
\end{align}
where the outer expectation  the distribution of the hallucinated ledger $\ledhall$ conditioned on the totally censored ledger $\ledcensl$, and the inner expectation over the cannonical distribution given the hallucinated ledger. Note that $\Exphall$ and $\Prhall$ are functions of $\ledcensl$, though this is made
Reiterating the proof sketch, our aim is to ensure that
\begin{itemize}
\item[(a)] For highly visited triples $\xah \in \calU_{\ell}^c$, $\modvarhat$ has small rewards $\sfr_{\modvarhat}\xah$.
\item[(b)] For highly visited triples $\xah \in \calU_{\ell}^c$, the transition probabilities $\sfp_{\modvarhat}(\cdot \mid x,a,h)$ are close to those for the true model, $\sfp_{\modst}(\cdot \mid x,a,h)$ (and a similar closeness holds for the initial state distributions).
\end{itemize}


We assign the following definitions to the properties (a) - low reward,  and (b) - accurate transitions - described above.\footnote{definitions are stated for the \emph{complements} of subsets $\calU$ to remain consistent with how the definitions are used}.
\begin{definition}[Punished] Given $\calU \subset [S] \times [A] \times [H]$, we say that a model $\model$ is $\varepsilon$-punished on $\calU^c$, for all $\xah \in \calU^c$, $\sfr_{\model}\xah \le \varepsilon$.
\end{definition}
\begin{restatable}[Transition-Similar]{definition}{defnsimilar} \label{defn:similarity_transition} Let $\|\cdot\|_{\ell_1}$ denote the $\ell_1$-distance between probability distributions.  Given $\calU \subset [S] \times [A] \times [H]$, we say two models $(\model,\modst)$ are $\varepsilon$-transition-similar on $\calU^c$ if (i) $\|\sfp_{\model}(\cdot \mid 0 ) - \sfp_{\modst}(\cdot \mid 0)\|_{\ell_1} \le \varepsilon $ \emph{(closeness of initial state distribution)}, and (ii) for each $(x,a,h) \in \calU^c$, $\|\sfp_{\model}(\cdot \mid x,a,h) - \sfp_{\modst}(\cdot\mid x,a,h)\|_{\ell_1} \le \varepsilon$ \emph{(closeness of transitions on $\calU^c$)}.
\end{restatable}
 Note that transition-similarity concerns \emph{transition probabilities but \textbf{not} rewards}.
The various tolerances $\varepsilon$ for which we show these properties hold is in part determined by randomness in the transitions and rewards; these up up being quantified by terms arising from Azuma-Hoeffding's inequality:
\begin{definition}[Error Bounds]\label{defn:error_bounds} The reward and transition error bounds are
\begin{align}
\textstyle \epsr := \sqrt{ \frac{2\log(1/\delta_0)}{\nlearn}}, \quad \text{ and } \epsp:= 2\sqrt{ \frac{2(S\log(5) + \log(1/\delta_0))}{\nlearn}}, \quad \text{where } \delta_0 := \frac{\deltafail \cdot \qpunish \cdot \epspunish}{4SAH}.  \label{eq:delta_not}
\end{align}
\end{definition}
Here, $\epsr$ arises form the the two-sided concentration of the first $\nlearn$ samples from rewards at triple $\xah$ collected during the hallucination episodes; $\epsp$ reflects concentration of transitions in the $\ell_1$ norm, incurring an extra $S$ factor due to a covering argument (see \Cref{lem:conc_bounds} for details). Using these error bounds, we define the set of models:
\begin{definition}[Good Models] We define the \emph{good model set}, $\modgoodl \subset \modtotal$, as
\begin{align}
\modgoodl := \left\{\model: \begin{matrix} &\model \text{ is } (\epspunish + 2\epsr) \text{ punished  on } \calU_{\ell}^c \\
&(\model,\modst) \text{ are } 2\epsp \text{ transition-similar on } \calU_{\ell}^c\end{matrix}   \right\}. \label{eq:modgoodl_a}
\end{align}
We call models $\model \in \modgoodl$ ``good models''.
\end{definition}
Note that the above definition admits two interpretations: (a) a frequentist interpretation, where $\modgoodl$ is a fixed set depending on the unknown parameter $\modst$, and (b) a Bayesian interpretation, where $\modgoodl$ is a random set depending on the random model $\modst$.

The models in the $\modgoodl$ satisfy two key properties, for all sufficiently visited triples $\xah \in \calU_{\ell}^c$. First, the transition probabilities are $2\epsp$-close to those of the true model $\modst$, and second, the rewards from those triples are at most $\epspunish$, pluss a  $2\epsr$ error term. Crucially, the cannonical posterior given $\ledhall$, $\Prhall$, concentrates on $\modgoodl$.
\begin{lemma}\label{lem:hallucination_good_event}
For any phase $\ell > \nlearn$, the following event holds with probability $ 1- \deltafail$:
\begin{align*}
\Egoodl := \{\Prhall\left[ \modvarhat \in \modgoodl\right]\ge 1 - \epspunish\}
\end{align*}
The randomness in $\Egoodl $ is over the randomness in $\modst$ (determining $\modgoodl$) and the censored ledger $\ledcensl$ (determining $\Prhall[\cdot]$).
\end{lemma}
\begin{proof}[Proof Sketch] The proof builds on the Bayesian Chernoff bounds due to \citep{Selke-PoIE-ec21}. First, we define estimators $\theta_{\sfp}$ and $\theta_r$ of the empirical transitions and rewards of the true model $\modst$, which we show concentrate around the true transitions and rewards for sufficiently visited triples $\xah \in \calU^c$. We argue that this implies that the posteriors under $\Prhall$ must also concentrate around the truth. However, we modify \citep{Selke-PoIE-ec21} to adress that ledger $\ledhall$ with respect to which the posterior $\Prhall$ is defined is based on a samples from hallucinated model $\modhall$. This model is not an exact draw from the true posterior given $\ledcensl$ (which would be the analogue to \citep{Selke-PoIE-ec21}), but a  posterior which \emph restrict to $ \EvPun$ (that is, theevent that all rewards on $\xah \in \calU_{\ell}^c$ are at most $\epsilon$); refer back to \Cref{eq:hallucination_expectations} for the formal definition of $\Prhall$.

This difference from  \citep{Selke-PoIE-ec21} has two implications: first, we must account for the minimal probably that $\EvPun$ occurs given the censored ledger, which incurs a factor of $\qpunish$ (\Cref{eq:qpun-defn}) in our selection of $\delta_0$ . Second, this restriction allows us to argue that the posterior $\modvarhat \sim \Prhall$ is $\epspunish + 2\epsr$-punished, where the  $\epspunish$ is from restriction to the punishing class, and $2\epsr$ is from the Bayesian Chernoff. Combining with a union bound for all triples $\xah \in \calU^c_{\ell}$, and applying Bayesian Chernoff to the appropriate transitions and initial state distribution to verify $2\epsp$transition-similarity, we conclude the argument. The full proof is given in  \Cref{sec:proof_hall_good_event}.
\end{proof}
Next, let us use the punished and transition-similarity properties of $\modgoodl$ to control obtain the bound in \Cref{lemma:gap_bound_prob}. Our key technical tool is relating certain cumulative rewards between transition-similar models, whose proof is in the spirit of \cite{kearns2002near}:

\newcommand{\Evisitnol}{\scrE_{\calU}}
\newcommand{\omegast}{\omega_{\star}}
\begin{lemma}[Simulation Lemma]\label{lem:visitation_comparison_general}
Fix $\calU \subset [S] \times [A] \times [H]$ and $\varepsilon \ge 0$, and let $(\model,\modst)$ be two models which are $\varepsilon$-transition-similar on $\calU^c$.  For $h \in [H]$, introduce the events $\scrE_h := \{(\bmx_\tau,\bma_{\tau},\tau) \in \calU^c,~ \forall \tau < h\}$.\footnote{These events are measurable under the probability measures of the form $\sfP^{\pi}_{\model}[\cdot]$. } Then, for any reward function $\rtil: [S] \times [A] \times [H] \to [0,1]$, and policy $\pi \in \Pimarkov$,
\begin{align*}
\left|\sfE^{\pi}_{\model}\left[\sum_{h=1}^H \rtil(\bmx_h,\bma_h,h) \ind_{\{\scrE_h\}}\right] - \sfE^{\pi}_{\modst}\left[\sum_{h=1}^H\rtil(\bmx_h,\bma_h,h) \ind_{\{\scrE_h\}}\right]\right| \le \binom{H}{2}\varepsilon.
\end{align*}
In particular, defining $\Evisitnol := \{\exists h : (\bmx_h,\bma_{h},h) \in \calU\}$, then $|\sfP^{\pi}_{\model}\left[\Evisitnol \right] - \sfP^{\pi}_{\modst}\left[\Evisitnol \right]| \le \binom{H}{2}\varepsilon$
\end{lemma}
The above lemma is proven in \Cref{proof:visitation_comparison_general}, and its purpose is to relate visitations under good models $\model \in \modgoodl$ to visitations under the true model $\modst$.

We apply the bound in two ways. First, we upper bound on the value of policies under good models in terms of the probability of visiting under-visited triples $\xah \in \calU_{\ell}$:
\begin{claim}[Value Upper Bound for Good Models]\label{claim:value_upper_bound} For any good $\model \in \modgoodl$,
\begin{align*}
\valuef{\pi}{\model} &\le H \Pr^{\pi}_{\model}\left[ \Evisit \right] + H (2\epsr + \epspunish) \tag*{(punished rewards)}\\
&\le H \Pr^{\pi}_{\modst}\left[ \Evisit \right] + H (2\epsr + \epspunish) + H(H-1)\epsp \tag*{(similarity \& punished rewards)}
\end{align*}
In particular for $\pi \in \Pimarkov \setminus \Pi_{\ell}$, we have
\begin{align}
\valuef{\pi}{\model} \le H \rho_0 + H (2\epsr + \epspunish) + H(H-1)\epsp. \label{eq:value_bound_on_Pi_l_c}
\end{align}
\end{claim}
The proof is direct, and given in \Cref{sec:proof_of_prob_claims}, along with the proofs of the subsequent four claims. Notably, \Cref{eq:value_bound_on_Pi_l_c} upper bounds the value of policies  $\pi \in \Pimarkov \setminus \Pi_{\ell}$; that is, for good models, policies which do not explore $\calU_{\ell}$ do \emph{not} have high value. Next, we establish a lower bound on the policy values. To do so, we shall opt for the following representation of the exploration probability $\sfP_{\modst}^{\pi}[\Evisit],$:
\begin{claim}\label{claim:omega_star}Define $\omegast^\pi\xah :=  \sfP_{\modst}^{\pi}[(\bmx_h,\bma_{h}) = (x,a) \text{ and } (\bmx_\tau,\bma_{\tau},\tau) \in \calU_{\ell}^c, \quad \forall \tau < h]$ as the probability that the MDP visits $\xah$, but does not leave $\calU_\ell^c$ before step $h$. Then,
\begin{align*}
\sum_{\xah \in \calU_\ell}\omegast^\pi\xah = \sfP_{\modst}^{\pi}[\Evisit],
\end{align*}
Moreover, if $\rho \ge \rho_0$ and $\calU_{\ell} \cap \reach_{\rho}(\modst)$ is \emph{nonempty}, then there exists a policy $\pi \in \Pi_{\ell}$ for which 
$$\sum_{\xah \in \calU_\ell}\omegast^\pi\xah \ge \rho.$$
\end{claim}
The first part of the claim uses that the events in the definition of $\omegast^\pi\xah$ over $\xah \in \calU_{\ell}$ give a disjoint decomposition of the event $\Evisit$; the second par uses the first identity, together with the fact that if there $\calU_{\ell} \cap \reach_{\rho}(\modst)$ is non-empty, then there is policy $\pi$ which reaches a triple $\xah \in \calU_{\ell}$ with probabilty at least $\rho$; this policy therefore has $\sfP_{\modst}^{\pi}[\Evisit] \ge \rho \ge \rho_0$.  We combine \Cref{claim:omega_star} with the following value lower bound in terms of $\omegast$ and rewards on $\xah \in \calU_\ell$:
\begin{claim}[Value Lower Bound for Good Models] For any good model $\model \in \modgoodl$, \label{claim:value_lower_bound}
\begin{align*}
\valuef{\pi}{\model}  \ge \sum_{(x,a,h) \in \calU_{\ell}} \sfr_{\model}\xah \cdot \omegast^\pi\xah - H(H-1)\epsp.
\end{align*}
\end{claim}
In particular, from \Cref{claim:omega_star}, if $\calU_{\ell} \cap \reach_{\rho}(\modst)$, then there exists a policy $\pi \in \Pi_{\ell}$ for which $\valuef{\pi}{\model}   \ge \rho \min_{\xah \in \calU_{\ell}}  \sfr_{\model}\xah - H(H-1)\epsp$. However, using this inequality directly forces us to consider the minimal reward (on $\calU_{\ell}$) on each good model $\model \in \modst$.

Instead, by using the weighting (which depends only on the \emph{true} model $\modst$), we can commpute the lower bound in \Cref{claim:value_lower_bound} with expectations, permitting a weaker condition on the prior. Specifically, combining the above two claims, together with the fact that $\Pr^{\pi_2}_{\modst}\left[ \Evisit \right] \le \rho_0$ for $\pi_2 \in \Pi_{\ell}^c$ and the bound $\epsr \le \epsp$ by definition, we achieve the following synthesis:
\begin{claim}[Gap for Good Models]\label{claim:value_diff} Let $\model \in \modgoodl$, and $\pi \in \Pimarkov$. Then,
\begin{align*}
\valuef{\pi}{\model} - \max_{\pi_2 \in \Pimarkov \setminus \Pi_{\ell}}\valuef{\pi_2}{\model}  \ge \sum_{(x,a,h) \in \calU_{\ell}} \sfr_{\model}\xah \cdot \omegast^{\pi}\xah -H \left(\rho_0 + \epspunish  + 2H\epsp\right).
\end{align*}
\end{claim}
Now recall from \Cref{lem:hallucination_good_event} that, on the high-probability good event $\Egoodl$, the model $\modvarhat$ sampled from the posterior lies in the good set $\modgoodl$ with $(1-\epspunish)$-probability. Hence, we can convert \Cref{claim:value_diff} into the following guarantee in expectation under $\Exphall$:
\begin{claim}[Gap under Hallucination]\label{claim:value_diff_expectation}
Set $\varepsilon_0 :=  H \left(\rho_0 + 3\epspunish  + 2H\epsp\right)$.  Then, if $\Egoodl$ holds,
\begin{align*}
\Exphall[\valuef{\pi}{\modvarhat} - \max_{\pi' \in  \Pi^c} \valuef{\pi'}{\modvarhat} ] &\ge \textstyle\sum_{(x,a,h) \in \calU_{\ell}} \Exphall[\sfr_{\modvarhat}\xah] \cdot \omegast^{\pi}\xah  - \varepsilon_0.
\end{align*}
In particular, \Cref{claim:omega_star} ensures that if $\calU_{\ell} \cap \reach_{\rho}(\modst)$ is nonempty,
\begin{align}
\max_{\pi \in \Pi_{\ell}}\Exphall[\valuef{\pi}{\modvarhat} - \max_{\pi' \in  \Pi^c} \valuef{\pi'}{\modvarhat} ]\ge  \rho \cdot\min_{\xah \in \calU_{\ell}} \Exphall[\sfr_{\modvarhat}\xah] -  \varepsilon_0.  \label{eq:RHS_value_diff_expecation}
\end{align}
\end{claim}

We are now ready to conclude the proof of \Cref{lemma:gap_bound_prob}:
\begin{proof}[Concluding the proof of \Cref{lemma:gap_bound_prob}] It suffices to establish that the RHS of \Cref{eq:RHS_value_diff_expecation} is at least $\Delta_0 := \rho \ralt/2$, where  $\ralt$ was defined as in \Cref{eq:ralt-defn}. Then,
\begin{align*}
\text{(RHS of \Cref{eq:RHS_value_diff_expecation})} \ge \ralt \rho -  \varepsilon_0 = 2\Delta_0 - H \left(\rho_0 + 3\epspunish  + 2H\epsp\right),
\end{align*}
where we subsituted the definitions of $\varepsilon_0$ and $\Delta_0$ in above. Under the assumptions of the lemma, we immediately have $H (\rho_0 + 3\epspunish) \le 2\Delta_0/3$. Hence, it suffices to establish that, for our given condition on $\nlearn$, $2H^2\epsp \le \Delta_0/3$. Recall that $\epsp:= 2\sqrt{ \frac{2(S\log(5) + \log(1/\delta_0))}{\nlearn}}$. Then, we require $\epsp^2 \le \Delta_0^2/12 H^4$, so that it suffices that $\nlearn \ge \frac{96 H^4((S\log(5) + \log(1/\delta_0))}{\Delta_0}^2$.
\end{proof}


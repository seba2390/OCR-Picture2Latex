\section{User Study}
\label{sec:user-study}

We designed and implemented \deuce{} with the goal to incorporate structured
editing within a text-based program editor. In this section, we describe a user
study designed to measure the degree to which we were successful.

Besides the two novel mechanisms in our user interface design---structural
\maybecode{} selection and context-sensitive preview menus---that we wish to
evaluate, there are several additional factors at play. First, many users may
not have extensive experience with functional programming languages, especially
the custom \little{} language supported in our
implementation. Second, our implementation provides some familiar
transformations but some---particularly those involving target positions---are
not. Furthermore, some users may prefer to use text-editing rather than structured
edits, even when the latter can be used. These factors make it hard to perform a
direct comparison between our implementation of \deuce{} and an existing system,
such as Eclipse.

To mitigate these factors, we designed a study that compared \deuce{} with a
``baseline'' version of the system, with features designed to emulate the
traditional text-select-based interface described in \autoref{sec:intro}. We
then designed tasks, to be completed in both versions and \emph{without}
text-edits, to measure the effect of the new \deuce{} user interface features
compared to the baseline ones. Below, we describe the different configurations
of our system, our study procedures, and our results.

\subsection{System Configurations}

\newcommand{\startInteractionList}{}
\newcommand{\interactionItem}[2]{\paragraph{(#1) #2}}
\newcommand{\finishInteractionList}{}

\newcommand{\interactionName}[1]{Interaction {#1}}



Recall that tools may be \verb+Active+ or \verb+NotYetActive+ based on one or
more selected items and target positions (\autoref{fig:code-tool-interface}).

\paraheadNoDot{Traditional Mode (``Text-Select Mode'')}

To form the traditional mode of the tool, which we called Text-Select Mode in
the user study materials, we implemented four interactions separate from the
workflow described in \autoref{sec:overview} and \autoref{sec:user-interface} to
invoke code tools.

\startInteractionList{}

\interactionItem{A}{Code Tools Menu}

The editor displays a Code Tools menu at the top of the window with a list
of all transformations available in the system; this menu is akin to the Source
and Refactor menus in Eclipse. The user selects a tool from this menu without
first selecting anything in the program. Then, the editor displays a Tool
Configuration Panel that displays tool-specific instructions. Tool Configuration
Panels, which appear in all four interactions of Traditional Mode,
are discussed below.

\interactionItem{B}{Text-Select Single Argument + Code Tools Menu}

This interaction is like \interactionName{A}, except that the user first
text-selects an item or target in the code. Like Eclipse, text-selecting
requires the entire item to be selected, possibly with trailing or leading
whitespace. Our implementation provides more generous
text-selection mechanisms (\eg{} largest containing expression, smallest
surrounding expression), but the stricter version is used in the study because
it is more similar to existing approaches~\citep{Murphy-Hill-ICSE2008}. Also like
Eclipse, all tools are displayed and enabled in the Code Tools menu, even if the
tool is \verb+Inactive+ based on the selection.

\interactionItem{C}{Text-Select Single Argument + Right-Click Menu}

After first text-selecting an item, as in \interactionName{B}, the user right-clicks
to trigger a pop-up menu that displays \emph{only} plausible tools
(\verb+Active+ or \verb+NotYetActive+).
A similar workflow is provided by Eclipse.

\begin{wrapfigure}{r}{0pt}
\includegraphics[scale=\lambdaScreenshotScale]{red-square-right-click.png}
\end{wrapfigure}
Returning to Example 1 from \autoref{sec:overview},
the screenshot on the right shows the right-click menu after
text-selecting the \verb+120+ constant.
By comparison, notice how this right-click menu displays more tools
(\verb+NotYetActive+ tools in addition to \verb+Active+ ones).
After the text selection is made, the editor draws an
orange box (as with \deuce{} widgets) to identify the selection.

\interactionItem{D}{Cursor-Select Single Argument + Right-Click Menu}

For atomic code items (\ie{} constants and variables), the user implicitly
selects the item by right-clicking on the token (rather than text-selecting it)
to trigger the right-click menu, as in \interactionName{C}. Again, a similar
workflow is provided by Eclipse.

\finishInteractionList{}

\paragraph{Tool Configuration Panels}


\begin{wrapfigure}{r}{0pt}
\includegraphics[scale=\lambdaScreenshotScale]{red-square-config-panel-2-with-target.png}
\end{wrapfigure}
Each of the four interactions above trigger Tool Configuration Panels, which
display the \verb+requirements+ string that explains how to invoke the tool.
The user selects any additional arguments by hovering over and clicking
structural selection widgets. That is, structural selection widgets are
\emph{not} accessible to make the primary selection, but they \emph{are} used to
make all remaining selections in a Tool Configuration Panel.
The screenshot above shows the Configuration Panel after text-selecting
\verb+120+, as above, and then selecting \verb+80+ and a target position using
structural selection. Because the tool requirements are satisfied,
the panel displays the list of \verb+Result+s,
each of which can be hovered to preview the change before selecting it.


\paraheadNoDot{\deuce{} Mode (``Box-Select Mode'')}

This configuration, called Box-Select Mode in the user study materials, isolates
the new \deuce{} features.
%%
To review, the user holds down the Shift key, then hovers over and clicks one or more
structural \maybecode{} selection widgets. When at least one widget is
selected, the pop-up preview menu displays the list of \verb+Active+ tools.

There is no Code Tools menu at the top of the editor in this mode, even
though the ``full'' version of our tool (not used by participants in the study)
does; the list of tool names and descriptions in Tool Configuration Panels (which
are \emph{not} accessible in \deuce{} Mode) can help understand unfamiliar
transformations.

\parahead{Combined Mode}

Our last configuration combines Traditional and \deuce{} Modes, with all
interactions described above.

\subsection{Questions and Procedures}

We sought to address several questions:

\begin{itemize}

\item Is either mode more effective for (a) completing tasks, (b) rapid editing, or (c) achieving more with fewer transforms?
\item Is either mode preferred by users? In which cases?

\end{itemize}

\noindent
To answer these questions, we designed the following IRB-approved, controlled
user study with \numUsers{} undergraduate and graduate students from the
University of Chicago.
%
We recruited users by sending emails to public mailing lists, offering
a monetary incentive of \$50 for participating in the two-hour study. Prior
experience with functional programming or \sns{} was not required. Each user
attended an individual session and was given the option to use the laptop and
mouse provided by us or their own devices.

The primary components of the study included a tutorial portion followed by a
tasks portion. We configured a pared-down version of the system that turned off
all \sns{} features unrelated to the interactions being studied. The tutorial
and tasks were set up as a self-guided progression of steps through the tool, to
be completed at the user's own pace.
%
In the description of the tutorial and tasks below, all random choices were
made independently of other choices, as well as across users.

Our system logged user events to analyze the tutorial and tasks. We also
recorded video of the users performing the tasks, for manual inspection
in situations where the log information was insufficient or
more difficult to process. Besides helping to get started and correct minor
issues unrelated to \deuce{}, the user study proctor did not answer any
questions about \deuce{} or the tasks.
%
To wrap up, users answered questions about their programming background and
experience using \deuce{} in an exit survey.


\input{fig-tasks}

\parahead{Tutorial}

The first part of the tutorial introduced ordinary text-based programming in
\little{}, emphasizing that the syntax would not be too important for subsequent
tasks.

The majority of the tutorial introduced the code tools using both
Traditional and \deuce{} Modes.
%
The first tool introduced---\codeTool{Rename Variable}, a familiar tool to
many---was explained using all five interaction modes. But because the four interactions
in Traditional Mode are largely similar, all subsequent tools introduced
in the tutorial had only one set of instructions for Traditional Mode. For all
tools introduced, a random choice was used to determine whether to explain
Traditional or \deuce{} Mode first. In total, 10 of the 22 code tools in
our implementation were demonstrated in the tutorial.
To give a flavor of the tutorial, Example 1 in \autoref{sec:overview}
is adapted from the steps that introduced the \codeTool{Make Equal} tools.
%
In addition to tool-specific tutorial steps,
we also dedicated a step for more practice with target positions, independent
of a specific tool, because the notion of target positions was likely to be
unfamiliar. %%  foreign to all users; we know of no analog in existing editors.


\parahead{Tasks}

After the tutorial, users worked on six \emph{tasks}, each a
different program and a list of one or more edits to perform using code tools.
%
For some tasks, there were multiple different sequences of code tool invocations
that could lead to the desired result.
%
The starting programs ranged from 7 to 11 lines of code and required between
2 and 8 tool invocations (at minimum) to finish the tasks.
%
\autoref{tab:tasks} outlines the tasks. The Two Circles task was
presented as Example 2 in \autoref{sec:overview}. Extended task
descriptions
can be found in
the \suppMaterials{}.

Before every task, the participant was given a read-only reading period to understand the program
before seeing the list of edits to perform.
%
To emulate a real-world scenario where the programmer knows what to accomplish
but may not quite remember all the steps, the task directions were written in a
more natural style without direct reference to tool names---for example, ``move
the \verb+ring+ definition inside \verb+target+'' instead of ``invoke
\codeTool{Move Definition} on the \verb+ring+ definition with a target position
inside \verb+target+.''

Each of the first four tasks (``head-to-head tasks'') was performed twice, once
each in Traditional and \deuce{} Modes, resulting in eight \emph{trials}. The first four trials
comprised each of the four tasks, in random order and with one of the modes
randomly chosen per trial. For the next four trials, the order of tasks was, again,
randomized, each using the mode not chosen for the task in the first round.
%
After these eight trials, the user performed each of the last two tasks
(``open-ended tasks'') once using the Combined Mode---both Traditional and
\deuce{} Modes were available for use, to mix-and-match the two modes however
they saw fit.

For each task, comments showed what the desired final code should look like,
sometimes modulo minor whitespace differences. The editor provided an
indicator about whether the task was completed, giving the user the option to
Give Up at any point if needed. There was also a maximum time limit of six and
twelve minutes for each head-to-head and open-ended task, respectively, with no
indication about the time limit until and unless the user reached the two
and four minutes remaining mark, respectively.


\subsection{Results}
\label{sec:user-study-results}

Participants reported between 2 and 10 years of programming experience (mean: 5.1), of which
between 0 and 3 years involved functional programming (mean: 0.76). 10 participants (48\%)
reported no prior functional programming experience.
%
8 participants reported using tools that supported automated refactoring (Eclipse, IntelliJ, and
PyCharm all received multiple mentions). 4 participants reported some prior exposure to
previous versions of the \sns{} project, but none reported knowledge of the code tools presented
in the study.

For the study itself, 8 users brought their own laptop, the remaining 13 used
ours. 15 participants used a mouse, and 6 relied on their laptop's trackpad.
%
Each session took a mean of 1hr 44min (range: 1h 11m -- 2h 27m). Users spent between 23 and 66
minutes on the tutorial (mean: 41) and 20 and 65 minutes on the tasks (mean: 44). The remaining
time was spent on introductory remarks and the exit survey.
%
All users attempted all tasks. Two trials were discarded because of tool malfunction,
for a final total of 166 head-to-head trials and 42 open-ended tasks suitable for analysis.

The tasks proved moderately difficult. On average, each participant successfully completed 71\%
of the trials and open-ended tasks within the time limits, with 3 users
completing them all and 1 user failing to complete any.
\autoref{fig:pooled_completion_rates} shows completion rates by task.
%
The One Rectangle and Lambda tasks had particularly low completion rates. Based on
videos of failed attempts, many users struggled with choosing appropriate
tools---\eg{}~many chose \codeTool{Introduce Variables} rather than
\codeTool{Make Equal}, and some chose \codeTool{Inline} rather than
\codeTool{Move Definitions} in an attempt to create a tuple definition.
%
The tutorial was not sufficient for everyone to remember and understand all the
tools needed for the tasks.
%
The task descriptions may have also presented obstacles---\eg{}~for Lambda,
the phrase ``Define and use...'', along with \verb+(def [x y w h] ...)+ in the final
code, may have led some to use \codeTool{Introduce Variables}, which would then
require several roundabout transformations to complete the task.
%
We believe these difficulties
are largely independent of the user interface features.
%
We now address each of the research questions in turn.

\parahead{Is either mode more effective for completing tasks?}


\autoref{fig:faceted_completion_rates} breaks down
completion rates for head-to-head tasks by mode. Because each was attempted
twice,
to assess possible learning effects from already completing a task in the other mode,
\autoref{fig:faceted_completion_rates} also differentiates
between the user's first or second encounter with each task.
%
Visually, the data suggest that on the first encounter with a task, Traditional Mode may
better facilitate completion, and is also a better teacher for the
subsequent encounter with
\deuce{} Mode. In contrast, a first encounter with \deuce{} Mode may be less helpful for the second
encounter
with Traditional Mode.

To control for learning effects, a mixed effects logistic
regression model~\cite{GelmanHill} was fit with \texttt{lme4}~\cite{lme4} to predict task completion probability based upon fixed effect
predictors for the mode (coded as 0 or 1), the trial number (1-8), whether the trial was the second
encounter with the task (0 or 1), whether the participant used a mouse (0 or 1), whether the
participant used their own computer (0 or 1), and the interaction of mode with the second
encounter (0, or 1 when \deuce{} Mode and a second encounter). To model
differences in user skill and task difficulty, a random effect was added for each participant as well as
each task, and a random interaction was added to model
differences in the second encounter difficulty per task. Reported p-values are based on Wald Z-statistics.

In the fit model, the coefficient for mode was on the edge of significance (p=0.057), indicating
that Traditional Mode did better facilitate task completion on the first encounter with a task.
Given this, \deuce{} Mode performed better than expected on the second encounter (interaction term
p=0.036), but not enough to confidently say that \deuce{} Mode was absolutely better than
Traditional Mode for the second encounter (p=0.17). No other fixed effect coefficients approached significance.

\deuce{} Mode therefore seems to present a learning curve, but may be just as effective as
Traditional Mode once that learning curve is overcome. This interpretation accords with the surveys:
5 participants wrote that Traditional Mode might be better for learning, and
4 participants---including 3 of the previous 5---said \deuce{} Mode was
better when they knew the desired transformation.
However, the data may be
alternatively explained if \deuce{} Mode on the first encounter is a poor teacher, actively
misleading users on the second encounter with Traditional Mode.


\input{fig-pooled-completion-rates}

\input{fig-faceted-completion-rates}


\input{fig-task-times}

\paraheadNoDot{Is either mode more effective for rapid editing?} Among trials successfully
completed, the duration of each trial was measured from the start of configuration of the first refactoring
to the end of the final refactoring. The distribution of these timings is presented
in \autoref{fig:task_times}, scaled relative to the mean duration for each task.

Again, to tease out if any of these differences are significant, from the same predictors described above
two linear mixed effects models were fit to predict (1) trial duration and (2) the logarithm of trial duration
(\ie{} considering effects to be multiplicative rather than additive).
Percentile bootstrap p-values
for the fixed effect coefficients were calculated
from 10,000 parametric simulate-refit samples.\footnote{See \url{https://www.rdocumentation.org/packages/lme4/versions/1.1-13/topics/bootMer}}
For the first encounter
with a task, Traditional Mode was insignificantly faster (by 13 seconds, p=0.44; or 9.2\%, p=0.52).
However, \deuce{} Mode was
on average 25 seconds (p=0.13) or 36\% (p$<$0.01) faster for the second encounter with a task, suggesting that
\deuce{} Mode may be faster once users become familiar with the available tools. Most of the gain
comes from less time spent in configuration---after discounting all idle thinking time between
configurations, the model still reveals an 18 second difference.

\paraheadNoDot{Is either mode more effective for achieving more with fewer transforms?} To
determine if either mode facilitated more efficient use of interactions, the
same mixed effects model was fit to predict the number of refactorings invoked during each
successful trial, as well as the number of Undos.
On the first encounter with a task, Traditional Mode accounted for an average
of 2.0 fewer refactorings (p$<$0.01) and 2.1 fewer Undos (p$<$0.01), but on the second encounter no significant difference in
number of refactorings or Undos was indicated. As a second encounter with \deuce{} Mode is faster than
Traditional Mode, the speed gain thus appears to be explained by faster invocations rather than fewer
invocations.

\paraheadNoDot{Is either mode preferred by users? In which cases?}

The two final open-ended tasks allowed participants to mix-and-match the two modes
as they pleased. As shown in \autoref{fig:objective}, on both tasks the overwhelming number of users performed a
greater share of refactorings using \deuce{} Mode. We believe a main advantage of \deuce{}
 Mode is that it simplifies the configuration of refactorings that require multiple arguments, as the user
may select all the arguments together before choosing a transformation from a short menu. In
Traditional Mode, the workflow is stuttered: the user must select a single argument, right-click
to choose a transformation, then select the remaining arguments. However, for a refactoring requiring
only a single argument, Traditional Mode is more streamlined: a user may simply select the desired
transformation immediately after right-clicking on the first argument. Thus, for single-argument
refactorings, \deuce{} Mode's advantages may be limited. A breakdown of mode usage by popular tools
(\autoref{fig:tool_modes}) lends support to this hypothesis. For the most commonly used tool, \codeTool{Rename},
which always takes only a single argument, participants used Traditional and \deuce{} Modes with
roughly even frequency. Most other tools showed strong preferences towards \deuce{} Mode, with
the notable exception of  \codeTool{Create Function by Merging Definitions}.
Because the Four Squares task required invoking this tool with four expressions, according to
the hypothesis, users should prefer \deuce{} Mode. The videos revealed that several
users were unable to discover how to structurally select a function call, which required hovering
on the open parenthesis (not demonstrated
in the tutorial). Several of these users were, however, able to invoke the tool by
text-selecting a function call or by starting from the full Code Tools menu.

\input{fig-objective}

\input{fig-tool-modes}

Subjectively, the concluding survey asked whether \deuce{} or Traditional Mode worked better for
each head-to-head task, measured on a 5-point scale from ``Text-Select Mode worked much better'' to
``Box-Select Mode worked much better''. For each participant, a random choice
determined which mode appeared at each end of the scale.
As shown in \autoref{fig:subjective}, on average a similar
modest preference for \deuce{} Mode was expressed for each task.

\input{fig-subjective}

On the free-response portion of the survey, several explanations were given for this
preference for \deuce{} Mode.
3 participants
appreciated the ability to select multiple arguments;
2 other participants
appreciated selecting all arguments before selecting a tool;
1 other participant
appreciated the smaller menu of refactorings; and
1 other participant
appreciated the ease of starting a refactoring by clicking code objects rather
than having to create a text selection.

Altogether, users demonstrated a strong objective and modest subjective preference for
\deuce{} over Traditional Mode, suggesting that \deuce{} accomplishes its goal
to provide a more human-friendly interface to identify, configure, and invoke refactorings.

\parahead{Limitations}

There are several threats to the validity of our experimental setup.
One is that our emulation of traditional features may have been less
effective than those features in existing tools. Another is that
the participants may have felt compelled to use \deuce{} Mode (which could
likely have been deduced to be more novel than Traditional Mode) more during the
open-ended tasks---and pronounce a preference for it in the survey---because the
participants were drawn from the same academic community as the authors. Another
is that participants used the tool in heterogeneous environments---different
computers and browsers, configured with different screen sizes and mouse
settings. Performance on the tasks may have also been affected by the presence
of the user study proctor and video recording device. According
to self-reported assessments, participants were relatively unfamiliar with
functional programming and with refactoring tools, so the results may differ
for users with more extensive experience. Finally, our results were obtained on
small programs and tasks in a prototype language.

\parahead{Future Improvements}

There are opportunities to improve our implementation of \deuce{}.
First, to reduce the learning curve, it would be worth adding more explanatory
features (\eg{}~in a tutorial, or within the tool when the user selects certain
kinds of items for the first time), particularly for unfamiliar transformations
(\eg{}~\codeTool{Move Definitions}) and for unfamiliar user interface features
(\ie{}~target positions). Enabling the full Code Tools menu may also help
because of the descriptions of requirements in the Tool Configuration Panels
(\cf{}~the ``\deuce{} Mode'' discussion). Also, to allow easy corrections of
misconfigured refactorings, it would help if
Undo restored the previous selection state rather than just the previous version of
the code; we have since implemented this feature.

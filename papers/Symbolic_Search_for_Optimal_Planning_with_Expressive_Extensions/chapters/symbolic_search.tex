\chapter{Symbolic Heuristic Search}\label{ch:symbolic_heuristic_search}
\chapterquote{While the main observations of this paper are both intuitive and pretty obvious, I still consider the work a significant contribution in focusing attention on a key and often overlooked difference between explicit and symbolic search [\dots].}{Reviewer \#3 (2020)}

\section*{Core Publication of this Chapter}
\renewcommand{\citebf}[1]{\textbf{#1}}
\begin{itemize}
    \item \fullcite{speck-et-al-icaps2020}
\end{itemize}
\renewcommand{\citebf}[1]{#1}

Explicit search and symbolic search have been shown to be strong and competitive approaches for optimal classical planning.
While explicit search usually occurs as variants of forward \astar{} search \autocite{hart-et-al-ieeessc1968}, which are equipped with strong and efficient goal-distance heuristics, symbolic search is usually performed as (bidirectional) blind search, i.e., without heuristics.
This naturally raises the question of why not combine the two techniques to obtain a planning algorithm that combines the state pruning of explicit heuristic search with the concise representation of symbolic search.
This combination is referred to as symbolic heuristic search, which includes a variety of symbolic generalizations of \astar{} for different decision diagrams such as \bddastar{} \autocite{edelkamp-reffel-ki1998}, \addastar{} \autocite{hansen-et-al-sara2002} and \evmddastar{} \autocite{speck-et-al-icaps2018}.

The underlying idea of symbolic \astar{} search is to precompute and represent a \emph{heuristic function} $h$ with decision diagrams, where $h: \states \to \mathbb{N}_0 \cup \{ \infty \}$ such that $h(s_\star) = 0$ for all $s_\star \in \goalstates$.
Symbolic operations are then used to assign the corresponding $f$-values ($f = g + h$) to each state of a set of states $S_g$ reachable with cost $g$.
As usual with \astar{}, symbolic \astar{} expands the states in ascending order of the $f$-value and uses a tie-breaking rule in favor of states with smaller $g$-values \autocite{kissmann-edelkamp-aaai2011,torralba-phd2015}.
To guarantee optimal solutions, a \emph{consistent heuristic} is assumed, i.e., its estimate is always less than or equal to the estimated distance from each direct successor to the goal, plus the cost to reach that successor, i.e., $h(s) \leq h(s[o]) + \constcostfun(o)$.
Note that any consistent heuristic is also admissible, i.e., never overestimates the cost of reaching a goal state \autocite{pearl-1984}.
Two important examples of consistent heuristics and at the same time the extreme cases are the perfect heuristic $\perfecth{}$, which maps any state $s$ to the cost of the cheapest path from $s$ to any goal state, and the blind heuristic $\heu{blind}{}$, which maps any state $s$ to $0$.

\begin{figure}
    \centering
    \subfloat[First step.\label{fid:bddastar_example_a}]{
        \centering
        \makebox[0.5\textwidth][c]{
            \input{figures/bddastar_example_a.tex}
        }
    }
    \subfloat[Last step.\label{fid:bddastar_example_b}]{
        \centering
        \makebox[0.5\textwidth][c]{
            \input{figures/bddastar_example_b.tex}
        }
    }
    \caption[Illustration of BDDA$^\star$.]{Illustration of BDDA$^\star$, where the cells represent state sets $S_{g,h}$ and the arrows denote successor state sets. The gray cells are expanded in the order indicated by the numbers \autocite{torralba-gnad-icaps2017tutorial,torralba-phd2015}.
        %Inspired by similar visualizations of \textcite{torralba-phd2015,edelkamp-reffel-ki1998}.
    }
    \label{fid:bddastar_example}
\end{figure}

In \bddastar{}, a consistent heuristic function is precomputed and represented by multiple BDDs, one for each heuristic value $h$, where each BDD is used to represent the states $S_h$ with heuristic value $h$.
During search, states $S_g$ reachable with cost $g$ are partitioned according to their heuristic value by computing the intersections of $S_g$ and $S_h$ for each heuristic value $h$ resulting in sets of states $S_{g,h}$.
%
%As usual with \astar{}, \bddastar{} expands states in ascending order of $f = g + h$  and uses a tie-breaking rule in favor of states with smaller g-values \autocite{kissmann-edelkamp-aaai2011,torralba-phd2015}.
\Cref{ex:bddastar} exemplifies how \bddastar{} works.

\begin{example}\label{ex:bddastar}
    We consider a planning task with unit costs. \bddastar{} starts with the state set $S_{0,2} = \{ \init \}$, which contains only the initial state with a $g$-value of 0 and an $h$-value of $2$ (\Cref{fid:bddastar_example_a}).
    The expansion of $S_{0,2}$ leads to sets of states with $g$-value of $1$ and different $h$-values.
    Next, the state set $S_{1,1}$ is expanded, then $S_{1,2}$, and so on until a goal state is contained in $S_{4,0}$ (\Cref{fid:bddastar_example_b}).
\end{example}

While \bddastar{} utilizing a heuristic expands fewer states, symbolic blind search (\bddastar{} with $\heu{blind}{}$) potentially expands fewer sets of states.
Moreover, as \textcite{speck-et-al-icaps2020} have shown and we will examine in this chapter, the BDD representation of the state sets can deteriorate if the states are partitioned according to their $h$-values.
%In other words, in \bddastar{} the search fringe is described using symbolic representations and the notion of node expansions is generalized to region expansions as instead of single states represented as nodes whole sets of states are expanded.
%As all computations are performed with decision diagrams such that the concise presentation is maintained which then allows to expand the most promising states (minimal $f$-value) in form of a set of state represented as decision diagram.

There are several heuristics that can be precomputed and represented using symbolic search and decision diagrams, leading to cutting-edge performance in explicit heuristic search \autocite{edelkamp-aips2002,franco-et-al-ijcai2017,franco-et-al-ipc2018b,moraru-et-al-ki2019}.
Thus, all the ingredients are present to allow a symbolic planner utilizing heuristics, as explicit planners do.
However, \textcite{jensen-et-al-aij2008} identified the partitioning of state sets according to their heuristic values as a bottleneck, because multiple arithmetic operations have to be performed during search.
This leads to different extension of \bddastar{} to overcome this bottleneck such as Lazy \bddastar{} \autocite{torralba-phd2015}, which delays the heuristic evaluation as long as possible, or Set\astar{} \autocite{jensen-et-al-aij2008}, which encodes the heuristic values as preconditions of actions resulting in multiple actions with costs according to the heuristic values.
However, empirical evaluations show that all versions of \bddastar{} perform better than symbolic blind search in some domains but overall symbolic bidirectional search without any heuristic  performs best \autocite{torralba-et-al-ijcai2016}.

In the remainder of this chapter, we describe and summarize the results of \textcite{speck-et-al-icaps2020}, which theoretically and empirically evaluate the search behavior of \bddastar{}.
On the theoretical side, this study reveals another fundamental problem of symbolic heuristics, namely that the use of a heuristic does not always improve the search performance of \bddastar{}, as it may affect the size of the representation.
In general, even the \emph{perfect heuristic} can exponentially deteriorate the search performance of symbolic \astar{}.
The empirical evaluation is consistent with these theoretical results.
Finally, we conclude this chapter with a discussion of the implications of these
%theoretical and empirical results.
findings.

\begin{figure}
    \begin{center}
        %\resizebox{1\textwidth}{!}{
        \input{figures/bddastar-proof}
        %}
    \end{center}
    \caption[Visualization of two BDDs with exponential size difference.]{
        Visualization of two BDDs $B_S$ (with $h_{\text{\scriptsize blind}}$) and $B_{S'}$ (with $h_{\scriptsize \star}$) representing state sets $S$ and $S'$, where $B_{S'}$ is exponentially larger in the number of variables than $B_{S}$, although $S' \subsetneq S$ \autocite{speck-et-al-icaps2020}.}
    \label{fid:bddastar_proof}
\end{figure}

\section{Theoretical Results}

\textcite{speck-et-al-icaps2020} show that good goal-distance estimations in the form of heuristics are not the appropriate quantity to improve the search performance of symbolic heuristic search.
The reason for this is that, in contrast to explicit \astar{}, where every
consistent heuristic can only reduce the number of necessary node expansions (up to tie-breaking) and thus the search effort compared to blind search, in \bddastar{} no such guarantee exists.
In \bddastar{}, the size of expanded BDDs, i.e., number of BDD nodes, representing expanded states determines the search effort and thus the runtime.
As a BDD $B_{S'}$ can be exponentially larger than a BDD $B_{S}$ although the set of states $S'$ is a strict subset of $S$, i.e., $S' \subsetneq S$, it is not always beneficial to represent and expand fewer states (\Cref{fid:bddastar_proof}).
In other words, in explicit search, where the most promising states (search fringe) are simply enumerated explicitly, reducing the number of states to expand directly improves search performance.
However, in symbolic search, reducing the number of states to be expanded can lead to a larger representation size in form of BDDs and a fragmentation of the search fringe as the search progresses.

Similar to \say{must-expand} nodes in explicit search, \textcite{speck-et-al-icaps2020} introduce the notion of \emph{expansion size} for \bddastar{} as the cumulative size of BDDs that must always be expanded by \bddastar{} before finding an optimal solution to measure search effort.
Using this notion it is possible to prove that even under the best possible and unrealistic circumstances, namely the perfect heuristic, the search effort of \bddastar{} can be exponentially larger than the search effort of symbolic
search without heuristic, and vice versa (\Cref{thm:bddastar}).

\begin{theorem}[\cite{speck-et-al-icaps2020}]\label{thm:bddastar}
    Using the perfect heuristic $\perfecth$ instead of the blind heuristic $\heu{blind}{}$ can \emph{decrease} or \emph{increase} the expansion size of \bddastar{} exponentially in the size of the planning task for a given variable ordering. \qed
\end{theorem}

While the result that the search performance of \bddastar{} can be exponentially improved when $\perfecth$ is used instead of $\heu{blind}{}$ is less surprising, the opposite result is very surprising.
This highlights the difference between explicit and symbolic search: the representation of the search fringe must be concise, and in symbolic search the decision diagram size is not directly related to the number of states represented.
To prove that using $\perfecth$ instead of $\heu{blind}{}$ can exponentially increase the expansion size and thus exponentially deteriorate search performance, \textcite{speck-et-al-icaps2020} constructed a family of planning tasks $\task_n$ parameterized over the number of (relevant) variables.
Solving tasks of this family of planning tasks $\task_n$ with \bddastar{} using the perfect heuristic prunes states from the expanded set of states (search fringe) so that the representation size increases exponentially.
\Cref{fid:bddastar_proof} shows the core idea of the proof, with two BDDs representing the search fringe, i.e., the expanded state set, in the last expansion step of \bddastar{} using $\perfecth$ or $\heu{blind}{}$ when solving $\task_3$.
The key observation is that when $\heu{blind}{}$ is used, no states are pruned according to their values over variables $v_i$, resulting in a compact BDD representation.
However, if $\perfecth$ is used, states are pruned according to their values over the variables $v_i$ and the function $(v_1 \land v_{n+1}) \lor \dots \lor (v_{n} \land v_{2n})$ has to be represented, which under certain variable orders requires a BDD with exponentially many nodes \autocite{kissmann-phd2012}.

Finally, \textcite{speck-et-al-icaps2020} show that these theoretical results also hold for several other symbolic \astar{} variants such as Lazy \bddastar{}, Set\astar{}, \addastar{}, and \evmddastar{}, as well as for their bidirectional extensions.

\begin{figure}
    \subfloat[Search Effort (BDD nodes)\label{fig:bddastar_data_a}]{
        \centering
        \makebox[1\textwidth][c]{
            \resizebox{0.95\textwidth}{!}{
                \input{figures/bdd-nodes-fwd.tex}
                \hfill
                \input{figures/bdd-nodes-bid.tex}
            }
        }
    }\\
    \subfloat[Image Time (seconds)\label{fig:bddastar_data_b}]{
        \centering
        \makebox[1\textwidth][c]{
            \resizebox{0.95\textwidth}{!}{
                \includegraphics{figures/image_time-fwd.pdf}
                \hfill
                \includegraphics{figures/image_time-bid.pdf}
            }
        }
    }\\
    \subfloat[Overall Runtime (seconds)\label{fig:bddastar_data_c}]{
        \centering
        \makebox[1\textwidth][c]{
            \resizebox{0.95\textwidth}{!}{
                \includegraphics{figures/overall_search_time-fwd.pdf}
                \hfill
                \includegraphics{figures/overall_search_time-bid.pdf}
            }
        }
    }
    \vspace{-0.2cm}
    %\input{figures/image_time-bid.tex}
    %\input{figures/overall_search_time-bid.tex}
    \caption[Comparison of BDDA$^\star$ with two different heuristics.]{
        Comparison of BDDA$^\star$ with the blind heuristic and with given (fraction) perfect heuristics \autocite{speck-et-al-icaps2020}.
        With \emph{uns.} we refer to instances that were not solved within the time and memory limits.
    }
    %with the blind heuristic \heu{blind}{} and with a given fraction perfect heuristics ($c \in \{1, \frac{3}{4}, \frac{1}{2}\}$)}
    \label{fig:bddastar_data}
\end{figure}

\section{Empirical Results}
\textcite{speck-et-al-icaps2020} empirically investigated forward and bidirectional \bddastar{} with precomputed fraction perfect heuristics on domains from the optimal track from the International Planning Competitions between 1998 and 2018.
A heuristic $c \cdot h$ is called fraction perfect if it assigns to all states the values of the perfect heuristic multiplied by a constant $0 \leq c \leq 1$, where $0\perfecth = \heu{blind}{}$ and $1\perfecth = \perfecth$ are important extreme cases.
Note that \bddastar{} with blind heuristic $0\perfecth = \heu{blind}{}$ corresponds to symbolic blind search.

\Cref{fig:bddastar_data_a} compares the search effort of \bddastar{} with the blind heuristic and the search effort of \bddastar{} with the fraction perfect heuristics.
While the unrealistic case of the perfect heuristic almost always leads to a reduction in search effort in practice, when we consider more realistic cases, namely the fraction perfect heuristic, we can see that the search effort of \bddastar{} can improve or deteriorate to the same extent.

\Cref{fig:bddastar_data_b} shows the expansion time of \bddastar{}, i.e., the cumulative time required to generate all successors with the image operation.
A correlation is observed between the search effort and the expansion time, which also empirically shows that the introduced notion of search effort is an adequate quantity to measure the performance of \bddastar{}.
This highlights the fundamental problem highlighted by \textcite{speck-et-al-icaps2020}: using a heuristic does not always improve the search performance of \bddastar{}.

Finally, \Cref{fig:bddastar_data_c} shows the total running time of \bddastar{} without the time for computing the corresponding heuristic.
Comparing the expansion time with the total running time, we find that \bddastar{} with fraction perfect heuristics has a higher time increase than \bddastar{} with $\heu{blind}{}$, which is due to the time-consuming partitioning of the state sets by heuristic values \autocite{jensen-et-al-aij2008}.

Overall, these empirical results show that also in practice a heuristic can improve or deteriorate the search effort of \bddastar{} to the same extent.
These empirical results are consistent with the presented theoretical results.
Furthermore, \textcite{speck-et-al-icaps2020} show that it appears to be domain
dependent whether a heuristic helps \bddastar{} as the structure of the reachable search space appears to play a central role.

\section{Discussion}\label{sec:symbolic_search_discussion}
As the results of \textcite{speck-et-al-icaps2020} show, using goal-distance estimators, i.e., heuristics, to prune states in symbolic heuristic search does not always pay off.
Indeed, even the perfect heuristic can exponentially deteriorate the search performance of \bddastar{} and other symbolic \astar{} variants.
Since the search performance of \bddastar{} is not directly related to the number of expanded states, but to the size of the involved BDDs during the search, \textcite{speck-et-al-icaps2020} suggest using heuristic functions that can provide a nice structure of the involved decision diagrams or even give a size guarantee.
One possible candidate are potential heuristics \autocite{pommerening-et-al-aaai2015}, which have recently been shown to be encodable as operator potentials within symbolic heuristic search, resulting in state-of-the-art performance \autocite{fiser-et-al-icaps2021wshsdip}.

The fact that symbolic blind search does not use heuristics and yet can compete with explicit heuristic search in cost-optimal planning \autocite{edelkamp-et-al-aaai2015,torralba-et-al-aij2017,speck-et-al-icaps2020} has the advantage that it is not constrained by the limits of heuristics.
Considering expressive extensions of classical planning, such as conditional effects, axioms, and many more, explicit heuristic search planners rarely support them.
The reason is that it is very challenging to design admissible heuristics that are both informative and fast to compute when considering such extensions.
Symbolic blind search, however, provides a good basis to support these extensions, since it does not rely on heuristics and performs an efficient exhaustive search.
In the next chapters, we will take advantage of this and show how symbolic search can be adapted to support expressive extensions in cost-optimal planning.

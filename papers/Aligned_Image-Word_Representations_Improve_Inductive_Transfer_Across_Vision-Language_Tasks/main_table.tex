\begin{table*}
    \centering 
\setlength\tabcolsep{4 pt}

    \resizebox{\textwidth}{!}{
    \begin{tabular}{|c||c|c|c|c|c||c|c|c|c|c|c|c|c|c|c|c||c|c|c||c|}
    \hline
     %\textbf{\parbox{4cm}{Accuracies on Real-MCQ-VQA Validation Set}}&
     \textbf{Accuracies on Real-MCQ-VQA Validation Set}&
     \rot{\textbf{what color}}& 
     \rot{\textbf{\parbox{3cm}{what is the\\(wo)man/person}}}& 
     \rot{\textbf{what is in/on}}& 
     \rot{\textbf{\parbox{3cm}{what kind/\\type/animal}}}&
     \rot{\textbf{what room/sport}}&
     \rot{\parbox{3cm}{can/could/\\does/do/has}} & 
     \rot{\parbox{3cm}{what does/\\number/name}}& 
     \rot{what brand}&
     \rot{which/who}& 
     \rot{what is/are}& 
     \rot{why/how}&
     \rot{how many}&
     \rot{what time}& 
     \rot{where}&
     \rot{is/are/was}&
     \rot{none of the above}&
     \rot{other} &
     \rot{number}&
     \rot{yes/no}&
     \rot{overall accuracy}\\ \hline
     VQA Only & 53.5 & 70.5 & 53.6 & 56.8 & 89.8 & 81.8 & 41.9 & 45.9 & 49.0 & 58.3 & \textbf{33.8} & 38.4 & \textbf{53.9} & 45.8 & 80.2 & 56.0 & 54.5 & 39.2 & 82.1 & 62.9 \\
     \parbox{5cm}{\centering Joint Multitask} & 59.4 & 71.8& 54.6 & 58.3 & 91.0 & 81.9 & \textbf{43.8} & 46.4 & 50.8 & 59.2 & 32.3 & \textbf{39.4} &  \textbf{53.9} & 47.0 & 80.4 & 57.1 & 56.7 & \textbf{39.8} & 82.2 & 64.1 \\
     \parbox{5cm}{\centering Joint SVLR} & \textbf{62.1} & \textbf{74.1} & \textbf{57.9} & \textbf{60.0} & \textbf{91.1} & \textbf{82.8} & 41.6 & \textbf{52.9} & \textbf{52.0} & \textbf{61.1} & 33.6 & 39.0 & 51.3 & \textbf{48.6} & \textbf{81.4} & \textbf{58.5} &  \textbf{58.8} & 38.8 & \textbf{83.0} & \textbf{65.3} \\ \hline
     \parbox{5cm}{\centering Zero-Shot VQA} & 18.8 & 21.0 & 27.4 & 31.4 & 22.0 & 17.1 & 13.9 & 11.6 & 20.6 & 22.9 & 12.7 & 0.7 & 7.2 & 26.1 & 13.5 & 19.2 & 22.4 & 1.2 & 13.3 & 16.4 \\ \hline
     %\parbox{5cm}{\centering Zero-Shot VQA} & 36.5 & 28.7 & 37.6 & 33.6 & 55.6 & 6.1 & 13.0 & 7.6 & 34.2 & 39.6 & 16.2 & 3.8 & 14.1 & 42.5 & 9.5 & 27.0 & 34.4 & 5.0 & 8.1 & 20.8 \\ \hline
    \end{tabular}}
    \vspace{-3mm}
    \caption{\textbf{Inductive transfer from VR to VQA through SVLR in joint training and zero-shot settings:} We evaluate the performance of our model with SVLR module trained jointly with VR and VQA supervision (provided by Genome and VQA datasets respectively) on the VQA task. We compare this \textit{jointly-trained} model to a model trained on \textit{only} VQA data. We also compare to a traditional multitask learning setup that is jointly trained on VQA and VR (i.e. uses same amount of data as Joint SVLR) and shares visual features but \textit{does not} use the object and attribute word embeddings for recognition. While multitask learning outperforms VQA-only model, using the SVLR module doubles the improvement. Our model is most suited for the question types in bold that require visual recognition without specialized skills like counting or reading. Formulation of VR and \textit{attention} in VQA in terms of inner products between word and region representations enables Zero-Shot VQA. In this setting we train on Genome VR data and apply to VQA val (Sec~\ref{sec:vqa_eval}).}
    \vspace{-3mm}
    \label{Tbl:abltionperf}
\end{table*}
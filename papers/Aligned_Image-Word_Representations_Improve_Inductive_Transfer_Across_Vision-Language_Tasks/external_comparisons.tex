\begin{table}[]
\scriptsize
\centering
\setlength{\tabcolsep}{2 pt}
\resizebox{\columnwidth}{!}{
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline 
& WTL\cite{shih2016look}  & FDA\cite{ilievski2016focused}  & MLP\cite{mallya2016simplevqa,jabri2016revisiting}  &  MCB\cite{fukui2016multimodal} & HiCo\cite{lu2016hierarchical} & Ours \\

\hline
%\multicolumn{2}{|c|}{Base recognition network}                                                                       & VGG         & Resnet-101 & Resnet-152  & Resnet-152    & Resnet-200 & Resnet-152          \\\hline
%\multirow{6}{*}{\rot{\parbox{4cm}{\centering val}}} & What color (9.8\%)                                                            & 54.0          & -    & 51.9  & - & - & 65.0                      \\
%                     & What is in/on (1.8\%)                                                         & 54.8          & -    & 61.7 & - & -  & 60.1                      \\
%                     & \begin{tabular}[c]{@{}c@{}}What kind/\\ type/animal (23.8\%)\end{tabular}     & 52.9        & -    & 65.8  & - & -  & 61.1                      \\
%                     & \begin{tabular}[c]{@{}c@{}}What is the \\ man/woman/person (2\%)\end{tabular} & 70.2        & -    & 78.0    & - & -  & 76.1                      \\
%                     & \begin{tabular}[c]{@{}c@{}}Can/could/does/do/has \\ (4.6\%)\end{tabular}      & 75.7       & -    & 51.5 & -  & -  & 82.6                  \\
val                                                                      & 58.9         & -    & 63.6  & -  & -  & 66.2 \\  \hline
test-dev                                                                       & 62.4           & 64.0 & 65.9  & 69.9 & 65.8 & 64.8                      \\
test-std                                                                       & 63.5          & 64.2 & -  & -    & 66.1 & 64.8          \\ \hline
Trained on                                                                        & \textit{train+val}          & \textit{-} & \textit{train}  & \textit{train+val}    & \textit{train+val} & \textit{train}  \\\hline 
\end{tabular}}
\vspace{-2mm}
\caption{\textbf{External Comparisons on VQA:} We include external comparisons, but note that internal comparisons are more controlled and informative.  The MLP results use the implementation from \cite{mallya2016simplevqa}. For test accuracy, it is unclear whether FDA uses \textit{val} to train. The original MLP implementation \cite{jabri2016revisiting} using Resnet-101 yields 64.9 and 65.2 on \textit{test-dev} and \textit{test-std} respectively. MCB reports only \textit{test-dev} accuracy for the directly comparable model (final without ensemble). Note that the overall performance of our model is slightly worse than MLP and MCB because only about $10\%$ of the VQA dataset benefits from visual attention. Our model achieves $62.1\%$ on color questions using attention, outperforming WTL's $54\%$ and MLP's $51.9\%$.}
\label{tab:state_art}
\end{table}

%
\section{Introduction}
\begin{quote}
\textit{If you want your children to be intelligent, read them fairy tales. If you want them to be more intelligent, read them more fairy tales}.\\
\begin{flushright}
--- \textit{Albert Einstein}
\end{flushright}
\end{quote}

\begin{figure*}[t]
\begin{center}
   \includegraphics[width=1.0\linewidth]{figs/pipeline.pdf}
\end{center}
\caption{System prototyping. The system is initialized with user facial features. We assign a fairy tale cast to each user participating (left). The AI fairy tale generator will generated an intial story based on casts (i.e characters). For visualization, we first parse the story into a scene graph based intermediate representation, then we adopt trained scene compositor to predict the layout for each cast in the story. Finally, we visualize the story by drawing doodlers according to the predicted layout.}
\label{fig:sys_proto}
\end{figure*}

Language and mental development are key aspects in early childhood education. Fairy tales, through the characters and virtues shown in the stories, provide moral models for kids to follow and help to develop their vocabulary by offering vivid illustrations. The majority of existing story visualization researches \cite{Gregor2015DRAWAR,Johnson,Johnson2018,Li2019ObjectDrivenTS,Liu2020,Rose2010} have relied on the combination of recurrent neural networks (RNN) and generative adversarial models (GANs). While achieving stunning results on constrained datasets like MS COCO~\cite{}, such end-to-end text-to-image mapping could fail on composite scenes with multiple objects. 
Recently, \cite{Herzig2019,Huang2019,Mirza2014} induce scene graph as an intermediate representation to support visualization of compound sentences. The Scene graph \cite{Johnson} describes things in a scene and their relationships, most commonly position relationships. Compared with raw text, scene graph conceptualizes scene contents as abstract semantic elements that are not bounded by object class or relationship types, boosting text-to-image studies in flexibility and representation power.
%
However, most existing visual language models are trained on massive real-life photos with captions. In fairy tale visualization, we still face the challenge of data shortage. On the one hand, fairy tale illustration conserves much artist labor; on the other hand, the illustration style usually varies from artist to artist, making it more challenging to learn. Based on this point, we combine a rule-based fairy tale parser with a neural sketch generator into an intelligent and interactive visualization system that specially focuses on fairy tale visualization.

In light of this, we propose a new AI fairy-tale co-creation system: AI.R Taletorium. 
xxx %todo 这里缺一块，针对上面的缺陷，我们针对性地提出xx，xx，xx分别解决上述的几个问题，取得什么效果，需要整理下
It enables common creative experiences between groups of children with different physical preferences and at other locations. We aimed at offering an entertaining and imaginative platform for children to communicate with each other, improving their psychological health, especially under extreme circumstances such as the COVID-19 pandemic. The system is composed by two novel modules, a character-centric story generator and a visualizer in the form of doodlers. We connect those two modules by characters and build a bidirectional link to allow kids to interactively participant in the fairy tale creation process by simple doodling without vocabulary requirements.

We summarize our key contribution as follows: 
\begin{itemize}
\item A novel multimodal fairytale co-creation interface based on interactive text-to-image transfer and vice-visa.

\item The system presents a novel fusion method between learn-based language model and rule-based graph update, allowing for more flexibility on both story generation and visualization with limited data.

\item Proposing a CLIP transformed story graph as an intermediate representation to transcends the barrier between digital storytelling content and insufficient illustration data (automatic AI fairy tales storytelling case).
\end{itemize}

% todo：给一下章节的引用
In this paper, we will first give a brief description of the AI.R. Taletorium system. Then we explain our character-centric approach for fairy tale generation and visualization. 
Finally, we present the results from the performed experiments and demonstrate various applications to prove the generation flexibility of our proposed system. 


We leverage AI’s potentials in both knowledge understanding and creation process to design a co-creative environment for imaginative Human-AI interactive storytelling. The fairy tale storyline and content illustrations elicit AI interpretation of the user’s facial characteristics and visual content. They are adding during the process of AI agent fairy tales generation. AI.R Taletorium is a multi-user platform, which runs online and follows the basic principle of \textit{PWA (progressive web application)} design. It works in real-time on multiple devices, which enables users to participate at any time from anywhere.

In this paper, we focus on AI.R Taletorium intelligent and artistic fairy tale visualizer that interacts with users in the real-time proposal. While the story provides an effective and concise way to share experiences, visual content acts as a more comprehensive and universal communication tool that transcends barriers between user groups with different cultural backgrounds and psychological and physical preferences. The learning for meaningful and coherent story visualization thus becoming a popular yet challenging task among AI studies.

Story visualization as a downstream task of text to image generation has met with great success in the deep learning era. Most studies \cite{Gregor2015DRAWAR,Johnson,Johnson2018,Li2019ObjectDrivenTS,Liu2020,Rose2010} have relied on the combination of recurrent neural networks (RNN) and generative adversarial models (GANs). While achieving stunning results on constrained datasets like MS COCO, such end-to-end text to image mapping could fail on composite scenes with multiple objects. Recently, \cite{Herzig2019,Huang2019,Mirza2014} induce scene graph as an intermediate representation to support visualization of compound sentences. The Scene graph \cite{Johnson} describes things in a scene and their relationships, most commonly position relationships. Compared with raw text, scene graph conceptualizes scene contents as abstract semantic elements that are not bounded by object class or relationship types, boosting text-to-image studies in flexibility and representation power.


However, most existing visual-language models are trained on massive real-life photos with captions. In fairy tale visualization, we still face the challenge of data shortage. On the one hand, fairy tale illustration conserves much artist labor; on the other hand, the illustration style usually varies from artist to artist, making it more challenging to learn. Based on this point, we combine a rule-based fairy tale parser with a neural sketch generator into an intelligent and interactive visualization system that specially focuses on fairy tale visualization.

We summarize our key contribution as follows: 
\begin{itemize}
\item Novel approach to multimodal interface design based on dynamic AI text-to-image visualization.
\item Proposing intelligent visualization interface that enables content co-creation between users and AI.
\item Proposing a story graph as an intermediate representation to transcends the barrier between digital storytelling content and insufficient illustration data (automatic AI fairy tales storytelling case).
\end{itemize}

The system presents a novel fusion method between a learn-based language model and rule-based graph update, allowing for more flexibility in defining visualization flexibility.

First, we will give a brief description of the AI.R. Taletorium consisting of parts. We will then explain our approach to fairy tales visualization, the patterns that define AI as an evolved visualization interface, and present the results from the performed experiments. Lastly, we will conclude and specify future directions of the project.
\section{Experiments}
\label{sec:experiments}
\subsection{Experimental Setup}
We evaluate the effectiveness of our approach on three different domain adaptation datasets: DomainNet~\cite{peng2019moment}, Office-Home~\cite{Venkateswara2017DeepHN} and Office31~\cite{Saenko2010AdaptingVC}. DomainNet ~\cite{peng2019moment} is a large-scale domain adaptation dataset with 345 classes across 6 domains. Following MME ~\cite{Saito2019SemiSupervisedDA}, we use a subset of the dataset containing 126 categories across four domains: Real(R), Clipart(C), Sketch(S), and Painting(P). The performance on DomainNet is evaluated using 7 different combinations out of possible 12 combinations. Office-Home~\cite{Venkateswara2017DeepHN} is another widely used domain adaptation benchmark dataset with 65 classes across four domains: Art(Ar), Product(Pr), Clipart(Cl), and Real (Rl). We perform experiments on all possible combinations of 4 domains. Office31~\cite{Saenko2010AdaptingVC} is a relatively smaller dataset containing just 31 categories of data across three domains- Amazon(A), Dslr(D), Webcam(W). Following prior work ~\cite{Saito2019SemiSupervisedDA, Kim2020AttractPA}, we evaluate our approach on two combinations for the office31 dataset. 

For the fair comparison, we use the data-splits (train, validation, and test splits) released by ~\cite{Saito2019SemiSupervisedDA} on Github \footnote{\url{https://github.com/VisionLearningGroup/SSDA_MME}}. We use the same settings for the benchmark datasets as in the prior work ~\cite{Saito2019SemiSupervisedDA, Kim2020AttractPA}, including the number of labeled samples in the target domain, which are consistent across all experiments.

\subsection{Implementation Details}
Similar to the previous works on SSDA ~\cite{Saito2019SemiSupervisedDA, Kim2020AttractPA, Li2020OnlineMF}, we use Resnet34 and Alexnet as the backbone networks in our paper. We only used VGG for Office31 due to its higher memory requirements. The feature generator model is initialized with ImageNet weights, and the classifier is randomly initialized and has the same architecture as in ~\cite{Saito2019SemiSupervisedDA, Kim2020AttractPA, Li2020OnlineMF}. All our experiments are performed using Pytorch ~\cite{Paszke2019PyTorchAI}.We use an identical set of hyperparameters ($\alpha= 4$, $\beta= 1$ ) across all our experiments other than minibatch size. All the hyperparameters values are decided using validation performance on Product to Art experiments on the Office-Home dataset. We have set $\tau=5$ in our experiments. Each minibatch of size $B$  contains an equal number of source and labeled target examples, while the number of unlabeled target samples is $\mu \times B$. We study the effect of $\mu$ in section \ref{ablation}. Resnet34 experiments are performed with minibatch size, $B= 32$ and Alexnet models are trained with $B= 24$. We use $\mu=4$ for all our experiments. We use SGD optimizer with a momentum of $0.9$ and an initial learning rate of $0.01$ with cosine learning rate decay for all our experiments. Weight decay is set to $0.0005$ for all our models. Other details of the experiments are included in the Appendix.
\subsection{Baselines}
We compare our CLDA framework with previous state-of-the-art SSDA approaches : \textbf{MME} ~\cite{Saito2019SemiSupervisedDA}, \textbf{APE} ~\cite{Kim2020AttractPA}, \textbf{BiAT} ~\cite{Jiang2020BidirectionalAT} , \textbf{UODA} ~\cite{Qin2020Contradictory}, ~\textbf{Meta-MME} ~\cite{Li2020OnlineMF} and ~\textbf{ENT} ~\cite{Grandvalet2004SemisupervisedLB} using the performance reported by these papers. papers. We also included the results from adversarial based baseline methods:
% DANN [12] ,ADR
% 212 [43] and CDANWe also include the results from UDA (Unsupervised Domain Adaptation) based baseline methods using the adversarial approach for the Semi-Supervised Domain Adaptation task: 
\textbf{DANN} ~\cite{Ganin2016DomainAdversarialTO}, \textbf{ADR} ~\cite{Saito2018AdversarialDR} and \textbf{CDAN} ~\cite{Long2018ConditionalAD} as reported in \cite{Saito2019SemiSupervisedDA}. We also provide the \textbf{S+T} results where the model is trained using all the labeled samples across domains.
\begin{table}[!t]
\caption{ \textbf{Performance Comparison in Office-Home.} Numbers show top-1 accuracy values for different domain adaptation scenarios under 3-shot setting using Alexnet and Resnet34 as backbone networks. We have highlighted the best method for each transfer task. CLDA surpasses all the baseline methods in most adaptation scenarios. Our Proposed framework achieves the best average performance among all compared methods.
}
\renewcommand{\arraystretch}{1.2}
\vspace{2mm}
\centering
\label{base_office_home_table}
\resizebox{\columnwidth}{!}{
\begin{tabular}{c|c|cccccccccccc|c}
\specialrule{.1em}{.05em}{.05em}
Net & Method & Rl$\rightarrow$Cl & Rl$\rightarrow$Pr & Rl$\rightarrow$Ar & Pr$\rightarrow$Rl & Pr$\rightarrow$Cl & Pr$\rightarrow$Ar & Ar$\rightarrow$Pl & Ar$\rightarrow$Cl & Ar$\rightarrow$Rl & Cl$\rightarrow$Rl & Cl$\rightarrow$Ar & Cl$\rightarrow$Pr & Mean \\
\hline
\multirow{8}{*}{Alexnet} & S+T & 44.6 & 66.7 & 47.7 & 57.8 & 44.4 & 36.1 & 57.6 & 38.8 & 57.0 & 54.3 & 37.5 & 57.9 & 50.0 \\
 & DANN & 47.2 & 66.7 & 46.6 & 58.1 & 44.4 & 36.1 & 57.2 & 39.8 & 56.6 & 54.3 & 38.6 & 57.9 & 50.3 \\
 & ADR  & 37.8 & 63.5 & 45.4 & 53.5 & 32.5 & 32.2 & 49.5 & 31.8 & 53.4 & 49.7 & 34.2 & 50.4 & 44.5 \\
& CDAN & 36.1 & 62.3 & 42.2 & 52.7 & 28.0 & 27.8 & 48.7 & 28.0 & 51.3 & 41.0 & 26.8 & 49.9 & 41.2 \\
 & ENT & 44.9 & 70.4 & 47.1 & 60.3 & 41.2 & 34.6 & 60.7 & 37.8 & 60.5 & 58.0 & 31.8 & 63.4 & 50.9 \\
 & MME & 51.2 & 73.0 & 50.3 & 61.6 & 47.2 & 40.7 & 63.9 & 43.8 & 61.4 & 59.9 & 44.7 & 64.7 & 55.2 \\
 & Meta-MME & 50.3 & - & - & - & 48.3 & 40.3 & - & 44.5 & - & - & 44.5 & - & - \\
 & BiAT & - & - & - & - & - & - & - & - & - & - & - & - & 56.4 \\
 & APE & \textbf{51.9} & \textbf{74.6} & 51.2 & 61.6 & 47.9 & 42.1 & 65.5 & 44.5 & 60.9 & 58.1 & 44.3 & 64.8 & 55.6 \\
 & \textbf{CLDA}(ours) & 51.5 & 74.1 & \textbf{54.3} & \textbf{67.0} & \textbf{47.9} & \textbf{47.0} & \textbf{65.8} & \textbf{47.4} & \textbf{66.6} & \textbf{64.1} & \textbf{46.8} & \textbf{67.5} & \textbf{58.3} \\
\hline
\hline
\multirow{7}{*}{Resnet34} & S+T & 55.7 & 80.8 & 67.8 & 73.1 & 53.8 & 63.5 & 73.1 & 54.0 & 74.2 & 68.3 & 57.6 & 72.3 & 66.2 \\
 & DANN & 57.3 & 75.5 & 65.2 & 69.2 & 51.8 & 56.6 & 68.3 & 54.7 & 73.8 & 67.1 & 55.1 & 67.5 & 63.5 \\
 & ENT & 62.6 & 85.7 & 70.2 & 79.9 & 60.5 & 63.9 & 79.5 & 61.3 & 79.1 & 76.4 & 64.7 & 79.1 & 71.9 \\
 & MME & 64.6 & 85.5 & 71.3 & 80.1 & 64.6 & 65.5 & 79.0 & 63.6 & 79.7 & 76.6 & 67.2 & 79.3 & 73.1 \\
 & Meta-MME & 65.2 & - & - & - & 64.5 & 66.7 & - & 63.3 & - & - & 67.5 & - & - \\
 & APE & \textbf{66.4} & 86.2 & 73.4 & 82.0 & \textbf{65.2} & 66.1 & 81.1 & \textbf{63.9} & 80.2 & 76.8 & 66.6 & 79.9 & 74.0 \\
 & \textbf{CLDA} (ours) & 66.0 & \textbf{87.6} & \textbf{76.7} & \textbf{82.2} & 63.9 & \textbf{72.4} & \textbf{81.4} & 63.4 & \textbf{81.3} & \textbf{80.3} & \textbf{70.5} & \textbf{80.9} & \textbf{75.5} \\
\specialrule{.1em}{.05em}{.05em}
\end{tabular}}

\vspace{2mm}
\end{table}
% %------------------------------------------------------------------------- 
% %-------------------------------------------------------------------------
\subsection{Results}
Table  ~\ref{base_office_home_table}- ~\ref{base_office_table} show  top-1 accuracies  and mean accuracies for different combination of domain adaptation scenarios for all three datasets in comparison with baseline SSDA methods.

\noindent\textbf{Office-Home.} Table ~\ref{base_office_home_table} contains the results of the Office-Home dataset for 3-shot setting with Alexnet and Resnet34 as backbone networks. Results for the $1$-shot adaptation scenarios are included in the Appendix ~\ref{office_home_1_shot}. 
Our method consistently performs better than the baseline approaches and achieves $58.3\%$  and $75.5\%$ mean accuracy with Alexnet and Resnet34, respectively. Our approach surpasses the state-of-the-art SSDA approaches in most of the adaptation tasks. In some domain adaptation cases, such as Cl $\rightarrow$ Rl, Rl $\rightarrow$ Ar and Pr $\rightarrow$ Ar, we exceeded APE by more than $3\%$.

\noindent\textbf{DomainNet}: Our CLDA approach surpasses the performance of existing SSDA baselines as shown in Table ~\ref{base_domainNet_table}. Using Alexnet backbone, our method improves over BiAT by $5.2\%$ and $4.9\%$ in 1-shot and 3-shot settings, respectively. We obtain similarly improved performance when we switch the neural backbone from Alexnet to Resnet34. With Resnet34 as the backbone, we gain $4.3\%$ and $3.6\%$ over APE in 1-shot and 3-shot settings, respectively. Similar to the Office-Home, our approach surpasses the well-known domain adaptation benchmarks methods in most domain adaptation tasks of the DomainNet dataset. Such consistent improved performance shows that our approach reduces both inter and intra domain discrepancy prevalent in SSDA. 

\noindent\textbf{Office31}: Similar to other datasets, our proposed method with Alexnet and VGG as neural backbone achieves the best performance in both domain adaption scenarios for office31 as shown in Table ~\ref{base_office_table}. Using Alexnet backbone, we beat the APE ~\cite{Kim2020AttractPA} by $3.2\%$ in 3-shot and BiAT by $7.3\%$ in 1-shot settings. We observe similar gains over all the baselines methods with VGG as the neural network backbone. This shows the efficacy of our proposed approach irrespective of the used backbone.







\begin{table}[!t]

\caption{ \textbf{Performance Comparison in DomainNet.} Numbers show Top-1 accuracy values for different domain adaptation scenarios under 1-shot and 3-shot settings using Alexnet and Resnet34 as backbone networks. CLDA achieves better performance than all the baseline methods in most of the domain adaptation tasks. We have highlighted the best approach for each domain adaptation task. Our Proposed framework achieves the best average performance among all compared methods.
}
\renewcommand{\arraystretch}{1.2}
\vspace{2mm}
\label{base_domainNet_table}
\begin{center}{
\resizebox{\columnwidth}{!}{
\begin{tabular}{c|c|cccccccccccccc|cc}
\specialrule{.1em}{.05em}{.05em}
\multirow{2}{*}{Net} & \multirow{2}{*}{Method} & \multicolumn{2}{c}{R$\rightarrow$C} & \multicolumn{2}{c}{R$\rightarrow$P} & \multicolumn{2}{c}{P$\rightarrow$C} & \multicolumn{2}{c}{C$\rightarrow$S} & \multicolumn{2}{c}{S$\rightarrow$P} & \multicolumn{2}{c}{R$\rightarrow$S} & \multicolumn{2}{c|}{P$\rightarrow$R} & \multicolumn{2}{c}{Mean} \\
 & & 1-shot & 3-shot & 1-shot & 3-shot & 1-shot & 3-shot & 1-shot & 3-shot & 1-shot & 3-shot & 1-shot & 3-shot & 1-shot & 3-shot & 1-shot & 3-shot \\ \hline
\multirow{8}{*}{Alexnet} & S+T & 43.3 & 47.1 & 42.4 & 45.0 & 40.1 & 44.9 & 33.6 & 36.4 & 35.7 & 38.4 & 29.1 & 33.3 & 55.8 & 58.7 & 40.0 & 43.4 \\
 & DANN & 43.3 & 46.1 & 41.6 & 43.8 & 39.1 & 41.0 & 35.9 & 36.5 & 36.9 & 38.9 & 32.5 & 33.4 & 53.5 & 57.3 & 40.4 & 42.4 \\
 & ADR      & 43.1 & 46.2 & 41.4 & 44.4 & 39.3 & 43.6 & 32.8 & 36.4 & 33.1 & 38.9 & 29.1 & 32.4 & 55.9 & 57.3 & 39.2 & 42.7 \\
 & CDAN     & 46.3 & 46.8 & 45.7 & 45.0 & 38.3 & 42.3 & 27.5 & 29.5 & 30.2 & 33.7 & 28.8 & 31.3 & 56.7 & 58.7 & 39.1 & 41.0 \\
 & ENT & 37.0 & 45.5 & 35.6 & 42.6 & 26.8 & 40.4 & 18.9 & 31.1 & 15.1 & 29.6 & 18.0 & 29.6 & 52.2 & 60.0 & 29.1 & 39.8 \\
 & MME & 48.9 & 55.6 & 48.0 & 49.0 & 46.7 & 51.7 & 36.3 & 39.4 & 39.4 & 43.0 & 33.3 & 37.9 & 56.8 & 60.7 & 44.2 & 48.2 \\
 & Meta-MME & - & 56.4 & - & 50.2 & & 51.9 & - & 39.6 & - & 43.7 & - & 38.7 & - & 60.7 & - & 48.8 \\
 & BiAT & 54.2 & 58.6 & 49.2 & 50.6 & 44.0 & 52.0 & 37.7 & 41.9 & 39.6 & 42.1 & 37.2 & 42.0 & 56.9 & 58.8 & 45.5 & 49.4 \\
 & APE & 47.7 & 54.6 & 49.0 & 50.5 & 46.9 & 52.1 & 38.5 & 42.6 & 38.5 & 42.2 & 33.8 & 38.7 & 57.5 & 61.4 & 44.6 & 48.9 \\
 & \textbf{CLDA} (ours) & \textbf{56.3} & \textbf{59.9} & \textbf{56.0} & \textbf{57.2} & \textbf{50.8} & \textbf{54.6} & \textbf{42.5} & \textbf{47.3} & \textbf{46.8} & \textbf{51.4} & \textbf{38.0} & \textbf{42.7} & \textbf{64.4} & \textbf{67.0} & \textbf{50.7} & \textbf{54.3} \\ 
\hline
\hline
\multirow{9}{*}{Resnet34} & S+T & 55.6 & 60.0 & 60.6 & 62.2 & 56.8 & 59.4 & 50.8 & 55.0 & 56.0 & 59.5 & 46.3 & 50.1 & 71.8 & 73.9 & 56.9 & 60.0 \\
 & DANN & 58.2 & 59.8 & 61.4 & 62.8 & 56.3 & 59.6 & 52.8 & 55.4 & 57.4 & 59.9 & 52.2 & 54.9 & 70.3 & 72.2 & 58.4 & 60.7 \\
  & ADR      & 57.1 & 60.7 & 61.3 & 61.9 & 57.0 & 60.7 & 51.0 & 54.4 & 56.0 & 59.9 & 49.0 & 51.1 & 72.0 & 74.2 & 57.6 & 60.4 \\
 & CDAN     & 65.0 & 69.0 & 64.9 & 67.3 & 63.7 & 68.4 & 53.1 & 57.8 & 63.4 & 65.3 & 54.5 & 59.0 & 73.2 & 78.5 & 62.5 & 66.5 \\
 & ENT & 65.2 & 71.0 & 65.9 & 69.2 & 65.4 & 71.1 & 54.6 & 60.0 & 59.7 & 62.1 & 52.1 & 61.1 & 75.0 & 78.6 & 62.6 & 67.6 \\
 & MME & 70.0 & 72.2 & 67.7 & 69.7 & 69.0 & 71.7 & 56.3 & 61.8 & 64.8 & 66.8 & 61.0 & 61.9 & 76.1 & 78.5 & 66.4 & 68.9 \\
 & UODA & 72.7 & 75.4 & 70.3 & 71.5 & 69.8 & 73.2 & 60.5 & 64.1 & 66.4 & 69.4 & 62.7 & 64.2 & 77.3 & 80.8 & 68.5 & 71.2 \\
 & Meta-MME & - & 73.5 & - & 70.3 & - & 72.8 & - & 62.8 & - & 68.0 & - & 63.8 & - & 79.2 & - & 70.1 \\
 & BiAT & 73.0 & 74.9 & 68.0 & 68.8 & 71.6 & 74.6 & 57.9 & 61.5 & 63.9 & 67.5 & 58.5 & 62.1 & 77.0 & 78.6 & 67.1 & 69.7 \\
 & APE & 70.4 & 76.6 & 70.8 & 72.1 & \textbf{72.9} & \textbf{76.7} & 56.7 & 63.1 & 64.5 & 66.1 & 63.0 & 67.8 & 76.6 & 79.4 & 67.6 & 71.7 \\
 & \textbf{CLDA} (ours) & \textbf{76.1} & \textbf{77.7} & \textbf{75.1} & \textbf{75.7} & 71.0 & 76.4 & \textbf{63.7} & \textbf{69.7} & \textbf{70.2} & \textbf{73.7} & \textbf{67.1} & \textbf{71.1} & \textbf{80.1} & \textbf{82.9} & \textbf{71.9} & \textbf{75.3} \\ 
 \specialrule{.1em}{.05em}{.05em}
 
\end{tabular}}}
\end{center}
\end{table}
%------------------------------------------------------------------------- 

% %-------------------------------------------------------------------------

\begin{table}[t]
\centering
\caption{ \textbf{Performance Comparison in Office31.} Numbers show Top-1 accuracy values for different domain adaptation scenarios under 1-shot and 3-shot settings using Alexnet and VGG as backbone networks. CLDA outperforms all the baseline approaches in both scenarios. We have highlighted the superior method on each domain adaptation task. Our Proposed framework achieves the best mean accuracy among all baseline methods.
}
\renewcommand{\arraystretch}{1.2}
\label{base_office_table}
\begin{center}{
\resizebox{\columnwidth}{!}{
\begin{tabular}{c|cc|cc|cc||cc|cc|cc}
\specialrule{.1em}{.05em}{.05em}
\multicolumn{7}{c}{Alexnet} & \multicolumn{6}{c}{VGG} \\
\hline
 \multirow{3}{*}{Method} & \multicolumn{2}{c}{W$\rightarrow$A} & \multicolumn{2}{c|}{D$\rightarrow$A} & \multicolumn{2}{c}{Mean} & \multicolumn{2}{c}{W$\rightarrow$A} & \multicolumn{2}{c|}{D$\rightarrow$A} & \multicolumn{2}{c}{Mean}\\
 & 1-shot & 3-shot & 1-shot & 3-shot & 1-shot & 3-shot & 1-shot & 3-shot & 1-shot & 3-shot & 1-shot & 3-shot \\ \hline
 S+T & 50.4 & 61.2 & 50.0 & 62.4 & 50.2 & 61.8 &169.2 &73.2 &68.2 &73.3 &68.7 &73.25 \\
 DANN & 57.0 & 64.4 & 54.5 & 65.2 & 55.8 & 64.8 &69.3 &75.4 &70.4 &74.6 &69.85 &75.0\\
 ADR & 50.2 & 61.2 & 50.9 & 61.4 & 50.6 & 61.3 &69.7 &73.3 &69.2 &74.1 &69.45 &73.7\\
 CDAN & 50.4 & 60.3 & 48.5 & 61.4 & 49.5 & 60.8 &65.9 &74.4 &64.4 &71.4 &65.15 &72.9\\
 ENT & 50.7 & 64.0 & 50.0 & 66.2 & 50.4 & 65.1 &69.1 &75.4 &72.1 &75.1 &70.6 &75.25\\
 MME & 57.2 & 67.3 & 55.8 & 67.8 & 56.5 & 67.6 &73.1 &76.3 &73.6 &\textbf{77.6} &73.35 &76.95\\
BiAT & 57.9 & 68.2 & 54.6 & 68.5 & 56.3 & 68.4 &- &- &- &- &- &- \\
 APE & - & 67.6 & - & 69.0 & - & 68.3 &- &- &- &- &- &-\\
 CLDA & \textbf{64.6} & \textbf{70.5} & \textbf{62.7} & \textbf{72.5} & \textbf{63.6} & \textbf{71.5} &\textbf{76.2} &\textbf{78.6} &\textbf{75.1} &76.7 &\textbf{75.6} &\textbf{77.6} \\
\specialrule{.1em}{.05em}{.05em}
\end{tabular}}}
% \vspace{-2.0mm}
\end{center}
\end{table}


\input{Ablation}
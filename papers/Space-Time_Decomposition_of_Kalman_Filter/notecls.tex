\documentclass{report}

\usepackage{amsfonts,latexsym}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage[latin1]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath}








\begin{document}

\section{Validation Results}


We perform  validation and parallel efficiency of the proposed  approach.\\ Simulation results are implemented using MATLABR2019b and 
Parallel Computing Toolbox on a laptop  with  1.6GHz CPU with 2 physical cores, 4 logical cores (i.e. numbers of threads) and 4 GB of memory.
\\
Parallel Computing Toolbox lets us solve computationally and data-intensive problems using multicore processors and use the full processing power of multicore desktops by executing applications on workers (MATLAB computational engines) that run locally.\\
\noindent The proposed approach involves the decomposition of the domain (set) $I=\{1,\ldots,n\}$ with $n\in \mathbb{N}$ into $nsub<n$ subdomains (sets) as follows:
\begin{displaymath}
\begin{split}
 I_ {1}:=\{1,\ldots,\frac{n}{nsub}\}, \quad  & I_ {2}:=\{\frac{n}{nsub}+1,\ldots,2\cdot \frac{n}{nsub}\}, \ldots,\\ & I_{nsub}:=\{\frac{n}{nsub}\cdot (nsub-1),\ldots,  \frac{n}{nsub}\cdot (nsub)\}.
 \end{split}
 \end{displaymath}
 Hence, we adopted the following correspondence between $p$ the number of workers and $nsub$ the number of subdomains
 \begin{displaymath}
 p\leftrightarrow nsub
 \end{displaymath}
 which means that the number of subdomains coincides with the number of workers, in this way it is possible to execute code in parallel by distributing the workload between $p$ workers by using the MATLAB statements \textit{spmd} (single program multiple data).\\ The construct \textit{spmd} lets DD-KF-CLS procedure to run simultaneously on $nsub$ workers that it can operate on a different domains and can communicate with each other while performing the parallel computations. Within the body of the \textit{spmd} statement, the communication functions \textit{labSend} and \textit{labReceive} transfer data between workers so that each worker can proceed with the parallel execution of the procedure.
\\

\\
We consider:
\begin{itemize}
\item $l=5$, $m_0\equiv n+l$, $m_1\equiv 1$, $m:=m_0+m_1$;
\item $H_{0}\in \mathbb{R}^{m_0\times n}$, $H_{1}\equiv h^{T}\in \mathbb{R}^{m_1\times n}$:  identity matrices;
\item $y_{0} \in \mathbb{R}^{m_0}$, $y_{1}\in \mathbb{R}^{m_1}$:  random vectors; 
 \item  $b=\left[\begin{array}{ll}
y_{0}, y_{1}\end{array}\right]\in \mathbb{R}^{m_0+m_1}$ the vector in (\ref{sistema_kalman}); 
\item  ${R}_{0}=0.5\cdot I$:  weight matrix, with $I\in \mathbb{R}^{ m_0\times m_0}$ identity matrix, $R_{1}=0.5$ and $R=diag(R_{0},R_{1})\in\mathbb{R}^{m_0+m_1\times m_0+m_1}$  weight matrix.
\end{itemize}
This choice of data involves exchanges of data only between two adjacent subdomains and allows us to apply the DD-KF-CLS procedure for $nsub>2$, in particular, $nsub$ must be a multiple of 2.
\\
\\

\noindent We underline that the dimension $r:=((m_0+m_1)\cdot n)$ of CLS problem in (\ref{minimi_quadrati}) depends on numbers of rows $m_0$, columns $n$ of matrix $H_0$ and the number of rows $m_1$ of matrix $H_1$, in particular, we define $m_0:=n+l$ with $l, m_1\in \mathbb{N}$ fixed, thus it only depends on $n$. \\
\\
 We apply the DD approach to  CLS problem in (\ref{minimi_quadrati}) by using:
 \begin{itemize}
 \item  $nmax=50$:  maximum number of iterations; 
 \item $k=1$: step of KF method;
\item $tol=10^{-6}$: tolerance.
\end{itemize}

We compute:
\begin{itemize}
\item $T^1(n)$: the amount of time to compute the solution problem CLS in (\ref{minimi_quadrati}) using a serial procedure i.e.  KF method;
\item $T^p(\frac{n}{p})$: the amount of time to compute the solution problem CLS in (\ref{minimi_quadrati}) using DD-KF-CLS method on $p$ workers;
\item $\frac{S}{V}(\frac{n}{p}):=\frac{T_{oh}(\frac{n}{p})}{T^1(\frac{n}{p})}$: the surface-to-volume ratio, i.e. it is a measure of amount of data exchange where $T_{oh}(\frac{n}{p})$ is an overhead which is given by synchronization, memory accesses and communication time;
\item  
$s_{loc}^{p}(\frac{n}{p}):=\frac{T^1(\frac{n}{p})}{T^p(\frac{n}{p})}$: local speed-up;
\item
$Sc_{1,p}(\frac{n}{p}):=\frac{T^1(n)}{p\cdot (T^{1}(\frac{n}{p})+T_{oh}(\frac{n}{p})}$: scale-upr.
\item $Sc_{p,1}^{f}(n/p)=\frac{T^{1}(n)}{p\cdot T^{1}(\frac{n}{p})}$: relative scale up.
\end{itemize}


\noindent We discuss the performance of DD-KF-CLS procedure by measuring scalability in term of \textit{strong scaling} (which is the measure of the alghorithm's capability to exploit performance of emerging computing architectures in order to get a solution in a suitable acceptable time), and \textit{weak scaling} (which is the measure of the algorithm's capability to use additional computational resources effectively to solve increasingly larger problems).
\\
\\
\noindent For the \textit{strong scaling} analysis, fixed $p=2$ and $p=4$, in Table \ref{tab3} we report the values of the scale up $Sc_{1,p}^{means}\left({n}/{p}\right)$ we have computed as follows (proved in \cite{JPP})
\begin{equation}
Sc_{1,p}^{means}\left(\frac{n}{p}\right)=\alpha(n,p)\cdot Sc_{1,p}^{f}\left(\frac{n}{p}\right)
\end{equation}
where
\begin{equation}
\alpha(n,p)=\frac{s_{loc}^{p}\left(\frac{n}{p}\right)}{1+s_{loc}^{p}\left(\frac{n}{p}\right)\cdot \frac{S}{V}\left(\frac{n}{p}\right)}
\end{equation}
by starting from the values in Table \ref{tab1}.
\\
\\
In Table \ref{tab2} we observe that the values of local speed up are $s_{loc}^{p}({{n}/{p}})>1$ as proved in \cite{JPP} and the values of scale upr satisfy the condition
\begin{equation}\label{cond_scaleup}
Sc_{1,p}^{means}\left(\frac{n}{p}\right)>Sc_{1,p}^{f}\left(\frac{n}{p}\right)
\end{equation}
where $Sc_{1,p}^{f}\left({n}/{p}\right)=p^{2}$ as described in\cite{JSC}.
\\
\\
\noindent For the \textit{weak scaling} analysis, fixed $N=256$ and for $n=p\cdot N$ we computed the values of $Sc_{1,p}^{means}\left({n}/{p}\right)$  $\forall p=2,4,8$.\\ We observe that the values of scale up satisfy the condition in (\ref{cond_scaleup}) 
except the value $Sc_{1,p}^{means}\left({n}/{p}\right)$ for $p=8$, this depends on MATLABR2019b with Parallel Computing Toolbox that allows us to consider as the maximum number of worker (consequently of subdomains) the number of logical cores (i.e. 4 logical cores) and consequently considering $p>4$ not improve performance.
\\
\\
Performance results obtained confirm that the DD-KF-CLS approach allows us to leads to an effective reduction of the overall execution time needed to solve the global problem. This approach produced a reduction of overall execution time needed to solve the problem CLS in (\ref{minimiquadrati}) and a reduction of execution time needed to solve the problem. 
\\



 \begin{table}
\caption{Results computed for $n = 512$ and dimension $r:=(m_0+m_1)\cdot n=(n+6)\cdot n$ of CLS problem in  (\ref{minimiquadrati}) for $p = 2,4$ subdomains/workers.}
\label{tab1}
\\
\centering
\begin{tabular}{rlllllllllll}
\hline
\\
 $p$ &  $n/p$  & $\frac{S}{V}(n/p)$& $\alpha(r,p)$ \ \ \ \ $T^1(n/p)$ \ \ \ \  $T^p(n/p)$ \ \ \ \ \ \  $s_{loc}^p(n/p)$\\
 \\
\hline
$2$ & 256 &  $ 1.13\cdot 10^{-2}$ &$2.02$ \ \ \ \ \ \ \ $5.16\cdot 10^{-1}$ \ \  $2.50\cdot 10^{-1}$ \ \ \ $2.07$  \\
\\
$4$  & 128  &$7.58\cdot 10^{-1}$ &$1.01$ \ \ \ \ \ \ \ $6.48\cdot 10^{-1}$ \ \  $1.53\cdot 10^{-1}$\ \ \ \  $4.23$ \\
\hline 
\end{tabular}
\end{table} 




 \begin{table}
\caption{Strong Scaling. Scalability measures of DD-KF.CLS procedure computed with respect the values in Table \ref{tab2}.}
\label{tab2}
\\
\centering
\begin{tabular}{rlllllllllll}
\hline
\\
$p$ & $Sc_{1,p}^{means}(\frac{n}{p})$&$Sc_{1,p}^{f}(\frac{n}{p})$\\
\\
\hline 
$2$&$8.09$&4\\
\\
$4$&$16.11$&16\\
\hline
\end{tabular}
\end{table} 







\begin{table}
\caption{Weak Scaling. Scalability prediction of DD-KF-CLS procedure computed by fixing $N=256$ and for $n=p\cdot N$, $\forall p=2,4,8$.}
\label{tab3}
\\
\centering
\begin{tabular}{r|lllllllllll}
\hline
\\
$p$   & $2$ & $4$  &  $8$    \\
\\
\hline
\\
$n$& $128$& $256$& $512$\\
\\
\hline
\\
$r$&$265216$& $1054720$&$4206592$\\
\\
\hline
\\
$Sc_{1,p}^{means}$& $8.09 \cdot 10^{0}$ &$7.11\cdot 10^{2}$&$17.99\cdot 10^{0}$\\
\hline
\end{tabular}
\end{table} 














\end{document}
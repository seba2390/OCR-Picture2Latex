\section{Appendix}
\subsection{Supplementary Text and Experiment}
\subsubsection{Sink Functions}
\label{appendix:sinkfunctions}
In addition to \autoref{table:sinkfunctions}, \autoref{table:additional_sink_functions} provides additional sink functions for XML and database subsystems.

\input{tex/table_appendix_sinks.tex}


% \subsection{Details of Selected Programs and Vulnerability}
% \label{appendix:details_selected_programs}

% \autoref{table:vulnanddescription} presents
% detailed descriptions of the target applications and vulnerabilities we used in the evaluation in Section~\ref{sec:eval}.
% The first column shows the program ID that corresponds to the first column of \autoref{table:selectedprograms}.
% The third column shows the vulnerabilities that we used in our evaluation with citations. The last column presents brief descriptions of the applications.

%As shown in the last column, there are three different results: 
%{\it Command not found}, {\it File not found}, and {\it Time out}.
%The first two essentially mean that the exploit failed to execute the command as the command is already randomized. Time out happens because the program waits for the completion of the command while the command will never be completed as it fails to execute.


% \input{tex/table_vulnAndDescrption}

\subsubsection{Automated Vulnerability Discovery Tools}
\label{appendix:vulnerability_discovery_tools}
Commix~\cite{commix} is an automated testing tool that aims to find command injection vulnerabilities on web server-side applications.
We test all programs except for \code{s4} and \code{s5} which do not have functions executing OS/shell commands. 
%Note that they are tested for SQL injection and XXE injection attacks later in this section.
%Among them, \code{Commix} were not able to find command injection vulnerability in \code{s5}, \code{s6} 
%In this experiment, we choose five different applications: . \code{s2} is WordPress Plainview Activity Monotor plugin which represents the typical PHP program.
%\code{s7} is \code{Leptonica} image processing library and it is the C program with the most instrument statements. 
%\code{s10} is the only program running on the embedded devices, and at the same time, it has the most instrument statements of all the programs. \code{s20} is the largest JavaScript program in our cases.
%
%To use Commix, we define all the input interfaces for each target program. 
%Then, it automatically injects malicious commands to the target programs.
Commix identified vulnerabilities shown in \autoref{table:selectedprograms}, and successfully executed 102 malicious commands, while it failed to do so for \sysname protected programs. %. The result shows that \sysname protects all the injected commands.
sqlmap~\cite{sqlmap} is a penetration testing tool for SQL injection vulnerability testing. We apply sqlmap to the applications that use SQL database engines: \code{s1} (WordPress), \code{s5} (Pie Register), and \code{s6} (Lighttpd).
We instruct sqlmap to inject the SQL statements through typical input channels (e.g., \code{GET} and \code{POST} requests).
sqlmap supports various types of injection attack payloads, including boolean blind SQL injection, error-based SQL injection, stacked queries SQL injection, and time blind SQL injection, just to name a few.
\sysname mitigates all the injected statements. %failed to be executed, while they were successfully injected in vanilla versions.
%(e.g., \code{PUT} 
%We installed the vulnerable \code{s5} (Pie Register) on the server and defines the \code{sqlmap} use \code{PUT} to send a generated payload to the program. 
%And it succeeded in finding time-based sql injection vulnerability. Then we tested it with our \sysname, the \code{Sqlmap} fails to exploit the vulnerability.\mw{add data} 
%In the test, we use various methods to try to exploit the vulnerability including boolean blind sql injection, error based sql injection, inline query sql injection, stacked queries sql injection, time blind sql injection and union query sql injection. In all there are 97 different kinds of payloads.
% http://sqlmap.org/
% blackhat europe 2009 https://www.blackhat.com/presentations/bh-europe-09/Guimaraes/Blackhat-europe-09-Damele-SQLInjection-whitepaper.pdf
%We use \code{xcat} \cite{xcat} to test our \sysname on XML injection. 
xcat~\cite{xcat} is a command line tool to exploit and investigate XML injection vulnerabilities. We tested \code{s4} and \code{s5}, which are vulnerable to the XXE injection. 
%
%Note that while the program is a plugin of WordPress. As it has compatible issues with the current version of \code{WordPress}, we fix the issues for this experiment.
%
xcat successfully discovers XXE injection vulnerability in the original programs while it failed with the \sysname protected application.
%Because the \code{Advanced XML Reader} is a project not maintained for 6 years, it has server compatible problem with the current \code{Wordpress} and \code{PHP}. 
%So we modify the part of its source code to make it can work on the newer version environment. 
%We use \code{Xcat} set a built-in out of bound server to test if it exists XXE injection vulnerability. We define the vulnerable parameter and xpath query for the \code{xcat}. It succeeded in finding the XXE injection vulnerability but after applyintg \sysname to the program. \code{xcat} cannot find any potential vulnerability. 
%https://github.com/orf/xcat




\subsubsection{Overhead on Database Engines}
\label{appendix:overhead_database_engines}

%In Section~\ref{subsec:eval_perf}, we apply \sysname to SQLite and MySQL to evaluate performance overhead of \sysname on database engines.
We use OLTP-Bench~\cite{difallah2013oltp}, which is an extensible testbed for benchmarking relational databases. 
It provides 15 data-sets. However, when we test the data-sets on the vanilla MySQL and SQLite, \emph{only three data-sets (TPC-C, Wikipedia, and Twitter) were successfully completed} while all others lead to crashes. 
Hence, we select the three working data-sets.
%\autoref{table:OverheadDB} shows the result. 
The average overheads are 4.9\% and 5.3\% for SQLite and MySQL respectively. % less than 5.5\%. %SQLite is slightly faster than MySQL due to the complexity of MySQL leading to additional instrumentations.

%\input{tex/table_db_overhead}


\subsubsection{Overhead on XML Library}
\label{appendix:microbenchmarks_xml}
%In Section~\ref{subsec:eval_perf}, we evaluate the performance overhead of \sysname on four popular XML parsers.
We use Libxml~\cite{libxml}, SimpleXML~\cite{simplexml}, libxmljs~\cite{libxmljs}, and LuaExpat~\cite{luaexpat}. 
%
For XML test-data, we download a data-set (1GB in total) from the University of Washington~\cite{xmldata}.
The average overheads are 1.5\%, 1.38\%, 1.43\%, and 1.29\% for Libxml, SimpleXML, LuaExpat, and libxmljs respectively.

% http://aiweb.cs.washington.edu/research/projects/xmltk/xmldata/
%There are 11 different files. Ten of the files are taken from UW XML data repository). 
%Note that the XML files are fairly large .
%In \autoref{fig:Perf_xml}, the first 10 results from Protein Sqeuence to Mondial are from the XML data repository~\cite{xmldata}.

% We test XML parser in parsing and handling XML files with external entities. Specifically, we use the existing XML files and inject randomly generated 30 external entities. 
% We measure the loading and processing time of XML parsers. % spent on loading and generating output. 
% Note that in practice, external entities are not frequently used. 
% Hence, we choose to inject 30 entities to measure performance conservatively. 
% The overhead for the external entity is around 4\%. % on all of them.

% \begin{figure}[ht]
%     \centering
%     \includegraphics[width=1.0\columnwidth]{fig/xml_perf.pdf}
%     \vspace{-2em}
%      \caption{Performance on XML Libraries}
%      \label{fig:Perf_xml}
%      \vspace{-1em}
% \end{figure}


%The last task is an XML file filled with 30 different external entities. We are evaluating the time spent on loading and generating output. 
%http://aiweb.cs.washington.edu/research/projects/xmltk/xmldata/


% \subsubsection{Overhead on Instrumented APIs}
% \label{appendix:microbenchmarks_apis}
% We conduct microbenchmarks to understand the performance overhead imposed on each instrumented API.
% Specifically, we create a simple program that repeatedly calls instrumented APIs to measure overhead. 
% As programs written in different programming languages may lead to different overhead results, we conduct tests on programs written in all programming languages we support.
% %Specifically, we tested the overhead on different programming language by comparing the execution time of some simple programs

% As executing a long-running command may lead to a favorable result for \sysname, we choose lightweight commands such as \code{whoami}, \code{ls}, and \code{id}. We repeat each test 100 times and take the average. Similarly, we use simple SQL and XML queries to measure the performance per each API call.
% The normalized overhead result is shown in \autoref{table:single_perf}.
% %\code{whoami; ls; id} for 100 times. The normalized overhead is shown in the below table for different languages.
% \input{tex/table_single_execution}

\subsubsection{Overhead on OpenWrt}
\label{appendix:embedded_devices_perf}
We applied \sysname to the OpenWrt firmware's uHTTPd~\cite{uHTTPd} web server and LuCI web configuration interface~\cite{LuCI}.
%LuCI runs instrumented functions such as \code{os.execute()}, and we confirm that the test cases cover the instrumented functions.
%As they do not run on the authors' workstation, which is x64, 
We use QEMU~\cite{QEMU} to run OpenWrt ARM firmware with 256MB RAM, which represents the standard router hardware specification. 
%
%uhttpd is the official webserver used by Openwrt project to run the Luci Configuration Interface. 
We use Apache Jmeter to generate 1,000 concurrent requests to visit the LuCI interface to get system status information. 
Note that 1,000 parallel requests are sufficient to exhaust the test system's resources and the test workload is more intensive than the common usage.
%
The average overhead is 5.83\%.
%to retrieve system information or status from the router and present it on the web page. 
%Our test's pressure is much higher than the common usage, but the overhead is still around 3\%.

\subsubsection{Versions of the Evaluated Programs}
\label{appendix:versions}
\autoref{table:versions} shows the versions of all the evaluated programs including those in \autoref{table:extra_programs}.

\input{tex/table_versions.tex}


\subsubsection{Trusted Command Specification (TCS) Generation Tool}
\label{appendix:tcstool}
We provide an automated trusted command specification generation tool~\cite{csr-tool} that takes a list of sink-functions (e.g., \autoref{table:sinkfunctions}) and trusted-folders (e.g., \code{/var/www/}) as input. It derived all the TCSs used in the paper without significant domain-knowledge and completed the analysis in less than four minutes. 
%Our project website~\cite{csr-tool} also presents the inputs for this tool. 
It can also detect incomplete specifications (e.g., untrusted commands passed to sink-functions). Note that we did not observe incomplete specifications.

\noindent
{\bf Performance of TCS Generator.}
\autoref{table:tcs_time} shows the time required to generate the TCS by our TCS generator. We generate the same TCS used in our evaluation. Note that generating TCS for Leptonica (s8) took the longest time: 217.75 seconds, which is 3 min 37.75 seconds.

\input{tex/table_time_gen_tcs}




\subsection{Effectiveness of \sysname}

\revised{
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Applicability of \sysname} 
To understand whether \sysname can be a generic solution for various applications, we additionally collect the five most popular applications from three well-known open-source package managers (NPM~\cite{npmpackage}, Packagist~\cite{packagist} and WordPress Plugin~\cite{wordpressplugins}) as shown in \autoref{table:extra_programs}. 
We prune out programs that are not meant to be deployed such as a unit-test framework~\cite{PHPUnit}. 
%We apply \sysname to them and the results are shown in \autoref{table:extra_programs}. 
\sysname successfully handled them without errors 
}



%\CJ{4) [2.4] (\#C) How general or application-specific is the solution?}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\revised{
\subsubsection{Correctness of Instrumentation}
\label{appendix:correctness_instrumentation}
\updated{}{
\autoref{table:selectedprograms_cov} shows the number of test cases. Our additional test cases to cover all the instrumented code and increase code coverage are shown in the ``Added'' column. 
}
}
%The experiment results in \autoref{table:selectedprograms_cov} show that our instrumentation does not break the functionalities so \sysname instrumented the applications in the correct position.} 
%\CJ{1) [1] (\#C) Correctness verification: verify the instrumentation does not break the application.}

\input{tex/table_extra_app_instru.tex}

\input{tex/table_unit_test.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Supporting Polymorphic Objects}


\begin{figure}[!h]
    \centering
    \vspace{1em}
    \includegraphics[width=1.0\columnwidth]{fig/oop_case.pdf}
    \vspace{-2em}
    \caption{\updated{}{Handling Polymorphic Objects (Red and black arrows represent backward and forward analysis respectively)}}
    \vspace{-1em}
    \label{fig:oop_case}
\end{figure}


%
\sysname supports complex real-world applications including OOP programs such as WordPress in \autoref{table:selectedprograms}.
In this example, we show that our analysis handles polymorphism and dynamic bindings. 
In particular, \autoref{fig:oop_case} shows how \sysname analyzes polymorphic objects in a WordPress plugin called Elementor~\cite{ElementorWebsiteBuilder}.
%
From line 11, we identify an instantiation of an object with a string (\code{\$class\_name}). We backtrace the string variable (annotated via red arrows), identifying that the class name starts with ``\code{Control\_}''. However, as the return value of \code{get\_control\_names()} can be updated at runtime, we conservatively assume that any class that has name starting with \code{Control\_} (i.e., \code{Control\_*}) can be created at line 11.

Then, we conduct a forward analysis to identify the object's usage (annotated through black arrows). \autoref{fig:oop_case} shows only a few of the forward flows due to space. 
%Note that our analyses (both forward and backward) are conservative, meaning that it may have false positives but no false negatives. 
We check all the omitted flows and they are not relevant to command execution. %, meaning that false positives do not cause wrong instrumentations.

%Note that our analysis is conservative which may cause false positive cases. However, with the false positives, since they are not relevant to the command execution APIs, \sysname is not affected by this limitation during our evaluation.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\revised{
\subsubsection{Effectiveness of Bidirectional Analysis}
\label{appendix:bidirectional_effectiveness}
%\sysname uses bidirectional analysis to mitigate inaccurate analysis results caused by false negative of the forward and backward analysis alone, as described in Section~\ref{sec:design}. 
This section provides an example of the effectiveness of bidirectional analysis. % mitigating false negative issues of the forward and backward analysis alone.



\begin{figure}[h]
    \centering
    \includegraphics[width=1.0\columnwidth]{fig/false_negative.pdf}
    \vspace{-2.5em}
    \caption{\updated{}{Bidirectional Analysis on WordPress}}
    \vspace{-1em}
    \label{fig:false_negative}
\end{figure}

\textit{1) Backward Analysis:} 
The backward flow analysis begins from the sink function \code{mysql\_query()} at line 32. Following the backward data flow (depicted as purple arrows), it reaches to line 38, which is a SQL query. However, the backward analysis alone is not able to identify the original of \code{\$wpdb->users} to determine whether this is from a trusted source (hence requires instrumentation) or not.
Note that the value of \code{\$wpdb->users} is assigned by dynamic construct, which is unreachable by the backward analysis. 

\textit{2) Forward Analysis:} Our forward analysis starts from trusted sources such as constant strings at lines 1, 8, and 9. \code{\$table\_prefix} (global variable) is assigned to \code{\$this->base\_prefix} at line 20 (\blkcc{1}), which will be used at line 13 in \code{tables()}. \autoref{fig:false_negative}-(b) shows values of variables at the lines marked by circled numbers.
From lines 8 and 9, the two arrays are merged at line 12 (\blkcc{2}), resulting in an array shown in \autoref{fig:false_negative}-(b). At line 15, it constructs an array consisting of pairs of table names and table names with \code{wp\_} prefix (\blkcc{3}). The composed new table (\code{\$\_table}) is returned by \code{tables()}, which is called at line 21 in \code{set\_prefix()}.
Hence, we further analyze \code{set\_prefix()} which iterates arrays shown in \autoref{fig:false_negative}-(b)-\blkcc{4}. 
Note that PHP allows a string variable to be used to specify a member variable's name in an object (line 22). To this end, the line 22 essentially executes statements shown in \autoref{fig:false_negative}-(b)-\blkcc{5}.
Note that the first statement define \code{\$this->users}, where \code{\$this} is essentially \code{\$wpdb}. 


\textit{3) Combining Forward and Backward Analysis:}
Recall that the backward analysis stops at line 37, as it was unable to resolve \code{\$wpdb->users}, while the forward analysis can resolve the value. 
Bidirectional analysis successfully finds out that the variable in the query (\code{\$wpdb->users}) is a constant string from a trusted source.
}


\subsubsection{Evaluation of Bidirectional Analysis's Accuracy}
\label{appendix:bidir_accuracy}
% https://github.com/cmd-spinner/commandrandom-spinner-php/tree/master/Supplementary/Evaluation
In this section, we explain the details of how we evaluate \sysname's bidirectional analysis's effectiveness and correctness. 
Note that since obtaining the ground-truth is challenging, we try to evaluate the bidirectional analysis's accuracy as follows.
We manually verified that all the results from our analysis are true-positives. We also run other static/dynamic taint-analysis tools~\cite{taintall, psalm, pecltaint} and compare the results (i.e., dependencies) from them with the result from \sysname. 
As shown in \autoref{table:num_detected}, we observe that \sysname covers the majority of the dependencies chains that are generated by the other tools. For dependencies not covered by \sysname, we manually check them and find that they are false-positives (hence we are not missing anything covered by other tools).

Note that during this process, we have updated and implemented a few tools. First, we update the AST parser of taintless~\cite{taintless} to the new version and add extra rules to help it handle WordPress's callback function hook.
Second, we add additional plugins to psalm~\cite{psalm} to enhance its ability on tracing data flow on object inheritance. Third, we add additional sinks to PECL taint~\cite{pecltaint} for tainting WordPress.


\noindent
{\bf Procedure of the Evaluation.}
We do our evaluation as follows. 

\begin{itemize}[leftmargin=*]
    \item [\it 1.] Run the bi-directional analysis and manually verify the dependency chains identified by the analysis. a) Manually check the propagation rules applied by the bi-directional analysis (both forward and backward analyses). b) Verify that all the dependencies identified by the bi-directional analysis are true-positives.
    
    \item [\it 2.] Run other static/dynamic analysis tools to get dependency chains (Note that static/dynamic analysis tools suffer from over and under-approximations). a) If other tools find more dependencies, then they might be potential false-negatives of the bi-directional analysis. We manually verify them all, and the result shows that they are all false-positives, meaning that we did not find false-negatives from the bi-directional analysis. b) If other tools find lesser dependencies, then they might be potential false-positives of the bi-directional analysis. We manually verify them all, and the result shows that they are all false-negatives, meaning that we did not find false-positives from the bi-directional analysis.
\end{itemize}


\noindent
{\bf Procedure and Method for Manual Analysis.}
Our manual analysis leverages existing static/dynamic analysis techniques. While they are inaccurate, we only apply them for a single dependency chain and reason about the result. Since we only reason a single dependency at a time, the task was manageable even though it is a time-consuming task. 
We conduct inter-procedural manual analysis, meaning that we follow through the callee functions' arguments if values propagate through the functions.
The analysis finishes when the data reaches a trusted/untrusted source.
In addition to the static/dynamic taint analysis techniques, we manually run the programs and observe how the concrete values are propagated by changing inputs and checking output differences. Note that if an output value is changed from the above testing due to the input change, there is a dependency.

\input{tex/table_num_detected}

%* Except for these 6 applications, there is no difference between the tools.
To make sure \sysname's bi-directional analysis does not miss anything, we compared the results with existing techniques (Taintless, Psalm, and PECL taint). We manually analyzed them and verified that all the results from bi-directional analysis are true-positives. 
Details on the notable cases are as follows.

\begin{itemize}[leftmargin=*]
    \item [\it 1.] {\it WordPress:} 
    Compared to Taintless, Taintless has 49 false negatives. Among them, 24 false negatives are caused as described in \autoref{fig:false_negative}. 5 false negatives are caused by handling PHP dynamic function call (e.g., \code{call\_user\_func\_array()}). 20 false negatives are caused by handling WordPress \code{apply\_filter} which invokes a function by the nickname registered by \code{add\_filter}.
    Compared to Psalm, Psalm has 24 false negatives as described in \autoref{fig:false_negative}. Psalm is not accurate in handling object inheritance. It will miss the data dependencies from subclass methods to base class methods in 36 cases.
    Compared to PECL taint, PECL taint has 35 false positives caused by handling WordPress \code{do\_action} dynamic function hook.  PECL taint has 40 false positives caused by string array filtering operation.
    
    \item [\it 2.] {\it Activity Monitor:}
     Compared to Taintless, Taintless has 11 false negatives. Among them, 3 false negatives are caused as shown in \autoref{fig:false_negative}. 8 false negatives are caused by not supporting WordPress \code{apply\_filter} which invoke a function registered by \code{add\_filter} dynamically. The data flow will be broken when it goes into such APIs.
    Compared to Psalm, Psalm has 14 false negative and 4 false positive cases. Among them, 3 false negatives are caused as shown in \autoref{fig:false_negative}. 8 false negatives are caused by \code{add\_filter} and \code{apply\_filter}. 3 false negatives are caused by mishandling object inheritance. Variables defined in base class will not be recognized in subclass. 4 false positive cases are caused by mishandling regex matching API \code{preg\_match}.
    
    \item[\it 3.] {\it Avideo-Encoder:}
    Compared to Taintless, Taintless has 2 false negatives and 7 false positives. Among them, 2 false negatives are caused by unsupported API \code{DateTime()} which should be considered as trusted. 7 false positives are caused by mishandling regex API \code{preg\_match}. 
    
    \item[\it 4.] {\it PHPSHE:}
    Compared to Taintless, Taintless has 16 false negatives and 47 false positives. Among them, 16 false negatives are caused by parsing error on one PHP file. Internal bug on an old version of PHP-Parser. 47 false positives are caused by history upgrading scripts.
    Compared to Psalm, Psalm has 15 false negatives and 11 false positives. Among them, 3 false negatives are caused by \code{time()} API. 12 false negatives are caused by class object inheritance. 11 false positives are caused by SQL keywords in arguments used matching pattern of \code{preg\_match} functions. 
    Compared to PECL taint, PECL taint has 47 false negatives because of PHP fatal error in executing database update script
    
    \item[\it 5.] {\it Pie-register:}
    Compared to Taintless, Taintless has 2 false negatives and 8 false positives. Among them, 2 false negatives are caused by the case shown in \autoref{fig:false_negative}. 8 false positives are caused by SQL keywords in the embedded HTML while they are not SQL statements.
    Compared to Psalm, Psalm has 2 false negatives caused by the case shown in \autoref{fig:false_negative}.



\end{itemize}






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\subsubsection{Impact Analysis for Instrumentated Code}
\label{appendix:manual_analysis_instr_detail}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\columnwidth]{fig/instr_sample_1.pdf}
    \vspace{-1em}
     \caption{Examples of Impact of Instrumentation}
     \label{fig:instr_sample}
     \vspace{-1em}
\end{figure}

\autoref{fig:instr_sample} shows examples of instrumentations impacting a single basic block (a), a single function (b), and multiple functions (c).
%We explain each example as follows.

\noindent
{\bf Single Basic Block (the BB column in \autoref{table:selectedprograms}).}
This is the simplest type of instrumentation. As shown in \autoref{fig:instr_sample}-(a), all the instrumented commands (i.e., \code{lsof}, \code{grep}, and \code{cat}) are directly fed into the sync function (\code{execSync} at line 2). The instrumented commands are not saved and transferred to other functions. %This does not affect any other parts of the target program.

\noindent
{\bf Single Function (the Fn column in \autoref{table:selectedprograms}).}
Instrumented commands can affect or stored in local variables. However, they only affect statements within the same function and do not propagate to other functions. 
In \autoref{fig:instr_sample}-(b), the instrumentation (\code{rand()} at line 10) affects a local variable \code{buf}. However, the local variable does not affect any other statements nor passed/returned to other functions.
Note that it is relatively easy to verify the impact of instrumentation since it only requires analysis within the function. %Our analysis is capable of identifying all the affected variables and code to make sure it does not break the target program's functionalities.

\noindent
{\bf Multiple Functions (the Fns column in \autoref{table:selectedprograms}).}
In this type, an instrumentation affects multiple functions through function calls and global/member variables. 
\autoref{fig:instr_sample}-(c) shows an example. 
The instrumented SQL query is shown at line 15. The randomized query is passed to \code{get\_var()} (\blkcc{1}). The query is then used to call \code{query()} function (\blkcc{2}) and passed to the function again (\blkcc{3}). In the \code{query()} function, it is stored to the \code{\$last\_query} member variable (at line 24, \blkcc{4}) and passed to the \code{\_do\_query()} function (\blkcc{4}). Finally, in the \code{\_do\_query()} function, the query is used to call a sink function which is \code{mysql\_query()}.
%
Note that the \code{\$last\_query} variable that stores the randomized query is used later in the \code{print\_error()} function at lines 34 and 37 (\blkcc{7} and \blkcc{8}). 
%
In this example, the instrumentation at line 15 affects 5 functions (\code{prepare\_sql\_data()}, \code{get\_var()}, \code{query()}, \code{\_do\_query()}, and \code{print\_error()}).

%We verified all the instrumentations belong to this category are correct by tracing variables affected by the instrumentations. 
%To check whether this type of instrumentation breaks the benign functionalities or not, we trace all the variables that are affected by the instrumentation. %The next three columns present the number of local and global variables as well as functions. 
%Details are presented in the next section.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace{-0.5em}
\subsection{Additional Discussions}
\label{appendix:additional_discussion}
\revised{
\subsubsection{Alternative Approach: Screening Unintended Commands}
\label{appendix:whitelist_approach}
One can develop an approach that only allows intended commands identified.
For instance, given a function call ``\code{system("rm file \$opt")}'', the approach will only allow the ``\code{rm}'' command. 
Such an approach (i.e., allowlist method) is fundamentally different from \sysname since it cannot distinguish \textit{different instances of commands} and enforce the same rule for every commands on an API. %, failing to identify the injected commands having the same name.
%\updated{}{\mw{The mechanism of allowlist and how we use our analysis results are different. We use static analysis to identify the intended commands from the trusted sources. Allowlist will allow the execution of commands even if it is not the developers' intention. So the attacker can inject the same command to compromise the system. However, we use static analysis to identify the benign commands from the trusted sources and those benign commands can only be used in the developers' intended conditions.}}\CJ{8) [6] (\#A) Clear justification of complex design choices (e.g., motivation for designing the Spinner instead of using a simple allowlist or sanitization).}
\updated{Unfortunately,}{For example,} it cannot prevent if an attacker injects the same command (e.g., ``\code{rm}'' in this case). % while \sysname can prevent such an attack. % because only randomized commands will be properly executed while the injected command is not randomized.
\updated{}{\sysname randomizes the first ``\code{rm}'' and leaves the second ``\code{rm}'' command, which is injected, preventing the attack.}
For SQL injections, approaches relying on known/allowed SQL keywords cannot prevent attacks leveraging keywords that are not considered (e.g., Section~\ref{subsec:comparison_existing}) while \sysname can prevent them.
}
% http://g2pc1.bu.edu/~qzpeng/manual/MySQL%20Commands.htm list of some sql statements

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsubsection{Command Line including Multiple Commands}
% A command line containing multiple commands can be passed to a command execution API. For instance, two commands can be chained by using a pipe operator: `\code{ls | grep arg}'. To randomize them, \sysname's scanner identifies the four terms (\code{ls}, \code{|},  \code{grep}, and \code{arg}), and randomizes \code{ls} and \code{grep} as they are commands. 
% All commands are executed by the randomized shell process (by \sysname) as shown in Section~\ref{subsubsec:shellcommand_rand}.
% %
% In addition, a program may accept another binary program as an argument and can execute at runtime (e.g., `\code{exec open ls}'). In such case, the first program (i.e., \code{exec}) calls a command execution API to execute the second program (i.e., \code{open}) which again calls a command execution API to run the third command (i.e., \code{ls}). In such a case, all the programs except for the last program should be hardened by \sysname to prevent command injection attacks.


\subsubsection{Prepared Statements in Practice}
\label{appendix:enc_sql_statements}
%The most often recommended way to prevent SQL injection is to make use of prepared statements. However, 
As mentioned in Section~\ref{sec:discussion}, prepared statements are not well adopted in practice. We analyze all the SQL queries in the applications used in our evaluation. We find that 866 SQL queries from WordPress~\cite{wordpress} (459 queries), Pie Register~\cite{pieregister} (70 queries), PHPSHE~\cite{PHPSHE} (277 queries), AVideo-Encode~\cite{videoencoder} (39 queries), and Plainview Activity Monitor~\cite{PlainviewActivityMonitor} (21 queries).
None of them use the prepared statements.

\noindent
{\bf Unsupported Keywords.}
The following SQL keywords are not supported: \code{DESCRIBE} (or \code{DESC}), \code{ALTER DATABASE}, \code{LOAD DATA}, \code{LOAD XML}, \code{RENAME USER}, and \code{SHOW TABLES LIKE}.
In particular, WordPress (\code{s1}) is using the unsupported keywords, i.e., \code{DESC}, \code{SHOW TABLES LIKE}, in their queries, making it challenging to convert.
%We analyze all the SQL queries (866 queries) in the applications used in our evaluation, and there are XXX programs using them. 


\revised{
\subsubsection{Brute-force Attack \sysname.}
\label{appendix:bruteforce_attack}
Attackers may inject multiple commands (or a shell script file containing multiple commands) to try out a number of guesses of randomization schemes.
From the attacker's perspective, if any of the guesses lead to the successful execution of the command, the attack is successful.
\autoref{fig:bruteforce}-(a) shows such a shell script containing multiple commands. 
We find that the Linux shell process handles individual commands separately, causing multiple command execution API invocations for each command. 
Recall that \sysname uses different randomizations on command execution API invocations. To this end, we randomize the subsystems differently, as shown in 
\autoref{fig:bruteforce}-(b-e). 
The first command failed because we randomize \optmap{ls}{cT}. The second attempt also failed as `\code{ka}' is expected. Even if an attacker learned this previous randomized command and injects \code{ka} next time, as shown in this example, it still fails as \sysname changes the randomization scheme to \optmap{ls}{ml}. Finally, one may try to inject a large number of the same command (e.g., millions of \code{sl}), waiting for our randomization scheme to become \optmap{ls}{sl}. Unfortunately, \sysname allows can be configured to use multiple bytes translation rules. For example, the randomization scheme 4 translates a single byte to 4 bytes. With this, searching space is practically too large to brute-force. 
Specifically, assume our randomization schemes use all printable ASCII characters (94 of them) to substitute, two-byte commands such as `\code{ls}', can be randomized to 8,741 (=$P(94,2)-1$) different two-byte characters. For 4 bytes commands, the space becomes extremely large: $P(94^4,2)-1$.
%Assuming that an attacker knows that his target is protected by \sysname and uses the basic one-to-one randomization, he will try to inject commands \code{`ls'} using a script. However, as shown in \autoref{fig:bruteforce}-(b), the shell will handle those commands one by one and each of them will have a different randomization table so the brute-force attack will fail.
}
%\CJ{2) [2.2] (\#A+C) Is the randomization method for a simple command easy to be attacked (e.g., `ls’ to `sl’ )?}


\begin{figure}[h]
    \centering
    \includegraphics[width=1\columnwidth]{fig/randomization_schemes.pdf}
    \vspace{-2em}
    \caption{\updated{}{Randomization Schemes Used for Each Command}}
    \label{fig:bruteforce}
\end{figure}


\noindent
{\bf Effectiveness of Dynamic Randomization.}
\sysname dynamically changes randomization scheme on every command, which we call dynamic randomization. 
To understand the effectiveness of dynamic randomization compared with the static randomization which uses a single randomization scheme during the entire execution, we tried brute-force attacks on both static and dynamic randomization approaches. 
In general, attackers need to try twice more attacks to break the dynamic approach than the static approach. 
For instance, using the dynamic approach (1-to-1 mapping) for three characters-long commands requires 70,191 more attempts to succeed the attack (which we believe quite effective) than the static approach.
% Details can be found on \cite{technical_report}.


\noindent
{\bf Experiment Results.} 
We conduct brute-force attack experiments. Specifically, we brute-force four different randomization schemes to show the effectiveness of the dynamic randomization scheme. 

\input{tex/table_bruteforce}

\autoref{table:brute_force_attack} shows the number of failed attempts before the first correct guess, leading to a successful attack. For instance, using the 1 to 1 mapping scheme, the static method prevents 71.1K attempts successfully. With the dynamic randomization scheme, the attack has to run 141.3K commands until the first successful guess.
Note that we decided to use the estimation for 1 to 3 and 1 to 4 randomization schemes because the experiment did not finish within 10 hours. We observe this result follows the distribution (i.e., static randomization approach follows the uniform distribution and dynamic randomization approach follows the geometric distribution). According to this observation, we put the expected value through the statistical method.
For the case of 1 to 2 scheme, using dynamic approaches for this command requires 9,807,906,470 more attempts to succeed the attack than static randomization.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% we find that it is sufficient for applications we analyze, including WordPress, for our purpose. 
%Code in line 37 and line 40 show that the object \code{\$control\_obj} is a dynamic object. Backward data flow analysis are applied here to find the instantiation of the object. We find that this object is initialized in two different places: line 18 and line 4. Among our collected applications, 16 of them are object-oriented programming applications. We check the number of dynamic objects and the polymorphic classes as shown in \autoref{table:oopprograms}. WordPress, Yoast SEO and Composer have lots of dynamic objects because they frequently initialize dynamic object to store the error information.
%\input{tex/table_oop_apps.tex}

%\CJ{6) [3.3] (\#D) How to handle object-oriented programming systems?}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \begin{figure}[!h]
%     \centering
%     \includegraphics[width=1\columnwidth]{fig/trusted_specifications.pdf}
%     \caption{\updated{}{\updated{}{Trusted Command Specification Examples.}}}
%     \label{fig:trusted_specifications}
% \end{figure}

% \updated{}{
% \subsection{Examples of Trusted Command Specification}
% \label{appendix:tcs_examples}
% \autoref{fig:trusted_specifications} shows the example of trusted specifications for (a) WordPress~\cite{wordpress}, (b) Composer~\cite{Composer} and (c) Lighttpd~\cite{lighttpd}. 
% %
% \code{"Constant":"String"} means that all constant strings in the program source code are trusted. 
% \code{"Configuration"} is a list of configuration files where strings originated from those files are trusted.
% \code{"API"} is a list of API functions. Return values from those APIs will be trusted. 
% \code{"Directory"} is a list of directories containing trusted files. This is typically used for XXE injection prevention. 
% }



\input{tex/table_history_release.tex}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\revised{
\subsubsection{Impact of Software Updates on \sysname}
\label{appendix:software_update_impact}
As discussed in Section~\ref{sec:discussion}, if software updates of a target application cause changes in the trusted command specification, manual analysis of the target application is required. 
To understand how prevalent such cases are in practice, we study the update history of 42 applications (27 applications in Table~\ref{table:selectedprograms} and 15 programs in Table~\ref{table:extra_programs}).
As shown in \autoref{table:history_release}, we track major version updates from the first stable version to the most recent major update until November 2020. We analyze each major update to understand whether the trusted command specification of an old version should be updated for a new version to use \sysname.
The result shows that none of the trusted command specifications are changed between versions. 


\autoref{table:history_release} shows the results. 
All 42 applications use constant strings as a trusted source. 
%An example of trusted command specification of such applications is shown in \autoref{fig:trusted_specifications}.
There are 9 programs that have both configuration files and constant strings as trusted sources. 
Their trusted command specification is similar to \autoref{fig:spec_example}-(a). 
\texttt{s7} and \texttt{s10} have folder paths and constant strings as trusted sources and can be defined as shown in \autoref{fig:spec_example}-(c).
\texttt{s35} requires the environment variable as a trusted source. For this program, to prevent attacks that attempt to compromise environment variables, we hook \code{setenv} and \code{getenv}. % functions to detect unauthorized modifications. %\CJ{@MW, fix XXX and missing link here.}
%source and the file is not exposed to the remote-user. One application Composer uses the environment variable as a trusted source. There is only one application monolog that allows the trusted source to be modified by remote users. However, it is a log framework for developers that are not meant to be exposed. 2 applications lighttpd and Goahead use file path a trusted source because they are both web servers. Examples of trusted command specifications are shown in \autoref{fig:trusted_specifications}
}

\input{tex/table_perf_corr}


\noindent
{\bf \sysname on Different Versions of Target Programs.}
To understand the impact of software updates on the performance of \sysname, we applied \sysname to WordPress (v5.6.2; released on Feb 22, 2021) and Leptonica (v1.8; released in July 28, 2020) in addition to the versions we have evaluated in Section~\ref{sec:eval}, as shown in \autoref{table:perf_corr}. 
The resulting protected programs are correct where we observe a similar average overhead of 4.31\%. 



%The intended commands of one application might be changed in the new version. But if the trusted sources remain the same, we only need to re-apply \sysname again. 
%We checked the trusted sources of the history releases of the applications evaluated in this paper. For the frequently updated applications like WordPress, we checked the major update of the releases. 
%We find that the trusted sources remain unchaged in different versions so we can easily apply \sysname in different versions of the applications. The detailed results are shown in \autoref{table:history_release}.} \CJ{7) [5] (\#B+C) Need discussion on the system’s scalability and reproducibility}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\revised{
\subsubsection{Preventing Trusted Sources from Being Compromised}
\sysname often trusts configuration files that cannot be modified by remote attackers. However, if our analysis is incomplete or the system has other vulnerabilities that allow attackers to compromise the trusted configuration files, \sysname's protection can be affected. 
As a mitigation, we implement a kernel module that denies any modifications to the configuration files. We also tried secure file systems~\cite{li2004secure} to prevent unauthorized modifications to the configuration files. 
We enabled them during our evaluation, and we do not observe any errors caused by them, meaning that users may also use such approaches to protect \sysname.
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%this is not a practice well observed. In the table below, we provide a breakdown of SQL statements we have encountered during instrumentation. 
%\input{tex/table_enc_sql_statements.tex}
%\textcolor{red}{From all the applications that use SQL statements, none of them use prepared statements, making the case for instrumentation with \sysname.}



% \updated{}{
%     \subsection{Static Analysis False Negative Statistics}
% \label{appendix:false_negative}
%     The average data dependencies of our data flow analysis and false negative cases are shown in \autoref{table:data_dependencies}. 
%     The first two columns show the average length of data dependencies from forward and backward analysis alone. False negative cases are presented in the next three columns. Note that for WordPress, Activity Monitor, and Pie Register, there are false negatives. This is because the data dependency length becomes large (especially larger than 10 in general).  Observe that when we apply the bidirectional analysis, we resolve all the false negative cases.
% }

%\autoref{fig:false_negative} shows the bi-directional data flows when we analyze WordPress. The backward flow analysis begins from the sink function \code{mysql\_query()} in line 32. The purple arrows represent the data flow of backward data flow analysis. When it encounters line 37, backward data flow analysis will try to find reference of \code{\$wpdb->users} but failed.

%It is because \code{class wpdb} uses constant arrays to store the name of the class properties and accesses them through string variables of the arrays. Black arrows represent the forward data flow analysis.it begins from constant array \code{\$global\_tables} (line 9) holding the constant value `users'.  Our static analysis tool also makes sure that there is no data flow originating from untrusted sources to those constant variables. In line 22, forward data flow analysis infers that constant value \code{``wp\_users"} will be assign to class property \code{"users"} and this property is considered as a trusted variable. So the forward data flow analysis covered the false negative of backward data flow analysis and merged with backward data flow analysis in line 22. The average data dependencies of our data flow analysis and false negative cases are shown in \autoref{table:data_dependencies}. For most of applications, forward flow analysis will not have any false negatives because the data flow from trusted source to the sink function is explicit. Backward flow analysis will have some false negatives but the pattern of them are similar which is using string variable storing names of class properties to access class properties.}


%TF is step dependencies.......
%\input{tex/table_step_dependencies.tex}









% \begin{figure}[h]
%     \centering  
%      \includegraphics[width=1.0\columnwidth]{fig/diglossia_failure2.pdf}
%      \caption{Failure Case of Diglossia with php-parse~\cite{phpmyadmin/sql-parser}}
%     \label{fig:diglossia_failure_2} 
% \end{figure}

% The second example is shown in \autoref{fig:diglossia_failure_2}. In this case, the parser failed to parse the subquery after the \code{IN} keyword. When the malicious input is injected (\autoref{fig:diglossia_failure_2}-(b)), the original parse tree and the shadow parse tree have the injected code as a sequence of expressions, and failed to recognize SQL keywords and build a proper tree.
% In other words, \autoref{fig:diglossia_failure_2}-(d) and \autoref{fig:diglossia_failure_2}-(e) shows that they have identical nodes, marked with red borders. However, they are simply considered as literal nodes, hence not considered as an injected code. 
% Moreover, observe that the parsing tree is broken, due to the bug of PHP-SQL-Parser. Unfortunately, the parser does not show error messages but silently processes the query with errors.
% To this end, the injected SQL query is allowed again. 
% \sysname is able to prevent the injected SQL statement \code{DROP TABLE users} from being executed.


%In terms of the performance overhead, the average overhead of \sysname is about 5\% while the average run-time overhead of Diglossia is 7.54\%.

%\input{tex/table_sql_parser.tex}
% \subsection{SQL Parser Selection for Section~\ref{subsubsec:advanced_sql_injection}}
% \label{appendix:popular_parser_selection}
% In Section~\ref{subsubsec:advanced_sql_injection}, we use 11 popular parsers to show they fail to handle various SQL queries, allowing malicious queries to be injected or breaking benign queries.
% \autoref{table:sqlparser} shows the 11 parsers that we selected. 
% The second column shows the number of stars in their GitHub repositories. 
% The third column shows the version number (or the last updated time of the repository) of the tested parsers.
% As shown in the fourth column, we selected parses written in diverse programming languages including C/C++, Python, Go, PHP, and JavaScript (JS).
% In addition to the issues we presented in Section~\ref{subsubsec:advanced_sql_injection}, we find that two parsers (nquery~\cite{alibaba/nquery} and druid-sql-parser~\cite{druid-sql-parser}) do not support the SQL comment via ``\code{/**/}''.




% \subsubsection{Complexity of Instrumentated Data Propagation}
% \label{appendix:data_propagation}
% Given an instrumented data, \autoref{table:table_layer} shows how many times it is propagated to other variables. For instance, if a variable \code{x} is stored to another variable \code{y}, we count it as the first propagation (i.e., Depth=1). If \code{y} is stored to another variable, \code{z}, we count it as the second propagation (i.e., Depth=2). If the instrumentation is not propagated at all, the depth is 0, the first column of \autoref{table:table_layer}.
% Intuitively, it represents the depth of the data dependency graph \sysname has to traverse and analyze. The last column shows the average depth of all the instrumented variables. 
% For each instrumentation, we find the deepest propagation and present in the table. For instance, if an instrumented value is propagated to another variable 5 times, it is counted as one in the column ``5''.
% Note that the average depth for large applications (e.g., \code{s1} and \code{s5}) is less than 4. \sysname handles all the cases and does not break benign functionalities.

%\vspace{-0.5em}
\subsection{Diglossia~\cite{diglossia} vs \sysname}
\label{appendix:diglossia_comparison}

\begin{figure}[h]
    \centering  
    %\vspace{-1em}
     \includegraphics[width=1.0\columnwidth]{fig/diglossia_failure1.pdf}
     %\vspace{-2em}
     \caption{\updated{}{Failure Case of Diglossia with PHP-SQL-Parser}}
     %\vspace{-2em}
    \label{fig:diglossia_failure_1} 
\end{figure}

\revised{
%\subsubsection{Diglossia~\cite{diglossia} vs \sysname}
%\label{appendix:diglossia_comparison}
In addition to Section~\ref{subsec:comparison_existing}, we compare \sysname with another our own implementation of Diglossia~\cite{diglossia} using PHP-SQL-Parser~\cite{greenlion/PHP-SQL-Parser}, which is the most popular SQL Parser for PHP in GitHub. 
%
\autoref{fig:diglossia_failure_1}-(a) shows a vulnerable PHP program's code.
Given the malicious input shown in \autoref{fig:diglossia_failure_1}-(b), the malicious query is injected as shown in \autoref{fig:diglossia_failure_1}-(c).
%
\autoref{fig:diglossia_failure_1}-(d) and (e) show parse trees from the original parser and the shadow parser. Nodes with yellow backgrounds represent keywords while nodes with gray backgrounds represent strings or numbers which are allowed to be injected.
Nodes with green borders are correctly translated in the shadow parser, meaning that they are intended nodes.
Nodes with the violet borders are those that are \emph{not fully translated}, meaning that some values (i.e., the first 2 characters) are translated and some are not.
%Note that they have hence having the same value between the original parser and the shadow parser.
Note that Diglossia detects an injected input by identifying nodes with the same values between the two parse trees. In this case, we do not have such nodes, meaning that Diglossia will miss the attack. 
%They are essentially injected input. Diglossia will raise an alarm if the injected input is a keyword, which is yellow background boxes in \autoref{fig:diglossia_failure_1}.
The injected code is not properly parsed due to the bug of the parser. It fails to recognize SQL grammar after the \code{\#} symbol, an XOR operator in PostgreSQL. 
%Since the entire injected query is not considered as a keyword, the exploitation is successful.

\sysname uses a scanner and applies reverse-randomization scheme to the injected query, preventing the attack.
}



%\vspace{-1em}
% \subsubsection{Command Injection (CVE-2018-15877)}

% We use a vulnerable WordPress plugin, \emph{Plainview Activity Monitor}~\cite{PlainviewActivityMonitor}, to show how \sysname prevents command injection in a real-world application. 
% The plugin records visitors' activities and analyzes information recorded in the logs. 
% It has a command injection vulnerability~\cite{CVE-plaiview} in which a remote user can inject additional commands through its IP lookup functionality. Specifically, the program allows a remote user to specify an IP address for a DNS lookup. Internally, it uses the `\code{dig}' command to perform the lookup. An attacker can launch a command injection attack  by adding additional commands to the input IP (e.g., `\code{127.0.0.1{\color{red}|ls}}').

% \begin{figure}[h]
%     \centering
%     \vspace{-0.5em}    
%      \includegraphics[width=0.9\columnwidth]{fig/case_phpcmdinj.pdf}
%      \vspace{-1em}
%      \caption{Preventing CVE-2018-15877}
%     \label{fig:case_cmd_inj}
%     \vspace{-0.5em}    
% \end{figure}

% \autoref{fig:case_cmd_inj} shows code snippets from the vulnerable plugin. We conduct a backward analysis from the command execution API. Specifically, we first identify the sink function \code{exec()} in line 17. It originally includes an intended command as a constant (i.e., `\code{dig}') and concatenates \code{\$ip} to pass it to the shell. 
% We further analyze the origin of the \code{\$ip}, reaching lines 15 and 9. 
% \code{\$ip} is defined at line 9 as a return value of \code{get\_filtered\_post\_value()}. Inside the function, it returns a value from a remote user through a \code{POST} request. Then, the input is going through a filter function \code{htmlspecialchars()} which sanitizes a few special characters. While this function might be effective in preventing some script injection and SQL injection attacks, it did not filter out the pipe symbol `\code{|}' used in our attack case. 

% \sysname prevents the attack by randomizing the two command names in the shell process: \code{dig} and \code{ls} to \code{gid} and \code{sl} respectively (i.e.,
% \optmap{dig}{QzA} and \optmap{ls}{Rx}).
% Consider an attacker injects a command with the input `\code{127.0.0.1|ls}' to \code{\$ip} at line 17.
% Since we instrument the `\code{dig}' command, the \code{exec()} at line 17 will execute the following command: `\code{QzA -x 127.0.0.1|ls}'.
% \updated{As \sysname randomizes the command names, `\code{gid}' will be successfully executed while `\code{ls}' will result in the command not found error.}{The randomized command `\code{QzA}' will be successfully executed while the injected `\code{ls}' will fail.}












\subsubsection{Preventing XXE Injection}
XML External Entity (XXE) injection allows attackers to inject an XML external entity in an XML file. XML external entity is a custom XML tag that allows an entity to be defined based on the content of a file path or URL.
An attacker can abuse the external entity to leak the content of arbitrary files.
In this case, we use a WordPress plugin, Advanced XML Reader~\cite{AdvancedXMLReader}, to demonstrate how \sysname prevents the XXE injection attack.


\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\columnwidth]{fig/xxe_attack.pdf}
    \vspace{-1em}
     \caption{XXE Injection Attack Scenario}
     \vspace{-1em}
     \label{fig:case_xee_attack}
     %\vspace{-1em}
\end{figure}


\autoref{fig:case_xee_attack}-(a) shows an attack scenario. The attacker first sends a malicious XML file with a malicious external entity (\blkcc{1}). The malicious XML file's content is shown in \autoref{fig:case_xee_attack}-(b). The XML file defines an \code{$<$!ENTITY SYSTEM$>$} tag with a file path \code{/etc/passwd}. The tag is used in line 4, which will be the content of the XML file when it is requested. 
The vulnerable plugin uploads the XML file and returns a shortcode (\blkcc{2}), which is essentially the name of the uploaded file to refer to the XML content in the future.
Now, the attacker posts an article with the shortcode (\blkcc{3}) as shown in \autoref{fig:case_xee_attack}-(c). Note that the tag value indicates the uploaded file's name. 
Once the post is uploaded, WordPress sends it to the plugin (Advanced XML Reader), which will parse and resolve the XML file referred to in the post (\blkcc{4}). During the processing, the plugin reads the password file and returns the content. When the posted article is requested, the password file's content will be delivered (\blkcc{5}).

\autoref{fig:case_xee_prevention} shows how \sysname ensures benign operations while preventing the XXE injection attack described in \autoref{fig:case_xee_attack}. 


\begin{figure}[ht]
    \centering
    \includegraphics[width=1.0\columnwidth]{fig/xxe_inj_prev.pdf}
    \vspace{-2em}
     \caption{Preventing an XXE Injection Attack}
     \vspace{-1em}
     \label{fig:case_xee_prevention}
         %\vspace{-0.5em}

\end{figure}

\noindent
{\bf Benign Operation.}
When the plugin reads an XML file (\blkcc{1}), \sysname intercepts the file I/O and check whether it reads a trusted XML file or not. Note that \sysname maintains a list of trusted XML file paths. Typically, those are the XML files provided by an administrator, not the files that are uploaded by remote users.
If the file path of the XML file is in the list, \sysname randomizes the external entities' file contents (\blkcc{2}). Then, it tries to access the file system with the randomized file name. As the file paths of the file system are randomized by \sysname, it successfully reads the file and returns (\blkcc{3} and \blkcc{4}). Finally, the content is returned (\blkcc{5}).

\noindent
{\bf Preventing XXE Injection.}
When an attacker uploads a malicious XML file, it is not included in the trusted XML file list. 
When the plugin tries to read an XML file that is uploaded by a remote user (which is not trusted, \blkcc{6}), the XML file's entity will not be randomized. As a result, it will not be able to access the file system correctly, leading to a file open error.



% \subsection{Static/Dynamic Randomization}
% https://github.com/cmd-spinner/commandrandom-spinner-php/tree/master/Supplementary/BruteForceAttack
% Brute-force Attack Result

% Randomization scheme
% We tried brute-force attacks to break the randomization scheme of 3 characters long command (e.g., env). We assume a strong attacker who already knows that the Spinner is using 1-to-2 mapping randomization scheme (e.g., e ↦ gc, n ↦ kv, v ↦ mS in the first row of below table). The below table shows a few records of failed brute force attempts.

% Table //

% # of attempts to successfully launch the attack
% The below table shows the number of failed attempts before the first correct guess, leading to a successful attack. For instance, using the 1 to 1 mapping scheme, the static method prevents 71.1K attempts successfully. With the dynamic randomization scheme, the attack has to run 141.3K commands until the first successful guess.

% Table//
% *: Estimated value (unit: trillion): We decided to use the estimation because the experiment did not finish within 10 hours. We observe this result follows the distribution (i.e., static randomization approach follows the uniform distribution and dynamic randomization approach follows the geometric distribution). According to this observation, we put the expected value through the statistical method.

% For the case of 1 to 2 scheme, using dynamic approaches for this command requires 9,807,906,470 more attempts to succeed the attack than static randomization.






%\subsection{Database}
% https://github.com/cmd-spinner/commandrandom-spinner-php/tree/master/Supplementary/Is%20Database%20Trusted%20Untrusted





%%% may not be needed
%\input{tex/table_rand_sch}
%%% already added
%\input{tex/table_num_suc_atk}
%%% already there.
%\input{tex/table_prog_ver}




\section{Trends in Forecasting}
\label{sec_trends_special_topics}

In this section, we discuss observed trends and several more specialised topics that we think are of interest to this research area, that may have received less attention, or are only just emerging.


\subsection{Process automation and move to operations}
An interesting emerging trend is attempts to generalise and automate a forecasting process, which is indifferent to the particular methods employed. A few papers, e.g. \cite{hoverstad2015stl,opera2019mla}, are investigating ways to produce an automated process including pre-processing and a feature selection process agnostic to the type of forecast method being applied. In \cite{hoverstad2015stl}, seasonalities are removed in a preprocessing phase, then an evolutionary algorithm is used to select features and train coefficients across a wide parameter space. In \cite{opera2019mla}, an automated process utilises three feature selection algorithms to pick inputs (LASSO, recursive feature estimation and univariate selection - the latter, considers F scores between input and response variables - the greater the F score, the greater the dependency of load on the input variable). After this step, clustering is applied and forecasts of each cluster are selected automatically from a set of various statistical and machine learning methods. In \cite{diamantoulakis2015bda}, a limited selection of pre-processing methods for short-term, smart grid, load forecasts are reviewed, considering only dimension reduction and clustering. Dimension reduction techniques include random projection of smart meter data, and online dimension reduction are applied, usually aiming to find correlations between features such as voltage, frequency, current, etc. The authors in \cite{tornai2016cfc} compare several forecasting methods, i.e., linear regression, radial basis function and ANNs, for classifying individual customers' time series. In particular, several classifiers are developed from an annotated dataset. A new unlabelled time series passes through the forecasts and it is assigned to the class with the lowest forecasting error.

With the increase and advances in monitoring, and communications equipment there are opportunities for more real-time applications, and online forecasting methods which are more robust to concept shifts. Of the reviewed papers only the online forecasting as seen in De Silva et al.~\cite{desilva2011ipc} utilising data-streams was found to consider such real-time operational questions. 

Research and comparison of different methods for data preprocessing, feature and parameter selection, and evaluation of different forecasting methods are of great importance and we hope to see more papers coming in this area in search of reliable, and robust optimal methods, that can be scaled up, productionised and used in real-life applications.


\subsection{'Divide and conquer' - Components of Load}
Splitting demand into different classes or clusters is a common technique to improve the aggregated forecasts that manifest in many different approaches. We discuss clustering in more details in Section \ref{sec:clustering}, but here we list several examples of splitting load into different components to improve the accuracy of the prediction. There are many ways to split up LV level demand, such as according to particular appliances, individual consumers, or the time series itself can be split into its frequency components as is common in Wavelet type models (some of these types of models are described in Section \ref{secStatandTS}). 

In \cite{dong2016ahm} demand is split into air-conditioning (AC) demand and non-AC demand and a hybrid model is used to predict a total load combining different data-driven machine learning algorithms and physics-driven heating models. 

Net load forecasting \cite{chu2017nlf} presents an interesting adaptation to traditional load forecasting. Preprocessing includes decomposition of the net-load time series to remove low-frequency load variation due to daily human activities. The load is split into daytime and nighttime and models are trained separately on each component. The exogenous predictors for the daytime forecast's include sky image features.  

Rabie et al. \cite{rabie2019afb} introduces a feature selection methodology 
for peak load forecasting at the grid level. The interesting aspect is that the forecasting is performed as a classification task, not a regression, classifying load into three classes; low, medium and high. The features selection task is a two-step method consisting of a filter feature selection which ranks the features based on several criteria and a feature wrapper method on the ranked features of the previous step using a Naive Bayes classification. However, the proposed feature selection technique is applied to a small set of features (five), selecting three of them. The method should have been tested in a larger feature set.
Similarly, in \cite{vats2020meo}, the authors perform a day-ahead load forecast for buildings in Patna, India, using classification. Particularly, they classify the loads into five classes and use them to predict the load for the next day using regression analysis. Three classification methods were considered, kNN, Random Forest and SVM, using the power factor, voltage, current, weekday and hour features.

For a special case of load splitting into appliances (so-called `behind the meter') an earlier analysis by \cite{bao2011ubp} based on only one household with 60 days of data, aimed to forecast user behaviour, i.e., devices usage. Regular devices (such as fridges) are more accurately forecasted using simple periodic models, while for other devices a semi-Markov model performed better. Hence, they find that the overall best predictions are done through a hybrid model. Welikala et al.~\cite{welikala2017iau} propose an approach using appliance usage patterns to improve the performance of non-intrusive load monitoring. They also show, how their approach can be used for conducting more accurate very-short term load forecasts at the household-level (5 minutes ahead). 


\subsection{Peak forecasting}  \label{sec:application_specific}

Peak forecasting is relevant for demand forecasts for several reasons: 1) errors when forecasting peaks are usually much more costly than other errors; 2) peaks (in 'values over the threshold' sense)  are relatively rare compared to the full time series,  and 3)  it is more difficult to predict peaks in LV settings than in more aggregated, smoother demand. However, only a few papers discuss peaks forecasting and the related errors,  (see e.g. \cite{chaouch2015rcq, Jacob2020faa}). In \cite{Komatsu2020pda} early warning systems for peak electricity consumption demand is presented using SVR for demand forecasting, where demand alerts are sent to grid managers when the predicted demand exceeds the predefined threshold. 


\subsection{Forecast Evaluation}
\label{subsec:eval} 
Issues around peak significance spill over into forecast evaluation. Over the last few years, numerous methodologies have been proposed to forecast the household-level consumption time series. However, despite the significant advancements in the modelling of smart electricity meter data, very little progress has been made in designing reliable performance scores to evaluate high-resolution household-level point forecasts. In \cite{Haben2014ane}, a new, adjusted error measure based on the $l^p$ norm, ($p$ is 4, to highlight peak errors) is proposed that evaluates the accuracy of a model for the timing and amplitude of the peak at the household-level. They show that a flat forecast can outperform a better informed, `peaky' forecast, if evaluated using the absolute error. Namely,  a forecast that accurately predicts a peak's amplitude and duration, but slightly displaced in time, e.g half-hour early, will incur a double penalty, one penalty for predicting a slightly early non-existing peak and another for missing the peak one half-hour later. Teeraratkul et al.~\cite{teeraratkul2017sba} show that Dynamic Time Warping (DTW), a popular time series measure can also be used as a forecast error measure and propose a shape-based forecasting approach to minimise it. While the measures proposed by these authors \cite{Haben2014ane, teeraratkul2017sba} is a step in the right direction, there is a need for similar error measures that are rewarding more informed forecasts that accurately predict peaks at the LV level. Any new error measures can be used to generate tailored forecasts as with the Average Adjusted Forecaster (AAF) proposed in \cite{Haben2014ane} or simple kNN approaches as in \cite{voss2018adjusted} that are aimed to minimise the adjusted $p$-norm error. Rowe et al~\cite{rowe2014apr} show how the AAF can be used in a peak reduction algorithm for battery control in LV networks. Voss~\cite{voss2020pbr} showed how optimal choice and configurations of the error measure, depend on the specific down-stream optimization objective for household-level energy management. More studies are needed in these specific downstream applications.

Finally, it is encouraging to see that statistical tests are becoming a more common trend in forecast evaluation, e.g. \cite{grmanova2016iel} uses the Wilcoxon rank sum test. In \cite{lusis2017str}  a Holm-Bonferroni's multiple hypothesis test based on a one-sided Wilcoxon signed-rank test is used to see if using calendar effects significantly reduces the error (it does not). Friedman statistical test and nonparametric Wilcoxon test are applied in \cite{gerossier2018rda} to see if the models perform differently (they do), however the best performing model is not statistically different in performance to one of the reference models. 


\subsection{Clustering for Forecasting Improvement}
\label{sec:clustering}

Clustering can be used to improve load forecasts in several ways. For instance, it can be used to estimate parameters of parametric models by fitting one set of parameters that suits similar households ~\cite{Arora2016fes}. Similarly, deep learning models can benefit from additional training data to pool profile uncertainties, allowing more data of similar households to train (possibly different) models~\cite{Shi2017dlf,yang2020bdl} (see also Section~\ref{sec:deep_learning}). Further, load profile clustering can be used to improve an aggregate forecast. This is done by first agglomerating similar groups, generating a forecast per group and then aggregating the groups'  forecasts~\cite{Wijaya2015caf,Humeau2013elf,kurniawan2015cba,fahiman2017ilf,gajowniczek2018sso,alzate2013iel}. The two main advantages of this approach are that \begin{itemize}
	\item
	the clusters of similar behaviour result in more regular time series, facilitating accurate prediction;
	\item the load becomes smoother, so even random clusters might bring forecast accuracy improvements (as noticed in \cite{Wijaya2015caf}).
\end{itemize}
The main challenge with clustering evaluation is that one needs to have sufficient disaggregated data to test the effect. As illustrated in Section~\ref{secdatasets}, there are a limited number of openly available smart meter dataset (beyond the Irish CER dataset~\cite{Commission2012csm} and UK Low Carbon London~\cite{UK2014ulc}) that can be used as benchmarks. Other datasets used in most papers are not open, so it is difficult to compare different methods. 

Load profiles are most commonly clustered directly using the raw time series or indirectly based on features obtained from the time series. When clustering load profiles, especially at the LV level, the choice of a distance measure can significantly influence the clustering result. 

Gajowniczek et al.~\cite{gajowniczek2018sso} compare different distance measures and find that the edit distance, longest common sub-sequence (LCSS), as well as the cross-correlation and TQuest distance\cite{TQuest} work well for clustering. Furthermore, they find that around 6-8 clusters can most improve the forecast results of ANN and SVR. 

We observed that broadly,  k-means is the most popular method. More recently, methods better suited to clustering time series data are emerging such as k-shape. The methods are typically used as a pre-processing step to improve short term forecasts. 

\subsubsection{K-means clustering}
Humeau et al.~\cite{Humeau2013elf} analyse if clustering can improve the forecast of the aggregated Irish CER dataset~\cite{Commission2012csm} using \textit{k}-means. They find that for MLP and linear regression clustering does not improve results, but the SVR results are best when using four clusters. In \cite{quilumba2015usm}, the authors also use k-means clustering of smart-meter data to produce aggregate forecasts. Once clusters are found, ANNs are used to forecast time-horizons up to one-day ahead. In \cite{Shahzadeh2015ilf}, neural networks are used to forecast the Irish CER dataset~\cite{Commission2012csm}. They show that clustering consumers result in more accurate forecasts. They train a separate neural network model on each separate cluster, whereby for clustering, they use \textit{k}-means.

The authors of \cite{Li2016slf} model the Irish CER smart meter data and argue that their modelling takes into account different consumer behaviours. Firstly, average load profiles based on different day types are calculated. Secondly, consumers with similar consumption behaviour are clustered using \textit{k}-means. Finally, an Online Sequential Extreme Learning Machine (OS-ELM) is used for load forecasting for different clusters, which are aggregated to get the system load. 

In \cite{li2020sbp}, the authors use a parallel \textit{k}-means implementation in Spark for clustering users. Then they forecast the clustered demand using essentially a parallel implementation of an ANN with a hidden layer of 20 neurons. The clustering and parallelisation attempt to address the increasing volume of household data. The method is applied to the Irish household dataset. Lu et al. in  \cite{lu2019awl} propose a Davies-Bouldin index-based adaptive \textit{k}-means algorithm to cluster 2000 large users, in Foshan, Guangdong province of China, into several groups. A hidden Markov model describing the probabilistic transitions of different load levels is established for each cluster to extract the representative dynamic weekly load features. An MLR and ANN are used as benchmarks, however, the HMM does not outperform the benchmarks for all clusters. The authors suggest that a combination of forecasts should be utilized to improve forecast accuracy.

While a vast majority of studies on modelling residential electricity data use only lagged consumption values, \cite{Fu2018csl} include temperature along with consumption, and report that temperature was a salient feature in the modelling. Their modelling relies on clustering consumers using a Fuzzy C-means clustering algorithm. 

Different clusters are modelled separately, and the individual predictions for a given cluster are aggregated to compute the net usage. 
Abera and Khedkar \cite{abera2020mla} focus on forecasting the appliance consumption and peak demand, using the Irish CER~\cite{Commission2012csm} and UMass datasets. They first cluster the profiles using CLARA (Clustering LARge Application - an extension of k-medoids), while for forecasting they use SVMs and ANNs. 


\subsubsection{Other methods}
The work \cite{fahiman2017ilf} focuses on the short term load forecasting of the aggregate households one day-ahead. The authors first cluster the household profiles of the Irish CER dataset~\cite{Commission2012csm} using k-shape clustering, then they forecast the load of the cluster before applying a \textit{weighted} sum of the clusters to forecast the aggregate household demand. For forecasting two main methods were used, ANN and Deep Belief Networks (DBN), a multi-layer generative model that learns one layer of features at a time from unlabelled data.
For clustering, a \textit{k}-shape algorithm is used, which clusters households with similar shape, instead of the traditional \textit{k}-means. 
The \textit{k}-shape with DBN outperforms all other methods (\textit{k}-means and/or ANN).

The authors of \cite{Fu2018csl} propose a short-term residential load forecasting framework. In their modelling, they consider the adoption of increasing-block tariffs, which is broadly based on the concept of allocating each consumer to a consumption block such that higher consumption blocks are associated with higher prices. 

To forecast the system load for a group of customers, \cite{Goehry2020ame} employ clustering techniques, aggregation methods, and machine learning along with survey and weather data to produce a forecast applied to the Irish CER dataset~\cite{Commission2012csm}. For clustering consumers, the authors use and compare hierarchical agglomerative clustering (a flexible technique, giving different numbers of clusters on different hierarchical levels) and random clustering. A random forest is then used for forecasting. 
Interestingly, the authors reported that random clustering performed as well as hierarchical agglomerative clustering, which may be due to the rather similar nature of consumers considered. Namely, hierarchical agglomerative clustering may be more suited for applications where there is more heterogeneity in the predictor variables being considered. Chen et al.\cite{chen2019daa} propose a multi-step load forecasting approach for aggregate load in the LV grid. They propose to use Affinity Propagation clustering to separate the customers into similar groups of customers (see section \ref{sec:deep_learning}).

Kernel spectral clustering is used in \cite{alzate2013iel}, to improve aggregated forecasts (Periodic auto-regressive base forecast) of Irish smart meters~\cite{Commission2012csm}. Small numbers of clusters appear to perform best. In \cite{kurniawan2015cba} the authors cluster the Irish CER data using features with the highest correlation.  Several clustering strategies are deployed, including a random assignment. As in \cite{alzate2013iel}, the accuracy changes with the number of clusters, but this paper also shows that it can depend on the forecast and cluster method as well. There does not appear to be any criteria for knowing this in advance.

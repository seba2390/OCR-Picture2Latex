\section{Related work}
\label{sec:relatedwork}
\paragraph{3D shape completion.} 
The application addressed in this paper is a very active research area in computer vision and graphics, ranging from completion of small holes~\cite{sarkar2017learning} and larger missing regions in individual objects~\cite{pointcloudGAN,rock2015completing,varley17iros,wu20153d,sharma16eccvw}, to entire scenes~\cite{song2016semantic}.
Completion guided by geometric priors has been explored, for example Poisson filling~\cite{kazhdan2013screened} and self-similarity~\cite{korman2015peeking,sarkar2017learning,litany2016cloud}. However, such methods work only for small missing regions, and dealing with bigger occlusions requires stronger priors. A viable alternative is model-based approaches, where a parametric morphable model describing the variability of a certain class of objects can be fit to the observed data~\cite{blanz1999morphable,gerig2017morphable}. 

The setting of non-rigid shape completion differs from its rigid counterpart in that at inference, the input partial shape may admit a deformation unseen in the training data. This distinction becomes crucial as large missing regions force the priors to become more complex (see for example the human model designed in \cite{anguelov2005scape}).

\paragraph{Generative methods for non-rigid shapes.} 
The state-of-the-art in generative modeling has rapidly advanced with the introduction of Variational Autoencoders (VAE~\cite{kingma2014iclr}), Generative Adversarial Networks~\cite{goodfellow2014generative}, and related variations (e.g. VAEGAN~\cite{larsen16icml}). These advances have been adopted by the 3D shape analysis community for dynamic surface generation through VAE~\cite{kostrikov2017surfnet} and image-to-shape generation through VAEGAN~\cite{wu16nips}. In~\cite{tan2017variational}, a VAE for non-rigid shapes is proposed. This work differs from ours in that the core operations of our network are graph-convolutional operations as opposed to fully-connected layers, and our network operates directly on raw 3D vertex positions rather than relying on hand-crafted features.

\paragraph{Geometric deep learning.} 
This paper is closely related to a broad area of active research in geometric deep learning (see~\cite{gdl} for a summary). The success of deep learning (in particular, convolutional architectures \cite{lecun1998gradient}) in computer vision has brought a keen interest in the computer graphics community to replicate this progress for applications dealing with geometric 3D data. One of the key difficulties is that for such data it requires great care to define the basic operations constituting deep neural networks, such as convolution and pooling.

Several works avoid this problem by using a Euclidean representation of 3D shapes, such as rendering a collection of 2D views \cite{su2015multi,wei2016dense}, volumetric representations \cite{wu20153d}, or point cloud \cite{qi2016pointnet,qi2017pointnet++}. One of the main drawbacks of such extrinsic deep learning methods is their difficulty to deal with shape deformations as discussed earlier. Additionally, voxel representations are often memory intensive and suffer from poor resolution \cite{wu20153d}, although recent models have been proposed to address these issues: implicit surface representation~\cite{dai2016shape}, sparse octree networks~\cite{wang17ocnn,riegler17cvpr}, encoder-decoder CNN for patch-level geometry refinement~\cite{han17iccv}, and a long-term recurrent CNN for upsampling coarse shapes~\cite{wang17iccv}. Regarding point cloud representations, the PointNet model~\cite{qi2016pointnet} applies identical operations to the coordinates of each point and aggregates this local information without allowing for interaction between different points which makes it difficult to capture local surface properties. PointNet++~\cite{qi2017pointnet++} addresses this by proposing a spatially hierarchical model. Additionally, for PointNet to be invariant to rigid transformations the input point clouds are aligned to a canonical space. This is achieved by a small network that predicts the appropriate affine transformation, but in general such an alignment would be difficult for articulated and deformable shapes.

An alternative strategy is to redefine the basic ingredients of deep neural networks in a geometrically meaningful or intrinsic manner. The first intrinsic CNN-type architectures for 3D shapes were based on local charting techniques generalizing the notion of ``patches'' to non-Euclidean and irregularly-sampled domains \cite{masci15,boscaini2016learning,monet}. The key advantage of this approach is that the generalized convolution operations are defined intrinsically on the manifold, and thus automatically invariant to its isometric deformations. As a result, intrinsic CNNs are capable of achieving correspondence results with significantly less parameters and a very small training set. Related independent efforts developed CNN-type architectures for general graphs \cite{bruna2013spectral,henaff2015deep,defferrard2016convolutional,kipf2016semi,monet,levie2017cayleynets}. 

Recently,~\cite{dynFilt} suggested a dynamic filter in which the assignment of each filter to each member of the k-ring in a graph neighborhood is determined by its feature values. Importantly, this method demonstrated state-of-the-art performance working directly on the embedding features. Thus, in our work we build upon~\cite{dynFilt} as a basic building block for convolution operations. 

\paragraph{Partial shape correspondences.}
Dense non-rigid shape correspondence \cite{kim11,chen15,fmnet,rodola14,bronstein2006generalized} is a fundamental challenge as it is an enabler for many high level tasks like pose or texture transfer across surfaces. We refer the interested reader to \cite{van2011survey,biasotti2015recent} for a detailed review of the literature. The proposed method in this work builds upon correspondence between a partial input and a canonical shape of the same class, and related to this are several methods that explore partial shape correspondence and matching~\cite{rodola16-partial,monet,litany17fully}. The approaches demonstrating state-of-the-art performance on partial human shapes (e.g.~\cite{monet}) treat correspondence as a vertex classification task. Recently~\cite{wei2016dense} has shown impressive results for correspondence across different human subjects in varied pose and clothing. 

\paragraph{Inpainting.}
The 3D shape completion task is closely related to the analogous structured prediction task of image inpainting~\cite{pathakCVPR16context,Yang_2017_CVPR}. However, our proposed optimization scheme is more reminiscent of style transfer~\cite{gatysStyleTransfer} techniques. In our setting we optimize only for the best complete shape with no constraints on the internal feature representation.
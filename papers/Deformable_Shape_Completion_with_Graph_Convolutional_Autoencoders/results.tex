%------ VAE performance ------
\subsection{Representation quality}
To understand the generative capabilities of the VAE we show several examples related to shape generation as well as explore the structure of the learned latent space.
Figure~\ref{fig:random_sample} depicts shapes generated by the decoder fed with latent variables randomly sampled from $\mathcal{N}(\bb{0},\bb{I})$. As we have explicitly relaxed the Gaussian prior on the latent variables (small $\lambda$) during training. As discussed earlier, the tradeoff is that samples coming from the prior may generate slightly unrealistic shapes.

Figure \ref{fig:interpolation} depicts generated shapes as the result of linear interpolation in the latent space. The source and target shapes are first passed through the encoder to obtain latent representations; applying the decoder to convex combinations of these latent vectors produces a highly non-linear interpolation in $\mathbb{R}^3$. The top two rows of Figure~\ref{fig:interpolation} show interpolation for networks trained with $\lambda=10^{-6}$ and $\lambda=10^{-8}$, respectively. The bottom row of Figure~\ref{fig:interpolation} highlights the interesting structure of the learned latent space through arithmetic. Applying the difference of a subject with left knee raised and lowered to the same subject with right knee raised results in a lowering of the right knee. The network learned this symmetry without any explicit modeling.


% fig: Random sampling
\begin{figure}
\centering
\includegraphics[height=0.15\textwidth]{./figures/random_sample_6.png}
\includegraphics[height=0.15\textwidth]{./figures/random_sample_13.png}
\includegraphics[height=0.15\textwidth]{./figures/random_sample_14.png}
\includegraphics[height=0.15\textwidth]{./figures/random_sample_15.png}
\includegraphics[height=0.15\textwidth]{./figures/random_sample_22.png}
\includegraphics[height=0.15\textwidth]{./figures/random_sample_30.png}
\includegraphics[height=0.15\textwidth]{./figures/random_sample_59.png}
\includegraphics[height=0.15\textwidth]{./figures/random_sample_66.png}
\includegraphics[height=0.15\textwidth]{./figures/random_sample_70.png}

\caption{\textbf{Random human shapes generated by the VAE.} We have explicitly relaxed the Gaussian prior on the latent variables during training. The tradeoff is that samples coming from the prior may generate slightly unrealistic shapes.}
\label{fig:random_sample}
\end{figure} 
%
\definecolor{mygray}{rgb}{0.6,0.6,0.6}
% fig: interpolation
\begin{figure}
\centering
\resizebox{1\columnwidth}{!}{
\addtolength{\tabcolsep}{-4pt}
\begin{tabular}{cccccc}
\includegraphics[height=0.12\textwidth]{./figures/interp_1e-6_1.png} &
\includegraphics[height=0.12\textwidth]{./figures/interp_1e-6_5.png} &
\includegraphics[height=0.12\textwidth]{./figures/interp_1e-6_9.png} &
\includegraphics[height=0.12\textwidth]{./figures/interp_1e-6_13.png} &
\includegraphics[height=0.12\textwidth]{./figures/interp_1e-6_17.png} &
\includegraphics[height=0.12\textwidth]{./figures/interp_1e-6_19.png} \\
\includegraphics[height=0.12\textwidth]{./figures/interp_1e-8_1.png} &
\includegraphics[height=0.12\textwidth]{./figures/interp_1e-8_5.png} &
\includegraphics[height=0.12\textwidth]{./figures/interp_1e-8_9.png} &
\includegraphics[height=0.12\textwidth]{./figures/interp_1e-8_13.png} &
\includegraphics[height=0.12\textwidth]{./figures/interp_1e-8_17.png} &
\includegraphics[height=0.12\textwidth]{./figures/interp_1e-8_19.png} \\ 
\vspace{10pt} \\
\begin{overpic}
[trim=0cm 0cm 0cm 0cm,clip,height=0.12\textwidth]{./figures/arith_C.png}
\put(12,65){\small Z}
\put(23,65){$+$}
\put(33,65){\small $\alpha$}
\put(41,65){$($}
\end{overpic} &
\begin{overpic}
[trim=0cm 0cm 0cm 0cm,clip,height=0.12\textwidth]{./figures/arith_B.png}
\put(8,65){\small X}
\put(28,65){$ - $}
\end{overpic} &
\begin{overpic}
[trim=0cm 0cm 0cm 0cm,clip,height=0.12\textwidth]{./figures/arith_A.png}
\put(10,65){\small Y}
\put(20,65){$)$}
\put(35,70){ {\color{mygray}\line(0,-1){70}} }
\end{overpic} &
\begin{overpic}
[trim=0cm 0cm 0cm 0cm,clip,height=0.12\textwidth]{./figures/50022_one_leg_jump_00284_12.png}
\put(0,65){\small$\alpha = 0.5$}
\end{overpic} &
\begin{overpic}
[trim=0cm 0cm 0cm 0cm,clip,height=0.12\textwidth]{./figures/50022_one_leg_jump_00284_17.png}
\put(0,65){\small$\alpha = 0.7$}
\end{overpic} &
\begin{overpic}
[trim=0cm 0cm 0cm 0cm,clip,height=0.12\textwidth]{./figures/50022_one_leg_jump_00284_24.png}
\put(0,65){\small $\alpha = 1$}
\end{overpic}
\end{tabular}
}
\caption{\textbf{Latent space interpolation.} Interpolation between two poses (left- and right-most shapes) obtained as convex combinations of the respective representations the the latent space. Bottom row: latent space arithmetic.%All the intermediate poses are plausible. 
%\orlit{top row is 1e-6 and bottom row is 1e-8.}
} 
\label{fig:interpolation}
\end{figure} 
%


%------ Variability ------
\subsection{Completion variability}
\label{subsec:completion_variability}
As explained in Section \ref{sec:method}, given a partial input with more than one solution consistent with the data, we may explore this space of completions by sampling the initialization of problem~\ref{eq:optimization} at random from the Gaussian prior. For evaluation we consider several test subjects with removed limbs. Figure \ref{fig:completion_variability} shows unique plausible completions of the same partial input achieved by random initializations.

\definecolor{mygray}{rgb}{0.6,0.6,0.6}

% fig: Variability
\begin{figure}
%\vspace{3mm}
\centering
\resizebox{1.05\columnwidth}{!}{
%\begin{tabular}{c@{\hskip 0.02\textwidth}c@{\hskip 0.002\textwidth}c@{\hskip 0.002\textwidth}c@{\hskip 0.002\textwidth}c@{\hskip 0.002\textwidth}}
\begin{tabular}{c@{\hskip 5mm}|@{\hskip 5mm}cccc}
%@{\hskip 0.002\textwidth}c@{\hskip 0.002\textwidth}c@{\hskip 0.002\textwidth}c@{\hskip 0.002\textwidth}}
%\begin{overpic}
%[trim=0cm 0cm 0cm 0cm,clip,height=0.20\textwidth]{./figures/both_arms.png}
%\put(2,82){\footnotesize input}
%\put(130,82){\footnotesize completions}
%\put(45,70){ {\color{mygray}\line(0,-1){220}} }
%\end{overpic}
%\hspace{-1mm} & \hspace{2.5mm}
Input & \multicolumn{4}{c}{Completions} \hspace{5mm} \\ \\
\includegraphics[trim=0 0 150 0,clip,height=0.20\textwidth]{./figures/both_arms.png} &
\includegraphics[height=0.20\textwidth]{./figures/both_arms_2.png} &
\includegraphics[height=0.20\textwidth]{./figures/both_arms_1.png} &
\includegraphics[height=0.20\textwidth]{./figures/both_arms_3.png} &
\includegraphics[height=0.20\textwidth]{./figures/both_arms_4.png} \\
\includegraphics[trim=0 0 150 0,clip,height=0.20\textwidth]{./figures/torso.png} &
\includegraphics[height=0.20\textwidth]{./figures/torso_1.png} &
\includegraphics[height=0.20\textwidth]{./figures/torso_2.png} &
\includegraphics[height=0.20\textwidth]{./figures/torso_5.png} &
\includegraphics[height=0.20\textwidth]{./figures/torso_8.png} \\
\includegraphics[trim=0 0 150 0,clip,height=0.20\textwidth]{./figures/torso_limbs.png} &
\includegraphics[height=0.20\textwidth]{./figures/torso_limbs_3.png} & 
\includegraphics[height=0.20\textwidth]{./figures/torso_limbs_4.png} & 
\includegraphics[height=0.20\textwidth]{./figures/torso_limbs_5.png} & 
\includegraphics[height=0.20\textwidth]{./figures/torso_limbs_6.png}
\end{tabular}
}
\caption{\textbf{Completion variability.} When large contiguous regions (e.g. limbs) are missing, the solution to shape completion is not unique. Shown here are different reconstructions with our method obtained using random initializations.
} 
\label{fig:completion_variability}
\end{figure} 

%

%------ Range scan completion ------
\subsection{Synthetic range scans completion}
\label{subsec:range_scans_completion}
%To demonstrate the usefulness of our method, we tested it on what is probably the most common use case, namely, range scans of humans under different articulation. This data is also suitable for qualitative comparison as sufficient information is given in the partial shape to make the completion problem nearly deterministic.
The following experiment considers the common practical scenario of range scan completion.
We utilize a test-set of $200$ virtual scans produced from $10$ viewpoints around $2$ human subjects exhibiting $10$ different poses. The full shapes were taken from FAUST~\cite{Bogo:CVPR:2014}, and are completely disjoint from our train set, as they contain novel subjects and poses. Furthermore, the data is suitable for quantitative comparison as sufficient information is given in the partial shape to make the completion problem nearly deterministic. Keeping the ground truth correspondence from each view to the full shape, we report the mean completion error in table~\ref{tab_proj_completion} as \emph{Ours (ground truth)}. More interesting are the results of end-to-end completion using partial correspondence obtained by MoNet~\cite{monet} (reported as \emph{Ours (MoNet)}). For reference we report the performance of other shape completion methods: 3D-EPN \cite{dai2016shape} which has shown state-of-the-art performance for shape completion using volumetric networks, Poisson reconstruction \cite{kazhdan2013screened}, and nearest neighbor (NN). Note, in order to comply with the architecture of 3D-EPN, we also provide viewpoint information, which is unknown for our method. For NN the completion is considered to be the closest shape from the entire training using the ground truth correspondences. Results in table~\ref{tab_proj_completion} show mean Euclidean distance (in cm) and relative volumetric error (in \%) for the missing region. More results are shown in Figures~\ref{fig:err_matrix} and~\ref{fig:proj_completion}.

\paragraph{Robust optimization.}
Our method is able to generalize well to partial shapes in poses unseen during training. However, there is a gap in performance when using correspondences from an oracle versus an off-the-shelf technique (MoNet). To handle noisy correspondences better, we propose a robust enhancement to (\ref{eq:optimization}). Observing that our method may not converge to the ideal completion if the alignment is guided by poor correspondences. However, if the partial shape is somewhat well aligned with the generated shape we can recalculate the correspondence $\bb{\Pi}$ using a simple Euclidean closest-vertex assignment. We find that recalculating when SGD plateaus leads to improved completions (results are reported in Table~\ref{tab_proj_completion} as \emph{Ours (MoNet with refinement)}).
A pleasant side-effect of this refinement step is that our shape completion method can be used to obtain a de-noised (albeit sparser) set  of correspondences (see the supplemental material for analysis).
We also evaluate shape completion when the optimization steps are capped at 300 (reported as \emph{Ours (MoNet with refinement $300$)}) as opposed to running until convergence. Note, for simplicity we did not explore tuning different aspects of the method (learning rate, different reconstruction losses, etc).

\begin{table}[tb]
\centering
\small
\begin{tabular}{ l@{\hskip 0.01\textwidth}c@{\hskip 0.01\textwidth}c@{\hskip 0.01\textwidth}c@{\hskip 0.01\textwidth}c@{\hskip 0.01\textwidth}c@{\hskip 0.01\textwidth}c@{\hskip 0.01\textwidth}c  }
    \hline\hline
    Error & Euclidean & Volumetric err. \\     
          & distance [cm] & mean $\pm$ std [\%] \\ \hline    
    Poisson \cite{kazhdan2013screened}  & $7.3$ 	& $24.8 \pm 23.2$  \\
    NN   (ground truth)   & $5.4$ 	& $34.01 \pm 9.23$  \\   
    3D-EPN \cite{dai2016shape} & $4.43$ & $89.7 \pm 33.8$  \\        
    {\bf Ours} (MoNet)   & $3.40$ 	& $12.51 \pm 11.1$  \\ 
    {\bf Ours} (MoNet with ref. $300$)   & $3.01$ & $10.00  \pm 8.83$ \\ 
    {\bf Ours} (MoNet with refinement)   & $\textbf{2.84}$ 	& $\textbf{9.24}  \pm \textbf{8.62}$ \\ %\hline
    {\bf Ours} (ground truth)   & $\textbf{2.51}$ 	& $\textbf{7.48} \pm \textbf{5.64}$ \\ \hline \hline 
  \end{tabular}   
  \vspace{2mm}
\caption{\small \textbf{Synthetic range scans completion.} Comparison of different methods with respect to errors in vertex position and shape volume. Our method is evaluated using ground truth and MoNet~\cite{monet} correspondences, as well as with and without refinement (details in Section \ref{subsec:range_scans_completion}).
}
\label{tab_proj_completion}
\end{table}


\begin{figure}
\centering
\includegraphics[width=0.5\columnwidth]{./figures/range_scan_comparison}
%\input{corr_denoising.tex}
\caption{\textbf{Reconstruction error as a function of view angle.} Our method produces a consistently accurate reconstruction independent of the view angle. } 
\label{fig:err_matrix}
\end{figure} 

% \begin{figure}
% \centering
% %\vspace{12pt}
% \resizebox{1.05\columnwidth}{!}{
% \addtolength{\tabcolsep}{-4pt}
% \begin{tabular}{cccccc}
% \begin{overpic}
% [trim=0cm 0cm 0cm 0cm,clip,height=0.165\textwidth]{./figures/proj_part.png}
% \put(0,88){\small input}
% \end{overpic} & 
% \begin{overpic}
% [trim=0cm 0cm 0cm 0cm,clip,height=0.165\textwidth]{./figures/proj_full.png}
% \put(-7,88){\small ground truth}
% \end{overpic} & 
% \begin{overpic}
% [trim=0cm 0cm 0cm 0cm,clip,height=0.165\textwidth]{./figures/proj_poiss_recon.png}
% \put(-5,88){\small Poisson}
% \end{overpic} & 
% \begin{overpic}
% [trim=0cm 0cm 0cm 0cm,clip,height=0.165\textwidth]{./figures/proj_NN_recon.png}
% \put(0,88){\small NN}
% \end{overpic} & 
% \begin{overpic}
% [trim=0cm 0cm 0cm 0cm,clip,height=0.165\textwidth]{./figures/proj_voxnet_recon.png}
% \put(-7,88){\small 3D-EPN}
% \end{overpic} & 
% \begin{overpic}
% [trim=0cm 0cm 0cm 0cm,clip,height=0.165\textwidth]{./figures/proj_ours_recon.png}
% \put(3,88){\small Ours}
% \end{overpic} \vspace{2mm}\\ 
% \includegraphics[height=0.15\textwidth]{./figures/proj_99_5_part.png} &
% \includegraphics[height=0.15\textwidth]{./figures/proj_99_5_full.png} &
% \includegraphics[height=0.15\textwidth]{./figures/proj_99_5_poiss_recon.png} &
% \includegraphics[height=0.15\textwidth]{./figures/proj_99_5_NN_recon.png} &
% \includegraphics[height=0.15\textwidth]{./figures/proj_99_5_voxnet_recon.png} &
% \includegraphics[height=0.15\textwidth]{./figures/proj_99_5_ours_recon.png}
% %  & \includegraphics[height=0.15\textwidth]{./figures/colorbar.eps} %& \includegraphics[height=0.15\textwidth]{./figures/ptwise_err_poiss.png} & \includegraphics[height=0.15\textwidth]{./figures/ptwise_err_nn.png} %&
% %\includegraphics[height=0.15\textwidth]{./figures/ptwise_err_voxnet.png} & 
% %\includegraphics[height=0.15\textwidth]%{./figures/ptwise_err_ours.png} 
% \end{tabular}
% }
% \vspace{2mm}
% \caption{\textbf{Comparison of different synthetic range scan completion methods.} Depicted left-to-right: input range scan, ground truth complete shape, Poisson reconstruction, 3D-EPN, and our method. 
% %Bottom row shows pointwise errors between the ground truth and the completed shapes on the unseen parts.
% } 
% \label{fig:proj_completion}
% \end{figure} 

\begin{figure*}
\centering
%\vspace{12pt}
%\resizebox{1.85\columnwidth}{!}{
\addtolength{\tabcolsep}{-4pt}
\begin{tabular}{c@{\hskip 7mm}c@{\hskip 7mm}c@{\hskip 7mm}c@{\hskip 7mm}c@{\hskip 7mm}c}
Input & Ground truth & Poisson & NN & 3D-EPN & Ours \\ \\
\includegraphics[trim=0 0 75 0,clip,height=0.18\textwidth]{./figures/proj_part.png} &
\includegraphics[trim=0 0 75 0,clip,height=0.18\textwidth]{./figures/proj_full.png} &
\includegraphics[trim=0 0 75 0,clip,height=0.18\textwidth]{./figures/proj_poiss_recon.png} &
\includegraphics[trim=0 0 75 0,clip,height=0.18\textwidth]{./figures/proj_NN_recon.png} &
\includegraphics[trim=0 0 75 0,clip,height=0.18\textwidth]{./figures/proj_voxnet_recon.png} &
\includegraphics[trim=0 0 75 0,clip,height=0.18\textwidth]{./figures/proj_ours_recon.png} \\ 
\includegraphics[trim=0 0 75 0,clip,height=0.18\textwidth]{./figures/proj_99_5_part.png} &
\includegraphics[trim=0 0 75 0,clip,height=0.18\textwidth]{./figures/proj_99_5_full.png} &
\includegraphics[trim=0 0 75 0,clip,height=0.18\textwidth]{./figures/proj_99_5_poiss_recon.png} &
\includegraphics[trim=0 0 75 0,clip,height=0.18\textwidth]{./figures/proj_99_5_NN_recon.png} &
\includegraphics[trim=0 0 75 0,clip,height=0.18\textwidth]{./figures/proj_99_5_voxnet_recon.png} &
\includegraphics[trim=0 0 75 0,clip,height=0.18\textwidth]{./figures/proj_99_5_ours_recon.png}
\end{tabular}
%}
\caption{\textbf{Comparison of different synthetic range scan completion methods.} From left to right: input range scan, ground truth complete shape, Poisson reconstruction, 3D-EPN, and our method. 
%Bottom row shows pointwise errors between the ground truth and the completed shapes on the unseen parts.
} 
\label{fig:proj_completion}
\end{figure*} 

% \begin{figure}
% \centering
% \includegraphics[width=0.35\textwidth]{./figures/refine_monet.eps}
% \caption{\textbf{Correspondence refinement.}
% %\orlit{TBD}
% } 
% \label{fig:monet_refine}
% \end{figure}

%------ Dynamic Fusion ------
\subsection{Dynamic Fusion}
\label{subsec:dynamic_fusion}

A common use case of depth scanners is object reconstruction form multiple viewpoints. For static scenes, this problem was explored extensively, e.g., in \cite{newcombe2011kinectfusion,niessner2013real,endres2012evaluation}. Non-rigid deformations pose a much bigger challenge. The works of \cite{newcombe2015dynamicfusion} and \cite{innmann2016volumedeform} have shown very impressive reconstructions, however they are limited to small motions between consecutive frames. This limitation was addressed in \cite{slavcheva2017killingfusion} by introducing a damped Killing motion constraint. These methods are focused on reconstructing only the observed dynamic surfaces and cannot convincingly hallucinate large unseen regions. 
Having developed a completion method for non-rigid shapes, we propose its extension to multiple partial inputs. Registering the partial inputs, or the individual reconstructed shapes, is challenging. Instead, we propose to merge shapes in the latent space: we obtain $\bb{z}$ by averaging the completed shape latent variables for each partial input, and $\mathrm{dec}(\bb{z})$ produces the fused 3D shape. Since the latent representation mixes body shape and pose, the reconstructed pose will generally not adhere to any of the input poses, but rather will be an interpolation thereof. 

For a quantitative analysis, we perform fusion on three partial views from a static shape. We use the same FAUST shapes used for testing in Section \ref{subsec:range_scans_completion}. Table~\ref{tab:static_fusion} shows mean reconstruction errors for all $20$ test shapes when fusing three different partial views. The results show how reconstruction accuracy changes according to the viewpoint, and consistently improves with latent space fusion. A qualitative evaluation of the fusion problem is shown for the dynamic setting in Figure~\ref{fig:dynamic_fusion}. Each row shows three partial views of the same human subject from a different viewpoint \emph{and} a different pose. The latent space fusion of the completed shapes is shown in column 4. %and for comparison the human subject in a canonical pose is shown in the final column.   
%\orlit{TBD} 


%--- tab: rigid fusion
\begin{table}[tb]
\centering
\small
\begin{tabular}{ c c c c }
    \hline\hline
     View 1 & View 2 & View 3 & Fused  \\ \hline  
     $2.78$ & $2.94$ & $2.93$ & $\textbf{2.59}$ \\
     $3.03$ & $3.39$ & $2.73$ & $\textbf{2.61}$ \\ 
     \hline \hline 
\end{tabular}   
  \vspace{2mm}

\caption{\small \textbf{Fusion in the latent space.}
Reported is the mean Euclidean error in cm for three partial views ($0^o$, $120^o$ and $240^o$ for the first row and $80^o$, $200^o$ and $320^o$ for the second row). 
}

\label{tab:static_fusion}
\end{table}



%--- fig: dynamic fusion
\begin{figure}
\centering
\resizebox{0.9\columnwidth}{!}{
\addtolength{\tabcolsep}{-4pt}
\begin{tabular}{cccc}
%{\footnotesize pose 1, view 1} & {\footnotesize pose 2, view 2} & {\footnotesize pose 10, view 7} & {\footnotesize fused} %\\
\includegraphics[height=0.25\textwidth]{./figures/scan_1_80_3.png} &
\includegraphics[height=0.25\textwidth]{./figures/scan_1_81_5.png} &
\includegraphics[height=0.25\textwidth]{./figures/scan_1_89_7.png} &
\includegraphics[height=0.25\textwidth]{./figures/fuse_1.png} \\
%\includegraphics[width=0.2\textwidth]{./figures/canonical_80.png} \\
%pose 1, view 4 & pose 2, view 7 & pose 10, view 10 & fused %\\
\includegraphics[height=0.25\textwidth]{./figures/scan_5_90_4.png} &
\includegraphics[height=0.25\textwidth]{./figures/scan_5_91_7.png} &
\includegraphics[height=0.25\textwidth]{./figures/scan_5_99_10.png} &
\includegraphics[height=0.25\textwidth]{./figures/fuse_5.png}
%\includegraphics[width=0.2\textwidth]{./figures/canonical_90.png} \\
\end{tabular}
}
\vspace{3mm}
\caption{\textbf{Dynamic fusion.} Three partial views (columns 1-3) and the reconstructed complete shape (rightmost column).} 
\label{fig:dynamic_fusion}
\end{figure} 

%------ Real data experiment ------
\subsection{Real range scan completion}
The MHAD dataset \cite{ofli2013berkeley} provides Kinect scans from $2$ viewpoints of subjects performing a variety of actions. We apply our completion method to the extracted point cloud (correspondences were initialized through coarse alignment to a training shape, see the supplemental for details). Figure \ref{fig:err_real_data} depicts examples of scan completion on the Kinect data as well as on real scans from the DFAUST dataset.

\begin{figure}
\centering
\resizebox{0.95\columnwidth}{!}{
\begin{tabular}{ccc}
\includegraphics[height=0.3\textwidth]{./figures/mhad_depth.png} &
\includegraphics[height=0.3\textwidth]{./figures/mhad_pc.png} &
\includegraphics[trim=0 0 40 0,clip,height=0.3\textwidth]{./figures/mhad_recon_1.png} \\
\includegraphics[height=0.3\textwidth]{./figures/mhad_depth_3.png} &
\includegraphics[height=0.3\textwidth]{./figures/mhad_pc_3.png} &
\includegraphics[trim=0 0 40 0,clip,height=0.3\textwidth]{./figures/mhad_recon_3.png}
\end{tabular}
}
\newline
\resizebox{0.95\columnwidth}{!}{
\begin{tabular}{cc@{\hskip 15mm}cc}
\includegraphics[height=0.3\textwidth]{./figures/real_scan_dfaust_50022_knees.png} &
\includegraphics[trim=0 0 40 0,clip,height=0.3\textwidth]{./figures/real_scan_dfaust_50022_knees_recon.png} &
\includegraphics[height=0.3\textwidth] {./figures/real_scan_dfaust_50026_shake_arms.png} &
\includegraphics[trim=0 0 40 0,clip,height=0.3\textwidth]{./figures/real_scan_dfaust_50026_shake_arms_recon.png}
\end{tabular}
}
\caption{\textbf{Completion of real range scans.} First two rows: completion of Kinect scans (left: depth image; middle: extracted point cloud; right: completed shape). Last row: completion of scans from the DFAUST dataset.
\vspace{-2mm}
} 
\label{fig:err_real_data}
\end{figure} 

%------ Non-human experiment ------
\subsection{Face completion}
\label{sec:facecompletion}
A strength of our fully data-driven approach is that by avoiding explicit shape modeling it generalizes easily to different classes of shapes. This is illustrated by an evaluation on deformable faces. $2000$ training face meshes, each with $525$ vertices, are generated from the model provided by \cite{gerig2017morphable}. These face models exhibit less variability in pose relative to the human meshes, so we use a much smaller VAE network (only two convolutional layers and a latent dimensionality of $32$). Figure~\ref{fig:faces} shows completion for different styles of simulated partiality as well as simulated correspondence noise (see the supplemental for more details).

\begin{figure}%[tbh]
\centering
%\addtolength{\tabcolsep}{-4pt}
\resizebox{0.95\columnwidth}{!}{
\begin{tabular}{cccc}
\includegraphics[width=0.11\textwidth]{./figures/part_00.png} &
\includegraphics[width=0.11\textwidth]{./figures/part_03.png} &
\includegraphics[width=0.10\textwidth]{./figures/part_11.png} &
\includegraphics[width=0.11\textwidth]{./figures/part_19.png} \\

\includegraphics[width=0.11\textwidth]{./figures/recon_00.png} &
\includegraphics[width=0.11\textwidth]{./figures/recon_03.png} &
\includegraphics[width=0.11\textwidth]{./figures/recon_11.png} &
\includegraphics[width=0.11\textwidth]{./figures/recon_19.png} \\ \\

\includegraphics[width=0.11\textwidth]{./figures/face_hyp_part_01.png} &
\includegraphics[width=0.09\textwidth]{./figures/face_hyp_part_02.png} &
\includegraphics[width=0.11\textwidth]{./figures/face_hyp_part_07.png} &
\includegraphics[width=0.11\textwidth]{./figures/face_hyp_part_12.png} \\

\includegraphics[width=0.11\textwidth]{./figures/face_hyp_recon_01.png} &
\includegraphics[width=0.11\textwidth]{./figures/face_hyp_recon_02.png} &
\includegraphics[width=0.11\textwidth]{./figures/face_hyp_recon_07.png} &
\includegraphics[width=0.11\textwidth]{./figures/face_hyp_recon_12.png} \\ \\

\includegraphics[width=0.11\textwidth]{./figures/face_n5_part_01.png} &
\includegraphics[width=0.11\textwidth]{./figures/face_n5_part_02.png} &
\includegraphics[width=0.11\textwidth]{./figures/face_n5_part_09.png} &
\includegraphics[width=0.11\textwidth]{./figures/face_n5_part_10.png} \\ 

\includegraphics[width=0.11\textwidth]{./figures/face_n5_recon_01.png} &
\includegraphics[width=0.11\textwidth]{./figures/face_n5_recon_02.png} &
\includegraphics[width=0.11\textwidth]{./figures/face_n5_recon_09.png} &
\includegraphics[width=0.11\textwidth]{./figures/face_n5_recon_10.png} \\ \\

\includegraphics[width=0.11\textwidth]{./figures/face_n30_part_00.png} &
\includegraphics[width=0.06\textwidth]{./figures/face_n30_part_01.png} &
\includegraphics[width=0.11\textwidth]{./figures/face_n30_part_08.png} &
\includegraphics[width=0.11\textwidth]{./figures/face_n30_part_09.png} \\ 

\includegraphics[width=0.11\textwidth]{./figures/face_n30_recon_00.png} &
\includegraphics[width=0.11\textwidth]{./figures/face_n30_recon_01.png} &
\includegraphics[width=0.11\textwidth]{./figures/face_n30_recon_08.png} &
\includegraphics[width=0.11\textwidth]{./figures/face_n30_recon_09.png}
\end{tabular}
}
\caption{{\bf Completion of faces.} Inputs and outputs are shown in the odd and even rows, respectively.
Rows 1-2 show completion for missing patches, rows 3-4 show completion for hyperplane cuts, rows 5-6 show completion for hyperplane cuts and 5\% correspondence error, and rows 7-8 show 30\% correspondence error. Results indicate completion is plausible even under large missing regions and robust to reasonable correspondence error.}
\label{fig:faces}
\end{figure} 
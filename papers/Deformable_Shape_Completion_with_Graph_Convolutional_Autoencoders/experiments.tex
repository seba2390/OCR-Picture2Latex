\section{Experiments}
\paragraph{Dataset.} 
The majority of our experiments are performed on human shapes. The VAE is trained on registered 4D scans from the DFAUST dataset~\cite{dfaust:CVPR:2017} comprising $10$ human subjects performing $14$ different activities. Scans are captured at a high frame rate and registered to a canonical topology. Due to the high frame rate, we subsample the data temporally by a factor of $4$. We consistently subsample each mesh by the factor of $2$ down to $N=3446$ vertices. Refer to the supplemental info for details on the data processing. The training set is created by holding out all scans for two human subjects and two activities leaving approximately $7000$ training shapes. Details for additional experiments with face meshes is provided in Section~\ref{sec:facecompletion}.

\paragraph{Network parameters.} 
The structure of our graph-convolutional VAE is illustrated in Figure~\ref{fig:teaser}. We evaluated a number of model parameters on a subset of the training set to inform our final design choices. We use $M=8$ and latent dimensionality of $128$ for all our DFAUST experiments.  
A more important and delicate decision is the selection of the parameter $\lambda$ controlling the emphasis on pushing the variational latent distribution towards the Gaussian prior. Our experiments show, as expected, that a higher weight for the Gaussian prior causes randomly sampled latent vectors to generate realistic shapes more likely, while a lower $\lambda$ improves reconstruction accuracy over a wider variety of shapes. In the context of our problem, it is more important for the latent space to represent and for the decoder to be able to generate a wide variety of shapes accurately. Sampling from the latent space is less important since the final latent vectors are obtained by means of solving the optimization problem (\ref{eq:optimization}). Consequently, we selected $\lambda = 10^{-8}$ at training (see supplemental material for empirical analysis motivating these choices).

\paragraph{Implementation details.}
We train the model directly on the $3 \times N$ input meshes from the DFAUST dataset as described above; the sparse adjacency matrices (we use a vertex 2-ring as the neighborhood size) are passed as side information to define the graph convolutional layers. Data are augmented by adding normally distributed noise to the vertex positions as well as a global planar translations and scalings. We use the ADAM~\cite{kingma2014adam} optimizer with the learning rate set to $10^{-4}$, momentum to $0.9$, batch size to $2$, Xavier initialization~\cite{xavierInit} for all weights, and train for $3 \times 10^5$ iterations. For shape completion optimization we use an SGD optimizer with a $0.1$ learning rate. All additional data for training and evaluation will be provided on the authors' websites.
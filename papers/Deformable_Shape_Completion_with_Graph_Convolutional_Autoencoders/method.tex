\section{Method}
\label{sec:method}
We propose a shape completion method that detaches the process of learning to generate 3D shapes from the task of partial shape completion. Our method requires a generative model for complete 3D shapes which we construct by training a graph-convolutional variational autoencoder (VAE~\cite{kingma2014iclr}). Partial shapes can be completed by identifying the shape in the output space of the VAE's generator which best aligns with the partial input. We propose an optimization in the latent space that iteratively deforms (non-rigidly) a randomly generated shape to align with a partial input. In what follows, we describe in more detail both ingredients of our process, the VAE generator and the partial shape completion scheme. A schematic rendition of the method is depicted in Figure \ref{fig:teaser}.

\paragraph{3D shape generator.}
We fix the number of vertices $N$ and the topology of a reference shape and refer to the three-dimensional vertex embedding $\bb{X}  \in \mathbb{R}^{3 \times N}$ as to a shape.
%
The VAE consists of two networks: the \emph{encoder} that encodes 3D shape inputs $\bb{X}$ to a latent representation vector $\bb{z}=\mathrm{enc}(\bb{x})$, and the \emph{decoder} that decodes the latent vectors into 3D shapes $\bb{X}'=\mathrm{dec}(\bb{z})$. The variational distribution $q(\bb{z}|\bb{X})$ is associated with a prior distribution over the latent variables, and the usual choice which we follow here is a centered multivariate Gaussian with unit variance $\mathcal{N}(\bb{0},\bb{I})$. Our VAE loss combines the shape reconstruction loss $L_r = ||\mathrm{dec}\circ \mathrm{enc} (\bb{X})-\bb{X}||_2$ encouraging the encoder-decoder pair to be a nearly identity transformation, and a regularization prior loss measured by the Kullback-Leibler divergence, $L_p=D_\mathrm{KL}(q(\bb{z}|\bb{X})||p(\bb{z}))$. The total VAE loss is computed as $L=L_r + \lambda L_p$, where $\lambda \geq 0$ controls the similarity of the variational distribution to the prior.

The choice to measure shape reconstruction loss with pointwise distances is not the only option. For example, the VAE can be combined with a Generative Adversarial Network (VAE-GAN) as in~\cite{larsen16icml,wu16nips}, thus introducing an additional discriminator loss on the reconstructed shape. We do not consider a discriminator in the scope of this work to avoid additional model complexity but leave it as future work to investigate different loss functions that can be imposed on reconstructed shapes.

The internal details of the VAE encoder $\mathrm{enc}(\bb{X})$ and decoder $\mathrm{dec}(\bb{z})$ are largely influenced by the choice of the 3D shape representation. As discussed in Section~\ref{sec:relatedwork}, many representations have been explored ranging from voxels to raw point clouds. Our desire to focus on shape completion for deformable object classes leads us to consider intrinsic mesh and surface models that have shown promising results for deformable shape correspondence among other applications (e.g.~\cite{masci15,monet}). Multiple approaches have been proposed to perform convolution on spatial meshes. The primary factor which distinguishes spatial graph convolutional operations is how correspondence is determined between convolutional filters and the local graph neighborhoods. Rather than relying on properties of the underlying geometry to map filters to surface patches, we adopt data-adaptive models which learn the mapping from the neighborhood patch to filters weights. Specifically, our VAE is primarily composed of the dynamic filtering convolutional layers proposed in FeaStNet~\cite{dynFilt}. The input to the layer is a feature vector field on the mesh vertices, attaching to a vertex $i$ a vector $\bb{x}_i$. The output is also a vector field $\bb{y}_i$, possibly of a different dimension, computed as  
\begin{align}\label{eq:filt}
\bb{y}_i = \bb{b} + \sum_{m=1}^{M} \frac{1}{|\mathcal{N}_i|} \sum_{j\in \mathcal{N}_i} q_m(\bb{x}_i, \bb{x}_j) \bb{W}_m \bb{x}_j,
\end{align}
where $\mathcal{N}_i$ denotes a patch around the vertex $i$, and 
$q_m(\bb{x}_i, \bb{x}_j) \propto \exp (\bb{u}_m^\mathrm{T} (\bb{x}_i - \bb{x}_j) + c_m)$
are positive edge weights in the patch normalized to sum to one over $m$.
%
The trainable weights of the layer are $\bb{W}_m$, $\bb{u}_m$, $c_m$ and $\bb{b}$, while the number of weight matrices $M$ is a fixed design parameter. Note that the mapping from neighborhood patch to weights is translation invariant in the input feature space, as $q$ operates only on the differences $\bb{x}_i-\bb{x}_j$. Refer to Figure \ref{fig:teaser} and \cite{dynFilt} for further details.


\paragraph{Partial shape completion.}
Once the encoder-decoder pair has been trained, the encoder is essentially tossed away, while the decoder acts as a complete shape generator, associating to each input latent vector $\bb{z}$ an $\mathbb{R}^3$ embedding of the reference shape, $\bb{X} = \mathrm{dec}(\bb{z})$. Importantly, this acts as a strong shape prior, generating plausible looking shapes (see Figure~\ref{fig:random_sample}).


At inference, a partial shape $\bb{Y}$ is given. We first use an off-the-shelf method (MoNet) \cite{monet} to compute a dense  partial intrinsic correspondence between $\bb{Y}$ and the reference shape. Representing this correspondence as a partial permutation matrix $\bb{\Pi}$ and applying it to any shape $\bb{X}$ generated by the decoder produces a subset of points in $\mathbb{R}^3$, $\bb{X} \bb{\Pi} )$, ordered compatibly with their counterparts in $\bb{Y}$. 
%
We therefore define an extrinsic dissimilarity between the input shape and the generated full shape as
$\mathrm{D}(\bb{X},\bb{Y}) =  \| \bb{X} - \bb{Y} \|$, possibly weighed by the confidence of the correspondence at each point. 

Inference consists essentially of finding a latent vector $\bb{z}^\ast$ minimizing the dissimilarity between the input and the output shape,
\begin{eqnarray}
\min_{\bb{z}, \bb{T} \in \mathrm{SE}(3)} \mathrm{D}(\mathrm{dec}(\bb{z}) \bb{\Pi}, \bb{T} \bb{Y} ),
\label{eq:optimization}
\end{eqnarray}
where $\bb{T}$ denotes a rigid transformation. Alternating steps are performed over $\bb{z}$ (non-rigid deformation) and $\bb{T}$ (rigid registration). When the $\ell_2$ norm is used to define the shape dissimilarity, the rigid registration step has a closed-form solution via the singular value decomposition of the covariance matrix of $\bb{Y}$ and $\bb{X}\bb{\Pi}$, while the non-rigid deformation step is performed using stochastic gradient descent.

%\paragraph{Solution space.}
Shape completion is an inherently ill-posed problem that can have multiple plausible solutions. In cases where there exists more than one solution consistent with the data, sampling a result from our proposed generative model allows us to explore this space. The results in Section \ref{subsec:completion_variability} illustrate the variability in completed shapes when repeating the optimization procedure (\ref{eq:optimization}) with random initializations.
%Initializing the solution of optimization problem (\ref{eq:optimization}) with a random latent vector $\bb{z}$ representing a complete human shape results in convergence to a plausible shape consistent with the input. Multiple random initializations allow to explore this subspace of shapes \orlit{this is a bit repetitive, don't you think?}, as demonstrated in Section \ref{subsec:completion_variability}.
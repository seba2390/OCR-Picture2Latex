%!TEX root = paper.tex
\section{Introduction}

Deep learning methods are highly effective when they can be trained with large amounts of labeled training data in the domain of interest. While such data are not always available in real applications, it is nevertheless often possible to find labeled data in another related domain or for another related task. Considerable effort has gone into designing domain transfer algorithms that leverage such related data~\cite{glorot2011domain,chen2012marginalized,zhou2016bi}. In a typical case, the related domain involves the same classification task (e.g., sentiment analysis) but over different types of examples (e.g., hotel vs restaurant reviews). Labeled training data are available only in the source domain (e.g., hotel reviews) while the task is to provide an effective method for the target domain (e.g., restaurant reviews) without any additional labeled examples. 


% \begin{figure}[t]
% \centering
% \includegraphics[width=0.46\textwidth]{figures/pathology.pdf}
% \caption{A snippet of a breast pathology report with diagnosis results for two types of disease. Evidence for both results is in red and blue, respectively. }\label{fig:pathology}
% \vspace{-0.1in}
% \end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=0.48\textwidth]{figures/task.pdf}
\caption{\add{Comparisons between (a) standard domain adaptation and (b) our aspect transfer problem. Note that in domain adaptation input documents are naturally \emph{different} for the two domains while in aspect transfer both aspects are in the \emph{same} example. The model must find the correct fragment for each aspect (marked by solid line for source and dash line for target) in order to succeed in aspect transfer.}
}\label{fig:pathology}
\vspace{-0.1in}
\end{figure}

In this paper we are primarily interested in transfer between two classification tasks over the same domain, i.e., over the same set of examples. We call this ``aspect transfer'' as the two classification tasks can be thought to pertain to different aspects of the same example. For example, the target goal may be to classify pathology reports (shown in Figure \ref{fig:pathology}b) for the presence of lymph invasion but the available training data involve only annotations for carcinoma in the same reports. \add{Figure \ref{fig:pathology} illustrates how aspect transfer is different from standard domain adaptation (DA). Both transfer problems have to solve the challenge in learning the correspondence of keyword information (in bold) between source and target domains or aspects. However, }existing DA methods do not directly solve this aspect transfer problem because input examples are the \emph{same} across the two aspects. \add{As a result, DA methods will always predict the same label for both aspects and thus fail. The model must learn to extract information from the correct fragment in order to succeed.} 

\add{To address this challenge, we propose to encode the document in an aspect-driven fashion.} Specifically, our approach builds on auxiliary aspect-relevance annotations of sentences which are considerably easier to obtain than actual class labels. Relevance merely indicates a possibility that the answer could be found in a sentence, not what the answer is. One can often write simple keyword rules that identify sentence relevance to a particular aspect through representative terms, e.g., specific hormonal markers in the context of pathology reports. 
%Similar keywords can also indicate absence of relevance.
We can also use keywords of other irrelevant aspects to indicate absence of relevance.
Annotations of this kind can be readily provided by domain experts, or extracted from medical literature such as codex rules in pathology~\cite{pantanowitz2008informatics}. We therefore assume a small number of relevance annotations pertaining to both source and target aspects as a form of weak supervision to learn a sentence-level aspect relevance. This aspect relevance permits us to learn how to encode the examples (e.g., pathology reports) from the point of view of the desired aspect. Specifically, in our approach we construct different aspect-dependent encodings of the same report by softly selecting aspect-relevant sentences from the report.

Our aspect-driven encoding reduces the aspect transfer problem closer to the realm of standard DA. The two domains as in standard DA are induced by different ways of interpreting the same example in our case. These interpretations are themselves learned based on relevance feedback, thus naturally pulled apart. We employ only one label classifier shared between the aspects but it is exercised differently due to aspect-driven encoding of examples. To ensure that the classifier can be adjusted only based on the source class labels and still reasonably applied to the target encodings, we must align the two sets of encoded examples. \add{Learning this alignment is possible in our case because certain common keywords are directly transferable and can serve as anchors of an invariant space. For example, in pathology reports ``identified'' indicates a positive label in both carcinoma and invasion aspects. The key challenge is to learn to project aspect-specific information to this invariant space.}

To address this challenge, we introduce an adversarial domain classifier analogously to recent successful use of adversarial training in computer vision~\cite{ganin2014unsupervised}. \add{This approach is motivated by the theory \cite{ben2007analysis,ben2010theory} that a good transferable representation is one that a classifier cannot learn to identify the origin domain of the input. In particular, the domain classifier is trained to predict the origin aspect/domain of the encoded document. It will achieve a high accuracy as long as encodings contain aspect-specific information. The key of adversarial training is to update the encoder as an adversary against the classifier. In other words, we reverse the gradient from the domain classifier (the adversary) therefore encouraging encodings that make the classifier fail. The encoder therefore learns to eliminate aspect-specific information, establishing aspect-invariance encodings. Such encodings will allow transfer across aspects.} 
Note that this invariance is enforced on the level of sets, not individual examples or reports; encoding of any specific report should remain substantially different for label prediction. To learn the invariance, All the three components in our approach, 1) aspect-driven encoding, 2) classification of source labels, and 3) domain adversary, are trained jointly (concurrently) to complement and balance each other.

%Our relevance driven encoding returns the aspect-transfer problem closer to the realm of standard domain adaption. We employ a shared end classifier between the tasks but it is exercised differently due to aspect-driven encoding of examples. The two domains in a standard domain adaption are therefore induced in our case by different ways of interpreting the same examples. Note that these interpretations are themselves learned based on relevance feedback, thus naturally pulled apart. To ensure that the classifier can be adjusted only based on the source class labels and also reasonably applies to the target encodings, we must align the two sets of encoded examples. This alignment or invariance is enforced on the level of sets, not individual examples or reports; aspect-drive encoding of any specific report should remain substantially different for the two tasks since the encoded examples are passed on to the same classifier. To learn the invariance, we introduce an adversarial domain classifier analogously to recent successful use of adversarial training in computer vision~\cite{ganin2014unsupervised}. The role of the adversary is to learn to distinguish between the two types of encodings, establishing invariance (as sets) when it fails. All the three components in our approach, 1) aspect-driven encoding, 2) classification of source labels, and 3) domain adversary, are trained jointly (concurrently) to complement and balance each other.

Adversarial training of domain and label classifiers can be challenging to stabilize. In our setting, sentences are encoded with a shared convolutional model, weighted by predicted aspect relevance, and then combined into aspect-driven document representations. Feedback from adversarial training can be an unstable guide for how the sentences should be encoded in the first place. To this end, we incorporate an additional word-level autoencoder reconstruction loss to ground the convolutional processing of sentences. We empirically demonstrate that this additional objective yields richer and more diversified feature representations, improving transfer. 

We evaluate our approach on pathology reports (aspect transfer) as well as on a more standard review dataset (domain adaptation). On the pathology dataset, we explore cross-aspect transfer across different types of breast disease. Specifically, we test on six adaptation tasks, consistently outperforming all other baselines. Overall, our full model achieves 27\% and 20.2\% absolute improvement arising from aspect-driven encoding and adversarial training, respectively. Moreover, our unsupervised adaptation method is only 5.7\% behind the accuracy of a supervised target model. On the review dataset, we test adaptation from hotel to restaurant reviews.
Our model outperforms the marginalized denoising autoencoder~\cite{chen2012marginalized} by 5\%.
%Our model outperforms the baseline without adversarial training by 2.5\%. 
Finally, we examine and illustrate the impact of individual components on the resulting performance. 


%We evaluate our approach on pathology reports (aspect transfer) as well as on more standard review dataset (domain adaptation). On the pathology dataset, we explore cross-aspect transfer across different types of breast disease. Specifically, we test on six adaptation tasks, consistently outperforming all other baselines. Overall, our full model achieves 12.8\% absolute improvement arising from adversarial training. Moreover, our unsupervised adaptation method is only 2.8\% behind the accuracy of a supervised target model. On the review dataset, we test adaptation from hotel to restaurant reviews. Our model achieves the best performance on four out of five adaptation tasks, and outperforms the baseline without adversarial training by 2.5\%. Finally, we examine and illustrate the impact of individual components on the resulting performance.  

%This document encoding mechanism brings the problem closer to the realm of standard domain adaption. Such aspect-dependent encodings can be considered as features extracted from source or target domains, which are then passed to one label classifier that are shared between the two domains. To ensure that the classifier can be adjusted only based on the source class labels and also reasonably applies to the target encodings, we must align the two sets of encoded examples.\footnote{This alignment or invariance is enforced on the level of sets, not individual examples or reports; aspect-drive encoding of any specific report should remain substantially different for the two tasks since the encoded examples are passed on to the same classifier.}  Learning this alignment is possible because, as discussed above, some keywords are directly transferable and can serve as anchors for constructing this invariant space. To learn this invariant representation, we employ domain adversarial training analogously to recent success in computer vision~\cite{ganin2014unsupervised}. The core idea is to jointly learn a domain classifier (adversary) whose role is to distinguish between the two types of encodings. During training the encoder is updated with an adversarial objective to fail the classifier. The encoder therefore learns to eliminate aspect-specific information so that encodings look invariant (as sets) to the classifier, thus enabling transfer. All the three components in our approach, 1) aspect-driven encoding, 2) classification of source labels, and 3) domain adversary, are trained jointly (concurrently) to complement and balance each other.
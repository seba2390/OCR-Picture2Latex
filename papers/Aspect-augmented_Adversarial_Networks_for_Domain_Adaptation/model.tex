%!TEX root = paper.tex

%YUAN_CHANGE
\section{Problem Formulation}

We begin by formalizing \emph{aspect transfer} with the idea of differentiating it from standard domain adaptation. In our setup, we have two classification tasks called the source and the target tasks. In contrast to source and target tasks in domain adaptation, both of these tasks are defined over the same set of examples (here documents, e.g., pathology reports). What differentiates the two classification tasks is that they pertain to different aspects in the examples. If each training document were annotated with both the source and the target aspect labels, the problem would reduce to multi-label classification. However, in our setting training labels are available only for the source aspect so the goal is to solve the target task without any associated training label. 

To fix notation, let $\mb{d}=\{\mb{s}_i\}_{i=1}^{|\mb{d}|}$ be a document that consists of a sequence of $|\mb{d}|$ sentences $\mb{s}_i$. Given a document $\mb{d}$, and the aspect of interest, we wish to predict the corresponding aspect-dependent class label $y$ (e.g., $y\in\{-1,1\}$). We assume that the set of possible labels are the same across aspects. We use $y^s_{l;k}$ to denote the k-th coordinate of a one-hot vector indicating the correct training source aspect label for document $\mb{d}_l$. Target aspect labels are not available during training. 

%Each sentence is a sequence of words, namely $\mb{s}_i=\{\mb{x}_{i,j}\}_{j=1}^{|\mb{s}_i|}$, where $\mb{x}_{i,j}\in\mathbb{R}^d$ denotes the vector representation of the j-th word in the i-th sentence. 

Beyond labeled documents for the source aspect $\{\mb{d}_l,y^s_l\}_{l\in L}$, and shared unlabeled documents for source and target aspects $\{\mb{d}_l\}_{l\in U}$, we assume further that we have relevance scores pertaining to each aspect. The relevance is given per sentence, for some subset of sentences across the documents, and indicates the possibility that the answer for that document would be found in the sentence but without indicating which way the answer goes. Relevance is always aspect dependent yet often easy to provide in the form of simple keyword rules. 

We use $r^a_{i} \in \{0,1\}$ to denote the given relevance label pertaining to aspect $a$ for sentence $\mb{s}_i$. Only a small subset of sentences in the training set have associated relevance labels. Let $R = \{(a,l,i)\}$ denote the index set of relevance labels such that if $(a,l,i)\in R$ then aspect $a$'s relevance label $r^a_{l,i}$ is available for the $i^{th}$ sentence in document $\mb{d}_l$. In our case relevance labels arise from aspect-dependent keyword matches. $r^a_{i}=1$ when the sentence contains any keywords pertaining to aspect $a$ and $r^a_i=0$ if it has any keywords of other aspects.\footnote{$r^a_i=1$ if the sentence contains keywords pertaining to both aspect $a$ and other aspects.} Separate subsets of relevance labels are available for each aspect as the keywords differ.

The transfer that is sought here is between two tasks over the same set of examples rather than between two different types of examples for the same task as in standard domain adaptation. However, the two formulations can be reconciled if full relevance annotations are assumed to be available during training and testing. In this scenario, we could simply lift the sets of relevant sentences from each document as new types of documents. The goal would be then to learn to classify documents of type $\mathcal{T}$ (consisting of sentences relevant to the target aspect) based on having labels only for type $\mathcal{S}$ (source) documents, a standard domain adaptation task. Our problem is more challenging as the aspect-relevance of sentences must be learned from limited annotations.

Finally, we note that the aspect transfer problem and the method we develop to solve it work the same even when source and target documents are a priori different, something we will demonstrate later. 

%%%%%%%%%%%OLD FORMULATION BEGIN%%%%%%%%%%%
%We formalize here the aspect transfer problem between the source and target classification tasks over the same set of examples (here documents, e.g., pathology reports). Class labels are available only for the source aspect, and the goal is to solve the target classification task. While we develop our method under the assumption that the examples in the two aspects are the same (as an extreme case), this is not a requirement for our method and it will work fine in more traditional domain adaptation settings as well, which we demonstrate. 

%Let $\mb{d}=\{\mb{s}_i\}_{i=1}^{|\mb{d}|}$ be a document that consists of a sequence of $|\mb{d}|$ sentences. Each sentence is a sequence of words, namely $\mb{s}_i=\{\mb{x}_{i,j}\}_{j=1}^{|\mb{s}_i|}$, where $\mb{x}_{i,j}\in\mathbb{R}^d$ denotes the vector representation of the j-th word in the i-th sentence. Given a document $\mb{d}$ we wish to predict the corresponding class label $y$ (e.g., $y\in\{-1,1\}$) which varies for the same document depending on which aspect (source, target) we are interested in. We assume that the set of possible labels are the same across aspects. %For %example, given a breast cancer pathology %report, the target task may be to %predict whether Ductal Carcinoma In-Situ %(DCIS) is present or not. In sentiment %analysis of hotel reviews, on the other %hand, the output label can be the %polarity of the service or room %quality. We use $y^s_{l;k}$ to denote the k-th coordinate of a one-hot vector indicating the correct source label for document $\mb{d}_l$. 

%Beyond labeled documents for the source aspect $\{\mb{d}_l,y^s_l\}_{l\in L}$, and shared unlabeled documents for source and target aspects $\{\mb{d}_l\}_{l\in U}$, we assume further that we have relevance scores pertaining to each aspect. The relevance is given per sentence, for some subset of sentences across the documents, and indicates the possibility that the answer for that document would be found in the sentence but without indicating which way the answer goes. Relevance is always aspect dependent yet often easy to provide with simple keyword rules. We use $r^a_{i} \in \{0,1\}$ to denote the given relevance label pertaining to aspect $a$ for sentence $\mb{s}_i$.  Specifically, if sentence $\mb{s}_i$ has a relevance label, then $r^a_{i}=1$ when the sentence contains any keywords pertaining to aspect $a$ and $r^a_i=0$ if it has any keywords of other aspects.\footnote{$r^a_i=1$ if the sentence contains keywords pertaining to both aspect $a$ and other aspects.} Otherwise the sentence has no relevance label. Separate subsets of relevance labels are available for each aspect as the keywords differ. Let $R = \{(a,l,i)\}$ denote the index set of relevance labels such that if $(a,l,i)\in R$ then relevance label $r^a_{l,i}$ is available for aspect $a$ and the $i^{th}$ sentence in document $\mb{d}_l$.
%%%%%%%%%%%OLD FORMULATION END%%%%%%%%%%%


\begin{figure*}[t]
%\vspace{-0.1in}
\centering
\includegraphics[width=0.95\textwidth]{figures/model_new2.pdf}
%\vspace{-0.11in}
\caption{Aspect-augmented adversarial network for transfer learning.
%YUAN_CHANGE domain adaptation. 
The model is composed of (a) an aspect-driven document encoder, (b) a label predictor and (c) a domain classifier. 
%\add{Each document is encoded in a relevance weighted, aspect-dependent manner and passed on to both the primary label classifier and the domain classifier as the adversary to ensure invariance. Parameters of all the components are learned jointly during training.}
}
\label{fig:model}
\end{figure*}

\section{Methods}


\subsection{Overview of our approach}


Our model consists of three key components as shown in Figure \ref{fig:model}. Each document is encoded in a relevance weighted, aspect-dependent manner (green, left part of Figure \ref{fig:model}) and classified using the label predictor (blue, top-right). During training, the encoded documents are also passed on to the domain classifier (orange, bottom-right). The role of the domain classifier, as the adversary, is to ensure that the aspect-dependent encodings of documents are distributionally matched. This matching justifies the use of the same end-classifier to provide the predicted label regardless of the task (aspect).  

To encode a document, the model first maps each sentence into a vector and then passes the vector to a scoring network to determine whether the sentence is relevant for the chosen aspect. These predicted relevance scores are used to obtain document vectors by taking relevance-weighted sum of the associated sentence vectors. Thus, the manner in which the document vector is constructed is always \emph{aspect-dependent} due to the chosen relevance weights.

During training, the resulting adjusted document vectors are consumed by the two classifiers. The primary label classifier aims to predict the source labels (when available), while the domain classifier determines whether the document vector pertains to the source or target aspect, which is the label that we know by construction. Furthermore, we jointly update the document encoder with a reverse of the gradient from the domain classifier, so that the encoder learns to induce document representations that fool the domain classifier. The resulting encoded representations will be aspect-invariant, facilitating transfer. 
%The two classifiers involve separate training losses that co-operatively adjust the document representation to ensure it combines both the label predictability and the aspect-invariance property. 
%The primary label classifier aims to predict the source labels (when available), thus enforcing the representation to encode sufficient information for predicting document labels. In the meantime, the domain classifier with adversarial training encourages aspect-invariance in the representation, so that the label classifier trained on source can be directly applied to target. In particular, we update the document encoder with a reverse of the gradient from the domain classifier, so that the encoder learns to induce document representations that make the classifier fail. The resulting representations therefore will be aspect-invariant and will be good for transfer. 

Our adversarial training scheme uses all the training losses concurrently to adjust the model parameters. During testing, we simply encode each test document in a target-aspect dependent manner, and apply the same label predictor. We expect that the same label classifier does well on the target task since it solves the source task, and operates on relevance-weighted representations that are matched across the tasks. 
%We expect that the primary label classifier is able to be exercised in an aspect invariant manner, enabling transfer to the target classification task.
%YUAN_CHANGE, TJ revised
While our method is designed to work in the extreme setting that the examples for the two aspects are the same, this is by no means a requirement. Our method will also work fine in the more traditional domain adaptation setting, which we will demonstrate later.

% During testing

% backup
% We further ground this convolutional model by including a reconstruction step for each word. This process is not illustrated in Figure \ref{fig:model}, but we will detail it in the following subsection. 
%The constrained manner in which these document vectors arise from sentence vectors means that they will retain aspect-specific information that will hinder transfer across aspects. To provide more flexibility in removing non-transferable information, we introduce an additional linear transformation layer after the initial document encoding.

%\add{The resulting document vectors are used by a classifier to predict labels. We use only one final label predictor that for both aspects. While the classifier is trained only on the source labels (when available), we hope it also generalizes well on the target.}

%\add{To this end, the learned document representations need to be transferable across aspects. Similarly to standard domain adaptation, the core goal is to learn to align representations of key information across aspects and project them into the same space, so that the label predictor can treat the two aspects similarly. To achieve this goal, we use the idea of adversarial learning. The key of this idea is to feed the document vector into a domain/aspect classifier that determines whether the document vector pertains to the source or target aspect (i.e., label that we know by construction). This classifier provides a natural measurement on the dissimilarity between aspects because it can achieve high accuracy if representations contain aspect-specific information. We make use of this property in an adversarial way. In other words, we reverse the gradient from the domain classifier (the adversary) therefore encouraging document representations that make the classifier fail. As a result, the encoder learns to eliminate aspect-specific information and thus the representations become directly transferable.}
%Note that The two classifiers involve separate training losses that interact only in terms of the document representation. Specifically, the training signal from the primary classifier is used to co-operatively adjust the document representation.

%%%%%%%%%%OLD VERSION BEGIN%%%%%%%%%%%
%Figure 2 outlines the overall model. Each sentence is first encoded into a vector using a shared convolutional model. We ground this convolutional model by including a reconstruction step for each word based on the internal state centered at the same position. The sentence vectors are then passed on to a single hidden layer network, a separate network for each aspect with a shared hidden layer, to determine whether the sentences are relevant for the chosen aspect. Our relevance predictors are non-negative regression methods as relevance varies more on a linear rather than binary scale. The predicted relevance scores are used to construct document vectors by taking relevance-weighted combinations of the associated sentence vectors. The constrained manner in which these document vectors arise from sentence vectors means that they will retain explicit information about the aspect they were based on. Such explicit cues are not helpful in our setting: the end classifier, trained only on source labels, would unnecessarily rely on cues present only in source-aspect encodings. To remove those cues, we introduce an additional linear transformation layer after the initial document encoding. 

%During training, the resulting adjusted document vectors are used by two classifiers, each involving one hidden layer. The primary end classifier aims to predict the source labels (when available), while the domain classifier determines whether the document vector pertains to the source or target aspect (i.e., label that we know by construction). The two classifiers involve separate training losses that interact only in terms of the document representation. Specifically, the training signal from the primary classifier is used to co-operatively adjust the document representation whereas the gradient from the domain classifier (the adversary) is reversed therefore encouraging representations that make it fail. 

%The four training losses pertaining to word reconstruction, relevance labels, source class labels, and domain labels are used concurrently in our adversarial training scheme to adjust the model parameters. At the conclusion of training, we expect that the primary classifier is able to predict the source labels while appearing to be exercised in a domain invariant manner, enabling transfer to the target task.
%%%%%%%%%%%OLD VERSION END%%%%%%%%%%%%%

\begin{figure}[t]
\centering
\includegraphics[width=0.44\textwidth]{figures/recon_new.pdf}
%\vspace{-0.11in}
\caption{Illustration of the convolutional model and the reconstruction of word embeddings from the associated convolutional layer.}
\label{fig:recon}
%\vspace{-0.05in}
\end{figure}

\subsection{Components in detail}

%We provide here additional details of %each of the components in the model, %including how they are trained as part %of the overall approach. 

\paragraph{Sentence embedding} 
We apply a convolutional model illustrated in Figure \ref{fig:recon} to each sentence $\mb{s}_i$ to obtain sentence-level vector embeddings $\mb{x}^{sen}_i$. The use of RNNs or bi-LSTMs would result in more flexible sentence embeddings but based on our initial experiments, we did not observe any significant gains over the simpler CNNs. 

%With adversarial training, we observe that the document representation $\mb{x}^{doc}$ always has non-zero values only on a small \emph{fixed} set of dimensions, while all other dimensions have zero values. This feature distribution is trivially domain-invariant, but it eliminates too much information for label predictions. Tuning the strength weight $\rho$ in Equation \ref{eq:adv} is tricky and hard to work well. To address this issue, 


We further ground the resulting sentence embeddings by including an additional word-level reconstruction step in the convolutional model. The purpose of this reconstruction step is to balance adversarial training signals propagating back from the domain classifier. Specifically, it forces the sentence encoder to keep rich word-level information in contrast to adversarial training that seeks to eliminate aspect specific features. We provide an empirical analysis of the impact of this reconstruction in the experiment section (Section \ref{sec:analysis}).

%based on the internal state centered at the same position
More concretely, we reconstruct word embedding from the corresponding convolutional layer, as shown in Figure \ref{fig:recon}.\footnote{
This process is omitted in Figure \ref{fig:model} for brevity.} 
We use $\mb{x}_{i,j}$ to denote the embedding of the $j$-th word in sentence $\mb{s}_i$.
Let $\mb{h}_{i,j}$ be the convolutional output when $\mb{x}_{i,j}$ is at the center of the window. We reconstruct $\mb{x}_{i,j}$ by
\be
\hat{\mb{x}}_{i,j} = \tanh(\mb{W}^c\mb{h}_{i,j}+\mb{b}^c)
\ee
where $\mb{W}^c$ and $\mb{b}^c$ are parameters of the reconstruction layer. The loss associated with the reconstruction for document $\mb{d}$ is 
\be
\mathcal{L}^{rec}(\mb{d}) = \frac{1}{n}\sum_{i,j} ||\hat{\mb{x}}_{i,j}-\tanh(\mb{x}_{i,j})||_2^2
\ee
where $n$ is the number of tokens in the document and indexes $i$, $j$ identify the sentence and word, respectively. The overall reconstruction loss $\mathcal{L}^{rec}$ is obtained by summing over all labeled/unlabeled documents. 


%a single hidden layer network, a separate network for each aspect with a shared hidden layer, to determine whether the sentences are relevant for the chosen aspect. Our relevance predictors are non-negative regression methods as relevance varies more on a linear rather than binary scale. 
\paragraph{Relevance prediction} 
We use a small set of keyword rules to generate binary relevance labels, both positive ($r=1$) and negative ($r=0$). These labels represent the only supervision available to predict relevance. The prediction is made on the basis of the sentence vector $\mb{x}^{sen}_i$ passed through a feed-forward network with a ReLU output unit. The network has a single shared hidden layer and a separate output layer for each aspect. Note that our relevance prediction network is trained as a non-negative regression model even though the available labels are binary, as relevance varies more on a linear rather than binary scale.
%\footnote{A linear regression model could work equally well, but we opt to use a network in our work as part of the unified model.}

Given relevance labels indexed by $R=\{(a,l,i)\}$, we minimize 
\be
\mathcal{L}^{rel} = \sum_{(a,l,i)\in R} \big(r^a_{l,i} - \hat r^a_{l,i}\big)^2
\ee
where $\hat r^a_{l,i}$ is the predicted (non-negative) relevance score pertaining to aspect $a$ for the $i^{th}$ sentence in document $\mb{d}_l$, as shown in the left part of Figure~\ref{fig:model}. $r^a_{l,i}$, defined earlier, is the given binary (0/1) relevance label. 
% YUAN CHANGE: 5
We use a score in $[0, 1]$ scale because it can be naturally used as a weight for vector combinations, as shown next.

\paragraph{Document encoding}

The initial vector representation for each document such as $\mb{d}_l$ is obtained as a relevance weighted combination of the associated sentence vectors, i.e.,
\be
\mb{x}^{doc,a}_l = 
\frac{\sum_{i}\hat{r}^a_{l,i}\cdot \mb{x}^{sen}_{l,i}}{\sum_{i}\hat{r}^a_{l,i}}
\ee
The resulting vector selectively encodes information from the sentences based on relevance to the focal aspect.

%The constrained manner in which these document vectors arise from sentence vectors means that they will retain aspect-specific information that will hinder transfer across aspects. To provide more flexibility in removing non-transferable information, we introduce an additional linear transformation layer after the initial document encoding.
\paragraph{Transformation layer} The manner in which document vectors arise from sentence vectors means that they will retain aspect-specific information that will hinder transfer across aspects. To help remove non-transferable information, we add a transformation layer to map the initial document vectors $\mb{x}^{doc,a}_l$ to their domain invariant (as a set) versions, as shown in Figure \ref{fig:model}. Specifically, the transformed representation is given by $\mb{x}^{tr,a}_l=\mb{W}^{tr}\mb{x}^{doc,a}_l$. Meanwhile, the transformation has to be strongly regularized lest the gradient from the adversary would wipe out all the document signal.  
We add the following regularization term 
\be\label{eq:transformation}
\Omega^{tr} = \lambda^{tr}||\mb{W}^{tr}-\mb{I}||_F^2
\ee
to discourage significant deviation away from identity $\mb{I}$. $\lambda^{tr}$ is a regularization parameter that has to be set separately based on validation performance. We show an empirical analysis of the impact of this transformation layer in Section~\ref{sec:analysis}.
%We show the importance of this transformation in our experiments (Section~\ref{sec:analysis}).

\paragraph{Primary label classifier} As shown in the top-right part of Figure~\ref{fig:model}, the classifier takes in the adjusted document representation as an input and predicts a probability distribution over the possible class labels. The classifier is a feed-forward network with a single hidden layer using ReLU activations and a softmax output layer over the possible class labels. 
% YUAN CHANGE: 4(b)
Note that we train only one label classifier that is shared by both aspects.
The classifier operates the same regardless of the aspect to which the document was encoded. It must therefore be co-operatively learned together with the encodings. 

Let $\hat p_{l;k}$ denote the predicted probability of class $k$ for document $\mb{d}_l$ when the document is encoded from the point of view of the source aspect. Recall that $[y^s_{l;1},\ldots,y^s_{l;m}]$ is a one-hot vector for the correct (given) source class label for document $\mb{d}_l$, hence also a distribution. We use the cross-entropy loss for the label classifier
\be
\mathcal{L}^{lab} = \sum_{l\in L}\left[
-\sum_{k=1}^m y^s_{l;k} \log\hat{p}_{l;k}
\right] 
\ee

\paragraph{Domain classifier} As shown in the bottom-right part of Figure~\ref{fig:model}, the domain classifier functions as an adversary to ensure that the documents encoded with respect to the source and target aspects look the same as sets of examples. The invariance is achieved when the domain classifier (as the adversary) fails to distinguish between the two. Structurally, the domain classifier is a feed-forward network with a single ReLU hidden layer and a softmax output layer over the two aspect labels.

Let $y^a = [y^a_{1},y^a_{2}]$ denote the one-hot domain label vector for aspect $a\in \{s,t\}$. In other words, $y^s = [1,0]$ and $y^t = [0,1]$. We use $\hat q_{k}(\mb{x}^{tr,a}_l)$ as the predicted probability that the domain label is $k$ when the domain classifier receives $\mb{x}^{tr,a}_l$ as the input. The domain classifier is trained to minimize 
\be
\mathcal{L}^{dom} = \sum_{l\in L\cup U}\sum_{a\in \{s,t\}}\left[
-\sum_{k=1}^2 y^a_k \log \hat q_k(\mb{x}^{tr,a}_l)
\right]
\ee

\iffalse % ---------------------
The learning objective of the domain classifier is to minimize the squared error between the prediction $\tilde{y}^d$ and the domain label $y^d$.

\be
\mathcal{L}^{dom} = (\tilde{y}^d - y^d)^2
\ee

\tb{other options}

\be
\mathcal{L}^{dom} = -\sum_{d}y^d\log \tilde{y}^d
\ee

In the meantime, we optimize the underlying document features to confuse the domain classifier. In other words, the document encoder should generate features that make the classifier output $\tilde{y}^d=0.5$ on both domains. Therefore, we update the encoder to minimize the following adversarial loss function.
\be\label{eq:adv}
\mathcal{L}^{adv} = \rho(\tilde{y}^d - 0.5)^2
\ee
\tb{other options}
\be
\mathcal{L}^{adv} = - \rho\mathcal{L}^{dom}
\ee
\tb{or}
\be
\mathcal{L}^{adv} = -\rho\sum_{d}(1-y^d)\log \tilde{y}^d
\ee
\tb{or}
\be
\mathcal{L}^{adv} = -\rho\sum_{d}0.5\log \tilde{y}^d
\ee
\tb{Eq 5 is used by original GAN}

where $\rho$ is a hyper-parameter that controls the strength of adversarial training. Because domain labels $y^d$ are known to every input, we can train the classifier with both labeled and unlabeled data.
\fi % ---------------------

\subsection{Joint learning}

%The four training losses pertaining to word reconstruction, relevance labels, source class labels, and domain labels are used concurrently in our adversarial training scheme to adjust the model parameters. At the conclusion of training, we expect that the primary classifier is able to predict the source labels while appearing to be exercised in a domain invariant manner, enabling transfer to the target task.
We combine the individual component losses pertaining to word reconstruction, relevance labels, transformation layer regularization, source class labels, and domain adversary into an overall objective function
\begin{align}
&\mathcal{L}^{all} = 
\mathcal{L}^{rec}+\mathcal{L}^{rel}+\Omega^{tr}+\mathcal{L}^{lab}
-\rho\mathcal{L}^{dom}
\end{align}
which is minimized with respect to the model parameters except for the adversary (domain classifier). The adversary is maximizing the same objective with respect to its own parameters. The last term $-\rho\mathcal{L}^{dom}$ corresponds to the objective of causing the domain classifier to fail. The proportionality constant $\rho$ controls the impact of gradients from the adversary on the document representation; the adversary itself is always directly minimizing $\mathcal{L}^{dom}$.

All the parameters are optimized jointly using standard backpropagation (concurrent for the adversary). Each mini-batch is balanced by aspect, half coming from the source, the other half from the target. All the loss functions except $\mathcal{L}^{lab}$ make use of both labeled and unlabeled documents. Additionally, it would be straightforward to add a loss term for target labels if they are available. 

% intro, talk about multi aspect challenge. motivation for domain adversarial

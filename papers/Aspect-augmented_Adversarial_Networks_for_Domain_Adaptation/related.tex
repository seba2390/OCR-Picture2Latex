% domain adaptation, SCL etc. deep learning approach
% technically similar
% semeval shared task
% rationale augmented CNN
% In both approaches, the actual classifier/predictor is learned in a separate step using the feature representation learned by autoencoder(s)

\section{Related Work}

\paragraph{Domain Adaptation for Deep Learning}
%A large number of domain adaptation %methods have been proposed in the %context of shallow learning, ranging %from data reweighing %\cite{huang2006correcting,gong2013connec%ting} to learning correspondence between %features %\cite{blitzer2006domain,daume2009frustra%tingly,yang2015unsupervised}. The key %idea is to learn to distill the domain-%invariant properties from explicitly %defined features, such as word n-grams. %However, this idea is not directly %applicable to deep learning methods %because the learned mapping from inputs %to representations lacks %interpretability in this case.

%RB This sentence is really pedestrian and can be safely removed.
%Recently, there has been an increasing %amount of deep learning work on domain %adaptation for NLP tasks. 

%RB you need to have some high level summary of what is common across prior approaches. And also add a few sentences about each method. You have to expand this part
Existing approaches commonly induce abstract representations without pulling apart different aspects in the same example, and therefore are likely to fail on the aspect transfer problem.
The majority of these prior methods first learn a task-independent representation, and then train a label predictor (e.g. SVM) on this representation in a separate step. 
For example, earlier researches employ a shared autoencoder~\cite{glorot2011domain,chopra2013dlid} to learn a cross-domain representation.  
%or a deep convolutional neural network~\cite{donahue2014decaf} to learn cross-domain representation.  
%\newcite{donahue2014decaf} extract cross-domain features of images from activation values of a shared deep convolutional neural network.  
\newcite{chen2012marginalized} further improve and stabilize the representation learning by utilizing marginalized denoising autoencoders.
Later, \newcite{zhou2016bi} propose to minimize domain-shift of the autoencoder in a linear data combination manner.
Other researches have focused on learning transferable representations in an end-to-end fashion. Examples include using transduction learning for object recognition~\cite{sener2016learning} and using residual transfer networks for image classification~\cite{long2016unsupervised}. In contrast, we use adversarial training to encourage learning domain-invariant features in a more explicit way. Our approach offers another two advantages over prior work. First, we jointly optimize features with the final classification task while many previous works only learn task-independent features using autoencoders. Second, our model can handle traditional domain transfer as well as aspect transfer, while previous methods can only handle the former.
%residual transfer networks to learn adaptive classifiers



\paragraph{Adversarial Learning in Vision and NLP}
%RB You need to have a summary sentence that explains what is adversarial training and how it was used in vision
Our approach closely relates to the idea of domain-adversarial training. Adversarial networks were originally developed for image generation \cite{goodfellow2014generative,makhzani2015adversarial,springenberg2015unsupervised,radford2015unsupervised,taigman2016unsupervised}, and were later applied to domain adaptation in computer vision~\cite{ganin2014unsupervised,ganin2015domain,domain_separation_nets16,tzeng2014deep} and speech recognition~\cite{shinohara2016adversarial}. 
The core idea of these approaches is to promote the emergence of invariant image features by optimizing the feature extractor as an adversary against the domain classifier.
While \newcite{ganin2015domain} also apply this idea to sentiment analysis, their practical gains have remained limited. 

Our approach presents two main departures. In computer vision, adversarial learning has been used for transferring across domains, while our method can also handle aspect transfer.  In addition, we introduce a
reconstruction loss which results in more robust adversarial training. We believe that this formulation will benefit other applications of adversarial training, beyond the ones described in this paper.

\paragraph{Semi-supervised Learning with Keywords} In our work, we use a small set of keywords as a source of weak supervision for aspect-relevance scoring. This relates to prior work on utilizing prototypes and seed words in semi-supervised learning~\cite{haghighi2006prototype,grenager2005unsupervised,chang2007guiding,mann2008generalized,jagarlamudi2012incorporating,li2012wiki,eisenstein2017unsupervised}. 
All these prior approaches utilize prototype annotations primarily targeting model bootstrapping but not for learning representations. In contrast, our model uses provided keywords to learn aspect-driven encoding of input examples. 

%Most recently, %\newcite{eisenstein2017unsupervised} %propose a prototype reweighing strategy %to improve lexicon-based classification.  

%RB this comparison is very weak. I hope you can generate a more informative sentence
%All these approaches assume prototypes as a direct label for the target task, such as ``dog must be a noun'' in POS tagging. In contrast, our keywords have no information about labels of the target task and our model only utilizes keywords to identify different aspects in a document.


\paragraph{Attention Mechanism in NLP} One may view our aspect-relevance scorer as a sentence-level ``semi-supervised attention'', in which relevant sentences receive more attention during feature extraction. While traditional attention-based models typically induce attention in an unsupervised manner, they have to rely on a large amount of labeled data for the target task~\cite{bahdanau2014neural,rush2015neural,chen2015abc,cheng2016long,xu2015show,xu2015ask,yang2015stacked,martins2016softmax,lei2016rationalizing}. Unlike these methods, our approach assumes no label annotations in the target domain. Other researches have focused on utilizing human-provided rationales as ``supervised attention'' to improve prediction~\cite{zaidan2007using,marshall2015robotreviewer,zhang2016rationale,brun-perez-roux:2016:SemEval}. In contrast, our model only assumes access to a small set of keywords as a source of weak supervision. Moreover, all these prior approaches focus on in-domain classification. In this paper, however, we study the task in the context of domain adaptation. 

\paragraph{Multitask Learning}  Existing multitask learning methods
focus on the case where supervision is available for all tasks. A typical architecture involves using a shared encoder with a separate classifier for each task. \cite{caruana1998multitask,pan2010survey,collobert2008unified,liu2015representation,bordes2012joint}. In contrast, our work assumes labeled data only for the source aspect. We train a single classifier for both aspects by learning aspect-invariant representation that enables the transfer. 

%Our aspect-augmented model also relates to previous work on rationale/aspect-based classification \cite{zaidan2007using,marshall2015robotreviewer,zhang2016rationale,brun-perez-roux:2016:SemEval}. These methods typically rely on human-provided rationales to improve prediction. In contrast, our model only assumes access to a small set of keywords as a source of weak supervision. Attention-based models, on the other hand, offer an unsupervised mechanism to induce \emph{soft} attention over each unit in texts \cite{bahdanau2014neural,rush2015neural,chen2015abc,cheng2016long,xu2015show,xu2015ask,yang2015stacked,martins2016softmax}. However, such attention is learned with a large amount of labeled data while our work assumes no annotations in the target domain. Most recently, \newcite{lei2016rationalizing} introduce a stochastic attention mechanism that selects \emph{hard} rationales in an unsupervised manner. However, similarly to attention models, this rationale selections is also learned using labeled data. Moreover, all prior approaches focus on in-domain classification. In this paper, however, we study aspect-based classification in the context of domain adaptation. 

% Domain-Adversarial Training of Neural Networks
% Adversarial Multi-Task Learning of Deep Neural Networks for Robust Speech Recognition
% Revisiting Batch Normalization For Practical Domain Adaptation
% Bi-Transferring Deep Neural Networks for Domain Adaptation, a linear data reconstruction manner
% Deep learning for domain adaptation by interpolating between domains
%Deep Learning for Aspect-Based Sentiment Analysis, assume gold relevance score. 1
% brun-perez-roux:2016:SemEval
% Show, attend and tell: Neural image caption generation with visual attention
% Rationale-Augmented Convolutional Neural Networks for Text Classification


\section{Related Work}

\xhdr{Contextual Reasoning and Scene Graphs.}
The idea of using context to improve scene understanding has a long history in computer vision \cite{parikh2008appearance, oliva2007role, ladicky2010graph, rabinovich2007objects}. More recently, inspired by representations studied by the graphics community, Johnson \etal \cite{Johnson2015CVPR} introduced the problem of extracting scene graphs from images, which generalizes the task of object detection \cite{girshick2014rich, girshick2015fast, ren2015faster, redmon2016you, liu2016ssd} to also detecting relationships and attributes of objects.

\xhdr{Scene Graph Generation}. A number of approaches have been proposed for the detection of both objects and their relationships \cite{lu2016visual, zhuang2017towards, peyre2017weakly, zhang2017ppr, zhang2017visual, xu2017scene, li2017vip, liang2017deep, dai2017detecting, li2017scene, newell2017pixels, zellers2017neural}. Though most of these works point out that reasoning over a quadratic number of relationships in the scene graph is intractable, each resorted to heuristic methods like random sampling to address this problem. Our work is the first to introduce a trainable relationship proposal network (RePN) that learns to prune unlikely relationship edges from the graph without sacrificing efficacy. RePN provides high-quality relationship candidates, which we find improves overall scene graph generation performance. 

Most scene graph generation methods also include some mechanisms for context propagation and reasoning over a candidate scene graph in order to refine the final labeling. 
In \cite{xu2017scene}, Xu \etal decomposed the problem into two sub-graphs -- one for objects and one for relationships -- and performed message passing. 
Similarly, in \cite{li2017vip}, the authors propose two message-passing strategies (parallel and sequential) for propagating information between objects and relationships. 
Dai \etal \cite{dai2017detecting} address model the scene graph generation process as inference on a conditional random field (CRF). 
Newell \etal ~\cite{newell2017pixels} proposed to directly generate scene graphs  
from image pixels without the use of object detector based on associative graph embeddings. 
%
In our work, we develop a novel attentional graph convolutional network (aGCN) to update node and relationship 
representations by propagating context between nodes in candidate scene graphs -- operating both on visual and semantic features. 
While similar in function to the message-passing based approach above, aGCN is highly efficient and can learn to place 
attention on reliable edges and dampen the influence of unlikely ones. 

%regularities
A number of previous approaches have noted the strong regularities in scene graph generation which motivate our approach.
In \cite{lu2016visual}, Lu \etal ~integrates semantic priors from language to improve the detection of meaningful relationships between objects. Likewise, Li \etal ~\cite{li2017scene} demonstrated that region captions can also provide useful context for scene graph generation. Most related to our motivation, Zeller \etal \cite{zellers2017neural} formalize the notion of motifs (\ie, regularly occurring graph structures) and examine their prevalence in the Visual Genome dataset \cite{krishna2017visual}. The authors also propose a surprisingly strong baseline which directly uses frequency priors to predict relationships -- explicitly integrating regularities in the graph structure. 

\xhdr{Relationship Proposals}. Our Relationship Proposal Network  (RePN) is inspired and relates strongly to the region proposal network (RPN) of faster R-CNN \cite{ren2015faster} used in object detection. Our RePN is also similar in spirit to the recently-proposed relationship proposal network (Rel-PN) \cite{zhang2017relationship}. There are a number of subtle differences between these approaches. The Rel-PN model independently predicts proposals for subject, objects and predicates, and then re-scores all valid triples, while our RePN generates relations conditioned on objects, allowing it to learn object-pair relationship biases. Moreover, their approach is class agnostic and has not been used for scene graph generation. 

\xhdr{Graph Convolutional Networks (GCNs)}. GCNs were first proposed in \cite{kipf2016semi} in the context of semi-supervised learning. GCNs decompose complicated computation over graph data into a series of localized operations (typically only involving neighboring nodes) for each node at each time step. The structure and edge strengths are typically fixed prior to the computation. 
%
For completeness, we note that an upcoming publication \cite{velivckovic2017graph} has concurrently and independently developed a similar GCN attention mechanism (as aGCN) and shown its effectiveness in other (non-computer vision) contexts.
\section{Preliminaries} \label{sec:overview}
\begin{figure}[t]
    \centering
    \includegraphics[width=0.48\textwidth]{figs/overview3.pdf}
    \caption{\system{} pipeline. The explanation Mining module and the Opinion Phrase Canonicalization module form our major technical contributions.}
    \label{fig:overview}
    \vspace{-2mm}
\end{figure}


An \textsl{opinion phrase} is a pair $p=(o, a)$, where $o$ is the \textsl{opinion term}, and $a$ is the aspect term $o$ is referring to. 
For example, the last sentence of Review \#1 in Figure~\ref{fig:example}, ``Cons: extremely noisy room with paper thin walls'', contains two opinion phrases: $p_1=$ (``\asop{extremely noisy}'', ``\asop{room}''); and $p_2=$ (``\asop{paper thin}'', ``\asop{walls}''). 
An \textsl{explanation} $e = (p_i\rightarrow p_j)$ is a relationship between two opinion phrases, where $p_i$ explains $p_j$. For example, (\asop{``paper thin walls''} $\rightarrow$ \asop{``extremely noisy room''}) and (\asop{``close to attractions''} $\rightarrow$ \asop{``great location''}) are two valid explanations.\smallskip

\noindent \textsc{\textbf{Definition:}} An \textsl{Opinion  Graph} $G = (N,E)$ for a set $S$ of opinion phrases is such that 
(1) every opinion phrase $p\in S$ belongs to exactly one node $n\in N$,
(2) each node $n\in N$ consists of {\em semantically consistent opinion phrases}, and 
(3) an edge \mbox{$(n_i\rightarrow n_j) \in E$} represents a explanation relationship from $n_i$ to $n_j$. That is, the member phrases of $n_i$ explain the member phrases of $n_j$.\smallskip

The right of Figure~\ref{fig:example} depicts an opinion graph obtained from the opinion phrases mined from the given reviews. Observe that a ``perfect node'' would contain paraphrases and two perfect nodes $n_i$ and $n_j$ will be connected with an edge \mbox{$(n_i\rightarrow n_j) \in E$} if and only if $(p_i\rightarrow p_j) \; \forall \; p_i \in n_i, \; p_j \in n_j$, as is the case in the example of Figure 1. In practice, however, we often deal with imperfect nodes, containing semantically \textsl{similar} phrases and we draw an edge between two nodes whenever
an explanation relationship between the two nodes is very likely (i.e., when a significant number of explanation relationships exist between opinions in the two nodes).

Our goal is to build an opinion graph $G=(N,E)$ with optimal precision and recall for both the nodes (i.e., the clusters of opinion phrases) and the edges (i.e., the explanations between clusters). It is hard, if at all possible, to produce an opinion graph with a single end-to-end model because of the need for mining both opinion phrases and their relationships, as well as the scale of the problem, which often involves thousands of reviews. Therefore, just like the knowledge base construction pipelines~\cite{fader2011identifying, weikum2010information, dong2014knowledge}, we decompose the opinion graph construction problem into several sub-problems and focus on optimizing each sub-problem individually.

\subsection{Opinion Graph Construction Pipeline}
Our opinion graph construction method is inspired by methods used in 
knowledge base construction. We break down the construction of an opinion graph into the four components as illustrated in Figure \ref{fig:overview}. We provide an overview of each component next.\smallskip

\noindent
\textbf{Opinion Mining~} The first step mines opinion phrases from a set of reviews about an entity. For this, we can leverage Aspect-based Sentiment Analysis (ABSA) models~\cite{pontiki2015semeval,pontiki2016semeval} and, in our pipeline, we use an open-source system~\cite{Li:2019:Opine}. The system also predicts the aspect category and sentiment associated with every opinion phrase. As we describe in Section~\ref{sec:cluster}, we exploit these additional signals to improve opinion phrase canonicalization. \smallskip

\noindent    
\textbf{Explanation Mining~}
Next, \system{} discovers explanation relationships, if any, between pairs of extracted opinion phrases from reviews.
We use crowdsourcing to obtain domain-specific labeled data, and develop a supervised multi-task classifier
to discover the explanation relationship between two opinion phrases. Our model outperforms a series of baseline approaches~\cite{rocktaschel2015reasoning,parikh-etal-2016-decomposable}, including the fine-tuned BERT model~\cite{devlin2018bert}. 
    
\noindent \textbf{Opinion Phrase Canonicalization~}  Semantically similar opinion phrases are grouped together (e.g., ``\asop{not far away from Fisherman's Wharf}'' and ``\asop{close to the wharf}'') to form a node in the opinion graph. This is necessary as reviews  
overlap significantly in content and, hence, contain many similar opinion phrases.
To canonicalize opinion phrases, we develop a novel opinion phrase representation learning framework that learns opinion phrase embeddings using weak supervision obtained from the previous steps, namely predicted aspect categories, sentiment polarity scores, and explanation relationships. Similar to entity canonicalization techniques for open knowledge base construction~\cite{Vahishth:2018:CESI,Chen:2019:CanonicalizingKB}, we apply a clustering algorithm to the learned opinion phrase embeddings to cluster semantically similar opinion phrases to canonicalize those opinion phrases. 
We demonstrate improvements in the quality of the canonicalization outcome using our learned opinion phrase embeddings.


\smallskip

\noindent \textbf{Opinion Graph Generation~} Finally, we present an algorithm to construct the final opinion graph. The algorithm constructs an opinion graph by connecting graph nodes according to the aggregated explanation predictions between opinion phrases in the respective nodes. Our user study shows that our method produces graphs that are both accurate and intuitive.

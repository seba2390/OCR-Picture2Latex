\section{Introduction}\label{sec:intro}
The Web is a major resource for people to acquire information, whether factual or subjective. In recent years, there have been significant advances in extracting facts in the form of subject-predicate-object triples and constructing knowledge bases of such facts~\cite{weikum2010information, dong2014knowledge, nickel2015review, mitchell2018never}. In comparison, there are much less efforts around 
constructing organized knowledge bases of opinions~\cite{bhutanisampo}, which are abundant in subjective data, such as reviews and tweets. 
In fact, according to a recent study\footnote{\url{https://fanandfuel.com/no-online-customer-reviews-means-big-problems-2017/}}, more than $90\%$ of customers read reviews before committing on visiting a business or making a purchase. A natural question is thus the following: is there a systematic way to organize opinions into knowledge bases that will make it easier for customers to understand the opinions found in subjective data?


Existing opinion mining techniques~\cite{hu2004aaai, qiu2011coling, liu2012sentiment, pontiki2015semeval, pontiki2016semeval, xu2019bert} cannot be directly applied to organize
the extracted opinions. First, they largely focus on improving the 
accuracy of opinion extraction and aspect-based sentiment analysis of the extracted opinions over a set of predefined aspects. They cannot be used, in particular, to determine the relationships between opinions. For example, while they can determine the sentiment of an extracted opinion \op{very good location}, they cannot explain why the location is very good in relation to other extracted opinions.
Furthermore, simply collecting all extracted opinions will result in a lot of redundancy and may also lead to incorrect conclusions. 
For example, if the list of all extracted opinions are \{\op{quiet room}, \op{very noisy street}, \op{loud neighborhood}, \op{horrible city noise}, \op{quiet room}\}, one can incorrectly conclude that \op{quiet room} is the most popular opinion if the opinions are not organized according to similarity. 
An early attempt~\cite{bhutanisampo} that produces knowledge bases of opinions does not fully address the above limitations since it does not de-duplicate similar opinions, nor considers the direction of explanation between opinions. 

\begin{figure*}[t]
\begin{minipage}[t][][b]{0.45\textwidth}
\centering
\begin{mdframed}
\small
\begin{tabular}{l}%\toprule
\textbf{Review \#1, Score 85, Date: Feb. 30, 2020}  \\
\multicolumn{1}{p{7cm}} {\it Pros: Friendly and helpful staff. Great location. Walking distance to Muni bus stops. Not too far away from Fisherman's Wharf, Aquatic Park. Cons: extremely noisy room with paper thin walls.}  \\ \bottomrule
\textbf{Review \#2, Score 80, Date: Feb. 30, 2019}  \\
\multicolumn{1}{p{7cm}} {\it Good location close to the wharf, aquatic park and the many other attractions. the rooms are ok but a bit noisy, loud fridge and AC.
}  \\%\bottomrule
\end{tabular}
\end{mdframed}
\vspace{-2mm}
\end{minipage}
\begin{minipage}[t][][b]{0.5\textwidth}
\vspace{2mm}
\includegraphics[width=\linewidth]{figs/opinion_graph.pdf}
\end{minipage}
    \caption{Opinion Graph (right) based on opinions extracted from reviews (left). A node explains its parent node.}
\label{fig:example}
\end{figure*}


With the above observations, we asked ourselves the following question:
\textit{Can we go beyond opinion mining to represent opinions and the relationships among them uniformly into a knowledge base?}
To understand how best to organize opinions into a knowledge base, we analyzed the properties of subjective information in reviews through a series of annotation tasks and confirmed that:
\begin{itemize}%[topsep=1pt]
    \item {\em Opinions phrases}, or opinions in short, are pairs of the form (opinion term, aspect term) such as (\op{very good}, \op{location}). Opinions are the most common expression for subjective information in reviews. In $100$ random review sentences that we annotated, we observed that $84.75\%$ of subjective information is in this form. 
    \item {\em Explanation}, or inference, is the most common relationship between opinions that are correlated in reviews.
    We annotated opinions that co-occur in $40$K random review sentences\footnote{Under the Appen platform (\url{https://appen.com/}).} and observed that $12.3\%$ of the opinions are correlated under some relationship (e.g., one explains/contradicts/paraphrases the other). Among these opinions, $74.2\%$ of the opinions are related under the explanation relationship, which is the focus of this paper.
    \item Many opinions and relationships between opinions are oriented around specific entities, not across multiple entities.
    For example, the opinion \op{close to main street} explains \op{very noisy room} for a specific hotel in the review ``Our room was very noisy as it is close to the main street''. However, this explanation may not be true for arbitrary hotels.
\end{itemize}




Based on this analysis, we propose a graph representation for organizing opinions, called the \textsl{Opinion Graph} that organizes opinions around the explanation relationship based on reviews specific to an entity.
A node is an opinion of
the form (opinion term, aspect term) and consists of all opinions that are close to the node according to their semantic similarity. An edge ($u$,$v$) between two nodes $u$ and $v$ denotes that $u$ explains $v$. 
We found this to be a versatile structure for organizing opinions of reviews because (a) the opinion graph is a concise and structured representation of the opinions over lots of reviews, 
(b) the nodes can aggregate and represent opinions at different levels of granularity, (c) the edges explain the opinions based on other opinions that appear in the reviews, (d) the provenance of opinions in nodes can be traced back to the input reviews where they are extracted from, and (e) the opinion graph is a useful abstraction that supports a series of downstream applications, from the generation of explainable review summaries to facilitating search over opinion phrases or criteria~\cite{Li:2019:Opine}. 

The right of Figure~\ref{fig:example} shows an opinion graph that is generated from the hotel reviews on the left of the figure. Each node in the graph represents a set of semantically similar opinions. Each opinion consists of an opinion term, followed by an aspect term. For example, \op{good location}, where \textsl{``good''} is an opinion term and \textsl{``location''} is an aspect term. Each edge represents the explanation relationship between opinions. For example, \op{paper thin walls} explains \op{extremely noisy room}.
This opinion graph enables one to easily create a customized summary of the reviews by using the entire graph, or only for portions of the graph, such as which attractions the hotel is in close proximity with. 
Moreover, end users or downstream applications can navigate aspects and opinions based on their specific needs and seek explanations of the extracted opinions, e.g., understand why the hotel is \textsl{``extremely noisy''} or why it is in a \textsl{``great location''}. A prototype based on this application has been demonstrated~\cite{wang2020extremereader}.

Opinion Graphs are constructed from reviews through a novel opinion graph construction pipeline \system, which we will present in this paper. To the best of our knowledge, \system\ is the first pipeline that can extract and organize both opinions and their explanation relationships from reviews. 
It is challenging to construct an opinion graph from reviews. First, the review sentences are inherently noisy and can be nuanced. Hence, mining
opinions and the explanation relationships between them can be difficult. Second, all opinions and their predicted explanation relationships need to be integrated into one opinion graph, while taking into account potential inaccuracies and the noise and nuances inherent in languages.
To summarize, we make the following contributions:

\begin{itemize} %[topsep=1pt]
    \item We develop \system, a system that generates an opinion graph about an entity from a set of reviews about the entity. \system{} (a) mines opinion phrases, (b) determines the explanation relationships between them, (c) canonicalizes semantically similar opinions into opinion clusters, and (d) generates an opinion graph for the entity from the inferred explanation relationships and opinion clusters. In particular, our technical contributions include the explanation classifier, the in-domain training data, and the opinion phrase learning mechanism for opinion canonicalization.
    \item We evaluate the performance of \system\ through a series of experiments. We show that our explanation classifier performs $5\%$ better than a fine-tuned BERT model~\cite{devlin2018bert} and $10\%$ better than a re-trained textual entailment model~\cite{parikh-etal-2016-decomposable}. We show that learned opinion phrase representations are able to improve existing clustering algorithms by up to $12.7\%$ in V-measure.  
    Finally, our user study shows that human judges agree with the predicted graph edges produced by our system in more than $77\%$ of the cases. 
    \item Our crowdsourced labeled datasets (in the hotel and restaurant domains) for two subtasks (mining explanation relationships and canonicalizing semantically similar opinion phrases) that we use for training and evaluation are publicly available at \url{https://github.com/megagonlabs/explainit}.
\end{itemize}

\noindent
{\bf Outline~}
We give an overview of \system\ in Section~\ref{sec:overview}. We present the component for mining explanation relationships in Section~\ref{sec:exp}. We demonstrate how we canonicalize similar opinion phrases in Section~\ref{sec:cluster} and how we construct an opinion graph in Section~\ref{sec:graph}. We evaluate \system\ in Section~\ref{sec:eval}. We outline related work in Section~\ref{sec:related} and conclude this paper in Section~\ref{sec:conclusion}.



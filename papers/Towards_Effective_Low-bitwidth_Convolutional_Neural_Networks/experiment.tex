\section{Experiment}

To investigate the performance of the proposed methods, we conduct experiments on Cifar100 and ImageNet datasets. Two representative networks, different precisions AlexNet and ResNet-50 are evaluated with top-1 and top-5 accuracy reported. We use a variant of AlexNet structure~\cite{krizhevsky2012imagenet} by removing dropout layers and add batch normalization after each convolutional layer and fully-connected layer. This structure is widely used in previous works~\cite{zhou2016dorefa, zhu2016trained}.  We analyze the effect of the guided training approach, two-stage optimization and the progressive quantization in details in the ablation study. Seven methods are implemented and compared:

\begin{enumerate}
\item ``\textbf{Baseline}'': We implement the baseline model based on DoReFa-Net as described in Section~\ref{sec:baseline}.

\item ``\textbf{TS}'': We apply the two-stage optimization strategy described in  Sec.~\ref{sec:two-stage} and Algorithm~\ref{algo:two-stage} to quantize the weights and activations. We denote the first stage as \textbf{Stage1} and the second stage as \textbf{Stage2}.

\item ``\textbf{PQ}'': We apply the progressive quantization strategy described in  Sec.~\ref{sec:progressive} and Algorithm~\ref{algo:progressive optimization} to continuously quantize weights and activations simultaneously from high-precision (\ie, 32-bit) to low-precision.

\item ``\textbf{Guided}'': We implement the guided training approach as described in Sec.~\ref{sec:mutual} and Algorithm~\ref{algo:one-mutual learning} to independently investigate its effect on the final performance.


\item ``\textbf{PQ+TS}'': We further combine \textbf{PQ} and \textbf{TS} together to see whether their combination can improve the performance.

\item ``\textbf{PQ+TS+Guided}'': This implements the full model by combining \textbf{PQ}, \textbf{TS} and \textbf{Guided} modules together.

\item ``\textbf{PQ+TS+Guided**}'': Based on PQ\-+\-TS\-+\-Guided, we use full-precision weights for the first convolutional layer and the last fully-connected layer following the setting of~\cite{zhu2016trained, zhou2016dorefa} to investigate its sensitivity to the proposed method.
\end{enumerate}



\subsection{Evaluation on ImageNet}

We further train and evaluate our model on ILSVRC2012~\cite{russakovsky2015imagenet}, which includes over 1.2 million images and 50 thousand validation images. We report 4-bit and 2-bit precision accuracy for both AlexNet and ResNet-50. The sequence of bit-width precisions are set as $\{32, 8, 4, 2\}$. The results of INQ~\cite{zhou2017incremental} are directly cited from the original paper. We did not use the sophisticated image augmentation and more details can be found in Sec.~\ref{sec:implementation}. We compare our model to the 32-bit full-precision model, INQ, DoReFa-Net and the baseline approach described in Sec.~\ref{sec:baseline}. For INQ, only the weights are quantized. For DoReFa-Net, the first convolutional layer uses the full-precision weights and the last fully-connected layer use both full-precision weights and activations.


\emph{\textbf{Results on AlexNet:}}
The results for AlexNet are listed in Table~\ref{tab:AlexNet}. Compared to competing approaches, we achieve steadily improvement for 4-bit and 2-bit settings. This can be attributed to the effective progressive optimization and the knowledge from the full-precision model for assisting the optimization process. Furthermore, our 4-bit full model even outperforms the full-precision reference by 0.7\% on top-1 accuracy. This may be due to the fact that on this data, we may not need a model as complex as the full-precision one. However, when the expected bit-width decrease to 2-bit, we observe obvious performance drop compared to the 32-bit model while our low-bit model still brings 2.8\% top-1 accuracy increase compared to the \emph{Baseline} method.


\emph{\textbf{Results on ResNet-50:}}
The results for ResNet-50 are listed in Table~\ref{tab:ResNet-50}. For the full-precision model, we implement it using Pytorch following the re-implementation provided by Facebook\footnote{\url{https://github.com/facebook/fb.resnet.torch}}.
Comparatively, we find that the performance are approximately consistent with the results of AlexNet. Similarly, we observe that our 4-bit full model is comparable with the full-precision reference with no loss of accuracy. When decreasing the precision to 2-bit, we achieve promising improvement over the competing \emph{Baseline} even though there's still an accuracy gap between the full-precision model. Similar to the AlexNet on ImageNet dataset, we find our 2-bit full model improves more comparing with the 4-bit case. This phenomenon shows that when the model becomes more difficult to optimize, the proposed approach turns out to be more effective in dealing with the optimization difficulty.
To better understand our model, we also draw the process of training for 2-bit ResNet-50 in Figure~\ref{fig:resnet_2bits} and more analysis can be referred in Sec.~\ref{sec:ablation}.



\begin{table*}[!tbp]
		\centering
		\scalebox{0.7}
		{
			\begin{tabular}{c c c | c c c | c c c }
				\hline
                 Accuracy & Full precision &5-bit (INQ) &4-bit (DoReFa-Net)  & 4-bit (Baseline)  & 4-bit (PQ+TS+Guided) &2-bit (DoReFa-Net) &2-bit (Baseline) & 2-bit (PQ+TS+Guided)\\\hline
                 Top1 &57.2\%  &57.4\%  &56.2\%  &56.8\%  &\bf{58.0}\%  &48.3\%  &48.8\%  &\bf{51.6}\% \\
                 Top5 &80.3\%  &80.6\%  &79.4\% &80.0\% &\bf{81.1}\% &71.6\%  &72.2\%  &\bf{76.2}\%  \\\hline

			\end{tabular}}
			\caption{Top1 and Top5 validation accuracy of AlexNet on ImageNet.}
			\label{tab:AlexNet}
\end{table*}

\begin{table*}[!tbp]
	\centering
	\scalebox{0.7}
	{
		\begin{tabular}{c c c| c c c | c c c }
			\hline
			Accuracy & Full precision &5-bit (INQ) &4-bit (DoReFa-Net) & 4-bit (Baseline)  & 4-bit (PQ+TS+Guided) &2-bit (DoReFa-Net) &2-bit (Baseline) & 2-bit (PQ+TS+Guided)\\\hline
			Top1 &75.6\%  &74.8\%  &74.5\%  &75.1\%  &\bf{75.7}\%  &67.3\%  &67.7\%  &\bf{70.0}\%  \\
			Top5 &92.2\%  &91.7\%  &91.5\%  &91.9\%  &\bf{92.0}\% &84.3\% &84.7\%  &\bf{87.5}\%  \\\hline

		\end{tabular}}
		\caption{Top1 and Top5 validation accuracy of ResNet-50 on ImageNet.}
		\label{tab:ResNet-50}
	\end{table*}


\subsection{Evaluation on Cifar100}
Cifar100 is an image classification benchmark containing images of size 32x32 in a training set of 50,000 and
a test set of 10,000. We use the AlexNet for our experiment. The quantitative results are reported in  Table~\ref{tab:cifar100_AlexNet}. From the table, we can observe that the proposed approach steadily outperforms the competing method DoReFa-Net. Interestingly, the accuracy of our 4-bit full model also surpasses its full precision model. We speculate that this is due to 4-bit weights and activations providing the right model capacity and preventing overfitting for the networks.

\begin{table*}[!tbp]
	\centering
	\scalebox{0.76}
	{
		\begin{tabular}{c c |c  c c | c c c}
			\hline
			Accuracy & Full precision &4-bit (DoReFa-Net)  & 4-bit (Baseline) & 4-bit (PQ+TS+Guided) &2-bit (DoReFa-Net) &2-bit (Baseline) &2-bit (PQ+TS+Guided)\\\hline
			Top1 &65.4\%  &64.9\% &65.0\%   &\bf{65.8}\%  &63.4\% &63.9\%  &\bf{64.6}\%  \\
			Top5 &88.3\% &88.5\%  &88.5\%   &\bf{88.6}\% &87.5\%  &87.6\%  &\bf{87.8}\% \\\hline

		\end{tabular}}
		\caption{Top1 and Top5 validation accuracy of AlexNet on Cifar100.}
		\label{tab:cifar100_AlexNet}
	\end{table*}


\subsection{Ablation study} \label{sec:ablation}
In this section, we analyze the effects of different components of the proposed model.

\vspace{1mm}
\noindent\textbf{\emph{Learning from scratch vs. Fine-tuning:}}
To analyze the effect, we perform comparative experiments on Cifar100 with AlexNet using learning from scratch and fine-tuning strategies. The results are shown in Figure~\ref{fig:cifar}, respectively. For convenience of exposition, this comparison study is performed based on method \emph{TS}.
First, we observe that the overall accuracy of fine-tuning from full-precision model is higher than that of learning from scratch. This indicates that the initial point for training low-bitwidth model is crutial for obtaining good accuracy.
In addition, the gap between the \emph{Baseline} and \emph{TS} is obvious (\ie, 2.7 \% in our experiment) with learning from scratch. This justifies that the two-stage optimization strategy can effectively help the model converge to a better local minimum.
\begin{figure}
	\centering
	\resizebox{0.9\linewidth}{!}
	{
		\begin{tabular}{c}
			\includegraphics{pdf/cifar100.pdf}
		\end{tabular}
	}
	\caption{Validation accuracy of 4-bit AlexNet on Cifar100 using (a): the fine-tuning strategy; (b): learning from scratch strategy. \emph{Stage2+Guided} means we combine the methods \emph{Stage2} and \emph{Guided} together during optimization to investigate the effect of the guided training on the final performance.}
	\label{fig:cifar}
\end{figure}


\begin{table}[!tbp]
	\centering
	\scalebox{1.0}
	{
		\begin{tabular}{c c c}
			\hline
			Method &top-1  &top-5 \\\hline
			 4-bit (TS) &57.7\% &81.0\%\\
			 4-bit (PQ)  &57.5\%  &80.8\%\\
			 4-bit (PQ+TS) &57.8\% &80.8\% \\
			 4-bit (Guided) &57.3\% &80.4\%\\
			 4-bit (PQ+TS+Guided)  &58.0\% &81.1\%\\
			 4-bit (PQ+TS+Guided**)  &\bf{58.1}\% &\bf{81.2}\% \\\hline
			 2-bit (TS)  &50.7\% &74.9\% \\
			 2-bit (PQ)  &50.3\% &74.8\% \\
			 2-bit (PQ+TS)  &50.9\% &74.9\% \\
			 2-bit (Guided) &50.0\%  &74.1\% \\
			 2-bit (PQ+TS+Guided)  &51.6\% &76.2\% \\
			 2-bit (PQ+TS+Guided**) &\bf{52.5}\% &\bf{77.3}\% \\\hline

		\end{tabular}}
		\caption{Evaluation of different components of the proposed method on the validation accuracy with AlexNet on ImageNet.}
		\label{tab:AlexNet_ablation}
	\end{table}

\begin{table}[!tbp]
	\centering
	\scalebox{1.0}
	{
		\begin{tabular}{c c c}
			\hline
			Method &top-1  &top-5 \\\hline
			4-bit (TS) &75.3\% &91.9\%\\
			4-bit (PQ)  &75.4\%  &91.8\%\\
			4-bit (PQ+TS) &75.5\% &92.0\% \\
			4-bit (Guided) &75.3 \% &91.7\% \\
			4-bit (PQ+TS+Guided)  &75.7\% &92.0\%\\
			4-bit (PQ+TS+Guided**)  &\bf{75.9}\% &\bf{92.4}\% \\\hline
			2-bit (TS)  &69.2\% &87.0\% \\
			2-bit (PQ)  &68.8\% &86.9\% \\
			2-bit (PQ+TS)  &69.4\% &87.0\% \\
		    2-bit (Guided) &69.0\%  & 86.8\%\\
			2-bit (PQ+TS+Guided)  &70.0\% &87.5\% \\
			2-bit (PQ+TS+Guided**) &\bf{70.8}\% &\bf{88.3}\% \\\hline

		\end{tabular}}
			\caption{Evaluation of different components of the proposed method on the validation accuracy with ResNet-50 on ImageNet.}
			\label{tab:ResNet-50_ablation}
\end{table}


\vspace{1mm}
\noindent\textbf{{\emph{The effect of quantizing all layers:}}}
This set of experiments is performed to analyze the influence for quantizing the first convolutional layer and the last fully-connected layer. Several previous works~\cite{zhu2016trained} argue to keep these two layers precision as 32-bit floating points to decrease accuracy loss. By comparing the results of \emph{PQ+TS+Guided**} and \emph{PQ+TS+Guided} in Table~\ref{tab:AlexNet_ablation} and Table~\ref{tab:ResNet-50_ablation}, we notice that the accuracy gap between the two settings is not large, which indicates that our model is not sensitive to the precision of these two layers. It can be attributed to two facts. On one hand, fine-tuning from 32-bit precision can drastically decrease the difficulty for optimization. On the other hand, the progressive optimization approach as well as the guided training strategy further ease the instability during training.

\vspace{1mm}
\noindent\textbf{{\emph{The effect of the two-stage optimization strategy:}}}
We further analyze the effect of each stage in the \emph{TS} approach in Figure~\ref{fig:cifar} and Figure~\ref{fig:resnet_2bits}.
We take the 2-bitwidth ResNet-50 on ImageNet as an example. In Figure~\ref{fig:resnet_2bits}, \emph{Stage1} has the minimal loss of accuracy. As for the \emph{Stage2}, although it incurs apparent accuracy decrease in comparison with that of the \emph{Stage1}, its accuracy is consistently better than the results of \emph{Baseline} in every epoch. This illustrates that progressively seeking for the local minimum point is crutial for final better convergence. We also conduct additional experiments on Cifar100 with 4-bit AlexNet. Interestingly, taking the model of \emph{Stage1} as the initial point, the results of \emph{Stage2} even have relative increase using two different training strategies as mentioned above. This can be interpreted by that further quantizing the activations impose more regularization on the model to overcome overfitting.
Overall, the two-step optimization strategy still performs steadily better than the Baseline method which proves the effectiveness of this simple mechanism.
\begin{figure}[!htb]
	\centering
	\resizebox{0.9\linewidth}{!}
	{
		\begin{tabular}{c}
			\includegraphics{pdf/resnet_2bits.pdf}
		\end{tabular}
	}
	\caption{Validation accuracy of 2-bit ResNet-50 on ImageNet. \emph{Stage2+Guided} means we combine the methods \emph{Stage2} and \emph{Guided} together during training.}
	\label{fig:resnet_2bits}
\end{figure}

\vspace{1mm}
\noindent\textbf{{\emph{The effect of the progressive quantization strategy:}}} What's more, we also separately explore the progressive quantization (\ie, \emph{PQ}) effect on the final performance.
In this experiment, we apply AlexNet on the ImageNet dataset.
We continuously quantize both weights and activations simultaneously from 32-bit$\to$8-bit$\to$4-bit$\to$2-bit and explictly illustrate the accuracy change process for each precision in Figure~\ref{fig:progressive}. The quantitative results are also reported in Table~\ref{tab:AlexNet_ablation}  and Table~\ref{tab:ResNet-50_ablation}. From the figure we can find that for the 8-bit and 4-bit, the low-bit model has no accuracy loss with respect to the full precision model. However, when quantizing from 4-bit to 2-bit, we can observe significant accuracy drop.
Despite this, we still observe $1.5\%$ relative improvement by comparing the top-1 accuracy over the 2-bit baseline, which proves the effectiveness of the proposed strategy. It is worth noticing that the accuracy curves become more unstable when quantizing to lower bit. This phenomenon is reasonable since the precision becomes lower, the value will change more frequently during training.

\begin{figure}[!htb]
	\centering
	\resizebox{0.9\linewidth}{!}
	{
		\begin{tabular}{c}
			\includegraphics{pdf/progressive.pdf}
		\end{tabular}
	}
	\caption{Validation accuracy of the progressive quantization approach using AlexNet on ImageNet.}
	\label{fig:progressive}
\end{figure}

\vspace{1mm}
\noindent\textbf{{\emph{The effect of the jointly guided training:}}}
We also investigate the effect of the guided joint training approach explained in Sec.~\ref{sec:mutual}. By comparing the results in Table~\ref{tab:AlexNet_ablation} and Table~\ref{tab:ResNet-50_ablation}, we can find that \emph{Guided} method steadily improves the \emph{baseline} method by a promising margin. This justifies the low-precision model can always benefit by learning from the full-precision model.
What's more, we can find \emph{PQ+TS+Guided} outperforms \emph{PQ+TS} in all settings. This shows that the guided training strategy and the progressive learning mechanism can benefit from each other for further improvement.

\vspace{1mm}
\noindent\textbf{{\emph{Joint vs. without joint:}}}
We further illustrate the joint optimization effect on guided training in Figure~\ref{fig:mutual}. For explaning convenience, we implement it based on the method \emph{Stage2+Guided} and report the 2-bit AlexNet top-1 validation accuracy on ImageNet. From the figure, we can observe that both the full-precision model and its low-precision counterpart can benefit from learning from each other. In contrast, if we keep the full-precision model unchanged, apparent performance drop is observed. This result strongly supports our assumption that the high-precision and the low-precision models should be jointly optimized in order to obtain the optimal gradient during training. The improvement on the full-precision model may due to the ensemble learning with the low-precision model and similar observation is found in~\cite{zhang2017deep} but with different task.
\begin{figure}[!htb]
	\centering
	\resizebox{0.9\linewidth}{!}
	{
		\begin{tabular}{c}
			\includegraphics{pdf/mutual.pdf}
		\end{tabular}
	}
	\caption{The effect of the joint training strategy using AlexNet on ImageNet.}
	\label{fig:mutual}
\end{figure}


%
%
%
%
%
%
%
%
%
%
%
%
%
%




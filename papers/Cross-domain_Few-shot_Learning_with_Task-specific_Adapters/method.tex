% !TEX root = main.tex

\begin{figure*}[t]
% \begin{center}
\includegraphics[width=0.9\linewidth]{figures/diagram.pdf}
% \end{center}
\vspace{-0.35cm}
\caption{Illustration of our task adaptation for cross-domain few-shot learning. In meta-test stage (a), our method first attaches a parametric transformation $r_{\alpha}$ to each layer, where $\alpha$ can be constructed by (b) a serial or (c) a residual topology. They can be parameterized with matrix multiplication (d) or  channel-wise scaling (e).
We found that (c) is the best configuration with matrix parameterization which is further improved by attaching a linear transformation $A_{\beta}$ to the end of the network. We adapt the network for a given task by optimizing $\alpha$ and $A_{\beta}$ on a few labeled images from the support set, then map query images to the task-specific space and assign them to the nearest class center.}
\label{fig:framework}
\end{figure*}

% few-shot learning
Few-shot classification aims at learning to classify samples of new categories efficiently from few samples only. 
Each few-shot learning task consists of a support set $\mathcal{S}=\{(\bx_i, y_i)\}_{i=1}^{\rvert \mathcal{S} \lvert}$ with $\rvert \mathcal{S} \lvert$ sample and label pairs respectively and a query set $\mathcal{Q}=\{(\bx_j)\}_{j=1}^{\lvert \mathcal{Q} \rvert }$ with $\lvert \mathcal{Q} \rvert$ samples to be classified.
The goal is to learn a classifier on $\mathcal{S}$ that accurately predicts the labels of $\mathcal{Q}$.
Note that this paper focuses on few-shot image classification problem, \ie $\bx$ and $y$ denote an image and its label.

As in \cite{dvornik2020selecting,liu2020universal,li2021universal}, we solve this problem in two steps involving i) representation learning where we learn a task-agnostic feature extractor $f$ from a large dataset $\mathcal{D}_b$, ii) task adaptation where we adapt the task-agnostic representations through various task-specific weights to the target tasks $(\mathcal{S},\mathcal{Q})$ that are sampled from another large dataset $\mathcal{D}_{t}$ by taking the subsets of the dataset to build $\mathcal{S}$ and $\mathcal{Q}$.
Note that $\mathcal{D}_{b}$ and $\mathcal{D}_{t}$ contain mutually exclusive classes.

% simply describe meta-training procedure URL
% \vspace{-0.35cm}
\subsection{Task-agnostic representation learning}
Learning task-agnostic or universal representations~\cite{bilen2017universal} has been key to the success of cross-domain generalization.
Representations learned from a large diverse dataset such as ImageNet~\cite{deng2009imagenet} can be considered as universal and successfully transferred to tasks in different domains with minor adaptations~\cite{rebuffi2017learning,liu2020universal,dvornik2020selecting}.
We denote this setting as single domain learning (SDL).

More powerful and diverse representations can be obtained by training a single network over multiple domains.
Let $\mathcal{D}_{b}=\{\mathcal{D}_{k}\}_{k=1}^{K}$ consists of $K$ subdatasets, each sampled from a different domain. 
The vanilla multi-domain learning (MDL) strategy jointly optimizes network parameters over the images from all $K$ subdatasets:
\begin{equation}\label{eq:mtl}
    \min_{\phi, \psi_{k}} \sum_{k=1}^{K} \frac{1}{|\mathcal{D}_{k}|} \sum_{\bx, y \in \mathcal{D}_{k}} \ell(g_{\psi_{k}} \circ f_{\phi}(\bx), y),
\end{equation} where $\ell$ is cross-entropy loss, $f$ is feature extractor that takes an image as input and outputs a $d$ dimensional feature.
$f$ is parameterized by $\phi$ which is shared across $K$ domains. 
$g_{\psi_{k}}$ is the classifier for domain $k$ and parameterized by $\psi_k$ which is discarded in meta-test.
We denote this setting as MDL.
The challenge in MDL is to allow efficiently sharing the knowledge across the domains while preventing negative transfer between them and also carefully balancing the individual loss functions ( \cite{chen2018gradnorm}). 
URL~\cite{li2021universal}, a variant of MDL, mitigates these challenges by first training individual domain-specific networks offline and then distilling their knowledge into a \emph{single} multi-domain network.
We refer to \cite{li2021universal} for more details.

Another way of obtaining multi-domain representations is to employ multiple domain-specific feature extractors, one for each domain, and adaptively ``fuse'' their features for each task \cite{dvornik2020selecting,liu2021multi,triantafillou2021flute}.
While these methods are effective, they require computing features for each image through multiple feature extractors and are thus computationally expensive.
Due to its simplicity and effectiveness, we conduct experiments with the feature extractor of URL~\cite{li2021universal} along with the SDL one.

% meta-test stage with task adaptation r_{\alpha}
\subsection{Task-specific weight learning}
A good task-agnostic feature extractor $f_{\phi}$ is expected to produce representations that generalize to many previously unseen tasks and domains.
However this gets more challenging when there is a large domain gap between the training set $\mathcal{D}_b$ and test set $\mathcal{D}_t$ which requires further adaptation to the target task.
In this work, we propose to incorporate additional capacity to the task-agnostic feature extractor by adding task-specific weights to adapt the representations to the target task by using the support set. Specifically, we directly attach task-specific weights to a learned task-agnostic model, and estimate them from scratch given the support set.
We denote the task-specific weights with $\vartheta$ and task-adapted classifier with $p_{(\phi,\vartheta)}$ that outputs a softmax probability vector whose dimensionality equals to the number of categories in the support set $\mathcal{S}$.

To obtain the task-specific weights, we freeze the task-agnostic weights $\phi$ and minimize the cross-entropy loss $\ell$ over the support samples in meta-test w.r.t. the task-specific weights $\vartheta$ \cite{dvornik2020selecting,tian2020rethinking,li2021universal}:
\begin{equation}
    \label{eq:learn-tsw}
\min_{\vartheta}\frac{1}{|\mathcal{S}|}\sum_{(\bx, y) \in \mathcal{S}} \ell(p_{(\phi,\vartheta)}(\bx),y),
\end{equation} where $\mathcal{S}$ is sampled from the test set $\mathcal{D}_t$. 
Most previous works freeze the task-agnostic weights but estimate the task-specific weights through an auxiliary network (or a task encoder)~\cite{requeima2019fast,bateni2020improved,li2021universal,triantafillou2021flute}, where inaccurate prediction of parameters can lead to noisy adaptation and wrong prediction.

 
\subsection{Task-specific adapter parameterization ($\vartheta$)}
Task adaptation techniques can be broadly grouped into two categories that aims
to adapt the feature extractor or classifier to a given target task.
We use $\alpha$ and $\beta$ to denote task-specific weights for adapting the feature extractor and classifier respectively where $\vartheta=\{\alpha, \beta\}$.

\paragraph{Feature extractor adaptation.} A simple method to adapt $f_{\phi}$ is finetuning its parameters on the support set \cite{chen2020new,dhillon2019baseline}. 
However, this strategy tends to suffer from the unproportionate optimization, \ie updating very high-dimensional weights from a small number of support samples.
In this paper, we propose to attach task-specific adapters directly to the existing task-agnostic model, \eg we attach the adapters to each module of a ResNet backbone in \cref{fig:framework} (a), and the adapters can be efficiently learned/estimated from few samples.
Concretely, let $f_{\phi_l}$ denote the $l$-th layer of the feature extractor $f_{\phi}$ (\ie a convolutional layer) with the weights $\phi_l$. 
Given a support set $\mathcal{S}$, the task-specific adapters $r_{\alpha}$ parameterized by $\alpha$, can be incorporated to the output of the layer $f_{\phi_l}$ as
\begin{equation}\label{eq:ra}
	f_{\{\phi_l,\alpha\}}(\bh) = r_{\alpha}(f_{\phi_l}(\bh),\bh)
\end{equation} where $\bh\in\mathrm{R}^{W\times H \times C}$ is the input tensor, $f_{\phi_l}$ is a convolutional layer in $f_{\phi}$. 
Importantly, the number of the task-specific adaptation parameters $\alpha$ are significantly smaller than the task-agnostic ones.
The adapters can be designed in different ways.

Next we propose two connection types for incorporating $r_\alpha$ to $f_{\phi_l}$: i) serial connection by subsequently applying it to the output of layer $f_{\phi_l}(\bh)$ as
\[
    f_{\{\phi_l,\alpha\}}(\bh) = r_{\alpha} \circ f_{\phi_l}(\bh)
\] which is illustrated in \cref{fig:framework}(b), and ii) parallel connection by a residual addition as in \cite{rebuffi2018efficient}
\[
    f_{\{\phi_l,\alpha\}}(\bh) = r_{\alpha}(\bh) + f_{\phi_l}(\bh)
\] which is illustrated in \cref{fig:framework}(c). 
In our experiments, we found the parallel setting performing the best when $\alpha$ is learned on a support set during meta-test (illustrated in \cref{fig:framework}(c)) which we discuss in \cref{sec:exp}. 

For the parameterization of $r_{\alpha}$, we consider two options.
Matrix multiplication (illustrated in \cref{fig:framework}(d)) with $\alpha\in\mathrm{R}^{C\times C}$:
\[
    r_{\alpha}(\bh) = \bh \ast \alpha,
\] where $\ast$ denotes a convolution, $\alpha\in \mathbb{R}^{C\times C}$ and the transformation is implemented as a convolutional operation with $1\times 1$ kernels in our code.
And channelwise scaling (illustrated in \cref{fig:framework}(e)):
\[
    r_{\alpha}(\bh) = \bh \odot \alpha,
\] where $\odot$ is a Hadamard product and $\alpha\in \mathbb{R}^C$.
Note that one can also use an additive bias weight in both settings, however, this has not resulted in any significant gains in our experiments. 
While the matrix multiplication is more powerful than the scaling operation, it also requires more parameters to be estimated or learned.
Note that, in a deep neural network, the number of input $C_{\text{in}}$ and output channels $C_{\text{out}}$ for a layer can be different. 
In that case, one can still use a non-square matrix: $\alpha\in\mathrm{R}^{C_{out}\times C_{in}}$, however, it is not possible to use a scaling operator in the parallel setting. 
In our experiments, we use ResNet architecture~\cite{he2016deep} where most input and output channels are the same.
$r_\alpha$ connected in parallel with matrix multiplication form, when its parameters $\alpha$ are learned on the support set, is known as residual adapter~\cite{rebuffi2018efficient} and $r_\alpha$ connected serial in channelwise is known as FiLM~\cite{perez2018film}.

% Comparison with state-of-the-art methods
\begin{table*}[t]
	\centering
    \resizebox{0.9\textwidth}{!}
    {
		\begin{tabular}{ccccccccccccc}

		    \toprule
		    Test Dataset & CNAPS~\cite{requeima2019fast} & Simple CNAPS~\cite{bateni2020improved} & TransductiveCNAPS~\cite{bateni2020enhancing} & SUR~\cite{dvornik2020selecting} & URT~\cite{liu2020universal} & FLUTE~\cite{triantafillou2021flute} & tri-M~\cite{liu2021multi} & URL~\cite{li2021universal} & Ours\\
		    \midrule
			ImageNet & $50.8 \pm 1.1$ & $58.4 \pm 1.1$ & $57.9 \pm 1.1$ & $56.2 \pm 1.0$ & $56.8 \pm 1.1$ & $58.6 \pm 1.0$ & $51.8 \pm 1.1$ & $58.8 \pm 1.1$ & ${\bf 59.5 \pm 1.0}$ \\
			Omniglot & $91.7 \pm 0.5$ & $91.6 \pm 0.6$ & $94.3 \pm 0.4$ & $94.1 \pm 0.4$ & $94.2 \pm 0.4$ & $92.0 \pm 0.6$ & $93.2 \pm 0.5$ & $94.5 \pm 0.4$ & ${\bf 94.9 \pm 0.4}$ \\
			Aircraft & $83.7 \pm 0.6$ & $82.0 \pm 0.7$ & $84.7 \pm 0.5$ & $85.5 \pm 0.5$ & $85.8 \pm 0.5$ & $82.8 \pm 0.7$ & $87.2 \pm 0.5$ & $89.4 \pm 0.4$ & ${\bf 89.9 \pm 0.4}$ \\
			Birds & $73.6 \pm 0.9$ & $74.8 \pm 0.9$ & $78.8 \pm 0.7$ & $71.0 \pm 1.0$ & $76.2 \pm 0.8$ & $75.3 \pm 0.8$ & $79.2 \pm 0.8$ & $80.7 \pm 0.8$ & ${\bf 81.1 \pm 0.8}$ \\
			Textures & $59.5 \pm 0.7$ & $68.8 \pm 0.9$ & $66.2 \pm 0.8$ & $71.0 \pm 0.8$ & $71.6 \pm 0.7$ & $71.2 \pm 0.8$ & $68.8 \pm 0.8$ & $77.2 \pm 0.7$ & ${\bf 77.5 \pm 0.7}$ \\
			Quick Draw & $74.7 \pm 0.8$ & $76.5 \pm 0.8$ & $77.9 \pm 0.6$ & $81.8 \pm 0.6$ & $82.4 \pm 0.6$ & $77.3 \pm 0.7$ & $79.5 \pm 0.7$ & ${\bf 82.5 \pm 0.6}$ & $81.7 \pm 0.6$ \\
			Fungi & $50.2 \pm 1.1$ & $46.6 \pm 1.0$ & $48.9 \pm 1.2$ & $64.3 \pm 0.9$ & $64.0 \pm 1.0$ & $48.5 \pm 1.0$ & $58.1 \pm 1.1$ & ${\bf 68.1 \pm 0.9}$ & $66.3 \pm 0.8$ \\
			VGG Flower & $88.9 \pm 0.5$ & $90.5 \pm 0.5$ & ${\bf 92.3 \pm 0.4}$ & $82.9 \pm 0.8$ & $87.9 \pm 0.6$ & $90.5 \pm 0.5$ & $91.6 \pm 0.6$ & $92.0 \pm 0.5$ & $92.2 \pm 0.5$ \\
			\midrule
			Traffic Sign & $56.5 \pm 1.1$ & $57.2 \pm 1.0$ & $59.7 \pm 1.1$ & $51.0 \pm 1.1$ & $48.2 \pm 1.1$ & $63.0 \pm 1.0$ & $58.4 \pm 1.1$ & $63.3 \pm 1.1$ & ${\bf 82.8 \pm 1.0}$ \\
			MSCOCO & $39.4 \pm 1.0$ & $48.9 \pm 1.1$ & $42.5 \pm 1.1$ & $52.0 \pm 1.1$ & $51.5 \pm 1.1$ & $52.8 \pm 1.1$ & $50.0 \pm 1.0$ & $57.3 \pm 1.0$ & ${\bf 57.6 \pm 1.0}$ \\
			MNIST & - & $94.6 \pm 0.4$ & $94.7 \pm 0.3$ & $94.3 \pm 0.4$ & $90.6 \pm 0.5$ & $96.2 \pm 0.3$ & $95.6 \pm 0.5$ & $94.7 \pm 0.4$ & ${\bf 96.7 \pm 0.4}$ \\
			CIFAR-10 & - & $74.9 \pm 0.7$ & $73.6 \pm 0.7$ & $66.5 \pm 0.9$ & $67.0 \pm 0.8$ & $75.4 \pm 0.8$ & $78.6 \pm 0.7$ & $74.2 \pm 0.8$ & ${\bf 82.9 \pm 0.7}$ \\
			CIFAR-100 & - & $61.3 \pm 1.1$ & $61.8 \pm 1.0$ & $56.9 \pm 1.1$ & $57.3 \pm 1.0$ & $62.0 \pm 1.0$ & $67.1 \pm 1.0$ & $63.5 \pm 1.0$ & ${\bf 70.4 \pm 0.9}$ \\
			\midrule
			Average Seen & $71.6$ & $73.7$ & $75.1$ & $75.9$ & $77.4$ & $74.5$ & $76.2$ & ${\bf 80.4}$ & ${\bf 80.4}$ \\
			Average Unseen & - & $67.4$ & $66.5$ & $64.1$ & $62.9$ & $69.9$ & $69.9$ & $70.6$ & ${\bf 78.1}$ \\
			Average All & - & $71.2$ & $71.8$ & $71.4$ & $71.8$ & $72.7$ & $73.8$ & $76.6$ & ${\bf 79.5}$ \\
			\midrule
			Average Rank & - & $6.1$ & $5.5$ & $5.6$ & $5.5$ & $4.8$ & $4.4$ & $2.5$ & ${\bf 1.6}$ \\
			\bottomrule
		\end{tabular}%
			}
		\vspace{-0.35cm}
		\caption{Comparison state-of-the-art methods on Meta-Dataset (using a multi-domain feature extractor of \cite{li2021universal}). Mean accuracy, 95\% confidence interval are reported. The first eight datasets are seen during training and the last five datasets are unseen and used for test only.}
		\label{tab:currmethod}
\end{table*}%


An alternative to reduce the dimensionality of $\alpha$ in case of matrix multiplication is matrix decomposition:
$\alpha=V\gamma^\top$, where $V\in\mathrm{R}^{C\times B}$ and $\gamma\in\mathrm{R}^{C\times B}$, $B\ll C$.
Using a bottleneck, \ie setting $B<C/2$, reduces the number of parameters in the multiplication.
In this work, we set $B=[C/N]$ and evaluate the performance for various $N$ in \cref{sec:exp}.



\paragraph{Classifier learning.} 
Finally, the adapted feature extractor $f_{(\phi,\alpha)}$ can be combined with a task-specific classifier $c_{\beta}$, parameterized by $\beta$ to obtain the final model, \ie $c \circ f_{(\phi,\alpha)}$.
Based on the recent works, we investigate use of various linear classifiers in~\cite{dhillon2019baseline,lee2019meta,chen2020new,requeima2019fast}, also nonparameteric ones including nearest centroid classifier (NCC)~\cite{mensink2013distance,snell2017prototypical} and their variants based on Mahalanobis distance (MD) \cite{bateni2020improved}.
Recently, it was shown in \cite{li2021universal} that nonparametric classifiers can be successfully combined with a pre-classifier transformation.
Concretely, the transformation in~\cite{li2021universal} that takes in the features computed from the network $f_{\{\phi, \alpha\}} \in \mathrm{R}^d$ and apply an affine transformation $A_{\beta}:\mathrm{R}^d\rightarrow \mathrm{R}^d$ parameterized by $\beta\in\mathrm{R}^{d\times d}$ to obtain the network embedding that is fed into the classifier, \ie $p_{\phi,\vartheta} =  c \circ A_{\beta} \circ f_{\{\phi, \alpha\}}$.
Note that in the case of non-parametric classifier, $c$ is not parameterized by $\beta$ and we use $\beta$ to denote the transformation parameters.


In our experiments, the best performing setting uses parallel adapters, whose parameters are in the matrix form, to adapt the feature extractor and followed by the pre-classifier transformation and NCC.





% CVPR 2022 Paper Template
% based on the CVPR template provided by Ming-Ming Cheng (https://github.com/MCG-NKU/CVPR_Template)
% modified and extended by Stefan Roth (stefan.roth@NOSPAMtu-darmstadt.de)

\documentclass[10pt,twocolumn,letterpaper]{article}

%%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
\usepackage{authblk}
% \usepackage[review]{cvpr}      % To produce the REVIEW version
% \usepackage{cvpr}              % To produce the CAMERA-READY version
\usepackage[pagenumbers]{cvpr} % To force page numbers, e.g. for an arXiv version
\usepackage[accsupp]{axessibility}  % Improves PDF readability for those with disabilities.

% Include other packages here, before hyperref.
% \usepackage{graphicx}
\usepackage{amsmath}
% \usepackage{amssymb}
% \usepackage{booktabs}
\input{preamble}

% It is strongly recommended to use hyperref, especially for the review version.
% hyperref with option pagebackref eases the reviewers' job.
% Please disable hyperref *only* if you encounter grave issues, e.g. with the
% file validation for the camera-ready version.
%
% If you comment hyperref and then uncomment it, you should delete
% ReviewTempalte.aux before re-running LaTeX.
% (Or just hit 'q' on the first LaTeX run, let it finish, and you
%  should be clear).
% \usepackage[pagebackref,breaklinks,colorlinks]{hyperref}


% Support for easy cross-referencing
% \usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}
% \newcommand{\whupdate}{\textcolor{blue}}



\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{Cross-domain Few-shot Learning with Task-specific Adapters}


\author[]{\vspace{-0.3cm}Wei-Hong Li}
\author[]{Xialei Liu\thanks{Xialei Liu is the corresponding author.}}
\author[]{Hakan Bilen\vspace{-0.25cm}}

\affil[]{VICO Group, University of Edinburgh, United Kingdom\vspace{-0.25cm}}
\affil[]{\small \rurl{github.com/VICO-UoE/URL}\vspace{-0.3cm}}

\maketitle

\begin{abstract}
    In this paper, we look at the problem of cross-domain few-shot classification that aims to learn a classifier from previously unseen classes and domains with few labeled samples. 
    Recent approaches broadly solve this problem by parameterizing their few-shot classifiers with task-agnostic and task-specific weights where the former is typically learned on a large training set and the latter is dynamically predicted through an auxiliary network conditioned on a small support set. 
    In this work, we focus on the estimation of the latter, and propose to learn task-specific weights from scratch directly on a small support set, in contrast to dynamically estimating them.
    In particular, through systematic analysis, we show that task-specific weights through parametric adapters in matrix form with residual connections to multiple intermediate layers of a backbone network significantly improves the performance of the state-of-the-art models in the Meta-Dataset benchmark with minor additional cost.
\end{abstract}

%-------------------------------------------------------------------------
\section{Introduction}\label{sec:intro}
\input{intro}

\section{Method}\label{sec:method}
\input{method}

\section{Experiments}\label{sec:exp}
\input{experiments}

\section{Conclusion and Limitations}\label{sec:con}
\input{conclusion}

\paragraph{Acknowledgments.} HB is supported by the EPSRC programme grant Visual AI EP/T028572/1.



\bibliographystyle{ieee_fullname}
\bibliography{ref}

\clearpage
\appendix
\input{supp}

\end{document}

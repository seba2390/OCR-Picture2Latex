\section{Numerical Experiments}
\label{sec:numerics}
To support our theoretical analysis, we performed numerical experiments on linear elliptic parametric PDEs of the form
%\subsection{Linear elliptic PDE}
%\label{ssec:numlin}
%We consider the PDE

\begin{equation}
\label{eq:pdenum}
\begin{aligned}
-\nabla \cdot (a(x,\psmi) \nabla \pde(x,\psmi))&=1&&\text{ in }U:=[-1,1]^D\\
\pde(x,\psmi)&=0&&\text{ on } \partial U,
\end{aligned}
\end{equation}
as in \Cref{sec:uq}.
%In the pre-asymptotic regime of our numerical experiments we observed convergence of the approximations at the rate $h^{-2.2}$ that the required computational work behaved like $h^{1.7}$ and . This corresponds to the values $\beta=2.2$, $\gamma=1.7$ for the parameters in \Cref{sec:nonadaptive}.
%\subsection{Non-smooth case}
We let
\begin{equation*}
a(x,\psmi)={1 + \|x\|_2^{r} + \|\psmi\|_2^{s}},\quad \psmi\in\domPS:=[-1,1]^d
\end{equation*}
for $r := 1$, $s := 3$, $D:=2$ and $d\in\{2,3,4,6\}$.
Our goal was to approximate the response surface
\begin{equation*}
\psmi\mapsto \rs(\psmi):=\QoI(\pde(\cdot,\psmi)):=0.5 \int_{U}\pde(\cdot,\psmi)\;dx
\end{equation*}
in $L^2(\Gamma)$.
%
%The results agree with the theory in \Cref{sec:nonadaptive}.
%Since the dependence of the coefficient $a_{\psmi}$ on $\psmi$ has a kink at $\psmi=0$, the response surface $\rs$ is only Lipschitz continuous. By \cite[Theorem 2]{BagbyBosLevenberg2002}) it can be approximated by polynomials of degree at most $k$ with accuracy $k^{-1}$.
%
%For $d\geq 1$ and $p\in\{2,\infty\}$, similar results hold with $\alpha<1$ and $\dvsp=\dim \vsp$, where $\vsp$ is a downward closed polynomial space (see e.g. \cite[Theorem 2]{BagbyBosLevenberg2002}).
The numerical scheme we used to solve \Cref{eq:pdenum} employs
centered finite difference approximations to the derivatives with a
constant mesh size, $h$. Such a numerical scheme converges
asymptotically at a rate of $\mathcal O(h^{2})$ in the $L^2$ norm
and requires a computational work of $\mathcal O(h^{-2})$, since the
PDE is two-dimensional. This corresponds to the values
$\beta_s = \beta_w = 2$ and $\gamma=2$ for the parameters in
Assumptions A2 and A3.
%%%%%
    % The
    % value of $\alpha$ in A1$(\infty)$ was fitted and found to be
    % $\alpha \approx 1$ for $d=1$ and $\alpha \approx 0.5$ for $d=2$.
    % \todo{Using what method}.  Using these values we can expect the
    % multilevel weighted least squares approximation to have a
    % complexity of $\mathcal{O}({\epsilon^{-1}})$ for $d=1$ and of
    % around $\mathcal{O}({\epsilon^{-2}})$ for $d=2$.
To estimate the projection error of our
estimate we evaluate the $L^2$ error norm using Monte Carlo sampling with $M=1000$ samples,
\begin{equation}\label{eq:l2-mc-error}
  \norm{f - S_L(f)}{L^2(\Gamma)}^2 \approx \frac{1}{M} \sum_{j=1}^M
  (f_{L+1}(\psmi_j) - S_L(f)(\psmi_j))^2.
\end{equation}
In our tests we employ both the nonadaptive and the adaptive
algorithms from Sections 4 and 5. As a basis for the nonadaptive
algorithm, we use total degree polynomial spaces
\(
  \vsp_{\dvsp} := \vspan\left\{ \leg_{\eta} : |\eta|_{1} \leq \dvsp \right\},
\)
where $\leg_\eta$ is a tensor product of Legendre
polynomials as in \Cref{sec:adaptive}.  We also compare the multilevel algorithm to the
straightforward, single-level approach, which for a given polynomial
approximation space $\vsp_{\dvsp}$ uses samples from a fixed PDE discretization
level that matches the accuracy of the polynomial best
approximation in $\vsp_{\dvsp}$. To find these matching PDE discretization levels, we consider the complexity curve of the single-level
method as the lower envelope of complexity curves with different
PDE discretization levels. Even though such a method is not practical, the
choice of discretization level for a given tolerance is always
optimal. The random points were sampled from the optimal
distribution as explained in \Cref{sec:optimal-sampling}.

Before presenting the numerical results, let us derive some a-priori
estimates of the complexity of the single-level and multilevel
projection methods.  From \Cref{pro:finite}, if
$a \in C^{r}(U)\otimes C^{s}(\domPS)$, then using finite elements
of order $r$ and mesh size $h$ would yield convergence in the space $F:=C^{s}(\domPS)$ with the values $\sc=\wc=r+1$ of the parameters in \Cref{sec:nonadaptive}, and  optimal solvers
would require the work $\mathcal{O}(h^{-\gamma})$,  $\gamma:=D$. Furthermore, since functions in
$C^{s}(\domPS)$ are approximable by polynomials of total degree less than or equal to $k$ at the rate $\mathcal{O}(k^{-s})$ in the supremum norm \cite{BagbyBosLevenberg2002}, we expect at least $\alpha=s$.
Even though our choice $a(x,\psmi) = 1 + \|  x\|_2^{r} + \| \psmi\|_2^{s}$
satisfies only $a \in C^{r-1, 1}(U)\otimes C^{s-1,1}(\domPS)$, we do not expect different rates than those derived above for $a\in C^{r}(U)\otimes C^{s}(\domPS)$. Finally, the dimension of total degree polynomial spaces $\vsp_{\dvsp}$ equals $\binom{\dvsp+d}{d}$ and asymptotically we have $\binom{\dvsp+d}{d}\lesssim \dvsp^d$.

Thus, we expect the complexity of the single-level method to be
$\mathcal{O}\left(\epsilon^{-\frac{D}{r+1} -
    \frac{d}{s}}\log(\epsilon^{-1})\right)$, while the complexity of
the multilevel method is of
$\mathcal{O}\left({\epsilon^{-\max\left({\frac{D}{r + 1},
          \frac{d}{s}}\right)}} \log(\epsilon^{-1})^{t}\right)$,
where
\[t =
  \begin{cases}
    1 & \frac{D}{r + 1} > \frac{d}{s},\\
    3 + \frac{D}{r+1} & \frac{D}{r + 1} = \frac{d}{s},\\
    2 & \frac{D}{r + 1} < \frac{d}{s}.
  \end{cases}
\]
Hence, for $r=1$ and $s=3$, the complexity of the single-level
method is
$\mathcal{O}\left(\epsilon^{-1 -
    \frac{d}{3}}\log(\epsilon^{-1})\right)$ and the complexity of the
multilevel method is
$\mathcal{O}\left({\epsilon^{-\max({1, \frac{d}{3}})}}
  \log(\epsilon^{-1})^{t}\right)$ where
\[t =
  \begin{cases}
    1, & d < 3,\\
    4, & d = 3,\\
    2, & d > 3.
  \end{cases}
\]

\Cref{fig:kink-work} shows the work estimate as defined in
\cref{eq:workdef} versus the $L^2$ error approximation in
\Cref{eq:l2-mc-error}. The results for the multilevel algorithm displayed there were obtained with the work parameter $\dimp:=d/2$, which we found describes the pre-asymptotic behavior of $\dim \vsp_{\dvsp}=\binom{\dvsp+d}{d}$ better than $\dimp:=d$. The theoretical rates
satisfactorily match the obtained numerical rates, which show an
improvement of the multilevel methods over the single-level method. Note
that the work estimate does \emph{not} include the cost of generating
points or the cost of assembling the projection matrix and computing
the projection. On the other hand, these costs are included in
\Cref{fig:kink-time}, which shows the total running time in seconds of the
three different methods. While these plots still show the same
complexity rates as \Cref{fig:kink-work} for all three methods for
sufficiently small errors, these plots also show the overhead of the
multilevel methods, especially as $d$ increases. The overhead of the
adaptive algorithm for the multilevel method is especially significant
and more work needs to be done to reduce it.

\setlength\figureheight{7.4cm}
\setlength\figurewidth{8.2cm}
\providecommand{\figlabel}{fig:}

\begin{figure}
	\centering
	\begin{subfigure}{0.49\textwidth}
      \renewcommand{\figlabel}{fig:work-est-vs-error-d2}
      \input{./figures/poisson-kink-2/work-est-vs-error.tex}
      \caption{$d=2$}
	\end{subfigure}
	\begin{subfigure}{0.5\textwidth}
      \renewcommand{\figlabel}{fig:work-est-vs-error-d3}
      \input{./figures/poisson-kink-3/work-est-vs-error.tex}
      \caption{$d=3$}
	\end{subfigure}
	\begin{subfigure}{0.49\textwidth}
      \renewcommand{\figlabel}{fig:work-est-vs-error-d4}
      \input{./figures/poisson-kink-4/work-est-vs-error.tex}
      \caption{$d=4$}
	\end{subfigure}
	\begin{subfigure}{0.5\textwidth}
      \renewcommand{\figlabel}{fig:work-est-vs-error-d6}
      \input{./figures/poisson-kink-6/work-est-vs-error.tex}
      \caption{$d=6$}
	\end{subfigure}
	\caption{$L^2([-1,1]^d)$-error, approximated using
      \Cref{eq:l2-mc-error} vs work estimate \Cref{eq:workdef} of
      single-level (SL), multilevel (ML) and adaptive ML (ML adaptive)
      methods for a linear elliptic PDE with non-smooth parameter
      dependence. The grey dotted lines are the complexity curves of
      different runs of the single-level, each with a different PDE
      discretization level. The single-level (SL) complexity curve is
      then the lower envelope of all single-level complexity
      curves. This figure shows the agreement of the numerical results
      with the theoretical rates.}
	\label{fig:kink-work}
  \end{figure}


  \begin{figure}
	\centering
    \begin{subfigure}{0.49\textwidth}
      \renewcommand{\figlabel}{fig:total-time-vs-error-d2}
      \input{./figures/poisson-kink-2/total-time-vs-error.tex}
      \caption{$d=2$}
	\end{subfigure}
	\begin{subfigure}{0.5\textwidth}
      \renewcommand{\figlabel}{fig:total-time-vs-error-d3}
      \input{./figures/poisson-kink-3/total-time-vs-error.tex}
      \caption{$d=3$}
	\end{subfigure}
	\begin{subfigure}{0.49\textwidth}
      \renewcommand{\figlabel}{fig:total-time-vs-error-d4}
      \input{./figures/poisson-kink-4/total-time-vs-error.tex}
      \caption{$d=4$}
	\end{subfigure}
	\begin{subfigure}{0.5\textwidth}
      \renewcommand{\figlabel}{fig:total-time-vs-error-d6}
      \input{./figures/poisson-kink-6/total-time-vs-error.tex}
      \caption{$d=6$}
	\end{subfigure}
	\caption{Similar to \Cref{fig:kink-work}, but showing the total
      running time of the methods instead of their work estimate. The
      discrepancy of the two figures is due to the overhead of
      sampling the points, assembling the projection matrix and
      computing the projection. Moreover, this plot shows the overhead
      of the adaptive algorithm compared to the non-adaptive one.}
	\label{fig:kink-time}
  \end{figure}


%   \begin{tcolorbox}
% 	Another possible example is:
% 	$a(x,\psmi):=|x-\psmi|^5$, with $\domPS:=U:=[0,1]^2$.
% 	In terms of, we then have
% 	\begin{equation*}
% 	a\in C^5(U\times \domPS)
% 	\end{equation*}
% 	(strictly speaking, the last derivative is not continuous, but lets ignore that).
% 	Using finite elements of order $5$ should thus give us
% 	\begin{align*}
% 	\sc=2\\
% 	\wc=4\\
% 	\alpha=4/d=2\\
% 	\end{align*}
% (the "strong" convergence in \Cref{pro:finite} happens in $C^{4}(\domPS)$ and such functions are approximable by polynomials of degree $k$ at rate $(k+1)^{-4}$. Again, divide by $d=2$ because space of polynomials of degree $k$ has dimension $k^2$

% 	Finally, optimal solvers should have $\gamma=2$.
% 	Since $\gamma/\sc=1>1/\alpha=1/2$ we expect
% 	\begin{align*}
% 	\rate=\theta \gamma/\sc+(1-\theta)1/\alpha=1/2+1/2*1/2=3/4.
% 	\end{align*}

% 	Replacing $5$ by $3$ should give you $\gamma/\sc=1/\alpha=1$.
% 	\end{tcolorbox}
% \subsection{Matern-like example}
% Our second example is the same as the one in
% \cite{Haji-AliNobileTamelliniEtAl2015}. More specifically, we let
% \begin{equation*}
% a_{\psmi}(x)=\exp\left( \sum_{\vec k \in \N^D} A_{\vec k}
% \sum_{\vec \ell \in \{0,1\}^D} \gamma_{\vec k,\vec \ell } \, \prod_{i=1}^D
% \left(\cos\left({\pi }  k_i  x_i \right)\right)^{\ell_i}
% \left(\sin\left({\pi }  k_i  x_i \right)\right)^{1-\ell_i} \right).
% \end{equation*}
% for $\gamma_{\vec k,\vec \ell } \in [-1,1]$ and
% \begin{equation}
% A_{\vec k} {= \left(\sqrt{3}\right)} 2^{\frac{|\vec k|_0}{2}}(1 + |\vec k|^2)^{-\frac{\nu+D/2}{2}},
% \end{equation}
% for some $\nu>0$. The summability of $a_{\psmi}$ is controlled by
% $\nu$. Namely, using the notation of \Cref{pro:UQ} we have that
% $(\|\psi_j\|_{L^{\infty}})_{j\in\N}\in \ell^p(\N)$ with
% $p = \left( \frac{\nu}{D} + \frac{1}{2} \right)^{-1}$ hence $\alpha$
% in Assumption A1($\infty$) is $\frac{\nu}{D} - \frac{1}{2}$. On the
% other hand, the solver we used employs a second order
% finite-difference method with step size $h$ along each dimension,
% which asymptotically converge at the rate $h^{2}$ in the $L^2$ norm
% and require the computational work $h^{-D}$, corresponding to the
% values $\beta=2$ and $\gamma=D$ for the parameters in Assumptions A2
% and A3.

% The quantity of interest in this example is:
% \begin{equation*}
% \QoI(\pde_{\gamma}):= \frac{10}{(\sigma\sqrt{2\pi})^D}
% \int_\mathscr{B} u_\gamma(x) \exp \left( -\frac{\|x-x_o\|_2^2}{2\sigma^2} \right) \;dx.
% \end{equation*}
% with $\sigma=0.2$ and location $x_o=0.3$ for $D=1$ and
% $x_0 =(0.3, 0.2,0.6)$ for $D=3$.

% \begin{tcolorbox}
% 	Consider $D=1$. In terms of \Cref{pro:UQ} we have:
% 	\begin{align*}
% 	r_{\max}&=\nu+1/2\\
% 	\delta&=1.
% 	\end{align*}
% Choosing $r:=1$ in \Cref{pro:UQ} shows that we can take
% 	\begin{align*}
% 	\sc&=1+1=2\\
% 	\alpha&=r_{\max}-1-1-\epsilon=\nu-3/2-\epsilon
% 	\end{align*}
% 	(meaning we can take any $\epsilon>0$. Below let's just assume we can take $\epsilon=0$.)
% 	Choosing $r:=\nu$ shows that we can take
% 	\begin{align*}
% 	\wc=1+\nu.
% 	\end{align*}
% Finally, optimal solver should have
% 	\begin{align*}
% 	\gamma=1.
% 	\end{align*}

% 	Let's for example say $\nu=3.5$. Then $\gamma/\sc=1/\alpha=1/2$ and we expect $\lambda=1/2$.


% %	\textbf{Mean square convergence}
% %If you consider mean square convergence instead, then $\alpha$ improves	by $1/2$ %and you expect (with $\theta=2/4.5=4/9$)
% %\begin{align*}
% %\lambda=\theta \gamma/\sc+(1-\theta)1/\alpha=4/9*1/2+5/9*1/2.5=4/9
% %\end{align*}
% \end{tcolorbox}

% %\begin{figure}[h]
% %	\centering
% %	\input{./figures/kl2/kl2.tex}
% %	\caption{Convergence of nonadaptive and adaptive multilevel algorithm for smooth infinite-dimensional problem.}
% %	\label{fig:kl}
% %\end{figure}

% %\subsection{Smooth case}
% %We let
% %\begin{equation*}
% %a_{\psmi}(x)=\exp\left(\sum_{j=1}^{\infty}\ps_j\psi_j(x)\right)
% %\end{equation*}
% %with
% %\begin{equation*}
% %\psi_j(x_1,x_2):=j^{-4}\phi_{\sigma_j(1)}(x_1)\phi_{\sigma_j(2)}(x_2),
% %\end{equation*}
% %\begin{equation*}
% %\phi_{n}(x):=\begin{cases}
% %	\sin(\frac{n}{2}\pi x)\quad&\text{if }n\text{ is even}\\
% %	\cos(\frac{n-1}{2}\pi x)\quad&\text{else}.
% %\end{cases}
% %\end{equation*}
% %and an enumeration $(\sigma_{j})_{j=1}^{\infty}$ of $\N^2$.
% %
% %
% %Our goal is to approximate the response surface
% %\begin{equation*}
% %\psmi\mapsto \rs(\psmi):=\QoI(\pde_{\psmi}),
% %\end{equation*}
% %with the quantity of interest
% %\begin{equation*}
% %\QoI(\pde):=\int_{[0,1]^2}u\;dx.
% %\end{equation*}
% %Since we are using piecewise linear finite elements as before, the work required to obtain an error of size $\epsilon>0$ grows at least like $\epsilon^{-1}$. \Cref{fig:kl} shows that both the adaptive and the non-adaptive algorithm are able to achieve this rate.
% %%\begin{figure}[h]
% %%	\centering
% %%	\input{./figures/kl/kl.tex}
% %%	\caption{Convergence of multilevel algorithm for smooth infinite-dimensional  problem.}
% %%	\label{fig:kl}
% %%\end{figure}
% %\begin{figure}[h]
% %	\centering
% %	\input{./figures/kl2/kl2.tex}
% %	\caption{Convergence of nonadaptive and adaptive multilevel algorithm for smooth infinite-dimensional problem.}
% %	\label{fig:kl}
% %\end{figure}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../document"
%%% End:

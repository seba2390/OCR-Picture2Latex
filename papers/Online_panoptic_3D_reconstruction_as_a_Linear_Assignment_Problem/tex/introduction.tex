
Panoptic segmentation \cite{panoptic_segmentation} is a recent computer vision topic, which combines the tasks of semantic segmentation -- assign a class label to each pixel -- and instance segmentation -- detect, classify and segment each object instance. The objective is to segment and classify both \textit{stuff} -- amorphous, unquantifiable areas of the image like floor, buildings and roads -- and \textit{things} -- quantifiable objects. Many potential applications -- \textit{e.g.} in the fields of context-aware augmented reality \cite{panopticfusion}, autonomous driving \cite{real_time_panoptic} and robotics \cite{interactive_3d_scenes} -- require rich semantic information in real time from the environment. For instance, real-time semantic knowledge of objects around a robot would allow it to interact with it's environment at a higher level of autonomy and utilise the information for more robust localisation.

While panoptic image segmentation has been researched quite extensively \cite{panopticfpn,seamless,panoptic_deeplab,efficientps,real_time_panoptic}, panoptic 3D reconstruction has not been studied as much. Segmented images alone are often not sufficient: in many applications the segments 3D location relative to the actor needs to be known as well. The segmentation of 3D reconstructions has gained quite a lot of attention recently \cite{scannet,s3dis,paris_lille_3d}, but many works assume offline processing -- \textit{i.e.} that all the data is available simultaneously rather than sequentially -- which rules out many real-time applications. 
%Simply processing images, however, can save a lot of computational resources. Training data for image segmentation models is also easier to collect and annotate, which enables parties with limited time and resources to enter the field as well.

%The purpose of this work is to design a bare-bones system for online panoptic 3D reconstruction from segmented RGB-D images or point clouds, targeting real-time operation. We aim to create a simple yet effective algorithm to solve the problem, and to focus on some key design choices and their effects on its performance. Through the simple design, we aim to gain more insight on challenges and possible bottlenecks in the process, which could be utilised to improve upon this system in the future. Even though our method and its implementation are quite simple, it seems to outperform other comparable methods on the ScanNet dataset. The source code and means to replicate our results will be published alongside this manuscript.

\begin{figure}[t]
\centering
\begin{subfigure}[b]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{fig/sc0783_rgb_1470.pdf}
        \caption[]%
        {{\small Original image}}    
        \label{fig:intro_orig}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{fig/sc0783_seg_1470.pdf}
        \caption[]%
        {{\small Segmented image}}    
        \label{fig:intro_2d_seg}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{fig/0783_00_scannet_mesh.pdf}
        \caption[]%
        {{\small 3D reconstruction}}    
        \label{fig:ntro_3d_seg}
\end{subfigure}
\caption[]{An example of online panoptic 3D reconstruction. RGB-D Images (a) are segmented (b) and integrated sequentially into a panoptic 3D reconstruction (c)}
\label{fig:intro_example}
\end{figure}

% Real-time 3D applications:
% Applications in fields like AR, Autonomous Machines and Semantic SLAM require real-time operation and 3D information
% -> image segmentation is not enough
%  - need to either process 3D data, or project images to 3D
% -> information has to be processed online
%  - algorithms need to be fast
%  - data has to processed sequentially

% Images
% pros:
% - easy / fast to process, lots of literature
% - lots of data available, easy to collect
% - videos are sequential by nature
% cons:
% - single viewpoint, occlusions, distortions, projections

% 3D data
% pros:
% - geometry information
% - data is processed directly in the applied format 
% cons:
% - hard / slow to process
% - requires multiple image frames to generate
% - or: lidar etc. which is large, heavy and expensive

\subsubsection{Contributions and scope} This work is focused on online panoptic 3D reconstruction of static scenes from sequences of RGB-D images or point clouds. Segmentation of completed 3D reconstructions and other ways of achieving the same result offline are considered out of scope. Since the focus is on what happens after panoptic segmentation, the related segmentation methods are only discussed briefly. The main contributions in this article are as follow:

\begin{itemize}
    \item[\textbullet] We revisit the method introduced with PanopticFusion \cite{panopticfusion}, explore some unanswered aspects and provide an open-source implementation with the updated method,
    \item[\textbullet] formulate online panoptic 3D data-association as a Linear Assignment Problem (LAP), separate from segmentation and reconstruction,
    \item[\textbullet] provide a simple yet effective baseline for real-time operation, with TSDF integration and optimal LAP solution in relation to association likelihood.
\end{itemize}

\subsubsection{Organisation of the rest of the article}

Background and a brief introduction to the applied methods are provided in Section \ref{sec:background}. Section \ref{sec:methods} introduces our proposed method, which is evaluated in Section \ref{sec:evaluation}. Finally, Section \ref{sec:conclusion} concludes the paper, adding some final remarks on the system's applications and future possibilities.
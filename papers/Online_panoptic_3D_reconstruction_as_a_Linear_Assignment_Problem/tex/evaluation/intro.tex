
% Effect of framerate?
%
% ScanNet input is 30 fps -> for real time operation, computation has to happen in under ~ 0.03 s
%  - not feasible with our test hardware, maybe possible with faster cpu
%
% A more realistic case with our optimisations:
%  - skip 10 frames -> real time requirement ~ 0.3 s
%
% Another example:
%  - a graph slam producing keyframes once every second
%  - equivalent to skipping 30 frames
%   -> not accounting for segmentation, real time requirement ~ 1 s, which is completely feasible even with our laptop (or e.g. a mobile robot platform)
%  - real-time panoptic segmentation:
%    - https://github.com/TRI-ML/realtime_panoptic
%    - PQ 58.8 in 99ms (=10fps) with one high end GPU (V100)
%    - would leave around 0.9 s for fusion, more than enough
%    - some operations could be run in parallel on CPU (e.g. finishing last fusion iteration)

% TEST:
% - what options work / don't with lower fps?
% - with skip of 10 (3 fps), all iou tests at least seemed similar (outlier rejection had no effect on PQ)
% - less fps -> less data -> effects of faulty segmentation could be accentuated?

% ! TEST with voxblox parameters found in panopticfusion paper !
% (at least on ScanNet test?)

%With the framerate of $30~Hz$ in ScanNet video streams, real-time panoptic 3D reconstruction would require an extremely fast computer. This framerate would require one to process one frame in under thirty milliseconds. For example, with pretty high-end consumer hardware, PanopticFusion was able to perform at around $4.3~Hz$ \cite{panopticfusion} -- including segmentation -- which means one frame took on average around $233~ms$. Thus, PanopticFusion would reach hard real-time requirements most of the time, if only every 8th frame of the video stream is processed. As another example, when localising with a graph-based visual SLAM -- a popular method in  mobile robotics -- one could only process each keyframe -- a frame where the algorithm deemed viewpoint to have changed by a significant amount -- to save computational resources. For instance, RTAB-Map outputs keyframes at the constant rate of $2~Hz$ on default settings \cite{rtabmap}, while ORB-SLAM3 is reported to output around $3-6$ keyframes per second during real-time operation. \cite{orbslam3} Nowadays, panoptic segmentation models are also capable of running in real time. For example, in \cite{real_time_panoptic} a panoptic segmentation model optimised for speed was reported to be able to run at $30~Hz$ on a single NVIDIA V100 GPU reaching a really competitive PQ of $58.8$ on the Cityscapes panoptic segmentation challenge.

%With these considerations in mind, we test the effect of different framerates and options in our algorithm on the panoptic quality of the reconstructions. Since a lower framerate means less data is available, we assume that the effects of errors in segmentation will be more pronounced. The tests will be run equivalent to real-time framerates of $3~Hz$, $1~Hz$ and $0.6~Hz$, by processing only every 10th, 30th or 50th frame. In our tests we found that processing ScanNet frames at a higher rate than $3~Hz$ only had the effect of the tests taking more time, having no notable effect on panoptic quality. 

%NOTE: AP 25 is much higher (51.5) -> objects are found, but segmentation is not always that accurate 

We evaluate the systems performance on the ScanNet dataset \cite{scannet}. Since PanopticFusion \cite{panopticfusion} is the only similar approach on the dataset, we only report its results as a comparison. While \cite{voxblox++} and  \cite{interactive_3d_scenes} are not evaluated on the dataset, their data-association method is quite similar to the one in PanopticFusion, thus their performance can be roughly estimated with its results as well.

In all of the tests below, only every 10th frame of the RGB-D video feed is processed. The original frame-rate of ScanNet data is $30~Hz$, thus with the new rate we are required to process each frame in $333~ms$ or less to run the algorithm in real time. Processing more frames than this does not seem to increase quality of the results much. On the other hand, the number of points in the panoptic point cloud has a huge effect the amount of computation required, therefore the point cloud resolution is reduced from the original $640 \times 480$ points after segmentation, multiplier depending on the voxel size used. The authors of PanopticFusion did not mention which one of Voxblox's TSDF integrators they applied in the article, thus we apply the 'fast' integrator.

To compare them to the ground truth, the results have to be labelled in the original meshes, therefore all our results are transformed to ScanNet evaluation meshes via an approximate nearest neighbour search implemented in Faiss \cite{faiss}. Panoptic Quality is computed similarly to the 2D metric \cite{panoptic_segmentation}, however IoU is computed over mesh vertices instead of pixels. Panoptic image segmentations are inferred separately, and are read from disk during operation so that they can be re-used in all of the tests. All our tests were run on Intel Core i7-8665u CPU at $1.90~GHz$.

%Voxel sizes smaller than $5~cm$ seem to slow down computation quite a lot as well, thus  

% CPU: Intel Core i7-8665u  @ 1.90 GHz

% Some additional section for analysis?
% - models are different -> we shouldn't compare them directly
% - hardware is different -> cant' compare speed directly
%
% - worse segmentation performance could be because of different models, or because we are solving both segmentation tasks wit a single model

% However:
% - we are roughly on-par -> were able to replicate the results
% - open source implementation
% - should be able to run in real time
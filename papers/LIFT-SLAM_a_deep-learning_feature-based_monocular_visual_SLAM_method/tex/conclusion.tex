\section{Conclusion}
\label{sec:conclusion}

In this work, we successfully apply a deep neural network in the front-end of a traditional monocular visual SLAM algorithm. This approach showed that it is possible to improve VSLAM algorithms' performance with learned feature extraction and description. We also showed that transfer learning could be used to fine-tune these networks with VO/VSLAM datasets to improve the entire system's performance on cross-datasets. Moreover, we successfully created a method to adapt the matching thresholds while executing the VO pipeline, depending on the number of outliers. This method allowed us to eliminate the fixed values of the matching thresholds without requiring dataset fine-tuning. All of these methods allowed us to evaluate five variations of LIFT-SLAM: LIFT-SLAM fine-tuned with KITTI sequences, LIFT-SLAM fine-tuned with Euroc sequences, Adaptive LIFT-SLAM, Adaptive LIFT-SLAM fine-tuned with KITTI sequences and Adaptive LIFT-SLAM fine-tuned with Euroc sequences. 

We also proposed a set of experiments to evaluate the robustness of VSLAM algorithms. With these experiments, we showed that our hybrid VSLAM algorithm is more robust than a traditional VSLAM algorithm without losing accuracy, such as end-to-end deep learning-based algorithms. Results demonstrate that the proposed system can operate in different environments (indoors and outdoors) while improving its results with an artificial distortion applied to the images (gamma power transformation and quantile-based truncation). This fact indicates that a selection of the learned features could improve the algorithm' performance. Therefore, in future work, we plan to add an attention-based mechanism to select the best features for VSLAM.
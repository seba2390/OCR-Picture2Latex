\section{Experiments}
\label{sec:experiments}

\subsection{Datasets}

Our experiments were performed in KITTI dataset \cite{kitti-dataset} and Euroc MAV Dataset \cite{euroc-mav}. KITTI dataset (Karlsruhe Institute of Technology and Toyota Technological Institute at Chicago) \cite{kitti-dataset} is one of the most used benchmarks for evaluation in VO/VSLAM algorithms. They have developed benchmarks for stereo, optical flow, VO/VSLAM, and 3D object detection. The VO/VSLAM dataset consists of 22 stereo images sequences with a total length of 39.2 km recorded from a moving car. As our goal is to work with monocular images, we get only the left images in all sequences to run our algorithms. Moreover, we use only sequences from $00$ to $10$, as these are the only sequences with ground-truth information available.

The Euroc MAV dataset (Swiss Federal Institute of Technology and Autonomous Systems Lab) \cite{euroc-mav} is a dataset created to assess the visual-inertial SLAM and 3D reconstruction capabilities of contestants from the European Robotics Challenge (Euroc) on Micro Aerial Vehicles (MAVs). Eleven sequences are provided in total, ranging from slow flights under good visual conditions to dynamic flights with motion blur and poor illumination. There are two types of sequences. The first type is from images taken in a realistic industrial scenario, recorded in a machine hall (sequences from MH\_01 to MH\_05). The second type is from images taken inside a Vicon motion capture system, with obstacles placed over the scene (sequences from V1\_01 to V1\_03).

These datasets were chosen to test the robustness of the proposed algorithms for different camera motion (e.g., acceleration, velocities, DoF, etc.) and environments (e.g., outdoors/indoors, size, illumination, etc.). Moreover, in LIFT-SLAM fine-tuned approaches, using different datasets has allowed us to validate the network's improvement for VO problems in general, instead of biasing the network for a single dataset.

\subsection{Trajectory Evaluation}
\label{sec:traj-evaluation}
We generate a quantitative and qualitative comparison between the estimated trajectories and the ground-truth data for each sequence of the datasets. The quantitative evaluation in KITTI sequences are based on Relative Pose Error (RPE) of translation and rotation, as described in \cite{kitti-benchmark}, and Absolute Trajectory Error (ATE), detailed in \cite{tum-vi}. Due to the stochastic nature of the algorithms, all of the quantitative metrics are an average of 5 executions. The estimates on Euroc sequences were evaluated only by ATE. 

ORB-SLAM's results were computed by our executions since, in ORB-SLAM's paper, an evaluation with RPE is not presented and does not provide results in the Euroc dataset. Furthermore, we present qualitative comparisons showing a 2-D plot of the trajectories. Moreover, for LIFT-SLAM versions that are not adaptative we set the matching thresholds values to $TH_{LOW} = 1$ and $TH_{HIGH} = 2$ for Euroc sequences and $TH_{LOW} = 2$ and $TH_{HIGH} = 3$ for KITTI sequences.

The quantitative comparison of all algorithms in the KITTI dataset presented in table \ref{tab:all-results-kitti} shows that, in general, LIFT-SLAM systems presented a better performance than ORB-SLAM, especially in smaller sequences, such as $03$ and $04$. Furthermore, we can notice that the proposed versions of LIFT-SLAM achieved a better performance than LIFT-SLAM in most of the sequences. The algorithm performance improved even when we used the Euroc dataset to fine-tune the LIFT network. Therefore, we confirmed that the network learned important features from VO datasets. 

%Table KITTI
\begin{table}[!h]
\centering
\resizebox{\textwidth}{!}{\begin{tabular}{|c|c|ccccccccccc|}
\hline \textbf{Algorithm} & \textbf{Metric} & \textbf{00} & \textbf{01} & \textbf{02} & \textbf{03} & \textbf{04} & \textbf{05} & \textbf{06} & \textbf{07} & \textbf{08} & \textbf{09} & \textbf{10}\\ \hline


                         & ATE (m) & 11.54& X & X & 15.13& 4.29 & \textbf{7.74} & 20.26 & 13.47 &\textbf{39.51} & \textbf{49.67} & 19.94\\
ORB-SLAM      & $RPE_{trans}$ (\%) & 4.46 & X & X & 9.75 & 3.71 & \textbf{3.35} & 8.11 & 7.43 & \textbf{12.16} & 26.51 & 8.65 \\
              &$RPE_{rot}$ (deg/m) & 3.28 & X & X & 2.78 & 2.15 & 3.57 & 2.88 & 3.58 &3.05 & 11.13 & 3.62 \\ \hline

          & ATE (m)            &18.77 & X & X & 1.10 & 0.40 & 8.09 & 18.47 & 4.03 & 80.97 & 59.88 & 31.84 \\
LIFT-SLAM & $RPE_{trans}$ (\%) & 6.71          & X & X & 0.87          & \textbf{2.10} & 4.46 & 7.76 & 2.51 & 27.63 & 20.65 & 10.08 \\
          & $RPE_{rot}$ (deg/m)& \textbf{2.20} & X & X & \textbf{0.34} & 0.65 & 2.58 & 2.49 & 3.60 & 2.10 & 2.12 & 2.25 \\  \hline

                               & ATE (m)            & - & X & \textbf{29.83} & 1.91 & \textbf{0.36} & 12.47 & - & \textbf{2.54} & 188.51 & - & -  \\
LIFT-SLAM fine-tuned with KITTI & $RPE_{trans}$ (\%) & - & X & 8.80 & 1.32 & 2.16 & 5.02          & - & \textbf{1.80} & 48.90 & - & - \\
                     & $RPE_{rot}$ (deg/m)& - & X & \textbf{2.11} & \textbf{0.34} & 0.52 & 2.43  & - & \textbf{2.67} & 2.11 & - & -  \\  \hline
          
                               & ATE (m)    & 9.84 & X & 34.23 & 0.97 & 0.42 & 11.50 & \textbf{16.58} & 3.98 &  82.61 & 54.91 & 30.34\\
LIFT-SLAM fine-tuned with Euroc & $RPE_{trans}$ (\%) & 3.49 & X & 9.84 & 0.86 & 2.22 & 5.35          & \textbf{7.05}         & 2.60 & 28.99 & \textbf{19.16} & 9.81\\
                               & $RPE_{rot}$ (deg/m)& 2.63 & X & 2.10 & 0.46 & 0.50 & \textbf{1.91} & \textbf{2.36} & 3.64 & \textbf{1.95} & \textbf{2.08} & 2.20\\  \hline

          & ATE (m)                     & 13.70 & X & 40.33 & \textbf{0.84} & 0.47 & 10.85 & 17.83 & 4.09 & 81.69 & 57.74 & \textbf{10.51} \\
Adaptive LIFT-SLAM & $RPE_{trans}$ (\%) & \textbf{2.64} & X & 11.54         & \textbf{0.78} & 2.22 & 5.49 & 7.50 & 2.67 & 28.49 & 19.28 & 4.96 \\
          & $RPE_{rot}$ (deg/m)         & 4.95 & X & 2.22 & 0.38 & 0.60 & 2.97 & 2.42 & 3.42 & 2.05 & 2.17 & \textbf{1.57} \\  \hline


                                & ATE (m)                    & - & X & 48.09 & 1.91 & 0.42 & 10.35 & - & 4.10 & 185.15 & - & -  \\
Adaptive LIFT-SLAM fine-tuned with KITTI & $RPE_{trans}$ (\%) & - & X & 9.57 & 1.29        & 2.11 & 4.64 & - & 2.64 & 47.20 & - & - \\
                               & $RPE_{rot}$ (deg/m)         & - & X & 2.43 &\textbf{0.34}& 0.57 & 2.93 & - & 3.51 & 2.00 & - & -  \\  \hline


                                        & ATE (m) & \textbf{8.06} & X & 40.04 & 2.23 & 0.51 & 13.55 & 30.38 & 3.63 & 184.43 & 59.62 & 29.87 \\
Adaptive LIFT-SLAM fine-tuned with Euroc & $RPE_{trans}$ (\%) & 3.18 & X & \textbf{8.73} & 1.46 & 2.22 & 6.09 & 12.24 & 2.42 & 47.10 & 19.91 & 9.72 \\
                                        & $RPE_{rot}$ (deg/m) & 2.99 & X & 2.49 & \textbf{0.34} & \textbf{0.48} & 3.11 & 2.91 & 4.02 & 2.02 & 2.14 & 2.24  \\  \hline
\end{tabular}}

\caption{Quantitative comparison of ORB-SLAM and all versions of LIFT-SLAM in the KITTI dataset. We fill with "X" the sequences unavailable due to tracking failure, and with "-" sequences, we do not execute the algorithm to avoid biased results. The smaller average in each metric is highlighted.}
\label{tab:all-results-kitti}
\end{table}

Figure \ref{fig:all-traj-kitti} shows the qualitative comparison between the algorithms in the KITTI dataset. In sequences $00$ (Fig. \ref{fig:kitti-00}) and $02$ (Fig. \ref{fig:kitti-02}) most of the algorithms could not track the entire trajectory, except for Adaptive LIFT-SLAM fine-tuned with Euroc. Figure \ref{fig:kitti-03} shows the difference in performance in smaller sequences between ORB-SLAM and all LIFT-SLAM versions. Moreover, in sequences $05$, $06$, and $07$, ORB-SLAM could not detect loop-closure, thus, its trajectories has an accumulated drift as shown in Figures \ref{fig:kitti-05}, \ref{fig:kitti-06} and \ref{fig:kitti-07}. On the other hand, in Figure \ref{fig:kitti-08}, we can notice that none of the algorithms could detect loop closure in the sequence of $08$. Therefore, all estimated trajectories have a big error accumulated over the entire sequence.

%kitti trajectories
\begin{figure}
\centering
\subfloat[][KITTI 00]{
\includegraphics[width=0.44\textwidth, height=4cm]{figures/all-results-kitti00_2.png}
\label{fig:kitti-00}}
\qquad
\subfloat[][KITTI 02]{
\includegraphics[width=0.44\textwidth, height=4cm]{figures/all-results-kitti02_2.png}
\label{fig:kitti-02}}

\subfloat[][KITTI 03]{
\includegraphics[width=0.44\textwidth, height=4cm]{figures/all-results-kitti03_2.png}
\label{fig:kitti-03}}
\qquad
\subfloat[][KITTI 05]{
\includegraphics[width=0.44\textwidth, height=4cm]{figures/all-results-kitti05_2.png}
\label{fig:kitti-05}}

\subfloat[][KITTI 06]{
\includegraphics[width=0.44\textwidth, height=4cm]{figures/all-results-kitti06_2.png}
\label{fig:kitti-06}}
\qquad
\subfloat[][KITTI 07]{
\includegraphics[width=0.44\textwidth, height=4cm]{figures/all-results-kitti07_2.png}
\label{fig:kitti-07}}

\subfloat[][KITTI 08]{
\includegraphics[width=0.44\textwidth, height=4cm]{figures/all-results-kitti08_2.png}
\label{fig:kitti-08}}
\qquad
\subfloat[][KITTI 10]{
\includegraphics[width=0.44\textwidth, height=4cm]{figures/all-results-kitti10_2.png}
\label{fig:kitti-10}}

\caption{Results in KITTI dataset.}
\label{fig:all-traj-kitti}
\end{figure}

Table \ref{tab:all-results-euroc} shows the quantitative comparison between the algorithms in Euroc dataset. We can notice that ORB-SLAM has the smallest average in 3 sequences. Moreover, the proposed versions of LIFT-SLAM performed better than original LIFT-SLAM in all sequences. The algorithm's performance improved even when we used the KITTI dataset to fine-tune the LIFT network. Therefore we confirmed that this network version also learned essential features from the dataset.

%Table Euroc
\begin{table}[!h]
\centering
\resizebox{0.8\textwidth}{!}{\begin{tabular}{|c|cccccc|}
\hline \textbf{Algorithm} & \textbf{MH\_01} & \textbf{MH\_02} & \textbf{MH\_03} & \textbf{MH\_04} & \textbf{V1\_01} & \textbf{V1\_03} \\ \hline
ORB-SLAM & 0.048 & 0.037 & \textbf{0.040} & 0.432 & \textbf{0.100} & \textbf{0.370} \\
LIFT-SLAM & 0.062 & 0.227 & 0.144 & 1.859 & X & X \\
LIFT-SLAM fine-tuned with KITTI & 0.115 & 0.042 & 0.055 & \textbf{0.117} & 0.117 & X \\
LIFT-SLAM fine-tuned with Euroc & 0.117 & 0.062 & 0.053 & - & 0.150 & - \\
Adaptive LIFT-SLAM & 0.046 & \textbf{0.034} & X & X & 0.101 & X \\
Adaptive LIFT-SLAM fine-tuned with KITTI & 0.455 & X & 0.116 & X & 0.194 & X \\
Adaptive LIFT-SLAM fine-tuned with Euroc & \textbf{0.044} & 0.053 & 0.049 & - & 0.157 & - \\ \hline
\end{tabular}}

\caption{ATE (m) comparison between ORB-SLAM and all versions of LIFT-SLAM in the Euroc dataset. We fill with "X" the sequences unavailable due to tracking failure, and with "-" sequences, we do not execute the algorithm to avoid biased results. We highlight the smaller average in each metric.}
\label{tab:all-results-euroc}
\end{table}

Figure \ref{fig:all-traj-euroc} shows the qualitative comparison between the algorithms in Euroc dataset. %LIFT-SLAM and most of its versions could not track some of the sequences completely, except for Adaptive LIFT-SLAM fine-tuned with Euroc. 
In sequence MH\_01 (Fig. \ref{fig:mh01}), all algorithms had a good performance. Moreover, in MH\_02 (Fig. \ref{fig:mh02}), most of the algorithms also performed well, except for Adaptive LIFT-SLAM finetuned with KITTI that failed to compute the pose. Figure \ref{fig:mh03} shows that the only algorithm that could track the entire trajectory was Adaptive LIFT-SLAM finetuned with Euroc. In sequence MH\_04 (Fig. \ref{fig:mh04}), LIFT-SLAM had a terrible performance, but its version finetuned with KITTI is more similar to the ground-truth, which shows that finetuning the network was effective. Lastly, in sequence V1\_01 (Fig. \ref{fig:v101}), all LIFT-SLAM versions presented in the Figure could track the trajectory while ORB-SLAM lost track multiple times. Therefore, considering the quantitative and qualitative results of all versions of LIFT-SLAM, Adaptive LIFT-SLAM finetuned with Euroc sequences is the one with better overall results.


%euroc trajectories
\begin{figure}
\centering
\subfloat[][Euroc MH\_01]{
\includegraphics[width=0.44\textwidth, height=4cm]{figures/all-results-mh01_2.png}
\label{fig:mh01}}
\qquad
\subfloat[][Euroc MH\_02]{
\includegraphics[width=0.44\textwidth, height=4cm]{figures/all-results-mh02_2.png}
\label{fig:mh02}}

\subfloat[][Euroc MH\_03]{
\includegraphics[width=0.44\textwidth, height=4cm]{figures/all-results-mh03_2.png}
\label{fig:mh03}}
\qquad
\subfloat[][Euroc MH\_04]{
\includegraphics[width=0.44\textwidth, height=4cm]{figures/all-results-mh04_2.png}
\label{fig:mh04}}

\subfloat[][Euroc V1\_01]{
\includegraphics[width=0.44\textwidth, height=4cm]{figures/all-results-v101_2.png}
\label{fig:v101}}

\caption{Results in Euroc dataset.}
\label{fig:all-traj-euroc}
\end{figure}

\subsection{Robustness tests}

To test our system's robustness to camera sensor noise, we created different image distortion in some sequences of KITTI and Euroc simulating camera ill exposure conditions. These scenarios were emulated with the application of gamma power transformation and quantile-based truncation, as proposed in \cite{emulate-exposure}. More details about these operations are described next:

\begin{itemize}
    \item Gamma power transformation: This transformation creates a new image $I' $ from image $I$ by applying: $I' =I^{\gamma}$. We used four values of $\gamma$: $0.25$, $0.5$, $2$ and $4$. Values of $\gamma < 1$ results in data loss for bright regions emulating camera overexposing, as shown in Figure \ref{fig:gamma0.25}. $\gamma > 1$ results data loss for dark regions emulating camera underexposing \cite{emulate-exposure} (Fig. \ref{fig:gamma4});
    
    \item Quantile-based truncation: We have truncated the first ($Q_1$) and third ($Q_3$) quantiles of the pixels' intensities distribution to reproduce the effects of low dynamic range imaging sensors. When truncating pixels in $Q_1$ we emulate sensor underexposing (Fig. \ref{fig:quantile1}), and in $Q_3$ we emulate sensor overexposing (Fig. \ref{fig:quantile3}).
\end{itemize}

We also tried to apply a salt-and-pepper noise in the sequences to simulate the malfunctioning of the camera's sensor cell \cite{emulate-exposure}. However, in this scenario, none of the algorithms were capable of initializing the map. Therefore, we do not present results for this case.

\begin{figure}
\centering
\subfloat[][$\gamma < 1$.]{
\includegraphics[width=0.6\textwidth]{figures/gamma0.25.png}
\label{fig:gamma0.25}}

\subfloat[][$\gamma > 1$.]{
\includegraphics[width=0.6\textwidth]{figures/gamma4.png}
\label{fig:gamma4}}

\subfloat[][Truncation in $Q_1$.]{
\includegraphics[width=0.6\textwidth]{figures/quantile1.png}
\label{fig:quantile1}}

\subfloat[][Truncation in $Q_3$.]{
\includegraphics[width=0.6\textwidth]{figures/quantile3.png}
\label{fig:quantile3}}

\caption{Examples of the distortions applied to images to test the robustness of the algorithms.}
\label{fig:distortions}
\end{figure}


As Adaptive LIFT-SLAM fine-tuned with Euroc sequences obtained the best overall results, we tested this algorithm under the described scenarios and compared its performance with ORB-SLAM under the same scenarios. The quantitative results of the tests are shown in table \ref{tab:distortion-results}. ORB-SLAM could not track the camera's pose with some distortion in sequences KITTI 03, 06, and 10, while LIFT-SLAM failed in some cases for sequences KITTI 10 and Euroc MH\_02. 
We can also notice that in most of the sequences, LIFT-SLAM improved its performance when we applied the distortions. This fact occurs because the distortions remove some outliers from the images, which allows the algorithms to select better keypoints.


\begin{table}[!h]
\centering
\resizebox{\textwidth}{!}{\begin{tabular}{|c|c|ccc|ccc|}
\hline
 Sequence & \textbf{Distortion} &  \multicolumn{3}{|c|}{\textbf{ORB-SLAM}} &  \multicolumn{3}{c|}{\textbf{LIFT-SLAM}} \\ \hline
 &  & $\mathbf{RPE_{trans}}$ \textbf{(\%)} & $\mathbf{RPE_{rot}}$ \textbf{(deg/m)} & \textbf{ATE (m)} & $\mathbf{RPE_{trans}}$ \textbf{(\%)} & $\mathbf{RPE_{rot}}$ \textbf{(deg/m)} & \textbf{ATE (m)} \\ \hline
 & no distortion & 9.75 & 2.78 &15.13 & 1.46 & 0.34 & 2.23 \\
 & $\gamma = 0.25$ & 7.68 & 1.95 & 11.72 & 1.02 & 0.40 & 1.23  \\
 & $\gamma = 0.5$ & 8.25 & 2.24 & 11.38 & 1.28 & 0.36 & 1.74 \\
KITTI 03 & $\gamma = 2$ & X & X & X & 1.07 & 0.51 & 1.47 \\
& $\gamma = 4$ & X & X & X & 2.82 & 0.70 & 5.23 \\
& Truncation in $Q_1$ & 8.34 & 1.41 & 13.63 & 1.36 & 0.45 & 2.07  \\
& Truncation in $Q_3$ & 9.78 & 2.23 & 15.66 & 1.10 & 0.46 & 1.27 \\ \hline

& no distortion & 8.11 & 2.88 & 20.26 & 12.24 & 2.91 & 30.38 \\
& $\gamma = 0.25$ & 8.97 & 2.11 & 21.85 & 7.94 & 2.22 & 19.07 \\
& $\gamma = 0.5$ & 9.55 & 2.16 & 24.11 & 7.61 & 2.27 & 18.19 \\
KITTI 06 & $\gamma = 2$ & 11.69 & 4.50 & 27.24 & 6.91 & 2.30 & 16.22  \\
& $\gamma = 4$ & 11.12 & 5.71 & 28.10 & 8.29 & 2.68 & 18.60  \\
& Truncation in $Q_1$ & 15.01 & 4.69 & 36.52 & 6.44 & 2.36 & 15.09  \\
& Truncation in $Q_3$ & X & X & X & 8.09 & 2.29 & 19.33 \\ \hline

& no distortion & 7.43 & 3.58 & 13.47 & 2.42 & 4.02 & 3.63 \\
& $\gamma = 0.25$ & 7.61 & 2.42 & 12.54 & 2.09 & 3.17 & 3.30\\
& $\gamma = 0.5$ & 6.37 & 2.02 & 9.58 & 1.99 & 3.88 & 2.86 \\
KITTI 07 & $\gamma = 2$ & 5.89 & 2.11 & 9.36 & 3.43 & 4.32 & 5.91 \\
& $\gamma = 4$ & 6.61 & 7.06 & 7.84 & 8.03 & 7.40 & 16.13\\
& Truncation in $Q_1$ & 8.50 & 2.47 & 10.69 & 2.45 & 4.10 & 3.58 \\
& Truncation in $Q_3$ & 7.01 & 2.40 & 7.08 & 2.69 & 3.77 & 4.49 \\ \hline

& no distortion & 8.65 & 3.62 & 19.94 & 9.72 & 2.24 & 29.87 \\
& $\gamma = 0.25$ & 13.52 & 3.01 & 26.56 & 10.72 & 2.15 & 30.77 \\
& $\gamma = 0.5$ & 12.40 & 3.95 & 25.55 & 10.03 & 2.24 & 31.93 \\
KITTI 10 & $\gamma = 2$ & 16.88 & 4.59 & 28.07 & X & X & X\\
& $\gamma = 4$ & X & X & X & X & X & X \\
& Truncation in $Q_1$ & 20.79 & 2.95 & 34.79 & X & X & X \\
& Truncation in $Q_3$ & X & X & X & X & X & X\\ \hline

& no distortion & - & - & 0.037 & - & - & 0.053\\
& $\gamma = 0.25$ & - & - & 0.055 & - & - & 0.035 \\
& $\gamma = 0.5$ & - & - & 0.040 & - & - & 0.039 \\
Euroc MH\_02 & $\gamma = 2$ & - & - & 0.061 & - & - & 0.037 \\
& $\gamma = 4$ & - & - & 0.010 & - & - & 0.194 \\
& Truncation in $Q_1$ & - & - & 0.039 & - & - & 0.043 \\
& Truncation in $Q_3$ & - & - & 0.043 & - & - & X \\ \hline

\end{tabular}}
\caption[]{Results of the robustness tests. The LIFT-SLAM version used in these tests is the adaptive fine-tuned with Euroc sequences. We fill with "X" the sequences unavailable due to tracking failure and with "-" the sequences we do not execute the algorithms.}
\label{tab:distortion-results}
\end{table}

Figure \ref{fig:all-traj-robustness} shows the comparison of the algorithm's trajectories with each distortion in KITTI and Euroc sequences. In sequences KITTI 03 and KITTI 06, LIFT-SLAM's trajectories were not much affected by distortions (Figures \ref{fig:liftslam-noise-03} and \ref{fig:liftslam-noise-06}). On the other side, the trajectories of ORB-SLAM are worse, especially in sequence KITTI 06 (Figure \ref{fig:orbslam-noise-06}). Furthermore, the trajectories of both algorithms were more affected in KITTI 07 (Figures \ref{fig:orbslam-noise-07} and \ref{fig:liftslam-noise-07}), but ORB-SLAM could not track a considerable part of the trajectory in most scenarios, while LIFT-SLAM could. In MH\_02, both algorithms' trajectories were less affected, but they lost track of the pose and relocalized in some parts of the sequence. Therefore, we can conclude by quantitative and qualitative results that LIFT-SLAM is more robust to the distortions we applied in the sequences. The main reason for this is because the learned features can handle better camera ill exposure, as the datasets used to train and fine-tune the network naturally contain varying illumination.

%robustness trajectories
\begin{figure}
\centering
\subfloat[ORB-SLAM in KITTI 03]{
\includegraphics[width=0.4\textwidth, height=3cm]{figures/orb-slam-noise03_2.png}
\label{fig:orbslam-noise-03}}
\qquad
\subfloat[LIFT-SLAM in KITTI 03]{
\includegraphics[width=0.4\textwidth, height=3cm]{figures/lift-slam-noise03_2.png}
\label{fig:liftslam-noise-03}}

\subfloat[ORB-SLAM in KITTI 06]{
\includegraphics[width=0.4\textwidth, height=3cm]{figures/orb-slam-noise-06_2.png}
\label{fig:orbslam-noise-06}}
\qquad
\subfloat[LIFT-SLAM in KITTI 06]{
\includegraphics[width=0.4\textwidth, height=3cm]{figures/lift-slam-noise-06_2.png}
\label{fig:liftslam-noise-06}}

\subfloat[ORB-SLAM in KITTI 07]{
\includegraphics[width=0.4\textwidth, height=3cm]{figures/orb-slam-noise-07_2.png}
\label{fig:orbslam-noise-07}}
\qquad
\subfloat[LIFT-SLAM in KITTI 07]{
\includegraphics[width=0.4\textwidth, height=3cm]{figures/lift-slam-noise-07_2.png}
\label{fig:liftslam-noise-07}}

\subfloat[ORB-SLAM in KITTI 10]{
\includegraphics[width=0.4\textwidth, height=3cm]{figures/orb-slam-noise-10_2.png}
\label{fig:orbslam-noise-10}}
\qquad
\subfloat[LIFT-SLAM in KITTI 10]{
\includegraphics[width=0.4\textwidth, height=3cm]{figures/lift-slam-noise-10_2.png}
\label{fig:liftslam-noise-10}}

\subfloat[ORB-SLAM in Euroc MH\_02]{
\includegraphics[width=0.4\textwidth, height=3cm]{figures/orb-slam-noise-mh02_2.png}
\label{fig:orbslam-noise-mh02}}
\qquad
\subfloat[LIFT-SLAM in Euroc MH\_02]{
\includegraphics[width=0.4\textwidth, height=3cm]{figures/lift-slam-noise-mh02_2.png}
\label{fig:liftslam-noise-mh02}}

\caption{Qualitative results of the robustness tests.}
\label{fig:all-traj-robustness}
\end{figure}


\subsection{Comparison with literature}

The results obtained have shown that LIFT is capable of improving a traditional VSLAM algorithm. Moreover, transfer learning proved to be a crucial process in our system since it improved our algorithms in different VSLAM problems. The main drawback in our system is that the good performance in large environments depends on loop closure detection, if a loop is not recognized the error increases indefinitely since the drift accumulation is not corrected with pose graph optimization, as in sequences $08$ and $09$.

Furthermore, currently, LIFT-SLAM is slow compared to other state-of-the-art algorithms because we did not optimize the LIFT code for real-time execution. The network does not have many parameters (approximately 290K) when compared to other deep networks. However, the code has some time-consuming operations that are unnecessary for our pipeline. Therefore, the time spent to generate the LIFT descriptors in a GTX 1050 Ti is 36 seconds for images from the KITTI dataset and 35 seconds for images from the Euroc dataset. This code can be improved to perform better and work in real-time (30Hz). For the sake of comparison, in the same machine, the Yolo V3 network \cite{yolov3}, with 61.9M parameters, takes approximately 22 seconds to detect objects in a KITTI image and 21 seconds in a Euroc image. 

We chose Adaptive LIFT-SLAM fine-tuned with Euroc sequences to compare with some results available in the literature. We provide in table \ref{tab:comparison-sota} compared to other algorithms in the KITTI dataset. We selected different monocular VO and VSLAM algorithms to compare with LIFT-SLAM: traditional methods, hybrid methods, and end-to-end methods. In this way, we could compare our results with algorithms that present different characteristics and are trained directly from KITTI images. Unfortunately, there are not many monocular algorithms that evaluate Euroc available in the literature. 

\begin{table}[h]
\begin{threeparttable}

\centering
\resizebox{\textwidth}{!}{\begin{tabular}{|c|c|c|ccccccccccc|}
\hline \textbf{Algorithm} & \textbf{Type} & \textbf{Metric} & \textbf{00} & \textbf{01} & \textbf{02} & \textbf{03} & \textbf{04} & \textbf{05} & \textbf{06} & \textbf{07} & \textbf{08} & \textbf{09} & \textbf{10}\\ \hline


          & &ATE (m) & 8.06 & X & 40.04 & \textbf{2.23} & \textbf{0.51} & 13.55 & 30.38 & \textbf{3.63} & 184.43 & 59.62 & 29.87 \\
LIFT-SLAM & Hybrid & $RPE_{trans}$ (\%) & \textbf{3.18} & X & 8.73 & \textbf{1.46} & \textbf{2.22} & 6.09 & 12.24 & \textbf{2.42} & 47.10 & 19.91 & 9.72 \\
          & &$RPE_{rot}$ (deg/m) & 2.99 & X & 2.49 & \textbf{0.34} & \textbf{0.48} & 3.11 & 2.91 & 4.02 & \textbf{2.02} & 2.14 & \textbf{2.24}  \\  \hline
          
          
           && ATE (m) & 11.54 & X & X & 15.13& 4.29 & \textbf{7.74} & 20.26 & 13.47 & \textbf{39.51} & 49.67 & \textbf{19.94}\\
ORB-SLAM\tnote{*}   & Traditional  & $RPE_{trans}$ (\%) & 4.46 & X & X & 9.75 & 3.71 & 3.35 & 8.11 & 7.43 & \textbf{12.16} & 26.51 & 8.65 \\
            && $RPE_{rot}$ (deg/m) & 3.28 & X & X & 2.78 & 2.15 & 3.57 & 2.88 & 3.58 &3.05 & 11.13 & 3.62 \\ \hline
              
              
          & &ATE (m) & \textbf{5.33} & X & \textbf{21.28} & 1.51 & 1.62 & 4.85 & \textbf{12.34} & 2.26 & 46.68 & \textbf{6.62} & 8.80 \\
ORB-SLAM \cite{orb-slam} & Traditional & $RPE_{trans}$ (\%) &-&-&-&-&-&-&-&-&-&-&- \\
                        & &$RPE_{rot}$ (deg/m) &-&-&-&-&-&-&-&-&-&-&- \\ \hline


                     & &ATE (m)&-&-&-&-&-&-&-&-&-&-&- \\ 
DeepVO\cite{deep-vo}\tnote{**}& End-to-end & $RPE_{trans}$ (\%)&-&-&-& 8.49 & 7.19 & 2.62 & 5.42 & 3.91 &-&-& \textbf{8.11} \\
                    & &$RPE_{rot}$ (deg/m)&-&-&-& 6.89 & 6.97 & 3.61 & 5.82 & 4.60 &-&-& 8.83 \\\hline

                     %& &ATE (m)& 95.92 & - & 150.56 & 21.02 & 5.65 & 54.86 & 91.06 & 7.96 & 68.19 & 30.70 & 22.76 \\ 
%\textcolor{red}{DeepVO\tnote{*}}& End-to-end & $RPE_{trans}$ (\%)& 80.62 & - & 106.76 & 64.86 & 18.95 & 62.27 & 67.37 & 43.49 &  85.28 & 86.68 & 95.93\\
 %                   & &$RPE_{rot}$ (deg/m)& 114.58 & - & 111.50 & 59.40 & 16.75 & 113.07 & 109.59 & 122.13 & 105.65 & 108.44 & 102.15 \\\hline

                  &  & ATE (m) &-&-&-&-&-&-&-&-&-&-&- \\ 
NeuralBundler \cite{pose-graph-optimization}& Hybrid & $RPE_{trans}$ (\%) & 3.24 & - & \textbf{4.85} & - & - & \textbf{1.83} & \textbf{2.74} & 3.53 &-& \textbf{6.23} &- \\
                    && $RPE_{rot}$ (deg/m) & \textbf{1.35} & - & \textbf{1.60} & - & - &\textbf{0.7} & \textbf{2.6} & \textbf{2.02} & - &\textbf{2.11} & - \\\hline
                    
\end{tabular}}
        \begin{tablenotes}
            \item[*] {\footnotesize Our executions.}
            \item[**]{\footnotesize  Only VO.}
        \end{tablenotes}
\end{threeparttable}

\caption{Comparison of LIFT-SLAM with results from monocular VO/VSLAM algorithms available in the literature. We fill with "X" results that are unavailable due to tracking failure and with "-" results that were not given by the authors.}
\label{tab:comparison-sota}
\end{table}

Table \ref{tab:comparison-sota} shows that LIFT-SLAM obtained the smallest error in sequences 00, 03, 04, 07, 08, and 10. Additionally, we can verify that the end-to-end approach is not as accurate as traditional and hybrid approaches. It is important to mention that the LIFT-SLAM version used in this evaluation was not finetuned with any KITTI sequence, while DeepVO \cite{deep-vo} and NeuralBundler \cite{pose-graph-optimization} approaches were trained with some KITTI sequences,  typically indicating an overfit over this dataset. Nevertheless, we still present competitive results without overfitting in the dataset. 


Figure \ref{fig:deepvo-vs-ours} shows a qualitative comparison between our algorithm and DeepVO \cite{deep-vo}. The DeepVO trajectories were generated by us, based on the model trained by the unofficial PyTorch implementation available at \cite{deepvo-github}. In most of the sequences, LIFT-SLAM trajectories are closer to the ground-truth. It is important to remark that DeepVO has no loop-closure detection. However, LIFT-SLAM performed better even in sequences without a loop, such as 03 (Fig. \ref{fig:deepvo-03}) and 04 (Fig. \ref{fig:deepvo-04}). Unfortunately, there are no hybrid methods for monocular VSLAM with open code available, so we could not evaluate these algorithms' qualitative results.


%deepvo vs ours trajectories
\begin{figure}
\centering
\subfloat[LIFT-SLAM and DeepVO trajectories in KITTI 03.]{
\includegraphics[width=0.4\textwidth, height=3cm]{figures/comparison-deepvo-kitti03.png}
\label{fig:deepvo-03}}
\qquad
\subfloat[LIFT-SLAM and DeepVO trajectories in KITTI 04.]{
\includegraphics[width=0.4\textwidth, height=3cm]{figures/comparison-deepvo-kitti04.png}
\label{fig:deepvo-04}}

\subfloat[LIFT-SLAM and DeepVO trajectories in KITTI 05.]{
\includegraphics[width=0.4\textwidth, height=3cm]{figures/comparison-deepvo-kitti05.png}
\label{fig:deepvo-05}}
\qquad
\subfloat[LIFT-SLAM and DeepVO trajectories in KITTI 06.]{
\includegraphics[width=0.4\textwidth, height=3cm]{figures/comparison-deepvo-kitti06.png}
\label{fig:deepvo-06}}

\subfloat[LIFT-SLAM and DeepVO trajectories in KITTI 07.]{
\includegraphics[width=0.4\textwidth, height=3cm]{figures/comparison-deepvo-kitti07.png}
\label{fig:deepvo-07}}
\qquad
\subfloat[LIFT-SLAM and DeepVO trajectories in KITTI 10.]{
\includegraphics[width=0.4\textwidth, height=3cm]{figures/comparison-deepvo-kitti10.png}
\label{fig:deepvo-10}

}


\caption{Qualitative comparison with DeepVO trajectories we generated in KITTI dataset. The LIFT-SLAM version used in this comparison is the Adaptive finetuned with Euroc sequences.}
\label{fig:deepvo-vs-ours}
\end{figure}
\subsection{Architecture}
\label{subsec:architecture}
We realized the \tcpa protocol as described above in the \tool system to enable 
trusted and confidential program analysis for programs that compile to web assembly (\wasm). 
Specifically, we used the AMD SEV~\cite{sev2020strengthening} as the underlying trusted execution 
environment and a symbolic-execution-based engine to deliver program analysis~\cite{yang2020seraph}. 
The architecture of \tool is shown in Figure~\ref{fig:sys}. 

\begin{figure*}[h]
\centering
\includegraphics[width=.7\linewidth]{tcwasm-architecture.pdf}
\caption{\label{fig:sys}The architecture of \tool.}	
\end{figure*}

In general, \tool is implemented as a form of cloud service and is compatible with any existing 
platform, \eg, Amazon, Google, Alibaba etc. We offer four types of sub-services for 
end users, \eg, Alice and Bob in Figure~\ref{fig:protocol}, who are trying to agree on the 
regulatory compliance of a confidential software. The functionalities of these sub-services 
are summarized below.

\begin{itemize}[leftmargin=*]

\item \textbf{Regulatory Property Service} allows a software customer to publish an agreed set of 
regulatory properties which will be verified for the software created by a provider later in \tool. 
The agreement on properties is formed with signatures of both the provider and customer 
included. The service also offers accesses to properties that are publicly available. Any relevant 
participant - \eg, downstream users, audit teams, \textit{etc} - can check the properties managed on \tool 
and understand the compliance guarantee from their own perspective.

\item \textbf{Program Analysis Service} runs the underlying analysis processes to decide whether the 
given software is compliant with the specified set of properties. As illustrated in Figure~\ref{fig:protocol}, 
the provider is required to submit an encrypted version of source code and the deployed executable. 
The service will generate a certificate of compliance as a form of report for relevant parties, \eg, the 
customer, to confirm that the specified computation process has been executed on the given software and 
yielded a compliance decision for it to explain whether the software satisfies the properties, and why it 
is the case.

\item \textbf{Configuration Service} helps users configure \tool based on their preference. 
Practically, it is reasonable to make the projection that \tool will probably have a collection 
of program analysis settings instead of a single one. For example, different customers might like to adopt 
different algorithms to analyze the software. The configuration service allows users to specify the computation 
without looking into too many technical details. 

\item \textbf{Remote Attestation Service} enables an end user to verify the running environment 
on the cloud. To this end, a user is required to post a request to \tool and start the remote attestation 
process. The service sends back a cryptographic certificate to guarantee that the running environment is indeed 
as stated (\eg, an AMD SEV) and the image to be loaded and executed is as expected. The certificate can be passed to 
other parties and they can then confirm the validity of the running environment by checking the certificate. 
The remote attestation service can be contacted at any time during the execution to generate the certificate as long 
as it is necessary to do so.

\end{itemize}


 

\subsection{Trusted Environment}
\label{subsec:env}

We use AMD SEV as the underlying \tee environment for \tool. A cryptography library is included to realize 
encryption and decryption actions as specified in \tcpa based on the set of cryptographic keys provided in AMD SEV. 
In addition, \tool implements a set of APIs to deliver the trusted certificate from AMD SEV to end users, \eg, a 
verifiable measurement of firmware, disk, memory, \textit{etc}. Due to the portability of AMD SEV, integration with other 
program analysis engines is straightforward.


\subsection{Property Specification and Management}
\label{subsec:property}
In \tool, the agreed set of regulatory properties is stored on a blockchain. Therefore, a majority of nodes 
in the network will have a consistent view on those properties as they replicate the ledger and states. To 
this end, \tool embeds a blockchain client to interact with the underlying blockchain. In principle, both 
permissioned and permissionless blockchains can fit in our setting, \eg, \ethereum~\cite{wood2014ethereum}, 
Fabric~\cite{cachin2016architecture}, \textit{etc}. While the former is more suitable for a relatively stable group of 
software providers and customers, the latter fits better in an open market where any global participant is 
allowed to join. The blockchain client can submit properties provided by users to blockchain in several different 
ways, \eg, as transaction metadata, as structural storage of smart contracts, \textit{etc}. In cases of dispute (\ie, 
providers and consumers have conflicting views on properties) which is commonly resulted from forking on the 
blockchain, \tool is able to have a further decision after several blocks and the longest chain can be identified. 

Moreover, properties can be defined with both existing or user-defined specification languages, \eg, computation 
tree logic, linear temporal logic, \etc In the preliminary realization of \tcpa, we specify safety properties as 
program assertions, \eg, via \texttt{assert} statement. Therefore, the checking of such properties is converted to 
a reachability problem where an analysis is required to search for a transition that can potentially lead to a 
unsafe state. As mentioned earlier, it is possible to have multiple types of specifications in \tool. Users are allowed to configure 
which one they will apply for the submitted properties. 


%\subsection{WASM Analysis Framework}
%\label{subsec:wasm}
%The analysis framework in \tool can have different implementations. As Figure~\ref{fig:sys} shows, we currently use 
%a framework based on symbolic execution but the general design can fit into a wider range of program analysis techniques, 
%\eg, formal verification, automated testing \etc. In the current realization, the given source code is processed by 
%a software building framework specified by the provider of the software. The provider needs to guarantee that the building 
%process is exactly what they have used to generate the target software. They building process will compile the confidential 
%source code to binary. As described above, the program analysis process is executed via transforming 
%the binary into a control flow graph and symbolically exploring its semantic space to check whether the properties hold or 
%not. For those passing the checks, \tool performs a comparison between two versions of executables, \ie, the one given by 
%the software provider and the one generated by \tool. The comparison checks every single bit in the pair of binaries and 
%decides whether they match.

\subsection{A Formal Framework For Analyzing \wasm}
\label{subsec:formal}
We formalize a \wasm program $P \coloneqq \langle \mathcal{M}_0, \mathcal{M}_1, \cdots, \mathcal{M}_n \rangle$ as a group of modules to be deployed, each of 
which is a tuple $\mathcal{M} \coloneqq \langle \mathbb{T}, F, T, M, G \rangle$, where 
\begin{itemize}[leftmargin=*]
\item $\mathbb{T}$ defines a vector of function types.

\item $F \coloneqq \langle F_0, F_1, \cdots, F_n \rangle$ is a collection of functions. For each function $f\in F$, 
$ f = \langle \textit{ft} \in \mathbb{T}, L, E\rangle$ comes with a type, a set $L$ of local variables 
that are only accessible inside a function and a list $E$ of expressions. More specifically, expressions in $E$ are 
converted to a control flow graph, where a node in the graph is a basic block that includes a sequence of 
\wasm statements and an edge is a jump from one basic block to another.
 
\item $T$ is a table of indexed function references.

\item $M$ is a list of memory elements which can be linearly addressed inside a module.

\item $G$ is a set of global variables which can be assessed from any function.
\end{itemize}

The program analysis framework $A$ that we developed in this work for \wasm programs is formalized 
as a tuple $A \coloneqq \langle K_f, K_o, M, \mathit{SrcMap}, \mathit{Spec} \rangle$, 
where $K_f$ and $K_o$ are stacks of function calls and operands, respectively. 
$M$ denotes the set of modules to be analyzed by $A$. $\mathit{SrcMap}$ is a source map 
which creates a bidirectional link between confidential source code and bytecode of \wasm. 
$\mathit{Spec}$ is the specification standard of \wasm. Moreover, a configuration 
of $A$ is abstracted as $c \coloneqq \langle \mathit{pc}, \mathit{src}, k_f, k_o, S, P, \mathcal{G} \rangle$, 
where 
\begin{itemize}[leftmargin=*]
\item $\mathit{pc}$ is a program counter that points to the current program location.

\item $\mathit{src}$ is a source code pointer which maps from current $\mathit{pc}$ to 
the corresponding source code (\eg, at a specific line of code and offset).

\item $k_f$ shows the current stack of functions.

\item $k_o$ describes the current stack of operands.

\item $S \coloneqq \langle S_0, S_1, \cdots, S_n \rangle$ is a tuple containing one state per module. 
Specifically, $S_i \in S$ ($0\le i \le n$) is the state for module $\mathcal{M}_i$, which is a 
tuple $\langle m, G, L\rangle$. $m$ is a snapshot of memory. $G$ and $L$ describe valuation for 
both global and local variables. 

\item $P$ is a set of path conditions, each of which is a group of symbolic conditions to enable 
the exploration of a specific program path.

\item $\mathcal{G} = \langle V, E \rangle$ is a semantic graph that describes fundamental program 
relations. The vertices $V$ represent variables, \eg, local variable, global variable, \etc Edges 
$E$ are an abstraction of dependency between variables. In general, we defined two types of dependencies, 
\ie, data flow and control flow dependency (marked as $\mapsto$ and $\rightarrowtail$), respectively. 
For example, $a \mapsto b$ indicates that the value of $b$ is dependent on the value of $a$ (data flow). 
$c \rightarrowtail d$ defines a control flow relation where the value of $c$ is related to the path selection 
of a control flow therefore affects the value of $d$.
\end{itemize}

As introduced above, the current implementation of program analysis in \tcpa is based on 
symbolic execution. Specifically, the configuration of $A$ is initialized with a starting 
module $M_j$ and function $f_k$. The analysis start by examining the statements in this function's body.
Given a statement $e$, the program analysis framework $A$ retrieves elements from $K_o$, performs 
computation as specified in the \wasm standard, potentially updating memory, local storage, 
global storage, path conditions and semantic graph. That said, the processing of $e$ yields a transition 
of configuration of $A$, from the current one $c \coloneqq \langle \mathit{pc}, \mathit{src}, k_f, k_o, S, P, \mathcal{G} \rangle$ 
to a new one $c'$. When a program path has been visited, we combine the path conditions with the specified 
properties for SMT solving and further verifying whether the properties hold or not. This process iterates 
until a completion criterion for program analysis is realized, \eg, coverage, time, \etc

Although symbolic execution is performed on \wasm bytecode, it requires fundamental knowledge from the 
confidential source code. The most obvious information required in \tcpa is a source map that links 
every bit in the bytecode back to source code, and the other way around as well. With a source map, \tcpa 
can provide software producers with understandable results, \eg, a bug is located at a specific line. 
Moreover, type information at source code level is also important to facilitate program analysis. For example, we 
would be able to associate memory access with variables in source code with their types.

The analysis framework $A$ can have different implementations. As Figure~\ref{fig:sys} shows, we currently use 
a framework based on symbolic execution but the general design can fit into a wider range of program analysis techniques, 
\eg, formal verification, automated testing, \etc
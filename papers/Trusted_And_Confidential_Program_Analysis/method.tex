\subsection{Overview}
\label{subsec:overview}

The general workflow of \tcpa is shown in Figure~\ref{fig:protocol}. The protocol defines the following types of actors, namely, Provider (Alice), Consumer (Bob), and the Trusted and Confidential Program Analysis Isolated Computation (\TCPAIC{}). Alice is the software provider in this 
setting who wants to export her products to the Consumer Bob and therefore needs to convince 
him that the exported software is strictly compliant with regulations. 
As aforementioned, Alice also needs to avoid revealing the product's business secrets 
(\eg, source code) to non-relevant parties such as Bob. In this set-up, Bob hosts the \tee{} where \TCPAIC{} is to be executed. He is in charge of setting up the TEE-enabled platform and \TCPAIC{}. Even with unlimited access to the platform, not even Bob can infer any secrets from this compliance analysis since the product is analysed within the isolated service \TCPAIC{}. Of course, we could have an alternative setup where Alice or a third party would host the \tee where \TCPAIC{} executes. This set-up, however, reinforces and highlights that even the platform's operator, with unrestricted access, cannot read into the isolated computation's execution.

Important concepts in \tcpa as listed below.

\begin{itemize}[leftmargin=*]
\item $S$ is the source code of a given piece of software.

\item $E$ is the executable corresponding to $S$.

\item $P=\{p_1, p_2, \cdots, p_n\}$ is a set of regulatory properties to be checked.

\item $X$ is a program analysis framework, \eg, static analysis, dynamic analysis. 

\item $B$ is the building framework of $S$, \ie, create $E$ from $S$. The most common example of 
$B$ is a compiler.

\item $\TCPAIC{}(X,B,P)$ is the isolated computation that carries out the indicated trusted and confidential program analysis.

\item Public and private keys \IC{}$_{\pb{}}$ and \IC{}$_{\pv{}}$, respectively, are elements of a signature scheme used to authenticate messages issued by $\TCPAIC{}(X,B,P)$. 
%These keys are generated within $\TCPAIC{}(X,B,P),$ and the private key is never exported. Hence, no-one can access this secret, not even the platform owner/operator.

\item $T$ is a symmetric key for encryption and decryption. $S_T$ indicates an encrypted version of $S$.

\item The platform certificate (\PC{}), isolated computation certificate (\ICC{}), and compliance certificate (\CC{}) attest the platform's capabilities, the isolated computation's measurement, and the program analysis' outcome, respectively - we detail these elements in the following.

%\item The isolated computation report (\ICR{}) is a certificate issued by the platform that is cryptographically signed using a protected key only accessible to the TEE, and contains the cryptographic measurement for the corresponding computation.
%
%\item The compliance report (\CR{}) are the platform authenticity certificate, attestation report, and compliance report, respectively.
%
%\item The platform report (\PR{}) is a certificate issued by the TEE implementer - i.e., the processor's manufacturer - cryptographically signed using a well-known,  attesting the authenticity and validity of the TEE's hardware and software components.
%
%\item The isolated computation report (\ICR{}) is a certificate issued by the platform that is cryptographically signed using a protected key only accessible to the TEE, and contains the cryptographic measurement for the corresponding computation.
%
%\item The compliance report (\CR{}) are the platform authenticity certificate, attestation report, and compliance report, respectively.

\end{itemize}

\subsection{Platform set-up}

%Roughly speaking, as evidence that a computation has been properly isolated, TEE implementations provide an \emph{attestation certificate chain} consisting of: (i) a certificate with the \emph{trusted platform's public key} signed by a well-known \emph{root-of-trust public key} owned by the chip's manufacturer, and (ii) a certificate with the desired \emph{isolated computation's measurement} cryptographically signed by the \emph{platform protected private key} - the attestation report might also include some extra data that the isolated computation passed to the TEE implementation. We refer to certificate (i) as a \emph{platform authenticity certificate} (PAC) and certificate (ii) as \emph{attestation report}. This signature is only given once the manufacturer has engaged in a protocol with the TEE implementation by which it verifies the authenticity of the chip, its capability to run isolated computations, and that the trusted software components that are part of the TEE implementation have been properly set up. Manufacturers store a non-exportable secret in the chip's fuses that allows processors to be authenticated by them and its capabilities checked. Once a chip is authenticated, hardware primitives can be trusted to correctly measure software components of the TEE implementation.
%
%Before we discuss the protocol in detail in the next sections, we Roughly speaking, as evidence that a computation has been properly isolated, TEE implementations provide an \emph{attestation certificate chain} consisting of: (i) a certificate with the \emph{trusted platform's public key} signed by a well-known \emph{root-of-trust public key} owned by the chip's manufacturer, and (ii) a certificate with the desired \emph{isolated computation's measurement} cryptographically signed by the \emph{platform protected private key} - the attestation report might also include some extra data that the isolated computation passed to the TEE implementation. We refer to certificate (i) as a \emph{platform authenticity certificate} (PAC) and certificate (ii) as \emph{attestation report}. This signature is only given once the manufacturer has engaged in a protocol with the TEE implementation by which it verifies the authenticity of the chip, its capability to run isolated computations, and that the trusted software components that are part of the TEE implementation have been properly set up. Manufacturers store an unrecoverable secret in the chip's fuses that allows processors to be authenticated by them and its capabilities checked. Once a chip is authenticated, hardware primitives can be trusted to correctly measure software components of the TEE implementation.

Before the protocol in Figure~\ref{fig:protocol} can be executed, we assume a \emph{platform setup} step; omitted from that figure for the sake of simplicity. In this step, the platform engage in a protocol with the processor manufacturer, who is typically also the TEE implementer, aimed at proving the processor's authenticity, its capability to run isolated computations, and that all the trusted elements - both hardware and software - part of the TEE implementation are valid and have been properly set up. Manufacturers store a non-exportable secret in the chip's fuses that allows them to authenticate processors. Once a chip is authenticated and its capabilities checked, low-level primitives can be trusted to correctly validate hardware and software components of the TEE implementation. As a result of this process, the processor's manufacturer issues a \emph{platform certificate} (\PC{}) - we describe this certificate and its elements as follows.

\begin{itemize}[leftmargin=*]
	\item The manufacturer's public and private \emph{root of trust} keys \RoT{}$_{\pb{}}$ and \RoT{}$_{\pv{}}$, respectively, are elements of a signature scheme used to authenticate messages issued by this actor. The public component is well-known and trusted to be the correct \emph{root of trust} key for the manufacturer.
	
	\item The platform's public and private \emph{protected} keys \Plat{}$_{\pb{}}$ and \Plat{}$_{\pv{}}$, respectively, are elements of a signature scheme used to authenticate messages issued by this actor, and more specifically its TEE. These keys are managed by the TEE implementation and not even the platform owner has access to the private components.
	
	\item $\PC{} = (\Plat_{\pb{}})_{\RoT{}_{\pv{}}}$ is a certificate containing the platform's protected public key and a cryptographic signature of this key issued by the processor's manufacturer using \RoT{}$_{\pv{}}$. 
	
	\begin{itemize}
			\item In this paper, we use  $(el_1,\ldots,el_n)_{k}$ to denote a certificate containing the elements $el_1,\ldots,el_n$ together with a cryptographic signature of them using key $k$.
	\end{itemize}
\end{itemize}

This certificate is evidence that the platform's TEE is valid and has been properly set up, and its authenticity can be verified using \RoT{}$_{\pb{}}$. It also vouches for the platform protected key $\Plat_{\pb{}}$. As we detail later, this certificate and the elements above play a part in the attestation process.
%This guarantee is based on the assumption that the manufacturer only issues this certificate upon the appropriate execution of its certification protocol and that the signature schemes used give the    

As shown in Figure~\ref{fig:protocol}, the protocol works in three phases, \ie, initialization, 
remote attestation and program analysis. We now describe them in detail.

\subsection{Initialization}
\label{subsec:initialization}

The initialization phase of \tcpa begins with Producer and Consumer agreeing on the program analysis framework $X$, building framework $B$, and regulatory properties $P$ that are to be used by our isolated computation \TCPAIC{}. Once they have agreed on these parameters, Bob creates the isolated computation $\TCPAIC{}(X,B,P)$ as he is the owner of the platform. Thus, the code and data used by $\TCPAIC{}(X,B,P)$ is loaded in encrypted form, measured, and executed. Once this service starts, it generates its own key pair using a trusted source of randomness, and the \emph{isolated computation certificate} ($\ICC$). We define these elements as follows. 

\begin{itemize}[leftmargin=*]
	\item The $\TCPAIC{}(X,B,P)$ public and private keys \IC{}$_{\pb{}}$ and \IC{}$_{\pv{}}$, respectively, are elements of a signature scheme used to authenticate messages issued by this actor. These keys are managed by the isolated computation process $\TCPAIC{}(X,B,P)$ and not even the platform owner has access to the private components.
	
	\item $\ICC{} = (m_{\IC{}}, \IC{}_{\pb})_{\Plat{}_{\pv{}}}$ is a certificate containing the cryptographic measurement of the isolated computation process $\TCPAIC{}(X,B,P)$ given by $m_{\IC{}}$, and $\TCPAIC{}(X,B,P)$'s public key $\IC{}_{\pb{}}$. The certificate is signed by the platform's protected private key $\Plat{}_{\pv{}}$. The measurement $m_{\IC{}}$ is a cryptographic hash of the memory pages, \ie, code and data, loaded into main memory corresponding to $\TCPAIC{}(X,B,P)$; it accounts for the parameters $X$, $B$ and $P$. 
\end{itemize} 

This certificate provides evidence that an isolated computation with measurement $m_{\IC{}}$ has been created by a platform identified by key $\Plat_{\pb{}}$, and that this computation certified the blob of data, which happens to be its public key, $\IC{}_{\pb{}}$. While the measurement of the computation is calculated and set by the TEE, the isolated computation is free to pass any extra blob of data to be certified. Thus, while the measurement can be trusted to be correct, provided that the platform and TEE are trusted, the blob of data must only be relied upon if the isolated computation's code request the certification of the appropriate data.


%As aforementioned, \tool performs \emph{oracle analysis} to check whether 
%a \defi is dependent on the oracle provided by another \defi. Particularly, 
%we focused on the price feed of assets shared through oracles.

%\begin{figure}[h]
%\begin{lstlisting}[frame=tblr, language=Solidity, showstringspaces=false]
%function calculateContinuousMintReturn(uint _amount) 
%  public view returns (uint mintAmount) {
%	return CURVE.calculatePurchaseReturn(totalSupply(), 
%	       reserveBalance, uint32(reserveRatio), _amount);
%}
%
%function sell(uint _amount, uint _min) external 
%  returns (uint _bought) {
%  _bought = _sell(_amount);
%  require(_bought >= _min, "slippage");
%  _burn(msg.sender, _amount);
%  DAI.transfer(msg.sender, _bought);
%  ...
%}
%\end{lstlisting}
%\caption{Oracle in the \texttt{EMN} project}
%\label{lst:oracle}
%\end{figure}

%we Roughly speaking, as evidence that a computation has been properly isolated, TEE implementations provide an \emph{attestation certificate chain} consisting of: (i) a certificate with the \emph{trusted platform's public key} signed by a well-known \emph{root-of-trust public key} owned by the chip's manufacturer, and (ii) a certificate with the desired \emph{isolated computation's measurement} cryptographically signed by the \emph{platform protected private key} - the attestation report might also include some extra data that the isolated computation passed to the TEE implementation. We refer to certificate (i) as a \emph{platform authenticity certificate} (PAC) and certificate (ii) as \emph{attestation report}. This signature is only given once the manufacturer has engaged in a protocol with the TEE implementation by which it verifies the authenticity of the chip, its capability to run isolated computations, and that the trusted software components that are part of the TEE implementation have been properly set up. Manufacturers store a non-exportable secret in the chip's fuses that allows processors to be authenticated by them and its capabilities checked. Once a chip is authenticated, hardware primitives can be trusted to correctly measure software components of the TEE implementation.



\subsection{Remote Attestation}
\label{subsec:attestation}

%The remote attestation process should provide enough evidence to convince Alice (Provider) that the expected isolated computation has been properly set up and started in a valid TEE-enabled platform. This phase begins by Alice requesting both the platform and isolated computation certificates $\PC{}$ and $\ICC{}$. Once she receives them, Alice can verify this \emph{attestation certificate chain} as follows. She knowns and trust the manufacturer's $\RoT{}_{\pb{}}$ key. Therefore, she can use this key to verify $\PC{}$'s signature/authenticity. If the verification succeeds, Alice trusts the TEE implementation managing the key $\Plat{}_{\pb{}}$ in $\PC{}$ - and its private counterpart $\Plat{}_{\pv{}}$. She can then use this platform protected public key $\Plat{}_{\pb{}}$ to verify $\ICC$'s authenticity. If this verification is successful, Alice trusts the   The last step in this verification process consists of checking for the expected measurement. Alice calculates the measurement that she expects for $\TCPAIC(X,B,P)$ - let us call is $m_{exp}$ - and then compare it to the $m_{\IC{}}$ element of $\ICC{}$. If any of these verifications fail, Alice stops taking part in the protocol. If all of them suceed, however, Alice should be convinced that $\TCPAIC(X,B,P)$ has been correctly isolated, it is the computation expected, and as part of its execution its public key $\IC{}_{\pb{}}$, an element of certificate \ICC{}, has been certified. In the final step in this phase Alice and $\TCPAIC(X,B,P)$ negotiate $T$: a symmetric encryption scheme key used to confidentially transmit data between them. The key pair $\IC_{pb}$ and $\IC_{pv}$ can be used to authenticate $\TCPAIC(X,B,P)$'s messages in this negotiation process. 

The remote attestation process should provide enough evidence to convince Alice (Provider) that the expected isolated computation has been properly set up and started in a valid TEE-enabled platform. This phase begins by Alice requesting both the platform and isolated computation certificates $\PC{}$ and $\ICC{}$. Once she receives them, Alice can verify this \emph{attestation certificate chain}. She knows and trusts the manufacturer's $\RoT{}_{\pb{}}$ key. Therefore, she can use this key to verify $\PC{}$'s signature/authenticity. Once this certificate is verified, she can extract the platform protected key $\Plat{}_{\pb{}}$ from it and use this key to verify $\ICC$. The last step in this verification process consists of checking for the expected measurement. Alice calculates the measurement that she expects for $\TCPAIC(X,B,P)$ - let us call is $m_{exp}$ - and then compares it to the $m_{\IC{}}$ element of $\ICC{}$. If any of these verifications fail, Alice stops taking part in the protocol. If all of them succeed, however, Alice should be convinced that $\TCPAIC(X,B,P)$ has been correctly isolated, it is the computation expected, and, as part of its execution, its public key $\IC{}_{\pb{}}$, an element of certificate \ICC{}, has been certified. In the final step in this phase Alice and $\TCPAIC(X,B,P)$ negotiate $T$: a symmetric encryption scheme key used to confidentially transmit data between them. This key is negotiated in a way that it does not become known to Bob, say using some form of the Diffie–Hellman key exchange method. The key pair $\IC_{\pb{}}$ and $\IC_{\pv{}}$ can be used to authenticate $\TCPAIC(X,B,P)$'s messages in this negotiation process. 

%The remote attestation process should provide enough evidence to convince Alice (Provider) that the expected isolated computation has been properly set up and started in a valid TEE-enabled platform. This phase begins by Alice requesting both the platform and isolated computation certificates $\PC{}$ and $\ICC{}$. Once she receives them, Alice can verify this \emph{attestation certificate chain}. She knowns and trust the manufacturer's $\RoT{}_{\pb{}}$ key. Therefore, she can use this key to verify $\PC{}$'s signature/authenticity. Once this certificate is verified, she can extract the platform protected key $\Plat{}_{pb}$ from it and use this key to verify $\ICC$. The last step in this verification process consists of checking for the expected measurement. Alice calculates the measurement that she expects for $\TCPAIC(X,B,P)$ - let us call is $m_{exp}$ - and then compare it to the $m_{\IC{}}$ element of $\ICC{}$. If any of these verifications fail, Alice stops taking part in the protocol. If all of them suceed, however, Alice should be convinced that $\TCPAIC(X,B,P)$ has been correctly isolated, it is the computation expected, and as part of its execution its public key $\IC{}_{\pb{}}$, an element of certificate \ICC{}, has been certified. In the final step in this phase Alice and $\TCPAIC(X,B,P)$ negotiate $T$: a symmetric encryption scheme key used to confidentially transmit data between them. The key pair $\IC_{pb}$ and $\IC_{pv}$ can be used to authenticate $\TCPAIC(X,B,P)$'s messages in this negotiation process. 

\subsection{Program Analysis}
\label{subsec:ssg}

The program analysis phase of our protocol involves the examination of $S$ and $E$. 
Alice starts this phase by sending $S_T$ and $E$ to $\TCPAIC{}(X,B,P)$. 
The isolated computation, then, decrypts $S_T$ and proceeds to check: (i) whether $S$ meets the properties $P$, and (ii) whether $E$ is an executable capturing the behaviour of $S$. In principle, \tcpa does not limit the type of analysis 
run by $\TCPAIC{}$, that is, any well-defined framework could be used to verify $S$'s compliance with $P$ and $E$'s correspondence to $S$. Figure~\ref{fig:program-analysis} illustrates a framework to check both (i) and (ii).
The left part demonstrates a typical analysis flow based on symbolic execution. The source code 
of a program is firstly taken by \cfg builder to generate a control flow graph , \ie, \cfg. 
Then, a symbolic execution engine is triggered to explore the \cfg with symbolic inputs. 
In the process of symbolic execution, symbolic traces are produced for further analysis. 
For a specific trace, a semantic analyzer checks whether the properties hold or not. Lastly, 
an analysis report is generated as a summary of the process. The design 
of a specific program analysis technique is not our main focus in this paper, and as mentioned before, other verification frameworks could be plugged into our \tcpa protocol. The right part of this framework describes a process to determine $E$'s correspondence 
to $S$. Specifically, an executable $E'$ is built with $B$ for the given $S$. 
Then, $E'$ is compared with $E$ (\ie, executable provided by Alice) using an executable checker that syntactically compares them for equality. If so, it is safe to conclude that $E$ corresponds to $S$. Of course, we could have more sophisticated executable checkers where some form of \emph{semantic} equivalence between $E$ and $E'$ could be checked instead. Furthermore, we could even completely bypass this comparison step, and return $E'$ to Alice. Given that this executable was created by $\TCPAIC{}(X,B,P)$ using $B$ and that $B$ is trusted to be correct, $E'$ should correspond to $S$. Once the analysis is finished, $\TCPAIC{}(X,B,P)$ creates the \emph{compliance certificate} (\CC{}) as follows.

\begin{figure}[t]
	\centering
	\includegraphics[width=\linewidth]{program-analysis.pdf}
	\caption{\label{fig:program-analysis}The workflow of program analysis.}	
\end{figure}

\begin{itemize}[leftmargin=*]
	\item $\CC{} = (h(S), E, R)_{\IC{}_{\pv{}}}$ contains a cryptographic hash of $S$ (i.e., $h(S)$), the executable $E$ sent by Alice, and an analysis report $R$, and it is signed using the computation $\TCPAIC{}(X,B,P)$'s private key $\IC{}_{\pv{}}$ . The report $R$ is a pair $(eo, (po_1,\ldots,po_{n}))$ where $eo$ is the executable equality outcome - a boolean that is true if they are equivalent, and false otherwise - and the tuple $(po_1,\ldots,po_{n})$ has a property verification outcome $po_i$ for each corresponding to property $p_i$ in $P$. The format of property outcomes $po_i$ will vary based on the choice of source code and property languages, and verification framework. For instance, considering stochastic systems and verification frameworks, a property outcome would present the likelihood of a property being valid. On the other hand, a non-stochastic model checker applied to a deterministic program could output precisely whether a property holds. There are even non-stochastic approximate analysers which might admit an \emph{unknown} outcome when they cannot issue a definitive statement about the specific $S$ and $p_i$ being analysed. These approximations are typically used for the sake of decidability or efficiency.
\end{itemize}

Finally, $\CC{}$ is sent back to Alice which can forward $\PC{}$, $\ICC{}$ and $\CC{}$ to Bob. He can then verify this certificate chain just like Alice does on the remote attestation phase with the extra steps that $\CC{}$'s signature must be verified against $\IC_{\pb{}}$ and that the report $R$ in $\CC{}$ must have the executable equality outcome set to true and that all properties are valid. If the verification of this certificate chain succeeds, Bob trusts $R$ - and, consequently, the compliance status of $E$ - and can start using this product.

In this protocol, neither Alice or Bob authenticate any messages by, say, signing them. We could, of course, require that Alice and Bob have a key pair each, for which public component is known to the other participant, that they could use to set up authenticated and confidential channels between them using well-known cryptographic protocols. The protocol could then take place over these channels. We do not detail this set-up as our primary goal in this paper is to introduce a protocol by which Bob can be convinced of $E$'s (and $S$') compliance without having access to $S$ and not make it confidential to other parties.

Perhaps one interesting addition to the protocol would be a \emph{certificate of origin} provided by Alice. In the current version of the protocol, Bob can verify that $E$ meets the expected regulatory properties, but the protocol does not have any mechanism to tie $E$ and $S$ to Alice. Of course, Bob might be satisfied that $E$ complies with $P$ alone, regardless of who the author of $E$ or $S$ is. However, Bob could also demand to know their author so that he can later raise a dispute related to $E$ against its author, for instance. To satisfy this demand, the protocol could be extended with an extra step by which Alice generates an origin certificate (\OC{}) containing the $h(S)$ and $E$, and cryptographically signed by its private key $A_{\pv{}}$ - the public counterpart $A_{\pb{}}$ of which is known to Bob. This certificate attests Alice's authorship and can be verified by Bob using $A_{\pb{}}$. This certificate together with $h(S)$ in $\CC{}$ commits Alice to the source code used in \tcpa. Thus, she cannot claim a different source code was used by the protocol in a possible dispute resolution process.

Note that, as the platform owner/TEE host, Bob has unrestricted access to the messages transiting between Alice and $\TCPAIC{}(X,B,P)$, and to the platform and TEE running this isolated computation, and yet he is unable to learn anything about the source code $S$ apart from its compliance status with respect to properties $P$ and that it gives rise to executable $E$. He does not have access to the source code when sent by Alice to $\TCPAIC{}(X,B,P)$ as the negotiated symmetric key $T$ is not known to him, and the TEE managing the execution and isolation of $\TCPAIC{}(X,B,P)$ prevents him from accessing this secret when its compliance analysis is being carried out.

Regulators may also impose restrictions on the verification framework $X$ used to verify whether $S$ meets $P$. They could, for instance, have a list of approved frameworks, and expect only those to be used in the context of $\TCPAIC{}$. The measurement of $\TCPAIC{}(X,B,P)$ - which depends on $X$, $B$, and $P$ - can be used to show that an approved framework has been indeed used. A party using our protocol ought to be able to independently calculate the measurement of $\TCPAIC{}(X,B,P)$, given $X$, $B$, and $P$, for the sake of confirming it is interacting with the appropriate isolated computation in the process of remote attestation. Therefore, it can use this trusted measurement to test if a given framework $X'$ was used and, then, check whether $X'$ is in the list of approved frameworks. More sophisticated procedures could be devised to ensure a given verification framework meets the norms of a regulator, including having its code verified for some properties using perhaps its own separate $\TCPAIC{}$ instantiation for that.

It is worth mentioning that verification frameworks can be non-deterministic, that is, for some frameworks, two executions checking the same system and property can give rise to different verification outcomes. The parties relying on our protocol must keep this sort of behaviour in mind as it can be maliciously exploited. Let us say, for instance, that a verification framework in very rare occasions fail to report that a property is violated, returning that it was unable to assert the property instead, and let us assume that this sort of \emph{unknown} result is good enough to pass some regulation. This sort of behaviour could be explained, for instance, if we had a verifier $X'$ that has a constraint on the number of states it can examine, and so, for a given input system $S'$, a large randomly-selected portion of its state space can be analysed but not all of it. In such a case, a malicious party could re-analyse $S'$ using our protocol until $X'$ misses the small fraction of states of $S'$ that witness the violation. Thus, the consumer $B$ might then need to know that the \tcpa analysis is instigated by someone he trusts such as $B$ himself - as it is in the detailed protocol we have set out. 
Program analysis typically produces reports in addition to a yes/no/unknown result. In \tcpa, the form of a report, \eg, 
an exception leading to a counter example, may need to be withheld from the software customer because it gives away details of 
the confidential sources.

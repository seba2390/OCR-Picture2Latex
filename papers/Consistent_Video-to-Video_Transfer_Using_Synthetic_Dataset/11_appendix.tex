\appendix
\section*{\centering Supplementary of Coherent Video-to-Video Transfer Using Synthetic Datasets}
\section{Instruction For Zero-shot MPT Data Generation:}\label{sec:appendix_mpt}

The instruction for MPT comprises three parts. The first is the task description which delineates the objectives for the bot.


\begin{Verbatim}[breaklines=true]
You are a bot to generate synthetic text data for generating video clip. You will creatively generate paired prompt triplet for synthetic data generation for video clip. You will be given an input prompt and you should return the edit prompt and output prompt. The output prompt reflects the sentence after applying edit prompt on the input prompt. Ensure that the prompt are proper for generating video clip (i.e. prompt should describe a scene).

Successful editing do changing the main subject, modifying the context or setting or altering the artistic style. 

Here are some examples of editing that are likely to success (do not limit to the verb used in the follow. You must be creative and the editing should be diverse):

Edit of Landscape:
Edit: Convert the cityscape to a seascape.
Edit: Turn the desert scene into a lush forest.

Replacement of Characters:
Edit: Replace the cowboys with astronauts.
Edit: Turn the group of children into a group of elderly people.

Edit of Time:
Edit: Switch the night scene to a day scene.
Edit: Transform the contemporary setting into a medieval setting.

Addition of Significant Elements:
Edit: Add a full moon to the clear sky.
Edit: Include a rainbow in the cloudy scene.

Edit of Weather or Season:
Edit: Make the sunny day into a snowfall.
Edit: Transform the summer scene into autumn.

Edit the Action or Activity:
Edit: Change the soccer game to a ballet performance.
Edit: Replace the cooking scene with a gardening scene.

Edit of Artistic Style:
Edit: Make it look like a watercolor painting.
Edit: It is now in the style of Van Gogh. (do not only use Van Gogh)

\end{Verbatim}

The subsequent phase of the instruction involves presenting MPT with five randomly selected examples from the LAION-IPTP dataset. These samples have been previously successful in generating paired prompts that meet the CLIP filter criteria. The depiction below illustrates this process:

\begin{Verbatim}[breaklines=true]
Here are some success examples (please be creative and not limited to examples)

Input: Graham Wands - George Square, Glasgow, watercolour
Edit: Turn the watercolour into a pencil sketch
Output: Graham Wands - George Square, Glasgow, pencil sketch

Input: Pierre de Clausade, (French, 1910-1976), Winter at the Lake
Edit: make it a sunset
Output: Pierre de Clausade, (French, 1910-1976), Sunset at the Lake

Input: Rex Beanland, Charing Cross, watercolour, 9 12
Edit: make it an oil painting
Output: Rex Beanland, Charing Cross, oil painting, 9 12

Input: Mark Van Crombrugge, Old Milk Bottle and Grapes, oil, 31 x 59.
Edit: Make the bottle transparent.
Output: Mark Van Crombrugge, Transparent Old Milk Bottle, oil, 31 x 59.

Input: """Large Original Oil painting on canvas. Beautiful portrait of a woman 24x24"""""""
Edit: make the woman a cat
Output: """Large Original Oil painting on canvas. Beautiful portrait of a cat 24x24""""

\end{Verbatim}


Finally, MPT is provided with video captions from the WebVid dataset that are designated for processing. This marks the initiation of the generation process for novel, paired prompts.

\begin{Verbatim}[breaklines=true]
Generate triplet for following inputs:

Merida, mexico - may 23, 2017: tourists are walking on a roadside near catholic church in the street of mexico at sunny summer day.

Fun clown - 3d animation

Happy family using laptop on bed at home

11th march 2017. nakhon pathom, thailand. devotees goes into a trance at the wai khru ceremony at wat bang phra temple. what bang phra is famous for its magically charged tattoos and amulets.

Decorate with pineapple sweet cake roll.

Beautiful lake aerial view

Frankfurt, germany-circa 2013:traffic with skyscrapers in background at night along the river main in frankfurt, time lapse

Young positive couple laughing in the backyard in front of the large house under falling snow. bearded man and attractive woman in warm clothes have winter fun. the guy showing thumb up

Broadcast twinkling squared diamonds, multi color, abstract, loopable, 4k

Wheat harvesting. combine harvester gathers the wheat crop on the field.
\end{Verbatim}

\section{Visualization of Synthetic Video Dataset}\label{sec.appendix_synthetic_vid}
In \Cref{sec.synthetic_data_pipe}, we introduce a pipeline designed to produce synthetic paired videos. Further visual demonstrations of these results can be found in \Cref{fig.synthetic_vid1,fig.synthetic_vid2}. The generated paired videos maintain a similar structure, and the editing can showcase the edit prompt.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figs/cat2dog.png}
    \includegraphics[width=\linewidth]{figs/frog2turtle.png}
    \caption{Visualization of synthetic samples produced by the data generation pipeline in \Cref{sec.synthetic_data_pipe}. Each sample contains two generated videos: the upper one represents the input prompt, while the lower one depicts the output prompt. The actual videos comprise 16 frames while 6 subsampled frames are displayed here for brevity.}
    \label{fig.synthetic_vid1}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figs/lion2dragon.png}
    \includegraphics[width=\linewidth]{figs/pinkflower2sunflower.png}
    \includegraphics[width=\linewidth]{figs/pizza2sushi.png}
    \caption{Visualization of synthetic samples produced by the data generation pipeline in \Cref{sec.synthetic_data_pipe}. Each sample contains two generated videos: the upper one represents the input prompt, while the lower one depicts the output prompt. The actual videos comprise 16 frames while 6 subsampled frames are displayed here for brevity.}
    \label{fig.synthetic_vid2}
\end{figure}

% \section{Long Video Sampling Detail Illustration and Examples}\label{sec.long_vid_editing_appendix}

% In~\Cref{sec.long_vid_editing}, we discussed the challenge of maintaining consistency between different batches when sampling long videos, especially when each batch is processed in isolation. In this section, we 
% provide an illustration of how the reference latents interacts with the subsequent latents in \Cref{fig.lvsc_detail}. there will be $N$ overlapping frames of reference between two consecutive batches while this is not a mere slide window approach as we are using the reference frames to instruct how the subsequent frames should look like during editing, instead of giving editing model freedom to arbitrarily conduct transfer that satisfies the editing instruction. 
% we also illustrate a visual comparison between the application of the proposed Long Video Sampling Correction (LVSC) and the absence of such correction. \Cref{fig.long_vid_sampling} delineates the results of both utilizing and omitting LVSC. It is evident from the comparison that, without LVSC, the sampled frames between two consecutive batches lack consistency. Conversely, with the application of LVSC, there is a marked consistency between the first frame in the second batch and the last frame in the preceding batch.

\section{Long Video Sampling Detail Illustration and Examples}\label{sec.long_vid_editing_appendix}
In Section \ref{sec.long_vid_editing}, we addressed the challenge of ensuring consistency across different batches when sampling long videos, particularly when each batch is processed separately. This section introduces an illustrative explanation of the Long Video Sampling Correction (LVSC) method in Figure \ref{fig.lvsc_detail}. In LVSC, there are $N$ overlapping reference frames between two consecutive batches, but this method transcends a basic sliding window technique. Instead of allowing the editing model unrestricted freedom in transferring edits, the reference frames guide the appearance of subsequent frames during the editing process.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figs/LVSC_detail_illustration.pdf}
    \caption{Schematic of Long Video Sampling Correction (LVSC) mechanism. The diagram illustrates the interaction between reference latents from a preceding batch and subsequent latents during the denoising process. The closed-form inferred noise (\Cref{eq.1}) is computed for the $N$ reference latents (shown in blue), which then guides the correction of the actual denoised subsequent latents (shown in orange).}
    \label{fig.lvsc_detail}
\end{figure}

Additionally, we present a visual comparison to demonstrate the impact of LVSC. Figure \ref{fig.long_vid_sampling} contrasts the results with and without LVSC implementation. This comparison clearly shows the lack of continuity in the sampled frames between batches when LVSC is not applied. In contrast, employing LVSC achieves noticeable consistency, aligning the first frame of a subsequent batch with the last frame of the previous batch.


\begin{figure}
    \centering
    Edit Prompt: Change the watermelon to hamburger.
    \includegraphics[width=\linewidth]{figs/long_vid_sample.pdf}
    \caption{In the process of video sampling, we utilize a batch size of 16. The 17th to 28th frames in the video are processed in the second batch, and they reference the last four sampled frames from the preceding batch. By employing the Long Video Sampling Correction (LVSC), we can ensure the content consistency between sampled frames across different batches (green boxes in the figure). In contrast, sampling two batches separately may lead to inconsistencies at the boundaries where the batches change  (rex boxes in the figure).}
    \label{fig.long_vid_sampling}
\end{figure}

\section{Effect of Motion Compensation in Long Video Sampling Correction}\label{sec.motion_compensation}
In our experiments, we observed that the presence of holistic camera motion could degrade the transfer results of subsequent batches processed by the LVSC model (see red boxes in \Cref{fig.motion_compensation}). This degradation arises because the same regions across different frames require consistent score corrections. In other words, score corrections should ``travel'' with the regions affected by camera movement, ensuring that identical corrections are applied to the same areas regardless of motion. To address this issue, we introduce a motion compensation strategy. Specifically, we first employ the RAFT flow estimator~\cite{teed2020raft} to compute the optical flow between each reference frame and the remaining frames in subsequent batches. The original equation for LVSC (\Cref{eq.lvsc}) is then modified as follows:
\begin{align}
\tilde{\varepsilon_\theta}(z_t)[:, m] &= \varepsilon_\theta(z_t)[:, m] + (\frac{1}{N} \sum_{i=1}^N o(\varepsilon_t^{ref}[:, i]), i \rightarrow m) - \varepsilon_\theta(z_t)[:, m]
\end{align}

Here, $m=[1, 2, ..., M]$ represents the indices of frames in the subsequent batches, which contain a total of $M$ frames, $o(\cdot, i \rightarrow m)$ is a warping function that uses optical flow to align the $i$-th reference frame with the $m$-th frame in the subsequent batch. This modification ensures better transfer quality by making the score corrections to be aware of camera movement. The green boxes in \Cref{fig.motion_compensation} reveal that applying motion compensation significantly enhances content consistency and overall quality. This improvement is particularly noticeable in the last few frames of the subsequent batches.

\begin{figure}
    \centering
    Edit Prompt: Make it Van Gogh Starry Night style.
    \includegraphics[width=\linewidth]{figs/motion_compensation.pdf}
    \caption{When the video exhibits extensive camera motion, the LVSC model without motion compensation (LVSC without MC) suffers significant quality degradation, particularly in frames from subsequent batches (red boxes in the figure). Incorporating motion compensation (LVSC with MC) substantially improves frame consistency with the reference and maintains high transfer quality, even when the camera view changes dramatically in later batches (green boxes in the figure). }
    \label{fig.motion_compensation}
\end{figure}

\section{Effect of Sampling Hyperparameters and Picking Criteria}\label{sec.pick_criteria}
In our experiments, we observed that the video CFG and resolution have a greater impact on the generated video than the text CFG. To streamline the parameter search process, we thus focus solely on picking the video CFG and resolution, effectively reducing the search space. Detailed visual effects of the hyperparameter choices are provided in \Cref{fig.pickscore_sample}. We opt for PickScore~\cite{kirstain2023pick} as our automated selection criterion. Our choice is motivated by the fact that PickScore aligns more closely with human perception compared to the CLIP score, as indicated in \cite{kirstain2023pick}.

\begin{figure}
    \centering
    Edit Prompt: Make the rabbit robotic.
    \includegraphics[width=\linewidth]{figs/pickscore_sample.pdf}
    \caption{During sampling, the interplay between the scale of image classifier-free guidance (CFG) and image size can significantly influence the transfer result. In our evaluation, we sample videos by employing various combinations of CFG scales and resolutions, utilizing the average PickScore across all frames as the selection metric. The video with the highest PickScore is designated as the final transfer result. As indicated by the green box in the figure, the chosen video and its corresponding hyperparameters bear the highest PickScore, thereby making it the final selection.}
    \label{fig.pickscore_sample}
\end{figure}

\section{Qualitative Comparisons}\label{sec.qualitative_comparison}
We provide qualitative comparisons with baselines in ~\Cref{fig.additional_qua1,fig.additional_qua2,fig.additional_qua3,fig.additional_qua4,fig.additional_qua5,fig.additional_qua6,fig.additional_qua7,fig.additional_qua8,fig.additional_qua9}
\begin{figure}
    \centering
    
    \includegraphics[width=\linewidth]{figs/qualitative/swans_object.jpg}
    \caption{\textbf{Swans} gliding over a lake. $\rightarrow$ \textbf{Pink flamengos} gliding over a lake.}\label{fig.additional_qua1}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figs/qualitative/cat-dog-play_multiple.jpg}
    \caption{A cat and a dog playing on the street while a girl walks around them. \\ $\rightarrow$ A cat and a dog playing on the beach while a girl walks around them, \textbf{golden hour lighting}.}\label{fig.additional_qua2}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figs/qualitative/cat-in-the-sun_object.jpg}
    \caption{A \textbf{cat} in the grass in the sun. $\rightarrow$ A \textbf{dog} in the grass in the sun.}\label{fig.additional_qua3}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figs/qualitative/earth-full-view_background.jpg}
    \caption{Full view of the Earth as it moves slowly \textbf{toward the sun}. \\ $\rightarrow$ Full view of the Earth as it moves slowly \textbf{through a fireworks display.}}\label{fig.additional_qua4}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figs/qualitative/gold-fish_background.jpg}
    \caption{Several goldfish swim in a \textbf{tank}. \\ $\rightarrow$ Several goldfish swim in a \textbf{pond}.}
    \label{fig.additional_qua5}
    
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figs/qualitative/red-roses-sunny-day_style.jpg}
    \caption{A static shot of red roses in sunlight, gently swaying in the breeze. \\ $\rightarrow$ A static shot of red roses in sunlight, gently swaying in the breeze, \textbf{origami style}.}
    \label{fig.additional_qua6}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figs/qualitative/aircraft-landing_multiple.jpg}
    \caption{A Delta Airlines aircraft descends onto the runaway during a cloudless morning. \\ $\rightarrow$ A \textbf{brightly colored cyberpunk aircraft} descends onto the runway during a cloudless morning, \textbf{with a bustling cityscape in the background}.}
    \label{fig.additional_qua7}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figs/qualitative/ship-sailing_background.jpg}
    \caption{A ship sails on the \textbf{sea}. \\ $\rightarrow$ A ship sails on the \textbf{lunar surface}.}
    \label{fig.additional_qua8}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figs/qualitative/fireworks-display_style.jpg}
    \caption{A colourful fireworks display in the night sky. \\ $\rightarrow$ A colourful fireworks display in the night sky, \textbf{8-bit pixelated}.}
    \label{fig.additional_qua9}
\end{figure}

\section{Failure Cases}
Our model, \ours, occasionally encounters challenges in video transfer, particularly when the object of interest is difficult to detect. Such difficulties arise when the object is positioned close to the video's edge, is unusually small or large, or is partially obscured. These scenarios can lead to the object either vanishing in the edited video or exhibiting inconsistent appearances.

For instance, as depicted in \Cref{fig.failure1}, when a person is situated near the frame's border and occupies a small area, \ours\ struggles to maintain the person's structural integrity, resulting in their disappearance from the transferred video. However, when the person moves away from the border, \ours\ can recognize them again, but with a notably altered appearance.

\Cref{fig.failure2} presents another scenario where the object, in this case, the front part of a truck, is only partially visible in certain frames. While \ours\ can accurately transfer the image when the truck is fully visible, it misinterprets the partially visible truck as a car's front, leading to inconsistent results in the transferred video.

In summary, when object detection is hindered due to size, positioning, or occlusion, \ours\ may not deliver satisfactory transfer results.

\begin{figure}
    \centering
    Prompt: Change background to tropical river.
    \includegraphics[width=\linewidth]{figs/failuer_case1.pdf}
    \caption{Illustration of a failure case where \ours\ struggles to maintain the structure of a person located near the video's edge and occupying a small area, resulting in the disappearance of the person from the transferred video.}
    \label{fig.failure1}
\end{figure}

\begin{figure}
    \centering
    Prompt: Make trucks made of wood (wooden style truck).
    \includegraphics[width=\linewidth]{figs/failure_case2.pdf}
    \caption{Demonstration of a failure scenario in \ours\ where a partially visible truck is misidentified as a car's front, leading to inconsistent transfer results in the edited video.}
    \label{fig.failure2}
\end{figure}

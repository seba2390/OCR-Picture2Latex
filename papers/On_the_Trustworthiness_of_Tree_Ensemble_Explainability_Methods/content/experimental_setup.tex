%Trustworthy explanations are the ones reflective of real patterns in the world the explanations to be reflective of real patterns in the world, then we 
%Data is collected from the world with finite precision, and we should allow for that by ensuring that the uncertainty in- volved in those measurements does not drastically affect the decisions we make. However, it appears that this uncertainty could drastically affect the explanations we use to explain our results, if we use LIME or Shapley values.
%As suggested by~\cite{hancox2020robustness}, trustworthy explanations reflective of real patterns in the world are the ones that remain correlated over a set of equally well-performing models. 


%As suggested by~\cite{hancox2020robustness}, if we expect the explanations to be reflective of real patterns in the world, then we expect them to remain consistent over a set of equally well-performing models (i.e., models with similar input-output mappings). Moreover, reliable explanations should also remain consistent with slight perturbations in the input data as discussed in~\cite{alvarez2018robustness}.
% To give a reliable global feature importance to the user, feature importances of models trained under different settings should still be correlated, especially when the performance of both models are quite comparable and the models have reached convergence.
% Both models under different settings should still be able to identify the same important features and a lack of stable feature importances can cause lack of trust with the user.
%To simulate this situation, we evaluate the stability of global feature importances under the following two scenarios:
% ========================================================

\vspace{-.2cm}
\section{Experimental Setup} \label{sec:exp_setup}
\vspace{-.2cm}
In this section we describe the setup we use to evaluate the accuracy and stability of global feature importance methods.
%We measure the accuracy and stability of global feature importance methods using the following setup. 

% In our experiments, we would like to assess the accuracy and stability of feature importances. To assess accuracy, we simulate data such that the true coefficients are known, and assess how accurate the ordering of top features are based on feature importances, as well as whether the overall importances are correlated with the true coefficients. We also assess the accuracy of feature importances when the input values are perturbed, simulating real-world settings where noisy data is present.

\paragraph{Datasets.} To thoroughly evaluate the accuracy and stability of global feature importances, we conduct our experiments on synthetic data as well as four real-world datasets from various domains.

% are the numerical features drawn i.i.d.? Are the components of the weight vector sampled i.i.d. from a Gaussian? Moreover, how are the categorical features sampled?
For synthetic data, we generate 300 training samples with varying number of features (5, 10, 25, 100, and 150 features). %from a normal distribution with randomized mean and standard deviation. 
We randomly set the features to be either continuous or categorical (each with equal probability). For continuous features, we sample from a uniform distribution between $[0, 1)$. For categorical features, we first randomly sample values like continuous features and we then binarize them based on an independently-sampled threshold selected from $[0, 1)$. Lastly, to obtain the target values, we sum the multiplication of each feature by a randomized set of coefficients (sampled independently per feature between -10 to 10). Then, we categorize the summation values to 1 for values greater than the median and 0 otherwise. 

We use the following four real-world datasets in addition to the synthetic data for our stability assessments:
\begin{enumerate}
    \item Forest Fire: prediction of the amount of burned area resulted from forest fires in the northeast region of Portugal, by using meteorological data, such as coordinates, time, wind, rain, relative humidity, etc. \cite{cortez2007data}.
    \item Concrete: prediction of concrete compressive strength given material types, composition, and age \cite{yeh1998modeling}.
    \item Auto MPG: prediction of fuel consumption in miles per gallon (MPG) of cars in the city given its model, horsepower, etc. \cite{quinlan1993combining}
    \item Company Finance\footnote{This dataset is confidential and the details of it cannot be shared.}: prediction of whether companies would make a good investment based on their finances.
\end{enumerate}

All datasets except the Company Finance dataset (our proprietary dataset) come from the UCI ML data repository~\cite{Dua:2019} and are parsed with the py\_uci package~\cite{skafte_2019}. A summary of these datasets is shown in Table \ref{tab:dataset}. 
                        
\begin{table}
 \centering
  \caption{Description of datasets used in this study.}
  \label{tab:dataset}
  \scriptsize
  \begin{tabular}{ccccc}
    \toprule
    Dataset & Domain & Task Type & \# Samples & \# Features \\
    \midrule
    Synthetic Data & & Classification & 300 & 5-150 \\
    Forest Fire & Meteorology & Regression & 517 & 12 \\
    Concrete & Civil & Regression & 1030 & 8 \\
    Auto MPG & Automotive & Regression & 406 & 7 \\
    Company Finance & Finance & Classification & 2716 & 892 \\
  \bottomrule
\end{tabular}
\end{table}

\paragraph{Experimental Settings.}
In our experiments, we use random forest and gradient boosting machine implemented by sklearn package~\cite{scikit-learn}, as well as XGBoost, an implementation of gradient boosting that uses second-order gradients and has a faster runtime~\cite{Chen:2016:XST:2939672.2939785}. For each of these models, we run the following experiments:
\begin{enumerate}
    \item Input perturbation: where the input data are perturbed by adding different levels of noise. Noise is sampled randomly from a normal distribution with mean 0 and standard deviation of:
    \begin{enumerate*}
        \item half of the original feature's standard deviation for low noise
        \item the original feature's standard deviation for medium noise
        \item double of the original feature's standard deviation for high noise.
    \end{enumerate*}
    \item Model perturbation: where the model is perturbed by \begin{enumerate*}
        \item initializing with a different random seed without hyperparameter tuning, or
        \item optimizing hyperparameters~\cite{bergstra2013making} (e.g., number of trees, depth of trees, etc.) with a different random seed.
    \end{enumerate*} In these experiments, we ensure that the predictions of the two models (the original model and the perturbed model) have high correlations, such that of discrepancies in predictions affect the analysis minimally. %A summary of these experiments can be found in Table \ref{tab:diff_seeds_training_setting}.
\end{enumerate}

We iterate all experiments 50 times with a different random seed, except for the Company Finance dataset. For this dataset, we run the experiments 5 times due to long training time caused by the high number of features. In each iteration of input perturbation experiment, we train two models, one with the original setting (e.g., unperturbed input data) and another with the perturbed setting (e.g., noised input data). In model perturbation experiments, we also train two models in each iteration where we change the random seed of the second model to be different than the first model. For each trained model, we compute gain and SHAP feature importances as described in Section \ref{sec:background}. 

% \begin{table}
%   \centering
%   \caption{Summary of model perturbation experiments.}
%   \label{tab:diff_seeds_training_setting}
%   \scriptsize
%   \begin{tabular}{cc}
%     \toprule
%     Model & Optimize hyperparameter?  \\
%     \midrule
%     XGBoost & Yes  \\
%     XGBoost & No \\
%     Gradient Boosting Machine & Yes \\
%     Gradient Boosting Machine & No \\
%     Random Forest & Yes \\
%     Random Forest & No \\
%   \bottomrule
% \end{tabular}
% \end{table}

\paragraph{Accuracy Metrics.}
To evaluate the accuracy of global feature importances, we use simulated data so that the true coefficients (importances) are known. The features are ranked based on the magnitude of their corresponding coefficients used during data generation. %Having access to true coefficients, we then measure how accurate the ranking of top features are. We also measure the correlation of feature importances with the true coefficients to get a sense of accuracy across all features.
% \textcolor{red}{One of the most important attributes of feature importance is how well it captures the true underlying relationship of the input data. With synthetic data, we have access to the underlying feature importances that are usually hidden in real-world datasets. Through this, we examine how often gain and SHAP feature importances correctly rank top features.}
% We also assess the accuracy of feature importances when the input values are perturbed, simulating real-world settings where noisy data is present. 
We examine the accuracy under the following scenarios: \begin{enumerate*}
    \item when no noise is added to the input, and
    \item when different level of noise is added to the input.
\end{enumerate*}
%For each iteration, the model has its hyperparameter settings optimized. 
We do not consider the model perturbation scenario for this analysis as we are mainly interested in measuring the accuracy of the model's feature importances to the true coefficients.

We evaluate the accuracy of the top features' ranking in the following way:
\begin{itemize}
    \item First, we rank features based on their coefficients' magnitude, largest magnitude being the most important. Since all features are uniformly sampled from $[0, 1)$, we assume the coefficients' magnitude represent the importances. 
    \item Second, we assess whether these top features are ranked correctly with gain and SHAP feature importances. 
    \item Finally, we count the number of times each top feature is ranked correctly by gain or SHAP feature importances across multiple iterations. If it is ranked incorrectly, there are 2 possible situations: \begin{enumerate*}
        \item The feature is still considered a top feature by gain or SHAP feature importances,
        \item The feature is not considered a top feature by gain or SHAP feature importances.
    \end{enumerate*}
    We present this count proportionally across the 3 groups (correct, incorrect\_but\_top, and incorrect) to compare the accuracy of these models on different levels.
\end{itemize} 
Furthermore, to get a sense of feature importances' accuracy across all features, we evaluate the Spearman correlation of gain and SHAP feature importances compared to the coefficients.

\paragraph{Stability Metrics.}
%In addition to the noise introduced by the limited precision of the input data, in real-world settings models are often trained on different random seeds and hyperparameter settings. To simulate the aforementioned situations, we evaluate the stability of global feature importances under the following two scenarios:
To evaluate the stability of global feature importances, we consider the following two scenarios:
\begin{enumerate*}
    \item when different levels of noise is added to the input.
    \item when models are perturbed by initializing with different random seeds and different hyperparameter settings.
\end{enumerate*}
We use Spearman correlation to compare feature importances calculated from the 2 models (one unperturbed and the other perturbed), because it is distribution-free unlike parametric tests (e.g., Pearson correlation)~\cite{zwillinger1999crc}. We also report both the Spearman and Pearson correlations between the predicted outputs of the two models trained in each iteration as a sanity check to ensure similar performance.
% To compare the stability of feature importances, we calculate the Spearman correlation of feature importances. We chose Spearman correlation, because it captures the ordering of the values without making any assumption about their distribution, compared to Pearson correlation that captures the linear relationship of the values assuming they are normally distributed \cite{zwillinger1999crc}. 
% We also report the Spearman correlation between the predicted outputs of the two models trained in each iteration as a sanity check to ensure they have similar performance. 

%In Section \ref{sec:results}, we dive into how these correlations change across gain and SHAP feature importances. 
%To ensure that these models have similar predictions and that any differences of the feature importances resulted from the model perturbations, we also report the Spearman correlation of the predicted outputs of the 2 models per iteration.



%\textcolor{blue}{Based on the magnitude of these coefficients, we are able to rank features and assess whether gain and SHAP feature importances rank these features as top features as well. We then can compare the proportion of gain and SHAP feature importances ranking the top features correctly across the simulations iterations. We report the proportion of feature ranks being correct, slightly incorrectly ranked but close (as it's still in the top features), or completely incorrectly ranked.}

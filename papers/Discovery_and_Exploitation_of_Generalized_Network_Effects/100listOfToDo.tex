
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% AUTHOR: Christos Faloutsos
% INSTITUTION: CMU
% DATE: April 2019
% GOAL: to streamline the paper presentations
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% \todototoc
% \listoftodos

Reviewer 4

Questions
1. Does the paper make novel contributions to data science research (methodology, process, evaluation, systems, and so on)?
Neutral
2. Is the paper properly contextualized, i.e., does the proposed work makes a nontrivial advance over relevant related work?
Disagree
3. If the authors have identified the paper as an Application to Social Good or Data Science and Society from the Subject Areas, please select from the following options. Please use your evaluation on the basis of the following criteria: compelling problem statement at the interface of data science and society, demonstrable stakeholder engagement, interdisciplinary, and demonstrable societal impact (validated or deployed).
N/A
4. Please provide justification for your response to Question 3.
N/A
5. Are the most important claims of the paper justified based on theoretical contribution(s) or experimental validation?
Neutral
6. Is the presentation of the paper (organization, writing style, formatting etc.) consistent with the high and well established SIGKDD standards?
Agree
7. Please use this space to provide detailed feedback to the authors and justify your selection to the above questions. Please provide at least one paragraph of justification per question.
This paper aims to infer node labels accurately given a graph with a few labeled nodes and without node attributes while being scalable, principled, and automatic. To handle neighbor-differentiation, the authors proposed “emphasis” matrix with weighted edges estimated by similarity functions. In network effect analysis, the authors uses Fisher’s exact test to evaluate the existence of network-effect, then estimate the compatibility matrix. The calculation of the final belief follows the standard linear BP.

The paper is theoretically logical and well-organized overall. The authors proposed to solve the target problem from two insights in Section 3 and 4 then presented overall algorithm of the proposed UltraProp in Section 5. The authors also provided complete theoretical proof for lemmas. Extensive experiments are conducted on four million-scale graph datasets to evaluate the performance of the proposed method.

However, the paper still has several limitations and weaknesses.

First, the authors proposed “emphasis” matrix with weighted edges estimated by similarity function S. The authors use the Euclidean distance in S. Various pairwise proximity functions can evaluate the similarity between two nodes. Does the Euclidean distance have specific properties under the setting in this paper compared to other popular ones (e.g., the cosine similarity)?

Secondly, according to the results in Table 3, 4 and 5, the proposed UltraProp achieves obviously higher accuracy on heterophily datasets but not on homophily datasets compared to LinBP (1.2% accuracy improvement at most in Table 3). On the other hand, LinBP has apparently smaller running time than the proposed methods. The performance makes the proposed method less convincing.

Finally, some minor problems include a) the estimated errors from line 385 to 389 are incorrect. According to the upper bounds from Lemma 1 and Lemma 2, the error using regular random walks should not be 2x as that using non-backtracking random walks. b) $X_(n×d)$ is denoted as the node embedding in Table 2; another definition in line 530 of $X_(m×n)$ is confusing. c) M=30 and L=4 are fixed values in Algorithm 1. I think they should be hyperparameters which can be adjusted in the proposed method.
8. Please make a recommendation regarding acceptance of the paper.
Weak Reject

Reviewer 5

Questions
1. Does the paper make novel contributions to data science research (methodology, process, evaluation, systems, and so on)?
Neutral
2. Is the paper properly contextualized, i.e., does the proposed work makes a nontrivial advance over relevant related work?
Neutral
3. If the authors have identified the paper as an Application to Social Good or Data Science and Society from the Subject Areas, please select from the following options. Please use your evaluation on the basis of the following criteria: compelling problem statement at the interface of data science and society, demonstrable stakeholder engagement, interdisciplinary, and demonstrable societal impact (validated or deployed).
No
4. Please provide justification for your response to Question 3.
N/A
5. Are the most important claims of the paper justified based on theoretical contribution(s) or experimental validation?
Neutral
6. Is the presentation of the paper (organization, writing style, formatting etc.) consistent with the high and well established SIGKDD standards?
Agree
7. Please use this space to provide detailed feedback to the authors and justify your selection to the above questions. Please provide at least one paragraph of justification per question.
This paper proposes a label prediction approach for undirected and unweighted graph without attributes. Its computes embeddings of nodes by using random walks and SVD to compute the emphasis matrix. It then computes the compatibility matrix by using Fisher’s exact test. It obtains the belief matrix from the emphasis matrix and the compatibility matrix. Using real datasets, this paper conducts experiments to show the effectiveness of the proposed approach.

I like the paper's motivation; it is quite a fundamental research problem to improve the effectiveness of label prediction. Besides, this paper is well structured, and easy to follow.

Although this paper says that the proposed approach has no parameters for the user to tune, it is clear that the number of steps L, number of random walks trials M, and the number of dimensions of the embedding d have large impacts for the effectiveness and efficiency of the proposed approach. The paper should show the impacts of these parameter for the proposed approach in the experiments.

If a graph has small diameter, matrix W yielded in Algorithm 1 would be dense. In that case, since the size of W is n times n, it is impractical to hold the dense matrix W; it is difficult to run the proposed approach by using stock machines. Since the number of nonzero elments is relatively large, the computation cost of the proposed approach is not so efficient. In fact, as shown in Table 3, 4, and 5, the proposes approach is slower than the previous belief propagation approach, LinBP.

Since the proposed approach assumes to use graphs without node attributes, it is natural to compare the proposed approach to the following recent embedding methods;

- NetSMF: Large-Scale Network Embedding as Sparse Matrix Factorization. WWW 2019
- LightNE: A Lightweight Graph Processing System for Network Embedding. SIGMOD 2021:
- FREDE: Anytime Graph Embeddings. VLDB 2021
- REFINE: Random RangE FInder for Network Embedding. CIKM 2021
8. Please make a recommendation regarding acceptance of the paper.
Strong Reject

Reviewer 6

Questions
1. Does the paper make novel contributions to data science research (methodology, process, evaluation, systems, and so on)?
Neutral
2. Is the paper properly contextualized, i.e., does the proposed work makes a nontrivial advance over relevant related work?
Neutral
3. If the authors have identified the paper as an Application to Social Good or Data Science and Society from the Subject Areas, please select from the following options. Please use your evaluation on the basis of the following criteria: compelling problem statement at the interface of data science and society, demonstrable stakeholder engagement, interdisciplinary, and demonstrable societal impact (validated or deployed).
N/A
4. Please provide justification for your response to Question 3.
Not applicable.
5. Are the most important claims of the paper justified based on theoretical contribution(s) or experimental validation?
Agree
6. Is the presentation of the paper (organization, writing style, formatting etc.) consistent with the high and well established SIGKDD standards?
Neutral
7. Please use this space to provide detailed feedback to the authors and justify your selection to the above questions. Please provide at least one paragraph of justification per question.
This paper discusses about graph semi-supervised learning with undirected and unweighted graphs without node attributes. The authors put forward two intractable challenges within the task and propose the methods to resolve them. The general idea of this paper is clear and well expressed. However, there still exists several problems in the paper. My justification for each question above is listed below:

For Q1: This paper proposes an effective approach for graph semi-supervised learning with undirected and unweighted graphs without node attributes, but the novelty is limited. The new approaches in this paper do not appear to contain exciting new ideas or introduce a new complex model and compared with the existing related work, this paper does not have significant advantages.

For Q2: Based on the experiments conducted by the authors, the proposed method achieves better results than other baselines. However, compared with LINBP, it does not have distinct advantages

For Q3-4: The paper is not identified as an Application to Social Good or Data Science and Society from the Subject Areas.

For Q5: The paper compares its method with eight baselines and
separate them into four groups and fully provide the details of the experiment.
8. Please make a recommendation regarding acceptance of the paper.
Neutral

Reviewer 7

Questions
1. Does the paper make novel contributions to data science research (methodology, process, evaluation, systems, and so on)?
Neutral
2. Is the paper properly contextualized, i.e., does the proposed work makes a nontrivial advance over relevant related work?
Agree
3. If the authors have identified the paper as an Application to Social Good or Data Science and Society from the Subject Areas, please select from the following options. Please use your evaluation on the basis of the following criteria: compelling problem statement at the interface of data science and society, demonstrable stakeholder engagement, interdisciplinary, and demonstrable societal impact (validated or deployed).
N/A
4. Please provide justification for your response to Question 3.
The paper does not qualify for this criteria.
5. Are the most important claims of the paper justified based on theoretical contribution(s) or experimental validation?
Disagree
6. Is the presentation of the paper (organization, writing style, formatting etc.) consistent with the high and well established SIGKDD standards?
Disagree
7. Please use this space to provide detailed feedback to the authors and justify your selection to the above questions. Please provide at least one paragraph of justification per question.
There are many confusing points in this paper:

1. It is unclear to this reviewer what "A matrix “centered around” k has all its entries
close to k and the average of the entries is exactly k"? k is a class. What's the meaning of 'close to k' and 'the average of the entries is exactly k'?

2. In proximity matrix computation, this paper shows that the number of trials for walks will be set to M = 30 and walk length is equal to L = 4 to ensure both the effectiveness and efficiency. Can the paper provide technical proofs or experiments to show the settings can ensure both the effectiveness and efficiency?

3. In equation (5), the meaning of X is unclear. Is the variable X the same as the variable X in line 4 of the algorithm 4?

4. The variable X in the section 4.2 should be different from the variable X in the section 3.2. The X in section 3.2 represents node embedding, but the X in the section should be equal to a result of the Hadamard product. The paper should make this clear.

5. What's the meaning of line 6 in algorithm 3. There is no detailed (clear) explanation about the update of the variable I.

6. It's unclear why the convergence criterion should be lower than the minimum error /frac{1}{lg n c}. How should we obtain the error?

7. In line 9 of algorithm 4, the paper uses scaling factor f. However, the algorithm does not show how to get f. Can we set the f manually or can we calculate the f by some equations? It's unclear.
8. Please make a recommendation regarding acceptance of the paper.
Weak Reject
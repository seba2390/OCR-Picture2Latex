
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% AUTHOR: Christos Faloutsos
% INSTITUTION: CMU
% DATE: April 2019
% GOAL: to streamline the paper presentations
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Given a large, undirected and unweighted graph with a few labeled nodes, how can we infer the labels of remaining unlabeled nodes without node attributes? Graph semi-supervised learning (SSL) is often employed to infer labels on large real-world graphs~\cite{talukdar2009new, kipf2016semi, belkin2004regularization, abu2019mixhop} since these graphs typically contain only a few labeled nodes as labeling is usually expensive. For example, in social networks with millions of users, identifying even a fraction (say $5\%$) of users' groups is prohibitive which limits the application of supervised methods. 

\begin{figure*}[]
\centering
\subfloat[\label{fig:c1} \ndiff]
{\includegraphics[scale=0.46]{FIG/cj1.pdf}}
\rulesep
\subfloat[\label{fig:c2} Compatibility Matrix Estimation]
{\includegraphics[scale=0.46]{FIG/cj2.pdf}}
\rulesep
\subfloat[\label{fig:c3} Scalability]
{\includegraphics[scale=0.46]{FIG/scale.pdf}}
\caption{\label{fig:crown} \underline{\method is \effect, \explain \xspace , and \scale.} (a) Thanks to \ndiff, \method predicts the label of the gray node \textit{X} correctly, while \linbp fails. (b) \method explains the dataset by precisely estimating the compatibility matrix, observing both heterophily and homophily. (c) \method scales linearly with the number of edges.}
\end{figure*}

Traditional label inference problems use belief propagation (BP) as the core of algorithms. Most studies ignore the different influence level of the neighbors for each node, i.e., \ndiff, treating all the neighbors equally so as to fail to predict correctly in more ambiguous cases. Although recent work \cite{eswaran2020higher} solves this by weighting the neighbors with their occurrences in the motifs, searching and counting motifs are computationally expensive.
Owing to the fast development of hardware, there is a surge of research in deep graph models that can be used for label inference recently, improving the accuracy by leveraging various techniques, such as attention.
Many studies \cite{velivckovic2017graph, brody2021attentive} try to learn more than one relationship for each neighborhood relying on the node features, while suffering from poor scalability without GPUs. Even one of the best GPUs fails to afford fitting that huge amount of parameters into memory.

% which are strongly based on the \emph{homophily} of nodes i.e. neighbors are likely to share the same label. 
% all of them suffer from poor scalability without GPUs, and are unamenable to theoretical analysis and guarantees. 

More importantly, instead of solely pursuing accuracy on small benchmark datasets with increasingly complex models, a more comprehensive algorithm should also seek to give users a better understanding about the given datasets. 
However, the importance of investigating \neteffect during label inference is usually downplayed.
BP-based methods assume the compatibility matrix is given by the domain experts \cite{DBLP:journals/pvldb/GatterbauerGKF15}.
Deep graph models either assume the datasets to be homophily \cite{kipf2016semi, wu2019simplifying}, or select the advantageous datasets after analyzing with all the labels \cite{ma2022is, lim2021large}.
In addition, nodes with a certain label may also have no network effect, i.e., the label distributions of their neighbors are all uniform. This is the usual case of easily getting confused with heterophily graphs, where the label distributions should potentially contain some patterns. For example, talkative people tend to get friends with silent ones, then this is heterophily; however, if talkative people are friends of talkative and silent ones equally (which may be the real case), then we are not able to distinguish talkative people easily. Identifying how the labels relate to each other is crucial to understand the datasets.

To address all the aforementioned issues, we raise the problem:
\begin{iprob}
	\hfill
	\begin{itemize}[leftmargin=20pt]
		\item {\bfseries Given} an undirected and unweighted graph
		\bit
			\item with a few labeled nodes,
			\item without node attributes and
		\eit
		\item {\bfseries infer} the labels of all the remaining nodes accurately as well as,
		\bit
			\item {\bfseries explain} to human experts with \neteffect,
			\item {\bfseries estimate} the compatibility matrix,
			\item {\bfseries scale} to million-scale real-world graphs.
		\eit
	\end{itemize}
	%\eit
\end{iprob}

We propose \method, a BP-based method benefitting from both \ndiff and \neteffect analysis to solve SSL on large graphs and provide explanation. 
We provide a much more efficient way to draw attention to those structurally important neighbors by random walk. We derive convergence error of random walk, and further show that we can make it tighter by adopting the idea of non-backtracking. Figure~\ref{fig:c1} shows that \method is accurate as it incorporates \ndiff and predicts correctly --- the central vertex X participates in a closely-knit community with three friends R1, R2 and R3. 
With only few labels, \method is capable of estimating the compatibility matrix precisely based on the closed formula, and supports it by the statistical tests. Figure~\ref{fig:c2} illustrates how \method provides explanation by the estimated compatibility matrix. Given an adjacency matrix and only 5\% of labels, the interrelations of labels are discovered, where one half of them is heterophily, and the other half is homophily.
Figure~\ref{fig:c3} shows that \method scales linearly with the number of edges and runs less than one and half hour on a graph with $50$M edges.

The advantages of \method are:
\bit
\item {\bf \Accurate}, due to \ndiff identifying the different importance of neighbors for each node, as well as thanks to \neteffect analysis,
\item {\bf \explain}, interpreting the dataset with \neteffect analysis and compatibility matrix estimation, 
\item {\bf \thrift \space and \scale}, requiring little computational resources (no GPU), and scaling linearly,
\item {\bf \theory}, providing a tighter bound of convergence error for the random walk, and the closed formula for the compatibility matrix (see Lemma~\ref{lem:crw2} and ~\ref{lem:nef}).
\eit

{\bf Reproducibility}: Our implemented source code and preprocessed datasets are available online\footnote{\codeurl}.

%The rest of the paper is organized as follows. We give the survey in Section~\ref{sec:background}, and then introduce \method in Section~\ref{sec:meth}. The experiments are presented in Section~\ref{sec:exp}. Section~\ref{sec:concl} concludes.

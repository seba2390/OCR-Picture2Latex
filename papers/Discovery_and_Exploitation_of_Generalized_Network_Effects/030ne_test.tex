
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% AUTHOR: Christos Faloutsos
% INSTITUTION: CMU
% DATE: April 2019
% GOAL: to streamline the paper presentations
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure*}[]
	\centering
	\subfloat[\label{fig:dis1} ``Genius'': No \nef]
	{\includegraphics[height=1in]{FIG/ec_genius.pdf}
	 \includegraphics[height=1.03in]{FIG/pt_genius.pdf}}
	 \rulesep
	 \subfloat[\label{fig:dis2} ``Penn94'': No \nef]
	{\includegraphics[height=1in]{FIG/ec_penn94.pdf}
	 \includegraphics[height=1.03in]{FIG/pt_penn94.pdf}}
	 \rulesep
	 \subfloat[\label{fig:dis3} ``Twitch'': No \nef]
	{\includegraphics[height=1in]{FIG/ec_twitch.pdf}
	 \includegraphics[height=1.03in]{FIG/pt_twitch.pdf}} \\
	 \hrule
    \vspace{-3mm}
	 \subfloat[\label{fig:dis4} ``arXiv-Year'': \xophily with Weak \nef]
	{\includegraphics[height=1in]{FIG/ec_arxivyear.pdf}
	 \includegraphics[height=1.03in]{FIG/pt_arxivyear.pdf}}
	 \rulesep
	 \subfloat[\label{fig:dis5} ``Patent-Year'': Heterophily with Weak \nef]
	{\includegraphics[height=1in]{FIG/ec_patentyear1.pdf}
	 \includegraphics[height=1.03in]{FIG/pt_patentyear1.pdf}}
	 \rulesep
	 \subfloat[\label{fig:dis6} ``Pokec-Gender'': Heterophily with Strong \nef]
	{\includegraphics[height=1in]{FIG/ec_pokecgender1.pdf}
	 \includegraphics[height=1.03in]{FIG/pt_pokecgender1.pdf}} \\
    \hrule
    \vspace{-2mm}
    \captionsetup[subfloat]{captionskip=2pt}
    \subfloat[\label{tab:homstat} Homophily statistics of graphs and their \nef.]
    {       
        \setlength{\tabcolsep}{1pt}
        \resizebox{1.6\columnwidth}{!}{
        \begin{tabular}{C{3.8cm} | C{2.3cm} C{2.3cm} C{2.3cm} | C{2.3cm} C{2.3cm} | C{2.3cm} C{2.3cm}}
        \hline
        \textbf{Datasets} & \textbf{Genius} & \textbf{Penn94} & \textbf{Twitch} & \textbf{Patent-Year} & \textbf{Pokec-Gender} & \textbf{arXiv-Year} & \textbf{Synthetic} \\
        \hline
        \# of Nodes / Edges / Classes & 422K / 985K / 2 & 42KM / 1.4M / 2 & 168K / 6.8M / 2 & 1.3M / 4.3M / 5 & 1.6M / 22.3M / 2 & 169K / 1.2M / 5 & 1.2M / 34.0M / 6 \\
        \hline
        Edge Homophily & 0.618 & 0.470 & 0.545 & 0.132 & 0.425 & 0.222 & 0.314 \\
        $\hat{h}$ & 0.080 & 0.046 & 0.090 & 0.000 & 0.000 & 0.272 & 0.245 \\
        \hline
        \nef & No \nef & No \nef & No \nef & Heterophily & Heterophily & \xophily & \xophily \\
        \hline
        \end{tabular}}
    }
    \vspace{-3mm}
	\caption{\label{fig:dis} \underline{\smash{\methodtest works:}} It discovers that real-world heterophily graphs do not necessarily have \nef. For each graph, we report the edge counting on the left (not available in practice), and the $p$-value table output from \methodtest on the right.
    In the $p$-value table, \textcolor{blue}{``P''} denotes the presence of \nef in the class pair, while \textcolor{red}{``F''} denotes the absence of \nef.
    % We also discover a case of \xophily{}, i.e. in ``arXiv-Year'', class $1$ is homophily, and the rest are heterophily.
    }
\end{figure*}

Given a graph with few labels, how can we identify whether the graph has \neteffect (\nef) or not?
In other words, how can we check whether the graph structure is useful for inferring node labels?
% Given a graph with few labels, how can we identify the classes that a node with a specific class connects to?
% Precise estimation on compatibility matrix helps users better interpret the results, 
% In other words, how can we find whether the graph exhibits homophily, heterophily, \xophily, or even none?
% When there is no \nef, it means that the structure is useless to infer labels to the nodes.
% Nevertheless, how to solve this is still challenging.
% While most studies \cite{zhu2020beyond, lim2021large} use the entire label set to analyze the \neteffect (\nef) of datasets, we provide a solution which is feasible when few labels are given.
% Moreover, they tend to misunderstand a class with no \nef as heterophily when it connects to other classes.
% This becomes problematic especially when the node attributes are not available, since one node have equal probabilities to have one of the classes.
We propose \methodtest, a statistical approach to identify the presence of \nef in a graph.
% This is used as a preliminary test to check whether the graph contains meaningful information for the task.
% It leads to interesting discovery that many widely used heterophily graphs exhibit no \nef.
By applying \methodtest to real-world graphs, we show that many popular heterophily graphs exhibit little \nef.

\subsection{\methodtest} \label{ssec:neanalysis}

% Previous works on identifying \nef of a graph \cite{zhu2020beyond, lim2021large} have two main limitations.
% First, they misunderstand a class with no \nef as heterophily when it connects to all existing classes uniformly.
% First, they are not designed to distinguish different non-homophily cases, i.e., heterophily or no \nef.
% Second, they require the labels of most nodes in a graph for the homophily ratios, even though in most real-world node classification tasks only a few node labels are observed.
% This becomes problematic especially when the node attributes are not available, since one node has equal probabilities to be any of the classes.
% Our proposed \methodtest addresses such limitations, and purely focuses on the graph structure.
% We firstly provide two definitions:
We first provide two main definitions regarding \nef:
\begin{definition}
\label{def:noGNEclass}
Given a class $c_{i}$ in a graph, if the nodes with class $c_{i}$ tend to connect randomly to the nodes with all classes $1, ..., c$ (with no specific preference), then class $c_{i}$ has no \nef.
\end{definition}
\begin{definition}
\label{def:noGNEall}
If all classes $c_{i}=1,...,c$ in a graph have no \nef, then this graph has no \nef.
\end{definition}
% \reminder{I commented out the next para}
\noindent
We distinguish heterophily graphs from those with no \nef by the definition.
In heterophily graphs, the nodes of a specific class are likely to be connected to the nodes of other classes, such as in bipartite graphs that connect different classes of nodes.
In this case, knowing the label of a node gives meaningful information about the labels of its neighbors.
% On the other hand, we can not benefit from the structural information in graphs having no \nef, since the class of a node does not give any information of its neighbors.
On the other hand, if a graph has no \nef, knowing the label of a node gives no useful information about its neighbors.
In other words, the structural information of a graph is not useful to infer the unknown labels of nodes.


\begin{algorithm}[t]
\KwData{Edges $\mathcal{E}$ and priors $\mathcal{P}$}
\KwResult{$p$-value table ${\boldsymbol F}$}
\tcc{edges with both nodes in priors}
Extract $\mathcal{E}^{'}$ such that $(i, j) \in \mathcal{E}, i, j \in \mathcal{P} \ \forall (i, j) \in \mathcal{E}^{'}$\;
${\boldsymbol T} \leftarrow {\boldsymbol O}_{c \times c}$\tcp*{test statistic table}
\tcc{do $\chi^{2}$ test for $B$ times ($B = 1000$ by default)}
\For{$b_{1}=1,...,B$}{
    \For{$c_{1}=1,...,c-1$}{
        \For{$c_{2}=c_{1}+1,...,c$}{
            ${\boldsymbol V} \leftarrow {\boldsymbol O}_{2 \times 2}$\tcp*{contingency table}
            % $\text{Shuffle}(\mathcal{E}^{'})$\tcp*{sampling}
            \For{$(i, j) \in \text{Sampled}(\mathcal{E}^{'})$}{
                \uIf{$l(i) = c_{1}$ and $l(j) = c_{1}$}{
                    ${\boldsymbol V}_{11} \leftarrow {\boldsymbol V}_{11} + 2$\;
                }
                \uElseIf{($l(i) = c_{1}$ and $l(j) = c_{2}$) or \\($l(i) = c_{2}$ and $l(j) = c_{1}$)}{
                    ${\boldsymbol V}_{21} \leftarrow {\boldsymbol V}_{21} + 1$\;
                    ${\boldsymbol V}_{12} \leftarrow {\boldsymbol V}_{12} + 1$\;
                }
                \uElseIf{$l(i) = c_{2}$ and $l(j) = c_{2}$}{
                    ${\boldsymbol V}_{22} \leftarrow {\boldsymbol V}_{22} + 2$\;
                }
                \If{$\sum_{i=1}^{2}{\sum_{j=1}^{2}{\boldsymbol {\boldsymbol V}_{ij}}} > 500$}{
                    Break\;
                }
            }
            \tcc{record statistics of class pairs}
            % ${\boldsymbol F}_{c_{1}c_{2}} = {\boldsymbol F}_{c_{2}c_{1}} = \text{FishersExactTest}({\boldsymbol V} / 2)$\;
            $T = \chi^{2}\text{-Test-Statistic}({\boldsymbol V} / 2)$\;
            ${\boldsymbol T}_{c_{1}c_{2}} \leftarrow {\boldsymbol T}_{c_{1}c_{2}} + T / B $\;
            ${\boldsymbol T}_{c_{2}c_{1}} \leftarrow {\boldsymbol T}_{c_{2}c_{1}} + T / B$\;
        }
    }
}
Compute $p$-value table ${\boldsymbol F}_{c \times c}$ with average statistics in ${\boldsymbol T}$\;
Return ${\boldsymbol F}$\;
\caption{\methodtest \label{algo:fisher}}
\end{algorithm}

% \reminder{Jeremy, please check - I re-wrote the next paragraph}
Next we describe how we propose to determine
the existence or absence of \nef.
In the inner loop, we need to decide whether class $c_i$ (say, ``talkative people''), has statistically more, or fewer edges
to class
% to either class $c_i$ or 
$c_j$ (say, ``silent people'').
\hide{\tiny 
To identify whether a given class has \nef or not, we propose to test whether the class is distinguishable with other classes in the graph.
If it is not distinguishable, then it means the class has no \nef.}
% in each of its class pairs with other classes.
We propose to use
Pearson's $\chi^2$ test \cite{pearson1900x} for that.
% is used to identify whether there exists a statistically significant contingency between two classes.
Specifically,
given a class pair $(c_i, c_j)$, the input to the test is a $2 \times 2$ contingency table containing the counts of edges that connect pairs of nodes whose labels are in $\{c_{i}, c_{j} \}$.
The null hypothesis of the test is:
% \reminder{Jeremy, I think the hypothesis should be... equally likely to exist between $c_i$-$c_j$, and $c_i$ and any other class}
\begin{h0}
Edges are equally likely to exist between nodes of the same class and those of different classes.
% Edges uniformly connect to both classes.
% Edges are equally likely to exhibit homophily and heterophilly.
% ($c_{i}-c_{i}$) 
% ($c_{i}-c_{j}; i \neq j$).
\end{h0}




\noindent
If the $p$-value from the test is no less than $0.05$, we accept the null hypothesis, which represents that the chosen class pair $(c_i, c_j)$ exhibits no statistically significant \nef in the graph.
Then we call them {\em mutually indistinguishable}:

\begin{definition}[Mutually indistinguishable]
\label{def:mIndistinguishable}
Two classes $c_i$ and $c_j$ are {\em mutually indistinguishable}
if we can not reject the null hypothesis above.
\end{definition}

\paragraph{Novel Implementation Details}
The detailed procedure of proposed \methodtest is depicted in Alg.~\ref{algo:fisher}.
A practical challenge on the test is that if the numbers in the table are too large, $p$-value becomes very small and meaningless \cite{lin2013research}.
Uniform edge sampling can be a natural solution, but sampling for only a single round can be unstable and output very different results.
% To solve these issues, 
To address this, we combine $p$-values from different random sampling by Universal Inference \cite{wasserman2020universal}.
We firstly sample edges to add to the contingency table until the frequency is above a specified threshold, and compute the $\chi^2$ test statistic for each class pair. 
Next, following Universal Inference, we repeat the procedure for random samples of edges for $B$ rounds and average the statistics.
% for $B$ samples as $\Bar{T} = 1/B \sum_{j=1}^{B}T_j$.
At last, we use the average statistics to compute the $p$-value table ${\boldsymbol F}_{c \times c}$ of $\chi^2$ tests. 

Notice that \methodtest is robust to noisy edges thanks to the sampling process, and works well given either a few or many node labels.
Given only a few observations, the $\chi^2$ test works well when the frequency in the contingency table is at least only $5$;
given many observations, our sampling trick ensures the correctness and the consistency of the computed $p$-value.

% In line $1$, given a set $\mathcal{P}$ of labeled nodes, called \emph{priors}, we first filter out the edges with unknown node label(s).
% Then in line $3$ to $22$, we compute the $p$-value by Fisher's exact test for each pair of classes. We limit the sum of the contingency table to no more than $500$ and divide the table by two before the test.
% This prevents Fisher's exact test becoming inaccurate when the number of observations is too large.
% The shuffling operation of edges $\mathcal{E}^{'}$ in line $6$ is to prevent biases caused by the sampling.
% % We return the set $\mathcal{C}$ of classes that accept the null hypotheses for all other classes, i.e., the classes without \nef.
% We finally return the computed the $p$-value table ${\boldsymbol F}$.

% \reminder{Jeremy, please check - I dropped the propositions}
At the end, 
% We give propositions on the result of \methodtest:
% \begin{prop} \label{obs:nf}
if a class accepts all the null hypotheses in Alg.~\ref{algo:fisher} with all other classes 
% (including itself)
, then this class has no \nef, and satisfies Def.~\ref{def:noGNEclass}.
Furthermore, if all classes exhibit no \nef, then the whole graph satisfies Def.~\ref{def:noGNEall}.
In that case, no label propagation methods will help
with node classification.

% we expect one of the two following cases:
% \ben
%     \item The class $c$ does not have \nef, or
%     \item The training data do not include enough information to identify whether the class $c$ has \nef.
% \een
% \end{prop}

% If one class obeys this observation, it is impossible to estimate its \nef. 
% Therefore, we should assume homophily for this class, which tends to give better results in practice.
% Therefore, instead of estimating the \nef (in Section~\ref{ssec:comp}), we should assume homophily for this class, which is empirically proved to be useful in many studies and tends to give a better result in practice.

\hide{
% We then extend Observation~\ref{obs:nf} to an extreme case:
\begin{prop} \label{obs:nf2}
If all classes in a graph obey Prop.~\ref{obs:nf}, then without extra information other than the given graph structure, exploiting \nef in node classification can not perform statistically better than random. % after exploiting \nef.
\end{prop}
% Proposition~\label{obs:nf2} implies that the graph structure is entirely useless for inferring labels to the nodes without labels, which can also be considered as random data.
% In this case, one should not try to run any tasks on the data which is random.
} % end hide

\subsection{Discoveries on Real-World Graphs} \label{ssec:discover}

% Based on \methodtest, 
We apply \methodtest to $6$ real-world graphs and analyze their \nef.
% , which are widely used in prior works \cite{lim2021large, liu2022ud, li2022finding, xiao2022decoupled, wang2022augmentation, park2022deformable}.
% We use $6$ popular real-world graphs in this analysis, whose detailed information is given also in \reminder{Section X}.
For each dataset, we sample $5$\% of node labels and compute the $p$-value table using \methodtest.
This is because 
a) only few labels are available in most node classification tasks in practice, and thus it is reasonable to make the same assumption in the analysis, and 
b) \methodtest can analyze \nef even from partial observations.
$B$ is set to $1000$ to output stable results.
Based on Definition~\ref{def:noGNEall} % Prop.~\ref{obs:nf2}, 
our surprising discoveries are:\looseness=-1
% Based on Observation~\ref{obs:nf2}, we surprisingly reveal that three large heterophily datasets, which have been widely used in previous works \cite{lim2021large, liu2022ud, li2022finding, xiao2022decoupled, wang2022augmentation, park2022deformable}, have no \nef, namely ``Genius'' \cite{lim2020expertise}, ``Penn94'' \cite{traud2012social}, and ``Twitch'' \cite{rozemberczki2021twitch}. 
% We also find that ``arXiv-Year'' \cite{hu2020open} is a dataset with mixed \nef. 

\begin{discovery}[No \nef]
\methodtest identifies the lack of \nef in ``Genius'', ``Penn94'', and ``Twitch''.
% have no \nef, exhibiting neither homophily nor heterophily.
\end{discovery}
\noindent
``Genius'' \cite{lim2020expertise}, ``Penn94'' \cite{traud2012social}, and ``Twitch'' \cite{rozemberczki2021twitch} are graphs which have been widely used in prior works \cite{liu2022ud, li2022finding, xiao2022decoupled, wang2022augmentation, park2022deformable}.
In ``Genius'' (Fig.~\ref{fig:dis1}), we see that both classes $1$ and $2$ tend to connect to class $1$, making class $2$ indistinguishable by the graph structure. 
\methodtest thus accepts the null hypothesis, and identifies the lack of \nef.
% This means that the edges have the same probability to be homophily and heterophily.
We can observe a similar phenomenon in ``Penn94'' (Fig.~\ref{fig:dis2}).
``Twitch'' (Fig.~\ref{fig:dis3}) used to be considered as a heterophily graph because of its weak homophily effect, but \methodtest finds that each of the classes uniformly connects to both classes, and thus it has little \nef.

% ``Twitch'' (Figure~\ref{fig:dis3}) is used to be considered as a homophily graph, but we have found that the homophily effect is too weak, and thus it has no \nef.
% ``Twitch'' (Figure~\ref{fig:dis3}) is not considered as a homophily graph because the effect is too weak, where the scales on the color bar are very close.
% However, it is not a heterophily graph as well, where 
% \methodtest correctly identifies that these graphs exhibit little \nef.

\begin{discovery}[Heterophily and \xophily]
\methodtest identifies \nef in ``Arxiv-Year'', ``Patent-Year'', and ``Pokec-Gender''.
\end{discovery}
\noindent
While ``Patent-Year'' and ``Pokec-Gender'' exhibit heterophily (Fig.~\ref{fig:dis5} and \ref{fig:dis6}),
``Arxiv-Year'' exhibits \xophily, i.e., not straight homophily or heterophily (Fig.~\ref{fig:dis4}).
These datasets with \nef will then be used in our experiments.
% Therefore, \method outperforms competitors as shown in Table~\ref{tab:effecthet}, where the datasets are used in our experiments.

\begin{discovery}[Weak vs strong \nef]
\methodtest identifies weak, and strong \nef:
``Arxiv-Year'' and ``Patent-Year'' exhibit weak \nef;
and ``Pokec-Gender'' exhibits strong \nef.
\end{discovery}
\noindent
We consider graphs to have weak \nef if there exists at least one class which is not distinguishable from some other classes.
Such graphs limit the accuracy of node classification, compared with graphs with strong \nef (i.e., all classes have \nef), regardless of the specific method used for classification.
% We show in Table~\ref{tab:effecthet} that the accuracy of our \method 
% Graphs with weak \nef have at least one class which is not distinguishable from the rest of classes.
% This explains why \method performs comparatively better when \nef is strong.
% In other words, \nef is better exploited when the graph structure is more meaningful (Table~\ref{tab:effecthet}).

\paragraph{Discussion of Homophily Statistics}
In Fig.~\ref{tab:homstat}, we report two homophily statistics for each dataset.
Edge homophily \cite{zhu2020beyond} is the ratio of edges that connect two nodes with the same class, and $\hat{h}$ \cite{lim2021large} is an improved metric which is insensitive to the number of classes and class sizes.
We find that, even using all labels, a single metric is not enough to capture the interrelations of all class pairs in detail, and the graphs with low homophily statistics are not guaranteed to be heterophily.
The homophily statistics can only detect the absence of homophily, instead of distinguishing different non-homophily cases, including heterophily, \xophily, and no \nef.
This is also discussed in \cite{lim2021large}.
In contrast, our proposed \methodtest identifies whether the graph exhibits \nef or not from only few labels.

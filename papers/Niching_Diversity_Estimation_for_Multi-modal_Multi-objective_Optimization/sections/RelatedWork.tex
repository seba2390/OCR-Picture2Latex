\section{Related Work}
\label{sec: Related Work}
In this section, we introduce two representative diversity estimators and discuss the difficulties they meet when handling MMOPs. Subsequently, some existing multi-modal multi-objective optimization algorithms are reviewed.
\subsection{Review of diversity estimators}
\subsubsection{Density in SPEA2}
In SPEA2 \cite{SPEA2}, each solution is assigned a density value which is used to calculate its fitness value. Eq. (\ref{eq: Density in SPEA2}) gives the density of a solution $\boldsymbol{x}$.
\begin{equation}
	\textit{Density} (\boldsymbol{x}) = \frac{1}{\sigma_k(\boldsymbol{x}) + 2},
	\label{eq: Density in SPEA2}
\end{equation}
where $\sigma_k(\boldsymbol{x})$ is the distance from $\boldsymbol{x}$ to its $k$-th nearest neighbor in the objective space. In SPEA2, $k$ is set to the square root of the total number of solutions in the current population as a general parameter setting.

Notice that in SPEA2, higher density means worse diversity in the objective space.

\subsubsection{Crowding distance}
Crowding distance is proposed along with the NSGA-II algorithm\cite{NSGAII} to preserve the diversity of the population in the objective space. The crowding distance of a solution $\boldsymbol{x}$ is given by the average side length of the hypercube constructed by its left and right neighbors in each objective. More precisely, for each objective, the left and right neighbors of $\boldsymbol{x}$ are the solutions at the left and right positions of $\boldsymbol{x}$ for that objective (i.e., in the list obtained by sorting the population in an increasing order of the objective values of that objective). The crowding distance of all boundary solutions (i.e., best solutions in any objectives) are set to $\infty$ to ensure that they are always selected. In NSGA-II, larger crowding distance values indicate better diversity. Formally, Eq. (\ref{eq: crowding distance}) calculates the crowding distance for a solution $\boldsymbol{x}$.
\begin{equation}
	\textit{Crowding-Distance} (\boldsymbol{x}) =
	\begin{cases}
		\infty                                                                     & ,\boldsymbol{x} \text{ is a boundary solution} \\
		\frac{1}{M}\sum_{m=1}^M[f_m(\boldsymbol{x}_{rm})-f_m(\boldsymbol{x}_{lm})] & ,\text{otherwise}
	\end{cases},
	\label{eq: crowding distance}
\end{equation}
where $M$ refers to the number of objectives, and $\boldsymbol{x}_{lm}$ and $\boldsymbol{x}_{rm}$ are the left and right neighbors of solution $\boldsymbol{x}$ regarding the $m$-th objective, respectively.
\subsection{Difficulties when handling MMOPs}
In most diversity estimators in MOEAs, the solution distribution in the decision space is out of consideration, which makes them inefficient on MMOPs. As we have discussed in Section \ref{sec: Introduction}, in MMOPs, equivalent solutions have the same or almost the same objective values. Consequently, they are usually not preferable in terms of diversity (in the objective space). For this reason, diversity estimators used in MOEAs are often responsible for the loss of equivalent solutions when tackling MMOPs. Fig. \ref{fig: Difficulty when handling MMOPs} gives an example when a diversity estimator such as crowding distance produces undesirable effects. In Fig. \ref{fig: Difficulty when handling MMOPs}, $A$ and $B$ are two Pareto optimal solutions on different (but equivalent) Pareto subsets (i.e., the upper and lower dash lines in (a)). Although $A$ and $B$ have similar objective values, the decision maker may want to keep both of them since they represent different implementations (i.e., they are different in the decision space). However, a diversity estimator tends to assign bad diversity values to them due to the small difference between their objective values. As a result, some of them are likely to be removed. From this example, we can see that solutions in different regions in the decision space should be considered separately when estimating solution diversity for MMOPs. Following this idea, we propose a niching diversity estimation method in Section \ref{sec: Proposed method}.

\begin{figure}
	\centering
	\includegraphics[width=.75\textwidth]{figures/RelatedWork/Difficulties}
	\caption{Explanation of the diversity loss in the decision space caused by diversity estimators when handling an MMOP. The dash lines in (a) and (b) denote the Pareto set and Pareto front, respectively.}
	\label{fig: Difficulty when handling MMOPs}
\end{figure}

\subsection{Multi-modal multi-objective optimization algorithms}
\label{sec: Existing multi-modal multi-objective optimization algorithms}
In most state-of-the-art multi-modal multi-objective evolutionary algorithms (MMEAs), the diversity in the decision space is maintained by niching strategies. Some MMEAs extend existing niching strategies in MOEAs to enable them to maintain the diversity in the objective space as well as in the decision space. For example, in \cite{OmniOptimizer}, Deb and Tiwari proposed one of the first MMEA called Omni-optimizer which modifies the crowding distance to measure the diversity in the decision space and the objective space simultaneously. Yue et. al. proposed a particle swarm optimizer named MO\_Ring\_PSO\_SCD \cite{MO_Ring_PSO_SCD} which adopts a similar modified crowding distance and a ring topology to create a niche structure. The DNEA algorithm \cite{DNEA} applies the fitness sharing \cite{Sharing} to both decision and objective spaces and combines them into a single sharing function. Some MMEAs are proposed with dedicated niching strategies in the decision space. Tanabe et. al. proposed a decomposition-based MMEA called MOEA/D-AD\cite{MOEAD_AD} where multiple solutions can be assigned to a weight vector, and a newly generated solution only competes with other solutions which are assigned to the same weight vector and neighboring to that solution in the decision space. In our previous study \cite{MOEAD_MM}, we proposed another decomposition-based MMEA which utilizes a clearing strategy in the decision space. Some MMEAs such as the algorithms proposed in \cite{DBSCAN_MMEA} and \cite{MMOEADC} use clustering approaches to maintain the niching structure in the decision space.
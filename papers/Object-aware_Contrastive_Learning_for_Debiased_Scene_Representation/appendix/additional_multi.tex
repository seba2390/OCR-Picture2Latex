\section{Additional contextual bias results}
\label{sec:add-multi}


\subsection{Hard negative issue in MoCov2}
\label{sec:add-multi-stability}

We found that MoCov2 trained with the object-aware random crop (OA-Crop) using ground-truth (GT) bounding boxes does not perform well, often worse than the original image (Baseline). This is because the contrastive learning objective is hard to optimize and unstable during training for the OA-Crop (GT), as shown in Figure~\ref{fig:hard-loss}. In contrast, OA-Crop using the ContraCAM boxes is much stable, yet it is a little harder to optimize than the original image.

\input{resources_appx_multi/fig_multi_hard_loss}

The reason behind this phenomenon is that the ground-truth boxes often contain objects that are hard to distinguish from each other, i.e., hard negatives for contrastive learning. In contrast, ContraCAM finds more discriminative objects as defined in Eq.~\eqref{eq:con-score}. Figure~\ref{fig:hard-hist} shows the histogram of the number of ContraCAM and ground-truth boxes, and Figure~\ref{fig:hard-box} shows a visual example of them. ContraCAM finds the most recognizable 1$\sim$3 objects from the full ground-truth boxes.

\input{resources_appx_multi/fig_multi_hard_hist}
\input{resources_appx_multi/fig_multi_hard_box}


\newpage
\subsection{Analysis on the contextual bias}
\label{sec:add-multi-bias}

We analyze whether the object-aware random crop (OA-Crop) actually relieves the contextual bias. To verify this, we visualize the embeddings of correlated classes under the original MoCov2 and the debiased model using the OA-Crop with the ContraCAM boxes. Specifically, we choose giraffe and zebra, which frequently co-occurs in the safari scene (see Figure~\ref{fig:intro-crop}). Figure~\ref{fig:multi-bias} shows the t-SNE \citep{van2008visualizing} visualization of the giraffe and zebra embeddings of the original and debiased models. The debiased OA-Crop (CAM) model less entangles the features of giraffe and zebra. However, even the debiased model using the ground-truth boxes, i.e., OA-Crop (GT), does not perfectly disentangle the features; since the bounding boxes often contain nearby or occluded objects.

We also quantitatively measure the contextual bias of the models in Table~\ref{tab:multi-bias}. Specifically, we compute the average minimum $\ell_2$-distance of the features, i.e.,
\begin{align}
    \frac{1}{\abs{\mathcal{X}}} \sum_{x \in \mathcal{X}} \min_{y \in \mathcal{Y}} d(x,y)
    + \frac{1}{\abs{\mathcal{Y}}} \sum_{y \in \mathcal{Y}} \min_{x \in \mathcal{X}} d(x,y),
\end{align}
where $\mathcal{X},\mathcal{Y} \subset \mathcal{R}^m$ are the penultimate embeddings of each class (giraffe and zebra) and $d$ denotes a $\ell_2$-distance function, under the MoCov2 using the ResNet-50 architecture. The model trained by OA-Crop (CAM) has a larger distance between the embeddings than the original image.

\input{resources_appx_multi/fig_multi_bias}
\input{resources_appx_multi/tab_multi_bias}

To further verify that the contextual bias harms the discriminability, we report the classification error of co-occurring classes (giraffe vs. zebra) over epochs. Upon the fixed representation, we compute the 5 seed average of 1-shot binary classification error. The classification error of vanilla MoCov2 increases for later epochs while the object-aware random crop shows consistent results.

\input{resources_appx_multi/tab_multi_bias_epoch}


\newpage
\subsection{Comparison with supervised models}
\label{sec:add-multi-supervised}

We provide the linear evaluation and detection/segmentation results of supervised models. Specificlaly, we consider two representative supervised learning model: Faster R-CNN \citep{ren2015faster} and Mask R-CNN \citep{he2017mask}, which are trained on bounding boxes and instance segmentations, respectively. We use the publicly available PyTorch models\footnote{\url{https://pytorch.org/vision/stable/models.html}} trained on the COCO dataset using the ResNet-50 architecture. We use the pretrained weights for detection/segmentation experiments (Table~\ref{tab:multi-supervised-det}) and trained a linear classifier upon the pretrained weights for linear evaluation experiments (Table~\ref{tab:multi-supervised-lineval}).

Table~\ref{tab:multi-supervised-lineval} and Table~\ref{tab:multi-supervised-det} show that the supervised Faster R-CNN and Mask R-CNN learns better representation than the self-supervised models. However, BYOL trained with ground-truth object boxes matches the supervised models' linear evaluation performance, implying the self-supervised methods' potentials. While ContraCAM significantly improves the vanilla MoCov2/BYOL, it would be an interesting future direction to reduce the gap between the supervised models further.

\input{resources_appx_multi/tab_multi_supervised}


\newpage
\subsection{Class-wise accuracy on CIFAR-10}
\label{sec:add-multi-class-wise}

We check if our debiased models suffer from the over-reliance on conspicuous objects as concerned in the potential negative effects section. Table~\ref{tab:multi-class-wise} shows the class-wise accuracy of the original and our debiased models on CIFAR-10. OA-Crop does not degrade the performance on certain classes, implying that the concerned bias issue does not occur for our considered transfer scenario.

\input{resources_appx_multi/tab_multi_class-wise}


\subsection{Comparison with the ImageNet-trained models}
\label{sec:add-multi-imagenet}

We compare the models trained under the COCO dataset (original or with OA-Crop) with the 10\% subset of the ImageNet dataset (i.e., ImageNet 10\%) under the ResNet-18 architecture in Table~\ref{tab:multi-imagenet}. We randomly choose 10\% of samples to make a similar size ($\sim$100,000) with the COCO dataset. While the models trained under COCO performing better on the COCO-Crop, ImageNet significantly outperforms the other datasets, implying ImageNet has fewer distribution shifts with them.

\input{resources_appx_multi/tab_multi_imagenet}


\subsection{Second iteration using the CAM from the debiased models}
\label{sec:add-multi-second}

We compare the models trained with the ContraCAM inferred from the original models (Iter. 1) and the debiased models (Iter. 2) in Table~\ref{tab:multi-second}. Using the debiased models has no additional gain from the original models. Thus, we use the single iteration version for all experiments.

\input{resources_appx_multi/tab_multi_second}

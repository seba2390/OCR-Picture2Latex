\section{Additional background bias results}
\label{sec:add-bg}

\subsection{Comparison with the copy-and-paste augmentation}
\label{sec:add-bg-soft}

We compare the background mixup using the ContraCAM (BG-Mixup) with the copy-and-paste augmentation using the binarized CAM (BG-HardMix) in Table~~\ref{tab:bg-soft-hard}. BG-Mixup (CAM) shows better accuracy (e.g., \textsc{Original}) and better generalization (e.g., \textsc{Mixed-Rand}) than the BG-HardMix, implying that the soft blending of foreground and background images performs better than the hard copy-and-paste. Indeed, one should consider the confidence of the predicted CAM masks as they are inaccurate. Also, the soft blending gives a further regularization effect of mixup \citep{zhang2018mixup}.

\input{resources_appx_bg/tab_bg_soft_hard}


\subsection{Ablation study on the mixup probability}
\label{sec:add-bg-augp}

We study the effect of the mixup probability $p_\texttt{mix}$, a probability of applying BG-Mixup augmentation. Table~\ref{tab:bg-probability} shows the BG-Mixup results with varying $p_\texttt{mix} \in  \{0.2,0.3,0.4,0.5\}$ applied on MoCov2 and BYOL. We first remark that BG-Mixup gives a consistent gain regardless of $p_\texttt{mix}$. Despite of the insensitivity on the hyperparameter $p_\texttt{mix}$, we choose $p_\texttt{mix} = 0.4$ for MoCov2 and $p_\texttt{mix} = 0.3$ for BYOL since they performed best for the most datasets in Background Challenge. MoCov2 permits the higher mixup probability since finding the closest sample from the finite batch (i.e., contrastive learning) is easier than clustering infinitely many samples (i.e., positive-only methods).

\input{resources_appx_bg/tab_bg_probability}


\newpage
\subsection{ContraCAM vs. GT masks on the distribution shifts}
\label{sec:add-bg-shift}

We provide distribution shift results of the copy-and-paste augmentation using ground-truth masks (BG-HardMix (GT)) in Table~\ref{tab:bg-more-dist}. BG-HardMix also improves the performance on distribution shifts by enforcing object-centric learning, but BG-Mixup performs better due to both object-centricness and input interpolation. Recall that BG-HardMix (GT) uses ground-truth masks and thus performs better for background shifts; yet, BG-Mixup is better for the distribution shifts.

\input{resources_appx_bg/tab_bg_more_dist}


\subsection{Mixup and CutMix on the background shifts}
\label{sec:add-bg-mixup}

We provide background shift results of Mixup and CutMix in Table~\ref{tab:bg-more-bg}. Since they are not designed for addressing the background bias, they are not effective on the Background Challenge benchmarks. In contrast, the background mixup is effective on both background and distribution shifts.

\input{resources_appx_bg/tab_bg_more_bg}


\subsection{Corruption-wise results on ImageNet-C-9}
\label{sec:add-bg-imagenetc}

We provide the corruption-wise results on the ImageNet-C-9 dataset in Table~\ref{tab:bg-imagenetc}. Background mixup using the ContraCAM masks (BG-Mixup (CAM)) shows the overall best performance. Especially, the BG-Mixup performs well for the `weather' and `digital' class, e.g., improves 24.41\% of the baseline to 54.30\% (+29.89\%), while less performs for the 'noise' class. Indeed, the `weather' and `digital' classes require more understanding of the objects (i.e., shape bias) than the `noise' class.

\clearpage
\input{resources_appx_bg/tab_bg_imagenet_c9}


\clearpage
\subsection{Results on additional datasets}
\label{sec:add-bg-datasets}

We additionally evaluate the generalization performance of background mixup on ObjectNet~\citep{barbu2019objectnet} and SI-Score~\citep{djolonga2021robustness}, datasets for distribution shift and background shift, respectively. Following previous experiment settings, we train a linear classifier on ImageNet-9 and evaluate the 9-superclass subset of ObjectNet and SI-Score, denoted by adding `-9' in suffix. Table~\ref{tab:bg-more-datasets} shows that background mixup outperforms the vanilla MoCov2/BYOL (and also Mixup and CutMix) for both datasets.  Note that BG-Mixup (CAM) performs better than BG-HardMix (GT) for ObjectNet-9 (distribution-shifted) but less effective for SI-Score-9 (background-shifted).

\input{resources_appx_bg/tab_bg_more_datasets}



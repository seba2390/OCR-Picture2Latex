\section{Conclusion}

We propose IDAPT, a novel policy transfer approach that addresses visual and dynamics domain gaps with minimal assumptions in the target environment by grounding the source environment in the target environment with a visual transformation and action transformation between domains.  IDAPT iteratively updates the transformations and optimizes a policy in the grounded environment to progressively align the domains and train a policy.  We demonstrate that IDAPT outperforms domain randomization methods which struggle to learn in high randomization regimes.
IDAPT is designed for target environments that have difficulties in collecting task supervision and interactions, which is not limited to sim-to-sim transfer. Therefore, applying IDAPT to sim-to-real and real-to-real policy transfer is a promising future direction.
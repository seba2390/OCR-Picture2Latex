% last updated in April 2002 by Antje Endemann
% Based on CVPR 07 and LNCS, with modifications by DAF, AZ and elle, 2008 and AA, 2010, and CC, 2011; TT, 2014; AAS, 2016
\documentclass[runningheads]{llncs}
\usepackage{graphicx}
% \usepackage{times}
\usepackage{amsmath,amssymb} % define this before the line numbering.
% \usepackage{ruler}
\usepackage[usenames, dvipsnames]{color}
\usepackage[width=122mm,left=12mm,paperwidth=146mm,height=193mm,top=12mm,paperheight=217mm]{geometry}
\usepackage{caption}
\captionsetup{compatibility=false}
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{xspace}
% \setlength{\intextsep}{8mm}
% \setlength{\belowcaptionskip}{-\baselineskip}\addtolength{\belowcaptionskip}{0.1mm}%
% \addtolength{\parskip}{-0.3mm}
\setlength{\textfloatsep}{10pt plus 1.0pt minus 2.0pt}

 \captionsetup[table]{aboveskip=2pt}
 \captionsetup[table]{belowskip=2pt} 
 
% Add a period to the end of an abbreviation unless there's one
% already, then \xspace.
\makeatletter
\DeclareRobustCommand\onedot{\futurelet\@let@token\@onedot}
\def\@onedot{\ifx\@let@token.\else.\null\fi\xspace}

\def\eg{\emph{e.g}\onedot} \def\Eg{\emph{E.g}\onedot}
\def\ie{\emph{i.e}\onedot} \def\Ie{\emph{I.e}\onedot}
\def\cf{\emph{c.f}\onedot} \def\Cf{\emph{C.f}\onedot}
\def\etc{\emph{etc}\onedot} \def\vs{\emph{vs}\onedot}
\def\wrt{w.r.t\onedot} \def\dof{d.o.f\onedot}
\def\etal{\emph{et al}\onedot}

\newcommand\err[1]{{\color{red}#1}}
\newcommand\look[1]{{\color{ForestGreen}#1}}

\makeatother
\begin{document}
% \renewcommand\thelinenumber{\color[rgb]{0.2,0.5,0.8}\normalfont\sffamily\scriptsize\arabic{linenumber}\color[rgb]{0,0,0}}
% \renewcommand\makeLineNumber {\hss\thelinenumber\ \hspace{6mm} \rlap{\hskip\textwidth\ \hspace{6.5mm}\thelinenumber}}
% \linenumbers
\pagestyle{headings}
\mainmatter
\def\ECCV18SubNumber{6}  % Insert your submission number here

\title{Action Anticipation By Predicting Future Dynamic Images} % Replace with your title

\titlerunning{Action Anticipation By Predicting Future Dynamic Images}

\authorrunning{C. Rodriguez et al.}

\author{Cristian Rodriguez, Basura Fernando and Hongdong Li}
\institute{Australian Centre for Robotic Vision, ANU, Canberra, Australia\\ \texttt{\{cristian.rodriguez, basura.fernando, hongdong.li\}@.anu.edu.au} }


\maketitle

\begin{abstract}
Human action-anticipation methods predict what is the future action by observing only a few portion of an action in progress.
This is critical for applications where computers have to react to human actions as early as possible such as autonomous driving, human-robotic interaction, assistive robotics among others.
In this paper, we present a method for human action anticipation by predicting the most plausible future human motion.  
We represent human motion using {\em Dynamic Images} \cite{bilen2016dynamic} and make use of tailored loss functions to encourage a generative model to produce accurate future motion prediction. 
Our method outperforms the currently best performing action-anticipation methods by 4\% on JHMDB-21, 5.2\% on UT-Interaction and 5.1\% on UCF 101-24 benchmarks.
\keywords{Action-Anticipation, Prediction, Generation, Motion Representation, Dynamic Image}
\end{abstract}

\section{Introduction}
\input{intro}
\section{Related work}
\input{related}
\section{Method}
\input{method}
\section{Experiments and results}
\input{experiments}
\section{Discussion}
\input{discussion}


\bibliographystyle{splncs}
\bibliography{egbib}
\end{document}

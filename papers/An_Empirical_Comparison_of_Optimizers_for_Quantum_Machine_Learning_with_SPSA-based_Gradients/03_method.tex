\section{Methods}
\label{sec:Methods}

We conducted numerical experiments to study the performance of different optimizers in training a VQC for multiple regression tasks, where the gradients are either inferred from SPSA or the parameter-shift rule. The following datasets were employed in the experiments:
\begin{itemize}
    \item The \textit{sklearn} python library features a built-in function \textit{make\_regression} (MReg), which generates the regression target from a random linear combination of the input features with some added gaussian noise.
    \item Three different four- to five-dimensional artificial datasets first introduced by Friedman \cite{friedman1991multivariate, breiman1996bagging} (F1, F2, F3). They are built from rational and trigonometric functions of the the input features.
    \item A real world dataset that captures the relationship of the four ambient variables temperature, air pressure, relative humidity and exhaust vacuum pressure with the power output of a Combined Cycle Power Plant (CCPP) \cite{Tufekci2014}.
\end{itemize}
For each dataset, 500 data points were used for training, 50 for validation, and 100 for model testing. The training was done for a maximum of 30 epochs, with one validation step between each epoch. At the end of the training, the model that attained the best validation results was tested on the test dataset.

\begin{figure}
    \centering
    \resizebox{0.3\linewidth}{!}{%
    \begin{tikzpicture}
        \begin{yquant}
            qubit {} q[4];
            box {$R_y(\theta_{0})$} q[0];
            box {$R_y(\theta_{1})$} q[1];
            box {$R_y(\theta_{2})$} q[2];
            box {$R_y(\theta_{3})$} q[3];
            box {$R_z(\theta_{4})$} q[0];
            box {$R_z(\theta_{5})$} q[1];
            box {$R_z(\theta_{6})$} q[2];
            box {$R_z(\theta_{7})$} q[3];
            zz (q[1, 0]);
            zz (q[2, 1]);
            zz (q[3, 2]);
        \end{yquant}
    \end{tikzpicture}
    }
    \caption{The variational layer of the VQC. Parametrized \(Y\)- and \(Z\)-rotation gates are used to transform the quantum state. A series of \(ZZ\)-gates with nearest-neighbor connectivity is used to create entanglement between qubits. In the full VQC circuit this variational layer is repeated five times. It is preceded by a single encoding layer.}
    \label{fig:VariationalLayer}
\end{figure}

The function approximator used for these regression tasks is a VQC consisting of four to five qubits, depending on the feature dimension of the considered dataset, with five repeated variational layers (cf. \cref{fig:VariationalLayer}) and a single observable \(A = Z^{\otimes n}\) estimation constituting the output according to equation \eqref{eq:expectation_value}. The classical input data was encoded into quantum states with parametrized single-qubit \(X\)-rotations, where the rotation angles are obtained by linearly scaling the feature space into \(\left[-\pi, \pi\right]^n\). The variational parameters were all initialized to zero. 

All hyperparameters of the optimizers from section \ref{sec:Optimizers} were tuned on each dataset, including the perturbation strength \(c^k\) and learning rate (i.e. a scaling factor applied to each gradient) for the SPSA-based gradient estimation. Since even with SPSA inferred gradients, training the optimizers on the full datasets is computationally expensive, only a subset of 50 randomly sampled points from each dataset were considered for the hyperparameter-tuning.

Since SPSA is often claimed to be especially well suited in noisy settings, it is of prime interest to study the effects of different types of noise, and error mitigation on the optimization procedure. Therefore, the training was done in four different settings. First, an ideal simulation with analytical calculation of all expectation values was performed. Then, shot-noise was taken into account by using a noiseless shot-based simulator with an overall budget of 1024 shots per expectation value estimation. As a next step, realistic hardware noise mimicking the ibmq\_ehningen device was added to the simulation. Finally, the experiments were repeated with zero noise extrapolation \cite{temme2017error} as a technique to mitigate the hardware noise. For this purpose, we used the native error mitigation capabilities of the IBM Quantum services.
\section{Results}
\label{sec:Results}

The results obtained in an ideal, noise-free simulation with the best performing model from the hyperparameter tuning for the SPSA-based gradient estimation step are shown in the top of \cref{tab:Hyperparameter}. Based on the average loss reported in the last row, AMSGrad significantly outperforms SGD, followed closely by Adam and RMSProp when SPSA-based gradients are used. Likewise, the bottom of \cref{tab:Hyperparameter} shows the results obtained during the hyperparameter tuning step of the parameter shift gradient estimation under the same conditions. The average loss shown in \cref{tab:Hyperparameter} already indicates that the parameter-shift based gradient estimation underperforms compared to the SPSA based gradient estimation with all optimizer combinations. However, it should be noted that the hyperparameter results are based on training with 50 data points. Therefore, to validate this observation, we trained all the best performing models again with 500 data points.

\begin{table*}[hbtp!]
    \centering
    \caption{Loss after hyperparameter tuning for each dataset and optimizer in an ideal noise-free simulation using SPSA-based gradients (left) and parameter-shift rule (right).}
    %\begin{tabular}{l|*{5}{c}}
    %    Dataset & SPSA & SGD + Momentum & Adam & AMSGrad & RMSProp\\
    %    \hline
    \resizebox{0.45\linewidth}{!}{
        \begin{tabular}{l|*{5}{c}}
        Dataset & SGD & \shortstack[c]{SGD +\\momentum}{} & Adam & AMSGrad & RMSProp\\
        \hline
        MReg & 0.17 & 0.14 & 0.04 & 0.02	& 0.04\\
        CCPP & 0.13	& 0.14 & 0.11 & 0.10 & 0.10 \\
        F1 & 0.30 & 0.30 & 0.16 & 0.15 & 0.15\\
        F2 & 0.34 & 0.26 & 0.10	& 0.10 & 0.14\\
        F3 & 0.22 & 0.22 & 0.14 & 0.12 & 0.16\\
        \hline
        Average & 0.23 & 0.21 & 0.11 & 0.10	& 0.12 \\
        \end{tabular}
        }
        \vspace{0.5cm}
\resizebox{0.45\linewidth}{!}{
\begin{tabular}{l|*{5}{c}}
        Dataset & SGD & \shortstack[c]{SGD +\\momentum}{} & Adam & AMSGrad & RMSProp\\
        \hline
        MReg & 0.23 & 0.22 & 0.20 & 0.21 & 0.20\\
        CCPP & 0.16 & 0.32 & 0.13 & 0.15 & 0.13 \\
        F1   & 0.30 & 0.30 & 0.22 & 0.24 & 0.23\\
        F2   & 0.41 & 0.45 & 0.38 & 0.39 & 0.39\\
        F3   & 0.33 & 0.36 & 0.26 & 0.27 & 0.26\\
        \hline
        Average & 0.29 & 0.33 & 0.24 & 0.25 & 0.24 \\
        \end{tabular}
    }
    \label{tab:Hyperparameter}
\end{table*}


\cref{fig:ideal_validResults} and \cref{fig:param_validResults} show the validation results obtained during training by different optimizers combined with SPSA and parameter-shift based gradient estimation. All curves of the validation results are averaged over five trials and all five datasets. The plots show that the SPSA-based gradient estimation achieves a better solution than the parameter-shift rule in all optimizer combinations. The parameter-shift rule based gradient estimation methods converged to a suboptimal solution and performed two to three times worse than the SPSA-based gradient estimation. On the other hand, the parameter-shift rule requires forty times more circuit simulations per optimization step compared to SPSA, resulting in high computational costs. The same pattern can be seen in the test results in \cref{tab:SPSA_results} and \cref{tab:Parameter_shift_results}. Therefore, no further experiments were performed using the parameter-shift based gradient estimation method. \cref{tab:SPSA_results} shows that AMSGrad achieves a better solution, followed by Adam and RMSProp within the SPSA-based gradient estimation group. As SGD with Momentum in combination with SPSA converged to a suboptimal solution on the validation curve, it was not tested.
%, but SGD with Momentum in combination with SPSA performs worse than standard SPSA. 
From \cref{fig:ideal_validResults} and \cref{tab:SPSA_results}, we can infer that AMSGrad, in combination with SPSA, not only converges two to three times faster but also achieves two times better solutions under ideal simulation.


%\begin{figure}[htbp!]
%    \centering
%    \includegraphics[width=\linewidth]{img/validation_curve_ideal.eps}
%    \caption{Validation results after every epoch during training on an %ideal simulator using SPSA based gradient estimation}
%    \label{fig:ideal_validResults}
%\end{figure}

\begin{figure}[htbp!]
    \centering
    \resizebox{0.8\linewidth}{!}{%
    \begin{tikzpicture}
    \begin{axis}[
        xlabel={Epochs},
        ylabel={Average Mean Square Error},
        legend style={at={(0.9, 1.1)},anchor=north},
    ]
        \addplot+[color=red, style=solid, mark=none] table[x=index, y=Standard SPSA, col sep=comma] {img/pgfdata/SPSA_pure_ideal.csv};
        \addplot+[color=orange, style=solid, mark=none] table[x=index, y=SGD + momentum, col sep=comma] {img/pgfdata/SPSA_sgd_ideal.csv};
        \addplot+[color=green, style=solid, mark=none] table[x=index, y=Adam, col sep=comma] {img/pgfdata/SPSA_adam_ideal.csv};
        \addplot+[color=blue, style=solid, mark=none] table[x=index, y=AMSGrad, col sep=comma] {img/pgfdata/SPSA_amsgrad_ideal.csv};
        \addplot+[color=violet, style=solid, mark=none] table[x=index, y=RMSProp, col sep=comma] {img/pgfdata/SPSA_rmsprop_ideal.csv};
        \legend{Standard SPSA, SGD + momentum, Adam, AMSGrad, RMSProp}
        
    \end{axis}
    \end{tikzpicture}
    }
     \caption{Validation results after every epoch during training on an ideal simulator using SPSA-based gradient estimation}
    \label{fig:ideal_validResults}
\end{figure}




%\begin{figure}[htbp!]
%    \centering
%    \includegraphics[width=\linewidth]{img/validation_curve_ideal_param-shift.eps}
%    \caption{Validation results after every epoch during training on an ideal simulator using Parameter-%shift rule based gradient estimation}
%    \label{fig:param_validResults}
%\end{figure}

\begin{figure}[htbp!]
    \centering
    \resizebox{0.8\linewidth}{!}{%
    \begin{tikzpicture}
    \begin{axis}[
        xlabel={Epochs},
        ylabel={Average Mean Square Error},
        legend style={at={(0.9, 1.15)},anchor=north}
    ]
        \addplot+[color=red, style=solid, mark=none] table[x=index, y=SGD, col sep=comma] {img/pgfdata/Param-shift_pure_ideal.csv};
        \addplot+[color=orange,  style=solid, mark=none] table[x=index, y=SGD + momentum, col sep=comma] {img/pgfdata/Param-shift_sgd_ideal.csv};
        \addplot+[color=green, style=solid, mark=none] table[x=index, y=Adam, col sep=comma] {img/pgfdata/Param-shift_adam_ideal.csv};
        \addplot+[color=blue,  style=solid, mark=none] table[x=index, y=AMSGrad, col sep=comma] {img/pgfdata/Param-shift_amsgrad_ideal.csv};
        \addplot+[color=violet,  style=solid, mark=none] table[x=index, y=RMSProp, col sep=comma] {img/pgfdata/Param-shift_rmsprop_ideal.csv};
        \legend{SGD, SGD + momentum, Adam, AMSGrad, RMSProp}
        
    \end{axis}
    \end{tikzpicture}
    }
     \caption{Validation results after every epoch during training on an ideal simulator using parameter-shift rule based gradient estimation}
    \label{fig:param_validResults}
\end{figure}

Validation results obtained by different optimizers when simulated on an ideal simulator with shot noise showed similar convergence to ideal simulator results. The test results in \cref{tab:SPSA_results} show that the performance of all optimizers degrades when shot noise is introduced. However, the standard SPSA and SPSA with RMSProp showed a greater decrease in performance compared to SPSA with Adam or AMSGrad. Next, we repeated the same set of experiments with a noisy simulator simulating the ibmq\_ehningen noise model. All the optimizers showed similar convergence patterns during training as shown in \cref{fig:ideal_validResults} and the test results are given in \cref{tab:SPSA_results}. From \cref{tab:SPSA_results}, it can be seen that the performance of standard SPSA seems to degrade under different noise conditions, while SPSA with Adam or AMSGrad exhibited a performance similar to its performance under an ideal simulator with shot noise. Finally, the experiments defined above were repeated with a noisy simulator that simulates the ibmq\_ehningen noise model and the error mitigation method presented in \cref{sec:error_mitigation}. The test results reported in \cref{tab:SPSA_results} show again the same hierarchy, with AMSGrad performing the best on average. However, RMSProp achieves almost the same accuracy on average and even surpasses AMSGrad on the F3 dataset. Additionally, it is striking that with the use of error mitigation all methods perform significantly worse than even in the noisy case. A possible explanation for this is the fact that a global observable \(A = Z^{\otimes n }\) was used to constitute the output of the VQC. Kim et al.~\cite{kim2023scalable} demonstrated that zero-noise extrapolation performs poorly on global observables.

%Average is computed over 5 trials per dataset and the total average is given by the average over all trials of all datasets. Convergence gives the number of epochs till convergence is reached, averaged over 5 trials per dataset and rounded to next integer.
\begin{table}[hbtp!]
    \centering
    \caption{SPSA results. For each individual dataset the reported loss is the average computed over 5 trials. The Normalized average error with respect to standard SPSA (Norm. Avg.), computed over all trials for all datasets, is given at the bottom of each method.}
\resizebox{\linewidth}{!}{
\begin{tabular}{l|l|c|c|c|c}
%\hline
Method & 
Dataset &
SGD &
%\multicolumn{3}{ c| } {SGD + Momentum}  &
Adam &
AMSGrad &
RMSProp \\
\hline
\multirow{6}{*}{Ideal} 
 & MReg & 0.0465 & 0.0317 & 0.0269  & 0.0394\\
 & CCPP & 0.1034 & 0.1028 & 0.1008 & 0.1036\\
 & F1 & 0.1587 & 0.1183 & 0.1436 & 0.1449\\
 & F2 & 0.1327 & 0.1122 & 0.0981 & 0.0841\\
 & F3 & 0.1440 & 0.1441 & 0.1298 & 0.1559\\
 \cline{2-6}
 & Norm. Avg. & 1.0000 & 0.8536 & 0.8198 & 0.8958\\
 \hline
\multirow{6}{*}{\shortstack[l]{Shot-\\based}} 
 & MReg & 0.0492 & 0.0457 & 0,0398 & 0.0546\\
 & CCPP & 0.1107 & 0.1075 & 0,1049 & 0.1014\\
 & F1 & 0.1722 & 0.1292 & 0.1391 & 0.1634\\
 & F2 & 0.1348 & 0.1081 & 0.1146 & 0.1202\\
 & F3 & 0.1551 & 0.1510 & 0.1328 & 0.1646\\
 \cline{2-6}
 & Norm. Avg. & 1.0000 & 0.8849 & 0.8540 & 0.9851\\
 \hline
\multirow{6}{*}{Noisy} 
 & MReg & 0.0773 & 0.0537 & 0,0480 & 0.0622\\
 & CCPP & 0.1219 & 0.1136 & 0.0993 & 0.1070\\
 & F1 & 0.2441 & 0.1719 & 0.1213 & 0.2126\\
 & F2 & 0.1620 & 0.1167 & 0.1005 & 0.1218\\
 & F3 & 0.1762 & 0.1703 & 0.1226 & 0.1655\\ 
 \cline{2-6}
 & Norm. Avg. & 1.0000 & 0.8036 & 0.6498 & 0.8492\\
 \hline
\multirow{6}{*}{\shortstack[l]{Error-\\Mitigated}} 
 & MReg & 0.2080 & 0.1213 & 0.0875 & 0.0885\\
 & CCPP & 0.1589 & 0.1577 & 0.1343 & 0.1388\\
 & F1   & 0.2999 & 0.1780 & 0.1972 & 0.2393\\
 & F2   & 0.4421 & 0.2002 & 0.1800 & 0.1808\\
 & F3   & 0.2804 & 0.2062 & 0.2162 & 0.1941\\
 \cline{2-6}
 & Norm. Avg. & 1.0000 & 0.6716 & 0.6203 & 0.6397\\
 %\hline
\end{tabular}
}
    \label{tab:SPSA_results}
\end{table}

\begin{table}[hbtp!]
    \centering
    \caption{Parameter-shift rule results. For each individual dataset the reported loss is the average computed over 5 trials. The Normalized average error with respect to standard SPSA (Norm. Avg.), computed over all trials for all datasets, is given at the bottom of each method.}
    \resizebox{\linewidth}{!}{\begin{tabular}{l|l|c|c|c|c}
%\hline
Method & Dataset & SGD & Adam & AMSGrad & RMSProp\\ \hline
\multirow{6}{*}{Ideal} 
 & MReg & 0.2096 & 0.2112 & 0,2071 & 0.2107\\
 & CCPP & 0.2208 & 0.1271 & 0.1287 & 0.1269\\
 & F1 & 0.2595 & 0.2352 & 0.2282 & 0.2176\\
 & F2 & 0.3722 & 0.3784 & 0.3754 & 0.3783\\
 & F3 & 0.3017 & 0.2795 & 0.2859 & 0.2840\\
 \cline{2-6}
 & Norm. Avg. & 1.0000 & 0.8866 & 0.8813 & 0.8753 %\hline
\end{tabular}}
    \label{tab:Parameter_shift_results}
\end{table}

\iffalse
\begin{table*}[hbt]
    \centering
    \caption{Parameter-shift rule results, where Average (Avg.) is computed over 5 trials per dataset and Total Average (Tot. avg.) computed over all trials for all datasets.}
    \resizebox{0.8\textwidth}{!}{\begin{tabular}{l|l|*{2}{l}|*{2}{l}|*{2}{l}|*{2}{l} }
%\hline
\multicolumn{2}{ c| } {} &  
\multicolumn{2}{ c| } {SGD} &
\multicolumn{2}{ c| } {Adam}  &
\multicolumn{2}{ c| } {AMSGrad} &
\multicolumn{2}{ c } {RMSProp} \\
\hline
Method & Dataset & Avg. & Tot. avg. & Avg. & Tot. avg. & Avg. & Tot. avg. & Avg. & Tot. avg.\\ \hline
\multirow{5}{*}{Ideal} 
 & MReg & 0.2096 & 0.2727 & 0.2112 & 0.2463 & 0,2071 & 0.2451 & 0.2107 & 0.2435\\
 & CCPP & 0.2208 & & 0.1271 & & 0.1287 & & 0.1269 & \\
 & F1 & 0.2595 & & 0.2352 &  & 0.2282 & & 0.2176 & \\
 & F2 & 0.3722 & & 0.3784 &  & 0.3754 & & 0.3783 & \\
 & F3 & 0.3017 & & 0.2795 &  & 0.2859 & & 0.2840 & \\ %\hline
%\multirow{5}{*}{Shot-based} 
% & MReg & 0.0492& 0.1244 & 25 & 0.0457 & 0.1083 & 8 & 0,0398 & 0,1062 & 8 & & &\\
% & CCPP & 0.1107 & & 29 & 0.1075 & & 5 & 0,1049 & & 11 & & &\\
% & F1 & 0.1722 & & 30 & 0.1292 & & 18 & 0,1391 & & 13 & & &\\
% & F2 & 0.1348 & & 29 & 0.1081 & & 15 & 0,1146 & & 9 & & &\\
% & F3 & 0.1551 & & 29 & 0.1510 & & 8 & 0,1328 & & 13 & & &\\
\end{tabular}}
    \label{tab:Parameter_shift_results}
\end{table*}
\fi
Throughout all methods used, AMSGrad shows the strongest performance. Adam comes close in terms of performance and requires fewer training steps for some datasets such as CCPP. Generally, both optimizers require drastically fewer training steps until convergence is achieved than standard SPSA and SGD with momentum.


\begin{figure*}[htbp!]
    \centering
    \resizebox{0.95\textwidth}{!}{
    \begin{tikzpicture}
        \begin{yquant}
            qubit {} q[4];
            box {$R_x(\theta_{0})$} q[0];
            box {$R_x(\theta_{1})$} q[1];
            box {$R_x(\theta_{2})$} q[2];
            box {$R_x(\theta_{3})$} q[3];
            box {$R_z(\theta_{4})$} q[0];
            box {$R_z(\theta_{5})$} q[1];
            box {$R_z(\theta_{6})$} q[2];
            box {$R_z(\theta_{7})$} q[3];
            
            box {$R_x(\theta_{8})$} q[2]|q[3];
            box {$R_x(\theta_{9})$} q[1]|q[3];
            box {$R_x(\theta_{10})$} q[0]|q[3];

            box {$R_x(\theta_{11})$} q[3]|q[2];
            box {$R_x(\theta_{12})$} q[1]|q[2];
            box {$R_x(\theta_{13})$} q[0]|q[2];

            box {$R_x(\theta_{14})$} q[3]|q[1];
            box {$R_x(\theta_{15})$} q[2]|q[1];
            box {$R_x(\theta_{16})$} q[0]|q[1];

            box {$R_x(\theta_{14})$} q[3]|q[0];
            box {$R_x(\theta_{15})$} q[2]|q[0];
            box {$R_x(\theta_{16})$} q[1]|q[0];
            align -;
            box {$R_x(\theta_{17})$} q[0];
            box {$R_x(\theta_{18})$} q[1];
            box {$R_x(\theta_{19})$} q[2];
            box {$R_x(\theta_{20})$} q[3];
            box {$R_z(\theta_{21})$} q[0];
            box {$R_z(\theta_{22})$} q[1];
            box {$R_z(\theta_{23})$} q[2];
            box {$R_z(\theta_{24})$} q[3];
            
        \end{yquant}
    \end{tikzpicture}
    }
    \caption{The variational layer of the least expressive VQC proposed by Sim et al.}
    \label{fig:MostExpressive}
\end{figure*}

\subsection{Generalization on different architecture ansatz}
To investigate the dependence of the advantage brought in by AMSGrad on the circuit ansatz, we trained two different VQCs with different circuit ansatzes in the same setting with AMSGrad and the standard SPSA optimizer. Since the difficulty of training the circuit depends strongly on the expressivity, the least and most expressive circuits proposed by Sim et al.~\cite{Sim2019, dragan2022quantum} respectively were chosen to validate the performance of AMSGrad in combination with SPSA-based gradient estimation. \cref{fig:leastExpressive} represents one variational layer of the least expressive circuit, and \cref{fig:MostExpressive} represents one variational layer of the most expressive circuit. Five such layers were repeated in each VQC. The results shown in \cref{tab:expressivity_results} validate that the combination of AMSGrad with SPSA-based gradient estimation yields superior results compared to the standard SPSA method, irrespective of the expressivity of the circuit.

%\textcolor{blue}{To investigate the dependence of the advantage brought in by AMSGrad on the circuit ansatz, we trained two different VQCs with different circuit ansatzes in the same setting with AMSGrad and standard SPSA optimizers. The selected circuits were the least expressive circuit and the most expressive circuit proposed by Sim et al.~\cite{Sim2019, dragan2022quantum}. The reason for this selection is to validate the performance of AMSGrad in combination with SPSA-based gradient estimation over different circuits with different expressiveness, leading to different ease of training and gradient descent to a solution. \cref{fig:leastExpressive} represents one variational layer of the least expressive circuit, and \cref{fig:MostExpressive} represents one variational layer of the most expressive circuit. Five such layers were repeated in each VQC. The results shown in \cref{tab:expressivity_results} validate that the combination of AMSGrad with SPSA-based gradient estimation yields superior results compared to the standard SPSA method, irrespective of the expressivity of the circuit.
%}

\begin{figure}
    \centering
    \resizebox{0.3\linewidth}{!}{%
    \begin{tikzpicture}
        \begin{yquant}
            qubit {} q[4];
            H q[0];
            H q[1];
            H q[2];
            H q[3];
            zz (q[3, 2]);
            zz (q[2, 1]);
            zz (q[1, 0]);
            align -;
            box {$R_y(\theta_{0})$} q[0];
            box {$R_y(\theta_{1})$} q[1];
            box {$R_y(\theta_{2})$} q[2];
            box {$R_y(\theta_{3})$} q[3];
            
        \end{yquant}
    \end{tikzpicture}
    }
    \caption{The variational layer of the least expressive VQC proposed by Sim et al.}
    \label{fig:leastExpressive}
\end{figure}




\begin{table}[hbtp!]
    \centering
    \caption{Perormance of AMSGrad and SPSA on circuits with different expressivity}

\begin{tabular}{l|l|c|c}
%\hline
Circuit & 
Dataset &
SGD &
%\multicolumn{3}{ c| } {SGD + Momentum}  
AMSGrad  \\
\hline
\multirow{6}{*}{\shortstack[l]{Least \\ Expressive \\ circuit}} 
 & MReg & 0.2166 & 0.0453 \\
 & CCPP & 0.1406 & 0.1142 \\
 & F1 & 0.2839 & 0.1671 \\
 & F2 & 0.5589 & 0.1287 \\
 & F3 & 0.5147 & 0.1652 \\
 \cline{2-4}
 & Norm. Avg. & 1.0000 & 0.4322 \\
 \hline
\multirow{6}{*}{\shortstack[l]{Most \\ Expressive \\ circuit}} 
 & MReg & 0.2192 & 0.0920 \\
 & CCPP & 0.2353 & 0.1236 \\
 & F1 & 0.3099 & 0.2933 \\
 & F2 & 0.5600 & 0.1533 \\
 & F3 & 0.5483 & 0.5149 \\
 \cline{2-4}
 & Norm. Avg. & 1.000 & 0.6208 \\
\end{tabular}

    \label{tab:expressivity_results}
\end{table}
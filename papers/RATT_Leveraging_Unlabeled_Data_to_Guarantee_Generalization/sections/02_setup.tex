By $\enorm{\cdot}$, 
and $\inner{\cdot}{\cdot}$
we denote the Euclidean norm
and inner product,
respectively.
For a vector $v\in \Real^d$, 
we use $v_j$ to denote its $j^\text{th}$ entry, and for an event $E$ we let $\indict{E}$ denote the binary indicator of the event.

Suppose we have a multiclass classification problem
with the input domain $\calX \subseteq \Real^d$ 
and label space $\calY = \{1, 2, \ldots, k\}$\footnote{For 
binary classification, 
we use $\calY = \{-1,1\}$.}. 
By $\calD$, we denote the distribution 
over $\calX \times \calY$. 
A dataset $S \defeq \{(x_i, y_i)\}_{i=1}^n \sim \calD^n$
contains $n$ points sampled i.i.d. from $\calD$.
By $\calS$, $\calT$, and $\wt \calS$, 
we denote the (uniform) empirical distribution
over points in datasets $S$, $T$, 
and $\wt S$, respectively. 
Let $\calF$ be a class of hypotheses 
mapping $\calX$ to $\Real^{k}$.  
A \emph{training algorithm} $\calA$:
takes a dataset $S$
and returns a classifier $f(\calA,S) \in \calF$. 
When the context is clear,
we drop the parentheses for convenience.
Given a classifier $f$ and datum $(x, y)$,
we denote the 0-1 error 
(i.e., classification error)
on that point by 
$\error(f(x), y) \defeq \indict{ y\not\in \argmax_{j\in\calY} f_j(x) }$,
We express the \emph{population error} on $\calD$ as
$\error_\calD (f) \defeq \Expt{(x,y) \sim \calD}{\error(f(x),y) }$ 
and the \emph{empirical error} on $S$ as  
$\error_\calS(f) \defeq \Expt{(x,y) \sim \calS}{\error(f(x),y)} = \frac{1}{n} \sum_{i=1}^n {\error(f(x_i),y_i)}$.


Throughout,
% the paper, 
we consider 
a \emph{random label assignment} procedure: 
draw $x\sim \calD_\calX$ 
(the underlying distribution over $\calX$),
and then assign a label sampled
uniformly at random. 
We denote a randomly labeled dataset 
by $\wt S \defeq \{ (x_i, y_i)\}_{i=1}^m \sim \wt \calD^m $, 
where $\wt \calD$
is the distribution of randomly labeled data. 
By $\calDm$, we denote the mislabeled distribution
that corresponds to selecting examples $(x,y)$ 
according to $\calD$ and then re-assigning the label 
by sampling among the incorrect labels $y' \neq y$
(renormalizing the label marginal). 
% Because our analysis centers 
% on uniform label distributions, 
% The reader can think of $\calDm$ as assigning labels 
% uniformly among the incorrect labels. 

% While $\calDm$ and $\calD$ share 
% the same marginal distribution over $\calX$, 
% the distribution over labels $y$ 
% given an input $x\sim \calD_\calX$ is changed.
% In particular, for any $x$, the pdf over $y$ is changed to:  
% $p_{\calDm} (\cdot \vert x) \defeq \frac{1 - p_{\calD}(\cdot \vert x)}{k - 1}$.


% In particular, define $\calDm \defeq  \wt \calD - \calD$ as the distribution of mislabeled data. 
% \todos{Define this nicely.}  
% For binary classification, $\error(f(x), y)$ reduces to $\indict{ y\not\in \argmax_{j\in\calY} f_j(x) }$


% 
%  CACHED
% 



% \textbf{Notation.} We use $\enorm{\cdot}$ to denote the Euclidean norm. Let $\inner{\cdot}{\cdot}$ represents the standard inner product. For a vector $v\in \Real^d$, we use $v_j$ to access $j^\text{th}(<d)$ element. $\indict{X}$ denotes the indicator of event X.  

% \subsection{Problem Setup}\label{subsec:setup}

% Suppose we have a multiclass classification setup
% with the input domain $\calX \in \mathrm{R}^d$ 
% and the label space $\calY = \{1, 2, \cdots, k\}$\footnote{For 
% binary classification, we will use $\calY = \{-1,1\}$}. 
% We denote the underlying distribution 
% over $\calX \times \calY$ by $\calD$ 
% and let $p_\calD(\cdot)$ denote 
% the corresponding probability density function (pdf). 
% Consider a dataset set 
% $S \defeq \{(x_i, y_i)\}_{i=1}^n \sim \calD^n$
% of $n$ points sampled i.i.d. from $\calD$.
% Define $\calS$ as the uniform distribution over $S$, 
% and more generally we use caligraphic symbols
% to denote 
% % an uniform distribution over a specific dataset.
% the empirical distribution corresponding to a specific dataset.
% Let $\calF$ be a class of hypotheses 
% mapping $\calX$ to $\Real^{k}$.  
% % We now define a
% A \emph{training algorithm} $\calA$:
% % a algorithm that 
% takes in an input a training set $S$ and outputs a classifier $f(\calA,S) \in \calF$. When the training algorithm and the training dataset is clear from the context, we drop the parenthesis.  
% In  classification, we mainly care about the 0-1 error. Given a classifier output $f(x)$, let $\error(f(x), y) \defeq \indict{ y\not\in \argmax_{j\in\calY} f_j(x) }$ denote the (top 1) classification error of a data point $(x,y)$. We define $\error_\calD (f) \defeq \Expt{(x,y) \sim \calD}{\error(f(x),y) }$ as the \emph{population error} on $\calD$ and $\error_\calS(f) \defeq \Expt{(x,y) \sim \calS}{\error(f(x),y)} = \frac{1}{n} \sum_{i=1}^n {\error(f(x_i),y_i)}$ as the \emph{empricial error} on $S$.  
% The \emph{generalization gap} of a classifier $f_S$ obtained by training algorithm $\calA$ with training data $S$ is the expected difference between its test error $(\error_{\calD}(f))$ and its empirical train error  $(\error_{\calS}(f))$. \todos{Fix this to be consistent and maybe define  this in definition? Shall we remove this?}


% Throughout the paper, we consider a \emph{random label assignment} procedure: draw $x\sim \calD_\calX$ (the underlying distribution over $\calX$), and then assign a label randomly sampled from the underlying marginal over $\calY$, i.e. $y \sim \calD_\calY$ (the underlying distribution over $\calY$). For a distribution with uniform label marginal, this procedure assigns labels uniformly at random. We denote a randomly labeled dataset with $\wt S \defeq \{ (x_i, y_i)\}_{i=1}^m \sim \wt \calD^m $, where $\wt \calD \defeq \calD_{\calX}\times \calD_{\calY}$ is the distribution of random labels.
% We now define a mislabeled distribution $\calDm$ for a given clean distribution $\calD$. While $\calDm$ and $\calD$ share the same marginal distribution over $\calX$, the distribution over labels $y$ given an input $x\sim \calD_\calX$ is changed. In particular, for any $x$, the pdf over $y$ is changed to:  $p_{\calDm} (\cdot \vert x) \defeq \frac{1 - p_{\calD}(\cdot \vert x)}{k - 1}$.
% % In particular, define $\calDm \defeq  \wt \calD - \calD$ as the distribution of mislabeled data. 
% % \todos{Define this nicely.}  
% % For binary classification, $\error(f(x), y)$ reduces to $\indict{ y\not\in \argmax_{j\in\calY} f_j(x) }$



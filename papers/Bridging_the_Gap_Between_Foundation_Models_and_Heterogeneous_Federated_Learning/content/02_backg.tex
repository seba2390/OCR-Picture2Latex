\section{Background}
\subsection{Federated Learning}
With growing concerns over data privacy, Federated Learning (FL) has emerged as a decentralized, privacy-preserving machine learning paradigm. It allows model training on private user data without compromising its confidentiality~\citep{mcmahan2017fedavg}. 
In FL, private data remains on local clients, and the target model is optimized locally, ensuring data privacy and security. Clients only share model updates, such as weights and gradients, asynchronously, minimizing the risk of data leaks.
A representative FL algorithm is FedAvg~\citep{mcmahan2017fedavg}. The innate privacy features of FL have made it a preferred choice in various applications, especially in sectors with stringent privacy requirements like healthcare.


However, data and resource heterogeneity in FL often lead to training failures. Unbalanced training across clients leads to poor model convergence and performance. Recent work in FL has focused on improving gradient descent to stabilize training~\citep{liu2020momentum_fl,karimireddy2020scaffold,li2020fedprox}; personalizing model weights to enhance performance on downstream tasks~\citep{deng2020adaptive_pfl,tan2022personalizedfl,yu2022rafl}; and employing model compression techniques like knowledge distillation~\citep{yu2022kdfl}, dynamic dropout~\citep{yu2021feddp}, and adaptive pruning to reduce overfitting on non-IID datasets and improve communication efficiency ~\citep{jiang2022pruneFL,yu2021feddp,lin2020feddf,yu2022spatl}.
%  yu2022rafl
%\citep{jiang2022pruneFL,yu2021feddp,lin2020feddf,yu2022spatl,yu2022kdfl,yu2021agmc,yu2022gnnrl}.
Despite these advances, there remains a gap between traditional model training and FL, particularly in heterogeneous FL-edge environments.




\subsection{Foundation Models}
Foundation models (FMs)~\citep{Bommasani2021FoundationModels}, such as the GPT family~\citep{brown2020gpt3,radford2019gpt2}, LLaMA~\cite{touvron2023llama2}, ViT~\citep{dosovitskiy2020vit}, CLIP~\citep{radford2021clip}, and BERT~\citep{kenton2019bert}, stand at the forefront of AI advancements. FMs pre-trained on vast datasets exhibiting remarkable performance across multiple tasks.
The typical lifecycle of an FM encompasses pre-training, fine-tuning, and application. During pre-training, models undergo unsupervised or self-supervised learning on large datasets. The fine-tuning phase tailors them for specific tasks. As an illustration, GPT models~\citep{brown2020gpt3,radford2019gpt2,openai2023gpt4} acquire grammar, syntax, and semantics during pre-training, making subsequent fine-tuning for tasks like text classification or sentiment analysis more effective.
FMs excel in few-shot transfer learning~\citep{brown2020llm-fewshot}, making them particularly suited for data-heterogeneous FL environments where limited and imbalanced local data are present. However, the inherent large size and resource-hungry of FMs pose significant challenges to seamlessly apply in FL settings.

% The superior strengths of FMs in few-shot transfer learning~\citep{brown2020llm-fewshot}, making them ideal for non-IID FL environments, where local data are insufficient and unbalanced. However, substantial size of FMs making them deployment on FL challenging.

% Recent work in FL identified FMs as an ideal solution to address the data heterogeneous and privacy challenges in FL~\citep{zhuang2023foundationfl,arora2022fm_privacy}.















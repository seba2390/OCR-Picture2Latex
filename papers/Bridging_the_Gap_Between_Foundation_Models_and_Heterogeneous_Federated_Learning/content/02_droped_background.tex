\section{Background}
\subsection{Federated learning}
As concerns about user data privacy grow, there is an increasing need for AI models to be trained on decentralized data without sharing private information between clients. Federated Learning (FL) has emerged as a solution to this problem, offering a distributed and privacy-preserving machine learning approach that enables training on decentralized data without compromising data privacy~\cite{}.


In FL, raw data remains on local clients, ensuring data privacy and security while also enabling collaborative learning across multiple clients. The FL process involves local model training, model aggregation, and global model updates. Throughout this process, clients only share model updates, such as weights and gradients, asynchronously, reducing bandwidth requirements and minimizing the risk of data leaks and breaches.
A typical FL algorithm is FedAvg~\cite{}, which demonstrates the FL process (see Algorithm~\ref{algo:fedavg}). The privacy-preserving nature of FL has led to its widespread adoption in various applications, particularly in privacy-sensitive domains like healthcare.

\input{content/algorithm/fedavg}

However, FL still faces challenges related to heterogeneous data distribution. Data may be non-independent and identically distributed (non-IID) across clients, leading to poor model convergence and performance. Recent work in FL has focused on improving gradient descent to stabilize training~\cite{}; personalizing model weights to enhance performance on downstream tasks~\cite{}; and employing model compression techniques like knowledge distillation, dynamic dropout, and adaptive pruning to reduce overfitting on non-IID datasets and improve communication efficiency (Add specific examples of prominent works here).
(Add specific examples of prominent works here)

Despite these advances, there remains a gap between traditional model training and FL, particularly in terms of performance when dealing with heterogeneous data distributions.




\subsection{Foundation model}
Foundation Models (FMs) have emerged as a driving force in the field of AI, with large-scale pre-trained models such as GPT-3~\cite{}, GPT-4~\cite{}, ViT~\cite{}, CLIP~\cite{}, and BERT~\cite{} serving as the foundation for a wide variety of downstream tasks. These models are trained on massive amounts of data and have demonstrated remarkable capabilities across multiple domains. 
The lifespan of FMs usually includes pre-training, fine-tuning and transfer learning, and application.

First, the training process of FMs consists of two stages pre-training and fine-tuning in the lifespan of FMs. This two-stage process is crucial for the success of Foundation Models, as it enables them to learn general representations from large-scale datasets during pre-training and adapt to specialized tasks during fine-tuning. In the pre-training stage, which is usually an unsupervised or self-supervised learning process, models are trained on vast amounts of data. This is followed by the fine-tuning stage, where, given the broad knowledge FMs gain from the pre-training stage, they can be easily fine-tuned and transferred to specialized downstream tasks using supervised learning with labeled data.

For instance, Generative Pre-trained Transformer (GPT)~\cite{} is pre-trained on predicting the next word in a sequence given the context of the previous words in an unsupervised manner. During pre-training, GPT learns to generate text by completing sentences, which helps it capture grammar, syntax, semantics, and factual knowledge from the training data. This makes it easy to fine-tune GPT for a broad range of downstream tasks, such as text classification, sentiment analysis, translation, and summarization.



In application stage of FMs, 


\subsubsection{Newly Emerging Research in FMs}
One inspiring and charming of FMs is their extraordinary ability of adaptive to donwstream tasks with few-shot or even zero-shot learning. New research areas emerges to exploit such potential of FMs, such as Prompt Engineering, In-context Learning, etc.
In recent years, the AI research community has been actively exploring and developing novel techniques and strategies to leverage the full potential of foundation models. These emerging research areas seek to improve the adaptability, efficiency, and interpretability of FMs while reducing their reliance on extensive fine-tuning and labeled data. In this subsection, we will discuss some of the most promising and influential research directions in the field, including prompt engineering, zero-shot and few-shot learning, in-context learning, and continual/lifelong learning. By examining these cutting-edge advancements, we aim to provide a comprehensive understanding of the current state of the art in foundation model research and to highlight the immense opportunities that lie at the intersection of federated learning and foundation models.

\paragraph{Zero-Shot and Few-Shot Learning:} 
%1. brief introduce zero-shot and few-shot learning in FMs
%2. why FMs superior on zero and few shot learning
%3. examples on various of applications and use cases, also given the reference/
Zero-Shot and Few-Shot Learning are learning paradigms where models are required to adapt to new tasks without any labeled examples (zero-shot) or with very few labeled examples (few-shot). Foundation Models exhibit remarkable capabilities in these learning settings, allowing them to adapt to new tasks without or with very little task-specific training data. The superior performance of FMs in these paradigms can be attributed to the vast amounts of knowledge and general language understanding they acquire during the pre-training phase. FMs, such as CLIP~\cite{}, GPT-3~\cite{}, GPT-4~\cite{}, etc, have been proven that they can efficiently generalize to a wide range of applications and use cases, such as natural language understanding, machine translation, and sentiment analysis~\cite{}.
However, despite the remarkable success of FMs in zero-shot and few-shot learning, there are limitations and challenges to be addressed. For instance, the performance of FMs in these settings might be sensitive to the choice of prompts or task formulations, and they may struggle with tasks that require reasoning or knowledge outside their pre-training data. By investigating these challenges and exploring novel approaches, researchers aim to further enhance the adaptability and robustness of FMs in zero-shot and few-shot learning scenarios.







\paragraph{Prompt Engineering.} 
%1.what is prompt engineering
%2. why is important? (becasue we can get better performance)
%3. what kind of type we have? template, prompt tuning/insturction tuning
%4.give example and related work
Prompt Engineering is an emerging technology that focuses on optimizing the interaction between users and Foundation Models by carefully crafting and selecting prompts, thereby improving performance on downstream tasks. The significance of prompt engineering stems from its ability to fully exploit the potential of FMs and substantially enhance the accuracy and relevance of model responses, while minimizing the need for extensive fine-tuning.
Various methods for prompt engineering have been proposed. Prompt templates~\cite{} employ manually crafted and pre-defined linguistic patterns or structures to generate prompts. In contrast, prompt tuning~\cite{} and automated prompt generation~\cite{} involve training AI models or utilizing large language models to generate or discover high-quality prompts. Instruction tuning~\cite{}, a related method, is similar to prompt tuning but places greater emphasis on refining the model's understanding of natural language instructions embedded within the prompts. By fine-tuning the model on a dataset of input-output pairs, instruction tuning enhances the model's responsiveness and adaptability to a variety of tasks.

\paragraph{In-context Learning:} 
%1. briefly introduce what is in-context learning
%2. give related work and specific examples.
In-context Learning is a learning paradigm in which Foundation Models adapt to new tasks by leveraging the context provided within the input sequence itself. This approach allows FMs to learn from a series of examples or instructions, supplied as part of the input, without the need for explicit fine-tuning or labeled examples. In-context learning has been demonstrated to be effective in various applications, such as question-answering and programming tasks, with models like GPT-3 and GPT-4 showcasing impressive performance in these scenarios~\cite{}.
Recent work has explored different strategies for improving in-context learning, such as refining the input formatting or providing multiple examples within the context~\cite{}. One potential avenue for future research is the integration of in-context learning with federated learning in the context of Federated Foundation Models. This approach could enable models to learn from diverse, distributed data sources in a privacy-preserving manner, while still benefiting from the advantages of in-context learning. Investigating the combination of these techniques could lead to more robust and adaptable models that can efficiently learn from a wide range of data sources and contexts.

% \paragraph{Model compression:} Methods such as dropout, weight decay, and layer normalization can be employed to prevent overfitting and improve the generalization of Foundation Models. These techniques are important for mitigating the impact of non-IID data in Federated Learning, ensuring more robust and accurate models.


% Challenges and Limitations
% \subsubsection{Challenges and Limitations}
% Despite their remarkable success, Foundation Models present several challenges and limitations, including biases, ethical concerns, and the need for large-scale data and computation. Integrating Foundation Models with Federated Learning brings unique challenges, such as maintaining data privacy and dealing with non-IID data distributions. Research in this area aims to address these challenges and explore potential solutions to enhance the capabilities of Federated Foundation Models, paving the way for more robust, accurate, and privacy-preserving AI systems.

In summary, there are great opportunities in the intersection of FL and FM, 
which has the potential to revolutionize the AI landscape by leveraging the strengths of both paradigms. 
% Federated learning allows for decentralized and privacy-preserving data processing, enabling models to learn from a diverse range of data sources without violating user privacy. Meanwhile, foundation models excel at capturing rich representations and generalizing knowledge across a multitude of tasks. By integrating these two powerful approaches, we can create a new generation of AI systems that are not only more accurate and adaptive but also respectful of user privacy and data security.
This combination opens up numerous research directions and applications, ranging from personalized recommendations and natural language understanding to healthcare, finance, and beyond. As the AI research community continues to explore the intersection of federated learning and foundation models, we believe that a wide array of innovative solutions and breakthroughs will emerge, leading to more robust, efficient, and ethical AI systems that can better serve the needs of individuals and society as a whole.


%The Need for Federated Foundation Models

% \section{Foundation Models: A Brief Overview}
% \subsubsection{Definition and characteristics}
% Foundation Models~(FMs) are large-scale pre-trained machine learning models that serve as a starting point for downstream task-specific fine-tuning. These models, typically based on deep neural networks, capture a broad range of knowledge from diverse data sources and can be efficiently adapted to a wide array of tasks with minimal fine-tuning. 
% Key characteristics of foundation models include:

% \begin{itemize}
% \item Pre-training: Foundation models are trained on massive datasets to learn general-purpose features and representations.
% \item Transfer learning: These models can be fine-tuned with smaller labeled datasets for specific tasks, leading to improved performance and reduced training time.
% \item Multi-modal and multi-task capabilities: Foundation models can be designed to handle various data modalities (e.g., text, images, audio) and multiple tasks simultaneously.
% \end{itemize}

% \subsubsection{State-of-the-art foundation models}
% Transformer-based FMs have been developed in recent years and achieved state-of-the-art~(SoTA) performance in a wide range of scientific domains, particularly in natural language processing (NLP) and computer vision (CV). Some notable examples include:

% \begin{itemize}
% \item {BERT} (Bidirectional Encoder Representations from Transformers) \cite{devlin2018bert}: A transformer-based model that has achieved groundbreaking results in various NLP tasks, including question answering, sentiment analysis, and named entity recognition.
% \item {GPT} (Generative Pre-trained Transformer) \cite{radford2018improving}: Another transformer-based model initially designed for language modeling but has been successfully applied to a wide range of NLP tasks, with its latest version, GPT-3 \cite{brown2020language}, being one of the largest and most powerful language models available.

% % \item \textbf{ResNet} (Residual Networks) \cite{he2016deep}: A deep convolutional neural network (CNN) architecture for image recognition that introduced residual connections to alleviate the vanishing gradient problem, enabling the training of much deeper networks.

% \item {ViT} (Vision Transformer) \cite{dosovitskiy2020image}: A transformer-based model adapted for computer vision tasks, such as image classification and object detection, which demonstrates the potential of transformers to generalize beyond NLP tasks.
% \end{itemize}
% \subsubsection{Pre-training}
% Pre-training is the initial phase in the development of foundation models, where models are trained on large-scale datasets to learn general-purpose representations. This process involves unsupervised or self-supervised learning techniques, such as language modeling for natural language processing (NLP) tasks, or contrastive learning for computer vision tasks. Pre-training aims to: 
% Capture diverse knowledge and semantic structures from large-scale data sources.
% Learn transferable representations that can be efficiently adapted to downstream tasks.
% Reduce the need for extensive labeled data for task-specific fine-tuning.


% Recent advances in pre-training techniques have focused on improving efficiency, scalability, and transferability of foundation models \cite{liu2021gpt}. For example, methods like layer-wise learning rate adaptation \cite{you2020large} and model distillation \cite{hinton2015distilling} have been proposed to speed up the pre-training process and reduce computational requirements.

% \subsubsection{Fine-tuning and Transfer Learning}
% Once the foundation models are pre-trained, they can be fine-tuned on specific tasks using smaller labeled datasets. Fine-tuning involves updating the model's parameters through supervised learning to optimize performance on the target task. There are several approaches to fine-tuning, including instruction tuning and multi-task tuning:


%  \textbf{Instruction Tuning:} This approach involves training the model to understand and follow natural language instructions, allowing it to generalize across a range of tasks with minimal explicit supervision \cite{schick2021exploiting}. Instruction tuning typically requires modifying the model's input and output formats and adapting its loss function to the specific task.

%  \textbf{Multi-task Tuning:} In this approach, the foundation model is fine-tuned on multiple tasks simultaneously, which encourages the model to learn shared representations that generalize across tasks \cite{ruder2017overview}. Multi-task tuning can involve training the model on a combination of tasks with shared or separate task-specific layers, and may require designing novel training objectives and evaluation metrics to balance the trade-offs between tasks.

% \subsubsection{Prompting and Zero-shot Learning}
% Prompting and zero-shot learning are techniques that leverage the generalization capabilities of foundation models without requiring task-specific fine-tuning. These methods enable the models to perform new tasks by:

%  \textbf{Prompting:} Providing the model with a carefully designed input query or prompt, which guides the model to generate the desired output. This approach relies on the model's pre-trained knowledge and its ability to understand and respond to natural language instructions \cite{shin2020autoprompt}.
%  \textbf{Zero-shot Learning:} Training the model to recognize and classify novel instances or concepts without any prior exposure to labeled examples from those classes. Zero-shot learning often involves the use of auxiliary information, such as class descriptions or semantic embeddings, to bridge the gap between the pre-trained model and the target task \cite{soares2019matching}.

% \subsubsection{Challenges and limitations}
% Despite their remarkable performance, foundation models face several challenges and limitations, including:

% \begin{itemize}
% \item \textbf{Computational resources:} Training foundation models requires substantial computational power and energy, which may not be accessible to all researchers and organizations.

% \item \textbf{Data biases:} Foundation models can inherit biases present in their training data, which may lead to unintended consequences and ethical concerns when applied to real-world tasks \cite{bender2021dangers}.

% \item \textbf{Model interpretability:} Due to their complex nature, understanding the decision-making process of foundation models remains a challenge, limiting their applicability in safety-critical and regulated domains.

% \item \textbf{Adaptation to new tasks and domains:} While foundation models exhibit strong transfer learning capabilities, their performance may still be suboptimal for tasks or domains with limited available data or unique characteristics that deviate significantly from their pre-training data.
% \end{itemize}

% % \section{Background: Foundation Model Optimization}

% Foundation models have demonstrated remarkable performance across a wide range of tasks and domains. However, there is still room for improvement in terms of efficiency, generalization, and applicability. This section provides an overview of the key optimization strategies employed for foundation models, which include pre-training, fine-tuning, and prompting and zero-shot learning.



\input{content/f02_ffm_tasks}
\section{Federated Foundation Models}
In this section, we introduce and discuss potential tasks and applications related to Federated Foundation Models~(FFMs), including:
\begin{itemize}
\item Federated Foundation Model Pre-training
\item Federated Foundation Model Fine-tuning
\item Federated Prompt Engineering
\item Federated Continual (Lifelong) Learning
\end{itemize}
We examine the unique characteristics and requirements of these tasks, highlighting the opportunities and challenges that arise when leveraging FFMs to tackle real-world problems. Our goal is to establish a solid foundation for understanding the scope and potential of this new paradigm, paving the way for future research and development. As mentioned in Section~\ref{sec:prospective}, some tasks may not be feasible until computational power at the edge advances further.

\subsection{Federated Foundation Model Pre-training}
% The motivation for FFM pre-training is not to replace traditional FM pre-training methods but to enhance them by applying FL's ability to leverage private data for improved model generalizability while maintaining data privacy. By utilizing private data, the model can access a wider range of knowledge, reduce the risk of overfitting public data, and potentially enable more personalized and context-aware models, all while the FM can still learn from well-crafted centralized data.
Federated Foundation Model pre-training~(FFM pre-training) aims to enhance traditional FM pre-training methods by incorporating Federated Learning's~(FL's) ability to leverage private data for improved model generalization while maintaining data privacy. This allows the model to access a wider range of knowledge, reduce overfitting on public data, and potentially enable more personalized and context-aware models, while still benefiting from centralized data.


The FFM pre-training process involves two stages: centralized pre-training on public data and federated pre-training on private data. As shown in Figure~\ref{fig:FFM_tasks}, these stages interact through an adaptive switching mechanism, allowing the model to alternate between centralized pre-training and federated pre-training.
For example, an FFM pre-training round may involve pre-training the model on public data for $n_c$ epochs using existing FM pre-training methods, followed by pre-training for $n_f$ epochs on private data via federated learning. The FFM can also first pre-train via FL and then on centralized public data, providing a flexible and adaptive process. Existing federated learning algorithms can be adapted for FM pre-training to enable seamless integration of federated learning benefits.

The main advantage of FFM pre-training is its flexibility, as it builds on existing FM pre-training methods without extensive modifications. This approach can easily incorporate future advancements in FM pre-training while maintaining the benefits of both existing methods and federated learning. However, it is crucial to consider the available computational resources on edge devices when deploying Foundation Models locally. Advancements in computational power will be essential for enabling local deployment on a wide range of devices, ensuring efficient performance across various tasks and domains.
% The Federated Foundation Model Pre-training methodology builds on top of existing FM pre-training methods and integrates federated learning into the process. As shown in Figure~\ref{} and Algorithm~\ref{}, the Federated Foundation Model pre-training process can be described as the interaction of two types of training: centralized pre-training on public data and federated pre-training on private data. These two stages of pre-training interact with each other through the Federated Foundation Model pre-training process, where the FM adaptively switches between centralized pre-training on public data and federated pre-training on distributed private data.

% For instance, a Federated Foundation Model pre-training round can be formulated as follows: the FM is first pre-trained on public data for $n_c$ epochs via existing FM pre-training methods, and then pre-trained for $n_f$ epochs on private data using federated learning. Alternatively, the Federated Foundation Model is highly flexible and adaptive, allowing for the possibility to pre-train via FL first, then pre-train on centralized public data. To achieve this, existing federated learning algorithms can be adapted for Foundation Model pre-training, allowing for a seamless integration of federated learning benefits into the pre-training process.

% One of the main advantages of Federated Foundation Model Pre-training is its flexibility. As it builds on top of existing FM pre-training methods without extensive modifications, this approach can easily incorporate future advancements in FM pre-training while maintaining the benefits of both existing FM pre-training methods and federated learning. This flexibility allows for a more robust and adaptable pre-training process, resulting in models that are better suited for a wide range of tasks and applications.

% Again, it is essential to consider the available computational resources on edge devices when deploying Foundation Models locally. As discussed in the Scalability section, advancements in computational power will be crucial for enabling the local deployment of Foundation Models on a wide range of devices, ensuring efficient and effective performance across various tasks and domains.
% Explanation of the Federated Foundation Model and its components
% Technical details of implementing the Federated Foundation Model
% Evaluation metrics and criteria for success

%benefit of federated FM fine-tuning vs simply deploy and personalized FMs.
\subsection{Federated Foundation Model Fine-tuning}
Traditional FM fine-tuning often involves offline deployment, where the model is fine-tuned on private data and then isolated, preventing collaboration between end-users. This approach may not fully exploit the potential of the FM, especially when local private data is limited or biased.
Federated Foundation Model fine-tuning (FFM fine-tuning) addresses these limitations by fostering collaboration between end-users while preserving data privacy. This approach allows for direct fine-tuning of FMs on private data at the edge for downstream tasks while sharing the fine-tuned FMs with other clients/end-users, enabling a more robust and better-performing model.

As shown in Figure~\ref{fig:FFM_tasks}, FFM fine-tuning builds upon FFM pre-training and employs an adaptive switching mechanism that alternates between centralized fine-tuning on public datasets for benchmark tasks and federated fine-tuning on private data with local tasks. We propose two FFM fine-tuning strategies: (1) directly fine-tuning the FM backbone, and (2) fine-tuning a lightweight adapter head while keeping the FM backbone frozen.

In the first strategy, the FM backbone's weights are updated on user private data and evaluated on local tasks, then uploaded to the server for aggregation across all clients. The server also leverages public data to fine-tune the aggregated FM on benchmark tasks. However, the complexity of FMs can make this strategy difficult to apply at the edge right now, particularly in resource-limited scenarios.

To address this challenge, we propose the second strategy of fine-tuning a lightweight adapter head while keeping the FM backbone frozen. This approach uses an adapter to transfer the FM's capabilities directly to local tasks, sharing only the lightweight adapter between the edge and the server. This improves efficiency in both computation and communication while maintaining the benefits of FFM fine-tuning. Moreover, due to the scalability and heterogeneity of FL, FFM fine-tuning can be easily extended to multi-modal tasks.

In summary, FFM fine-tuning provides a promising alternative to traditional FM fine-tuning, offering increased privacy, collaboration, adaptability, and efficiency. This approach has the potential to improve both the performance and generalizability of Foundation Models across various applications and domains.















% Similar to Federated Foundation Model Pre-training, the Federated Foundation Model fine-tuning methodology builds upon traditional federated learning approaches. It deploys the FM at edge institutions and fine-tunes the FM on private data at the edge. Within the fine-tuning process, the participate institutions can share their fine-tuned model to aggregate to a more generalized global model.

% One of the benefits of federated fine-tuning is that it enables collaboration with other private institutions that have similar downstream tasks, allowing for more efficient fine-tuning through shared knowledge and expertise.
% Another key advantage of Federated Foundation Model fine-tuning is the enhanced privacy it offers, as private data never leaves the edge institutions. Furthermore, the adaptability of the Federated Foundation Model fine-tuning methodology allows it to be tailored to different edge institutions and their specific downstream tasks, leading to more personalized and context-aware models.

% Overall, Federated Foundation Model fine-tuning offers a promising alternative to traditional FM fine-tuning, with increased privacy, collaboration, adaptability, and efficiency. This approach has the potential to improve both the performance and generalizability of Foundation Models across a wide range of applications and domains.

\subsection{Federated prompt engineering}
Integrating FL into prompt engineering has promising potential for enhancing the performance of FMs while preserving data privacy. For instance, FFMs can enable the use of sensitive data in prompt templates, allowing more accurate and personalized prompt conditioning for tasks like in-context learning. By providing contextual priors or examples from private data, the model can better understand and generate context-aware responses while ensuring the sensitive data never leaves the local end-user.

Here we mainly discuss the automated prompt (soft prompt) methods, such as instruction tuning~\cite{wei2021prompt}, which refines the model's understanding of natural language instructions, and prompt tuning~\cite{lester2021prompt_tune}, which tailors the input prompt to improve the model's output. As shown in Figure~\ref{fig:FFM_tasks}, in federated prompt engineering settings, 
In federated prompt engineering settings, end-users can collaboratively train auto prompt models (prompt generator components in Figure~\ref{fig:FFM_tasks}) on their local private data and tasks, sharing the learned auto prompt models without exposing the sensitive data. 
This collaborative process allows for the creation of more effective and adaptable prompts, improving the overall performance of Foundation Models on downstream tasks.

Federated prompt engineering not only facilitates the development of better prompts using private data but also maintains the privacy of sensitive information. By combining the advantages of FL with the power of FMs, federated prompt engineering opens up new possibilities for the deployment of AI systems across various domains and applications.









\subsection{Federated continual (lifelong) learning}
One disadvantage of FMs is their limitation to pre-trained, offline knowledge. For example, ChatGPT's knowledge is up-to-date only until 2021. With the anticipated increase in computational power, FM optimization at the edge may become feasible. FFMs can unlock the possibility of continual/lifelong learning from newly generated private edge data. With its scalability and privacy-preserving nature, FL can harness decentralized power to optimize FMs using emerging private data at the edge, which can serve as a valuable resource for model optimization.

In terms of methodology, a federated server can be established to facilitate communication between the server and edge end-users. The Foundation Model is optimized at the edge, with local updates sent to the server for aggregation. This process keeps the global model up-to-date while preserving data privacy, as local private data remains at the edge and is never directly shared. The server then sends the updated global model back to the edge institutions or clients, ensuring that each participant benefits from the collaborative learning process.

Moreover, federated continual/lifelong learning can contribute to more efficient use of resources, as institutions no longer need to retrain their models from scratch whenever new data becomes available. By leveraging federated learning, institutions can incrementally improve their models, reducing the time and computational resources required for model training and refinement.

One additional point to consider is the adaptability of Federated Continual/Lifelong Learning to handle non-stationary data distributions. As the world is constantly changing, data distributions may shift over time. This approach enables the continual adaptation of FMs to ever-changing real-world scenarios, enhancing their performance in dynamic environments.







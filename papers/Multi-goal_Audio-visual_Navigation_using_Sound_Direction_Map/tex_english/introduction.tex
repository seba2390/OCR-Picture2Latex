\section{INTRODUCTION}

Visual navigation tasks in indoor environments with deep reinforcement learning agents have been a research area of particular interest in the last decade.
Basic visual navigation uses only visual information in the form of first-person images to navigate to a single goal.
In recent years, more advanced tasks have emerged, such as audio-visual navigation~\cite{chen2020soundspaces}, which uses auditory as well as visual information to navigate to a sound source, and multi-object navigation (MultiON)~\cite{wani2020multion}, which navigates to not one but multiple goals. 
However, a task that uses both visual and auditory information to navigate to multiple sound source goals, i.e., a combination of audio-visual navigation and MultiON, has not yet been proposed.
In terms of real-world applications, there are many tasks, such as lifesaving or bird and animal control, where auditory information is helpful and there is not necessarily a single goal.
%It is rather natural to assume that there are multiple goals in these tasks.

\begin{figure}[t]
    \begin{center}
        \centering
        \includegraphics[width=\linewidth]{fig/multi-goal-audio-visual-navigation.pdf}
        \caption{
            Overview of the multi-goal audio-visual navigation.
            Here, navigation is performed to three different sound sources in an indoor environment.
            The agent observes the first-person visual information and the auditory information, which is a superposition of sounds from three different sound sources. The agent must make appropriate action choices.
        }
        \label{fig:multi_goal_av_nav}
    \end{center}
\end{figure}

% Therefore, with these applications in mind, it would be worthwhile to study navigation tasks to multiple sound source goals that use both visual and auditory information. Audiovisual navigation alone would throw away valid information obtained to reach a single goal. Multi-object navigation alone would throw away valid information in the form of auditory information. However, to be able to perform efficient navigation, the available valid information should be handled as much as possible without discarding it.
In this study, we propose a new task \textit{multi-goal audio-visual navigation} (Fig.~\ref{fig:multi_goal_av_nav}), which combines audio-visual navigation and MultiON.
There are three key elements to solving multi-goal audio-visual navigation:
sound source separation, memory, and action planning.
First, the reinforcement learning agent observes images and spectrograms of multiple overlapping sounds.
Therefore, accurate sound source separation plays an important role in improving the accuracy of sound source localization.
In addition, by remembering the information acquired before reaching one goal, it is expected to be able to efficiently navigate to the next goal.
Finally, action planning is important because it is necessary to infer which sound source should be the next goal to make an efficient route plan.

This study has two objectives.
The first objective is to identify where the difficulties in multi-goal audio-visual navigation lie by conducting experiments in various situations.
% As mentioned earlier, there is no prior research on Audio-Visual Navigation in the presence of multiple sound source goals.
% This study aims to clarify where the difficulty lies in Multi-Goal Audio-Visual Navigation by conducting experiments under a variety of situations.
The second objective is to propose a new method for solving multi-goal audio-visual navigation with higher accuracy.
To overcome the difficulties found in this new task, we propose a method based on implicit dynamic multiple sound source localization, which is named a sound direction map (SDM).
The SDM aids path planning by simultaneously localizing multiple sound sources in a learning-based manner.
The SDM is dynamically updated by making effective use of memory.
This dynamic updating method can potentially improve the performance of sound source separation by utilizing previously predicted sound source localization information.

The three main contributions of this paper are summarized as follows.

\begin{itemize}[leftmargin=*]
\item A new navigation framework \textit{multi-goal audio-visual navigation} is proposed. We tested in a variety of situations to examine where the difficulties of this task lie.
\item As an efficient method for solving the new task, we propose the sound direction map (SDM), which represents the history of implicitly predicted dynamic multiple sound source locations.
\item In SoundSpaces 2.0~\cite{chen2022soundspaces}, we show that the proposed SDM consistently improves the performance of multiple baseline methods in all situations.
\end{itemize}
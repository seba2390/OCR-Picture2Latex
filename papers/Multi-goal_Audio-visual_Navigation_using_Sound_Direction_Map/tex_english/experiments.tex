\section{Experiments}

\subsection{Implementation Details}

\subsubsection{Simulation}
Agents were trained and tested on a simulator named SoundSpaces \cite{chen2020soundspaces, chen2022soundspaces} and a scene dataset named Replica \cite{straub2019replica}.
SoundSpaces 2.0 \cite{chen2022soundspaces} used in this study is a simulator that extends a visual rendering simulator Habitat-Sim \cite{savva2019habitat} by integrating an acoustic propagation engine RLR-Audio-Propagation. 
Replica is a scene dataset consisting of 18 different apartment, office, room, and hotel scenes.

Scenes for training, validation, and testing are divided in the same way as in the previous study \cite{chen2020soundspaces}.
Therefore, scenes not used during training are used during testing.
Also, we did not use the dataset for validation but tested with the parameters obtained from the last parameter update.
Here, the number of test episodes is 1,000 for all experiments.


\subsubsection{Episode generation}

In this study, $\boldsymbol{p}_s, \theta_s, \boldsymbol{p}_{g_1}, ... , \boldsymbol{p}_{g_n}$ are subject to some constraints when they are generated to eliminate episodes that are too easy and too difficult.

First, to eliminate episodes that are too easy, the distances between each point $\boldsymbol{p}_s, \boldsymbol{p}_{g_1}, ..., \boldsymbol{p}_{g_n}$ are to be at least $1\ \mathrm{m}$ apart and the ratio of the geodesic distance to the Euclidean distance is to be greater than $1.1$.
The second reason for the constraint is to eliminate cases where the goal can be reached almost exclusively in a straight line.
However, since it was difficult to satisfy these constraints in room 2 and office 1 due to their narrowness, we decided that the distance between each point should be at least $0.6\ \mathrm{m}$, and the ratio of the geodesic distance to the Euclidean distance should be greater than $1.001$ in these.

To eliminate episodes that are too difficult, the height between each point was made to be less than $0.3\ \mathrm{m}$, and the distance (m) between each point $d$ was made to be less likely to increase in apartment 0 due to its wideness.
Specifically, the locations are rejected with probability $p=1.0$ if $d>10$, with $p=0.7$ if $d>6$, with $p=0.6$ if $d>5$, with $p=0.5$ if $d>4$, with $p=0.4$ if $d>3$, and with $p=0$ if $d<3$.
The reason for this constraint is that we found that without this constraint, the performance in only apartment 0 would be significantly lower and the learning curve would be unstable.
We believe that the essential solution to this problem requires the introduction of curriculum learning.




\subsubsection{Sound sources}
Unless otherwise noted, we use 73 different sound sources for training and 18 different sound sources for testing, following the previous study \cite{chen2020soundspaces}.
Here, there are no sound sources that overlap between training and testing.
Therefore, the test evaluates generalization performance for sounds that were never heard during training.

All sound source is $1$ second of sound data sampled at a sampling frequency of 44,100$\ \mathrm{Hz}$.
This sound data is played repeatedly until the agent reaches its sound source.
Unless otherwise noted, in each episode, the sound data is made to start playing at a random time between $0$ and $1$ seconds.


\subsection{Comparison by the number of goals}
\label{comparison-by-the-number-of-goals}
First, an experiment was conducted using the baseline methods, varying only the number of goals.
The purpose of this experiment was to investigate the differences in difficulty with the number of goals.
The number of goals $n$ was performed in three ways: $n=1,2,3$.
The test results are shown in TABLE \ref{tab:n_goal_results}.


\begin{table}[tb]
    \setlength{\tabcolsep}{4pt}
    \centering
    \caption{
        Comparison by the number of goals.
        % $n$ denotes the number of goals.
        Here, the number of goals is $n$, meaning that there are $n$ goals in all episodes of training and testing.
    }
    \label{tab:n_goal_results}
    \begin{tabular}{@{}cccccc@{}}
    \toprule
        Method & $n$ & $SUCCESS$ & $SPL$ & $PROGRESS$ & $PPL$ \\ \midrule
        Random & 1 & \textbf{0.432} & \textbf{0.141} & \textbf{0.432} & \textbf{0.141} \\
        & 2 & 0.167 & 0.048 & 0.377 & 0.070 \\
        & 3 & 0.053 & 0.017 & 0.317 & 0.055 \\ \midrule
        AV-Nav~\cite{chen2020soundspaces} & 1 & \textbf{0.503} & \textbf{0.323} & \textbf{0.503} & \textbf{0.323} \\
        & 2 & 0.179 & 0.119 & 0.229 & 0.142 \\
        & 3 & 0.107 & 0.071 & 0.292 & 0.160 \\ \midrule
        SAVi~\cite{chen2021semantic} & 1 & \textbf{0.771} & \textbf{0.507} & \textbf{0.771} & \textbf{0.507} \\
        & 2 & 0.643 & 0.416 & 0.720 & 0.438 \\
        & 3 & 0.226 & 0.138 & 0.449 & 0.215 \\ \bottomrule
        \end{tabular}
\end{table}


We found that increasing the number of goals tends to cause a large drop in accuracy.
We believe there are two reasons for the large drop in $SUCCESS$.
The first reason is that $SUCCESS$ degrades exponentially.
This is because if the probability of reaching one goal from the start is $p$, the probability of reaching $n$ goals is $p^n$.
The second reason is that the need for sound source separation arises, which will be discussed in more detail in Section~\ref{invest_difficulties}.
We also believe that the reason for the lower $PROGRESS$ is due to the end condition of the episode.
In this setting, if navigating to a goal in the middle of the episode fails, the episode will end.
Thus, if there are multiple goals remaining, the failure of navigating to one goal will fail to navigate to multiple goals.
This is considered to have lowered $PROGRESS$ as the reachability is lowered.


\begin{figure*}[t]
    \begin{center}
        \centering
        \includegraphics[scale=0.7]{fig/2g-nav-traj.pdf}
        \caption{
            Navigation trajectory comparison.
            The upper row is AV-Nav w/o SDM and the lower row is AV-Nav w/ SDM.
            The color of the Path represents the step elapsed.
            It changes from blue to red as the steps elapse.
            It can be seen that the use of SDM has reduced the number of unnecessary actions.
        }
        \label{fig:qualitative_eval}
    \end{center}
\end{figure*}



\subsection{Investigating difficulties with multiple sound source goals}
\label{invest_difficulties}

We investigate the difficulties that lie in multi-goal audio-visual navigation.
In this section, we used AV-Nav~\cite{chen2020soundspaces} for the navigation performance evaluation.

\subsubsection{Loud and quiet sounds}

We investigated whether the difficulty level varies with the loudness of the sound, i.e., with the volume of the sound.
Here, we compare the difference in reachability to quiet and loud sounds.
The ratio of the number of goals reached to the number of all goals is shown here. In other words, if the goals are selected from the same set, it is the same as $PROGRESS$. However, if the goals are selected from different sets, it is slightly different from $PROGRESS$.
All of these sounds were selected from those not used in the training.
The sounds were selected so that the average length of the sounds in the quiet sound set and the loud sound set are close to each other.

\begin{table}[tb]
    \caption{
        Comparison of reachability to quiet (top) and loud (bottom) sounds.
        $n$-quiet and $n$-loud means that $n$ goals were selected from the set of quiet sounds and the set of loud sounds, respectively.
        Note that all 73 sound sources for training were used during training.
    }
    \label{tab:loud_and_quiet}
    \centering
    \begin{tabular}{@{}ccccccc@{}}
      \toprule
      & \multicolumn{2}{c}{1-goal task} & \multicolumn{3}{c}{2-goal task} \\
      \cmidrule(lr){2-3} \cmidrule(lr){4-6}
      & 1-quiet & 1-loud & 2-quiet & 2-loud & 1-quiet-1-loud \\ \midrule
      quiet & 0.441 & N/A & 0.232 & N/A & 0.187 \\
      loud & N/A & 0.449 & N/A & 0.209 & 0.253 \\
      \bottomrule
    \end{tabular}
\end{table}

The results are shown in TABLE \ref{tab:loud_and_quiet}.
It shows that the accuracy of both loud and quiet sounds decreases when a loud sound is heard at the same time.
We believe this is because loud sounds can be heard at a distance and therefore tend to become noise even if the other sound is also loud.





\subsubsection{Long and short sounds}

We investigated whether the difficulty level varies with the length of time a sound is played.
Here we compare the difference in reachability to short and long sounds.
As in the previous section, the ratio of the number of goals reached to the number of all goals is shown here. 
All of these sounds were selected from those not used in training.
Also, these sounds were selected so that the average of the maximum volume of the short sound set and long sound set are close to each other.

\begin{table}[tb]
    \centering
    \caption{
        Comparison of reachability to short (top) and long (bottom) sounds.
        $n$-short and $n$-long mean that $n$ goals were selected from the set of short sounds and the set of long sounds, respectively.
        Note that all 73 sound sources for training were used during training.
    }
    \label{tab:long_and_short}
    \begin{tabular}{@{}ccccccc@{}}
    \toprule
      & \multicolumn{2}{c}{1-goal task} & \multicolumn{3}{c}{2-goal task} \\
      \cmidrule(lr){2-3} \cmidrule(lr){4-6}
      & 1-short & 1-long & 2-short & 2-long & 1-short-1-long \\ \midrule
      short & 0.235 & N/A & 0.160 & N/A & 0.141 \\
      long & N/A & 0.632 & N/A & 0.255 & 0.262 \\ \bottomrule
    \end{tabular}
\end{table}

The results are shown in TABLE \ref{tab:long_and_short}.
It shows that the accuracy of both long and short sounds decreases when a long sound is played at the same time.
We believe that this is because long sounds are always being played and thus tend to become noise for the other sound.



\subsubsection{Same and different sounds}

We investigated whether the difficulty level varied depending on whether multiple sound types were the same or different.
Here, "same" 
% does not mean the same at the category level, but rather 
means the same sound data is used.
Also, two types of sound sources were used randomly, allowing duplicates during training. Three situations were performed during testing: two same types, two different types, and two random types allowing duplicates.

\begin{table}[tb]
    \centering
    \caption{
        Comparison in different situations where there are two same, different, and random sounds.
    }
    \label{tab:same_and_different_sound}
    \begin{tabular}{@{}ccccc@{}}
    \toprule
        & $SUCCESS$ & $SPL$ & $PROGRESS$ & $PPL$ \\ \midrule
        same & \textbf{0.193} & \textbf{0.131} & \textbf{0.244} & \textbf{0.155} \\
        different & 0.181 & 0.120 & 0.232 & 0.145 \\
        random & 0.179 & 0.119 & 0.229 & 0.142  \\ \bottomrule
        \end{tabular}
\end{table}

The results are shown in TABLE \ref{tab:same_and_different_sound}.
It was found that accuracy was lower when different sounds were sounding.
We suspect that this is because sounds of different natures reduce the reachability of one sound, just as sounding a loud sound and a quiet sound reduces the reachability of a quiet sound, and sounding a long sound and a short sound reduces the reachability of a short sound when the two sounds are different.
We suspect that when they are different, one is drowned out by the other, thus lowering the reachability.
These results indicate the importance of sound source separation.





\subsubsection{Timing of sounding}


\begin{table}[tb]
    \centering
    \caption{
        Comparison by different timing of two goal sounding.
        Only \textit{telephone} sound was used in this experiment.
        Also, the training is done in a random setting.
    }
    \label{tab:sound_timing}
    \begin{tabular}{@{}ccccc@{}}
    \toprule
        & $SUCCESS$ & $SPL$ & $PROGRESS$ & $PPL$ \\ \midrule
        overlap & \textbf{0.792} & \textbf{0.430} & \textbf{0.868} & \textbf{0.444} \\
        non-overlapping & 0.735 & 0.410 & 0.811 & 0.424 \\
        random & 0.736 & 0.413 & 0.820 & 0.440 \\ \bottomrule
    \end{tabular}
\end{table}

We investigated whether the difficulty varied depending on the timing of multiple sounds sounding.
The results are shown in TABLE \ref{tab:sound_timing}.
When two identical sounds are sounding, the result is that accuracy is lower when there is no overlap between the sounds.
We believe that this is because it is more difficult to localize the sound source when the same sound is played alternately.
Since the number of sound sources is not given to the agent, if the same sound is heard in different places alternately, it may be judged that one sound is coming and going.
Therefore, a method to represent the history of dynamic multiple sound source localization is considered to be important.




\subsection{Sound Direction Map}



\subsubsection{Quantitative evaluation}

To demonstrate the usefulness of SDM, we compared the performance with and without SDM for two baselines.
The results are shown in TABLE \ref{tab:dm_results}.
Here, the experimental procedure is the same as in Section \ref{comparison-by-the-number-of-goals}.
For all the number of goals and all baselines, performance was improved by using SDM.
Furthermore, we found that SDM tended to suppress the degradation caused by an increase in the number of goals.
We believe that the reason is that SDM effectively utilizes memory and allows for more accurate localization for multiple sound sources.

However, these results did not reveal whether there is a limit on the number of achievable goals. The number of goals the agent reached, expressed as $n \times PROGRESS$, still tends to increase when calculated based on the results in TABLE \ref{tab:dm_results}.

\begin{table}[tb]
    \setlength{\tabcolsep}{3pt}
    \centering
    \caption{
        Quantitative evaluation of SDM.
        $n$ denotes the number of goals.
    }
    \label{tab:dm_results}
    \begin{tabular}{@{}llcccc@{}}
    \toprule
        $n$~ & method & $SUCCESS$ & $SPL$ & $PROGRESS$ & $PPL$ \\ \midrule
        1 & AV-Nav~\cite{chen2020soundspaces} & 0.503 & 0.323 & 0.503 & 0.323  \\
        & SAVi~\cite{chen2021semantic} & 0.771 & 0.507 & 0.771 & 0.507 \\
        & AV-Nav~\cite{chen2020soundspaces} w/ SDM & 0.610 & 0.354 & 0.610 & 0.354 \\
        & SAVi~\cite{chen2021semantic} w/ SDM & \textbf{0.838} & \textbf{0.616} & \textbf{0.838} & \textbf{0.616} \\ \midrule
        2 & AV-Nav~\cite{chen2020soundspaces} & 0.179 & 0.119 & 0.229 & 0.142  \\
        & SAVi~\cite{chen2021semantic} & 0.643 & 0.416 & 0.720 & 0.438 \\
        & AV-Nav~\cite{chen2020soundspaces} w/ SDM & 0.332 & 0.172 & 0.506 & 0.232 \\
        & SAVi~\cite{chen2021semantic} w/ SDM & \textbf{0.764} & \textbf{0.464} & \textbf{0.822} & \textbf{0.480} \\ \midrule
        3 & AV-Nav~\cite{chen2020soundspaces} & 0.107 & 0.071 & 0.292 & 0.160 \\
        & SAVi~\cite{chen2021semantic} & 0.226 & 0.138 & 0.449 & 0.215 \\
        & AV-Nav~\cite{chen2020soundspaces} w/ SDM & 0.174 & 0.101 & 0.368 & 0.186 \\
        & SAVi~\cite{chen2021semantic} w/ SDM & \textbf{0.469} & \textbf{0.319} & \textbf{0.615} & \textbf{0.385} \\ \bottomrule
    \end{tabular}
\end{table}



\subsubsection{Qualitative evaluation}




Fig.~\ref{fig:qualitative_eval} compares the trajectories of the agents with and without SDM.
It can be seen that the use of SDM has reduced the number of unnecessary actions.
We believe that this is due to more accurate sound source localization.
In addition, in the cases where AV-Nav w/o SDM failed, there were examples of long wandering.
We believe this may be due to inaccurate sound source localization and the inability to determine where the goal is located.
Also, without SDM, there were cases of failure due to being caught by obstacles.
We believe this is because the SDM has determined that the sound source is on the opposite side of the obstacle.

\begin{abstract}

近年、深層強化学習エージェントによる室内環境のナビゲーションタスクについて、盛んに研究が行われている。
これらの多くは、一人称視点の画像という視覚の情報のみを用いて、ある一つのゴールまでナビゲーションを行うものである。
しかし近年では、音源をゴールとして聴覚の情報も同時に用いるナビゲーションタスクや、ゴールを一つではなく複数にしたナビゲーションタスクまでも提案されている。
一方で、これらを組み合わせて一般化した、複数の音源がゴールとなっている状況下で、視覚と聴覚の二つの情報を用いるナビゲーションタスクは提案されていない。
そこで、本論文ではこの一般化したタスクであるマルチゴール視聴覚ナビゲーションというフレームワークを提案する。
本研究では、まず、マルチゴール視聴覚ナビゲーションタスクの詳細な定義を行った。
次に、様々な異なる状況下で実験を行うことで、従来のタスクに対するマルチゴール視聴覚ナビゲーションタスクの難しさについて調査した。
調査の結果、マルチゴール視聴覚ナビゲーションには暗に音源を分離しなくてはいけないという難しさがあることがわかった。
そこで、本研究ではこのタスクにおける記憶の重要性に着目し、記憶を用いながら動的に複数の音源について定位を行う手法、Sound Direction Map (SDM)を提案した。
実験により、SDMの活用はゴールの数によらずに複数のベースライン手法に対して精度を向上させることを示した。

\end{abstract}


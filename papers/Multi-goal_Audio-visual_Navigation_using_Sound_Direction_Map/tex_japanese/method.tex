\section{METHODS}

\begin{figure}[t]
    \begin{center}
        \centering
        \includegraphics[scale=0.3]{fig/direct_map.pdf}
        \caption{
            Sound Direction Map (SDM)の概要。
            エージェントを囲う黒い円によってSDMが表現されている。
            ここでは、二つの音源がある場合の例を示している。
            エージェントから見て音源方向のSDMのノードの値が高くなる様子が、ノードの色の濃さで表現されている。
        }
        \label{fig:direct_map_abst}
    \end{center}
\end{figure}

\begin{figure*}[t]
    \begin{center}
        \centering
        \includegraphics[scale=0.6]{fig/direct-map-encoder.pdf}
        \caption{
            AV-Nav\cite{chen2020soundspaces}のネットワークアーキテクチャーにSDM作成のためのネットワークを適用した様子。
            Sound Direction Map Encoderが、今回提案するSDM作成のためのネットワークアーキテクチャである。
            ここで、$\boldsymbol{a}_{t}$と$\hat{\boldsymbol{d}}_t$は、それぞれ時刻$t$における、行動を表すワンホットベクトルとSDMの予測を表す。
            入力には、音の観測$A_t$だけではなく、前回の行動を表すワンホットベクトル$\boldsymbol{a}_{t-1}$と前回のSDMの予測$\hat{\boldsymbol{d}}_{t-1}$の二つも入力している。
        }
        \label{fig:direct_map_encoder}
    \end{center}
\end{figure*}

\subsection{Baselines}

本研究ではベースライン手法として、最もシンプルなランダム行動選択方法に加え、二つのよく知られた深層強化学習手法をテストする。
それぞれの手法について、下記に詳しく説明する。

\subsubsection{Random}
このエージェントは、$\{MoveForward, TurnLeft, TurnRight\}$の三つの中から、ランダムに行動を選択する。
ただし、ゴールである音源の半径$1\ \mathrm{m}$未満にエージェントがいる場合は$Found$を必ず選択する。

\subsubsection{AV-Nav \cite{chen2020soundspaces}}
エンドツーエンドの深層強化学習手法。
一人称視点の画像とスペクトログラムを入力とする、GRUをベースとした方策ネットワークを持つ。
これは、視聴覚ナビゲーションタスクで一番はじめに提案された手法であり、最もシンプルな手法である。

\subsubsection{SAVi \cite{chen2021semantic}}
Transformerをベースとした方策ネットワークを持つ深層強化学習手法。
一人称視点の画像とスペクトログラムに加え、エージェントの姿勢と前回の行動を入力とする。
さらに、ゴールとなる音源のカテゴリとその位置を予測するGoal Descriptor Networkを持ち、カテゴリの予測部分は事前学習される。
また、ポリシーの学習は2段階に分かれる。
first stageでは、Transformerのメモリーサイズを1にしてObservationの埋め込みを学習する。
second stageでは、Observationの埋め込みの学習をfreezeさせてメモリーサイズを150にしてその他の場所を学習させる。

本研究の対象タスクはSemantic Audio-Visual Navigation~\cite{chen2021semantic}ではないことと、マルチゴールへの拡張の困難さのため、本研究ではGoal Descriptor Networkは使っていない。


\subsection{Proposed Method}


以下では、記憶を用いて明示的かつ動的に複数の音源の定位を行うことを可能にする提案手法、Sound Direction Map (SDM)について説明する。

SDMとは、エージェントを中心として、どの方向のどれくらい離れた場所に音源があるのかを表すものである。
図\ref{fig:direct_map_abst}では、エージェントを囲う黒いノードでSDMが表現されている。
SDMでは、エージェントから音源までの距離が近ければ近いほど、その音源の方向にあるノードの値が高くなる。
こうすることで、SDMは、複数の音源に対して方向と距離による音源定位を可能にする。
ただし、同じ方向に複数音源がある場合は最も近い音源だけが考慮される。

各ノードの値は、その方向にある音源までのGeodesic Distanceの逆数としている。
ここで、ユークリッド距離ではなく測地線距離を用いた理由は、音波は壁などの障害物によって反射・回折・減衰を起こすため、測地線距離の方が予測がしやすいと考えたからである。
また、今回は距離が$1\ \mathrm{m}$以内の音源に対しては、クリッピングを行っている。
これには二つの理由がある。一つは、エージェントは半径$1\ \mathrm{m}$以内であれば厳密に定位を行う必要がないためである。
もう一つは、SDMを作成するエンコーダーの学習時に、非常に大きな値に過剰に反応してしまうことを防ぐためである。

本研究では、ニューラルネットワークを用いることで、エージェントが行動を繰り返しながら、動的にSDMを予測していく手法を提案する。
今回提案するニューラルネットワークのアーキテクチャーは図\ref{fig:direct_map_encoder}のとおりである。

今回、AV-Nav\cite{chen2020soundspaces}とSAVi\cite{chen2021semantic}のネットワークにSDMを適用させ、エンドツーエンドで学習させた。
SAViでは、Observation Encoderの一部としてSound Direction Map Encoderを追加する。
つまり、SAViでは、Sound Direction Map Encoderはfirst stageでのみ学習させる。
SDMを作成するネットワークの重みの更新には、方策ネットワークから流れてくる勾配に加え、予測したSDMと真のSDMの平均二乗誤差（Mean Squared Error; MSE）による勾配も用いている。

また、学習時には、前回のSDMとして、前回のSDMの真値$\boldsymbol{d}_{t-1}$を入力している。
我々は予備実験において、前回のSDMとして、前回の自身の予測$\hat{\boldsymbol{d}}_{t-1}$を入力して学習させる場合もテストした。
実験により、予測値よりも真値を入力して学習させる方が性能が高くなることが分かったため、その方法を採用した。
ただし、テスト時とSAViの学習のsecond stageでは真値を使用せず、前回の自身のSDM予測値を入力している。

さらに、学習時にはDropoutという工夫を行った。
これは、前回のSDMとして入力するSDMの各ノードの値を、ある一定の確率で0にするというものである。
これは、現在のSDMを予測するときに、前回のSDMに依存しすぎることを防ぐことを目的としている。
なぜなら、前回のSDMとして入力される$\hat{\boldsymbol{d}}_{t-1}$が、真の前回のSDM $\boldsymbol{d}_{t-1}$を適切に予測しているとは限らないためである。
ただし、SAViの学習のsecond stageではDropoutは行わない。


\subsection{Reward}

時刻$t$にエージェントが受け取る報酬は以下のように定義した。
\[
r_t = r_{\mathrm{found}} - \Delta_{\mathrm{geo}} - 0.01 \label{eq:reward_definition}
\]
ここで、$r_{\mathrm{found}}$は、エージェントが時刻$t$においてゴールに到達した場合$5$になり、到達していない場合は$0$になる。
また、$\Delta_{\mathrm{geo}} \in \mathbb{R}$は、まだ到達していないすべてのゴールに到達するための最小の測地線距離の変化量である。
つまり、$\Delta_{\mathrm{geo}}$は、まだ到達していないすべてのゴールに到達するための最小測地線距離が、小さくなれば負の値になり、大きくなれば正の値になる。



\subsection{Training}

エージェントの学習にはDecentralized Distributed Proximal Policy Optimization（DD-PPO）\cite{wijmans2019dd}とよばれる、分散深層強化学習手法を用いた。
AV-Navを用いた学習には4 GPUsを利用し各GPUに四体のワーカーを配置させた。
また、SAViを用いた学習には16 GPUsを利用し各GPUに二体のワーカーを配置させた。

本研究におけるハイパーパラメータの設定は以下のとおりである。
まず、SDMのユニット数は$8$にし、各ユニットでドロップアウトが実行される確率は$0.2$にした。
さらに、SDMを予測するネットワークの重み更新時の勾配において、予測したSDMと真のSDMの平均二乗誤差による勾配の係数は、$100$にしている。
また、AV-NavとSAViに関するハイパーパラメーターは、SoundSpacesのデフォルトのパラメータを用いた。
ただし、重みの更新回数はAV-Navでは1,250回であり、SAViではfirst stageは570回、second stageは580回である。




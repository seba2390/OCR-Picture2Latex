\begin{table}[t]
% \floatconts
  \caption{Experimental results aggregated by tasks. \textbf{Bold} and \underline{underline} indicate the best and second best results for each dataset, respectively. $\dagger$: The models can only be applied to NER tasks, and the number is reported from the original paper. $*$: Since the two $\dagger$ models only report results on two NER datasets, we report an average performance on those two datasets for a fair comparison.}
  \resizebox{\linewidth}{!}{
  \begin{tabular}{lcc|cccc|ccccc}
  \toprule
  \multirow{3.5}{*}{\bf Task}  & \multicolumn{2}{c|}{\textit {Single-Sentence Tasks}} &  \multicolumn{4}{c|}{\textit{Sentence-Pair Tasks}} & \multicolumn{5}{c}{\textit{Token Classification Tasks}} \\
  \cmidrule(lr){2-3} \cmidrule(lr){4-7} \cmidrule(lr){8-12} 
  & \bfseries Text Class & \bfseries RE & \bfseries NLI & \multicolumn{2}{c}{\textbf{Fact Verification}} & \bfseries STS & \multicolumn{2}{c}{\textbf{NER}} & \multicolumn{3}{c}{\textbf{MedAttr}} \\
  % \midrule
  \cmidrule(lr){2-2} \cmidrule(lr){3-3} \cmidrule(lr){4-4} \cmidrule(lr){5-6} \cmidrule(lr){7-7} \cmidrule(lr){8-9} \cmidrule(lr){10-12}
  & F1 & F1 & Acc & Acc & F1 & Acc & F1 & F1-subset$^*$ & P & R & F1\\
  \midrule
  \multicolumn{12}{l}{\textbf{PubMedBERT$_{\texttt{Base}}$}} \\
  \midrule
  Supervised-Full & 77.01 & 77.34 & 79.20 & 67.58 & 65.49 & 75.70 & 89.67 & 87.27 & --- & --- & ---\\
  Supervised-Few & 18.61 & 43.89 & 44.64 & 29.43 & 27.10 & 55.70 & 39.41 & 34.12 & 38.11 & 43.82 & 40.77 \\
  \midrule
  DA-Word Sub & 40.74 & 38.14 & 55.08 & 28.86 & 25.83 & 54.40 & 44.30 & 40.41 & 40.25 & 47.65 & 43.64\\
  DA-Back Trans & 47.24 & --- & 54.30 & 32.15 & 28.04 & 55.80 & --- & --- & --- & --- & ---\\
  DA-Mixup & 45.09 & 43.37 & 53.52 & 32.78 & 29.12 & 58.20 & 42.20 & 37.65 & 42.37 & 48.96 & 45.43\\
  DA-Transformer & 41.02 & 47.56 & 55.71 & 35.32 & 31.77 & 58.80 & 44.75 & 39.66 & 37.82 & 44.28 & 40.80\\
  LightNER$^\dagger$ & --- & --- & --- & --- & --- & --- & --- & 39.49 & --- & --- & ---\\
  % DA-MELM$^\dagger$& --- & --- & --- & --- & --- & --- & 44.75 & 39.66 & 37.82 & 44.28 & 40.80\\
  KGPC$^\dagger$ & --- & --- & --- & --- & --- & --- & --- & 51.60 & --- & --- & ---\\
  \midrule
  ZeroGen & 59.02 & 63.84 & 55.96 & 35.30 & 32.50 & 68.35 & 56.97 & 48.26 & 52.80 & 49.53 & 51.11\\
  DemoGen & 64.09 & 67.46 & 59.80 & 40.30 & 35.95 & 70.85 & 60.16 & 53.91 & 58.15 & 56.84 & 57.49\\
  ProGen & 65.16 & 67.23 & 59.57 & 37.71 & 34.54 & 69.30 & 60.49 & 55.11 & 57.76 & 58.57 & 58.16\\  
  \midrule
  % \hline
  \rowcolor{teal!10} {\ours} w/ KG & \underline{67.15} & \underline{69.01} & \underline{64.89} & \underline{43.83} & \underline{39.43} & \underline{72.17} & \textbf{64.26} & \textbf{60.11} & \textbf{71.75} & \underline{65.20} & \textbf{68.32}\\
  \rowcolor{teal!10} {\ours} w/ LLM & \textbf{67.82} & \textbf{70.06} & \textbf{67.24} & \textbf{46.50} & \textbf{41.46} & \textbf{73.31} & \underline{63.17} & \underline{58.49} & \underline{68.19} & \textbf{66.79} & \underline{67.48}\\
  % \midrule
  \rowcolor{gray!15} Performance Gain & 4.08\% & 3.85\% & 12.44\% & 15.38\% & 15.33\% & 3.47\% & 6.23\% & --- & --- & --- & 17.47\% \\
  \midrule
  \multicolumn{12}{l}{\textbf{PubMedBERT$_{\texttt{Large}}$}} \\
  \midrule
  Supervised-Full & 80.06 & 79.64 & 82.65 & 72.97 & 69.23 & 78.80 & 90.15 & 87.68 & --- & --- & ---\\
  Supervised-Few & 17.86 & 52.68 & 50.00& 40.90 & 30.50 & 59.73 & 42.84 & 37.57 & 41.30 & 45.02 & 43.08 \\
  \midrule
  DA-Word Sub & 43.99 & 44.35 & 57.66 & 35.51 & 31.95 & 55.30 & 46.67 & 43.70 & 46.77 & 43.52 & 45.09\\
  DA-Back Trans & 50.98 & --- & 58.39 & 34.12 & 31.36 & 56.40 & --- & --- & --- & --- & ---\\
  DA-Mixup & 46.74 & 50.97 & 57.35 & 34.01 & 31.10 & 58.50 & 46.69 & 43.01 & 41.25 & 52.09 & 46.04\\
  DA-Transformer & 44.41 & 46.12 & 58.94 & 35.09 & 30.95 & 58.10 & 46.94 & 43.50 & 43.36 & 45.78 & 44.54\\
  LightNER$^\dagger$ & --- & --- & --- & --- & --- & --- & --- & --- & --- & --- & ---\\
  % DA-MELM$^\dagger$ & --- & --- & --- & --- & --- & --- & 46.94 & 43.50 & 43.36 & 45.78 & 44.54\\
  KGPC$^\dagger$ & --- & --- & --- & --- & --- & --- & --- & --- & --- & --- & ---\\
  \midrule
  ZeroGen & 61.51 & 65.18 & 63.47 & 41.12 & 36.10 & 72.69 & 57.79 & 49.10 & 54.04 & 51.40 & 52.69\\
  DemoGen & 64.97 & 68.65 & 64.58 & 42.61 & 38.69 & 74.37 & 61.43 & 55.61 & 62.67 & 61.02 & 61.83\\
  ProGen & 65.01 & 69.23 & 63.32 & 42.79 & 38.63 & 74.89 & 62.47 & 57.31 & 57.21 & 63.70 & 60.28\\
  \midrule
  % \hline
  \rowcolor{teal!10} {\ours} w/ KG & \underline{66.76} & \underline{71.47} & \textbf{70.90} & \underline{48.62} & \underline{42.45} & \underline{75.82} & \textbf{65.48} & \textbf{62.23} & \underline{70.96} & \textbf{69.66} & \textbf{70.30}\\
  \rowcolor{teal!10} {\ours} w/ LLM & \textbf{67.61} & \textbf{72.81} & \underline{70.50} & \textbf{49.51} & \textbf{43.72} & \textbf{76.21} & \underline{65.36} & \underline{61.89} & \textbf{71.61} & \underline{66.86} & \underline{69.15}\\
  \rowcolor{gray!15} {Performance Gain} & 4.00\% & 5.17\% & 9.79\% & 15.70\% & 13.00\% & 3.47\% & 1.76\% & --- & --- & --- & 13.70\% \\
  \bottomrule
  \end{tabular}
  }
  \vspace{-1ex}
  \label{tab:main-table}
\end{table}
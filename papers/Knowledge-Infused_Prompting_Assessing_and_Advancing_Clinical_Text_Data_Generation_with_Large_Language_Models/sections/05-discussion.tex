\section{Conclusion}
% Large language models (LLMs) inherently capture significant clinical knowledge. 
% In this work, we focus on an effective and generic approach for clinical text data generation with LLMs. 
% We thoroughly examine existing synthetic data generation methods for clinical tasks and identify significant issues, such as large distribution shifts and limited diversity in the generated data. 
% To address these challenges, we proposed a novel clinical knowledge-infuse framework, {\ours}, where clinical knowledge from both non-parametric KGs and parametric LLMs are leveraged to contextualize the clinical data generation. Specifically, clinical topic knowledge and real-world writing styles are elicited to serve as the foundation to create domain-specific prompts. 
% Through extensive empirical evaluations across 7 clinical NLP tasks spanning 16 datasets and comparing against 9 baseline methods from various categories, our results consistently demonstrate that {\ours}-generated data improves task performance, closely aligns with real data distributions, and significantly enhances data diversity compared to existing approaches.
% We anticipate this knowledge-infused clinical data generation paradigm be readily adapted for any future clinical text tasks, serving as a versatile approach for clinical NLP studies.  

In this work, we propose a versatile approach to clinical text data generation using LLMs. We thoroughly assess existing methods for clinical data generation and identify issues including distribution shifts and limited diversity. To tackle these challenges, we introduce {\ours}, a new framework that leverages clinical knowledge from non-parametric KGs and parametric LLMs. This knowledge empowers data generation by utilizing clinical topic knowledge and real-world writing styles in domain-specific prompts. Our extensive empirical evaluations across 7 clinical NLP tasks and 16 datasets, comparing to 9 baseline methods, consistently show that {\ours} improves task performance, aligns closely with real data, and enhances data diversity. We expect this approach can be seamlessly incorporated into a broad suite of clinical text tasks to advance clinical NLP research.
% \begin{table}[hbtp]
% \floatconts
%     {tab:datasets}
%     {\caption{Dataset statistics. For \# of hyperedges in MIMIC-III, the first number indicates the hyperedges without labels, while the second one indicates ones with labels.}}
%     {
%     \resizebox{0.8\linewidth}{!}{
%     \begin{tabular}{lcc}
%     \toprule
%     \bfseries Stats & \bfseries MIMIC-III    & \bfseries \dataset          \\ 
%     \midrule 
%     \# of diagnosis & 846 & 7915\\
%     \# of medication & 4525 & 489\\
%     \# of procedure & 2032 & 4321\\
%     \# of service & 20 & ---\\
%     \# of hyperedges & 36875/12353 & 36611 \\
%     \bottomrule
%     \end{tabular}
%     }
%     }
% \end{table}

\begin{table}[h]
% \floatconts
  \caption{Dataset statistics. We do not count the non-entity/non-relation class for relation extraction and token classification tasks to align with existing works. P and R stand for Precision and Recall. Metrics in \textbf{bold} are considered as the main metrics. $*$ is not allowed to put into GPT and $\dagger$ does not provide training data, so we sample few-shot examples from the SciTail~\citep{khot2018scitail} instead.}
  \label{tab:datastats}
  
  {
  \resizebox{0.95\linewidth}{!}{
  \begin{tabular}{lcccc}
  \toprule
  \bfseries Corpus & \bfseries Tasks & \bfseries \#Class & \bfseries \#Train/\#Test & \bfseries Metrics \\
  \midrule
  \multicolumn{5}{l}{\textbf{Single-Sentence Tasks}}\\
  \midrule
  LitCovid~\citep{litcovid} & Text Classification & 7 & 24960/6238 & \textbf{F1}\\
  HOC~\citep{hoc} & Text Classification & 10 & 3091/898 &\textbf{F1}\\
  GAD~\citep{gad} & Relation Extraction (RE) & 1 & 4750/350 & P, R, \textbf{F1}\\
  CDR~\citep{cdr_dataset} & Relation Extraction (RE) & 1 & 8431/2522 &  P, R, \textbf{F1}\\
  ChemProt~\citep{chemprot} & Relation Extraction (RE) & 5 & 8793/1087 & \textbf{F1}\\
  \midrule
  \multicolumn{5}{l}{\textbf{Sentence-Pair Tasks}}\\
  \midrule
  MedNLI$^*$~\citep{mednli} & Natural Language Inference (NLI) & 3 & 11232/1422 & \textbf{Acc}\\
  MEDIQA-NLI$^\dagger$~\citep{mediqa-nli} & Natural Language Inference (NLI) & 3 & -/405 & \textbf{Acc}\\
  MEDIQA-RQE~\citep{abacha2016recognizing} & Natural Language Inference (NLI) & 2 & 8588/302 & \textbf{Acc}\\
  PUBHEALTH~\citep{PUBHEALTH} & Fact Verification & 4 & 9804/1231 & Acc, \textbf{F1}\\
  HealthVer~\citep{healthver} & Fact Verification & 3 & 10591/1824 & Acc, \textbf{F1}\\
  MQP~\citep{mqp} & Sentences Similarity (STS) & 2 & 10/3033 & \textbf{Acc}\\
  \midrule
  \multicolumn{5}{l}{\textbf{Token Classification Tasks}}\\
  \midrule
  BC5CDR-Disease~\citep{bc5cdr} & Named Entity Recognition (NER) & 1 & 4882/5085 & P, R, \textbf{F1}\\
  BC5CDR-Chemical~\citep{bc5cdr} & Named Entity Recognition (NER) & 1 & 4882/5085 & P, R, \textbf{F1}\\
  NCBI-Disease~\citep{ncbi-disease} & Named Entity Recognition (NER) & 1 & 5336/921 &  P, R, \textbf{F1}\\
  CHEMDNER~\citep{chemdner} & Named Entity Recognition (NER) & 1 & 14522/12430 &  P, R, \textbf{F1}\\
  CASI~\citep{agrawal2022large,claim} & Attribute Extraction & 6 & 5/100 & \textbf{F1}\\
  \bottomrule
  \end{tabular}
     }
  }

\end{table}

% \begin{table}[hbtp]
% % \floatconts
%   {\caption{Dataset statistics. We do not count the non-entity/non-relation class for relation extraction and token classification tasks to align with existing works. P and R stand for Precision and Recall. Metrics in \textbf{bold} are considered as the main metrics.}\label{tab:datastats}}
  
%   {
%   \resizebox{0.8\linewidth}{!}{
%   \begin{tabular}{lcccc}
%   \toprule
%   \bfseries Corpus & \bfseries Tasks & \bfseries \#Class & \bfseries \#Train/\#Test & \bfseries Metrics \\
%   \midrule
%   \multicolumn{5}{c}{\textbf{Single-Sentence Tasks}}\\
%   \midrule
%   LitCovid & Text Classification & 7 & 24960/6238 & \textbf{F1}\\
%   HOC & Text Classification & 10 & 3091/898 &\textbf{F1}\\
%   GAD & Relation Extraction & 1 & 8431/2522 & P, R, \textbf{F1}\\
%   CDR & Relation Extraction & 1 & 8431/2522 &  P, R, \textbf{F1}\\
%   ChemProt & Relation Extraction & 5 & 8793/1087 & \textbf{F1}\\
%   \midrule
%   \multicolumn{5}{c}{\textbf{Sentence-Pair Tasks}}\\
%   \midrule
%   MedNLI* & NLI & 3 & 11232/1422 & \textbf{Acc}\\
%   MEDIQA-NLI & NLI & 3 & -/405 & \textbf{Acc}\\
%   MEDIQA-RQE & NLI & 2 & 8588/302 & \textbf{Acc}\\
%   PUBHEALTH & Fact Verification & 4 & 9804/1231 & Acc, \textbf{F1}\\
%   HealthVer & Fact Verification & 3 & 10591/1824 & Acc, \textbf{F1}\\
%   MQP & Sentences Similarity & 2 & 10/3033 & \textbf{Acc}\\
%   \midrule
%   \multicolumn{5}{c}{\textbf{Token Classification Tasks}}\\
%   \midrule
%   BC5CDR-Disease & NER & 1 & 4882/5085 & P, R, \textbf{F1}\\
%   BC5CDR-Chemical & NER & 1 & 4882/5085 & P, R, \textbf{F1}\\
%   NCBI-Disease & NER & 1 & 5336/921 &  P, R, \textbf{F1}\\
%   CHEMDNER & NER & 1 & 14522/12430 &  P, R, \textbf{F1}\\
%   CASI & Attribute Extraction & 6 & 5/100 & \textbf{F1}\\
%   \bottomrule
%   \end{tabular}
%      }
%   }

% \end{table}

\vspace{-1ex}
\section{Introduction}
\vspace{-1ex}
\label{sec:intro}
Clinical Natural Language Processing (NLP) emerges as a distinct subfield including the extraction, analysis, and interpretation of medical data from unstructured clinical text~\citep{wornow2023shaky}.  
Despite its significance, unique challenges evolve for methodology development in clinical NLP. For example, clinical texts are often dense with abbreviations and specialized medical terminologies that can be perplexing to standard NLP models~\citep{cui2022can,lee2023ai}. 
Fortunately, recent advances in Large Language Models (LLMs)~\citep{brown2020language,chung2022scaling,ouyang2022training,chatgpt,gpt4} provide a promising way to resolve these issues, as they contain billions of parameters and have been pretrained on massive corpora, thus inherently capture a significant amount of clinical knowledge~\citep{agrawal2022large,nori2023capabilities,pmlr-v209-eric23a,wong2023scaling,singhal2022large,singhal2023towards,luo2022biogpt,shi2023retrieval,liu2023radiology}.  
These progresses inspire the need for designing specialized approaches for adapting LLMs to clinical settings, which both address the terminology complexities and improve models through clinical data finetuning~\citep{tu2023towards,liu2023utility}.



% \paragraph{Why study clinical synthetic data generation?} 
Despite the strong capacity of general LLMs, 
directly applying them to infer over clinical text data is often undesired in practice. 
Firstly, these LLMs often have billions of parameters that translate to significant computational resources even for inference, leading to \emph{increased infrastructure costs} and \emph{long inference time}. 
%Such limitations can be particularly constraining in real-time clinical settings where swift decision-making is paramount.
Furthermore, the sensitive patient information contained in the clinical text naturally raises \emph{privacy and regulatory compliance concerns}~\citep{mesko2023imperative,keeling2023algorithmic}. 
To effectively combat these challenges, generating synthetic training data using LLMs stands out as a promising solution: 
It leverages the capability of LLMs in a way that is both resource-efficient and privacy-centric. When trained with these synthetic datasets mimicking real-world clinical data, models can achieve high performance while obeying data protection regulations.

Synthetic data generation with foundation models is a popular research domain in general machine learning~\citep{azizi2023synthetic,borisov2023language,openvik,meng2022generating,ye2022zerogen,ye2022progen}. However, when considering producing high-quality data that conforms to the distribution of the original dataset, simply adapting LLMs trained on general texts to generate clinical data presents unique challenges. To assess the quality of data generated by current methods, we carry out an exhaustive evaluation centered on distribution and diversity, detailed in Section~\ref{sec:preliminary}. Insights from the t-SNE embeddings visualization and the Central Moment Discrepancy (CMD) score indicate a noteworthy data distribution shift. We further examine the clinically-related entity quantities and frequencies in synthetic data, where a notable decline is observed when contrasting synthetic data with ground truth data.  
While some research has delved into clinical data generation with language models, many of these efforts are tailored to specific tasks. 
Examples include medical dialogues~\citep{chintagunta2021medically}, clinical notes~\citep{giorgi2023clinical}, medical text mining~\citep{tang2023does}, and electronic health records~\citep{promptehr,theodorou2023synthesize,qian2023synthetic}. 
These studies often directly adopt language models for text generation, and sometimes on excessive training data.
Till now, a unified principle to better adapt LLMs for generating synthetic text for facilitating clinical downstream applications is still missing.
% This limitation is especially salient in real-world contexts when usually only minimal training data is available. 

Motivated by the above analysis, we propose \ours, a \emph{clinical knowledge-infused} generic framework for high-quality clinical text generation in few-shot scenarios. 
Our ultimate goal is to narrow the gap between synthetic and ground-truth data and encourage the topic diversity of the generated text. 
Towards this end, we propose a strategy to utilize clinical knowledge extraction to contextualize the prompts. This includes generating clinical topics from both KGs and LLMs and deriving writing style suggestions from LLMs. 
By doing this, {\ours} integrates both non-parametric insights from external clinical knowledge graphs with the intrinsic parametric knowledge encoded in large language models.
It is worth noting that, \ours only rely on minimal additional human efforts, and can be readily applied to a wide array of core tasks in clinical NLP.
% We conduct an exhaustive empirical evaluation of synthetic clinical data generation \textbf{across 7 clinical NLP tasks and 16 datasets}. Empirical findings demonstrate that the proposed knowledge-infused framework not only aligns more closely with the distribution of the original data and amplifies the diversity of the generated training samples but also consistently enhances performance across various tasks.
% \wei{can we use some numbers to highlight the improvement? For example, XXXX performs the best in most cases with improvements up to XX\% over the best baselines. }

% \ran{release code}

Our contributions can be summarized as follows:
\begin{itemize}[leftmargin=0.5cm]
    \item We propose {\ours}, a generic clinical knowledge-infused framework for clinical text data generation in few-shot settings. It can be readily applied to a wide range of tasks in clinical NLP.
    \item We present a simple yet effective strategy to utilize clinical knowledge extraction to customize the prompts toward target clinical NLP tasks. This includes generating clinical topics from both KGs and LLMs and deriving writing style suggestions from LLMs. 
    \item We conduct an exhaustive evaluation of synthetic clinical data generation \textbf{across 7 clinical NLP tasks and 16 datasets}. Empirical findings demonstrate that {\ours} not only aligns more closely with the distribution of the original data but also amplifies the diversity of the generated training samples. The empirical performance gains are consistent across various tasks with different LLMs and classifiers (8.98\% for PubMedBERT$_{\texttt{Base}}$ and 7.27\% for PubMedBERT$_{\texttt{Large}}$).
\end{itemize}

% comprehensive empirical evaluation of synthetic data generation under few-shot settings spanning tasks ...
% strategy: clinical hints prompting -> diverse training instances -> performance gain

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Evaluation: \cite{wang2023large} \cite{tang2023does}

% \footnote{\url{https://physionet.org/news/post/415}}

% \cite{wang-etal-2022-iteratively}

% Biomed \cite{gu2021domain,tinybert}

% Distant Supervision \cite{fries2017swellshark,min2013distant,liang2020bond,mintz2009distant}

% ikbh \cite{su2023biomedical}


% KG \cite{blankemeier2023interactive}


% Bias Fairness \cite{active}
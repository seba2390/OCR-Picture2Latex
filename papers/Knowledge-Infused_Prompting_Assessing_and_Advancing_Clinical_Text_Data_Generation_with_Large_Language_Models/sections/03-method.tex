% \vspace{-3ex}
\section{Preliminary Study}
\vspace{-1ex}
\label{sec:preliminary}
This section first presents the foundational setup of synthetic data generation. 
Then, we provide an in-depth investigation into the pitfalls of existing synthetic data generation methods. 


\vspace{-1ex}
\subsection{Problem Setup}
In this paper, we study the synthetic data generation problem in the few-shot setting.
The input consists of a training set $\cD_{train}=\{(x_i,y_i)\}_{i=1}^K$, where $(x_i, y_i)$ represents the text and its label for the $i$-th example. $K$ denotes the total number of training samples, which is intentionally kept at a very small value (5-shot per label). The primary objective is to harness the capabilities of an LLM $\cM$ to generate a synthetic dataset, denoted as $\cD_{\text{syn}}=\{(\tilde{x_i},\tilde{y_i})\}_{i=1}^N$, where $N$ is the number of generated samples ($N \gg K$). 
% To use  for 
For each downstream task, we fine-tune an additional pre-trained classifier $\cC_{\theta}$ parameterized by $\theta$ on the synthetic dataset $\cD_{\text{syn}}$ for evaluating on the target task\footnote{While In-context Learning~\citep{brown2020language} can also be utilized, it is often hard to fit all generated instances into the context window, especially for datasets with high cardinality.}. 
% This deliberate design is aimed at leveraging $\cM$ to create a substantially augmented dataset for downstream tasks.





% The training set Dtrain = {(x, y)i}
% consists of K training samples per label where x =
% [x1, x2, . . . , xn] is a text sequence with n tokens.
\vspace{-1ex}
\subsection{Limitations of Existing Synthetic Data Generation Methods}
\label{sec:limitations}
Here, we take a closer look at the synthetic text data generated by two representative approaches: ZeroGen~\citep{ye2022zerogen}, which directly instructs LLMs for data generation, and DemoGen~\citep{gpt3mix,meng2023tuning}, which augments the prompt with few-shot demonstrations. 
We observe that these methods often introduce distribution shifts and exhibit limited diversity, which can be suboptimal for improving downstream performance. The illustration is as follows, and we include additional figures in Appendix~\ref{sec:add_prelim}.



\begin{figure}
	\centering
	\vspace{-3ex}
	\subfigure[t-SNE plot]{
		\includegraphics[width=0.28\linewidth]{figures/bc5cdr_disease_sentencebert_bsl.pdf}
		\label{fig:bc5cdr_disease_sentencebert_bsl}
	} %\hfill
         \hspace{-2.3ex}
	% \subfigure[MEDIQA-RQE]{
	% 	\includegraphics[width=0.25\linewidth]{figures/mediqa_rqe_sentencebert_bsl.pdf}
	% 	\label{fig:mediqa_rqe_sentencebert_bsl}
	% }\hspace{-1.5ex}
     \subfigure[Case study of generated examples]{
		\includegraphics[width=0.69\linewidth]{figures/case_study_prelim.pdf}
		\label{fig:case_study_prelim}
	}
	\caption{Preliminary Studies. (a) is from BC5CDR-Disease and (b) is from MEDIQA-RQE.\vspace{-1ex}}
	\vspace{-1ex}
\label{fig:prelim1}
% \vspace{-3ex}
\end{figure}



\textbf{Distribution Shift.} An inherent challenge when adapting LLMs to specific domains for text generation is the issue of \emph{distribution shift}, given that LLMs are primarily trained on vast amounts of web text in general domains. In Figure \ref{fig:bc5cdr_disease_sentencebert_bsl}, we visualize the embeddings\footnote{We employ SentenceBERT~\citep{reimers2019sentence} as the text encoder.} of both the ground truth training data and synthetic datasets generated via two representative methods. Overall, these methods use generic prompts (see Appendix~\ref{sec:prompt_format_bsl} for details) with minimal domain-specific constraints.
This limitation remains evident even when incorporating few-shot demonstrations into the process, with a notable disparity between the embeddings of the ground truth data and synthetic data.
% as there exists a large discrepancy between the embeddings of the ground truth data and the synthetic data. 
% \ran{sentencebert, more in appendix} 

To quantify the data distribution shift, we employ Central Moment Discrepancy (CMD)~\citep{zellinger2017central} to measure the gap between synthetic and real data across six clinical NLP datasets. Particularly, a high CMD value indicates a large gap between the two given distributions. Figure \ref{fig:cmd-baseline} illustrates that both ZeroGen and DemoGen exhibit elevated CMD scores, indicating substantial dissimilarity between the synthetic data and those of the real dataset.

% TSNE-embedding
% Case Study

 \begin{figure}
	\centering
	\vspace{-4.5ex}
	\subfigure[CMD]{
		\includegraphics[width=0.345\linewidth]{figures/cmd-baseline.pdf}
		\label{fig:cmd-baseline}
	} %\hfill
         \hspace{-1.5ex}
	% \subfigure[MEDIQA-RQE]{
	% 	\includegraphics[width=0.25\linewidth]{figures/mediqa_rqe_sentencebert_bsl.pdf}
	% 	\label{fig:mediqa_rqe_sentencebert_bsl}
	% }\hspace{-1.5ex}
     \subfigure[Entity Coverage]{
		\includegraphics[width=0.345\linewidth]{figures/avg-entity-baseline.pdf}
		\label{fig:avg-entity-baseline}
	}
 \hspace{-1.5ex}
      \subfigure[Entity Frequency]{
		\includegraphics[width=0.28\linewidth]{figures/bc5cdr_disease_freq_bsl.pdf}
		\label{fig:bc5cdr_disease_freq_bsl}
	}
 \vspace{-2ex}
	\caption{Preliminary Studies. (c) is from BC5CDR-Disease and is in log scale. \vspace{-3ex}}

\label{fig:prelim2}
\end{figure}

\textbf{Limited Diversity.}
Clinical datasets in real-world scenarios harbor a wealth of valuable knowledge that can be challenging to replicate within synthetically generated data by AI models. We evaluate synthetic dataset diversity by using both entity quantity and their normalized frequencies. The results are illustrated in Figures~\ref{fig:avg-entity-baseline} and \ref{fig:bc5cdr_disease_freq_bsl}. Our analysis reveals that datasets generated by ZeroGen and DemoGen exhibit a limited number of clinical entities, having a substantial discrepancy with the ground truth. 
Furthermore, it is highlighted that only a minority of potential entities and relations are frequently referenced across instances, while the majority are generated infrequently.

% Furthermore, these synthetic entities exhibit a \textit{long-tailed distribution} of normalized frequencies, highlighting that only a minority are frequently referenced across instances, while the majority of potential entities and relations are generated infrequently.

To explicitly illustrate the aforementioned limitations of synthetic datasets created using existing methods, we present a case study in Figure~\ref{fig:case_study_prelim}. In this case study, we randomly select one sample from each class within the training set generated by ZeroGen and DemoGen. These selected samples are compared with the ground truth data from the MEDIQA-RQE dataset, which aims to predict whether a consumer health query can entail an existing Frequently Asked Question (FAQ). The comparison reveals that the samples generated by ZeroGen and DemoGen tend to be more straightforward, lacking the \textit{sufficient details} and \textit{real-case nuances} present in the ground truth data. 
Furthermore, the generated samples adhere to a more uniform style and structure, while the ground truth encompasses various situations and writing styles, including urgent and informal inquiries.
% Furthermore, the generated samples lack the \textit{situation diversity} and \textit{style variability} present in the ground truth. The ground truth encompasses various situations and writing styles, including urgent and informal inquiries, while the generated samples adhere to a more uniform style and structure.


\section{Clinical Knowledge Infused Data Generation}
The revealed insights from the preliminary studies assert the necessity of domain-tailored knowledge for clinical synthetic data generation. In pursuit of efficient, effective, and scalable data generation for clinical domains, we introduce our novel framework, {\ours}, a prior knowledge-informed clinical data generation. The overview of {\ours} is shown in Figure~\ref{fig:overall}. This innovative two-step methodology harnesses the emergent capabilities of LLMs and external knowledge from KGs to facilitate the synthesis of clinical data, even when only presented with few-shot examples. 



\subsection{Clinical knowledge extraction}
Contrary to previous studies~\citep{ye2022zerogen,ye2022progen,meng2022generating,meng2023tuning} which employ generic queries to prompt LLMs for text generation, {\ours} emphasizes refining clinically informed prompts. This approach aims to extract rich clinically relevant knowledge from parametric (\eg LLMs) or nonparametric sources (\eg knowledge graphs) and tailor it to clinical NLP tasks.
% Different from prior research~\citep{ye2022zerogen,ye2022progen,meng2022generating,meng2023tuning} that use the simple task-specific queries to prompt Language Model (LLM) for data generation,
% {\ours}'s primary focus is to optimize clinically informed prompts to better harvest the clinical-relevant knowledge from LLMs and adapt them to clinical NLP tasks.
% emphasize on the initial ground of contextual domain knowledge.
To realize this objective, our modeling contains two dimensions including \emph{clinical topics} and \emph{writing styles}, which are integrated into the original prompts to infuse domain-specific knowledge. 
By dynamically composing different topics and writing styles together, {\ours} can provide a diverse suite of prompts, resulting in a wider spectrum of text produced from LLM.


% harness the synergistic potential of Knowledge Graphs (KGs) and Large Language Models (LLMs) in constructing a candidate set enriched with prior knowledge, specifically (1) the sampling of pertinent entities or relations from external knowledge graphs (KGs), and (2) the extraction of relevant hints through queries to Language Models (LLMs).\ran{style}

\subsubsection{Clinical Topics Generation}
We provide two choices to generate clinical topics -- one is to sample related entities or relations from external KG, and the other is to query relevant knowledge from LLM.

\textbf{Topics sampled from Non-Parametric KGs.} 
Healthcare KGs offer 
% comprehensive view of medical concepts and their relationships.
a rich collection of medical concepts and their complex relationships, and have emerged as a promising tool for organizing medical knowledge in a structured way~\citep{li2022graph,cui2023survey}. 
In our methodology, we employ the iBKH KG~\citep{su2023biomedical} due to its broad coverage over clinical entities. 
To illustrate, for the Disease Recognition task (NCBI)~\citep{ncbi-disease}, we extract all medication nodes from the iBKH to bolster the pharmaceutical information. 
As another example, we retrieve links between drug and disease nodes for the chemical and disease relation extraction (CDR) task~\citep{cdr_dataset}. 
By integrating the information from the clinical KG into our data generation process, we guarantee that our generated samples exhibit a high degree of contextual accuracy, diversity, and semantic richness.


\begin{figure}[t]
    \centering
    \vspace{-4ex}
    \includegraphics[width=0.96\linewidth]{figures/clingen-framework.pdf}
    \caption{The overview of \ours. \vspace{-2.5ex}
    % The left orange panel illustrates the knowledge extraction part. The middle purple panel shows the synthetic data generation module. The right green one is the fine-tuning step.}
    }
    % \vspace{-ex}
    \label{fig:overall}
\end{figure}

\textbf{Topics queried from Parametric Model (LLMs).} 
LLMs provide an alternative method for acquiring domain knowledge, as they are pre-trained on extensive text corpora, including medical literature.
% Large Language Models (LLMs) offer another viable avenue for acquiring foundational domain knowledge, owing to their extensive training on diverse text corpora, including the vast expanse of medical literature. 
Specifically, we aim to harness the rich clinical domain knowledge encoded in ChatGPT (\texttt{gpt-3.5-turbo-0301}) to augment the prompt. 
The incorporated prior knowledge from LLMs is focused on entity categories that hold significant relevance within clinical text datasets, including diseases, drugs, symptoms, and side effects.
For each of these pivotal entity types, we prompt the LLMs by formulating inquiries, \eg, ``\texttt{Suppose you are a clinician and want to collect a set of <Entity Type>. Could you list 100 entities about <Entity Type>?}''. These crafted conversational cues serve as effective prompts, aiding in the retrieval of clinically significant entities from the extensive domain knowledge within LLMs. For each entity type, we generate 300 entities which will be used for synthetic data generation.

\vspace{-0.5ex}
\subsubsection{Writing Styles Suggestion}
\vspace{-0.5ex}
\textbf{Styles suggested by LLMs.} To address the limitations mentioned in Sec~\ref{sec:limitations} and introduce a diverse range of writing styles into the generated samples, we leverage the powerful LLM again by suggesting candidate writing styles for each task. Specifically, we incorporate task names into our prompts (e.g., disease entity recognition, recognizing text entailment, etc.) and integrate few-shot demonstrations. We then engage ChatGPT in suggesting several potential sources, speakers, or authors of the sentences. See Appendix~\ref{sec: style_prompt} for detailed prompt. Responses such as ``\texttt{medical literature}" or ``\texttt{patient-doctor dialogues}" are augmented into the prompts to imitate the writing styles found in real datasets. 
% \joyce{I'm not quite sure what this quite looks like. Is there an example in the appendix/supplemental part? Seems you're downplaying it here otherwise.}
% explicitly query 

\vspace{-0.5ex}
\subsection{Knowledge-infused Synthetic Data Generation}
\vspace{-0.5ex}
% After building the candidate set with one of the previous approaches, we randomly sample one keyword each time and augment it into the prompt. 
% % An example of the prompt on xxx dataset is shown in Figure xxx. 
% For example, a keyword for the NCBI dataset could be ``\texttt{stroke}", then we enrich the prompt for querying ChatGPT by adding an additional sentence ``\texttt{generate a sentence about stroke}" (see Figure/Appendix for full prompt). 
With the generated entities as well as styles, the key challenge becomes how to leverage them to extract rich clinical information from the LLM for improving synthetic data quality.
% hat, if used wisely, can be potentially leveraged for generalizing over limited context.
% if they are guided effectively. 
Directly putting all the elements to enrich the prompt is often infeasible due to the massive size of entities.
% and over-complicated 
To balance informativeness as well as diversity, we propose a  knowledge-infused strategy, where the collected clinical topics and writing styles serve as the base unit. 
% for leading LLMs towards clinical domains.  
% To elucidate, each extracted hinting keyword from the candidate set takes a role in shaping a clinically informed prompt structure. 
In each step, we randomly sample a topic and a writing style from the candidate set to augment the prompts.
For instance, for the Disease Recognition (NCBI) task, consider a clinical entity like ``\texttt{stroke}" . We enrich the prompt query for LLM by appending ``\texttt{generate a sentence about stroke}" as a generation guidance. For a comprehensive view of the prompt formats across various tasks, please refer to Appendix~\ref{sec:prompt_format}. 
Despite its simplicity, this knowledge-infused strategy ensures that the clinical context is incorporated into the prompts while encouraging prompt diversity (via composing different entities and writing styles), 
thereby enhancing the quality and clinical relevance of the generated synthetic data.


\subsection{Language model fine-tuning}
After generating synthetic data $\cD_{\text{syn}}$ through LLMs, we fine-tune a pre-trained classifier $\cC_{\theta}$ to each downstream task. Following \citep{meng2023tuning}, we first fine-tune $\cC_{\theta}$ on $\cD_{\text{train}}$ with standard supervised training objectives (denoted as $\ell(\cdot)$), then on the synthetic data $\cD_{\text{syn}}$ as  
\begin{align}
    \label{eq:stage1}
    \mathrm{Stage~I}: \theta^{(1)} = \min_{\theta}~\mathbb{E}_{(x, y) \sim \cD_{\text{train}}} \ell\left( f(x; \theta), y \right), \\
    \mathrm{Stage~II}: \theta^{(2)} =  \min_{\theta}~\mathbb{E}_{(x, y) \sim \cD_{\text{syn}}} \ell\left( f(x; \theta), y \right),  \theta_{\text{init}} = \theta^{(1)}.
\end{align} 
% \end{equation}
It's important to highlight that we strictly follow a standard fine-tuning process and avoid using any extra techniques: (1) for standard classification tasks, $\ell(\cdot)$ is the cross-entropy loss; (2) for multi-label classification tasks, $\ell(\cdot)$ is the binary cross-entropy loss; 
(3) for token-level classification tasks, we stack an additional linear layer as the classification head and  $\ell(\cdot)$ is the token-level cross-entropy loss. 
% This is to ensure methodological consistency and transparency throughout the evaluation across different methods and tasks. 
The design of \emph{advanced learning objectives} as well as \emph{data mixing strategies}, while important, are orthogonal to the scope of this paper. 






% It is important to underscore that, in pursuit of a rigorous quality evaluation of the synthetic data, we rigorously adhere to a conventional fine-tuning pipeline, without any auxiliary techniques. Our chosen learning objective is the minimization of the cross-entropy loss against the task-specific target, ensuring methodological consistency and transparency throughout the evaluation across different methods and tasks.

% \subsubsection{Style}

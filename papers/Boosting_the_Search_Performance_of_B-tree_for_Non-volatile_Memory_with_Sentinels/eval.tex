\section{Evaluation}



In this section, we implement and evaluate our Sentinel Array based on FAST-FAIR and Circle-Tree in terms of insertion and search performance. We use a synthetic benchmark YCSB \cite{cooper2010benchmarking} to evaluate the performance between original FAST-FAIR/Circle-Tree and ones with Sentinel Array. 

\subsection{Evaluation Setup}\label{AA}
All of our experiments are conducted on Linux Server (Kernel version 3.10) with an Intel \textsuperscript{\textregistered} Xeon \textsuperscript{\textregistered} E5-2620v4 2.10GHz CPU with 512KB/2MB/20MB L1/L2/L3 cache, 8GB DRAM. We use DRAM to emulate the NVM space. We keep the read latency of NVM as the same as DRAM, and emulate the write latency by adding an extra delay after each \textsf{clflushshopt} instruction. We set the default write latency of NVM as 300ns. \cite{yang2015nv, zhao2013kiln, wang2019circ}



\begin{figure}[t]
\centering
\subfigure[Average latency (1m data, search, $\mu$s)]{
\centering
\includegraphics[width=0.48\columnwidth]{./concurrent_search.pdf}
\label{concurrent_search} 
}%
%\hspace{.001in}
\subfigure[Average latency (1m data, insertion, $\mu$s)]{
\centering
\includegraphics[width=0.48\columnwidth]{./concurrent_insert.pdf}
\label{concurrent_insertion} 
}%
\centering
\caption{A Comparison of Six Trees with Multi-Threading}
\label{concurrent_testing} 
\end{figure}



% YCSB:
\begin{figure*}[t]
\centering
\subfigure[99th percentile latency (insertion, $\mu$s)]{
\centering
\includegraphics[width=0.64\columnwidth]{./YCSB_load.pdf}
\label{YCSB_load} 
}%
%\hspace{.001in}
\subfigure[99th percentile latency (search, $\mu$s)]{
\centering
\includegraphics[width=0.64\columnwidth]{./YCSB_search.pdf}
\label{YCSB_search} 
}%
%\hspace{.001in}
\subfigure[99th percentile latency (update, $\mu$s)]{
\centering
\includegraphics[width=0.64\columnwidth]{./YCSB_multi_update.pdf}
\label{YCSB_update} 
}%
\centering
\caption{A Comparison of six KV Stores (4KB Node) on SessionStore Workload of YCSB}
\end{figure*}

\begin{figure*}[t]
\centering
\subfigure[99th percentile latency (insertion, $\mu$s)]{
\centering
\includegraphics[width=0.64\columnwidth]{./YCSB_multi_load.pdf}
\label{YCSB_multi_load} 
}%
%\hspace{.001in}
\subfigure[99th percentile latency (search, $\mu$s)]{
\centering
\includegraphics[width=0.64\columnwidth]{./YCSB_multi_search.pdf}
\label{YCSB_multi_search} 
}%
%\hspace{.001in}
\subfigure[99th percentile latency (update, $\mu$s)]{
\centering
\includegraphics[width=0.64\columnwidth]{./YCSB_multi_update.pdf}
\label{YCSB_multi_update} 
}%
\centering
\caption{A Comparison of six KV Stores (4KB Node) with Multi-threading on SessionStore Workload of YCSB}
\end{figure*}





Fig.~\ref{10m_testing} and Fig.~\ref{100m_testing} show the insertion and search performance of multi-version B+-tree variants. FAST-FAIR has open-source code and Circle-Tree is implemented with respect to its original literature. Given the large gap between the performance of the search function mentioned in the Circle-Tree and the linear search in FAST-FAIR. The Circle-Tree's search function was implemented as a linear search starting from the logical base location of a node to the last valid KV pair. Moreover, the name that has the `S' suffix is the Sentinel Array. The one that has the `F' suffix contains a fingerprint array proposed in the FP-Tree. All implementations have been compiled with -O option. 



Fig.~\ref{10m_testing} and Fig.~\ref{100m_testing} show average latencies by running 1/10/100 million insertion and search operations.  A shorter average latency means higher performance. We have chosen the geometric mean to calculate the average latency. 

From Fig.~\ref{1m_search}, a B+-tree with Sentinel Array outperforms the one without Sentinel Array with much shorter search latencies. For example, using the idea of Sentinel Array helps to reduce the average search latency of Circle-Tree and FAST-FAIR by 48.4\% and 42.6\%, respectively, with 4KB node size. However, as also shown in Fig.~\ref{1m_search}, the effect of using fingerprints is limited. For example, the search latency of Circle-Tree with 4KB node size is shortened by 3.1\%. 

Although the Sentinel Array influences the insertion performance because of its update needs, still with 4KB node, the average insertion latencies of Circle-Tree and FAST-FAIR with the Sentinel Array are increased by 6.5\% and 4.0\% that of the same structure without the Sentinel Array in Fig.~\ref{1m_insertion}. 

Another observation illustrated in Fig.~\ref{10m_testing} is that the search performance of the B+-tree with the Sentinel Array gets better with larger node size. Search latency of B+-tree with Sentinel Array is larger than the ones without Sentinel Array with 512B node. The reason is that CPU combined with the compiler has branch predict feature and could prefetch the data into cache-line. The node with small size node could find the target with less cache misses, but the Sentinel Array implementation needs at least one solid cache miss to search Sentinel Array and more branch judgment between Array switch. So it's better to add the Sentinel Array to the B+-tree like data structure with large node size. The same results are also observed in Fig.~\ref{100m_testing}, which refer to more data insertion and search.




\subsection{Multi-threading Performance}

We have performed multi-threading tests with 1/2/4/8 threads, to evaluate the performance of the B+-tree with Sentinel Array. We evaluated the tests with 4KB node size and the data size is 1 million keys. Fig.~\ref{concurrent_search} shows the performance of each multi-threading search operation and we could observe that FAST-FAIR and Circle-Tree with the Sentinel Array outperform the one without the Sentinel Array. For example, using sentinels reduces the average search latency by 46.1\% and 47.6\%, for FAST-FAIR and Circle-Tree with 2 threads.

The multi-thread insertion showed in Fig.~\ref{concurrent_insertion}, indicates that the Sentinel Array has insignificant influence on insertion performance. 


\subsection{Evaluation on YCSB}




For end-to-end comparison, we built an interface for each B+-tree like data structure to receive and handle access requests issued by YCSB. Because the key from a YCSB workload is a string with a prefix and a number, we removed the prefix and treated the number as an 8B key in unsigned integer. The default load value of YCSB has ten fields with 100 bytes per field, so the pointer of a KV pair in a leaf node points to the address of stored value.

We used the `workloada' workload with YCSB. It first inserts a predefined number of KV pairs ({\em load}) and then follows a search/update ratio of 50\%/50\% over keys selected in accordance with a Zipf distribution ({\em run}). YCSB reports a series of latencies from which we choose the 99th percentile latency to rule out the impact of very short or very long operations. It means that 99\% of overall write/read requests can be completed below such a latency.

In our experiment, we use 1 million KV pairs to test performance with YCSB. Fig.~\ref{YCSB_load} shows the average latencies of inserting 1 million data into each tree. The structure with the Sentinel Array still gets lower latency than the original implementation. Fig.~\ref{YCSB_search} captures search performance and FAST-FAIR and Circle-Tree with the Sentinel Array get 16.9\% and 13.0\% improvement on 4KB node size. From Fig.~\ref{YCSB_update}, which represents the average latency of updating the KV pair of the loaded data, the structure with the Sentinel Array still gets a shorter latency. The reason is that update operation is like the search operation and they only need to find the KV pair's position without shifting the KV pair.

We also tested multi-threads of the B+-tree with Sentinel Array with YCSB. As showed in Fig.~\ref{YCSB_multi_load}, Fig.~\ref{YCSB_multi_search} and Fig.~\ref{YCSB_multi_update} the average search latencies is significantly reduced compared to ones without Sentinel Array.
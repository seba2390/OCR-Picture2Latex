\section{Background and Motivation}



\subsection{Background}
Byte-addressable non-volatile memory (NVM), such as Phase Change Memory (PCM), Spin-Transfer Torque RAM (STT-RAM), and Resistive RAM (RRAM), has an increasingly important demand in high-performance computing and big data analysis \cite{zhao2013kiln, moraru2013consistent}. It combines the durability of hard disk and the comparable access performance of DRAM. 

Data consistency between the volatile device and the non-volatile device is always one of the most crucial features of storage systems. In the traditional storage architecture, where DRAM acts as the main memory, the system needs to ensure the data consistency from DRAM to the hard disk to prevent the data from being lost if system failure happens \cite{mohan1992aries}. As to NVM, the effort becomes to keep data consistency between CPU and NVM. However, modern CPUs mainly support an atomic write of no more than the memory bus width (8 bytes for 64-bit CPUs) when NVM is put on the memory bus \cite{hwang2018endurable, dulloor2014system, intel64and}. Moreover, compared to the known persistent status of each page in DRAM, the status of data in cache-lines is unknown and the CPU or the memory controller may write the cache-lines back to the main memory in a different order from the programmed order. Make memory writes are in a certain order is critical to the crash consistency of pointer-based data structures. For example, a new B+-tree from a split operation must be written completely before the pointer to it is added to its parental node. The pointer may turn to be dangling if the order is reversed but the crash occurs \cite{yang2015nv} and it's necessary to maintain the writing order. 

Some CPU instructions, such as \textsf{cache line flush} and \textsf{memory fence}, are provided to maintain the written order from cache to memory. \textsf{cache line flush} explicitly invalidates a dirty cache-line and flush it to memory. \textsf{memory fence} makes a barrier that holds back the memory operations after the barrier until those before the barrier complete. However, these instructions incur performance overheads \cite{yang2015nv, hwang2018endurable, lu2014loose}. Therefore, it is necessary to reduce the use of \textsf{cache line flush} and \textsf{memory fence}.
\subsection{Related Work}

Researchers have proposed a number of mechanisms to provide data consistency and optimize the performance of B+-trees developed for NVM. \textsf{FAST-FAIR} \cite{hwang2018endurable} uses two features that CPU only ensures 8-bytes atomic write and duplicate pointers are impossible in B+-tree node. It exploits the store dependencies in shifting a sequence of KV pairs in a node on insertion/deletion. (e.g. $KV_{i} \xrightarrow{} KV_{i+1}$), which reduces the cost of cache line flushes and memory fence. 

\textsf{FAST-FAIR} still follows the classic B+-tree node in a linear structure. \textsf{Circle-Tree}~\cite{wang2019circ} was proposed to reduce write amplification caused by shifting KV pairs in the linear structure. The circular structure supports bidirectional shifting. KV pair is inserted/deleted at the left or right side by deciding which side requires fewer shifting operations. 

Most B+-trees developed for NVM optimize insertion/deletion performance. Although \textsf{FP-Tree}~\cite{oukid2016fptree} use a technique named fingerprinting, which maps the key of KV pair into a byte of fingerprint (hash value), to optimize the search performance by checking the array of fingerprint instead of the original data container. The efficacy of fingerprinting is low due to hash calculations and the collisions of 1B hash values. 

\subsection{Motivation}

\begin{figure}[htbp]
\centerline{\includegraphics[width=0.5\textwidth]{./B+Tree_diff_search.pdf}}
\caption{B+-tree with different search way comparison}
\label{L_B_Comparison}
\end{figure}

\begin{figure}[htbp]
\centerline{\includegraphics[width=0.5\textwidth]{./Sentinel_Array.pdf}}
\caption{Sentinel Array example}
\label{fig1}
\end{figure}

With further and further understanding of B+-tree's properties, researchers have switched from sorted nodes to unsorted nodes, and again to sorted nodes now. More importantly, the researcher found that a large CPU cache of modern processor makes linear search outperform binary search in a sorted B+-tree node because of the former's good cache line locality \cite{danowitz2012cpu}. Fig.~\ref{L_B_Comparison} verifies that the latency of binary search is greater than that of linear search with small node size (512B/1KB/2KB) when we searched 1 million KV pairs in a sorted B+-tree node. 

As the search is so important that used not only in independent operation, but also in insertion and deletion, optimize the search performance is a key point to boost the throughput. Accessing the key and check if that is the target one is the cause of cache misses. This is the observation of {\em read amplification} in searching a sorted B+-tree node. Our goal focus on reducing cache misses in searching. Fig.~\ref{fig1} shows a sorted B+-tree node with a Sentinel Array which has the smallest key from each cache line. When searching a target key 130, instead of scanning 4 cache lines, we go through the Sentinel Array to determine the 4th cache is the target key stays in. As a result, searching key 130 converts to searching the Sentinel Array and one actual cache line of KV pairs.


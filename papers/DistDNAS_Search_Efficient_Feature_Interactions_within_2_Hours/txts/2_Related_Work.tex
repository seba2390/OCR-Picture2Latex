\section{Related Work}

\noindent \textbf{Feature Interactions in Recommender Systems.}
The feature interactions within recommender systems such as CTR prediction have been thoroughly investigated in various approaches, such as Logistic Regression~\cite{richardson2007predicting}, and Gradient-Boosting Decision Trees~\cite{he2014practical}.
Recent approaches apply deep learning based interaction~\cite{zhang2019deep} to enhance end-to-end modeling experience by innovating Wide \& Deep Neural Networks~\cite{cheng2016wide}, Deep Crossing~\cite{wang2017deep}, Factorization Machines~\cite{guo2017deepfm,lian2018xdeepfm}, DotProduct~\cite{naumov2019deep} and gating mechanism~\cite{wang2017deep, wang2021dcn}, ensemble of feature interactions~\cite{zhang2022dhen}, feature-wise multiplications~\cite{wang2021masknet}, and sparsifications~\cite{deng2021deeplight}.
In addition, these works do not fully consider the impact of fusing different types of feature interactions, such as the potential redundancy, conflict, and performance enhancement induced by a variety of feature interactions.
DistDNAS constructs a supernet to explore different orders and types of interaction modules and distributes differentiable search to advance search efficiency.

\noindent \textbf{Cost-aware Neural Architecture Search.}     
Neural Architecture Search (NAS) automates the design of Deep Neural Network (DNN) in various applications: the popularity of NAS is consistently growing in brewing Computer Vision~\cite{zoph2018learning,liu2018darts,wen2020neural,cai2019once}, Natural Language Processing~\cite{so2019evolved,wang2020hat}, and Recommender Systems~\cite{song2020towards,gao2021progressive,krishna2021differentiable,zhang2022nasrec}.
Tremendous efforts are made to advance the performance of discovered architectures to brew a state-of-the-art model.
Despite the improvement in search/evaluation algorithms, existing NAS algorithms overlook the opportunity to harvest performance improvements by addressing potential conflict and redundancy in feature interaction modules.
DistDNAS regularizes the cost of the searched feature interactions and prunes unnecessary interaction modules as building blocks, yielding better FLOPs-LogLoss trade-offs on CTR benchmarks.
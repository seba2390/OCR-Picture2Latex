\section{Introduction}
\label{sec:intro}

\begin{comment}
``while programmers may program directly with persistence primitives, they require
a sophisticated understanding of recovery protocols similar to databases or file system.
Durable transactions provide a much simpler interface to persistent memory and
require few application changes, so we concentrate our evaluation on transaction performance.''

``The cost of durable transaction sis two writes to SCM for every update: xxxx.
Other consistent-update mechanisms may perform better. But, they come at
the cost of increased complexity, such as recovery code to replay logs for append-only updates, garbage collection for memory lost during shadow updates, and explicit fences to order updates.''

``make it persistent by allocating it from a persistent heap and wrapping updates in transactions''
\end{comment}

%Paragraph 1: reliability challenge for future HPC;
Resilience  is  one  of  the  major  design  goals  for extreme-scale HPC systems.  Looking forward to future HPC with shrinking feature size of hardware and aggressive
power management techniques, mean time between failures (MTBF) in HPC
could be shortened because of more frequent soft and hard errors;
the application execution could be interrupted more frequently;
and the application result correctness could be corrupted more often.

%Paragraph 2: The limitation of traditional checkpoint/restart mechanisms
To address the above resilience challenge, checkpoint (or more specifically, application-level checkpoint) is the most common method deployed in current production supercomputers.
Application level checkpoint periodically saves application critical data objects to non-volatile storage %or system states 
to enable data persistence.
Once a failure happens, the application can restart from the last valid state of the data objects without restarting from the beginning.
However, checkpoint faces two dilemmas. 
First, there is a dilemma between HPC resilience and checkpoint overhead.
On one hand, as MTBF may become shorter in the future, 
we have to increase checkpoint frequency to improve HPC fault tolerance.
On the other hand, the frequent checkpoint results in larger runtime overhead.
We call this dilemma as the resilience dilemma.
Second, there is a dilemma between recomputation cost
and checkpoint overhead. 
On one hand, we want to increase checkpoint frequency to 
minimize recomputation cost and reduce data loss. 
On the other hand, the frequent checkpoint results in larger runtime overhead. We call this dilemma as the recomputation dilemma.

The fundamental reason that accounts for the above two dilemmas 
is the cost of data copying inherent in the checkpoint mechanism.
The data copying operations can be expense, because
checkpoint data has to be stored in remote or local durable hard drive. 
Although the disk-less checkpoint reduces data copying overhead~\cite{tpds98:plank, Lu:2005:SDC:1145057, ppopp17:tang, isftc94:plank, ipdps09:bronevetsky}
by using main memory, this technique has to encode data across multiple nodes to create redundancy and only tolerates up to a certain number of node failures, because of the volatility of memory.
Other techniques, such as multi-level checkpoint~\cite{sc10:moody, sc09:dong, sc11:gomez} and incremental checkpoint~\cite{isftc94:plank, ics04:agarwal, icpads10:wang, ipdps09:bronevetsky} partially remove expensive data copying off the critical path of application execution,
but a checkpoint with a large data size can still cause large runtime overhead.
%see related work section in ''Low-overhead diskless checkpoint for hybrid computing systems``

The emergence of non-volatile memories (NVM), such as phase change memory (PCM) and RRAM, is poised to revolutionize memory systems~\cite{sc10:Caulfield, cse15:vetter}.
The performance of NVM is much better than hard drive, and even close to or match that of DRAM~\cite{NVMDB, eurosys16:dulloor}. 
%Emerging nonvolatile memory technologies (NVRAM) promise the performance of DRAM with the persistence of disk. 
Furthermore, NVM has better scalability than DRAM while remain non-volatility. These features make it possible to merge the traditional two layers of memory hierarchy (i.e, memory plus back-end storage) into one layer (i.e, memory without back-end storage)~\cite{imw13:mutlu}.
Given NVM as main memory and its non-volatility nature,
is it possible to change or even remove checkpoint to enable data persistence frequently, thus fundamentally addressing the above two dilemmas in future HPC systems?
How can NVM be used to address the resilience challenge for HPC?

This paper aims to answer the above questions, and explores
how to build resilient HPC with emerging NVM as main memory.
We introduce a variety of optimization techniques
to leverage high performance and non-volatility of
NVM to establish data persistence for application critical data objects frequently.
%as the traditional checkpoint mechanism does.

\begin{comment}
constraining NVRAM write order, necessary
to ensure recovery correctness, limits NVRAM write concurrency and degrades throughput.

We require new memory interfaces to minimally describe write constraints and allow high performance and high concurrency data structures.
\end{comment}

%Paragraph 5: The challenges of using NVM to address reliability challenge.
%(1) data consistency; (2) The existing work may have large overhead
We start from a preliminary design that uses NVM as either main memory or storage to implement checkpoint. We expect that the superior performance of NVM would allow us to achieve frequent checkpoint with small runtime overhead and hence address the two dilemmas. 
To improve checkpoint performance, we introduce 
%parallel cache flushing to enable a consistent state of data objects for NVM-based checkpoint, and introduce \textbf{TODO: SSE2 instruction-based} data copy with cache bypassing to minimize data movement between caches and memory.
a couple of optimizations, including parallelization of cache flushing and using 
SIMD-based, non-temporal load/store instructions (e.g.,
MOVDQU) to bypass CPU caches and minimize data movement between caches
and memory.
%\textbf{TODO: SSE2 instruction-based} 
%data copy with cache bypassing to minimize data movement between caches and memory.
However, we reveal that even based on an optimistic assumption on NVM performance, NVM-based checkpoint can still lead to large runtime overhead (up to 46\%), because of data copying in checkpoint. 

%We further study removing checkpoint and leverage non-volatility of NVM to build a consistent state on NVM as main memory. 
We further study how to leverage non-volatility of NVM to create a copy
of the data objects. We aim to replace traditional data copying in checkpoint, which is the fundamental reason that accounts for expensive checkpoint. 
We introduce a technique, named in-place versioning.
This technique hides programmers from application and algorithm details, and leverages application-inherent memory write operations to create a new version of the data objects in NVM without extra data copying. We derive a set of rules to enable automatic transformation of programs to achieve in-place versioning. %based on application profiling.
%However, to build a consistent state and ensure proper recover,
%we must place constraints on the order of NVM writes. The prevalence of hardware and software volatile caches introduces randomness into write operations on NVM. We must flush 

%Once a new version of the data objects is created in NVM, 
To ensure proper recovery based on the new version of the data objects, 
%we must ensure proper recovery based on this new version. 
we must guarantee that the data of the new version is consistent between caches and NVM.
%This is challenging, 
%because the prevalence of hardware caches causes a data consistency problem
%between caches and main memory. 
Hence, we must flush data blocks of the new version out of caches, after the new version is created by the in-place versioning technique.
Such cache flushing operations can be expensive, because there is
no mechanism that allows us to track which data blocks of the new version are in caches and whether data blocks in caches are clean. As a result, we must flush all data blocks of the new version as if all data blocks are in caches,
which brings large performance loss.

To minimize the cache flushing cost, we propose to use a privileged instruction and make it accessible to the application to flush the entire cache hierarchy, instead of flushing all data blocks of the new version. For a large data object, flushing the entire cache hierarchy are often much cheaper.
Furthermore, we introduce an asynchronous and proactive cache flushing mechanism to 
remove cache flushing cost off the critical path of application execution
while enabling data consistency in NVM.

In general, the in-place versioning plus the optimized cache flushing allow us to establish data persistence with consistence for application critical data objects in NVM.  %as the traditional checkpoint mechanism.
The establishment of data persistence can happen much more frequently 
than the traditional checkpoint mechanism, with high performance.
%very small runtime overhead.
With the evaluation of six representative HPC benchmarks and one production HPC application (Nek5000), we show that the runtime overhead is \%4.4 on average (up to 9\%) when the establishment of data persistence frequently happens at every iteration of the main computation loop. 
Such frequent and high performance data persistence allows us to
minimize recomputation cost and tolerate high error rate
in future HPC.
%This achievement comes from high performance and non-volatility of NVM. 

Our major contributions are summarized as follows.
\vspace{-1pt}
\begin{itemize}
  %\item We explore how to use NVM to enable resilient HPC.
  %achieve the same functionality as the traditional checkpoint for future resilient HPC. 
%We demonstrate that using NVM is very beneficial to enable resilient HPC. 
%Without data copying and with the optimization of cache flushing, using NVM has potential to address the resilience and recomputation dilemmas rooted in the traditional checkpoint.   
  
  \item We explore how to use NVM to enable resilient HPC. We demonstrate that using NVM (either as main memory or storage) to implement frequent checkpoint based on data copying to address the two dilemmas may not be feasible, because of large data copying overhead, even though NVM is expected to have superior performance.
  
  \item We explore how to enable data persistence with consistency in NVM with minimized runtime overhead. Without data copying and with the optimization of cache flushing, using NVM has potential to address the resilience and recomputation dilemmas rooted in the traditional checkpoint.
  %This is critical to enable NVM success for HPC which is highly sensitive to the impact of NVM on application performance. 
\end{itemize}



\begin{comment}
\textbf{Dong's comments: (1) comparison with dual version in HPDC'16: our dual version is based on a series of general rules and don't use algorithm knowledge}

\textbf{Dong's comments: (2) Comparison with the existing method (e.g., PMEM from intel): we can implement undo-log or redo-log and make a comparison with our approach. I am not sure if PEME can work in our cases}.
\end{comment}
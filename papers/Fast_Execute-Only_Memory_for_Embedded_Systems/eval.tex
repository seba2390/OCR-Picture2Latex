%==============================================================================
\section{Evaluation}
\label{sec:eval}
%==============================================================================

We evaluated {\System} on our STM32F469 Discovery
board~\cite{STM32F469I-DISCO:Manual} which has an ARM Cortex-M4
processor implementing the ARMv7-M architecture that can run as fast as
180~MHz.  The board comes with 2~MB of
flash memory, 384~KB of SRAM, and 16~MB of SDRAM, and has an LCD screen
and a microSD card slot.  We configured the
board to run at its fastest speed to understand the maximum impact
that {\System} can incur on performance.

\input{tables/perf-beebs}

To evaluate {\System}'s performance and code size overhead, we used the
BEEBS~\cite{BEEBS:ArXiv13} and CoreMark-Pro~\cite{CoreMark-Pro}
benchmark suites and five embedded applications (FatFs-RAM,
FatFs-uSD, LCD-Animation, LCD-uSD, and PinLock).  {\bf BEEBS} targets
energy consumption measurement for embedded platforms and is widely used
in evaluating embedded systems including uXOM~\cite{uXOM:UsenixSec19},
the state-of-the-art XOM implementation on ARM microcontrollers.  It
consists of a wide range of programs characterizing different
workloads seen on embedded systems, including AES encryption, data
compression, and matrix multiplication.
Of all 80 benchmarks in BEEBS,
we picked 42 benchmarks that have an execution time
longer than 500 milliseconds when executed for 10,240 iterations.
{\bf CoreMark-Pro} is a
processor benchmark suite that works on both
high-performance processors and low-end microcontrollers, featuring five
integer benchmarks (e.g., JPEG image compression, XML parser, and
SHA-256) and four floating-point benchmarks (e.g., fast Fourier
transform and neural network) that stress the
CPU and memory.  {\bf FatFs-RAM} and {\bf FatFs-uSD} operate a FAT file
system on SDRAM and an SD card, respectively. {\bf LCD-Animation}
displays a single animated picture loaded from an SD card.
{\bf LCD-uSD} displays multiple static pictures from an SD card with
fading transitions.
{\bf PinLock} simulates a smart lock reading
user input from a serial port and deciding whether to unlock
(send an I/O signal) based on whether the SHA-256 hashed input matches
a precomputed hash.  The above five applications
represent real-world use cases of embedded devices and were also used
to evaluate previous work~\cite{EPOXY:Oakland17,ACES:UsenixSec18,uRAI:NDSS20}.

We used the LLVM compiler infrastructure~\cite{LLVM:CGO04} to compile
benchmarks and applications into the default non-XO format,
with MPU and DWT disabled; this is our baseline.  We then used
{\System}'s configuration, i.e. enabling MPU, DWT, and constant island
removal.  Note that with {\System}, none
of the benchmarks and applications exceeds the code size limitation
(128 KB) on our board.  Only {\tt cjpeg-rose7-preset} in CoreMark-Pro has a
code size larger than 64~KB and thereby has to run in unprivileged mode;
nevertheless, it does not require source code modifications as it does
not perform privileged operations.

%------------------------------------------------------------------------------
\subsection{Performance}
\label{sec:eval:perf}
%------------------------------------------------------------------------------

\input{tables/perf-coremark-pro}

\begin{figure}[tb]
  \centering
  \resizebox{1.0\columnwidth}{!}{%
    \includegraphics{figs/perf-apps}
  }
  \caption{Performance Overhead on Real-World Applications}
  \label{fig:perf-apps}
\end{figure}

We measured {\System}'s performance on our
benchmarks and applications.  We configured each BEEBS benchmark
to print the time, in milliseconds, for executing its workload 10,240
times.  We ran each BEEBS benchmark 10~times and report the average
execution time.  Each CoreMark-Pro benchmark
is pre-programmed to print out the execution time in a similar way; the
difference is that we configure each benchmark to run a minimal number
of iterations so that the program takes at least 10 seconds to run for
each experimental trial.  Again, we ran each benchmark 10~times and
report the average execution time.
For the real-world applications, we ran FatFs-RAM 10~times
and report the average execution time.  The other
applications exhibit higher variance in their execution times as
they access peripherals like an SD card, an LCD
screen, and a serial port, so we ran them
20~times and report the average with a standard deviation.
All other programs exhibit a standard deviation of zero.

Tables~\ref{tbl:perf-beebs} and~\ref{tbl:perf-coremark-pro}
and Figure~\ref{fig:perf-apps} present {\System}'s performance on BEEBS,
CoreMark-Pro, and the five real-world applications, respectively;
Figure~\ref{fig:perf-apps} shows
baseline execution time in milliseconds on top of the Baseline bars.
Overall, {\System} incurs negligible
performance overhead of 0.33\%: 0.46\% on BEEBS with a maximum of 7.48\%,
$-$0.11\% on CoreMark-Pro with a maximum of 0.17\%, and 0.02\% on
the applications with a maximum of 0.22\%.  Thirteen programs exhibit a
minor speedup with {\System}.  We re-ran our experiments with the MPU
and
DWT disabled so that the only change to performance is due to
constant island removal and the alignment of the code segment
(the DWT on ARMv7-M requires the monitored address range to be aligned
by its power-of-two size).
In this configuration, we observed the same speedups, so either
constant island removal and/or code alignment is causing the slight
performance improvement.

%------------------------------------------------------------------------------
\subsection{Code Size}
\label{sec:eval:mem}
%------------------------------------------------------------------------------

\input{tables/mem-beebs}

\begin{figure}[tb]
  \centering
  \resizebox{1.0\columnwidth}{!}{%
    \includegraphics{figs/mem-coremark-pro-apps}
  }
  \caption{Code Size Overhead on CoreMark-Pro and Real-World Applications}
  \label{fig:mem-coremark-pro-apps}
\end{figure}

We measured the code size of benchmarks and applications by using the
{\tt size} utility on generated binaries and collecting the {\tt .text}
segment size.

Table~\ref{tbl:mem-beebs} and Figure~\ref{fig:mem-coremark-pro-apps}
show the baseline code size and the overhead
incurred by {\System} on BEEBS, CoreMark-Pro, and the five real-world
applications, respectively.  On average, {\System} increases the code
size by 6.14\% on BEEBS, 4.39\% on CoreMark-Pro, and 6.52\% on the
real-world applications, with a 5.89\% overall overhead.
We studied {\System}'s code size overhead and
discovered that constant island removal caused
the majority of the code size overhead, especially for programs with
relatively large code bases like
CoreMark-Pro.  In fact, the additional code that sets up the MPU
and DWT only contributes a minor part of the overhead (1.22\% and 0.53\%
on average, respectively).

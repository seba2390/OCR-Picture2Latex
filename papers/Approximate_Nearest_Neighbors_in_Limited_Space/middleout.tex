\section{Practical Variant}\label{sec:middleout}
\cite{indyk2017practical} presented a simplified version of the sketch of~\cite{indyk2017near}, which is lossier by a factor $O(\log\log n)$ in the size bound (more precisely it uses $O(\epsilon^{-2}\log(n)(\log\log(n) + \log(1/\epsilon))+\log\log\Phi)$ bits per point; compare this to Table~\ref{tbl:sketches_related_work}), but on the other hand is practical to implement and was shown to work well empirically.
Both variants do not provably support out-of-sample queries.

In the main part of this work, we showed how to adapt the framework of~\cite{indyk2017near} to support out-of-sample queries with nearly optimal size bounds.
The goal of this section is to show that our techniques can also be applied in a simplified way to~\cite{indyk2017practical} in order to obtain a~\emph{practical} algorithm.
Specifically, focusing on the all-nearest-neighbors problem, we will show that a slight modification to~\cite{indyk2017practical} yields provable support in out-of-sample approximate nearest neighbor queries, with a size bound that is the same as in Theorem~\ref{thm:ann_ub} plus an additive $O(\epsilon^{-2}\log(n)\log\log(n))$ term.

\paragraph{Technique: Middle-out compression}
In~\cite{indyk2017practical}, every $1$-path is pruned (i.e.~replaced by a long edge) except for its top $\Lambda$ nodes, where $\Lambda$ is an integer parameter.
Combining this ``bottom-out'' compression with the ``top-out'' compression which was introduced in Section~\ref{sec:sketch}, we obtain~\emph{middle-out compression}: every long $1$-path longer than $2\Lambda$ is replaced by a long edge, except for its top and bottom $\Lambda$ nodes.
As we will show in the remainder of this section, applying this pruning rule to the quadtree of~\cite{indyk2017practical} (instead of their ``bottom-out'' rule) is sufficient to obtain a sketch that provably supports out-of-sample approximate nearest neighbor queries. Thus, the sketching algorithm is nearly unchanged.

We remark that in Section~\ref{sec:sketch} we introduced two additional modifications: \emph{grid-net quantization} and~\emph{surrogate hashing}. These were required in order to prove Theorems~\ref{thm:ann_ub} and~\ref{thm:distances_ub}, but in the framework of~\cite{indyk2017practical} they turn out to be unnecessary: grid-net quantization is already organically built into the quadtree approach of~\cite{indyk2017practical}, and surrogate hashing only served to avoid a $O(\log\log n)$ factor in the sketch size (see footnote 4), but in~\cite{indyk2017practical} this factor is tolerated anyway.

\subsection{Sketching Algorithm Recap}
For completeness, let us briefly describe the sketching algorithm of~\cite{indyk2017practical} (the reader is referred to that paper for more formal details), with our modification.
To this end, set
\[ \Lambda = \lceil\log\left(\frac{16d^{1.5}\log\Phi}{\epsilon\delta}\right)\rceil . \]
Suppose w.l.o.g.~that $\Phi$ is a power of $2$. The sketching algorithm proceeds in three steps:
\begin{enumerate}
  \item\emph{Random shifted grids:} Impose a randomly shifted enclosing hypercube on the data points $X$. More precisely, choose a uniformly random shift $\sigma\in\{-\Phi,\ldots,\Phi\}^d$, and set the enclosing hypercube to be $H=[-2\Phi+\sigma_1,2\Phi+\sigma_1]\times[-2\Phi+\sigma_2,2\Phi+\sigma_2]\times\ldots\times[-2\Phi+\sigma_d,2\Phi+\sigma_d]$. Since $X\subset\{-\Phi,\ldots,\Phi\}^d$, it is indeed enclosed by $H$. We then half $H$ along every dimension to create a finer grid with $2^d$ cells, and proceed so (recursively halving every cell along every dimension) to create a hierarchy of nested grids, with $\log(4\Phi)+\Lambda$ hierarchy levels. The top level is numbered $\Phi+2$, which is the log the side length of $H$, and the next levels are decrementing, so  that the grid cells in level $\ell$ have side length $2^\ell$.
  \item\emph{Quadtree construction:} Construct the quadtree which is naturally associated with the nested grids: the root corresponds to $H$, its children correspond to the non-empty cells of the next grid in the hierarchy (a cell is non-empty if it contains a point in $X$), and so on.
Each tree edge is annotated by a bitstring of length $d$, that marks whether the child cell coincides with the bottom half (bit $0$) or the top half (bit $1$) of the parent cell in each dimension.
  \item\emph{Middle-out compression:} For every path of degree-$1$ tree nodes whose length is more than $2\Lambda$, we keep its top $\Lambda$ and bottom $\Lambda$, and replace its remaining middle portion by a long edge. This removes the edge annotations of the middle section (this achieving compression). We label each long edge with the length of the path it replaces.
\end{enumerate}

In the remainder of this section we prove the following.
\begin{theorem}\label{thm:ann_practical}
The above algorithm, with the above setting of $\Lambda$, runs in time $\tilde O(nd(\log\Phi+\Lambda))$ and produces a sketch for the all-nearest-neighbors problem, whose size in bits is
\[
  O\left( n\left(\frac{\log n\cdot(\log\log n + \log(1/\epsilon))}{\epsilon^2} + \log\log\Phi + \log\left(\frac{q}{\delta}\right)\right) + d\log\Phi  + \log\left(\frac{q}{\delta}\right)\log\left(\frac{\log(q/\delta)}{\epsilon}\right) \right).
\]
\end{theorem}

The sketch size is the same as in~\cite{indyk2017practical}, except that we keep at most $2\Lambda$ instead of $\Lambda$ nodes per $1$-path, which increases the sketch size by only a factor of $2$.

\subsection{Basic lemmas}
We start with some useful properties of the above sketch, which are analogous to lemmas from in Section~\ref{sec:sketch}. In the notation below, for a node $v$ in the quadtree, $C(v)$ denotes the subset of points in $X$ that are contained in the grid cell associated with $v$. As in Section~\ref{sec:sketch}, the quadtree is partitioned into a set $\mathcal F(T)$ of~\emph{subtrees} by removing the long edges.

\begin{lemma}[analog of Lemma~\ref{lmm:separation}]\label{lmm:separation_quadtree}
For every point $x\in X$, with probability $1-\delta$, the following holds.
If $z\in\R^d$ is any point outside the grid cell that contains $x$ in level $\ell$ of the quadtree, then $\norm{x-x'}\geq 8\epsilon^{-1}\cdot2^{\ell-\Lambda}\sqrt{d}$.
\end{lemma}
\begin{proof}
The setting of $\Lambda$ is such that with probability $1-\delta$, in every level $\ell$ of the quadtree, the grid cell that contains $x$ also contains the ball at radius $8\epsilon^{-1}\cdot2^{\ell-\Lambda}\sqrt{d}$ around $x$. (This property is known as ``padding''.) The lemma is just a restatement of this property.
See Lemma 1 and Equation (1) in~\cite{indyk2017practical} for details.
\end{proof}

\begin{lemma}[analog of Lemmas~\ref{lmm:subtree_root}, \ref{lmm:subtree_leaf}, \ref{lmm:surrogates}]\label{lmm:samecell}
Let $v$ be a node in the quadtree, and $x,x'\in\R^d$ points contained in the grid cell associated with $v$. Then $\norm{x-x'}\leq2^{\ell(v)}\sqrt{d}$.
\end{lemma}
\begin{proof}
The grid cell associated with $v$ is a hypercube with side $2^{\ell(v)}$ and diameter $2^{\ell(v)}\sqrt{d}$.
\end{proof}

Before proceeding let us make the following point about the quadtree.
\begin{claim}\label{clm:quadtree_levels}
For every leaf $v$ of the quadtree, $C(v)$ contains a single point of $X$, and $v$ is the bottom of a $1$-path of length at least $\Lambda$.
\end{claim}
\begin{proof}
Refining the quadtree grid hierarchy for $\log(4\Phi)$ levels ensures that each grid cell contains at most one point from $X$, and refining for $\Lambda$ additional levels ensures that each leaf is the bottom of a $1$-path of length at least $\Lambda$.
\end{proof}

\begin{claim}\label{clm:leaves}
Every subtree leaf in the quadtree is the bottom of a $1$-path of length at least $\Lambda$.
\end{claim}
\begin{proof}
If $v$ is a leaf of the quadtree, this follows from Claim~\ref{clm:quadtree_levels}. Otherwise this follows from middle-out compression.
\end{proof}

Next we define centers and surrogates.
Centers $c(v)$ are chosen similarly to Section~\ref{sec:sketch}.
The surrogate $s^*(v)$ of every tree node $v$ is simply defined to be the ``bottom-left'' (i.e.~minimal in all dimensions) corner of the grid cell associated with $v$.

\subsection{Approximate Nearest Neighbor Search}
Finally, we can describe the query algorithm and complete its analysis.
Let $y$ be a query point for which we need to report an approximate nearest neighbor from the sketch. The query algorithm is the same as in Section~\ref{sec:ann}: starting with the subtree that contains the quadtree root, it recovers the surrogates in the current subtree and chooses the subtree $v$ whose surrogate is the closest to $y$. If $v$ is a quadtree leaf, its center is returned as the approximate nearest neighbor. Otherwise, the algorithm proceeds by recursion on the subtree under $v$.

\paragraph{Surrogate recovery}
The difference is in the way we recover the surrogates of a given subtree. In Section~\ref{sec:ann} this was done using the surrogate hashes. Here we will use a simpler, deterministic surrogate recovery subroutine.
Let $s^*(H)\in\R^d$ the surrogate of the quadtree root. (We store this point explicitly in the sketch, and it will be convenient to think of it w.l.o.g.~as the the origin in $\R^d$.) As observed in~\cite{indyk2017practical}, for every tree node $v$, if we concatenate the bits annotating the edges on the path from the root to $v$, we get the binary expansion of the point $s^*(H)+s^*(v)$. Therefore, we can recover $s^*(v)$ from the sketch, as long as the path from the root to $v$ does not traverse a long edge.

If the path to $v$ contains long edges (and thus missing bits in the binary expansion of $s^*(v)$), the algorithm completes these bits from the binary expansion of $y$.
Let $r_0,r_1,\ldots$ be the subtree roots traversed by the algorithm, and let $T_0,T_1,\ldots$ be the corresponding subtrees. Let $t$ be the smallest such that the algorithm does not recover the surrogates in $T_t$ correctly (because the bits missing on the long edge connecting $T_{t-1}$ to $T_t$ are not truly equal to those of $y$). As in Section~\ref{sec:ann}, the query algorithm does not know $t$ (it simply always assumes that the bits of $y$ are the correct missing ones), but we will use it for analysis.
Note that by definition of $t$, all surrogates in the subtrees rooted at $r_0,\ldots,r_{t-1}$ are recovered correctly. Thus, the event from Lemma~\ref{lmm:hashes} holds deterministically.

\paragraph{Proof of Theorem~\ref{thm:ann_practical}}
Let $x^*\in X$ be a fixed true nearest neighbor of $y$ in $X$ (chosen arbitrarily if there is more than one). We shall assume that the event in Lemma~\ref{lmm:separation_quadtree} occurs for $x^*$.

\begin{lemma}[analog of Lemma~\ref{lmm:annrounds}]\label{lmm:annrounds_quadtree}
Let $T'\in\mathcal F(T)$ be a subtree rooted in $r$, such that $x^*\in C(r)$.
Let $v$ a leaf of $T'$ that minimizes $\norm{y-s^*(v)}$.
Then either $x^*\in C(v)$,
or every $z\in C(v)$ is a $(1+O(\epsilon))$-approximate nearest neighbor of $y$.
\end{lemma}
\begin{proof}
If $x^*\in C(v)$ then we are done. Assume now that $x^*\in C(u)$ for a leaf $u\neq v$ of $T'$.
Let $\ell:=\max\{\ell(v),\ell(u)\}$. We start by showing that $\norm{y-x^*}>\epsilon^{-1}2^\ell\sqrt{d}$.
Assume by contradiction this is not the case.
Since $x^*\in C(u)$ we have $\norm{x^*-x_{c(u)}}\leq2^{\ell}\sqrt{d}$ by Lemma~\ref{lmm:samecell}, and similarly $\norm{x_{c(u)}-s^*(u)}\leq2^{\ell}\sqrt{d}$. Together, $\norm{y-s^*(u)}\leq(\epsilon^{-1}+2)2^\ell\sqrt{d}$.
On the other hand, by the triangle inequality,
$\norm{y-s^*(v)} \geq \norm{x^*-x_{c(v)}} - \norm{y-x^*} - \norm{x_{c(v)}-s^*(v)}$.
By Claim~\ref{clm:leaves}, both $v$ and $u$ are the bottom of $1$-paths of length at least $\Lambda$, This means that $x^*$ and $x_{c(v)}$ are separated already at level $\ell+\Lambda$, and by Lemma~\ref{lmm:separation_quadtree} this implies $\norm{x^*-x_{c(v)}}\geq8\epsilon^{-1}\cdot2^{\ell}\sqrt{d}$. By the contradiction hypothesis we have $\norm{y-x^*}\leq\epsilon^{-1}2^\ell\sqrt{d}$, and by Lemma~\ref{lmm:samecell}, $\norm{x_{c(v)}-s^*(v)}\leq2^\ell\sqrt{d}$. 
Putting these together yields $\norm{y-s^*(v)}\geq8\epsilon^{-1}\cdot2^{\ell}\sqrt{d}-\epsilon^{-1}2^\ell\sqrt{d}-2^\ell\sqrt{d} > (\epsilon^{-1}+2)2^\ell\sqrt{d}\geq \norm{x_{c(u)}-s^*(u)}$. This contradicts the choice of $v$.

The lemma now follows because for every $z\in C(v)$,
\begin{align}
\norm{y-z} &\leq \norm{y-s^*(v)} + \norm{s^*(v)-x_{c(v)}} + \norm{x_{c(v)}-z} \label{ineq1b} \\
&\leq \norm{y-s^*(u)} + \norm{s^*(v)-x_{c(v)}} + \norm{x_{c(v)}-z} \label{ineq2b} \\
&\leq \norm{y-x^*} + \norm{x^*-x_{c(u)}} + \norm{x_{c(u)}-s^*(u)} +\norm{s^*(v)-x_{c(v)}} + \norm{x_{c(v)}-z} \label{ineq3b} \\
&\leq \norm{y-x^*} + 4\cdot2^\ell\sqrt{d} \label{ineq4b} \\
&\leq (1+4\epsilon)\norm{y-x^*}, \label{ineq5b}
\end{align}
where~(\ref{ineq1b}) and (\ref{ineq3b}) are by the triangle inequality, (\ref{ineq2b}) is since $\norm{y-s^*(v)}\leq\norm{y-s^*(u)}$ by choice of $v$, (\ref{ineq4b}) is by applying Lemma~\ref{lmm:samecell} to each of the last four summands, and~(\ref{ineq5b}) is since we have shown that $\norm{y-x^*}>\epsilon^{-1}2^\ell\sqrt{d}$.
Therefore $z$ is a $(1+4\epsilon)$-approximate nearest neighbor of $y$.
\end{proof}

Now we prove that the query algorithm returns an approximate nearest neighbor for $y$.
We may assume w.l.o.g.~that $\epsilon$ is smaller than a sufficiently small constant.
We consider two cases. In the first case, $x^*\notin C(r_t)$.
Let $i\in\{1,\ldots,t\}$ be the smallest such that $x^*\notin C(r_i)$.
By applying Lemma~\ref{lmm:annrounds_quadtree} on $r_{i-1}$, we have that every point in $C(r_i)$ is a $(1+O(\epsilon))$-approximate nearest neighbor of $y$. After reaching $r_i$, the algorithm would return the center of some leaf reachable from $r_i$, and it would be a correct output.

In the second case, $x^*\in C(r_t)$ contains a true nearest neighbor of $y$. We will show that every point in $C(r_t)$ is a $(1+O(\epsilon))$-approximate nearest neighbor of $y$, so once again, once the algorithm arrives at $r_t$ it can return anything.
By definition of $t$, we know that $y$ does not reside in the grid cell associated with $r_t$. Since $y$ does reside in that cell, we have $\norm{y-x^*}\geq8\epsilon^{-1}2^{\ell(r_t)-\Lambda}\sqrt{d}$ by Lemma~\ref{lmm:separation_quadtree}. On the other hand, by Claim~\ref{clm:leaves}, $r_t$ is the bottom of a $1$-path of length at least $\Lambda$, and therefore any two points in $C(r_t)$ are contained in the same grid cell at level $\ell(r_t)-\Lambda$, whose diameter is $2^{\ell(r_t)-\Lambda}\sqrt{d}$. In particular, for every $x\in C(r_t)$ we have $\norm{x-x^*}\leq2^{\ell(r_t)-\Lambda}\sqrt{d}\leq\frac{1}{8}\epsilon\norm{y-x^*}$. Altogether we get $\norm{y-x} \leq \norm{y-x^*} + \norm{x^*-x} \leq (1+\frac{1}{8}\epsilon)\norm{y-x^*}$, so every $x\in C(r_t)$ is a $(1+\epsilon)$-approximate nearest neighbor of $y$ in $X$.

The proof assumes the event in Lemma~\ref{lmm:separation_quadtree} holds for $x^*$, which happens with probability $1-\delta$. To handle $q$ queries, we can scale $\delta$ down to $\delta/q$ and take a union bound over the $q$ nearest neighbors of the $q$ query points. \qed

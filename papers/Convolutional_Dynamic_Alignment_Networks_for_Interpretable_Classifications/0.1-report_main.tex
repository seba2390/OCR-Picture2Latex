% This version of CVPR template is provided by Ming-Ming Cheng.
% Please leave an issue if you found a bug:
% https://github.com/MCG-NKU/CVPR_Template.
\documentclass[final]{cvpr}
\include{0.0-packages_and_commands}
\begin{document}
\justifying

%%%%%%%%% TITLE
\title{Convolutional Dynamic Alignment Networks for Interpretable Classifications}


%%%%%%%%% AUTHORS
\author{Moritz BÃ¶hle\\
\normalsize{MPI for Informatics}\\ 
\normalsize{Saarland Informatics Campus}
\and
Mario Fritz\\
\normalsize{CISPA Helmholtz Center}\\
\normalsize{for Information Security}
\and
Bernt Schiele\\
\normalsize{MPI for Informatics}\\ 
\normalsize{Saarland Informatics Campus}
}



%%%%%%%%% TEASER FIGURE
\twocolumn[{%
\renewcommand\twocolumn[1][]{#1}%
\maketitle
\begin{center}
    \centering
    \captionsetup{type=figure}
    \includegraphics[width=.925\textwidth]{resources/CoDA-Teaser.pdf}
    \captionof{figure}{\small {
    Sketch of a 9-layer CoDA-Net, which computes its {\bf \color[RGB]{0, 136, 43} output $\vec {a_9}$} for an  {\bf \color[RGB]{3, 101, 192}input $\vec {a_0}$} as a linear transform via a  matrix {\color[RGB]{200, 37, 6}$\mat {W_{0\rightarrow9}(\vec a_0)}$}, such that the output can be linearly decomposed into input contributions (see right). {\color[RGB]{200, 37, 6}$\mat {w_{0\rightarrow9}}$} is computed successively via multiple layers of Dynamic Alignment Units (DAUs), which produce matrices {\color[RGB]{200, 37, 6}$\mat w_l$} that align with their respective inputs $\vec a_{l-1}$. As a result, the combined matrix {\color[RGB]{200, 37, 6}$\mat {w_{0\rightarrow9}}$} aligns well with task-relevant patterns. Positive (negative) contributions for the class `goldfinch' are shown in red (blue).}}
    \label{fig:teaser}
\end{center}%
\bigskip
}]
\thispagestyle{fancy}

%%%%%%%%% ABSTRACT


\begin{abstract}
We introduce a new family of neural network models called Convolutional Dynamic Alignment Networks\footnote{Code will be available at \url{github.com/moboehle/CoDA-Nets}.} (CoDA-Nets),
which are performant classifiers with a high degree of inherent interpretability. 
{Their core building blocks are Dynamic Alignment Units (DAUs), which \mbox{{linearly transform}} their input with weight vectors that \mbox{{dynamically align}} with task-relevant patterns.} As a result, CoDA-Nets model the classification prediction through a series of input-dependent linear transformations, allowing for linear decomposition of the output into individual input contributions.
    Given the alignment of the DAUs, the resulting contribution maps 
    align with discriminative input patterns. 
These model-inherent decompositions are of high visual quality and  outperform existing attribution methods under quantitative metrics. 
Further, CoDA-Nets constitute performant classifiers, achieving on par results 
to ResNet and VGG models on e.g. CIFAR-10 and TinyImagenet.

\end{abstract}
%
%%%%%%%%% BODY TEXT
%
\section{Introduction}
\label{sec:intro}
\input{1-introduction}
\section{Related work}
\label{sec:related}
\input{2-related_work}
\input{3-method}
\section{Results}
\label{sec:results}
\input{4.0-results}
\input{4.2-accuracy}
\input{4.3-interpretability}
\input{5-discussion}
{\small
\justifying
\bibliographystyle{ieee_fullname}
\bibliography{main_bib}
\justifying
}
\clearpage
\input{supplement/appendix_content}

\end{document}

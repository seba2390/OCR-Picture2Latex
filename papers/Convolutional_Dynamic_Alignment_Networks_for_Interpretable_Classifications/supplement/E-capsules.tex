\section{Comparison to capsule networks}
\label{sec:capsule_comparison}
In order to discuss the relationship to capsule networks, in section~\ref{subsec:capsule_diff_notation} we will first rewrite the classical capsule formulation in
    `Dynamic Routing Between Capsules' by Sabour et al.~\citesupp{sabour2017dynamic} 
    to mitigate the notational differences between their work and our work.
In section~\ref{subsec:capsule_diff_usage} we then show that while capsules and Dynamic Alignment Units share some computations, there are several important differences that we summarise in Table~\ref{tbl:caps}.
\begin{table}[th]
    \vspace{.5em}
    \centering
    \begin{tabular}{r | c c}
        &\small\textbf{Classical capsules$\,\,$} &
        \small\textbf{Dynamic Alignment Units} \\\cline{1-3}&&\\[-.1em]
         \small\textbf{Non-Lin. $g$} &
         \small
         SQ&
         \small
         SQ, L2, ...\\[.5em]
         \small\textbf{Activations} &
         \small
         $ g\left(\mat v \vec x\right)$&
         \small$
         g\left(\mat{AB}\vec x+ \vec b\right)$\\[.5em]
         \small\textbf{Routing} &
         \small\textbf{yes} &
         \small\textbf{no}\\[.5em]
         \small\textbf{Low-rank} &
         \small\textbf{no} &
         \small\textbf{yes}\\[.5em]
         \small\textbf{Output} &
         $\text{CAP}(\vec x)$ &
         $\text{CAP}(\vec x)^T\vec x$
    \end{tabular}
    \caption{Comparison between capsules and Dynamic Alignment Units (DAUs). Importantly, DAUs produce a linear transformation of the input by multiplying the `capsule activations' with the input (see `Output') and allow for constraining the rank of the transformation. The dynamic weights in the DAUs can be seen as the activations of a capsule, s.t.~$\vec w(\vec x)=\text{CAP}(\vec x)$, see `Output' in the table.}
    \label{tbl:caps}
    \vspace{-.5em}
\end{table}
\subsection{Reformulating capsules}
\label{subsec:capsule_diff_notation}
In this subsection, we will show that the classical capsule formulation (eq.~\eqref{eq:sabour_caps1}), in which input capsules `vote' for the activations of an output capsule, can be written as a simple linear transformation $\vec S = \mat v \vec x$ if just one iteration of the dynamic routing algorithm is applied; here, $\vec s$ is a vector containing the activations of the output capsule, $\mat v$ stores the `votes' of the input capsules to an output capsule, and $\vec x$ is a vector containing the activations of all input capsules. In the following, we will start from how capsules are formulated in~\citesupp{sabour2017dynamic} and rewrite this formulation step by step.

In~\citesupp{sabour2017dynamic} eq.~(2), the authors calculate the activations $\vec s$ of a capsule\footnote{
    As we only discuss a single output capsule, we omitted the subscript $j$ for the $j$-th output capsule for simplicity.} \emph{before} any routing
    or non-linearity as 
%
\begin{align}
    \label{eq:sabour_caps1}
    \vec s = \sum_i c_{i}\hat{\vec u}_{i}\,\,, \quad \hat{\vec u}_{i} = \mat{W}_{i} \vec u_i\quad\text{.}
\end{align}
Here, $\vec{u}_i$ is the capsule vector of capsule $i$ from the incoming layer and 
    $\mat W_{i}$ a matrix which transforms the capsule activations to generate the votes $\hat{\vec u}_{i}$,
    i.e., the vote of the $i$-th incoming capsule to the output capsule in the current layer.
    Note that $c_{i}$ are the coefficients for the dynamic routing algorithm. If no routing is applied, they
        can be combined with $\mat W_{i}$ to yield $\widetilde{\mat{W}}_{i} = c_{i}\mat W_{i}$,
    which simplifies eq.~\eqref{eq:sabour_caps1} to
\begin{align}
    \label{eq:sabour_caps2}
    \vec s = \sum_i \hat{\vec u}_{i}\,\,, \quad \hat{\vec u}_{i} = \widetilde{\mat{W}}_{i} \vec u_i\quad\text{.}
\end{align}
Further, we note that the linear transformation of $\vec u_i$ can be represented as votes of the individual
    entries $t$ of $\vec u_i$:
\begin{align}
    \label{eq:sabour_caps3}
    \hat{\vec u}_{i} = \widetilde{\mat{W}}_{i} \vec u_i = \sum_t \left[\vec u_i\right]_t \left[\widetilde{\mat W}_{i}^T\right]_t \quad\text{.}
\end{align}  
Here, 
    $\left[ \mat W\right]_t$ denotes the $t$-th row in a matrix $\mat W$ (equivalently for a vector).
    %
Inserting this formulation of $\hat{\vec u}_{i}$ in eq.~\eqref{eq:sabour_caps2} yields
\begin{align}
    \label{eq:sabour_caps4}
    \vec s = \sum_i \sum_t \left[\vec u_i\right]_t \left[\widetilde{\mat W}_{i}^T\right]_t \quad\text{.}
\end{align}
Hence, $\vec s$ can be represented as the result of votes from all neurons $u$ contained in any of the incoming capsules (note that we sum over all entries in all capsules).
If we represent the activations of these neurons in a single vector $\vec x$, denote their activations by $x_u$,
    and their respective votes for the output capsule by ${\vec v}_u$
    we can write eq.~\eqref{eq:sabour_caps4} as:
\begin{align}
   \vec s = \sum_i \sum_t \displaystyle\overbrace{\left[\vec u_i\right]_t}^{\widehat{=} x_u} \;
                                \overbrace{\left[\widetilde{\mat W}_{i}^T\right]_t}^{\widehat{=} {\vec v}_u}
                                = \sum_u x_u {\vec v}_u
    \quad\text{.}
    \label{eq:sabour_caps6}
\end{align}
The sum on the right hand side in eq.~\eqref{eq:sabour_caps6}, in turn, can be expressed as a simple matrix-vector multiplication, such that
\begin{align}
    \vec s = \sum_u x_u\vec v_u = \mat v \vec x
    \label{eq:sabour_caps7}
\end{align}
with $\vec v_u$ as the columns of \tmat v.
The result is, of course, trivial and only shows that the capsule activations (a weighted sum of the inputs, eq.~\eqref{eq:sabour_caps1}) are obtained as a linear transformation of the input if no dynamic routing is applied.

Finally, we note that subsequent to this linear transformation, the authors in~\citesupp{sabour2017dynamic} apply the squashing function SQ (see eq.~(2) in our main paper) to the output vector $\vec s$, which yields the final capsule output $\text{CAP}(\vec x)$:
\begin{align}
    \text{CAP}(\vec x) = \text{SQ}(\vec s(\vec x)) = \text{SQ}(\mat v\vec x)\quad .
    \label{eq:sabour_caps8}
\end{align}
    
\subsection{Differences to capsules}
\label{subsec:capsule_diff_usage}
In the previous section we showed that the activation of a single capsule is computed as a linear transformation of all input activations, which is subsequently squashed (see eq.~\eqref{eq:sabour_caps8}).
Comparing this with the computation of the DAU outputs (eq.~(1) in our main paper), we see that this is equivalent to the dynamic weight computation if $\mat v =\mat{ab}$ and $\vec b=\vec 0$.
As such, Dynamic Alignment Units and capsules are related. However, there are important differences, which we discuss in the following and summarise in Table~\ref{tbl:caps}.

First, in~\citesupp{sabour2017dynamic}, the squashed capsule activations $\text{CAP}(\vec x)$
    are used as input to the next layer (after potentially applying the dynamic routing algorithm first).
    Instead of forwarding the squashed activations directly, in our DAUs they are used to linearly transform the input.
Second, by factorising the matrix $\mat v$ into two matrices $\mat{ab}$, we are able to control the rank of the linear transformation. Third,
when computing the weights in the DAUs we allow for an additional bias term, which in the context of capsules can be considered a `default vote'.
Fourth, we generalise the non-linearity in the DAUs to any non-linearity that only changes the norm.
Lastly, we do not apply dynamic routing in the DAUs.
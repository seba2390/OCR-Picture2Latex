\section{Additional quantitative results}
\label{sec:additional_quantitative}

\myparagraph{Performance / interpretability trade-off.}
While the CoDA-Nets were observed to train and perform well over a wide range of choices for the logit temperature $T$, there seems to be a trade-off between the accuracies of the network and their interpretability---the implicit alignment regularisation comes at a cost. For example, in Fig.~\ref{fig:T_ablation}, we contrast the gain in interpretability (left, same figure as in main paper) with the corresponding accuracies (right). 
\begin{figure}
\centering
    \begin{subfigure}[c]{\textwidth}
    \centering
    % CIFAR10 Localisation L2 non-linearity 
    \begin{subfigure}[c]{0.45\textwidth}
    \centering
    \includegraphics[width=\textwidth, trim=0 1em 0 1em, clip]{resources/CIFAR10-t_scaling.pdf}
    \end{subfigure}
    % CIFAR10 Pixel Removal L2 non-linearity
    \begin{subfigure}[c]{0.45\textwidth}
    \centering
\includegraphics[width=\textwidth]{supplement/resources/ablations/CIFAR10-t_scaling-accs.pdf}
    \end{subfigure}
    \vspace{.75em}
    \end{subfigure}
    \caption{\textbf{Left:} Localisation metric results for models trained with different temperatures $T$, same as in main paper (see Fig.~6, top right). 
    \textbf{Right:} Corresponding accuracies of the models on the CIFAR10 test set. There seems to be a trade-off between the interpretability and the accuracy of the models due to the regularising effect of $T$.}
    \label{fig:T_ablation}
\end{figure}

\myparagraph{Model size vs.~accuracy.}
Given the quadratic form in the DAUs (cf.~eq.~(1), $\approx \vec x^T\mat M \vec x$), the number of parameters per DAU scales quadratically with the input dimensions. In order to limit the model size, we decided to explicitly limit the rank of the DAUs by factorising the matrix $\mat M$ into $\mat a\mat b$ with $\mat a\in\mathbb{R}^{d\times r}$ and $\mat b\in\mathbb{R}^{r\times d}$.
While this allows to be more parameter efficient, it, of course, affects the modelling capacity of the DAUs. In Fig.~\ref{fig:R_ablation}, we present how the accuracy changes with the model size; for this, we scaled the ranks of all DAUs per layer with factors of 1/8, 1/4, 1/2, and 4.5 compared to the S-CoDA-SQ model presented in the main paper. This results in models with 1.1M, 2.0M, 4.0M, and 34.6M parameters respectively. For comparison, the original model is also included in Fig.~\ref{fig:R_ablation} (8M parameters).
\begin{figure}
\centering
    \begin{subfigure}[c]{\textwidth}
    \centering
    % CIFAR10 Localisation L2 non-linearity 
    \begin{subfigure}[c]{0.45\textwidth}
    \centering
    \includegraphics[width=\textwidth, trim=0 1em 0 1em, clip]{supplement/resources/ablations/CIFAR10-rank_ablation-accs.pdf}
    \end{subfigure}
    % CIFAR10 Pixel Removal L2 non-linearity
    \vspace{.75em}
    \end{subfigure}
    \caption{Effect of scaling the rank of the DAUs in the CoDA-Nets on accuracy. Specifically, all ranks in the S-CoDA-SQ model presented in the main paper were scaled with the same factor, thereby changing the model size. The original model is shown with 8M parameters for comparison.}
    \label{fig:R_ablation}
\end{figure}


\myparagraph{Results for L2 non-linearity.}
In Fig.~\ref{fig:l2_ablation} we show the results of evaluating the different methods for importance attribution on a model with the L2 non-linearity, see~eq.~(2) in the main paper. As can be seen, the results are very similar to those presented in the main paper in Fig.~6 (center column); in particular, the model-inherent contribution maps outperform the other methods under the localisation metric and are on par with the occlusion methods under the pixel removal metric; note, however, that the occlusion methods are a direct estimate of the behaviour under pixel removal and therefore expected to perform well under this metric.
\begin{figure}
\centering
    \begin{subfigure}[c]{\textwidth}
    \centering
    % CIFAR10 Localisation L2 non-linearity 
    \begin{subfigure}[c]{0.45\textwidth}
    \centering
    \includegraphics[width=\textwidth, trim=0 1em 0 1em, clip]{supplement/resources/ablations/CIFAR10-cvpr2021_3-9L-DLCN-L2-S-norm-1000-500_3x3-srtd.pdf}
    \end{subfigure}
    % CIFAR10 Pixel Removal L2 non-linearity
    \begin{subfigure}[c]{0.45\textwidth}
    \centering
    \includegraphics[width=\textwidth, trim=0 1em 0 1em, clip]{supplement/resources/ablations/CIFAR10-cvpr2021_3-9L-DLCN-L2-S-norm-1000-default.pdf}
    \end{subfigure}
    \caption{The quantitative results for a CoDA-Net trained with the L2 non-linearity are very similar to those of a model trained with the squashing non-linearity, see eq.~(2) in the main paper and compare with Fig.~6 (center column) in the main paper. In particular, we observe that the CoDA-Net outperforms the other methods under the localisation metric and achieves similar performance to the occlusion attribution method, which directly estimates the change in model prediction when removing a pixel.}
    \label{fig:l2_ablation}
    \vspace{.75em}
    \end{subfigure}
    \begin{subfigure}[c]{\textwidth}
    \centering
    % CIFAR10 Localisation regularise W_{0 -> L}  
    \begin{subfigure}[c]{0.45\textwidth}
    \centering
    \includegraphics[width=\textwidth, trim=0 1em 0 1em, clip]{supplement/resources/ablations/CIFAR10-regul_strength.pdf}
    \end{subfigure}
    % CIFAR10 Pixel Removal regularise W_{0 -> L} 
    \begin{subfigure}[c]{0.45\textwidth}
    \centering
    \includegraphics[width=\textwidth, trim=0 1em 0 1em, clip]{supplement/resources/ablations/CIFAR10-regul_impact-regul_strength.pdf}
    \end{subfigure}
    \caption{Similar to the effect of temperature scaling, cf.~Fig.~6 (right column) in the main paper, here we show quantitative results for different regularisation strengths $\lambda$. Similar to increasing the temperature, stronger regularisations also improve the localisation metric (left). While the pixel perturbation metric (right) also improves at first ($\lambda = 0.01$ and $\lambda = 0.05$), the models become less stable for stronger regularisation strengths. In comparison, we found that increasing the temperature also improves the performance of the models under this metric, see Fig.~6 (right column) in the main paper.}
    \label{fig:regul_ablation}
    \vspace{.75em}
    \end{subfigure}
    \caption{Quantitative results for two ablations: (a) using the L2 non-linearity and (b) increasing the regularisation of the linear mapping $\mat W_{0\rightarrow L}$, see~eqs.~(2) and (10) in the main paper respectively. Compare with Fig.~6 in the main paper.}
\end{figure}
\begin{figure}
\centering
    \begin{subfigure}[c]{\textwidth}
    \centering
    % TinyImagenet Pixel Removal most important
    \begin{subfigure}[c]{0.45\textwidth}
    \centering
    \includegraphics[width=\textwidth]{supplement/resources/ablations/TinyImagenet-cvpr2021-widenet-0-most_important.pdf}
    \end{subfigure}
    \caption{Results for the pixel removal metric when first removing the most important pixels. As can be seen, the ranking given by the model-inherent contribution maps seems to best reflect the pixel importance, since the confidence most rapidly drops when removing pixels according to this ranking.}
    \label{fig:most_important}
    \vspace{.75em}
    \end{subfigure}
    \begin{subfigure}[c]{\textwidth}
    \centering
    % CIFAR10 Localisation ResNet-56
    \begin{subfigure}[c]{0.45\textwidth}
    \centering
    \includegraphics[width=\textwidth, trim=0 1em 0 1em, clip]{supplement/resources/ablations/CIFAR10-resnets-resnet56-pretrained-500_3x3-srtd.pdf}
    \end{subfigure}
    % CIFAR10 Pixel Removal ResNet-56
    \begin{subfigure}[c]{0.45\textwidth}
    \centering
    \includegraphics[width=\textwidth, trim=0 1em 0 1em, clip]{supplement/resources/ablations/CIFAR10-resnets-resnet56-pretrained-default.pdf}
    \end{subfigure}
    \caption{Quantitative results for methods for importance attribtution evaluated on a pre-trained ResNet-56 on CIFAR-10. Comparing these results to Fig.~6 (center column) in the main paper or Fig.~\ref{fig:l2_ablation}, it can be seen that the model-inherent contribution maps of the CoDA-Net are also strong when compared to importance attributions evaluated on a different model.}
    \label{fig:resnet_results}
    \vspace{.75em}
    \end{subfigure}
    \caption{In (a) we show the results of the pixel-removal metric when removing those pixels first that are considered the most important ones according to the importance attribution method. Moreover, in (b) we plot the quantitative results for the evaluation metrics of the importance attributions for a pre-trained ResNet-56.}
    \vspace{-.25em}
\end{figure}

\myparagraph{Regularisation of $\mat w_{0\rightarrow L}$.} In Fig.~\ref{fig:regul_ablation}, we show the results of the localisation metric and the pixel removal metric for models trained on CIFAR-10 with different regularisation strengths $\lambda$, see~eq.~(10) in the main paper. We note that the localisation metric benefits from an increase in the regularisation strength $\lambda$. For the pixel removal metric, we observe that while the models improve at first under this metric, a strong regularisation makes the predictions more brittle. 

\myparagraph{Removing the \emph{most important} pixels first.} In Fig.~\ref{fig:most_important}, we show the results of the pixel removal metric when removing the most important pixels first. As can be seen, the model-inherent contributions better predict the importance of pixels and outperform the other attribution methods under this metric; in particular, the confidence drops most rapidly when removing pixels according to the ranking given by the model-inherent contribution maps.

\myparagraph{Evaluating a pre-trained ResNet.} 
In order to establish a baseline for the performance of the different attribution methods on a classical neural network architecture, we additionally evaluated the attribution methods on a pre-trained ResNet and show the results in Fig.~\ref{fig:resnet_results}. Specifically, we rely on a publicly available 
    pre-trained ResNet-56 obtained from
    \mbox{\url{https://github.com/akamaster/pytorch_resnet_cifar10}}, which achieves a classification accuracy of $93.39\%$. 
%
The results show that the performance of the CoDA-Net-derived contribution maps is not only strong when comparing them to attribution methods evaluated \emph{on the same model}. Instead, they also perform well in comparison to those methods evaluated \emph{on a different model}. In particular, the model-inherent contribution maps of the CoDA-Net outperform attribution methods evaluated on the pre-trained ResNet-56 under the localisation metric. Further, only the occlusion attributions produce similarly strong pixel importance rankings for the ResNet; note, however, that the occlusion methods are a direct estimate of the behaviour under pixel removal and therefore expected to perform well under this metric.
    
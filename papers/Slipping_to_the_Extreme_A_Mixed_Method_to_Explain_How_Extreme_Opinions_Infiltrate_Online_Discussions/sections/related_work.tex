

\section{Related Work}
\textbf{Problematic speech datasets.}
Several datasets \citep{wang2017liar,shu2018fakenewsnet,hasan2020truth} on problematic speeches have been made available recently. Among these, \citet{wang2017liar,shu2018fakenewsnet} crawled and used labels from existing fact-checking sites (e.g., POLITIFACT\footnote{\url{https://www.politifact.com}}), whereas \citet{hasan2020truth} employed an active learning component in their pipeline with a goal of maximizing the accuracy of fake news detection.

\textbf{Human-in-the-loop.}
HITL machine learning algorithms have been widely applied for building datasets in various applications, including sentiment analysis \citep{mozafari2014scaling}, computer vision \citep{vijayanarasimhan2011cost} and medical image classification \citep{hoi2006batch}. 
\citet{wang2021putting} provide a comprehensive review of applying HITL methods to natural language processing tasks, in which they stress the importance of designing both quantitative and qualitative methods to evaluate human feedback for complex feedback types. 
In particular, \citet{chen2018using} propose to identify ambiguity in qualitative coding via active learning, which is the most relevant work to ours. 
In this paper, we extend the method by introducing two other strategies to balance exploration and exploitation.

Overall, our study differs from prior works by highlighting the benefits of deploying HITL algorithms to accelerate qualitative studies on online problematic speeches. The augmented data in this paper exposes us to a richer context of problematic discussions where we can identify trajectories of opinion evolutions (in \Cref{sec:opinion-analysis}).


\subsection{Proof of Theorem~\ref{thm:ERM_necessary}}\label{proof:ERM_necessary}
We first show that for sufficiently large $\kappa \in (0, \infty)$ and if $n$ is not sufficiently large, 
$S$ can be linearly separable because data points usually concentrated around $\vmu$ and $-\vmu$. Next, we characterize cosine similarity between $\ell_2$ max-margin vector and the Bayes optimal solution. In our analysis, we use the following well-known lemma (See \citet{hanson1971bound,lugosi2019sub}).

\begin{lemma}\label{lemma:gaussian norm}
For positive definite matrix $\mM$, let $\rvx \sim N(\vzero, \mM)$. For any $\delta \in (0,1)$ 
\begin{equation*}
\lVert \rvx \rVert \leq  \Tr(\mM)^{1/2} + (2 \lVert \mM \rVert \log(1/\delta))^{1/2},
\end{equation*}
with probability at least $1-\delta$.
\end{lemma}
First, we introduce some technical quantities. Let $\delta = 0.99$ and $t = \left (\Tr( \mSigma)^{1/2} + (2 \lVert \mSigma \rVert \log(n/\delta))^{1/2} \right )/\lVert \vmu \rVert$ with
\begin{equation}\label{eqn:ERM_nec}
    n \leq \delta \exp\left( \frac{1}{2} \lVert \mSigma \rVert^{-1} \left( \kappa^{1/2}\lVert \vmu \rVert \cdot \frac{1- \cosim(\vmu, \mSigma^{-1} \vmu)}{2} - \Tr(\mSigma)^{1/2}\right)^2 \right) = \exp(\Theta(\kappa)),
\end{equation}
and we assume $\kappa$ is large enough so that $\kappa^{1/2}\lVert \vmu \rVert \cdot \frac{1- \cosim(\vmu, \mSigma^{-1} \vmu)}{2} - \Tr(\mSigma)^{1/2} >0$.
Then, by substituting $n$ in the definition of $t$ by RHS of \Eqref{eqn:ERM_nec} we have
\begin{align*}
\lVert \vmu \rVert t 
&= \Tr( \mSigma)^{1/2} + (2 \lVert \mSigma \rVert \log(n/\delta))^{1/2}\\
&\leq \Tr( \mSigma)^{1/2} + \left[ 2 \lVert \mSigma \rVert \log\left (\exp\left( \frac{1}{2} \lVert \mSigma \rVert^{-1} \left( \kappa^{1/2}\lVert \vmu \rVert \cdot \frac{1- \cosim(\vmu, \mSigma^{-1} \vmu)}{2} - \Tr(\mSigma)^{1/2}\right)^2 \right) \right) \right]^{1/2}\\
&= \Tr( \mSigma)^{1/2} + \left[ 2 \lVert \mSigma \rVert \left\{ \frac{1}{2} \lVert \mSigma \rVert^{-1} \left( \kappa^{1/2}\lVert \vmu \rVert \cdot \frac{1- \cosim(\vmu, \mSigma^{-1} \vmu)}{2} - \Tr(\mSigma)^{1/2}\right)^2 \right\}  \right]^{1/2}\\
&= \Tr( \mSigma)^{1/2} + \left[ \left( \kappa^{1/2}\lVert \vmu \rVert \cdot \frac{1- \cosim(\vmu, \mSigma^{-1} \vmu)}{2} - \Tr(\mSigma)^{1/2}\right)^2   \right]^{1/2}\\
&= \kappa^{1/2}\lVert \vmu \rVert \cdot\frac{1- \cosim(\vmu, \mSigma^{-1} \vmu)}{2}.
\end{align*}
Thus, 
\begin{equation}
\kappa^{-1/2} t \leq \frac{1-\cosim(\vmu, \mSigma^{-1}\vmu)}{2} < \sqrt{1-\cosim(\vmu, \mSigma^{-1}\vmu)^2}.
\label{eqn:ERM_Necessary-3}
\end{equation}
Next, we investigate how much positive and negative data points are concentrated near their means $\vmu$ and $-\vmu$. By applying Lemma~\ref{lemma:gaussian norm} with $\mM = \kappa^{-1}\mSigma$, for each $i\in [n]$, $\lVert (2y_i-1) \vx_i -  \vmu \rVert \leq \kappa^{-1/2} t \lVert \vmu \rVert$ with probability at least $1-\delta/n$; to see why, recall the definition of $t$. Hence, by union bound, we have $\lVert (2y_i-1) \vx_i -  \vmu \rVert  \leq \kappa^{-1/2}t \lVert \vmu \rVert$ for all $i\in [n]$, with probability at least $1-\delta$. We now condition that this event occurred and we prove that our conclusion holds. First, $S$ is strictly linearly separable by $\vmu$ since 
\begin{align*}
     (2y_i-1) \vmu^\top \vx_i &= \vmu^\top \big((2y_i-1)\vx_i - \vmu \big) + \lVert \vmu \rVert^2\\
     &\geq  \left(- \lVert(2y_i-1)\vx_i - \vmu \rVert +\lVert \vmu \rVert \right)\lVert \vmu \rVert \\
     &\geq (1-\kappa^{-1/2}t) \lVert \vmu\rVert^2 \\
     &\geq  \frac{1+\cosim(\vmu, \mSigma^{-1}\vmu)}{2} \cdot \lVert \vmu\rVert^2 \\
     &>0.
\end{align*}
Hence, there exists $\ell_2$ max-margin vector 
\begin{equation*}
    \bar{\vw}_S = \argmin_{\vw\in \mathbb{R}^d} \lVert \vw \rVert^2 \quad \text{subject to} \quad (2y_i-1) \vw^\top \vx_i \geq 1 \quad \forall i\in [n].
\end{equation*}
From the KKT condition of problem above, we have $\bar{\vw}_S = \sum_{i=1}^n \alpha_i (2y_i-1)\vx_i$ where $\alpha_i \geq 0$ for all $i \in [n]$. By triangular inequality, we have
\begin{equation*}
    \cosim(\bar{\vw}_S, \vmu) = \frac{\vmu^\top \bar{\vw}_S} {\lVert \vmu \rVert \lVert \bar{\vw}_S \rVert}
    = \frac{\vmu^\top (\sum_{i=1}^n \alpha_i (2y_i-1)\vx_i)} {\lVert \vmu \rVert \lVert \sum_{i=1}^n \alpha_i (2y_i-1)\vx_i \rVert}
    \geq \frac{\sum_{i=1}^n \alpha_i \vmu^\top (2y_i-1)\vx_i} { \sum_{i=1}^n \alpha_i \lVert \vmu\rVert \lVert (2y_i-1)\vx_i \rVert}.
\end{equation*}
Also, for all $i \in [n]$,
\begin{align*}
    \frac{\vmu^\top (2y_i-1)\vx_i}{\lVert \vmu\rVert \lVert (2y_i-1)\vx_i \rVert} &= \cosim(\vmu, (2y_i-1)\vx_i )
    = \left (1-\sin^2 \angle(\vmu, (2y_i-1)\vx_i) \right )^{1/2}\\
    &\geq \left ( 1-\left ( \frac{\lVert (2y_i-1)\vx_i - \vmu \rVert}{\lVert \vmu \rVert} \right)^2 \right)^{1/2}
    \geq \sqrt{1-\kappa^{-1}t^2}\\
    & \geq \cosim(\vmu, \mSigma^{-1}\vmu),
\end{align*}
where the last inequality used \Eqref{eqn:ERM_Necessary-3}.
Hence, we have $\cosim(\bar{\vw}_S, \vmu) \geq \sqrt{1-\kappa^{-1} t^2} \geq \cosim(\vmu, \mSigma^{-1}\vmu)$. By triangular inequality for angle, 
\begin{equation*}
    \angle(\bar{\vw}_S, \mSigma^{-1}\vmu) \geq \angle(\vmu, \mSigma^{-1}\vmu) - \angle(\bar{\vw}_S, \vmu)\geq \cos^{-1}(\cosim(\vmu, \mSigma^{-1}\vmu)) - \cos^{-1}\left(\sqrt{1-\kappa^{-1}t^2}\right)\geq 0,
\end{equation*}
and we have
\begin{align}\label{eqn:ERM_Necessary-1}
    &\quad \cosim (\bar{\vw}_S, \mSigma^{-1}\vmu) \nonumber \\
    & \leq \cos \left( \cos^{-1}(\cosim(\vmu, \mSigma^{-1}\vmu)) - \cos^{-1}\left(\sqrt{1-\kappa^{-1}t^2}\right) \right)\nonumber \\
    &= \cos \left(\cos^{-1}(\cosim(\vmu, \mSigma^{-1}\vmu))\right)\cdot  \cos \left(\cos^{-1}\left(\sqrt{1-\kappa^{-1}t^2}\right)\right)\nonumber \\
    &\quad + \sin \left(\cos^{-1}(\cosim(\vmu, \mSigma^{-1}\vmu))\right) \cdot \sin \left(\cos^{-1}\left(\sqrt{1-\kappa^{-1}t^2}\right)\right) \nonumber \\
    &= \cosim(\vmu, \mSigma^{-1}\vmu) \cdot \sqrt{1-\kappa^{-1}t^2} + \sqrt{1-\cosim(\vmu, \mSigma^{-1}\vmu)^2} \cdot \kappa^{-1/2}t\nonumber \\
    &= \cosim(\vmu, \mSigma^{-1}\vmu)\cdot \left (\sqrt{1-\kappa^{-1}t^2}-1\right) + \sqrt{1-\cosim(\vmu, \mSigma^{-1}\vmu)^2} \cdot \kappa^{-1/2} t + \cosim(\vmu, \mSigma^{-1}\vmu).
\end{align}
It is clear that $s \mapsto s\left (\sqrt{1-\kappa^{-1}t^2}-1\right) + \sqrt{1-s^2}\cdot \kappa^{-1/2}t$ is a decreasing function on $[0,1]$ for each fixed $t\in[0,1]$. Therefore, by changing $s = \cosim(\vmu, \mSigma^{-1}\vmu)$ to $s = 0$, we have
\begin{align}\label{eqn:ERM_Necessary-2}
&\quad \cosim(\vmu, \mSigma^{-1}\vmu) \cdot \left(\sqrt{1-\kappa^{-1}t^2}-1\right) + \sqrt{1-\cosim(\vmu, \mSigma^{-1}\vmu)^2}\cdot \kappa^{-1/2} t + \cosim(\vmu, \mSigma^{-1}\vmu)\nonumber \\
&\leq \kappa^{-1/2}t + \cosim(\vmu, \mSigma^{-1}\vmu)\nonumber \\
&\leq \frac{1+\cosim(\vmu, \mSigma^{-1}\vmu)}{2},
\end{align}
where the last inequality used \Eqref{eqn:ERM_Necessary-3}. 
Combining \Eqref{eqn:ERM_Necessary-1} and \Eqref{eqn:ERM_Necessary-2}, we have our conclusion. \hfill $\square$
\subsection{Proof of Theorem~\ref{thm:expected_loss_ERM}}\label{proof:expected_loss_ERM}
We prove the existence and uniqueness of a minimizer of $\mathbb{E}_\kappa [\loss (\vw)]$ first. Next, we characterize a direction of a unique minimizer of $\mathbb{E}_\kappa [\loss (\vw)]$.
\paragraph{Step 1: Existence and Uniqueness of a Minimizer of $\mathbb{E}_\kappa[\loss(\vw)]$}\quad

From convexity of $l(\cdot)$, for any $z \in \mathbb{R}$, $l(z) \geq -\frac{1}{2}z + \log 2 \geq -\frac{1}{2}z$ since $z \mapsto -\frac{1}{2} z + \log 2$ is tangent line of the graph of $l(z)$ at $z=0$. Thus, we have 
\begin{equation*}
    \mathbb{E}_\kappa[\loss(\vw)] = \mathbb{E}_{\rvx\sim N(\vmu,\kappa^{-1}\mSigma)}[l(\vw^\top \rvx)] \geq \mathbb{E}_{\rvx\sim N(\vmu,\kappa^{-1}\mSigma)}[l(\vw^\top \rvx) \cdot \vone_{\vw^\top \rvx < 0} ]\geq \mathbb{E}_{\rvx \sim N(\vmu, \kappa^{-1}\mSigma)}\left[-\frac{1}{2}\vw^\top \rvx \cdot \vone_{\vw^\top \rvx < 0}\right].
\end{equation*}
\begin{claim}
\label{claim:1}
For any $\kappa \in (0, \infty)$, a mapping $\vw \mapsto \mathbb{E}_{\rvx \sim N(\vmu, \kappa^{-1}\mSigma)} [\vw^\top \rvx \cdot \vone_{\vw^\top \rvx<0}]$ is continuous.
\end{claim}
\begin{proof}[Proof of Claim A.1]
For any $\epsilon >0$, let $\delta_\epsilon:= \left(\kappa^{-1} \lVert \mSigma \rVert + \lVert \vmu \rVert^2 \right)^{-1/2} \cdot \epsilon /2 >0$. Then, for any $\vDelta \in \mathbb{R}^d$ with $\lVert \vDelta \rVert \leq \delta_\epsilon$ and $\vw \in \mathbb{R}^d$, we are going to show that 
\begin{equation*}
\left | \mathbb{E}_{\rvx \sim N(\vmu, \kappa^{-1} \mSigma)} [(\vw+\vDelta)^\top \rvx \cdot \vone_{(\vw+\vDelta)^\top \rvx<0}]-\mathbb{E}_{\rvx \sim N(\vmu, \kappa^{-1} \mSigma)} [\vw^\top \rvx \cdot \vone_{\vw^\top \rvx<0}] \right | \leq \epsilon,
\end{equation*}
to conclude that the mapping $\vw \mapsto \mathbb{E}_{\rvx \sim N(\vmu, \kappa^{-1} \mSigma)} [\vw^\top \rvx \cdot \vone_{\vw^\top \rvx<0}]$ is continuous.

To this end, we start by
\begin{align*}
    &\quad \left | \mathbb{E}_{\rvx \sim N(\vmu, \kappa^{-1} \mSigma)} [(\vw+\vDelta)^\top \rvx \cdot \vone_{(\vw+\vDelta)^\top \rvx<0}]-\mathbb{E}_{\rvx \sim N(\vmu, \kappa^{-1}\mSigma)} [\vw^\top \rvx \cdot \vone_{\vw^\top \rvx<0}]\right|\\
    &\leq \mathbb{E}_{\rvx \sim N(\vmu, \kappa^{-1} \mSigma)}\left[ \left| (\vw+\vDelta)^\top \rvx \cdot \vone_{(\vw+\vDelta)^\top \rvx<0}- \vw^\top \rvx \cdot \vone_{\vw^\top \rvx<0}\right| \right]\\
    &=  \mathbb{E}_{\rvx \sim N(\vmu, \kappa^{-1} \mSigma)}\left[ \left| \vDelta ^\top \rvx \cdot \vone_{(\vw+\vDelta)^\top \rvx <0} + \vw^\top \rvx \cdot (\vone_{(\vw+\vDelta)^\top \rvx <0} - \vone_{\vw^\top \rvx <0})\right| \right]\\
    &\leq \mathbb{E}_{\rvx \sim N(\vmu, \kappa^{-1} \mSigma)}\left[ \left| \vDelta ^\top \rvx \cdot \vone_{(\vw+\vDelta)^\top \rvx <0} \right| \right]+\mathbb{E}_{\rvx \sim N(\vmu, \kappa^{-1} \mSigma)}\left[ \left| \vw^\top \rvx \cdot (\vone_{(\vw+\vDelta)^\top \rvx <0} - \vone_{\vw^\top \rvx <0})\right| \right].
\end{align*}
It is clear that $\mathbb{E}_{\rvx \sim N(\vmu, \kappa^{-1} \mSigma)}\left[ \left| \vDelta ^\top \rvx \cdot \vone_{(\vw+\vDelta)^\top \rvx <0} \right| \right] \leq \mathbb{E}_{\rvx \sim N(\vmu, \kappa^{-1} \mSigma)}\left[ \left| \vDelta ^\top \rvx\right| \right]$. Also, for each $\vx \in \mathbb{R}^d$,
\begin{align*}
    \vw^\top \vx \cdot (\vone_{(\vw+\vDelta)^\top \vx <0} - \vone_{\vw^\top \vx <0}) = 
    \begin{cases}
    \vw^\top \vx \leq -\vDelta^\top \vx = |\vDelta ^\top \vx| &\text{if} (\vw+\vDelta)^\top \vx <0, \vw^\top \vx \geq 0,\\
    -\vw^\top \vx \leq \vDelta^\top \vx = |\vDelta ^\top \vx| &\text{if} (\vw+\vDelta)^\top \vx \geq0, \vw^\top \vx< 0,\\
    0 \leq |\vDelta ^\top \vx| &\text{otherwise}.
    \end{cases}
\end{align*}
Therefore, $\mathbb{E}_{\rvx \sim N(\vmu, \kappa^{-1} \mSigma)}\left[ \left| \vw^\top \rvx \cdot (\vone_{(\vw+\vDelta)^\top \rvx <0} - \vone_{\vw^\top \rvx <0})\right| \right] \leq \mathbb{E}_{\rvx \sim N(\vmu, \kappa^{-1} \mSigma)}\left[ \left| \vDelta ^\top \rvx\right| \right]$. Also, by Jensen's inequality,
\begin{align*}
    \mathbb{E}_{\rvx \sim N(\vmu, \kappa^{-1} \mSigma)}\left[ \left| \vDelta ^\top \rvx \right| \right] &\leq \mathbb{E}_{\rvx \sim N(\vmu, \kappa^{-1} \mSigma)}\left[ (\vDelta ^\top \rvx)^2 \right]^{1/2}\\
    &= \left( \kappa^{-1} \vDelta ^\top \mSigma \vDelta +(\vDelta^\top \vmu)^2 \right)^{1/2}\\
    &\leq \left(\kappa^{-1} \lVert \mSigma \rVert \lVert \vDelta \rVert^2 + \lVert \vmu\rVert^2\lVert \vDelta \rVert^2 \right)^{1/2}\\
    &\leq \left(\kappa^{-1} \lVert \mSigma \rVert + \lVert \vmu\rVert^2\right)^{1/2} \cdot \delta_\epsilon\\
    &= \epsilon/2.
\end{align*}
Hence, we have $\left | \mathbb{E}_{\rvx \sim N(\vmu, \kappa^{-1} \mSigma)} [(\vw+\vDelta)^\top \rvx \cdot \vone_{(\vw+\vDelta)^\top \rvx<0}]-\mathbb{E}_{\rvx \sim N(\vmu, \kappa^{-1} \mSigma)} [\vw^\top \rvx \cdot \vone_{\vw^\top \rvx<0}] \right| \leq \epsilon$, as desired. \hfill $\square$

From Claim~\ref{claim:1} and compactness of the unit sphere $\{ \vw\in \mathbb{R}^d : \lVert \vw \rVert = 1 \} \subset \mathbb{R}^d$, it follows that for any given $\kappa \in (0,\infty)$, a mapping $\vw \mapsto \mathbb{E}_{\rvx \sim N(\vmu, \kappa^{-1} \mSigma)} [\vw^\top \rvx \cdot \mathbf{1}_{\vw^\top \rvx<0}]$ has the maximum value (over the unit sphere) $-m_\kappa$ with $m_\kappa >0$. For any $\vw$ satisfying $\lVert \vw \rVert > 2 m_\kappa^{-1}$, we have
\begin{align}\label{eqn:ball}
    \mathbb{E}_\kappa[\loss (\vw)] &\geq \mathbb{E}_{\rvx \sim N(\vmu, \kappa^{-1} \mSigma)}\left[- \frac{1}{2} \vw^\top \rvx \cdot \vone_{\vw^\top \rvx<0} \right] \nonumber \\
    &= \lVert \vw \rVert \cdot \mathbb{E}_{\rvx \sim N(\vmu, \kappa^{-1}\mSigma)}\left[- \frac{1}{2} \cdot \frac{\vw^\top \rvx}{\lVert \vw \rVert}\cdot \vone_{\frac{\vw^\top \rvx}{\lVert \vw \rVert}<0} \right]\\
    &\geq \frac{m_\kappa \lVert \vw \rVert}{2} 
    > 1 > \log 2 \nonumber\\
    &= \mathbb{E}_\kappa[\loss(\vzero)] \nonumber.
\end{align}
Therefore, a minimizer of $\mathbb{E}_\kappa [ \loss (\vw) ]$ has to be necessarily contained in a compact set $\{ \vw \in \mathbb{R}^d :  \lVert \vw \rVert \leq 2  m_\kappa^{-1} \}$. Since $\mathbb{E}_\kappa [ \loss (\vw) ]$ is a continuous function of $\vw$, there must exist a minimizer. The existence part is hence proved.

To show uniqueness, we will prove strict convexity of $\mathbb{E}_\kappa[\loss (\vw)]$. From strict convexity of $l(\cdot)$, for any $t \in [0,1]$, $\vw_1, \vw_2 \in \mathbb{R}^d$ with $\vw_1 \neq \vw_2$ and $y \in \{0,1\}$, we have
\begin{align*}
    &\quad t[yl(\vw_1^\top \vx) + (1-y) l(-\vw_1^\top \vx)] + (1-t) [yl(\vw_2^\top \vx) + (1-y) l(-\vw_2^\top \vx)]\\
    &> y l((t\vw_1+(1-t)\vw_2)^\top \vx) + (1-y) l(-(t\vw_1+(1-t)\vw_2)^\top \vx),
\end{align*}
and any $\vx \in \mathbb{R}^d$ except for a Lebesgue measure zero set (i.e., the set of points $\vx \in \R^d$ satisfying  $\vw_1^\top \vx = \vw_2^\top \vx$).

By taking expectation, we have for any $t \in [0,1]$, and $\vw_1, \vw_2 \in \mathbb{R}^d$,
\begin{equation*}
    t \mathbb{E}_\kappa[\loss(\vw_1)] + (1-t) \mathbb{E}_\kappa[\loss(\vw_2)] >  \mathbb{E}_\kappa[\loss(t\vw_1+(1-t)\vw_2)].
\end{equation*}
Therefore, $\mathbb{E}_\kappa[\loss(\vw)]$ is strictly convex.
Since a strictly convex function has at most one minimizer, we conclude that $\mathbb{E}_\kappa[\loss(\vw)]$ has a unique minimizer $\w$ for any given $\kappa \in (0,\infty)$. 
\end{proof}

\paragraph{Step 2: Direction of a Unique Minimizer of $\mathbb{E}_\kappa[\loss(\vw)]$} \quad

We rewrite $\mathbb{E}_\kappa[\loss (\vw) ] $ as
\begin{align}\label{eqn:ERM_rewrite}
    \mathbb{E}_\kappa[\loss (\vw) ] &= \mathbb{E}_{\rvx \sim N(\vmu, \kappa^{-1} \mSigma)}\left[l\left( \vw^\top \rvx \right)\right]\nonumber \\
    &= \mathbb{E}_{X \sim N(\vw^\top \vmu, \kappa^{-1} \vw^\top \mSigma \vw )}\left[l(X)\right] \nonumber\\
    &= \mathbb{E}_{Z\sim N(0, 1 )}\left[l\left( \kappa^{-1/2} \left(\vw ^\top \mSigma \vw \right)^{1/2} Z + \vw^\top \vmu \right)\right].
\end{align}
We recall two lemmas we described in our proof sketch.
\logistic*
\opt*
Let $C_\kappa := \w^\top \vmu$. By \Eqref{eqn:ERM_rewrite} and Lemma~\ref{lemma:logistic}, $\w$ is a solution for the problem $\min_{\vw^\top \vmu = C_\kappa}\frac{1}{2} \vw^\top \mSigma \vw$.
 Hence, Lemma~\ref{lemma:opt} implies that there exists $c_\kappa \in \mathbb{R}$ such that $\w:= c_\kappa \mSigma^{-1}\vmu$. The only remaining part is showing $c_\kappa>0$. If $c_\kappa <0$, we have 
\begin{align*}
    \mathbb{E}_\kappa[\loss(\w)] &= \mathbb{E}_{Z \sim N(0,1)} \left [l\left (\kappa^{-1/2}(\w^\top \mSigma \w)^{1/2} Z + c_\kappa \vmu^\top \mSigma^{-1} \vmu \right ) \right ]\\
    &> \mathbb{E}_{Z \sim N(0,1)} \left [l \left (\kappa^{-1/2}(-\w)^\top  \mSigma (-\w))^{1/2} Z - c_\kappa \vmu^\top \mSigma^{-1} \vmu) \right ) \right ]\\
    &= \mathbb{E}\left [\loss \left ( -\w  \right ) \right ],
\end{align*}
where the inequality holds because $l(\cdot)$ is strictly decreasing and $c_\kappa \vmu^\top \mSigma^{-1} \vmu < 0$.
It is contradictory to $\w$ being a unique minimizer of $\mathbb{E}_\kappa[\loss(\vw)]$, so we conclude $c_\kappa \geq 0$.  Showing $c_\kappa$ is strictly positive will be handled in the proof of Lemma~\ref{lemma:ERM_norm} which can be found in Appendix~\ref{proof:lemma:ERM_norm}. \hfill $\square$

\subsection{Proof of Lemma~\ref{lemma:logistic}}
Define a function $f:(0,\infty) \rightarrow \mathbb{R}$ as $f(\sigma) := \mathbb{E}_{Z \sim N(0,1)}[l(m+\sigma Z)]$. It suffices to show that $f$ is strictly increasing. For each $\sigma \in (0,\infty)$ and $z \in \mathbb{R}$, $\left | \frac{\partial}{\partial \sigma} l(m+\sigma z) \right| = \left| l'(m+\sigma z) z \right|  = \left| \frac{z}{1+e^{m+\sigma z}} \right|\leq |z|$ and $\mathbb{E}_{Z \sim N(0,1)}[|Z|]< \infty$. Thus, by Lemma~\ref{lemma:leibniz}, 
\begin{align*}
    \frac{d}{d\sigma}f(\sigma) &= \mathbb{E}_{Z \sim N(0,1)}\left[\frac{\partial}{\partial \sigma} l(m+\sigma Z)\right] = \mathbb{E}_{Z \sim N(0,1)}[l'(m+\sigma Z) Z]\\
    &= - \frac{1}{\sqrt{2 \pi}} \int_{-\infty}^\infty \frac{z}{1+e^{m+\sigma z}}e^{-z^2/2}dz\\
     &= -\frac{1}{\sqrt{2 \pi}} \left( \int_0^\infty \frac{z}{1+e^{m+\sigma z}}e^{-z^2/2}dz + \int_{-\infty}^0 \frac{z}{1+e^{m-\sigma z}}e^{-z^2/2}dz \right)\\
    &= -\frac{1}{\sqrt{2 \pi}} \left( \int_0^\infty \frac{z}{1+e^{m+\sigma z}}e^{-z^2/2}dz - \int_0^\infty \frac{z}{1+e^{m-\sigma z}}e^{-z^2/2}dz \right)\\
    &= -\frac{1}{\sqrt{2 \pi}}  \int_0^\infty \left( \frac{z}{1+e^{m+\sigma z}}-\frac{z}{1+e^{m-\sigma z}} \right)e^{-z^2/2}dz\\
    &>0.
\end{align*}
The last inequality holds since $\frac{z}{1+e^{m+\sigma z}} < \frac{z}{1+e^{m-\sigma z}}$ for each $z>0$. Therefore, $f$ is strictly increasing as we desired. \hfill $\square$

\subsection{Proof of Lemma~\ref{lemma:opt}}
Consider a function $f : \mathbb{R}^d \rightarrow \mathbb{R}$ defined as $f(\vw) = \frac{1}{2} \vw^\top \mSigma \vw$. Since $\nabla_\vw^2 f(\vw) = \mSigma$ is positive definite, $f$ is strictly convex. The strict convexity continues to hold even when we restrict the domain to $\{\vw \mid \vw^\top \vmu = C\}$, so $\min_{\vw \in \mathbb{R}^d, \vw^\top \vmu = C} f(\vw)$ has at most one minimizer. Let $\bar{\vw} = \frac{C}{ \vmu^\top \mSigma^{-1} \vmu} \mSigma^{-1} \vmu$. Then, for any $\vw\in \mathbb{R}^d$ such that $\vw^\top \vmu = C$, we have 
\begin{equation*}
    f(\vw) - f(\bar{\vw}) \geq \nabla f(\bar{\vw})^\top(\vw - \bar{\vw})= \left(\mSigma \bar{\vw}\right)^\top (\vw - \bar{\vw}) = \frac{C}{\vmu^\top \mSigma^{-1} \vmu}\vmu^\top \left (\vw - \frac{C}{\vmu^\top \mSigma^{-1} \vmu}\mSigma^{-1} \vmu \right) = 0.
\end{equation*}
Therefore, $\bar{\vw} = \frac{C}{\vmu^\top \mSigma^{-1} \vmu} \mSigma^{-1} \vmu$, a rescaling of $\mSigma^{-1} \vmu$, is the unique minimizer.\hfill $\square$
\section{Further Applications}\label{app:applications}

In this appendix, we illustrate additional 0/1-polyhedral domains in which our polyhedral kernel can be computed efficiently.

\subsection{$n$-sets}\label{sec:nsets}

We start from $n$-sets, that is, the 0/1-polydral set $\Omega^d_n \defeq \textrm{co}\{\vpi \in \{0,1\}^d: \|\vpi\|_1 = n\}$. Learning over $n$-sets is a classic problem first considered by~\citet{warmuth2008randomized} with an application to online Principal Component Analysis.
They proposed an Online Mirror Descent algorithm operating over the convex hull $\Omega^d_n$, with per-iteration complexity of $\bigOh(d^2)$.
The Follow-the-Perturbed-Leader approach~\citep{Kalai05:Efficient} is even faster with per-iteration complexity of $\bigOh(d\log d)$, but it often leads to sub-optimal regret bounds (see discussions in~\citep{koolen2010hedging}).
Simulating MWU over the vertices of $\nset$ has been considered in for example~\citep{cesa2012combinatorial}, where they proposed to use the general approach of~\citep{Takimoto03:Path} to implement this algorithm, leading to per-iteration complexity of $\bigOh(d^2 n)$.
Below, we show that our kernelized approach admits an even faster per-iteration complexity of $\bigOh(d\min\{n, d-n\})$.

\subsubsection{Polynomial, $\bigOh(d \min\{n, d-n\})$-time kernel evaluation} Let $\vx, \vy \in \bbR^d$, and assume for now $n \le d-n$. Introduce the polynomial $p_{\vx,\vy}(z)$ of $z$, defined as
\[
    p_{\vx,\vy}(z) \defeq (\vx[1]\vy[1]\, z + 1) \cdots (\vx[d]\vy[d]\, z + 1).
\]
It is immediate to see that the coefficient of $z^n$ in the expansion of $p_{\vx,\vy}(z)$ is exactly $K_{\nset}(\vx, \vy)$. Such coefficient can be computed by directly carrying out the multiplication of the binomial terms, keeping track of the term of degree $0,\dots,n$. So, each evaluation of $K_\nset(\vx,\vy)$ can be carried out in $\bigOh(nd)$ time under the assumption that $n < d-n$.

If on the other hand $n < d-n$, we can repeat the whole argument above for the polynomial
$q_{\vx,\vy}(z) \defeq (z + \vx[1]\vy[1]) \cdots (z + \vx[d]\vy[d])$ instead. In that case, we are interested in the coefficients of $z^{d-n}$, which can be computed in $\bigOh(d(d-n))$ using the same procedure described above.

Putting together the two cases, we conclude that the computation of $K_\nset(\vx,\vy)$ requires $\bigOh(d\min\{n,d-n\})$ time.


\subsubsection{Implementing KOMWU with $\bigOh(d\min\{n, d-n\})$ per-iteration complexity}
The result described in the previous paragraph immediately implies that KOMWU can be implemented with $\bigOh(d^2\min\{n,d-n\})$-time iterations. In this subsection we refine the that result by showing that it is possible to compute the $d$ kernel evaluations $\{K_{\nset}(\vx,\ebar_k) : k =1,\dots,d\}$ required at every iteration by KOMWU so that they take cumulative $\bigOh(d\cdot\min\{n,d-n\})$ time.

To do so, we build on the technique described in the previous subsection. Assume again that $n \le d-n$. The key insight is that the coefficient of $z^n$ of the polynomial $p_{\vx,\vone}(z) / (\vx[j]\, z + 1)$ is exactly $K_{\nset}(\vx, \ebar_j)$. So, to compute all $\{K_{\nset}(\vx, \ebar_k): k =1,\dots,d\}$ we can do the following:
\begin{enumerate}[nosep,left=1mm]
    \item First, for all $k = 0,\dots,d$ and $h=0,\dots,n$, we compute the coefficient $A[k,h]$ of the $z^h$ in the expansion of $(\vx[1]\,z+1)\dots (\vx[k]\,z +1)$

          We can compute all such values in $\bigOh(dn)$ time by using dynamic programming. In particular, we have
          \[
              A[k,h] = \begin{cases}
                  1                                 & \text{if }h=0               \\
                  0                                 & \text{if }k=0 \land h\neq 0 \\
                  A[k-1,h] + \vx[k]\cdot A[k-1,h-1] & \text{otherwise.}
              \end{cases}
          \]

    \item Then, for all $k=1, \dots, d+1$ and $h=0,\dots,n$, we compute the coeffience $B[k,h]$ of $z^h$ in the expansion of $(\vx[k]\,z+1)\cdots (\vx[d]\, z+1)$

          Again, we can do that in $\bigOh(dn)$ time by using dynamic programming. Specifically,
          \[
              B[k,h] = \begin{cases}
                  1                                 & \text{if }h=0                \\
                  0                                 & \text{if }k=d+1\land h\neq 0 \\
                  B[k+1,h] + \vx[k]\cdot B[k+1,h-1] & \text{otherwise.}
              \end{cases}
          \]

    \item (Note that at this point, $K_{\nset}(\vx,\mathbf{1})$ is simply $A[d,n]$.)
    \item For each $k = 1,\dots,d$, $K_{\nset}(x, \ebar_j)$ can be computed as
          \[
              K_{\nset}(\vx,\ebar_k) = \sum_{h=0}^n A[k-1,h]\cdot B[k+1,n-h].
          \]
          The above formula takes $\bigOh(n)$ time to be computed (we need to iterate over $h=0,\dots,n$), and we need to evaluate it $d$ times (once per each $k=1,\dots,d$). So, computing all $\{K_{\nset}(\vx,\ebar_k): k =1,\dots,d\}$ takes cumulative $\bigOh(dn)$ time, as we wanted to show.
\end{enumerate}

As in the previous subsection, the case $n > d-n$ is symmetric. In that case, the set of values $\{K_{\nset}(\vx,\ebar_k): k =1,\dots,d\}$ can be computed in cumulative $\bigOh(d(d-n))$ time.

\subsection{Unit Hypercube}

Consider the hypercube $[0,1]^d$, whose vertices are all the vectors in $\{0,1\}^d$. In this case, the polyhedral kernel is simply
\[
    K_{[0,1]^d}(\vx,\vy) = (\vx[1]\cdot \vy[1] + 1) \cdots (\vx[d]\cdot \vy[d] + 1),
\]
which can be clearly evaluated in $\bigOh(d)$ time. Similarly to $n$-sets (\cref{sec:nsets}), we can avoid paying an extra $d$ factor in the per-iteration complexity of KOMWU by using the following procedure:
\begin{enumerate}
    \item For each $k = 0,\dots,d$ define $A[k] \defeq (\vx[1]\cdot \vy[1] + 1) \cdots (\vx[k] \cdot \vy[k] + 1)$. Clearly, the $A[k]$ values can be computed in $\bigOh(d)$ cumulative time.
    \item For each $k = 1,\dots,d+1$, define $B[k] \defeq (\vx[k]\cdot \vy[k] + 1) \cdots (\vx[d] \cdot \vy[d] + 1)$. Again, all $B[k]$ values can be computed in $\bigOh(d)$ cumulative time.
    \item For each $k=1,\dots,d$, we have that $K_{[0,1]^d}(\vx, \ebar_k) = A[k-1]\cdot B[k+1]$. Hence, we can compute $\{K_{[0,1]^d}(\vx,\ebar_k): k=1,\dots,d\}$ in cumulative $\bigOh(d)$ time.
\end{enumerate}

\subsection{Flows in Directed Acyclic Graphs}

The polytope $\mathcal{F}$ of flows in a generic directed acyclic graphs (DAGs) has vertices with 0/1 integer coordinates, corresponding to paths in the DAG. The 0/1-polyhedral kernel $K_{\mathcal{F}}$ corresponding to the set of flows in a DAG coincides with the kernel function introduced by \citet{Takimoto03:Path}, which was shown to be computable in polynomial-time in the size of the DAG. Consequently, $K_\mathcal{F}$ admits polynomial-time (in the size of the DAG) evaluation.


\subsection{Permutations}

When $\mathcal{P}$ is the convex hull of the set of all $d\times d$ permutation matrices, it is believed that $K_{\mathcal{P}}$ cannot be evaluated in polynomial time in $\bigOh(d)$, since the computation of the permanent of a matrix $\mat{A}$ can be expressed as $K_\Omega(\mat{A}, \vone)$. However, an $\epsilon$-approximate computation of $K_{\mathcal{P}}$ can be performed in $\bigOh(\poly(d,\log(1/\epsilon)))$ for any $\epsilon > 0$ by using a landmark result by \citet{jerrum2004polynomial}. We refer the interested reader to the paper by \citet[Section 5.3]{cesa2012combinatorial}.

\subsection{Cartesian Product}

Finally, we remark that when two 0/1-polyhedral sets have efficiently-computable 0/1-polyhedral kernels, then so does their Cartesian product. Specifically, let $\Omega\subseteq\bbR^d, \Omega'\subseteq\bbR^{d'}$ be 0/1-polyhedral sets, and let $K_\Omega, K_{\Omega'}$ be their corresponding 0/1-polyhedral kernels. Then, it follows immediately from the definition that the polyhedral kernel of $\Omega\times\Omega'$ satisfies
\newcommand{\vstack}[2]{\begin{pmatrix}#1\\#2\end{pmatrix}}
\[
    K_{\Omega\times\Omega'}\mleft(\vstack{\vx}{\vx'}, \vstack{\vy}{\vy'}\mright) = K_\Omega(\vx, \vy) \cdot K_{\Omega'}(\vx',\vy') \qquad\forall\,\vstack{\vx}{\vy}, \vstack{\vx'}{\vy'} \in \bbR^d\times\bbR^{d'}.
\]



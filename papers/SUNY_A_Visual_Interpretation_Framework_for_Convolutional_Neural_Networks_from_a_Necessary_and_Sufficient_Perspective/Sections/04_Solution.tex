\begin{figure*}[htbp]
  \centering
   \includegraphics[width=1.0\linewidth]{Figures/Framework.png}
\caption{
Overview of \name{} framework.
Phase(a) is a forward pass of input image $I$ through a CNN model, where the prediction probability of the target class is $p_{c}(F)$.
Phase(b)-(e) present the generation of \textcolor{ForestGreen}{\name{}-feature (green)} and \textcolor{RoyalBlue}{\name{}-filter (blue)}, respectively, referring to different types of hypothesized causes.
Note that they are not simultaneous processes.
In Phase(b), we obtain filters and feature maps of a specified layer, and intervene on model filters or the corresponding input features.
We get new prediction probabilities after the intervention and calculate \textbf{N-S Effect}, $E_N$, $E_S$ in Phase(c), which are fed back to Phase(b) to construct hypothesized cause sets $F_{hypN}$ and $F_{hypS}$.
Through intervening on $F_{hypN}$ and $F_{hypS}$ (Phase(b)), we can obtain $E_N$, $E_S$ (Phase(c)) and \textbf{N-S Responsibilities} $R_N$ and $R_S$ (Phase(d)), which are weights for the linear combination of feature maps.
The saliency maps are generated in Phase(e), where we show \name{}-feature results as an example.
Implementation details are included in Sec.~\ref{sec:solution}.
}
   \label{fig:framework}
\end{figure*}

\subsection{Causal Importance Evaluation}
\label{subsec:ns_res}

To address the deficiencies of current causal importance evaluations as discussed in Sec.~\ref{sec:related}, our evaluation should follow the below design requirements:

\begin{enumerate}[start=1,label={\bfseries R\arabic*},leftmargin=*,topsep=2px,partopsep=2px]
\setlength{\itemsep}{0pt}%
\setlength{\parskip}{0pt}
    \item \label{req:set_size}
Our method should measure the importance of each individual cause in a group of coordinating causes. 
    \item \label{req:dual_direction}
Our method should quantify the actual effect towards the outcome and pay attention to both \textit{N} and \textit{S}.
\end{enumerate}

The first step of achieving~\ref{req:dual_direction} is to define \textbf{N-S Effect} to quantify effects caused by the intervention of removing/keeping specific causes.
We denote a set of causes to be analyzed as $F_*$, where $F_* \subseteq F$ and $F$ is the universal set of all causes.
For \textbf{N Effect}, we measure the degree of the outcome change when removing $F_*$, as shown in Eqn.~(\ref{eqn:n_eff}):

\begin{equation}\label{eqn:n_eff}
   E_N(F_*) = \frac{p_{c}(I)-p_{c}({\rm do} \; (F \setminus F_*))} {p_{c}(I)},
\end{equation}
where ${\rm do}(F \setminus F_*)$ represents the CF intervention of removing $F_*$.
And $p_{c}(\bigcdot)$ refers to the model's prediction probability w.r.t.\;a target class $c$, where $p_{c}(I)$ is its original value without any intervention; $p_{c}({\rm do}(F \setminus F_*))$ represents the value after the removal intervention.
A higher $E_{N}(F_*)$ indicates a more \textit{necessary} $F_*$.

Similarly, \textbf{S Effect} is defined in Eqn.~(\ref{eqn:s_eff}):

\begin{equation}\label{eqn:s_eff}
   E_S(F_*) = \frac{p_{c}({\rm do}\; (F_*))} {p_{c}(I)},
\end{equation}
where ${\rm do}(F_*)$ represents the CF intervention of only keeping $F_*$, i.e., removing $\{F \setminus F_*\}$.
A higher $E_{S}(F_*)$ indicates a more \textit{sufficient} $F_*$.

To fulfill~\ref{req:set_size}, we provide a quantification to approximate a fair distribution of \textbf{N-S Effect} to a number of causes working cooperatively.
Starting from the \textit{N} aspect,  $\forall f_i \in F$, where $f_i$ is a single cause, we set $F_* = \{f_i\}$ to calculate $E_N(f_i)$ and construct a set $F_N \subseteq F$ by combining the relatively more \textit{necessary} $f_i$.
To analyze a single cause $f_n \in F_N$ when it interacts with different causes, we intervene on $f_n$ by removing it together with $F_{N}^k$, a set of causes with a varying size $k$.
That is, $F_*=F_{hypN}(f_n)=\{f_n \cup F_{N}^k\} \subseteq F_N$ and we can calculate $E_N(F_{hypN}(f_n))$ based on Eqn.~(\ref{eqn:n_eff}).
We then equally distribute it to the containing individual causes.
Finally, we accumulate all such $F_{hypN}(f_n)$ by linearly combining the distributed \textbf{N Effect} corresponding to each $f_n$ and the result is defined as \textbf{N Responsibility} of $f_n$, as defined in Eqn.~(\ref{eqn:n_res}):

\begin{equation}\label{eqn:n_res}
   R_N(f_n) = \sum_{F_N^k\subseteq \{F_N \setminus f_n\}}^{k \in [a,b] }  \frac{E_N(F_{hypN}(f_n))} {k+1},
\end{equation}
where $a$ and $b$ are the pre-defined minimum and maximum set sizes of $F_N^k$. 
In the implementation, we can reduce the amount of computation by setting the values of $a$ and $b$. Also, the sum in Eqn. \ref{eqn:n_res} can be empirically estimated using Monte Carlo sampling.

Similarly, $\forall f_i \in F$, we construct $F_S$ for analyzing $S$, and $\forall f_s \in F_S$, we have $F_*=F_{hypS}(f_s) = \{f_s \cup F_{S}^k\} \subseteq F_S$, where $F_{S}^k$ is of a varying size.
The definition of \textbf{S Responsibility} is provided in Eqn.~(\ref{eqn:s_res}):
\begin{equation}\label{eqn:s_res}
    R_S(f_s)=\sum_{F_S^k\subseteq \{F_S \setminus f_s\}}^{k \in [a,b] }  \frac{E_S(F_{hypS}(f_s))} {k+1}.
\end{equation}

Additionally, for $f_n^\prime \in \{F\setminus F_N\}$ and $f_s^\prime \in \{F\setminus F_S\}$, we set $R_N(f_n^\prime) = 0$ and $R_S(f_s^\prime) = 0$.

\begin{figure*}[htbp]
  \centering
   \includegraphics[width=1\linewidth]{Figures/CompareAll.png}
\caption{Visual comparison of saliency maps from different methods. The first row: a VGG16 trained on CUB-200-2011, and the image is correctly predicted as {\fontfamily{qcr}\selectfont Gull}. The second row: a VGG16 trained on ILSVRC2012, and the image is correctly predicted as {\fontfamily{qcr}\selectfont Dog-sled}.
}
   \label{fig:Compare all}
\end{figure*}

\subsection{\textbf{\name{}} Implementation}


We present the implementation of \name{} in Alg.~\ref{alg:suny} and an visual overview in Fig.~\ref{fig:framework}.
Following the definitions in Sec.~\ref{subsec:ns_res}, \name{} provides CAM-based causal explanations regarding input features and model filters as hypothesized causes, respectively, represented by the cause type $E$ in Alg.~\ref{alg:suny} with values ``feature'' or ``filter''.
The corresponding explanations are \name{}-feature and \name{}-filter.
\begin{algorithm}[bhpt]
\caption{\name{}: Causal Explanation of CNN}\label{alg:suny}
\textbf{Input} Image $I$, model $M$, layer $l$, class $c$, cause type $E$\\
\textbf{Output} N-S saliency maps: $N_{map}$, $S_{map}$
\begin{algorithmic}[1]
% \State{\textcolor{gray}{// Function for model's class prediction probability}}
\State{$p_{c}(\bigcdot) =$ Softmax$(M(\bigcdot))[c]${\small \textcolor{gray}{  // prediction probability on $c$}}}
\State{$A_l \gets M_l(I)$ {\small \textcolor{gray}{  // feature maps of the layer $l$}}}
\State{$F_{hypN}, F_{hypS} \gets $ getHypCauses($I, M, l, E$)}
\State{$N, S \gets zeros(A_l.shape[0])$ {\small \textcolor{gray}{  // initialize responsibilities}}}
\If {$E$ is $``feature"$}
    \For{$A_l^n$ \textbf{in} $F_{hypN}$}
    \State{$mask \gets$ norm(upsample$(A_l^n)$)}
    \State{$N[A_l^n.index] \mathrel{{+}{=}} \frac{p_{c}(I) - p_{c}(I \bigodot (1 - mask))}{len(A_l^n.index)\times p_{c}(I)}$}
    \EndFor
    \For{$A_l^s$ \textbf{in} $F_{hypS}$}
    \State{$mask \gets$ norm(upsample$(A_l^s)$)}
    \State{$S[A_l^s.index] \mathrel{{+}{=}} \frac{p_{c}(I \bigodot mask)}{len(A_l^s.index)\times p_{c}(I)}$}
    \EndFor
\ElsIf {$E$ is $``filter"$}
    \For{$F_l^n$ \textbf{in} $F_{hypN}$} 
    \State{$M^{n} \gets$ pruneFilters$(M, F_l^n)$}
    \State{$p^{n}_{c}(\bigcdot) =$ Softmax$(M^{n}(\bigcdot))[c]$}
    \State{$N[F_l^n.index] \mathrel{{+}{=}} \frac{p_{c}(I) - p^{n}_{c}(I)}{len(F_l^n.index)\times p_{c}(I)}$}
    \EndFor
    \For{$F_l^s$ \textbf{in} $F_{hypS}$} 
    \State{$M^{s} \gets$ pruneFilters$(M, (F_l \setminus F_l^s))$}
    \State{$p^{s}_{c}(\bigcdot) =$ Softmax$(M^{s}(\bigcdot))[c]$}
    \State{$S[F_l^s.index] \mathrel{{+}{=}} \frac{p^{s}_{c}(I)}{len(F_l^n.index)\times p_{c}(I)}$}
    \EndFor
\EndIf
\State{$N_{map} =$ norm(upsample(Relu$(\sum_{n^i \in N} n^{i}A_l^i)$))}
\State{$S_{map} =$ norm(upsample(Relu$(\sum_{s^i \in S} s^{i}A_l^i)$))}
\State{\Return{$N_{map}$, $S_{map}$}}
\end{algorithmic}
\end{algorithm}

We first define $p_c(\bigcdot)$ as a function to calculate the model's prediction probability w.r.t.\;a class $c$ for the input denoted by $\bigcdot$, as shown in line 1 of Alg.~\ref{alg:suny}.
Next, in line 3, we construct $F_{hypN}$ and $F_{hypS}$, where $F_{hypN}$ contains all different $F_{hypN}(f_n)$ that we defined in Sec.~\ref{subsec:ns_res}.
Similarly, $F_{hypS}$ contains all different $F_{hypS}(f_s)$.
We then calculate \textbf{N-S Responsibilities} for every single cause in $F_{hypN}$ and $F_{hypS}$ following lines 5 - 20.
Specifically, for generating \name{}-feature (lines 6 - 11), we upsample and normalize the feature maps, $A_l^n$ and $A_l^s$, and use the generated $mask$ to identify input features from the image $I$.
The operation ${\rm do}(F \setminus F_*)$ is realized by the Hadamard product, $(I \bigodot (1 - mask))$.
Similarly, ${\rm do}(F_*)$ is implemented as $(I \bigodot mask)$.
\name{}-filter (lines 13 - 20) removes and keeps the hypothesized causes by filter pruning, which means setting the corresponding filters' weights to zero.
Line 14 and line 18 correspond to ${\rm do}(F \setminus F_l^n)$ and ${\rm do}(F_l^s)$, respectively.
After calculating \textbf{N-S Responsibilities} for all single causes, in lines 21 and 22, we obtain small saliency maps by $Relu(\sum_{n \in N} n^{i}A_l^i)$, $Relu(\sum_{s \in S} s^{i}A_l^i)$ and then upsample and normalize them to get the final saliency maps.
The operation $norm$ represents the min-max normalization, $norm(X) = \frac{X - min(X)}{max(X) - min(X)}$, and $upsample$ represents the bilinear interpolation.

In the following section, we validate the performance of \name{} from both quantitative and qualitative perspectives.

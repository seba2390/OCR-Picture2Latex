\section{Variational inference}
\label{sec:vi}

Variational inference (VI) chooses an approximation to the posterior
distribution $p(z | x)$ from a class of candidate distributions via numerical optimization.
The candidate approximating distributions $q_\theta(z)$, called ``variational distributions'', are parameterized by a real-valued vector $\theta$.
Through numerical optimization, VI minimizes (with respect to $\theta$) the KL divergence between $q_\theta(z)$ and $p(z|x)$.

For an introduction to VI, we recommend
\cite{blei2017variational} to statisticians,
\cite{mackay1995developments} to physicists, and
\cite{smidl2006variational} to readers with a background in signal processing.


\subsection{The variational distributions}
\label{vi_dist}

We restrict the variational distributions to a class that makes KL minimization tractable.
Our variational distributions all factorize:
\begin{align}
q_\theta(z) &=\prod_{s=1}^{S} q(a_{s}) q(u_{s}) q(e_{s}) q(r_{s}|a_{s}) q(c_{s}|a_{s}).\label{eq:q_factorization}
\end{align}
We have suppressed the subscript $\theta$ in the variational factors.
This is not quite mean-field variational inference \citep{blei2017variational},
where the variational distribution factorizes across all random variables,
because some factors are conditional on $a_s$ (i.e., whether a light source is a star or a galaxy).
The next equations show the constituents of $\theta$.
We use ``acute'' and ``hat'' accents to denote variational parameters.
For $s=1,\ldots,S$ and $i\in\{0,1\}$ we take
\begin{align}
q(a_{s}) & \sim\mathrm{Bernoulli}\left( \acute a_s \right),\label{eq0}\\
q\left(r_{s}|a_{s}=i\right) & \sim\mathrm{LogNormal}\left( \acute r_{si}, \hat r_{si}\right),\\
q\left(c_{s}|a_{s}=i\right) & \sim\mathrm{MvNormal}\left( \acute c_{si}, I \hat c_{si}\right),\\
q\left(u_{s}\right) & \sim\mathrm{PointMass}\left( \acute u_s \right),\\
q\left(e_{s}\right) & \sim\mathrm{PointMass}\left( \acute e_s \right).\label{eq1}
\end{align}
Here $\acute e_s \coloneqq (\acute e_s^{angle}, \acute e_s^{radius}, \acute e_s^{profile}, \acute e_s^{axis})$.

Approximating the posterior for $u_s$ and $e_s$ with a point mass is a strong assumption.
It is analogous to performing maximum a posteriori (MAP) inference for these parameters.
We do so only because of computational considerations: it lets us write the objective function as an analytic expression.
Analytic expressions can be optimized efficiently by deterministic numerical optimization routines, which
in turn can converge much faster than stochastic optimization \citep{bubeck2015convex}.
Ongoing research aims to expand the class of models and variational distributions that can be optimized with deterministic VI,
though limitations persist~\citep{fraysse2014measure,zheng2015efficient,giordano2015linear}.


\subsection{The variational lower bound}

Because $p(x)$ is constant with respect to $\theta$,
minimizing $D_{\mathrm{KL}}(q_\theta(z), p(z|x))$ is equivalent to maximizing
\begin{align}
\mathcal L(\theta) \coloneqq \mathbb{E}_{q_\theta} \left[ \log p(x | z) \right]
                   - D_{KL}(q_\theta(z), p(z)).\label{elbo}
\end{align}
Maximization of $\mathcal L(\theta)$ is the standard approach;
see \cite{blei2017variational} for discussion.

The first term of $\mathcal L(\theta)$ is the expected log likelihood of the data.
It is
\begin{align}
\mathbb{E}_{q} \left[\log p(x|z)\right]
&=\sum_{n=1}^{N} \sum_{m=1}^{M} \left\{
  -\mathbb{E}_{q}\left[\lambda_{nm}\right]
  + x_{nm}\mathbb{E}_{q}\left[\log \lambda_{nm}\right]
  -\log\left(x_{nm}!\right)
\right\}.\label{eq:log_p_last}
\end{align}

\subsubsection{Expectation of the rate parameter}
The first expectation is
\begin{align}
\mathbb{E}_{q}\left[\lambda_{nm}\right]
&= \sigma_{nm} + \sum_{s=1}^S
     \mathbb E_q \left[ \ell_{s\beta_n} f_{nms} \right].
\end{align}
We can factorize the right-hand expectation based on the factorization of the variational distribution, upon conditioning on $a_s$:
\begin{align}
\begin{split}
\mathbb E_q \left[ \ell_{s\beta_n} f_{nms} \right]
= (1 - \acute a_s) &\mathbb E_q \left[ \ell_{s\beta_n} | a_s = 0 \right]\mathbb E_q \left[ f_{nms} | a_s = 0 \right]\\
+ \acute a_s &\mathbb E_q \left[ \ell_{s\beta_n} | a_s = 1 \right]\mathbb E_q \left[ f_{nms} | a_s = 1 \right].
\end{split}
\label{conditional}
\end{align}
The integral $\mathbb E_q \left[ \ell_{s\beta} | a_s \right]$ is tractable because flux~$r_s$
and each entry of~$c_s$ (the colors) are independent in the variational distribution given $a_s$.
The integral~$\mathbb E_q \left[ f_{nms} | a_s \right]$ is tractable because $u_s$ is a point mass in the variational distribution.


\subsubsection{Expectation of the log rate parameter}

We approximate the expected logarithm of $\lambda_{nm}$ using the delta method for moments \citep{bickel2015mathematical}.
We replace the integrand with a second-order Taylor expansion around its mean:
\begin{align}
\begin{split}
\log(\lambda_{nm})
\approx \log\mathbb{E}_{q}[\lambda_{nm}]
  &+\frac{1}{\mathbb{E}_{q}[\lambda_{nm}]}\left(\lambda_{nm} - \mathbb{E}_{q}[\lambda_{nm}]\right)\\
  &-\frac{1}{2\mathbb{E}_{q}[\lambda_{nm}]^{2}}\left(\lambda_{nm}-\mathbb{E}_{q}[\lambda_{nm}]\right)^{2}\,.
\end{split}
\end{align}
Then, taking expectations,
\begin{align}
\mathbb{E}_{q}[ \log(\lambda_{nm}) ]
&\approx \log\mathbb{E}_{q}[\lambda_{nm}]
  -\frac{\mathbb{V}_{q}[\lambda_{nm}]}{2\mathbb{E}_{q}[\lambda_{nm}]^{2}},
\end{align}
where $\mathbb V_q$ denotes variance with respect to the variational distribution $q$.
That term may be further expanded:
\begin{align}
\mathbb{V}_{q}[\lambda_{nm}] & =\sum_{s=1}^{S}\mathbb{V}_{q}\left[\ell_{s\beta_n}f_{nms}\right]\\
&=\sum_{s=1}^{S} \mathbb{E}_{q}\left[\ell_{s\beta_n}^{2}f_{nms}^{2}\right]
    - \left(\mathbb{E}_{q}\left[\ell_{s\beta_n}f_{nms}\right]\right)^{2}.
    \label{vareq}
\end{align}
The second expectation on the right-hand side is given in Equation~\ref{conditional}. The first is
\begin{align}
\begin{split}
\mathbb{E}_{q}\left[\ell_{s\beta_n}^{2}f_{nms}^{2}\right]
&= (1 - \acute a_s) \mathbb E_q \left[ \ell_{s\beta_n}^2 | a_s = 0 \right]\mathbb E_q \left[ f_{nms}^2 | a_s = 0 \right]\\
&+ \acute a_s \mathbb E_q \left[ \ell_{s\beta_n}^2 | a_s = 1 \right]\mathbb E_q \left[ f_{nms}^2 | a_s = 1 \right].
\end{split}
\end{align}


\subsubsection{KL divergence}

Because of the factorization of the variational distribution, the KL term in Equation~\ref{elbo} separates across sources:
\begin{align}
D_{\mathrm{KL}}(q(z), p(z)) &= \sum_{s=1}^S D_{\mathrm{KL}}(q(z_s), p(z_s)).\label{eq:kl}
\end{align}
It separates further within each source:
\begin{align}
\begin{split}
D_{\mathrm{KL}}(q(z_s), p(z_s)) &=
D_{\mathrm{KL}}(q(a_s), p(a_s))\\
&+ D_{\mathrm{KL}}(q(u_s), p(u_s))
+ D_{\mathrm{KL}}(q(e_s), p(e_s))\\
&+ \sum_{i=0}^1 q(a_s = i) \Big[
    D_{\mathrm{KL}}(q(r_s | a_s = i), p(r_s | a_s = i))\\
    &\qquad\qquad\qquad + D_{\mathrm{KL}}(q(c_s | a_s = i), p(c_s | a_s = i))
\Big].
\end{split}
\label{kleq}
\end{align}
Except for the last, these KL divergences are between common exponential family distributions. We give formulas for them in~\ref{kl}.

The last KL divergence is more complicated because the prior on $c_s$ is a Gaussian mixture model.
We take the eighth approach from \citet{hershey2007approximating} to identify an upper bound on this KL divergence:
\begin{multline}
D_{\mathrm{KL}}(q(c_s | a_s = i), p(c_s | a_s = i)) \\ \le
D_{\mathrm{KL}}(\xi_i, \mathcal C_{i}^{weights}) + \sum_{j=1}^J \xi_{ij} D_{\mathrm{KL}}(q(c_s | a_s = i), \mathcal C_{ij}).
\end{multline}
Here $\mathcal C_{i}^{weights}$ is the categorical distribution over the color prior's mixture components, $\mathcal C_{ij}$ is the color prior's $j$th mixture component, and $\xi_{i} \in [0,1]^J$ is a vector of free parameters.
To make the bound as tight as possible, we optimize the $\xi_i$ along with the variational lower bound. The optimal $\xi_i$
can also be expressed analytically in terms of $\mathcal C_i$:
\begin{align}
\xi_{ij}^\star \propto \mathcal C_{ij}^{weights} \exp\{-D_{\mathrm{KL}}(q(c_s | a_s = i), \mathcal C_{ij})\}.
\end{align}


\subsection{Numerical optimization}
\label{numerical}

Traditionally, variational lower bounds are maximized through coordinate ascent: each update sets a variational parameter to its optimal value with the others held fixed~\citep{bishop2006pattern,murphy2012machine}. This approach is simple to implement because gradients and Hessians do not need to be explicitly computed. Each update increases the variational lower bound. The algorithm converges to a local optimum even for nonconvex objective functions.
However, coordinate ascent can take many iterations to converge when the Hessian of the objective function is not diagonal.
Additionally, for many models, including ours, optimal coordinate ascent updates cannot be expressed analytically.

Instead, we propose an optimization procedure based on \textit{block} coordinate ascent. Each light source corresponds to a block of 44 parameters: the 37 variational parameters in Equations~\ref{eq0}--\ref{eq1} and the $7$-dimensional parameter~$\xi$. We optimize each block using a subsolver, explained in the next paragraph. Because most pairs of light sources do not overlap, the Hessian has low fill off the block diagonal.
Block coordinate ascent converges quickly in this setting: for light sources that do not overlap with any other light source, just one update step, based on one call to a subsolver, is required to reach a local maximum. For groups of light sources that overlap with each other, a few passes over each light source suffice in practice. Light sources may be optimized in a round-robin order or at random.

As a subsolver to optimize one block of parameters with all others fixed, we use Newton's method with a trust-region constraint that restricts each step to a Euclidean ball centered at the previous iterate~\citep{nocedal2006numerical}.
The trust-region constraint ensures that we find a local maximum even though the variational objective is nonconvex.
The method consistently converges in tens of iterations, whereas first-order methods take thousands. BFGS~\citep{nocedal2006numerical} also on occasion required thousands of iterations per call. Newton iterations are more expensive computationally than the iterations of first-order methods  because the former require computing a dense Hessian along with each gradient.
For our objective function, computing both a Hessian and a gradient takes $3\times$ longer than computing a gradient alone. In the end, we gain at least an order of magnitude speedup by using Newton's method rather than a gradient-only method because the former requires many fewer iterations.


\subsection{Distributed optimization}
\label{distributed}

Modern compute clusters and supercomputers contain many individual \textit{compute nodes} that execute instructions in parallel. Additionally, each compute node runs many \textit{threads} in parallel---at least one per CPU core.
Communication among compute nodes is orders of magnitude slower than communication among threads on the same node.

Block coordinate ascent (the outer loop of our optimization procedure) is a serial algorithm: if multiple blocks of parameters are updated simultaneously based on the current iterate, the objective value may decrease, and the algorithm may diverge. By taking of advantage of the structure of our problem, however, we parallelize block coordinate ascent across both compute nodes and CPU cores.
Equation~\ref{eq:log_p_last} is a sum over pixels and Equation~\ref{eq:kl} is a sum over light sources.
Therefore, our objective function may be expressed as a sum whose terms each depend on the parameters for at most one light source from any particular collection of non-overlapping light sources.
Thus, for any collection of non-overlapping light sources, maximizing over each light source's parameters serially is equivalent to maximizing over all these light sources' parameters in parallel.

Each compute node is tasked with optimizing all the light sources in a region of the sky.
Because these light sources are physically near each other, they appear in many of the same images; we only need to load these images once for to infer parameters for all these light sources.
Each node implements a locking mechanism that prevents its threads from optimizing overlapping light sources simultaneously. Because within-node communication is fast, there is almost no overhead from this type of locking mechanism.

Communication between nodes is relatively slow. We avoid using an inter-node locking mechanism by assigning each node to optimize different regions of the sky. Because the boundaries of these regions are small relative to the interior,
we find an iterate near a stationary point with this approach. A second pass with shifted boundaries ensures that even light sources near a boundary during the first pass are fully optimized.

\begin{figure}
	\centering
	\includegraphics[scale=0.31]{figures/framework.pdf}
    \caption{An overview of three approaches for using LLMs: (a) Standard prompting for generating a prediction in response to a query. (b) Chain-of-thought prompting for generating both an explanation and a prediction in response to a query. (c)  Rethinking with retrieval, our proposed approach for using the decomposed reasoning steps obtained from chain-of-thought prompting to retrieve relevant external knowledge for LLMs, leading to more faithful explanations and improved predictions in response to a query.}
	\label{fig:framework}
\end{figure}
\section{Introduction}

Large language models (LLMs) have shown exceptional performance across various tasks through in-context learning without task-specific training or fine-tuning \cite{brown2020language, chowdhery2022palm, zhang2022opt, ouyang2022training}. Recent progress in prompting \cite{wei2022chain, zhou2022least, kojima2022large} and decoding \cite{wang2022self} has made it feasible for LLMs to tackle tasks that demand complex reasoning. 

However, the knowledge stored in LLMs might inevitably be incomplete, out-of-date, or incorrect. As a result, external sources of knowledge, such as Wikipedia, may be essential for the successful deployment of LLMs for real-world applications. Previously, people tried to utilize knowledge for smaller language models (LMs), such as T5 \cite{raffel2020exploring}, BERT \cite{devlin2019bert}, and RoBERTa \cite{liu2019roberta}. However, these methods often require additional training or fine-tuning, which can be costly and thus impractical for LLMs. 
%Furthermore, the emergent abilities of LLMs cannot be accurately predicted by simply extrapolating the performance of smaller LMs based on scaling laws \cite{kaplan2020scaling, hoffmann2022training}, as these abilities may be present in larger models but not in smaller ones \cite{wei2022emergent}. 

In this paper, we present a post-processing approach called \textit{rethinking with retrieval} (\NAME{}) for utilizing external knowledge in LLMs. Our method begins by using the chain-of-thought (CoT) prompting method \cite{wei2022chain} to generate a diverse set of reasoning paths, as described in \citet{wang2022self}. We then use each reasoning step in those paths to retrieve relevant external knowledge, which enables \NAME{} to provide more faithful explanations and more accurate predictions, as illustrated in Figure \ref{fig:framework}.

We evaluate the effectiveness of our proposed method, \NAME{}, on three complex reasoning tasks: commonsense reasoning, temporal reasoning, and tabular reasoning, using GPT-3 175B \cite{brown2020language} and different external knowledge sources: Wikipedia, Wikidata \cite{vrandevcic2014wikidata}, WordNet \cite{miller1995wordnet}, and Conceptnet \cite{speer2017conceptnet}. The results demonstrate that \NAME{} consistently outperforms all baselines on all three tasks without requiring additional training or fine-tuning, indicating the superiority of our approach in leveraging external knowledge to enhance the performance of LLMs. 
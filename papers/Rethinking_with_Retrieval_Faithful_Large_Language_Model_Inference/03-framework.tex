\section{Rethinking with Retrieval}
\label{sec:framework}

LLMs have been shown to generate incorrect supporting facts from time to time, even when they accurately capture the perspective needed to answer a question. This phenomenon highlights intrinsic issues in the way LLMs store and retrieve knowledge, including (1) the presence of out-of-date, incorrect, or missing relevant knowledge in the pre-training corpus; (2) incorrect memorization of relevant knowledge during pre-training; and (3) incorrect retrieval of relevant knowledge during the inference stage. To address these issues, we propose the use of \NAME{}, which leverages external knowledge through the retrieval of relevant information based on decomposed reasoning steps.

\paragraph{Overview.} Given a query $Q$, we utilize chain-of-thought prompting to generate a diverse set of reasoning paths $R_1, R_2, \cdots R_N$, where each reasoning path $R_i$ consists of an explanation $E_i$ followed by a prediction $P_i$. After that, we retrieve relevant knowledge $K_1, \cdots K_M$ from a suitable knowledge base $\mathcal{KB}$ to support the explanation in each reasoning path, and select the prediction $\hat{P}$ that is most faithful to this knowledge. To better illustrate our proposal, we use ``\textit{Did Aristotle use a laptop?}'' as a running example in this work.

\paragraph{Chain-of-thought prompting.}  In contrast to standard prompting, CoT prompting \cite{wei2022chain} includes demonstrations of step-by-step reasoning examples in the prompt
to produce a series of short sentences that capture the reasoning process. For instance, given the question ``\textit{Did Aristotle use a laptop?}'', CoT prompting aims to generate the complete reasoning path ``Aristotle died in 322 BC. The first laptop was invented in 1980. Thus, Aristotle did not use a laptop. So the answer is no.'' rather than simply outputs ``No.'' Empirical results show that CoT prompting significantly improves the performance of LLMs on many multi-step reasoning tasks. Therefore, we adopt CoT prompting to obtain both explanation $E$ and prediction $P$ for the query $Q$. 

\paragraph{Sampling diverse reasoning paths.} Similar to \citet{wang2022self}, we sample a diverse set of reasoning paths $R_1, R_2, \cdots R_N$ rather than only considering the greedy path as in \citet{wei2022chain}. For the question ``\textit{Did Aristotle use a laptop?}'', the potential reasoning paths can be as follows:
\begin{itemize}
    \item[($R_1$)] Aristotle died in 2000. The first laptop was invented in 1980. Thus, Aristotle used a laptop. So the answer is yes.
    \item[($R_2$)] Aristotle died in 322BC. The first laptop was invented in 2000. Thus, Aristotle did not use a laptop. So the answer is no.
    \item[($R_3$)] Aristotle died in 322BC. The first laptop was invented in 1980. Thus, Aristotle did not use a laptop. So the answer is no.
\end{itemize}

\paragraph{Knowledge retrieval.} Different knowledge bases can be used to address different tasks. For example, to address the question ``\textit{Did Aristotle use a laptop?}'', we can use Wikipedia as the external knowledge base $\mathcal{KB}$. Information retrieval techniques can be applied to retrieve the relevant knowledge $K_1, \cdots K_M$ from Wikipedia based on the decomposed reasoning steps. Ideally, we would obtain the following two paragraphs from Wikipedia for this question:
\begin{itemize}
    \item[($K_1$)] Aristotle (384â€“322 BC) was a Greek philosopher and polymath during the Classical period in Ancient Greece. ...
    \item[($K_2$)] The Epson HX-20, the first laptop computer, was invented in 1980. ...
\end{itemize}

\paragraph{Faithful inference.} 
The faithfulness of each reasoning path $R_i$ can be estimated using a function $f_{\mathcal{KB}}(R_i)$, which is based on relevant knowledge $K_1, \cdots, K_M$ retrieved from the knowledge base $\mathcal{KB}$. The final prediction is obtained through the application of the following inference procedure\footnote{Note that this is the basic version of faithful inference, and further variations can be found in Section \ref{subsec:variations}.}:
\begin{equation}
\hat{P} = \argmax_{P_i \in\{P_1, \cdots, P_N\}} \sum_{i=1}^N \mathbbm{1}(P_i=P) f_{\mathcal{KB}}(R_i),
\label{eq:inference}
\end{equation}
where $P_i$ denotes the corresponding prediction in the reasoning path $R_i$. This inference procedure is designed to identify the most faithful prediction $\hat{P}$ to the knowledge base among all predictions in the $N$ reasoning paths. For instance, in the running example, given reasoning paths $R_1, R_2, R_3$ and the retrieved knowledge $K_1, K_2$, the above inference procedure would output the prediction ``So the answer is no.'', as it is supported by both $R_2$ and $R_3$ and has a higher faithfulness score compared to the prediction ``So the answer is yes.'', which is only supported by $R_1$. 


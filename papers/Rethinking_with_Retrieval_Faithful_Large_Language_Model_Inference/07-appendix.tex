\begin{table*}[ht]
\centering
\scalebox{1.0}{
\begin{tabular}{m{1.0\linewidth}}
\hline
{\bf Q:} who was governor of minnesota when maathaad maathaadu mallige was released? \bigstrut[t] \\
{\bf A:} Maathaad Maathaadu Mallige was released on 24 August 2007. Tim Pawlenty served as the 39th governor of Minnesota from 2003 to 2011. Thus, Tim Pawlenty was governor of minnesota when maathaad maathaadu mallige was released. {\bf So the answer is Tim Pawlenty.} \\
{\bf Q:} who was us president during the costa rican civil war? \bigstrut[t]  \\
{\bf A:} The Costa Rican civil war was a civil war in Costa Rica from 12 March to 24 April 1948. Harry S. Truman was the 33rd president of the United States, serving from 1945 to 1953. Thus, Harry S. Truman was us president during the costa rican civil war. {\bf So the answer is Harry S. Truman.} \\
{\bf Q:} who was governor of oregon when the collector was released? \bigstrut[t]\\
{\bf A:} The Collector premiered at the Cannes Film Festival on May 20, 1965. Mark Hatfield served as the 29th governor of Oregon from 1959 to 1967. Thus, Mark Hatfield was governor of oregon when the collector was released. {\bf So the answer is Mark Hatfield.}\\
{\bf Q:} who was governor of oregon when shanghai noon was released? \bigstrut[t] \\
{\bf A:} Shanghai Noon was released on May 26, 2000. John Kitzhaber served as the 35th governor of Oregon from 1995 to 2003. Thus, John Kitzhaber was governor of oregon when shanghai noon was released. {\bf So the answer is John Kitzhaber.}\\
{\bf Q:} who was us president when john andrew shulze was a teenager? \bigstrut[t] \\
{\bf A:} John Andrew Shulze was born on July 19, 1775. A teenager is someone who is between 13 and 19 years old. George Washington served as the first president of the United States from 1789 to 1797. Thus, George Washington was us president when john andrew shulze was a teenager. {\bf So the answer is George Washington.}\\
{\bf Q:} who was us president during the seventh coalition? \bigstrut[t] \\
{\bf A:} The War of the Seventh Coalition was from 20 March to 8 July 1815. James Madison served as the fourth president of the United States from 1809 to 1817. Thus, James Madison was us president during the seventh coalition. {\bf So the answer is James Madison.} \bigstrut[b]\\
\hline
\end{tabular}}
\caption{The CoT prompt for temporal reasoning.
}
\label{table:temporal-prompt}
\end{table*} 

\section{Appendix}
\label{sec:appendix}

In this section, we provide additional details on our experimental setup. Further information can be found in our code.

\subsection{Detailed Prompts}
\label{subsec:prompts}

We adopt the same CoT prompt for commonsense reasoning (i.e., StrategyQA) as those presented in \citet{wei2022chain}. The CoT prompt for temporal reasoning is provided in Table \ref{table:temporal-prompt}. For tabular reasoning, we adopt the method of \citet{brown2020language} for converting NLI into QA for RTE \cite{dagan2005pascal}, and randomly sample $6$ examples from the training data to construct the prompt, as shown in Table \ref{table:tabular-prompt}. The few-shot prompt utilizes the same exemplars as the CoT prompt and does not involve CoT reasoning processes.

\subsection{Description of Faithfulness Functions}
\label{subsec:faithfulness-functions}
For a sentence $s$, we denote its MPNet similarity, entailment score, and contradiction score as $M(s)$, $E(s)$, and $C(s)$, respectively. In our experiments, the corresponding thresholds for these scores are $T_m = 0.5$, $T_e = 0.6$, and $T_c = 0.99$. Given the entailment scores, contradiction scores, and MPNet similarities of all supporting facts (denoted as $S$) in the explanation of a reasoning path $R$, different faithfulness functions $f_{\mathcal{KB}}(\cdot)$ can be adopted in different settings as follows:
\begin{itemize}
    \item[(1)] $f_{\mathcal{KB}}(R) = \sum_{s \in S}
 [M(s) \times (M(s) >= T_m) + E(s) \times (M(s) < T_m)  - C(s)]$
    \item[(2)] $f_{\mathcal{KB}}(R) = \sum_{s \in S} [M(s) + E(s)]$
    \item[(3)] $f_{\mathcal{KB}}(R) = \sum_{s \in S} [E(s) \times (E(s) >= T_e) - C(s) \times (C(s) >= T_c)]$
\end{itemize}

In Section \ref{sec:experiments}, we employ function (1) for commonsense and tabular reasoning. For temporal reasoning, we use function (2) as the distinct nature of sentences converted from temporal relations leads to unreliable contradiction scores. In Sections \ref{subsec:variations}-\ref{subsec:model-size}, we use function (3) for commonsense reasoning with evidence paragraphs, as the high quality of the relevant knowledge negates the need for the complementary use of the MPNet similarity to improve the entailment score.


\subsection{Comparison of Retrieval Systems}
\label{subsec:retrieval-comparison}

For commonsense reasoning, we utilized different retrieval systems in \citet{karpukhin2020dense} to retrieve relevant paragraphs from Wikipedia. The performance of BM25, DPR, and BM25+DPR were $77.73\%$, $58.52\%$, and $77.29\%$, respectively, indicating that BM25 is the best choice in our case.

\iffalse
\subsection{Converting Temporal Relations to Sentences}
\label{subsec:temporal-templates}
\subsection{Converting Word Relations to Sentences}
\label{subsec:word-templates}
\fi

\subsection{Implementation Details for the Two Variants of \NAME{}}
\label{subsec:variants-implementation}

\paragraph{Fact selection implementation details.} In this work, we utilize the information present in the top-ranked output produced by our basic approach as a guide. To this end, we apply a greedy clustering algorithm to group the sentences from all outputs into distinct topic categories based on the cosine similarity of their MPNet sentence embeddings. For each fact in the top-ranked output of our basic approach, we identify the fact with the highest faithfulness within the same topic group and replace it in the output. The faithfulness of a fact is calculated using the $f_{\mathcal{KB}}$ function by replacing the supporting facts with a single fact.

\paragraph{Fact generation implementation details.} In this part, we generate questions for the named entities present in each fact of the top-ranked output produced by our basic approach, and retrieve the corresponding answers from the evidence paragraphs using UnifiedQA. We employ the question generation model described in \citet{deutsch2021towards}, which has been shown to be more extractive compared to other models as demonstrated in \citet{fabbri2021qafacteval}. We adopt the question filtering approach proposed in \citet{honovich2021q2} using an off-the-shelf extractive QA model (ktrapeznikov/albert-xlarge-v2-squad-v2 from Hugging Face \cite{wolf2020transformers}). We then use an off-the-shelf model (MarkS/bart-base-qa2d from Hugging Face) to convert the generated QA pairs into declarative sentences. We apply simple rules based on the entailment and contradiction scores of the selected facts from the fact selection variant and the generated declarative sentences to obtain the final generated facts.

\subsection{Comparison of Different Inference Methods with Supporting Facts}
\label{subsec:inference-comparison}

In our experiments, we utilize UnifiedQA for the final step of inference in both variants. However, it is worth noting that GPT-3 could also be used for this purpose. As shown in Table \ref{table:inference-comparison}, we observe that UnifiedQA performs better at inference with generated facts, while GPT-3 with CoT prompting performs better with empty or gold facts. This suggests that UnifiedQA is more robust to noisy inputs compared to GPT-3. Additionally, both UnifiedQA and GPT-3 with CoT prompting significantly outperform GPT-3 with zero-shot prompting, indicating that the CoT prompting is also beneficial for the final step of inference.



\begin{table}
\centering
\scalebox{0.85}{
\begin{tabular}{c|c|c}
 & Methods & Accuracy (\%) \bigstrut[b] \\ \hline
\multirow{3}{*}{Empty facts} &  GPT-3 (zero-shot) & 58.08 \bigstrut[t] \\ 
 & GPT-3 (CoT) & {\bf 65.94} \\
 & UnifiedQA & 58.95 \bigstrut[b] \\ \hline
 \multirow{3}{*}{Gold facts} & GPT-3 (zero-shot) & 81.66 \bigstrut[t] \\ 
 & GPT-3 (CoT) & {\bf 91.70} \\
 & UnifiedQA & 90.83 \bigstrut[b] \\ \hline
 \multirow{3}{*}{Generated facts} & GPT-3 (zero-shot) & 69.87 \bigstrut[t] \\ 
 & GPT-3 (CoT) & 76.42 \\
 & UnifiedQA & {\bf 78.60} \bigstrut[b]  \\ \Xhline{2\arrayrulewidth}
\end{tabular}}
\caption{Comparison of different inference methods on empty, gold, and generated facts.
}
\label{table:inference-comparison}
\end{table} 

\begin{table*}
\centering
\scalebox{1.0}{
\begin{tabular}{m{1.0\linewidth}}
\hline
Charles Sumner Tainter was Born on April 25, 1854   ( 1854-04-25 )   Watertown, Massachusetts, U.S..  Charles Sumner Tainter was Died on April 20, 1940   ( 1940-04-21 )  (aged 85)  San Diego, California, U.S..  The Nationality of Charles Sumner Tainter are American.  The Known for of Charles Sumner Tainter are Photophone, phonograph Father Of The Speaking Machine. \bigstrut[t] \\
{\bf Question:} Charles Sumner Tainter never left the state of Massachusetts. True or False?\\
{\bf Answer:} Charles Sumner Tainter was died in San Diego, California, U.S.. California is a state. Thus, Charles Sumner Tainter has left the state of Massachusetts. {\bf So the answer is false.} \\
The Region of Curitiba are South.  The Elevation of Curitiba are 934.6 m (3,066.3 ft).  The Density of Curitiba are 4,062/km 2  (10,523/sq mi).  The Metro density of Curitiba are 210.9/km 2  (546.2/sq mi). \bigstrut[t] \\
{\bf Question:} Curitiba is above sea level. True or False?\\
{\bf Answer:} The elevation of Curitiba are 934.6 m (3,066.3 ft). Elevation is a hypernym of level. Thus, Curitiba is above sea level. {\bf So the answer is true.}\\
Charles (Prince of Wales) was Born on 14 November 1948 ( 1948-11-14 )   (age 70)  Buckingham Palace, London, England.  The Spouse of Charles (Prince of Wales) are Lady Diana Spencer ( m.   1981 ;  div.   1996 )  , and Camilla Parker Bowles  ( m.   2005 ).  The Issue of Charles (Prince of Wales) are Prince William, Duke of Cambridge , and Prince Harry, Duke of Sussex. \bigstrut[t] \\
{\bf Question:} Charles was born in 1948 and has been married twice. True or False?\\
{\bf Answer:} Charles (Prince of Wales) was Born on 14 November 1948. The Spouse of Charles (Prince of Wales) are Lady Diana Spencer ( m.   1981 ;  div.   1996 )  , and Camilla Parker Bowles  ( m.   2005 ). Married is related to spouse. Thus, Charles was born in 1948 and has been married twice. {\bf So the answer is true.}\\
The Born of Idris Elba are 6 September 1972  (age 46)   Hackney, London, England.  The Residence of Idris Elba are London.  The Other names of Idris Elba are DJ Big Driis, Big Driis the Londoner, Big Driis, and 7 Dub.  The Occupation of Idris Elba are Actor, producer, director, musician, and DJ. \bigstrut[t] \\
{\bf Question:} Idris Elba is an English entertainer. True or False?\\
{\bf Answer:} The residence of Idris Elba is London. English is related to London. The occupation of Idris Elba are actor, producer, director, musician, and DJ. Actor is a hyponym of entertainer. Musician is a hyponym of entertainer. DJ is an entertainer. Thus, Idris Elba is an English entertainer. {\bf So the answer is true.} \\
The Breed of Jean, the Vitagraph Dog are Scotch Collie.  The Sex of Jean, the Vitagraph Dog are Female.  The Born of Jean, the Vitagraph Dog are 1902 Eastport, Maine.  The Years active of Jean, the Vitagraph Dog are 1909 - 1916. \bigstrut[t] \\
{\bf Question:} Jean, the Vitagraph Dog was a Golden Retriever which perform in circus. True or False?\\
{\bf Answer:} The Breed of Jean, the Vitagraph Dog are Scotch Collie. Collie is a hyponym of dog. Retriever is a hyponym of dog. Thus, Jean, the Vitagraph Dog was not a Golden Retriever which perform in circus. {\bf So the answer is false.}\\
The Studio of Hydrograd are Sphere Studios, North Hollywood, Los Angeles.  The Genre of Hydrograd are Hard rock.  The Label of Hydrograd are Roadrunner.  The Producer of Hydrograd are Jay Ruston. \bigstrut[t]\\
{\bf Question:} Hydrograd is in the rap genre. True or False?\\
{\bf Answer:} The Genre of Hydrograd are Hard rock. Rap is distinct from rock. Thus, Hydrograd is not in the rap genre. {\bf So the answer is false.} \bigstrut[b]\\
\hline
\end{tabular}}
\caption{The CoT prompt for tabular reasoning.
}
\label{table:tabular-prompt}
\end{table*} 
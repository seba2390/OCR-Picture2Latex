\section{Related Work}

\paragraph{Enhancing LMs through retrieval.} Retrieval-enhanced LMs have received significant attention as a means of improving performance through the incorporation of external knowledge. For example, the k-most similar training contexts can be retrieved to improve the estimation of the next word distribution in both the training stage \cite{borgeaud2021improving} and the inference stage \cite{khandelwal2019generalization}. Furthermore, search query generators have been adopted to generate search queries for search engines to retrieve relevant documents \cite{komeili2022internet, shuster2022language, thoppilan2022lamda}. Other approaches have utilized retrieved documents as the additional context in generation tasks \cite{joshi2020contextualized, guu2020retrieval, lewis2020retrieval}. \citet{nakano2021webgpt} instead use human feedback in a text-based web-browsing environment. Among these previous works, \citet{khandelwal2019generalization} is most closely related to our approach. However, they focus on improving local inference by using the nearest neighbor datastore constructed from training data, whereas we focus on conducting faithful inference using external knowledge. In contrast to other aforementioned approaches, which require training or fine-tuning to incorporate retrieved knowledge, we propose a post-processing method for leveraging retrieved knowledge without additional training or fine-tuning.

\paragraph{Incorporating external knowledge into LMs.} Significant effort has been devoted to leveraging external knowledge to improve the reasoning ability of LMs. Previous work has incorporated external knowledge sources such as WordNet \cite{miller1995wordnet} and ConceptNet \cite{speer2017conceptnet} to enhance LMs for tabular reasoning tasks \cite{neeraja2021incorporating, varun2022trans}. Explicit rules have also been added to inputs to improve reasoning ability over implicit knowledge \cite{talmor2020leap}. In addition, explicit knowledge from Wikidata \cite{vrandevcic2014wikidata} and implicit knowledge in LLMs have been integrated into a transformer \cite{vaswani2017attention} for visual question answering \cite{gui2021kat}. \citet{nye2021improving} instead introduces a symbolic reasoning module to improve coherence and consistency in LLMs. Among these previous works, \citet{nye2021improving} is the most relevant to our approach. Still, they focus on incorporating logical constraints to improve coherence and consistency, whereas we aim to improve the faithfulness of explanations through the use of external knowledge. In contrast to other aforementioned approaches that incorporate external knowledge before generation and require additional training or fine-tuning, our proposal leverages external knowledge in a post-processing manner to enhance LMs without additional training or fine-tuning.

\paragraph{Uncovering latent Knowledge in LLMs.} There has been a line of work exploring the knowledge hidden within LLMs for reasoning. This has included the use of careful prompting to encourage LLMs to generate explanations in the reasoning process, such as through chain of thought prompting in few-shot \cite{wei2022chain} or zero-shot \cite{kojima2022large} learning, or through the use of scratchpads for intermediate computation \cite{nye2022show}. In addition, various methods based on sampling a diverse set of reasoning paths in LLMs have been proposed, including training verifiers to judge the correctness of model completions \cite{cobbe2021training}, calibrating model predictions based on the reliability of the explanations \cite{ye2022unreliability}, and promoting self-consistency over diverse reasoning paths \cite{wang2022self}. \citet{zelikman2022star} instead iteratively bootstrap the ability of LLMs to generate high-quality rationales from a few initial examples. \citet{liu2022generated} further propose generating knowledge from LLMs, which is then used as additional input to improve commonsense reasoning. In contrast to this line of work, our proposal focuses on leveraging external knowledge to enhance LLMs, while they aim to explore the knowledge hidden within LLMs.







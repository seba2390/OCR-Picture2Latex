\section{Related work}
\label{sec:related}

During the last two decades, several algorithms have addressed image-based pupil detection.
\citet{perez2003precise} first thresholded the image and compute the mass center of the resulting dark pixels. This process was iteratively repeated in an area
around the previously estimated mass center to determine a new mass center until convergence.
The Starburst algorithm, proposed by \citet{li2005starburst}, first
removed the corneal reflection and then located pupil edge points using an iterative feature-based approach.
Based on the RANSAC algorithm~\citet{fischler1981random}, a
best fitting ellipse is determined, and the final ellipse parameters are selected by applying a model-based optimization.
\citet{long2007high} first down sampled the image and search there for an approximate pupil location. The image area around this location was further processed and a parallelogram-based symmetric mass center algorithm is
applied to locate the pupil center.
In another approach, \citet{lin2010robust} thresholded the image, removed
artifacts by means of morphological operations, and applied inscribed
parallelograms to determine the pupil center.
\citet{keil2010real} first located corneal reflections; afterwards,
the input image was thresholded, the pupil blob was searched in the adjacency of
the corneal reflection, and the centroid of pixels belonging to the blob was
taken as pupil center.
\citet{san2010evaluation} threshold the input image and extract
points in the contour between pupil and iris, which were then fitted to an
ellipse based on the RANSAC method to eliminate possible outliers.
\citet{swirski2012robust} started with
a coarse positioning using Haar-like features. The intensity histogram of the coarse position was clustered using  k-means clustering, followed by a modified RANSAC-based ellipse fit.
The above approaches have shown good detection rates and robustness  in controlled settings, i.e., laboratory conditions.

Three recent methods, SET~\citet{javadi2015set}, ExCuSe~\citet{fuhl2015excuse},
and ElSe~\citet{fuhl2015else}, explicitly address the aforementioned challenges
associated with pupil detection in natural environments.
SET~\citet{javadi2015set} first extracts pupil pixels based on a luminance
threshold. The resulting image is then segmented, and the segment borders are
extracted using a Convex Hull method.  Ellipses are fit to the segments based on
their sinusoidal components, and the ellipse closest to a circle is selected as
pupil.  ExCuSe~\citet{fuhl2015excuse} first analyzes the input image with regard
to reflections based on intensity histograms. Several processing steps based on
edge detectors, morphologic operations, and the Angular Integral Projection
Function are then applied to extract the pupil contour. Finally, an ellipse is
fit to this line using the direct least squares method.
ElSe~\citet{fuhl2015else} is based on the same edge based approach as
ExCuSe~\citet{fuhl2015excuse} with further modifications like improved
morphologic operations and line segment filtering by applying an ellipse fit. In
addition the Angular Integral Projection function is replaced by a weighted blob
detector. Although the latter three methods report substantial improvements over
earlier methods, noise still remains a major issue.  Thus, robust detection,
which is critical in many online real-world applications, remains an open and
challenging problem~\citet{JEMR3657}.

Recent developments in machine learning, especially in the field of
neuronal networks, had a big breakthrough by learning cascaded filter
banks, e.g.,~\citet{krizhevsky2012imagenet,lecun1998gradient}. In particular for
computer vision, there are three main advantages of CNNs when compared to fully
connected neuronal networks.
First, the convolution layers, which are linear filter banks learned
by the CNN can be seen as neuronal network layers with
shared weights.%, meaning that one neuron uses the same weights as the others in
%this layer.
 In image processing, this is achieved by convolving the weights with the
input layer. As a result, these filters are shift-invariant and applicable to the
entire image (since image statistics are stationary). Furthermore, only the local neighborhood of a location has an influence on the result, i.e, the
spatial information of the response remains through to the neuron position. Each
convolution layer has many of these filters and is usually followed by a pooling
layer. The pooling layer subsamples the data and therefore reduces noise. The
second advantage is the topological structure of a CNN, which arises from
cascading multiple convolution layers. This allows to learn features from lower
level features, which is generally known as deep learning. The third advantage is
the consecutive reduction of the parameters in comparison to a fully connected
neuronal network, which results from the topological structure.

Recent developments in CNNs are multi scale
layers~\citet{gong2014multi,cai2016unified}, the inclusion of transposed
convolutional layers (approximated deconvolution)~\citet{xu2014deep,
long2015fully} and recurrent
CNNs~\citet{liang2015recurrent,pinheiro2014recurrent}.
For example, the multi scale approach
by \citet{gong2014multi} is based on spatial pyramid matching from
\citet{lazebnik2006beyond}. The input image is processed on multiple scales
using ImageNet from \citet{krizhevsky2012imagenet}. The extracted feature
vectors are than feed into a CNN. This approach was evaluated for
classification, recognition, and image retrieval. \citet{cai2016unified} proposed
a CNN architecture with fixed input size capable of handling multiple object
sizes. This multi scale CNN follows the idea of training multiple detectors for
each object size summarized in one CNN. For training they used a multi-task loss
formulation where each label consists of the class and the enclosing bounding
box. Another interesting development is the use of recurrent neuronal
networks~\citet{carpenter1987massively} as convolution layer. The idea behind
recurrent neuronal networks is the usage of information from previous
computations. \citet{liang2015recurrent} proposed the recurrent convolution
layer based approach and showed its applicability for image recognition. For
scene labeling \citet{pinheiro2014recurrent} proposed an architecture, which
corrects itself due to this recurrence information. If it is about detection all
mentioned architectures have to be applied to multiple image locations in a
sliding window approach, due to the fact that each layer reduces the output
size. CNNs with transposed convolutional layers address this problem by
spreading the convolution of one location to multiple positions in the output.
These layers approximate a deconvolution. The architecture with transposed
convolutional layers was first proposed by \citet{long2015fully}. Alternatively
\citet{xu2014deep} trained a CNN to learn real deconvolution filters for image
restoration. The architecture of the net consists of large one dimensional
kernels which represent the separable deconvolution filters.

In our scenario, we want to train a CNN for real time pupil center detection
based on the CPU. Therefore most of the extensions like recurrent neuronal
networks, deconvolution or multi scale networks remain prohibitively expensive.
We used the classical window based approach with coarse and fine positioning to
reduce the computational costs of convolutions. In addition, we propose a fast
direct approach.



\section{Evaluation}
\label{sec:eval}
\label{sec:expeval}
Training and evaluation figures reported in this paper were obtained on an
Intel\textsuperscript{\textregistered} Core\texttrademark i5-4670 desktop
computer with 8GB RAM. This setup was chosen because it provides a
performance similar to systems that are usually provided by eye-tracker vendors,
thus enabling the actual eye-tracking system to perform other experiments along with the evaluation.
The algorithm was implemented using MATLAB (r2015b) combined with caffe~\citet{jia2014caffe}.
We report our results in terms of the average pupil detection rate as a function
of pixel distance between the algorithmically established and the hand-labeled
pupil center.
Although the ground truth was labeled by experts in eye-tracking research,
imprecision cannot be excluded. Therefore, the results are discussed for a pixel
error of five (i.e., pixel distance between the algorithmically established and
the hand-labeled pupil center), analogously to~\citet{fuhl2015excuse,swirski2012robust}.\\
We performed a per data set cross validation guaranteeing that the CNNs are evaluated on distinct images from those it was trained on. In addition this gives us the advantage for a more detailed comparison between PupilNet and the state-of-the-art algorithms.

\subsection{Coarse positioning}
\begin{figure}[h]
	\begin{center}
		\includegraphics[width=.95\textwidth]{coarse.png}
	\end{center}
	\caption{
		Performance for the evaluated coarse CNNs using the per data set cross validation showing the downscaled error ($*4$ for real error). Each data set is weighted equally meaning that the average result over all data sets is shown independent of their image count.
	}
	\label{fig:evalcoarse}
\end{figure}
We start by evaluating the candidates from~\tblref{tbl:overview} for the coarse
positioning CNN. \figref{fig:evalcoarse} shows the performance of the coarse positioning CNNs
when trained using the per data set cross validation.
As can be seen in figure~\ref{fig:evalcoarse}, the number of filters in the first layer
(\ckp{8}{8}, and \ckp{8}{16}) have only a small impact to the detection rate.
Increasing the amount for both convolutions (\ckp{16}{32}) improves the result slightly but also increases the computational costs (\figref{fig:evalcoarse} shows he average detection rate over all data sets meaning that one percent improvement means an betterment on all data sets). However, it is important to notice
that this is the most expensive parameter in the proposed CNN architecture in
terms of computation time and, thus, further increments must be carefully included.

\subsection{Fine positioning}
\begin{figure}[h]
	\begin{center}
		\includegraphics[width=\textwidth]{fine.png}
	\end{center}
	\caption{
		All CNNs were trained and evaluated using the per data set cross validation. The average detection rate over all data sets is shown. The result for \csin{} is with accuracy improvement from section~\ref{sec:ffai}.
	}
	\label{fig:evalfine}
\end{figure}

\setlength{\tabcolsep}{0.2mm}
\renewcommand{\arraystretch}{0.5}
\begin{table}[h!]
	\caption{Five pixel error for the proposed CNNs and the state-of-the-art per data set.}
	\begin{center}
		\begin{tabular}{c|c|c|c|c|c|}
			& ElSe & ExCuSe & \csin{} & \cfin & $F_{SK_{X}P_{Y}}$  \\
			I & \textbf{0.86} & 0.72 & 0.77 & 0.78 & 0.82 \\
			II & 0.65 & 0.40 & \textbf{0.80} & 0.79 & 0.79 \\
			III & 0.64 & 0.38 & 0.62 & 0.60 & \textbf{0.66} \\
			IV & 0.83 & 0.80 & 0.90 & 0.90 & \textbf{0.92} \\
			V & 0.85 & 0.76 & 0.91 & 0.89 & \textbf{0.92} \\
			VI & 0.78 & 0.60 & 0.73 & 0.78 & \textbf{0.79} \\
			VII & 0.60 & 0.49 & 0.73 & \textbf{0.80} & 0.73 \\
			VIII & 0.68 & 0.55 & \textbf{0.84} & 0.83 & 0.81 \\
			IX & \textbf{0.87} & 0.76 & 0.86 & 0.86 & 0.86 \\
			X & 0.79 & 0.79 & 0.80 & 0.78 & \textbf{0.81} \\
			XI & 0.75 & 0.58 & 0.85 & 0.74 & \textbf{0.91} \\
			XII & 0.79 & 0.80 & \textbf{0.87} & 0.85 & 0.85 \\
			XIII & 0.74 & 0.69 & 0.79 & 0.81 & \textbf{0.83} \\
			XIV & 0.84 & 0.68 & 0.91 & 0.94 & \textbf{0.95} \\
			XV & 0.57 & 0.56 & \textbf{0.81} & 0.71 & \textbf{0.81} \\
			XVI & 0.60 & 0.35 & \textbf{0.80} & 0.72 & \textbf{0.80} \\
			XVII & 0.90 & 0.79 & \textbf{0.99} & 0.87 & 0.97 \\
			XVIII & 0.57 & 0.24 & 0.55 & 0.44 & \textbf{0.62} \\
			XIX & 0.33 & 0.23 & 0.34 & 0.20 & \textbf{0.37} \\
			XX & 0.78 & 0.58 & \textbf{0.79} & 0.73 & \textbf{0.79} \\
			XXI & 0.47 & 0.52 & 0.81 & 0.67 & \textbf{0.83} \\
			XXII & 0.53 & 0.26 & 0.50 & 0.52 & \textbf{0.58} \\
			XXIII & \textbf{0.94} & 0.93 & 0.86 & 0.87 & 0.90 \\
			XXIV & 0.53 & 0.46 & 0.46 & \textbf{0.55} & \textbf{0.55} \\
			new I & 0.62 & 0.22 & \textbf{0.69} & 0.56 & \textbf{0.69} \\
			new II & 0.26 & 0.16 & 0.44 & 0.35 & \textbf{0.45} \\
			new III & 0.39 & 0.34 & 0.45 & 0.44 & \textbf{0.49} \\
			new IV & 0.54 & 0.48 & \textbf{0.83} & 0.77 & 0.82 \\
			new V & 0.75 & 0.59 & 0.78 & 0.76 & \textbf{0.81} \\
			\cline{1-6}
		\end{tabular}
	\end{center}
	\label{tbl:eye}
\end{table}

The \cfin was evaluated using all the previously evaluated coarse CNNs (i.e., \ckp{8}{8}, \ckp{8}{16}, and
\ckp{16}{32}). In addition the direct approach \csin{} was evaluated with the accuracy correction from \secref{sec:ffai}. Similarly to the coarse positioning, these were also evaluated
through the per data set cross validation.

As baseline, we evaluated five state-of-the-art algorithms, namely, \emph{ElSe}~\citet{fuhl2015else},
\emph{ExCuSe}~\citet{fuhl2015excuse}, \emph{SET}~\citet{javadi2015set},
\emph{Starburst}~\citet{li2005starburst}, and \citet{swirski2012robust}. The
average performance of the evaluated approaches is shown in~\figref{fig:evalfine}.

As can be seen in the figure, all two-stage CNNs surpass the best performing state-of-the-art approach \emph{ElSe}~\citet{fuhl2015else} by $\approx4$\% and $\approx9$\%. Although the proposed two stage approaches (\cfin and $F_{SK_8P_8}$) reach the best pupil detection rate in average per data set at a pixel error of five, it is worth highlighting the performance of the \csin{} ($\approx7$\% over the state-of-the-art) with its reduced computational costs (runtime of 7ms on a intel i5-4570 3.2GHz single core). This low runtime was reached by only evaluating every second image position in the first step and afterwards extracting the CNN responses on a per pixel level only surrounding the found maximum. The final optimization applied to this region is described in section~\ref{sec:ffai}. In comparison \emph{ElSe} has a runtime of 7ms, \emph{ExCuSe} 6ms and \citet{swirski2012robust} 8ms. \emph{Starburst} and \emph{SET} are not comparable because we used the MATLAB implementation. \cfin has a runtime of 1.2 seconds where in the first step \ckp{8}{8} is used with a runtime of 6ms. Due to the lower accuracy of \ckp{8}{8} in comparison to \csin{} we had to increase the search region of \cfin ($49 \times 49$). This large search region and the high computational costs of \cfin forced us to only evaluate every second image position. For $F_{SK_8P_8}$ we used \csin{} as coarse positioning CNN followed by a fine positioning in a $21 \times 21$ search region. $F_{SK_8P_8}$ has a runtime of 850ms. Due to the architecture of CNNs both approaches \cfin and $F_{SK_8P_8}$ are fully parallelizable with a runtime per patch ($89\times89$) of 2ms. For a finer comparison at a pixel error of five, all results are shown in Table~\ref{tbl:eye}.



\section{Introduction}
For over a century now, the observation and measurement of eye movements have
been employed to gain a comprehensive understanding on how the human oculomotor
and visual perception systems work, providing key insights about cognitive
processes and behavior~\citet{wade2005moving}. Eye-tracking devices are rather
modern tools for the observation of eye movements.
In its early stages, eye tracking was restricted to static activities, such as
reading and image perception~\citet{yarbus1957perception}, due to restrictions
imposed by the eye-tracking system -- e.g., size, weight, cable connections, and
restrictions to the subject itself.
With recent developments in video-based eye-tracking technology, eye tracking
has become an important instrument for cognitive behavior studies in many areas,
ranging from real-time and complex applications (e.g., driving
assistance based on eye-tracking input~\citet{kasneci2013towards} and gaze-based
interaction~\citet{turner2013eye}) to less demanding use cases, such as usability
analysis for web pages~\citet{cowen2002eye}.
Moreover, the future seems to hold promises of pervasive and unobtrusive
video-based eye tracking~\citet{kassner2014pupil}, enabling research and
applications previously only imagined.
Whereas video-based eye tracking has been shown to perform satisfactorily under
laboratory conditions, many studies report the occurrence of difficulties and
low pupil detection rates when these eye trackers are employed for tasks in
natural environments, for instance
driving~\citet{kasneci2013towards,liu2002real,trosterer2014eye} and
shopping~\citet{kasneci2014homonymous}.
The main source of noise in such realistic scenarios is an unreliable pupil
signal, stemming from intricate challenges in the image-based pupil
detection.
A variety of difficulties occurring when using video-based eye trackers, such as
changing illumination, motion blur, and pupil occlusion due to eyelashes, are
summarized in~\citet{schnipke2000trials}.
Rapidly changing illumination conditions arise primarily in tasks where the
subject is moving fast (e.g., while driving) or rotates relative to unequally
distributed light sources, while motion blur can be caused by the image sensor
capturing images during fast eye movements such as saccades.
Furthermore, eyewear (e.g., spectacles and contact lenses) can result in
substantial and varied forms of reflections (\figref{fig:reflection} and
\figref{fig:reflection2}), non-centered or off-axis eye position relative to the
eye-tracker can lead to pupil detection problems, e.g., when the pupil is
surrounded by a dark region (\figref{fig:dark}).
Other difficulties are often posed by physiological eye characteristics, which
may interfere with detection algorithms (\figref{fig:physiological}).
It is worth noticing that such unreliable pupil signals can not only
significantly disturb algorithms for the automatic identification of eye
movements~\citet{santini2016bayesian} but also result in inaccurate gaze estimates.
As a consequence, the data collected in such studies must be post-processed
manually, which is a laborious and time-consuming procedure.
Additionally, this post-processing is impossible for real-time applications that
rely on the pupil monitoring (e.g., driving or surgery assistance).
Therefore, a real-time, accurate, and robust pupil detection is an essential
prerequisite for pervasive video-based eye-tracking.
\begin{figure}[h]
	\begin{center}
		\subfloat[][\label{a}]{
			\includegraphics[width=.23\columnwidth]{reflection-ex.png}
			\label{fig:reflection}
		}
		\subfloat[][\label{b}]{
			\includegraphics[width=.23\columnwidth]{reflection2-ex.png}
			\label{fig:reflection2}
		}
		\subfloat[][\label{c}]{
			\includegraphics[width=.23\columnwidth]{dark-ex.png}
			\label{fig:dark}
		}
		\subfloat[][\label{d}]{
			\includegraphics[width=.23\columnwidth]{physiological-ex.png}
			\label{fig:physiological}
		}
		\caption{
			Images of typical pupil detection challenges in
			real-world scenarios: (a) and (b) reflections, (c) pupil
			located in dark area, and (d) unexpected physiological structures.
		}
	\end{center}
\end{figure}

State-of-the-art pupil detection methods range from relatively simple methods
such as combining thresholding and mass center
estimation~\citet{perez2003precise} to more elaborated methods that attempt to
identify the presence of reflections in the eye image and apply
pupil-detection methods specifically tailored to handle such challenges~\citet{fuhl2015excuse} -- a
comprehensive review is given in \secref{sec:related}.
Despite substantial improvements over earlier methods in real-world scenarios,
these current algorithms still present unsatisfactory detection rates in many
important realistic use cases (as low as 34\%~\citet{fuhl2015excuse}).
However, in this work we show that carefully designed and trained convolutional
neural networks~(CNN)~\citet{domingos2012few,lecun1998gradient}, which rely on
statistical learning rather than hand-crafted heuristics, are a substantial step
forward in the field of automated pupil detection.
CNNs have been shown to reach human-level performance on a multitude of pattern
recognition tasks (e.g., digit recognition~\citet{ciresan2012multi}, image
classification~\citet{krizhevsky2012imagenet}).
These networks attempt to emulate the behavior of the visual processing system
and were designed based on insights from visual perception research.

We propose a dual convolutional neural network pipeline for image-based pupil detection. The first pipeline stage employs a shallow CNN on subregions of a downscaled version of the input image to quickly infer a coarse
estimate of the pupil location. This coarse estimation allows the
second stage to consider only a small region of the original image, thus, mitigating the impact of noise and decreasing computational costs.
The second pipeline stage then samples a small window around the coarse position
estimate and refines the initial estimate by evaluating
subregions derived from this window using a second CNN. We have focused on
robust learning strategies (batch learning) instead of more accurate ones
(stochastic gradient descent)~\citet{lecun2012efficient} due to the fact that an
adaptive approach has to handle noise (e.g., illumination, occlusion,
interference) effectively. The motivation behind the proposed pipeline is (i) to reduce the noise in the coarse estimation of the pupil position, (ii) to reliably detect the exact pupil position from the initial estimate, and (iii) to provide an efficient method that can be run in real-time on hardware architectures without an accessible GPU.

A further contribution of this work is a new hand-labeled data set with more
than 40,000 eye images recorded in real world experiments. This data set
consists of highly challenging eye images containing scattered reflections on
glasses covering the parts or the complete pupil, pupils in dark areas whereby
the contrast to the surrounding area is low, and additional black blobs on the
iris, which may result from eye surgery.
In addition, we propose a method for generating training data in an online-fashion, thus being applicable to the task of pupil center detection in online scenarios. We evaluated the performance of different CNN configurations both in terms of quality and efficiency and report considerable improvements over stat-of-the-art techniques.


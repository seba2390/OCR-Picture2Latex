\section{Introduction}
\label{sec:intro}

Epidemic models are used across biological and social sciences, engineering and computer science, and have had important impact in the study of the dynamics of human disease, computer viruses, but also trends rumors, viral videos, and most recently the spread of fake news of social networks. Their history in the literature dates to the first mathematical model of epidemics by Bernoulli in 1760 ~\cite{Bernoulli2004}.
%, epidemics have been studied extensively. Although the initial focus was on modeling precisely the dynamics of diseases under a variety of propagation assumptions, epidemic behavior is not limited to the disease setting, and in fact also accurately models the propagation of computer viruses, trends, and rumors. Recent applications of interest include yearly flu outbreaks, viral videos, and the spread of fake news on social networks. 
In this paper, we focus on epidemics propagating on a graph, as introduced by the seminal paper ~\cite{Newman2002}. In particular, we consider so-called SI models (see below for a precise definition) where an infected node can only propagate the infection to its non-infected neighbor, as opposed to the fully mixed models considered in the early literature. This graph-based approach provides a more realistic model, in which the spread of the epidemic is determined by the connectivity of the graph, and accordingly some nodes may play a larger role than others in the spread of the infection.  
%high-degree nodes can potentially infect many more nodes if they become infected themselves (e.g., a school teacher or a politician), and low-degree nodes are less of a risk (e.g. a PhD student working from home).

At any point in time, the {\em state} of an SI-type epidemic on a graph is given by the list of nodes on the graph that are infected, and their relative topology (position) in the graph. Having a good estimate of the state is critical, as it determines the dynamics of the spread of the epidemic into the future. As a simple example, we can ask what the spreading rate is on an $N$-node line graph of an infection with $N/2$ infected nodes. If those nodes are contiguous, then it will take $O(N)$ time for the epidemic to spread to the entire graph. If every other node is infected, it will take $O(1)$ time. 

If we have access to the status of each node (infected or not), then we know the state exactly. Much work has focused on the state estimation problem, in the setting where only noisy information is available. Indeed, work in ~\cite{Milling2015,Milling2015a,meirom2015}, ~\cite{Arias-castro2011,Arias-Castro2008,Arias-castro}, and elsewhere, considers a setting where only noisy observations of the status of each node are possible, and even answering whether there is an epidemic or not is a challenge. Those and related works, as we discuss in more detail below, focus on the problems related to epidemic state estimation, and do not consider the control problem of curing the epidemic.

%
%When considering a potential epidemic outbreak, the first question we need to answer is whether or not there is indeed an epidemic, and if the answer is positive, where the epidemic is. If only generative data is available without noise, there is nonetheless a profusion of highly noisy data ~\cite{bla}. The detection problem in the noisy setting has been considered in the statistical literature ~\cite{Arias-castro2011DetectionNetwork}, as well as in the networks literature (Milling et al.). 

On the other side, the problem of curing an epidemic with a limited budget, {\em but with perfect observation} (i.e., perfect knowledge of the state at each point in time), has been recently considered in ~\cite{Drakopoulos2015a,Drakopoulos2014}. Their budget, as we explain more precisely further below, is essentially a bound on the {\em curing effort} they can expend at a given time (as opposed to total curing effort over time). In this setting, the problem is to optimize the allocation of the curing budget across nodes at every point in time. They characterize the budget required for fast curing, as a function of a combinatorial property of the graph -- its {\sc CutWidth} (we define this below).
% prove fast curing is possible if the rate of curing is sufficiently large, and if we know the state of every node on the graph at every possible time. 

The problem of curing an epidemic with a limited budget and partial observation of the state of the epidemic (i.e., which nodes are infected and which are not) introduces a fundamentally new element to the problem. Indeed, this interaction represents a fundamental tension: our estimate of the state of a node improves the longer we observe it, and so the longer we wait to cure a node, the less likely we are to waste precious curing resources on non-infected nodes. On the other hand, the longer an infected node remains untreated, the more the epidemic spreads. To the best of our knowledge, no work has successfully attacked the problem of curing an epidemic with a limited budget and partial observation of the state of the epidemic (i.e., which nodes are infected and which are not). Our work considers precisely this problem, and therefore, broadly speaking, is about the interaction of -- specifically, simultaneous -- learning and control. 
%Our work aims at reconciling the detection approach and the curing approach. Broadly speaking, this work is about the interaction of learning (where the epidemic is) and control (the spread). %What happens when we only have partial information on the state of the graph (noisy data), but our goal is still to cure the graph? Can we detect where the epidemics is in time for this information to still be relevant?
% these questions are bad. Try to convey the fact that the infection has moved on
% In particular, we are interested in the interaction of partial information and the budget required to cure. 

By considering learning the state and controlling the epidemic simultaneously, we prove a lower bound that shows (see Section \ref{sec:partial} for precise result) that partial information can have a dramatic impact on the resources (either time or budget) required to cure an infection: even with slightly imperfect/incomplete information, the time to cure a particular graph may increase exponentially, unless the budget is also significantly increased. Concretely, we show that if instead of receiving the state of each node at each point in time, we receive a slightly noisy (e.g., only 99\% accurate) guess of the state, then there is no constant factor of the {\sc CutWidth} which is sufficient for {\em any algorithm} to cure the epidemic in linear (expected) time. 
 
\subsection{Related Work and Background}
\label{sec:related}

% We need a discussion of the work by Kesten, Bahmidi et al., and how this was used in the Milling et al. papers.
% We need a discussion of the work by Arias-Castro et al.
% We need a discussion of the MIT work. This should be fairly in depth, to the point where we (briefly) describe their ideas and main definitions, insofar as we need them ourselves. Possibly the details should be in another section, and here we discuss only their results and how they interact with our results?


Detecting an epidemic, as well as its location, under noisy data, has been well-studied in ~\cite{Arias-castro2011}, in the context of detecting a multidimensional anomalous cluster, with time playing the same role as any other dimension. Graph-specific epidemic detection has been further studied by ~\cite{Sharpnack2012}, with constraints based on the cut of this anomalous cluster. ~\cite{Milling2015} study the detection of epidemic-specific clusters by detecting the shapes which arise specifically when there is an epidemic. The focus in those works has been to understand the limit of information required in order to detect the epidemic. More generally, inverse problems have also been of interest, especially source detection ~\cite{spencer2015impossibility,shah2011rumors, shah2012rumor,wang2014rumor, shah2010detecting} or obfuscation ~\cite{fanti2015spy, fanti2016rumor}. 

In our work, we adopt a much stronger observation model than in the papers listed above; our negative result establishes, however, that controlling the epidemic is impossible with weaker information than the threshold we characterize.

In ~\cite{Drakopoulos2015,Drakopoulos2014}, the authors tackle the problem of curing graphs with perfect knowledge of the state of each node, constrained by a budget which corresponds to the speed at which the nodes are cured. Their results show that there exists a threshold phenomenon: for any given graph, if the curing budget is lower than a combinatorial quantity of the graph called the {\sc CutWidth}, the curing time is exponential; if it is higher, they exhibit a strategy to cure any graph in sublinear time. The {\sc CutWidth} captures a key bottleneck in curing, and is important in our work as well. Therefore it is useful to define this precisely now.
\begin{definition}
\label{def:cutwidth}
Given a graph $G = G(V,E)$, and any subset of the nodes, $S \subseteq V$, the {\sc Cut} of $S$ is the number of edges crossing from $S$ to $S^c$. Given any sequence of $|V|+1$ subsets $S_0,\dots,S_{|V|}$ such that $S_0 = \emptyset$, $S_{|V|} = V$, and $S_k$ and $S_{k+1}$ differ by the addition of a single node (called a {\em crusade} in \cite{Drakopoulos2014,Drakopoulos2015}), the cut of the sequence is the largest cut of any of the sets $S_k$. The {\sc CutWidth} of a graph is the minimum cut of any sequence satisfying the above properties.
\end{definition}
Intuitively, the {\sc CutWidth} of a graph is the largest cut one would be {\em forced} to encounter when curing a graph. The cut of a subset is critical, because for an infected set of nodes $S$, its cut is the number of non-infected nodes adjacent to infected nodes, and hence is the instantaneous rate of infection of the epidemic at that moment (in that configuration). For an illustration, consider again an $N$-node line graph. Its {\sc CutWidth} is equal to one, since when curing the graph from one end to the other, we have only one single non-infected node adjacent to an infected node at any time. Note that this is the best case, because if we were to start curing nodes in the middle of the infection, the cut between the infected nodes and the non-infected nodes could be made as large as $O(N)$. 

Their strategy is based on two main ideas. The nodes are cured following an ordering which keeps the cut between the infected set and the non-infected set as low as possible. Then, as soon as there is a new infection, the strategy switches to damage control, and focuses on returning to the ordering previously mentioned. 

Our result hinges on the fact that the damage-control part of the strategy is exactly the part which is hard to accomplish with partial information. If the number of $k$-hop neighbors of a node grows exponentially, as is the case for the binary tree, detecting where the infection can have spread becomes a difficult task. Moreover, if we can detect such an escape path, but the infection has spread to a high number of nodes by the time we have enough information to try to prevent it, detection was useless. It is the tension between waiting less time and wasting budget on false alerts, or waiting too long and being unable to prevent the spread, which makes the problem of curing with partial information challenging. 
 
 
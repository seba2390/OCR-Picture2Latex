\section{Proof for Partial Information} \label{sec:partial}
\begin{definition}
We call \textbf{sample} the information given by one node at a given time step (i.e., whether a flag was raised or not). We call an \textbf{infected-sample} a sample from an infected node.
\end{definition}

When an $Escape$ happens, we show that with constant probability, not too many infected-samples are produced. In particular, by the time reinfecting $\frac{N}{r^4}$ new nodes becomes inevitable with constant probability, not enough infected-samples are produced to determine if one of the minimal trees' nodes is infected with better than constant error probability. In other words, no strategy can utilize the information available without making mistakes a constant fraction $P_{confuse}$ of the time.

If we cannot recognize that an infection has happened before it is too late to prevent it, everything is as if we were in the Blind Curing model. We can therefore extend the results from the previous section.

\subsection{Quantity of information available before the cut reaches $3r$}

If we reuse the terms introduced in Section \ref{sec:BlindCuring}, the $Escapes$ we consider are composed of four phases: 
\begin{enumerate}
\item reaching the root
\item reaching the root of a minimal tree. There are $r$ possible such minimal trees.
\item infecting $3r$ nodes in this minimal tree
\item spreading the infection from $3r$ to $\frac{N}{r^4}$ nodes
\end{enumerate}
Since the spreading phase (4) happens with constant probability even in the Complete Information setting, we focus on the number of samples created by the first three phases. We focus in particular on the number of samples created by phase (3) in Lemma \ref{lem:nSamples}. We show in the proof of Lemma \ref{lem:escapeTime} that the number of samples produced by phases (1) and (2) is negligible compared to the number of samples produced by phase (3). To make sure that no other infected-samples can be gathered, we forbid infections from happening outside of an $Escape$ (Lemma \ref{cl:noOtherInfection}).

Let us notice that every time a new infection takes place, the cut increases by 1 (every new node infected gives access to 2 new nodes, but the edge leading to it is not part of the cut any longer).

The next lemma says that in the event of an infection in a minimal tree, it is likely that the number of infected-samples we obtain is small.

\begin{lemma}\label{lem:nSamples} 
In the event that the root of the minimal tree becomes infected, then conditioned on the event that $3r$ new nodes of this minimal tree become infected, we gather at most $\frac{6r}{\tau}$ samples from the newly infected nodes, with probability at least $\frac{1}{2}$.
\proof Let $N_{\rm samples}$ be the number of samples produced by infected nodes from the time one node was infected to the moment the $3r^{th}$ node was infected. The time to infect one more node when $i$ nodes are infected is given by a geometric variable $Geo(i,\mu)$ of parameter $1-(1-\mu)^i$ (Proposition \ref{cl:minGeo} of the appendix). Therefore, the $j$th node to be infected produces $\sum_{i=j}^{3r-1} Geo(i,\mu)$ samples. Thus, conditioned on the event that $3r$ nodes become infected:
\begin{align*}
N_{\rm samples} &= \sum_{j=1}^{3r-1} \sum_{i=j}^{3r-1} Geo(i,\mu) = \sum_{j=1}^{3r-1} j\cdot Geo(j,\mu) .
\end{align*}
Therefore, again conditioned on $3r$ nodes becoming infected, the expected number of samples is:
\begin{align*}
\E(N_{\rm samples} \,| \, \mbox{$3r$ infected}) &= \sum_{j=1}^{3r-1} j\cdot \E(Geo(j,\mu)) = \sum_{j=1}^{3r-1} j\cdot \frac{1}{1-(1-\mu)^j} \\
&=_{\tau \to 0} \sum_{j=1}^{3r-1} j\cdot  \frac{1}{j\tau} \qquad \leq_{\tau \to 0} \frac{3r}{\tau}.
\end{align*}
We conclude by using Markov's Inequality.
\qed
\end{lemma}

We now count the number of samples available from phases (1), (2) and (3) of an $Escape$.

\begin{lemma} \label{lem:escapeTime} 
Conditioned on the event that an $Escape$ happened, we gather at most  $\frac{6r}{\tau}$ infected-samples from phase (3), and $\frac{360\log^2(r)}{\tau}$ infected-samples from phases (1) and (2), with probability at least $\frac{1}{4}$.
\proof
Using Proposition \ref{cl:rootclose}, there are at most $9\log(r)$ nodes from one infected node to the root. Using Proposition \ref{lem:minimalTree}, the minimal tree is at distance $3\log(r)$ from the root. We then need $3r$ additional infections to get to a point where the infection is unstoppable (Proposition \ref{cl:Pspread}).  Using Markov's Inequality, we can infect these $9\log(r) + 3\log(r) = 12 \log(r)$ nodes in $\frac{24\log(r)}{\tau}$ time steps with probability $\frac{1}{2}$. Using Lemma \ref{lem:infectionTime} of the appendix, we can infect the $3r$ nodes in $\frac{2\log(3r)}{\tau} \leq \frac{6\log(r)}{\tau}$ time steps with probability $\frac{1}{2}$. Therefore, we can infect all these nodes in $\frac{30\log(r)}{\tau}$ time steps with probability $\frac{1}{4}$, which gives at most $\frac{30\log(r)}{\tau} \cdot 12 \log(r)$ samples for the first $12 \log(r)$ nodes, and $2 \cdot \frac{3r}{\tau} = \frac{6r}{\tau}$ samples for the last $3r$ nodes, which concludes the proof.
\qed
\end{lemma}

Conditioned on reaching a cut of $3r$ in a minimal tree in less than $\frac{30\log(r)}{\tau}$ time steps, we now bound the probability of not infecting any nodes which are not part of the $Escape$. This ensures that the only infected samples we could get come from the nodes in the $Escape$.

\begin{proposition}
	Conditioned on reaching a cut of $3r$ in a minimal tree in less than $\frac{30\log(r)}{\tau}$ time steps, the probability $P_{\rm NoOtherInfections}$ of not infecting any nodes outside of the $Escape$  is bounded by:
		\begin{align*}
		 P_{\rm NoOtherInfections} &\leq e^{-\frac{360\log^2(r)\mu}{\tau}} \\
		 &\leq_{\tau \to 0} e^{-360\log^2(r)}.
		 \end{align*}
	\proof The proof can be found in Proposition  \ref{cl:noOtherInfection} in the Appendix.
\end{proposition}


\subsection{Distinguishing between infected and not infected}
The proof relies on this idea: any strategy attempting to prevent an $Escape$ needs to shift its budget towards the minimal tree in which the infection is progressing. For this to happen, it is necessary to realize that one of the minimal trees is threatened. Determining which one amounts to distinguishing between the following hypotheses: 
\begin{itemize}
\item $H_0$: In the null hypothesis, none of the $r$ minimal trees have any infected nodes.
\item $H_1$: One of the $r$ minimal trees has at least one infected node, while the others do not.
\end{itemize}

We use the results in Lemma \ref{cl:samples} to show that there are not enough infected-samples created by nodes on the path from the node close to the root to the root of a minimal tree to realize that even one node is infected. This implies that the nodes from phase (1) and (2) cannot help detect a threat to a minimal tree. Lemma  \ref{cl:samples} is also used to show that we do not gather enough infected-samples from phase (3) to distinguish between $H_0$ and $H_1$ defined above, which means we cannot know if there is at least one infected node in one minimal tree.

Thus, we combine all these results to calculate $\p(NoEscapePI)$, the probability that an $Escape$ happens, that not too many samples are produced during this $Escape$, that no other nodes are infected outside of the $Escape$, that the samples from phase (1) and (2) do not allow the identification of the infected minimal tree, and that the samples from phase (3) are not enough to reveal whether or not one minimal tree is indeed infected. 

We finally use these results to extend the Blind Curing theorem to the Partial Information setting (Theorem \ref{th:partialInfo}).


\begin{lemma} \label{cl:samples} 
\begin{enumerate}
\item We need $\Omega \left(  \frac{\log\left(\frac{1}{\epsilon}\right)}{\mathcal{D}(p||q)} \right)$ samples to decide if a node is infected or not with probability at least $\Omega \left( 1 - \epsilon \right)$.
\item We need $\Omega \left(  \frac{\log\left(\frac{1}{\epsilon}\right) \sqrt{\log(r)}}{\mathcal{D}(p||q)} \right)$ samples to distinguish between hypothesis $H_0$ and $H_1$, and detect if one minimal tree has at least one node infected among $r$ minimal trees.
\end{enumerate}

\proof \begin{enumerate}
\item Using Sanov's Theorem ~\cite{Sanov1961}, following the proof in Proposition 5.6 of ~\cite{Mansour2011}, we know that we need $\Omega\left(\frac{1}{\mathcal{D}(p||q)}\right)$ samples to distinguish between two coins of parameters $p$ and $q$ with probability $\Omega(1)$. We can boost this probability to show that we need  $\Omega \left(  \frac{\log\left(\frac{1}{\epsilon}\right)}{\mathcal{D}(p||q)} \right)$ to distinguish between $p$ and $q$ with probability $\Omega \left( 1 - \epsilon \right)$.
\item This follows by considering the maximum of $r$ $\mathcal{B}(n,q)$ binomial random variables. Using a Gaussian approximation to the binomial, and the fact that the maximum of $r$ standard Gaussian random variables is $\sqrt{2 \log(r)}$, we obtain the desired result. 
%from work on PAC-bounds for finding the best arm in the multi-armed bandit setting (e.g., \cite{even2006action}), and it essentially amounts to using a union bound over the $r$ minimal trees, thus obtaining the additional $\log(r)$ factor. As the calculation is standard, we refer to Theorem 6 of \cite{even2006action}. The result directly implies that if we have $r$ coins where one of them has probability of heads $q$ and the others have probability of heads $p < q$, then if they are each flipped $n$ times, the biased one will be identified correctly with probability $(1-\epsilon)$ if $n = \Omega\left( \frac{\log(\frac{1}{\epsilon})\log(r)}{D(p||q)}\right)$ times.
\end{enumerate}
\qed
\end{lemma}


\begin{corollary} \label{cor:Pconfuse} 
The probability $P_{\rm confuse}$ of not being able to detect which minimal tree is infected during phase (3) is bounded away from 0. 

In particular, we have:
\begin{align*}
P_{\rm confuse} &=_{N \gg 1} \Omega\left(e^{-\frac{\mathcal{D}(p||q)}{\tau} \cdot \frac{r}{\sqrt{\log(r)}} } \right).
\end{align*}
\proof We separate the samples in two groups:
\begin{itemize}
	\item The sample from phase (1) and (2) are used to detect if one node was infected on the path from the node close to the root to the root of a minimal tree. We get $\frac{360\log^2(r)}{\tau} = \frac{\log\left(e^{\frac{\mathcal{D}(p||q)}{\tau} \cdot 360\log^2(r) }\right) } {\mathcal{D}(p||q)}$ samples from phase (1) and (2) (Lemma \ref{lem:nSamples}), so the probability of confusing coins of parameters $p$ and $q$ is at least $ \Omega\left(e^{-\frac{\mathcal{D}(p||q)}{\tau} \cdot 360\log^2(r) } \right)$ according to Lemma \ref{cl:samples}.
	\item The samples from all phases are used to distinguish between $H_0$ and $H_1$. We get $\frac{6r}{\tau} = \frac{\log\left(e^{\frac{\mathcal{D}(p||q)}{\tau} \cdot \frac{6r}{\sqrt{\log(r)}} }\right) \sqrt{\log(r)} } {\mathcal{D}(p||q)}$ samples from phase (1) and (2) (Lemma \ref{lem:nSamples}), so the probability of confusing coins of parameters $p$ and $q$ is at least $ \Omega\left(e^{-\frac{\mathcal{D}(p||q)}{\tau} \cdot \frac{6r}{\sqrt{\log(r)} } } \right)$ according to Lemma \ref{cl:samples}.
\end{itemize}
Combining the two, the probability of not detecting the threat is at least:
\begin{align*}
	P_{\rm confuse} &= \Omega\left(e^{-\frac{\mathcal{D}(p||q)}{\tau} \cdot (\frac{6r}{\sqrt{\log(r)} } + 360\log^2(r))} \right) \\
	&=_{N \gg 1} \Omega\left(e^{-\frac{\mathcal{D}(p||q)}{\tau} \cdot \frac{r}{\sqrt{\log(r)} } } \right).
\end{align*}
\qed
\end{corollary}
We now consider the time needed to cure the graph for  $P_{\rm confuse} > 0$.


\begin{lemma} \label{lem:timePconfuse} 
Let $EscapePI$ be the event that by the time it takes to cure half of $\frac{N}{r^4}$ infected nodes, an $Escape$ happens but remains undetectable (\textit{i.e.,} the samples produced by the newly infected nodes during phases (1), (2), and (3) are not enough to deduce that there exists an infected minimal tree), and no node outside of the $Escape$ becomes infected. We provide a bound for $NoEscapePI$, the complementary of this event.

$$ \p(NoEscapePI) \leq e^{-\frac{P_{\rm NoOtherInfections} \cdot P_{\rm confuse} \cdot N}{e^{96\alpha^2\log^2\log(N)}}}.$$
\proof Let $EscapeOneStepPI$ be the conjunction of all the following events:
\begin{itemize}
	\item An $Escape$ happens at a given time step, which happens with probability at least $P_{\rm EscapeOneStep}$ (Lemma \ref{lem:Pescape}).
	\item Conditioned on an $Escape$ happening, less than $\frac{6r}{\tau}$ samples are produced by the newly infected nodes during phase (3), and less than $\frac{360\log^2(r)}{\tau}$ infected-samples are produced during phase (1)-(2), which happens with probability at least $\frac{1}{4}$ (Lemma \ref{lem:nSamples}).
	\item Conditioned on an $Escape$ happening in less than $\frac{30\log(r)}{\tau}$ time steps, no node outside of the $Escape$ becomes infected, which happens with probability $P_{\rm NoOtherInfections}$.
    \item Conditioned on all the above, the samples from phase (3) are not enough to reveal whether or not one minimal tree is indeed infected, which happens with probability $P_{\rm confuse}$.
\end{itemize} 
We notice that if we cannot tell whether or not a minimal tree is infected by the time it takes to reach phase (4) of an $Escape$, the situation is almost equivalent to the Blind Curing model. We can therefore apply exactly the same reasoning as in Theorem \ref{th:BlindCuring} if we replace $\p(EscapeOneStep)$ by $\p(EscapeOneStepPI)$. 
\begin{align*} 
\p(EscapeOneStepPI) \geq &P_{\rm EscapeOneStep} \cdot \frac{1}{4}  \\
&\, \cdot P_{\rm NoOtherInfections} \cdot P_{\rm confuse},
 \end{align*}
Following the exact same reasoning as in Lemma \ref{lem:Pescape}, we get:
$$ \p(NoEscapePI) \leq e^{-\frac{P_{\rm NoOtherInfections} \cdot P_{\rm confuse} \cdot N}{e^{96\alpha^2\log^2\log(N)}}}.$$
%Thus, it takes $\Omega \left(   \frac{e^{\frac{P_{\rm confuse} \cdot N}{e^{20\alpha^2\log^2\log(N)}}} \cdot N}{2\log^{4\alpha}(N)} \right) $ time to cure the graph in expectation.
\qed
\end{lemma}

\begin{theorem}{A Partial Information impossibility result} \label{th:partialInfo} \\
Let $\frac{\mathcal{D}(p||q)}{\tau}$ be a measure of the amount of information we get by time step. If:
\begin{align*}
\frac{\mathcal{D}(p||q)}{\tau} &\leq \OO\left( \left(\log\left(\frac{N}{e^{456\alpha^2\log^2\log(N)}} \right)  - 2\log\log(N)\right)\frac{\sqrt{\log(r)} }{r} \right)  \\ 
&= \OO\left(\frac{\log(N)\sqrt{\log(r)} }{r}\right),
\end{align*}  as $\tau \to 0$, we cannot cure the complete binary tree in polynomial expected time with budget $r = W^\alpha$, for any $\alpha$ constant.
\proof 
From Lemma \ref{lem:timePconfuse}, we know: 
$$ \p(NoEscapePI) \leq e^{-\frac{P_{\rm confuse} \cdot P_{\rm NoOtherInfections} \cdot N}{e^{96\alpha^2\log^2\log(N)}}}.$$
From Corollary \ref{cor:Pconfuse}, we know 
$$P_{\rm confuse} \geq \Omega\left(e^{-\frac{\mathcal{D}(p||q)}{\tau} \cdot \frac{r}{\sqrt{\log(r)} } } \right).$$
\begin{align*}
 \p(NoEscapePI) &\leq e^{-\frac{ P_{\rm NoOtherInfections} \cdot P_{\rm confuse} \cdot N}{e^{96\alpha^2\log^2\log(N)}}} \\
 %&\geq e^{-\OO\left(\frac{ e^{-\frac{\mathcal{D}(p||q)}{\tau} \cdot \frac{r}{\log(r)}} \cdot N}{e^{96\alpha^2\log^2\log(N) + 12\log^2(r)}}\right)} \\
 &\geq  e^{-\OO\left(\frac{ e^{- \cdot\left(\log\left(\frac{N}{e^{456\alpha^2\log^2\log(N)}} \right)  - 2\log\log(N)\right)  \cdot \frac{r\sqrt{\log(r)}}{\sqrt{\log(r)} r}} \cdot N}{e^{456\alpha^2\log^2\log(N)}}\right)} \\
 &\geq e^{-\OO\left(\log^2(N)\right)}.
\end{align*}
Following the same reasoning as in Theorem \ref{th:BlindCuring}, we conclude it takes at least $ \frac{e^{\Omega \left(  \log^2(N)\right)} \cdot N}{2\log^{4\alpha}(N)}  \geq e^{\Omega\left(  \log^2(N)\right)} $ time to cure the graph, so more than any polynomial expected time.
\qed 
\end{theorem}
In particular, this holds for $\alpha = 1$. If we remember that the {\sc CutWidth} of a tree is smaller than $\log(N)$ (Proposition \ref{cl:Wtree} of the appendix), we obtain:

\begin{corollary}
If the quantity of information by time step measured by $\frac{\mathcal{D}(p||q)}{\tau} $ is constant, no strategy can achieve polynomial time curing for the complete binary tree in the Partial Information setting, for budget $r= \OO(W) = \OO(\log(N))$.
\end{corollary}

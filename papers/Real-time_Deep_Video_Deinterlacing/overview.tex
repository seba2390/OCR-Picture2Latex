Given an input interlaced frame $\mathbf{I}$ (Fig.~\ref{fig:cnn_model}(a)),  our
goal of deinterlacing is to reconstruct two full size original frames
$\mathbf{X}_t$ and $\mathbf{X}_{t+1}$ from $\mathbf{I}$
(Fig.~\ref{fig:cnn_model}(d)). We denote the odd field of $\mathbf{I}$ as
$\mathbf{X}^{\text{odd}}_t$ (blue pixels in Fig.~\ref{fig:cnn_model}(a)), and
the even field of $\mathbf{I}$ as $\mathbf{X}^{\text{even}}_{t+1}$ (red pixels in
Fig.~\ref{fig:cnn_model}(a)). The superscripts, $\text{odd}$ and $\text{even}$,
denote the odd- or even-numbered half frames. The subscripts, $t$ and $t+1$,
denote the two fields are captured at two different time instances. Our goal is
to reconstruct two missing half frames, $\mathbf{X}^{\text{even}}_t$ (light blue
pixels in Fig.~\ref{fig:cnn_model}(c)) and $\mathbf{X}^{\text{odd}}_{t+1}$ (pink
pixels in Fig.~\ref{fig:cnn_model}(c)). Note that we retain the known fields
$\mathbf{X}^{\text{odd}}_t$  (blue pixels) and $\mathbf{X}^{\text{even}}_{t+1}$
(red pixels) in our two output full frames (Fig.~\ref{fig:cnn_model}(d)).

To estimate the unknown pixels $\mathbf{X}^{\text{even}}_t$ and
$\mathbf{X}^{\text{odd}}_{t+1}$ from the interlaced frame $\mathbf{I}$, we
propose a novel DCNN model (Fig.~\ref{fig:cnn_model}(b) \& (c)). The input
interlaced frame can be of any resolution, and two half output images are
obtained with five convolutional layers. The weights of the convolutional
operators are trained from a DCNN model training procedure based on a prepared
training dataset. During the training phase, we synthesize a set of interlaced
videos from progressive videos of different types as the training pairs. The
reason that we need to synthesize interlaced videos for training is that no
groundtruth exists for the existing interlaced videos captured by interlaced
scan devices. The details of preparing the training dataset and the design
of the proposed DCNN are described in Section~\ref{sec:deinterlacing}. 
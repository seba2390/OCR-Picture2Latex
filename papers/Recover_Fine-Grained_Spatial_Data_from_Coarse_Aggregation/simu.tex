%!TEX root = main.tex
\section{Performance Evaluation}
\label{sec:simu}

% compare CDFs
\begin{figure*}[!htb]
    \centering
            \subfigure[November, $n_{\text{BS}} = 200$]{
                \includegraphics[width=1.7in]{figures/CDF_200_Nov}
                    \label{fig:CDF200Nov}
            }
            \hspace{-3mm}
            \subfigure[December, $n_{\text{BS}} = 200$]{
                \includegraphics[width=1.7in]{figures/CDF_200_Dec}
                    \label{fig:CDF200Dec}
            }
            \hspace{-3mm}
            \subfigure[November, $n_{\text{BS}} = 100$]{
                \includegraphics[width=1.7in]{figures/CDF_100_Nov}
                    \label{fig:CDF100Nov}
            }
            \hspace{-3mm}
            \subfigure[December, $n_{\text{BS}} = 100$]{
                \includegraphics[width=1.7in]{figures/CDF_100_Dec}
                    \label{fig:CDF100Dec}
            }
            \vspace{-3mm}
    \caption{The comparison of the CDFs of relative errors given by different estimation methods when $n_{\text{BS}} = 200$ and $n_{\text{BS}} = 100$ for stress-testing. The legends follow the same order as the curves at relative error $= 0.5$.}
    \label{fig:compareCDF100}
\vspace{-3mm}
\end{figure*}

% % % compare bar plot. 4 in one line.
% % \begin{figure*}[t]
%     \centering
%             \subfigure[November, $n_{\text{BS}} = 200$]{
%                 \includegraphics[width=3.2in]{figures/barplot_200_Nov}
%                     \label{fig:barplot200Nov}
%             }
%             \hspace{-3mm}
%             \subfigure[December, $n_{\text{BS}} = 200$]{
%                 \includegraphics[width=3.2in]{figures/barplot_200_Dec}
%                     \label{fig:barplot200Dec}
%             }
%             \vspace{0mm}
%             \subfigure[November, $n_{\text{BS}} = 100$]{
%                 \includegraphics[width=3.2in]{figures/barplot_100_Nov}
%                     \label{fig:barplot100Nov}
%             }
%             \hspace{-3mm}
%             \subfigure[December, $n_{\text{BS}} = 100$]{
%                 \includegraphics[width=3.2in]{figures/barplot_100_Dec}
%                     \label{fig:barplot100Dec}
%             }
%             \vspace{0mm}
%     \caption{Comparison of the estimation's Mean Relative Error of different methods when $n_{\text{BS}} = 200$ or $n_{\text{BS}} = 100$ for stress-testing. In each figure, the bars from left to right stands for Patched Estimation, Patched Estimation + SSR 1, Patched Estimation + SSR 2, Constrained Spatial Smoothing, and Constrained Spatial Smoothing + Features respectively.}
%     \label{fig:compareMRE}
% \vspace{0mm}
% \end{figure*}

% compare bar plot. 4 in one line.
\begin{figure*}[t]
    \centering
            \subfigure[November, $n_{\text{BS}} = 200$]{
                \includegraphics[width=1.7in]{figures/barplot_200_Nov}
                    \label{fig:barplot200Nov}
            }
            \hspace{-3mm}
            \subfigure[December, $n_{\text{BS}} = 200$]{
                \includegraphics[width=1.7in]{figures/barplot_200_Dec}
                    \label{fig:barplot200Dec}
            }
            \hspace{-3mm}
            \subfigure[November, $n_{\text{BS}} = 100$]{
                \includegraphics[width=1.7in]{figures/barplot_100_Nov}
                    \label{fig:barplot100Nov}
            }
            \hspace{-3mm}
            \subfigure[December, $n_{\text{BS}} = 100$]{
                \includegraphics[width=1.7in]{figures/barplot_100_Dec}
                    \label{fig:barplot100Dec}
            }
            \vspace{-3mm}
    \caption{The comparison of the Mean Relative Error of different estimation methods when $n_{\text{BS}} = 200$ or $n_{\text{BS}} = 100$ for stress-testing. In each figure, the bars from left to right represent Patched Estimation, Patched Estimation + SSR 1, Patched Estimation + SSR 2, Constrained Spatial Smoothing, and Constrained Spatial Smoothing + Features, respectively.}
    \label{fig:compareMRE}
\vspace{-6mm}
\end{figure*}


% % compare bar plots
% \begin{figure*}[t]
%     \centering
%             \subfigure[November]{
%                 \includegraphics[width=3.2in]{figures/barplot_200_Nov}
%                     \label{fig:barplot200Nov}
%             }
%             \hspace{-3mm}
%             \subfigure[December]{
%                 \includegraphics[width=3.2in]{figures/barplot_200_Dec}
%                     \label{fig:barplot200Dec}
%             }
%             \vspace{-3mm}
%     \caption{Comparison of the estimation's Mean Relative Error of different methods when $n_{\text{BS}} = 200$.}
%     \label{fig:compareMRE200}
% \vspace{1mm}
% %\end{figure*}

% %\begin{figure*}[t]
%     \centering
%             \subfigure[November]{
%                 \includegraphics[width=3.2in]{figures/barplot_100_Nov}
%                     \label{fig:barplot100Nov}
%             }
%             \hspace{-3mm}
%             \subfigure[December]{
%                 \includegraphics[width=3.2in]{figures/barplot_100_Dec}
%                     \label{fig:barplot100Dec}
%             }
%             \vspace{-3mm}
%     \caption{Comparison of the estimation's Mean Relative Error of different methods when $n_{\text{BS}} = 100$ for stress-testing.}
%     \label{fig:compareMRE100}
% \vspace{-5mm}
% \end{figure*}




% In this section, we perform an extensive case study of the approach we described above in order to demonstrate its applicability. 
The model in \eqref{eq:add-auxiliary} is not attached to any particular empirical problem and does not contain many implicit assumptions, it is general. However, in order to measure its performance we evaluate the model using real-world cell phone data.
% We picked the cell phone data as an example of how the model can solve empirical problem and compare the model's performance to other approaches.

% \subsection{Dataset Description}
% \label{sec:activity-recovery}

% The model in \eqref{eq:add-auxiliary} is not attached to any particular empirical problem and does not contain many implicit assumptions, it is general. However, in order to measure its performance we evaluate the model using real-world data. Due to generality of the proposed learning algorithm the range of possible data sets is potentially big. For our empirical case study we chose cell phone data, where there exists a problem of recovering a spatial field from coarse aggregations observed at sparse cell phone towers. We do not overestimate the problem, but rather see this particular data set suitable for extensive case study.
%To give a more intuitive idea about our problem, here we %introduce the datasets we utilized, and describe how we %process the data to study the problem of inferring cell %phone activities spatial distribution.

The Milan Call Description Records (CDR) dataset
% is a part of the Telecom Italia Big Data Challenge dataset provided by Telecom Italia Mobile.
% It
contains the telecommunications activity records from November 1$st$, 2013 to December 31$th$, 2013 in the city of Milan~\cite{bigdatachallenge}. In the Milan CDR dataset, the city of Milan is divided into a $100\times 100$ square grid. Each square is size of about 235m $\times$ 235m. Each activity record consists of the following entries: square ID, time-stamp of 10-minute time slot, incoming SMS activity, outgoing SMS activity, incoming call activity and outgoing call activity. The values of the four types of activities are normalized to the same scale.



% % grid
% \begin{figure}[t]
%         %\hspace{7mm}
%         \includegraphics[width=3.3in]{figures/grid}
%         %\vspace{-5mm}
%         \caption{The map shows the metropolitan area of Milan, Italy, and the area covered by the 2726 grid squares.}
%         \label{fig:grid}
%         \vspace{-3mm}
% \end{figure}


Another dataset we utilized is the Milan geographical attribute dataset available from the Municipality of Milan's Open Data website \cite{barlacchi2015multi}. This dataset consists of features of central 2726 squares among the whole $10,000$ squares. The features of each square include: population, green area percentage, number of sport centers, number of universities, number of businesses, and number of bus stops.
% Fig.~\ref{fig:grid} shows the map of Milan and the area covered by these grid squares. The 2726 squares covers the central part of the Milan city and contains the majority of telecommunication activities in the dataset.
% We refer to~\cite{bcici_mobihoc15} for more detailed description about this dataset.
In our empirical study, we focus on these squares to compare the performance of different algorithms.

% % value distribution
% \begin{figure}[t]
%                         \centering
%                         \subfigure[November]{
%                 \includegraphics[width=1.5in]{figures/heatmap_Nov_call_sms}
%                                 \label{fig:heatmapNov}
%                         }
%                 \hspace{-4mm}
%                         \subfigure[December]{
%                 \includegraphics[width=1.5in]{figures/heatmap_Dec_call_sms}
%                                 \label{fig:heatmapDec}
%                         }
%                         \vspace{-1mm}
%                 \caption{The heat map of call + sms activities during November and December.}
%                 \label{fig:NovDecHeatmap}
% \vspace{-5mm}
% \end{figure}



The general \textbf{\textit{problem of recovering a spatial field from coarse aggregations observed at sparse points in
the field}} in this particular case study is reformulated into \textbf{\textit{the problem of recovering the distribution of cell phone activities over the whole 2726 square regions given that only aggregated activity observations in base stations are known}}. To study this problem, we need to further process the Milan CDR dataset.

\textit{First}, we sum up the four types of activities during November and December respectively to come up with the activity volume of each square during the two months. These two datasets are served as the ground-truth datasets of Milan cell phone activity distributions.
% Fig.~\ref{fig:heatmapNov} and Fig.~\ref{fig:heatmapDec} show the heat maps of activity volumes in each square during November and December. 
\textit{Second}, after we aggregated the two months' activities for each square, we need to set the locations of base stations (BSs). According to \cite{ratti2006mobile}, there are roughly $200$ base stations in Milan. However, the exact locations are not available. Thus, we assume the $n_{\text{BS}}$ ($n_{\text{BS}} = 200$ or $100$ for stress-test) BSs are randomly distributed according to the probability distribution
$
\Pr (\text{Set square $i$ as BS}) = f(\mathbf p_i) / \sum_{j=1}^{N}f(\mathbf p_j),
$
where $f(\mathbf p_i)$ is the cell phone activity volume in square $i$, $i=\{1, \ldots, N\}$, $N=2726$ is the number of squares we are focusing on. 
% Notice that when we have 200 base station's aggregated observations, they only cover $7.34 \%$ of the whole 2726 squares region. This is extremely sparse and makes our problem highly challenging.
% In addition, we also assume $n_{\text{BS}} = 100$ and choose $100$ squares as BSs according to the same probability distribution to stress-test our algorithm's capability under even sparser observations.
\textit{Third}, after the base station locations are sampled, the activity of each square will be assigned to its closest base station. If multiple base stations are equidistant from the square, then the activity of this square will be evenly distributed among these base stations. We then assume we only know the aggregated activities in base station squares, which is usually the true case in reality.
Fig.~\ref{fig:100BS} and Fig.~\ref{fig:100BSincharge} show the base station distributions and the region charged by each base station for $n_{\text{BS}} = 100$ respectively.
% To save space, we don't present the figure for 200 base stations. 

% % sample BS location
% \begin{figure}[t]
%                         \centering
%                         \subfigure[$n_{\text{BS}} = 200$]{
%                 \includegraphics[width=1.5in]{figures/heatmap_200BS}
%                                 \label{fig:200BS}
%                         }
%                 \hspace{-4mm}
%                         \subfigure[$n_{\text{BS}} = 100$]{
%                 \includegraphics[width=1.5in]{figures/heatmap_100BS}
%                                 \label{fig:100BS}
%                         }
%                         \vspace{-1mm}
%                 \caption{The sampled base station distributions for $n_{\text{BS}} = 200$ and $n_{\text{BS}} = 100$.}
%                 \label{fig:BSLocations}
% \vspace{-5mm}
% \end{figure}







% \subsection{Experimental Setup}
% \subsubsection{\bf Algorithms Evaluated}
We test our proposed approach and compare it with 3 baseline methods.
% In particular, we evaluate and compare the following models using the aggregated November and December datasets, with number of base stations $n_{\text{BS}} = 200$ or $n_{\text{BS}} = 100$ for stress testing.
\begin{itemize}
\item \textbf{Patched Estimation (PE)}:
% estimate the cell phone activity distribution by patched piece-wise constant estimation, that is, 
assume cell phone activity density is distributed uniformly within each sub-region $\Omega_{B_i}$
% , i.e., the area covered by base station $B_i$,
and estimate each square's activity volume by \eqref{eq:patched}.
\item \textbf{Patched Estimation + SSR 1}: first estimate \textit{only base station} activity volumes by \eqref{eq:patched}. Use these sparse points to fit a smooth surface by running Spatial Spline Regression to obtain the estimated cell phone activity in all squares. 
\item \textbf{Patched Estimation + SSR 2}: first estimate the activity volumes of \textit{all squares} by Patched Estimation. Then use all these points to fit a smooth surface by running Spatial Spline Regression to obtain the final estimated cell phone activity in all squares.
\item \textbf{Constrained Spatial Smoothing (CSS)}: first get the initial estimation of the activity volumes of all squares by Patched Estimation, then run Constrained Spatial Smoothing algorithm to get the final activity volumes estimation of all squares.
\item \textbf{Constrained Spatial Smoothing + Features}: in this case, we incorporate the geographical features into the Constrained Spatial Smoothing algorithm.
\end{itemize}

We set the penalty parameter $\lambda = 1$ when $n_{\text{BS}} = 200$ and $\lambda = 10$ when $n_{\text{BS}} = 100$, for all methods that utilize SSR. The geographical features of Milan are only incorporated in the last algorithm described above.
% Besides, for the implementation of Spatial Spline Regression, we use the \emph{fdaPDE} R Package~\cite{fdaPDE}.
We evaluate the performance by the Mean Relative Error (MRE) of the produced activity estimates for the true activity values. 
% The relative error of an estimation $\hat{f}(\mathbf{p}_j)$ compared to the true value $f(\mathbf{p}_j)$ is defined as $|\hat{f}(\mathbf{p}_j) - f(\mathbf{p}_j)| / f(\mathbf{p}_j)$.

\subsection{Performance Evaluation}
\subsubsection{\bf Comparison of Different Algorithms}


We show the cumulative distribution function (CDF) of Relative Errors given by each approach in Fig.~\ref{fig:compareCDF100}. In addition, we compare the estimation's Mean Relative Errors of different approaches in Fig.~\ref{fig:compareMRE}. It is quite clear that our proposed algorithms outperform other three baseline approaches significantly in all the cases ($n_{\text{BS}} = 200$ and $n_{\text{BS}}=100$, data aggregated in November and in December). 

By comparing Patched Estimation + SSR 1 with Patched Estimation approach, we can see that using spatial smoothing based on only base station squares' observations leads to worse performance than patched estimation. This can be explained by the smoothing property of SSR and the way we set the values of base station squares. As we described, we set the activity values of base stations by averaging the total activity amount of each base station on all the squares it covers. Thus, given the activity $\frac{z_i}{|\Omega_{B_i}|}$ ($|\Omega_{B_i}|$ denotes the number of squares within region $\Omega_{B_i}$) of a base station $B_i$, the true activities of itself and its surrounding squares within region $B_i$ are distributed with a mean of $\frac{z_i}{|\Omega_{B_i}|}$. Given two base stations $B_1$ and $B_2$ that are close to each other, with aggregated activities of $z_1$ and $z_2$ respectively, the Spatial Smoothing approach will fit a smooth surface between the two base stations. Suppose $z_1 > z_2$, in this case, in overall the activities of $B_1$'s neighbour squares will be under estimated, and that of $B_2$ will be over estimated. Therefore, Patched Estimation + SSR 1's performance is not as good as Patched Estimation.

By comparing Patched Estimation + SSR 2 with Patched Estimation and Patched Estimation + SSR 1, we can observe that applying spatial smoothing on the results of patched estimation improves the performance. This proves the rationality and effectiveness of introducing smoothness into the estimated cell phone activity distribution surface.

Our proposed approaches achieves much better performance compared with the three baseline methods. By using Constrained Spatial Smoothing instead of applying Spatial Spline Regression directly, we are able to fit a smooth activity distribution while forcing it to match the observations of base station squares (the aggregated activity volumes) at the same time. By comparing Constrained Spatial Smoothing that incorporates additional features of each square with the version without features, we can see that the performance is further improved. The reason is that the heterogeneity of different locations will influence the telecommunication activity distribution, therefore making the distribution not everywhere smooth. Incorporating additional features into our model can help to explain the residuals between estimated smooth distribution and the true activity distribution, therefore further increases estimation accuracy.
% By comparing Fig.~\ref{fig:compareCDF200} and Fig.~\ref{fig:compareCDF100}, we also can see that incorporating additional features into Constrained Spatial Smoothing becomes more important when the base stations are more sparse.

The performance of different methods on December dataset is worse than on November dataset. The reason is that, there are multiple holidays during December, therefore the cell phone activities will be much more irregular than usual. 

% % 3d plots
% \begin{figure*}[t]
%                         \centering
%                         \subfigure[Real distribution]{
%                 \includegraphics[width=2.3in]{figures/3d_200BS_Nov_trueval.png}
%                                 \label{fig:3Dtrueval.png}
%                         }
%                 \hspace{-4mm}
%                         \subfigure[Estimation of Patched Estimation]{
%                 \includegraphics[width=2.3in]{figures/3d_200BS_Nov_baseline1.png}
%                                 \label{fig:3Dbaseline1.png}
%                         }
%                         \hspace{-4mm}
%                         \subfigure[Estimation of Constrained Spatial Smoothing + Features]{
%                 \includegraphics[width=2.3in]{figures/3d_200BS_Nov_SsrAdmm.png}
%                                 \label{fig:3DSsrAdmm.png}
%                         }
%                         \vspace{0mm}
%                 \caption{The true telecommunication activity distribution on November and the fitted surface of Patched Estimation and our method SSR + ADMM when $n_{\text{BS}} = 200$.}
%                 \label{fig:compareSurface}
% \vspace{-5mm}
% \end{figure*}








% % map and heatmap
% \begin{figure*}[t]
%                         \centering
%                         \subfigure[Map of Milan]{
%                 \includegraphics[width=1.95in]{figures/grid}
%                                 \label{fig:grid}
%                         }
%                 \hspace{-4mm}
%                         \subfigure[Activity Distribution in November]{
%                 \includegraphics[width=2.5in]{figures/heatmap_Nov_call_sms}
%                                 \label{fig:heatmapNov}
%                         }
%                         \hspace{-4mm}
%                         \subfigure[Activity Distribution in December]{
%                 \includegraphics[width=2.5in]{figures/heatmap_Dec_call_sms}
%                                 \label{fig:heatmapDec}
%                         }
%                         \vspace{0mm}
%                 \caption{ (a) shows the metropolitan area of Milan, Italy, and the area covered by the 2726 grid squares. (b) and (c) show the heat map of cell phone activities (Call + SMS) during November and December.}
%                 \label{fig:compareSurface}
% \vspace{1mm}
% \end{figure*}

% sample BS location
\begin{figure}[t]
                        \centering
                %         \subfigure[$n_{\text{BS}} = 200$]{
                % \includegraphics[width=2.2in]{figures/heatmap_200BS}
                %                 \label{fig:200BS}
                %         }
                % \hspace{-0mm}
                        \subfigure[Distribution of BSs]{
                \includegraphics[width=1.3in]{figures/heatmap_100BS}
                                \label{fig:100BS}
                        }
                \hspace{-0mm}
                        \subfigure[Areas covered by each BS]{
                \includegraphics[width=1.3in]{figures/incharge_100BS}
                                \label{fig:100BSincharge}
                        }
                        \vspace{-3mm}
                \caption{(a) The geographical distribution of sampled base stations for $n_{\text{BS}} = 100$. (b) The areas that the individual base stations are responsible for, when $n_{\text{BS}} = 100$.}
                \label{fig:BSLocations}
\vspace{-6mm}
\end{figure}












% Fig.~\ref{fig:3Dtrueval.png}, Fig.~\ref{fig:3Dbaseline1.png} and Fig.~\ref{fig:3DSsrAdmm.png} show the distribution surfaces of true cell phone activity volumes, estimated volumes by Patched Estimation, and estimated volumes by Constrained Spatial Smoothing with features when $n_{\text{BS}} = 200$ using the November dataset. We can see that the Patched Estimation approach fits a stepped surface, while our approach gives a much smoother surface.





% \subsubsection{\bf Impact of Smooth Penalty Parameter $\lambda$}

% % influence of lambda
% \begin{figure}[t]
%         %\hspace{7mm}
%         \includegraphics[width=3.4in]{figures/lambda}
%         %\vspace{-5mm}
%         \caption{Influence of $\lambda$ to estimation's Mean Relative Error when $n_{\text{BS}} = 200$ and $n_{\text{BS}}=100$ for stress-testing. The figure is based on the November dataset. Result on the December dataset is similar.}
%         \label{fig:lambda}
%         \vspace{1.5mm}
% \end{figure}

% Fig.~\ref{fig:lambda} shows how the the estimation's Mean Relative Error varies when $\lambda$ increases from $10^{-4}$ to $10^3$. We make two interesting observations. First, $\lambda$ around $1 \sim 10$ usually gives the best performance. Too big or too small $\lambda$ will decrease the estimation accuracy. This is reasonable, as when $\lambda$ is too small, we put little emphasis on the smoothness of estimated surface, thus the performance will suffer. If $\lambda$ is too big, it enforces a smooth surface, which also doesn't match the reality. 
% Second, when we have less base stations, $\lambda$ that gives the best performance will increase (from 1 to 10). Besides, we can see that the performance of the model with $\lambda$ between $1 \sim 100$ does not significantly change when $n_{\text{BS}} = 100$. That indicates the following: when the base station distribution is more sparse, the estimation performance is less sensitive to $\lambda$ when it is around the best value ($1$ for $n_{\text{BS}} = 200$ and $10$ for $n_{\text{BS}} = 100$).  
















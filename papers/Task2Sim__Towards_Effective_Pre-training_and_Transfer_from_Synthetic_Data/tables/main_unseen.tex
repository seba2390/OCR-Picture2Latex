\begin{table*}[h!]
\centering
\scalebox{1}{
  
    \begin{tabular}{l|ccc|cc}
    \Xhline{2\arrayrulewidth}
          & \multicolumn{5}{c}{\textbf{Average Downstream Accuracy --- \texttt{Unseen Tasks}}} \\
    \cline{2-6}
    & \multicolumn{3}{c|}{\textbf{100 classes / 40k images}} & \multicolumn{2}{c}{\textbf{237 classes / 100k images}} \\
    \cline{2-6}
    \multicolumn{1}{c|}{\textbf{Pretraining Dataset}} & \thead{\textbf{5NN} } & \thead{\textbf{Linear Probing}} & \thead{\textbf{Finetuning}} & \thead{\textbf{Linear Probing}} & \thead{\textbf{Finetuning}} \\
    \Xhline{2\arrayrulewidth}
    Scratch &   -    &  -     & 76.86 & -      & 76.86 \\
    Random & 51.80 & 74.68 & 83.97 & 74.11 & 83.49 \\
    Domain Randomization & 45.06 & 56.96 & 72.64 & 69.12 & 78.15 \\
    Imagenet$^*$ & \textbf{54.12} & \underline{75.47} & \underline{84.78} & \underline{81.33} & \underline{87.84} \\
    \texttt{\textbf{\ours}} & \underline{53.06} & \textbf{79.25} & \textbf{87.05} & \textbf{82.05} & \textbf{88.77} \\
\Xhline{2\arrayrulewidth}
    \end{tabular}%
} \vspace{-2mm}
  \caption{Comparing the downstream accuracy on unseen tasks for the \ours chosen pretraining dataset and other baselines. \ours also generalizes well to ``unseen'' tasks, not encountered during training, maintaining an edge over other synthetic data, while still being competitive with Imagenet. $^{*}$Imagenet subsampled as in \cref{tab:main_seen}. boldface=highest, underline=$2^{nd}$ highest in column.}
  \label{tab:main_unseen}%
  \vspace{-3mm}
\end{table*}%



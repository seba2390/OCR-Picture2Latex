% Template for ICASSP-2021 paper; to be used with:
%          spconf.sty  - ICASSP/ICIP LaTeX style file, and
%          IEEEbib.bst - IEEE bibliography style file.
% --------------------------------------------------------------------------
\documentclass{article}

\usepackage{spconf,amsmath,amssymb,graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{float}
\usepackage[skip=1pt]{caption}
\DeclareMathOperator{\E}{\mathbb{E}}
% Example definitions.
% --------------------
\def\x{{\mathbf x}}
\def\L{{\cal L}}

\usepackage{color}
\newcommand{\cco}[1]{\textcolor{cyan}{CCO: #1}}

% Title.
% ------
% \title{Identifying and Mitigating Domain Shift in baby cry neuro injury models using Unsupervised Domain Adaptation}
% \title{Identifying and Mitigating Domain Shift for baby cry neuro-injury models}
\title{Learning domain-invariant classifiers for infant cry sounds}
%
% Single address.
% ---------------
\name{ Charles C. Onu\textsuperscript{1,2,3*}, Hemanth K. Sheetha\textsuperscript{1,2*}, Arsenii Gorin\textsuperscript{1}, Doina Precup\textsuperscript{2,3}}
\address{\textsuperscript{1}Ubenwa Health\\ \textsuperscript{2}Mila-Quebec Artificial Intelligence Institute\\  \textsuperscript{3}McGill University}

%
% For example:
% ------------
%\address{School\\
%	Department\\
%	Address}
%
% Two addresses (uncomment and modify for two-address case).
% ----------------------------------------------------------
%\twoauthors
%  {A. Author-one, B. Author-two\sthanks{Thanks to XYZ agency for funding.}}
%	{School A-B\\
%	Department A-B\\
%	Address A-B}
%  {C. Author-three, D. Author-four\sthanks{The fourth author performed the work
%	while at ...}}
%	{School C-D\\
%	Department C-D\\
%	Address C-D}
% (For example: In Computer Vision, some datasets might collect more amateur photographs, others might collect more professional photographs etc.)
\begin{document}
%\ninept
%
\maketitle
%
\begin{abstract}

The issue of domain shift remains a problematic phenomenon in most real-world datasets and clinical audio is no exception. In this work, we study the nature of domain shift in a clinical database of infant cry sounds acquired across different geographies. We find that though the pitches of infant cries are similarly distributed regardless of the place of birth, other characteristics introduce peculiar biases into the data. We explore methodologies for mitigating the impact of domain shift in a model for identifying neurological injury from cry sounds. We adapt unsupervised domain adaptation methods from computer vision which learn an audio representation that is domain-invariant to hospitals and is task discriminative. We also propose a new approach, target noise injection (TNI), for unsupervised domain adaptation which requires neither labels nor training data from the target domain. Our best-performing model significantly improves target accuracy by 7.2\%, without negatively affecting the source domain.
\end{abstract}
%
\begin{keywords}
domain adaptation, dataset bias, domain shift, infant cry classification, neonatal asphyxia
\end{keywords}
%
%\ninept
\section{Introduction}
\label{sec:intro} 
\def\thefootnote{*}\footnotetext{Equal contribution}

Training a neural net for a new task can be expensive. Models typically contain hundreds of millions of parameters requiring immense compute but also large amounts of labelled data which can be costly to obtain in a clinical setting. When solving a given task, we ideally want to build a model that performs at similar accuracy when deployed in new settings or domains. In reality, it is rarely the case that distributions of source and target data are the same \cite{candela2009dataset}, typically resulting in inconsistent model performance \cite{torralba2011unbiased, yosinski2014transferable}. This bias in a dataset can be due to many factors including variations in sensors used to capture data, environmental noise, acquisition protocols, and many more. 

%Neural nets are quite good at capturing dataset bias in their internal representations, and it has been found to lead to significantly lower performance on target domain data \cite{torralba2011unbiased, yosinski2014transferable}. 

Domain adaptation (DA) aims to address the impact of dataset bias on generalization. In pursuing DA, we want to learn a cross-domain classifier that performs well in both the source and the target domain by mitigating the distributional shift. The core idea in most DA algorithms is to simultaneously or adversarially solve a classification task while learning a domain-invariant representation. This is typically achieved by minimizing a loss consisting of terms for the classification error as well as a measure of the statistical difference between the 2 distributions. Divergence measures used in the latter include mean maximum discrepancy (MMD) \cite{tzeng2014deep},  maximum mean feature norm discrepancy \cite{xu2019larger}, and correlation distance \cite{sun2016deep, sun2016return}. The H-divergence has also been employed in an adversarial objective by using a gradient reversal on a domain classifier \cite{ganin2016domain} or adversarial discriminative domain adaptation \cite{tzeng2017adversarial}. The Wasserstein distance has also proved a useful divergence in adversarial domain adaptation \cite{shen2018wasserstein}. %Dataset bias and domain adaptation have been studied extensively in classifiers built for medical images such as x-rays, CT scans and histopathology \cite{perone2019unsupervised}, \cite{pooch2020can}, \cite{stacke2019closer}. In contrast, dataset bias in medical audio is much less understood. 

\begin{figure}[b!]
\begin{minipage}[b]{0.45\textwidth}
  \centering
  \centerline{\includegraphics[width=\linewidth]{figures/da-illustration.png}}
%  \vspace{2.0cm}
\end{minipage}
\caption{In domain adaptation, we aim to build a cross-domain classifier that generalizes in a consistent fashion regardless of biases in the data samples. Image source \cite{shi2022deep}.}
\label{da-illustration}
%
\end{figure}


% Domain Identification Figure
\begin{figure*}[ht!]
\label{fig:domain-shift-id}
\begin{minipage}[b]{0.33\textwidth}
  \centering
  \centerline{\includegraphics[width=\linewidth]{figures/norm_conf_matrix.png}}
%  \vspace{2.0cm}
  \centerline{(a)}\medskip
  \label{fig:1a}
\end{minipage}
%
\begin{minipage}[b]{0.33\textwidth}
  \centering
  \centerline{\includegraphics[width=\linewidth]{figures/cross-domain-figure.png}}
%  \vspace{1.5cm}
  \centerline{(b)}\medskip
  \label{fig:1b}
\end{minipage}
\hfill
\begin{minipage}[b]{0.33\textwidth}
  \centering
  \centerline{\includegraphics[width=\linewidth]{figures/pitch.png}}
%  \vspace{1.5cm}
  \centerline{(c)}\medskip
  \label{fig:1c}
\end{minipage}
%
\caption{Identifying and understanding the nature of domain shift between source and target hospital datasets of infant crying. (a) Confusion matrix of the domain classifier indicating that model can correctly guess where a sample came from (b) Cross-hospital generalization showing that model train on source data only doesn't generalize well to target domain. (c) The distribution of cry pitch in the source and target domain suggests that dataset bias does not emanate from the cry signals.}

\label{fig:identification}
%
\end{figure*}
Here, we are interested in domain adaptation in the context of identifying signs of neurological injury from audio recordings of infant cries. Over a span of 3 years, the Ubenwa clinical study \cite{gorin2023selfsupervised} collected cry recordings across hospitals in 3 countries (Brazil, Canada, and Nigeria) for this problem. Multiple prior work have developed neuro injury detection models from cry sounds using neural transfer learning\cite{onu2020neural} and self-supervised learning\cite{gorin2023selfsupervised}. Although these methods show effectiveness on in-domain test sets, they fail to generalize as well to new hospital data.

In this work, we identify and study patterns of domain shift using this international database of infant cry recordings and explore methods for domain adaptation. We show that DA methods from computer vision can be repurposed and applied to infant cry audio. By experimenting with 5 different methods we illustrate that the best methods not only improve target accuracy but also accuracy in the source domain. Secondly, we validate previous clinical findings about the newborn cry as a universal language -- the pitch of baby cries is similarly distributed regardless of geography. We propose a relatively simple and promising approach for DA in infant cry data. Our method requires no architectural changes nor complex, min-max optimization, employs a simple cross-entropy loss function, and requires neither labels nor cry recordings from the target domain -- only target noise samples \cite{NANNI2020101084}. Experiments show that this is a promising direction worth exploring further in future work.

% Given that recordings were taken using the same device, this suggests that bias in the dataset emanates from environmental acoustics and background noise.



\begin{table*}[htbp]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{cccccccc}
    \hline
    Methods & \begin{tabular}[c]{@{}c@{}}Source \\ test AUC\end{tabular} & \begin{tabular}[c]{@{}c@{}}Target \\ test AUC\end{tabular} & Loss Function & \begin{tabular}[c]{@{}c@{}}Requires architecture \\ modification\end{tabular} & \begin{tabular}[c]{@{}c@{}}Requires cry samples \\ from target domain\end{tabular} & \begin{tabular}[c]{@{}c@{}}Target test \\ AUC improvement\end{tabular} & \begin{tabular}[c]{@{}c@{}}Source test \\ AUC improvement\end{tabular} \\ \hline
    No DA & 80.00 $\pm$ 1.9 & 72.30 $\pm$ 0.9 & - & - & - & - & - \\ \hline 
    EM & 76.00 $\pm$ 3.3 & 72.86 $\pm$ 1.8 & CE + EM & no & yes & 0.7\% & -5.3\% \\
    Unsupervised BN & 77.16 $\pm$ 1.9 & 73.04 $\pm$ 0.9 & CE & no & yes & 1.00\% & -3.55\% \\
    SAFN & 86.67 $\pm$ 1.1 & 75.85 $\pm$ 1.3 & CE + DC & yes & yes & 4.89\% & \textbf{8.33\%} \\
    HAFN & 85.47 $\pm$ 1.9 & 73.98 $\pm$ 1.9 & CE + DC & yes & yes & 2.30\% & 6.80\% \\
    SymNets & 83.54 $\pm$ 0.7 & 77.52 $\pm$ 2.1 & CE + DC + DD & yes & yes & \textbf{7.20\%} & 4.42\% \\
    TNI & 84.09 $\pm$ 0.2 & 72.94 $\pm$ 2.0 & CE & no & no (only noise) & 0.87\% & 5.1\% \\ 
    \hline
\end{tabular}
}
\caption{Performance of different unsupervised domain adaptation methods. CE=Cross Entropy, EM=Entropy Minimization, DC=Domain Confusion, DD=Domain Discrimination. Other abbreviations are as used in this paper.}
\label{tab:main-result}

\end{table*}

\section{Domain Shift Identification}
\label{sec:domain_shift_id}

In this section, we present our approach to studying the presence and patterns of domain shift in infant cry audio

\subsection{Name-the-hospital challenge}
We first ask the question: Can we build a model to identify which hospital or location a given cry recording came from? Domain shift is characterized by bias in the datasets. If such bias exists, we can build a classifier to identify which hospital a sample comes from \cite{5995347}. If it doesn't, the classifier should struggle to distinguish recordings from different hospitals. We thus train a domain classifier using the hospital as target labels. Our model was a simple convolutional neural net and the result showed that it could accurately identify the originating hospital of a cry recording (Fig \ref{fig:identification}a).

\subsection{Cross-hospital generalization}
We further conducted experiments on cross-hospital generalization. Here we train a classifier (CNN14 \cite{kong2020panns}) on the source hospital data and test it on the target. If there is no domain shift between hospitals, the model should generalize to the target domain. However, results (Fig \ref{fig:identification}b) show that the model trained on only source data performs worse than models training using (in-domain) target training data -- another sign of domain shift.

\subsection{Distribution of fundamental frequency}
\label{sec:pitch-distribution}
Thirdly, to better understand the nature of domain shift, we compare the distribution of features of data from the two domains. In the case of an infant cry, one of the most important features is pitch or fundamental frequency \cite{corwin1996infant}. It corresponds to the rate of vibration of the vocal cords during a cry expiration and defines the harmonic properties of infant cries including the formants \cite{golub1985physioacoustic}. We compare pitch distributions across the two domains as a way of isolating where bias in the dataset might be coming from. To do this, we use a cry activity detection model to segment cry sounds, then run a pitch estimator (CREPE \cite{8461329}) to obtain the pitch tracks per cry utterance. As seen in the overlapping histograms in figure \ref{fig:identification}c, pitch is similarly distributed across cry samples from the different hospitals, suggesting that the bias is coming from other factors such as background noises or acoustic properties of the recording environment. This finding is consistent with previous research showing that the newborn cry is a pure signal not altered by a baby's genes or birthplace. 

% First, we build a domain classifier that is a simple CNN model to identify the domains(source or target) of our cry audio on equal subsets of our train data and evaluate them on equal subsets of our test data.  Figure \ref{fig:identification}(a) summarizes the test results of our trained model. The Confusion Matrix of our trained model has a clearly pronounced diagonal\cite{5995347} suggesting that source and target datasets possess a unique, identifiable "signature". This indicates that there is a domain shift between our domains. 

% Next, we investigate cross-domain generalization by building a classifier for the main task - neuro injury. We train the CNN14 \cite{kong2020panns}(pre-trained on VGGSound, all layers frozen except batch norm layers and classifier) model on the source, target, and source+target dataset. Figure \ref{fig:identification}(b) shows the target test AUC comparison between all of these models. We can see that the model trained on the source dataset severely underperforms relative to models trained on target / source+target datasets in terms of Target test AUC. This further supports the conclusion that there is a domain shift between our source and target datasets

% The above methods make a strong argument that domain shift exists in our datasets. In an attempt to understand if the domain shift in our data comes from the fact that babies cry differently in different hospitals, we also compared the distribution of pitch in source and target infant cries.  Pitch for both domains is extracted with pitch estimation using torchcrepe's \cite{8461329} Full CNN model. Figure \ref{fig:identification}(c) summarizes the comparison of pitch distribution across two domains. We can see that there is almost no distribution shift in between both of these domains indicating that this is not the primary cause of the domain shift. We hypothesize that other subtle acoustic features like noise and recording environments may account for this domain shift between our domain datasets. 

\section{Learning Domain-Invariant Classifiers}
% Here, we present the different methods repurposed from computer vision to solve the problem of domain adaption for infant cry audio.

\subsection{Encoder \& Classifier Architecture}
Our model consists of a backbone encoder followed by a classifier. We adopt, as an encoder, a CNN14 \cite{kong2020panns} pre-trained on VGGSound\cite{chen2020vggsound}, a large generic audio dataset. We chose VGGSound for pre-training as it consists of sounds rather than speech which is more transferable to cry sounds. For the classifier, we add one feed-forward layer on top of the backbone encoder. Unless otherwise specified, we only tune the batch norm layers of the backbone encoder(the rest of the encoder layers are frozen) and also train the classifier from scratch as it was found to be efficient in low resource transfer learning\cite{gorin2023selfsupervised} and confirmed in our preliminary experiments.

\begin{figure*}[h]
\begin{minipage}[b]{0.5\textwidth}
  \centering
  \centerline{\includegraphics[width=\linewidth]{figures/alpha.png}}
%  \vspace{2.0cm}
    \centerline{(a)}\medskip
  \label{fig:3a}
\end{minipage}
\begin{minipage}[b]{0.5\textwidth}
  \centering
  \centerline{\includegraphics[width=\linewidth]{figures/sample_size_noise.png}}
 % \vspace{2.0cm}
  \centerline{(b)}\medskip
  \label{fig:3b}
\end{minipage}
\caption{(a) AUC in target domain for different values of $\alpha$, the weight on the target domain noise (b) AUC in target domain as the amount of target domain noise is increased}
\label{fig:noise_sample_size}
\end{figure*}

\subsection{Unsupervised Domain Adaptation Methods}

Here we introduce the different domain adaptation methods tailored to infant cry audio.\\
\\
\noindent \textbf{Unsupervised Batch Normalization(BN)}\cite{li2016revisiting} assumes a model that is pre-trained on source domain data. We freeze the whole pre-trained model and classifier (including affine params of the batch normalization layers). Fine-tuning consists of updating the running mean and variance of the corresponding batch normalization layers on unlabeled target domain data. \\

% All of the methods below consider a model that is simultaneously trained together on labeled source data and unlabelled target data. \\

\noindent \textbf{Entropy Minimization(EM)}\cite{NIPS2004_96f2b50b}\cite{zhang2018importance} is a semi-supervised learning method that simultaneously trains the model using labeled data and unlabeled data together. We optimize the following extra term along with the cross-entropy loss which tries to increase the confidence of the classifier output of target examples by minimizing the entropy:
\begin{equation}
\min_{G} \min_{C} \mathbb{E}_{\textbf{x}\sim p_t(x)}C(G(\textbf{x}))
\end{equation}
% 
% \min_{G} \min_{C} \mathbb{E}_{\textbf{x}\sim p_t(x)}C(G(\textbf{x}))
% 

\noindent where G is the backbone encoder,  C is the Classifier, and $p_t(x)$ is a distribution sampling from the target domain.\\ %The target domain data is denoted as $X_t \in  \mathbb{R}^{D \times n_t}$ which is drawn from $p_t(x)$ where D is the dimension of each target sample and $n_t$ is the number of target domain samples\\

\noindent \textbf{Adaptive Feature Norm(AFN)}\cite{xu2019larger} introduces the Maximum Mean Feature Norm Discrepancy(MMFND) metric which measures the gap between the two domain distributions. This measure helps in reducing the domain shift. The optimization objective consists of the cross-entropy loss of labeled source examples and has another loss that reduces the statistical domain gap between source and target domains using the AFN objective. In hard AFN (HAFN), a restrictive scalar R restricts the mean feature norms of our domains, while in stepwise AFN (SAFN), a step size of $\Delta r$ is introduced to encourage larger norms that are more informative and leads to better target performance.\\

% Although this gives a good statistical measure of the domain gap, it is not stable. To resolve this problem they introduce a Hard Adaptive Feature Norm(HAFN) which introduces a restrictive scalar R that restricts the mean feature norms of our domains and converges towards the shared equilibrium R which implicitly reduces the domain gap to zero. They found that as the value of R increases, the target performance also increases. Setting very large R in HAFN can lead to gradient explosion so they introduce an improved variant called the Stepwise Adaptive Feature Norm(SAFN). This method uses a step size of $\Delta r$ to encourage feature norm enlargement which promotes bigger norms that are more informative and leads to better target performance. \\
% The optimization objective consists of the cross-entropy loss of labeled source examples and has another loss that reduces the statistical domain gap between source and target domains using AFN objective(HAFN or SAFN). The feature norms are calculated from the final embeddings of our backbone encoder. We also add an L2-preserved dropout before our final classifier layer. \\
\noindent \textbf{Domain Symmetric Networks(SymNets)}\cite{zhang2019domainsymmetric} uses adversarial training to make domains invariant and tasks discriminative. While other methods only use a source domain classifier, SymNets makes use of a symmetric design that includes an explicit task classifier for the target domain in addition to the source domain classifier. The target classifier is trained to improve target predictions using source labels, making them more task discriminative. Their optimization objective comprises cross-domain training terms, two-level domain confusion losses for domain invariance, and domain discrimination and entropy minimization. 

\subsection{Target noise injection for domain adaptation}
Sequel to the insights from section \ref{sec:pitch-distribution}, we propose a relatively simple approach for domain adaptation -- target noise injection (TNI). In this method, we segment, extract, and inject target domain noise into source samples during training. The intuition is that if the environmental noise in the target hospital is the primary source of domain shift, then training the source classifier to be robust to such noise will enable the classifier to learn effective, cross-domain representations. This approach has practical benefits. Data collection only requires recording noises in the target environment -- no need for labels or actual cry recordings -- which can be much cheaper and faster to accomplish. During model training, this method requires no new loss function (cross-entropy is sufficient), no change to model architecture, and no complicated training paradigm like min-max optimization. Each audio sample, $s$ in a batch is augmented as $s' = s + \alpha n$, where n is a sample of target domain noise, and $\alpha \in [0, 1]$ is a hyperparameter.

\section{Experiments}

\subsection{Experimental setup and training details}
This study uses a subset of the Ubenwa newborn cry database collected from hospitals in Brazil, Canada, and Nigeria. Each cry recording is annotated as either healthy or neurological injury based on clinical exams conducted by doctors. We select a source hospital and a target hospital for the purposes of this work. The data is split into train, validation, and test sets making sure that all recordings from an individual patient belong to only one set. There were a total of 406 patients in the source hospital and 1,507 in the target hospital. We report the mean and standard error of AUC across 5 training runs. All models were trained using the Adam optimizer with a batch size of 32. For each method, learning rates for the backbone encoder and classifier were tuned as separate hyperparameters using the validation sets. For HAFN, R is set to 30, and for SAFN, $\Delta r$ is set to 0.2.

%The SymNets model achieved the best results with a Backbone Encoder learning rate (lr) of 5e-3 and a classifier lr of 5e-4. For the other models, we used an lr of 1e-4 for both the encoder and classifier learning rates. For HAFN, R is set to 30, and for SAFN, $\Delta r$ is set to 0.2. Hyperparameter tuning is done on the source data validation set

% \begin{table}[h]
% \begin{center}
% \begin{tabular}{cccccccc}
% \hline
% &\multicolumn{3}{c}{\textbf{Healthy}}    
% &&                           
% \multicolumn{3}{c}{\textbf{Neuro-injury}} \\\cmidrule(r){2-5}\cmidrule(l){5-8}

          
% &\textbf{train}&\textbf{val}&\textbf{test}    && \textbf{train}&\textbf{val}&\textbf{test}      \\\hline
% \textbf{Source}&172&52&132  && 14&18&18 \\
% \textbf{Target}&1251&38&90  && 84&5&39 \\
% \end{tabular}
% \end{center}
% \caption{Summary of source and target neuro-injury datasets}
% \label{dataset}
% \end{table}


\subsection{Results}
Our results for unsupervised domain adaptation (UDA) on infant cry data for classifying neurological injury are summarized in Table \ref{tab:main-result}. We see that all domain-adapted models outperform the unadapted model in the target domain. This is consistent with previous work in computer vision where these methods were found to to be effective. The biggest improvement in target AUC of 7.2\% was achieved by SymNet, while the smallest improvements were observed with entropy minimization (0.7\%) and target noise injection (0.87\%). Though TNI achieves, a relatively small improvement over the unadapted model, sample size experiments (Fig \ref{fig:noise_sample_size}b) indicate that the model is far from saturated and it improves as more target noise is collected. In Fig \ref{fig:noise_sample_size}a, we see as well that the value of $\alpha$ impacts the quality of the adaptation. Too small values would mean not enough signal to reap benefits, while too large values could degrade performance due to too much noise.

When adapting models in the clinical setting, we are interested in not only improving model performance in the target hospital but also preserving source hospital performance, such that the model remains useful across the board. We find that only 2 methods negatively impact source AUC -- entropy minimization and unsupervised BN. We suspect that, in the case of BN, this is due to its post-hoc nature i.e., the adaptation step is applied after the model has been trained as opposed to simultaneous training and adaptation.


%All models except Unsupervised BN(initially model is trained on source data and then fine-tuned on target data) are trained simultaneously with labeled source data and unlabeled target data. 

%Figure \ref{fig:results}(a) summarizes the target test AUC performance across different Unsupervised DA models. We observe that all of the methods outperform the Target test AUC of the model trained only on source data(source model). SymNets outperforms all of the methods getting close to 78\% target test AUC. SAFN also gives good improvements relative to other methods and source model. Entropy Minimization, Unsupervised Batch Norm, and HAFN gave minor improvements in target test AUC over the source model.

%Figure \ref{fig:results}(b) summarizes the Source test AUC performance across different Unsupervised DA models. Interestingly, most of them outperformed the model trained on the source dataset in terms of Source test AUC. We believe this could have happened because of two reasons: One is that our target dataset is larger than our source dataset. We believe the target dataset implicitly helped improve source performance by introducing good inductive bias. Another reason could be because of learned domain invariant features which could have implicitly improved both source and target performance as we simultaneously train on both labeled source data and unlabeled target data.

\section{Conclusion}
In this paper, we demonstrated the effectiveness of unsupervised domain adaptation methods in neuro-injury cry models. These methods were originally designed for computer vision tasks, but we show that they can be accurately repurposed for clinical audio like infant cry sounds. Through insights generated in this study, we propose a new unsupervised domain adaptation technique that requires neither training examples nor training labels in the target domain -- only noise recordings. It is practically convenient and shows promise worth exploring further in future work and with more data.

% We showed that domain shift exists in data collected from various hospitals using multiple identification methods. We demonstrated that our unsupervised domain adaptation methods not only lead to improvement in target but also source performance in a real-world scenario. We have successfully demonstrated that our approach reduces the need for labeled data by leveraging both unlabeled and pre-existing labeled data to improve our target performance. We have also shown that our best domain adaptation method is scalable and leads to better performance as we increase our dataset size.



%\section{REFERENCES}
%\label{sec:refs}



% References should be produced using the bibtex program from suitable
% BiBTeX files (here: strings, refs, manuals). The IEEEbib.bst bibliography
% style file from IEEE produces unsorted bibliography list. strings,refs}
% -------------------------------------------------------------------------
\bibliographystyle{IEEEbib}
\bibliography{main}

\end{document}
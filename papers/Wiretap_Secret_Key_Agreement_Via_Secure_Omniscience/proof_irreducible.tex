\subsection{Proof of Lemma~\ref{lem:irred}}\label{lem:proof:irred}
In this proof, we first identify an edge whose m.c.f. with the wiretapper's observations is a non-constant function. Then, by appropriately transforming the source, we separate out the m.c.f. from the random variables corresponding to the edge and the wiretapper. Later we argue that the source can be reduced by removing the m.c.f. component entirely without affecting  $\wskc$ and $\rl$. And we repeat this process until the source becomes irreducible. At each stage, to show that the reduction indeed leaves the m.c.f. related to the other edges  unchanged and makes the m.c.f. of the reduced edge a constant function, we  use  the following lemma which is proved in Appendix~\ref{lem:mcf}.
\begin{lemma}\label{lem:indgk}
 If $(\RX,\RY)$ is independent of $\RZ$, then  $\op{mcf}(\RX, (\RY,\RZ)) = \op{mcf}(\RX,\RY)$ and $\op{mcf}((\RX,\RZ), (\RY,\RZ))  = \linebreak(\op{mcf}(\RX,\RY),\RZ)$.
\end{lemma}
 


 Since $(\RZ_V, \RZ_{\opw})$ is not irreducible, there exists an edge $e \in E$ such that $\RG_e := \op{mcf}(\RY_e, \RZ_{\opw})$ is a non-constant function. By using the result that the m.c.f. of a finite linear source is a linear function~\cite{chan18zero}, we can write $\RG_e =\RY_e \MM_e  =\RZ_{\opw} \MM_{\opw}$ for some full column-rank matrices, $\MM_e$ and $\MM_{\opw}$ over $\Fq$. 

We will appropriately transform the random vector $\RY_e$. Let $\MN_e$ be any matrix with full column-rank such that $\bM \MM_e \mid  \MN_e \eM$ is invertible. Define $\tRY_e := \RY_e \MN_e$, then
\begin{align*}
  \bM \RX_{e,1},\ldots,\RX_{e,n_e}\eM \bM \MM_e \mid  \MN_e \eM &= \RY_e \bM \MM_e \mid  \MN_e \eM \\
  &=\bM \RG_e, \tRY_e \eM\\
  &= \bM \RG_{e,1},\ldots,\RG_{e,\ell}, \tRX_{e,1},\ldots,\tRX_{e,\tilde{n}_e} \eM
\end{align*}
where $\tRY_e = [\tRX_{e,1},\ldots,\tRX_{e,\tilde{n}_e}]$, $\RG_e = [\RG_{e,1},\ldots, \RG_{e,\ell}]$, $\ell$ is the length of the vector $\RG_e$ and $\tilde{n}_e = n_e -\ell$. Therefore, we can obtain $(\RG_e, \tRY_e)$ by an invertible linear transformation of $\RY_e$. Note that the components $ \RG_{e,1},\ldots,\RG_{e,\ell}, \tRX_{e,1},\ldots,\linebreak \tRX_{e,\tilde{n}_e}$ are also  i.i.d. random variables that are uniformly distributed over $\Fq$, and they are independent of $ \RY_{E \setminus \{e\}}:=(\RY_b: b \in E \setminus \{e\}))$. Hence $\RG_e$ is independent of $\tRY_e$ and $\RY_{E \setminus \{e\}}$.

Now we will express $\RZ_{\opw}$ in terms of  $\RG_e$ and $\tRY_e$.
\begin{align*}
 \RZ_{\opw} &= \RX \MW\\
 & =\RY_e\MW_e + \RY_{E \setminus \{e\}} \MW_{E \setminus \{e\}}\\
 &= \bM \RG_e & \tRY_e\eM\bM \MM_e & \MN_e \eM^{-1}\MW_e + \RY_{E \setminus \{e\}} \MW_{E \setminus \{e\}}\\
 &= \RG_e \MW^{'}_e +\tRY_e \MW^{''}_e + \RY_{E \setminus \{e\}} \MW_{E \setminus \{e\}}
\end{align*}
where the  matrices $\MW_e$ and $\MW_{E \setminus \{e\}}$ are sub-matrices  of $\MW$ formed by rows corresponding to $e$ and $E \setminus \{e\}$ respectively. Also, the matrices $\MW^{'}_e$ and $\MW^{''}_e$ are sub-matrices  of $\bM \MM_e &  \MN_e \eM^{-1}\MW_e$ formed  by first $\ell$ rows and last $\tilde{n}_e$ rows respectively. Define $\tRZ_{\opw}:=\tRY_e \MW^{''}_e + \RY_{E \setminus \{e\}} \MW_{E \setminus \{e\}}$. Since $\RZ_{\opw}= \bM\RG_e & \tRZ_{\opw}\eM\bM  \MW^{'}_e \\ \MI \eM$ and $\bM\RG_e & \tRZ_{\opw}\eM = \RZ_{\opw}\bM \MM_{\opw} & \MI -\MM_{\opw}\MW^{'}_e \eM$, $\bM \RG_e & \tRZ_{\opw} \eM$ can be obtained by an invertible linear transformation of $\RZ_{\opw}$.

Since the transformations are invertible, $\RY_e$ and $\RZ_{\opw}$ can equivalently be written as $(\RG_e, \tRY_e)$ and $(\RG_e, \tRZ_{\opw} )$ respectively. We will see that $\RG_e$ can be removed from the source without affecting $\wskc$ and $\rl$.  Let us consider a  new tree-PIN  source $\tRZ_V$, which is the same as $\RZ_V$ except that  $\tRY_e$ and $\tilde{n}_e$ are associated to the edge $e$, and the wiretapper side information is  $\tRZ_{\opw}$. Note that $(\tRZ_V, \tRZ_{\opw})$ is also a tree-PIN source with linear wiretapper, and $\RG_e$ is independent of $(\tRZ_V, \tRZ_{\opw})$.

 For the edge $e$, $\op{mcf}(\tRY_e, \tRZ_{\opw})$ is a  constant function. Suppose if it were a non-constant function $\tRG_e$ w.p. 1, which  is indeed independent of $\RG_e$, then $\op{mcf}(\RY_e, \RZ_{\opw}) = \op{mcf}((\RG_e, \tRY_e), (\RG_e,\tRZ_{\opw}))= (\RG_e, \tRG_e)$. The last equality uses Lemma~\ref{lem:indgk}. Therefore, $H(\RG_e) =H(\op{mcf}(\RY_e, \RZ_{\opw}))=H(\RG_e, \tRG_e) >  H(\RG_e)$, which is a contradiction.  Moreover $H(\RY_e|\op{mcf}(\RY_e, \RZ_{\opw}))= H(\RY_e|\RG_e) =H(\tRY_e, \RG_e|\RG_e) = H(\tRY_e)$. For the other edges $b \neq e$, $\tRY_b = \RY_b$ and $\op{mcf}(\tRY_b,\tRZ_{\opw})= \op{mcf}(\RY_b,\tRZ_{\opw})= \op{mcf}(\RY_b, (\RG_e,\tRZ_{\opw})) = \op{mcf}(\RY_b, \RZ_{\opw})$, which follows from Lemma~\ref{lem:indgk}.
 
Now we will verify that $\wskc$ and $\rl$ do not change.  First let us show that $\rl(\RZ_V\|\RZ_{\opw}) \leq \rl(\tRZ_V\|\tRZ_{\opw})$ and $\wskc(\RZ_V\| \RZ_{\opw}) \geq \wskc(\tRZ_V\|\tRZ_{\opw})$.
Let $\tRF^{(n)}$  be  an optimal communication  for $\rl(\tRZ_V\|\tRZ_{\opw})$. We can make use of $\tRF^{(n)}$ to construct an omniscience communication for the source $(\RZ_V,\RZ_{\opw})$. Set  $\RF^{(n)}= (\RG_e^n, \tRF^{(n)})$. This communication is made as follows. Both the terminals incident on the edge $e$  have $\RY_e^n$ or equivalently $(\RG_e^n, \tRY_e^n)$. One of them  communicates $\RG_e^n$. In addition, all the terminals communicate according to $\tRF^{(n)}$ because for every user $i$,  $\tRZ_i^n$ is recoverable from $\RZ_i^n$. It is easy to verify that this is an omniscience communication for $(\RZ_V,\RZ_{\opw})$.
The minimum rate of leakage for omniscience 
\begin{align*}
\rl(\RZ_V\|\RZ_{\opw})&\leq \frac{1}{n}I(\RZ_V^n\wedge  \RF^{(n)}|\RZ_{\opw}^n)\\ &= \frac{1}{n}I(\RZ_V^n\wedge  \RG_e^n, \tRF^{(n)}|\RZ_{\opw}^n)\\
&\utag{a}= \frac{1}{n}I(\tRZ_V^n,\RG_e^n\wedge  \RG_e^n, \tRF^{(n)}|\tRZ_{\opw}^n, \RG_e^n) \\ &= \frac{1}{n}I(\tRZ_V^n\wedge \tRF^{(n)}|\tRZ_{\opw}^n, \RG_e^n) \\
&\utag{b}= \frac{1}{n}I(\tRZ_V^n\wedge \tRF^{(n)}|\tRZ_{\opw}^n) \utag{c}\leq \rl(\tRZ_V\|\tRZ_{\opw}) + \delta_n,
\end{align*}
for some $\delta_n \to 0$. Here, \uref{a} is due to the fact that $(\RG_e, \tRZ_{\opw})$ is obtained by a linear invertible transformation of $\RZ_{\opw}$, \uref{b} follows from the independence of $\RG_e$ and $(\tRZ_V, \tRZ_{\opw})$, and (c) uses the fact that $\tRF^{(n)}$ is an $\rl(\tRZ_V\|\tRZ_{\opw})-$achieving communication. It shows that  $\rl(\RZ_V\|\RZ_{\opw}) \leq \rl(\tRZ_V\|\tRZ_{\opw})$. Similarly, let $(\tRF^{(n)},\tRK^{(n)})$ be a communication and key pair  which is optimal  for  $\wskc(\tRZ_V\|\tRZ_{\opw})$. By letting $(\RF^{(n)},\RK^{(n)})=( \tRF^{(n)}, \tRK^{(n)})$ for the source $(\RZ_V, \RZ_{\opw})$, we can see that the key recoverability condition is satisfied. Thus $(\RF^{(n)},\RK^{(n)})$ constitute a valid SKA scheme for $(\RZ_V, \RZ_{\opw})$ which implies that $\wskc(\RZ_V\| \RZ_{\opw}) \geq \wskc(\tRZ_V\|\tRZ_{\opw})$. 

To prove the  reverse inequalities, $\rl(\RZ_V\|\RZ_{\opw}) \geq \rl(\tRZ_V\|\tRZ_{\opw})$ and $\wskc(\RZ_V\| \RZ_{\opw}) \leq \wskc(\tRZ_V\|\tRZ_{\opw})$, we use the idea of simulating  source $(\RZ_V, \RZ_{\opw})$ from  $(\tRZ_V,\tRZ_{\opw})$. Consider the source $(\tRZ_V,\tRZ_{\opw})$ in which one of the terminals $i$ incident on the edge $e$ generates an independent randomness $\tRG_e$ that has the same distribution as $\RG_e$. Then, terminal $i$ reveals $\tRG_e$ in public, from which the other terminal $j$ incident on $e$ and the wiretapper gain access to $\tRG_e$. The two terminals $i$ and $j$ simulate $\RY_e$ from $\tRY_e$ and $\tRG_e$, whereas the other terminals' observations, besides $\tRG_e$, are the same as those of $\RZ_V$.  Hence  they can communicate according to $\RF^{(n)}$ on the simulated source $\RZ_V$.  If  $\RF^{(n)}$  achieves omniscience for $\RZ_V^n$ then so does $\tRF^{(n)}=(\tRG_e^n, \RF^{(n)})$ for $\tRZ_V^n$ . Therefore the omniscience recoverability condition is satisfied. Furthermore, if we choose $\RF^{(n)}$ to be an $\rl(\RZ_V\|\RZ_{\opw})$-achieving communication, then the minimum  rate of leakage for omniscience,
\begin{align*}
\rl(\tRZ_V\|\tRZ_{\opw})&\leq \frac{1}{n}I(\tRZ_V^n\wedge  \tRF^{(n)}|\tRZ_{\opw}^n)\\
&= \frac{1}{n}I(\tRZ_V^n\wedge  \tRG_e^n, \RF^{(n)}|\tRZ_{\opw}^n)\\
&= \frac{1}{n}I(\tRZ_V^n\wedge  \tRG_e^n|\tRZ_{\opw}^n)+\frac{1}{n}I(\tRZ_V^n\wedge  \RF^{(n)}|\tRZ_{\opw}^n,\tRG_e^n)\\
&\utag{a}= \frac{1}{n}I(\tRZ_V^n,\tRG_e^n\wedge  \RF^{(n)}|\tRZ_{\opw}^n,\tRG_e^n) \\
&\utag{b}= \frac{1}{n}I(\RZ_V^n\wedge  \RF^{(n)}|\RZ_{\opw}^n) \\
&\utag{c}\leq \rl(\RZ_V\|\RZ_{\opw})+\delta_n,
\end{align*}
for some $\delta_n \to 0$. Here, \uref{a} follows from the independence of $\tRG_e$ and $(\tRZ_V, \tRZ_{\opw})$, \uref{b} is because $(\tRG_e, \tRZ_{\opw})$ can be obtained by a linear invertible transformation of $\RZ_{\opw}$, and (c) uses the fact that $\RF^{(n)}$ is an $\rl(\RZ_V\|\RZ_{\opw})$-achieving communication.
This shows that $\rl(\RZ_V\|\RZ_{\opw}) \geq \rl(\tRZ_V\|\tRZ_{\opw})$. Similarly, if  $(\RF^{(n)}, \RK^{(n)})$ is a communication and key pair for $(\RZ_V, \RZ_{\opw})$ then terminals can communicate according to  $\tRF^{(n)}= (\tRG_e^n, \RF^{(n)})$ and agree upon the key $\tRK^{(n)}= \RK^{(n)}$, which is possible due to simulation. Hence the key recoverability is immediate. The secrecy condition is also satisfied because $ I(\tRK^{(n)}\wedge  \tRF^{(n)}, \tRZ_{\opw}^n) = I(\RK^{(n)}\wedge  \RF^{(n)}, \tRG_e^n, \tRZ_{\opw}^n) = I(\RK^{(n)}\wedge  \RF^{(n)}, \RZ_{\opw}^n) $. Hence $(\tRF^{(n)},\tRK^{(n)})$ forms a valid WSKA scheme for $(\tRZ_V, \tRZ_{\opw})$ which implies that $\wskc(\RZ_V\| \RZ_{\opw}) \geq \wskc(\tRZ_V\|\tRZ_{\opw})$.


We have shown that $\rl(\RZ_V\|\RZ_{\opw}) = \rl(\tRZ_V\|\tRZ_{\opw})$,  $\wskc(\RZ_V\| \RZ_{\opw}) = \wskc(\tRZ_V\|\tRZ_{\opw})$  and  for the edge $e$, $\op{mcf}(\tRY_e, \tRZ_{\opw})$ is a constant function and $H(\RY_e|\op{mcf}(\RY_e, \RZ_{\opw}))= H(\tRY_e)$. Furthermore, we have shown that this  reduction does not change the m.c.f. of  $\RY_b$  and  $\tRZ_{\opw}$, when $b \neq e$. If the source $(\tRZ_V, \tRZ_{\opw})$ is not irreducible, then we can apply the above reduction again on $(\tRZ_V, \tRZ_{\opw})$ without affecting $\wskc$ and $\rl$. Note that the cardinality of the set of all edges $b$ such that $\op{mcf}(\RY_b, \RZ_{\opw})$ is a non-constant function reduces by one after each reduction step. So, this process terminates after a finite number of steps at an irreducible source, which completes the proof.

\subsection{Proof of Theorem~\ref{thm:cwsk:irred}}\label{thm:proof:cwsk:irred}
\emph{Converse part.} An  upper bound on  $\wskc$  is $\skc$ because the key generation ability of the users can only increase if the wiretapper has no side information. It was shown in \cite[Example 5]{csiszar04} that if the random variables of a source form a Markov chain on a tree, then $\skc = \min_{(i,j) : \{i,j\} = \xi(e) } I(\RZ_i \wedge \RZ_j)$. In the tree-PIN case, which satisfies the Markov property, this turns out to be $\skc=\min_{e \in E} H(\RY_e)$. As a consequence, we have $\wskc \leq \min_{e \in E} H(\RY_e)$ and 
\begin{align}\label{eq:rl:conv}
\begin{split}
 \rl&\utag{a}\geq H(\RZ_V|\RZ_{\opw}) -\wskc \\ 
 &\utag{b}= \left(\sum_{e \in E}n_e -n_w\right)\log_2q -\wskc \\
 &\geq \left(\sum_{e \in E}n_e -n_w\right)\log_2q  - \min_{e \in E} H(\RY_e)
 \end{split}
\end{align}\\
where \uref{a} follows from Theorem~\ref{thm:RL:lb} and \uref{b} is due to the full column-rank assumption on $\MW$.

\emph{Achievability part.}  In this section, we will show the existence of an omniscience scheme with leakage rate $\left(\sum_{e \in E}n_e -n_w\right)\log_2q  - \min_{e \in E} H(\RY_e)$. Hence $\rl \leq \left(\sum_{e \in E}n_e -n_w\right)\log_2q  - \min_{e \in E} H(\RY_e)$,  which together with the chain of inequalities~\eqref{eq:rl:conv} imply that $\wskc = \min_{e \in E} H(\RY_e)=\skc$  and $\rl =\left(\sum_{e \in E}n_e -n_w\right)\log_2q- \skc$. In particular, for achieving a secret key of rate $\wskc = \min_{e \in E} H(\RY_e)$, the terminals use privacy amplification on the recovered source.

In fact, the existence of an omniscience scheme is shown by first constructing a template for the communication with desired properties and then showing the existence of an instance of it by a probabilistic argument. The  following are the key components involved in this construction.
\begin{enumerate}
\item \emph{Deterministic scheme:} A scheme is said to be \emph{deterministic} if  terminals are  not allowed to use any locally generated private randomness. 
 \item \emph{Perfect omniscience~\cite{sirinperfect}:} For a fixed $n \in \bb{N}$, $\RF^{(n)}$ is said to achieve \emph{perfect omniscience} if  terminals can recover the source $\RZ_V^n$ perfectly, i.e., $H(\RZ_V^n|\RF^{(n)}, \RZ_i^n) =0$ for all $i \in V$. If we do not allow any private randomness, then $H( \RF^{(n)} |  \RZ_V^n) = 0$, which implies
  \begin{align*}\label{eq:perfectomni}
  \begin{split}
   \frac{1}{n}  I(\RZ_V^n\wedge \RF^{(n)} | \RZ_{\opw}^n) &= \frac{1}{n}\left [H( \RF^{(n)} | \RZ_{\opw}^n) - H( \RF^{(n)} | \RZ_{\opw}^n, \RZ_V^n) \right] \\&= \frac{1}{n}H( \RF^{(n)} | \RZ_{\opw}^n).
  \end{split}
\end{align*} 
\item \emph{Perfect alignment:} For an $n \in \bb{N}$, we say that $\RF^{(n)}$ \emph{perfectly aligns} with $\RZ_{\opw}^n$ if $H( \RZ_{\opw}^n|\RF^{(n)} ) = 0$. Note that $\RZ_{\opw}^n$ is  recoverable from $\RF^{(n)}$ but not the other way around. In this case, $H( \RF^{(n)} | \RZ_{\opw}^n) =H( \RF^{(n)}) - H( \RZ_{\opw}^n)$. In an FLS, the wiretapper side information is $\RZ_{\opw}^n = \RX^n \MW^{(n)}$ where $\RX$ is the base vector. Suppose the communication is of the form $\RF^{(n)} = \RX^n \MF^{(n)}$, for some matrix $\MF^{(n)}$, then the condition of  perfect alignment is equivalent to the condition that the column space of $\MF^{(n)}$ contains the column space of $\MW^{(n)}$. This is in turn equivalent to the condition that the left nullspace of $\MW^{(n)}$ contains the left nullspace of $\MF^{(n)}$, i.e., if $\Ry \MF^{(n)}=\R0$ for some vector $\Ry$ then $\Ry \MW^{(n)}=\R0$.
\end{enumerate}
So we will construct a (deterministic) linear communication scheme, for some fixed $n$, achieving both perfect omniscience and perfect alignment. As a consequence,  the leakage rate for omniscience is equal to $\frac{1}{n}  I(\RZ_V^n\wedge \RF^{(n)} | \RZ_{\opw}^n) = \frac{1}{n}H( \RF^{(n)} | \RZ_{\opw}^n) = \frac{1}{n}[H( \RF^{(n)}) - H( \RZ_{\opw}^n)] = \frac{1}{n}H( \RF^{(n)}) - n_w\log_2q$. To show the desired rate, it is enough to have $\frac{1}{n}H( \RF^{(n)}) = \left(\sum_{e \in E}n_e\right) \log_2q  - \min_{e \in E} H(\RY_e) $.

We describe our construction first for the case of a PIN model on a path of length $L$, and $n_e = s$ for all edges $e \in E$. The essential ideas in this construction will serve as a road map for other, more general, cases. The construction is extended to the case of tree-PIN models, again with $n_e = s$ for all edges $e$, using the the fact that there exists a unique path from any vertex to a particular vertex designated as the root of the tree. Finally, for tree-PIN models in which $n_e$ can be different for distinct edges $e$, we give only a sketch of the proof; the technical details required to fill in the sketch can be found in \cite{treepin21arxiv}. 

% This construction has been separated into multiple cases for the ease of understanding:
% \begin{enumerate}
%    \item Path with length $L$ and $n_e=s$ for all $e \in E$,
%    \item Tree with $L$ edges and $n_e=s$ for all $e \in E$,
%    \item Path and tree with $L$ edges  and arbitrary $n_e$.
% \end{enumerate}
% We give detailed constructions only for the case $n_e=s$ for all $e \in E$. First we consider a PIN model defined on a path  graph and prove the result.  We then extend it to the tree-PIN case by using the fact that there exists a unique path from any vertex to the root of the tree. For the arbitrary $n_e$ case, we can extend the proof ideas for a slightly different communication. The technical details for these two cases can be found in \cite{treepin21arxiv}.

\subsubsection{Path of length $L$ and $n_e=s$ for all $e \in E$}
 Let $V= \{0,1,\ldots,L\}$ be the set of vertices and $E=\{1,\ldots,L\}$ be the edge set such that edge $i$ is incident on  vertices $i-1$ and $i$ (Fig.~\ref{fig:path_model}). Since $n_e =s$, $\min_{e \in E} H(\RY_e)=s \log_2q$. Fix a positive integer $n$,  such that $n > \log_q(sL)$. With $n$ i.i.d. realizations of the source, the vector corresponding to edge $i$ can be expressed as $\RY_i^{n} =[ \RX^n_{i,1} \ldots \RX^n_{i,s}]$ where $\RX^n_{i,j}$'s  can be viewed as elements in $\bb{F}_{q^n}$. Hence $\RY_i^{n} \in (\bb{F}_{q^n})^s$.  The goal is to construct a linear communication scheme $\RF^{(n)}$ that simultaneously achieves perfect omniscience and perfect alignment, such that $H( \RF^{(n)}) =n \left[ \left(\sum_{e \in E}n_e\right) \log_2q  - \min_{e \in E} H(\RY_e)\right] = n  \left(sL - s\right) \log_2q$.
 

 \begin{figure}[h]
\centering
\input{Figures/path_model}
%\captionsetup{justification=centering}
\caption{Path of length $L$.}
\label{fig:path_model}
 \end{figure}
 
 Now we will construct the  communication as follows. Leaf nodes $0$ and $L$ do not communicate. The internal node $i$ communicates $\tRF_i^{(n)} = \RY^n_{i} + \RY^n_{i+1}\MA_{i}$, where $\MA_{i}$ is an $s \times s$ matrix with elements from $\bb{F}_{q^n}$. This  communication is of the form
\begin{align*}
\RF^{(n)} & = \begin{bmatrix}
\tRF_1^{(n)} \cdots \tRF_{L-1}^{(n)}
\end{bmatrix} = \begin{bmatrix}
\RY_1^{n}\cdots \RY_L^{n}
\end{bmatrix} \underbrace{\begin{bmatrix}
\MI & \M0& \cdots  &\M0&\M0\\
\MA_1&\MI &  \cdots &\M0&\M0\\
\M0&{\MA_2} & \cdots &\M0&\M0\\
\vdots&\vdots&\ddots&\vdots&\vdots\\
 \M0 &\M0&\cdots&\MA_{L-2}&\MI  \\
\M0 &\M0&\cdots& \M0&\MA_{L-1} \\
\end{bmatrix}}_{:=\MF^{(n)}}
\end{align*}
Here $\MF^{(n)}$ is an $sL \times s(L-1) $ matrix over $\bb{F}_{q^n}$. Observe that $\rank_{\bb{F}_{q^n}}(\MF^{(n)})= s(L-1)$, which implies that $H( \RF^{(n)}) =\left(sL - s\right) \log_2q^n$ and  the dimension of the left nullspace of $\MF^{(n)}$ is $s$. Now the communication coefficients, $(\MA_i : 1\leq i\leq L-1)$, have to be chosen such that $\RF^{(n)}$ achieves both perfect omniscience and perfect alignment. Let us derive some conditions on these matrices.

For  perfect  omniscience,  it  is  sufficient  for  the $\MA_i$'s  to  be invertible. 
%Perfect omniscience  is equivalent to the condition that the $\MA_i$'s  are invertible. The necessity of the invertibility condition is immediate since if $\MA_{L-1}$ were not invertible, then vector $\RY_L^n$ is not completely recoverable from the communication by some users, for instance, user $0$. Sufficiency 
This follows from the observation that for any $i \in V$, $[\MF^{(n)} \mid \MH_i]$  is  full rank,  where $\MH_i$ is a block-column vector with an $s \times s$ identity matrix at block-index $i$ and all-zero $s \times s$ matrix at the rest of the block-indices. In other words, $(\RY_1^{n}\cdots \RY_L^{n})$ is recoverable from $(\RF^{(n)},  \RY_i^n)$ for any $i \in E$, hence achieving omniscience. 

 For perfect alignment, we require that the left nullspace of $\MF^{(n)}$ is contained in  the left nullspace of $\MW^{(n)}$, which is the wiretapper matrix corresponding to $n$ i.i.d. realizations. Note that $\MW^{(n)}$ is a $\left(\sum_{e \in E} n_e\right) \times n_w$ matrix over $\bb{F}_{q^n}$ with entries $\MW^{(n)}(k,l) = \MW(k,l) \in  \bb{F}_{q}$; since $\bb{F}_{q} \subseteq \bb{F}_{q^n}$, $\MW^{(n)}(k,l) \in \bb{F}_{q^n}$. As pointed out before, the dimension of the  left nullspace of $\MF^{(n)}$ is $s$ whereas the dimension of the left nullspace of $\MW^{(n)}$ is $sL-n_w$. Since the source is irreducible, it follows from Lemma~\ref{lem:upbdirred} in Appendix~\ref{subsec:lemmas:irreducible} that $s \leq sL-n_w$. Since the dimensions are appropriate, the left nullspace inclusion condition is not impossible. Set $\MS := [\MS_1 \; \MS_2 \; \cdots \; \MS_L]$, where  $\MS_1$  is some invertible matrix (over $\bb{F}_{q^n}$) and $\MS_{i+1} :=(-1)^{i}\MS_1\MA_{1}^{-1}\cdots \MA_{i}^{-1}$ for $1 \leq i \leq L-1$. Observe that $\MS \MF^{(n)}=\M0$. Note that the $\MS_i$'s are also invertible, and $\MA_i= -\MS_{i+1}^{-1}\MS_i$ for $1 \leq i \leq L-1$.
%  Observe that 
% \begin{align*}
% \underbrace{\begin{bmatrix}
% \MS_1 & -\MS_1\MA_1^{-1} &
% \cdots&
% (-1)^{L-1}\MS_1\MA_{1}^{-1}\ldots \MA_{L-1}^{-1}
% \end{bmatrix}}_{:=\MS} \MF^{(n)}=\M0.
% \end{align*}
% where  $\MS_1$  is some invertible matrix. We write $\MS = [\MS_1 \ldots \MS_L]$ with $\MS_{i+1} :=(-1)^{i}\MS_1\MA_{1}^{-1}\ldots \MA_{i}^{-1}$ for $1 \leq i \leq L-1$. Notice that the $\MS_i$'s are invertible. We can also express the $\MA_i$'s in terms of the $\MS_i$'s as $\MA_i= -\MS_{i+1}^{-1}\MS_i$ for $1 \leq i \leq L-1$. 
The dimension of the left nullspace of $\MF^{(n)}$ is $s$, and all the $s$ rows of $\MS$ are independent,  so these rows span the left nullspace of $\MF^{(n)}$. Therefore for the inclusion, we must have $\MS\MW^{(n)} =\M0.$

Thus, proving the existence of communication coefficients $\MA_i$'s  that achieve perfect omniscience and perfect alignment is equivalent to proving the existence of  $\MS_i$'s  that are invertible and satisfy $[\MS_1\:\cdots\: \MS_L]\MW^{(n)} =\M0$. To do this, we use the probabilistic method.  Consider the system of equations $[\Ry_1\:\cdots\:\Ry_{sL}]\MW^{(n)} =\M0$ in $sL$ variables. Since the matrix $\MW^{(n)}$ has full column rank, the solutions can be described in terms of  $m:=sL- n_w$ free variables. As a result, any $\MS$ that satisfies $\MS\MW^{(n)}=\M0$ can be parametrized by $ms$ variables. Without loss of generality, we assume that the submatrix of $\MS$ formed by the first $m$ columns has these independent variables, $(\Rs_{i,j}: 1\leq i \leq s, 1 \leq j \leq m)$. Knowing these entries will determine the rest of the entries of $\MS$.  So we choose $\Rs_{i,j}$'s independently and uniformly from $\bb{F}_{q^n}$.  We would like to know if there is any realization such that all the $\MS_i$'s are invertible, which is equivalent to the condition $\prod_{i=1}^{L} \det(\MS_i)\neq 0$. Note that $\prod_{i=1}^{L} \det(\MS_i)$ is a multivariate polynomial in the variables $\Rs_{i,j}$, $1\leq i \leq s, 1 \leq j \leq m$, with degree at most $sL$. Furthermore the polynomial is not identically zero, which follows from the irreducibility of $\MW^{(n)}$. A proof of this fact is given in  Lemma~\ref{lem:nonzeropoly} in  Appendix~\ref{subsec:lemmas:irreducible}. Therefore, applying the  Schwartz-Zippel lemma (Lemma~\ref{lem:sz} in Appendix~\ref{subsec:lemmas:irreducible}), we have
\begin{align*}
 \Pr\left\lbrace \prod_{i=1}^{L} \det(\MS_i)\neq 0\right\rbrace \geq 1- \frac{sL}{q^n} \stackrel{(a)}{>} 0 \\
\end{align*}  
where $(a)$ follows from the choice $n > \log_q(sL)$.  Since the probability is strictly positive, there exists a realization of $\MS= [\MS_1 \;  \cdots \; \MS_L]$ such that $\MS \MW^{(n)} = 0$ and the $\MS_i$'s are invertible, which in turn shows the existence of a desired $\MF^{(n)}$.

\subsubsection{Tree with $L$ edges and $n_e=s$ for all $e \in E$}
For the tree-PIN model, we essentially use the same kind of communication construction as that of the path model.  Consider a PIN model on a tree with $L+1$ nodes and $L$ edges. To describe the linear communication, fix some leaf node as the root, $\rho$, of the tree. For any internal node $i$ of the tree, let $E_i$ denote the edges incident with $i$, and in particular, let $e^*(i)\in E_i$ denote the edge incident with $i$ that is on the unique path between $i$ and $\rho$ --- see Fig.~\ref{fig:uniquepath}. Fix a positive integer $n$,  such that $n > \log_q(sL)$. The communication from an internal node $i$ is  $(  \RY^n_{e^*(i)} + \RY^n_{e}\MA_{i,e}: e \in E_i \setminus \{e^*(i)\})$, where $\MA_{i,e}$ is an $s \times s$ matrix.  Each internal node communicates $s(d_i - 1)$ symbols from $\bb{F}_{q^n}$, where $d_i$ is the degree of the node $i$. Leaf nodes do not communicate. The total number of $\bb{F}_{q^n}$-symbols communicated is $\sum_i s(d_i-1)$, where the sum is over all nodes, including leaf nodes. The contribution to the sum from leaf nodes is in fact $0$, but including all nodes in the sum allows us to evaluate the sum as $s[2 \times(\text{number of edges}) - (\text{number of nodes})] = s(L-1)$.
 Thus, we have the overall communication of the form 
\begin{align*}
 \RF^{(n)} = \RY^n \MF^{(n)} 
\end{align*}
 where $\MF^{(n)} $ is a $sL \times s(L-1)$ matrix over $\bb{F}_{q^n}$ and $\RY^n = (\RY^n_e)$. The rows of $\MF^{(n)}$  correspond to the edges  of the tree.  The aim is to  choose the matrices $\MA_{i,e}$ in a way that simultaneously achieves perfect omniscience and perfect alignment.
%  such that $H( \RF^{(n)}) =n \left[ \left(\sum_{e \in E}n_e\right) \log_2q  - \min_{e \in E} H(\RY_e)\right] = n  \left(sL - s\right) \log_2q$.  
 
For perfect omniscience,  it is sufficient for the $\MA_{i,e}$'s to be     invertible. First observe that all the leaf nodes are connected to  the root node $\rho$  via paths. On each of these paths the communication has exactly the same form as that of the path model considered before. So when the $\MA_{i,e}$'s are invertible, the root node can recover the entire source using  $\RY_{e_\rho}^n$, where $e_\rho$ is the edge incident on $\rho$. Now fix a node $i \neq \rho$.  It follows from a property of trees that there is a unique path from $\rho$ to $i$. Again the form of the communication restricted to this path is the same as that of the path model.
Therefore, if the $\MA_{i,e}$'s are invertible, then node $i$ can recover the observation, $\RY_{e_\rho}^n$, of node $\rho$, using the communication along the unique path. Since the root node is able to recover the entire source using $\RY_{e_\rho}^n$ and the overall communication, node $i$ can also recover the entire source using the recovered observation $\RY_{e_\rho}^n$ and the overall communication.  


Because $\RY^n$ is recoverable from $(\RF^{(n)},  \RY_e^n)$ for any $e \in E$, $[\MF^{(n)} \mid \MH_e]$ is an invertible $sL \times sL$ matrix, where $\MH_e$ is a block-column vector with $\MI$ at the location corresponding to edge e and zero matrices in the rest of the locations. Therefore $\MF^{(n)}$ is a full column-rank matrix, i.e., $\rank_{\bb{F}_{q^n}}(\MF^{(n)})= s(L-1)$, which implies that $H( \RF^{(n)}) =\left(sL - s\right) \log_2q^n$ and  the dimension of the left nullspace of $\MF^{(n)}$ is $s$.

For perfect alignment, we require that the left nullspace of $\MF^{(n)}$ is contained in  the left nullspace of $\MW^{(n)}$. So, let us construct an $\MS = (\MS_e)$ such that  $ \MS\MF^{(n)}=\M0$ as follows. Let $\MS_1$ be an invertible matrix. Each edge $e$ has two nodes incident with it; let $i^*(e)$ denote the node that is closer to the root $\rho$. There is a unique path $i^*(e) = i_1 \longrightarrow i_2 \longrightarrow  \cdots \longrightarrow i_{\ell} = \rho$ that connects $i^*(e)$ to $\rho$ and let the edges along the path in this order be $(e=e_1, e_2,\ldots, e_{\ell})$ --- see Fig.~\ref{fig:uniquepath}.
 \begin{figure}[h]
\centering
\resizebox{\totalheight}{!}{\input{Figures/root_internalnode}}
\caption{Unique path between an internal node $i$ and the root $\rho$}
\label{fig:uniquepath}
 \end{figure}
We set $\MS_e := (-1)^{\ell-1} \MS_1 \MA^{-1}_{i_{\ell -1}, e_{\ell-1}} \cdots \MA^{-1}_{i_{1}, e_{1}} $ for all edges $e$ except for the edge incident with $\rho$, to which we associate $\MS_1$. Note that the $\MS_e$'s are invertible and $\MS_e= - \MS_{e^{\#}}\MA^{-1}_{i^*(e), e}$, where  $e^{\#}$ is the edge adjacent to $e$ on the unique path from $i^*(e)$ to $\rho$. Let us now verify that $\MS \MF^{(n)} = \M0$. The  component corresponding to the internal node $i$ in $\MS \MF^{(n)}$ is of the form $(\MS_{e^*(i)} + \MS_{e}\MA_{i,e}: e \in E_i \setminus \{e^*(i)\})$. But for an  $e \in E_i \setminus \{e^*(i)\}$, $i^{*}(e) = i$ and $e^{\#} = e^*(i)$, thus $\MS_{e}\MA_{i,e} = - \MS_{e^{\#}}\MA^{-1}_{i^*(e), e}\MA_{i,e}= - \MS_{e^*(i)}\MA^{-1}_{i, e}\MA_{i,e} =- \MS_{e^*(i)}$. Hence we have  $\MS_{e^*(i)} + \MS_{e}\MA_{i,e}=\M0$ which implies $\MS \MF^{(n)} = \M0$.
The dimension of the left nullspace of $\MF^{(n)}$ is $s$ and all the $s$ rows of $\MS$ are independent,  so these rows span the left nullspace of $\MF^{(n)}$. Therefore, for the inclusion of one nullspace within the other, we must have $\MS\MW^{(n)} =\M0$.

Finally, we can prove the existence of an $\MS=(\MS_e)$ such that $\MS\MW^{(n)} =\M0$ and the $\MS_e$'s are invertible, using the probabilistic method exactly as before. The details are omitted.  This shows the existence of a desired $\MF^{(n)}$.

\subsubsection{Path and tree with $L$ edges  and arbitrary $n_e$}
In this case, we define $s := \min\{n_e: e \in E\}$. We consider a communication $\RF^{(n)}$ that consists of two parts. One part involves the communication that is similar to that of the $n_e =s$ case, where we use the first $s$ random variables associated to each edge $e$. And the other part involves revealing the rest of the random variables on each edge, but this is done by linearly combining them with the first $s$ rvs.

For this kind of a communication structure, we can in fact show, in a similar way as in the $n_e =s$ case, the existence of an $\MF^{(n)}$ with the desired properties. The technical details are omitted but they can be found in \cite{treepin21arxiv}.


\subsection{Proof of Lemma~\ref{lem:indgk}}\label{lem:mcf}
Recall that we assume that $\RZ$ is independent of  $(\RX,\RY)$.  Any common function (c.f.) of $\RX$ and $\RY$ is also a common function of $\RX$ and $(\RY,\RZ)$. Let $\RF$ be a c.f. of $\RX$ and $(\RY,\RZ)$ which means that $H(\RF|\RX)=0=H(\RF|\RY,\RZ)$. Note that $H(\RF|\RY)=H(\RZ|\RY)+H(\RF|\RY,\RZ)-H(\RZ|\RF,\RY)=H(\RZ)-H(\RZ|\RF,\RY)$. Also we have $H(\RZ|\RF,\RY) \geq H(\RZ|\RX,\RY)$ which follows from the  fact that $\RF$ is a function of $\RX$. Both these inequalities together imply that $0 \le H(\RF|\RY) \leq H(\RZ)-H(\RZ|\RX,\RY) =0$. So any c.f. of $\RX$ and $(\RY,\RZ)$ is also a c.f. of $\RX$ and $\RY$.  Therefore $\op{mcf}(\RX, (\RY,\RZ)) = \op{mcf}(\RX,\RY)$. 
 
 We can see that $ (\op{mcf}(\RX,\RY) ,\RZ)$ is a c.f. of $(\RX,\RZ)$ and $(\RY,\RZ)$. To show that $\op{mcf}((\RX,\RZ), (\RY,\RZ)) = (\op{mcf}(\RX,\RY), \RZ)$, it is enough to show that $H(\op{mcf}(\RX,\RY) ,\RZ) \geq H(\RG)$ for any $\RG$ satisfying $H(\RG|\RX,\RZ)=0=H(\RG|\RY,\RZ)$. Since $\sum_{\Rz \in \mc{Z}}P_{\RZ}(\Rz) H(\RG|\RX,\RZ=\Rz)=H(\RG|\RX,\RZ)=0$, for a $\Rz \in \op{supp}(P_{\RZ})$,  we have $H(\RG|\RX,\RZ=\Rz)=0$. Similarly, $H(\RG|\RY,\RZ=\Rz)=0$. Thus, for a fixed $\RZ =\Rz$, $\RG$ is a c.f.\ of rvs $\RX$ and $\RY$ jointly distributed according to $P_{\RX, \RY \mid \RZ=\Rz}$. In this case, let $\op{mcf}(\RX,\RY)_{\RZ=\Rz}$ denote the m.c.f. which indeed depends on the conditional distribution.  However, because of the independence $P_{\RX, \RY \mid \RZ=\Rz} =P_{\RX, \RY}$,  the $\op{mcf}(\RX,\RY)_{\RZ=\Rz}$ remains the same across all $\Rz$, and is equal to  $\op{mcf}(\RX,\RY)$. Therefore, from the optimality of m.c.f., we have $H(\RG |\RZ=\Rz) \leq  H(\op{mcf}(\RX,\RY)_{\RZ=\Rz} |\RZ=\Rz)=H(\op{mcf}(\RX,\RY) |\RZ=\Rz)= H(\op{mcf}(\RX,\RY))$, where the last equality follows from the independence of $\RZ$ and $(\RX,\RY)$. As a consequence, we have $H(\RG |\RZ) =\sum_{\Rz \in \mc{Z}}P_{\RZ}(\Rz) H(\RG|\RZ=\Rz)\leq H(\op{mcf}(\RX,\RY))$. The desired inequality follows from $H(\RG) \leq H(\RG,\RZ) =H(\RG |\RZ) + H(\RZ) \leq  H(\op{mcf}(\RX,\RY)) + H(\RZ) =H(\op{mcf}(\RX,\RY),\RZ)$.  This proves that $\op{mcf}((\RX,\RZ), (\RY,\RZ)) = (\op{mcf}(\RX,\RY), \RZ)$.

 \subsection{Useful Lemmas related to the proof of Theorem~\ref{thm:cwsk:irred}} \label{subsec:lemmas:irreducible}
\begin{lemma}[Schwartz-Zippel lemma]\label{lem:sz}
Let $\op{P}(\RX_1,\ldots,\RX_n)$ be a non-zero polynomial in $n$ variables with degree $d$ and coefficients from a finite field $\Fq$. Given a non-empty set $S \subseteq \Fq$, if we choose the $n$-tuple $(\RMx_1, \ldots, \RMx_n)$ uniformly from $S^n$, then
\begin{align*}
\Pr \{(\RMx_1, \ldots, \RMx_n)\in S^n: \op{P}(\RMx_1, \ldots, \RMx_n) = 0\} \leq \frac{d}{|S|}.
\end{align*}
\end{lemma}

Fix two positive integers $m$ and $s$ such that $s\leq m$. Consider the integral domain $\Fq\left[\RX_{11}, \ldots ,\RX_{1m},\ldots, \RX_{s1}, \ldots ,\RX_{sm}\right]$, which is the set of all multivariate polynomials in indeterminates $ \RX_{11}, \ldots ,\RX_{1m},\ldots, \RX_{s1}, \ldots ,\RX_{sm}$ with coefficients from a finite field $\Fq$. Let us consider a matrix of the form
\begin{align}
\MM=\begin{bmatrix}
\op{L}_1(\RY_1)&\op{L}_2(\RY_1)&\cdots &\op{L}_s(\RY_1) \\
\op{L}_1(\RY_2)&\op{L}_2(\RY_2)&\cdots &\op{L}_s(\RY_2) \\
\vdots & \vdots & \ddots & \vdots\\
\op{L}_1(\RY_s)&\op{L}_2(\RY_s)&\cdots &\op{L}_s(\RY_s)
\end{bmatrix}_{s \times s}, \label{eqn:detmatrix}
\end{align}
where $\RY_k:=[\RX_{k1}, \ldots ,\RX_{km}]$ for $1 \leq k \leq s$ and $\op{L}_{i}(\RY_k)$  denotes a linear combination over $\Fq $ of the indeterminates $ \RX_{k1}, \ldots ,\RX_{km}$. Note that row $k$ depends only on $\RY_k$.  Let  $\RX := [\RY^T_1, \ldots, \RY^T_s]^T$, and let $\op{P}(\RX)$ denote a polynomial in the indeterminates $ \RX_{11}, \ldots ,\RX_{1m},\ldots, \RX_{s1}, \ldots ,\RX_{sm}$, with coefficients from $\Fq$. 
 
It is a fact \cite[p.~528]{bourbaki1989algebra} that  for a general matrix $\MM$ with entries from $\Fq\left[\RX\right]$, $\det(\MM)=0$ if and only if  there exist polynomials $\op{P}_k (\RX)$, $1 \leq k \leq s$, not all zero,  such that
\begin{align*}
\MM \begin{bmatrix} \op{P}_1(\RX)  , \ldots ,  {\op{P}_s} (\RX) \end{bmatrix}^T= \M0.
\end{align*}
But this does not guarantee a non-zero $\lambda = [\lambda_1, \ldots, \lambda_s]  \in \Fq^s$ such that $ \MM \lambda^T= 0$.  However, the following lemma shows that if the matrix is of the form  (\ref{eqn:detmatrix}), then this is the case.


\begin{lemma} \label{lem:det}
Let $\MM$ be a matrix of the form (\ref{eqn:detmatrix}). Then  $\det(\MM)=0$ iff  there exists a  non-zero $\lambda = [\lambda_1, \ldots, \lambda_s]  \in \Fq^s$ such that $\MM \lambda^T= 0$.
\end{lemma}
\begin{proof}
The ``if" part holds for any matrix $\MM$ by the fact stated above. 
%If $\MM \lambda^T= 0$ for some non-zero $\lambda = [\lambda_1, \ldots, \lambda_s]  \in \Fq^n$, then columns are linearly dependent over $\Fq\left[X\right]$ which implies that $\det(\MM)=0$.
For the ``only if" part, suppose that $\det(\MM)=0$.  We can write $\MM$ as follows
\[\MM=\underbrace{\begin{bmatrix}
\RX_{11}&\RX_{12}&\cdots &\RX_{1m} \\
\RX_{21}&\RX_{22}&\cdots &\RX_{2m} \\
\vdots & \vdots & \ddots & \vdots\\
\RX_{s1}&\RX_{s2}&\cdots &\RX_{sm} 
\end{bmatrix}}_{=\MX}\underbrace{\begin{bmatrix}
a_{11}&a_{21}&\cdots &a_{s1} \\
a_{12}&a_{22}&\cdots &a_{s2} \\
a_{13}&a_{23}&\cdots &a_{s3} \\
\vdots & \vdots & \ddots & \vdots\\
a_{1m}&a_{2m}&\cdots &a_{sm} 
\end{bmatrix}}_{:=\MA}.\]
 for some $\MA \in \Fq^{m \times s}$.  
Now consider the determinant of the matrix $\MM$,
\begin{align*}
\det(\MM) &= \sum_{\sigma \in S_s} \sgn(\sigma )\op{L}\nolimits_{\sigma(1)}(\RY_1)\cdots \op{L}\nolimits_{\sigma(s)}(\RY_s)\\
&=\sum_{\sigma \in S_s}\sgn(\sigma ) \left( \sum_{j_1=1}^{m}a_{\sigma(1)j_1} \RX_{1j_1}\right)\cdots \left( \sum_{j_s=1}^{m}a_{\sigma(s)j_s} \RX_{sj_s}\right)\\
&= \sum_{\sigma \in S_s}\sgn(\sigma )\sum_{j_1,\dots,j_s \in [m]^s}\left(a_{\sigma(1)j_1}\cdots a_{\sigma(s)j_s}\right)\RX_{1j_1}\cdots \RX_{sj_s}\\
& = \sum_{j_1,\ldots,j_s\in [m]^s}\left(\sum_{\sigma \in S_s}\sgn(\sigma )a_{\sigma(1)j_1}\cdots a_{\sigma(s)j_s}\right)\RX_{1j_1}\cdots \RX_{sj_s}\\
&= \sum_{j_1,\ldots,j_s\in [m]^s} \det(A_{j_1\ldots j_s})\RX_{1j_1}\cdots\RX_{sj_s} 
\end{align*}
where $\MA_{j_1j_2\ldots j_s}$ is the $s\times s$ submatrix of $\MA$ formed by the rows $j_1, j_2, \dots ,j_s$. 
%$(a)$ follows from the fact that the monomials $\RX_{1j_1}\RX_{2j_2}\ldots \RX_{sj_s}$, for $j_1,j_2,\ldots,j_s\in [m]^s$, are distinct. $(b)$ holds because the inner sum is just the determinant of $\MA_{j_1j_2\ldots j_s}$. 
Since $\det(\MM)=0$, $\det(\MA_{j_1j_2\ldots j_s})= 0$ for every collection of distinct indices $j_1,j_2,\dots,j_s$, which implies that  any $s$ rows of $\MA$ are linearly dependent over $\Fq$. This shows that the rank$_{ \Fq}(\MA) < s$, therefore the columns of $\MA$ are linearly dependent over $\Fq$. Hence there exists a  non-zero $\lambda = [\lambda_1, \ldots, \lambda_s]  \in \Fq^n$ such that $ \MA\lambda^T= 0 \Rightarrow \MM\lambda ^T= 0$.
\end{proof}

\begin{definition}
 Let $\MW$ be a row-partitioned matrix of the form  
 \begin{align} \label{blockcolumn}
 \renewcommand{\arraystretch}{1.5}
 \begin{bmatrix}
 \begin{array}{c}
  \MW_1\\ \hline
  \MW_2\\ \hline
  \vdots\\ \hline
  \MW_{|E|}
  \end{array}
  \end{bmatrix}
 \end{align}
where $\MW_i$ is an $n_i \times n_w$ matrix over $\Fq$. We say that the matrix $\MW$ is \emph{reducible} if there exist an index $i$ and a non-zero row vector $r_i$ in $\Fq^{n_i}$ such that the column span of $\MW$ contains the column vector $[-0- \mid  \cdots \mid - r_i-\mid \cdots \mid -0-]^T$. If the matrix $\MW$ is not reducible then, we say it is \emph{irreducible}.
\end{definition}
A tree-PIN source with linear wiretapper is irreducible iff  the wiretapper matrix $\MW$ is irreducible.
\begin{lemma} \label{lem:upbdirred}
 Let $\MW$ be a $(\sum_{e \in E} n_e) \times  n_w$ wiretapper  matrix  in the row-partitioned form \eqref{blockcolumn}. If the matrix $\MW$ is irreducible then $n_w  \leq (\sum_{e \in E}n_e)-s$ where $s=\min\{n_e: e \in E\}$. 
\end{lemma}
\begin{proof}
 By  elementary column operations and block-row swapping, we can reduce $\MW$ into the following form
 \begin{align*}
 \renewcommand{\arraystretch}{1.5}
 \left[\begin{array}{cccc}
 \MW_{11}&\M0& \cdots&\M0\\ \hline
 \MW_{21}&\MW_{22}& \cdots &\M0\\ \hline
 \vdots&\vdots&\ddots&\vdots\\ \hline
  \MW_{k1}&\MW_{k2}& \cdots &\MW_{kk}\\ \hline
  \vdots&\vdots&\ddots&\vdots\\ \hline
  \MW_{|E|1}&\MW_{|E|2}& \cdots &\MW_{|E|k}\\
 \end{array}\right]
\end{align*}
 where the diagonal matrices $\MW_{jj}$ are full column-rank matrices. Since $\MW$ is an irreducible matrix, $k \leq (|E|-1)$. An upper bound on  the number of columns of $\MW_{jj}$ is  $n_{e_j}$, where $e_j$ is the edge corresponding to the row $j$ (after block-row swapping). So, 
 \begin{align*}
  n_w & \leq \max\biggl\{\sum_{j\in K} n_{e_j}: K \subseteq [|E|], |K| \leq (|E|-1)\biggr\} \\
  &\leq \max\biggl\{\sum_{j\in K} n_{e_j}:  |K| = (|E|-1)\biggr\}\\
  &= \max\biggl\{\sum_{e\in E} n_e - n_{e'}:  e' \in E\biggr\}\\
  &=\sum_{e\in E} n_e - s.
 \end{align*}
 This completes the proof.
\end{proof}

The next lemma is about matrices over $\Fq\left[\RX\right]$ of the form
\begin{align}
\begin{bmatrix}
\RX_{11}&\cdots &\RX_{1m} & \op{L}_1(\RY_1)&\cdots &\op{L}_{l}(\RY_1) \\
\RX_{21}&\cdots &\RX_{2m} & \op{L}_1(\RY_2)&\cdots &\op{L}_{l}(\RY_2) \\
\vdots &  \ddots & \vdots &\vdots &  \ddots & \vdots\\
\RX_{s1}&\cdots &\RX_{sm} & \op{L}_1(\RY_s)&\cdots &\op{L}_{l}(\RY_s) 
\end{bmatrix}_{s \times m+l} \label{eqn:lemma_matrix}
\end{align}
where $\op{L}_{i}(\RY_k)$  denotes a linear combination over $\Fq$ of entries of $\RY_k=[\RX_{k1}, \ldots ,\RX_{km}]$. Let us denote a matrix whose entries are the zero polynomials by $\M0$.


\begin{lemma}\label{lem:nonzeropoly}
Let $\MW$ be a $(\sum_{e \in E} n_e) \times  n_w$ wiretapper  matrix over $\Fq$ with full column-rank such that $n_w  \leq (\sum_{e \in E}n_e)-s$, where $s=\min\{n_e: e \in E\}$. Let $m := \sum_{e \in E}n_e - n_w $. Consider a  matrix $\MS:=(\MS_e, \MT_e)_{e \in E}$ over $\Fq\left[\RX\right]$ of the form \eqref{eqn:lemma_matrix}, where $\MS_e$ is an $s \times s$ matrix and $\MT_e$ is an $s \times (n_e -s)$ matrix. Furthermore, assume that $\MS$ satisfies $\MS\MW=\M0$ . If $\MW$ is an irreducible matrix, then $\prod_{e\in E} \det (\MS_e)$ is a non-zero polynomial.
   %(Polynomial in terms of the inderterminates corresponding to the free variables of $\MS$  corresponding to $\MS\MW=0$). 
\end{lemma}
\begin{proof}
 Suppose  $\prod_{e\in E} \det (\MS_e)$ is the zero polynomial; then $ \det (\MS_{e^*}) \equiv 0$ for some $i\in E$. There are $sm$ indeterminates in $\MS$, where $s\leq m$. Note that $\MS_{e^*}$ is of the form $\eqref{eqn:detmatrix}$ for some linear functions. By Lemma~\ref{lem:det}, $ \det (\MS_{e^*}) \equiv 0$ implies that there exists a non-zero $\lambda = [\lambda_1, \ldots, \lambda_s]  \in \Fq^s$ such that $ \MS_{e^*} \lambda^T= 0$.  Consider the row vector $\MR=(\MR_e)_{e \in E}$ with $\MR_{e^*} = [\lambda_1, \ldots, \lambda_s, 0,\ldots, 0]\in \Fq^{n_{e^*}}$ and  $\MR_j =[- 0 -]\in \Fq^{n_{e'}}$ for every $e' \in E \setminus \{e^*\}$. Then $ \MS \MR^T= 0$. 
 
 Moreover, it is given that $\MS$ satisfies $\MS\MW=\M0$. Now, let the $m$ indeterminates in the first row of $\MS$ take values in $\Fq$ so that we get $m$ linearly independent vectors in the left nullspace of $\MW$. These vectors are also in the left nullspace of $\MR^T$ because $\MS \MR^T= 0$. Since $\MW$ has full column-rank, this is possible only if $\MR^T$ is in the column span of $\MW$, which implies that $\MW$ is reducible.  
 
 
% Consider the matrix $\tMW = [\MW \mid \MR^T]$ which also satisfies $\MS \tMW =\M0$. One can see that $\ker(\tMW^T) \subseteq \ker(\MW^T) $. For the other direction, note that any vector in the $\ker(\MW^T)$ also belongs to $\ker(\MR)$. As a consequence $\ker(\tMW^T) = \ker(\MW^T) $, then the dimension of the column space of $\tMW$ is $\sum_{e\in E} n_e  - \dim(\ker(\tMW^T)) =\sum_{e\in E} n_e  - \dim(\ker(\MW^T)) = n_w$. Hence $\MR^T$ is in the column span of $\MW$ which implies that $\MW$ is reducible.  
\end{proof}
 
 
 %Since $\MS$ satisfies $\MS\MW = 0$, in each row of $\MS$ there are $m$ independent variables, which are indeterminates, and every other element in the row is expressed  as  a linear combination of these indeterminates. So, in total there are $sm$ indeterminates in $\MS$; without loss of generality, assume them to be in the first $m$ columns of $\MS$. 
 
 




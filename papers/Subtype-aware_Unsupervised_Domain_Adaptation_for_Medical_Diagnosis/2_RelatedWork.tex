

\section{Related Work}

In recent years, big data drives the fast development of deep learning, which has transformed many fields, such as computer vision and medical image analysis \cite{Han_2020_CVPR_Workshops,liu2019deep,liu2020symmetric}. Deep learning has drastically transformed the way in which features are extracted and then fed into a prediction model into simultaneously learning both features and a prediction model in an end-to-end fashion. The effectiveness of deep learning has been demonstrated in many computer vision tasks, such as classification, detection, and segmentation \cite{Liu_2019_ICCV,liu2020identity,liu2018dependency,liu2019permutation}. In addition, to date, conventional machine learning research in medical image analysis has relied on hand-crafted features \cite{maraci2017framework,liu2018joint,liu2017line} and expert decision rules \cite{de2018clinically}. End-to-end deep learning approaches have also shown promising performance in many disease diagnosis tasks \cite{liu2019unimodal,liu2018ordinal}. For example, \cite{litjens2019state} attempts to analyze ultrasonic data with deep learning and provides a diagnosis suggestion. 

%More researchers are turning their attention to the data analysis and identification of medical imaging data. Early attempts extracted the handcrafted features from a cardiovascular image  and fed them into the statistical classifier 

%Recently, CNN-based deep learning has gained enormous successes in image analysis tasks. Instead of designing features by hand and subsequently feeding the features to a prediction model, deep learning proposes to simultaneously learn relevant features and the prediction model from raw image data in an end-to-end fashion .


%Related studies have shown that by using deep neural networks, machines can effectively identify abnormalities from ultrasonic views \cite{liu2018ordinal}.

Compared with over one million images of the ImageNet dataset, the collection of large-scale medical data is challenging for clinical applications \cite{liu2020unimodal,liu2018data,He_2020_CVPR_Workshopsb}. To counter this, UDA has gradually become popular \cite{zou2019confidence,liu2020energy}, which aims to match covariate shift (i.e., only $p(x)$ shift). Discrepancy-based methods \cite{long2015learning}, such as minimizing MMD, address the dataset shift by mitigating specific discrepancies defined on different layers of a shared model between domains. Recently, adversarial training utilizes a discriminator to classify the domain to encourage domain confusion \cite{tzeng2017adversarial,liu2020auto3d}. These methods assume that the label proportion is invariant for all of the involved domains \cite{moreno2012unifying}. Yet, the conditional shift \cite{magliacane2018domain} (i.e., only $p(x|y)$ shift) can be more realistic than the covariate shift \cite{zhao2019learning}, and the class label shift (i.e., only $p(y)$ shift) also widely exists in the most of real-world applications \cite{kouw2018introduction}. Furthermore, the subtype-wise conditional and label shifts are a realistic assumption in many applications, which can be more challenging than the class-wise shifts, due to the unavailability of subtype labels in both source and target domains.

Recently, pseudo labels of a target domain have been widely used in UDA \cite{zou2019confidence,liu2020energy}. The pseudo labels are used to estimate target class centers \cite{chen2019progressive}, and the results are enforced to match the source class centers. Contrastive Adaptation Network \cite{kang2019contrastive} is proposed to estimate contrastive domain discrepancy with the target pseudo labels. Considering that the pseudo labels can be noisy, the Gaussian-uniform mixture model is proposed to measure the correctness \cite{gu2020spherical}. In this work, rather than using a sophisticated noisy model, we propose a noise-robust sub-graph scheme with a simple online semi-hard mining method \cite{liu2017adaptive,liu2019hard}. 

 The class-wise conditional alignment~\cite{pan2019transferrable} is also proposed by matching the source and target class centers as in \cite{chen2019progressive}. Moreover, source centers can be regarded as class protocols for classification. Although the source class-wise separation can be enforced by its CE loss \cite{liu2016large}, the center matching does not encourage the compactness of source and target samples, and can lead to sparse target distribution and considerable inner-class variation.      

The center loss \cite{wen2016discriminative} is proposed to encourage the compact distributed representation feature for face identification. Following this line of research, numerous works \cite{liu2017adaptive,liu2018adaptive,xu2020reliable,liu2019hard,liu2019dependency} adapt the center loss to metric learning and optimal transport methods. However, the underlying subtype distribution and shifts are largely ignored. Moreover, the online exploring of the subtype proposed in this work is also closely related to the unsupervised deep clustering \cite{caron2018deep}. Not limited by using $k$-means with the prior knowledge of the subtype numbers, we further propose a scalable sub-graph scheme without the need for the subtype number. Notably, the dynamic memory framework is robust to the pseudo label noise and subtype undersampling.

  


%As shown in experiments, our method can robustly utilize pseudo-labels and achieves performance improvement.

























\section{Introduction} \label{sec:intro}

The design of revenue-optimal auctions is a central problem in Economics and Computer Science, which has found myriad applications in online and offline settings, ranging from sponsored search and online advertising to selling artwork by auction houses, and public goods such as drilling rights and radio spectrum by governments. The problem involves a seller who wants to sell one or several items to one or multiple strategic bidders with private valuation functions, mapping each bundle of items they may receive to how much value they derive from the bundle. As no meaningful revenue guarantee can possibly be achieved without any information about the valuations of the bidders, the problem has been classically studied under {\em Bayesian assumptions,} where a joint distribution from which all bidders' valuations are drawn is common knowledge, and the goal is to maximize  revenue in expectation with respect to this distribution. 

In the {\em single-item setting}, Bayesian assumptions have enabled beautiful and influential developments in auction theory. Already 36 years ago, a breakthrough result by Myerson identified the optimal single-item auction when bidder values are independent~\cite{Myerson81}, and the ensuing decades saw a great deal of further understanding and practical applications of single-item auctions, importantly in online settings. 

However, the quest for optimal {\em multi-item auctions} has been quite more challenging. It has been recognized that revenue-optimal multi-item auctions can be really complex, may exhibit counter-intuitive properties, and be fragile to changes in the underlying distributions; for a discussion and examples see survey~\cite{Daskalakis15}. As such, it is doubtful that there is a crisp characterization of the structure of optimal multi-item auctions, at least not beyond single-bidder settings~\cite{DaskalakisDT17}. On the other hand, there has been significant recent progress in efficient computation of revenue-optimal auctions~\cite{ChawlaHK07,ChawlaHMS10,Alaei11,CaiD11b,AlaeiFHHM12,CaiDW12a,CaiDW12b,CaiH13,CaiDW13b,AlaeiFHHM13,BhalgatGM13,DaskalakisDW15}. Importantly, this progress has enabled identifying {\em simple auctions} (mostly variations of sequential posted pricing mechanisms) that achieve constant factor approximations to the revenue of the optimum~\cite{BabaioffILW14,Yao15,CaiDW16,ChawlaM16, CaiZ17}, under the {\em item-independence} assumption of Definition~\ref{def:subadditive independent} and Example~\ref{eg:valuation}. These auctions are {\em way simpler} than the optimum, and have {\em strong incentive properties}: they are dominant strategy truthful, while still competing against the optimal Bayesian truthful mechanism. The current state-of-the-art is given as Theorem~\ref{thm:simple XOS}, which applies to bidders with valuation functions from the broad class of fractionally subbaditive (a.k.a.~XOS) valuations, which contains submodular.

\medskip As our discussion illustrates, studying auctions assuming Bayesian priors has been quite fruitful, enabling us to identify guiding principles for how to structure auctions to achieve optimal (in single-item settings) or approximately optimal (in multi-item settings) revenue. To apply this theory to practice, however, one needs knowledge of the underlying distributions. Typically, one would estimate these distributions via market research or by observations of bidder behavior in prior auctions, then use the estimated distributions to design a good auction. However, estimation  involves approximation, and the performance of mechanisms can be quite fragile to errors in the distributions. This motivates studying whether optimal or approximately optimal auctions can be identified when one has imperfect knowledge of the true distributions.

With this motivation, recent work in Computer Science has studied whether approximately optimal mechanisms can be ``learned'' given sample access to the underlying distributions. This work has lead to an almost complete picture for the single-item (and the more general single-parameter) setting where Myerson's theory applies, showing how near-optimal mechanisms can be learned from polynomially many (in the approximation and the number of bidders) samples~\cite{Elkind07,ColeR14,MohriM14,HuangMR15,MorgensternR15,DevanurHP16,RoughgardenS16,GonczarowskiN16}. 

On the multi-item front, however, where the analogue of Myerson's theory is elusive, and unlikely, our understanding is much sparser. Recent work of Morgenstern and Roughgarden~\cite{MorgensternR16} has taken a computational learning theory approach to identify the sample complexity required to optimize over classes of simple auctions. Combined with the afore-described results on the revenue guarantees of simple auctions, their work leads to algorithms that learn approximately optimal auctions in multi-item settings with multiple unit-demand bidders, or a single subadditive bidder, from polynomially many samples in the number of items and bidders. These results apply to distributions satisfying the {\em item-independence} assumption of Definition~\ref{def:subadditive independent} and Example~\ref{eg:valuation}, under which the approximate optimality of simple auctions has been established.
 
While well-suited for identifying the sample complexity required to optimize over a class of simple mechanisms, which is a perfectly reasonable goal to have but not the one in this paper, the approach taken in~\cite{MorgensternR16} is arguably imperfect towards proving polynomial sample bounds for learning approximately optimal auctions in the settings where simple mechanisms are known to perform well in the first place. This is due to the following discordance: (i) On the one hand, simple and approximately optimal mechanisms in multi-item settings are mostly only known under item-independence. (ii) On the other hand, the computational learning techniques employed in~\cite{MorgensternR16}, and in particular bounding the {\em pseudo-dimension} of a class of auctions, are not fine enough to discern the difference in sample complexity required to optimize under item-independence and without item-independence. As such, this technique can only obtain polynomial sample bounds for approximate revenue optimization if it so happens that a class of mechanisms is both learnable from polynomially-many samples under arbitrary distributions, and it guarantees approximately optimal revenue under item-independence, or for some other interesting class of distributions.\footnote{It is known that some restriction {\em needs to be made} on the distribution to gain polynomial sample complexity, as otherwise exponential lower bounds are known for learning approximately optimal auctions even for a single unit-demand bidder~\cite{DughmiHN14}.} 

In particular, bounding the pseudo-dimension of classes of auctions as a means to prove polynomial-sample bounds for approximate revenue optimization hits a barrier even for multiple additive bidders with independent values for items. In this setting, the approximately optimal auctions that are known are the best of selling the items separately or running a VCG mechanism with entry fees~\cite{Yao15,CaiDW16}, as described in Section~\ref{sec:additive}. Unfortunately, the latter can easily be seen to have pseudo-dimension that is exponential in the number of bidders, thus only implying a sufficient exponentially large sample size to optimize over these mechanisms. Is this exponential sample size really necessary or an artifact of the approach? Recent work of Goldner and Karlin~\cite{GoldnerK16} gives us hope that it is the latter. They show how to learn approximately optimal auctions in the multi-item multi-bidder setting with additive bidders using only one sample from each bidder's distribution, assuming that it is {\em regular} and independent across items. 

\vspace{-10pt}\paragraph{Our results.} We show that simple and approximately optimal mechanisms are learnable from polynomially-many samples for multi-item multi-bidder settings, whenever:
\begin{itemize} 
\item the bidder valuations are fractionally subadditive (XOS), i.e. we can accommodate additive, unit-demand, constrained additive, and submodular valuations;
\item the distributions over valuations satisfy the standard item-independence assumption of Definition~\ref{def:subadditive independent} and Example~\ref{eg:valuation}, and their single-item marginals are arbitrary and bounded, or (have arbitrary supports but are) regular.\footnote{We note again that without the standard item-independence (or some other) restriction on the distributions, we cannot hope to learn approximately optimal auctions from sub-exponentially many samples, even for a single unit-demand bidder~\cite{DughmiHN14}.}
\end{itemize}
In particular, our results constitute vast extensions of known results on the polynomial learnability of approximately optimal auctions in multi-item settings~\cite{MorgensternR16,GoldnerK16}. Additionally we show that:
\begin{itemize}
\item whenever the valuations are additive and unit-demand, or whenever the bidders are symmetric and have XOS valuations, our approximately optimal mechanisms can be identified from polynomially many samples and in polynomial time;
\item whenever the bidders are symmetric (i.e.~their valuations are independent and identically distributed)  and have {\em subadditive valuations}, we can compute from polynomially many samples and in polynomial-time a simple mechanism whose revenue is a $\Omega\left({n \over \max\{m,n\}}\right)$-fraction of the optimum, where $m$ and $n$ are respectively the number of items and bidders. In particular, if the number of bidders is at least a constant fraction of the number of items, the mechanism is a constant factor approximation; and

\item in the setting of the previous bullet, if the item marginals are regular, our mechanism is {\em prior-independent}, i.e. there is a single mechanism, identifiable without any samples from the distributions, providing the afore-described revenue guarantee.
\end{itemize}
Finally, the mechanisms learned by our algorithms for XOS bidders are either {\em rationed sequential posted price mechanisms} (RSPMs) or {\em anonymous sequential posted price mechanisms with entry fees} (ASPEs) as defined in Section~\ref{sec:constrained additive}. The mechanisms learned for symmetric subadditive bidders are RSPMs. RSPMs maintain a price $p_{ij}$ for every bidder and item pair and, in some order over bidders $i=1,\ldots,n$, they give one opportunity to bidder $i$ to purchase {\em one} item $j$ that has not been purchased yet at price $p_{ij}$. ASPEs maintain one price $p_j$ for every item and, in some order over bidders $i=1,\ldots,n$, they give one opportunity to bidder $i$ to purchase {\em any subset} $S'$ of the items $S$ that have not been purchased yet as long as he also pays an ``entry fee'' that depends on $S$ and the identity of the bidder. See Algorithm~\ref{alg:aspe-mech}. 

\vspace{-10pt}\paragraph{Learning without Samples.} Thus far, our algorithms used {\em samples} from the valuation distributions to identify an approximately optimal and simple mechanism under item-independence. However, having sample access to the distributions may be impractical. Often we can observe the actions used by bidders in non-truthful auctions that were previously run, and use these observations to estimate the distributions over valuations using econometric methods~\cite{GuerrePV00,PaarschH06,AtheyH2007nonparametric}. In fact, it may likely be the case we have never sold all the items together in the past, and only have observations of bidder behavior in non-truthful auctions selling each item separately. Econometric methods would achieve better approximations in this case, but only for the item marginals. Finally, we may want to combine multiple sources of information about the distributions, combining past bidder behavior in several different auctions and with market research data. 

With this motivation in mind, we would like to extend our learnability results beyond the setting where sample access to the valuation distributions is provided. We propose ``learning'' approximately optimal multi-item auctions given distributions that are close to the true distributions under some distribution distance $d(\cdot,\cdot)$. In particular, given approximate distributions $\hat{D}_1,\ldots,\hat{D}_n$ over bidder valuations, we are looking to identify a mechanism $\cal M$ satisfying the following {\em max-min style objective}:
\begin{align}\forall {D_1,\ldots,D_n~\text{s.t.}~d(D_i,\hat{D}_i) \le \epsilon, \forall i}: {\rm Rev}_{\cal M}(D_1,\ldots,D_n) \ge \Omega({\rm OPT}(D_1,\ldots,D_n)) -{\rm poly}({\epsilon},m,n). \label{eq:max min goal}
\end{align}
That is, we want to find a mechanism $\cal M$ whose revenue is within a constant multiplicative and a ${\rm poly}({\epsilon},m,n)$ additive error from optimum, simultaneously in all possible worlds $D_1,\ldots,D_n$, where $d(D_i,\hat{D}_i) \le \epsilon, \forall i$. It is not a priori clear that such a ``one-fits-all'' mechanism actually exists. 

There are several notions of distance $d(\cdot,\cdot)$ between distributions that we could study in the formulation of Goal~\eqref{eq:max min goal}, but we opt for an easy one to satisfy. We only require that we know every bidder's marginal distributions over single-item values to within~$\epsilon$ in Kolmogorov distance;\footnote{{Indeed, Goal~\eqref{eq:max min goal} is achievable only for bounded distributions even in the single-item single-bidder setting. Given any bounded distribution $\hat{D}$, create $D$ by moving $\epsilon$ probability mass in $\hat{D}$ to $+\infty$. It is not hard to see that $D$ and $\hat{D}$ are within $\epsilon$ in Kolmogorov distance, but no single mechanism can satisfy the approximation guarantee for both $D$ and $\hat{D}$ simultaneously. Using a similar argument, we can argue that the additive error has to depend on $H$ which is the upper bound on any bidder's value for a single item. See Section~\ref{sec:prelim} for our formal model.}} see Definition~\ref{def:Kolm and TV}. All that this requires is that the cumulative density functions of the approximating distributions over single-item values is within $\epsilon$ in infinity norm from the corresponding cumulative density functions of the corresponding true distributions. As such, it is an easy property to satisfy. For example, given sample access to any single-item marginal, the DKW inequality~\cite{DvoretzkyKW56} implies that $O(\log(1/\delta)/\epsilon^2)$ samples suffice to learn it to within $\epsilon$ in Kolmogorov distance, with probability at least $1-\delta$. So achieving Goal~\eqref{eq:max min goal} directly also implies polynomial sample learnability of approximately optimal auctions. But a Kolmogorov approximation can also be arrived at by combining different sources of information about the single-item marginals such as the ones described above. Regardless of how the approximations were obtained, the max-min goal outlined above guarantees robustness of the revenue of the identified mechanism $\cal M$ with respect to all sources of error that came into the estimation of the single-item marginal distributions. 

While Goal~\eqref{eq:max min goal} is not a priori feasible, we show how to achieve it in multi-item multi-bidder settings with constrained additive bidders, or symmetric bidders with subadditive valuations, under the standard assumption of item-independence. Our results are polynomial-time in the same cases as our sample-based results discussed above.


%Approximation in Kolmogorov distance is easy to achieve, even for high dimensional distributions. For example, using VC techniques, one can easily argue that a distribution over $\mathbb{R}^d$ can be learned to within $\epsilon$-Kolmogorov distance from $\tilde{O}(d/\epsilon^2)$ samples. Given a distribution $\hat{D}$ such that, for all items $j$,

\vspace{-10pt}\paragraph{Roadmap and Technical Ideas.} In Section~\ref{sec:uniform convergence under product measure}, we present a new approach for obtaining uniform convergence bounds for hypotheses classes under product distributions; see Theorem~\ref{thm:uniform convergence for product measure PARTITION} and Corollary~\ref{cor:VC for product measure}. We show that our approach can significantly improve the sample complexity bound obtained via traditional methods such as VC theory. In particular, Table~\ref{tab:productVC} compares the sample complexity bounds obtained via our approach to those obtained by VC theory for different classes of hypotheses.

Our results for mechanisms make use of recent work on the revenue guarantees of simple mechanisms, which are mainly variants of sequential posted pricing mechanisms~\cite{CaiDW16,CaiZ17}. Using our results from Section~\ref{sec:uniform convergence under product measure}, in Section~\ref{sec:uniform convergence of SPEM}, we derive uniform convergence bounds for the revenue of a class of mechanisms shown to achieve a constant fraction of optimal revenue when all bidders have valuations that are constrained additive over independent items. These mechanisms are called Sequential Posted Price with Entry Fee Mechanisms, a.k.a.~SPEMs,\footnote{Note that any RSPM or ASPE is an SPEM.}. As a corollary of the uniform convergence of SPEMs, we obtain our sample based results for constrained additive bidders. In fact, we obtain a slightly stronger statement than uniform convergence of the revenue of SPEMs, which also implies our max-min results for constrained-additive bidders; see Theorems~\ref{thm:revenue stability under K-distance} and~\ref{thm:constrained additive Kolmogorov}. In particular, Theorem~\ref{thm:constrained additive Kolmogorov} and the DKW inequality imply the polynomial-sample learnability of approximately revenue-optimal auctions for constrained additive bidders.




Technically speaking, our sample based and max-min approximation results for constrained additive bidders provide a crisp illustration of how we leverage item-independence and our new uniform convergence bounds for product measures to sidestep the exponential pseudo-dimension of the class of mechanisms that we are optimizing over. Let us discuss our max-min results which are stronger. Suppose $D_i=\times_j D_{ij}$ is the true distribution over bidder $i$'s valuation and $\hat{D}_i=\times_j \hat{D}_{ij}$ is the approximating distribution, where $D_{ij}$ and $\hat{D}_{ij}$ are respectively the item $j$ marginals. To argue that the revenue of some anonymous sequential posted price with entry fees (ASPE) mechanism is similar under $D=\times_i D_i$ and $\hat{D}=\times_i \hat{D}_i$, we need to couple in total variation distance the decisions of what sets all bidders buy in the execution of the mechanism under $D$ and $\hat{D}$. The issue that we encounter is that there are exponentially many subsets each bidder may buy, hence the naive use of the Kolmogorov bound $||D_{ij}-\hat{D}_{ij}||_K \le \epsilon$, on each single-item marginal results in an exponential blow-up in the total variation distance of what subset of items bidder $i$ buys, invalidating our desired coupling. To circumvent this challenge, we argue in Lemma~\ref{lem:stable demand set} that the events corresponding to which subset of items each buyer will buy are {\em single-intersecting}, according to Definition~\ref{def:single-intersecting}, when seen as events on the buyer's single-item values. Single-intersecting events may be non-convex and have infinite VC dimension. Nevertheless, because single-item values are independent, our new uniform convergence bounds for product measures (Lemma~\ref{lem:Kolmogorov stable for sc}) imply that the difference in probabilities of any such event under $D$ and $\hat{D}$ is only a factor of $m$, the number of items, larger than the bound $\epsilon$ on the Kolmogorov distance between single-item marginals.


We specialize our results to unit-demand bidders in Section~\ref{sec:unit-demand} to obtain computationally efficient solutions for both max-min and sample-based models. Similarly, Section~\ref{sec:additive} contains our results for additive bidders. %As these settings are subsumed by those for constrained additive {and XOS} bidders we skip their proof details to the Appendix.
 We also generalize our sample-based results for constrained additive bidders to XOS bidders in Section~\ref{sec:constrained additive}.  %Our sample-based results for XOS bidders are given in Section~\ref{sec:XOS sample} with proof details postponed to the Appendix. 
 Finally, we provide computationally efficient solutions for symmetric XOS and even symmetric subadditive bidders in Section~\ref{sec:symmetric bidders}.
 These results are based on showing that (i) the right parameters of SPEMs can be efficiently and approximately identified with sample  or max-min access to the distributions; and (ii) that the revenue guarantees of simple mechanisms can be robustified to accommodate error in the setting of the parameters. In particular, our sample-based result for unit-demand bidders robustifies the ex-ante relaxation of the revenue maximization problem from~\cite{Alaei11} and its conversion to a sequential posted pricing mechanism from~\cite{ChawlaHMS10}, and makes use of the extreme-value theorem for regular distributions from~\cite{CaiD11b}. Our sample-based result for additive bidders shows how to use samples to design mechanisms that approximate the revenue of Yao's VCG with entry fees mechanism~\cite{Yao15}. Our sample-based results for  XOS bidders show how to use samples to approximate the parameters of the RSPM and ASPE mechanisms of~\cite{CaiZ17}, and argue, by re-doing their duality proofs, that their revenue guarantees are robust to errors in the approximation. Finally, our sample based result for symmetric subadditive bidders is based on a new, duality based, approximation, showing how to eliminate the use of ASPEs from the result of~\cite{CaiZ17}. This even allows us to obtain prior-independent mechanisms when the item marginals are regular.










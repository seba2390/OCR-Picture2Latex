\documentclass[1p]{elsarticle}
%\documentclass[<options>]{elsarticle}
\makeatletter
\def\ps@pprintTitle{%
 \let\@oddhead\@empty
 \let\@evenhead\@empty
 \def\@oddfoot{\centerline{\thepage}}%
 \let\@evenfoot\@oddfoot}
\makeatother
\usepackage{graphicx}
%
\usepackage{mathptmx}      % use Times fonts if available on your TeX system
\newcommand{\argmax}{\operatornamewithlimits{arg\,max}}
\usepackage{amsmath}
\usepackage{enumitem}
% \usepackage{alltt}
\usepackage{subfigure}
\usepackage{multirow}
\usepackage{url}
\usepackage{pifont}
% \usepackage{balance}
\usepackage{graphicx}
\usepackage{amsmath}
% \usepackage{array}
\usepackage{footnote}
% \usepackage[chapter]{algorithm}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{fancyvrb}

\newcommand{\tick}{\ding{52}}
\newcommand{\cross}{\ding{55}}



\def\bibsection{\section*{References}}
%
% insert here the call for the packages your document requires
%\usepackage{latexsym}
% etc.
%
% please place your own definitions here and don't use \def but
% \newcommand{}{}
%
% Insert the name of "your journal" with
% \journalname{myjournal}
%
\begin{document}

\title{Inferring Conceptual Relationships when Ranking Patients}
% \title{Insert your title here%\thanks{Grants or other notes
% %about the article that should go on the front page should be
% %placed here. General acknowledgments should be placed at the end of the article.}
% }
% \subtitle{Do you have a subtitle?\\ If so, write it here}

%\titlerunning{Short form of title}        % if too long for running head

\author[cam]{Nut Limsopatham} %etc.}
\ead{nl347@cam.ac.uk}

\author[gla]{Craig Macdonald}
\ead{craig.macdonald@glasgow.ac.uk}

\author[gla]{Iadh Ounis}
\ead{iadh.ounis@glasgow.ac.uk}

\address[cam]{Language Technology Lab, University of Cambridge, United Kingdom}
\address[gla] {School of Computing Science, University of Glasgow, United Kingdom}
%\author{No author}

%\authorrunning{Short form of author list} % if too long for running head

%\institute{Nut Limsopatham \at
%               University of Glasgow, UK.\\
%               Tel.: +44-141-330-6292\\
%               Fax: +44-141-330-4913\\
%               \email{nut.limsopatham@glasgow.ac.uk}           %  \\
%%             \emph{Present address:} of F. Author  %  if needed
%%            \and
%%            S. Author \at
%%               second address
%}
%
%\date{Received: date / Accepted: date}
% The correct dates will be entered by the editor




\begin{abstract}
% Insert your abstract here. Include keywords, PACS and mathematical
% subject classification numbers as needed.

Searching patients based on the relevance of their medical records is challenging because of the inherent implicit knowledge within the patients' medical records and queries. Such knowledge is known to the medical practitioners but may be hidden from a search system. For example, when searching for the patients with a heart disease, medical practitioners commonly know that patients who are taking the amiodarone medicine are relevant, since this drug is used to combat heart disease. In this article, we argue that leveraging such implicit knowledge improves the retrieval effectiveness, since it provides new evidence to infer the relevance of patients' medical records towards a query. Specifically, built upon existing conceptual representation for both medical records and queries, we proposed a novel expansion of queries that infers additional conceptual relationships from domain-specific resources as well as by extracting informative concepts from the top-ranked patients' medical records. We evaluate the retrieval effectiveness of our proposed approach in the context of the TREC 2011 and 2012 Medical Records track. Our results show the effectiveness of our approach to model the implicit knowledge in patient search, whereby the retrieval performance is significantly improved over both an effective conceptual representation baseline and an existing semantic query expansion baseline. In addition, we provide an analysis of the types of queries that the proposed approach is likely to be effective.
% Moreover, our proposed approach could achieve retrieval effectiveness comparable to the performance of the best TREC 2011 and 2012 systems.



%\keywords{Patient Search \and Inference \and Stochastic Analysis}
% \PACS{PACS code1 \and PACS code2 \and more}
% \subclass{MSC code1 \and MSC code2 \and more}
\end{abstract}

\maketitle

\section{Introduction}\label{intro}

\looseness-1 Electronic medical records (EMRs) detail the medical history of patients visiting healthcare providers~\cite{kotsipoulos,tambouris}. Within a patient search system, these EMRs could be exploited to identify cohorts for clinical studies~\cite{limsopatham2013oair,voorhees2011trec,voorhees2012trec}. One of the major challenges of searching in the medical domain is to deal with often complex, inconsistent and ambiguous terminology~\cite{krauthammer2004jbi,limsopatham2011sigir,trieschnigg2010cikm}. For example, it is commonly known by medical practitioners that \emph{`cancer'}, \emph{`carcinoma'}, \emph{`CA'}, and \emph{`malignant tumour'} share a similar meaning. However, such information may be hidden from traditional search systems. To handle such a challenge, prior works resorted to domain-specific resources to improve the representation of medical documents and queries. For instance, by exploiting the knowledge obtained from domain-specific resources, such as MeSH,\footnote{\url{http://www.nlm.nih.gov/mesh/}} using concept-based representation approaches, \emph{`cancer'}, \emph{`carcinoma'}, \emph{`CA'}, and \emph{`malignant tumour'} are represented with the same concept to lessen the mismatch of synonymous terms in medical documents and queries~\cite{trieschnigg2010cikm,hersh1994jamia,srinivasan1996ipma}. Moreover, synonym and hyponym relationships of medical terms obtained from domain-specific resources have been effectively exploited to reformulate queries in order to further improve retrieval performance (e.g.~\cite{aronson1997amia,srinivasan1996ipmb}). Hence, a search system could infer that patients whose medical records stated that they are suffering from \emph{`pulmonary atresia'} are relevant to a query searching for the patients suffering from \emph{`a heart disease'}, since according to MeSH, \emph{`pulmonary atresia'} is a particular form of \emph{`a heart disease'}. 

Nevertheless, the aforementioned approaches do not leverage the inherent implicit knowledge in medical records and queries, which could be exploited to improve retrieval effectiveness. For example, we can infer that a patient is suffering from a particular disease, if the patient is prescribed a medicine used specifically to treat that disease. Statistical query expansion (QE) approaches, such as pseudo-relevance feedback, indirectly deal with the implicit knowledge challenge by using occurrence statistics of terms in the top-ranked documents to improve the representation of the original query~\cite{amati2003thesis}. For example, Limsopatham et al.~\cite{limsopatham2012sigir,limsopatham2015cikm} effectively applied the Divergence from Randomness (DFR) Bo1 QE model~\cite{amati2003thesis} to improve the retrieval performance of a patient search system.
However, these QE approaches might not effectively deal with the implicit knowledge challenge, if inherently related concepts are not observed in the top-ranked records.

\looseness-1 Instead, to leverage the implicit knowledge inherent to the patient search process, in this article, we go beyond classical statistical QE techniques. 
We propose to improve the representation of medical queries by inferring the relationships of medical conditions that are extracted from the queries. In particular, we focus on medical conditions that are related to \emph{four aspects of the medical decision process (namely, symptom, diagnostic test, diagnosis, and treatment)}~\cite{Silfen2006664,limsopatham2013oair,limsopatham2013ecir-b}, as they are important information considered by healthcare practitioners when consulting with a patient.
% typically considered by a medical practitioner when dealing with a patient. In particular, we propose to initially represent medical records and queries using only concepts related to \emph{the four aspects of the medical decision criteria (namely, symptom, diagnostic test, diagnosis, and treatment)}~\cite{Silfen2006664}, as they are important information considered by healthcare practitioners when consulting with a patient. 
Next, using this conceptual representation of the medical records and queries, we propose a novel query expansion approach to further improve the query representation by exploiting two types of resources. The first type consists of external resources about the possible relationships between medical conditions (i.e.\ medical concepts). For example, we can infer that a patient suffers from a particular disease, if the patient is prescribed a medicine for that disease. To infer the relationships between medical concepts using external resources, we propose two techniques, which are based on Bayes' theorem and a stochastic analysis, respectively. On the other hand, as a second type of resource, we use the collection of patients' medical records itself. In particular, we extract the most informative concepts from the top-ranked medical records retrieved using the original query. The medical concepts inferred using these two types of resources are used to expand the original queries to improve their representations.
% 
% we deploy a novel query expansion approach to further improve the query representation by exploiting two types of resources. Firstly, we use knowledge gained from external resources to infer the relationships between concepts using the four aforementioned aspects. For example, we can infer that a patient suffers from a particular disease, if the patient takes a particular medicine. Secondly, we extract the most informative concepts from the top-ranked medical records. Importantly, the concepts inferred using these two types of resources are used to expand the original queries to improve their representation.

We evaluate our proposed approach in the context of the TREC 2011~\cite{voorhees2011trec} and 2012~\cite{voorhees2012trec} Medical Records track. Our results attest the effectiveness of our proposed approach, as it can significantly improve the retrieval performance over an existing query expansion baseline. 
% We also find that our proposed approach markedly outperforms the system that leverages only either of the two resource types. Moreover, our achieved retrieval effectiveness is comparable to the performance of the best systems at TREC 2011 and 2012~\cite{voorhees2012trec,voorhees2011trec}.

The main contributions of this paper are threefold:
\begin{enumerate}
% \item We introduce a task-specific representation approach to effectively represent medical records and queries using medical concepts based on the four aspects of medical decision criteria.  
\item We propose a novel query expansion approach that models the relationships between concepts using the four aspects of medical decision process, by leveraging medical knowledge gained from external resources and the occurrence statistics of concepts in the top-ranked medical records to improve the query representation and to infer relevance.
\item We introduce two techniques for inferring the relationships between medical concepts derived from external resources, based on Bayes' theorem and a stochastic analysis, respectively.
\item We thoroughly evaluate our proposed approach within the standard experimentation paradigm provided by the TREC 2011 and 2012 Medical Records track. 
\end{enumerate}

\looseness-1 The remainder of this paper is organised as follows. In Section~\ref{RelatedWork}, the backgrounds of searching patients based on the relevance of their medical records and related works are discussed. Section~\ref{Approach} discusses our approach for improving query representation that infers relationships between medical concepts by using information from both external resources and the informative concepts extracted from the top-ranked medical records. 
% Section~\ref{c7sRules} discusses how we derive possible relationships between medical concepts from external resources and represent them as association rules. In Section~\ref{All} and~\ref{c7sRandomWalk}, we propose two techniques based on Bayes' theorem and a stochastic analysis, respectively, to infer relationships between medical concepts from the extracted association rules. Section~\ref{c7sModel} discusses our approach to improve the representation of the query by using both medical concepts derived from the external resources using either Bayes' theorem or a stochastic analysis, and informative concepts extracted from the top-ranked medical records. 
%the medical concepts derived from the medical record collection by using a pseudo-relevance feedback approach.
% proposes our novel query expansion approach that leverages the concept\-ual relationships gained from both the external resources and occurrence statistics of concepts in the top-ranked medical records to improve retrieval performance.
Experimental setup and results are presented in Sections~\ref{c7sSetup} and~\ref{c7sResults}, respectively. Section~\ref{c7sAnalysis} provides a further analysis and discussion of the proposed approach. 
% In Section~\ref{srRelevance}, we further evaluate our proposed conceptual QE approach when combined with a term-based representation technique. 
Finally, we conclude the paper in Section~\ref{Conclusions}.

\section{Related Work}\label{RelatedWork}

Electronic medical records (EMRs), which detail the healthcare information of patients, have been developed to improve the quality of healthcare services~\cite{hersh2009bio}. For instance, EMRs could be exploited to identify treatments that have been used effectively to combat a particular disease~\cite{hersh2009bio,hersh2004jama}. However, the characteristics of medical records and queries, such as the complexity of the medical terminology, are different from those of other domains. Hence, effective search approaches for medical records are needed.
In 2011, TREC developed a search task to facilitate the research in this area~\cite{voorhees2011trec}. In particular, the task of the TREC Medical Records track~\cite{voorhees2011trec,voorhees2012trec} aims to rank patients with respect to the relevance of their medical records towards a query. 

Prior work (e.g.~\cite{gurulingappa2011trec,limsopatham2011trec,zhu2012shb}) effectively handled this search task using techniques previously developed for expert search~\cite{balog2008trec},
since the goal of both tasks is to rank people (i.e.\ patients or expert persons) based on the relevance of their associated documents. On one hand, expert search aims to rank experts based on the relevance of the documents they have written or that mention them~\cite{balog2008trec}. On the other hand, patient search uses the estimated relevance of medical records, when ranking their associated patients. Hence, in this work, we also handle patient search using well-establ\-i\-s\-hed approaches previously developed for expert search, 
which use ranked medical records to rank patients (e.g.\ Voting Model~\cite{macdonald2006cikm} and Model~2~\cite{balog2006sigir}). Specifically, the Voting Model ranks patients using a voting process, where the ranking of medical records (denoted $R(Q)$) defines the relevance scores for the patients to be retrieved. Each retrieved medical records in $R(Q)$ is said to vote for the relevance of its associated candidate patient using voting techniques such as, CombMAX, CombSUM, expCombSUM. Indeed, each voting technique firstly ranks medical records based on their relevance towards a query using a traditional weighting model (e.g.\ BM25~\cite{robertson1994sigir}, DFR DPH~\cite{amati2007trec}), and then aggregates the votes from the medical records to their associated patients, to create a ranked list of likely relevant patients for the query~\cite{macdonald2006cikm}. 

One of the important research areas of searching in the medical domain is dealing with
the complexity, ambiguity and inconsistency of the medical terminology~\cite{krauthammer2004jbi,limsopatham2011sigir,trieschnigg2010cikm}. For example, when referring to \emph{`coronary heart disease'}, different medical practitioners may use terms, such as \emph{`coronary artery disease'}, \emph{`arteriosclerotic heart disease'}, \emph{`CHD'}, or \emph{`CAD'}. Previous work has leveraged domain-specific resources to handle such a challenge~\cite{krauthammer2004jbi,limsopatham2011sigir,trieschnigg2010cikm}. For instance, Srinivasan~\cite{srinivasan1996ipma} and Trieschnigg et al.~\cite{trieschnigg2010cikm} represented medical documents and queries using medical concepts obtained from domain-specific resources, such as MeSH, to alleviate the synonymous mismatch of terms in medical documents and queries. Aronson~\cite{aronson1994riao} deployed MetaMap~\cite{aronson2010jamia} -- a medical concept recognition tool based on the UMLS Metathesaurus\footnote{\url{http://www.nlm.nih.gov/research/umls/}} -- to identify all concept, in the medical documents and queries, and to represent them in the form of the UMLS Concept Unique Identifier (CUI). 
However, conceptual representation approaches are effective only when combined with a traditional term-based representation~\cite{trieschnigg2010cikm,srinivasan1996ipma}.
Koopman et al.~\cite{koopman2012adcs} proposed a graph-based approach for weighting patients based on the occurrences of medical concepts in their medical records. They built a graph model based on the co-occurrences of medical concepts within a particular window of concepts, and calculated the PageRank~\cite{brin1998} scores for each medical concepts. Then, during retrieval, they scored patients based on the PageRank scores of the query concepts that matched their medical records. Later, Limsopatham et al.~\cite{limsopatham2013oair} proposed a task-specific representation approach, which represented medical records and queries by using only concepts that are related to four aspects of the medical decision process (namely, symptom, diagnostic test, diagnosis and treatment)~\cite{Silfen2006664}, as they are essential information for health practitioners when dealing with a patient. 
Note that these aspects can be viewed as the criteria aspects that the medical records of relevant patients should cover as suggested in~\cite{koopman2014sigir,limsopatham2014cikm}. 
In this work, we follow~\cite{limsopatham2013oair} when representing medical records and queries. In particular, we deploy MetaMap to extract concepts, in medical records and queries, and represent the identified concepts in the form of the UMLS Concept Unique Identifier (CUI). Importantly, we identify concepts related to the four aforementioned aspects based on their MetaMap's semantic type.\footnote{\url{http://metamap.nlm.nih.gov/SemanticTypeMappings_2011AA.txt}} In Table~\ref{tab:CU}, we list the 16 MetaMap's semantic types that are associated to the medical decision process~\cite{limsopatham2013ecir-b}. Medical concepts with the MetaMap's semantic type defined in the first column are associated to an aspect of the medical decision process, if there is a tick (\tick) in the column of that aspect. For example, concepts having the MetaMap's semantic type \emph{Disease or Syndrome} are associated with the \emph{diagnosis} aspect.
Figure~\ref{fig:c5metamap} shows an example of using the MetaMap tool to extract medical concepts from the query ``Patients with diabetes mellitus who also have thrombocytosis'', where 
%`C0011849' and `C0836924' are the CUIs extracted from the query with the highest confidence (identified as \emph{Meta Mapping} concepts by MetaMap in Figure~\ref{fig:c5metamap}), and shown in Table~\ref{tab:c5CUIs}. Note that, 
%we use the medical concepts identified with any level of confidence. For example, instead of using only medical concepts with the highest confidence (as shown in Table~\ref{tab:c5CUIs}), we can use all of the extracted medical concepts regardless of their confidence levels. With this variant, 
we can extract four different CUIs, including `C0011849', `C0011847', `C0241863' and `C0836924', from. Nevertheless, even though this approach could effectively represent medical concepts mentioned in documents and queries, related medical concepts that are not explicitly mentioned may not be inferred and uncovered.

\begin{figure}[tb]
% \vspace{-3mm}
% \begin{tabular}{|c|}
% \small
% \scriptsize
\centering
% \begin{minipage}{3in}
\begin{Verbatim}[frame=single]
Input: "Patients with diabetes mellitus who also 
	have thrombocytosis"

Phrase: "Patients"

Phrase: "with diabetes mellitus"
Meta Candidates (4):
  1000 C0011849:Diabetes Mellitus [Disease or Syndrome]
          Diabetes
   861 C0011847:Diabetes [Disease or Syndrome]
   789 C0241863:DIABETIC [Finding]
Meta Mapping (1000):
  1000 C0011849:Diabetes Mellitus [Disease or Syndrome]

Phrase: "who also"

Phrase: "have"

Phrase: "thrombocytosis."
Meta Candidates (1):
  1000 C0836924:Thrombocytosis [Disease or Syndrome]
Meta Mapping (1000):
  1000 C0836924:Thrombocytosis [Disease or Syndrome]
\end{Verbatim}
% \end{minipage}
% \hline
% \end{tabular}
% \vspace{-5mm}
\caption{Medical concepts extracted by the MetaMap tool from the query `Patients with diabetes mellitus who also have thrombocytosis'}\label{fig:c5metamap}
% \vspace{-2mm}
\end{figure}


% Our work differs from these previous approaches, in that to alleviate the challenge of the complex, ambiguous and inconsistent terminology, we propose to represent medical records and queries by using only concepts that are related to \emph{the four aspects of the medical decision criteria}~\cite{Silfen2006664}, as they are essential information for health practitioners when dealing with a patient.

On the other hand, query expansion (QE) techniques, such as pseudo-relevance feedback, have been used to effectively improve the representation of queries in different search tasks~\cite{aronson1997amia,srinivasan1996ipmb,amati2003thesis}. 
In the form of QE, synonyms and hyponyms of concepts in the medical documents and queries have been used to improve the representation of medical queries
~\cite{aronson1997amia,martinez2014,srinivasan1996ipmb,zuccon2012}. For example, Aronson and Rindflesch~\cite{aronson1997amia}, and Srinivasan~\cite{srinivasan1996ipmb} effectively expanded concepts in a query with their synonyms and hyponyms obtained from domain-specific resources, such as MeSH and UMLS Metathesaurus. In the context of patient search, King et al.~\cite{king2011trec} effectively deployed the UMLS Metathesaurus and their collection of medical reference encyclopedias in their query expansion technique. In particular, they simply added the derived medical concepts to the query and set the weights equally for all the medical concepts. Zuccon et al.~\cite{zuccon2012} investigated into exploiting hierarchical structure of SNOMED-CT ontology\footnote{\url{https://www.nlm.nih.gov/snomed/}} to extract expansion concepts and several techniques (e.g. tf-idf) for calculating weights of the expansion concepts. However, they found a limited performance improvement. Recently, Martinez et al.~\cite{martinez2014} achieved significant improvement when applied PageRank random walks on the UMLS Metathesaurus to extract expansion concepts and their weight. However, a limitation is that some types of relationships between medical concepts (e.g.\ the relationships between diagnosis and treatment) may not be directly presented in the UMLS Metathesaurus.
% Later, a technique called \emph{concept-based retrieval} was proposed to semantically handle the challenge~\cite{stokes2009ir,zhong2006sigir,zhou2008cikm}. It identifies medical concepts in the query and exploits domain-specific resources to expand the query with its associated terms, while ranking.
Meanwhile, pseudo-relevance feedback is to expand a query with \emph{a set of informative terms} obtained from the top-ranked documents. In the context of searching the medical domain, Srinivasan~\cite{srinivasan1996ipmb} and Limsopatham et al.~\cite{limsopatham2012sigir} reported that pseudo-relevance feedback could effectively improve retrieval performance. In particular, pseudo-relevance feedback can indirectly deal with the implicit knowledge, since it may expand the query with semantically-related concepts. For example, for a query searching for \emph{``patients with heart disease"}, the expanded terms might be \emph{`amiodarone'} and \emph{`angina'}, which are a treatment and a symptom associated to \emph{`heart disease'}. Importantly, in medical records such relationships between concepts related to the aspects of the medical decision process are strongly established. On the other hand, from a medical record of a patient taking \emph{`amiodarone'} medicine (treatment), healthcare practitioners can infer that the patient is suffering from \emph{`heart disease'} (diagnosis), since according to the indication \emph{`amiodarone'} is used to combat \emph{`heart disease'}. However, pseudo-relevance feedback may not always be able to leverage such implicit knowledge, if the associated concepts do not appear in the top-ranked medical records. Hence, in this work, we propose to also directly infer these relationships to improve the query representation. Specifically, we propose a new QE approach that uses conceptual relationships extracted from both external resources and the top-ranked medical records to improve retrieval effectiveness.

% \section{Inferring Conceptual Relationships}\label{All}
% \looseness-1 In this section, we propose our approach to infer medical conceptual relationships in order to improve the representation of medical queries, and hence enhance retrieval performance. In particular, in Section~\ref{Task-Specific}, we first discuss our task-specific representation approach to represent medical records and queries in the forms of concepts. Section~\ref{QueryReformulation} introduces our query expansion approach that models the relationships between concepts associated to the aspects of the medical decision criteria using external resources. Finally, Section~\ref{LocalQueryExpansion} discusses how the occurrence statistics of concepts in the top-ranked medical records are used to infer conceptual relationships within our query expansion approach.
% 
% \subsection{Task-Specific Representation}\label{Task-Specific}
% \looseness-1 We first introduce our task-specific representation approach.  
% While traditional concept-based representation approaches (e.g.~\cite{hersh1994jamia,srinivasan1996ipma}) represent medical records and queries using all identified medical concepts,
% we propose to represent them
% by focusing only on concepts related to the four aspects of the \emph{medical decision criteria} (namely, symptoms, diagnostic tests, diagnoses, and treatments), which are derived from the medical decision making process described by Silfen et al.~\cite{Silfen2006664}. Indeed, these criteria are considered by medical practitioners when dealing with a patient, including problems (symptoms and diagnoses), diagnostic procedures (diagnostic tests), and management options (treatments). For example, knowing that a patient visiting a hospital with \emph{`chest pain'} (symptom), a healthcare practitioner may suspect that the patient has \emph{`heart disease'} (diagnosis). Hence, given the symptom, the practitioner compiles a set of diagnostic procedures, such as \emph{`chest X-ray'} (diagnostic test) for the patient. Once the practitioner is confident that the patient suffers from \emph{`heart disease'} (diagnosis), the practitioner may prescribe a treatment, such as \emph{`coronary artery bypass surgery'}, for the patient.
% We hypothesise that these inferences can be effectively used to identify medical records relevant to a query. We deploy MetaMap~\cite{aronson2010jamia} to extract concepts, in medical records and queries, and represent the identified concepts in the form of the UMLS Concept Unique Identifier (CUI). Importantly, we use only the concepts related to the four aforementioned aspects, which we identify based on their MetaMap's semantic type.\footnote{\url{http://metamap.nlm.nih.gov/SemanticTypeMappings_2011AA.txt}} In Table~\ref{tab:CU}, we list the 16 MetaMap's semantic types that are associated to the medical decision criteria. Medical concepts with the MetaMap's semantic type defined in the first column are associated to an aspect of the medical decision criteria, if there is a tick (\tick) in the column of that aspect. For example, concepts having the MetaMap's semantic type \emph{Disease or Syndrome} are associated with the \emph{diagnosis} aspect. Table~\ref{tab:CUIs} shows the concepts obtained from the query \emph{``patients with diabetes mellitus who also have thrombocytosis"}, using our task-specific representation approach. Indeed, our approach identifies two diagnosis concepts: \emph{`diabetes mellitus' (C0011849)} and \emph{`thrombocytosis' (C0836924)}, from the query.
% 
\begin{table*}[tb]%[thbp!]
  \caption{\looseness-1  List of 16 of the MetaMap's 133 semantic types that we consider for our proposed approach, based on the four aspects of the medical decision process.}
  \label{tab:CU}
  \centering 
%\small
\resizebox{1.0\textwidth}{!}{
\begin{tabular}{|l|c|c|c|c|}
\hline
\multirow{2}{*}{MetaMap's Semantic Type} & \multicolumn{4}{c|}{Aspects of the Medical Decision Process}\\ \cline{2-5}
& Symptom & Diagnostic test & Diagnosis & Treatment \\
\hline
Body Location or Region & \tick & \tick & \tick & \tick \\
Body Part, Organ, or Organ Component  & \tick & \tick & \tick & \tick \\
Clinical Drug & -- & -- & -- & \tick \\
Diagnostic Procedure& -- & \tick & -- & --\\
Disease or Syndrome&  -- & -- & \tick & --\\
Finding & \tick & -- & -- & --\\ 
Health Care Activity&  -- & \tick & -- & \tick \\
Injury or Poisoning& \tick & -- & -- & --\\
Intellectual Product& -- & \tick & -- & \tick \\
Medical Device & -- & \tick & -- & \tick \\
Mental or Behavioral Dysfunction & \tick & -- & \tick & --\\
Neoplastic Process& \tick & \tick & \tick & \tick \\
Pathologic Function& \tick & -- & -- & --\\
Pharmacologic Substance & -- & -- & -- & \tick \\
Sign or Symptom& \tick & -- & -- & --\\
Therapeutic or Preventive Procedure & -- & -- & -- & \tick \\
\hline
\end{tabular}
}
\end{table*}
% 
% 
% \begin{table}[thbp]
% \centering 
% \resizebox{8.7cm}{!}{
% \small
% \begin{tabular}{|l|l|l|}
%  \hline
% Concept (CUI) & MetaMap's Definition & Related Aspects\\ \hline
% C0011849 & Diabetes Mellitus [Disease or Syndrome] & Diagnosis\\
% C0836924 & Thrombocytosis [Disease or Syndrome] & Diagnosis\\
% \hline
% \end{tabular}
% }
% \caption{\looseness-1 An example of medical concepts obtained from the query \emph{``patients with diabetes mellitus who also have thrombocytosis"} using our task-specific representation approach.}
%   \label{tab:CUIs}
% \end{table}

\section{An Approach for Inferring Conceptual Relationships when Ranking Patients}\label{Approach}
In this section, we introduce our proposed approach for inferring the relationships between medical concepts that leverage both external resources and the local statistics of the top-ranked medical records. In particular, Section~\ref{c7sRules} discusses how we derive possible relationships between medical concepts from external resources and represent them as association rules. In Section~\ref{All} and~\ref{c7sRandomWalk}, we propose two techniques based on Bayes' theorem and a stochastic analysis, respectively, to infer relationships between medical concepts from the extracted association rules. Section~\ref{c7sModel} discusses our approach to improve the representation of the query by using both medical concepts derived from the external resources using either Bayes' theorem or a stochastic analysis, and informative concepts extracted from the top-ranked medical records.

\subsection{Extracting and Representing Medical Concept Relationships from External Resources as Association Rules}\label{c7sRules}

Driven by the aforementioned medical decision process~\cite{limsopatham2013ecir-b}, we extract directed association rules representing the relationships between concepts from two different types of medical resources\footnote{We provide the list of all of the used resources in Section~\ref{c7sSetup}.}, which are ontology-based and free-text-based resources, respectively. We use different strategies for extracting conceptual relationships from each type of resource. For the ontology-based resources (e.g.\ MedDRA\footnote{\url{http://www.meddramsso.com}} and DOID\footnote{\url{http://purl.bioontology.org/ontology/DOID}}), we use the semantic relationships of concepts within each ontology to represent the relationships between concepts. For instance, `Coronary heart disease' is a particular type of `heart disease' (i.e.\ \emph{`Coronary heart disease'$\rightarrow$`heart disease'} -- A patient suffering from `Coronary heart disease' can be considered as having `heart disease' condition). 

For the free-text-based resources (e.g.\ \url{http://www.rxlist.com}), we use Meta\-Map to identify concepts related to the four aforementioned medical aspects from the free-text documents (we use the task-specific representation approach~\cite{limsopatham2013ecir-b} described in Section~\ref{RelatedWork} to identify medical concepts from sentences in the free-text documents), and then assume the existence of relationships between the identified concepts.
For example, from a drug indication in the \url{http://www.rxlist.com} website, which states that \emph{``Boniva (ibandronate sodium) is indicated for the treatment and prevention of osteoporosis in postmenopausal women''}, as shown in Figure~\ref{fig:rxlist},
MetaMap can identify the concepts \emph{`Boniva'} (treatment) and \emph{`osteoporosis'} (diagnosis). Assuming the relationships between medical concepts found in the drug description, we surmise that there is an association between the two concepts (i.e.\ \emph{`Boniva'$\rightarrow$`osteoporosis'} and \emph{`osteoporosis'$\rightarrow$`Boniva'}). Next, the extracted association rules are stored in a database. For instance, as shown in Table~\ref{tab:reasoning}, the rules associated to the concept \emph{`osteoporosis'} are \emph{`Dowager's hump'$\rightarrow$`os\-teoporosis'}, \emph{`DEXA'$\rightarrow$`os\-teoporosis'}, \emph{`Prolia'}\emph{$\rightarrow$`os\-teo\-porosis'}, and \emph{`Boniva'$\rightarrow$`os\-teo\-poro\-sis'}.
These association rules provide new evidence to infer the possible relevance of medical records, which are then aggregated to estimate the relevance of their associated patients. For instance, we can infer that patients taking the \emph{`Boniva'} medicine suffer from \emph{`osteoporosis'}, since \emph{`Boniva'} is a treatment for \emph{`osteoporosis'}.

\begin{figure}[tb]
  \centering
\includegraphics[angle=0,width=100mm]{rxlist.png}
\caption{An example of the indications of `Boniva' from \protect\url{http://www.rxlist.com} website.}\label{fig:rxlist}
\end{figure}

\begin{table}[tb]
\caption{Examples of medical concepts associated to `osteoporosis' defined in our associated rules database.}\label{tab:reasoning}
  \centering
% \small
\begin{tabular}{|l|l|}
    \hline
    Medical Concept & Related Concept\\ \hline
    Dowager's hump & Osteoporosis\\ 
    DEXA & Osteoporosis\\ 
    Prolia & Osteoporosis\\ 
    Boniva & Osteoporosis\\ \hline
  \end{tabular}   
\end{table}

% \begin{figure}%[tb]
%   \centering
% \includegraphics[angle=0,width=85mm]{images/ch7reasoningExample.png}
% \caption{Examples of medical concepts associated to `osteoporosis' defined in our associated rules database.}\label{tab:reasoning}
% \end{figure}

\subsection{A Bayesian-based Technique for Inferring Conceptual Relationships}\label{All}
% strongly established
\looseness-1 We argue that the relationships between concepts that are related to the medical decision process could be leveraged to deal with the complexity of medical terminology.
For example, if we have evidence that a patient is taking the \emph{`olmesartan'} medicine (treatment), we can infer that the patient suffers from \emph{`hypertension'} (diagnosis), since \emph{`olmesartan'} is a treatment for \emph{`hypertension'}. Therefore, using external domain-specific resources, we propose to 
% enhance the representation of queries by inferring the relationships between concepts related to the four aspects of the medical decision process. We 
reformulate the queries by using the association rules extracted from the medical resources (described in Section~\ref{c7sRules}). 

Specifically, we first retrieve a set of candidate concept expansions (denoted $inferred(q)$) corresponding to the query concepts from the extracted association rules. Then, to prevent excessively general candidate concepts being added to the query, we estimate the association of a query concept and each candidate concept expansion using a Bayesian probabilistic score computed based on the occurrences of concepts in the association rules (both derived from ontologies and free-text resources). The higher the probability, the stronger the relationship between the two concepts. Indeed, the Bayesian probabilistic score of the association between query concept $t$ and its corresponding concept $t'$ is estimated as follows:
\begin{align}\label{eq:conditional}
w_a(t,t') = p(t'|t) = \frac{p(t' \cap t)}{p(t)}
\end{align}
where $p(t' \cap t)$ is the maximum likelihood that the concept $t'$ co-occurs with the query concept $t$ within all the extracted association rules, and $p(t)$ is the maximum likelihood that the concept $t$ is contained in an association rule. 
This maximum likelihood is calculated based on the frequency of the occurrences of each concept in the whole association rules database.

\begin{figure}[tb]
  \centering
\includegraphics[angle=0,width=85mm]{reasoningExample2.png}
\caption{An example of identifying candidate con\-cept expansions using our technique on query \emph{``patients with osteoporosis"}.}\label{fig:reasoning}
\end{figure}

Figure~\ref{fig:reasoning} shows an example of how our technique identifies candidate concept expansions for the query \emph{``patients with osteoporosis"}. In particular, we first obtain the concept \emph{`osteoporosis'} from the query using the task-specific representation approach. Then, the concept \emph{`osteoporosis'} is used to retrieve related concepts from the database of association rules previously extracted from the medical resources (see Section~\ref{c7sRules}). As shown in Figure~\ref{fig:reasoning}, the retrieved candidate concept expansions include \emph{`Dowager's hump'}, \emph{`DE\-XA'}, \emph{`Prolia'} and \emph{`Boniva'}, which are the symptom, diagnostic test, and treatments associated to the original query concept (i.e.\ \emph{`osteoporosis'}). 
% As discussed in Section~\ref{c2sPRF}, it has been shown that QE is effective when the highly informative terms are added to the original query. Hence, 
However, as previously discussed in Section~\ref{RelatedWork}, QE is effective when a number of highly informative terms that are associated to the query are added to the query~\cite{amati2003thesis}, we select a top-k candidate concept expansions, which are ranked based on the score computed using Equation~(\ref{eq:conditional}), to expand the original query. 
%we follow the work of~\cite{amati2003thesis} and use only the \emph{top 10} candidate concept expansions, which are ranked based on the score computed using Equation~(\ref{eq:conditional}), to expand the original query.

\subsection{A Stochastic Analysis for Inferring Conceptual Relationships}\label{c7sRandomWalk}

Next, we discuss our stochastic analysis technique for inferring relationships between medical concepts in the association rule database built in Section~\ref{c7sRules}. Indeed, we propose to measure the strength of the relationships between the medical concepts in the association rule database using a stochastic analysis of some random walk behaviour through the association rules.
% hypothesise that the strength of the relationships between medical concepts in an association rule database can be measured using a stochastic analysis of some random-walk behaviour through the association rules.

%A stochastic analysis of random-walk behaviour has been studied before in information retrieval (IR) (e.g.~\cite{brin1998,lempel2001tois,blanco2012ir}). For example, Brin and Page~\cite{brin1998}'s PageRank used a stochastic analysis of random walks on the hyperlink of the entire Web to determine the importance of each web page. Lempel and Moran~\cite{lempel2001tois} introduced a stochastic analysis technique for link-structure analysis (SALSA), which performed random walks on a sub-graph derived from the link-structure of an initial set of retrieved results. 
%%As discussed in Section~\ref{RelatedWork}, Koopman et al.~\cite{koopman2012adcs} used the PageRank scores of medical concepts 
%% within a particular document, as a discriminative score of each concept for that document, 
%%when calculating the document's relevance score. In particular, 
%Koopman et al.~\cite{koopman2012adcs} built a linked structure of medical concepts within a document based on the co-occurrences between the medical concepts within a particular size of window of concepts, and used the PageRank scores of medical concepts when calculating the document's relevance score.

A stochastic analysis of random-walk behaviour has been studied before in IR (e.g.~\cite{brin1998,lempel2001tois,blanco2012ir}). For example, \cite{brin1998}'s PageRank used a stochastic analysis of random walks on the hyperlink of the entire Web to determine the importance of each web page. \cite{lempel2001tois} introduced a stochastic approach for link-structure analysis (SALSA), which performed random walks on a sub-graph derived from the link-structure of an initial set of retrieved results. 
In particular, consider a collection \emph{D} of documents (e.g.\ \emph{1, 2, 3, 4 and 5}) and directed relationships between the documents (see Figure~\ref{fig:c7:sub-a}). For example, there is a relationship from document $1$ to document $2$. The approach first converts the collection \emph{D} to a bipartite graph \emph{G}, of which the two parts are considered \emph{hubs} and \emph{authorities}. Hubs are documents (i.e.\ nodes) that link to other documents, while authorities are documents that are linked to by other documents. The SALSA algorithm performs random walks to uncover the relationships between these documents. 

\begin{figure*}[tb]
\centering
        \subfigure[A collection \emph{D} of documents \emph{1, 2, 3, 4, 5}]{
            \label{fig:c7:sub-a}
            \includegraphics[angle=0,width=70mm,scale=1]{salsa-a.png}
        }%\hspace{10mm}%\\%
        \subfigure[A bipartite graph \emph{G}]{
           \label{fig:c7:sub-b}
           \includegraphics[angle=0,width=70mm,scale=1]{salsa-b.png}
        }%\\%
    \caption{%
        Transforming (a) the collection \emph{D} into (b) a bipartite graph \emph{G}.
     }%
   \label{fig:example}
\end{figure*}

Different from existing work, we propose to apply the SALSA algorithm to uncover medical concepts that are related to a given query and identify the strength of their relationships, using the link structure within our association rule database. Later, we discuss in Section~\ref{c7sModel} how these medical concepts are used to enrich the query.

Specifically, we adapt the SALSA algorithm to perform the analysis of the links between the concepts in the association rules. In this work, the nodes (e.g.\ \emph{1, 2, 3, 4 and 5} in Figure~\ref{fig:c7:sub-a}) are the medical concepts in the association rule database, while an edge is a directed relationship between two concepts (i.e.\ nodes). Consider a bipartite graph \emph{G} where the two parts are hubs and authorities, a directed edge between hub $h$ and authority $a$ is indicated by a conceptual relationship between them (e.g.\ the edge between concept \emph{1} and concept \emph{2} -- $h_1 \rightarrow a_2$ in Figure~\ref{fig:c7:sub-b}). A good hub points to many authorities, and a good authority is pointed by many hubs. 

%While the previously mentioned approaches are based on the hyperlink structure of the documents to be ranked, we propose to apply a stochastic analysis to determine the medical concepts related to a given query and the strength of their relationships, using the link structure within our association rule database. Later, we discuss in Section~\ref{c7sModel} how these medical concepts are used to enrich the query.

%We adapt the SALSA algorithm to perform the analysis of the links between the concepts in the association rule database. In this work, the nodes are the medical concepts in the association rule database, while an edge is a directed relationship between two concepts (i.e.\ nodes). Specifically, consider a bipartite graph \emph{G}, of which the two parts are considered hubs and authorities. A directed edge between hub $h$ and authority $a$ is indicated by a conceptual relationship between them. A good hub points to many authorities, and a good authority is pointed by many hubs. 
% 
% We hypothesise that the authoritative medical concepts in query $q$ should be linked to by many medical concepts in the sub-graph induced by a set of medical concepts $C$, which are used as the query $q$. Therefore, a random walk on the sub-graph $C$ will visit those authoritative concepts with high probability. In particular, our approach, which adapts the SALSA algorithm to identify medical concepts related to the medical concepts in the query $q$, uses the following iterative algorithm~\cite{lempel2001tois}:
%The authoritative medical concepts related to the query $q$ should be linked to by many medical concepts in the sub-graph induced by a set of medical concepts $C$ in the query $q$. A random walk on the sub-graph induced by $C$ will visit those authoritative concepts with high probability. Hence, our adaptation of the SALSA algorithm~\cite{lempel2001tois} identifies medical concepts that are related to those medical concepts occurring in the query $q$, by using the iterative algorithm presented in Algorithm~\ref{al:c7:salsa}.
The authoritative medical concepts related to the query $q$ should be linked to by many medical concepts in the sub-graph induced by a set of medical concepts $C$ in the query $q$. A random walk on the sub-graph induced by $C$ will visit those authoritative concepts with high probability. Hence, our adaptation of the SALSA algorithm~\cite{lempel2001tois} identifies medical concepts that are related to those medical concepts occurring in the query $q$, by using the iterative algorithm presented in Algorithm~\ref{al:c7:salsa}.
% \begin{enumerate}
% \item Initialise $a(s) \leftarrow 1$, $h(s) \leftarrow 1$, all concepts $s \in C \cup C_a$, where $C_a$ is a set of medical concepts in the association rule database that link to or are linked to by a concept in $C$.
% \item Repeat the following steps until convergence:
% \subitem Update the authority score of each concept $s$:
% \begin{equation}
% a(s) \leftarrow \sum_{\{ x | x \textrm{ points to } s\}} h(x) \nonumber
% \end{equation}
% \subitem Update the hub score of each concept $s$:
% \begin{equation}
% h(s) \leftarrow \sum_{\{ x | s \textrm{ points to } x\}} a(x) \nonumber
% \end{equation}
% \subitem Normalise the authority scores and the hub scores.
% \end{enumerate}

The medical concepts with high authority scores are the concepts highly related to the query $q$, as they can be inferred by many concepts related to the query. 
% As previously discussed in Section~\ref{All}, \cite{amati2003thesis} showed that expanding the query with highly informative terms helped to improve retrieval performance. We use only the \emph{top 10} medical concepts ranked based on their authoritative scores computed using Algorithm~\ref{al:c7:salsa}.
To incorporate these medical concepts while ranking patients based on the relevance of their medical records, we select top-k candidate concept expansions based on their authoritative scores computed using Algorithm~\ref{al:c7:salsa}.
%follow~\cite{amati2003thesis} and use only the \emph{top 10} candidate concept expansions ranked based on their authoritative scores computed using Algorithm~\ref{al:c7:salsa}.
% (see Section~\ref{All}), which are ranked based on the authority scores.

% \begin{algorithm}[6.1]
% \caption{The Adapted SALSA Algorithm}
% \label{al:c7:salsa}
% % \begin{algorithmic}
% 1. Initialise $a(s) \leftarrow 1$, $h(s) \leftarrow 1$, all concepts $s \in C \cup C_a$, where $C_a$ is a set of medical concepts in the association rule database that link to or are linked to by a concept in $C$. \\
% 2. Repeat the following steps until convergence: \\
% $        $Update the authority score of each concept $s$: \\
% $               $ $a(s) \leftarrow \sum_{\{ x | x \textrm{ points to } s\}} h(x)$ \\
% $        $Update the hub score of each concept $s$: \\
% $               $ $h(s) \leftarrow \sum_{\{ x | s \textrm{ points to } x\}} a(x)$ \\
% $        $Normalise the authority scores and the hub scores.
% % \quntil convergence
% % \end{algorithmic}
% \end{algorithm}
\begin{algorithm}[tb]
% \textbf{The Adapted SALSA Algorithm}
% \noindent\fbox{%
% \begin{minipage}{\dimexpr\linewidth-2\fboxsep-2\fboxrule\relax}
\begin{algorithmic}[1]
\STATE Initialise $a(s) \leftarrow 1$, $h(s) \leftarrow 1$ for all concepts $s \in C \cup C_a$, where $C_a$ is a set of medical concepts in the association rule database that link to or are linked to by a concept in $C$.
\STATE Repeat the following steps until convergence:
\STATE ~~~~~~~~Update the authority score of each concept $s$:
\STATE ~~~~~~~~~~~~~~~~$a(s) \leftarrow \sum_{\{ x | x \textrm{ points to } s\}} h(x)$
\STATE ~~~~~~~~Update the hub score of each concept $s$:
\STATE ~~~~~~~~~~~~~~~~$h(s) \leftarrow \sum_{\{ x | s \textrm{ points to } x\}} a(x)$
\STATE ~~~~~~~~Normalise the authority scores and the hub scores.
% \RETURN $S(q)$
\end{algorithmic}
% \end{minipage}% 
% }
\caption{The Adapted SALSA Algorithm}
\label{al:c7:salsa}
\end{algorithm}
% \begin{algorithm}
% \textbf{xQuAD[$q, R(q), Q(q), r, i_X, \tau, \omega$]}
% \begin{algorithmic}[1]
% \STATE $S(q) \leftarrow \emptyset$
% \WHILE {$|S(q)| < \tau$}
%   \FOR {$d \in R(q)$}
%     \STATE $r(d,q,S) \leftarrow r(d,q) \times \left(\sum_{s \in Q(q)} i_X(s,q) r(d,s) / m(s)\right)^\omega$
%   \ENDFOR
%   \STATE $d^* \leftarrow \mbox{argmax}_d\ r(d,q,S)$
%   \FOR {$s \in Q(q)$}
%     \STATE $m(s) \leftarrow m(s) + r(d^*,s)$
%   \ENDFOR
%   \STATE $R(q) \leftarrow R(q) \setminus \{d^*\}$
%   \STATE $S(q) \leftarrow S(q) \cup \{d^*\}$
% \ENDWHILE
% \RETURN $S(q)$
% \end{algorithmic}
% \caption{The xQuAD model}
% \label{alg:xquad}
% \end{algorithm}

\subsection{Modelling Conceptual Relationships when Ranking Medical Records}\label{c7sModel}
We leverage both the local statistics from the top-ranked medical records and the association rules extracted from external resources to improve the representation of a given query. 
% Firstly, we infer medical concepts that are related to a given query from the occurrence statistics of medical concepts in the top-ranked medical records. 
In particular, we apply a pseudo-relevance feedback technique to identify informative concepts from the top-ranked medical records retrieved using the original query. 
% As discussed in Section~\ref{c2sPRF}, 
Indeed, when applying a pseudo-relevance feedback technique, concepts occurring in the top-ranked medical records are firstly weighted and ranked using a term weighting model. Then, the top-ranked concepts (i.e.\ the most informative concepts) are used to expand the original query. 
For example, for the query \emph{``patients with vascular disease"}, which is represented as \emph{``C0042373"} (\emph{`vascular disease'}), a pseudo-relevance feedback QE technique could identify related concepts, such as \emph{`C0190932'} (\emph{`femoral-popliteal artery bypass graft'}) and \emph{`C0014098'} (\emph{`endarterectomy'}), which correspond to treatments for that disease. However, the related diagnostic procedures and symptoms, such as \emph{`C0202896'} (\emph{`carotid angiogram'}), might not be added to the query, if they do not appear in the top-ranked medical records. 
Hence, on other hand, we also expand the query with medical concepts inferred using the association rules. We identify candidate expansion concepts and their weights using either the Bayesian-based technique or the stochastic technique introduced in Section~\ref{All} or~\ref{c7sRandomWalk}, respectively.
% , which is based on either a Bayesian probabilistic approach or a stochastic analysis, respectively.
% . aforementioned association rules. Specifically, we propose two approaches to define expanded concepts and their weight based on either a Bayesian probabilistic approach and a Markov process in Sections~\ref{All} and~\ref{c7sRandomwork}, respectively.

% Hence, in this work, we leverage both the external resources and the local statistics from the top-ranked medical records to improve the representation of the queries. Indeed, our proposed QE approach infers relationships of concepts using both the association rules extracted from the domain-specific resources and the occurrence statistics of concepts in the top-ranked medical records. 
% Combining both medical concepts inferred using the local statistics and external resources
In particular, our approach estimates the relevance score of a medical record $d$ towards the query $q$ as follows:
% Indeed, our proposed QE approach infers relationships of concepts using both the association rules extracted from the domain-specific resources and the occurrence statistics of concepts in the top-ranked medical records. 
% Indeed, we estimates the relevance of a medical record $d$ towards the query $Q$ as follows:
\begin{align}\label{eq:combining}
score(d,q)& = \sum_{t'' \in q_e} qtw(t'') \cdot score(d,t'') \\ \nonumber
&+ \lambda_r \cdot \sum_{t \in q}\sum_{t' \in inferred(q)} w_a(t,t') \cdot score(d,t')
\end{align}
where $t''$ and $qtw(t'')$ are a medical concept and its term weight in the expanded query $q_e$, which is reformulated using the occurrence statistics of medical concepts in the top-ranked medical records using any pseudo-relevance feedback model (e.g.\ Bo1 from the Divergence from Randomness (DFR) framework). $score()$ can be calculated using any term weighting model such as BM25,
$inferred(q)$ returns a set of expanded concepts, which are related to the concepts in the original query $q$. We use either of the techniques previously proposed in Section~\ref{All} or~\ref{c7sRandomWalk} to extract the expanded concepts (i.e.\ $t' \in inferred(q)$) and their weights (i.e.\ $w_a()$) from the association rule database. In particular, the Bayesian-based technique, and the stochastic analysis technique uses Equation~(\ref{eq:conditional}) and the authority score ($a()$) computed using Algorithm~\ref{al:c7:salsa}, respectively, to calculate $w_a()$. $\lambda_r$ is a parameter to weight the importance of the relevance scores computed for the medical concepts derived using either of the two proposed techniques.

To learn the $\lambda_r$ value for each query, we use the Gradient Boosted Regression Trees (GBRT) regression technique~\cite{tyree2011www} (as implemented in the jforest package~\cite{ganjisaffar2011sigir}\footnote{\url{http://code.google.com/p/jforests}}), since it has shown to be effective for regression tasks (e.g.~\cite{limsopatham2013sigir}). To learn an value of parameter $\lambda_r$ for an unseen query, we use 12 features, which measure the predicted difficulty of the query. An effective feature should indicate the level of emphasis on the relevance scores computed for the concepts inferred using the association rules. Our intuition for using these features is that if the query is difficult, then it might be beneficial to take into account the relevance estimated from the inferred concepts. In particular, if using only the information from the original query is difficult for a search system, medical concepts inferred using the extracted association rules might bring novel evidence that can improve the representation of the query and hence enhance the retrieval performance. 
% 
Table~\ref{tab:features-c7} lists the 12 query performance predictors computed on the original query, which are well-known for measuring the difficulty of a query. 
% Specifically, the 12 QPP features include Features 1-4; the clarity score~\cite{cronen-townsend2002sigir}, SCQ~\cite{zhao2008ecir}, MAXCQ~\cite{zhao2008ecir} and NSCQ~\cite{zhao2008ecir} that use the coherence of the language model of the collection to measure the difficulty. The more the difference between the language models of the query and the collection, the more difficult the query. Next, Features 5-8 (AvICTF~\cite{carmel2010sl}, AvIDF~\cite{carmel2010sl}, EnIDF~\cite{carmel2010sl}, and Query Scope ($\omega$)~\cite{he2006is}) measure the difficulty of a query based on the specificity of the query concepts. Features 9 and 10 ($\gamma_1$~\cite{he2006is} and $\gamma_2$~\cite{he2006is}) measure the distribution of the informativeness of the query concepts. The query is likely to be less difficult, if most of query concepts are informative. Feature 11 (AvPMI~\cite{carmel2010sl}) measures the co-occurrences of the query concepts. If the query terms co-occur frequently, it is likely that the focuses on a particular group of medical concepts. Feature 12 is the length of the query i.e.\ the number of medical concepts in the query. Short queries are more likely to be difficult~\cite{carmel2010sl}.
Specifically, the first set of features (Features 1-4), including the clarity score~\cite{cronen-townsend2002sigir}, SCQ~\cite{zhao2008ecir}, MaxSCQ~\cite{zhao2008ecir} and NSCQ~\cite{zhao2008ecir}, consider the ambiguity of a query by measuring the coherence of the language used in each medical record. 
The more similar the query model is to the collection model, the better the retrieval performance would be expected. The next set of features (Features 5-8) measure the specificity of each query. Indeed, queries with explicit intents could result in a better performance than queries with general concepts. The features include Average Inverse Collection Term Frequency (AvICTF)~\cite{carmel2010sl}, Average Inverse Document Frequency (AvIDF)~\cite{carmel2010sl}, EnIDF~\cite{carmel2010sl}, and the query scope ($\omega$)~\cite{he2006is}. Features 9-10 measure the distribution of informativeness among the query concepts (i.e.\ $\gamma_1$ and $\gamma_2$~\cite{he2006is}), as a query with informative concepts could attain an effective retrieval performance. Next, Feature 11, the Average of the Pointwise Mutual Information over all query term pairs (AvPMI)~\cite{carmel2010sl}, focuses on the relationship between query concepts. The more co-occurrences among the query concepts, the better the chance that the relevant documents are being retrieved.
Finally, Feature 12 is the number of non-stopword query concepts.
% , which could impact the normalisation methods of the probabilistic retrieval models, and hence affect retrieval performance~\cite{he2006is}.

\begin{table}[tb]
\caption{List of the features used for learning the emphasise on medical concepts derived from association rules.}
\label{tab:features-c7}   
\centering
% \small
\begin{tabular}{|r|l|}
    \hline
    ID & Feature\\ \hline
    1&Clarity Score~\cite{cronen-townsend2002sigir} \\ \hline
    2&SCQ~\cite{zhao2008ecir} \\ \hline
    3&MAXCQ~\cite{zhao2008ecir} \\ \hline
    4&NSCQ~\cite{zhao2008ecir} \\ \hline
    5&AvICTF~\cite{carmel2010sl} \\ \hline
    6&AvIDF~\cite{carmel2010sl} \\ \hline
    7&EnIDF~\cite{carmel2010sl} \\ \hline
    8&Query Scope ($\omega$)~\cite{he2006is} \\ \hline
    9&$\gamma_1$~\cite{he2006is} \\ \hline
    10&$\gamma_2$~\cite{he2006is} \\ \hline
    11&AvPMI~\cite{carmel2010sl} \\ \hline  
    12&Query length~\cite{he2006is}\\ \hline
  \end{tabular}   
\end{table}

\section{Experimental Setup}\label{c7sSetup}

\subsection{Corpus/Queries/Measures}
We evaluate our proposed approach in the context of the TREC 2011~\cite{voorhees2011trec} and 2012~\cite{voorhees2012trec} Medical Records track.
In this track, the task is to identify relevant patient \emph{visits} for a given query topic. Each visit contains all of the medical records associated with a patient's visit to a hospital. A visit is used to represent a \emph{patient} as a unit of retrieval, due to privacy concerns~\cite{voorhees2011trec}. The medical records collection consists of approximately 102k medical records, which can be mapped to 17,265 patient visits, from the University of Pittsburgh NLP Repository. We evaluate our proposed approach using the 34 and 47 topics from the TREC 2011 and 2012 Medical Records track, respectively.

We evaluate the retrieval effectiveness of our proposed approach, in terms of the TREC official measures, which are bpref measure~\cite{buckley2004sigir} for TREC 2011, and infNDCG measure~\cite{yilmaz2008sigir} for TREC 2012. In particular, bpref is the official measure of TREC 2011, since the absolute number of judged patient visits per topic is relatively small~\cite{voorhees2011trec}. bpref is designed for evaluating environments with incomplete relevance data and penalises a system which ranks a judged non-relevant document above a judged relevant document~\cite{buckley2004sigir}. On the other hand, infNDCG is the primary measure of the TREC 2012 Medical Records track~\cite{voorhees2012trec}, since the gold standard judgements are incomplete; hence a sampling approach is deployed to infer the NDCG performance. In addition, we measure statistically significant differences between the retrieval performance achieved by our approach and the baselines using the paired t-test at $p < 0.05$.

\subsection{Medical Record \& Patient Ranking}
\looseness-1 We index the medical records using the Terrier retrieval platform~\cite{ounis06terrier-osir}. The BM25 weighting model~\cite{robertson1994sigir} is used to rank medical records (e.g.\ $score_t()$ in Equation~(\ref{eq:combining})).
Then, to rank the patients, as explained in Section~\ref{RelatedWork}, we deploy the expCombSUM 
voting technique~\cite{macdonald2006cikm}, which gives more importance to the highly relevant medical records while voting for the relevance of the patients. 
In particular, for a given ranking of medical records ($R(Q)$) with respect to query $Q$, each medical record is said to vote for the relevance of its associated patient. The number of medical records in $R(Q)$ to vote for the relevance of the patients is limited to 5,000, as suggested in~\cite{limsopatham2011trec}. 


% To evaluate the proposed approach for inferring the conceptual relationships between medical concepts to deal with the medical terminology (discussed in Section~\ref{c7sIntroduction}) we use the similar settings to those in Chapter~\ref{cNegation}. Specifically, we use the TREC Medical Records track's test collection. As it has been shown to be effective in Section~\ref{c5sEvalRanking}, we initially rank medical records using the BM25 weighting model, and then use the expCombSUM voting technique to aggregate the relevance scores of patients. We represent the medical records and queries using the task-specific representation approach introduced in Section~\ref{c5sConcept} of Chapter~\ref{cTaskSpecific}.
% Importantly, as the approaches discussed on this chapter build upon a conceptual representation of medical records and queries, we deploy the task-specific representation approach introduced in Chapter~\ref{cTaskSpecific} because of its effectiveness.

\subsection{Association Rules}

To create the association rule database (discussed in Section~\ref{c7sRules}), we use the external resources listed in Table~\ref{tab:resources}, which are representatives of both ontology-based and free-text-based medical resources. Table~\ref{tab:resources:stat} shows the number of association rules between concepts extracted from the 7 domain-specific resources. The types of relationships that are extracted from each resource are described in Column 2 of Table~\ref{tab:resources}. Note that there are some association rules that overlap between resources. In total, there are 11,373,014 extracted association rules in our database. Meanwhile, Table~\ref{tab:rule:count} shows the number of the extracted association rules with respect to the four aspects of the medical decision process. For example, the rules with the type `diagnosis $\rightarrow$ symptom' are the association rules that can be used to infer the related symptoms that the medical records of the relevant patients are likely to contain if the query contains a particular diagnosis. Note that there are some association rules that are duplicated among different types of rules, since using the technique described in~\cite{limsopatham2013ecir-b}, some medical concepts can be categorised into several medical aspects. For example, medical concepts related to parts of body are considered to be associated with symptom, diagnostic test, diagnosis and treatment (see Table~\ref{tab:CU}). We use these extracted association rules to extract concept expansions by using the Bayesian-based and stochastic techniques previously introduced in Sections~\ref{All} and~\ref{c7sRandomWalk}, respectively. In addition, we follow~\cite{amati2003thesis} and use only \emph{top 10} candidate concept expansions ($k=10$) extracted using each technique.
%However, as discussed in Section~\ref{c2sPRF}, QE is effective when a number of highly informative terms that are associated to the query are added to the query~\cite{amati2003thesis}, we select a top-k candidate concept expansions, which are ranked based on the score computed using Equation~(\ref{eq:conditional}), to expand the original query. 
%we follow the work of~\cite{amati2003thesis} and use only the \emph{top 10} candidate concept expansions, which are ranked based on the score computed using Equation~(\ref{eq:conditional}), to expand the original query.

\begin{table*}[tb]
\caption{List of resources used for extracting the conceptual relationships related to the four aspects of the medical decision process.}\label{tab:resources}
  \centering
\resizebox{1.0\textwidth}{!}{
  \begin{tabular}{|l|p{8.5cm}|}
    \hline
    Resource & Description of the Extracted Association Rules\\ 
    \hline
    DOID hierarchy & Hierarchical relationships between concepts within the same aspects e.g.\ a general disease and a specific type of the general disease\\ 
    MeSH & Hierarchical relationships between concepts within the same aspects e.g.\ a general disease and a specific type of the general disease\\ 
    MedDRA & Hierarchical relationships between concepts within the same aspects e.g.\ a general disease and a specific type of the general disease\\
    DOID & Relationships between concepts across the aspects e.g.\ a disease and its symptoms\\
    \url{http://www.rxlist.com} & Relationships between concepts across the aspects e.g.\ a medicine and the diseases that it can remedy\\
    \url{http://www.webmd.com} & Relationships between concepts across the aspects e.g.\ a diagnostic test and the diseases that it can diagnosed\\
    UMLS & Both hierarchical and across-aspects relationships e.g.\ a general disease and a specific type of the general disease\\
    \hline
  \end{tabular}
}
\end{table*}

\begin{table}[tb]
\caption{Number of association rules extracted from each domain-specific resource.}\label{tab:resources:stat}
  \centering
  \begin{tabular}{|l|l|r|}
    \hline
    Resources & Association Types & \# of Rules\\ 
    \hline
    DOID hierarchy & Specific-general& 2,046\\
    MeSH & Specific-general& 53,915\\
    MedDRA & Specific-general & 86,109\\
    DOID & Across aspects& 9,664\\
    \url{http://www.rxlist.com} & Across aspects & 5,433\\
    \url{http://www.webmd.com} & Across aspects& 3,694\\
    UMLS & Specific-general \& Across aspects & 11,212,153\\
    \hline
  \end{tabular}
\end{table}

\begin{table}[tb]
\caption{The types of the extracted association rules in terms of the four medical aspects.}\label{tab:rule:count}
  \centering
% \small
\begin{tabular}{|l|l|}
    \hline
Rule type & \# of rules \\ \hline
diagnosis $\rightarrow$ diagnosis&2,900,788\\
diagnosis $\rightarrow$ diagnostic test&1,907,492\\
diagnosis $\rightarrow$ symptom&2,306,712\\
diagnosis $\rightarrow$ treatment&2,018,061\\
diagnostic test $\rightarrow$ diagnosis&1,905,521\\
diagnostic test $\rightarrow$ diagnostic test&2,726,341\\
diagnostic test $\rightarrow$ symptom&2,023,443\\
diagnostic test $\rightarrow$ treatment&2,695,757\\
symptom $\rightarrow$ diagnosis&2,303,486\\
symptom $\rightarrow$ diagnostic test&2,020,294\\
symptom $\rightarrow$ symptom&4,205,071\\
symptom $\rightarrow$ treatment&2,096,350\\
treatment $\rightarrow$ diagnosis&2,015,362\\
treatment $\rightarrow$ diagnostic test&2,698,453\\
treatment $\rightarrow$ symptom&2,097,231\\
treatment $\rightarrow$ treatment&6,597,028\\
\hline
  \end{tabular}   
\end{table}


For the local-statistic query expansion technique used in Equation~(\ref{eq:combining}) of Section~\ref{c7sModel}, we deploy a parameter-free Bose-Einstein statistics-based (Bo1) model from the DFR framework to extract informative concepts from the top-ranked medical records as it has shown to be effective in previous works~\cite{limsopatham2011trec,limsopatham2013ecir-b}. DFR Bo1 measures the informativeness of a concept based on the divergence of the concept's distribution in the pseudo-relevant feedback documents (i.e.\ top-ranked medical records) from its distribution in the entire collection. The more the divergence is measured, the more likely that the concept is informative and related to the query. Specifically, Bo1 from the Divergence from Randomness framework calculates the weight $w(t)$ of a concept $t$ in the pseudo-relevant documents, as follows~\cite{amati2003thesis}:
\begin{equation}
w(t) = tf_x \cdot log_2 \frac {1+P_n}{P_n} + log_2 (1+P_n)
\end{equation}
where $tf_x$ is the frequency of concept $t$ in the set of pseudo-relevant documents $x$. $P_n = \frac{TF}{N}$, where $TF$ is the term frequency of $t$ in all documents in the collection, and $N$ is the number of documents in the collection. In this work, we follow~\cite{amati2003thesis} and set the number of pseudo-relevant documents and expanded concepts to 3 and 10, respectively.

Once we identify the expanded concepts, a parameter-free function is used to calculate the query term weight $qtw(t)$ of each concept $t$ in the expanded query, as follows~\cite{amati2003thesis}:
\begin{align}
qtw(t) &= \frac{qtf}{qtf_{max}} + \frac{w(t)}{\lim_{TF \rightarrow tfw} w(t)} \\ \nonumber
&= TF_{max} \log_2 \frac{1+P_{n,max}}{P_{n,max}} + \log_2 (1+P_{n,max})
\end{align}\label{eq:c2sBo12}
where $qtf$ is the frequency of a concept $t$ in the query, and $qtf_{max}$ is the maximum of $qtf$. $\lim_{TF \rightarrow tfw} w(t)$ is the upper bound of $w(t)$, $TF_{max}$ is the frequency $TF$ of the concept with the maximum $w(t)$ in the pseudo-relevant documents. $P_{n,max} = \frac{TF_{max}}{N}$. Note that if an original query concept $t$ does not appear in the most informative concept list extracted from the pseudo-relevant documents, its query term weight $qtw(t)$ remains equal to the original one.
% , as it has been shown to be effective in Section~\ref{ssCE} of Chapter~\ref{cNegation}. 
% Specifically, we follow~\cite{amati2003thesis} and extract the 10 most informative concepts from the top 3 retrieved medical records to generate the expanded query $Q_e$ in Equation~(\ref{eq:combining}).

As both the Bayesian-based and the stochastic analysis-based techniques require the $\lambda_r$ parameter in Equation~(\ref{eq:combining}) to be properly set, we apply two different training regimes. 
%(namely, \emph{5-fold and x-collection validations}). 
Firstly, we apply a five-fold cross-validation (5-fold) within each set of queries, since the target measure of TREC 2011 and 2012 queries are different. Secondly, we use the TREC 2012 queries as training data, when testing with the TREC 2011 queries, and vice versa. We refer to this setting as \emph{cross-collection validation} (x-collection). 
% To estimate the oracle weight $O(t')$ as described in Section~\ref{ssObjective}, 
We optimise the TREC primary measure (i.e.\ bpref and infNDCG measures for TREC 2011 and 2012, respectively) when learning the $\lambda_r$ parameter.

\subsection{Baselines}
We compare the retrieval effectiveness of the proposed approach to infer relationships between medical concepts with the following baselines:
\begin{itemize}
\item The task-specific representation baseline~\cite{limsopatham2013ecir-b} (see Section~\ref{RelatedWork}), which does not apply any QE technique.
\item The Bo1 baseline: applying the Bo1 query expansion technique with the task-specific representation approach.
\item The Bo1 \& Semantic QE baseline: using both the Bo1 query expansion technique and a semantic query expansion technique that adds all of the related medical concepts into the queries (as used in~\cite{king2011trec}). Note that this baseline uses the same set of external resources as the proposed approach.
% (i.e.\ the baseline identified in Section~\ref{c5sEvalConcept}). Specifically, our baselines include the task-specific representation approach when no query expansion is applied, when only a query expansion technique based on the occurrence statistics of medical concepts in the top-ranked medical records (namely, Bo1) is used to enhance the representation of the queries, and when the synonyms of or medical concepts related to a medical concept in a query are used to expand the query (as in~\cite{king2011trec}).
\end{itemize}


\section{Experimental Results}\label{c7sResults}

\begin{table}[tb]
\caption{Retrieval performance of our Bayesian-based approache for inferring relationships between medical concepts in comparison with the three baselines on TREC 2011 and 2012 Medical Records track's queries. Statistical significance (paired t-test) at $p<0.05$ over the task-specific representation and the Bo1 \& Semantic QE baselines are denoted $^t$ and $^{s}$, respectively.}\label{tab:c7Bayesian}
  \centering
\resizebox{1.0\textwidth}{!}{
  \begin{tabular}{|l|c|c|}
    \hline
     Approach & bpref (TREC 2011) & infNDCG (TREC 2012) \\ 
    \hline
     Task-specific representation & 0.5243 & 0.4880\\
     + Bo1 & 0.5403 & 0.5129 \\
     + Bo1 \& Semantic QE & 0.3013 & 0.2228\\
%     + Our Bayesian probabilistic approach ($\lambda=1$) & 0.5478 & 0.5077 \\
     + Our Bayesian-based approach (5-fold) & {\bf0.5474}$^{s}$ & {\bf0.5133}$^{t,s}$ \\
     + Our Bayesian-based approach (x-collection) & 0.5464$^{s}$ & 0.5125$^{t,s}$\\
\hline
     + Our Bayesian-based approach (oracle) & 0.5646$^{t,s}$ & 0.5393$^{t,s}$ \\
    \hline
  \end{tabular}
}
\end{table}

In Sections~\ref{c7sExperimentBayesian} and~\ref{c7sExperimentRandomWalk}, we evaluate the proposed approach when using Bayes' theorem and a stochastic analysis to derive associated medical concepts $t''$ and their weights $qtw(t'')$ in Equation~(\ref{eq:combining}), respectively. In particular, we refer the two variants as the Bayesian-based approach and the stochastic approach.

\subsection{Experiment with our Bayesian-based Approach for Inferring Conceptual Relationships}\label{c7sExperimentBayesian}
% Next, we evaluate the effectiveness of our proposed QE approach that builds upon the task-specific representation. Indeed, our QE approach infers conceptual relationships from medical knowledge extracted from the external resources (Section~\ref{QueryReformulation}) and from the occurrence statistics of concepts in the top-ranked medical records (Section~\ref{LocalQueryExpansion}).
% We compare the retrieval effectiveness of our proposed approach with the baselines, where only either the knowledge from the external resources or the occurrence statistics of medical concepts in the top-ranked medical records is used to enhance the representation of the queries. In addition, the retrieval performance of the task-specific representation approach (i.e.\ no QE applied) is also reported. 
% 
% Our proposed QE approach requires a parameter $\lambda_r$ as per Equation~(\ref{eq:combining}) to be properly set. Hence, to have a fair train/test setting, when conducting experiments on TREC 2011 Medical Records track test collection, we set $\lambda_r$ based on the best infAP retrieval performance achieved on the TREC 2012 test collection, and for the experiments on the TREC 2012 test collection, we set $\lambda_r$ based on the best bpref retrieval performance attained on the TREC 2011 test collection. We refer to this parameter setting method as \emph{cross-collection setting}. Furthermore, to see how the parameter setting impacts on the retrieval performance and the potential effectiveness of our QE approach, the performances achieved when using the best $\lambda_r$ for each retrieval measure on each test collection (i.e.\ best setting) are also reported.
% 
% 
% Table~\ref{tab:qe} shows the retrieval performance of our proposed QE approach on the TREC 2011 and 2012 test collections. We observe that for the TREC 2011 test collection, our proposed QE approach significantly (paired t-test, $p < 0.05$) improves the bpref retrieval performance from 0.4929 to 0.5250 (+6.51\%) over the task-specific representation baseline where no QE is applied. For TREC 2012 test collection, our proposed QE approach also significantly outperforms the task-specific representation baseline, in terms of both infNDCG ($p < 0.05$) and infAP ($p < 0.01$) measures. In particular, the infNDCG retrieval performance is improved from 0.4218 to 0.4534 (+7.49\%) and infAP is increased from 0.1920 to 0.2128 (+10.83\%). 
% Additionally, as expected, we find that with a proper setting of the parameter $\lambda_r$ (i.e.\ the $\lambda_r$ that results in the best retrieval performance for each topic set), our proposed QE approach can achieve a better retrieval performance.\footnote{\small Nevertheless, our training using the fair cross-collection setting achieves a retrieval performance comparable to the best setting.}
% In particular, the infNDCG retrieval performance is improved to 0.4745 (+12.49\% over the task-specific representation baseline). This performance significantly outperforms the task-specific representation, local statistics-based QE, and our proposed QE approaches (cross-collection setting), at $p < 0.001$, $p < 0.05$, and $p < 0.05$, respectively. In term of infAP retrieval performance, with the best $\lambda_r$, our proposed approach markedly outperforms the task-specific representation baseline (14.43\% improvement from infAP 0.1920 to 0.2197). Moreover, we find that our QE approach when using both external resources and information from the top-ranked medical records markedly outperform when using only either of them.
% 
% % \vspace{-2mm}
% % \section{Relevance Score Combination}\label{srRelevance}
% % Finally, as previous work (e.g.~\cite{srinivasan1996ipma}) showed that a concept-based representation approach is effective only when combined with a term-based representation approach, we further evaluate the effectiveness of our proposed QE approach when combined with a term-based representation approach. In particular, we follow the approach by Srinivasan~\cite{srinivasan1996ipma}, which we refer to as the \emph{relevance score combination} approach, to linearly combine the relevance scores calculated using both the term-based representation approach and our proposed approach (cross-collection setting), as follows~\cite{srinivasan1996ipma}:
% % \begin{align}\label{eq:concept_combine}
% % \small
% % score(d,Q) = &\delta \cdot score_{term-based}(d,Q) \\ \nonumber
% %  &+ score_{our-approach}(d,Q) 
% % \end{align}
% % \looseness-1 where $\delta$ is a parameter to emphasise the relevance score computed using the term-based representation, which is set to 2.00, as suggested in~\cite{srinivasan1996ipma}.
% % 
% % In order to have a strong baseline for the term-based representation approach, we follow Diaz and Metzler~\cite{diaz2006sigir} to improve the representation of the queries by using information from different corpora (we call this the \emph{enriched term-based representation}). In particular, we apply the Bo1 QE model to expand the queries with the top 10 informative terms from the top 3 ranked documents retrieved from the TREC Medical Records and TREC 2005 Genomics~\cite{hersh2005trec} track collections, respectively. In addition, we follow~\cite{limsopatham2012sigir} to deal with negated language in medical records.
% % 
% % \looseness-1 We hypothesise that when combined with the enriched term-based representation approach, our proposed approach could further improve the retrieval effectiveness. In particular, we expect that the retrieval performance of the relevance score combination approach could be better than that of either the enriched term-based representation or our proposed QE approaches. Table~\ref{tab:combine} compares the retrieval performance of the relevance score combination approach to these two baselines. Moreover, the retrieval performance of the top 3 best TREC 2011 and 2012 Medical Records track systems are also reported. 
% % 
% % From Table~\ref{tab:combine}, we observe that the relevance score combination approach markedly outperforms both our proposed QE approach and the enriched term-based representation approach. In particular, for the TREC 2011 Medical Records track test collection, the achieved bpref retrieval performance (0.5764) is markedly better than the TREC best system (0.5520). Furthermore, for the TREC 2012 test collection, in terms of infNDCG retrieval performance, the relevance score combination approach (0.5266) could markedly outperform both the enriched term-based representation (0.4865) and our proposed QE (0.4534) approaches. Specifically, the infNDCG of the relevance score combination is significantly (paired t-test, $p<0.05$) better than that of the enriched term-based representation, improving by 7.63\%. Moreover, the infAP retrieval performance of the relevance score combination is also markedly better than the performance of the two baselines. Indeed, the infAP of the relevance score combination (0.2442) is 12.68\% better than the performance of the enriched term-based representation. Hence, our results show that our proposed QE approach could improve the representation and bring novel evidence for a search system to infer the relevance of medical records. Importantly, when combined with a term-based representation (as suggested by~\cite{srinivasan1996ipma}), without requiring any training for $\delta$ in Equation~(\ref{eq:concept_combine}), our approach could further improve the retrieval performance and the achieved performance is comparable to the best systems reported at TREC 2011 and 2012 Medical Records track.
% % 
% \begin{table*}[tb]
%   \centering
%   \begin{tabular}{|l|c|c|c|}
%     \hline
%     \multirow{2}{*}{Approaches} & 2011 & \multicolumn{2}{c|}{2012} \\ \cline{2-4}
%      & bpref & infNDCG & infAP \\ 
% \hline
%       Task-specific representation & 0.4929 & 0.4218&0.1920\\
%       Local Statistics-based QE& {\bf0.5282}$^*$ (+7.16\%)& 0.4530$^*$ (+7.49\%) & 0.2126$^{**}$ (+10.73\%)\\
%       Conceptual association-based QE (cross-collection setting) & 0.4929 (+0\%)& 0.4198 (-0.47\%) & 0.1913 (-0.37\%)\\ 
%       Conceptual association-based QE (best setting) & 0.4929 (+0\%) & 0.4358 (+3.32\%) & 0.1981 (+3.2\%) \\ 
%       Our proposed QE approach (cross-collection setting) & 0.5250$^*$ (+6.51\%) & {\bf0.4534}$^*$ (+7.49\%) & {\bf0.2128}$^{**}$ (+10.83\%) \\
% \hline
%       Our proposed QE approach (best setting) & 0.5283$^{*}$ (+7.18\%) & 0.4745$^{***+o}$ (+12.49\%) &0.2197$^{**}$ (+14.43\%) \\
%     \hline
%   \end{tabular}
% \caption{Comparing the retrieval performances of different query representation approaches on TREC 2011 and 2012 Medical Records track's test topics. Statistical significance (paired t-test) at $p<0.05$, at $p<0.01$, and at $p<0.001$ over the task-specific representation baseline are denoted $^*$, $^{**}$ and $^{***}$, respectively.  Statistical significance (paired t-test) at $p<0.05$ over the local statistics-based QE and our proposed QE (cross-collection setting) are denoted $^+$ and $^o$. }\label{tab:qe}
% \end{table*}
% % 
% % \begin{table*}[tb]
% %   \centering
% % \small
% % \resizebox{17.7cm}{!}{
% %   \begin{tabular}{|l|c|l|c|c|}
% %     \hline
% %     \multicolumn{2}{|c|}{2011} & \multicolumn{3}{c|}{2012} \\ 
% %     \hline 
% %     Approaches & bpref & Approaches & infNDCG & infAP \\ 
% % \hline
% %       Enriched term-based representation & 0.5733 & Enriched term-based representation & 0.4865 & 0.2132 \\
% %       Our proposed QE approach & 0.5250 & Our proposed QE approach & 0.4534 & 0.2128\\ 
% %       Relevance score combination & {\bf0.5764}$^+$ (+0.54\%,+8.92\%) & Relevance score combination & {\bf0.5266}$^{*++}$ (+7.63\%,+13.91\%) & {\bf0.2442} (+12.68\%,+12.85\%) \\
% % \hline
% %       \multicolumn{5}{|c|}{Best TREC systems} \\
% % \hline
% %       CengageM11R3 & {\bf0.5520} & udelSUM & {\bf0.5780} & {\bf0.2860}  \\
% %       SCIAMED7 & {\bf0.5520} & sennamed2 & 0.5470 & 0.2750 \\
% %       UTDHLTCIR & 0.5450  & atigeo1 & 0.5240 & 0.2240\\
% %     \hline
% %   \end{tabular}
% % }
% % \vspace{-3mm}
% % \caption{Comparing the retrieval performances of different retrieval approaches on TREC 2011 and 2012 Medical Records track's test topics. Statistical significance (paired t-test) at $p<0.05$, and at $p<0.01$ over the enriched term-based representation are denoted $^*$, and $^{**}$. Statistical significance (paired t-test) at $p<0.05$, and at $p<0.01$ over our proposed QE approach are denoted $^+$, and $^{++}$, respectively.}\label{tab:combine}
% % \vspace{-3mm}
% % \end{table*}
% % 


We first evaluate the effectiveness of the Bayesian-based technique for inferring the relationships between medical concepts. 
% using the local statistics and the Bayesian probability. Indeed, our approach infers conceptual relationships from medical knowledge extracted from the external resources (as listed in Table~\ref{tab:resources}) and from the occurrence statistics of concepts in the top-ranked medical records (see Section~\ref{c7sModel}). 
%We compare the retrieval effectiveness of the Bayesian-based technique with the following baselines:
%\begin{itemize}
%\item The task-specific representation baseline~\cite{limsopatham2013ecir-b}.
%\item The Bo1 baseline: applying the Bo1 query expansion technique with the task-specific representation approach.
%\item The Bo1 \& Semantic QE baseline: using both the Bo1 query expansion technique and a semantic query expansion technique that adds all of the related medical concepts into the queries (as used in~\cite{king2011trec}). Note that this baseline uses the same set of external resources as the Bayesian-based approach.
% (i.e.\ the baseline identified in Section~\ref{c5sEvalConcept}). Specifically, our baselines include the task-specific representation approach when no query expansion is applied, when only a query expansion technique based on the occurrence statistics of medical concepts in the top-ranked medical records (namely, Bo1) is used to enhance the representation of the queries, and when the synonyms of or medical concepts related to a medical concept in a query are used to expand the query (as in~\cite{king2011trec}).
%\end{itemize}
% , which are built upon the task-specific representation approach (i.e.\ the baseline identified in Section~\ref{c5sEvalConcept}). Specifically, our baselines include the task-specific representation approach when no query expansion is applied, when only a query expansion technique based on the occurrence statistics of medical concepts in the top-ranked medical records (namely, Bo1) is used to enhance the representation of the queries, and when the synonyms of or medical concepts related to a medical concept in a query are used to expand the query (as in~\cite{king2011trec}). 
%
% where only either the knowledge from the external resources or the occurrence statistics of medical concepts in the top-ranked medical records is used to enhance the representation of the queries. In addition, the retrieval performance of the task-specific representation approach (i.e.\ no QE applied) is also reported. 
%
% Our proposed approach requires a parameter $\lambda_r$ as per Equation~(\ref{eq:combining}) to be properly set. Hence, 
To have a fair train/test setting, we use the \emph{cross-collection validation} and \emph{5-fold cross validation} as described in Section~\ref{c7sSetup} when setting $\lambda_r$ within the Bayesian-based approach. Furthermore, to see how the parameter setting impacts on the retrieval performance and the potential effectiveness of our approach, the performance achieved when using the best $\lambda_r$ for each retrieval measure on each test collection (i.e.\ best possible setting) is also reported, denoted \emph{oracle}.

% when conducting experiments on TREC 2011 Medical Records track test collection, we set $\lambda_r$ based on the best infAP retrieval performance achieved on the TREC 2012 test collection, and for the experiments on the TREC 2012 test collection, we set $\lambda_r$ based on the best bpref retrieval performance attained on the TREC 2011 test collection. We refer to this parameter setting method as \emph{cross-collection setting}. Furthermore, to see how the parameter setting impacts on the retrieval performance and the potential effectiveness of our QE approach, the performances achieved when using the best $\lambda_r$ for each retrieval measure on each test collection (i.e.\ best setting) are also reported.

Table~\ref{tab:c7Bayesian} compares the retrieval performances of the Bayesian-based approach with the three baselines on TREC 2011 and 2012 Medical Records track test collection. From Table~\ref{tab:c7Bayesian}, we observe that the Bo1 baseline outperforms the task-specific representation baseline (i.e.\ no QE) for both TREC 2011 and 2012. Specifically, the retrieval performances improve from bpref 0.5243 to 0.5403 and from infNDCG 0.4880 to 0.5129 for TREC 2011 and 2012, respectively. Meanwhile, the Bo1 \& Semantic QE baseline decreases the retrieval performance. 

In contrast, the Bayesian-based approach, using either a 5-fold or an x-collection training regime, outperforms the task-specific representation baseline (both TREC 2011 and 2012). Specifically, the Bayesian-based approach with the 5-fold regime (5-fold) outperforms all of the three used baselines. The Bayesian-based approach (5-fold) achieves a bpref of 0.5474 and an infNDCG of 0.5133. Importantly, our approach (5-fold) significantly (paired t-test, $p<0.05$) outperforms the task-specific representation baseline in terms of infNDCG for TREC 2012 (0.5133 vs 0.4880). 

When comparing the Bayesian-based approach with the Bo1 \& Semantic QE baseline, which also uses the same set of resources as the Bayesian-based approach, we observe that the Bayesian-based approach, either using the 5-fold or x-collection training regime, significantly ($p<0.05$) outperforms this baseline for both the TREC 2011 and 2012 queries. However, the Bayesian-based approach could not significantly outperform the Bo1 baseline.

% Meanwhile, comparing with the semantically expansion baseline that expands a query using both local statistics and external resources (Bo1 \& Semantic QE), our proposed approach, either using the 5-fold or x-collection regime, significantly ($p<0.05$) outperforms this baseline for both TREC 2011 and 2012 queries.

Additionally, as expected, we find that with a proper setting of the parameter $\lambda_r$ (i.e.\ the $\lambda_r$ that results in the best retrieval performance for each query), the Bayesian-based approach (oracle) can achieve a better retrieval performance. 
In particular, the bpref retrieval performance is increased to 0.5646, while the infNDCG retrieval performance is improved to 0.5393 (+7.69\% and +10.51\% over the task-specific representation baseline, respectively). This shows the potential of the Bayesian-based approach if the $\lambda_r$ value could be effectively set. 
% With proper training data, our approach could further enhance retrieval effectiveness.

%In answer to our first research question, the Bayesian-based approach is effective for the patient search task as it outperforms the three baselines, namely the task-specific representation baseline, the Bo1 baseline and the Bo1 \& Semantic QE baseline. Indeed, the Bayesian-based approach performs significantly better than the Bo1 \& Semantic QE baseline for both TREC 2011 and TREC 2012. Meanwhile, the Bayesian-based approach significantly outperforms the task-specific baseline for the TREC 2012 queries.
%  , since it performs effectively, as previously discussed.

Later, in Section~\ref{c7sAnalysis}, we further analyse the Bayesian-based approach, in comparison with the task-specific representation and the Bo1 baselines.

% 0.5376 when using the 5-fold and the cross-collection cross validation, respectively. However, for TREC 2012, with the fair settings, our approach performs comparable to the task-specific representation baseline. When considering the number of queries that are benefited or harmed by our approach, we observe that our approach is more likely to be helpful than harmful for a given query, when comparing with the task-specific representation baseline. In addition, we observe that when we could effectively set $\lambda_r$ for each query, the retrieval performance is significantly improved.


% Table~\ref{tab:c7Bayesian} shows the retrieval performance of our proposed approach on the TREC 2011 and 2012 test collections. We observe that for the TREC 2011 test collection, our proposed approach (when $\lambda$ is set to 1) improves the bpref retrieval performance from 0.5243 to 0.5478 (+4.48\%) over the task-specific representation baseline where no QE is applied. For TREC 2012 test collection, our proposed QE approach also outperforms the task-specific representation baseline. The infNDCG retrieval performance is improved from 0.4880 to 0.5077 (+4.04\%). However, with the 5-fold and the x-collection settings, our approach could not outperform the task-specific representation baseline. This is partially because of the limited number of available queries for training and testing. Later, in Section~\ref{c7sAnalysis}, we will conduct an analysis to investigate the impact of different $\lambda_r$ values.

% Next, we compare our approach with the baseline where related medical concepts are simply added to the query along with informative concepts from the top-ranked medical records, as suggested by~\cite{king2011trec}. We observe that our approach (when $\lambda_r=1$) significantly outperforms ($p<0.05$) this baseline for both TREC 2011 and 2012 collections.

% Additionally, as expected, we find that with a proper setting of the parameter $\lambda_r$ (i.e.\ the $\lambda_r$ that results in the best retrieval performance for each query), our proposed approach can achieve a better retrieval performance. 
% In particular, the bpref retrieval performance can be increased to 0.5646, while the infNDCG retrieval performance is improved to 0.5393 (+7.69\% and +10.51\% over the task-specific representation baseline, respectively). This shows the potential of our proposed approach. With proper training data, our approach could further enhance retrieval effectiveness.
% This performance significantly outperforms the task-specific representation, local statistics-based QE, and our proposed QE approaches (cross-collection setting), at $p < 0.001$, $p < 0.05$, and $p < 0.05$, respectively. In term of infAP retrieval performance, with the best $\lambda_r$, our proposed approach markedly outperforms the task-specific representation baseline (14.43\% improvement from infAP 0.1920 to 0.2197). Moreover, we find that our QE approach when using both external resources and information from the top-ranked medical records markedly outperform when using only either of them.





\subsection{Experiments with a Stochastic Approach for Inferring Conceptual Relationships}\label{c7sExperimentRandomWalk}

Next, we discuss the evaluation of the stochastic approach for inferring the conceptual relationships to improve the representation of a given query. We compare the retrieval effectiveness of our approach with the same baselines as in Section~\ref{c7sExperimentBayesian}.
% , including when no query expansion is applied, when only a query expansion technique based on the occurrence statistics of medical concepts in the top-ranked medical records (namely, Bo1) is used to enhance the representation of the queries, and when the synonyms of or medical concepts related to a medical concept in a query are used to expand the query (as in~\cite{king2011trec}). 
% In addition, the retrieval performance of the task-specific representation approach (i.e.\ no QE applied) is also reported. 
Table~\ref{tab:c7Salsa} shows the retrieval performances in terms of bpref and infNDCG for TREC 2011 and 2012, respectively.

\begin{table}[tb]
\caption{Retrieval performance of our stochastic approach for inferring relationships between medical concepts in comparison with the three baselines on TREC 2011 and 2012 Medical Records track's queries. Statistical significance (paired t-test) at $p<0.05$ over the task-specific representation and the Bo1 \& Semantic QE baselines are denoted $^t$ and $^{s}$, respectively.}\label{tab:c7Salsa}
  \centering
\resizebox{1.0\textwidth}{!}{
  \begin{tabular}{|l|c|c|}
    \hline
     Approach & bpref (TREC 2011) & infNDCG (TREC 2012) \\ 
    \hline
     Task-specific representation & 0.5243 & 0.4880\\
     + Bo1 & {\bf0.5403} & {\bf0.5129} \\
     + Bo1 \& Semantic QE & 0.3013 & 0.2228\\
%     + Our stochastic analysis approach ($\lambda=1$) & 0.4998 & 0.4508\\
     + Our stochastic approach (5-fold) & 0.5355$^{s}$ & 0.4846$^{s}$ \\
     + Our stochastic approach (x-collection) & 0.5376$^{s}$ & 0.4761$^{s}$ \\
\hline
     + Our stochastic approach (oracle) & 0.5586$^{t,s}$ & 0.5311$^{t,s}$ \\
\hline
  \end{tabular}
}
\end{table}

From Table~\ref{tab:c7Salsa}, we observe that the stochastic approach significantly ($p<0.05$) outperforms the Bo1 \& Semantic QE baseline for both TREC 2011 and 2012 queries. In addition, the stochastic approach
outperforms the task-specific representation baseline for the TREC 2011 queries. Specifically, our approach with the 5-fold and the x-collection training regimes achieves bpref 0.5355 and 0.5376, respectively, in comparison with bpref 0.5243 for the task-specific representation baseline. However, for the TREC 2012 queries, our approach (either with the 5-fold or the x-collection training regime) could not improve the retrieval performance over the task-specific representation baseline. Meanwhile, we observe that the Bo1 baseline performs better than the stochastic approach. This is partly due to the limited number of available queries for training the $\lambda_r$ parameter (in Equation~(\ref{eq:combining})). 
%In answer to our second research question, the stochastic approach is effective for the patient search task, as it outperforms both the task-specific representation and the Bo1 \& Semantic QE baselines. It significantly (paired t-test, $p<0.05$) outperforms the latter baseline for both TREC 2011 and 2012 queries. However, we note that it could not outperform the Bo1 baseline. 
%We further discuss the comparison of the stochastic approach and both the task-specific and the Bo1 baselines in Sections~\ref{c7sAnalysisTask} and~\ref{c7sAnalysisBo1}, respectively.

When considering the oracle setting with $\lambda_r$ set to the most effective value for each query, we observe that the stochastic approach could further improve the retrieval performance significantly. This shows the potential of the stochastic approach. However, we leave for future work the study of a more effective training of $\lambda_r$.

Next, when comparing the two proposed approaches (see Tables~\ref{tab:c7Bayesian} and \ref{tab:c7Salsa}), we observe that the Bayesian-based approach is more effective than the stochastic approach for both TREC 2011 and TREC 2012. For example, with the 5-fold training regime, the Bayesian-based approach achieves infNDCG 0.5133, while the infNDCG performance of the stochastic approach is 0.4846.

% With a proper training data, our approach would be highly effective.

% we observe that Bo1 query expansion outperforms the task-specific representation baseline (i.e.\ no QE) for both TREC 2011 and 2012. Specifically, the retrieval performances improve from bpref 0.5243 to 0.5403 and infNDCG 0.4880 to 0.5129 for TREC 2011 and 2012, respectively. Meanwhile, the existing approach that expand a query with semantically related concepts (Bo1 \& Semantic QE) decreases the retrieval performance. In contrast, we find that our proposed approach outperforms the task-specific representation baseline for TREC 2011. Specifically, our approach achieves bpref 0.5355 and 0.5376 when using the 5-fold and the cross-collection cross validation, respectively. However, for TREC 2012, with the fair settings, our approach performs comparable to the task-specific representation baseline. When considering the number of queries that are benefited or harmed by our approach, we observe that our approach is more likely to be helpful than harmful for a given query, when comparing with the task-specific representation baseline. In addition, we observe that when we could effectively set $\lambda_r$ for each query, the retrieval performance is significantly improved.


\section{Analysis and Discussion}\label{c7sAnalysis}
This section further discusses the performances of the Bayesian-based and the stochastic approaches for inferring the relationships between medical concepts. 
%  that represents medical records and queries by using medical concepts related to the four aspects of the medical decision process. 
Specifically, Section~\ref{c7sFailure} discusses which types of queries are likely to benefit from these proposed approaches, while Sections~\ref{c7sAnalysisTask} and~\ref{c7sAnalysisBo1} compare the performances of the two proposed approaches with the task-specific representation baseline and the Bo1 baseline, respectively, on a per-query basis.

\subsection{Failure Analysis}\label{c7sFailure}

% In this section, we conduct a failure analysis for our task-specific representation approach. In particular, in Figure~\ref{fig:subfigures:task-term7}, we compare the retrieval performances achieved by our task-specific representation approach and the term-based representation approach, on a per-query basis. We use the setting where BM25 and the expCombSUM voting technique are used to rank medical records and patients, respectively, since it is effective for both the term-based representation and our task-specific representation approaches, as shown in Tables~\ref{tab:c7term} and~\ref{tab:c7task}. We also limit the number of voting documents to 5,000. From Figure~\ref{fig:subfigures:qe}, we firstly observe that our proposed approach performs better than the term-based representation approach for 17 out of 34 queries and 31 out of 47 queries for TREC 2011 and 2012, respectively. Meanwhile, our proposed approach decreases the retrieval performances for 17 out of 34 queries from TREC 2011 and 14 out of 47 queries for TREC 2012. These show that our task-specific representation approach is effective for many queries, especially for TREC 2012 queries. 
% Importantly, for the query 179: ``Patients taking atypical antipsychotics without a diagnosis schizophrenia or bipolar depression'', where the negated language is used in the query, our approach markedly improves the retrieval performance from infNDCG 0.0255 to 0.1635.

% \begin{figure}%[htb]
% \centering
% %         }\\%
%         \subfigure[TREC 2011]{
%            \label{fig:task-term:20117}
%            \includegraphics[angle=270,width=140mm,scale=0.5]{images/compare2011.png}
%         }\\%
% 	\subfigure[TREC 2012]{
%            \label{fig:task-term:20127}
%            \includegraphics[angle=270,width=140mm,scale=0.5]{images/compare2012.png}
%         }%\\%
% % \vspace{-3mm}
%     \caption{%
% %         Comparing the performances of our task-specific representation approach against the term-based representation approach using the TREC 2011 and 2012 Medical Records track, on a per-query basis..
%      }%
%    \label{fig:subfigures:task-term7}
% % \vspace{-2mm}
% \end{figure}

In this section, we analyse the performances of both the Bayesian-based and the stochastic approaches in comparison with the task-specific representation baseline to identify which types of queries that are likely to benefit from each of the two approaches. 
Tables~\ref{tab:c7:analysis-bayesian} and~\ref{tab:c7:analysis-salsa} show the numbers of queries benefited or harmed by the Bayesian-based and the stochastic approaches, respectively, which are grouped based on the types of the medical concepts in the queries. 
% The types of medical concepts are based on the four aspects of the medical decision process discussed in Chapter~\ref{cTaskSpecific}. 

From Tables~\ref{tab:c7:analysis-bayesian} and~\ref{tab:c7:analysis-salsa}, we observe that both the Bayesian-based approach and the stochastic approach are more likely to be effective when the query contains medical concepts related to diagnostic tests. In particular, the Bayesian-based approach and the stochastic approach improve the retrieval performance for 57.7\% and 55.8\% of the queries containing medical concepts related to diagnostic tests, respectively. 
% 
% We observe that our learned approach is most likely to be effective when medical concepts related to all of the four aspects can be extracted from the query, followed by the queries that contains medical concepts related to treatment. In particular, our learned approach improves the retrieval performance for 75\% of the queries that contain medical concepts related to all of the four aspects.
% On the other hand, from Table~\ref{tab:c7:analysis-bayesian}, we also observe that our stochastic approach is more likely to benefit the queries containing medical concepts related to diagnostic tests. 
Meanwhile, we observe that the queries that contain medical concepts related to all of the four aspects are less likely to benefit from our two approaches.  
%In answer to the third and the fourth research questions, both the Bayesian-based approach and the stochastic approach are likely to benefit the queries containing medical concepts related to diagnostic tests.

% In general, we observe that our proposed approaches are more likely to be beneficial than harmful, in comparison with the task-specific representation baseline, for a query from each of the categories. The category that is likely to be benefited from our approaches the most is the queries that contain medical concepts related to diagnostic tests. However, the likelihood is not markedly different. In contrast, we observe that the queries that contain medical concepts related to all of the four aspects are less likely to be benefited from our approaches.

% Table~\ref{tab:c6analysis} shows the numbers of queries benefited or harmed by our learned approach, which are grouped based on the types of medical concepts that can be extracted from the queries. Specifically, we define the types of medical concepts based on the four aspects of the medical decision process (namely, symptom, diagnostic test, diagnosis an treatment), discussed in Chapter~\ref{cTaskSpecific}. We observe that our learned approach is most likely to be effective when medical concepts related to all of the four aspects can be extracted from the query, followed by the queries that contains medical concepts related to treatment. In particular, our learned approach improves the retrieval performance for 75\% of the queries that contain medical concepts related to all of the four aspects.

% Next, in Table~\ref{tab:c7:analysis}, we compare the numbers of queries benefited or harmed by our task-specific representation approach, by grouping based on the types of medical concepts that can be extracted from the queries. We find that our proposed approach is likely to be effective when a query contains medical concepts related to all of the four aspects of medical decision process (67.7\%), and when a medical concept related to a treatment or a symptom is identified in a query (63.5\% and 62.9\% respectively). However, our approach is less likely to be beneficial if a medical concept related to diagnostic test can be identified in the query (51.9\%).
%  followed by the queries that contains medical concepts related to treatment. In particular, our LTHN framework improves the retrieval performance for 75\% of the queries that contain medical concepts related to all of the four aspects.


\begin{table}[tb]
\caption{Analysis of our Bayesian-based approach w.r.t.\ the aspects of medical concepts found in the queries. The numbers between the parentheses indicate the number of queries impacted (benefited/harmed) compared to the total number of queries.}\label{tab:c7:analysis-bayesian}
  \centering
\begin{tabular}{|l|c|c|}
    \hline
    Aspects of medical concepts in the query & Benefited & Harmed \\ \hline
    Symptom & 52.9\% (37/70)& 42.9\%(30/70) \\
    Diagnostic test & 57.7\% (30/52) & 38.5\%(20/52)\\
    Diagnosis & 55.9\% (38/68) & 38.2\% (26/68)\\
    Treatment & 55.8\% (29/52) & 40.4\% (21/52)\\
    All 4 & 50\% (16/32) & 46.9\%(15/32) \\
    \hline
  \end{tabular}
% }
\end{table}

\begin{table}[tb]
\caption{Analysis of our stochastic approach w.r.t.\ the aspects of medical concepts found the queries. The numbers between the parentheses indicate the number of queries impacted (benefited/harmed) compared to the total number of queries.}\label{tab:c7:analysis-salsa}
  \centering
  \small
\begin{tabular}{|l|c|c|}
    \hline
    Aspects of medical concepts in the query & Benefited & Harmed \\ \hline
    Symptom & 52.9\% (37/70)& 41.4\%(29/70) \\
    Diagnostic test & 55.8\% (29/52) & 40.4\%(21/52)\\
    Diagnosis & 51.5\% (35/68) & 41.2\% (28/68)\\
    Treatment & 53.8\% (28/52) & 38.5\% (20/52)\\
    All 4 & 50\% (16/32) & 43.8\%(14/32) \\
    \hline
  \end{tabular}
% }
\end{table}

\subsection{Comparison with the Task-Specific Representation Baseline}\label{c7sAnalysisTask}

\begin{figure}[tb]
\centering
%         }\\%
        \subfigure[TREC 2011]{
            \label{fig:CR1}
            \includegraphics[angle=270,width=95mm,scale=0.5]{2011-bayesian5f-baseline.png}
	}\\%
        \subfigure[TREC 2012]{
           \label{fig:CR2}
           \includegraphics[angle=270,width=95mm,scale=0.5]{2012-bayesian5f-baseline.png}
        } 
    \caption{%
        The retrieval performances of our Bayesian-based approach for inferring the conceptual relationships and the task-specific representation baseline on a per-query basis, evaluated using the TREC 2011 and 2012 Medical Records Track.
     }%
   \label{fig:ch7:bayesian}
% \vspace{-2mm}
\end{figure}

Next, we compare the retrieval performance of the Bayesian-based and the stochastic approaches with the task-specific representation baseline on a per-query basis. We choose to discuss only the 5-fold setting as it is the most effective. 



\begin{figure}[tb]
\centering
%         }\\%
        \subfigure[TREC 2011]{
            \label{fig:CR1}
            \includegraphics[angle=270,width=95mm,scale=0.5]{2011-salsa5f-baseline.png}
	}\\%
        \subfigure[TREC 2012]{
           \label{fig:CR2}
           \includegraphics[angle=270,width=95mm,scale=0.5]{2012-salsa5f-baseline.png}
        } 
    \caption{%
        The retrieval performances of our stochastic approach for inferring the conceptual relationships and the task-specific representation baseline on a per-query basis, evaluated using the TREC 2011 and 2012 Medical Records Track.
     }%
   \label{fig:ch7:salsa}
% \vspace{-2mm}
\end{figure}

We first discuss the performance of the Bayesian-based approach. From Figure~\ref{fig:ch7:bayesian}, we observe that in general the Bayesian-based approach performs better than the task-specific representation baseline. In particular, for the TREC 2011 queries, the Bayesian-based approach outperforms the task-specific representation baseline for 22 out of 34 queries, while it performs worse than the baseline for 10 queries. We observe that the Bayesian-based approach is likely to be more effective for difficult queries. For instance, the Bayesian-based approach could improve the retrieval performance of the queries with a bpref retrieval performance less than 0.25 for 5 out of 6 queries (e.g.\ queries\# 108, 111, 121, and 125). Meanwhile, for the TREC 2012 queries, the Bayesian-based approach outperforms the task-specific representation baseline for 23 out of 47 queries, while performing worse than the baseline for 22 queries.
% This supports our hypothesis for using query performance predictors as our features that difficult are likely to be benefited from our approach. 

% for a particular group of queries (e.g.\ queries 101, 116, 126, 146, 151 and 182). This shows that our approach could be helpful for a particular types of queries. Later, in Section~\ref{c7sAnalysis}, we analyse which types of queries are likely to be benefited from our stochastic analysis for inferring conceptual relationship approach.

%\begin{figure}[tb]
%\centering
%%         }\\%
%        \subfigure[TREC 2011]{
%            \label{fig:CR1}
%            \includegraphics[angle=270,width=115mm,scale=0.5]{images/2011-bayesian5f-baseline.eps}
%	}\\%
%        \subfigure[TREC 2012]{
%           \label{fig:CR2}
%           \includegraphics[angle=270,width=115mm,scale=0.5]{images/2012-bayesian5f-baseline.eps}
%        } 
%    \caption{%
%        The retrieval performances of our Bayesian-based approach for inferring the conceptual relationships and the task-specific representation baseline on a per-query basis, evaluated using the TREC 2011 and 2012 Medical Records Track.
%     }%
%   \label{fig:ch7:bayesian}
%% \vspace{-2mm}
%\end{figure}
%
%\begin{figure}[tb]
%\centering
%%         }\\%
%        \subfigure[TREC 2011]{
%            \label{fig:CR1}
%            \includegraphics[angle=270,width=115mm,scale=0.5]{images/2011-salsa5f-baseline.eps}
%	}\\%
%        \subfigure[TREC 2012]{
%           \label{fig:CR2}
%           \includegraphics[angle=270,width=115mm,scale=0.5]{images/2012-salsa5f-baseline.eps}
%        } 
%    \caption{%
%        The retrieval performances of our stochastic approach for inferring the conceptual relationships and the task-specific representation baseline on a per-query basis, evaluated using the TREC 2011 and 2012 Medical Records Track.
%     }%
%   \label{fig:ch7:salsa}
%% \vspace{-2mm}
%\end{figure}

% In addition, when considering the number of queries that are benefited or harmed by our approach, we observe that our approach is more likely to be helpful than harmful for a given query, when comparing with the task-specific representation baseline.

In Figure~\ref{fig:ch7:salsa}, we show the per-query retrieval effectiveness of the stochastic approach in comparison with the task-specific representation baseline. We observe that the stochastic approach outperforms this baseline for the majority of the queries. Indeed, our approach is more effective for 18 out of 34 queries and for 24 out of 47 queries from TREC 2011 and 2012, respectively. Similar to the Bayesian-based approach, we also observe that the stochastic approach tends to be effective for difficult queries. 
% , which is in line with the finding in Section~\ref{c7sExperimentBayesian}. 
Specifically, for the queries where the task-specific representation baseline obtains a retrieval performance less than 0.25 (bpref for TREC 2011 and infNDCG for TREC 2012), the stochastic approach outperforms the task-specific representation baseline for 7 out of 11 queries for TREC 2011 and for 5 out of 6 for TREC 2012. 
% This again supports the effectiveness of our proposed approach for inferring relationships between medical concepts using associated rules extracted from external resources.

% 
%\begin{figure}[tb]
%\centering
%%         }\\%
%        \subfigure[TREC 2011]{
%            \label{fig:CR1}
%            \includegraphics[angle=270,width=115mm,scale=0.5]{images/2011-salsa5f-baseline.eps}
%	}\\%
%        \subfigure[TREC 2012]{
%           \label{fig:CR2}
%           \includegraphics[angle=270,width=115mm,scale=0.5]{images/2012-salsa5f-baseline.eps}
%        } 
%    \caption{%
%        The retrieval performances of our stochastic approach for inferring the conceptual relationships and the task-specific representation baseline on a per-query basis, evaluated using the TREC 2011 and 2012 Medical Records Track.
%     }%
%   \label{fig:ch7:salsa}
%% \vspace{-2mm}
%\end{figure}

\subsection{Comparison with the Bo1 Baseline}\label{c7sAnalysisBo1}

%bayesian

This section discusses the retrieval performances of the Bayesian-based and the stochastic approaches in comparison with the Bo1 baseline, which is a stronger baseline. We compare the retrieval performances on a per-query basis.

We first discuss the retrieval effectiveness of the Bayesian-based approach. From Figure~\ref{fig:ch7:bayesian-bo1}, we observe that the Bayesian-based approach performs comparable to the Bo1 baseline. Indeed, our approach outperforms the Bo1 baseline for 16 out of 34 queries and for 21 out of 47 queries for TREC 2011 and TREC 2012, respectively. Meanwhile, the Bo1 baseline performs better than our approach for 12 and 20 queries for TREC 2011 and 2012. 
% 
% Next, we compare the performance on the difficult queries for both TREC 2011 and 2012 (i.e.\ queries that obtain retrieval performance $<$ 0.25 when do not apply query expansion). We observe that out of 17 queries, our approach performs better than the Bo1 baseline for 7 queries, while performs worse than the Bo1 baseline 6 queries. This shows that both our Baysian-based approach and the Bo1 baseline are effective for the difficult queries.
% , the Bo1 baseline is also helpful for some difficult queries.

\begin{figure}[tb]
\centering
%         }\\%
        \subfigure[TREC 2011]{
            \label{fig:CR1}
            \includegraphics[angle=270,width=95mm,scale=0.5]{2011-bayesian5f-bo1.png}
	}\\%
        \subfigure[TREC 2012]{
           \label{fig:CR2}
           \includegraphics[angle=270,width=95mm,scale=0.5]{2012-bayesian5f-bo1.png}
        } 
    \caption{%
        The retrieval performances of our Bayesian-based approach for inferring the conceptual relationships and the Bo1 query baseline on a per-query basis, evaluated using the TREC 2011 and 2012 Medical Records Track.
     }%
   \label{fig:ch7:bayesian-bo1}
% \vspace{-2mm}
\end{figure}

%salsa

Next, we discuss the retrieval performance of the proposed stochastic approach. From Figure~\ref{fig:ch7:salsa-bo1}, we observe that the Bo1 baseline benefits more queries than the stochastic approach. Specifically, the Bo1 baseline outperforms the stochastic approach for 16 (resp.\ 23) out of 34 (resp.\ 47) queries for TREC 2011 (resp.\ TREC 2012), while the stochastic approach performs better for 11 and 20 queries for TREC 2011 and 2012, respectively. However, this is expected, as the Bo1 baseline achieves a better retrieval performance than the stochastic approach, as shown in Table~\ref{tab:c7Salsa}. Nevertheless, when considering the performance on \emph{the difficult queries} (i.e.\ queries that obtain retrieval performance $<$ 0.25 when query expansion is not applied), we observe that the stochastic approach performs better than the Bo1 baseline for 8 out of 16 queries across the TREC 2011 and 2012, while it performs worse than the Bo1 baseline for only 3 queries.

%Importantly, from this analysis, we observe that the Bayesian-based approach is in general effective, and in particular more effective than the Bo1 baseline. On the other hand, the stochastic approach is more effective for the difficult queries.
%  (i.e.\ queries with a retrieval performance less than 0.25 in terms of either bpref or infNDCG).

From the per-query performance comparison in Sections~\ref{c7sAnalysisTask} and~\ref{c7sAnalysisBo1}, we observe that both the Bayesian-based and the stochastic approaches are more likely to benefit the difficult queries (i.e.\ the queries that obtain retrieval performance $<$ 0.25 when do not apply query expansion).
% , answering the third and the fourth research questions.

\begin{figure}[tb]
\centering
%         }\\%
        \subfigure[TREC 2011]{
            \label{fig:CR1}
            \includegraphics[angle=270,width=95mm,scale=0.5]{2011-salsa5f-bo1.png}
	}\\%
        \subfigure[TREC 2012]{
           \label{fig:CR2}
           \includegraphics[angle=270,width=95mm,scale=0.5]{2012-salsa5f-bo1.png}
        } 
    \caption{%
        The retrieval performances of our stochastic approach for inferring the conceptual relationships and the Bo1 baseline on a per-query basis, evaluated using the TREC 2011 and 2012 Medical Records Track.
     }%
   \label{fig:ch7:salsa-bo1}
% \vspace{-2mm}
\end{figure}


\section{Conclusions}\label{Conclusions}

We have proposed a novel approach that uncovers implicit knowledge in medical records and queries. In particular, the proposed approach to infer the relationships between medical conditions by using both external resources (e.g. ontologies and health-related websites) and the local statistics of top-ranked medical records to reformulate the queries. 
% Building upon a conceptual representation approach. 
In particular, we extracted association rules of relationships between medical concepts from external resources. Then, to infer the relationships of medical concepts from the association rules, we introduced two techniques based on Bayes' theorem and a stochastic analysis, respectively. The medical concepts inferred using the association rules are combined with the medical concepts derived using a pseudo-relevance feedback technique in order to improve the representation of the query.
% We firstly showed how to extract association rules between medical concepts from external resources, including free-text documents and ontologies, in Section~\ref{c7sRules}. 
% Then, we investigated two approaches to take into account both medical concepts inferred using a pseudo-relevance feedback approach and the association rules of relationships between medical concepts. 
% we discussed two approaches to exploit these association rules to 
% These two approaches infer the relationships between medical concepts in the association rule database by using a Bayes' theorem (Sections~\ref{All}) and a stochastic analysis (Section~\ref{c7sRandomWalk}), respectively. 
% Each of the two approaches is incorporated with a local statistics approach in a ranking model proposed in Section~\ref{c7sModel}. 
From the experimental results, we observed that with a fair setting the Bayesian-based approach improved the retrieval performance by up to 10.51\% over the baseline that does not apply a QE technique. Meanwhile, the stochastic approach was likely to perform effectively for difficult queries (i.e.\ the queries where the retrieval performance of the original queries are less than 0.25 in term of bpref and infNDCG for TREC 2011 and 2012, respectively). In addition, we observed that both the Bayesian-based and the stochastic approaches were less likely to be effective for the queries that contain medical concepts related to all of the four aspects of the medical decision process. For future work, we aim to investigate a more effective technique for extracting association rules from different external resources and compare which resources are more useful for the patient search task.

% We have proposed our QE approach that infers the relationships between medical concepts to handle the implicit knowledge challenge. In particular, we represent only concepts related to the four aspects of the medical decision criteria, which are essential information that medical practitioners take into account when dealing with patients. Then, our QE approach models relationships between concepts obtained from both domain-specific resources, such as, ontologies and health-related websites, and the local statistics of top-ranked medical records to reformulate the queries. Our results show that our proposed QE approach could effectively enhance the representation of the queries, as it could significantly improve the retrieval performance over an effective concept-based representation baseline
% up to 14.43\%. Furthermore, we showed that our proposed approach could work effectively with a term-based representation approach, since when combining the relevance scores computed using both approaches, the retrieval performance is markedly increased. In particular, the achieved retrieval performance is comparable to the best systems at the TREC 2011 and 2012 Medical Records track, who also deployed other additional techniques (e.g.\ document segmentation, and document clustering).

% For future work, we plan to investigate machine learning techniques to learn to properly set the $\lambda_r$ parameter of on a per-query basis, and to learn to apply only effective association rules based on the importance and the types of medical concepts to improve the representation of the queries.

%\begin{acknowledgements}
%If you'd like to thank anyone, place your comments here
%and remove the percent signs.
%\end{acknowledgements}

% BibTeX users please use one of
% \bibliographystyle{spbasic}      % basic style, author-year citations
%\bibliographystyle{spmpsci}      % mathematics and physical sciences
%\bibliographystyle{spphys}       % APS-like style for physics
%\bibliography{}   % name your BibTeX data base
\bibliographystyle{unsrt}
\bibliography{limsopatham2014medicalir}

% Non-BibTeX users please use
% \begin{thebibliography}{}
% %
% % and use \bibitem to create references. Consult the Instructions
% % for authors for reference list style.
% %
% \bibitem{RefJ}
% % Format for Journal Reference
% Author, Article title, Journal, Volume, page numbers (year)
% % Format for books
% \bibitem{RefB}
% Author, Book title, page numbers. Publisher, place (year)
% % etc
% \end{thebibliography}

\end{document}
% end of file template.tex
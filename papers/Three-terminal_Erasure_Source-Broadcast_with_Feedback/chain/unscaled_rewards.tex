\subsubsection{Unscaled Rewards}
\label{subsec:unscaled_rewards}

% --------------------------------------------------------------
% R bar inf
% --------------------------------------------------------------

%\begin{mydef}
%	Let $\barRinfij{i}{j} = \lim_{n \to \infty} \barRij{i}{j}$ be the long-term value of $\barRij{i}{j}$.
%\end{mydef}

%\begin{mydef}
%	Let $\barRinf$ be the $|\myState| \times |\myState|$ matrix whose $(i, j)$th entry is given by $\barRinfij{i}{j}$.
%\end{mydef}

%\begin{theorem}
%	\label{thm:barR_inf}
%	Let $\transM^{\infty}$ be the steady state transition matrix in Lemma~\ref{lem:transM_infty}. Then $\barRinf = \hatRinf \odot \transM^{\infty}$
%\end{theorem}

Having found an expression for $\hatR$ in the previous section, we now show that given initial state $\Si{0} = i$, the expected accumulated reward at time $n$ is given by the sum over all columns of the $i$th row of the matrix $\hatR$.
%give the relationship between $\barRi{i}$ and $\hatRij{i}{j}$ according to the law of total probability as follows

%\begin{myTheorem}
\begin{theorem}
\label{thm:barRi}
	Let $\barRi{i}$ be defined as in Definition~\ref{def:barRi}.  Then
\begin{align}
	\barRi{i} &=  \sum_{j = 1}^{|\myState|} \hatRij{i}{j}
%	\addtocounter{cnt}{1}
%	\addtocounter{cnt}{1}	
%	&\stackrel{(\alph{cnt})}{=}  k - \sum_{i = 0}^{k} \epsilon_{2}^{\nRepi{i}} \\
\end{align}	
%\end{myTheorem}
\end{theorem}
\begin{proof}
	By the law of total expectation we have that 
	\setcounter{cnt}{1}
	\begin{align}
		\barRi{i} &= \sum_{j = 1}^{|\myState|} \barRij{i}{j} \Prob(\Si{n} = j | \Si{0} = i).
	\end{align}
	We conclude the result in Theorem~\ref{thm:barRi} holds by Definition~\ref{def:hatRij}.
\end{proof}

\begin{mycor}
\label{cor:barRinfi}
	Let $\barRinf(i)$ be defined as in Definition~\ref{def:barRinfi}.  Then
\begin{align}
	\barRinf(i) &=  \sum_{j = 1}^{|\myState|} \hatRinf(i, j).
\end{align}	
\end{mycor}

Similarly, given $\barRi{i}$ and a prior distribution over initial states, we can use the law of total expectation to calculate the unconditional expected value of $\Rn$. 

%\begin{myTheorem}
\begin{theorem}
\label{thm:barR_prior}
	Let $\Rn$ be as defined in Definition~\ref{def:Rn}. If a prior distribution $\Prob(\Si{0})$ over the initial state $\Si{0}$ is known, then $\mathbb{E}\Rn$, the expected value of $\Rn$ is given by
	\begin{equation}
		\mathbb{E}\Rn = \sum_{i = 1}^{|\myState|} \barRi{i} \Prob(\Si{0} = i).
	\end{equation}
%\end{myTheorem}
\end{theorem}
\begin{mycor}
	Let $\barRinf = \lim_{n \to \infty} \mathbb{E}\Rn$.  Then 
\label{cor:barRinf}
\begin{align}
	\barRinf &=  \sum_{i= 1}^{|\myState|} \barRinf(i)\Prob(\Si{0} = i).
\end{align}	
\end{mycor}

Finally, it may be of interest to know the expected accumulated reward after absorption given initial state~$i$ and absorbing state~$j$.

%\begin{myTheorem}
\begin{theorem}
\label{thm:barRinf_absorb}
	Let $i \in \StateTrans$ and $j \in \StateAbs$.  Let $\barRinf(i, j)$ represent the expected accumulated reward after absorption given initial state~$i$ and absorbing state~$j$.  Then 
	\begin{align}
		\barRinf(i, j) &=  \frac{1}{\transM^{\infty}(i, j)}\hatRinf(i, j), 
	\end{align}
	where $\transM^{\infty}(i, j)$ is the $(i, j)th$ entry of $\transM^{\infty}$ given in Lemma~\ref{lem:transM_infty}.
%\end{myTheorem}
\end{theorem}

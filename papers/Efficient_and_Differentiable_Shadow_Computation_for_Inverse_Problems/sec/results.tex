%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\section{Results}
%
\label{sec:results}
%
Our method is implemented in Pytorch~\cite{NEURIPS2019_9015}.
%
We use an Intel(R) Xeon(R) Gold 6144 CPU processing unit and a Nvidia V100 graphics card for all results.
%
The supplemental video includes more visual results and comparisons.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\paragraph{Evaluation Dataset.}
%
To evaluate our approach, we create different virtual scenes containing various challenging geometries, textures, and lighting conditions.
%
In total, we use 7 different mesh models, e.g. animals and humans.
%
We acquired 10 environments maps~\cite{laval_hdr} containing various lighting conditions, e.g. outdoor skies.
%
These environment maps are projected onto the SH space.
%
We use a ray tracing approach~\cite{li2018differentiable} to render the reference images, where we choose 1024 sample rays per pixel to obtain a noise free reference.
%
Fig.~\ref{fig:scenes} shows some examples.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\begin{figure}
	%
	\centering
	\includegraphics[width=0.8\linewidth]{figures/dataset1.PNG} 
	%
	\caption
	{
	%
		Example scenes of our evaluation dataset.
		%
		Note that geometry as well as lighting conditions are very complex making it a challenge for inverse problems.
		%
	}
	%
	\label{fig:scenes}
	%
\end{figure}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\subsection{Inverse Problems}
%
We conduct several experiments where the individual scene parameters are reconstructed from monocular images using analysis-by-synthesis optimization (Sec.~\ref{sec:IBO}). 
%
We compare to Redner~\cite{li2018differentiable}, which models global illumination using ray tracing, and to the implementation of Ravi~\etal~\cite{ravi2020pytorch3d} of a rasterization-based direct illumination (DI) method~\cite{10.1145/383259.383317}, which uses SH shading without shadows.
%
For Redner, we set the number of rays per pixel to 64 for all experiments, which was the smallest number that still gave us noise free renderings.
%
We use single bounce, as we do not evaluate indirect illumination effects.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%s
\paragraph{Texture Optimization.}
%
\label{sec:texOpt}
%
First, we evaluate our approach for the purpose of texture estimation.
%
Given the geometry, lighting, and one reference image of the scene, we optimize for the diffuse albedo texture, initialized as pure white, using the different rendering methods.
%
Note that the reference images shown in Fig.~\ref{fig:texResult} contain shadows cast by the occluders, as well as self-shadows which makes it particularly challenging to recover the correct albedo.
%
In the first row, the texture of the cow is optimized.
%
However, a large sphere (not visible in the image) is also placed in the scene blocking the light coming from a large area of the environment map.
%
In the second row, the texture of the ground plane should be recovered onto which the armadillo is casting a shadow.
%
In both cases, our approach recovers albedo which is almost free from shadows, due to our shadow-aware renderer.
%
Note that DI method~\cite{ravi2020pytorch3d} cannot account for the shadow which manifests in the bright initialization (top row), as the occluding sphere is ignored and all the light arrives at the surface of the cow.
%
More importantly, these methods bake the shadows into the texture. 
%
In contrast, Redner~\cite{li2018differentiable} also obtains shadow-free textures but at a significantly slower speed.
%
This is also quantitatively evaluated in Tab.~\ref{tab:texture} where we measure the mean squared pixel error (MSE) between the optimized and the ground truth texture maps for all pixels that are visible in the rendered image.
%
Although Redner performs slightly better, our approach is very close in quality while being much faster.
%
Our method clearly outperforms the direct illumination renderer. 
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\begin{figure*}
%
\includegraphics[width=\textwidth]{figures/texture.PNG} 
%
\caption
{
%
Texture optimization results.
%
From left to right. 
%
Ground truth rendering and texture map. 
%
Rendering with initial and optimized texture map as well as the optimized texture map for Redner, DI and our method.
%
Note that our approach outperforms DI method as they cannot remove the shadow in the texture and we are also close to Redner~\cite{li2018differentiable} while being much faster.
%
}
%
\label{fig:texResult}
%
\end{figure*}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\begin{table}
	\begin{center}
		\begin{tabular}{|c|c|}
			%
			\hline
			\multicolumn{2}{|c|}{\textit{Texture Reconstruction Accuracy}} \\
			\hline
			%
			\textbf{Method}                                             & \textbf{MSE}$\downarrow$     	    \\
			%
			\hline
			%
			Redner~\cite{li2018differentiable}							& \textbf{0.0213}		           	\\
			DI~\cite{ravi2020pytorch3d} 			                    & 0.2763		           			\\
			\hline
			Ours    									   	            & 0.0272		  				    \\
			%
			\hline
			%
		\end{tabular}
	\end{center}
	%	
	\caption
	{
		%
		Texture reconstruction accuracy averaged over 10 scenes.
		%
		We quantitatively outperform DI method  using mean squared error, as shadows are  baked in the texture for these approaches.
		%
	}
	%
	\label{tab:texture}
	%
\end{table}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\paragraph{Lighting Optimization.}
%
Next, we evaluate our approach in terms of lighting reconstruction.
%
Here the geometry and albedo texture of the object are known, and we are interested in reconstructing the lighting from a reference image.
%
The reference images are shown in the left column of Fig.~\ref{fig:lightResult}.
%
We initialize all methods with no lights, i.e. all SH coefficients are set to zero.
%
The converged results are shown in Fig.~\ref{fig:lightResult} for two different scenes.
%
Moreover, we relight new objects with the optimized scene lighting, and compare it to the ground truth for an additional evaluation of the estimate.
%
We do not directly compute quantitative errors on the estimated environment maps because it is not easy to compute the visible regions in the environment map. 
%
Computing the error on the full environment map would not be indicative of the quality, as the occluded regions could be arbitrarily different for each method. 
%
Our indirect metric using a different object does not face this issue.
%
We outperform the DI method, as they cannot model the shadows.
%
As expected, the ray tracing method gives the most accurate results at the cost of a slow runtime.
%
In Tab.~\ref{tab:lighting}, we further quantitatively evaluate the accuracy of the lighting estimation \textit{on the new objects} in terms of mean squared error (MSE) by comparing the scene rendering with the ground truth.
%
Our method offers a good compromise between the more accurate but slow ray tracing approach and the more efficient but less accurate direct illumination method.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\begin{figure*}
	%
	\includegraphics[width=\linewidth]{figures/lighting.png} 
	%
	\caption
	{
	    %   
		Lighting optimization results. 
		%
		From left to right. 
		%
		The reference image used to optimize the scene lighting.
		%
	    The rendered scene with the optimized scene lighting.
	    %
        The ground truth image for a new object.
        %
        The rendering of the new object using the previously optimized scene lighting.
	    %
	    Note that our approach gives a good compromise between runtime and accuracy, compared to other approaches.
		%
	}
	%
	\label{fig:lightResult}
	%
\end{figure*}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\begin{table}
	\begin{center}
		\begin{tabular}{|c|c|}
			%
			\hline
			\multicolumn{2}{|c|}{\textit{Lighting Estimation Accuracy}} \\
			\hline
			%
			\textbf{Method}                                           & \textbf{MSE}$\downarrow$ 	   \\
			%
			\hline
			%
			Redner~\cite{li2018differentiable}						  & \textbf{1.854e-3}	           \\
			DI~\cite{ravi2020pytorch3d} 						      & 9.512e-3              		   \\
			\hline
			Ours    									   	     	  & 2.667e-3                  	   \\
			%
			\hline
			%
		\end{tabular}
	\end{center}
	%	
	\caption
	{
		%
		Lighting estimation accuracy averaged over 10 different scenes.
		%
		Here, we evaluate the mean squared error between the rendered  and  ground truth  images.
		%
		Our approach outperforms the direct illumination method, and is close to the ray tracing method. 
	    %
	}
	%
	\label{tab:lighting}
	%
\end{table}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\paragraph{6D Pose Optimization.}
%
Here, we optimize the 6D pose of the object with known light and texture, see Fig.~\ref{fig:Pose} and Tab.~\ref{tab:Pose} from one image.
%
Our renderer provides useful supervision for correctly optimizing the rigid pose which can be seen qualitatively as well as quantitatively.
%
Compared to previous methods, we clearly outperform DI method as they cannot use the shadow cues as signal.
%
In contrast, the cast shadows directly provide supervision for the unknown pose in our case.
%
Interestingly, we also outperform the ray tracing approach~\cite{li2018differentiable}.
%
We hypothesize that it is difficult for ray tracing renderers to optimize the geometry because of their local nature of computation. 
%
The gradients at any point in the scene are propagated through the rays which reach this point.
%
Thus, the gradients mostly rely on local properties of the scene. 
%
In contrast, the shadow computation at any point in our renderer directly depends on the global scene geometry, which leads to less noisy gradients. 
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\begin{figure}
	%
	\includegraphics[width=\linewidth]{figures/pose.PNG} 
	%
	\caption
	{
		6D Pose optimization result. 
        %
		We outperform both direct illumination and global illumination methods.
		%
	}
	%
	\label{fig:Pose}
	%
\end{figure}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\begin{table}
	\begin{center}
		\begin{tabular}{|c|c|c|c|}
			%
			\hline
			\multicolumn{4}{|c|}{\textit{Pose Estimation Accuracy}} \\
			\hline
			%
			\textbf{Method}                                             & \textbf{MDE}  $\downarrow$        & \textbf{RE} $\downarrow$ 		  & \textbf{TE} $\downarrow$    \\
			%
			\hline
			%
			Redner~\cite{li2018differentiable}							& 12.72		                            & 0.2289           	   	           & \textbf{4.633e-4}     \\
			DI~\cite{ravi2020pytorch3d} 							    & 23.53	                                &  1.0154      		                & 7.719e-2     \\
			\hline
			Ours    									   	            & \textbf{6.420}	                        & \textbf{0.0702}   	            & 1.075e-3     \\
			%
			\hline
			%
		\end{tabular}
	\end{center}
	%	
	\caption
	{
		%
		Pose reconstruction accuracy averaged over 10 different scenes.
		%
		The mean distance error is calculated between the ground truth and  optimized vertex positions. 
		%
		We report MDE as a percentage of the diagonal length of the bounding box around the ground truth shape.
		%
		Rotation error (RE) is calculated as the angle between the rotations, and translation error (TE) as the squared distance between the translations.
		%
		We outperform both approaches.
	    %
	}
	%
	\label{tab:Pose}
	%
\end{table}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\paragraph{Geometry Optimization.}
%
In Fig.~\ref{fig:geometry} and Tab.~\ref{tab:Geometry}, we evaluate how our renderer can be used for estimating the geometric deformation of an object, given the \textit{undeformed} template as well as the lighting and albedo of the scene.
%
To this end, the rotation and translation parameters of the embedded graph are optimized.
%
Like in the case of global pose reconstruction, our approach outperforms the previous works~\cite{li2018differentiable, ravi2020pytorch3d} both qualitatively and quantitatively.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\begin{figure}
	%
	\includegraphics[width=\linewidth]{figures/geometry1.png} 
	%
	\caption
	{
	    %
		Geometry optimization results. 
		%
		We outperform both direct illumination and global illumination methods.
		%
	}
	%
	\label{fig:geometry}
	%
\end{figure}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\begin{table}
	\begin{center}
		\begin{tabular}{|c|c|}
			%
			\hline
			\multicolumn{2}{|c|}{\textit{Geometry Reconstruction Accuracy}} \\
			\hline
			%
			\textbf{Method}                                             & \textbf{MDE}  $\downarrow$    		  \\
			%
			\hline
			%
			Redner~\cite{li2018differentiable}							& 18.66		                  	   	              \\
			DI~\cite{ravi2020pytorch3d} 							    & 28.98	                           		          \\
			\hline
			Ours    									   	            & \textbf{11.80}	                    	          \\
			%
			\hline
			%
		\end{tabular}
	\end{center}
	%	
	\caption
	{
		%
		Geometry reconstruction accuracy averaged over 10 different scenes.
		%
		We outperform both approaches in terms of MDE (explained in Tab.~\ref{tab:Pose}).
	    %
	}
	%
	\label{tab:Geometry}
	%
\end{table}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\subsection{Runtime}
%
We evaluate the runtime of our approach and compare it with the state of the art.
%
Tab.~\ref{tab:runtime} reports the average runtime per iteration in milliseconds (ms) and frames per second (fps).
%
Our approach is significantly (up to two orders of magnitude) faster than the ray tracing  approach~\cite{li2018differentiable}.
%
We are close to the runtime of the method of Ravi~\etal~\cite{ravi2020pytorch3d} for most tasks except for pose and geometry estimation.
%
This shows that our shadow computation requires a minimal overhead compared to DI method, with the advantage of higher-quality reconstruction of all scene properties.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\begin{table}
	\begin{center}
	
		\begin{tabular}{|c|c|c|c|c|}
			%
			\hline
			\multicolumn{5}{|c|}{\textit{Runtime Performance(in ms)$\downarrow$ }} \\
			\hline
			%
			\textbf{Method}                                             & \textbf{Texture }      & \textbf{Light }              & 
			\textbf{Pose } 	 & 
			\textbf{Geometry }   \\
			%
			\hline
			%
			Redner~\cite{li2018differentiable}						& 3261  & 2938  & 4473   &4897                        \\
			DI~\cite{ravi2020pytorch3d} 							& \textbf{18}  & \textbf{18}  & \textbf{81} & \textbf{233}
			      		                    \\
			\hline
			Ours    									   	            & \textbf{18}	& \textbf{18}  & 216 &391                                          
			\\     
			%
			\hline
			%
		\end{tabular}
	\end{center}
	%	
	\caption
	{
		%
		Runtime performance averaged over multiple iterations including forward and backward passes.
		%
		Our approach clearly outperforms the ray tracing renderer, and is  close to the DI method, indicating that our shadow computation is efficient.
	    %
	}
	%
	\label{tab:runtime}
	%
\end{table}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\subsection{Reconstruction from Shadows}
%
In Fig.~\ref{fig:shadow}, we show how the shadow alone can be used to optimize the object deformations. 
%
We optimize the embedded graph deformation parameters and compare the rendered shadows with the reference shadow image.
%
This demonstrates that shadows offer very strong cues about the scenes. 
%
Our method, in contrast to direct illumination renderers can utilize these cues for accurate reconstruction.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\begin{figure}
	%
	\includegraphics[width=\linewidth]{figures/shadow1.png} 
	%
	\caption
	{
		Shadow fitting result.
		%
		The shadow alone can be used to recover the geometric deformations.
	}
	%
	\label{fig:shadow}
	%
\end{figure}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\subsection{Ablation}
%
In Tab.~\ref{tab:ablation}, we study the influence of the number of spheres used to approximate the underlying geometry of the object.
%
We solve for the lighting reconstruction, see Fig.~\ref{fig:lightResult}.
%
Even a small number like 100 spheres can approximate the geometry quite well.
%
Adding more spheres improves the quality of reconstruction.
%
We also evaluate the influence of the number of spherical harmonics coeffcients while fixing the number of spheres to 100 using the same setting.
%
A small number of coefficients can already approximate the scene lighting quite well.
%
Adding more coefficients leads to better results as higher frequency lighting can be captured as well.
%
Importantly, for all experiments with different numbers of spheres and lighting coefficients,  we achieve a runtime of 18ms due to GPU parallelization .
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\begin{table}
	\begin{center}
		\begin{tabular}{|c|c|c|c|c|}
			%
			\hline
			\multicolumn{5}{|c|}{\textit{Ablation Study}} \\
			\hline
			%
		    \textbf{Spheres}                                        & 	50 	                    & 	100 	            & 		150          & 	200            	     \\
			\textbf{MSE}$\downarrow \times 10^{-3}$                 & 1.445                     & 1.349                 & 1.336            & \textbf{1.335}                      \\


			%
			\hline
			%
		    \textbf{Coeffs}                                         & 16                        &  25 	               & 36            &    49                           	    \\
			\textbf{MSE}$\downarrow \times 10^{-3}$                 & 2.437                     & 1.982                 & 1.629          & \textbf{1.493}              \\
			%
			\hline
			%
		\end{tabular}
	\end{center}
	%	
	\caption
	{
		%
		Ablation study.
		%
		Even a small number of spheres and lighting coefficients can lead to plausible results.
		%
		Adding more spheres and lighting coefficients constantly improves the result as surface details can be better approximated and higher frequency lighting can be modeled.
	    %
	}
	%
	\label{tab:ablation}
	%
\end{table}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
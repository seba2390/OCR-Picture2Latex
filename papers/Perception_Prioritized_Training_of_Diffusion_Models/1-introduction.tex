\section{Introduction}
\label{sec:intro}

Diffusion models~\cite{sohl2015deep,ho2020denoising}, a recent family of generative models, have achieved remarkable image generation performance. Diffusion models have been rapidly studied, as they offer several desirable properties for image synthesis, including stable training, easy model scaling, and good distribution coverage~\cite{nichol2021improved}. Starting from Ho et al.~\cite{ho2020denoising}, recent works~\cite{nichol2021improved,dhariwal2021diffusion,song2020score} have shown that the diffusion models can render high-fidelity images comparable to those generated by generative adversarial networks (GANs)~\cite{goodfellow2014generative}, especially in class-conditional settings, by relying on additional efforts such as classifier guidance~\cite{dhariwal2021diffusion} and cascaded models~\cite{saharia2021image}. However, the unconditional generation of single models still has considerable room for improvement, and performance has not been explored for various high-resolution datasets (e.g., FFHQ~\cite{stylegan}, MetFaces~\cite{karras2020training}) where other families of generative models~\cite{stylegan,vahdat2020nvae,kingma2018glow,esser2021taming,brock2018large} mainly compete.

Starting from tractable noise distribution, a diffusion model generates images by progressively removing noise. To achieve this, a model learns the reverse of the predefined \textit{diffusion process}, which sequentially corrupts the contents of an image with various levels of noise. A model is trained by optimizing the sum of denoising score matching losses~\cite{vincent2011connection} for various noise levels~\cite{song2019generative}, which aims to learn the recovery of clean images from corrupted images. 
Instead of using a simple sum of losses, Ho et al.~\cite{ho2020denoising} observed that their empirically obtained weighted sum of losses was more beneficial to sample quality. Their weighted objective is the current de facto standard objective for training diffusion models~\cite{nichol2021improved,dhariwal2021diffusion,kong2020diffwave,saharia2021image,song2020score}. However, surprisingly, it remains unknown why this performs well or whether it is optimal for sample quality. To the best of our knowledge, the design of a better weighting scheme to achieve better sample quality has not yet been explored.

Given the success of diffusion models with the standard weighted objective, we aim to amplify this benefit by exploring a more appropriate weighting scheme for the objective function. However, designing a weighting scheme is difficult owing to two factors. First, there are thousands of noise levels; therefore, an exhaustive grid search is impossible. Second, it is not clear what information the model learns at each noise level during training, therefore hard to determine the priority of each level.


In this paper, we first investigate what a diffusion model learns at each noise level. Our key intuition is that the diffusion model learns rich visual concepts by solving \textit{pretext tasks} for each level, which is to recover the image from corrupted images. At the noise level where the images are slightly corrupted, images are already available for perceptually rich content and thus, recovering images does not require prior knowledge of image contexts. For example, the model can recover noisy pixels from neighboring clean pixels. Therefore, the model learns imperceptible details, rather than high-level contexts. In contrast, when images are highly corrupted so that the contents are unrecognizable, the model learns perceptually recognizable contents to solve the given pretext task. Our observations motivate us to propose P2 (perception prioritized) weighting, which aims to prioritize solving the pretext task of more important noise levels. We assign higher weights to the loss at levels where the model learns perceptually rich contents while minimal weights to which the model learns imperceptible details.


To validate the effectiveness of the proposed P2 weighting, we first compare diffusion models trained with previous standard weighting scheme and P2 weighting on various datasets. Models trained with our objective are consistently superior to the previous standard objective by large margins. Moreover, we show that diffusion models trained with our objective achieve state-of-the-art performance on CelebA-HQ~\cite{karras2017progressive} and Oxford-flowers~\cite{nilsback2008automated} datasets, and comparable performance on FFHQ~\cite{stylegan} among various types of generative models, including generative adversarial networks (GANs)~\cite{goodfellow2014generative}. We further analyze whether P2 weighting is effective to various model configurations and sampling steps. Our main contributions are as follows:

\begin{itemize}

\item We introduce a simple and effective weighting scheme of training objectives to encourage the model to learn rich visual concepts. 

\item We investigate how the diffusion models learn visual concepts from each noise level.

\item We show consistent improvement of diffusion models across various datasets, model configurations, and sampling steps.
\end{itemize}



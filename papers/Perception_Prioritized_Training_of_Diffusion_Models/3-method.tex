\section{Method}
\label{sec:method}
We first investigate what the model learns at each diffusion step in~\cref{sec:method_3.1}. Then, we propose our weighting scheme in~\cref{sec:method_3.2}. We provide discussions on how our weighting scheme is effective in~\cref{sec:method_3.3}.

\begin{figure*}[t!]
  \centering
  \includegraphics[width=1.0\linewidth]{figures/recon-qualonly.png}
  \caption{\textbf{Stochastic reconstruction.} (Left) Illustration of reconstruction, where sample are obtained from full sampling chain. %When input $x_0$ is corrupted until large step $t$, a large amount of contents are removed from the image therefore the reconstruction $\hat{x}_0$ is perceptually different from $x_0$.
  (Right) Reconstructions $\hat{x}_0$ with input images $x_0$ on the rightmost column and SNR of $x_t$ on the bottom. Samples in the 1st, 2nd columns share only the coarse attributes (e.g., global color structure) with the input. The 3rd, 4th columns share perceptually discriminative contents with the input. 5th column are almost identical to the input, suggesting that the model learns imperceptible details when SNRs are large.}
  \label{fig:recon}
\end{figure*}

\subsection{Learning to Recover Signals from Noisy Data}
\label{sec:method_3.1}
Diffusion models learn visual concepts by solving \textit{pretext task} at each noise level, which is to recover signals from corrupted signals.
More specifically, the model predicts the noise component $\epsilon$ of a noisy image $x_t$, where the time step $t$ is an index of the noise level. While the output of diffusion models is noise, other generative models (VAE, GAN) directly output images. Because noise does not contain any content or signals, it is difficult to understand how the noise predictions contribute to learning rich visual concepts. Such nature of diffusion models arises the following question: \textit{what information does the model learn at each step during training?} 

\textbf{Investigating diffusion process.  }
We first investigate the predefined diffusion process to explore what the model can learn from each noise level. 
Let say we have two different clean images $x_0$, $x'_0$ and three noisy images $x_{tA},~x_{tB}\sim q(x_t|x_0)$, $x'_t\sim q(x_t|x'_0)$, where $q$ is the diffusion process. In~\cref{fig:mode} (left), we measure perceptual distances (LPIPS~\cite{zhang2018unreasonable}) in two cases: the distance between $x_{tA}$ and $x_{tB}$ (blue line), which share the same $x_0$, and the distance between $x_{tA}$ and $x'_t$ (orange line), which were synthesized from different images $x_0$ and $x'_0$. We present the distances of the two cases as functions of the \textit{signal-to-noise ratio} (SNR) introduced in~\cref{eq:snr}, which characterizes the noise level at each step. To briefly review, SNR decreases through the diffusion process, as shown in~\cref{fig:mode} (right), and increases through the denoising process.



The early steps of the diffusion process have large SNRs, which indicates invisibly small noise; thus, noisy images $x_t$ retain a large amount of contents from the clean image $x_0$. Therefore, in the early steps, $x_{tA}$ and $x_{tB}$ are perceptually similar, while $x_{tA}$ and $x'_t$ are perceptually different, as shown by the large SNR side in~\cref{fig:mode} (left). A model can recover signals without understanding holistic contexts, as perceptually rich signals are already prepared in the image. Thus the model will learn only imperceptible details by solving recovery tasks when SNR is large. 

In contrast, the late steps have small SNRs, indicating a sufficiently large noise to remove the contents of $x_0$. Therefore, distances of both cases start to converge to a constant value, as the noisy images become difficult to recognize the high-level contents. It is shown in the small SNR side in~\cref{fig:mode} (left). Here, a model needs prior knowledge to recover signals because the noisy images lack recognizable content. We argue that the model will learn perceptually rich contents by solving recovery tasks when SNR is small.

\textbf{Investigating a trained model.  }
We would like to verify the aforementioned discussions with a trained model.
Given an input image $x_0$, we first perturb it to $x_t$ using a diffusion process $q(x_t|x_0)$ and reconstruct it with the learned denoising process $p_\theta(\hat{x}_0|x_t)$, as illustrated in~\cref{fig:recon} (left). When $t$ is small, the reconstruction $\hat{x}_0$ will be highly similar to the input $x_0$ as the diffusion process removes a small amount of signals, while $\hat{x}_0$ will share less content with $x_0$ when $t$ is large. In \cref{fig:recon} (right), we compare $x_0$ and $\hat{x}_0$ among various $t$ to show how each step contributes to the sample. 
Samples in the first two columns share only coarse features (e.g., global color scheme) with the input on the rightmost column, whereas samples in the third and fourth columns share perceptually discriminative contents. This suggests that the model learns coarse features when the SNR of step $t$ is smaller than $10^{-2}$ and the model learns the content when SNR is between $10^{-2}$ and $10^0$. When the SNR is larger than $10^0$ (fifth column), reconstructions are perceptually identical to the inputs, suggesting that the model learns imperceptible details that do not contribute to perceptually recognizable contents. 


Based on the above observations, we hypothesize that diffusion models learn coarse features (e.g., global color structure) at steps of small SNRs ($0\text{--}10^{-2}$), perceptually rich contents at medium SNRs ($10^{-2}\text {--}10^0$), and remove remaining noise at large SNRs ($10^{0}\text{--}10^4$). 
According to our hypothesis, we group noise levels into three stages, which we term \textit{coarse}, \textit{content}, and \textit{clean-up} stages. 



\subsection{Perception Prioritized Weighting}
\label{sec:method_3.2}

In the previous section, we explored what the diffusion model learns from each step in terms of SNR. We discussed that the model learns coarse features (e.g., global color structure), perceptually rich contents, and to clean up the remaining noise at three groups of noise levels. We pointed out that the model learns imperceptible details at the clean-up stage. In this section, we introduce Perception Prioritized (P2) weighting, a new weighting scheme for the training objective, which aims to prioritize learning from more important noise levels.

We opt to assign minimal weights to the unnecessary clean-up stage thereby assigning relatively higher weights to the rest. In particular, we aim to emphasize training on the content stage to encourage the model to learn perceptually rich contexts. 
To this end, we construct the following weighting scheme:
\begin{equation}\label{eq:ours}
\lambda'_t = \frac{\lambda_t}{(k+\text{SNR}(t))^{\gamma}},
\end{equation}
where $\lambda_t$ is the previous standard weighting scheme (\cref{eq:simple_snr}) and $\gamma$ is a hyperparameter that controls the strength of down-weighting focus on learning imperceptible details. $k$ is a hyperparameter that prevents exploding weights for extremely small SNRs and determines sharpness of the weighting scheme. While multiple designs are possible, we show that even the simplest choice (P2) outperforms the standard scheme $\lambda_t$. Our method is applicable to existing diffusion models by replacing $\sum_t\lambda _t L_t$ with $\sum_t\lambda' _t L_t$.

In fact, our weighting scheme $\lambda'_t$ is a generalization of the popularly used~\cite{nichol2021improved,dhariwal2021diffusion,kong2020diffwave,song2020score} weighting scheme $\lambda_t$ of Ho et al.~\cite{ho2020denoising} (\cref{eq:simple_snr}), where $\lambda'_t$ arrives at $\lambda_t$ when $\gamma=0$. We refer to $\lambda_t$ as the \textit{baseline} herein. 

\begin{figure*}[t!]
  \centering
  \includegraphics[width=1.0\linewidth]{figures/snr_weight.png}
  \caption{\textbf{Weighting schemes.} (Left) Signal-to-noise ratio (SNR) of linear and cosine noise schedules for reference. (Middle) Weights of our P2 weighting and the baseline with a cosine schedule. (Right) Weights of P2 weighting and the baseline with a linear schedule. Compared to the baseline, P2 weighting suppresses weights for large SNRs, where the model learns imperceptible details.}
  \label{fig:snr_weight}
\end{figure*}

\begin{figure}[t!]
  \centering
  \includegraphics[width=0.9\linewidth]{figures/ablation.png}
  \caption{\textbf{Comparison of FID-10k through training on FFHQ.} P2 weighting consistently improves performance for both linear and cosine schedules. Training progress refers to the number of images seen by the model. Samples are generated with 250 steps.}
  \label{fig:ablation}
\end{figure}

\begin{figure*}[t!]
  \centering
  \includegraphics[width=1.0\linewidth]{figures/teaser.pdf}
  \caption{Samples generated by our models trained on several datasets (FFHQ, CelebA-HQ, MetFaces, AFHQ-Dogs, Oxford Flowers, CUB Bird) at 256$\times$256 resolution. See appendix for more samples.}
  \label{fig:teaser}
\end{figure*}

\subsection{Effectiveness of P2 Weighting}
\label{sec:method_3.3}
Prior works~\cite{ho2020denoising,nichol2021improved} empirically suggest that the baseline objective $\sum_t\lambda _t L_t$ offers a better inductive bias for sample quality than the VLB objective $\sum_t L_t$, which does not impose any inductive bias during training. \cref{fig:snr_weight} exhibits $\lambda'_t$ and $\lambda_t$ for both linear~\cite{ho2020denoising} and cosine~\cite{nichol2021improved} noise schedules, which are explained in~\cref{sec:background_def}, indicating that both weighting schemes focus training on the content stage the most and the cleaning stage the least. The success of the baseline weighting is in line with our previous hypothesis that models learn perceptually rich content by solving pretext tasks at the content stage.

However, despite the success of the baseline objective, we argue that the baseline objective still imposes an undeserved focus on learning imperceptible details and prevents from learning perceptually rich content. \cref{fig:snr_weight} shows that our $\lambda'_t$ further suppresses the weights for the cleaning stage, which relatively uplifts the weights for the coarse and the content stages. To visualize relative changes of weights, we exhibit normalized weighting schemes.
\cref{fig:ablation} supports our method in that FID of the diffusion model trained with our weighting scheme ($\gamma = 1$) beats the baseline for both linear and cosine schedules throughout the training. 

Another notable result from \cref{fig:ablation} is that the cosine schedule is inferior to the linear schedule by a large margin, although our weighting scheme improves the FID by a large gap. 
\cref{eq:vlb} indicates that the weighting scheme is closely related to the noise schedule.
As shown in~\cref{fig:snr_weight}, the cosine schedule assigns smaller weights to the content stage compared with the linear schedule. We would like to note that designing weighting schemes and noise schedules are correlated but not equivalent, as the noise schedules affects both weights and MSE terms.

% This indicates that models learn more beneficial features at the coarse stage than the clean-up stage. \textcolor{blue}{여기서 noise schedule과 weight의 correlation을 설명하자}

To summarize, our P2 weighting provides a good inductive bias for learning rich visual concepts, by uplifting weights at the coarse and the content stages, and suppressing weights at the clean-up stage.



\subsection{Implementation}
We set $k$ as 1 for easy deployment, because $1/(1+\text{SNR}(t))=1-\alpha_t$, as discussed in~\cref{sec:background_def}. We set $\gamma$ as either 0.5 and 1. We empirically observed that $\gamma$ over 2 suffers noise artifacts in the sample because it assigns almost zero weight to the clean-up stage. We set $T=1000$ for all experiments. We implemented the proposed approach on top of ADM~\cite{dhariwal2021diffusion}, which offers well-designed architecture and efficient sampling. We use lighter version of ADM through our experiments. Our code and models are available\footnote{\url{https://github.com/jychoi118/P2-weighting}}.


\section{Background}
\label{sec:background}

\subsection{Definitions}
\label{sec:background_def}
Diffusion models~\cite{sohl2015deep,ho2020denoising} transform complex data distribution $p_{data}(x)$ into simple noise distribution $\mathcal{N}(0,\mathbf{I})$ and learn to recover data from noise.
The \textit{diffusion process} of diffusion models gradually corrupts data $x_0$ with predefined noise scales $0<\beta _1, \beta _2, ..., \beta_T <1$, indexed by time step $t$.
Corrupted data $x_1,...,x_T$ are sampled from data $x_0\sim p_{data}(x)$, with a diffusion process, which is defined as Gaussian transition:
\begin{equation}\label{eq:forward}
q(x_{t}|x_{t-1})=\mathcal{N}(x_{t};\sqrt{1-\beta _{t}}x_{t-1},\beta _{t}\mathbf{I}).
\end{equation}
Noisy data $x_t$ can be sampled from $x_0$ directly:
\begin{equation}\label{eq:closed}
x_t=\sqrt{\alpha _{t}}x_{0} + \sqrt{1-\alpha _{t}}\epsilon,
\end{equation}
where $\epsilon\sim \mathcal{N}(0,\mathbf{I})$ and $\alpha_{t}:=\prod_{s=1}^t (1-\beta _{s})$. We note that data $x_0$, noisy data $x_1,...,x_T$, and noise $\epsilon$ are of the same dimensionality. 
To ensure $p(x_T)\sim \mathcal{N}(0,\mathbf{I})$ and the reversibility of the diffusion process~\cite{sohl2015deep}, one should set $\beta_t$ to be small and $\alpha_T$ to be near zero. To this end, Ho et al.~\cite{ho2020denoising} and Dhariwal et al.~\cite{dhariwal2021diffusion} use a linear noise schedule where $\beta_t$ increases linearly from $\beta_1$ to $\beta_T$. Nichol et al.~\cite{nichol2021improved} use a cosine schedule where $\alpha_t$ resembles the cosine function.

Diffusion models generate data $x_0$ with the learned \textit{denoising process} $p_\theta(x_{t-1}|x_t)$ which reverses the diffusion process of~\cref{eq:forward}. Starting from noise $x_T\sim \mathcal{N}(0,\mathbf{I})$, we iteratively subtract the noise predicted by noise predictor $\epsilon _\theta$:
\begin{equation}\label{eq:reverse}
x_{t-1}= \frac{1}{\sqrt{1-\beta _t}}(x_t-\frac{\beta_t}{\sqrt{1-\alpha _t}}\epsilon _{\theta}(x_t,t))+\sigma _t z,
\end{equation}
where $\sigma _t^2$ is a variance of the denoising process and $z\sim \mathcal{N}(0,\mathbf{I})$. Ho et al.~\cite{ho2020denoising} used $\beta _t$ as $\sigma _t^2$.


Recent work Kingma et al.~\cite{kingma2021variational} simplified the noise schedules of diffusion models in terms of \textit{signal-to-noise ratio} (SNR). SNR of corrupted data $x_t$ is a ratio of squares of mean and variance from~\cref{eq:closed}, which can be written as:
\begin{equation}\label{eq:snr}
\text{SNR}(t)=\alpha _{t}/(1-\alpha _{t}),
\end{equation}
and thus the variance of noisy data $x_t$ can be written in terms of SNR: $\alpha _t= 1 - 1/(1+\text{SNR}(t))$. We would like to note that SNR($t$) is a monotonically decreasing function.

\begin{figure*}[t!]
  \centering
  \includegraphics[width=1.0\linewidth]{figures/mode.png}
  \caption{\textbf{Information removal of a diffusion process.} (Left) Perceptual distance of corrupted images as a function of signal-to-noise ratio (SNR). Distances are measured between two noisy images either corrupted from the same image (blue) or different images (orange). 
  We averaged distances measured with 200 random triplets from CelebA-HQ. 
  Perceptually recognizable contents are removed when SNR magnitude is between $10^{-2}$ and $10^0$. %, which suggests that diffusion models learn rich visual contents by solving recovery tasks at corresponding noise levels. 
  (Right) Illustration of the diffusion process.}
  \label{fig:mode}
\end{figure*}

\subsection{Training Objectives}
\label{sec:objective}
The diffusion model is a type of variational auto-encoder (VAE); where the encoder is defined as a fixed \textit{diffusion process} rather than a learnable neural network, and the decoder is defined as a learnable \textit{denoising process} that generates data. Similar to VAE, we can train diffusion models by optimizing a variational lower bound (VLB), which is a sum of denoising score matching losses~\cite{vincent2011connection}: $L_{vlb}=\sum_t L_t$, where weights for each loss term are uniform. For each step $t$, denoising score matching loss $L_t$ is a distance between two Gaussian distributions, which can be rewritten in terms of noise predictor $\epsilon_\theta$ as:
\begin{align}\label{eq:vlb}
L_{t}=~&D_{KL}(q(x_{t-1}|x_t,x_0)~||~p_\theta(x_{t-1}|x_t))  \nonumber \\
=~&\mathbb{E}_{x_0,\epsilon}[\frac{\beta _t}{(1-\beta _t)(1
-\alpha _t)}||\epsilon-\epsilon_\theta(x_t, t)||^2].
\end{align}
Intuitively, we train a neural network $\epsilon _\theta$ to predict the noise $\epsilon$ added in noisy image $x_t$ for given time step $t$.

Ho et al.~\cite{ho2020denoising} empirically observed that the following simplified objective is more beneficial to sample quality:
\begin{equation}\label{eq:simple}
L_{simple}=\sum _t \mathbb{E}_{x_0,\epsilon}[||\epsilon-\epsilon_\theta(x_t, t)||^2].
\end{equation}
In terms of VLB, their objective is $L_{simple}=\sum_t\lambda _t L_t$ with weighting scheme $\lambda _t=(1-\beta _t)(1-\alpha _t)/\beta _t$. In a continuous-time setting, this scheme can be expressed in terms of SNR: 
\begin{equation}\label{eq:simple_snr}
\lambda_t = -1/\text{log-SNR}'(t)= -\text{SNR}(t)/\text{SNR}'(t),
\end{equation}
where $\text{SNR}'(t)=\frac{d\text{SNR}(t)}{dt}$. See appendix for derivations.

While Ho et al.~\cite{ho2020denoising} use fixed values for the variance $\sigma _t$, Nichol et al.~\cite{nichol2021improved} propose to learn it with hybrid objective $L_{hybird}=L_{simple}+c L_{vlb}$, where $c = 1e^{-3}$. They observed that learning $\sigma _t$ enables reducing sampling steps while maintaining the generation performance. 
We inherit their hybrid objective for efficient sampling and modify $L_{simple}$ to improve performance.


\subsection{Evaluation Metrics}
We use FID~\cite{heusel2017gans} and KID~\cite{binkowski2018demystifying} for quantitative evaluations.
FID is well-known to be analogous to human perception~\cite{heusel2017gans} and well-used as a default metric~\cite{karras2020training,dhariwal2021diffusion,stylegan,esser2021taming,parmar2021cleanfid} for measuring generation performances. KID is a well-used metric to measure performance on small datasets~\cite{karras2020training,karras2021alias,parmar2021cleanfid}. However, since both metrics are sensitive to the preprocessing~\cite{parmar2021cleanfid}, we use a correctly implemented library~\cite{parmar2021cleanfid}. We compute FID and KID between the generated samples and the entire training set. We measured final scores with 50k samples and conducted ablation studies with 10k samples for efficiency, following~\cite{dhariwal2021diffusion}. We denote them as FID-50k and FID-10k respectively.

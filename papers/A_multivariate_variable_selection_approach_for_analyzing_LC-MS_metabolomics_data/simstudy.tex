The goal of this section is to assess the statistical performance of
our methodology. In order to emphasize the benefits of using a
whitening approach from the variable selection point of view, we shall
first compare our approach to standard methodologies. Then, we shall analyze the performance
of our statistical test for choosing the best dependence
modeling. Finally, we shall investigate the performance of our model
selection criterion.

To assess the performance of
these different methodologies, we generated observations
$\boldsymbol{Y}$ according to Model (\ref{eq:model:matriciel}) with $q=1000$,
$p=3$, $n=30$ and different dependence modelings, namely different
matrices $\boldsymbol{\Sigma}_q$ corresponding to the AR(1) model
described in (\ref{eq:AR1}) with $\sigma=1$ and $\phi_1=0.7$ or 0.9.

Note that we have chosen the values of the parameters $p$, $q$ and $n$
in order to be as close as possible to the real data that we plan to analyze in
Section \ref{sec:real}.

We shall also investigate the effect of the sparsity and of the signal
to noise ratio. In the following, the sparsity level 
corresponds to the number of non null elements in $\mathcal{B}$
divided by the total number $nq$ of elements of $\mathcal{B}$. Different signal to noise ratios are
obtained by multiplying $\boldsymbol{B}$ in (\ref{eq:model:matriciel})
by a coefficient $\kappa$. 


\subsection{Variable selection performance}

The goal of this section is to compare
the performance of our different whitening strategies presented above to standard existing methodologies.
More precisely, we shall compare our approaches to the classical
ANOVA method (denoted \textsf{ANOVA}), the standard Lasso
(denoted \textsf{Lasso}), namely the Lasso approach without
the whitening step and to \textsf{sPLSDA} devised by \cite{LeCao2011} and implemented in the \textsf{mixOmics} R package, which is widely used in the metabolomics field. 
By \textsf{ANOVA}, we mean the classical one-way ANOVA applied to each column of the observations matrix $\boldsymbol{Y}$
without taking the dependence into account. 

In the following, the different whitening
approaches that we propose will be denoted by \textsf{AR1} and
\textsf{Nonparam}. They are described in Sections
\ref{subsec:param} and \ref{subsec:nonparam}, respectively. These methods will also be
compared to the \textsf{Oracle} approach which assumes that the matrix
$\boldsymbol{\Sigma}_q$ is known, which is never the case in practical
situations. 

For comparing these different methods, we shall use two classical
criteria: ROC curves and AUC (Area Under the ROC Curve). ROC curves display the true positive rates as
a function of the false positive rates and the closer to one the AUC
the better the methodology. Since \textsf{sPLSDA} only selects relevant metabolites but does not assign them to a level
of the factor, we shall consider that as soon as a relevant metabolite is selected it is a true positive which gives an advantage
to \textsf{sPLSDA}.

\begin{figure}[t!]
\hspace{-2mm}
\begin{tabular}{@{}l@{}c@{}c@{}c@{}c@{}c@{}r@{}}
  & \multicolumn{2}{c}{$s=0.01$} & \hspace{1em} & \multicolumn{2}{c}{$s=0.3$} & \\
  \cline{2-3}\cline{5-6}
  & $\phi_1=0.7$ & $\phi_1=0.9$ & &$\phi_1=0.7$ & $\phi_1=0.9$ & \\
  \rotatebox{90}{\hspace{6em}\small TPR} & 
\includegraphics[scale=0.235]{ROC_AR1_SNR1_phi07_s001.pdf}
& \includegraphics[scale=0.235]{ROC_AR1_SNR1_phi09_s001.pdf}
& & \includegraphics[scale=0.235]{ROC_AR1_SNR1_phi07_s03.pdf}
& \includegraphics[scale=0.235]{ROC_AR1_SNR1_phi09_s03.pdf} & \rotatebox{90}{\hspace{6em}\small $\kappa=1$}\\
\rotatebox{90}{\hspace{6em}\small TPR} & \includegraphics[scale=0.24]{ROC_AR1_SNR2_phi07_s001.pdf}
& \includegraphics[scale=0.235]{ROC_AR1_SNR2_phi09_s001.pdf}
& & \includegraphics[scale=0.235]{ROC_AR1_SNR2_phi07_s03.pdf}
& \includegraphics[scale=0.235]{ROC_AR1_SNR2_phi09_s03.pdf} & \rotatebox{90}{\hspace{6em}\small $\kappa=2$}\\
& \multicolumn{4}{c}{FPR} & \\
\end{tabular}
\caption{Means of  the ROC curves  obtained from 200  replications for
  the  different  methodologies  in  the  AR(1)  dependence  modeling;
  $\kappa$ is linked to the signal to noise ratio (first row: $\kappa=1$, second row $\kappa=2$); $\phi_1$ is the
  correlation level in the AR(1) and  $s$ the sparsity level (i.e. the
  fraction of nonzero elements) in the vector of true parameters.\label{fig:AR1_1}}
\end{figure}




We can see  from Figure \ref{fig:AR1_1} that in the  case of an AR(1)
dependence,  taking  into  account  this  dependence  provides  better
results  than \textsf{sPLSDA} and than  approaches that consider  the  columns of  the  residual  matrix  as
independent.  Moreover,  we  observe  that  the
performance of the non parametric modeling  are on a par with those of
the parametric and the oracle ones.   We also note that the larger the
sparsity level the  smaller the difference of  performance between the
different approaches.  However,  the larger the signal  to noise ratio
the better the performance of the different methodologies.

\subsection{Choice of the dependence modeling}

The goal of this section is to assess the performance of the dependence modeling
strategy that we proposed in Section \ref{sec:whitening_test}. We
generated observations $\boldsymbol{Y}$ with the parameters described
at the beginning of Section \ref{sec:num_exp} in the case of an AR(1)
dependence, for a sparsity level of 0.01 and when $\kappa=1$. The corresponding results are displayed
in Figure \ref{fig:test}.


\begin{figure}[!h]
\centering
\includegraphics[scale=0.4]{Pvalue_sum_ar.pdf}
\caption{Means and standard deviations of the $p$-values of the test
   described in Section \ref{sec:whitening_test} for the different
   approaches in the AR(1) dependence modeling when $\phi_1=0.7$ (left)
   and $\phi_1=0.9$ (right).\label{fig:test}}
\end{figure}

We observe from this figure that our test provides
$p$-values close to zero in the case where no whitening strategy is
used (\textsf{Lasso}) and that when one of the proposed whitening
approaches is used the $p$-values are larger than 0.7. 


\subsection{Choice of the model selection criterion}

We investigate hereafter the performance of our model selection
criterion described in Section \ref{sec:model_selection}.

Figure \ref{fig:pval_simul} displays the means of the $p$-values of
the test described in \ref{sec:whitening_test} obtained from 5000 replications of the observations $\boldsymbol{Y}$
generated with the parameters described
at the beginning of Section \ref{sec:num_exp} in the case of an AR(1)
dependence with $\phi_1=0.9$ and $\kappa=1$. 
\begin{figure}[htbp!]
\centering
\includegraphics[scale=0.25]{pVals_sum_snr1_ar109_selontresh.pdf}
%\end{tabular}
\caption{Means of the $p$-values associated to the test statistic defined in (\ref{eq:stat_test_2}) obtained
  from 5000 replications when $\kappa=1$. 
%(left) and $\kappa=10$ (right).
\label{fig:pval_simul}}
%\end{center}
\end{figure}

We observe
from this figure that the $p$-values are all the more high that the
thresholds are large. 

Figure   \ref{fig:boulier_simuls}  displays   with  bullets
('$\bullet$')  the   positions  of  the  variables   selected  by  our
three-step approach  for the two  possible choices of  thresholds from
500 replications of $\boldsymbol{Y}$  obtained  with   the  parameters
described at the beginning of Section \ref{sec:num_exp} in the case of
an  AR(1) dependence  with $\phi_1=0.9$  and $\kappa=10$.

   We observe
from  this figure  that  mostly  all the  positions  of  the non  null
variables in $\mathcal{B}$ are retrieved with some false positive when
the  threshold  is obtained  by  maximizing  the $p$-value.  When the
threshold is equal to 1, there are  no false positive but all the true
positions are not recovered.


\begin{figure}[!htbp!]
\centering
\includegraphics[scale=0.2]{Abacus_threshold1_SNR10_5000repli_500simu.pdf}%\\
\includegraphics[scale=0.2]{Abacus_threshold_max_pval_SNR10_5000repli_500simu.pdf}
\includegraphics[scale=0.2]{legend_abacus.pdf}
\caption{Positions of the variables selected by our
  approach  ('$\bullet$') when  $\kappa=10$.  Values  on the  $y$-axis
  correspond to the 3 levels
  of the factor. The results obtained when the threshold
  is equal to 1 are on the left and the results when the threshold is
  obtained by maximizing the $p$-value are on the right. The size
  of the bullets are all the more large that 
  the number of times where a variable has been selected is large.
\label{fig:boulier_simuls}}
\end{figure}


\subsection{Numerical performance}

In order to investigate the computational burden of our approach, we generated matrices $\boldsymbol{Y}$
satisfying Model (\ref{eq:model:matriciel}) with $n=30$ and $q\in\{100,200,\dots,1000\}$. Here, the rows of the matrix
$\boldsymbol{E}$ are generated as realizations of an AR(1) process and the level of sparsity $s$ 
of $\boldsymbol{B}$ is equal to 0.01.

Figure \ref{fig:time} displays the computational times of \textsf{MultiVarSel}
obtained from a computer having the following configuration: RAM 16 GB, CPU $8\times 3.6$ GHz for different 
number of replications in the stability selection stage.
We can see from this figure that the computational burden  of \textsf{MultiVarSel} is very low and that it takes
only a few seconds to analyze matrices having 1000 columns.


\begin{figure}
\centering
\includegraphics[scale=0.8]{temp_computing.pdf}
\caption{Computational times (in seconds) of \textsf{MultiVarSel}.\label{fig:time}}
\end{figure}

%%% Local Variables:
%%% mode: latex
%%% eval: (TeX-PDF-mode 1)
%%% TeX-master: "perrot_levy_chiquet_arxiv.tex"
%%% ispell-local-dictionary: "en_US"
%%% eval: (flyspell-mode 1)
%%% End: 

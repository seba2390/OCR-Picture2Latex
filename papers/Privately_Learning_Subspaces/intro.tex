\section{Introduction}

Differentially private algorithms generally have a poor dependence on the dimensionality of their input. That is, their error or sample complexity grows polynomially with the dimension. For example, for the simple task of estimating the mean of a distribution supported on $[0,1]^d$, we have per-coordinate error $\Theta(\sqrt{d}/n)$ to attain differential privacy, where $n$ is the number of samples. In contrast, the non-private error is $\Theta(\sqrt{\log(d)/n})$.

This cost of dimensionality is inherent \cite{BunUV14,SteinkeU17a,DworkSSUV15}. \emph{Any} method with lower error is susceptible to tracing attacks (a.k.a.~membership inference attacks). However, these lower bounds only apply when the data distribution is ``high-entropy.'' This leaves open the posssibility that we can circumvent the curse of dimensionality when the data has an underlying low-dimensional structure.

Data often does possess an underlying low-dimensional structure. For example, the gradients that arise in deep learning tend to be close to a low-dimensional subspace \cite{AbadiCGMMTZ16,LiZTSG17,GurAriRD18,LiFLY18,LiGZCB19,ZhouWB20,FengT20}. Low dimensionality can arise from meaningful relationships that are at least locally linear, such as income versus tax paid. It can also arise because we are looking at a function of data with relatively few attributes.

A long line of work \cite[etc.]{BlumLR08,HardtT10,HardtR10,Ullman15,BlasiokBNS19,BassilyCMNUW20,ZhouWB20,KairouzRRT20} has shown how to exploit structure in the data to attain better privacy and accuracy. However, these approaches assume that this structure is known \emph{a priori} or that it can be learned from non-private sources. This raises the question:
\begin{quote}
    Can we learn low-dimensional structure from the data subject to differential privacy?
\end{quote}
We consider the simple setting where the data lies in $\mathbb{R}^d$ but is in, or very close to a linear subspace, of dimension $k$. We focus on the setting where $k \ll d$ and we develop algorithms whose sample complexity does not depend on the ambient dimension $d$; a polynomial dependence on the true dimension $k$ is unavoidable.

Our algorithms identify the subspace in question or, if the data is perturbed slightly, an approximation to it. Identifying the subspace structure is interesting in its own right, but it also can be used as a pre-processing step for further analysis -- by projecting to the low-dimensional subspace, we ensure subsequent data analysis steps do not need to deal with high-dimensional data.

\subsection{Our Contributions: Privately Learning Subspaces -- Exact Case}

We first consider the exact case, where the data $X_1, \cdots, X_n \in \mathbb{R}^d$ are assumed to lie in a $k$-dimensional subspace (rather than merely being near to it) -- i.e., $\mathsf{rank}\left(A\right) = k$, where $A = \sum_i^n X_i X_i^T \in \mathbb{R}^{d \times d}$. In this case, we can also recover the subspace exactly.

However, we must also make some non-degeneracy assumptions. We want to avoid a pathological input dataset such as the following. Suppose $X_1, \cdots, X_k$ are linearly independent, but $X_k=X_{k+1}=X_{k+2}=\cdots=X_n$. While we can easily reveal the repeated data point, we cannot reveal anything about the other points due to the privacy constraint. 

A natural non-degeneracy assumption would be to assume that the data points are in ``general position'' -- that is, that there are no non-trivial linear dependencies among the data points. This means that \emph{every} set of $k$ data points spans the subspace or, equivalently, no subspace of dimension $k-1$ contains more than $k-1$ data points. This is a very natural assumption -- if the data consists of $n$ samples from a continuous distribution on the subspace, then this holds with probability $1$. We relax this assumption slightly and assume that no subspace of dimension $k-1$ contains more than $\ell$ data points. We also assume that all points are non-zero. Note that we define subspaces to pass through the origin; our results can easily be extended to affine subspaces.

\begin{theorem}[Main Result -- Exact Case]\label{thm:intro-main-exact}
For all $n,d,k,\ell \in \mathbb{N}$ and $\varepsilon,\delta>0$ satisfying $n \ge O\left(\ell + \frac{\log(1/\delta)}{\varepsilon}\right)$, there exists a randomized algorithm $M : \mathbb{R}^{d \times n} \to \mathcal{S}_d^k$ satisfying the following. Here $\mathcal{S}_d^k$ denotes the set of all $k$-dimensional subspaces of $\mathbb{R}^d$.
\begin{itemize}
    \item $M$ is $(\varepsilon,\delta)$-differentially private with respect to changing one column of its input.
    \item Let $X = (X_1, \cdots, X_n) \in \mathbb{R}^{d \times n}$.
    Suppose there exists a $k$-dimensional subspace $S_* \in \mathcal{S}_d^k$ that contains all but $\ell$ of the points -- i.e., $|\{i \in [n] : X_i \in S_*\}| \ge n -\ell$.
    Further suppose that any $(k-1)$-dimensional subspace contains at most $\ell$ points -- i.e., for all $S \in \mathcal{S}_d^{k-1}$, we have $|\{i \in [n] : X_i \in S\}| \le \ell$. 
    Then $\pr{}{M(X)=S_*}=1$.
\end{itemize}
\end{theorem}

The parameter $\ell$ in Theorem \ref{thm:intro-main-exact} can be thought of as a robustness parameter. Ideally the data points are in general position, in which case $\ell=k-1$. If a few points are corrupted, then we increase $\ell$ accordingly; our algorithm can tolerate the corruption of a small constant fraction of the data points.
Theorem \ref{thm:intro-main-exact} is optimal in the sense that $n \ge \Omega\left(\ell + \frac{\log(1/\delta)}{\varepsilon}\right)$ samples are required.

\subsection{Our Contributions: Privately Learning Subspaces -- Approximate Case}

Next we turn to the substantially more challenging approximate case, where the data $X_1, \cdots, X_n \in \mathbb{R}^d$ are assumed to be close to a $k$-dimensional subspace, but are not assumed to be contained within that subspace. Our algorithm for the exact case is robust to changing a few points, but very brittle if we change all the points by a little bit. Tiny perturbations of the data points (due to numerical errors or measurement imprecision) could push the point outside the subspace, which would cause the algorithm to fail. Thus it is important to for us to cover the approximate case and our algorithm for the approximate is entirely different from our algorithm for the exact case. 

The approximate case requires us to precisely quantify how close the input data and our output are to the subspace and we also need to make quantitative non-degeneracy assumptions. It is easiest to formulate this via a distributional assumption. We will assume that the data comes from a Gaussian distribution where the covariance matrix has a certain eigenvalue gap. This is a strong assumption and we emphasize that this is only for ease of presentation; our algorithm works under weaker assumptions. Furthermore, we stress that the differential privacy guarantee is worst-case and does not depend on any distributional assumptions.

We assume that the data is drawn from a multivariate Gaussian $\mathcal{N}(0,\Sigma)$. Let $\lambda_1(\Sigma) \ge \lambda_2(\Sigma) \ge \cdots \ge \lambda_d(\Sigma)$ be the eigenvalues of $\Sigma \in \mathbb{R}^{d \times d}$. We assume that there are $k$ large eigenvalues $\lambda_1(\Sigma), \cdots, \lambda_k(\Sigma)$ -- these represent the ``signal'' we want -- and $d-k$ small eigenvalues $\lambda_{k+1}(\Sigma), \cdots, \lambda_d(\Sigma)$ --  these are the ``noise''. Our goal is to recover the subspace spanned by the eigenvectors corresponding to the $k$ largest eigenvalues $\lambda_1(\Sigma), \cdots, \lambda_k(\Sigma)$.
Our assumption is that there is a large \emph{multiplicative} gap between the large and small eigenvalues. Namely, we assume $\frac{\lambda_{k+1}(\Sigma)}{\lambda_{k}(\Sigma)} \le \frac{1}{\mathsf{poly}(d)}$. 

\begin{theorem}[Main Result -- Approximate Case]\label{thm:intro-main-approx}
    For all $n,d,k \in \mathbb{N}$ and $\alpha,\gamma,\varepsilon, \delta > 0$ satisfying
    \[n \!\ge\! \Theta\!\left(\!\frac{k\log(1/\delta)}{\varepsilon} \!+\!
        \frac{\ln(1/\delta)\ln(\ln(1/\delta)/\eps)}{\eps}\!\right)
    ~\text{and}~
    \gamma^2 \!\le\! \Theta\!\left(\!\frac{\eps\alpha^2n}{d^2k\log(1/\delta)}\!\cdot\!\min\!\left\{\!\frac{1}{k},\!
        \frac{1}{\log(k\log(1/\delta)/\varepsilon)}\!\right\}\!\right)\!,\]
    there exists an algorithm $M : \mathbb{R}^{d \times n} \to \mathcal{S}_d^k$ satisfying the following. Here $\mathcal{S}_d^k$ is the set of all $k$-dimensional subspaces of $\mathbb{R}^d$ represented as projection matricies -- i.e., $\mathcal{S}_d^k = \{\Pi \in \mathbb{R}^{d \times d} : \Pi^2=\Pi=\Pi^T, \mathsf{rank}(\Pi)=k\}$.
\begin{itemize}
    \item $M$ is $(\varepsilon,\delta)$-differentially private with respect to changing one column of its input.
    \item Let $X_1, \cdots, X_n$ be independent samples from $\mathcal{N}(0,\Sigma)$. Let $\lambda_1(\Sigma) \ge \lambda_2(\Sigma) \ge \cdots \ge \lambda_d(\Sigma)$ be the eigenvalues of $\Sigma \in \mathbb{R}^{d \times d}$. Suppose $\lambda_{k+1}(\Sigma) \le \gamma^2 \cdot \lambda_k(\Sigma)$. Let $\Pi \in \mathcal{S}_d^k$ be the projection matrix onto the subspace spanned by the eigenvectors corresponding to the $k$ largest eigenvalues of $\Sigma$. Then $\pr{}{\|M(X)-\Pi\| \le \alpha} \ge 0.7$.
\end{itemize}
\end{theorem}

The sample complexity of our algorithm $n=O(k \log(1/\delta)/\varepsilon)$ is independent of the ambient dimension $d$; this is ideal. However, there is a polynomial dependence on $d$ in $\gamma$, which controls the multiplicative eigenvalue gap. % We conjecture that this can be improved, but it cannot eliminated entirely.
This multiplicative eigenvalue gap is a strong assumption, but it is also a necessary assumption if we want the sample complexity $n$ to be independent of the dimension $d$. In fact, it is necessary \emph{even without the differential privacy constraint} \cite{CaiZ16}. That is, if we did not assume an eigenvalue gap that depends polynomially on the ambient dimension $d$, then it would be impossible to estimate the subspace with sample complexity $n$ that is independent of the ambient dimension $d$ even in the non-private setting.

Our algorithm is based on the subsample and aggregate framework \cite{NissimRS07} and a differentially private histogram algorithm. These methods are generally quite robust and thus our algorithm is, too. For example, our algorithm can tolerate $o(n/k)$ input points being corrupted arbitrarily. \vnote{We don't exactly prove that in the technical section.} We also believe that our algorithm's utility guarantee is robust to relaxing the Gaussianity assumption. All that we require in the analysis is that the empirical covariance matrix of a few samples from the distribution is sufficiently close to its expectation $\Sigma$ with high probability.

\subsection{Related Work}

To the best of our knowledge, the problem of privately learning subspaces, as we formulate it, has not been studied before. However, a closely-related line of work is on Private Principal Component Analysis (PCA) and low-rank approximations. We briefly discuss this extensive line of work below, but first we note that, in our setting, all of these techniques have a sample complexity $n$ that grows polynomially with the ambient dimension $d$. Thus, they do not evade privacy's curse of dimensionality. However, we make a stronger assumption than these prior works -- namely, we assume a large multiplicative eigenvalue gap. (Many of the prior works consider an \emph{additive} eigenvalue gap, which is a weaker assumption.)

There has been a lot of interest in Private PCA, matrix completion, and low-rank approximation. One motivation for this is the infamous Netflix prize, which can be interpreted as a matrix completion problem. The competition was cancelled after researchers showed that the public training data revealed the private movie viewing histories of many of Netflix's customers \cite{NarayananS06}. Thus privacy is a real concern for matrix analysis tasks.

Many variants of these problems have been considered: Some provide approximations to the data matrix $X = (X_1, \cdots, X_n) \in \mathbb{R}^{d \times n}$; others approximate the covariance matrix $A = \sum_i^n X_i X_i^T \in \mathbb{R}^{d \times d}$ (as we do). There are also different forms of approximation -- we can either produce a subspace or an approximation to the entire matrix, and the approximation can be measured by different norms (we consider the operator norm between projection matrices). Importantly, we define differential privacy to allow one data point $X_i$ to be changed arbitrarily, whereas most of the prior work assumes a bound on the norm of the change or even assumes that only one coordinate of one vector can be changed. In the discussion below we focus on the techniques that have been considered for these problems, rather than the specific results and settings.

\citetall{DworkTTZ14} consider the simple algorithm which adds independent Gaussian noise to each of entries of the covariance matrix $A$, and then perform analysis on the noisy matrix. (%This algorithm is sometimes confusingly referred to as ``randomized response.''
In fact, this algorithm predates the development of differential privacy \cite{BlumDMN05} and was also analyzed under differential privacy by McSherry and Mironov \cite{McSherryM09} and Chaudhuri, Sarwate, and Sinha \cite{ChaudhuriSS12}.) %This requires a bound on $\|X_i\|_2$ to control sensitivity. 
This simple algorithm is versatile and several bounds are provided for the accuracy of the noisy PCA. The downside of this is that a polynomial dependence on the ambient dimension $d$ is inherent -- indeed, they prove a sample complexity lower bound of $n = \tilde\Omega(\sqrt{d})$ for any algorithm that identifies a useful approximation to the top eigenvector of $A$. This lower bound does not contradict our results because the relevant inputs do not satisfy our near low-rank assumption.

\citetall{HardtR12} and \citetall{AroraBU18} apply techniques from dimensionality reduction to privately compute a low-rank approximation to the input matrix $X$. \citetall{HardtR13} and \citetall{HardtP13} use the power iteration method with noise injected at each step to compute low-rank approximations to the input matrix $X$. In all of these, the underlying privacy mechanism is still noise addition and the results still require the sample complexity to grow polynomially with the ambient dimension to obtain interesting guarantees. (However, the results can be dimension-independent if we define differential privacy so that only one entry -- as opposed to one column -- of the matrix $X$ can be changed by $1$. This is a significantly weaker privacy guarantee.)

\citetall{BlockiBDS12} and \citetall{Sheffet19} also use tools from dimensionality reduction; they approximate the covariance matrix $A$. However, they show that the dimensionality reduction step itself provides a privacy guarantee (whereas the aforementioned results did not exploit this and relied on noise added at a later stage). \citetall{Sheffet19} analyzes two additional techniques -- the addition of Wishart noise (i.e., $YY^T$ where the columns of $Y$ are independent multivariate Gaussians) and sampling from an inverse Wishart distribution (which has a Bayesian interpretation).

\citetall{ChaudhuriSS12}, \citetall{KapralovT13}, \citetall{WeiSCHT16}, and \citetall{AminDKMV18} apply variants of the exponential mechanism \cite{McSherryT07} to privately select a low-rank approximation to the covariance matrix $A$. This method is nontrivial to implement and analyse, but it ultimately requires the sample complexity to grow polynomially in the ambient dimension. %The exponential mechanism satisfies \emph{pure} differential privacy.%, and packing lower bounds \cite{HardtT10} can be used to show that a polynomial dependence on the dimension is necessary for any algorithm satisfying pure differential privacy.

\citetall{GonemG18} exploit smooth sensitivity \cite{NissimRS07} to release a low-rank approximation to the matrix $A$. This allows adding less noise than worst case sensitivity, under an eigenvalue gap assumption. However, the sample complexity $n$ is polynomial in the dimension $d$.

\paragraph{Limitations of Prior Work}
Given the great variety of techniques and analyses that have been applied to differentially private matrix analysis problems, what is missing?
We see that almost all of these techniques are ultimately based on some form of noise addition or the exponential mechanism. With the singular exception of the techniques of Sheffet \cite{Sheffet19}, all of these prior techniques satisfy pure\footnote{Pure differential privacy (a.k.a.~pointwise differential privacy) is $(\varepsilon,\delta)$-differential privacy with $\delta=0$.} or concentrated differential privacy \cite{BunS16}. This is enough to conclude that these techniques cannot yield the dimension-independent guarantees that we seek. No amount of postprocessing or careful analysis can avoid this limitation. This is because pure and concentrated differential privacy have strong group privacy properties, which means ``packing'' lower bounds \cite{HardtT10} apply.

We briefly sketch why concentrated differential privacy is incompatible with dimension-independent guarantees. Let the input be $X_1 = X_2 = \cdots = X_n = \xi/\sqrt{d}$ for a uniformly random $\xi \in \{-1,+1\}^d$. That is, the input is one random point repeated $n$ times. If $M$ satisfies $O(1)$-concentrated differential privacy, then it satisfies the mutual information bound $I(M(X);X) \le O(n^2)$ \cite{BunS16}. But, if $M$ provides a meaningful approximation to $X$ or $A = XX^T$, then we must be able to recover an approximation to $\xi$ from its output, whence $I(M(X);X) \ge \Omega(d)$, as the entropy of $X$ is $d$ bits. This gives a lower bound of $n \ge \Omega(\sqrt{d})$, even though $X$ and $A$ have rank $k=1$.

The above example shows that, even under the strongest assumptions (i.e., the data lies exactly in a rank-$1$ subspace), any good approximation to the subspace, to the data matrix $X$, or to the covariance matrix $A = XX^T$ must require the sample complexity $n$ to grow polynomially in the ambient dimension $d$ if we restrict to techniques that satisfy concentrated differential privacy. Almost all of the prior work in this general area is subject to this restriction.

To avoid a sample complexity $n$ that grows polynomially with the ambient dimension $d$, we need fundamentally new techniques.

\subsection{Our Techniques}

For the exact case, we construct a score function for subspaces that has low sensitivity, assigns high score to the correct subspace, and assigns a low score to all other subspaces. Then we can simply apply a $\GAPMAX$ algorithm to privately select the correct subspace \cite{BunDRS18}. 

The $\GAPMAX$ algorithm satisfies $(\varepsilon,\delta)$-differential privacy and outputs the correct subspace as long as the gap between its score and that of any other subspace is larger than $O(\log(1/\delta)/\varepsilon)$. This works even though there are infinitely many subspaces to consider, which would not be possible under concentrated differential privacy. 

The simplest score function would simply be the number of input points that the subspace contains. This assigns high score to the correct subspace, but it also assigns high score to any larger subspace that contains the correct subspace. To remedy this, we subtract from the score the number of points contained in a strictly smaller subspace. That is, the score of subspace $S$ is the number of points in $S$ minus the maximum over all subspaces $S' \subsetneq S$ of the number of points contained in $S'$.

This $\GAPMAX$ approach easily solves the exact case, but it does not readily extend to the approximate case. If we count points near to the subspace, rather than in it, then (infinitely) many subspaces will have high score, which violates the assumptions needed for $\GAPMAX$ to work. Thus we use a completely different approach for the approximate case.

We apply the ``subsample and aggregate'' paradigm of \cite{NissimRS07}. That is, we split the dataset $X_1, \cdots, X_n$ into $n/O(k)$ sub-datasets each of size $O(k)$. We use each sub-dataset to compute an approximation to the subspace by doing a (non-private) PCA on the sub-dataset. Let $\Pi$ be the projection matrix onto the correct subspace and $\Pi_1, \cdots, \Pi_{n/O(k)}$ the projection matrices onto the approximations derived from the sub-datasets. With high probability $\|\Pi_j-\Pi\|$ is small for most $j$. (Exactly how small depends on the eigengap.) Now we must privately aggregate the projection matrices $\Pi_1, \cdots, \Pi_{n/O(k)}$ into a single projection matrix.

Rather than directly trying to aggregate the projection matrices, we pick a set of reference points, project them onto the subspaces, and then aggregate the projected points. We draw $p_1, \cdots, p_{O(k)}$ independently from a standard spherical Gaussian. Then $\|\Pi_j p_i - \Pi p_i \| \le \|\Pi_j - \Pi\| \cdot O(\sqrt{k})$ is also small for all $i$ and most $j$. We wish to privately approximate $\Pi p_i$ and to do this we have $n/O(k)$ points $\Pi_j p_i$ most of which are close to $\Pi p_i$. This is now a location or mean estimation problem, which we can solve privately. Thus we obtain points $\hat p_i$ such that $\|\hat p_i - \Pi p_i\|$ is small for all $i$. From a PCA of these points we can obtain a projection $\hat\Pi$ with $\|\hat\Pi-\Pi\|$ being small, as required.

Finally, we discuss how to privately obtain $(\hat p_1, \hat p_2, \cdots, \hat p_{O(k)})$ from $(\Pi_1 p_1, \cdots, \Pi_1 p_{O(k)}), \cdots,$\\$(\Pi_{n/O(k)} p_1, \cdots, \Pi_{n/O(k)} p_{O(k)})$. It is better here to treat $(\hat p_1, \hat p_2, \cdots, \hat p_{O(k)})$ as a single vector in $\mathbb{R}^{O(kd)}$, rather than as $O(k)$ vectors in $\mathbb{R}^d$. We split $\mathbb{R}^{O(kd)}$ into cells and then run a differentially private histogram algorithm.
If we construct the cells carefully, for most $j$ we have that $(\Pi_j p_1, \cdots, \Pi_j p_{O(k)})$ is in the same histogram cell as the desired point $(\Pi p_1, \cdots, \Pi p_{O(k)})$. The histogram algorithm will thus identify this cell, and we take an arbitrary point from this cell as our estimate $(\hat p_1, \hat p_2, \cdots, \hat p_{O(k)})$. The differentially private histogram algorithm is run over exponentially \vnote{infinitely?} many cells, which is possible under $(\varepsilon,\delta)$-differential privacy if $n/O(k) \ge O(\log(1/\delta)/\varepsilon)$. (Note that under concentrated differential privacy the histogram algorithm's sample complexity $n$ would need to depend on the number of cells and, hence, the ambient dimension $d$.)

The main technical ingredients in the analysis of our algorithm for the approximate case are matrix perturbation and concentration analysis and the location estimation procedure using differentially private histograms.
Our matrix perturbation analysis uses a variant of the Davis-Kahan theorem to show that if the empirical covariance matrix is close to the true covariance matrix, then the subspaces corresponding to the top $k$ eigenvalues of each are also close; this is applied to both the subsamples and the projection of the reference points.
The matrix concentration results that we use show that the empirical covariance matrices in all the subsamples are close to the true covariance matrix.
This is the only place where the multivariate Gaussian assumption arises. Any distribution that concentrates well will work.

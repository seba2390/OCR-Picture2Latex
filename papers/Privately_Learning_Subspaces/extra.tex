\section{Approximate case}

What if the points are only close to a subspace?

\subsection{TV distance between 1-d gaussians}
%By [\url{https://arxiv.org/pdf/1810.08693.pdf} Thm.~1.1], \[ \mathrm{d}_{\mathrm{TV}} (\mathcal{N}(0,\Sigma_1),\mathcal{N}(0,\Sigma_2) = \Theta\left(\sqrt{\sum_i^d \lambda_i^2}\right),  \]
where $\lambda_1, \cdots, \lambda_d$ are the eignenvalues of $\Sigma_1^{-1} \Sigma_2 - I$.

In our setting $\Sigma_1 = xx^T + \gamma I$ and $\Sigma_2 = yy^T + \gamma I$.

%By [\url{https://en.wikipedia.org/wiki/Sherman-Morrison_formula}], \[\Sigma_1^{-1} = (\gamma I + xx^T)^{-1} = \gamma^{-1} I - \frac{\gamma^{-1} I x x^T \gamma^{-1} I}{1 + x^T \gamma^{-1} I x} = \gamma^{-1} I - \frac{\gamma^{-2}}{1 + \gamma^{-1} \|x\|_2^2} xx^T.\]
Thus 
\begin{align*}
    \Sigma_1^{-1} \Sigma_2 - I &= \left( \gamma^{-1} I - \frac{\gamma^{-2}}{1 + \gamma^{-1} \|x\|_2^2} xx^T \right) \left( \gamma I + yy^T \right) - I\\
    &=\frac{\gamma^{-1}}{1 + \gamma^{-1} \|x\|_2^2} \left( (1 + \gamma^{-1} \|x\|_2^2)yy^T -  xx^T - \gamma^{-1} \langle x, y\rangle xy^T \right)\\
    &=\frac{\gamma^{-1}}{1 + \gamma^{-1} \|x\|_2^2} \left( yy^T -  xx^T + \gamma^{-1} \left( y x^Tx y^T - x x^Ty y^T\right)\right)\\
\end{align*}

\subsection{Case: $k\leq2$}

Algorithm:
\begin{enumerate}
    \item Truncate all points to within a ball of radius
        $O(\sqrt{d\log(n)})$.
    \item Choose reference points $p_1,p_2$ uniformly at
        random on $\cS^{d-1}$.
    \item Randomly partition the dataset into subsets of
        size $k=2$.
    \item For each subset $\{X_{2i},X_{2i+1}\}$:
        \begin{itemize}
            \item Normalise the data points to get
                $Y_{2i},Y_{2i+1}$ respectively.
            \item Project $p_1,p_2$ on to the subspace spanned
                by $Y_{2i},Y_{2i+1}$, and the origin.
            \item Let $Z_i$ be the $kd$-dimensional vector
                containing the projected points.
        \end{itemize}
    \item Run private histograms with randomised offset to collect
        the two clusters.
    \item Truncate all $Z_i$'s to within the nearest histogram
    cluster.
    \item Return the noisy empirical mean of all the $Z_i$'s.
\end{enumerate}

The following definition characterises what good pairs of
points are. A good pair is essentially a pair of points where
both points are far enough from the origin, and their respective
normalised projections with respect to the parameter subspace
are also far from one another.
\begin{definition}[$(\tau,\Pi)$-Aligned Points]
    Let $p_1,p_2 \in \R^d$ and let $\Pi$ be a $k$-dimensional
    subspace of $\R^d$. Suppose $p'_1,p'_2$ are their respective
    projections on to $\Pi$, and $p''_1,p''_2$ are $p'_1,p'_2$
    respectively on being normalised. We say that $p_1,p_2$
    are $(\tau,\Pi)$-aligned if $\|p_1\|,\|p_2\| \geq \tau$,
    $\|p''_1-p''_2\| \geq \tau$ and $\|p''_1+p''_2\| \geq \tau$.
    When the context is clear, we get rid of $(\tau,\Pi)$
    for brevity.
\end{definition}

This definition characterises points if their projections on
to the parameter subspace could be potentially collinear using
sectors of a circle.
\begin{definition}[$(\tau,\Pi)$-Collinear Set]
    Let $S=\{p_1,p_2\}$ be a set of unit vectors, and let $\Pi$
    be a $2$-dimensional subspace of $\R^d$. Suppose $p'_1,p'_2$
    are their respective projections on to $\Pi$, and
    $p''_1,p''_2$ are $p'_1,p'_2$ respectively on being normalised.
    Suppose we divide the unit circle around the origin
    in $\Pi$ into sectors of maximum width $\sqrt{\tau}$.
    We say that $S$ is collinear if $p_1,p_2$ lie in sectors,
    where collinearity of $p_1,p_2$, and the origin is possible.
\end{definition}
Rephrase the last sentence of the definition.

\begin{lemma}
    Let $\Pi$ be a $k$-dimensional subspace of $\R^d$,
    and $p_1,p_2\in\mathcal{S}^{d-1}$ be random unit vectors.
    Then with probability at least $BLAH$, $p_1,p_2$ are
    $(\tau,\Pi)$-aligned.
\end{lemma}
\begin{proof}
    Enough to prove that (1) the points are
    at least $\tau$ far from the origin (easy to generalise
    to $k>2$), and (2) $\{p_1,p_2\}$ is not $(\tau,\Pi)$-collinear.
\end{proof}

\begin{corollary}
    Reference points are aligned with respect to the true
    subspace.
\end{corollary}

\begin{lemma}
    Let $x,y \in \R^d$, such that $\langle x,y \rangle = 0$,
    and let $p_1,p_2 \sim \cN(0,x^Tx + y^Ty + \gamma \id)$.
    Suppose $\Pi$ is the subspace spanned by $x,y$. Then with
    probability at least $BLAH$, $p_1,p_2$ are $(\tau,\Pi)$-aligned.
\end{lemma}
\begin{proof}
    Enough to prove that (1) the points are
    at least $\tau$ far from the origin using the PDF of
    a two-dimensional Gaussian (easy to generalise
    to $k>2$), and (2) $\{p_1,p_2\}$ is not $(\tau,\Pi)$-collinear.
\end{proof}

\begin{corollary}
    At least half the subsets are aligned with respect to
    the true subspace and are at most $O(\gamma\sqrt{d})$
    from their projections on the true subspace.
\end{corollary}
\begin{proof}
    Chernoff bound for the first part. For the second part,
    apply Gaussian tail bound for remaining $d-k$ directions
    for all $n$ points.
\end{proof}

\begin{definition}[$\tau$-Close Subspaces]
    Let $\Pi_1,\Pi_2$ be subspaces of $\R^d$ with the same
    dimensions. Let $p$ be an arbitrary point in the unit
    ball around the origin. We say that $\Pi_1,\Pi_2$ are
    $\tau$-close if for any such $p$,
    $\|\Pi_1 p - \Pi_2 p\| \leq \tau$.
\end{definition}

\begin{lemma}
    Let $\Pi_1$ be a subspace, and $p_1,p_2$ be
    $(\tau,\Pi_1)$-aligned. Suppose $p'_1,p'_2$ are their
    respective projections on to $\Pi_1$, and
    $\|p_i-p'_i\| \leq \tau$ for $i = 1,2$. If $\Pi_2$
    is the subspace spanned by $p_1,p_2$, and the origin,
    then $\Pi_1,\Pi_2$ are $\tau\sqrt{d}$-close.
\end{lemma}
\begin{proof}
    Geometry. EZ PZ.
\end{proof}

\begin{corollary}
    Let $x,y \in \cS^{d-1}$, such that $\langle x,y \rangle = 0$,
    and let $X_1,\dots,X_n \sim \cN(0,x^Tx + y^Ty + \gamma \id)$.
    Suppose $\Pi$ is the subspace spanned by $x,y$, and the origin.
    Let $\{X_1,X_2\},\dots,\{X_{n-1},X_n\}$ be disjoint subsets.
    Then with probability at least $BLAH$, the subspaces spanned
    by at least half of the subsets (and the origin) are
    $\tau\sqrt{d}$-close to $\Pi$.
\end{corollary}

\begin{lemma}
    Let $\wh{Z}$ be the empirical mean of all the $Z_i$'s in the
    algorithm. Then the sensitivity of $\wh{Z}$ is
    square root of twice the size of a single cluster, over $n$.
\end{lemma}

\begin{lemma}
    With probability at least BLAH, there are two histogram clusters, and the ``size'' of each histogram cluster is at most $BLAH$.
\end{lemma}

\section{Approximate case}

Let $X_1, \cdots, X_m \gets \mathcal{N}(0,\sum_i^k u_i u_i^T)$, where $\langle u_i, u_j \rangle = \mathbb{I}[i=j]$ for all $i,j \in [k]$. Let $\xi_1, \cdots, \xi_m \gets \mathcal{N}(0,\gamma I)$. Assume everything is independent. Let $\tilde{X}_i = X_i + \xi_i$ for all $i \in [m]$.

Let $Y \gets \mathcal{N}(0,I)$ be independent from everything else. Let $\hat{Y}$ be the projection of $Y$ onto the space spanned by $u_1, \cdots, u_k$. Note that $\hat Y$ has the same distribution as $X_i$ and that $\hat Y$ is also the projection of $Y$ onto the space spanned by $X_1, \cdots, X_m$. 

Let $\tilde Y$ be the projection of $Y$ onto the space spanned by $\tilde{X}_1, \cdots, \tilde{X}_m$. We wish to show that $\|\hat{Y} - \tilde{Y}\|$ is small on average.



That is, $\hat Y = X(X^TX)^{-1}X^TY$ and $\tilde Y = \tilde{X}(\tilde{X}^T\tilde{X})^{-1}\tilde{X}^TY$. Here $X \in \mathbb{R}^{d \times m}$ is the matrix with $X_1, \cdots, X_m \in \mathbb{R}^d$ as columns.

\begin{comment}
We have $\hat Y = \sum_i^m \alpha_i X_i$ and $\tilde Y = \sum_i^m \tilde\alpha_i \tilde{X}_i$ for appropriate weights. Now 
\begin{align*}
    \|\hat{Y} - \tilde{Y}\| &= \left\|\sum_i^m \alpha_i X_i -\tilde\alpha_i \tilde{X}_i\right\|\\
    &= \left\|\sum_i^m (\alpha_i -\tilde\alpha_i) X_i - \tilde\alpha_i \xi_i\right\|\\
    &\le \sum_i^m |\alpha_i-\tilde\alpha_i| \cdot \|X_i\| + |\tilde\alpha_i|\cdot\|\xi_i\|
\end{align*}

\begin{conj}
Let $y \in \mathbb{R}^d$. Let $S_1, S_2$ be subspaces of dimension $k$. Let $y_i$ be the projection of $y$ onto $S_i$. Let $y_{i,j}$ be the projection of $y_i$ onto $S_j$. Suppose $\|y_1 - y_{1,2}\|\le \gamma$. Then $\|y_1 - y_2\|\le f(\gamma, k, d, \|y\|)$, where $f$ is ``small'' -- specifically, $\lim_{\gamma\to0} f(\gamma,k,d,r)=0$ for all $k$, $d$, and $r$.
\end{conj}
Conjecture is bad: Suppose $y \in S_2$ and $y$ is orthogonal to $S_1$. Then $y_1=y_{1,2}=0$ and $y_2=y$. So $\gamma=0$ and $\|y_1-y_2\|=\|y\|$.
\end{comment}

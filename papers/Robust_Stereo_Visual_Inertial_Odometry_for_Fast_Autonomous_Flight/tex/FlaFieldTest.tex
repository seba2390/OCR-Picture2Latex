\subsection{Autonomous Flight in Unstructured Environments}
\label{subsec: fla field test}
The proposed S-MSCKF has been thoroughly tested in various field experiments. In this section, we show an example of a fully autonomous flight where the robot has to first navigate through a wooded area, then look for an entrance into a warehouse, find a target, then return to the starting point. This experiment is illustrative since it includes a combination of different kinds of environments as well as common challenges for vision-based estimation including feature poverty, aggressive maneuvers, and significant changes in lighting conditions during indoor-outdoor transitions. 

Figure \ref{fig: fla experiment iv} shows the global laser point cloud and round-trip trajectory overlaid on the Google satellite map.  Note that, during the experiment, the laser measurement is used for mapping only. The state estimation is solely based on the stereo cameras and IMU as the sensor configuration given in Section~\ref{subsec: fast flight dataset}. Over $700$m round-trip trajectory, the final drift is around $3$m, which is less than $0.5\%$ of the total traveled distance despite the combination of various challenges along the flight. More details of this trial can be found in the supplementary video\footnote{https://youtu.be/jxfJFgzmNSw}

\begin{figure}[htp]
\centering
\includegraphics[width=0.45\textwidth]{figures/fla_experiment_iv_map.png}
\caption{The global map and round-trip trajectory overlaid on the Google satellite map in an fully autonomous flight experiment. The \textcolor{blue}{blue}, \textcolor{red}{red}, and \textcolor{yellow}{yellow} dots represents the staring point, goal location, and the only entrance of the warehouse respectively. The global laser point cloud is registered using the estimation produced by the S-MSCKF. Over $700$m trajectory, the final drift is around $3$m under $0.5\%$ of the total traveled distance.}
\label{fig: fla experiment iv}
\end{figure}
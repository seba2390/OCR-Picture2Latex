

\section{Data Generation}
\label{sec:appendix_data_generation}
% \gabis{Also, I think we should have a central place for examples of the different biases, e.g., in a nice table which can act as reference for readers throughout the paper. Then the text here can interact with the table: ``For the decoy bias, we see in Table ...''}

% \gabis{I think the text here abuses the verb ``create'' here. Maybe before starting to describe each bias, describe this ``creation'' process? Are there any common elements in writing the examples to all biases? }
% \itay{I rephrased every 'create' in here to a more suitable word in each case (not sure if that is what you meant).
% I also added a common element, but most of the description is specific for each bias.}

\input{Sections/Tables/data_numbers}

To thoroughly examine the models and mitigate potential confounders we carefully design a range of prompts to assess the models' susceptibility to the three biases.
We generate an extensive collection of \biaseddataset{} and control samples, encompassing various options' values, textual templates, and permutations of option order.

By employing this approach, we aim to introduce substantial variability among the samples while ensuring independence from the original papers' examples, thus minimizing the risk of data contamination.
We elaborate on the data generation process of each one of the biases.
A table representing the total number of samples in each bias is in Table \ref{appendix:tab:data_numbers}


\subsection{Decoy Effect Data}
\label{subsec:data_gen_decoy}
To generate the data for the decoy effect, we follow \cite{huber1982adding} and compose a set of textual prompts, each posing a selection from four different product categories: cars, phones, frying pans, and real estate properties.
Depending if the sample is from the control or from the \biaseddataset{} dataset, each example involved either two or three product alternatives, each with two attributes - product price and quality rating.

In each conditions, we compared two conditions:
% \nir{`setting' sounds like something you make comparisions within -- not accross.}
% \nir{as i said, i would save the word `bias' for the general effect and measurement; consider calling this `control' and `treatment' instead}
\begin{enumerate}
    \item \textbf{Control -- Two Options} Two options are presented: the \textit{Target Option} and the \textit{Competitor Option}.
    \item \textbf{\Biaseddataset{} -- Third Decoy Option} Three options are presented. In addition to \textit{Target Option} and \textit{Competitor Option}, we added the \textit{Decoy Option}.
    % \item \textbf{False Decoy} Three options are presented. \textit{Target Option} and \textit{Competitor Option},  and we add a third \textit{Decoy Option} which is deliberately chosen \textit{not} to be a decoy option according to the definition to act as a control.
\end{enumerate}

We chose price values according to the actual price ranges from web consumer stores or by prompting the model for a reasonable price range.
We chose low-end and high-end products as our two options in the control condition.

To create the decoy option, we follow \citep{huber1982adding} and create four possible decoys according to the target option, each is worse than the target in the price dimension (more expensive, same quality), or the quality dimension (less quality, same price), or a combination of both.


We constructed variations with different price and quality gaps between the options, five different textual templates, and permutations between the location of each option.


\subsection{Certainty Effect Data}
Similarly to the decoy effect, we follow the original work by \citet{kahneman1979prospect} to generate our data.
In both conditions,  two options for getting prize money with different probabilities are presented. One option is with a lower excepted utility than the other (\textit{Target}) while the other option with a higher excepted utility (\textit{Higher Excepted Value}).

% \nir{could we rewrite this to emphasize that both conditions are the same expect that in the treatment condition `high probability' is actually 1?}
\begin{enumerate}
\item \textbf{\Biaseddataset{} - Certainty} The lower excepted utility \textit{Target} option is certain, while the other option with a higher excepted utility is given at some probability (\textit{Higher Excepted Value}).
\item \textbf{Control - No Certainty} The lower excepted utility \textit{Target} option has a higher probability, while the other option (\textit{Higher Excepted Value})  has a higher excepted utility with a lower probability.
\end{enumerate}

In both conditions, the probability gap between the options was held constant.
For instance, in the \biaseddataset{} condition, if one option was certain (100\%) and the other option had an 80\% chance of yielding a reward, the corresponding options in the control condition would have a 20\% probability gap.
% We obtained the values for prize rewards and probabilities from \cite{Kahneman1979ProspectTA} and also included additional values that maintained the same relationships.
% \nir{i would start the paragraph with this; otherwise readers will think we've invented this experimental paradigm (and only then find out we didn't)}

Similar to the decoy effect, we used a diverse set of prompts using 4 different sub-template combinations and options permutations to create our test set.

\input{Sections/Tables/table_not_probable}

\subsection{Belief Bias Data}

To explore the belief bias in LMs we conduct our experiments using the data generated by \citet{dasgupta2022language}.

% To explore the Belief bias in LMs we also conduct two experiments.
The model is presented with two premises and a conclusion and instructed to choose if the conclusion stems directly from the premises.
If the conclusion logically stems from the premises the model should output 'Valid', otherwise, it should output 'Invalid'.

Here there are two conditions, the bias condition where each argument is believable or unbelievable, and the control condition where the arguments are neutral in terms of believability.
% To control the effect of believability on the performance of the model we run a control experiment, in which we use a different set of objects in each experiment.
% \nir{not really clear what the treatment is at this point}

\begin{enumerate}
    \item \textbf{\Biaseddataset{} - Real-Life Objects } The objects the logical reasoning is based on \textit{real-life} objects, which can have believable or unbelievable nature according to world knowledge (e.g. ``cigarettes are addictive'' as believable, ``cigarettes are non-addictive'' as unbelievable).
    .\item \textbf{Control - Non-real Objects}  The objects the logical reasoning is based on our \textit{non-real} objects using made-up words, which do not have believable or unbelievable nature according to world knowledge (e.g ``wobars are shnesive'' and ``wobars are non-shnesive''), which create neutral arguments.
\end{enumerate}

The valid-believable and invalid-unbelievable conclusions in the condition of the Real-life object are considered as consistent conclusions and valid-unbelievable and invalid-believable are the inconsistent conclusions.
% In this bias, since there is a correct answer we can also measure the model accuracy on the task.
See \citet{dasgupta2022language} for more details on the belief bias data generation process.

% The real-life objects were taken from the original work on Belief bias \cite{evans1983conflict}.
% The non-real objects were created with made-up words that follow the grammatical English rules.

% To generate the non-real samples, we transformed each real-life sample by replacing each real-life object with a corresponding non-real object ("cigarettes" $\rightarrow$ "wobars"; "addictive" $ \rightarrow $ "shnesive").
% % This resulted in a set of non-real samples that were split into believable and unbelievable groups based on their alignment with real-life samples, even though believability has no meaning in the context of non-real objects.
% % This split allows for easier comparison of the results with those of real-life objects.

% We designed the data such that each conclusion could be either valid or invalid and believable or unbelievable, and we included an equal number of samples for each combination of attributes. To create a diverse set of samples, we used 5 different text templates and 3 different object sets, resulting in a total of 766 samples after permuting the premises.

% Beyond using our own data, we also used data from \cite{dasgupta2022language} where they used hand-crafted real-life objects which allow a higher level of unbelievability, and we report our result for both datasets.

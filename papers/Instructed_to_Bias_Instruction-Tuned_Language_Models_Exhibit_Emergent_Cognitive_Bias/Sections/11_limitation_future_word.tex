\section{Limitations}

This study has several limitations.
First, the biases we examine are well-known, potentially leading to data contamination despite our efforts to introduce variations through different text templates and values we employ ourselves.
Second, the reliance on specific OpenAI models poses a limitation as their training details are undisclosed, and the future availability of these models is uncertain.
Nonetheless, our findings contribute to the understanding of cognitive biases in language models and provide insights for bias mitigation in NLP systems.
Beyond that, we focus only on English-based models so our results reflect existing biases only in English.

\section{Future Work}
Future work involves two key aspects. First, further exploration of both known and potentially unknown cognitive biases exhibited by language models is necessary to broaden our understanding.
This will provide insights into the comprehensive landscape of biases in NLP systems.
Second, it is crucial to advance debiasing methods based on promising initial findings. By refining and expanding these techniques, we can progress toward the development of more reliable and unbiased language models for practical applications.

\section*{Acknowledgment}
We would like to express our sincere gratitude to Ishita Dasgupta, Andrew K. Lampinen, and the entire team at \citet{dasgupta2022language} for generously sharing their valuable data.
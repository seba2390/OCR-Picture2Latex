



\section{Problem Statement}
\label{sec:problem}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\comment{
\begin{figure*}[t]
	% \vspace{-0.3cm}
	\centering
	\begin{tabular}[h]{c}
		\hspace{-0.8cm}
		%\vspace{-0.3cm}
		\subfigure[Single Graph Shared Communities] {
			\includegraphics[ width=0.55\columnwidth]{fig/sgsc.pdf}
			\label{fig:task:sgsc}
		}
		\subfigure[Single Graph Disjoint Communities] {
			\includegraphics[ width=0.55\columnwidth]{fig/sgdc.pdf}
			\label{fig:task:sgdc}
		}
		\subfigure[Multiple Graphs Disjoint Communities] {
			\includegraphics[ width=0.55\columnwidth]{fig/mgdc.pdf}
			\label{fig:task:mgdc}
		}	
	\end{tabular}
	\vspace{-0.3cm}
	\caption{Three Task Structures for Community Search}
	\vspace{-0.3cm}
	\label{fig:task}
\end{figure*}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\comment{
\begin{table}[t]
	\begin{center}
		{\footnotesize
			\caption{Frequently Used Notations} \label{tab:notation}
			\vspace{-0.2cm}
			\begin{tabular}{p{0.2\columnwidth}|p{0.7\columnwidth}} \hline
				{\bf Symbols} & {\bf Definitions} \\ \hline
				$G(V, E)$  & An undirected graph with nodes $V(G)$ and edges $E(G)$ \\ \hline
				$\mathcal{N}(v)$ & the neighbors of node $v$ \\ \hline
				$ \mathcal{A}$ & The node attributes \\ \hline
				$\community_q(G)$ & The communities containing node $q$ in graph $G$ \\ \hline 
				$\task = (G, Q, L)$ & A learning task with graph $G$, queries $Q$ and ground-truth $L$ \\ \hline
				$\Fagg/\Fcom$ & The aggregate/combine function of a GNN layer. \\ \hline
				$h_v^{(k)}$ & Representation of node $v$ in the $k$-layer of GNN. \\ \hline
				$\loss(q;\theta)$ & The loss of query $q$ with model parameters $\theta$ \\ \hline
				$l_q/ \hat{l_q}$ & The ground-truth/binary prediction of query node $q$\\ \hline
				$\support/\query$ & The support/query set \\ \hline
				$\phi_\theta/\rho_\theta$ & The encoder/decoder of CGNP with parameter $\theta$ \\ \hline
				$I_q(v)/I_l(v)$ & The query/label identifier of node $v$ \\ \hline
				$H_q$ & The representation view specific to query node $q$ \\ \hline	
				$H$ & The representation combined by multiple $H_q$ views \\ \hline			
			\end{tabular}
		\vspace{-0.4cm}
		}
	\end{center}
\end{table}
}



We consider an undirected simple graph ${\cal G} = (V, E)$, where
$V({\cal G})$ is the node set and $E({\cal G})$ is the edge set. Let
$n = |V({\cal G})|$ and $m = |E({\cal G})|$ denote the number of nodes
and edges, respectively.
%We also use a symmetric adjacency matrix $A \in \{0, 1\}^{n \times n}$ to represent of a graph where $a_{ij} = 1$ if and only if there is an edge $(v_i, v_j) \in E$ connecting a pair of nodes $v_i, v_j \in V(G)$.  
The neighborhood of node $v$ is denoted as $\mathcal{N}(v) = \{ u |
(u, v) \in E({\cal G}) \}$.  The nodes may possess $d$ attributes
$\mathcal{A} = \{ \mathcal{A}_1, \cdots, \mathcal{A}_d\}$.  For each
node $v$, a one-hot $d$-dimensional vector $\mathcal{A}(v) \in \{0,
1\}^d$ encodes whether $v$ is associated with the $d$ attributes in
$\mathcal{A}$.
%
In the following, we use ${\bf G}$ to represent a large data graph.  A
\emph{community} in ${\bf G}$ is a cohesive subgraph $G = (V, E)$
induced by its node set $V(G)$, such that the nodes $V(G)$ are
intensively connected within $G$ whereas are sparsely connected with
other nodes in the graph, i.e., $|E(G)| \gg |\{ (u, v) | u \in V(G), v
\in V({\bf G}) \setminus V(G) \}|$.  Below, we denote a community as
an induced subgraph in a graph $G$ by $\community(G)$.

\stitle{Problem Statement (Community Search):}
The community search problem is to find the
query-dependent community $\community_q$, for a user-given query node
$q$ in a graph $G$, such that $q \in \community_q(G)$. Distinguished
from prior algorithmic approaches~\cite{ATC, ACQ, CTC}, the community
$\community_q(G)$ in this paper is not restricted in any $k$-related
subgraph, instead it is learned from given community membership
ground-truth.

We construct a meta model $\model$ to
support community search queries in a data graph ${\bf G}$ by multiple
tasks.  The model $\model$ is trained on a set of training tasks
$\mathcal{D} = \{ \task_i\}_{i = 1}^{N}$.  Here, a training task,
$\task_i$, is a triplet $\task = (G, Q, L)$, where $G$ is a subgraph
of ${\bf G}$, $Q= \{ q_1, \cdots, q_{j} | q_{i} \in V(G)\}$ is a set
of $j$ query nodes in $G$, and $L = \{ l_{q_1}, \cdots, l_{q_j}\}$ is
the ground-truth of the $j$ query nodes, respectively.  Specifically,
$l_{q}$ is a nonempty set of nodes in $G$ w.r.t. the query node $q$,
that contains a set of positive samples, $l_q^+ \subset
\mathcal{C}_{q}(G)$, and a set of negative samples, $l_q^{-} \subset
(V(G) \setminus \community_{q}(G))$.
% 
 For a new test task $\task^*= (G^*, Q^*, L^*)$, the meta model $\model$ will exploit the query node set $Q^*$ associated
with the ground-truth $L^*$ to adapt to task $\task^*$, and
can make community search prediction for nodes in $V(G^*)\setminus Q^*$. Note that for test task, the number
of query nodes in $Q^*$, named shots, is rather limited, i.e., $|Q^*| \ll |V(G^*)|$.

%Table~\ref{tab:notation} lists the frequently used notations throughout this paper.

It is important to mention that the main idea behind multiple tasks is
that it is difficult to obtain all required ground-truth to train.
There are many possible scenarios with different ways that the
training task set $\mathcal{D}$ and new test tasks are constructed.
%
%In this paper, we explore the following three task structures, whose diagrammatic sketches are shown in Fig.~\ref{fig:task}.
%
In this paper, we construct tasks from two dimensions: Single/Multiple
graphs and Shared/Disjoint communities.
%
% By Single/Multiple graphs, all
% communities to find are from a single or multiple large data graphs.
% By Shared/Disjoint communities, the training tasks are used to train a
% model for communities that are the same/different for a query node in
% a test task to test.
%
% we explore three generalized task structures that represent
% comprehensive CS query scenarios.  
%
% The diagrammatic sketches of the task structures are shown in
% Fig.~\ref{fig:task}.


%\begin{figure*}
%	\begin{tabular}{c}
%		\includegraphics[width=1\textwidth]{fig/task.pdf}
%	\end{tabular}
%	\caption{Three task configuration for our model.}
%	\label{fig:task}
%	\vspace*{-0.0cm}
%\end{figure*}

\begin{itemize}[noitemsep,topsep=0pt,parsep=5pt,partopsep=0pt,leftmargin=*]
\item {\sl Single Graph Shared Communities.}
%  (Fig.~\ref{fig:task:sgsc}).}
The graphs in any training task, $G$, and test task, $G^*$, are
subgraphs of a single large graph ${\bf G}$. The query nodes in
training/test tasks are different but are from the same communities in
${\bf G}$.

\item {\sl Single Graph Disjoint Communities.}
%  (Fig.~\ref{fig:task:sgdc}).}
The graphs in any training task, $G$, and test task $G^*$, are
subgraphs of a single large graph ${\bf G}$. The query nodes in
training/test task are from different communities in ${\bf G}$, such
that $\community_{q}(G) \cap \community_{q^*}(G^*) = \emptyset$, for
all $q \in Q$ and $q^* \in Q^*$.

\item {\sl Multiple Graphs Disjoint Communities.}
%  (Fig.~\ref{fig:task:mgdc}).}
The graphs in any training task, $G$, and test task, $G^*$, are from
different large data graphs. The query nodes in training/test tasks
are from different communities.  Here, all the subgraphs $G$ in the
training tasks are from the same domain, whereas a subgraph $G^*$ in a
test task can be in the same or a different domain.
%  
%$G$ and $G^*$ can be different graphs in the same domain, or in
%different domains. But all the graphs in the training tasks are from
%the same domain.  
\end{itemize}

\begin{example}
% We use an example to further explain the different type of tasks.
% Here, `Single Graph' means that all the training tasks and test tasks
% are on a single large graph.
Assume that the DBLP graph in Fig.~\ref{fig:case} is a single graph
${\bf G}$. A graph $G$ in a training task $\task = (G, Q, L)$ and a
graph $G^*$ in a test task $\task^* = (G^*, Q^*, L^*)$ are subgraphs
of ${\bf G}$.  Suppose a subgraph $G$ in a training task contains a
part of the community that `Jure' belongs to (i.e., the orange nodes)
in Fig.~\ref{fig:case}.  In the scenario of shared communities,
% (Fig.~\ref{fig:task:sgsc}),
some nodes in $Q^*$ in a test task $\task^*$ may contain some
ground-truth (e.g., orange nodes) that do not appear in any training
tasks.  The model $\model$ trained is to find the community for any
query node in $Q^*$ in the same test task $\task^*$ without any
ground-truth associated with.
%
In the scenario of disjoint communities,
% (Fig.~\ref{fig:task:sgdc}),
the ground-truth given in a test task may have nothing to do with the
community that 'Jure' belongs to.  The model $\model$ trained is to
find the community for any query node in $Q^*$ in the test task
$\task^*$ without any ground-truth associated with. Note that the
community to be found is a different community that 'Jure' belongs to.
%
For the scenario of multiple graphs, a subgraph $G$ in a training task
$\task$ is from a data graph, ${\bf G}$, whereas a subgraph $G^*$ in a
test task is from a different data graph ${\bf G}'$.
%
\comment{ Single Graph with
  Shared Communities, which indicates the training and test tasks have
  overlapped community information. If the test task does not contain
  any orange node of the community of `Jure', but contains partial
  yellow nodes in other communities, this is the scenario of
  Fig.~\ref{fig:task:sgdc}, Single Graph with Disjoint Communities. If
  $G$ and $G^*$ are different graphs, e.g., one is from DBLP graph and
  the other is ACM graph, this is the scenario of
  Fig.~\ref{fig:task:mgdc}, Multiple Graphs with Disjoint Communities.
}
\end{example}

\comment{
\kfadd{
\begin{example}
We use an example to further explain the differences of the three types of task. 
Suppose a training task $\task = \{G, Q, L\}$ from training task set $\mathcal{D}$, a test task $\task^* = \{G^*, Q^*, L^*\}$. 
Both $G$ and $G^*$ are local subgraphs of the DBLP graph.
Suppose $V(G) = \{ Danel, Julian, Xiaolin, Eric, Jure\}$, $Q=\{ Eric\}$ and $V(G^*) =\{ David, Andrew, Christopher, Dan, Ravi\}$, $Q^*=\{ David\}$. 
They are in the type of single graph with shared communities because query nodes with ground-truth, $Eric$ and $David$ are from the same community, which is the ego-centric network of 'Jure'. It indicates the supervision information of train and test tasks have some degree of overlap. 
If $Q^* = \{$`Christopher' $\}$, they are in the type of single graph with disjoint communities, ase `Eric' and `Christopher' are from different communities. 
\end{example}
}
}

\comment{
\textcolor{blue}{
	\begin{example}		To better understand the three scenarios proposed above, we give examples to illustrate it with Fig.~\ref{fig:task}.
		\begin{itemize}[noitemsep,topsep=0pt,parsep=5pt,partopsep=0pt,leftmargin=*]
			\item {\sl Single Graph with Shared Communities.} Suppose the graph $G$ in Fig.~\ref{fig:task:sgsc} is a co-authorship network, DBLP in Fig.~\ref{fig:case}, while a Train task \{1-Jure, 10-Andrew, 69-Eric, 81-Julio, 90-LadaA\} and a Test Task \{12-Deepayan, 16-Julian, 32-Jaewon, 92-PaeaLe, 100-Jeff\} are constituted from $G$ as Fig.~\ref{fig:task:sgsc} shows. The query node '1-Jure Leskovec' for Train Task and '16-Julian McAuley' for Test Task are both from the same community. Given query nodes '16-Julian McAuley' in Test Task, we aim to find those nodes that are in the same community with it, i.e., \{12-Deepayan, 32-Jaewon\}.
			\item {\sl Single Graph with Disjoint Communities.} The single graph $G$ is still DBLP in Fig.~\ref{fig:case}. As Fig.~\ref{fig:task:sgdc} shows, Train Task is \{1-Jure, 10-Andrew, 69-Eric, 81-Julio, 90-LadaA\} and Test Task is \{50-Manuel, 51-Bernhard, 65-Matthew, 116-Paul, 117-Lee, 118-Alon\}. Different from SGSC, query node '1-Jure Leskovec' for Train Task and '116-Paul Bennett' for Test Task are from disjoint community. After trained on Train Tasks, the model has to test for disjoint community, i.e., find those nodes that are in the same community with '116-Paul Bennett'.
			\item {\sl Multiple Graphs with Disjoint Communities.} Take Facebook for example, the multiple graph $\{G_1, ... ,G_i\}$ can be ego network of Facebook, i.e., \{0-ego, 107-ego, ..., 3980-ego\}. A Train Task is a subset of $G_1$, 0-ego network while a Test Task is a subset of $G_i$, 3980-ego network. They are from different graph. It is natural that query nodes from Train Task and Test Task are from disjoint community.
		\end{itemize}
		\end{example}
}
}

\comment{
\begin{example}
	Consider a co-authorship network, DBLP in Fig.~\ref{fig:case} where vertices and edges represent researchers and their collaboration in papers. To better understand the three scenarios, we give example as follows.
	\begin{itemize}[noitemsep,topsep=0pt,parsep=5pt,partopsep=0pt,leftmargin=*]
		\item {\sl Single Graph with Shared Communities.} We first sample subgraphs to construct training task $\task_1=\{1, 10, 69, 81, 90\}$ and test task $\task_2=\{12, 16, 32, 92, 100\}$. Then we select query nodes '1-Jure Leskovec' and '16-Julian McAuley' which can be used as query nodes for $\task_1$ and $\task_2$, respectively. Their query nodes come from the same community.
		\item {\sl Single Graph with Disjoint Communities.} The query nodes must be sampled from different community. For training task $\task_1=\{1, 10, 69, 81, 90\}$, we select red nodes '1-Jure Leskovec' as query nodes. For test task $\task_2=\{50, 51, 65, 116, 117, 118\}$, yellow nodes '116-Paul Bennett' is selected as query nodes.
		\item {\sl Multiple Graphs with Disjoint Communities.} We can sample subgraphs from Fig.~\ref{fig:case} to construct training tasks while test tasks can be sampled from other dataset, i.e. \Citeseer. Naturally, the query nodes of them are naturally from different community. 
	\end{itemize}
\end{example}
}


\section{Naive Approaches}
\label{sec:naive}

\comment{
\begin{figure*}[t]
	\centering
	\begin{tabular}[h]{c}
		%\hspace{-0.8cm}
		%\vspace{-0.3cm}
		\subfigure[MAML: an Optimization-based View] {
			\includegraphics[ height=0.65\columnwidth]{fig/maml.pdf}
			\label{fig:views:maml}
		}
		\hspace{-0.2cm}
		\subfigure[GPN: a Metric-based View] {
			\includegraphics[ height=0.65\columnwidth]{fig/gpn.pdf}
			\label{fig:views:gpn}
		}
		\hspace{-0.2cm}
		\subfigure[CNP: a Kernel-based View] {
			\includegraphics[ height=0.65\columnwidth]{fig/kernel.pdf}
			\label{fig:views:kernel}
		}
		\hspace{-0.2cm}
		\subfigure[CGNP: a Metric-based View] {
			\includegraphics[ height=0.65\columnwidth]{fig/distance.pdf}
			\label{fig:views:distance}
		}	
		
	\end{tabular}
	\vspace{-0.2cm}
	\caption{Intuitions of MAML, GPN, CNP and CGNP}
	\vspace{-0.2cm}
	\label{fig:views}
\end{figure*}
}

To construct a meta model, a naive approach is to pre-train a Graph
Neural Network (GNN) model over $\mathcal{D}$ and finetune the model
for a new task $\task^*$. Below, we first introduce multi-label
classification by GNN, which serves as the basis of the naive
approaches and our meta-learning approach.

Given a graph $G$, a $K$-layer GNN follows a neighborhood aggregation paradigm to generate a new representation for each node by aggregating the representations of its neighbors in $K$ iterations. 
Let $h_v^{(k)}$ denote the representation of a node $v$ generated in the $k$-th iteration, which is a $d^{(k)}$ dimensional vector. 
In the GNN $k$-th iteration (layer), for each node $v \in V(G)$, an aggregate function $\Fagg^{(k)}$ aggregates the representations of the neighbors of $v$ that are generated in the ($k$-$1$)-th iteration as Eq.~(\ref{eq:gnn:fagg}). 
Then, a combine function $\Fcom^{(k)}$ updates the representation of $v$ by the aggregated representation $a_v^{(k)}$ and previous representation $h_v^{(k-1)}$ as Eq.~(\ref{eq:gnn:fcom}). 
\begin{align}
	a_v^{(k)} &= \Fagg^{(k)}(\{ h_u^{(k - 1)} | u \in \neighbor(v)\}) \label{eq:gnn:fagg} \\
	h_v^{(k)}  &= \Fcom^{(k)}(h_v^{(k - 1)}, a_v^{(k)}) \label{eq:gnn:fcom}
\end{align}
The functions $\Fagg^{(k)}$ and $\Fcom^{(k)}$ are neural networks, e.g., linear transformation with non-linearities and optional Dropout for preventing overfitting. 
%They transform $d^{(k -1)}$-dimensional node representation $h_v^{(k-1)}$ into $d^{(k)}$-dimensional representation $h_v^{(k)}$. 
The neural network parameters from $\Fagg^{(k)}$ and $\Fcom^{(k)}$ are shared by all the nodes.
%

For a given task $\task = (G, Q, L)$, a GNN can be built by training
over $Q$ and $L$, then is deployed to make predictions for any query
node $q \in V(G) \setminus Q$ as a query.  Concretely, a binary query
identifier $I_q(v) \in \{ 0, 1\}$ is concatenated with the attribute
feature vector $\mathcal{A}(v)$ to form the initial node
representation $h_{v}^{(0)}$, where $I_q(v) = 1$ if $v$ is the query
node $q$ otherwise $I_q(v) = 0$. Through transformation of $K$ layers,
the 1-dimensional node representation $h_v^{(K)}$ is activated by a
$\sigmoid$~function, i.e., $\hat{y}(v) = \sigmoid(h_v^{(K)})$, which
is the likelihood that $v$ is in the same community with query node
$q$.  The given $Q$ and the ground-truth $L$ provide
the training data for the GNN model.  For a known node $q \in Q$ with
its ground-truth $l_q = (l_q^{+}, l_q^{-})$, where $l_q^{+}$ and
$l_q^{-}$ are the positive and negative samples respectively,
w.r.t. $q$, the binary cross entropy (BCE) loss in
Eq.~(\ref{eq:loss:bce}) evaluates the divergence between the
predictive probability of the nodes from the positive and negative
samples, under the GNN with parameter $\theta$.
%
\begin{align}
	\label{eq:loss:bce}
	\loss(q; \theta) = - \sum_{v^{+} \in l_q^+} \log\hat{y}(v^+) -  \sum_{v^{-} \in l_q^-} \log (1-\hat{y}(v^-)) 
\end{align}
%
Based on the simple GNN approach, we review three naive approaches
which are simple combinations of GNN and meta/transfer learning
algorithms. 
%, i.e., direct feature transfer, GNN-based model-agnostic
%meta-learning, and graph prototypical network.

\stitle{Feature Transfer.}  The learned parameters of shallow layers in neural network 
%trained by one or multiple tasks 
can be transferred to new tasks, instead of learning from scratch. The intuition is that the pre-trained low-level feature transformation can be shared with a new task. 
%Usually, the parameters of the final layer of the neural network are updated by the training data of the new task by several gradient steps, whereas other parameters in the former layers are frozen in this procedure. 
Thereby, we can train a GNN by the union of all the $Q$ and $L$ of every training task $\task$ in the training set $\mathcal{D}$.
When a new task $\task^*$ arrives, the parameters of $\Fagg^{(K)}$ and $\Fcom^{(K)}$ will be updated by minimizing the BCE loss in Eq.~(\ref{eq:loss:bce}) over $Q^*$ and $L^*$ by several gradient steps. 
However, the effectiveness of simple feature transfer is limited. For one thing, this approach is originally proposed for convolutional neural network (CNN) to process image data, which has an explicit feature hierarchy to be transferred. However, whether the same transfer mechanism well suits GNN over graph data still needs exploration.  
For the other thing, it is hard to control the gradient steps in the fine-tuning procedure for various test tasks. 
%Too many steps will incur overfitting whereas too few will incur underfitting.


\stitle{Model-Agnostic Meta-Learning (MAML).} A meta GNN model can be built by a model-agnostic meta-learning algorithm, MAML~\cite{MAML}, over a set of training tasks $\mathcal{D}$.
MAML is a two-level end-to-end optimization algorithm, where the lower level is to optimize task-specific parameters $\theta_i$ for one task $\task_i$ and the upper level is to optimize the task-common parameters $\theta^*$ over the training task set $\mathcal{D}$. 
The learned task-common parameters $\theta^*$ will be used as the neural network initialization and updated by a few gradient steps to generalize a new task $\task^*$, given the few-shot task-specific data $Q^*$ and $L^*$.
To be concrete, training data $Q_i = \{q_{j}\}_{j = 1}^{J}$ and $L_i = \{l_{q_j}\}_{j = 1}^{J}$ of one training task $\task_i$ are divided into two sets, $\support_i = \{(q_{j}, l_{q_j})\}_{j = 1}^{J'}$ and $\query_i = \{(q_{j}, l_{q_j})\}_{j = J' + 1}^{J}$. $\support_i$ is called \emph{support set} and $\query_i$ is called \emph{query set}. The task-specific parameters $\theta_i$ is updated by the support set of $\task_i$ as Eq.~(\ref{eq:maml:inner}) in an inner loop, and the task-common parameters $\theta^*$ is updated by the query set over $\mathcal{D}$ in an outer loop as Eq.~(\ref{eq:maml:outer}), by gradient descent with learning rates $\alpha$ and $\beta$, respectively. %Fig.~\ref{fig:views:maml} delineates this two-level optimization framework.
%
\begin{align}
	\theta_i & \leftarrow \theta - \alpha \nabla_{\theta} \sum_{(q, l_q) \in \support_i}\loss(q; \theta) \label{eq:maml:inner}\\
	\theta^*  & \leftarrow \theta -\beta \nabla_{\theta} \sum_{\task_i \sim \mathcal{D}} \sum_{(q, l_q) \in \query_i}\loss(q; \theta_i)  \label{eq:maml:outer}
\end{align}
%
Although MAML is an effective and fairly general framework, it suffers
from a variety of problems, including training instability,
restrictive model generalization performance and extensive
computational overhead~\cite{DBLP:conf/iclr/AntoniouES19}.  To
alleviate the computational overhead, Reptile, is proposed as a
first-order meta-learning algorithm~\cite{reptile}.  Reptile directly
updates the task-common parameters $\theta^*$ by the first-order
gradients, bypassing the computation of the high-order
derivatives. First, the inner loop follows MAML to compute the
task-specific parameters $\theta_{i}$ for $\task_i$ as
Eq.~(\ref{eq:maml:inner}). Then, in the outer loop, the task-common
parameters $\theta^*$ are directly updated by the difference of
$\theta_{i}$ to current parameters $\theta$ as shown in
Eq.~(\ref{eq:reptile:outer}).
%
\begin{align}
\theta^*  & \leftarrow \theta + \beta \frac{1}{|\mathcal{D}|}\sum_{\task_i \sim \mathcal{D}}(\theta_i-\theta) \label{eq:reptile:outer}
\end{align}
Here, since evaluating the query set $\query_i$ of $\task_i$ is unnecessary,
%as shown in Eq.~(\ref{eq:maml:outer})
Reptile does not split $\query_i$ and $\support_i$ for updating $\theta_i$, but update $\theta_i$ by all the training data of $\task_i$ in the inner loop.

 
\comment{
\textcolor{blue}{
	\stitle{Reptile.} Reptile is a first-order gradient-based meta-learning algorithm. Like MAML, Reptile is optimized by two-level optimization algorithm. In inner loop, a batch of tasks $\mathcal{B}$ are randomly sampled from $\mathcal{D}$ and the task-specific parameters $\theta_i$ for one task $\task_i$ are optimized. While in outer loop, it get the average difference between initial parameter $\theta$ and updated parameter$\theta_i$ for each task $\task_i$ and then it performs stochastic gradient descent to update the task-common parameters $\theta^*$. The learned $\theta^*$ will be used as the initialization of model and updated by a few gradient steps to generalize a new task $\task^*$. To be specific, the task-specific parameters $\theta_i$ is updated by the task $\task_i$ as Eq.~(\ref{eq:reptile:inner}) and the task-common parameters $\theta^*$ is updated as Eq.~(\ref{eq:reptile:outer}).
\begin{align}
	\theta_i & \leftarrow \theta - \alpha \nabla_{\theta} \sum_{(q, l_q) \in \task_i}\loss(q; \theta) \label{eq:reptile:inner}\\
	\theta^*  & \leftarrow \theta +\epsilon \frac{1}{|\mathcal{B}|}\sum_{\task_i \sim \mathcal{B}}(\theta_i-\theta) \label{eq:reptile:outer}
\end{align}
The framework of reptile is similar to MAML, however, reptile is less complicated and more efficient due to its first-order gradient-based strategy.
}
}

\comment{
{\color{red}\stitle{Graph Prototypical Networks (\PN).} Prototypical Networks~\cite{prototypical} learn a metric space where classification problem can be solved by computing distances to prototype representations of each class. 
We propose Graph Prototypical Networks to apply GNN in Prototypical Networks and it can be used to solve community search problem.	
Since the community membership determination can be formulated as a binary classification task, the key of GPN is to compute the prototypes for different community membership.
%
To be specific, given a query node $q$, GNN generates $d$-dimensional representations for each node. The prototype is the mean vector of the embedded nodes belonging to its class, $c_k=\frac{1}{|S_k|}\sum_{(x_i,y_i) \in S_k }\text{GNN}(x_i)$, where $k=0$ means the nodes are not in the searched community, while $k=1$ is the opposite. 
The distance function $d: \mathbb{R}\times \mathbb{R} \rightarrow [0,\infty)$ measures the distance between representations of nodes and prototypes. GPN produces a distribution over community membership for a node based on a softmax over distances to the prototypes in the embedding space:
\begin{align}
\label{eq:gpn}
	p(y=k|x)=\frac{\text{exp}(-d(\text{GNN}(x),c_k))}{\sum_{k'}\text{exp}(-d(\text{GNN}(x),c_{k'}))}
\end{align}
The learning process is minimizing the negative log probability $J=-\text{log}(p(y=k|x))$ of the true class $k$ via SGD.
In training episodes, the same number of positive and negative samples with ground truth are used to compute prototype, while the remaining nodes with ground truth learn the parameter of GNN to minimize the negative log probability. 
In the test stage, the trained GNN generate representations for new encountered query node. A few instances with both positive and negative labels are needed to compute prototype. Prediction are made from the distance between prototypes and unknown nodes.
Fig.~\ref{fig:views:gpn} shows the framework of GPN.
}
}

\stitle{Graph Prototypical Network (GPN).} Prototypical
Network~\cite{prototypical} is an effective approach for few-shot
classification, which learns a metric space in which classification
is performed by computing distances to the centroid (prototype)
representation of each class. Different from general classification,
the prototype representation of CS should be query-specific. For a
query node $q$, two prototypes, $c_q^{+}$ and $c_q^{-}$, are computed
by the mean representations of the positive and negative samples in
the ground-truth $l_q$, respectively (Eq.~(\ref{eq:gpn:proto})).
Here, $h_{v}^{(K)}$ is the node representation of $v$ of the $K$-th
layer of GNN, generated by Eq.~(\ref{eq:gnn:fcom}). Then, the
likelihood that node $v$ is in the same community with $q$ is
predicted by its distances to the prototypes as
Eq.~(\ref{eq:gpn:likelihood}), given a distance function \distance.
%
\comment{
\begin{align}
c_q^{+} = \frac{1}{|l_q^{+}|}\sum_{v^{+} \in l_q^{+}} f_{\theta}(v^{+}, G, q),~c_q^{-} = \frac{1}{|l_q^{-}|}\sum_{v^{-} \in l_q^{-}} f_{\theta}(v^{-}, G, q)  \\
%\hat{y}(v^{\star}) = \frac{e^{(-\distance(f_{\theta}(v, G, q), c_q^{\star}))}}{ e^{(-\distance(f_{\theta}(v, G, q), c_q^{+}))} + e^{(-\distance(f_{\theta}(v, G, q), c_q^{-}))}}, {\star} \in \{ +, -\}   
\hat{y}(v) = \softmax \biggl( [-\distance(f_{\theta}(v, G, q), c_q^{+}) \| -\distance(f_{\theta}(v, G, q), c_q^{-})] \biggr)
\end {align}
}
%
\begin{align}
c_q^{+}  & = \frac{1}{|l_q^{+}|}\sum_{v^{+} \in l_q^{+}} h_{v^{+}}^{(K)},~c_q^{-} = \frac{1}{|l_q^{-}|}\sum_{v^{-} \in l_q^{-}} h_{v^{-}}^{(K)} \label{eq:gpn:proto} \\
%\hat{y}(v^{\star}) = \frac{e^{(-\distance(f_{\theta}(v, G, q), c_q^{\star}))}}{ e^{(-\distance(f_{\theta}(v, G, q), c_q^{+}))} + e^{(-\distance(f_{\theta}(v, G, q), c_q^{-}))}}, {\star} \in \{ +, -\}   
\hat{y}(v) & = \softmax \biggl( [-\distance(h_{v}^{(K)}, c_q^{+}) \| -\distance(h_{v}^{(K)}, c_q^{-}) ] \biggr) \label{eq:gpn:likelihood}
\end {align}
%
In the training stage, ground-truth sets $l_q^{+}$ and $l_q^{-}$ are
split into two sets, respectively. One is used to compute the prototypes
in Eq.~(\ref{eq:gpn:proto}) and the other is to compute the BCE loss
in Eq.~(\ref{eq:loss:bce}) for parameter update.  It is worth
noting that each query node must compute its own prototypes as it has
its own communities.  Therefore, GPN cannot support query node in
the test task without any ground-truth, where computing prototypes is
infeasible.
%Fig.~\ref{fig:views:gpn} shows the framework of GPN.


\section{CGNP for CS}
\label{sec:metric}

%\begin{figure*}[t]
%	\vspace{-0.3cm}
%    \centering
%	\includegraphics[ width=2\columnwidth]{fig/three.pdf}
%	\vspace{-0.2cm}
%	\caption{Illustrate three different ways to train model for meta.}
%	\label{indicate}
%	\vspace{-0.2cm}
%\end{figure*}



To overcome the disadvantages of the naive approaches, 
we devise a novel meta-learning framework for CS, named Conditional Graph Neural Process (CGNP), on the basis of Conditional Neural Process (CNP)~\cite{CNP}.
In this section, we first introduce CNP as a preliminary, then present the core idea of CGNP for CS as an overview of our framework.
%In this section, we present the core idea of CNP and CGNP for CS as an overview.
%we devise a novel meta-learning framework for CS, named Conditional Graph Neural Process (CGNP), in the family of Conditional Neural Process (CNP)~\cite{CNP}.
%Firstly, we briefly introduce CNP.
 %\comment{Compared with neural process, conditinal neural process (CNP) is a deterministic process. Given observed data $x_i$ with ground-truth $y_i$, CNP generates a deterministic variable $r_i$. For newly come data $x^*$, CNP can predict via $y^*=\rho_\theta(x^*,r_i)$. However, neural process (NP) learns to map from data $x_i$ to predictive stochastic processes. Specifically, neural process introduces a stochastic variable $z\sim q(z|x_i,y_i)$ and utilize variational inference to solve problems.} 

%\stitle{\shadd{Conditianl Neural Process (CNP).}} \shadd{We first briefly introduce CNP as preliminary.} 
CNP is a neural network approximation of stochastic process, e.g., Gaussian Process (GP). It directly models the predictive distribution conditioned on an arbitrary number of context observations by neural networks.
%, in contrast to GP that explicitly specifies the prior of the model  
%and infers the predictive distribution by Bayes rule and Bayesian model average.
Specifically, given observed data $X = \{x_i\}_{i = 1}^N$ with corresponding ground-truth $Y = \{ y_i\}_{i = 1}^N$, CNP models the predictive distribution of new data $x^*$ with the target $y^*$, $p(y^*| x^*, X, Y)$, by the neural network architecture in Eq.~(\ref{eq:cnp}).
\begin{align}
	\label{eq:cnp}
	p(y^*| x^*, X, Y) = \rho_\theta \biggl(x^*,  \bigoplus_{i = 1}^{N} \phi_\theta(x_i,y_i) \biggr) 
\end{align}
Here, $\phi_\theta: X \times Y \rightarrow \mathbb{R}^d$ and $\rho_\theta: X \times \mathbb{R}^d \rightarrow \mathbb{R}^e$ are neural networks. The big $\oplus$ is a commutative operation that takes elements in $\mathbb{R}^d$ and aggregates them into a single element of fixed length $\mathbb{R}^d$. 
$\phi_\theta$ is the encoder that transforms pairs of $(x_i, y_i)$ into $d$-dimensional hidden representations. 
The big $\oplus$ aggregates $N$ representations into a context representation in a permutation-invariant fashion which memorizes the whole dataset $X$ and $Y$. 
To deal with a query for new observation $x^*$,  a decoder $\rho_\theta$ takes the context and $x^*$ as inputs and makes a final prediction for $x^*$. 
%

Similar to stochastic process, CNP can be used to build meta models via learning the prior of data generation, where each data instance is a collection of $(x_i, y_i)$, i.e., a task. 
The difference lies in that stochastic process, e.g., GP, explicitly specifies the prior distribution, and optimizes the hyper-parameters of the prior by maximum likelihood. CNP instead explicitly parameterizes the predictive distribution as neural networks thereby learning the prior implicitly. 
%\shadd{CNP combines the benefits of deep neural network and Gaussian Process, which can exploit prior knowledge to infer a new function at test stage quickly. CNP can liberate the model from having to specify an analytic form for the prior knowledge and ultimately summarize the empirical data.}


%
\stitle{Conditional Graph Neural Process (CGNP).}
The CGNP model we propose is a graph specification of CNP for
query-dependent node classification. 
%\shadd{We design $\phi_{\theta}$, $\rho_{\theta}$ and $\bigoplus$ in \cref{eq:cnp} to enable CNP to be used in graph for CS tasks.} 
For a CS task $\task = (G, Q,
L)$, CGNP directly models the predictive probability $p(\hat{l_{q^*}}
| q^*, \task)$ for a new query node $q^* \in V(G) \setminus Q$, where
$\hat{l_{q^*}} = \{ \hat{l_{q^*}}(v) \}_{v \in V(G)} \in \{0, 1\}^{n}$
is the binary target prediction for all the nodes in $G$.  
We instantiate the encoder $\phi_{\theta}$ that encodes each query node $q$ with its ground $l_q$ in the task $\task$,
the commutative operation that generates the context representation of $\task$, and the encoder $\rho_{\theta}$ that predicts $p(\hat{l_{q^*}}| q^*, \task)$ as Eq.~(\ref{eq:cnp:kernel1}).
CGNP inherits the interpretation of CNP~\cite{CNP} that using neural networks to mimic an \emph{implicit kernel function}, $\Kernel(\cdot, \cdot)$, which evaluating the  similarity between an observed query node $q$ and the target query node $q^*$.
The predictive probability is the summation of the observed ground-truth $l_q$, weighted by the similarities of query nodes as Eq.~(\ref{eq:cnp:kernel2}).
%CGNP preserves the property of CNP for meta-learning, which learns a kernel
%function, $\Kernel(\cdot, \cdot)$ for input pairs as what GP
%does~\cite{CNP}.  In this kernel-based perspective, CGNP can be
%regarded as reinterpreting the predictive distribution as
%Eq.~(\ref{eq:cnp:kernel1})-(\ref{eq:cnp:kernel2}), which is a sum of
%the observed ground-truth $l$, weighted by the similarity between an
%observed query node $q$ and the target query node $q^*$.  The
%similarity is specified by a kernel function $\Kernel(\cdot,\cdot)$.
%CNP learns a common kernel function $\Kernel(\cdot,\cdot)$ between $q$ and $q^*$, shared by all the tasks.  This implicit kernel learning prompts CNP and CGNP to be metric-based meta-learning. 

\begin{figure*}[t] 
	\centering 
	\includegraphics[width=0.85\textwidth]{fig/cgnp.pdf} 
	\vspace{-0.3cm}
	\caption{The Architecture of CGNP} 
	\vspace{-0.5cm}
	\label{fig:cgnp} 
\end{figure*}

%
\begin{align}
\label{eq:cnp:kernel1}
%p(y^* |x^*, X, Y) \approx \sum_{i=1}^{N} \Kernel(x^*, x_i) y_i,
p(\hat{l_{q^*}} |q^*, \task) &= \rho_\theta \biggl(q^*, \bigoplus_{(q, l_q) \in (Q, L)}  \phi_\theta(q, l_q) \biggr) \\
\label{eq:cnp:kernel2}
&\approx \sum_{(q, l_q) \in (Q, L)} \Kernel(q^*, q) \odot l_q 
\end{align}
Like k-nearest neighbor (KNN) algorithm, the non-parametric metric learning intuition makes CGNP promising for small samples and classification tasks as CS.
Unlike KNN, for CGNP, the kernel function $\Kernel(\cdot,\cdot)$, as well as the multiplication operation $\odot$ is implicitly learned from the data by our instantiated $\rho_\theta$, $\phi_\theta$ and big $\oplus$. 
In other words, KNN and CGNP memorize the input data in different ways. KNN persists the input data by simple concatenation whereas CGNP persists it by learning a hidden context representation.
%Notice that metric-based meta-learning framework, GPN~\cite{prototypical}, whose core idea is from KNN, a distance kernel is explicitly defined to derive the predictive distribution as Eq.~(\ref{eq:cnp:kernel2}). 
%Like KNN, the metric learning intuition of CNP makes it promising for small samples and classification tasks as CS.
%Unlike KNN, for CNP and CGNP, the kernel function $\Kernel(\cdot,\cdot)$, as well as the multiplication operation $\odot$ is implicitly learned from the data by the defined $\rho_\theta$, $\phi_\theta$ and big $\oplus$. 
%In addition, KNN and CNP memorize the input data in different ways. KNN persists the input data by simple concatenation whereas CNP persists it by a more abstract operation, i.e., big $\oplus$. 



%We also impose an explicit metric objective on the learning of CGNP. 
Apart from the implicit kernel $\Kernel(\cdot, \cdot)$ derived from CNP, in particular, we also impose an explicit metric objective on the learning of CGNP. 
For CS task, since we only need a binary prediction to indicate whether a node $v$ is a community member of the query node $q^*$, we let the predictive probability of the membership be determined by the distance of $v$ and $q^*$ in a hidden space $H$ as Eq.~(\ref{eq:cnp:distance}). 
The mapping function from the initial node features to that hidden space is specified by the neural network encoder $\phi_\theta$, decoder $\rho_\theta$ and the commutative operation big $\oplus$ of CNP.
%
%. 
\begin{align}
\label{eq:cnp:distance}
p(\hat{l_{q^*}}(v) | q^*, \task) &\models \distance( H(q^*), H(v)) 
%	&= \distance(\bigoplus_{q \in Q} H_q(q^*), \bigoplus_{q \in Q} H_q(v))
\end{align}
In this explicit metric-based modeling perspective, we use inner product similarity to distinguish between membership and nonmembership in the hidden space $H$ that is learned in the training process.
%As shown in Fig.~\ref{fig:views:distance}, 
The meta CGNP model is also a common neural network mapping, shared by multiple CS tasks, that maps nodes for partitioning in a task-specific hidden space $H$.
Note the kernel $\Kernel(\cdot,\cdot)$ in Eq.~(\ref{eq:cnp:kernel2}) and the distance $\distance(\cdot, \cdot)$ in Eq.~(\ref{eq:cnp:distance}) are two different concepts. 
The kernel measures the similarity between two input query nodes $q$ and $q^*$ regarding their community-member relationship with all the remaining nodes in $G$, whereas the distance measures the closeness of a query node $q$ and one remaining node $v$ in $G$ regarding their community membership.  
%Therefore, a meta CGNP model corresponds to a common implicit kernel function for KNN evaluation, or a common neural network mapping for node partitioning in the hidden space $H$, across multiple community search tasks. 
%Fig.~\ref{fig:views:kernel} and Fig.~\ref{fig:views:distance} sketch the intuitions of CNP and CGNP in the views of kernel learning and metric (distance) learning, respectively.
%In the following, first, we introduce the neural network design of CGNP, followed by the meta training procedure in \cref{sec:meta}.
To learn a task-common kernel and distance mapping, CGNP iterates on the training task set to optimize the neural network parameters $\theta$, where data in one task is processed as a batch.
Compared with the two-level optimization-based algorithm MAML, %in Fig~\ref{fig:views:maml},
CGNP learns the prior knowledge of CS by metric learning for node clustering/partitioning, which better exploits small data for classification and avoids unstable and inefficient parameter adaptation in the test stage.
%
The metric learning principle of CGNP is also different from that of GPN. %in Fig.~\ref{fig:views:gpn}. 
GPN computes positive and negative prototypes, $c_q^{+}$ and $c_q^{-}$, for each query node $q$ by its ground-truth. Inference on other nodes is based on their distances to the prototypes. 
In contrast, CGNP directly models and evaluates the distances between the query nodes and the remaining nodes, thereby supporting queries without any ground-truth in test tasks.

\comment{
\textcolor{blue}{
CGNP is a metric-based learning approach that mimics a non-parametric model, Gaussian Process. Predictions are made by evaluating the distances between the embedding of the query nodes and other nodes. This metric-based learning strategy is more robust to the problem of imbalanced labels, achieving a higher recall than direct binary classification. That's the main reason that CGNP can outperform other naive approaches for CS.
}
}

%\subsection{Model Design of CGNP}
\section{CGNP Model Design}
\label{sec:CGNP}



\comment{
A meta CGNP model $\mathcal{M}$ over multiple tasks should achieves the minimize conditional log probability over the probability of tasks $\mathcal{D}$. 
\begin{align}
\mathcal{M} &= \arg \min_{\theta} -\mathbb{E}_{\task \sim \mathcal{D}} [ \mathbb{E}_{q^*} [\log p(\hat{y}| q^*, \task)] ] 
 %  &=\arg \min_{\theta} -\mathbb{E}_{\task \sim \mathcal{D}} [ \mathbb{E}_{q^*} [\log \Pi_{v \in V(G)} p(\hat{y}(v)| q^*, \task)] ]
\end{align}
}
%
We elaborate on how to design a CGNP model for the query-dependent node classification over graphs.
CGNP adopts an encoder-decoder based architecture and operates on task-level. Fig.~\ref{fig:cgnp} delineates the architecture of CGNP, which is composed of a GNN based encoder operating on query-level representation, a commutative operation, big $\oplus$, combining query-level representation to task-level context, and a decoder to perform final predictions.

\stitle{GNN Encoder ($\phi_{\theta}(q, l_q, G)$).} For each query node $q \in Q$ and its corresponding ground-truth $l_q \in L$, the encoder $\phi_{\theta}(q, l_q, G)$ is a $K$-layer GNN that maps the pair $(q, l_q)$ together with the graph $G$ to a node embedding matrix $H_q = \{ h_{v}^{(K)}\}_{v \in V(G)} \in \mathbb{R}^{n \times d^K}$. 
Here, $h_{v}^{(K)}$ is a $d^K$-dimensional output of the $K$-th layer of GNN for node $v$. 
The subscript $q$ of $H_q$ indicates the node embedding $H_q$ is generated particularly for query node $q$, as all the query nodes in $Q$ share the same GNN encoder.
Specifically, as the inputs of GNN, the adjacency matrix of graph $G$ is used for message passing of GNN, and $(q, l)$ determines the initial node $h_v^{(0)}$ as Eq.~(\ref{eq:cnp:encoder:feats}), where $\|$ is the vector/bit concatenation operation, $\mathcal{A}(v)$ is the attribute features of node $v$. In Eq.~(\ref{eq:cnp:encoder:feats}), $I_l(v) \in \{0, 1\}$ is a binary ground-truth identifier which distinguishes nodes within and without a same community, under the close world assumption. 
\begin{align}
	\label{eq:cnp:encoder:feats}
	h_v^{(0)} &= [ I_l(v) \| \mathcal{A}(v) ],
	I_l(v) =
	\begin{cases}
		1 & {v \in l_q^{+} \cup \{q\}  }  \\
		0 & \text{otherwise}
	\end{cases}
\end{align}
%
We can concatenate auxiliary features, e.g., the core number and local clustering coefficient of node $v$ on $h_v^{(0)}$ to exploit additional structural information.
The intuition of the GNN encoder is to generate a view, $H_q$, for the whole graph given an observation $(q, l_q)$ by message passing. 
A collection of views will be aggregated by the commutative operation big $\oplus$. This idea is enlightened by a CNP specialization for 3D scene understanding and rendering, Generative Query Network (GQN)~\cite{GQN}, where few-shot observed 3D views are summed up for predicting the view of a new query perspective. It is worth mentioning that, to the best of our knowledge, we are the first to introduce the insight of GQN to graph domain. 

\stitle{Commutative Operation ($\oplus$).} To combine the views $H_q$ for all query nodes in $ Q$ into one context representation, CGNP is equipped with three choices of commutative operations, sum, average and self-attention. All of the three operations are permutation-invariant. 

\etitle{Sum \& Average} are simple yet widely used pooling operations in many CNP instances~\cite{GQN, CNP}. The sum operation conducts element-wise sum up as Eq.~(\ref{eq:cnp:pool:sum}) and average further imposes a denominator of $|Q|$.
%
% \begin{align}
\begin{equation}
	\label{eq:cnp:pool:sum}
	H = \sum_{q \in Q} H_q
\end{equation}
% \end{align}

\etitle{Self-Attention} is inspired by Attentive Neural Process (ANP)~\cite{DBLP:conf/iclr/KimMSGERVT19} and GP. 
Instead of giving the same weight to aggregate multiple data points, ANP and GP aggregate observed data by self-adaptive weights by self-attention~\cite{attention} and GP's kernel function, respectively.  
Thereby, CGNP leverages the self-attention to combine the node representations derived from all the query nodes, weighted by a set of learnable weights $\{w_q \}_{q \in Q} \in \mathbb{R}^{|Q|}$ as $H = \sum_{q \in Q} w_q H_q$. The weights $\{w_q \}_{q \in Q}$ are shared by all the nodes in $G$. 
%
\comment{
\begin{align}
	\label{eq:cnp:pool:attention}
	
\end{align}
}
%
Specifically, to compute the attention weight $\{w_q \}_{q \in Q}$ by the multiple views $\{ H_q\}_{q \in Q}$, let $\mathcal{H} = \{H_q[v]\}_{q \in Q} \in \mathbb{R}^{|Q| \times d^K}$ be the matrix stacked by the $|Q|$ node embeddings in $\{ H_q\}_{q \in Q}$ for an arbitrary node $v$. 
In Eq.~(\ref{eq:cnp:pool:att:trans}), 
$\mathcal{H}_{1} , \mathcal{H}_{2} \in \mathbb{R}^{|Q| \times d'}$ are transformed by linear weight matrices $W_{1} , W_{2} \in \mathbb{R}^{d^{K} \times d'}$, respectively. 
%
$\{w_q \}_{q \in Q}$ is computed by the inner product of $\mathcal{H}_{1}$ and the transpose of $\mathcal{H}_{2}$ followed by a $\softmax$ function that normalizes the weights to a probability, as Eq.~(\ref{eq:cnp:pool:att:weight}) shows.
\begin{align}
	\label{eq:cnp:pool:att:trans}
	\mathcal{H}_{1} &= \mathcal{H} W_{1},~ \mathcal{H}_{2} = \mathcal{H} W_{2},~\\
	\label{eq:cnp:pool:att:weight}
	\{w_q \}_{q \in Q} &= \softmax \biggl(\frac{ \langle\mathcal{H}_{1},  \mathcal{H}_{2}^T \rangle}{\sqrt{d'}} \biggr) 
\end{align}

\stitle{Decoder ($\rho_{\theta}(q^*, H)$).} Given the combined context $H$, a decoder $\rho_{\theta}(q^*, H)$ estimates the membership  for a new query node $q^*$, $p(l^* | q^*, H) \in \mathbb{R}^{n}$, conditioned on the memorized context $H$. 
We design three decoders with different complexities, a simple inner product decoder, multi-layer perception (MLP) decoder and GNN decoder. The latter two decoders MLP and GNN are also based on inner product. 

\etitle{Inner Product Decoder} is free of parameters and only operates on the context $H$. Since $H$ is a node embedding combined by multiple views, we can directly compute the node similarities between the embedding of a query node $q$ and all the other nodes. We use the inner product operation, $\langle \cdot, \cdot \rangle$, to compute the similarity score as Eq.~(\ref{eq:cnp:decoder:product}), followed by a $\sigmoid$ function to predict the probability that one node is in the same community with query node $q^*$.
The inner product operation indicates that the smaller the angle of two node embeddings in the vector space, the more likely the two nodes are from the same community.  
\begin{align}
	\label{eq:cnp:decoder:product}
	p(\hat{l_{q^*}} | q^*, \task) = \sigmoid(\langle H[q^*], H \rangle) 
\end{align}

\comment{
\etitle{MLP Decoder} firstly transforms the context matrix $H$ by a two-layer MLP as  Eq.~(\ref{eq:cnp:decoder:mlp}), then feeds the transformed $H$ to an inner product decoder of Eq.~(\ref{eq:cnp:decoder:product}). 

\begin{align}
	\label{eq:cnp:decoder:mlp}
	H \leftarrow \relu(H W_1) W_2
\end{align}

\etitle{GNN Decoder} firstly transforms the context matrix $H$ by a $K$-layer GNN as Eq.~(\ref{eq:cnp:decoder:gnn}), then feeds the transformed $H$ to an inner product decoder of Eq.~(\ref{eq:cnp:decoder:product}). In Eq.~(\ref{eq:cnp:decoder:gnn}), we use $W = \{ \Fagg^{(0)}, \Fcom^{(0)}, \cdots, \Fagg^{(K)}, \Fcom^{(K)} \}$ to denote the weights in the $K$-layer GNN. Note the GNN here is independent to the GNN in the encoder. 
\begin{align}
	\label{eq:cnp:decoder:gnn}
	H \leftarrow \kw{GNN}(H, G, W)
\end{align}
}

\etitle{MLP \& GNN Decoder.} MLP decoder firstly transforms the context matrix $H$ by an MLP, then feeds the transformed $H$ to an inner product operation of Eq.~(\ref{eq:cnp:decoder:product}). Similarly, 
firstly transforms the context matrix $H$ by a $K$-layer GNN, followed by the inner product. Note the GNN here is independent to the GNN in the encoder.
In contrast to the inner product decoder, the MLP and GNN encoder impose additional parametric transformations on the combined context embedding $H$ to improve the modeling capability of the decoder. The difference between MLP and GNN lies in that GNN further allows message passing among the nodes whereas the MLP transforms each node independently. 

\comment{
\textcolor{blue}{
	\begin{example}
		Take Single Graph with Shared Communities (SGSC) for example, given the Test Task \{12-Deepayan, 16-Julian, 32-Jaewon, 92-PaeaLe, 100-Jeff\} with query node $16-Julian$, the GNN Encoder maps the pair $(q, l_q)$ to the node embedding $H_q \in \mathbb{R}^{n \times d^K}$, where $q=16$ and $n=5$. Then combine the views of several different query nodes $H_q$ and get combined context $H$. Then It will transform by different decoder type. A new query node $(q, l_q)$ where $q=32$ is given, use inner product to measure the similarity score, that is $\langle H[q], H\rangle$. Followed by a sigmoid function, we predict the probability of node $\{12, 16, 92, 100\}$ is in the same community with query node $q=32$.
		%Take Single Graph with Shared Communities (SGSC) for example, to learn the model, we have to train it on training tasks. For training task $\task_1=\{1, 10, 69, 81, 90\}$ with query node $1$, the GNN Encoder maps the pair $(1, l_1)$ to the node embedding $H_1 \in \mathbb{R}^{5 \times d^K}$. Then combine the views of several different query nodes $H_q$ and get combined context $H$. It may transform by different decoder type. Given a new query node $q^*=10$, use inner product operation followed by to measure the similarity score, that is $<H[10], H>$. Followed by a sigmoid function, we predict the probability of node $\{1,69,81,80\}$ is in the same community with query node $10$.
	\end{example}
 }
 }
 
%\vspace{0.2cm}
%\section{Meta-learning by CGNP}
%\label{sec:meta}
%In this section, 
In the following, we present the learning algorithms to train a meta CGNP model $\model$ and adapt the model to new tasks.
Recall that CGNP is to model a generative process of tasks $f \sim \mathcal{D}$, where $\mathcal{D}$ is the set of training tasks $\{ \task_i \}_{i = 1}^{N}$. Suppose the tasks are independent and the query nodes are independent in each task. The marginal likelihood of CGNP over $\mathcal{D}$ is 
\begin{align}
	p(\{L_1, \cdots, L_N\} | \{Q_1, \cdots, Q_N\}, \theta) = \prod_{\task_i \in \mathcal{D}} p(L_i | Q_i) 
\end{align}
Similar to MAML, for one training task $\task_i$, we split the training data $Q_i = \{ q_{j}\}_{j = 1}^{J}$ and $L_i = \{ l_{q_j} \}_{j = 1}^{J}$ into the support set $\support_i = \{ (q_{j}, l_{q_j})\}_{j = 1}^{J'}$ and query set $\query_i = \{ (q_{j}, l_{q_j})\}_{j = J' + 1}^{J}$.
The learning objective is to minimize the negative log-likelihood of the query set $\query_i$ conditioned on the support set $\support_i$ across all the tasks in $\mathcal{D}$ as Eq.~(\ref{eq:loss:nll}). 
The negative  log-likelihood loss in Eq.~(\ref{eq:loss:nll}) is in accordance with the BCE loss (Eq.~(\ref{eq:loss:bce})) of the query nodes in the query set $\query_i$. 
\begin{align}
	\label{eq:loss:nll}
	\loss &= -\sum_{\task_i \in \mathcal{D}} \sum _{(q, l_q) \in \query_i} \log p(l_q | q, \support_i) \\
	\nonumber
	&= -\sum_{\task_i \in \mathcal{D}} \!\sum _{(q, l_q) \in \query_i} \biggl (\sum_{v^{+} \in l_q^+} \log\hat{y}(v^+) +  \sum_{v^{-} \in l_q^-} \log (1-\hat{y}(v^-)) \biggr ) 
\end{align}



\begin{algorithm}[t]
	\footnotesize
	\caption{CGNP Meta Train}
	\label{alg:train}
	\DontPrintSemicolon
	\SetKwData{Up}{up}  \SetKwInOut{Input}{Input} \SetKwInOut{Output}{Output}
	\Input{training task set $\mathcal{D} =\{\task_i\}_{i = 1}^{N}$, learning rate $\alpha$, number of epochs $T$ }
	\Output{parameters $\theta$ of meta model $\mathcal{M}$}
	\SetKwFunction{Emit}{Emit}
	\SetKwFunction{Check}{Check}
	
	\For{$epoch \leftarrow 1$ to $T$}{ \label{line:epoch:start}
		Shuffle the task set $\mathcal{D} =\{\task_i\}_{i = 1}^{N}$; \label{line:shuffle} \; 	
		\For { $\task_i=(G_i, Q_i, L_i) \in \mathcal{D}$ } 
		{ 
			$\support_i, \query_i \sim (Q_i, L_i)$;  \label{line:support-query:split}   {\shadd{\tiny $\rhd$ allocate support and query sets} }\;
			\For {$(q, l_q) \in \support_i$}
			{ 
				\label{line:train:encoder:start}
				$H_q\leftarrow \phi_\theta(q, l_q, G_i)$; \label{line:train:encoder:end}  {\shadd{\tiny $\rhd$  compute query-specific view}} \;
			}
			$H \leftarrow \bigoplus_{(q, l_q) \in \support_i} H_q$; \label{line:train:agg} {\shadd{\tiny $\rhd$ compute context embedding (Eq.~(\ref{eq:cnp:pool:sum}))}}  \;
			\For {\ $(q, l_q) \in \query_i$}
			{
				$p(\hat{l_q}|q, \support_i) \leftarrow \rho_{\theta}(q, H)$; \label{line:train:decoder} {\shadd{\tiny $\rhd$ compute pred. prob. (Eq.~(\ref{eq:cnp:decoder:product}))}} \;
				Compute the Loss $\mathcal{L}(q)$ by $p(\hat{l_q}|q, \support_i)$ and $l_q$; \label{line:train:loss} \;
			}
			$\mathcal{L} \leftarrow \sum_{(q, l_q) \in \query_i}\mathcal{L}(q)$; \label{line:train:taskloss} \;
			
			$\theta \leftarrow \theta-\alpha \nabla_{\theta} \mathcal{L}$; \label{line:epoch:end}  {\shadd{\tiny$\rhd$  update model parameters}}\; 
	}}
	\Return{$\theta$};\
\end{algorithm}


\begin{algorithm}[!t]
	\footnotesize
	\caption{CGNP Meta Test}
	\label{alg:test}
	\DontPrintSemicolon
	\SetKwData{Up}{up}  \SetKwInOut{Input}{Input} \SetKwInOut{Output}{Output}
	\Input{test task $\mathcal{T^*}=(G^*, Q^*, L^*)$, parameter $\theta$ of meta model $\mathcal{M}$, a query node $q^* \in V(G^*) \setminus Q^*$}
	\Output{predictive probability of $q^*$}
	\SetKwFunction{Emit}{Emit}
	\SetKwFunction{Check}{Check}
	$\support^* \leftarrow (Q^*, L^*)$; \label{line:test:support-query:split} 
	
	\For { $(q, l_q) \in \support^*$}
	{ \label{line:test:encoder:start}
		$H_q\leftarrow \phi_\theta(q,l_q, G^*)$; \label{line:test:encoder:end}  {\shadd{\tiny $\rhd$  compute query-specific view}} \; 
	}
	$H \leftarrow \bigoplus_{q \in \support^*} H_q$;\label{line:test:agg}{\shadd {\tiny $\rhd$ compute context embedding (Eq.~(\ref{eq:cnp:pool:sum}))}} \;
	$p(\hat{l_{q^*}} | q^*, \support^*) \leftarrow \rho_\theta(q^*, H)$; \label{line:test:decoder}  {\shadd{\tiny $\rhd$ compute pred. prob. (Eq.~(\ref{eq:cnp:decoder:product}))} }\; 
	\Return{$p(\hat{l_{q^*}} | q^*, \support^*)$}; \;
\end{algorithm}

\stitle{Meta Training.} 
In the training stage, given the training task set $\mathcal{D}$, learning rate $\alpha$, and the number of epochs $T$, a meta CGNP model is trained by optimizing the negative log-likelihood of Eq.~(\ref{eq:loss:nll}) by stochastic gradient descent. 
Algorithm~\ref{alg:train} presents the training process. 
In each epoch (line~\ref{line:epoch:start}-\ref{line:epoch:end}), all the training tasks are randomly shuffled in line~\ref{line:shuffle}.
For each task $\task_i$, we get the allocated support set $\support_i$ and query set $\query_i$ from the given query node and ground-truth (line~\ref{line:support-query:split}).  
First, each query node $q$ associated with the ground-truth $l$ in the support set $\support_i$, together with the graph structure $G_i$ is fed into the GNN encoder, $\phi_\theta$ , to generate a query-specific view $H_q$ (line~\ref{line:train:encoder:start}-\ref{line:train:encoder:end}).
Second, in line~\ref{line:train:agg}, all the views are aggregated into the context matrix $H$ by the permutation-invariant operation big $\oplus$, e.g., by the summation aggregation of Eq.~(\ref{eq:cnp:pool:sum}). 
Third, for each query node in the query set $\query_i$, 
we compute its predictive probability and loss in line~\ref{line:train:decoder}-\ref{line:train:loss}, via evaluating the inner product similarities between node presentations and the query representation in $H$ as Eq.~(\ref{eq:cnp:decoder:product}).
Fourth, the model is updated by one gradient step of the aggregated task-specific loss (line~\ref{line:train:taskloss}-\ref{line:epoch:end}).
% meta train

	
%\vspace{-0.2cm}
\stitle{Meta Testing.} For a test task $\task^*$ with graph $G^*$, few-shot query nodes $Q^*$ and the associated ground-truth $L^*$, Algorithm~\ref{alg:test} presents the steps to predict the community members for a query node $q^*$. The whole $Q^*$ and $L^*$ serve as the support set $\support^*$ (line~\ref{line:test:support-query:split}), followed by computing the context representation $H$ (line~\ref{line:test:encoder:start}-\ref{line:test:agg}). 
Finally, the query node $q^*$ and context $H$ are fed into the decoder network $\rho_\theta$ to obtain the prediction.


\begin{example}
We use a real example to illustrate how CGNP works in
Algorithm~\ref{alg:test} on a test task $\task^*= (G^*, Q^*, L^*)$ of
a DBLP subgraph, $G^*$, in Fig.~\ref{fig:case}. Suppose the task
possesses query nodes $Q^* =\{q_1, q_2, q_3\}$ correspond to 3 users
\{Julian, Jaewon, Deepayan\}, respectively, and the corresponding
ground-truth $L^* =\{ l_1, l_2, l_3\}$.  Each $l_i$ is composed a
positive node set $l_i^+$, and a negative node set $l_i^-$.  First,
for the 3 pairs $(q_1, l_1), (q_2, l_2), (q_3, l_3)$, by
line~\ref{line:test:encoder:start}-\ref{line:test:encoder:end}, the
GNN encoder $\phi_{\theta}$ generates 3 node embedding matrices $H_1,
H_2, H_3 \in \mathbb{R}^{n \times d^K}$ as the query-specific views,
respectively, where $n = |V(G)|$.  Second, by
line~\ref{line:test:agg}, the combine operator big $\oplus$ aggregates
the three matrices $H_1, H_2, H_3$ to one context embedding $H$.
Given a query node $q^*$ in the subgraph $G$, e.g, Jure, by
line~\ref{line:test:decoder} the inner product decoder $\rho_{\theta}$
predicts the probability of community membership of Jure for all the
nodes, by computing the inner product similarity of vector $H[q^*]$
and $H$ followed by a \kw{sigmoid} function as
Eq.~(\ref{eq:cnp:decoder:product}).
\end{example}


\stitle{Computation Complexity.}
 We analyze the time complexity of CGNP in brief. To be concise, we assume fixed dimension vector add, multiplication, and inner product take constant time when the dimension is far smaller than the graph node number $n$. 
For the GNN encoder of CGNP, the time complexity is $\mathcal{O}(K m |\support|)$ for a single task, where $K$ is the number of GNN layers, $m$ is the number of edges and $|\support|$ denotes the number of shots.   
The complexity of the big $\oplus$ operation is $\mathcal{O}(n |\support|)$ for the sum and average pooling and $\mathcal{O}(n |\support|^2)$ for the self-attention, respectively.  
For the decoders, the inner product operation takes $\mathcal{O}(n |\query|)$ time, and an MLP decoder and $K'$ layer GNN decoder takes extra $\mathcal{O}(n |\query|)$ and $\mathcal{O}(K' m |\query|)$ cost, respectively.
In total, the complexity of the meta test algorithm, Algorithm~\ref{alg:test},  is $\mathcal{O}(c (n + m))$, where $c$ is a constant determined by $K, K', |\support|, |\query|$. And the training complexity of Algorithm~\ref{alg:train} is $\mathcal{O}(TNc(n + m))$, where $T$ and $N$ are the numbers of iterations and training tasks. 
%We first present the complexity of GNN Encoder. It aggregates neighbor's features for every vertices in one layer with the cost of $\sum_{i=u}^{n}D_u$, where $D_u$ is the degree of vertex $u$. Thus the complexity of encoder GNN is $O(l|E|\cdot |S|)$, where $l$ denotes the number of layers. Then the Commutative Operation, sum and average aggregation costs $(O(|V|\cdot |S|))$, while attention operation costs $(O(dl|V|^2 \cdot|S|))$, where $d$ denotes the output dimension. Three types of Decoder have different time complexity. Inner product Decoder takes $O(|V|^2\cdot |Q|)$, MLP Decoder costs $(d^l|V| \cdot|Q|+|V|^2\cdot |Q|)$, while GNN Decoder costs $O(|E|\cdot |Q|+|V|^2\cdot |Q|)$. Since the size of support set $S$ and query set $Q$ is small, $|S|$ and $|Q|$ can be regarded as constants. Sum the above steps all and multiple the iteration (number of tasks $T$), we can get the time complexity of CGNP Meta Train. In the similar way, we can also get the time consuming for CGNP Meta Test is the sum of three components of CGNP.






\subsection{Numerical Scheme}
\label{sec:numerical_scheme}

In this section we introduce a splitting scheme for simulating
the perturbed underdamped Langevin dynamics given by equation (\ref{eq:perturbed_underdamped}).
In the unpertubed case, i.e. when $J_{1}=J_{2}=0$, the right-hand side
can be decomposed into parts $A$, $B$ and $C$ according to 

\[
\mathrm{d}\left(\begin{array}{c}
q_{t}\\
p_{t}
\end{array}\right)=\underbrace{\left(\begin{array}{c}
	M^{-1}p_{t}\\
	\boldsymbol{0}
	\end{array}\right)\mathrm{d}t}_{A}+\underbrace{\left(\begin{array}{c}
	\boldsymbol{0}\\
	-\nabla V(q_{t})
	\end{array}\right)\mathrm{d}t}_{B}+\underbrace{\left(\begin{array}{c}
	\boldsymbol{0}\\
	-\Gamma M^{-1}+\sqrt{2\Gamma}\mathrm{d}W_{t}
	\end{array}\right),}_{O}
\]
i.e. $O$ refers to the Ornstein-Uhlenbeck part of the dynamics, whereas $A$ and $B$ stand for the momentum and position updates, respectively.
\\\\
One particular splitting scheme which has proven to be efficient is the  $BAOAB$ scheme, (see \cite{LeimkuhlerMatthews2015} and references therein).  The string
of letters refers to the order in which the different parts are integrated, namely
\begin{subequations}
\begin{eqnarray}
p_{n+1/2} & = & p_{n}-\frac{1}{2}\Delta t\nabla V(q_{n}),\\
q_{n+1/2} & = & q_{n}+\frac{1}{2}\Delta t\cdot M^{-1}p_{n+1/2},\\
\hat{p}   & = & \exp(-\Delta t\Gamma M^{-1})p_{n+1/2}+\sqrt{I-e^{-2\Gamma\Delta t}}\mathcal{N}(0,I),\label{eq:OU-step-1}\\
q_{n+1}   & = & q{}_{n+1/2}+\frac{1}{2}\Delta t\cdot M^{-1}\hat{p},\\
p_{n+1}   & = & \hat{p}-\frac{1}{2}\Delta t\cdot\nabla V(q_{n+1}).
\end{eqnarray}
\end{subequations}
We note that many different discretisation schemes such as $ABOBA$,
$OABAO$, etc. are viable, but that analytical and numerical evidence
has shown that the $BAOAB$-ordering has particularly good properties
to compute long-time ergodic averages with respect to $q$-dependent observables.
Motivated by this, we introduce the following perturbed scheme,
introducing additional Runge-Kutta integration steps between the $A$, $B$ and
$O$ parts:

\begin{subequations}
\begin{eqnarray}
p_{n+1/2} 	& = & p_{n}-\frac{1}{2}\Delta t\nabla V(q_{n}),\\
q_{n+1/2}	& = & q_{n}+\frac{1}{2}\Delta t\cdot M^{-1}p_{n+1/2},\\
q'_{n+1/2}	& = & RK_{4}(\frac{1}{2}\Delta t,q_{n+1/2})\label{eq:q'},\\
\hat{p}		& = & \exp(-\Delta t(\Gamma M^{-1}+\nu J_{2}M^{-1}))p_{n+1/2}+\sqrt{I-e^{-2\Gamma\Delta t}}\mathcal{N}(0,1)\label{OU},\\
q''_{n+1/2}	& = & RK_{4}(\frac{1}{2}\Delta t,q'_{n+1/2})\label{eq:q''},\\
q_{n+1}		& = & q''_{n+1/2}+\frac{1}{2}\Delta t\cdot M^{-1}\hat{p},\\
p_{n+1}		& = & \hat{p}-\frac{1}{2}\Delta t\cdot\nabla V(q_{n+1}),
\end{eqnarray}
\end{subequations}
where $RK_{4}(\Delta t,q_{0})$
refers to fourth order Runge-Kutta integration of the ODE 
\begin{equation}
\dot{q}=-J_{1}\nabla V(q), \quad q(0)=q_0\label{eq:J1 ODE}
\end{equation}
up until time $\Delta t$.
We remark that the $J_{2}$-perturbation is linear and can therefore be
included in the $O$-part without much computational overhead. Clearly,
other discretisation schemes are possible as well, for instance one could use a symplectic integrator for the ODE \eqref{eq:J1 ODE}, noting that it is of Hamiltonian type. However, since $V$ as the Hamiltonian for \eqref{eq:J1 ODE} is not separable in general, such a symplectic integrator would have to be implcit. Moreover, (\ref{eq:q'}) and (\ref{eq:q''})
could be merged since (\ref{eq:q''}) commutes with (\ref{OU}). In
this paper, we content ourselves with the above scheme for our numerical
experiments.
\begin{remark}
	The aformentioned schemes lead to an error in the approximation
	for $\pi(f)$, since the invariant measure $\pi$ is not preserved
	exactly by the numerical scheme. In practice, the $BAOAB$-scheme
	can therefore be accompanied by an accept-reject Metropolis step as in \cite{BAOABMetropolis},
	leading to an unbiased estimate of $\pi(f)$, albeit with an inflated
	variance. In this case, after every rejection the momentum variable
	has to be flipped ($p\mapsto-p$) in order to keep the correct invariant
	measure. We note here that our perturbed scheme can be 'Metropolized'
	in a similar way by 'flipping the matrices $J_{1}$ and $J_{2}$ after
	every rejection ($J_{1}\mapsto-J_{1}$ and $J_{2}\mapsto-J_{2})$
	and using an appropriate (volume-preserving and time-reversible) integrator for the
	dynamics given by (\ref{eq:J1 ODE}). Implementations of this idea are the subject of ongoing work.
\end{remark}


\subsection{Diffusion Bridge Sampling}


To numerically test our analytical results, we will apply the dynamics
(\ref{eq:perturbed_underdamped}) to sample a measure on
path space associated to a diffusion bridge. Specifically, consider
the SDE 

\[
\mathrm{d}X_{s}=-\nabla U(X_{s})\mathrm{d}s+\sqrt{2\beta^{-1}}\mathrm{d}W_{s},
\]
with $X_{s}\in\mathbb{R}^{n}$, $\beta>0$ and the potential $U:\mathbb{R}^{n}\rightarrow\mathbb{R}$ obeying adequate growth and smoothness conditions (see \cite{HairerStuartVoss2007}, Section 5 for precise statements). The law of the solution to this SDE conditioned on the events $X(0)=x_{-}$ and $X(s_{+})=x_{+}$ is a probability measure $\pi$ on $L^{2}([0,s_{+}],\mathbb{R}^{n})$
which poses a challenging and important sampling problem, especially if $U$ is multimodal. This
setting has been used as a test case for sampling probability measures
in high dimensions (see for example \cite{BeskosPinskiSanz-SernaEtAl2011} and
\cite{OttobrePillaiPinskiEtAl2016}). For a more detailed introduction (including applications)
see \cite{BeskosStuart2009} and for a rigorous theoretical treatment
the papers \cite{HairerStuartVossEtAl2005,HairerStuartVoss2007,HairerStuartVos2009,BeskosStuart2009} .

In the case $U\equiv0$, it can be shown that the law of the conditioned
process is given by a Gaussian measure $\pi_{0}$ with mean zero and
precision operator $\mathcal{S}=-\frac{\beta}{2}\Delta$ on the Sobolev
space $H^{1}([0,s_{+}],\mathbb{R}^{d})$ equipped with appropriate
boundary conditions. The general case can then be understood as a
perturbation thereof: The measure $\pi$ is absolutely continuous
with respect to $\pi_{0}$ with Radon-Nikodym derivative 
\begin{equation}
\frac{\mathrm{d}\pi}{\mathrm{d}\pi_{0}}\propto\exp\big(-\Psi\big),\label{eq:Radon-Nikodyn for diffusion bridges}
\end{equation}
where
\[
\Psi(x)=\frac{\beta}{2}\int_{0}^{s_{+}}G(x(s),\beta)\mathrm{d}s
\]
and 
\[
G(x,\beta)=\frac{1}{2}\vert\nabla U(x)\vert^{2}-\frac{1}{\beta}\Delta U(x).
\]
We will make the choice $x_{-}=x_{+}=0$, which is possible without
loss of generality as explained in \cite[Remark 3.1]{BeskosRobertsStuartEtAl2008}, leading to Dirichlet boundary conditions on $[0,s_+]$ for the precision operator $\mathcal{S}$. Furthermore, we choose $s_{+}=1$ and discretise the ensuing
$s$-interval $[0,1]$ according to 
\[
[0,1]=[0,s_{1})\cup[s_{1},s_{2})\cup\ldots\cup[s_{n-1},s_{n})\cup[s_{n},1]
\]
in an equidistant way with stespize $s_{j+1}-s_{j}\equiv\delta=\frac{1}{d+1}$. Functions on this grid are determined by the values $x(s_1)=x_1,\ldots,x(s_n)=x_n$, recalling that $x(0)=x(1)=0$ by the Dirichlet boundary conditions. We discretise the functional
$\Psi$ as
\begin{align*}
\tilde{\Psi}(x_{1},\ldots,x_{n}) & =\frac{\beta}{2}\delta\sum_{i=1}^{d}G(x_{i},\beta)\\
& =\frac{\beta}{2}\delta \sum_{i=1}^{d}\big((U'(x_{i})^{2}-\frac{1}{\beta}U''(x_{i})\big),
\end{align*}
such that its gradient is given by 
\[
(\nabla\tilde{\Psi})_{i}=\frac{\beta}{2}\delta\big(2U'(x_{i})U''(x_{i})-\frac{1}{\beta}U'''(x_{i})\big),\quad i=1,\ldots,d.
\]
The discretised version $A$ of the Dirichlet-Laplacian $\Delta$ on $[0,1]$ is given by
\[
A=\delta^{-2}\left(\begin{array}{ccccc}
-2 & 1\\
1 & -2\\
&  & \ldots\\
&  &  &  & 1\\
&  &  & 1 & -2
\end{array}\right).
\]
Following (\ref{eq:Radon-Nikodyn for diffusion bridges}), the discretised
target measure $\widehat{\pi}$ has the form
\[
\widehat{\pi}=\frac{1}{Z}e^{-V}\mathrm{d}x,
\]
with 
\[
V(x)=\tilde{\Psi}(x)-\frac{\beta\delta }{4}x\cdot Ax,\quad x\in\mathbb{R}^{d}.
\]
In the following we will consider the case $n=1$ with potential $U:\mathbb{R}\rightarrow\mathbb{R}$
given by $U(x)=\frac{1}{2}(x^{2}-1)^{2}$ and set $\beta=1$. To test
our algorithm we adjust the parameters $M$, $\Gamma$, $J_{1}$ and
$J_{2}$ according to the recommended choice in the Gaussian case,
\begin{equation}
\label{eq:Gaussian_parameters}
M  = S, \quad
\Gamma =\gamma S, \quad
SJ_{1}S =J_{2}, \quad 
\mu =\nu,
\end{equation}
where we take $S=\frac{\beta}{2}\delta\cdot A$ as the precision
operator of the Gaussian target.  We will consider the linear observable
$f_{1}(x)=l\cdot x$ with $l=(1,\ldots,1)$ and the quadratic observable
$f_{2}(x)=\vert x\vert^{2}$. In a first experiment we adjust the
perturbation $J_{1}$ (and via (\ref{eq:Gaussian_parameters})
also $J_{2}$) to the observable $f_{2}$ according to Algorithm \ref{alg:optimal J general}.
The dynamics (\ref{eq:perturbed_underdamped}) is integrated
using the splitting scheme introduced in Section \ref{sec:numerical_scheme}
with a stepsize of $\Delta t=10^{-4}$ over the time interval $[0,T]$
with $T=10^{2}$. Furthermore, we choose initial conditions $q_0=(1,\ldots,1)$, $p_0=(0,\ldots,0)$  and introduce a burn-in time $T_{0}=1$,
i.e. we take the estimator to be 
\[
\hat{\pi}(f)\approx\frac{1}{T-T_{0}}\int_{T_{0}}^{T}f(q_{t})\mathrm{d}t.
\]
We compute the variance of the above estimator from $N=500$ realisations
and compare the results for different choices of the friction coefficient $\gamma$
and of the perturbation strength $\mu$. 

The numerical experiments show that the perturbed dynamics generally outperform
the unperturbed dynamics independently of the choice of $\mu$ and $\gamma$, both for linear and quadratic observables. One notable exception is the behaviour of the linear observable for small friction $\gamma = 10^{-3}$ (see Figure \ref{fig:lin_1}), where the asymptotic variance initially increases for small perturbation strengths $\mu$. However, this does not contradict our analytical results, since the small perturbation results from Section \ref{sec:small perturbations} generally require $\gamma$ to be sufficiently big (for example $\gamma\ge \sqrt{2}$ in Theorem \ref{cor:small pert unit var}). We remark here that the condition $\gamma\ge\sqrt{2}$, while necessary for the theoretical results from Section \ref{sec:small perturbations}, is not a very advisable choice in practice (at least in this experiment), since Figures \ref{fig:lin_2} and \ref{fig:quad2} clearly indicate that the optimal friction is around $\gamma \approx 10^{-1}$. Interestingly, the problem of choosing a suitable value for the friction coefficient coefficient $\gamma$ becomes mitigated by the introduction of the perturbation: While the performance of the unperturbed sampler depends quite sensitively on $\gamma$, the asymptotic variance of the perturbed dynamics is a lot more stable with respect to variations of $\gamma$. 

In the regime of growing values of $\mu$, the experiments confirm the results from Section \ref{sec:large perturbations}, i.e. the asymptotic variance approaches a limit that is smaller than the asymptotic variance of the unperturbed dynamics.

As a final remark we report our finding that the performance of the sampler for the linear observable is qualitatively independent of the coice of $J_1$ (as long as $J_2$ is adjusted according to \eqref{eq:Gaussian_parameters}). This result is in alignment with Propostion \ref{prop:antisymmetric observables} which predicts good properties of the sampler for antisymmetric observables. In contrast to this, a judicious choice of $J_1$ is critical for quadratic observables. In particular, applying Algorithm \ref{alg:optimal J general} significantly improves the performance of the perturbed sampler in comparison to choosing $J_1$ arbitrarily.   
\begin{figure}
	\begin{subfigure}[b]{0.45 \textwidth}
		\includegraphics[width=\textwidth]{linear_observable1}
		\caption{}
		\label{fig:lin_1}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.45 \textwidth}
		\includegraphics[width=\textwidth]{linear_observable2}
		\caption{}
		\label{fig:lin_2}
	\end{subfigure}
	.	\caption{Standard deviation of $\hat{\pi}(f)$ for a linear observable as
			a function of friction $\gamma$ and perturbation strength $\mu$}
	\label{fig:linear_observable}
\end{figure}

\begin{figure}
	\begin{subfigure}[b]{0.45 \textwidth}
		\includegraphics[width=\textwidth]{quadratic_observable1}
		\caption{}
		\label{fig:quad1}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.45 \textwidth}
		\includegraphics[width=\textwidth]{quadratic_observable2}
		\caption{}
		\label{fig:quad2}
	\end{subfigure}
	.	\caption{Standard deviation of $\hat{\pi}(f)$ for a quadratic observable as
		a function of friction $\gamma$ and perturbation strength $\mu$}
	\label{fig:linear_observable}
\end{figure}

Given a symmetric matrix $K\in\mathbb{R}_{sym}^{d\times d}$ with
$\Tr K=0$, we seek to find an orthogonal matrix $U\in O(\mathbb{R}^{d})$
such that $UKU^{T}$ has zeros on the diagonal. This is a crucial
step in Algorithms \ref{alg:optimal J} and \ref{alg:optimal J general}
and has been addressed in various places in the literature (see for
instance \cite{alg_zero_diag} or \cite{Bhatia1997}, Chapter 2,
Section 2). For the convenience of the reader, in the following we
summarize an algorithm very similar to the one in \cite{alg_zero_diag}.
\\\\
Since $K$ is symmetric, there exists an orthogonal matrix $U_{0}\in O(\mathbb{R}^{d})$
such that $U_{0}KU_{0}^{T}=\diag(\lambda_{1},\ldots,\lambda_{d})$.
Now the algorithm proceeds iteratively, orthogonally transforming
this matrix into one with the first diagonal entry vanishing, then
the first two diagonal entries vanishing, etc, until after $d$ steps
we are left with a matrix with zeros on the diagonal. Starting with
$\lambda_{1}$, assume that $\lambda_{1}\neq0$ (otherwise proceed
with $\lambda_{2}$). Since $\Tr(K)=\Tr(U_{0}KU_{0}^{T})=\sum\lambda_{i}=0$,
there exists $\lambda_{j}$, $j\in\{2,\ldots,d\}$ such that $\lambda_{1}\lambda_{j}<0$
(i.e. $\lambda_{1}$ and $\lambda_{j}$ have opposing signs). We now
apply a rotation in the $1j$-plane to transform the first diagonal
entry into zero. More specifically, let 
\[
U_{1}=\begin{blockarray}{ccccccccc}
 ~ & ~ & ~ & ~ & j & ~ & ~ & ~ & ~\\
\begin{block}{(cccccccc)c}
\cos\alpha & 0 & \ldots & 0 & -\sin\alpha & 0 & \ldots & 0 & ~\\
0 & 1 & ~ & ~ & 0 & ~ & ~ & \vdots & ~\\
\vdots & ~ & \ddots & ~ & ~ & ~ & ~ & ~ & ~\\
0 & ~ & ~ & 1 & 0 & ~ & ~ & ~ & ~\\
\sin\alpha & 0 & ~ & 0 & \cos\alpha & 0 & ~ & ~ & j\\
0 & ~ & ~ & ~ & 0 & 1 & ~ & \vdots & ~\\
\vdots & ~ & ~ & ~ & ~ & ~ & \ddots & 0 & ~\\
0 & 0 & \hdots & ~ & ~ & \hdots & 0 & 1 & ~ \\
\end{block}\end{blockarray} \in O(\mathbb{R}^{d})
\]
with $\alpha=\arctan\sqrt{-\frac{\lambda_{1}}{\lambda_{j}}}.$ We
then have $(U_{1}U_{0}KU_{0}^{T}U_{1}^{T})_{11}=0$. Now the same
procedure can be applied to the second diagonal entry $\text{\ensuremath{\lambda}}_{2}$,
leading to the matrix $U_{2}U_{1}U_{0}KU_{0}^{T}U_{1}^{T}U_{2}^{T}$
with 
\[
(U_{2}U_{1}U_{0}KU_{0}^{T}U_{1}^{T}U_{2}^{T})_{11}=(U_{2}U_{1}U_{0}KU_{0}^{T}U_{1}^{T}U_{2}^{T})_{22}=0
\]
Iterating this process, we obtain that $U_{d}\ldots U_{1}U_{0}KU_{0}^{T}U_{1}^{T}\ldots U_{d}^{T}$
has zeros on the diagonal, so $U_{d}\ldots U_{1}U_{0}\in O(\mathbb{R}^{d})$
is the required orthogonal transformation. 


In this section we study in detail the performance of the Langevin sampler~\eqref{eq:perturbed_underdamped} for Gaussian target densities, first considering the case of unit covariance. In particular, we study the optimal choice for the parameters in the sampler, the exponential decay rate and the asymptotic variance. We then extend our results to Gaussian target densities with arbitrary covariance matrices.

\subsection{Unit covariance - small perturbations}
\label{sec:small perturbations}

In our study of the dynamics given by \eqref{eq:perturbed_underdamped}
we first consider the simple case when $V(q)=\frac{1}{2}\vert q\vert^{2}$,
i.e. the task of sampling from a Gaussian measure with unit covariance.
We will assume $M=I$, $\Gamma=\gamma I$ and $J_{1}=J_{2}=:J$
(so that the $q-$ and $p-$dynamics are perturbed in the same way,
albeit posssibly with different strengths $\mu$ and $\nu$). Using
these simplifications, (\ref{eq:perturbed_underdamped})
reduces to the linear system 
\begin{align}
\mathrm{d}q_{t} & =p_{t}\mathrm{d}t-\mu Jq_{t}\mathrm{d}t\nonumber, \\
\mathrm{d}p_{t} & =-q_{t}\mathrm{d}t-\nu Jp_{t}\mathrm{d}t-\gamma p_{t}\mathrm{d}t+\sqrt{2\gamma}\mathrm{d}W_{t}.\label{eq:unit covariance}
\end{align}
The above dynamics are of Ornstein-Uhlenbeck type, i.e. we can write
\begin{equation}
\mathrm{d}X_{t}=-BX_{t}\mathrm{d}t+\sqrt{2Q}\mathrm{d}\bar{W}_{t}\label{eq:OU process}
\end{equation}
with $X=(q,p)^{T}$, 
\begin{equation}
B=\left(\begin{array}{cc}
\mu J & -I\\
I & \gamma I+\nu J
\end{array}\right),\label{eq:drift matrix}
\end{equation}
\begin{equation}
Q=\left(\begin{array}{cc}
\boldsymbol{0} & \boldsymbol{0}\\
\boldsymbol{0} & \gamma I
\end{array}\right)\label{eq:diffusion matrix}
\end{equation}
and $(\bar{W}_{t})_{t\ge0}$ denoting a standard Wiener process on
$\mathbb{R}^{2d}$. The generator of (\ref{eq:OU process}) is then
given by 
\begin{equation}
\mathcal{L}=-Bx\cdot\nabla+\nabla^{T}Q\nabla.\label{eq:OU generator}
\end{equation}
We will consider quadratic observables of the form 
\[
f(q)=q\cdot Kq+l\cdot q+C,
\]
with $K\in\mathbb{R}_{sym}^{d\times d}$, $l\in\mathbb{R}^{d}$ and
$C\in\mathbb{R}$, however it is worth recalling that the asymptotic variance $\sigma^2_f$ does not depend on $C$. We also stress that $f$ is assumed to be independent of
$p$ as those extra degrees of freedom are merely auxiliary. Our
aim will be to study the associated asymptotic variance $\sigma_{f}^{2}$, see equation (\ref{eq:asymptoticvariance}), in particular its
dependence on the parameters $\mu$ and $\nu$.  This dependence is encoded in the
function 
\begin{alignat*}{1}
\Theta:\quad\mathbb{R}^{2} & \rightarrow\mathbb{R}\\
(\mu,\nu) & \mapsto\sigma_{f}^{2},
\end{alignat*}
assuming a fixed observable $f$ and perturbation matrix $J$. In
this section we will focus on small perturbations, i.e. on the behaviour
of the function $\Theta$ in the neighbourhood of the origin. Our
main theoretical tool will be the Poisson equation \eqref{eq:poisson_general}, see the proofs in Appendix \ref{app:Gaussian_proofs}. Anticipating the forthcoming analysis, let us already state our main result, showing that in the neighbourhood of the origin, the function $\Theta$ has favourable properties along the diagonal $\mu=\nu$ (note that the perturbation strengths in the first and second line of \eqref{eq: unit covariance-1-1} coincide):

\begin{theorem}
	\label{cor:small pert unit var}Consider the dynamics 
\begin{align}
\mathrm{d}q_{t} & =p_{t}\mathrm{d}t-\mu Jq_{t}\mathrm{d}t,\nonumber \\
\mathrm{d}p_{t} & =-q_{t}\mathrm{d}t-\mu Jp_{t}\mathrm{d}t-\gamma p_{t}\mathrm{d}t+\sqrt{2\gamma}\mathrm{d}W_{t},\label{eq: unit covariance-1-1}
\end{align}
with $\gamma>\sqrt{2}$ and an observable of the form $f(q)=q\cdot Kq+l\cdot q+C$.
If at least one of the conditions $[J,K]\neq0$ and $l\notin\ker J$
is satisfied, then the asymptotic variance of the unperturbed sampler
is at a local maximum independently of $K$ and $J$ (and $\gamma$,
as long as $\gamma>\sqrt{2}$), i.e. 
\[
\left. \partial_{\mu}\sigma_{f}^{2} \right\rvert_{\mu =0}=0
\]
and 
\[
\left. \partial_{\mu}^{2}\sigma_{f}^{2}\right\rvert_{\mu = 0}<0.
\]
\end{theorem}



\subsubsection{\label{sub:Purely-quadratic-observables}Purely quadratic observables}

Let us start with the case $l=0$, i.e. $f(q)=q\cdot Kq+C$. The following
holds: 
\begin{proposition}
	\label{thm: local quadratic observable}The function $\Theta$ satisfies
	\begin{equation}
	\left. \nabla\Theta\right\rvert_{(\mu,\nu)=(0,0)}=0\label{eq:gradTheta}
	\end{equation}
	and 
	\begin{equation}
	\left. \Hess\Theta\right\rvert_{(\mu,\nu)=(0,0)}=\left(\begin{array}{cc}
	-(\gamma+\frac{1}{\gamma^{3}}+\gamma^{3})\left(\Tr(JKJK)-\Tr(J^{2}K^{2})\right) & (\frac{1}{\gamma^{3}}+\frac{1}{\gamma}-\gamma)\Tr(J^{2}K^{2})\\
	-\frac{2}{\gamma}\Tr(JKJK) & +(-\frac{1}{\gamma^{3}}+\frac{1}{\gamma}+\gamma)\Tr(JKJK)\\
	(\frac{1}{\gamma^{3}}+\frac{1}{\gamma}-\gamma)\Tr(J^{2}K^{2}) & (\frac{1}{\gamma^{3}}-\frac{1}{\gamma})\Tr(J^{2}K^{2})\\
	+(-\frac{1}{\gamma^{3}}+\frac{1}{\gamma}+\gamma)\Tr(JKJK) & -(\frac{1}{\gamma^{3}}+\frac{1}{\gamma})\Tr(JKJK)
	\end{array}\right).\label{eq:HessTheta}
	\end{equation}
\end{proposition}
\begin{proof}
	See Appendix \ref{app:Gaussian_proofs}.
	\qed
\end{proof}
The above proposition shows that the unperturbed dynamics represents a
critical point of $\Theta$, independently of the choice of $K$,
$J$ and $\gamma$. In general though, $\Hess\Theta\vert_{(\mu,\nu)=(0,0)}$
can have both positive and negative eigenvalues. In particular, this
implies that an unfortunate choice of the perturbations will actually
increase the asymptotic variance of the dynamics (in contrast to the situation
of perturbed \emph{overdamped }Langevin dynamics, where any nonreversible
perturbation leads to an improvement in asymptotic variance as detailed
in \cite{asvar_Hwang} and \cite{duncan2016variance}). Furthermore, the nondiagonality
of $\Hess\Theta\vert_{(\mu,\nu)=(0,0)}$ hints at the fact that the
interplay of the perturbations $J_{1}$ and $J_{2}$ (or rather their
relative strengths $\mu$ and $\nu$) is crucial for the performance
of the sampler and, consequently, the effect of these perturbations cannot be satisfactorily
studied independently. 
\begin{example}
	Assuming $J^{2}=-I$ and $[J,K]=0$ it follows that
	\[
	\left. \partial_{\mu}^{2}\Theta\right\rvert_{\mu=0}=\left. \partial_{\nu}^{2}\Theta\right\rvert_{\mu=0}=\frac{1}{\gamma}\Tr(K^{2})>0,
	\]
	for all nonzero $K$. Therefore in this case, a small perturbation of $J_{1}$ only or $J_{2}$ only will increase  the asymptotic variance, uniformly over all choices of $K$ and $\gamma$.
\end{example}
However, it turns out that it is possible to construct an improved sampler
by combining both perturbations in a suitable way. Indeed,
the function $\Theta$ can be seen to have good properties along $\mu=\nu$. We set $\mu(s)=s$, $\nu(s):=s$ and compute

\begin{align*}
\left. \frac{\mathrm{d}^{2}}{\mathrm{d}s^{2}}\Theta\right\rvert_{s=0} & =(1,1)\cdot\Hess\Theta\vert_{(\mu,\nu)=(0,0)}(1,1)\\
& =-(\gamma+\frac{1}{\gamma^{3}}+\gamma^{3})\left(\Tr(JKJK)-\Tr(J^{2}K^{2})\right)-\frac{2}{\gamma}\Tr(JKJK)\\
& +2\cdot\left((\frac{1}{\gamma^{3}}+\frac{1}{\gamma}-\gamma)\Tr(J^{2}K^{2})+(-\frac{1}{\gamma^{3}}+\frac{1}{\gamma}+\gamma)\Tr(JKJK)\right)\\
& +(\frac{1}{\gamma^{3}}-\frac{1}{\gamma})\Tr(J^{2}K^{2})-(\frac{1}{\gamma^{3}}+\frac{1}{\gamma})\Tr(JKJK)\\
& =\big(\gamma-\frac{4}{\gamma^{3}}-\gamma^{3}-\frac{1}{\gamma}\big)\cdot(\Tr(JKJK)-\Tr(J^{2}K^{2}))\le0.
\end{align*}
The last inequality follows from 
\[
\gamma-\frac{4}{\gamma^{3}}-\gamma^{3}-\frac{1}{\gamma}<0
\]
and 
\[
\Tr(JKJK)-\Tr(J^{2}K^{2})\ge0
\]
(both inequalities are proven in the Appendix, Lemma \ref{lem:basic_inequalities}), where the last inequality
is strict if $[J,K]\neq0$. Consequently, choosing both perturbations
to be of the same magnitude ($\mu=\nu$) and assuring that $J$ and
$K$ do not commute always leads to a smaller asymptotic variance,
independently of the choice of $K$, $J$ and $\gamma$. We state
this result in the following corrolary:
\begin{corollary}
	\label{cor:unit covariance quadratic obs}Consider the dynamics 
	\begin{align}
	\mathrm{d}q_{t} & =p_{t}\mathrm{d}t-\mu Jq_{t}\mathrm{d}t\nonumber, \\
	\mathrm{d}p_{t} & =-q_{t}\mathrm{d}t-\mu Jp_{t}\mathrm{d}t-\gamma p_{t}\mathrm{d}t+\sqrt{2\gamma}\mathrm{d}W_{t},\label{eq: unit covariance-1}
	\end{align}
 and a quadratic observable $f(q)=q\cdot Kq+C$. If $[J,K] \neq 0,$
	then the asymptotic variance of the unperturbed sampler is at a local
	maximum independently of K, $J$ and $\gamma$, i.e. 
	\[
	\left. \partial_{\mu}\sigma_{f}^{2}\right\rvert_{\mu=0}=0
	\]
	and 
	\[
	\left. \partial_{\mu}^{2}\sigma_{f}^{2}\right\rvert_{\mu=0}<0.
	\]
\end{corollary}
\begin{remark}
	As we will see in Section \ref{sec:large perturbations}, more precisely Example \ref{ex:commutation quadratic observables}, if $[J,K]=0,$
	the asymptotic variance is constant as a function of $\mu$, i.e.
	the perturbation has no effect.\end{remark}
\begin{example}
\label{ex:opposed perturbation}
	Let us set $\mu(s):=s$ and $\nu(s):=-s$ (this corresponds to a small
	perturbation with $J\nabla V(q_{t})\mathrm{d}t$ in $q$ and $-Jp_{t}\mathrm{d}t$
	in $p$). In this case we get 
	\[
	\left. \frac{\mathrm{d}^{2}\Theta}{\mathrm{d}s^{2}} \right\rvert_{s=0}=\underbrace{-\frac{1}{2}\cdot\frac{\gamma^{4}+3\gamma^{2}+5}{\gamma}\left(\Tr(JKJK)-\Tr(J^{2}K^{2})\right)}_{\le0}\underbrace{-4\frac{\Tr(J^{2}K^{2})}{\gamma}}_{\ge0},
	\]
	which changes its sign depending on $J$ and $K$ as the first term
	is negative and the second is positive. Whether the perturbation improves the performance of the sampler in terms of asymptotic variance therefore depends on the specifics of the observable and the perturbation in this case.
	
\end{example}

\subsubsection{Linear observables}

Here we consider the case $K=0$, i.e. $f(q)=l\cdot q+C$, where
again $l\in\mathbb{R}^{d}$ and $C\in\mathbb{R}$. We have the following
result: 
\begin{proposition}
	\label{thm:linear_full_J}The function $\Theta$ satisfies 
	\[
	\nabla\Theta\vert_{(\mu,\nu)=(0,0)}=0
	\]
	and 
	\[
	\Hess\Theta\vert_{(\mu,\nu)=(0,0)}=\left(\begin{array}{cc}
	-2\gamma^{3}\vert Jl\vert^{2} & 2\gamma\vert Jl\vert^{2}\\
	2\gamma\vert Jl\vert^{2} & 0
	\end{array}\right).
	\]
\end{proposition}
\begin{proof}
	See Appendix \ref{app:Gaussian_proofs}.
	\qed
\end{proof}
	Let us assume that $l\notin\ker J$. Then $\partial_{\mu}^{2}\Theta\vert_{\mu,\nu=0}<0$,
	and hence Theorem \ref{thm:linear_full_J} shows that a small perturbation
	by $\mu J\nabla V(q_{t})\mathrm{d}t$ alone always results in an improvement
	of the asymptotic variance. However, if we combine both perturbations
	$\mu J\nabla V(q_{t})\mathrm{d}t$ and $\nu Jp_{t}\mathrm{d}t$, then
	the effect depends on the sign of 
	\[
	\left(\begin{array}{cc}
	\mu & \nu\end{array}\right)\left(\begin{array}{cc}
	-2\gamma^{3}\vert Jl\vert^{2} & 2\gamma\vert Jl\vert^{2}\\
	2\gamma\vert Jl\vert^{2} & 0
	\end{array}\right)\left(\begin{array}{c}
	\mu\\
	\nu
	\end{array}\right)=-(2\mu^{2}\gamma^{3}-4\mu\nu\gamma)\vert Jl\vert^{2}.
	\]
	This will be negative if $\mu$ and $\nu$ have different signs, and
	also if they have the same sign and $\gamma$ is big enough.
Following Section \ref{sub:Purely-quadratic-observables}, we require
$\mu=\nu$. We then end up with the requirement 
\[
2\mu^{2}\gamma^{3}-4\mu\nu\gamma>0,
\]
which is satisfied if $\gamma>\sqrt{2}$

Summarizing the results of this section, for observables of the form
$f(q)=q\cdot Kq+l\cdot q+C$, choosing equal perturbations ($\mu=\nu$)
with a sufficiently strong damping $(\gamma>\sqrt{2}$) always leads
to an improvement in asymptotic variance under the conditions $[J,K]\neq0$
and $l\notin\ker J$. This is finally the content of Theorem \ref{cor:small pert unit var}.
\begin{figure}
	\begin{subfigure}[b]{0.5 \textwidth}
		\includegraphics[width=\textwidth]{q_equal}
		\caption{Equal perturbations: $\mu=\nu$}
		\label{fig:asym_quad}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.5 \textwidth}
		\includegraphics[width=\textwidth]{q_09}
		\caption{Approximately equal perturbations: $\mu=0.9\nu$}
		\label{fig:no_limit1}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.5 \textwidth}
		\includegraphics[width=\textwidth]{q_opp}
		\caption{Opposing perturbations: $\mu=-\nu$ 
			\label{fig:no_limit2}}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.5 \textwidth}
		\includegraphics[width=\textwidth]{l_equalg25.pdf}
		\caption{Equal perturbations: $\mu=\nu$ (sufficiently large friction $\gamma$)}
		\label{fig:lin_large_friction}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.5 \textwidth}
		\includegraphics[width=\textwidth]{l_equal_g1.pdf}
		
		\caption{Equal perturbations: $\mu=\nu$ (small friction $\gamma$)}
		\label{fig:lin_small_friction}
	\end{subfigure}
	\caption{Asymptotic variance for linear and quadratic observables, depending on relative perturbation and friction strengths}
	\label{fig:linear and quadratic observables}
\end{figure}

Let us illustrate the results of this section by plotting the asymptotic variance as a function of the perturbation strength $\mu$ (see Figure \ref{fig:linear and quadratic observables}), making the choices $d=2$, $l=(1,1)^{T}$,
\begin{equation}
K=\left(\begin{array}{cc}
2 & 0\\
0 & 1
\end{array}\right)
\quad \text{and} \quad
J=\left(\begin{array}{cc}
0 & 1\\
-1 & 0
\end{array}\right).
\end{equation}
The asymptotic variance has been computed according to \eqref{eq:Gaussian asymvar}, using \eqref{eq:Lyapunov equation} and \eqref{eq:linear condition} from Appendix \ref{app:Gaussian_proofs}. The graphs confirm the results summarized in Corollary \ref{cor:small pert unit var} concerning the asymptotic variance in the neighbourhood of the unperturbed dynamics ($\mu = 0$). Additionally, they give an impression of the global behaviour, i.e. for larger values of $\mu$.

Figures \ref{fig:asym_quad}, \ref{fig:no_limit1} and \ref{fig:no_limit2}  show the asymptotic variance associated with the quadratic observable $f(q)=q\cdot K q$. In accordance with Corollary \ref{cor:unit covariance quadratic obs}, the asymptotic variance is at a  local maximum at zero perturbation in the case $\mu=\nu$ (see Figure \ref{fig:asym_quad}). For increasing perturbation strength, the graph shows that it decays monotonically
and reaches a limit for $\mu\rightarrow\infty$ (this limiting behaviour will be explored analytically in Section \ref{sec:large perturbations}). If the condition $\mu=\nu$ is only approximately satisfied (Figure \ref{fig:no_limit1}), our numerical examples still exhibits decaying asymptotic variance in the neighbourhood of the critical point. In this case, however, the asymptotic variance diverges for growing values of the perturbation $\mu$. If the perturbations are opposed ($\mu=-\nu$) as in Example \ref{ex:opposed perturbation}, it is possible for certain observables that the unperturbed dynamics represents a global minimum. Such a case is observed in Figure \ref{fig:no_limit2}. In Figures \ref{fig:lin_large_friction} and \ref{fig:lin_small_friction} the observable $f(q)=l\cdot q$ is considered. If the damping is sufficiently strong ($\gamma > \sqrt{2}$), the unperturbed dynamics is at a local maximum of the asymptotic variance (Figure \ref{fig:lin_large_friction}). Furthermore, the asymptotic variance approaches zero as $\mu \rightarrow \infty$ (for a theoretical explanation see again Section \ref{sec:large perturbations}). The graph in Figure \ref{fig:lin_small_friction} shows that the assumption of $\gamma$ not being too small cannot be dropped from Corollary \ref{cor:small pert unit var}. Even in this case though the example shows decay of the asymptotic variance for large values of $\mu$.    
\subsection{Exponential decay rate}
\label{sec:exp_decay}
Let us denote by $\lambda^{*}$ the \emph{optimal exponential decay rate} in \eqref{eq:hypocoercive estimate}, i.e.
\begin{equation}
\lambda^{*}=\sup\{\lambda > 0 \, \vert \, \text{There exists } C\ge 1 \text{ such that } \eqref{eq:hypocoercive estimate} \text{ holds}\}.
\end{equation}
Note that $\lambda^{*}$ is well-defined and positive by Theorem \ref{theorem:Hypocoercivity}. We also define the \emph{spectral bound} of the generator $\gen$ by
\begin{equation}
s(\gen)=\inf(\text{Re}\,\sigma(-\gen)\setminus\{0\}).
\end{equation} 
In \cite{Metafune_formula} it is proven that the Ornstein-Uhlenbeck semigroup $(P_t)_{t\ge0}$ considered in this section is differentiable (see Proposition 2.1). In this case (see Corollary 3.12 of \cite{Engel2000Semigroup}), it is known that the exponential decay rate and the spectral bound coincide, i.e. $\lambda^{*}=s(\gen)$, whereas in general only $\lambda^{*}\le s(\gen)$ holds.
In this section we will therefore analyse the spectral properties of the generator
(\ref{eq:OU generator}). In particular, this leads to some intuition
of why choosing equal perturbations ($\mu=\nu$) is crucial for the
performance of the sampler.

In \cite{Metafune_formula} (see also \cite{OPP12}), it was proven that
the spectrum of $\mathcal{L}$ as in (\ref{eq:OU generator}) in $L^{2}(\widehat{\pi})$
is given by 
\begin{equation}
\sigma(\mathcal{L})=\left\{-\sum_{j=1}^{r}n_{j}\lambda_{j}:\, n_{j}\in\mathbb{N},\lambda_{j}\in \sigma(B)\right\}.\label{eq:Metafune formula}
\end{equation}
Note that $\sigma(\mathcal{L})$ only depends on the drift matrix
$B$. In the case where $\mu=\nu$,
the spectrum of $B$ can be computed explicitly. 
\begin{lemma}
	\label{lem:drift matrix properties}Assume $\mu=\nu$. Then the spectrum
	of $B$ is given by
	\begin{equation}
	\sigma(B)=\left\{\mu\lambda+\sqrt{\big(\frac{\gamma}{2}\big)^{2}-1}+\frac{\gamma}{2}\vert\lambda\in\sigma(J)\}\cup\{\mu\lambda-\sqrt{\big(\frac{\gamma}{2}\big)^{2}-1}+\frac{\gamma}{2}\vert\lambda\in\sigma(J)\right\}.\label{eq:spectrum of B}
	\end{equation}
\end{lemma}
\begin{proof}
	We will compute $\sigma\big(B-\frac{\gamma}{2}I\big)$ and then use
	the identity
	\begin{equation}
	\sigma(B)=\left\{\lambda+\frac{\gamma}{2}\vert\lambda\in\sigma\left(B-\frac{\gamma}{2}I\right)\right\}.\label{eq:shift spectrum}
	\end{equation}
	We have 
	\begin{align*}
	\det\left(B-\frac{\gamma}{2}I-\lambda I\right) & =\det\left(\left(\mu J-\frac{\gamma}{2}I-\lambda I\right)\left(\mu J+\frac{\gamma}{2}I-\lambda I\right)+I\right)\\
	& =\det\left((\mu J-\lambda I)^{2}-\left(\frac{\gamma}{2}\right)^{2}I+I\right)\\
	& =\det\left(\left(\mu J-\lambda I+\sqrt{\left(\frac{\gamma}{2}\right)^{2}-1} I\right)\cdot\left(\mu J-\lambda I-\sqrt{\left(\frac{\gamma}{2} \right)^{2}-1} I\right)\right)\\
	& =\det\left(\mu J-\lambda I+\sqrt{\left(\frac{\gamma}{2}\right)^{2}-1} I\right)\cdot\det\left(\mu J-\lambda I-\sqrt{\left(\frac{\gamma}{2}\right)^{2}-1} I\right),
	\end{align*}
	where $I$ is understood to denote the identity matrix of appropriate dimension.
	The above quantity is zero if and only if 
	\[
	\lambda-\sqrt{\left(\frac{\gamma}{2}\right)^{2}-1}\in\sigma(\mu J)
	\]
	or 
	\[
	\lambda+\sqrt{\left(\frac{\gamma}{2}\right)^{2}-1}\in\sigma(\mu J).
	\]
	Together with (\ref{eq:shift spectrum}), the claim follows.
	\qed
\end{proof}
Using formula \eqref{eq:Metafune formula}, in Figure \ref{fig:good_spectrum} we show a sketch of the spectrum $\sigma(-\mathcal{L}$)
for the case of equal perturbations ($\mu=\nu)$ with the convenient
choices $n=1$ and $\gamma=2.$ Of course, the eigenvalue at $0$ is
associated to the invariant measure since $\sigma(-\mathcal{L})=\sigma(-\mathcal{L}^{\dagger})$
and $\mathcal{L}^{\dagger}\widehat{\pi}=0$, where $\mathcal{L}^{\dagger}$ denotes the Fokker-Planck operator, i.e. the $L^2(\mathbb{R}^{2d})$-adjoint of $\mathcal{L}$. The arrows indicate the movement
of the eigenvalues as the perturbation $\mu$ increases in accordance
with Lemma \ref{lem:drift matrix properties}. Clearly, the spectral
bound of $\gen$ is not affected by the perturbation. 
Note that the eigenvalues on the real axis stay invariant under the
perturbation. The subspace of $L_{0}^{2}(\widehat{\pi})$ associated to
those will turn out to be crucial for the characterisation of the
limiting asymptotic variance as $\mu\rightarrow\infty$.

To illustrate the suboptimal properties of the perturbed dynamics
when the perturbations are not equal, we plot the spectrum of the
drift matrix $\sigma(B)$ in the case when the dynamics is only perturbed
by the term $\nu J_{2}p\mathrm{d}t$ (i.e. $\mu=0$) for $n=2$, $\gamma=2$ and
\begin{equation}
J_2=\left(\begin{array}{cc}
0 & -1\\
1 & 0
\end{array}\right),
\end{equation} 
(see Figure \ref{fig:bad_spectrum}). Note that the full spectrum $\sigma(-\mathcal{L})$
can be inferred from (\ref{eq:Metafune formula}). For $\nu=0$ we have that the spectrum $\sigma(B)$
only consists of the (degenerate) eigenvalue $1$. For increasing
$\nu$, the figure shows that the degenerate eigenvalue splits up
into four eigenvalues, two of which get closer to the imaginary axis as $\nu$ increases, leading to a smaller spectral
bound and therefore to a decrease in the speed of convergence to equilibrium.
Figures (\ref{fig:good_spectrum}) and (\ref{fig:bad_spectrum}) give an intuitive explanation
of why the fine-tuning of the perturbation strengths is crucial.

\begin{figure}
	\begin{subfigure}[b]{0.45 \textwidth}
		\includegraphics[width=\textwidth]{spectrum2.pdf}
		\caption{$\sigma(-\gen)$ in the case $\mu=\nu$. The arrows indicate the movement of the spectrum as the perturbation strength $\mu$ increases.\label{fig:good_spectrum}}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.45 \textwidth}
		\includegraphics[width=\textwidth]{moving2.pdf}
		\caption{$\sigma(B)$ in the case $J_{1}=0$, i.e. the dynamics is only perturbed
			by $-\nu J_{2}p\mathrm{d}t$. The arrows indicate the movement of
			the eigenvalues as $\nu$ increases.\label{fig:bad_spectrum}}
	\end{subfigure}
	.	\caption{Effects of the perturbation on the spectra of $-\gen$ and $B$.}
	\label{fig:examples-introduction}
\end{figure}

\subsection{Unit covariance - large perturbations}
\label{sec:large perturbations}

In the previous subsection we observed that for the particular perturbation $J_1 = J_2$ and $\mu = \nu$, i.e. 
\begin{align}
\mathrm{d}q_{t} & =p_{t}\mathrm{d}t-\mu Jq_{t}\mathrm{d}t\nonumber \\
\mathrm{d}p_{t} & =-q_{t}\mathrm{d}t-\mu Jp_{t}\mathrm{d}t-\gamma p_{t}\mathrm{d}t+\sqrt{2\gamma}\,\mathrm{d}W_{t},\label{eq: unit covariance perfect perturbation}
\end{align}
the perturbed Langevin dynamics demonstrated an improvement in performance for $\mu$ in a neighbourhood of $0$, when the observable is linear or quadratic.  Recall that this dynamics is ergodic with respect to a standard Gaussian measure $\widehat{\pi}$ on $\mathbb{R}^{2d}$ with marginal $\pi$  with respect to the $q$--variable.  In the following we shall consider only observables that do not depend on $p$. Moreover, we assume without loss of generality that $\pi(f)=0$. For such an observable we will write $f\in L^2_0(\pi)$ and assume the canonical embedding $L^2_0(\pi)\subset L^2(\widehat{\pi})$.  The infinitesimal generator of (\ref{eq: unit covariance perfect perturbation})
is given by 
\begin{equation}
\label{eq:generator_equal}
\mathcal{L}=\underbrace{p\cdot\nabla_{q}-q\cdot\nabla_{p}+\gamma(-p\cdot\nabla_{p}+\Delta_{p})}_{\mathcal{L}_{0}}+\mu\underbrace{(-Jq\cdot\nabla_{q}-Jp\cdot\nabla_{p})}_{\mathcal{A}}=:\mathcal{L}_{0}+\mu\mathcal{A},
\end{equation}
where we have introduced the notation $\mathcal{L}_{pert}=\mu \mathcal{A}$. In the sequel, the adjoint of an operator $B$ in $L^2(\widehat{\pi})$ will be denoted by $B^{*}$. In the rest of this section we will make repeated use of the Hermite polynomials
\begin{equation}
g_{\alpha}(x)=(-1)^{\vert\alpha\vert}e^{\frac{\vert x\vert^{2}}{2}}\nabla^{\alpha}e^{-\frac{\vert x\vert^{2}}{2}},\quad\alpha\in\mathbb{N}^{2d},\label{eq: Hermite polynomials}
\end{equation}
invoking the notation $x=(q,p)\in\mathbb{R}^{2d}$. For $m\in\mathbb{N}_{0}$
define the spaces 
\[
\label{eq:Hermite spaces}
H_{m}=\Span\{g_{\alpha}:\,\vert\alpha\vert=m\},
\]
with induced scalar product 
\[
\langle f,g\rangle_{m}:=\langle f,g\rangle_{L^2(\widehat{\pi})},\quad f,g\in H_{m}.
\]
The space $(H_{m},\langle\cdot,\cdot\rangle_{m})$ is then a real Hilbert
space with (finite) dimension
\[
\dim H_{m}=\left(\begin{array}{c}
m+2d-1\\
m
\end{array}\right).
\]
The following result (Theorem \ref{thm:L2 decomposition}) holds for operators of the form
\begin{equation}
\label{eq:OU_operator}
\mathcal{L}=-Bx\cdot\nabla+\nabla^{T}Q\nabla,
\end{equation}
where the quadratic drift and diffusion matrices $B$ and $Q$ are such that $\mathcal{L}$ is the generator of an ergodic stochastic process (see \cite[Definition 2.1]{Arnold2014} for precise conditions on $B$ and $Q$ that ensure ergodicity). The generator of the SDE \eqref{eq: unit covariance perfect perturbation} is given by \eqref{eq:OU_operator} with $B$ and $Q$  as in equations \eqref{eq:drift matrix}
and \eqref{eq:diffusion matrix}, respectively.  The following result provides an orthogonal decomposition of $L^{2}(\widehat{\pi})$ into invariant subspaces of the operator $\mathcal{L}$.
\begin{theorem}{\cite[Section 5]{Arnold2014}.}
	\label{thm:L2 decomposition}The following holds:
	\begin{enumerate}[label=(\alph*)]
		\item The space $L^{2}(\widehat{\pi})$ has a decomposition into mutually orthogonal
		subspaces:
		\[
		L^{2}(\widehat{\pi})=\bigoplus_{m\in\mathbb{N}_{0}}H_{m}.
		\]
		
		\item For all $m\in\mathbb{N}_{0}$, $H_{m}$ is invariant under $\mathcal{L}$
		as well as under the semigroup $(e^{-t\mathcal{L}})_{t\ge0}$. 
		\item The spectrum of $\mathcal{L}$ has the following decomposition:
		\[
		\sigma(\mathcal{L})=\bigcup_{m\in\mathbb{N}_{0}}\sigma(\mathcal{L}\vert_{H_{m}}),
		\]
		where 
		\begin{equation}
		\sigma(\mathcal{L}\vert_{H_{m}})=\left\lbrace\sum_{j=1}^{2d}\alpha_{j}\lambda_{j}:\,\vert\alpha\vert=m,\,\lambda_{j}\in\sigma(B)\right\rbrace.\label{eq:spectrum on subspaces}
		\end{equation}
		
	\end{enumerate}
\end{theorem}
\begin{remark}
	Note that by the ergodicity of the dynamics, $\ker\mathcal{L}$ consists of constant functions and so $\ker\mathcal{L}=H_{0}$. Therefore, $L^2_0(\widehat{\pi})$ has the decomposition
	\[
	L_{0}^{2}(\widehat{\pi})=L^{2}(\widehat{\pi})/\ker\mathcal{L}=\bigoplus_{m\ge1}H_{m}.
	\]
	\end{remark}
Our first main result of this section is an expression for the asymptotic
variance in terms of the unperturbed operator $\mathcal{L}_{0}$ and
the perturbation $\mathcal{A}$:
\begin{proposition}
	\label{prop:asymvar_op_formula}
	Let $f\in L_{0}^{2}(\pi)$  (so in particular $f=f(q)$).
	Then the associated asymptotic variance is given by 
	\begin{equation}
	\label{eq:asymvar_op_formula}
	\sigma_{f}^{2}=\langle f,-\mathcal{L}_{0}(\mathcal{L}_{0}^{2}+\mu^{2}\mathcal{A}^{*}\mathcal{A})^{-1}f\rangle_{L^{2}(\widehat{\pi})}.
	\end{equation}
	
\end{proposition}
\begin{remark}
The proof of the preceding Proposition will show that $\mathcal{L}_{0}^{2}+\mu^{2}\mathcal{A}^{*}\mathcal{A}$ is invertible on $L^2_0(\widehat{\pi})$ and that $(\mathcal{L}_{0}^{2}+\mu^{2}\mathcal{A}^{*}\mathcal{A})^{-1}f \in \mathcal{D}(\mathcal{L}_0)$ for all $f \in L^2_0(\widehat{\pi})$. 
\end{remark}
To prove Proposition \ref{prop:asymvar_op_formula} we will make use of the \emph{generator
	with reversed perturbation} 
\[
\mathcal{L}_{-}=\mathcal{L}_{0}-\mu\mathcal{A}
\]
and the \emph{momentum flip operator} 
\begin{align*}
P:L_{0}^{2}(\widehat{\pi}) & \rightarrow L_{0}^{2}(\widehat{\pi})\\
\phi(q,p) & \mapsto\phi(q,-p).
\end{align*}
Clearly, $P^{2}=I$ and $P^{*}=P$. Further properties of $\mathcal{L}_{0}$,
$\mathcal{A}$ and the auxiliary operators $\mathcal{L}_{-}$ and
$P$ are gathered in the following lemma:
\begin{lemma}
	\label{operator lemma}
	For all $\phi, \psi \in C^{\infty}(\mathbb{R}^{2d})\cap L^2(\widehat{\pi})$ the following holds:
	\begin{enumerate}[label=(\alph*)]
		\item \label{it:oplem1} The generator $\mathcal{L}_{0}$ is symmetric in $L^2(\widehat{\pi})$ with respect to $P$:
		\[
		\langle  \phi, P\mathcal{L}_{0}P \psi\rangle_{L^2(\widehat{\pi})}=\langle \mathcal{L}_{0} \phi, \psi \rangle_{L^2(\widehat{\pi})}.
		\]
		
		\item \label{it:oplem2} The perturbation $\mathcal{A}$ is skewadjoint in $L^{2}(\widehat{\pi})$:
		\[ 
		\mathcal{A}^{*} = -\mathcal{A}.
		\]
		
		\item \label{it:oplem3} The operators $\mathcal{L}_{0}$ and $\mathcal{A}$ commute:
		\[
		[\mathcal{L}_{0},\mathcal{A}]\phi=0.
		\]
		
		\item \label{it:oplem4} The perturbation $\mathcal{A}$ satisfies
		\[
		P\mathcal{A}P\phi=\mathcal{A}\phi.
		\]
		
		\item \label{it:oplem5} $\mathcal{L}$ and $\mathcal{L}_{-}$ commute,
		\begin{equation*}
		[\mathcal{L},\mathcal{L}_{-}]\phi = 0,
		\end{equation*}
		
		 and the following relation holds:
		\begin{equation}
		\langle \phi ,P\mathcal{L}P\psi\rangle_{L^{2}(\widehat{\pi})}=\langle\mathcal{L}_{-}\phi,\psi\rangle_{ L^{2}(\widehat{\pi})}.\label{eq:L+L-}
		\end{equation}
		\item \label{it:oplem6} 
		The operators $\mathcal{L}$, $\mathcal{L}_0$, $\mathcal{L}_{-}$, $\mathcal{A}$ and $P$ leave the Hermite spaces $H_m$ invariant.
	\end{enumerate}
\end{lemma}
\begin{remark}
	The claim \ref{it:oplem3} in the above lemma is crucial for our approach, which
	itself rests heavily on the fact that the $q-$ and $p-$perturbations
	match ($J_{1}=J_{2}$).
\end{remark}
\begin{proof}[of Lemma \ref{operator lemma}]
	To prove \ref{it:oplem1}, consider the following
	decomposition of $\mathcal{L}_{0}$ as in (\ref{eq:generator}):
	\[
	\mathcal{L}_{0}=\underbrace{p\cdot\nabla_{q}-q\cdot\nabla_{p}}_{\mathcal{L}_{ham}}+\underbrace{\gamma\left(- p\cdot\nabla_{p}+ \Delta_{p}\right)}_{\mathcal{L}_{therm}}.
	\]
	By partial integration it is straightforward to see that 
	\begin{equation*}
	\langle\phi,\mathcal{L}_{ham}\psi\rangle_{ L^{2}(\widehat{\pi})}=-\langle\mathcal{L}_{ham}\phi,\psi\rangle_{ L^{2}(\widehat{\pi})}
	\end{equation*}
	and
	\begin{equation*}
	 \langle \phi,\mathcal{L}_{therm}\psi\rangle_{ L^{2}(\widehat{\pi})}=\langle\mathcal{L}_{therm}\phi,\psi\rangle_{ L^{2}(\widehat{\pi})},
	 \end{equation*}
	 for all $\phi,\psi \in C^{\infty}(\mathbb{R}^{2d})\cap L^2(\widehat{\pi})$,
	  i.e. $\mathcal{L}_{ham}$ and $\mathcal{L}_{therm}$
	are antisymmetric and symmetric in $L^{2}(\widehat{\pi})$ respectively.
	Furthermore, we immediately see that $P\mathcal{L}_{ham}P\phi=-\mathcal{L}_{ham}\phi$ and $P\mathcal{L}_{therm}P\phi = \mathcal{L}_{therm}\phi$, so that
	\[
	\langle \phi,P\mathcal{L}_{0}P\psi\rangle_{ L^{2}(\widehat{\pi})}=\langle\phi,-\mathcal{L}_{ham}\psi+\mathcal{L}_{therm}\psi\rangle_{ L^{2}(\widehat{\pi})}=\langle\mathcal{L}_{0}\phi,\psi\rangle_{ L^{2}(\widehat{\pi})}.
	\]
	We note that this result holds in the more general setting of Section \ref{sec:perturbed_langevin} for the infinitesimal generator \eqref{eq:generator}.  The claim \ref{it:oplem2} follows by noting that the flow vector field $b(q,p)=(-Jq,-Jp)$ associated to $\mathcal{A}$ is divergence-free with respect to $\widehat{\pi}$, i.e. $\nabla \cdot(\widehat{\pi}b)=0$. Therefore, $\mathcal{A}$ is the generator of a strongly continuous unitary semigroup on $L^2(\widehat{\pi})$ and hence skewadjoint by Stone's Theorem.
  To prove \ref{it:oplem3} we use the decomposition $\mathcal{L}_{0}=\mathcal{L}_{ham}+\mathcal{L}_{therm}$ to obtain
	\begin{equation}
	\label{eq:oplemmac_proof}
	[\mathcal{L}_{0},\mathcal{A}]\phi=[\mathcal{L}_{ham},\mathcal{A}]\phi+[\mathcal{L}_{therm},\mathcal{A}]\phi,\quad \phi \in C^\infty(\mathbb{R}^{2d})\cap L^2(\widehat{\pi}).
	\end{equation}
	The first term of \eqref{eq:oplemmac_proof} gives 
	\begin{align*}
	[p\cdot\nabla_{q}-q\cdot\nabla_{p}&,-Jq\cdot\nabla_{q} -Jp\cdot\nabla_{p}]\phi\\
	& =\big([p\cdot\nabla_{q},-Jq\cdot\nabla_{q}]+[p\cdot\nabla_{q},-Jp\cdot\nabla_{p}]+[-q\cdot\nabla_{p},-Jq\cdot\nabla_{q}] \\
	& \qquad +[-q\cdot\nabla_{p},-Jp\cdot\nabla_{p}]\big)\phi\\
	&= Jp\cdot\nabla_{q}\phi-Jp\cdot\nabla_{q}\phi+Jq\cdot\nabla_{p}\phi-Jq\cdot\nabla_{p}\phi=0.
	\end{align*}
	The second term of \eqref{eq:oplemmac_proof} gives 
	\begin{equation}
	\label{eq:term1}
	[-p\cdot\nabla_{p}+\Delta_{p},\mathcal{A}]\phi =[-p\cdot\nabla_{p},-Jp\cdot\nabla_{p}]\phi+[\Delta_{p},-Jp\cdot\nabla_{p}]\phi,
	\end{equation}
	since $Jq\cdot\nabla_{q}$ commutes with $p\cdot\nabla_{p}+\Delta_{p}$. Both  terms in \eqref{eq:term1} are clearly zero due the antisymmetry of $J$ and the symmetry of the Hessian $D^2_p \phi$. 
	\\\\
	The claim \ref{it:oplem4} follows from a short calculation similar to the proof of  \ref{it:oplem1}.  To prove \ref{it:oplem5}, note that the fact that $\mathcal{L}$ and $\mathcal{L}_{-}$ commute follows from \ref{it:oplem3}, as 
	\[
	[\mathcal{L},\mathcal{L}_{-}]\phi=[\mathcal{L}_{0}+\mu\mathcal{A},\mathcal{L}_{0}-\mu\mathcal{A}]\phi=-2\mu[\mathcal{L}_{0},\mathcal{A}]\phi=0,\quad \phi \in C^{\infty}\cap L^2(\widehat{\pi}),
	\]
	while the property $\langle \phi ,P\mathcal{L}_{0}P\psi\rangle_{L^{2}(\widehat{\pi})}=\langle\mathcal{L}_{-}\phi,\psi\rangle_{ L^{2}(\widehat{\pi})}$ follows from properties \ref{it:oplem1}, \ref{it:oplem2} and \ref{it:oplem4}. Indeed,
	\begin{subequations}
	\begin{eqnarray*}
	\langle \phi,P\mathcal{L}P\psi\rangle_{ L^{2}(\widehat{\pi})}& = & \langle \phi, P(\mathcal{L}_{0}+\mu\mathcal{A})P\psi\rangle_{ L^{2}(\widehat{\pi})}=\langle\phi,\left(P\mathcal{L}_{0}P+\mu\mathcal{A}\right)\psi\rangle_{ L^{2}(\widehat{\pi})} \\	
	 & = & \langle (\mathcal{L}_{0}-\mu\mathcal{A})\phi,\psi\rangle_{ L^{2}(\widehat{\pi})}=\langle\mathcal{L}_{-}\phi,\psi\rangle_{ L^{2}(\widehat{\pi})}, 
\end{eqnarray*}
\end{subequations}
	as required. To prove \ref{it:oplem6} first notice that $\mathcal{L}$, $\mathcal{L}_0$ and $\mathcal{L}_{-}$ are of the form \eqref{eq:OU_operator} and therefore leave the spaces $H_m$ invariant by Theorem \ref{thm:L2 decomposition}. It follows immediately that also $\mathcal{A}$ leaves those spaces invariant. The fact that $P$ leaves the spaces $H_m$ invariant follows directly by inspection of \eqref{eq: Hermite polynomials}.
	\qed
\end{proof}
Now we proceed with the proof of Proposition  \ref{prop:asymvar_op_formula}:
\begin{proof}[of Proposition \ref{prop:asymvar_op_formula}] Since the potential $V$ is quadratic, Assumption \ref{ass:bounded+Poincare} clearly holds and thus Lemma \ref{lemma:variance} ensures that $\mathcal{L}$ and $\mathcal{L}_{-}$ are invertible on $L^2_{0}(\widehat{\pi})$ with 
\begin{equation}
\label{eq:Laplace transform}
\mathcal{L}^{-1}=\int_0^\infty e^{-t\mathcal{L}}\mathrm{d}t,
\end{equation}
	and analogously for $\mathcal{L}_{-}^{-1}$.
	 In particular, the asymptotic variance can be written as 
	 \begin{equation*}
	 \sigma_{f}^{2}=\langle f,(-\mathcal{L})^{-1}f\rangle_{L^{2}(\widehat{\pi})}.
	 \end{equation*}
	  Due to the respresentation \eqref{eq:Laplace transform} and Theorem \ref{thm:L2 decomposition}, the inverses of $\mathcal{L}$ and $\mathcal{L}_{-}$ leave the Hermite spaces $H_m$ invariant. We will prove the claim from Proposition \ref{prop:asymvar_op_formula} under the assumption that $Pf=f$ which includes the case 
	$f=f(q)$. For the following calculations we will assume $f\in H_m$ for fixed $m \ge 1$. Combining statement \ref{it:oplem6} with \ref{it:oplem1} and \ref{it:oplem5} of Lemma \ref{operator lemma} (and noting that $H_m \subset C^\infty(\mathbb{R}^{2d})\cap L^2(\widehat{\pi})$) we see that 
	\begin{equation}
	\label{eq:PLPL-}
	P\mathcal{L}P=\mathcal{L}_{-}^{*}
	\end{equation}
	 and 
	 \begin{equation}
	 P\mathcal{L}_{0}P=\mathcal{L}_{0}^{*}
	 \end{equation}
	  when restricted to $H_m$. Therefore, the following calculations are justified:
	\begin{align*}
	\langle f,(-\mathcal{L})^{-1}f\rangle_{L^{2}(\widehat{\pi})} &=\frac{1}{2}\langle f,(-\mathcal{L})^{-1}f\rangle_{L^{2}(\widehat{\pi})}+\langle f,(-\mathcal{L}^{*})^{-1}f\rangle_{L^{2}(\widehat{\pi})}\\
	&=\frac{1}{2}\langle f,(-\mathcal{L})^{-1}f\rangle_{L^{2}(\widehat{\pi})}+\langle Pf,(-\mathcal{L}^{*})^{-1}Pf\rangle_{L^{2}(\widehat{\pi})}\\
	&=\frac{1}{2}\langle f,(-\mathcal{L})^{-1}f\rangle_{L^{2}(\widehat{\pi})}+\langle f,(-\mathcal{L}_{-})^{-1}f\rangle_{L^{2}(\widehat{\pi})}\\
	&=\frac{1}{2}\langle f,\left((-\mathcal{L})^{-1}+(-\mathcal{L}_{-})^{-1}\right)f\rangle_{L^{2}(\widehat{\pi})},
	\end{align*}
	where in the third line we have used the assumption $Pf=f$ and in
	the fourth line the properties $P^{2}=I$, $P^{*}=P$ and equation
	(\ref{eq:PLPL-}).   Since $\mathcal{L}$ and $\mathcal{L}_{-}$ commute on $H_m$ according to Lemma
	\ref{operator lemma}\ref{it:oplem5},\ref{it:oplem6} we can write
	\begin{equation*}
	(-\mathcal{L})^{-1}+(-\mathcal{L}_{-})^{-1}  =\mathcal{L}_{-}(-\mathcal{L}\mathcal{L}_{-})^{-1}+\mathcal{L}(-\mathcal{L}\mathcal{L}_{-})^{-1}
	=-2\mathcal{L}_{0}(\mathcal{L}\mathcal{L}_{-})^{-1}
	\end{equation*}
	for the restrictions on $H_m$, 
	using $\mathcal{L}+\mathcal{L}_{-}=2\mathcal{L}_{0}$. We also have
	\begin{alignat*}{1}
	\mathcal{L}\mathcal{L}_{-} & =(\mathcal{L}_{0}+\mu\mathcal{A})(\mathcal{L}_{0}-\mu\mathcal{A}) =\mathcal{L}_{0}^{2}+\mu^{2}\mathcal{A}^{*}\mathcal{A},
	\end{alignat*}
	since $\mathcal{L}_{0}$ and $\mathcal{A}$ commute. We thus arrive at the formula
	\begin{equation}
	\label{eq:av_formula_Hm}
	\sigma_{f}^{2}=\langle f,-\mathcal{L}_{0}(\mathcal{L}_{0}^{2}+\mu^{2}\mathcal{A}^{*}\mathcal{A})^{-1}f\rangle_{L^{2}(\widehat{\pi})}, \quad f\in H_m.
	\end{equation}
	Now since $(\mathcal{L}_{0}^{2}+\mu^{2}\mathcal{A}^{*}\mathcal{A})^{-1}f = (\mathcal{L}\mathcal{L}_{-})^{-1}f \in \mathcal{D}(\mathcal{L}_{0})$ for all $f\in L^2(\widehat{\pi})$, it follows that the operator $-\mathcal{L}_{0}(\mathcal{L}_{0}^{2}+\mu^{2}\mathcal{A}^{*}\mathcal{A})^{-1}$ is bounded. We can therefore extend formula \eqref{eq:av_formula_Hm} to the whole of $L^2(\widehat{\pi})$ by continuity, using the fact that $L^2_0(\widehat{\pi})=\bigoplus_{m\ge 1}H_m$. 
	\qed
\end{proof}
Applying Proposition \ref{prop:asymvar_op_formula} we can analyse the behaviour
of $\sigma_{f}^{2}$ in the limit of large perturbation strength $\mu\rightarrow\infty$.
To this end, we introduce the orthogonal decomposition
\begin{equation}
\label{eq:kernel decomposition}
L_{0}^{2}(\pi)=\ker (Jq\cdot \nabla_q) \oplus\ker (Jq\cdot \nabla_q)^{\perp},
\end{equation}
where $Jq\cdot\nabla_q$ is understood as an unbounded operator acting on $L_0^2(\pi)$, obtained as the smallest closed extension of $Jq\cdot \nabla_q$ acting on $C^{\infty}_c(\mathbb{R}^d)$. In particular, $\ker (Jq\cdot \nabla_q)$ is a closed linear subspace of $L^2_0(\pi)$.   
Let $\Pi$ denote the $L_{0}^{2}(\pi)$-orthogonal projection onto
$\ker (Jq\cdot \nabla_q)$. We will write $\sigma_{f}^{2}(\mu)$ to
stress the dependence of the asymptotic variance on the perturbation
strength. The following result shows that for large perturbations,
the limiting asymptotic variance is always smaller than the asymptotic
variance in the unperturbed case. Furthermore, the limit is given as
the asymptotic variance of the projected observable $\Pi f$ for the
unperturbed dynamics.
\begin{theorem}
	\label{prop:large pert}
	Let $f\in L_{0}^{2}(\pi)$, then
	\[
	\lim_{\mu\rightarrow\infty}\sigma_{f}^{2}(\mu)=\sigma_{\Pi f}^{2}(0)\le\sigma_{f}^{2}(0).
	\]
\end{theorem}
\begin{remark}
	Note that the fact that the limit exists and is finite is nontrivial.
	In particular, as Figures \ref{fig:no_limit1} and \ref{fig:no_limit2} demonstrate, it is often
	the case that $\lim_{\mu\rightarrow\infty}\sigma_{f}^{2}(\mu)=\infty$
	if the condition $\mu=\nu$ is not satisfied.
\end{remark}
\begin{remark}
	\label{rem:projection}
	The projection $\Pi$ onto $\ker(Jq\cdot\nabla_q)$ can be understood in terms of Figure \ref{fig:good_spectrum}. Indeed, the eigenvalues on the real axis (highlighted by diamonds) are not affected by the perturbations. Let us denote by $\tilde{\Pi}$ the projection onto the span of the eigenspaces of those eigenvalues. As $\mu \rightarrow \infty$, the limiting asymptotic  variance is given as the asymptotic variance associated to the unperturbed dynamics of the projection $\tilde{\Pi}f$. If we denote by $\Pi_0$ the projection of $L^2(\widehat{\pi})$ onto $L^2_0(\pi)$, then we have that $\Pi\Pi_0=\Pi_0\tilde{\Pi}$. 
\end{remark}
\begin{proof}[of Theorem \ref{prop:large pert}]
	Note that $\mathcal{L}_{0}$ and $\mathcal{A}^{*}\mathcal{A}$ leave the Hermite spaces $H_m$ invariant and their restrictions to those spaces commute 
	(see Lemma \ref{operator lemma}, \ref{it:oplem2}, \ref{it:oplem3} and \ref{it:oplem6}). Furthermore, as the Hermite spaces $H_m$ are finite-dimensional, those operators have discrete spectrum. As $\mathcal{A}^{*}\mathcal{A}$
	is nonnegative self-adjoint, there exists an orthogonal
	decomposition $L_{0}^{2}(\pi)=\bigoplus_{i}W_{i}$  into eigenspaces of the operator $-\mathcal{L}_{0}(\mathcal{L}_{0}^{2}+\mu^{2}\mathcal{A}^{*}\mathcal{A})^{-1}$,
	the decomposition $\bigoplus W_i$ being finer then $\bigoplus H_m$ in the sense that every $W_i$ is a subspace of some $H_m$. 
	 Moreover,
	\[
	-\mathcal{L}_{0}(\mathcal{L}_{0}^{2}+\mu^{2}\mathcal{A}^{*}\mathcal{A})^{-1}\vert_{W_{i}}=-\mathcal{L}_{0}(\mathcal{L}_{0}^{2}+\mu^{2}\lambda_{i})^{-1}\vert_{W_i},
	\]
	where $\lambda_{i}\ge0$ is the eigenvalue of $\mathcal{A}^{*}\mathcal{A}$
	associated to the subspace $W_{i}$. Consequently, formula (\ref{eq:asymvar_op_formula})
	can be written as 
	\begin{equation}
	\label{eq:asymvar_spectral}
	\sigma_{f}^{2}=\sum_{i}\langle f_{i},-\mathcal{L}_{0}(\mathcal{L}_{0}^{2}+\mu^{2}\lambda_{i})^{-1}f_{i}\rangle_{L^{2}(\widehat{\pi})},
	\end{equation}
	where $f=\sum_{i}f_{i}$ and $f_{i}\in W_{i}$. Let us assume now
	without loss of generality that $W_{0}=\ker\mathcal{A}^{*}\mathcal{A}$,
	so in particular $\lambda_{0}=0$. Then clearly 
	\[
	\lim_{\mu\rightarrow\infty}\sigma_{f}^{2}=2\langle f_{0},-\mathcal{L}_{0}(\mathcal{L}_{0}^{2})^{-1}f_{0}\rangle_{L^{2}(\widehat{\pi})}=2\langle f_{0},(-\mathcal{L}_{0})^{-1}f_{0}\rangle_{L^{2}(\widehat{\pi})}=\sigma_{f_{0}}^{2}(0).
	\]
	Now note that $W_{0}=\ker\mathcal{A}^{*}\mathcal{A}=\ker\mathcal{A}$ due
	to $\ker\mathcal{A}^{*}=(\im\mathcal{A})^{\perp}$.  It remains to show that  $\sigma_{\Pi f}^{2}(0)\le\sigma_{f}^{2}(0)$.  To see this, we write 
	\begin{align*}
	\sigma_{f}^{2}(0) & =2\langle f,(-\mathcal{L}_{0})^{-1}f\rangle_{L^{2}(\widehat{\pi})}=2\langle\Pi f+(1-\Pi)f,(-\mathcal{L}_{0})^{-1}\big(\Pi f+(1-\Pi)f\big)\rangle_{L^{2}(\widehat{\pi})}\\
	& =\sigma_{\Pi f}^{2}(0)+\sigma_{(1-\Pi)f}^{2}(0)+R,
	\end{align*}
	where 
	\[
	R=2\langle\Pi f,(-\mathcal{L}_{0})^{-1}(1-\Pi)f\rangle_{L^{2}(\widehat{\pi})}+2\langle(1-\Pi)f,(-\mathcal{L}_{0})^{-1}\Pi f\rangle_{L^{2}(\widehat{\pi})}.
	\]
	Note that since we only consider observables that do not depend on $p$, $\Pi f\in \ker (Jq\cdot \nabla_q)$ and $(1-\Pi)f\in\bigoplus_{i\ge1}W_{i}$.
	Since $\mathcal{L}_{0}$ commutes with $\mathcal{A}$, it follows
	that $(-\mathcal{L}_{0})^{-1}$ leaves both $W_{0}$ and $\bigoplus_{i\ge1}W_{i}$
	invariant. Therefore, as the latter spaces are orthogonal to each
	other, it follows that $R=0$, from which the result follows. 
	\qed
\end{proof}
From Theorem \ref{prop:large pert} it follows that in the limit as $\mu \rightarrow \infty$, the asymptotic variance $\sigma_f^2(\mu)$ is not decreased by the perturbation if $f \in \ker(Jq \cdot \nabla_q)$. In fact, this result also holds true non-asymptotically, i.e. observables in $\ker(Jq \cdot \nabla_q)$ are not affected at all by the perturbation:
\begin{lemma}
	\label{lem:invariant observables}
	Let $f\in \ker (Jq\cdot \nabla_q)$. Then
	\begin{equation*}
	\sigma^2_f(\mu) = \sigma^2_f(0)
	\end{equation*}
	for all $\mu \in \mathbb{R}$.
\end{lemma}
\begin{proof}
	From $f \in  \ker (Jq\cdot \nabla_q)$ it follows immediately that $f \in \ker \mathcal{A}^{*}\mathcal{A}$. Then the claim follows from the expression \eqref{eq:asymvar_spectral}.
	\qed
\end{proof}
\begin{example}
	\label{ex:commutation quadratic observables}
	Recall the case of observables of the form $f(q)=q\cdot Kq+l\cdot q+C$
	with $K\in\mathbb{R}_{sym}^{d\times d}$, $l\in\mathbb{R}^{d}$ and
	$C\in\mathbb{R}$ from Section \ref{sec:small perturbations}. If $[J,K]=0$
	and $l\in\ker J$, then $f\in\ker (Jq\cdot \nabla_q)$ as 
	\[
	Jq\cdot\nabla_{q}(q\cdot Kq+l\cdot q+C)=2Jq\cdot Kq+Jq\cdot l=q\cdot(KJ-JK)q-q\cdot Jl=0.
	\]
	From the preceding lemma it follows that $\sigma_{f}^{2}(\mu)=\sigma_{f}^{2}(0)$
	for all $\mu\in\mathbb{R},$ showing that the assumption in Theorem
	\ref{cor:small pert unit var} does not exclude nontrivial cases.
\end{example}
The following result shows that the dynamics (\ref{eq: unit covariance perfect perturbation})
is particularly effective for antisymmetric observables (at least
in the limit of large perturbations):
\begin{proposition}
	\label{prop:antisymmetric observables}Let $f\in L_{0}^{2}(\pi)$
	satisfy $f(-q)=-f(q)$ and assume that $\ker J=\{0\}$.
	Furthermore, assume that the eigenvalues of $J$ are rationally independent, i.e. 
	\begin{equation}
	\label{eq:rat_indp_spectrum}
	\sigma(J)=\{\pm i\lambda_{1},\pm i\lambda_{2},\ldots,\pm i\lambda_d\}
	\end{equation}
	with $\lambda_{i}\in\mathbb{R}_{>0}$ and  $\sum_i k_i \lambda_i \neq 0$ for all $(k_1,\ldots,k_d)\in\mathbb{Z}^d\setminus(0,\ldots,0)$. Then $\lim_{\mu\rightarrow\infty}\sigma_{f}^{2}(\mu)=0$.
\end{proposition} 
\begin{proof}
	[of Proposition \ref{prop:antisymmetric observables}]
	The claim would
	immediately follow from $f\in\ker(Jq\cdot\nabla)^{\perp}$ according to Theorem \ref{prop:large pert}, but that does not seem to be so easy to prove directly. Instead, we again make
	use of the Hermite polynomials.
	
	Recall from the proof of Proposition \ref{prop:asymvar_op_formula} that $\gen$ is invertible on $L_{0}^{2}(\widehat{\pi})$ and its inverse leaves the Hermite spaces $H_m$ invariant. Consequently, the
	asymptotic variance of an observable $f\in L_{0}^{2}(\widehat{\pi})$ can be written as  
	\begin{subequations}
	\begin{eqnarray}
	\sigma_{f}^{2} & = & \langle f,(-\mathcal{L})^{-1}f\rangle_{L^{2}(\widehat{\pi})} \\
	& = & \sum_{m=1}^{\infty}\langle\Pi_{m}f,(-\mathcal{L}\vert_{H_{m}})^{-1}\Pi_{m}f\rangle_{L^2(\widehat{\pi})},\label{eq:asymvar decomposition} 
	\end{eqnarray}
	\end{subequations}
	where $\Pi_{m}:L_{0}^{2}(\widehat{\pi})\rightarrow H_{m}$ denotes the orthogonal
	projection onto $H_{m}$. From (\ref{eq: Hermite polynomials}) it
	is clear that $g_{a}$ is symmetric for $\vert\alpha\vert$ even and
	antisymmetric for $\vert\alpha\vert$ odd. Therefore, from $f$ being
	antisymmetric it follows that 
	\[
	f\in\bigoplus_{m\ge1,m\,\text{odd}}H_{m}.
	\]
	In view of (\ref{eq:spectrum of B}), (\ref{eq:spectrum on subspaces}) and (\ref{eq:rat_indp_spectrum})
	the spectrum of $\mathcal{L}_{\vert H_{m}}$ can be written as 
	\begin{subequations}
	\begin{eqnarray}
	\sigma(\mathcal{L}\vert_{H_{m}}) & = &\left\lbrace \mu\sum_{j=1}^{2d}\alpha_{j}\beta_{j}+C_{\alpha,\gamma}:\,\vert\alpha\vert=m,\,\beta_{j}\in\sigma(J)\right\rbrace  \nonumber \\
	& = & \left\lbrace i\mu\sum_{j=1}^{d}(\alpha_{j}-\alpha_{j+d})\lambda_{j}+C_{\alpha,\gamma}:\,\vert\alpha\vert=m\right\rbrace  \label{eq:spec_grow}
	\end{eqnarray}
	\end{subequations}
	with appropriate real constants $C_{\alpha,\gamma}\in\mathbb{R}$ that depend
	on $\alpha$ and $\gamma$, but not on $\mu$. For $\vert\alpha\vert=\sum_{j=1}^{2d} \alpha_j=m$ odd, we have that
	\begin{equation}
	\label{eq:nonzero}
	\sum_{j=1}^{d}(\alpha_{j}-\alpha_{j+d})\lambda_{j} \neq 0.
	\end{equation}
	Indeed, assume to the contrary that the above expression is zero. Then it follows that $\alpha_j = \alpha_{j+d}$ for all $j=1,\ldots,d$ by rational independence of $\lambda_1,\ldots,\lambda_d$.
	From \eqref{eq:spec_grow} and \eqref{eq:nonzero} it is clear that
	\begin{equation*}
	\sup \left\lbrace r>0 : B(0,r) \cap \sigma(\mathcal{L}\vert_{H_m}) = \emptyset \right\rbrace \xrightarrow{\mu \rightarrow \infty} \infty,
	\end{equation*}
	where $B(0,r)$ denotes the ball of radius $r$ centered at the origin in $\mathbb{C}$.
	Consequently, the spectral radius of $(-\mathcal{L}\vert_{H_m})^{-1}$ and hence $(-\mathcal{L}\vert_{H_m})^{-1}$ itself converge to zero as $\mu \rightarrow \infty$. The result then follows from (\ref{eq:asymvar decomposition}). \qed\end{proof}
\begin{remark}
	The idea of the preceding proof can be explained using Figure \ref{fig:good_spectrum} and Remark \ref{rem:projection}. Since the real eigenvalues correspond to Hermite polynomials of even order, antisymmetric observables are orthogonal to the associated subspaces. The rational independence condition on the eigenvalues of $J$ prevents cancellations  that would lead to further eigenvalues on the real axis.
\end{remark}
The following corollary gives a version of the converse of Proposition \ref{prop:antisymmetric observables} and provides further intuition into the mechanics of the variance reduction achieved by the perturbation.
\begin{corollary}
	Let $f\in L_{0}^{2}(\pi)$ and assume that $lim_{\mu\rightarrow\infty}\sigma_{f}^{2}(\mu)=0$. Then 
	\[
	\int_{B(0,r)}f\mathrm{dq=0}
	\]
	for all $r\in(0,\infty)$, where $B(0,r)$ denotes the ball centered at $0$ with radius $r$.
\end{corollary}
\begin{proof}
	According to Theorem \ref{prop:large pert},  $\lim_{\mu\rightarrow\infty}\sigma_{f}^{2}(\mu)=0$  implies $\sigma_{\Pi f}^{2}(0)=0$. We can write 
	\begin{subequations}
	\begin{eqnarray}
	\sigma_{\Pi f}^{2}(0) & = & \langle \Pi f, (-\mathcal{L}_0)^{-1}\Pi f \rangle_{ L^{2}(\widehat{\pi})} \nonumber \\
	& = & \frac{1}{2}\langle \Pi f, \left((-\mathcal{L}_0)^{-1}+(-\mathcal{L}^{*}_0)^{-1}\right)\Pi f \rangle_{ L^{2}(\widehat{\pi})} \nonumber
	\end{eqnarray}
	\end{subequations}
	and recall from the proof of Proposition \ref{prop:asymvar_op_formula} that $(-\mathcal{L}_0)^{-1}$ and $(-\mathcal{L}^{*}_0)^{-1}$ leave the Hermite spaces $H_m$ invariant. Therefore  
	\begin{equation}
	\ker \left((-\mathcal{L}_0)^{-1}+(-\mathcal{L}^{*}_0)^{-1}\right) = {0}
	\end{equation}
	in $L^2_0(\widehat{\pi})$, and in particular $\sigma_{\Pi f}^{2}(0)=0$ implies $\Pi f = 0$, which in turn shows that
	  $f\in\ker(Jq\cdot\nabla)^{\perp}$. Using $\ker(Jq\cdot\nabla)^{\perp}=\overline{\im(Jq\cdot\nabla)}$,
	it follows that there exists a sequence $(\phi_n)_n\in C_c^{\infty}(\mathbb{R}^d)$ such that $Jq\cdot\nabla\phi_n \rightarrow f$ in $L^2(\pi)$. Taking a subsequence if necessary, we can assume that the convergence is pointwise $\pi$-almost everywhere and that the sequence is pointwise bounded by a function in $L^1(\pi)$. 
	Since $J$ is antisymmetric, we have that $Jq\cdot\nabla\phi_n=\nabla\cdot(\phi_n Jq)$.
	Now Gauss's theorem yields
	\[
	\int_{B(0,r)}f\mathrm{d}q=\int_{B(0,r)}\nabla\cdot(\phi Jq)\mathrm{d}q=\int_{\partial B(0,r)}\phi Jq\cdot\mathrm{d}n,
	\]
	where $n$ denotes
	the outward normal to the sphere $\partial B(0,r)$. This quantity
	is zero due to the orthogonality of $Jq$ and $n$, and so the result
	follows from Lebesgue's dominated convergence theorem.\qed
\end{proof}
\subsection{Optimal Choices of $J$ for Quadratic Observables}

Assume $f\in L_{0}^{2}(\pi)$ is given by $f(q)=q\cdot Kq+l\cdot q -\Tr K$,  with $K\in\mathbb{R}_{sym}^{d\times d}$ and $l\in\mathbb{R}^{d}$ (note that the constant term is chosen such that $ \pi(f)=0 $). Our objective is to choose $J$ in such a way that $\lim_{\mu\rightarrow\infty}\sigma_{f}^{2}(\mu)$ becomes as small as possible. To stress the dependence on the choice
of $J$, we introduce the notation $\sigma_{f}^{2}(\mu,J)$. Also, we denote the orthogonal projection onto $(\ker J)^{\perp}$ by $\Pi^{\perp}_{\ker J}$.
\begin{lemma}
	\label{lem:lin_observables}{(Zero variance limit for linear observables).} Assume $K=0$ and $\Pi^{\perp}_{\ker J}l=0$. Then 
	\[
	\lim_{\mu\rightarrow\infty}\sigma_{f}^{2}(\mu,J)=0.
	\]
\end{lemma}
\begin{proof}
	According to Proposition \ref{prop:large pert}, we have to show that
	$\Pi f=0$, where $\Pi$ is the $L^{2}(\pi)$-orthogonal projection
	onto $\ker(Jq\cdot\nabla)$. Let us thus prove that 
	\[
	f\in\ker(Jq\cdot\nabla)^{\perp}=\overline{\im(Jq\cdot\nabla)^{*}}=\overline{\im(Jq\cdot\nabla)},
	\]
	where the second identity uses the fact that $(Jq\cdot\nabla)^{*}=-Jq\cdot\nabla$.
	Indeed, since $\Pi^{\perp}_{\ker J}=0$, by Fredholm's alternative there exists $u \in \mathbb{R}^d$ such that $Ju=l$. Now define $\phi\in L_{0}^{2}(\pi)$
	by $\phi(q)=-u\cdot q,$ leading to 
	\[
	f=Jq\cdot\nabla\phi,
	\]
	so the result follows.\qed
\end{proof}

\begin{lemma}
	\label{lem:optimal_perturbation}{(Zero variance limit for purely quadratic observables.)} Let $l=0$ and consider the decomposition $K=K_{0}+K_{1}$ into the traceless part $K_{0}=K-\frac{\Tr K}{d}\cdot I$ and the
	trace-part $K_{1}=\frac{\Tr K}{d}\cdot I.$ For the corresponding
	decomposition of the observable 
	\[
	f(q)=f_{0}(q)+f_{1}(q)=q\cdot K_{0}q+q\cdot K_{1}q-\Tr K
	\]
	the following holds:
	\begin{enumerate}[label=(\alph*)]
		\item There exists an antisymmetric matrix $J$ such that  $\lim_{\mu\rightarrow\infty}\sigma_{f_{0}}^{2}(\mu,J)=0,$
		and there is an algorithmic way (see Algorithm \ref{alg:optimal J}) to compute an appropriate $J$ in terms
		of $K$.
		\item The trace-part is not effected by the perturbation, i.e. $\sigma_{f_{1}}^{2}(\mu,J)=\sigma_{f_{1}}^{2}(0)$ for all $\mu\in\mathbb{R}$.
	\end{enumerate}
\end{lemma}
\begin{proof}
	To prove the first claim, according to Theorem \ref{prop:large pert}
	it is sufficient to show that $f_{0}\in\ker(Jq\cdot\nabla)^{\perp}=\overline{\im(Jq\cdot\nabla)}$.
	Let us consider the function $\phi(q)=q\cdot Aq$, with $A\in\mathbb{R}_{sym}^{d\times d}$. It holds that
	\begin{equation*}
	Jq\cdot\nabla\phi=q\cdot(J^{T}Aq)=q\cdot[A,J]q.
	\end{equation*}
	The task of finding an antisymmetric matrix $J$ such that 
	\begin{equation}
	\label{eq:quad_var_reduction}
	\lim_{\mu\rightarrow\infty}\sigma_{f_{0}}^{2}(\mu,J)=0
	\end{equation}
	can therefore be accomplished by constructing an antisymmetric matrix
	$J$ such that there exists a symmetric matrix $A$ with the property
	$K_{0}=[A,J]$.  Given any traceless matrix $K_{0}$ there exists
	an orthogonal matrix $U\in O(\mathbb{R}^{d})$ such that $UK_{0}U^{T}$
	has zero entries on the diagonal, and that $U$ can be obtained in
	an algorithmic manner (see for example \cite{alg_zero_diag} or \cite[Chapter 2, Section 2, Problem 3]{Horn_Johnson_Matrix_Analysis}; for the reader's convenience we have summarised the algorithm in Appendix \ref{tracefree}.) Assume
	thus that such a matrix $U\in O(\mathbb{R}^{d})$ has been found and choose real numbers $a_1,\ldots,a_d \in \mathbb{R}$ such that $a_{i}\neq a_{j}$ if $i\neq j$.
	We now set
	\begin{equation}
	\bar{A}=\diag(a_{1},\ldots,a_{n}),
	\end{equation}
	and 
	\begin{equation}
	\bar{J}_{ij}= 
	\begin{cases}
	\frac{(UK_{0}U^{T})_{ij}}{a_{i}-a_{j}} & \text{if } i\neq j, \\
	0 & \text{if } i=j. \\ 
	\end{cases}
	\end{equation}
	Observe that since $UK_{0}U^{T}$ is symmetric, $\bar{J}$ is antisymmetric. 
	A short calculation shows that $[\bar{A},\bar{J}]= UK_{0}U^{T}$.
	We can thus define $A=U^{T}\bar{A}U$ and $J=U^{T}\bar{J}U$ to obtain $[A,J]=K_0$. Therefore, the $J$ constructed in this way indeed satisfies \eqref{eq:quad_var_reduction}.  For the second claim, note that $f_{1}\in\ker(Jq\cdot\nabla)$, since
	\begin{equation}
	\label{eq:constant_trace}
	Jq\cdot\nabla\left(q\cdot\frac{\Tr K}{d}q\right)=2\frac{\Tr K}{d}q\cdot Jq=0
	\end{equation}
	because of the antisymmetry of $J$. The result then follows from
	Lemma \ref{lem:invariant observables}.\qed
\end{proof}
We would like to stress that the perturbation $J$ constructed in the previous lemma is far from unique due to the freedom of choice of $U$ and $a_1,\ldots,a_d \in \mathbb{R}$ in its proof. However, it is asymptotically optimal:
\begin{corollary}
	\label{cor:optimality}
	In the setting of Lemma \ref{lem:optimal_perturbation} the following holds:
	\[
	\min_{J^T=-J}\left(\lim_{\mu\rightarrow\infty} \sigma^2_{f}(\mu,J)\right)=\sigma^2_{f_1}(0).
	\]
\end{corollary}
\begin{proof}
	The claim follows immediately since $f_{1}\in\ker(Jq\cdot\nabla)$ for arbitrary antisymmetric $J$ as shown in \eqref{eq:constant_trace}, and therefore the contribution of the trace part $f_1$ to the asymptotic variance cannot be reduced by any choice of $J$ according to Lemma \ref{lem:invariant observables}.	
\end{proof}
As the proof of Lemma \ref{lem:optimal_perturbation} is constructive, we obtain the following algorithm for determining optimal perturbations for quadratic observables:
\begin{algorithm}
	\label{alg:optimal J}
	Given $K\in\mathbb{R}_{sym}^{d\times d}$,
	determine an optimal antisymmetric perturbation $J$ as follows:
	\begin{enumerate}
		\item Set $K_{0}=K-\frac{\Tr K}{d}\cdot I.$
		\item Find $U\in O(\mathbb{R}^{d})$ such that $UK_{0}U^{T}$ has zero entries
		on the diagonal (see Appendix \ref{tracefree}).
		\item Choose $a_{i}\in\mathbb{R},$ $i=1,\ldots d$ such that $a_{i}\neq a_{j}$
		for $i\neq j$ and set 
		\[
		\bar{J}_{ij}=\frac{(UK_{0}U^{T})_{ij}}{a_{i}-a_{j}}
		\]
		for $i\ne j$ and $\bar{J}_{ii}=0$ otherwise.
		\item
		Set $J=U^{T}\bar{J}U$.
	\end{enumerate}
\end{algorithm}
\begin{remark}
	In \cite{duncan2016variance}, the authors consider the task of finding optimal perturbations $J$ for the nonreversible overdamped Langevin dynamics given in \eqref{eq:nonrev_overdamped_J}. In the Gaussian case this optimization problem turns out be equivalent to the one considered in this section. Indeed, equation (39) of \cite{duncan2016variance} can be rephrased as 
	\begin{equation*}
	f \in \ker(Jq\cdot \nabla)^{\perp}.
	\end{equation*}
	Therefore, Algorithm \ref{alg:optimal J} and its generalization Algorithm \ref{alg:optimal J general} (described in Section~\ref{sec:arbitrary covariance})  can be used without modifications to find optimal perturbations of overdamped Langevin dynamics.
\end{remark}

\subsection{Gaussians with Arbitrary Covariance and Preconditioning}
\label{sec:arbitrary covariance}

In this section we  extend the results of the preceding sections to the case
when the target measure $\pi$ is given by a Gaussian with arbitrary
covariance, i.e. $V(q)=\frac{1}{2}q\cdot Sq$ with $S\in\mathbb{R}_{sym}^{d\times d}$ symmetric and positive definite. The
dynamics (\ref{eq:perturbed_underdamped}) then takes the
form 

\begin{align}
\mathrm{d}q_{t} & =M^{-1}p_{t}\mathrm{d}t-\mu J_{1}Sq_{t}\mathrm{d}t\nonumber, \\
\mathrm{d}p_{t} & =-Sq_{t}\mathrm{d}t-\nu J_{2}M^{-1}p_{t}\mathrm{d}t-\Gamma M^{-1}p_{t}\mathrm{d}t+\sqrt{2\Gamma}\mathrm{d}W_{t}.\label{eq:Underdamped Langevin Gaussian}
\end{align}
The key observation is now that the choices $M=S$ and $\Gamma=\gamma S$
together with the transformation $\widetilde{q}=S^{1/2}q$ and $\widetilde{p}=S^{-1/2}p$
lead to the dynamics
\begin{align}
\mathrm{d}\widetilde{q}_{t} & =\widetilde{p}_{t}\mathrm{d}t-\mu S^{1/2}J_{1}S^{1/2}\widetilde{q}_{t}\mathrm{d}t,\nonumber \\
\mathrm{d}\widetilde{p}_{t} & =-\widetilde{q}_{t}\mathrm{d}t-\mu S^{-1/2}J_{2}S^{-1/2}\widetilde{p}_{t}\mathrm{d}t-\gamma\widetilde{p}_{t}\mathrm{d}t+\sqrt{2\gamma}\mathrm{d}W_{t},\label{eq:Underdamped Langevin transformed}
\end{align}
which is of the form (\ref{eq:unit covariance}) if $J_{1}$ and
$J_{2}$ obey the condition $SJ_{1}S=J_{2}$ (note that both $S^{1/2}J_{1}S^{1/2}$
and $S^{-1/2}J_{2}S^{-1/2}$ are of course antisymmetric). Clearly
the dynamics (\ref{eq:Underdamped Langevin transformed}) is ergodic
with respect to a Gaussian measure with unit covariance, in the following
denoted by $\widetilde{\pi}$. The connection between the asymptotic variances
associated to (\ref{eq:Underdamped Langevin Gaussian}) and (\ref{eq:Underdamped Langevin transformed})
is as follows: 
\\\\
For an observable $f\in L_{0}^{2}(\pi)$ we can write 
\[
\sqrt{T}\bigg(\frac{1}{T}\int_{0}^{T}f(q_{s})\mathrm{d}s-\pi(f)\bigg)=\sqrt{T}\bigg(\frac{1}{T}\int_{0}^{T}\widetilde{f}(\widetilde{q}_{s})\mathrm{d}s-\widetilde{\pi}(\widetilde{f})\bigg),
\]
where $\widetilde{f}(q)=f(S^{-1/2}q)$. Therefore, the asymptotic variances
satisfy
\begin{equation}
\sigma_{f}^{2}=\widetilde{\sigma}_{\widetilde{f}}^{2},\label{eq:asymvar transform}
\end{equation}
where $\widetilde{\sigma}_{\widetilde{f}}^{2}$ denotes the asymptotic variance
of the process $(\widetilde{q}_{t})_{t\ge0}$. Because of this, the results
from the previous sections generalise to (\ref{eq:Underdamped Langevin Gaussian}),
subject to the condition that the choices $M=S$, $\Gamma=\gamma S$
and $SJ_{1}S=J_{2}$ are made. We formulate our results in this general
setting as corollaries:
\begin{corollary}
	\label{cor:small_pert_general}
	Consider the dynamics 
	\begin{align}
	\mathrm{d}q_{t} & =M^{-1}p_{t}\mathrm{d}t-\mu J_{1}\nabla V(q_{t})\mathrm{d}t,\nonumber \\
	\mathrm{d}p_{t} & =-\nabla V(q_{t})\mathrm{d}t-\mu J_{2}M^{-1}p_{t}\mathrm{d}t-\Gamma M^{-1}p_{t}\mathrm{d}t+\sqrt{2\Gamma}\mathrm{d}W_{t},\label{eq: perturbed Langevin corollary}
	\end{align}
	with $V(q)=\frac{1}{2}q\cdot Sq$. Assume that $M=S$, $\Gamma=\gamma S$
	with $\gamma > \sqrt{2}$ and $SJ_{1}S=J_{2}$. Let $f\in L^{2}(\pi)$ be an observable of the form 
	\begin{equation}
	f(q)=q\cdot Kq+l\cdot q+C\label{eq:quadratic observable}
	\end{equation}
	with $K\in\mathbb{R}_{sym}^{d\times d}$, $l\in\mathbb{R}^{d}$ and
	$C\in\mathbb{R}$. If at least one of the conditions $KJ_{1}S\neq SJ_{1}K$
	and $l \notin \ker J$ is satisfied, then the asymptotic variance is at a local maximum for the unperturbed sampler, i.e.
	\[
	\left. \partial_{\mu}\sigma_{f}^{2}\right\rvert_{\mu=0}=0\qquad \mbox{ and } \qquad 	\left. \partial_{\mu}^{2}\sigma_{f}^{2}\right\rvert_{\mu=0}<0.
	\]
\end{corollary}
\begin{proof}
	Note that 
	\[
	\widetilde{f}(q)=f(S^{-1/2}q)=q\cdot S^{-1/2}KS^{-1/2}q+S^{-1/2}l\cdot q+C=q\cdot\widetilde{K}q+\widetilde{l}\cdot q+C
	\]
	is again of the form (\ref{eq:quadratic observable}) (where in the
	last equality, $\widetilde{K}=S^{-1/2}KS^{-1/2}$ and $\widetilde{l}=S^{-1/2}l$
	have been defined). From (\ref{eq:Underdamped Langevin transformed}),
	(\ref{eq:asymvar transform}) and Theorem \ref{cor:small pert unit var}
	the claim follows if at least one of the conditions $[\widetilde{K},S^{1/2}J_{1}S^{1/2}]\neq0$
	and $\widetilde{l}\notin\ker(S^{1/2}J_{1}S^{1/2})$ is satisfied. The
	first of those can easily seen to be equivalent to 
	\[
	S^{-1/2}(KJS-SJK)S^{-1/2}\neq0,
	\]
	which is equivalent to $KJ_{1}S\neq SJ_{1}K$ since $S$ is nondegenerate.
	The second condition is equivalent to 
	\[
	S^{1/2}J_{1}l\neq0,
	\]
	which is equivalent to $J_{1}l\neq0,$ again by nondegeneracy of $S$. \qed \end{proof}
\begin{corollary}
	\label{cor:limit_asym_var}
	Assume the setting from the previous corollary and denote by $\Pi$
	the orthogonal projection onto $\ker(J_{1}Sq\cdot\nabla)$. For $f\in L^{2}(\pi)$
	it holds that
	\[
	\lim_{\mu\rightarrow\infty}\sigma_{f}^{2}(\mu)=\sigma_{\Pi f}^{2}(0)\le\sigma_{f}^{2}(0).
	\]
\end{corollary}
\begin{proof}
	Theorem \ref{prop:large pert} implies 
	\[
	\lim_{\mu\rightarrow\infty}\widetilde{\sigma}_{\widetilde{f}}^{2}(\mu)=\widetilde{\sigma}_{\widetilde{\Pi}\widetilde{f}}^{2}(0)\le\widetilde{\sigma}_{\widetilde{f}}^{2}(0)
	\]
	for the transformed system (\ref{eq:Underdamped Langevin transformed}).
	Here $\widetilde{f}(q)=f(S^{-1/2}q)$ is the transformed observable and
	$\widetilde{\Pi}$ denotes $L^{2}(\pi)$-orthogonal projection onto $\ker(S^{1/2}J_{1}S^{1/2}q\cdot\nabla)$.
	According to (\ref{eq:asymvar transform}), it is sufficient to show
	that $(\Pi f)\circ S^{-1/2}=\widetilde{\Pi}\widetilde{f}$. This however follows
	directly from the fact that the linear transformation $\phi\mapsto\phi\circ S^{1/2}$
	maps $\ker(S^{1/2}J_{1}S^{1/2}q\cdot\nabla)$ bijectively onto $\ker(J_{1}Sq\cdot\nabla)$.\qed
\end{proof}
Let us also reformulate Algorithm \ref{alg:optimal J} for the case of a Gaussian with arbitrary covariance.
\begin{algorithm}
	\label{alg:optimal J general}Given $K,S\in\mathbb{R}_{sym}^{d\times d}$
	with $f(q)=q\cdot Kq$ and $V(q)=\frac{1}{2}q\cdot Sq$ (assuming $S$ is nondegenerate), determine optimal perturbations $J_{1}$
	and $J_{2}$ as follows:
	\begin{enumerate}
		\item Set $\widetilde{K}=S^{-1/2}KS^{-1/2}$ and $\widetilde{K}_{0}=\widetilde{K}-\frac{\Tr\widetilde{K}}{d}\cdot I$.
		\item Find $U\in O(\mathbb{R}^{d})$ such that $U\widetilde{K}_{0}U^{T}$ has
		zero entries on the diagonal (see Appendix \ref{tracefree}).
		\item Choose $a_{i}\in\mathbb{R}$, $i=1,\ldots,d$ such that $a_{i}\ne a_{j}$
		for $i\ne j$ and set 
		\[
		\bar{J}_{ij}=\frac{(U\widetilde{K}_{0}U^{T})_{ij}}{a_{i}-a_{j}}.
		\]
		\item
		Set $\widetilde{J}=U^{T}\bar{J}U$.
		\item Put $J_{1}=S^{-1/2}\widetilde{J}S^{-1/2}$ and $J_{2}=S^{1/2}JS^{1/2}$.
	\end{enumerate}
\end{algorithm}
Finally, we obtain the following optimality result from Lemma \ref{lem:lin_observables} and Corollary \ref{cor:optimality}.
\begin{corollary}
	Let $f(q)=q\cdot Kq+l\cdot q-\Tr K$ and assume that $\Pi^{\perp}_{\ker J}l=0$.
	Then 
	\[
	\min_{J_1^T=-J_1,\, J_2=SJ_1 S}\left(\lim_{\mu\rightarrow\infty} \sigma^2_{f}(\mu,J_1,J_2)\right)=\sigma^2_{f_1}(0),
	\]
	where $f_{1}(q)=q\cdot K_{1}q$, $K_{1}=\frac{\Tr(S^{-1}K)}{d}S$.
	Optimal choices for $J_{1}$ and $J_{2}$ can be obtained using Algorithm \ref{alg:optimal J general}.
\end{corollary}
\begin{remark}
	Since in Section \ref{sec:small perturbations} we analysed the case
	where $J_{1}$ and $J_{2}$ are proportional, we are not able to drop
	the restriction $J_{2}=SJ_{1}S$ from the above optimality
	result. Analysis of completely arbitrary perturbations will be the
	subject of future work. 
\end{remark}

\begin{remark}
	The choices $M=S$ and $\Gamma=\gamma S$ have been introduced to
	make the perturbations considered in this article lead to samplers that perform well in terms of reducing the asymptotic variance. However, adjusting
	the mass and friction matrices according to the target covariance
	in this way (i.e. $M=S$ and $\Gamma=\gamma S$) is a popular way of preconditioning the dynamics, see for instance \cite{GirolamiCalderhead2011} and, in particular mass-tensor molecular dynamics~\cite{Bennett1975267}. Here we will present an argument why such a preconditioning
	is indeed beneficial in terms of the convergence rate of the dynamics.
	Let us first assume that $S$ is diagonal, i.e. $S=\diag(s^{(1)},\ldots,s^{(d)})$
	and that $M=\diag(m^{(d)},\ldots,m^{(d)})$ and $\Gamma=\diag(\gamma^{(d)},\ldots,\gamma^{(d)})$
	are chosen diagonally as well. Then (\ref{eq:Underdamped Langevin Gaussian})
	decouples into one-dimensional SDEs of the following form: 
	\begin{align}
	\mathrm{d}q_{t}^{(i)} & =\frac{1}{m^{(i)}}p_{t}^{(i)}\mathrm{d}t,\nonumber \\
	\mathrm{d}p_{t}^{(i)} & =-s^{(i)}q_{t}^{(i)}\mathrm{d}t-\frac{\gamma^{(i)}}{m^{(i)}}p_{t}^{(i)}\mathrm{d}t+\sqrt{2\gamma^{(i)}}\mathrm{d}W_{t},\quad i=1,\ldots,d.\label{eq:decoupled Langevin}
	\end{align}
	Let us write those Ornstein-Uhlenbeck processes as 
	\begin{equation}
	\mathrm{d}X_{t}^{(i)}=-B^{(i)}X_{t}^{(i)}\mathrm{d}t+\sqrt{2Q^{(i)}}\mathrm{d}W_{t}^{(i)}\label{eq: decoupled OU process}
	\end{equation}
	with 
	\[
	B^{(i)}=\left(\begin{array}{cc}
	0 & -\frac{1}{m^{(i)}}\\
	s^{(i)} & \frac{\gamma^{(i)}}{m^{(i)}}
	\end{array}\right)\,\text{and }\,Q^{(i)}=\left(\begin{array}{cc}
	0 & 0\\
	0 & \gamma^{(i)}
	\end{array}\right).
	\]
	As in Section \ref{sec:exp_decay}, the rate of the exponential decay of (\ref{eq: decoupled OU process}) is equal to $\min\text{Re}\,\sigma(B^{(i)})$. A short calculation shows that the eigenvalues of $B^{(i)}$ are given by  
	\[
	\lambda_{1,2}^{(i)}=\frac{\gamma^{(i)}}{2m^{(i)}}\pm\sqrt{\bigg(\frac{\gamma^{(i)}}{2m^{(i)}}\bigg)^{2}-\frac{s^{(i)}}{m^{(i)}}}.
	\]
	Therefore, the rate of exponential decay is maximal when 
	\begin{equation}
	\bigg(\frac{\gamma^{(i)}}{2m^{(i)}}\bigg)^{2}-\frac{s^{(i)}}{m^{(i)}}=0,\label{eq:gm constraint}
	\end{equation}
	in which case it is given by 
	\[
	(\lambda^{(i)})^{*}=\sqrt{\frac{s^{(i)}}{m^{(i)}}}.
	\]
	Naturally, it is reasonable to choose $m^{(i)}$ in such a way that
	the exponential rate $(\lambda^{(i)})^{*}$ is the same for all $i$, leading
	to the restriction $M=cS$ with $c>0$. Choosing $c$ small will result in fast convergence to equilibrium,
	but also make the dynamics (\ref{eq:decoupled Langevin}) quite stiff,
	requiring a very small timestep $\Delta t$ in a discretisation scheme.
	The choice of $c$ will therefore need to strike a balance between
	those two competing effects. The constraint (\ref{eq:gm constraint})
	then implies $\Gamma=2cS$.	 By a coordinate transformation, the preceding argument also applies if $S$, $M$ and $\Gamma$ are diagonal in the same basis, and of course $M$ and $\Gamma$ can always be chosen that way.
	Numerical experiments show that it is possible to increase the rate of convergence to equilibrium even further by choosing $M$ and $\Gamma$ nondiagonally with respect to $S$ (although
	only by a small margin). A clearer understanding of this is a topic of further investigation.
\end{remark}

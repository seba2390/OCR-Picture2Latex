\begin{figure}[t!]
    \centering
	\includegraphics[width=0.9\linewidth]{figure/images/teaser.pdf}
	\vspace{-2mm}
    \caption{
    \textbf{Unsupervised sound localization via iterative contrastive learning.} 
    (\textit{Baseline}) Existing contrastive learning usually takes the image-audio pairs sampled from the same video frame as the positive pairs, and those extracted from different videos as the negative pairs. 
    %
    (\textit{Ours}) %ith the model initialized by the conventional contrastive learning, 
    %The proposed iterative approach exploits the sounding and non-sounding regions predicted in the previous training epoch as the \emph{peudo}-labels (green and red dashed circles).
    %
    %Moreover, the correlation (positive or negative) between the image and audio sampled across videos is determined by observing the relationship in the audio modality (black line).
    %
    %positive or negative correlation between the image and audio across instances is determined by observing the relationship in the audio modality (black line).
    The proposed iterative approach exploits the \textbf{intra-frame sampling} that takes the sounding and non-sounding regions predicted in the previous training epoch as the \emph{pseudo}-labels (green and red dashed circles), and the \textbf{inter-frame relation} that provides additional positive or negative correlations between the image and audio sampled across different videos where the correlations are determined by observing the relationships in the audio modality (positive in this example).
    }
	\label{fig:teaser}
	\vspace{-3.5mm}
\end{figure}

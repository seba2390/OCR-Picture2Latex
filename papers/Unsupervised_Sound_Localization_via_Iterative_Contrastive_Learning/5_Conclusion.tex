\vspace{-2mm}
\section{Conclusions}
\vspace{\secmargin}
\label{sec:conclusions}
%In this paper, we present a novel framework to learn to localize sound in a visual scene in an unsupervised manner.
In this paper, we present a novel unsupervised sound localization framework that does not require any prior assumption or data annotation.
%
We propose two modules to provide pseudo positive and negative training pairs based on an iterative contrastive learning pipeline.
The \textit{intra-frame sampling} leverages the localization results estimated in the previous epoch as pseudo-labels.
The \textit{inter-frame relation} contributes  to training pairs across different videos by exploiting the relationships in the audio modality with the audio features learned from the previous epoch.
%Iterative contrastive learning is developed to use the localization results estimated in the previous epoch as the pseudo-labels for the current training epochs.
%
%Specifically, these pseudo-labels are used to determine the potential (non-)sounding regions.
%
%The novelty of our proposed model lies in the results from previous epoch as pseudo-annotations, which would guide the sound localization learning for the current epoch by estimating the sounding and non-sounding regions.
% 
%Moreover, the relationship among audio across instances implies correlation between potential sounding regions with a batch. 
%Moreover, we find that the relationship in the audio modality benefits the contrastive learning process as it serves as the cue to determine the correlation between the image and audio sampled from different video sequences.
% 
%Such the correlation can benefit the representation learning by address the drawbacks of typical contrastive learning methods, which differentiates the audio-visual representation as long as the instances are selected from different videos.
% 
%To be more specific, the sounding objects and related audio signals across videos are associated.
%
Extensive experimental results show that our approach performs favorably against the state-of-the-art weakly-supervised and unsupervised algorithms.
%Our experimental results quantitatively and qualitatively support the effectiveness of our training scheme, confirming its superiority over state-of-the-arts unsupervised and weakly supervised models.
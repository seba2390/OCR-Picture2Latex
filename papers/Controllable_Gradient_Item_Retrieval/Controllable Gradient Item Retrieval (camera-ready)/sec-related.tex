%!TEX root = main.tex
\section{related work}
\label{sec:Related Work}
\textbf{Product Search and Item Retrieval}
There are a lot of research has been done on product searches by incorporating text into the query, such as \cite{JiangHX12MMdetection, HanWHZZLZD17ConceptDiscovery} use the user's feedback to the search query. For the problem of image-based product search Vo et al. \cite{Vo19TIRG} proposed a method that regards an image and a text string as a query and allows attribute modification. Besides, for image-based fashion search, Zhao et al. \cite{Zhao17MemoryFashionSearch} developed a memory-augmented deep learning system that can perform
attribute manipulation based on the reference image. Moreover, there are a lot of cross-modal methods that deal with the item retrieval problem \cite{Zhen19DSCMR, wen19advCrossModalIR, Yu19UnsupCrossModalIR}. Cross-modal methods try to encode information from different modalities into a common representation space. To learn a high-quality common representation space, Zhen et al. \cite{Zhen19DSCMR} leveraged data pairs to match them in representation space. To deal with the unparalleled data scenario, \cite{wen19advCrossModalIR} proposed an adversarial learning method to deal with it. We are approaching the item retrieval problem where image data are not available. Besides, unlike previous work which seldom shows its effectiveness of gradient retrieval, in this work, we also focus on how to retrieval items in a gradient manner with respect to certain attributes indicated by a modification.
\\
\textbf{Disentangled representation learning} 
Disentanglement is an open problem in the realm of representation learning which aims to identify and
disentangle the underlying explanatory factors \cite{Bengio13Disentangle}. There are a lot of works that focus on unsupervised disentanglement \cite{Higgins17betaVAE, kumar18DIPVAE, Zhao17InfoVAE, chen18betaTCVAE, KimM18FactorVAE, mazhou0Y019MacridVAE}. $\beta$-VAE \cite{Higgins17betaVAE} demonstrates that disentanglement can emerge once the KL divergence term in the VAE \cite{KingmaW13VAE} objective is aggressively penalized. Later, Zhao et al. \cite{Zhao17InfoVAE} proposed InfoVAE which regarded VAE from the view of information theory. By maximizing the mutual information between the data variables and latent variables, the mutual information between the latent variables is minimized. However, Locatello et al. \cite{Locatello18ChallengeDisentangle} theoretically demonstrate that unsupervised learning of disentanglement arises from model inductive bias and empirically shows that many existing methods for the unsupervised learning of disentangled representations are brittle, requiring careful supervision-based hyper-parameter tuning. Therefore, recently, the research attention has turned to forms of disentanglement in supervised or weakly supervised setting \cite{Feng18DualSwap, Chen17MVGAN, ChenB20PairwiseVAE, Gabbay19LatentOptimDisentangle}. To model pairwise similarities between data samples, Chen et al.\cite{ChenB20PairwiseVAE} proposed a pairwise VAE that tries to capture a binary relationship(similar or not). And Feng et al.\cite{Feng18DualSwap} proposed a Dual Swap Disentangling method to leverage binary similarity labels. Besides, a theoretical framework was given by Shu et al. \cite{shu20disentangleguarantee}, which guarantees consistency and restrictiveness can be achieved under three types of weakly supervised setting. Different from \cite{Feng18DualSwap, ChenB20PairwiseVAE}, in this work, we focus on using ranking triples information as supervision. In the ranking triples, not only the ranking relation between two data samples were given, but we also provided the information about we compare the two data samples in which point of view. Besides, our method aims to ground the semantic meaning of the comparison view into the dimensions of disentangled representations.
\\
\textbf{Critiquing Recommender Systems}
Critiquing is a method widely used conversational recommendation\cite{thompson2004personalized} which supports a task-oriented, multi-turn dialogue with their users to discover the detailed and current preferences of the user\cite{jannach2020survey}. In critiquing approaches, users are presented with a recommendation result during the dialogue and then apply pre-defined critiques on the result\cite{burke1997findme, hammond1995faq}. Specifically, in this setting, a user is iteratively provided with an item
recommendation and attribute description for that item; a user
may either accept the recommendation, or critique the attributes
in the item description to generate a new recommendation result\cite{tou1982rabbit}. Recently, there are some works introduce the critiquing method into the current deep learning recommendation system to improve the explainability of the system\cite{antognini2020interacting} which a system proposes to the user a recommendation with its keyphrases and the user can interact with the explanation and critique phrases. Furthermore, there are some work focus on the latent linear critiquing\cite{luo2020latent, luo2020deep} which built on  existing linear embedding recommendation
algorithm to co-embed keyphrase attributes and user preference embeddings and modulate the strength of multi-step critiquing feedback. By levering the linear structure of the embeddings, the number of interactions required to find a satisfactory item is reduced. Different from those methods, we think a better way is to provide a user with an item sequence with a gradual change on an indicated attributes in order to allow users to obtain satisfactory items with as few interactions as possible. Besides, in those methods, keyphrase frequency usage data is necessary to learn the strengthen of a critiquing. However, in our method, only attributes data is required.
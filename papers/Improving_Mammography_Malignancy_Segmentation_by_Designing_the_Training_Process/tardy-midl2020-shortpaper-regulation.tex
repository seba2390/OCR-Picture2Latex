%\documentclass{midl} % Include author names
\documentclass{midl} % Anonymized submission

% The following packages will be automatically loaded:
% jmlr, amsmath, amssymb, natbib, graphicx, url, algorithm2e
% ifoddpage, relsize and probably more
% make sure they are installed with your latex distribution


% Header for extended abstracts
\jmlrproceedings{MIDL 2020}{Medical Imaging with Deep Learning 2020}
\jmlrvolume{}
\jmlryear{}
\jmlrworkshop{MIDL 2020 -- Short Paper}
\editors{}

% to be uncommented for submissions under review
%\jmlrworkshop{Short Paper -- MIDL 2020 submission}
%\jmlrvolume{-- Under Review}
%\editors{Under Review for MIDL 2020}

\title[Improving Mammography Malignancy Segmentation ]{Improving Mammography Malignancy Segmentation with a Semi-Supervised Training Process}

%\title[Towards the explainability of DNN]{Towards the explainability of neural network via explainable learning process}

% Other suggestions
%\title[Short Title]{Natural training process as network regularizer}


 % Use \Name{Author Name} to specify the name.
 % If the surname contains spaces, enclose the surname
 % in braces, e.g. \Name{John {Smith Jones}} similarly
 % if the name has a "von" part, e.g \Name{Jane {de Winter}}.
 % If the first letter in the forenames is a diacritic
 % enclose the diacritic in braces, e.g. \Name{{\'E}louise Smith}

 % Two authors with the same address
 % \midlauthor{\Name{Author Name1} \Email{abc@sample.edu}\and
 %  \Name{Author Name2} \Email{xyz@sample.edu}\\
 %  \addr Address}

 % Three or more authors with the same address:
 % \midlauthor{\Name{Author Name1} \Email{an1@sample.edu}\\
 %  \Name{Author Name2} \Email{an2@sample.edu}\\
 %  \Name{Author Name3} \Email{an3@sample.edu}\\
 %  \addr Address}


% Authors with different addresses:
% \midlauthor{\Name{Author Name1} \Email{abc@sample.edu}\\
% \addr Address 1
% \AND
% \Name{Author Name2} \Email{xyz@sample.edu}\\
% \addr Address 2
% }

%\footnotetext[1]{Contributed equally}

% More complicate cases, e.g. with dual affiliations and joint authorship
\midlauthor{\Name{Mickael Tardy\nametag{$^{1,2}$}} \Email{mickael.tardy@ec-nantes.fr}\\
\addr $^{1}$ Ecole Centrale de Nantes, LS2N, UMR CNRS 6004, Nantes, France \\
\addr $^{2}$ Hera-MI, SAS, Nantes, France \AND
\Name{Diana Mateus\nametag{$^{1}$}} \Email{diana.mateus@ec-nantes.fr}\\
}

\begin{document}

\maketitle
\vspace{-0.5cm}
\begin{abstract}
We work on the breast imaging malignancy segmentation task while focusing on the training process instead of network complexity. We designed a training process based on a modified U-Net, increasing the overall segmentation performances by using both, benign and malignant data for training. Our approach makes use of only a small amount of annotated data and relies on transfer learning from a self-supervised reconstruction task, and favors explainability. 

\end{abstract}

\begin{keywords}
Mammography, Segmentation, Malignancy Detection, Explainability
\end{keywords}

\section{Introduction}
\label{sec:intro}

Breast cancer is one of the most frequent cancers, and thus, an important public health issue. Mammography is the most common screening exam in early breast cancer detection. While a big amount of imaging is generated, its use for learning-based CAD solutions is not obvious due to the lack of detailed annotations of the malignant regions. In this work, we propose a method to train a segmentation network having few annotated images. 

Typically, to perform image segmentation with a supervised deep learning approach, the network needs an explicit segmentation mask as a ground truth. For medical imaging, this means that each image shall have delimited regions of interest provided by an expert. In clinical practice, such ground truth is rarely available since its collection is a tedious and time-consuming process. Besides, only malignant images can be labeled pixel-wise, which are only a portion of the available data. However, even with 1/8 of women population being affected by breast cancer \cite{Siegel2019}, a great part of mammography imaging is benign and can not be used for supervised segmentation training.

We address the problem with a two-step training process. In first, we follow-up on the work of \cite{Zhou2019a}, which proposes weights initialization by pre-training the neural network for reconstruction in a self-supervised manner, before training it for the same or different application. Such an approach enables taking advantage of large amounts of benign images to initialize the model with prior knowledge, improving the overall performance. As in  \cite{Zhou2019a}, we train a reconstruction network in a self-supervised manner but adapt it to full-images instead of patches (see Section \ref{ssec:selfsup}). In our second step, we wrapped the backbone U-Net with a subtraction layer on top of the U-Net (see Fig. \ref{fig:model}), taking the output from the input, so the network is still trained for reconstruction, rather than being trained to yield the probability of pixel belonging to a malignant region.

% Our training process is composed of the following steps: 
% \begin{itemize}
%   \item image-wise self-supervised training for texture and spatial knowledge on full-sized benign mammograms
%   \item image-wise discriminative training from malignant mammograms. 
% \end{itemize}

%Below we discuss the interest/benefit of each step of the proposed training process and discuss further development avenues.


\section{Methods}

Our training process (see Fig. \ref{fig:model}) is composed of two steps: i) image-wise self-supervised training on full-sized benign mammograms for the reconstruction task followed by ii) image-wise discriminative reconstruction training on malignant mammograms. % We are convinced that by continuously training from both, benign and malign data play a role of a natural regularizer. 

\paragraph{U-Net for full-size mammograms} We trained the network on the full images (mammograms cropped and rescaled to \textbf{1536x1536}), instead of patches. The cropping allows us to keep the pixel spacing low and the smaller findings visible. We modified traditional U-Net \cite{Ronneberger2015} as follows: i) we used separable convolutions \cite{Chen2018,Qi2019}, ii)  we adjusted the skip connections, removing the top long ones, and introducing short ones in each block \cite{Drozdzal2016,Szegedy2016}, iii) we used instance normalization and leaky ReLU activations \cite{Isensee2019}. 


\paragraph{Self-supervised training}
\label{ssec:selfsup}

We adopted the self-supervised training approach \cite{Zhou2019a}, with few modifications. Unlike Zhou et al. who focused on patch-wise trining of CT images, we worked with image-wise training on mammograms, so we introduced operations that better fit the task, namely: i) instead of non-linear intensity transformation we used gamma-based one, ii) we excluded local-shuffling as too harmful for full mammograms, and iii) we extended in-painting with a range of non-rectangle shapes.

At this stage, we use only benign mammograms, filtered by the patient-wise labels: that is, only confirmed benign patient-files were included. 
%As stated previously, the benign cases consist around 7/8 of all of the cases in breast cancer screening. However, mammography imaging is often not self-sufficient the benign classification is often supported by additional imaging (ultrasound, MRI) or by other types of examinations (e.g. biopsy). 
We filtered the dataset according to the patient-wise labels of ACR cancer probability. We kept only the cases classified as ACR1 and ACR2 and remove all the others (ACR3-6) as uncertain or malignant. 


\paragraph{Image-wise segmentation}
\label{ssec:discriminative}

Once the U-Net network was initialized with the reconstruction task on benign mammograms, we trained it on the malignant images (ACR4-6) in a supervised manner with pixel-wise ground truth. However, instead of changing the top activation of the U-Net, we added a layer on top of the U-Net (see Fig. \ref{fig:model}), subtracting the output from the input. Thus, we continue to train the backbone network for a reconstruction task, while the whole model was designed to yield malignancy segmentation regions (see Fig. \ref{fig:segresults}).


\section{Results}

We show the performances on the malignant images of INBreast dataset \cite{Moreira2012} in Table \ref{tab:results} (80\% train, 20\% test). We note, that unlike common U-Net implementations \cite{Sun2020}, we combine both, masses and calcification masks.
%
\begin{figure}[htbp]
 % Caption and label go in the first argument and the figure contents
 % go in the second argument
\floatconts
  {fig:model}
  {\caption{Two-step training process design}}
  {\includegraphics[width=.9\linewidth]{u-net-diff.pdf}}
\end{figure}

{
\begin{table}[htbp]
 % The first argument is the label.
 % The caption goes in the second argument, and the table contents
 % go in the third argument.
\floatconts
  {tab:results}%
  {\caption{Segmentation performances}}%
  {\vspace{-0.2mm}\begin{tabular}{l|c|c}
%  \bfseries & \multicolumn{2}{c}{\bfseries DICE} \\ \hline
  \bfseries Method  & \bfseries $DICE_{Max}$ & \bfseries $DICE_{Avg}$ (on 10 eps) \\ \hline
  \scriptsize Fully Supervised segmentation (\textit{from scratch}) (baseline) & 0.58 & 0.44\\
  \scriptsize Fully Supervised seg. (\textit{pre-trained}) \cite{Zhou2019a} & 0.58 & 0.57\\
  \scriptsize \textbf{Discriminative segmentation (\textit{from scratch}) (ours)} & \textbf{0.61}  & 0.52 \\
  \scriptsize \textbf{Discriminative segmentation (\textit{with pre-training}) (ours)} & \textbf{0.61} & \textbf{0.59} \\
  \end{tabular}}
\end{table}
}

\section{Discussion}

Our network can be trained on both, benign and malignant images. Such an approach yields better segmentation performances (i.e. higher $DICE_{Max}$) and acts as a natural regularizer (i.e. higher $DICE_{Avg}$) since the transition to malignant images is closer to fine-tuning than to transfer learning. Our results show that such duality is beneficial for the segmentation results (see Tab. \ref{tab:results}). Working on high-resolution mammograms, our discriminative network is sensitive to both, masses and calcifications (see Fig. \ref{fig:segresults}).

Our approach contributes to the explainability of the output: our network is designed to discriminate malignant regions on the full-sized mammograms instead of yielding a probability of pixel to belong to a malignant region. Our network is trained with full mammograms, so, the spatial information is kept by design. The proposed process is scalable, meaning it can take advantage of both benign and malignant imaging. Furthermore, such a process more naturally integrates with the federated or distributed learning scheme thanks to its efficient data use, thus its ability to switch easier between vendors.

The obtained results may be helpful to the radiologists when performing diagnosis. It also can help radiographers making additional examinations (such as spot localizations or magnification), before interpretation by a radiologist. 


\begin{figure}[htbp]
% Caption and label go in the first argument and the figure contents
 % go in the second argument
\floatconts
  {fig:segresults}
  {\caption{Segmentation results. \textbf{Left}: U-Net (pre-trained), \textbf{Right}:  Discriminative network (pre-trained). \textbf{1st row}: Input \textbf{\textit{I}}, \textbf{2nd row}: Output \textbf{\textit{O}}, \textbf{3rd row}: GT masks \textbf{\textit{M}}}}
%  {\includegraphics[width=0.60\linewidth]{src/unet_seg_output_23_20200103235519_crop.png}}
  {\includegraphics[width=.9\linewidth]{unet_seg_output_23_20200103235519_crop-combo-split-v2.png}\vspace{-0.5mm}}

\end{figure}



% Acknowledgments---Will not appear in anonymized version
\midlacknowledgments{Research funding is provided by Hera-MI, SAS and Association Nationale de la Recherche et de la Technologie, CIFRE grant no. 2018/0308}



\bibliography{tardy-midl2020-shortpaper-regulation.bib}




\end{document}

%\documentclass{article}
\documentclass[review,hidelinks,onefignum,onetabnum]{siamart220329}

% Optional PDF information
\ifpdf
\hypersetup{
  pdftitle={Constrained Local Approximate Ideal Restriction for Advection-Diffusion Problems},
  pdfauthor={Ahsan Ali, James Brannick, Karsten Kahl, Oliver A. Krzysik, Jacob B. Schroder, and Ben S. Southworth}
}
\fi

% The next STATEment enables references to information in the
% supplement. See the xr-hyperref package for details.
\input{ex_shared}

%\externaldocument[][nocite]{ex_supplement}

% FundRef data to be entered by SIAM
%<funding-group specific-use="FundRef">
%<award-group>
%<funding-source>
%<named-content content-type="funder-name"> 
%</named-content> 
%<named-content content-type="funder-identifier"> 
%</named-content>
%</funding-source>
%<award-id> </award-id>
%</award-group>
%</funding-group>
\usepackage{lipsum}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{epstopdf}
\usepackage{algorithmic}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb,mathtools}
\usepackage{amsfonts}
\nolinenumbers
\usepackage{cleveref}
\usepackage{booktabs}
\usepackage[total={6.25in, 9.3in}]{geometry}
\usepackage{url}

\usepackage{xcolor}
\newcommand{\tcb}[1]{\textcolor{blue}{#1}}
\newcommand{\tcp}[1]{\textcolor{purple}{#1}}
\newcommand{\aff}[1]{\ensuremath{A_{ff}^{(#1)}}} 
\newcommand{\affinv}[1]{\ensuremath{A_{ff}^{(#1),-1}}} 
\newcommand{\afc}[1]{\ensuremath{a_{fc}^{[#1]}}} 
\newcommand{\acf}[1]{\ensuremath{a_cf}^{[#1]}}
\newcommand{\w}[1]{\ensuremath{w^{[#1]}}} 
\newcommand{\witer}[2]{\ensuremath{w^{[#1],#2}}}
%\newcommand{\witerupdate}[2]{\ensuremath{w^{[#1]}_{(#2)}}} 
\newcommand{\witerupdate}[2]{\ensuremath{\bar{w}^{[#1]}}} 
\newcommand{\bg}[1]{\ensuremath{G_{#1}}} 
\newcommand{\B}[1]{\ensuremath{B^{[#1]}}} 


\newcommand{\clair}{C$\ell$AIR}
\newcommand{\RR}{\ensuremath{\mathbb{R}} } 
\newcommand{\pideal}{\ensuremath{P_{\textnormal{ideal}}}}
\newcommand{\rideal}{\ensuremath{R_{\textnormal{ideal}}}}

\graphicspath{ {./plots/} }
\DeclareMathOperator*{\argmin}{argmin}

\newcommand{\squishlist}{
   \begin{list}{--}
    { \setlength{\itemsep}{1pt}      \setlength{\parsep}{0pt}
      \setlength{\topsep}{0pt}       \setlength{\partopsep}{0pt}
      \setlength{\labelwidth}{1em}   \setlength{\leftmargin}{20pt}
      \setlength{\labelsep}{0.5em}   \setlength{\parskip}{0pt} } }

\newcommand{\squishend}{
    \end{list}  }

\begin{document}

\maketitle 

\begin{abstract}
This paper focuses on developing a reduction-based algebraic multigrid method that is suitable for solving general (non)symmetric linear systems and is naturally robust from pure advection to pure diffusion. Initial motivation comes from a new reduction-based algebraic multigrid (AMG) approach, $\ell$AIR (local approximate ideal restriction), that was developed for solving advection-dominated problems. Though this new solver is very effective in the advection dominated regime, its performance degrades in cases where diffusion becomes dominant. This is consistent with the fact that in general, reduction-based AMG methods tend to suffer from growth in complexity and/or convergence rates as the problem size is increased, especially for diffusion dominated problems in two or three dimensions. Motivated by the success of $\ell$AIR in the advective regime, our aim in this paper is to generalize the AIR framework with the goal of improving the performance of the solver in diffusion dominated regimes. To do so, we propose a novel way to combine mode constraints as used commonly in energy minimization AMG methods with the local approximation of ideal operators used in $\ell$AIR. The resulting constrained $\ell$AIR (\clair) algorithm is able to achieve fast scalable convergence on advective and diffusive problems. In addition, it is able to achieve standard low complexity hierarchies in the diffusive regime through aggressive coarsening, something that has been previously difficult for reduction-based methods. 

% We focus on developing reduction-based coarsening and interpolation methods that yield optimal AMG solvers, both in terms of computational cost and complexity.  Our proposed approach combines a root-node coarsening algorithm with an $\ell$AIR formulation that allows for column-wise constrained energy-minimization techniques.  In order to focus on these two aspects of the algorithm, we restrict the smoother to the simplest case of so-called Jacobi $F$-relaxation in the AMG solver.  As a result, though our method is in fact effective for the targeted elliptic test problems, we expect that further improvements to the method based on this framework are still possible, which will be the subject of future research. 

\end{abstract}
%\tableofcontents

% REQUIRED
\begin{keywords}
algebraic multigrid, multigrid reduction, root-node, energy minimization, nonsymmetric, preconditioning
\end{keywords}

% REQUIRED
\begin{MSCcodes}
65N55, 65N22, 65F08, 65F10
\end{MSCcodes}


\section{Introduction}
We design and analyze a reduction-based algebraic multigrid (rAMG) algorithm for linear systems of algebraic equations
\begin{equation}\label{eq:mod}
A \bf{u} = \bf{f},
\end{equation} 
where $A \in \mathbb{R}^{n\times n}$
is assumed to be a sparse nonsymmetric matrix. Our focus in this paper is on solving \eqref{eq:mod} arising from discretizations of advection-diffusion-reaction partial differential equations (PDEs), which arise in various practical applications and also serve as interesting initial model problems for testing nonsymmetric AMG solvers. Ultimately, our objective is a method that is naturally robust and efficient in both the advection and diffusion limits.

Multigrid methods for solving~\eqref{eq:mod} use a relaxation process or smoother, defined in this paper by $M$, as a local solver for a sequence of coarse-level systems of equations to reduce the global error resulting from applying relaxation on the finest level.  In AMG, a recursive two-level point of view is often used, both in terms of the development of the AMG setup algorithm as well as the analysis of the solver it produces. In this two-level context, the idea is to analyze two complementary processes to efficiently solve sparse linear systems, a relaxation scheme on the fine-level, with corresponding
error propagation matrix given by $I - M^{-1}A$, and a coarse-level correction, with error propagation matrix given by $ I - P A_c^{-1} R A$.  
%\textcolor{red}{OAK: Is this correct? Shouldn't it be $ I - P A_c^{-1} R A$? (and same in the equation below where $E_{TG}$ is defined.) (at the very least, it doesn't work dimensionally, because $R$ cannot be multiplied into $A_c^{-1}$). JBS: I also agree, but let's check with James/Ben, who I think wrote this.}
Here, $P \in \mathbb{R}^{n \times n_c}$, $n_c < n$, denotes the interpolation matrix that maps corrections from the coarse-level, $R \in \mathbb{R}^{n_c \times n}$ is the restriction matrix that maps residuals to the coarse-level, and $A_c = RAP$ is the coarse-level operator. The error propagation matrix of the resulting two-level method, from which a multilevel method is defined recursively, reads
\begin{equation}\label{eq:tl}
E_{TG} = (I-M^{-1}A)(P A_c^{-1} R A).
\end{equation} 
The AMG solver is then defined from this two-level scheme by recursively applying it on the coarse-level to approximate $A_c^{-1}$, and reduce the errors remaining after applying relaxation on the finer levels.

In AMG, the smoother $M$ is typically fixed to be a simple point-wise method and then $R$ and $P$ are constructed in
an automated setup algorithm that takes as input the system matrix $A$.  In this paper, since we consider a reduction-based AMG framework, we assume that the smoother is a point-wise $F$-relaxation scheme, where the set $F$ denotes the set of fine variables in the coarse-fine ($C/F$) splitting of the degrees of freedom $\Omega$ such that $C\cup F = \Omega$ and $C\cap F = \emptyset$.  
In this setting, the main tasks in the AMG setup algorithm are to construct the restriction and interpolation matrices $R$ and $P$ such 
that certain {\em approximation properties} hold and $R$ and $P$ (and thus $A_c=RAP$) are {\em sparse} matrices.  The latter sparsity requirement implies 
that the setup procedure can be efficiently applied recursively to $A_c = RAP$ in order to construct an optimal multilevel AMG
solver.

In the SPD case, the variational choice $R=P^T$ is used and the weak approximation property for $P$ bounds the convergence rate of the two-level method in the $A$-norm.  Notably, the weak approximation property has as its minimizer the so-called ideal interpolation
matrix~\cite{Falgout}.  This ideal form of interpolation gives rise to the Schur-complement of $A$ as
the coarse-level system matrix and, thus, coincides with block Gaussian elimination based on the given coarse-fine splitting.
In contrast to classical AMG methods that use a global smoother in the AMG solver (e.g., weighted-Jacobi or lexicographic Gauss-Seidel), reduction based methods that are motivated by this block factorization interpretation choose smoothers that focus on the subspace defined by the fine variables $F$. 

Traditionally, classical AMG methods are very effective for sparse SPD problems, e.g., discretizations of various diffusion and heat conduction problems, and not as effective for nonsymmetric problems, whereas, reduction-based AMG methods have been developed that work well for nonsymmetric problems with a near-triangular (upwinded) structure, e.g., space-time discretizations \cite{st-air} and advection-dominated PDEs \cite{Ben,air1}. The parallel-in-time method called multigrid reduction in time (MGRIT) \cite{mgrit} is another recent application of reduction-based multigrid methods, where time integration is recognized as suitable for reduction-based approaches because time is one-dimensional and optimal coarsening is practical; however, MGRIT differs from rAMG methods in using a non-Galerkin coarse grid typically based on rediscretization in time. Interestingly, theory \cite{mgrit-theory-ben,mgrit-theory-jacob,southworth2021tight} (and practice) has indicated that without special care (e.g., \cite{mgrit-adv}) MGRIT is effective on space-time PDEs with parabolic problems, particularly SPD spatial discretizations, but struggles with hyperbolic PDEs and highly nonsymmetric spatial discretizations. 

Indeed, solving more general non-symmetric systems arising from higher dimensional spatial PDEs or space-time PDEs is more complicated in terms of balancing the convergence and complexity of a multilevel solver.  A viable approach for solving the latter higher dimensional problems is given by the $\ell$AIR solver~\cite{Ben}. The approach has been extensively studied and tested for analogous advection-diffusion-reaction model problems we consider here~\cite{BenTheory,air1,Ben}, and also demonstrated on more complex advection-dominated physics, e.g., \cite{southworth2022fast,dargaville2023air}. In general, $\ell$AIR performs very well for advection-dominated problems, with performance more mixed for diffusive problems, i.e., for problems with strong diffusion $\ell$AIR suffers from degraded convergence and similar complexity issues as other reduction-based AMG methods for diffusion type problems in higher dimensions. We mention the recent paper~\cite{Scott} which represents the state-of-the-art in research on techniques for improving the performance of reduction-based AMG solvers for diffusion problems. There, the traditional approach of constructing a row-wise approximation of ideal interpolation is considered and the focus is on improving approximations to $A_{ff}^{-1}$ using sparse approximate inverse techniques, similar to the sparse Krylov approximations that have been studied, and very recently used for a highly efficient %more performant 
parallel variation of $\ell$AIR \cite{dargaville2023air}.

In this paper, we combine the reduction-based principles of $\ell$AIR with the mode constraints of energy-minimization AMG \cite{Mandel98energyoptimization,Wan,Brannick_Trace_06,OlScTu2011,Jacob,root-node}. The $\ell$AIR algorithm offers sparse, accurate approximations of ideal transfer operators in the strongly advective regime, which also yields excellent AMG approximation properties \cite{BenTheory}. In contrast, in diffusive regimes, accurate and sparse approximations of ideal transfer operators are generally not viable due to the density of $A_{ff}^{-1}$; because no other information is taken into account, the AMG approximation properties of $\ell$AIR also suffer or the complexity must dramatically increase. Classical and energy-minimization AMG methods suffer from the opposite problem -- they tend to offer excellent AMG approximation properties for diffusive problems, but very poor approximation properties in the advective regime \cite{BenTheory}. On a high level, this is because the near nullspace of advective operators cannot be represented simply by smoothed constant vectors, the basis for almost all classical AMG and energy minimization methods. Energy minimization methods inadvertently further block their potential by using some form of normal equations to perform energy minimization in the nonsymmetric setting (wherein the nonsymmetric matrix $A$ does not define a natural energy or minimization). Such minimization converges to the ideal transfer operators \emph{of the normal equations} \cite{root-node}, even though a sparse accurate approximation of ideal transfer operators is often viable for matrix $A$, which $\ell$AIR successfully targets.

Here, we recognize this subtlety in approximation properties that guides the success of different AMG methods in different regimes, and define a new constrained variation of the $\ell$AIR algorithm. Constrained $\ell$AIR (\clair) directly approximates the ideal transfer operators using a similar objective as in $\ell$AIR, while constraining the range of $P$ or $R^T$ to include known or expected near-null space mode(s), thereby harnessing the power of reduction-based and energy-minimization methods in their respective regimes.  In relaxation, we restrict ourselves to simple $F$- and $C$-point Jacobi relaxation, demonstrating that with careful construction of transfer operators, we are able to apply an efficient reduction-based method for diffusive-dominated problems. %(i.e., without relying on \emph{global} smoothers). 
As it turns out, the construction of sparsity patterns for transfer operators in $\ell$AIR and root-node based energy minimization \cite{root-node} are very similar in principle, namely that they are defined column-wise for $P$ and row-wise for $R$. As a result, we are also able to naturally incorporate an aggressive root-node approach to choosing coarse variables~\cite{Jacob,root-node} for diffusion dominated problems, ameliorating the (necessarily) high complexity that tends to arise in reduction-based and advective solvers \cite{Ben}. 

% . Two novelties of the proposed approach are  (1) (similar to energy-minimization (enmin) and smoothed aggregation (SA)) the $\ell$AIR approach is based on a column-wise approximation to ideal interpolation and thus naturally allows for the the direct inclusion of global mode interpolation constraints and (2) this column-wise approach also fits together naturally with root-node coarsening, which has been used to successfully control complexity in classical AMG for anisotropic diffusion problems~\cite{Jacob}.
 
This paper is organized as follows. 
The next section reviews reduction-based AMG and the $\ell$AIR framework that motivates our new method, and provides practical connections to energy minimization AMG methods that facilitate our method design. Our new method \clair\  is presented in \Cref{sec:iter-air}, and \Cref{sec:num} contains numerical results that illustrate the performance of our algorithms applied to various discretizations of our model advection-diffusion problem. In particular, \clair\ is able to maintain fast robust convergence on advection-dominated problems, while also yielding low-complexity scalable solutions for diffusion dominated problems. To complement the numerical results for the proposed method \clair, we present a study of classical AMG weak and strong approximation properties in Appendix A.

\section[Reduction based AMG and lAIR interpolation]{Reduction based AMG and $\ell$AIR interpolation}
Let $A\in\mathbb{R}^{n\times n}$ and assume that the degrees of freedom $\Omega = \{1,...,n\}$ are partitioned in the classical sense such that we have $n_c$ $C$-points and $n_f$ $F$-points.  Then, as before, define $P:\mathbb{R}^{n_c}\mapsto\mathbb{R}^n$ and $R:\mathbb{R}^{n}\mapsto\mathbb{R}^{n_c}$ as restriction and interpolation. Further, assume that $C$-points are interpolated and restricted by injection in the classical AMG sense; then, the transfer operators $P$ and $R$ in  reduction based AMG can be written in the following block form:
%
\begin{align}
\label{eqn:basicsplit}
A & = \begin{pmatrix} A_{ff} & A_{fc} \\ A_{cf} & A_{cc}\end{pmatrix},
\hspace{3ex}
P = \begin{pmatrix} W \\ I\end{pmatrix},
\hspace{3ex} R = \begin{pmatrix} Z & I \end{pmatrix},
\end{align}
%
where the ordering here is useful in formalizing a reduction-based AMG method.
Design of classical reduction based AMG methods is motivated by the observation that the ideal interpolation operator is the unique operator 
%
\begin{align}
\pideal & = \begin{pmatrix} -A_{ff}^{-1}A_{fc} \\ I \end{pmatrix}\label{eq:p_ideal}
\end{align}
%
that eliminates the contribution of the coarse-grid correction $\mathbf{e}_c$ to the $F$-point residual:
%
% OAK: What is the final e_c doing in this equation? Maybe it should be a \forall e_c? Maybe also it's clearer what's meant if the equation is written as AP_{ideal} (and ditto for the RA -> R_{ideal}A equation in the next section).
% JBS: Agreed.  I removed this last e_c, but added e_c to the above sentence, so it's defined.
\begin{align}
AP\mathbf{e}_c = \begin{pmatrix}\mathbf{0}\\ S\mathbf{e}_c \end{pmatrix} \label{eq:def1}. 
\end{align}
%
Assuming $R$ and $P$ take the form of \eqref{eqn:basicsplit}, we have independent of $A$ that the Petrov-Galerkin coarse grid satisfies $RAP = S\coloneqq A_{cc}-A_{cf}A_{ff}^{-1}A_{fc} $, where $S$ is the Schur complement \cite{Falgout,Ben}.  

Reduction based methods for diffusion type problems have traditionally assumed the classical AMG form of interpolation in~\eqref{eq:p_ideal} and approximate $-A_{ff}^{-1}A_{fc}$ by solving for each $i\in F$
% OAK: Should there be a minus in the RHS of this equation (since W approximates the first block of P_ideal)? And If W_i is a row of W, should it be written as W^{i}?
% JBS: Agreed.  I added the minus.
\begin{align}
A_{ff} W_i = -A_{fc}^{\{i\}}, 
\end{align}
for the $n_f$ rows of the interpolation weight matrix 
$W$ defined as in~\eqref{eqn:basicsplit}.
Here, we use the notation $X^{\{i\}}$ to refer to the $i$th row of a matrix $X$, whereas, $X^{[i]}$ will denote a column of the matrix.
In this classical reduction-based setting, choosing the coarse grid degrees of freedom $C$ 
as well as choosing the sparsity structure of the rows of $W$ are done using classical AMG coarsening and strength of connection heuristics and the resulting algorithms typically lead to high grid and operator complexities, even when very simple approximations of $A_{ff}^{-1}$ are used.  
We mention that various approximations to $A_{ff}^{-1}$ in the computation of $P$ and in relaxation are possible and have been considered in the literature, and we reiterate that in our development we focus on designing an approach that achieves both low grid and operator complexities while at the same time only requiring the simplest diagonal (Jacobi) F-relaxation scheme for fast convergence.

\subsection[Review of lAIR]{Review of $\ell$AIR}
The $\ell$AIR approach that we build our new method around is based on the similar observation that the ideal restriction operator is the unique operator \cite{Ben}
\begin{align}
\rideal & = \begin{pmatrix} -A_{cf}A_{ff}^{-1} & I \end{pmatrix}\label{eq:r_ideal}
\end{align}
that eliminates all error at $F$-points:
%
\begin{align}
RA\begin{pmatrix}\delta\mathbf{e}_f\\\mathbf{0}\end{pmatrix} = \mathbf{0}\hspace{3ex}\forall \delta\mathbf{e}_f. \label{eq:def0}
\end{align}
%
Here, the ordering of the equations is again based on a splitting of $\Omega = C \cup F$. 
The $\ell$AIR  approach is then based on setting $RA$ equal to zero in~\eqref{eq:def0} within a pre-determined $F$-point sparsity pattern for $Z$. A similar method to approximate ideal interpolation can be expressed as satisfying $AP=0$ exactly a specified sparsity pattern for $W$.  Note that the AIR approach can also be seen as directly approximating the action of $\rideal$ on F-points, where $\rideal A = (\mathbf{0} , S)$, for the Schur complement $S$. Expressing this result in terms of some matrix $Z$, the approach is equivalent to satisfying
%
\begin{equation}\label{eq:z-formula}
    ZA_{ff} = -A_{cf}
\end{equation}
%
within a predetermined sparsity pattern for $Z$. Here, the AIR approach is clearly different from the classical (reduction) AMG \cite{1985BrandtA_McCormickS_RugeJ-aa,JWRuge_KStuben_1987a,maclachlan2006adaptive,FromKahlMaclZikaBran2010} approach in that~\eqref{eq:z-formula} involves solving for the $n_c$ rows of $Z$ (or $R$), which now gives a column-wise view of computing $R^T$ and thereby an $\ell$AIR style form of $P$.~\footnote{We note that the reduction-based AMG approaches \cite{maclachlan2006adaptive,FromKahlMaclZikaBran2010} have also previously explored the use of constraint vector(s), however in addition to our different column-wise view of computing $R^T$, these approaches use cheap approximations to $A_{ff}^{-1}$ (e.g., diagonal) with a more expensive multilevel adaptive approach for generating the constraint vector.  In this work, we take the more expensive $\ell$AIR approach to approximating $A_{ff}^{-1}$ based on small block inverses, but combine that with a cheap constraint vector similar to energy-minimization methods, which require only a few relaxation sweeps on each level for improvement.}

Denoting indices of the sparsity pattern for the $i$th row of $Z$ as $\mathcal{Z}_i = \{\ell_1,...,\ell_{S_i}\}$, where $S_i = |\mathcal{Z}_i|$ is the size of the sparsity pattern, the resulting (transposed) linear system for $Z$ takes the form
%
\begin{align}
\begin{pmatrix} a_{\ell_1 \ell_1} & a_{\ell_2\ell_1} & ... & a_{\ell_{S_i}\ell_1} \\
a_{\ell_1\ell_2} & a_{\ell_2\ell_2} & ... & a_{\ell_{S_i}\ell_2} \\
\vdots & & \ddots & \vdots \\
a_{\ell_1\ell_{S_i}} & a_{\ell_2\ell_{S_i}} & ... & a_{\ell_{S_i}\ell_{S_i}}\end{pmatrix}
\begin{pmatrix} z_{i\ell_1} \\ z_{i \ell_2} \\ \vdots \\ z_{i\ell_{S_i}}\end{pmatrix}
& = - \begin{pmatrix} a_{i\ell_1} \\ a_{i\ell_2} \\ \vdots \\ a_{i\ell_{S_i}}\end{pmatrix} \label{eq:system}.
\end{align}
%
As demonstrated in \cite{Ben,air1}, for upwinded advection-dominated problems, very good sparse approximations to $A_{ff}^{-1}$ can be made, which means that satisfying \eqref{eq:z-formula} within a sparsity pattern provides an accurate approximation to $\rideal$. For advection-dominated problems, this approach also provides very good approximation properties of the resulting restriction operator, as demonstrated in ~\cite{BenTheory} and the numerical results. In contrast, relying only on solving \eqref{eq:z-formula} for a diffusion dominated problem is unlikely to be effective, because $A_{ff}^{-1}$ is generally more dense in this setting and not well approximated by a sparse matrix. Hand-in-hand with this, the resulting approximation properties are also poor. This has been mitigated reasonably well by combining $\ell$AIR restriction with classical AMG interpolation for problems with strong diffusion, but the complexity remains high and convergence sub-par compared with classical AMG or energy minimization methods. 

\subsection{Energy minimization and mode constraints}
\label{sec:enmin_modeconst}

Another well-known class of AMG methods is that of energy-minimization. We will particularly focus on root-node energy-minimization \cite{root-node}, which shares the CF-splitting design of reduction-based methods. One key part of energy-minimization is the use of constraints during the minimization process.  For efficiency reasons, the sparsity pattern of $P$ is constrained.  Let $\mathcal{W}$ be the sparsity pattern for the F-rows in $P$.  We denote that $P$ obeys the sparsity pattern constraint with 
\begin{equation}
\label{eqn:sparsityconst}
P \in \begin{bmatrix} \mathcal{W}\; I \end{bmatrix} \quad \mbox{or} \quad W \in \mathcal{W}.
\end{equation}
For approximation property reasons, a near nullspace mode constraint is also typically enforced where
\begin{equation}\label{eq:Pcontraint}
    B \in \mbox{span}(P),
\end{equation}
and $B \in \RR^{n,k}$ is a set of $k$ global near nullspace modes.  With $P$ of the form~\eqref{eqn:basicsplit} and equation~\eqref{eq:Pcontraint}, this then implies that $B_c = [0\; I]\, B$, i.e., the fine-grid $B$ is injected to the coarse-grid, along with the constraint,  
\begin{equation}
   \label{eqn:global_const1}
    P B_c = B.
\end{equation} 
%\textcolor{red}{(Karsten) Assuming $P = \begin{bmatrix}W\\I\end{bmatrix}$ there is really nothing to be said here, as~\eqref{eq:Pcontraint} already implies~\eqref{eqn:global_const1}. The latter paragraph seems redundant to me.  JBS:  Yes, you're right.  I modified this last paragraph to remind the reader that equation~\eqref{eqn:global_const1} is naturally implied.  We'll use this constraint~\eqref{eqn:global_const1} later, so I decided for now, to keep this equation here.}

Similar to $\ell$AIR, energy-minimization AMG takes a column-oriented view.  Letting $P_j$ denote column $j$, construction of transfer operators is based around a minimization along the lines of
\begin{equation}
\label{eqn:rn_min}
P = \argmin_P \sum_j \| P_j \|_{\mathcal{X}}^2 \mbox{, such that constraints (\ref{eqn:global_const1}) and (\ref{eqn:sparsityconst}) are satisfied,}
\end{equation}
where $\mathcal{X}$ denotes some norm, usually $A$ for SPD operators or $A^*A$ for nonsymmetric matrices. This column-oriented view is analogous to $\ell$AIR in \eqref{eq:system}, but here we are minimizing in some energy-induced inner product, rather than solving each block equation exactly as in $\ell$AIR. 

Interestingly, this distinction has more profound consequences for the efficacy of the methods. For SPD operators, root-node uses projected CG for equation (\ref{eqn:rn_min}); without constraints (\ref{eqn:global_const1}) and (\ref{eqn:sparsityconst}), such a minimization procedure converges to \pideal\ for $A$ \cite[Lemma 4.2]{root-node}. However in the nonsymmetric case, root-node uses a projected GMRES for equation \eqref{eqn:rn_min}, which in turn (without constraints (\ref{eqn:global_const1}) and (\ref{eqn:sparsityconst})), converges to $\pideal$ for $A^* A$ \cite[Lemma 4.6]{root-node}.
%the 2-norm of the residual of equation (\ref{eq:w-formula}).  
Indeed, by posing the unconstrained problem as an (overdetermined) minimization, root-node is required to define an energy-induced inner product through the normal equations, which in turn leads to the approximation of $\pideal$ for the normal equations rather than directly for the operator of interest. In contrast, the base algorithm of $\ell$AIR directly approximates (and converges to) $\pideal$ for the original operator $A$. This is possible because the algorithm is built around local matrix approximation \eqref{eq:z-formula} rather than a matrix-induced norm, which does not naturally exist for non-SPD matrices. 

As it turns out, which ideal operators we are trying to approximate (without constraints) is an important distinction for highly advective problems, which typically generate discretization matrices that are close to block lower-triangular in some ordering \cite{air1}. For such cases \cite{air1}, $\ell$AIR achieves good sparse approximations to $A_{ff}^{-1}$ for computing $\rideal$ and overall excellent AMG convergence. However if one were to approximate ideal transfer operators based on $A^*A$ instead of $A$, the block lower-triangular structure that is key to achieving sparse and accurate approximations to $A_{ff}^{-1}$ and $\rideal$ is completely lost. The natural result is that a good sparse approximation to $A_{ff}^{-1}$ becomes more difficult to compute
(see \cite{air1}, Section 4 for more discussion), and the resulting AMG method is significantly less effective. Thus although the underlying problem that energy-minimization is based around, namely approximating $AP = \mathbf{0}$, is almost equivalent to $\ell$AIR, by formulating via energy minimization the resulting class of methods yield lackluster performance on highly advective problems. 

\subsection{The best of both worlds}

Looking carefully at the $\ell$AIR and energy-minimization approaches leads us to consider a new interpretation combining the best of both worlds. By directly approximating $\rideal$ of the original operator $A$, $\ell$AIR is able to construct highly effective transfer operators for advection-dominated problems; in contrast, mode constraints are fundamental to the efficacy of energy-minimization methods for diffusion dominated problems (indeed, without constraints energy minimization alone is generally not effective). Although $\ell$AIR is based around approximation of ideal transfer operators, we can also think in terms of approximation properties -- consider each row of $R$ as the local fine-grid mode being restricted to a given C-point, where these modes should be local representations of the smooth error. This is exactly what happens in classical smoothed aggregation \cite{VaMaBr1996}, as well as when bilinear interpolation is used in geometric MG for diffusion. Thus we propose a new constrained $\ell$AIR (\clair) method that is built around directly approximating the ideal transfer operators of $A$ in an $\ell$AIR framework, regardless of whether $A$ is SPD or nonsymmetric, while also incorporating mode constraints as in energy minimization to improve robustness in diffusion dominated problems. 

In summary, the proposed \clair\ approach combines strengths of root-node and $\ell$AIR, with the goal of a robust solver in both the advective and diffusive regimes.  The \clair\ approach for constructing $\ell$AIR interpolation with constraints is directly related to solving \eqref{eq:z-formula} and thus is a constrained approximation of \pideal\ for the original operator, in contrast to root-node, which targets the normal equations in the nonsymmetric setting. Also, all of our proposed generalizations can be used to build $R$ and/or $P$.

\section[]{Constrained $\ell$AIR transfer operators}\label{sec:iter-air}

The main goals of our new reduction-based AMG method built around $\ell$AIR-style interpolation, is to have a solver that (i) works well for both advection and diffusion problems, (ii) allows for the incorporation of mode interpolation constraints (local or global), and (iii) allows for an $\ell$AIR-like algorithm to be applied to matrices with large stencils (i.e., when the inverted matrix windows are large, which is currently expensive). 
To achieve these goals, we consider mixing ideas from $\ell$AIR, which works well for advection, with energy-minimization and smoothed aggregation (SA) \cite{VaMaBr1996}, which work well for anisotropic diffusion problems and allow for mode constraints.  Another key component of the algorithm for diffusion dominated problems, described in detail in a latter section, is our use of a root-node aggregation-based coarsening algorithm.

The overall $\ell$AIR interpolation scheme we consider is described as follows.  Similar to the energy-minimization discussion above, we will 
enforce that $P$ obeys the sparsity pattern constraint (\ref{eqn:sparsityconst}).
Regarding the sparsity pattern $\mathcal{W}$ for the $F$-rows, let $\mathcal{W}_i$ denote the sparsity pattern for the $i$th column of $W$, that is $\mathcal{W}_i = \{m_1, \dots, m_{T_i} \}$ and the number of nonzeros in column $i$ equals $T_i = |\mathcal{W}_i|$.
Define \aff{i} as $A_{ff}$ restricted (in rows and columns) to the sparsity pattern $\mathcal{W}_i$, and 
 \afc{i} and \w{i} as $A_{fc}$ and $W$ restricted to column $i$, respectively, with rows restricted to the sparsity pattern of $\mathcal{W}_i$.
The standard $\ell$AIR approach for finding each \w{i} is then equivalent to solving: for each $i\in n_c$ solve
\begin{equation}
    \label{eqn:airwi}
    \aff{i} \w{i} = - \afc{i}.
\end{equation}
If we consider solving \eqref{eqn:airwi} at each $i$, we can rewrite the procedure as the following global block diagonal system, where we assume $n_c$ points on the coarse grid:
\begin{equation}
    \label{eqn:Affdefn}
    \aff{*} \w{*} := 
    \begin{bmatrix}
    \aff{0} &           &           & \\
            & \aff{1}   &           & \\
            &           & \ddots    & \\
            &           &           & \aff{n_c}
    \end{bmatrix}
    \begin{bmatrix}
    \w{0} \\ \w{1} \\ \vdots \\ \w{n_c} 
    \end{bmatrix}
    =
    -
    \begin{bmatrix}
    \afc{0} \\ \afc{1} \\ \vdots \\ \afc{n_c}
    \end{bmatrix}
    = - \afc{*}.
\end{equation}
The solution of system \eqref{eqn:Affdefn} gives us classic AIR interpolation. As a side note, let $W$ be stored in a sparse matrix format, then the global vector of all the nonzeros of $W$, denoted \w{*}, corresponds to the data array for the sparse representation of $W$ when stored in compressed column format.

\subsection{Proposed Method with Global Constraints}
Given the above formulation of $\ell$AIR in \eqref{eqn:Affdefn}, we define the procedure for incorporating a global mode interpolation constraint into the approach. To enforce the mode interpolation constraint (\ref{eqn:global_const1}), define the matrix $Q$, such that $Q \w{*}$ is equivalent to $P B_c$, i.e., the entries of $B_c$ populate $Q$ such that the constraint equation \eqref{eqn:global_const1} is equivalent to saying
\begin{equation}
    \label{eqn:Qdef}
    Q \w{*} = \begin{bmatrix} \B{0}|_F \\ \B{1}|_F \\ \vdots\\ \B{k}|_F \end{bmatrix} = \B{*}|_F,
\end{equation}
where $\B{i}$ is the $i$th column of $B$ and $\B{*}$ represents the columns of $B$ stacked vertically.  Equation \eqref{eqn:Qdef} is also equivalent to the constraint that $W B_c = B|_F$.

Thus our constrained minimization problem is
\begin{subequations}
\begin{align}
\min_{\w{*}} \left\| \afc{*}  + \aff{*} \w{*} \right\|_2  \label{eqn:minproba} \\
\mbox{subject to } Q \w{*} = \B{*}|_F.  \label{eqn:minprobb}
\end{align}
\end{subequations}
This is an equality constrained minimization problem, with various 
solution approaches \cite{GoHrNo2001}.

\subsubsection{Direct Solution to Minimization Problem}
% See  http://www.seas.ucla.edu/~vandenbe/133A/lectures/cls.pdf
The minimization problem (\ref{eqn:minproba})--(\ref{eqn:minprobb}) can be solved directly via
the following KKT system
\begin{equation}
    \label{eqn:KKT}
    \begin{bmatrix}
    (\aff{*})^T \aff{*} & Q^T \\
    Q       &  \mathbf{0}   \\
    \end{bmatrix}
    \begin{bmatrix}
    \w{*} \\ \lambda
    \end{bmatrix}
    =
    \begin{bmatrix}
    - (\aff{*})^T \afc{*} \\ \B{*}|_F
    \end{bmatrix}.
\end{equation}
The (1,1) block of equation (\ref{eqn:KKT}) uses the normal equations, as the minimization principle requires
an SPD matrix and we do not assume that $\aff{*}$ is SPD.

System \eqref{eqn:KKT} could be solved exactly via a Schur complement approach.  If this is done, letting $\bar{A}^{-1} = \left( (\aff{*})^T \aff{*} \right)^{-1}$, the solution is
\begin{align}
    \label{eqn:KKTsoln}
    \w{*} = & \left(I - \bar{A}^{-1} Q^T( Q \bar{A}^{-1} Q^T)^{-1} Q\right) \bar{A}^{-1} (\aff{*})^T \afc{*}\; + \; \left( \bar{A}^{-1} Q^T (Q \bar{A}^{-1} Q^T)^{-1} Q^T \right)^{-1} \B{*}|_F,
\end{align}
where $Q$ is the rectangular constraint matrix from above. Upon inspection, computing (\ref{eqn:KKTsoln}) is an expensive endeavour, especially $( Q \bar{A}^{-1} Q^T)^{-1}$ and potentially, the transpose of $\aff{*}$. 
To avoid these costs, we consider an iterative approach related to energy-minimization AMG \cite{OlScTu2011}. 

\subsubsection{Iterative Solution to Minimization problem}

A review of approaches for obtaining an inexpensive iterative solution to~\eqref{eqn:KKT} is given in~\cite{GoHrNo2001}.  One option previously used for AMG (e.g., for root-node) is projected Krylov methods. Here, an initial guess (tentative interpolation) $\witer{*}{t}$ that satisfies the constraints is constructed,
so that $Q \witer{*}{t} = \B{*}|F$. Then, a projected Krylov method using $Q$ is applied to solve the interpolation equation (\ref{eqn:Affdefn}). 
%During this Krylov solve, each new Krylov vector 
%is projected orthogonally onto the nullspace of $Q$ with $I - Q^T (Q Q^T)^{-1} Q$.  The result is that the 
%initial guess plus the update from a linear combination of the Krylov vectors satisfies the constraints 
%\cite{GoHrNo2001}. Such an approach avoids the most expensive aspects of computing (\ref{eqn:KKTsoln}). 
The inverse $( Q \bar{A}^{-1} Q^T)^{-1}$ is not required and the transpose is not needed, because we only compute the residual for the interpolation equation (\ref{eqn:Affdefn}) when computing a descent direction for equation (\ref{eqn:minproba}).  The previous works \cite{OlScTu2011,root-node} use such a projected CG and GMRES approach for the symmetric and nonsymmetric cases, respectively.  However as noted in Section \ref{sec:enmin_modeconst}, the nonsymmetric GMRES approach will approximate \pideal\ in the constraint space for the normal equations, which is not desirable.

Thus here, we consider a simpler and cheaper linear
iteration for minimizing (\ref{eqn:minproba}) that approximates \pideal\ for the original operator in the constraint space.  We find that this approach yields effective restriction and interpolation operators.  
%Considering possible benefits from Krylov approaches to solving the interpolation equation (\ref{eqn:Affdefn}) is future work.
% Simple Projected CG reference: https://antonior92.github.io/posts/2017/05/projected-CG/#:~:text=The%20projected%20CG%20method%20is,subject%20to%20Ax%3Db

An additional cost consideration is whether or not to precondition such an iterative solve.  Since the 
matrix $\aff{*}$ is block diagonal, each block could be inverted (or approximately inverted). Thus,
we consider the use of approximate inverse preconditioners of the following form:
\begin{equation}
    \affinv{*} \approx \widehat{\affinv{*}} =
    \begin{bmatrix}
    \widehat{\affinv{0}} &                        &           & \\
                         & \widehat{\affinv{1}}   &           & \\
                         &                        & \ddots    & \\
                         &                        &           & \widehat{\affinv{n_c}}
    \end{bmatrix},
\end{equation}
where $\widehat{\affinv{i}}$ represents an approximate inverse to that block.  Importantly, this inverse is \textit{local} and can be generated in a variety of ways, e.g., diagonal, GMRES, or ILU approximations to each individual block inverse.  This is \textit{in contrast} to the ``classic" energy-minimization which uses a single global Krylov polynomial to simultaneously approximate all block inverses. It is our belief that the block inverse approach is more effective. In particular, a global Krylov polynomial effectively assumes that each block has the same minimizing polynomial, whereas in reality each block will likely have its own unique minimizing polynomial (distinct from other blocks). The local approach allows us to calculate more accurate local inverses faster through locally accurate approximations and polynomials, or to solve each local equation directly.

%\begin{remark}
%   In the original paper \cite{OlScTu2011}, GMRES was applied directly to the
%   interpolation equation $A P = 0$, with a constraint satisfying initial
%   guess, and every Krylov vector projected on the null space of the
%   constraints. That is, the analogous procedure as projected CG.  Here, if we
%   are interested in doing something similar, GMRES would be applied to solve
%   the interpolation equation $\aff{*} \w{*} = - \afc{*}$, subject to the
%   constraints. GMRES still minimizes something ``quadratic", i.e., the
%   residual norm squared.  

%   But, is the projected GMRES from \cite{OlScTu2011} guaranteed to converge
%   like the projected CG?  I'm not entirely sure.  My gut says yes, with a
%   sufficient initial guess, as the Krylov space will eventually span
%   everything in the constraint space.  However, it may be that GMRES will
%   only converge to the best solution relative to the specific initial guess
%   used.  
%\end{remark}

\subsubsection[]{Proposed Algorithm for Computing $R$ and $P$}
\label{sec:prop_algorithm}

We now present our simple iterative scheme for minimizing
(\ref{eqn:minproba})--(\ref{eqn:minprobb}) in Algorithm \ref{alg:iterativeAIR}.
The approach is a projected one-step iteration, which iteratively finds
AIR-like interpolation operators with constraints. For restriction, the simplest approach on paper applies Algorithm \ref{alg:iterativeAIR} to $A^T$. However if forming a transpose is computationally expensive, one can also reformulate Algorithm \ref{alg:iterativeAIR} relative to $R A = 0$, as in the original $\ell$AIR method \cite{Ben}. Then, the algorithm will still extract small submatrices $\aff{i}$, but after the extraction these submatrices will be transposed. 
%Note, the below iteration could easily be extended to Krylov methods as in \cite{OlScTu2011}.

As input, the algorithm takes the operator $A$ and corresponding strength of
connection matrix $S$.  Unless noted otherwise, we use the classical strength
measure \cite{JWRuge_KStuben_1987a}.  The input sparsity degree pattern $m$
determines how wide the sparsity pattern in $P$ will be, with $m=1$
corresponding to distance-one interpolation based on the sparsity pattern of
$S_{fc}$.  Most commonly, we will use $m=2$, which expands the sparsity to
consider degree-two connections, similarly to $\ell$AIR and root-node.  Next,
the input ``Coarsen type" considers whether a classical ``FC" coarsening, e.g.,
Ruge-St\"{u}ben coarsening \cite{JWRuge_KStuben_1987a}, or an aggregation-based
coarsening is used.

The coarsen type controls the base sparsity pattern for $P$.  If classical FC
coarsening is used, then the base pattern $T$ comes from the FC rows of the
strength matrix, $S_{fc}$. If an aggregation-based coarsening is used, which is
significantly more aggressive, then the ``Aggregation Operator"\footnote{\label{foot:agg} The
``Aggregation Operator" is generated by the algorithm from \cite{VaMaBr1996}.
First, an aggregation (disjoint splitting) is computed with a greedy graph
algorithm that finds the next degree-of-freedom (root node) with all unmarked
neighbors and places those degrees-of-freedom in an aggregate and then marks
them. A clean-up phase takes all unmarked degrees-of-freedom and places them in
an adjacent aggregate.  The root node of each aggregate is treated as a
C-point.  This procedure produces a CF-splitting that is significantly more
aggressive (fewer C-points) than is typical for classical AMG or rAMG.  The
``Aggregation Operator" is then a binary matrix where column $i$ corresponds to
aggregate $i$ (i.e., the $i$th C-point) and this column is nonzero only for the
degrees-of-freedom in aggregate $i$.  See also \cite{root-node} which constructs initial sparsity patterns in this manner.} is used for $T$. This base pattern $T$ is then expanded 
based on the strength of connection matrix $S$ via $m-1$ multiplications in line \ref{alg:expandsparsity}.
We note that basing the interpolation pattern on strong connections is the same 
strategy as used by $\ell$AIR and root-node, and this approach allows us to generate nearly identical patterns.

The least squares solution for line \ref{alg:constraint1} is computed using a psuedoinverse based on $B_c$ restricted to the sparsity pattern of row $i$, $w^{\{i\},t}$. 
These pseudoinverses can be locally precomputed for efficiency and are typically small.

The projection operation in line \ref{alg:constraint2} takes each new update
$\witerupdate{*}{k}$ and projects it so that $Q \witerupdate{*}{k} = 0$.  That is, this
operation ensures that each update $\witerupdate{*}{k}$ does not disturb the mode
interpolation relationship $Q \witer{*}{t} = \B{*}|F$.  The projection operation
with $Q$ can be implemented locally using the same strategy as for line \ref{alg:constraint1} (see \cite{OlScTu2011}).

\begin{algorithm}
\caption{\clair\ Algorithm}\label{alg:iterativeAIR}
\begin{algorithmic}[1]
   \STATE \textbf{Input}: Matrix $A$
   \STATE $\phantom{\mbox{\textbf{Input}:}}$ Strength matrix $S$ for interpolation
   \STATE $\phantom{\mbox{\textbf{Input}:}}$ Mode constraint vector(s) $B$
   \STATE $\phantom{\mbox{\textbf{Input}:}}$ Sparsity pattern degree $m$
   \STATE $\phantom{\mbox{\textbf{Input}:}}$ Coarsen type, either FC or Agg
   \STATE \textbf{Output}: Interpolation $P$, in the form of the weight block \witer{*}{t} \vspace{4pt}
   \STATE \textbf{set} tentative prolongation \witer{*}{t}, corresponding to $[-A_{fc}, I]$
   \STATE \textbf{set} base sparsity pattern $T$ based on coarsening type
     \STATE $\phantom{**}$ \textbf{if} Coarsen type is FC
     \STATE $\phantom{*****}$ $T \leftarrow [S_{fc}, I]$
     \STATE $\phantom{**}$ \textbf{else if} Coarsen type is Agg
     \STATE $\phantom{*****}$ $T \leftarrow \mbox{Aggregation Operator}$\vspace{4pt}

   \STATE \textbf{set} expanded sparsity pattern to match F-row structure of $S^{m-1} T$ \label{alg:expandsparsity}\newline
    $\mathcal{W} \leftarrow \mbox{sparsity\_pattern}\left( (S^{m-1} T)|_F \right)$
   \STATE \textbf{expand} \witer{*}{t} to store (possibly zero) entries for every nonzero in $\mathcal{W}$ 
   \STATE \textbf{enforce} constraints on \witer{*}{t} such that $Q \witer{*}{t} = \B{*}|F$, by taking row $i$, $w^{\{i\},t}$, and computing  \label{alg:constraint1}\newline
       $w^{\{i\},t} \leftarrow$ least squares solution to $w^{\{i\},t} B_c = B$ \vspace{5pt}

   \STATE \textbf{compute} exact or approximate block inverses for $\widehat{\affinv{*}}$ \label{alg:invcompute}
   \FOR{$k = 1, 2, ...$}
   \STATE %Solve (possibly inexactly): $\aff{*}\, \witerupdate{*}{k} = -\afc{*} - \aff{*}\, \witer{*}{t}$\vspace{5pt}
          $\phantom{*}$ \textbf{compute residual update} to minimize equation (\ref{eqn:minproba}), using $\mathbf{0}$ initial guess for $\witerupdate{*}{k}$\,:
          $$\witerupdate{*}{k} \leftarrow \widehat{\affinv{*}} \left( \left(-\afc{*} - \aff{*}\, \witer{*}{t} \right) - \aff{*} \mathbf{0} \right) $$
   \STATE $\phantom{*}$ \textbf{project update}: $\witerupdate{*}{k} \leftarrow (I - Q^T (Q Q^T)^{-1} Q) \witerupdate{*}{k}$ \label{alg:constraint2}
   \STATE $\phantom{*}$ \textbf{update interp}: $\witer{*}{t} \leftarrow \witer{*}{t} + \witerupdate{*}{k}$ \label{alg:finalupdate}
   \ENDFOR
   \STATE \textbf{set} final interpolation weights: $\w{*} \leftarrow \witer{*}{t}$
   \STATE \textbf{Return} \w{*}
\end{algorithmic}
\end{algorithm}


\begin{remark}
    If the constraints are removed from Algorithm \ref{alg:iterativeAIR} and the exact inverse $\affinv{*}$ is used, then $\ell$AIR is recovered.  That is, removing the constraint lines \ref{alg:constraint1} and
    \ref{alg:constraint2} and assuming $k=1$ yields  the final update in line \ref{alg:finalupdate} of
    \begin{align*}
        \witer{*}{t} &\leftarrow \witer{*}{t} + \witer{*}{1}\\
                     & \leftarrow \witer{*}{t} + \affinv{*} \left(-\afc{*} - \aff{*}\, \witer{*}{t} \right) \\
                     & \leftarrow - \affinv{*} \afc{*}
    \end{align*}
    However, we always use the constraints in Algorithm \ref{alg:iterativeAIR}, making \clair\ distinct from $\ell$AIR.
\end{remark}

% OAK: I'm a bit confused, the first line in the previous remark states that AIR uses the exact inverse, but then the remark below says that when the exact inverse is used, it is only "similar" to what is done in AIR. Am I missing something, or is this a bit contradictory?
% JBS: I added a new sentence to the above remark, at the end.  Hopefully, this clarifies things
\begin{remark}
   We will most often use the exact inverse $\affinv{*}$ for
   $\widehat{\affinv{*}}$ in line \ref{alg:invcompute}, similar to $\ell$AIR.
   In this case, Algorithm \ref{alg:iterativeAIR} is run with $k=1$, i.e.,
   the output of the algorithm does not change for $k>1$.
\end{remark}



%% \begin{remark}
%% Here, we examine one iteration of Algorithm \ref{alg:iterativeAIR} when using the exact inverse
%% $\affinv{*}$.  We see that the solution is \textbf{not} the same solution as obtained from the KKT 
%% system (\ref{eqn:KKTsoln}).  The solution is simpler and \textbf{dependent on the initial condition} $\witer{*}{t}$.
%% 
%% Moving through each step of the algorithm, we derive an expanded form for the return value $\witer{*}{t}$.
%% \begin{subequations}
%% \begin{align}
%%     \witer{*}{t} & \leftarrow \witer{*}{t} + (I - Q^T(Q Q^T)^{-1} Q) \witer{*}{1} \\
%%                  & \leftarrow \witer{*}{t} + (I - Q^T(Q Q^T)^{-1} Q) (\affinv{*}(-\afc{*}) - \witer{*}{t}) \\
%%                  & \leftarrow (I - Q^T (Q Q^T)^{-1} Q) (-\affinv{*} \afc{*}) + Q^T (Q Q^T)^{-1} Q \witer{*}{t} \\
%%                  & \leftarrow (I - Q^T (Q Q^T)^{-1} Q) (-\affinv{*} \afc{*}) + \witer{*}{t}
%% \end{align}
%% \end{subequations}
%% where the last step holds because $\witer{*}{t}$ satisfies the constraints.
%% 
%% Comparing this value for $\witer{*}{t}$ with the KKT solution (\ref{eqn:KKTsoln}) we see that this solution is 
%% much computationally cheaper, and \textbf{depends} on the initial condition.  Practical experience with the related 
%% root-node method \cite{OlScTu2011} and other energy-minimization works indicates that this approximation nonetheless works well.
%% \end{remark}

\subsubsection{Comparison to Root-node}

We now clearly distinguish the similarities and differences between \clair\ and root-node. The \clair\ approach shares with root-node (i) the same mode and sparsity constraints (\ref{eqn:global_const1}) and (\ref{eqn:sparsityconst}), (ii) the ability to iteratively find $P$, and (iii) approximates some form of $\pideal$.

Regarding differences, root-node uses a simple diagonal approximation to $A_{ff}^{-1}$, whereas \clair\ uses a potentially much more powerful approximation $\widehat{\affinv{*}}$, where each block is often inverted exactly\footnote{Note that \clair\ also supports using a diagonal inverse similar to root-node, where each block of $\widehat{\affinv{*}}$ would be the local diagonal inverse.  However, this approximation does not always lead to effective AMG hierarchies in our experiments, e.g., for the 3D Poisson problem. Developing more effective approximations is future research.}.  
%We additionally note that there is not a simple linear mapping of $\widehat{\affinv{*}}$ to an $n_f \times n_f$ operator ``$X$" such that $-\widehat{\affinv{*}} \afc{*}$ yields equivalent output to $X A_{fc}$.  
% Additional distinctions are as follows.
%In summary, key differences between root-node and \clair\ are as follows. For the nonsymmetric case, root-node approximates $\pideal$ for $A^* A$, which is not desirable for our target advection problems, while \clair\ approximates $\pideal$ for $A$.  Root-node uses a simple diagonal preconditioner for $A_{ff}$, while \clair\ uses a much more powerful approximation based on $\ell$AIR. 
The proposed \clair\ method also uses a simple one-step iteration that is cheaper computationally than root-node, with no required global storage of Krylov vectors or the additional computations and communications required to maintain the (globally) orthogonal Krylov basis. Lastly, root-node has only considered fast aggregation-based coarsening, whereas \clair\ will support and explore both fast and slow coarsening, targeting diffusive and advective problems, respectively.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% This block discusses differences between root-node and classic ell-AIR
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Root-node AMG minimizes the defect in the equation 
%\begin{equation}
%   \label{eqn:rootnode}
%   AP = 0,
%\end{equation}
%subject to the mode interpolation constraints (\ref{eqn:global_const1}) and %the sparsity pattern constraint 
%\begin{equation}
%   \label{eqn:rootnodesparsity}
%   P \in \begin{bmatrix} \mathcal{W}\\ I \end{bmatrix}.
%\end{equation}
%The constraints ensure a nonzero solution. 
%
%Typically, equation (\ref{eqn:rootnode}) is solved column-wise with a few iterations of
%projected CG or GMRES (depending on symmetry) with a diagonal preconditioner.
%Reordering equation (\ref{eqn:rootnode}) according to F- and C-points yields 
%\begin{equation}\label{eq:w-formula}
%   \begin{bmatrix}
%      A_{ff} & A_{fc} \\
%      A_{cf} & A_{cc} 
%   \end{bmatrix}
%   \begin{bmatrix}
%      W \\ I 
%   \end{bmatrix} =
%   \begin{bmatrix} 
%   0 \\ 0 
%   \end{bmatrix},
%\end{equation}
%where application of the sparsity pattern yields $W \in \mathcal{W}$. 
% Depending on how the defect for the $W$ is computed, the minimization process can converge to $\pideal$ for $A$ or $A^* A$.  
%
%For restriction, root-node instead minimizes the defect in 
%\begin{equation}
%   \label{eqn:rootnodeAT}
%   A^T R^T = 0,
%\end{equation}
%subject to mode interpolation constraints on $R^T$ analogous to
%(\ref{eqn:global_const1}), (i.e., $R^T B_c = B$), and a sparsity pattern constraint on $R^T$ analogous to
%(\ref{eqn:sparsityconst}).  It is then easy to show that the root-node process for restriction is equivalent
%to solving this transposed analogue to equation (\ref{eqn:Affdefn}), 
%\begin{equation}
%    \label{eqn:Affdefn2}
%    \aff{*,T} \w{*} := 
%    \begin{bmatrix}
%    \aff{0,T} &           &           & \\
%              & \aff{1,T} &           & \\
%              &           & \ddots    & \\
%              &           &           & \aff{n_c,T}
%    \end{bmatrix}
%    \begin{bmatrix}
%    \w{0} \\ \w{1} \\ \vdots \\ \w{n_c} 
%    \end{bmatrix}
%    =
%    -
%    \begin{bmatrix}
%    \acf{0} \\ \acf{1} \\ \vdots \\ \acf{n_c}
%    \end{bmatrix}
%    = - \acf{*},
%\end{equation}
%subject to mode interpolation constraints.  Note that $\w{i,T}$ denotes here
%row $i$ of $R$.  Also, note that this process iteratively solves for so-called
%ideal restriction $R = [ -A_{cf} A_{ff}; I]$, subject to the sparsity and mode interpolation
%constraints.
%In summary, root-node computes an AIR-like $R$ and $P$, but with the following
%differences: (i) mode interpolation constraint(s), (ii) an iterative CG or
%GMRES solver with diagonal preconditioner, and (iii) a typically much sparser
%$C/$F splitting from standard aggregation.  

%We recall that, root-node does very well for diffusion (similar in complexity
%to classic SA) and also OK for advection-diffusion dominated problems \cite{Jacob}.  We thus consider a combined approach  that uses certain aspects of root-node AMG in 
%an $\ell$AIR framework in order to get a solver that works well for strong advection and also when 
%the diffusion becomes dominant. 
%In other words, can we utilize these techniques from root-node with AIR: (i) 
%sparse and dense $C/F$ splittings, (ii) mode interpolation constraints for diffusion and advection, 
%(iii) inexact block solves.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Commented out AMG Setup for CLAIR, could be added back in
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \subsubsection{AMG Setup Algorithm for \clair}
%% 
%% Since \clair\ requires a few items not always present in an AMG setup hierarchy, e.g., $B$ and an interpolation strength-of-connection operator, we now describe an appropriate AMG setup algorithm in Algorithm \ref{alg:amgsetup}.  We note that $\ell$AIR also uses a separate strength matrix for interpolation. 
%% 
%% The algorithm begins by looping over each level in the AMG hierarchy, until the matrix is below some threshhold, \texttt{max\textunderscore size}.  During the setup for each level, the first task is to compute the strength-of-connection matrix for coarsening via the classic measure \cite{JWRuge_KStuben_1987a}, followed by computing the C,F splitting according to either Ruge-St\"{u}ben first or second pass \cite{JWRuge_KStuben_1987a} or via the aggregation operator as described in footnote \ref{foot:agg}.  Next, the base or initial sparsity pattern $T$ is constructed, according to either the FC-splitting or the aggregation operator.  Following that, the mode constraint vector(s) $B$ are smoothed and restricted to the next coarser level, thus ensuring that span$(P_0 P_1 \dots P_k)$ always contains the finest level smoothed $B$. The final phase constructs interpolation and restriction, based on the symmetry of the matrix and whether classical interpolation \cite{JWRuge_KStuben_1987a} is desired.
%% 
%% \begin{algorithm}
%% \caption{AMG Setup Algorithm for \clair}\label{alg:amgsetup}
%% \begin{algorithmic}[1]
%% 
%%    \STATE \textbf{Input}: Matrix $A$
%%    \STATE $\phantom{\mbox{\textbf{Input}:}}$ Mode constraint vector(s) $B$
%%    \STATE $\phantom{\mbox{\textbf{Input}:}}$ Threshold for maximum size of coarsest level  \texttt{max\textunderscore size}
%%    \STATE $\phantom{\mbox{\textbf{Input}:}}$ Coarsening and interpolation strength tolerances $\theta_c$, $\theta_p$, respectively 
%%    \STATE $\phantom{\mbox{\textbf{Input}:}}$ Coarsen type, either FC or Agg
%%    \STATE $\phantom{\mbox{\textbf{Input}:}}$ Interpolation degree $m$
%%    \STATE $\phantom{\mbox{\textbf{Input}:}}$ Problem type, symmetric or nonsymmetric 
%%    
%%    \STATE \textbf{Output}: Operators for each level, $\{A_0, A_1, \dots A_L\}$, 
%%    \STATE $\phantom{\mbox{\textbf{Output}:}}$ Restriction and interpolation operators for each level, $\{R_0, R_1, \dots R_L\}$, $\{P_0, P_1, \dots P_L\}$ \vspace{4pt}
%% 
%%    \STATE $k \leftarrow 0$
%%    \STATE \textbf{set} fine-level matrix and mode constraint vectors, $A_k, B_k \leftarrow A, B$
%%    \STATE \textbf{while} \texttt{size}($A_k$) $>$ \texttt{max\textunderscore size} \vspace{4pt}
%%    
%%    \STATE $\phantom{**}$ \textbf{set} strength matrix for coarsening, $S^{(c)} \leftarrow \mbox{strength}(A_k, \theta_c)$
%%    \STATE $\phantom{**}$ \textbf{set} F,C splitting and base sparsity pattern $T$ 
%%    \STATE $\phantom{****}$ \textbf{if} Coarsen type is FC
%%    \STATE $\phantom{******}$ F,C $\leftarrow$ RugeSt\"{u}ben$(S^{(c)})$
%%    \STATE $\phantom{******}$ $T \leftarrow [S^{(c)}_{fc}, I]$
%%    \STATE $\phantom{****}$ \textbf{else if} Coarsen type is Agg
%%    \STATE $\phantom{******}$ F,C $\leftarrow$ Aggregation$(S^{(c)})$
%%    \STATE $\phantom{******}$ $T \leftarrow \mbox{Aggregation Operator}$\vspace{4pt}
%%    
%%    \STATE $\phantom{**}$ \textbf{relax} constraint vectors, $B_k \leftarrow \mbox{jacobi}(A_k, B_k)$
%%    \STATE $\phantom{**}$ \textbf{recursively define} constraint vectors with injection, $B_{k+1} \leftarrow [0, I] B_k$
%%    \STATE $\phantom{**}$ \textbf{set} strength matrix for interpolation, $S^{(p)} \leftarrow \mbox{strength}(A_k, \theta_c)$ \vspace{4pt}
%%    \STATE $\phantom{**}$ \textbf{set} interpolation
%%    \STATE $\phantom{****}$ \textbf{if} Classical interpolation
%%      \STATE $\phantom{*******}$ $P_k \leftarrow \mbox{classical\textunderscore interp}(A_k, S^{(p)})$
%%      \STATE $\phantom{****}$ \textbf{else}
%%      \STATE $\phantom{*******}$ $P_k \leftarrow \mbox{\clair}(A_k, S_{(p)}, B_k, m, \mbox{Coarsen type})$ \vspace{4pt}
%%    
%%    \STATE $\phantom{**}$ \textbf{if} symmetric 
%%    \STATE $\phantom{****}$ $R_k \leftarrow P_k^T$
%%    \STATE $\phantom{**}$ \textbf{else if} nonsymmetric 
%%    \STATE $\phantom{****}$ $R_k \leftarrow \mbox{\clair}(A_k^T, S^{(p)}, B_k, m, \mbox{Coarsen type})$ \vspace{4pt}   
%%    \STATE \textbf{Return} $\{A_0, A_1, \dots A_L\}$, $\{R_0, R_1, \dots R_L\}$, $\{P_0, P_1, \dots P_L\}$
%% \end{algorithmic}
%% \end{algorithm}


\section{Numerical Results}    
\label{sec:num}

We now present supporting numerical results for \clair, 
comparing against root-node and $\ell$AIR for a variety of classic 
model diffusion problems and for advection-diffusion problems over a range of diffusion parameters.  The proposed solver is shown to (i) achieve more desirable operator complexities than $\ell$AIR, (ii) compare well against the root-node solver for symmetric diffusion problems, where root-node is already known to perform well, and (iii) be more robust regarding parameter tuning when compared to $\ell$AIR, e.g., for the advection-diffusion problems when going from the purely advective to highly diffusive regimes.

Our basic test framework is as follows.  The $\ell$AIR and root-node solvers use the library implementations in PyAMG \cite{BeOlScSo2023} and \clair\ is also implemented in PyAMG\footnote{The \clair\ implementation is in the \texttt{CF\textunderscore rootnode} branch, commit bf56195b55a27bd99625c385ee9ba1df8814f764.}.  We use V(1,1) cycles as a preconditioner for CG and GMRES in the symmetric and nonsymmetric settings, respectively. The smoother choices respect the reduction framework.  For presmoothing, we use 1 iteration of CFF-weighted-Jacobi, i.e., one Jacobi sweep on the C-points, followed by two Jacobi sweeps on the F-points.  The weight is equal to $1/\rho(D^{-1}A)$. (Here, $\rho(\cdot)$ denotes the spectral radius, which is approximated numerically by 15 iterations of Arnoldi.) For postsmoothing, we use 1 iteration of FFC-weighted-Jacobi, which is defined analogously to CFF. Such relaxation methods are chosen for simplicity, parallelism, and the preservation of a symmetric preconditioner when $A$ is symmetric, so that CG can be used.
%% 
The absolute halting criteria is $10^{-9}$ for the smallest problem size, and is then scaled to simulate a discrete L2-norm\footnote{In 2D, the tolerance is scaled by 2 each grid refinement, and in 3D, by $\sqrt{8}$.}. We report preconditioned Krylov iterations and work-per-digit of accuracy.  One work unit is defined to be the cost of a fine-grid matrix-vector product, and work-per-digit of accuracy estimates how many work units are required to reduce the residual by one order of magnitude.  Work measurements allow for easy comparison across methods.  To derive our work-per-digit measure, we first estimate the total cost of doing one matrix-vector product at each level in the hierarchy, relative to one matrix-vector product on the finest level.  This yields the operator complexity measure
\begin{equation}
\mbox{OC} = \sum_k \mbox{nnz}(A_k) / \mbox{nnz}(A_0),
\end{equation}
where $A_k$ is the operator on level $k$ in the multigrid hierarchy.  To account for the cost of doing relaxation at each level, we multiply OC by 3.5 because we estimate (roughly) the cost of CFF- and FFC-Jacobi to be slightly less than 4 matrix-vector products. Thus work-per-digit of accuracy is estimated as
\begin{equation}
    \mbox{wpd} = 3.5\; \mbox{OC} / \log_{10}(\gamma),
\end{equation}
where the average residual convergence factor is $\gamma = (\| r \|_k / \|r_0\|)^{1/k}$, $r_k$ is the final residual, and $r_0$ is the initial residual.



\subsection{Diffusion Tests}
\label{sec:difftests}

For the symmetric case, we consider a variety of classic diffusion tests.
\subsubsection*{2D Poisson} The PDE here is $-u_{xx} - u_{yy} = f$, with Dirichlet boundary conditions on the unit box. The discretization is classic second-order 5-point finite differencing on a regular grid.

\subsubsection*{3D Poisson}
The PDE here is $-u_{xx} - u_{yy} - u_{zz} = f$, with Dirichlet boundary conditions on the unit box. The discretization is classic second-order 7-point finite differencing on a regular grid.


\subsubsection*{2D Grid-Aligned Anisotropic Diffusion} The PDE here is 
\begin{subequations}
\begin{align}
-\nabla \cdot Q^T D Q \nabla u &= f \quad \mbox{for } \Omega = [0,1]^2, \label{eqn:anisodiff1}\\
u &= 0 \quad \mbox{on } \partial \Omega, \label{eqn:anisodiff2}
\end{align}
\end{subequations}
where $\Omega$ is the unit box domain and
\begin{equation} 
Q = \begin{bmatrix} \cos(\varphi) & -\sin(\varphi)\\ \sin(\varphi) & \cos(\varphi)\end{bmatrix}, \quad D = \begin{bmatrix} 1 & 0\\ 0 & \epsilon \end{bmatrix}
\end{equation}
represent the rotation by angle $\varphi$ and the strength of anisotropy $\epsilon$.  The discretization uses a regular grid and bilinear (Q1) finite elements.  For this problem $\varphi = 0$ and $\epsilon = 0.001$, representing strong grid-aligned anisotropy in the $x$-direction.

\subsubsection*{2D Rotated Anisotropic Diffusion}
Here the PDE and discretization are the same as for equations (\ref{eqn:anisodiff1})--(\ref{eqn:anisodiff2}), but $\varphi = \pi/8$ and $\epsilon$ remains 0.001.  This represents strong non-grid-aligned anisotropy at the angle of $\pi/8$.  As noted in \cite{Jacob,KahlRott2018,BranBranKahlLivs2015b}, this is a difficult discretization and angle of anisotropy for AMG.

\subsubsection*{Box-in-Box Coefficient Jump} The PDE here is 
\begin{subequations}
\begin{align}
-\nabla \cdot d(x,y) \nabla u &= f \quad \mbox{for } \Omega, \label{eqn:jumpy1}\\
u &= 0 \quad \mbox{on } \partial \Omega, \label{eqn:jumpy2}
\end{align}
\end{subequations}
where $d(x,y)$ is the jumping coefficient.  Here, $\Omega = [0,1]^2$, $d(x,y) = 1 \mbox{ if } (x,y) \notin [0.44,0.52]^2$, and
$d(x,y) = 10^4 \mbox{ if } (x,y) \in [0.44,0.52]^2$.  The grid is regular and the coefficient jumps are grid-aligned on the finest level, but will not be grid-aligned at coarser levels due to the algebraic coarsening.  The discretization is classic second-order 5-point finite differencing from \cite{alcouffe1981multi} for coefficient jump problems. 

\subsubsection*{Sawtooth Coefficient Jump}
Here, the PDE and discretization are the same as for equations (\ref{eqn:jumpy1})--(\ref{eqn:jumpy2}), but $\Omega = [0,16]^2$,  $d(x,y) = 1$ for points outside the shaded region of 
Figure \ref{fig:sawtooth}, and $d(x,y) = 10^4$ for points inside the shaded region \cite{alcouffe1981multi}.
\begin{figure}[h!]
     \centering
         \includegraphics[width=0.32\textwidth]{plots/sawtooth.pdf}
         \caption{Sawtooth coefficient jump domain, $d(x,y)=10^4$ in shaded region and $d(x,y)=1$ outside.}
         \label{fig:sawtooth}
\end{figure}


\subsubsection*{Standard Solver Parameters}
We now list our standard solver parameters for all three methods, $\ell$AIR, \clair, and root-node.  We will occasionally tune the parameters (e.g., strength) for $\ell$AIR and root-node, in order to make the existing methods more competitive.  The parameters for the proposed \clair\ method will remain fixed for all symmetric test cases, except for the 2D Rotated Anisotropic Diffusion case, where we will follow the guidance of \cite{Jacob} and consider larger degree interpolation sparsity patterns. We use accelerated CG for \clair\ and root-node and accelerated GMRES for $\ell$AIR, as the typical approach for $\ell$AIR is not symmetric (i.e., does not satisfy $R = P^T$, see below parameter choices).

\vspace{6pt} \noindent \textit{Parameters for $\ell$AIR} (see \cite{Ben} for more details on parameter definitions)
\squishlist
    \item Strength-of-connection tolerance for coarsening 0.25 
    \item Degree 2 $\ell$AIR restriction (sparsity pattern similar to $m=2$ in Algorithm \ref{alg:iterativeAIR}) with  interpolation strength tolerance 0.05
    \item Ruge-St\"{u}ben coarsening first-pass only~\cite{JWRuge_KStuben_1987a} (coarsen type FC in Algorithm \ref{alg:iterativeAIR}, relatively slow coarsening often used by $\ell$AIR)
    \item Coarse-grid matrices filtered with drop-tolerance of $10^{-4}$ 
    \item Classical interpolation formula used for $P$ \cite{JWRuge_KStuben_1987a}, which is typical for $\ell$AIR and diffusive problems
\squishend

\vspace{6pt} \noindent \textit{Parameters for \clair}
\squishlist
    \item Strength-of-connection tolerance for coarsening 0.5 
    \item Degree 2 sparsity pattern for $P$ ($m=2$ in Algorithm \ref{alg:iterativeAIR}) with interpolation strength tolerance 0.5 used to generate $S$ in Algorithm \ref{alg:iterativeAIR}
    \item Mode constraint vector $B = \mathbf{1}$, presmoothed with 5 iterations of CFF-weighted-Jacobi at each level
    \item $R = P^T$ used (see discussion below)
    \item Aggregation based coarsening (coarsen type Agg in Algorithm \ref{alg:iterativeAIR})
\squishend
 
\vspace{6pt} \noindent \textit{Parameters for root-node} (see \cite{root-node} for more parameter details)
\squishlist
    \item Strength-of-connection tolerance for coarsening 0.25
    \item $P$ smoothed with energy-minimizing projected CG and a degree 2 sparsity pattern (sparsity pattern similar to $m=2$ in Algorithm \ref{alg:iterativeAIR})
    \item Mode constraint vector $B = \mathbf{1}$, presmoothed with 5 iterations of CFF-weighted-Jacobi at each level
    \item $R = P^T$ used (see discussion below)
    \item Aggregation based coarsening (standard coarsening for root-node) \vspace{6pt}
\squishend

We note that the interpolation strength-of-connection tolerance for \clair\ is different than that for $\ell$AIR (0.5 versus 0.05).  Both of these tolerance were tuned individually for each method.  We also note that \clair\ and root-node both use $R=P^T$, while $\ell$AIR uses classical interpolation. The use of classical interpolation (instead of $R^T$, the transpose of $\ell$AIR restriction) with $\ell$AIR is typical for diffusive problems, and additionally, the use of $R^T$ as interpolation leads to undesirably large operator complexities.


\subsubsection{Poisson Results}

We next examine convergence results for the 2D and 3D Poisson problems in Figure \ref{fig:Poisson_data}.  Here, we tune $\ell$AIR to obtain a more challenging baseline solver and set the sparsity pattern in $R$ to degree 1.  For these simplest of problems, this choice reduces the operator complexity, while not affecting convergence.  For our other test problems, such a parameter choice does not lead to the best performance.  Operator complexities over all test problems, which are an advantage of \clair, are discussed later in Section \ref{sec:complexity}.

Figures \ref{fig:2d_poisson_1} and \ref{fig:3d_poisson} depict results for the 2D and 3D Poisson problems, respectively.  Overall, we see flat iteration counts for all methods, except a slight growth for $\ell$AIR in the 2D Poisson case. The chief performance difference is that $\ell$AIR has a significantly higher operator complexity than \clair\ and root-node, which will be discussed in Section \ref{sec:complexity}

Figure \ref{fig:2d_poisson_2} demonstrates that \clair\ can also be run similar to $\ell$AIR with Ruge-St\"{u}ben coarsening with first-pass only and classical interpolation for $P$.  In general, this setup does not lead to the most efficient solver for \clair, due to the high operator complexity ($\mbox{OC} \approx  3.3$).

\begin{figure}[h!]
     \centering
     \begin{subfigure}[b]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{plots/poisson2d_air_plot_low.png}
         \caption{Poisson 2D }
         \label{fig:2d_poisson_1}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{plots/poisson2d_air_plot_high.png}
         \caption{Poisson 2D, showing high complexity \clair}
         \label{fig:2d_poisson_2}
     \end{subfigure}
     \hfill
     % JS: I think we can leave this out
     %\begin{subfigure}[b]{0.49\textwidth}
     %    \centering
     %    \includegraphics[width=\textwidth]{plots/poisson2d_air_plot_usual_low.png}
     %    \caption{Performance differences between $\ell$AIR vs. \clair \,\, for 2D Poisson, multilevel results.}
     %    \label{fig:2d_poisson_3}
     %\end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{plots/poisson3d_air_plot_low.png}
         \caption{Poisson 3D}
         \label{fig:3d_poisson}
     \end{subfigure}
        \caption{2D and 3D Poisson, comparison of iterations and work-per-digit of accuracy for $\ell$AIR, \clair, and root-node.}
        \label{fig:Poisson_data}
\end{figure}


\subsubsection{Other Diffusion Results}

We now consider our other diffusion test problems in Figure \ref{fig:diffusion_data}, which again depicts iterations and work-per-digit of accuracy. For these tests, we tune root-node and $\ell$AIR on the 2D Grid-Aligned Anisotropic Diffusion problem, in order to obtain more challenging baseline solvers.  Here, we set the coarsening and interpolation strength-of-connection tolerances to 0.5 and note that using such a high interpolation strength tolerance typically hurts $\ell$AIR performance, with this case being the outlier.  Thus, this is not a general parameter setting for $\ell$AIR and is used to highlight the greater flexibility of the untuned \clair\ solver. Following the work \cite{Jacob}, we also consider higher-degree interpolation for the 2D Rotated Anisotropic Diffusion case, for both root-node and \clair.  Unfortunately, prohibitive increases in operator complexity for $\ell$AIR do not allow for such an examination of higher-degree interpolation.

Figure \ref{fig:diffusion_1} depicts results for the 2D Grid-Aligned Anisotropic Diffusion problem, where we see similar performance for \clair, root-node, and $\ell$AIR. Figure \ref{fig:diffusion_2} depicts results for the 2D Rotated Anisotropic Diffusion problem where all three solvers produce similar work-per-digit numbers, and the root-node and \clair\ solvers show flat, scalable iteration counts for the higher-degree interpolation option.

Figures \ref{fig:diffusion_3} and \ref{fig:diffusion_4} depict results for the Box-in-Box Coefficient Jump and Sawtooth Coefficient Jump problems. All three solvers again show similar work-per-digit numbers, with the main difference being in operator complexity, which we discuss next.

\begin{figure}[h!]
     \centering
     \begin{subfigure}[b]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{plots/diffusion_grid_aligned.png}
         \caption{2D Grid-aligned Anisotropic Diffusion, when not visible, the lines for \clair\ are underneath root-node.}
         \label{fig:diffusion_1}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{plots/rotated_anisotropic_diffusion.png}
         \caption{2D Rotated Anisotropic Diffusion  }
         \label{fig:diffusion_2}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{plots/jump_box_in_box.png}
         \caption{Box-in-Box Coefficient Jump}
         \label{fig:diffusion_3}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{plots/jump_sawtooth.png}
         \caption{Sawtooth Coefficient Jump, when not visible, the lines for \clair\ are underneath root-node.}
         \label{fig:diffusion_4}
     \end{subfigure}
        \caption{Various diffusion test problems, comparison of iterations and work-per-digit of accuracy for $\ell$AIR, \clair, and root-node.}
        \label{fig:diffusion_data}
\end{figure}
% OAK: You cannot really see the CLAIR lines at all in the top left plot. Rather than chnaging the color/plotting scheme, perhaps a note could be added to the caption of the figure along the lines of "the CLAIR data is not visible but is essentially underneath the root-node data"?
% JBS: I added a note.  Thanks!


% OAK: Would it make more sense for discussion on operator complexities to come after the initial results that are presented in "Poisson Results"? 
% JBS: THis section has been moved around...I'll move it back to the end.
\subsubsection{Operator Complexity Comparison}
\label{sec:complexity}

One key advantage for \clair\ when compared to other reduction-based approaches on diffusion problems is the ability to achieve moderate operator complexities with good convergence.  To illustrate this, Table \ref{table_op_comp} depicts the operator complexity for all three solvers and the largest problem size for each of the diffusion test problems.  Here, this advantage to \clair\ becomes obvious.  The faster aggregation-based coarsening, which only root-node and \clair\ support, allows for dramatically lower operator complexities and the associated lower storage requirements. 
%JBS: not sure this is true here, can have smaller OC, but still relatively "dense" rows ... and some computational advantages, especially from reduced number of nonzeros per row of coarse-grid matrices when doing parallel \cite{GaBaScYaJoGr2011,FaSc2014,BiFaGrOlSc2016}.

Importantly, one could not simply introduce the aggregation-based coarsening into $\ell$AIR and maintain good convergence. The addition of the mode interpolation constraint vector $B$ is needed for good convergence.

We note that the operator complexity of 1.98 for \clair\ and the 2D Rotated Anisotropic Diffusion case can easily be brought down to 1.78 without a meaningful effect on convergence by using 0.25 as the strength-of-connection tolerance, but we choose to maintain uniform parameters for \clair.

\begin{table}[h!]
\begin{center}
\begin{tabular}{ c|c|c|c } 
\toprule
\textbf{Test Problem}                   & $\ell$AIR OC & \clair\ OC & Root-node OC \\
\midrule
2D Poisson                              & $2.20$ & $1.40$ & 1.34 \\ 
3D Poisson                              & $2.87$ & $1.71$ & 1.57 \\ 
2D Grid-aligned Anisotropic Diffusion   & $4.92$ & $1.52$ & 1.51\\
2D Rotated Anisotropic Diffusion        & $2.89$ & $1.98$ & 1.52 \\ 
Box-in-Box Coefficient Jump             & $2.73$ & $1.40$ & 1.34 \\ 
Sawtooth Coefficient Jump               & $2.71$ & $1.42$ & 1.35 \\
\bottomrule
\end{tabular}
\end{center}
\caption{Operator complexities of $\ell$AIR and \clair\, for different diffusion test problems.}
\label{table_op_comp}
\end{table}

\begin{remark}
In summary, we have shown that \clair\ performs similarly in terms of work-per-digit, operator complexity, and iterations on this suite of classic diffusion test problems when compared to root-node, an AMG method known to be efficient for such problems.  Our goal is not to find a faster solver for the 5-point Poisson operator, which would be difficult and of questionable value, but instead to verify the proposed solver.  We have furthermore shown greater parameter insensitivity and dramatically lower operator complexities when compared to $\ell$AIR for these problems.  Lastly, we note that achieving such low operator complexities with good convergence, something that has been previously difficult for reduction-based methods. 
\end{remark}

\subsection{Advection-Diffusion Tests}
\label{sec:advtests}

We now turn our attention to nonsymmetric tests and consider the following two advection-diffusion  problems.

\subsubsection*{2D Constant Direction Advection-Diffusion}  Here the PDE is 
\begin{subequations}
\begin{align}
-\alpha \nabla \cdot \nabla u + \mathbf{b}(x,y) \cdot \nabla u &= f \quad \mbox{for } \Omega = [-1,1]^2, \label{eqn:advdiff1}\\
u &= 0 \quad \mbox{on } \partial \Omega, \label{eqn:advdiff2}
\end{align}
\end{subequations}
where $\alpha$ is the diffusion constant and $\mathbf{b}(x,y)$ describes the advection.  For this problem $\mathbf{b}(x,y) = [ \sqrt{2/3},\, \sqrt{1/3} ]$ representing constant non-grid-aligned advection.  The discretization is first-order upwinded discontinuous Galerkin (DG) for advection and the interior-penalty method for the DG discretization of diffusion.  The discretization was generating by utilizing examples 1 (diffusion) and 9 (advection) with PyMFEM \cite{mfem,pymfem}. For the case where $\alpha=0$, the boundary conditions are modified slightly such that an outflow now occurs on the North and East walls ($u=0$ is still prescribed on the West and South walls). We use $u=0$ for the inflow, so that we may test our solver with a zero right-hand-side and random initial guess, as is commonly done to verify AMG solvers.

% OAK: The advection field for the constant case is also divergence free. Is there a reason why divergence free is used as a descriptor for this problem?
% JBS: Changed div-free to just recirculating in the test problem "name"
\subsubsection*{2D Recirculating Advection-Diffusion} Here the PDE and discretization is the same as for equations (\ref{eqn:advdiff1})--(\ref{eqn:advdiff2}), 
except $\mathbf{b}(x,y)= [ x(1-x)(2y-1),\, -(2x-1)(1-y)y]$, representing divergence-free recirculating advection about the origin.  For $\alpha=0$, this problem is ill-defined, thus we only go to $\alpha=10^{-4}$.

\subsubsection{Advection-Diffusion Results}

Our goal here is to test the solver's robustness from the highly advective to highly diffusive regime and show improved performance and robustness relative to the current state $\ell$AIR. Similar to \cite{Ben}, we pre-scale the fine-grid matrices with the inverse of their diagonal block (block-size equals the DG element size of 4).  Our solver parameters will remain fixed over these tests, and involve only minor changes to the symmetric parameters from Section \ref{sec:difftests}.  As the matrices are nonsymmetric, GMRES is accelerated with V(1,1)-cycles. The relaxation weight for postsmoothing with FFC-Jacobi is removed, as we no longer need symmetry for our preconditioner and this change slightly improves convergence for all methods.\footnote{The removal of the weight also more closely follows the reduction point-of-view in that post-smoothing should primarily solve the F-equations, so the slight improvement of convergence is not surprising.} The parameters for $\ell$AIR were changed slightly to use the second pass of Ruge-St\"{u}ben coarsening.  The parameters for \clair\ changed slightly with the strength-of-connection parameters becoming the same as for $\ell$AIR (0.25 for coarsening and 0.05 for interpolation).  Additionally because of the nonsymmetry, $P$ is generated separately from $R$ using $A$ and $A^T$, respectively. We also again consider two variants of \clair, a high complexity version that uses first pass only Ruge-St\"{u}ben coarsening, and lower complexity versions that uses aggregation-based coarsening. %(see Algorithm \ref{alg:amgsetup}).  
The parameters for root-node changed similarly, where GMRES is now used for the energy-minimization when computing $P$ and $P$ is generated separately from $R$ using $A$ and $A^T$, respectively.

Figure \ref{fig:adv_diff_1} depicts work-per-digit for the 
2D Constant Direction Advection problem with no diffusion ($\alpha=0$).  The purpose of this
plot is to show that \clair\ enjoys similar convergence to $\ell$AIR for this test problem, where we know that $\ell$AIR works well and is essentially the state-of-the-art \cite{Ben}.

Figures \ref{fig:adv_diff_3} and \ref{fig:adv_diff_4} depict for all three solvers (with two different variants of \clair) the work-per-digit of accuracy over a range of diffusion ($\alpha$) values for the constant direction and recirculating test problems.  The data points for root-node are omitted whenever the solver did not converge within 100 iterations (typically for small $\alpha$ values). We plainly see that \clair\  has the most consistent performance in terms of work-per-digit accuracy across all regimes.

Table \ref{table_op_comp_adv} highlights the operator complexity advantage of \clair\ over $\ell$AIR for the constant advection case (the recirculating free case is similar).  For the more advective cases (smaller $\alpha$), the high complexity variant of \clair, using first-pass only Ruge-St\"{u}ben coarsening, obtains lower
operator complexities of roughly 15--30\%, while for the more diffusive cases (larger $\alpha$), the lower complexity variant of \clair, using aggregation based coarsening, obtains operator complexities roughly 1.6x--2.5x smaller.  In both settings, significant storage savings are achieved. 
%
\begin{table}[h!]
\begin{center}
\begin{tabular}{ c|c|c|c |c|c|c|c } 
\toprule
\hfill $\alpha$          & 10.0 &  1.0 &  0.1 & 0.01 & 0.001 & 0.0001 & 0.0 \\
\midrule
$\ell$AIR                & 3.19 & 3.19 & 3.20 & 3.19 & 3.70  & 3.19   & 4.28 \\
\clair, High Complexity  & 3.00 & 2.97 & 2.94 & 2.81 & 2.89  & 2.69   & 3.06 \\
\clair                   & 1.28 & 1.29 & 1.29 & 1.96 &  DNC  &  DNC   &  DNC \\
Root-node                & 1.20 & 1.20 & 1.20 & 1.42 &  DNC  &  DNC   &  DNC \\
\bottomrule
\end{tabular}
\end{center}
\caption{Operator complexities of $\ell$AIR and \clair\, for different diffusion $\alpha$ values and the constant advection test problem.  Entries ``DNC" indicate the solver did not converge within 100 iterations.}
\label{table_op_comp_adv}
\end{table}
 
\begin{figure}[h!]
     \centering
     \begin{subfigure}[b]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{plots/const_advection_air_plot.png}
         \caption{Solver performance for 2D Constant Direction Advection, but no diffusion ($\alpha=0$), comparing $\ell$AIR and \clair. Note, root-node does not converge within 100 iterations for this problem and is not shown.}
         \label{fig:adv_diff_1}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{plots/const_advection_air_plot_gamma_10.png}
         \caption{Solver performance for 2D Constant Direction Advection with diffusion ($\alpha=10$), comparing $\ell$AIR, \clair\ and Root-node.}
         \label{fig:adv_diff_2}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{plots/const_advection_varyalpha_plot.png}
         \caption{Constant advection with varying diffusion}
         \label{fig:adv_diff_3}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{plots/divfree_advection_varyalpha_plot_broken.png}
         \caption{Recirculating advection with varying diffusion}
         \label{fig:adv_diff_4}
     \end{subfigure}
     
        \caption{Advection-diffusion problems, comparison of iterations, work-per-digit of accuracy and operator complexity for $\ell$AIR, \clair\ and Root-node.}
        \label{fig:advection_diffusion_data}
\end{figure}

\begin{remark}
For these plots, our goal is to highlight the robustness (lack of need for tuning) for the \clair\ solver.  Thus, we searched for good general parameters for each solver and held them fixed over all tests.  However, better parameters for individual problems and $\ell$AIR do exist.  For instance, if the matrix is \emph{not} block diagonally pre-scaled, then the solver iterations and work for $\ell$AIR in Figure \ref{fig:adv_diff_2} ($\alpha=10$ case) improve and become 7, 8, 8, 9 and 10.35, 10.43, 11.60, 11.81, respectively, but with a prohibitively large operator complexity of $\sim 4.23$.  However with no pre-scaling, the $\ell$AIR then fails to converge within 100 iterations for the small $\alpha$ cases, e.g., Figure \ref{fig:adv_diff_1}.  Another place where tuning is beneficial for $\ell$AIR is the smallest $\alpha$ value for the recirculating advection-diffusion problem ($\alpha = 10^{-4})$, where using first-pass only Ruge-St\"{u}ben coarsening lowers the iterations and work from 88 and 85.34 to 21 and 15.86, respectively.  However, the use of first-pass only Ruge-St\"{u}ben coarsening then substantially degrades iterations and work-per-digit results for $\ell$AIR and other $\alpha$ values.
\end{remark}
\begin{remark}
    For a subset of the advection-diffusion problems considered in this section, Appendix A considers AMG approximation properties of \clair\ and $\ell$AIR, with the results indicating that \clair\ either maintains or improves on the approximation properties of $\ell$AIR.
\end{remark}
% Ben: read this below paragraph, too
In summary, the benefits of \clair\ are as follows.  The $\ell$AIR solver (i) requires more tuning for these problems than \clair, (ii) requires more work-per-digit than \clair\ for more diffusive problems (larger $\alpha$ values), and (iii) has significantly larger operator complexities. 

\section{Conclusion}
In this paper, we developed a new type of reduction-based AMG that is suitable for solving nonsymmetric linear systems coming from the discretization of advection-diffusion PDEs.  By combining techniques from $\ell$AIR that have been effective for advective problems, with energy minimization and root node techniques that are well suited for diffusion problems, we have developed an efficient method for solving advection-diffusion problems in a general setting -- the solver is insensitive to varying contribution of the diffusive part in the PDE.  An important distinction between our proposed solver and existing reduction based methods is that we take a column-wise approach to computing an approximation to ideal restriction and interpolation, which more naturally allows us to incorporate energy minimization and mode constraint techniques into the process.  Our future work focuses on deriving a two-grid convergence theory for the proposed approach applied to nonsymmetric systems and to incorporate the idea of compatible relaxation into the \clair\ coarsening process.

\appendix
\label{sec:appendix_approx}
\section{Classical AMG Weak and Strong Approximation Properties} \subsection{Approximation Properties in the Nonsymmetric Setting}  We consider convergence of $\ell$AIR and \clair\ based on classical multigrid weak and strong approximation properties. Targeting nonsymmetric problems, we consider the generalization of the $A$-norm as $\sqrt{A^{*}A}$ or $\sqrt{AA^{*}}$  \cite{brezina2010towards,BenTheory}. %(\textcolor{red}{OAK: Probably also cite here the Brezina et al. paper that is cited in Tom and Ben's paper as generalizing the A norm. i.e., their reference number 2)}. 
For a nonsingular matrix $A \in \mathbb{C}^{n\times n}$, consider the singular value decomposition (SVD) given by $A=U\Sigma V^{*}$ where the singular values are $0<\sigma_{1}\leq \sigma_{2}\leq...\leq \sigma_{n}$. Then $\sqrt{A^{*}A}=V\Sigma V^{*}=VU^{*}U\Sigma V^{*}= QA$ where $Q=VU^{*}$. In a similar manner, we can also obtain  $\sqrt{AA^{*}}=U\Sigma U^{*}=AQ$. Since $\sqrt{A^{*}A}$ or $\sqrt{AA^{*}}$ are SPD matrices, therefore we can still consider classical AMG approximation properties with respect to the SPD matrices $QA$ and $AQ$ corresponding to the right and left singular vectors, respectively.  Such approximation properties measure, in a sense, how effective the coarse spaces are at capturing the near nullspace of the operator.

For several test problems, we numerically evaluate approximation properties for $\ell$AIR and \clair\ by making use of the generalized fractional approximation property (FAP) \cite{BenTheory}. The FAP of a transfer operator $T \in \mathbb{R}^{n \times n_c}$ is with respect to the SPD matrix $\mathcal{A}$, with powers $\beta, \eta \geq 0$ and constant $K_{T,\beta,\eta}$. Specifically, $T$ is said to have a FAP if for every fine grid vector, $\mathbf{v}$, there exists a coarse grid vector, $\mathbf{v}_{c}$, such that 
\begin{equation}\label{FAP}
||\mathbf{v}-T\mathbf{v}_c||_{\mathcal{A}^{\eta}}^{2}\leq \displaystyle\frac{K_{T,\beta, \eta}}{||\mathcal{A}||^{2\beta-\eta}}\langle\mathcal{A}^{2\beta}\mathbf{v},\mathbf{v}\rangle,
\end{equation}
where $\mathcal{A} = QA$ ($T = P$) or $\mathcal{A} = AQ$ ($T = R^*$). The classical multigrid weak approximation property (WAP) is a FAP($1/2, 0$), that is 
\begin{equation}\label{WAP}
   ||\mathbf{v}-T\mathbf{v}_c||_{2}^{2}\leq \displaystyle\frac{K_{T,1/2, 0}}{||\mathcal{A}||}\langle\mathcal{A}\mathbf{v},\mathbf{v}\rangle.
\end{equation}
Further, the classical multigrid strong approximation property (SAP) is a FAP(1,1), that is 
\begin{equation}\label{SAP}
    ||\mathbf{v}-T\mathbf{v}_c||_{\mathcal{A}}^{2}\leq \displaystyle\frac{K_{T,1, 1}}{||\mathcal{A}||}\langle\mathcal{A}^{2}\mathbf{v},\mathbf{v}\rangle.
\end{equation}
For a given vector $\mathbf{v}$, we compute the approximation constant $K_{T,\beta, \eta}(\mathbf{v})$ with
\begin{equation}\label{minimize}
    K_{T,\beta, \eta}(\mathbf{v})=\displaystyle\frac{||\mathcal{A}||^{2\beta-\eta}}{||\mathbf{v}||^{2}_{\mathcal{A}^{2\beta}}}\,\,\min_{\mathbf{v}_{c}}||\mathbf{v}-T\mathbf{v}_c||_{\mathcal{A}^{\eta}}^{2}.
\end{equation}
%Note that the minimizing $\mathbf{v}_{c}$ is $\mathbf{v}_{c}=P(P^{*}\mathcal{A}^{\eta}P)^{-1}P^{*}\mathcal{A}^{\eta} \mathbf{v}$. 

\noindent Let $\Pi_{\eta}$ denote the $\mathcal{A}^{\eta}$-orthogonal projection onto the range of $T$, $\Pi_{\eta}= T(T^{*}\mathcal{A}^{\eta}T)^{-1}T^{*}\mathcal{A}^{\eta}  $. 
%In order to minimize $\mathbf{v}_{c}$ we take $T\mathbf{v}_{c}=\Pi_{\eta}\mathbf{v}$. 
Substituting into \eqref{minimize} we obtain,

\begin{equation}\label{minimize2}
    K_{T,\beta, \eta}(\mathbf{v})=\displaystyle\frac{||\mathcal{A}||^{2\beta-\eta}}{||\mathbf{v}||^{2}_{\mathcal{A}^{2\beta}}}\,\,||(I-\Pi_{\eta})\mathbf{v}||_{\mathcal{A}^{\eta}}^{2}.
\end{equation}



\noindent
To compute the approximation constant $K_{\max}$ that holds for all fine grid vectors $\mathbf{v}$, we take maximum of the above expression over all $\mathbf{v}$, which leads to
\begin{equation}    
  K_{\max}=\max_{\mathbf{v}\neq 0}\,\,K_{T,\beta, \eta}(\mathbf{v})={||\mathcal{A}||^{2\beta-\eta}}\,\,||\mathcal{A}^{\eta/2} (I-\Pi_{\eta}) \mathcal{A}^{-\beta}||_{2}^{2}.
\end{equation}

\subsection{Numerical Tests} To complement the numerical results in the main text, we now measure classical AMG approximation property constants for both $\ell$AIR and \clair\ from the purely advective to diffusion dominated case. Specifically, we consider the 2D constant direction advection problem \eqref{eqn:advdiff1}--\eqref{eqn:advdiff2} for various diffusion coefficients $\alpha$. For numerical tests, a $32\times 32$ size spatial domain is considered, resulting in $1024$ total DOFs. In the following numerical tests, we consider the approximation properties of the restriction operators from both $\ell$AIR and \clair.

\begin{figure}[h!]
     \centering
     \begin{subfigure}[b]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{plots/WAP_approx_0_5_iter.png}
         \caption{WAP for Constant Advection with zero diffusion ($\alpha=0$) where constraint vector $B = \mathbf{1}$ is presmoothed with 5 iterations of CFF-weighted-Jacobi.}
         \label{fig:air_approx_0}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{plots/SAP_approx_0_5_iter.png}
         \caption{SAP for Constant Advection with zero diffusion ($\alpha=0$) where constraint vector $B = \mathbf{1}$ is presmoothed with 5 iterations of CFF-weighted-Jacobi.}
         \label{fig:air_approx_1}
     \end{subfigure}
     
     
        \caption{WAP and SAP constants for the restriction operators of $\ell$AIR and \clair\ for the constant advection with 
 zero diffusion ($\alpha=0$) problem. Five (5) iterations of CFF-weighted-Jacobi relaxation has been used to improve the mode constraint vector $B=\mathbf{1}$ in \clair. Singular values are shown in the dotted blue line and are associated with the right vertical axis, and the dot-dashed lines show the approximation constant for each of the left singular vectors of $A$. Horizontal dashed lines show the approximation constant for $\ell$AIR and \clair\ that holds for all vectors.}  
        \label{fig:approx_fig_air_zero_diff}
\end{figure}

Figure \ref{fig:approx_fig_air_zero_diff} shows the WAP (FAP($1/2, 0$)) and SAP (FAP($1,1$)) approximation constants for the left singular vectors of $A$. Here, 5 iterations of CFF-weighted-Jacobi relaxation has been used to improve the mode constraint vector $B=\mathbf{1}$. From Figure \ref{fig:air_approx_0} and \ref{fig:air_approx_1}, we see that \clair\ demonstrates moderately smaller (i.e., better) WAP and SAP constants than $\ell$AIR. Since $\ell$AIR is primarily designed for such purely advective problems these results indicate that \clair\ is also effective for advection problems, with similar convergence properties. This is indeed what we see in Figures \ref{fig:adv_diff_1} and \ref{fig:adv_diff_3}. This motivates us to further study approximation properties of \clair\ for  diffusion dominated problems.
%

Next, we consider a diffusion dominated case by setting the  diffusion coefficient to be $\alpha=10$. First, as previously, we use 5 iterations of a CFF-weighted-Jacobi smoother to improve the mode constraint vector $B=\mathbf{1}$. Carefully investigating the results in Figure \ref{fig:air_approx_2}, we observe that WAP constant for the new method \clair\ is almost a factor of two smaller than that for $\ell$AIR. Now if we compare the SAP constants in Figure \ref{fig:air_approx_3}, $K_{\max}$ is smaller for \clair\ than for $\ell$AIR, although the constants are very large for both solvers (184 for \clair\ and 2246 for $\ell$AIR). Somewhat surprisingly, while the SAP constant for \clair\ in Figure \ref{fig:air_approx_3} is quite large, we find that  the iteration counts of the solver are mesh independent (as we have seen in Figure \ref{fig:adv_diff_2} for the $\alpha=10$ case). In this case, we suspect that the Krylov method is able to account for what the solver is lacking. We note that the significantly larger SAP constants for $\ell$AIR are consistent with the poorer scalability of $\ell$AIR seen in Figure \ref{fig:adv_diff_2} for the $\alpha=10$ case. A key advantage of \clair\ is that it allows the flexibility to improve the approximation properties of the restriction operator by employing a suitable relaxation scheme for smoothing the mode constraint vector (such as weighted CFF-Jacobi). This type of flexibility is not available in $\ell$AIR. Therefore, further improvement of \clair's SAP constant can be obtained by increasing the number of iterations applied to $B$. In our experiments, we find that if the mode constraint vector $B = \mathbf{1}$ is presmoothed with 25 iterations of CFF-weighted-Jacobi (instead of 5 iterations), the SAP approximation constant for \clair\ decreases further to $K_{\max} = 77$ (Figure \ref{fig:air_approx_5}).  However, we do not find that these extra iterations lead to a meaningful improvement in practice for \clair\ convergence on the tested problems.
%
%\textcolor{red}{(OAK: I guess we should refer to a table of results here, and generally for this section I think it may be good to refer to the convergence plots or tables or whatever the discretizations we consider in this section correspond to. Also, the above statement is a bit speculative, and I'm a bit confused about the fact that the constants spike on smooth modes since these are what we fit to. Anyway, I'm happy for something along the lines of the above to be said, but someone else other than me should sign off on it :D)}

\begin{figure}[h!]
     \centering
     \begin{subfigure}[b]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{plots/WAP_approx_10_5_iter.png}
         \caption{WAP for Constant Advection with added diffusion ($\alpha=10$) where constraint vector $B = \mathbf{1}$ is presmoothed with 5 iterations of CFF-weighted-Jacobi.}
         \label{fig:air_approx_2}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{plots/SAP_approx_10_5_iter.png}
         \caption{SAP for Constant Advection with added diffusion ($\alpha=10$) where constraint vector $B = \mathbf{1}$ is presmoothed with 5 iterations of CFF-weighted-Jacobi.}
         \label{fig:air_approx_3}
     \end{subfigure}
     \begin{subfigure}[b]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{plots/WAP_approx_10_25_iter.png}
         \caption{WAP for Constant Advection with added diffusion ($\alpha=10$) where constraint vector $B = \mathbf{1}$ is presmoothed with 25 iterations of CFF-weighted-Jacobi.}
         \label{fig:air_approx_4}
     \end{subfigure}
        \hfill
     \begin{subfigure}[b]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{plots/SAP_approx_10_25_iter.png}
         \caption{SAP for Constant Advection with added diffusion ($\alpha=10$) where constraint vector $B = \mathbf{1}$ is presmoothed with 25 iterations of CFF-weighted-Jacobi.}
         \label{fig:air_approx_5}
     \end{subfigure}
     
        \caption{WAP and SAP constants for the restriction operators of $\ell$AIR and \clair\ for the constant advection with 
 added diffusion ($\alpha=10$) problem. Different number of iterations (5 and then 25) of CFF-weighted-Jacobi relaxation has been used to improve the mode constraint vector $B=\mathbf{1}$ in \clair. Singular values are shown in the dotted blue line and are associated with the right vertical axis, and the dot-dashed lines show the approximation constant for each of the left singular vectors of $A$. Horizontal dashed lines show the approximation constant for $\ell$AIR and \clair\ that holds for all vectors.}  
 \label{fig:approx_fig_air_10_diff}
 \end{figure}

\subsection*{Acknowledgments}
Los Alamos National Laboratory Report LA-UR-23-27101.



  \bibliography{refs}
  \bibliographystyle{plain}


\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FINAL TABLES ARE HERE%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\section{Poisson Data}
%
% The test data is in 
%     same_params_results_symmetric, which holds RN and lAIR results
%     and
%     same_params_results_symmetric_FCC, which holds CLAIR results for FCC relaxation for improve_candidates
\begin{center} \textbf{Begin 2D Poisson Data} \end{center}
\begin{table}[H]
  \centering
  \begin{tabular}{cccccc}
  \toprule
     n   & op comp & iter & piter & $\gamma$ & work \\
\midrule
\multicolumn{6}{c}{\textit{AIR deg=1 $\theta=0.05$, $P_{classical}$, RS-1st, $\tau = 1e-4$, $A_{Unscaled}$  Strength 0.25  CFF Jac  FFC Jac}} \\
   1024  &   2.15  &  10  &   7   &  0.03 & 5.13 \\
   4096  &   2.18  &  10  &   8   &  0.04 & 5.46 \\
  16384  &   2.19  &  10  &   8   &  0.05 & 5.96 \\
  65536  &   2.20  &  10  &   9   &  0.06 & 6.37 \\
  262144 &   2.20  &  10  &   10  &  0.07 & 6.62 \\
 1048576 &   2.20  &  11  &   11  &  0.10 & 7.57 \\
  \bottomrule
  \end{tabular}
  \caption{ Classic AIR results for 2D Poisson, multilevel results.}
  \label{tab:2d_poisson_air}
\end{table}
%%
\begin{table}[H]
  \centering
  \begin{tabular}{cccccc}
  \toprule
     n   & op comp & iter & piter & $\gamma$ & work \\
\midrule
\multicolumn{6}{c}{\textit{Iterair $R=P^T$, Iter AIR deg=2 exact theta 0.05, RS-1st, , $A_{Unscaled}$  $B_{Smoothed}$ 5 FFC,  Strength 0.25  wJac x2  FFC Jac}} \\
   1024  &   2.68  &  9   &   8   &  0.03 & 6.31 \\
   4096  &   2.96  &  9   &   8   &  0.04 & 7.41 \\
  16384  &   3.17  &  8   &   8   &  0.05 & 8.33 \\
  65536  &   3.32  &  8   &   8   &  0.05 & 8.77 \\
  262144 &   3.39  &  8   &   8   &  0.05 & 9.11 \\
 1048576 &   3.43  &  7   &   7   &  0.05 & 9.35 \\
  \bottomrule
  \end{tabular}
  \caption{ \clair\ results for 2D Poisson, multilevel results.}
  \label{tab:2d_poisson_iterair}
\end{table}
\newpage
 \begin{center} \textbf{Begin 3D Poisson Data} \end{center}

\begin{table}[H]
  \centering
  \begin{tabular}{cccccc}
  \toprule
     n   & op comp & iter & piter & $\gamma$ & work \\
\midrule
\multicolumn{6}{c}{\textit{AIR deg=1 $\theta=0.05$, $P_{classical}$, RS-1st, $\tau = 1e-4$, $A_{Unscaled}$  Strength 0.25  CFF Jac  FFC Jac}} \\
  4096  &   2.65  &  10  &   7   &  0.03 & 6.06 \\
 32768  &   2.78  &  10  &   8   &  0.04 & 6.82 \\
 110592 &   2.84  &  10  &   9   &  0.06 & 8.03 \\
 262144 &   2.87  &  10  &   10  &  0.07 & 8.48 \\
 512000 &   2.86  &  10  &   10  &  0.07 & 8.59 \\
 884736 &   2.87  &  10  &   9   &  0.06 & 8.46 \\
\midrule  \bottomrule
  \end{tabular}
  \caption{ Classic AIR results for 3D Poisson, multilevel results.}
  \label{tab:3d_poisson_air}
\end{table}
%%

\section{Low Complexity Tables}
\begin{table}[H]
  \centering
  \begin{tabular}{cccccc}
  \toprule
     n   & op comp & iter & piter & $\gamma$ & work \\
\midrule
  4096  &   1.58  &  35  &   16  &  0.19 & 7.63 \\
 32768  &   1.65  &  30  &   15  &  0.17 & 7.58 \\
 110592 &   1.69  &  32  &   16  &  0.19 & 8.10 \\
 262144 &   1.70  &  34  &   17  &  0.20 & 8.62 \\
 512000 &   1.70  &  32  &   16  &  0.20 & 8.43 \\
 884736 &   1.72  &  36  &   17  &  0.22 & 9.04 \\
 \bottomrule
  \end{tabular}
  \caption{ \clair\ results for 3D Poisson, multilevel results.}
  \label{tab:3d_poisson_iterair}
\end{table}
%%
\begin{table}[H]
  \centering
  \begin{tabular}{cccccc}
  \toprule
     n   & op comp & iter & piter & $\gamma$ & work \\
\midrule
\multicolumn{6}{c}{\textit{RN CG EnMin, deg=2, standard agg, , $A_{Unscaled}$  $B_{Smoothed}$ 5,  Strength 0.25  CFF Jac  FFC Jac}} \\
  4096  &   1.49  &  33  &   16  &  0.18 & 7.12 \\
 32768  &   1.54  &  30  &   15  &  0.17 & 7.07 \\
 110592 &   1.55  &  32  &   16  &  0.19 & 7.49 \\
 262144 &   1.56  &  31  &   16  &  0.19 & 7.54 \\
 512000 &   1.57  &  30  &   15  &  0.17 & 7.24 \\
 884736 &   1.57  &  31  &   16  &  0.19 & 7.59 \\
 \bottomrule
  \end{tabular}
  \caption{ Root-node results for 3D Poisson, multilevel results.}
  \label{tab:3d_poisson_RN}
\end{table}

Now, we repeat the above for the 2D Poisson operator and also see good results.
\begin{table}[H]
  \centering
  \begin{tabular}{cccccc}
  \toprule
     n   & op comp & iter & piter & $\gamma$ & work \\
\midrule
\multicolumn{6}{c}{\textit{Iterair $R=P^T$, Iter AIR deg=2 exact theta 0.5 AggPattern, standard agg, , $A_{Unscaled}$  $B_{Smoothed}$ 5,  Strength 0.5  CFF Jac  FFC Jac}} \\
   1024  &   1.39  &  26  &   14  &  0.15 & 5.92 \\
   4096  &   1.40  &  27  &   14  &  0.17 & 6.44 \\
  16384  &   1.39  &  32  &   16  &  0.20 & 6.93 \\
  65536  &   1.40  &  31  &   16  &  0.21 & 7.26 \\
  262144 &   1.39  &  32  &   16  &  0.21 & 7.27 \\
 1048576 &   1.39  &  33  &   17  &  0.23 & 7.61 \\
  \bottomrule
  \end{tabular}
  \caption{ \clair\ results for 2D Poisson, \emph{low complexity} multilevel results.}
  \label{tab:2d_poisson_iterair_lowcomp}
\end{table}
%%
\begin{table}[H]
  \centering
  \begin{tabular}{cccccc}
  \toprule
     n   & op comp & iter & piter & $\gamma$ & work \\
\midrule
\multicolumn{6}{c}{\textit{RN CG EnMin, deg=2, standard agg, , $A_{Unscaled}$  $B_{Smoothed}$ 5,  Strength 0.25  CFF Jac  FFC Jac}} \\
   1024  &   1.33  &  25  &   13  &  0.15 & 5.64 \\
   4096  &   1.34  &  26  &   14  &  0.15 & 5.72 \\
  16384  &   1.33  &  26  &   14  &  0.15 & 5.69 \\
  65536  &   1.34  &  26  &   14  &  0.17 & 6.01 \\
  262144 &   1.34  &  26  &   14  &  0.17 & 6.04 \\
 1048576 &   1.34  &  27  &   15  &  0.19 & 6.54 \\
 \bottomrule
  \end{tabular}
  \caption{ Root-node results for 2D Poisson, \emph{low complexity} multilevel results.}
  \label{tab:2d_poisson_iterair_RN}
\end{table}

\section{Grid aligned anisotropic diffusion, Q1 Elements}

% same_params_results_symmetric/aniso_pi0_lair.txt
\begin{table}[H]
  \centering
  \begin{tabular}{cccccc}
  \toprule
     n   & op comp & iter & piter & $\gamma$ & work \\
\midrule
\multicolumn{6}{c}{\textit{AIR deg=2 $\theta=0.5$, $P_{classical}$, RS-1st, $\tau = 1e-4$, $A_{Unscaled}$  Strength 0.5  CFF Jac  FFC Jac}} \\
   1024  &   2.01  &  24  &   13  &  0.15 & 8.41 \\
   4096  &   2.07  &  23  &   13  &  0.15 & 8.71 \\
  16384  &   2.12  &  24  &   13  &  0.15 & 8.94 \\
  65536  &   2.13  &  24  &   13  &  0.15 & 9.09 \\
  262144 &   2.15  &  24  &   13  &  0.16 & 9.42 \\
 1048576 &   2.15  &  24  &   14  &  0.18 & 9.99 \\
     \bottomrule
  \end{tabular}
  \caption{ Classic AIR results for grid-aligned anisotropic diffusion, multilevel results. \textcolor{red}{Note, the SoC thresh must be 0.5 for both P and coarsening.}}
  \label{tab:theta0_aniso_air}
\end{table}
%%
\begin{table}[H]
  \centering
  \begin{tabular}{cccccc}
  \toprule
     n   & op comp & iter & piter & $\gamma$ & work \\
\midrule
\multicolumn{6}{c}{\textit{Iterair $R=P^T$, Iter AIR deg=2 exact theta 0.5 AggPattern, standard agg, , $A_{Unscaled}$  $B_{Smoothed}$ 5,  Strength 0.5  CFF Jac  FFC Jac}} \\
   1024  &   1.50  &  54  &   20  &  0.29 & 9.82 \\
   4096  &   1.51  &  54  &   20  &  0.30 & 9.98 \\
  16384  &   1.51  &  55  &   20  &  0.30 & 10.03 \\
  65536  &   1.52  &  55  &   20  &  0.30 & 10.06 \\
  262144 &   1.51  &  55  &   20  &  0.30 & 10.06 \\
 1048576 &   1.52  &  55  &   20  &  0.30 & 10.07 \\
  \bottomrule
  \end{tabular}
  \caption{ \clair\ results for grid-aligned anisotropic diffusion, multilevel results.}
  \label{tab:theta0_aniso_iterair}
  \end{table}
%%
\begin{table}[H]
  \centering
  \begin{tabular}{cccccc}
  \toprule
     n   & op comp & iter & piter & $\gamma$ & work \\
\midrule
\multicolumn{6}{c}{\textit{RN CG EnMin, deg=2, standard agg, , $A_{Unscaled}$  $B_{Smoothed}$ 5,  Strength 0.5  CFF Jac  FFC Jac}} \\
   1024  &   1.48  &  54  &   20  &  0.29 & 9.72 \\
   4096  &   1.51  &  54  &   20  &  0.29 & 10.00 \\
  16384  &   1.51  &  55  &   20  &  0.30 & 10.03 \\
  65536  &   1.52  &  55  &   20  &  0.30 & 10.06 \\
  262144 &   1.51  &  55  &   20  &  0.30 & 10.06 \\
 1048576 &   1.51  &  55  &   20  &  0.30 & 10.06 \\
  \bottomrule
  \end{tabular}
  \caption{ Root-node results for grid-aligned anisotropic diffusion, multilevel results.}
  \label{tab:theta0_aniso_RN}
  \end{table}

\section{Rotated $\pi/8$ anisotropic diffusion, Q1 elements}
  
Here, the best convergence mirrors the rootnode paper where larger sparsity patterns really help.

\begin{table}[H]
  \centering
  \begin{tabular}{cccccc}
  \toprule
     n   & op comp & iter & piter & $\gamma$ & work \\
\midrule
\multicolumn{6}{c}{\textit{AIR deg=2 $\theta=0.05$, $P_{classical}$, RS-1st, $\tau = 1e-4$, $A_{Unscaled}$  Strength 0.25  CFF Jac  FFC Jac}} \\
   1024  &   2.41  &  59  &   21  &  0.32 & 16.85 \\
   4096  &   2.63  &  60  &   22  &  0.33 & 18.90 \\
  16384  &   2.75  &  61  &   22  &  0.33 & 20.20 \\
  65536  &   2.82  &  62  &   23  &  0.35 & 21.43 \\
  262144 &   2.87  &  62  &   24  &  0.35 & 22.00 \\
 1048576 &   2.89  &  64  &   25  &  0.36 & 22.70 \\
\midrule
  \bottomrule
  \end{tabular}
  \caption{ Classic AIR results for rotated $\pi/8$ anisotropic diffusion, multilevel results.}
  \label{tab:thetapi8_aniso_air}
\end{table}
%%
\begin{table}[H]
  \centering
  \begin{tabular}{cccccc}
  \toprule
     n   & op comp & iter & piter & $\gamma$ & work \\
\midrule
\multicolumn{6}{c}{\textit{Iterair $R=P^T$, Iter AIR deg=2 exact theta 0.5 AggPattern, standard agg, , $A_{Unscaled}$  $B_{Smoothed}$ 5,  Strength 0.5  CFF Jac  FFC Jac}} \\
   1024  &   1.29  & 101  &   32  &  0.48 & 14.03 \\
   4096  &   1.30  & 101  &   40  &  0.55 & 17.51 \\
  16384  &   1.30  & 101  &   44  &  0.58 & 19.41 \\
  65536  &   1.31  & 101  &   45  &  0.59 & 19.98 \\
  262144 &   1.31  & 101  &   49  &  0.62 & 21.81 \\
 1048576 &   1.31  & 101  &   55  &  0.65 & 24.59 \\
 \midrule
\multicolumn{6}{c}{\textit{Iterair $R=P^T$, Iter AIR deg=4 exact theta 0.5 AggPattern, standard agg, , $A_{Unscaled}$  $B_{Smoothed}$ 5,  Strength 0.5  CFF Jac  FFC Jac}} \\
   1024  &   1.68  &  75  &   23  &  0.36 & 13.23 \\
   4096  &   1.84  &  99  &   28  &  0.43 & 17.31 \\
  16384  &   1.90  & 101  &   30  &  0.46 & 19.50 \\
  65536  &   1.95  & 101  &   31  &  0.46 & 20.48 \\
  262144 &   1.97  & 101  &   31  &  0.47 & 20.82 \\
 1048576 &   1.98  & 101  &   31  &  0.47 & 20.97 \\
  \bottomrule
  \end{tabular}
  \caption{ \clair\ results for rotated $\pi/8$ anisotropic diffusion, multilevel results.}
  \label{tab:thetapi8_aniso_iterair}
\end{table}
%%
\begin{table}[H]
  \centering
  \begin{tabular}{cccccc}
  \toprule
     n   & op comp & iter & piter & $\gamma$ & work \\
\midrule
\multicolumn{6}{c}{\textit{RN CG EnMin, deg=2, standard agg, , $A_{Unscaled}$  $B_{Smoothed}$ 5,  Strength 0.25  CFF Jac  FFC Jac}} \\
   1024  &   1.21  & 101  &   33  &  0.48 & 13.30 \\
   4096  &   1.23  & 101  &   37  &  0.53 & 15.48 \\
  16384  &   1.23  & 101  &   40  &  0.56 & 16.90 \\
  65536  &   1.24  & 101  &   45  &  0.59 & 18.83 \\
  262144 &   1.24  & 101  &   50  &  0.62 & 21.01 \\
 1048576 &   1.24  & 101  &   53  &  0.64 & 22.34 \\
 \midrule
\multicolumn{6}{c}{\textit{RN CG EnMin, deg=4, standard agg, , $A_{Unscaled}$  $B_{Smoothed}$ 5,  Strength 0.25  CFF Jac  FFC Jac}} \\
   1024  &   1.39  & 100  &   27  &  0.41 & 12.46 \\
   4096  &   1.47  & 101  &   29  &  0.44 & 14.29 \\
  16384  &   1.48  & 101  &   31  &  0.47 & 15.70 \\
  65536  &   1.51  & 101  &   33  &  0.48 & 16.71 \\
  262144 &   1.51  & 101  &   33  &  0.48 & 16.80 \\
 1048576 &   1.52  & 101  &   33  &  0.48 & 16.94 \\
 \bottomrule
  \end{tabular}
  \caption{ Root-node results for rotated $\pi/8$ anisotropic diffusion, multilevel results.}
  \label{tab:thetapi8_aniso_RN}
\end{table}

Now, for the jumping coefficients, directionality of strength of connection is key.  I had to be careful to use $A$ and not $A^T$ when constructing $P$.  Also, using $A_{FC}$ as the initial sparsity pattern did not work as well as using the aggregation based initial sparsity pattern.  So here, we use the aggregation initial sparsity pattern.
\newpage
\section{Jumping Coefficient, Box-in-a-box, Jump 1e4}
\begin{table}[H]
  \centering
  \begin{tabular}{cccccc}
  \toprule
     n   & op comp & iter & piter & $\gamma$ & work \\
\midrule
\multicolumn{6}{c}{\textit{AIR deg=2 $\theta=0.05$, $P_{classical}$, RS-1st, $\tau = 1e-4$, $A_{Unscaled}$  Strength 0.25  CFF Jac  FFC Jac}} \\
  676   &   2.39  & 101  &   10  &  0.08 & 7.69 \\
  2601  &   2.57  & 101  &   10  &  0.05 & 7.06 \\
 10201  &   2.64  & 101  &   11  &  0.06 & 7.63 \\
 40401  &   2.69  & 101  &   11  &  0.07 & 8.15 \\
 160801 &   2.72  & 101  &   12  &  0.08 & 8.86 \\
 641601 &   2.73  & 101  &   12  &  0.09 & 9.15 \\
  \bottomrule
  \end{tabular}
  \caption{ Classic AIR results for 2D Coefficient Jump of 1e4, Box-in-a-Box, multilevel results.}
  \label{tab:coeffjump_air}
\end{table}
%%
\begin{table}[H]
  \centering
  \begin{tabular}{cccccc}
  \toprule
     n   & op comp & iter & piter & $\gamma$ & work \\
\midrule
\multicolumn{6}{c}{\textit{Iterair $R=P^T$, Iter AIR deg=2 exact theta 0.5 AggPattern, standard agg, , $A_{Unscaled}$  $B_{Smoothed}$ 5,  Strength 0.5  CFF Jac  FFC Jac}} \\
  676   &   1.43  &  51  &   17  &  0.17 & 6.43 \\
  2601  &   1.43  &  43  &   18  &  0.18 & 6.64 \\
 10201  &   1.41  &  47  &   20  &  0.22 & 7.58 \\
 40401  &   1.41  &  90  &   25  &  0.30 & 9.30 \\
 160801 &   1.40  &  79  &   25  &  0.30 & 9.30 \\
 641601 &   1.40  &  66  &   25  &  0.30 & 9.34 \\
  \bottomrule
  \end{tabular}
  \caption{ \clair\ results for 2D Coefficient Jump of 1e4, Box-in-a-Box, multilevel results.}
  \label{tab:coeffjump_iterair}
\end{table}
%%
\begin{table}[H]
  \centering
  \begin{tabular}{cccccc}
  \toprule
     n   & op comp & iter & piter & $\gamma$ & work \\
\midrule
\multicolumn{6}{c}{\textit{RN CG EnMin, deg=2, standard agg, , $A_{Unscaled}$  $B_{Smoothed}$ 5,  Strength 0.25  CFF Jac  FFC Jac}} \\
  676   &   1.37  &  41  &   17  &  0.17 & 6.29 \\
  2601  &   1.36  &  64  &   20  &  0.21 & 7.04 \\
 10201  &   1.35  &  82  &   23  &  0.26 & 8.08 \\
 40401  &   1.34  &  77  &   24  &  0.28 & 8.39 \\
 160801 &   1.34  &  52  &   23  &  0.26 & 8.09 \\
 641601 &   1.34  &  88  &   27  &  0.33 & 9.61 \\
  \bottomrule
  \end{tabular}
  \caption{ Root-node results for 2D Coefficient Jump of 1e4, Box-in-a-Box, multilevel results.}
  \label{tab:coeffjump_RN}
\end{table}


\newpage
\section{Jumping Coefficient, Sawtooth, Jump 1e4}

\begin{table}[H]
  \centering
  \begin{tabular}{cccccc}
  \toprule
     n   & op comp & iter & piter & $\gamma$ & work \\
\midrule
\multicolumn{6}{c}{\textit{AIR deg=2 $\theta=0.05$, $P_{classical}$, RS-1st, $\tau = 1e-4$, $A_{Unscaled}$  Strength 0.25  CFF Jac  FFC Jac}} \\
   1089  &   2.31  &  13  &   9   &  0.05 & 6.21 \\
   4225  &   2.46  &  14  &   9   &  0.06 & 7.21 \\
  16641  &   2.56  &  16  &   11  &  0.10 & 9.06 \\
  66049  &   2.64  &  16  &   11  &  0.10 & 9.04 \\
  263169 &   2.68  &  15  &   13  &  0.13 & 10.59 \\
 1050625 &   2.71  &  14  &   12  &  0.11 & 9.97 \\
  \bottomrule
  \end{tabular}
  \caption{ Classic AIR results for 2D Coefficient Jump of 1e4, Saw-Shaped Jump Region, multilevel results.}
  \label{tab:coeffjumpSaw_air}
\end{table}
%%
\begin{table}[H]
  \centering
  \begin{tabular}{cccccc}
  \toprule
     n   & op comp & iter & piter & $\gamma$ & work \\
\midrule
\multicolumn{6}{c}{\textit{Iterair $R=P^T$, Iter AIR deg=2 exact theta 0.5 AggPattern, standard agg, , $A_{Unscaled}$  $B_{Smoothed}$ 5,  Strength 0.5  CFF Jac  FFC Jac}} \\
   1089  &   1.43  &  59  &   23  &  0.24 & 8.03 \\
   4225  &   1.44  &  63  &   26  &  0.27 & 8.95 \\
  16641  &   1.43  &  75  &   27  &  0.29 & 9.38 \\
  66049  &   1.43  &  78  &   29  &  0.31 & 9.80 \\
  263169 &   1.42  &  80  &   29  &  0.32 & 10.04 \\
 1050625 &   1.42  &  85  &   32  &  0.35 & 10.87 \\
 \bottomrule
  \end{tabular}
  \caption{ \clair\ results for 2D Coefficient Jump of 1e4, Saw-Shaped Jump Region, multilevel results.}
  \label{tab:coeffjumpSaw_iterair}
\end{table}
%%
\begin{table}[H]
  \centering
  \begin{tabular}{cccccc}
  \toprule
     n   & op comp & iter & piter & $\gamma$ & work \\
\midrule
\multicolumn{6}{c}{\textit{RN CG EnMin, deg=2, standard agg, , $A_{Unscaled}$  $B_{Smoothed}$ 5,  Strength 0.25  CFF Jac  FFC Jac}} \\
   1089  &   1.38  &  68  &   24  &  0.25 & 7.93 \\
   4225  &   1.38  &  73  &   25  &  0.27 & 8.41 \\
  16641  &   1.37  &  67  &   27  &  0.28 & 8.76 \\
  66049  &   1.36  &  83  &   29  &  0.31 & 9.45 \\
  263169 &   1.35  &  82  &   29  &  0.32 & 9.54 \\
 1050625 &   1.35  &  89  &   31  &  0.34 & 10.12 \\
   \bottomrule
  \end{tabular}
  \caption{ Root-node results for 2D Coefficient Jump of 1e4, Saw-Shaped Jump Region, multilevel results.}
  \label{tab:coeffjumpSaw_RN}
\end{table}

\newpage
\section{Constant Advection with various Diffusion Constants $\alpha$ Values}

% The test data is in 
%     same_params_results_nonsymm, which holds RN and lAIR results
%     and
%     same_params_results_nonsymme_FCC, which holds CLAIR results for FCC relaxation for improve_candidates
\begin{table}[H]
  \centering
  \begin{tabular}{ccccccc}
  \toprule
     $\alpha$ & n   & op comp & iter & piter & $\gamma$ & work \\
  \midrule
  \multicolumn{7}{c}{\textit{AIR deg=2 $\theta=0.05$, $P_{classical}$, RS-2nd, $\tau = 1e-4$, $A_{Scaled}$  Strength 0.25  CFF Jac  FFC Jac}} \\
 \midrule  
  %       &   1024  &   2.84  &  10  &   8   &  0.05 & 7.75 \\
  %       &   4096  &   3.02  &  10  &   9   &  0.06 & 8.56 \\
  10.0    &  16384  &   3.10  &  11  &   9   &  0.07 & 9.41 \\
          &  65536  &   3.15  &  12  &   10  &  0.08 & 9.82 \\
          &  262144 &   3.18  &  12  &   11  &  0.10 & 11.32 \\
          & 1048576 &   3.19  &  14  &   13  &  0.14 & 13.90 \\
 \midrule  
 %        &   1024  &   2.80  &  10  &   9   &  0.05 & 7.56 \\
 %        &   4096  &   3.04  &  10  &   9   &  0.07 & 9.03 \\
   1.0    &  16384  &   3.12  &  10  &   10  &  0.07 & 9.23 \\
          &  65536  &   3.15  &  11  &   10  &  0.08 & 9.90 \\
          &  262144 &   3.18  &  11  &   11  &  0.11 & 11.65 \\
          & 1048576 &   3.19  &  13  &   13  &  0.15 & 13.32 \\
 \midrule  
 %        &   1024  &   3.32  &  8   &   8   &  0.05 & 8.65 \\
 %        &   4096  &   3.23  &  10  &   9   &  0.07 & 9.76 \\
  0.1     &  16384  &   3.06  &  9   &   9   &  0.07 & 9.09 \\
          &  65536  &   3.14  &  10  &   10  &  0.09 & 10.72 \\
          &  262144 &   3.18  &  10  &   11  &  0.11 & 11.49 \\
          & 1048576 &   3.20  &  11  &   12  &  0.13 & 12.74 \\
 \midrule  
 %        &   1024  &   2.59  &  6   &   6   &  0.02 & 5.19 \\
 %        &   4096  &   3.36  &  7   &   7   &  0.02 & 7.11 \\
   0.01   &  16384  &   3.45  &  8   &   8   &  0.05 & 9.25 \\
          &  65536  &   3.56  &  9   &   9   &  0.07 & 10.61 \\
          &  262144 &   3.14  &  11  &   12  &  0.11 & 11.67 \\
          & 1048576 &   3.19  &  10  &   10  &  0.08 & 10.35 \\
 \midrule  
 %        &   1024  &   2.67  &  7   &   7   &  0.03 & 5.93 \\
 %        &   4096  &   2.89  &  8   &   7   &  0.03 & 6.82 \\
   0.001  &  16384  &   3.12  &  8   &   8   &  0.04 & 7.55 \\
          &  65536  &   3.55  &  9   &   10  &  0.07 & 10.70 \\
          &  262144 &   3.58  &  7   &   7   &  0.03 & 8.18 \\
          & 1048576 &   3.70  &  10  &   10  &  0.08 & 11.62 \\
 \midrule  
 %        &   1024  &   2.73  &  6   &   6   &  0.02 & 5.56 \\
 %        &   4096  &   2.87  &  8   &   8   &  0.03 & 6.75 \\
  0.0001  &  16384  &   3.15  &  9   &   9   &  0.06 & 9.11 \\
          &  65536  &   3.20  &  10  &   10  &  0.09 & 10.61 \\
          &  262144 &   3.15  &  10  &   11  &  0.10 & 11.08 \\
          & 1048576 &   3.19  &  9   &   10  &  0.07 & 9.72 \\
 \midrule  
 %        &   1024  &   3.14  &  6   &   6   &  0.02 & 6.33 \\
 %        &   4096  &   3.45  &  7   &   7   &  0.03 & 7.90 \\
   0.0    &  16384  &   3.70  &  8   &   9   &  0.05 & 9.86 \\
          &  65536  &   3.90  &  9   &   10  &  0.07 & 12.04 \\
          &  262144 &   4.06  &  11  &   11  &  0.11 & 14.67 \\
          & 1048576 &   4.28  &  13  &   13  &  0.15 & 18.23 \\
  \bottomrule
  \end{tabular}
  \caption{ Classic AIR results for constant advection with varying $\alpha$, multilevel results.}
   \label{tab:constadv_varygamma_air}
\end{table}
%%
\begin{table}[H]
  \centering
  \begin{tabular}{ccccccc}
  \toprule
     $\alpha$ & n   & op comp & iter & piter & $\gamma$ & work \\
  \midrule
 \multicolumn{7}{c}{\textit{Iter AIR deg=2 $\theta=0.05$, $P_{classical}$, RS-1st, , $A_{Scaled}$  $B_{Smoothed}$ 5 CFF-J,  Strength 0.25  CFF Jac  FFC Jac}} \\
  \midrule
   %       &    1024  &   2.48  &  10  &   9   &  0.06 & 6.91 \\
   %       &    4096  &   2.72  &  9   &   9   &  0.06 & 7.63 \\
   10.0    &   16384  &   2.84  &  9   &   9   &  0.06 & 8.21 \\
           &   65536  &   2.93  &  9   &   9   &  0.06 & 8.54 \\
           &   262144 &   2.96  &  9   &   9   &  0.07 & 8.90 \\
           &  1048576 &   2.99  &  9   &   9   &  0.07 & 9.10 \\
  \midrule  
  %        &   1024  &   2.46  &  10  &   9   &  0.07 & 7.36 \\
  %        &   4096  &   2.67  &  10  &   9   &  0.06 & 7.82 \\
    1.0    &  16384  &   2.82  &  9   &   9   &  0.07 & 8.52 \\
           &  65536  &   2.88  &  9   &   9   &  0.07 & 8.71 \\
           &  262144 &   2.93  &  9   &   9   &  0.07 & 8.84 \\
           & 1048576 &   2.97  &  9   &   9   &  0.07 & 9.03 \\
  \midrule  
  %        &   1024  &   2.48  &  17  &   12  &  0.12 & 9.39 \\
  %        &   4096  &   2.49  &  13  &   12  &  0.14 & 10.15 \\\
   0.1     &  16384  &   2.70  &  10  &   11  &  0.09 & 9.16 \\
           &  65536  &   2.77  &  11  &   11  &  0.10 & 9.58 \\
           &  262144 &   2.87  &  10  &   10  &  0.09 & 9.61 \\
           & 1048576 &   2.94  &  9   &   10  &  0.08 & 9.59 \\
  \midrule  
  %        &   1024  &   2.41  &  9   &   8   &  0.05 & 6.27 \\
  %        &   4096  &   2.83  &  9   &   9   &  0.06 & 7.89 \\
    0.01   &  16384  &   2.37  &  9   &   10  &  0.08 & 7.69 \\
           &  65536  &   2.93  &  18  &   13  &  0.16 & 12.73 \\
           &  262144 &   2.72  &  13  &   12  &  0.14 & 11.03 \\
           & 1048576 &   2.81  &  13  &   12  &  0.12 & 10.68 \\
  \midrule  
  %        &   1024  &   1.93  &  9   &   8   &  0.05 &  5.09 \\
  %        &   4096  &   2.27  &  9   &   9   &  0.06 &  6.49 \\
    0.001  &  16384  &   2.22  &  10  &   10  &  0.08 &  7.12 \\
           &  65536  &   2.69  &  25  &   23  &  0.35 &  20.82 \\
           &  262144 &   2.76  &  11  &   10  &  0.08 &  8.74 \\
           & 1048576 &   2.72  &  18  &   15  &  0.13 &  11.35 \\ % constant_advection_gamma0_001_theta_tweak.txt
  \midrule  
  %        &   1024  &   1.86  &  8   &   8   &  0.03 & 4.42 \\
  %        &   4096  &   2.20  &  10  &   9   &  0.06 & 6.26 \\
   0.0001  &  16384  &   2.24  &  11  &   11  &  0.10 & 7.85 \\
           &  65536  &   2.51  &  12  &   11  &  0.11 & 9.28 \\
           &  262144 &   2.71  &  12  &   12  &  0.12 & 10.16 \\
           & 1048576 &   2.67  &  14  &   13  &  0.11 & 9.78 \\
  \midrule  
  %        &   1024  &   2.06  &  8   &   8   &  0.04 & 5.08 \\
  %        &   4096  &   2.34  &  9   &   9   &  0.05 & 6.48 \\
    0.0    &  16384  &   2.68  &  10  &   10  &  0.09 & 8.86 \\
           &  65536  &   2.85  &  12  &   12  &  0.13 & 11.17 \\
           &  262144 &   3.00  &  16  &   15  &  0.20 & 14.87 \\
           & 1048576 &   3.10  &  19  &   18  &  0.26 & 18.44 \\
  \bottomrule
  \end{tabular}
  \caption{ \clair\ results for constant advection with varying $\alpha$, multilevel results.}
  \label{tab:constadv_varygamma_iterair}
\end{table}
%%
\begin{table}[H]
  \centering
  \begin{tabular}{ccccccc}
  \toprule
     $\alpha$ & n   & op comp & iter & piter & $\gamma$ & work \\
  \midrule
 \multicolumn{7}{c}{\textit{RN GMRES EnMin, deg=2, standard agg, , $A_{Scaled}$  $B_{Smoothed}$ 5 CFF-J,  Strength 0.25  CFF Jac  FFC Jac}} \\
  \midrule
   %       &   1024  &   1.21  &  37  &   18  &  0.26 & 7.22 \\
   %       &   4096  &   1.21  &  39  &   19  &  0.27 & 7.48 \\
   10.0    &  16384  &   1.21  &  39  &   19  &  0.28 & 7.69 \\
           &  65536  &   1.20  &  40  &   20  &  0.30 & 8.04 \\
           &  262144 &   1.20  &  41  &   22  &  0.33 & 8.70 \\
           & 1048576 &   1.20  &  43  &   22  &  0.33 & 8.77 \\
  \midrule  
  %        &   1024  &   1.21  &  35  &   18  &  0.25 & 7.07 \\
  %        &   4096  &   1.21  &  37  &   18  &  0.27 & 7.39 \\
    1.0    &  16384  &   1.21  &  38  &   19  &  0.28 & 7.68 \\
           &  65536  &   1.20  &  38  &   20  &  0.29 & 7.85 \\
           &  262144 &   1.20  & 101  &   22  &  0.27 & 7.41 \\
           & 1048576 &   1.20  &  44  &   23  &  0.34 & 9.01 \\
  \midrule  
  %        &   1024  &   1.32  &  26  &   16  &  0.22 & 7.01 \\
  %        &   4096  &   1.37  &  25  &   16  &  0.23 & 7.45 \\
   0.1     &  16384  &   1.40  &  24  &   16  &  0.23 & 7.63 \\
           &  65536  &   1.20  &  37  &   21  &  0.31 & 8.31 \\
           &  262144 &   1.20  &  37  &   22  &  0.34 & 8.88 \\
           & 1048576 &   1.20  &  38  &   23  &  0.35 & 9.30 \\
  \midrule  
  %        &   1024  &   1.42  &  34  &   19  &  0.27 & 8.79 \\
  %        &   4096  &   1.45  & 101  &   17  &  0.24 & 8.16 \\
    0.01   &  16384  &   1.46  & 101  &   21  &  0.29 & 9.50 \\
           &  65536  &   1.43  & 101  &   25  &  0.31 & 9.88 \\
           &  262144 &   1.42  & 101  &   25  &  0.36 & 11.18 \\
           & 1048576 &   1.42  & 101  &   26  &  0.33 & 10.35 \\
  \midrule  
  %        &   1024  &   **    & DNC  &  DNC  &  **   & **\\
  %        &   4096  &   **    & DNC  &  DNC  &  **   & **\\
    0.001  &  16384  &   **    & DNC  &  DNC  &  **   & **\\
           &  65536  &   **    & DNC  &  DNC  &  **   & ** \\
           &  262144 &   **    & DNC  &  DNC  &  **   & ** \\
           & 1048576 &   **    & DNC  &  DNC  &  **   & **\\  
  \midrule  
  %        &   1024  &   **    & DNC  &  DNC  &  **   & **\\
  %        &   4096  &   **    & DNC  &  DNC  &  **   & **\\
   0.0001  &  16384  &   **    & DNC  &  DNC  &  **   & **\\
           &  65536  &   **    & DNC  &  DNC  &  **   & ** \\
           &  262144 &   **    & DNC  &  DNC  &  **   & ** \\
           & 1048576 &   **    & DNC  &  DNC  &  **   & **\\ 
  \midrule  
  %        &   1024  &   **    & DNC  &  DNC  &  **   & **\\
  %        &   4096  &   **    & DNC  &  DNC  &  **   & **\\
    0.0    &  16384  &   **    & DNC  &  DNC  &  **   & **\\
           &  65536  &   **    & DNC  &  DNC  &  **   & ** \\
           &  262144 &   **    & DNC  &  DNC  &  **   & ** \\
           & 1048576 &   **    & DNC  &  DNC  &  **   & **\\ 
  \bottomrule
  \end{tabular}
  \caption{ Root-node results for constant advection with varying $\alpha$, multilevel results.}
  \label{tab:constadv_varygamma_RN}
\end{table}
%%
\begin{table}[H]
  \centering
  \begin{tabular}{ccccccc}
  \toprule
     $\alpha$ & n   & op comp & iter & piter & $\gamma$ & work \\
  \midrule
 \multicolumn{7}{c}{\textit{Iter AIR deg=2 $\theta=0.05$, $P =$ Iter AIR deg=2 $\theta=0.05$, standard agg, , $A_{Scaled}$  $B_{Smoothed}$ 5 CFF-J,  Strength 0.25  CFF Jac  FFC Jac}} \\
  \midrule
   %       &   1024  &   1.31  & 101  &   18  &  0.25 & 7.70 \\
   %       &   4096  &   1.32  & 101  &   21  &  0.29 & 8.49 \\
   10.0    &  16384  &   1.30  & 101  &   20  &  0.24 & 7.44 \\
           &  65536  &   1.29  & 101  &   24  &  0.32 & 9.16 \\
           &  262144 &   1.29  & 101  &   22  &  0.33 & 9.45 \\
           & 1048576 &   1.28  & 101  &   22  &  0.33 & 9.25 \\
  \midrule  
  %        &   1024  &   1.31  &  42  &   17  &  0.24 & 7.35 \\
  %        &   4096  &   1.32  &  81  &   19  &  0.28 & 8.27 \\
    1.0    &  16384  &   1.30  & 101  &   21  &  0.31 & 8.95 \\
           &  65536  &   1.29  & 101  &   20  &  0.29 & 8.41 \\
           &  262144 &   1.29  & 101  &   24  &  0.33 & 9.47 \\
           & 1048576 &   1.28  & 101  &   21  &  0.31 & 8.89 \\
  \midrule  
  %        &   1024  &   1.61  &  31  &   16  &  0.21 & 8.26 \\
  %        &   4096  &   1.75  &  30  &   16  &  0.21 & 9.08 \\
   0.1     &  16384  &   1.86  &  30  &   17  &  0.23 & 10.27 \\
           &  65536  &   1.29  &  38  &   18  &  0.26 & 7.76 \\
           &  262144 &   1.29  &  48  &   19  &  0.29 & 8.32 \\
           & 1048576 &   1.29  & 101  &   22  &  0.33 & 9.35 \\
  \midrule  
  %        &   1024  &   1.61  & 101  &   57  &  0.75 & 44.99 \\
  %        &   4096  &   1.71  &  30  &   22  &  0.33 & 12.38 \\
    0.01   &  16384  &   1.74  &  19  &   20  &  0.30 & 11.70 \\
           &  65536  &   1.89  &  24  &   18  &  0.20 & 9.59 \\
           &  262144 &   1.94  &  26  &   18  &  0.22 & 10.31 \\
           & 1048576 &   1.96  &  27  &   19  &  0.25 & 11.52 \\
  \midrule  
  %        &   1024  &   **    & DNC  &  DNC  &  **   & **\\
  %        &   4096  &   **    & DNC  &  DNC  &  **   & **\\
    0.001  &  16384  &   **    & DNC  &  DNC  &  **   & **\\
           &  65536  &   **    & DNC  &  DNC  &  **   & ** \\
           &  262144 &   **    & DNC  &  DNC  &  **   & ** \\
           & 1048576 &   **    & DNC  &  DNC  &  **   & **\\  
  \midrule  
  %        &   1024  &   **    & DNC  &  DNC  &  **   & **\\
  %        &   4096  &   **    & DNC  &  DNC  &  **   & **\\
   0.0001  &  16384  &   **    & DNC  &  DNC  &  **   & **\\
           &  65536  &   **    & DNC  &  DNC  &  **   & ** \\
           &  262144 &   **    & DNC  &  DNC  &  **   & ** \\
           & 1048576 &   **    & DNC  &  DNC  &  **   & **\\ 
  \midrule  
  %        &   1024  &   **    & DNC  &  DNC  &  **   & **\\
  %        &   4096  &   **    & DNC  &  DNC  &  **   & **\\
    0.0    &  16384  &   **    & DNC  &  DNC  &  **   & **\\
           &  65536  &   **    & DNC  &  DNC  &  **   & ** \\
           &  262144 &   **    & DNC  &  DNC  &  **   & ** \\
           & 1048576 &   **    & DNC  &  DNC  &  **   & **\\ 
  \bottomrule
  \end{tabular}
  \caption{ Low-complexity \clair\ results for constant advection with varying $\alpha$, multilevel results.}
   \label{tab:constadv_varygamma_lowcompCLAIR}
\end{table}


\newpage
\section{Recirculating Advection with Various Diffusion Constants $\alpha$ values}

\begin{table}[H]
  \centering
  \begin{tabular}{ccccccc}
  \toprule
     $\alpha$ & n   & op comp & iter & piter & $\gamma$ & work \\
  \midrule
  \multicolumn{7}{c}{\textit{AIR deg=2 $\theta=0.05$, $P_{classical}$, RS-2nd, $\tau = 1e-4$, $A_{Scaled}$  Strength 0.25  CFF Jac  FFC Jac}} \\ 
 \midrule  
 %        &   1024  &   2.84  &  10  &   8   &  0.05 & 7.75 \\
 %        &   4096  &   3.01  &  10  &   9   &  0.05 & 8.30 \\
  10.0    &  16384  &   3.10  &  11  &   9   &  0.07 & 9.54 \\
          &  65536  &   3.16  &  11  &   10  &  0.07 & 9.55 \\
          &  262144 &   3.18  &  12  &   11  &  0.10 & 11.28 \\
          & 1048576 &   3.19  &  13  &   13  &  0.14 & 13.23 \\
 \midrule  
 %        &   1024  &   2.84  &  10  &   8   &  0.05 & 7.59 \\
 %        &   4096  &   3.02  &  10  &   9   &  0.05 & 8.32 \\
   1.0    &  16384  &   3.11  &  10  &   9   &  0.06 & 8.97 \\
          &  65536  &   3.15  &  11  &   10  &  0.08 & 9.99 \\
          &  262144 &   3.18  &  11  &   11  &  0.11 & 11.36 \\
          & 1048576 &   3.19  &  12  &   13  &  0.14 & 13.05 \\
 \midrule  
 %        &   1024  &   2.84  &  9   &   8   &  0.04 & 7.38 \\
 %        &   4096  &   2.97  &  9   &   9   &  0.06 & 8.34 \\
  0.1     &  16384  &   3.11  &  10  &   10  &  0.07 & 9.58 \\
          &  65536  &   3.16  &  10  &   11  &  0.09 & 10.59 \\
          &  262144 &   3.17  &  11  &   11  &  0.11 & 11.50 \\
          & 1048576 &   3.19  &  11  &   12  &  0.13 & 12.66 \\
 \midrule  
 %        &   1024  &   2.76  &  8   &   8   &  0.04 & 7.07 \\
 %        &   4096  &   3.05  &  9   &   9   &  0.06 & 8.70 \\
   0.01   &  16384  &   3.19  &  9   &   9   &  0.07 & 9.47 \\
          &  65536  &   3.24  &  9   &   10  &  0.08 & 10.37 \\
          &  262144 &   3.24  &  11  &   11  &  0.11 & 11.75 \\
          & 1048576 &   3.22  &  11  &   12  &  0.12 & 12.00 \\
 \midrule  
 %        &   1024  &   2.82  &  12  &   9   &  0.05 & 7.64 \\
 %        &   4096  &   3.01  &  14  &   9   &  0.06 & 8.56 \\
   0.001  &  16384  &   3.30  &  12  &   9   &  0.07 & 10.01 \\
          &  65536  &   3.37  &  14  &   11  &  0.10 & 11.64 \\
          &  262144 &   3.47  &  11  &   11  &  0.09 & 11.85 \\
          & 1048576 &   3.44  &  11  &   11  &  0.11 & 12.83 \\
 \midrule  
 %        &   1024  &   2.42  &  16  &   11  &  0.09 & 7.91 \\
 %        &   4096  &   2.77  &  11  &   9   &  0.07 & 8.40 \\
  0.0001  &  16384  &   3.11  &  12  &   10  &  0.07 & 9.31 \\
          &  65536  &   3.37  & 101  &   15  &  0.19 & 16.30 \\
          &  262144 &   3.45  & 101  &   17  &  0.24 & 19.67 \\
          & 1048576 &   3.56  & 101  &   32  &  0.41 & 32.47 \\
  \bottomrule
  \end{tabular}
  \caption{ Classic AIR results for div-free advection with varying $\alpha$, multilevel results.}
   \label{tab:divfree_adv_varygamma_air}
\end{table}
%%
\begin{table}[H]
  \centering
  \begin{tabular}{ccccccc}
  \toprule
     $\alpha$ & n   & op comp & iter & piter & $\gamma$ & work \\
  \midrule
 \multicolumn{7}{c}{\textit{Iter AIR deg=2 $\theta=0.05$, $P_{classical}$, RS-1st, , $A_{Scaled}$  $B_{Smoothed}$ 5 CFF-J,  Strength 0.25  CFF Jac  FFC Jac}} \\
  \midrule
   %       &   1024  &   2.49  &  9   &   9   &  0.05 & 6.72 \\
   %       &   4096  &   2.74  &  9   &   9   &  0.06 & 7.74 \\
   10.0    &  16384  &   2.85  &  9   &   9   &  0.06 & 8.33 \\
           &  65536  &   2.93  &  9   &   9   &  0.06 & 8.60 \\
           &  262144 &   2.97  &  9   &   9   &  0.07 & 8.92 \\
           & 1048576 &   2.99  &  9   &   9   &  0.07 & 9.10 \\
  \midrule  
  %        &   1024  &   2.52  &  11  &   9   &  0.07 & 7.63 \\
  %        &   4096  &   2.70  &  10  &   9   &  0.07 & 8.12 \\
    1.0    &  16384  &   2.83  &  9   &   9   &  0.06 & 8.21 \\
           &  65536  &   2.91  &  9   &   9   &  0.07 & 8.73 \\
           &  262144 &   2.94  &  9   &   9   &  0.07 & 8.74 \\
           & 1048576 &   2.97  &  9   &   10  &  0.07 & 9.05 \\
  \midrule  
  %        &   1024  &   2.55  &  11  &   10  &  0.07 & 7.81 \\
  %        &   4096  &   2.67  &  9   &   10  &  0.08 & 8.41 \\
   0.1     &  16384  &   2.79  &  23  &   12  &  0.14 & 11.23 \\
           &  65536  &   2.85  &  13  &   12  &  0.13 & 11.13 \\
           &  262144 &   2.90  &  11  &   11  &  0.11 & 10.68 \\
           & 1048576 &   2.95  &  10  &   10  &  0.08 & 9.49 \\
  \midrule  
  %        &   1024  &   2.36  &  11  &   9   &  0.07 & 7.06 \\
  %        &   4096  &   2.56  &  11  &   10  &  0.07 & 7.91 \\
    0.01   &  16384  &   2.71  &  11  &   11  &  0.10 & 9.33 \\
           &  65536  &   2.75  &  12  &   12  &  0.13 & 11.03 \\
           &  262144 &   2.82  &  12  &   12  &  0.14 & 11.47 \\
           & 1048576 &   2.86  &  28  &   15  &  0.19 & 13.92 \\
  \midrule  
  %        &   1024  &   2.01  & 101  &   11  &  0.10 & 7.12 \\
  %        &   4096  &   2.32  &  13  &   11  &  0.10 & 8.19 \\
    0.001  &  16384  &   2.56  &  13  &   11  &  0.09 & 8.64 \\
           &  65536  &   2.68  &  13  &   12  &  0.13 & 10.56 \\
           &  262144 &   2.79  &  13  &   13  &  0.14 & 11.36 \\
           & 1048576 &   2.84  &  14  &   14  &  0.18 & 13.34 \\
  \midrule  
  %        &   1024  &   1.85  &  19  &   12  &  0.10 & 6.61 \\
  %        &   4096  &   2.12  &  18  &   12  &  0.12 & 8.20 \\
   0.0001  &  16384  &   2.29  &  17  &   13  &  0.15 & 9.76 \\
           &  65536  &   2.43  &  13  &   13  &  0.13 & 9.50 \\
           &  262144 &   2.54  &  17  &   16  &  0.14 & 10.57 \\
           & 1048576 &   2.71  &  17  &   15  &  0.14 & 11.21 \\
  \bottomrule
  \end{tabular}
  \caption{ \clair\ results for div-free advection with varying $\alpha$, multilevel results.}
  \label{tab:divfree_adv_varygamma_iterair}
\end{table}
%%
\begin{table}[H]
  \centering
  \begin{tabular}{ccccccc}
  \toprule
     $\alpha$ & n   & op comp & iter & piter & $\gamma$ & work \\
  \midrule
 \multicolumn{7}{c}{\textit{RN GMRES EnMin, deg=2, standard agg, , $A_{Scaled}$  $B_{Smoothed}$ 5 CFF-J,  Strength 0.25  wJac x2  FFC Jac}} \\
  \midrule
   %       &   1024  &   1.21  &  39  &   18  &  0.26 & 7.27 \\
   %       &   4096  &   1.21  &  39  &   19  &  0.27 & 7.48 \\
   10.0    &  16384  &   1.21  &  39  &   19  &  0.28 & 7.70 \\
           &  65536  &   1.20  &  39  &   20  &  0.28 & 7.68 \\
           &  262144 &   1.20  &  46  &   22  &  0.31 & 8.36 \\
           & 1048576 &   1.20  &  46  &   22  &  0.34 & 9.05 \\
  \midrule  
  %        &   1024  &   1.24  &  36  &   18  &  0.25 & 7.09 \\
  %        &   4096  &   1.22  &  38  &   18  &  0.26 & 7.37 \\
    1.0    &  16384  &   1.21  &  39  &   19  &  0.27 & 7.46 \\
           &  65536  &   1.20  &  39  &   20  &  0.29 & 7.81 \\
           &  262144 &   1.20  &  41  &   21  &  0.31 & 8.34 \\
           & 1048576 &   1.20  &  43  &   22  &  0.33 & 8.60 \\
  \midrule  
  %        &   1024  &   1.29  &  33  &   18  &  0.25 & 7.49 \\
  %        &   4096  &   1.29  &  36  &   19  &  0.28 & 8.13 \\
   0.1     &  16384  &   1.26  &  37  &   21  &  0.31 & 8.68 \\
           &  65536  &   1.23  &  38  &   22  &  0.33 & 9.00 \\
           &  262144 &   1.20  & 101  &   23  &  0.29 & 7.76 \\
           & 1048576 &   1.20  &  40  &   24  &  0.37 & 9.70 \\
  \midrule  
  %        &   1024  &   1.31  & 101  &   25  &  0.35 & 10.17 \\
  %        &   4096  &   1.34  & 101  &   30  &  0.44 & 12.99 \\
    0.01   &  16384  &   1.34  & 101  &   48  &  0.57 & 19.44 \\
           &  65536  &   1.33  & 101  &   35  &  0.48 & 14.39 \\
           &  262144 &   1.30  & 101  &   32  &  0.45 & 13.07 \\
           & 1048576 &   1.27  & 101  &   33  &  0.46 & 13.08 \\
  \midrule  
  %        &   1024  &   **    & DNC  &  DNC  &  **   & **\\
  %        &   4096  &   **    & DNC  &  DNC  &  **   & **\\
    0.001  &  16384  &   **    & DNC  &  DNC  &  **   & **\\
           &  65536  &   **    & DNC  &  DNC  &  **   & ** \\
           &  262144 &   **    & DNC  &  DNC  &  **   & ** \\
           & 1048576 &   **    & DNC  &  DNC  &  **   & **\\ 
  \midrule  
  %        &   1024  &   **    & DNC  &  DNC  &  **   & **\\
  %        &   4096  &   **    & DNC  &  DNC  &  **   & **\\
   0.0001  &  16384  &   **    & DNC  &  DNC  &  **   & **\\
           &  65536  &   **    & DNC  &  DNC  &  **   & ** \\
           &  262144 &   **    & DNC  &  DNC  &  **   & ** \\
           & 1048576 &   **    & DNC  &  DNC  &  **   & **\\ 
  \bottomrule
  \end{tabular}
  \caption{ Root-node results for div-free advection with varying $\alpha$, multilevel results.}
  \label{tab:divfree_adv_varygamma_RN}
\end{table}
%%
\begin{table}[H]
  \centering
  \begin{tabular}{ccccccc}
  \toprule
     $\alpha$ & n   & op comp & iter & piter & $\gamma$ & work \\
  \midrule
 \multicolumn{7}{c}{\textit{Iter AIR deg=2 $\theta=0.05$, $P =$ Iter AIR deg=2 $\theta=0.05$, standard agg, , $A_{Scaled}$  $B_{Smoothed}$ 5 CFF-J,  Strength 0.25  CFF Jac  FFC Jac}} \\
  \midrule
   %       &   1024  &   1.31  &  62  &   17  &  0.24 & 7.40 \\
   %       &   4096  &   1.32  & 101  &   20  &  0.29 & 8.57 \\
   10.0    &  16384  &   1.30  & 101  &   22  &  0.32 & 9.30 \\
           &  65536  &   1.29  & 101  &   20  &  0.30 & 8.68 \\
           &  262144 &   1.29  & 101  &   25  &  0.35 & 9.81 \\
           & 1048576 &   1.28  & 101  &   22  &  0.34 & 9.49 \\
  \midrule  
  %        &   1024  &   1.35  &  30  &   16  &  0.22 & 7.21 \\
  %        &   4096  &   1.32  &  31  &   17  &  0.24 & 7.43 \\
    1.0    &  16384  &   1.30  &  32  &   18  &  0.25 & 7.54 \\
           &  65536  &   1.29  &  51  &   18  &  0.26 & 7.81 \\
           &  262144 &   1.29  & 101  &   21  &  0.32 & 9.01 \\
           & 1048576 &   1.28  & 101  &   22  &  0.32 & 9.15 \\
  \midrule  
  %        &   1024  &   1.52  &  29  &   17  &  0.24 & 8.51 \\
  %        &   4096  &   1.51  &  30  &   19  &  0.27 & 9.37 \\
   0.1     &  16384  &   1.45  & 101  &   21  &  0.27 & 8.86 \\
           &  65536  &   1.37  &  31  &   19  &  0.28 & 8.78 \\
           &  262144 &   1.30  &  31  &   18  &  0.27 & 7.94 \\
           & 1048576 &   1.28  &  31  &   18  &  0.27 & 7.83 \\
  \midrule  
  %        &   1024  &   1.52  &  26  &   18  &  0.25 & 8.85 \\
  %        &   4096  &   1.58  & 101  &   26  &  0.37 & 12.66 \\
    0.01   &  16384  &   1.64  & 101  &   46  &  0.50 & 18.92 \\
           &  65536  &   1.62  & 101  &   33  &  0.44 & 15.66 \\
           &  262144 &   1.55  &  32  &   26  &  0.38 & 13.04 \\
           & 1048576 &   1.48  &  31  &   26  &  0.40 & 12.92 \\
  \midrule  
  %        &   1024  &   **    & DNC  &  DNC  &  **   & **\\
  %        &   4096  &   **    & DNC  &  DNC  &  **   & **\\
    0.001  &  16384  &   **    & DNC  &  DNC  &  **   & **\\
           &  65536  &   **    & DNC  &  DNC  &  **   & ** \\
           &  262144 &   **    & DNC  &  DNC  &  **   & ** \\
           & 1048576 &   **    & DNC  &  DNC  &  **   & **\\  
  \midrule  
  %        &   1024  &   **    & DNC  &  DNC  &  **   & **\\
  %        &   4096  &   **    & DNC  &  DNC  &  **   & **\\
   0.0001  &  16384  &   **    & DNC  &  DNC  &  **   & **\\
           &  65536  &   **    & DNC  &  DNC  &  **   & ** \\
           &  262144 &   **    & DNC  &  DNC  &  **   & ** \\
           & 1048576 &   **    & DNC  &  DNC  &  **   & **\\ 
  \midrule  
  %        &   1024  &   **    & DNC  &  DNC  &  **   & **\\
  %        &   4096  &   **    & DNC  &  DNC  &  **   & **\\
    0.0    &  16384  &   **    & DNC  &  DNC  &  **   & **\\
           &  65536  &   **    & DNC  &  DNC  &  **   & ** \\
           &  262144 &   **    & DNC  &  DNC  &  **   & ** \\
           & 1048576 &   **    & DNC  &  DNC  &  **   & **\\ 
  \bottomrule
  \end{tabular}
  \caption{ Low-complexity \clair\ results for constant advection with varying $\alpha$, multilevel results.}
   \label{tab:divfree_adv_varygamma_lowcompCLAIR}
\end{table}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\subsection{Advection Results}

We now examine the advection problems for classic AIR and then for iterative
AIR. Many, many experiments were run, but we try to show only the most relevant
few.

\begin{enumerate}
   
    \item Can this approach give us AIR-like convergence for advective problems?
       Are the constraints good/bad for iterative AIR convergence?  Are the
       constraints important for complexity?

    \item Can simple block inverse approximations like diagonal and lower/upper
       triangle work?  Do constraints help with these approximations?

\end{enumerate}

%constant_advection_gamma00.txt
%constant_advection_gamma0_01.txt
%constant_advection_gamma1_00.txt

%divfree_recirc_advection_gamma0_01.txt
%divfree_recirc_advection_gamma1_00.txt

% then add low complexity section...when things are diffusy, then OK

\clearpage
\subsubsection{Constant Advection with Various Diffusion Constants $\gamma$ Values} 

\begin{center} \textbf{Begin $\gamma=1.0$ Data} \end{center}

\begin{table}[H]
  \centering
  \begin{tabular}{ccccc}
  \toprule  n   & iter & piter & op comp & work \\
\midrule
\multicolumn{4}{c}{\textit{AIR deg=2 $\theta=0.05$, $P_{one-pt}$, RS-2nd, $\tau = 1e-4$, $A_{Scaled}$  }} \\
  1024  &  14  &   11  &   2.80  & 9.84 \\
  4096  &  31  &   16  &   2.99  & 15.52 \\
 16384  & 101  &   25  &   3.09  & 24.50 \\
 65536  & 101  &   42  &   3.14  & 39.54 \\
 262144 & 101  &   76  &   3.16  & 72.96 \\
\midrule
\multicolumn{4}{c}{\textit{AIR deg=2 $\theta=0.05$, $P_{classical}$, RS-2nd, $\tau = 1e-4$, $A_{Scaled}$  }} \\
  1024  &  9   &   8   &   2.80  & 7.59 \\
  4096  &  9   &   9   &   3.04  & 8.62 \\
 16384  &  10  &   9   &   3.12  & 8.62 \\
 65536  &  10  &   10  &   3.15  & 9.78 \\
 262144 &  10  &   12  &   3.18  & 10.83 \\
\midrule
\multicolumn{4}{c}{\textit{AIR deg=2 $\theta=0.05$, $P_{classical}$, RS-1st, $\tau = 1e-4$, $A_{Scaled}$  }} \\
  1024  &  9   &   9   &   2.36  & 6.97 \\
  4096  &  9   &   11  &   2.49  & 8.32 \\
 16384  &  11  &   12  &   2.57  & 9.29 \\
 65536  &  16  &   15  &   2.61  & 11.76 \\
 262144 &  33  &   21  &   2.63  & 16.19 \\

  \bottomrule
  \end{tabular}
  \caption{ Classic AIR results for constant advection with $\gamma=1.0$, multilevel results.}
   \label{tab:constadv_gamma1_0_air}
\end{table}
%
\begin{table}[H]
 \vspace{-0.2in}
  \centering
  \begin{tabular}{ccccc}
  \toprule
  n   & iter & piter & op comp & work \\
  \midrule
\multicolumn{4}{c}{\textit{Iter AIR deg=2 $\theta=0.05$, $P_{one-pt}$, RS-2nd, , $A_{Scaled}$  $B_{Smoothed}$,  }} \\
  1024  &  11  &   10  &   3.14  & 9.90 \\
  4096  &  12  &   11  &   3.56  & 12.03 \\
 16384  &  13  &   12  &   3.83  & 13.63 \\
 65536  &  14  &   12  &   3.96  & 14.26 \\
 262144 &  14  &   13  &   4.01  & 14.67 \\
\midrule
\multicolumn{4}{c}{\textit{Iter AIR deg=2 $\theta=0.05$, $P_{classical}$, RS-2nd, , $A_{Scaled}$  $B_{Smoothed}$,  }} \\
  1024  &  11  &   9   &   3.18  & 8.80 \\
  4096  &  11  &   9   &   3.59  & 10.04 \\
 16384  &  12  &   9   &   3.84  & 10.91 \\
 65536  &  12  &   10  &   3.95  & 11.51 \\
 262144 &  13  &   11  &   4.02  & 12.51 \\
\midrule
\multicolumn{4}{c}{\textit{Iter AIR deg=2 $\theta=0.05$, $P_{classical}$, RS-1st, , $A_{Scaled}$  $B_{Smoothed}$,  }} \\
  1024  &  11  &   9   &   2.48  & 7.40 \\
  4096  &  10  &   10  &   2.68  & 8.10 \\
 16384  &  11  &   10  &   2.82  & 8.60 \\
 65536  &  14  &   11  &   2.88  & 8.95 \\
 262144 &  16  &   11  &   2.93  & 9.28 \\
  \bottomrule
  \end{tabular}
  \caption{ \clair\ results for constant advection with $\gamma=1.0$, multilevel results.}
  \label{tab:constadv_gamma1_0_iterair}
\end{table}


\clearpage 
\begin{center} \textbf{Begin $\gamma=0.01$ Data} \end{center}

\begin{table}[H]
  \centering
  \begin{tabular}{ccccc}
  \toprule
    n   & iter & piter & op comp & work \\
\midrule
\multicolumn{4}{c}{\textit{AIR deg=2 $\theta=0.05$, $P_{one-pt}$, RS-2nd, $\tau = 0$, $A_{Scaled}$  }} \\
  1024  &  7   &   7   &   2.80  & 6.54 \\
  4096  &  8   &   8   &   3.91  & 10.11 \\
 16384  &  13  &   12  &   4.48  & 16.44 \\
 65536  &  12  &   12  &   5.08  & 18.32 \\
 262144 &  22  &   19  &   4.67  & 26.13 \\
\midrule
\multicolumn{4}{c}{\textit{AIR deg=2 $\theta=0.05$, $P_{one-pt}$, RS-1st, $\tau = 1e-4$, $A_{Scaled}$  }} \\
  1024  &  9   &   9   &   2.14  & 5.53 \\
  4096  &  11  &   11  &   2.48  & 8.09 \\
 16384  &  11  &   11  &   2.35  & 8.07 \\
 65536  &  14  &   14  &   2.43  & 10.34 \\
 262144 &  17  &   17  &   2.54  & 12.66 \\
\midrule
\multicolumn{4}{c}{\textit{AIR deg=2 $\theta=0.05$, $P_{classical}$, RS-1st, $\tau = 1e-4$, $A_{Scaled}$  }} \\
  1024  &  8   &   8   &   2.23  & 5.89 \\
  4096  &  9   &   10  &   2.62  & 7.49 \\
 16384  &  14  &   12  &   2.28  & 8.52 \\
 65536  &  14  &   13  &   2.59  & 10.20 \\
 262144 &  14  &   14  &   2.49  & 10.53 \\
 \bottomrule
  \end{tabular}
  \caption{ Classic AIR results for constant advection with $\gamma=0.01$, multilevel results.}
   \label{tab:constadv_gamma0_01_air}
\end{table}
%
\begin{table}[H]
  \vspace{-0.2in}
  \centering
  \begin{tabular}{ccccc}
  \toprule
    n   & iter & piter & op comp & work \\
\midrule
\multicolumn{4}{c}{\textit{Iter AIR deg=2 $\theta=0.05$, $P_{one-pt}$, RS-2nd, , $A_{Scaled}$  $B_{Smoothed}$,  }} \\
  1024  &  16  &   10  &   2.87  & 9.23 \\
  4096  &  23  &   15  &   3.88  & 14.01 \\
 16384  &  13  &   12  &   4.58  & 16.67 \\
 65536  &  12  &   11  &   5.05  & 15.83 \\
 262144 &  12  &   13  &   5.22  & 19.96 \\
\midrule
\multicolumn{4}{c}{\textit{Iter AIR deg=2 $\theta=0.05$, $P_{one-pt}$, RS-1st, , $A_{Scaled}$  $B_{Smoothed}$,  }} \\
  1024  &  15  &   11  &   2.27  & 7.77 \\
  4096  &  12  &   11  &   2.67  & 8.75 \\
 16384  &  18  &   15  &   2.38  & 10.96 \\
 65536  &  16  &   16  &   2.60  & 12.24 \\
 262144 &  18  &   17  &   2.68  & 12.83 \\
\midrule
\multicolumn{4}{c}{\textit{Iter AIR deg=2 $\theta=0.05$, $P_{classical}$, RS-2nd, , $A_{Scaled}$  $B_{Smoothed}$,  }} \\
  1024  &  12  &   10  &   3.03  & 9.52 \\
  4096  &  13  &   10  &   4.10  & 13.28 \\
 16384  &  14  &   10  &   4.78  & 14.02 \\
 65536  &  13  &   11  &   5.16  & 16.84 \\
 262144 &  13  &   12  &   4.41  & 15.66 \\
\midrule
\multicolumn{4}{c}{\textit{Iter AIR deg=2 $\theta=0.05$, $P_{classical}$, RS-1st, , $A_{Scaled}$  $B_{Smoothed}$,  }} \\
  1024  &  13  &   10  &   2.39  & 7.46 \\
  4096  &  12  &   11  &   2.83  & 9.29 \\
 16384  &  13  &   12  &   2.71  & 9.78 \\
 65536  &  16  &   14  &   2.94  & 11.12 \\
 262144 &  18  &   16  &   2.71  & 11.44 \\
  \bottomrule
  \end{tabular}
  \caption{ \clair\ results for constant advection with $\gamma=0.01$, multilevel results.}
  \label{tab:constadv_gamma0_01_iterair}
\end{table}


\clearpage 
\begin{center} \textbf{Begin $\gamma=0.0$ Data} \end{center}

\begin{table}[H]
  \centering
  \begin{tabular}{ccccc}
  \toprule
    n   & iter & piter & op comp & work \\
\midrule
\multicolumn{4}{c}{\textit{AIR deg=2 $\theta=0.05$, $P_{one-pt}$, RS-2nd, $\tau = 1e-4$, $A_{Scaled}$  }} \\
  1024  &  7   &   7   &   3.15  & 7.04 \\
  4096  &  8   &   8   &   3.37  & 8.80 \\
 16384  &  10  &   10  &   3.65  & 10.89 \\
 65536  &  12  &   11  &   3.91  & 13.35 \\
 262144 &  14  &   13  &   4.05  & 15.06 \\
\midrule
\multicolumn{4}{c}{\textit{AIR deg=2 $\theta=0.05$, $P_{one-pt}$, RS-1st, $\tau = 1e-4$, $A_{Scaled}$  }} \\
  1024  &  8   &   7   &   1.99  & 4.56 \\
  4096  &  9   &   9   &   2.21  & 5.82 \\
 16384  &  12  &   11  &   2.48  & 7.79 \\
 65536  &  16  &   13  &   2.50  & 9.46 \\
 262144 &  24  &   17  &   2.54  & 11.95 \\
\midrule
\multicolumn{4}{c}{\textit{AIR deg=2 $\theta=0.05$, $P_{classical}$, RS-1st, $\tau = 1e-4$, $A_{Scaled}$  }} \\
  1024  &  8   &   7   &   1.99  & 4.54 \\
  4096  &  9   &   9   &   2.27  & 5.97 \\
 16384  &  12  &   11  &   2.47  & 8.02 \\
 65536  &  16  &   13  &   2.51  & 9.92 \\
 262144 &  23  &   18  &   2.55  & 12.12 \\
  \bottomrule
  \end{tabular}
  \caption{ Classic AIR results for constant advection with $\gamma=0.00$, multilevel results.}
   \label{tab:constadv_gamma0_00_air}
\end{table}
%
\begin{table}[H]
  \vspace{-0.2in}
  \centering
  \begin{tabular}{ccccc}
  \toprule
    n   & iter & piter & op comp & work \\
\multicolumn{4}{c}{\textit{Iter AIR deg=2 $\theta=0.05$, $P_{one-pt}$, RS-2nd, , $A_{Scaled}$  $B_{Smoothed}$,  }} \\
  1024  &  9   &   9   &   3.55  & 9.21 \\
  4096  &  10  &   10  &   3.74  & 11.72 \\
 16384  &  12  &   12  &   4.40  & 14.62 \\
 65536  &  14  &   13  &   5.04  & 18.65 \\
 262144 &  20  &   16  &   5.63  & 22.91 \\
\midrule
\multicolumn{4}{c}{\textit{Iter AIR deg=2 $\theta=0.05$, $P_{one-pt}$, RS-1st, , $A_{Scaled}$  $B_{Smoothed}$,  }} \\
  1024  &  9   &   9   &   2.07  & 4.64 \\
  4096  &  12  &   11  &   2.36  & 7.42 \\
 16384  &  13  &   13  &   2.57  & 9.25 \\
 65536  &  15  &   14  &   2.83  & 10.79 \\
 262144 &  18  &   17  &   2.82  & 11.68 \\
\midrule
\multicolumn{4}{c}{\textit{Iter AIR deg=2 $\theta=0.05$, $P_{classical}$, RS-2nd, , $A_{Scaled}$  $B_{Smoothed}$,  }} \\
  1024  &  9   &   8   &   3.67  & 9.45 \\
  4096  &  10  &   10  &   4.40  & 13.88 \\
 16384  &  11  &   11  &   4.79  & 15.72 \\
 65536  &  12  &   12  &   5.22  & 17.88 \\
 262144 &  15  &   14  &   6.02  & 22.10 \\
\midrule
\multicolumn{4}{c}{\textit{Iter AIR deg=2 $\theta=0.05$, $P_{classical}$, RS-1st, , $A_{Scaled}$  $B_{Smoothed}$,  }} \\
  1024  &  10  &   9   &   2.07  & 5.18 \\
  4096  &  12  &   11  &   2.43  & 7.76 \\
 16384  &  13  &   13  &   2.70  & 8.99 \\
 65536  &  15  &   14  &   2.89  & 11.54 \\
 262144 &  18  &   17  &   2.93  & 13.83 \\
  \bottomrule
  \end{tabular}
  \caption{ \clair\ results for constant advection with $\gamma=0.00$, multilevel results.}
  \label{tab:constadv_gamma0_00_iterair}
\end{table}


\clearpage
\subsubsection{Low complexity attempts}

Here, we again attempt to use low complexity approaches more similar to
rootnode and smoothed aggregation.  We use standard aggregation to choose the
CF-splitting.  It was also found to be important to set interpolation to
something stronger than one-point.  Here, interpolation is generated via the
iterative AIR algorithm.  

For the diffusive advection-diffusion problem ($\gamma = 1.0$), the low
complexity approach works very well.  When $\gamma$ is decreased, though, this
no longer works.  Ben's intuition that advective problems are generally solved
easiest with dense CF-splittings is probably right.

\begin{table}[H]
  \vspace{-0.2in}
  \centering
  \begin{tabular}{cccccc}
  \toprule
  $\gamma$ &  n   & iter & piter & op comp & work \\
  \midrule
  \multicolumn{4}{c}{\textit{Iter AIR deg=2 $\theta=0.05$, $P =$ Iter AIR deg=2 $\theta=0.05$, standard agg, , $A_{Scaled}$  $B_{Smoothed}$,  }} \\
   %       &  1024  &  61  &   17  &   1.31  & 7.55 \\ 
           &  4096  & 101  &   21  &   1.32  & 8.74 \\ 
   10.0    & 16384  & 101  &   22  &   1.30  & 8.75 \\ 
           & 65536  & 101  &   22  &   1.29  & 8.56 \\ 
           & 262144 & 101  &   23  &   1.29  & 8.66 \\ 
  \midrule  
  %        &  1024  &  38  &   17  &   1.31  & 7.35 \\ 
           &  4096  &  45  &   19  &   1.32  & 7.91 \\ 
    1.0    & 16384  &  53  &   20  &   1.30  & 8.02 \\ 
           & 65536  & 101  &   22  &   1.29  & 8.60 \\ 
           & 262144 & 101  &   23  &   1.29  & 8.62 \\ 
  \midrule  
  %        &  1024  &  30  &   16  &   1.61  & 8.51 \\ 
           &  4096  &  32  &   16  &   1.75  & 9.25 \\ 
   0.1     & 16384  &  30  &   18  &   1.75  & 9.79 \\ 
           & 65536  &  35  &   19  &   1.29  & 7.60 \\ 
           & 262144 &  45  &   21  &   1.29  & 8.11 \\ 
  \midrule  
  %        &  1024  & 101  &   33  &   1.54  & 12.86 \\ 
           &  4096  & 101  &   26  &   1.69  & 13.80 \\ 
    0.01   & 16384  & 101  &   24  &   1.74  & 10.41 \\ 
           & 65536  &  25  &   19  &   1.89  & 11.22 \\ 
           & 262144 &  38  &   23  &   1.94  & 12.03 \\ 
  \midrule  
  %        &  1024  &   & DNC  &     &  \\
           &  4096  &   & DNC  &     &  \\  
    0.001  & 16384  &   & DNC  &     &  \\  
           & 65536  &   & DNC  &     &  \\  
           & 262144 &   & DNC  &     &  \\  
  \midrule  
  %        &   1024  &   & DNC  &     &  \\
           &   4096  &   & DNC  &     &  \\
   0.0001  &  16384  &   & DNC  &     &  \\
           &  65536  &   & DNC  &     &  \\
           &  262144 &   & DNC  &     &  \\
  \midrule  
  %        &   1024  &   & DNC  &     &  \\ 
           &   4096  &   & DNC  &     &  \\ 
    0.0    &  16384  &   & DNC  &     &  \\ 
           &  65536  &   & DNC  &     &  \\ 
           &  262144 &   & DNC  &     &  \\ 
  \bottomrule
  \end{tabular}
  \caption{ \clair\ results for constant advection with varying $\alpha$, multilevel results.}
  \label{tab:constadv_varygamma_iterair_lowcomplexity}
\end{table}





\clearpage 
\begin{center} \textbf{Experiments over varying $\alpha$} \end{center}
We now run the most robust general solver configuration over a variety of $gamma$ values

\begin{table}[H]
  \centering
  \begin{tabular}{cccccc}
  \toprule
  $\gamma$ & n   & iter & piter & op comp & work \\
  \midrule
  \multicolumn{6}{c}{\textit{AIR deg=2 $\theta=0.05$, $P_{classical}$, RS-1st, $\tau = 1e-4$, $A_{Scaled}$  }} \\
 \midrule  
  %       &  1024  &  9   &   9   &   2.37  & 6.83 \\
          &  4096  &  10  &   10  &   2.51  & 7.96 \\
  10.0    & 16384  &  12  &   12  &   2.58  & 9.54 \\
          & 65536  &  16  &   16  &   2.60  & 12.23 \\
          & 262144 &  27  &   22  &   2.62  & 17.24 \\
 \midrule  
 %        &  1024  &  9   &   9   &   2.36  & 6.97 \\
          &  4096  &  9   &   11  &   2.49  & 8.32 \\
   1.0    & 16384  &  11  &   12  &   2.57  & 9.29 \\
          & 65536  &  16  &   15  &   2.61  & 11.76 \\
          & 262144 &  33  &   21  &   2.63  & 16.19 \\
 \midrule  
 %        & 1024  &  11  &   11  &   2.29  & 7.81 \\   
          &  4096  &  13  &   13  &   2.34  & 9.41 \\  
  0.1     & 16384  &  11  &   12  &   2.51  & 9.49 \\
          & 65536  &  12  &   14  &   2.57  & 11.01 \\
          & 262144 &  15  &   17  &   2.61  & 13.16 \\ 
 \midrule  
 %        & 1024  &  8   &   8   &   2.23  & 5.89 \\
          & 4096  &  9   &   10  &   2.62  & 7.49 \\
   0.01   &16384  &  14  &   12  &   2.28  & 8.52 \\
          &65536  &  14  &   13  &   2.59  & 10.20 \\
          &262144 &  14  &   14  &   2.49  & 10.53 \\
 \midrule  
 %        &  1024  &  9   &   8   &   1.79  & 4.57 \\
          &  4096  &  10  &   9   &   2.12  & 6.02 \\
   0.001  & 16384  &  12  &   11  &   2.04  & 6.94 \\
          & 65536  &  26  &   24  &   2.15  & 15.37 \\
          & 262144 &  12  &   13  &   2.58  & 9.87 \\ 
 \midrule  
 %        &   1024  &  8   &   7   &   1.73  & 4.11 \\
          &   4096  &  9   &   9   &   1.98  & 5.62 \\
  0.0001  &  16384  &  11  &   12  &   2.06  & 7.19 \\
          &  65536  &  13  &   13  &   2.19  & 8.24 \\
          &  262144 &  16  &   15  &   2.35  & 10.49 \\
 \midrule  
 %        &  1024  &  8   &   7   &   1.99  & 4.54 \\
          &  4096  &  9   &   9   &   2.27  & 5.97 \\
   0.0    & 16384  &  12  &   11  &   2.47  & 8.02 \\
          & 65536  &  16  &   13  &   2.51  & 9.92 \\
          & 262144 &  23  &   18  &   2.55  & 12.12 \\
  \bottomrule
  \end{tabular}
  \caption{ Classic AIR results for constant advection with varying $\alpha$, multilevel results.}
   \label{tab:constadv_varygamma_air}
\end{table}
%
\begin{table}[H]
  \vspace{-0.2in}
  \centering
  \begin{tabular}{cccccc}
  \toprule
  $\gamma$ &  n   & iter & piter & op comp & work \\
  \midrule
 \multicolumn{4}{c}{\textit{Iter AIR deg=2 $\theta=0.05$, $P_{classical}$, RS-1st, , $A_{Scaled}$  $B_{Smoothed}$,  }} \\
  \midrule
   %       &  1024  &  14  &   9   &   2.47  & 7.33 \\
           &  4096  &  15  &   10  &   2.71  & 7.98 \\
   10.0    & 16384  &  18  &   10  &   2.84  & 8.49 \\
           & 65536  &  18  &   11  &   2.90  & 9.17 \\
           & 262144 &  23  &   11  &   2.95  & 9.64 \\
  \midrule  
  %        &  1024  &  11  &   9   &   2.48  & 7.40 \\
           &  4096  &  10  &   10  &   2.68  & 8.10 \\
    1.0    & 16384  &  11  &   10  &   2.82  & 8.60 \\
           & 65536  &  14  &   11  &   2.88  & 8.95 \\
           & 262144 &  16  &   11  &   2.93  & 9.28 \\
  \midrule  
  %        &  1024  &  14  &   12  &   2.48  & 9.11 \\
           &  4096  &  14  &   13  &   2.52  & 10.29 \\
   0.1     & 16384  &  11  &   11  &   2.68  & 8.67 \\
           & 65536  &  12  &   12  &   2.77  & 9.84 \\
           & 262144 &  11  &   11  &   2.87  & 9.47 \\
  \midrule  
  %        &  1024  &  13  &   10  &   2.39  & 7.46 \\
           &  4096  &  12  &   11  &   2.83  & 9.29 \\
    0.01   & 16384  &  13  &   12  &   2.71  & 9.78 \\
           & 65536  &  16  &   14  &   2.94  & 11.12 \\
           & 262144 &  18  &   16  &   2.71  & 11.44 \\
  \midrule  
  %        &  1024  &  10  &   10  &   1.93  & 5.75 \\
           &  4096  &  14  &   12  &   2.32  & 8.18 \\
    0.001  & 16384  &  18  &   15  &   2.22  & 9.59 \\
           & 65536  &  24  &   23  &   2.67  & 15.98 \\
           & 262144 &  18  &   16  &   2.78  & 11.59 \\
  \midrule  
  %        & 1024  &  10  &   9   &   1.87  & 4.83 \\
           &  4096  &  12  &   11  &   2.21  & 7.08 \\
   0.0001  & 16384  &  14  &   13  &   2.27  & 8.26 \\
           & 65536  &  15  &   14  &   2.48  & 9.83 \\
           & 262144 &  17  &   15  &   2.72  & 11.12 \\
  \midrule  
  %         &  1024  &  10  &   9   &   2.07  & 5.18 \\
           &   4096  &  12  &   11  &   2.43  & 7.76 \\
    0.0    &  16384  &  13  &   13  &   2.70  & 8.99 \\
           &  65536  &  15  &   14  &   2.89  & 11.54 \\
           &  262144 &  18  &   17  &   2.93  & 13.83 \\
  \bottomrule
  \end{tabular}
  \caption{ \clair\ results for constant advection with varying $\alpha$, multilevel results.}
  \label{tab:constadv_varygamma_iterair}
\end{table}



\newpage
\subsubsection{Div-Free Recirculating Advection with Various Diffusion Constants $\gamma$ Values} 

Note for small enough $\gamma$, the problem is ill-posed. This happens at roughly $\gamma=0.00001$.

\begin{table}[H]
  \centering
  \begin{tabular}{cccccc}
  \toprule
  $\gamma$ & n   & iter & piter & op comp & work \\
  \midrule
  \multicolumn{6}{c}{\textit{AIR deg=2 $\theta=0.05$, $P_{classical}$, RS-2nd, $\tau = 1e-4$, $A_{Scaled}$  }} \\
 \midrule  
  %       & 1024  &  11  &   9   &   2.39  & 7.04 \\  
          & 4096  &  10  &   10  &   2.50  & 7.54 \\  
  10.0    &16384  &  10  &   11  &   2.57  & 8.60 \\  
          &65536  &  13  &   14  &   2.60  & 10.46 \\ 
          &262144 &  19  &   19  &   2.63  & 14.75 \\ 
 \midrule  
 %        & 1024  &  9   &   9   &   2.37  & 6.71 \\  
          & 4096  &  10  &   10  &   2.52  & 7.58 \\  
   1.0    &16384  &  11  &   11  &   2.58  & 8.96 \\  
          &65536  &  16  &   15  &   2.61  & 11.27 \\ 
          &262144 &  24  &   22  &   2.62  & 17.01 \\ 
 \midrule  
 %        & 1024  &  10  &   9   &   2.38  & 7.16 \\  
          & 4096  &  11  &   11  &   2.47  & 8.10 \\  
  0.1     &16384  &  12  &   12  &   2.55  & 9.64 \\  
          &65536  &  12  &   14  &   2.59  & 10.74 \\ 
          &262144 &  16  &   17  &   2.62  & 12.96 \\ 
 \midrule  
 %        & 1024  &  11  &   9   &   2.19  & 6.67 \\  
          & 4096  &  11  &   10  &   2.38  & 7.56 \\  
   0.01   &16384  &  11  &   11  &   2.50  & 8.47 \\
          &65536  &  12  &   13  &   2.54  & 10.05 \\
          &262144 &  14  &   15  &   2.58  & 11.47 \\
 \midrule  
 %        & 1024  &  12  &   11  &   1.84  & 6.39 \\  
          & 4096  &  14  &   12  &   2.09  & 7.90 \\  
   0.001  &16384  &  13  &   12  &   2.28  & 8.38 \\  
          &65536  &  17  &   15  &   2.41  & 10.72 \\ 
          &262144 &  16  &   15  &   2.51  & 11.11 \\ 
 \midrule  
 %        & 1024  &  23  &   12  &   1.71  & 6.40 \\  
          & 4096  & 101  &   14  &   1.93  & 8.29 \\  
  0.0001  &16384  & 101  &   17  &   2.06  & 10.77 \\ 
          &65536  & 101  &   20  &   2.13  & 11.59 \\ 
          &262144 & 101  &   34  &   2.21  & 20.68 \\ 
 \midrule  
 %        & 1023  & 101  &   13  &   1.64  & 7.31 \\  
          & 4095  & 101  &   17  &   1.80  & 9.77 \\  
   0.00001&16383  & 101  &   22  &   1.93  & 12.84 \\ 
          &65535  & 101  &   29  &   2.05  & 17.41 \\ 
          &262143 & 101  &   37  &   2.14  & 22.70 \\ 
  \bottomrule
  \end{tabular}
  \caption{ Classic AIR results for constant advection with varying $\alpha$, multilevel results.}
   \label{tab:constadv_varygamma_air}
\end{table}
%
\begin{table}[H]
  \vspace{-0.2in}
  \centering
  \begin{tabular}{cccccc}
  \toprule
  $\gamma$ &  n   & iter & piter & op comp & work \\
  \midrule
 \multicolumn{4}{c}{\textit{Iter AIR deg=2 $\theta=0.05$, $P_{classical}$, RS-1st, , $A_{Scaled}$  $B_{Smoothed}$,  }} \\
  \midrule
   %       & 1024  &  13  &   9   &   2.50  & 7.21 \\ 
           & 4096  &  15  &   10  &   2.71  & 8.00 \\ 
   10.0    &16384  &  15  &   10  &   2.84  & 8.65 \\ 
           &65536  &  16  &   11  &   2.91  & 9.20 \\ 
           &262144 &  18  &   11  &   2.96  & 9.53 \\ 
  \midrule  
  %        & 1024  &  11  &   10  &   2.48  & 7.54 \\ 
           & 4096  &  11  &   10  &   2.69  & 8.00 \\ 
    1.0    &16384  &  11  &   10  &   2.83  & 8.35 \\ 
           &65536  &  11  &   10  &   2.89  & 8.77 \\ 
           &262144 &  12  &   11  &   2.94  & 9.21 \\ 
  \midrule  
  %        & 1024  &  12  &   10  &   2.55  & 7.95 \\  
           & 4096  &  11  &   11  &   2.63  & 8.78 \\  
   0.1     &16384  &  17  &   12  &   2.78  & 10.31 \\ 
           &65536  &  12  &   13  &   2.85  & 10.88 \\ 
           &262144 &  12  &   13  &   2.90  & 10.63 \\ 
  \midrule  
  %        & 1024  &  22  &   12  &   2.43  & 8.97 \\  
           & 4096  &  13  &   12  &   2.57  & 9.46 \\  
    0.01   &16384  &  15  &   13  &   2.71  & 10.65 \\ 
           &65536  &  16  &   14  &   2.75  & 10.39 \\ 
           &262144 &  16  &   15  &   2.83  & 11.44 \\ 
  \midrule  
  %        & 1024  &  13  &   11  &   2.04  & 7.26 \\  
           & 4096  &  17  &   12  &   2.33  & 8.78 \\  
    0.001  &16384  &  14  &   13  &   2.57  & 9.35 \\  
           &65536  &  17  &   15  &   2.69  & 10.40 \\ 
           &262144 &  17  &   16  &   2.80  & 11.81 \\ 
  \midrule  
  %        & 1024  &  27  &   13  &   1.85  & 7.76 \\  
           & 4096  &  28  &   14  &   2.15  & 9.15 \\  
   0.0001  &16384  & 101  &   16  &   2.28  & 9.80 \\  
           &65536  & 101  &   16  &   2.44  & 10.64 \\ 
           &262144 & 101  &   21  &   2.54  & 13.68 \\ 
  \midrule  
  %        & 1024  & 101  &   14  &   1.86  & 8.70 \\  
           & 4096  & 101  &   22  &   2.11  & 14.41 \\ 
    0.00001&16384  & 101  &   25  &   2.21  & 16.86 \\ 
           &65536  & 101  &   32  &   2.34  & 19.11 \\ 
           &262144 & 101  &   27  &   2.45  & 17.23 \\ 
  \bottomrule
  \end{tabular}
  \caption{ \clair\ results for constant advection with varying $\alpha$, multilevel results.}
  \label{tab:constadv_varygamma_iterair}
\end{table}


\section{Discussion}

This proposed approach is almost like root-node \cite{Jacob}, but with local (approximate) block inverses used to (approximately) invert $\aff{*}$, instead of a single global Krylov polynomial used to invert $\aff{*}$. Thus, I hope that this approach be be as good/better than root-node!
\begin{enumerate}
    
    \item A recent paper \cite{DaSmSmPa2023} also used a global Krylov polynomial to invert $\aff{*}$ when constructing AIR-like $R$ and $P$.

    \item Using a Krylov polynomial instead of dense (approx) block solves would be much cheaper computationally. If the current code shows promise with the \texttt{diag} option for approximate block solves, this could be a good direction.
    
\end{enumerate}

\subsubsection*{Alternate Path}

The goal is more general AMG interpolation.  So far, we have considered a framework tying root-node and AIR together, where root-node does well on diffusion, and AIR for advection.  But, there's another direction for tying together good AMG interpolation for diffusion and good AIR for advective problems.  

The recent paper \url{https://epubs.siam.org/doi/abs/10.1137/20M134931X} computes $P$ for AMG interpolation like ext+i via matrix-matrix multiply.  If we could derive a similar matrix multiplication formula for standard interpolation, we could try and connect that formula to AIR, which can also be viewed via matrix multiplication.  The goal would be to transition or combine the approaches.  We are interested in standard interpolation, because it is robust for diffusion and like AIR, relies on a more classical RS CF splitting.  That is, both standard interpolation and AIR can use the same CF splitting.

\subsubsection*{Research Questions}

\begin{enumerate}
    
   \item Can we get fast root-node-like convergence and low complexity for
      diffusion problems when using iterative AIR?  Are the constraints
      important to convergence? Are the constraints important for complexity
      (e.g., allow for more aggressive coarsening?  Is using PMIS or standard
      aggregation important for the low complexity?
      \textit{Results so far indicate yes.}

   \item Can this approach give us AIR-like convergence for advective problems?
      \textit{Results so far indicate yes.}

      Are the constraints good/bad for iterative AIR convergence?  Are the
      constraints important for complexity?  \textit{Constraints don't seem to
      help convergence for advective problems, while they help for diffusion.}

    \item Can simple block inverse approximations like diagonal and lower/upper
       triangle work?  Do constraints help with these approximations?
    
    \item Consider adaptive coarsening that can do PMIS like coarsening in
       diffusive regions, and RS coarsening in advective regions.
    \begin{itemize}
        \item Consider CR with PMIS as the starting point.  PMIS and CR are both in PyAMG, so this would be easy.  Look at Kaczmarx and FC-Jacobi as relaxation in CR.
        \item Develop new deterministic coarsening algorithm that looks if $k\%$ of connections are strong, then do PMIS coarsening (isotropic stencil detected), else do RS coarsening.
    \end{itemize}
 

    \item Construct constraint vector(s) either with adaptive (BAMG), or
       through a local adaptive process based on locally relaxed global
       vector(s) or matrix-window modes
       \begin{itemize}
           \item Can we use locally relaxed columns of the identity for the mode constraints?  
              
           \item Could we piggy-back on evolution measure here?  That would be cool. 
       \end{itemize}



    \item Do the mode constraints make filtering the coarse operator harder?
       That is, do they uniformly lift all the nonzeros in a row of $R$?  If
       so, we may want to apply the constraints only over the ``large" entries
       of $R$.

\end{enumerate}

\bigskip
\textbf{Other discussion/research points}
\begin{enumerate}
    \item Given the important of F-relaxation to AIR, we may want to consider
       2-stage F-relaxation when doing aggressive coarsening for advective
       problems.  That is, if aggressive coarsening is applied to $A$, this
       will essentially generate two sets of F-points, $F_1$ and $F_2$, from
       each of the two passes of coarsening.  If F-relaxation were done on both
       sets of points simultaneously, the conditioning of that F-relaxation is
       probably pretty bad.  But, the conditioning of $A_{F_1, F_1}$ should be
       good (because AIR already converges quickly when using just one pass of
       coarsening).  And the conditioning of $A_{F_2, F_2}$ is \emph{probably}
       good when ignoring the $F_1 \leftrightarrow F_2$ couplings.  So, we
       could consider relaxing once or twice on $F_1$ and then relaxing once or
       twice on $F_2$.  If the initial relaxation makes the residual close to
       zero at $F_1$, this may effectively remove the $F_1 \leftrightarrow F_2$
       couplings during the relaxation on the $F_2$ points. 

    \item Does anyone have ideas on better iterative algorithms than the one outlined above? 

    \item Solve systems in block form (i.e., in BSR form, with block relaxation and block interpolation)

    \item Improved non-Galerkin could be a focus of research, where there are
       existing (Jacob) implementations of more sophisticiated non-Galerking
       strategies.  These could be useful for problems with stronger diffusion
       at least somewhere.
    
\end{enumerate}


\section{Code}

Current code is in \texttt{CF\_rootnode} branch of PyAMG.
This branch is meant to be a flexible (semi-efficient) framework for experimenting with 
different ways of iteratively computing AIR-like restriction and prolongation operators.
The new iterative AIR solver is called \texttt{energymin\_cf\_solver()} and is implemented in 
\texttt{pyamg/aggregation/energymin\_cf\_solver.py}.  The code to compute iterative AIR restriction/interpolation operators is at the bottom of  \texttt{pyamg/aggregation/smooth.py}

This branch does the following.  It is a nice sandbox.
\begin{enumerate}
    
    \item Flexibly allows for exact or iterative schemes for computing the block inverses used in AIR.
    
    \item For CF-splittings, you can use standard aggregation, Ruge-Stuben, PMIS, CLJP, and others.
    
    \item For interpolation, you can use energy-min, iterative AIR, and classical AMG formulas (e.g., direct, standard, and one-point).
    
    \item For restriction, you can use energy-minimization or iterative AIR.
    
    \item Allows for mode interpolation constraints with restriction and interpolation
    
    \item Has classical AIR implementation available for easy comparisons
    
\end{enumerate}

Verification: I compared the iterative AIR code (without constraints) and Ben's classical AIR implementation, and found that they agree to within numerical precision.

\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{table}[H]
  \centering
  \begin{tabular}{cccccc}
  \toprule
     n   & op comp & iter & piter & $\gamma$ & work \\
  \midrule
    ...
  \bottomrule
  \end{tabular}
  \caption{ Classic AIR results for **** with $\gamma=1.0$, multilevel results.}
  \label{tab:****_gamma***_air}
  %%\caption{ Classic AIR results for 2D Poisson, multilevel results.}
  %%\label{tab:2d_poisson_air}
\end{table}


\begin{table}[H]
  \centering
  \begin{tabular}{cccccc}
  \toprule
     n   & op comp & iter & piter & $\gamma$ & work \\
  \midrule
    ...
  \bottomrule
  \end{tabular}
  \caption{ \clair\ results for **** with $\gamma=1.0$, multilevel results.}
  \label{tab:****_gamma***_iterair}
  %%\caption{ \clair\ results for 2D Poisson, multilevel results.}
  %%\label{tab:2d_poisson_iterair}
\end{table}

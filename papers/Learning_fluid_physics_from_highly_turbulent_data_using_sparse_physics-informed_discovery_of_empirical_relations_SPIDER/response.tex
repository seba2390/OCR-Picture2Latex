\documentclass{article}

\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{geometry}
\usepackage{amsmath}
\usepackage{mathtools} %for \coloneqq for definitions

\newcommand{\response}{\textcolor{blue}}

\begin{document}

\section*{Response to Reviewer 1}
We would like to thank reviewer 1 for the time and effort devoted to reviewing our manuscript. Below, we have listed the criticism from reviewer 1 and our responses (in blue).\\

My main criticism stems from the central result of the paper, in which
an “augmented Navier-Stokes equation” is identified as the evolution
equation for the channel flow.  The authors state that the linear
forcing term is “reliably identified” by their algorithm and thus is
not spurious.  This result is explained as an indication of “a
numerical instability in the simulation used to generate the data”.
Are the authors calling into question the accuracy of the Johns
Hopkins DNS data?  I seriously doubt there is an undetected numerical
instability in this simulation.  In my opinion, the fact that this
term is reliably identified by the SPIDER algorithm raises questions
about the numerics of the algorithm, not the DNS.  In other words, we
know this term is spurious; the fact that the algorithm reliably
identifies it seems to be a problem with the algorithm.  For example,
even in the noiseless case, the residual given in Figure 2(a) only
reaches $10^{-4}$, which is certainly much larger than numerical errors
in the DNS.  What is the origin of this nonzero residual?  Could this
indicate an inaccuracy of the trapezoidal quadrature used in
evaluation of the weak form?  Given these issues, I am also skeptical
of the proposed application of this method as a “diagnostic tool for
validating and troubleshooting numerical simulations”.

Model discovery with sparse regression is often somewhat fragile, as
has been shown by many studies.  It is not surprising that a spurious
term might be selected.  However, since this is the only example in
this manuscript I would find the proposed method much more convincing
if it could reliably recover the correct equation. 

\medskip
\response{
The manuscript has been significantly rewritten upon learning the pressure data was misinterpreted. The JHU database stores the periodic pressure with the mean gradient removed. The linear term was being identified since it was very close on average to the constant pressure gradient ${\bf u} \sim \langle \nabla p \rangle$. Adding back the mean pressure gradient, we now reliably recover the Navier-Stokes equation. So it was not a problem with the algorithm, rather it was a problem with the interpretation of the data.}

\response{
We do find a spurious term appearing in the pressure equation for the data from the middle of the channel, however. This finding has been discussed with one of the curators of the JHU database (Charles Meneveau), and the consensus is that the presence of the spurious term is most likely a result of the insufficient grid resolution in the middle of the channel which limits the precision of the numerical solution for the pressure field. The correct momentum, energy, and pressure equations, with highly accurate coefficients, are discovered from clean data near the edge of the channel, where the grid is finer, confirming the accuracy of our approach.}

\response{
We have added a discussion of the factors that control the magnitude of the residual. For noiseless data, it represents the error of the quadrature associated with a nonuniform Chebyshev grid in $y$ (the quadratures are far more accurate for the uniform directions, $x$, $z$, and $t$ as shown by Gurevich et al. 2019 and confirmed for the present problem). For noisy data, the residual is controlled by the magnitude of the noise. Furthermore, we are now using data from the original numerical grid, rather than data obtained through interpolation onto a user-specified uniform grid, which further decreased the residuals.
}

\medskip
%  Aside from this main issue, there are several minor points I would like to see
%clarified.
One possibly related question regards the symmetry of the flow.  The
channel flow is simulated with an imposed pressure gradient, which is
often treated as anisotropic forcing in the u-momentum equation.  This
is not addressed in the manuscript; how is this handled in SPIDER?  If
I understand correctly, this would break the rotational symmetry
assumption used to select terms in (2.3).   If the imposed pressure
gradient is not explicitly treated in this scheme, could the spurious
“alpha” term be the algorithm’s approximation of the pressure gradient
forcing?  More generally, I wonder how the method would change when
the system is not isotropic (which could be the case for many of the
proposed applications in the conclusion, including fusion plasmas and
biophysical systems).  Doesn’t the symmetry assumption used here rule
out systems where an external potential is applied (e.g. gravity or a
forcing field such as in Reinbold et al (2021))?

\medskip
\response{The functional form of governing equations retains rotational and translational symmetry regardless of whether the forcing breaks the symmetry. The problem considered in Reinbold et al (2021), a pressure-driven fluid flow, and fusion plasma are three good illustrations. The imposed body forcing in the first case, the applied pressure gradient in the second case, and an imposed magnetic field in the third case break all or some of the symmetries. However, all the governing equations retain the symmetry, so long as the forcing, pressure gradient, or magnetic field, respectively, are written in the vector form. The symmetry of solutions (which is what the referee appears to have in mind) and of the governing equations are generally not directly related. The solutions tend to have a lower symmetry than the equations due to, say, boundary or initial conditions. In short, the former lacking a particular symmetry does not imply that the latter do not have that symmetry.}

\medskip
The identification of a sparse vector in the nullspace
of a matrix is known to be a challenge, as discussed for instance by
Mangan, et al (2016).  As regards the proposed approach, experience
(for example with proper orthogonal decomposition) shows that singular
vectors associated with small singular values tend to be numerically
noisy or poorly converged, particularly when the matrix is
ill-conditioned, as I assume is the case for the library matrix Q.
Can the authors comment on if and how their approach bypasses these
problems?

\medskip
\response{
%\begin{enumerate}
    %\item 
    Our rescaling procedure, which is now explicitly detailed in the manuscript, tends to significantly improve the condition number of $Q$. For the scalar library in the center of the channel, rescaling the columns lowers the condition number from $O( 10^{8})$ to $O( 10^6)$. Rescaling terms so that the coefficients have physical meaning is critical to the general success of this algorithm. This has been noted in \textit{Weak SINDy for partial differential equations} by Messenger et al.
}

\medskip
       The discussion in Sec 2.2. about “single-term
identities” is not clear:
Why does the iterative method fail?  Shouldn’t the
vector $c$ corresponding to $\nabla \cdot u$ correspond to a small
singular value of $Q$?

\medskip
\response{
While there is indeed a singular vector with a small singular value corresponding to a single-term identity, due to its small magnitude, such a term may be eliminated from the library during the iterative procedure. While the greedy iterative regression algorithm described in the paper should, in principle, be capable of identifying single-term identities, it is both more robust and computationally efficient to identify respective terms by directly evaluating their magnitudes and pruning them from all the libraries before looking for multi-term relations. We have updated the text to explain this in more detail.
%It is appropriate to treat them separately because applying the iterative SVD approach is much more computationally expensive than checking the norms of the rescaled columns.
}

\medskip
 On line 234, $u(\nabla \cdot u)$ and $\nabla(\nabla
\cdot u)$ are vector quantities and wouldn’t appear in (2.2); why is
this relevant for the scalar problem?

\medskip
\response{Thank you for pointing out this typo. The vector library should have been referenced instead.}

\medskip
   The norm of each term is compared with “the residual
$\eta$ for the identified multi-term model”, but compared in what
sense?  Is this an expert judgement, or can a rule be given?  What is
the “identified multi-term model” in this case?

\medskip
\response{This comment is no longer relevant for the revised manuscript. Single term identities are discovered independently from any multi-term relations.}

\medskip
     The approach to identifying boundary conditions in
Sec. 2.3 seems very natural and general, although a couple of points
need clarification:
\begin{itemize}
\item The authors “exclude time derivatives, because these
can be eliminated with the help of the bulk equations”.  I assume this
elimination with the bulk equations is a rationale for this exclusion
and not a procedure.  Are the authors actually manipulating the
library functions with the learned momentum equation?

\response{The referee is correct; this is a rationale rather than a procedure. We are not manipulating the library with the help of bulk equations.}

\item Can this approach handle boundary conditions that vary
in time or space?  This is fairly common; what modifications would be necessary?

\response{
The approach described in this manuscript is designed for governing equations and boundary conditions with translational symmetry in space and time, hence no explicit dependence of boundary conditions on space or time is assumed. If the boundary conditions vary in space and/or time, SPIDER can be adapted to identify them, provided such dependencies can be represented using some functional basis (e.g., Fourier modes). In this case, the coefficients $c_n$ would be replaced with linear combinations of the basis functions, see e.g., Parametric variation is a problem with a known solution, see e.g., Rudy et al. (2019) \textit{Data-Driven Identification of Parametric Partial Differential Equations}. Detection of parametric variation is fairly trivial too: applying regression to subsets of data within small spatiotemporal volumes at different positions would, in this case, yield relations of the same functional form but with different coefficients. We added a brief discussion of this.}

\item Why are the normal and tangential components
separated?  My guess would be to allow for something like free-slip
conditions to be identified, but this should be explained.

\response{All libraries correspond to irreducible representations of the corresponding symmetry group. For boundary conditions, the symmetry group is O(2) and $\mathcal{L}_\parallel$ and $\mathcal{L}_\pepr$ represent different irreducible representations of O(2), respectively, vectors and scalars. We have revised the text to make this explicit.
}
\end{itemize}
        
\medskip
The authors claim that energy and pressure Poisson
equations could also be identified if more terms were to be added to
the libraries, but no evidence is given in support.  In particular,
expanding the libraries would lead to multiple space solutions to the
optimization problem (e.g. for mass and energy in the scalar equation
(2.2)).  It is certainly conceivable that both equations could be
identified, but it is not obvious that the greedy algorithm would
actually recover both.

\medskip
\response{
We have verified that both equations mentioned by the referee are indeed discovered using our approach. The updated manuscript provides all of the necessary details.}

\medskip
The method is described as assuming smoothness of the
physical field.  Where does this requirement come from?  Doesn’t the
weak formulation allow integration over shocks or discontinuities?  If
not, could this approach be applied to systems whose solutions exhibit
this type of behavior?

\medskip
\response{
The assumption of smoothness is used to write the empirical relations in the form of PDEs. This assumption does not exclude discontinuities/shocks in the fields describing the physical problem; in their presence, derivatives can be formally evaluated by taking a one-sided limit. Discontinuous fields can indeed be easily accommodated by the weak form, provided the weight functions are chosen appropriately. This is however outside the scope of this paper.
}

\newpage

\section*{Reviewer 2:}
We would like to thank reviewer 2 for the time and effort devoted to reviewing our manuscript. Below, we have listed the criticism from reviewer 2 and our responses (in blue).\\

Because of the assumptions of invariance with respect to spatial and temporal translation, the functional relation is expressed as Volterra series which are nonlinear partial differential equations with constant coefficients.   While  the  invariance  with  respect  to  temporal  translation  is  a  corner  stone  of  classical  physics,  many  systems  may be described by non-constant coefficients in space (e.g.  eddy viscosity in RANS models or, for all purposes, many of the applications mentioned  by  the  authors  in  their  conclusion).   To  what  extent can this framework be generalized to such situations? Although I do not expect the authors to come up the solution,  I believe that extending §3 with such a discussion might be valuable for the readers.  In particular,  it might help them to place this technique in a broader context and get a better understanding of its generalizability and/or limitations.
    
\medskip
\response{
The approach described in this manuscript is designed for governing equations and boundary conditions with translational symmetry in space and time, hence no explicit dependence of boundary conditions on space or time is assumed. If the boundary conditions vary in space and/or time, SPIDER can be adapted to identify them, provided such dependencies can be represented using some functional basis (e.g., Fourier modes). In this case, the coefficients $c_n$ would be replaced with linear combinations of the basis functions, see e.g., Parametric variation is a problem with a known solution, see e.g., Rudy et al. (2019) \textit{Data-Driven Identification of Parametric Partial Differential Equations}. Detection of parametric variation is fairly trivial too: applying regression to subsets of data within small spatiotemporal volumes at different positions would, in this case, yield relations of the same functional form but with different coefficients. We added a brief discussion of this.}
    
\medskip
High-fidelity data, both in time and space, has been used.  To what extent does the accuracy in space or time influences the results?
    
\medskip
\response{High-fidelity data is not at all necessary when weak form of differential equations is used to identify the functional relations. Data could be both noisy and relatively sparse, as illustrated by our previous studies where governing equations have been identified from experimental data (Reinbold et al, 2021, Golden et al. 2023). We have added a discussion of how the residuals are affected by both noise and discretization to quantify these dependencies.}
    
\medskip
As far as I understood, full state observations are needed, thus precluding the applications to experimental data.  How would the authors proceed if given only 2D PIV (time-resolved) measurements of an otherwise three-dimensional flow for instance?
    
\medskip
\response{
As our response to the previous comment illustrates, the proposed algorithm can be successfully applied to experimental data. Both studies deal with the exact situation described by the referee. In the former case, the pressure dependence was eliminated by a suitable choice of the weight function. In both cases, the knowledge of the third component of the velocity field was not needed as the flow was confined to a thin layer. As these two studies illustrate, effective 2D models of nominally 3D fluid flows could be constructed from incomplete data for problems with high aspect ratio (such as thin fluid layers) where the lack of data is offset by additional domain knowledge (e.g., that the flow is essentially two-dimensional). However, it would be rather naive to think that a quantitatively accurate model of any physical phenomenon could be constructed when both the data and domain knowledge are lacking. Some balance between data and domain knowledge is necessary. It is perhaps worth emphasizing that a data-driven approach is meant for situations in which data are plentiful. All data-driven approaches to equation inference, not just the one described here, will break down when both the data and domain knowledge are limited.}
    
\medskip
While discussing the noise robustness of their techniques, the authors only considered a very special type of noise, namely Gaussian white noise.  In numerous situations,  noise may however be correlated in time and/or in space.  Such correlated noise is known to have a detrimental effect in least-squares regression.  Could the authors elaborate on this issue?
    
\medskip
\response{
The referee's comment applies to regression in strong form only. Weak form dramatically reduces noise sensitivity, for both correlated and uncorrelated noise. Investigation of the effect of noise correlation in weak form may be of interest, but is far outside of the scope of this paper. 
    }
    
\medskip
Equation (2.2) should be a scalar equation, yet it involves terms such as ${\bf u}^2$, ${\bf u}^2p$ and $\partial_t ({\bf u}^2)$.  How do you define the square of a vector quantity?

\medskip
\response{We define the square of a vector to be an implicit dot product, e.g., ${\bf u}^2 \equiv {\bf u} \cdot {\bf u}$. In this manuscript, the tensor product is notated as ${\bf u} {\bf u}$.
    }
    
\medskip
It is written on line 234 that ${\bf u}(\nabla \cdot {\bf u})$ and $\nabla(\nabla\cdot {\bf u})$ in (2.2) have very small magnitudes.  Yet, none of these two (vector-valued) terms actually appears in the (scalar) equation (2.2).  Is this a typo?
    
\medskip
\response{ Yes, that is a typo. The vector library should have been referenced there.
    }
    
\medskip
Although  convincing  to  me,  the  discussion  pertaining  to  the  link between the identification of the extra linear term and the instability of the numerical scheme in the bulk region is somewhat speculative.Would the authors have some references (or some kind of von Neuman analysis) to better support their claim?
    
\medskip
\response{
This is no longer a claim of the manuscript. However, we do find a spurious term appearing in the pressure equation for the data from the middle of the channel, however. This finding has been discussed with one of the curators of the JHU database (Charles Meneveau), and the consensus is that the presence of the spurious term is most likely a result of the insufficient grid resolution in the middle of the channel which limits the precision of the numerical solution for the pressure field.}
    
\medskip
As far as I understood, the greedy algorithm used to select the different  terms  is,  at  least  in  spirit,  similar  to  what  is  used  in  Implicit SINDy.  Recently, Brunton’s group came up with an alternative known as SINDy-PI which appear to be much more robust.  Would the authors mind trying it out and see if it improves even further the robustness of their approach?
    
\medskip
\response{
We see no reason why SINDy-PI would be any more robust. First, our approach successfully identifies all of the expected relations with highly accurate coefficients even in the presence of rather extreme levels of noise. It would be quite hard for SINDy-PI to improve on that. Second, while both approaches use greedy regression, our thresholding procedure is far better equipped to identify weak effects such as viscosity in the center of the channel. SINDy-PI discards terms based on the values of their coefficients instead of the magnitude of the terms. For data that has not been properly nondimensionalized, this will certainly lead to incorrect results, e.g., discarding the viscous term even in the viscous boundary layer where viscosity plays an important role.
}

\end{document}
In this paper, we investigate the problem of joint denoising / compression of detected contours in images. 
We show theoretically that in general a joint denoising / compression approach can outperform a separate two-stage approach that first denoises then encodes the denoised contours lossily.
Using a burst error model that models errors in an observed string of directional edges, we formulate a rate-constrained MAP problem to identify an optimal string for lossless encoding.
The optimization is solved optimally using a DP algorithm, sped up by using a total suffix tree (TST) representation of contexts.
Experimental results show that our proposal outperforms a separate scheme noticeably in RD performance.
Advances in depth sensing technologies like Microsoft Kinect 2.0 means that depth images---per pixel distances between physical objects in a 3D scene and the camera---can now be captured easily and inexpensively.
Depth imaging has in turn eased the extraction of object contours in a captured image, which was traditionally a challenging computer vision problem \cite{grigorescu2003contour}.
Detected contours can be used to facilitate recent advanced image coding schemes; if object contours are compressed efficiently as side information (SI), they can enable new edge-adaptive techniques such as graph Fourier transform (GFT) coding \cite{hu15,hu15spl} and motion prediction of arbitrarily shaped blocks \cite{daribo14}. 
Further, coded object contours can also be transmitted to a central cloud for computationally expensive application-specific tasks such as object detection or human action recognition \cite{weinland2011survey}, at a much lower coding cost than the original captured depth video.

Unfortunately, captured depth images are often corrupted by acquisition noise, and hence unavoidably the detected contours also contain errors. 
In this paper, we propose to jointly denoise and compress detected object contours in images.
First, we prove theoretically that in general a joint denoising / compression approach outperforms a two-stage separate approach that first denoises an observed contour then compresses the denoised version lossily.
Adopting a joint approach, we first propose a burst error model that captures unique characteristics of typical errors encountered in detected contours.
We then formulate a rate-constrained \textit{maximum a posteriori} (MAP) problem that trades off the posterior probability $P(\hat{\vec{x}} | \vec{y})$ of an estimated contour $\hat{\vec{x}}$ given observed contour $\vec{y}$ with its code rate $R(\hat{\vec{x}})$. 
Given our burst error model, we show that the negative log of the likelihood $P(\vec{y}|\vec{x})$ can be written intuitively as a simple sum of burst error events, error symbols and burst lengths. 
Further, we construct a geometric prior $P(\vec{x})$ stating intuitively that contours are more likely straight than curvy. 

We design a dynamic programming (DP) \cite{dreyfus1977art} algorithm that solves the posed problem optimally, and propose a compact context representation called \textit{total suffix tree} (TST) that can reduce the algorithm complexity dramatically.
Experimental results show that our joint denoising / compression scheme outperformed a competing separate scheme in RD performance noticeably.
We note that, to the best of our knowledge, we are the first in the literature\footnote{An early version of this work appeared as a conference paper \cite{zheng16}.} to formally address the problem of joint denoising / compression of detected image contours.

The outline of the paper is as follows. 
We first overview related works in Section\;\ref{sec:related}. 
We pose our rate-constrained MAP problem in Section \ref{sec:problem}, and define the corresponding error and rate terms in Section\;\ref{sec:error} and \ref{sec:rate}, respectively.
We describe our proposed optimal algorithm in Section\;\ref{sec:algorithm}. 
Experimental results are presented in Section\;\ref{sec:results}, and we conclude in Section\;\ref{sec:conclude}. 
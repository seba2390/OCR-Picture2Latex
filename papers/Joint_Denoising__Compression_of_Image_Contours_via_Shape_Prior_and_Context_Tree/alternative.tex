In this section, we show that it is possible to formulate an alternative \textit{rate-constrained Maximum Likelihood (ML)} problem or \textit{unconstrained Maximum a Posterior (MAP)} problem by combining the prior term and the rate term into a \textit{super rate} term denoted by $R_s(\hat{\vec{x}})$ or a \textit{super prior} denoted by $P_s(\hat{\vec{x}})$ respectively.
\red{I don' get this super rate and super prior. why do we need this definitions? this needs more explanation why these combos are reasonable.}
The corresponding formulations are as follows:
\begin{equation}
\label{eq:alternative_lagrangian_objective}
\underset{\hat{\vec{x}}\in  \mathcal{S}}{\min}\ -\log P(\vec{y}|\hat{\vec{x}})+\lambda_s R_s(\hat{\vec{x}})
\end{equation}
\begin{equation}
\label{eq:alternative_MAP}
\underset{\hat{\vec{x}}\in  \mathcal{S}}{\max}\ P(\vec{y}|\hat{\vec{x}})\cdot P_s(\hat{\vec{x}})
\end{equation}
Different from (\ref{eq:lagrangian_objective}), (\ref{eq:alternative_lagrangian_objective}) performs the rate-constrained ML estimation, \textit{i.e.}, find $\hat{\vec{x}} \in  \mathcal{S}$ that maximize likelihood $P(\vec{y}|\hat{\vec{x}})$ subject to $R_s(\hat{\vec{x}})\leq R_{\max}$.
In contrast, (\ref{eq:alternative_MAP}) performs the unconstrained MAP estimation, \textit{i.e.}, find $\hat{\vec{x}} \in  \mathcal{S}$ that maximizes the product of the likelihood $P(\vec{y}|\hat{\vec{x}})$ and the super prior $P_s(\hat{\vec{x}})$.

In (\ref{eq:objective}), both the prior term and the rate term can be regarded as a modelling of the contour signal.
Specifically, the prior models the underlying statistics of the contour by assuming that contours are more likely to be straight than curvy, which is independent of the signal observations. 
In contrast, the rate term models the symbol probabilities from the training data, which is a data-driven statistical model.
It is possible to combine the two terms into one term as in (\ref{eq:alternative_lagrangian_objective}) and (\ref{eq:alternative_MAP}), but in general they are capturing distinct distributions of the contour.
For example, if the rate constraint is loose and the signal is corrupted by heavy noise, then the reconstructed contours obtained by solving (\ref{eq:objective}) without the prior term are not likely straight.
Similarly, after removing the rate term in (\ref{eq:objective}), the reconstructed contours may not have a small entropy (rate).
\red{point being made here is not crystal clear.}

To find out the relationship between the rate-constrained MAP, rate-constrained ML and unconstrained MAP problems, we rewrite (\ref{eq:alternative_MAP}) as follows:
\begin{equation}
\underset{\hat{\vec{x}}\in  \mathcal{S}}{\min}\ -\log P(\vec{y}|\hat{\vec{x}}) - \beta_s \log P_s(\hat{\vec{x}})
\end{equation}
When the combined super rate term and super prior term are both equal to the sum of the prior term and rate term in the original formulation (\ref{eq:objective}), \textit{i.e.}, 
\begin{equation}
\lambda_s R_s(\hat{\vec{x}}) = -\beta_s \log P_s(\hat{\vec{x}}) = \lambda R(\hat{\vec{x}}) - \beta \log P(\hat{\vec{x}}),
\end{equation}
all the three formulations lead to the same solution.
This provides additional insight into the relationship between the rate-constrained MAP, rate-constrained ML and unconstrained MAP problems.
\red{Idon't get this. why do we have this discussion?}
\section{Discussion}
\label{sec:discussion}

The preceding analytical and empirical analysis shows that \system, adversarial radius analysis (\ara) in specific, effectively discriminates adversarial inputs and even reveals their correct classification outputs.

One limitation of \system is that its effectiveness, to some extent, depends on the generalization capabilities of \dnns, although practically useful \dnns need to have sufficient generalizability (\dnn generalizability and robustness are two related but distinct properties~\cite{Feng:2016:arXiv}). We thus argue that the research on improving \dnn generalizability and that on defense mechanisms against adversarial inputs complement each other. It is our ongoing research to improve the effectiveness of \system against ambiguous inputs and weak \dnn.

% Another limitation of \rva is its premise that the attackers attempt to minimize the adversarial perturbation amplitude in order to evade detection (e.g., by human perception)


We measure the distortion amplitude using $l_1$- or $l_\infty$-norm. There are other metrics for measuring input distance. For example, crafting adversarial malware samples to evade malware detection may require adopting other metrics ~\cite{Fogla:2006:ccs,Grosse:arxiv:2016}. We plan to investigate how to extend our solution to other metrics and perturbations. Yet, we believe the minimality principle still holds. For example, the malware author still wishes to preserve malware's functional behaviors.


In~\myref{sec:evaluation}, we empirically show the synergistic effects of combining defensive distillation and \system. It is expected because defense-enhanced \dnns, with stronger generalization capabilities than original models, provide better foundations for \ara to operate. Thus, we consider the integration of other defense mechanisms (e.g., data augmentation and robust optimization) and \system as a promising future direction to explore.

%
% why we don't consider a global perturbation scheme (e.g.,~\cite{Goodfellow:2014:arxiv})? It can be easily detected using thresholding: if the perturbation is too non-significant (i.e., below the threshold), it has no effect; if it is too significant, it can easily detected.


 Finally, it is worth emphasizing that \system does not create new attack vectors. It can be deployed compatibly with existing defense solutions. Its premise, the minimality principle, is an underlying principle followed by many attack models~\cite{Goodfellow:2014:arxiv,Huang:2015:arxiv,Papernot:2016:eurosp,Carlini:2016:arXiv}. Even if the adversary knows that \system is deployed, the only way to evade its detection is to amplify the adversarial distortion amplitude, which however reduces the attack's evasiveness with respect to other defense mechanisms. Therefore, \system indeed creates a difficult dilemma for the adversary.

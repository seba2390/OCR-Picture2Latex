\section{Conclusion}\label{sec:conclusion}
% In this paper we proposed a dimensionality reduction algorithm for sparse categorical data that ``preserves'' the Hamming distances. %such that the compressed data can be used to estimate Hamming distance between the uncompressed ones.
% Our method does not require learning from the dataset and instead, exploits randomization to bring forth large speedup and high quality output for standard data analytic tasks.
% %
% %remain the fastest among the existing algorithms and at the same among the best in terms of quality of estimation.
% %It was recently shown how to reduce edit distance between strings to Hamming distance by a randomized embedding that makes a single pass over the string~\citep{streaming_edit}. 
% We feel that our technique, in conjunction with a recent work that
% reduced edit distance between strings to Hamming distance~\citep{streaming_edit},
% may efficiently estimate the edit distance between strings, a problem whose
% exact computation is believed to be hard under standard assumptions~\citep{edit_dist_hardness}.
%\textcolor{blue}{
In this paper, we proposed a sketching algorithm named \fsketch for sparse categorical data such that the Hamming distances estimated from the sketches closely approximate the original pairwise Hamming distances. The low-dimensional data obtained by \texttt{FSketch} are discrete-valued, and therefore, enjoy the flexibility of running the data analytics tasks suitable for categorical data. The sketches allow tasks like clustering, similarity search to run which might not be possible on a high-dimensional dataset.% due to their high-dimensionality.

%Our algorithm uses a parameter $p$ and produces discrete sketches whose features belong to $\{0, 1, \ldots, p-1\}$. We show that a higher value of $p$ offers better performance but at the cost of more space requirements for sketches. As a special setting $p=2$ generates binary sketches that not only offer space-efficient sketching but also enable faster training and inference, due to the flexibility of using faster bitwise operations.

Our method does not require learning from the dataset and instead, exploits randomization to bring forth large speedup and high-quality output for standard data analytic tasks. We empirically validated the performance of our algorithm on several metric and end tasks such as RMSE, clustering,  similarity search, and observed comparable performance while simultaneously getting significant speed up in dimensionality reduction and end-task with respect to several baselines.
%We feel that our technique, in conjunction with a recent work that reduced edit distance between strings to Hamming distance~\cite{streaming_edit},may efficiently estimate the edit distance between strings, a problem whose exact computation is believed to be hard under standard assumptions~\cite{edit_dist_hardness}.
\bl{A common practice to analyse high-dimensional datasets is to partition} them into smaller datasets. Given the simplicity, efficiency, and effectiveness of our proposal, we hope that \fsketch will allow \bl{such analysis to be done on the full datasets and on general-purpose hardware}.
%}


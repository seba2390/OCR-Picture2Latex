\section{ Reproducibility details}\label{sec:Reproducibility_details}
\subsection{Baseline implementations }\label{sec:Reproducibility_baseline}

\begin{enumerate}
 \item  We implemented the {feature hashing (FH)}~\cite{WeinbergerDLSA09},   {SimHash (SH)}\cite{simhash}, {Sketching via Stable Distribution (SSD)}\cite{SSD} and {One Hot Encoding (OHE)}\cite{ICDM} algorithms on own own; we have made these implementations publicly available~\footnote{\url{https://github.com/Anonymus135/F-Sketch}}.
 \item For  {Kendall rank correlation coefficient}\cite{kendall1938measure} we used the implementation provided by \texttt{pandas data frame}~\footnote{\url{https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html}}. 
 \item For {Latent Semantic Analysis (LSA)}~\cite{LSI}, {Latent Dirichlet Allocation (LDA)}\cite{LDA}, {Non-negative Matrix Factorisation (NNMF)}\cite{NNMF}, and  vanilla {Principal component analysis (PCA)}, we used their implementations available in the \texttt{sklearn.decomposition} library~\footnote{\url{https://scikit-learn.org/stable/modules/classes.html\#module-sklearn.decomposition}}.
 \item For {Multiple Correspondence Analysis (MCA)}~\cite{MCA}, we used a Python library~\footnote{\url{https://pypi.org/project/mca/}}.
 \item { For HCA~\cite{Sulc2015DimensionalityRO}, we performed hierarchical clustering~\footnote{\url{https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html}} over the features in which we set the number of clusters to the value of reduced dimension. We then randomly sampled one feature from each of the clusters, and considered the data points restricted to the sampled features.
 \item For CATPCA~\cite{Sulc2015DimensionalityRO}, we
used an R package~\footnote{\url{https://rdrr.io/rforge/Gifi/man/princals.html}}.}

%  \item finally for $\chi^2$-{feature selection} \footnote{\url{https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html\#}}\cite{chi_square} and  {Mutual Information based feature selection}~\cite{MI}\footnote{\url{https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html}} we use the implementation available at  \texttt{sklearn.feature\_selection} library.
 \end{enumerate}
% \textcolor{red}{ We include $\chi^2$-{feature selection}, and   {Mutual Information  based feature selection} algorithm  only in the classification tasks for comparison as they   require labeled data for feature selection.}
It should be noted that PCA, MCA and LSA cannot reduce the dimension beyond the number of data points.



%  \subsection{ Reproducibility details of end tasks experiments }\label{sec:Reproducibility_end_taks}
\subsection{Reproducibility details for clustering task}\label{appendix:clustering}
    We first generated the ground truth clustering results on the datasets using $k$-mode~\cite{kmode} (we used a Python library~\footnote{\url{https://pypi.org/project/kmodes/}}).
    
    We then compressed the datasets using the baselines. Of them, {feature hashing}~\cite{WeinbergerDLSA09}, {SimHash}~\cite{simhash}, and {Kendall rank correlation coefficient}\cite{kendall1938measure} generate integer/discrete valued  sketches on which we can define a Hamming distance. Therefore we use the $k$-mode algorithm on compressed datasets. On the other hand, {Latent Semantic Analysis (LSA)}~\cite{LSI}, {Latent Dirichlet Allocation (LDA)}~\cite{LDA}, {Non-negative Matrix Factorisation (NNMF)}~\cite{NNMF},  {Principal component analysis (PCA)}, and {Multiple Correspondence Analysis (MCA)}~\cite{MCA} generate real-valued sketches. For these we used the $k$-means algorithm (available in the \texttt{sklearn} library~\footnote{\url{https://scikit-learn.org/stable/modules/classes.html\#module-sklearn.cluster}}) on the compressed datasets. We set \texttt{random\_state = 42} for both $k$-mode and $k$-means.
    
    We evaluated the clustering outputs using {\em purity index}. Let $m$ be the number of data points and $\Omega=\{\omega_1, \omega_2,\ldots, \omega_k\}$ be a set of 
   clusters obtained on the original data. Further, let $\mathcal{C}=\{c_1, c_2,\ldots, c_k\}$ be a set of 
   clusters obtained on reduced dimensional data. Then the \textit{purity index} of the clusters $\mathcal{C}$ is defined as
 $$
   \textit{purity index}(\Omega, \mathcal{C})=\frac{1}{m}\sum_{i=1}^k \max_{1\leq j\leq k}|\omega_i \cap  c_j|.
  $$
  
%\subsubsection{Speedup \textit{w.r.t} full dimensional data on end tasks}


\begin{figure*}
{
\centering
% \includegraphics[scale = 0.22]{images/different_p/RMSE.png}
\includegraphics[width=\linewidth]{images/RMSE_extended_new_revision1.pdf}
%\vspace{-2mm}
    \caption{Comparison of $\RMSE$ values. A lower value is an indication of better performance. The GISETTE dataset is of 5000 dimensions and hence, FSketch suffers from an increase in RMSE as the embedding dimension also reaches 5000.}
\label{appendix:fig:rmse}
}
\end{figure*}

\begin{figure*}
{
\centering
% \includegraphics[scale = 0.22]{images/different_p/RMSE.png}
    \includegraphics[width=0.75\linewidth]{images/Purity_index_extended_revision1_new.pdf}
\caption{{Comparing the quality of clusters on the compressed datasets. 
}}
\label{appendix:fig:purity}
}
\end{figure*}

%\begin{figure}
%\centering
%% \includegraphics[scale = 0.22]{images/different_p/RMSE.png}
%    \includegraphics[width=\linewidth]{images/Purity_index_extended_2.pdf}
%\caption{{Comparing the quality of clusters on the compressed datasets. 
%}}
%\label{appendix:fig:purity1}
%\end{figure}
%\textcolor{red}{@Deb .. for clustering we have two plots in Figures~\ref{appendix:fig:purity1} and \ref{appendix:fig:purity}.. referring to the same result  Basically the Y axis is scaled differently ...you may keep one and discard the other }

\begin{figure*}
{
\centering
% \includegraphics[scale = 0.22]{images/different_p/RMSE.png}
\includegraphics[width=\linewidth]{images/TopK_extended_revision1_new.pdf}
\caption{{Comparing the performance of the similarity search task (estimating top-$k$ similar points with $k=100$) achieved on the reduced dimensional data obtained from various baselines.
}}
\label{appendix:fig:similarity_search}
}
\end{figure*}

\begin{figure*}
{
\centering
% \includegraphics[scale = 0.22]{images/different_p/RMSE.png}
\includegraphics[width=\linewidth]{images/Time_extended_revision1_new.pdf}
\caption{Comparison of the dimensionality reduction times.}
\label{appendix:fig:reduction_time}
}
\end{figure*}


\section{Errors during dimensionality
reduction experiments}\label{sec:appendix_oom_error}
% \textcolor{red}{ ...error details for the baselines remains to  add ... here for some algorithms  like  NNMF and KT we are mentioning reduction time 20hrs but we have  taken 10hrs as time threshold for our experiments ... }\\
Several baselines give \textit{out-of-memory} error or their running time is quite high on some datasets. This makes it infeasible to include them in empirical comparison on $\RMSE$ and other end tasks.

We list these errors here. OHE gives \textit{out-of-memory} error for Brain cell dataset. { HCA gives DNS errors on NYTimes and BrainCell datasets. CATPCA could only on KOS and DeliciousMIL datasets that too upto only $300$ reduced dimension. Other than that it gives a DNS error.  VAE gives DNS errors on Enron datasets. }
 KT gives \textit{out-of-memory} error for NYTimes and Brain cell and on Enron it didnâ€™t stop even after $10$ hrs. MCA also gives \textit{out-of-memory} error for NYTimes and Brain cell  datasets. Further, the dimensionality reduction time for NNMF was quite high -- on NYTimes it takes around $20$ hrs to do the dimensionality reduction for $3000$ dimension, and on the Brain cell dataset, NNMF didn't stop even after $10$ hrs. These errors prevented us from performing dimensionality reduction for all dimension using some of the algorithms.

\section{Extended experimental results}\label{appendix:section:extended_exp}
This section contains the remaining comparative plots for the RMSE (Figure~\ref{appendix:fig:rmse}), clustering (Figure~\ref{appendix:fig:purity}), similarity search experiments (Figure~\ref{appendix:fig:similarity_search}) and the dimensionality reduction time (Figure~\ref{appendix:fig:reduction_time}).

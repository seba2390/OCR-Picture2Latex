\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{amsfonts,amssymb,amsmath,amsthm}
\usepackage{xcolor}
\usepackage{appendix}
\usepackage{nicefrac}
\usepackage{placeins}

\numberwithin{equation}{section}
%\setlength{\parindent}{0pt}
\setlength{\oddsidemargin}{0cm}
\setlength{\evensidemargin}{0cm}
\setlength{\textwidth}{150mm}
%\setlength{\textheight}{250 mm}
%\renewcommand{\headrulewidth}{0pt}
%\renewcommand{\footrulewidth}{.5pt}
%\setlength{\headheight}{13.6pt}
\setlength{\parskip}{.5ex}
\allowdisplaybreaks



\title{Practical asymptotic stability of data-driven model
	predictive control using extended DMD\thanks{K.~Worthmann gratefully acknowledges funding by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) -- {Project-ID 507037103}}}
\author{Lea Bold$^1$, Lars Gr√ºne$^2$, Manuel Schaller$^1$, and Karl Worthmann$^1$}
\date{%
	\normalsize
	$^1$Optimization-based Control Group, Technische Universit\"at Ilmenau, Germany\\%
	$^2$Chair of Applied Mathematics, University of Bayreuth, Germany\\[2ex]%
	July 2023
}


\newtheorem{theorem}{Theorem}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{assumption}[theorem]{Assumption}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{algorithm}[theorem]{Algorithm}

\newcommand{\R}{\mathbb{R}}
\newcommand{\nx}{n_x}
\newcommand{\nc}{n_c}
\newcommand{\N}{M}
\renewcommand{\d}{d}
\newcommand{\calK}{\mathcal K}
\newcommand{\calL}{\mathcal L}
\newcommand{\calU}{\mathcal U}
\newcommand{\bX}{\mathbb X}
\newcommand{\bU}{\mathbb U}




\begin{document}
	
	\maketitle
	
	\noindent \textbf{Abstract}: The 
	extended Dynamic Mode Decomposition (eDMD) is a very popular method to obtain data-driven surrogate models for nonlinear (control) systems governed by ordinary and stochastic differential equations.
	Its theoretical foundation is the Koopman framework, in which one propagates observable functions of the state to obtain a linear representation in an infinite-dimensional space. In this work, we prove practical asymptotic stability of a (controlled) equilibrium %set point 
	for eDMD-based model predictive control, in which the optimization step is conducted using the data-based surrogate model. To this end, we derive error bounds that converge to zero if the state approaches the desired equilibrium.
	Further, we show that, if the underlying system is cost controllable, 
	then this stabilizablility property is preserved. 
	We conduct numerical simulations, which illustrate the proven practical asymptotic stability.
	
	
	\section{Introduction}
	Model Predictive Control (MPC; \cite{GrunPann17,RawlMayn17}) is a well-established feedback control technique. 
	In each iteration, an optimal control problem is solved, and a first portion of the optimal control is applied to the system~\cite{CoroGrun20}. This process is then repeated at the successor time instant after measuring (or estimating) the resulting state of the system. The popularity of MPC is mainly due to its solid mathematical foundation and the ability to cope with nonlinear multi-input systems with state and control constraints. In the optimization step, it is, however, necessary to predict the cost functional and/or constraints along the flow of the underlying dynamical system, which requires a model. A common approach is to model the system by means of first principles. 
	
	Due to the recent progress in data-driven methods, there are several works considering MPC using data-driven surrogate models. 
	For linear discrete-time systems, a very powerful predictive-control approach~\cite{CoulLyge19} is based on Willems et al.'s so-called fundamental lemma~\cite{WillRapi05}, see~\cite{BerbKohl20} for the respective closed-loop analysis and also the recent survey paper~\cite{FaulOu23} as well as~\cite{CoulLyge21,WaarPers20} for extensions of the underlying concept towards stochastic systems, distributional robustness, and multiple data sets. 
	Several other data-based MPC-related approaches are available based on, e.g., Gaussian-processes~\cite{HewiKabz19} invoking nowadays well-established error bounds~\cite{CapoLede22}, reinforcement learning~\cite{ZanoGros20}, and many more. 
	Another popular approach is based on extended Dynamic Mode Decomposition (eDMD) \cite{WillKevr15} as an approximation technique~\cite{KlusNusk20} in the Koopman framework~\cite{BevaSosn21}. 
	The key idea is to lift a nonlinear (control) system to a linear, but infinite-dimensional one and, then, employ eDMD to generate a data-driven finite-dimensional approximation~\cite{OttoRowl21}.
	Recently, the respective data-based surrogate models were applied in the prediciton step for MPC, cf.\ \cite{PeitOtto20,KordMezi18b} and \cite{ZhanPan22} for a robust tube-based approach. 
	
	Generally speaking, the Koopman framework can be utilized for data-driven predictions of so-called observables (quantities of interest, e.g.,  
	the stage cost in MPC) along the flow of the dynamical (control) system. Convergence in the infinite-data limit was shown in~\cite{KordMezi18a} and finite-data error bounds for ordinary and stochastic differential equations with i.i.d.\ and ergodic sampling were recently proven in~\cite{SchaWort23,NuskPeit23}. 
	Therein, the approximation error is split up into two sources: A deterministic projection error quantifying the error due to a finite dictionary (i.e., finitely many observable functions defined on the state space), and a probabilistic estimation error due to the finite amount of data. To avoid or to mitigate the projection error, subspace identification methods may be employed to (approximately) ensure invariance of the dictionary, i.e., the space spanned by the choosen observables, see, e.g., \cite{HaseCort21,KrolTell22}.
	For controlled systems there are two popular approaches: The first seeks a linear surrogate control system and is widely called (e)DMDc~\cite{ProcBrun16,KordMezi18b}. The second approach yields a bi-linear representation, cf.\ \cite{Sura16,WillHema2016} and also \cite{BrudFu21} and in particular performs very well for systems with direct state-control coupling. Moreover, rigorous error bounds for this bi-linear approach are available~\cite{SchaWort23,NuskPeit23}.
	
	Due to its potential to also obtain data-driven surrogates for control systems, there are many works considering Koopman-based optimal control and stabilization. In \cite{MamaCast21}, an LQR-based approach to control unconstrained systems by means of a linear surrogate model using Taylor arguments is proposed. 
	The performance of such an LQR-approach was assessed in~\cite{MaHuan19} by means of a simulation study. 
	The authors in~\cite{IwatKawa21} add, in addition, an RL strategy, which is experimentally verified. 
	Further, simulation-based case studies can be found in~\cite{YuShen22} for Koopman-based MPC. For the bi-linear approach~\cite{KanaYama22} see also the recent survey~\cite{ManzRawa23} on Koopman and control for vehicles.
	A state feedback law leveraging control Lyapunov functions and a bi-linear Koopman ansatz was provided in \cite{SinhNand22}. 
	Very recently, robust control of the bi-linear Koopman model with guarantees was performed in~\cite{StraBerb23} or, using Lyapunov-based arguments~\cite{SonNara22,NaraSon23}. 
	The main drawback of the known work is that the closed-loop analysis is conducted in the lifted space without ensuring consistency of the training data and the data-driven surrogate model by projecting back, see~\cite{MaurGonc16} and the follow-up work~\cite{GoorMaho23}. 
	However, without such a consistency step, the optimization step within MPC is conducted based on the \emph{current} lifted state, which may not have a preimage in the original state space.
	
	The main contribution of this work is to lay a theoretical foundation for practical asymptotic stability (PAS) of eDMD-based MPC of nonlinear control-affine systems building upon the error bounds derived in~\cite{NuskPeit23} and~\cite{SchaWort23} for bi-linear eDMD-based surrogate models.
	Instead of a uniform error bound independent of the state, we rather exploit that the dynamical system has a (controlled) equilibrium at the desired set point (always taken as the origin in this paper) to show that the error scales with the deviation from the desired set point. 
	Then, after recalling a central result from~\cite{GrunPann17} on PAS for numerical approximations, the key step in this paper is to rigorously derive all required conditions for this result, based on the assumption that the underlying original system is cost controllable (i.e., asymptotically null controllable with stage costs satisfying some bound). 
	In particular, we show that cost controllability is preserved under the eDMD-based approximations, which allows to rigorously derive semi-global practical asymptotic stability of the original system if the feedback law is computed using the data-driven surrogate model only. The main argumentation of this work is generalizable to MPC with terminal ingredients.
	\\
	
	\noindent The manuscript is organized as follows. In Section~\ref{sec:eDMD}, we briefly recap eDMD within the Koopman framework.
	In Section~\ref{sec:problem}, we concisely introduce MPC and the relaxed Lyapunov inequality, before we derive a key result on the approximation error and providing the problem formulation. Then, in Section~\ref{sec:PAS}, we present our main result showing practical asymptotic stability of eDMD-based MPC. In the subsequent section, we illustrate our findings by means of a simulation study for the van-der-Pol oscillator. Finally, conclusions are drawn in Section~\ref{sec:conclusions}.
	\\
	
	\noindent\textbf{Notation}: For integers $n \leq m$, we denote $[n:m] := [n,m] \cap \mathbb{Z}$. The $i$-th standard unit vector in $\mathbb{R}^n$ is denoted by $e_i$, $i\in [1:n]$. For a matrix $A=(a_{ij})\in \R^{n\times m}$, $\|A\|_F=\sqrt{\sum_{i=1}^{n}\sum_{j=1}^m a_{ij}^2}$ denotes the Frobenius norm. For a set~$X$, we denote the interior by $\operatorname{int}(X)$. 
	%
	We further make use of the following comparison functions:
	\begin{align*}
	\calK&:= \{\alpha:\R_{\geq 0} \to \R_{\geq 0}\,|\,\alpha\text{ is continuous and strictly increasing with }\alpha(0)=0\}\\
	\calK_\infty &:= \{\alpha \in \calK\,|\, \alpha \text{ is unbounded}\}\\
	\calL &:= \{\delta : \R_{\geq 0} \to \R_{\geq 0}\,|\, \delta\text{ is continuous and strictly decreasing with}\lim_{t\to \infty}\delta(t)=0\}\\
	\calK\calL &:= \{\beta: \R_{\geq 0}\times \R_{\geq 0} \to \R_{\geq 0}\,|\, \beta\text{ is continuous, }\beta(\cdot,t)\in \calK,\ \beta(r,\cdot)\in \calL\}.
	\end{align*}
	
	
	
	
	
	
	\section{Koopman-based prediction and control}
	\label{sec:eDMD}
	
	In this section, we recap the basics of surrogate modeling of nonlinear (control) systems within the Koopman framework. The underlying idea is to exploit an identity between the nonlinear flow of an ordinary differential equation and a linear, but infinite-dimensional operator. Then, a compression of this %linear 
	operator onto a finite-dimensional subspace can be approximated by extended Dynamic Mode Decomposition (eDMD) using finitely many samples of the system.
	
	
	
	\subsection{The Koopman framework} 
	
	First, we consider an autonomous continuous-time dynamical system governed by the \emph{nonlinear} ordinary differential equation (ODE)
	\begin{align}\label{eq:ode}
	\dot{x}(t) = g_0(x(t)),
	\end{align}
	where the map $g_0: \mathbb{R}^{\nx} \rightarrow \mathbb{R}^{\nx}$ is locally Lipschitz continuous. 
	For given initial condition $x(0) = \hat{x} \in \R^{\nx}$, we denote the unique solution of System~\eqref{eq:ode} at time $t \in [0,\infty)$ by $x(t;\hat{x})$. 
	We consider the ODE~\eqref{eq:ode} on a compact and non-empty set $\bX \subset \mathbb{R}^{\nx}$. Then, to avoid technical difficulties in this introductory section, forward invariance of the set~$\bX$ w.r.t.\ the dynamics~\eqref{eq:ode} is assumed, i.e., $x(t;\hat{x}) \in \mathbb{X}$, $t \geq 0$, holds for all $\hat{x} \in \mathbb{X}$. This may be ensured, e.g., by some inward-pointing condition and guarantees existence of the solution on~$[0,\infty)$. Otherwise, additional care has to be paid to technical details, see, e.g., \cite{ZhanZuaz23} or~\cite{SchaWort23} for an extension for control systems. Then, the Koopman semigroup $(\mathcal{K}^t)_{t \geq 0}$ of bounded linear operators is defined by the identity 
	\begin{equation}\label{eq:Koopman}
	(\mathcal{K}^t \varphi)(\hat{x}) = \varphi(x(t;\hat{x})) \qquad\forall\,t \geq 0, \hat{x} \in \bX, \varphi \in L^2(\bX,\mathbb{R}),
	\end{equation}
	see, e.g., \cite[Prop.~2.4]{MaurSusu20}. Here, the real-valued functions~$\varphi$ are called \emph{observables}. 
	The identity~\eqref{eq:Koopman} states that, instead of evaluating the observable~$\varphi$ at the solution of the \emph{nonlinear} differential equation~\eqref{eq:ode} emanating from initial state~$\hat{x}$ at time~$t$, one may also apply the \emph{infinite-dimensional} Koopman operator~$\mathcal{K}^t$ to the observable~$\varphi$ and, then, evaluate the propagated observable at~$\hat{x}$.
	
	Since the flow of system~\eqref{eq:ode} is continuous, $(\calK^t)_{t \geq 0}$ is a strongly-continuous semigroup of bounded linear operators. 
	Correspondingly, we can define the, in general, unbounded infinitesimal generator~$\mathcal{L}$ of this semigroup by
	\begin{align}\label{eq:generator}
	\calL \varphi := \lim_{t \searrow 0}\frac{\calK^t \varphi - \varphi}{t} \qquad \forall\, \varphi \in D(\calL),
	\end{align}
	where the domain $D(\calL)$ consists of all $L^2$-functions, for which the above limit exists. 
	Using this generator, we may formulate an evolution equation, which describes the action of the Koopman operator \eqref{eq:Koopman}: The propagated observable $\Phi(t)= \calK^t\varphi = \varphi(x(t;\cdot))$ solves the abstract Cauchy problem
	\begin{align}\label{eq:Cauchy_problem}
	\dot \Phi(t) = \calL \Phi(t), \qquad \Phi(0)=\varphi,
	\end{align}
	see, e.g., \cite{CurtZwar12} for details on abstract evolution equations.\\
	
	\noindent Next, we recap the extension of the Koopman theory to control-affine systems, i.e., systems governed by the dynamics
	\begin{equation}\label{eq:dynamics_control_affine}
	\dot{x}(t) = g_0(x(t)) + \sum_{i=1}^{\nc} g_i(x(t)) u_i(t),
	\end{equation}
	where the control function $u \in L^\infty_{\operatorname{loc}}([0,\infty),\R^{\nc})$ serves as an input and the input maps $g_i:\R^{\nx} \to \R^{\nx}$, $i \in [0:\nc]$, are locally Lipschitz continuous.
	A popular approach to obtain a data-based surrogate model is DMDc~\cite{ProcBrun16} or eDMDc~\cite{KordMezi18b}, where one seeks a linear control system. In this paper, we pursue an alternative \emph{bi-linear} approach, which exploits the control-affine structure of the system~\eqref{eq:dynamics_control_affine} and was --~to the best of our knowledge~-- first proposed by~\cite{WillHema2016,Sura16}, see also~\cite{PeitOtto20} for further details. 
	This approach shows a superior performance for systems with state-control coupling~\cite{BrudFu21,FolkBurd21,BoldEsch23}. Moreover, a rigorous analysis of the approximation error depending on the amount of employed data is available, see~\cite{NuskPeit23} and~\cite{SchaWort23} for a detailed exposition w.r.t.\ the estimation and the projection error, respectively. We recap the required details in Subsection~\ref{subsec:eDMD}.
	
	For the flow of the control system \eqref{eq:dynamics_control_affine} with constant control input $u$, the Koopman operator $\calK^t_u$ is defined analogously to~\eqref{eq:Koopman}.
	A straightforward computation shows that its generator preserves control affinity, i.e.,
	\begin{align}\label{eq:generator_control}
	\calL^{u} = \calL^0 + \sum_{i=1}^{\nc} u_i(\calL^{e_i}-\calL^0)
	\end{align}
	holds for $u \in \mathbb{R}^{\nc}$,
	where $\calL^0$ and $\calL^{e_i}$, $i\in [1:\nc]$, are the generators of the Koopman semigroups corresponding to the constant control function $u \equiv 0$ and $u \equiv e_i$, $i \in [1:\nc]$, respectively.
	For general control functions~$u \in L^\infty_{\operatorname{loc}}([0,\infty),\R^{\nc})$, one can now state the respective abstract Cauchy problem analogously to~\eqref{eq:Cauchy_problem} replacing the generator~$\mathcal{L}$ by its time-varying counterpart~$\mathcal{L}^{u(t)}$ defined by~\eqref{eq:generator_control}, see~\cite{NuskPeit23} for details.
	
	
	
	\subsection{Data-driven approximations via eDMD}
	\label{subsec:eDMD}
	
	The success of the Koopman approach in recent years is due to its linear nature such that the compression of the Koopman operator or its generator~\eqref{eq:generator_control} to a finite-dimensional subspace -- called dictionary -- leads to matrix representations. 
	Being finite-dimensional objects, these matrices can then be approximated by a finite amount of data.
	
	Let the dictionary $\mathbb{V} := \operatorname{span}(\{ \psi_k: k \in [1:\N]\} )$ be the $\N$-dimensional subspace spanned by the chosen observables~$\psi_k$, $k \in [1:\N]$. We denote the $L^2$-orthogonal projection onto $\mathbb{V}$ by $P_\mathbb{V}$. Further, using $\d$ i.i.d.\ data points $x_1,\ldots,x_{\d}\in \bX \subset \R^{\nx}$, we define the $(\N \times \d)$-matrices
	\begin{align*}
	X := \left( \left.   \left(\begin{smallmatrix}
	\psi_1(x_1)\\
	:\\
	\psi_{\N}(x_1)
	\end{smallmatrix}\right)\right| \ldots \left| \left(\begin{smallmatrix}
	\psi_1(x_{\d})\\
	:\\
	\psi_{\N}(x_{\d})
	\end{smallmatrix}\right)\right. \right)\quad\text{ and }\quad
	Y := \left( \left. \left(\begin{smallmatrix}
	(\mathcal{L}^0\psi_1)(x_1)\\
	:\\
	(\mathcal{L}^0\psi_{\N})(x_1)
	\end{smallmatrix}\right)\right| \ldots \left| \left(\begin{smallmatrix}
	(\mathcal{L}^0\psi_1)(x_{\d})\\
	:\\
	(\mathcal{L}^0\psi_{\N})(x_{\d})
	\end{smallmatrix}\right)\right. \right),
	\end{align*}
	where $(\mathcal{L}^0 \psi_k)(x_j) = \nabla \psi_k(x_j)^\top g_0(x_j)$ holds for $k \in [1:\N]$ and $j \in [1:\d]$. 
	Then, the empirical estimator of the compressed Koopman generator $P_\mathbb{V}\calL^0\vert_\mathbb{V}$ is given by
	\begin{align*}
	{\calL}^0_\d := \operatorname{arg}\min_{{L} \in \R^{\N\times \N}} \|{L}X-Y\|_F^2,
	\end{align*}
	i.e., as the solution of a regression problem. 
	We have to repeat this step for $\mathcal{L}^{e_i}$, $i \in [1:\nc]$, based on the identity $(\mathcal{L}^{e_i} \psi_k)(x_j) = \nabla \psi_k(x_j)^\top \left(g_0(x_j) + g_i(x_j)\right)$ to construct the data-driven approximation of~$\mathcal{L}^{u}$ according to~\eqref{eq:generator_control}. 
	Consequently, for $\varphi \in \mathbb{V}$ and control function $u \in L^\infty_{\operatorname{loc}}([0,t],\R^{\nc})$, a data-driven predictor is given as the solution of the linear time-varying Cauchy problem~\eqref{eq:Cauchy_problem}, where the unbounded operator~$\mathcal{L}$ is replaced by $\calL_d^{u(t)}$. 
	The convergence of this estimator was shown in~\cite{KordMezi18a} if both the dictionary size and the number of data points goes to infinity. 
	Finite-data bounds typically split the error into two sources: A projection error stemming from the finite dictionary and an estimation error resulting from a finite amount of data. 
	For an analysis of these errors for autonomous systems and i.i.d.\ data, we refer the reader to~\cite{ZhanZuaz23}. An estimation error for control systems was derived in~\cite{NuskPeit23}, where, in addition to i.i.d.\ sampling of ODEs, also SDEs and ergodic sampling, i.e.\ sampling along one sufficiently-long trajectory, were considered. 
	A full approximation error bound for control systems was provided in~\cite{SchaWort23} using a dictionary of finite elements. For error bounds in reproducing kernel Hilbert spaces we refer the reader to~\cite{PhilScha23}. We provide an error bound tailored to the sampled-data setting used in this work in Proposition~\ref{prop:errbound} of Subsection~\ref{subsec:sampled}.
	
	
	
	
	
	\section{MPC, sampled-data systems, and problem formulation}
	\label{sec:problem}
	
	\noindent We consider a discrete-time dynamical control system governed by the dynamics
	\begin{equation}\label{eq:dynamics_DT}
	x^+ = f(x,u)    
	\end{equation}
	with (nonlinear) map $f: \mathbb{R}^{\nx} \times \mathbb{R}^{\nc} \rightarrow \mathbb{R}^{\nx}$.
	Then, for given (initial) state $\hat{x} \in \mathbb{R}^{\nx}$ and sequence of control values $(u(k))_{k \in \mathbb{N}_0}$, $x_u(n;\hat{x})$ denotes the solution at time instant~$n \in \mathbb{N}_0$, which is recursively defined by the dynamics~\eqref{eq:dynamics_DT} and the initial condition $x_u(0;\hat{x}) = \hat{x}$. 
	In the following, we assume that $f(0,0) = 0$ holds, i.e., that the origin is a controlled equilibrium for the control value~$u = 0$. 
	After reviewing the basics of model predictive control in the subsequent subsection, we derive a sampled-data representation of the continuous-time dynamics~\eqref{eq:dynamics_control_affine} and the corresponding abstract Cauchy problem, i.e., \eqref{eq:Cauchy_problem} with $\calL^{u(t)}$ including its eDMD-based surrogate in Subsection~\ref{subsec:sampled}. 
	Finally, we provide the problem formulation in Subsection~\ref{subsec:problem}.
	
	
	
	\subsection{Stability and suboptimality of model predictive control}\label{sec:mpc}
	
	We impose state and control constraints using the compact sets $\bX \subset \mathbb{R}^{\nx}$ and $\bU \subset \mathbb{R}^{\nc}$ with~$(0,0) \in \operatorname{int}(\bX \times \bU)$, respectively. %Constraints: $\mathbb{X} \subseteq X$, $\mathbb{U} \subseteq U$
	Then, admissibility of a sequence of control values is defined as follows.
	\begin{definition}\label{def:admissibility}
		A sequence of control values $(u(k))_{k=0}^{N-1} \subset \bU$ of length~$N$ is said to be admissible for state $\hat{x} \in \bX$, if $x_u(k;\hat{x}) \in \bX$ holds for all $k \in [1:N]$. 
		For $\hat{x} \in \bX$, the set of admissible control sequences is denoted by~$\calU_N(\hat{x})$. If, for $u = (u(k))_{k \in \mathbb{N}_0}$, $(u(k))_{k=0}^{N-1} \in \calU_N(\hat{x})$ holds for the restriction of~$u$ for all $N \in \mathbb{N}_0$, we write $u \in \calU_\infty(\hat{x})$.
	\end{definition}
	
	\noindent We introduce the quadratic %\marginpar{\LG{Eine Begr√ºndung, warum wir uns auf diese Kostenart einschr√§nken, w√§re gut}} 
	(and continuous) stage cost $\ell: \bX \times \bU \rightarrow \mathbb{R}_{\geq 0}$ given by
	\begin{equation}\label{eq:stage_cost}
	\ell(x,u) := \| x \|_Q^2 + \| u \|_R^2 := x^\top Q x + u^\top R u
	\end{equation}
	for symmetric and positive definite matrices $Q \in \mathbb{R}^{\nx \times \nx}$ and $R \in \mathbb{R}^{\nc \times \nc}$. Here, we choose quadratic costs in order to streamline the presentation. Otherwise, some adaptations of the proposed error bound, see Proposition~\ref{prop:errbound} below, are required to ensure consistency between stage cost and error bound, which is required to deduce our main result presented in Theorem~\ref{thm:main}.
	Then, based on Definition~\ref{def:admissibility}, we introduce the MPC Algorithm, %~\ref{alg:MPC}, 
	where we tacitly assume existence of an optimal sequence of control values in Step~(2) along the MPC closed-loop dynamics and full-state measurement.
	\begin{algorithm}[Model Predictive Control]\label{alg:MPC}
		At each time instant~$n \in \mathbb{N}_0$: %sampling time~$t_n = n \Delta t$, $n \in \mathbb{N}_0$
		\begin{enumerate}
			\item [(1)] Measure the state $x(n) \in X$ and set $\hat{x} := x(n)$. %of the system
			\item [(2)] Solve the optimization problem
			\begin{equation}\nonumber
			u^\star \in \operatorname{argmin}_{u \in \calU_N(\hat{x})}\ \ J_N(\hat{x},u) := \sum_{k=0}^{N - 1} \ell(x_u(k;\hat{x}),u(k)) %\qquad\text{w.r.t.}\quad u \in \calU_N(\hat{x})
			\end{equation}
			subject to $x_u(0;\hat{x}) = \hat{x}$ and $x_u(k+1;\hat{x}) = f(x_u(k;\hat{x}),u(k))$, $k \in [0:N-2]$.% to compute the optimal sequence of control values~$u^\star$
			\item [(3)] Apply the feedback value $\mu_N(x(n)) := u^\star(0) \in \bU$ at the plant.
		\end{enumerate}
	\end{algorithm}
	\noindent Overall, Algorithm~\ref{alg:MPC} yields the MPC closed-loop dynamics
	\begin{equation}\label{eq:dynamics_closed_loop}
	x^+_{\mu_N} = f(x_{\mu_N}, \mu_N(x_{\mu_N})),
	\end{equation}
	where the feedback law~$\mu_N$ is well defined at~$\hat{x}$ if $\calU_N(\hat{x}) \neq \emptyset$ holds. 
	We emphasize that this condition holds if, e.g., $\bX$ is controlled forward invariant and refer to~\cite{BoccGrun14} and~\cite{EsteWort20} for sufficient condition to ensure recursive feasibility without requiring controlled forward invariance of $\bX$ (and without terminal conditions) for discrete and continuous-time systems, respectively. 
	The closed-loop solution resulting from the dynamics~\eqref{eq:dynamics_closed_loop} is denoted by $x_{\mu_N}(n;\hat{x})$, where $x_{\mu_N}(0;\hat{x}) = \hat{x}$ holds. 
	Moreover, we define the (optimal) value function~$V_N: \bX \rightarrow \mathbb{R}_{\geq 0} \cup \{ \infty \}$ as $V_N(x) := \inf_{u \in \calU_N(x)} J_N(x,u)$.
	
	Next, we recall \cite[Theorem~4.11]{GrunPann17} regarding \emph{asymptotic stability and suboptimality estimates} of the MPC closed-loop, see also~\cite{GrunRant08}.
	\begin{proposition}\label{thm:stability_suboptimality}
		Suppose that, for $N \in \mathbb{N}$, 
		a set $S \subseteq \mathbb{X}$ is forward-invariant w.r.t.\ the closed-loop dynamics~\eqref{eq:dynamics_closed_loop} and there exists $\alpha \in (0,1]$ such that the \emph{relaxed Lyapunov inequality}
		\begin{equation}\label{eq:inequality_DP_relaxed_DP}
		V_N(x) \geq \alpha \ell(x,\mu_N(x)) + V_N(f(x,\mu_N(x))) \qquad\forall\,x \in S
		\end{equation}
		holds. Then, the suboptimality estimate $J_\infty^{\operatorname{cl}}(\hat{x}) := \sum_{n=0}^\infty \ell(x_{\mu_N}(n;\hat{x}), \mu_N(x_{\mu_N}(n;\hat{x}))) \leq V_N(\hat{x}) / \alpha$ holds for all $\hat{x} \in S$. If, in addition, $\exists\,\alpha_1, \alpha_2, \alpha_3 \in \mathcal{K}_\infty$ such that
		\begin{equation}\nonumber
		\alpha_1( \| x \| ) \leq V_N(x) \leq \alpha_2( \| x \|) \qquad\text{ and }\qquad \inf_{u \in \bU} \ell(x,u) \geq \alpha_3( \| x \|)
		\end{equation}
		hold for all $x \in S$, then the origin is asymptotically stable w.r.t.\ the closed-loop dynamics~\eqref{eq:dynamics_closed_loop} on~$S$ in the sense of \cite[Definition~2.16]{GrunPann17}, i.e., there exists $\beta \in \mathcal{KL}$ satisfying the inequality $\| x_{\mu_N}(n;\hat{x}) \| \leq \beta(\| \hat{x} \|,n)$, for all $\hat{x} \in S$ and all $n \in \mathbb{N}_0$.
	\end{proposition}
	\noindent Before we conclude this section, we briefly note that the argumentation is not limited to finite-dimensional spaces.
	
	
	
	\subsection{Sampled-data systems with zero-order hold and eDMD}\label{subsec:sampled}
	
	We consider the nonlinear continuous-time control system governed by the dynamics~\eqref{eq:dynamics_control_affine}. Equidistantly discretizing the time axis~$[0,\infty)$, i.e., using the partition $\bigcup_{k=0}^\infty [k \Delta t, (k+1) \Delta t)$ with sampling period~$\Delta t > 0$, and using a (piecewise) constant control function on each sampling interval, i.e., $u(t) \equiv \hat{u} \in \bU \subset \mathbb{R}^{\nc}$ on~$[k \Delta t, (k+1) \Delta)$, we can generate a discrete-time system governed by the dynamics
	\begin{equation}\label{eq:dynamics_sampled_data}
	%x(k+1) = \tilde{x}(k \Delta t + \Delta t) 
	x^+ = f(\hat{x},\hat{u}) := \int_0^{\Delta t} g_0(x(t;\hat{x},u)) + \sum_{i=1}^{\nc} g_i(x(t;\hat{x},u)) u_i(t)\,\mathrm{d}t.
	\end{equation}
	We emphasize that the drift~$g_0$ does not exhibit an offset independently of the state variable~$x$ in view of our assumption $f(0,0) = 0 = g_0(0)$.
	We define the vector-valued observable
	\begin{align}\label{eq:dictionary}
	\begin{split}
	\Psi(x) &= \begin{pmatrix}
	\psi_1(x),\ldots,\psi_\N(x)
	\end{pmatrix} \\&= \begin{pmatrix}
	1, x_1,\ldots,x_{\nx},\psi_{\nx+2}(x),\ldots,\psi_\N(x)
	\end{pmatrix},
	\end{split}
	\end{align}
	where $\psi_1(x)\equiv 1$, $\psi_{k+1}(x) = x_k$, $k \in [1:\nx]$ and $\psi_k \in \mathcal{C}^1(\mathbb{R}^{\nx},\mathbb{R})$, $k \in [\nx + 2:\N]$, are locally-Lipschitz continuous functions satisfying $\psi_k(0) = 0$ and $(D \psi_k)(0) = 0$. 
	Hence, $\Psi:\bX \to \mathbb{R}^\N$ is Lipschitz continuous with Lipschitz constant~$L_\Psi$ such that $\| \Psi(x) - \Psi(0) \| \leq L_\Psi \| x \|$. A straightforward calculation then shows $(P_{\mathbb{V}} \mathcal{L}^0|_{\mathbb{V}})_{k,1} \equiv 0$, $k \in [1:\N]$, %and $(\mathcal{L}^0\Psi)(0)=0$
	which we %simply 
	impose for the data-driven approximation to ensure consistency, i.e., that $f(0,0) = g_0(0) = 0$ is preserved. For $g_i$, $i \in [1:n_c]$, the first (constant) observable enable us to approximate components of the control maps, which do not depend on the state~$x$, \textit{separately}.  Moreover, $\Psi(\mathbb{R}^{\nx}) := \{ y \in \mathbb{V}: \exists\,x \in \mathbb{R}^{\nx}: \Psi(x) = y\}$ is an $\nx$-dimensional submanifold of the dictionary~$\mathbb{V}$ defined in Section~\ref{subsec:eDMD}. 
	We emphasize that, for all measurable control functions $u :[0,\Delta t)\to \bU$, the Koopman operator~$\mathcal{K}^{\Delta t}_u$ respects the manifold structure since $(\mathcal{K}^{\Delta t}_u \Psi)(\hat{x}) := ((\mathcal{K}^{\Delta t}_u\psi_1)(\hat x)^\top,\ldots,(\mathcal{K}^{\Delta t}_u\psi_\N)(\hat x)^\top)^\top =  \Psi(x(\Delta t;\hat{x},u)) \in \Psi(\mathbb{R}^{\nx})$ holds for all $\hat{x}$.
	Here, $\mathcal{K}^{\Delta t}_u\psi_k$, $k \in [1:\N]$, denotes the solution of the respective time-varying abstract Cauchy problem.
	
	\begin{remark}[Metric spaces]
		We point out that all results presented in Section \ref{sec:mpc} can be generalized to arbitrary metric spaces~$X$ and~$U$ instead of $\mathbb{R}^{\nx}$ and $\mathbb{R}^{\nc}$, respectively. In particular, the latter would allow us to define $U$ as the space of control functions on some interval, e.g., $u\in U= L^\infty([0,\Delta t),\mathbb{R}^{\nc})$ instead of control values $u \in \mathbb{R}^{\nc}$, see \cite{Wort11} and \cite[Chapter~2 and~3]{GrunPann17} for details.
	\end{remark}
	
	\noindent In this paper, we make use of the following Assumption~\ref{ass:invariance}, which ensures that no projection error occurs. This assumption is common in systems and control when the Koopman framework is used, see, e.g., \cite{ProcBrun18,KordMezi18b}. The construction of suitable dictionaries ensuring this assumption is discussed in \cite{BrunBrun16,KordMezi20,ShiKary21} and also in the recent preprint~\cite{GadgKris22} for control-affine systems based on differential-geometric arguments. A condition ensuring this invariance is provided, e.g., in~\cite[Theorem~1]{GoswPale21}, where even a method for the construction of a suitable dictionary is discussed in detail, see also \cite[Section~III and~IV]{GoswPale21}.
	\begin{assumption}[Invariance of~$\mathbb{V}$ from Section~\ref{subsec:eDMD}]    \label{ass:invariance}
		For any $\varphi \in \mathbb{V}$, the relation $\varphi(x(\Delta t;\cdot,u)) \in \mathbb{V}$ holds for all $u(t) \equiv \hat{u} \in \bU \subset \R^{\nc}$.
	\end{assumption}
	\noindent Next, we provide a bound on the estimation error adapted to our sampled-data setting. Assumption~\ref{ass:invariance} implies that the compression of the generator coincides with its restriction onto $\mathbb{V}$, i.e., $P_\mathbb{V} \mathcal{L}^u\vert_\mathbb{V} = \mathcal{L}^u\vert_\mathbb{V}$. Thus, for $u\in \bU$, the Koopman operator is the matrix exponential of the generator, that is, $\calK^{\Delta t}_u = e^{\Delta t \mathcal{L}^u}$.
	\begin{proposition}\label{prop:generatorbound}
		Let Assumption~\ref{ass:invariance} hold.
		Let an error bound $\varepsilon>0$ and a probabilistic tolerance $\delta \in (0,1)$ be given. Then there is an amount of data $\d_0\in \mathbb{N}$ such that the error bound
		\begin{align}\label{eq:operatorbound}
		\big\|e^{\Delta t \mathcal{L}^u \vert_{\mathbb{V}}} - e^{\Delta t \calL_\d^u}\big\| \leq \varepsilon
		\end{align}
		holds for all $\d \geq \d_0$ and all $u\in \bU$ for the Koopman operator $\calK^{\Delta t}_u = e^{\Delta t \mathcal{L}^u}$ with probability $1-\delta$.
	\end{proposition}
	\begin{proof}
		By definition of the matrix exponential, we compute
		\begin{align*}
		\| e^{\Delta t \mathcal{L}^u \vert_{\mathbb{V}}} - e^{\Delta t \mathcal{L}^u_d} \| = \left\| \sum_{k=1}^\infty \frac{\Delta t^k}{k!}(\mathcal{L}^u\vert_\mathbb{V} -\mathcal{L}^u_\d)^k \right\| \leq  \sum_{k=1}^\infty \frac{\Delta t^k}{k!}\|\mathcal{L}^u\vert_\mathbb{V} -\mathcal{L}^u_\d \|^k \leq e^{\Delta t \|\mathcal{L}^u\vert_\mathbb{V} -\mathcal{L}^u_\d \|} - 1.
		\end{align*}
		Invoking \cite[Theorem 3]{SchaWort23} yields a sufficient amount of data $d_0\in \mathbb{N}$ such that $\|\mathcal{L}^u\vert_\mathbb{V} -\mathcal{L}^u_\d \| \leq \ln (1+\varepsilon)/\Delta t$ holds for $d\geq d_0$ with probability $1-\delta$. Plugging this into the above computations implies \eqref{eq:operatorbound} with probability $1-\delta$.
	\end{proof}
	\begin{remark}
		We briefly quantify the sufficient amount of data $d_0$ of Proposition~\ref{prop:generatorbound} in view of the dictionary size $\N$, the error bound $\varepsilon$ and the probabilistic tolerance $\delta$. 
		First, by a standard Chebychev inequality, one obtains a dependency $d_0 \sim \nicefrac{\N^2}{\varepsilon^2\delta}$, cf.\ \cite{SchaWort23,NuskPeit23}. 
		This can be improved in a reproducing kernel Hilbert space setting, where the dictionary is given by feature maps given by the kernel evaluated at the samples. Here a scaling depending logarithmically on $\delta$ was shown in \cite[Proposition 3.4]{PhilScha23} using Hoeffding's inequality.
	\end{remark}
	
	\noindent For the discrete-time dynamics~\eqref{eq:dynamics_sampled_data}, we get the identity
	\begin{align}\label{eq:dynamics_exact}
	f(\hat{x},\hat{u}) = P_{x} e^{\Delta t \mathcal{L}^{\hat{u}}} \Psi(\hat{x})
	\end{align}
	resulting from sampling with zero-order hold based on Assumption~\ref{ass:invariance}, where $P_x:\mathbb{R}^\N \to \mathbb{R}^{\nx}$ is the projection onto the first $\nx$~components.
	Further, based on the bi-linear eDMD-based surrogate model of Subsection~\ref{subsec:eDMD} for $\d$~data points and the respective error bound~\eqref{eq:operatorbound} linking the error $\varepsilon$ with the amount of data $\d$, we define the data-driven surrogate model
	\begin{align}\label{eq:dynamics_approx}
	f^\varepsilon(\hat{x},\hat{u}) = P_xe^{\Delta t \mathcal{L}^{\hat{u}}_\d} \Psi(\hat{x}).
	\end{align}
	Next, we leverage the finite-data error bound~\eqref{eq:operatorbound} to ensure that the error becomes small close to the origin.
	\begin{proposition}\label{prop:errbound}
		Let~$L_\Psi$ be the Lipschitz constant of $\Psi$ on $\bX$. 
		Then, for each desired error bound $\varepsilon > 0$, the inequality
		\begin{align}\label{eq:dynamics_bound}
		\|f(x,u)-f^\varepsilon(x,u)\| \leq \varepsilon \left( L_\Psi \| x \| + \Delta t \cdot \tilde{c} \| u \| \right)
		\end{align}
		holds for all $x \in \bX$ and $u \in \bU$ with some constant~$\tilde{c}$ if \eqref{eq:operatorbound} holds provided $\{ f(x,u), f^\varepsilon(x,u) \} \in \bX$. %$f(x,u) \in \bX$ and $f^\varepsilon(x,u) \in \bX \ominus \mathcal{B}_\varepsilon(0)$.
	\end{proposition}
	\begin{proof}
		By local Lipschitz continuity of $\Psi$, $0\in \operatorname{int}(\bX)$ and $\| P_x \| \leq 1$ we compute
		\begin{align*}
		\|f(x,u)-f^\varepsilon(x,u)\| &= \big\|P_x (e^{\Delta t \mathcal{L}^u\vert_\mathbb{V}} - e^{\Delta t \mathcal{L}^u_\d})\Psi(x) \big\| \\ 
		&\leq  \big\| \left( e^{\Delta t \mathcal{L}^u \vert_\mathbb{V}} - e^{\Delta t \calL_\d^u} \right) ( \Psi(x) \pm \Psi(0)) \big\| \\
		&\leq  \underbrace{\varepsilon \|\Psi(x) - \Psi(0) \|}_{\leq L_\Psi \varepsilon \| x \|} + \big\| \underbrace{ \left( e^{\Delta t \mathcal{L}^u \vert_\mathbb{V}} - e^{\Delta t \calL_\d^u} \right) \Psi(0) }_{ =:h(\Delta t) } \big\|, %\\ 
		%\leq & \text{\textcolor{red}{$L_\Psi \varepsilon$}} 
		%\|x\| \text{\textcolor{red}{$+ \varepsilon \| u \|$}}
		\end{align*}
		Then, using the Taylor series expansion for $h(\Delta t)$ yields
		\begin{align*}
		 h(\Delta t) = h(0) + \Delta t \cdot h^\prime(\xi) &= 0 + \Delta t \cdot \left( e^{\xi \mathcal{L}^u \vert_\mathbb{V}} \mathcal{L}^u \vert_\mathbb{V} \pm e^{\xi \calL_\d^u} \mathcal{L}^u \vert_\mathbb{V} - e^{\xi \calL_\d^u} \calL_\d^u \right) \Psi(0) \\
		& = \Delta t \left[ \left( e^{\xi \mathcal{L}^u \vert_\mathbb{V}} - e^{\xi \calL_\d^u} \right) \mathcal{L}^u \vert_\mathbb{V} \Psi(0) + e^{\xi \calL_\d^u} \left( \mathcal{L}^u \vert_\mathbb{V} - \calL_\d^u \right) \Psi(0) \right]
		\end{align*}
		with $\xi \in [0,\Delta t]$. The second summand can be estimated by
		\begin{align}\label{eq:bound_u}
		\| e^{\xi \calL_\d^u} \| \left\| \left( \mathcal{L}^u \vert_\mathbb{V} - \calL_\d^u \right) \Psi(0) \right\| \leq c_1 \varepsilon \| u \|
		\end{align}
		with $c_1 := \max_{u \in \bU, \xi \in [0,\Delta t] } \| e^{\xi \calL_\d^u} \|$, 
		where we have used that the contribution of $\mathcal{L}^0$ and $\mathcal{L}^0_d$ cancels out thanks to $\Psi(0)$ and the control value acts as a multiplicative (constant) factor.
		The same line of reasoning shows $\| \mathcal{L}^u \vert_\mathbb{V} \Psi(0) \| \leq c_2 \| u \|$ with $c_2 := \max_{u \in \bU} \| \mathcal{L}^u \vert_\mathbb{V} \|$. Combining this inequality with Inequality~\eqref{eq:operatorbound} of Proposition~\ref{prop:generatorbound} and the derived Inequality~\eqref{eq:bound_u} yields the assertion, i.e., Inequality~\eqref{eq:dynamics_bound} with $\tilde{c} := c_1 + c_2$.
	\end{proof}
\noindent	In~\cite{StraBerb23}, a bound of the form~\eqref{eq:dynamics_bound} was assumed in the lifted space, i.e., without the projection $P_x$. Therein, the bound was used to construct a feedback controller achieving robust local stability using a finite gain argument.
	
	\noindent In the following, the dependence of the right hand side of~\eqref{eq:dynamics_bound} on~$\|x\|$ is key, since we get convergence of the error to zero if the state approaches the origin.
	
	
	
	\subsection{Problem statement}
	\label{subsec:problem}
	
	We will leverage the error bound of Proposition~\ref{prop:errbound} to provide a stability result when using the surrogate model $f^\varepsilon$ in Step (2) of the MPC Algorithm~\ref{alg:MPC} to stabilize the original system with right hand side $f$. 
	The main result will show that, if the nominal MPC controller is asymptotically stabilizing, the data-based controller with $f^\varepsilon$ ensures convergence to a neighborhood of the origin, whose size depends on $\varepsilon$, i.e., practical asymptotic stability as defined in the following. 
	
	\begin{definition}[Practical asymptotic stability]\label{def:pracstab}
		For $\varepsilon>0$, let $\mu_N^\varepsilon$ be the feedback law defined in Algorithm~\ref{alg:MPC} with $f=f^\varepsilon$, where admissibility of control sequences at $\hat{x}$, i.e., $u \in \calU_N^\varepsilon(\hat{x})$, is defined w.r.t.\ the tightened set $\bX \ominus \mathcal{B}_\varepsilon(0)$. Consider a set $A \subset \mathbb{X} \ominus \mathcal{B}_\varepsilon(0)$ such that the optimal control problem defining $\mu_N^\varepsilon$ is feasible for all $\hat{x} \in A$. 
		Then we say that the origin is semi-globally practically asymptotically stable on~$A$ with respect to the error $\varepsilon$ if there is $\beta \in \mathcal{K}\mathcal{L}$ such that the following holds:
		
		For each $r>0$ and $R > r$ there is $ \varepsilon_0 > 0$ such that for each $\hat{x} \in A$ with $\| \hat{x} \|\leq R$ and all $\varepsilon \in (0,\varepsilon_0]$ such that \eqref{eq:dynamics_bound} holds, the solution $x_{\mu_N^\varepsilon}(\cdot,\hat{x})$ of 
		\begin{align}\label{eq:ex_cl}
		x_{\mu_N^\varepsilon} (n+1) = f(x_{\mu_N^\varepsilon}(n),\mu_N^\varepsilon(x_{\mu_N^\varepsilon}(n)))
		\end{align}
		with $x_{\mu_N^\varepsilon}(0) = \hat{x}$ satisfies $x_{\mu_N^\varepsilon}(n;\hat{x})\in A$ and 
		\begin{align*}
		\| x_{\mu_N^\varepsilon}(n;\hat{x}) \| \leq \max \{\beta(\| \hat{x} \|,n),r\} \qquad\forall\,n \in \mathbb{N}_0.
		\end{align*}
	\end{definition}
	\noindent The incorporation of the Pontryagin difference $\mathbb{X} \ominus \mathcal{B}_\varepsilon(0)$ in the admissibility of control sequences for the surrogate model ensures that the original system evolves in the compact set~$\bX$, i.e., that every optimal control function is, in particular, admissible for the original system in view of the error bound of Proposition~\ref{prop:generatorbound}.
	In the following section, we will show that the error bound shown in Proposition~\ref{prop:errbound} and cost-controllability of the original dynamics imply practical asymptotic stability of the closed-loop using data-based MPC.
	
	
	
	
	\section{Practical asymptotic stability of surrogate-based MPC}
	\label{sec:PAS}
	
	In this part, we prove the main result of this work, i.e., practical asymptotic stability of data-based MPC Algorithm~\ref{alg:MPC} using the eDMD-based surrogate $f^\varepsilon$ as defined in \eqref{eq:dynamics_approx} to stabilize the original system given by $f$ as defined in \eqref{eq:dynamics_sampled_data} or, equivalently, \eqref{eq:dynamics_exact}.
	
	
	
	\subsection{%Numerical a
		Approximation errors and stability}
	
	In this section, we follow 
	the line of reasoning outlined in~\cite[Section~11.5]{GrunPann17}. To this end, in Proposition \ref{thm:PAS} we recall \cite[Theorem 11.10]{GrunPann17} regarding \emph{stability for perturbed solutions}, which is key in our analysis. We define
	$$
	V^\varepsilon_N(\hat{x}) := \inf_{u \in \calU_N^\varepsilon(\hat{x})}\sum_{k=0}^{N - 1} \ell(x^\varepsilon_u(k;\hat{x}),u(k))
	$$
	where $x_u^\varepsilon(0;\hat{x}) = \hat{x}$ and $x_u^\varepsilon(k+1;\hat{x}) = f^\varepsilon(x_u^\varepsilon(k;\hat{x}),u(k))$ for $k\in [0:N-2]$.
	\begin{proposition}\label{thm:PAS}
		Consider the NMPC-feedback law~$\mu_N^\varepsilon$ obtained from Algorithm~\ref{alg:MPC} with $f = f^\varepsilon$ with $f^{\varepsilon}$ satisfying Condition~\eqref{eq:dynamics_bound} and let $S \subset \bX$ be a set that is forward invariant w.r.t.\ $f^\varepsilon(\cdot,\mu^\varepsilon_N(\cdot))$.     Further assume that the following hold:
		\begin{enumerate}
			\item [(i)] $V^\varepsilon_N$ satisfies the assumptions of Proposition~\ref{thm:stability_suboptimality} in the following sense: 
			There is $\varepsilon_0>0$ and $\alpha \in (0,1]$ such that for all $\varepsilon\in (0,\varepsilon_0]$ the relaxed dynamic programming inequality
			\begin{align*}
			V_N^\varepsilon(x) \geq \alpha \ell(x,\mu^\varepsilon_N(x)) + V_N^\varepsilon(f^\varepsilon(x,\mu^\varepsilon_N(x)))
			\end{align*}
			holds on $S$. 
			Further there exist $\varepsilon_0>0$ and $\alpha_1,\alpha_2,\alpha_3 \in \mathcal{K}_\infty$ such that for all $x \in S$
			\begin{align*}
			\alpha_1(\|x\|) \leq V_N^\varepsilon(x) \leq \alpha_2(\|x\|) \quad \mathrm{and}\quad \ell(x,u) \geq \alpha_3(\|x\|)
			\end{align*}
			hold for all $\varepsilon \in (0,\varepsilon_0]$ and $u\in \mathbb{U}$.
			\item [(ii)] $V^\varepsilon_N$ is uniformly continuous on closed balls $\overline{B}_\rho(0)$ in the following sense: 
			There is $\varepsilon_0$ such that for each $\rho >0$ there exists $\omega_V\in \mathcal{K}$ satisfying
			\begin{align*}
			|V^\varepsilon_N(x)-V^\varepsilon_N(y)| \leq \omega_V(\|x-y\|).
			\end{align*}
			for all $x,y \in \overline{B}_\rho(0) \cap S$ and $\varepsilon\in (0,\varepsilon_0]$.
			\item [(iii)] $f^\varepsilon$ is uniformly continuous on closed balls $\overline{B}_\rho(0)$, uniformly in $u$: 
			There is $\varepsilon_0>0$ such that for each $\rho > 0$ there exists $\omega_f\in \mathcal{K}$ satisfying
			\begin{align*}
			\|f^\varepsilon(x,u)-f^\varepsilon(y,u)\| \leq \omega_f(\|x-y\|)
			\end{align*}
			for all $x,y \in \overline{B}_\rho(x^*) \cap S$, $u\in \mathbb{U}$, and $\varepsilon\in (0,\varepsilon_0]$.
		\end{enumerate}
		Then the exact closed-loop system with perturbed feedback $\mu_N^\varepsilon$ defined in \eqref{eq:ex_cl} is semiglobally
		practically asymptotically stable with respect to $\varepsilon$ on $A = S$ in the sense of Definition~\ref{def:pracstab}.
	\end{proposition}
	
	
	
	\subsection{Practical asymptotic stability of the eDMD-based surrogate model}
	
	We first verify the second condition of Proposition~\ref{thm:PAS} in the following proposition.
	\begin{proposition}[Uniform continuity of $f^\varepsilon$]\label{lem:as12}
		Let $\varepsilon_0 > 0$ be given such that the error bound~\eqref{eq:operatorbound} holds with~$\varepsilon_0$. 
		Then there is a constant $c(\varepsilon_0)\geq 0$ such that for all $\varepsilon\in (0,\varepsilon_0]$ 
		\begin{align}\label{eq:feps_lipschitz}
		\|f^\varepsilon(x,u)-f^\varepsilon(y,u)\| \leq c(\varepsilon_0) L_\Psi \|x-y\|
		\end{align}
		holds for all $x,y \in \bX$ % \ominus \mathcal{B}_\varepsilon(0)$ 
		and $u\in \mathbb{U}$. Thus, condition~$(iii)$ of Proposition~\ref{thm:PAS} holds true for $\omega_f(r)=c(\varepsilon_0)L_\Psi r$.
	\end{proposition}
	\begin{proof}
		Since the error bound~\eqref{eq:operatorbound} holds with $\varepsilon_0$ and $\|P_x\|\leq 1$, we have
		\begin{align}\label{eq:errorbound_eps0}
		\|P_x e^{\Delta t \mathcal{L}^u_\d}\| \leq \|e^{\Delta t \mathcal{L}^u_\d}\| \leq \|e^{\Delta t \mathcal{L}^u_\d}- e^{\Delta t \mathcal{L}^u}\| +  \|e^{\Delta t \mathcal{L}^u}\| \leq \varepsilon_0 + \|e^{\Delta t \mathcal{L}^u}\| \leq \underbrace{\varepsilon_0 + \max_{u \in \bU} \|e^{\Delta t \mathcal{L}^u}\|}_{=: c(\varepsilon_0)}
		\end{align}
		for all $u\in \mathbb{U}$ and all $\d\geq \d_0$.
		Further, for all $\varepsilon \in (0,\varepsilon_0]$, $x,y\in \bX$ and $u \in \bU$, the claim follows from
		\begin{align*}
		\|f^\varepsilon(x,u) - f^\varepsilon(y,u)\| = \|P_xe^{\Delta t \mathcal{L}^u_\d}(\Psi(x)-\Psi(y))\| \leq c(\varepsilon_0)\|\Psi(x)-\Psi(y)\| %&\leq c(\varepsilon) L_\Psi \|x-y\| \\
		&\leq c(\varepsilon_0) L_\Psi \|x-y\|.
		\end{align*}
	\end{proof}
	
	\noindent Next, we show condition~(i) of Proposition~\ref{thm:PAS}. To this end, we assume that the original system satisfies a sufficient condition for cost controllability and show that this controllability property is preserved for the data-based surrogate model~\eqref{eq:dynamics_approx}. Cost controllability links stabilizability with the stage cost employed in MPC, see, e.g., \cite{GrunPann10,Wort11}.
	\begin{proposition}[Condition~(i) of Proposition~\ref{thm:PAS}]\label{prop:as3}
		Let the following \emph{cost-controllability}-like assumption for the original dynamics~\eqref{eq:dynamics_sampled_data} and the quadratic stage cost~\eqref{eq:stage_cost} hold: 
		There is $(c_n)_{n \in \mathbb{N}_0} \subset \mathbb{R}_{\geq 0}$ with $\gamma := \sum_{n=0}^\infty c_n < \infty$ and a set $S \subseteq \mathbb{X} \ominus \mathcal{B}_\varepsilon(0) \subset \mathbb{R}^{\nx}$ such that, for each $\hat{x} \in S$, there exists an admissible sequence of control values $(u_n)_{n \in \mathbb{N}_0} \in \mathcal{U}_N(\hat{x}) \cap \mathcal{U}_N^\varepsilon(\hat{x})$ with the property
		\begin{equation}\label{eq:cost_controllability_cn}
		\ell(x_u(n;\hat{x}),u_n) \leq c_n \ell^\star(\hat{x}) := c_n \cdot \!\!\inf_{u \in \bU} \ell(\hat{x},u).
		\end{equation}
		Then there is a prediction horizon $N\in \mathbb{N}$ such that for all sufficiently small $\varepsilon_0 > 0$, if the error bound~\eqref{eq:operatorbound} holds for $\varepsilon \in (0,\varepsilon_0]$, condition~(i) of Proposition~\ref{thm:PAS} holds for the system dynamics~\eqref{eq:dynamics_approx}.
	\end{proposition}
	\begin{proof}
		First, we note that the lower bound on the optimal value function can be straightforwardly inferred from the choice of the stage cost in \eqref{eq:stage_cost}:
		\begin{align*}
		V_N^\varepsilon(\hat{x}) = \inf_{u\in \mathcal{U}_N^\varepsilon(\hat{x})} J_N^\varepsilon(\hat{x},u) \geq \inf_{u\in \mathbb{U}}\ell(\hat{x},u) = \| \hat{x} \|_Q^2 \geq \lambda_{\min}(Q) \| \hat{x} \|^2,
		\end{align*}
		where $\lambda_{\min}(Q) > 0$ denotes the minimal eigenvalue of the positive definite matrix~$Q$.
		Let $\hat{x} \in S$ be arbitrarily chosen, but fixed. Further, invoking the assumption based on~$\hat{x}$ yields a sequence of control values $(u_n)_{n \in \mathbb{N}_0}$ satisfying property~\eqref{eq:cost_controllability_cn}. Let $\tilde{x}_u(n)$ and ${x}_u(n)$, $n \in \mathbb{N}_0$, denote the trajectories governed by $\tilde{x}_u(n+1) = f^\varepsilon(\tilde{x}_u(n),u(n))$, $\tilde{x}_u(0) = \hat{x}$ and $x_u(n+1) = f({x}_u(n),u(n))$, ${x}_u(0) = \hat{x}$, respectively.
		Then, we have
		\begin{align*}
		\ell(\tilde{x}_u(n), u(n)) & = \| \tilde{x}_u(n) \|^2_Q + \| u(n) \|^2_R \\
		& = \| \tilde{x}_u(n) - x_u(n) + x_u(n) \|^2_Q + \| u(n) \|^2_R \\
		& \leq \| \tilde{x}_u(n) - x_u(n) \|^2_Q + 2 \lambda_{\max}(Q) \| \tilde{x}_u(n) - x_u(n) \| \| x_u(n) \| + \ell(x_u(n),u(n)) \\
		& \!\!\stackrel{\eqref{eq:cost_controllability_cn}}{\leq} \| \tilde{x}_u(n) - x_u(n) \|^2_Q + \frac {2\sqrt{c_n} \lambda_{\max}(Q)}{\sqrt{\lambda_{\min}(Q)}} \cdot \| \tilde{x}_u(n) - x_u(n) \| \| \hat{x} \|_Q + c_n \ell^\star(\hat{x}),
		\end{align*}    
		where $\lambda_{\max}(Q) > 0$ denotes the maximal eigenvalue of the positive definite matrix~$Q$.
		If \eqref{eq:operatorbound} holds, then Proposition~\ref{prop:errbound} yields the bound \eqref{eq:dynamics_bound} on the difference of~$f$ and~$f^\varepsilon$. Thus, we may estimate the term $e_n := \| \tilde{x}_u(n) - x_u(n) \|$:
		\begin{align*}
		e_n & = \| f_\varepsilon(\tilde{x}_u(n-1),u(n-1)) \pm f(\tilde{x}_u(n-1),u(n-1)) - f(x_u(n-1),u(n-1)) \| \\
		& \leq \varepsilon \left( L_\Psi \| \tilde{x}_u(n-1) \| + \Delta t \tilde{c} \| u(n-1) \| \right)  + L_f \| \tilde{x}_u(n-1) - x_u(n-1) \| \\
		& = \varepsilon \bar{c} \left(\| \tilde{x}_u(n-1) \| + \| u(n-1) \| \right) + L_f e_{n-1}
		\end{align*}
		with $\bar{c} := \max \{ L_\Psi, \Delta t \tilde{c} \}$.
		Then, using the inequality
		\begin{align*}
		\| \tilde{x}_u(n-1) \| & = \| \tilde{x}_u(n-1) - x_u(n-1) + x_u(n-1) \| \\
		& \leq e_{n-1} + \| x_u(n-1) \| \stackrel{\eqref{eq:cost_controllability_cn}}{\leq} e_{n-1} + \frac {\sqrt{c_{n-1}} \lambda_{\max}(Q)}{\sqrt{\lambda_{\min}(Q)}} \| \hat{x} \| - \| u(n-1) \|
		\end{align*}
		yields
		\begin{equation}\label{eq:recursion}
		e_n \leq (L_f + \varepsilon \bar{c} ) e_{n-1} + \varepsilon \bar{c} \frac {\sqrt{c_{n-1}} \lambda_{\max}(Q)}{\sqrt{\lambda_{\min}(Q)}} \| \hat{x} \|.
		\end{equation}
		Iterative application of the recursion~\eqref{eq:recursion} and using $e_0 := 0$ yields
		\begin{equation}\nonumber
		e_n \leq \varepsilon \cdot \left( \frac { \lambda_{\max}(Q) \bar{c} }{\sqrt{\lambda_{\min}(Q)}} \sum_{i=1}^n (L_f + \bar{c} \varepsilon)^{i-1} \sqrt{c_{n-i}} \right) \| \hat{x} \|.
		\end{equation}
		Overall, using $\ell^\star(\hat{x}) = \| \hat{x} \|^2_Q$, we get the estimate
		% \begin{align*}\nonumber
		%      \ell(\tilde{x}_n(n), u(n)) & \leq e_n^2 + \frac {2\sqrt{c_n} \lambda_{\max}(Q)}{\sqrt{\lambda_{\min}(Q)}} \cdot e_n \| \hat{x} \| + c_n \ell^\star(\hat{x}) \\
		%      & \leq \underbrace{\left[ \varepsilon^2 \left( \sum_{i=1}^n (L_f + \varepsilon)^{i-1} \sqrt{c_{n-i}} \right)^2 + \varepsilon \cdot \frac {2\sqrt{c_n} \lambda_{\max}(Q)^2}{\lambda_{\min}(Q)} \left( \sum_{i=1}^n (L_f + \varepsilon)^{i-1} \sqrt{c_{n-i}} \right) + c_n \right]}_{=: c_n^\varepsilon} \ell^\star(\hat{x}).
		%  \end{align*}   
		\begin{align*}
		\ell(\tilde{x}_n(n), u(n))
		\leq & \lambda_{\max}(Q) e_n^2 + \frac {2\sqrt{c_n} \lambda_{\max}(Q)}{\sqrt{\lambda_{\min}(Q)}} \cdot e_n \| \hat{x} \|_Q + c_n \ell^\star(\hat{x}) \\
		\leq & \bigg[ \varepsilon^2 \frac { \lambda_{\max}(Q)^3 \bar{c}^2}{{\lambda_{\min}(Q)}} \left( \sum_{i=1}^n (L_f + \varepsilon \bar{c})^{i-1} \sqrt{c_{n-i}} \right)^2 
		\\ 
		& \qquad \qquad+ \varepsilon \frac {2\sqrt{c_n} \lambda_{\max}(Q)^2 \bar{c}}{\lambda_{\min}(Q)} \left( \sum_{i=1}^n (L_f + \varepsilon \bar{c})^{i-1} \sqrt{c_{n-i}} \right) + c_n \bigg] \ell^\star(\hat{x})
		=:  c_n^\varepsilon \ell^\star(\hat{x}).
		\end{align*}
		Next, we choose the prediction horizon~$N$ large enough such that $\alpha = \alpha(N) \in (0,1)$ holds for $\alpha_N$ as introduced in~\cite[Theorem~5.4]{GrunPann10} and~\cite{Wort11}, i.e.,
		\begin{equation}\label{eq:alpha}
		\alpha = \alpha_N := 1 - \frac {(\gamma_2 - \omega) (\gamma_N - 1) \prod_{i=3}^N (\gamma_i - 1)} {\prod_{i=2}^N \gamma_i - (\gamma_2 - \omega) \prod_{i=3}^N (\gamma_i - 1)}
		\end{equation}
		using the notation $\gamma_i := \sum_{n=0}^{i-1} c_n$ for $i \in [2:N]$ and setting $\omega = 1$.
		Then, defining $\alpha^\varepsilon$ analogously using the coefficient sequence $(c_n^\varepsilon)_{n \in \mathbb{N}_0}$ instead and invoking $\lim_{\varepsilon \searrow 0} c_n^\varepsilon = c_n$, yields $\alpha^\varepsilon \in (0,1)$ for sufficiently small~$\varepsilon$. 
		Using this $\varepsilon$ as $\varepsilon^0$ ensures the relaxed Lyapunov inequality for all $V_N^\varepsilon$, $\varepsilon \in (0,\varepsilon^0]$ by applying \cite[Theorem 5.2]{Grun09}.
		
		Last, the desired upper bound on the value function $V_N^\varepsilon(\hat{x})$ directly follows from the deduced cost controllability with $\alpha_2(r) :=  \lambda_{\min}(Q)^{-1} \cdot \sum_{n=0}^{N-1} c_n^\varepsilon \cdot r^2$.
	\end{proof}
	We emphasize that condition~\eqref{eq:cost_controllability_cn} coincides with the one proposed in~\cite{Grun09} except for the slight amendment that the respective control sequence has to be admissible for the surrogate model. While this may be a severe restriction close to the boundary of the set~$\bX \ominus \mathcal{B}_\varepsilon(0)$, it is typically 
	satisfied on a suitably chosen sub-level set of the optimal value function~$V_N$ in view of the finite prediction horizon~$N$.
	\begin{remark}
		We may add a term $\omega \ell(x_u(N;\hat{x}),u(N))$ to the cost functional to be minimized in Step~(2) of the MPC Algorithm~\ref{alg:MPC}, where $\omega \in [1,\gamma_2)$ denotes the terminal weight. Doing so may drastically reduce the required length of the prediction horizon~$N$ to ensure positivity of $\alpha = \alpha(N)$, see, e.g., \cite{Wort11}. 
	\end{remark}
	
	\noindent We briefly provide an extension of the previous result, in which we replace the condition~\eqref{eq:cost_controllability_cn} by cost controllability as defined in~\cite{CoroGrun20} and~\cite{Wort11} for continuous- and discrete-time systems, respectively. 
	The proof is similar to the one of Proposition~\ref{prop:as3}, but slightly more technical. Hence, we present the additional details in the appendix.
	\begin{proposition}[Cost controllability]\label{prop:link_costcont}
		Assume that there is a monotonically increasing and bounded sequence $(B_k)_{k = 1}^\infty \subset \mathbb R$ such that for all $x \in S \subseteq \bX \ominus \mathcal{B}_\varepsilon(0)$ the growth bound
		\begin{align}\label{eq:cost_controllability}
		V_k(\hat{x}) \leq J_k(\hat{x},u_{\hat{x}}^\star) \leq B_k \ell^\star(\hat{x}) \qquad\forall\,k\in \mathbb{N}
		\end{align}
		holds with the (optimal) sequence of control values $u_{\hat{x}} \in \mathcal{U}_N(\hat{x}) \cap \mathcal{U}_N^\varepsilon(\hat{x})$.
		Then, for all sufficiently small $\varepsilon_0 > 0$, if the error bound~\eqref{eq:operatorbound} holds for $\varepsilon \in (0,\varepsilon_0]$, condition~(i) of Proposition~\ref{thm:PAS} holds for the system dynamics~\eqref{eq:dynamics_approx}.
	\end{proposition}
	
	Finally, invoking our finding on cost controllability, we verify the third condition of Proposition~\ref{thm:PAS} in the following. % proposition. 
	In the previous result we showed that the optimal value function $V_N^\varepsilon$ is a Lyapunov function for the closed loop along the surrogate dynamics $f^\varepsilon$. 
	\begin{proposition}[Uniform continuity of $V^\varepsilon_N$]\label{prop:V_continuity}
		Let $\varepsilon_0 > 0$ be given such that the error bound~\eqref{eq:operatorbound} holds with~$\varepsilon_0$. 
		Let $S \subset \bX \ominus \mathcal{B}_\varepsilon(0)$ and $\eta > 0$ be given such that, for all $\varepsilon \in (0,\varepsilon_0]$, the optimal value function $V^\varepsilon_N(\hat{x})$, $\hat{x} \in \bX$ is finite on~$S$ and the minimum is attained for a control function~$u^\star \in \mathcal{U}_N^\varepsilon(\hat{x})$ such that $x^\varepsilon_{u^\star}(k;\hat{x}) \in \bX \ominus \mathcal{B}_{\varepsilon + \eta}(0)$ for all $k\in [0:N-1]$. Then there is $L \geq 0$ such that
		\begin{align*}
		|V^\varepsilon_N(y_1)-V^\varepsilon_N(y_2)| \leq L\|y_1-y_2\| \qquad\forall\,y_1,y_2 \in S %\bX
		\end{align*}
		holds for all $\varepsilon \in (0,\varepsilon_0]$. In particular, Condition~$(ii)$ of Proposition~\ref{thm:PAS} holds with $\omega_V(r)=Lr$.
	\end{proposition}
	\noindent The assumption that $V_N^\varepsilon(x)$ is finite is, in view of compactness of the sets~$\bX$ and~$\bU$, equivalent to the existence of an admissible sequence of control values, i.e., $\mathcal{U}_N^\varepsilon(x) \neq \emptyset$ %for all $x \in \bX$ 
	and can be relaxed by restricting the assertion to some level set of~$V_N^\varepsilon$ contained in the compact set~$\bX \ominus \mathcal{B}_\varepsilon(0)$. The assumption that the minimum exists may be completely dropped and is only imposed to streamline the presentation, see, e.g., \cite[p.\ 59]{GrunPann17} for details.
	\begin{proof}
		In combination with the uniform continuity of~$f^\varepsilon$ proven in Proposition~\ref{lem:as12}, the assumption that $x^\varepsilon_{u^\star}(k;\hat{x}) \in \bX \ominus \mathcal{B}_{\varepsilon + \eta}(0)$ for all $k\in [0:N-1]$ implies the existence of some~$\hat{\eta}>0$ such that, for each $\hat{x} \in \bX$, the optimal control $u^\star \in \mathcal{U}_N^\varepsilon(\hat{x})$ remains admissible for all initial values from $\mathcal{B}_{\hat{\eta}}(\hat{x})$. That means that there exists at least one optimal sequence of control values for which the corresponding optimal trajectory is bounded away from the state constraints --~uniformly w.r.t.\ the initial condition chosen in the set~$S$.
		
		Then, $V_N^\varepsilon$ is uniformly bounded on~$S$. This immediately shows the assertion for all $y_1, y_2 \in S$ satisfying $\| y_1 - y_2 \| > \hat{\eta}$, see, e.g., \cite{BoccGrun14} for a detailed outline of the construction. 
		Hence, we only have to show the assumption for $y_1,y_2 \in S$ satisfying $\| y_1 - y_2 \| \leq \hat{\eta}$.
		
		Based on our assumption that an optimal sequence of control values exists, for every $y_2 \in \bX$ there is $u_2^{\star} \in \calU_N^\varepsilon(y_2)$ such that $V^\varepsilon_N(y_2)=J_N(y_2,u_2^{\star})$ and
		\begin{align*}
		V^\varepsilon_N(y_1) - V^\varepsilon_N(y_2) & = \inf_{ u \in \calU_N^\varepsilon(y_1) } J_N(y_1,u) - \inf_{ u \in \calU_N^\varepsilon(y_2) } J_N(y_2,u) %J_N(x^\varepsilon(y_1;u),u) - \inf_{u\in \mathbb{U}} J_N(x^\varepsilon(y_2;u),u) 
		% \\ &
		\leq J_N(y_1,u_2^{\star}) - J_N(y_2,u_2^{\star}),
		\end{align*}
		where we invoked admissibility of $u_2^\star$ for~$y_1$.
		As $f^\varepsilon(\cdot,u)$ is uniformly Lipschitz continuous on $S$ in $\varepsilon$, $\varepsilon \leq \varepsilon_0$, and $u \in \mathbb{U}$ as shown in Proposition~\ref{lem:as12}, we get
		\begin{align*}
		V^\varepsilon_N(y_1)-V^\varepsilon_N(y_2) & \leq J_N(y_1,u_2^{\star}) - J_N(y_2,u_2^{\star}) \\
		&=\sum_{k=0}^{N-1} \|x_{u_2^{\star}}^\varepsilon(k;y_1)\|^2_Q-\|x_{u_2^{\star}}^\varepsilon(k;y_2)\|^2_Q\\
		& = \sum_{k=0}^{N-1} \| x_{u_2^{\star}}^\varepsilon(k;y_1) - x_{u_2^{\star}}^\varepsilon(k;y_2) \|_Q^2 + 2 x_{u_2^{\star}}^\varepsilon(k;y_2)^\top Q (x_{u_2^{\star}}^\varepsilon(k;y_1)-x_{u_2^{\star}}^\varepsilon(k;y_2)) \\
		& \leq \| Q \| \sum_{k=0}^{N-1} \left( \| x_{u_2^{\star}}^\varepsilon(k;y_1) - x_{u_2^{\star}}^\varepsilon(k;y_2) \|^2 + 2 \| x_{u_2^{\star}}^\varepsilon(k;y_2) \| \| x_{u_2^{\star}}^\varepsilon(k;y_1)-x_{u_2^{\star}}^\varepsilon(k;y_2) \| \right) \\
		& \leq \left[ \| Q \| (c(\varepsilon_0) {L}_\Psi)^k \sum_{k=0}^{N-1} \left( (c(\varepsilon_0) {L}_\Psi)^k \| y_1 - y_2 \| + 2 \| x_{u_2^{\star}}^\varepsilon(k;y_2) \| \right) \right] \| y_1 - y_2 \|
		\end{align*}
		for all $y_1,y_2\in \bX$, where we have invoked the derived Lipschitz continuity $k$~times. 
		Then, using that both $\| y_1 - y_2 \|$ as well as $\| x_{u_2^{\star}}^\varepsilon(k;y_2) \|$ are uniformly bounded for $y_1$ and $y_2$ belonging to the compact set~$\bX$, we have derived the inequality $V^\varepsilon_N(y_1)-V^\varepsilon_N(y_2) \leq L \| y_1 - y_2 \|$.
		Analogously, inserting an optimal sequence of control values $u_1^{\star} \in \calU^\varepsilon_N(y_1)$ satisfying $V^\varepsilon_N(y_1) = J_N(y_1,u_1^{\star})$, we can analogously derive the inequality
		\begin{align*}
		V^\varepsilon_N(y_2) - V^\varepsilon_N(y_1) \leq J_N(y_2,u_1^{\star}) - J_N(y_1,u_1^{\star}) \leq L \|y_1-y_2\|.
		\end{align*}
		for all $y_1,y_2\in S$. %Defining $\omega_V(r)=\max\{\omega_1(r),\omega_2(r)\}$ yields the result.
		Combining both inequalities yields the assertion.
	\end{proof}
	\begin{remark}
		The imposed (technical) condition w.r.t.\ $\eta > 0$ in the assumptions of Proposition~\ref{prop:V_continuity} can, e.g., be ensured in view of Propositions~\ref{prop:as3} and~\ref{prop:link_costcont} by choosing a sufficiently small sub-level set $\{ x \in S : V_N^\varepsilon(x) \leq a\}$ such that $x_{u^\star}^\varepsilon(k) \notin \bX \ominus \mathcal{B}_{\varepsilon + \eta}(0)$ for some $k \in [1:N-1]$ yields a contradiction in view of the quadratic penalization of that state in the stage cost and the assumed bound~$a$ on the sub-level set --~similar to the construction used in~\cite{BoccGrun14}.
	\end{remark}
	
	\noindent We now state the main result of this work.
	\begin{theorem}[PAS of eDMD-based MPC]\label{thm:main}
		Let Assumption~\ref{ass:invariance} hold and suppose that the assumptions of Proposition~\ref{prop:V_continuity} hold.
		Further assume cost controllability, i.e., Condition~\eqref{eq:cost_controllability}, of the dynamics~\eqref{eq:dynamics_sampled_data} and the stage cost~\eqref{eq:stage_cost} and that the prediction horizon~$N$ is chosen such that $\alpha_N^\varepsilon > 0$ holds for the respective suboptimality index defined by~\eqref{eq:alpha} with $\gamma_k = B_k^\varepsilon$. 
		
		If the error bound~\eqref{eq:operatorbound} holds with $\varepsilon > 0$, then the eDMD-based MPC controller ensures semi-global practical asymptotic stability of the origin w.r.t.\ $\varepsilon$ on the set $S$ from Proposition~\ref{prop:V_continuity}.
	\end{theorem}
	\begin{proof}
		By Propositions~\ref{lem:as12}, %\ref{prop:as3}, %
		\ref{prop:link_costcont}
		and \ref{prop:V_continuity}, the bound~\eqref{eq:operatorbound} and the stated assumptions imply conditions~(i)--(iii) of Proposition~\ref{thm:PAS}. This yields the claim.
	\end{proof}
	\noindent Theorem~\ref{thm:main} shows that the bound \eqref{eq:operatorbound} is the key ingredient for PAS of eDMD-based MPC. In Proposition~\ref{prop:generatorbound} we proved that such a bound can be guaranteed with probability $1-\delta$. This allows to also deduce PAS with probability $1-\delta$. Increasing the number of samples can then be used to either increase the confidence (that is, to reduce $\delta$), or reduce $\varepsilon$ which allows to shrink the set of PAS, i.e., reduce the radius $r>0$ in Definition~\ref{def:pracstab}.
	
	\noindent We conclude this section by briefly sketching a possible extension to stochastic dynamics.
	\begin{remark}[Stochastic dynamical systems]
		The central error bound \eqref{eq:operatorbound} is -- with slight adaptation including an expected value -- also transferable to the dynamics given by a stochastic differential equation with i.i.d.\ or ergodic sampling, cf.\ \cite{NuskPeit23}. In this context, one would optimize an expected value and may then be able to derive a decrease of the corresponding optimal value function in expectation. 
	\end{remark}
	
	
	
	
	\section{Numerical simulations}
	\label{sec:example}
	
	In this section we %will 
	conduct numerical simulations illustrating practical asymptotic stability of the origin for eDMD-based MPC as proven in Theorem~\ref{thm:main}. To this end, we consider two nonlinear two-dimensional control systems: the van der Pol oscillator and a simple pendulum.
	
	
	
	\subsection{Van-der-Pol oscillator} \label{subsec:vanderpol}
	
	First, we consider the van-der-Pol oscillator, whose system dynamics is modeled as 
	\begin{align} \label{eq:vanderPol}
	\dot{x}(t) = \begin{pmatrix}
	\dot x_1(t) \\ \dot x_2(t)
	\end{pmatrix} = \begin{pmatrix}
	x_2(t) \\ \mu (1 - x_1^2(t)) x_2(t) - x_1(t) + u(t)
	\end{pmatrix}
	\end{align}
	with the scalar parameter~$\mu=0.1$. %, the state vector $x(t) \in \R^2$ and the control input $u(t) \in \R$. 
	Since the linearization at the origin is controllable, cost controllablility holds for the quadratic stage cost~\eqref{eq:stage_cost}, see, e.g., \cite{Wort11}.
	%For our simulations, which are performed in Python, we choose $\mu = 0.1$. \\
	We consider the ODE~\eqref{eq:vanderPol} as a sampled-data system with zero-order hold as introduced in~\eqref{eq:dynamics_sampled_data}, where the integrals are numerically solved using the Runge-Kutta-Fehlberg method (RK45) with step-size control (Python function \textit{scipy.integrate.solve\_ivp}). This results in a discrete-time system
	\begin{align}\label{eq:RKV discrete}
	x_u(k+1;\hat{x}) = f(x_u(k;\hat{x}),u(k)), \qquad x_u(0;\hat{x}) = \hat{x}
	\end{align} 
	which serves as the ground truth. For the approximation of the Koopman operator on the set $\mathbb{X} = [-2, 2]^2$, eDMD as described in Section~\ref{subsec:eDMD} is used. As dictionary of observables we choose all $n_x$-variate monomials of degree less or equal than three, resulting in a dictionary size of $M = 10$.
	
	\noindent First, we inspect the open-loop error of the eDMD-based surrogate compared to the ground truth~\eqref{eq:RKV discrete}. In Figure~\ref{fig:openloop}, we show the results for a random but fixed control sequence $u$ and different numbers of data points $d \in \lbrace 10, 50, 100, 1000, 10000 \rbrace$. %As a reference, the ODE was numerically solved by using a Runge-Kutta method with step size $\Delta t = 0.05$. 
	The left plot of Figure~\ref{fig:openloop} shows the average norm of the error for $100$ initial conditions distributed uniformly over $\mathbb{X} = [-2, 2]^2$. As to be expected from Proposition~\ref{prop:errbound}, the open-loop error decreases for increased number of samples. %, as shown in , but does in view of fix error tolerances in the ODE solver not to zero. 
	
	\begin{figure}[htb]
		\centering
		\includegraphics[width=.48\linewidth]{Images/error_lessdata7.png} \includegraphics[width=.467\linewidth]{Images/random_control3.png}
		\caption{Averaged error of eDMD-based solution for different number of data points (left) for fixed random control sequence (right).
		}
		\label{fig:openloop}
	\end{figure}
	
	\noindent Next, we inspect the MPC closed-loop behavior. To this end, we define an optimal control problem with quadratic costs $J_N(\hat{x},u) := \sum_{k=0}^{N - 1} \|x_u(k;\hat{x})\|_2^2 + \lambda\|u(k)\|_2^2$ subject to \eqref{eq:RKV discrete}, $-5 \leq u(k) \leq 5$ for $k \in [0:N-1]$ and $x(k)\in \bX$ for $k \in [0:N]$. In Figure~\ref{fig:MPC RKV}, we compare the performance of the closed-loop of nominal MPC denoted by $x_{\mu_N}$ as defined in \eqref{eq:dynamics_closed_loop}
	and the closed-loop of eDMD-based MPC $x_{\mu_N^\varepsilon}$ defined in \eqref{eq:ex_cl} for two choices of the control penalization parameter $\lambda \in \lbrace 0.05, 0.25\rbrace$ and two optimization horizons $N \in \lbrace 30, 50\rbrace$. The approximation of the Koopman matrix is performed using eDMD with the monomial dictionary described above and with $d = 10000$ i.i.d.\ data points. %
	
	In Figure~\ref{fig:phase portrait}, we depict the closed-loop behavior of nominal MPC in phase space. We see, that the state approaches the origin for all horizons $N\in\{30,50\}$ and penalization parameters $\lambda \in \{0.05,0.25\}$.
	\begin{figure}[htb]
		\centering
		\includegraphics[width=.55\linewidth]{Images/RKV_3.png}
		\caption{Phase portrait of closed-loop solution corresponding to \eqref{eq:vanderPol} for nominal MPC.}
		\label{fig:phase portrait}
	\end{figure}
	
	\begin{figure}[htb]
		\centering
		% \includegraphics[width=.47\linewidth]{Images/vanderpol_lambda025.png}\includegraphics[width=.47\linewidth]{Images/vanderpol_lambda005_short.png}
		\includegraphics[width=.49\linewidth]{Images/lambda005b.png}    \includegraphics[width=.49\linewidth]{Images/lambda025b.png}
		\caption{Norm of closed-loop solution of \eqref{eq:vanderPol} for nominal MPC (black) and eDMD-based MPC~(gray) for horizons $N = 30$ (solid) and $N = 50$ (dashed) and penalization parameters $\lambda = 0.05$ (left) and $\lambda = 0.25$~(right).}%optimal value function of nominal MPC and eDMD-based MPC for $\lambda = 0.25$ (bottom right) and $\lambda = 0.05$ (bottom left)}%,
		\label{fig:MPC RKV}
	\end{figure}
	
	\noindent Next, we compare the nominal MPC with eDMD-based MPC in Figure~\ref{fig:MPC RKV}. For small control penalization parameter $\lambda = 0.05$, the norm of the closed-loop state corresponding to nominal MPC % depicted on the bottom right of Figure~\ref{fig:MPC RKV} 
	converges to the precision $10^{-12}$ of the optimization solver used. As to be expected, this convergence is faster for a longer prediction horizon. As proven in our main result Theorem~\ref{thm:main}, the eDMD-based surrogate only enjoys practical asymptotic stability, i.e., for both horizons the convergence stagnates around $10^{-8}$. More precisely, increasing the horizon only increases the convergence speed and does not lead to a lower norm at the end of the considered simulation horizon. The same qualitative behavior also can be observed for the larger control penalization $\lambda = 0.25$. Here, both nominal and eDMD-based MPC converge slower due to a higher control cost. However, the behavior of eDMD-based MPC
	is qualitatively the same: At around $10^{-8}$, the convergence stagnates. The fact that this point of stagnation is the same for both horizons and both control penalization parameters illustrates that the bottleneck is the approximation quality of the eDMD-based surrogate. 
	
	In Figure~\ref{fig:VN vanderpol}, we illustrate the decrease of the optimal value function along the closed-loop trajectory. The behavior is qualitatively very similar to the norm of the solution depicted in Figure~\ref{fig:MPC RKV}. Moreover, as a consequence of the established relaxed Lyapunov inequality (inferred from the imposed cost controllability in the proof of Proposition~\ref{prop:as3}) 
	of the original dynamics, the value function $V_N$ is a Lyapunov function for the nominal closed loop, such that we observe a strict decrease over time. This is not the case for the eDMD-based MPC, for which we only proved \emph{practical} asymptotic stability of the origin in Theorem~\ref{thm:main}. To this end, $V_N^\varepsilon$ was shown to be a Lyapunov function for the surrogate system only, compare Propositions~\ref{prop:as3} and~\ref{prop:link_costcont}. Correspondingly, $V_N(x_{\mu_N^{\varepsilon}}(\cdot;\hat{x}))$ only decreases outside of a neighboorhood of the origin. 
	\begin{figure}[htb]
		\centering
		\includegraphics[width=.55\linewidth]{Images/V_Nlambda025vanderpol.png}
		\caption{Optimal value function along the closed-loop corresponding to \eqref{eq:vanderPol} for nominal MPC~(black) and eDMD-based MPC (gray) for horizons $N = 30$ (solid) and $N = 50$ (dashed) and $\lambda = 0.25$.}
		\label{fig:VN vanderpol}
	\end{figure}
	
	
	\subsection{Simple pendulum}
	The second example we consider is the simple pendulum 
	\begin{align} \label{eq:pendulum}
	\dot{x}(t) = \begin{pmatrix}
	\dot x_1(t) \\ \dot x_2(t)
	\end{pmatrix} = \begin{pmatrix}
	x_2(t) \\ 0.01 x_2 - \sin(x_1) + u
	\end{pmatrix}
	\end{align}
	with angular displacement $x_1\in \mathbb{R}$ and angular velocity $x_2\in \mathbb{R}$. This system was also explored in the Lyapunov-based data-driven MPC approach of~\cite{NaraSon23}.
	Again, we utilize the RK45 method to obtain a discrete dynamics of type~\eqref{eq:RKV discrete}
	% \begin{align}\label{eq:RKV discrete pendulum}
	%     x_u(k+1;\hat{x}) = f(x_u(k;\hat{x}),u(k)), \qquad x_u(0;\hat{x}) = \hat{x}
	% \end{align} 
	serving as the ground truth. For the approximation of the Koopman operator, the same set $\mathbb{X}$, the same observables, and the same number of training data points are used as in Subsection~\ref{subsec:vanderpol} for the van-der-Pol oscillator. 
	Again, we consider the optimal control problem with quadratic costs $J_N(\hat{x},u) := \sum_{k=0}^{N - 1} \|x_u(k;\hat{x})\|_2^2 + \lambda\|u(k)\|_2^2$ subject to the system dynamics, % \eqref{eq:RKV discrete pendulum}, 
	the control constraints $-5 \leq u(k) \leq 5$ for $k \in [0:N-1]$, and the state constraints $x(k)\in \bX$ for $k \in [0:N]$.
	\begin{figure}[!h]
		\centering
		%\includegraphics[width=.47\linewidth]{Images/pendulum_phaseportrait.png} \\[-.7em]
		\includegraphics[width=.47\linewidth]{Images/lambda025pendulum.png}
		\includegraphics[width=.48\linewidth]{Images/lambda005pendulum.png}
		\caption{Norm of closed-loop solution of \eqref{eq:pendulum} for nominal MPC (black) and eDMD-based~MPC (gray) for horizons $N = 30$ (solid) and $N = 50$ (dashed) and penalization parameters $\lambda = 0.05$~(left) and $\lambda = 0.25$ (right).}
		\label{fig:pendulum}
	\end{figure}

	\noindent In Figure~\ref{fig:pendulum}, we inspect the closed-loop results.
	%The top figure shows that again, all closed-loop trajectories appraoch the origin. 
	The evolution %courses 
	of the optimal value functions are very similar to those in Subsection~\ref{subsec:vanderpol}. For larger prediction horizon $N$ and a smaller penalization parameter $\lambda$ the convergence is faster. For nominal MPC, the optimal value function converges to the precision of the optimal control solver used. The eDMD-based MPC feedback law again leads only to practical asymptotic stability as proven in Theorem~\ref{thm:main}, as the convergence stagnates around $10^{-8}$ for both horizons and control penalizations.
	
	\FloatBarrier
	\section{Conclusions and outlook}
	\label{sec:conclusions}
	
	We proved practical asymptotic stability of data-driven MPC for nonlinear systems using extended Dynamic Mode Decomposition embedded in the Koopman framework. To this end, we provided a novel error bound, which shows that the approximation error vanishes if the lifted state approaches the origin. Further, we showed that cost controllability of the original model implies cost controllability of the data-based surrogate for quadratic stage cost. Last, we provided two numerical examples, i.e., the van der Pol-oscillator and a simple pendulum, to illustrate our findings and, in particular, the practical asymptotic stability of the origin.
	
	Future work will generalize the derived results to more general stage cost, see, e.g., \cite{CoroGrun20} and to economic MPC schemes based on dissipativity conditions, see, e.g., \cite{Grun22} and the references therein. 
	Moreover, future work may also be devoted to include constraints resulting from cost controllability in the construction of the surrogate model. In addition, using trajectory-based data within the construction of the surrogate model might be considered, see, e.g., \cite{SaltJaya22}.
	
	
	
	\bibliographystyle{abbrv}
	\bibliography{references}
	
	\appendix
	
	
	
	\section{Proof of Proposition~\ref{prop:link_costcont}}
	
	We present the proof of Proposition~\ref{prop:link_costcont} for $Q = \mathrm{Id}_{\nx}$ and $R = \mathrm{Id}_{\nc}$ to keep it less technical. Furthermore, we focus on the required changes in comparison to the proof of Proposition~\ref{prop:as3}.
	\begin{proof}
		Analogously to the proof of Proposition~\ref{prop:as3}, one derives
		\begin{equation}\nonumber   
		\ell(\tilde{x}_u(n), u(n)) \leq \ell(x_u(n), u(n)) + 2 e_n \| x_u(n) \| + e_n^2
		\end{equation}
		and 
		\begin{equation}\nonumber
		e_n \leq \varepsilon\bar{c} \left( \sum_{i=1}^n (L_f + \varepsilon\bar{c})^{i-1} \big(\| x_u(n-i) \|+ \|u(n-i)\| \big) \right)
		\end{equation}
		where {$\bar c :=\max\{L_\Psi,\Delta t\tilde c\}$ with $\tilde c$ from Inequality~\eqref{eq:dynamics_bound} of Proposition~\ref{prop:generatorbound}.}
		Combining both inequalities and using $\| x_u(k) \|^2 + \|u(k)\|^2 = \ell(x_u(k),u(k))$, $k \in [0:N-1]$, yields for every $n\in [1:N-1]$ %$n \in [1:N]$
		\begin{align*}
		& \ell(\tilde{x}_u(n), u(n)) \\& \leq \ell(x_u(n),u(n)) + \varepsilon^2 \bar{c}^2(L_f + \varepsilon \bar{c})^{2(n-1)} \sum_{i=0}^{n-1} \ell(x_u(i),u(i)) 
		\\[-.8em]& \qquad  + 2 \varepsilon\bar{c} (L_f + \varepsilon)^{n-1} \ell(x_u(n),u(n)) \sum_{i=0}^{n-1} \ell(x_u(i),u(i)) \\%\| x_u(i) \| \| x_u(n) \|  \\
		& \leq \ell(x_u(n),u(n)) + 2\varepsilon^2\bar{c}^2 (L_f + \varepsilon \bar{c})^{2(n-1)} B_{n-1} 
		\\&\qquad \qquad + 2 \varepsilon\bar{c} (L_f + \varepsilon)^{n-1} \sqrt{B_{n-1}} \sqrt{B_n}. 
		\end{align*}
		Summing up these inequalities for $n\in [1:N-1]$ and using that the first summand in $\tilde{J}_N(\hat{x},u)$ and $V_N(\hat{x})$ coincides, we get %$n \in [1:N]$ 
		\begin{align*}
		&\tilde{V}_N(\hat{x}) \leq \tilde{J}_N(\hat{x},u) 
		\\&\leq V_N(\hat{x}) + \varepsilon\bar{c} \sum_{n=1}^{N-1} (L_f + \varepsilon \bar{c})^{n} \left( \varepsilon \bar{c} (L_f + \varepsilon \bar{c})^{n-1} B_{n-1} + 2 B_n \right).
		\end{align*}
		%\textcolor{red}{In the last estimate we used that $u$ is the minimizer of $J_N(\hat{x},\cdot)$ such .}
		Hence, the remaining argumentation remains unchanged.
	\end{proof}
	
	
	
\end{document}

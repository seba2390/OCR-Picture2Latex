\section{Experiments}
\label{sec:exps}
 % Present it in a mathematical way
 %\ylcomment{Until 01/21 18:57 pm , removing duplicated or verbose content/sentences to here.}
 \subsection{Data Set Description}
 \label{sec:data_desc}

 We evaluated our method with three data sets: Ubuntu Dialog Corpus (UDC), MSDialog, and AliMe  data consisting of a set of %internal commercial Chinese 
 customer service conversations in Chinese from Alibaba.
% \begin{table*}[]
% 	\footnotesize
% 	\centering
% 	\caption{The statistics of data sets used in experiments. \ylcomment{Will update this table later.}}
% 	\vspace{-0.1in}
% 	\label{tab:exp_data_stat_train_valid_test_1}
% 	\begin{tabular}{l||l|l|l|l|l|l|l|l|l}
% 		\hline \hline
% 		Data                               & \multicolumn{3}{c|}{UDC} & \multicolumn{3}{c|}{MSDialog} &
% 		\multicolumn{3}{c}{AliMe}\\ \hline
% 		Items  & Train & Valid & Test & Train & Valid & Test & Train & Valid & Test    \\ \hline
% 		\# Context-response pairs          & 1,000,000       & 500,000       & 500,000       & 171,950   & 36,820  & 34,900 & 51,000 & 6,000 & 6,000 \\ \hline
% 		\# Candidates per context          & 2               & 10            & 10            & 10        & 10      & 10  & 15 & 15 & 15   \\ \hline
% 		\# Positive candidates per context & 1               & 1             & 1             & 1         & 1       & 1  & 2.9 & 2.8 & 2.9     \\ \hline
% 		Min \# turns per context           & 1               & 2             & 1  & 3  & 3 & 3 & 2 & 2 & 2      \\ \hline
% 		Max \# turns per context           & 19              & 19            & 19            & 12 & 12 & 12 & 3 & 3 & 3 \\ \hline
% 		Avg \# turns per context           & 10.1           & 10.1         & 10.1         & 6.0      & 5.9    & 5.4 & 2.4 & 2.1 & 2.2    \\ \hline
% 		%Median \# turns per context        & 8               & 8             & 8             & 5         & 5       & 4    & 2 & 2 & 2   \\ \hline
% 		Avg \# words per context           & 116.0          & 115.6        & 115.9        & 569.0    & 549.2  & 480.4  & 38.3 & 35.3 & 34.2\\ \hline
% 		Avg \# words per utterance         & 22.1           & 22.1         & 22.1         & 105.0    & 106.2  & 104.3 & 4.9 & 4.7 & 4.6 \\ \hline  \hline
% 		%Median \# words per context        & 95              & 94            & 94            & 430       & 418     & 364 & 34 & 32 & 33    \\ \hline
% 		%Median \# words per utterance      & 19              & 19            & 19            & 85        & 89      & 86  & 3 & 3 & 3    \\ \hline \hline
% 	\end{tabular}
% \end{table*}

%  \begin{table*}[]
% 	\footnotesize
% 	\centering
% 	\caption{The statistics of data sets used in experiments.}
% 	\vspace{-0.1in}
% 	\label{tab:exp_data_stat_train_valid_test}
% 	\begin{tabular}{l||l|l|l|l|l|l|l|l|l}
% 		\hline \hline
% 		Data                               & \multicolumn{3}{c|}{UDC}      & \multicolumn{3}{c|}{MSDialog} & \multicolumn{3}{c}{AliMe} \\ \hline
% 		Items                              & Train     & Valid   & Test    & Train     & Valid   & Test    & Train    & Valid  & Test   \\ \hline
% 		\# Context-response pairs          & 1,000,000 & 500,000 & 500,000 & 173,680   & 37,210  & 35,110  & 51,000   & 6,000  & 6,000  \\ \hline
% 		\# Candidates per context          & 2         & 10      & 10      & 10        & 10      & 10      & 15       & 15     & 15     \\ \hline
% 		\# Positive candidates per context & 1         & 1       & 1       & 1         & 1       & 1       & 2.9      & 2.8    & 2.9    \\ \hline
% 		Min \# turns per context           & 1         & 2       & 1       & 2         & 2       & 2       & 2        & 2      & 2      \\ \hline
% 		Max \# turns per context           & 19        & 19      & 19      & 11        & 11      & 11      & 3        & 3      & 3      \\ \hline
% 		Avg \# turns per context           & 10.1      & 10.1    & 10.1    & 5.0       & 4.9     & 4.4     & 2.4      & 2.1    & 2.2    \\ \hline
% 		Avg \# words per context           & 116.0     & 115.6   & 115.9   & 271.4     & 263.2   & 227.4   & 38.3     & 35.3   & 34.2   \\ \hline
% 		Avg \# words per response          & 22.1      & 22.1    & 22.1    & 66.7      & 67.6    & 66.8    & 4.9      & 4.7    & 4.6    \\ \hline \hline
% 	\end{tabular}
% \end{table*}
 \begin{table}[]
	\footnotesize
	%\scriptsize
	\centering
	\caption{The statistics of experimental datasets, where C denotes context and R denotes response. \# Cand. per C denotes the number of candidate responses per context.}
	\vspace{-0.1in}
	\label{tab:exp_data_stat_train_valid_test}
	\begin{tabular}{l | p{0.35cm} p{0.35cm} p{0.35cm} | p{0.35cm} p{0.35cm} p{0.35cm} | p{0.3cm} p{0.3cm} p{0.3cm}}
		\hline \hline
		Data                               & \multicolumn{3}{c|}{UDC}      & \multicolumn{3}{c|}{MSDialog} & \multicolumn{3}{c}{AliMe} \\ \hline
		Items                              & Train     & Valid   & Test    & Train     & Valid   & Test    & Train    & Valid  & Test   \\ \hline
		\# C-R pairs          & 1000k & 500k & 500k & 173k   & 37k  & 35k  & 51k   & 6k  & 6k  \\ \hline
		\# Cand. per C          & 2         & 10      & 10      & 10        & 10      & 10      & 15       & 15     & 15     \\ \hline
		\# + Cand. per C & 1         & 1       & 1       & 1         & 1       & 1       & 2.9      & 2.8    & 2.9    \\ \hline
		Min \# turns per C           & 1         & 2       & 1       & 2         & 2       & 2       & 2        & 2      & 2      \\ \hline
		Max \# turns per C           & 19        & 19      & 19      & 11        & 11      & 11      & 3        & 3      & 3      \\ \hline
		Avg \# turns per C           & 10.1      & 10.1    & 10.1    & 5.0       & 4.9     & 4.4     & 2.4      & 2.1    & 2.2    \\ \hline
		Avg \# words per C           & 116     & 116   & 116   & 271     & 263   & 227   & 38     & 35   & 34   \\ \hline
		Avg \# words per R          & 22.1      & 22.1    & 22.1    & 66.7      & 67.6    & 66.8    & 4.9      & 4.7    & 4.6    \\ \hline \hline
	\end{tabular}
\end{table}

\subsubsection{\textbf{Ubuntu Dialog Corpus}} The Ubuntu Dialog Corpus (UDC) \cite{DBLP:journals/corr/LowePSP15} contains multi-turn technical support conversation data collected from the chat logs of the Freenode Internet Relay Chat (IRC) network. We used the data copy shared by Xu et al.\cite{DBLP:journals/corr/XuLWSW16}, in which numbers, urls and paths are replaced by special placeholders. It is also used in several previous related works \cite{DBLP:conf/acl/WuWXZL17}\footnote{The data can be downloaded from \url{https://www.dropbox.com/s/2fdn26rj6h9bpvl/ubuntu\%20data.zip?dl=0}}. It consists of $1$ million context-response pairs for training, $0.5$ million pairs for validation and  $0.5$ million pairs for testing. The statistics of this data is shown in Table \ref{tab:exp_data_stat_train_valid_test}. The positive response candidates in this data come form the true responses by human and negative response candidates are randomly sampled. %In average, there are around $10$ turns in the dialog context and $22$ words in each utterance. 

\subsubsection{\textbf{MSDialog}}
 % Data preprocess, response candidate sampling, data spliting and statistics for train/valid/test data sets of the MSDialog data
  In addition to UDC, we also crawled another technical support conversation data from the Microsoft Answer community, which is a QA forum on topics about a variety of Microsoft products. We firstly crawled $35,536$ dialogs about $76$ different categories of Microsoft products including ``Windows'', ``IE'', ``Office'', ``Skype'', ``Surface'', ``Xbox'', etc. \footnote{Note that some categories are more fine-grained, such as``Outlook\_Calendar'', ``Outlook\_Contacts'', ``Outlook\_Email'', ``Outlook\_Messaging'', etc.} Then we filtered dialogs whose number of turns are out of the range $[3,99]$. After that we split the data into training/validation/testing partitions by time. Specifically, the training data contains $25,019$ dialogs from ``2005-11-12'' to ``2017-08-20''. The validation data contains $4,654$ dialogs from ``2017-08-21'' to ``2017-09-20''. The testing data contains $5,064$ dialogs from ``2017-09-21'' to ``2017-10-04''. 
  
  The next step is to generate the dialog context and response candidates. For each dialog, we assigned ``User'' label to the first participant who proposed the question leading to this information-seeking conversation, and ``Agent'' label to the other participants who provided responses. The ``Agent'' in our data could be Microsoft customer service staff, a Microsoft MVP (Most Valuable Professional) or a user from the Microsoft Answer community. Then for each utterance by the ``User'' $u_i^t$ \footnote{We consider the utterances by the user except the first utterance, since there is no associated dialog context with it. }, we collected the previous $c$ utterances as the dialog context, where $c = \min(t-1,10)$ and $t-1$ is the total number of utterances before $u_i^t$. The true response by the ``Agent'' becomes the positive response candidate. For the negative response candidates, we adopted negative sampling to construct them following previous work \cite{DBLP:conf/aaai/WanLGXPC16,DBLP:journals/corr/LowePSP15,DBLP:conf/acl/WuWXZL17}. For each dialog context, we firstly used the true response as the query to retrieve the top $1,000$ results from the whole response set of agents with BM25. Then we randomly sampled $9$ responses from them to construct the negative response candidates. The statistics of MSDialog data is presented in Table \ref{tab:exp_data_stat_train_valid_test}. For data preprocessing, we performed tokenization and punctuation removal. Then we removed stop words and performed word stemming. For neural models, we also removed words that appear less than $5$ times in the whole corpus. 
  %  The used different QA post collections as source of external knowledge (e.g. Stack Overflow data for MSDialog, AskUbuntu for UDC) have been presented in Table \ref{tab:data_summery}. 
  % with NLTK \footnote{\url{https://www.nltk.org/}} toolkit. 
  
\subsubsection{\textbf{AliMe Data}}
We collected the chat logs between customers and a chatbot AliMe from ``2017-10-01'' to ``2017-10-20'' in Alibaba. %We filter out single turn conversation and focus our study on conversations within 3 turns~\footnote{The majority (around $85\%$) of conversations in the dataset are within 3 turns.}. %We randomly sampled 4200 sessions, and for each session, we concatenate all the utterances to 
The chatbot is built based on a question-to-question matching system~\footnote{
Interested readers can access AliMe Assist through the Taobao App, or the web version via \url{https://consumerservice.taobao.com/online-help}}~\cite{alime-demo}, where for each query, it finds the most similar candidate question in a QA database and return its answer as the reply. It indexes all the questions in our QA database using Lucence\footnote{\url{https://lucene.apache.org/core/}}. For each given query, it uses TF-IDF ranking algorithm to call back candidates. %top-K~\footnote{We set K=15.} most similar candidate questions as candidate `responses'~\footnote{A `response' here is a question in our QA system.}. 
To form our data set, we concatenated utterances within three turns~\footnote{The majority (around $85\%$) of conversations in the data set are within 3 turns.} to form a query, and used the chatbot system to call back top-K ~\footnote{We set K=15.} most similar candidate questions as candidate ``responses''.~\footnote{A ``response'' here is a question in our system.} We then asked a business analyst to annotate the candidate responses, where a ``response'' is labeled as positive if it matches the query, otherwise negative. In all, we have annotated 63,000 context-response pairs, where we use 51,000 as training, 6,000 for testing, and 6,000 for validation shown in Table \ref{tab:exp_data_stat_train_valid_test}. Note that we have included human evaluation in AliMe data. Furthermore, if the confidence score of answering a given user query is low, the system will prompt three top related questions for users to choose. We collected such user click logs as our external data, where we treat the clicked question as positive and the others as negative. We collected 510,000 clicked questions with answers from the click logs in total as the source of external knowledge. %\ylcomment{ToDo: Double check the number $51,000$ and $510,000$ here. Should the ``context-response pairs from the click logs'' here be changed to ``retrieved QA pairs from the click logs ?''}
%\ylcomment{ToDo by MH. The description of data preprocess, response candidate sampling, data spliting and statistics for train/valid/test data of the E-commerce data ...}

 % https://www.tablesgenerator.com/latex_tables
 
 % https://www.tablesgenerator.com/latex_tables
% \begin{table*}[]
% 	\footnotesize
% 	\centering
% 	\caption{Comparison of different models over Ubuntu Dialog Corpus (UDC) and MSDialog data sets. Numbers in bold font mean the result is better compared with the best baseline. $\ddagger$ means statistically significant difference over the best baseline with $p < 0.01$ measured by the Student's paired t-test. \mhcomment{still working on SMN for MS data, will update if have better results.} } %  $**$means statistically significant difference over DMN with $p < 0.01$ measured by the Student's paired t-test.  \ylcomment{To do: statistically significant test for DMN-KD. waiting for the score files on the server.}
% 	\label{tab:exp_res_udc_ms}
% 	\begin{tabular}{l|l|l|l|l|l|l|l|l}
% 		\hline \hline
% 		Data                       & \multicolumn{4}{l|}{UDC (ExtKnowledge-AskUbuntu)} & \multicolumn{4}{l}{MSDialog(ExtKnowledge-StackOverflow)} \\ \hline
% 		Methods                    & MAP        & Recall@5     & Recall@1     & Recall@2     & MAP          & Recall@5       & Recall@1       & Recall@2       \\ \hline \hline
% 		BM25         & 0.6504 & 0.8206   & 0.5138   & 0.6439   & 0.4214    & 0.6092      & 0.2472     & 0.3649     \\ \hline
% 		%QL           & 0.3908 & 0.6521   & 0.1901   & 0.3247   & 0.5186    & 0.8547      & 0.2988     & 0.5044     \\ \hline \hline 
% 		%ARC-I (Hu et al., 2014 \cite{DBLP:conf/nips/HuLLC14} )        & 0.2810 & 0.4887   & 0.0873   & 0.1840   & 0.4275    & 0.7321      & 0.2057     & 0.3928     \\ \hline
% 		ARC-II (Hu et al., 2014 \cite{DBLP:conf/nips/HuLLC14} )       & 0.5451 & 0.8197   & 0.3498   & 0.5349   & 0.4309    & 0.7315      & 0.2157     & 0.3857     \\ \hline
% 		MV-LSTM (Wan et al., 2016 \cite{DBLP:conf/aaai/WanLGXPC16} )      & 0.6918 & 0.8982   & 0.5457   & 0.7005   & 0.5488    & 0.8619      & 0.3375     & 0.5473     \\ \hline
% 		MatchPyramid (Pang et al., 2016 \cite{DBLP:conf/aaai/PangLGXWC16})  & 0.6418 & 0.8324   & 0.4986   & 0.6298   & 0.5041    & 0.7725      & 0.3088     & 0.4791     \\ \hline
% 		aNMM (Yang et al., 2016 \cite{Yang:2016:ARS:2983323.2983818})          & 0.6289 & 0.8343   & 0.4756   & 0.6226   & 0.4582    & 0.7628      & 0.2433     & 0.4235     \\ \hline
% 		Duet (Mitra et al., 2017 \cite{Mitra:2017:LMU:3038912.3052579})          & 0.5692 & 0.8272   & 0.4756   & 0.5592   & 0.5227    & 0.8372      & 0.3063     & 0.5166     \\ \hline
% 		SMN  (Wu et al., 2017 \cite{DBLP:conf/acl/WuWXZL17})           & 0.7327 & 0.9273   & 0.5948   & 0.7523   & 0.5045    & 0.8157      & 0.2898     & 0.4761     \\ \hline
% 		DMN ( Degenerated Model)          & 0.6398 & 0.9143   & 0.4539   & 0.6564   & 0.6119    & 0.9009      & 0.4146     & 0.6255    \\ \hline   \hline 
% 		DMN-KD       & \textbf{0.7716}$^\ddagger$ &	\textbf{0.9364}$^\ddagger$ & \textbf{0.6534}$^\ddagger$	& \textbf{0.7899}$^\ddagger$  & \textbf{0.7008}$^\ddagger$    & \textbf{0.9372}$^\ddagger$   & \textbf{0.5301}$^\ddagger$    & \textbf{0.7407}$^\ddagger$     \\ \hline
% 		%DMN-PRF-Title    & \textbf{0.7682} & \textbf{0.9314}   & \textbf{0.6503}   & \textbf{0.7842}   & \textbf{0.6882}    & \textbf{0.9368}      & \textbf{0.5162}     & \textbf{0.7202}     \\ \hline
% 		DMN-PRF    & \textbf{0.7719}$^\ddagger$ & \textbf{0.9343}$^\ddagger$   & \textbf{0.6552}$^\ddagger$  & \textbf{0.7893}$^\ddagger$   & \textbf{0.6836}$^\ddagger$    & \textbf{0.9413}$^\ddagger$      & \textbf{0.5076}$^\ddagger$     & \textbf{0.7167}$^\ddagger$     \\ \hline  \hline
% 	\end{tabular}
% \end{table*}
 % Only report the best setting of DMN-PRF, which is DMN-PRF-Body
 % Only report the best setting of DMN-KD, which is DMN-KD-Word
 
%\begin{table*}[]
% 	\footnotesize
% 	\centering
% 	\caption{Comparison of different models over Ubuntu Dialog Corpus (UDC), MSDialog, and AliMe data sets. 
% 	Numbers in bold font mean the result is better compared with the best baseline. 
% 	$\ddagger$ means statistically significant difference over the best baseline with $p < 0.01$ measured by the Student's paired t-test.  \ylcomment{The old table for references. I will remove this table later.}}
% 	\vspace{-0.1in}
% 	%\mhcomment{pls double check whether this is ok.} } %  $**$means statistically significant difference over DMN with $p < 0.01$ measured by the Student's paired t-test.  \ylcomment{To do: statistically significant test for DMN-KD. waiting for the score files on the server.}
% 	\label{tab:exp_res_udc_ms_ec_1}
% 	\begin{tabular}{l|l l l l | l l l l | l l l l}
% 		\hline \hline
% 		Data                       & \multicolumn{4}{c|}{UDC } & \multicolumn{4}{c|}{MSDialog}& \multicolumn{4}{c}{AliMe}\\ \hline
% 		Methods                    & MAP        & Recall@5     & Recall@1     & Recall@2     & MAP          & Recall@5       & Recall@1       & Recall@2 & MAP          & Recall@5       & Recall@2       & Recall@1      \\ \hline \hline
% 		BM25         & 0.6504 & 0.8206   & 0.5138   & 0.6439   & 0.4214    & 0.6092      & 0.2472     & 0.3649  &  0.6392 & 0.6407 & 0.4204 & 0.2371       \\ \hline 
% 		%QL           & 0.3908 & 0.6521   & 0.1901   & 0.3247   & 0.5186    & 0.8547      & 0.2988     & 0.5044  & - & - & - & -   \\ \hline \hline 
% 		ARC-II & 0.5451 & 0.8197   & 0.3498   & 0.5349   & 0.4309    & 0.7315      & 0.2157     & 0.3857  &	0.7306	&	0.6595	&	0.3671	&	0.2236   \\  \hline 
% 		MV-LSTM      & 0.6918 & 0.8982   & 0.5457   & 0.7005   & 0.5488    & 0.8619      & 0.3375     & 0.5473  &	0.7734	&	0.7017	&	0.4105	&	0.2480   \\  \hline 
% 		MatchPyramid  & 0.6418 & 0.8324   & 0.4986   & 0.6298   & 0.5041    & 0.7725      & 0.3088     & 0.4791 &	0.8389	&	0.7604	&	0.4778	&	0.3114    \\  \hline 
% 		aNMM    & 0.6289 & 0.8343   & 0.4756   & 0.6226   & 0.4582    & 0.7628      & 0.2433     & 0.4235 &	0.7165	&	0.6575	&	0.3616	&	0.2212    \\  \hline 
% 		Duet    & 0.5692 & 0.8272   & 0.4756   & 0.5592   & 0.5227    & 0.8372      & 0.3063     & 0.5166   &	0.7651	&	0.6870	&	0.4088	&	0.2433  \\  \hline 
% 		SMN    & 0.7327 & 0.9273   & 0.5948   & 0.7523   & 0.5045    & 0.8157      & 0.2898     & 0.4761  &	0.8145	&	0.7271	&	0.4680	&	0.2881   \\  \hline 
% 		DMN (Degenerated)          & 0.7363	& 0.9196 & 0.6056	& 0.7509	& 0.5835	& 0.8751 & 	0.3854 &	0.5865 &   0.7833  &   0.7629  &   0.5012  &   0.3568   \\ \hline   \hline 
% 		DMN-KD       &   \textbf{0.7655}$^\ddagger$ &	\textbf{0.9351}$^\ddagger$ & \textbf{0.6443}$^\ddagger$ & \textbf{0.7841}$^\ddagger$   &	\textbf{0.6839}$^\ddagger$  &	\textbf{0.9301}$^\ddagger$  &	\textbf{0.5166}$^\ddagger$  & 	\textbf{0.7063}$^\ddagger$   & \textbf{0.8323}  &  \textbf{0.7631} & \textbf{0.5122}$^\ddagger$ & \textbf{0.3596}$^\ddagger$   \\ \hline
% 		DMN-PRF    & \textbf{0.7719}$^\ddagger$ & \textbf{0.9343}$^\ddagger$   & \textbf{0.6552}$^\ddagger$  & \textbf{0.7893}$^\ddagger$   & \textbf{0.6836}$^\ddagger$    & \textbf{0.9413}$^\ddagger$      & \textbf{0.5076}$^\ddagger$     & \textbf{0.7167}$^\ddagger$ & \textbf{0.8435}$^\ddagger$ & \textbf{0.7701}$^\ddagger$ & \textbf{0.5323}$^\ddagger$ & \textbf{0.3601}$^\ddagger$     \\ \hline  \hline
% 	\end{tabular}
% \end{table*}

\begin{table*}[]
	\footnotesize
	\centering
	\caption{Comparison of different models over Ubuntu Dialog Corpus (UDC), MSDialog, and AliMe data sets. 
		Numbers in bold font mean the result is better compared with the best baseline. 
		$\ddagger$ means statistically significant difference over the best baseline with $p < 0.05$ measured by the Student's paired t-test.} % \ylcomment{needs score files of SMN on MS\_V2 for sig test}
	\vspace{-0.1in}
	\label{tab:exp_res_udc_ms_ec}
	\begin{tabular}{l|l l l l | l l l l | l l l l}
		\hline \hline
		Data     & \multicolumn{4}{c|}{UDC}                & \multicolumn{4}{c|}{MSDialog}           & \multicolumn{4}{c}{AliMe}              \\ \hline
		Methods  & MAP    & Recall@5 & Recall@1 & Recall@2 & MAP    & Recall@5 & Recall@1 & Recall@2 & MAP    & Recall@5 & Recall@1 & Recall@2 \\ \hline \hline
		BM25     & 0.6504 & 0.8206   & 0.5138   & 0.6439   & 0.4387 & 0.6329   & 0.2626   & 0.3933   & 0.6392 & 0.6407   & 0.2371   & 0.4204   \\ \hline
		BM25-PRF & 0.6620 & 0.8292   & 0.5289   & 0.6554   & 0.4419 & 0.6423   & 0.2652   & 0.3970   & 0.6412 & 0.6510 & 0.2454         &  0.4209        \\ \hline
		ARC-II   & 0.6855 & 0.8978   & 0.5350   & 0.6959   & 0.5398 & 0.8662   & 0.3189   & 0.5413   & 0.7306 & 0.6595   & 0.2236   & 0.3671   \\ \hline
		MV-LSTM  & 0.6611 & 0.8936   & 0.4973   & 0.6733   & 0.5059 & 0.8516   & 0.2768   & 0.5000   & 0.7734 & 0.7017   & 0.2480   & 0.4105   \\ \hline
		DRMM     & 0.6749 & 0.8776   & 0.5287   & 0.6773   & 0.5704 & 0.9003   & 0.3507   & 0.5854   & 0.7165 & 0.6575   & 0.2212   & 0.3616   \\ \hline
		Duet     & 0.5692 & 0.8272   & 0.4756   & 0.5592   & 0.5158 & 0.8481   & 0.2934   & 0.5046   & 0.7651 & 0.6870   & 0.2433   & 0.4088   \\ \hline
		SMN      & 0.7327 & 0.9273   & 0.5948   & 0.7523   &  0.6188 & 0.8374 & 0.4529 & 0.6195 & 0.8145 & 0.7271   & 0.2881   & 0.4680   \\ \hline
		DMN      & 0.7363 & 0.9196   & 0.6056   & 0.7509   & 0.6415 & 0.9155   & 0.4521   & 0.6673   & 0.7833 & 0.7629   & 0.3568   & 0.5012   \\ \hline \hline
		DMN-KD   & \textbf{0.7655}$^\ddagger$ & \textbf{0.9351}$^\ddagger$   & \textbf{0.6443}$^\ddagger$   & \textbf{0.7841}$^\ddagger$   & \textbf{0.6728}$^\ddagger$ & \textbf{0.9304}$^\ddagger$   & \textbf{0.4908}$^\ddagger$   & \textbf{0.7089}$^\ddagger$   & \textbf{0.8323} & \textbf{0.7631}   & \textbf{0.3596}$^\ddagger$   & \textbf{0.5122}$^\ddagger$  \\ \hline
		DMN-PRF  & \textbf{0.7719}$^\ddagger$ & \textbf{0.9343}$^\ddagger$   & \textbf{0.6552}$^\ddagger$   & \textbf{0.7893}$^\ddagger$   & \textbf{0.6792}$^\ddagger$ & \textbf{0.9356}$^\ddagger$   & \textbf{0.5021}$^\ddagger$   & \textbf{0.7122}$^\ddagger$   & \textbf{0.8435}$^\ddagger$ & \textbf{0.7701} $^\ddagger$  & \textbf{0.3601} $^\ddagger$  & \textbf{0.5323} $^\ddagger$  \\ \hline \hline
	\end{tabular}
\end{table*}


% Please add the following required packages to your document preamble:
% \usepackage{multirow}
%\begin{table}[]
%	\footnotesize
%	\centering
%	\caption{Performance comparison over different response types on MSDialog data. \ylcomment{To do: response type based analysis with for DMN-KD.}} 
%	\vspace{-0.1in}
%	\label{tab:result_diff_response_type}
%	\begin{tabular}{l|l|l|l|l|l}
%		\hline \hline
%		Model                    & ResponseType & MAP    & Recall@5 & Recall@1 & Recall@2 \\ \hline \hline
%		\multirow{4}{*}{SMN}     & Question     & 0.5244 & 0.8184   & 0.3225   & 0.4986   \\ \cline{2-6} 
%		& Answer       & 0.4366 & 0.7405   & 0.2178   & 0.4021   \\ \cline{2-6} 
%		& Gratitude    & 0.5027 & 0.7676   & 0.3089   & 0.4789   \\ \cline{2-6} 
%		& Feedback     & 0.6360 & 0.8788   & 0.4545   & 0.6667   \\ \hline
%		%		\multirow{4}{*}{DMN}     & Question     &        &          &          &          \\ \cline{2-6} 
%		%		& Answer       &        &          &          &          \\ \cline{2-6} 
%		%		& Gratitude    &        &          &          &          \\ \cline{2-6} 
%		%		& Feedback     &        &          &          &          \\ \hline
%		\multirow{4}{*}{DMN-KD}  & Question     &        &          &          &          \\ \cline{2-6} 
%		& Answer       &        &          &          &          \\ \cline{2-6} 
%		& Gratitude    &        &          &          &          \\ \cline{2-6} 
%		& Feedback     &        &          &          &          \\ \hline
%		\multirow{4}{*}{DMN-PRF} & Question     & 0.7187 & 0.9459   & 0.5568   & 0.7703   \\ \cline{2-6} 
%		& Answer       & 0.6742 & 0.9319   & 0.4971   & 0.7017   \\ \cline{2-6} 
%		& Gratitude    & 0.6962 & 0.9485   & 0.5179   & 0.7410   \\ \cline{2-6} 
%		& Feedback     & 0.6366 & 0.9697   & 0.3939   & 0.7273   \\ \hline \hline
%	\end{tabular}
%\end{table}

\subsection{Experimental Setup}

\subsubsection{\textbf{Baselines.}}
We consider different types of baselines for comparison, including traditional retrieval models, deep text matching models and the state-of-the-art multi-turn conversation response ranking method as the following:

%\begin{itemize}
 \textbf{BM25.} This method uses the dialog context as the query to retrieve response candidates for response selection. We consider BM25 model \cite{Robertson:1994:SEA:188490.188561} as the retrieval model.

 \textbf{ARC-II.} ARC-II is an interaction focused deep text matching architectures proposed by Hu et al. \cite{DBLP:conf/nips/HuLLC14}, which is built directly on the interaction matrix between the dialog context and response candidates. A CNN is running on the interaction matrix to learn the matching representation score.
 %It could let the two text sequences meet before their own high-level representations mature, while still retaining the space for the individual development of abstraction of each text sequence. 
 % It is essentially the Siamese CNN architecture. 

% \textbf{DSSM.} DSSM \cite{DBLP:conf/cikm/HuangHGDAH13} is neural text matching model proposed from Web search and trained with click-through data. It consists of a word hashing layer, two non-linear feed forward hidden layers and an output layer.
%
% \textbf{CDSSM.} CDSSM \cite{Shen:2014:LSR:2567948.2577348} is a similar neural text matching model with DSSM. It uses CNN to learn low dimensional semantic vectors for the dialog context and response candidate. 
% 
% \ylcomment{To be updated. Since DSSM/CDSSM need large click-through data for effective training, we need to directly use the released models Sent2Vec on MS Web (trained on large click-through dataset) on our test data. Training DSSM/CDSSM on smaller data sets are likely to overfit the data. Or we can also delete these two baselines.}
 
 \textbf{MV-LSTM.} MV-LSTM \cite{DBLP:conf/aaai/WanLGXPC16} is a neural text matching model that matches two sequences with multiple positional representations learned by a Bi-LSTM layer. 
 %Then it models the interactions between a pair of text sequences from different positions. The matching score is finally produced by aggregating interactions through k-Max pooling and a multi-layer perceptron.

% \textbf{MatchPyramid.} MatchPyramid \cite{DBLP:conf/aaai/PangLGXWC16} firstly constructs a word level interaction similarity matrix of two text sequences to capture the basic word level matching signals and then applies a CNN on this matrix to learn representations of matching patterns. 
 
 %Dynamic pooling strategy is used to deal with the text length variability.
 \textbf{DRMM.} DRMM \cite{Guo:2016:DRM:2983323.2983769} is a deep relevance matching model for ad-hoc retrieval. We implemented a variant of DRMM for short text matching. Specifically, the matching histogram is replaced by a top-k max pooling layer and the remaining part is the same with the original model.
 
 \textbf{Duet.} Duet \cite{Mitra:2017:LMU:3038912.3052579} is the state-of-the-art deep text matching model that jointly learns local lexical matching and global semantic matching between the two text sequences. 

% \textbf{DL2R.} Deep Learning to Respond (DL2R) \cite{DBLP:conf/sigir/YanSW16} is a multi-turn conversation response ranking method, which enhances the current utterance by adding its contexts. Then the model uses a BiLSTM layer to propagate information across words; a CNN layer further captures patterns of adjacent words. Then a matching layer combines the information in each individual sentence.

 \textbf{SMN.} Sequential Matching Network (SMN) \cite{DBLP:conf/acl/WuWXZL17} is the state-of-the-art deep neural architecture for multi-turn conversation response selection. It matches a response candidate with each utterance in the context on multiple levels of granularity and then adopts a CNN network to distill matching features. We used the TensorFlow \footnote{\url{https://www.tensorflow.org/}} implementation of SMN shared by authors \cite{DBLP:conf/acl/WuWXZL17} \footnote{The reported SMN results with the code from authors are on the raw data sets of UDC and MSDialog without any over sampling of negative training data.}.
 % The final matching score is aggregated from the hidden states of a RNN layer on the output of the CNN network. 
%\end{itemize}

We also consider a degenerated version of our model, denoted as \textbf{DMN}, where we do not incorporate external knowledge via pseudo-relevance feedback or QA correspondence knowledge distillation. Finally, we consider a baseline \textbf{BM25-PRF}, where we incorporate external knowledge into BM25 by matching conversation context with the expanded responses as in Section \ref{sec:response_expansion} using BM25 model.
%With the comparison of DMN with DMN-PRF and DMN-KD, we can see whether external knowledge helps improve the ranking performance of response selection in conversations. 

%\ylcomment{Note that we combine DMN with KD and PRF separately because we want to isolate different proposed method for controlled experiments and clear comparison.}

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% Final version results on 01/24/2018
%\begin{table*}[]
%	\footnotesize
%	\centering
%	\caption{Evaluation results of model ablation. ``TB\ref{tab:exp_res_udc_ms_ec}'' means the setting is the same with the results in Table \ref{tab:exp_res_udc_ms_ec}. For DMN-KD, the model is the same with DMN if we remove M3.}
%	\vspace{-0.1in}
%	\label{tab:model_ablation_results}
%	\begin{tabular}{l|l|l|l|l|l|l|l|l|l}
%		\hline \hline
%		& Data            & \multicolumn{4}{c|}{UDC} & \multicolumn{4}{c}{MSDialog} \\ \hline
%		Model                    & Change          & MAP    & Recall@5 & Recall@1 & Recall@2 & MAP       & Recall@5   & Recall@1   & Recall@2   \\ \hline \hline
%		\multirow{5}{*}{DMN-PRF} & Only M1         & 0.7599 & 0.9294   & 0.6385   & 0.7761   & 0.5872    & 0.8813     & 0.3868     & 0.5969     \\ \cline{2-10} 
%		& Only M2         & 0.7253 & 0.9271   & 0.5836   & 0.7440   & 0.5042    & 0.8415     & 0.2761     & 0.4956     \\ \cline{2-10} 
%		& Inter-Dot (TB\ref{tab:exp_res_udc_ms_ec}) & \textbf{0.7719} & \textbf{0.9343}   & \textbf{0.6552}   & \textbf{0.7893}   & \textbf{0.6836}    & \textbf{0.9413}     & 0.5076     & \textbf{0.7167}     \\ \cline{2-10} 
%		& Inter-Cosine    & 0.7507 & 0.9260   & 0.6248   & 0.7675    & 0.6819    & 0.9265     & \textbf{0.5104}     & 0.7110     \\ \cline{2-10} 
%		& Inter-Bilinear  & 0.7228 & 0.9199   & 0.5829   & 0.7401   & 0.4887    & 0.8243     & 0.2661     & 0.4661     \\ \hline
%		\multirow{9}{*}{DMN-KD}  & Only M1         & 0.7449 & 0.9247   & 0.6167   & 0.7612   & 0.5094    & 0.8172     & 0.2954     & 0.4951     \\ \cline{2-10} 
%		& Only M2         & 0.7052 & 0.9203   & 0.5538   & 0.7260   & 0.4947    & 0.8433     & 0.2607     & 0.4848     \\ \cline{2-10} 
%		& Only M3         & 0.3887 & 0.6017   & 0.2015   & 0.3268   & 0.3742    & 0.6785     & 0.1587     & 0.3049     \\ \cline{2-10} 
%		& M1+M2 (DMN)     & 0.6398 & 0.9143   & 0.4539   & 0.6564   & 0.6119    & 0.9009     & 0.4146     & 0.6255     \\ \cline{2-10} 
%		& M1+M3           & 0.7442 & 0.9251   & 0.6149   & 0.7612   & 0.6830    & 0.9203     & 0.5140     & 0.7135     \\ \cline{2-10} 
%		& M2+M3           & 0.7077 & 0.9198   & 0.5586   & 0.7263   & 0.4770    & 0.7997     & 0.2567     & 0.4467     \\ \cline{2-10} 
%		& Inter-Dot (TB\ref{tab:exp_res_udc_ms_ec}) & \textbf{0.7716} &	\textbf{0.9364} & \textbf{0.6534}	& \textbf{0.7899}  & \textbf{0.7008}    & \textbf{0.9372}     & \textbf{0.5301}     & \textbf{0.7407}     \\ \cline{2-10} 
%		& Inter-Cosine    & 0.7156 & 0.9121   & 0.5770   & 0.7268   & 0.6830    & 0.9203     & 0.5140     & 0.7135     \\ \cline{2-10} 
%		& Inter-Bilinear  & 0.7061 & 0.9135   & 0.5590   & 0.7225   & 0.4770    & 0.7997     & 0.2567     & 0.4467     \\ \hline \hline
%	\end{tabular}
%\end{table*}

\subsubsection{\textbf{Evaluation Methodology}.}
For the evaluation metrics, we adopted mean average precision (MAP), Recall@1, Recall@2, and Recall@5 following previous related works \cite{DBLP:conf/acl/WuWXZL17,DBLP:journals/corr/LowePSP15}. For UDC and MSDialog,  MAP is equivalent to the mean reciprocal rank (MRR) since there is only one positive response candidate per dialog context. For AliMe data, each dialog context could have more than one positive response candidates.

\subsubsection{\textbf{ Parameter Settings}.} 
All models were implemented with TensorFlow and MatchZoo\footnote{\url{https://github.com/faneshion/MatchZoo}} toolkit. Hyper-parameters are tuned with the validation data. For the hyper-parameter settings of DMN-KD and DMN-PRF models, we set the window size of the convolution and pooling kernels as $(3,3)$. The number of convolution kernels is $8$ for UDC and $2$ for MSDialog. The dimension of the hidden states of BiGRU layer is set as $200$ for UDC  and $100$ for MSDialog . The dropout rate is set as $0.3$ for UDC  and $0.6$ for MSDialog . All models are trained on a single Nvidia Titan X GPU by stochastic gradient descent with Adam\cite{DBLP:journals/corr/KingmaB14} algorithm. The initial learning rate is $0.001$. The parameters of Adam, $\beta_1$ and $\beta_2$ are $0.9$ and $0.999$ respectively. The batch size is $200$ for UDC and $50$ for MSDialog. The maximum utterance length is $50$ for UDC and $90$ for MSDialog. The maximum conversation context length is set as $10$ following previous work \cite{DBLP:conf/acl/WuWXZL17}. We padded zeros if the number of utterances in a context is less than $10$. Otherwise the most recent $10$ utterances will be kept. For DMN-PRF, we retrieved top $10$ QA posts and extracted $10$ terms as response expansion terms. For DMN-KD, we retrieved top $10$ question posts with accepted answers. For the word embeddings used in our experiments, we trained word embeddings with the Word2Vec tool \cite{DBLP:conf/nips/MikolovSCCD13} with the Skip-gram model using our training data. The max skip length between words and the number of negative examples is set as $5$ and $10$ respectively. The dimension of word vectors is $200$. Word embeddings will be initialized by these pre-trained word vectors and updated during the training process.

% The number of convolution/pooling layers is set as $1$ as adding more layers would lead to over-fitting on our training data. 

%\ylcomment{Revise and double check the camera ready version to here until 18:16pm on 04/25/2018.}
%\subsubsection{\textbf{ Word Embeddings}.}
\subsection{Evaluation Results}
\subsubsection{\textbf{Performance Comparison on UDC and MSDialog}}
% https://www.tablesgenerator.com/latex_tables
%\begin{table*}[]
%	\centering
%	\caption{Comparison of different models over Ubuntu Dialog Corpus (UDC) and MSDialog data sets.\ylcomment{will add significance test later. We can add a note that the reported SMN results from the shared code of the authors on UDC and MSDialog without any over sampling negative training data.}\mhcomment{still working on SMN for MS data, will update if have better results.}}
%	\label{tab:exp_res}
%	\begin{tabular}{l|l|l|l|l|l|l|l|l}
%		\hline \hline
%		Data                       & \multicolumn{4}{l|}{UDC (ExtKnowledge-AskUbuntu)} & \multicolumn{4}{l}{MSDialog(ExtKnowledge-StackOverflow)} \\ \hline
%		Methods                    & MAP        & Recall@5     & Recall@1     & Recall@2     & MAP          & Recall@5       & Recall@1       & Recall@2       \\ \hline \hline
%		%TF-IDF                     &            &              &              &              &              &                &                &                \\ \hline
%		BM25                       & 0.6343     & 0.7505       & 0.5153       & 0.6363       & 0.4304       & 0.6186         & 0.2572         & 0.3785         \\ \hline
%		QL                         & 0.4518     & 0.6921       & 0.2663       & 0.3981       & 0.5406       & 0.8431         & 0.3384         & 0.5229         \\ \hline \hline
%		ARC-I (Hu et al., 2014 \cite{DBLP:conf/nips/HuLLC14} )                & 0.2810     & 0.4887       & 0.0873       & 0.1840       & 0.4275       & 0.7321         & 0.2057         & 0.3928         \\ \hline
%		ARC-II (Hu et al., 2014 \cite{DBLP:conf/nips/HuLLC14} )              & 0.5451     & 0.8197       & 0.3498       & 0.5349       & 0.4309       & 0.7315         & 0.2157         & 0.3857         \\ \hline
%		%DSSM  (et al. cite)               & 0.2919     & 0.4999       & 0.0990       & 0.2003       & 0.2857       & 0.5201         & 0.0991         & 0.1957         \\ \hline
%		%CDSSM  (et al. cite)             & 0.2934     & 0.4993       & 0.1002       & 0.1975       & 0.2951       & 0.5023         & 0.1069         & 0.2040         \\ \hline
%		MV-LSTM (Wan et al., 2016 \cite{DBLP:conf/aaai/WanLGXPC16} )             & 0.6918     & 0.8982       & 0.5457       & 0.7005       & 0.5488       & 0.8619         & 0.3375         & 0.5473         \\ \hline
%		MatchPyramid (Pang et al., 2016 \cite{DBLP:conf/aaai/PangLGXWC16})    & 0.6418     & 0.8324       & 0.4986       & 0.6298       & 0.5041       & 0.7725         & 0.3088         & 0.4791         \\ \hline
%		aNMM (Yang et al., 2016 \cite{Yang:2016:ARS:2983323.2983818})     & 0.6289     & 0.8343       & 0.4756       & 0.6226       & 0.4582       & 0.7628         & 0.2433         & 0.4235         \\ \hline
%		Duet (Mitra et al., 2017 \cite{Mitra:2017:LMU:3038912.3052579})            & 0.5692     & 0.8272       & 0.4756       & 0.5592       & 0.5227       & 0.8372         & 0.3063         & 0.5166         \\ \hline
%		%DL2R  (Yan et al. cite) &            & 0.9440       & 0.6260       & 0.7830       &              &                &                &                \\ \hline
%		SMN  (Wu et al., 2017 \cite{DBLP:conf/acl/WuWXZL17})   &  0.7327	&	0.9273	&	0.5948	& 0.7523	    & 0.5045 & 0.8157 & 0.2898 & 0.4761 \\ \hline \hline
%		DMN                        & 0.6398     & 0.9143       & 0.4539       & 0.6564       & 0.6119       & 0.9009         & 0.4146         & 0.6255         \\ \hline
%		
%		DMN-KD-Word                &            &              &              &              &              &                &                &                \\ \hline
%		DMN-KD-Term                &            &              &              &              &              &                &                &                \\ \hline 
%		DMN-PRF-Title              & 0.7682     & 0.9314       & 0.6503       & 0.7842       & 0.6882       & 0.9368         & 0.5162         & 0.7202         \\ \hline
%		DMN-PRF-Body               & 0.7719     & 0.9343       & 0.6552       & 0.7893       & 0.6836       & 0.9413         & 0.5076         & 0.7167         \\ \hline \hline
%	\end{tabular}
%\end{table*}

We present evaluation results over different methods on UDC and MSDialog in Table \ref{tab:exp_res_udc_ms_ec}. We summarize our observations as follows: (1) DMN-PRF model outperforms all the baseline methods including traditional retrieval models, deep text matching models and the state-of-the-art SMN model for response ranking on both conversation datasets. The results demonstrate that candidate response expansion with pseudo-relevance feedback could improve the ranking performance of responses in conversations. The main difference between DMN-PRF model and SMN model is the information extracted from retrieved feedback QA posts as external knowledge. This indicates the importance of modeling external knowledge with pseudo-relevant feedback beyond the dialog context for response selection. (2) DMN-KD model also outperforms all the baseline methods on MSDialog and UDC. These results show that the extracted QA correspondence matching knowledge could help the model select better responses. Comparing DMN-KD and DMN-PRF, their performances are very close. (3) If we compare the performances of DMN-PRF, DMN-KD with the degenerated model DMN, we can see that incorporating external knowledge via both pseudo-relevance feedback and QA correspondence knowledge distillation could improve the performance of the deep neural networks for response ranking with large margins. For example, the improvement of DMN-PRF against DMN on UDC is $4.83\%$ for MAP, $1.60\%$ for Recall@5, $8.19\%$ for Recall@1, $5.11\%$ for Recall@2 respectively. The differences are statistically significant with $p < 0.05$ measured by the Student's paired t-test. %These results justify that the performance of response selection in information-seeking conversations could be improved by incorporating external knowledge. Pseudo relevance feedback and QA knowledge correspondence distillation from relevant external QA pairs are effective methods to achieve this goal. ; the improvement of DMN-PRF against DMN on MSDialog is $\%17.16$ for MAP, $\%7.57$ for Recall@5, $\%31.71$ for Recall@1, $\%22.20$ for Recall@2 respectively. 

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% Final version results on 01/24/2018
%\begin{table*}[]
%	\footnotesize
%	\centering
%	\caption{Evaluation results of model ablation. ``TB\ref{tab:exp_res_udc_ms_ec}'' means the setting is the same with the results in Table \ref{tab:exp_res_udc_ms_ec}. For DMN-KD, the model is the same with DMN if we remove M3. Numbers in bold font mean the result is better compared with other settings.   \ylcomment{Will update this table later.}}
%	\vspace{-0.1in}
%	\label{tab:model_ablation_results_1}
%	\begin{tabular}{l|l|l|l|l|l|l|l|l|l}
%		\hline \hline
%		& Data            & \multicolumn{4}{c|}{UDC} & \multicolumn{4}{c}{MSDialog} \\ \hline
%		Model                    & Change          & MAP    & Recall@5 & Recall@1 & Recall@2 & MAP       & Recall@5   & Recall@1   & Recall@2   \\ \hline \hline
%		\multirow{5}{*}{DMN-PRF} & Only M1         & 0.7599 & 0.9294   & 0.6385   & 0.7761   & 0.5872 & 0.8813   & 0.3868   & 0.5969   \\ \cline{2-10} 
%		& Only M2         & 0.7253 & 0.9271   & 0.5836   & 0.7440   & 0.5042 & 0.8415   & 0.2761   & 0.4956   \\ \cline{2-10} 
%		& Inter-Dot (TB\ref{tab:exp_res_udc_ms_ec}) & \textbf{0.7719} & \textbf{0.9343}   & \textbf{0.6552}   & \textbf{0.7893}   & \textbf{0.6836} & \textbf{0.9413}   & 0.5076   & \textbf{0.7167}   \\ \cline{2-10} 
%		& Inter-Cosine    & 0.7507 & 0.9260   & 0.6248   & 0.7675   & 0.6819 & 0.9265   & \textbf{0.5104}   & 0.7110   \\ \cline{2-10} 
%		& Inter-Bilinear  & 0.7228 & 0.9199   & 0.5829   & 0.7401   & 0.4887 & 0.8243   & 0.2661   & 0.4661   \\ \hline
%		\multirow{9}{*}{DMN-KD}  & Only M1         & 0.7449 & 0.9247   & 0.6167   & 0.7612   & 0.5094 & 0.8172   & 0.2954   & 0.4951   \\ \cline{2-10} 
%		& Only M2         & 0.7052 & 0.9203   & 0.5538   & 0.7260   & 0.4947 & 0.8433   & 0.2607   & 0.4848   \\ \cline{2-10} 
%		& Only M3         & 0.3887 & 0.6017   & 0.2015   & 0.3268   & 0.3742 & 0.6785   & 0.1587   & 0.3049   \\ \cline{2-10} 
%		& M1+M2 (DMN)     & 0.7363 & 0.9196   & 0.6056   & 0.7509   & 0.5835 & 0.8751   & 0.3854   & 0.5865   \\ \cline{2-10} 
%		& M1+M3           & 0.7442 & 0.9251   & 0.6149   & 0.7612   & 0.5019 & 0.8292   & 0.2834   & 0.4834   \\ \cline{2-10} 
%		& M2+M3           & 0.7077 & 0.9198   & 0.5586   & 0.7263   & 0.4926 & 0.8421   & 0.2613   & 0.4782   \\ \cline{2-10} 
%		& Inter-Dot (TB\ref{tab:exp_res_udc_ms_ec}) & \textbf{0.7655} &	\textbf{0.9351} & \textbf{0.6443} & \textbf{0.7841}   & \textbf{0.6839} & \textbf{0.9301}   & \textbf{0.5166}   & 0.7063   \\ \cline{2-10} 
%		& Inter-Cosine    & 0.7156 & 0.9121   & 0.5770   & 0.7268   & 0.6830 & 0.9203   & 0.5140   & \textbf{0.7135}   \\ \cline{2-10} 
%		& Inter-Bilinear  & 0.7061 & 0.9135   & 0.5590   & 0.7225   & 0.4770 & 0.7997   & 0.2567   & 0.4467   \\ \hline \hline
%	\end{tabular}
%\end{table*}

%https://www.tablesgenerator.com/latex_tables
 
% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{table*}[]
	\footnotesize
	\centering
	\caption{Evaluation results of model ablation. ``TB\ref{tab:exp_res_udc_ms_ec}'' means the setting is the same with the results in Table \ref{tab:exp_res_udc_ms_ec}. For DMN-KD, the model is the same with DMN if we remove M3. Numbers in bold font mean the result is better compared with other settings.}
	\vspace{-0.1in}
	\label{tab:model_ablation_results}
	\begin{tabular}{l|l|l|l|l|l|l|l|l|l}
		\hline \hline
		& Data            & \multicolumn{4}{c|}{UDC}                                              & \multicolumn{4}{c}{MSDialog}                                         \\ \hline
		Model                    & Change          & MAP             & Recall@5        & Recall@1        & Recall@2        & MAP             & Recall@5        & Recall@1        & Recall@2        \\ \hline \hline
		\multirow{5}{*}{DMN-PRF} & Only M1         & 0.7599          & 0.9294          & 0.6385          & 0.7761          & 0.5632          & 0.8509          & 0.3654          & 0.5579          \\ \cline{2-10} 
		& Only M2         & 0.7253          & 0.9271          & 0.5836          & 0.7440          & 0.4996          & 0.8584          & 0.2595          & 0.5021          \\ \cline{2-10} 
		& Inter-Dot (TB5) & \textbf{0.7719} & \textbf{0.9343} & \textbf{0.6552} & \textbf{0.7893} & \textbf{0.6792} & \textbf{0.9356} & \textbf{0.5021} & \textbf{0.7122} \\ \cline{2-10} 
		& Inter-Cosine    & 0.7507          & 0.9260          & 0.6248          & 0.7675          & 0.6729          & 0.9356          & 0.4944          & 0.7027          \\ \cline{2-10} 
		& Inter-Bilinear  & 0.7228          & 0.9199          & 0.5829          & 0.7401          & 0.4923          & 0.8421          & 0.2647          & 0.4744          \\ \hline
		\multirow{9}{*}{DMN-KD}  & Only M1         & 0.7449          & 0.9247          & 0.6167          & 0.7612          & 0.5776          & 0.8673          & 0.3805          & 0.5779          \\ \cline{2-10} 
		& Only M2         & 0.7052          & 0.9203          & 0.5538          & 0.7260          & 0.5100          & 0.8613          & 0.2794          & 0.5011          \\ \cline{2-10} 
		& Only M3         & 0.3887          & 0.6017          & 0.2015          & 0.3268          & 0.3699          & 0.6650          & 0.1585          & 0.2957          \\ \cline{2-10} 
		& M1+M2 (DMN)     & 0.7363          & 0.9196          & 0.6056          & 0.7509          & 0.6415          & 0.9155          & 0.4521          & 0.6673          \\ \cline{2-10} 
		& M1+M3           & 0.7442          & 0.9251          & 0.6149          & 0.7612          & 0.6134          & 0.8860          & 0.4224          & 0.6266          \\ \cline{2-10} 
		& M2+M3           & 0.7077          & 0.9198          & 0.5586          & 0.7263          & 0.5141          & 0.8659          & 0.2885          & 0.5069          \\ \cline{2-10} 
		& Inter-Dot (TB5) & \textbf{0.7655} & \textbf{0.9351} & \textbf{0.6443} & \textbf{0.7841} & 0.6728          & \textbf{0.9304} & 0.4908          & 0.7089          \\ \cline{2-10} 
		& Inter-Cosine    & 0.7156          & 0.9121          & 0.5770          & 0.7268          & \textbf{0.6916} & 0.9249          & \textbf{0.5241} & \textbf{0.7249} \\ \cline{2-10} 
		& Inter-Bilinear  & 0.7061          & 0.9135          & 0.5590          & 0.7225          & 0.4936          & 0.8224          & 0.2679          & 0.4814          \\ \hline \hline
	\end{tabular}
\end{table*}


\subsubsection{\textbf{Performance Comparison on AliMe Data}}

%\begin{table}[h!]
%\footnotesize
%\centering
%\caption{Comparison of different models over a Commercial E-commerce Data. $\ddagger$ means statistically significant difference over the best baseline with $p < 0.01$ measured by the Student's paired t-test.} % ylcomment{Why the results of MP is high on this data. Can try to find the reason.}
%\label{tab:exp_ecomm}
%\begin{tabular}{l|l|l|l|l}
%	\hline \hline
%	Data & \multicolumn{4}{c}{E-commerce data} \\ \hline
%	Methods  & MAP    & Recall@5 & Recall@2  & Recall@1 \\ \hline \hline
%%ARC-I	&	0.7314	&	0.6383	&	0.3733	&	0.2171	\\ \hline
%ARC-II 	&	0.7306	&	0.6595	&	0.3671	&	0.2236	\\ \hline
%MV-LSTM	&	0.7734	&	0.7017	&	0.4105	&	0.2480	\\ \hline
%MatchPyramid	&	0.8389	&	0.7604	&	0.4778	&	0.3114	\\ \hline
%aNMM	&	0.7165	&	0.6575	&	0.3616	&	0.2212	\\ \hline
%Duet	&	0.7651	&	0.6870	&	0.4088	&	0.2433	\\ \hline 
%SMN	&	0.8145	&	0.7271	&	0.4680	&	0.2881	\\\hline
%DMN &   0.7833  &   0.7629  &   0.5012  &   0.3568 \\ \hline \hline
%DMN-KD& 0.8323  &  \textbf{0.7631} & \textbf{0.5122}$^\ddagger$ & \textbf{0.3596}$^\ddagger$ \\ \hline
%DMN-PRF & \textbf{0.8435}$^\ddagger$ & \textbf{0.7701}$^\ddagger$ & \textbf{0.5323}$^\ddagger$ & \textbf{0.3601}$^\ddagger$ \\ \hline \hline
%	\end{tabular}
%\end{table}

%ARC-I (Hu et al., 2014 \cite{DBLP:conf/nips/HuLLC14} )	&	0.7314	&	0.6383	&	0.3733	&	0.2171	\\ \hline
%ARC-II (Hu et al., 2014 \cite{DBLP:conf/nips/HuLLC14} ) 	&	0.7306	&	0.6595	&	0.3671	&	0.2236	\\ \hline
%MV-LSTM (Wan et al., 2016 \cite{DBLP:conf/aaai/WanLGXPC16} )	&	0.7734	&	0.7017	&	0.4105	&	0.2480	\\ \hline
%MatchPyramid (Pang et al., 2016 \cite{DBLP:conf/aaai/PangLGXWC16})	&	0.8389	&	0.7604	&	0.4778	&	0.3114	\\ \hline
%aNMM (Yang et al., 2016 \cite{Yang:2016:ARS:2983323.2983818})     	&	0.7165	&	0.6575	&	0.3616	&	0.2212	\\ \hline
%Duet (Mitra et al., 2017 \cite{Mitra:2017:LMU:3038912.3052579})   	&	0.7651	&	0.6870	&	0.4088	&	0.2433	\\ \hline 
%SMN  (Wu et al., 2017 \cite{DBLP:conf/acl/WuWXZL17})	&	0.8145	&	0.7271	&	0.4680	&	0.2881	\\\hline
%DMN ( Degenerated Model)  &   0.7833  &   0.7629  &   0.5012  &   0.3568 \\ \hline \hline
%DMN-KD              &  & & & \\ \hline
%DMN-PRF & 0.8435 & 0.7701 & 0.5323 & 0.3601 \\ \hline \hline

% \ylcomment{Until 19:52pm 01262018 3rd round revision and checking to here.}
We further compare our models with the competing methods on AliMe data in Table~\ref{tab:exp_res_udc_ms_ec}. We find that: (1) our DMN model has comparable results in terms of MAP when compared with SMN, but has better Recall; (2) DMN-KD shows comparable or better results than all the baseline methods; (3) DMN-PRF significantly outperforms other competing baselines which shows the effectiveness of adding external pseudo-relevance feedback to the task; (4) both DMN-PRF and DMN-KD show better results than DMN, which demonstrates the importance of incorporating external knowledge via both pseudo-relevance feedback and QA correspondence knowledge distillation. 
%our model results ... \ylcomment{To be added by MH.}

 %\vspace{-0.3cm}
\begin{figure}[th]
	\center
	\includegraphics*[viewport=0mm 0mm 160mm 120mm, scale=0.4]{figures/response-type-analysis.pdf}
	%\includegraphics[width=6.8in, height=3.0in]{figures/blstm-cnn}\\
	\vspace{-0.4cm}
	\caption{Performance comparison over different response types on MSDialog data.}\label{fig:result_diff_response_type}
	%\vspace{-0.4cm}
\end{figure}



\begin{figure*}
	\centering
	\begin{subfigure}[b]{0.245\textwidth}
		\includegraphics[width=\textwidth]{figures/convlen-udc-dmnkd}
		\label{fig:convlen-udc-dmnkd}
	\end{subfigure}
	\hspace{-0.1in}
	~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
	%(or a blank line to force the subfigure onto a new line)
	\begin{subfigure}[b]{0.245\textwidth}
		\includegraphics[width=\textwidth]{figures/convlen-udc-dmnprf}
		\label{fig:convlen-udc-dmnprf}
	\end{subfigure}
	\hspace{-0.1in}
	~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
	%(or a blank line to force the subfigure onto a new line)
	\begin{subfigure}[b]{0.245\textwidth}
		\includegraphics[width=\textwidth]{figures/convlen-ms-dmnkd}
		\label{fig:convlen-ms-dmnkd}
	\end{subfigure}
	\hspace{-0.1in}
	\begin{subfigure}[b]{0.245\textwidth}
		\includegraphics[width=\textwidth]{figures/convlen-ms-dmnprf}
		\label{fig:convlen-ms-dmnprf}
	\end{subfigure}
	\vspace{-0.25in}
	\caption{Performance of DMN-KD and DMN-PRF with different choices of conversation context length.}\label{fig:tune_convlen}
\end{figure*}

\subsubsection{\textbf{Performance Comparison over Different Response Types}}
%\ylcomment{to be updated. Update to the comparison of DMN-PRF/DMN-KD over DMN.}
We conduct fine-grained analysis on the performance of different models on different response types. We annotated the user intents in $10,020$ MSDialog utterances using Amazon Mechanical Turk \footnote{\url{https://www.mturk.com/}}. We defined $12$ user intent types including several types related to ``questions'' (original question, follow-up question, information request, clarifying question, and etc.), ``answers'' ( potential answer and further details), ``gratitude'' (expressing thanks, greetings) and ``feedback'' (positive feedback and negative feedback). Then we trained a Random Forest classifier with TF-IDF features and applied this classifier to predict the response candidate types in the testing data of MSDialog.  The dialog contexts were grouped by the type of the true response candidate. Finally we computed the average Recall@1 over different groups. Figure \ref{fig:result_diff_response_type} shows the results. We find that both DMN-KD and DMN-PRF improve the performances of SMN for responses with type ``questions'', ``answers'' and ``gratitude''. This indicates that incorporating external knowledge with PRF or QA correspondence knowledge distillation can help the model select better responses, especially for QA related responses. For responses with type ``Feedback'', DMN-KD and DMN-PRF achieved similar performances comparing with SMN.

% The classification accuracy is $\%78$ over our testing data.

%\ylcomment{For each true response candidate in MSDialog, we firstly classify it into different response types (GG/PA/FD/OQ/IR ...) using the labeled dialog intent data as training data with Chen's classier. Then we compute the average performances over each response type (aggregate dialog by the true response type) of SMN/DMN-KD/DMN-PRF/DMN. This fine-grained analysis could provide more insights and reusable/interesting findings.}
%\ylcomment{Similar to performance analysis on different question types on answer sentence selection.}
%\ylcomment{Refer to Figure 3 on  performance decomposition according to the length of answers and the question types of this paper \url{https://arxiv.org/pdf/1711.05116.pdf}}

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
%\begin{table}[]
%	\footnotesize
%	\centering
%	\caption{Performance comparison over different response types}
%	\vspace{-0.1in}
%	\label{tab:result_diff_response_type}
%	\begin{tabular}{l|l|l|l|l|l}
%		\hline \hline
%		Model                    & ResponseType & MAP    & Recall@5 & Recall@1 & Recall@2 \\ \hline \hline
%		\multirow{3}{*}{SMN}     & Question     & 0.5004 & 0.8051   & 0.2852   & 0.4874   \\ \cline{2-6} 
%		& Answer       & 0.4537 & 0.7490   & 0.2417   & 0.4181   \\ \cline{2-6} 
%		& Gratitude    & 0.4893 & 0.7692   & 0.2827   & 0.4769   \\ \hline
%		\multirow{3}{*}{DMN}     & Question     &        &          &          &          \\ \cline{2-6} 
%		& Answer       &        &          &          &          \\ \cline{2-6} 
%		& Gratitude    &        &          &          &          \\ \hline
%		\multirow{3}{*}{DMN-KD}  & Question     &        &          &          &          \\ \cline{2-6} 
%		& Answer       &        &          &          &          \\ \cline{2-6} 
%		& Gratitude    &        &          &          &          \\ \hline
%		\multirow{3}{*}{DMN-PRF} & Question     & 0.6929 & 0.9458   & 0.5162   & 0.7437   \\ \cline{2-6} 
%		& Answer       & 0.6807 & 0.9351   & 0.5041   & 0.7131   \\ \cline{2-6} 
%		& Gratitude    & 0.6938 & 0.9442   & 0.5192   & 0.7327   \\ \hline \hline
%	\end{tabular}
%\end{table}


\subsection{Model Ablation Analysis}
We investigate the effectiveness of different components of DMN-PRF and DMN-KD by removing them one by one from the original model with UDC and MSDialog data. We also study the effectiveness of different interaction types for $\mathbf{M1}/\mathbf{M2}/\mathbf{M3}$. Table \ref{tab:model_ablation_results} shows the results. We summarize our observations as follows: 1) For the interaction matrices, we find that the performance will drop if we remove any one of $\mathbf{M1}/\mathbf{M2}$ for DMN-PRF or $\mathbf{M1}/\mathbf{M2}/\mathbf{M3}$ for DMN-KD. This indicates that all of word level interaction matching, sequence level interaction matching and external QA correspondence interaction matching are useful for response selection in information-seeking conversation. 2) For interaction types, we can find that dot product is the best setting on both UDC and MSDialog except the results of DMN-KD on MSDialog. The next best one is cosine similarity. Bilinear product is the worst, especially on MSDialog data. This is because bilinear product will introduce a transformation matrix $\mathbf{A}$ as an additional model parameter, leading to higher model complexity. Thus the model is more likely to overfit the training data, especially for the relatively small MSDialog data. 3) If we only leave one channel in the interaction matrices, we can find that $\mathbf{M1}$ is more powerful than $\mathbf{M2}$ for DMN-PRF. For DMN-KD, $\mathbf{M1}$ is also the best one, followed by $\mathbf{M2}$. $\mathbf{M3}$ is the last one, but it stills adds additional matching signals when it is combined with $\mathbf{M1}$ and $\mathbf{M2}$. The matching signals $\mathbf{M3}$ from external collection could be supplementary features to the word embedding based matching matrix $\mathbf{M1}$ and BiGRU representation based matching matrix  $\mathbf{M2}$.

%\ylcomment{The table needs to be updated. Will finish this subsection in the morning of 01/24/2018}
%\ylcomment{Investigate the effect of different components/parts of DMN-PRF and DMN-KD model by removing them one by one.}
%\ylcomment{1 Table, submitted 22jobs on MSDialog data and UDC.}
%\ylcomment{Got 2nd version of model ablation results in the Excel file. Will include this table after training 48 hours.}

%\begin{table*}[]
%	\footnotesize
%	\centering
%	\caption{Evaluation results of model ablation. \ylcomment{The table needs to be updated. Will finish this subsection in the morning of 01/24/2018}}
%	\label{my-label}
%	\begin{tabular}{l|l|l|l|l|l|l|l|l|l}
%		\hline
%		& Data               & \multicolumn{4}{l|}{UDC (EK-Askubuntu)} & \multicolumn{4}{l}{MSDialog (EK-Stackoverflow)} \\ \hline
%		Model                    & Change             & MAP    & Recall@5 & Recall@1 & Recall@2 & MAP       & Recall@5   & Recall@1   & Recall@2   \\ \hline
%		\multirow{5}{*}{DMN-PRF} & Only M1            & 0.7599 & 0.9294   & 0.6385   & 0.7761   & 0.5872    & 0.8813     & 0.3868     & 0.5969     \\ \cline{2-10} 
%		& Only M2            & 0.6796 & 0.9063   & 0.5207   & 0.6943   & 0.5042    & 0.8415     & 0.2761     & 0.4956     \\ \cline{2-10} 
%		& Inter-Dot (TB6)    & 0.7719 & 0.9343   & 0.6552   & 0.7893   & 0.6836    & 0.9413     & 0.5076     & 0.7167     \\ \cline{2-10} 
%		& Inter-Cosine       & 0.7507 & 0.9260   & 0.6248   & 0.7675   & 0.6819    & 0.9265     & 0.5104     & 0.7110     \\ \cline{2-10} 
%		& Inter-Bilinear     & 0.6753 & 0.8992   & 0.5173   & 0.6874   & 0.4887    & 0.8243     & 0.2661     & 0.4661     \\ \hline
%		\multirow{9}{*}{DMN-KD}  & Only M1            & 0.7449 & 0.9247   & 0.6167   & 0.7612   & 0.5019    & 0.8115     & 0.2923     & 0.4754     \\ \cline{2-10} 
%		& Only M2            & 0.6477 & 0.8916   & 0.4766   & 0.6602   & 0.4947    & 0.8433     & 0.2607     & 0.4848     \\ \cline{2-10} 
%		& Only M3            & 0.3887 & 0.6017   & 0.2015   & 0.3268   & 0.3742    & 0.6785     & 0.1587     & 0.3049     \\ \cline{2-10} 
%		& M1+M2              & 0.6398 & 0.9143   & 0.4539   & 0.6564   & 0.6119    & 0.9009     & 0.4146     & 0.6255     \\ \cline{2-10} 
%		& M1+M3              & 0.7442 & 0.9251   & 0.6149   & 0.7612   & 0.5019    & 0.8292     & 0.2834     & 0.4834     \\ \cline{2-10} 
%		& M2+M3              & 0.6470 & 0.8884   & 0.4778   & 0.6565   & 0.4977    & 0.8404     & 0.2676     & 0.4857     \\ \cline{2-10} 
%		& Inter-Dot (TB6)    & 0.7604 & 0.9300   & 0.6393   & 0.7760   & 0.7008    & 0.9372     & 0.5301     & 0.7407     \\ \cline{2-10} 
%		& Inter-Cosine (R13) & 0.4425 & 0.7262   & 0.2356   & 0.3988   & 0.6830    & 0.9203     & 0.5140     & 0.7135     \\ \cline{2-10} 
%		& Inter-Bilinear     & 0.6614 & 0.8919   & 0.4980   & 0.6738   & 0.4770    & 0.7997     & 0.2567     & 0.4467     \\ \hline
%	\end{tabular}
%\end{table*}

%\subsection{Model Results Visualization}
%
%\subsubsection{\textbf{Visualization of Interaction Matching Matrix Weights}}\
%
%\subsubsection{\textbf{Model Learning Curves}}

%\subsection{Further Analysis of DMN-PRF and DMN-KD}
%We further analyze the impact of several model settings on the performances to give some insights on the implementation and application of our proposed methods. Specially, we analyze  the following ...

%$4$ factors: conversation context length, size of retrieved QA posts, number of expanded terms and embedding size.

\subsection{\textbf{Impact of Conversation Context Length}}
%\ylcomment{Experiments with changing ``text1\_max\_utt\_num'' in the model configuration file. Draw figures on the change of performances $\{MAP, Recall@1, Recall@2, Recall@5\}$ of DMN-PRF and DMN-KD as the conversation context length change in $\{2,4,6,8,10,12\}$ for MSDialog and $\{3,6,9,12,15, 18\}$ for UDC.}
%\ylcomment{4 Figures}
We further analyze the impact of the conversation context length on the performances of our proposed DMN-KD and DMN-PRF models. 
%We conduct experiments by observing the change of model performances when we vary the choices of the maximum conversation context length in the model. We present the results in Figure \ref{fig:tune_convlen}. 
As presented in Figure \ref{fig:tune_convlen}, we find the performance first increases and then decreases, with the increase of conversation context length. The reason for these trends is that the context length controls the available previous utterances in the dialog context modeled by DMN-KD and DMN-PRF. If the context length is too small, there would be not enough information for the model to learn the matching patterns between the context and response candidates. However, setting the context length too large will also bring noise into the model results, since the words in utterances a few turns ago could be very different due to the topic changes during conversations. %\ylcomment{Add `` $8$ is a good choice for both data.''}
%\cqcomment{structure of the last sentence}


%\begin{figure*}[!t]
%	%\mbox{
%		%\hspace{-15pt}
%		\centering
%		\subfigure{
%			\label{fig:convlen-udc-dmnkd}
%			\includegraphics*[viewport=8mm 9mm 196mm 144mm, width=0.23\textwidth, height=0.13\textheight]{figures/convlen-udc-dmnkd}}
%		\hspace{-0.05in}
%		\subfigure{
%			\label{fig:convlen-udc-dmnprf}
%			\includegraphics*[viewport=8mm 9mm 196mm 144mm, width=0.23\textwidth, height=0.13\textheight]{figures/convlen-udc-dmnprf}}
%		\hspace{-0.05in}
%		\subfigure{
%			\label{fig:convlen-ms-dmnkd}
%			\includegraphics*[viewport=8mm 9mm 196mm 144mm, width=0.23\textwidth, height=0.13\textheight]{figures/convlen-ms-dmnkd}}
%		\hspace{-0.05in}
%		\subfigure{
%			\label{fig:convlen-ms-dmnprf}
%			\includegraphics*[viewport=8mm 9mm 196mm 144mm, width=0.23\textwidth, height=0.13\textheight]{figures/convlen-ms-dmnprf}}
%	%}
%	\vspace{-0.2in}
%	\caption{Performance of DMN-KD and DMN-PRF with different choices of conversation context length over UDC and MSDialog data.}
%	\label{fig:convlen}
%	%\vspace{-5pt}
%\end{figure*}


%\subsection{\textbf{Impact of Embedding Size}}
%\ylcomment{Will remove this subsection and figure 4 on tuning embedding size if no spaces.}
%%\ylcomment{Train word embeddings with Word2Vec in different dimensions. Then draw figures on the change of performances $\{MAP, Recall@1, Recall@2, Recall@5\}$ of DMN-PRF and DMN-KD as the embedding size change in $\{100, 200, 300, 400 ,500\}$ over UDC and MSDialog.}
%%\ylcomment{4 Figures}
%
%We further investigate the impact of embedding size on the model performances. We vary the embedding size of DMN-KD and DMN-PRF models and observe the change of their performances on UDC and MSDialog. From the results shown in Figure \ref{fig:tune_embed}, we can see that the choice of embedding size has larger impact on MSDialog data, whereas performances of DMN-KD and DMN-PRF are quite stable on UDC as the embedding size changes. The possible reason might be that UDC is much larger than MSDialog. Thus the choice of embedding size on UDC could be more flexible as the word embedding will be updated and further optimized during model training process on UDC. On the other hand, it is more difficult to learn good word embeddings from MSDialog during model training phase due to its relative small size. In general, $200$ or $300$ are good choices for word embedding size on both data sets.
%
%\begin{figure*}
%	\centering
%	\begin{subfigure}[b]{0.245\textwidth}
%		\includegraphics[width=\textwidth]{figures/embed-udc-dmnkd}
%		\label{fig:embed-udc-dmnkd}
%	\end{subfigure}
%	\hspace{-0.1in}
%	~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
%	%(or a blank line to force the subfigure onto a new line)
%	\begin{subfigure}[b]{0.245\textwidth}
%		\includegraphics[width=\textwidth]{figures/embed-udc-dmnprf}
%		\label{fig:embed-udc-dmnprf}
%	\end{subfigure}
%	\hspace{-0.1in}
%	~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
%	%(or a blank line to force the subfigure onto a new line)
%	\begin{subfigure}[b]{0.245\textwidth}
%		\includegraphics[width=\textwidth]{figures/embed-ms-dmnkd}
%		\label{fig:embed-ms-dmnkd}
%	\end{subfigure}
%	\hspace{-0.1in}
%	\begin{subfigure}[b]{0.245\textwidth}
%		\includegraphics[width=\textwidth]{figures/embed-ms-dmnprf}
%		\label{fig:embed-ms-dmnprf}
%	\end{subfigure}
%	\vspace{-0.25in}
%	\caption{Performance of DMN-KD and DMN-PRF with different choices of embedding size over UDC and MSDialog data.}\label{fig:tune_embed}
%\end{figure*}


%\ylcomment{Remove this subsection if there are no spaces.}

%\subsection{\textbf{Impact of Number of Expanded Terms}}
%\ylcomment{Remove this subsection if there is no spaces/time.}

%\ylcomment{This only applies for DMN-PRF model. Fix the number of retrieved QA posts as $10$ and change the number of expanded terms. Draw figures on the change of performances $\{MAP, Recall@1, Recall@2, Recall@5\}$ of DMN-PRF as the number of expanded terms change in $\{5, 10, 15, 25, 30\}$ over UDC and MSDialog.}
%\ylcomment{2 Figures}

%\subsubsection{\textbf{Impact of Size of Retrieved QA Posts}}
%\ylcomment{Retrieve the top 50 QA posts for DMN-PRF and DMN-KD model. Then draw figures on the change of performances $\{MAP, Recall@1, Recall@2, Recall@5\}$ of DMN-PRF and DMN-KD as the size of retrieved QA posts change in $\{10, 20, 30, 40 ,50\}$ over UDC and MSDialog.}

\subsection{Case Study}

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{table}[]
	\footnotesize
	\centering
	\caption{Examples of Top-1 ranked responses by different methods. $y_i^k$  means the label of a response candidate.}
	\vspace{-0.1in}
	\label{tab:case_study}
	\begin{tabular}{p{1.1cm}  | p{0.2cm} | p{6.3cm}}
		\hline  \hline% What is your computer set to for it's global date formatting?
		\multirow{2}{*}{Context} & \multicolumn{2}{p{6.9cm}}{ [User] I open Excel and it automatically formats my dates into American formatting. I have changed and saved the formatting to NZ style. } \\ %\cline{2-4} 
		& \multicolumn{2}{p{6.9cm}}{However everytime I pull the document out of office 365 it reverts back to the American format. How do I stop this ? \quad [Agent] Is it one file  or all files in Excel ? \quad [User] It does seem to be all Excel files. How do I change the global  date format setting ? }     \\  \hline
		Method      & $y_i^k$   & Top-1 Ranked Response        \\ \hline
		SMN     & 0    & Go to Settings -\textgreater System -\textgreater Tablet Mode....Change setting as indicated in the snapshot below.         \\ \hline
		DMN-KD   & 1      & That is a Windows setting.  Go to Control Panel \textgreater Regional settings.  This will change date settings for all applications.   \\ \hline
		DMN-PRF    & 1   & That is a Windows setting.  Go to Control Panel \textgreater Regional settings.  This will change date settings for all applications.\\ \hline \hline
	\end{tabular}
\end{table}

We perform a case study in Table \ref{tab:case_study} on the top ranked responses by different methods including SMN, DMN-KD and DMN-PRF. In this example, both DMN-KD and DMN-PRF produced correct top ranked responses. We checked the retrieved QA posts by the correct response candidate and found that ``\textit{settings, regional, change, windows, separator, format, excel, panel, application}'' are the most frequent terms. Among them ``\textit{excel}'' is especially useful for promoting the rank of the correct response candidate, since this term which is included multiple times by the dialog context does not actually appear in the raw text of the correct response candidate. This gives an example of the effectiveness of incorporating external knowledge from the retrieved QA posts into response candidates.

%\ylcomment{Doing this with one of MSDialog/UDC is enough.}
%
%\ylcomment{Do this with significant test together since both tasks need model prediction and model score files on testing data.}
%
%\ylcomment{Select some ranking examples to show on which cases DMN-PRF/DMN-KD/SMN is better/worse. Show example query dialog context where DMN-PRF/DMN-KD are better than DMN/SMN and explain why. Explain why the incorporated external knowledge in DMN-PRF/DMN-KD could be helpful in this example. Fine-grained/in-depth analysis to provide more insights and interesting findings. Refer to discussion notes with JF and examples in ECIR16 papers/NEUIR17 papers/ CX papers/ Cortana information cards Before\&After examples.}
%
%\ylcomment{Win/Tie/Loss analysis between DMN-PRF/DMN-KD/DMN over SMN. Refer to Table 6 and 7 of this paper \url{http://www.cs.cmu.edu/~cx/papers/word-entity-duet.pdf}}
%
%\ylcomment{Refer to Table 5 of this paper \url{https://arxiv.org/pdf/1506.06714.pdf}}
%
%\ylcomment{1 Table} \ylcomment{Adding more examples is good.}



%\ylcomment{Remove this section if there is no time}
%Hyper-parameter tuning results.
%
%More detailed experimental results.

% The paper should not exceed ten (10) pages in the current ACM two-column conference format (including references and figures). 

%\section{Discussion}
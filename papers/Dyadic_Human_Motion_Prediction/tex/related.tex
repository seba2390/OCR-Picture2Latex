\section{Related Work}

\subsection{Single-actor Motion Prediction} Although early approaches to human motion prediction relied on traditional models, such as Hidden Markov Models~\cite{Brand00}, Gaussian Processes for time-series analysis~\cite{Wang05b}, conditional restricted Boltzmann machine~\cite{Taylor06} and dynamic random forest~\cite{Lehrmann14}, the state-of-the-art in this field is now achieved via deep networks.
As motion forecasting inherently is a sequence-to-sequence prediction task~\cite{Sutskever11,Sutskever14,Bahdanau15,Dutil17,Vaswani17}, much work has focused on encoder-decoder models. This was pioneered by the Encoder-Recurrent-Decoder (ERD) model of~\cite{Fragkiadaki15}, which led to the development of several RNN-based strategies. For example,~\cite{Jain16a} introduces a Structural-RNN (S-RNN) based on a spatio-temporal graph that encapsulates the dependencies among the body joints over time; \cite{Ghosh17} leverages de-noising autoencoders to learn the spatial structure of the human skeleton by randomly removing information about joints during training; \cite{Martinez17b,Chiu19b} use velocities instead of poses; \cite{Gopalakrishnan19} similarly integrates motion derivatives; \cite{Zhou18a} uses an auto-regressive approach for long-term prediction. Unfortunately, these RNN-based methods tend to produce discontinuities at the transition between the last observed pose and the first predicted one.

To address this limitation, several methods have attempted to better model the distribution of valid motions. In this context, \cite{Gui18a} integrates adversarial training to enforce frame-wise geometric plausibility and sequence-wise coherence; \cite{Ruiz19} uses a GAN with several discriminators that operates on input sequences with masked joints and learns to inpaint the missing information; \cite{Cui21} exploits a similar GAN but uses spectral normalization to perform temporal attention; \cite{Wang19h} formulates motion prediction as a generative adversarial imitation learning task to focus on shorter sequences by breaking long ones into small chunks. In contrast to the previous methods that generate a single future prediction, several GAN- and VAE-based methods aim to produce multiple diverse future motion sequences~\cite{Barsoum18,Yan18a,Kundu19,Yuan20,Aliakbarian20,Aliakbarian21,Mao21b}. For example, \cite{Aliakbarian20,Aliakbarian21} achieve this via a conditional variational autoencoder (CVAE); \cite{Mao21b} generates the motion of different body parts sequentially; \cite{Yuan20} proposes a novel sampling strategy to produce diverse samples from a pretrained generative model; \cite{Cao20,Wang21d} generate multiple trajectory and pose predictions conditioned on the scene context. While these methods produce smoother transitions than RNNs, they do not explicitly model the dependencies between the different body joints.

Recently, this has been addressed via graph convolutional networks (GCNs). In particular, \cite{Mao19} encodes the spatio-temporal relationships across the joints via a GCN that adaptively learns the body connectivity; \cite{Lebailly20} also relies on a GCN and processes the past sequence at different lengths; \cite{Lingwei21} proposes to predict the poses first at a coarse level, and then at finer levels using a multi-scale residual GCN; Similarly,~\cite{Li21b} employs a multi-scale GCN that jointly learns action categories and motion dynamics at different granularities.

As an alternative to RNNs, GANs and VAEs, several methods rely on attention-based models, which proved to be effective in machine translation and image caption generation~\cite{Bahdanau15, Xu15, Vaswani17}. In particular, \cite{Tang18c} proposes an attention mechanism to focus on the moving joints of the human body for motion forecasting; \cite{Shu20} uses a similar idea to learn the spatial coherence and temporal evolution of joints via a co-attention mechanism; \cite{Mao20} combines a GCN with an attention module to learn the repetitive motion patterns from the past;  \cite{Mao21a} fuses the predictions from three attention modules that process motion at different levels: full body, body parts, and individual joints; \cite{Gonzalez21} trains a computationally less intensive Transformer~\cite{Vaswani17} to infer the future poses in parallel.

In any event, all the above-mentioned methods tackle the single-actor scenario. As such, and as will be evidenced by our experiments, they are sub-optimal to handle the case of two closely-interacting subjects.

\subsection{Social Interactions in Motion Prediction}
Modeling human-to-human interactions is a long-studied problem, with much focus on the social dynamics occurring in a group of people~\cite{Helbing95}. In particular, much work in this space has been dedicated to the problem of trajectory prediction~\cite{Alahi14,Mehran09,Pellegrini09,Yamaguchi11,Robicquet16}, whose goal is to predict the global motion of people in a group, not their detailed 3D pose. In this context, recent methods have also studied the use of RNNs~\cite{Alahi16,Santaro17a,Deo18,Sun18c,Sun19c}, GANs~\cite{Gupta18,Sadeghian19,Kosaraju19}, graph neural networks~\cite{Huang19b,Casas20,Zhang21}, and attention mechanisms~\cite{Li21c,Li21d,Liu21c,Shafiee21}, but also of reinforcement~\cite{Lee17a} and contrastive~\cite{Liu21d} learning.

Another task that has benefited from modeling social interactions is 3D multi-person pose estimation~\cite{Corona20a,Guo21,Wang20f,Ng20}. However, the scenarios studied in this context typically do not involve closely-interacting subjects, but rather individuals exchanging objects, crossing path, or coexisting in an environment during a short period of time. Therefore, the existing solutions only aim to encode weak constraints arising from such social interactions instead of exploiting strong dependencies as we do here.

To the best of our knowledge,~\cite{Adeli20,Guo21b} are the only works that, as us, target multi-person motion prediction.~\cite{Adeli20} uses a social pooling layer to fuse the features corresponding to the encoded past motion of each subject. However, by relying on either $\textit{max}$, $\textit{average}$ or $\textit{sum}$ pooling of the individuals' features, it only encodes weak dependencies between the subjects and was demonstrated in scenarios where the motions of the individuals are only weakly correlated. By contrast, we focus on the case of two closely-interacting subjects, and introduce an approach that models the subjects' dependencies. Concurrently,~\cite{Guo21b} has also been working on multi-person motion prediction for a lindy hop scenario. However, unlike our method,~\cite{Guo21b} is not agnostic to the roles of the dancers and requires separate pipelines and losses based on the role. In addition to that~\cite{Guo21b} does not exploit relative motion between the interacting people which is an integral part of our model. Since the training code and dataset of this work are not publicly available, we could not compare against them. 

\label{sec:related}


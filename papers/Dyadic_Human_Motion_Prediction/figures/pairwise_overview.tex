\begin{figure*}[t]
	\centering
	\begin{tabular}{c}
		\includegraphics[width=0.68\linewidth]{figures/pairwise_attention.pdf} \\
	\end{tabular}
	\vspace{-3mm}
	\caption[Overview of our 3D motion forecasting model based on self- and pairwise attention]{\textbf{Overview of our 3D motion forecasting model based on self- and pairwise attention.} Our model takes as input the past poses of the primary (skeleton models depicted using green-purple) and past poses of the auxiliary (red-blue) subject relative to the primary one depicted by $\Delta \text{Pose}$ operation. The superscript $1$ is used for the primary subject whereas $2$ represents the interactee. As proposed by~\cite{Mao20}, the self-attention module takes as input the key, query and value vectors of the primary subject. We build on top of this approach by integrating a pairwise module that takes as input the query from one subject and key-value pair from the other subject. This module learns to put higher attention on the sub-sequences in the motion history of the primary subject that are more relevant to the current motion of the interactee. The merge block applies concatenation followed by a convolutional layer. The embeddings from self- and pairwise attention are fed into two separate GCNs with shared weights. The outputs of GCNs are projected to the future pose predictions of the primary subject via the merge block.}
	\label{fig:overview_3dmotion_forecasting}
	\vspace{-3mm}
\end{figure*}
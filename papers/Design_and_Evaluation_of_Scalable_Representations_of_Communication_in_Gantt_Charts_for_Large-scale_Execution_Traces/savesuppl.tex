% Sticking huge amount of text here for possible inclusion in supplemental material




\section{Visual Design}
\label{sec:design}

Taking the lessons learned from our preliminary studies and synthesizing them with expert knowledge about what insights performance analysts are seeking, we worked to produce a set of designs intended to mitigate problems with current communication trace visualizations at large scales. 

\subsection{Design Process}

\textbf{Brainstorming:} The design process began with a brainstorming session, where ten possible visualizations were put to paper with informal drawings. The ideas brainstormed ranged from the straightforward -- like linked views summarizing communication data with histograms -- to the radical -- like a redesign of the Gantt chart itself with the x and y axes marking processes with lines connecting them showing time with a gradient color or opacity. Most brainstormed visualizations were quickly rejected due to their design propagating the same scaling errors as traditional Gantt charts or due to not encoding the critical information sufficiently directly. Ultimately this left us with a "pattern glyph" design which sought to encode the underlying structure of communication lines directly with easy-to-identify symbols.

\note{to self: argue why these variables are important/ where we got them from; maybe in the previous section}
\textbf{Variables and Channels:} After settling on our core design idea, we narrow down what we will be encoding with these designs and how we will be encoding them. After significant consideration, we identify that the underlying structure of the lines showing communication was the most critical element we want to encode, so that becomes our first variable. Following from that, the grouping of a structure of lines was deemed important to distinguish different underlying processes at a glance, as a grouped structure and continuous structure would could have very different domain decompositions. Accordingly, this becomes our second variable. Next, we observed that although stride was not very salient characteristic, participants in pilot studies frequently referenced the angle and offset of lines so we chose to include it as our third variable to reflect it's observed importance in discriminating patterns. Finally, we determined that a structure's position in time would need to be reflected in our glyph, so that becomes our final variable.

Although we considered many potential channels for encoding these variables, we ultimately landed on shape, position on a common scale, position on an unaligned scale, and angle as channels we want to use for encoding our variables. We strongly considered color to encode grouping in multiple different ways, however in keeping with the gestalt principal of similarity there is no way to effectively use color to show that a structure was grouped into multiple smaller sub structures while also showing that the sub-structures themselves were part of the larger structure. Closure was also considered as a channel to indicate the scope of a glyph, but was ultimately dismissed for adding unnecessary visual noise when x-position should prove sufficient.

\subsection{Final Designs and Encoding Rules}
\note{to self: we need to add images demonstrating these encoding rules. The design doc image only shows like one encoding rule. Maybe switch out this overall figure with a comprehensive one?.}

\begin{figure*}
    \centering
    \includegraphics[width=\textwidth]{figures/abstract_designs.png}
    \caption{A breakdown of the new designs . . . \note{fix this figure and change distance to stride}}
    \label{fig:abstract_designs}
\end{figure*}

From the above design process we arrived at the new proposed designs which can be seen in Figure \ref{fig:abstract_designs}. In this figure, we see our first encoding rule: structures are encoded with extensible shapes. We designed shapes for three commonly-occurring communication structures: offset, rings and exchanges. All of these shapes strongly resemble the underlying structures they represent but abstract away any direct encoding of stride, communication time, and connection between processes.

Offsets are the most simple with angled repeating lines forming a rhombus-like shape. Rings are slightly more complicated with the addition of a few lines running perpendicular to the main body of the design. As stride increases in the underlying ring structure, the number of perpendicular lines would increase. To reflect this, more perpendicular lines are added to the ring shape as line angle increases. To reduce visual noise of overlapping lines, the perpendicular lines are cut at the top and bottom of this shape to give the impression of continuation across the parallel lines but without the overlap. Exchanges employ the same design characteristics as rings, but will always be grouped by default resulting in shorter, symmetrical ``x" shapes. 

From a visual design perspective, we opt to render the paths of our lines making up our structure glyph with narrow centers and tapered ends to distinctly show, at a glance, that they are not the real lines. We intend for this to prevent possible confusion because these representations use the same primitives of lines to show communication but have different meaning from those normally used in Gantt charts. The specific style chosen was made to emulate an engineer's pen which would be used in drafting blueprints or making designs. This final design element unfortunately did not make it into the controlled experiment as it was considered too difficult to implement with little expected impact on the outcomes of the experiment.


To represent grouping, we shrink down the glyph associated with the grouped structure shown in Figure \ref{fig:abstract_designs}, duplicate them multiple times and evenly space them along the y-axis. More formally, the encoding rule to show ``grouping" is repetition and alignment on a non-common scale. If there is no repetition, then the structure is continuous.

% This may be nice to include
% Although not pictured here, a gradient can be placed on top of these patterns to represent that they continue past the bounds of the currently rendered area. These designs have the additional benefit of being vertically collapsible or expansible to fill the height of a Gantt chart by removing intermediary ``horizontal lines." The visual structure of each of these figures remains clear when represented with as few as three horizontal lines. This is beneficial because it allows us to represent groups of patterns using the same amount of space as one long pattern, while persevering individual characteristics like distance and structure in a recognizable way.

For our next encoding rule, stride is expressed with the use of angle. The angle of the ``horizontal" lines increases from 15 degrees to 60 degrees. They do not encode the true stride of communication between time steps, but rather hint at the magnitude of distance over which communication is occurring. We include this encoding rule as a direct result of our first preliminary experiment with the idea that our abstract structure can resemble the look of communication lines on a zoomed-in chart.

For our final variable, a structure's temporal range, we encode this approximately. Rather than show the exact range, we place the glyph -- or series of glyphs in the case of a grouped structure -- representing a particular structure on the x-axis in the center of that range. If two structures overlap, they are placed alongside one another. Due to the design of our controlled experiment, we did not evaluate or implement this encoding rule as we only tested artificial charts with two time steps. 

In practice, these primitive abstractions of real communication structures, will be overlayed on top of a Gantt chart when the view is zoomed-out. To reduce visual noise, but keep these glyphs grounded in the context of the underlying chart, the real lines showing program communication will not be drawn at this resolution and the underlying chart will be blurred. Taking a lesson learned from our first preliminary experiment, this will diminish a user's inclination to examine unnecessary or hard to parse background details and enable them to focus on the high level communication structures which can show areas of interest.  


\section{Visual Design}
\label{sec:design}

Taking the lessons learned from our preliminary studies and synthesizing them with expert knowledge about what insights performance analysts are seeking, we worked to produce a set of designs intended to mitigate problems with current communication trace visualizations at large scales. 

\subsection{Design Process}

\textbf{Brainstorming:} The design process began with a brainstorming session, where ten possible visualizations were put to paper with informal drawings. The ideas brainstormed ranged from the straightforward -- like linked views summarizing communication data with histograms -- to the radical -- like a redesign of the Gantt chart itself with the x and y axes marking processes with lines connecting them showing time with a gradient color or opacity. Most brainstormed visualizations were quickly rejected due to their design propagating the same scaling errors as traditional Gantt charts or due to not encoding the critical information sufficiently directly. Ultimately this left us with a "pattern glyph" design which sought to encode the underlying structure of communication lines directly with easy-to-identify symbols.

\note{to self: argue why these variables are important/ where we got them from; maybe in the previous section}
\textbf{Variables and Channels:} After settling on our core design idea, we narrow down what we will be encoding with these designs and how we will be encoding them. After significant consideration, we identify that the underlying structure of the lines showing communication was the most critical element we want to encode, so that becomes our first variable. Following from that, the grouping of a structure of lines was deemed important to distinguish different underlying processes at a glance, as a grouped structure and continuous structure would could have very different domain decompositions. Accordingly, this becomes our second variable. Next, we observed that although stride was not very salient characteristic, participants in pilot studies frequently referenced the angle and offset of lines so we chose to include it as our third variable to reflect it's observed importance in discriminating patterns. Finally, we determined that a structure's position in time would need to be reflected in our glyph, so that becomes our final variable.

Although we considered many potential channels for encoding these variables, we ultimately landed on shape, position on a common scale, position on an unaligned scale, and angle as channels we want to use for encoding our variables. We strongly considered color to encode grouping in multiple different ways, however in keeping with the gestalt principal of similarity there is no way to effectively use color to show that a structure was grouped into multiple smaller sub structures while also showing that the sub-structures themselves were part of the larger structure. Closure was also considered as a channel to indicate the scope of a glyph, but was ultimately dismissed for adding unnecessary visual noise when x-position should prove sufficient.

\subsection{Final Designs and Encoding Rules}
\note{to self: we need to add images demonstrating these encoding rules. The design doc image only shows like one encoding rule. Maybe switch out this overall figure with a comprehensive one?.}

\begin{figure*}
    \centering
    \includegraphics[width=\textwidth]{figures/abstract_designs.png}
    \caption{A breakdown of the new designs . . . \note{fix this figure and change distance to stride}}
    \label{fig:abstract_designs}
\end{figure*}

From the above design process we arrived at the new proposed designs which can be seen in Figure \ref{fig:abstract_designs}. In this figure, we see our first encoding rule: structures are encoded with extensible shapes. We designed shapes for three commonly-occurring communication structures: offset, rings and exchanges. All of these shapes strongly resemble the underlying structures they represent but abstract away any direct encoding of stride, communication time, and connection between processes.

Offsets are the most simple with angled repeating lines forming a rhombus-like shape. Rings are slightly more complicated with the addition of a few lines running perpendicular to the main body of the design. As stride increases in the underlying ring structure, the number of perpendicular lines would increase. To reflect this, more perpendicular lines are added to the ring shape as line angle increases. To reduce visual noise of overlapping lines, the perpendicular lines are cut at the top and bottom of this shape to give the impression of continuation across the parallel lines but without the overlap. Exchanges employ the same design characteristics as rings, but will always be grouped by default resulting in shorter, symmetrical ``x" shapes. 

From a visual design perspective, we opt to render the paths of our lines making up our structure glyph with narrow centers and tapered ends to distinctly show, at a glance, that they are not the real lines. We intend for this to prevent possible confusion because these representations use the same primitives of lines to show communication but have different meaning from those normally used in Gantt charts. The specific style chosen was made to emulate an engineer's pen which would be used in drafting blueprints or making designs. This final design element unfortunately did not make it into the controlled experiment as it was considered too difficult to implement with little expected impact on the outcomes of the experiment.


To represent grouping, we shrink down the glyph associated with the grouped structure shown in Figure \ref{fig:abstract_designs}, duplicate them multiple times and evenly space them along the y-axis. More formally, the encoding rule to show ``grouping" is repetition and alignment on a non-common scale. If there is no repetition, then the structure is continuous.

% This may be nice to include
% Although not pictured here, a gradient can be placed on top of these patterns to represent that they continue past the bounds of the currently rendered area. These designs have the additional benefit of being vertically collapsible or expansible to fill the height of a Gantt chart by removing intermediary ``horizontal lines." The visual structure of each of these figures remains clear when represented with as few as three horizontal lines. This is beneficial because it allows us to represent groups of patterns using the same amount of space as one long pattern, while persevering individual characteristics like distance and structure in a recognizable way.

For our next encoding rule, stride is expressed with the use of angle. The angle of the ``horizontal" lines increases from 15 degrees to 60 degrees. They do not encode the true stride of communication between time steps, but rather hint at the magnitude of distance over which communication is occurring. We include this encoding rule as a direct result of our first preliminary experiment with the idea that our abstract structure can resemble the look of communication lines on a zoomed-in chart.

For our final variable, a structure's temporal range, we encode this approximately. Rather than show the exact range, we place the glyph -- or series of glyphs in the case of a grouped structure -- representing a particular structure on the x-axis in the center of that range. If two structures overlap, they are placed alongside one another. Due to the design of our controlled experiment, we did not evaluate or implement this encoding rule as we only tested artificial charts with two time steps. 

In practice, these primitive abstractions of real communication structures, will be overlayed on top of a Gantt chart when the view is zoomed-out. To reduce visual noise, but keep these glyphs grounded in the context of the underlying chart, the real lines showing program communication will not be drawn at this resolution and the underlying chart will be blurred. Taking a lesson learned from our first preliminary experiment, this will diminish a user's inclination to examine unnecessary or hard to parse background details and enable them to focus on the high level communication structures which can show areas of interest.  




% Analysis Section
\section{Analysis}
\label{sec:analysis}
    We evaluate the hypotheses outlined in Section \ref{sec:methodology} using an Analysis of Variance test (ANVOA) with a Tukey HSD Post-Hoc test to evaluate the impact of and pairwise significance of our independent variables. We choose a significance of $0.05$ and apply a Bonferroni correction for multiple testing, resulting in an effective significance of $0.01$. 
    
    To justify the validity of using ANOVA, we applied a Shapiro-Wilk test to evaluate the normality of each subset of data associated with a particular level of our independent variable. For each level, the p-value produced by the Shapiro-Wilk test exceeded the target $0.05$, so we proceeded with the test. We further supplement the analysis with bootstrapped confidence intervals which are consistent with the ANOVA results.
    
    We then examine a confusion matrix in an exploratory fashion for further insight into how users may have arrived at the incorrect answers.
    
    
\subsection{Hypothesis 1 --- Overall Accuracy}
    Recall that our first pre-registered hypothesis is, ``New designs will be approximately the same in accuracy as traditional full representations for identification of patterns, grouping and stride when taken all-together." This is our broadest hypothesis, evaluating a combination of our independent variables to give an intuition of ``overall which design was best". If we examine Figure \ref{fig:ci_all_prob} we see the bootstrapped confidence intervals of accuracies aggregated across all tasks: pattern identification, grouping identification and stride comparison.
    
    \begin{figure}
        \centering
        \includegraphics[width=\columnwidth]{figures/ci_all_problems.png}
        \caption{Confidence intervals for all problem types: pattern identification, grouping identification, and stride comparison.}
        \label{fig:ci_all_prob}
    \end{figure}
    
    From Figure \ref{fig:ci_all_prob}, we see that our Hypothesis did not hold. There is no overlap between new and full representations and this difference is statistically significant (F$_{2,32}$ = 17.58, p $<$ .01). We fail to reject the null hypothesis that our representation choice made no difference. However, as our new representations intend to improve on densely packed full representations, these results are very promising. They indicate that the new representations have a statistically significant, positive effect on response accuracy. As we dig further into the data we see that this impact was driven almost entirely by the classification questions, despite poor performance with discrimination questions.

\subsection{Hypothesis 2}
    For hypothesis 2, we speculate that, "New designs will enable more accurate identification of communication trace patterns, for sufficiently dense charts ($>1000$ rows/processes), than either partial or full representations." Referencing Figure \ref{fig:ci_pattern}, we see that our hypothesis holds true. The new representations did significantly better compared to the full representations when it comes to accurately identifying the communication pattern between two rows of processes. 
    \begin{figure}
        \centering
        \includegraphics[width=\columnwidth]{figures/ci_pattern.png}
        \caption{Bootstrapped confidence intervals for pattern classification questions.}
        \label{fig:ci_pattern}
    \end{figure}
    
    The effect of our representation types on the classification accuracy of patterns was determined to be statistically significant (F$_{2,32}$ = 7.62, p $<$ .01). Furthermore, our Tukey HSD test indicated that the mean accuracy for the new representation was significantly different from the mean accuracy of the full representation. By comparison, the mean accuracy of the partial representations vs. new representations was found not to be statistically significant. This holds true as we look at Figure \ref{fig:ci_pattern} and see the large overlap between new and partial representations.

    With specific regard to the comparison of new designs vs. full designs, these findings are consistent with our expectations. When rendered over greater than 1000 rows, its very hard to make out any clear details of a full representation of communication lines. Although some aspects of a pattern could be caught if one is very observant -- like a small empty triangle at the top for a ``ring" -- the overall pattern just starts to look like a black mass spanning our rows of process rectangles. By comparison, the new representations use symbols to convey the idea of a particular pattern and render it the same in a way agnostic of the number of rows/processes. 
    
    When looking at the absolute accuracy numbers, however, the new representations are still far from perfect, failing to reach a mean of $2/3$ accuracy. This is likely attributable to a visual similarity between how grouped rings and exchanges are rendered, as is supported by Figure \ref{fig:abstract_conf_mat}. In this figure we see that the majority of false positive identifications of Exchange-Grouped (EG), came from charts which were truly Ring-Grouped (RG).
    
    \begin{figure}
        \centering
        \includegraphics[width=\columnwidth]{figures/abstract_conf_mat.png}
        \caption{Confusion matrix showing user responses mapped against ground truth grouping and patterns for particular charts.}
        \label{fig:abstract_conf_mat}
    \end{figure}
    
\subsection{Hypothesis 3}
    By comparison to H2, our third hypothesis was concerned with classifying patterns as grouped or continuous. Specifically it read "New designs will enable more accurate identification of communication trace pattern "grouping", for sufficiently dense charts (>1000 rows/processes), than either partial or full representations." Figure \ref{fig:ci_grouping} shows that our hypothesis was validated. The new designs did significantly better than both full and partial representations.
    
    \begin{figure}
        \centering
        \includegraphics[width=\columnwidth]{figures/ci_grouping.png}
        \caption{Bootstrapped confidence intervals for grouping classification questions.}
        \label{fig:ci_grouping}
    \end{figure}
    
    Consistent with our bootstrapped confidence intervals, the effect of the representation type on classification accuracy for ``grouping" questions is statistically significant (F$_{2,32}$ = 23.34, p $<$ .01). Our Tukey HSD test further indicated that the mean accuracy for the new representation was significantly different than the mean accuracies for both the full and partial representations. Looking at absolute accuracies, we can also see that the new representation produced a very high median accuracy of 73\% while the full and partial representations are hovering in the 50\% area; functionally equivalent to random guesses. 
    
    These results were consistent with expectations due to the fact that the new representations very clearly highlight the ``grouping" of a pattern at any density of rows. As was the case with patterns, the lines in very dense full representations just became an indecipherable black rectangle. So even though a trained eye could detect "hints" of grouping, most patterns just looked continuous. For partial representations on the other hand, we speculate that accuracies were relatively low due to the fact that a ``break" in the pattern can be cutoff when we show only 8 rows. If a pattern repeats every 10 rows, a user will never be able to tell with certainty if a pattern was grouped or not when they can only see the top or bottom 8. So, with both the full and partial representation it's easy to see how this classification problem is reduced to random guessing.

\subsection{Hypothesis 4}
    Our fourth hypothesis is focused around user's ability to discern stride from full, new and partial representations. Specifically, it states "For individuals with some coding experience, our proposed new designs will enable less accurate identification of communication trace pattern stride than either partial or full representations." In Figure \ref{fig:ci_stride}, we see that our hypothesis appears to hold true for both full and partial representations. However, due to the significant overlap between new and full representations, our Tukey HSD test will be critical in evaluating if the difference is statistically significant.
    
    \begin{figure}
        \centering
        \includegraphics[width=\columnwidth]{figures/ci_stride.png}
        \caption{Bootstrapped confidence intervals for questions asking users to compare the strides between two charts.}
        \label{fig:ci_stride}
    \end{figure}

    Overall, the effect of swapping out representation types on accuracy for stride questions is statistically significant (F$_{2,32}$ = 28.71, p $<$ .01). However, this significance extends only when comparing the mean accuracy of partial representations with new and full. Between the full and new representations there was not a statistically significant difference in the mean accuracies of new and full representations, according to a Tukey HSD test. So, when looking only a statistically significant differences, this hypothesis came out half true.
    
    Although our hypothesis states our expectations that both full and partial representations will do better than the new representation at conveying the stride of communication patterns, this outcome is very reasonable. For the new representations, it was expected that they would very poorly convey stride, because they only approximated stride with a very limited range of angles.  When comparing with directly encoded lines in the full and partial charts the angle of the lines would often not match up and they could not even be counted if one wanted to spend the time. For full representations, we have the same problem as with the prior two tasks, the lines are too dense to make any meaningful judgements about the stride. Accordingly, participants were just left with random guessing. Finally, partial representations directly encoded the strides of lines in a way visible to users. Even though a similar situation to the grouping problem is possible, with the whole stride being cut off, any comparisons between partial and partial charts would be easy to see at a glance because the lines would have the exact same angle. Furthermore, even comparisons between partial charts and visible full charts (with 10's of rows) would be much more realistic than with either the full or new representations.

\subsection{Hypothesis 5}
    Like our first hypothesis, the fifth and final hypothesis was a more general one. It states, ``Partial or `zoomed in' representations will result in less accurate identification of communication trace stride, grouping, and structure identification than either full representations or new designs." As evidenced by each of the above charts showing our confidence intervals, this hypothesis obviously did not hold. 
    
    This hypothesis came from analysis of data collected in a pilot study. In that pilot study, partial representation under-performed both representations in every accuracy measure. In The final study, however this had flipped with full being the worst across the board. We attribute this swap to users misunderstanding or forgetting details from the tutorial before we modified the structure of our experiment to be broken into two modules.


% 
\subsection{Exploratory Analysis }
    
    In many of the above confidence interval charts we have plotted above, we observe that the partial representations tended to produce more accurate results than their full counterparts. Most notably, although not statistically significant with regards to the new representations, partial did best overall when accuracies are aggregated across all metrics. This finding hints at a deeper revelation:  with partial representations acting as our analogue for a ``zoomed in" view of a Gantt chart, this implies that users can glean more meaningful information across every metric we chose for this test from a fully ``zoomed in" view compared to a fully ``zoomed out" view. Extrapolating, this hints at a need for deeper research into zoomed in vs. zoomed out views with this style of chart and highlights the deficiencies of current practices. 
   

    
    % \begin{figure}
    %     \centering
    %     \includegraphics[width=\columnwidth]{figures/full_conf_mat.png}
    %     \caption{Caption}
    %     \label{fig:full_conf_mat}
    % \end{figure}
    
    % Figure \ref{fig:full_conf_mat} shows a confusion matrix for the 
    
    
    To elaborate on the concept of ``factor mining", we cite Elmqvist and Yi who describe it an experiment design pattern intended to solve a problem in the exploratory phases of a experiment \cite{elmqvist2015patterns}. When evaluating very complex domains or research questions it's difficult to find interesting factors among all possible combinations and variations of test conditions. Factor mining aids in this by splitting an experiment into two phases, with one being the initial experiment and the other being a more broad, less-structured experiment which precedes it. The conclusions from this less structured experiment can be used to narrow down trials and factors in the main experiment to those which are only the most interesting.

For our particular experiment there exists many possible interesting independent variables: the density of a chart, the structure being shown, the grouping of a structure, the representation type (a partial or full chart), the stride of a structure. If we too the approach of including all these factors, participants would be subjected to hundreds (if not thousands) of trials capture all possible combinations of factors. So, to leverage this technique and simplify our experiment, we execute a semi-structured interview to explore what features of these repeating lines are most interesting or salient to subjects.

In this interview, we show users four visual prompts comprised of simulations of logical-time charts  lines making up a communication structure. An example image can be seen in Figure \ref{fig:interview_prompt}. While showing each prompt, we ask the participant three questions:

\begin{enumerate}
    \item Please describe the pattern of lines on the right.
    \item Please describe the pattern of lines on the left.
    \item Do you think that these two patterns are the same? Why or why not?
\end{enumerate}

The side-by-side charts for a particular question would sometimes show the same structure while others would show two completely different structures. The number of rows in a chart were varied between charts and the representation type as a full or partial chart was varied randomly as well.  

Seven individuals were recruited for this experiment. One was solicited at the University of Arizona with the other six randomly selected from among attendees at the 2019 Supercomputing conference. Among these subjects, all but one had prior computing experience in some form or another and the majority had HPC experience. No respondents had worked with HPC profiling software like Vampir and HPC Toolkit. For those who have profiled and analyzed HPC code, they reported using only command line tools.

\begin{figure}[h]
    \centering
    \includegraphics[width=.4\textwidth]{figures/Annotation2019-11-17113949.png}
    \caption{An example of an image which users were prompted with in our first preliminary study, an open ended interview.}
    \label{fig:interview_prompt}
\end{figure}

The interviews were recorded, transcribed and coded to provide an understanding of what features users found most salient and how users responded to certain combinations of factors. After coding, the responses provided by our 7 interviewees were analyzed for common themes and patterns. Among the 30+ unique codes used to summarize these interviews, several occurred frequently across multiple different subjects and multiple questions within a given single subject's responses: \textbf{line angle}, \textbf{comparison}+\textbf{uncertainty}, \textbf{background}, and \textbf{line direction}. 

% Occurring less frequently, but appearing between different subjects and worthy of note, were the codes: \textbf{transformation} and \textbf{one line (ring)}.

Among the very common codes, \textbf{line angle} is the most prevalent feature used to describe patterns of lines and justify comparisons of patterns of lines. Not a single respondent eschews mention of line angle and three in particular reference it greater than 10 times. 

The code \textbf{background}, describes situations where people deviate from describing the pattern of lines and instead add additional information about the boxes and columns they connected. Although not all participants do this, a majority at one point or another reference the background during the interview. In some instances, this characteristic is used as a justification for differentiating two patterns of lines. 

Following from angle and background, \textbf{line direction} encoded a user's direct declaration or implicit expression that lines may have some direction associated with them. These codes occurred across all subjects but were almost exclusively reserved for describing patterns and rarely for justifying comparisons. 

Finally, the linked attributes of \textbf{comparison} and \textbf{uncertainty}, were used to encode a subject's conviction when making a comparison between the two charts. This pair occurred significantly more frequently across all subjects than the antithetical pair of codes \textbf{comparison} + \textbf{certainty}. Basically, users rarely felt confident comparing charts because simple changes of height and representation make them very different looking. 

% The first of the two noteworthy but less common codes, \textbf{transformation}, encoded any occurrence where a subject compared two charts with an description of how one might be a graphically transformed version of another. Such descriptions appealed to concepts of ``rotation," ``squashing/stretching" and ``enlargement." The code \textbf{one line (ring)} was used to encapsulate situations where users were presented with a ``ring" pattern and mistakenly identified multiple lines crossing perpendicular to the offset pattern as one darker or thicker line. Some respondents noted upon closer observation that it was indeed two lines, but others did not.

\note{may not include}
In addition to the codes we generate from the transcribed dataset some observations about subjects reactions to ``stencil" structures made by the test facilitator should be included. First, across respondents presented with stencil structures there is a general notable inability to comprehend these structures. Not only were respondents often uncertain about where connections began and ended, they often misidentified discrete lines connecting cells as a single line. In some cases they seemed to identify the pattern as only one single continuous line zig-zagging and overlapping across the cells.

Second, we observe that the stencil representations appear to be viscerally off-putting to some interviewees with the visual complexity resulting in a hesitancy to speak. In one case, a subject does not notice very distinct characteristics distinguishing two stencil patterns until prompted to look more closely by the interviewer. This same respondent describes them as ``a mess" when prompted for justification of his comparison.

It is interesting that \textbf{line angle} is such a commonly occurring code because angle is not a defining characteristic of any our selected patterns: offset, ring, exchange or stencil. Although angle is tied to the stride of communication from one column to the other, the visual angle is primarily dependant on chart density. With many rows, the angle of lines will be shallower; with fewer it will be steeper. This means that the density of rendering significantly impacts recognizability, causing people to associate different charts and discriminate between two versions of the same chart.

% (eg. with a one offset every $n^{th}$ rectangle on the left will be connected to the $n+1^{th}$ on the right. 

Continuing with this analysis we can further say that among our research population, given the other commonly occurring descriptive codes (\textbf{line direction} and \textbf{background}) subjects generally did not focus on the features which formally define the provided patterns. Two respondents did note for both offset and ring patterns that the stride was a feature worth noting however they did not emphasize it when justifying comparisons, instead deciding to fall back onto the more obvious differences in line angle.

Together, these findings, along with subject's use of line angle as key descriptors of these patterns indicate that an effective visualization of communication lines in gantt charts may need to distort some features to give the impression of continuity between high-level and detailed views. With a naive zoom on an offset pattern from a scale 100+ lines high to 8 lines high, the line angle would be naturally distorted. This could lead to ambiguity when users are attempting to verify that this detailed representation is the same pattern as the one they saw when ``zoomed out." If the angle of lines are persevered between views however, our findings indicate that users will be much more likely to associate these patterns.

As for the results expressed on stencil patterns, we can reasonably conclude that these patterns are hard to interpret and difficult to meaningfully render at various scales. Furthermore, subtle differences in parameters which change the internal structure of a stencil may be hard to discern because users may not want to look that closely at the visual noise in the center of the pattern. Generally this lead us to conclude that Stencils may be too complicated to experiment with at this time.


% Concerning the first of our noteworthy codes, \textbf{transformation}: the efforts made by people to relate patterns to one another seem to generally indicate a natural desire by some individuals to find patterns even where none exist. In the same way that users were hesitant to declare two patterns the same, they were often equally hesitant to say they were different. In order to justify this reluctance, some respondents relied on this idea that one pattern may be the inverse, or stretched, or rotated version of the other pattern. This shows, that humans may be more flexible or willing to accept that two patterns are the same even if key features do not line up in the way they expect.

% The second code, \textbf{one line (ring)}, does not significantly impact the conclusions we can make about these charts in general; however it does provide us with a reference for how even very simple patterns can be misleading. Although the offset may be clear with the majority of lines, very rarely did people relate that offset to the offset of lines which "wrap" around and form the ring. Furthermore, it's interesting to note that even as few as two lines alone can effectively occlude one another. These observations reinforce the importance of this research by demonstrating how easy it is for these charts to become undecipherable.

\subsection{Insights}

The stated goal of our first study was to narrow down the number of potential factors we could vary in the controlled experiment. Unfortunately, this experiment did not support that goal as initially intended. Rather than cut away factors we thought people would use to describe these structures, we added one in the form of line angle. Ultimately, this failure to mine salient factors will result in a controlled experiment design where most of these factors are relegated to random variables to more generally asses the impact of the proposed designs against full and partial representations of charts.

External to the stated goal, however, we integrate the following insights into our design and controlled experiment. First, line angle is a salient characteristic to potential users of a new visualization and should be reflected as a channel in a proposed design. Second, we should obscure the background in our proposed designs to highlight the most important features of communication structures. Finally, since stencils are so confusing and difficult to parse at any number of rows or representation type, we can simplify our study by omitting them for now as they will likely remain incomprehensible in a controlled experiment.



\section{Experiment Methodology}
\label{sec:methodology}

We evaluate the efficacy of the proposed design and the existing methods through a controlled user study.

\subsection{Experiment Overview}

We design a within-subjects study with one factor: representation type. This 

    Our experiment is implemented as a within-subjects study with one factor: chart "representation type." This factor has three levels: ``full," ``partial," and ``new". \autoref{fig:exp_levels}, shows how these representation types are rendered on the experiment platform. The ``full" representation type represents a semantically zoomed-out view of a logical time-step Gantt chart with communication lines drawn over processes. The ``partial" representation emulates of a semantically zoomed-in view of a logical time Gantt chart. Finally the ``new" representations show our proposed visual designs, introduced in \autoref{sec:design}, as they would be overlayed on a zoomed-out view of our hypothetical Gantt chart. They will be referred to as ``new representations" for the remainder of this paper.
    
    Outside of "representation type", all other variables used to generate these charts are randomized. This approach simplifies the combinatorics problem raised in \autoref{sec:prelim}. This randomized variable approach offers the further benefit of making any findings more generalizeable, as they will apply across many different communication structures, patterns and pattern orientations. Due to the fact that we only use simulated Gantt charts across two time steps, we did not implement or consider \textbf{temporal range} as a variable represented in the chart, although it was included as a variable in our visual design.
    
    From this experiment we measure four dependant variables: total accuracy across all question types, accuracy for pattern classification questions, accuracy for grouping classification questions and accuracy for stride comparison questions. For the purposes of our study, accuracy is measured as the ratio of correct answers / total answers, per participant. We chose to make the denominator total answers instead of \textit{total questions} to account for missing values in the dataset where the platform failed to log a user's response properly. 
    
    For the classification questions, each participant is presented with 8 unique charts, rendered differently for each of the three experiment conditions. For each condition, a particular chart would be shown to a participant two times, once for structure classification and again for grouping classification. For discrimination questions, users would again be shown these same 8 charts again varying across the representation types. For each chart, they would be asked to compare it against two other charts. Thus we get the following number of total trials undertaken by a participant:
    
    (8 charts x 3 conditions x 2 categorizations) $+$ (8 charts x 3 conditions x 2 discriminations) $=$ 96 total trials.
    

    \begin{figure}
        \centering
        \includegraphics[width=\columnwidth]{figures/error-feedback-bar.png}
        \caption{A notification which pops up during the interactive tutorial. Participants are told they answered incorrectly and given information which can help them answer correctly in the future.}
        \label{fig:bad-answer}
    \end{figure}
    

\subsection{Procedure}
    At the highest level, this experiment is broken into two modules: classification and discrimination. The classification module comes first, and encompasses the tutorial and tasks associated with classifying communication patterns based on their patterns \textit{and} grouping. The discrimination module comes next and encompasses the tutorial and tasks associated with asking users to discriminate stride between two charts.
    
    Both modules follow the same general sub-structure. First comes a text-based tutorial explaining key information participants will need to know to perform required tasks. Next, participants move into an interactive tutorial where they perform the same classification or discrimination task that comprises the main experiment phase of that module. This interactive tutorial acquaints participants with the structure of the task they will be asked to perform in a consequence free space. To correct any potential misunderstandings subjects may have, the experiment platform provides feedback on the correctness of answers when in this phase. When incorrect, users are provided a reminder of tutorial information related to their current task (\autoref{fig:bad-answer}).
    
    Finally, following the interactive tutorial, users are prompted with a screen notifying them that they are leaving the tutorial portion of this module and entering the main phase. They are warned on this screen that they will no longer be given feedback on their responses. By clicking on an ``acknowledge" button, participants are sent into the main phase of this module where they are presented with randomly ordered questions. They are informed of their relative progress during this portion with a progress bar displayed at the top of the screen.

\subsection{Tasks}
    
    In this experiment we asked users to perform two tasks:
    \vspace{-.5em}
    \begin{enumerate}[start=1, label={\bfseries T\arabic*}]
        \itemsep0em
        \item Classify a pattern in a chart
        \item Discriminate stride between two charts
    \end{enumerate}
    
    For \textbf{T1}, users are asked to classify -- across two separate questions generated per-chart -- what pattern a certain chart is showing and whether that pattern is "grouped" or not. \autoref{fig:class-pattern} shows an example of a pattern classification question. For this question the response type is a three-alternative forced choice for classifying pattern. The grouping question strongly resembles the pattern classification question with a two-alternative forced choice (grouped vs continuous) replacing the three choices in the latter.
    
    \begin{figure}
        \centering
        \includegraphics[width=\columnwidth]{figures/classification-pattern.png}
        \caption{An example of structure classification question. Users are prompted with a chart on the left side of the screen and given a 3-alternative forced choice prompt to select the underlying communication structure shown by the chart on the left.}
        \label{fig:class-pattern}
    \end{figure}
 
    % \begin{figure}
    %     \centering
    %     \includegraphics[width=\columnwidth]{figures/classification-grouped.png}
    %     \caption{An example of }
    %     \label{fig:class-group}
    % \end{figure}
    
\textbf{T2} asks participants to discriminate between two charts. Specifically, they are asked to compare the strides of the communication patterns shown in the two charts and assert if they have the same stride with a "yes" or "no" answer. An example of such a question can be seen in \autoref{fig:discrim-ex}.
    
    \begin{figure}
        \centering
        \includegraphics[width=\columnwidth]{figures/discrimination-stride.png}
        \caption{An example of a stride discrimination question. Users are prompted with two charts, of different representation or number of rows and asked if they have the same stride.}
        \label{fig:discrim-ex}
    \end{figure}
    
    The design of these tasks were strongly informed by piloting in the early phases of this experiment design. Our decision to separate the discrimination task from classification tasks was attributable to our first pilot where users were asked very generally to identify if a particular chart had the ``same pattern" as four other charts. Observations from this pilot also led to a breaking up of our discrimination task into two questions with one comparison pattern instead of the original one question with four comparison patterns. The constrained nature of these tasks was further informed by a second pilot we executed where users were asked to extrapolate patterns from partial representations or reduce patterns from full representations by drawing them on a piece of paper. The results of this pilot lead us to believe that a open experiment would be difficult to tutorialize and extract meaningful data from at this time. For more information on these pilots, please see our supplemental documentation. 
    

\subsection{Participants}
    For this study we recruited 35 participants who had at least a self reported "beginner" level of coding experience.
    Participants were recruited using the Prolific crowd sourcing platform and were not filtered on any other demographic information. Participants were payed a flat rate of \$9.00 for our estimated 35 minute experiment. We set this rate to reflect a target wage of \$15/hr. The ages of participants ranged from 20-56. Males made up the majority of the tested population with 28 individuals and 7 individuals identifying as female.
    
    \note{Todo kate: argue for the participant population}
    
    Because we were using a crowd-sourcing platform, we accounted for potential bad actors with the inclusion of four simple guard questions. These questions were trivial to answer and would indicate if someone was clicking through without paying sufficient attention to the study. We threw out a total of eight responses due to failures of these guard questions. 
    
    The number of participants was decided upon using a power analysis of data collected in a small scale pilot study of 10 subjects. Specifically, we calculate an expected mean of paired differences and an expected standard deviation of paired differences for each of our hypothesis. We then input each of these pairwise values into an online power analysis calculator \note{(cite: http://statulator.com/SampleSize/ss2PM.html)} and took the max required participants among all pairs necessary to achieve a power of .8 and .05 level of significance. Due to our criteria for discarding low-quality responses, we continuously collected participants until we arrived at our target 

\subsection{Experiment Platform}
    The experiment platform is a custom built website hosted for free on a Heroku web application server.\cite{experiment_platform} Python and JavaScript are the main development programming languages. Python manages the serving of platform web pages to the client through the Flask library \cite{flask}, and the storing of user responses in a remote non-relational database. Our JavaScript code primarily manages the drawing of "charts" for questions with the D3.js library. We include the source code in supplemental materials.
    
    The hardware for this experiment was the participant's own. Through the crowd sourcing platform, we limit participation to those with desktop or laptop computers. We collect screen resolution from participants automatically and observe that the highest resolution screen used was 2560 x 1440, 1093 x 615 was the lowest, and the mode was 1920 x 1080. 
    
\subsection{Hypotheses}

    In our pre-registration of this experiment, we indicated that our experiment would test five hypotheses. These hypotheses were derived from an analysis of data obtained from a small scale pilot of this study. There are as follows:
    
    
    \vspace{-.5em}
    \begin{enumerate}[start=1, label={\bfseries H\arabic*}]
        \itemsep-.2em
        \item New designs will be approximately the same in accuracy as traditional full representations for identification of structure, grouping and stride when taken all-together.
        \item New designs will enable more accurate identification of communication trace structure, for sufficiently dense charts ($>1000$ rows/processes), than either partial or full representations.
        \item New designs will enable more accurate identification of communication trace structure "grouping", for sufficiently dense charts ($>1000$ rows/processes), than either partial or full representations.
        \item New designs will enable less accurate identification of communication trace pattern stride than either partial or full representations.
        \item Partial or "zoomed in" representations will result in less accurate identification of communication trace pattern stride, in addition to grouping and pattern identification than either full representations or new designs.
    \end{enumerate}
    


In the High Performance Computing (HPC) domain, Gantt charts are commonly used to visualize the execution trace of a parallel program. By visualizing multiple processing elements (PEs) as a stack of horizontal tracks, users can see which methods ran on which PE and at what time. The utility of this chart is further enhanced with the inclusion of communication trace data encoded as lines running from one process on a particular PE to another process on a different PE. Figure \ref{fig:simple_gantt}, shows an example of such a Gantt chart integrated into the Vampir toolkit.


\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{figures/basic_gantt.png}
    \caption{A Gantt chart produced by Vampir from \cite{isaacs2014state}, showing a slice of time in a 16-PE execution. Black lines denote communication.}
    \label{fig:simple_gantt}
\end{figure}

For relatively small parallel programs, run on 8-32 cores, this straightforward encoding of communications between methods provides an intuitive interface for following the transfer of data between processes. If users want to see how long a communication took between two processes, they need only to trace the line and judge the length of it relative to the x-axis: a longer line indicates a longer amount of time spent on communication. 

By organizing Gantt charts using logical time instead of ``wall clock" time, these individual lines form patterns of communication related to common processes in parallel programming. By observing these patterns of lines holistically, these charts enable insights into the operation of a parallel program which were not possible before \cite{isaacs2014combing}. 

Unfortunately, despite the usefulness of this encoding, it does not effectively scale to large parallel programs. As the number of processing elements grows from the tens to the thousands, the visualization becomes incomprehensible. As is often the case with very dense graphs, multiple lines are mapped to a single pixel resulting in pillars of inscrutable ``hairballs." \autoref{fig:dense_gantt}, shows several examples of this phenomenon where several different communication patterns are drawn over 1024 PEs.

In order better understand the nature of this issue and propose a solution, we undertake a process of exploration, design and evaluation to understand the nature of these patterns and produce a viable solution for our observed scalability problem. This process begins with a quantitative study investigating what features in these line patterns are most important in identifying a particular pattern. We then leverage lessons learned from this study to design a set of glyphs which convey the base structure, grouping and stride of these communication patterns. 

We evaluate these new designs in a controlled experiment with 35 participants recruited using the Prolific crowd sourcing platform. This experiment demonstrates that our new glyph designs enable users to more accurately identify the base structure of a pattern of communication lines compared to naively drawn renderings like those found in \autoref{fig:dense_gantt}. Our new designs furthermore enable users to more accurately identify if a particular pattern of communication is “grouped” or repeating over chunks of execution threads. 
\section{Background}
\label{sec:background}

\begin{figure}
    \centering
    \begin{subfigure}{0.15\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/dense-ring-full.png}
        \caption{Continuous ring}
        \label{fig:dense-ring}
    \end{subfigure}
    \begin{subfigure}{0.15\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/dense-offset.png}
        \caption{Continuous offset}
        \label{fig:dense-offset}
    \end{subfigure}
    \begin{subfigure}{0.15\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/dense-ring.png}
        \caption{Exchange}
        \label{fig:dense-exchange}
    \end{subfigure}
    
    % \includegraphics{figures/very-dense-short.png}
    \caption{Examples of dense communication lines in Gantt charts across two time steps. The resolution is such that each processing elements is less thann a pixel and individual lines occlude. }
    \label{fig:dense_gantt}
\end{figure}


We discuss relevant background in high performance computing, execution traces and their visualization, and communication patterns.

\begin{figure*}
    \centering
    \begin{subfigure}{0.18\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/basic-offset.png}
         \caption{Continuous offset pattern}
         \label{fig:oc}
    \end{subfigure}
    \begin{subfigure}{0.18\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/basic-offset-grouped.png}
         \caption{Grouped offset pattern}
         \label{fig:og}
    \end{subfigure}
    \begin{subfigure}{0.18\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/basic-ring.png}
         \caption{Continuous ring pattern}
         \label{fig:rc}
    \end{subfigure}
    \begin{subfigure}{0.18\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/basic-ring-grouped.png}
         \caption{Grouped ring pattern}
         \label{fig:rg}
    \end{subfigure}
    \begin{subfigure}{0.18\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/basic-exchange.png}
         \caption{Exchange pattern}
         \label{fig:eg}
    \end{subfigure}
    \caption{Communication patterns supported by our new design. Each of these show 8 PEs and two time steps.}
    \label{fig:commpatterns}
\end{figure*}

\vspace{1ex}

\textbf{High Performance Computing (HPC).} A central goal of HPC is completing large computational problems, such as scientific simulations or large numeric (e.g., matrix) calculations, more efficiently, typically through the use of large-scale parallel resources. In some cases, the computational problem is large enough that it is infeasible to compute on fewer resources. To perform such computation, the problem is typically divided into smaller sub-problems, such as slices of the domain, and distributed across the parallel resources. We refer to these parallel resources as {\em processing elements (PEs).}

During program execution, there are times when the PEs must pass data, such as partial results or shared boundary information, to each other. We refer to the messages sent between PEs as {\em communication.}


\vspace{1ex}

\textbf{Execution Traces.} As HPC aims for efficient use of resources, analyzing a program for its performance (e.g., the time it took to execute) is a common task. At its most simple, performance measurement might just be recording the time taken for a full execution. While this tells developers and performance analysts whether a version of the code or a change in configuration performed better than others, it doesn't reveal why. {\em Tracing} is a form of performance measurement that logs individual timestamped events, such as the beginning and ending of functions or communication calls. From these fine-grained measurements, the history of a program's execution can be reconstructed and used to explore how events, in concert, led to observed performance.

\vspace{1ex}

\textbf{Visualizing Execution Traces with Gantt Charts.} Traces are often employed in an attempt to understand complex behavior from the intersection of the parallel program and the resources on which it was executed. This exploratory task is often performed with the aid of a Gantt chart. In HPC, typically the x-axis denotes time and processing elements are stacked as rows in the y-axis, usually in order of their ID. Rectangles are plotted to show the start, end, and executing PE of a function call. Straight lines originating at one rectangle and spanning rows to another show the send time, receive time, and end points of communication. \autoref{fig:simple_gantt} shows a time-slice of a small-scale (16 PEs) execution trace, rendered by the commercial software Vampir~\cite{nagel1996vampir}.

While most Gantt charts in HPC depict physical time in seconds (\autoref{fig:physical-logical} (top)), another approach is to arrange events into an idealized unit time using logical rules~\cite{Leblanc1990, Schaubschlager2003DeWiz, Isaacs2015, Isaacs2016} (\autoref{fig:physical-logical} (bottom)). In this scheme, events are partitioned by relationships, e.g., functions called by a PE remain in that order and sends must occur before receives~\cite{Lamport1978}. Physical time data is then encoded with another channel, such as color. This arrangement has been used to emphasize what programmers might expect in an ideal situation, where work is evenly divided and there is no contention for resources, thereby allowing them to identify code regions and compare events that {\em should have} behaved similarly. Use of these views has resulted in significant performance improvements in real-world production code~\cite{isaacs2014combing}.

\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{figures/phys-time.png}\\
    \vspace{1ex}
    \includegraphics[width=\columnwidth]{figures/tutorial_gc.png}
    \caption{A toy example trace visualized in a Gantt chart in physical time (top) and idealized unit time (bottom). The latter enforces logical rules, like receives happening after sends, and aligns events on PEs created by the same code.}
    \label{fig:physical-logical}
\end{figure}

Typically the main view of a Gantt chart shows a navigable window of time. The bounds of the window may also be adjusted by brushing an overview (\autoref{fig:simple_gantt} top left). As the number of PEs increases, vertical panning and zooming can be used. When zoomed in, only some of the communication lines are shown. When zoomed out, the lines are either omitted or obscure the view. The goal of our work is retaining recognizability of communication at larger scales.

\vspace{1ex}

\textbf{Communication Patterns.} In many parallel programs, processing elements communicate at logically equivalent times with neighbors that can be calculated based on their ID, the total number of PEs, and optionally additional information about the domain. For example, at a specific line of code, all PEs might send a message to the PE that is their own ID plus one. We refer to commonly observed instances of these as {\em communication patterns.}

Communication patterns often show a degree of regularity and symmetry when depicted in idealized unit time. When recognized in a trace visualization, communication patterns can serve as an indicator of what part of the source code is being executed and what the program is trying to accomplish. Thus, we focus this work on preserving that capability. We describe the specific patterns we consider (shown in \autoref{fig:commpatterns}):

\begin{enumerate}
    \itemsep0em
    \item \textbf{Offsets.} Each PE sends to the PE that is their own ID plus some offset or {\em stride} if (ID + stride) is a valid PE ID. These appear as parallel lines in idealized time Gantt charts. These are seen in applications like PF3D~\cite{pf3d} and several NAS benchmarks~\cite{nas}.
    
    \item \textbf{Rings.} Each PE sends to the PE that is their own ID plus some stride, modulo the total number of PEs in the ring. In idealized time Gantt charts, these appear like offsets with cross lines where the send-receive pair ``wraps around''. These are used in Jacobi iterations, libNBC~\cite{libnbc}, and BT from the NAS benchmarks~\cite{nas}.
    
    \item \textbf{Exchanges.} The PEs are paired off, each one sends to their partner. Typically the pairs are regularly spaced. These are identical to a ring where the stride is half the ring size. We separate this class however as they are thought of separately and are typically formed of many small groups across the PE ID space. These seen in LULESH~\cite{LULESH} and MG from the NAS benchmarks~\cite{nas}.
    
    \item \textbf{Stencils.} The PEs are assumed to be arranged in a kD (typically 3D) grid. Each PE sends to all of its j-hop neighbors in the grid, sometimes including diagonal neighbors. Stencils are used in applications such as AMG~\cite{amg} and LASSEN~\cite{lassen}.
    
\end{enumerate}

Offsets and rings can subsume the entire ID space. Alternatively the ID space can be partitioned and the calculation of the receiving ID can be done within that partition. These form {\em groups} in the pattern.


We note that communication patterns are {\em extensible}, much like the programs that contain them. Executing using more PEs can results in a larger instance or more replications of the same pattern. In a sense, a pattern defines a family of structures that vary across number of PEs, similar to how there are families of graphs, such as cliques. We use this fact to design visualizations of these patterns and test their efficacy.


\section{Related Work}
\label{sec:related}

We discuss relevant related work in visualizing execution traces and extensible structures.

\vspace{1ex}

\textbf{Visualizing Execution Traces with Many Processing Elements.} Most approaches for scaling Gantt charts for execution traces do so by removing communication entirely. Zinsight~\cite{Zinsight} elides PEs on the same chip while Cottam et al.~\cite{Cottam2015} use pixels in each row to show event-type distribution. Muelder et al.~\cite{Muelder2009} and Sigovan et al.~\cite{Sigovan2013} forgo separate rows for PEs, transforming the y-axis into duration and plotting all PE events in the same space. Ocelotl~\cite{Dosimont2014Ocelotlb} aggregates events that are similar in time and PE, a strategy similar to LiveGantt~\cite{Jo2014} which was used for manufacturing schedules rather than HPC.

SmartTraces~\cite{Osmari2014SmartTraces} combines line-less Gantt charts with a node-link diagram of tasks to show overall workflow, but not communication. Fine-grained task graphs have been used in lieu of Gantt charts, but aggregation schemes~\cite{Huynh2015DAGViz, Reissmann2017GrainGraphs} require fork-join programming models. 

Few approaches retain communication lines in Gantt charts. Ravel~\cite{isaacs2014combing} shows subgraphs induced by communication lines, but it is unclear if these are large enough to show patterns. Brendel et al.~\cite{Brendel2016} apply force-directed edge bundling, but only for small PEs counts.

\vspace{1ex}

\textbf{Visualizing Extensible Structures.} Biological workflows often have repetitive subgraphs. AVOCADO~\cite{Stitz2016} collapses subgraphs with similar motifs into single nodes to provide an overview of biomedical workflow-based provenance graphs. Maguire et al.~\cite{maguire2013visual} design pictograms for encoding motifs in biological workflows. These workflows exhibit behavior similar to fork-join parallelism, which does not match our communication patterns. More generally, Dunne and Shneiderman~\cite{Dunne2013Motifs} simplify node-link diagrams by replacing clique and fan subgraphs with a small representative solid shape. While these approaches compress heavily, often to icon-scale, our circumstance allow us more space, though not enough to draw the original encoding in a discernable way. Seeking to retain the visceral notion of each structure, we design depictions to evoke the larger pattern, based on how they are interpreted by viewers. 
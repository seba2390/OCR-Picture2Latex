\section{Conclusion}
We have presented a neural performance rendering system to generate high-quality geometry and photo-realistic textures of human-object interaction activities in novel views using sparse RGB cameras only. 
%
Our layer-wise scene decoupling strategy enables explicit disentanglement of human and object for robust reconstruction and photo-realistic rendering under challenging occlusion caused by interactions. 
%
Specifically, the proposed implicit human-object capture scheme with occlusion-aware human implicit regression and human-aware object tracking enables consistent 4D human-object dynamic geometry reconstruction.
%
Additionally, our layer-wise human-object rendering scheme encodes the occlusion information and human motion priors to provide high-resolution and photo-realistic texture results of interaction activities in the novel views.
%
Extensive experimental results demonstrate the effectiveness of our approach for compelling performance capture and rendering in various challenging scenarios with human-object interactions under the sparse setting.
%
We believe that it is a critical step for dynamic reconstruction under human-object interactions and neural human performance analysis, with many potential applications in VR/AR, entertainment,  human behavior analysis and immersive telepresence.




%\newpage
\appendix
\section{Performance} \label{sec:performance}
Our goal is to directly model file bytes, with privacy-preserving applications. Since all previous methods involve some level of domain-specific modeling at inference time (including file decoding and different stems for different input domains), direct comparison disadvantages our model. Nevertheless, it's important to characterize the runtime of our model, and compare to previous approaches. This helps to contextualize our model's performance.

We compare BF-Ti to related works in \autoref{table:perf}. We show performance on ImageNet \cite{imagenet}, including efficiency and accuracy metrics. We only report train time and throughput for models we trained ourselves. This is to avoid hardware differences creating inconsistent results. For these experiments, we tuned BF-Ti's batch sizes to maximize GPU utilization. Note that this improved training time by a relatively small amount (less than 10\%) compared to the experiments in \autoref{sec:experiments}.

Our model's size and accuracy (8.82 million parameters, 77.27\%) falls between DeiT-Ti (5.72 million parameters, 78.62\%) and DeiT-S (22.05 million parameters, 73.20\%). Our model's forward pass time is slower due to the large number of tokens being modeled. Domain-specific modeling (which our model avoids) can drastically reduce compute time.

Compared to other multi-modal models \cite{perceiver,perceiverio}, our model achieves a comparable accuracy with far fewer flops and a far smaller model. Note that our model performs no domain-specific modeling at inference time. By contrast, Perceiver includes domain-specific modeling (file decoding, tensor reshaping, and optionally convolutions) at inference time.

\begin{table}[]

\newcommand*\colourcheck[1]{%
  \expandafter\newcommand\csname #1check\endcsname{\textcolor{#1}{\ding{52}}}%
}
\colourcheck{green}
\colourcheck{yellow}

\newcommand*\colourx[1]{%
  \expandafter\newcommand\csname #1x\endcsname{\textcolor{#1}{\ding{56}}}
}
\colourx{red}

    \centering
    \resizebox{\columnwidth}{!}{
    \begin{tabular}{lccccccc}
        \toprule[1.5pt]
         \textbf{Model} & M & $\mathbb{E}[L_t]$ &\textbf{Top-1} & Sec & P (M) & F (B) & Im/s \\
         \midrule
          MobileNetv3 Large & \redx &  N/A & 75.1 & - & 5.43 & 0.22 & 9615 \\
          ResNet-50 & \redx & N/A & 78.12 & - & 25.55 & 4.017 & 3488 \\
         \midrule
          DeiT-S p16 & \redx & 196 & 78.62 & 336 & 22.05 & 4.61 & 3594 \\ % n9mki96m4d
          DeiT-Ti p=16 & \redx & 196 & 73.20 & 334 & 5.72 & 1.26 & 6885 \\
          DeiT-Ti p=14 & \redx & 256 & 74.62 & 331 & 5.69 & 1.70 & 4970 \\
          DeiT-Ti p=8  & \redx & 784 & 77.44 & 824 & 5.72 & 7.06 & 1243 \\ % nvpyhg3ggh
          RGB No More DeiT-Ti \cite{rgbnomore} & \redx & 196 & 75.1 & - & 5.72 & 1.26 & 6885 \\
          \midrule
          Perceiver (learned pos) \cite{perceiver}   & \yellowcheck & N/A  & 67.6 & - & 55.9 & 62.3 & -\\
          Perceiver IO (learned pos) \cite{perceiverio} & \yellowcheck & N/A & 72.7 & - & 62.3 & 407 & -\\ 
          Perceiver (conv) \cite{perceiver} & \yellowcheck & N/A & 77.4 & - & 42.1 & 367 & -\\
          Perceiver IO (conv) \cite{perceiverio} & \yellowcheck & N/A & 82.1 & - & 48.6 & 369 & -\\
          \midrule
          BF-Ti k=32& \greencheck & 9415 & 77.27 & 1314 & 8.82 & 23.74 & 373 \\ % c5bw66inem
          BF-Ti k=32 -C & \greencheck & 9415 & 74.54 & 1122 & 7.64 & 12.63 & 370 \\ %xafcypsdgj
          BF-Ti k=32 -C -NPE & \greencheck & 9415 & 68.42 & 1121 & 5.83 & 12.63 & 372 \\ % 2fgirt9zmt
          \midrule
          BF-Ti k=4 f0.05        & \greencheck & 3762 & 67.53 & 368 & 6.70 & 5.70 & 1687 \\ % wne342kzhv
   %BF-Ti k=4 f0.05 -C -NE        & \greencheck & 3762 & 45.59 & 351 & 5.83 & 5.14 & 1721 \\ % jj7uzxmcc3
          BF-Ti k=4 f=0.1         & \greencheck & 7524 & 71.26 & 580 & 7.42 & 11.07 & 875 \\ % eisxkgu6pq
          %BF-Ti k=4 f=0.1 -C -NE  & \greencheck & 7524 & 51.01 & 563 & 5.83 & 9.97 & 894 \\ % 7bu99fb78v
          BF-Ti k=8 f=0.25        & \greencheck & 9407 & 73.65 & 769 & 7.93 & 15.40 & 634 \\ % jx4h7rtc8d
          %BF-Ti k=8 f=0.25 -C -NE & \greencheck & 9407 & 58.21 & 732 & 5.83 & 12.63 & 645 \\ % xzuetndyqs 
          \bottomrule[1.5pt]
    \end{tabular}
    }
    \caption{ImageNet Top-1 accuracy. \textbf{M}: whether the model accepts various modalities (\redx: No. \yellowcheck: Yes, but with modality-specific modeling. \greencheck: Yes). \textbf{$\mathbb{E}[L_t]$}: length of token inputs to transformer (after Conv1D for BF-Ti. Note, Perceiver feeds inputs through cross-attention, so this concept doesn't directly apply). \textbf{Sec}: Train epoch time (only reported for models we train to avoid hardware differences affecting results). \textbf{P (M)}: Number of parameters (millions). \textbf{F (B)}: Number of flops (billions). \textbf{Im/s}: Throughput (images/sec) on an A100 80GB Nvidia GPU. ``-'' means ``not reported''. For DeiT, $p$ is patch size. Choosing $p \le 4$ is unfeasible (epochs take hours or days). For BF-Ti, $k$ is conv kernel size, and $f$ indicates fraction of retained pixels for privacy-preserving camera experiments (\autoref{sec:experiments-privacy-preserving-camera}). ``-C'' indicates replacement of Conv1D with a windowed mean. ``-NPE'' indicates an ablation that removes the positional embedding.
    }
    % TODO mention batch size non-variable.
    \label{table:perf}
\end{table}

\begin{comment}
    
\section{Multimodal Experiment}
% TODO include this when finished.

\begin{table}[]
    \centering
    \resizebox{\columnwidth}{!}{
    \begin{tabular}{lcccc}
        \toprule[1.5pt]
         \textbf{Balanced?} & Finished? & Top-1 & IN Top-1 & SC2 Top-1 \\
         \midrule
          No & Yes & 75.12 & 77.47 & 85.71 \\
          Yes & No (Ep 199/300) & 74.93 & 73.16 & 95.43 \\
          \bottomrule[1.5pt]
    \end{tabular}
    }
    \caption{
    Joint image and audio classification (TIFF and WAV-FP32). \textbf{Top-1}: The top-1 accuracy on 1012-way joint classification (image+audio). \textbf{IN Top-1}: The top-1 on 1000-way image classification. \textbf{SC2 Top-1}: The top-1 on 12-way audio classification. Note, the IN training set is 33x as large as SC2. We optionally add class balancing (replicating Speech Commands v2 by 33x; it's still training).
}
    \label{table:multimodal}
\end{table}
\end{comment}
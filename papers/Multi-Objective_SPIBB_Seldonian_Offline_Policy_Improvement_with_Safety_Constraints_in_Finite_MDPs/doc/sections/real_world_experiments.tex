% \pagebreak

\section{Real-world experiment}
\label{sec:sepsis-experiments}


% --------
% Give the brief task description (SEPSIS),  the context of RL for sepsis,
% --------
In order to validate the applicability of our methods on a real-world  task, 
we consider recent works on %the improvement of 
sepsis management via RL, where we only have access to a pre-collected patient dataset and goal is to recommend treatment strategies for patients with sepsis in the ICU \citep{komorowski2018artificial,tang2020clinician}.
% \citep{raghu2017deep, komorowski2018artificial,tang2020clinician}.
Sepsis is defined as a life-threatening organ dysfunction caused by a dysregulated host response to an infection \citep{singer2016third}.
The main treatment method of sepsis involves the repeated administration of intravenous (IV) fluids and vasopressors, but how to manage their appropriate doses at the patient level is still a key clinical challenge \citep{rhodes2017surviving}. 
%\citep{rhodes2017surviving, byrne2017fluid}. 


% --------
% Here how we aim to use this Sepsis task
% --------
% The problem is safety-critical as our methods need to be cautious about using the data that was possibly collected under unobservable confounders and other biases that can lead to biased model estimates. 
% For instance, a study by \citet{ji2020trajectory} of the model used in \citet{komorowski2018artificial} found that the learned model suffers from two major kinds of limitations when it comes to clinically implausible behavior.
% The first kind of challenges are related to the inaccurate modelling assumptions such as discretization of time, and are not the focus of this work. 
% The second aspect, where we believe our methodology can help, is to prevent unexpectedly aggressive treatments resulting from small sample sizes.
% We propose to do so by incorporating safety constraints to prevent recommending the treatments decisions that were never or rarely performed in the dataset. 
% 

The problem is safety-critical as our methods need to be cautious about using the data that was possibly collected under unobservable confounders and that can lead to biased model estimates. 
For instance, a study by \citet{ji2020trajectory} of the model used in \citet{komorowski2018artificial} found that the learned model suggests clinically implausible behavior in the form of unexpectedly aggressive treatments.
We show that our methodology can be applied here to prevent such behavior that results from small sample sizes. We propose to do so by incorporating safety constraints to prevent recommending the treatment decisions that were never or rarely performed in the dataset. 

% against such propose to do so by incorporating safety constraints to prevent recommending the treatments decisions that were never or rarely performed in the dataset. 

% We believe our methodology here can help to prevent clinically implausible behavior that
% We believe our methodology can help prevent unexpectedly aggressive treatments resulting from small sample sizes.



% --------
% Data/Cohort 
% --------
% \textbf{Data and Cohort design:} 
% We use the publicly available ICU dataset MIMIC-III  \cite{johnson2016mimic}, with the setup described by \citet{komorowski2018artificial, tang2020clinician} and build on top of their data pre-processing methodology
% % The cohort is defined by adults fulfilling the sepsis-3 criteria \citep{singer2016third}
% , that includes prescription of antibiotics, lab work of bodily fluids and a Sequential Organ Failure Assessment (SOFA) score $\geq 2$ \citep{singer2016third}. 
% After applying the exclusion criteria \citep{komorowski2018artificial} we are left with a cohort of 20,954 unique patients. 
% --------
% Methodology recap 
% --------
% \textbf{MDP construction:} 
% We follow the MDP construction procedure by \citet{komorowski2018artificial, tang2020clinician} and very briefly describe the methodology here

\textbf{Data and MDP Construction:} 
We use the publicly available ICU dataset MIMIC-III  \citep{johnson2016mimic}, with the setup described by \citet{komorowski2018artificial, tang2020clinician} and build on top of their data pre-processing and MDP construction methodology.\footnote{A caveat here is regarding the underlying assumption that the MDP construction methodology by \citet{komorowski2018artificial, tang2020clinician} maintains the Markovian property in the discretized state-space.} 
This leaves us with a cohort of 20,954 unique patients. 
% The patient data is discretized into 4-hour windows, each of which is pre-processed to be treated as a single time-step.
The state-space consisting of 48 clinical variables summarizing features like demographics, physiological condition, laboratory values, etc., is discretized using a k-means based clustering algorithm to map the states to 750 clusters.
The actions include administration of IV fluids and vasopressors, which are categorized into 5 dosage bins each, leading to a total of $|\A|=25$. The $\gamma$ is set to $0.99$. The reward is based on patient mortality. The agent gets a reward, $r_0$, of $\pm 100$ at the end of the episode based on the survival of the patient. More details can be found in \Cref{app:sepsis-dataset}.


In the original work, the rare state-actions taken by the clinicians (state-action pairs observed infrequently in the training set) are removed from the dataset. Instead of removing them,
% in the pre-processing, 
we define an additional reward, $r_1$, based on the rarity of the state-action pair. We define rare state-action pairs to be those that are taken less than 10 times throughout training dataset, and the agent gets a reward of $-10$ for every such rare state-action taken, i.e.,  $r_1(x,a) = -10.0 \text{ if } \texttt{Count}(x,a) < 10$.
The final task objective then becomes to suggest treatments that handles the trade-off between prioritizing improving the survival vs prioritizing commonly used treatment decisions.


% --------
% Evaluation 
% --------
\textbf{Evaluation:} 
We compare our approach with the same baselines from \Cref{sec:synthetic-experiments} on different $\bml$ combinations.  
We run our methods for 10 runs with different random seeds, where for each run the cohort dataset was split into train/valid/test sets in the ratios of 0.7/0.1/0.2.
We evaluate the performance of the solution policies returned by different methods on the test sets using two different OPE methods, Doubly Robust (DR) \citep{jiang2015dependence} and Weighted Doubly Robust (WDR) \citep{thomas2016data}.
We acknowledge that these methods are a proxy of the actual performance of the deployed policies. Hence, these results should not be misinterpreted as us claiming that the policies returned by our methods are now ready to be used in the ICU. 
% and much more details would be needed before quantifying a policy's performance in the actual clinical setting. Hence, 

% -- Result table

\begin{table*}[ht!]
\centering
\caption{Performance of various methods using DR and WDR estimators with mean and standard deviation on 10 random splits of the cohort dataset. The red cells denote the corresponding safety constraint violation, i.e, either $\mathcal{J}_{0}^{\pi} < \mathcal{J}_{0}^{\pib}$ or $-\mathcal{J}_{1}^{\pi} > -\mathcal{J}_{1}^{\pib}$.}
\label{table:sepsis-best-results}
\begin{adjustbox}{max width=1\textwidth,center}
\begin{tabular}{cccccc}
\toprule
\multicolumn{1}{c}{User preference $(\bml)$} & \multicolumn{1}{c}{Policy} & \multicolumn{2}{c}{Survival return ($\mathcal{J}_0$)} & \multicolumn{2}{c}{Rare-treatment return ($- \mathcal{J}_1$)} \\
\hline
& & DR & WDR & DR & WDR  \\  \cline{3-6}
& Clinician's ($\pib$) & 64.78 $\pm$ 0.90 & 64.78 $\pm$ 0.90          & 13.58 $\pm$ 0.19 & 13.58 $\pm$ 0.19  \\
\midrule % \hline \hline
\multirow{4}{*}{$[\lambda_0=1, \lambda_1 = 0]$} 
& Linearized & 97.68 $\pm$ 0.22 & 97.58 $\pm$ 0.20   & \textcolor{red}{27.64 $\pm$ 1.11 }& \textcolor{red}{27.84 $\pm$ 1.09 } \\ 
& Adv-Linearized  & 91.62 $\pm$ 0.46 & 92.68 $\pm$ 0.23   & \textcolor{red}{15.18 $\pm$ 0.59 }& 13.56 $\pm$ 0.42 \\
& \ref{eq:s-opt}   & 66.11 $\pm$ 0.87 & 66.05 $\pm$ 0.86   & 13.42 $\pm$ 0.20 & 13.46 $\pm$ 0.20   \\
& \ref{eq:h-opt} & 65.95 $\pm$ 0.00 & 65.95 $\pm$ 0.00   & 13.37 $\pm$ 0.00 & 13.37 $\pm$ 0.00  \\
\midrule 
\multirow{4}{*}{$[\lambda_0=1, \lambda_1 = 1]$}
& Linearized & 87.17 $\pm$ 0.48 & 89.11 $\pm$ 0.37   & 2.41 $\pm$ 0.47 & 1.52 $\pm$ 0.41\\
& Adv-Linearized  & 86.77 $\pm$ 0.49 & 88.58 $\pm$ 0.25   & 2.53 $\pm$ 0.50 & 1.57 $\pm$ 0.43  \\
& \ref{eq:s-opt}  & 86.77 $\pm$ 0.49 & 88.58 $\pm$ 0.25   & 2.53 $\pm$ 0.50 & 1.57 $\pm$ 0.43   \\
& \ref{eq:h-opt} & 86.37 $\pm$ 0.00 & 88.03 $\pm$ 0.00   & 2.58 $\pm$ 0.00 & 1.43 $\pm$ 0.00  \\
\midrule 
\multirow{4}{*}{$[\lambda_0=0, \lambda_1 = 0]$}
& Linearized & \textcolor{red}{-89.39 $\pm$ 0.43} & \textcolor{red}{-90.90 $\pm$ 0.29 }  & \textcolor{red}{22.99 $\pm$ 0.40 }& \textcolor{red}{22.81 $\pm$ 0.30 }  \\ 
& Adv-Linearized  & \textcolor{red}{60.27 $\pm$ 0.49} & \textcolor{red}{61.44 $\pm$ 0.85 }  & \textcolor{red}{18.40 $\pm$ 0.27 }& \textcolor{red}{15.36 $\pm$ 0.58 }  \\
& \ref{eq:s-opt} & 67.73 $\pm$ 0.82 & 67.22 $\pm$ 0.88   & 13.24 $\pm$ 0.24 & 13.55 $\pm$ 0.33  \\
& \ref{eq:h-opt} & 65.95 $\pm$ 0.00 & 65.95 $\pm$ 0.00   & 13.37 $\pm$ 0.00 & 13.37 $\pm$ 0.00  \\
\midrule %\hline \hline
\multirow{4}{*}{$[\lambda_0=0, \lambda_1 = 1]$}
& Linearized & \textcolor{red}{58.27 $\pm$ 2.18} & \textcolor{red}{60.52 $\pm$ 2.07 }  & 0.04 $\pm$ 0.03 & 0.02 $\pm$ 0.01  \\ 
& Adv-Linearized  & 76.05 $\pm$ 0.65 & 76.85 $\pm$ 0.72   & 0.07 $\pm$ 0.05 & 0.04 $\pm$ 0.03  \\
& \ref{eq:s-opt}  & 76.07 $\pm$ 0.65 & 76.87 $\pm$ 0.73   & 0.07 $\pm$ 0.05 & 0.04 $\pm$ 0.03  \\
& \ref{eq:h-opt} & 76.54 $\pm$ 0.00 & 77.55 $\pm$ 0.00   & 0.09 $\pm$ 0.00 & 0.05 $\pm$ 0.00  \\
\bottomrule 
\end{tabular}
\end{adjustbox}
\vskip -0.1in
\end{table*}


% --------
%  Results
% --------
\textbf{Results:}
We refer to the return associated with the mortality reward ($r_0$) as survival return ($\mathcal{J}_{0}$), and the negative return associated with rare state-action reward ($r_1$) as rare-treatment return ($- \mathcal{J}_{1}$). Higher survival return implies more successful discharges, and lower rare-treatment return implies more adherence to common practice treatment decisions.
We present the results on survival and rare-treatment returns 
% with mean and standard deviation for the 10 runs 
in \Cref{table:sepsis-best-results}. 
% As expected, we observe the Linearized baseline violates most of the constraints across different $\bml$. The Adv-Linearized baseline performs better than Linearized, but still ends up violating some constraints, possibly due to unreliable estimates.
% We observe the Linearized baseline violates most of the constraints across different $\bml$. The Adv-Linearized baseline performs a bit better, but still ends up violating some constraints, possibly due to unreliable estimates.
% We expect both \ref{eq:s-opt} and \ref{eq:h-opt} to respect the safety constraints 
% irrespective of the $\bml$, and indeed they are able to do so.
As expected, we observe both the Linearized and Adv-Linearized baselines violates constraints across different $\bml$, whereas \ref{eq:s-opt} and \ref{eq:h-opt} are able to respect the safety constraints irrespective of the $\bml$.\footnote{In \Cref{table:sepsis-best-results}, $\bml =[1,1]$ represents a rare case of reward scalarization that allows all the methods to find a good solution policy that satisfies the constraints.  In general, it is difficult to find such scalarization parameters as seen in synthetic experiments (\Cref{app:cmdp-fixed-param-results}).}
The validation set was used to tune the hyper-parameters, and we report how the performance varies with different hyper-parameters in \Cref{app:sepsis-hyperparams}. 




% --------
% Qualitative Results 
% --------
\textbf{Qualitative Analysis:} 
We conclude with a qualitative analysis of the policies returned from our setting and the traditional RL approach of maximizing just the survival return. 
% We calculate how many rare-actions are recommended by different solution policies and compare them with the most common actions taken by the clinicians.
% For each state, for the action recommended by a solution policy, we calculate the frequency with which that state-action was observed in the training data and calculate the percentage of time that state-action pair was observed among all the possible actions taken from that state.
% Across all the states, the actions suggested by the traditional single-objective RL baseline are observed only 3\% of the time on average (5.3 observations per state). Whereas, the actions most commonly chosen by the clinicians  are observed 51.4\% of the time on average (138.2 observations per state). We study this behavior for two of the policies returned by MO-SPIBB that deviate the most from the baseline: for the policy returned by \ref{eq:s-opt} ($\bml=[1,1]$) the recommended actions are observed 24.8\% of time on average (61.0 observations per state) and for  \ref{eq:s-opt} ($\bml=[0,1]$) the recommended actions are observed 23.4\% of times (56.14 observations per state).
%
\citet{ji2020trajectory} found that the RL-policies for sepsis-management task usually end up recommending aggressive treatments, particularly high vasopressor doses for states where the common practice 
(according to most frequent action chosen by the clinician for that state) 
is to give no vasopressors at all. The common practice involves giving zero vasopressors for 722 of the 750 states. However, the policy returned by the traditional single-objective RL baseline recommends vasopressors in 562 (77.84\%) of those 722 states, with 295 of those recommendations being large doses
% , where large doses are defined as the dosages belonging in the upper 50th percentile of nonzero amounts 
(upper 50th percentile of nonzero amounts  or $>0.2$ $\mu$g/kg/min). 
We compare these statistics for two of the policies returned by MO-SPIBB that deviate the most from $\pib$. 
The policy returned by \ref{eq:s-opt} ($\bml=[1,1]$) recommends vasopressors in only 93 of those states (12.88 \%), with 47 of those recommendations belonging to high dosages. The other policy, \ref{eq:s-opt} ($\bml=[0,1]$), recommends vasopressors in 134 (18.56 \%) of those states and 70 of those recommendations fall in large dosages.
Therefore, the policies returned by our approach, even when they deviate from the baseline, are less aggressive in recommending rare treatments. 
In \Cref{app:sepsis-qual-analysis}, we present an additional qualitative analysis that demonstrates our methods recommend lesser rare-action treatments than the traditional single-objective RL approach.

% This is on argument against why include rare-action as costs.
An argument can be made against the case when all rare state-action pairs are removed from the training data itself. This will ensure that any learned policy will have near 0 rare-treatment return. However, it is not always clear how to define the cut-off criteria for rare-actions, and it might be possible that some of these rare state-action pairs are actually crucial for finding a better policy. 
For instance, we did an experiment where we assigned state-actions pairs with frequency $<100$ to be rare state-action pairs and filtered those from the training set. The clinician's performance on the test set using a DR estimator for survival return is 65.95. % (and $C$: 59.63).
In this case, the traditional single-objective RL baseline gives the survival return of 11.26, %(and $C$: 18.40), 
which shows that removing such transitions from the dataset actually hampers the solution quality. Our approach of assigning a separate reward for rare state-action pairs is able to find a solution with a survival return of 86.75 %(and $C$: 24.66)
even in this scenario.





\section{Additional details for synthetic CMDP experiments}
\label{app:additional-details-for-synthetic-exp}


% ------------------------------------------------------
%               Solving CMDP
% ------------------------------------------------------
\subsection{Solving CMDP}
\label{app:cmdp-solver}

Constrained-MDPs~\citep{altman1999constrained} are MDPs with multiple rewards where $r_0$ is the main objective, and $r_1, \dots, r_{n-1}$ are the reward signals that are used to enforce some behavior or constraints. 

Let $\J{\pi}{i}{m}(\mu)$ denote the total expected discount reward under $r_i$ in an MDP $m$, when $\pi$ is followed from an initial state chosen at random from $\mu$, the initial state distribution. 
For some given reals $c_1, \dots, c_n$ (each corresponding to $r_i$), the CMDP optimization problem is to find the policy that maximizes the $\J{\pi}{0}{m}(\mu)$ subject to the constraints $\J{\pi}{i}{\mopt}(\mu) \le c_i$ :
\begin{align}
    \label{eq:cmdp-obj}
    &\max_\pi \J{\pi}{0}{m}(\mu) \\ 
        \quad \text{ s.t. } & \J{\pi}{i}{m}(\mu) \le c_i, \, \forall i \in \{1,\dots,n-1\}. \nonumber
\end{align}
    
% CMDPs have many interesting properties that make it different from regular MDPs. One particular property is the lack of deterministic optimal policies that makes reward shaping (or reduction to regular) not always possible .

The Dual LP based algorithm for solving CMDP is based on the occupation measure w.r.t. the optimal policy $\piopt$. For any policy $\pi$ and initial state $x_0 \sim \mu(\cdot)$, the occupancy measure is described as:
\begin{align*}
    \rho^{\pi}(x,a) &= \E \left[ \sum_{t=0}^{\infty} \gamma^t \mathbbm{1}\{x_t=x, a_t=a\} \Big| x_0, \pi \right], \forall x \in \X, \forall a \in \A. 
\end{align*}
The occupation measure at any state $x \in X$ is defined as $\sum_{a} \rho^{\pi}(x,a)$.  From \citep[Chapter 9]{altman1999constrained}, the problem of finding the optimal policy for a CMDP can be solved by the solving the following LP problem: %$2|\X||\A| +1 $
\begin{align*}
    \max_{\rho}  &\quad \sum_{x \in \X, a \in \A} \rho(x,a) r_0(x,a) \\  
    \texttt{s.t.}  &\quad \sum_{x \in \X, a \in \A} \rho(x,a) r_i(x,a) \leq c_i, \; \forall i \in \{1,\dots,n-1\}.
\end{align*}
 As $\rho$ is the occupation measure it also needs to satisfy the following constraints $\forall x \in \X$:
\begin{align*}
    \rho(x,a) &\geq 0,  \quad \forall a \in \A \\
    \sum_{x_p \in \X, a \in \A} \rho(x_p,a) (\mathbbm{1}\{ x_p = x\} - p(x|x_p,a))  &= \mathbbm{1}\{ x=x_0 \}
\end{align*}
The above constraints originate from the conservation of probability mass of a stationary distribution on a Markov process.  The state-action visitations should satisfy the single-step transpose Bellman recurrence relation:
\begin{equation*}
    \rho^{\pi}(x,a) = (1-\gamma) \mu(x) \pi(a|x) + \gamma \cdot p_{T}^{\pi} \rho^{\pi}(x,a), 
\end{equation*}
where transpose policy transition operator $p_{T}^{\pi}$ is a linear operator and is the mathematical transpose (or adjoint) of $p^{\pi}$ in the sense that $<y, p^{\pi}x> = <p_{T}^{\pi} y, x>$ for any $x, y$:
\begin{equation*}
    p_{T}^{\pi} \rho(x,a) \doteq \pi(a|s)\sum_{\tilde{x}, \tilde{a}} p(x|\tilde{x}, \tilde{a}) \rho(\tilde{x}, \tilde{a})
\end{equation*}
% Therefore the total number of constraints are 3|X||A|+1
% The above relations are used to define the \textit{transpose Bellman operator} \citep{nachum2019algaedice}:
% \begin{equation*}
%     \mathcal{B}^{T}_{\pi}(\rho)(x',a') \doteq \gamma \sum_{x,a} \pi(a'|x') P(x'|x,a) \rho(x,a) + (1-\gamma) \mu_{x_0}(x') \pi(a'|x').
% \end{equation*}

In conclusion, the complete dual problem can be written as:
\begin{align}
    \label{eq:cmdp-opt}
    \max_{\rho: \X \times \A \rightarrow \mathbb{R}_{+}}  &\quad \sum_{x \in \X, a \in \A} \rho(x,a) r_0(x,a) \\  
    \texttt{s.t.}  &\quad \sum_{x \in \X, a \in \A} \rho(x,a) r_i(x,a) \leq c_i,  \; \forall i \in \{1,\dots,n-1\}, \nonumber \\
    % &\quad \rho(x',a') = \sum_{x,a} \pi(a'|x') P(x'|x,a) \rho(x,a) + (1-\gamma) \mu_{x_0}(x') \pi(a'|x'), \tag{$\forall (x',a') \in \X \times \A$}\\
    % &\quad \sum_{a'} \rho(x',a') = \sum_{x,a} P(x'|x,a) \rho(x,a) + \mu_{x_0}(x'). \tag{$\forall x' \in \X$}
    &\quad \sum_{a} \rho(x,a) = \sum_{\tilde{x},\tilde{a}} p(x|\tilde{x},\tilde{a}) \rho(\tilde{x},\tilde{a}) + \mu(x). \tag{$\forall x \in \X$}
\end{align}


The solution of the above problem $\rho^{\star}$ gives the optimal (stochastic) policy of the form:
\begin{align*}
    \piopt(a|x) &= \frac{\rho^{\star}(x,a)}{\sum_a \rho^{\star}(x,a)} , \forall x \in \X, \forall a \in \A. 
\end{align*}


% ------------------------------------------------------
%               Fixed param details
% ------------------------------------------------------
\subsection{Additional results with fixed hyper-parameters}
\label{app:cmdp-fixed-param-results}

\Cref{fig:delta-0x1-params-grid} gives the individual plots for different $\bml, \rho$ combinations corresponding to the plot in \Cref{fig:delta-params-mean}. This is the fixed parameters setting in \Cref{sec:synthetic-experiments} where the same set of parameters are used across different $\bml, \rho$ combinations. Here, we run \ref{eq:s-opt} with $\epsilon \in \{0.01, 0.1, 1.0\}$ and \ref{eq:h-opt} with Doubly Robust IS estimator \citep{jiang2015doubly} and student's t-test.  
% The failure rate is less than $\delta$ for all the cases except for $\lR=0,\lC=1,\rho=0.9$ \cref{fig:delta-params-grid}, where only \ref{eq:h-opt} ends up with a failure rate $> \delta$. The only way \ref{eq:h-opt} can violate the constraints is either due to bad IS estimator or approximate CI that are not representative of the underlying distribution. By using an exact CI like Bernstein's inequality, we can make sure the failure rate is $< \delta$, however that CI is too conservative, and always returns the baseline as the solution for any of the $\lR, \lC, \rho$ combination.
The mean results with $\delta=0.9$ can be found in \Cref{fig:extra-delta-0.9-params-mean}. A more detailed plot containing the $\bml, \rho$ wise breakdown can be found in \Cref{fig:extra-delta-0.9-params-grid}.


\begin{figure*}
  \includegraphics[width=\textwidth]{doc/figures/random-mdps/delta_0x1_grid_sem.png}
  \caption{Results on random CMDPs with fixed parameters and $\delta=0.1$. 
  The different agents are represented by different markers and color lines. 
  Each point on the grid, corresponding to a $\bml, \rho$ combination, denotes the mean (with standard error bars) for the 100 randomly generated CMDPs. 
  The x-axis denotes the amount of data the agents were trained on. They y-axis for the top subplot in a grid cell represents the improvement over baseline and the y-axis for bottom subplot in a grid cell denotes the failure rate.
  The dotted black line represents the high-confidence parameter $\delta=0.1$.
  }
  \label{fig:delta-0x1-params-grid}
\end{figure*}


\begin{figure}
    \centering
  \includegraphics[scale=0.4]{doc/figures/random-mdps/delta_0x9_mean_sem.png}
  \caption{
  Mean results on random CMDPs with fixed parameters and $\delta=0.9$. 
  The different agents are represented by different markers and color lines. 
  Each point on the plot denotes the mean (with standard error bars) for 12 different $\bml,\rho$ combinations for the 100 randomly generated CMDPs (1200 datapoints). 
  The x-axis denotes the amount of data the agents were trained on. They y-axis for the left subplot represents the improvement over baseline and the y-axis for the right subplot in a grid cell denotes the failure rate.
  The dotted black line represents the high-confidence parameter $\delta=0.9$.
  }
  \label{fig:extra-delta-0.9-params-mean}
\end{figure}


\begin{figure*}
  \includegraphics[width=\textwidth]{doc/figures/random-mdps/delta_0x9_grid_sem.png}
  \caption{
  Results on random CMDPs with fixed parameters and $\delta=0.9$. 
  The different agents are represented by different markers and color lines. 
  Each point on the grid, corresponding to a $\bml, \rho$ combination, denotes the mean (with standard error bars) for the 100 randomly generated CMDPs. 
  The x-axis denotes the amount of data the agents were trained on. They y-axis for the top subplot in a grid cell represents the improvement over baseline and the y-axis for bottom subplot in a grid cell denotes the failure rate.
  The dotted black line represents the high-confidence parameter $\delta=0.9$.
  }
  \label{fig:extra-delta-0.9-params-grid}
\end{figure*}



% ------------------------------------------------------
%               Best params
% ------------------------------------------------------
\subsection{Additional results with tuned hyper-parameters}
\label{app:cmdp-best-param-results}

\Cref{fig:best-params-grid} gives the individual plots for different $\bml, \rho$ combinations corresponding to the plot in \Cref{fig:best-params-mean}.
The best hyper-parameters are tuned in a single environment and then are used to benchmark the results on 100 random CMDPs. The following procedure is used for selecting the best hyper-parameter candidates: We first generate a random CMDP and run different hyper-parameters on that environment instance. Next, we filter the candidates that violate the safety-constraint in that CMDP instance. From the remaining candidates, we select the one that yields the highest improvement over $\pib$. 

For \ref{eq:s-opt}, we searched for $\epsilon \in \{1e^{-4}, 1e^{-3}, 1e^{-2}, 1e^{-1}, 0.5, 1.0, 2.0, 5.0\}$. For \ref{eq:h-opt}, we used student's t-test with the following $\IS$ estimators: Importance Sampling (IS), Per Decision IS (PDIS), Weighted IS, Weighted PDIS and Doubly Robust (DR) \citep{precup2000eligibility, jiang2015doubly}.




\begin{figure*}
  \includegraphics[width=\textwidth]{doc/figures/random-mdps/benchmark_best_params_delta_0x1_grid.png}
  \caption{
  Results on 100 random CMDPs for different $\bml, \rho$ combinations with best $\epsilon, \IS$ combination for $\delta=0.1$.
  The different agents are represented by different markers and color lines. 
  Each point on the grid, corresponding to a $\bml, \rho$ combination, denotes the mean (with standard error bars) for the 100 randomly generated CMDPs. 
  The x-axis denotes the amount of data the agents were trained on. They y-axis for the top subplot in a grid cell represents the improvement over baseline and the y-axis for bottom subplot in a grid cell denotes the failure rate.
  The dotted black line represents the high-confidence parameter $\delta=0.1$.
  }
  \label{fig:best-params-grid}
\end{figure*}


% Just looking from the mean across different combinations we can say that \ref{eq:s-opt} performs better on average, on average, in terms of improvement while satisfying $< \delta$ failure rate. However, from \Cref{fig:best-params-mean}, we see that choosing the best hyper-param just based on 1 run can sometimes lead to an aggressive $\epsilon$ that makes \ref{eq:s-opt} having higher failure rate $> \delta$ for a few combinations (compared to \ref{eq:h-opt} that violates it only for one combination). Maybe if we chose hyper-params smartly we can optimize further? Does that add any value?


We plot the results based on the optimized hyper-parameters for a single CMDP in \Cref{fig:10x10-gridworld-seed-0} . Here, we plot the individual performance w.r.t $r_0$ (goal reward) and $r_1$ (pit reward) for multiple agents along with the baseline's performance.  Instead of working with surrogate measures, we investigate the returns for both $\J{\pi}{r_0}{\mopt}$ and $- \J{\pi}{r_1}{\mopt}$, and see what kind of scenarios lead to violation (all the returns are normalized in $[0,1]$). In \Cref{fig:10x10-gridworld-seed-0}, the intersection of the red and blue lines denotes the performance of the baseline in the true MDP.  As we observed in the mean plots, the Linearized baseline violate most of constraints for all the dataset sizes. The Adv-Linearized baseline violates the constraints mostly for low data settings ($\blacktriangledown$ marker with darker shades). There are more violations for higher values of $\rho$ as the $\pib$ gets better and the task gets tougher. We can observe that both \ref{eq:s-opt} and \ref{eq:h-opt} based agents (denoted by $\star$ and $\blacksquare$ markers) never leave the top-left quadrant and consistently satisfy the constraints. We also observe that the deviation from the origin increases with the increase in dataset size (represented via color of the agent).

\begin{figure*}
  \includegraphics[width=\textwidth]{doc/figures/random-mdps/qual_analys_best_params.png}
  \caption{
  Results on a random $10 \times 10$ synthetic CMDP. Each $\bml$ and $\rho$ combination represents a different setting denoted by the corresponding cell in the grid. The different agents are represented by different markers and the color of the marker denotes the amount of data the agent was trained on. 
  The x-axis for individual plots are normalized $- \mathcal{J}^{\pi}_{\mopt, r_1}$ returns (for pits), and y-axis are normalized $\mathcal{J}^{\pi}_{\mopt, r_0}$ returns (for goal).
  The red line denotes the performance of the baseline w.r.t. $- \mathcal{J}^{\pib}_{\mopt, r_1}$, and the blue line for $\mathcal{J}^{\pib}_{\mopt, r_0}$. For each plot in the grid, only the points in the top-left quadrant (defined by baseline's performance via red and blue lines) satisfy the constraint for that task.
  }
  \label{fig:10x10-gridworld-seed-0}
\end{figure*}


% ------------------------------------------------------
%               Lagrangian experiments
% ------------------------------------------------------
\subsection{Comparison with \cite{le2019batch}}
\label{app:lag-baseline}



\begin{figure}[t]
\centering
\begin{subfigure}[b]{1\textwidth}
    \includegraphics[width=1\textwidth]{doc/figures/lag-baseline/fig_1.png}
    \caption{Comparisons of Lagrangian \citep{le2019batch} with $\eta = 0.01$ and MO-SPIBB (\ref{eq:s-opt}) with $\epsilon=0.1$.}
    \label{fig:lag-only-single-sopt} 
\end{subfigure}
\\
\begin{subfigure}[b]{1\textwidth}
    \includegraphics[width=1\textwidth]{doc/figures/lag-baseline/fig_all.png}
    \caption{MO-SPIBB (\cref{eq:s-opt}) and Lagrangian \citep{le2019batch} comparisons across different hyper-parameters.}
    \label{fig:lag-multiple-sopt}
\end{subfigure}
% }
\caption[]{
\small
Results on 100 random CMDPs for different $\bml$ and $\rho$ combinations with $\delta=0.1$. The different agents are represented by different markers and colored lines. Each point on the plot denotes the mean (with standard error bars) for 12 different $\bml,\rho$ combinations for the 100 randomly generated CMDPs (1200 datapoints).  The x-axis denotes the amount of data the agents were trained on. 
The y-axis for left subplot in each sub-figure represents the improvement over baseline and the right subplot denotes the failure rate. The dotted black line in the right subplots represents the high-confidence parameter $\delta=0.1$.
\Cref{fig:lag-only-single-sopt} denotes the case when MO-SPIBB (\ref{eq:s-opt}) is run with $\epsilon=0.1$, MO-HCPI (\ref{eq:h-opt}) with $\IS=$ Doubly Robust (DR) estimator with student's t-test concentration inequality, and Lagrangian \citep{le2019batch} with $\eta = 0.01$ . 
\Cref{fig:lag-multiple-sopt} shows how MO-SPIBB and Lagrangian perform across different hyper-parameters.
\label{fig:lag-combined-results}}
\vskip -0.1in
\end{figure}



We test the method by \cite{le2019batch} (henceforth referred to as Lagrangian) in the synthetic navigation CMDP task described in \Cref{sec:synthetic-experiments}. In \Cref{fig:lag-only-single-sopt}, we present the results for the best performing Lagrangian baseline on 100 random CMDPs for different $\bml$ and $\rho$ combinations with $\delta=0.1$. Similar to \Cref{fig:delta-params-mean}, we provide a more detailed plot of how the Lagrangian baseline performs with different hyper-parameters in the above setting in \Cref{fig:lag-multiple-sopt}.


% In the figure, each point on the plot denotes the mean (with standard error bars) for 12 different ,  combinations for the 10 randomly generated CMDPs (120 data points). The x-axis denotes the amount of data the agents were trained on. The y-axis for the left subplot represents the improvement over baseline and the right subplot denotes the failure rate. The dotted black line in the right subplot represents the high-confidence parameter . 
% The MO-SPIBB (\cref{eq:s-opt}) is run with $\epsilon=0.1$ and MO-HCPI (\cref{eq:h-opt}) with $\IS$ = Doubly Robust estimator with studentâ€™s t-test concentration inequality. Similar to \Cref{fig:delta-params-mean}, we provide a more detailed plot of how the Lagrangian baseline performs with different hyper-parameters in the above setting in \Cref{fig:lag-multiple-sopt}.

\textbf{Results:} As expected, we observe that the Lagrangian baseline has a high failure rate, particularly in the low-data setting. 
This makes sense as the guarantees provided by \cite{le2019batch} are of the form $\mathcal{J}^\pi_{k,m^{\star}} - \mathcal{J}^{\pi_{b}}_{k, m^{\star}} \geq - \frac{C}{(1-\gamma)^{3/2}}$ (Theorem 4.4 of \cite{le2019batch}), where $C$ is a term that depends on a constant that comes from the Concentrability assumption (Assumption 1 of \cite{le2019batch}). This assumption upper bounds the ratio between the future state-action distributions of any non-stationary policy and the baseline policy under which the dataset was generated by some constant. In other words, it makes assumptions on the quality of the data gathered under the baseline policy. Unfortunately, this assumption cannot be verified in practice, and it is unclear how to get a tractable estimate of this constant. As such, this constant can be arbitrarily large (even infinite) when the baseline policy fails to cover the support of all non-stationary policies, for instance, when the baseline policy is not exploratory enough or when the size of the dataset is small. Hence, we observe a high failure rate of \cite{le2019batch} in the experiments, especially in the low data setting. Compared to \cite{le2019batch}, our performance guarantees do not make any assumptions on the quality of the dataset or the baseline. Therefore, our approach can ensure a low failure rate even in the low-data regime.
%  in the low data setting the concentrability coefficient can be arbitrarily high, and therefore the performance guarantees provided by Le et al. do not hold anymore. As the size of the dataset increases, we observe that the failure rate of the Le et al. starts decreasing, which seems reasonable because with more data more reliable MDP parameters are estimated and the baseline policy now covers more support of the space of all non-stationary policies required for the concentrability assumption to be valid. In contrast, both the MO-SPIBB and MO-SPIBB can ensure low failure rates even in low-data scenarios.




\textbf{Implementation details and Hyper-parameters:} We build on top of the publicly available code of \cite{le2019batch} released by the authors and extend it to our setting. 
% In the accompanied code, we also provide a standalone Jupyter notebook Lagrange\_agent.ipynb that contains the implementation of Algorithm 2 of Le et al. (Section 1 of the notebook). 
We are confident that our implementation is correct as we made sure it passes various sanity tests such as convergence of the primal-dual gap and feasibility on access to true MDP parameters.

The algorithm in \cite{le2019batch} (Algorithm 2, Constrained Batch Policy Learning) requires the following hyper-parameters:

\begin{itemize}
    \item Online Learning Subroutine: We use the same online learning algorithm as used by the authors in their experiments, i.e. Exponentiated Gradient \citep{kivinen1997exponentiated}.
    
    \item Duality gap $\omega$ : This denotes the primal-dual gap or the early termination condition. We tried the values in $\set{0.01, 0.001}$ and fix the value to $0.01$.
    
    \item Number of iterations: This parameter denotes the number of iterations for which the Lagrange coefficients should be updated. We experimented in the range $\set{100, 250, 500}$ and set this to $250$.
    
    \item Norm bound $B$: The bound on the norm of Lagrange coefficients vector. We tried the values in $\set{1, 10, 50, 100}$ and fixed it $10$.
    
    \item Learning rate $\eta$: This parameter denotes the learning rate for the update of the Lagrange coefficients via the online learning subroutine. We found that this is the most sensitive variable and we tried with values in $\set{0.005, 0.01, 0.05, 0.1, 0.5, 1.0, 5.0}$. For the final experiments, we benchmark with three different values $(0.01, 0.1, 1.0)$ as mentioned in the \Cref{fig:lag-multiple-sopt}.
    
\end{itemize}

We would like to point out that the hyper-parameter tuning for the Lagrangian baseline can be particularly challenging as in the low-data setting none of the combinations of the above hyper-parameters can ensure a low failure rate even though the duality gap has converged. 

% Environments in Le et al.: Le et al. test their approach on two domains: a grid-world domain under safety constraint, and a high-dimensional car racing domain. The car racing domain takes the raw pixel image tensor as input, and as we mentioned in the limitations, it is out of the scope of our work. We would like to highlight that the grid-world domain and empirical methodology in Le et al. are considerably weaker than the approach we take in our work with respect to the safety constraints. This can be observed in Figure 2 (middle) of Le et al. where even the online-RL (equivalent to the Linearized baseline in our case) also has no constraint violation. Moreover, they do not experiment with the different sizes of the dataset  or the quality of the baseline under which the dataset was collected . Compared to that, we base our grid-world environments on the standard CMDP safety benchmarks [2,3], have comparisons against different dataset sizes and baseline quality parameters, and also explicitly calculate the failure rate.

The above experiments show the advantage of our approach over \cite{le2019batch}, particularly in the low-data safety-critical tasks, where our methods can improve over the baseline policy while ensuring a low failure rate. 






% ------------------------------------------------------
%               Scaling experiments
% ------------------------------------------------------
\subsection{Scaling experiments with number of objectives $d$}
\label{app:cmdp-scaling-experiments}

We experimented with the different number of objectives $d$ to validate if the trends we observed for \ref{eq:s-opt} and \ref{eq:h-opt} in \Cref{sec:synthetic-experiments} also extend to $d>2$. 
In the CMDP formulation, as there can only be one primary reward, we extend the CMDP to include more than 1 type of pits. The extended CMDP now has $d-1$ different kinds of pits and corresponding reward functions, where the agent gets a pit reward of $-1$ if the agent steps into a cell containing that particular kind of pit. We relax the CMDP threshold to $c_i = -10.0$ as the CMDP problem gets harder with more number of pits, and a lower threshold makes the problem of finding $\piopt$ of a random CMDP easier. Therefore, the task objective for the agent in the extended CMDP is to reach the goal in the least amount of steps, such that it can only step into at most 10 pits of every different type. 

We use the same experiment methodology from \Cref{sec:synthetic-experiments}. As the focus is to see how the trends scale with $d$, we fix the $\bml$, with $\lambda_0=1.0$ and the rest of $\lambda_{\ge 1}=0.0$.  We compare \ref{eq:s-opt} and \ref{eq:h-opt} over different $|\D|\in \{ 10, 50, 500, 2000\}$, $\rho \in \{0.1, 0.4, 0.7, 0.9\}$, the fixed set of parameters: $\IS$=DR, $\CI=$student's t-test, $\epsilon\in \{0.001, 0.01, 0.1, 1.0\}$, and $\delta=0.1$.

The results over 10 random CMDPs with fixed parameters can be found in \Cref{fig:scale-exp-10-runs-fixed-delta}. We notice that the trends from \Cref{sec:synthetic-experiments} case still carry till $d\le 1+16$, where for some value of $\epsilon$, \ref{eq:s-opt} can lead to better improvement in $\pib$ while still having failure rate $<\delta$. However, $d > 1+16$ we see there are no obvious trends and both \ref{eq:s-opt} and \ref{eq:h-opt} tend to become very conservative and returning the baseline becomes the best solution choice.


\begin{figure*}
  \includegraphics[width=\textwidth]{doc/figures/random-mdps/scale_exp_10runs_grid.png}
  \caption{Scaling with $d$ with results on a 10 random CMDPs and $\delta=0.1$. The different agents are represented by different markers and color. Each point on the graph denotes the mean for 100 runs, the standard errors is denoted by the error bars. The x-axis denotes the amount of data the agents were trained on. They y-axis for the top plot in a grid represents the improvement over baseline and the y-axis for bottom plot denotes the failure rate.
  }
  \label{fig:scale-exp-10-runs-fixed-delta}
\end{figure*}


% ------------------------------------------------------
%               Miscellaneuos details
% ------------------------------------------------------
\subsection{Additional details}

For the experiments in \Cref{sec:synthetic-experiments}, on an Intel(R) Xeon(R) Gold 6230 CPU (2.10GHz), the baselines take around 3 seconds to run, and both \ref{eq:s-opt} and \ref{eq:h-opt} take about 5 seconds.
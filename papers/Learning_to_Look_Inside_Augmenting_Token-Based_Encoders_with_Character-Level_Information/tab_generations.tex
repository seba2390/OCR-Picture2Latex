\begin{table*}
    \centering
    \footnotesize
    \begin{tabular}{lHcccccc}
        \toprule
        Model & Uncased BERT & BERT & \multicolumn{2}{c}{GPT-2} & \multicolumn{2}{c}{RoBERTa} \\ % 202102052207 & 202103171733 & 202104091857 & 202102260408 & 202103192237 & 202103192237 \\
        Corpus & Wikipedia & Wikipedia & Wikipedia & Twitter & Twitter & Twitter \\
        Steps & 76,000 & 9,000 & 13,500 & 21,000 & 7,500 & 57,500 \\
        Sequences ($10^3$) & 3,648 & 5,184 & 7,776 & 10,080 & 2,160 & 16,560 \\
         % 48x & 576x & 576x & 480x & 288x & 288x \\
         \midrule
        & ppercented & proming & crordman & d & orereren & everyone \\
        & or & dy & sssion & . & ant & kerned \\
        & ter & deded & gental & the & re & levernger \\
        & peprepored & terse & 2 & @ & cerent & and \\
        & essed & h & ther & ==666!!!!!!!!!!!!!!! & ennte & ed \\
         \bottomrule
    \end{tabular}
    \caption{Example generated words from random locations near the surface of the unit sphere in $\mathds{R}^{768}$.}
    \label{tab:gen}
\end{table*}


% More, from RoBERTa: Wiki-5\% after step 6,300 (576x):
% .<e> reenter<e> rencement<e> o<e> e<e> Äµ<e> ,<e> reciention<e> underesting<e> and<e>

% RoBERTa 13,000 Twitter-7.5\% (576x): reverally<e>	the<e>	revering<e>	.<e>	prot<e>	handers<e>	a<e>	there<e>	.<e>	@<e>




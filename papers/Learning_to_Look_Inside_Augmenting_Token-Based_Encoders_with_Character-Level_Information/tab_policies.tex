\begin{table*}
    \centering
    \tiny
    \begin{tabular}{ll}
        \toprule
        % Original & \texttt{Approx~~~~~~~~~~distance in miles from Bruges~~~~~~~to Amsterdam is 107 miles or 172.16 KMS~~~~.} \\
        % Tokenization & \texttt{A \#\#pp \#\#ro \#\#x distance in miles from B \#\#rug \#\#es to Amsterdam is 107 miles or 172 . 16 K \#\#MS .}  \\
        {\small Original} & \texttt{He was emphatically~~~~~a modern gentleman,~~of scrupulous~~~~~~~courtesy,~~sportive~~~gaiety,} \\ % acquainted with what was going on in the world.} \\
        {\small Word pieces} & \texttt{He was em \#pha \#tically a modern gentleman , of s \#c \#rup \#ulous courtesy , sport \#ive g \#ai \#ety ,} \\
        \midrule
        % \multirow{2}{*}{\small Random-20\%} & {\Monospace .9~.75~.15~~~~~~~~~~~~~.3~.05~~~~.55~~~~~~.6~.4~.7~~~~~~~~~~~~~~~.1~~~~~~.8~.25~~~~~~~~.45~~~~~~~.3} \\
        {\small Random-20\%} & \texttt{He was [TOK]~~~~~~~~~~~~a [TOK]~~gentleman , of s \#c \#rup \#ulous~[TOK]~~~~, sport \#ive g \#ai \#ety ,} \\
        {\small All-multi} & \texttt{He was [TOK]~~~~~~~~~~~~a modern gentleman , of [TOK]~~~~~~~~~~~~courtesy , [TOK]~~~~~~[TOK]~~~~~~,} \\
        {\small \textsc{Suffixes}} & \texttt{He was [TOK]~~~~~~~~~~~~a modern gentleman , of [TOK]~~~~~~~~~~~~courtesy , sport \#ive [TOK]~~~~~~,} \\
        \bottomrule
    \end{tabular}
    \caption{Example of token input selection by different policies,
    % (randomly-generated numbers determine the random policy) 
    where \texttt{[TOK]} signifies a word to be replaced by its character-based representation from \tok{}.
    Sentence fragment taken from the MS-MARCO QA dataset (see \S\ref{sec:tasks}) and tokenized using BERT-cased (\#\# replaced with \# to fit paper width).}
    \label{tab:policies}
\end{table*}


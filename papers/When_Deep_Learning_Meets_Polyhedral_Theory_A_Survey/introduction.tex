

\section{Introduction}
\label{sec:intro}
Deep learning has continuously achieved new landmarks in varied areas of artificial intelligence for the past decade. Examples of those areas include predictive tasks in computer vision \citep{Krizhevsky2012,Ciresan2012,Szegedy2015,He2016DeepRL,NoisyStudent}, natural language processing \citep{sutskever2014sequence,ELMo,GPT,BERT}, and speech recognition \citep{Hinton2012,EndToEndSpeech,SpecAugment}. 
The artificial neural networks behind such feats are being used in many applications, 
and there is a growing interest for analytical insights to %help designing such networks and leveraging what they can learn. 
help design such networks and then to leverage the model that they have learned. 
For the most commonly used types of neural networks, some of those results and methods are coming from operations research tools such as polyhedral theory and associated optimization techniques such as Linear Programming~(LP) and Mixed-Integer Linear Programming~(MILP). 
Among other things, 
these connections with mathematical optimization may help us understand what neural networks can represent, how to train them, and %subsequently 
how to make them more compact.
% Interest to understand how they work and how to explore their structure in different ways
For example, consider the popular task of classifying images (Figure \ref{fig:mnist}); polyhedral theory and associated optimization techniques may help us answer questions such as the following. How should we train the classifier model? How large should it be? How robust to perturbations is it?

\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{mnistclassification.png}
\caption{Example classification task on the MNIST database of handwritten digits, in which the image of a handwritten digit is given as input and the probability of that digit being from each possible class is provided as output.}
\label{fig:mnist}
\end{figure}

%\todo[inline]{TS: Should we add a friendly example of NN application here, including a figure? The description in the next paragraph could refer to such a picture.}

\subsection{What neural networks can model}

We can essentially think of artificial neural networks as functions mapping an input $\vx$ from a given domain to an output $\vy$ for a given application. 
For the classification task in Figure \ref{fig:mnist}, inputs $\vx$ correspond to images from the dataset, and $\vy$ to the associated predicted labels, or probabilities for labels describing the content of those images. 
The basic units of neural networks mimic biological neurons in that they receive inputs from adjacent units, transform those inputs, and may produce an output to subsequent units of the network. 
In other words, every unit is also a function, and in fact %every unit is the composition of a nonlinear function and a linear function. 
the output of most units is defined by the composition of a nonlinear function with a linear function. 
The nonlinear function is often denoted as the \emph{activation function} in analogy to how a biological neuron is triggered to send a signal to adjacent neurons when the stimulus caused by the input exceeds a certain activation threshold. Such non-linearity is behind the remarkable expressiveness of neural networks.

%\subsection{First models and feedforward networks}
This model was pioneered by~\cite{FirstANN}, who considered a thresholding function for activation that is now often denoted as the Linear Threshold Unit~(LTU). 
That activation is also the basis of the classic \emph{perceptron} algorithm by ~\cite{perceptron}, 
which yields a binary classifier of the form 
\begin{equation}
f(\vx) = \left\{ \begin{array}{cl} 1 & \text{if } \vw \cdot \vx + b > 0; \\ 0 & \text{otherwise} \end{array} \right. 
\end{equation}
for an input $\vx \in \mathbb{R}^{n_0}$ and with parameters $\vw \in\mathbb{R}^{n_0}$ and $b \in \mathbb{R}$. Those parameters are chosen by optimizing the predictions for a given task, as discussed below and in Section \ref{sec:training}. The term \emph{single-layer perceptron} is used for a neural network consisting of a set of such units processing the same input in parallel. 
The term \emph{multi-layer perceptron} is used for a generalization of this concept, by which the output of a \emph{layer} ---a set of units with same input--- is the input for a subsequent layer. This perceptron terminology has also been loosely applied to neural networks with other activation functions.

More generally, neural networks that successively transform inputs through an ordered sequence of layers are also denoted \emph{feedforward networks}. 
The layers that do not produce the final output of the neural network are denoted \emph{hidden layers}. 
For a network with $L$ layers, 
we denote $n_l$ as the number of units ---or \emph{width}--- of layer $l \in \sL := \{1, 2, \ldots, L\}$ and $h_i^l$ as the output of the $i$-th unit in layer $l$, where $i \in \{1, 2, \ldots, n_l\}$. The output of a unit is given by
\begin{equation} \label{eq:single-neuron}
h_i^l = \sigma^l\left(\vw^l_i \cdot \vh^{l-1} + b^l_i\right),
\end{equation}
where the \emph{weights} $\vw^l_i \in \mathbb{R}^{n_{l-1}}$ and the \emph{bias} $b^l_i \in \mathbb{R}$ are parameters of the unit. %that can be aggregated across the layer as the matrix $\mW^l \in \mathbb{R}^{n_l \times n_{l-1}}$ and the vector $\biases^l \in \mathbb{R}^{n_l}$, the 
Those parameters can be aggregated across the layer as the matrix $\mW^l \in \mathbb{R}^{n_l \times n_{l-1}}$ and the vector $\vb^l \in \mathbb{R}^{n_l}$. 
The vector $\vh^{l-1} \in \mathbb{R}^{n_{l-1}}$ represents the aggregated outputs from layer $(l-1)$. 
The activation function $\sigma^l : \mathbb{R} \rightarrow \mathbb{R}$ is applied by the units in layer $l$. 
These definitions implicitly assume that $n_0$ is the size of the network input $\vx \in \mathbb{R}^{n_0}$ and that $\vh^0$ and $\vx$ are the same. %Likewise, we may assume that $n_{L+1}$ is the size of the network output $\vh^{L+1} \equiv \vy \in \mathbb{R}^{n_{L+1}}$. 
% Talking about outputs may require discussing the softmax layer, which might only complicate things.
Figure~\ref{fig:ins_outs} illustrates the operation of a feedforward network as described above. 

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{Fig_01_Architecture.pdf}
    \caption{Mapping from $\vx \in \mathbb{R}^{n_0}$ to $\vy \in \mathbb{R}^{n_L}$ through a feedforward neural network with $L$ layers, layer widths $\{ n_l \}_{l \in \sL}$, and activation functions $\{ \sigma_l \}_{l \in \sL}$.}
    \label{fig:ins_outs}
\end{figure}

\subsection{How neural networks are obtained and evaluated}
%\subsection{Training neural networks}
In resemblance to how other models for \emph{supervised learning} in machine learning are obtained,  
we can \emph{train} a neural network for a given task by adjusting its behavior with respect to the examples of a \emph{training set} and then evaluate the final trained network on a \emph{test set}. 
Both of these sets consist of inputs for which the correct output $\hat{y}$ is known. 
We can define an objective function to model %the difference 
a measure of distance 
between the output $y$ and the correct output $\hat{y}$, which is typically denoted as the \emph{loss function}, and then iteratively update parameters such as $\{ \mW^l \}_{l \in \sL}$ and $\{ \vb^l \}_{l \in \sL}$ to minimize that loss function over the training set. A common objective function is the square error $\|y - \hat{y}\|^2$ summed over the points in the training set. 
The test set contains a separate collection of inputs and their outputs, 
which is used to evaluate the trained neural network with examples that were not seen during training. 
A good performance on the test set may indicate that the trained neural network is able to \emph{generalize} beyond the seen examples, whereas a bad performance may suggest that it \emph{overfits} for the training set. 
Neural networks also have \emph{hyperparameters} that are often chosen manually and do not change during training, such as the \emph{depth} $L$, the widths of the layers $\{ n_l \}_{l \in \sL}$, and the activation functions used in each layer $\{ \sigma^l \}_{l \in \sL}$. 
Different models can be produced by varying the hyperparameters. 
In such a case, a \emph{validation set} disjoint from the training and test sets can be used to compare models with different hyperparameters. 
Whereas the validation set may serve as a benchmark to different trained models corresponding to different choices of hyperparameters, 
the test set can only be used to evaluate a single neural network chosen among those evaluated with the validation set. 
The emergent field of \emph{neural architecture search} ---recently surveyed by \cite{NAS}--- concerns with automatically choosing such hyperparameters. 

One of the key factors for the success of deep learning is that first-order methods for continuous  optimization can be effectively applied to train deep networks. 
The interest in neural networks first vanished due to negative results in the Perceptrons book by~\cite{perceptrons}, which showed that single-layer perceptrons cannot represent functions such as the Boolean XOR. 
However, moving to multi-layer perceptrons capable of expressing the Boolean XOR as well as other more expressive models would require a clever training strategy. 
Hence, the interest was regained with papers that popularized the use of \emph{backpropagation}, such as ~\cite{BackPOP1} and ~\cite{BackPOP2}. 
Note that backpropagation was first discussed much earlier in the context of networks by~\cite{BackpropNetworks} and of neural networks explicitly by~\cite{BackpropNN}. 
The backpropagation algorithm calculates the derivative of the loss function with respect to each neural network parameter by applying the chain rule through the units of the neural network, 
which is considerably more efficient than explicitly evaluating the derivative of each network parameter.
Consequently, neural networks are generally trained with gradient descent methods in which the parameters are updated sequentially from the output to the input layer in each step. 
In fact, 
most algorithms for training neural networks are based on Stochastic Gradient Descent~(SGD), 
which is a form of the stochastic approximation through sampling pioneered by~\cite{StochasticApproximation}. 
SGD approximates the partial derivatives of the loss function at each step by using only a subset of the data in order to make the training process more efficient. 
Examples of popular SGD algorithms include momentum \citep{momentum}, Adam \citep{Adam}, and Nesterov Adaptive Gradient \citep{NAG} ---the later inspired by~\cite{Nesterov}. 
%Curiously, 
Interestingly, 
however, we generally cannot guarantee convergence to a global optimum with gradient descent due to the nonconvexity of the loss function. 
Nevertheless, neural networks trained with adequately parameterized SGD algorithms tend to generalize well. 

%\subsection{Importance of nonlinearity}
\subsection{Why nonlinearity is important in artificial neurons}

The nonlinearity of the activation function leads to such nonconvexity of the loss function. 
However, as we will see in Section~\ref{sec:LR}, that same nonlinearity enables the neural network to represent more complex functions as a whole. 
In fact, removing such nonlinearities by using an identity activation function $\sigma^l(u) = u ~ \forall l \in \sL$ would reduce the entire neural network to an affine transformation of the form $f(x) = \mW^{L} ( \mW^{L-1} \left( \ldots \left( \mW^2 \left( \mW^1 x + \vb^1 \right) + \vb^2 \right) + \ldots \right) + \vb^{L-1} ) + \vb^{L}$. 
Hence, a feedforward network without nonlinear activation functions is equivalent to a linear regression model. 
However, in that case we can easily obtain such a model without resorting to neural networks and backpropagation: the loss function is convex and the optimal solution is given by a closed formula, such as in least squares regression.  
In contrast, 
neural networks with a single hidden layer of arbitrary width have been long known to be universal function approximators for a broad variety of activation functions \citep{Cybenko1989,funahashi1989approximate,Hornik1989}, as well as for ReLU more recently \citep{yarotsky2017relu}. 
These results have also been extended to the converse case of limited width but arbitrarily large depth \citep{lu2017expressive,hanin2017approximating,park2021width}. 

Although nonlinear activation functions are important for obtaining more complex models, these functions do not need to be overly complex to produce good results. 
In the past, it was common practice to use sigmoid functions for activation \citep{TricksBP}. Those are monotonically increasing functions that approach finite values for arbitrarily large positive and negative inputs, 
such as the standard logistic function $\sigma(u) = \frac{1}{1+e^{-u}}$ and the hyperbolic tangent $\sigma(u) = \tanh(u)$. 
In the present, the most commonly used activation function is the Rectified Linear Unit~(ReLU) $\sigma(u) = \max\{0,u\}$ \citep{CurrentDNN,ReluPop2018}, which was proposed by~\cite{OriginReLU} and first applied to neural networks by~\cite{nair2010rectified}. 
The popularity of ReLU is in part due to experiments by~\cite{nair2010rectified} and~\cite{ReLUGood2} showing that this simpler form of activation yields competitive results. 
Thinking back in terms of the analogy with biological neurons, 
we say that a ReLU is \emph{active} when the output is positive and \emph{inactive} when the output is zero. 
ReLUs have a linear output behavior on the inputs associated with the same ReLUs being active and inactive; this property also holds for other piecewise linear and piecewise constant functions that are used as activation functions in neural networks. 
Table~\ref{tab:activations} lists some of the most commonly used activation functions of that kind. For more comprehensive lists of activation functions, including several other variations based on ReLU, we refer to~\cite{dubey2021activations} and~\cite{tao2022piecewise}.

\begin{table}
\caption{Main piecewise constant and piecewise linear activation functions.}
\label{tab:activations}
\centering
\vspace{2ex}
\begin{tabular}{@{\extracolsep{3pt}}m{0.13\textwidth}cm{0.23\textwidth}}
\textbf{Name} & \textbf{Function} & \textbf{Reference} \\
\cline{1-1}
\cline{2-2}
\cline{3-3}
\noalign{\vskip8pt}
LTU & $\sigma(u) = \left\{ \begin{array}{cl} 1 & \text{if } u > 0 \\ 0 & \text{if } u \leq 0 \end{array}\right.$ & ~\cite{FirstANN} \\
\noalign{\vskip8pt}
ReLU & $\sigma(u) = \max\{0,u\}$ &  ~\cite{OriginReLU,nair2010rectified} \\
\noalign{\vskip8pt}
leaky ReLU & $\begin{array}{c} \sigma(u) = \left\{ \begin{array}{cl} u & \text{if } u > 0 \\ \varepsilon u & \text{if } u \leq 0 \end{array}\right.\\ \text{($\varepsilon$ is small and fixed)} \end{array}$ & ~\cite{leaky} \\
\noalign{\vskip8pt}
parametric ReLU & $\begin{array}{c} \sigma(u) = \left\{ \begin{array}{cl} u & \text{if } u > 0 \\ a u & \text{if } u \leq 0 \end{array}\right. \\ \text{($a$ is a trainable parameter)} \end{array}$ & ~\cite{prelu} \\
\noalign{\vskip8pt}
hard tanh & $\sigma(u) = \left\{ \begin{array}{cl} 1 & \text{if } u > 1 \\ u & \text{if } -1 \leq u \leq 1 \\ -1 & \text{if } u < -1 \end{array}\right.$ & ~\cite{htanh} \\
\noalign{\vskip8pt}
hard sigmoid & $\sigma(u) = \left\{ \begin{array}{cl} 1 & \text{if } u > \frac{1}{2} \\ u + \frac{1}{2} & \text{if } -\frac{1}{2} \leq u \leq \frac{1}{2} \\ 0 & \text{if } u < -\frac{1}{2} \end{array}\right.$ & ~\cite{courbariaux2015bc} \\
\noalign{\vskip8pt}
max pooling & $\begin{array}{c} \sigma(u_1, \ldots, u_k) = \max\{0, u_1, \ldots, u_k\} \\ \text{(each $u_i$ is the output of another neuron)}
\end{array}$ & ~\cite{maxpooling} \\
\noalign{\vskip8pt}
maxout  & $\begin{array}{c} \sigma(u_1, \ldots, u_k) = \max\{u_1, \ldots, u_k\} \\ \text{(each $u_i$ is an affine function)} \end{array}$ & ~\cite{Goodfellow2013} \\
\end{tabular}
\end{table}

\subsection{When deep learning meets polyhedral theory} 
It is commonly accepted in machine learning that a simpler model is preferred if it trains as well as a more complex one, since a simpler model is less likely to overfit. 
Conveniently, 
the successful return of neural networks to relatively simpler activation functions %prepared the soil 
prepared the ground 
for deep learning to meet polyhedral theory. 
In other words, 
we are now able to analyze and leverage neural networks through the same lenses and tools that have been successfully used for linear and discrete optimization in operations research for many decades. 
We explain this connection in more detail and 
some lines of research that it has opened up in Section~\ref{sec:poly}. 

\subsection{Scope of this survey and related work}
The interplay between mathematical optimization and machine learning has also been discussed by other recent surveys. \cite{CombOptTour} review the use of machine learning in mathematical optimization, whereas~\cite{OptimizationSurvey} formulate mathematical optimization problems with the main focus of obtaining machine learning models, such as by training neural networks. 
A similar scope has been previously surveyed by~\cite{curtis2017optimization} and~\cite{bottou2018optimization}. 
Our survey complements those by focusing exclusively on neural networks while outlining how linear optimization can be used more broadly in that context, from network training and verification to  model embedding and  compression, as well as refined through formulation strengthening. 
In addition, we illustrate how polyhedral theory can ground the use of such linear formulations and also provide a more nuanced understanding of the discriminative ability of neural networks.  

The presentation in this survey is centered on \emph{feedforward rectifier networks}. These are very commonly used networks with only ReLU activations and for which most polyhedral results and applications of linear optimization are known. The focus on a single type of neural network is intended to help the reader capture the intuition behind different developments and understand the nuances involved. 
% or that can be often reduced to rectifier networks and for which there are currently fewer specific results. 
%
Despite our focus on \emph{fully-connected} models, which are those in which every unit is connected to all units in the subsequent layer, there are many variants of interest with fewer or different types of connection that can be interpreted as a special case of fully-connected models. For example, the units of Convolutional Neural Networks~(CNNs or ConvNets) \citep{CNN} have local connectivity:
only a subset of adjacent units defines the output of each unit in the next layer, and the same parameters are used to define the output of different units. In fact, multiple \emph{filters} of parameters can be applied to a set of adjacent units through the output of different units in the next layer. 
CNNs are often applied to identify and aggregate the same local features in different parts of a picture, 
and we can interpret them as a special case of feedforward networks. 
%\todo{Illustrate equivalent of CNN and fully-connected network with a figure.}
Another common variant, the Residual Network~(ResNet) \citep{He2016DeepRL}, includes \emph{skip connections} that directly connect units in nonadjacent layers. 
Those connections can be emulated by adding units passing their outputs through the intermediary layers. 
Hence, many of the results and applications discussed along the survey are relevant to other variants (e.g., LTU and maxout activations, or those other connectivity patterns), and we also provide references to more specific results and applications involving them. 

We also discuss the extent to which other variants remain relevant or can be analyzed through the same lenses. 
For example, \emph{feedback connections} in \emph{recurrent networks} \citep{recurrent1,recurrent2} allow the output of a unit to be used as an input of units in previous layers. 
Recurrent networks such as Long Short-Term Memory~(LSTM) \citep{LSTM} produce outputs that depend on their internal state, and they may consequently process sequential inputs with arbitrary length. 
While feedback connections may not be emulated with a feeforward network, we discuss in the following paragraph how recurrent networks have been replaced with great success by attention mechanisms, which are implemented with feedforward networks. 
In the realm of variants that remain relevant, it is very common to apply a different type of activation to the output layer of the network, such as the layer-wise softmax function $\sigma : \mathbb{R}^{n_{L}} \rightarrow \mathbb{R}^{n_{L}}$ in which $\sigma(u)_i = e^{u_i}/\sum_{j=1}^{n_{L}} e^{u_j} ~ \forall i \in \{1, \ldots, n_{L}\}$ \citep{softmax}, 
which is used to normalize a multidimensional output as a probability distribution. 
While softmax is not piecewise linear, 
we describe how its output can also be analyzed from a polyhedral perspective. 


\paragraph{Other uses of deep learning}
Deep learning is also being used in machine learning beyond the realm of  supervised learning. 
In \emph{unsupervised learning}, the focus is on drawing inferences from unlabeled datasets. 
For example, 
Generative Adversarial Networks~(GANs) \citep{GAN} have been used to generate realistic images using a pair of neural networks. 
One of these networks is a \emph{discriminator} trained to identify elements from a dataset and the other is a \emph{generator} aiming to mislead the discriminator with synthetic inputs that could be classified as belonging to the dataset. 

In \emph{reinforcement learning}, the focus is on modeling agents that can interact with their environment through actions and associated rewards. Examples of such applications include neural networks designed for the navigation of self-driving vehicles \citep{gao2020vectornet} and for playing Atari games \citep{Atari}, more contemporary electronic games such as Dota 2 \citep{dota2} and StarCraft II \citep{starcraft2}, and the game of Go \citep{AlphaGo} at levels that are either better or at least comparable to human players.  

A more recent and popular example are generative transformers \citep{GPT}, such as DALL·E 2 \citep{dalle2} producing realistic images from text prompts in mid-2022 
and ChatGPT \citep{ChatGPT} producing realistic dialogues with users in early 2023, 
the latter belonging to the fast growing family of large language models. 
They are based on replacing architectures based on feedback connections, such as LSTM, with the attention mechanisms aimed at scoring the relevance of past states \citep{bahdanau2015translation}, which is the foundation of the transformer architecture \citep{vaswani2017attention}.





\paragraph{Further reading}
For a historical perspective on neural networks, we recommend \cite{historical}. 
For a recent and broad introduction to the fundamentals of deep learning, we recommend~\cite{zhang2023dive}. 
For other forms of measuring model complexity in neural networks, we refer to~\cite{hu2021complexity}. 

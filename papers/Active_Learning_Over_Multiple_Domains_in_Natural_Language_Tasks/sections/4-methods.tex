% \section{Document Body}

% \subsection{Footnotes}

% Footnotes are inserted with the \verb|\footnote| command.\footnote{This is a footnote.}

% \subsection{Tables and figures}

% See Table~\ref{tab:accents} for an example of a table and its caption.
% \textbf{Do not override the default caption sizes.}

% \begin{table}
% \centering
% \begin{tabular}{lc}
% \hline
% \textbf{Command} & \textbf{Output}\\
% \hline
% \verb|{\"a}| & {\"a} \\
% \verb|{\^e}| & {\^e} \\
% \verb|{\`i}| & {\`i} \\ 
% \verb|{\.I}| & {\.I} \\ 
% \verb|{\o}| & {\o} \\
% \verb|{\'u}| & {\'u}  \\ 
% \verb|{\aa}| & {\aa}  \\\hline
% \end{tabular}
% \begin{tabular}{lc}
% \hline
% \textbf{Command} & \textbf{Output}\\
% \hline
% \verb|{\c c}| & {\c c} \\ 
% \verb|{\u g}| & {\u g} \\ 
% \verb|{\l}| & {\l} \\ 
% \verb|{\~n}| & {\~n} \\ 
% \verb|{\H o}| & {\H o} \\ 
% \verb|{\v r}| & {\v r} \\ 
% \verb|{\ss}| & {\ss} \\
% \hline
% \end{tabular}
% \caption{Example commands for accented characters, to be used in, \emph{e.g.}, Bib\TeX{} entries.}
% \label{tab:accents}
% \end{table}

% \subsection{Hyperlinks}

% Users of older versions of \LaTeX{} may encounter the following error during compilation: 
% \begin{quote}
% \tt\verb|\pdfendlink| ended up in different nesting level than \verb|\pdfstartlink|.
% \end{quote}
% This happens when pdf\LaTeX{} is used and a citation splits across a page boundary. The best way to fix this is to upgrade \LaTeX{} to 2018-12-01 or later.

% \subsection{Citations}

% \begin{table*}
% \centering
% \begin{tabular}{lll}
% \hline
% \textbf{Output} & \textbf{natbib command} & \textbf{Old ACL-style command}\\
% \hline
% \citep{Gusfield:97} & \verb|\citep| & \verb|\cite| \\
% \citealp{Gusfield:97} & \verb|\citealp| & no equivalent \\
% \citet{Gusfield:97} & \verb|\citet| & \verb|\newcite| \\
% \citeyearpar{Gusfield:97} & \verb|\citeyearpar| & \verb|\shortcite| \\
% \hline
% \end{tabular}
% \caption{\label{citation-guide}
% Citation commands supported by the style file.
% The style is based on the natbib package and supports all natbib citation commands.
% It also supports commands defined in previous ACL style files for compatibility.
% }
% \end{table*}

% Table~\ref{citation-guide} shows the syntax supported by the style files.
% We encourage you to use the natbib styles.
% You can use the command \verb|\citet| (cite in text) to get ``author (year)'' citations, like this citation to a paper by \citet{Gusfield:97}.
% You can use the command \verb|\citep| (cite in parentheses) to get ``(author, year)'' citations \citep{Gusfield:97}.
% You can use the command \verb|\citealp| (alternative cite without parentheses) to get ``author, year'' citations, which is useful for using citations within parentheses (e.g. \citealp{Gusfield:97}).

% \subsection{References}

% \nocite{Ando2005,borschinger-johnson-2011-particle,andrew2007scalable,rasooli-tetrault-2015,goodman-etal-2016-noise,harper-2014-learning}

% The \LaTeX{} and Bib\TeX{} style files provided roughly follow the American Psychological Association format.
% If your own bib file is named \texttt{custom.bib}, then placing the following before any appendices in your \LaTeX{} file will generate the references section for you:
% \begin{quote}
% \begin{verbatim}
% \bibliographystyle{acl_natbib}
% \bibliography{custom}
% \end{verbatim}
% \end{quote}

% You can obtain the complete ACL Anthology as a Bib\TeX{} file from \url{https://aclweb.org/anthology/anthology.bib.gz}.
% To include both the Anthology and your own .bib file, use the following instead of the above.
% \begin{quote}
% \begin{verbatim}
% \bibliographystyle{acl_natbib}
% \bibliography{anthology,custom}
% \end{verbatim}
% \end{quote}

% Please see Section~\ref{sec:bibtex} for information on preparing Bib\TeX{} files.

% \subsection{Appendices}

% Use \verb|\appendix| before any appendix section to switch the section numbering over to letters. See Appendix~\ref{sec:appendix} for an example.

\section{Methods}
\label{sec:methods}

We identify four families of methods relevant to active learning over multiple shifted domains.
\textbf{Uncertainty methods} are common in standard active learning for measuring example uncertainty or familiarity to a model; \textbf{$\mathcal{H}$-Divergence} techniques train classifiers for domain shift detection; \textbf{Semantic Similarity Detection} finds data points similar to points in the target domain; and \textbf{Reverse Classification Accuracy} approximates the benefit of training on a dataset. 
A limitation of our work is we do not cover all method families, such as domain adaptation, just those we consider most applicable.
%Not all active learning and domain shift detection methods are represented here, such as query-by-committee or density weighted sampling \citep{settles2009active}, but we derive \~18 of the most prevalent variants from prior work, including novel extensions/variants of existing paradigms for the multi-domain active learning setting (see \knn{}, \rcas{} and \dale{}).
We derive $\sim$18 active learning variants, comprising the most prevalent and effective from prior work, and novel extensions/variants of existing paradigms for the multi-domain active learning setting (see \knn{}, \rcas{} and \dale{}).

Furthermore, we split the families into two acquisition strategies: \textbf{Single Pool Strategy} and \textbf{Domain Budget Allocation}. 
\textbf{Single Pool Strategy}, comprising the first three families of methods, treats all examples as coming from one single unlabeled pool. \textbf{Domain Budget Allocation}, consisting of \textbf{Reverse Classification Accuracy} methods, simply allocate an example budget for each domain.

We enumerate acquisition methods $A_f$ below. 
Each method produces a full ranking of examples in the source set $D_S$.
To rank examples, most acquisition methods train an acquisition model, $M_A$, using the same model architecture as $M$. 
$M_A$ is trained on all samples from $D_T^{train}$, except for \dal{} and \knn{}, which split $D_T^{train}$ into two equal segments, one for training $M_A$ and one for an internal model.
%For methods where $M_A$ requires supervision, $M_A$ is trained on $D_T^{train}$, or for variants of \dal{} and \knn{} which train another supervised model, they are each trained on separate 1000 examples from $D_T^{train}$.
Some methods have both ascending and descending orders of these rankings (denoted by $\uparrow$ and $\downarrow$ respectively, in the method abbreviations), to test whether similar or distant examples are preferred in a multi-domain setting.

% For Uncertainty methods (Section~\ref{sec:uncertainty-methods}) and Reverse Classification Accuracy (Section~\ref{sec:rca-methods}) we use BERT-Base \citep{devlin2019bert}.
% For $\mathcal{H}$-Divergence Methods (Section~\ref{sec:h-divergence-methods}) and Semantic Similarity Detection (Section~\ref{sec:kNN-method}) we experiment with both task-agnostic and task-specific embeddings.
Certain methods use vector representations of candidate examples.
We benchmark with both task-agnostic and task-specific encoders.
The task-agnostic embeddings are taken from the last layer's CLS token in \citet{reimers-2019-sentence-bert}'s sentence encoder (Appendix for details).
%\footnote{A RoBERTa-Large model fine-tuned on SNLI \citep{bowman2015large} and STSb \citep{cer2017semeval}: \url{https://github.com/UKPLab/sentence-transformers}}
The task-specific embeddings are taken from the last layer's CLS token in the trained model $M_A$.

The motivation of the task-specific variant is that each example's representation will capture task-relevant differences between examples while ignoring irrelevant differences.\footnote{For instance, consider in one domain every example is prefixed with ``Text:'' while the other is not --- telling the difference is trivial, but the examples could be near-identical with respect to the task.}
The versions of \dal{} and \knn{} methods that use task-specific vectors are denoted with ``$*$'' in their abbreviation. 
Otherwise, they use task-agnostic vectors.

    \subsection{Uncertainty Methods}
    \label{sec:uncertainty-methods}
    \respace
    These methods measure the uncertainty of a trained model on a new example.
    Uncertainty can reflect either \textit{aleatoric} uncertainty, due to ambiguity inherent in the example, or \textit{epistemic} uncertainty, due to limitations of the model \citep{kendall2017uncertainties}.
    For the following methods, let $Y$ be the set of all possible labels produced from the model $M(x)$ and $l_y$ be the logit value for $y \in Y$.

        \paragraph{Confidence (\conf)}
        A model's confidence $P(y|x)$ in its prediction $y$ estimates the difficulty or unfamiliarity of an example \citep{guo2017calibration, elsahar-galle-2019-annotate}.
        \respace
        $$ A_{\text{CONF}}(x, M_A) = -\max(P(y|x))$$ 
        \respace
        \paragraph{Entropy (\entr)}
        Entropy applies Shannon entropy \citep{shannon1948mathematical} to the full distribution of class probabilities for each example, formalized as $A_{\text{ENTR}}$.
        \respace
        \respace
         $$ A_{\text{ENTR}}(x, M_A) = -\sum_{i = 1}^{|Y|} { P(y_i|x) \cdot \log{P(y_i|x)}  }$$ 
        
        % $$ A_{\text{ENTR}}(x, M_A) = -\sum_{i = 1}^{|Y|} { P(y_i|x) \cdot \log{P(y_i|x)}  }$$

        \respace
        \respace
        \paragraph{Energy-based Out-of-Distribution Detection (\eod)}
        \citet{liu2020energy} use an \textit{energy-based score} to distinguish between in- and out-distribution examples.
        They demonstrate this method is less susceptible to overconfidence issues of softmax approaches.
        \respace
        % We chose $T=1$ to maximize the distinction between in- and out-domain predictions.
        $$ A_{ENG}(x, M_A) = - \log \sum_{y \in Y} e^{l_y} $$ 
        \respace
        \respace
        \paragraph{Bayesian Active Learning by Disagreement (\bald)}
        \citet{gal2016} introduces estimating uncertainty by measuring prediction disagreement over multiple inference passes, each with a distinct dropout mask.
        \bald{} isolates \textit{epistemic} uncertainty, as the model would theoretically produce stable predictions over inference passes given sufficient capacity.
        We conduct $T=20$ forward passes on $x$.
        $\hat{y}_t = \text{argmax}_{i}P(y_i|x)_t$, representing the predicted class on the $t$-th model pass on $x$.
        Following \citep{lowell2019practical}, ties are broken by taking the mean label entropy over all $T$ runs. 
        \respace
        \respace
        $$ A_{\text{BALD}}(x, M_{A}) = 1 - \frac{\text{count}(\text{mode}_{t \in T} (\hat{y}_t))}{T} $$
        
        % $$ A_{ENG}(x, M_A) = -T \cdot \log \sum_{y \in Y} e^{l_y / T} \;\;\;\;\;\; A_{\text{BALD}}(x, M_{A}) = 1 - \frac{\text{count}(\text{mode}_{t \in T} (\hat{y}_t))}{T} $$
        
    \respace
    \respace
    \subsection{$\mathcal{H}$-Divergence Methods}
    \label{sec:h-divergence-methods}
    \citet{ben2006analysis, ben2010theory} formalize the divergence between two domains as the $\mathcal{H}$-Divergence, which they approximate as the difficulty for a discriminator to differentiate between the two.\footnote{The approximation is also referred to as Proxy $\mathcal{A}$-Distance (PAD) from \citep{elsahar-galle-2019-annotate}}
    Discriminative Active Learning (\dal) applies this concept to the active learning setting \citep{gissin2019discriminative}.
    
    We explore variants of \dal{}, using an XGBoost decision tree \citep{Chen:2016:XST:2939672.2939785} as the discriminator model $g$.\footnote{Hyperparameter choices and training procedures are detailed in the Appendix.}
    For the following methods, let $D_T^{train-B}$ be the 1k examples from $D_T^{train}$ that were \emph{not} used to train $M_A$. 
    Let $E$ be an encoder function, which can be task-specific or agnostic as described above. 
    We use samples both from $D_T^{train-B}$ and $D_S$ to train the discriminator. 
    We assign samples origin labels $l$, which depend on the \dal{} variant. 
    Samples from $D_S$ with discriminator predictions closest to 1 are selected for labeling.
    The acquisition scoring function for each \dal{} method and training set definition, respectively, are:
    \respace
    \respace
    $$A_{\text{DAL}}(x, g, E) = g(E(x)) $$
    $$ \{(E(x), \: l) \; | \; x \in D_T^{train-B} \cup D_{S} \}$$

    %This is inspired by deep NLP models producing intermediate representations that exclude features irrelevant to the NLP task. Motivated by this work and by \citep{gissin2019discriminative}, which uses a discriminator for active learning, we explore $TAL_E$ and $TAL_T$.
    %Both $TAL_E$ and $TAL_T$ perform discriminative active learning. 
    % Both $TAL_E$ and $TAL_T$ perform discriminatory active learning where
    % %the input to the discriminator $E(x)$ is the penultimate layer from model $M_1$.
    % the input $g(\xi)$ to the discriminator $C$ is the penultimate layer from model $M_1$.
    % Their acquisition functions can be written as 
    % %$$x* = argmax_{x\in D_{source}}C(g(x)).$$
    % $$ a_{TAL}(x, M_1) = C(g(\xi), x) $$

    % For both methods, $C$ is an XGBoost gradient boosting decision tree \citep{Chen:2016:XST:2939672.2939785}. Hyperparameter choices are discussed in the appendix. \shayne{Do you know how to set up an appendix?}
    % \julia{Define C}
        \respace
        \respace
        \paragraph{Discriminative Active Learning --- Target (\dalt)}
        \dalt{} trains a discriminator $g$ to distinguish between target examples in $D_T^{train-B}$ and out-of-distribution examples from $D_{S}$. 
        For \dalt{}, $l=\mathbbm{1}_{D_T^{train-B}}(x)$.
        % \footnote{Multiple models, each trained on a different segment of the data, are used to fairly train and select from $D_{S}$. Full details are in the appendix.}
        % To do this, it assigns pseudo-labels to samples in $D_{val}$ and $D_{S}$ such that $g$'s training set consists of samples 
        % %$\{(g(x), l) \; | \; l=\mathbbm{1}_{D_{val}}(x), x\in \{D_{val}, D_{source}\}\}$.
        % $\{(g(\xi), \: l) \; | \; l=\mathbbm{1}_{D_{val}}(\xi), \; \xi \in D_{val} \cup D_{S} \}$.
        
        \respace
        \paragraph{Discriminative Active Learning --- Error (\dale)}
        \dale{} is a novel variant of \dal.
        \dale's approach is to find examples that are similar to those in the target domain that $M_A$ misclassified.
        %These ``erroneous'' examples represent those the model finds most challenging from the target domain.
        %We define a non-erroneous sample as one where the prediction from $M_1$ is an exact match of its label. 
        % We define an erroneous sample as one where the predicted pseudo-label is incorrect. 
        We partition $D_T^{train-B}$ further into erroneous samples $D_T^{err}$ and correct samples $D_T^{corr}$, where $D_T^{train-B} = D_T^{err} \cup D_T^{corr}$. For \dale{}, $l=\mathbbm{1}_{D^{err}_T}(x)$.

        % For both methods, the discriminator is an XGBoost gradient boosting decision tree \citep{Chen:2016:XST:2939672.2939785}. 
        % The model had $10$ for $n\_estimators$, $2$ for $max\_depth$, hist for $tree\_method$, $5$ for $lambda$, $binary:logistic$ for $objective$, $0.1$ for $learning\_rate$, and $5$ for $gamma$. The rest of the hyperparameters were set to the default XGBoost parameters.

    \respace
    \subsection{Reverse Classification Accuracy}
    \label{sec:rca-methods}

        \respace
        \paragraph{\rca}

        Reverse Classification Accuracy (\rca) estimates how effective source set $D_{i, i \in S}$ is as a training data for target test set $D_T$ \citep{fan2006reverse, elsahar-galle-2019-annotate}.
        Without gold labels for $D_{i}$ we compute soft labels instead, using the BERT-Base $M_A$ trained on the small labeled set $D_T^{train}$.
        We then train a child model $M_i$ on $D_{i}$ using these soft labels, and evaluate the child model on $D_T^{dev}$.
        \rca{} chooses examples randomly from whichever domain $i$ produced the highest score $s_i$.
        \respace
        \respace
        
        $$A_{\text{RCA}} = \mathbbm{1}_{D_{(\argmax_{i\in S}s_{i})}}(x) $$ 
        $$ \widetilde{RCA}:\;\;\; \tau_i = \dfrac{s_i}{s_T - s_i}, \; |D^{chosen}_i| = \dfrac{\tau_i}{\sum\limits_{j} s_j}$$

        \respace
        \respace
        \respace
        \paragraph{RCA-Smoothed (\rcas)}
        Standard \rca{} only selects examples from one domain $D_{i}$.
        We develop a novel variant which samples from multiple domains, proportional to their relative performance on the target domain $D_T^{dev}$.
        RCA-smoothed (\rcas) selects $|D^{chosen}_i|$ examples from source domain $i$, based on the relative difference between the performance $s_i$ (of child model $M_i$ trained on domain $i$ with pseudo-labels from $M_A$) on the target domain, and the performance $s_T$ of a model trained directly on the target domain $D_T^{dev}$. 
        Since these strategies directly estimates model performance on the target domain resulting from training on each source domain, \rca{} and \rcas{} are strong \textbf{Domain Budget Allocation} candidates.
        
    \respace
    \subsection{Nearest Neighbour / Semantic Similarity Detection (\knn)}
    \label{sec:kNN-method}
    \respace
    
    Nearest neighbour methods (\knn) are used to find examples that are semantically similar.
    Using sentence encoders we can search the source set $D_S$ to select the top $k$ nearest examples by cosine similarity to the target set.
    We represent the target set as the mean embedding of $D_T^{train}$. 
    For question answering, where an example contains two sentences (the query and context), we refer to \knnq{} where we only encode the query text, \knnc{} where we only encode the context text, or \knnqc{} where we encode both concatenated together.
    The acquisition scoring function per example, uses either a task-specific or task-agnostic encoder $E$:
    \respace
    $$A_{\text{KNN}}(x, E) = \text{CosSim}(E(x), \text{Mean}( E(D_{T}^{train} ))$$

    
    %For task-specific vector representations, we use the common convention of the final hidden layer of the $0$th token of the model $M_A$ trained on $D_{T}^{train}$.
    %The task-specific variants of the \knn{} approach are suffixed with $*$, such as \knns.
    
    



% \begin{abstract}
% This document is a supplement to the general instructions for *ACL authors. It contains instructions for using the \LaTeX{} style files for ACL conferences. 
% The document itself conforms to its own specifications, and is therefore an example of what your manuscript should look like.
% These instructions should be used both for papers submitted for review and for final versions of accepted papers.
% \end{abstract}

\begin{abstract}
Studies of active learning traditionally assume the target and source data stem from a single domain.
However, in realistic applications, practitioners often require active learning with multiple sources of out-of-distribution data, where it is unclear a priori which data sources will help or hurt the target domain.
We survey a wide variety of techniques in active learning (AL), domain shift detection (DS), and multi-domain sampling to examine this challenging setting for question answering and sentiment analysis.
We ask (1) what family of methods are effective for this task? And, (2) what properties of selected examples and domains achieve strong results?
Among 18 acquisition functions from 4 families of methods, we find $\mathcal{H}$-Divergence methods, and particularly our proposed variant DAL-E, yield effective results, averaging 2-3\% improvements over the random baseline.
We also show the importance of a diverse allocation of domains, as well as room-for-improvement of existing methods on both domain and example selection.
Our findings yield the first comprehensive analysis of both existing and novel methods for practitioners faced with multi-domain active learning for natural language tasks.
\end{abstract}


% Studies of active learning mostly assume the target and source data stem from a single domain.
% However, in realistic applications new problems often require active learning with multiple sources of out-of-distribution data.
% We examine this challenging setting for question answering and sentiment analysis, where it is unclear a priori which of many unlabeled data sources will help or hurt the target domain. 
% Our empirical investigation surveys and compares a wide variety of techniques in active learning (AL), domain shift detection (DS), and multi-domain data sampling to answer: (1) what methods are effective for this task? And, (2) how can using source domain information improve results beyond treating source samples as coming from a single unlabeled pool?
% While no single active learner outperforms the others for every task, we find DALE, a novel variant of H-Divergence Methods, is most effective on average, showing x\% gains above random in question answering and y\% in sentiment analysis. 
% We show that for most settings, selecting a diversity of domains is better than selecting from a single domain. 
% Furthermore, allocating a budget from each domain can lead to improvement over treating the unlabeled set as a single pool. 
% Our findings yield the first comprehensive analysis of both existing and novel methods for practitioners faced with this challenging setting for natural language tasks.
% \iffalse
% Studies of active learning mostly assume the target and source data stem from a single domain.
% However, in realistic applications new problems often require active learning with multiple sources of out-of-distribution data.
% We examine this challenging setting for question answering and sentiment analysis, where it is unclear a priori which of many unlabeled data sources will help or hurt the target domain. 
% Our empirical investigation surveys a wide variety of techniques in active learning (AL), domain shift detection (DS), and multi-domain data sampling to answer: (1) What methods, if any, are effective for this task? (2) How do the characteristics of these methods compare? And, (3) What are ideal properties of an effective method?
% Our findings yield the first comprehensive analysis of both existing and novel methods for practitioners faced with this challenging setting for natural language tasks.
% \fi

% Previous Abstract:

% In this work we empirically examine a set of practical questions at the intersection of active learning (AL), domain adaptation (DA), and multi-domain data sampling.
% While most prior work in active learning assumes the target and source data stem from a single domain, realistic applications often tackle new problems which require active learning with multiple source domains, frequently shifted from the target distribution.
% We examine this setting, where it is unclear a priori which of many unlabelled data sources will help or hurt the target domain, with limited labelled data. 
% We survey a wide variety of traditional active learning and domain shift detection techniques to answer: (1) What methods, if any, are effective for active learning over multiple domains? (2) What are desirable properties of selected training distributions? (3) What is more important between example selection and domain selection?
% Our findings yield actionable insights to practitioners faced with this challenging, realistic setup in low-resource data environments.
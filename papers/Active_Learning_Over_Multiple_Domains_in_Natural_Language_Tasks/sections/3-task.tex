% \section{Preamble}

% The first line of the file must be
% \begin{quote}
% \begin{verbatim}
% \documentclass[11pt]{article}
% \end{verbatim}
% \end{quote}

% To load the style file in the review version:
% \begin{quote}
% \begin{verbatim}
% \usepackage[review]{acl}
% \end{verbatim}
% \end{quote}
% For the final version, omit the \verb|review| option:
% \begin{quote}
% \begin{verbatim}
% \usepackage{acl}
% \end{verbatim}
% \end{quote}

% To use Times Roman, put the following in the preamble:
% \begin{quote}
% \begin{verbatim}
% \usepackage{times}
% \end{verbatim}
% \end{quote}
% (Alternatives like txfonts or newtx are also acceptable.)

% Please see the \LaTeX{} source of this document for comments on other packages that may be useful.

% Set the title and author using \verb|\title| and \verb|\author|. Within the author list, format multiple authors using \verb|\and| and \verb|\And| and \verb|\AND|; please see the \LaTeX{} source for examples.

% By default, the box containing the title and author names is set to the minimum of 5 cm. If you need more space, include the following in the preamble:
% \begin{quote}
% \begin{verbatim}
% \setlength\titlebox{<dim>}
% \end{verbatim}
% \end{quote}
% where \verb|<dim>| is replaced with a length. Do not set this length smaller than 5 cm.

\respace
\section{Multi-Domain Active Learning}
\respace
\label{sec:task}

% Suppose we have $K$ domains $D_1, D_2, ..., D_k \in D$.\footnote{We define a domain as a dataset collected independently of the others.}
%Suppose we have multiple domains $D = \bigcup\limits_{i=1} D_{i}$.\footnote{We define a domain as a dataset collected independently of the others.}
Suppose we have multiple domains $D_1, D_2, ..., D_k$.\footnote{We define a domain as a dataset collected independently of the others.}
Let one of the $k$ domains be the \target{} set $D_T$, and let the other $k-1$ domains comprise the \source{} set $D_S=\bigcup\limits_{i\neq T} D_{i}$.
% Each domain comprises a training set $D_i^{train}$, development set $D_i^{dev}$, and test set $D_i^{test}$, all sets of $(x, y)$ input-label pairs.
% One of these domains is designated the \target{} set $D_T$, while the other $\{D_i^{train} \mid i\ne T\}$ domains collectively become the \source{} set $D_S$.

\respace
\respace
\paragraph{Given:}
\begin{itemize}\itemsep0em
    \item \textbf{Target:} Small samples of \textit{labeled} data points $(x, y)$ from the \target{} domain. \\
    $D_T^{train},D_T^{dev}, D_T^{test} \sim D_T$.\footnote{$|D_T^{train}|=2000$ to simulate a small but reasonable quantity of labeled, in-domain training data for active learning scenarios.}
    \item  \textbf{Source:} A large sample of \textit{unlabeled} points $(x)$ from the \source{} domains. \\
    $D_S=\bigcup\limits_{i\neq T} D_{i}$
\end{itemize}
\respace
\paragraph{Task:}
\begin{enumerate}\itemsep0em
    \item \textbf{Choose} $n$ samples from $D_S$ to label. \\
    $D_{S}^{chosen} \subset D_S$, $|D_{S}^{chosen}|=n$, selected by $ \argmax_{x \in D_S} A_{f}(x) $ where $ A_{f} $ is an acquisition function: a policy to select unlabeled examples from $D_S$ for labeling.
    \item \textbf{Train} a model $M$ on $D^{final-train}$, validating on $D_{T}^{dev}$. \\
    $D^{final-train} = D_T^{train} \cup D_S^{chosen}$
    \item \textbf{Evaluate} $M$ on $D_T^{test}$, giving score $s$.
\end{enumerate}

For Step 1, the practitioner chooses $n$ samples with the highest scores according to their acquisition function $A_f$. 
$M$ is fine-tuned on these $n$ samples, then evaluated on $D_T^{test}$ to demonstrate $A_f$'s ability to choose relevant out-of-distribution training examples.

% Many functions train an acquisition model $M_A$, on $D_T^{train}$.
% Both $M_A$ and $M$ use $D_T^{dev}$ as their development set.
% Section \ref{sec:methods} describes the choice of $M_A$ and how it is used for each acquisition method $A_f$.
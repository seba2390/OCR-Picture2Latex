\section{Introduction}

Restricted skyline (rskyline) query is a recently proposed powerful tool for multi-criteria decision making.
It extends the skyline query by supporting personalized preferences.
In particular, given a dataset and a set $\calF$ of scoring functions of interest, the rskyline query retrieves a set of tuples that are not $\calF$-dominated by any other tuples.
Here a tuple $t$ is said to $\calF$-dominated another tuple $s$ if $t$ scores better than $s$ under all functions in $\calF$.
It has been verified that rskyline query is highly effective in restricting the set of tuples of interest.

In~\cite{DBLP:journals/pvldb/CiacciaM17, DBLP:conf/icde/Liu0ZP021}, many efficient algorithms have been proposed to answer rskyline queries on traditional datasets where no uncertainty is involved.
However, data uncertainty is inherent in multi-criteria decision making from various causes such as equipment limitations, data randomness, outdated sources, and so on~\cite{DBLP:journals/fcsc/LiWLG20}.
%In this paper, we investigate the problem of conducting rskyline queries on uncertain.
%We first describe two application scenarios as follows.
And typically using a probability distribution to model data uncertainty~\cite{DBLP:journals/tkde/KimIP12, DBLP:conf/pods/AtallahQ09, DBLP:conf/vldb/PeiJLY07}.
In this paper, we focus on computing rskyline probabilities on datasets with discrete uncertainty, \ie, each object is represented by a set of tuples, also called instances, and corresponding probabilities to take those particular instances, where the \textit{rskyline probability} of an object is defined as the probability that it is not $\calF$-dominated by any other objects with respect to a set of scoring functions $\calF$.
We first describe two application scenarios as follows.

\noindent\underline{\it E-commerce Scenario:}
Probabilistic selling is a novel selling strategy in e-commerce~\cite{DBLP:journals/mktsci/FayX08}.
%The sellers create probabilistic goods which involve a probability of getting any one of a set of multiple distinct products.
For example, when booking hotels on \textit{Hotwire}, each product has a probability of getting any one of a set of hotels with different locations and room numbers.
And only when users pay for a product, the particular hotel property is revealed to them.
Consider products provided by \textit{Hotwire} as an uncertain dataset with two attributed \textsc{\#Room} and \textsc{Loc} (\eg, distance to the beach).
If a user prefers \textsc{Loc} to \textsc{\#Room}, \ie, let $\calF = \{\omega_1 \textsc{\#Room} + \omega_2 \textsc{Loc} \mid \omega_1 \le \omega_2\}$, computing rskyline probabilities of products with respect to $\calF$ can mathematically quantify the probability that the final hotel obtained by choosing a product is a rskyline tuple.

\noindent\underline{\it Player Selection Scenario:}
The performance data of a player may vary differently game by game due to many factors such as fluctuations of playersâ€™ conditions, the locations of the games, and the support from audience.
Modeling players' game-by-game performance data as uncertain datasets for interesting knowledge and comprehensive view has been widely investigated in~\cite{DBLP:conf/vldb/PeiJLY07, DBLP:conf/cikm/LiuZXLL15, DBLP:journals/tkde/KimIP12}.
Suppose the two criteria for evaluating a player are \textsc{Point} and \textsc{Assist}, and it is pointed out that \textsc{Point} is more important than \textsc{Assist}, but no more than twice, \ie, $\calF = \{\omega_1 \textsc{Point} + \omega_2 \textsc{Assist} \mid \omega_2 \le \omega_1 \le 2\omega_2\}$.
Computing rskyline probabilities of players with respect to $\calF$ can compute the probability that a player belongs to rskyline players (\eg, most valuable players) of a game.

Instead of identifying objects with top-$k$ rskyline probabilities or whose rskyline probabilities are higher than a given threshold, we study the problem of computing rskyline probabilities of all objects from both complexity and algorithm perspective.
This overcomes the difficulty of selecting a suitable threshold and is convenient for users to retrieve results with different sizes.
For problem complexity, we prove that no algorithm can compute rskyline probabilities of all objects within truly subquadratic time, unless the Orthogonal Vectors conjecture~\cite{DBLP:conf/stacs/Bringmann19} fails.

Then, for efficient algorithms, we focus on a practically relevant case where $\calF$ consists of linear scoring functions whose weights are described by linear constraints.
A major challenge to overcome is the irregularity of the $\calF$-dominance region, which contains all instances $\calF$-dominated by an instance.
We address this by mapping objects into a higher dimensional data space and results in a near-optimal algorithm with time complexity $O(n^{2 - 1/d'})$, where $d'$ is the dimensionality of the mapped data space.
Furthermore, by conducting the mapping on the fly and designing effective pruning strategies, we propose an algorithm with better expercted time complexity based on the branch-and-bound paradigm.

When linear constraints are composed of $d - 1$ ratio bound constraints, we propose a more efficient $\calF$-dominance test method.
Based on the test condition, we establish a Turing reduction from the problem of computing rskyline probabilities of all objects to the half-space range search problem~\cite{agarwal2017simplex}.
And we introduce a $O(2^dmn\log{n})$-time algorithm with polynomial-time preprocessing, where $m$ and $n$ is the number of objects and instances, respectively.
Subsequently, we introduce a \textit{multi-level} structure and a \textit{data-shifting} strategy to further improve the time complexity to $O(2^{d-1}\log{n} + n)$, where the additional linear time is required by reporting the final results.
This algorithm matters from the following two aspects.
First, it proves that the \textit{online rskyline probability query} belongs to the complexity class $\mathrm{PsL}$~\cite{DBLP:journals/tcs/GaoLML20}, which can be further used to design efficient algorithms for other queries in $\mathrm{PsL}$.
Second, although this algorithm is somewhat inherently theoretical, experimental results shows that its extension for this special rskyline query on certain datasets outperforms the state-of-the-art index-based method proposed in~\cite{DBLP:conf/icde/Liu0ZP021}.


To the best of our knowledge, this paper is the first work conducting rskyline analysis on uncertain datasets.
The main contributions of this paper are summarized as follows.
\begin{enumerate}[$\bullet$]
	\item We formalize the problem of computing rskyline probabilities of all objects and prove that there is no algorithm can solve this problem in $O(n^{2-\delta})$ time for any $\delta > 0$, unless the Orthogonal Vectors conjecture fails.
	\item When $\calF$ consists of linear scoring functions whose weights are described by linear constraints, we propose an near-optimal algorithm with time complexity $O(n^{2 - 1/d'})$, where $d'$ is the number of vertices of the preference region, and an algorithm with expected time complexity $O(mn\log{n})$.
	\item When $\calF$ consists of linear scoring functions whose weights are described by $d-1$ ratio bound constraints, we propose an algorithm with polynomial preprocessing time and $O(2^{d-1}\log{n} + n)$ query time.
    For online rskyline probability query, we propose an algorithm with polynomial preprocessing time and $O(2^{d-1}\log{n})$ query time.
	\item We conduct extensive experiments over real and synthetic datasets to demonstrate the effectiveness of the problem studied in this paper and the efficiency and scalability of the proposed algorithms.
\end{enumerate}

The reminder of this paper is organized as follows.
We review the related work in Section~\ref{sec:relatedwork}.
We formally define the problem studied in this paper and study its conditional lower bound in Section~\ref{sec:preliminary}.
Then, we propose two efficient algorithms for the ARSP problem in Section~\ref{sec:rskyprobalg}, and design an algorithm with sublinear query time and polynomial preprocessing time for ratio bound constraints in Section~\ref{sec:eclprobalg}.
We report the experimental results in Section~\ref{sec:experiments}.
Finally, we conclude the paper in Section~\ref{sec:conclusions}.
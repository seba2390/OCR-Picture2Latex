\section{Related Work}
\subsection{Contextual Neural Machine Translation}
As the quality of single-sentence machine translation has improved dramatically with the advent of neural machine translation \citep{NIPS2014_a14ac55a,NIPS2017_3f5ee243}, translation models that take wider contexts into account have seen a surge of interest \citep{Jean2017DoesNM,bawden-etal-2018-evaluating,voita-etal-2019-good,voita-etal-2019-context,ma-etal-2020-simple,saunders-etal-2020-using}.
In contrast to the studies trying to incorporate information outside the sentence, in this work, we propose a method to improve zero-pronoun translation by only considering the information within the sentence, but we also explore the effect of combining our method with a contextual machine translation model.

\subsection{ZP Resolution in Japanese}
In some languages, pronouns are sometimes omitted when they are inferable from the context. Such languages are called pro-drop languages and the omitted pronouns are called ZPs.

The translation of ZPs poses a challenge when the corresponding pronoun is syntactically required on the target language side: the model has to infer the omitted pronoun.
The task of identifying the omitted pronouns is called ZP resolution and for Japanese, this has been a long-standing problem \citep{isozaki-hirao-2003-japanese,sasano-etal-2008-fully,imamura-etal-2009-discriminative,shibata-kurohashi-2018-entity}.
Japanese is one of the most difficult languages because Japanese words usually do not have any inflectional forms that depend on the omitted pronoun, unlike other pro-drop languages such as Portuguese and Spanish in which ZPs can be inferred from the grammatical case of other words.

Still, Japanese sentences sometimes contain expressions indicative of the missing pronoun. For example,  Japanese honorifics naturally indicate the subject is the second person.
In this work, we do not explicitly solve ZP resolution but let the translation model learn heuristic relations between ZPs and local context within the sentence \citep{hangyo-etal-2013-japanese,kudo-etal-2015-anlp} and produce appropriate English pronouns.


\subsection{ZPs in Translation}
In the context of statistical machine translation, Japanese ZPs are explicitly predicted by considering verbal semantic attributes \citep{nakaiwa-ikehara-1992-zero}, local context in the source and target sentence \citep{kudo-etal-2015-anlp}, and incorporated into the resulting translation.

On the other hand, in neural machine translation, the missing pronouns can be automatically inferred by the translation model because of the nature of end-to-end learning, although the correctness cannot be guaranteed. To improve the quality of ZP translation, previous studies have explored a multi-task approach with ZP prediction \citep{wang-etal-2016-novel,wang-etal-2019-one}.

In this study, we propose a ZP data augmentation method to provide additional training signals useful to correctly translate ZPs.

\chapter{Matrix Representations of Iterative Methods}
\label{chap:appendixRepresentations}

In this chapter, a collection of matrix representations of iterative methods is provided. The representations for the Krylov sequence, Steepest Descent, symmetric CG and nonsymmetric CG are modifications of the ones introduced in \cite{eijkhout:CGderivation}. The differences lie in the use of the underline. The representation for BiCG is based on the one for symmetric CG.
%
\section{Krylov Subspace Methods}
%
\subsection{Krylov Sequence}

\begin{align*}
P_\text{pre}: \{ &\text{\ttfamily Input}(A) \land \text{\ttfamily Matrix}(A) \land \\
		&\text{\ttfamily Matrix}[\underline{J}] \land \text{\ttfamily LowerDiagonalR}[\underline{J}] \land \\
		&\text{\ttfamily FirstColumnInput}(K) \land \text{\ttfamily Matrix}[K] \}
\end{align*}
%
\begin{align*}
P_\text{post}: \{ &A \underline{K} = K \underline{J} \\
			&\text{size}(K) = n \times m \}
\end{align*}

\subsection{Steepest Descent}

%
\begin{align*}
P_\text{pre}: \{ &\text{\ttfamily Input}[A] \land \text{\ttfamily Matrix}[A] \land \text{\ttfamily NonSingular}[A] \land \\
		&\text{\ttfamily Output}[D] \land \text{\ttfamily Matrix}[D] \land \text{\ttfamily Diagonal}[D] \land \\
		&\text{\ttfamily FirstColumnInput}[R] \land \text{\ttfamily Matrix}[R] \land \\
		&\text{\ttfamily ZeroDiagonal}[R^T R J] \land \text{\ttfamily ZeroDiagonal}[R^T R J^T] \land \\
		&\text{\ttfamily FirstColumnInput}[X] \land \text{\ttfamily Matrix}[X] \land \\
		& \text{\ttfamily Matrix}[\underline{I} - \underline{J}] \land \text{\ttfamily LowerTrapezoidal}[\underline{I} - \underline{J}] \}
\end{align*}
%
\begin{align*}
P_\text{post}:	\{ 	&ARD = R \left( \underline{I} - \underline{J} \right) \\
				&RD = X \left( \underline{I} - \underline{J} \right) \\
				&\| R e_r^T \| < \varepsilon \}
\end{align*}

\subsection{Conjugate Gradient (symmetric)}
%
\begin{align*}
P_\text{pre}: \{ &\text{\ttfamily Input}[A] \land \text{\ttfamily Matrix}[A] \land \text{\ttfamily NonSingular}[A] \land \text{\ttfamily Symmetric}[A] \land \\
		&\text{\ttfamily Output}[P] \land \text{\ttfamily Matrix}[P] \land \\
		&\text{\ttfamily Output}[D] \land \text{\ttfamily Matrix}[D] \land \text{\ttfamily Diagonal}[D] \land \\
		&\text{\ttfamily FirstColumnInput}[R] \land \text{\ttfamily Matrix}[R] \land \text{\ttfamily Orthogonal}[R] \land \\
		&\text{\ttfamily FirstColumnInput}[\underline{R}] \land \text{\ttfamily Matrix}[\underline{R}] \land \text{\ttfamily Orthogonal}[\underline{R}] \land \\
		&\text{\ttfamily DiagonalR}[R^T \underline{R}] \land \text{\ttfamily DiagonalR}[\underline{R}^T R] \land \\
		&\text{\ttfamily FirstColumnInput}[X] \land \text{\ttfamily Matrix}[X] \land \\
		&\text{\ttfamily Output}[U] \land \text{\ttfamily Matrix}[U] \land \text{\ttfamily UpperDiagonal}[U] \land \\
		& \text{\ttfamily Matrix}[\underline{I} - \underline{J}] \land \text{\ttfamily LowerTrapezoidal}[\underline{I} - \underline{J}] \}
\end{align*}
%
\begin{align*}
P_\text{post}:	\{ 	&APD = R \left( \underline{I} - \underline{J}  \right) \\
				&P \left( I - U \right) = \underline{R} \\
				&PD = X \left( \underline{I} - \underline{J} \right) \\
				&\| R e_r^T \| < \varepsilon \}
\end{align*}

\subsection{Conjugate Gradient (nonsymmetric)}

%
\begin{align*}
P_\text{pre}: \{ &\text{\ttfamily Input}[A] \land \text{\ttfamily Matrix}[A] \land \text{\ttfamily NonSingular}[A] \land \\
		&\text{\ttfamily Output}[P] \land \text{\ttfamily Matrix}[P] \land \\
		&\text{\ttfamily Output}[D] \land \text{\ttfamily Matrix}[D] \land \text{\ttfamily Diagonal}[D] \land \\
		&\text{\ttfamily FirstColumnInput}[R] \land \text{\ttfamily Matrix}[R] \land \text{\ttfamily Orthogonal}[R] \land \\
		&\text{\ttfamily FirstColumnInput}[\underline{R}] \land \text{\ttfamily Matrix}[\underline{R}] \land \text{\ttfamily Orthogonal}[\underline{R}] \land \\
		&\text{\ttfamily DiagonalR}[R^T \underline{R}] \land \text{\ttfamily DiagonalR}[\underline{R}^T R] \land \\
		&\text{\ttfamily FirstColumnInput}[X] \land \text{\ttfamily Matrix}[X] \land \\
		&\text{\ttfamily Output}[U] \land \text{\ttfamily Matrix}[U] \land \text{\ttfamily StrictlyUpperTriangular}[U] \land \\
		& \text{\ttfamily Matrix}[\underline{I} - \underline{J}] \land \text{\ttfamily LowerTrapezoidal}[\underline{I} - \underline{J}] \}
\end{align*}
%
\begin{align*}
P_\text{post}:	\{ 	&APD = R \left( \underline{I} - \underline{J} \right) \\
				&P \left( I - U \right) = \underline{R} \\
				&PD = X \left( \underline{I} - \underline{J} \right) \\
				&\| R e_r^T \| < \varepsilon \}
\end{align*}

\subsection{BiCG}

\begin{align*}
P_\text{pre}: \{ &\text{\ttfamily Input}[A] \land \text{\ttfamily Matrix}[A] \land \text{\ttfamily NonSingular}[A] \land \\
		&\text{\ttfamily Output}[P] \land \text{\ttfamily Matrix}[P] \land \\
		&\text{\ttfamily Output}[\tilde{P}] \land \text{\ttfamily Matrix}[\tilde{P}] \land \\
		&\text{\ttfamily Output}[D] \land \text{\ttfamily Matrix}[D] \land \text{\ttfamily Diagonal}[D] \land \\
		&\text{\ttfamily FirstColumnInput}[R] \land \text{\ttfamily Matrix}[R] \land \\
		&\text{\ttfamily FirstColumnInput}[\underline{R}] \land \text{\ttfamily Matrix}[\underline{R}]  \land \\
		&\text{\ttfamily FirstColumnInput}[\tilde{R}] \land \text{\ttfamily Matrix}[\tilde{R}] \land  \\
		&\text{\ttfamily FirstColumnInput}[\underline{\tilde{R}}] \land \text{\ttfamily Matrix}[\underline{\tilde{R}}] \land \\
		&\text{\ttfamily Diagonal}[R^T \tilde{R}] \land \text{\ttfamily Diagonal}[\underline{R}^T \underline{\tilde{R}}] \land \\
		&\text{\ttfamily DiagonalR}[\underline{R}^T \tilde{R}] \land \text{\ttfamily DiagonalR}[R^T \underline{\tilde{R}}] \land \\
		&\text{\ttfamily FirstColumnInput}[X] \land \text{\ttfamily Matrix}[X] \land \\
		&\text{\ttfamily Output}[U] \land \text{\ttfamily Matrix}[U] \land \text{\ttfamily UpperDiagonal}[U] \land \\
		& \text{\ttfamily Matrix}[\underline{I} - \underline{J}] \land \text{\ttfamily LowerTrapezoidal}[\underline{I} - \underline{J}] \}
\end{align*}
%
\begin{align*}
P_\text{post}:	\{ 	&APD = R \left( \underline{I} - \underline{J} \right) 
				&&A^T \tilde{P}D = \tilde{R} \left( \underline{I} - \underline{J} \right) \\
				&P \left( I - U \right) = \underline{R}
				&&\tilde{P} \left( I - U \right) = \underline{\tilde{R}} \\
				&PD = X \left( \underline{I} - \underline{J} \right) 
				&&\| R e_r^T \| < \varepsilon \}
\end{align*}



%\todo{do we include the following two? We can't use them. Okay, maybe we can. If they are included: Reference? One of Victor's TRs.}
%
%\subsection{Chronopoulos-Gear CG}
%
%The precondition of Chronopoulos-Gear CG is identical to the one for symmetric CG.
%
%\begin{align*}
%P_\text{post}:	\{ 	&T = P^T A P \\
%				&S = \underline{R}^T A \underline{R} \\
%				&S = \left( I - U \right)^T T \left( I - U \right) \\
%				&APD = R \left( \underline{I} - \underline{J}  \right) \\
%				&P \left( I - U \right) = \underline{R} \\
%				&PD = X \left( \underline{I} - \underline{J} \right) \\
%				&\| R e_r^T \| < \varepsilon \}
%\end{align*}
%
%\todo{I can probably just to the ``Saad'' part}
%
%\subsection{Saad-Meurant CG}
%
%The precondition of Saad-Meurant CG is identical to the one for symmetric CG.
%
%\begin{align*}
%P_\text{post}:	\{ 	&K = R^T R \\
%				&(I - J)^T K (I - J) = D^T P^T A^T APD \\
%				&APD = R \left( \underline{I} - \underline{J} \right) \\
%				&P \left( I - U \right) = \underline{R} \\
%				&PD = X \left( \underline{I} - \underline{J} \right) \\
%				&\| R e_r^T \| < \varepsilon \}
%\end{align*}

%\begin{table}[htdp]
%\begin{center}
%\begin{tabular}{|c|c|c|}
%
%\hline
%Name		&	Precondition	&	Postcondition \\ \hline
%%%%%%%%%%%%%%%%%%%%%
%Symmetric CG	&
%pre			&	
%$
%\begin{aligned}
%
%\end{aligned}
%$ \\ \hline
%%%%%%%%%%%%%%%%%%%%%
%Nonsymmetric CG	&
%pre				&	
%$
%\begin{aligned}
%APD &= R \left( I -J  \right) \\
%P \left( I - U \right) &= R \\
%PD &= X \left( I - J \right)
%\end{aligned}
%$ \\ \hline
%%%%%%%%%%%%%%%%%%%%%
%Steepest Descent	&
%pre				&	
%$
%\begin{aligned}
%APD &= P \left( I -J \right) \\
%PD &= X \left( I - J \right)
%\end{aligned}
%$ \\ \hline
%%%%%%%%%%%%%%%%%%%%%
%Bi-CG	&
%pre				&	
%$
%\begin{aligned}
%APD &= R \left( I -J  \right) \\
%A^T \tilde{P}D &= \tilde{R} \left( I -J  \right) \\
%P \left( I - U \right) &= R \\
%\tilde{P} \left( I - U \right) &= \tilde{R} \\
%PD &= X \left( I - J \right)
%\end{aligned}
%$ \\ \hline
%%%%%%%%%%%%%%%%%%%%%
%Chronopoulos-Gear CG	&
%pre					&	
%$
%\begin{aligned}
%T &= P^T A P \\
%S &= R^T A R \\
%S &= \left( I - U \right)^T T \left( I - U \right) \\
%APD &= R \left( I -J  \right) \\
%P \left( I - U \right) &= R \\
%PD &= X \left( I - J \right)
%\end{aligned}
%$ \\ \hline
%%%%%%%%%%%%%%%%%%%%%
%Saad-Meurant CG	&
%pre					&	
%$
%\begin{aligned}
%K &= R^T R \\
%(I - J)^T K (I - J) &= D^T P^T A^T APD \\
%APD &= R \left( I -J  \right) \\
%P \left( I - U \right) &= R \\
%PD &= X \left( I - J \right)
%\end{aligned}
%$ \\ \hline
%%%%%%%%%%%%%%%%%%%%%
%\end{tabular}
%\end{center}
%\caption{default}
%\label{default}
%\end{table}%

\section{Stationary Iterative Methods}
\label{sec:stationaryIterative}

Let $Ax = b$ be a linear system. $e$ is a column vector where all entries are one. We write $A$ as $A = D - L - U$, where $D$ contains the entries on the main diagonal of $A$, $L$ contains the entries below the main diagonal and $U$ the ones above the main diagonal. The representations for the Gauss-Seidel, Jacobi and Successive Overrelaxation method are based on the descriptions (in indexed notation) in \cite{barrett:templates}. The one for the Richardson iteration is based on the the description (in indexed notation) in \cite{eijkhout:CGderivation}.
%
\subsection{Gauss-Seidel Method}
%
\begin{align*}
P_\text{pre}: \{ &\text{\ttfamily Input}[D] \land \text{\ttfamily Matrix}[D] \land \text{\ttfamily Diagonal}[D] \land \\
		&\text{\ttfamily Input}[L] \land \text{\ttfamily Matrix}[L] \land \text{\ttfamily LowerTriangular}[L] \land \\
		&\text{\ttfamily Input}[U] \land \text{\ttfamily Matrix}[U] \land \text{\ttfamily UpperTriangular}[U] \land \\
		&\text{\ttfamily Input}[b] \land \text{\ttfamily Vector}[b] \land \\
%		&\text{\ttfamily Input}[\alpha] \land \text{\ttfamily Scalar}[\alpha] \\
		&\text{\ttfamily FirstColumnInput}[X] \land \text{\ttfamily Matrix}[X] \}
\end{align*}
%
\begin{align*}
P_\text{post}:	\{ 	&(D - L) X \underline{J} = U \underline{X} + be^T \\
				& \| X e_r^T - X e_{r-1}^T \| < \varepsilon \}
\end{align*}
%
\subsection{Jacobi Method}
%
The precondition of the Jacobi method is identical to the one for the Gauss-Seidel method.
%
\begin{align*}
P_\text{post}:	\{ 	&D X \underline{J} = ( L + U ) \underline{X} + be^T \\
				& \| X e_r^T - X e_{r-1}^T \| < \varepsilon \}
\end{align*}
%
\subsection{Successive Overrelaxation Method}
%
\begin{align*}
P_\text{pre}: \{ &\text{\ttfamily Input}[D] \land \text{\ttfamily Matrix}[D] \land \text{\ttfamily Diagonal}[D] \land \\
		&\text{\ttfamily Input}[L] \land \text{\ttfamily Matrix}[L] \land \text{\ttfamily LowerTriangular}[L] \land \\
		&\text{\ttfamily Input}[U] \land \text{\ttfamily Matrix}[U] \land \text{\ttfamily UpperTriangular}[U] \land \\
		&\text{\ttfamily Input}[b] \land \text{\ttfamily Vector}[b] \land \\
		&\text{\ttfamily Input}[\omega] \land \text{\ttfamily Scalar}[\omega] \\
		&\text{\ttfamily FirstColumnInput}[X] \land \text{\ttfamily Matrix}[X] \}
\end{align*}
%
\begin{align*}
P_\text{post}:	\{ &(D - \omega L) X \underline{J} = ( \omega U + (1 - \omega) D ) \underline{X} + \omega b e^T \\
			& \| X e_r^T - X e_{r-1}^T \| < \varepsilon\}
\end{align*}
%
%\subsection{Symmetric Successive Overrelaxation Method}
%%
%Now, we assume that $A$ is symmetric, so $L = U^T$. 
%
%\todo{correct version?}


\subsection{Richardson Iteration}
\begin{align*}
P_\text{pre}: \{ &\text{\ttfamily Input}[A] \land \text{\ttfamily Matrix}[A] \land \text{\ttfamily NonSingular}[A] \land \\
		&\text{\ttfamily Input}[b] \land \text{\ttfamily Vector}[b] \land \\
		&\text{\ttfamily Input}[\alpha] \land \text{\ttfamily Scalar}[\alpha] \\
		&\text{\ttfamily FirstColumnInput}[X] \land \text{\ttfamily Matrix}[X] \land \\
		&\text{\ttfamily Output}[R] \land \text{\ttfamily Matrix}[R] \}
\end{align*}
%
\begin{align*}
P_\text{post}:	\{ & \alpha R = X \left( \underline{I} - \underline{J} \right) \\
			& R = A \underline{X} - be^T \\
			& \| R e_r^T \| < \varepsilon \}
\end{align*}




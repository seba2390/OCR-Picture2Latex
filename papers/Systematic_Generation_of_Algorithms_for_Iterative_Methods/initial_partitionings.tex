\section{Initial Partitionings}
\label{sec:MatrixRepresentationPartitionings}

The first step towards the derivation of algorithms in the FLAME methodology is to partition the operands. The matrix representation of iterative methods gives rise to a new type of operands, namely those which are initially partially known and partially unknown. Thus, we have to address the question of how to partition them. To some extent, it is easy to answer. Standard CG algorithms always compute full vectors $r_i$ and $x_i$ \cite{barrett:templates, saad2000iterative, vanderVorst:book}, so refraining from partitioning $R$ and $X$ horizontally, that is, into a top and a bottom part, is a very natural choice. For partitioning vertically, there are multiple possibilities. Their advantages and disadvantages will be discussed in this section.

While not strictly necessary to derive algorithms, describing the partitioned op\-er\-ands in terms of functions proved to be useful for the systematic derivation \cite{Fabregat-Traver2011:54}. Hence, if and how different partitionings permit to match functions is an important criterion for their evaluation. %For CG, this function may not be what one would expect.

%Since finding such a systematic derivation is the goal of this thesis,
%we will also discuss if and how different partitionings permit to match functions in a meaningful way.

We begin this section with a discussion of what such a function should look like. Then, we investigate different possible partitionings, starting with partitionings that are also used for direct methods and continuing with some that are tailored to properties of algorithms for iterative methods.

\subsubsection{Functions}

On the highest level, the input of a CG algorithm are vectors $b$ and $x_0$, as well as the matrix $A$, so a function would have the form $x_i :=  \text{CG}(A, b, x_0)$. As we are using the recurrence relation to derive algorithms, which does not involve $b$, but a number of other quantities, for example the residual $r$, a function like this is not helpful.

From direct methods, we remember that the function is  uniquely\footnote{Except for the ordering of input and output.} defined by the precondition. Every quantity that is initially known has the property $\text{\ttfamily Input}[X]$, initially unknown quantities have the property $\text{\ttfamily Output}[X]$. Take the LU factorization as an example. The governing equation is $LU = A$. $A$ is input, $L$ and $U$ are output. This naturally leads to a function $\{L, U\} = \Psi (A)$. It is important to note that this function is defined prior to any derivation steps, solely based on the abstract description of the operation. It then happens, due to the recursive nature of the operations, \emph{and a partitioning that reveals it}, that this function matches expressions obtained by partitioning the postcondition. In some cases, the expressions have to be rewritten first. The remaining expressions can be decomposed into basic buildings blocks.

Applying this scheme to CG, the function $\{R, U, P, D, X\} := \text{CG} (A, R e_0, X e_0)$ is obtained. For simplicity, we omit $I$ and $J$ as input, since they are constant. 

\subsubsection{Standard 2 x 2 Partitioning}

Naturally, the first choice for a partitioning is the one that is usually used for direct methods. Partitioning $R$ into $\myFlaOneByTwo{R_L}{R_R}$ implies the following partitioning for equations (\ref{eq:CGrr1}) and (\ref{eq:CGrr2}). Because of its similarity to the first equation, we will usually omit equation (\ref{eq:CGrr3}) in this section.
%
\begin{align*}
A \myFlaOneByTwo{P_L}{P_R} \myFlaTwoByTwo{D_{TL}}{0}{0}{D_{BR}} &= \myFlaOneByTwo{R_L}{R_R} \myFlaTwoByTwo{I - J}{0}{-H}{\underline{I} - \underline{J}} \\
\myFlaOneByTwo{P_L}{P_R} \myFlaTwoByTwo{I - U_{TL}}{- U_{TR}}{0}{I - U_{BR}} &= \myFlaOneByTwo{R_L}{\underline{R}_R}
%\\
%\myFlaOneByTwo{P_L}{P_R} \myFlaTwoByTwo{D_{TL}}{0}{0}{D_{BR}} &= \myFlaOneByTwo{X_L}{X_R} \myFlaTwoByTwo{I - J}{0}{-H}{I - J}
\end{align*}
%
Here, $H$ is a matrix with one more row than columns that is one in the top right corner and zero everywhere else. Flattening the expressions, we obtain
%
\begin{align}
\myFlaOneByTwo{A P_L D_{TL} = R_L \left( I - J \right) - R_R H}{ A P_R D_{BR} = R_R \left( \underline{I} - \underline{J} \right) } \label{eq:CG:2x2s1}\\
%
\myFlaOneByTwo{P_L \left( I - U_{TL} \right) = R_L}{- P_L U_{TR} + P_R \left( I - U_{BR} \right) = \underline{R}_R} \text{.} \label{eq:CG:2x2s2}
\end{align}
%
%The CG function defined earlier abstracts from multiple equations. To match this function, there has to be a matching equation for each of them. Additionally, if a quantity appears in the original equation multiple times,
%
In this form, the expressions are not matched by the pattern of the CG function. While both the right equation of (\ref{eq:CG:2x2s1}) and the left one of (\ref{eq:CG:2x2s2}) have the correct shape, one contains $R_L$ and $P_L$, while $R_R$ and $P_R$ appear in the other. In the original equations, those quantities are the same. If it is possible to match the function at all, then either all parts on the left or all parts on the right match (or both). Rewriting the equation on the left in (\ref{eq:CG:2x2s1}) as
%
$$A P_L D_{TL} = \myFlaOneByTwo{R_L}{R_R} \myFlaTwoByOne{ I - J }{ -H}\text{,}$$
%
we recognize similarities to the corresponding equation of the recurrence relation (\ref{eq:CGrr1}). However,
%
$$\myFlaTwoByOne{ I - J }{ -H}$$
%
does not have one more row than columns. While we know that only the first row of $H$ has a nonzero entry, formally, this equation does not match the pattern.

\subsubsection{3 x 3 Partitioning}

The problem above can be solved by applying a $1 \times 3$ partitioning to $R$ where the middle part is a single column. This has the effect that the first row of $H$ becomes a separate block. As CG proceeds by one column per iteration, exposing a single column appears to be a suitable choice. The partitioned operands and the resulting expressions are shown below.
%
\begin{gather*}
A \myFlaOneByThree{P_L}{p_M}{P_R}
\myFlaThreeByThree{D_{TL}}{0}{0}
				{0}{\delta_{MM}}{0}
				{0}{0}{D_{BR}}
=\myFlaOneByThree{R_L}{r_M}{R_R}
\myFlaThreeByThree{I - J}{0}{0}
				{-e_r^T}{1}{0}
				{0}{-e_0}{\underline{I} - \underline{J}} \\
%
\myFlaOneByThree{P_L}{p_M}{P_R}
\myFlaThreeByThree{I - U_{TL}}{-u_{TM}}{-U_{TR}}
				{0}{1}{-u_{MR}}
				{0}{0}{I - U_{BR}}
= \myFlaOneByThree{R_L}{r_M}{\underline{R}_R}
\end{gather*}
%
\begin{align*}
\myFlaOneByThree{A P_L D_{TL} = R_L \left(I - J\right) - r_M e_r^T}{A p_M \delta_{MM} = r_M - R_R e_0}{A P_R D_{BR} = R_R \left( \underline{I} - \underline{J}  \right)} \quad \\
%
\myFlaOneByThree{P_L \left( I - U_{TL} \right) = R_L}{-P_L u_{TM} + p_M = r_M}{-P_L U_{TR} - p_M u_{MR} + P_R \left( I - U_{BR} \right) = \underline{R}_R}
\end{align*}
%
Now, a similar rewriting as in the previous section yields
%
$$A P_L D_{TL} = \myFlaOneByTwo{R_L}{r_M} \myFlaTwoByOne{ I - J }{ -e_r^T}\text{.}$$
%
Here, the constant matrix has one more row than columns, and $\myFlaOneByTwo{R_L}{r_M}$ has one more column than $R_L$ in $P_L \left( I - U_{TL} \right) = R_L$. Hence, those equations, together with the additional one for $X$, are matched by the pattern of the CG function. The resulting assignment is
%
\begin{gather*}
\left\{ \myFlaOneByTwo{R_L}{r_M}, U_{TL}, P_L, D_{TL}, \myFlaOneByTwo{X_L}{x_M} \right\} := \qquad \qquad \qquad \qquad \qquad \\ \qquad \qquad \qquad \qquad \qquad \text{CG} \left(A, \myFlaOneByTwo{R_L}{r_M} \myFlaTwoByOne{e_0}{0}, \myFlaOneByTwo{X_L}{x_M} \myFlaTwoByOne{e_0}{0} \right) \text{.}
\end{gather*}
%
While the equations in the middle are not matched by the function, they can be solved to $u_{TM}$, $p_M$, $\delta_{MM}$ and $R_R e_0$, leading to computable assignments. Unfortunately, the function does not match the equations on the right-hand side. For direct methods, in a comparable situation, an equation like
%
$${-P_L U_{TR} - p_M u_{MR} + P_R \left( I - U_{BR} \right) = \underline{R}_R}$$
%
would be rewritten as 
%
$${P_R \left( I - U_{BR} \right) = \underline{R}_R + P_L U_{TR} + p_M u_{MR}}\text{,}$$
%
such that $\underline{R}_R$ is updated. Here, this is not possible. While the first column of $\underline{R}_R$ can be considered known at this point, neither the first column of $P_L U_{TR}$ nor $p_M u_{MR}$ is known, because neither $U_{TR}$ nor $u_{MR}$ are known. Apart from that, $\underline{R}_R$ can not be updated, as this would have influences on the other two equations. Finally, if quantities are updated, they are usually updated in their entirety, before they are used as input for a function. Here, $U_{TR}$ and $u_{MR}$ are not known, and we would expect them to be the output of said function, leading to circular data dependencies.

\subsubsection{Splitting off the First Column}

Since the first column of $R$ and $X$, respectively, plays a special role, an entirely different approach could be to apply a partitioning that splits off this first column. $R$ is partitioned into $\myFlaOneByTwo{r_0}{R'}$, and for the actual derivation of algorithms, $R'$ is used. The advantage is that there is a clear distinction between input and output, and it would be possible to write CG as $\{R', \ldots, X'\} := \text{CG} (A, r_0, x_0)$. As usual, partitioning $R$ and $X$ like that also implies a matching partitioning for the remaining operands:
%
\begin{align*}
A \myFlaOneByTwo{p_0}{P'}
\myFlaTwoByTwo	{\delta_{0}}{0}
				{0}{D'}
&=\myFlaOneByTwo{r_0 }{ R'}
\myFlaTwoByTwo	{1}{0}
				{-e_0}{\underline{I} - \underline{J}} \\
%
\myFlaOneByTwo{p_0}{P'}
\myFlaTwoByTwo	{1}{-u'}
				{0}{I - U'}
&= \myFlaOneByTwo{r_0}{\underline{R}'}
\end{align*}
%
Flattening those expression, we immediately obtain a value for $p_0$:
%
\begin{gather*}
\myFlaOneByTwo{A p_0 \delta_0 = r_0 - R' e_0}{ A P' D' = R' \left( \underline{I} - \underline{J} \right)} \\
\myFlaOneByTwo{p_0 = r_0}{ - p_0 u' + P' \left(I - U' \right) = \underline{R}'}
\end{gather*}
%
Using the orthogonality of $R$, it is also possible to find an assignment for $\delta_0$. Thus, this partitioning allows to compute all quantities of the first iteration and declare them as known. Unfortunately, splitting off $r_0$ forces us to also split off the first row of $U$. At this point, it is not possible to compute it in its entirety. Furthermore, because of $-p_0 u'$, the equations on the right-hand side do not have the same shape as the original description of CG. While it is of course still possible to compute $u'$, it is only possible entry by entry, adding an additional assignment to any update we can derive. Consequently, it will not be possible to derive the updates for CG usually found in textbooks.%, for example \cite{barrett:templates, vanderVorst:book}.

%In case of nonsymmetric CG, $U$ is strictly upper triangular, so $u'$ is a full vector. For symmetric 

\subsubsection{Divide and Conquer}

So far, no partitioning enabled us to describe one CG operation as multiple, smaller CG operations, if necessary, with updated quantities as input, similar to how the PME of the triangular system in Section \ref{sec:triLS} contains the function $\Phi$ two times. This is, however, possible, if we define a generalized version of CG. The disadvantage is that it requires a deeper understanding of the algorithm, in addition to some knowledge that is initially not available when deriving algorithms solely based on their matrix representation.

To derive such a representation, we partition $R$ into \smash{$\myFlaOneByFour{R_0}{r_1}{r_2}{R_3}$}. Since the resulting partitioned postcondition is very large, it is not shown here. The generalized version of CG requires some parts of $P$ as an additional argument. Initially, it is only the first column $P$, here denoted with $P e_0$: $\{R, U, P, D, X\} := \text{CG} (A, R e_0, X e_0, P e_0)$. Since it is equal to the first column of $R$, it can be considered known. For now, we will assume that $A$ is nonsymmetric.

Our goal is now to write this CG operation as two separate ones, one covering \smash{$\myFlaOneByTwo{R_0}{r_1}$}, and one for \smash{$\myFlaOneByTwo{r_2}{R_3}$}. Clearly, the first one is
%
$$\left\{\myFlaOneByThree{R_0}{r_1}{r_2}, \ldots, \myFlaOneByTwo{P_0}{p_1}, \ldots, \myFlaOneByThree{X_0}{x_1}{x_2}\right\} := \text{CG} \left(A, R_0 e_0, X_0 e_0, P_0 e_0 \right) \text{,}$$
%
omitting some of the output in the interest of legibility. Now, to find the correct arguments for the second one, we need to know how $p_2$ is computed:
%
$$p_2 = r_2 + P_0 u_{02} + p_1 \nu_{12}$$
%
$u_{02}$ and $\nu_{12}$ are not part of the output of the function above, but they can in turn be computed using known quantities only:
%
\begin{align*}
u_{02} &= \left(- P_0^T A P_0 \right)^{-1} \cdot P_0^T A r_2 \\
\nu_{12} &= - \frac{p_1^T A r_2 + p_1^T A P_0 u_{02}}{p_1^T A p_1}
\end{align*}
%
To eliminate them entirely, we can also write 
%
$$p_2 = r_2 - \myFlaOneByTwo{P_0}{p_1} \myFlaTwoByTwo{P_0^T A P_0}{0}{p_1^T A P_0}{p_1^T A p_1}^{-1} \myFlaTwoByOne{P_0^T A r_2}{p_1^T A r_2} \text{.}$$
%
Now, we can write the second part as
%
$$\{R_3, \ldots, P_{3}, \ldots, X_3\} := \text{CG} \left(A, r_2, x_2, \myFlaOneByThree{P_0}{p_1}{p_2} \right) \text{.}$$
%
To ensure that this function computes the correct sequence of search directions, it also has to use the ones computed by the first function, which are $\myFlaOneByTwo{P_0}{p_1}$. This is the reason why not just $p_2$, but $\myFlaOneByThree{P_0}{p_1}{p_2}$ is input.

This situation is slightly different if $A$ is symmetric. In that case, $U$ is upper diagonal and $P^T A P$ is diagonal, so $p_2$ is computed as
%
$$p_2 = r_2 - p_2 \frac{p_1^T A r_2}{p_1^T A p_1}\text{.}$$
%
Now, each search direction is computed using only the last one, so $\myFlaOneByTwo{P_0}{p_1}$ is not needed as input. Thus, the second function simplifies to
%
$$\left\{R_3, \ldots, P_{3}, \ldots, X_3 \right\} := \text{CG} \left(A, r_2, x_2, p_2\right) \text{.}$$
%
As mentioned before, the disadvantage is that we already need to know how some quantities are computed to derive this representation, while it is actually our goal to find those updates.

\subsubsection{Splitting off the Last Column}

Among those presented in this section, the $3 \times 3$ partitioning that exposes a single column is the only one that resulted in expressions that were naturally matched by the CG function. The problem of this partitioning is that there is no obvious way how to deal with the right-hand side parts.

To find one that better suits iterative methods, it is helpful to again inspect the differences to direct methods. After all, the $3 \times 3$ partitioning came to existence as a modification of the standard partitioning used for direct methods. As mentioned before, with direct methods, the sizes of all operands are initially known. Thus, at any point during the computation, there are (potentially empty) parts of operands that are already computed, and (potentially empty) parts that are not computed yet. The loop invariant describes those parts that are already computed at the beginning of the loop body. Conversely, one can think of those parts of the PME that are not part of the loop invariant as those parts that are not computed yet.

To see that this is consistent, recall that the reason that the full set of nodes can never be a feasible loop invariant is that it would imply that the solution is already computed before the loop is entered. Clearly, this is equivalent to saying that there are no parts left that are not computed yet, even before the loop is entered.

In case of iterative methods, there is little use in talking about parts of operands that are not yet computed beyond the current iteration, as each iteration might be the last.
%If the right-hand side parts of the $3 \times 3$ partitioning were matched by a function, this function could not be part of any loop invariant, just as with direct methods. Recall that the reason is that this loop invariant would imply that the solution is already computed before the loop is entered. Thus, in a manner of speaking, those parts represent those iterations that are not computed yet.
We can conclude that it makes little sense to use a partitioning where the right-hand side is more than a single column.

The solution is to use a partitioning that is a hybrid of the standard $2 \times 2$ partitioning and the $3 \times 3$ partitioning that exposes a single column: A partitioning that splits off the last column: $P$ is partitioned into $\myFlaOneByTwo{P_L}{p_R}$. Because of the additional column of $R$, it is partitioned into $\myFlaOneByThree{R_L}{r_R}{r_+}$. Thus, for CG, we obtain
%
\label{eq:partitionedPostconditionNonsymCG}
\begin{align*}
A \myFlaOneByTwo{P_L}{p_R} \myFlaTwoByTwo{D_{TL}}{0}{0}{\delta_{BR}} &= \myFlaOneByThree{R_L}{r_R}{r_+} \myFlaThreeByTwo{I - J}{0}{-e_r^T}{1}{0}{-1} \\
\myFlaOneByTwo{P_L}{p_R}\myFlaTwoByTwo{I- U_{TL}}{- u_{TR}}{0}{1} &= \myFlaOneByTwo{R_L}{r_R} \\
\myFlaOneByTwo{P_L}{p_R} \myFlaTwoByTwo{D_{TL}}{0}{0}{\delta_{BR}} &= \myFlaOneByThree{X_L}{x_R}{x_+} \myFlaThreeByTwo{I - J}{0}{-e_r^T}{1}{0}{-1} \text{.}
\end{align*}
%
Flattening those expressions yields
%
\begin{gather*}
\myFlaOneByTwo{A P_L D_{TL} = R_L \left( I - J \right) - r_R e_r^T}{ A p_R \delta_{BR} = r_R - r_+ } \\
\myFlaOneByTwo{P_L \left( I - U_{TL} \right) = R_L}{ - P_L u_{TR} + p_R = r_R} \\
\myFlaOneByTwo{ P_L D_{TL} = X_L \left( I - J \right) - x_R e_r^T}{ p_R \delta_{BR} = x_R - x_+ } \text{.}
\end{gather*}
%
The left-hand side parts are now matched by
%
\begin{gather*}
\left\{ \myFlaOneByTwo{R_L}{r_R}, U_{TL}, P_L, D_{TL}, \myFlaOneByTwo{X_L}{x_R} \right\} := \qquad \qquad \qquad \qquad \qquad \\ \qquad \qquad \qquad \qquad \qquad \text{CG} \left(A, \myFlaOneByTwo{R_L}{r_R} \myFlaTwoByOne{e_0}{0}, \myFlaOneByTwo{X_L}{x_R} \myFlaTwoByOne{e_0}{0} \right) \text{.}
\end{gather*}
%
Using some of the properties derived with the approach presented in Section \ref{sec:propertyDerivation}, the equations on the right can be solved to all remaining unknowns. Thus, we obtain a PME with assignments for every unknown quantity. The systematic derivation of loop-based algorithms, using this partitioning, is presented in the next chapter.

Note that this PME can be interpreted as an ``inductive PME'': Assuming it is possible to compute an arbitrary number of previous iterations, it is possible to compute one additional iteration. The previous iterations are represented by the CG function, and the additional iteration is computed using the remaining, explicit assignments of the PME. The base case is obtained by assuming all left and top left parts to be empty.
%\todo{CG difference: function itself never shows up in the update}
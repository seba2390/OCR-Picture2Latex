\chapter{Introduction}

The goal of this thesis is to simplify the development of algorithms for iterative methods. We present a methodology for the systematic derivation of such algorithms and lay the foundations for a system that automates the generation of algorithms and code for iterative solvers for linear systems.

%A methodology for the systematic derivation of such algorithms is presented. Thereby, we lay the foundations for a system that automates the generation of algorithms and code for iterative solvers for linear systems.

Over the last few decades, iterative methods have become an indispensable tool for solving sparse linear systems. Such systems commonly occur in science and engineering, for instance when discretized partial differential equations have to be solved. While direct methods are a reliable tool to solve linear systems, their ability to use the sparsity of a matrix to their advantage is limited to specific sparsity patterns.
% not able to use the sparsity of a matrix to their advantage. %The reason is that for example the LU decomposition of a sparse matrix is in general not sparse: While a very large sparse matrix might fit into memory, a dense matrix of the same dimensions quite likely does not, making the use of direct methods infeasible.
Often enough, those sparse systems are so large that using direct methods is impractical.

Since the introduction of the Conjugate Gradient (CG) method in 1952 \cite{hestenes1952methods}, much progress has been made in the field (for an overview, consider \cite{barrett:templates, saad2000iterative, vanderVorst:book}).
%
%Direct methods like the LU decomposition do not preserve the sparseness of a matrix.
%
%Applying direct methods, for example the LU decomposition, to sparse matrices usually leads to matrices that are not sparse. 
%
%where direct methods are infeasible
%
However, the way from an expert's idea for an algorithm to a working implementation is still a long one.
%Iterative methods are no exception.
At first, a formal description of the algorithm has to be derived on paper. Then, it has to be shown that the algorithm is correct, something that ideally follows from the derivation. Furthermore, to assess how useful the algorithm is in practice, it is desirable to prove that it is numerically stable. Finally, the algorithm has to be translated into code. Usually, that is done multiple times, for different languages, or potentially using different libraries. Every one of those steps takes time and is a potential source of errors.

To speed up this process and eliminate those sources of error, one may try to automate some or all of the steps described above. Automating the ingenuity of the iterative methods expert certainly lies in the distant future. In contrast, automatically translating a sufficiently formal description of an algorithm into code is a lot more feasible.

This thesis covers the systematical derivation of provably correct (pseudocode) algorithms, based on an abstract, formal description of an iterative method.

%This thesis focuses on the middle part of the process described above. An approach will be presented for systematically deriving provably correct (pseudocode) algorithms, based on an abstract, formal description of an iterative method.

%Based on an abstract, formal description of an iterative method, multiple provably correct algorithms in pseudocode are derived.
%
%However, research conducted over the past 15 years in the field of automation has shown that much more than that is possible.
%
\section{Background: FLAME}

The Formal Linear Algebra Methods Environment (FLAME) \cite{Bientinesi2005:504, gunnels2001flame} is a project with the goal to automate the derivation of linear algebra algorithms, as well as their implementation.
%As part of this project, a simple, index-free notation for deriving and representing algorithms was introduced \cite{}\todo{farewell to indices?}.
In \cite{Bientinesi:thesis}, it was shown that it is possible to systematically derive algorithms for dense linear algebra in a number of well defined steps.

The starting point of this derivation is a formal description of the input, consisting of a precondition ($P_\text{pre}$) and a postcondition ($P_\text{post}$). As an example, the description of a linear system where A is lower triangular is shown below:
%
\begin{align*}
x:= \Phi ( A, b) \equiv
\left\{
\begin{aligned}
P_\text{pre}: \{ &\text{\ttfamily Input}[A] \land \text{\ttfamily Matrix}[A] \land \text{\ttfamily NonSingular}[A] \land \\
		&\text{\ttfamily LowerTriangular}[A] \land \\
		&\text{\ttfamily Input}[b] \land \text{\ttfamily Vector}[b] \land \\
		&\text{\ttfamily Output}[x] \land \text{\ttfamily Vector}[x] \} \\
P_\text{post}: \{ & Ax = b \}
\end{aligned}
\right. %\label{eq:introExample}
\end{align*}
%
The function $x:= \Phi (A, b)$ is used to abstract from the details of this representation.

At the core of the derivation lies the concept of a Partitioned Matrix Expression (PME). A PME describes all parts of the output operands of a linear algebra operation in terms of parts of the input operands. 
%and serves as a starting point for the derivation.
For the lower triangular system, the equation $Ax=b$ is partitioned as
%
$$\myFlaTwoByTwo{A_{TL}}{ 0 }{A_{BL}}{A_{BR}} \myFlaTwoByOne{x_T}{x_B} = \myFlaTwoByOne{b_T}{b_B}\text{,}$$
%
where $A_{TL}$ and $A_{BR}$ are square. Then, the PME is
%
$$\myFlaTwoByOne{x_T := \Phi \left( A_{TL}, b_T \right)}{x_B := \Phi \left( A_{BR}, b_B - A_{BL} x_T \right)} \text{.}$$
%
%From this PME, multiple loop invariants are obtained. A loop invariant ($P_\text{inv}$) is a logical predicate that is true at certain points of a loop in an algorithm. It is true before the loop is entered and after it is left, as well as at the beginning and the end of the loop body. Finally, each loop invariant is used as a basis to construct one algorithm.
%
% (1) The resulting algorithms are provably correct because they are built around a proof of correctness.
%
%\todo{1}
%
The approach described in \cite{Bientinesi:thesis} has a number of advantages: %(1) It allows to derive provably correct algorithms. Since every algorithm is built around a loop invariant, it is possible to formally reason about the correctness of the algorithm without the difficult task of identifying a loop invariant after the construction.
(1) The resulting algorithms are built around a proof of correctness, so they are correct by construction. (2) It naturally leads to multiple variants of algorithms for the same operation. While they are all correct in exact arithmetic, they potentially behave very different in presence of round-off errors. (3) Furthermore, it was shown that this derivation can be combined with a systematic stability analysis \cite{Bientinesi2011:810}.

The author of \cite{Bientinesi:thesis} presented evidence that this derivation, based on a formal description of the operation and the PME, is systematic enough to be automated. A system that automates this process, including the generation of PMEs, was presented in \cite{Fabregat-Traver:thesis, Fabregat-Traver2011:238}. 

%One of the strengths of this approach is that it allows to derive provably correct algorithms. This is done constructing the algorithm from a loop invariant ($P_\text{inv}$), which allows to formally reason about the correctness or the resulting algorithm \todo{mention Hoare logicâ€¦?}\cite{}. Another advantage of this approach is that it naturally leads to multiple variants of algorithms that compute the same operation. While they are all correct in exact arithmetic, they potentially behave very different in presence of round off errors. Furthermore, it was shown that this derivation can be combined with a systematic stability analysis. Finally, the author presented evidence that this derivation, based on a formal description of the operation and the PME, is systematic enough to be automated.


%can be done systematically, indicating that it is possible to automate this process.



%One part of this process is a methodology to derive provably correct algorithms, based on a formal description of the operation \cite{}. It started with a systematic procedure that allowed a person with sufficient knowledge about linear algebra to derive an algorithm following a number of well-defined steps. In \cite{Bientinesi:thesis}, evidence was presented that this can be done automatically, without any human intervention.
%
%
%In this thesis, the concept of a Partitioned Matrix Expression (PME) was introduced in \cite{Bientinesi:thesis}. A PME describes all parts of the output operands in terms of parts of the input operands and serves as a starting point for the derivation of algorithms. Furthermore, the author showed that the derivation of algorithms, based on a formal description of the operation
%%the predicates $P_\text{pre}$ and $P_\text{post}$
%and the PME, can be done systematically, indicating that it is possible to automate this process.
%
%A system that automates this process, including the generation of PMEs, was presented in \cite{Fabregat-Traver:thesis}.
%
%
%
%\todo{reference TRs?}
%
%
%Traditionally, at the core of the derivation of such methods are elaborate proofs by induction.

All of the efforts described above focused on direct methods. Naturally, the question arises if this methodology extends to iterative methods. In \cite{eijkhout:CGderivation}, Eijkhout et al.\ introduced a matrix representation of the CG method and showed preliminary evidence that a systematic derivation of algorithms with a FLAME-like methodology is possible. However, the approach presented there heavily relied on guidance by a human expert. This thesis can be seen as a continuation of this work.

\section{Challenges}

The systematic derivation of algorithms for iterative methods introduces new challenges, especially  for deriving the PME.
%
\begin{itemize}
\item[-] For direct methods, the sizes of all operands are constant. In case of iterative methods, a variable number of iterations can be performed. In the matrix representation, this is reflected by the fact that some operands have variable sizes.
\item[-] The matrix representation of iterative methods introduces new types of op\-er\-ands. Usually, an operand is either known or unknown, so it is input or output, respectively. Now, there are operands that are initially partially known and partially unknown.
\item[-] Quite often, equations have to be solved by using properties of certain expressions. Consider the following equation as an example:
%
$$-P u + p = r$$
%
$P$, $p$ and $r$ are known, and the goal is to find an assignment for $u$. It can be solved by using the fact that $P^T A P$ is lower triangular and $P^T A p$ is zero ($A$ is known as well). Multiplying $P^T A$ from the left to both sides of the equation results in
%
$$-P^T A P u = P^T A r \text{,}$$
%
which is a triangular system that can easily be solved.

This introduces two challenges: The properties of $P^T A P$ and $P^T A p$ are not explicitly part of the matrix representation, so they have to be derived from it by algebraic manipulations and deductive reasoning. Then, to enable a system to solve this equation, it must be capable of identifying that  the properties of those expressions can be used to do so.
\item[-] To ensure that the derived algorithms can be used in practice, it is desirable to derive the exact same algorithms as used today. The difficulty in achieving this goal lies in the fact that some of those algorithms are the result of nontrivial rewritings of easily derivable formulas. Those rewritings are hard to automate.
\end{itemize}
%




\section{Contributions}

The following contributions are made in this thesis:

\begin{description}
\item[Systematic derivation of algorithms for iterative methods.] We present an approach for sys\-tematically deriving algorithms for iterative methods similar to the one discussed above for direct methods. To achieve this, we present solutions to the following two problems:

\begin{description}

\item[Systematic derivation of matrix properties.] To be able to derive algorithms, properties of matrices or matrix expressions are needed that are not explicitly part of the formal description of the operation. We present a method for deriving those properties from the description, using a set of inference rules that encode linear algebra knowledge.

\item[Systematic derivation of PMEs for iterative methods.] The derivation of PMEs for iterative methods is more complex compared to direct methods. As part of this derivation, equations have to be solved using the derived matrix properties.

\end{description}
\end{description}

The presented methodology is systematic enough to be executed mechanically, that is, without any human intervention, thus setting the ground for a system that indeed automates its application.

Having made clear what is accomplished with this thesis, it should also be pointed out what is beyond its scope: The input to the derivation process is a representation of an iterative method that still has to be derived by an expert in the field. In case of direct methods, the formal description that is input immediately follows from the operation itself, as shown above for the lower triangular system. 
%In case of direct methods, the equation that defines for example the LU decomposition, $LU = A$, together with the properties of the operands, is sufficient to derive algorithms \todo{LU is used to solve linear systems, so maybe that's a bad example, because it doesn't naturally follow from $Ax=b$ either. Sylvester?}.
In contrast, the way from a linear system $Ax=b$ to a formal description of an iterative method that is suitable as input for the presented approach is much more complicated.

\section{Outline of the Thesis}

The thesis is structured as follows: Chapter \ref{chap:directMethods} serves as an introduction to familiarize the reader with the FLAME approach for deriving algorithms for direct methods. In Chapter \ref{chap:iterativeMethodsIntro}, we lay the foundations for applying a similar approach to iterative methods. The matrix representation for iterative methods is introduced in Section \ref{sec:matrixRepresentationIntroduction}. In Section \ref{sec:propertyDerivation}, we describe a method for systematically deriving matrix properties from this representation. At the end of this chapter, in Section \ref{sec:MatrixRepresentationPartitionings}, the implications of the matrix representation for the derivation of algorithms are discussed. In Chapter \ref{chap:derivationIM}, we explain how to derive algorithms for iterative methods. Finally, Chapter \ref{chap:conclusion} summarizes the results of this thesis and points out opportunities for future research.%In Appendix \ref{chap:appendixProperties}, a number of matrix properties are defined, and Appendix \ref{chap:appendixRepresentations} lists several matrix representations of iterative methods.


%\newpage
%
%\todo{Mention:}
%
%\begin{itemize}
%\item What are we trying to do?
%\item Why is that interesting/different/novel?
%\item The reader should familiarize himself with the FLAME methodology.
%\item Difference between iterative and directs methods, especially in matrix form.
%\item Provably correct algorithms.
%\item We are not concerned with the usefulness of the derived algorithms.
%\end{itemize}


%	So my contribution would be
%	
%	a) to apply the FLAME methodology to a number of iterative methods
%	b) define/find PMEs for iterative methods
%	c) show that it can be done systematically
%	Yes. The automatic derivation of properties is also new in the context of FLAME. So:
%
%1) You apply the FLAME methodology to a number of iterative methods
%2) What is the problem with the direct-method approach:
%   a) Need to derive properties beyond what is given in the precondition
%   b) Generation of PMEs requires more complex processing using these properties
%3) You show that 2 (and thus the whole process) can be done systematically




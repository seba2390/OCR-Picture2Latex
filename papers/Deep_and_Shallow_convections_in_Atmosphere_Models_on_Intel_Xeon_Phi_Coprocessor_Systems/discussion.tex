\section{Discussion}
\label{discussion}

While we had primarily worked on and demonstrated our results for a climate modeling application, we can derive some general principles that can be applied for other scientific applications.

The shallow convection loop that we consider in our study of fine-grained parallelism on the Xeon Phi, displayed loop level data parallelism involving hundreds of multi-dimensional variables. Our optimization related to data management served to illustrate the importance of carefully choosing and designing the OpenMP clause (dynamic vs static scheduling, data management clauses), not only for correctness but also for performance. While studying the scalability of the unoptimized version, we noted that designating variables as firstprivate led to poor scalability of the loop on the Xeon, and this negative effect was vastly amplified on the Xeon Phi. The underlying cause is the bottleneck created by the memory copies that are used to implement this clause. These challenges will be widely seen in future large-scale scientific applications when deployed on the widely prevalent large-scale heterogeneous architecture. A generic tool that automatically chooses the OpenMP clause based on performance will be highly useful for the scientific community. Building such a tool can be part of our future work.

Based on the results in Figures \ref{opt_deepshallow_perf_xeon} and \ref{opt_deepshallow_perf_xeonphi} and Table \ref{pp_results}, we find that the Xeon Phi shows 2X slowdown when compared to the Xeon CPU. This is primarily due to the poor single thread performance on Xeon Phi, and the lack of vectorization opportunities in the critical loops of the shallow and deep convection routines, in which convergence is tested for termination. We expect the performance to improve in the next generation Intel Xeon Phi Knoghts Landing processors that have superior single thread performance.

Proportional partitioning of computations to Xeon and Xeon Phi can generally be applied to applications and loops where the co-processor can serve as yet another in-node compute device that can lead to overall reduction in application runtime. Applications that consider fine-grained offloading of parallel computations involving multiple transfers of large number of small arrays should consider packing of the data into structure of arrays.

The Xeon Phi supports hardware instructions for certain transcendental operations like power, exp, etc. It is likely that many scientific codes make heavy use of these operations, but rarely experiment by changing the floating point model used because of the potential impact that it could have on correctness of the simulation output. We performed a study to illustrate the potential performance benefits of using these hardware instructions on the Xeon Phi, and demonstrated about 8\% improvement in performance of shallow convection loop by using a fast-math floating point model, with an acceptable level of accuracy.

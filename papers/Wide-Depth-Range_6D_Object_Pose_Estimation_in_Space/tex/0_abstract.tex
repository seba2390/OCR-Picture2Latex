% !TEX root = ../top.tex
% !TEX spellcheck = en-US

%%%%%%%%% ABSTRACT
\begin{abstract}
% Performing reliable 6D pose estimation in space poses challenges that most earth-bound algorithms do not address. Chief among them is the fact that objects can be seen at very different scales, a problem that is underrepresented in traditional benchmark datasets and, hence, underappreciated in our community.
%
% Existing approaches to solving this problem rely on a two-stage approach that first estimates scale and then pose on a resized image patch. We propose instead a single-stage hierarchical end-to-end trainable network that yields better robustness to scale variations.
% We will demonstrate that it outperforms existing approaches not only on images synthesized to resemble images taken in space but also on standard benchmarks.

    6D pose estimation in space poses unique challenges that are
    not commonly encountered in the terrestrial setting. One of the most
    striking differences is the lack of atmospheric scattering, 
    allowing objects to be visible from a great distance while complicating illumination conditions.
    %which implies
    %that objects can be observed at vastly different scales as the camera (e.g.,
    %on a satellite) approaches an object. \MS{Why is this due to the lack of atmospheric scattering?} 
    %\YH{In my understanding, this is because the air near the earth's surface can also occlude something?
    %While, to be honest, this is too technical.}
    Currently available benchmark
    datasets do not place a sufficient emphasis on this aspect and mostly
    depict the target in close proximity.

    Prior work tackling pose estimation under large scale variations relies on a two-stage approach to first estimate
    scale, followed by pose estimation on a resized image patch. We instead
    propose a single-stage hierarchical end-to-end trainable network that is
    more robust to scale variations. We demonstrate that it outperforms
    existing approaches not only on images synthesized to resemble images taken
    in space but also on standard benchmarks.
\end{abstract}

%Earth orbits become more and more congested, which is a severe threat to space safety. Estimating 6D pose of space-borne objects is the crucial component of the future solutions, such as debris removal and spacecraft interactivity. Unlike general 6D object pose estimation, the object in space often exhibits a wide depth range, making the general method suffering from the scaling problem. A straightforward strategy is to detect the target first and resize the detected object to a uniform resolution before pose estimation, which, however, is heavy and suboptimal. In this paper, we propose to use a single hierarchical network to handle this problem.  Moreover, we introduce a scale-aware sampling strategy during training to make pyramid levels interactive with others. Based on it, we show that pose fused from multiple levels can achieve much more accurate results. To fully demonstrate the effectiveness of our method in space, we introduce a photorealistic satellite dataset based on a Cubesat-type satellite SwissCube, which is the first satellite dataset with accurate 3D models, complex movement modelings, and also physical simulations of the Sun, Earth, and galaxies. Furthermore, we show that our multi-scale fusion framework is also effective in the general 6D object pose estimation, demonstrated by achieving state-of-the-art performance on the general 6D pose dataset.

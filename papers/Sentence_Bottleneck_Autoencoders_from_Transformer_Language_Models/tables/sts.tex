

\begin{table}[t]
	\centering 
	\footnotesize
	\renewcommand{\arraystretch}{1.3}
	\begin{tabular}{l | c | c}
		\toprule
		\textbf{Model} & \textbf{Spearman} & \textbf{Parameters} \\ \midrule
		\multicolumn{3}{l}{\textit{Unsupervised}} \\\midrule
% 		\multicolumn{2}{l}{\textit{Trained on NLI (not STS Benchmark)}} \\ \hline
		Avg.\ GloVe embeddings & 58.02 & - \\
		Avg.\ BERT embeddings &  46.35 & - \\
		\textsc{Autobot}-base unsup. & \textbf{58.49} & - \\\midrule
		\multicolumn{3}{l}{\textit{Supervised}} \\\midrule
		InferSent - GloVe &  68.03 & - \\
		Universal Sentence Encoder &  74.92 & - \\
% 		SBERT-base & 77.03 & \\
% 		SBERT-large & 79.23 & \\\hline

        % BERT-base & 74.81 & 110M \\
        RoBERTa-base & 75.37 & 125M\\
% 		SBERT-base & 76.81 & 110M \\
		SRoBERTa-base & 76.89 & 125M \\
% 		AUTOBOT BERT-base & 77.03 & 111M \\
		\textsc{Autobot}-base (ours) & \textbf{78.59} & 127M \\\hline
        % BERT-large & 78.67 & 336M \\
        RoBERTa-large & 80.16 & 355M \\
% 		SBERT-large & 79.23 & 336M \\
% 		SRoBERTa-large &  \textbf{80.32}  & 355M \\
% 		AUTOBOT BERT-large & 77.01 & 338M \\
% 		AUTOBOT RoBERTa-large & 79.93 & 360M \\
		 
% 		AUTOBOT RoBERTa-base ft1 & 77.24 & \\
% 		ft 2 & 76.17 & \\
% 		ft 3 & 76.20 & \\
% 		ft 1 10k & 78.26 & \\
% 		ft 2 10k & 77.03 & \\
% 		ft 3 10k & 77.37 & \\
% 		SBERT-base  &  85.35 &  \\
% 		SRoBERTa-base  & 84.79  & \\
% 		SBERT-large & 86.10 &  \\
% 		SRoBERTa-large & 86.15  &\\\hline 
% 		BARNEY BERT-base &  84.25 &  \\  % 84.31
% 		BARNEY RoBERTa-base &  & \\
% 		BARNEY BERT-large &  &\\
% 		BARNEY RoBERTa-large &  &\\
% 		\multicolumn{2}{l}{\textit{Trained on STS Benchmark}} \\ \hline
% 		BERT-base & 84.30 $\pm$ 0.76  \\
% 		SBERT-base & 84.67 $\pm$ 0.19 \\ 
% 		SRoBERTa-base & 84.92 $\pm$ 0.34 \\
% 		BARNEY RoBERTa-base &  $\pm$  \\
% 		BARNEY BERT-base &  $\pm$  \\ \hline 
		
% 		BERT-large  & 85.64 $\pm$ 0.81 \\ 
% 		SBERT-large & 84.45 $\pm$ 0.43 \\ 
% 		SRoBERTa-large & 85.02 $\pm$ 0.76 \\ 
% 		BARNEY RoBERTa-base &  $\pm$  \\
% 		BARNEY BERT-base &  $\pm$  \\ \midrule
		
% 		\multicolumn{2}{l}{\textit{Trained on NLI + STS benchmark}} \\ \hline
		
% 		BERT-base & 88.33 $\pm$ 0.19 \\ 
% 		SBERT-base & 85.35 $\pm$ 0.17 \\ 
% 		SRoBERTa-base & 84.79 $\pm$ 0.38 \\ 
% 		BARNEY RoBERTa-base &  $\pm$  \\
% 		BARNEY BERT-base &  $\pm$  \\ \hline 
		
% 		BERT-large & 88.77 $\pm$ 0.46 \\ 
% 		BARNEY RoBERTa-base &  $\pm$  \\
% 		BARNEY BERT-base &  $\pm$  \\
    \bottomrule
	\end{tabular}
	\caption{ \label{tab:nli_sts}On semantic textual similarity (STS), \textsc{Autobot} outperforms previous sentence representation methods and reaches a score similar to RoBERTa-large while having fewer parameters.   %The transformer models were finetuned on the natural language inference training set, and 
	We report Spearman's rank correlation on the test set and the model sizes are reported in terms of trained parameter size.}
% 	The test performance of different models finetuned on the NLI training set then evacuated on the STS test set. The model sizes are reported in parameter size for comparison. 

% 	\ivan{SBERT, whose framework we evaluate in using their hyperparameters, doesn't even have a significant improvement in the large model. I suspect this is due to not enough hyperparameter search. Should we keep just RoBERTa-large for the large models to keep our claim?} \ivan{They also actually don't report RoBERTa-large results}
% 	Trained only on NLI, eval on STS 
	
% 	\ivan{Only show this, and rerun these experiments. Might just show RoBERTa results for simplicity} \nikos{fix acronyms here and in other places in the text. btw are these results up-to-date?}
	 % Evaluation on the STS benchmark test set. BERT systems were trained with 10 random seeds and 4 epochs. SBERT was fine-tuned on the STSb dataset, SBERT-NLI was pretrained on the NLI datasets, then fine-tuned on the STSb dataset.
	
\end{table}



% 	\begin{tabular}{l|c}
% 		\toprule
% 		\textbf{Model} & \textbf{Spearman} \\ \midrule
% 		\multicolumn{2}{l}{\textit{Trained on NLI (not STS Benchmark)}} \\ \hline
% 		Avg.\ GloVe embeddings & 58.02\\
% 		Avg.\ BERT embeddings &  46.35\\
% 		InferSent - GloVe &  68.03 \\
% 		Universal Sentence Encoder &  74.92\\
% 		SBERT-base  &  77.03\\
% 		SBERT-large & 79.23 \\
% 		BARNEY BERT-base & \\
% 		BARNEY BERT-large & \\ \midrule
% 		\multicolumn{2}{l}{\textit{Trained on STS Benchmark}} \\ \hline
% 		BERT-base & 84.30 $\pm$ 0.76  \\
% 		SBERT-base & 84.67 $\pm$ 0.19 \\ 
% 		SRoBERTa-base & \textbf{84.92} $\pm$ 0.34 \\
% 		BARNEY RoBERTa-base &  $\pm$  \\
% 		BARNEY BERT-base &  $\pm$  \\ \hline 
		
% 		BERT-large  & \textbf{85.64} $\pm$ 0.81 \\ 
% 		SBERT-large & 84.45 $\pm$ 0.43 \\ 
% 		SRoBERTa-large & 85.02 $\pm$ 0.76 \\ 
% 		BARNEY RoBERTa-base &  $\pm$  \\
% 		BARNEY BERT-base &  $\pm$  \\ \midrule
		
% 		\multicolumn{2}{l}{\textit{Trained on NLI + STS benchmark}} \\ \hline
		
% 		BERT-base & \textbf{88.33} $\pm$ 0.19 \\ 
% 		SBERT-base & 85.35 $\pm$ 0.17 \\ 
% 		SRoBERTa-base & 84.79 $\pm$ 0.38 \\ 
% 		BARNEY RoBERTa-base &  $\pm$  \\
% 		BARNEY BERT-base &  $\pm$  \\ \hline 
		
% 		BERT-large & \textbf{88.77} $\pm$ 0.46 \\ 
% 		BARNEY RoBERTa-base &  $\pm$  \\
% 		BARNEY BERT-base &  $\pm$  \\ \bottomrule
% 	\end{tabular}






% % 		\multicolumn{2}{l}{\textit{Trained on NLI (not STS Benchmark)}} \\ \hline
% 		Avg.\ GloVe embeddings & 58.02 & - \\
% 		Avg.\ BERT embeddings &  46.35 & - \\
% 		InferSent - GloVe &  68.03 & - \\
% 		Universal Sentence Encoder &  74.92 & - \\\hline
% % 		SBERT-base & 77.03 & \\
% % 		SBERT-large & 79.23 & \\\hline

%         BERT-base & 74.81 & 110M \\
%         RoBERTa-base & 75.37 & 125M\\
%         BERT-large & & 336M \\
%         RoBERTa-large & & 355M \\\hline
		
		
% 		SBERT-base & 76.81 & 110M \\
% 		SRoBERTa-base & 76.89 & 125M \\
% 		SBERT-large & 79.23 & 336M \\
% 		SRoBERTa-large &   & 355M \\\hline
		
% 		AUTOBOT BERT-base & 77.03 & \\
% 		AUTOBOT RoBERTa-base & 78.59 & \\
% % 		AUTOBOT RoBERTa-base ft1 & 77.24 & \\
% % 		ft 2 & 76.17 & \\
% % 		ft 3 & 76.20 & \\
% % 		ft 1 10k & 78.26 & \\
% % 		ft 2 10k & 77.03 & \\
% % 		ft 3 10k & 77.37 & \\
% 		AUTOBOT BERT-large & \\
% 		AUTOBOT RoBERTa-large & \\
% % 		SBERT-base  &  85.35 &  \\
% % 		SRoBERTa-base  & 84.79  & \\
% % 		SBERT-large & 86.10 &  \\
% % 		SRoBERTa-large & 86.15  &\\\hline 
% % 		BARNEY BERT-base &  84.25 &  \\  % 84.31
% % 		BARNEY RoBERTa-base &  & \\
% % 		BARNEY BERT-large &  &\\
% % 		BARNEY RoBERTa-large &  &\\
% % 		\multicolumn{2}{l}{\textit{Trained on STS Benchmark}} \\ \hline
% % 		BERT-base & 84.30 $\pm$ 0.76  \\
% % 		SBERT-base & 84.67 $\pm$ 0.19 \\ 
% % 		SRoBERTa-base & 84.92 $\pm$ 0.34 \\
% % 		BARNEY RoBERTa-base &  $\pm$  \\
% % 		BARNEY BERT-base &  $\pm$  \\ \hline 
		
% % 		BERT-large  & 85.64 $\pm$ 0.81 \\ 
% % 		SBERT-large & 84.45 $\pm$ 0.43 \\ 
% % 		SRoBERTa-large & 85.02 $\pm$ 0.76 \\ 
% % 		BARNEY RoBERTa-base &  $\pm$  \\
% % 		BARNEY BERT-base &  $\pm$  \\ \midrule
		
% % 		\multicolumn{2}{l}{\textit{Trained on NLI + STS benchmark}} \\ \hline
		
% % 		BERT-base & 88.33 $\pm$ 0.19 \\ 
% % 		SBERT-base & 85.35 $\pm$ 0.17 \\ 
% % 		SRoBERTa-base & 84.79 $\pm$ 0.38 \\ 
% % 		BARNEY RoBERTa-base &  $\pm$  \\
% % 		BARNEY BERT-base &  $\pm$  \\ \hline 
		
% % 		BERT-large & 88.77 $\pm$ 0.46 \\ 
% % 		BARNEY RoBERTa-base &  $\pm$  \\
% % 		BARNEY BERT-base &  $\pm$  \\
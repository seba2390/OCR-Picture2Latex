  We turn the space of configurations into a pseudo-metric space by
  introducing the intrinsic Kolmogorov-Sinai distance and asymptotic
  Kolmogorov-Sinai distance. For brevity, we will usually call it the
  Kolmogorov distance and asymptotic Kolmogorov distance.  The
  intrinsic Kolmogorov-Sinai distance is obtained by taking an infimum
  of the shared information distance over all possible joint
  distributions on two probability spaces. The name is justified by
  the fact that the shared information distance (not under this name)
  appears in the proof of the theorem about generating partitions for
  ergodic systems by Kolmogorov and Sinai, see for
  example \cite{Sinai-ergodic-1976}.  Note that the Kolmogorov
  distance in statistics refers to a different notion.

\subsection{Kolmogorov distance and asymptotic Kolmogorov distance}
\label{s:kolmogorov-ikd-aikd}
\subsubsection{Kolmogorov distance in the case of single probability spaces}
\label{s:kolmogorov-single}
  For a two-fan $\Fcal=(X\ot Z\to Y)$ define a ``distance'' $\kd(\Fcal
  )$ between probability spaces $X$ and $Y$ with respect to $\Fcal$ by
  \[
  \begin{split}
 \kd(\Fcal )&:=\ent(Z\rel Y)+\ent(Z\rel X) \\
 &= 2\ent(Z)-\ent(X)-\ent(Y)
 \end{split}
  \]

  Essentially $\kd(\Fcal )$ measures the deviation of the statistical map
  defined by $\Fcal$ from being a deterministic bijection between $X$ and
  $Y$.
  
  The minimal reduction $\Fcal '$ of $\Fcal$ satisfies
  \[\tageq{kd-min-reduction}
  \kd(\Fcal ') \leq \kd (\Fcal)
  \]
  
  
  If the two-fan $\Fcal$ is minimal the ``distance''
  $\kd( \Fcal )$ can also be calculated by 
  \[ 
  \kd(\Fcal) = h( p_X ) +
  h( p_Y ) - 2 D( p_Z \sep p_X \otimes p_Y ), 
  \] 
  where $h$ and $D$ are
  respectively the entropy and relative entropy functions defined in
  (\ref{eq:entropyformula}) and (\ref{eq:relativeentropy}).

  For a pair of probability spaces $X$, $Y$ define the
  \term[Kolmogorov-Sinai distance (spaces)]{intrinsic Kolmogorov-Sinai distance} as
  \[
  \ikd(X,Y)
  :=
  \inf\set{\kd(\Fcal)\st \Fcal=(X\ot Z \to Y) 
    \text{ is a two-fan} 
  }
  \]

  The optimization takes place over all two-fans with terminal spaces
  $X$ and $Y$. In view of inequality~(\ref{eq:kd-min-reduction}) one
  could as well optimize over the space of \emph{minimal} two-fans,
  which we will also refer to as \term[coupling between probability
    spaces]{couplings} between $X$ and $Y$. The tensor product of $X$
  and $Y$ trivially provides a coupling and the set of couplings is
  compact, therefore an optimum is always achieved and it is finite.

  The bivariate function $\ikd:\Prob\times\Prob\to\Rbb_{\geq0}$
  defines a notion of pseudo-distance and it vanishes exactly on
    pairs of isomorphic probability spaces. This follows directly
  from the Shannon inequality~(\ref{eq:shannonineq}), and a more
  general statement will be proven in Proposition
  \ref{p:kolmogorovisdistance} below.

\subsubsection{Kolmogorov distance for complete configurations}
\label{s:kolmogorov-config}
  The definition of Kolmogorov distance for complete configurations
  repeats almost literally the definition for single spaces. We fix a
  complete diagram category $\Gbf$ and will be considering configurations
  from $\prob\<\Gbf>$.
  
  Consider three configurations $\Xcal=\set{X_{i},f_{ij}}$,
  $\Ycal=\set{Y_{i},g_{ij}}$ and $\Zcal=\set{Z_{i},h_{ij}}$ from
  $\prob\<\Gbf>$. Recall that a two-fan $\Fcal=(\Xcal\ot\Zcal\to\Ycal)$ is
  a $\Gbf$-configuration of two-fans
  \[
  \Fcal_{i}=(X_{i}\ot Z_{i}\to Y_{i})
  \]
  
  Define
  \begin{align*}
    \kd(\Fcal)
    &:=
    \sum_{i} \kd(\Fcal_{i})\\
    &=
    \sum_{i}\big(2\ent(Z_{i})-\ent(X_{i})-\ent(Y_{i})\big)
  \end{align*}
  
  The quantity $\kd(\Fcal)$ vanishes if and only if the fan $\Fcal$
  provides isomorphisms between all individual spaces in $\Xcal$ and
  $\Ycal$ that commute with the inner structure of the configurations,
  that is, it provides an isomorphism between $\Xcal$ and $\Ycal$ in
  $\prob\<\Gbf>$.
  
  The \term[Kolmogorov-Sinai distance (configurations)]{intrinsic
    Kolmogorov-Sinai distance between configurations} is defined in analogy
  with the case of single probability spaces
  \[
  \ikd(\Xcal,\Ycal)
  :=
  \inf\set{\kd(\Fcal) \st \Fcal=(\Xcal\ot\Zcal\to\Ycal)}
  \]
  where the infimum is over all two-fans of $\Gbf$-configurations with
  terminal vertices $\Xcal$ and $\Ycal$.
  
  The following proposition records that the intrinsic
  Kolmogorov distance is in fact a pseudo-distance on $\prob\<\Gbf>$,
  provided $\Gbf$ is a complete diagram category (that is when $\Gbf$
  has a unique initial space).
  
  \begin{proposition}{p:kolmogorovisdistance}
    Let $\Gbf$ be a complete diagram category.
    Then the bivariate function 
    \[
    \ikd:\prob\<\Gbf> \times \prob\<\Gbf>\to\Rbb
    \]
    is a pseudo-distance on $\Prob\<\Gbf>$.  \\
    Moreover, two
    configurations $\Xcal, \Ycal \in \prob\<\Gbf>$ satisfy
    $\ikd(\Xcal,\Ycal)=0$ if and only if $\Xcal$ is isomorphic to
    $\Ycal$ in $\prob\<\Gbf>$.
  \end{proposition}

  The idea of the proof is very simple.  In the case of single
  probability spaces $X, Y, Z$ a coupling between $X$ and $Z$ can be
  constructed from a coupling between $X$ and $Y$ and a coupling
  between $Y$ and $Z$ by adhesion on $Y$, see Section \ref{s:config-adhesion}.  The triangle inequality
  then follows from a Shannon inequality.  However, since we are
  dealing with configurations the combinatorial structure requires
  careful treatment.  Therefore, we provide a detailed proof on
  page \pageref{p:kolmogorovisdistance.rep}.

  It is important to note, that the proof uses the fact that $\Gbf$ is
  complete. In fact, even though the definition of $\ikd$ could be
  easily extended to some bivariate function on the space of
  configurations of any fixed combinatorial type, it fails to satisfy
  the triangle inequality in general, because the composition of
  couplings requires completeness of $\Gbf$.

\subsubsection{The asymptotic Kolmogorov-Sinai distance}
\label{kolmogorov-aikd}
Let $\Gbf$ be a complete diagram category.  We define the
\term{asymptotic Kolmogorov-Sinai distance} between two
configurations $\Xcal, \Ycal \in \prob\< \Gbf>$ by
\[\tageq{definitionaikd}
  \aikd( \Xcal, \Ycal ) 
  = 
  \lim_{n \to \infty} \frac{1}{n}
  \ikd(\Xcal^{\otimes n}, \Ycal^{\otimes n}).
\]
We will show in Corollary \ref{p:subadditivity}, that the sequence 
\[
  n \mapsto \ikd(\Xcal^{\otimes n}, \Ycal^{\otimes n})
\]
is subadditive, and therefore the limit in the definition
(\ref{eq:definitionaikd}) of $\aikd(\Xcal, \Ycal)$ always exists
and for all $n\in\Nbb$ holds
\[\tageq{aikd-ikd-bound}
  \aikd(\Xcal, \Ycal ) 
  \leq 
  \frac1n\cdot
  \ikd(\Xcal^{\otimes n}, \Ycal^{\otimes n}).
\]

As a corollary of Proposition~\ref{p:kolmogorovisdistance} and 
definition~(\ref{eq:definitionaikd}) we immediately obtain 
that also the asymptotic Kolmogorov-Sinai distance is a pseudo-distance on $\prob\<\Gbf>$.
\begin{corollary}{p:aikdisdistance}
  Let $\Gbf$ be a complete diagram category.
  Then the bivariate function 
  \[
    \aikd:\prob\<\Gbf> \times \prob\<\Gbf>\to\Rbb
  \]
  is a pseudo-distance on $\Prob\<\Gbf>$ satisfying the following
  homogeneity property.
  For any pair of configurations $\Xcal,\Ycal\in\Prob\<\Gbf>$ and any
  $n\in\Nbb_{0}$ holds
  \[
  \aikd(\Xcal^{\otimes n},\Ycal^{\otimes n})=n\cdot\aikd(\Xcal,\Ycal)
  \]
\end{corollary}

We will show in a later section, however, that there
are probability spaces $X$ and $Y$ for which $\aikd(X, Y) = 0$ that
are not isomorphic.


\bigskip 

In the rest of this section we derive some elementary properties of the intrinsic 
Kolmogorov distance and the asymptotic Kolmogorov distance.

\subsection[Lipschitz property]
{Lipschitz property for operations}
\label{s:kolmogorov-lipschitz}
  In this section we show that certain natural operations on
  configurations, namely the tensor product, entropy function and
  restriction operator, are Lipschitz continuous.  In Section
  \ref{s:extensions} we will show Lipschitz continuity of certain
  extension operations.

\subsubsection{Tensor product}\label{s:kolmogorov-lipschitz-tensor}
  We show that the tensor product on the space of configurations is
  1-Lipschitz. Later this will allow us to give a simple description
  of tropical configurations, that is of points in the asymptotic cone of
  $\prob\<\Gbf>$, as limits of certain sequences of ``classical''
  configurations.

\begin{proposition}{p:tensor1lip}
  Let $\Gbf$ be a complete diagram category.
  Then with respect to the Kolmogorov distance on $\prob\<\Gbf>$
  the tensor product
  \[
  \otimes:(\Prob\<\Gbf>,\ikd)^2\to(\Prob\<\Gbf>,\ikd)
  \]
  is 1-Lipschitz in each variable, that is, for every triple $\Xcal,
  \Ycal, \Ycal' \in \Prob\<\Gbf>$ the following
    bound holds
  \[
  \ikd(\Xcal \otimes \Ycal, \Xcal \otimes \Ycal') 
  \leq 
  \ikd(\Ycal,\Ycal')
  \]
\end{proposition}

This statement is a direct consequence of additivity of entropy with
respect to the tensor product. Details can be found on
page~\pageref{p:tensor1lip.rep}.

It follows directly from definition~(\ref{eq:definitionaikd}) and
Proposition~\ref{p:tensor1lip}, that the asymptotic Kolmogorov distance
enjoys a similar property.
\begin{corollary}{p:aikdtensor1lip}
  Let $\Gbf$ be a complete diagram category.
  Then with respect to the Kolmogorov distance on $\prob\<\Gbf>$
  the tensor product
  \[
  \otimes:(\Prob\<\Gbf>,\aikd)^2\to(\Prob\<\Gbf>,\aikd)
  \]
  is 1-Lipschitz in each variable.
\end{corollary}

As another corollary we obtain the subadditivity properties of the intrinsic
Kolmogorov distance and asymptotic Kolmogorov distance.

\begin{corollary}{p:subadditivity}
  Let $\Gbf$ be a complete diagram category and let $\Xcal, \Ycal,
  \Ucal, \Vcal \in \prob\<\Gbf>$, then
  \[
  \ikd(\Xcal \otimes \Ucal, \Ycal \otimes \Vcal)
  \leq \ikd(\Xcal, \Ycal) + \ikd( \Ucal, \Vcal ).
  \]	
  and 
  \[
  \aikd(\Xcal \otimes \Ucal, \Ycal \otimes \Vcal)
  \leq 
  \aikd(\Xcal, \Ycal) + \aikd( \Ucal, \Vcal ).
  \]	
\end{corollary}

It implies in particular that shifts are non-expanding maps in
$(\prob\<\Gbf>,\ikd)$ or $(\prob\<\Gbf>,\aikd)$. 
\begin{corollary}{p:shiftcontracting}
  Let $\Gbf$ be a complete diagram category and $\dist=\ikd,\aikd$ be
  either Kolmogorov distance or asymptotic Kolmogorov distance on
  $\prob\<\Gbf>$. Let
  $\Ucal\in\prob\<\Gbf>$. Then the shift map
  \[
  \Ucal\otimes\cdot:(\prob\<\Gbf>,\dist)\to(\prob\<\Gbf>,\dist),
  \quad
  \Xcal\mapsto \Ucal\otimes\Xcal
  \]
  is a non-expanding map with respect to either Kolmogorov distance or
  asymptotic Kolmogorov distance.
\end{corollary}

\subsubsection{Entropy}\label{s:kolmogorov-lipschitz-entropy}
Recall that we defined the entropy function 
\[
\ent_{*}:\prob\<\Gbf>\to\Rbb^{\size{\Gbf}}
\]
by evaluating the entropy of all individual spaces in a
$\Gbf$-configuration. The target space $\Rbb^{\size{\Gbf}}$ will be
endowed with the $\ell^{1}$-norm with respect to the natural coordinate
system. With such a choice, the entropy function is 1-Lipschitz with
respect to the Kolmogorov distance on $\prob\<\Gbf>$.

\begin{proposition}{p:entropy1lip}
  Suppose $\Gbf$ is a complete diagram category and $\dist=\ikd,\aikd$
  is either Kolmogorov distance or asymptotic Kolmogorov distance on
  $\prob\<\Gbf>$.  Then the entropy
  function
  \[
  \ent_{*}:(\prob\<\Gbf>,\dist)\to(\Rbb^{\size{\Gbf}},\;|\cdot|_{1}),
  \quad
  \Xcal=\set{X_{i},f_{ij}}\mapsto (\ent X_{i})_{i}\in\Rbb^{\size{\Gbf}}
  \]
  is 1-Lipschitz.
\end{proposition}
  Again, the proof of the proposition above is an application of Shannon's
  inequality, see page~\pageref{p:entropy1lip.rep} for details.

\subsubsection{Restrictions}\label{s:kolmogorov-lipschitz-restrictions}
 The restriction operators are also Lipschitz, as shown in the next
 proposition.
  \begin{proposition}{p:restriction1lip}
    Suppose $R:\Gbf'\to\Gbf$ is a functor between two complete diagram
    categories and $\dist$ stands for either Kolmogorov or asymptotic
    Kolmogorov distance. Then the restriction operator
    \[
    R^{*}:(\Prob\<\Gbf>,\dist)\to(\Prob\<\Gbf'>,\dist),
    \quad 
    \Xcal\mapsto \Xcal\circ R
    \]
    is Lipschitz.
  \end{proposition}

  As can be seen from the proof on
  page~\pageref{p:restriction1lip.rep}, the Lipschitz constant in the
  proposition above can be bounded by $\size{\Gbf'}$. In fact, a more
  careful analysis provides a better bound by the maximal number of
  objects in $\Gbf'$ that are mapped by $R$ to a single object in $\Gbf$.


\subsection{The Slicing Lemma}\label{s:kolmogorov-slicing}
  The Slicing Lemma, Proposition \ref{p:slicing} below, allows to estimate the
  Kolmogorov distance between two configurations with the integrated
  Kolmogorov distance between ``slices'', which are configurations obtained by
  conditioning on another probability space.

  The Slicing Lemma, along with the local estimate in Section~\ref{s:kolmogorov-local}, turned out to be a
  very powerful tool for estimation of the Kolmogorov distance and will be
  used below on many occasions.

  As described in Section \ref{s:config-constantconfig}, by a reduction
  of a configuration $\Xcal=\set{X_{i},f_{ij}}$ to a single space $U$ we
  mean a collection of reductions $\set{\rho_{i}:X_{i}\to U}$ from the
  individual spaces in $\Xcal$ to $U$, that commute with the reductions
  within $\Xcal$
  \[
  \rho_{j}\circ f_{ij}=\rho_{i}
  \]
  Alternatively, whenever a single probability space appears together
  with a $\Gbf$-configuration in a commutative diagram, it should be
  replaced by a constant $\Gbf$-configuration.
  \begin{proposition}{p:slicing}
    {\rm (Slicing Lemma)} Suppose $\Gbf$ is a complete diagram
    category and we are given
    $\Xcal,\hat\Xcal,\Ycal,\hat\Ycal\in\prob\<\Gbf>$ -- four
    $\Gbf$-configurations and $U,V,W\in\prob$ -- probability spaces,
    that are included into the following three-tents configuration
    \[
    \begin{tikzcd}[column sep=small,row sep=tiny,ampersand replacement=\&]
      \mbox{}
      \&
      \hat\Xcal
      \arrow{dl}{}
      \arrow{dr}{}
      \&
      \&
      W
      \arrow{dl}{}
      \arrow{dr}{}
      \&
      \&
      \hat\Ycal
      \arrow{dl}{}
      \arrow{dr}{}
      \&
      \mbox{}
      \\
      \Xcal
      \&
      \&
      U
      \&
      \&
      V
      \&
      \&
      \Ycal
    \end{tikzcd}
    \]
    such that the two-fan $(U\ot W\to V)$ is minimal.
    Then the following estimate holds
    \begin{align*}
      \ikd(\Xcal,\Ycal) 
      &\leq 
      \int_{W}\ikd(\Xcal\rel u,\Ycal\rel v)\d p_{W}(u,v)\\
      &\quad+
      \size{\Gbf}\cdot\kd(U\ot W\to V)\\
      &\quad+
      \sum_{i}\big[\ent(U\rel X_{i})+\ent(V\rel Y_{i})\big]
    \end{align*}
  \end{proposition}
  The idea of the proof of the Slicing Lemma (page~\pageref{p:slicing.rep})
  is as follows. For every pair $(u,v)\in\un W$ we consider an optimal
  two-fan $\Gcal_{uv}$ coupling $\Xcal\rel u$ and $\Ycal\rel v$.
  These fans have the same underlying configuration of sets.
  Then we construct a coupling between $\Xcal$ and $\Ycal$ as a convex combination of distributions of
  $\Gcal_{uv}$'s weighted by $p_{W}(u,v)$. The estimates on the
  resulting two-fan then imply the proposition.

  Various implications of the Slicing Lemma are summarized in the next
  corollary.
  
  \begin{corollary}{p:slicingcorollary}
    Let $\Gbf$ be a complete diagram category, $\Xcal,\Ycal\in\prob\<\Gbf>$ and
    $U\in\prob$.
    \begin{enumerate}
    \item
      \label{i:slicing2tents}
      Given a ``two-tents'' configuration
      \[
      \Xcal\ot\hat\Xcal\to U\ot\hat\Ycal\to\Ycal
      \]
      the following inequality holds
      \begin{align*}
      \ikd(\Xcal,\Ycal) 
      &\leq 
      \int_{U}\ikd(\Xcal\rel u,\Ycal\rel u)\d p_{U}(u)
      +2\cdot\size{\Gbf}\cdot\ent(U)
      \end{align*}
    \item 
    \label{p:slicingtwofan}
      Given a fan
      \[
      \Xcal\ot\hat\Xcal\to U
      \]
      the following inequality holds
      \begin{align*}
        \ikd(\Xcal,\Ycal)
        &\leq 
        \int_{UV}\ikd(\Xcal\rel u,\Ycal)\d p_{U}(u)
        + 
        2\cdot\size{\Gbf}\cdot\ent(U)
      \end{align*}
    \item
      \label{p:slicingreduction}      
      Let $\Xcal\to U$ be a reduction, then
      \begin{align*}
      \ikd(\Xcal,\Ycal) 
      &\leq 
      \int_{U}\ikd(\Xcal\rel u,\Ycal)\d p_{U}(u)+
      \size{\Gbf}\cdot\ent(U)
      \end{align*}
    \item
      \label{p:slicingcofan}
      For a co-fan $\Xcal\to U\ot\Ycal$ holds
      \[
      \ikd(\Xcal,\Ycal)
      \leq
      \int_{U}\ikd(\Xcal\rel u,\Ycal\rel u)\d p_{U}(u)
      \]
    \end{enumerate}
  \end{corollary}
  
\subsection{Local estimate}\label{s:kolmogorov-local}
  Fix a complete diagram category $\Gbf$ and consider a
  $\Gbf$-configuration of sets $\Scal\in\Set\<\Gbf>$ with $S_{0}$
  being an initial set in $\Scal$. As discussed in Section
  \ref{s:disttypes-distributions-config}, the space of distributions
  on $\Scal$ could be identified with the space of distributions on the
  initial set
  \[
  \Delta\Scal\cong\Delta S_{0}
  \]
  Therefore, all $\Gbf$-configurations of probability spaces with the
  underlying configuration of sets equal to $\Scal$ are in one-to-one
  correspondence with the interior points of $\Delta S_{0}$.  The set
  $\Interior\Delta S_{0}$ consists of fully supported measures on the
  set $S_{0}$ and carries a total variation distance, which is just an
  $\ell^{1}$-distance with respect to the convex coordinates on the
  simplex $\Delta S_{0}$.  Our task presently is to compare the total
  variation distance with the Kolmogorov distance on the space of
  configurations with the fixed underlying configuration of sets.

  The upper bound on Kolmogorov distance, that we derive below, has two
  summands. One is linear in the total variation distance with the
  slope proportional to the $\log$-cardinality of $S_{0}$. The second one is
  super-linear in the total variation distance, but it does not depend
  on $\Scal$. So we have the following interesting observation: of
  course, the super-linear summand always dominates the linear one
  locally. However as the cardinality of $\Scal$ becomes large it is
  the linear summand that starts playing the main role.

\subsubsection{The estimate}
\label{p:kolmogorov-local-estimate}
  Suppose we are given a configuration of sets
  $\Scal=\set{S_{i},f_{ij}}\in\Set\<\Gbf>$ modeled on a complete diagram
  category $\Gbf$ with the initial set $S_{0}$.  
  We use once again the isomorphism
  \[ 
  \Delta\Scal\stackrel{\cong}{\to}\Delta S_{0}
  \]      
  that sends $p\in\Delta\Scal$ to its component in the initial space
  $p_{0}\in\Delta S_{0}$, while its inverse is given by
  $p=\set{(f_{0i})_{*}p_{0}}$.  For a pair of distributions
  $p_{0},q_{0}\in\Delta S_{0}$ denote by $|p_{0}-q_{0}|$ the
  total variation of the difference.

  For $\alpha\in[0,1]$ consider a binary probability space with the
  weight of one of the atoms equal to $\alpha$
  \[
  \Lambda_{\alpha}
  :=
  \big(
    \set{\square,\blacksquare};\,
    p_{\Lambda_{\alpha}}(\square)=1-\alpha,\,
    p_{\Lambda_{\alpha}}(\blacksquare)=\alpha
  \big)
  \]

  \newpage        
  \begin{proposition}{p:kolmogorovlocal}
    Let $\Scal=\set{S_{i},f_{ij}}\in\Set\<\Gbf>$ be a configuration of
    sets modeled on a complete diagram category $\Gbf$ with the
    initial set $S_{0}$. Let $p,q\in\Delta \Scal$ be two probability
    distributions.
    Denote $\Xcal:=(\Scal,p)$, $\Ycal:=(\Scal,q)$ and
    $\alpha=\frac12|p_{0}-q_{0}|_1$. Then
    \[
    \ikd(\Xcal,\Ycal)
    \leq
    2\cdot\size{\Gbf}\cdot\big(\alpha\cdot\ln|S_{0}|+\ent(\Lambda_{\alpha})\big)
    \]
  \end{proposition}
  To prove the local estimate we decompose both $p$ and $q$ into
  a convex combination of a common part $\hat p$ and rests $p^{+}$ and $q^+$. 
  The coupling between the common parts gives no contribution to the distance, and the worst possible estimate on the other parts is still enough to get the bound in the lemma, by using Corollary \ref{p:slicingcorollary} part (\ref{i:slicing2tents}). 
  Details of the proof can be found on page \pageref{p:kolmogorovlocal.rep}.
  
  In fact, the lower bound also holds, more specifically given a
  complete $\Gbf$-configuration of sets $\Scal$ and $p\in\Delta\Scal$
  there is a constant $C>0$ such that for any $q\in\Delta\Scal$ with
  $|p-q|_1<\!<1$ holds
  \[
  C\cdot\ent(\Lambda_{\alpha})\leq\ikd(\Xcal,\Ycal)
  \]      
  where $\Xcal=(\Scal,p)$, $\Ycal=(\Scal,q)$ and
  $\alpha=\frac12|p-q|_1$.
  We will not use this fact and therefore do not include a proof.

  Once the $\Gbf$-configuration of sets $\Scal$ is fixed, there is a map from $\Delta \Scal$ to $\Prob\<\Gbf>$.
  As can be seen from the discussion above, even though the map is continuous it is not Lipschitz.


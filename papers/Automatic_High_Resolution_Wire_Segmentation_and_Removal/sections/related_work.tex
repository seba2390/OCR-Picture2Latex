%auto-ignore
\section{Related Work} \label{sec:related}

\input{figure_tex/motivation}

% \textcolor{blue}{1. semantic segemtnation,however, as we will discuss, directly using these methods will nto help.  , 3. high resolution: xxx, - directly using them is not working 3. wire segmentnion.}

%We introduce related works in the following way. We first describe several widely-used semantic segmentation methods, followed by methods that tackle more specific challenges such as high-resolution segmentation and wire segmentation. We describe key principles of these works, where we can draw inspirations and improve upon.

\paragraph{Semantic segmentation}
Semantic segmentation has been actively researched over the past decade. For example, the DeepLab series~\cite{deeplab, deeplabv3, deeplabv3p} has been one of the most widely used set of semantic segmentation methods. They leverage dilated convolutions to capture long-range pixel correlations. Similarly, CCNet~\cite{ccnet} attend to non-local regions via a two-step axial attention mechanism. PSPNet~\cite{pspnet} use multi-scale pooling to extract high-resolution features.

Recently, the self-attention mechanism~\cite{attention} has gained increasing popularity. 
% Originally applied in Natural Language Processing tasks, its vision-based variants~\cite{vit, swin} have shown to be superior to traditional convolution-based methods. 
Transformer-based models for semantic segmentation~\cite{dpt, setr, swin, segformer, hassani2022neighborhood, hassani2022dilated, jain2021semask, jain2022oneformer} significantly outperform convolution-based networks since the attention modules benefit from their global receptive fields~\cite{segformer}, which let the models attend to objects that span across larger portions of the feature map.

While these above methods work well in common object semantic segmentation, when applied to our task of wire segmentation in high-resolution images, they either drop significantly in segmentation quality or require long inference times. We show in Section~\ref{sec:results} that directly applying these methods to our task yields undesirable results.

\vspace{-5mm}
\paragraph{High-resolution image segmentation}
Segmentation in high-resolution images involves additional design considerations. It is computationally infeasible to perform inference on the full-resolution image with a deep network. As a result, to maximally preserve image details within the available computation resources, many methods employ a global-local inference pipeline. For instance, GLNet~\cite{glnet} simultaneously predict a coarse segmentation map on the downsampled image and a fine segmentation map on local patches at the original resolution, then fuse them to produce the final prediction. 
%Their model shares features produced by both the global and local branch, thus achieving feature fusion.
MagNet~\cite{magnet} is a recent method that proposes to iteratively predict and refine coarse segmentation maps at multiple scales using a single feature extractor and multiple lightweight refinement modules. CascadePSP~\cite{cascadepsp} train a standalone class-agnostic model to refine predictions at a higher resolution from a pretrained segmentation model. ISDNet~\cite{isdnet} propose to use an extremely lightweight subnetwork to take in the entire full-resolution image. However, the subnetwork is limited in capacity and thus segmentation quality. We share the same idea with these past works on using a coarse-to-fine approach for wire segmentation, but modify the architecture and data processing to tailor to wires.

% Most of these methods share a similar coarse-to-fine approach, where instead of performing a single inference on high-resolution images, they divide them into a coarse-to-fine approach. We repurpose important components of these methods into a two-stage model design optimized for wire segmentation in high-resolution images.
%While our model pipeline is similar to the above methods, there are a few fundamental differences that makes our pipeline more effective and efficient in our task. First, GLNet essentially uses two separate networks for their global and local branches. The combined network does not share weights, and requires a three-stage training scheme. Meanwhile, CascadePSP only does segmentation refinement, which means they require an entire separate network to produce the initial prediction. MagNet uses an iterative refinement method at multiple scales, where the inference time scales quadratically with number of refinement scales. They also use a much smaller module for refinement, which limits quality of refinement. In contrast, our proposed network shares the feature extractor and can be trained end-to-end. Our model is also capable of predicting accurate wire masks on very high-resolution images with only two stages and without requiring any separately trained model for initial prediction.
\vspace{-5mm}
\paragraph{Wire/Curve segmentation}
While few works tackle wire segmentation in high-resolution images, there are prior works that handle similar objects. For example, Transmission Line Detection (TLD) is an actively researched area in aerial imagery for drone applications. Convolutional neural networks are used~\cite{ttpla, pldu, cable_inst, lsnet} to segment overhanging power cables in outdoor scenes. However, wire patterns in TLD datasets are relatively consistent in appearance and shape -- evenly spaced and only spanning locally. In contrast, we handle more generic wires seen in regular photographic contents, where the wire appearance has much higher variety. 
%We will discuss in Section~\ref{sec:results} that the models from these works do not generalize to wires in our task.

Some other topics are loosely related to our task. Lane detection~\cite{lanedet,swiftlane,structurelane} aims to segment lanes for autonomous driving applications. These methods benefit from simple line parameterization (e.g., as two end-points), and strong positional priors. In contrast, as shown in Figure~\ref{fig:motivation}, wires vary drastically in shapes and sizes in our task, thus making them difficult to parameterize.

\vspace{-5mm}
\paragraph{High-Resolution Image Inpainting}
Image inpainting has been well-explored using patch synthesis-based methods \cite{barnes2009patchmatch, wexler2007space, darabi2012image, kaspar2015self} or deep neural networks \cite{contextencoder, globallocal, partialconv, contextual, yu2019free, xu2022image}. Zhao \textit{et al.} leveraged the powerful image sysnthesis ability of StyleGAN2 \cite{karras2020analyzing} and proposed CoModGAN \cite{comodgan} to push the image generation quality to a newer level, and was followed by \cite{zheng2022cm, jain2022keys}. Most of these deep models cannot be applied to inpainting tasks at high-resolution images. The latest diffusion-based inpainting model like DALLE-2 \cite{dalle}, LDM \cite{rombach2022high}, and StableDiffusion etc. also suffer from long inference time and low output resolution. ProFill \cite{zeng2020high} was first proposed to address high resolution inpainting via a guided super resolution module. HiFill \cite{hifill} utilized a contextual residual aggregation module and the resolution can be up to 8K. LaMa \cite{suvorov2022resolution} applied the fourier convoluational residual blocks to make the propagation of image structures well. LaMa was trained on only $256 \times 256$ images, but can be used for images up to 2K with high quality. Recently, Zhang \textit{et al.} \cite{supercaf} proposed to use guided PatchMatch for any-resolution inpainting and extended the deep inpainting results from LaMa to modern camera resolution. The textures are better reused, while the structure and line completion at high-resolution can still be challenging. In this paper, we aim at removing wires from high resolution photos. The problem can become easier if we run inpainting in a local manner since wires are usually thin and long. Therefore, we propose to revisit LaMa for wire removal, and run the inference in a tile-based fashion. 
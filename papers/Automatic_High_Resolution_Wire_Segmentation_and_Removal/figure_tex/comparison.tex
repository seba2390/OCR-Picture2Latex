%auto-ignore
\begin{figure*}[t!]
\centering
% \vspace{1mm}
\includegraphics[width=1.0\linewidth]{figures/wire-qualitative.pdf}
\vspace{-8mm}
\caption{
% Qualitative comparison between our method and baseline networks on a 32 Megapixel image. (a), (b): Whole image inference. (c), (d): Sliding window inference. (e), (f): Our two-stage model. Our model predicts much tighter segmentation masks without artifacts such as aliasing, while avoiding false positives caused by only seeing local regions. Each R/G/B bounding box in (c),(d),(e) represents a 1024$\times$1024 sliding-window used by the fine module for refinement.
\textbf{Qualitative comparison of several semantic segmentation models.} %Our model predicts much tighter and consistent segmentation masks, while avoiding false positives caused by only seeing local regions. Note that in the third row, our two-stage model successfully suppresses false positives that would otherwise be misclassified without global context.
A common object semantic segmentation model (DeepLabv3+) either fails to find thin wires or overpredicts due to lack of global context. On the other hand, CascadePSP and MagNet, being refinement-based models, cannot work well on wires when the predictions are inaccurate or missing. While ISDNet can capture many thin wires regions, it cannot produce a high-quality prediction. In contrast, our model is able to both capture accurate wire regions and produce fine wire masks, and maintain low inference time.
\vspace{-5mm}
}
\label{fig:visual}
\end{figure*}


\begin{figure*}[t!]
\centering
\vspace{1mm}
\includegraphics[width=1.0\linewidth]{figures/wire-ablation.pdf}
\vspace{-7mm}
\caption{
\textbf{Qualitative comparison of our model components.} MinMax enhances wire image features when they are too subtle to see in RGB, while MaxPool encourages aggressive predictions in the coarse branch. Both components enable the model to pick up more regions for the final wire mask prediction.
}
% \vspace{-2mm}
\label{fig:visual}
\end{figure*}
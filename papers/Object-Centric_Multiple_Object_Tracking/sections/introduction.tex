\section{Introduction}

%Object-level scene representations are at the basis of our ability to perceive the world.
%Thanks to object-level abstraction, we can learn about object relations and the causal structures that govern their behaviour making the vision system more robust and benefiting in various applications.
%Since we live in a world where causal relations unfold in time, learning relations and interactions requires temporal dynamic modeling where consistent object representations are necessary.
%This is particularly in line visual indexing theory~\cite{pylyshyn1989role} developed in the cognitive sciences.
%Visual indexing theory proposes a psychological mechanism that includes a set of indexes that can be associated with a visible object in the environment where each index retains its association with an object even when that object moves or changes appearance.

%Suggested version (comments above are original version)
Visual indexing theory~\cite{pylyshyn1989role} proposes a psychological mechanism that includes a set of indexes that can be associated with an object in the environment. 
Each index retains its association with an object, even when that object moves, interacts with other objects, or becomes partially occluded. 
This theory was originally developed in the cognitive sciences, however, a very similar principle lies at the heart of object-centric representation learning.
By learning object-level representations, we can develop models inferring object relations~\cite{mambelli2022compositional,wu2022slotformer,yoon2023investigation} and even their causal structure~\cite{liu2023causal,mansouri2022object}. 
Additionally, object-centric representations have shown to be more robust \cite{dittadi2022generalization}, allow for combinatorial generalization \cite{liu2023causal}, and are beneficial for various downstream applications \cite{wu2022slotformer}.
Since causal relations often unfold in time, it is only logical to combine object-centric learning (OCL) with temporal dynamics modeling, where consistent object representations are necessary.

\begin{figure}[!t]
	\centering
	\includegraphics[width=82mm]{imgs/teaser.pdf}
 \vspace{+0.3cm}
\caption{\textbf{Temporal inconsistency and part-whole split of object-centric representations. } We visualize a video object-centric model SAVi~\cite{kipf2022conditional} that groups objects into a set of slots without labels. Common issues include that there exist many duplicate slots that capture the same object or its parts (dashed arrows),  and the slots fail to track objects consistently over time (red boxes). 
 }
\label{fig:teaser}
\end{figure}
%In computer vision, multiple object tracking (MOT) is such a pipeline inspired by visual indexing theory.
%MOT aims at localizing a set of objects, while following their trajectories over time so that the same object keeps the same identities in the entire input video stream.
%The dominant MOT methods follow the tracking-by-detection paradigm: first employ an object detector to localize objects in each frame, then perform association on detected objects between adjacent frames to get tracklets.
%To develop such a state-of-the-art MOT pipeline, one usually needs to collect large amount of detection labels for the objects we are interested in, and collect a video dataset with object ID labels to train the association module.
%Nevertheless, this approach faces challenges in labeling costs and generalization issue in open-world scenarios.

%Suggested version (comments above are original version)
Multiple object tracking (MOT) is a computer-vision problem that resembles visual indexing theory.
MOT aims at localizing a set of objects while following their trajectories over time so that the same object keeps the same identity in the entire video stream.
The dominant MOT methods follow the detect-to-track paradigm: First, employ an object detector to localize objects in each frame, then perform association on detected objects between adjacent frames to get tracklets.
The development of state-of-the-art MOT pipelines usually requires large amounts of detection labels for the objects we are interested in, as well as video datasets with object ID labels to train the association module.
Consequently, such approaches are label intense and do not generalize well in open-world scenarios.



%Unsupervised object-centric learning describes approaches which aim at tackling the object discovery and binding problem of visual input signals to objects without additional supervision.
%Recent work such as SAVi~\cite{kipf2022conditional} and STEVE~\cite{singh2022simple} have made progress in providing object representations across the temporal dimension.
%However, there still remains a significant gap in terms of multiple object tracking metrics between these approaches and state-of-the-art fully-supervised MOT methods and few comparisons have been made across both communities.
%This gap hinders downstream utility of object-centric methods for more complicated reasoning tasks, as without consistent tracking of objects understand their dynamics and interactions is almost impossible.

%Suggested version (comments above are original version)
Unsupervised object-centric representation learning tackles the object discovery and binding problem in visual data without additional supervision \cite{seitzer2022bridging}. %cite a lot here
Recent work, such as SAVi~\cite{kipf2022conditional} and STEVE~\cite{singh2022simple}, extended such models to the video domain, which hints at possible applications to MOT. %have made progress in providing object representations across the temporal dimension.
However, existing approaches are primarily evaluated without heavy punishment if slots exchange ``ownerships'' of pixels and rather rely on clustering similarity metrics such as FG-ARI~\cite{kipf2022conditional}. An object may appear in different slots across time (a.k.a ID switch issue),  which hinders downstream applications of OCL models, especially when \emph{directional relationship} among objects and their dynamics must be reasoned upon (e.g., who acts upon whom). Additionally, the part-whole issues are not fully explored, allowing slots to only track parts of an object. Figure~\ref{fig:teaser} visualizes the two problems of OCL models that are developed orthogonally with respect to MOT downstream tasks, leading to a significant gap with the state-of-the-art fully supervised MOT methods.
%Additionally, these metrics do not fully capture part-whole issues as strongly as MOT metrics like mAP or MOTA, allowing slots to only track parts of an object.
%As a consequence, OCL approaches developed orthogonally with respect to MOT downstream tasks, leading to a significant gap with the state-of-the-art fully supervised MOT methods. 
Scalability challenges of unsupervised OCL methods only accentuate this gap.



%\looseness=-1Our framework starts at object-centric grouping. The grouping stage of our model uses Slot Attention\cite{locatello2020object} to turn the set of encoder features from video frames  into a set of slot vectors $\{\mathcal{S}_t\}_{t=1}^{T}$. The model is trained with a self-supervised reconstruction loss $L_{oc\_rec}=||y - \text{Dec}(\mathcal{S})||^2$, where $y$ can be the raw frame pixels, or feature representations extracted from the frames. The decoder $Dec$ has a compete-to-explain inductive bias to encourage binding the objects in the slots. 
%However, two kinds of error will not be punished strongly from this reconstruction loss: 1) Splitting a whole object into parts (a.k.a part-whole issue), as long as the combined reconstruction keeps all the information of the whole object. 2) The same object appears in different slots in different frames (a.k.a ID switch issue), as long as no object will be dropped when switching happens. Fig \ref{fig:teaser} shows these two errors from a video object-centric model SAVi\cite{kipf2022conditional}, even when the slots in the previous frame are used to initialize the slot queries for the next frame to encourage temporal consistency.

%This is where our own design chimes in.
% This gap is partly due to challenges in the temporal consistency within those object-centric representation learning models, which diminishes their applicability to computer vision downstream tasks.
% % value for downstream tasks. 
% In addition to the difficulties in scaling these methods to real world data, temporal consistency between object representations is clearly important to accurately model object dynamics and interactions.

In this work, we take steps to bridge the gap between object-centric learning and fully-supervised multiple object tracking pipelines. Our design focuses on improving OCL framework on two key issues: 1) track objects as a whole, and 2) track objects consistently over time. For these, we insert a memory model to consolidate slots into memory buffers (to solve the part-whole problem) and roll past representations of the memory forward (to improve temporal consistency). 
%We use standard multi-head attention (MHA) models as the components, which scale well to real-world data in a semi-supervised setting. 
%This effort aims at enhancing the existing object-centric methods by improving the temporal consistency on the object representation, which can be measured by MOT metrics, meanwhile, also providing a object-centric-based label-efficient alternative to the costly MOT pipeline that relies on detection and ID labels.
% We enhance existing object-centric methods with memory modules that improve their temporal consistency, which is reflected in the MOT metrics. At the same time, we can rely on additional self-supervised objectives to reduce the labelling needs of MOT.
Overall, our model provides a label-efficient alternative to the otherwise costly MOT pipelines that rely on detection and ID labels.
Our contributions can be summarized as follows:
\begin{enumerate}[label=(\arabic*)]
    \item We develop a video object-centric model that can be applied to MOT task with very few detection labels ($0\,\%$-$6.25\,\%$) and no ID labels.
    %which achieves $15\,\%$-$40\,\%$ higher performance in terms of MOT metrics compared to existing video object-centric models.
    \item OC-MOT leverages an unsupervised memory to predict completed future object states even if occlusion happens. Besides, the index-merge module can tackle the part-whole and duplication issues specific to OC models. The two cross-attention design is simple but nontrivial, serving as the “index” and “merge” functions with their key and query being bi-directional.
    %Our OC-MOT achieves MOT performance improvements by leveraging a self-supervised memory. We utilize the object-centric representations to guide the self-supervised learning of the association using memory. OC-MOT greatly improves the temporal consistency and handles part-whole issues. 
    %\item Our pipeline has the potential to augment the existing MOT pipeline that requires costly detection and ID labels with a more label-efficient object-centric pipeline. With only $0\,\%$-$6.25\,\%$ detection label and $0\,\%$ ID label, our method achieves competitive MOT metrics compared to the fully-supervised  MOTR~\cite{zeng2022motr}.
    \item We are the first to introduce the object-centric representations to MOT that are versatile enough in a way of supporting all the association, rolling-out, and merging functions, and can be trained with low labeling cost.

\end{enumerate}

% \paragraph{A discussion of metrics} Existing models of OCL on video data is primarily measured by consistency of grouping of pixies across adjacent frames, e.g. FG-ARI (or Rand Index). One problem is that metrics give no punishment if slots exchange ``ownerships'' of pixies. This is problematic in future downstream tasks of OCL, especially when \emph{directional relationship} among objects must to be reasoned (e.g. who acts upon whom). A further problem is that such metrics do not reflect the challenge of part-whole, where slots can track parts of an object and do so without being detected.

% The root of these problems is that for OCL to make progress we must evaluate models with object-level metrics. In this work, we straightforwardly repurpose MOT metrics to evaluate model performance. 


% Our design focuses on improving OCL framework on two key issues: 1) track an objects as a whole, and 2) do so consistently over time. We do so by inserting a layer of memory where we consolidate slots into memory buffers (to solve part-whole problem) and roll past representations of the memory forward (to improve temporal consistency). We use standard multi-head attention (MHA) models as the components. 
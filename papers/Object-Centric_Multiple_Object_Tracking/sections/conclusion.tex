\section{Conclusion}
\looseness=-1In this paper, we build a pipeline for MOT with object-centric backbones. With memory modules, we can address both part-whole issues and consistently track objects over time. Overall, our approach improves over conventional tracking-by-detection pipelines by replacing expensive annotations (especially ID annotations) with self supervision. This work opens many directions for new research. First of all, it allows for active learning. For example, the model could elicit a request for labeling on specific frames, further reducing necessity for costly annotations.
Furthermore, incorporating memory information as top-down reasoning prior for the object-centric encoder still remains to be explored.
Additionally, we still require few masks and class labels to resolve over-segmentation. Those semantic signals could be distilled from multi-modal foundation models trained with weaker supervision signals (e.g., captioned images). Finally, our results delineate a clear benefit in improving (video) object-centric backbones. 
As we have demonstrated, improvements in self-supervised object-centric learning can greatly facilitate complex downstream vision tasks like MOT, improving performance by training on unsupervised or weakly-supervised data.



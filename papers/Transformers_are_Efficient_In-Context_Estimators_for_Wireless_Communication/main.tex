\documentclass[journal,letterpaper,onecolumn]{IEEEtran}
\IEEEoverridecommandlockouts
\usepackage[utf8]{inputenc}
\usepackage{amsmath,amssymb}
\usepackage{tablefootnote}
% \usepackage{booktabs}
\usepackage{multirow}
\usepackage{hyperref}
\input{math_commands.tex}
\input{./Arxiv_Files/preamble}


\title{Transformers are Efficient In-Context\\ Estimators for Wireless Communication}

\author{
Vicram Rajagopalan$^{*~1}$ \quad
Vishnu Teja Kunde$^{*~2}$ \\
Chandra Shekhara Kaushik Valmeekam$^{2}$ \\
Krishna Narayanan$^{2}$ \quad
Srinivas Shakkottai$^{2}$ \\
Dileep Kalathil$^{2}$ \quad
Jean-Francois Chamberland$^{2}$ \\
{\small $^{1}$Department of Computer Science and Engineering, Texas A\&M University} \\
{\small $^{2}$Department of Electrical and Computer Engineering, Texas A\&M University}
}

\begin{document}
\maketitle
\def\thefootnote{*}\footnotetext{Equal contribution}

\begin{abstract}
Pre-trained transformers can perform in-context learning, where they adapt to a new task using only a small number of prompts without any explicit model optimization. Inspired by this attribute, we propose a novel approach, called in-context estimation, for the canonical communication problem of estimating transmitted symbols from received symbols. A communication channel is essentially a noisy function that maps transmitted symbols to received symbols, and this function can be represented by an unknown parameter whose statistics depend on an (also unknown) latent context. 
Conventional approaches typically do not fully exploit hierarchical model with the latent context. Instead, they often use mismatched priors to form a linear minimum mean-squared error estimate of the channel parameter,
which is then used to estimate successive, unknown transmitted symbols. We make the basic connection that transformers show excellent contextual sequence completion with a few prompts, and so they should be able to implicitly determine the latent context from pilot symbols to perform end-to-end in-context estimation of transmitted symbols. Furthermore, the transformer should use information efficiently, i.e., it should utilize any pilots received to attain the best possible symbol estimates. Through extensive simulations, we show that in-context estimation not only significantly outperforms standard approaches, but also achieves the same performance as an estimator with perfect knowledge of the latent context within a few context examples. Thus, we make a strong case that transformers are efficient in-context estimators in the communication setting. 
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% INTRODUCTION
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}

Recent advances in our understanding of transformers have brought to the fore the notion that they are capable of in-context learning.  Here, a pre-trained transformer is presented with example prompts followed by query to be answered of the form $(\rvx_1,f(\rvx_1, \theta), \hdots, \rvx_p, f(\rvx_p, \theta), \rvx_{p+1}),$ where $\theta$ is a context common to all the prompts.  The finding is that the transformer is able to respond with a good approximation to $f(\rvx_{p+1},\theta)$ for many function classes~\cite{garg2023transformers,ahuja2023incontext}. 
The transformer itself is pre-trained, either implicitly or explicitly over a variety of contexts and so acquires the ability to generate in-distribution outputs conditioned on a specific context.

While our theoretical understanding of such in-context learning in transformers is still in its infancy, their excellent empirical performance motivates us to explore the \emph{inverse problem} of in-context estimation.  Here, we are presented with the sequence $(f(\rvx_1, \theta), \rvx_1,\hdots,  f(\rvx_p, \theta), \rvx_p, f(\rvx_{p+1}, \theta)),$ and are required to estimate $\rvx_{p+1}.$  This inverse problem is of particular interest to communication theory, as the canonical communication problem can be posed precisely in this form, with the communication channel mapping an input symbol $\rvx$ to a received observation $\rvy = f(\rvx, \theta),$  with the addition of noise.  The receiver is required to recover $\rvx$ using the past observations.  The context here corresponds to the communication channel physics, with the mobile velocity and receiver occlusion playing major roles in the specific channel evolution.      

The prompts in the case of the communication problem are called ``pilot symbols,'' which are known in advance at the receiver.  A baseline approach towards estimating the transmitted symbol $\rvx_{p+1}$ from the observation $\rvy_{p+1}$ is to first estimate the channel function using the pilots, and then to estimate the transmitted symbol, conditioned on the channel estimate.  However, such an approach does not optimally exploit the relationship between the context, the channel function and the received symbol.  
The optimal estimator (in the mean squared error sense) computes the posterior mean estimate taking into account the full structure of the problem. However, the computational complexity of the optimal estimator is prohibitive. 

In this paper, we make the fundamental connection between the in-context learning property of transformers with our desire for in-context estimation applicable to communication systems.  Our observation is that a pre-trained transformer's ability to perform in-context sequence completion suggests strongly that it should be able to approximate the desired conditional mean estimator given the in-context examples (pilots) for our inverse problem.  Essentially, if a transformer is pre-trained on a variety of contexts, it should be able to implicitly determine the latent context from pilot symbols and then perform end-to-end in-context estimation of transmitted symbols.  Once trained, such a transformer is simple to deploy, since there are no runtime modifications.

Our main results are to show that our connection is indeed accurate and that pre-trained transformers  easily outperform the baseline algorithm, both for fixed and time-varying channels.  Furthermore, we observe that transformers are information efficient in that they come close to matching the performance of a genie-aided algorithm that conducts estimation with full knowledge of the latent context, suggesting that they are actually learning the optimal contextual inference function.  Thus, we demonstrate that transformers are well able to perform efficient in-context estimation.

\section{Related Work}
\subsection{Transformers and In-Context Learning}
Transformer architectures have become a popular model architecture across a variety of problems. The recent popularity of this architecture is in large part due to the fact that multi-head self-attention units have been shown to perform well on a wide variety of natural language tasks~\cite{NIPS2017_3f5ee243}.

In \cite{LanguageModelsAreFewShotLearners} it was shown that GPT-3, a transformer-based large language model, is able to perform well on novel, unseen tasks in a few-shot or zero-shot manner, known as in-context learning. The authors of \cite{xie2022an} used synthetic data to show that in-context learning can be interpreted as Bayesian inference, wherein a model first attempts to infer the task and then uses this prediction to carry out the task.

\cite{garg2023transformers} and \cite{ahuja2023incontext} are closely related to our work. In \cite{garg2023transformers}, the authors explore in-context learning from a different perspective than prior work. Rather than looking at in-context learning in the natural language setting, they pose this as the problem of learning to perform least-squares estimation for linear regression by being trained on sequence data. The authors of \cite{ahuja2023incontext} build on this work and provide mathematical theory to describe how this can be interpreted as the model performing Bayesian inference by estimating a posterior distribution.

Other work has gone further in explaining the mechanisms by which transformers are able to perform in-context learning. Some authors have explored the behavior of simplified transformer models on synthetic linear regression problems, as compared to the globally optimal solutions for these problems\cite{mahankali2023step,Zhang2023TrainedTL}.
In \cite{whatlearningalgorithm}, it is shown by construction that transformers can learn to fit a linear model at inference time given a context. This tells us that, at least in theory, transformers can learn to literally perform regression and related computations given some data. A related line of work explores the manner by which transformer models carry out these optimization procedures and shows that transformer models can perform nontrivial gradient-based optimization procedures at inference time\cite{von2023transformers,ahn2023transformers}. 
In \cite{EmergentICL}, the authors test how properties of training data impact in-context learning behaviors. 
The authors of \cite{min2022rethinking} similarly study how the properties of the context itself impact in-context learning performance. 

In summary, many different research directions have provided ways to interpret and understand in-context learning and the mechanisms by which transformer models do it. In our work, we primarily use the Bayesian perspective to view this ability and to understand how we can apply it to the wireless communication domain.

\subsection{Machine Learning for Wireless Communication}
The problem of symbol estimation in the presence of an unknown channel is a canonical problem in wireless communication and there is a large body of literature that considers model-driven traditional signal processing approaches. 
When the prior distribution for the channel follows a hierarchical model with latent contexts such as what we study in this paper, optimal model-based estimators become computationally infeasible. 
While approximations to the optimal estimators have been studied with restricted priors, the structure and performance of such estimators are highly dependent on the priors.






Recently, there has been significant interest in using machine learning methods such as variational inference \cite{ChannelEstimationUsingVAE}, \cite{UnsupervisedEqualizationUsingVAEs} and deep neural network models such as fully connected neural networks \cite{DeepLearningAidedChannelEstimation}, convolutional neural networks \cite{LearningMMSEChannelEstimator}, and recurrent neural networks \cite{RNNforChannelEstimation} 
for channel estimation and for symbol estimation \cite{aoudia2021end}. The authors of \cite{faycal} design an  end-to-end wireless communication system design using learning-based approach.
The work of \cite{neumann} provides a principled way of designing channel estimators in the setting of wireless communication, by training CNN-based neural network to efficiently estimate the channel parameters when it follows a hierarchical prior. The authors of \cite{UnsupervisedLinearAndNonLinearChannelEqAndDecoding} used variational autoencoders (VAEs) and unsupervised learning to implicitly learn and decode symbols in a wireless channel. In \cite{SemisupervisedVAEForNonLinearChannels}, the authors use VAEs in a semi-supervised setting to operate over non-linear channels. The approach in \cite{deepLearningForTimeVaryingMIMOChannels} uses a long short-term memory (LSTM) based channel parameter estimator for a time-varying channel. They are interested in learning the spatial correlation structure of the channel coefficients across the receiver antennae.
 
 
 The main distinction of our work from the previous works is that we make the connection between the in-context learning capabilities of the transformer and the symbol estimation problem in wireless communication. We show how the problem fits naturally in the setting, and provide empirical evidence that transformers achieve near-optimal performance. A comparative study of the performance of the transformers and other machine learning models is left for the future work.


\section{Transformers for In-Context Estimation}
\label{in_context_estimation}
Consider the problem of estimating $\rvx_t \in\sR^{d_x}$ from the observations $\rvy_t \in \sR^{d_y}$, where $\rvy_t = f(\rvx_t, \rvh_t(\theta), \rvz_t)$, i.e., the observation $\rvy_t$ is a function of $\rvx_t$, a latent context dependent parameter $\rvh_t(\theta) \in\sR^d$, and an independent noise $\rvz_t \in \sR^{d_z}$, for $t \in [\ell] \triangleq \{1, \dots, \ell\}$. Here, $\ell$ denotes maximum context length. We assume that the random processes are generated as $\{\rvx_t\}_{t\in[\ell]} \sim P_x, \{\rvz_t\}_{t\in[\ell]} \sim P_z, \{\rvh_{t}\}_{t\in[\ell]} \sim P_{h\mid\theta}$, where distribution $P_{h\mid \theta}$ is determined by a latent parameter $\theta$. The latent parameter is drawn from a distribution $P_\Theta$ on the latent space $\Theta$. We assume that the random processes $\{\rvx_t\}_{t\in[\ell]}$ and $\{\rvh_t(\theta)\}_{t\in[\ell]}$ are independent from each other for all $\theta \in \Theta$. Denote $S_k = \{(\rvy_t, \rvx_t), t\in[k]\}$ to be the set of example prompts until time $k$.

Given the current observation $\rvy_{k+1}$, and the past $k$ examples $S_k$, the minimum mean squared error estimate (MMSE) of $\rvx_{k+1}$ is known to be the conditional expectation
\begin{equation}
\label{eq:context_agnostic_estimator}
    \hat{\rvx}_{k+1} = \E[ \rvx_{k+1} \mid S_k, \rvy_{k+1}].
\end{equation}

In addition, if the estimator knows the latent context parameter $\theta$ apriori, then the optimal estimator is given by
\begin{equation}
\label{eq:in_context_estimator}
    \hat{\rvx}_{k+1}^\theta = \E[ \rvx_{k+1} \mid S_k, \rvy_{k+1}, \theta],
\end{equation}
which we call the optimal context-aware estimator. It is known that the MSE achieved by an optimal context-aware estimator not worse than that of a context agnostic estimator given by \ref{eq:context_agnostic_estimator}.


Having a closer look at the computation of the conditional expectation in \ref{eq:context_agnostic_estimator}, we get
\begin{align*}
    \hat{\rvx}_{k+1} &= \E[\rvx_{k+1} \mid S_k, \rvy_{k+1}] \\
    &= \int_{\vx\in \sR^{d_x}} \vx P_x( \rvx_{k+1} =  \vx \mid S_k, \rvy_{k+1}) d\vx \\
    &= \frac{1}{C_1} \int_{\vx\in \sR^{d_x}} \vx P_x(\vx) P(S_k, \rvy_{k+1} \mid \vx) d\vx \\
    &= \frac{1}{C_1} \int_{\vx\in \sR^{d_x}} \int_{\theta \in \Theta} P_\Theta(\theta)\int_{\vh_1, \dots, \vh_k, \vh_{k+1} \in\sR^{d_h}} \vx P_x(\vx) P_{h \mid \theta}(\vh_1, \dots, \vh_k) \\
    &\hspace{1cm} P(S_k, \rvy_{k+1} \mid \vx, \vh_{1}, \dots, \vh_k, \vh_{k+1}) d\vx d\vh_1 \dots d\vh_{k+1},
\end{align*}
where $C_1$ is a normalization constant. The above involves evaluating a multi-dimensional integral. In most practical problems of estimation, computation of \ref{eq:context_agnostic_estimator} can be very difficult or even intractable. This is indeed the case with the wireless communication problem of interest (see Section. \ref{wireless_communication_problem}). Motivated by recent studies (\cite{garg2023transformers,bartlett}) that demonstrate the remarkable ability of transformers to exhibit in-context learning, we train a transformer-based model to approximate \ref{eq:context_agnostic_estimator}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%% main figure below %%%%%%%%%%%%%
\begin{figure}[ht]
\centering
\input{figures/TransformerModel}
\caption{Transformer model performing causal attention}
\label{fig:TransformerModel}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%% main figure above %%%%%%%%%%%%%

Specifically, let $T_W$ denote a decoder-only transformer\cite{gpt2} with parameters (weights) $W$. Let $T^{k+1}_W(S_{k}, \rvy_{k+1})$ be predicted value of $\rvx_{k+1}$ by the transformer given $S_k, \rvy_{k+1}$ (see Fig. \ref{fig:TransformerModel}). Denote the data set $\mathcal{D}=\{ S_\ell^n = \{(\rvy_t^n, \rvx_t^n), t\in[\ell]\} \mid {\rm for~each}~n\in N,  \theta \sim P_{\Theta}, \rvx_t \sim P_x, \rvz_t \sim P_z, \rvh_t(\theta) \sim P_{h \mid \theta}, \rvy_t = f(\rvx_t, \rvh_t(\theta), \rvz_t)\}$ of trajectories generated via our sampling procedure. We first sample $\theta \sim P_{\Theta}, \{\rvx_t\} \sim P_x,$ and $\{\rvz_t\} \sim P_z$ independent of each other. We then sample $\{\rvh_t(\theta)\} \sim P_{h \mid \theta}$ using $\theta$ and use the sampled quantities to compute $\rvy_t = f(\rvx_t, \rvh_t(\theta), \rvz_t)$. We repeat this $N$ times to sample a batch of $N$ independent sequences.

Then, we can train the transformer by minimizing the sum of the squared norms of the difference between the predicted value and the actual values, i.e., we optimize $W$ such that the loss $\mathcal{L}(W; \mathcal{D})$ is minimized:
\begin{equation}
\label{eq:loss_function}
     \mathcal{L}(W; \mathcal{D}) = \frac{1}{N} \sum_{n=1}^N \sum_{k=0}^{\ell-1} ||T_W^{k+1}(S_k^n, \rvy_{k+1}^n) - \rvx_{k+1}^n||^2 \approx \sum_{k=1}^{\ell-1}\E[||T^{k+1}_W(S_{k}, \rvy_{k+1}) - \rvx_{k+1}||^2].
\end{equation}

Let $T_{W^*}$ denote the \emph{trained} transformer. In the setting of in-context estimation, we are interested in the performance of $T_{W^*}^{k+1}(S_k, \rvy_{k+1})$ as a function of $k$.

\section{Wireless Communication System Model}
\label{wireless_communication_problem}

In this section, we specialize the estimation problem stated in Section \ref{in_context_estimation} to the wireless communication problems of interest.
Consider a wireless channel with a single transmit antenna and $d$ receive antennae (see Fig. \ref{fig:TranEstimator}). Let $\rx_t \in \sA = \{x_I+ \sqrt{-1} \ x_Q  \mid x_I, x_Q\in\{\pm 1\}\}$ be the $t$th transmitted symbol.
The transmit sequence $\{\rx_t\}$ is an i.i.d sequence of symbols drawn from $\sA$ with uniform probability.

Let $\rvy_t \in \sC^d$ be the received symbol vector, where $\ervy^j_t$ denotes the received symbol at the $j$th antenna at time $t$. 
Let $\rvh_t(\theta) \in\sC^d$ be the wireless channel coefficient between the transmitter and the $j$th receiver antenna, and let $\rvz_t$ be the additive noise at the receiver, at time $t$. 
Then, we can write the input-output relation as
\begin{equation}
\label{eq:io_relation}
    \rvy_t = \rvh_t(\theta) \rx_t + \rvz_t, \quad t\in[\ell].
\end{equation}




%%%%%%%%%%%%%%%%%%%%%%%%%%%% main figure below %%%%%%%%%%%%%
\begin{figure}[ht]
\centering
\input{figures/TranEstimator}
\caption{Notional diagram of a typical single-input multiple-output (SIMO) wireless channel combined with a transformer-based receiver}
\label{fig:TranEstimator}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%% main figure above %%%%%%%%%%%%%

For some $\sigma^2 > 0$, the sequence $\{\rvz_t\}$ are independent and identically distributed (i.i.d.) Gaussian random vectors, with $\rvz_{t, I},\rvz_{t,Q}\sim \mathcal{N}(\mathbf{0}, \sigma^2 \mI_{d})$ for each $t\in[\ell]$. The ratio $1/\sigma^2$ is called the signal-to-noise-ratio (SNR).




Next, we describe the latent context space $\Theta$, and the conditional distributions for the channel, i.e., $P_{h\mid \theta}$ for $\theta\in\Theta$. The channel parameter process $\{\rvh_t(\theta)\}$ in the wireless communications typically depends on two aspects, discussed in the following subsections.


\subsection{Type of Scattering}

In wireless communication, signals transmitted from the transmitter antenna reach the receiver antenna from multiple directions after being scattered by the obstacles in the environment. In this situation, the channel parameter depends on the configuration of the environment and the positioning and influence of the obstacles. If there are few or no obstacles, there is a direct path called the line-of-sight (LoS) path between the transmitter and the receiver, and in this case, the received signal can be modeled by a single ray of signal reaching the antenna. Thus, the effective channel parameter depends on the angle of arrival of this LoS component of the signal. On the other hand, if there are significantly many scatterers in the environment, as in an urban environment, there is a large number of reflected rays reaching the receiver at the same time. This scenario is (aptly) called the rich-scattering environment, and the channel parameter in this case can be approximated as a Gaussian random variable. 

Each of the above cases gives rise to a different distribution on the channel, and hence, we model the type of scattering of the signal as the latent context $\theta$. More formally, let $\Theta=\{0, 1\}$ denote the latent context space where $\theta = 0$ corresponds to the LoS model, and $\theta=1$ corresponds to the rich scattering model. In this case, we first generate $\rvh_1(\theta)$ and assume that it remains constant for the period of interest, i.e., $\rvh_t(\theta) = \rvh_1(\theta)$ for all $t\in[\ell]$. This corresponds to the environment being stationary, i.e., the signal paths do not change over time in the period of interest.

    When $\theta=0$, $\rh_1^j(0) = \exp(-(\sqrt{-1})2\pi (s/\lambda)(j-1)\cos(\alpha)) \triangleq \phi_j(\alpha)$, where $j\in[d]$. 
    
    Here, $\alpha \sim {\rm Unif}[0, \pi)$ is the angle of arrival of the one ray (\cite{goldsmith_2005}), $s$ is the spacing between the antennae, $\lambda$ is the wavelength of the signal used for transmission.

    When $\theta=1$, the channel parameter is modeled by $\rvh_{1, I}(1),\rvh_{1, Q}(1) \sim \mathcal{N}(0, \frac{1}{2}\mI_d)$, with $\rvh_{1, I}(1), \rvh_{1, Q}(1)$ are drawn independently. We call the above case as scenario C1.

\subsection{Mobility}

Assume that the transmitter is fixed and the receiver is moving towards the transmitter with some velocity $v$ m/s. This situation naturally arises in the wireless communication application. Considering a rich-scattering environment, the properties of the channel parameter, and the correlation of the parameter process depends on the velocity: more the velocity, less the correlation. Therefore, having a estimate of the velocity in such environments and the correlation structure would greatly improve the performance of the estimator at the receiver. However, in practice, this can be difficult to obtain online. Hence, we model velocity to parameterize the latent context $\theta$. 

More specifically, we consider a latent space $\Theta = [M]$  representing the $M$ possible velocities with $v_\theta$ being the mobile velocity when the latent variable is $\theta$. Let $\{\rh^j_t(\theta)\}_t$ denote the channel parameter process at the $j$th antenna. Note that this process is a time-varying process with unlike in the last scenario, where the process that remains constant across the time. Across the antennae $j\in[d]$, we assume that the processes $\{\rh^j_t(\theta)\}_t$ are  i.i.d. zero-mean, wide-sense stationary Gaussian random processes (Section 15.5, \cite{Kay97}). The correlation function $R_\theta(m) = \E[\rh_{t, I}^1(\theta) \rh^1_{m+t, I}(\theta)]$ for any $t\in\sN$ is determined by the latent context $\theta$. We use the well-known Clarke's model (Section 3.2.1, \cite{goldsmith_2005})and set $R_\theta(m) = J_0(\frac{2\pi T_s m v_\theta}{\lambda})$. Here, $T_s$ is the symbol duration, $\lambda$ is the wavelength of the signal, $v_\theta$ is the relative velocity between the transmitter and the receiver, $J_0$ denotes the Bessel function of the first kind of order $0$. 
We call the above scenario as scenario C2.


In both the scenarios C1 and C2, the latent parameter $\theta$ is drawn uniformly at random from $\Theta$. 


In wireless communications, a set of known symbols called pilots are transmitted as part of the transmitted symbols. 
These symbols are used to estimate the channel parameter process and then the estimate is typically used to perform symbol estimation. 
There is a natural way in which these pilots can be used as in-context examples. 
In the language of Section \ref{in_context_estimation}, the set $S_k$ contains the pilots symbols $(\rx_t, t\in[k])$ until time $k$
and the corresponding received symbols $(\rvy_t, t\in[k])$. 
The pilots do not communicate any information and hence, it is important to keep the number of pilots small. 
Thus, machine learning model based estimators need to be information-efficient and make maximal use of the information in $S_k$.


\section{Methodology}

In this section, we describe the classical estimation techniques used to solve the estimation problem, along with a transformer model as an alternative.

\subsection{Context-aware and baseline estimators}
\label{baseline_genie_descriptions}
In this section, we describe some feasible context-aware estimators, that achieve a low MSE (close to that of \ref{eq:in_context_estimator}). For C1, $\theta = 0$, since the randomness of the channel parameter vector comes from a single random variable $\alpha$, the computation of the posterior mean involves an integral in one dimension. Hence, it can be computed in a computationally efficient manner. The exact expression appears in \ref{eq:one_ray_model_symbol_estimation}. 
In the remaining cases, we cannot evaluate the expression explicitly. In these cases, the context-aware estimator first computes the Linear Minimum Mean Square Estimate (LMMSE) $\hat{\vh}_{k+1}^{\rm LMMSE, \theta}$  of the channel parameter ${\rvh}_{k+1}(\theta)$ given $S_k, \theta$. The exact details of computing the expression for $\hat{\vh}_{k+1}^{\rm LMMSE, \theta}$ are given in Appendix \ref{context_aware_estimators_derivation}. Incidentally, for $\theta=1$ in C1, and for all $\theta \in \Theta$ in C2, since $\rvh_{k+1}(\theta)$ and $(\rvy_t, t\in [k])$ are jointly Gaussian, conditioned on $(\rx_t, t\in[k])$, this channel estimate is in fact the minimum mean squared estimate (MMSE) of $\rvh_{k+1}(\theta)$ given $S_k, \theta$. Then, the symbol is estimated by computing $\E[\rx_{k+1} \mid \rvh_{k+1}(\theta) = \hat{\vh}_{k+1}^{\rm LMMSE, \theta} \mid \rvy_{k+1}]$; the exact expression for above conditional expectation is given in \ref{eq:symbol_estimate}.



For the context agnostic baseline, we describe an estimation procedure commonly used in the wireless communication. The estimator first computes the LMMSE of the channel (see Appendix \ref{baseline_for_agnostic_estimators}), which uses the correlation matrices corresponding to prior for the channel parameter process. Then, it estimates the symbol as the conditional mean, conditioned on the LMMSE for the channel. The exact details are given in Appendix \ref{baseline_for_agnostic_estimators}.

\subsection{Transformer} \label{training}
We train our transformer models as described in Section~\ref{in_context_estimation}. We follow the training setup used in \cite{ahuja2023incontext}, which is in turn based on the approach used in \cite{garg2023transformers}. For all experiments, we train a GPT-2 decoder-only model from scratch.

We specifically modify the setting in Section 4 of \cite{ahuja2023incontext}, regarding learning of functions sampled from a hierarchical distribution of function classes (``tasks"). In this setting, a task $\theta$ is sampled from some set of tasks $\Theta$, then a function $f$ is sampled from a set of functions $\mathcal{F}_\theta$ which is determined by $\theta$. In our case, $f$ is determined by the channel coefficients $\vh$, which we sample as described in Section~\ref{wireless_communication_problem}.

The training data is generated as follows. First we draw $\theta \sim {\rm Unif}(\Theta)$. In C1, we generate $\alpha \sim {\rm Unif}[0, \pi)$ and set $\rh^j_t(0) = \phi_j(\alpha)$. In C2, we generate the sequence $\rvh^j = (\rh_t^j, t\in \sN)$ from a stationary Gaussian random process. For each training mini-batch, we re-sample $\theta$ and then independently sample each $\vh^j$.

As done in \cite{ahuja2023incontext}, we train our decoder models to perform prediction in the style of language models, where $$((\rvy_1, \rvx_1), (\rvy_2, \rvx_2), \dots, (\rvy_k, \rvx_k), \rvy_{k+1})$$ are used to predict $\rvx_{k+1}$. We use the sum of squared errors between all $(\rvx_t, \hat{\rvx}_t), t\in[k+1]$ as our loss function, where $\hat{\rvx}_t =  T_W^{k+1}(S_k, \rvy_{k+1})$. 

We set the number of antennae $d = 4$. For C2, we consider $M = 3$, where $v_1 = 5, v_2 = 15, v_3 = 30$ (all in m/s). These are representative of the typical values seen in practice for wireless communications. For C1, $\theta = 1$, we set $s = \lambda/4$. For C2, we use $f_c = 2.9 \times 10^9$ Hz, and $\lambda = f_c/c$, where $c = 3\times 10^8$ m/s is the speed of light. Further, we set the symbol duration $T_s =$ 1 millisecond in C2.

We include our model architecture details and other hyperparameter settings in Appendix~\ref{parameters}.

\section{Results and discussion}

Here, we present experimental results for scenarios C1 and C2. In short, across the scenarios we discuss, we show that GPT-2 models trained on sequences sampled from these scenarios are able to approach the performance of genie-aided estimates. This is surprising, in that the genie estimates are given the exact realization of $\theta$ for each case, while the models have to estimate this from context in addition to predicting the symbols $\rvx$.

\subsection{Scenario C1: Estimation on 1-Ray and Fading Channels}
We trained two GPT-2 models as described in Section~\ref{training} on data sampled from the C1 scenario. The only difference in training was the SNR used when sampling the data: we trained one model with an SNR of 0 dB and the other model with an SNR of -5 dB. In Figure~\ref{fig:ray_fading_results}, we present results for our trained models and our baseline methods on sequences from these two latent contexts. In these figures, for each context length $k$, we plot the MSE between the true $\rvx$ and the predicted $\hat{\rvx}$. 
We present these curves for the transformer model, context-aware estimate, and context-agnostic baseline (Section~\ref{baseline_genie_descriptions}).
We also plot a 90\% confidence interval for the transformer model's prediction errors.

%%%%%%%%%%%%%%%%%%%%%%%%% main plot below %%%%%%%%%%%%%%
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/ray_fading_results.pdf}
    \caption{Results for Scenario C1, SNR = 0, -5 dB}
    \label{fig:ray_fading_results}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%% main plot above %%%%%%%%%%%%%%

Let us first discuss the 1-ray context. Here, even with zero context (pilots), the transformer model is able to perform better than the context-agnostic model. This indicates that the model is able to use the statistics of the $\rvy$ vectors to distinguish between 1-ray and rich-scattering data. As the context length increases, for both SNR values, the transformer model performs better than the context-agnostic baseline and approaches the performance of the lower-bound genie estimate. This shows that the model is able to determine the latent context and make a good estimate of the channel parameters, without being given any information beyond the $(\rvy, \rvx)$ pairs themselves.

In the rich-scattering context, the three methods perform roughly the same across both SNR values and all context lengths. This is to be expected. The channel in this case is Gaussian with Gaussian noise, and simply estimating the mean and variance of the channel will grant the best performance. The notable aspect of this is that the transformer model is able to correctly identify the context and has learned the correct way to estimate the channel for this context.

\subsection{Scenario C2: Estimation on a Time-Varying Channel}
We trained a GPT-2 model as described previously on data sampled from scenario C2. We present results for this scenario in Figure~\ref{fig:time_varying}. The plot here is produced similarly to Figure~\ref{fig:ray_fading_results} with the added challenge that the channel coefficients vary with the index $k$.



%%%%%%%%%%%%%%%%%%%%%%%%% main plot below %%%%%%%%%%%%%%
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/demodulation_time_varying_snr_0_results.pdf}
    \caption{Results for Scenario C2, SNR = 0 dB}
    \label{fig:time_varying}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%% main plot above %%%%%%%%%%%%%%

In Figure~\ref{fig:time_varying}, we can see that the transformer model and both estimators have an MSE of 2.0 for zero context at every velocity. This is to be expected, as an MSE of 2.0 indicates that the model is "hedging" by returning a value of 0, rather than predicting -1 or 1. Because the Gaussian noise $\rvz$ is negative or positive with equal probability, any model requires at least one $(\rvy, \rvx)$ pair before it is able to make a meaningful prediction. Across all velocity values, the transformer model's performance approaches the performance of the context-aware estimator as the context length increases. This indicates that with enough context, the model is able to estimate the latent context and the channel coefficients, even though those channel coefficients are changing over time. There is a significant gap between the performance of the context-agnostic baseline method and the performance of the two other methods, demonstrating that performing well on this problem requires knowing or estimating the velocity. The transformer model is able to accurately infer the context and use this information to perform nearly as well as the genie-aided context-aware estimator.

\subsection{Discussion}
Across the various tasks, parameters, and regimes studied, transformer models are able to infer the context from a few samples and then use this information to make an accurate estimation of the channel coefficients. We use genie-aided context-aware estimators to find lower bounds on the performance of any such model. These estimators are given exact, noiseless information about the context, which is not available to the transformer model. Even without such extra information, the transformer models we trained are able to approach and reach the performance of the context-aware methods. This finding demonstrates that the ability of transformers to learn in-context from prompts enables these models to perform well on wireless communication problems.

\section{Conclusion}

Prior work has shown that transformer models are able to perform in-context learning and that this ability can be applied to solve a large variety of problems. This work shows that the in-context learning setting translates directly to problems in wireless communication and that transformer models can be trained to perform estimation in this domain. The communication problems described here are difficult, and existing methods for solving them require significant knowledge of the problem setting. For example, the context-aware estimators which we use as lower bounds on estimation performance require exact knowledge of the current context, which is not readily available in practice.

Through empirical case studies, we have demonstrated that transformer models can achieve similarly good performance without prior knowledge by being trained on data from the relevant distribution. Other than these training samples, we do not give our transformer models any prior knowledge about the problem setting, even the fact that there are finitely many different contexts. The transformer models we trained have inferred details of the distribution from training samples and have learned to condition their outputs on the predicted context in a Bayesian manner. 
This surprising ability indicates that transformer models can reduce the information required to achieve state-of-the-art results across a variety of problems.




\bibliographystyle{Arxiv_Files/IEEEbib}
\bibliography{iclbiblio}


\appendix


\subsection{Detailed Derivation of Baseline and Context-Aware Estimators}
\label{baseline_genie}

Following Section \ref{baseline_genie_descriptions}, we derive the exact expressions for the context-aware and the baseline estimators. First, we describe some notations. For $\va\in\sC^d$, denote its real and imaginary parts as $\va_I, \va_Q \in \sR^d$ respectively, and its real vector representation (also, by abuse of notation) as $\va = [\va_I^T~\va_Q^T]^T\in\R^{2d}$. For $a\in\sC$, define $T^d(a) \triangleq \begin{bmatrix}
    a_{I} & -a_Q \\ a_Q & a_I
\end{bmatrix} \otimes \mI_d \in \R^{2d\times 2d}$, where $\otimes$ denotes the Kronecker product. Observe that the real-valued matrix equation corresponding to \ref{eq:io_relation} is given by
\begin{align*}
    \rvy_t = \rmX_t\rvh_t(\theta) + \rvz_t, \quad t\in[\ell],
\end{align*}
where $\rvy_t = \begin{bmatrix}\rvy_{t, I} \\ \rvy_{t, Q} \end{bmatrix} \in \R^{2d}, \rmX_t = T^d(\rx_t) \in \R^{2d \times 2d}, \rvz_t = \begin{bmatrix}\rvz_{t, I} \\ \rvz_{t, Q} \end{bmatrix} \in \R^{2d}, \rvh_t(\theta) = \begin{bmatrix}\rvh_{t, I}(\theta) \\ \rvh_{t, Q}(\theta) \end{bmatrix} \in\R^{2d}$. For $k\in[\ell-1]$, we can define
\begin{equation}
\label{eq:channel_model_real}
    \bar{\rvy}_{k} = \bar{\rmX}_k \bar{\rvh}_k(\theta) + \bar{\rvz}_k, 
\end{equation}
where $\bar{\rmX}_k = {\rm diag}(\rmX_1, \rmX_2, \dots, \rmX_k) \in \R^{2dk\times 2dk}$, $\bar{\rvy}_k = [\rvy_1^T~\rvy_2^T~\dots~\rvy_k^T]^T \in \R^{2dk}$ and similarly for $\bar{\rvh}_k(\theta), \bar{\rvz}_k$. 

In the scenario C1, since $\rvh_t(\theta) = \rvh_1(\theta)$ for all $t\in[\ell]$, we can rewrite \ref{eq:channel_model_real} as
\begin{equation}
\label{eq:c1_equation}
    \bar{\rvy}_k = \tilde{\rmX}_k \rvh_1(\theta) + \bar{\rvz}_k, 
\end{equation}
where $\tilde{\rmX}_k = [\rmX_1^T ~\rmX_2^T ~\dots ~ \rmX_k^T ]^T \in\sR^{2dk\times 2d}$. 


\subsubsection{Context-aware estimators}

\label{context_aware_estimators_derivation}

In this subsection, we describe the context-aware genie-estimators that achieve low MSE when the latent context $\theta$ is known, whose MSE serves as a lower bound on the achievable MSE for a context-agnostic estimator.  

For $\theta = 0$ in C1, we can evaluate the integral in the conditional expectation $\E[\rx_{k+1} \mid S_k, \rvy_{k+1}, \theta = 0]$ explicitly as follows

\begin{align}
\label{eq:contextual_con_mean_estimate}
    \E[\rx_{k+1} \mid S_k, \rvy_{k+1}, \theta = 0] = \sum_{a\in \sS} a P(\rx_{k+1} = a \mid S_k, \rvy_{k+1}, \theta = 0).
\end{align}

Denoting $\bar{q}_0(a) = P(\rx_{k+1} = a \mid S_k, \rvy_{k+1}, \theta = 0)$, we can write that
\begin{align*}
    \bar{q}_0(a) &= P(\rx_{k+1} = a \mid S_k, \rvy_{k+1}, \theta = 0) \\
    &= \frac{1}{C_1} P(a) P(S_k, \rvy_{k+1} \mid a, \theta = 0) \\
    % &= \frac{1}{C_1} P(a) \int_{\alpha=0}^\infty P(\alpha, S_k, \rvy_{k+1} \mid a, \theta = 0) d\alpha \\
    &= \frac{1}{C_1}P(a) \int_{\alpha = 0}^\infty  P(S_k, \rvy_{k+1}, \rvh_1(0) = \boldsymbol{\phi}(\alpha) \mid a) d\alpha \\
     &= \frac{1}{C_2}P(a) \int_{\alpha = 0}^\infty P(\rvy_{k+1} \mid T^d(a), \rvh_1(0) = \boldsymbol{\phi}(\alpha)) \prod_{t=1}^k P(\rvy_t \mid \rmX_t, \rvh_1(0) = \boldsymbol{\phi}(\alpha)) d\alpha \\
    &= \frac{1}{C_3}P(a) \int_{\alpha = 0}^\infty \exp(-||\rvy_{k+1}-T^d(a) \boldsymbol{\phi}(\alpha)||^2/(2\sigma^2))  \prod_{t=1}^k \exp(-||\rvy_t-\rmX_t \boldsymbol{\phi}(\alpha)||^2/(2\sigma^2))d\alpha \\
    &=\frac{1}{C_3} \underbrace{P(a) \int_{\alpha = 0}^\infty \exp\Big(-\frac{1}{2\sigma^2}\Big(||\rvy_{k+1}-T^d(a)\boldsymbol{\phi}(\alpha)||^2+ \sum_{t=1}^k||\rvy_t-\rmX_t \boldsymbol{\phi}(\alpha)||^2) \Big)\Big)d\alpha}_{q_0(a)},
\end{align*}
where $C_1, C_2, C_3$ are constants independent of $a$, and $C_3 = \sum_{a\in\sS}q_0(a)$. Therefore, we have

\begin{equation}
    \label{eq:one_ray_model_symbol_estimation}
    \E[\rx_{k+1} \mid S_k, \rvy_{k+1}, \theta = 0] = \sum_{a\in\sS}a\bar{q}_0(a) = \frac{\sum_{a\in\sS} a q_0(a)}{\sum_{a \in \sS} q_0(a)}.
\end{equation}

Therefore, in the scenario C1, $\theta= 0$, the mean squared error (MSE) achieved by the above estimator is the lower bound for any other estimator for $\rx_{k+1}$ that is given only $S_k$ (and also $\theta$). In other cases, the explicit design of estimators that achieve the lowest MSE is infeasible due to a high dimensional integral. Hence instead, we design a context-aware genie-estimator that achieves a reasonably low MSE as an estimator given $S_k, \theta$. Therefore, the emphasis is on how quickly the posterior on the the latent parameter concentrates by the set of in-context examples $S_k$.
The context-aware estimator computes the Linear Minimum Mean Square Estimate (LMMSE) $\hat{\vh}_{k+1}^{\rm LMMSE, \theta}$ for the channel parameter $\rvh_{k+1}(\theta)$ given the pilots $S_k$ and the latent context $\theta$. From Equations (\ref{eq:channel_model_real}), (\ref{eq:c1_equation}), we can compute the LMMSE (Theorem 12.1, \cite{Kay97}) estimates for the channel given the context $\theta$ as
\begin{align}
\label{eq:LMMSE_channel_estimate_C1}
    ({\rm C1})~\hat{\vh}_{1}^{\rm LMMSE, \theta} &= \E[\rvh_1(\theta)] + \mR_{h_{1}, \tilde{Y}_k}^\theta (\mR_{\tilde{Y}_k}^\theta)^{-1} \bar{\rvy}_{k} \\
    \label{eq:LMMSE_channel_estimate_C2}
    ({\rm C2})~\hat{\vh}_{k+1}^{\rm LMMSE, \theta}  &= \mR_{h_{k+1}, Y_k}^\theta (\mR_{X_k}^\theta)^{-1} \bar{\rvy}_{k},
\end{align}

where $\mR^\theta_{h_1, \tilde{Y}_k} = \E[\bar{\rvy}_{k}\bar{\rvy}_k^T], \mR^\theta_{h_1, \tilde{Y}_k} = \E[\rvh_1(\theta) \bar{\rvy}_{k}^T]$ from \ref{eq:c1_equation}, and $\mR^\theta_{h_{k+1}, {Y}_k} = \E[\bar{\rvy}_{k}\bar{\rvy}_k^T], \mR^\theta_{h_{k+1}, {Y}_k} = \E[\rvh_{k+1}(\theta) \bar{\rvy}_{k}^T]$ from \ref{eq:channel_model_real}. Note that $\E[\bar{\rvy}_{k}] = \mathbf{0}_{2dk}$ since $\E[\bar{\rmX}_k] = \mathbf{0}_{2dk\times 2dk}$, and $\E[\rvh_{k+1}(\theta)] = 0$ for any $\theta$ in C2.
Observe that since $\bar{\rvy}_k$ and ${\rvh}_{k+1}(\theta)$ are jointly Gaussian conditioned on $\theta$, the estimate for the channel parameter $\rvh_{k+1}$ given $S_k,\theta$ is in fact the minimum mean squared error (MMSE) estimate. Next, we give the expressions for the above correlation matrices.


For $\theta = 0$, the mean and auto-correlation function can be computed as $\boldsymbol{\mu}_{h_1}^0 = \E[\rvh_1(0)] = \frac{1}{\pi} \int_{\alpha = 0}^\pi \boldsymbol{\phi}(\alpha) d\alpha$, and $\mR^0_{h_1} = \E[\rvh_1(0)\rvh_1^T(0)] =  \frac{1}{\pi} \int_{\alpha = 0}^\pi \boldsymbol{\phi}(\alpha) \boldsymbol{\phi}^T(\alpha) d\alpha$. For $\theta=1$, the mean and the auto-correlation function for $\rvh_1(1)$ are given by $\boldsymbol{\mu}^1_{h_1} = \mathbf{0} \in \sR^{2d}$, and $\mR^1_{h_1} = \E[\rvh_1(1)\rvh_1(1)^T] = \frac{1}{2}\mI_{2d}$ respectively. Further, the auto-correlation of $\bar{\rvy}_k$ is given by $\mR^\theta_{X_k} = \tilde{\rmX}_k \mR_{h_1}^\theta \tilde{\rmX}_k^T + \sigma^2\mI_{2dk}$, and the cross-correlation matrix is given by $\mR_{h_1, X_k}^\theta = \mR_{h_1}^\theta \tilde{\rmX}_k^T$.

In C2, the auto-correlation of channel parameter variables under the latent context $\theta$ is given by $\mR^\theta_{H_k^d} = \E[\bar{\rvh}_k(\theta) \bar{\rvh}_k^T(\theta)] 
= \mR_{H_k}^\theta \otimes \mI_d$, where $(\mR_{H_k}^\theta)_{i,j} = R_\theta(|i-j|)$.  Further, the cross correlation between $\bar{\rvy}_k$ and $\rvh_{k+1}$ is given by
$\mR_{h_{k+1}, Y_k}^\theta = \E[\rvh_{k+1} \bar{\rvy}_{k}^T] = \mR_{h_{k+1}, H^d_k}^\theta \bar{\rmX}_k^T$, where $\mR^\theta_{h_{k+1}, H_k^d} = [R_\theta(k)~R_{\theta}(k-1)~\dots~R_\theta(1)]\otimes \mI_{2d} \in\sR^{2d \times 2dk}$. Finally, the auto-correlation of $\bar{\rvy}_{k}$ is given by $\mR^\theta_{Y_k} = \bar{\rmX}_k \mR^\theta_{H_k^d} \bar{\rmX}_k^T + \sigma^2 \mI_{2dk}$.

After computing $\hat{\vh}_{k+1}^{\rm LMMSE, \theta}$ using Equations (\ref{eq:LMMSE_channel_estimate_C1}), (\ref{eq:LMMSE_channel_estimate_C2}) the estimator computes the posterior mean estimate for symbol $\rx_{k+1}$ as $\hat{\rx}_{k+1} = \E[\rx_{k+1} \mid \rvh_{k+1}(\theta) = \hat{\vh}_{k+1}^{\rm LMMSE, \theta}, \rvy_{k+1}] = \sum_{a \in \sS} a P_x(\rx_{k+1} = a \mid  \hat{\vh}_{k+1}^{\rm LMMSE, \theta},\rvy_{k+1} )$. Simplifying, we have
\begin{align*}   
 \bar{q}_\vh(a) \triangleq P(\rx_{k+1} = a \mid \rvh_{k+1}(\theta) = \vh, \rvy_{k+1}) &= \frac{1}{C_1} P(a)  P(\rvy_{k+1} \mid \rvh_{k+1}(\theta) = \vh, a) \\
    &= \frac{1}{C_2} \underbrace{P(a)\exp(-(||\rvy_{k+1} - T^d(a)\vh)||^2/(2\sigma^2)))}_{q_\vh(a)},
\end{align*}
where $C_1, C_2$ are constants independent of $a$. Since $C_2 = \sum_{a\in\sS} q_{\vh}(a)$, we have that the symbol estimate is
\begin{equation}
    \label{eq:symbol_estimate}
    \hat{\rx}_{k+1} = \sum_{a\in \sS} \bar{q}_{\hat{\vh}_{k+1}^{\rm LMMSE, \theta}}(a) = \frac{\sum_{a \in \sS} a q_{\hat{\vh}_{k+1}^{\rm LMMSE, \theta}}(a)}{\sum_{a \in\sS} q_{\hat{\vh}_{k+1}^{\rm LMMSE, \theta}}(a)}.
\end{equation}



\subsubsection{Baseline for context-agnostic estimators}
\label{baseline_for_agnostic_estimators}

Traditional signal processing techniques cannot use the hierarchical structure of the prior on the channel. We design a baseline which first computes the LMMSE for the channel parameter as 
\begin{equation}
\label{eq:context_agnostic_LMMSE_channel}
    \hat{\vh}_{k+1}^{\rm LMMSE} = \E[\rvh_{k+1}] + \mR_{h_{k+1}, Y_k} \mR_{Y_k}^{-1} \bar{\rvy}_k.
\end{equation}
Notice that since the above estimator does not have the information about the latent context $\theta$, we use the true correlation matrices on the joint prior of on the process $(\rvh_t)$, given by $\mR_{Y_k} = \sum_{\theta\in \Theta} P_\Theta(\theta)\mR^\theta_{Y_k}$, $\mR_{h_{k+1}, Y_k} = \sum_{\theta\in\Theta}P_\Theta(\theta) \mR^\theta_{h_{k+1}, Y_k}$, and $\E[\rvh_{k+1}] = \sum_{\theta\in\Theta} P_\Theta(\theta) \E[\rvh_{k+1}(\theta)]$. Finally, we estimate the symbol $\rx_{k+1}$ using \ref{eq:symbol_estimate} with $q_{\hat{\vh}_{k+1}^{\rm LMMSE,\theta}}$ is replaced by $q_{\hat{\vh}_{k+1}^{\rm LMMSE}}$.

\subsection{Model Parameters}
\label{parameters}
We extend the codebase from~\cite{ahuja2023incontext} for our models and experiments. We use the same GPT-2 model size as in this paper, as well as the same optimizer (Adam, \cite{Kingma2014AdamAM}), the same learning rate (0.0001), 
and the same training length (500,000 steps).


\begin{table}[ht]
    \centering
    \begin{tabular}{|c|c|c|}
         \hline
         \textbf{Embedding Size} & \textbf{\# Layers} & \textbf{\# Attention Heads} \\
         \hline
         256 & 12 & 8\\
         \hline
    \end{tabular}
    \vspace{2pt}
    \caption{Model Parameters}
    \label{tab:modelparameters}
\end{table}


\begin{table}[ht]
    \centering
    \begin{tabular}{|c|c|c|c|c|}
         \hline
         \textbf{Scenario}& \textbf{Curriculum Start Length} & \textbf{Curr. End Length} & \textbf{Batch Size} & \textbf{Learning Rate} \\
         \hline
         \textbf{C1} & 5 & 11 & 64 & 1e-4 \\
         \hline
         \textbf{C2} & 5 & 15 & 64 & 1e-4 \\
         \hline
    \end{tabular}
    \vspace{2pt}
    \caption{Training Parameters}
    \label{tab:trainingparameters}
\end{table}

\textbf{Curriculum:} \cite{garg2023transformers} observed that curriculum learning is useful in training models to perform in-context learning consistently and effectively.
In \cite{garg2023transformers} and \cite{ahuja2023incontext}, the curriculum is to initiate training with small sequence lengths and vector dimensions and to increase these gradually over training until they reach the desired sizes. In our tasks, the vector dimension is fixed to twice the number of antennae,
and we modify only the sequence lengths in our curriculum. For scenario C1, we vary the sequence length from 5 to a maximum of 11. For scenario C2, we vary the sequence length from 5 to a maximum of 15. We choose to use a larger sequence length for scenario C2 in order to better demonstrate the impact of using a time-varying channel.

We present the relevant architecture details and training parameters in Tables~\ref{tab:modelparameters} and~\ref{tab:trainingparameters}.




\end{document}

\section{Background and related works}
\label{sec:related}
% self-supervision audio
Self-supervised representation learning has shown remarkable success in vision~\cite{simclr} and speech
recognition~\cite{baevski2020wav2vec}. The \wavvec~\cite{baevski2020wav2vec} and Conformer models~\cite{conformer} are most relevant to our work. % on paralinguistic speech representations. 
%\wavvec
\cite{baevski2020wav2vec} was one of the first frameworks to successfully combine Transformers~\cite{transformer} and a self-supervised contrastive learning objective for speech. The same training objective was subsequently combined with Conformer architectures~\cite{conformer}, which added convolution filters to Transformer layers, producing further improvements in semi-supervised speech recognition applications~\cite{bigssl}. Recently,  \cite{cap12} developed Conformer-based models (CAP12) that created representations for
non-ASR speech analysis and paralinguistics tasks. Linear models on time-averaged CAP12 representations performed at or above state-of-the-at across several tasks simultaneously. However, as with most self-supervised models, their resource footprint (memory and compute) makes them less suitable for on-device applications. In this work, we distill the CAP12 model from \cite{cap12} to several ``lite'' architectures for use on mobile devices, and we release them publicly.

% distilling architectures
Distillation~\cite{distillation} has been popular for transferring knowledge from large models to smaller ones. We distill the Conformer model to a variety of smaller, fixed-length input architectures that have been used in audio classification, such as ResNets~\cite{hershey2017cnn}, EfficientNets~\cite{efficientnetv2}, and ASTs~\cite{ast}. Other works have applied distillation to speech representations~\cite{frill}, but to our knowledge this work is the first successful speech embedding distillation from arbitrary-length input Transformers to fixed-length input models.
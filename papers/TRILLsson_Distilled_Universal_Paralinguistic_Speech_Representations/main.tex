% Template for ICASSP-2021 paper; to be used with:
%          spconf.sty  - ICASSP/ICIP LaTeX style file, and
%          IEEEbib.bst - IEEE bibliography style file.
% --------------------------------------------------------------------------
%
%
%
\documentclass{article}
\usepackage{spconf,amsmath,graphicx}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{caption}
\usepackage{tikz}
\usepackage{pifont}% http://ctan.org/pkg/pifont
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
\newcommand{\trillsson}{{TRILLsson}}
\newcommand{\wavvec}{{Wav2Vec$2.0$}}
\captionsetup{font=footnotesize}

% Example definitions.
% --------------------
\def\x{{\mathbf x}}
\def\L{{\cal L}}

% Title.
% ------
%\title{TRILLsson: Publicly Available and On-Device Universal Paralinguistic Speech Representations via Cross-Architecture Knowledge Distillation}
%\title{TRILLsson: Paralinguistic Speech Representations via Knowledge Distillation}
\title{TRILLsson: Distilled Universal Paralinguistic Speech Representations}
% alternate names DISTRILL

%
% Single address.
% ---------------
\name{Joel Shor$^1$, Subhashini Venugopalan$^2$}
\address{Verily Life Sciences$^1$, Google Research$^2$ \\
joelshor@verily.com}

\begin{document}
%\ninept
%
\maketitle
%
\begin{abstract}
Recent advances in self-supervision have dramatically improved the quality of speech representations.
However, deployment of state-of-the-art embedding models on devices has been restricted due to their limited public availability and large resource footprint.
Our work addresses these issues by \textbf{publicly releasing a collection of paralinguistic speech models}\footnote[1]{\scriptsize\url{https://tfhub.dev/s?q=trillsson}} that are small and near state-of-the-art performance. Our approach is based on knowledge distillation, and our models are distilled on public data only. We explore different architectures 
and thoroughly evaluate our models on the Non-Semantic Speech (NOSS) benchmark.
Our largest distilled model is \textbf{less than 15\% the size} of the original model (314MB vs 2.2GB), achieves \textbf{over 96\% the accuracy on 6 of 7 tasks}, and is trained on 6.5\% the data. The smallest model is \textbf{1\% in size} (22MB) and achieves over \textbf{90\% the accuracy on 6 of 7 tasks}. Our models outperform the open source Wav2Vec 2.0 model on 6 of 7 tasks, and our smallest model outperforms the open source Wav2Vec 2.0 on both emotion recognition tasks despite being 7\% the size.
%However there are still constraints that have prevented them from being more widely deployed on devices particularly for paralinguistic tasks. For one, the models are often too large to be run in resource constrained environments. Second, general-purpose speech representations from large self-supervised techniques are rarely publicly available. 
%Our work addresses these. We train a collection of near state-of-the-art paralinguistic speech representations on only public data and \textbf{publicly release them}\footnote[1]{\url{https://tfhub.dev/s?q=nonsemantic-speech-benchmark}}.
%Our work addresses these by training a collection of near state-of-the-art paralinguistic speech representations on public data and \textbf{publicly releasing them}\footnote[1]{\url{https://tfhub.dev/s?q=nonsemantic-speech-benchmark}}.
%We achieve this dramatic reduction in model size and latency via a collection of techniques such as limited context windows and generating target vectors at the right timescale.
\end{abstract}
%
\begin{keywords}
speech, representations, on-device, paralinguistic speech
\end{keywords}
%
\section{Introduction}
\label{sec:intro}

\input{1_introduction}

\input{2_related}
\input{3_experiments}

\section{Results}
\label{sec:results}
\input{4_results}

\vspace{-3mm}

\section{Conclusion}
\label{sec:conclusion}
\input{5_conclusion}

\vspace{-3mm}
\section{Acknowledgements}
We want to thank Aren Jansen, Channing Moore, Wei Han, Daniel Park, Yu Zhang, and the entire author list of \cite{bigssl}, without which this work wouldn't have been possible.


\bibliographystyle{IEEE}
\bibliography{biblio}
%\bibliography{strings,refs}

%\section{Appendix}
%\input{6_appendix}

\end{document}

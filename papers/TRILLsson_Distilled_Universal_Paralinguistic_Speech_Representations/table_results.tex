\begin{centering}
\begin{table*}[t]
\scriptsize
\vspace{-0.2cm}
\caption{Test performance on the NOSS Benchmark and extended tasks. 
``Prev. SoTA" are usually domain specific, but all other rows are linear models on time-averaged input. TRILLsson model sizes are shown without frontends.
$\uparrow$ indicates higher values are better, and $\downarrow$ indicates lower is better.
%``Prev SoTA" are arbitrarily complicated models, but \textbf{all other rows are linear models on time-averaged input}.
$^\dagger$We use a filtered subset of Voxceleb1 according to YouTubeâ€™s privacy guidelines. We omit previous SoTA results on this dataset, since they used the entire dataset.
$^{**}$ASVSpoof uses equal error rate~\cite{asvspoof}. We report the best single-model performance (as compared to model ensembles).
$^{\#}$Euphonia is the only non-public dataset. We use a larger dataset than was reported on in~\cite{cap12}.
$^*$We use the public Wav2Vec 2.0 model from \href{https://huggingface.co/docs/transformers/model_doc/wav2vec2}{Hugging Face}~\cite{transformers_lib}
}\label{tab:results}

\centering
%\begin{tabular}{@{} llcc|cccccccc @{}}
\begin{tabular}{@{} llcc|ccccccc @{}}
\toprule[2pt]
\begin{tabular}{@{}c@{}}Model\\(input size)\end{tabular} &
%Arch. &
\begin{tabular}{@{}c@{}}Params\\ (M)\end{tabular} &
\begin{tabular}{@{}c@{}}Size\\ (MB)\end{tabular} &
Public &
%\begin{tabular}{@{}c@{}}Avg D-\\Prime $\uparrow$\end{tabular}   & 
Voxceleb1$^\dagger$ $\uparrow$ & 
Voxforge $\uparrow$\ & 
\begin{tabular}{@{}c@{}}Speech $\uparrow$\\ Commands\end{tabular}   &  
\begin{tabular}{@{}c@{}}ASVSpoof\\ 2019$^{**}$ $\downarrow$ \end{tabular} & 
Euphonia$^{\#}$ $\uparrow$ &
CREMA-D $\uparrow$ &
IEMOCAP $\uparrow$
\\
\toprule[2pt]
\textbf{Prev. SoTA}
& -
& -
& -
%& -
%& -
& -
& 99.8~\cite{cap12} 
& 97.9~\cite{speech_commandssota} 
& 2.5~\cite{cap12} 
& -
& 88.2~\cite{cap12} 
& 79.2~\cite{cap12}
\\
\midrule
\textbf{CAP12} \\
% Architecture avg test voxceleb voxforge speechcommands asvspoof euphonia cremad iemocap params size 
\quad (full)  
& 606 & 2,200 & \xmark
%& 3.31
& 51.0  & 99.7      & 97.1 & 2.5 & 46.9  & 88.2 & 75.5  \\
\quad (3s) 
& 606 & 2,200 & \xmark
%& 3.25
& 47.9  & 99.4      & 97.1 & 3.8 & 46.9  & 88.1 & 74.3    \\
\quad (2s) 
& 606 & 2,200 & \xmark
%& 3.10
& 48.1  & 99.4      & 97.0 & 6.9 & 46.9  & 85.3 & 72.7   \\
\midrule
\midrule
\textbf{Baselines} \\
%\quad \begin{tabular}{@{}c@{}}Wav2Vec2*\\(full)\end{tabular} & Transformer
%\quad Wav2Vec2 Lg L6$^*$
%& \tiny{Transformer}
%& ? & ? & \cmark
%& ?
%& ? & ? & ? & ? & ? & ? & ? \\
%\quad Wav2Vec2 Lg. final
%& \tiny{Transformer}
%& ? & ? & \cmark
%& ?
%& ? & ? & ? & ? & ? & ? & ? \\
\quad Wav2Vec2 Sm. L6$^*$
& 93.4 & 360 & \cmark
%& 2.87
& 17.9 & 98.5 & \textbf{95.0} & 6.7 & 48.2 & 77.4 & 65.8 \\
\quad Wav2Vec2 Sm.$^*$
& 93.4 & 360 & \cmark
%& 2.31
& 1.7 & 95.9 & 89.3 & 11.2 & 50.0 & 58.0 & 52.4 \\
\quad TRILL 
%& \tiny{Resnetish}
& 24.5 & 87 & \cmark
%& 2.06
& 13.8 & 84.5 & 77.6 & 6.3 & 47.0 & 65.7 & 55.4 \\
%\quad FRILL (1s)     & MobileNet
%& 10 & 36 & \cmark
%& 1.97 & 13.8 & 78.8 & 74.3 & 7.8 & 46.2 & 71.3 & 59.9 \\
\quad YAMNet
%& \tiny{Resnetish}
& 3.7 & 17 & \cmark
%& 2.00
& 9.6 & 79.8 & 78.5 & 6.7 & 43.8 & 66.4 & 57.5 \\
\midrule
\textbf{TRILLsson} \\
% voxceleb voxforge speechcommands asvspoof euphonia cremad iemocap 

% This is what the new code generates.
% ast_sec2_l24_m2048,	678.0	0.447263	0.995385	0.936810	0.071780	0.482906	0.856684	0.712329	
%\quad 5 (AST) 
%& \tiny{AST}
%& 176.9 & 678 & \cmark
%& 3.31
%& \textbf{44.7} & \textbf{99.5} & 93.7 & 7.2 & 48.3 & 85.7 & \textbf{71.2}  \\

% ????
% This is the old model.
%vox-filtered-acc-test	voxforge-acc-test	speech_commands-acc-test	asvspoof2019-eer-test	euphonia_5cls-acc-test	crema_d-acc-test	iemocap-acc-test
%trillsson5_public	0.461949	0.996656	0.939468	0.054253	0.480963	0.860540	0.726833
\quad 5 (AST) 
%& \tiny{AST}
& 88.6 & 314 & \cmark
%& ?
& \textbf{46.2} & \textbf{99.7} & 93.9 & \textbf{5.4} & 48.1 & 86.1 & 72.7  \\

% ast_sec2_l24_m512,	390.0	0.429907	0.995418	0.932106	0.090685	0.459984	0.857969	0.709106
%\quad 4 (AST) 
%& 101.3 & 390 & \cmark
%& 3.21
%& 43.0 & \textbf{99.5} & 93.2 & 9.1 & 46.0 & \textbf{85.8} & 70.9    \\

%vox-filtered-acc-test	voxforge-acc-test	speech_commands-acc-test	asvspoof2019-eer-test	euphonia_5cls-acc-test	crema_d-acc-test	iemocap-acc-test
%trillsson4_public	0.431242	0.996020	0.944785	0.070835	0.506605	0.862468	0.722804
% ???
\quad 4 (AST) 
& 63.4 & 224 & \cmark
%& ?
& 43.1 & 99.6 & 94.5 & 7.1 & \textbf{50.7} & \textbf{86.2} & \textbf{73.2}    \\

% This is the new model, which is too large.
% efficientnetv2bM,	231.0	0.409880	0.991940	0.937219	0.071112	0.480963	0.837404	0.705077
%\quad 3 (EffNetv2) 
%& 54.1 & 231 & \cmark
%& 3.20
%& 41.0 & 99.2 & 93.7 & 7.1 & 48.1 & 83.7 & 70.5    \\

% efficientnetv2bS,	99.0	0.400534	0.991806	0.932106	0.068359	0.474359	0.832262	0.703465
\quad 3 (EffNetv2) 
& 21.5 & 99 & \cmark
%& ?
& 40.1 & 99.2 & 93.2 & 6.8 & 47.4 & 83.2 & 70.3    \\

% efficientnetv2b1,	42.0	0.375167	0.991873	0.920654	0.065784	0.445610	0.825835	0.697824
\quad 2 (EffNetv2) 
& 8.1 & 42 & \cmark
%& 3.06
& 37.5 & 99.2 & 92.1 & 6.6 & 44.6 & 82.6 & 69.8    \\

% resnetish_sec2_2352_0.5,	22.0	0.299065	0.978563	0.890798	0.130392	0.458819	0.795630	0.670427
\quad 1 (ResNet) 
& 5.0 & 22 & \cmark
%& 2.79
& 36.6 & 98.6 & 91.2 & 7.5 & 43.3 & 81.3 & 68.5    \\
\bottomrule
\end{tabular}
\vspace{-4mm}
\end{table*}
\end{centering}
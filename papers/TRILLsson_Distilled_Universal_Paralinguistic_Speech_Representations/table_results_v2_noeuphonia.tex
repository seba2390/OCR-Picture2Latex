\begin{centering}
\begin{table*}[t]
\scriptsize
\vspace{-0.2cm}
\caption{Test performance on the NOSS Benchmark and extended tasks. 
``Prev. SoTA" are usually domain specific, but all other rows are linear models on time-averaged input. TRILLsson model sizes are shown without frontends.
%``Prev SoTA" are arbitrarily complicated models, but \textbf{all other rows are linear models on time-averaged input}.
$^\dagger$We use a filtered subset of Voxceleb1 according to YouTubeâ€™s privacy guidelines. We omit previous SoTA results on this dataset, since they used the entire dataset.
$^{**}$ASVSpoof uses equal error rate~\cite{asvspoof}. We report the best single-model performance (as compared to model ensembles).
$^*$We use the public Wav2Vec 2.0 model from \href{https://huggingface.co/docs/transformers/model_doc/wav2vec2}{Hugging Face}~\cite{transformers_lib}
}\label{tab:results}

\centering
\begin{tabular}{@{} llcc|ccccccc @{}}
\toprule[2pt]
\begin{tabular}{@{}c@{}}Model\\(input size)\end{tabular} &
%Arch. &
\begin{tabular}{@{}c@{}}Params\\ (M)\end{tabular} &
\begin{tabular}{@{}c@{}}Size\\ (MB)\end{tabular} &
Public &
\begin{tabular}{@{}c@{}}Avg D-\\Prime\end{tabular}   & 
Voxceleb1$^\dagger$ & 
Voxforge & 
\begin{tabular}{@{}c@{}}Speech \\ Commands\end{tabular}   &  
\begin{tabular}{@{}c@{}}ASVSpoof\\ 2019$^{**}$\end{tabular} &
CREMA-D &
IEMOCAP
\\
\toprule[2pt]
\textbf{Prev. SoTA}
& -
& -
& -
& -
%& -
& -
& 99.8~\cite{cap12} 
& 97.9~\cite{speech_commandssota} 
& 2.5~\cite{cap12} 
& 88.2~\cite{cap12} 
& 79.2~\cite{cap12}
\\
\midrule
\textbf{CAP12} \\
% Architecture avg test voxceleb voxforge speechcommands asvspoof euphonia cremad iemocap params size 
\quad (full)  
& 606 & 2,200 & \xmark
& 3.31
& 51.0  & 99.7      & 97.1 & 2.5  & 88.2 & 75.5  \\
\quad (3s) 
& 606 & 2,200 & \xmark
& 3.25
& 47.9  & 99.4      & 97.1 & 3.8  & 88.1 & 74.3    \\
\quad (2s) 
& 606 & 2,200 & \xmark
& 3.10
& 48.1  & 99.4      & 97.0 & 6.9  & 85.3 & 72.7   \\
\midrule
\midrule
\textbf{Baselines} \\
%\quad \begin{tabular}{@{}c@{}}Wav2Vec2*\\(full)\end{tabular} & Transformer
%\quad Wav2Vec2 Lg L6$^*$
%& \tiny{Transformer}
%& ? & ? & \cmark
%& ?
%& ? & ? & ? & ? & ? & ? & ? \\
%\quad Wav2Vec2 Lg. final
%& \tiny{Transformer}
%& ? & ? & \cmark
%& ?
%& ? & ? & ? & ? & ? & ? & ? \\
\quad Wav2Vec2 Sm. L6$^*$
& 93.4 & 360 & \cmark
& ?
& 17.9 & 98.5 & \textbf{95.0} & 6.7 & 77.4 & 65.8 \\
\quad Wav2Vec2 Sm.$^*$
& 93.4 & 360 & \cmark
& ?
& 1.7 & 95.9 & 89.3 & 11.2 & 58.0 & 52.4 \\
\quad TRILL 
%& \tiny{Resnetish}
& 24.5 & 87 & \cmark
& 2.08
& 13.8 & 84.5 & 77.6 & 6.3 & 65.7 & 55.4 \\
\quad YAMNet
%& \tiny{Resnetish}
& 3.7 & 17 & \cmark
& 2.01
& 9.6 & 79.8 & 78.5 & 6.7 & 66.4 & 57.5 \\
\midrule
\textbf{TRILLsson} \\
% voxceleb voxforge speechcommands asvspoof euphonia cremad iemocap 

% ast_sec2_l24_m2048,	678.0	0.447263	0.995385	0.936810	0.071780	0.482906	0.856684	0.712329	
\quad 5 (AST) 
%& \tiny{AST}
& ? & 678 & \cmark
& ?
& \textbf{44.7} & \textbf{99.5} & 93.7 & \textbf{?} & 85.7 & \textbf{71.2}  \\

% ast_sec2_l24_m512,	390.0	0.429907	0.995418	0.932106	0.090685	0.459984	0.857969	0.709106
\quad 4 (AST) 
& ? & 390 & \cmark
& ?
& 43.0 & \textbf{99.5} & 93.2 & ? & \textbf{85.8} & 70.9    \\

% efficientnetv2bM,	231.0	0.409880	0.991940	0.937219	0.071112	0.480963	0.837404	0.705077
\quad 3 (EffNetv2) 
& ? & 231 & \cmark
& ?
& 41.0 & 99.2 & 93.7 & ? & 83.7 & 70.5    \\

% efficientnetv2b1,	42.0	0.375167	0.991873	0.920654	0.065784	0.445610	0.825835	0.697824
\quad 2 (EffNetv2) 
& ? & 42 & \cmark
& ?
& 37.5 & 99.2 & 92.1 & ? & 82.6 & 69.8    \\

% resnetish_sec2_2352_0.5,	22.0	0.299065	0.978563	0.890798	0.130392	0.458819	0.795630	0.670427
\quad 1 (ResNet) 
& 5.0 & 22 & \cmark
& ?
& 30.0 & 97.9 & 89.1 & ? & 79.6 & 67.0    \\
\bottomrule
\end{tabular}
\vspace{-3mm}
\end{table*}
\end{centering}

\section{Proof of Theorem \ref{thm:gamma_main_theorem} (Finitely Divisible Items)} \label{sec:gamma_algo_analysis}
Throughout the analysis, the defective set $\mathcal{S}$ is fixed but otherwise arbitrary, and we condition on fixed placements of the defective items into tests (and hence, fixed test outcomes and a fixed defective tree). The test placements of the non-defective items are independent of those of the defective items, and our analysis will hold regardless of which particular tests the defectives were placed in. The defective test placements are written as $\mathcal{T}_{\mathcal{S}}$, and we write $\mathbb{P}[\cdot \,|\,  \mathcal{T}_{\mathcal{S}}]$ to denote the conditioning.

We proceed with three lemmas that follow analogous steps to \cite{Eri20}.  At level $l=1$, the probability of a non-defective node being placed in a positive test is zero, because each node is placed in its own individual test. As for levels $l \in \{2,\dotsc,\gamma'-2\}$, we proceed with the following simple lemma.

\begin{lemma} \label{lem:gamma_prob_of_nondef_node_being_in_pos_test} {\textup{(Probabilities of Non-Defectives Being in Positive Tests)}}
Under the above test design, the following holds at any given level $l=2,\dots,\gamma'-2$: Conditioned on any defective test placements $\mathcal{T}_{\mathcal{S}}$, any given non-defective node at level $l$ has probability at most $(1/C)(n/k)^{-1/\gamma'}$ of being placed in a positive test.
\end{lemma} 

\begin{proof}
Since there are $k$ defective items, at most $k$ nodes at a given level can be defective. Hence, since each node is placed in a single test, at most $k$ tests out of the $Ck(n/k)^{1/\gamma'}$ tests at the given level can be positive. Since the test placements are independent and uniform, it follows that for any non-defective node, the probability of being in a positive test is at most $k/T_{\text{len}}=k/\big(Ck(n/k)^{1/\gamma'}\big)=(1/C)(n/k)^{-1/\gamma'}$.
\end{proof}

In view of this lemma, when starting at any non-defective child of any defective node, we can view any further branches down the non-defective sub-tree as ``continuing'' (i.e., the $M^{1/(\gamma'-1)}$ children are marked as possibility defective) with probability at most $(1/C)(n/k)^{-1/\gamma'}$, in particular implying Lemma \ref{lem:gamma_prob_of_nondef_node_at_dist_away} below.  
% 
Before stating the lemma, we introduce some terminology that well help us make more concise statements:
\begin{itemize}
    \item We say that a node is \emph{reached} if all of its ancestors are placed in positive tests, so the node will be considered possibly defective.  This is in contrast to nodes that are not reached (by the decoding algorithm) because one of their ancestors is found to be non-defective.
    \item For any non-defective node, we define its \emph{distance to the defective tree} as the smallest number of edges that needs to be traversed to reach a defective node (e.g., $\Delta = 1$ for a non-defective child of a defective node).
\end{itemize}

\begin{lemma} \label{lem:gamma_prob_of_nondef_node_at_dist_away} \textup{(Probability of Reaching a Non-Defective Node)}
    Under the setup of Lemma \ref{lem:gamma_prob_of_nondef_node_being_in_pos_test}, any given non-defective node at distance $\Delta$ from the defective tree is reached with probability at most $(1/C)^{\Delta-1}(n/k)^{(1-\Delta)/\gamma'}$.
\end{lemma} 

We will use the preceding lemmas to control the quantity $N_{\text{total}}$, defined to be the total number of non-defective nodes that are \textit{reached}---in the sense of Lemma \ref{lem:gamma_prob_of_nondef_node_at_dist_away}---among levels $l\in\{2,\dots,\gamma'-1\}$. It will be useful to upper bound $N_{\text{total}}$ for the purpose of controlling the overall decoding time and the number of items considered at the final level.

\subsection{Bounding $N_{\text{total}}$} 

We first present a lemma bounding the average of $N_{\text{total}}$.

\begin{lemma} \label{lem:N_total_average_bound_gamma} \textup{(Bounding $N_{\text{total}}$ on Average)}
For any parameters $C>1$ and $\gamma'>1$, and any defective test placements $\mathcal{T}_{\mathcal{S}}$, under the choice $M=(n/k)^{\frac{\gamma'-1}{\gamma'}}$, we have
\begin{align}
    \E[N_{\textup{total}}|\mathcal{T}_{\mathcal{S}}]=O\bigg(\gamma'k\Big(\frac{n}{k}\Big)^{\frac{1}{\gamma'}}\bigg).
\end{align}
\end{lemma} 

\begin{proof}
At level $l=1$, we use $n/M$ tests for individual nodes. This results in correct identification of the non-defective nodes, guaranteeing that they will not ``continue'' to branch. Hence, at level $l=1$, we trivially upper bound the number of non-defective nodes by $n/M$.

For the remaining levels $l=2,\dots,\gamma'-1$, all splits are $\big(M^{1/(\gamma'-1)}\big)$-ary, and each defective node can have at most $M^{\Delta/(\gamma'-1)}$ descendants at distance $\Delta$. Since there are at most $\gamma'k$ defective nodes in total among levels $l=1,\dots,\gamma'-1$, it follows that there are at most $\gamma'kM^{\frac{\Delta}{\gamma'-1}}$ non-defective nodes at distance $\Delta$ from defective nodes starting at those levels.  Furthermore, we established in Lemma \ref{lem:gamma_prob_of_nondef_node_at_dist_away} that a distance of $\Delta$ gives a probability of at most $\big(\frac{1}{C}\big)^{\Delta-1}\big(\frac{n}{k}\big)^{(1-\Delta)/\gamma'}$ of being reached. This gives
\begin{align}
    \E[N_{\textup{total}}|\mathcal{T}_{\mathcal{S}}]
    &\leq\sum_{\Delta=1}^{\gamma'}\gamma'kM^{\frac{\Delta}{\gamma'-1}}\Big(\frac{1}{C}\Big)^{\Delta-1}\Big(\frac{n}{k}\Big)^{\frac{1-\Delta}{\gamma'}}
    +\frac{n}{M} \\
    &=\gamma'kM^{\frac{1}{\gamma'-1}}\sum_{\Delta=1}^{\gamma'}M^{\frac{\Delta-1}{\gamma'-1}}\Big(\frac{1}{C}\Big)^{\Delta-1}\Big(\frac{n}{k}\Big)^{\frac{1-\Delta}{\gamma'}}+\frac{n}{M} \\
    &\stackrel{(a)}{\le}\gamma'kM^{\frac{1}{\gamma'-1}}\frac{1}{1-M^{\frac{1}{\gamma'-1}}\big(\frac{1}{C}\big)\big(\frac{n}{k}\big)^{-1/\gamma'}}+\frac{n}{M} \\
    &\stackrel{(b)}{=}\gamma'k\Big(\frac{n}{k}\Big)^{\frac{1}{\gamma'}}\frac{1}{1-1/C}+k\Big(\frac{n}{k}\Big)^{\frac{1}{\gamma'}},
     % \\ & = \frac{C}{C-1}\gamma'k\Big(\frac{n}{k}\Big)^{\frac{1}{\gamma'}}+k\Big(\frac{n}{k}\Big)^{\frac{1}{\gamma'}},
\end{align}
where (a) applies the geometric series formula (increasing the upper limit of the sum from $\gamma'$ to $\infty$), and (b) follows by substituting $M=(n/k)^{\frac{\gamma'-1}{\gamma'}}$.
\end{proof}

We now wish to move from a characterization of the average to a high-probability characterization.  At this point, we depart somewhat further from the analysis of \cite{Eri20}, which is based on branching process theory, and appears to yield suboptimal results in the case that the tree's branching factor scales as $\omega(1)$.

We introduce the following definition, in which we refer to a \textit{full} $m$-ary tree as a tree where every \textit{internal} node has exactly $m$ children.
 
\begin{lemma}\label{lem:cat_num} \textup{\cite[Prop.~3.1]{AVAL08} (Fuss-Catalan Numbers)} 
For natural integers $m,n\geq2$, the order-$m$ Fuss-Catalan number
\begin{align}
    \textup{Cat}_m^{n}&=\frac{1}{(m-1)n+1}{mn\choose n}
    \leq{mn\choose n}
    \leq(em)^n,
\end{align}
is the number of full $m$-ary trees with exactly $n$ internal nodes.
\end{lemma}

We note that the Catalan numbers also played an important role in the analysis of the unconstrained setting it \cite{cher20}, but were used in a rather different manner that we were unable to extend to obtain a result comparable to Theorem \ref{thm:gamma_main_theorem}.  In the proof of the following lemma, these are used in a counting argument in order to establish the sub-exponential behavior of the random variable $N_{\rm total}$.

\begin{lemma} \label{lem:N_total_high_prob_bound_gamma} \textup{(High Probability Bound on $N_{\text{total}}$)}
For any parameters $C\geq e^2$ and $\gamma'>1$, and any defective test placements $\mathcal{T}_{\mathcal{S}}$, under the choice $M=(n/k)^{\frac{\gamma'-1}{\gamma'}}$, we have $N_{\textup{total}}=O\big(\gamma'k(n/k)^{1/\gamma'}\big)$ with probability $1-e^{-\Omega(\gamma'k)}$.
\end{lemma}

\begin{proof}
Consider a single non-defective sub-tree following a defective node, and let $N_b$ be the number of nodes in the sub-tree such that itself and all its ancestors only appear in positive tests (i.e., the number of nodes that lead to further branching).  We have
\begin{align}
    \mathbb{P}[N_b=n_b]&\leq\mathbb{P}[\exists\text{ a full $M^{1/(\gamma'-1)}$-tree reached with $n_b$ internal nodes}] \\
    &\stackrel{(a)}{\leq}(\text{\#full $M^{1/(\gamma'-1)}$-trees with $n_b$ internal nodes})\cdot\bigg(\frac{1}{C}\Big(\frac{n}{k}\Big)^{-\frac{1}{\gamma'}}\bigg)^{n_b} \\
    &\stackrel{(b)}{\leq}\big(eM^{1/(\gamma'-1)}\big)^{n_b}\bigg(\frac{1}{C}\Big(\frac{n}{k}\Big)^{-\frac{1}{\gamma'}}\bigg)^{n_b} \\
    &\stackrel{(c)}{=}\Big(\frac{e}{C}\Big)^{n_b}
    \stackrel{(d)}{\leq}e^{-n_b},
\end{align}
where (a) applies Lemma \ref{lem:gamma_prob_of_nondef_node_being_in_pos_test} and the union bound, (b) applies Lemma \ref{lem:cat_num}, (c) is obtained by substituting $M=(n/k)^{\frac{\gamma'-1}{\gamma'}}$ and simplifying, and (d) holds since $C\geq e^2$. This implies that $N_b$ is a sub-exponential random variable. Since we have at most $(\gamma'-1)k$ defective nodes in levels $l=1,\dots,\gamma'-1$, we are adding together $O(\gamma'k)$ independent copies of such random variables (each corresponding to a different non-defective sub-tree following a defective node).\footnote{We do not consider the non-defective nodes at level $l=1$, because they are guaranteed to be identified correctly as a result of individual testing of nodes.} Letting $N_b^{(i)}$ denote the $i$-th copy, we can apply a standard concentration bound for sums of independent sub-exponential random variables \cite[Prop. 5.16]{Ver12} to obtain 
\begin{align}
    \mathbb{P}\big[N_b^{(1)}+\dots+N_b^{(O(\gamma'k))}&\geq\E[N_b^{(1)}+\dots+N_b^{(O(\gamma'k))}]+t|\mathcal{T}_\mathcal{S}\big]\leq\exp\bigg(\Omega\Big(\min\Big\{\frac{t^2}{\gamma'k},t\Big\}\Big)\bigg).
\end{align}
Setting $t=\Theta(\gamma'k)$, we get
\begin{align}
    \mathbb{P}[N_b^{(1)}+\dots+N_b^{(O(\gamma'k))}\geq\E[N_b^{(1)}+\dots+N_b^{(O(\gamma'k))}]+\Theta(\gamma'k)|\mathcal{T}_\mathcal{S}]\leq e^{-\Omega(\gamma'k)}. \label{eq:N_conc}
\end{align}
Recall that each $N_b^{(i)}$ only counts ``internal'' nodes, whereas $N_{\rm total}$ also counts leaves, so passing from the former to the latter requires multiplying by the branching factor $M^{1/(\gamma'-1)}=(n/k)^{1/\gamma'}$.   Multiplying on both sides inside the probability in \eqref{eq:N_conc} accordingly, we obtain
% By first multiplying $M^{1/(\gamma'-1)}=(n/k)^{1/\gamma'}$ (i.e., the branching factor) to both sides of the inequality inside $\mathbb{P}[\cdot]$, then adding the number of defective nodes ($=O(\gamma'k)$) and all their children ($=O\big(\gamma'k(n/k)^{1/\gamma'}\big)$) in levels $l=1,\dots,\gamma'-1$ to both sides of the inequality inside $\mathbb{P}[\cdot]$, we get
\begin{align}
    \mathbb{P}\bigg[N_{\text{total}}\geq\E[N_{\text{total}}]+\Theta\bigg(\gamma'k\Big(\frac{n}{k}\Big)^{1/\gamma'}\bigg)\Big|\mathcal{T}_\mathcal{S}\bigg]\leq e^{-\Omega(\gamma'k)}. \label{eq:concentration_bound}
\end{align}
Substituting $\E[N_{\text{total}}]=O\big(\gamma'k(n/k)^{1/\gamma'}\big)$ (see Lemma \ref{lem:N_total_average_bound_gamma}) into \eqref{eq:concentration_bound}, we obtain the desired result.
\end{proof}

We now briefly consider level $l=\gamma'-1$, which uses $T'_{\rm len} = \gamma'k(n/k)^{1/\gamma'}$ tests (see Figure \ref{fig:test_constraint_diagram_3cases}).  Since $|\mathcal{PD}^{(\gamma'-1)}|\leq N_{\text{total}}+k$ holds trivially, Lemma \ref{lem:N_total_high_prob_bound_gamma} implies that $|\mathcal{PD}^{(\gamma'-1)}|=O\big(\gamma'k(n/k)^{1/\gamma'}\big)$ with probability $1-e^{-\Omega(\gamma' k)}$. Using the same argument as Lemma \ref{lem:gamma_prob_of_nondef_node_being_in_pos_test}, the probability of a non-defective node being in a positive test at level $l=\gamma'-1$ is at most $k/T'_{\text{len}}=(1/\gamma')(n/k)^{-1/\gamma'}$. Hence, conditioned on $|\mathcal{PD}^{(\gamma'-1)}|=O\big(\gamma'k(n/k)^{1/\gamma'}\big)$, the number of non-defective nodes placed in a positive test is stochastically dominated by
\begin{align}
    \text{Binomial}\bigg( O\Big( \gamma'k\Big(\frac{n}{k}\Big)^{1/\gamma'} \Big),\frac{1}{\gamma'}\Big(\frac{n}{k}\Big)^{-1/\gamma'}\bigg).
\end{align}
By a multiplicative form of Chernoff bound, the number of such non-defective nodes in $\mathcal{PD}^{(\gamma'-1)}$ is $O(k)$ with probability at least $1-e^{-\Omega(k)}$. Since the branching factor is $(n/k)^{1/\gamma'}$, it follows that the number of non-defective nodes in $\mathcal{PD}^{(\gamma')}$ behaves as $O(k(n/k)^{1/\gamma'})$.

\subsection{Analysis of the Final Level} \label{sec:gamma_final_lvl_analysis}

Recall that at the final level, we perform $\gamma-\gamma'+1$ independent sequences of tests of length $T_{\text{len}}''$, with each item being randomly placed in one of these $T_{\text{len}}''$ tests. Conditioned on the high probability event that $|\mathcal{PD}^{(\gamma')}|=O(k(n/k)^{1/\gamma'})$, we study the required $T_{\text{len}}''$ for a vanishing error probability. Specifically, we upper bound the error probability by $O(\beta_n)$ for some decaying function $\beta_n\rightarrow0$ as $n\rightarrow\infty$. 

For a given non-defective item and a given sequence of $T_{\text{len}}''$ tests, the probability of colliding with any defective item is at most $k/T_{\text{len}}''$ by the same argument as Lemma \ref{lem:gamma_prob_of_nondef_node_being_in_pos_test}. Due to the $\gamma-\gamma'+1$ independent repetitions, the probability of a given non-defective item appearing only in positive tests is at most $(k/T_{\text{len}}'')^{\gamma-\gamma'+1}$. By a union bound over $O(k(n/k)^{1/\gamma'})$ non-defective items at the final level, we find that the estimate $\widehat{\mathcal{S}}$ differs from $\mathcal{S}$ with (conditional) probability $O\big(k(n/k)^{1/\gamma'}(k/T_{\text{len}}'')^{\gamma-\gamma'+1}\big)$. The error probability is thus upper bounded by $O(\beta_n)$ provided that
\begin{align}
    &k\Big(\frac{n}{k}\Big)^{\frac{1}{\gamma'}}\Big(\frac{k}{T_{\text{len}}''}\Big)^{\gamma-\gamma'+1}\leq\beta_n \\
    \iff &T_{\text{len}}''\geq k\Big(\frac{k}{\beta_n}\Big)^{\frac{1}{\gamma-\gamma'+1}}\Big(\frac{n}{k}\Big)^{\frac{1}{\gamma'(\gamma-\gamma'+1)}}.
\end{align}
Hence, we set $T_{\text{len}}''=k(k/\beta_n)^{\frac{1}{\gamma-\gamma'+1}}(n/k)^{\frac{1}{\gamma'(\gamma-\gamma'+1)}}$.

\subsection{Number of Tests, Error Probability, and Decoding Time}

\begin{itemize}
    \item \textbf{Number of tests:} For $l=1,\dots,\gamma'-1$, we used a total of $n/M+ C(\gamma'-3)k(n/k)^{1/\gamma'}+\gamma'k(n/k)^{1/\gamma'}$ tests, which scales as $O\big(\gamma'k(n/k)^{1/\gamma'}\big)$ by substituting $M=(n/k)^{\frac{\gamma'-1}{\gamma'}}$ and $C = O(1)$. For the final level, we used $(\gamma-\gamma'+1)T_{\text{len}}''=O\big(\gamma k(k/\beta_n)^{\frac{1}{\gamma-\gamma'+1}}(n/k)^{\frac{1}{\gamma'(\gamma-\gamma'+1)}}\big)$ tests, due to the fact that  $T_{\text{len}}''=k(k/\beta_n)^{\frac{1}{\gamma-\gamma'+1}}(n/k)^{\frac{1}{\gamma'(\gamma-\gamma'+1)}}$. Combining these, we obtain
    \begin{align}
        T&=O\bigg(\gamma k\max\bigg\{\Big(\frac{n}{k}\Big)^{\frac{1}{\gamma'}}
        ,\Big(\frac{k}{\beta_n}\Big)^{\frac{1}{\gamma-\gamma'+1}}\Big(\frac{n}{k}\Big)^{\frac{1}{\gamma'(\gamma-\gamma'+1)}}\bigg\}\bigg). \label{eq:splitting_algo__upper_bound}
    \end{align}
    \item \textbf{Error probability:} The concentration bound on $N_{\text{total}}$ (see Lemma \ref{lem:N_total_high_prob_bound_gamma}) holds with probability $1-e^{-\Omega(\gamma'k)}$, and at level $l=\gamma'-1$, we incur $e^{-\Omega(k)}$ error probability. Furthermore, the final stage incurs $O(\beta_n)$ error (conditional) probability. In total, we incur $\beta_n+e^{-\Omega(\gamma'k)}+e^{-\Omega(k)}=O(\beta_n)+e^{-\Omega(k)}$ error probability.
    \item \textbf{Decoding time:} We claim that conditioned on the high-probability events above (in particular, $N_{\text{total}}=O\big(\gamma'k(n/k)^{1/\gamma'}\big)$), the decoding time is $O\big(\gamma k(n/k)^{1/\gamma'}\big)$. Since we consider the word-RAM model, it takes constant time to check whether each defective node or non-defective node is in a positive or negative test. First considering the levels $l=2,\dotsc,\gamma'-1$, we reached $N_{\text{total}}=O\big(\gamma'k(n/k)^{1/\gamma'}\big)$ non-defective nodes and $O(\gamma'k)$ defective nodes, which leads to a total of $O\big(\gamma'k(n/k)^{1/\gamma'}\big)$ decoding time.  At level $l=1$, we iterate through $\frac{n}{M} = O\big(k(n/k)^{1/\gamma'}\big)$ nodes, and at the final level $l=\gamma'$, for each of the $O\big(k(n/k)^{1/\gamma'}\big)$ relevant leaf nodes, we perform $\gamma-\gamma'+1=O(\gamma)$ checks of tests for a total time of $O\big(\gamma k(n/k)^{1/\gamma'}\big)$. Combining these terms, we deduce the desired claim.
    % \item \textbf{Storage:} At $l=1$, we need to store $n/M=k(n/k)^{1/\gamma'}$ integers in $\big\{1,\dots,k(n/k)^{1/\gamma'}\big\}$, or $O\big(k(n/k)^{1/\gamma'}\allowbreak\log\big(k(n/k)^{1/\gamma'}\big)\big)$ bits. For any level $l\in\{2,\dots,\gamma'-2\}$, we need to store $(n/M)M^{\frac{l-1}{\gamma'-1}}=k(n/k)^{l/\gamma'}$ integers in $\big\{1,\dots,Ck(n/k)^{1/\gamma'}\big\}$. Summing these together, we obtain
    % \begin{align}
    %     \text{\#integers}&=k\sum_{l=1}^{\gamma'-2}\Big(\frac{n}{k}\Big)^{\frac{l}{\gamma'}}
    %     \stackrel{(a)}{=}k\Big(\frac{n}{k}\Big)^{\frac{1}{\gamma'}}\frac{1-(n/k)^{\frac{\gamma'-2}{\gamma'}}}{1-(n/k)^{1/\gamma'}}
    %     =O\bigg(k\Big(\frac{n}{k}\Big)^{\frac{\gamma'-2}{\gamma'}}\bigg)
    %     =O\bigg(n\Big(\frac{n}{k}\Big)^{-\frac{2}{\gamma'}}\bigg),
    % \end{align}
    % where (a) is by the geometric series formula. This is equivalent to $O\big(n(n/k)^{-2/\gamma'}\log\big(k(n/k)^{-1/\gamma'}\big)\big)$ bits. In addition, at level $l=\gamma'-1$, we need to store $k(n/k)^{\frac{\gamma'-1}{\gamma'}}=n(n/k)^{-1/\gamma'}$ integers in $\big\{1,\dots,\gamma'k\big(\frac{n}{k}\big)^{1/\gamma'}\big\}$, or $O\big(n(n/k)^{-1/\gamma'}\log\big(\gamma'k(n/k)^{1/\gamma'}\big)\big)$ bits. At the final level $l=\gamma'$, we have $n$ singletons, each participating in $\gamma-\gamma'+1=O(\gamma)$ tests. This requires $O(\gamma n)$ integers in $\{1,\dots,T''_{\text{len}}\}$, or $O(\gamma n\log T''_{\text{len}})$ bits. In addition, under the high probability events $N_{\text{total}}=O\big(k(n/k)^{1/\gamma'}\big)$, $|\mathcal{PD}^{(\gamma'-1)}|=O(k)$, and $|\mathcal{PD}^{(\gamma')}|=O\big(k(n/k)^{1/\gamma'}\big)$, the storage of the possibly defective set requires $O\big(k(n/k)^{1/\gamma'}\big)$ integers, or $O\big(k(n/k)^{1/\gamma'}\log n\big)$ bits. In total, the number of bits we require is
    % \begin{align}
    %     &O\bigg(k\Big(\frac{n}{k}\Big)^{\frac{1}{\gamma'}}\log n
    %     +n\Big(\frac{n}{k}\Big)^{-\frac{1}{\gamma'}}\log\bigg(\gamma'k\Big(\frac{n}{k}\Big)^{\frac{1}{\gamma'}}\bigg)
    %     +\gamma n\log T''_{\text{len}}\bigg) \\
    %     &\qquad=
    %     O\bigg(k\Big(\frac{n}{k}\Big)^{\frac{1}{\gamma'}}\log n
    %     +n\Big(\frac{n}{k}\Big)^{-\frac{1}{\gamma'}}\log\bigg(\gamma'k\Big(\frac{n}{k}\Big)^{\frac{1}{\gamma'}}\bigg)
    %     +\gamma n\log\bigg(k\Big(\frac{k}{\beta_n}\Big)^{\frac{1}{\gamma-\gamma'+1}}\Big(\frac{n}{k}\Big)^{\frac{1}{\gamma'(\gamma-\gamma'+1)}}\bigg)\bigg),
    % \end{align}
    % where we substitute $T_{\text{len}}''=k(k/\beta_n)^{\frac{1}{\gamma-\gamma'+1}}(n/k)^{\frac{1}{\gamma'(\gamma-\gamma'+1)}}$.
\end{itemize}

\subsection{Note on Optimizing $\gamma'$} \label{sec:convex}

We note that the function $f(\gamma') = \max\big\{\frac{1-\theta}{\gamma'},\frac{\theta}{\gamma-\gamma'+1}+\frac{1-\theta}{\gamma'(\gamma-\gamma'+1)}\big\}$ is convex on $[3,\gamma]$; this is easily proved by computing the second derivative of each term in $\max\{.,.\}$. 
% which we denote as $f(\gamma')$ and $g(\gamma')$ for the first and second term respectively. This gives
%\begin{align}
%    f''(\gamma')&=\frac{2(1-\theta)}{(\gamma')^3}>0 \\
%    g''(\gamma')&=\frac{2\theta}{(\gamma-\gamma'+1)^3}+\frac{2(1-\theta)(\gamma-2\gamma'+1)^2}{(\gamma'(\gamma-\gamma'+1))^3}+\frac{2(1-\theta)}{(\gamma'(\gamma-\gamma'+1))^2}>0,
%\end{align}
%for $\gamma'\in[1,\gamma]$. 
Since a convex function is monotone on either side of its minimum (in this case $(1-\theta)\gamma$), it follows that the optimal choice of $\gamma'$ is given by
\begin{align}
    \gamma'&=\argmin\limits_{\gamma'\in\{3,\dots,\gamma\}}\Big(\gamma k\max\Big\{n^{\frac{1-\theta}{\gamma'}},
    n^{\frac{\theta}{\gamma-\gamma'+1}+\frac{1-\theta}{\gamma'(\gamma-\gamma'+1)}}\Big\}\Big) \\
    &=
    \begin{cases}
    3 &\text{if $(1-\theta)\gamma<3$} \\
    \argmin\limits_{\gamma'\in\{\lfloor(1-\theta)\gamma\rfloor,\lceil(1-\theta)\gamma\rceil\}}\bigg(\max\bigg\{\frac{1-\theta}{\gamma'},\frac{\theta}{\gamma-\gamma'+1}+\frac{1-\theta}{\gamma'(\gamma-\gamma'+1)}\bigg\}\bigg) &\text{otherwise.} \label{eq:gamma'}
    \end{cases}
\end{align}
That is, we can simply evaluate the objective for three values of $\gamma'$, rather than all values.

\section{Proof of Theorem \ref{thm:rho_main_theorem} (Size-Constrained Tests)} \label{sec:rho_algo_analysis}

We start at level $l=0$ (see Figure \ref{fig:size_constraint_diagram}), where we note that the probability of a non-defective node being placed in a positive test is zero because each node is placed in its own individual test.  For subsequent levels, we proceed with the following lemma.

\begin{lemma} \label{lem:rho_prob_of_nondef_node_being_in_pos_test} {\textup{(Probabilities of Non-Defectives Being in Positive Tests)}}
Under the above test design, for any given level $l=1,\dots,C$ and any given iteration indexed by $\{1,\dotsc,N\}$, each non-defective node has probability at most $k\rho/n$ of being placed in a positive test.
\end{lemma} 

\begin{proof}
At any given iteration of level $l$, the probability that a non-defective node $u$ collides (i.e., is in the same test) with a given defective node $v$ is
\begin{align}
    \frac{\text{\#matrices with $u$ \& $v$ in test $1$}}{\text{\#matrices with $v$ in test $1$}}
    &\stackrel{(a)}{=}\frac{{\frac{n}{\rho^{1-l/C}}-2\choose\rho^{l/C}-2}\prod_{i=1}^{n/\rho-1}{\frac{n}{\rho^{1-l/C}}-i\rho^{l/C}\choose\rho^{l/C}}}
    {{\frac{n}{\rho^{1-l/C}}-1\choose\rho^{l/C}-1}\prod_{i=1}^{n/\rho-1}{\frac{n}{\rho^{1-l/C}}-i\rho^{l/C}\choose\rho^{l/C}}} \\
    &=\frac{{\frac{n}{\rho^{1-l/C}}-2\choose\rho^{l/C}-2}}{{\frac{n}{\rho^{1-l/C}}-1\choose\rho^{l/C}-1}}
    \stackrel{(b)}{=}\frac{\rho^{l/C}-1}{\frac{n}{\rho^{1-l/C}}-1} \\
    &=\frac{\rho}{n}\bigg(\frac{\rho^{l/C}-1}{\rho^{l/C}-\rho/n}\bigg)
    \stackrel{(c)}{\leq}\frac{\rho}{n},
\end{align}
where:
\begin{itemize}
    \item (a) follows by considering the rows of the matrix $\mathsf{X}_l$ (of size $\frac{n}{\rho} \times \frac{n}{\rho^{1-l/C}}$, column weight one, and row weight $\rho^{l/C}$) sequentially to count the number of possible matrices. For the numerator, we start with the first row, where $u$ and $v$ collide.  The number of ways to fill this row (i.e., assigning items to this test) is the first term in the numerator. For the remaining $n/\rho-1$ rows, in any particular order, the number of ways to fill those rows (while maintaining column weights of one) is represented by the second product term. The same analysis is then repeated for the denominator.
    \item (b) follows by expanding the binomial coefficient in terms of factorials, and then simplifying.
    \item (c) follows from the fact that $\rho/n\leq1$.
\end{itemize}
Since there are at most $k$ defective nodes, by the union bound, we find that the probability that a non-defective node collides with any defective node is at most $k\rho/n$.
\end{proof}

The following technical lemma will also be used on several occasions.

\begin{lemma} \label{lem:asymp}
    For any $k$ and $\rho$ satisfying $k=O\big(n^{1-\epsilon_1}\big)$ for some $\epsilon_1\in(0,1]$ and $\rho=O\big((n/k)^{1-\epsilon_2}\big)$ for some $\epsilon_2 \in (0,1]$, we have the following:
    \begin{itemize}
        \item For sufficiently large $C$, we have $\frac{k\rho^{1/C}}{n/\rho} = n^{-\Omega(1)}$;
        \item For any $\zeta_1 > 0$ , we have for sufficiently large $C$ and $N$ that $\rho^{1/C}\big(\frac{k\rho}{n}\big)^N = O(n^{-\zeta_1})$.
    \end{itemize}
    In addition, if $\rho = O(1)$, then the same holds true for any fixed $C>0$, only requiring $N$ to be sufficiently large in the second part.
\end{lemma}
\begin{proof}
    For the first part, we write
    \begin{align}
        \frac{n/\rho}{k\rho^{1/C}}&=\frac{n/k}{\rho^{1+1/C}}
        \stackrel{(a)}{=}\Omega\bigg(\Big(\frac{n}{k}\Big)^{\epsilon_2-\frac{1-\epsilon_2}{C}}\bigg)
        \stackrel{(b)}{=}\Omega\big(n^{\epsilon_1(\epsilon_2-\frac{1-\epsilon_2}{C})}\big), \label{eq:k*rho^(1/C)<<n/rho_proof}
    \end{align}
    where (a) is by substituting $\rho=O\big((n/k)^{1-\epsilon_2}\big)$ and simplifying, and (b) is by substituting $k=O\big(n^{1-\epsilon_1}\big)$ and simplifying. Note that the power is positive for sufficiently large $C$.

    For the second part, we write
    \begin{align}
        \rho^{1/C}\Big(\frac{k\rho}{n}\Big)^{N}
        &\stackrel{(a)}{=} O\bigg(\Big(\frac{n}{k}\Big)^{\frac{1-\epsilon_2}{C}-\epsilon_2N}\bigg)
        \stackrel{(b)}{=}O\big(n^{\epsilon_1(\frac{1-\epsilon_2}{C}-\epsilon_2N)}\big),
    \end{align}
    where (a) is by substituting $\rho=O\big((n/k)^{1-\epsilon_2}\big)$ and simplifying, and (b) is by substituting $k=O\big(n^{1-\epsilon_1}\big)$ and simplifying.  Note that the power can be made arbitrarily negative by choosing $N$ and $C$ sufficiently large.
    
    For the final part regarding $\rho = O(1)$, we simply note that the two claims reduce to (i) $\frac{k}{n} = n^{-\Omega(1)}$, and (ii) $\big(\frac{k}{n}\big)^{N} = O(n^{-\zeta_1})$ for sufficiently large $N$.  Both of these are true since $k = O(n^{1-\epsilon_1})$.
\end{proof}

We will show that throughout the course of the algorithm, for levels $l=1,\dots,C$, the size of the possibly defective set $\mathcal{PD}^{(l)}$ remains at $O\big(k\rho^{1/C}\big)$ with high probability.  We show this using an induction argument.  

\subsection{Analysis of Levels $l=1,\dots,C-1$}

For the base case $l=1$, we start by looking at the preceding level $l=0$. Each node at level $l=0$ is allocated to an individual test, which implies that all nodes in $l=0$ are identified correctly. Hence, only the children of the defective nodes in $l=0$ are ``explored'' further in $l=1$. Since the number of defective nodes in $l=0$ is at most $k$ and each node has $\rho^{1/C}$ children, we have $|\mathcal{PD}^{(1)}|\leq k\rho^{1/C}$. 

Consider a non-defective node indexed by $i$ at a given level $l > 1$ having $k'\leq k$ defective nodes, and let $A_i$ be the indicator random variable of that non-defective node colliding with at least one defective node in all of its $N$ repetitions. The dependence of these quantities on $l$ is left implicit. We condition on all of the test placements performed at the earlier levels, writing $\mathbb{E}_l[\cdot]$ for the conditional expectation. By the inductive hypothesis, we have $|\mathcal{PD}^{(l)}|=O\big(k\rho^{1/C}\big)$.

\begin{lemma} \label{lem:average_bound_rho_case}
Under the preceding setup and definitions, if $|\mathcal{PD}^{(l)}|=O\big(k\rho^{1/C}\big)$, then we have
\begin{align}
    \E_l\Big[\sum_iA_i\Big]=O\bigg(k\rho^{1/C}\cdot\Big(\frac{k\rho}{n}\Big)^{N}\bigg).
\end{align}
\end{lemma}

\begin{proof}
From Lemma \ref{lem:rho_prob_of_nondef_node_being_in_pos_test}, we know that a given non-defective item $i$ has a probability at most $k\rho/n$ of being placed in a positive test. Since we used $N$ independent test design matrices $\mathsf{X}_l$ to assign $i$ to $N$ tests, we have $\mathbb{P}_l[A_i]\leq(k\rho/n)^{N}$. Hence, we have
\begin{align}
    \E_l\Big[\sum_iA_i\Big]
    &=\sum_i\E_l[A_i]
    =\sum_i\mathbb{P}_l[A_i = 1]
    \leq\sum_i\Big(\frac{k\rho}{n}\Big)^{N}
    =O\bigg(k\rho^{1/C}\cdot\Big(\frac{k\rho}{n}\Big)^{N}\bigg),
\end{align}
where we used the linearity of expectation and the fact that $|\mathcal{PD}^{(l)}|=O\big(k\rho^{1/C}\big)$.
\end{proof}

\begin{lemma}
For any constant $\zeta_1>0$, there exist choices of $C$ and $N$ such that the following holds: Conditioned on the $l$-th level having $|\mathcal{PD}^{(l)}|=O\big(k\rho^{1/C}\big)$, the same is true at the $(l+1)$-th level with probability $1-O\big(n^{-\zeta_1}\big)$.
\end{lemma}

\begin{proof}
Among the possibly defective nodes at the $l$-th level, at most $k$ are defective, amounting to at most $k\rho^{1/C}$ children at the next level. Furthermore, by Lemma \ref{lem:average_bound_rho_case} and Markov's inequality, at most $k$ non-defective nodes are marked as possibly defective, with probability at least
\begin{align}
    1-O\bigg(\rho^{1/C}\Big(\frac{k\rho}{n}\Big)^{N}\bigg) = 1 - O(n^{-\zeta_1}), 
\end{align}
where the equality holds for any $\zeta_1 > 0$ by suitable choices of $C$ and $N$ (see Lemma \ref{lem:asymp}).
Thus, this also amounts to at most $k\rho^{1/C}$ additional children at the next level. Summing these together, we have $|\mathcal{PD}^{(l+1)}| \le 2 k\rho^{1/C}$, with probability at least $1-O\big(n^{-\zeta_1}\big)$.
\end{proof}

By induction, for any given level $l$, we have $|\mathcal{PD}^{(l)}|=O\big(k\rho^{1/C}\big)$ with conditional probability at least $1-O\big(n^{-\zeta_1}\big)$. Taking a union bound over all $C$ levels (with $C = O(1)$), the same follows for all levels simultaneously with probability at least $1-O\big(n^{-\zeta_1}\big)$.

\subsection{Analysis of the Final Level}

Recall that at the final level, we perform $C'n/\rho$ tests. We study the error probability conditioned on the high-probability event $|\mathcal{PD}^{(C)}|=O\big(k\rho^{1/C}\big)$.

For a given non-defective item in a single iteration of the $C'$ independent iterations of tests, by Lemma \ref{lem:rho_prob_of_nondef_node_being_in_pos_test}, the probability of appearing in a positive test is at most $k\rho/n$. Since the non-defective item participates in $C'$ independent tests, the probability of it appearing only in positive tests is $(k\rho/n)^{C'}$. By a union bound over the $O\big(k\rho^{1/C}\big)$ non-defective singletons at the final level, the error probability is upper bounded by
\begin{align}
    O\bigg(k\rho^{1/C}\Big(\frac{k\rho}{n}\Big)^{C'}\bigg) = O(n^{-\zeta_2}),
    % &\stackrel{(a)}{=}O\bigg(k\Big(\frac{n}{k}\Big)^{\frac{1-\epsilon_2}{C}-C'\epsilon_2}\bigg)
    % \stackrel{(b)}{=}O\big(n^{1-\epsilon_1+\epsilon_1(\frac{1-\epsilon_2}{C}-\epsilon_2C')}\big), \label{eq:err_prob_upp_bound}
\end{align}
where the equality holds for any $\zeta_2 > 0$ and suitably-chosen $C$ and $C'$ due to Lemma \ref{lem:asymp} (with $C'$ replacing $N$).

% where (a) is by substituting $\rho=O\big((n/k)^{1-\epsilon_2}\big)$ and simplifying, and (b) is by substituting $k=O\big(n^{1-\epsilon_1}\big)$ and simplifying. Note that our error probability is in $O\big(n^{-\zeta_2}\big)=o(1)$, where $\zeta_2=\epsilon_1\big(\epsilon_2C'-\frac{1-\epsilon_2}{C}\big)-1+\epsilon_1$, by choosing sufficiently large $C$ and $C'$.

\subsection{Number of Tests, Error Probability, and Decoding Time}

\begin{itemize}
    \item \textbf{Number of tests:} We used $CNn/\rho$ tests in the first $C$ levels and $C'n/\rho$ tests in the final level, which sums up to $CNn/\rho+C'n/\rho=O(n/\rho)$.
    \item \textbf{Error probability:} For each level $l$, we have $|\mathcal{PD}^{(l)}|=O\big(k\rho^{1/C}\big)$ with probability $1-O\big(n^{-\zeta_1}\big)$. Furthermore, the final level incurs $O\big(n^{-\zeta_2}\big)$ error probability. This gives us a total error probability of $O\big(n^{-\zeta_1}+n^{-\zeta_2}\big)=O\big(n^{-\zeta}\big)$, where $\zeta=\min\{\zeta_1,\zeta_2\}$.  Since we allowed $\zeta_1$ and $\zeta_2$ to be arbitrarily large, the same holds for $\zeta$.
    \item \textbf{Decoding time:} The decoding time is dominated by the test outcome checks in our decoding procedure. For the first level $l=0$, we have $|\mathcal{PD}^{(0)}|=n/\rho$, which coincides with the total number of test outcome checks. For the remaining $C-1$ levels $l\in\{1,\dots,C-1\}$, we considered a total of $O\big(k\rho^{1/C}\big)$ possibly defective nodes w.h.p.,\footnote{Here and subsequently, we write {\em with high probability} (w.h.p.) to mean holding under the high-probability events used in proving that the algorithm succeeds.} and for each possibly defective item, we conducted $N$ test outcome checks. This gives us total number of $O\big(k\rho^{1/C}\big)$ test outcome checks. At the final level, for each of the $O\big(k\rho^{1/C}\big)$ relevant leaf nodes, we perform $C'$ test outcome checks for a total time of $O\big(k\rho^{1/C}\big)$. Summing these gives $O(n/\rho)$, since $O\big(k\rho^{1/C}\big)=o(n/\rho)$ for a sufficiently large $C$ (refer to \eqref{eq:k*rho^(1/C)<<n/rho_proof}). Since it takes $O(1)$ time to check whether each node is in a positive or negative test, we get a total decoding time of $O(n/\rho)$.
    % \item \textbf{Storage:} At $l=0$, we need to store $n/\rho$ integers. For $l\in\{1,\dots,C-1\}$, we need to store $N\frac{n}{\rho^{1-l/C}}$ integers per level, which indicate the tests associated with each of the $\frac{n}{\rho^{1-l/C}}$ nodes. Hence, excluding the last level, we need to store
    % \begin{align}
    %     n/\rho+\sum_{l=1}^{C-1}N\Big(\frac{n}{\rho}\Big)(\rho^{l/C})
    %     &=\frac{n}{\rho}+N\Big(\frac{n}{\rho}\Big)(\rho^{1/C})\Big(\frac{\rho^{1-1/C}-1}{\rho^{1/C}-1}\Big)
    %     =O\Big(\frac{n}{\rho^{1/C}}\Big),
    % \end{align}
    % integers in $\{1,\dots,n/\rho\}$, or $O\big(\big(n/\rho^{1/C}\big)\log(n/\rho)\big)=O\big(\big(n/\rho^{1/C}\big)\log n\big)$ bits. Similarly, at the final level, we have $n$ singletons and each participates in $C'$ tests. This amounts to storing $O(n)$ integers, or $O(n\log(n/\rho))=O(n\log n)$ bits. In addition, under the high probability event that all levels $l$ have $|\mathcal{PD}^{(l)}|=O(k\rho^{1/C})$, the storage of the possibly defective set requires $O(k\rho^{1/C})$ integers, or $O(k\rho^{1/C}\log n)$ bits. The total storage is $O(n\log n)$ bits.
\end{itemize}

\section{Proof of Theorem \ref{thm:noisy_main_theorem} (Noisy Setting)} \label{sec:noisy_algo_analysis}

The outline of the analysis is as follows:
\begin{itemize}
    \item We first consider levels $l=\log_2k,\dots,\log_2n-1$, and bound the probability that any node among three kinds---non-defective nodes at level $l_{\text{min}} = \log_2 k$, defective nodes, and non-defective child nodes of defective nodes---are identified wrongly. Note that we do not have to consider other nodes, because if none of the nodes of these three kinds are identified wrongly, then the algorithm would not explore any of the other nodes when decoding.
    \item Conditioned on the correct identification of nodes of these three kinds, we consider the final level $l=\log_2n$ and provide a bound for its error probability.
\end{itemize}

\subsection{Analysis of Levels $l=\log_2k,\dots,\log_2n-1$}

We consider defective and non-defective nodes separately.

\textbf{Defective nodes:} Recall the notions of intermediate labels and final labels from Section \ref{sec:noisy_algo_descrip}.  Let $p_{\text{int}}^{(\text{d})}$ (respectively, $p_{\text{final}}^{(\text{d})}$) be the probability that the intermediate label (respectively, final label) of a given defective node is flipped from a one to a zero. Note that these may vary from node to node, but we will give upper bounds that hold uniformly.

For a given defective node, there are only two possible situations for each test it is in: A positive outcome due to no flip, or a negative test outcome due to a $1\rightarrow0$ flip. Hence, the number of negative tests that a given defective node participates in (i.e., the outcome is flipped) is distributed as $\text{Binomial}(N,p)$. By the majority voting of $N$ test outcomes at a given level, $p_{\text{int}}^{(\text{d})}$ is upper bounded by the probability that a given defective node participates in at least $N/2$ negative tests. Applying Hoeffding's inequality, we obtain
\begin{align}
    p_{\text{int}}^{(\text{d})}&\leq\exp\bigg(-2N\Big(\frac{1}{2}-p\Big)^2\bigg).
\end{align}
At this point, we introduce the variable $t$ appearing in the theorem statement. Since $\exp\big(-2N(1/2-p)^2\big)\leq \frac{2^{-2t}}{4}\Leftrightarrow N\geq \frac{2t\log2+\log4}{2(1/2-p)^2}$, we find that choosing $N\geq \frac{2t\log2+\log4}{2(1/2-p)^2}$ ensures that
\begin{align}
    p_{\text{int}}^{(\text{d})}\leq\frac{2^{-2t}}{4}. \label{eq:rho_int_def_upperbound}
\end{align}

For the case that $l\leq\log_2n-r$, we consider the length-$r$ paths below the defective node. The defective node will be labeled as negative if all $2^r$ paths below it have at least $r/2$ negative intermediate labels. The probability of this event is upper bounded by the probability that one particular \textit{defective} path (i.e., every node along the path is defective) has at least $r/2$ negative intermediate labels, which is at most
\begin{align}
    {r\choose r/2}\big(p_{\text{int}}^{(\text{d})}\big)^{r/2}\leq\big(4p_{\text{int}}^{(\text{d})}\big)^{r/2}, \label{eq:p_final_bound}
\end{align}
where the left hand side (LHS) is by the union bound, and the right hand side (RHS) is by ${r\choose r/2}\leq2^r$.
This gives $p_{\text{final}}^{(\text{d})}\leq\big(4p_{\text{int}}^{(\text{d})}\big)^{r/2}$, and substituting \eqref{eq:rho_int_def_upperbound} gives $p_{\text{final}}^{(\text{d})}\leq2^{-tr}$. 

For the case that $l>\log_2n-r$ (i.e., there are less than $r$ levels below the given node), the probability of the (single) defective path having at least $r/2$ negative intermediate labels remains unchanged, and hence, the preceding bound $p_{\text{final}}^{(\text{d})}\leq2^{-tr}$ still holds. Note that this step requires $C'\log_2n\geq r$ in order to have enough intermediate labels per node in the final level to ``pad'' paths of length less than $r$ (see Section \ref{sec:noisy_algo_descrip}), and we will later set $C'$ and $r$ to ensure  this.

\textbf{Non-defective nodes:} Let $p_{\text{int}}^{(\text{nd})}$ (respectively, $p_{\text{final}}^{(\text{nd})}$) be the probability that the intermediate label (respectively, final label) of a given non-defective node is flipped from a zero to a one. Again, these may vary from node to node, but we will give upper bounds that hold uniformly. For a given non-defective node, there are four possible situations for each test: A negative outcome with no flip (i.e., no defectives), a negative outcome due to a $1\rightarrow0$ flip (i.e., at least one defective), a positive outcome with no flip (i.e., at least one defective), and a positive outcome due to a $0\rightarrow1$ flip (i.e., no defectives).

Focusing on one test sequence of length $T_{\text{len}} = Ck$ for now, let $A$ be the event that a given non-defective node participates in a positive test, and let $B$ be the event that the given node's test contains no defective item. We have
\begin{align}
    \mathbb{P}[A]
    &=\mathbb{P}[B]\cdot\mathbb{P}[A|B]+\mathbb{P}[\neg B]\cdot\mathbb{P}[A|\neg B] \\
    &\stackrel{(a)}{\leq}\mathbb{P}[B]\cdot p+\frac{1}{C}(1-p) \\
    &\leq p+\frac{1}{C}, \label{eq:upperbound_of_P[A]}
\end{align}
where (a) holds since the probability of being in the same test as a given defective node is $1/T_{\rm len} = 1/(Ck)$, and thus the union bound over $k$ defective nodes gives $\mathbb{P}[\neg B] \le 1/C$.

Equation \eqref{eq:upperbound_of_P[A]} implies that for a given non-defective node, the number of positive tests that it participates in (out of $N$ tests in total) is stochastically dominated by $\text{Binomial}(N,p+1/C)$. Recalling that $p_{\text{int}}^{(\text{nd})}$ is the probability that a given non-defective node participates in at least $N/2$ positive tests, Hoeffding's inequality gives
\begin{align}
    p_{\text{int}}^{(\text{nd})}&\leq\exp\bigg(-2N\Big(\frac{1}{2}-p-\frac{1}{C}\Big)^2\bigg), \label{eq:rho_int_nondef_upperbound0}
\end{align}
where we require $1/2-p-1/C>0\Leftrightarrow C>2/(1-2p)$. Hence, we set $C=\lceil2/(1-2p)\rceil+1$. Since $\exp\big(-2N(1/2-p-1/C)^2\big)\leq \frac{2^{-2t}}{16} \Leftrightarrow N\geq \frac{2t\log2+\log16}{2(1/2-p-1/C)^2}$, we find that choosing $N\geq \frac{2t\log2+\log16}{2(1/2-p-1/C)^2}$ ensures that
\begin{align}
    p_{\text{int}}^{(\text{nd})}\leq\frac{2^{-2t}}{16}. \label{eq:rho_int_nondef_upperbound}
\end{align}

For the case that $l\leq\log_2n-r$, we look at the length-$r$ path below the non-defective node. The non-defective node will be labeled as positive if any of the $2^r$ paths below it has at least $r/2$ positive intermediate labels. By a union bound over all $2^r$ paths, this probability is upper bounded as follows, similar to \eqref{eq:p_final_bound}:
\begin{align}
    2^r{r\choose r/2}\big(p_{\text{int}}^{(\text{nd})}\big)^{r/2}
    \leq2^r\big(4p_{\text{int}}^{(\text{nd})}\big)^{r/2}
    \leq\big(16p_{\text{int}}^{(\text{nd})}\big)^{r/2}.
\end{align}
This gives $p_{\text{final}}^{(\text{nd})}\leq\big(16p_{\text{int}}^{(\text{nd})}\big)^{r/2}$, and substituting \eqref{eq:rho_int_nondef_upperbound} gives $p_{\text{final}}^{(\text{nd})}\leq2^{-tr}$.

Similarly to the defective nodes handled above, the case that $l>\log_2n-r$ follows essentially unchanged; while the above analysis has an additional union bound over $2^r$ paths, the number of paths when $l > \log_2n - r$ only gets smaller.  Hence, the preceding bound on $p_{\text{final}}^{(\text{nd})}\leq2^{-tr}$ also holds in this case.

% For the case that $l>\log_2n-r$ (i.e., there are less than $r$ levels below the node), the probability of any path having more than $r/2$ positive intermediate labels remains unchanged. In addition, the number of paths we consider is less than $2^r$ (see Figure \ref{fig:r_paths}). Hence, our previous bound on $p_{\text{final}}^{(\text{d})}\leq2^{-tr}$ still holds.

\textbf{Combining the defective and non-defective cases:} Taking the more stringent requirement on $N$ in the above two cases, we set
\begin{align}
    N&=\bigg\lceil\frac{2t\log2+\log16}{2(1/2-p-1/C)^2}\bigg\rceil, \label{eq:Nchoice}
\end{align}
and we observe that regardless of the defectivity of a given node, the probability of the node's final label being wrong is at most $2^{-tr}$. 

Next, we upper bound the probability that any node among three groups---non-defective nodes at level $l_{\text{min}}$, defective nodes, and child nodes of defective nodes---is identified wrongly.  Note that if all such nodes are identified correctly, then the branching is only ever continued for defective nodes, and it follows that at most $2k$ nodes remain at the final level (analyzed below).

Since there are $\log_2(n/k)$ levels and $k$ defectives, the number of non-defective children nodes of defective nodes is at most $k\log_2(n/k)$, and the number of non-defective nodes at level $l_{\text{min}}$ is at most $k$. Summing these up, we have at most $2k\log_2(n/k)+k$ nodes. By taking the union bound over all $2k\log_2(n/k)+k$ nodes, the probability of making an error in identifying any node in the mentioned three groups is at most $2^{-tr}(2k\log_2(n/k)+k)$. This can be upper bounded by a given target value $\beta_n$ (approaching zero as $n\rightarrow\infty$), provided that
\begin{align}
    2^{-tr}\bigg(2k\log_2\Big(\frac{n}{k}\Big)+k\bigg)\leq\beta_n, \label{eq:beta_n_eq}
\end{align}
which rearranges to give
\begin{align}
    r&\geq\frac{1}{t}\log_2\bigg(\frac{2k}{\beta_n}\log_2\Big(\frac{n}{k}\Big)+\frac{k}{\beta_n}\bigg).
\end{align}
By choosing
\begin{align}
    r=\bigg\lceil\frac{1}{t}\log_2\bigg(\frac{3k}{\beta_n}\log_2\Big(\frac{n}{k}\Big)\bigg)\bigg\rceil,
\end{align}
we deduce that the probability of any wrong decision is upper bounded by $\beta_n$.

\subsection{Analysis of the Final Level}

% We condition on the event that all non-defective nodes at $l_{\text{min}}$, all nodes in the defective tree, and all children nodes of all defective nodes, are correctly identified. From \eqref{eq:beta_n_eq}, we see that this occurs with probability $1-\beta_n$. Under this condition, we have $|\mathcal{PD}^{(\log_2n)}|\leq2k$, which implies that the number of non-defectives in $\mathcal{PD}^{(\log_2n)}$ is at most $k$. In addition, we need $C'\log_2n\geq r$ to have enough intermediate labels per node in the final level to ``pad'' paths of length less than $r$ (see Figure \ref{fig:noisy_algo_diag}).

Recall from the analyses of \eqref{eq:rho_int_def_upperbound} and \eqref{eq:rho_int_nondef_upperbound} that given our choice of $N$ in \eqref{eq:Nchoice}, regardless of the defectivity of a given node, the probability of a wrong intermediate label---let us call this $p_{\text{int}}$---is at most $2^{-2t}/4$. To get the final label of each node (singleton), we conduct a majority voting of $C'\log_2n$ intermediate labels. Hence, a given node is labeled wrongly when it has at least $(C'\log_2n)/2$ wrong intermediate labels. This gives the following upper bound on the probability of a wrong final label, denoted by $p_{\text{final}}$:
\begin{align}
    p_{\text{final}}
    &\leq{C'\log_2n\choose (C'\log_2n)/2}\big(p_{\text{int}}\big)^{(C'\log_2n)/2}
    \stackrel{(a)}{\leq}\big(4p_{\text{int}}\big)^{(C'\log_2n)/2}
    \stackrel{(b)}{\leq}2^{-tC'\log_2n},
\end{align}
where (a) uses ${x \choose x/2} \le 2^x$, and (b) uses $p_{\text{int}}\leq2^{-2t}/4$. Taking the union bound over all $n$ nodes at the final level, we obtain
\begin{align}
    n\big(2^{-tC'\log_2n}\big)
    &=n\big(n^{-tC'}\big)
    =O(n^{1-tC'}),
\end{align}
which approaches zero as $n\rightarrow\infty$ as long as $tC' > 1$. Note that while we have shown that all $n$ nodes (singletons) at the final level would be correctly identified if their final labels were to be computed, only at most $2k$ of these will actually be used by the algorithm, in accordance with the above analysis.

% This is because we have shown earlier in \eqref{eq:beta_n_eq} that with probability $1-\beta_n$, all non-defective nodes at $l_{\text{min}}$, all nodes in the defective tree, and all children nodes of all defective nodes, are correctly identified, which implies that $|\mathcal{PD}^{(\log_2n)}|\leq2k$.

\subsection{Number of Tests, Error Probability, and Decoding Time}

For convenience, we restate all the values that we have assigned in our analysis above:
\begin{align}
    C&=\bigg\lceil\frac{2}{1-2p}\bigg\rceil+1=O(1) \\
    N&=\bigg\lceil\frac{2t\log2+\log16}{2(1/2-p-1/C)^2}\bigg\rceil=O(t) \\
    r&=\bigg\lceil\frac{1}{t}\log_2\bigg(\frac{3k}{\beta_n}\log_2\Big(\frac{n}{k}\Big)\bigg)\bigg\rceil
    =O\bigg(\frac{1}{t}\log\Big(\frac{k\log(n/k)}{\beta_n}\Big)\bigg), \label{eq:r_formula_general}
\end{align}
where $p\in(0,1/2)$ is the noise level. Now, we choose $t=O(1)$ and $\beta_n=\big(k\log_2(n/k)\big)^{1-\epsilon t}$, for some constant $\epsilon\in(1/t,1)$. Substituting $\beta_n=\big(k\log_2(n/k)\big)^{1-\epsilon t}$ into \eqref{eq:r_formula_general} gives
\begin{align}
    r&=\bigg\lceil\frac{1}{t}\log_2\bigg(\frac{3k\log_2(n/k)}{\big(k\log_2(n/k)\big)^{1-\epsilon t}}\bigg)\bigg\rceil
    =\bigg\lceil\frac{1}{t}\log_2\bigg(3\Big(k\log_2\Big(\frac{n}{k}\Big)\Big)^{\epsilon t}\bigg)\bigg\rceil. \label{eq:r_formula_specific}
\end{align}
Recall that we require $C' \log_2n \geq r$, or equivalently $C'\geq r/\log_2n$. Substituting \eqref{eq:r_formula_specific} into $C'\geq r/\log_2n$, we find that we require
\begin{align}
    C'&\geq\frac{\big\lceil\frac{1}{t}\log_2\big(3\big(k\log_2\big(\frac{n}{k}\big)\big)^{\epsilon t}\big)\big\rceil}{\log_2n}, \label{eq:C'_cond}
\end{align}
Since $\epsilon$ is constant, we can choose $C'=O(1)$ that is large enough to satisfy \eqref{eq:C'_cond}. With our choices of $C,C',N,t=O(1)$ and $\beta_n=\Theta\big((k\log n)^{1-\epsilon t}\big)$, we obtain the following:

\begin{itemize}
    \item \textbf{Number of tests:} We used $CNk$ tests per level for $l=\log_2k,\dots,\log_2n-1$. At the final level $l=\log_2n$, we used $CC'Nk\log_2n$ tests. Summing these together gives
    \begin{align}
        T&\leq CNk\log_2\Big(\frac{n}{k}\Big)+CC'Nk\log_2n\stackrel{(a)}{=}O(k\log n), \label{eq:final_test_num}
    \end{align}
    where (a) follows by substituting $C,C',N=O(1)$ and simplifying.
    \item \textbf{Error probability:} Combining the error probabilities from all levels, we have a total error probability of at most
    \begin{align}
        \beta_n+O\big(n^{1-tC'}\big)=O\bigg(\Big(k\log\Big(\frac{n}{k}\Big)\Big)^{1-\epsilon t}\bigg),
    \end{align}
    by substituting $\beta_n=\big(k\log_2(n/k)\big)^{1-\epsilon t}$ and choosing $C'$ sufficiently large.
    \item \textbf{Decoding time:} To characterize the decoding time, we consider the number of test outcome checks made throughout the course of the algorithm. For $l=\log_2k,\dots,\log_2n-1$, w.h.p., we involved $O\big(k\log(n/k)\big)$ nodes in total. For each node involved, we checked at most $\sum_{i=1}^r2^{i}=O\big(2^r\big) \stackrel{\eqref{eq:r_formula_general}}{=} O\big(\big(\frac{k\log(n/k)}{\beta_n}\big)^{1/t}\big)$ intermediate labels of other nodes to decide the final label of the given node. For each these nodes being checked, we checked $N=O(t)$ test outcomes to determine the intermediate label. Therefore, the decoding time for these levels is
    \begin{align}
        O\bigg(k\log\Big(\frac{n}{k}\Big)\cdot\Big(\frac{k\log(n/k)}{\beta_n}\Big)^{1/t}\cdot t\bigg), \label{eq:decoding_time_except_final_level}
    \end{align}
    At the final level $l=\log_2n$, we have already shown that w.h.p., at most $2k$ nodes remain possibly defective. For each such node, we checked $C'\log_2n$ intermediate labels to decide the final label of the given node. To decide each intermediate label, we checked $N=O(t)$ test outcomes. Therefore, the decoding time at this level is $O(2k\cdot C'\log n\cdot t)$. Summing this with \eqref{eq:decoding_time_except_final_level} gives us the total decoding time of 
    \begin{align}
        O\bigg(k\log\Big(\frac{n}{k}\Big)\cdot\Big(\frac{k\log(n/k)}{\beta_n}\Big)^{1/t}\cdot t\bigg)+O(2k\cdot C'\log n\cdot t)
        =O\bigg(\Big(k\log\frac{n}{k}\Big)^{1+\epsilon}\bigg), \label{eq:final_decoding_time}
    \end{align}
    by substituting $C',t=O(1)$ and $\beta_n=\big(k\log_2(n/k)\big)^{1-\epsilon t}$, and noting that the $O(k \log n)$ term is dominated by $O\big(\big(k\log\frac{n}{k}\big)^{1+\epsilon}\big)$ regardless of the scaling of $k$.
    % \item \textbf{Storage:} For levels $l=\log_2k,\dots,\log_2n-1$, we need to store $N2^l$ integers indicating the $N$ tests associated with each of the $2^l$ nodes. Hence, we need to store $N\sum_{l=\log_2k}^{\log_2n-1}2^l=O(tn)$ integers in $\{1,\dots,Ck\}$, or $O(tn\log k)$ bits. Similarly, the $C'N\log_2n=O(C't\log n)$ independent sequences of tests at the final level amount to storing $O(C'tn\log n)$ integers, or $O(C'tn\log k\cdot\log n)$ bits. In addition, w.h.p., the storage of the possibly defective set requires $2k\log_2(n/k)+k=O(k\log n)$ integers, or $O(k\log^2n)$ bits. In total, we need $O(C'tn\log k\cdot\log n)=O(n\log k\cdot\log n)$ bits, where we substituted $C',t=O(1)$.
\end{itemize}

\section{Non-Binary Trees in the Noisy Setting} \label{sec:non_binary}

\subsection{Unconstrained Noisy Setting}

Our algorithm for the noisy setting in Section \ref{sec:noisy_algo_intro} is based on binary splitting, and combats noise by both (i) performing independent repetitions at each level, and (ii) classifying a given node by exploring levels further down the tree.  Here we discuss an alternative approach based on non-binary splitting, which attains similar results using only the former of these.\footnote{This approach was pointed out by an anonymous reviewer of an earlier version of this paper.}  Despite this, we believe that there is value in also showing that binary splitting suffices, and that our technique of exploring further down the tree may be of independent interest.

The non-binary approach we consider in this section is based on the analysis of the heavy hitters problem in \cite[Sec.~B.2]{Lar19}, which in turn builds on \cite{Cor08}.  Instead of forming a binary tree as in Figure \ref{fig:noisy_algo_diag}, consider forming a $b$-ary tree for some value of $b$ to be chosen later.  Hence, the depth of the tree is $O\big( \frac{\log n}{\log b} \big)$.  

At each level, instead of using $O(1)$ independent repetitions (as was done in Algorithm \ref{alg:noisy_nonadap_testing}), we use $O(\log b)$ repetitions.  Since there are $O\big( \frac{\log n}{\log b} \big)$ levels, and each repetition contains $O(k)$ tests, the total number of tests is $O(k \log n)$.   In addition, by a similar analysis to that of $p_{\text{int}}^{(\text{d})}$ and $p_{\text{int}}^{(\text{nd})}$ in Appendix \ref{sec:noisy_algo_analysis}, each majority vote over these repetitions succeeds with probability at least $1 - \frac{1}{{\rm poly}(b)}$, where the polynomial has arbitrarily high degree.

When all such majority votes are correct, the algorithm only visits $O(kb)$ nodes, and thus, if $b = (k \log n)^{\epsilon}$, the probability of any wrong decision can be made to decay as $\frac{1}{{\rm poly}(k \log n)}$.  While the list size at the final level increases from $O(k)$ (in our binary splitting approach) to $O(bk)$, the final level can still be analyzed in the same way as Appendix \ref{sec:noisy_algo_analysis}, and the total decoding time is $O(kb \log n) = O\big( (k \log n)^{1+\epsilon} )$.  This is equivalent to the decoding time $O\big( \big(k \log \frac{n}{k} \big)^{1+\epsilon} )$ given in Theorem \ref{thm:noisy_main_theorem}, since if $k$ is large enough for $\log\frac{n}{k}$ to significantly differ from $\log n$, then the logarithmic factor can be factored into the $k^{\epsilon}$ term anyway.

\subsection{Noisy Setting with Size-Constrained Tests}

At first glance, it may appear to be difficult to combine our techniques for the size-constrained and noisy settings, since the latter is based on searching $\omega(1)$ levels down the tree, whereas the former uses a tree with depth $O(1)$.  However, even in \cite{Ven19} where the computation time is $\Omega(n)$, moving to the noisy setting increases the number of tests from $O\big(\frac{n}{\rho}\big)$ to $O\big(\frac{n}{\rho} \log n\big)$.  We can incur a similar increase by increasing our tree depth from $O(1)$ to $O(\log n)$, and this added depth permits us to combat noise in the same way as the unconstrained setting.  For the sake of brevity, we omit the details.

\section{Storage Reductions via Hashing} \label{sec:storage_reductions}

For all of our algorithms considered, the storage comprises of storing the assignments of nodes to tests, storing the possibly defective set $\mathcal{PD}$, and storing the test outcomes.  We observe that since every tree that we consider has a final level containing $n$ nodes, storing the test assignments at that level alone requires $\Omega(n)$ storage, meaning that the standard versions of our algorithms do not have sublinear storage.

%We now provide a simple lower bound on the storage. Storing the associated test outcome(s) of every node leads to a total of $\Omega(n)$ bits of storage. This is because, regardless of the tree design, we have $n$ nodes at the last level. Since each node has at least one test outcome associated with it, this requires the storage of at least $n$ integers, which implies that the total storage is in $\Omega(n)$. 

In order to reduce the storage, we can make modifications to each algorithm in a similar manner to \cite{Eri20}:  Instead of directly storing the test outcomes of every node, we interpret the node-to-test mappings at each level (except for one-to-one mappings) as hash functions. Since the high storage comes from explicitly storing the corresponding test outcomes of nodes, the key to reducing the overall storage is to use lower-storage hash families. 

The reduced storage comes at the expense of reduced independence between different hash values. Fortunately, this drawback has a negligible effect on the guarantees of our algorithm under the noisy setting and size-constrained setting, as the proofs of Theorems \ref{thm:noisy_main_theorem} and \ref{thm:rho_main_theorem} only require pairwise independence or weaker. However, the effect is more significant for our algorithm under the finitely divisible items constraint, as our proof of Theorem \ref{thm:gamma_main_theorem} uses full independence.  In the following, we briefly describe suitable properties and choices for the hash families, and how they affect the algorithmic guarantees.  We let $\mathsf{T}_{\text{hash}}$ and $\mathsf{S}_{\text{hash}}$ respectively denote the evaluation time for one hash value and the number of bits of storage required for one hash function.

\textbf{Finitely divisible items:} Consider using an $O(\gamma)$-wise independent hash family to generate a hash function, with $\mathsf{T}_{\text{hash}}=O(\gamma)$ and $\mathsf{S}_{\text{hash}}=O(\gamma\log n)$ (e.g., see \cite[Section 3.1]{Eri20}). Since the analysis in Appendix \ref{sec:gamma_algo_analysis} requires full independence, a different analysis is required for the algorithmic guarantees. 

To address this, we note that two distinct analyses were given in \cite{Eri20}, with fully independent hashes attaining the stronger result, and limited-independence hashes reducing the storage but increasing the error probability. The latter of these in fact extends to the finitely divisible setting significantly more easily than the former does, so we simply state the corresponding result and omit the proof: For any function $\beta_n$ decaying as $n$ increases, using
\begin{align}
    T&=O\bigg(\gamma k\max\bigg\{\Big(\frac{n}{k}\Big)^{\frac{1}{\gamma'}},
    \Big(\frac{k}{\beta_n}\Big)^{\frac{1}{\gamma-\gamma'+1}}\Big(\frac{n}{k}\Big)^{\frac{1}{\gamma'(\gamma-\gamma'+1)}}\bigg\}\bigg)
\end{align}
tests, the algorithm has $O\big(\mathsf{T}_{\textup{hash}}\gamma k(n/k)^{1/\gamma'}\big)=O\big(\gamma^2k(n/k)^{1/\gamma'}\big)$ runtime, requires a storage of $O\big(k(n/k)^{1/\gamma'}\log n+\mathsf{S}_{\textup{hash}}\gamma+T\big)=O\big(\big(k(n/k)^{1/\gamma'}+\gamma^2\big)\log n+T\big)$ bits, and incurs an error probability of $O(\gamma/k+\beta_n)$.  Thus, we maintain a similar number of tests and decoding time as Theorem \ref{thm:gamma_main_theorem}, but the error probability increases, and in fact only behaves as $o(1)$ in the case that $\gamma=o(k)$ (which occurs, for example, under the mild condition $k = \Omega(\log n)$).

\textbf{Size-constrained tests:} Some care is required here to ensure that the constraints of our design matrix (i.e., fixed row and column weights) are satisfied. Specifically, at each level $l\in\{1,\dots,C\}$, we desire a hash function $h_l:\big\{1,\dots,\frac{n}{\rho^{1-l/C}}\big\}\rightarrow\{1,\dots,n/\rho\}$ such at each ``bucket'' (test) has a ``load'' (number of nodes in the test) of exactly $\rho^{l/C}$. An inspection of our analysis in Appendix \ref{sec:rho_algo_analysis} reveals that we only require the probability of two nodes colliding to be $O(\rho/n)$, i.e., only an approximately pairwise independent family is needed.

To construct the hash function above, we first consider a random permutation $\pi:\{1,\dots,\frac{n}{\rho^{1-l/C}}\}\rightarrow\{1,\dots,\frac{n}{\rho^{1-l/C}}\}$ such that for any $i,i'\in\{1,\dots,\frac{n}{\rho^{1-l/C}}\big\}$, we have $\mathbb{P}[|\pi(i)-\pi(i')|\leq t]=O\big(t\rho^{1-l/C}/n\big)$.  Such permutations are well-understood (e.g., see Definition 4.1 and Lemma 4.1 in \cite{Cev16}), and we can use this to design a hash function $h_l(\cdot)$ in the following manner: First apply the permutation discussed above, and then truncate the last $(l/C)\log_2\rho$ bits of the permutation value.  Then, for any $i,i'\in\{1,\dots,\frac{n}{\rho^{1-l/C}}\big\}$, we have
\begin{align}
    \mathbb{P}[h_l(i)=h_l(i')]
    \stackrel{(a)}{\le}\mathbb{P}[|\pi(i)-\pi(i')|\leq\rho^{l/C}]
    \stackrel{(b)}{=}O\Big(\frac{\rho}{n}\Big),
\end{align}
where (a) holds since if $i$ and $i'$ are in the same bucket, then all their bits except the last $(l/C)\log_2\rho$ bits are the same, and $\pi(i)$ and $\pi(i')$ can be at most $\rho^{l/C}$ (bucket size) apart; then, (b) holds by applying the collision property of our permutation. This proves that the constructed hash function has the required properties.  Moreover, we have $\mathsf{T}_{\text{hash}}=O(1)$ and $\mathsf{S}_{\text{hash}}=O(1)$. % and it follows that only the scaling of the storage required is affected; the analysis of the number of tests, error probability, and decoding time in Appendix \ref{sec:noisy_algo_analysis} still holds. 

Given the preceding hash construction, we again provide a brief analysis of the storage as follows: Recall that we use $N=O(1)$ hashes at each level (except $l=0$ and $l=C$), and $C'=O(1)$ hashes at the final level, for a total of $O(1)$ hashes, requiring $O(\mathsf{S}_{\text{hash}}) = O(1)$ storage. In addition, under the high probability event that there are $O(k\rho^{1/C})$ possibly defective nodes at each level, their storage requires $O(k\rho^{1/C})$ integers, or $O(k\rho^{1/C}\log n)=o(n/\rho)$ bits (see Lemma \ref{lem:asymp}). Lastly, we need to store a total of $O(n/\rho)$ test outcomes, each requiring a bit of storage. Hence, the total storage is $O(\mathsf{S}_{\text{hash}}+k\rho^{1/C}\log n+n/\rho)=O(n/\rho)$ bits.

\textbf{Noisy setting:} Since we only need pairwise independence in our analysis in Appendix \ref{sec:noisy_algo_analysis}, we can use any pairwise independent hash family to generate a hash function, which only requires $\mathsf{T}_{\text{hash}}=O(1)$ and $\mathsf{S}_{\text{hash}}=O(\log n)$ (e.g., see \cite[Section 3.1]{Eri20}).   Here the analysis of the number of tests, error probability, and decoding time in Appendix \ref{sec:noisy_algo_analysis} remain unchanged. 

We provide a brief analysis of the storage as follows: Recalling our choices of $C',t, N=O(1)$, we use $N=O(1)$ hashes at each level except the last, and $C'N\log_2n=O(\log n)$ hashes at the final level, for a total of $O(\log n)$ hashes, requiring $O(\mathsf{S}_{\textup{hash}}\log n)$ storage. In addition, for any level $l$, we know that $|\mathcal{PD}^{(l)}|=O(k\log n)$ w.h.p, which implies that the storage required for the possibly defective set is $O(k\log n)$ integers, or $O(k\log^2n)$ bits. Lastly, we need to store a total of $O(k\log n)$ test outcomes, each requiring a bit of storage. The total storage is $O(\mathsf{S}_{\textup{hash}}\log n+k\log^2n+k\log n)=O(k\log^2n)$ by substituting $\mathsf{S}_{\text{hash}}=O(\log n)$.


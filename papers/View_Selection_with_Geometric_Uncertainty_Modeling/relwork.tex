\section{Contributions and Related Work}
The importance of view selection for scene reconstruction is well
established.  One of the first view selection schemes for multi-view
stereo is presented in~\cite{farid1994view}.  The work of Maver and
Bajcsy~\cite{maver1993occlusions} and Kutulakos and Dyer~\cite{kutulakos1994recovering} use
contour information to choose viewing locations. 
A 2003 paper by Scott et al.~\cite{scott2003view} surveys
view selection methods.  Recently, Furukawa et
al.~\cite{furukawa2010towards} proposed a view selection scheme to
enable large scale 3D reconstruction.  Their method relies on
clustering images based on overlap. The resulting optimization problem
is solved iteratively.  The method of Hornung et
al.~\cite{hornung2008image} incrementally selects images and uses a
proxy to ensure coverage.  Mauro et al. resort to linear programming
to solve the view selection problem~\cite{mauro2014integer}. Sub-modular optimization~\cite{krause2014submodular}
has also been considered to jointly optimize the coverage and accuracy. 
However, it requires repeated visit of the same region. Both \cite{krause2014submodular} and \cite{hoppe2012photogrammetric}
uses surface meshes as geometrical reference to reason about optimal view selection. 
View selection has also been involved in image based modeling~\cite{vazquez2003automatic}, object
retrieval~\cite{gao2011less} and target
localization~\cite{isler2008sensor}. 

In the general reconstruction domain, key-frame methods \cite{klein2007parallel} \cite{murORB2} \cite{engel2014lsd} implement heuristics such as visible map features, distance between key-frames to decide if the current frame should be used for mapping. The main idea is to reduce the number of frames for bundle adjustment so as to make the system work in real-time. Mur-Artal et al.~\cite{murORB2} introduced the ``essential-graph" which builds a spanning tree from the image graph to achieve real-time performance. 
Snavely et al. \cite{snavely2008skeletal} proposed a method called ``skeleton set" that selects a subset of frames from the image graph to achieve similar reconstruction accuracy. However, they do not consider the geometry of the mapped environments. In Kaucic et al. \cite{planeBasedRecon}, the environment is assumed to be planar and the factorization method~\cite{sturm1996factorization} is used to speed up the bundle adjustment. 

In the present work, we consider an abstraction of the problem as: cameras on a viewing plane observing a planar world scene. We present a novel uncertainty model which allows us to characterize worst-case reconstruction error in a way that is independent of particular measurements. What differentiates our work from the previous body of work is that we present a  view selection mechanism with theoretical performance guarantees. Specifically, our \textbf{contributions} are the following. 
\begin{enumerate}
    \item We show that one can select two good views and obtain a reconstruction which is almost as good as merging all possible views from the entire viewing plane.
    \item We also show that a coarse camera grid (of resolution proportional to the scene depth) can provide a good reconstruction of the entire world plane.
    \item We present a multi-resolution view selection method which can be used for more general environments that are not strictly planar. 
\end{enumerate}


Our work is also related to error analysis in
stereo~\cite{sahabi1996analysis,cheong1998effects}. 
There are also many different uncertainty models. Bayram et al. \cite{Bayram2016sensor} models the bearing measurement's uncertainty as a function of linearized intersection area. Davison~\cite{davison2003real} approximates the uncertainty as a Gaussian distribution. 
We contribute to this line of work by analyzing the reconstruction error for two (best)
cameras with respect to the reconstruction error achievable by using
all possible cameras for the particular geometry we consider.


%In addition to mathematical proofs, we validate our results in simulations and show how our model can handle calibration errors and uncertainty in camera pose. We also establish their practical relevance in an image mosaicking application and show that the proposed view selection methods can drastically (from an overnight computation to one that takes a few minutes) improve the speed of existing algorithms without sacrificing accuracy.

%
%For optimal sensor selection regarding different sensor model, there have been many works. For example, \cite{isler2005sensor} and \cite{isler2008sensor} mainly focused on sensors with arbitrary convex model in $d$ dimensions. The results from those paper shows that at least 8 sensors are required in three dimensions to bound the optimal region with approximation ratio of 9. Another paper \cite{tokekar2013sensor} specifically used a camera model to estimate the uncertainty bound in a region using sensor grid methods. However, the results were limited to two dimensional cases. There are some other works that approaches the same localization and sensor selection problem from a different perspective. \cite{bishop2010optimality} models the localization error as a Gaussian distribution and formulate the whole problem as a optimization problem. While such approaches yields accurate results, the true nature of the uncertainty can only be accurately described geometrically. 
%
%In this paper, we focus on three dimensional cases of a camera model. The uncertainty region of any feature become a cone shape. There have been some work on cones intersections, but the specific geometry of the intersection are still unclear. Therefore, we provide a novel geometrical method to analyse the uncertainty of the intersection region while providing a tight bound. 
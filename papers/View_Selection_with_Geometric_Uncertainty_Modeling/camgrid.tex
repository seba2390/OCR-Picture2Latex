\section{Sensor Selection for the Entire Scene}\label{sec:camgrid}

In the previous section, we established that for a world point $g$, the optimal pair of cameras can produce a reconstruction with approximation ratio less than $\sqrt{\frac{1+2\alpha}{1-4\alpha}}$ (Theorem~\ref{thrm:opt2cameras3dbound}).
However, if we use this directly for every scene point, we may end up choosing two cameras for each scene point, which in turn might result in a large number of cameras.

 \begin{figure}[h]
 \centering
 	\includegraphics[width=0.5\textwidth]{fig/camgrid.png}
 	\caption{The square sensor grid in 3D}
 	\label{fig:grid}
 \end{figure}


In this section, we show that a coarse grid of cameras provide a good reconstruction for every scene point.

Recall that $\mathcal{G}$ is the ground plane, $\mathcal{S}$ is the view plane,   $\mathcal{G}$ is parallel to  $\mathcal{P}$ and the distance between them is $h$. 
Let $\mathcal{\overline{S}}$ be a square grid imposed on $\mathcal{S}$ with resolution $\delta_d$, which is shown in Fig~\ref{fig:grid}. The same grid $\mathcal{\overline{G}}$ is also imposed on the ground plane $\mathcal{G}$. 
To demonstrate the main strategy at a high-level, consider a ground point $g \in \mathcal{G}$, where we can find the optimal pair of cameras in the corse camera grid $\mathcal{\overline{S}}$. By moving the ground point in a region $\mathcal{R}(g)$ and using the same pair of cameras, we establish an upper bound of any points in the region $\mathcal{R}(g)$.

In this section, we make this rough argument concrete. Specifically, we show that 
with the choice of $\delta_d = \frac{h}{\tan(\pi/4-\alpha)}$, we achieve a $2$ approximation ratio for uncertainty everywhere using 
$|\mathcal{\overline{S}}| = \lceil \frac{9Area(\mathcal{G})}{h^2} \rceil$ cameras.
Due to space limitations, we present the lemmas and main ideas and leave detailed proofs to the supplementary material.

\subsection{Problem 2 in 2D}
For cameras in the grid $s \in \overline{S}$ and target $g \in G$, we define the grid uncertainty $\overline{\varepsilon}(g)$ using only the best two cameras in grid $\overline{S}$ as the following
$$
\overline{\varepsilon}(g) = \min_{s_i, s_j \in \overline{S}}\varepsilon(g,\{s_i,s_j\}) 
$$
As mentioned earlier, we will choose the grid resolution to be $\delta_d = \frac{h}{\tan(\pi/4-\alpha)}$ which is half of the distance between the optimal pair of cameras. 


\begin{lemma}\label{lem:gridu}
The minimum worst case uncertainty of any point $g$ is given as $\varepsilon_\infty$,
we claim that $\forall g \in \overline{G}$
$$
\overline{\varepsilon}(g) \leq \sqrt{\frac{1+2\alpha}{1-4\alpha}} \cdot \varepsilon_\infty
$$ 
\end{lemma}

In order to bound the uncertainty of any target $\forall g \in G$ using the camera grid $\overline{S}$, we need to explore the uncertainty of the targets in between the grid. Therefore, we fix a grid point and define a range of targets $R(g) = [g-\delta_d/2, g+\delta_d/2]$ such that $R(g)$ is generated by moving $g \in \overline{G}$ along the $x$-axis of the grid as shown in Fig~\ref{fig:grid3dv2}. We now show that the worst case uncertainty is achieved at the end points of this interval (i.e. the midpoint of two grid locations). We do this in two parts: first, we show that the sum of the viewing angles increases as we move away from a grid point until we reach to the midpoint. Next, we use this result to upper bound the uncertainty. 

\begin{lemma}\label{lem:maxtheta}
Let $g \in \overline{G}$ be a grid location with grid uncertainty $\overline{\varepsilon}(g)$ using the optimal pair of cameras $\{s_i,s_j\}$ with orientation $\theta_i,\theta_j$ respectively.  For any $g' \in R(g) = [g-\delta_d/2, g+\delta_d/2]$, 
$s_i$ and $s_j$ view $g'$ at an angle at most $\theta_i + \theta_j$ is maximized. This value is achieved when the inner half-plane of $Cone_i$ and $Cone_j$ intersects $g \pm \delta_d/2$.
\end{lemma}

It turns out that computing the uncertainty directly, as we did for a single point is tricky because the change in the viewing angles is monotonic.
Instead we show that $\theta_i+\theta_j$ is monotonic and further, there is a function $\xi(g)$ which increase monotonically with $\theta_i+\theta_j$ and upper bounds $\overline{\varepsilon}(g)$ -- i.e .$\overline{\varepsilon}(g) \leq \xi(g)$ for all $g$. This yields our main result:

\begin{theorem}\label{thrm:grid3d1}
For all targets $g \in G$, the worst case grid uncertainty is bounded as follows
$$
\overline{\varepsilon}(g) \leqslant 1.75 \varepsilon_\infty
$$
\end{theorem}

\subsection{Problem 2 in 3D}

In 3D, we use the same grid resolution $\delta_d = \frac{h}{\tan(\pi/4-\alpha)}$ for the this section, which is half of the distance between the optimal pair of cameras. The main result is

\begin{theorem}\label{thrm:grid3d2}
For all targets $g \in \mathcal{G}$, the worst case grid uncertainty is bounded as follows
$$
\overline{\varepsilon}(g) \leqslant 2 \varepsilon_\infty
$$
\end{theorem}

The proof is similar to the 2D case. It is extended to include perturbations in both $x$ and $y$ directions which slightly increases the bounds.
See Figures~\ref{fig:camgridtopdown} and \ref{fig:grid3dv2}.

\begin{figure}[h]
\centering
	\includegraphics[width=0.5\textwidth]{fig/camgridtopdown2.png}
	\caption{Camera grid: top down view}
	\label{fig:camgridtopdown}
\end{figure} 

\begin{figure}[h]
\centering
	\includegraphics[width=0.4\textwidth]{fig/grid3dv2.png}
	\caption{Camera grid in 3D: $g$ is perturbed to $g^*$ to achieve maximum uncertainty.}
	\label{fig:grid3dv2}
\end{figure} 

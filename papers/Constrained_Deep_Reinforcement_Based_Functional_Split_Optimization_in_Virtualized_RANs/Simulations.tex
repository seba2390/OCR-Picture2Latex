

\section{Results and Discussion} \label{sec:results}
\vspace{-1mm}
In this section, we conduct several experiments to evaluate our approach using synthetic and real network datasets. We aim to examine our approach in regards to: \textit{(i)} the behaviour during the training process, \textit{(ii)} the accuracy and solution distributions to the optimality with different penalty coefficient and search strategy settings, \textit{(iii)} the impact of routing costs and traffic loads on the optimality performance and total network cost, and \textit{(iv)} the computational time.




\vspace{-2mm}
\subsection{Environment \& Experiment Setup}
%\vspace{-1mm}
We use synthetic (R1) and real (R2) network datasets to evaluate our approach. We generate R1 \thirdrev{with} stricter constraints and a larger scale environment than R2. R1 is generated using the Waxman algorithm \cite{waxman} with parameters such as link probability ($\alpha$) and edge length control ($\beta$). These respective parameters $(\alpha,\beta)$ are set to $(0.5, 0.1)$. R1 has 1 CU and 99 DUs. In the case of R2, we utilize a real network dataset from \cite{network_sndb}, which has 1 CU and 63 DUs. \secrev{We assume that the routers are co-located with the DUs.} R1 and R2 differ in parameters, e.g., location, link capacity, weighted link, delay. We use  a standard store-and-forward model to calculate the delay. It is from $12000/c_{ij}$, $4 \mu\text{secs}$/Km and $5 \mu\text{secs}$ for transmission, propagation and processing delay, respectively; see \cite{vranmec_andres}. The link capacity varies to $100$ Gbps (R1) and $252$ Gbps (R2). The path delay reaches to $3658 \ \mu s$ (R1) and $42 \ \mu s$ (R2). In R1, the routing cost per path is calculated from the total cost per link (randomly generated) which belongs to the selected path. A link with a routing cost of 1 monetary unit per Mbps means having the same cost as a DU computing cost. We consider the routing cost within a range of $0.001 - 0.01$ times of DU computing cost (for the same network load) for each link in R1. In R2, we calculate the distance between nodes based on its geolocation dataset from \cite{network_sndb} and charge the cost of $0.01$ monetary units per Mbps/km. Fig. \ref{fig:ran_params} depicts the parameter distributions of our RANs with eCDF.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[t]
	\centering
	\begin{subfigure}[t]{.23\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./images/cdf_weight1.pdf}
		%\vspace{-3mm}	
		\small\caption{\small}
	\end{subfigure}
	%
	\begin{subfigure}[t]{.235\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./images/cdf_bw1.pdf}
		%\vspace{-3mm}	
		\small\caption{\small }
	\end{subfigure}
	\begin{subfigure}[t]{.235\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./images/cdf_lat1.pdf}
		%\vspace{-3mm}	
		\small\caption{\small }
	\end{subfigure}
	\caption{\small \textbf{RANs dist.} eCDF of (a) per-path routing cost, (b) per-link capacity, (c) per-path latency for R1 and R2.}
	\label{fig:ran}	
	\label{fig:ran_params}
	%\vspace{-3mm}	
	\vspace{-3mm}	
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


In this experiment, all system parameters correspond to testbed measurements of previous studies \cite{crancomplexity, vranmec_andres, vran_murti2,cost_vm}. We assume a high load scenario $\lambda_{n} = 150$ Mbps for every DU. This setting is based on 1 user/TTI, $2 \times 2$ MIMO, 20 Mhz (100 PRB), 2 TBs of 75376 bits/subframe and IP MTU 1500B. We use an Intel Haswell i7-4770 3.40GHz CPU as the \textit{reference core}, and set the maximum computing capacity to 75 RCs for CU and 7.5 RCs for each DU. Each split $o \in \{ 0,1,2,3 \}$ inccurs computational load $\rho_{o}^{{d}} = \{ 0.05, 0.04, 0.00325, 0\}$ RCs per Mbps at each DU and $\rho_{o}^{{c}} = \{0, 0.001, 0.00175, 0.05 \} $ RCs per Mbps at the CU. The VM instantiation cost at the CU is half of the DU $(\alpha_0 = \alpha_n/2)$ and the processing cost is set to $\beta_0 = 0.017 \beta_n$. 

Our learning rate is initially set to $\eta_a = 0.0001$ (Agent) and $\eta_b = 0.005$ (Baseline) with the batch size: 128. Our neural network has the number of layers, hidden dimension and embedding size with $1, 32$ and $ 32$, respectively. The temperature hyperparameter is set to $T=1$ by default, so the model computes the softmax function directly. We scale all the original values of weighted paths and traffic loads randomly with uniform distribution $[0,1]$ as in \cite{neural_bello}. Then, we generate three models (RL-pretaining) as outputs of our training with 50000 (in R1) and 15000 (in R2) epochs each. CDRS-Fixed uses a fixed penalty coefficient with $\mu_i =1, \forall i$ for all epochs while CDRS-Ada is set with initial penalty coefficient $\mu_i (0) =1, \forall i$ and step-size $\eta_d = 0.001$. The training is performed with Tensorflow 1.15.3 and Python 3.7.4. In the test, the temperature sampling method uses $16$ samples and $T = 15 $ (softmax temperature). 
%Finally, we summarize our default parameters in this experiment in Table xxx. 

\vspace{-2mm}
\subsection{Training Analysis}
%\vspace{-1mm}

\begin{figure*}[t] 
	\centering
	\begin{subfigure}[t]{.49\textwidth} %\label{fig:res_traina}
		\centering
		\includegraphics[width=\textwidth]{./images/train_r1.pdf}
		\small\caption{\small R1}
	\end{subfigure}
	%
	\begin{subfigure}[t]{.49\textwidth} %\label{fig:res_trainb}
		\centering
		\includegraphics[width=\textwidth]{./images/train_r2.pdf}
		\small\caption{\small R2}
	\end{subfigure}		
	\caption{\small \textbf{Training results of CDRS in (a) R1 and (b) R2.} CDRS-Fixed uses a fixed value of penalty coefficient (reward shaping) with $\mu_i = 1, \forall i$. CDRS-Ada utilizes an adaptive update of penalty coefficient.} 
	\label{fig:res_train} 
	\vspace{-3mm}
\end{figure*}

We aim to examine the behaviour of CDRS-Fixed and CDRS-Ada during the training process in R1 and R2. We focus on the mini-batch loss, reward (total network cost), Lagrangian cost and penalization.  

Fig. \ref{fig:res_train} visualizes the training of CDRS-Fixed and CDRS-Ada in R1 and R2. We found additional costs because of penalization at the beginning of the training for both settings in R1 and R2. It occurs because CDRS-Fixed and CDRS-Ada try to find the solution, but violate the constraint sets (e.g., latency, bandwidth, computation). Fig. \ref{fig:res_train} also shows a significant difference in the cost of penalization in R1 compared to R2. The main reason is that R1 has stricter constraints, e.g., larger path delays, smaller link capacity than R2. We can also see that CDRS-Fixed and CDRS-Ada improve their policy by focusing on constraint satisfaction and then correcting the weights via stochastic gradient descent. It is proven from our agent's behaviour in R1 and R2, where each penalization cost keeps decreasing and turns to zero as soon as the training goes. CDRS-Ada sets the penalty coefficient increasing in the ascent direction, causing a higher penalization value than CDRS-Fixed. However, it can help speed up the policy toward constraint satisfaction, i.e., CDRS-Ada penalization downs faster than CDRS-Fixed.


We also found that the policy of CDRS-Ada converges faster than CDRS-Fixed from the behaviour of mini-batch loss in R1. Despite the mini-batch loss decreases to near zero after several epochs, the mini-batch loss of CDRS-Ada diminishes faster than CDRS-Fixed. However, CDRS-Ada suffers from more severe sub-optimality. It is shown by the total vRAN cost of CDRS-Ada that converges to a fixed value but has a higher cost compared to CDRS-Fixed.  Then, we have the Lagrangian cost from the sum of vRAN cost and penalization cost. It describes how our agent tries to minimize the primal problem $\mathbb{P}_{\text{1P}}$ through the dual problem $\mathbb{P}_{\text{1D}}$.  When our agent finally dismisses the penalization cost, it means that all constraints are satisfied. As a result, the Lagrangian cost becomes equal to the vRAN cost, and the penalty coefficient of CDRS-Ada converges to a fixed value.  Although having different behaviours, CDRS-Ada and CDRS-Fixed can learn the solution and converge to the local minima or saddle point in R1 and R2.

\textbf{Findings:} 1) R1 has stricter constraint requirements than R2; hence, it produces a higher additional cost for penalization to CDRS-Fixed and CDRS-Ada. 2) CDRS-Fixed and CDRS-Ada improve the policy by focusing on the penalization; then, it adjusts the weights as the training goes. 3) CDRS-Ada receives higher penalization compared to CDRS-Fixed as a result of increasing the penalty coefficient in the ascent direction; however, it also helps speed up the policy to constraint satisfaction. 4) CDRS-Ada converges faster but has a higher cost than CDRS-Fixed in R1. 5) When all constraints are satisfied,  the Lagrangian cost becomes equal to the total vRAN cost, and the penalty coefficient of CDRS-Ada converges to a fixed value.

%

\vspace{-2mm}
\subsection{Accuracy of Solutions}
%\vspace{-1mm}
%
%
\begin{figure*}[t]
	\centering
	\begin{subfigure}[t]{.47\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./images/acc_r1.pdf}
		\small\caption{\small R1}
	\end{subfigure}
	%
	\begin{subfigure}[t]{.47\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./images/acc_r2.pdf}
		\small\caption{\small R2}
	\end{subfigure}	
	\caption{\small \textbf{Histogram of CDRS accuracy in (a) R1 and (b) R2.} The accuracy is calculated over 128 tests. CDRS-Ada-T and CDRS-Fixed-T are set with $T=15$ and $16$ samples.} 	\label{fig:_accmain}
	\vspace{-3mm}	
\end{figure*}


In this part, we study the accuracy of CDRS over different penalty coefficient and search strategy settings: CDRS-Fixed-G, CDRS-Fixed-T, CDRS-Ada-G and CDRS-Ada-T. We conduct 128 tests with a distinct sequence order of the BSs in R1 and R2 to assess how accurate these four CDRS settings find the solution of the vRAN split problem. We utilize three pretraining models \secrev{from} our CDRS training.

Fig. \ref{fig:_accmain} shows the distribution of \secrev{the solutions from} CDRS-Fixed-G, CDRS-Fixed-T, CDRS-Ada-G and CDRS-Ada-T in R1 and R2. \secrev{Each bar counts the number of offered solutions resulting in some suboptimality, represented using the optimality gap (error). It shows that the distribution varies between four settings, especially in a stricter environment (R1). Still,} all of these settings can guarantee less than $0.6 \%$ (R1) and $0.1 \%$ (R2) of the optimality gap. In R1, CDRS-Fixed-G and CDRS-Fixed-T perform better by offering lower solution errors ($ \leq 0.05 \%$ and $\leq 0.05 \%$ of optimality gap) than CDRS-Ada-G and CDRS-Ada-T ($\leq 0.6 \%$). It means that a fixed penalty coefficient setting can lead to a better optimality performance during the test than the adaptive one. However, CDRS-Fixed-G, CDRS-Ada-G and CDRS-Ada-T have a similar performance in R2. Regardless of R1 or R2, using a sampling method with a temperature hyperparameter can improve (or at least at same) the optimality performance than greedy decoding. It is shown from the higher total number of solutions (counts) for a sampling method that having a lower error. The combination of a fixed penalty in the training and temperature sampling method (CDRS-Fixed-T) can improve the solution performance significantly both in R1 and R2. It can achieve an optimal value (R2) and less than $0.05 \%$ of error for a more complex environment (R1). It is also shown that CDRS-Fixed-T is less affected to the stricter environment than any other settings where all of the distribution solutions are in less than $0.05 \%$.


\textbf{Findings:} 1) CDRS-Fixed-G, CDRS-Fixed-T, CDRS-Ada-G and CDRS-Ada-T can guarantee the solution with very close to the optimal value offering less than $0.6 \%$ (R1) and $0.1 \%$ (R2) of the optimality gap over 128 tests. 2) CDRS-Fixed-T can significantly improve the optimality performance (offers $\leq 0.05 \%$ of optimality gap) and outperforms the other settings.  



\vspace{-2mm}
\subsection{Impact of Routing Cost}
\vspace{-1mm}


This part studies the impact of altering the routing cost to CDRS-Fixed-G, CDRS-Fixed-T, CDRS-Ada-G and CDRS-Ada-T. We aim to examine how the routing cost affects optimality performance and the total network cost. Hence, the default routing cost is changed within a range of $\gamma=0.1$ to $\gamma=1$. This change can arise due to increasing or decreasing the leasing agreement's price, maintenance, etc. The traffic load is fixed with $\lambda_{n}=150$ Mbps. We utilize three \secrev{pretraining} models, conduct 128 tests for each routing cost scale, and analyze the offered solutions' distribution. We also consider benchmarking with two extremes of RAN setups, fully D-RAN and C-RAN\footnote{We practically can not implement C-RAN because our RANs do not meet the constraint requirements of delay, bandwidth and CU capacity to deploy C-RAN. The presented C-RAN in this experiment is just for benchmarking; hence we also do not consider the penalization cost (constrains violation) for this case.} to assess how significant the routing cost affects the total network cost over various RAN setups.


\begin{figure*}[t] 
	\centering
	\begin{subfigure}[t]{.99\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./images/routing_acc_r1.pdf}
		\small\caption{\small R1}
	\end{subfigure}
	%
	\begin{subfigure}[t]{.99\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./images/routing_acc_r2.pdf}
		\small\caption{\small R2}
	\end{subfigure}		
	\caption{\small \textbf{Impact of the routing cost to the accuracy in (a) R1 and (b) R2.} Study of altering the routing cost to the optimality performance with $\lambda_{n}=150$ Mbps, $\forall n \in \mathcal{N}$. There are 128 tests for each routing scale $[0.1,1]$.} \label{fig:routing_acc}
	\vspace{-3mm}
\end{figure*}


\begin{figure*}[t] 
	\centering
	\begin{subfigure}[t]{.375\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./images/routing_cost_r1.pdf}
		\small\caption{\small R1}
	\end{subfigure}
	%
	\begin{subfigure}[t]{.375\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./images/routing_cost_r2.pdf}
		\small\caption{\small R2}
	\end{subfigure}		
	\caption{\small \textbf{Impact of routing cost to the total cost in (a) R1 and (b) R2.} We also compare our approach (e.g., CDRS-Fixed-T) to two extreme cases: fully D-RAN and C-RAN, and the optimal value with the routing cost scaling from 0.1 to 1 of default R1 and R2. The presented cost above is normalized toward fully C-RAN cost.} \label{fig:routing_cost}
	\vspace{-3mm}
\end{figure*}


Fig. \ref{fig:routing_acc} depicts how the routing cost affects the optimality performance of CDRS-Fixed-G, CDRS-Fixed-T, CDRS-Ada-G and CDRS-Ada-T. It shows that the \secrev{overall} optimality gap (error) diminishes as the routing cost increases; then, it converges to a specific value. In R1, we see a performance improvement as the errors decrease for CDRS-Fixed-G ($\approx75\%$), CDRS-Fixed-T ($\approx75\%$), CDRS-Ada-G ($\approx78\%$) and CDRS-Ada-T ($\approx75\%$) \secrev{by the increase of routing cost}. It also shows that CDRS-Ada-G gets the most impact while CDRS-Fixed-T is the least affected. In R2, all CDRS settings \secrev{also} have a similar trend in terms of error \secrev{performance}. Although we have changed the routing cost from the default parameter, we found that \secrev{altering the} routing cost gives relatively less effect to these settings where the errors are maintained under $1.8 \%$. CDRS-Fixed-T even can guarantee the solution under $0.08 \%$ ($\gamma  = 0.1$) of the optimality gap.



Fig. \ref{fig:routing_cost} shows the routing cost's effect on the total network cost of CDRS-Fixed-T and D-RAN, normalized to the C-RAN cost in R1 and R2. \secrev{It shows that CDRS-Fixed-T can obtain a larger cost-saving than the D-RAN cost at a cheaper routing cost by up to $59.06\%$ of cost-saving at $\gamma = 0.1$ while only $25.49\%$ of cost-saving at $\gamma = 1$ in R1. Compared to C-RAN, CDRS-Fixed-T can save the cost by up to $92\%$ at $\gamma = 1$ in R1. However, this gain diminishes as the routing cost decreases and eventually CDRS-Fixed-T will reach near the C-RAN cost if all constraint requirements are eligible. A similar trend also appears for R2. Moreover, CDRS-Fixed-T can offer the solution extremely close to the optimal solution by $\leq 0.09\%$ (R1) and $\leq 0.5\%$  (R2). }
%

%It shows that the increase of routing cost gives CDRS-Fixed-T and D-RAN cost relatively decrease (around $320\%$ and  $420\%$ from $\gamma = 0.1$ to $\gamma = 1$ in R1) to the C-RAN cost. Hence, we can conclude that the routing cost gives more impact to C-RAN than other setups. Additionally, CDRS-Fixed-T is the most cost-efficient with around $500\%$ and $200\%$ cost-saving of C-RAN and D-RAN at low routing cost ($ \gamma = 0.1$). It also can save to 20 times and two-fold compared to the respective RAN setups at high routing cost ($ \gamma = 1$) in R1. In R2, CDRS-Fixed-T can save to around five times and two times of C-RAN and D-RAN cost at low routing cost ($ \gamma = 0.1$). It has cost-saving to 20 times and two-fold compared to the respective RAN setups at high routing cost ($ \gamma = 1$). CDRS-Fixed-T offers the solution very close to the optimal solution ($\leq 0.09\%$ in R1 and $\leq 0.5\%$ in R2) and efficiently adapts to the change of the routing cost. 



\textbf{Findings:} 1) The increase of routing cost \secrev{reduces} the optimality gap \secrev{(error)}; then, \secrev{it} converges to a fixed value. 2) CDRS-Fixed-T is the least affected by the routing cost changes, while CDRS-Ada-G is the most affected. 3) \secrev{Scaling} the routing cost from $\gamma = 0.1$ to $\gamma = 1$ does not significantly degrade the optimality performance. 4) CDRS-Fixed-T has the lowest optimality gap  \secrev{than other CDRS settings}, and becomes the most cost-effective setup in R1 and R2. \secrev{5) CDRS-Fixed-T can reach near the D-RAN cost at a high routing cost, while it can be near the C-RAN cost at a cheap routing cost if all constraint requirements are eligible.}
%

\vspace{-2mm}
\subsection{Impact of Traffic Load}
\vspace{-1mm}

\begin{figure*}[t] 
	\centering
	\begin{subfigure}[t]{.99\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./images/traffic_acc_r1.pdf}
		\small\caption{\small R1}
	\end{subfigure}
	%
	\begin{subfigure}[t]{.99\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./images/traffic_acc_r2.pdf}
		\small\caption{\small R2}
	\end{subfigure}		
	\caption{\small \textbf{Impact of the traffic load to the accuracy in (a) R1 and (b) R2.} Study of traffic load to the optimality performance. There are 128 tests for each traffic load. } \label{fig:traffic_acc}
	\vspace{-3mm}
\end{figure*}


\begin{figure*}[t] 
	\centering
	\begin{subfigure}[t]{.375\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./images/traffic_cost_r1.pdf}
		\small\caption{\small R1}
	\end{subfigure}
	%
	\begin{subfigure}[t]{.375\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./images/traffic_cost_r2.pdf}
		\small\caption{\small R2}
	\end{subfigure}		
	\caption{\small \textbf{Impact of traffic load to total vRAN cost in (a) R1 and (b) R2.} On the comparison of our approach (e.g., CDRS-Fixed-T) to fully D-RAN. The presented cost above is normalized toward fully C-RAN cost.} \label{fig:traffic_cost}
	\vspace{-3mm}
\end{figure*}

In this part, we assess how the traffic load affects the optimality performance and the total network cost. We change the traffic load from 10 Mbps to 150 Mbps. This evaluation is conducted using three \secrev{pretraining} models and examined over 128 tests.   

Fig \ref{fig:traffic_acc} shows the impact of altering the traffic load to the optimality performance of CDRS-Fixed-G, CDRS-Fixed-T, CDRS-Ada-G and CDRS-Ada-T. In R1, it shows that the increase of traffic load in line with the rise of the error to CDRS-Ada-G and CDRS-Ada-T, but it then diminishes to a fixed value, i.e., around $0.4 \%$ (CDRS-Ada-G) and $0.18\%$ (CDRS-Ada-T). However, the traffic load does not significantly affect CDRS-Fixed-G and CDRS-Fixed-T, where they stay at around $0.04\%$ and $0.02\%$ of errors, respectively, in R1. In R2, CDRS-Fixed-G, CDRS-Fixed-T, CDRS-Ada-G and CDRS-Ada-T have the same trend where the optimality gap increases with the traffic load; then, it diminishes at around  $0.05\%$. We also found that CDRS-Fixed-T \secrev{has a} better optimality performance and a more stable solution. 


Fig \ref{fig:traffic_cost} examines the impact of traffic load on CDRS-Fixed-T and D-RAN cost normalized to the C-RAN cost. Despite an increase in CDRS-Fixed-T cost as the traffic load rises, it shows that CDRS-Fixed-T is still the most cost-effective compared to D-RAN and C-RAN \secrev{in} R1 and R2. \secrev{CDRS-Fixed-T almost has the same cost as D-RAN at the low traffic load with only $12.33\%$ cost-saving. This cost-saving then increases for the higher traffic load settings by up to $25.5\%$ at 150 Mbps in R1. This trend also happens in R2. Compared to C-RAN, CDRS-Fixed-T significantly outperforms at the low traffic load, but this gain then diminishes as the increase of the load. CDRS-Fixed-T can reach near the C-RAN cost when all constraint requirements are satisfied, and the traffic load is high, but the routing cost is significantly low.}

%
%In R1, CDRS-Fixed-T can save $114\%$ at low traffic load (10 Mbps) and $134\%$ at high traffic load (150 Mbps) of D-RAN cost, while $124\%$ and $177\%$ for the respective load in R2. The cost-saving gap is also more prominent with the increase of traffic load. We also found that D-RAN is the most affected by the increase in traffic load.

\textbf{Findings:} 1) CDRS-Fixed-T can offer to better optimality performance and more stable solution \secrev{than other CDRS settings}. 2) In R2, all CDRS settings have similar trends where the increase of traffic load can also increase the optimality gap, but it then diminishes and stays at around $0.05\%$ for CDRS-Fixed-T and $0.06\%$ for the others. 3)  CDRS-Fixed-T is the most cost-efficient compared to C-RAN and D-RAN. 4) \secrev{CDRS-Fixed-T can eventually almost have the same C-RAN cost when all constraint requirements are satisfied, and the traffic load is high, but the routing cost is significantly low.}

\vspace{-2mm}
\subsection{Computational Time}
\vspace{-1mm}

Finally, we examine the computational time to solve a single instance of the vRAN split problem. We use a small laptop with an Intel Core i5-7300U CPU@2.60GHz and 8GB memory. The computational time for each CDRS setting is a result of averaging 128 executions with a trained model. We report this evaluation in Table \ref{table:computationaltime}.  Overall, our proposed CDRS settings: CDRS-Fixed-G, CDRS-Fixed-T, CDRS-Ada-G and CDRS-Ada-T, have a faster computational time than the MIP solver. CDRS-Ada-G is the fastest with $0.0120$ secs and $0.0077$ secs in R1 and R2 reaching to $22.82$ times faster than the MIP solver. We also found that any CDRS settings with greedy decoding for the inference process, e.g., CDRS-Fixed-G, CDRS-Ada-G, is more time-efficient than a temperature sampling method with around 10-20 times faster. It is also shown that CDRS-Ada-G/T has a slightly faster computational time than CDRS-Fixed-G/T. Finally, we can sort from the fastest computational time as 1) CDRS-Ada-G, 2) CDRS-Fixed-G, 3) CDRS-Ada-T, 4) CDRS-Fixed-T, 5) the MIP solver.
%Besides, an adaptive penalty coefficient can speed up the policy to find the solution than a fixed penalty coefficient, especially in the highly constrained environment (R1).

\begin{table*}[t!] \centering
	%\ra{1.3}
	\begin{small}
		\begin{tabular}{@{}cccccc@{}}\toprule
			\textbf{Topology}& \textbf{MIP solver} &\textbf{CDRS-Fixed-T} & \textbf{CDRS-Fixed-G}  & \textbf{CDRS-Ada-T} & \textbf{CDRS-Ada-G}
			\\ \midrule
			\textbf{R1} &      0.2527   & 0.2026 & 0.0155& 0.1985 & 0.0120          
			\\ \hdashline
			{\textbf{R2}} &  0.1756 &  0.1240 & 0.0098 & 0.1207 &0.0077
			\\ \hdashline
			\bottomrule
		\end{tabular}
	\end{small}
	\caption{\small \textbf{Computational time.} Study of computational time for solving a single problem instance in seconds. The presented computational time is a result of averaging 128 executions.}
	\label{table:computationaltime}
	\vspace{-3mm}
\end{table*}

\textbf{Findings:} 1) CDRS-Ada-G, CDRS-Fixed-G, CDRS-Ada-T, and CDRS-Fixed-T can reach up to $22.82, 17.99, 1.45$ and $1.41$ times faster than the MIP solver. 2) Greedy decoding is more time-efficient than a temperature sampling method for the inference process.

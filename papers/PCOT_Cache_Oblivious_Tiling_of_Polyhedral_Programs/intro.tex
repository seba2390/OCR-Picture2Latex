\section{Introduction}
\label{sec:introduction}

Modern multicore processors are complicated, and programming them is a
challenge, especially when seeking the best performance.  Many different, and
often conflicting factors need to be optimized, notably, parallelism and data
locality, and that too, at multiple levels of the memory/processor hierarchy
(vectors-registers cores-caches).  Indeed, in the exascale era, the very
notion of ``performance'' may refer to execution time (i.e., speed) or to
energy (product of the average power and time), or even the energy-delay
product.

Iteration space tiling~\cite{irigoin-popl88, Wol87, Wolf91tiling} (variously
called loop blocking~\cite{schreiber-TR90} or
partitioning~\cite{bu-deprettere, darte-partitioning91, teich-thiele93}) is a
critical transformation, used for multiple objectives: balancing granularity
of communication to computation across nodes in a distributed machine,
improving data locality on a single node, controlling locality and parallelism
among multiple cores on a node, and, at the finest grain, exploiting
vectorization while avoiding register pressure on a single core.  It is an
essential strategy used by compilers and automatic parallelizers.

%Tiling is particularly relevant for programs like affine control loops, that
%match the constraints of the polyhedral model~

Another approach to optimizing memory transfers is provided by cache oblivious
algorithms~\cite{prokop-thesis99, frigo-etal-focs99}.  They come with elegant
theoretical bounds on the number of cache misses, and are claimed to require
less tuning than iteration space tiling.  When applied to specific computation
patterns like ``stencils,'' cache-oblivious the strategy may also be viewed as
tiling, where a tile is recursively split into smaller ones through the
divide-and-conquer strategy~\cite{frigo-strumpen-ics05}.

The fundamental difference between the two approaches is the \emph{schedule},
or temporal order in which tiles are executed. A program transformed with
(single-level) iteration space tiling visits the tiles in the lexicographic
order.  Cache oblivious methods visit (leaf) tiles in a different order,
yielding better locality---this can also be viewed as hierarchical
tiling~\cite{carter1995hierarchical} where the number of levels depends on the
problem size.

The practical impact of this difference is not fully understood due to many
complicating factors.  The theoretical results for cache oblivious methods
assume fully associative caches, and therefore do not fully account for
conflict misses.  Hardware prefetching plays an important role in modern
architecture, and it also has significant impact on the choice of tile
sizes~\cite{mehta2016turbotiling}.  Most importantly, existing tools for cache
oblivious code generation are domain specific: Pochoir targets Jacobi-style
stencils~\cite{Tang2011} and AutoGen specializes on dynamic
programming~\cite{autogen-ppopp16}.  This makes an ``apples-to-apples''
comparison of the two techniques difficult because of the mismatch between the
classes of programs where the application of the two techniques are automated.

Our objective is to understand the difference between iteration space tiling
and cache oblivious strategy on modern architecture.  Our study emphasizes the
influence of tile sizes (or base case thresholds) that strongly impact the
performance of both approaches.  To do this we generalized cache oblivious
code generation to all computations that fit the polyhedral model, i.e.,
(imperfect) loop nests with affine bounds and array
accesses~\cite{feautrier2011polyhedral, sanjay-fsttcs86, quinton-jvsp89,
  quinton-sanjay-tf, feautrier91, feautrier92a, feautrier92b}.  This class of
programs include, as a \emph{proper} subset, all the inputs handled by Pochoir
and Autogen, and many others such as dense linear algebra algorithms and
Gauss-Seidel style stencils.  Our study reveals the following:
\begin{itemize}\itemsep 0mm
\item The absolute number of cache misses, as well as the variability of this
  number as a function of tile sizes, are both significantly lower with cache
  oblivious codes.  This is consistent with theeory.
\item Both approaches show similar variability in speed,
  % as a function of tile size
  implying that the tuning effort for both methods is similar.  The main
  reason is that speed does not depend on cache behavior alone.  The leaf tile
  sizes influence other aspects such as recursion overhead, register
  allocation, vectorization, and prefetcher effectiveness.
\item The additional levels of tiling in cache oblivious codes do not
  contribute to speed, especially for polyhedral programs.  Once there the
  code is compute-bound at a certain level of cache, additional locality in
  slower caches does not improve speed.
\item The benefit of cache oblivious approaches diminish on architectures with
  low set-associativity of caches, and with prefetching.  The tile execution
  order of cache oblivious codes can increase conflict misses with high
  dimensional data.  Hardware prefetching may favor large tile sizes in the
  innermost dimension, if speed is the primary objective, where the leaf tile
  sizes are already targeting the LLC (Last Level Cache).
\end{itemize}
These results are, in part, confirmation of the work by Yotov et
al.~\cite{yotov2007experimental}, who focused on sequential executions of
matrix computations.  We extended the study to a broader range of kernels, and
to parallel execution.  The main takeaway is that if the main interest is in
speed, then cache oblivious codes are unlikely to help.  However, if the
goal is to reduce off-chip memory traffic, e.g., for better energy
efficiency, then cache oblivious codes give this for ``free:'' no additional
tuning is required beyond that required for speed.  Even then, its
effectiveness is constrained by various aspects of the code and the platform,
and care must be taken to select the appropriate strategy.  We provide a
generalized cache oblivious code generator to offer this option to any
polyhedral program, and give insights on when it will be effective.

% Local Variables: ***
% TeX-master: "TACO2017.tex" ***
% fill-column: 78 ***
% End: ***

\begin{algorithm}[tb]
% \setstretch{1.3}

\begin{algorithmic}
 \STATE {\bfseries Input:} Source data $S={\{(x_i,y_i)\}}_{i=1}^n$ and network architecture $G_f,G_y,G_d$
 \STATE {\bfseries Parameters:} Batch size $m$, perturbation size $\epsilon$, pgd attack step size $\tau$, adversarial trade-off $\lambda$, initial reversal ratio $r$, and step size $\alpha$
 \STATE {\bfseries Init:} $Y_{0}$ and $Y_{1}$  source and target domain vectors filled with 0 and 1 respectively
 \STATE {\bfseries Output:} Robust network $G=(G_f,G_y,G_d)$ parameterized by $\hat{\theta}=(\theta_f,\theta_y, \theta_d)$ respectively

 \REPEAT 
  \STATE {Fetch mini-batch $X_{s}={\{x_j\}}_{j=1}^m$, $Y_{s}={\{y_j\}}_{j=1}^m$}
  
  \STATE{\# Generate adversarial target domain batch $X_{t}$}
  
  \FOR{$j=1,\ldots,m$ (in parallel)} \STATE{ 
    $x'_j \leftarrow PGD(x_j,y_j,\epsilon,\tau)$
   
    $X_{t} \leftarrow X_{t} + x'_j$
  }
  \ENDFOR

  \STATE{$\ell_{s}^y, \, \ell_{t}^y \leftarrow \text{CE}(G_y(G_f(X_{s})), Y_{s}), \, \text{CE}(G_y(G_f(X_{t})), Y_{s})$}

  
  \STATE{$\ell_{s}^d, \, \ell_{t}^d \leftarrow \text{CE}(G_d(G_f(X_{s})), Y_{0}), \, \text{CE}(G_d(G_f(X_{t})), Y_{1})$}
  
  \STATE{$\ell \leftarrow \ell_{s}^y + \lambda\ell_{t}^y - r(\ell_{s}^d + \ell_{t}^d)$}
  
  \STATE{$\hat{\theta} \leftarrow \hat{\theta} - \alpha\nabla_{\hat{\theta}}(\ell)$}
\UNTIL{stopping criterion is not met}

 
\caption{Domain Invariant Adversarial Learning}
\label{DIAL-algorithm}
\end{algorithmic}
\end{algorithm}

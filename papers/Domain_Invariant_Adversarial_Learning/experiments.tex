In this section we conduct comprehensive experiments to emphasise the effectiveness of DIAL, including evaluations under white-box and black-box settings, robustness to unforeseen adversaries, robustness to unforeseen corruptions, transfer learning, and ablation studies. Finally, we present a new measurement to test the balance between robustness and natural accuracy, which we named $F_1$-robust score. 


\subsection{A case study on SVHN and CIFAR-100}
In the first part of our analysis, we conduct a case study experiment on two benchmark datasets: SVHN \citep{netzer2011reading} and CIFAR-100 \cite{krizhevsky2009learning}. We follow common experiment settings as in \cite{rice2020overfitting, wu2020adversarial}. We used the PreAct ResNet-18 \citep{he2016identity} architecture on which we integrate a domain classification layer. The adversarial training is done using 10-step PGD adversary with perturbation size of 0.031 and a step size of 0.003 for SVHN and 0.007 for CIFAR-100. The batch size is 128, weight decay is $7e^{-4}$ and the model is trained for 100 epochs. For SVHN, the initial learinnig rate is set to 0.01 and decays by a factor of 10 after 55, 75 and 90 iteration. For CIFAR-100, the initial learning rate is set to 0.1 and decays by a factor of 10 after 75 and 90 iterations. 
%We compared DIAL to \cite{madry2017towards} and TRADES \citep{zhang2019theoretically}. 
%The evaluation is done using Auto-Attack~\citep{croce2020reliable}, which is an ensemble of three white-box and one black-box parameter-free attacks, and various $\ell_{\infty}$ adversaries: PGD$^{20}$, PGD$^{100}$, PGD$^{1000}$ and CW$_{\infty}$ with step size of 0.003. 
Results are averaged over 3 restarts while omitting one standard deviation (which is smaller than 0.2\% in all experiments). As can be seen by the results in Tables~\ref{black-and_white-svhn} and \ref{black-and_white-cifar100}, DIAL presents consistent improvement in robustness (e.g., 5.75\% improved robustness on SVHN against AA) compared to the standard AT 
%under variety of attacks 
while also improving the natural accuracy. More results are presented in Appendix \ref{cifar100-svhn-appendix}.


\begin{table}[!ht]
  \caption{Robustness against white-box, black-box attacks and Auto-Attack (AA) on SVHN. Black-box attacks are generated using naturally trained surrogate model. Natural represents the naturally trained (non-adversarial) model.
  %and applied to the best performing robust models.
  }
  \vskip 0.1in
  \label{black-and_white-svhn}
  \centering
  \small
  \begin{tabular}{l@{\hspace{1\tabcolsep}}c@{\hspace{1\tabcolsep}}c@{\hspace{1\tabcolsep}}c@{\hspace{1\tabcolsep}}c@{\hspace{1\tabcolsep}}c@{\hspace{1\tabcolsep}}c@{\hspace{1\tabcolsep}}c@{\hspace{1\tabcolsep}}c@{\hspace{1\tabcolsep}}c@{\hspace{1\tabcolsep}}c}
    \toprule
    & & \multicolumn{4}{c}{White-box} & \multicolumn{4}{c}{Black-Box}  \\
    \cmidrule(r){3-6} 
    \cmidrule(r){7-10}
    Defense Model & Natural & PGD$^{20}$ & PGD$^{100}$  & PGD$^{1000}$  & CW$^{\infty}$ & PGD$^{20}$ & PGD$^{100}$ & PGD$^{1000}$  & CW$^{\infty}$ & AA \\
    \midrule
    NATURAL & 96.85 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
    \midrule
    AT & 89.90 & 53.23 & 49.45 & 49.23 & 48.25 & 86.44 & 86.28 & 86.18 & 86.42 & 45.25 \\
    % TRADES & 90.35 & 57.10 & 54.13 & 54.08 & 52.19 & 86.89 & 86.73 & 86.57 & 86.70 &  49.50 \\
    $\DIAL_{\kl}$ (Ours) & 90.66 & \textbf{58.91} & \textbf{55.30} & \textbf{55.11} & \textbf{53.67} & 87.62 & 87.52 & 87.41 & 87.63 & \textbf{51.00} \\
    $\DIAL_{\ce}$ (Ours) & \textbf{92.88} & 55.26  & 50.82 & 50.54 & 49.66 & \textbf{89.12} & \textbf{89.01} & \textbf{88.74} & \textbf{89.10} &  46.52  \\
    \bottomrule
  \end{tabular}
\end{table}


\begin{table}[!ht]
  \caption{Robustness against white-box, black-box attacks and Auto-Attack (AA) on CIFAR100. Black-box attacks are generated using naturally trained surrogate model. Natural represents the naturally trained (non-adversarial) model.
  %and applied to the best performing robust models.
  }
  \vskip 0.1in
  \label{black-and_white-cifar100}
  \centering
  \small
  \begin{tabular}{l@{\hspace{1\tabcolsep}}c@{\hspace{1\tabcolsep}}c@{\hspace{1\tabcolsep}}c@{\hspace{1\tabcolsep}}c@{\hspace{1\tabcolsep}}c@{\hspace{1\tabcolsep}}c@{\hspace{1\tabcolsep}}c@{\hspace{1\tabcolsep}}c@{\hspace{1\tabcolsep}}c@{\hspace{1\tabcolsep}}c}
    \toprule
    & & \multicolumn{4}{c}{White-box} & \multicolumn{4}{c}{Black-Box}  \\
    \cmidrule(r){3-6} 
    \cmidrule(r){7-10}
    Defense Model & Natural & PGD$^{20}$ & PGD$^{100}$  & PGD$^{1000}$  & CW$^{\infty}$ & PGD$^{20}$ & PGD$^{100}$ & PGD$^{1000}$  & CW$^{\infty}$ & AA \\
    \midrule
    NATURAL & 79.30 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
    \midrule
    AT & 56.73 & 29.57 & 28.45 & 28.39 & 26.6 & 55.52 & 55.29 & 55.26 & 55.40 & 24.12 \\
    % TRADES & 58.24 & 30.10 & 29.66 & 29.64 & 25.97 & 57.05 & 56.71 & 56.67 & 56.77 & 24.92 \\
    $\DIAL_{\kl}$ (Ours) & 58.47 & \textbf{31.19} & \textbf{30.50} & \textbf{30.42} & \textbf{26.91} & 57.16 & 56.81 & 56.80 & 57.00 & \textbf{25.87} \\
    $\DIAL_{\ce}$ (Ours) & \textbf{60.77} & 27.87 & 26.66 & 26.61 & 25.98 & \textbf{59.48} & \textbf{59.06} & \textbf{58.96} & \textbf{59.20} & 23.51  \\
    \bottomrule
  \end{tabular}
\end{table}


% \begin{table}[!ht]
%   \caption{Robustness comparison of DIAL to Madry et al. and TRADES defense models on the SVHN dataset under different PGD white-box attacks and the ensemble Auto-Attack (AA).}
%   \label{svhn}
%   \centering
%   \begin{tabular}{llllll|l}
%     \toprule
%     \cmidrule(r){1-5}
%     Defense Model & Natural & PGD$^{20}$ & PGD$^{100}$ & PGD$^{1000}$ & CW$_{\infty}$ & AA\\
%     \midrule
%     $\DIAL_{\kl}$ (Ours) & $\mathbf{90.66}$ & $\mathbf{58.91}$ & $\mathbf{55.30}$ & $\mathbf{55.12}$ & $\mathbf{53.67}$  & $\mathbf{51.00}$  \\
%     Madry et al. & 89.90 & 53.23 & 49.45 & 49.23 & 48.25 & 45.25  \\
%     TRADES & 90.35 & 57.10 & 54.13 & 54.08 & 52.19 & 49.50 \\
%     \bottomrule
%   \end{tabular}
% \end{table}


\subsection{Performance comparison on CIFAR-10} \label{defence-settings}
In this part, we evaluate the performance of DIAL compared to other well-known methods on CIFAR-10. 
%To be consistent with other methods, 
We follow the same experiment setups as in~\cite{madry2017towards, wang2019improving, zhang2019theoretically}. When experiment settings are not identical between tested methods, we choose the most commonly used settings, and apply it to all experiments. This way, we keep the comparison as fair as possible and avoid reporting changes in results which are caused by inconsistent experiment settings \citep{pang2020bag}. To show that our results are not caused because of what is referred to as \textit{obfuscated gradients}~\citep{athalye2018obfuscated}, we evaluate our method with same setup as in our defense model, under strong attacks (e.g., PGD$^{1000}$) in both white-box, black-box settings, Auto-Attack ~\citep{croce2020reliable}, unforeseen "natural" corruptions~\citep{hendrycks2018benchmarking}, and unforeseen adversaries. To make sure that the reported improvements are not caused by \textit{adversarial overfitting}~\citep{rice2020overfitting}, we report best robust results for each method on average of 3 restarts, while omitting one standard deviation (which is smaller than 0.2\% in all experiments). Additional results for CIFAR-10 as well as comprehensive evaluation on MNIST can be found in Appendix \ref{mnist-results} and \ref{additional_res}.
%To further keep the comparison consistent, we followed the same attack settings for all methods.


\begin{table}[ht]
  \caption{Robustness against white-box, black-box attacks and Auto-Attack (AA) on CIFAR-10. Black-box attacks are generated using naturally trained surrogate model. Natural represents the naturally trained (non-adversarial) model.
  %and applied to the best performing robust models.
  }
  \vskip 0.1in
  \label{black-and_white-cifar}
  \centering
  \small
  \begin{tabular}{cccccccc@{\hspace{1\tabcolsep}}c}
    \toprule
    & & \multicolumn{3}{c}{White-box} & \multicolumn{3}{c}{Black-Box} \\
    \cmidrule(r){3-5} 
    \cmidrule(r){6-8}
    Defense Model & Natural & PGD$^{20}$ & PGD$^{100}$ & CW$^{\infty}$ & PGD$^{20}$ & PGD$^{100}$ & CW$^{\infty}$ & AA \\
    \midrule
    NATURAL & 95.43 & 0 & 0 & 0 & 0 & 0 & 0 &  0 \\
    \midrule
    TRADES & 84.92 & 56.60 & 55.56 & 54.20 & 84.08 & 83.89 & 83.91 &  53.08 \\
    MART & 83.62 & 58.12 & 56.48 & 53.09 & 82.82 & 82.52 & 82.80 & 51.10 \\
    AT & 85.10 & 56.28 & 54.46 & 53.99 & 84.22 & 84.14 & 83.92 & 51.52 \\
    ATDA & 76.91 & 43.27 & 41.13 & 41.01 & 75.59 & 75.37 & 75.35 & 40.08\\
    $\DIAL_{\kl}$ (Ours) & 85.25 & $\mathbf{58.43}$ & $\mathbf{56.80}$ & $\mathbf{55.00}$ & 84.30 & 84.18 & 84.05 & \textbf{53.75} \\
    $\DIAL_{\ce}$ (Ours)  & $\mathbf{89.59}$ & 54.31 & 51.67 & 52.04 &$ \mathbf{88.60}$ & $\mathbf{88.39}$ & $\mathbf{88.44}$ & 49.85 \\
    \midrule
    $\DIAL_{\awp}$ (Ours) & $\mathbf{85.91}$ & $\mathbf{61.10}$ & $\mathbf{59.86}$ & $\mathbf{57.67}$ & $\mathbf{85.13}$ & $\mathbf{84.93}$ & $\mathbf{85.03}$  & \textbf{56.78} \\
    $\TRADES_{\awp}$ & 85.36 & 59.27 & 59.12 & 57.07 & 84.58 & 84.58 & 84.59 & 56.17 \\
    \bottomrule
  \end{tabular}
\end{table}



\paragraph{CIFAR-10 setup.} We use the wide residual network (WRN-34-10)~\citep{zagoruyko2016wide} architecture. %used in the experiments of~\cite{madry2017towards, wang2019improving, zhang2019theoretically}. 
Sidelong this architecture, we integrate a domain classification layer. To generate the adversarial domain dataset, we use a perturbation size of $\epsilon=0.031$. We apply 10 of inner maximization iterations with perturbation step size of 0.007. Batch size is set to 128, weight decay is set to $7e^{-4}$, and the model is trained for 100 epochs. Similar to the other methods, the initial learning rate was set to 0.1, and decays by a factor of 10 at iterations 75 and 90. 
%For being consistent with other methods, the natural images are padded with 4-pixel padding with 32-random crop and random horizontal flip. Furthermore, all methods are trained using SGD with momentum 0.9. For $\DIAL_{\kl}$, we balance the robust loss with $\lambda=6$ and the domains loss with $r=4$. For $\DIAL_{\ce}$, we balance the robust loss with $\lambda=1$ and the domains loss with $r=2$. 
%We also introduce a version of our method that incorporates the AWP double-perturbation mechanism, named DIAL-AWP.
%which is trained using the same learning rate schedule used in ~\cite{wu2020adversarial}, where the initial 0.1 learning rate decays by a factor of 10 after 100 and 150 iterations. 
See Appendix \ref{cifar10-additional-setup} for additional details.

\begin{table}[ht]
  \caption{Black-box attack using the adversarially trained surrogate models on CIFAR-10.}
  \vskip 0.1in
  \label{black-box-cifar-adv}
  \centering
  \small
  \begin{tabular}{ll|c}
    \toprule
    \cmidrule(r){1-2}
    Surrogate (source) model & Target model & robustness \% \\
    % \midrule
    \midrule
    TRADES & $\DIAL_{\ce}$ & $\mathbf{67.77}$ \\
    $\DIAL_{\ce}$ & TRADES & 65.75 \\
    \midrule
    MART & $\DIAL_{\ce}$ & $\mathbf{70.30}$ \\
    $\DIAL_{\ce}$ & MART & 64.91 \\
    \midrule
    AT & $\DIAL_{\ce}$ & $\mathbf{65.32}$ \\
    $\DIAL_{\ce}$ & AT  & 63.54 \\
    \midrule
    ATDA & $\DIAL_{\ce}$ & $\mathbf{66.77}$ \\
    $\DIAL_{\ce}$ & ATDA & 52.56 \\
    \bottomrule
  \end{tabular}
\end{table}

\paragraph{White-box/Black-box robustness.} 
%We evaluate all defense models using Auto-Attack, PGD$^{20}$, PGD$^{100}$, PGD$^{1000}$ and CW$_{\infty}$ with step size 0.003. We constrain all attacks by the same perturbation $\epsilon=0.031$. 
As reported in Table~\ref{black-and_white-cifar} and Appendix~\ref{additional_res}, our method achieves better robustness compared to the other methods. Specifically, in the white-box settings, our method improves robustness over~\citet{madry2017towards} and TRADES by 2\% 
%using the common PGD$^{20}$ attack 
while keeping higher natural accuracy. We also observe better natural accuracy of 1.65\% over MART while also achieving better robustness over all attacks. Moreover, our method presents significant improvement of up to 15\% compared to the the domain invariant method suggested by~\citet{song2018improving} (ATDA).
%in both natural and robust accuracy. 
When incorporating 
%the double-perturbation mechanism of 
AWP, our method improves the results of $\TRADES_{\awp}$ by almost 2\%.
%and reaches state-of-the-art results for robust models with no additional data. 
% Additional results are available in Appendix~\ref{additional_res}.
When tested on black-box settings, $\DIAL_{\ce}$ presents a significant improvement of more than 4.4\% over the second-best performing method, and up to 13\%. In Table~\ref{black-box-cifar-adv}, we also present the black-box results when the source model is taken from one of the adversarially trained models. %Then, we compare our model to each one of them both as the source model and target model. 
In addition to the improvement in black-box robustness, $\DIAL_{\ce}$ also manages to achieve better clean accuracy of more than 4.5\% over the second-best performing method.
% Moreover, based on the auto-attack leader-board \footnote{\url{https://github.com/fra31/auto-attack}}, our method achieves the 1st place among models without additional data using the WRN-34-10 architecture.

% \begin{table}
%   \caption{White-box robustness on CIFAR-10 using WRN-34-10}
%   \label{white-box-cifar-10}
%   \centering
%   \begin{tabular}{lllll}
%     \toprule
%     \cmidrule(r){1-2}
%     Defense Model & Natural & PGD$^{20}$ & PGD$^{100}$ & PGD$^{1000}$ \\
%     \midrule
%     TRADES ~\cite{zhang2019theoretically} & 84.92  & 56.6 & 55.56 & 56.43  \\
%     MART ~\cite{wang2019improving} & 83.62  & 58.12 & 56.48 & 56.55  \\
%     Madry et al. ~\cite{madry2017towards} & 85.1  & 56.28 & 54.46 & 54.4  \\
%     Song et al. ~\cite{song2018improving} & 76.91 & 43.27 & 41.13 & 41.02  \\
%     $\DIAL_{\ce}$ (Ours) & $ \mathbf{90}$  & 52.12 & 48.88 & 48.78  \\
%     $\DIAL_{\kl}$ (Ours) & 85.25 & $\mathbf{58.43}$ & $\mathbf{56.8}$ & $\mathbf{56.73}$ \\
%     \midrule
%     $\DIAL_{\kl}$+AWP (Ours) & $\mathbf{85.91}$ & $\mathbf{61.1}$ & - & -  \\
%     TRADES+AWP \cite{wu2020adversarial} & 85.36 & 59.27 & 59.12 & -  \\
%     % MART + AWP & 84.43 & 60.68 & 59.32 & -  \\
%     \bottomrule
%   \end{tabular}
% \end{table}


% \begin{table}
%   \caption{White-box robustness on MNIST}
%   \label{white-box-mnist}
%   \centering
%   \begin{tabular}{llllll}
%     \toprule
%     \cmidrule(r){1-2}
%     Defense Model & Natural & PGD$^{40}$ & PGD$^{100}$ & PGD$^{1000}$ \\
%     \midrule
%     TRADES ~\cite{zhang2019theoretically} & 99.48 & 96.07 & 95.52 & 95.22 \\
%     MART ~\cite{wang2019improving} & 99.38  & 96.99 & 96.11 & 95.74  \\
%     Madry et al. ~\cite{madry2017towards} & 99.41  & 96.01 & 95.49 & 95.36 \\
%     Song et al. ~\cite{song2018improving}  & 98.72 & 96.82 & 96.26 & 96.2  \\
%     $\DIAL_{\kl}$ (Ours) & 99.46 & 97.05 & 96.06 & 95.99  \\
%     $\DIAL_{\ce}$ (Ours) & $\mathbf{99.49}$  & $\mathbf{97.38}$ & $\mathbf{96.45}$ & $\mathbf{96.33}$ \\
%     \bottomrule
%   \end{tabular}
% \end{table}


% \paragraph{Attacking MNIST.} For consistency, we use the same perturbation and step sizes. For MNIST, we use $\epsilon=0.3$ and step size of $0.01$. The natural accuracy of our surrogate (source) model is 99.51\%. Attacks results are reported in Table~\ref{black-and_white-mnist}. It is worth noting that the improvement margin is not conclusive on MNIST as it is on CIFAR-10, which is a more complex task.

% \begin{table}
%   \caption{Black-box robustness on MNIST and CIFAR-10 using naturally trained surrogate model and best performing robust models}
%   \label{black-box-mnist-cifar}
%   \centering
%   \begin{tabular}{lllllll}
%     \toprule
%     & \multicolumn{3}{c}{MNIST} & \multicolumn{3}{c}{CIFAR-10} \\
%     \cmidrule(r){2-4} 
%     \cmidrule(r){5-7}  
%     Defense Model & PGD$^{40}$ & PGD$^{100}$ & PGD$^{1000}$ & PGD$^{20}$ & PGD$^{100}$ & PGD$^{1000}$ \\
%     \midrule
%     TRADES ~\cite{zhang2019theoretically} & 98.12 & 97.86 & 97.81 & 84.08 & 83.89 & 83.8 \\
%     MART ~\cite{wang2019improving} & 98.16 & 97.96 & 97.89  & 82.82 & 82.52 & 82.47 \\
%     Madry et al. ~\cite{madry2017towards}  & 98.05 & 97.73 & 97.78 & 84.22 & 84.14 & 83.96 \\
%     Song et al. ~\cite{song2018improving} & 97.74 & 97.28 & 97.34 & 75.59 & 75.37 & 75.11 \\
%     $\DIAL_{\kl}$ (Ours) & 98.14 & 97.83 & 97.87  & 84.3 & 84.18 & 84.0 \\
%     $\DIAL_{\ce}$ (Ours)  & $\mathbf{98.37}$ & $\mathbf{98.12}$ & $\mathbf{98.05}$  & $\mathbf{89.13}$ & $\mathbf{88.89}$ & $\mathbf{88.78}$ \\
%     \bottomrule
%   \end{tabular}
% \end{table}



% \subsubsection{Ensemble attack} In addition to the white-box and black-box settings, we evaluate our method on the Auto-Attack ~\citep{croce2020reliable} using $\ell_{\infty}$ threat model with perturbation $\epsilon=0.031$. Auto-Attack is an ensemble of parameter-free attacks. It consists of three white-box attacks: APGD-CE which is a step size-free version of PGD on the cross-entropy ~\citep{croce2020reliable}. APGD-DLR which is a step size-free version of PGD on the DLR loss ~\citep{croce2020reliable} and FAB which  minimizes the norm of the adversarial perturbations, and one black-box attack: square attack which is a query-efficient black-box attack ~\citep{andriushchenko2020square}. Results are presented in Table~\ref{auto-attack}. Based on the auto-attack leader-board \footnote{\url{https://github.com/fra31/auto-attack}}, our method achieves the 1st place among models without additional data using the WRN-34-10 architecture.

%Additional results can be found in Appendix ~\ref{additional_res}.

% \begin{table}
%   \caption{Auto-Attack (AA) on CIFAR-10 with perturbation size $\epsilon=0.031$ with $\ell_{\infty}$ threat model}
%   \label{auto-attack}
%   \centering
%   \begin{tabular}{lll}
%     \toprule
%     \cmidrule(r){1-2}
%     Defense Model & AA \\
%     \midrule
%     TRADES ~\cite{zhang2019theoretically} & 53.08  \\
%     MART ~\cite{wang2019improving} & 51.1  \\
%     Madry et al. ~\cite{madry2017towards} & 51.52    \\
%     Song et al.   ~\cite{song2018improving} & 40.18 \\
%     $\DIAL_{\ce}$ (Ours) & 47.33  \\
%     $\DIAL_{\kl}$ (Ours) & $\mathbf{53.75}$ \\
%     \midrule
%     DIAL-AWP (Ours) & $\mathbf{56.78}$ \\
%     TRADES-AWP \cite{wu2020adversarial} & 56.17 \\
%     \bottomrule
%   \end{tabular}
% \end{table}


% \begin{table}[!ht]
%   \caption{Auto-Attack (AA) Robustness (\%) on CIFAR-10 with $\epsilon=0.031$ using an $\ell_{\infty}$ threat model}
%   \label{auto-attack}
%   \centering
%   \begin{tabular}{cccccc|cc}
%     \toprule
%     % \multicolumn{8}{c}{Defence Model}  \\
%     % \cmidrule(r){1-8} 
%     TRADES & MART & Madry & Song & $\DIAL_{\ce}$ & $\DIAL_{\kl}$ & DIAL-AWP  & TRADES-AWP\\
%     \midrule
%     53.08 & 51.10 & 51.52 &  40.08 & 47.33  & $\mathbf{53.75}$ & $\mathbf{56.78}$ & 56.17 \\

%     \bottomrule
%   \end{tabular}
% \end{table}

% \begin{table}[!ht]
% \caption{$F_1$-robust measurement using PGD$^{20}$ attack in white-box and black-box settings on CIFAR-10}
%   \label{f1-robust}
%   \centering
%   \begin{tabular}{ccccccc|cc}
%     \toprule
%     % \multicolumn{8}{c}{Defence Model}  \\
%     % \cmidrule(r){1-8} 
%     Defense Model & TRADES & MART & Madry & Song & $\DIAL_{\kl}$ & $\DIAL_{\ce}$ & DIAL-AWP  & TRADES-AWP\\
%     \midrule
%     White-box & 0.659 & 0.666 & 0.657 & 0.518 & $\mathbf{0.675}$  & 0.643 & $\mathbf{0.698}$ & 0.682 \\
%     Black-box & 0.844 & 0.831 & 0.846 & 0.761 & 0.847 & $\mathbf{0.895}$ & $\mathbf{0.854}$ &  0.849 \\
%     \bottomrule
%   \end{tabular}
% \end{table}

\subsubsection{Robustness to Unforeseen Attacks and Corruptions}
\paragraph{Unforeseen Adversaries.} To further demonstrate the effectiveness of our approach, we test our method against various adversaries that were not used during the training process. We attack the model under the white-box settings with $\ell_{2}$-PGD, $\ell_{1}$-PGD, $\ell_{\infty}$-DeepFool and $\ell_{2}$-DeepFool \citep{moosavi2016deepfool} adversaries using Foolbox \citep{rauber2017foolbox}. We applied commonly used attack budget 
%(perturbation for PGD adversaries and overshot for DeepFool adversaries) 
with 20 and 50 iterations for PGD and DeepFool, respectively.
Results are presented in Table \ref{unseen-attacks}. As can be seen, our approach  gains an improvement of up to 4.73\% over the second best method under the various attack types and an average improvement of 3.7\% over all threat models.


\begin{table}[ht]
  \caption{Robustness on CIFAR-10 against unseen adversaries under white-box settings.}
  \vskip 0.1in
  \label{unseen-attacks}
  \centering
%   \small
  \begin{tabular}{c@{\hspace{1.5\tabcolsep}}c@{\hspace{1.5\tabcolsep}}c@{\hspace{1.5\tabcolsep}}c@{\hspace{1.5\tabcolsep}}c@{\hspace{1.5\tabcolsep}}c@{\hspace{1.5\tabcolsep}}c@{\hspace{1.5\tabcolsep}}c}
    \toprule
    Threat Model & Attack Constraints & $\DIAL_{\kl}$ & $\DIAL_{\ce}$ & AT & TRADES & MART & ATDA \\
    \midrule
    \multirow{2}{*}{$\ell_{2}$-PGD} & $\epsilon=0.5$ & 76.05 & \textbf{80.51} & 76.82 & 76.57 & 75.07 & 66.25 \\
    & $\epsilon=0.25$ & 80.98 & \textbf{85.38} & 81.41 & 81.10 & 80.04 & 71.87 \\\midrule
    \multirow{2}{*}{$\ell_{1}$-PGD} & $\epsilon=12$ & 74.84 & \textbf{80.00} & 76.17 & 75.52 & 75.95 & 65.76 \\
    & $\epsilon=7.84$ & 78.69 & \textbf{83.62} & 79.86 & 79.16 & 78.55 & 69.97 \\
    \midrule
    $\ell_{2}$-DeepFool & overshoot=0.02 & 84.53 & \textbf{88.88} & 84.15 & 84.23 & 82.96 & 76.08 \\\midrule
    $\ell_{\infty}$-DeepFool & overshoot=0.02 & 68.43 & \textbf{69.50} & 67.29 & 67.60 & 66.40 & 57.35 \\
    \bottomrule
  \end{tabular}
\end{table}


%%%%%%%%%%%%%%%%%%%%%%%%% conference version %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph{Unforeseen Corruptions.}
We further demonstrate that our method consistently holds against unforeseen ``natural'' corruptions, consists of 18 unforeseen diverse corruption types proposed by \citet{hendrycks2018benchmarking} on CIFAR-10, which we refer to as CIFAR10-C. The CIFAR10-C benchmark covers noise, blur, weather, and digital categories. As can be shown in Figure \ref{corruption}, our method gains a significant and consistent improvement over all the other methods. Our method leads to an average improvement of 4.7\% with minimum improvement of 3.5\% and maximum improvement of 5.9\% compared to the second best method over all unforeseen attacks. See Appendix \ref{corruptions-apendix} for the full experiment results.


\begin{figure}[h]
 \centering
  \includegraphics[width=0.4\textwidth]{figures/spider_full.png}
%   \caption{Summary of accuracy over all unforeseen corruptions compared to the second and third best performing methods.}
  \caption{Accuracy comparison over all unforeseen corruptions.}
  \label{corruption}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%% conference version %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%% Arxiv version %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \newpage
% \paragraph{Unforeseen Corruptions.}
% We further demonstrate that our method consistently holds against unforeseen "natural" corruptions, consists of 18 unforeseen diverse corruption types proposed by \cite{hendrycks2018benchmarking} on CIFAR-10, which we refer to as CIFAR10-C. The CIFAR10-C benchmark covers noise, blur, weather, and digital categories. As can be shown in Figure  \ref{spider-full-graph}, our method gains a significant and consistent improvement over all the other methods. Our approach leads to an average improvement of 4.7\% with minimum improvement of 3.5\% and maximum improvement of 5.9\% compared to the second best method over all unforeseen attacks. Full accuracy results against unforeseen corruptions are presented in Tables \ref{corruption-table1} and \ref{corruption-table2}. 

% \begin{table}[!ht]
%   \caption{Accuracy (\%) against unforeseen corruptions.}
%   \label{corruption-table1}
%   \centering
%   \tiny
%   \begin{tabular}{lcccccccccccccccccc}
%     \toprule
%     Defense Model & brightness & defocus blur & fog & glass blur & jpeg compression & motion blur & saturate & snow & speckle noise  \\
%     \midrule
%     TRADES & 82.63 & 80.04 & 60.19 & 78.00 & 82.81 & 76.49 & 81.53 & 80.68 & 80.14 \\
%     MART & 80.76 & 78.62 & 56.78 & 76.60 & 81.26 & 74.58 & 80.74 & 78.22 & 79.42 \\
%     AT &  83.30 & 80.42 & 60.22 & 77.90 & 82.73 & 76.64 & 82.31 & 80.37 & 80.74 \\
%     ATDA & 72.67 & 69.36 & 45.52 & 64.88 & 73.22 & 63.47 & 72.07 & 68.76 & 72.27 \\
%     DIAL (Ours)  & \textbf{87.14} & \textbf{84.84} & \textbf{66.08} & \textbf{81.82} & \textbf{87.07} & \textbf{81.20} & \textbf{86.45} & \textbf{84.18} & \textbf{84.94} \\
%     \bottomrule
%   \end{tabular}
% \end{table}


% \begin{table}[!ht]
%   \caption{Accuracy (\%) against unforeseen corruptions.}
%   \label{corruption-table2}
%   \centering
%   \tiny
%   \begin{tabular}{lcccccccccccccccccc}
%     \toprule
%     Defense Model & contrast & elastic transform & frost & gaussian noise & impulse noise & pixelate & shot noise & spatter & zoom blur \\
%     \midrule
%     TRADES & 43.11 & 79.11 & 76.45 & 79.21 & 73.72 & 82.73 & 80.42 & 80.72 & 78.97 \\
%     MART & 41.22 & 77.77 & 73.07 & 78.30 & 74.97 & 81.31 & 79.53 & 79.28 & 77.8 \\
%     AT & 43.30 & 79.58 & 77.53 & 79.47 & 73.76 & 82.78 & 80.86 & 80.49 & 79.58 \\
%     ATDA & 36.06 & 67.06 & 62.56 & 70.33 & 64.63 & 73.46 & 72.28 & 70.50 & 67.31 \\
%     DIAL (Ours) & \textbf{48.84} & \textbf{84.13} & \textbf{81.76} & \textbf{83.76} & \textbf{78.26} & \textbf{87.24} & \textbf{85.13} & \textbf{84.84} & \textbf{83.93}  \\
%     \bottomrule
%   \end{tabular}
% \end{table}


% \begin{figure}[!ht]
%   \centering
%   \includegraphics[width=9cm]{figures/spider_full.png}
%   \caption{Accuracy comparison with all tested methods over unforeseen corruptions.}
%   \label{spider-full-graph}
% \end{figure}
% %%%%%%%%%%%%%%%%%%%%%%%%% Arxiv version %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%% Arxiv version %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Transfer Learning}
Recent works \citep{salman2020adversarially,utrera2020adversarially} suggested that robust models transfer better on standard downstream classification tasks. In Table \ref{transfer-res} we demonstrate the advantage of our method when applied for transfer learning across CIFAR10 and CIFAR100 using the common linear evaluation protocol. see Appendix \ref{transfer-learning-settings} for detailed settings.

\begin{table}[H]
  \caption{Transfer learning results comparison.}
  \vskip 0.1in
  \label{transfer-res}
  \centering
  \small
\begin{tabular}{c|c|c|c}
\toprule

\multicolumn{2}{l}{} & \multicolumn{2}{c}{Target} \\
\cmidrule(r){3-4}
Source & Defence Model & CIFAR10 & CIFAR100 \\
\midrule
\multirow{3}{*}{CIFAR10} & DIAL & \multirow{3}{*}{-} & \textbf{28.57} \\
 & AT &  & 26.95  \\
 & TRADES &  & 25.40  \\
 \midrule
\multirow{3}{*}{CIFAR100} & DIAL & \textbf{73.68} & \multirow{3}{*}{-} \\
 & AT & 71.41 & \\
 & TRADES & 71.42 &  \\
%  \midrule
% \multirow{3}{}{SVHN} & DIAL &  &  & \multirow{3}{}{-} \\
%  & Madry et al. &  &  &  \\
%  & TRADES &  &  &  \\ 
\bottomrule
\end{tabular}
\end{table}


\subsubsection{Modularity and Ablation Studies}

We note that the domain classifier is a modular component that can be integrated into existing models for further improvements. Removing the domain head and related loss components from the different DIAL formulations results in some common adversarial training techniques. For $\DIAL_{\kl}$, removing the domain and related loss components results in the formulation of TRADES. For $\DIAL_{\ce}$, removing the domain and related loss components results in the original formulation of the standard adversarial training, and for $\DIAL_{\awp}$ the removal results in $\TRADES_{\awp}$. Therefore, the ablation studies will demonstrate the effectiveness of combining DIAL on top of different adversarial training methods. 

We investigate the contribution of the additional domain head component introduced in our method. Experiment configuration are as in \ref{defence-settings}, and robust accuracy is based on white-box PGD$^{20}$ on CIFAR-10 dataset. We remove the domain head from both $\DIAL_{\kl}$, $\DIAL_{\awp}$, and $\DIAL_{\ce}$ (equivalent to $r=0$) and report the natural and robust accuracy. We perform 3 random restarts and omit one standard deviation from the results. Results are presented in Figure \ref{ablation}. All DIAL variants exhibits stable improvements on both natural accuracy and robust accuracy. $\DIAL_{\ce}$, $\DIAL_{\kl}$, and $\DIAL_{\awp}$ present an improvement of 1.82\%, 0.33\%, and 0.55\% on natural accuracy and an improvement of 2.5\%, 1.87\%, and 0.83\% on robust accuracy, respectively. This evaluation empirically demonstrates the benefits of incorporating DIAL on top of different adversarial training techniques.
% \paragraph{semi-supervised extensions.} Since the domain classifier does not require the class labels, we argue that additional unlabeled data can be leveraged in future work.
%for improved results. 

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.35\textwidth]{figures/ablation_graphs3.png}
  \caption{Ablation studies for $\DIAL_{\kl}$, $\DIAL_{\ce}$, and $\DIAL_{\awp}$ on CIFAR-10. Circle represent the robust-natural accuracy without using DIAL, and square represent the robust-natural accuracy when incorporating DIAL.
  %to further investigate the impact of the domain head and loss on natural and robust accuracy.
  }
  \label{ablation}
\end{figure}

\subsubsection{Visualizing DIAL}
To further illustrate the superiority of our method, we visualize the model outputs from the different methods on both natural and adversarial test data.
% adversarial test data generated using PGD$^{20}$ white-box attack with step size 0.003 and $\epsilon=0.031$ on CIFAR-10. 
Figure~\ref{tsne1} shows the embedding received after applying t-SNE ~\citep{van2008visualizing} with two components on the model output for our method and for TRADES. DIAL seems to preserve strong separation between classes on both natural test data and adversarial test data. Additional illustrations for the other methods are attached in Appendix~\ref{additional_viz}. 

\begin{figure}[h]
\centering
  \subfigure[\textbf{DIAL} on natural logits]{\includegraphics[width=0.21\textwidth]{figures/domain_ce_test.png}}
  \hspace{0.03\textwidth}
  \subfigure[\textbf{DIAL} on adversarial logits]{\includegraphics[width=0.21\textwidth]{figures/domain_ce_adversarial.png}}
  \hspace{0.03\textwidth}
    \subfigure[\textbf{TRADES} on natural logits]{\includegraphics[width=0.21\textwidth]{figures/trades_test.png}}
    \hspace{0.03\textwidth}
    \subfigure[\textbf{TRADES} on adversarial logits]{\includegraphics[width=0.21\textwidth]{figures/trades_adversarial.png}}
  \caption{t-SNE embedding of model output (logits) into two-dimensional space for DIAL and TRADES using the CIFAR-10 natural test data and the corresponding PGD$^{20}$ generated adversarial examples.}
  \label{tsne1}
\end{figure}


% \begin{figure}[ht]
% \centering
%   \begin{subfigure}{4cm}
%     \centering\includegraphics[width=3.3cm]{figures/domain_ce_test.png}
%     \caption{\textbf{DIAL} on nat. examples}
%   \end{subfigure}
%   \begin{subfigure}{4cm}
%     \centering\includegraphics[width=3.3cm]{figures/domain_ce_adversarial.png}
%     \caption{\textbf{DIAL} on adv. examples}
%   \end{subfigure}
  
%   \begin{subfigure}{4cm}
%     \centering\includegraphics[width=3.3cm]{figures/trades_test.png}
%     \caption{\textbf{TRADES} on nat. examples}
%   \end{subfigure}
%   \begin{subfigure}{4cm}
%     \centering\includegraphics[width=3.3cm]{figures/trades_adversarial.png}
%     \caption{\textbf{TRADES} on adv. examples}
%   \end{subfigure}
%   \caption{t-SNE embedding of model output (logits) into two-dimensional space for DIAL and TRADES using the CIFAR-10 natural test data and the corresponding adversarial examples.}
%   \label{tsne1}
% \end{figure}



% \begin{figure}[ht]
% \centering
%   \begin{subfigure}{6cm}
%     \centering\includegraphics[width=5cm]{figures/domain_ce_test.png}
%     \caption{\textbf{DIAL} on nat. examples}
%   \end{subfigure}
%   \begin{subfigure}{6cm}
%     \centering\includegraphics[width=5cm]{figures/domain_ce_adversarial.png}
%     \caption{\textbf{DIAL} on adv. examples}
%   \end{subfigure}
  
%   \begin{subfigure}{6cm}
%     \centering\includegraphics[width=5cm]{figures/trades_test.png}
%     \caption{\textbf{TRADES} on nat. examples}
%   \end{subfigure}
%   \begin{subfigure}{6cm}
%     \centering\includegraphics[width=5cm]{figures/trades_adversarial.png}
%     \caption{\textbf{TRADES} on adv. examples}
%   \end{subfigure}
%   \caption{t-SNE embedding of model output (logits) into two-dimensional space for DIAL and TRADES using the CIFAR-10 natural test data and the corresponding adversarial examples.}
%   \label{tsne1}
% \end{figure}



\subsection{Balanced measurement for robust-natural accuracy}
One of the goals of our method is to better balance between robust and natural accuracy under a given model. For a balanced metric, we adopt the idea of $F_1$-score, which is the harmonic mean between the precision and recall. However, rather than using precision and recall, we measure the $F_1$-score between robustness and natural accuracy,
using a measure we call
%We named it
the
\textbf{$\mathbf{F_1}$-robust} score.
\begin{equation}
F_1\text{-robust} = \dfrac{\text{true\_robust}}
{\text{true\_robust}+\frac{1}{2}
%\cdot
(\text{false\_{robust}}+
\text{false\_natural})},
\end{equation}
where $\text{true\_robust}$ are the adversarial examples that were correctly classified, $\text{false\_{robust}}$ are the adversarial examples that were miss-classified, and $\text{false\_natural}$ are the natural examples that were miss-classified.
%We tested the proposed $F_1$-robust score using PGD$^{20}$ on CIFAR-10 dataset in white-box and black-box settings. 
Results are presented in Table~\ref{f1-robust} and demonstrate that our method achieves the best $F_1$-robust score in both settings, which supports our findings from previous sections.

% \begin{table}[!ht]
%   \caption{$F_1$-robust measurement using PGD$^{20}$ attack in white and black box settings on CIFAR-10}
%   \label{f1-robust}
%   \centering
%   \begin{tabular}{lll}
%     \toprule
%     \cmidrule(r){1-2}
%     Defense Model & White-box & Black-box \\
%     \midrule
%     TRADES & 0.65937  & 0.84435 \\
%     MART & 0.66613  & 0.83153  \\
%     Madry et al. & 0.65755 & 0.84574   \\
%     Song et al. & 0.51823 & 0.76092  \\
%     $\DIAL_{\ce}$ (Ours) & 0.65318   & $\mathbf{0.88806}$  \\
%     $\DIAL_{\kl}$ (Ours) & $\mathbf{0.67479}$ & 0.84702 \\
%     \midrule
%     \midrule
%     DIAL-AWP (Ours) & $\mathbf{0.69753}$  & $\mathbf{0.85406}$  \\
%     TRADES-AWP & 0.68162 & 0.84917 \\
%     \bottomrule
%   \end{tabular}
% \end{table}

\begin{table}[ht]
\small
  \caption{$F_1$-robust measurement using PGD$^{20}$ attack in white and black box settings on CIFAR-10.}
  \vskip 0.1in
  \label{f1-robust}
  \centering
%   \small
  \begin{tabular}{c
  @{\hspace{1.5\tabcolsep}}c @{\hspace{1.5\tabcolsep}}c @{\hspace{1.5\tabcolsep}}c @{\hspace{1.5\tabcolsep}}c
  @{\hspace{1.5\tabcolsep}}c @{\hspace{1.5\tabcolsep}}c @{\hspace{1.5\tabcolsep}}|
  @{\hspace{1.5\tabcolsep}}c
  @{\hspace{1.5\tabcolsep}}c}
    \toprule
    % \cmidrule(r){8-9}
     & TRADES & MART & AT & ATDA & $\DIAL_{\ce}$ & $\DIAL_{\kl}$ & $\DIAL_{\awp}$ & $\TRADES_{\awp}$ \\
    \midrule
    White-box & 0.659 & 0.666 & 0.657 & 0.518 & 0.660 & \textbf{0.675} & \textbf{0.698} & 0.682 \\
    Black-box & 0.844 & 0.831 & 0.845 & 0.761 & \textbf{0.890} & 0.847 & \textbf{0.854} & 0.849 \\ 
    \bottomrule
  \end{tabular}
\end{table}

\section{Related Work}
\label{sec:review}

% Subsequent works \cite{bloesch2018codeslam, zhi2019scenecode, sucar2020nodeslam} adopt a probabilistic formulation leading to a keyframe-based semantic mapping system that jointly estimates motion, geometry and semantics via a latent space representation\NA{latent space of what?}. 

Several RGB-D SLAM approaches \cite{newcombe2011kinectfusion, endres2012evaluation, kerl2013dense, endres20133, whelan2016elasticfusion} are able to generate accurate trajectory and a dense 3D model of the environment. However, early RGB-D SLAM techniques focus on obtaining a geometric map and overlook the semantics. 
Later, object-level SLAM approaches \cite{nicholson2018quadricslam, yang2019cubeslam} are proposed to model both geometry and semantics. Those works focus on estimating the object pose accurately, but have limited capabilities to model object shape details due to the very simple geometric shape models used, such as cuboids and quadrics.  

% commented out due to page limit 
% Subsequent attempts \cite{salas2013slam++, pillai2015monocular, slavcheva2016sdf, sunderhauf2017meaningful, nicholson2018quadricslam, xu2019mid, hu2019deep, nellithimaru2019rols, fenglocalization} model objects explicitly in RGB-D SLAM to attain both compactness and expressiveness. 
% For instance, SLAM++ \cite{salas2013slam++} enforces camera-object constraints based on prior object CAD models in the pose-graph optimization for SLAM, and the object-graph enables camera tracking via Iterative closest point (ICP). 
% An object-centric RGB-D SLAM algorithm capable of generating instance-level segmentation is proposed in \cite{sunderhauf2017meaningful}, which does not rely on a priori object models used in SLAM++. This work uses the RGB-D version of ORB-SLAM \cite{mur2017orb} for camera pose tracking and mapping geometric entities. To segment out objects from RGB-D measurements, an adjacency graph connecting nearby supervoxels are constructed, which is then partitioned into connected components to identify objects.
% Deep-SLAM++ \cite{hu2019deep} presents the first room-scale object SLAM which integrates an object shape prior into the estimation, using a Kinect V2 sensor. Instead of point clouds the paper uses scalable binary occupancy grids, but those have a severely limited resolution. 

Compared with other similar works~\cite{Mescheder_2019_CVPR, Chen_2019_CVPR} on learning implicit function for surface, DeepSDF \cite{park2019deepsdf} learns a continuous metric function of distance instead of binary classification function dividing inside or outside, which makes it suitable for gradient-based optimization in SLAM. 
Subsequent works along the direction of DeepSDF include FroDO \cite{runz2020frodo}, MOLTR \cite{li2020mo}, and DualSDF \cite{hao2020dualsdf}. 
FroDO leverages both point cloud and SDF representations, which defines sparse and dense losses to optimize the object shape. 
An extension of FroDO is MOLTR, which reconstructs an object shape by fusing multiple single-view shape codes to handle both static and dynamic objects. 
Similar to the coarse-to-fine shape estimation in FroDO and MOLTR, DualSDF uses two levels of granularity to represent 3D shapes. A shared latent space is employed to tightly couple the two levels, and a Gaussian prior is imposed on the latent space to enable sampling, interpolation, and optimization-based manipulation.  
DeepSDF and the derivatives offer models for accurate shape modeling but few of them consider object pose estimation. 

Object pose estimation is a critical step in the construction of an object level map. 
To estimate the transformation between world frame and the object frame, Scan2CAD \cite{avetisyan2019scan2cad} estimates the object pose and scale by establishing keypoint correspondences between the objects in the scene and their 3D CAD models. The keypoints are annotated for the CAD models and predicted by CNNs during inference. The Harris keypoints are detected from the 3D scan to be matched with those keypoints on the CAD models. However, both keypoint annotation and model retrieval take a long time for objects with complicated shapes, such as sofa. Later on Avetisyan \etal\cite{avetisyan2019end} dramatically increased the efficiency of the alignment process by utilizing a novel differentiable Procrustes alignment loss. Firstly, a proposed 3D CNN is used to identify objects in the 3D scan. Secondly, object bounding boxes are used to establish correspondence between scan objects and the CAD models. Lastly, alignment-informed correspondences are learnt via the differentiable Procrustes alignment loss.
Furthermore, multi-view constraints are introduced in Vid2CAD \cite{maninis2020vid2cad}. 
% Object pose estimation could also be achieved using generic geometric representations, such as cuboids in CubeSLAM \cite{yang2019cubeslam} or ellipsoids in QuadricSLAM \cite{rubino20173d, nicholson2018quadricslam}. 
% FroDO uses \cite{nicholson2018quadricslam} to initialize the object pose, but it does not take object shape prior or occlusion into account. 

In the proposed ELLIPSDF, a learnt continuous SDF is used to reconstruct the object at arbitrary resolutions, and thus our approach has a more expressive object model in comparison to \cite{hu2019deep, sucar2020nodeslam}. 
Furthermore, our model has two levels of granularity that provide a coarse object prior to optimize the object scale, which is different from FroDO or \cite{afolabi2020extending}. 
Our system is online and more efficient, and unlike prior works that focus on single object estimation, we also present a large-scale, quantitative evaluation using a public benchmark that has multiple objects. 

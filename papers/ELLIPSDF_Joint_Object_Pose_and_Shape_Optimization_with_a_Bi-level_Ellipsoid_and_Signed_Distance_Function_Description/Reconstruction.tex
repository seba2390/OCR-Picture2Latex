





\section{Object Pose and Shape Optimization}
\label{sec:reconstruction}

This section develops ELLIPSDF, an autodecoder model for bi-level object shape representation. Sec.~\ref{sec:train_code} presents the model and defines the error functions for its parameter optimization. Sec.~\ref{sec:shape_pose_inference} describes how a trained ELLIPSDF model is used at test time for multi-view joint optimization of object pose and shape. An overview is shown in Fig.~\ref{fig:framework}.



%ELLIPSDF includes learning shape representation as well as joint pose and shape optimization, as shown in Fig.~\ref{fig:framework}. In Sec.~\ref{sec:train_code}, we introduce the two-level object model (Fig.~\ref{fig:two_level_model}). In Sec.~\ref{sec:shape_pose_inference}, we introduce our pose initialization with ellipsoids (Sec.~\ref{sec:pose_init}). Then, the object model is utilized for joint optimization with gradient descent (Sec.~\ref{sec:pose_shape_opt}). 
% uses neural networks for shape representation

% This section provides the details about how we train the ELLIPSDF two-level object model, and then covers the inference framework for multi-view object shape and pose initialization as well as optimization. Fig. \ref{fig:framework} demonstrates the framework of our approach.

%\subsection{Learning a Shared Shape Latent Space}

\subsection{Training an ELLIPSDF Model}
\label{sec:train_code}

%\subsubsection{Bi-level Shape Representation}
%\label{sec:model}

{\vspace{1ex}\bf \noindent Bi-level Shape Representation: }%
The ELLIPSDF shape model consists of two autodecoders $g_{\bfphi}(\bfz)$ and $f_{\bftheta}(\bfx,\bfz)$, using a shared latent code $\bfz \in \bbR^d$. The first autodecoder provides a \emph{coarse} shape representation with parameters $\bfphi$, as an axis-aligned ellipsoid $\calE_{\bfu}$ in a canonical coordinate frame with semi-axis lengths $\bfu = g_{\bfphi}(\bfz)$. The second autoencoder provides a \emph{fine} shape representation with parameters $\bftheta$, as an implicit SDF surface $\crl{\bfx \in \bbR^3 \mid f_{\bftheta}(\bfx,\bfz) \leq 0}$ in the same canonical coordinate frame. We implement $g_{\bfphi}(\bfz)$ and $f_{\bftheta}(\bfx,\bfz)$ as $8$-layer perceptrons with one cross-connection, as described in Sec.~D in the supplementary material of DualSDF \cite{hao2020dualsdf}. The reparametrization trick \cite{kingma2013auto} is used to maintain a Gaussian distribution $\bfz = \bfmu + \diag(\bfsigma) \bfepsilon$ over the latent code with $\bfepsilon \sim \mathcal{N}(\bf{0},\bf{I})$. Thus, at training time, the ELLIPSDF model parameters are the mean $\bfmu \in \bbR^d$ and standard deviation $\bfsigma \in \bbR^d$ of the latent shape code and the coarse and fine shape autodecoder parameters $\bfphi$ and $\bftheta$. The model is visualized in Fig.~\ref{fig:two_level_model}. 

% \TODO{The input for $g_{\bfphi}(\bfz)$ is the latent code $\bfz$. The input for $f_{\bftheta}(\bfx,\bfz)$ is the concatenation of one 3D vector $\bfx$ and the latent code $\bfz$}\NA{Perhaps we can comment this out. Seems pretty obvious.}.

%by sampling $\bfepsilon \sim \mathcal{N}(\bf{0},\bf{I})$, and setting $\bfz = \bfmu + \bfsigma \odot \bfepsilon$ in order to optimize the parameters $\bfmu$ and $\bfsigma$ via gradient descent.

%Our object model employs a two-level representation for compact object shape modeling using a shared latent code. The fine level provides shape details where as the coarse level restrains the shape scale and pose. Both levels are linked to the shared latent code such that the shape and pose can be optimized jointly from the multiview observations. A diagram visualising the framework is Fig. \ref{fig:two_level_model}.



%\subsubsection{Error Functions}
%\label{sec:errors}

{\vspace{1ex}\bf \noindent Error Functions: }%
We introduce error terms that play a key role for optimizing the category-level latent code $\bfz$ and decoder parameters $\bftheta$, $\bfphi$, during training time, as well as the transformation $\bfT$ from the global frame to the canonical object frame and the latent code deformation $\delta\bfz$ of a particular instance during test time. The training data for an ELLIPSDF model consists of distance-labeled point clouds $\calX_{n,k}(\bfp)$ associated with instances $n$ from the same class, as introduced in Sec.~\ref{sec:problem}. A different latent code $\bfz_n$ is optimized for each instance $n$, while the decoder parameters $\bftheta$ and $\bfphi$ are common for all instances of the same class. 

% The input for the error functions are generated from a training set that consists of distance measurements $\calX_{n,k}(\bfp)$ associated with object instances $n$ from the same object class, as introduced in Sec.~\ref{sec:problem}, and described in details in Sec.~\ref{sec:training_details}. 

% The distance measurements $\calX_{n,k}(\bfp)$ of instance $n$ at time $k$ are obtained from the pixel-wise instance segmentation $\bfp \in \Omega_{n,k}^2$ observed with known camera pose $\bfC_k \in \text{SE}(3)$. 

% We define an error function $e^g_{\bfphi}$ to measure the discrepancy between a distance-labelled point $(\bfx,d) \in \calX_{n,k}(\bfp)$ observed close to the instance surface and the coarse shape $\calE_{\bfu}$ provided by $\hat{\bfu} = e^g_{\bfphi}(\bfz)$.
% Another error function $e^f_{\bftheta}$ is used for the difference between a distance-labelled point $(\bfx,d) \in \calX_{n,k}(\bfp)$ observed close to the surface and the SDF value provided by $\hat{d} = f_{\bftheta}(\bfx, \bfz)$.
% The overall cost function is thus $e(\bfx,\bfphi,\bftheta,\bfT,\delta \bfz) = \beta e^g_{\bfphi}(\bfx, \bfT, \bfz + \delta \bfz) + \gamma e^f_{\bftheta}(\bfx, \bfT, \bfz + \delta \bfz)$, where $\beta, \gamma \geq 0$ are the weights. 

% of the object with respect to point $\bfx$, whose signed distance to the object surface is $d$

The fine-level shape error function $e_{\bftheta}(\bfx,d,\bfT,\delta\bfz)$ of a point $\bfx$ in global coordinates  with signed distance label $d$ is defined as:
%
\begin{equation}
  \label{eq:e_k}
  e_{\bftheta}(\bfx,d,\bfT,\delta\bfz) \triangleq \rho(s f_{\bftheta}(\bfP\bfT \underline{\bfx}; \bfz+\delta\bfz) - d).
\end{equation}
%
In the definition above, the point $\bfx$ is first transformed to the object coordinate frame via $\bfP\bfT \underline{\bfx}$ and the fine-shape model $f_{\bftheta}$ is queried with the instance shape code $\bfz + \delta\bfz$ to predict the SDF to the object surface. Since SDF values vary proportionally with scaling \cite{afolabi2020extending}, the returned value is scaled back by $s$ before measuring its discrepancy with the label $d$. Instead of measuring the difference between $s f_{\bftheta}$ and $d$ in absolute value, we employ a Huber term \cite{Huber1964Robust} to make the error function robust against outliers:
%
\begin{equation}
\label{eq:huber_loss}
\rho(r) \triangleq 
\begin{cases}
\frac{1}{2}r^2 & |r|\leq \delta,\\
\delta(|r|-\frac{1}{2}\delta) & \text{else}.
\end{cases}
\end{equation}
%
Note that the error $e_{\bftheta}$ relates both the object pose and shape to the SDF residual, which is unique to our formulation and enables their joint optimization.

The coarse-level shape error function $e_{\bfphi}(\bfx,d,\bfT,\delta\bfz)$ is defined similarly, using a signed distance function for the coarse shape. Since the coarse shape decoder, $\bfu = g_{\bfphi}(\bfz)$, provides an explicit ellipsoid description, we first need a conversion to SDF before we can define the error term. An approximation of the SDF of an ellipsoid $\calE_{\bfu}$ with semi-axis lengths $\bfu$ can be obtained as:
%
\begin{equation}
  \label{eq:ellpsoid_sdf}
  h\left(\bfx, \bfu\right)
  =
  \frac{\left\|\bfU^{-1}\bfx\right\|_{2}\left(\left\|\bfU^{-1}\bfx\right\|_{2}-1\right)}
  {\left\|\bf{U}^{-2}\bfx\right\|_{2}}.
\end{equation}
%
Then, the coarse-level shape error of a point $\bfx$ in global coordinates  with signed distance label $d$ is defined as:
%
\begin{equation}
  \label{eq:e_g}
  e_{\bfphi}(\bfx,d,\bfT,\delta\bfz) \triangleq \rho(s h(\bfP\bfT \underline{\bfx}, g_{\bfphi}(\bfz+\delta\bfz)) - d).
\end{equation} 
%
%where $\bfP = [\bfI\;\mathbf{0}] \in \mathbb{R}^{3 \times 4}$ is a projection matrix, $\bfT \in \text{SIM}(3)$ is the transformation from world frame to object frame, and $s$ is the scale. 
%Furthermore $e_{\bfphi}$ is a novel error function that has not been used to jointly optimize object pose and shape before. 

During training, the object transformation is fixed to be the canonical coordinate frame $\bfT = \bfI_4$ because the training point-cloud data is collected directly in the object frame. The regularization term $e_r(\delta\bfz)$ in \eqref{eq:cost_function} is defined as the KL divergence between the distribution of $\delta\bfz$ and a standard normal distribution \cite{hao2020dualsdf}.



%Note that during training, $\bfT = \bfI_4$ since each object is already in its canonical frame and does not require any transformation to the world frame.  


%During training, we also add the regularization term $e_r(\delta\bfz)$ as the KL divergence between the distribution of $\delta\bfz$ and a standard normal distribution. 



%Note that SDF is invariant to rotation, translation but vary proportionally with scaling \cite{afolabi2020extending}. 

%The error function $e_{\bftheta}$ relates both the object pose and shape to the SDF residual, which enables the joint optimization of both pose and shape via SDF residuals, and is different from the error functions used in DeepSDF~\cite{park2019deepsdf} and its derivatives that only depend on the shape. 

% Before introducing the coarse level error function $e_{\bfphi}$, we need to define the function $h(\cdot, \cdot)$ that computes an inexact SDF value for a point $\bfx$ with respect to an ellipsoid with shape $\bfu$ centered at origin:
% \begin{equation}
%   \label{eq:ellpsoid_sdf}
%   h\left(\bfx, \bfu\right)
%   =
%   \frac{\left\|\bfU^{-1}\bfx\right\|_{2}\left(\left\|\bfU^{-1}\bfx\right\|_{2}-1\right)}
%   {\left\|\bf{U}^{-2}\bfx\right\|_{2}}.
% \end{equation}
% Then we present the term $e_{\bfphi}(\bfx,d,\bfT,\delta\bfz)$ to depict the SDF for the coarse level shape, and is defined as 
% \begin{equation}
%   \label{eq:e_g}
%   e_{\bfphi}((\bfx,d,\bfT,\delta\bfz) \triangleq \rho(s h(\bfP\bfT \underline{\bfx}, g_{\bfphi}(\bfz+\delta\bfz)) - d),
% \end{equation} 
% where $\bfP = [\bfI\;\mathbf{0}] \in \mathbb{R}^{3 \times 4}$ is a projection matrix, $\bfT \in \text{SIM}(3)$ is the transformation from world frame to object frame, and $s$ is the scale. Note that during training, $\bfT = \bfI_4$ since each object is already in its canonical frame and does not require any transformation to the world frame.  
% Furthermore $e_{\bfphi}$ is a novel error function that has not been used to jointly optimize object pose and shape before. 

%Lastly, we employ the Huber loss \eqref{eq:huber_loss} to make the error functions robust against outliers
%\begin{equation}
%\label{eq:huber_loss}
%\rho(r) \triangleq 
%\begin{cases}
%\frac{1}{2}r^2 & |r|\leq \delta,\\
%\delta(|r|-\frac{1}{2}\delta) & \text{else}.
%\end{cases}
%\end{equation}
%During training, we also add the regularization term $e_r(\delta\bfz)$ as the KL divergence between the distribution of $\delta\bfz$ and a standard normal distribution. 
% such that the $\delta\bfz$ is generated from a compact distribution.






\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{dualSDF_ellipsoid.png}
    \caption{Overview of our ELLIPSDF bi-level object shape model. A latent shape code, $\bfz$, with distribution $\calN(\bfmu,\diag(\bfsigma)^2)$ is shared by a coarse shape decoder $g_\phi$, providing an ellipsoid shape description, and a fine shape decoder $f_\theta$, providing an SDF shape description. During training, the decoder parameters $\phi$ and $\theta$ are optimized by minimizing the errors between the SDF values of the training points $\bfx$, obtained close to the object surface, and the coarse and fine shape models.}
    %decoded by $g_\phi$ for the ellipsoid shape $\bfu$ and $f_\theta$ for the object SDF. The network parameters $\phi$, $\theta$ are optimized by minimizing the loss between the predicted and ground truth SDF for each sampled point $\bfx$.}
    \label{fig:two_level_model}
\end{figure}



% The latent code can be learnt by minimizing the Huber loss defined in \eqref{eq:huber_loss} between the predicted and the real SDF in \eqref{eq:cost_function}. 

% \begin{definition}
%   \textit{Huber error function} \cite{Huber1964Robust} with parameter $\delta > 0$ is:
%   \begin{equation}
%   \label{eq:huber_loss}
%   \rho(r) \triangleq 
%   \begin{cases}
%   \frac{1}{2}r^2 & |r|\leq \delta,\\
%   \delta(|r|-\frac{1}{2}\delta) & \text{else}.
%   \end{cases}
%   \end{equation}
% \end{definition}
% whose gradient can be computed as 
% \[
%   \frac{\partial \rho(r)}{\partial r}
%   =\left\{\begin{array}{ll}
%     r & |r| \leq \delta \\
%     \text{sign}(r)\delta  & \text{ else}. 
%     \end{array}\right.
% \] 







% \subsubsection{Training Process}
% \label{sec:training}

% % The shared latent space is represented by a latent code vector $\mathbf{z} \in \mathbb{R}^{d}$, which can be decoded by two generative neural networks $\bfu = g_{\bfphi}\left(\mathbf{z}\right)$, and $f_{\bftheta}\left(\bfx; \mathbf{z}\right) \approx f(\bfx), \forall x \in \calS$, where $\bfu$ represents an ellipsoid shape and $f_{\bftheta}$ is an approximator of a given SDF $f(\bfx)$\NA{some of this stuff is repeated with the problem statement section.}.
% % The ellipsoid constrains the scale of the SDF model, whereas the SDF model provides details for the object shape. 
% % A diagram visualising the framework is Fig. \ref{fig:two_level_model}. 

% This section describes how to train the two-level shape code. 
% To prepare the training data, we sample pairs of 3D points $\bfX = \{\bfx_t\}_t$ and the corresponding groundtruth SDF values $\{ d_t \}_t$ from the object meshes in a database such as ShapeNet \cite{chang2015shapenet}. 


% The training loss $L_t(\delta\bfz)$ is formulated as\NA{Define this term only once in the problem statement section and reuse it here} 
% \begin{equation}
%   \label{eq:train_loss}
%   \begin{aligned}
%     L_t(\delta\bfz) = 
%     \alpha e_r(\delta\bfz) & + 
%     \beta \sum_{\bfx_t, d_t} 
%     e^g_{k}(\bfx_t,d_t,\bfI_4,\delta\bfz) 
%     \\ 
%     &+  \gamma \sum_{\bfx_t, d_t} e_{\bftheta}(\bfx_t,d_t,\bfI_4,\delta\bfz)
%   \end{aligned}
% \end{equation}
% in which $\bfT = \bfI_4$ since during training the canonical coordinate frame of the object class is known, and thus the training focuses on the coarse and fine shape decoders. Here we define $e_r(\delta\bfz)$ as the KL divergence between the distribution of $\delta\bfz$ and a standard normal distribution.





\subsection{Joint Pose and Shape Optimization with an ELLIPSDF Model}
\label{sec:shape_pose_inference}

% (Sec.~\ref{sec:pose_init}) 
% (Sec.~\ref{sec:pose_shape_opt}) 
This section describes how a trained ELLIPSDF model is used to initialize and optimize the pose and shape of a new object instance at test time.


%\subsubsection{Initialization}
%\label{sec:pose_init}

{\vspace{1ex}\bf \noindent Initialization: }%
We follow \cite{crocco2016structure, rubino20173d, gay2018visual} to initialize the $\text{SIM}(3)$ scale and pose of an observed object, relying on its coarse ellipsoid shape representation. We fit ellipses to the pixel-wise segmentation $\Omega_k^2$ of an object at each time $k$:
%
\begin{equation} \label{eq:ellipse_fit}
    \crl{ \bfq \in \Omega^2 \mid (\bfq - \bfc_k)^\top \bfE_k^{-1} (\bfq - \bfc_k) \leq 1},
\end{equation}
%
where the center and symmetric matrix are obtained as $\bfc_k = \frac{1}{|\Omega_k^2|}\sum_{\bfp \in \Omega_k^2} \bfp$ and $\bfE_k = \frac{2}{|\Omega_k^2|}\sum_{\bfp \in \Omega_k^2} (\bfp-\bfc_k)(\bfp-\bfc_k)^\top$. The axes lengths are the eigenvalues $\lambda_{0}$, $\lambda_{1}$ of $\bfE_k$. The 2D quadric surface corresponding to the ellipse in \eqref{eq:ellipse_fit} and its dual are defined by the matrix $\bfH_k$ and its inverse $\bfH_k^*$:
%
\begin{equation*}
    \scaleMathLine{\bfH_k = \begin{bmatrix} \bfE_k^{-1} & -\bfE_k^{-1}\bfc_k \\ -\bfc_k^\top \bfE_k^{-1} & \bfc_k^\top \bfE_k^{-1} \bfc_k - 1\end{bmatrix}, \;\; \bfH_k^* = \begin{bmatrix}\bfE_k - \bfc_k\bfc_k^\top & -\bfc_k \\ -\bfc_k^\top & -1\end{bmatrix}.}
\end{equation*}




% The dual form of the ellipse is 
% $
% \bfH_k = 
% \left(\begin{array}{cc}
% \bfE_k & \bf{0} \\
% \bf{0}^\top & -1  
% \end{array}\right) 
% \in \mathbb{R}^{3\times3}
% $.

%Given a set of pixels with image coordinates $\left\{\left(u_{p}, v_{p}\right) \in \Omega_k^2 \right\}$, its center of mass is $\bfc_k = \frac{1}{|\Omega_k^2|}\sum_{\bfp \in \Omega_k^2} \bfp$. We could fit an ellipse represented by $\bfE_k = \frac{2}{|\Omega_k^2|}\sum_{\bfp \in \Omega_k^2} (\bfp-\bfc_k)(\bfp-\bfc_k)^\top$. 
% \[
%   \scaleMathLine[0.9]{
%     \left\{(u, v) \in \mathbb{R}^{2} \mid\left[\begin{array}{l}
%       u-c_{u} \\
%       v-c_{v}
%       \end{array}\right]^{\top}\left[\begin{array}{ll}
%       E_{u u} & E_{u v} \\
%       E_{u v} & E_{v v}
%       \end{array}\right]^{-1}\left[\begin{array}{l}
%       u-c_{u} \\
%       v-c_{v}
%       \end{array}\right] \leq 1
%     \right\}
%   }
% \]  
% where $E_{u u}=\frac{2}{N_{p}} \sum_{p}\left(u_{p}-c_{u}\right)^{2}$, $E_{v v}=\frac{2}{N_{p}} \sum_{p}\left(v_{p}-c_{v}\right)^{2}$, $E_{u v}=\frac{2}{N_{p}} \sum_{p}\left(u_{p}-c_{u}\right)\left(v_{p}-c_{v}\right)$. 
%The axes lengths are the eigenvalues $\lambda_{0}, \lambda_{1}$ of $\bfE_k$. The dual form of the ellipse is $\bfH_k = \text{adj}(\bfE_k)$\NA{This is not true. Look at how the ellipse is defined using $\bfE_k^{-1}$ which is both inverted and a $2 \times 2$ matrix.}
% $
% \left[\begin{array}{ll}
%   E_{u u} & E_{u v} \\
%   E_{u v} & E_{v v}
% \end{array}\right]
% $.
% The dual form of ellipse is the conic and can be obtained by the adjoint operator.\NA{I am not sure what this sentence is saying. How is $\bfH_k$ related to $\bfE_k$?} 
% , \beta = (\beta_{1}, \beta_{2},..., \beta_{k})^\top

An ellipsoid in dual quadric form $\bfQ^*$ in global coordinates and its conic projection $\bfH_k^*$ in image $k$ are related by $\beta_{k} \mathbf{H}_{k}^*=\mathbf{P} \bfC_k^{-1} \mathbf{Q}^* \bfC_k^{-\top} \mathbf{P}^{\top}$ defined up to a scale factor $\beta_{k}$. This equation can be rearranged to $\beta_{k} \mathbf{h}_{k} = \mathbf{G}_k\mathbf{v}$, where $\mathbf{h}_{k} = \operatorname{vech}(\mathbf{H}_{k}^*)$, $\mathbf{h}_{k} \in \mathbb{R}^6$, $\mathbf{v} = \operatorname{vech}(\mathbf{Q}^*)$ and $\mathbf{v} \in \mathbb{R}^{10}$. The operator $\operatorname{vech}$ serializes the lower triangular part of a symmetric matrix, and $\mathbf{G}_k$ is a matrix that depends on $\mathbf{P} \bfC_k^{-1}$. The explicit form of $\mathbf{G}_k$ is derived in (5) in \cite{rubino20173d}. 
Next, a least squares system is constructed from the multi-view observations. By stacking all observations, we obtain $\mathbf{M} \mathbf{w} = \bf0$, where $\mathbf{w} = (\mathbf{v}, \beta_1,\ldots,\beta_k)^\top$, and $\bfM$ is defined in (8) in  \cite{rubino20173d}.  
This leads to a least squares system:
%
\begin{equation}
\label{eq:ellipsoid_lsq}
\hat{\mathbf{w}}=\arg \min _{\bfw}\left\|\mathbf{M} \mathbf{w}\right\|_{2}^{2} \quad \text { s.t. } \quad\|\mathbf{w}\|_{2}^{2}=1,
\end{equation}
%
which can be solved by applying SVD to $\mathbf{M}$, and taking the right singular vector associated to the minimum singular value. The constraint $\|\mathbf{w}\|_{2}^{2}=1$ avoids a trivial solution. The first $10$ entries of $\hat{\mathbf{w}}$ are $\hat{\mathbf{v}}$, which is a vectorized version of the dual ellipsoid $\hat{\mathbf{Q}}^*$ in the global frame. To avoid degenerate quadrics, a variant of the least squares system in \eqref{eq:ellipsoid_lsq} is proposed in \cite{gay2018visual}, which constrains the center of the ellipse and the reprojection of the center of the 3D ellipsoid to be close. Thus, we modify $\bfM$ using the version in (9) in \cite{gay2018visual} to improve the estimation.

The object pose $\hat{\bfT}^{-1}$ can be recovered by relating the estimated ellipsoid $\hat{\mathbf{Q}}^*$ in global coordinates to the ellipsoid $\bfQ^*_{\bfu}$ in the canonical coordinate frame predicted by the coarse shape decoder $\bfu = g_{\bfphi}(\bfz)$ using the average class shape $\bfz$: 
%from the estimated ellipsoid $\hat{\mathbf{Q}}^*$ using \eqref{eq:ellipsoid}. Since $\bfQ^*$ can be parameterized as a centered ellipsoid $\bfQ^*_{\bfu}$ transformed by the object pose:
\begin{equation*}
\begin{aligned}
\hat{\bfQ}^*\! =
\hat{\mathbf{T}}^{-1} \bfQ_{\bfu}^* \hat{\mathbf{T}}^{-\top}\!\!=
% \left[\begin{array}{cc}
% \mathbf{R} & \bft \\
% \mathbf{0}^{\top} & 1
% \end{array}\right]\left[\begin{array}{cc}
% \mathbf{U} \mathbf{U}^{\top} & \mathbf{0} \\
% \mathbf{0} & -1
% \end{array}\right]\left[\begin{array}{ll}
% \mathbf{R}^{\top} & \mathbf{0} \\
% \bft^{\top} & 1
% \end{array}\right] \\ 
% &=
\begin{bmatrix} 
\hat{s}^2 \hat{\mathbf{R}} \bfU\bfU^\top \hat{\mathbf{R}}^\top -  \hat{\bft} \hat{\bft}^\top & - \hat{\bft} \\ -\hat{\bft}^\top & -1
\end{bmatrix}.
\end{aligned}
\end{equation*}
The translation $\hat{\bft}$ can be recovered from the last column of $\hat{\bfQ}^*$.
%$\hat{\bft} = -\bfP \hat{\mathbf{Q}} [0,0,0,1]^\top$. 
To recover the rotation, note that $\bfA \triangleq \bfP\hat{\mathbf{Q}}^*\bfP^\top  + \hat{\bft} \hat{\bft}^\top = \hat{s}^2\hat{\bfR}\bfU\bfU^\top\hat{\bfR}^\top$ is a positive semidefinite matrix. Let its eigen-decomposition be $\bfA = \bfV\bfY\bfV^\top$, where $\bfY$ is a diagonal matrix containing the eigenvalues of $\bfA$. Since $\bfU\bfU^\top$ is diagonal, it follows that $\hat{\bfR} = \bfV$, while the scale $\hat{s}$ is obtained as $\hat{s} = \frac{1}{3} \sqrt{\tr(\bfU^{-1}\bfY \bfU^{-\top})}$.
%
% \begin{equation}
%   \label{eq:ellipsoid_scale}
%   \hat{s} = \frac{1}{3} \sqrt{\tr(\bfU^{-1}\bfY \bfU^{-\top})}
%   %\hat{s} = \frac{1}{3} (\frac{\sqrt{s_1}}{u_1} + \frac{\sqrt{s_2}}{u_2} + \frac{\sqrt{s_3}}{u_3}) 
% \end{equation}
%
%and $\bfU = \diag(\bfu)$ is a prior object shape obtained as the mean shape from the training set. 
% Finally, the ellipsoid $\hat{\mathbf{Q}}$ represented by $\hat{\bfU}, \hat{s}, \hat{\bfR}, \hat{\bft}$ is refined by the tangent plane residual. 
Note that although the $\text{SIM}(3)$ pose could also be recovered from the object point cloud, other outlier rejection methods are required \cite{wu2020eao} when the point cloud is noisy. 



%\subsubsection{Optimization}
%\label{sec:pose_shape_opt}

{\vspace{1ex}\bf \noindent Optimization: }%
Given the initialized instance transformation $\hat{\bfT}$ and initial shape deformation $\delta\hat{\bfz} = \mathbf{0}$, we solve the joint pose and shape optimization in \eqref{eq:test_optimization} via gradient descent. Note that the decoder parameters $\bftheta$, $\bfphi$ and the mean category shape code $\bfz$ are fixed during online inference. Since $\bfT$ is an element of the $\text{SIM}(3)$ manifold, the gradients and gradient steps need to be computed by projecting to the tangent $\text{sim}(3)$ vector space and retracting back to $\text{SIM}(3)$. We introduce local perturbations $\bfT = \exp\prl{\bfxi_\times} \hat{\bfT}$, $\delta\bfz = \delta\tilde{\bfz} + \delta\hat{\bfz}$ and derive the Jacobians of the error function in \eqref{eq:cost_function} with respect to $\bfxi$ and $\delta\tilde{\bfz}$. 



%To incorporate the proposed error functions in \eqref{eq:cost_function} in a tightly coupled localization and mapping algorithm such as~\cite{Atanasov_SemanticLocalization_IJRR15, sunderhauf2017meaningful, mur2017orb}, we could linearize the terms around the estimated camera and object states. However, to keep the presentation clear we leave this for future work, and use ground truth camera poses. Hence, in this paper we only linearize around the object instance $\hat{\bfi}$ using perturbation $\tilde{\bfi}$: $\bfT = \exp\prl{\bfxi_\times} \hat{\bfT}$, $\delta\bfz = \delta\tilde{\bfz} + \delta\hat{\bfz}$.
% \begin{equation}
% \label{eq:perturbations}
% \begin{aligned}
%   \bfT = \exp\prl{\bfxi_\times} \hat{\bfT} \quad 
% \delta\bfz = \delta\tilde{\bfz} + \delta\hat{\bfz}
% \end{aligned}
% \end{equation}
%We define the Jacobians of the pose and latent code perturbations with respect to the error functions next. Note that the parameters $\bftheta$, $\bfphi$ of the decoders, and the mean shape latent code $\bfz$ remain fixed during inference. 

\begin{proposition}
\label{prop:sdf-sim3-jacobians}
The Jacobian of $e_{\bftheta}$ in \eqref{eq:e_k} with respect to the transformation perturbation $\bfxi \in \mathfrak{sim}(3)$ is:
\begin{equation*}
% \label{eq:gk-jacobians}
\scaleMathLine[1]
{
  \begin{aligned}
    \frac{\partial e_{\bftheta}}{\partial \bfxi} 
    &= 
    \frac{\partial \rho(r)}{\partial r}
    \prl{
      \hat{s} [{\bf0}_6,1] f_{\bftheta} (\bfx,\delta\hat{\bfz})
      + 
      \hat{s} \nabla_{\bfx} f_{\bftheta}(\bfx,\delta\hat{\bfz})^\top
      \bfP \brl{\hat{\bfT} \underline{\bfx}}^\odot 
    }
    \\
    \frac{\partial e_{\bftheta}}{\partial \delta\tilde{\bfz}} 
    &= 
    \frac{\partial \rho(r)}{\partial r}
    \hat{s} \nabla_{\bfz} f_{\bftheta}(\bfx,\delta\hat{\bfz}), 
    \end{aligned}
}
\end{equation*}
where $f_{\bftheta}(\bfx,\delta\hat{\bfz}) = f_{\bftheta}(\bfP\hat{\bfT} \underline{\bfx}; \bfz+\delta\hat{\bfz})$ is defined in \eqref{eq:e_k} and $\frac{\partial \rho(r)}{\partial r}$ is the derivative of the Huber term in \eqref{eq:huber_loss} evaluated at $r = \hat{s} f_{\bftheta}(\bfx,\delta\hat{\bfz}) - d$:
\[
  \frac{\partial \rho(r)}{\partial r}
  =\left\{\begin{array}{ll}
    r & |r| \leq \delta \\
    \text{sign}(r)\delta  & \text{ else}. 
    \end{array}\right.
\] 
%The fine level autodecoder $f_{\bftheta}(\bfx,\delta\hat{\bfz}) = f_{\bftheta}(\bfP\hat{\bfT} \underline{\bfx}; \bfz+\delta\hat{\bfz})$ is defined in \eqref{eq:e_k}. 
The operator $\underline{\bfx}^\odot$ is defined as:
\begin{equation*}
\underline{\bfx}^\odot \triangleq \begin{bmatrix} \bfI_3 & -\bfx_\times & \bfx\\ \mathbf{0}^\top & \mathbf{0}^\top & 0 \end{bmatrix} \in \mathbb{R}^{4 \times 7}. 
\end{equation*}
% $r = \hat{s} f_{\bftheta}(\bfP\hat{\bfT} \bfC_k\underline{\bfx}; \bfz+\delta\hat{\bfz}) - d$, \YYJ{ abbreviated as $f_{\bftheta}(\bfx,\delta\hat{\bfz})$}.
\end{proposition}

%The first equality is proved as follows.
\begin{proof}
Using the chain rule and the product rule:
\begin{equation*}
\begin{aligned}
  \frac{\partial e_{\bftheta}}{\partial\bfxi} 
  = 
  \frac{\partial e_{\bftheta}}{\partial r}
  \frac{\partial r}{\partial\bfxi}
  = 
    \frac{\partial e_{\bftheta}}{\partial r}
    \prl{
      \frac{\partial s}{\partial\bfxi}
      f_{\bftheta} (\bfx,\delta\bfz)
      +
      s
      \frac{\partial f_{\bftheta}}{\partial{}^{}_{O}\bfx}
      \frac{\partial {}^{}_{O}\bfx}{\partial\bfxi}
    }, 
\end{aligned}
\end{equation*}
where ${}^{}_{O}\bfx = \bfP\bfT \underline{\bfx}$ is a point in the object frame. We have $
\frac{\partial s}{\partial\bfxi}
  = 
  e^\sigma [{\bf0}_6,1]
  = s [{\bf0}_6,1]
$. 
The term $s\frac{\partial f_{\bftheta}}{\partial{}^{}_{O}\bfx}$ is the gradient of the fine-level SDF decoder with respect to the input $s \nabla_{\bfx} f_{\bftheta}(\bfx, \delta\bfz)$, which could be obtained from auto-differentiation. Finally, we have:
%
\begin{equation*}
% \label{eq:sdf-sim3-jacobians-proof2b}
\begin{aligned}
{}^{}_{O} \bfx &= \bfP \bfT \underline{\bfx} \approx 
\bfP (\bfI + \bfxi_\times) \hat\bfT \underline{\bfx} \\
&=
\bfP \hat\bfT \underline{\bfx}
+
\bfP \bfxi_\times \hat\bfT \underline{\bfx} \\ 
&= 
\bfP \hat\bfT \underline{\bfx}
+
\underbrace{\bfP [\hat\bfT \underline{\bfx}]^\odot}_{\frac{\partial {}^{}_{O} \bfx}{\partial \bfxi}} \bfxi. 
% \underbrace{\bfP [\hat\bfT \underline{\bfx}]^\odot}_{Jacobian} \bfxi
\end{aligned}\qedhere
\end{equation*}
\end{proof}


In the second equality in Prop.~\ref{prop:sdf-sim3-jacobians}, the term $\frac{\partial \rho(r)}{\partial r} \hat{s} \nabla_{\bfz} f_{\bftheta}(\bfx, \delta\hat{\bfz})$ is the gradient of the fine-level SDF loss with respect to the input $\bfz$ and can be obtained via auto-differentiation. The Jacobians of the coarse-level SDF error $\frac{\partial e_{\bfphi}}{\partial \bfxi}$, $\frac{\partial e_{\bfphi}}{\partial \delta \tilde{\bfz}}$ can be obtained in a similar way. 

%Lastly, the object pose and the shape latent codes are optimized via gradient descent.
%The initialization step provides initial estimates $\bfT^0$, $\delta \bfz^0$. 

After obtaining the Jacobians, the pose and latent shape code can be optimized via:
\begin{equation*}
\begin{aligned}
\bfT^{i+1} &\triangleq 
\exp \prl{- \eta_1 
\frac{\partial e(\bfT,\delta \bfz, \bftheta^*, \bfphi^* ; \crl{\calX_k(\bfp)})}{\partial \bfxi}}
\bfT^{i}
\\
\delta \bfz^{i+1} &\triangleq 
\delta \bfz^{i} - \eta_2 
\prl{\frac{\partial e(\bfT,\delta \bfz, \bftheta^*, \bfphi^* ; \crl{\calX_k(\bfp)})}{\partial \delta \bfz}}, 
\end{aligned}
\end{equation*}
where $\eta_1, \eta_2$ are step sizes, $\delta \bfz^0 = \mathbf{0}$, and $\bfT^0 = \hat{\bfT}$ is obtained from the initialization. During optimization, we add regularization $e_r(\delta\bfz) = \|\delta\bfz\|_2^2$ to restrict the amount of latent code deformation.


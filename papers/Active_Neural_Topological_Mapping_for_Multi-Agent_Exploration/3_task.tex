\section{Task Setup}

%讲讲habita的设定
%我们multi-agent的设定
Multi-agent cooperative exploration requires agents to explore an unknown scene based on sensory signals.
At each time step, each agent receives a first-person RGB-D image and the estimated pose from
sensors. Agents then perform environmental actions in the physically realistic simulator, Habitat~\cite{habitat}. The horizon of the global decision-making step is 15 steps, and the available environmental actions include \emph{Turn Left}, \emph{Turn Right}, and \emph{Forward}. Following the settings in ANS~\cite{ans} and NRNS~\cite{norl}, we introduce Gaussian noise in the sensor readings and simulate real-world action noise. In the multi-agent scenario, we further consider the following settings. Firstly, we assume perfect communication, where relative spawn locations are shared between agents. This allows us to estimate the relative position of each agent at each timestep by using sensory pose readings and shared spawn locations. Besides, agents are randomly initialized within a 2-meter geodesic distance constraint. This spatially close initialization requires agents to expend more scanning effort for exploration, further increasing the difficulty of cooperation.\looseness=-1



%resulting in the bias between the estimated pose and the actual pose leading to the bias between the expected pose and the actual pose

%where the \emph{Turn} operation rotates the agent 10 degrees, and the \emph{Forward} operation enables the agent to go straight ahead for 0.25$m$.
% so that the behaviors of all agents tend to be the same with similar observations at the beginning. This constraint further increases the difficulty of cooperation.
% , where the \emph{Turn} operation rotates the agent 10 degrees, and the \emph{Forward} operation enables the agent to go straight ahead for 0.25$m$.  We consider a decision-making setting by assuming perfect communication between agents. The objective of the task is to maximize the accumulated explored area within a limited time horizon.






\begin{abstract}
% explore是个问题，一个流行的解决范式是map-》explore，多采用传统方法，rl也有。但是他们大多基于metric map（not sure，传统方法是不是基于？if 不是，那就是rl比传统好，但rl基于。），而metric map有问题，topo map是个啥，他因为啥可以解决啥，所以我们propose啥。
This paper investigates the multi-agent cooperative exploration problem, which requires multiple agents to explore an unseen environment via sensory signals in a limited time. 
A popular approach to exploration tasks is to combine active mapping with planning. Metric maps capture the details of the spatial representation, but are with high communication traffic and may vary significantly between scenarios, resulting in inferior generalization. Topological maps are a promising alternative as they consist only of nodes and edges with abstract but essential information and are less influenced by the scene structures. However, most existing topology-based exploration tasks utilize classical methods for planning, which are time-consuming and sub-optimal due to their handcrafted design. Deep reinforcement learning (DRL) has shown great potential for learning (near) optimal policies through fast end-to-end inference. In this paper, we propose \underline{M}ulti-\underline{A}gent \underline{N}eural \underline{T}opological \underline{M}apping (\name) to improve exploration efficiency and generalization for multi-agent exploration tasks. {\name} mainly comprises a Topological Mapper and a novel RL-based \underline{H}ierarchical \underline{T}opological \underline{P}lanner (\planner). The Topological Mapper employs a visual encoder and distance-based heuristics to construct a graph containing main nodes and their corresponding ghost nodes. The {\planner} leverages graph neural networks to capture correlations between agents and graph nodes in a coarse-to-fine manner for effective global goal selection. Extensive experiments conducted in a physically-realistic simulator, Habitat, demonstrate that {\name} reduces the steps by at least 26.40\% over planning-based baselines and by at least 7.63\% over RL-based competitors in unseen scenarios.\looseness=-1

%However, combine RL with topological therefore, the existing RL-based solutions primarily rely on metric maps. 

%栅格地图不好，拓扑地图好，但是目前拓扑地图探索在用于传统方法，传统方法本身。最好的是与rl相结合，但是目前rl方法只和metric maps，所以我们这里。。。。Metric map xxx, topological map xxx,
% outperforms RL-based baselines with at least 6.96\% higher exploration efficiency. Compared with planning-based competitors, {\name} has at least 12.99\% higher exploration efficiency. 



\end{abstract}

%传统方法运用metric map
%对于不同结构的地图构建网格地图差异大，不具有泛化性，因为网格地图与空间的布局强相关。
% The {\planner} first selects a main node and then chooses the corresponding ghost node as the global goal for each agent.
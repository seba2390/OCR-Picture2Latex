\section{Experiments}

\subsection{Experimental Details}
We conduct all experiments in the Habitat simulator~\cite{habitat}, using the Gibson Challenge dataset~\cite{dataset1} and the Habitat-Matterport 3D dataset (HM3D)~\cite{dataset2}. The scenes in these datasets are collected from real building-scale residential, commercial, and civic spaces using 3D scanning and reconstruction. We filter out some scenes that are inappropriate for our task, following \cite{RL_multi2}, which is one of the best RL-based approaches for cooperative exploration. This filtering process involved removing scenes with large disconnected regions or multiple floors where agents couldn't attain 90\% coverage of the entire house. 
Furthermore, we exclude scenes smaller than 70 $m^2$, as their topological maps would contain too few nodes to fully show the advantages of graphs.
To better demonstrate the robustness of {\name} on training scenes and its effective generalization to novel scenes, we follow \cite{RL_multi2,cvpr22} by dividing the remaining scenes into $10$ training scenes from the Gibson Challenge dataset and $28$ testing scenes from both datasets.
We perform RL training with $10^6$ timesteps over 3 random seeds. Each evaluation score has the format of ``mean (standard deviation)'', and is averaged over 300 testing episodes.\looseness=-1


% Due to space limitations, we only present the results with $N=2,3$ agents, while experimental results with other numbers of agents are provided in the appendix.

% such as scenes that have large disconnected regions or multiple floors so that the agents are not possible to achieve 90\% coverage of the entire house.

% We choose scenes in the size of over 70 $m^2$ with continuous regions and a single floor to better show the performance of multi-agent exploration. Besides, we only use 10 scenes for training and 25 scenes for evaluation in order to demonstrate the generalization ability.to illustrate the robustness and the generalization of {\name}, Then we categorize the remaining scenes into $23$ training scenes and $10$ testing scenes. where the agents are not possible to achieve 90\% coverage of the entire house. 

% \input{tables/communication}
\input{tables/gibson_34agents}
\input{tables/hm3d_34agents}
\subsection{Evaluation Metrics}
We consider 3 statistical metrics to capture different characteristics of a particular exploration strategy. These metrics are only for analysis, and we primarily focus on \emph{Steps} as our performance criterion.

% \vspace{-\topsep}
\begin{itemize}
\setlength{\parskip}{0pt} \setlength{\itemsep}{0pt plus 1pt}
    \item \textbf{Steps:  }This metric considers the timesteps required to achieve 90\% coverage within an episode. Fewer \emph{Steps} imply faster exploration.
    \item \textbf{Coverage:  }This metric denotes the final ratio of the explored area to total explorable area at the end of the episode. A higher \emph{Coverage} ratio reflects a more effective exploration.
    \item \textbf{Mutual Overlap: }This metric shows the ratio of the overlapped area to the currently explored area when the \emph{Coverage} ratio achieves 90\%. Lower \emph{Mutual Overlap} ratio indicates better collaboration.
\end{itemize}
\vspace{-\topsep}

%  We remark that there is an error in calculating the \emph{Coverage} ratio due to the inaccuracy of the explorable region and merged explored area. Therefore, the exploration can be considered thorough if the \emph{Coverage} ratio is over 95\%.  
%These metrics are only for analysis, and we primarily focus on \emph{Steps} as our performance criterion.

% \item \textbf{Communication Traffic: }This is the total bytes of message exchange when the coverage ratio achieves $90\%$. Lower \emph{Communication Traffic} infers lower bandwidth required.
\subsection{Baselines}
We challenge {\name} against three representative planning-based approaches (CoScan, Topological Frontier, Voronoi) and three prominent RL-based solutions (ANS-Merge, NeuralCoMapping, MAANS). Note that Topological Frontier and Voronoi are also graph-based approaches.

% Note that existing RL-based works with active topological mapping~\cite{vgm,norl,topo-map2} are designed for single-agent navigation, which is a downstream task of exploration~\cite{singleagent-RL1} and is difficult to be directly extended to multi-agent exploration without the pre-defined target goal.


% \vspace{-\topsep}
\begin{itemize}
\setlength{\parskip}{0pt} \setlength{\itemsep}{0pt plus 1pt}
 \item \textbf{CoScan}~\cite{CoScan}: This frontier-based method applies k-means clustering to all frontiers and assigns a frontier cluster to each agent. Afterward, each agent plans an optimal traverse path over the assigned frontiers.
 %based on the optimal mass transport problem
 \item \textbf{Topological Frontier (TF)}~\cite{normalized_frontier}: This graph-based approach calculates a normalized traveling cost for each ghost node built from the Topological Mapper and considers the node with the lowest cost as the global goal.\looseness=-1
%   which is a linear combination of the number of neighbor ghost nodes and the distance from the ghost node to the agent.  by considering the distance and the number of its neighbors 
% by considering the number of its neighbors and the distance from the agent to the node.
 \item \textbf{Voronoi}~\cite{Voronoi}: This graph-based solution divides the map into several parts and transforms it into a Voronoi graph. Each agent then only searches the unexplored region in its partition, reducing the overlapped area.
 \item \textbf{ANS-Merge}~\cite{ans}: ANS is exemplary in RL-based single-agent exploration. It takes in egocentric local and global metric maps and infers global goals for the agents. We extend ANS to multi-agent exploration by sending merged maps to the global planner and use the same reward function as ours.
 \item\textbf{NeuralCoMapping (NCM)}~\cite{cvpr22}: NeuralCoMapping introduces a multiplex graph neural network to predict the neural distance between frontier nodes and agents. It then assigns each agent a frontier node based on the neural distance in each global step.
 \item \textbf{MAANS}~\cite{RL_multi2}: MAANS is a variant of ANS for multi-agent exploration. This method leverages a transformer-based Spatial-TeamFormer to enhance cooperation. For a fair comparison, we conduct training on 10 maps without the policy distillation mentioned in \cite{RL_multi2}.
\end{itemize}
% \vspace{-\topsep}
% adopts a CNN-based architecture that
%  \item \textbf{WMA\_RRT}~\cite{WMA-RRT}: This is a multi-agent variant of RRT~\cite{RRT}, where agents cooperatively build a single tree and observe a locking-and-search scheme.
%\item\textbf{NeuralCoMapping (NCM)}~\cite{cvpr22}: This is a frontier-based multi-agent exploration method that constructs a multiplex graph neural network to choose a frontier node.
% \item \textbf{ILP}~\cite{ILP}: This strategy uses the information gain and the distance cost from frontiers to agents to calculate the utility function. The agents select a sequence of frontiers with the most utility value to make a planning using the Hungarian algorithm~\cite{Hungarian}.

We remark that {\name} and the baselines are under the same assumptions in our task. All the baselines only replace the Topological Mapper and the {\planner} with alternatives and keep the rest the same as {\name}, except for TF, which only substitutes the {\planner}. 


% We include more implementation details in the appendix.

\begin{figure*}[ht]
\captionsetup{justification=centering}
	\centering
    \subfigure[\label{fig:casea}Comparison of Map Construction]
        {\centering
        {\includegraphics[height=4cm]{figures/case_a.png}
            }
    }
    \subfigure[\label{fig:caseb}Comparison of Planning Strategy]
        {\centering
        {\includegraphics[height=4cm]{figures/case_b.png}
    	}
    }
     \vspace{-2mm}
    \caption{\raggedright{Case studies of Map Construction and Planning Strategy. (a) shows that the graph structures of different scenes seem congruous in general, marked in grey. (b) displays agents' trajectories in Voronoi and {\name}, respectively.  }}
    \label{fig:case}
    \vspace{-5mm}
\end{figure*} 

% Voronoi constrains 2 agents in the green and the black partition, respectively. {\name} distributes agents based on the graph nodes.

\begin{figure}[ht!]
	\centering
     \vspace{1mm}
    \includegraphics[width=1.0\linewidth]{figures/overall_scenes.png}
    \vspace{-4mm}
	\centering \caption{Comparison between {\name} (red) and its variants. {\name} has the lowest \emph{Steps}
and \emph{Mutual Overlap}}
\label{fig:ab}
\vspace{-6mm}
\end{figure}
\subsection{Main Results}
\subsubsection{Evaluation Results}
The results in \cref{tab: gibson_results} show that {\name} outperforms all baselines with $N=3,4$ agents on unseen scenes on Gibson.
In both middle and large maps, {\name} attains the fewest \emph{Steps} and the highest \emph{Coverage} ratio. More concretely, MAANS is the best RL baseline since its transformer-based Spatial-TeamFormer captures the spatial relationship and team representation, while {\name} has 10.10\% and 7.63\% fewer \emph{Steps} than MAANS with $N=3,4$ agents, respectively. This indicates that ghost nodes, which are always located in unexplored areas, motivate agents to explore unseen regions. {\name} also excels in the \emph{Mutual Overlap} ratio among the RL solutions, suggesting that it better assigns global goals to agents in different unexplored directions.\looseness=-1


Among the planning-based baselines, the best competitor, Voronoi, achieves the lowest \emph{Mutual Overlap} ratio in the 3-agent setting, demonstrating that the Voronoi separates agents to reduce the overlapped area. However, {\name} is superior to Voronoi in the \emph{Steps} and the \emph{Coverage} ratio, reducing \emph{Steps} by 26.40\% and 31.57\% for $N=3,4$ agents, respectively.
This implies that although the Voronoi partition separates agents, it may hinder exploration efficiency by confining agents to stay in their respective areas. 

% On the contrary, the RL-based solution has the potential to adapt to complex strategies in various situations.

% For example, the Voronoi agent cannot go through the corridor in the other agent's partition to further explore the unseen area. 

\subsubsection{Domain Generalization}
% We evaluate the model trained on the Gibson dataset  For domain generalization, \cref{tab: hm3d_results} summarizes the performance with $N=2,3$ agents on the HM3D dataset. 
We also report the domain generalization performance in \cref{tab: hm3d_results}, where
all models trained on the Gibson dataset are evaluated in the HM3D domain.
The results indicate that {\name} performs best. Compared to {MAANS}, the best competitor, {\name} achieves 13.45\% and 11.04\% fewer \emph{Steps} with $N=3,4$ in super large scenes. This implies that the trained MAANS may overfit to the spatial arrangements in the training maps, resulting in suboptimal performance on unseen scenes in other domains due to variations in different metric maps.
In contrast, {\name} exploits the graph structure with abstract but essential information to better adapt to scenarios in an unseen domain. \looseness=-1


The planning-based methods fail to achieve an average \emph{Coverage} ratio of 90\% on super large maps. 
This indicates that the factors affecting exploration success are more complex on unseen super large maps. It is difficult for planning-based agents to take all factors into account in manual parameter tuning. As a result, agents may get stuck in the corner and fail to reach 90\% \emph{Coverage}.



% The best planning-based method, Voronoi, has 11.06\% and 25.65\% more \emph{Steps} than {\name} with $N=2,3$ agents on super large maps.

% \subsubsection{Comparison in Communication Traffic}
% {\color{red}In a map with a size of $M\times M$, the communication traffic of the metric map can be compressed by Huffman encoding~\cite{Huffman}. At the same time, the communication traffic of each global step is $K\times b$ for the topological graph, where $K$ is the number of nodes, and $b$ is the feature dimension of a node. In {\name}, $K$ is around $40$ and $b$ is $4$ in a $480\times 480$ metric map. In~\cref{tab: communication}, the results of the communication traffic in an episode reveal that {\name} affords the best performance among all baselines, reducing the communication traffic by over 91.70\%. It is suggested that {\name} is more reliable in real scenarios with a restricted bandwidth.}
\iffalse
huffman 1bit*480*480 -> (5bit*4+4bit*6)/10 *480*480 -> 1bit*480*480
32 bit == 4 byte
\fi

\subsubsection{Case Study}
We present case studies of map construction in two different scenes to showcase the generalization of {\name}. Besides, to further demonstrate the cooperative exploration strategy of {\name}, we visualize the planning strategies of {\name} and the most competitive planning-based method, Voronoi.


%We visualize our MANTS and a planning-based algorithm Voronoi in three different scenes. The results show our capacity of generalization and coordination, which contributes to its great performance.

In Fig.~\ref{fig:casea}, the graph structures in two different scenes appear to be generally congruent (i.e., the area in grey). This suggests that topological maps, which contain abstract but essential information, are less influenced by scene structures, endowing them with significant generalization capabilities. Conversely, the shape of metric maps depends on the layout of the scene. As a result, finding a (near) optimal exploration strategy for various metric maps is challenging.
In Fig.~\ref{fig:caseb}, the agent trajectories show that {\name} successfully allocates agents to different unexplored areas via the selected ghost nodes. Moreover, {\name} agents can temporarily revisit previously explored areas to reach unexplored areas in different directions, thereby increasing the final coverage. 
On the contrary, when the only path to the unexplored area belongs to the partition of a particular Voronoi agent (i.e., the area in blue), the other agent can only be constrained to its own partition (i.e., the area in green), resulting in inefficient exploration.


%We hypothesize that Voronoi may fail in some complex environments due to its formally-designed cooperative strategy.

\iffalse
\subsubsection{Asynchronized Evaluation}
We consider an asynchronized situation where some agents loss their connection during exploration so that the message received by these agents is incomplete. In~\cref{tab: hm3d_results}



\fi

\iffalse

\begin{figure}[h]
	\centering
    \includegraphics[width=0.9\linewidth]{figures/real.png}
	\centering \caption{The deployment of real-world robot system. }
\label{fig:real}

\end{figure}
\fi




% and measure the \emph{Steps} and the \emph{Mutual Overlap} ratio  derived from the visual encoder~\cite{vgm}
\vspace{-1mm}
\subsection{Ablation Study}
We report the training performance of several RL variants to investigate the importance of the Mapper and the {\planner}.

% \vspace{-\topsep}
\begin{itemize}
\setlength{\parskip}{0pt} \setlength{\itemsep}{0pt plus 1pt}
 \item \textbf{Mapper w.o. Distance: }Without the help of the FMM distance, the Topological Mapper constructs the graph based solely on the similarity of the visual embeddings. 
  \item \textbf{{\planner} w.o. History: }We abandon the historical graphs, $\hat{G}$, and the Graph Fusion. The Main Node Selector only takes $G$ as input.
 \item \textbf{{\planner}-Single: }We abandon the Main Node Selector and only adopt the Ghost Node Selector to infer global goals.
 \item \textbf{{\planner}-Concat: }Before calculating $S_{g, re}$ in the Ghost Node Selector, we update ghost node features by concatenating them and the corresponding main node features. We then discard the multiplication in Equation~\ref{eq:multiply} and directly consider $S_{g, re}$ as the final matching score.
 
\end{itemize}
% \vspace{-\topsep}
\iffalse
\item \textbf{{\planner} w.o. GNN}: We replace GNN with Multi-Layer Perception to extract the relationship between different kinds of graphs in {\planner}.

  \item \textbf{{\planner}-Mean: }We replace GNN with mean operation to update the node features in the graphs and only implement GNN to calculate the weighted scores.
  \emph{{\planner}-Mean} results in the highest \emph{Mutual Overlap} ratio and \emph{Steps}, indicating that GNN infers probability distribution of different global goal candidates and can better capture the interactions among agents and topological map to encourage exploration efficiency and cooperation.
\fi

% an illogical map structure due to
As shown in Fig.~\ref{fig:ab}, {\name} has the lowest \emph{Steps} and \emph{Mutual Overlap} ratio in $N$= 2 agents on Gibson. {\name} is superior to \emph{Mapper w.o. Distance} with over 10\% lower \emph{Steps}, suggesting that distance-based heuristics reduce incorrect connections between nodes and provide a more accurate graph for effective global planning.
Among all {\planner} variants, \emph{{\planner}-Single} has the highest \emph{Mutual Overlap} ratio and \emph{Steps}. This indicates that directly selecting ghost nodes as global goals may lead to a sub-optimal solution due to the large number of node candidates. The performance of \emph{{\planner} w.o. History} is worse in \emph{Mutual Overlap} ratio, suggesting that the lack of historical memory affects cooperation.
\emph{{\planner}-Concat} shows the lowest training convergence. The result expresses that the concatenation of the main and ghost node features prevents the {\planner} from better perceiving the relationship between these two types of nodes.

% the hierarchical global selection can be easily optimized with much fewer node candidates, while 

% \subsection{Real-World Transfer}
% {\color{red}We deploy the {\name} for exploration on two Mecanum steering robots with noisy odometry sensors in the real world. However, the transfer from the visual-based simulator to the real world is challenging due to the perception gap and the imperfect motion. To reduce the uncertainty, we first test {\name} and baselines in Gazebo~\cite{Gazebo}, a simulator in support of ROS~(Robot Operating System)~\cite{ROS}, and then transfer the system into the real world.} 

% \input{tables/time}

% {\color{red}As shown in ~\cref{tab: time}, we compare {\name} with the best planning-based and RL-based competitors, Voronoi and MAANS, stating the \emph{Run-Time} when agents achieve 95\% \emph{Coverage} ratio in the environment. 
% In the Gazebo, {\name} shows the best performance, denoting that it prefers to assign distant targets to different agents resulting in cooperative and efficient exploration. However, {\name} is a bit better than other baselines in the real world. We hypothesize that the real-world test scene is relatively small (i.e., the size is 30 $m^2$), where {\name}'s strength of cooperative exploration is less obvious.
% More details can be found in Appendix 4.}

\iffalse
Besides, the running time of different methods in the real-world is presents in \yxy{tab:fig}, showing that {\name} outperforms the all the baselines with a large margin. Specifically, \yxy{add comment}, which suggests that {\name} effectively and cooperatively explores the environment.
\fi

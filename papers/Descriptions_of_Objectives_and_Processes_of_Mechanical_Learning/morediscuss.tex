{\bf Learning vs. Approximating}\\
Very often people are saying: "Machine learning is nothing but a kind of approximation to probability distribution". We would argue this view is quite far from reality. For the sake of arguments, let's see dictionary definition first. We use online dictionary "www.dictionary.com". For learning, the definition is "to acquire knowledge of or skill in by study, instruction, or experience"; for approximating, "to come near to; approach closely to; to estimate". They are very different. Of course, this pair of 2 words, like many other pairs, indeed have something in common, such as "to approach the knowledge vs. to acquire knowledge". It is hard to make one absolute black and white differentiation. However, we would like to point out one big difference: learning is to use outside information to build up one best possible inside model, while approximating is to use outside information to get closer to a model previously chosen. We would think this cutting line is acknowledged by most people. 

By this cutting line, we can see clearly that mechanical learning is indeed learning, not approximating, since it is using information of feed in data to get an X-form and drive X-form to become better. Mechanical learning is not approximating a model previously defined. In fact, there is no previously defined model at all. As we see in appendix, deep learning is not approximating either. Deep learning is trying to get a better X-form from a set of chosen X-forms (huge number of such X-forms) by using certain methods (like CD+SGD, etc). It is very different from approximating probability distribution.     

The above argument seems a little trivial. However, to clarify what is learning and what is approximating could help us to clean mind greatly. We want machine to build its own model for outside (as smartly as possible), and do not want machine just follow one model previously defined, which could not be suitable for all situations, no matter how good it is.
\bigskip

{\bf Internal Representation Space}\\
A learning machine consists of several parts. However, internal representation space is the most essential part. It might not be explicitly viewable, but it indeed exists. In our definition of learning machine, we do not specifically require a internal representation space. However, it comes as a consequence of being a learning machine. Such fact illustrates the importance of internal representation space even more clearly. In practice, a learning machine could have no a intentionally designed internal representation space. For example, RBM is such a learning machine. However, as we can see in Appendix, internal representation space indeed exists and play essential role in learning. Again, if a learning machine satisfies Definition 1, it must have an internal representation space, even though we might not know exactly how internal representation space works.

Though we might not know exactly how internal representation space works, we know that it is equivalent to a space consists of X-forms. X-form is a subjective way of a learning machine to organize its view about patterns. Learning machine learns from its input data and tries to adapt a better X-form. A better X-form means to have a better way to perceive and process the incoming pattern.

Thus, to have a good internal representation space would be the key to a successful learning machine. First, it should have sufficient expression power to include any necessary X-form; second, it should have good structure so that expressions can be easily understood; third, dynamics on X-form can be easily executed and easily understood. 

Here, we would like to raise such a question: In what way to mathematically describe internal representation space? We know it is collection of X-forms. This is actually one good mathematical description. However, can we do better? We need to find tools to describe relationship of X-forms and sub-forms in more details and to calculate X-form and sub-forms easily. One possible tool is catagory theory. This direction is very worth to pursue. 

We also point out one fact about internal representation space. As we see in the learning of both by teaching and without teaching, internal representation space serves a reservoir for X-forms. These X-forms, might not be useful for certain learning, however, could turn out to be very useful for others. Such fact highlights the importance of internal representation space. How to utilize this reservoir of X-forms is going to be critical for many applications. 
\bigskip
 


{\bf Combine 5 Learning Approaches together}\\
Petro Domingos in \cite{pedro} discussed 5 different learning approaches. In \cite{paper1}, we speculated possibilities to unite 5 different learning approaches. Now, we can confidently say: a good internal representation space indeed is the center to unite 5 different approaches together. We briefly put some thoughts below.

1. Logical Deduction Approach. 
This is very clear. One X-form is actually a logic statement. When doing learning, a lot of X-form would be accumulated in internal representation space. So, logical searching and logical deduction would be very naturally done on these X-forms. In this way, it is very natural to connect the learning machine with a set of logical deduction rules to generate new X-form, and compare new X-form with output feedback.  

2. Connectionist Approach.
Just looking into its definition, we can easily see that one X-form is a set of connections. So, it is already a connectionist approach. Reversely, for any connectionist model, all connections would form a visible internal representation space. Thus, to focus on internal representation space actually means connectionist approach. This is also a strong evidence that good learning machine should utilize connectionist model.

3. Probability Approach.
In principle, we can build probabilistic view on X-forms. For example, if we assign some probabilistic measure on X-forms, probabilistic operation can be done on learning. 
In this way, a Bayes like model can be build on the movement of X-forms. Also see "Deterministic vs. Probabilistic" below.

4. Analogy Approach. 
In internal representation space, we have many X-forms. Some X-form might be quite close to another, by this way or that way, subjectively or objectively, logically or probabilistically, realistically or imaginably, etc. So, analogy appears naturally. We can think analogy is just a different way to view those X-forms, transformed way, different connection way, distorted way, etc. Not only we can easily view analogy, we can also easily execute analogy, since X-form is already connect well to processing. For example, if we first have X-form $e$, and we can see another X-form $e'$, and see $e'$ as an analogy to $e$, we can immediately have execution of $e'$: just use $e'$ to replace $e$. It is very natural to conduct analogy approach with internal representation space. Also, analogy has a lot to do with subjectiveness. So, learning method utilizing analogy could be very efficient and powerful.

5. Evolution Approach.
If we stay with level 1 learning machine, there is no evolution, since learning method is not changing. But, if we go to level 2 learning machine, evolution starts immediately. We can go even higher level, i.e. evolution of evolution. See, our learning machine capture evolution well, and make all related execution easily realizable. 

Summarize, we now know that in a learning machine, if we have a good internal representation space, all kinds of learning approaches can live together and support each other on the internal representation space. This is one huge advantage. We can use each method for its own strength to get a better learning machine.
\bigskip


{\bf Deterministic vs. Probabilistic}\\
Our definition makes learning machine deterministic, and everything followed is also deterministic. In this framework, any probabilistic view, if any, is just supplementary. However, we would like to point out, 100\% deterministic is difficult. Probabilistic view indeed has advantages in some aspects, and it is necessary. For example, often it is easier to get a probability measure than an exact function. But, we would like to point out: learning machine should be mainly based on deterministic framework. There are compelling reasons for this. Input data indeed has rich intrinsic structure, and a learning machine needs to capture such structure in order to be efficiently and effectively learning and process patterns. If learning machine has 100\% probabilistic view, it would treat all things as a random event, its internal representation space would be very flat (i.e. no hierarchy structure), cause it very hard to get intrinsic structure. The reason to have a deterministic framework system is because the world around learning machine is structurally deterministic (data indeed has intrinsic structure). 

To adding probabilistic view, much more works are needs. Consider a $N$-1 IPU $\mathcal{M}$, and its processing $F: PS^0_N \rightarrow \{0, 1\}$. If we view it deterministically, $F$ is one mapping, which is exact and often hard to obtain. If we view it probabilistically, $F$ is not exact mapping, we can only consider probability of base pattern going to 1 or 0. Usually, it is much easier to approximate the probabilistic measure than to obtain exact mapping. However, easiness is only on surface. If we want to explore the inter-relationship of base patterns, such as "base pattern $b_1$ is base pattern $b_2$ and $b_3$ appears together with certain probability", it would be hard mathematically. This is why we only do deterministic view here. In this way, we hope to grasp the most essential understanding. 

However, our world is indeed full of probabilistic events, we do need to build one model combining intrinsic pattern structure with probability. In order to do so, we have to handle how logic ("+", "$\cdot$", "$\neg$", etc) propagate in probability measure, and how objective view and subjective view collides in probability space. Perhaps, this is a full view of new Bayes like logic. This is a great direction, we will try it in later works. Someone has done work from probabilistic view on deep learning, see \cite{gal}. However, the work is totally based on deep learning, which has no concept of subjectiveness and X-form. \\


{\bf Data Sufficiency} \\
We need data to drive learning. Generally speaking, more data, more learning. But, how much data are sufficient? Up to now, no any theory about this crucial issue exists. We use X-form and sub-form to understand this issue. We define data sufficient to support an X-form, and data sufficient to bound an X-form. Such sufficiency lays down a theoretical framework for us to understand data: why we need such amount of data for this learning? how much data are necessary for that learning? etc. But, to establish such data sufficiency is just beginning. 

In section 5, Strategy 2 and Strategy 3 show us that data sufficiency indeed depends on learning capability. Generally speaking, strong capability needs weaker data, and vise versa.  The relationship of data and learning strategy, methods and machine capability are very important. The data sufficiency we introduced is just the beginning, we need to more work in this direction. Also this is related to learning theory. 
\bigskip



{\bf Learning Strategies and Methods } \\
Learning is a dynamics on X-forms, from one X-form to another. Such a dynamics is determined by learning strategies and methods. A learning machine could be smart (i.e. it can learn better, using less data, learn faster, etc.), and could be dumb (more data, learn slow, etc.). Smartness or dumbness are mostly determined by learning strategies and methods. 

In section 5, we demonstrate 3 learning strategies. There should be many other learning strategies and methods. We invent strategy {\it squeezing to higher abstraction and more generalization} here. We should continue to invent more. 

Actually, learning method could be learned. We have defined Level 1 learning machine, which could not modify its learning method. Level 1 learning machine is what we focus on for most time. But, in many cases, it is good to introduce level 2 machine, which can modify its learning methods. In this sense, one approach should be: we are going to use learning to get more and better learning strategies and methods.
\bigskip


{\bf Mathematical Learning Theory} \\
If the learning machine is super intelligent, it might only need a few data to learn everything. But, we are discussing mechanical learning here. Learning machine only follow some simple and mechanical rules. It could not learn from nothing. Without sufficient data driven, it will not be able to learn. In order to understand these issues, it is best have a general theory about learning: by using what learning strategy and method, with what capabilities, by what kind of data, how much amount of data, what a learning machine can learn, with what kind of complexities. We strongly believe that such theory could be established, and such theory is mathematical. Though we cannot pursue such theory right now, we can speculate that this theory make learning clearer. This theory will be able to explain and measure the complexity of learning objects, structure of data, efficiency and effectiveness of learning methods and strategies, learning process and governing equations, and more. We might call this as Mathematical Learning Theory. Such a mathematical theory might be even expanded with philosophical flavor -- Mathematical Epistemology. This is one exciting view and we hope to do some concrete work in this direction later.
\bigskip


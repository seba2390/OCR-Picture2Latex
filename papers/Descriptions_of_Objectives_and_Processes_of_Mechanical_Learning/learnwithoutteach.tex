Learning by teaching is a very special way to drive learning. From discussions in last section, we can see clearly,  only when we have full knowledge of learning machine and the desired pattern, we could possibly design a teaching sequence. In this sense, learning by teaching is quite similar to programming -- to inject the ability into the machine, not machine to learn by itself. Of course, learning by teaching is still a further step than programming, and it will bring us a lot more power to handle machines than just programming. 

We focus on $N$-1 learning machine $\mathcal{M}$. 

{\bf Typical Mechanical Learning } \\
From examples of mechanical learning, typical mechanical learning would be as below: 
\begin{enumerate} [topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
\item For $N$-1 learning machine $\mathcal{M}$, the learning target is often is given as an objective pattern $p_o$, $\mathcal{M}$ is expected to learn, and the learning result is that the black set of $\mathcal{M}$ become $p_o$. 
\item To drive the mechanical learning, data sequence is fed into $\mathcal{M}$. In learning by teaching, the data sequence is a specially designed teaching sequence. In learning without teaching, typically, data to feed into $\mathcal{M}$ are chosen from target objective pattern $p_o$, and from $p_o^c$. In another word, it is sampling $p_o$.
\item Feed-in data will drive learning, i.e. the black set of $\mathcal{M}$ is changing. Hopefully, at some moment later, the black set $B_t$ at the moment $t$ becomes $p_o$, or at least $B_t$ approximates $p_o$ well. 
\end{enumerate}

We put the above observations into a formal definition. 


\begin{definition}[\bf Typical Mechanical Learning]
Let $\mathcal{M}$ be a $N$-1 learning machine, action of typical mechanical learning is: 
\begin{enumerate} [topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
\item to set one target pattern: $p_o \subset PS_0^N$; 
\item to choose one sampling set $S_{in} \subset p_o$, normally, $S_{in}$ is a much smaller set than $p_o$. But, in extreme case, could be $S_{in} = p_o$; 
\item to choose another sampling set $S_{out} \subset p_o^c$, i.e. all member in $S_{out}$ is not in $p_o$. $S_{out}$ is a much smaller set than $p_o^c$. But, in extreme case, could be $S_{out} = p_o^c$; 
\item to use sampling set of $S_{in}$ and $S_{out}$ to form data sequence. In data sequence, data are $(b_i, o_i), i = 1, 2, \ldots$, if $b_i \in S_{in}$, $o_i$ is 1 or $\varnothing$ (empty), if $b_i \in S_{out}$, $o_i$ is 0 or $\varnothing$ (empty). 
\item to feed data sequence into $\mathcal{M}$ consecutively, we do not restrict how to feed, and how long to feed, and how often to feed, how to repeat feeding, which part to feed, etc.
\end{enumerate}
The action above will drive $\mathcal{M}$ to learn. As the result of learning. its processing (equivalently, black set) is changing.
\end{definition}
Remark: $S_{out}$ could be empty, i.e. not sampling out of $p_o$. But, $S_{in}$ is often not empty. However, if $S_{in}$ is empty, $S_{out}$ should not be empty. We will discuss this more in Data Sufficiency. 
 
For such typical mechanical learning, what is happening in the learning process? To address this, first we want to examine learning machine.
\bigskip



{\bf Internal Representation Space }\\
For a learning machine $\mathcal{M}$, it has input space ($N$-dim binary array), and output space ($M$-dim binary array, but here $M=1$), and something between input space and output space. This something between is the major body of a learning machine, and we denote it as $\mathcal{E}$. What is $\mathcal{E}$? We have not discussed it yet. We need to carefully describe $\mathcal{E}$ and its essential properties.

At any point of learning, if we stop learning, then $\mathcal{M}$ is a IPU, i.e. it has processing $F: PS^N_0 \to \{0, 1\}$ at the moment. So we can say, at this moment, $F$ uniquely defines something between input and output. Thus, at the moment, we can think, between input space and output space is $F$. Thus, it is quite reasonable to define $\mathcal{E}$ as the collection of all processing of $\mathcal{M}$. And, we will give a better name to $\mathcal{E}$: Internal Representation Space. 

\begin{definition}[\bf Internal Representation Space]
For $N$-1 learning machine $\mathcal{M}$, the major body of $\mathcal{M}$ that lays between input space and output space is called as internal representation space of  $\mathcal{M}$. At any moment, the processing of $\mathcal{M}$ is one member of this internal representation space. So, the internal representation space is the collection of all possible processing of $\mathcal{M}$. We denote it as $\mathcal{E}$. 
\end{definition}
Remark: All possible processing of $\mathcal{E}$ is $2^{2^N}$, an extremely huge number for not too small $N$. But for a particular learning machine, its internal representation space might be limited, not fully. 

For $N$-1 learning machine, for any processing $F$, it is equivalent to its black set $B$. By theorem 4, there is at least one X-form (one algebraic expression $E$, and some base patterns $b_1, b_2, \ldots, b_K$) so that $B = E(b_1, b_2, \ldots, b_K)$. We say that this X-form expresses processing $F$. Thus, naturally, we can think, the collection of all X-forms can be used to express the internal expression space. We have following definition.


\begin{definition}[\bf Internal Representation Space (X-form)]
For $N$-1 learning machine $\mathcal{M}$, the major body of $\mathcal{M}$ that lays between input space and output space is called as internal representation space of  $\mathcal{M}$. At any moment, one X-form expresses the processing of $\mathcal{M}$, it is one member of this internal representation space. So, the internal representation space is the collection of all possible X-forms. We denote it as $\mathcal{E}_X$.
\end{definition}
Remark, for one processing (which is equivalent to one black set), there is at least one X-form to express it.
Quite often, there are many X-forms to express one processing. So, the size of $\mathcal{E}_X$ would be not less than the size of $\mathcal{E}$. In fact, it is much larger. Learning sure is to get correct processing. However, to seek a good X-form that expresses the processing is more important. Thus, to use definition 5.3 (all X-forms as the internal representation space) is much better than to use definition 5.2. From now on, we will use definition 5.3. And, we just denote internal representation space as $\mathcal{E}$.


Now, we can clearly say, learning is a dynamics on space $\mathcal{E}$, from one X-form to another X-form. Or, we can say, learning is a flow on internal representation space. 

One important note: No matter what a learning machine really is, if it satisfies the definition of learning machine, it must have internal representation space as we defined above. If we concretely design a learning machine,  the internal representation space is designed by us explicitly, we know it well and can view its inside directly. If the learning machine is formed by different way, such as from a RBM (see Appendix), we could not view the inside directly. But, in theory, internal representation space indeed exists, and this space, equivalently, consists of a collection of X-forms. In theory, such space might be limited, not all X-forms, but only a part of the collection of all possible X-forms. This is not good. But, unfortunately, many learning machines are just so. However, when we discuss learning machine theoretically, the internal representation space is as definition 5.3.  
\bigskip





{\bf Learning Methods} \\
For a learning machine $\mathcal{M}$, besides input space, output space, and internal representation space $\mathcal{E}$, clearly, it must also have learning mechanism, or learning methods. So, we need to describe learning methods.


Now we know that learning is a dynamics on internal representation space, moving from one X-form to another. But, how exactly? 




Let's make some notations. We have learning machine $\mathcal{M}$, its input space, output space, and its internal representation space $\mathcal{E}$, and a learning method $LM$. As in definition 5.1, we also have target pattern $p_o$, and data sequences $\{(b_i, o_i) \ | \ i = 1,2,\ldots\}$. Also assume the initial internal representation (one X-form)  is $e_0 \in \mathcal{E}$. 

Now, we start learning. First, one base pattern $b_1 \in S$ is feed into input space, and its feed-back value $o_1$ is also feed into output space ($o_1$ could be $\varnothing$ (empty), in that case, just has no feed-in to output space). Driven by this data, learning method $LM$ moves internal representation from $e_0$ to $e_1$, which can be written as:
$$
e_1 = LM(e_0, b_1, o_1 ) 
$$
Here, $LM$ is the learning method. Note, since the learning is mechanical, it is legible to write function form (if it is not mechanical, might not be justifiable to write in such function form). This is just the first step of learning. Next, we have: $e_2 = LM(e_1, b_2, o_2) = LM(e_0, b_1, o_1,  b_2, o_2)$. The process continues, we feed data  $(b_1, o_1), (b_2, o_2), \ldots, (b_k, o_k)$ into input space consecutively, and we have: 
\[
e_k = LM(e_0, b_1, o_1, b_2, o_2, \ldots, b_k, o_k ), k = 1, 2, \ldots  \label{eq:lmk} \tag{lm}  
\]
Note, the feed-in data could be repeating, i.e. could have $b_i = b_j$ while $i \ne j$.

This equation  \eqref{eq:lmk}  is actually the mathematical formulation for definition 5.1 -- typical mechanical learning.  

With this process, as $k$ increase, X-form $e_k$ continues to change, and we hope at some point, $e_k$ would be good enough for us. What is good enough? Perhaps, there are more than one criteria. For example, "$e_k$ to express $p_o$", i.e. the black set of $e_k$ equals the target pattern $p_o$. But, also, could be: "$e_k$ to express a good approximation to $p_o$". Or, additional to "express $p_o$, some additional goals are posted, such as $e_k$ is based upon less base patterns, etc.

Yet, how do we know $e_k$ would make our hope become true? Several questions immediately pop up:
\begin{enumerate} [topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
\item What is the mechanism of $LM$ to make the $e_k$ approach $p_o$?
\item Is data sequence good enough? how to know data sequence is good enough? 
\end{enumerate}

We would first discuss sufficiency of data, then further discuss the learning mechanism. 
\bigskip



{\bf Data Sufficiency} \\
Learning machine needs data, and data drives learning. More data, more driving. But, data are expensive. It would be nice to use less data to do more, if possible. More importantly, we need to understand what data are used for what purpose. 




As we know already, learning is actually to get one good X-form. But, one X-form normally is a quite complicated and is quite hard to get. How can a mechanical learning method get it? Mechanical learning is not as smart like human, it only follow certain simple and fixed rules. In order to make a mechanical learning to get a complicated X-form, sufficient data are necessary. But, what are sufficient data? Good thing is that X-form itself gives a good description of such data. 


We already know that an X-form and all its sub-forms give perception bits. This tells us that X-form and all its sub-forms describe the structure of black set. To tell one X-form, the least data necessary are 2: one is in the black set, another is not in the black set. Of course, just 2 data is not sufficient to describe a X-form. However, how about for each sub-form, we can find such pair of data, one is in, and one is out? It turns out, all such pairs are very good description for the X-form. This is why we have following definitions. 



\begin{definition}[\bf Data Sufficient to Support a X-form]
Suppose $e$ is a X-form, and suppose all sub-forms of $e$ are: $e_1, e_2, \ldots, e_L$. For a set of base patterns $DS \subset PS_N^0$, if for any sub-form $e_j$, there is at least one base patterns $b_j \in DS$ so that $e_j(b_j) = 0, e(b_j) = 1$, we said data set $DS$ is sufficient to support X-form $e$. That is to say, for each sub-form $e_j$, we have a data $b_j$ that is in black set of $e$, but not in black set of $e_j$.
\end{definition}
When we do sampling as in definition 5.1, if the sampling includes data sufficient to support X-form $e$, then the data sequence $D = \{(b_i, o_i) |  i =1, 2, \ldots\}$ will have such property: for each sub-form $e_j, j = 1, \ldots, L$, there is at least one data $(b_i, 1)$ in $D$ so that $e_j(b_i) = 0$. For such a kind of data sequence $D$, we say the data sequence is sufficient to support X-form $e$. 




Data sufficient to support means: for each sub-form of a X-form, there is at least one data to tell learning machine, {\it This is only a sub-form. It is good, but not good enough}. With such information, learning method could conduct learning further mechanically. 

Data sufficient to support a X-form is to provide information from inside a X-form. But, we also need information from outside a X-form. To do so, we will define data sufficient to bound a X-form. In order to say more easily, we make some terms first. For 2 X-form $e$ and $f$, if $b \in PS_N^0$ and $e(b) = 1$ implies $f(b) = 1$, we say $f$ is over $e$ (this is equivalent that the black set of $f$ is greater than the black set of $e$). For 2 X-form $e$ and $f$, if there is $b \in PS_N^0$ so that $e(b) = 0$ and $f(b) = 1$, we say $f$ is out boundary of $e$ (this is equivalent to say the black set of $f$ is not subset of the black set of $e$). 


\begin{definition}[\bf Data Sufficient to Bound a X-form]
Suppose $e$ is a X-form, and suppose all sub-forms of $e$ are: $e_1, e_2, \ldots, e_L$. For one sub-form $e_j$, if for any X-form $f$ that is both over $e_j$ and out boundary of $e$, there is at least one $b \in DS$ so that $e(b) = 0, f(b) = 1$, we call this data set $DS$ as sufficient to bound $e$.   
\end{definition}
When we do sampling as in definition 5.1, if the sampling includes data sufficient to bound X-form $e$, then the data sequence $D = \{(b_i, o_i) |  i =1, 2, \ldots\}$ will have such property: for each X-form $e'$ that is both over $e_j$ and out boundary of $e$, there is at least one data $(b_i, 0)$ in $D$ so that $e'(b_i) = 1$. For such a kind of data sequence $D$, we say it is sufficient to bound X-form $e$. 


Data sufficiency to bound means: for any X-form that is over a sub-form, and out of boundary of $e$, there is at least one data $b$ to tell learning machine, {\it This X-form is not good, it is out of boundary}. With such information, learning method could conduct learning further mechanically.  



{\bf Examples of Data Sufficient to Support a X-form: } \\
1. $e = b_1 + b_2$ is one X-form. Its all sub-forms are $b_1$ and $b_2$. So, $\{(b_1, 1), b_2\}$ are data sufficient to support $e$. \\
2. $e = b_1 \cdot b_2$ is one X-form. $e$ has no sub-form. Data set $\{b'\}$ or  $\{b''\}$ or $\{b'''\}$ are all data sufficient to support $e$. \\
3. $e = b_1 + (b_1 \cdot b_2)$ is one X-form. Its all sub-forms are $b_1$ and $b_1 \cdot b_2$. Data set $\{ b_1, b' \}$ is data sufficient to support $e$. And, so do  $\{ b_1, b'' \}$.  
\bigskip





{\bf Learning Strategies and Learning Methods } \\
Again, learning is a dynamics of X-forms, from one X-form to another. X-form is complicated. How come such a dynamics reaches the desired X-form? Such dynamics is determined by learning methods, and learning strategies. We discussed learning methods above, which is described well in equation  \eqref{eq:lmk}. Learning methods have set of rules on how to move from one X-form to another. Learning strategy is higher than learning method. It will govern these aspects: what X-forms to consider? what general approach to X-form? pre-set some X-forms? Or everything from scratch? etc. So, we can see that strategy governs method. Also, different strategy works for different kind of data. Different strategy also need different learning capabilities

We should emphasis here: learning is a complicated thing, one strategy and one method cannot fit all situations. There must be many strategies and even more methods. We are going to discuss some strategies and methods. But, still, there should have some common rules for these strategies and methods. 


One very important property of X-form is: one processing (equivalently one black set) could be expressed by more than one X-form (normally, many). This property will play very important role in learning. Let's see one simple example first. Consider a set of base patterns $B$:
\[
B = \{ b_1, b_2, \ldots, b_K \}    \label{eq:bset} \tag{bs}
\]
$B$ has totally $K$ base patterns. What X-form could express $B$? The easiest one is:
\[
e = b_1 + b_2 + \ldots + b_k   \label{eq:exp} \tag{exp}
\]
Sure $e$ is one X-form to express $B$. Now, if we assume we can write $b_3, \ldots, b_K$ as some subjective expressions of $b_1$ and $b_2$, as following:
\[
b_3 = E_3 (b_1, b_2), \ldots, b_K = E_K (b_1, b_2)
\]
So, we can further have:
\[
e' = E_3 (b_1, b_2) + \ldots + E_K (b_1, b_2) = E' (b_1, b_2)  \label{eq:exp2} \tag{exp2}
\]
We can see X-form $e$ and $e'$ express the same black set. But, the 2 X-forms are very different. In fact, $e'$ is more complicated than $e$, and with higher structure. But at the same time, $e'$ is upon much less base patterns, just $b_1$ and $b_2$, while $e$ is upon on $K$ base patterns. 

This is very crucial: to learn $e$, we might have to use all base patterns $b_1, \ldots, b_K$, while to learn $e'$, in principle, we might only use 2 base patterns $b_1, b_2$ (just might, might need more, depends on learning method). And, not only that, it is much more. $e$ is just a collection of some base patterns, and no relationship between these base patterns are found and used, while $e'$ is built on many the relationship between base patterns (of course subjectively). In this sense, comparing to $e$, $e'$ is a better X-form to express black set $B$.  

The lesson to us is: to express one processing (or black set), there are many possible X-forms. Some such X-forms are simple, but, not good. Some of such X-forms are complicated, but, actually more robust. All learning strategies will use this fact.

One learning strategy will put some requirements on data and on learning machine. That is to say, data must strong to some point. And, learning machine is required to have certain capabilities. We do not specifically design a learning machine here. So, we do not know exactly how to realize such capabilities. But, we describe learning machine, and we show that with such capabilities, this strategy will work.

Now, we would propose some learning strategies. 
\bigskip

{\bf Strategy 1 -- Embed X-forms into Parameter Space}\\
This strategy will embed X-forms into parameter space, and use the dynamics on parameter space to drive the flow of X-forms. Parameter space $\mathbb{R}^U$ is a real Euclidean space, usually $U$ is a big number. In this strategy, we choose $L$ X-forms, $e_i, i = 1, 2, \ldots, L$ (so we only use some X-forms), and we will cut $\mathbb{R}^U$ into $L$ pieces, each piece is a region, denote as $V_i, i = 1, 2, \ldots, L$, so that $\mathbb{R}^U = \bigcup_{i=1}^L V_i$, then we associate each X-form with each region, $e_i \sim V_i$. In this way, we embed $L$ X-forms into the parameter space  $\mathbb{R}^U$. If we introduce a dynamics on $\mathbb{R}^U$, we actually introduce a dynamics on those $L$ X-forms. Since dynamics on $\mathbb{R}^U$ is a very familiar and mature mathematical topic, we have a great lot of tools to handle such dynamics. In this way, we can transfer the dynamics on X-forms into dynamics on $\mathbb{R}^U$. Or, we transfer learning to a dynamics on $\mathbb{R}^U$.

More exactly, we can write down this strategy as following. Let $\mathbb{R}^U$ be a real Euclidean space, $U$ is a big integer. And, by some way, $\mathbb{R}^U$ is cut into $L$ regions so that $\mathbb{R}^U = \bigcup_{i=1}^L V_i$, and  $V_i \cap V_{i'} = \varnothing$ for any $i, i'$. We also choose $L$ X-forms $e_i, i = 1, 2, \ldots, L$, and assign each $e_i$ to a region $V_i$. That is to say, for any $x \in \mathbb{R}^U$,  if $x \in V_i$, then on $x$, the X-form is $e_i$. We can denote this X-form associated with $x$ as $e_x$ as well, so $e_x = e_i$.  
We have data sequence $D = \{ (b_j, o_j) \ | j = 1, 2, \ldots, J\}$.  We also have one dynamics on $\mathbb{R}^U$ driven by this data sequence. We assume this dynamics is discrete. 

\[
x_k = LM(x_0, b_1, o_1, b_2, o_2, \ldots, b_k, o_k ), k = 1, 2, \ldots  \label{eq:embk} \tag{emb}  
\]
where $x_0$ is the initial point, and $x_k$ is the point at $k$-th step, $LM$ is the mechanism of dynamics. This equation is very similar to previous equation \eqref{eq:lmk}. For each $x_k$, we have the associated X-form $e_k$, $e_k \in \{e_1, e_2, \ldots e_L\}$. Thus, we see the learning is going on. 

Of course, we want learning to reach desired result. But, with what conditions and requirements, the above dynamics will reach the desired result? We have following theorem. We define a function $Lo$ on $\mathbb{R}^U$ as below:
\[
Lo(x) = \sum_{j=1}^J ( e_x(b_j) - o_j )^2,  \ \ \forall x \in \mathbb{R}^U  
\]
where $e_x$ is the X-form associated with point $x$.


\begin{theorem}
Suppose we have a desired X-form $e^*$ among those X-form we chosen $\{e_1, e_2, \ldots e_L\}$ , and we have a data sequence $D$ that is sufficient to support $e^*$ and sufficient to bound $e^*$, and the dynamics in equation \eqref{eq:embk} will reach the minimization target, i.e. as $k$ increases, $Lo(x_k)$ has trend to decrease, and at some $k$, $Lo(x_k)$ reach the minimum. Then, at the time $Lo(x_k)$ reaches minimum, we get the desired X-form, i.e. $e_x = e^*$.        
\end{theorem}
{\bf Proof:} The proof is quite clear. Since $D$ is sufficient to support $e^*$ and sufficient to bound $e^*$, for any point $x \in \mathbb{R}^U$, assume the associated X-form for $x$ is $e_k$, if $e_k$ is not $e^*$, then must have some $j$ so that  $e_k(b_j) \not= o_j$, so $Lo(x) > 0$. And, for $e^*$, for all $j$ $e^*(b_j) = o_j$. So $Lo(x)$ reaches minimum when the X-form associated with $x$ is actually $e^*$. 

So, by this strategy, we indeed find a way to learn: To design a dynamics on $\mathbb{R}^U$, which will reach the minimum of function $Lo$. For this strategy, we need strong data sequence that is both sufficient to support and to bound the desired X-form. 

Of course, there are some very critical issues to consider: 1) How to choose those X-forms $\{e_1, e_2, \ldots e_L\}$? 2) How to cut $\mathbb{R}^U$ into regions? 3) How to design a good dynamics $LM$? All these are big issues and not easy to deal. However, there should have many ways to choose, to cut, to design. 

One very important example for this strategy is deep learning. We can see in Appendix that deep learning is under this strategy. It is good to know that this strategy is a working and is currently produce many good results. 
\bigskip



{\bf Strategy 2 -- Squeeze X-form from Inside to Higher Abstraction}\\
Strategy 1 is to choose a good X-form from a previously given set of X-forms. Now, we will see another strategy, which builds the desired X-form from bottom up. We summarize this strategy as: 
\begin{enumerate} [topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
\item Check input, to see if need to include the input. If so, add it. 
\item Squeeze current X-form to higher abstraction and more generalization, but not go over.
\item Choose best X-form from its internal representation space. 
\end{enumerate}
Learning will make sure X-form monotonously increase (in the term of its black set). This strategy require data to be sufficient to support the desired X-form. Note, no requirement on sufficient to bound. This is a huge difference. Also, this strategy needs machine has certain capability. We are not designing machine here. Here we just assume such capabilities, then to see what it can do. 


\begin{definition}[\bf Strategy 2 - Capability 1]
Capable to squeeze current X-form $e$ to another X-form $e'$ with higher abstraction and more generalization. More precisely, the squeezing action will do following: Assume X-form $e = E(g)$, where $E$ is one algebraic expression (of 3 operators), and $g = \{b_1, \ldots, b_K\}$ is a set of base patterns, then X-form $e' = E'(g')$ should satisfy that $g' \subset g$, and $B \subset B'$, where $B$ is the black set of $e$, $B'$ is the black set of $e'$. If could find such a X-form $e'$, $e'$ is put it into internal representation space, otherwise, take no action.  
\end{definition}
There is no restrictions on how to do this squeeze (could be smart, or could be dumb). This capability can be simply said as: learning method will try to find a better organized X-form to replace current X-form, with the condition: its black set should be larger, not smaller. More generalization follows getting higher abstraction and bigger black set.



\begin{definition}[\bf Strategy 2 - Capability 2]
Capable to check a X-form $e$ to tell if $e$ is over the desired X-form or not, i.e. to tell if the black set of $e$ is a subset of the black set of the desired X-form.  
\end{definition}


Now, with the strategy summarized above, and with the capabilities and required data, we see what learning machine can learn. 


\begin{theorem}
Suppose a learning machine $\mathcal{M}$ is using strategy 2 to learn, and it has Strategy 2 - Capability 1 and Capability 2, for a given black set $B_o$, if $e_o$ is a X-form that expresses $B_o$, and there is a data sequence $D = \{ (b_j, o_j) \ | j = 1, 2, \ldots \}$ that is inside $B_o$ and sufficient to support X-form $e_o$, then, start from empty X-form, if data in $D$ is fed to $\mathcal{M}$ fully and long enough (could be repeating feed, but not miss any data), eventually, $\mathcal{M}$ will learn $B_o$, i.e. the black set of $\mathcal{M}$ will become $B_o$.        
\end{theorem}
{\bf Proof:} We first describe the learning action as each data feed in. Suppose current X-form is $e$, and data feed in is $(b, o)$. Since data are all inside $B_o$, $o = 1$. Then learning method will check $e(b)$, if $e(b) = 1$, no need to do more, move to next data; if $e(b) = 0$, then this $b$ needs to be included, so replace $e$ with $e + b$. Then, capability 1 is used to get a X-form $e'$ with higher abstraction. Then, capability 2 is used to check if $e'$ is beyond the desired X-form. If $e'$ is OK, this X-form is put into internal representation space, and $e'$ replaces current X-form $e$. This is one step how learning is conducted.

Starting from $e = \varnothing$. The first data is $(b_1, 1)$. $b_1$ is a base pattern. This case, sure $e' = b_1$, and put in internal representation space. Since it is just beginning, this step is done. So, X-form becomes $e_1 = e' = b_1$. Note, at this time, the black set of current X-form is $B_1 = \{b_1\}$, so $B_1 \subset B_o$. 

This process continues. Now, consider step $k$. This time, current X-form is $e_{k-1}$. Input is $(b_k, 1)$. It will decide if $e' = e_{k-1}$ or $e' = e_{k-1} + b_k$. The logic here is: if $e_{k-1}(b_k) = 0$ , it means that $e_{k-1}$ is not good enough, it should be expand, so $e' = e_{k-1} + b_k$; if $e_{k-1}(b_k) = 1$, no need to expand, so, $e' = e_{k-1}$. 

Then, capability 1 is exercised. $e'$ is squeezed into higher abstraction, and the generalization is done at the same time. The result is a new X-form $e''$. Note, the capability 1 will make the black set of $e''$ getting bigger, at least not smaller. Moreover, capability 2 is exercised to check if $e''$ is out bound. If not, then set $e_k = e''$, i.e. update the X-form, and put $e''$ into internal representation space. 

This is the learning. We want to show, as $k$ increases, eventually, the black set of $e_k$ will become $B_o$. Since we know that the black set of $e_k$ is always a subset of $B_o$, so we only need to show that as $k$ increases, the black set of $e_k$ will not stay as a true subset of $B_o$ and not expand. But, this is clear. If at some $k$, the black set of $e_k$ is a true subset of $B_o$, so $e_k$ is sub-form of the X-form. Since data $D$ is sufficient to support the X-form, there must be a $k' > k$, at $k'$ data is $(b_{k'}, 1)$ and $e_{k'}(b_{k'}) = 0$. So, according to the learning process, $e_{k'}$ will be expanded. Proof is done.
\bigskip

We add another capability: Capability to forget current expression. That is to say, there are some special data, driving by them, learning machine could forget current X-form and make its X-form become empty. We name this capability as Capability Going Empty.


\begin{corollary}
A learning machine with Strategy 2 - Capability 1 and Capability 2 and Capability Going Empty is an universal learning machine.
\end{corollary}
{\bf Proof:} For any given black set $B_o$, we can find one X-form $e$ so that $B_o$ is black set of $e$. The data set $S \subset B_o$ so that it is sufficient to support $e$, according to above theorem, can be used to drive learning machine learn $e$ from any empty. Such data $S$ sufficient to support $e$ indeed exists. So, this machine is universal.
\bigskip




{\bf Strategy 3 -- Squeeze X-form from Inside and Outside to Higher Abstraction}\\
This strategy is quite similar to Strategy 2. They can be thought as one. Only for the purpose to show how data and learning method should work together, we write them differently here. The differences are 1) In Strategy 3, data are both sufficient to support and sufficient to bound, but in Strategy 2, only sufficient to support. 2) In Strategy 2, we have  Capability 2, but in Strategy 3, no such capability. That is to say, Strategy 3 uses much stronger data, but need much less capability. 

\begin{definition}[\bf Strategy 3 - Capability 1]
Same as Strategy 3 - Capability 1.
\end{definition}



\begin{theorem}
Suppose a learning machine $\mathcal{M}$ is using strategy 3 to learn, and it has Strategy 3 - Capability 1, for a given black set $B_o$, if $e_o$ is a X-form that expresses $B_o$, and there is a data sequence $D = \{ (b_j, o_j) \ | j = 1, 2, \ldots \}$ that is sufficient to support and sufficient to bound X-form $e_o$, then, start from empty expression, if data in $D$ is fed to $\mathcal{M}$ fully and long enough (could be repeating feed, but not miss any data), eventually, $\mathcal{M}$ will learn $B_o$, i.e. the black set of $\mathcal{M}$ will become $B_o$.        
\end{theorem}
{\bf Proof:} Since this is quite similar as strategy 2, we only say the part different. The data are different. So, in this strategy, $b_k$ could be inside $B_o$ or outside $B_o$. When data $(b_k, o_k)$ feed in, possibly  1) $e_k(b_k) = 1, o_k = 1$, 2)  $e(b_k) = 0, o_k = 1$, 3) $e_k(b_k) = 0, o_k = 0$, 4)  $e(b_k) = 1, o_k = 0$. For case 1) and 3), no need to do anything, move to next data. For case 2), it means $b_k$ needs to be included, so expand to $e_k + b_k$. For case 4), it means $b_k$ should be excluded, so prohibit $b_k$, the way to do so: $\neg (e_k \cdot b_k) + (e_k  \cdot \neg b_k)$. Other than this part, the learning is same as in last theorem. 

Then, capability 1 is exercised. And, no capability 2. The proof is also similar. 


\begin{corollary}
A learning machine with Strategy 3 - Capability 1 and Capability 2 and Capability Going Empty is an universal learning machine.
\end{corollary}





We briefly comment these 3 strategies below.
\begin{enumerate} [topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
\item They put different requirements on data and on machine. Strategy 2 only require data sufficient to support. This is much less than both sufficient to support and to bound. But, strategy 2 requires machine to have a very strong capability. Strategy 3 and 1 put same requirements on data. However, strategy 1 put a super strong requirement on setup. The desired X-form must be set into the regions.  
\item We just say, the above 3 strategies are not all learning strategies. There are many other learning strategies and methods.
\item Human perhaps never learn anything from very scratch. Previous learning results are used to help new learning. All learning strategies should utilize this approach. This is a huge topic. We will discuss this issue later.
\end{enumerate}



There are 2 approaches to study learning machine: one is to well describe learning machine, another is to design one particular learning machine. Both approaches should support each other. In this work, we are doing the first approach. We will do the second approach in other place. But, since we get some good insights from work here, which serves as good guidance for us to design effective and efficient learning machine, we briefly discuss some issues of designing learning machine. 


{\bf 1. It should have very effective and efficient internal representation space} \\
Without a good and easy to review internal represnetation space, a learning machine is hard to work well. How to make good internal representation space is not a simple issue. However, one thing is clear. It is not good to embed the internal representation space in some real parameter space $\mathbb{ R}^U$, where $U$ is a huge integer, like many millions. In that way, we will lose the ability to navigate and understand immediately. Armed with knowledge we discussed, we know that collection of X-forms is the internal representation space. It is naturally for us to find some mechanism to realize X-form in design. We also should realize that X-form is a connectionist model by its nature.

{\bf 2. It should be self-aware about new base patterns} \\
The self-awareness about new base patterns is one important property. If possible, we should make this property ready for a learning system. This needs big efforts to realize. 

{\bf 3. It is level 1 learning machine, but with ability to become higher level} \\
Learning method to be level 1 has advantage. It is simpler and eaiser to examine the learning. Since learning methods are not changing with the learning, if there is some trouble, it will be much easier to roll back. If it is not level 1, roll back would be much harder, or just impossible. However, it should be ready to move to level 2, or even higher learning level, if necessary. It should fully utilize evolution and inheritance methods if needed.

{\bf 4. It should have best possible prior knowledges} \\
In principle we want universal learning machine. But, in practice, one learning machine is for some special tasks. Often, we have prior knowledges about those tasks. To build these prior knowledges into learning machine could significantly improve learning. Prior knowledges could be build into learning methods and initial state of internal representation space. 


{\bf 5. Allow more learning strategies and methods be available} \\
Learning methods should have abilities to conduct multiple reasoning (like deterministic, probabilitstic, etc). It should have more than one strategy and method. It can switch the strategies and methods by reasoning on feed-in data. Since we demonstrated in section 4 and 5 that with certain capabilities, a learning machine become universal, it is reasonable to make learning machine to have the capabilities of learning by teaching and learning without teaching. Very likely, they might be the minimal capabilities of an effective learning machine. 


Guided by above principles, we have designed one type of learning machine: OSIPL machine. We will discuss details of OSIPL machine in other place.  


\noindent\textbf{Proof of \ref{prop::mm1}.\;} From \cref{assumption::mm} and line~\ref{line::xlG} of \cref{algorithm::mm}, we obtain
\begin{equation}\label{eq::Gacmp}
G^\alpha(\Xakp|\Xk) \leq G^\alpha(\Xakh|\Xk)
\end{equation}
and
\begin{equation}\label{eq::Hacmp}
H^\alpha(\Xakh|\Xk) \leq H^\alpha(\Xak|\Xk).
\end{equation}
From \cref{eq::lG2,eq::G2,eq::Gacmp,eq::Hacmp}, it can be concluded that
\begin{equation}\label{eq::Gcmp}
G(\Xkp|\Xk) \leq G(X^{(\sk+\shalf)}|\Xk)
\end{equation}
and
\begin{equation}\label{eq::Hcmp}
H(\Xkh|\Xk)\leq H(\Xk|\Xk).
\end{equation}
Note that \cref{eq::lGF} suggests
\begin{equation}\label{eq::lGGF1}
F(X^{(\sk+1)}) \leq G(X^{(\sk+1)}|X^{(\sk)})
\end{equation}
and
\begin{equation}\label{eq::lGGF2}
G(X^{(\sk+\shalf)}|X^{(\sk)}) \leq H(X^{(\sk+\shalf)}|X^{(\sk)}).
\end{equation}
Then, \cref{eq::Gcmp,eq::Hcmp,eq::lGGF1,eq::lGGF2} result in
\begin{multline}\label{eq::order}
F(X^{(\sk+1)}) \leq G(X^{(\sk+1)}|X^{(\sk)}) \leq\\
G(X^{(\sk+\shalf)}|X^{(\sk)}) \leq H(X^{(\sk+\shalf)}|X^{(\sk)})\leq \\
H(X^{(\sk)}|X^{(\sk)}) =  F(X^{(\sk)}),
\end{multline}
which indicates that $F(X^{(\sk)})$ is nonincreasing. The proof is completed.

\vspace{0.8em}
\noindent\textbf{Proof of \ref{prop::mm2}.\;} From \cref{prop::mm}\ref{prop::mm1}, it has been proved that $F(X^{(\sk)})$ is nonincreasing. From \cref{eq::obj} and \cref{assumption::loss}, $F(X^{(\sk)})\geq 0$, i.e., $F(X^{(\sk)})$ is bounded below. As a result, there exists $F^{\infty} \in \R $ such that $F(X^{(\sk)})\rightarrow F^{\infty}$. The proof is completed.

\vspace{0.8em}
\noindent\textbf{Proof of \ref{prop::mm3}.\;}
We introduce the following lemmas about $G(X|\Xk)$ and $H(X|\Xk)$ that are used in the proof.
 
 \begin{lemma}\label{lemma::G}
Let  $\nGammak \in \R^{(d+1)n\times (d+1)n}$ be a block diagonal matrix in the form of
 \begin{equation}\label{eq::nG}
 	\nGammak\triangleq\mathrm{diag}\big\{\nGamma^{1(\sk)},\,\cdots,\,\nGamma^{|\AA|(\sk)}\big\}\in \R^{(d+1)n\times (d+1)n}
 \end{equation}
where $\nGammaak$ is given in \cref{eq::GMa}. Then, we have the following results:
\begin{enumerate}[(a)]
\item\label{lemma::Ga} $G(\cdot|\Xk): \R^{d\times(d+1)n}\rightarrow\R$ in \cref{eq::G} is equivalent to
\begin{multline}\label{eq::GM}
	G(X|X^{(\sk)})
	=\frac{1}{2}\|X-X^{(\sk)}\|_{\nGammak}^2+\\
	\innprod{\nabla F(X^{(\sk)})}{{X-X^{(\sk)}}}+ F(X^{(\sk)}),
\end{multline}
where  $\nabla F(X^{(\sk)})\in \R^{d\times(d+1)n}$ is the Euclidean gradient of $F(X)$ at $X^{(\sk)}\in\XX$.
\item\label{lemma::Gb} $\nGammak\succeq\nMk$ where $\nMk$ is given in \cref{eq::M}. 
\item\label{lemma::Gc}$\nGammak$ is bounded, i.e.,  there exists a constant positive-semidefinite matrix $\nGamma\in \R^{(d+1)n\times (d+1)n}$ such that $\nGamma\succeq \nGammak$ holds for any $\sk\geq 0$. 
\end{enumerate}
 \end{lemma}

\begin{proof} The proofs of Lemmas \ref{lemma::G}\ref{lemma::Ga} to \ref{lemma::G}\ref{lemma::Gc} are as the following.

\ref{lemma::Ga} If we substitute \cref{eq::GMa} into \cref{eq::G2}, the result is
\begin{multline}\label{eq::EXk}
	G(X|\Xk)=\sum_{\alpha\in\AA}\Big[\frac{1}{2}\|\Xa-\Xak\|_{\nGamma^{\ak}}^2+\\
	\big\langle\nabla_{\Xa} F(X^{(\sk)}),\,{\Xa-\Xak}\big\rangle\Big] + F(\Xk).
\end{multline}
Also, it is straightforward to show that
\begin{equation}
	\nonumber
	\frac{1}{2}\|X-\Xk\|_{\nGammak}^2=\sum_{\alpha\in\AA}\frac{1}{2}\|\Xa-\Xak\|_{\nGamma^{\ak}}^2,
\end{equation}
where $\nGammak\in\R^{(d+1)n\times(d+1)n}$ is defined as \cref{eq::nG}, and  
\begin{multline}
	\nonumber
	\innprod{\nabla F(\Xk)}{X-\Xk}=\\
	\sum_{\alpha\in\AA}\innprod{\nabla_{\Xa} F(\Xk)}{X^\alpha-\Xak}.
\end{multline}
Thus, \cref{eq::EXk} is equivalent to \cref{eq::GM}, i.e.,
\begin{multline}\label{eq::E3}
	G(X|\Xk) = \frac{1}{2}\|X-\Xk\|_{\nGammak}^2+\\
	\innprod{\nabla F(X^{(\sk)})}{{X-X^{(\sk)}}}+ F(X^{(\sk)}).
\end{multline}
The proof is completed
\vspace{0.2em}

\ref{lemma::Gb} From \cref{eq::G,eq::FaaFab,eq::Eab,eq::E3}, we rewrite $\nGammak\in\R^{(d+1)n\times(d+1)n}$ as
\begin{multline}\label{eq::H}
	\nGammak=\sum_{\alpha\in\AA}\sum_{(i,j)\in \aEE^{\alpha\alpha}}\nM_{ij}^{\aa}+\\
	\sum_{\substack{\alpha,\beta\in\AA,\\\alpha\neq \beta}}\sum_{(i,j)\in \aEE^{\alpha\beta}}\wabijk\cdot \nH_{ij}^{\ab}+\xi\cdot\I,
\end{multline}
in which $\nH_{ij}^{\ab}\succeq\nM_{ij}^{\ab}$ by \cref{eq::MH} and $\xi\geq 0$. Then, as a result of \cref{eq::M,eq::H,eq::MH}, it is straightforward to conclude that
\begin{equation}\label{eq::GMk}
	\nGammak\succeq\nMk+\xi \cdot\I\succeq \nMk.
\end{equation} 
The proof is completed.
\vspace{0.2em}

\ref{lemma::Gc} Let $\nGamma\in\R^{(d+1)n\times(d+1)n}$ be defined as
\begin{equation}\label{eq::HH}
	\nGamma\triangleq\sum_{\alpha\in\AA}\sum_{(i,j)\in \aEE^{\alpha\alpha}}\nM_{ij}^{\aa}+
	\sum_{\substack{\alpha,\beta\in\AA,\\\alpha\neq \beta}}\sum_{(i,j)\in \aEE^{\alpha\beta}} \nH_{ij}^{\ab}+\xi\cdot\I.
\end{equation}
From \cref{assumption::loss}\ref{assumption::loss_drho} and \cref{eq::wabij}, it can be concluded that
\begin{equation}\label{eq::wabijkbnd}
	0\leq \wabijk \leq 1
\end{equation} 
for any $\Xk\in\R^{d\times(d+1)n}$. Furthermore, it is known that $\nH_{ij}^{\ab} \succeq 0$, then \cref{eq::HH,eq::H,eq::wabijkbnd} result in $\nGamma\succeq\nGammak$ for any $\Xk\in\R^{d\times(d+1)n}$. The proof is completed.
\end{proof}
 
 
 \begin{lemma}\label{lemma::lG}
	Let  $\lnGammak \in \R^{(d+1)n\times (d+1)n}$ be a block diagonal matrix in the form of
	\begin{equation}\label{eq::lnG}
		\lnGammak\triangleq\mathrm{diag}\big\{\lnGamma^{1(\sk)},\,\cdots,\,\lnGamma^{|\AA|(\sk)}\big\}\in \R^{(d+1)n\times (d+1)n}
	\end{equation}
	where $\lnGammaak$ is given in \cref{eq::lGMa}. Then, we have the following results:
	\begin{enumerate}[(a)]
		\item\label{lemma::lGa} $\lG(\cdot|\Xk): \R^{d\times(d+1)n}\rightarrow\R$ in \cref{eq::lG}  is equivalent to
		\begin{multline}\label{eq::lGM}
			\lG(X|X^{(\sk)})
			=\frac{1}{2}\|X-X^{(\sk)}\|_{\lnGammak}^2+\\
			\innprod{\nabla F(X^{(\sk)})}{{X-X^{(\sk)}}}+ F(X^{(\sk)}),
		\end{multline}
		where  $\nabla F(X^{(\sk)})\in \R^{d\times(d+1)n}$ is the Euclidean gradient of $F(X)$ at $X^{(\sk)}\in\XX$.
		\item\label{lemma::lGb} $\lnGammak\succeq\nGammak\succeq\nMk$ where $\nMk$ and $\nGammak$ are given in \cref{eq::M} and \cref{eq::nG}, respectively. 
		\item\label{lemma::lGc}$\lnGammak$ is bounded, i.e.,  there exists a constant positive-semidefinite matrix $\lnGamma\in \R^{(d+1)n\times (d+1)n}$ such that $\lnGamma\succeq \lnGammak$ holds for any $\sk\geq 0$.
		\item\label{lemma::lGd} $\lG^\alpha(\Xa|\Xk)\geq G^\alpha(\Xa|\Xk)$ for any $\Xa\in\R^{d\times (d+1)n_\alpha}$ where $G^\alpha(\Xa|\Xk)$ is given in \cref{eq::GMa} and the equality holds if  $\Xa=\Xak$.
	\end{enumerate}
\end{lemma}
 \begin{proof}
 The proofs of Lemmas \ref{lemma::lG}\ref{lemma::lGa} to \ref{lemma::lG}\ref{lemma::lGc}  are similar to those of \cref{lemma::G} and the proof of  \cref{lemma::lG}\ref{lemma::lGd} is  immediate from \cref{eq::GMa,eq::lGMa} and \cref{lemma::lG}\ref{lemma::lGb}.
 \end{proof}
 
From \cref{eq::order}, it is known that $F(\Xk)\geq G(\Xkp|\Xk)$, which suggests
\begin{equation}\label{eq::bound}
F(\Xk)- F(\Xkp) \geq
G(\Xkp|\Xk) - F(\Xkp).
\end{equation}
From \cref{eq::proxF,eq::GM}, we obtain
\begin{multline}\label{eq::Fxkp}
F(\Xkp) \leq \frac{1}{2}\|\Xkp-\Xk\|_{\nMk}^2+\\
\innprod{\nabla F(\Xk)}{X-\Xk}+F(\Xk)
\end{multline}
and
\begin{multline}\label{eq::Gxkp}
G(\Xkp|\Xk)=\frac{1}{2}\|\Xkp-\Xk\|_{\nGammak}^2+\\
\innprod{\nabla F(\Xk)}{X-\Xk}+F(\Xk),
\end{multline}
respectively. Substituting \cref{eq::Fxkp,eq::Gxkp} into the right-hand side of \cref{eq::bound}, we obtain
\begin{multline}\label{eq::GF2}
F(X^{(\sk)}) - F(X^{(\sk+1)}) \geq\\
\frac{1}{2}\|\Xkp-\Xk\|_{\nGammak}^2-\frac{1}{2}\|\Xkp-\Xk\|_{\nMk}^2.
\end{multline}
From \cref{eq::GF2,eq::GMk}, there exists a constant scalar $\delta>0$ such that
\begin{equation}\label{eq::dF}
F(X^{(\sk)}) - F(X^{(\sk+1)}) \geq
\frac{\delta}{2}\|X^{(\sk+1)}-X^{(\sk)}\|^2
\end{equation}
as long as $\xi>0$. From \cref{prop::mm}\ref{prop::mm2}, we obtain
\begin{equation}\label{eq::dF0}
F(X^{(\sk)}) - F(X^{(\sk+1)})\rightarrow 0,
\end{equation}
and thus, it can be concluded from \cref{eq::dF,eq::dF0} that
\begin{equation}
\|X^{(\sk+1)}-X^{(\sk)}\| \rightarrow 0.
\end{equation}
The proof is completed.

\vspace{0.8em}
\noindent\textbf{Proof of \ref{prop::mm4}.\;} From \cref{eq::order}, it is known that $F(\Xk)\geq H(\Xkh|\Xk)$ and $G(\Xkh|\Xk)\geq G(\Xkp|\Xk) \geq F(\Xkp)$, which suggests
\begin{multline}
\nonumber
F(\Xk)-F(\Xkp) \geq\\ 
H(\Xkh|\Xk) - G(\Xkh|\Xk).
\end{multline}
From \cref{eq::GM,eq::lGM}, the equation above is equivalent to
\begin{multline}\label{eq::FkFkp}
F(\Xk)-F(\Xkp) \geq \\
\frac{1}{2}\|\Xkh-\Xk\|_{\lnGammak}^2 - \frac{1}{2}\|\Xkh-\Xk\|_{\nGammak}^2.
\end{multline}
A similar procedure to the derivation of \cref{eq::GMk} results in
\begin{equation}\label{eq::lGGk}
\lnGammak \succeq \nGammak + (\zeta-\xi)\cdot\I,
\end{equation}
which suggests there exists a constant scalar $\delta' > 0$ such that
\begin{equation}
\nonumber
\lnGammak \succeq \nGammak + \delta'\cdot\I
\end{equation}
if $\zeta>\xi > 0$. Then, similar to the proof of \cref{prop::mm}\ref{prop::mm3}, we obtain
\begin{equation}\label{eq::DFh}
F(\Xk)-F(\Xkp) \geq \frac{\delta'}{2}\|\Xkh-\Xk\|^2.
\end{equation}
Thus, it can be concluded that
\begin{equation}
	\|\Xkh-\Xk\| \rightarrow 0.
\end{equation}
The proof is completed.

\vspace{0.8em}
\noindent\textbf{Proof of \ref{prop::mm5}.\;} The following lemma about $\nabla F(X)$ is needed in this proof.

\begin{lemma}\label{prop::DF}
If \cref{assumption::loss}\ref{assumption::loss_L} holds, then the Euclidean gradient $\nabla F(\cdot):\R^{d\times(d+1)n}\rightarrow \R^{d\times(d+1)n}$ of $F(X)$ in \cref{eq::F} is Lipschitz continuous, i.e., there exists a constant $\mu > 0$ such that $\|\nabla F(X)-\nabla F(X')\|\leq \mu\cdot\|X-X'\|$.
\end{lemma}

\begin{proof}
From \cref{assumption::loss}\ref{assumption::loss_L}, it is known that $\rho(\|X\|^2)$ has Lipschitz continuous gradient, which suggests that $F_{ij}^{\ab}(X)=\dfrac{1}{2}\rho(\|X\|_{\nM_{ij}^{\ab}}^2)$ in \cref{eq::Fab} has Lipschitz continuous gradient. Note that $F_{ij}^{\aa}(X)=\dfrac{1}{2}\|X\|_{\nM_{ij}^{\aa}}^2$ in \cref{eq::Faa} has Lipschitz continuous gradient as well. Then, from \cref{eq::F}, it can be concluded that $F(X)$ has Lipschitz continuous gradient. The proof is completed.
\end{proof}

It is straightforward to show that the Riemannian gradient $\grad\, F(X)$ takes the form as
\begin{equation}
	\nonumber
	\grad\, F(X) =\begin{bmatrix}
		\grad_{1} F(X) & \cdots  & \grad_{|\AA|} F(X)
	\end{bmatrix}\in T_X \XX.
\end{equation}
In the equation above, $\grad_{\alpha} F(X)$ is the Riemannian gradient of $F(X)$ with respect to $\Xa\in\XX^{\alpha}$ for node $\alpha\in\AA$, and can be written as
\begin{equation}\label{eq::grad}
	\grad_\alpha F(X)=
	\begin{bmatrix}
		\grad_{t^\alpha} F(X) & \grad_{R^\alpha} F(X)
	\end{bmatrix}\in
	T_{X^\alpha}\XX^\alpha
\end{equation}
in which recall that $$T_{X^\alpha}\XX^\alpha\triangleq\R^{d\times n_\alpha}\times T_{R^\alpha} SO(d)^{n_\alpha}.$$
From \cite{absil2009optimization,rosen2016se}, it can be shown that $\grad_{t^\alpha} F(X)$ and $\grad_{R^\alpha} F(X)$ in \cref{eq::grad} are
\begin{equation}\label{eq::grad_t}
	\grad_{t^\alpha} F(X) = \nabla_{t^\alpha} F(X)
\end{equation}
and
\begin{multline}\label{eq::grad_R}
	\grad_{R^\alpha} F(X) = \nabla_{R^\alpha} F(X)-\\
	R^\alpha\, \mathrm{SymBlockDiag}_d^\alpha({R^{\alpha}}^\transpose\nabla_{R^\alpha} F(X)).
\end{multline}
In \cref{eq::grad_R}, $\mathrm{SymBlockDiag}_d^\alpha: \R^{dn_\alpha\times dn_\alpha}\rightarrow \R^{dn_\alpha\times dn_\alpha}$ is a linear operator
\begin{equation}\label{eq::sym}
	\mathrm{SymBlockDiag}_d^\alpha(Z)\triangleq\frac{1}{2}\mathrm{BlockDiag}_d^\alpha(Z+Z^\transpose),
\end{equation} 
in which $\mathrm{BlockDiag}_d^\alpha: \R^{dn_\alpha \times dn_\alpha}\rightarrow \R^{dn_\alpha \times dn_\alpha}$ extracts the $d\times d$-block diagonals of a matrix, i.e.,
\begin{equation}
	\nonumber
	\mathrm{BlockDiag}_d^\alpha(Z)\triangleq\begin{bmatrix}
		Z_{11} & & \\
		&\ddots &\\
		& & Z_{n_\alpha n_\alpha}
	\end{bmatrix}\in \R^{dn_\alpha \times dn_\alpha}.
\end{equation}
As a result of \cref{eq::grad_t,eq::grad_R,eq::sym,eq::grad}, there exists a linear operator
\begin{equation}\label{eq::QQx}
	\QQ_X:\R^{d\times d(n+1)}\rightarrow \R^{d\times d(n+1)}
\end{equation} 
that continuously depends on $X\in \XX$ such that
\begin{equation}\label{eq::gradF}
	\grad\, F(X)=\QQ_X(\nabla F(X)).
\end{equation}
From \cref{eq::lGM}, it is straightforward to show that
\begin{equation}\label{eq::gradG}
	\begin{aligned}
	&\nabla H(\Xkh|\Xk)\\
	=&\nabla F(\Xk)+(\Xkh-\Xk)\lnGammak\\
	=&\nabla F(\Xkh)+(\Xkh-\Xk)\lnGammak\, +\\
	 &\big(\nabla F(\Xk) -\nabla F(\Xkh)\big).
	\end{aligned}
\end{equation}
Note that \cref{eq::gradF} applies to any functions on $\XX$. As a result of \cref{eq::gradF,eq::gradG}, we obtain 
\begin{equation}\label{eq::gradGX}
\begin{aligned}
&\grad\,H(\Xkh|\Xk)\\
=\,&\grad\, F(\Xkh) +\\
& \QQ_{\Xkh}\big((\Xkh-\Xk)\lnGammak\big)+\\
 &\QQ_{\Xkh}\big(\nabla F(\Xk)-\nabla F(\Xkh)\big).
\end{aligned}
\end{equation}
From line~\ref{line::xlG} of \cref{algorithm::mm}, we obtain. 
$$\grad\, H^\alpha(\Xakh|\Xk)=\0.$$
In addition, it is by definition that
\begin{multline}
	\nonumber
	\grad\, H(X|X^{(\sk)})=\\
	\begin{bmatrix}
		\grad\, H^1(X^1|\Xk) & \cdots & \grad\, H^{|\AA|}(X^{|\AA|}|\Xk),
	\end{bmatrix}
\end{multline}
which suggests
\begin{equation}\label{eq::gradG0}
	\grad\,H(\Xkh|\Xk)=\0.
\end{equation}
From \cref{eq::gradG0,eq::gradGX}, we obtain
\begin{multline}
	\nonumber
	\grad\, F(\Xkh)=\QQ_{\Xkh}\big((\Xk-\Xkh)\lnGammak\big)+\\
	\QQ_{\Xkh}\big(\nabla F(\Xkh)-\nabla F(\Xk)\big).
\end{multline}
From the equation above, it can be shown that
\begin{equation}\label{eq::gradFxk_n}
	\begin{aligned}
		&\|\grad\, F(\Xkh)\|\\
		=&\big\|\QQ_{\Xkh}\big((\Xk-\Xkh)\lnGammak\big)+\\
		&\hphantom{\big\|}\QQ_{\Xkh}\big(\nabla F(\Xkh)-\nabla F(\Xk)\big)\big\| \\
		\leq&\big\|\QQ_{\Xkh}\big((\Xk-\Xkh)\lnGammak\big)\big\|+\\
		&\big\|\QQ_{\Xkh}\big(\nabla F(\Xkh)-\nabla F(\Xk)\big)\big\| \\
		\leq& \|\QQ_{\Xkh}\|_2\cdot \|\lnGammak\|_2\cdot\|\Xkh-\Xk\|+\\
		&\|\QQ_{\Xkh}\|_2\cdot\|\nabla F(\Xkh)-\nabla F(\Xk)\|,
	\end{aligned}
\end{equation}
in which $\|\cdot\|_2$ denotes the induced $2$-norm of linear operators. From Lemmas \ref{lemma::lG}\ref{lemma::lGc} and \ref{prop::DF}, there exists a constant positive-semidefinite matrix $\lnGamma\in \R^{(d+1)n\times(d+1)n}$ and constant positive scalar $\mu > 0$ such that $\lnGamma \succeq \lnGammak \succeq 0$ and $\|\nabla F(\Xkh)-\nabla F(\Xk)\|\leq \mu\cdot\|\Xkh-\Xk\|$ for any $\sk\geq 0$, making it possible to upper-bound the right-hand side of \cref{eq::gradFxk_n}: 
\begin{equation}\label{eq::gradFk}
\begin{aligned}
	&\|\grad\, F(\Xkh)\|\\
\leq&\|\QQ_{\Xkh}\|_2\cdot \|\lnGamma\|_2\cdot\|\Xkh-\Xk\|+\\
	&\|\QQ_{\Xkh}\|_2\cdot\mu\cdot\|\Xkh-\Xk\|.
\end{aligned}
\end{equation}
Moreover, \cref{eq::grad_R,eq::grad_t,eq::grad} indicate that  $\QQ_X(\cdot)$ only depends on the rotation $R^\alpha\in SO(d)^{n_\alpha}$ for $\alpha\in\AA$. Since $\QQ_{X}(\cdot)$ is continuous and $SO(d)^{n_\alpha}$ is a compact manifold, $\|\QQ_{\Xkh}\|_2$ is bounded for any $\Xkh\in\XX$.
Thus, there exists a constant scalar $\nu > 0$ such that the right-hand side of \cref{eq::gradFk} can be upper-bounded as
\begin{equation}\label{eq::gradFh}
\|\grad\, F(\Xkh)\|\leq \nu \|\Xkh-\Xk\|.
\end{equation} 
As long as $\zeta>\xi>0$, \cref{eq::DFh,eq::gradFh} result in
\begin{equation}
\nonumber
\|\grad\, F(\Xkh)\|^2 \leq  \frac{2\nu^2}{\delta'}\big(F(\Xk)-F(\Xkp)\big).
\end{equation}
Then, there exists a constant scalar $\epsilon =\frac{\delta'}{\nu^2}>0$ with which the equation above can be rewritten as
\begin{equation}\label{eq::diff_F}
F(\Xk)-F(\Xkp) \geq \frac{\epsilon}{2}\|\grad\, F(\Xkh)\|^2.
\end{equation}
As a result of \cref{eq::diff_F}, we obtain
\begin{multline}\label{eq::diff_F2}
F(X^{(0)}) - F(X^{(\sK+1)}) \geq \frac{\epsilon}{2} \sum_{\sk=0}^{\sK}\|\grad\, F(\Xkh)\|^2\\
\geq \frac{\epsilon(\sK+1)}{2}\min_{0\leq\sk\leq\sK}\|\grad\, F(\Xkh)\|^2.
\end{multline}
From Propositions \ref{prop::mm}\ref{prop::mm1} and \ref{prop::mm}\ref{prop::mm2}, it can be concluded that  $F(\Xkp) \geq F^\infty$ for any $\sk\geq0$, which and \cref{eq::diff_F2} suggest
\begin{equation}
	\nonumber
	\min\limits_{0\leq\sk< \mathsf{K}}\|\grad\, F(\Xkh)\|\leq \sqrt{\frac{2}{\epsilon}\cdot\dfrac{F(X^{(0)})-F^\infty}{{\sK+1}}}.
\end{equation}
The proof is completed.


\vspace{0.8em}
\noindent\textbf{Proof of \ref{prop::mm6}.\;} As a result of Propositions \ref{prop::mm}\ref{prop::mm3} and \ref{prop::mm}\ref{prop::mm4}, it is known that 
\begin{equation}
\nonumber
\|\Xkp-\Xk\|\rightarrow 0
\end{equation}
and
\begin{equation}
\nonumber
\|\Xkh-\Xk\|\rightarrow 0
\end{equation}
as long as $\zeta>\xi>0$. Thus, it can be concluded from \cref{eq::gradFh} that
$$\grad\,F(\Xkh)\rightarrow \0$$
if $\zeta>\xi>0$. In addition, \cref{assumption::loss}\ref{assumption::loss_cont} indicates that $\grad\,F(\Xk)$ is continuous, which suggests
$$\grad\, F(\Xk)\rightarrow \grad\, F(\Xkh).$$
Then, we obtain
$$\grad\, F(\Xk) \rightarrow \0. $$
The proof is completed.

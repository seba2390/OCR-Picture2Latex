\section{Measuring Light from Darkness}
Digital camera technology has witnessed a remarkable revolution in terms
of size, cost and image quality over the past few years. Throughout this
progress, however, one fundamental characteristic of a camera sensor
has not changed: the way a camera pixel measures brightness.
Conventional image sensor pixels manufactured with complementary metal oxide
semiconductor (CMOS) and charge-coupled device (CCD) technology can be thought
of as light buckets (Fig.~\ref{fig:teaser}(a)), which measure scene brightness
in two steps: first, they collect hundreds or thousands of photons and convert
the energy into an analog electrical signal (e.g.  current or voltage), and
then they digitize this analog quantity using high-resolution analog-to-digital
converters. Conceptually, there are two main drawbacks of this image formation
strategy. First, at extremely low brightness levels, noise in the pixel
electronics dominates resulting in poor signal-to-noise-ratio (SNR). Second,
since each pixel bucket has a fixed maximum capacity, bright regions in the
scene cause the pixels to saturate and subsequent incident photons do not get
recorded.  

In this paper, we explore a different approach for measuring image intensities.
Instead of estimating intensities directly from the number of photons incident
on a pixel, we propose a novel intensity cue based on \emph{inter-photon
timing}, defined as the time delay between detection of successive photons.
Intuitively, as the brightness increases, the \emph{time-of-darkness} between
consecutive photon detections decreases.  By modeling the statistics of photon
arrivals, we derive a theoretical expressions that relates the average
inter-photon delay and the incident flux. The key observation is that because
photon arrivals are stochastic, the average inter-photon time
decreases asymptotically as the incident flux increases.
Using this novel temporal intensity cue, we design algorithms to estimate
brightness from as few as one photon timestamp per pixel to extremely high
brightness, beyond the saturation limit of conventional sensors.

\begin{figure*}[!ht]
\includegraphics[width=0.98\textwidth]{figures/Fig1_teaser.png}
\caption{\textbf{Passive imaging with an inter-photon single-photon
avalanche diode (IP-SPAD):} (a) A conventional image
sensor pixel estimates scene brightness using a well-filling mechanism;
the well has a finite capacity and saturates for very high brightness
levels. (b) An IP-SPAD measures scene brightness from inter-photon timing
measurements that follow Poisson statistics. The higher the brightness, the
smaller the inter-photon time, the faster the decay rate of the inter-photon
histogram. By capturing photon timing information with very high precision,
this estimator can provide scene brightness estimates well
beyond the saturation limit of conventional pixels.  (c) A representative
extreme dynamic range scene of a tunnel with three different flux levels
(low, moderate and high) shown for illustration.  (d) Experimental results
from our hardware prototype comparing a conventional CMOS camera image and an
image obtained from our IP-SPAD prototype.
\label{fig:teaser}
\vspace{-0.15in} }
\end{figure*}
%(a) A SPAD pixel, unlike a conventional
%image sensor, captures individual photons with extremely high timing
%resolution, down to picoseconds.  The timing data can be summarized as a
%histogram of inter-photon time-of-darkness.  
\smallskip
\noindent {\bf How to Measure Inter-Photon Timing?} The inter-photon
timing intensity cue and the resulting brightness estimators can achieve
extremely high dynamic range. A natural question to ask then is: How does one
measure the inter-photon timing? Conventional CMOS sensor pixels do not have
the ability to measure time delays between individual photons at the timing
granularity needed for estimating intensities with high precision. Fortunately,
there is an emerging class of sensors called single-photon avalanche diodes
(SPADs) \cite{cova1996avalanche,bruschini2019single}, that can not only detect
individual photons, but also precisely time-tag each captured photon with
picosecond resolution.

%So far these sensors have been limited to niche applications that require imaging in photon-starved scenarios or those requiring precise synchronization with respect to an active illumination source such as a pulsed laser. In this work we examine the problem of forming 2D intensity images, just like a conventional image sensor.  

%Direct sensing of light intensity using photon counts suffers from limited dynamic range. When imaging in low light, the poor performance is a result of \emph{shot noise}. At the high end, it was recently shown the reduction in performance is due to \emph{quantization} .

\smallskip \noindent {\bf Emergence of Single-Photon Sensors:} SPADs are
naturally suited for imaging in low illumination conditions, and thus, are fast
becoming the sensors of choice for applications that require extreme
sensitivity to photons together with fine-grained temporal information:
\atul{single-photon 3D time-of-flight imaging
\cite{yoshida_2020,lindner2018252,tachella2019real,rapp2020advances,lindell2020three},}
transient imaging \cite{Ulku_2019,turpin2020spatial}, non-line-of-sight imaging
\cite{liu2019non,grau2020deep}, and fluorescence microscopy
\cite{perenzoni2015160}. While these applications use SPADs in active imaging
setups in synchronization with an illumination source such as a pulsed
laser, recently these sensors have been explored as passive, general-purpose
imaging devices for high-speed and high-dynamic range photography
\cite{Antolovic_2018,ingle2019high,ma2020quanta}.  In particular, it was shown
that SPADs can be used to measure incident flux while operating as passive,
free-running pixels (PF-SPAD imaging) \cite{ingle2019high}. The dynamic range
of the resulting measurements, although higher than conventional pixels (that
rely on a finite-depth well filling light detection method like CCD and CMOS
sensors), is inherently limited due to \emph{quantization} stemming from the
discrete nature of photon counts.

\smallskip
\noindent {\bf Intensity from Inter-Photon Timing:} Our key idea is that
it is possible to circumvent the limitations of counts-based photon flux
estimation by exploiting photon timing information from a SPAD. The
additional time-dimension is a rich source of information that is
inaccessible to conventional photon count-based methods. We derive a scene
brightness estimator that relies on the decay time statistics of the
inter-photon times captured by a SPAD sensor as shown in
Fig.~\ref{fig:teaser}(b).  We call our image sensing method
\emph{inter-photon SPAD (IP-SPAD)} imaging. An IP-SPAD pixel captures the
decay time distribution which gets narrower with increasing brightness. As
shown in Fig.~\ref{fig:teaser}(d), the measurements can be summarized in
terms of the mean time-of-darkness, which can then be used to estimate
incident flux. 

Unlike a photon-counting PF-SPAD pixel whose measurements are inherently
discrete, an IP-SPAD measures decay times as floating point values, capturing
information at much finer granularity than integer-valued counts, thus enabling
measurement of extremely high flux values. In practice, the dynamic range of an
IP-SPAD is limited only by the precision of the floating point representation
used for measuring the time-of-darkness between consecutive photons. Coupled
with the sensitivity of SPADs to individual photons and lower noise compared to
conventional sensors, the proposed approach, for the first time, achieves ultra
high-dynamic range. We experimentally demonstrate a dynamic range of over ten
million to one, simultaneously imaging extremely dark (pixels
P\textsubscript{1} and P\textsubscript{2} inside the tunnel in
Fig.~\ref{fig:teaser}(c)) as well as very bright scene regions (pixel
P\textsubscript{3} outside the tunnel in Fig.~\ref{fig:teaser}(c)). 

%Photon counts obtained from a dead-time limited single-photon sensor can also
%provide several orders of magnitude extended dynamic range than conventional
%methods. However, the discrete nature of photon counts leads to reduced SNR in
%the high photon flux regime .


%Any single-photon sensing technique that captures precise timestamps of photon
%detection events suffers from a practical limitation called dead-time, where
%the detector becomes inactive for a short period after each photon
%detection.\footnote{A time-resolved single-photon sensitive detector with no
%dead-time would be a ideal light sensor. In practice, time delays and
%processing overheads in hardware precludes pixel designs with zero dead-time.}
%Here we focus on a specific type of dead-time-limited single-photon detector
%technology called \emph{single-photon avalanche diodes} (SPADs). 

%Fig.~\ref{fig:teaser}(a) shows a representative scene with extreme brightness
%variation. 

%Can photon time-of-arrival data provide any additional information about scene
%brightness over and above the number of photons? What information can the high
%sensitivity and picosecond resolution of SPAD pixels about the scene that a
%conventional camera cannot? 


% It is not
% clear, however, if the \emph{time at which these photons are captured} carries
% any useful information in a passive imaging context. 

% \smallskip
% \noindent\textbf{Relationship to Earlier Work}
% 
% 
% \smallskip
% \noindent\textbf{Limitations:} Our theory and experiments are limited to the
% analysis of single-pixel SPAD detectors. There is an implicit assumption that
% this will hold for individual pixels in an array of SPAD pixels. However, in
% reality, various practical challenges arise when scaling up to large form
% factor SPAD arrays. In particular, we do not analyze any additional sources of
% noise like cross-talk and blooming that may limit the performance of SPAD
% arrays.  Moreover, it is currently not possible to fabricate large form factor
% SPAD arrays that can compete with the specifications of existing CMOS image
% sensors. Our experimental results rely on raster-scanning a single SPAD pixel
% to form an image. However, SPAD technology is rapidly improving; we discuss the
% implications and some future directions in Section XX.
% 
% All image sensors today use photon counts to estimate scene brightness. Here
% we explore the value in using timing information to get additional dynamic
% range improvement. We also show that when imaging in low light conditions
% or imaging with a constraint of just one photon per pixel, timing gives additional
% information that counts do not. An ideal sensor it doesn't matter if you use
% counts or timing - an ideal sensor can count infinitely many photons in a fixed
% exposure time so it is only limited by shot noise. Any real world sensor,
% however, must deal with some missed photons; for example a conventional sensor
% has a full well capacity beyond which it drops additional incident photons and
% a free-running PF-SPAD has a dead-time during which it cannot capture additional
% photons. Here we show that, even though a PF-SPAD misses some photons, we can
% extract additional dynamic range by exploiting the pico-second time resolution
% with which it captures photons.

%Can timing help an ideal sensor?
%Why prefer our method over time to saturation?
%In practice SPADs can give much better time resolution.

%fig 1 - don't show timeline - remove (b)?
%give more space to results
%maybe show spad-counts figure also?
%make zoomed insets bigger?
%focus on avg time of darkness
%
%
%IPT-SPAD? PFT-SPAD?
%
%
%pixel designs:
%naive estimator: all time stamps. - not necessary - after section 3
%or after 
%
%data transmission rates needed?
%computations that you need to do?

%photon counting sensors - intro start more general, then focus on SPADs.  But
%we are more general in the sense that single photon sensors must have a notion
%of dead-time.  fortunately there is a sensor that has these properties - SPADs
%
%single photon sensors have hdr - but they also have very high time resolution.
%here we exploit the timing resolution to increase dynamic range.
%
%light is fundamentally quantized. digital to analog to digital. instead we
%directly measure a continuous thing and relate that to flux. any direct
%measurement of light is quantized.  this leads to poor snr due to shot noise
%in low flux. surprisingly, this also limits snr to high flux regimes too (cvpr
%2019). here we ask - is there a way to measure brightness to without using
%counts? limitation of count based estimators. point to teaser figure.
%
%for this we need a way to measure inter-photon timing. which sensor can do
%that? SPADs.
%
%Limitations: quantization becomes a problem in very low and very high flux.
%



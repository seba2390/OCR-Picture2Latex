\section{IP-SPAD Imaging with Low Photon Counts\label{suppl:timing_usefulness}}
The scene brightness estimator (Eq.~(\ref{eq:flux_estimator})) 
requires the IP-SPAD pixel to capture at least two photons; It
does not make sense to talk about ``inter-photon'' times with only one photon.
The situation where an IP-SPAD pixel captures only one incident photon
timestamp can be thought of as an extreme limiting case of passive inter-photon
imaging under low illumination. 

%We handle the case of $0$ or $1$ photon detections as
%special cases. If $N_T=0$, we define $\widehat{\Phi}=0$ and if $N_T=1$ our flux
%estimator reduces to the reciprocal of the arrival time of the first photon:
Intuitively, we can reconstruct an image from a single photon timestamp per
pixel by simply computing the reciprocal of the first photon timestamp at each
pixel. Brighter scene points should have a smaller first-photon timestamp (on
average) because, with high probability, a photon will be detected almost
immediately after the pixel starts collecting light.  In this supplementary
note we show that the conditional distribution of this first photon timestamp
(conditioned on there being at least one photon detection) is a uniform random
variable:
\[
  \{Y_1 | Y_1 \leq T\} \sim \mathcal{U}[0,T].
\]
when operating under low incident photon flux. This implies that timestamps
provide no additional information beyond merely the fact that at least one
photon was detected. We must, therefore, relax the requirement of a constant
exposure time and allow each pixel to capture at least one photon by allowing
variable exposure times per pixel. When operated this way, first-photon
timestamps do carry useful information about the scene brightness.  The
estimate of the scene pixel brightness is given by $\widehat \Phi =
\nicefrac{1}{q\,Y_i}$.

When the total number of photons is extremely small, the information contained
in the timestamp data is extremely noisy.  We leverage spatial-priors-based
image denoising techniques that have been developed for conventional images,
and adapt them denoising these noisy IP-SPAD images.  Coupled with the inherent
sensitivity of SPADs, this enables us to reconstruct intensity images with just
a single photon per pixel \cite{Johnson_2020}.

In this section we show that for passive imaging in the low photon flux regime
with a constant exposure time per pixel, the timestamp of the first arriving
photon is a uniform random variable and hence, carries no useful information
about the true photon flux. If we drop the constant exposure time constraint
and instead operate in a regime where each pixel is allowed to wait until the
first photon is captured (random exposure time per pixel), then the
first-photon timestamps carry useful information about the flux, albeit noisy.

\subsection{When Do Timestamps Carry Useful Information?}
Let us assume an IP-SPAD pixel operating with a fixed exposure time $T$ is
observing a scene point with photon flux $\Phi$. We assume that the photon
flux is low enough so that the pixel captures at most one
photon during this exposure time. The (random) first-photon arrival time is
denoted by $Y_1$ as shown in Suppl. Fig.~\ref{fig:first_photon_timeline}. We
would like to know if the first photon time-of-arrival carries useful
information about $\Phi$.

\begin{figure}[!ht]
\centering \includegraphics[width=0.45\textwidth]{figures/path823.png}
\caption{We capture the first arriving photon and record
its arrival time in a fixed exposure time T. Note that in the
low photon flux regime $\Phi T \ll 1$, so there is a high
probability that zero photons are detected in the time interval $[0,T]$.
\label{fig:first_photon_timeline}}
\end{figure}

We derive the probability distribution of $Y_1$, conditioning on $Y_1\leq T$.
For any $t>0$,
\begin{align}
     P(Y_1\leq t | Y_1\leq T) &= \frac{P(Y_1\leq t \cap Y_1 \leq T)}{P(Y_1\leq T)} \label{eq1}\\
       &= \frac{P(Y_1 \leq t)}{P(Y_1\leq T)}  \label{eq2}\\
       &= \frac{1-e^{-\Phi t}}{1-e^{-\Phi T}} \label{eq3}
\end{align}
where Eq.~(\ref{eq1}) follows from Bayes's rule,
Eq.~(\ref{eq2}) assumes $t\leq T$ (otherwise the answer is 1, 
trivially) and Eq.~(\ref{eq3}) is obtained by plugging
in the c.d.f. of $Y_1 \sim \text{Exp}(\Phi).$

Due to the low flux assumption, $\Phi \ll \frac{1}{T}$. Then $\Phi t \leq \Phi
T \ll 1$ and we can approximate $1-e^{-\Phi T} \approx \Phi T$ and $1-e^{-\Phi
t} \approx \Phi t$. This gives
\begin{equation}
    P(Y_1\leq t | Y_1\leq T) = \frac{t}{T}
\end{equation}
which is the c.d.f. of a uniform random variable. This implies that, in the low
photon flux regime the arrival time distribution converges weakly to a uniform
random variable:
\[
  \{Y_1 | Y_1 \leq T\} \overset{D}{\rightarrow} \mathcal{U}[0,T].
\]

For low illumination conditions, we drop the requirement of a fixed exposure
time and allow the IP-SPAD pixel to wait until the first photon timestamp
is captured.

\subsection{KPN-based Denoising Network for Low Light IP-SPAD Imaging}
In principle, any standard neighborhood-based image denoising algorithm (e.g.,
bilateral filtering \cite{paris2007gentle} and BM3D \cite{dabov2007image}) can
be applied to the IP-SPAD images captured in a low photon count regime. But the
heavy-tailed nature of the timestamps poses problems to off-the-shelf denoising
algorithms as they usually assume a light-tailed distribution of pixel
intensities (e.g., Gaussian distribution). A solution to this issue is the use
of a variance-stabilizing Anscombe transform
\cite{anscombe_transformation_1948} to make the noise variance uniform across
the whole image. For photon timestamp data, the variance-stabilizing transform
is the logarithm. See \nolink{\ref{sec:suppl_note_logT_estimator}} for a proof.
We design an image denoising deep neural network (DNN) that operates on
log-transformed first-photon timestamp images.

We use a kernel prediction network (KPN) architecture 
\cite{kpn_2017,burstkpn_2018}. Our network architecture is shown in
Suppl.~Fig.~\nolink{\ref{fig:kpn_logtimg}}. The network produces $5 \times 5$
kernels for every pixel in the input image, which we apply to generate the
denoised image. The only substantial post-processing step is to correct the
bias introduced by using the log-timestamp instead of the timestamp itself (see
\nolink{\ref{sec:suppl_note_logT_estimator}}).

We train the network with timestamp images simulated from the DIV2K dataset
\cite{DIV2K_Intro,DIV2K_Report}. This dataset has 800 high-resolution images;
we simulate four random timestamp images for each image in the dataset for a
total of 3200 training images. The original 8-bit images are first converted to
16-bit linear luminance \cite{imagemagick}, before simulating the timestamps.
The simulated timestamps are then log-transformed.

We use the Adam optimizer \cite{kingma2017adam} with a learning rate of
$10^{-4}$. The loss function is a sum of squared errors in the pixel
intensities and absolute errors in the pixel-wise image gradients, both with
respect to the original image from which the timestamps are simulated
\cite{burstkpn_2018}.  Training runs for 1920 iterations with a batch size of 5
images, for a total of 3 epochs. Images are randomly cropped into $128 \times
128$ patches before passing into the network when training. However, since
the network is fully convolutional, it can handle arbitrary input image sizes
at test time.


The architecture of our kernel prediction network-based denoising DNN is
shown in Suppl. Fig.~\ref{fig:kpn_logtimg}.

\begin{figure}[!htb]
    \centering
    \includegraphics[width=0.5\linewidth]{figures/kpn_logtimg.pdf}
    \caption{The kernel prediction network (KPN) architecture we have used to
      estimate per-pixel kernels of size $5 \times 5$, which is adapted from
      the architectures used for burst denoising in \cite{burstkpn_2018} and
      for denoising Monte-Carlo renderings in \cite{kpn_2017}. The input image
    size is $128 \times 128$ when training the network, but any image size can
    be used at the inference stage.}
    \label{fig:kpn_logtimg}
\end{figure}

Suppl. Fig.~\ref{fig:passive_first_photon} shows simulated denoising results
comparing our KPN-based denoiser with two standard denoising methods: bilateral
filtering and BM3D.
\begin{figure}[!htb]
  \centering
  \includegraphics[width=0.80\linewidth]{figures/Fig4_firstphoton.png}
  \caption{\textbf{Denoising IP-SPAD Images with Low Photon Counts:} (a-b) We simulate
  the extreme case of IP-SPAD imaging by sampling at most one photon
  time stamp per pixel of a ground truth image. (c) Simply inverting the each
  time stamp is not enough due to extreme noise, (d-f) so it is necessary to
  combine time stamps spatially. (d) We apply a bilateral filter ($\sigma=7$),
  which incorporates some spatial information, but still remains quite noisy.
  (e) BM3D \cite{Kostadin2006} may over smooth, and it seems to have particular
  trouble in bright regions. (f) Our KPN denoiser trained on photon timestamp
  data preserves some object shapes like the bright ceiling light and the
  couches.
  \label{fig:passive_first_photon}}
\end{figure}



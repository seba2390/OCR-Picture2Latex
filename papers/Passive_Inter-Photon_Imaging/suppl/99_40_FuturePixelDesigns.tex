\section{Pixel Designs for Passive SPAD Imaging\label{suppl:pixel_designs}}

\begin{figure}[!htb]
  \centering \includegraphics[width=0.61\columnwidth]{figures/SPADPixels_full.png}
  \caption{\textbf{IP-SPAD pixel designs for passive imaging:} (a) and (b) are
  existing SPAD pixel designs with counts and in-pixel timing circuits. (c) and
  (d) are hypothetical future pixel designs for passive IP-SPAD cameras that
  store individual photon timestamps or compute summary statistics on the fly.
  \label{fig:array_designs_full}}
\end{figure}


\smallskip
\noindent\textbf{Passive SPAD Pixel Architectures}
Many current SPAD pixel designs are targeted towards specialized active imaging
applications that operate the detector in synchronization with a light source,
such as pulsed laser. The most common data processing task is to generate a
\emph{timing histogram} which counts the number of photons detected by the SPAD
pixel as a function of the (discretized) time delay since the transmission of
the most recent laser pulse. The requirements for the passive imaging technique
shown in this paper are different: there is no pulsed light source to provide
a timing reference. Instead, it is important to precisely control (1) the dead
time duration (2) rise and fall times of the SPAD bias circuitry, and
(3) the duration of the global exposure time.

Our single-pixel IP-SPAD hardware prototype, although acceptable as a
proof-of-concept, is not a scalable solution for sensor arrays.
Delay-locked loops circuits suitable for multi-pixel implementation
can be used in the future to precisely control the dead-time duration.  A large
array of IP-SPAD pixels will generate an unreasonably large volume of raw
photon timestamp data that cannot be transferred off the sensor chip for
post-processing. A megapixel SPAD array has been recently demonstrated using a
\SI{180}{\nm} CMOS technology \cite{Morimoto_2020}, but the in-pixel
electronics is currently limited to gating circuitry and a 1-bit data register.
The trade-off between SPAD performance and pixel number can be overcome by
recently-developed 3D-stacking approaches where  SPAD arrays are fabricated in
a dedicated technology, the high density data-processing electronics are
developed in scaled technology, and then the two chips/wafers are mounted one
on top of the other \cite{Henderson_2019_ISSCC,Charbon_2018}.

Fig.~\ref{fig:array_designs_full}(a) shows the simplest single-pixel architecture
currently used as a building-block in large SPAD arrays. It comprises the
photodetector, its readout and quenching circuits and a digital counter, for
storing the number of detected photons. While this architecture is widely used
\cite{bronzi2015spad}, it does not exploit photon arrival times to increase
dynamic range. As shown in Fig.~\ref{fig:array_designs_full}(b), adding an
in-pixel time-to-digital converter (TDC) able to acquire and store individual
photon time-stamps (with respect to the exposure time synchronization signal)
can solve this limitation.  Also this approach is nowadays quite common when
designing SPAD arrays \cite{Henderson_2019, Portaluppi_2018}, however,
increasing the array dimension and considering a very high incident photon
flux, it will be impractical to acquire and transfer timestamps for each photon
and each pixel, because it will lead to intractable volume of data to be
processed. Instead, a more efficient way of storing and transmitting photon
time-stamp data for passive imaging can rely on simply storing the first and
last photon time-stamps within a single exposure time, together with the total
photon counts. The corresponding pixel design is shown in
Fig.~\ref{fig:array_designs_full}(c). While this increases pixel complexity
over the previous SPAD pixel design examples, it only requires two additional
data registers. The disadvantage of this scheme is that, depending on the total
exposure time, the TDC may require a large full-scale range.  For example,
using an exposure time in the millisecond range and the timestamp resolution in
picoseconds, the TDC data depth will be $\log_2(10^{-3}/10^{-12})\approx
30$~bits.

Note that our brightness estimator keeps track of the average time-of-darkness
between photon detections over a fixed exposure time. An alternative to storing
first and last timestamps may be to instead store a running average of the
inter-photon times, as shown in Fig.~\ref{fig:array_designs_full}(d). This can be
implemented in-pixel using basic digital signal processing circuits. At high
photon flux levels, the expected inter-photon times will be short enough that a
TDC with smaller full scale range could be used. Although the inter-photon
times may still be quite long for low flux levels, the flux estimator can fall
back to using photon counts only, instead of timestamps.

\paragraph{SPAD Array Designs for Passive Imaging}
The theoretical analysis and experimental results in this paper were restricted
to a single SPAD pixel. For most passive imaging applications, in practice,
there will be a need to scale this method to large form factor SPAD arrays with
thousands of pixels. This will introduce additional design challenges and noise
sources not discussed in this work. A large form-factor SPAD array of
free-running SPAD pixels will generate an unreasonably large volume of raw
photon time-stamp data that cannot be simply transferred off the sensor chip
for post-processing. For instance, consider a hypothetical 1 megapixel SPAD
array consisting of pixels shown in Fig.~\ref{fig:array_designs_full}(b), with dead
time of \num{100}~\si{\ns}. Assume an average photon flux of \num{e5} photons/s
over the pixel array and the pixels generate \num{32}-bit IEEE floating-point
timestamps for each detected photon. This corresponds to
\num{400}~\si{\gibi\byte\per\s} of data generated from the chip. A megapixel
SPAD array has been recently demonstrated using a 180nm CMOS technology
\cite{Morimoto_2020} , but the in-pixel electronics is currently limited to
gating circuitry and 1-bit data register (photon detected or not). 

One possible solution to overcome this problem could include the design of
large arrays using a combination of pixel architectures sketched in
Fig.~\ref{fig:array_designs_full}, i.e. where only a fraction of pixels would
include high resolution TDCs while the rest of the pixels only use photon
counters.  This will still enable capturing extremely high flux values albeit
with reduced spatial resolution. In another solution TDCs are shared among more
pixels, while counters are integrated in each pixel. This will reduce the
maximum count rate, but each detected photon is counted and time tagged.

SPAD performance (i.e. detection efficiency, dark count noise, temporal
resolution, afterpulsing probability) in developing multi-pixel arrays is
usually better when using ``legacy'' fabrication technologies, like 350 nm and
180 nm CMOS, or even ``custom'' technologies (which, however, do not allow the
on-chip integration of ancillary electronics) \cite{Ghioni_2007}. With such
technologies, the relatively large minimum feature size prevents in-pixel
integration of sophisticated electronics like high-resolution (few \si{\ps})
TDCs, data processing circuits and memories (unless without accepting an
extremely low fill-factor). The trade-off between SPAD performance and pixel
number can be overcome by recently-developed 3D-stacking approaches:  SPAD
array is fabricated in a dedicated technology, the high density data-processing
electronics is developed in scaled technology, and then the two chips/wafers
are mounted one on top of the other \cite{Henderson_2019_ISSCC,Charbon_2018}.

Passive IP-SPAD arrays may also require pixel-wise calibration. The non-linear
pixel response curve may make this more challenging than conventional CMOS
camera pixels. It will be necessary to characterize non-uniformity in terms of
dead-time durations and timing jitter and account for these for removing any
fixed pattern noise.

Another important practical consideration is power requirement, especially when
operating in high flux conditions where a large number of avalanches will be
created causing huge power requirement for processing these in real-time and
reading out the counts. There is also a significant heat dissipation issue
which can exacerbate pixel calibration due to the strong temperature dependence
of various pixel parameters like dark count rate and dead-time drifts. Such
power issues may be mitigated with scaled technologies operating at lower
supply voltage.


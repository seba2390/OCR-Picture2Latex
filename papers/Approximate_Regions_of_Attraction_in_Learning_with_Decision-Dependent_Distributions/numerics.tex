% !TEX root = main.tex

\begin{figure*}[t!]
  \centering
\includegraphics[width=0.325\textwidth]{./figs/0_simp_c1c2.pdf}
\includegraphics[width=0.315\textwidth]{./figs/0_simp_c3c4.pdf}
\includegraphics[width=0.26\textwidth]{./figs/0_simp_quad_bnds.pdf}
  \caption{We verify that the performative risk bounds in Assumption~\ref{ass:exist_V} are satisfied in the example discussed in Section~\ref{sec:example}. (a) As a function of $r$ (the radius of the domain where the inequalities hold), we show the tightest constants $c_1$ and $c_2$ for the bound. We also plot $\sqrt{c_1/c_2}r$, which is the radius of a neighborhood of $x=0$ to which Theorem~\ref{th:perturb1} can be applied. (b) As a function of $r$, we show the tightest constants for $c_3$ and $c_4$. (c) Choosing the $c_1$ and $c_2$ constants for $r = 0.5$, we visualize how the quadratic bounds hold for the performative risk locally.}
  \label{fig:simp_ex_demo}
\end{figure*}
In this section, we revisit the models introduced in Section~\ref{sec:example}. We demonstrate how the results of Sections~\ref{sec:analysis_prm} and~\ref{sec:analysis_RGD} can be applied. First, we show that the example satisfies Assumption~\ref{ass:exist_V} and we calculate its corresponding constants. Second, we apply Theorem~\ref{th:perturb1} and show the theoretical convergence rates match simulated trajectories. 
Finally, we also apply Theorem~\ref{th:perf_align} to the example from Section~\ref{sec:simple_ex} and characterize the class of distribution shifts satisfy the performative alignment condition.

\subsection{Checking the curvature of the performative risk and region of convergence}

Recall the example from Section~\ref{sec:simple_ex}, where $x$ was a scalar, the loss function was the squared error, and the decision-dependent distribution was a Bernoulli random variable whose distribution was determined by $p(\cdot)$. In this section, we consider the specific decision-dependent distribution shift $p = \varphi$, which is defined in Equation~\eqref{eq:varphi_def}.

When we consider this example, we can see that the bounds on Assumption~\ref{ass:exist_V} cannot hold globally, which matches our previous observation that there are multiple isolated performative risk minimizers. However, these bounds may hold locally: we can view the constants $(c_i)_{i=1}^4$ from Assumption~\ref{ass:exist_V} as a function of the size of the domain $r$.

For concreteness, let us focus on the equilibrium point $x = 0$. Recall that Assumption~\ref{ass:exist_V} must hold locally, on the domain $\{ x : |x-x^*| \le r\}$. As we increase $r$, the constants will worsen; we visualize this in Figure~\ref{fig:simp_ex_demo}(a)--(b). Note that these bounds only have to hold locally around the equilibria, as visualized in Figure~\ref{fig:simp_ex_demo}(c). Furthermore, the gradient bounds in Assumption~\ref{ass:exist_V} cannot hold beyond $r > 0.40$, since $\nabla PR(x) = 0$ at that point.

Recall that the convergence results of Theorem~\ref{th:perturb1} can only apply to all initial conditions satisfying $|x_0 - x^*| < \sqrt{c_1/c_2}r$; we visualize this as well in Figure~\ref{fig:simp_ex_demo}(a). 
On the set $(0,0.40]$, we can see the quantity $\sqrt{c_1/c_2}r$ is the largest at $r = 0.4$, with constants $c_1 = 0.50$ and $c_2 = 1.78$. 
Thus, around the equilibrium $x = 0$, the theorem can be applied to all points in the set $\{ x : |x| \le 0.21 \}$, with $\delta = 0$. Thus, our theorem shows that all points in this neighborhood of $x = 0$ will converge. This under-approximates the true region of attraction, which we numerically saw to be $\{ x : x < 0.23 \}$.



\subsection{Performative alignment with squared error and Bernoulli distributions}
\label{sec:perf_align_ex}

We again consider the example from Section~\ref{sec:simple_ex}. However, in this section, we consider a general decision-dependent distribution shift $p(\cdot)$. 
% Recall the example from Section~\ref{sec:simple_ex}, where $x$ was a scalar, the loss function was the squared error, and the decision-dependent distribution was a Bernoulli random variable whose distribution was determined by $p(\cdot)$.  
We suppose that $p(0) = 0$ and $p(1) = 1$, so we have two performative risk minimizers as in our previous example. We have $\nabla_{x_1}R(x,x) = x - p(x)$ and $\nabla_{x_2}R(x,x) = (1/2 - x) p'(x)$. 
The performative alignment condition becomes:
\begin{equation}
    \label{eq:perf_align_ex}
    |1/2 - x|^2 |p'(x)|^2 \le (p(x)-x)(1/2 - x)p'(x)
\end{equation}
Theorem~\ref{th:perf_align} states that if this condition holds for all $x \in (0,c)$, then any initial conditions $x_0 \in (0,c)$ will converge to $x = 0$. Similarly, if this condition holds for all $x \in (c,1)$, then all initial conditions in $(c,1)$ will converge to $x = 1$. Theorem~\ref{th:perf_align} also implies that this condition cannot be satisfied for all $x \in (0,1)$, as then these initial conditions would converge to \textit{both} $x = 0$ and $x = 1$.

If we suppose that $p(\cdot)$ is monotonic on $(0,1)$, i.e. $p'(x) \ge 0$, we can also interpret the performative alignment condition as follows. For $x \in (1/2,1)$, the performative alignment condition becomes $p(x) - x \ge (1/2 - x)p'(x)$. In this regime, $(1/2 - x)p'(x) \le 0$. In this setting, if $p(x) - x$ is too negative, the RGD flow will push $x$ away from the nearby minimizer $x = 1$. Similarly, for $x \in (0,1/2)$, the condition becomes $p(x) - x \le (1/2 - x)p'(x)$. In this regime, $(1/2 - x)p'(x) \ge 0$, and the condition states that $p(x) - x$ cannot be too large, or the RGD flow will push $x$ away from the minimizer $x = 0$.

In this section, we used Theorem~\ref{th:perf_align} to identify conditions on the decision-dependent distribution shift $p(\cdot)$ which ensure that the performative risk does not increase even when the dynamics follow repeated gradient descent.
For this example, the condition is that $p$ satisfies Equation~\eqref{eq:perf_align_ex} for all $x \in (0,c)$. 
More generally, the performative alignment condition allow us to specify a class of distribution shifts which behave well with respect to performative risk minimization.


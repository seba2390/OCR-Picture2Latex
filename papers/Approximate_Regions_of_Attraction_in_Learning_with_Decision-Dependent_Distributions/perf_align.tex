% !TEX root = main.tex

From the previous analysis, we also identify conditions on the directions of the performative perturbations that are sufficient to show the convergence of Equation~\eqref{eq:RGD_flow}, the RGD flow, to performative risk minimizers.

\begin{theorem}[Performative alignment]
\label{th:perf_align}
Suppose $x^*$ is a isolated local performative risk minimizer and the following holds for all $x$ in a neighborhood of $x^*$:
\begin{equation}
\label{eq:perf_align}
|\nabla_{x_2}R(x,x)|^2 \le \langle -\nabla_{x_1}R(x,x), \nabla_{x_2}R(x,x) \rangle
\end{equation}
Then $x^*$ is a locally asymptotically stable equilibrium point of the RGD flow, given by Equation~\eqref{eq:RGD_flow}. 
Note that this does \textbf{not} require Assumption~\ref{ass:exist_V}.
\end{theorem}

\begin{proof}
Let $V(x) = PR(x) - PR(x^*)$. 
Since $x^*$ is a locally asymptotically equilibria of the PRM flow, we have: $V(x^*) = 0$, $V(x) > 0$ for $x \neq 0$, and $\mc{L}_{\fnom} V(x) < 0$ for $x \neq 0$. The performative alignment condition ensures that $\mc{L}_{\fnom + g} V(x) < 0$ as well, and the desired result follows.
\end{proof}

We refer to Equation~\eqref{eq:perf_align} as the \textbf{performative alignment} condition. This condition states that the performative perturbation never increases the performative risk, and the convergence of performative risk minimization is sufficient to guarantee convergence of repeated risk minimization. In other words, the perturbation is pointing in the correct direction to ensure that $PR(\cdot) - PR(x^*)$ can still act as a Lyapunov function.

Another perspective on performative alignment is to consider the performative risk as a bilinear form whose arguments are parameterized by $x$. In particular, consider the decoupled performative risk $R(\cdot,\cdot)$. Let $\ell_{x} := \ell(\cdot, x)$ and let $\mu_x$ denote the probability distribution associated with $\mc{D}(x)$. Then, we can write $R(x_1,x_2) = \langle \mu_{x_2}, \ell_{x_1} \rangle$. From this perspective, $R(\cdot,\cdot)$ is a bilinear form in $\ell_x$ and $\mu_x$. As such, the performative alignment condition becomes a condition on the way in which $\ell$ and $\mu$ are \textit{parameterized} by $x$.

In Appendix~\ref{sec:perf_align_ex}, we apply Theorem~\ref{th:perf_align} to the example outlined in Section~\ref{sec:simple_ex}. It provides insight into one of the ways to use Theorem~\ref{th:perf_align}: when we fix a loss $\ell(\cdot)$, we can view the performative alignment condition as specifying a class of decision-dependent distribution shifts which do not hamper the convergence of RGD to performative risk minimizers.

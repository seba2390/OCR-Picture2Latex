
\section{Model for ordinal responses}
\label{sec:polyordinalmodel}

\subsection{The extended model}
\label{subsec:ordinalmodel}

We extend the model developed in Section \ref{subsec:standardmodel} to handle ordinal responses. 
Suppose the observation on subject $i$ at time $\tau_{it}$, denoted by $Y_{it}$, takes $C$ possible 
categories. We can equivalently encode the response as a vector with binary entries 
$\mathbf{Y}_{it}=(Y_{i1t}\cdots,Y_{iCt})$, such that $Y_{it}=j$ is equivalent to $Y_{ijt}=1$ 
and $Y_{ikt}=0$ for any $k\neq j$. We assume a multinomial response distribution for 
$\mathbf{Y}_{it}$, factorized in terms of binomial distributions,
\begin{equation}
	Mult(\mathbf{Y}_{it}\mid m_{it},\omega_{i1t},\cdots,\omega_{iCt})=\prod_{j=1}^{C-1}Bin(Y_{ijt}\mid m_{ijt},\varphi(Z_{ijt}+\epsilon_{ijt}))
	\label{eq:factmulti}
\end{equation}
where $m_{it}=\sum_{j=1}^CY_{ijt}\equiv 1$, $m_{i1t}=m_{it}$, and $m_{ijt}=m_{it}-\sum_{k=1}^{j-1}Y_{ikt}$. %Treating the variables as the functional evaluation at the corresponding time, (\ref{eq:factormultinomial}) can be written from a functional data analysis perspective,
%\begin{equation*}
%	Mult(\mathbf{Y}_{i}(\tau_{it})\mid m_{i}(\tau_{it}),\pi_{i1}(\tau_{it}),\cdots,\pi_{iC}(\tau_{it}))=\prod_{j=1}^{C-1}Bin(Y_{ij}(\tau_{it})\mid m_{ij}(\tau_{it}),\varphi(Z_{ij}(\tau_{it})+\epsilon_{ij}(\tau_{it})))
%	\label{eq:factormultinomial}
%\end{equation*}
This factorization bridges the gap between binary and ordinal responses. Similar to the model 
for binary responses, we adopt a functional data analysis perspective on $\{Z_{ijt}\}$, modeling 
them separately through the hierarchical framework developed in Section \ref{subsec:standardmodel}. 
That is, $Z_{ij}(\tau)\mid \mu_j,\Sigma_j\stackrel{i.i.d.}{\sim} GP(\mu_j,\Sigma_j)$, 
for $i=1,\cdots,n$, and $\mu_j|\Sigma_j\stackrel{ind.}{\sim} GP(\mu_{0j}, (\nu_j -3) \Sigma_j)$, $\Sigma_j\stackrel{ind.}{\sim}IWP(\nu_j,\Psi_{\boldsymbol{\phi}_j})$, where 
$\boldsymbol{\phi}_j=\{\sigma^2_j,\rho_j\}$, for $j=1,\cdots,C-1$. The error terms are modeled as 
$\epsilon_{ijt} \mid \sigma^2_{\epsilon j} \stackrel{ind.}{\sim}N(0,\sigma^2_{\epsilon j})$. 
Hence, the hierarchical model for the data can be expressed as 
\begin{equation}
    \begin{split}
        &\mathbf{Y}_i|\{\mathbf{Z}_{ij}\},\{\boldsymbol{\epsilon}_{ij}\}\stackrel{ind.}{\sim} \prod_{t=1}^{T_i}\prod_{j=1}^{C-1}Bin(Y_{ijt}\mid m_{ijt},\varphi(Z_{ijt}+\epsilon_{ijt})),\quad i=1,\cdots,n,\\
        &\mathbf{Z}_{ij}\mid \mu_j(\boldsymbol{\tau}_i),\Sigma_j(\boldsymbol{\tau}_i,\boldsymbol{\tau}_i)\stackrel{ind.}{\sim} N(\mu_j(\boldsymbol{\tau}_i),\Sigma_j(\boldsymbol{\tau}_i,\boldsymbol{\tau}_i)),\quad \boldsymbol{\epsilon}_{ij}\mid \sigma_{\epsilon j}^2\stackrel{ind.}{\sim} 
        N(\mathbf{0},\sigma_{\epsilon j}^2 \, \mathbf{I}),\\
        & \boldsymbol{\mu}_j\mid\mu_{0j},\boldsymbol{\Sigma}_j,\nu_j \stackrel{ind.}{\sim} 
        N(\mu_{0j}\mathbf{1}, (\nu_j - 3) \boldsymbol{\Sigma}_j); \, \boldsymbol{\Sigma}_j\mid\nu_j,\boldsymbol{\Psi}_j\stackrel{ind.}{\sim} 
        IW(\nu_j,\boldsymbol{\Psi}_j), \, j=1,\cdots,C-1
    \end{split}
    \label{eq:fddsmulti}
\end{equation}
where $\mathbf{Y}_{i}=(\mathbf{Y}_{i1},\cdots,\mathbf{Y}_{iT_i})^{\top}$, 
$\mathbf{Z}_{ij}=(Z_{ij1},\cdots,Z_{ijT_i})^{\top}$, 
$\boldsymbol{\epsilon}_{ij}=(\epsilon_{ij1},\cdots,\epsilon_{ijT_i})^{\top}$, 
and the collection of the functional evaluations on the pooled grid $\boldsymbol{\tau}$ 
are denoted by the corresponding bold letter.
%adopt the proposed model for the signal process and noise on the category specific signal $Z_{ij}(\tau)$ and noise $\epsilon_{ij}(\tau)$, $j=1,\cdots,C-1$, arriving at the model for ordinal functional data
%\begin{equation}
%	\begin{split}
%		&\mathbf{Y}_{i}(\tau_{it})\mid \{Z_{ij}(\tau_{it}),\epsilon_{ijt}\}_{j=1}^{C-1}\stackrel{ind.}{\sim} \prod_{j=1}^{C-1}Bin(Y_{ij}(\tau)\mid m_{ij}(\tau),\varphi(Z_{ij}(\tau)+\epsilon_{ij}(\tau)))\\
%		& Z_{ij}(\tau)\mid \mu_j,\Sigma_j\stackrel{i.i.d.}{\sim} GP(\mu_j,\Sigma_j),\quad \epsilon_{ij}(\tau)\stackrel{i.i.d.}{\sim} GP(0,\sigma_{\epsilon j}^2I_{\{\tau=\tau^{\prime}\}}),\quad i=1,\cdots,n\\
%		& \mu_j|\Sigma_j\stackrel{ind.}{\sim} GP(\mu_{0j},\Sigma_j/\kappa_j),\quad \Sigma_j\stackrel{ind.}{\sim}IWP(\nu_j,\Psi_{\boldsymbol{\phi}_j}),\quad j=1,\cdots,C-1.
%	\end{split}
%	\label{eq:modelgeneral}
%\end{equation}	


The structure in (\ref{eq:factmulti}) is referred to as the continuation-ratio logits representation 
of the multinomial distribution \citep{Tutz1991}. In the context of Bayesian nonparametric modeling,
it has been used as the kernel of nonparametric mixture models for cross-sectional ordinal 
regression \citep{KangKottas2022}. 


Examining model properties reveals the practical utility of the continuation-ratio logits 
structure. The factorization in (\ref{eq:factmulti}) allows us to examine the probability response 
curves and the within subject covariance structure in the same fashion as for binary responses. 
Specifically, the continuation-ratio logit for response category $j$ is the logit of the conditional 
probability of response $j$, given that the response is $j$ or higher. As a consequence, for any 
finite grid $\boldsymbol{\tau}=(\tau_1,\cdots,\tau_T)^{\top}$, the probability response 
curves are given by
\begin{equation}
\begin{split}
\mathbf{P}_{\mathbf{j}\boldsymbol{\tau}}& = (\text{Pr}(Y_{\tau_1}=j\mid \mathbf{Z}_{\boldsymbol{\tau}},\sigma_{\epsilon}^2),
\cdots,\text{Pr}(Y_{\tau_T}=j\mid \mathbf{Z}_{\boldsymbol{\tau}},
\sigma_{\epsilon}^2))^{\top}\\
&=\text{E}\left( \boldsymbol{\pi}_{j \boldsymbol{\tau}}\mid \mathbf{Z}_{j 
\boldsymbol{\tau}},\sigma_{\epsilon j}^2 \right)
\prod_{k=1}^{j-1} \text{E}\left( (1-\boldsymbol{\pi}_{k \boldsymbol{\tau}})\mid \mathbf{Z}_{k \boldsymbol{\tau}},\sigma_{\epsilon k}^2 \right),
\end{split}
	\label{eq:probmult}
\end{equation}
%\begin{equation*}
%\begin{split}
%	\text{Pr}(\mathbf{Y}_{\boldsymbol{\tau}}&=\mathbf{j}\mid\{\mathbf{Z}_{\boldsymbol{j \tau}}\},\{\sigma_{\epsilon j}^2\})\\
%	&=\left\{\begin{aligned} & E[\varphi(\boldsymbol{\mathcal{Z}}_{j \boldsymbol{\tau}}\mid \mathbf{Z}_{j \boldsymbol{\tau}},\sigma_{\epsilon j}^2)]\prod_{k=1}^{j-1}E[1-\varphi(\boldsymbol{\mathcal{Z}}_{k \boldsymbol{\tau}}\mid \mathbf{Z}_{k\boldsymbol{\tau}},\sigma_{\epsilon k}^2)] & j=1,\cdots, C-1\\ & \prod_{k=1}^{C-1}E[1-\varphi(\boldsymbol{\mathcal{Z}}_{k \boldsymbol{\tau}}\mid \mathbf{Z}_{k\boldsymbol{\tau}},\sigma_{\epsilon k}^2)] & j=C \end{aligned}\right.,
%\end{split}
%	\label{eq:probmult}
%\end{equation*}
where %$\mathbf{j}$ represents a vector of $j$ with length $|\boldsymbol{\tau}|$, 
$\boldsymbol{\pi}_{j\boldsymbol{\tau}}=(\varphi(\boldsymbol{\mathcal{Z}}_{j1}),\cdots,\varphi(\boldsymbol{\mathcal{Z}}_{jT}))^{\top}$ 
and $\boldsymbol{\mathcal{Z}}_{j \boldsymbol{\tau}}\mid \mathbf{Z}_{j 
\boldsymbol{\tau}},\sigma_{\epsilon j}^2\sim N(\mathbf{Z}_{j \boldsymbol{\tau}},
\sigma_{\epsilon j}^2\mathbf{I}_T)$, for $j=1,\cdots,C$.
To avoid redundant expressions, we include the term $\boldsymbol{\pi}_{C\boldsymbol{\tau}}$ 
and set it always equal to 1. As for the covariance structure, we study the joint probability 
of the repeated measurements on the same subject at time $\tau$ and $\tau^{\prime}$ taking 
category $j$ and $j^{\prime}$. Exploiting the conditional independence structure across 
the categories, 
\begin{equation}
\begin{split}
	&\text{Pr}(Y_{\tau}=j,Y_{\tau^{\prime}}=j^{\prime}\mid\{\mathbf{Z}_{\boldsymbol{j \tau}}\},\{\sigma_{\epsilon j}^2\})\\
	&=\left\{\begin{aligned} & \text{E}(\pi_{j\tau}\pi_{j\tau^{\prime}}\mid \mathbf{Z}_{j \boldsymbol{\tau}},\sigma_{\epsilon j}^2)\prod_{k\neq j}\text{E}[(1-\pi_{k\tau})(1-\pi_{k\tau^{\prime}})\mid \mathbf{Z}_{k \boldsymbol{\tau}},\sigma_{\epsilon k}^2] & j=j^{\prime}\\ & \text{E}[\pi_{j\tau}(1-\pi_{j\tau^{\prime}})\mid \mathbf{Z}_{j \boldsymbol{\tau}},\sigma_{\epsilon j}^2] \, 
 \text{E}[(1-\pi_{j^{\prime}\tau})\pi_{j^{\prime}\tau^{\prime}}\mid \mathbf{Z}_{j^{\prime} \boldsymbol{\tau}},\sigma_{\epsilon j^{\prime}}^2] & \\
 &\times \prod_{k\neq j,j^{\prime}}\text{E}[(1-\pi_{k\tau})(1-\pi_{k\tau^{\prime}})\mid \mathbf{Z}_{k \boldsymbol{\tau}},\sigma_{\epsilon k}^2] & j\neq j^{\prime} \end{aligned}\right..
\end{split}
	\label{eq:jointprobmult}
\end{equation}  
%Here, we slightly abuse notation by writing $\mathbf{Y}_{\tau}=j$, while it is actually $\mathbf{Y}_{\tau}=\mathbf{1}_j$, the unit vector in $\mathbb{R}^C$ with the $j$th element equal to 1. 
Hence, we can explore the covariance of the two ordinal responses 
$\mathbf{Y}_{\tau},\mathbf{Y}_{\tau^{\prime}}$ by studying the pairwise covariance 
for each entry.  


The continuation-ratio logits structure is also key to efficient model implementation. It implies 
a sequential mechanism, such that the ordinal response is determined through a sequence of binary 
outcomes. Starting from the lowest category, each binary outcome indicates whether the ordinal 
response belongs to that category or to one of the higher categories. This mechanism inspires 
a novel perspective on the model implementation. That is, we can re-organize the original data 
set containing longitudinal ordinal responses to create $C-1$ data sets with longitudinal 
binary outcomes. Then, fitting model (\ref{eq:fddsmulti}) to the original data set is equivalent 
to fitting the model of Section \ref{subsec:standardmodel} separately on the $C-1$ re-organized 
data sets. The procedure is elaborated below. 


Denote the set of all possible subject and time indices by $\boldsymbol{\mathcal{I}}_1$, 
that is, $\boldsymbol{\mathcal{I}}_1=\{(i,t):i=1,\cdots,n,t=1,\dots,T_i\}$. To build the first 
re-organized data set with binary outcomes, we create binary indicators $Y^{(1)}_{it}$, such 
that $Y^{(1)}_{it}=1$ if $Y_{i1t}=1$ and $Y^{(1)}_{it}=0$ if $Y_{i1t}=0$. The first 
data set is then $\boldsymbol{\mathcal{D}}_1 = \{Y^{(1)}_{it}: (i,t)\in\boldsymbol{\mathcal{I}}_1\}$.  
Moving to the second data set, we first filter out the observations that are already 
categorized into the smallest scale, and denote the remaining indices set 
by $\boldsymbol{\mathcal{I}}_2=\boldsymbol{\mathcal{I}}_1\setminus\{(i,t):Y_{i1t}=1\}$. 
This is the set of indices with original ordinal responses belonging to categories higher 
than or equal to the second smallest scale. Then, we create new binary indicators $Y^{(2)}_{it}$, 
such that $Y^{(2)}_{it}=1$ if $Y_{i2t}=1$, and $Y^{(2)}_{it}=0$ if $Y_{i2t}=0$. 
The second data set is obtained as $\boldsymbol{\mathcal{D}}_2 = \{Y^{(2)}_{it}: (i,t)\in\boldsymbol{\mathcal{I}}_2\}$. The process is continued until we obtain the 
$(C-1)$-th data set, 
$\boldsymbol{\mathcal{D}}_{C-1}=\{Y^{(C-1)}_{it}: (i,t)\in\boldsymbol{\mathcal{I}}_{C-1}\}$, 
where $\boldsymbol{\mathcal{I}}_{C-1}$ is the indices set such that the original ordinal 
responses belong to either category $C-1$ or $C$. Notice that every re-organized data 
set $\boldsymbol{\mathcal{D}}_{j}$, for $j=1,\cdots,C-1$, contains longitudinal binary 
outcomes for which the model of Section \ref{subsec:standardmodel} is directly applicable. 
Provided the priors placed on each ordinal response category's parameters are independent,
it is straightforward to verify that fitting separately the model for binary responses to the 
re-organized data sets $\{\boldsymbol{\mathcal{D}}_{j}: j=1,\cdots,C-1\}$ is
equivalent to fitting model (\ref{eq:fddsmulti}) to the original data set.
We formalize the conclusion in the following proposition.

\begin{proposition}
\label{prop:fitseparate}
Fitting the ordinal responses model in (\ref{eq:fddsmulti}) is equivalent to fitting 
the model for binary responses separately, $C-1$ times to the data sets 
$\{\boldsymbol{\mathcal{D}}_{j}: j=1,\cdots,C-1\}$.
\end{proposition}

Based on Proposition \ref{prop:fitseparate}, the posterior simulation algorithm for the ordinal 
responses model can be parallelized and implemented on separate cores. In applications where 
the number of response categories is moderate to large, such a parallel computing scheme 
is especially beneficial. Also, since the binary responses model serves as the backbone for 
modeling ordinal responses, the prior specification strategy and the posterior simulation 
method described in Section \ref{subsec:modelapply} can be readily extended to 
model (\ref{eq:fddsmulti}). Finally, from (\ref{eq:probmult}) and (\ref{eq:jointprobmult}), 
it is clear that the posterior samples obtained from the $C-1$ separate models suffice to 
obtain full posterior inference for the ordinal response process.
 
 %For ordinal data analysis, several other methods have been proposed, such as the adjacent-categories logits, the cumulative logits, and the proportional odds model, we refer to \citet[chap.~8]{Agresti2012} for a comprehensive review. Of particular interest to us is the continuation-ratio logits parameterization, because it implies a sequential mechanism, such that the ordinal response is determined through a sequence of binary outcomes. Starting from the lowest category, each binary outcome indicates whether the ordinal response belongs to that category or to one of the higher categories. The continuation-ratio logit for response category $j$ is the logit of the conditional probability of response $j$, given that the response is $j$ or higher.  A key consequence is that, the multivariate response distribution can be factorized into complete conditionals which are given by the univariate binary response models, which have been extensively studied in Section \ref{sec:binarymodel}. Despite its virtue, the continuation-ratio logits have not been explored for general Bayesian nonparametric methods in dealing with ordinal data. To our knowledge, the most relevant article is \citet{KangKottas2022}, in which they focused on the cross-sectional ordinal regression problem and proposed a nonparametric Bayesian mixture model with the continuation-ratio logits structure as the mixing kernel.  
 
%We summarize the major benefit of adopting the continuation-ratio logits parameterization in the following proposition. 



%This result follows directly from the factorization property of continuation-ratio logits parameterization of multinomial distribution and the independent prior we placed on the category specific signal and noise process. Proposition \ref{prop:fitseparate} suggests that we can collect the original ordinal responses $\{Y_{it}: i=1,\cdots,n, t=1,\cdots,T_i\}$ into $C-1$ smaller datasets, $\mathcal{D}_j:=\{Y_{ijt},i=1,\cdots,n, t=1,\cdots,T_i\}$, where $Y_{ijt}$ is a binary response such that $Y_{ijt}=1$ if $Y_{it}\geq j$ and $Y_{ijt}=0$ if $Y_{it}< j$, $j=1,\cdots,C-1$. We then fit the model proposed in the previous section on these $C-1$ smaller datasets separately. This process can be completely parallelized, facilitating the implementation to the ordinal responses with moderate to large number of possible categories. 
%Similar as for the longitudinal binary data, the primary quantities of interest for the ordinal responses are the probability response curves, and the covariance structure for the ordinal responses observed on the specific subject. 




\subsection{Data illustration}
\label{subsec:orddataexample}

As an illustration example, we consider the PAM arousal score on the original scale, which is 
obtained from the same EMA study discussed in Section \ref{sec:realapp}. PAM arousal is a -2 to 2 
(excluding 0) score. We examine the same cohort of students on the same study period as described 
in Section \ref{subsec:datarealapp}. Over all observations, the distribution of arousal scores 
involves $16.6\%$ for level -2, $27.7\%$ for level -1, $12.6\%$ for level 1, and $12\%$ for level 2, 
while $31.1\%$ of the observations are missing. 


To implement model (\ref{eq:fddsmulti}), we follow the procedure outlined above 
Proposition \ref{prop:fitseparate}. We re-organize the original data into separate data sets 
$\{\boldsymbol{\mathcal{D}_j}: j=1,\cdots,3\}$, each of them containing the binary responses 
indicating whether the arousal scores are at level $j$ or a higher level. Then, the proposed 
model is fitted to the three data sets in parallel. 
%To be conservative, we conduct posterior inference using 5000 posterior samples obtained 
%every 6 iterations from a chain of 30000 post burn-in iterations.


The primary inference focus is on the change of arousal scores as the term progresses, which 
is depicted by the probability response curve of each response level. We display posterior 
point and interval estimates of $\mathbf{P}_{\mathbf{j}\boldsymbol{\tau}}$ (defined 
in (\ref{eq:probmult})) in Figure \ref{fig:quadaroprob}. The probability of the highest arousal 
level drops dramatically as the term begins, indicating that the excitement of a new quarter 
may vanish within a week. The Boston marathon bombing slightly triggers higher probability 
for moderately low to low arousal level. There is a drop of the probability for moderately 
high to high arousal level after the Green Key festival and the Memorial Day holiday. 
The exams may have a significant impact on the arousal level. We observe peaks of arousal 
at the beginning of the final exam period, and also the middle of the term, which corresponding 
to the midterm exam period. Since the students are taking different courses, the midterm exam 
times vary, resulting in some curves with lead or lag peaks compared to the majority. This 
pattern is not clear in the analysis of binary arousal scores. Hence, examining the finer 
ordinal scale enables us to discover subtle changes of the students activation states.  
We have also investigated the temporal covariance structure of the ordinal responses, with 
details presented in the Supplementary Material.  

\begin{figure}[t!]
\centering
\includegraphics[width=16cm,height=10cm]{QuadAroProbCurve.png}
\caption{Four levels arousal score data. Posterior mean (dashed line) and 95\% interval 
estimate (shaded region) of probability response curve for an out-of-sample subject. 
The posterior mean estimates for the probability response curves of in-sample subjects 
are given by the solid lines. The vertical shaded regions correspond to the four 
special time periods (see Section \ref{subsec:datarealapp}).}
\label{fig:quadaroprob}
\end{figure}

%Particular to the ordinal responses, we assess the time dependence through the joint probability $\text{Pr}(\mathbf{Y}_{\tau}=j,\mathbf{Y}_{\tau^{\prime}}=j^{\prime}\mid\{\mathbf{Z}_{j\boldsymbol{\tau}}\},\{\sigma^2_{\epsilon j}\})$. Figure \ref{fig:quadarojointprob} displays the posterior point and interval estimate for all possible pairs of the joint probabilities. It suggests that the proposed model enables flexible estimate of the time dependence among the ordinal responses. 

%\begin{figure}[t!]
%\centering
%\includegraphics[width=16cm,height=10cm]{QuadAroJointProb.png}
%\caption{Four levels arousal score data. Posterior mean (dashed line) and 95\% interval estimate (shaded region) of the joint probability of the observations on the same subject made at time $\tau$ and $\tau^{\prime}$.}
%\label{fig:quadarojointprob}
%\end{figure}


%For comparison, we consider the binomial GLMM mentioned in Section \ref{subsec:comparerealapp}, implemented under the continuation-ratio logtis scheme to incorporate the ordinal responses. The criteria for model selection are the posterior predictive loss, the CRPS, and the LPML, computed at each ordinal level. The result is summarized in Table \ref{tab:compquadaro}. The proposed model is always  favored by the CRPS criterion. It also provides a more accurate fit to the data, except on level 2. The price to pay comes from model complexity. Here, the LPML criterion is teetering in determining the better model. Each model is favored on two levels, while the difference is insignificant. On the whole, the our method provides improvement over the GLMM approach in dealing with ordinal responses as well.   




%\begin{table}[t!] \centering
%\small
%\caption{Four levels arousal score data. Summary of comparison between the proposed model 
%and the generalized linear mixed effects model using different criteria. The values 
%in bold correspond to the model favored by the particular criterion.} 
%\label{tab:compquadaro}
%\begin{tabular}{cccccc}
%\hline
%\hline
%\multirow{2}{*}{Arousal} & \multirow{2}{*}{Model} & \multicolumn{2}{c}{Posterior predictive loss} & \multirow{2}{*}{CRPS} & \multirow{2}{*}{LPML} \\
%\cline{3-4} & & $G(\mathcal{M})$ & $P(\mathcal{M})$ & & \\
%\hline
%\hline
%\multirow{2}{*}{Level 1} & Proposed & \textbf{291.20} & 358.92 & \textbf{0.130} & -1010.57\\
%& GLMM & 295.08 & \textbf{309.59} & 0.132 & \textbf{-983.60}\\
%\hline
%\multirow{2}{*}{Level 2} & Proposed & 326.41 & 406.52 & \textbf{0.146} & -1085.20\\
%& GLMM & \textbf{321.29} & \textbf{279.13} & 0.144 & \textbf{-1037.62} \\
%\hline
%\multirow{2}{*}{Level 3} & Proposed & \textbf{500.06} & 458.89 & \textbf{0.224} & \textbf{-1483.51}\\
%& GLMM & 546.97 & \textbf{425.93} & 0.245 & -1535.75 \\
%\hline
%\multirow{2}{*}{Level 4} & Proposed & \textbf{383.12} & \textbf{314.23} & \textbf{0.172} & \textbf{-1223.42}\\
%& GLMM & 446.41 & 529.90 & 0.200 & -1379.08 \\
%\hline
%\hline
%\end{tabular}
%\end{table}


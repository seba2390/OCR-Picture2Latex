\section{Application with binary responses: \textit{Studentlife} data}
\label{sec:realapp}

%\subsection{Studentlife data}
%\label{subsec:studentlife}

%We focus on the PAM (a measure of the students emotion) EMA data. It contains multiple forms of binary/ordinal responses. The proposed ordinal responses to consider are valence (binary), arousal (binary), PAM score (trinary).
%Perform the proposed model, may include only the best result in the paper and move the others to the supplement material. Compare our model with a classic parametric generalized linear mixed effect model. 

\subsection{Data for analysis}
\label{subsec:datarealapp}

% about the study

\textit{Studentlife} \citep{StudentLife2014} is a study that integrates automatic 
sensing data and an EMA component to probe students' mental health status and to study 
its relationship with students' academic performance and behavior trends. The data were 
collected by a smartphone app carried by 48 students over a 10-week term at Dartmouth 
College. The dataset %and background information are 
is available from the R package ``studentlife'' \citep{Studentlifepackage}. 

% about the valence and arousal

We focus on a subset of the data that corresponds to assessing the students' emotional status. 
In the \textit{Studentlife} study, the assessment of emotion is conducted by the Photographic 
Affect Meter (PAM), a tool for measuring affect in which users select from a wide variety of 
photos the one which best suits their current mood \citep{Pollak2011}. The PAM survey is 
deployed to the mobile app and prompts everyday during the study period. The participants 
either respond to the survey, or ignore it, introducing missingness. The outcome of the survey 
contains two attributes, the PAM valence and the PAM arousal. They are scores of -2 to 2 
(excluding 0) that measure the subject's extent of displeasure to pleasure or state of 
activation ranging from low to high, respectively. We dichotomize the valence and arousal 
scores by their sign, representing the positive values by 1. In this section, we focus on 
analyzing the change of binary valence and arousal responses to evaluate students' affects 
as the term progresses.    

% about the studying period

The data were collected during the spring 2013 term at Dartmouth college. We set the study 
period according to the official academic calendar, from the first day of classes (March 25, 2013) 
to the end of the final exam period (June 4, 2013), resulting in a total of 72 days. We exclude 
subjects with less than 12 responses, resulting in 45 students. The longitudinal recordings of 
valence or arousal of the $i$-th student are denoted by $Y_i(\boldsymbol{\tau}_i)$, for
$i=1,\cdots,45$, where the student-specific grid points are a subset of $\boldsymbol{\tau}=$
$(0,1,\cdots,71)^{\top}$, representing the days on which the measurements are recorded. 
Several special events occurred during the study period, and we are particularly interested 
in investigating the change of students' affects on the time intervals around these events. 
Specifically, the events and corresponding periods are: (i) Days following the Boston marathon 
bombing (April 15, 2013 to April 17, 2013); (ii) The Green Key (a spring festival at Dartmouth) 
period (May 17, 2013 to May 18, 2013); (iii) The Memorial Day long weekend (May 25, 2013 to 
May 27, 2013); (iv) The final examination period (May 31, 2013 to June 3, 2013).       

% summary of EDA result

We retrieve the data for the specific responses and study period from the R package 
``studentlife'' that contains the database for the entire study. Over all observations, 
the percentage of missing values is 31.1\%. There are slightly more missing responses at 
the beginning and toward the end of the study, while the missing pattern for each subject 
can be viewed as random. We further explore the correlations between the binary responses 
within a week. We split the whole observation sequence into batches representing a week, 
and empirically calculate the Pearson and the tetrachoric correlation coefficient for each 
pair of time and distance combinations. Figure \ref{fig:datacorr} presents the results. 
It suggests that the correlation of the students' response to valence and arousal decreases 
slowly in time. 
%
%We use a prior for the range parameter $\rho$ that allows for moderate to large values.
%
%The slowly decreasing correlation provides indirect insight into specifying a prior for 
%$the range parameter $\rho$ that should allow for moderate to large values. 
%

\begin{figure}[t!]
    \centering
    \begin{subfigure}[b]{0.48\textwidth}
            \includegraphics[width=\textwidth,height=5cm]{covdataval.png}
            \caption{{\footnotesize Valence.}}
    \end{subfigure}
    \begin{subfigure}[b]{0.48\textwidth}
            \includegraphics[width=\textwidth,height=5cm]{covdataaro.png}
            \caption{{\footnotesize Arousal.}}
    \end{subfigure}
\caption{\textit{Studentlife} data. Empirical estimate of the correlation coefficients 
between binary responses within a week. In each panel, the upper triangle and the lower 
triangle are for the Pearson and the tetrachoric correlation coefficient, respectively. }
    \label{fig:datacorr}
\end{figure}



\subsection{Analysis and results}
\label{subsec:resultsrealapp}

We fit the proposed model for the binary valence and arousal responses separately. 
We specify the prior for the model parameters by the procedure mentioned in 
Section \ref{subsec:modelapply}. (Results from prior sensitivity analysis are 
presented in the Supplementary Material.) Posterior inference results are based on 
5000 MCMC samples obtained every 4 iterations from a chain of 50000 iterations with 
a 30000 burn-in period (which is conservative). 


We first examine in Figure \ref{fig:realappprobcurve} the probability response curves, 
defined as the probability of obtaining positive valence or arousal as a function of time.
For the valence, the happiness level drops as the term begins and increases when the term 
ends. The Boston marathon bombing may have had a minor effect on the valence. We observe 
local peaks around the Green Key festival and the Memorial Day holiday. As the students 
finish their exams, there is a trend toward happiness. As for arousal, it is relatively 
stable at the beginning of the term, and fluctuates as the term progresses. There is a 
drop in activation level after the Boston marathon bombing and during the final exam 
period, while the activation level reaches a local maximum at around the Green Key 
festival and the Memorial Day holiday. 
%The findings obtained here is reasonable to believe. 
 
\begin{figure}[t!]
\centering
\includegraphics[width=16cm,height=5cm]{ValAroProbCurve.png}
\caption{\textit{Studentlife} data. Posterior mean (dashed line) and 95\% interval estimate 
(shaded region) of the probability response curve for an out-of-sample subject. The posterior 
mean estimates of probability response curves for in-sample subjects are given by the solid 
lines. The vertical shaded regions correspond to the four special time periods 
(see Section \ref{subsec:datarealapp}).}
\label{fig:realappprobcurve}
\end{figure}


Moreover, we assess the student's emotional status on specific days. According to 
\citet{Russell1980}, various states of emotional status can be represented by points 
located at the two dimensional mood coordinate space spanned by valence for the horizontal 
dimension and arousal for the vertical dimension. Moods such as excitement, distress, 
depression, and contentment, are represented by points in the quadrants of the space. 
For each observation, we can map the corresponding pairs of probabilities for positive 
valence and arousal onto the unit square in the mood space. In Figure \ref{fig:densityday}, 
the density heatmap is obtained by the posterior samples of positive probabilities for 
a new student of the same cohort, while the posterior means of the in-sample positive 
probabilities are marked by crosses. Panels (a) and (b) suggest the students are mostly 
excited at the festival and holiday. Moving from panel (c) to panel (d), we observe that 
the happiness level increases and the activation level decreases towards the end of the 
exam period. 
%Note that the plots displayed in Figure \ref{fig:densityday} not only depict 
%the average mood, but also induce the full posterior distribution of the emotional status.  
%\footnote{
%\textcolor{blue}{do we need this last sentence? if it's kept, we should be a bit more
%clear about what we mean by ``full posterior distribution'', the heatmap depicts 
%posterior predictive uncertainty for a new student, right?}
%}


\begin{figure}[t!]
    \centering
    \begin{subfigure}[b]{0.24\textwidth}
            \includegraphics[width=\textwidth,height=4cm]{5-17-2013.png}
            \caption{{\footnotesize Green Key}}
    \end{subfigure}
    \begin{subfigure}[b]{0.24\textwidth}
            \includegraphics[width=\textwidth,height=4cm]{5-27-2013.png}
            \caption{{\footnotesize Memorial Day}}
    \end{subfigure}
    \begin{subfigure}[b]{0.24\textwidth}
            \includegraphics[width=\textwidth,height=4cm]{5-31-2013.png}
            \caption{{\footnotesize Final exams begin}}
    \end{subfigure}
    \begin{subfigure}[b]{0.24\textwidth}
            \includegraphics[width=\textwidth,height=4cm]{6-3-2013.png}
            \caption{{\footnotesize Final exams end}}
    \end{subfigure}
\caption{\textit{Studentlife} data. Posterior density estimate of an out-of-sample 
subject's valence and arousal probability over the mood coordinate space on four 
specific days. In each panel, the crosses represent the posterior means of the 
in-sample subjects' valence and arousal probability mapped to the mood coordinate space.}
    \label{fig:densityday}
\end{figure}


%\begin{figure}[t!]
%    \centering
%    \begin{subfigure}[b]{0.48\textwidth}
%            \includegraphics[width=\textwidth,height=5cm]{valcovpost.png}
%            \caption{{\footnotesize Valence.}}
%    \end{subfigure}
%    \begin{subfigure}[b]{0.48\textwidth}
%            \includegraphics[width=\textwidth,height=5cm]{arocovpost.png}
%            \caption{{\footnotesize Arousal.}}
%    \end{subfigure}
%    \caption{\textit{Studentlife} data. Posterior mean (solid line) and 95\% interval estimate of signal covariance kernel and its eigenfunctions corresponding to the top four largest eigenvalue.}
%    \label{fig:valarocovdecomp}
%\end{figure}

We also obtain the posterior point and 95\% interval estimate for the covariance kernel 
of the signal process, which is displayed in Figure \ref{fig:valarocov}. 
%Despite the responses, the covariance kernel of the signal process decreases in the 
%same pattern. 
It is noteworthy that there is a similar decreasing trend for the two distinct 
binary responses of valence and arousal. The practical range, defined as the distance 
at which the correlation is 0.05, has an estimated mean of 20.99 for valence 
and 22.97 for arousal. 

\begin{figure}[t!]
\centering
\includegraphics[width=16cm,height=4cm]{simplepostcov.png}
\caption{\textit{Studentlife} data. Posterior mean (solid line) and 95\% interval 
estimate of the signal process covariance kernel. }
\label{fig:valarocov}
\end{figure}



\subsection{Performance comparisons}
\label{subsec:comparerealapp}

For comparison with a traditional approach, we consider an analysis of the data under
the GLMM setting. In particular, we assume the model
\begin{equation*}
	%\begin{split}
		%&Y_{i}(\tau_{it})\mid Z_{i}(\tau_{it}) \stackrel{ind.}{\sim} Bern(\varphi(Z_{it})), \quad t=1,\cdots,T_i, \quad i=1,\cdots, n,\\
		%&Z_{it}=\tilde{\boldsymbol{\tau}}_{it}^{\top}\boldsymbol{\beta}+\sum_{k=1}^KS_{itk}b_{k}+\mu_i+\epsilon_{it},
		Y_{it}\mid \mathcal{Z}_{it} \stackrel{ind.}{\sim} Bin(1,\varphi(\mathcal{Z}_{it})), \,\,
		\mathcal{Z}_{it}=\tilde{\boldsymbol{\tau}}_{it}^{\top}\boldsymbol{\beta}+\sum_{k=1}^KS_{itk}b_{k}+\mu_i+\epsilon_{it},\,\, 
		t=1,\cdots,T_i, \,\, i=1,\cdots, n,
	%\end{split}
\end{equation*}  
where $\tilde{\boldsymbol{\tau}}_{it}=(1,\tau_{it})^{\top}$, $\boldsymbol{\beta}$ is the 
vector of fixed effects, and $\epsilon_{it}\stackrel{i.i.d.}{\sim}N(0,\sigma^2_{\epsilon})$ 
is the measurement error. To allow flexibility in modeling the time effect, we consider 
cubic B-spline basis functions with $K=9$ knots that separate naturally the observed interval
by week; $S_{itk}$ is the $k$-th basis associated with time, with parameter 
$b_k\stackrel{i.i.d.}{\sim}N(0,\sigma^2_b)$. Finally, $\mu_i\stackrel{i.i.d.}{\sim}N(0,\sigma_{\mu}^2)$ 
are subject-specific random effects. The model is implemented using the integrated nested Laplace 
approximation (INLA) approach \citep{Rue2009} with the ``INLA'' package in R \citep{Rue2017}. 
We used the default choices provided by the R package for the prior on $\boldsymbol{\beta}$
(a flat prior), and for the values of the variance terms, $\sigma^2_{\epsilon}$, $\sigma^2_{b}$, 
and $\sigma^2_{\mu}$.


%We perform model comparison using three different metrics: the posterior predictive loss 
%criterion which combines a goodness-of-fit term, $G(\mathcal{M})$, and a penalty term, 
%$P(\mathcal{M})$, for model complexity \citep{GelfandGhosh1998}; the continuous ranked 
%probability score (CRPS), defined in terms of predictive cumulative distribution 
%functions \citep{Gneiting2007}; and, the log pseudo-marginal likelihood (LPML) criterion,
%defined through the conditional predictive ordinate (CPO), i.e., the predictive density 
%of one observation based on all the data except itself \citep{GelfandDey1994}. 
%\footnote{
%\textcolor{blue}{how did you compute the LPML criterion, by removing the entire data 
%vector for each subject? and did you use any tricks to avoid refitting the model? if so,
%are you sure the results are stable? anyway, it may be a bit cheating, but things would 
%look much better for us overall if we were to skip the LPML numbers; BTW, we should include 
%an extra column for the GG criterion with the sum of G(M) and P(M)}
%}


\begin{table}[t!] \centering
\small
\caption{\textit{Studentlife} data. Summary of comparison between the proposed model 
and the generalized linear mixed effects model using two different criteria. The values 
in bold correspond to the model favored by the particular criterion.} 
\label{tab:comprealapp}
\begin{tabular}{cccccc}
\hline
\hline
\multirow{2}{*}{Response} & \multirow{2}{*}{Model} & \multicolumn{3}{c}{Posterior predictive loss} & \multirow{2}{*}{CRPS} \\
\cline{3-5} & & $G(\mathcal{M})$ & $P(\mathcal{M})$ & $G(\mathcal{M})+P(\mathcal{M})$ & \\
\hline
\hline
\multirow{2}{*}{Valence} & Proposed & \textbf{428.09} & \textbf{475.31} & \textbf{903.40} & \textbf{0.19}\\
& GLMM & 456.09 & 475.83 & 931.92 & 0.20 \\
\hline
\multirow{2}{*}{Arousal} & Proposed & \textbf{457.62} & 496.63 & \textbf{954.25} & \textbf{0.20}\\
& GLMM & 476.17 & \textbf{492.28} & 968.45 & 0.21 \\
\hline
\hline
\end{tabular}
\end{table}


We perform model comparison using two different metrics: the posterior predictive loss 
criterion which combines a goodness-of-fit term, $G(\mathcal{M})$, and a penalty term, 
$P(\mathcal{M})$, for model complexity \citep{GelfandGhosh1998}; and, the continuous 
ranked probability score (CRPS), defined in terms of predictive cumulative distribution 
functions \citep{Gneiting2007}. Both criteria can be calculated from the posterior samples 
for model parameters, and both favor the model with a smaller value.        
Table \ref{tab:comprealapp} summarizes the results. For the 
valence response, both criteria favor the proposed model. As for the arousal response, 
the proposed model provides a more accurate fit to the data, while being penalized more 
than the GLMM with respect to model complexity. Nonetheless, our model is favored in terms 
of total posterior predictive loss, as well as by the CRPS criterion.
%It is favored under the first two criteria that are based on the posterior 
%predictive samples, while it is borderline outperformed by the GLMM under the LPML criterion. 
%In general, our model provides improvement over the GLMM approach. 




%Table \ref{tab:comprealapp} shows the performance metrics of the two models. When considering valence, all three criteria favor the proposed model. As for arousal, the proposed model provides a more accurate fit to the data, while sacrificing a little in model complexity. It is favored under the first two criteria that are based on the posterior predictive samples, while it is borderline outperformed by the GLMM
%under the LPML criterion. In general, our model provides improvement over the GLMM approach. 


%\begin{table}[t!] \centering
%\small
%\caption{\textit{Studentlife} data. Summary of comparison between the proposed model 
%and the generalized linear mixed effects model using different criteria. The values 
%in bold correspond to the model favored by the particular criterion.} 
%\label{tab:comprealapp}
%\begin{tabular}{cccccc}
%\hline
%\hline
%\multirow{2}{*}{Response} & \multirow{2}{*}{Model} & \multicolumn{2}{c}{Posterior predictive loss} & \multirow{2}{*}{CRPS} & \multirow{2}{*}{LPML} \\
%\cline{3-4} & & $G(\mathcal{M})$ & $P(\mathcal{M})$ & & \\
%\hline
%\hline
%\multirow{2}{*}{Valence} & Proposed & \textbf{428.09} & \textbf{475.31} & \textbf{0.19} & \textbf{-1370.35}\\
%& GLMM & 456.09 & 475.83 & 0.20 & -1374.06 \\
%\hline
%\multirow{2}{*}{Arousal} & Proposed & \textbf{457.62} & 496.63 & \textbf{0.20} & -1441.39\\
%& GLMM & 476.17 & \textbf{492.28} & 0.21 & \textbf{-1411.47} \\
%\hline
%\hline
%\end{tabular}
%\end{table}




\section{Discussion and Research Roadmap}~\label{sec:Discussion}
From the analysis of our selected primary studies on MDE for ML, we present several interesting insights and recommendations for future research.
\subsection{MDE solutions for ML}
\subsubsection{Data for ML}
ML is a data-driven technique~\cite{braun2018open}, but most studies focus on other aspects instead. We found a surprisingly small number of studies related to data generation, pre-processing, storage, and visualization. Studies often assume that data has been pre-processed and is ready to use, whereas in reality, cleaning, wrangling, and transforming raw data is a tedious and time-consuming process~\cite{duong2021review}. Hence, the MDE techniques should consider the cases where real data is unavailable or insufficient and make data processing a part of the MDE solution.
%Data visualization can be helpful in uncovering insights, supporting decision-making, and communicating data-driven narratives effectively. 
We also identified six studies (P3, P19, P29, P31, P41, and P43) that do not consider the training data or training process in their MDE solutions for ML.

We recommend researchers consider data as a first-class citizen when devising MDE solutions for ML-based systems. MDE can be particularly useful for generating data or simulators from models ~\cite{jahic2023semkis}, creating meaningful visualizations ~\cite{barzdins2022metamodel}, modeling data pre-processing workflows, and generating code to prepare data for training ~\cite{bhattacharjee2019stratum, ries2021mde}. 

\subsubsection{Expressiveness of Models}
A key issue we identified in a few studies (P17, P20, and P21) was that ML concepts were not adequately expressed in models. For example, P17 and P21 rely on probabilistic graphical models (PGMs) to represent ML models and software models~\cite{moin2022model}. However, PGMs are not expressive enough~\cite{moin2022model} to sufficiently represent complex functions, software structures, and connections between ML components and traditional software components.   

We suggest researchers interested in using PGMs for MDE use them with software models to comprehensively capture both the statistical and software aspects of ML components and systems. 

\subsubsection{Solution Focus}

\sectopic{Development Aspect.} One of our major findings from this study was the high volume of MDE solutions for the design, development, and training of ML components. This narrow solution focus leads to the issue of many other important development aspects for ML being neglected, such as requirements engineering and integration. Requirements engineering for ML and integration of ML components with traditional software components is particularly challenging~\cite{ahmad2023requirements, atouani2021artifact} due to the inherent under-specification of ML~\cite{d2022underspecification} and the unique differences between ML components and traditional software components~\cite{atouani2021artifact,kusmenko2019modeling}. However, we only found five papers focusing on requirements engineering and four on integration. Furthermore, we found a lack of MDE solutions for ML pipelines~\cite{raedler2023model}, automated deployment, and monitoring of ML components, also known as MLOps. Despite the importance of runtime monitoring for early detection of unwanted behavior~\cite{nigenda2022amazon}, we only found two papers relevant to this. Another key area that has not received enough attention is documentation~\cite{giner2023domain}; documentation of datasets, ML models, training parameters, deployment configurations, and ML pipelines is extremely important for maintenance, reusability, and scalability. 

We recommend that researchers broaden the focus of their studies and leverage MDE capabilities to address the challenges in requirements engineering, integration, deployment, monitoring, and documentation of ML components. MDE can be beneficial in several ways, such as DSLs to support requirements engineering for ML, automated generation of runtime monitors from models, and models to automate and ease integration.

\sectopic{Machine Learning Type.} We identified a large fraction of studies focused on supervised and deep learning, while unsupervised and reinforcement learning were not as widely covered in the literature. Unsupervised learning is a powerful technique to identify hidden patterns in large unlabeled datasets. To this end, we did not find any paper providing an MDE solution focusing solely on unsupervised learning. Reinforcement learning has strengths in learning from experience, sequential decision-making, and handling complex state spaces, which are highly useful in robotics, personalized learning, and gaming. Only four studies proposed MDE solutions for reinforcement learning. 

We recommend researchers should explore developing MDE solutions that cater to unsupervised and reinforcement learning. Given the wealth of unlabeled data in various domains, MDE tools for unsupervised learning could pave the way for more efficient data analysis and knowledge extraction.
Similarly, reinforcement learning, with its expansive applications, presents a significant potential for applying MDE.

\sectopic{Model-driven Engineering Details.} We found a lack of MDE details in studies published in ML venues. These studies were focused on textual DSLs for specifying ML operations and transforming them into high-performance code for various hardware platforms like CPUs and GPUs. For instance, P41 provides a textual DSL for ML, and the model is automatically converted into optimized CUDA code for GPUs. Other similar studies include P40, P42, P43, P44 and P46. Although there are significant mathematical details about ML in these studies, the explanation of MDE aspects, such as the meta-models and transformations, is often overlooked. Additionally, we also found some studies in the MDE domain that lacked MDE details, such as studies P15, P18, P19, P24, P26, P29, P32, and P38.
 
We recommend authors, when specifying MDE approaches, add some level of detail with regard to the MDE steps taken in their solution. This would allow researchers and practitioners from the SE and MDE domains to better understand and apply these solutions.

\subsubsection{Solution Maturity}
Most reported MDE solutions for ML in our selected primary studies are still in their early stages, e.g., based on simple cases, and do not support an end-to-end ML lifecycle. This is not surprising since active research in the area dates only to a few years back (e.g., in our 46 primary studies, the earliest paper is from 2008, but 39/46 papers are from 2018 and later). Upon examination of the literature, we found that tools are available for 23 studies. Out of these, only 17 studies provided open-source tools. Some notable ones are P2, P10, P22, and P23. Moreover, existing solutions often overlook complex scenarios and focus only on simple models, for example, P3, P6, P15, and P26. Our analysis also revealed that manual configurations are required for the artifacts generated by ten studies (P3, P14, P19, P20, P22, P24, P35, P36, P39, and P45). The lack of available tool support, automation, and consideration of complex scenarios hinders the adoption, extension and reproducibility of MDE solutions for ML. %Future researchers are unable to reproduce results from the study and compare them with their own. 

We suggest researchers and practitioners further develop their solutions to consider the entire ML lifecycle and develop research prototypes that cater to end users. In the interest of lowering costs, fostering collaboration, and creating more opportunities for innovation, we recommend researchers to open-source their solutions, data and tools. Open-source software hosting platforms like GitHub, Zenodo, SourceForge, and Gitlab can be leveraged. Accessible and mature solutions are also more likely to be adopted in the industry. 

\subsubsection{MDE Solutions for Domain Experts}
While there were a substantial number of studies providing MDE solutions for ML engineers and software engineers, we found a lack of solutions for domain experts. With the rise of new trends like \textit{no code} and \textit{low code}~\cite{cabot2020positioning}, the complexity of developing ML-based systems can be significantly reduced for domain experts. No code and low code approaches allow users (mostly domain experts) to develop and deploy applications without writing much code~\cite{cabot2020positioning}. Additionally, ML experts, engineers, and analysts can also benefit from such low-code platforms.

We recommend researchers and practitioners develop low-code platforms for systems with ML components so that non-ML experts can benefit from the capabilities of ML. Low code platforms can significantly reduce development complexity and time to deployment.

\subsubsection{Machine Learning Algorithms and Terminology}
We came across varied ML terminology and granularity levels used in studies to describe ML. For instance, P9 and P32 mention at a very high level that their MDE solution is for ML, but studies like P8 and P30 are more specific and specify the exact nature of ML techniques, e.g., neural networks and reinforcement learning. The inconsistent terminologies made it challenging to analyze studies and draw conclusions. This issue was further exacerbated when studies did not explicitly mention the supported ML algorithms; these include P12, P24, P25, P27, P35, P38, and P40. 

We encourage the MDE community to build a consensus on the terminology used for devising ML-based solutions to facilitate understanding and comparisons with other studies. We further highlight the need for clearly specifying the details of the ML algorithms supported in the study.


\begin{figure}[htbp]
    \centering
    \begin{subfigure}{0.3\textwidth}
    \includegraphics[width=\textwidth]{Images/RQ4/scalability.png}
    \caption{Scalability Support in Studies}
    \label{fig:scalabilityLimits}
    \vspace{-0.8ex}

    \end{subfigure}
\hfill
    \begin{subfigure}{0.3\textwidth}
    \centering
    \includegraphics[width=\textwidth]{Images/RQ4/humanAspects.png}
    \caption{Responsible ML in Studies}
    \label{fig:responsibleLimits}
    \vspace{-0.3ex}
\end{subfigure}
\hfill
    \begin{subfigure}{0.3\textwidth}
    \centering
    \includegraphics[width=\textwidth]{Images/RQ4/evalLimits.png}
    \caption{Evaluation in Studies}
    \label{fig:evalLimits}
\end{subfigure}
\caption{Gaps Identified in Studies}
\end{figure}



\subsubsection{Solution Scalability}
Scalability in MDE is a well-known challenge~\cite{bucchiarone2020grand, kolovos2013research}. Little to no focus is placed on scalability in the selected studies on MDE for ML. As shown in Figure \ref{fig:scalabilityLimits}, almost 75\% of the studies (P1-P8, P10-P12, P15, P17, P18, P20-P22, P24-P29, P31, P32, P34-P36, P38, P40, P42, P43, P45, and
P46) do not discuss the scalability of their solution. One possible reason behind this could be 
that often, the primary goal is to develop a proof of concept, leading to the development of basic MDE tools that only work for simple projects. Scalability is often an afterthought in such solutions, rendering them of little or no practical use.

We recommend researchers consider the importance of scalability in MDE solutions and report their scalability results to facilitate practical adoption and comparison. %Additionally, we propose that researchers and tool developers develop their solutions and tools with scalability as a priority from the start. Without the ability to be scaled to larger projects, the wider adoption of MDE is not possible. 

\subsubsection{Responsible ML}
Responsible use of ML refers to applying ML to maximize the benefits for the end users and society while minimizing harm. This consists of developing and managing ML components prioritising human-centric needs such as fairness, trust, safety, explainability, privacy, and human values~\cite{zhu2022ai}. Despite the growing awareness of responsible ML, only nine of the selected primary studies (P2, P3, P7, P10, P27, P31, P33, P35, and P45) out of the total 46 considered human-centric aspects and/or the responsible use of ML in their MDE solutions as shown in Figure \ref{fig:responsibleLimits}. This is concerning since neglecting these critical human-centric requirements can have serious consequences, such as ML-based systems that are not trustworthy, biased, and violate ethical principles and legal policies~\cite{zhu2022ai}.

We suggest researchers prioritize the responsible applications of ML in their MDE solutions. As a result, the ML artifacts generated will better meet the needs of end-users and foster trust~\cite{zhu2022ai}. Some potential MDE approaches to achieve this include DSLs tailored for modeling human-centric requirements in ML components. These automated code generators of ML components conform to responsible ML practices and runtime monitoring for responsible ML. 

\subsection{Evaluations of MDE solutions for ML}
Figure \ref{fig:evalLimits} shows various limitations related to evaluation found in the selected primary studies.
\subsubsection{Real-world Evaluation}
Real-world evaluations in an industrial context demonstrate the usefulness of MDE solutions in the industry. Such evaluations also impact the likelihood of research being applied to the industry. Yet, only five of the selected studies (P12, P15, P31, P33, P35) perform an industrial evaluation. User studies (or surveys) are another useful method for evaluating the practical usability of the approach with actual end users. However, we found only four studies (P10, P22, P24, P35) with user study as an evaluation method.

We encourage researchers to evaluate their proposed MDE solutions on industrial case studies and with real-world users to get realistic results and feedback. More value can be added to user studies by evaluating with diverse groups of users representing a wide range of demographics and perspectives. We realize this may not always be possible, but it remains an ideal goal to strive in order to achieve a more comprehensive and inclusive evaluation.

\subsubsection{Evaluation Rigor}
 
One of the recurring issues we observed in studies was the lack of rigor in evaluation. For instance, eight studies (P5, P6, P8, P18, P21, P26, P32, and P43) did not report on any evaluation, 22 studies performed a partial evaluation (i.e., focused on either MDE or ML but not both), 14 studies (P7, P14, P15, P20, P29, P36-P42, P45, P46) had insufficient evaluation details, no clear rationale behind the evaluation settings (e.g., the choice of evaluation metrics and parameters selection) or provided only limited discussion on the implication of results. In studies P14, P15, P20, P24, P29, P30, P33, P35, and P40, there is no evaluation of the ML aspect. A greater number of studies P1, P3, P7, P9, P11, P13, P22, P23, P27, P34, P39, P42, and P46, provide no evaluation of the MDE aspect. These limitations impact the quality of the resulting evaluation and the ability to draw meaningful and reliable conclusions from the results.

%For example, non-empirical evaluations (e.g., P28, P32), partial evaluations focusing on MDE or ML but not both (e.g., P1, P20, P29), insufficient evaluation details (e.g., P29, P36, 37), lack of a clear rationale behind evaluation metrics and parameters selection (e.g., P7, 38), and limited discussion of results implications (e.g., P7, P29). These limitations reduce the quality of the evaluation and the ability to draw meaningful and reliable conclusions from the results.

We propose researchers perform and report empirical evaluations with respect to both aspects of MDE and ML. Clearly justify their choices of evaluation methods and metrics and provide comprehensive details of the result, based on the guidelines for reporting empirical software engineering research (e.g., ~\cite{runeson2009guidelines,ralph2020empirical}). Rigorous evaluation methods increase the credibility of research findings, making them more trustworthy for academia and industrial applications.

% \subsection{Limitations and Challenges of MDE}
% Although the benefits of MDE have been discussed throughout this study, it is important to mention that MDE also has certain limitations and challenges; it is not a silver bullet for all SE problems~\cite{brambilla2017model}. We describe these limitations and challenges ahead.

% One of the challenges in MDE is finding the appropriate level of abstraction for the problem at hand. Since modeling is a reductionist activity, it can eliminate critical details and oversimplify problems ~\cite{steimann2005coding}. Whereas, adding too many details in models can make them overly complex ~\cite{steimann2005coding}. There is also no way to guarantee that the high level of abstraction offered in models will improve the software. In some cases, people find abstractions more difficult to understand compared to concrete implementations or examples ~\cite{hutchinson2011model}. The success of MDE depends significantly on the context in which it is being applied, there must also be a well-justified rationale for adopting MDE ~\cite{hutchinson2011model}.

%  Automated artifact generation is known to overall improve productivity but the effort required to develop models and transformers and then configure the generated artifacts can decrease productivity ~\cite{hutchinson2011model}. The learning curve involved in familiarizing development teams with MDE tools and techniques can also be an overhead. MDE users can benefit from finding the right balance between long-term productivity increase and short-term decrease ~\cite{hutchinson2011model}. Furthermore, DSLs and tools can be developed for different stakeholders to ease understanding and encourage adoption ~\cite{bucchiarone2020grand}.
 
% Another prominent challenge when applying MDE is the lack of good tool support ~\cite{bucchiarone2020grand}. There are few tools available for model transformation languages while several are available for modeling, however, most of them are not mature, lack debugging methods, are difficult to use in reality, and are difficult to scale ~\cite{bucchiarone2020grand}. Scalability for MDE, in general, is one of the main challenges ~\cite{kolovos2013research}, scalable modeling languages, transformations, tools, model management methods, and diverse artifact generation are all areas that require further attention ~\cite{bucchiarone2020grand}. These challenges hinder the adoption of MDE, especially for development phases like requirements engineering, integration, and deployment. There is a need for more mature solutions, modeling languages, and advanced tools to leverage the full capabilities of MDE.




\label{sec:introduction}
%\outline{Par. 1: It is the memory, stupid! What happened to memory in recent years? What are the costs of having slow and expensive to access memory?}

\revdel{DRAM-based main memory is used in nearly all computing systems as a major component. The growing memory footprints and working-sets of modern workloads require main memory to satisfy three properties. \new{Main memory needs to be} (i) \emph{fast}, so that memory accesses induce small latency costs \juan{and applications can enjoy high memory bandwidth}, (ii) \emph{dense}, so that working-sets of workloads fit into the memory device and \juan{do} not need to be \juan{frequently} brought from \juan{secondary} storage, and (iii) \emph{low-power}, to lower energy consumption, prevent devices from overheating, and increase battery life in mobile computing systems. %~\cite{X,Y,Z}. 
%\jgl{This is our wish list, but it is not necessarily what DRAM provides: over time, it has been improved for higher capacity, while latency reduced minimally.}. 
Unfortunately, %recent attempts at developing memory devices that can continuously scale in all three properties \juan{have} not succeeded~\cite{mutlu2020modern} \jgl{What are these works? The way it is written it sounds like Industry attempts of increasing capacity, increasing bandwidth and reducing latency at once, which would have failed. I'm not aware of such attempts.} \todo{Cite from Onur's recent PIM primer}, and 
the trends in memory technology development show that it is especially difficult to scale existing memory devices in all three dimensions~\cite{mutlu2020modern}. 
\juan{In this context, DRAM vendors have prioritized memory capacity scaling over latency and bandwidth~\cite{chang.sigmetrics16,lee.hpca13}}. 
As a result, Memory performance improvements have been lagging behind processor performance improvements in recent years and m}Main memory \newnew{is a major performance and energy} bottleneck in computing systems~\cite{mutlu2020modern,ghose2019processing}.
%
%\outline{Par. 2: How can PIM help with the "main memory bottleneck"?}
%
One way of overcoming the main memory bottleneck is to move computation into/near memory, \juan{a paradigm known as \emph{processing-in-memory} (PiM)~\cite{mutlu2020modern}}. %Moving computation into/near where the data resides 
\juan{PiM} reduces memory latency between the %computation device and the memory device~\cite{X,Y,Z}
\juan{memory units and the compute units}, enables the %computation device 
\juan{compute units} to \atb{exploit the large internal bandwidth within} memory devices,  
%\jgl{Not sure "interfaces" is the right word. Better to say "PIM can exploit the large internal bandwidth".} 
and reduces the overall power consumption of the system by eliminating the need for transferring data over power-hungry off-chip interfaces~\cite{mutlu2020modern,ghose2019processing}.

Recent works propose a variety of \juan{PiM} techniques to alleviate the data movement problem. % by enabling computation near
\Copy{R4/4}{\juan{One {set} of techniques propose to place compute {logic} \emph{near} memory arrays {(e.g., processing capability in the memory controller{, logic layer of 3D-stacked memory,} or {near} the memory array within the memory chip)} }~\cite{fernandez2020natsa,cali2020genasm,kim.bmc18,ahn.pei.isca15,ahn.tesseract.isca15,boroumand.asplos18,boroumand2019conda,boroumand2016pim,singh2019napel,asghari-moghaddam.micro16,JAFAR,farmahini2015nda,gao.pact15,DBLP:conf/hpca/GaoK16,gu.isca16,hashemi.isca16,cont-runahead,hsieh.isca16,kim.isca16,kim.sc17,liu-spaa17,morad.taco15,nai2017graphpim,pattnaik.pact16,pugsley2014ndc,zhang.hpdc14,zhu2013accelerating,DBLP:conf/isca/AkinFH15,gao2017tetris,drumond2017mondrian,dai2018graphh,zhang2018graphp,huang2020heterogeneous,zhuo2019graphq,syncron}. 
\juan{These techniques are called \emph{processing-near-memory} (PnM)} \new{techniques}~\cite{mutlu2020modern}.
%\atb{(PnM)} or using
\juan{Another {set of techniques} propose to leverage analog properties of memory {(e.g., SRAM, DRAM, and NVM)} operation to perform computation in different ways {(e.g., leveraging non-deterministic behavior in memory array operation to generate random numbers, performing bitwise operations within the memory array by exploiting analog charge sharing properties of DRAM operation) }\Copy{R4/1}{~\cite{aga.hpca17,eckert2018neural,fujiki2019duality,kang.icassp14,chang.hpca16,seshadri.micro17,seshadri2013rowclone,angizi2019graphide,li.dac16,angizi2018pima,angizi2018cmp,angizi2019dna,levy.microelec14,kvatinsky.tcasii14,shafiee2016isaac,kvatinsky.iccd11,kvatinsky.tvlsi14,gaillardon2016plim,bhattacharjee2017revamp,hamdioui2015memristor,xie2015fast,hamdioui2017myth,yu2018memristive,rezaei2020nom,wang2020figaro,mandelman.ibmjrd02,xin2020elp2im,gao2020computedram,li.micro17,deng.dac2018,kim.hpca18,kim.hpca19,hajinazarsimdram,ali2019memory,ronen2022bitlet,zha2019liquid,testa2016inversion,borghetti2010memristive,intel-loihi,geoffrey2017neuromorphic}.} %\atb{(PuM)} memory. \jgl{I put a bunch of references. We may not need so many.}
\juan{These techniques are known as \emph{processing-using-memory} (PuM)} \new{techniques}~\cite{mutlu2020modern}.}}
%\jgl{I prefer the PnM-PuM classification for a start. Or we can be more specific: in the logic layer (HMC-based proposals), near-bank (UPMEM, FIMDRAM, Fulcrum, etc.), and using/in-situ.}

%\outline{\textcolor{red}{CRITICAL PARAGRAPH} Par. 3: What is in-DRAM processing? Why is in-DRAM processing important to study? How can in-DRAM processing be studied today? Why are existing simulation/evaluation platforms not sufficient? These motivate the need for a real platform that enables end-to-end exploration of in-DRAM processing methods.}
%\jgl{I'm not sure these are the right questions. The key question is: What do we need to enable in-DRAM processing? What are the challenges? E.g., enhanced MC, data allocation, alignment, coherence...
%Btw, "in-DRAM" is a bit undefined (near-bank is also in-DRAM). For now, we are doing "using-DRAM". However, I believe that your platform could also support something like UPMEM or FIMDRAM. It may be good to discuss about this.}

%\jgl{After enumerating the challenges, we have to explain why the solution to them cannot be found in a conventional processor or an existing characterization platform like SoftMC. Then, we can present our platform. Later (\atbc{Leaving this to following paragraphs}), we can say that we are already using our platform for some PuM techniques that have been shown feasible in off-the-shelf DRAM. However, I believe that we should not talk about these feasible techniques as our end -- your platform will also support future DRAM chips that implement, for example, FIGARO or RowClone PSM.} 


A subset of PuM proposals devise mechanisms that enable computation using DRAM arrays~\cite{seshadri.micro17,seshadri2013rowclone,angizi2019graphide,kim.hpca18,kim.hpca19,gao2020computedram,chang.hpca16,xin2020elp2im,li.micro17,deng.dac2018,hajinazarsimdram,rezaei2020nom,wang2020figaro,ali2019memory}. 
%These mechanisms provide significant improvements in system performance, by exploiting the high bit-level parallelism in DRAM row activation, and energy efficiency, by eliminating the need for data transfer over the off-chip interface. 
\juan{These mechanisms provide significant performance benefits and energy savings by exploiting the high internal bit-level parallelism of DRAM for (1) {bulk data} copy and initialization operations {\newnew{at row} granularity}~\cite{seshadri2013rowclone,chang.hpca16,rezaei2020nom,wang2020figaro,aga.hpca17}, (2) bitwise operations~\cite{seshadri.micro17,xin2020elp2im,li.dac16,angizi2018pima,Seshadri:2015:ANDOR,seshadri.arxiv16,seshadri.bookchapter17.arxiv,seshadri.thesis16,li.micro17,mandelman.ibmjrd02,angizi2018cmp,angizi2019dna}, (3) arithmetic operations~\cite{levy.microelec14,kvatinsky.tcasii14,aga.hpca17,kang.icassp14,li.micro17,shafiee2016isaac,eckert2018neural,fujiki2019duality,kvatinsky.iccd11,kvatinsky.tvlsi14,gaillardon2016plim,bhattacharjee2017revamp,hamdioui2015memristor,xie2015fast,hamdioui2017myth,yu2018memristive,deng.dac2018,angizi2019graphide}, and (4) security primitives (e.g., true random number generation~\cite{kim.hpca19}, physical unclonable functions~\cite{kim.hpca18,orosa2021codic})}. 
Recent works~\cite{gao2020computedram,kim.hpca19,kim.hpca18} show that \juan{some} of these PuM mechanisms \juan{can already be} reliably supported in contemporary, \juan{off-the-shelf} DRAM chips.\footnote{{We are especially interested in PiM techniques that do \emph{not} require {any} modification to the DRAM chips or the DRAM interface.}} 
Given that DRAM is \newnew{the} %major component in nearly all computing systems
\juan{dominant \newnew{main} memory technology}, these {commodity DRAM based} PuM techniques\footnote{{Commodity DRAM based PuM techniques are PuM techniques that can already be supported in existing off-the-shelf DRAM chips with\newnew{out \emph{any}} modification to \newnew{DRAM chips or DRAM interfaces}.}} provide a promising way to improve the performance and energy efficiency of existing and future systems at \emph{no additional \juan{DRAM} hardware cost}. 


%The challenges in implementing PuM mechanisms in real systems \behzadC{can we give a shortlist here? like ", e.g., coherency, ...} have not been explored and the benefits that can be provided by end-to-end implementations of these mechanisms are unclear. 
\juan{Integration of these PuM mechanisms in a real system imposes non-trivial challenges that require further research to find appropriate solutions.}
%\atb{For example, it is clear from a plethora of prior work~\cite{seshadri.micro17,seshadri2013rowclone}} that processing using DRAM techniques require modifications to memory management as they impose data allocation and alignment requirements, which are \textbf{not} satisfied by current memory management primitives (e.g., malloc, posix\_memalign), require efficient coherency mechanisms to keep DRAM data which is being operated on up-to-date~\cite{boroumand2019conda,boroumand2016pim,hsieh.isca16,nai2017graphpim}.
\juan{For example, in-DRAM {bulk data} copy and initialization \newnew{techniques}~\cite{seshadri.micro17,chang.hpca16} require modifications \newnew{to} memory management that affect different parts of the system. 
First, these \newnew{techniques} have specific memory allocation and alignment requirements ({e.g., page-granularity} source and destination operand arrays \newnew{should be} allocated and aligned in the same DRAM subarray) that are \emph{not} satisfied by existing memory allocation primitives {(e.g., \texttt{malloc}~\cite{malloc}, \texttt{posix\_memalign}~\cite{posixmemalign})}. 
Second, in-DRAM copy requires efficient handling of memory coherence, such that the contents of the source operand in DRAM are up-to-date}.
\revdel{\juan{Another example of an integration challenge is the need for bit transposition of in-DRAM computation mechanisms~\cite{hajinazarsimdram,ali2019memory,angizi2019graphide} that employ vertical data layout.}}
%\behzadC{REPLACE: "To conduct a study in order" with "Hence,"} to explore the challenges and analyze the trade-offs in implementing support for current and future PuM techniques in real systems, we require a flexible framework that implements a \emph{\behzadC{ADD: "holistic"?} computing system} and utilizes \emph{real} DRAM chips as main memory.

%Unfortunately, existing special-purpose DRAM testing platforms~\cite{X,Y,Z} do not implement a computing system, which eliminates the possibility of implementing PuDRAM techniques end-to-end on these platforms, and existing system simulators~\cite{X,Y,Z} are unable to interface with real DRAM chips that work under varying environmental (e.g. temperature, voltage) conditions, which makes observing the environmental effects on the behavior of in-DRAM computation mechanisms difficult on such platforms.

% Note to self, WE REQUIRE A TESTBED THAT CAN BOTH RUN SYSTEM AND CAN BE USED TO OBSERVE REAL-LIFE (TEMPERATURE, VOLTAGE...) EFFECTS ON DRAM DEVICES AND PIM MECHANISM'S BEHAVIOR THIS IS IMPORTANTTTTTTTTT.

%\outline{Reiterate on the problem: Why is it important to study E2E in-DRAM computation implementations on a "real" platform? What are the limitations of existing platforms? What is our \textbf{goal}? To this end, we develop PiDRAM, ...}

\juan{None of these system integration challenges of PuM mechanisms can be {efficiently} studied in existing {general-purpose} computing systems {(e.g., personal computers, cloud computers, embedded systems)}, special-purpose testing platforms {(e.g., SoftMC~\cite{hassan2017softmc})}, or system simulators {(e.g., gem5~\cite{gem5-gpu,GEM5}, Ramulator~\cite{ramulator.github,ramulator}, {Ramulator-PIM~\cite{ramulator-pim},} zsim~\cite{zsim}, \newnew{DAMOVSim~\cite{geraldodamov,oliveira2021damov}}, \new{\newnew{and} other simulators~\cite{zhang2022pim,forlin2022sim2pim,yu2021multipim,xu2019pimsim})}}.} %cannot be used to evaluate end-to-end implementations of \atb{PuM} mechanisms for two reasons. 
\atb{First, many {commodity DRAM based} PuM mechanisms in DRAM rely on non-standard DDRx operation, where timing parameters for DDRx commands} \juan{are violated~\cite{gao2020computedram,kim.hpca18,kim.hpca19}} {(or otherwise new DRAM commands are added, which requires new chip designs and interfaces)}. 
{Existing general-purpose} computing systems do \emph{not} permit dynamically changing DDRx timing parameters, which is required to integrate \juan{these PuM mechanisms} into real systems. 
Second, prior works show that the reliability of {commodity DRAM based} PuM mechanisms is highly dependent on environmental \atb{conditions} such as temperature and voltage fluctuations~\cite{kim.hpca18,kim.hpca19} \newnew{and process variation}. These effects are exacerbated by the non-standard behavior of \atb{PuM} mechanisms in real DRAM devices. 
Although \newnew{special-purpose} testing platforms {(e.g., SoftMC~\cite{hassan2017softmc})} can be used to conduct \juan{reliability studies}, these platforms do \emph{not} model \juan{an end-to-end} computing system, \juan{where system integration of PuM mechanisms can be studied.} %which makes studying end-to-end implementations of \atb{PuM} mechanisms difficult. 
System simulators {\newnew{(e.g., those aforementioned)}} can model \juan{end-to-end computing systems}. However, %end-to-end implementations of \atb{PuM} mechanisms on such simulators must follow an in-depth 
\juan{they \atb{(i) do \emph{not} model DRAM operation \newnew{that violates} manufacturer-recommended timing \newnew{parameters}, (ii) do \emph{not} have {a way of interfacing with real DRAM chips that {embody undisclosed and unique} characteristics {that ha{ve} implications on how PuM techniques are integrated into real systems} (e.g., {proprietary and chip-specific} DRAM internal address mapping~\cite{cojocar2020susceptible,salp,patel2022case}),} and (iii)} \emph{cannot} support characterization studies} on the reliability \juan{of} \atb{PuM} mechanisms %as its clear from prior work that the reliability of these mechanisms depends heavily on environmental conditions which are not taken into account by system simulators~\cite{X,Y,Z}. 
\juan{since system simulators do not model environmental conditions \newnew{and process variation}.}

%\jgl{Our goal is to design and implement a flexible platform that can be used to solve system integration challenges, analyze trade-offs of end-to-end implementations, compare different approaches to solving the integration challenges...}

\juan{Our goal is to design and implement a flexible \newnew{real-system} platform that can be used to solve system integration challenges and analyze trade-offs of end-to-end implementations of {commodity DRAM based} PuM mechanisms. To this end, we develop \emph{\textbf{P}rocessing-\textbf{i}n-\textbf{DRAM}} (\X) framework, \atb{the first flexible, end-to-end, and open source framework that enables system integration studies and evaluation of real PuM techniques using real {unmodified} DRAM devices.} 

\X facilitates system integration studies of new {commodity DRAM based} PuM mechanisms by providing \atb{four} customizable hardware and software components that can be used as \atb{a} common basis to enable system support for such mechanisms in real systems.}
%\atb{Evaluating solutions to overcome the challenges in implementing PuM techniques end-to-end require modifications across the HW/SW stack. We list three examples: First, in hardware, the memory controller must be augmented with the capability to issue valid sequences of DDRX command sequences that trigger PuM operations in DRAM. Second, to satisfy memory allocation requirements (e.g., alignment, mapping Section~\ref{X}) of PuM techniques, OS memory management schemes must be modified. Third, the operations enabled by PuM techniques (e.g., RowClone) must be exposed to the application via software APIs.} %Our goal is to design and implement a flexible platform that can be used to solve system integration challenges and analyze trade-offs of end-to-end implementations of PuM techniques. To this end, we develop \textbf{P}rocessing-\textbf{i}n-\textbf{DRAM} (PiDRAM) framework. \X facilitates rapid integration of new PuM techniques by providing a set of HW/SW components that can be used as a common basis to enable system support for such techniques in real systems.}
%\outline{Introduce PiDRAM. Key design goals of PiDRAM (flexibility, in-DRAM computation support, open-source, system support). Describe PiDRAM in more detail.}
%\todo{Rewrite this paragraph, use stuff from Section 4.}
%\atb{\X comprises the necessary HW/SW components to facilitate system integration of PuM techniques. \X provides five components that we identify as the \emph{common components} PuM implementations require. 
%First, PuM techniques require issuing DDRX command sequences with violated timings to DRAM devices \jgl{PiDRAM can do this, but could also be useful for DRAM PuM not requiring violation of timing parameters.}. To ease implementation of new command sequences, \X provides a new, custom, easy-to-extend memory controller. 
\juan{\X contains \atb{two} main \emph{hardware} components. 
First, a custom, easy-to-extend \emph{memory controller} allows for \atb{implementing} new DRAM command sequences that \new{perform PuM operations}. For example, \new{the memory controller can be extended with a single state machine in its hardware description to implement a new DDRx command sequence with \new{user-defined} timing parameters to \newnew{implement a new PuM technique (i.e., perform a new PuM operation)}.}\revdel{ we can program this memory controller to issue DDRx command sequences with violated timing parameters that are needed to implement some PuM mechanisms~\cite{kim.hpca18,kim.hpca19,gao2020computedram}}}
%Second, to facilitate implementation of new PuM techniques and remain compatible with different microprocessor architectures, \X provides an ISA-transparent controller that oversees PuM execution. 
\juan{Second, an \emph{ISA-transparent controller (\textbf{P}uM \textbf{O}perations \textbf{C}ontroller, POC)} supervises PuM execution.} \new{POC exposes the PuM operations to the software components of PiDRAM over a memory-mapped interface to the processor, allowing the programmer to perform PuM operations using the PiDRAM framework by executing \newnew{conventional} LOAD/STORE instructions. The memory-mapped interface allows PiDRAM to be easily ported to systems that implement different instruction set architectures.} %This component ensures \atb{the} compatibility of PuM mechanisms with any microprocessor architecture.} %\atb{We implement a general protocol defines the}}
%Third, to enable system designers to directly communicate PuM execution to the memory controller over the ISA-transparent controller, \X provides a general controller $\longleftrightarrow{}$ application interface. 
%\juan{Third, a \emph{\atb{general} \todo{protocol}} \atb{that defines the communication protocol between the memory controller}}
%Fourth, to enable system designers to quickly implement software support for PuM techniques, \X provides an extensible library that harbors customizable functions which are used to communicate with the custom memory controller over the controller $\longleftrightarrow{}$ application interface. 
\juan{\new{PiDRAM contains two main \emph{software} components}. 
First, an \emph{extensible library} allows system designers to implement software support for PuM mechanisms. This library contains customizable functions that \atb{communicate with POC to perform PuM operations.}}
%Fifth, to enable end-to-end exploration of PuM techniques, \X provides a custom supervisor software with the necessary OS primitives (e.g., virtual memory).}
\juan{Second, a custom \emph{supervisor software} \atb{contains the necessary OS primitives (e.g., memory management) to enable end-to-end implementations of {commodity DRAM based} PuM techniques.}} %end-to-end.} enables the interaction with the operating system (OS) for virtual memory management...}
%\jgl{THE COMPONENTS PART NEEDS WORK.}

%\atb{\X is designed to enable exploration of solutions for the challenges in implementing PuM techniques end-to-end, at every level of the HW/SW stack and contains no proprietary hardware/software components}. Overall, \X comprises four components: (i) a custom memory controller, which serves regular memory load and store operations and in-DRAM computation operations over the IMO interface, (iii) \atb{system software}, which we augment to provide system support for PuDRAM techniques and (iv) the in-DRAM operations library, which \atb{is an extensible library that} implements \atb{customizable} functions \atb{which} are used to communicate with the custom memory controller to \atb{perform} in-DRAM computation. \X incorporates the IMO interface to facilitate integration of in-DRAM computation mechanisms. This way, a new in-DRAM computation mechanism can be implemented by only modifying the custom memory controller and the extensible library. \X's design is based on multiple open-source projects (e.g. RocketChip SoC Generator~\cite{X}, RISC-V Proxy Kernel~\cite{X}), we will release PiDRAM as open-source when this work is published.

%\outline{Describe our case studies. Describe key results we obtained following our case studies.} \jgl{Yes, this is the place.}
\atb{We demonstrate a prototype of \X on an FPGA-based RISC-V system~\cite{asanovic2016rocket}. 
To demonstrate the flexibility and ease of use of \X, we implement two \newnew{prominent} PuM \juan{\newnew{techniques}}: (1) \emph{RowClone}~\cite{seshadri2013rowclone}, \juan{an in-DRAM \omi{data} copy and initialization \newnew{technique}}, and (2) \emph{D-RaNGe}~\cite{kim.hpca19}, \juan{an in-DRAM true random number generat{ion technique} based on activation-latency failure\atb{s}}. 
%First, we extensively study RowClone which enables bulk-data copy inside DRAM~\cite{X} using PiDRAM. 
\juan{In order to support RowClone (Section~\ref{sec:rowclone})}, (i) we \juan{customize} \newnew{the} \X memory controller %such that it can 
\juan{to} issue carefully-engineered \revdel{valid }sequences of DRAM commands that perform \omi{data} copy \newnew{(and initialization)} operations in DRAM, \juan{and} (ii) we extend the custom supervisor software to implement a new memory management mechanism \juan{that} satisfies the memory allocation \juan{and alignment} requirements of RowClone.} 
%Second, we integrate D-RaNGe, a DRAM activation latency-failure based true random number generator. 
%Our implementation of D-RaNGe, over the common components \X provides, requires modifications to our custom memory controller in \textbf{X} lines of Verilog code and modifications to the custom supervisor software in \textbf{Y} lines of C code. 
\juan{For D-RaNGe (Section~\ref{sec:drange}), \newnew{we extend} \new{(i) \newnew{the} \X{} memory controller with a new state machine that periodically performs DRAM accesses \newnew{with reduced activation latencies} to generate random numbers~\cite{kim.hpca19} and a new hardware \emph{random number buffer} that stores the generated random numbers, and (ii) the custom supervisor software with a function that retrieves the random numbers from the hardware buffer to the user program.}}
%
%we {make} simple modifications to \X's memory controller (only \textbf{190} lines of Verilog code) and supervisor software (only \textbf{74} lines of C code)}. 
%Our results show that an end-to-end implementation of RowClone provides up to \textbf{X\%} performance improvement for bulk-copy operations, over CPU-copy (i.e., conventional copy, \emph{memcpy}). Our implementation of D-RaNGe provides true random numbers with \textbf{4.15} Mb/s throughput.} 
\juan{Our end-to-end evaluation of (i) RowClone \newnew{demonstrates} up to {14.6$\times{}$} speedup for bulk copy and {12.6$\times{}$} initialization operations over CPU copy (i.e., conventional \texttt{memcpy}), \newnew{even when coherence is satisfied using inefficient cache flush operations,} and (ii) D-RaNGe \newnew{demonstrates} that an end-to-end integration of D-RaNGe can provide true random numbers at high throughput (8.30 Mb/s) and low latency (4-bit random number in \SI{220}{\nano\second})\newnew{, even without any \omi{hardware or software} optimizations}.} \new{Implementing both PuM techniques over the Verilog and C++ codebase provided by PiDRAM \newnew{requires} only 388 lines of Verilog \newnew{code} and 643 lines of C++ code.}
%Our implementation of D-RaNGe provides true random numbers with \textbf{4.15} Mb/s throughput} \jgl{SAY SOMETHING ELSE. FOR EXAMPLE, "This rate is sufficient to satisfy the trng requirements of security apps..."}.

Our contributions are as follows:

\begin{itemize}
  \item We develop \X, the first flexible framework that enables end-to-end integration and evaluation of PuM \juan{mechanisms} using real {unmodified} DRAM chips.
  
  \item We develop a prototype of \X on an FPGA-based platform. To demonstrate the ease-of-use {and evaluation benefits} of \X, we implement two state-of-the-art DRAM-based PuM \juan{mechanisms, RowClone and D-RaNGe,} and evaluate them on \X's prototype {using unmodified DDR3 chips}. 
  
  \item We devise a new memory management mechanism that satisfies the memory allocation \juan{and alignment} requirements of RowClone. We demonstrate that our mechanism enables RowClone end-to-end {in the full system, and} \revcommon{provid{es}} significant performance improvements \revcommon{over traditional CPU-{based} copy and initialization operations (\texttt{memcpy}~\cite{memcpy} and \texttt{calloc}~\cite{calloc}) as demonstrated on our PiDRAM prototype}. 
  %\jgl{WE ALSO DEVELOP A MECHANISMS FOR MEMORY COHERENCE, RIGHT?}
  
  \item \atb{We implement and evaluate a {state-of-the-art} DRAM-based true random number generat{ion technique} (D-RaNGe). Our implementation provides a {solid foundation} for future work on system integration of DRAM-based PuM security primitives (e.g., PUFs~\cite{talukder2019exploiting,kim.hpca18}, TRNGs~\cite{olgun2021quactrngieee,olgun2021quactrng,talukder2019exploiting}){, implemented using real unmodified DRAM chips}.}
  %\jgl{Nothing to say about D-RaNGe?}
\end{itemize}

\section{Related Work} \label{sec:related}

There has been extensive research on general registration problems and in three dimensions in particular. ICP~\cite{besl1992method} is a widely used algorithm for 3D registration. Some following ICP variants~\cite{rusinkiewicz2001efficient, segal2009generalized, bouaziz2013sparse} aim at improving from different aspects. Recently, DCP~\cite{wang2019dcp} is proposed that revisits ICP from a deep learning perspective.

There is an abundance of SLAM works that deals with registrations and pose estimation at the scene level. For a broad survey, see \cite{tam2012registration}. An apparently similar idea to our is presented by Yang et al.~\shortcite{yang2019extreme}. Unlike our one-step technique, they refine the registration and completion modules iteratively. Yang et al.~\cite{yang2020extreme} also propose hybrid representations for relative pose estimation. These methods, however, match 3D RGB-D scenes rather than point clouds, thus require more information such as color, 360-image.
Chen et al.~\shortcite{chen2019plade} introduce a plane-based descriptor for the point cloud registration with a small overlap. However, for many shapes on object-level, like cars or lamps, it is hard to find a plane surface for matching.
Brachmann et al.~\shortcite{brachmann2017dsac} propose a learning-based method for pose estimation, however, this method is mainly designed for camera localization and it's hard to directly adapt it for shape registration.

In the following, we discuss previous works that are most related to the specific tasks of paired shape registration and partial shape completion on the object level, focusing on deep learning techniques.


\subsection{Paired shape registration} 
Recently, there have been research efforts to apply deep neural networks for the task of rigid~\cite{su2015render} and non-rigid~\cite{hanocka2018alignet, groueix2019unsupervised} registration, to offer faster and more robust than classic techniques.
Elbaz et al. ~\shortcite{elbaz20173d} propose a method that focuses on localizing the close-proximity scanned point cloud in a large-scale point cloud scene. They use super-points to match the corresponding region, and a deep neural network to calculate the transformation between the local and global point cloud.
Yew et al. ~\shortcite{yew20183dfeat} propose a weakly supervised deep learning framework to holistically learn a 3D feature detector and descriptor from GPS/INS tagged 3D point clouds. They use a Siamese architecture that learns to recognize if the given point clouds are from the same location. The correspondences between point clouds are obtained by a learned descriptor vector.
Choy et al. ~\shortcite{choy2020deep} propose a framework for pairwise registration of real-world 3D scans. This method contains a 6-dimensional convolutional network for correspondence confidence prediction, and then the pose is estimated and further refined recursively.

\input{figures/net_overall.tex}

Aoki et al. ~\shortcite{yaoki2019pointnetlk} propose PointNetLK, a modification to the classical LK(Lucas \& Kanade) algorithm which circumvents the need for convolution on the PointNet representation. This framework for rigid registration is more robust to initialization and missing parts than classic ICP.
Wang et al. ~\shortcite{wang2019dcp} propose Deep Closest Point(DCP), that revisits ICP from a deep learning perspective. The ICP-style method consists of three parts, that learns the common features of the input point clouds to register them together.
Similarly, Yew and Lee \shortcite{yew2020rpm} propose RPM-Net, which is less sensitive to initialization alignment comparing to the original ICP method. However, RPM-Net assumes that the normal information is given in the point cloud data.
Wong and Solomon \shortcite{wang2019prnet} propose PRNet, a sequential decision-making framework to achieve point cloud registration iteratively. Unlike the methods mentioned above, this method is able to handle partial-to-partial registration, the key is to use a detector to find the points in common between partial views, and keypoint-to-keypoint correspondences. These deep-learning based methods are aiming at detecting key points in the input paired shape, then match and pair them to compute the alignment transformation. 
These methods assume that the two parts have a significant overlap region that contains a few key points. 
Huang et al.~\shortcite{Huang2012} present a field-guided algorithm that is able to automatically compose the 3D shape given several pieces of it, where the input pieces have no overlapping. In our work, we utilize a data-driven approach to enable the registration, without the prescribed feature prior. Given two partial point clouds with little or no overlapping, we do registration and completion at the same time, to allow the network to better align the input shapes.


\subsection{Partial shape completion}
There are an increasing number of works focusing on the partial to complete shape generation, many of which are applied on point cloud representation, since it is strongly related to realistic scenarios, where the point clouds are the raw data coming from 3D acquisition devices. PointNet~\cite{qi2017pointnet} proposed a deep learning method for point cloud shape, which promotes several learning-based applications on the point cloud, including completion. Yuan et al.~\shortcite{yuan2018pcn} proposed a method that generates point clouds in two stages, where the first stage is to use a fully-connected decoder to obtain a coarse resolution point cloud and the second stage generates the final output by a folding-based decoder.
Tchapmi et al.~\shortcite{tchapmi2019topnet} introduced a novel decoder for point cloud completion which generates arbitrarily structured point clouds without explicitly enforcing a specific structure. The proposed decoder generates point clouds according to a tree structure where each node of the tree represents a subset of the point cloud.
Wang et al.~\shortcite{wang2020cascaded} proposed a completion method that contains an up-sampling module that predicts denser results than other completion methods.
Huang et al.~\shortcite{huang2020pf} introduced a method that only completes the missing regions of the input shape and can preserve its details, and successfully addressed the blurring issues caused by the auto-encoder structure. However, they still require the input partial data to cover a significant portion of the surface region of the shape, while in many real cases only a small region of the shape is captured by a single scan.


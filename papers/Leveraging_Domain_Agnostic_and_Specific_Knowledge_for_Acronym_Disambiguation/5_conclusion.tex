\section{Conclusions}
\label{sec:conclusion}
An obstacle to scientific document understanding is the widespread use of acronyms which are shortened forms of long technical phrases.
Acronym disambiguation aims to find the correct meaning of an ambiguous acronym in a given text.
However, it is challenging and expensive to obtain large-scale high-quality annotated data in the scientific domain.
In this paper, we present a hierarchical dual-path BERT method coined hdBERT for acronym disambiguation to resolve the special challenges in this scenario.
The method is equipped with pretrained models RoBERTa and SciBERT and integrates their dual-path representations simultaneously to leveraging domain agnostic and specific knowledge.
Experiments on real-world datasets demonstrate the effectiveness of the proposed approach.
It achieves competitive performance and outperforms state-of-the-art methods among various evaluation metrics.
Moreover, there are still many research opportunities in this task, approaches such as self-training, adversarial learning, and contrastive learning are worth studying to further improve the performance.
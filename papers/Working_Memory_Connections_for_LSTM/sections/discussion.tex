\rev{With Working Memory Connections, we show that information stored in the LSTM cell should be accessible in the gate structure. We compare the performance of WMCs to a similar approach named peephole connections~\citep{gers2000recurrent}, and to vanilla LSTM. We find out that the structure of WMCs allows for two distinct improvements:
\begin{enumerate}
    \item \textit{A more precise control of the gates}. The multiplicative gates in the LSTM block must regulate the information flowing through the cell, but they cannot access the state of that same cell in the traditional LSTM formulation. The presence of the cell state in the multiplicative gates motivates the improvements of LSTM-WM \textit{w.r.t.}~vanilla LSTM. 
    \item \textit{Increased stability during training} compared to peephole connections. Exposing different projections of the cell state without squashing its content seems to be a critical point for the LSTM-PH. This element of novelty in our design explains why WMCs provide a boost in performance even when peepholes fail.
\end{enumerate}
As a consequence of these two improvements, WMCs incorporate the theoretical benefits of peephole connections, originally described by~\citet{gers2000recurrent}, with the training stability and versatility of vanilla LSTM.}

\rev{It is worth noting that, for tasks that do not require to access the content of the memory cell, Working Memory Connections would not probably bring any benefit in the LSTM formulation, while peepholes might still hinder the whole learning process because of unstable updates.}

\rev{At the same time, when training stacked LSTMs, the benefits given by WMCs may become less significant. We suppose that this is due to the increased complexity in the network structure, where multiple LSTM blocks can interact through the various layers.
Similarly, many architectures employ LSTMs as building blocks together with different components, and the influence of WMCs in these compound deep networks cannot be easily determined. Experiments on image captioning, proposed in this paper, partially answer this question and prove that WMCs afford a small yet existing improvement even in this scenario. However, there are many other complex tasks involving vision, language, and other modalities, that are worth investigating.}
\documentclass[11pt]{article}
\usepackage{empheq}
\usepackage{xcolor}

\input{preamble.tex}



\includeversion{paperonly}
\excludeversion{techreportonly}
%\includeversion{techreportonly}
%\excludeversion{paperonly}

\begin{document}
	\title{Approximation Schemes for Multiperiod Binary Knapsack Problems} 
	\author{Zuguang Gao, John R. Birge, and Varun Gupta\footnote{All authors are with the University of Chicago. Emails: \{zuguang.gao, john.birge, varun.gupta\}@chicagobooth.edu.}}
	\date{}

	\maketitle
	
	\begin{abstract}
		\begin{onehalfspace} 
			An instance of the multiperiod binary knapsack problem (MPBKP) is given by a horizon length $T$, a non-decreasing vector of knapsack sizes $(c_1, \ldots, c_T)$ where $c_t$ denotes the cumulative size for periods $1,\ldots,t$, and a list of $n$ items. Each item is a triple $(r, q, d)$ where $r$ denotes the reward or value of the item, $q$ its size, and $d$ denotes its time index (or, deadline). The goal is to choose, for each deadline $t$, which items to include to maximize the total reward, subject to the constraints that for all $t=1,\ldots,T$, the total size of selected items with deadlines at most $t$ does not exceed the cumulative capacity of the knapsack up to time $t$. We also consider the multiperiod binary knapsack problem with soft capacity constraints (MPBKP-S) where the capacity constraints are allowed to be violated by paying a penalty that is linear in the violation. The goal of MPBKP-S is to maximize the total profit, which is the total reward of the selected items less the total penalty. Finally, we consider the multiperiod binary knapsack problem with soft stochastic capacity constraints (MPBKP-SS), where the non-decreasing vector of knapsack sizes $(c_1, \ldots, c_T)$ follow some arbitrary joint distribution but we are given access to the profit as an oracle, and we must choose a subset of items to maximize the total expected profit, which is the total reward less the total expected penalty.

%			In the multiperiod binary knapsack problem (MPBKP), there are $T$ time periods. In each period, there are a number of items, each with a reward and a size. The goal is to choose in each period which items to include to maximize the total reward, subject to the constraints that for any $t=1,\ldots,T$, the total size of selected items from period~$1$ to period~$t$ cannot exceed the capacity of the knapsack at time $t$. In the multiperiod binary knapsack problem with soft capacity constriants (MPBKP-SS), the capacity constraints are allowed to be violated by paying some penalty for each unit size that goes beyond the capacity. The goal of MPBKP-SS is then to maximize the total profit, which is the total reward of the selected items deducted by the total penalty.

For MPBKP, we exhibit a fully polynomial-time approximation scheme that achieves $(1+\epsilon)$ approximation with runtime $\tilde{\mathcal{O}}\left(\min\left\{n+\frac{T^{3.25}}{\epsilon^{2.25}},n+\frac{T^{2}}{\epsilon^{3}},\frac{nT}{\epsilon^2},\frac{n^2}{\epsilon}\right\}\right)$; for MPBKP-S, the $(1+\epsilon)$ approximation can be achieved in $\mathcal{O}\left(\frac{n\log n}{\epsilon}\cdot\min\left\{\frac{T}{\epsilon},n\right\}\right)$. To the best of our knowledge, our algorithms are the first FPTAS for any multiperiod version of the Knapsack problem since its study began in 1980s. For MPBKP-SS, we prove that a natural greedy algorithm is a $2$-approximation when items have the same size. Our algorithms also provide insights on how other multiperiod versions of the knapsack problem may be approximated.

%\keywords{approximation algorithms \and knapsack problem \and optimization.}
		\end{onehalfspace}
	\end{abstract}
	
	%\tableofcontents
	\thispagestyle{empty}
	\setlength{\parskip}{.1in}
	\maketitle

	\clearpage
	\setcounter{page}{1}

	\section{Introduction}
	
	\input{introduction.tex}
	
	
%	\subsection{Notation}	
%	\[ \Qcal(\Scal) = \sum_{i \in \Scal} q_i \]
%	\[ \Rcal(\Scal) = \sum_{i \in \Scal} r_i \]
%	\[ \hat{\Rcal}(\Scal) = \sum_{i \in \Scal} \hat{r}_i \]
%	\[ \Pcal(\Scal) = \Rcal(\Scal) - \sum_{t=1}^T B_t \left[\sum_{j\in  \Scal : d_j = t } q_j - \max_{0 \leq t' < t}\left\{ c_t - c_{t'} - \sum_{j\in \Scal : t'+1 \leq d_j \leq  t-1}q_j \right\}\right]^+ \]
	
%	For a solution $\Scal =  \Scal(1) \cup \Scal(2) \cup \cdots \Scal(T)$ with $\Scal(t) = (i^{(t)}_1, \ldots, i^{(t)}_{I_t})$ denoting an indexing of items in the solution $\Scal$ with deadline $t$, we define the leftover capacity for serving items in $\Scal$ via the Lindley-type recursion:
%	\begin{align*}
%	W^{(1)}_1 &= c_1 \\
%	W^{(t)}_1 &= \left( W^{(t-1)}_{I_{t-1}} - q_{i^{(t-1)}_{I_{t-1}}}\right)^+  + (c_t-c_{t-1})   & (t \geq 2)\\
%	W^{(t)}_j &= \left( W^{(t)}_{j-1} - q_{i^{(t)}_{j-1}} \right)^+   & (j \geq 2).
%	\end{align*}
	
%	Based on $W^{(t)}_j$ defined above, we then define the rounded profit of the set $\Scal$ as the sum of the rounded (down) reward of each item in $\Scal$ minus the rounded (up) penalty for each item in $\Scal$ (the discretization quantum $\kappa$ will be clear from the context and hence we suppress the dependence of $\hat{\Pcal}$ on it):
%	
%	\[ \hat{\Pcal}(\Scal) = \hat{
%		\Rcal}(\Scal) - \sum_{t=1}^T \sum_{j =1 }^{I_t} \left\lceil B_t \cdot \left( q^{(t)}_j -  W^{(t)}_j \right)^+ \right \rceil_\kappa . \]
	
	%\clearpage
\section{Problem Formulation and Main Results}\label{sec:form}
In this section, we formally introduce the Multiperiod Binary Knapsack Problem (MPBKP), as well as the generalized versions: the Multiperiod Binary Knapsack Problem with Soft capacity constraints (MPBKP-S), {  and Multiperiod Binary Knapsack Problem with Soft Stochastic Capacity constraints (MPBKP-SS)}.

%	\varun{Maybe we can mention that intuitively this is $T$ knapsack problems with capacity $c_t-c_{t-1}$ for the $t$th problem but where we can (a) carry forward unused capacity, or (b) additionally buy extra capacity at cost $B_t$ (and optionally carry that forward too) }

\subsection{Multiperiod binary Knapsack problem (MPBKP)}

An instance of MPBKP is given by a set of $n$ items, each associated with a triple $(r_i,q_i,d_i)$, and a sequence of knapsack capacities $\{c_1,\ldots,c_T\}$. For each item $i$, we get reward $r_i$ if and only if $i$ is included in the knapsack by time $d_i$. We assume that $r_i\in \NN$, $q_i\in\NN$ and $d_i\in [T]:=\{1,\ldots, T\}$. The knapsack capacity at time $t$ is $c_t$, and by convention $c_0=0$. The MPBKP can be written in the integer program (IP) form:
\begin{subequations}\label{MPBKP}
	\begin{align}
	&\max_x z = \sum_{i=1}^{n} r_ix_i\\
	&\text{ s.t. } \sum_{j: d_j\le t} q_jx_j\le c_{t},\quad \forall t=1,\ldots, T\\
	&\qquad x_i\in\{0,1\},\quad \forall i=1,\ldots,n
	\end{align}
\end{subequations}
where $x_i$'s are binary decision variables, i.e., $x_i$ is~$1$ if item $i$ is included in the knapsack and is~$0$ otherwise. In~\eqref{MPBKP}, we aim to pick a subset of items to maximize the objective function, which is the total reward of picked items, subject to the constraints that by each time $t$, the total size of picked items with deadlines up to $t$ does not exceed the knapsack capacity at time $t$, which is $c_{t}$. 
For each $t\in [T]$, let $\mathcal{I}(t):=\{i\in [n]\mid d_i=t\}$ denote the set of items with deadline $t$. Note that without loss of generality, we may assume that $\mathcal{I}(t)\ne\emptyset, \forall t$ and $c_t>0$.
%for some $t\in [T]$, i.e., $d_i\ne t$ for all $i\in [n]$, then we can eliminate this $t$ by redefining $t:= \min_{j: d_j> t} d_j$. Thus, we can without loss of generality assume that $\mathcal{I}(t)\ne \emptyset$ for all $t\in [T]$, which also implies that $T\le n$. 
We further note that the decision variables $x_i$'s in~\eqref{MPBKP} are binary, but if we relax this to any nonnegative integers, the problem becomes the so-called multiperiod knapsack problem (MPKP) as in~\cite{faaland1981multiperiod}. %As we will see in the next subsection, MPBKP can be viewed as a special case of MPBKP-S, and thus is not further discussed in this paper. 
%\begin{comment}
Our first main result is the following theorem on MPBKP.
\begin{theorem}\label{mainthm1}
	An FPTAS exists for MPBKP. Specifically, there exists a deterministic algorithm that achieves $(1+\epsilon)$-approximation in $\tilde{\mathcal{O}}\left(\min\left\{n+\frac{T^{3.25}}{\epsilon^{2.25}},n+\frac{T^{2}}{\epsilon^{3}},\frac{nT}{\epsilon^2},\frac{n^2}{\epsilon}\right\}\right)$.
\end{theorem}
%\end{comment}
As we will see shortly, MPBKP can be viewed as a special case of MPBKP-S. In Section~\ref{sec:MPBKP}, we will provide an approximation algorithm for MPBKP with runtime $\tilde{\mathcal{O}}\left(n+\frac{T^{3.25}}{\epsilon^{2.25}}\right)$. An alternative algorithm with runtime $\tilde{\Ocal}\left(n+\frac{T^{2}}{\epsilon^{3}}\right)$ is provided in Appendix~\ref{appT2}. In Section~\ref{sec:approx2}, we will provide an approximation algorithm for MPBKP-S with runtime $\tilde{O}\left(\frac{nT}{\epsilon^2}\right)$, which is also applicable to MPBKP.

\subsection{Multiperiod binary Knapsack problem with soft capacity constraints (MPBKP-S)}
In MPBKP-S, the capacity constraints in~\eqref{MPBKP} no longer exist, i.e., the total size of selected items at each time step is allowed to be greater than the total capacity up to that time, however, there is a penalty rate $B_t\in\NN$ for each unit of overflow at period $t$. We assume that $B_t>\max_{i\in[n]:d_i\le t}\frac{r_i}{q_i}$ to avoid trivial cases (any item with $\frac{r_i}{q_i}\ge B_t$ and $d_i\le t$ will always be added to generate more profit). In the IP form, MPBKP-S can be written as 
\begin{comment}
\begin{equation}\label{MPBKP-S}
\begin{aligned}
\max_{x \in \{0,1\}^n} z(x) :=&\sum_{i=1}^nr_ix_i - B\cdot \Bigg\{\bigg[\sum_{j\in \mathcal{I}(1)}q_jx_j-c_1\bigg]^+ \\&+ \bigg[\sum_{j\in \mathcal{I}(2)}q_jx_j-\Big(c_1-\sum_{j\in \mathcal{I}(1)}q_jx_j\Big)^+-(c_2-c_1)\bigg]^++\cdots\Bigg\}
%\\
%&\text{ s.t. } x_i\in \{0,1\}, \quad\forall i\in[n]
\end{aligned}
\end{equation}
where $\left[a\right]^+$ is the maximum of $a$ and $0$. In the objective function, $\sum_{j\in \mathcal{I}(1)}q_jx_j$ is the total size of selected items with deadline~$1$, and $c_1$ is the capacity for time $1$, thus $B\cdot \left[\sum_{j\in \mathcal{I}(1)}q_jx_j-c_1\right]^+ $ is the penalty generated at time~$1$. Similarly, $\sum_{j\in \mathcal{I}(2)}q_jx_j$ is the total size of selected items with deadline~$2$, $c_2-c_1$ is the incremental capacity from time~$1$ to time~$2$, and $\left(c_1-\sum_{j\in \mathcal{I}(1)}q_jx_j\right)^+$ is the leftover capacity (if any) carried from time~$1$, thus $B\cdot \left[\sum_{j\in \mathcal{I}(2)}q_jx_j-\left(c_1-\sum_{j\in \mathcal{I}(1)}q_jx_j\right)^+-(c_2-c_1)\right]^+$ is the penalty generated at time~$2$. We continue this pattern and write out the penalties generated at each time.



An equivalent expression
of~\eqref{MPBKP-S} is the following.
\begin{equation}\label{MPBKP-S2}
\begin{aligned}
&\max_{x \in\{0,1\}^n} z(x) :=\sum_{i=1}^nr_ix_i - B\cdot \sum_{t=1}^T\left[\sum_{j\in \mathcal{I}(t)}q_jx_j-\max_{0\leq t' < t}\left\{ c_t - c_{t'}-\sum_{j  \in \Scal : t'+1 \leq d_j \leq t-1} q_j x_j\right\}\right]^+ .
%\\
%&\text{ s.t. } x_i\in \{0,1\}, \quad\forall i\in[n]
\end{aligned}
\end{equation}
Further, if we add decision variables $y_t, t=1,\ldots, T$, which represents the overflow at time $t$, then the problem can be written as
\end{comment}
\begin{subequations}\label{MPBKP-S3}
	\begin{align}
	&\max_{x,y} \sum_{i\in[n]}r_ix_i - \sum_{t=1}^TB_ty_t\\
%	&\text{s.t. } \sum_{i\in\Ical(1)\cup\cdots\cup\Ical(t)}q_ix_i - \sum_{s=1}^ty_s \le \sum_{s=1}^ta_t = c_t,\quad \forall t: 1\le t\le T\\
	&\text{s.t. } \sum_{i\in\Ical(1)\cup\cdots\cup\Ical(t)}q_ix_i - \sum_{s=1}^ty_s \le c_t,\quad \forall t: 1\le t\le T\\
	&\qquad x_i\in\{0,1\},\quad y_t\ge 0,
	\end{align}
\end{subequations}
where the  decision variables $y_t, t=1,\ldots, T$ represent the units of overflow at time~$t$, and {  $c_t-c_{t-1}$} is the incremental capacity at time~$t$. The objective is to choose a subset of the $n$ items to maximize the total profit, which is the sum of the rewards of the selected items  minus the sum of penalty paid at each period, and the constraints enforce that the total size of accepted items by the end of each period must not exceed the sum of the cumulative capacity and the units of overflow. Our second main result is the following theorem on MPBKP-S.
\begin{theorem}\label{mainthm2}
	An FPTAS exists for MPBKP-S. Specifically, there exists an algorithm which achieves $(1+\epsilon)$-approximation in  ${\mathcal{O}}\left(\frac{n\log n}{\epsilon}\cdot \min\left\{\frac{T}{\epsilon}, n\right\}\right)$.
\end{theorem}

In section~\ref{sec:approx2} we will present an approximation algorithm for solving MPBKP-S with time complexity $\mathcal{O}\left(\frac{nT\log n}{\epsilon^2}\right)$. An alternative FPTAS with runtime $\Ocal\left(\frac{n^2}{\epsilon}\right)$ is provided in Appendix~\ref{simple-MPBKP-S}. 
For the ease of presentation, our algorithms and analysis are presented for the case $B_t=B$, but they can be generalized to the heterogeneous $\{B_1,\ldots,B_T\}$ in a straightforward manner. It is worth noting that the algorithm for MPBKP that we introduce in section~\ref{sec:MPBKP} does not extend to MPBKP-S, and we will make this clear in the beginning of section~\ref{sec:approx2}.

{ 
\subsection{Multiperiod Binary Knapsack Problem with Soft Stochastic Capacity Constraints (MPBKP-SS)}
The MPBKP-SS formulation is similar to~\eqref{MPBKP-S3}, except that the vector of knapsack sizes $(c_1, \ldots, c_T)$ follows some arbitrary joint distribution given to the algorithm as the set of possible sample path (realization) of knapsack sizes and the probability of each sample path. We use $\omega$ to index sample paths which we denote by $\{c_t(\omega)\}$, $p(\omega)$ as the probability of sample path $\omega$, and $\Omega$ as the set of possible sample paths. The goal is to pick a subset of items before the realization of $\omega$ so as to maximize the expected total profit, which is the sum of the rewards of the selected items deducted by the total (expected) penalty. For a sample $\omega\in\Omega$ let $y_t(\omega)$ be the overflow at time $t$. Then, we can write the problem in IP form as:
\begin{subequations}\label{MPBKP-SS}
\begin{align}
&\max_{x,y} \sum_{i\in[n]}r_ix_i - \mathbb{E}_\omega\left[B_t\cdot \sum_{t=1}^Ty_t(\omega)\right]\\
&\text{s.t. } \sum_{i\in\Ical(1)\cup\cdots\cup\Ical(t)}q_ix_i - \sum_{s=1}^ty_s(\omega) \le   c_t(\omega),\quad \forall \omega\in\Omega, 1\le t\le T\\
&\qquad x_i\in\{0,1\},\quad y_t\ge 0
\end{align}
\end{subequations}

Our third main result is the following theorem on MPBKP-SS, which asserts a greedy algorithm for the special case when all items are of the same size. Details will be provided in Section~\ref{sec:unit-MPBKP-SS}.
\begin{theorem}\label{mainthm3}
	If $q_i=q$ for all $i\in[n]$, then there exists a greedy algorithm that achieves $2$-approximation for MPBKP-SS in $\Ocal\left(n^2T|\Omega|\right)$.
\end{theorem}

We further note that both MPBKP-S and MPBKP-SS are special cases of non-monotone submodular maximization which is \emph{not} non-negative, for which not many general approximations are known. In that sense, studying these problems would be an interesting direction to develop techniques for it.
}
	
	
\section{FPTAS for MPBKP}\label{sec:MPBKP}
In this section, we provide an FPTAS for the MPBKP with time complexity $\tilde{\mathcal{O}}\left(n+\frac{T^{3.25}}{\epsilon^{2.25}}\right)$. We will apply the ``functional approach'' as used in~\cite{chan:OASIcs:2018:8299}. The main idea is to use the results on function approximations~\citep{chan:OASIcs:2018:8299,jin:LIPIcs:2019:10652} as building blocks -- for each period we approximate one function that gives, for every choice of available capacity, the maximum reward obtainable by selecting items in that period. We then combine ``truncated'' version of these functions using $(\max,+)$-convolution. This idea, despite its simplicity, allows us to obtain an FPTAS for MPBKP. Such a result should not be taken as granted -- as we will see in the next section, this method does not apply for MPBKP-S, even though it is just a slight generalization of MPBKP. 

We begin with some preliminary definitions and notations. For a given set of item rewards and sizes, $\Ical = \{(r_1,q_1), \ldots, (r_{n'}, q_{n'})\}$, define the function
\begin{align}\label{eqn:func}
f_\Ical(c) := \max_{x_1,\ldots,x_{n'}}\left\{\sum_{i\in\Ical}r_ix_i\ :\ \sum_{i\in\Ical}q_ix_i\le c, \ x_1,\ldots,x_{n'}\in\{0,1\}\right\}
\end{align}
for all $c\ge 0$, and $f_\Ical(c) := -\infty$ for $c<0$. The function $f_\Ical$ is a nondecreasing step function, and the number of steps is called the \emph{complexity} of that function. Further, for any $\Ical = \Ical_1\sqcup \Ical_2$, i.e., $\Ical$ being a disjoint union of $\Ical_1$ and $\Ical_2$, we have that $f_\Ical = f_{\Ical_1}\oplus f_{\Ical_2}$, where $\oplus$ denotes the $(\max,+)$-\emph{convolution}: $(f\oplus g)(c) = \max_{c'\in\mathbb{R}}\left(f(c')+g(c-c')\right)$.

We define the \emph{truncated function} $f_\Ical^{c'}$ as follows:
\begin{align}
f_\Ical^{c'}(c) = \begin{cases}
f_\Ical(c) &  c\le c',\\
-\infty & c>c'.
\end{cases}
\end{align}
Recall that we denote the set of items with deadline $t$ by $\Ical(t)$. We next define the function $f_t$ as follows: 
\begin{align}\label{eqn:ft}
f_t := \begin{cases}
f_{\Ical(1)}^{c_1} & t=1,\\
\left(f_{t-1}\oplus f_{\Ical(t)}\right)^{c_t} & t\ge 2.
\end{cases}
\end{align}
%In other words, $f_t$'s are defined recursively: for $t=1$, let $f_1 := f_{\Ical(1)}^{c_1}$; for $t\ge 2$, we define $f_t = \left(f_{t-1}\oplus f_{\Ical(t)}\right)^{c_t}$.
%, we write $f_t$ for $f_{\Ical(t)}$. 
In words, each function value of $f_t(c)$ corresponds to a feasible, in fact an optimal, solution $x$ for items with deadline at most $t$ as the next proposition shows.
\begin{proposition}\label{prop:optimalfunc}
Let $x^*$ be the optimal solution for MPBKP~\eqref{MPBKP}. We have that
the optimal value of~\eqref{MPBKP}, $\sum_{i\in[n]}r_ix_i^*$, satisfies
$
\sum_{i\in[n]}r_ix_i^*  = f_T(c_T).
$
\end{proposition}

Proposition~\ref{prop:optimalfunc} implies that, to obtain an approximately optimal solution for MPBKP~\eqref{MPBKP}, it is sufficient to have a good approximation for the function
\begin{align}
f_T = \left(\cdots\left(\left(f_{\Ical(1)}^{c_1}\oplus f_{\Ical(2)}\right)^{c_2}\oplus f_{\Ical(3)}\right)^{c_3}\cdots\oplus f_{\Ical(T)}\right)^{c_{T}}.
\end{align}

We say that a function $\tilde{f}$ approximates the nonnegative function $f$ with factor $1+\epsilon$ if $\tilde{f}(c)\le f(c)\le (1+\epsilon)\tilde{f}(c)$ for all $c\in\mathbb{R}$. It should be clear that if $\tilde{f}$ approximates $f$ with factor $1+\epsilon$ and $\tilde{g}$ approximates $g$ with factor $1+\epsilon$, then $\tilde{f}\oplus\tilde{g}$ approximates $f\oplus g$ with factor $1+\epsilon$. We then introduce the following result from~\cite{jin:LIPIcs:2019:10652} for 0-1 Knapsack problem. 
\begin{lemma}[\cite{jin:LIPIcs:2019:10652}]\label{lem:01}
Given a set $\Ical=\{(r_1,q_1),\ldots,(r_n,q_n)\}$, we can obtain $\tilde{f}_{\Ical}$ that approximates $f_\Ical$ (defined in~\eqref{eqn:func}) with factor $1+\epsilon$ and complexity $\tilde{O}\left(\frac{1}{\epsilon}\right)$ in $\tilde{O}\left(n+\left(1/\epsilon\right)^{2.25}\right)$.
\end{lemma}
%Suppose that $\tilde{f}_\Ical$ has complexity $l$, then, we denote by $(C_k,R_k)$ as the ``steps'' of function $\tilde{f}_\Ical$, i.e., for $k=1,\ldots,l$, we have that $\tilde{f}_\Ical(C_k) = R_k$ and $C_k = \min_{\tilde{f}_{\Ical}(c)=R_k}c$. 
With the above lemma, we present Algorithm~\ref{alg:MPBKP} for MPBKP.
\begin{algorithm}[ht]
\footnotesize
\caption{FPTAS for MPBKP}
\label{alg:MPBKP}
\algsetblock[Name]{Parameters}{}{0}{}
\algsetblock[Name]{Initialize}{}{0}{}
\algsetblock[Name]{Define}{}{0}{}
\begin{algorithmic}[1]
	\Statex \textbf{Input:} $\epsilon, [n], c_1,\ldots, c_T$  \Comment {Set of items to be packed, cumulative capacities}
	\Statex \textbf{Output:} $\tilde{f}_t$ \Comment Approximation of function $f_t$
	\State Discard all items with $r_i\le \frac{\epsilon}{n}\max_jr_j$ and relabel the items 
	\State $r_0\gets \min_ir_i$ \Comment Lower bound of solution value
	\State $m\gets \left\lceil\log_{1+\epsilon}\frac{n^2}{\epsilon}\right\rceil$ \Comment number of distinct rewards to be considered, each in the form $r_0\cdot(1+\epsilon)^k$
	%		\State Initialize $\tilde{A}(0,r) = \begin{cases}
	%		0 & r = 0,\\
	%		-\infty & r > 0.
	%		\end{cases}$
	\State Obtain $\tilde{f}_{\Ical(1)}$ that approximates $f_{\Ical(1)}$ with factor $(1+\epsilon)$ using Lemma~\ref{lem:01}
	\State $\tilde{f}_1:= \tilde{f}_{\Ical(1)}^{c_1}$ \Comment $\tilde{f}_1$ has complexity at most $m=\tilde{\mathcal{O}}\left(\frac{1}{\epsilon}\right)$
	\For {$t=2,\ldots, T$}
	\State Obtain $\tilde{f}_{\Ical(t)}$ that approximates $f_{\Ical(t)}$ with factor $(1+\epsilon)$ using Lemma~\ref{lem:01}
	\State $l\gets$ complexity of $\tilde{f}_{\Ical(t)}$ \Comment $l=\tilde{\mathcal{O}}\left(\frac{1}{\epsilon}\right)$
	\State Compute (all breakpoints and their values of) $\hat{f}_{t}:= \left(\tilde{f}_{t-1}\oplus \tilde{f}_{\Ical(t)}\right)^{c_t}$, taking $m\cdot l$ time
\Comment $\hat{f}_t$ has complexity $\tilde{\mathcal{O}}\left(\frac{1}{\epsilon^2}\right)$
	\State $\tilde{f}_t := r_0\cdot (1+\epsilon)^{\left\lfloor\log_{1+\epsilon}\left(\frac{\hat{f}_t}{r_0}\right)\right\rfloor}$ \Comment Round $\hat{f}_t$ down to the nearest $r_0\cdot (1+\epsilon)^k$. Now $\tilde{f}_t$ has complexity at most $m=\tilde{\mathcal{O}}\left(\frac{1}{\epsilon}\right)$
	\EndFor
\end{algorithmic}
\end{algorithm}

We now describe the intuition behind Algorithm~\ref{alg:MPBKP}. We first discard all items with reward $r_i\le \frac{\epsilon}{n}\max_jr_j$. The maximum we could lose is $n\cdot \frac{\epsilon}{n}\max_jr_j = \epsilon\max_jr_j$, which is at most $\epsilon$ fraction of the optimal value. We next obtain all $\tilde{f}_{\Ical(t)}$, for all $t=1,\ldots, T$, that approximate $f_{\Ical(t)}$ (as defined in~\eqref{eqn:func}) within a $(1+\epsilon)$ factor. These functions $\tilde{f}_{\Ical(t)}$ have complexity $\tilde{\Ocal}\left(\frac{1}{\epsilon}\right)$. We start with combining the functions of period~$1$ and period~$2$ using $(\max,+)$-convolution. To enforce the constraint that the total size of selected items in period~$1$ does not exceed the capacity of period~$1$, we truncate $\tilde{f}_{\Ical(1)}$ by $c_1$ (so that any solution using more capacity in period~$1$ results in $-\infty$ reward) and do the convolution on the truncated function $\tilde{f}_1$. Since both functions are step functions with complexity $\tilde{\Ocal}\left(\frac{1}{\epsilon}\right)$, the $(\max,+)$ convolution can be done in time $\Ocal\left(\frac{1}{\epsilon^2}\right)$. The resulting function $\hat{f}_2$ would have complexity $\Ocal\left(\frac{1}{\epsilon^2}\right)$. To avoid inflating the complexity throughout different periods (which increases computation complexity), the function $\hat{f}_2$ is rounded down to the nearest $r_0\cdot (1+\epsilon)^k$, where $r_0:=\min_jr_j$ and $k$ is some nonnegative integer. Note that $r_0$ is a lower bound of any solution value. After discarding small-reward items, we have that $\frac{\max_jr_j}{r_0}\le \frac{n}{\epsilon}$, which implies that $n\max_jr_j = \frac{n^2}{\epsilon}r_0$ is an upper bound for the optimal solution value. Therefore, after rounding down the function values of $\hat{f}_2$ and obtaining $\tilde{f}_2$, there are at most $\log_{1+\epsilon}\frac{n^2}{\epsilon}\approx \frac{1}{\epsilon}\log\frac{n^2}{\epsilon}$ different values on $\tilde{f}_2$. Now we have brought down the complexity of $\tilde{f}_2$ again to $\tilde{\Ocal}\left(\frac{1}{\epsilon}\right)$, at an additional $(1+\epsilon)$ factor loss in the approximation error. We then move to period~$3$ and continue this pattern of $(\max,+)$-convolution, truncation, and rounding down. In the end when we reach period $T$, $\tilde{f}_T$ will only contain feasible solutions to~\eqref{MPBKP}, and approximate $f_T$ with total approximation factor of $(1+\epsilon)^T\approx (1+T\epsilon)$. Formally, we have the following lemma which shows the approximation factor of $\tilde{f}_t$ for $f_t$.
\begin{lemma}\label{lem:fapprox}
Let $\tilde{f}_t$ be the functions obtained from Algorithm~\ref{alg:MPBKP}, and let $f_t$ be defined as in~\eqref{eqn:ft}. Then, $\tilde{f}_t$ approximates $f_t$ with factor $(1+\epsilon)^t$, i.e., $\tilde{f}_t(c)\le f_t(c)\le (1+\epsilon)^t\tilde{f}_t(c)$ for all $0\le c\le c_t$.
\end{lemma}



Lemma~\ref{lem:fapprox} and Proposition~\ref{prop:optimalfunc} together imply that $\tilde{f}_T(c_T)$, obtained from Algorithm~\ref{alg:MPBKP}, approximates the optimal value of MPBKP~\eqref{MPBKP} by a factor of $(1+\epsilon)^T \approx (1+T\epsilon)$. In Algorithm~\ref{alg:MPBKP}, obtaining $\tilde{f}_{\Ical(t)}$ for all $t=1,\ldots,T$ takes time $\tilde{O}\left(n+{T}/{\epsilon^{2.25}}\right)$; computing the $(\max,+)$-convolution on $\tilde{f}_{t-1}\oplus \tilde{f}_{\Ical(t)}$ for all $t$ take time $T\cdot m\cdot l = \tilde{O}\left(T/\epsilon^2\right)$. Therefore, Algorithm~\ref{alg:MPBKP} has runtime $\tilde{O}\left(n+T/\epsilon^{2.25}\right)$. As a result, we have the following proposition. 
\begin{proposition}
Taking $\epsilon' = T\epsilon$, Algorithm~\ref{alg:MPBKP} achieves $(1+\epsilon')$-approximation for MPBKP in $\tilde{O}\left(n+\frac{T^{3.25}}{{\epsilon'}^{2.25}}\right)$.
\end{proposition}


\section{FPTAS for MPBKP-S}\label{sec:approx2}

In this section, we provide an FPTAS for the MPBKP-S with time complexity $\mathcal{O}\left(\frac{Tn\log n}{\epsilon^2}\right)$. An alternative FPTAS with time complexity $\mathcal{O}\left(\frac{n^2\log n}{\epsilon}\right)$ is provided in Appendix~\ref{simple-MPBKP-S}. Combining the two, we show that our algorithms achieve $(1+\epsilon)$ approximation ratio in time $\mathcal{O}\left(\frac{n\log n}{\epsilon}\cdot\min\left\{\frac{T}{\epsilon},n\right\}\right)$, which proves Theorem~\ref{mainthm2}. 
We should note that the algorithm in the previous section does not apply here: we could similarly define a function which gives the maximum profit ($=$reward$-$penalty) under a given capacity constraint, but the main obstacle is on the $(\max,+)$-convolution because profit does not ``add up''. In other words, the total profit we earn by selecting items in the set $\Scal_1\cup\Scal_2$ is not the sum of the profits we earned by selecting $\Scal_1$ and $\Scal_2$ separately. For this reason, we can no longer rely on the techniques used in function approximation and $(\max,+)$-convolution as in~\cite{chan:OASIcs:2018:8299,jin:LIPIcs:2019:10652}. Instead, our main idea is motivated by the techniques that originated from earlier papers~\citep{ibarra1975fast,lawler1979fast}, but adapting their technique to MPBKP-S requires significant modifications as we show in this section. %To a large extent the algorithms and proofs follow the structure of Section~\ref{sec:approx} and for succinctness we only emphasize the modifications necessary. 
We restrict our presentation to the case $B_t =B$ for readability, but our algorithms and analysis generalize in a straightforward manner when the penalties for buying capacity are heterogeneous $\{B_1, \ldots, B_T\}$ (by replacing $B$ with $\min_{\tau\le t}B_\tau$ in the calculations of profit/penalty at period $t$ on line 7 of Algorithm~\ref{alg:FPTAS_nTlogn_large2}).

%The main idea is motivated by the technique that originated from~\cite{ibarra1975fast}, but adapting their technique to MPBKP requires significant modifications as we show in this Section. 

%\subsubsection*{Preparation}
\noindent \textbf{Preliminaries:} We first introduce some notation. From now on, let $\Rcal(\Scal):=\sum_{i\in\Scal}r_i$. The optimal solution set to~\eqref{MPBKP-S3} is denoted by $\mathcal{S}^*$. The total profit earned can be expressed as a function of the solution set $\mathcal{S}$:
\begin{align}
\Pcal(\mathcal{S}) = \Rcal(\Scal) - B\cdot \sum_{t=1}^T\left[\sum_{j\in \Scal\cap\mathcal{I}(t)}q_j-\max\left\{c_t-\sum_{j\in \Scal , d_j \leq t }q_j,\ c_t-c_{t-1}\right\}\right]^+.
\end{align}
Let $p_i$ be the profit of item $i$, which is defined as the profit earned if we select only $i$, i.e., $p_i = r_i-B \cdot \left(q_i-c_{d_i}\right)^+$. Without loss of generality, we assume that each item $i$ is by itself profitable, i.e., $p_i\ge 0$, so one profitable solution would be $\{i\}$. % This assumption is natural as otherwise there exists some item $i$ that will only bring down the profit if included in any solution, in which case we may simply discard that item when solving for the problem.
Let $P:=\max_{i}p_i$ and $\bar{P}:=\sum_{i\in[n]}p_i$. %Then since each item $i$ is profitable by itself, 
The following bounds on $\Pcal(\Scal^*)$  follow: 
\begin{align}\label{upperP}
P \leq \Pcal(\mathcal{S}^*)\le \bar{P} \leq nP.
\end{align}

%\subsubsection*{Partition of items}
\noindent \textbf{Partition of items:} We partition the set of items $[n]$ into two sets: a set of ``large'' items $\Ical_L$ and a set of ``small'' items $\Ical_S$ such that we can bound the number of large items in any optimal solution. The main idea is to use dynamic programming to pick the large items in the solution, and a greedy heuristic for `padding' this partial solution with small items.
The criterion for small and large items is based on balancing the permissible error $\epsilon \Pcal(\Scal^*)$ equally in filling large items and filling small items. Instead of first packing all large items and then all small items, we consider items in the order of their deadlines, and for each deadline $t$, the large items are selected first and then the small items are selected greedily in order of their reward densities. As a result, the approximation error due to large items overall will be $\frac{1}{2}\epsilon \Pcal(\Scal^*)$ and the error due to the small items with each deadline will be $\frac{1}{2T}\epsilon \Pcal(\Scal^*)$. This gives a total approximation error of $\frac{1}{2}\epsilon \Pcal(\Scal^*) + T\cdot \frac{1}{2T}\epsilon \Pcal(\Scal^*) = \epsilon \Pcal(\Scal^*)$.
%\subsection{An alternative FPTAS: separation of items}\label{sec:alter2}
%As in Section~\ref{sec:alter}, we propose in this subsection another FPTAS with time complexity $\mathcal{O}\left(\frac{Tn\log n}{\epsilon^2}\right)$. The algorithms we propose will be similar to Algorithms~\ref{alg:FPTAS_nTlogn_large},~\ref{alg:FPTAS_nTlogn_small},~\ref{alg:FPTAS_nTlogn}, and~\ref{alg:FPTAS_enumerate}. 

Suppose that we can find some $P_0$ that satisfies~\eqref{P0}. \begin{align}\label{P0}
P_0\le \Pcal(\mathcal{S}^*)\le 2P_0.
\end{align}
Then, the set of items is partitioned as follows.
\begin{equation}\label{div2}
\begin{aligned}
\Ical_L := \left\{i\in[n]\mid p_i\ge \frac{1}{2T}\epsilon P_0\right\}; \qquad 
\Ical_S := \left\{i\in[n]\mid p_i< \frac{1}{2T}\epsilon P_0\right\}.
\end{aligned}
\end{equation}

This partition is computed in $\mathcal{O}(n)$ time and is not the dominant term in time complexity. Let $n_L = |\Ical_L|$ and $n_S=|\Ical_S|$, so that $n_L+n_S=n$. 
Further, let 
\begin{align*}
\mathcal{I}_L(t) := \left\{i\in \Scal_L\mid d_i = t\right\}, \quad  \mbox{and} \quad 
\mathcal{I}_S(t) := \left\{i\in \Scal_S\mid d_i = t\right\}
\end{align*}
denote the set of large and small items, respectively, with deadline $t$. 
We will assume that the items in $\Ical_L$ are indexed in non-decreasing order of their deadlines, i.e., $\forall i,j\in \Ical_L$ such that $j\ge i$, we have that $ d_i\le d_j$. Denote by $I_L(t)$ as the index of the last item with deadline $t$, i.e., $I_L(t):= \max_{i\in \Scal_L\cap \mathcal{I}_L(t)} i$. 
For each time $t$, we will also sort the small items in $\mathcal{I}_S(t)$ according to their reward densities, i.e., $\forall i<j$ and $i,j\in \mathcal{I}_S(t)$, $\frac{r_i}{q_i}\ge \frac{r_j}{q_j}$. This sorting only takes place once for each guess $P_0$, and does not affect our overall time complexity result. \\



\begin{algorithm}[ht]
\footnotesize
\caption{DP on large items for MPBKP-S}
\label{alg:FPTAS_nTlogn_large2}
\algsetblock[Name]{Parameters}{}{0}{}
\algsetblock[Name]{Initialize}{}{0}{}
\algsetblock[Name]{Define}{}{0}{}
\begin{algorithmic}[1]
	\Statex \textbf{Input:} $\ \Ical_L, \Delta c,$  \Comment Set of (large) items to be packed, additional capacity available for packing
	\Statex \hspace{0.35in}	$\widetilde{A}(p)$ for all $p = \left\{ 0, 1, \ldots,\left\lceil\frac{16T}{\epsilon^2}\right\rceil \right\} \cdot \kappa $ \Comment A set of partial solutions 
	\Statex \textbf{Output:} $\hat{A}(I_L,p)$ for all $p = \left\{ 0, 1, \ldots,\left\lceil\frac{16T}{\epsilon^2}\right\rceil \right\} \cdot \kappa $ \Comment Set of partial solutions after packing $\Ical_L$
	\State Initialize $\forall p \ : \ \hat{A}(0,p) := \widetilde{A}(p) + \Delta c$	
	\For {$i=1,\ldots, I_L$}
	\For {$p = \left\{ 0, 1, \ldots,\left\lceil\frac{16T}{\epsilon^2}\right\rceil \right\} \cdot \kappa $}
	\State $\hat{A}(i,p) := \hat{A}(i-1, p)$ 
	\Comment If reject item $i$
	\EndFor
	\For {$\bar{p} = \left\{ 0, 1, \ldots,\left\lceil\frac{16T}{\epsilon^2}\right\rceil \right\} \cdot \kappa $}
	\State ${p} = \bar{p} + \hat{r}_i - \left\lceil B\left(q_i - {\color{black}\max\left\{0, \hat{A}(i-1,\bar{p})\right\}}\right)^+\right\rceil_{\kappa}$
	\State $\hat{A}(i, p) = \max\left\{ \hat{A}(i,p ), \hat{A}(i-1,\bar{p}) - q_i \right\}$		\Comment Accept $i$
	\EndFor
	\For{$p = \left\{\left\lceil\frac{16T}{\epsilon^2}\right\rceil,\left\lceil\frac{16T}{\epsilon^2}\right\rceil-1,\ldots,1  \right\}\cdot \kappa$}
	\vspace{0.1cm}
	\If {$\hat{A}(i,p-\kappa)<\hat{A}(i,p)$}
	\vspace{0.1cm}
	\State $\hat{A}(i,p-\kappa) = \hat{A}(i,p)$
	\EndIf
	\EndFor
	\EndFor
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[h]
\footnotesize
\caption{Greedy on small items for MPBKP-S}
\label{alg:FPTAS_nTlogn_small2}
\algsetblock[Name]{Parameters}{}{0}{}
\algsetblock[Name]{Initialize}{}{0}{}
\algsetblock[Name]{Define}{}{0}{}
\begin{algorithmic}[1]
	\Statex \textbf{Input:} $\ \Ical_S$, $\hat{A}(p)$ for all $p = \left\{ 0, 1, \ldots,\left\lceil\frac{16T}{\epsilon^2}\right\rceil \right\} \cdot \kappa $.  \Comment Set of (small) items to be packed, a set of partial solutions
	\Statex \textbf{Output:} $\widetilde{A}(p)$ for all $p = \left\{ 0, 1, \ldots,\left\lceil\frac{16T}{\epsilon^2}\right\rceil \right\} \cdot \kappa $ \Comment Set of partial solutions after packing $\Ical_S$
	\State Initialize $\forall p \ : \ \widetilde{A}(p) = \hat{A}(p)$ 
	\For {$\bar{p}=\left\{ 0, 1, \ldots,\left\lceil\frac{16T}{\epsilon^2}\right\rceil \right\} \cdot \kappa$}
	\Statex  \texttt{// Filter out small items with size larger than $\hat{A}(p)$ } 
	%\State Sort the items in $\mathcal{I}_S(t)$ in decreasing order of reward density $r_i/q_i$
	\State $\widetilde{\mathcal{I}}_S\gets\emptyset$
	\For {$i\in \mathcal{I}_S$}
	\If {$\hat{A}(\bar{p}) \geq q_i$}
	%\State $\Delta p_{i} = r_{i} - B\cdot \left(q_{i}-\hat{A}(I_L(t),p)\right)$
	\State $\widetilde{\mathcal{I}}_S\gets \widetilde{\mathcal{I}}_S\cup \{i\}$
	\EndIf
	\EndFor
	
	
	
	\State $\tilde{\Rcal}_{0'} = 0, \tilde{q}_{0'} = 0$, and relabel the items in $\widetilde{\mathcal{I}}_S$ as $\left\{1',\ldots,|\widetilde{\mathcal{I}}_S|'\right\}$ (in decreasing order of reward density)
	\For {$i' = 1',\ldots, |\widetilde{\mathcal{I}}_S|'$}
	\State  $\tilde{\Rcal}_{i'} = \tilde{\Rcal}_{(i-1)'} + r_{i'}$
	\State  $\tilde{q}_{i'} = \tilde{q}_{(i-1)'} + q_{i'}$
	\EndFor
	
	\State {\texttt{// Add small items using Greedy algorithm}}
	\For {$i' = 1',\ldots, |\widetilde{\mathcal{I}}_S|'$}
	\If {$\tilde{q}_{i'} \leq \hat{A}(\bar{p})$}
	\State $p = \left\lfloor \bar{p} + \tilde{\Rcal}_{i'}\right\rfloor_\kappa$
	\State $\widetilde{A}({p}) = \max\left\{\widetilde{A}(p) , \hat{A}(\bar{p}) - \tilde{q}_{i'}  \right\}$
	\EndIf
	\EndFor
	\EndFor 
\end{algorithmic}
\end{algorithm}


\begin{algorithm}[ht]
\footnotesize
\caption{DP on large items and Greedy on small items for MPBKP-S}
\label{alg:FPTAS_nTlogn2}
\algsetblock[Name]{Parameters}{}{0}{}
\algsetblock[Name]{Initialize}{}{0}{}
\algsetblock[Name]{Define}{}{0}{}
\begin{algorithmic}[1]
	\Define \ $\kappa = \frac{\epsilon^2 P_0 }{8T}$
	\Define \ $\hat{r}_i = \floor{ {r_i} }_\kappa$ \Comment Round down reward
	\Statex  \texttt{// $\widetilde{A}_t(p)=$ leftover capacity for the algorithm's partial solution when earning (rounded) profit $p$ using items with deadlines at most $t$ (small and large)} %and rounded down supply
	\Statex  \texttt{// $\hat{A}_t(p)=$ capacity left for the algorithm's partial solution when earning (rounded) profit $p$ by selecting large items in $\mathcal{I}_L(t)$ with rounded down rewards $\hat{r}$, given the partial solutions $\widetilde{A}_{t-1}(p)$}
	\State Initialize $\hat{A}(0,p) = \widetilde{A}_0(p) = \begin{cases}
	0 & p = 0,\\
	-\infty & p > 0.
	\end{cases}$
	\For {$t=1,\ldots, T$}
	\State Run Algorithm~\ref{alg:FPTAS_nTlogn_large2} with $\Ical_L = \Ical_L(t), \Delta c = c_t - c_{t-1}$, and $\widetilde{A}(p)=\widetilde{A}_{t-1}(p)$ for all $p = \left\{ 0, 1, \ldots,\left\lceil\frac{16T}{\epsilon^2}\right\rceil \right\} \cdot \kappa $, and obtain $\hat{A}_t(p):= \hat{A}(I_L,p)$ for all $p$.
	\State Run Algorithm~\ref{alg:FPTAS_nTlogn_small2} with $\Ical_S=\Ical_S(t)$ and $\hat{A}(p) = \hat{A}(I_L(t),p)$ for all $p = \left\{ 0, 1, \ldots,\left\lceil\frac{16T}{\epsilon^2}\right\rceil \right\} \cdot \kappa $, and obtain $\widetilde{A}_{t}(p):=\widetilde{A}(p)$ for all $p$.
	\EndFor
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[ht]
\footnotesize
\caption{FPTAS for MPBKP-S in $\mathcal{O}(Tn\log n/\epsilon^2)$}
\label{alg:SC_FPTAS}
\algsetblock[Name]{Parameters}{}{0}{}
\algsetblock[Name]{Initialize}{}{0}{}
\algsetblock[Name]{Define}{}{0}{}
\begin{algorithmic}[1]
	\State $P_0\gets {\bar{P}}$
	\State $p^*\gets 0$
	\While {$p^*<(1-\epsilon)P_0$}
	\vspace{0.1cm}
	\State $P_0\gets \frac{P_0}{2}$
	\vspace{0.1cm}
	\State	Run Algorithm~\ref{alg:FPTAS_nTlogn2} with the current $P_0$.
	\State $p^*\gets \max_{\left\{\substack{p\in \left\{ 0,\ldots,\left\lceil\frac{16T}{\epsilon^2}\right\rceil \right\} \cdot \kappa\\ \widetilde{A}_T(p)> -\infty}\right\}}p$
	\EndWhile
\end{algorithmic}
\end{algorithm}
%\subsubsection*{Overview of the algorithm}


\noindent \textbf{Algorithm overview:} Our FPTAS algorithm is given in Algorithm~\ref{alg:SC_FPTAS} which uses a doubling trick to guess the value of $P_0$ satisfying \eqref{P0}, and for each guess uses Algorithm~\ref{alg:FPTAS_nTlogn2} as a subroutine. Algorithm~\ref{alg:FPTAS_nTlogn2} is the main  algorithm for MPBKP-S, which first selects the items with deadline~$1$, then the items with deadline~$2$, and so on. 
For each deadline $t$, we maintain two sets of partial solutions: the first, $\widetilde{A}_t(p)$, corresponds to an approximately optimal (in terms of leftover capacity carried forward to time $t+1$) subset of large and small items with deadline at most $t$ and some \emph{rounded profit} $p$ %(precise definition of rounded profit will be given in~\eqref{Ptilde})
; and the second $\hat{A}_t(p)$ corresponds to the optimal appending of large items with deadline $t$ to the approximately optimal set of solutions corresponding to $\widetilde{A}_{t-1}$.

Given $\widetilde{A}_{t-1}$, we first select large items from $\mathcal{I}_L(t)$ using dynamic programming to obtain $\hat{A}_t$, which is done in Algorithm~\ref{alg:FPTAS_nTlogn_large2}. In other words, {\it given} the partial solutions $\widetilde{A}_{t-1}(\bar{p})$ for all $\bar{p} \in \left\{ 0, 1, \ldots,\left\lceil\frac{16T}{\epsilon^2}\right\rceil \right\} \cdot \kappa$, $\hat{A}_t(p)$ is the maximum capacity left when earning \emph{rounded profit} (precise definition given in~\eqref{Ptilde}) $p$ by adding items in $\mathcal{I}_L(t)$. We then use a greedy heuristic to pick small items from $\mathcal{I}_S(t)$ to obtain $\widetilde{A}_t$, which is done in Algorithm~\ref{alg:FPTAS_nTlogn_small2}. Specifically, our goal in Algorithm~\ref{alg:FPTAS_nTlogn_small2} is to obtain the partial solutions $\widetilde{A}_t(\cdot)$ given the partial solutions $\hat{A}_t(\cdot)$ by packing the small items $\Ical_S(t)$. We initialize $\widetilde{A}_t(\bar{p})$ with $\hat{A}_t(\bar{p})$, and for each $\bar{p}$ we try to augment the solution corresponding to $\hat{A}_t(\bar{p})$ using a subset $\widetilde{\mathcal{I}}_S(t) \subseteq \Ical_S(t)$ defined as $$\widetilde{\mathcal{I}}_S(t):= \{i\in \mathcal{I}_S(t)\mid q_i\le \hat{A}_t(\bar{p})\}.$$  The small items in $\widetilde{\mathcal{I}}_S(t)$ are sorted according to their reward densities, and are added to the solution of $\hat{A}_t(\bar{p})$ one by one. After each addition of a small item, if the new total rounded reward is ${p}$, we compare the leftover capacity with current $\widetilde{A}_t({p})$, and update $\widetilde{A}_t({p})$ with the new solution if it has more leftover capacity. We continue this add-and-compare (and possibly update) until we reach the situation where adding the next small item overflows the available capacity.  

\begin{comment}
We now give intuition behind Algorithms~\ref{alg:FPTAS_nTlogn_large2} and~\ref{alg:FPTAS_nTlogn_small2}, with the rigorous proofs left to the end of this section.
%Similar to the previous section, by letting $\kappa:= \frac{\epsilon^2P_0}{8T}$ and $\hat{r}_i := \kappa\left\lfloor\frac{r_i}{\kappa}\right\rfloor$, we have that $\Pcal(\Scal^*)\le 2P_0\le \left\lceil\frac{16}{\epsilon^2}\right\rceil\kappa$. Since the large items are selected using dynamic program (Algorithm~\ref{alg:FPTAS_nTlogn_large2}), it is straightforward to prove (as we do later) that {\it given} the partial solutions $\widetilde{T}_{t-1}(\bar{p})$ for all $\bar{p} \in \left\{ 0, 1, \ldots,\left\lceil\frac{16T}{\epsilon^2}\right\rceil \right\} \cdot \kappa$, $\hat{A}_t(p)$ is the maximum capacity left when earning rounded profit $p$ by adding items in $\mathcal{I}_L(t)$. 
The intuition for Algorithm~\ref{alg:FPTAS_nTlogn_large2} (selecting large items using dynamic program) is the following: {\it given} the partial solutions $\widetilde{A}_{t-1}(\bar{p})$ for all $\bar{p} \in \left\{ 0, 1, \ldots,\left\lceil\frac{16T}{\epsilon^2}\right\rceil \right\} \cdot \kappa$, $\hat{A}_t(p)$ is the maximum capacity left when earning some \emph{rounded profit} (precise definition given in~\eqref{Ptilde}) $p$ by adding items in $\mathcal{I}_L(t)$.

The intuition behind Algorithm~\ref{alg:FPTAS_nTlogn_small2} for packing small items is similar: Our goal is to obtain the partial solutions $\widetilde{A}_t(\cdot)$ given the partial solutions $\hat{A}_t(\cdot)$ by packing the small items $\Ical_S(t)$. We initialize $\widetilde{A}_t(\bar{p})$ with $\hat{A}_t(\bar{p})$, and for each $\bar{p}$ we try to augment the solution corresponding to $\hat{A}_t(\bar{p})$ using a subset $\widetilde{\mathcal{I}}_S(t) \subseteq \Ical_S(t)$ defined as $$\widetilde{\mathcal{I}}_S(t):= \{i\in \mathcal{I}_S(t)\mid q_i\le \hat{A}_t(\bar{p})\}.$$  The small items in $\widetilde{\mathcal{I}}_S(t)$ are sorted according to their reward densities, and are added to the solution of $\hat{A}_t(\bar{p})$ one by one. After each addition of a small item, if the new total rounded reward is ${p}$, we compare the leftover capacity with current $\widetilde{A}_t({p})$, and update $\widetilde{A}_t({p})$ with the new solution if it has more leftover capacity. We continue this add-and-compare (and possibly update) until we reach the situation where adding the next small item overflows the available capacity.  
\end{comment}

%We further note that these small items have to be added one by one to the solutions of $\hat{A}_t(\bar{p})$, which in the worst case takes $\Ocal\left(\frac{nT}{\epsilon^2}\right)$. We cannot first group the small items into sets of partial solutions and do $(\max,+)$ convolution with solution sets of $\hat{A}_t(p)$, which would take $\Ocal\left(\frac{T^2}{\epsilon^4}\right)$ (similar to~\cite{ibarra1975fast,lawler1979fast}), because again the profits of two sets do not add up when we take the union of these two sets. For this reason, although we could further bound the number of large items from $\Ocal(n)$ to $\Ocal\left(\frac{T}{\epsilon^2}\right)$ in a similar manner as~\cite{lawler1979fast}, we do not adopt that method as it does not improve the overall time complexity (since the bottleneck is on packing small items).

Intuitively, for any amount of capacity available to be filled by small items, and a minimum increase in profit, the optimal solution either packs a single item from $\Ical_S(t) \setminus \widetilde{\Ical}_S(t)$ in which case the loss by ignoring items in this set is bounded by the maximum reward of any small item, or the optimal solution only contains items from $\widetilde{\Ical}_S(t)$ in which case the space used by this optimal set of items is lower bounded by the a fractional packing of the highest density items in  $\widetilde{I}_S(t)$. During Algorithm~\ref{alg:FPTAS_nTlogn_small2}, one of the solutions we would consider would be the integral items of this fractional solution, and lose at most $\frac{1}{2T}\epsilon P_0$ in profit, and obtain a solution with still smaller space used (more leftover capacity) than the fractional solution. Accumulation of these errors for $t$ periods then will give us the invariant: the partial solution $\widetilde{A}_t(p)$ obtained as above has more leftover capacity than any solution obtained by selecting items from $\cup_{t'=1}^t \mathcal{I}_L(t')$ with rounded rewards and rounded penalties, and items from $\cup_{t'=1}^t \mathcal{I}_S(t')$ with original (unrounded) rewards such that the rounded total profit is at least $p+\frac{1}{2T}\epsilon P_0t+\kappa t$.


%Recall that we have assumed $R_0\le \Rcal(\Scal^*)\le 2R_0$. To find such an $R_0$, we would again enumerate $R_0$ from $\bar{R}/2, \bar{R}/4, \bar{R}/8,\ldots$, and one of them must satisfy~\eqref{R0}. This is done in Algorithm~\ref{alg:FPTAS_enumerate}. 
Our main theorem for the approximation ratio for MPBKP follows.

\begin{theorem}[Partially restating Theorem~\ref{mainthm2}]\label{main:MPBKP-S}
Algorithm~\ref{alg:SC_FPTAS} is a fully polynomial approximation scheme for the MPBKP-S, which achieves $(1+\epsilon)$ approximation ratio with running time $\mathcal{O}\left(\frac{Tn\log n}{\epsilon^2}\right)$.
\end{theorem}
\begin{comment}
\begin{remark}
Theorem~\ref{main:MPBKP-S}, together with Theorem~\ref{thm:FPTAS2}, implies that we can obtain a $(1-\epsilon)$ approximate solution for the MPBKP-S in $\mathcal{O}\left(\frac{n\log n}{\epsilon}\cdot\min\left\{\frac{T}{\epsilon},n\right\}\right)$, where Algorithm~\ref{alg:FPTAS2} is used when $T/\epsilon \gg n$ and Algorithm~\ref{alg:SC_FPTAS} is used when $T/\epsilon \ll n$.
\end{remark}


\begin{remark}
One may question if it is possible to achieve $\tilde{\Ocal}\left(n+T^\alpha/\epsilon^\beta\right)$ for some $\alpha,\beta$, as in the 0-1 Knapsack problem. We note that using a finer rounding technique as in~\cite{lawler1979fast}, the number of large items can be further bounded from $\Ocal(n)$ to $\Ocal\left(\frac{T}{\epsilon^2}\right)$, which would reduce the runtime of the DP (for large items) from $\Ocal\left(nT/\epsilon^2\right)$ to $\tilde{\Ocal}\left(n+T^2/\epsilon^4\right)$. However, the small items still have to be added one by one to the solutions of $\hat{A}_t(\bar{p})$, which in the worst case takes $\Ocal\left(\frac{nT}{\epsilon^2}\right)$. We cannot first group the small items into sets of partial solutions and do $(\max,+)$ convolution with solution sets of $\hat{A}_t(p)$, which would take $\Ocal\left(\frac{T^2}{\epsilon^4}\right)$ (similar to~\cite{ibarra1975fast,lawler1979fast}), because again the profits of two sets do not add up when we take the union of these two sets. Therefore, we do not further bound the number of large items as it does not improve the overall asymptotic time complexity (since the bottleneck is on packing small items).
\end{remark}
\end{comment}


\section{A greedy algorithm for a special case of MPBKP-SS}\label{sec:unit-MPBKP-SS}
In this subsection, we consider the special case of MPBKP-SS when all items have the same size, i.e., $q_i=q,\forall i\in[n]$. We again only present for the case $B_t = B,\forall t\in[T]$. We note that in the deterministic problems (MPBKP or MPBKP-S), when items all have the same size, greedily adding items one by one in decreasing order of their rewards leads to the optimal solution. For MPBKP-SS, as the capacities are now stochastic, we wonder if there is any greedy algorithm performs well. We propose Algorithm~\ref{alg:unitq-greedybyprofit}, where we start with an empty set, and greedily insert the item that brings the maximum increment on expected profit, and we stop if adding any of the remaining items does not increase the expected profit.

\begin{algorithm}[h]
	\footnotesize
	\caption{Greedy algorithm according to profit change}
	\label{alg:unitq-greedybyprofit}
	\algsetblock[Name]{Parameters}{}{0}{}
	\algsetblock[Name]{Initialize}{}{0}{}
	\algsetblock[Name]{Define}{}{0}{}
	\begin{algorithmic}[1]
		\State $\Scal\gets \emptyset$
		\State $s\gets 1$
		\While {$s == 1$}
		\State $i^*\gets \argmax_{i \notin\Scal}\left\{\Pcal(\Scal\cup\{i\})-\Pcal(\Scal)\right\}$
		\If {$\Pcal(\Scal\cup\{i^*\})-\Pcal(\Scal)\ge 0$}
		\State $\Scal\gets \Scal\cup\{i^*\}$
		\Else 
		\State $s\gets 0$
		\EndIf
		\EndWhile
		\State $\Scal_{p}\gets \Scal$
		\State {\bf Return} $\Scal_p$
	\end{algorithmic}
\end{algorithm}

Let $\Scal^*$ be an optimal solution, i.e.,
%\begin{align}\label{obj:unitsize}
$\Scal^* \in \arg\max_{\Scal\subseteq [n]} \Pcal(\Scal) := \Rcal(\Scal) - B\cdot \Phi(\Scal)$,
%\end{align}
where $$\Phi(\Scal) := \mathbb{E}\left\{\sum_{t=1}^T\left[\sum_{j\in \mathcal{I}(t)\cap\Scal}q_j-\max_{0\leq t' < t}\left\{ c_t - c_{t'}-\sum_{j  \in \Scal : t'+1 \leq d_j \leq t-1} q_j\right\}\right]^+ \right\}$$ is the expected quantity of overflow on set $\Scal$, and let $\Scal_p$ be the set output by Algorithm~\ref{alg:unitq-greedybyprofit}.
Then, we have the following theorem. 
\begin{theorem}[Restating Theorem~\ref{mainthm3}]\label{thm:GRprofit}
	Algorithm~\ref{alg:unitq-greedybyprofit} achieves $2$-approximation factor for MPBKP-SS when items have the same size, i.e., $\Pcal(\Scal_p) \ge \frac{1}{2}\Pcal(\Scal^*)$  in $\Ocal\left(n^2T|\Omega|\right)$.
\end{theorem}

The proof of the $2$-approximation could be more nontrivial than one may think. The idea is to look at the greedy solution set $\Scal_p$ and the optimal solution set $\Scal^*$,  where we will use the dual to characterize the optimal solution on each sample path. By swapping each item in $\Scal_p$ to $\Scal^*$ in replacement of the same item or two other items, we construct a sequence of partial solutions of the greedy algorithm as well as modified optimal solution set, while maintaining the invariant that the profit of $\Scal^*$ is bounded by the sum of two times the profit of items in $\Scal_p$ swapped into $\Scal^*$ so far and the additional profit of remaining items in the modified optimal solution set. We leave the formal proof of Theorem~\ref{thm:GRprofit} to Appendix~\ref{appc-unit}.


\section{Comments and Future Directions}\label{sec:conc}
The current work represents to the best of our knowledge the first FPTAS  for the two multi-period variants of the classical knapsack problem. For MPBKP, we obtained the runtime $\tilde{\Ocal}\left(n+(T^{3.25}/\epsilon^{2.25})\right)$. This was done via the function approximation approach, where a function is approximated for each period. The runtime increases in $T$ since we conduct $T$ number of rounding downs, one after each $(\max,+)$-convolution. An alternative algorithm with runtime $\tilde{\Ocal}\left(n+\frac{T^{2}}{\epsilon^{3}}\right)$ is also provided in Appendix~\ref{appT2}. Note that the function we approximated is in the same form as used in the 0-1 knapsack problem~\citep{chan:OASIcs:2018:8299}. It is thus interesting to ask if we could instead directly approximate the following function:
$$
f_{\Ical}(c) = \max_{x}\left\{\sum_{i\in\Ical}r_ix_i\ :\ \sum_{i\in\cup_{t'=1}^t\Ical(t')}q_ix_i\le c_t,\forall t\in[T],\ x\in\{0,1\}^n\right\},
$$
where $\Ical = \cup_{t=1}^T\Ical(t)$ and $c=\{c_1,\ldots,c_T\}$ is a $T$-dimensional vector. Here we impose all $T$ constraints in the function. The hope is that, if the above function could be approximated, and if we could properly define the $(\max,+)$-convolution on $T$ dimensional vectors (and have a fairly easy computation of it), then we may get an algorithm that depends more mildly on~$T$.

For MPBKP-S and MPBKP-SS, there seems to be less we can do without further assumptions. One direction to explore is  parameterized approximation schemes: assuming that in the optimal solution, the total (expected) penalty is at most~$\beta$ fraction of the total reward. Then we may just focus on rewards. Our ongoing work suggests that an approximation factor of $\left(1+\frac{\epsilon}{1-\beta}\right)$ may be achieved in $\tilde{\Ocal}\left(n+(T^{3.25}/\epsilon^{2.25})\right)$ for MPBKP-S, and the same approximation factor in $\tilde{\Ocal}\left(n+\frac{1}{\epsilon^{T}}\right)$ for MPBKP-SS. 

We further note that the objective function for the three multiperiod variants are in fact submodular (but not non-negative, or monotone). Whether we can get a constant competitive solution in time $\widetilde{\Ocal}(n)$, using approaches in submodular function maximization, is also an intriguing open problem. 

Finally, motivated by applications, one natural extension that the authors are working on now is when there is a general non-decreasing cost function $\phi_t(\Delta c)$ for procuring capacity $\Delta c$ at time $t$, and the goal is to admit a profit maximizing set of items when the unused capacity can be carried forward. Another extension is when there is a bound on the leftover capacity that can be carried forward.
	
 
	
	
	{\small
		\begin{spacing}{1.2}
			\bibliographystyle{apalike}
			\bibliography{references}
		\end{spacing}
	}
	
	
	\begin{appendix}
		\input{appendix.tex} 
		
	\end{appendix}
	
	
	
	%\end{document}  % This is where a 'short' article might terminate
	%\addtolength{\partopsep}{3mm}
	
	
	%\thispagestyle{empty}
	
	%\bibliography{sigproc}  % sigproc.bib is the name of the Bibliography in this case
	% You must have a proper ".bib" file
	%  and remember to run:
	% latex bibtex latex latex
	% to resolve all references
	%
	% ACM needs 'a single self-contained file'!
	%
	%APPENDICES are optional
	
\end{document}
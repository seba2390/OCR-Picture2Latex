
\subsection{Connection with Successor Feature}
Successor features (SF) \citep[e.g.,][]{barreto2017successor} consider reward functions that are linear combinations of a set of basis functions, i.e. $r_w = w^\top \phi$.
The successor feature $\psi_\pi$ for basis feature $\phi$ satisfies the Bellman equation:
\begin{equation}\label{eqn:sf_bellman}
    \psi_\pi(x) = \phi(x) + \gamma \Ppi[\psi_\pi](x).\,
\end{equation}
Similar to DQN, successor feature can be approximated by neural network and estimated by Fitted Q Iteration:
$$
\theta_{t+1}\gets \arg\min_{\theta} \{ \E_{x\sim \D, a'\sim \pi(\cdot|a')}[\|\psi_\theta(x) - \phi(x) - \gamma \psi_{\theta'}(s',a')\|^2] \}\,.
$$
By leveraging the corresponding successor feature $\psi_{\theta}\approx \psi_\pi$, the action value function $q_{\pi,r_w}$ can be approximated as $q_{\pi,r_w} \approx q_{\theta,r_w} = w^\top \psi_\theta$.

Given a reward function $r$, its corresponding coefficient $w$ is unknown. However, notice that once we are given the offline dataset $\D = \{x_i, r_i = r(x_i)\}$, the linear coefficient $w$ can be estimated by ordinary least square (OLS) with a closed form:
\begin{equation}\label{eqn:ols_w}
    \hat{w} = \left(\hat{\E}_{\D}[\phi(x)\phi(x)^\top]\right)^{-1} \hat{\E}_{\D}[\phi(x)r(x)]
    := \frac{\Sigma_{\phi}^{-1}}{n} \sum_{i=1}^n \phi(x_i)r(x_i),\,
\end{equation}

where $\Sigma_{\phi} := \hat{\E}_{\D}[\phi(x)\phi(x)^\top]$\footnote{For simplicity we assume $\Sigma_\phi$ is invertible, otherwise we can add an $\ell_2$ regularization term on $w$.}.
Plugging it into $q_{\theta, r_w}$, we have:
\begin{equation}\label{eqn:sf_operator_view}
    \hat{w}^\top \psi_\theta =  \frac{1}{1-\gamma}\sum_{i=1}^n \left(\frac{(1-\gamma)\Sigma_{\phi}^{-1}}{n}\phi(x_i)^\top \psi_\theta(x)\right) r(x_i)
    := \frac{1}{1-\gamma}\sum_{i=1}^n w(x_i|x) r(x_i),\,
\end{equation}
where $w(x_i|x) =: \frac{(1-\gamma)\Sigma_{\phi}^{-1}}{n}\phi(x_i)^\top \psi_\theta(x)$ can be linearly decomposed as vector value function with respect to $x_i$ and $x$.
Compared with linear design of $\Gpi$ in Eq.~\eqref{eqn:linear_design_gpi}, we can see that successor feature can be viewed as a special case with a fixed vector function $f(x_i) = \frac{(1-\gamma)\Sigma_{\phi}^{-1}}{n}\phi(x_i)$.


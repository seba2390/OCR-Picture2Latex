\section{Introduction}

Quantum Machine Learning (QML) is a rapidly growing, emerging field, with a diverse set of ideas and applications.
While there are significant differences in applications as to where Machine Learning and where Quantum Computing are applied, quantum-enhanced machine learning has become one of the dominant subfields~\cite{Dunjko2020,Wiebe2020,Guan_2021,Cerezo_2021}.
The main benefits of such algorithms are potential quantum speed-ups~\cite{Rebentrost2014,Biamonte2017,Huang_2021,Huang_2021B,Liu_2021}, and the potential of recognizing statistical patterns hard to learn with purely classical schemes~\cite{Schuld_2019b}. Recent work on QML has started to tackle the problems of trainability~\cite{McClean_2018,Beer_2020,marrero2021entanglement,Pesah2021} and the generalization error~\cite{Banchi2021,Du2022} of quantum models.

However, machine learning algorithms on near-term quantum devices face an issue of constrained resources.
While there exist encodings that efficiently use qubits, they still do not allow to load datasets such as MNIST in quantum memory, while additionally introducing overhead when encoding and decoding information between classical and quantum devices.
To counter that issue researchers have used two approaches.

One was to use synthetic or very small datasets that could be learned efficiently (as in eg.~\cite{Havl_ek_2019}).
This however makes any benchmarks artificial, and comparison to their classical counter-parts hard.
As potential performance benefits are the main driver of the quantum-enhanced machine learning, we believe that ease of comparison to classical machine learning should be one of the priorities in the field.

Second approach is to classically pre-process data, so it can fit in the limited space defining the quantum model (as in eg.~\cite{peters2021machine}).
While this approach allows for direct comparison to classical performance on the same data, it also requires to factor in what impact pre-processing had on performance of both algorithms.
It requires scientists to carefully prepare experiments to not give unfair advantages to either quantum or classical algorithms.
Lastly, since no two studies will use the same pre-processing there is additional overhead when comparing two different quantum-enhanced approaches, or performing meta-analysis of the field.

To combat these issues, we propose a standardized approach of designing hybrid (quantum and classical) models.
Similarly to how TensorFlow~\cite{tensorflow2015-whitepaper} and PyTorch~\cite{PyTorch} changed classical machine learning field and increased reproducibility of efforts, we propose Scaled QUantum IDentifier (SQUID)~\cite{squid}, which is an extensible framework which can incorporate quantum models.
As it is based on top of PyTorch, it has most of the benefits of a mature framework when it comes to purely classical architectures.
For quantum models, we provide a standardized model design where user has to implement forward- and back-propagation functions.

By doing so, the pre-processing algorithms can be standard across applications and approaches, making them more directly comparable.
It also reduces overhead on new researchers, as it significantly reduces the amount of coding required for an experiment.
Such mix of both worlds also resembles quantum-inspired algorithms~\cite{Dunjko2020}, which also benefit from above points.

The article is organized in following manner.
In Section~\ref{sec:squid} we outline the framework design and describe the relevant internal details.
In Section~\ref{sec:results} we show an example application of the model using the MNIST dataset, and study the impact of including information from single vs. all available output qubits. We describe the use of the SQUID Helpers package and possible future extensions in Sec.~\ref{sec:ext}. Finally, in Section.~\ref{sec:conclusions} we provide a summary and perspective.

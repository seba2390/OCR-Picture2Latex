\documentclass[journal,compsoc]{IEEEtran}
\usepackage{amsmath,amsfonts}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{array}
\usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\usepackage{textcomp}
\usepackage{stfloats}
\usepackage{color}
\usepackage{url}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{cite}
\usepackage{multirow}
%\usepackage{hyperref}
%\hypersetup{
%	colorlinks=true,
%	linkcolor=red,
%	urlcolor=blue,
%}
\usepackage{multicol}
\usepackage{ragged2e}
\usepackage{caption}
\captionsetup[table]{labelsep=space}

\begin{document}

\title{A Comprehensive Review of Image Line Segment Detection and Description: Taxonomies, Comparisons, and Challenges}

\author{Xinyu Lin,~\IEEEmembership{Student Member,~IEEE} \\
	Yingjie Zhou,~\IEEEmembership{Member,~IEEE}, 
	Yipeng Liu,~\IEEEmembership{Senior Member,~IEEE}, 	
	and Ce Zhu*,~\IEEEmembership{Fellow,~IEEE}% <-this % stops a space
	\newline
	\thanks{Xinyu Lin (xinyu.lin@std.uestc.edu.cn), Yipeng Liu, and Ce Zhu (* Corresponding author) are with the School of Information and Communication Engineering, University of Electronic Science and Technology of China (UESTC), Chengdu 611731, China. Yingjie Zhou is with the College of Computer Science, Sichuan University, Chengdu, Sichuan, China.}}

\IEEEtitleabstractindextext{
\justifying
\begin{abstract}
	Detection and description of line segments lay the basis for numerous vision tasks. Although many studies have aimed to detect and describe line segments, a comprehensive review is lacking, obstructing their progress. This study fills the gap by comprehensively reviewing related studies on detecting and describing two-dimensional image line segments to provide researchers with an overall picture and deep understanding. Based on their mechanisms, two taxonomies for line segment detection and description are presented to introduce, analyze, and summarize these studies, facilitating researchers to learn about them quickly and extensively. The key issues, core ideas, advantages and disadvantages of existing methods, and their potential applications for each category are analyzed and summarized, including previously unknown findings. The challenges in existing methods and corresponding insights for potentially solving them are also provided to inspire researchers. In addition, some state-of-the-art line segment detection and description algorithms are evaluated without bias, and the evaluation code will be publicly available. The theoretical analysis, coupled with the experimental results, can guide researchers in selecting the best method for their intended vision applications. Finally, this study provides insights for potentially interesting future research directions to attract more attention from researchers to this field.
\end{abstract}

\begin{IEEEkeywords}
	Line segment detection, Line segment description, Line segment matching, Local feature, Review
\end{IEEEkeywords}
}
\maketitle

%\tableofcontents

\section{Introduction}
\label{sec_intro}
\IEEEPARstart{A}{s} a typical two-dimensional (2D) local image feature \cite{local_feature}, line segments \cite{LSD} contain more structural and geometric features about the scene than points \cite{SIFT,FASTER,8883063}, as shown in Fig. \ref{point_line_edge_demo}. In addition, they have the advantage of compact data expression and can completely support multiview geometry theory \cite{MultipleViewGeometryinComputerVision} in 2D and three-dimensional (3D) spaces compared with edges \cite{Canny,6975234}. Because of these excellent characteristics, line segments are widely used in numerous vision tasks, such as visual measurement \cite{1512061}, camera pose estimation \cite{w-MSAC,our_demo,PoseEstimationfromLineCorrespondencesACompleteAnalysisandaSeriesofSolutions,9969132}, visual odometry (VO) \cite{7898369,8691513}, visual simultaneous mapping and localization (V-SLAM) \cite{6193110,9521742}, and structure from motion (SFM) \cite{8395064}. In these vision tasks, line segments lay the foundation for other processes by providing line segment correspondences (matches) in different images containing the same scene.

\begin{figure}[tbp]
	\centering
	\includegraphics[width=0.49\textwidth]{figures/point_line_edge_demo.pdf}
	\caption{Local image features on a test image: (b) SIFT interest points \cite{SIFT}, (c) LSD line segments \cite{LSD}, and (d) Canny edges \cite{Canny}. Line segments contain more structural and geometric features about a scene than points and are more compact in data expression than edges.}
	\label{point_line_edge_demo}
\end{figure}

Generally, line segment matches are obtained through the following two steps. Line segments are first detected in images using developed detectors and then described by designed descriptors, which can be regarded as the signatures of line segments and matched by their descriptor similarity. Many line segment detection and description algorithms have been designed in recent decades. However, unlike well-reviewed points \cite{TPAMI_Interest_Point_Survey,LI2015736,10.1007/s11263-020-01359-2} and edges \cite{JING2022259,10.3389/frsip.2022.826967,1097737}, no comprehensive review is available that systematically analyzes and summarizes them, making them difficult for researchers to fully visualize and deeply understand. Specifically, (1) it is difficult and  time-consuming for researchers to determine the complex relationship among these algorithms, their key issues, core ideas, advantages and disadvantages, and potential applications. Although many studies have been proposed to robustly detect and describe line segments from images, some common challenges and unsolved problems remain in this field. (2) Almost all these studies reported that their approaches perform the "best" regarding their designed experiments, making it difficult for researchers to select a suitable line segment detection and description method for their intended applications. (3) Furthermore, compared with well-studied point features, research on line segment detection and description is ongoing, and more interesting future research directions need to be explored.

\begin{figure*}[tbp]
	\centering
	\includegraphics[width=1\textwidth]{figures/structure3.pdf}
	\caption{The structure of this review and high-level taxonomies of existing line segment detection and description methods.}
	\label{line_segment_taxonomy}
\end{figure*}

This study addresses the problems above by comprehensively reviewing numerous line segment detection and description algorithms to provide researchers with an overall picture and deep understanding of them. The contributions of this study are summarized as follows.

\begin{itemize}
	\item As shown in Fig. \ref{line_segment_taxonomy}, two taxonomies introducing and analyzing numerous line segment detection and description methods are presented according to their mechanisms, facilitating researchers to learn about these methods quickly and extensively.
	
	\item For the methods in each category, their key issues, core ideas, advantages and disadvantages, and potential applications are analyzed and summarized, including some previously unknown findings.
	
	\item The challenges in existing line segment detection and description methods and corresponding insights for potentially dealing with them are also provided to inspire researchers.
	
	\item An unbiased performance evaluation is performed for various state-of-the-art (SOTA) line segment detection and description methods based on natural and synthetic datasets. The theoretical analysis, coupled with the quantitative experimental results, can guide researchers in selecting an appropriate line segment detection and description method for their intended applications. The evaluation code (\url{https://github.com/roylin1229/line_segment_review}) will be released publicly, facilitating researchers to evaluate their developed algorithms and test other methods.
	
	\item Since the research on line segment detection and description is in development, this study provides some insights for potentially interesting future research directions to attract more attention from researchers to this field.
\end{itemize}

The rest of this review is organized as shown in Fig. \ref{line_segment_taxonomy}. A high-level overview of line segment detection and description is introduced in Section \ref{sec_high_level_overview}. Section \ref{sec_line_detection} and Section \ref{sec_line_description} review numerous line segment detection and description methods, respectively. Numerical experiments on natural and synthetic datasets are performed in Section \ref{sec_performance}. Section \ref{research_directions} provides some insights for potentially interesting future research directions. Section \ref{sec_conclusion} summarizes the conclusions.




\section{High-level Overview of Line Segment Detection and Description}
\label{sec_high_level_overview}
Line segments generally appear in image regions where the image feature has a trend and significant variance, as shown in Fig. \ref{point_line_edge_demo} (c). They are not dependent on specific objects and scenarios and are widely used in various vision tasks. They can be expressed by line segment endpoints or the combination of line segment midpoints, radii, and angles.

\subsection{Line Segment Properties}
\label{subsec_ls_properties}
As a typical local image feature \cite{local_feature}, line segments should have the following properties:
\begin{itemize}
	\item \textbf{Repeatability}: The most critical line segment property is the ability to be repeatedly detected, described, and matched in multiple images containing the same scene, which is essential for vision tasks that require the establishment of line segment correspondences between these images.
	
	\item \textbf{Distinctiveness}: The second line segment property is the ability to be uniquely identified and distinguished from other features in an image.
	
	\item \textbf{Accuracy}: The line segments should be detected accurately in an image, including the location of endpoints, related orientations, and scales.
	
	\item \textbf{Robustness and Stability}: The line segments should be robustly and stably detected, described, and matched among images with different imaging conditions, such as image noise, occlusion, rotation, scale, illumination, and viewpoint.
	
	\item \textbf{Efficiency}: The detection and description of line segments should be efficient regarding computational complexity and memory usage since they serve as the foundation for numerous vision tasks, particularly in resource-limited systems and platforms.
	
	\item \textbf{Quantity}: The detected and matched line segments (based on line segment description) should satisfy the requirements of specific vision tasks.
\end{itemize}

Line segments typically contain more structural and geometric information about a scene than point features. Consequently, their locality \cite{local_feature} may be slightly compromised compared to point features, as they are often detected within a larger image region.

\subsection{High-level Taxonomies}
\label{subsec_high_level_taxonomy}
As mentioned above, line segments form the basis for vision tasks by establishing matches across different images, typically achieved in two critical steps: first detecting and then describing line segments. After decades of development, numerous line segment detection and description algorithms have been proposed. According to the mechanism of existing line segment detection methods, they can be roughly classified into four categories, as shown in Fig. \ref{line_segment_taxonomy}.

\begin{enumerate}
	\item \textbf{Global Hough-based} methods \cite{METHODANDMEANSFORRECOGNIZINGCOMPLEXPATTERNS,UseoftheHoughTransformationtoDetectLinesandCurvesinPictures,GeneralizingtheHoughtransformtodetectarbitraryshapes,35497,HoughTransformfromtheRadonTransfor,CompletelinesegmentdescriptionusingtheHoughtransform,AfastHoughtransformforsegmentdetection,Houghtransformmodifiedbylineconnectivityandlinethickness,CompletedescriptionofmultiplelinesegmentsusingtheHoughtransform,RobustDetectionofLinesUsingtheProgressiveProbabilisticHoughTransform,AccurateandRobustLineSegmentExtractionbyAnalyzingDistributionaroundPeaksinHoughSpace,ExtendedHoughtransformforlinearfeaturedetection,OnStraightLineSegmentDetection,AnImprovedHoughTransformNeighborhoodMapforStraightLineSegments,CollinearSegmentDetectionUsingHTNeighborhoods,Connectivity-EnforcingHoughTransformfortheRobustExtractionofLineSegments,AnAccurateMethodforLineDetectionandManhattanFrameEstimation,AStatisticalMethodforLineSegmentDetection,AccurateandRobustLineSegmentExtractionUsingMinimumEntropyWithHoughTransform,ClosedFormLineSegmentExtractionUsingtheHoughTransform,Bachiller2017} exploit the duality between points and curves in the image and Hough spaces to detect line segments, in which the line segment detection problem in the image space is transformed into a peak statistic problem in the Hough space. (subsection \ref{subsec_detection_hough})
	
	\item \textbf{Local-based} methods with subcategories of gradient grouping-based and edge fitting-based approaches leverage the consistent image features in local regions to detect line segments, followed by merging and validation processes to improve line segment quality. \textbf{Gradient grouping-based} methods \cite{ExtractingStraightLines,Token-basedextractionofstraightlines,Findinglinesegmentsbystickgrowing,LSD,LSDaLineSegmentDetector,Linesegmentdetectionusingweightedmeanshiftproceduresona2Dslicesamplingstrategy,AParameterlessLineSegmentandEllipticalArcDetectorwithEnhancedEllipseFitting,MultiscalelinesegmentdetectorforrobustandaccurateSfM,JointAContrarioEllipseandLineDetection,ANovelLineletBasedRepresentationforLineSegmentDetection,FSG,PLSD,AG3line,FastLineSegmentDetectionandLargeSceneAirportDetectionforPolSAR,ALineSegmentDetectorforSpaceTargetImagesRobusttoComplexIllumination} group image regions with highly consistent gradient orientations or magnitudes to detect line segments. \textbf{Edge fitting-based} methods \cite{Extractionofstraightlinesinaerialimages,ASimpleandRobustLineDetectionAlgorithmBasedonSmallEigenvalueAnalysis,EDLines,Robustlinedetectionusingtwoorthogonaldirectionimagescanning,Outdoorplacerecognitioninurbanenvironmentsusingstraightlines,CannyLines,OTLines,LB-LSD,PropertySimilarityLineSegmentDetector,ELSED,Ultrafastlinedetector, E2LSD,ANovelPixelOrientationEstimationBasedLineSegmentDetectionFrameworkandItsApplicationstoSARImages} detect line segments by fitting highly consistent edge points. (subsection \ref{subsec_local_based})

	\item \textbf{Learning-based} methods with \textbf{line segment} \cite{Sem-LSD,LearningAttractionFieldRepresentationforRobustLineSegmentDetection,LearningtoCalibrateStraightLinesforFisheyeImageRectification,TP-LSD,LGNN,L2D2,FullyConvolutionalLineParsing,TowardsRealtimeandLightweightLineSegmentDetection,ULSD,WGLSM,SOLD2,Superline,LineSegmentDetectionUsingTransformerswithoutEdges,LearningRegionalAttractionforLineSegmentDetection,ELSD,SelfsupervisedLightweightLineSegmentDetectorandDescriptor} and \textbf{wireframe} (with more than one line segment and the corresponding junction) \cite{LearningtoParseWireframesinImagesofMan-MadeEnvironments,WireframeParsingWithGuidanceofDistanceMap,PPGNet,End-to-EndWireframeParsing, LearningtoReconstruct3DManhattanWireframesFromaSingleImage,Holistically-AttractedWireframeParsing,Hole-robustWireframeDetection,SemanticRoomWireframeDetectionfromaSingleView} detection subcategories learn the line segment or wireframe patterns by designing networks and loss functions in carefully prepared training and testing datasets. (subsection \ref{subsec_detection_learning})
		
	\item \textbf{Hybrid-based} methods \cite{MCMLSD,DeepHoughTransformLinePriors,LinedetectionviaalightweightCNNwithaHoughlayer,LSDNet,DeepLSD} incorporate multiple mechanisms to detect image line segments. The fundamental idea behind these approaches is to amalgamate the strengths of multiple mechanisms to overcome the drawback of the specific mechanism. These approaches provide a high degree of flexibility for customization. (subsection \ref{subsec_hybrid})
\end{enumerate}

Existing line segment description methods can be roughly classified into three categories according to the mechanism, as shown in Fig. \ref{line_segment_taxonomy}.
\begin{enumerate}
	\item \textbf{Statistic-based} methods with \textbf{gradient statistic-based} \cite{HLD,MSLD,Extendpointdescriptorsforlinecurveandregionmatching,Anoveldescriptorforline(curve)matching,FastLineDescriptionforLinebasedSLAM,Matchingofstraightlinesegmentsfromaerialstereoimagesofurbanareas,LineMatchingUsingAppearanceSimilaritiesandGeometricConstraints,LBD,Scaleinvariantlinedescriptorsforwidebaselinematching,Arobustlinematchingmethodbasedonlocalappearancedescriptorandneighboringgeometricattributes,RemoteSensingImageRegistrationwithLineSegmentsandTheirIntersections,LineSegmentMatchingFusingLocalGradientOrderandNonLocalStructureInformation,ALineDescriptorforSLAM,IILB} and \textbf{intensity statistic-based} subcategories \cite{Widebaselinestereomatchingwithlinesegments,Scaleinvariantlinedescriptorsforwidebaselinematching,Twoviewlinematchingalgorithmbasedoncontextandappearanceinlowtexturedimages,Arobustlinematchingmethodbasedonlocalappearancedescriptorandneighboringgeometricattributes,ALineMatchingMethodBasedonMultipleIntensityOrderingwithUniformlySpacedSampling,LineSegmentMatchingFusingLocalGradientOrderandNonLocalStructureInformation,IILB} exploit the statistic features, \textit{e.g.}, the histogram of gradients, or pixel intensities in line regions of support (ROSs) to encode line segments. A few of them \cite{Scaleinvariantlinedescriptorsforwidebaselinematching,Arobustlinematchingmethodbasedonlocalappearancedescriptorandneighboringgeometricattributes,LineSegmentMatchingFusingLocalGradientOrderandNonLocalStructureInformation,IILB} leverage both gradients and intensities to formulate descriptors. (subsection \ref{subsec_description_statistic})
		
	\item \textbf{Structure-based} methods with \textbf{local line segment-assisted} \cite{Linepatternretrievalusingrelationalhistograms,WidebaselineimagematchingusingLineSignatures,Robustaffineinvariantlinematchingforhighresolutionremotesensingimages,Anovelsimilarityinvariantlinedescriptorforgeometricmapregistration,NovelSimilarityInvariantLineDescriptorandMatchingAlgorithmforGlobalMotionEstimation,Twoviewlinematchingalgorithmbasedoncontextandappearanceinlowtexturedimages,AutomaticRegistrationMethodforOpticalRemoteSensingImageswithLargeBackgroundVariationsUsingLineSegments,MultimodalImageRegistrationWithLineSegmentsbySelectiveSearch} and \textbf{line intersection context-assisted} subcategories \cite{Anovellinematchingmethodbasedonintersectioncontext,Simultaneouslinematchingandepipolargeometryestimationbasedontheintersectioncontextofcoplanarlinepairs,LineMatchinginWideBaselineStereoATopDownApproach,Widebaselinestereomatchingbasedonthelineintersectioncontextforrealtimeworkspacemodeling,RobustLineMatchingBasedonRay-Point-RayStructureDescriptor,HierarchicalLineMatchingBasedonLineJunctionLineStructureDescriptorandLocalHomographyEstimation,Linesegmentmatchingandreconstructionviaexploitingcoplanarcues} use additional local line segments to structurally describe the relative relationships among them. (subsection \ref{subsec_description_structure})
		
	\item \textbf{Learning-based} methods with \textbf{line ROS-based} \cite{Abinaryrobustlinedescriptor,DLD,WLD,L2D2,Towardslearninglinedescriptorsfrompatchesanewparadigmandlargescaledataset} and \textbf{nonline ROS-based} subcategories \cite{LearnableLineSegmentDescriptorforVisualSLAM,SOLD2,Superline,LineasaVisualSentenceContextAwareLineDescriptorforVisualLocalization,ELSD,LDAM} learn the line segment representations locally or globally based on designed networks with loss functions regarding prepared training and testing datasets. (subsection \ref{subsec_description_learning})
\end{enumerate}

Note that multiple line segment descriptors can be combined to improve the description ability, as in \cite{Twoviewlinematchingalgorithmbasedoncontextandappearanceinlowtexturedimages}. Additionally, according to the data expression, these descriptors can be classified into binary and float descriptors. Except for the descriptors in \cite{Abinaryrobustlinedescriptor,IILB} and the binary version of \cite{LBD} in OpenCV, almost all other line segment descriptors are float descriptors.

\subsection{Generic Challenges}
\label{subsec_generic_challenges}
Despite numerous studies aimed at detecting and describing line segments from images, certain generic challenges remain in this field. Specifically,
\begin{itemize}
	\item \textbf{Unstable endpoints of line segments}. The first general challenge for line segment detection and description is that the endpoints of detected line segments are generally unstable due to many factors, such as image noise, occlusion, and illumination variance. This makes the line segment description and matching difficult since the corresponding line ROS or neighborhood relationship among line segments is generated according to the line segment endpoints.
		
\item \textbf{Imperfect detection and description methods}. The objective of line segment detection and description algorithms is to exhibit the diverse properties mentioned in subsection \ref{subsec_ls_properties} that line segments are expected to possess. However, it is frequently observed that numerous algorithms demonstrate exceptional performance in only one or some aspects. Therefore, discovering line segment detection and description algorithms that can simultaneously meet the multiple property requirements of line segments, such as accuracy, repeatability, robustness, and efficiency, mentioned in subsection \ref{subsec_ls_properties}, is challenging.
		
\item \textbf{Unsatisfactory performance in challenging scenarios.} Line segment detection and description usually perform unsatisfactorily in extremely challenging scenarios, including those with significant changes in illumination, wide variations in viewpoint, low texture scenes, and highly repetitive environments.
\end{itemize}




\section{Line Segment Detection Review}
\label{sec_line_detection}
This section reviews numerous line segment detection methods. As introduced above, these detection methods can be roughly classified into four categories: (1) global Hough-based methods (subsection \ref{subsec_detection_hough}), (2) local-based methods (subsection \ref{subsec_local_based}) with subcategories of gradient grouping-based and edge fitting-based approaches, (3) learning-based methods (subsection \ref{subsec_detection_learning}) with line segment and wireframe detection subcategories, and (4) hybrid methods (subsection \ref{subsec_hybrid}). First, this section introduces a subset of notable approaches from each category. Subsequently, an analysis and summary of the algorithms within each category are presented to provide a thorough understanding of them.

These detection methods have advantages, disadvantages, and positive applications, as summarized in TABLE \ref{line_segment_detection_comparsion} and analyzed in subsection \ref{subsec_detection_pro_cons}. The insights for potentially addressing the challenges in these methods are presented to inspire researchers, as detailed in subsection \ref{subsec_detection_challenges}. TABLE \ref{line_detection_implementation} lists some open-source implementations of line segment detection methods. Fig. \ref{detection_visualization} visually shows examples of line segments detected by six methods in four categories.

\subsection{Global Hough-based Approaches}
\label{subsec_detection_hough}

\begin{figure}[tbp]
	\centering
	\includegraphics[width=0.49\textwidth]{figures/hough_line.pdf}
	\caption{(a) - (b): The example in \cite{ExtendedHoughtransformforlinearfeaturedetection} shows the ideal Hough transformation in the Cartesian coordinate system. Two points $A(x_n, y_n)$ and $B(x_m, y_m)$ on a line $y=\alpha_lx+\beta_l$ in the image space correspond to two lines $\beta=-\alpha x_n + y_n$ and $\beta=-\alpha x_m + y_m$ in the Hough space, and they intersect at a point $C(\alpha_l, \beta_l)$. (c) - (d): The example shows the ideal Hough transformation in the polar coordinate system. Four points on a line in the image space correspond to four curves in the Hough space, and they intersect at a point.}
	\label{hough_line}
\end{figure}

\subsubsection{Hough Approach in the Polar Coordinate System}
Hough first proposed the Hough transformation \cite{METHODANDMEANSFORRECOGNIZINGCOMPLEXPATTERNS} and applied it to line detection. In the Cartesian coordinate system, a line $y=\alpha x + \beta$ in the image space corresponds to a point $(\alpha, \beta)$ in the Hough space, and vice versa. As shown in Fig. \ref{hough_line} (a) and (b), some points on a line in the image space correspond to some lines in the Hough space, and they intersect at a point. The lines can be detected by searching for the intersection point in the Hough space.

The approach in \cite{METHODANDMEANSFORRECOGNIZINGCOMPLEXPATTERNS} has a singularity problem. When lines in the image space are orthogonal to the $x$-axis, there are no intersecting points in the Hough space, meaning that the vertical lines cannot be detected. To address this issue, Duda et al. utilized the polar coordinate system to replace the Cartesian coordinate system for the Hough transformation \cite{UseoftheHoughTransformationtoDetectLinesandCurvesinPictures}, eliminating the singularity problem. A point in the image space can be transformed into a curve in the Hough space by leveraging the polar coordinate transformation $\rho = x cos \theta + y sin \theta$ and vice versa. As shown in Fig. \ref{hough_line} (c) and (d), some points on a line in the image space correspond to some curves in the Hough space, intersecting with each other at a point. Similarly, the lines can be detected by searching the intersecting point (peak) in the Hough space.

\subsubsection{Related Studies}
Based on \cite{UseoftheHoughTransformationtoDetectLinesandCurvesinPictures}, many related studies have been proposed to improve the line (segment) detection performance, as surveyed in \cite{AsurveyofHoughTransform,Rahmdel2015ARO}. The study in \cite{CompletelinesegmentdescriptionusingtheHoughtransform} and its improved version in \cite{CompletedescriptionofmultiplelinesegmentsusingtheHoughtransform} were presented to efficiently and effectively locate line endpoints. Matas presented a progressive probabilistic Hough transformation to improve the computational efficiency and decrease the memory cost \cite{RobustDetectionofLinesUsingtheProgressiveProbabilisticHoughTransform} for line segment detection. By analyzing the distribution around peaks in the Hough space, Furukawa et al. presented a robust line segment detection method \cite{AccurateandRobustLineSegmentExtractionbyAnalyzingDistributionaroundPeaksinHoughSpace}. Du et al. presented a collinear line segment detection approach by exploiting the information of wings around the peaks in the Hough space \cite{CollinearSegmentDetectionUsingHTNeighborhoods}. The authors in \cite{AnAccurateMethodforLineDetectionandManhattanFrameEstimation} presented the concept of "soft voting" in the Hough space, which leverages the uncertainty information in edge detection to improve detection performance. Xu et al. detected line segments based on minimum entropy analysis \cite{AccurateandRobustLineSegmentExtractionUsingMinimumEntropyWithHoughTransform}. In addition, they presented a statistical method for line segment detection by considering various information, such as quantization errors \cite{AStatisticalMethodforLineSegmentDetection}.

\subsubsection{Analysis and Summary}
\textit{\textbf{The core idea of global Hough-based approaches lies in exploiting the duality between points and curves in the image and Hough spaces to detect line segments, in which the line segment detection problem in the image space is transformed into a peak statistic problem in the Hough space.}} Therefore, analyzing and counting the peaks in the Hough space is critical. Considering the computational and memory costs, the quantitative values need to be utilized in searching for the intersection points (peaks) in the Hough space, \textit{e.g.}, the quantitative values of $\rho$ and $\theta$ in Fig. \ref{hough_line} (d). These quantitative values control the number and quality of detected lines or line segments to some extent. Furthermore, since images generally contain many pixels, performing the Hough transformation for each pixel is unacceptable, particularly for applications with limited computational and memory resources. Generally, input images need to be processed in advance to eliminate unnecessary processing pixels. A general approach is performing binary processing, such as edge detection \cite{Canny}. In this way, only these selected pixels are transformed into Hough space to further detect line segments, saving computational and memory resources.




\subsection{Local-based Approaches}
\label{subsec_local_based}
Local-based approaches leverage the consistent image features in local regions to detect line segments. According to the selection of image features, they can be further classified into gradient grouping-based and edge fitting-based approaches using image gradients and edges, respectively.

\subsubsection{Gradient Grouping-based Approaches}
\label{subsubsec_detection_gradient}
\textbf{LSD Method.} The baseline method for line segment detection is the LSD method \cite{LSD, LSDaLineSegmentDetector}. Its mechanism is straightforward but effective. As shown in Fig. \ref{lsd_level_line} (b), the level lines orthogonal to gradient orientations for image pixels are calculated to group a series of line ROSs. Based on these line ROSs, the corresponding approximated rectangles around them are obtained and validated based on the aligned points and total points inside them using the Contraio and Helmholtz model \cite{desolneux2007gestalt}. The line segment parameters are calculated based on the approximated rectangle if valid.

\begin{figure}[tbp]
	\centering
	\includegraphics[width=0.49\textwidth]{figures/lsd_demo.pdf}
	\caption{Visual illustrations in the LSD \cite{LSD,LSDaLineSegmentDetector} algorithm: (a) image region of interest; (b) level lines (small black lines) and the approximated rectangles for line ROSs. Line segments are detected from these approximated rectangles.}
	\label{lsd_level_line}
\end{figure}

\textbf{Related Studies.} In addition to the LSD method, other algorithms have grouped the image gradient for line segment detection. The authors in \cite{AParameterlessLineSegmentandEllipticalArcDetectorwithEnhancedEllipseFitting} and \cite{JointAContrarioEllipseandLineDetection} utilized image gradient orientations to group a series of line ROSs and extracted line segments from these line ROSs. By default, the LSD method was developed on a signal scale. The author in \cite{MultiscalelinesegmentdetectorforrobustandaccurateSfM} extended the LSD method by detecting line segments at multiple scales. Cho et al. first exploited the gradients in the horizontal and vertical directions to find these local maximum candidates for line segments and then detected, grouped, estimated, validated, and aggregated line segments based on these local maximum candidates \cite{ANovelLineletBasedRepresentationforLineSegmentDetection}. Considering that the line segments detected by the LSD method may contain small line fragments, the authors in \cite{FSG, PLSD} further grouped them into long line segments.


\subsubsection{Edge Fitting-based Approaches}
\label{subsubsec_detection_edge}
\textbf{EDLines Method.} In addition to the LSD method, another baseline method is the EDLines \cite{EDLines} method, which exploits edges for line segment detection. The EDLines algorithm is reported to be 10+ times faster than the LSD algorithm because line segments are extracted only from these extracted edges rather than from whole images. In the EDLines method, edge chains are extracted by an ultrafast edge drawing \cite{EdgeDrawing} algorithm. As shown in Fig. \ref{edlines}, line segments are detected by fitting the edge points using least squares and validated using the Helmholtz criteria \cite{desolneux2007gestalt}.

\textbf{Related Studies.} In addition to EDLines, other methods have employed image edges for line segment detection. The authors in \cite{Outdoorplacerecognitioninurbanenvironmentsusingstraightlines} extracted line segments from Canny edges by continually fitting line segments until the predefined conditions were satisfied. Lu et al. proposed a parameter-free Canny operator to extract image edges and then detected line segments from these edges \cite{CannyLines}. The authors in \cite{ELSED} presented an enhanced line segment drawing (ELSED) method for line segment detection. It was reported as the fastest line segment detection algorithm to date. The authors in \cite{E2LSD} argued that line segments should be located on edge points with consistent coordinates and level lines.

\begin{figure}[tbp]
	\centering
	\includegraphics[width=0.49\textwidth]{figures/edlines_demo.pdf}
	\caption{In the EDLines \cite{EDLines} algorithm, line segments (red lines) are detected from edges (green points). The figure shows a test image (a) and a region of interest (b) with drawn edges and detected line segments.}
	\label{edlines}
\end{figure}


\subsubsection{Analysis and Summary}
Local-based methods leverage consistent image features, \textit{e.g.}, gradients and edges, in local regions to detect line segments, followed by merging and validation processes to improve line segment quality. \textbf{\textit{The core idea of gradient grouping-based approaches lies in grouping image regions with highly consistent gradient orientations or magnitudes and further detecting corresponding line segments.}} Therefore, efficiently and effectively grouping these highly consistent region candidates in images is critical. Since most gradient grouping-based approaches only consider local connectivity for line segment detection and lack adequate semantic and global feature constraints, the region candidates are easily interrupted by noise and small occlusion. The detected line segments tend to be fragmentary instead of long and complete line segments; thus, additional processes, such as validation \cite{LSDaLineSegmentDetector} and aggregation \cite{ANovelLineletBasedRepresentationforLineSegmentDetection,Ametricforlinesegments}, are needed to robustly extract line segments. All of these processes control the quality of line segments to an extent. The detected image line segments generally have similar gradient properties in gradient magnitudes or orientations.

\textbf{\textit{The core idea of edge fitting-based approaches lies in fitting edge points based on least squares or other methods \cite{Whatsinasetofpointsstraightlinefitting,232082}, followed by merging \cite{250848} and validation \cite{EDLines} processes to improve line segment quality.}} Therefore, reliable and efficient edge extraction is critical for these approaches, particularly those based on edge chains, as in \cite{EDLines,ELSED,E2LSD}. The extracted edge quality and the aforementioned processes, such as aggregation and merging, deeply affect line segment detection performance.


\subsection{Learning-based Approaches}
\label{subsec_detection_learning}
\subsubsection{Widely Used Training and Testing Datasets}
\label{subsubsec_detection_dataset}
Training and testing data lay the foundation for learning-based line segment detection approaches. The most widely used training and testing dataset is the Wireframe dataset \cite{LearningtoParseWireframesinImagesofMan-MadeEnvironments}, which includes 5,000 training images and 462 testing images with manually labeled ground truth of line segments and junctions. Wireframes are combined features comprising more than one line segment and corresponding junctions, as shown in Fig. \ref{Wireframes}. Therefore, the Wireframe dataset can be used in line segment detection and wireframe parsing tasks. Another popular dataset is YorkUrban \cite{YorkUrban, ANovelLineletBasedRepresentationforLineSegmentDetection}, which contains 102 testing images with manually labeled ground truth of Manhattan line segments. Due to its limited data size, many studies only used YorkUrban for evaluation.

\begin{figure}[tbp]
	\centering
	\includegraphics[width=0.49\textwidth]{figures/wireframes.pdf}
	\caption{Labeled ground truth of line segments and junctions in the Wireframe \cite{LearningtoParseWireframesinImagesofMan-MadeEnvironments} dataset.}
	\label{Wireframes}
\end{figure}

\subsubsection{Related Studies on Line Segment Detection}
The authors in \cite{TP-LSD} trained a fast line segment detector, achieving real-time performance with the help of powerful GPU devices, in which the branch for line segment detection segments the pixels on straight lines from the background. Dai et al. developed a one-stage, fully convolutional line parsing network for line segment detection by predicting the center, position, length, and angle of line segments \cite{FullyConvolutionalLineParsing}. The authors in \cite{TowardsRealtimeandLightweightLineSegmentDetection} developed a lightweight line segment detection algorithm by minimizing a backbone network. In addition to performing only line segment detection, the authors in \cite{L2D2}, \cite{SOLD2}, \cite{Superline}, \cite{ELSD}, and \cite{SelfsupervisedLightweightLineSegmentDetectorandDescriptor} trained networks to simultaneously detect and describe line segments.

\subsubsection{Related Studies on Wireframe Detection}
Huang et al. presented the Wireframe dataset and trained two neural networks for wireframe detection \cite{LearningtoParseWireframesinImagesofMan-MadeEnvironments}, in which the branch network for line segment detection was designed by predicting whether a pixel falls on a line. In addition, they presented another wireframe parsing algorithm with the guidance of a distance map \cite{WireframeParsingWithGuidanceofDistanceMap}. Zhou et al. trained a network to detect wireframes directly from images \cite{End-to-EndWireframeParsing}. Xue et al. also presented an end-to-end network consisting of generation, matching, and verification components for line segments and their corresponding junctions \cite{Holistically-AttractedWireframeParsing}.

\subsubsection{Analysis and Summary}
\textbf{\textit{The core idea of learning-based approaches lies in learning the line segment or wireframe patterns by designing networks and loss functions in carefully prepared training and testing datasets, in which both local and global image features in multiple layers can be fused to detect line segments.}} Therefore, designing networks regarding the prepared training and testing datasets is critical. The network generalization ability needs to be further validated since most networks are trained using the Wireframe dataset with only 5,000 samples and validated based on the limited testing datasets mentioned above. Learning-based approaches tend to detect semantically meaningful line segments. Generally, the input image needs to be downsampled to decrease the network size, affecting the detection accuracy to an extent. With the help of GPU devices, a few of these approaches can achieve real-time detection performance.


\subsection{Hybrid-based Approaches}
\label{subsec_hybrid}
\subsubsection{Related Studies}
Several hybrid-based approaches incorporating multiple mechanisms were recently presented to detect image line segments. Almazan et al. presented a Markov chain marginal line segment detector (MCMLSD) \cite{MCMLSD} by leveraging global probabilistic Hough transformation and perceptual grouping in the image domain. The authors in \cite{DeepHoughTransformLinePriors, LinedetectionviaalightweightCNNwithaHoughlayer} introduced the Hough transformation into neural networks, enabling the constructed network to extract global and local features for line segment detection. By leveraging a lightweight convolutional neural network with a classical LSD detector, a hybrid-based line segment detection was presented in \cite{LSDNet}, named LSDNet. Pautrat et al. proposed the DeepLSD method \cite{DeepLSD}, in which a line attraction field based on a designed neural network was generated and fed to a traditionally handcrafted line detector.

\subsubsection{Analysis and Summary}
\textbf{\textit{Hybrid-based approaches utilize a combination of multiple mechanisms to detect line segments in images. The fundamental idea behind these approaches is to amalgamate the strengths of multiple mechanisms to overcome the drawback of the specific mechanism.}} Therefore, the primary goal is to seamlessly integrate these mechanisms and design dedicated algorithms for line segment detection in relevant applications. In doing so, customizing the adopted mechanisms as per the situation is crucial, with all such modifications influencing the line segment detection quality.


\subsection{Comparing Methods Across Categories}
\label{subsec_detection_pro_cons}
Line segment detection methods in different categories have advantages, disadvantages, and positive applications, as summarized in TABLE \ref{line_segment_detection_comparsion}. TABLE \ref{line_detection_implementation} lists some open-source implementations of these methods. Global Hough-based approaches can effectively incorporate global image features to detect line segments. Thus, they are robust to image noise, occlusion, and small line segment fragments. In addition, they are mathematically explainable. However, most global Hough-based approaches lack adequate local connectivity and semantic feature constraints and thus may lead to an inaccurate result. They are suitable for vision applications requiring the detection of long line segments, such as horizon line \cite{10.1145/2964284.2967198} and vanishing point \cite{10.1007/978-3-030-01249-6_20} detection.

\begin{table*}[tbp] 	
	\centering 	
	\scriptsize 	
	\caption{Qualitative comparisons of line segment detection algorithms from the four categories.}		 	\begin{tabular}{|p{0.06\textwidth}<{\centering}|p{0.1\textwidth}<{\centering}|p{0.26\textwidth}<{\centering}|p{0.28\textwidth}<{\centering}|p{0.18\textwidth}<{\centering}|}
		\hline 		Category       & \textit{e.g.} & Advantages                                                                                                                                  & Disadvantages                                                                                                                      & Typical Applications                                \\ \hline 		Global Hough-based    & Hough\cite{UseoftheHoughTransformationtoDetectLinesandCurvesinPictures}, HoughP \cite{RobustDetectionofLinesUsingtheProgressiveProbabilisticHoughTransform}         & (1) Robust to image noise and occlusion by fusing global features, (2) Fewer line fragments, (3) Mathematically explainable. & (1) With abnormal line segments, (2) Fewer local connectivity and semantic feature constraints.                    & Vanishing point detection \cite{10.1007/978-3-030-01249-6_20}, Horizon line detection \cite{10.1145/2964284.2967198} \\ \hline 		Local-based & LSD \cite{LSD}, Linelet \cite{ANovelLineletBasedRepresentationforLineSegmentDetection}, EDLines \cite{EDLines}                   & (1) Low computational cost, (2) Good local connectivity constraint, (3) Mathematically explainable.                                                  & (1) Sensitive to image noise and occlusion, (2) With line fragments, (3) Fewer global and semantic feature constraints.          & Visual odometry \cite{9521248}, Visual localization \cite{9106407}, Visual SLAM \cite{9856705} \\ \hline 		Learning-based & MLSD \cite{TowardsRealtimeandLightweightLineSegmentDetection}, L-CNN \cite{End-to-EndWireframeParsing}, FClip \cite{FullyConvolutionalLineParsing}              & (1) End-to-end manner, (2)   Fusing local and global features for semantic line segment detection.                                      & (1) Deeply affected by training and testing data, (2) Difficult to explain mathematically, (3) High computational cost, needing GPU. & 3D reconstruction \cite{LearningtoReconstruct3DManhattanWireframesFromaSingleImage}, Image partitioning \cite{7298931}, Scene parsing \cite{6619245}                   \\ \hline 		Hybrid-based    & MCMLSD \cite{MCMLSD}, HTLCNN \cite{DeepHoughTransformLinePriors}         & Fusing multiple mechanisms to detect line segments. &  Depending on the specific fusion mechanism.                   & Depending on the specific fusion mechanism. \\ \hline		 	
	\end{tabular} 	
	\label{line_segment_detection_comparsion} 
\end{table*}

\begin{table*}[tbp] 	
	\centering 	
	\scriptsize 	
	\caption{Open-source implementations of sampled line segment detection methods.} 	\begin{tabular}{|p{0.1\textwidth}<{\centering}|p{0.05\textwidth}<{\centering}|p{0.15\textwidth}<{\centering}|p{0.1\textwidth}<{\centering}|p{0.43\textwidth}<{\centering}|} 		
		\hline 		
		Method                                                                                                       & \multicolumn{1}{c|}{Category}                         & Subcategory                              & Implementation & URL                                                                    \\ \hline 		Hough                                                                                                        & \multicolumn{2}{c|}{\multirow{2}{*}{Global Hough-based}}                                                & OpenCV         & https://opencv.org/                                                    \\ \cline{1-1} \cline{4-5}  		HoughP \cite{RobustDetectionofLinesUsingtheProgressiveProbabilisticHoughTransform}          & \multicolumn{2}{c|}{}                                                                            & OpenCV         & https://opencv.org/                                                    \\ \hline 		AG3line \cite{AG3line}                                                                      & \multicolumn{1}{c|}{\multirow{12}{*}{Local-based}}    & \multirow{7}{*}{Gradient grouping-based} & C++            & https://github.com/weidong-whu/AG3line                                 \\ \cline{1-1} \cline{4-5}  		FSG \cite{FSG}                                                                              & \multicolumn{1}{c|}{}                                 &                                          & C++            & https://github.com/iago-suarez/FSG                                     \\ \cline{1-1} \cline{4-5}  		Linelet \cite{ANovelLineletBasedRepresentationforLineSegmentDetection}                      & \multicolumn{1}{c|}{}                                 &                                          & Matlab         & https://github.com/NamgyuCho/Linelet-code-and-YorkUrban-LineSegment-DB \\ \cline{1-1} \cline{4-5}  		ELSDc \cite{JointAContrarioEllipseandLineDetection}                                         & \multicolumn{1}{c|}{}                                 &                                          & C              & https://github.com/viorik/ELSDc                                        \\ \cline{1-1} \cline{4-5}  		MLSD \cite{MultiscalelinesegmentdetectorforrobustandaccurateSfM}                            & \multicolumn{1}{c|}{}                                 &                                          & C++            & https://github.com/ySalaun/MLSD                                        \\ \cline{1-1} \cline{4-5}  		LSD \cite{LSD,LSDaLineSegmentDetector}                                                      & \multicolumn{1}{c|}{}                                 &                                          & C, OpenCV      & http://www.ipol.im/pub/art/2012/gjmr-lsd/?utm\_source=doi              \\ \cline{1-1} \cline{4-5}  		LSWMS \cite{Linesegmentdetectionusingweightedmeanshiftproceduresona2Dslicesamplingstrategy} & \multicolumn{1}{c|}{}                                 &                                          & C++            & https://sourceforge.net/projects/lswms/                                \\ \cline{1-1} \cline{3-5}  		GEDRLSD \cite{E2LSD}                                                                        & \multicolumn{1}{c|}{}                                 & \multirow{5}{*}{Edge fitting-based}              & Matlab         & https://github.com/roylin1229/GEDRLSD                                  \\ \cline{1-1} \cline{4-5}  		ELSED \cite{ELSED}                                                                          & \multicolumn{1}{c|}{}                                 &                                          & C++, Python    & https://iago-suarez.com/ELSED                                          \\ \cline{1-1} \cline{4-5}  		FLD \cite{Outdoorplacerecognitioninurbanenvironmentsusingstraightlines}                     & \multicolumn{1}{c|}{}                                 &                                          & OpenCV         & https://opencv.org/                                                    \\ \cline{1-1} \cline{4-5}  		CannyLines \cite{CannyLines}                                                                & \multicolumn{1}{c|}{}                                 &                                          & C++            & https://cvrs.whu.edu.cn/cannylines/                                    \\ \cline{1-1} \cline{4-5}  		EDLines \cite{EDLines}                                                                      & \multicolumn{1}{c|}{}                                 &                                          & C++, OpenCV    & https://github.com/CihanTopal/ED\_Lib                                  \\ \hline 		AFM \cite{LearningAttractionFieldRepresentationforRobustLineSegmentDetection}               & \multicolumn{1}{c|}{\multirow{12}{*}{Learning-based}} & \multirow{6}{*}{Line segment approach}            & C++, Python    & https://github.com/cherubicXN/afm\_cvpr2019                            \\ \cline{1-1} \cline{4-5}  		LETR \cite{LineSegmentDetectionUsingTransformerswithoutEdges}                               & \multicolumn{1}{c|}{}                                 &                                          & Python         & https://github.com/mlpc-ucsd/LETR                                      \\ \cline{1-1} \cline{4-5}  		SOLD2 \cite{SOLD2}                                                                          & \multicolumn{1}{c|}{}                                 &                                          & Python         & https://github.com/cvg/SOLD2                                           \\ \cline{1-1} \cline{4-5}  		MLSD \cite{TowardsRealtimeandLightweightLineSegmentDetection}                               & \multicolumn{1}{c|}{}                                 &                                          & Python         & https://github.com/navervision/mlsd                                    \\ \cline{1-1} \cline{4-5}  		FClip \cite{FullyConvolutionalLineParsing}                                                 & \multicolumn{1}{c|}{}                                 &                                          & Python         & https://github.com/Delay-Xili/F-Clip                                   \\ \cline{1-1} \cline{4-5}  		TP-LSD \cite{TP-LSD}                                                                        & \multicolumn{1}{c|}{}                                 &                                          & Python         & https://github.com/Siyuada7/TP-LSD                                     \\ \cline{1-1} \cline{3-5}  		\cite{Hole-robustWireframeDetection}                                                        & \multicolumn{1}{c|}{}                                 & \multirow{6}{*}{Wireframe approach}               & Python         & https://github.com/SamsungLabs/hole-robust-wf                          \\ \cline{1-1} \cline{4-5}  		\cite{LearningtoReconstruct3DManhattanWireframesFromaSingleImage}                           & \multicolumn{1}{c|}{}                                 &                                          & Python         & https://github.com/zhou13/shapeunity                                   \\ \cline{1-1} \cline{4-5}  		L-CNN \cite{End-to-EndWireframeParsing}                                                     & \multicolumn{1}{c|}{}                                 &                                          & Python         & https://github.com/zhou13/lcnn                                         \\ \cline{1-1} \cline{4-5}  		PPGNet \cite{PPGNet}                                                                        & \multicolumn{1}{c|}{}                                 &                                          & Python         & https://github.com/svip-lab/PPGNet                                     \\ \cline{1-1} \cline{4-5}  		HAWP \cite{Holistically-AttractedWireframeParsing}                                          & \multicolumn{1}{c|}{}                                 &                                          & Python         & https://github.com/cherubicxn/hawp                                     \\ \cline{1-1} \cline{4-5}  		\cite{LearningtoParseWireframesinImagesofMan-MadeEnvironments}                              & \multicolumn{1}{c|}{}                                 &                                          & Python         & https://github.com/huangkuns/wireframe                                 \\ \hline 		MCMLSD \cite{MCMLSD}                                                                        & \multicolumn{2}{c|}{\multirow{4}{*}{Hybrid-based}}                                               & Matlab         & https://www.elderlab.yorku.ca/mcmlsd/                                  \\ \cline{1-1} \cline{4-5}  		HTLCNN \cite{DeepHoughTransformLinePriors}                                                 & \multicolumn{2}{c|}{}                                                                            & Python         & https://github.com/yanconglin/Deep-Hough-Transform-Line-Priors         \\ \cline{1-1} \cline{4-5}  		LSDNet \cite{LSDNet}                                                                        & \multicolumn{2}{c|}{}                                                                            & Python         & https://github.com/iitpvisionlab/LSDNet                                \\ \cline{1-1} \cline{4-5}  		DeepLSD \cite{DeepLSD}                                                                      & \multicolumn{2}{c|}{}                                                                            & Python         & https://github.com/cvg/DeepLSD                                         \\ \hline 	
	\end{tabular}%
	\label{line_detection_implementation} 
\end{table*}

Local-based approaches generally have a high detection efficiency. Particularly, edge fitting-based approaches \cite{EDLines,ELSED} have the lowest computational costs compared to other approaches since they only consider the drawn edge points instead of whole images when detecting line segments. Local-based methods can exploit local connectivity well to detect line segments and are mathematically explainable. However, most methods in this category only consider local connectivity for line segment detection and lack adequate semantic and global feature constraints. Even with the help of additional aggregation and merging processes, the detected line segments tend to be line fragments instead of long or semantic line segments. The stability of image gradients or edges deeply affects the detection performance, which may be affected by image noise and occlusion. They are suitable for vision applications with low computational and memory costs and low semantic feature requirements, such as VO \cite{9521248} and V-SLAM \cite{9856705}.

Learning-based approaches can achieve line segment detection end-to-end. They can fuse local and global image features for semantic line segment detection. However, the detection performance is deeply affected by the prepared training data. The generalization ability of trained models is difficult to ensure since most are trained based on the Wireframe dataset \cite{LearningtoParseWireframesinImagesofMan-MadeEnvironments}, which only contains 5,000 training images. Furthermore, they are difficult to explain mathematically and to achieve real-time detection without GPU devices, significantly limiting their applications, particularly those with resource-constrained systems and platforms. They are suitable for vision applications with high requirements for semantic understanding, such as scene reconstruction \cite{hartley1997lines} with tensor structure \cite{liu2022tensor,liu2021tensor}, image partitioning \cite{7298931}, and scene parsing \cite{6619245}.

Hybrid-based approaches generally lack a universal paradigm because they rely on fusing multiple dedicated mechanisms to detect line segments. Consequently, their advantages, disadvantages, and typical applications depend on specific fusion mechanisms. These approaches provide a high degree of flexibility for customization.


\subsection{Challenges and Insights for Potential Solutions}
\label{subsec_detection_challenges}
Global Hough-based approaches have already been well studied, but recently, research on the other three categories is ongoing. Therefore, in this subsection, the challenges for the other three method categories are decisively discussed, and corresponding insights for potential solutions dealing with these challenges are presented.

As mentioned in subsection \ref{subsec_generic_challenges}, the first challenge for line segment detection is that their endpoints are generally unstable due to many factors, such as image noise, occlusion, and illumination variance. An approach for stably determining the line segment endpoints is finding the anchor points on the line segment, such as corners \cite{SODC, ACRA} and junctions \cite{End-to-EndWireframeParsing}, which are highly discriminative and can be viewed as stable endpoints for line segments.

For local-based methods, the detected line segments tend to be line segment fragments instead of complete line segments due to the sensitivity to image noise or occlusion. In addition to the existing postprocessing approaches, such as aggregation and merging, as mentioned above, partial global features, \textit{e.g.}, the Hough transformation of limited sample points on line segments, can guide the line segment detection process. In this way, except for local connectivity, partial global features on line segments can be further exploited to detect line segments.

Learning-based methods generally have high computational costs and are deeply affected by the training and testing datasets. Two approaches are presented to potentially address the two challenges. (1) In addition to designing the lightweight network, as in \cite{TowardsRealtimeandLightweightLineSegmentDetection}, combining a shadow network and handcrafted features is feasible for accelerating the line segment detection algorithm inspired by \cite{KeyNet}. (2) In addition to self-supervised \cite{ELSD} and semisupervised \cite{Hole-robustWireframeDetection} learning schemes, an unsupervised learning scheme can also be considered for line segment detection tasks to decrease the dependency on training and testing datasets with the ground truth inspired by point features \cite{R2D2}.




\section{Line Segment Description Review}
\label{sec_line_description}
This section reviews numerous line segment description approaches. Similar to point \cite{SIFT}, corresponding descriptors can also describe line segments to match them. These descriptors should have various invariant properties, such as rotation, scale, viewpoint, and illumination invariance properties. In addition, line segments contain more structural and geometric features about the scene than point features. Their attributes, \textit{e.g.}, the length and direction, have certain geometric features by themselves and can be utilized to encode line segments. Furthermore, other line segments around the inspected line segment can be exploited to describe line segments structurally by encoding the relative relationship among them.

As introduced in subsection \ref{subsec_high_level_taxonomy}, these description methods can be roughly classified into three categories: (1) statistic-based methods with subcategories of gradient statistic-based and intensity statistic-based approaches (subsection \ref{subsec_description_statistic}), (2) structure-based methods with subcategories of local line segment-assisted and line intersection context-assisted approaches (subsection \ref{subsec_description_structure}), and (3) learning-based methods with line ROS-based and nonline ROS-based subcategories (subsection \ref{subsec_description_learning}). Most line segment descriptors are float descriptors, except for a few methods like \cite{IILB,Abinaryrobustlinedescriptor} and the binary version of \cite{LBD} in OpenCV.

These description methods in three categories have advantages, disadvantages, and positive application scenarios, as enumerated in TABLE \ref{line_segment_description_comparsion} and analyzed in subsection \ref{subsec_description_comparison}. The insights for potentially addressing the challenges in existing description methods are presented to inspire researchers, as detailed in subsection \ref{subsec_description_challenges}. TABLE \ref{line_description_implementation} lists some open-source implementations of line segment description methods. Fig. \ref{description_visualization} visually shows matched line segments based on four line segment descriptors using the mutual brute-force matching strategy.



\subsection{Statistic-based Approaches}
\label{subsec_description_statistic}

Generally, statistic-based approaches describe line segments by counting the features in line ROSs. Depending on the source of the features, they can be further classified into gradient statistic-based and intensity statistic-based approaches using gradients and intensities, respectively.

\subsubsection{Gradient Statistic-based Approaches}
\label{subsec_description_statistic_gradient}

\begin{figure}[tbp]
	\centering
	\includegraphics[width=0.49\textwidth]{figures/lbd_demo2.pdf}
	\caption{Illustrations of the LBD descriptor \cite{LBD}. (a) The blue arrows represent local gradient vectors with elements parallel ($g_L$) and orthogonal ($g_\bot$) to the line directions, and the red rectangles are local bands in line ROSs. $f_l$ and $f_g$ are weighted Gaussian functions. (b) A line segment (green) with a line ROS (red) in the test image. (c) The band description matrix $BDM_j$ is formulated by counting the gradients from band $B_j$ and its two neighboring bands $B_{j-1}$ and $B_{j+1}$, in which $M$ and $N_r$ are the number of bands and the row number in each band, respectively. The LBD descriptor is formulated by connecting the mean values and standard deviations of various BDMs.}
	\label{lbd_demo}
\end{figure}

\textbf{LBD Descriptor} The local band descriptor (LBD) \cite{LBD} is the baseline method for line segment description. As shown in Fig. \ref{lbd_demo} (a), in the LBD \cite{LBD} approach, the local gradients parallel and orthogonal to the line directions are first calculated and recorded as $g_L$ and $g_\bot$, respectively. Then, $g_L$ and $g_\bot$ are counted in the corresponding bands to formulate the band description matrix (BDM), as shown in Fig. \ref{lbd_demo} (c). Two Gaussian functions, $f_g$ and $f_l$, are used to enhance the LBD descriptor performance. The LBD descriptor is formulated by connecting the mean values and standard deviations of various BDMs and is normalized to improve the robustness in terms of the illumination variance.

\textbf{Related Studies}:
The LBD descriptor was partially inspired by the descriptor \cite{MSLD}, in which the authors exploited image gradients in local subregions to formulate line segment descriptors inspired by the SIFT \cite{SIFT} feature for points. They also presented another descriptor by exploiting the rotation invariant Harris feature \cite{HLD}, generated from image gradients, for line segment description. Liu et al. extended well-known feature point descriptors to line segment descriptions \cite{Extendpointdescriptorsforlinecurveandregionmatching} since line segments can be viewed as a series of points. To achieve the real-time extraction of line segment descriptors, the authors in \cite{FastLineDescriptionforLinebasedSLAM} utilized a constant number of sampled points in line ROSs to calculate gradients and formulate corresponding line descriptors inspired by \cite{MSLD}. The authors in \cite{Matchingofstraightlinesegmentsfromaerialstereoimagesofurbanareas} adapted the Daisy descriptor \cite{DAISY} for feature points to line segments, in which the histogram of gradients is used to construct descriptors. Verhagen et al. proposed a multiple-scale extension for \cite{MSLD}. Benefiting from computing the band difference of image intensity and gradient, an illumination-insensitive binary descriptor \cite{IILB} for line segments was proposed to match line segments under drastic illumination changes.

\subsubsection{Intensity Statistic-based Approaches}
\label{subsec_description_statistic_intensity}
\textbf{MLIOR Descriptor} The multiple local intensity order representation (MLIOR) \cite{ALineMatchingMethodBasedonMultipleIntensityOrderingwithUniformlySpacedSampling} is a representative intensity statistic-based approach. As shown in Fig. \ref{mlior_demo}, different from other methods \cite{LBD,MSLD} using the rectangles to construct subregion divisions, the subregions in line ROSs are formulated based on their intensity order, resulting in an irregular geometry division of subregions. This irregular subregion division makes the MLIOR descriptor insensitive to illumination changes to some extent. For each point in the subregion, the multiple local intensity ordering generated from sampled points around the target point is utilized to describe line segments inspired by \cite{LIOP}. To improve the computational efficiency and decrease the descriptor size, the sampled points are assigned to different circles and point sets to formulate groups when constructing the LIOR.

\begin{figure}[tbp]
	\centering
	\includegraphics[width=0.49\textwidth]{figures/mlior.pdf}
	\caption{Visual illustrations of the MLIOR descriptor \cite{ALineMatchingMethodBasedonMultipleIntensityOrderingwithUniformlySpacedSampling}. (a) A test line segment with start (red star) and end (blue star) points and its line ROS (green rectangle). (b) Line ROS. (c) Irregular subregions in the line ROS. (d) Sampled points around the target point $p$, where the point set with the same color and circle is grouped to construct the local intensity order representation (LIOR). The MLIOR descriptor is formulated by counting multiple LIORs inspired by \cite{LIOP}.}
	\label{mlior_demo}
\end{figure}

\textbf{Related Studies}
In addition to the MLIOR descriptor, some other intensity statistic-based line segment descriptors have been proposed. Bay et al. presented a simple line descriptor using a color histogram in HSV color space \cite{Widebaselinestereomatchingwithlinesegments}, in which the intensity values from different image channels are used to describe line segments. The multiple-scale version of \cite{Widebaselinestereomatchingwithlinesegments} was presented in \cite{Scaleinvariantlinedescriptorsforwidebaselinematching}. The authors in \cite{Twoviewlinematchingalgorithmbasedoncontextandappearanceinlowtexturedimages} designed a mixed line segment descriptor, in which the descriptor for reflecting local appearance was formulated based on intensity averages and correlations. Jing et al. proposed a line segment descriptor belonging to both gradient and intensity statistic-based descriptors, in which the gradient magnitude and orientation were counted according to the intensity order of the sampled points \cite{Arobustlinematchingmethodbasedonlocalappearancedescriptorandneighboringgeometricattributes}. 

\subsubsection{Analysis and Summary}
\textbf{\textit{The core idea of statistic-based line segment description approaches lies in exploiting the statistic features, \textit{e.g.}, the histogram of gradients or pixel intensities in line ROSs, to encode line segments.}} Therefore, counting the features, including the subregion division and feature encoding in line ROS, is critical. The subregion division can be regular, as in \cite{LBD}, or irregular, as in \cite{ALineMatchingMethodBasedonMultipleIntensityOrderingwithUniformlySpacedSampling}. A regular division approach is significantly more efficient than an irregular approach because the latter needs to sort the pixels in line ROSs, which is  time-consuming. The subregion division approach determines how the local features will be processed and organized. Feature encoding is performed to explore the invariant characteristics of line segment descriptors. Both of them control the description ability of line segments.


\subsection{Structure-based Approaches}\label{subsec_description_structure}
Structure-based approaches employ additional local line segments to structurally describe their relative relationship. These approaches can be classified into two subcategories based on the usage of local line segments: (1) local line segment-assisted and (2) line intersection context-assisted.

\subsubsection{Local Line Segment-assisted Approaches} \label{subsec_description_structure_local_line} The methods in this subcategory, \textit{i.e.}, \cite{WidebaselineimagematchingusingLineSignatures,Robustaffineinvariantlinematchingforhighresolutionremotesensingimages,Anovelsimilarityinvariantlinedescriptorforgeometricmapregistration,NovelSimilarityInvariantLineDescriptorandMatchingAlgorithmforGlobalMotionEstimation,Twoviewlinematchingalgorithmbasedoncontextandappearanceinlowtexturedimages,AutomaticRegistrationMethodforOpticalRemoteSensingImageswithLargeBackgroundVariationsUsingLineSegments,MultimodalImageRegistrationWithLineSegmentsbySelectiveSearch}, encode local line segments around the inspected line segment to formulate corresponding description signatures. The relative geometric and structural relationships, such as the angle between line segments \cite{Anovelsimilarityinvariantlinedescriptorforgeometricmapregistration,NovelSimilarityInvariantLineDescriptorandMatchingAlgorithmforGlobalMotionEstimation}, the angle between line segment endpoints and line segments \cite{Anovelsimilarityinvariantlinedescriptorforgeometricmapregistration,NovelSimilarityInvariantLineDescriptorandMatchingAlgorithmforGlobalMotionEstimation}, the histogram of local line segments \cite{AutomaticRegistrationMethodforOpticalRemoteSensingImageswithLargeBackgroundVariationsUsingLineSegments}, and the distance between line segment midpoints \cite{Twoviewlinematchingalgorithmbasedoncontextandappearanceinlowtexturedimages}, have been exploited to describe the invariance among these local line segments concerning the inspected line segment.

\subsubsection{Line Intersection Context-assisted Approaches} \label{subsec_description_structure_context} The methods in this subcategory, \textit{i.e.}, \cite{Anovellinematchingmethodbasedonintersectioncontext,Simultaneouslinematchingandepipolargeometryestimationbasedontheintersectioncontextofcoplanarlinepairs,LineMatchinginWideBaselineStereoATopDownApproach,Widebaselinestereomatchingbasedonthelineintersectioncontextforrealtimeworkspacemodeling,RobustLineMatchingBasedonRay-Point-RayStructureDescriptor,HierarchicalLineMatchingBasedonLineJunctionLineStructureDescriptorandLocalHomographyEstimation,Linesegmentmatchingandreconstructionviaexploitingcoplanarcues}, generally find the coplanar and adjacent line segment pairs to formulate the intersecting point, which can be encoded using the well-known feature descriptors for points. The corresponding line segment matches can be recovered based on the matching results of intersecting points. Therefore, the methods in this subcategory transform the line segment description into an intersecting point description.

\subsubsection{Analysis and Summary}
\textbf{\textit{The core idea of structure-based line segment description approaches lies in leveraging additional line segments to describe their relative relationship structurally}}. Therefore, selecting local line segments and encoding the relative relationship among them is critical. Many of them require that the local line segments be coplanar with the inspected line segments since the relative relationship among them is only preserved in coplanar scenarios, which also facilitates the calculation of local homography matrices to recover the precise line-to-line segment correspondences. The methods in this category deeply depend on the line segment detection stability since the local structure is formulated based on line segment detection results.


\subsection{Learning-based Approaches}
\label{subsec_description_learning}
To date, no widely used training and testing datasets exist for learning-based description methods. Most existing methods develop line segment descriptors based on their prepared datasets with the ground truth of line segment matches, either automatically or manually. In addition, their network design schemes are different. However, most of them utilize the triplet loss \cite{NIPS2017_831caa1b} or its variants in the loss function, in which a matched and unmatched pair are exploited. According to the dependence of line ROSs, they can be further classified into two subcategories: line ROS-based approaches and nonline ROS-based approaches.

\subsubsection{Line ROS-based Approaches} \label{subsec_description_learning_ros} Line ROS-based approaches \cite{Abinaryrobustlinedescriptor,DLD,WLD,L2D2,Towardslearninglinedescriptorsfrompatchesanewparadigmandlargescaledataset} train a network by focusing on the local image feature around the inspected line segments. The authors in \cite{DLD} first utilized deep learning to train a network for line segment description by exploiting the triplet loss among three lines, including a matching pair and another nonmatching line, and the approach was improved in their subsequent work \cite{WLD}. Abdellali et al. trained a network to describe line segments in a self-supervised manner with a normalized line ROS size of $32 \times 48$ \cite{L2D2}. The authors in \cite{Towardslearninglinedescriptorsfrompatchesanewparadigmandlargescaledataset} constructed a large-scale dataset of ~229,000 labeled matched line pairs and learned line descriptors from line patches (ROSs).

\subsubsection{Nonline ROS-based Approaches} \label{subsec_description_learning_non_ros} Nonline ROS-based approaches \cite{LearnableLineSegmentDescriptorforVisualSLAM,SOLD2,Superline,LineasaVisualSentenceContextAwareLineDescriptorforVisualLocalization,ELSD,LDAM} can leverage both local image features around the inspected line segment and global image features to encode line segments by using the features in multiple layers. The authors in \cite{LearnableLineSegmentDescriptorforVisualSLAM} designed a lightweight neural network to describe line segments using an automatically collected dataset of matching and nonmatching line segments. Inspired by \cite{SuperPoint}, Pautrat et al. proposed a single deep network for joint line segment detection and description \cite{SOLD2}. The authors in \cite{SOLD2}, \cite{Superline}, and \cite{ELSD} also presented schemes to jointly detect and describe line segments. Yoon et al. presented a context-aware line segment descriptor by dynamically attending to well-describable points on a line \cite{LineasaVisualSentenceContextAwareLineDescriptorforVisualLocalization}.

\subsubsection{Analysis and Summary}
\textbf{\textit{The core idea of learning-based line segment description approaches lies in learning the line segment representations locally or globally based on designed networks with loss functions and prepared training datasets.}} Therefore, designing the network and preparing the training and testing datasets are critical. Like learning-based line segment detection methods, the generalization ability of trained networks needs to be further validated since most of them trained their networks using their prepared datasets. Generally, the descriptors in this category are more robust than these nonlearning-based approaches since they can learn the deep features in multiple layers of the designed network. Most of these methods depend on a GPU for training and predicting. A few of them can extract line segment descriptors in real-time with the help of a powerful GPU.


\subsection{Comparing Methods Across Categories}
\label{subsec_description_comparison}

\begin{table*}[tbp] 	
	\centering 	
	\scriptsize 	
	\caption{Qualitative comparisons for three categories of line segment description algorithms.}		 	\begin{tabular}{|p{0.05\textwidth}<{\centering}|p{0.08\textwidth}<{\centering}|p{0.30\textwidth}<{\centering}|p{0.28\textwidth}<{\centering}|p{0.17\textwidth}<{\centering}|} 		
		\hline 		Category       & \textit{e.g.} & Advantages                                                                                                                                  & Disadvantages                                                                                                                      & Typical Applications                                \\ \hline 		Statistic-based    & LBD \cite{LBD}, MSLD \cite{MSLD}         & (1) Robust to image variance, (2) Mathematically explainable. & (1) Sensitive to low textures, (2) Fewer global and semantic features.                    & Visual localization \cite{9106407}, Visual SLAM \cite{9856705} \\ \hline 		Structure-based & NLD \cite{NovelSimilarityInvariantLineDescriptorandMatchingAlgorithmforGlobalMotionEstimation}, LS \cite{WidebaselineimagematchingusingLineSignatures}           & (1) Structure and geometry preserved, (2) Relatively insensitive to low textures, (3) Mathematically explainable.                                                  & (1) Deeply affected by other local points or line segments, (2) Coplanar hypothesis, (3) Fewer global features.           & Map registration \cite{Anovelsimilarityinvariantlinedescriptorforgeometricmapregistration,NovelSimilarityInvariantLineDescriptorandMatchingAlgorithmforGlobalMotionEstimation}, Remote sensing image matching \cite{Robustaffineinvariantlinematchingforhighresolutionremotesensingimages} \\ \hline 		Learning-based & DLD \cite{DLD}, WLD \cite{WLD}              & (1) End-to-end manner, (2)   Fusing local and global features for semantic line segment description.                                      & (1) Deeply affected by training dataset, (2) Difficult to explain mathematically, (3) High computational costs, requiring GPUs. &  Scene parsing \cite{6619245}, 3D scene abstraction \cite{HOFER2017167}                 \\ \hline 	
	\end{tabular} 	
	\label{line_segment_description_comparsion} 
\end{table*}

These description methods in different categories have advantages, disadvantages, and positive applications, as listed in TABLE \ref{line_segment_description_comparsion}. TABLE \ref{line_description_implementation} lists some open-source implementations of line segment description methods. Statistic-based approaches describe line segments by counting the gradients or intensities in line ROSs. Generally, they have a higher computational efficiency than learning-based methods and are insensitive to image variance. They can be explained well mathematically. Most of these approaches are formulated based on line ROSs, leading to insufficient global and semantic features and sensitivity to low texture scenarios. These approaches are suitable for applications such as visual localization \cite{9106407} and SLAM \cite{FastLineDescriptionforLinebasedSLAM}.

\begin{table*}[tbp] 	
	\centering 	
	\scriptsize 	
	\caption{Open-source implementations of sampled line segment description methods.} 	\begin{tabular}{|c|c|c|c|c|} 		
		\hline 		Method                                                                                                & Category                         & Subcategory                              & Implementation           & URL                                                      \\ \hline 		IILB \cite{IILB}                                                                                      & \multirow{4}{*}{Statistic-based} & gradient- and intensity-based            & Matlab                   & https://github.com/roylin1229/IILB\_descriptor           \\ \cline{1-1} \cline{3-5}  		LBD \cite{LBD}                                                                                        &                                  & \multirow{3}{*}{gradient grouping-based} & C++, OpenCV              & https://github.com/mtamburrano/LBD\_Descriptor           \\ \cline{1-1} \cline{4-5}  		\cite{MSLD}                                                                                           &                                  &                                          & C++                      & https://kailigo.github.io/projects/LineMatchingBenchmark \\ \cline{1-1} \cline{4-5}  		\cite{Scaleinvariantlinedescriptorsforwidebaselinematching}                                           &                                  &                                          & C++                      & https://github.com/bverhagen/SMSLD                       \\ \hline 		\cite{HierarchicalLineMatchingBasedonLineJunctionLineStructureDescriptorandLocalHomographyEstimation} & \multirow{2}{*}{Structure-based} & line intersection context-assisted       & Windows executable files & https://cvrs.whu.edu.cn/ljllinematcher/                  \\ \cline{1-1} \cline{3-5}  		\cite{WidebaselineimagematchingusingLineSignatures}                                                   &                                  & local line segment-assisted              & Windows executable files & https://kailigo.github.io/projects/LineMatchingBenchmark \\ \hline 		SOLD2 \cite{SOLD2}                                                                                    & \multirow{4}{*}{Learning-based}  & \multirow{2}{*}{nonline ROS-based}       & Python                   & https://github.com/cvg/SOLD2                             \\ \cline{1-1} \cline{4-5}  		LLD \cite{LearnableLineSegmentDescriptorforVisualSLAM}                                                &                                  &                                          & Python                   & https://github.com/alexandervakhitov/lld-public          \\ \cline{1-1} \cline{3-5}  		DLD  \cite{DLD}                                                                                       &                                  & \multirow{2}{*}{line ROS-based}          & Python                   & https://github.com/manuellange/DLD                       \\ \cline{1-1} \cline{4-5}  		WLD  \cite{WLD}                                                                                       &                                  &                                          & Python                   & https://github.com/manuellange/WLD                       \\ \hline 	
	\end{tabular}%
	\label{line_description_implementation} 
\end{table*}

Structure-based approaches describe line segments by leveraging additional line segments in the neighborhood. They can encode the structural and geometric features around the inspected line segment. Therefore, they are essentially structurally and geometrically preserved and insensitive to low textures to an extent. Similar to statistic-based approaches, they can also be well explained mathematically. However, since they use additional line segments to encode line segments, they are deeply affected by the line segment detection performance. In addition, most of these approaches require the precondition of the coplanar hypothesis, limiting their application to some extent. They can exploit the larger neighborhood context than statistic-based approaches to encode line segments but also lack corresponding global features. They are suitable for applications such as map registration \cite{NovelSimilarityInvariantLineDescriptorandMatchingAlgorithmforGlobalMotionEstimation}.

Learning-based approaches describe line segments using neural networks end-to-end, in which both the local and global features of line segments can be learned. However, training and testing data deeply affect their performance, and it is not easy to know whether they will perform well on other evaluation data since most of these networks are trained using their prepared datasets. In addition, they generally have difficulty achieving real-time line segment descriptor extraction without the help of powerful GPU devices and are difficult to explain mathematically. They are suitable for offline and complex applications such as scene parsing \cite{6619245} and 3D scene abstraction \cite{HOFER2017167}.


\subsection{Challenges and Insights for Potential Solutions}
\label{subsec_description_challenges}
As mentioned in subsection \ref{subsec_generic_challenges}, the first challenge for line segment description mentioned above also results from the unstable endpoints of detected line segments since the corresponding line ROSs or the local structure around the inspected line segment are generated according to the line segment endpoints. A new insight for dealing with this challenge lies in describing line segments in the Hough space, where the line segment endpoints are insensitive.

The second challenge lies in the lack of binary descriptors for line segments, limiting their usage in applications with high requirements of computational and storage costs. Except for the approaches in \cite{Abinaryrobustlinedescriptor,IILB} and the binary version of \cite{LBD}, almost all the line segment descriptors are float descriptors. Binary descriptors have significant advantages over float descriptors regarding computational and storage costs. A straightforward method for addressing this challenge is to design binary line segment descriptors based on well-developed binary point feature descriptors.

The third challenge is the inability to describe line segments in challenging scenarios, as mentioned in subsection \ref{subsec_generic_challenges}. To address this issue, some methods can be considered.
\begin{itemize}
	\item Additional geometry constraints, such as homography and epipolar geometry constraints, can be employed to enhance the line segment matching process, as in \cite{Automaticlinematchingacrossviews,MatchingDisparateViewsofPlanarSurfacesusingProjectiveInvariants,Thegeometryandmatchingoflinesandcurvesovermultipleviews,Anovellinematchingmethodbasedonintersectioncontext,Simultaneouslinematchingandepipolargeometryestimationbasedontheintersectioncontextofcoplanarlinepairs,LineMatchinginWideBaselineStereoATopDownApproach,Widebaselinestereomatchingbasedonthelineintersectioncontextforrealtimeworkspacemodeling,RobustLineMatchingBasedonRay-Point-RayStructureDescriptor,NovelCoplanarLinePointsInvariantsforRobustLineMatchingAcrossViews,HierarchicalLineMatchingBasedonLineJunctionLineStructureDescriptorandLocalHomographyEstimation,Linesegmentmatchingandreconstructionviaexploitingcoplanarcues,MultimodalImageRegistrationWithLineSegmentsbySelectiveSearch,Robustlinesegmentmatchingviareweightedrandomwalksonthehomographygraph}. These additional geometry constraints can be used when corresponding requirements, such as the coplanar hypothesis or image pose existence, are satisfied.
		
	\item For vision tasks operating in videos, line segment tracking \cite{Trackinglinesegments,GeometricbasedLineSegmentTrackingforHDRStereoSequences,LOF,LineFlowBasedSimultaneousLocalizationandMapping,HighlyEfficientLineSegmentTrackingwithanIMUKLTPredictionandaConvexGeometricDistanceMinimization,SparseOpticalFlow-BasedLineFeatureTracking} can also be exploited to enhance the line segment matching process.
		
	\item Additional point features can be used to enhance the line segment description \cite{MatchingDisparateViewsofPlanarSurfacesusingProjectiveInvariants,Linematchingleveragedbypointcorrespondences,Robustlinematchingthroughlinepointinvariants,Scaleinvariantlinematchingonthesphere,Line-sweep,NovelCoplanarLinePointsInvariantsforRobustLineMatchingAcrossViews,Dude}. These methods exploit the local coplanar points and lines to describe line segments by leveraging the intrinsic invariance among them, such as the projective invariant method that uses two lines and two points \cite{MatchingDisparateViewsofPlanarSurfacesusingProjectiveInvariants} or one line and four points \cite{Robustlinematchingthroughlinepointinvariants} and the affine invariant approach that uses one line and two points \cite{Linematchingleveragedbypointcorrespondences, Robustlinematchingthroughlinepointinvariants}. The precondition lies in that the point features are matched in advance.
\end{itemize}




\section{Performance Analysis}
\label{sec_performance}

\begin{table*}[tbp] 	
	\centering 	
	\setlength\tabcolsep{2pt} 	
	\scriptsize 	
	\caption{Widely used datasets for performance evaluation on line segment detection and description.} 	\begin{tabular}{|p{0.125\textwidth}<{\centering}|p{0.075\textwidth}<{\centering}|p{0.1\textwidth}<{\centering}|p{0.31\textwidth}<{\centering}|p{0.35\textwidth}<{\centering}|} 		
		\hline 		Dataset           & \# Images & Ground truth           & Notes                                       & URL                                                                                   \\ \hline 		VGGAffine \cite{vggaffine}               & 48        & N/A      & 8 groups with each of 6 natural testing images         & https://www.robots.ox.ac.uk/$\sim$vgg/research/affine/                                \\ \hline 		HPatches \cite{HPatches}          & 696       & N/A      & 116 groups with each of 6 natural testing images       & https://hpatches.github.io/                                                           \\ \hline 		Wireframe \cite{LearningtoParseWireframesinImagesofMan-MadeEnvironments}         & 5462      & wireframe & 5,000 training and 462 testing images (natural) & https://github.com/huangkuns/wireframe                                                \\ \hline 		Original YorkUrban \cite{YorkUrban}         & 102       & line segment           & 45 indoor and 57 outdoor natural testing images             & https://www.elderlab.yorku.ca/resources/york-urban-line-segment-database-information/ \\ \hline 		Refined YorkUrban \cite{ANovelLineletBasedRepresentationforLineSegmentDetection} & 102       & line segment           & 45 indoor and 57 outdoor natural testing images             & https://github.com/NamgyuCho/Linelet-code-and-YorkUrban-LineSegment-DB                \\ \hline 	
	\end{tabular}%
	\label{eva_datasets} 
\end{table*}

In this section, numerous SOTA line segment detection and description methods are qualitatively and quantitatively evaluated to review their performance unbiasedly and strictly. They are evaluated separately because many existing studies individually presented their line segment detection or description methods. Instead of evaluating line segments in specific vision tasks as in \cite{EVOLIN}, the line segment properties mentioned in subsection \ref{subsec_ls_properties} are evaluated in this review. They do not depend on specific vision tasks. Specifically, eleven line segment detection methods in different categories are compared, as listed in TABLE \ref{test_detection_methods}.

\begin{table}[tbp] 	
	\centering 	
	\scriptsize 	
	\caption{Eleven tested line segment detection methods.} 	
	\begin{tabular}{|c|cc|} 		\hline 		Method  & \multicolumn{1}{c|}{Category}                        & Subcategory                              \\ 
		\hline 		HoughP \cite{RobustDetectionofLinesUsingtheProgressiveProbabilisticHoughTransform} & \multicolumn{2}{c|}{Global Hough-based}                                                         \\ \hline 		LSD \cite{LSD}    & \multicolumn{1}{c|}{\multirow{5}{*}{Local-based}}    & \multirow{2}{*}{Gradient grouping-based} \\ \cline{1-1} 		Linelet \cite{ANovelLineletBasedRepresentationforLineSegmentDetection} & \multicolumn{1}{c|}{}                                &                                          \\ \cline{1-1} \cline{3-3}  		EDLines \cite{EDLines} & \multicolumn{1}{c|}{}                                & \multirow{3}{*}{Edge fitting-based}      \\ \cline{1-1} 		FLD \cite{Outdoorplacerecognitioninurbanenvironmentsusingstraightlines}     & \multicolumn{1}{c|}{}                                &                                          \\ \cline{1-1} 		ELSED \cite{ELSED}   & \multicolumn{1}{c|}{}                                &                                          \\ \hline 		FClip \cite{FullyConvolutionalLineParsing}   & \multicolumn{1}{c|}{\multirow{3}{*}{Learning-based}} & \multirow{2}{*}{Line segment detection}  \\ \cline{1-1} 		MLSD \cite{TowardsRealtimeandLightweightLineSegmentDetection}    & \multicolumn{1}{c|}{}                                &                                          \\ \cline{1-1} \cline{3-3}  		L-CNN \cite{End-to-EndWireframeParsing}  & \multicolumn{1}{c|}{}                                & Wireframe detection                      \\ \hline 		MCMLSD \cite{MCMLSD} & \multicolumn{2}{c|}{\multirow{2}{*}{Hybrid-based}}                                              \\ \cline{1-1} 		HTLCNN \cite{DeepHoughTransformLinePriors} & \multicolumn{2}{c|}{}                                                                           \\ \hline 	
	\end{tabular} 	
	\label{test_detection_methods} 
\end{table}

In addition, six line segment description methods, including the LBD \cite{LBD} with its binary version integrated into OpenCV, IILB \cite{IILB}, and MLIOR \cite{ALineMatchingMethodBasedonMultipleIntensityOrderingwithUniformlySpacedSampling} descriptors in the category of statistic-based methods and the DLD \cite{DLD} with its successor WLD \cite{WLD} descriptors in the learning-based method category, are compared. Except for the IILB descriptor and the binary version of the LBD descriptor, the other four testing descriptors are float descriptors. The statistic-based and learning-based methods are also called appearance-based methods in some studies. The structure-based approaches are excluded from the comparison because they require additional line segments; therefore, comparing them with the other two types of methods is unfair.

Note that the related parameters of the compared detection and description methods are set to their default values as suggested in corresponding references or recommended by the OpenCV implementations because they are optimal and already fine-tuned. For deep learning-based methods, the pretrained model detects line segments and extracts line segment descriptors for comparisons.


\subsection{Evaluation Datasets}
\label{subsec_performance_dataset}
As mentioned in subsection \ref{subsec_ls_properties}, line segments should be accurately, robustly, stably, and repeatably detected, described, and matched in multiple images containing the same scene. Here, two well-known natural datasets, as summarized in TABLE \ref{eva_datasets}, \textit{i.e.}, VGGAffine \cite{vggaffine} and HPatches \cite{HPatches}, are employed to evaluate various line segment detection and description algorithms. The corresponding homography matrices enable pixel-to-pixel correspondences between two test images, which in turn provide line segment to line segment correspondences for evaluation. They include test image groups with designed image variance properties. Specifically, the VGGAffine dataset has eight test groups with image variance characteristics of the blur, viewpoint, illumination, JPEG compression, and zoom with rotation. For the HPatches dataset, image viewpoint and illumination variance are provided in the 116 valid test groups with each of the six test images. In addition, a large-scale synthetic dataset, \textit{i.e.}, the KADID 10K dataset \cite{KADID}, is also utilized to evaluate these line segment detection and description algorithms, which includes the typical artificial image variance such as color distortion, noise, sharpness, and contrast.

Furthermore, line segment detection can be regarded as a typical object detection task, in which the carefully and manually labeled ground truth of line segments is employed as a reference for evaluation. Thus, as mentioned in subsection \ref{subsubsec_detection_dataset} and summarized in TABLE \ref{eva_datasets}, two additional datasets with manually labeled ground truth line segments, \textit{i.e.}, the improved YorkUrban \cite{ANovelLineletBasedRepresentationforLineSegmentDetection} and Wireframe \cite{LearningtoParseWireframesinImagesofMan-MadeEnvironments} datasets, are employed to evaluate line segment detection methods. There are 102 and 462 test images available for the improved YorkUrban and Wireframe datasets, respectively.


\subsection{Evaluation Metrics}
\label{subsec_performance_metric}
\subsubsection{Metrics for Line Segment Detection Evaluation}

\begin{figure}[tbp]
	\centering
	\includegraphics[width=0.485\textwidth]{./figures/valid_line_segments.pdf}
	\caption{The detected line segments in $I_1$ are valid if the projected line segments, according to the homography matrix, lie in image $I_2$. In addition, the length of line segments before and after projection should be larger than a threshold, \textit{e.g.}, 15 pixels in this review, to remove line fragments.}
	\label{valid_line_segments}
\end{figure}

\begin{figure}[tbp]
	\centering
	\includegraphics[width=0.45\textwidth]{./figures/matched_line_segment.pdf}
	\caption{Inspired by \cite{ANovelLineletBasedRepresentationforLineSegmentDetection}, two line segments $l_i$ and $l_j$ are a correct line segment pair if the projected line segment $l_j$ lies in the neighborhood of $l_i$, in which the distance $d_{ij}$ between the middle point of $l_j$ and $l_i$, their angle difference $|\theta_j-\theta_i|$, and overlap ratio $r_{ij}$ must satisfy the threshold requirements listed in the figure.}
	\label{matched_line_segment}
\end{figure}

As mentioned above, four datasets with or without ground truth are utilized to assess various line segment detection algorithms from two dimensions. For the category of nonground truth-based approaches, repeatability $\mathcal{R}$, widely used in local feature evaluation \cite{repeatability}, is exploited to evaluate the numerous methods. It can effectively indicate the ability to repeatedly detect line segments in different images containing the same scene. Inspired by \cite{CPDA}, the repeatability in this review is defined as $\mathcal{R} = {N_c}/{2} \times (1/{N^1_t} + 1/{N^2_t})$, in which $N_c$, $N^1_t$, and $N^2_t$ are the numbers of correct line segment pairs and valid line segments in the first and second test images, respectively. The definitions of valid line segments and correct line segment pairs are explained in Fig. \ref{valid_line_segments} and Fig. \ref{matched_line_segment}, respectively. In addition, for correct line segment pairs, only those mutually closest to each other are preserved to eliminate ambiguous line segment pairs.

For the ground truth-based approach, the $F_1$ score, formulated based on detection precision $N_c/N_t$ and recall $N_c/N_g$, is adopted as the key metric to evaluate the consistency with the labeled ground truth. It can be defined as $F_1 = 2 \times N_c / (N_g+N_t)$, in which $N_c$, $N_g$, and $N_t$ are the number of correct line segment pairs, line segment ground truth, and detected line segments, respectively. The validation criteria are listed in Fig. \ref{matched_line_segment}. Similarly, only those mutually closest to each other are preserved to eliminate ambiguous line segment pairs.

\subsubsection{Metrics for Line Segment Description Evaluation}
Since line segment descriptors are constructed based on line segments, line segment detection directly influences the evaluation performance for the line segment description. In this review, two strategies are employed to eliminate the effect of line segment detection as much as possible. (1) The same line segments detected by the LSD \cite{LSD} method are employed to test all descriptors. (2) To eliminate the inconsistent problem of line segment endpoints, inspired by \cite{HPatches}, line segments are only extracted in the first test image and then projected onto other test images according to homography matrices for each test group.

Based on the experimental settings mentioned above, the matching precision ($\mathcal{P}_{m}$) and recall ($\mathcal{C}_{m}$) based on predefined line segments are defined to evaluate the matching ability of line segment descriptors. They can be formulated as $\mathcal{P}_{m} = {N^c_m}/{N^p_m}$ and $\mathcal{C}_{m} = {N^c_m}/{\hat{N^1_{t}}}$, in which $N^p_m$ is the number of putative line segment matches between two test images based on descriptor similarity using the mutual brute-force matching strategy. $N^c_m$ is the number of correct matches in $N^p_m$ validated by the corresponding homography matrix, as shown in Fig. \ref{matched_line_segment}. $\hat{N^1_{t}}$ is the number of validly projected line segments onto other test images according to the extracted line segments in the first image.


\subsection{Results for Line Segment Detection Evaluation}
\begin{figure*}[tbp]
	\centering
	\includegraphics[width=\textwidth]{./figures/detection_non_ground_truth.pdf}
	\includegraphics[width=0.6\textwidth]{./figures/detection_non_ground_truth_bar.pdf}
	\caption{The plots show the average repeatability scores of eleven testing methods for line segment detection evaluated on the HPatches \cite{HPatches}, VGGAffine \cite{vggaffine}, and KADID \cite{KADID} datasets under three evaluation configurations.}
	\label{HPatches_VGG_detection}
\end{figure*}

As shown in Fig. \ref{matched_line_segment}, the thresholds of angle $T_\theta$, distance $T_d$, and overlap ratio $T_r$ are three critical evaluation parameters in the experiment. They control the strictness of matched line segments. Here, three configurations are employed in the experiments: (1) $T_\theta = 5^\circ, T_d = 1, T_r = 0.75$ for a strict configuration, (2) $T_\theta = 10^\circ, T_d = 3, T_r = 0.75$ for a moderate configuration, and (3) $T_\theta = 20^\circ, T_d = 5, T_r = 0.5$ for a loose configuration. Additional experimental results with details can be found in the supplementary material.

\subsubsection{Results of the Nonground Truth-based Approach}
Fig. \ref{HPatches_VGG_detection} shows the average repeatability scores of eleven testing methods evaluated on the three evaluation datasets under three evaluation configurations. The results show some interesting observations. (1) Generally, the local-based approaches outperform those in the other three categories. (2) The learning-based approaches do not significantly improve performance, although they generally have higher computational costs. (3) The global Hough-based approaches perform normally or poorly. (4) The hybrid-based approaches do not perform remarkably, although they incorporate multiple mechanisms to detect line segments.

\subsubsection{Results of the Ground Truth-based Approach}
Fig. \ref{detection_visualization} qualitatively visualizes the line segments detected by the six methods in the four categories. Fig. \ref{Wireframe_YorkUrban_detection} quantitatively exhibits the average $F_1$ scores of eleven testing methods evaluated on the Wireframe and improved YorkUrban datasets under three evaluation configurations. The results show some interesting observations. (1) Regarding the Wireframe dataset, learning-based methods outperform the other three types of methods in general, particularly for the experiments using moderate and loose configurations. (2) Regarding the YorkUrban dataset, local-based approaches generally outperform the other three types of methods. (3) Learning-based approaches perform better with looser evaluation configurations. (4) The global Hough-based approaches perform normally or poorly.

\begin{figure*}[tbp]
	\centering
	\includegraphics[width=\textwidth]{./figures/fig1.pdf}
	\includegraphics[width=\textwidth]{./figures/fig5.pdf}
	\caption{Line segments of two test images detected by six methods in four categories, detailed in TABLE \ref{test_detection_methods}. The top test image comes from the Wireframe dataset, and the bottom image comes from the YorkUrban dataset.}
	\label{detection_visualization}
\end{figure*}

\begin{figure}[tbp]
	\centering
	\includegraphics[width=0.49\textwidth]{./figures/Wireframe_detection_2.pdf}
	\includegraphics[width=0.49\textwidth]{./figures/York_detection_2.pdf}	
	\caption{The two plots show the average $F_1$ scores of eleven testing methods for line segment detection evaluated on the Wireframe (top) and improved YorkUrban (bottom) datasets under three evaluation configurations.}
	\label{Wireframe_YorkUrban_detection}
\end{figure}

\subsubsection{Explanations of the Evaluation Results}
The corresponding explanations regarding the interesting observations above are listed below.
\begin{itemize}
\item In both evaluations above, the global Hough-based methods perform normally or poorly. The major reason is that they lack adequate local connectivity and semantic feature constraints, which may lead to an inaccurate result.

\item In the nonground truth-based evaluation, the local-based approaches outperform the other three types of methods in general. The major reason is that they fully exploit the local connectivity to detect line segments with highly consistent local characteristics, which are easy to detect repeatedly.

\item Considering that most learning-based approaches train their networks based on the Wireframe dataset, the experimental results show that the generalization ability of learning-based approaches is constrained since they only perform well on the Wireframe dataset and perform normally or poorly on the YorkUrban, VGGAffine, and HPatches datasets.

\item The learning-based approaches perform well when the evaluation configuration is moderate and loose. In contrast, they perform normally or poorly when the evaluation configuration is strict, which indicates that the localization accuracy of the learning-based approaches is poor because most of them decrease the image size in line segment detection to decrease the network size.
\end{itemize}


\subsection{Results for Line Segment Description Evaluation}
Fig. \ref{description_visualization} visually shows matched line segments based on four descriptors using the mutual brute-force matching strategy. TABLE \ref{descriptor_type_size} shows the descriptor type and size of six testing line segment descriptors. Fig. \ref{descriptor_performance} quantitatively plots the matching precision ($\mathcal{P}_m$) and recall ($\mathcal{C}_m$) values of six testing line segment descriptors evaluated on the HPatches, VGGAffine, and KADID datasets. Additional experimental results with details can be found in the supplementary material. The experimental results show some interesting observations. (1) The learning-based approaches do not significantly outperform the statistic-based approaches as desired, although they generally need much more computational and memory costs. (2) The float version of the LBD descriptor outperforms the binary version of the LBD descriptor. However, the binary LBD descriptor size is significantly smaller than that of the LBD descriptor. (3) The IILB descriptor generally outperforms the others.

\begin{figure*}[tbp]
	\centering
	\includegraphics[width=\textwidth]{./figures/desc_match_2.jpg}
	\caption{Matched line segments based on four line segment descriptors using mutual brute-force matching strategy. The test images in the first and second rows contain image illumination and viewpoint variance, respectively.}
	\label{description_visualization}
\end{figure*}

\begin{figure}[tbp]
	\centering
	\includegraphics[width=0.49\textwidth]{./figures/descriptor_performance.pdf}
	\includegraphics[width=0.45\textwidth]{./figures/descriptor_performance_bar.pdf}
	\caption{The figure shows matching precision ($\mathcal{P}_m$) and recall ($\mathcal{C}_m$) values of six testing line segment descriptors evaluated on the HPatches, VGGAffine, and KADID datasets.}
	\label{descriptor_performance}
\end{figure}

\begin{table}[tbp] 	
	\centering 	
	\setlength\tabcolsep{1pt}	 	
	\scriptsize 	
	\caption{The descriptor type and size of six testing line segment descriptors.} 	\begin{tabular}{|c|c|c|c|c|c|c|} 		
		\hline 		Descriptor & WLD \cite{WLD}   & DLD \cite{DLD}   & LBD \cite{LBD}  & LBD\_b \cite{LBD} & IILB \cite{IILB} & MLIOR \cite{ALineMatchingMethodBasedonMultipleIntensityOrderingwithUniformlySpacedSampling} \\ \hline 		Type & float & float & float & binary & binary & float \\ \hline 		Size & 512   & 256   & 2304  & 256    & 228 & 6912  \\ \hline 	
	\end{tabular}%
	\label{descriptor_type_size} 
\end{table}

The corresponding explanations in terms of the observations above are listed below.
\begin{itemize}
\item Regarding observation (1), conceptually, learning-based approaches can learn the multiple-layer line segment representations, greatly facilitating the ability of line segment descriptors. However, the network design based on prepared training data also deeply affects the ability of a learning-based approach. Most of them perform remarkably in their testing dataset, not in other testing datasets. The generalization ability of these models is constrained.

\item Regarding observation (2), generally, the float descriptor outperforms the binary descriptor because they need a larger description size and evolve fewer truncation errors.

\item The IILB descriptor outperforms others mainly because it is a hybrid statistic-based descriptor that counts gradient and intensity features in line ROS.
\end{itemize}


\section{Future Research Directions}
\label{research_directions}
The previous sections analyzed and summarized existing line segment detection and description algorithms. This section looks at potentially interesting research directions, providing insights for researchers about line segment detection and description.

\begin{itemize}
	\item \textbf{Line Segment Detection and Description in Color Space.}
	Theoretically, local image features extracted in color space have more discriminative ability than those in gray space, as mentioned in \cite{1542040,977559}. However, most nondeep learning-based line segment detection and description methods operate on gray images, ignoring the corresponding color features to improve efficiency. With increasing computational resources, the concern can be decreased in the future, particularly those without real-time performance requirements. Thus, nondeep learning-based line segment detection and description in color space may receive more attention in the future.
	
	\item \textbf{Line Segment Detection and Description in the Spatiotemporal Domain}
	Local image features extracted in the spatiotemporal domain can reveal more features than those extracted only in the spatial domain, facilitating many vision tasks such as human action recognition \cite{6725627}. However, many existing line segment detection and description methods generally operate on single images (spatial domain) and ignore relationships in the time domain, limiting their applications for sequential vision tasks. In the future, line segment detection and description methods in the spatiotemporal domain may also receive more attention.
		
	\item \textbf{Cross-Modality Line Segment Detection and Description}
	Recently, multiple sensor configurations have been widely employed in many applications, such as sensor fusing-based localization and mapping \cite{9502143,9826793}. The cross-modality local features \cite{9678058} can significantly improve the line segment detection performance and description since they can leverage additional data to overcome the drawback of single-sensor data. Therefore, cross-modality line segment detection and description may receive more attention in the future.
		
	\item \textbf{Line Segment Detection and Description in Other Image Formats}
	With the rapid development of image sensing technology, more images, such as panoramic, spherical, infrared, depth, and event images, are available, providing additional and special sensing information compared with regular images. Many point detection and description methods have been applied to these images. However, only a few line segment detection \cite{ULSD,DetectingLineSegmentsinMotionblurredImageswithEvents} and description methods have been applied to these images. Therefore, line segment detection and description for these images may also receive more attention in the future.
		
	\item \textbf{Hardware Architecture Design and Implementation for Line Segment Detection and Description}
	Optimizing the efficiency of line segment detection and description algorithms is important because it forms the basis for numerous vision tasks. Similar to point \cite{8304764,8382255} and edge \cite{6378440,9546047} features, line segment detection and description algorithms can also be accelerated using hardware architecture.
\end{itemize}


\section{Conclusion}
\label{sec_conclusion}
This study comprehensively reviewed more than one hundred line segment detection and description algorithms to give academics an overall picture and deep understanding of them. Based on their mechanisms, two taxonomies were presented to introduce, analyze, and summarize these algorithms, facilitating researchers in quickly and extensively learning about them. For the algorithms in each category, their key issues, core ideas, advantages and disadvantages, and potential applications were also analyzed and summarized, including some previously unknown findings. This review also summarized existing challenges in line segment detection and description algorithms and provided some insights to potentially address these challenges. Some representative SOTA methods were unbiasedly evaluated based on natural and synthetic datasets to further show the performance of various line segment detection and description algorithms. The theoretical analysis and experimental results can guide scholars in selecting the best method for their intended applications. Finally, this study proposed potentially interesting future research directions to attract more attention from researchers to this field.

\bibliography{IEEEabrv,line_features,line_features_detection,line_features_description,others}
\bibliographystyle{IEEEtran}

\end{document}



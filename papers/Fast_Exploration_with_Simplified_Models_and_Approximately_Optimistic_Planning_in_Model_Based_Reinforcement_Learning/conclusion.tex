\section{Conclusion and Future Work}
To conclude, we showed how we can achieve a sample efficient RL algorithm with object priors. We proposed optimistic MCTS as a way to drive deep exploration when exact planning is impossible, and showed this to be more effective than posterior sampling methods. Additionally, we investigate how approximately deterministic simple models can be learned with object representation to support fast learning and planning.

We introduced Strategic Object Oriented RL (SOORL) that uses object representation and optimistic MCTS with automatic model selection that biases towards simple deterministic models. SOORL achieves state of the art results in the game of $\textit{Pitfall!}$. While there remains works to be done to reduce the engineering burden of SOORL, lookahead planning with object representation is a very promising path towards more sample efficient RL algorithms.

A very important line of future research is \textbf{robust planning}. One important challenge in model-based RL is making planning robust to model
inaccuracy. Identifying the right model class is a nontrivial task, and a wrong model class can
easily introduce a catastrophic error in long-horizon prediction that prohibits the use of tree search
algorithms like UCT.


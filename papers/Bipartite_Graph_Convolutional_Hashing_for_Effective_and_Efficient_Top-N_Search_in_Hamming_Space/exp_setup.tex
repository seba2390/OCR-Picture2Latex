\subsection{\textbf{Experiment Setup}}
\label{sec:exp_setup}

\textbf{Datasets and evaluation metrics.} 
We include six real-world bipartite graphs in Table~\ref{tab:datasets} that are widely evaluated~\cite{lightgcn,chen2021hyper,chen2021attentive,yang2022hrcf,ngcf,zhang2022knowledge}.
We adopt evaluation protocols Recall@N and NDCG@N to measure the Top-N Hamming space ranking capability.
% Dataset details and evaluation procedure are explained in Appendix~\ref{app:exp}.
Dataset details and evaluation procedure are explained in Appendix D.




\begin{table}[t]
% \setlength{\abovecaptionskip}{0.2cm}
% \setlength{\belowcaptionskip}{0.2cm}
\centering
\small
\caption{The statistics of datasets.}
\vspace{-0.15in}
\label{tab:datasets}
\setlength{\tabcolsep}{0.8mm}{
\begin{tabular}{c | c | c | c | c | c | c}
\toprule 
             & {\footnotesize MovieLens}  & {\footnotesize Gowalla}   & {\footnotesize Pinterest}  &  {\footnotesize Yelp2018} & {\footnotesize AMZ-Book} & {\footnotesize Dianping}\\
% \midrule
\midrule[0.1pt]
    {\footnotesize |$\mathcal{V}_1$| }  & {6,040}   & {29,858}   & {55,186}   & {31,668}  &{52,643}  &{332,295}  \\ 
    {\footnotesize |$\mathcal{V}_2$| }  & {3,952}   & {40,981}   & {9,916}    & {38,048}  &{91,599}  &{1,362}  \\
\midrule[0.1pt]
    {\footnotesize |$\mathcal{E}$| } & {1,000,209} & {1,027,370} & {1,463,556} & {1,561,406} & {2,984,108} &{10,000,014} \\
   \midrule[0.1pt]
 Density  & {0.04190}   & {0.00084}   & {0.00267}   & {0.00130}  &{0.00062}  &{0.02210}  \\
\bottomrule
\end{tabular}}
\end{table}



% \subsection{\textbf{Competing Methods}}
\textbf{Baselines.}
\label{sec:baseline}
We include the following representative hashing-based models for (1) general object retrieval (LSH~\cite{lsh}), (2) image search (HashNet~\cite{hashnet}), and (3) Top-N candidate generation for recommendation (Hash\_Gumbel~\cite{gumbel1,gumbel2}, CIGAR~\cite{kang2019candidate} and HashGNN~\cite{hashgnn}).
We also include several state-of-the-art full-precision\footnote{They are denoted by FT32 as we implement them with float32 in the experiments.} recommender models, i.e., NeurCF~\cite{neurcf}, NGCF~\cite{ngcf}, DGCF~\cite{dgcf}, LightGCN~\cite{lightgcn}, for the long-list ranking quality comparison.
% Model introductions are referred in Appendix~\ref{app:baselines}.
Model introductions are referred in Appendix D.
Early hashing methods, e.g., SH~\cite{weiss2008spectral}, RMMH~\cite{joly2011random}, LCH~\cite{zhang2010laplacian}, are excluded mainly because the above competing models~\cite{hashnet,kang2019candidate} have already validated the performance superiority over them. 



\subsection{\textbf{Comparing to FT32-based Models (RQ2)}}
\label{sec:exp_full}
\begin{table}[t]
\centering
\scriptsize
\caption{NDCG@1000 results of Float32-based models.}
\vspace{-0.15in}
\label{tab:full}
\setlength{\tabcolsep}{2mm}{
\begin{tabular}{c |c | c | c | c | c| c}
\toprule
    ~            & Movie & Gowalla & Pinterest & Yelp2018 & AMZ-Book & Dianping \\
\midrule
  NeurCF        & {58.76}  & {32.07} & {28.79} & {24.69} & {19.83} & {25.54} 	   \\
  NGCF         & {60.28}  & {32.13} & {29.78} & {25.23} & {20.37} & {25.76} 	   \\
  DGCF         & {62.41}  & {34.97} & \underline{31.47} & {26.28} & {21.74} & {26.87} 	   \\
  LightGCN     & \underline{62.88}  & \underline{35.26} & {31.32} & \underline{26.55} & \underline{21.92} & \underline{27.28} 	   \\
\midrule[0.1pt]
  \model            & \textbf{59.16}  & \textbf{32.87}   & \textbf{29.09}   & \textbf{25.01}   & \textbf{19.79}   & \textbf{25.57}   \\
  \% capacity	&{94.08\%} &{93.22\%} &{92.44\%} &{94.20\%} &{90.28\%} &{93.73\%} \\
\bottomrule
\end{tabular}}
\end{table}



In this section, we also compare \model~with several full-precision (FT32-based) models to evaluate the long-list search quality. 
% We use NDCG metric to indicates the ranking quality.
As we can observe from Table~\ref{tab:full}, we have the following analyses.
(1) We notice that our model \model~generally performs competitively with early full-precision models, e.g., NeurCF and NGCF, over all datasets.
As for the state-of-the-art model LightGCN, our model can generally achieve over 90\% of the Top-1000 ranking capability.
(2) The performance of \model~demonstrates its effectiveness in guaranteeing the long-list Top-N retrieval quality.
This is useful for some industrial applications, e.g., recommender systems, which usually consist of two major stages: \textit{candidate generation} and \textit{re-ranking}.
Thus, obviously, the good quality of candidate generation directly reduces the complexity of next-stage re-ranking, as the search space is substantially pruned.
(3) Considering the \textit{efficiency in Hamming space retrieval} and the \textit{reduced space cost} of those learned hash codes, we believe that \model~can provide the optional alternative to these full-precision models, especially in scenarios with limited computation resources.


\section{\model: Methodology}
\label{sec:method}
\begin{figure*}[tp]
\hspace{-0.1in}
\begin{minipage}{1\textwidth}
\includegraphics[width=7.1in]{figs/short_frame.pdf}
\end{minipage} 
% \setlength{\abovecaptionskip}{0.2cm}
% \setlength{\belowcaptionskip}{0.2cm}
\vspace{-0.1in}
\caption{(a) Visualized loss landscape comparison; (b) \model~model framework (best view in color); (c) Fourier Serialized gradient estimation in forward and bachward propagation. }
\label{fig:model}
% \vspace{-0.1in}
\end{figure*}


\subsection{Overview}
We formally introduce our \model~ model.
Notice that since the effect of feature dispersion module propagates along with convolutional hashing, we then introduce these modules in the following order:
(1) \textit{latent feature dispersion} (\cref{sec:fd}) aims to disperse the embedded features into wider embedding structures to hedge the inevitable information loss in hashing;
(2) \textit{adaptive graph convolutional hashing} (\cref{sec:hashing}) provides an effective encoding approach to significantly improve the hashed feature expressivity whilst maintaining the matching efficiency in the hamming space;
(3) \textit{Fourier serialized gradient estimation} (\cref{sec:ge}) introduces the Fourier Series decomposition for $\sign(\cdot)$ in the frequency domain to provide more accurate gradient approximation.
Based on the learned hash codes, \model~ develops efficient online matching with the Hamming distance measurement (\cref{sec:score}).
Our model illustration is attached in Figure~\ref{fig:model}(b).



% \begin{figure*}[tp]
% \hspace{-0.3cm}
% \begin{minipage}{1\textwidth}
% \includegraphics[width=7.1in]{figs/short_frame}
% \end{minipage} 
% \setlength{\abovecaptionskip}{0.2cm}
% \setlength{\belowcaptionskip}{0.2cm}
% \caption{Visualized loss landscape comparison and \model~model framework (best view in color).}
% \label{fig:model}
% \end{figure*}

\input{method_fd}

\input{method_hashing}

\input{method_gradient}

\input{method_optimize}






\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2020

% ready for submission
% \usepackage{neurips_2023}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2020}

% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2020}

% to avoid loading the natbib package, add option nonatbib:
 \usepackage[final]{neurips_2023}
 \setcitestyle{round}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{graphicx}      % includegraphics
\usepackage{xspace}
\usepackage[export]{adjustbox}

\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.16}
\usepackage{subcaption}
\usepackage{xcolor}
\usepackage{enumitem}
\usepackage[font=small]{caption}
\usepackage{stfloats}
\usepackage{colortbl}
\usepackage{makecell}

\newcommand{\ours}{\textsc{Pix2Act}\xspace}
\newcommand{\commentout}[1]{}

\makeatletter
\DeclareRobustCommand\onedot{\futurelet\@let@token\@onedot}
\def\@onedot{\ifx\@let@token.\else.\null\fi\xspace}

\def\aka{\emph{a.k.a}\onedot} \def\Eg{\emph{A.k.a}\onedot}
\def\eg{\emph{e.g}\onedot} \def\Eg{\emph{E.g}\onedot}
\def\ie{\emph{i.e}\onedot} \def\Ie{\emph{I.e}\onedot}
\def\cf{\emph{c.f}\onedot} \def\Cf{\emph{C.f}\onedot}
\def\etc{\emph{etc}\onedot} \def\vs{\emph{vs}\onedot}
\def\wrt{w.r.t\onedot} \def\dof{d.o.f\onedot}
\def\etal{\emph{et al}\onedot}
\makeatother

\newcommand{\frank}[1]{{\color{brown}Frank: #1}\xspace}
\newcommand{\pete}[1]{{\color{blue}Pete: #1}\xspace}
\newcommand{\kristout}[1]{{\color{magenta}Kristina: #1}\xspace}
\newcommand{\uk}[1]{{\color{orange}Urvashi: #1}\xspace}
\newcommand{\kenton}[1]{{\color{cyan}Kenton: #1}\xspace}
\newcommand{\mandar}[1]{{\color{red}Mandar: #1}\xspace}
\newcommand{\ice}[1]{{\color{green!65!blue}Ice: #1}\xspace}
\newcommand{\james}[1]{{\color{yellow}James: #1}\xspace}
\newcommand{\jb}[1]{{\color{purple}Jonathan: #1}\xspace}

% https://coolors.co/e0e1e0-f25f5c-ffe066-247ba0-70c1b3
\definecolor{dred}{HTML}{F25F5C}
\definecolor{dblue}{HTML}{247BA0}
\definecolor{dgreen}{HTML}{70C1B3}


% \title{Learning to Control Computers Via User Interfaces}
% \title{Accomplishing Tasks with Graphical User Interfaces via Pixel-Based Representations}
% \title{From Pixels to UI Actions: Learning to Follow Instructions Via Graphical User Interfaces }
\title{From Pixels to UI Actions: Learning to Follow Instructions via Graphical User Interfaces}


% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.


\author{%
  Peter Shaw$^1$\thanks{Equal contribution.}  \\
  \And 
  Mandar Joshi$^1$\footnotemark[1] \\
  \And
  James Cohan$^2$ \\
  \And
  Jonathan Berant$^1$ \\
  \And
  Panupong Pasupat$^1$ \\
  \And
  Hexiang Hu$^1$ \\
  \And
  Urvashi Khandelwal$^1$ \\
  \And
  Kenton Lee$^1$ \\
  \And
  Kristina Toutanova$^1$
  \\
  \\
 $^1$ Google DeepMind ~~~~~~~~ $^2$ Google
}

\begin{document}

\maketitle

\begin{abstract}
Much of the previous work towards digital agents for graphical user interfaces (GUIs) has relied on text-based representations (derived from HTML or other structured data sources), which are not always readily available. These input representations have been often coupled with custom, task-specific action spaces.  This paper focuses on creating agents that interact with the digital world using the same conceptual interface that humans commonly use â€” via pixel-based screenshots and a generic action space corresponding to keyboard and mouse actions. Building upon recent progress in pixel-based pretraining, we show, for the first time, that it is possible for such agents to outperform human crowdworkers on the 
MiniWob++ benchmark of GUI-based instruction following tasks.
\end{abstract}

\input{sections/intro.v3}
\input{sections/environment}
\input{sections/agent}
\input{sections/experiments}
\input{sections/related}
\input{sections/limitations}
\input{sections/ack}

\bibliographystyle{plainnat}
\bibliography{main}

\appendix

\input{sections/appendix}

\end{document}



Dimensionality reduction (DR) is one of the most widely used tools in conducting the visual cluster analysis of high-dimensional data \cite{ jiazhi21tvcg, pezzotti16cgf, jeon22arxiv, kwon18tvcg, quadri21tvcg, quadri22tvcg}. Using DR for cluster analysis relies on the assumption that the cluster structure of the original data is accurately represented in the low-dimensional DR embeddings. However, DR inherently generates distortions, i.e., the original cluster structure is imprecisely represented in the embeddings \cite{aupetit07neurocomputing, aupetit14vast, heulot13vamp, lespinats07tnn, lespinats11cgf}. As distortions can make visual cluster analysis performed with DR unreliable \cite{jeon21tvcg, jeon22arxiv},  it is important to evaluate how well the original cluster structure is preserved in the DR embeddings \cite{jiazhi21tvcg, jeon21tvcg, martins14cg, joia11lamp}, prior to the analysis. There exist ways to evaluate the reliability of cluster structures in DR embeddings, in either a perceptual \cite{etemadpour15ivapp, jiazhi21tvcg, sedlmair13tvcg} or computational \cite{jeon21tvcg, venna06nn, lee07springer, motta15neurocomputing} manner.

A general process to evaluate the preservation of cluster structure in DR embeddings is to utilize class labels. 
This is done by assessing \textit{cluster-label matching} (CLM), that is, the extent to which class labels form clusters in the embedded space \cite{joia11lamp, loch15neurocomputing, xia22tvcg, becht19nature, xiang21fig, yang21cellreports}.
CLM is mostly evaluated by using \textit{clustering validation measures} (CVMs) \cite{liu10icdm, wu09kdd}, such as the Silhouette Coefficient \cite{rousseuw87silhouette}.
CVMs inform how well the groups in the given label-based data partition form clear position-based clusters.
The partitions that contain mutually separated and individually condensed groups are preferred. 
For the label-based evaluation of DR, data embeddings and class labels are used as an input dataset and partition, respectively.
Embeddings with good CLM are considered to have good quality, assuming that the original data also have good CLM.

However, such an assumption can hardly be guaranteed \cite{aupetit14beliv, jiazhi21tvcg, farber10multiclust, jeon22arxiv2}.
\rev{There is no constraint on labels' sources. Labels can come from} an external source (e.g., human annotation), \rev{possibly unrelated to the features of the data space. Labels can also result from clustering techniques, which may not align with the actual clusters. 
Therefore, we do not know how well labels make up the clusters in the original data};
a single class can consist of multiple separated clusters, and multiple classes can be in close proximity or even overlapped \cite{aupetit14beliv} in a single cluster. 
These possibilities cast doubt on the conclusions derived from the general process of  label-based DR evaluation. 
For instance, an embedding that accurately represents overlapping classes in the original space might be considered to have low quality as it has bad CLM.




In this work, we revisit the process of evaluating DR using class labels. 
We introduce two measures---\textit{\LT} (\lt) and \textit{\LC} (\lc)---which examine CLM in an alternative way to assess the reliability of cluster structures in DR embeddings.
In contrast to the general label-based evaluation process, \ltc use CVM to quantify CLM \textit{distortions} as the difference between CLM estimated in both original and embedded spaces. 
\lt quantifies the distortion due to the degradation of CLM: the score is lower when the points of two different classes get closer in the embedding than in the original space. 
Conversely, \lc evaluates the distortion regarding the exaggeration of CLM: the score is lower when the points of two different classes get farther apart in the embedding than in the original space.
The rationale behind our measures is that in visual cluster analysis, it is important to investigate how class labels span the original cluster structure as seen through the embedding \cite{brehmer14beliv, aupetit14beliv, aupetit22arxiv, aupetit22topoinvis, wenskovitch18tvcg} (e.g., examine the individual density of a class or the pairwise proximity between classes). Since CLM distortions reduce the reliability of cluster structures represented by the embeddings, \ltc scores can be interpreted as proxies for the credibility of DR-based cluster analysis. 



We conduct a series of quantitative experiments to validate the effectiveness of \ltc. 
The results show that \ltc can better capture the distortions of cluster structures than the existing measures (e.g., Steadiness \& Cohesiveness \cite{jeon21tvcg} and Trustworthiness  \& Continuity \cite{venna06nn}) and the general process of label-based DR evaluation (i.e., naive application of CVMs).
From the scalability analysis, we validate that the runtime of using \ltc is competitive with that of the existing methods.
Finally, we demonstrate two case studies showing that  \ltc can be used to reveal how different DR techniques or hyperparameter settings affect embedding results. 




\section{\LS \& \LC}

\label{sec:lsc}

We introduce two distortion measures---\LT and \LC (\lsc)---as an alternative way of using class labels for DR evaluation. 
Our measures examine how CLM differs in \textit{both} the original and embedded spaces where CVM is used to quantify CLM.
\lt and \lc capture the False and Missing Groups distortions, respectively. 
The measures are named after Trustworthiness and Continuity, two local distortion measures that focus on capturing False and Missing Neighbors \cite{venna06nn}.


\subsection{Design Rationale}

\label{sec:overcom}

\noindent
\textbf{Inputs, output, and hyperparameters} \ltc take (1) the high-dimensional data $\mathbf{X}$, (2) its DR embedding $\mathbf{Z}$, and (3) class labels $\mathbf{\mathbf{P}_L} = \{P_{L,1}, P_{L,2}, \cdots P_{L,k} \}$ as inputs. Both \lt and \lc output a number between 0 and 1; a higher value indicates lower distortions and a better embedding. For hyperparameters, a CVM $m$ with distance function $\delta$ is given. If $m$ is an EVM, we need to additionally select the clustering technique $C$ as a hyperparameter (\autoref{sec:cvmprocess}). The $m$ should assign higher scores to better clusterings and range from 0 to 1 (refer to \autoref{sec:req} for a detailed explanation about this requirement). 

\noindent
\textbf{Step 1. Measuring CLM in the original and embedded spaces}
We apply CVM to both the original and embedded spaces to examine CLM. Here, unlike the general process of label-based DR evaluation that applies CVM to all classes at once, we apply CVM to every \textit{pair} of classes, so that we can take account of the relationships of classes in more detail.
% To examine CLM in detail, we apply CVM to every pair of classes in both the original and embedded spaces. 
Formally, we construct the class-pairwise CLM matrices $M(\mathbf{X})$ and $M(\mathbf{Z})$, where the $(i, j)$-th cell of the matrices $M(\mathbf{S})_{i,j}$ ($\mathbf{S} \in \{\mathbf{X}, \mathbf{Z}\}$) is defined as:
\[
\left\{
\begin{array}{rcl} 
m(\{P_{L, i}, P_{L, j}\}, \mathbf{S}, \delta) & \text{if} & i \neq j \text{ and $m$ is an IVM} \\ 
m(C(P_{L, i} \cup P_{L, j}, \delta), \{P_{L, i}, P_{L, j}\}) & \text{if} & i \neq j \text{ and $m$ is an EVM} \\
0 & \text{if} & i=j 
\end{array}
\right..
\]


\noindent
\textbf{Step 2. Computing distortion matrices}
We construct a matrix $M^{*} = M(\mathbf{X}) - M(\mathbf{Z})$ representing CLM distortions. We then compute $M^{FG}$ and $M^{MG}$, where $M^{FG}_{i,j} = (M^{*}_{i,j}$ if $M^{*}_{i,j} >0$, else $0)$, and $M^{MG}_{i,j} = (-M^{*}_{i,j}$ if $M^{*}_{i,j} <0$, else $0)$. 
$M^{FG}$ and $M^{MG}$ abstract the CLM decrement (False Groups) and increment (Missing Groups), respectively.


\noindent
\textbf{Step 3. Aggregating distortions}
Finally, we average the \rev{upper-diagonal elements of} $M^{FG}$ and $M^{MG}$ into final scores:

\begin{itemize}
    \item[] \hspace{7mm} \textsc{\LT}: $1 - \mbox{avg}_{i, j} \rev{M^{FG}_{i > j}}$ \vspace{-2mm}
    \item[] \hspace{7mm} \textsc{\LC}: $1 - \mbox{avg}_{i, j} \rev{M^{MG}_{i > j}}$.
\end{itemize}
Note that we subtract the average from 1 to make embeddings with fewer distortions receive higher quality scores.




\subsection{Selecting CVM for \lsc}

We establish the requirements for CVM to get proper \ltc scores and present suitable CVM options.
In this section, we denote $m(\mathbf{P}, \mathbf{S}, \delta)$ as a CVM score with respect to $\mathbf{P}$, $\mathbf{S}$, and $\delta$.
If $m$ is an IVM $m_I$, we set $m(\mathbf{P}, \mathbf{S}, \delta) = m_I(\mathbf{P}, \mathbf{S}, \delta)$. If $m$ is an EVM $m_E$, we set $m(\mathbf{P}, \mathbf{S}, \delta) = m_E(C(\mathbf{S}, \delta), \mathbf{P})$ with $C$, the chosen clustering technique.

%Throughout this section, we denote CVM as $m$, where $m(\mathbf{P}, \mathbf{X}, \delta)$ is the the score over $\mathbf{P}, \mathbf{X}$, and $ \delta$.
%If we use IVM, $m$ directly corresponds to the measure (i.e., $m(\mathbf{P}, \mathbf{X}, \delta) = m_I(\mathbf{P}, \mathbf{X}, \delta) $ for IVM $m_I$).
%For EVM, $m$ denotes the process of running the clustering technique and comparing the results with the class labels using EVM (i.e., $m(\mathbf{P}, \mathbf{X}, \delta) = m_E(C(\mathbf{X}, \delta), \mathbf{P})$ for EVM $m_E$ and clustering technique $C$).

\subsubsection{Requirements}

\label{sec:req}


We set the first three requirements based on the following proposition: to be used for \ltc, a proper CVM should be comparable across $\mathbf{X}$ and $\mathbf{Z}$.
In other words, $m$ shall consider only \textit{how well the given partition is clustered in the given data} and be invariant to the characteristics that differ between $\mathbf{X}$ and $\mathbf{Z}$ but are not related to the cluster structure. 
For example, the scaling of the pairwise distances should not alter the score. Otherwise, the evaluation will be unreliable; for example, we can simply manipulate \ltc scores by scaling the original or embedded data while there is no change in the cluster structure.

Previous works \cite{jeon22arxiv2, bendavid08neurips} set axioms defining how a CVM can be independent of such features.
They require CVMs to be invariant to the change of scale, dimensionality, and the number of points and classes and to have a fixed range. 
As $\mathbf{X}$ and $\mathbf{Z}$ already share the number of points and classes, we require CVMs to ensure the other three axioms. %requirements: borrowed the remaining three as our requirements.


The first axiom requires CVMs to be invariant against the scaling of distances between points, which can be inherently different in $\mathbf{X}$ and $\mathbf{Z}$:
\begin{itemize}[leftmargin=0pt]
    \item [] \textbf{Scale Invariance \cite{bendavid08neurips}} \textit{A CVM $m$ is scale invariant if $\forall$ partition $\mathbf{P}$, data $\mathbf{S}$, and distance function $\delta$, $m(\mathbf{P}, \mathbf{S}, \delta) = m(\mathbf{P}, \mathbf{S}, \alpha \delta)$ $\forall \alpha > 0$ (where $\alpha \delta$ is a distance function satisfying $\alpha \delta(x,y) = \alpha \cdot \delta(x,y)$, $\forall x, y \in \mathbf{S}$.). }
    \item [] \textbf{(R1)} A CVM should satisfy scale invariance.
\end{itemize}

The second axiom focuses on the effect of the data dimension on the distance $\delta$, due to the so-called curse of dimensionality \cite{bellman66science}. 
The growing dimensions increase the average of pairwise distances while the variances remain constant \cite{beyer99icdt, francois07tkde, lee11pcs}, thus the differences between distances become negligible. 
%As $\mathbf{X}$ and $\mathbf{Z}$ have different dimensions, the effect should be minimized; 
To be used for \ltc, CVM should be shift invariant \cite{lee11pcs, lee14cidm} to cancel the shift of the average distances due to the different dimensions of $\mathbf{X}$ and $\mathbf{Z}$.
\begin{itemize}[leftmargin=0pt]
    \item[]  \textbf{Shift Invariance \cite{jeon22arxiv2}} \textit{A CVM $m$ is shift invariant if $\forall \mathbf{P}, \mathbf{S}, \delta$, $m(\mathbf{P}, \mathbf{S}, \delta) = m(\mathbf{P}, \mathbf{S}, \delta+ \beta)$ $ \forall \beta > 0$ (where $\delta + \beta$ is a distance function satisfying $(\delta + \beta)(x,y) = \delta(x,y) + \beta$, $\forall x, y \in \mathbf{S}$).}
    \item[]  \textbf{(R2)} A  CVM should satisfy shift invariance.
\end{itemize}

The final axiom is about requiring CVMs to produce scores that conform to a fixed range of values, which is designed to capture the remaining subtle factors that are not influenced by the cluster structure. 
\begin{itemize}[leftmargin=0pt]
    \item[]  \textbf{Range Invariance \cite{jeon22arxiv2}} \textit{A CVM $m$ is range invariant if $\forall \mathbf{S}, \delta$, $\min_{\mathbf{P}} m(\mathbf{P},\mathbf{S},\delta)=\alpha$ and $\max_{\mathbf{P}} m(\mathbf{P},\mathbf{X},\delta)=\beta$, where $\alpha, \beta$ are constants satisfying $\alpha < \beta$ (arbitrarily set to 0 and 1, respectively).}
    \item[]  \textbf{(R3)} A CVM should satisfy range invariance.
\end{itemize}

Additionally, we want CVMs to be stable against the change of hyperparameters. 
This is because the alteration of CVM scores due to the hyperparameter change can induce uncertainty in utilizing \ltc. 
This leads to the last axiom:

\begin{itemize}[leftmargin=0pt]
    \item[]  \textbf{(R4)} A CVM should have no hyperparameter or should produce similar scores on the same input regardless of the hyperparameter settings.
\end{itemize}



\subsubsection{CVM Candidates}
\label{sec:lsc-examples}

We examine CVMs commonly used for DR evaluation (\autoref{sec:cvmprocess}) as potential candidates to be used for \ltc. 
\rev{For EVMs, we find that the combination of $K$-Means and adjusted rand index cannot be used. This is because the parameter $K$ (i.e., number of clusters) in $K$-Means
leads to the violation of \textbf{R4}. Indeed, as clustering techniques commonly require hyperparameters, EVMs hardly satisfy the aforementioned requirements. Studying how EVMs and clustering techniques can satisfy R4 is beyond the scope of this work.}

% At first, EVMs are excluded because clustering techniques have many hyperparameters that significantly affect the output partition, invalidating \textbf{R4}.
% For example, it is improper to use $K$-Means in the context  \cite{zubaroglu20icbdr, xiang21fig, ji21jasa} as $K$ (i.e., number of clusters) changes clustering results substantially.
For IVMs,  neither the Silhouette Coefficient \cite{rousseuw87silhouette} nor the Davies-Bouldin index \cite{davies79tpami} satisfies shift invariance (\textbf{R2}; refer to Appendix A for the proof). However, we found that DSC satisfies all requirements, setting it as a proper CVM for \ltc (Appendix A).


We additionally found that the between-dataset Calinski-Harabasz index ($CH_{btwn}$) \cite{jeon22arxiv2}, a variant of Calinski-Harabasz index \cite{calinski74cis}, satisfies the four requirements: satisfaction of \textbf{R1}, \textbf{R2}, and \textbf{R3} has been demonstrated earlier \cite{jeon22arxiv2}; it also satisfies \textbf{R4} as its unique hyperparameter is the number of Monte-Carlo simulations for normalizing the measure, which barely affects the output if the number is sufficiently high.
% We select $CH_{btwn}$  as it is already proven to fulfill our requirements; it was proposed along with the axioms as an example measure that satisfies every axiom introduced in the same work .
We give a brief description of these two CVMs usable for \ltc:

\noindent
\textbf{Distance Consistency (DSC) \cite{sips09cgf}} DSC is defined as the number of data points closer to the centroid of another class than their own in the data, normalized by the total number of data points.  As DSC ranges from $0.5$ to $1$ \rev{if the number of classes is two} and assigns a lower score for a better CLM, we use the value $2(1 - \text{DSC})$ to make it satisfy \textbf{R3} (\autoref{sec:overcom} (Step 1)).

\noindent
\textbf{Between-dataset Calinski-Harabasz index ($CH_{btwn}$) \cite{jeon22arxiv2}}
$CH_{btwn}$ is defined as the ratio of compactness to separability. Compactness is defined as the distance between data points and the class centroids to which each point belongs, and separability is determined by the distances between class centroids and the centroid of the entire data. 



\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{figures/guideline.pdf}
    \vspace{-6mm}
    \caption{Guidelines to infer the CLM of the high-dimensional data based on the CLM of the embedded data (left column) and the scores given by \lt (L-T) and \lc (L-C) (first row) (see \autoref{sec:guideline} for details).
    }
    \vspace{-3mm}
    \label{fig:guide}
\end{figure}





\subsection{Guidelines to Interpret \ltc}

\label{sec:guideline}

We present the guidelines to interpret embeddings based on \ltc.
If \lt and \lc are both high,  the CLM of the embedding accurately depicts the CLM in the original space (\autoref{fig:guide}A). 
High \lt and low \lc (\autoref{fig:guide}B) mean that Missing Groups distortions have occurred, i.e., the CLM of the original data is worse than it appears in the embedding (first row); some pairs of classes appear more separated than they actually are in the data space. 
When the CLM of the embedding is already low (\textit{e.g.} due to overlapping classes), Missing Groups distortions are more unlikely to happen as the CLM in the data would have to be even worse (second row).
In contrast, low \lt and high \lc (\autoref{fig:guide}C) inform that False Groups distortions have occurred; the CLM in the original data is better than in the embedding (second row).
As False Groups distortions deteriorate the CLM of the embedding, the situation is unlikely to occur if the embedding has a good CLM, and thus can hardly become better (first row).
\rev{Due to such a tradeoff between False and Missing Groups (i.e., more Missing Groups lead to fewer False Groups, and vice versa), }
it is unlikely to get low \lt and \lc at the same time (\autoref{fig:guide}D). \rev{Our sensitivity analysis (\autoref{sec:seneval}; \autoref{fig:senexp}) confirms the existence of the tradeoff. }


\subsection{Time Complexity}

The complexity of \ltc depends on the CVM. 
As DSC is  $O(|\mathbf{S}||\mathbf{P}_L|\Delta_\mathbf{S})$, where  $\Delta_\mathbf{S}$ denotes the dimensionality of $\mathbf{S}$, applying it to a pair of classes $P_{L,i}, P_{L,j}$ requires $O(|P_{L,i} \cup P_{L,j}|\Delta_\mathbf{S})$. As each class is considered $|\mathbf{P}_L|$ times, \ltc with DSC is $O(|\mathbf{S}||\mathbf{P}_L|\Delta_\mathbf{S})$. 
Similarly, as \CHb is $O(|\mathbf{S}||\mathbf{P}_L|^2\Delta_\mathbf{S})$, applying it to a pair of classes $P_{L,i}, P_{L,j}$ requires $O(|P_{L, i} \cup P_{L, j}|\Delta_\mathbf{S})$. Therefore,  \ltc with \CHb is $O(|\mathbf{S}||\mathbf{P}_L|\Delta_\mathbf{S})$. In both cases, the time complexity is linear in all variables. We  evaluate the scalability of \ltc in \autoref{sec:scaleval}.



\subsection{Implementation \& Deployment}

We deploy \ltc as a Python library. We provided an interface that allows users to implement and test custom CVM as a hyperparameter. The source code is available at \href{https://github.com/hj-n/ltnc}{\texttt{github.com/hj-n/ltnc}}.


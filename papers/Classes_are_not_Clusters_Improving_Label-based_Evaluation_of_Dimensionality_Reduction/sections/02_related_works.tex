\section{Background and Related Works}


We discuss the state-of-the-art in interpreting and measuring the reliability of DR embeddings. 
We then describe works about the common assumption that high-dimensional labeled data have good CLM.

\subsection{Reliability of Dimensionality Reduction}

\rev{
\subsubsection{Dimensionality Reduction}
}

Dimensionality reduction (DR), e.g., $t$-SNE \cite{maaten08jmlr}, UMAP \cite{mcinnes2020arxiv}, aims to produce the low-dimensional embedding preserving the structure of the input high-dimensional data. \rev{DR plays an important role in many visual analytics tasks, including cluster identification \cite{jeon22arxiv, xia22tvcg} or neighborhood search \cite{etemadpour15ivapp, etemadpour15tvcg, lespinats11cgf}. This research provides reliable measures for evaluating DR embeddings regarding the matching between clusters and classes in both input and embedding spaces, establishing a basis for more trustworthy DR-based visual analysis. }


\rev{
\subsubsection{Distortions in Dimensionality Reduction}
}

While transferring the data from broad high-dimensional space to narrow low-dimensional space, DR unavoidably introduces distortions \cite{nonato19tvcg, aupetit07neurocomputing}.
As distortions make embeddings less reliable in representing the original data, informing distortions is important in utilizing DR for data analysis \cite{nonato19tvcg, jeon21tvcg}.

Several distortion types were defined to formally explain DR distortions. Aupetit \cite{aupetit07neurocomputing} initially defined \textit{stretching} and \textit{compression}. Stretching describes the situation in which the pairwise distances in the embedded space are increased compared to the ones of the original space; conversely, compression indicates the case that the pairwise distances decreased. \textit{Missing Neighbors} and \textit{False Neighbors} \cite{lespinats07tnn, lespinats11cgf, venna10jmlr, lee07springer} were introduced as an interpretation of stretching and compression in terms of the neighborhood structure. Given a high-dimensional point $x$ and its corresponding low-dimensional point $z$, Missing Neighbors are defined as the $k$-nearest neighbors of $x$ that are not among the ones of $z$. Conversely, False Neighbors are defined as the $k$-nearest neighbors of $z$ that are not among the ones of $x$. 
However, Missing and False Neighbors are insufficient to explain the distortions of complex, intertwined cluster structures. 
For example,  the relative increase of cluster density in the embedding does not incur Missing and False Neighbors distortions, because it does not alter the $k$-nearest neighbor structure for small $k$ values.



As alternatives, \textit{cluster-level} distortions, named \textit{Missing Groups} and \textit{False Groups}, were proposed by Jeon et al. \cite{jeon21tvcg}. Missing Groups  occur when a cluster in the original space splits into multiple separated clusters in the embedding, and False Groups occur when a cluster in the embedding consists of multiple separated clusters in the original space. 
In the seminal work \cite{jeon21tvcg}, Missing and False Groups distortions are examined based on the groups obtained by clustering techniques. 


In this work, we focus on evaluating the reliability of the cluster structure of DR embeddings by quantifying both Missing and False Groups.
However, instead of extracting groups using clustering techniques, we focus on the groups given by the classes of labeled data.



\subsubsection{Distortion Measurement without Labels}

\label{sec:disme}

We discuss distortion measures that do not rely on class labels. 
These measures take the original and embedded data as input and quantify their structural difference.
Aligned with the aforementioned distortion types, they focus on three different levels of structural granularity: \textit{global}, \textit{local}, and \textit{cluster}.
\textit{Global measures}, such as Kullback-Liebler divergence (KL Divergence) and Distance to Measure (DTM) \cite{chazal11fcm, chazal17jmlr}, quantify how well the embeddings preserve the global structure of the original data against stretching and compression.
Meanwhile, \textit{local measures} focus on neighborhood preservation.
Trustworthiness and Continuity (T\&C) \cite{venna06nn} measure how Missing and False Neighbors affected the distance-based ranking of the nearest neighbor for every data point in both spaces. Mean Relative Rank Errors (MRREs) \cite{lee07springer} extends T\&C by additionally regarding the ranking of True Neighbors: the points that are neighbors in both the original and embedded spaces. 
Still, despite local and global measures' wide usage in practice \cite{jeon21tvcg, jeon22vis, lai22vis, xia22tvcg, nonato19tvcg, moor20icml}, they do not properly capture cluster-level distortions \cite{jeon21tvcg}. 

This leads to the necessity of measures that capture distortions on cluster structures (i.e., \textit{cluster-level measures}).
Steadiness and Cohesiveness (S\&C) \cite{jeon21tvcg}  assess how much Missing and False Groups  distortions have occurred by  (1) extracting clusters from one space and (2) evaluating their dispersion in the other space.
However, S\&C require users to specify the way of extracting and investigating clusters in both spaces, e.g., using clustering techniques, making the results of the cluster-level distortion measures sensitive to the clustering technique and hyperparameters used. 
S\&C also suffers from a scalability issue as it requires the iterative execution of a clustering technique \cite{jeon21tvcg, fujiwara22arxiv}.


\ltc is a pair of cluster-level measures that aim to tackle these limitations. At first, the measures require a CVM as the sole hyperparameter, which is used to evaluate CLM in the original and embedded spaces. 
Thanks to the low complexity of CVM \cite{liu10icdm, jeon22arxiv2}, our measures are very scalable (\autoref{sec:scaleval}). Furthermore, \lsc are more sensitive in distinguishing Missing and False Groups distortions compared to previous measures, including S\&C (\autoref{sec:seneval}).




\subsubsection{Distortion Measurement with Labels}

\label{sec:dislabel}

Exploiting labels is a common scheme in evaluating DR embeddings \cite{colange20neurips, joia11lamp, loch15neurocomputing, xia22tvcg, becht19nature, xiang21fig, yang21cellreports}.
A general process to do so is to utilize CVM to measure the CLM of embeddings \cite{joia11lamp, loch15neurocomputing, becht19nature, yang21cellreports}.
However, the approach is prone to producing errors while examining the quality of DR embedding.
For example, if the CLM of the original data is bad (e.g., some classes overlap), embeddings that have good CLM for bad reasons (e.g., DR artificially separates each class into a distinct cluster) will be considered high-quality embeddings. 
As non-expert users typically assume that DR techniques generate reliable embeddings of the original data, they may incorrectly conclude that CLM is also good in the high-dimensional space, while it is not actually true \cite{jeon22arxiv2, aupetit14beliv}.

A sole pair of measures that relies on class labels but is independent of CVM is Class-Aware Trustworthiness and Continuity (CA-T\&C) \cite{colange20neurips}.
CA-T\&C is a variant of T\&C that assess the degradation of CLM (i.e., False Groups distortions) by estimating 
the extent to which Missing and False Neighbors occurred within and between classes, respectively. 
However, CA-T\&C hardly captures the Missing Groups distortions as they do not consider the increase of CLM as distortions. 
The measures also mainly focus on local structures and thus cannot comprehensively examine CLM distortions.


In this work, we propose \ltc as novel measures utilizing class labels to evaluate  DR embeddings. 
As with the general process of label-based DR evaluation (i.e., the process of naively applying CVM in the embedded space), our measures utilize CVMs to evaluate CLM; however, by applying CVM to both the original and embedded spaces and assessing their difference, our measures precisely capture cluster-level distortions.



\subsection{The Cluster-Label Matching assumption}



The assumption that the CLM is good in the high-dimensional data is used as a basis not only for the label-based evaluation of DR embeddings but also for other applications. For example, the labels are often utilized as the ground truth partition in clustering validations, where clustering techniques that generate a similar partition to that of labels obtain higher scores (i.e., external clustering validation; refer to \autoref{sec:cvmdesc} for details). Another application is the perception-based evaluation of DR techniques \cite{xia22tvcg,etemadpour15tvcg, etemadpour15ivapp, sedlmair13tvcg}, where techniques that produce embeddings in which the visual clustering results of human subjects better match class labels are preferred. 
However, the assumption can be easily broken \cite{aupetit14beliv, farber10multiclust}, which casts doubt on the applications' reliability. 

Despite such a threat, only a few solutions have emerged. 
A trivial solution is to modify datasets to make them better satisfy the assumption. Aupetit \cite{aupetit14beliv, aupetit05neurocomputing} proposed to check the linear or nonlinear separability of classes and then merge overlapped classes or preserve one of them while removing the others \cite{aupetit14beliv}. However, classes can be separable but adjacent, not forming proper clusters (no low density or wide empty space between them).  Such a strategy also does not take into account whether each class forms a single, compact cluster. 
Another solution is to use synthetic datasets \cite{jeon21tvcg, moor20icml, jeon22vis}, where good CLM is guaranteed by design. Still, this makes the evaluation hardly generalizable to real data.
Alternatively, Jeon et al. \cite{jeon22arxiv2} suggested a systematic way to evaluate CLM; their purpose was to verify the validity of labeled datasets for use as clustering validation benchmarks.
Still, they suggested only utilizing datasets with good CLM, which reduces the number of available datasets for evaluating DR embeddings.

In this work, we neither verify the CLM of datasets in advance nor attempt to modify datasets to enhance CLM.
 Instead, we \textit{acknowledge} that datasets may not satisfy the CLM, and rather assess whether the degree of CLM, either high or low, in the original dataset is well preserved in the embedding. 


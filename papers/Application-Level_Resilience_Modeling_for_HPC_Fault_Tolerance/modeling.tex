\section{Application-Level Resilience \\ Modeling}
\label{sec:modeling}
This section describes our modeling methodology. %in details. 
We start with a classification of the application-level fault masking,
and then introduce a metric and investigate how to use it
to quantify the application resilience. %based on the classification. 

\subsection{General Description}
\label{sec:general_bg}
%Application-level fault masking can be manifested in different representations. 
Application-level fault masking has various representations.  
Listing~\ref{fig:general_desc} gives an example to illustrate the application-level fault masking. 
In this example, we focus on a data object, $par\_A$, which is a sparse matrix with 1$K$ non-zero data elements. We study \textit{fault masking happened in this data object}. $par\_A$ is involved in 4 statements (Lines 6, 7, 9 and 13). 
%To make this example easy to describe, we assume that the fault propagated to the application 
%is a single bit-flip in the least significant bit of . %of mantissa,
%but the application-level fault masking can happen to various faults. 
%the other faults can be tolerated by the application-level fault masking as well. 


\begin{comment}
\begin{figure}
	\begin{center}
		%\includegraphics[height=0.4\textheight,keepaspectratio]{general_desc.PNG} 
		\includegraphics[width=0.35\textheight,keepaspectratio]{general_desc.pdf} 
		\vspace{-8pt}
		\caption{An example code to show application-level fault masking}
		\label{fig:general_desc}
		\vspace{-20pt}
	\end{center}
\end{figure}
\end{comment}


In this example, the statement at Line 6 has a fault masking event:
% a data -> the data by anzheng
if a fault happened at a data element $par\_A[0].data$ of the target data object ($par\_A$), the fault can be overwritten by an assignment operation.
%The second statement has one fault masking event: the value of $c$ is determined by $b$ (not $2*a[2]$), because $b$ is significant bigger than $a[2]$.
The statement at Line 7 has no explicit fault masking event happened in the target data
%a->the by anzheng
object, but if a fault at a data element $par\_A[2].data$ occurs, the fault is propagated to $c$ by multiplication and assignment operations.
%and then indirectly masked at the statement of Line 8 by an addition operation.
At Line 9, assuming that the value of $c$ is much smaller than the value of a variable $GIANT$, 
%the operation result is determined by a variable $GIANT$ whose value is much bigger than $c$, 
the impact of the corrupted $c$ on the application outcome is ignorable.
%tolerating the fault in the second operation. 
Hence, the fault propagated from Line 7 to Line 9 can be indirectly masked.

\begin{lstlisting}[label={fig:general_desc}, caption={An example code to show application-level fault masking}]
void func (Matrix *par_A, Vector *par_b, Vector *par_x) {
	// the data object par_A has 1K data elements;
    float c=0.0;
    
    // pre-processing par_A
    par_A[0].data=sqrt(initInfo);
    c=par_A[2].data*2;
    if (c>THR) {
    	par_A[4].data=c+GIANT; // GIANT >> c
    }
    
    // using the algebraic multi-grid solve
    AMG_Sover(par_A, par_b, par_x);
}
\end{lstlisting}


At Line 9, there is also an explicit fault masking event (i.e., fault overwritten by an assignment operation) for $par\_A[4].data$ if a fault happens in $par\_A[4].data$. This fault masking is similar to the one at Line 6.
At Line 13, there is an invocation of an algebraic multi-grid solver (AMG)
%whose fault masking is quantified based on the algorithm-level analysis (see below).
that can tolerate faults in the matrix because of the algorithm-level semantics of AMG (particularly, AMG's iterative, multilevel structure~\cite{mg_ics12}).

This example reveals many interesting facts.
In essence, a program can be regarded as a combination of data objects and
operations performed on the data objects.
An operation refers to the arithmetic computation, assignment, logical and comparison operations,  
%occurred in a basic block ~\footnote{A basic block is a single entrance, single exit sequence of instructions.}
or an invocation of an algorithm implementation (e.g.,  a multigrid solver, a conjugate gradient method, or a Monte Carlo simulation).  %a conjugate gradient method,
%The operation can be a statement within a basic block or a routine implementing an algorithm.
%The operation can cause a data object to interact with other data objects by reading/writing the data objects, and at last impact the application outcome.
%(\textbf{TODO: Dong: add a sentence here to correlate the operation with LLVM IR}).
An operation may inherently come with fault masking effects, exemplified at Line 6 (fault overwritten);
An operation may propagate faults, exemplified at Line 7. 
%which affects the interaction between the target data objects and other data objects.
Different operations have different fault masking effects, and hence
impact the application outcome differently.
Different applications can have different operations because of
algorithm implementation and compiler optimization, hence the
applications can have different application-level resilience.
%application-level resilience, because 
%the applications have different program constructs, algorithm implementations, and 
%compiler optimizations, which impact operations.


Based on the above discussion, we classify application-level fault masking 
%commonly found in applications 
into three classes.

(1) \textbf{Operation-level fault masking.} At individual operations, a fault happened in a data object is masked because of the semantics of the operations. Line 6 in
%Figure->Listing by anzheng
Listing~\ref{fig:general_desc} is an example.

(2) \textbf{Fault masking due to fault propagation.} 
Some fault masking events are implicit and have to be identified beyond a single operation. %within a larger application context.
In particular, a corrupted bit in a data object is not masked in the current operation (e.g., Line 7 in 
%figure->listing by anzheng
Listing~\ref{fig:general_desc}),
but the fault is propagated to another data object and masked in another operation (e.g., Line 9).
Note that simply relying on the operation-level analysis without the fault propagation analysis is not sufficient to recognize these fault masking events.

(3) \textbf{Algorithm-level fault masking.}
Identification of some fault masking events happened in a data object must include algorithm-level information.
The identification of those events is beyond the first two classes.
Examples of such events include %some fault tolerant algorithms, such as 
the multigrid solver~\cite{mg_ics12}, some iterative methods~\cite{2-shantharam2011characterizing}, and certain sorting algorithm~\cite{prdc13:sharma}.  
Furthermore, some application domains, such as image processing and machine learning~\cite{isca07:li}, can also tolerate faults because of less 
strict requirements on the correctness of data values. 

In general, the first two classes are caused by program constructs, and the third class is caused by algorithm semantics. Due to the random nature, 
the traditional random fault injection may omit some fault masking events, or capture them multiple times.
%Hence, the traditional fault injection can be inaccurate.
%and have to rely on massive number of tests to generate sufficient coverage.
Relying on analytical modeling, we can avoid or control the randomness of the fault injection, hence greatly improve resilience evaluation. %accuracy and repeatability. 

Our resilience modeling is analytical, and %on the application-level resilience 
relies on the quantification of the above application-level fault masking events happened on data objects.
We create a new metric to quantify the application-level resilience at \textit{data objects}, and introduce methods to measure the metric based on the above classification of fault masking events.
%Why do we need a metric? How to identify fault masking? Give a general introduction here.
%(\textbf{Dong: add an example to show why random fault masking does not work??. Add a figure here?})

\vspace{-10pt}
\subsection{aDVF: An Application-Level Resilience \\ Metric}
\label{sec:metric}
To quantify the resilience of a data object due to fault masking events, we could simply count the number of fault masking events
that happen to the target data object. 
%However, the number of fault masking events is related to the code size and
%the access intensity of the target data objects. 
However, a direct resilience comparison between data objects in terms of the number of fault masking events cannot provide meaningful quantification of the resilience of data objects. 
%\textcolor{green}{Because the fault masking ratio varies across fault masking events on different data objects.} 
For example, a data object %referenced in most of basic blocks 
may be involved in a lot of fault masking events, 
but this does not necessarily mean this data object is more resilient to faults
than other data objects with fewer fault masking events, because the fault masking events of this data object 
%can spread throughout the application execution and only happen sporadically given a time frame.
%that happens sporadically can be accumulated throughout the program.
can come from a few repeated operations, and the number of fault masking events is accumulated throughout application execution;
This data object could be not resilient, if most of other operations for this data object do not have fault masking. 
%quantify->quantifying by anzheng
Hence, the key to quantifying the resilience of a data object is
to quantify \textit{how often} fault masking happens to the data object.
%the operations that happen to the data object have fault masking.
We introduce a new metric, \textit{aDVF} (i.e., the application-level Data Vulnerability Factor), 
to quantify application-inherent resilience due to fault masking in data objects. aDVF is defined as follows. %For an operation, 
%if an fault following a specific pattern (represented with $ep$) 
%happens at the target data object before this operation, 
%Before an operation happens, 

For an operation performed on a data element of a data object, we reason that if a fault happens at the data element in this operation, 
the application outcome could or could not remain correct in terms of the outcome value and application semantics. %after the operation.
%Here, the operation is defined at the application statement level.
%It can be a memory reference (load or store), an arithmetic operation, 
If the fault does not cause an incorrect application outcome,
then a fault masking event happens to the target data object.
A single operation can operate on one or more data elements of the target data object. 
For a specific operation, aDVF of the target data object is defined as the total number of fault masking events divided by the total number of data elements of the target data object operated on by the operation.

For example, an assignment operation $a[1] = w$ 
%has three operations happened to a data object, the array $a$. 
%The three operations are two reads and one addition.
happens to a data object, the array $a$.
This operation involves one data element ($a[1]$) of the data object $a$.
%An fault can happen at any operand involved in the operation. 
%Use the example $a[1]+C$ again. 
We calculate aDVF for the target data object $a$ in this operation as follows.
%Assuming that a fault happens to $a[1]$ and $C$ is always significantly larger than the erroneous $a[1]$, we reason that 
If a fault happens to $a[1]$, we deduce that 
the erroneous $a[1]$ does not impact application correctness and the fault in $a[1]$ is always masked. Hence, the number of fault masking events for
the target data object $a$ in this operation is 1. Also, the total number of data elements involved in the operation is 1.
Hence, the aDVF value for the target data object in this addition operation is $1/1=1$.

%The normalization binds the aDVF value to [0, 1], 
%such that we can establish analysis semantics consistent with that of the algorithm-level analysis (see below).
%for the convenience of integration with the algorithm-level analysis (see below). %also the effect the data object size
Based on the above discussion, the definition of aDVF for a data object $X$ in an operation ($aDVF^{X}_{op}$)
is formulated in Equation~\ref{eq:dvf}, where 
$x_i$ is a data element of the target data object $X$, and $m$ is the number of data elements operated on by the operation;
%changed a lot by anzheng
$f$ is a function to count fault masking events happened on a data element. %the i-$th$ data element $x_i$.
\begin{comment}
$f(i)$ %$f(i,ep)$ 
is a function to count fault masking events
happened to a data element $i$ of the target data object operated on by the operation. There are $m$ data elements of the target data object operated on by the operation.
\end{comment}
\vspace{-1pt}
\begin{equation} 
\label{eq:dvf}
%\scriptsize
\footnotesize
	aDVF^{X}_{op} = \sum_{i=0}^{m-1}f(x_i)/m
\end{equation}
\vspace{-5pt}
%We calculate $aDVF_{op}$ for each operation performed on the target data object. %or other interacting data objects,
%aDVF of the target data object for a code region is the arithmetic mean of aDVF of all related operations in the region.
%We calculate $aDVF$ for a code region as follows

The calculation of aDVF for a code segment is similar to the above for an operation, except that
$m$ is the total number of $x$
%add dynamic here by anzheng
involved in all %\textsl{dynamic} 
operations of the code segment. 
To further explain it, we use as an example
a code segment from LU benchmark in SNU\_NPB benchmark suite 1.0.3 (a C-based implementation of the Fortran-based NPB) shown in 
Listing~\ref{fig:advf_example}.
%all Figure -> Listing by anzheng

%\begin{minipage}{\linewidth}
\begin{lstlisting}[label={fig:advf_example}, caption={A code segment from LU.}]
void l2norm(int ldx, int ldy, int ldz, int nx0, \
	int ny0, int nz0, int ist, int iend, int jst, \
    int jend, double v[][ldy/2*2+1][ldx/2*2+1][5], \
    double sum[5])
{
	int i, j, k, m;
    for (m=0;m<5;m++) //the first loop
    	sum[m]=0.0;  //Statement A
    
    for (k=1;k<nz0-1;k++){  //the second loop
    	for (j=jst;j<jend;j++){
        	for (i=ist;i<iend;i++){
            	for (m=0;m<5,m++){
            		sum[m]=sum[m]+v[k][j][i][m]  \
                    	*v[k][j][i][m]; //Statement B
                }
            }
        }
    }
    
    for (m=0;m<5;m++){  //the third loop
    	sum[m]=sqrt(sum[m]/((nx0-2)*  \
        	(ny0-2)*(nz0-2))); //Statement C
    }
} 
\end{lstlisting}
%\end{minipage}


\textbf{An example from LU.} We calculate aDVF for the array $sum[]$. 
%the statement->Statement by Anzheng
Statement $A$ has an assignment operation involving one data element ($sum[m]$) and one fault masking event (i.e., if a fault happens to $sum[m]$, the fault is overwritten by the assignment). Considering that there are five iterations in the first loop ($iter_{num1} = 5$), there are 5 fault masking events happened in 5 data elements of $sum[]$

Statement B has two operations related to $sum[]$ (i.e., an assignment and an addition). The assignment operation involves one data element ($sum[m]$) and one fault masking; the addition operation involves one data element ($sum[m]$) and one potential fault masking (i.e., certain corruptions in $sum[m]$ can be ignored, if ($v[k][j][i][m]*v[k][j][i][m]$) is significantly larger than $sum[m]$). This potential fault masking is counted as $r^\prime$ ($0 \leq r^\prime \leq 1$), depending on where a corruption happens in $sum[m]$ and fault propagation analysis result (see Sections~\ref{sec:statement_analysis} and~\ref{sec:impl} for further discussion). 
Considering the loop structure, there are ($(1+r^\prime) * iter_{num2}$) fault masking events happened in ($2 * iter_{num2}$) elements of $sum[]$, where ``1'' and ``$r^\prime$'' come from the assignment and addition operations respectively. $iter_{num2}$ is the number of iterations in the second loop, which is equal to ($(nz0-2)*(jend-jst)*(iend-jst)*5$).

Statement C has two operations 
%with->to by anzheng
related to $sum[]$ (i.e., an assignment and a division), but only the assignment operation has fault masking.
Considering that there are 5 iterations in the third loop ($iter_{num3} = 5$), there are 5 fault masking events happened on 5 data elements of the target data object in the third loop. In 
%add the  by anzheng
summary, the aDVF calculation for $sum[]$ is shown in Figure~\ref{fig:advf_cal}.  

\begin{comment}
\begin{figure}[t]
	\centering
	\vspace{-10pt}
	\includegraphics[height=0.45\textheight, width=0.48\textwidth]{advf_example.pdf}
	\vspace{-15pt}
	\caption{A code segment from LU. }
	\label{fig:advf_example}
	\vspace{-10pt}
\end{figure}
\end{comment}

\begin{figure}
	\centering
	\includegraphics[height=0.15\textheight, width=0.48\textwidth]{advf_lu_calculation.pdf}
	\vspace{-8pt}
	\caption{Calculating aDVF for a target data object, the array \textit{sum}[] in a code segment from LU. In the figure, $iter_{num1}=5, iter_{num3}=5$ and $iter_{num2} = (nz0-2)*(jend-jst)*(iend-ist)*5.$}
	\label{fig:advf_cal}
	\vspace{-15pt}
\end{figure}

To calculate aDVF for a data object, we must rely on effective identification and counting of fault masking events (i.e., the function $f$).
In Sections~\ref{sec:statement_analysis},~\ref{sec:fault_propagation_analysis} and ~\ref{sec:algo_analysis}, 
we introduce a series of counting methods based on the classification of fault masking events. %(see Section~\ref{sec:general_bg}). 

\subsection{Operation-Level Analysis}
\label{sec:statement_analysis}
To identify fault masking events at the operation level, we analyze 
all possible operations. %performed on any data object.
In particular, we analyze 
architecture-independent, LLVM instructions %code representation
%(see Section~\ref{sec:impl} for implementation details),
and characterize them based on the instruction result sensitivity to corrupted operands. We classify the operation-level fault masking as follows. 

%\begin{itemize}
(1) \textbf{Value overwriting}.  
An operation writes a new value into the target data object, 
and the fault in the target data object is masked. 
For example, the store operation overwrites the fault in the store destination. 
%the add operation overwrites the fault %pre-existing fault in the result variable. 
We also include \textit{trunc} and bit-shifting operations into this category, because the fault can be truncated or shifted away in those operations.

(2) \textbf{Logical and comparison operations}.
If a fault in the target data object does not
change the correctness of logical and comparison operations, the fault is masked.  
Examples of such operations 
include logical \textit{AND} and the predicate expression in a \textit{switch} statement.
%We also attribute bit-shifting operations to this category, because
%these operations are often involved in the logical and comparison operations.    

(3) \textbf{Value shadowing}.
If the corrupted data value in an operand of an operation 
is shadowed by other correct operands involved in the operation,
then the corrupted data has an 
%add an by anzheng
ignorable impact on the correctness of the operation.
%and the incorrect data value is shadowed by other correct operands involved in the operation.
The addition operation at Line 9 in Figure~\ref{fig:general_desc} is such an example. 
We can find many other examples, such as arithmetic multiplication. %and square root.
%, and trunc operation for type casting.
The effectiveness of value shadowing is coupled with the application semantics.  
An operation of $1000+0.0012$ can be treated as equal to $1000+0.0011$ without impacting the execution correctness of application,
while such tiny difference in the two data values may be intolerable in a different application. We will discuss how to identify value shadowing in details in Section~\ref{sec:impl}.
%\end{itemize}
%(\textbf{Dong: add more to describe how we choose a threshold to determine value shadowing.})

Since we focus on the \textit{application}-level resilience modeling,
we do not consider those LLVM instructions that do not have
directly corresponding operations at the application statement level for fault masking analysis. 
Examples of those instructions 
include \textit{getelementptr} (getting the address of a sub-element of an aggregate data structure)
and \textit{phi} (implementing the $\phi$ node in the SSA graph~\cite{llvm_lrm}).

The effectiveness of the operation-level fault masking heavily relies on the fault pattern.
The fault pattern is defined by how fault bits are distributed within
a faulty data element (e.g., single-bit vs. spatial multiple-bit, least significant bit vs. most significant bit, mantissa vs. exponent).
To account for the effects of various fault patterns, an ideal method to count fault masking events %on a particular platform
would be to collect fault patterns in a production environment during a sufficiently long time period, and then use the realistic fault patterns to guide fault masking analysis. 
However, this method is not always practical. 
In the practice of our resilience modeling, we enumerate possible fault patterns for a given operation, %and a data element of the target data object, 
and derive the existence of fault masking for each fault pattern.
Suppose there are $n$ fault patterns, and $m$ ($0 \leq m \leq n$) of which have fault masking happened.
Then, the number of fault masking events is calculated as $m$/$n$,
which is a statistical quantification of possible fault masking.
Using this statistical quantification means that the number of fault masking events can be non-integer. 
%from the probability perspective.
We employ the above enumeration analysis to model fault masking for single-bit faults in our evaluation section, but the method of the enumeration analysis can be applied to analyze all fault patterns.
\vspace{-10pt}

\subsection{Fault Propagation Analysis}
\label{sec:fault_propagation_analysis}
At an operation performed on the target data object, 
if a fault happened in the target data object cannot be masked at the current operation, 
then we use the fault propagation analysis to track whether the corrupted data
is propagated to other data object(s) and the faults (including the original one and the new ones propagated to other data object(s)) 
are masked in the successor operations.
If all of the faults are masked, then we claim that the original fault happened in the target data object is masked.   

For the fault propagation analysis, a big challenge is to 
track all contaminated data which can quickly increase as the fault propagates. 
\begin{comment}
%handle fault explosion.
We use an example shown in Figure~\ref{fig:fault_propagation_code}
as a running example for the fault propagation analysis. %in this section.
This example is from the CG benchmark in SNU\_NPB.
%Figure~\ref{fig:fault_propagation} shows an example of the fault propagation analysis for NPB CG benchmark.
The target data object in this example is the array $r$, and we calculate aDVF for
the assignment operation in the statement $A$. 
If $r[j]$ has a fault at the statement $A$, the fault cannot be masked.
Instead, within the successor four statements (B-E), the fault quickly propagates to four data objects ($rho, d, alpha$ and $z[]$).
%The number of contaminated data objects grows at least linearly with the number of statements. 
\end{comment}
Tracking a large number of contaminated data objects largely increases
analysis time and memory usage. %code complexity. 
%The symbols in the blocks of the figure are a notation for fault masking analysis.
%In particular, the symbol $st_{x}:op_{y}:d_{z}$ refers to an fault occurred in an operation $y$ 
%of an statement $x$, and the fault happens in the data $z$ before the operation.
%For the example of the figure,  we analyze the fault masking of xxx data.
%Within xxx statements, we have xxx different data tainted by the corrupted data at the statement xxx.
To handle the above fault propagation problem, we avoid tracking fault propagation along a long chain of operations
to accelerate the analysis.
%This can address the fault explosion problem, and accelerate the analysis. 
%We introduce two optimization techniques to avoid long tracking.
We introduce an optimization technique to avoid long tracking.

\begin{comment}
\textbf{Optimization 1: leveraging intermediate states.}
%Avoiding tracking fault propagation along a long chain of operations is an effective way to address the fault explosion problem. 
During the fault propagation analysis, if we know the valid data values (i.e., the intermediate state) of some data objects, 
then we can compare the valid intermediate states with the data values in the fault propagation analysis.
A mismatch between the two indicates that the faults occurred in previous operations
will not be masked in the future.
%the pending data states do not have fault masking; otherwise, there is fault masking.
Hence, the valid intermediate state works as ``analysis shortcut'' that allows us to deduce fault masking without tracking fault propagation to the end of the application execution. 

\begin{figure}[h]
	\begin{center}
		\includegraphics[height=0.3\textheight,keepaspectratio]{error_propagation_code.PNG}
		\caption{A code excerpt from the SNU\_NPB CG benchmark to show the fault propagation from the statement $A$ at an iteration $j$.  The target data object is the array $r[]$. A fault in $r[j]$ is propagated to four data objects ($rho$, $d$, $alpha$ and $z$[]) in the statements B-E.}
		\label{fig:fault_propagation_code}
		\vspace{-20pt}
	\end{center}
\end{figure}
\begin{figure}[h]
	\begin{center}
		\includegraphics[height=0.3\textheight,keepaspectratio]{error_propagation_ddg.pdf}
		\caption{The data dependency graph to show the fault propagation for Figure~\ref{fig:fault_propagation_code}.}
		\label{fig:fault_propagation_ddg}
	\end{center}
	\vspace{-20pt}
\end{figure}

To further explain the idea, we use the example in Figure~\ref{fig:fault_propagation_code} again.
We use a dynamic dependency graph (Figure~\ref{fig:fault_propagation_ddg}) of the example to explain the idea.
%shows an example for using the intermediate state. %helps us immediately identify fault masking at the statement C.
%without reaching the statement xxx.
The dynamic dependency graph (DDG) captures the dynamic dependencies among data objects in the course of program execution~\cite{prdc05:Pattabiraman, tdsc11:pattabiraman}. 
%the values produced  in the course of program execution. 
A node in DDG represents a value of a data object produced in the program, and the node is associated with a dynamic operation that produced the value.
An edge in DDG represents an operation.
The source node of the outgoing edge corresponds to an operation operand,
and the destination node corresponds to the value produced by the operation.
The same memory location can be mapped onto
multiple nodes in DDG (e.g., the data object $rho$ in Figure~\ref{fig:fault_propagation_ddg}), just as a memory
location can have multiple value instances during the execution.
%DDG can be generated based on LLVM instrumentation.
%Function calls and returns are represented in the DDG. 
%The reason why DDG  --> (1) fanout; (2) fault propagation;

Tracking the edges in Figure~\ref{fig:fault_propagation_ddg},  we can know how a fault is propagated when $r[j]$ has the fault.
Assume that we know the valid value range\footnote{A \textit{valid} value always results in acceptable application outcomes. The \textit{valid} used in here and in the rest of the paper is defined in terms of application outcomes.} of the data object $alpha$ at the statement $D$.
If a fault that happens in $r[j]$ at the statement $A$ is propagated to $alpha$ and we find that the faulty $alpha$ is not in the valid value range,
then we can deduce that the original fault will not be masked, and 
we avoid the fault tracking after the statement $D$. 

To collect valid intermediate states to accelerate the fault propagation analysis,  
%we instrument the memory references to the target data object, and 
we record the values of some variables (e.g., the values of $alpha$ at the statement $D$) with fault-free execution. %after some operations. 
%In particular, the values of critical data objects are recorded immediately after an operation,
%if the operation has more than x\% of successor operations involving critical data objects 
%or the target data object in the next $y$ operations ($x=40, y=50$ in our tests). 
%involving critical data objects or the target data object in the next $y$ operations ($x=40, y=50$ in our tests). 
We record valid values of a variable if a value of the variable in DDG has at least 10 predecessor nodes.
%In Figure~\ref{fig:fault_propagation_ddg}, the node $alpha$ has 10 predecessor nodes. 
%We use such method to record variable values, because having a large number of predecessor nodes indicates that the recorded value is potentially helpful to address many fault prorogation analysis.
Recording those values is useful, because it is potentially helpful to resolve many pending fault propagation analysis.
%indicates how many nodes are directly impacted by an fault in that no
\end{comment}

\begin{comment}
We choose those operations to output the values, because 
those operations maximize the fanout of data corruption, 
and hence have big potential to result in the above fault propagation problem.
%Those operations heavily involve the target data object, and hence maximum the fanout of the orginia data corruption. 
%Those operations have big potential to lead the fault explosion problem. 
(\textbf{Dong: explain more what is fanout}).

\textbf{Fanout: the fanout of a node is the set of all immediate successors of the node in DDG. The fanout of a node indicates how many nodes are directly impacted by an fault in that node.}
\end{comment}


\textbf{Optimization: bounding propagation path.} 
%Another method to avoid long tracking of fault propagation is to bound the fault propagation path.
We take a sample of the whole fault propagation path.
In particular, we only track the first $k$ operations. 
%sample the whole fault propagation path with the first $k$ operations.
%If the original fault happened in the target data object 
If the original fault and the new faults propagated to other data object(s)
cannot be masked within the first $k$ operations, then we conclude that 
%the original fault 
all of the faults will not be masked after the $k$ operations.
%in the following operations. 

This method, as an analysis approximation, could introduce analysis inaccuracy because of the sampling nature of the method. 
%The effectiveness of this optimization varies from one operation to another.
However, for a fault that propagates to a large amount of data objects, 
%through successor operations, 
bounding the fault propagation path does not cause inaccurate analysis, because given a large amount of corrupted data, it is highly unlikely that all faults are masked, and
%In Bounding the propagation path and immediately 
making a conclusion of no fault masking is correct in most cases.
In the evaluation section, we explore the sensitivity of analysis correctness to the length of the fault propagation path (i.e., $k$). We find that setting the propagation path to 10 is
good to achieve accurate resilience modeling in most cases (87.5\% of all cases). Setting it to 50 is good for all cases.

\vspace{-10pt}
\subsection{Algorithm-Level Analysis}
\label{sec:algo_analysis}
Identifying the algorithm-level fault masking demands domain and algorithm knowledge.  
In our resilience modeling, we want to minimize the usage of domain and algorithm knowledge, such that
the modeling methodology can be general across different domains.

%Recognizing algorithm-level fault masking is challenging, because the domain knowledge is often demanded 
%to determine if an application outcome with the data corruption occurred in an operation is valid.
%The requirement of the domain knowledge imposes a challenge to make the tool portable and generalizable across different domains.
%From the perspective of a programmer who improves program reliability and fault tolerance mechanisms, we want to minimize
%the introduction of domain knowledge.

We use the following strategy to identify the algorithm-level fault masking (see the next paragraph). 
Furthermore, the user can optionally provide a threshold to indicate a satisfiable solution quality.
For example, for an iterative solver such as conjugate gradient and successive over relaxation,
this threshold can be the threshold that governs the convergence of the algorithms.
For the support vector machine algorithm (an artificial intelligence algorithm), this threshold can be a percentage (e.g., 5\%)
of result difference after the fault corruption.
Working hand-in-hand, the strategy (see the next paragraph) and user-defined threshold treat the algorithm as a black box without
%on->of by anzheng
requiring detailed knowledge of the algorithm internal mechanisms and semantics. 
We explain the strategy as follows.

\textbf{A practical strategy for algorithm-level analysis: deterministic fault injection.}
The traditional random fault injection treats the program as a black-box. 
Hence, using the traditional random fault injection could be an effective tool to identify the algorithm-level fault masking.
However, to avoid the limitation of the traditional random fault injection (i.e., randomness), %and high cost),
we use the operation-level analysis and fault propagation analysis to guide fault injection, 
without blindly enforcing fault injection as the traditional method.
%In particular, when determining fault masking for an operation $x$ by the fault propagation analysis and reaching the boundary of the fault propagation analysis,
In particular, when we cannot determine whether a fault masking can happen in the target data object for an operation $op$ because of fault propagation,  we track fault propagation until 
reaching the boundary of the fault propagation analysis.
%(see Optimization 2 in Section~\ref{sec:fault_propagation_analysis}),
If we still cannot determine fault masking at the boundary, then  
we inject a fault into the target data object in $op$, %right after the boundary, 
and then run the application to completion. 
%If the algorithm result is the same as the one without fault injection or does not go beyond the user-provided threshold, 
If the application result is different from the fault-free result, %without fault injection,
but does not go beyond the user-defined threshold, we claim that the algorithm-level fault masking takes effect. %for the operation $x$.

\begin{comment}
As described above, our fault injection has a deterministic plan on when and where to inject faults. Also, the operation-level and fault propagation analysis is complementary to our fault injection. Hence we avoid fault injection if possible.c
\end{comment}

\textbf{Discussion: coupling between fault propagation and algorithm level analysis.}
The fault propagation analysis and algorithm-level analysis are tightly coupled.
If we reach the boundary of the fault propagation analysis and cannot determine fault masking, we use the algorithm-level analysis. %(i.e., the guided fault injection).
%the fault masking attributed to the algorithm-level fault masking may actually come from the fault propagation-based fault masking. 
However, by doing this, 
some of the fault masking events due to the fault propagation and operation-level fault masking after the boundary may be accounted as algorithm-level fault masking.
Although this mis-counting will not impact the correctness of aDVF value, it would overestimate the algorithm-level fault masking.
%we are at a risk of losing accuracy for counting those fault masking events at the level of fault propagation.
%A correct application execution after the deterministic fault injection 
%may be because of fault masking during fault propagation, not because of the algorithm-level fault masking.
\begin{comment}
However, the application execution deemed to be correct at the end of the execution 
may be a result of both the algorithm-level fault masking and the fault propagation-based fault masking.
We cannot count those fault propagation-based fault masking, because we set an upper bound on the number of operations 
for the fault propagation analysis.
Simply speaking, we may lose accuracy trading for simplification of the fault propagation analysis.
\end{comment}

The fundamental reason for the above overestimation is that we bound the boundary of the fault propagation analysis.
However, our study (Section~\ref{sec:eval_sen}) reveals that we can have very good modeling
%in->on by anzheng
accuracy on our count of the algorithm level fault masking,
even if we set the boundary of the fault propagation analysis.
The reason is as follows. %because of the fault explosion:
After the boundary of the fault propagation analysis, the fault is widely propagated, and
the chance to mask all propagated faults by the operation-level fault masking is extremely low.
In fact, in our tests, we found that even if we use a longer fault propagation path to identify fault masking, we are not able to find more fault masking based on the fault propagation analysis.
Hence, as long as the threshold is sufficiently large (e.g., 10), 
we do not overestimate the algorithm-level fault masking. %for identifying fault masking. 
\vspace{-10pt}
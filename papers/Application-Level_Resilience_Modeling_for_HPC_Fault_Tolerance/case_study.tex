\section{Case Study: Optimizing Fault Tolerance for Applications}
\label{sec:case_study}
aDVF and its analysis are widely applicable to a number of use cases, such as
code optimization and algorithm choice.
%identifying vulnerable data objects of applications and optimizing fault tolerance mechanisms.
In this section, we study a case of using aDVF to help system designers to decide whether a specific application-level fault tolerance mechanism is helpful to improve the application resilience.

Application-level fault tolerance mechanisms, such as algorithm-based fault tolerance~\cite{abft_ecc:SC13, 21-chen2011algorithm, jcs13:wu, ics11:davies, hpdc13:davies, tc84_abft} and compiler-directed redundant execution~\cite{cgo05:reis, date05:hu, pact10:zhang, cgo07:wang, tr02:oh}, are extensively studied as a means to increase application resilience to faults. However, those application-level fault tolerance mechanisms can come with big performance and energy overheads 
(e.g., 35\% performance loss for dense matrix factorization in small scale deployments~\cite{ftfactor_ppopp12} and 41\% performance loss for compiler-directed instruction duplication~\cite{tr02:oh}). 
To justify the necessity of using these mechanisms, we must quantify how effectively those mechanisms improve the application resilience.
However, it is challenging to do so without a resilience metric and quantitative analysis method. 
%The existing work evaluates these mechanisms in terms of performance and energy efficiency, not resilience~\cite{}.
With the introduction of aDVF, we can evaluate if the application resilience is effectively improved with fault tolerance mechanisms in place.

In this section, we focus on a specific application-level fault tolerance mechanism,
the algorithm-based fault tolerance (ABFT) for general matrix multiplication ($C=A \times B$)~\cite{jcs13:wu}.
%The basic idea of ABFT is to leverage redundant information inherent in numerical algorithms, or exploiting invariant relationships between
%data structures.
This ABFT mechanism encodes matrices $A$, $B$ into a new form with checksums shown in the following equation, and protect $C$.
$e$ in the equation is an all-one column checksum vector. 

\scriptsize
\[ A^r:=\begin{bmatrix}A\\e^TA\end{bmatrix},
B^c:=\begin{bmatrix}B&Be\end{bmatrix} \]
\normalsize
To protect the result matrix $C$ from faults, instead of multiplying matrices $A$ by $B$, we use their checksum version.

\scriptsize
\[ A^rB^c=\begin{bmatrix} AB & ABe \\ e^TAB & e^TABe \end{bmatrix} =
\begin{bmatrix} C & Ce \\ e^TC & e^TCe \end{bmatrix} =: C^f \]
\normalsize
The new result matrix $C^f$ has extra checksum information, shown as above. The extra checksum information can be used to detect, locate, and recover fault during computation. 
If a fault occurs in an element of $C$, exactly one row and one column of the result
will not satisfy the checksum matrix definition. 
Then, leveraging either the row or column checksum, we are able to correct the faulty element. 

% Apply ABFT to applications.
We apply the aDVF analysis on this ABFT, and the matrix $C$ is the target data object. We compare the aDVF values of $C$
with and without ABFT. Figure~\ref{fig:abft_advf} shows the results.
The figure shows that ABFT effectively improves the resilience of the matrix $C$: the aDVF value increases
from 0.0172 to 0.82. The improvement mostly comes from the value overwriting
at the fault propagation level.
This result is expected, because an element of $C$, once a fault happens in it, is not corrected by ABFT right way.
%add , by instead by anzheng
Instead, it will be corrected in a specific verification phase of ABFT.
%which is exactly what we expect from ABFT. 

\begin{figure}
	\centering
	\includegraphics[width=0.49\textwidth, height=0.155\textheight]{abft_c_gray.pdf}
	\caption{Using aDVF analysis to study the effectiveness of an ABFT for matrix multiplication (MM). ABFT\_C is MM without the protection of ABFT on $C$; ABFT\_[C] is MM with ABFT taking effect.}
	\label{fig:abft_advf}
    \vspace{-10pt}
\end{figure}

Given the effectiveness of this ABFT, we further explore whether this ABFT can help us improve the resilience of data objects in an application, AMG.
AMG frequently employs matrix-vector multiplication. Given the fact that the vector can be treated as a special matrix, we can apply ABFT to protect 
the result vectors for those matrix-vector multiplications.
In particular, we protect a specific data object, the vector $r$, because this vector works as a result vector for 75\% of matrix-vector multiplications in AMG.
Using the vector $r$ as our target data object, we perform the aDVF analysis with and without ABFT.
We want to answer a question: Will using ABFT be an effective fault tolerance mechanism for AMG?

\begin{figure}
	\centering
	\includegraphics[width=0.49\textwidth,height=0.155\textheight]{amg_r_gray.pdf}
	\caption{Using aDVF analysis to study the effectiveness of the ABFT for a data object $r$ in AMG. AMG\_r has no protection of ABFT; ABFT\_[r] has ABFT taking effect on $r$.}
	\label{fig:abft_advf_qbox}
    \vspace{-12pt}
\end{figure}

Figure~\ref{fig:abft_advf_qbox} shows the results. The figure reveals that using ABFT is not very helpful to improve
the resilience of the data object $r$ in AMG:
%the data object $r$  in AMG is already resilient to faults, and 
%using ABFT is not very helpful: 
there is only a slightly change to the aDVF value.
After examining the AMG code, we found that the vector $r$ is involved in a generalized minimal residual method (GMRES).
This method approximates the solution
%remove s, by anzheng
of a linear equation by a vector with minimal residual. 
The approximation nature of GMRES determines that the GMRES method itself can tolerate faults. 
%add the to faults by anzheng
For the vector $r$, most of the faults correctable by ABFT are also tolerable by GMRES.
Hence, ABFT is not very helpful to improve the application resilience.
Our aDVF analysis result is consistent with the above code analysis result.
Furthermore, Figure~\ref{fig:abft_advf_qbox} reveals that how faults are masked in AMG with and without ABFT. With ABFT,
%most of->most by anzheng
most faults are masked at the fault propagation level, while without ABFT most faults are masked at the algorithm level. 

This case study is a clear demonstration of how powerful the aDVF analysis can help optimize
fault tolerance. Avoiding redundant protection as above will greatly improve performance and energy efficiency of HPC systems.
%the system. This is especially true for eliminating those unnecessary while expensive fault
%tolerance mechanisms.
\vspace{-5pt}

\begin{comment}
Besides the above use case to quantify effectiveness of fault tolerance mechanisms, 
aDVF and its analysis can be widely applied to many other use cases. We list some of them as follows.

\textbf{Code optimization}:
Programmers have been working on code optimization to improve performance and energy efficiency. 
However, the impact of code optimization on the application resilience is often ignored. 
The code optimization (including common compiler optimization on applications) 
can change memory access patterns and runtime values of data objects, 
which in turn impacts fault prorogation and fault shadowing.
aDVF and its analysis give programmers a feasible tool to study and compare the application resilience
before and after code optimization. The aDVF analysis is also helpful to pinpoint which part of the application code
is vulnerable, and hence demands further optimization.


\textbf{Algorithm choice}:
To solve a specific computation problem, we can have multiple algorithm choices.
For example, to solve Poisson's equation on a 2D grid, we could use direct method (Cholesky factorization), 
Multigrid, or red-black successive over relaxation. 
Different algorithms have different implications on data distribution, parallelism, and blocking~\cite{pldi09:ansel}.
Which algorithm should be employed depends on users' requirements on performance, energy/power efficiency and resilience.
aDVF and its analysis can help users (especially those users working on high performance computing) make the algorithm choice from the perspective of 
application resilience. It would be also interesting to integrate the aDVF analysis with programming language and compiler for algorithm choice, such as PetaBricks~\cite{pldi09:ansel}.
 
 
\textbf{Hardware-software co-design}:
Besides software-based fault tolerance mechanisms, large-scale high performance computing systems often employ hardware-based fault tolerance mechanisms, 
such as hardware Error Correction Code (ECC) and hardware checksum. Those hardware-based mechanisms not only bring performance and energy cost, but also bring hardware cost. 
Using a hardware-software co-design approach, we can avoid the expensive cost of hardware-based fault tolerance mechanisms. 
In particular, if based on the aDVF analysis we know that the application itself is fault-tolerant or the software-based fault tolerance mechanisms are already sufficient
to provide protection, then we do not have to employ costly hardware-based fault tolerance. 
This co-design methodology based on the aDVF analysis is especially attractive to the domain-specific hardware 
(e.g., the customized hardware to accelerate machine learning algorithms~\cite{asplos14:chen, isca16:reagen, isca16:likamwa}).
Because the domain-specific hardware is likely to run only one type of application, we can apply aDVF analysis on such application, based on
which to enable highly optimized, hardware-based fault tolerance mechanisms.
\end{comment}



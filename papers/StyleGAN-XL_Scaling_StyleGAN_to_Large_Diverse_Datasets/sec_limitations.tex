\section{Limitations and Future Work}
\label{sec:limitations}
Our contributions allow StyleGAN to accomplish state-of-the-art high-resolution image synthesis on ImageNet.  
Furthermore, applying it to big and small unimodal datasets is straightforward, and we also achieve state-of-the-art performance on FFHQ and Pokemon at resolution $1024^2$, see supplementary.
Exploring new editing methods and dataset generation~\cite{Chai2021CVPR,Li2022ARXIV} using StyleGAN-XL are exciting future avenues. Furthermore, future work may tackle an even larger megapixel dataset. However, a larger yet diverse dataset is not available so far. Current large-scale, high-resolution datasets are of single object classes or contain many similar images~\cite{Zhang2020ECCV,Fregin2018ICRA,Perot2020NEURIPS}. In the following, we discuss limitations of the current model, which should be addressed in the future.

\boldparagraph{Architectural Limitations.}
First, StyleGAN-XL is three times larger than StyleGAN3, constituting a higher computational overhead when used as a starting point for finetuning. Therefore, it will be worth exploring GAN distillation methods~\cite{Chang2020ACCV} that trade-off performance for model size. 
Second, we find StyleGAN3, and consequently, StyleGAN-XL, harder to edit, e.g., high-quality edits via $\mathcal{W}$ are noticeably easier to achieve with StyleGAN2. As already observed in~\cite{Karras2021NEURIPS}, StyleGAN3's semantic controllability is reduced for the sake of equivariance. 
However, techniques using the \textit{StyleSpace}~\cite{WU2021CVPRa}, e.g., StyleMC~\cite{Kocasari2021WACV}, tend to yield better results in our experiments, confirming the findings of concurrent work by~\cite{Alaluf2022ARXIV}. Furthermore, we remark that our framework can also easily be used with StyleGAN2 layers.


\section{Evaluation}
\label{sec:evaluation}

To evaluate the effectiveness of \nickName, we have conducted comprehensive evaluations from three aspects. 
First, we apply \nickName on an extensive set of apps to demonstrate its effectiveness in saving the initial download size of an Android app and the download/installation time. 
Second, we evaluate the robustness of the iterative back-complementary recovery tool on a set of open-source apps. 
At last, we evaluate the runtime performance of the decomposed apps in the \nickName{} client.


\subsection{Applicability over Real-World Apps}
In order to evaluate our practicality of real-world apps, we first analyze 1,000 apps downloaded from Google Play to measure the size distribution of base bundles and feature bundles. 


\begin{figure}[!t]
   \centering
  \subfigure[Base bundle]{
     \label{fig:size_of_base_bundle}
    \includegraphics[width=0.4\textwidth]{images/base_bundle_cdf.pdf}}
      \hspace{0in}
   \subfigure[Feature bundle]{
     \label{fig:size_of_feature_bundle}
    \includegraphics[width=0.4\textwidth]{images/size_of_feature_bundle.pdf}}
      \hspace{0in}
      \label{fig:decomposition}
      \caption{Distribution of the size of decomposed bundles}
\end{figure}



\noindent\textbf{The size of base bundles}. Figure~\ref{fig:size_of_base_bundle} shows the distribution of  size of base bundles and their original apps.
The results show that the median value for the saving of the size of the initial download is \textbf{44.17\%}, resulting in a significantly shorter download time and less local storage.

For some apps, the base bundles do not save much storage compared to original apps. 
The reason is that the developers may place most of the features in the lauching activity of their apps, and most of the other activities' dependent resources and code have been packed into base bundles. Meanwhile, our current implementation just decomposes resources that reside in the \textit{res} folder, and other resources are packed into the base bundle directly. Some apps place almost all of resources in the \textit{assets} folder (e.g., mobile games), so the savings of storage for such apps are much less.


\noindent\textbf{The size of feature bundles}. As shown in Figure~\ref{fig:size_of_feature_bundle}, users need to download only a feature bundle whose size is less than 500 KB for about \textbf{84.23\%} cases. To make a comparison, a recent study of \textit{httparchive.org}~\cite{httparchive} reports that the average web page size in 2016 was 2, 232 KB. In other words, a feature bundle is much smaller than a common Web page in size, and thus end users do not need to wait a long time to download it. The reason is that some feature bundles may just contain a small set of classes, and their dependent resources have been packed into the base bundle. Therefore, their size is relatively small.


\nickName can lower the barrier for accessing a new mobile app because of a smaller-size base bundle, especially for those big-size apps. Meanwhile, users just need to download a small-size feature bundle to visit a new activity that has not been downloaded on their devices.


\subsection{Robustness of Decomposed Apps}
\label{subsec:robustness}



\begin{figure}[!t]
\centering
\begin{minipage}[t]{0.4\linewidth}
	\centering
   	\includegraphics[width=1\textwidth]{images/iterative_count.pdf}
   	\caption{Distribution of the iteration times for bundles}
   	\label{fig:iterative_count}
\end{minipage}\hspace{.1cm}
\begin{minipage}[t]{0.4\linewidth}
	\centering
   	\includegraphics[width=1\textwidth]{images/time_merge_feature_bundle.pdf}
    \caption{Distribution of the time spent on merging feature bundles}
    \label{fig:time_on_merge_feature_bundle}
\end{minipage}
\end{figure}

To evaluate the robustness of the iterative back-complementary recovery mechanism, we conduct an evaluation on a set of open-source apps.
Although we can conduct evaluations on APK files directly, developers may have used some tools to protect their app from being reversely engineered. 
Therefore, we could fail to run the decomposed apps. 
To avoid such issue, we download 50 open-sourced apps from the F-droid\footnote{F-Droid is an installable catalogue of FOSS (Free and Open Source Software) apps for the Android platform (\url{https://f-droid.org/})} and Github and verify the correctness of our decomposition process.

For each app, we choose the home activity and those \emph{welcome} activities to generate the base bundle, and choose activities that are successor nodes of the home activity on the activity transition graph~\cite{OOPSLA13Azim} to generate feature bundles. We inject a piece of code to directly return before the code that opens an activity not included in either the base bundle or the feature bundles.

\noindent \textbf{Effectiveness and Efficiency of Supplementing Missing Code and Resources}.  We use the iterative back-complementary recovery mechanism to supplement the missing code and resources so that the decomposed apps can run correctly. We count the required iteration times to supplement the base bundle and the feature bundles for the 50 apps. Figure~\ref{fig:iterative_count} shows that we can successfully supplement the missing code and resources after 8 iterations, and no more than 10 iterations for 80\% of the apps. Notice that every iteration needs to add only one class. Compared to the number of classes (ranging from 1160 to 5817, 3347 in the median case) in the base bundle, the additional cost of iterations is quite marginal. Meanwhile, we find that supplementing feature bundles usually needs fewer iterations. This is because most of the missing code and resources in a feature bundle have been already included in the base bundle. We also find that many apps use some popular third-party libraries, and thus they miss same classes. In future work, we plan to use this finding to optimize the efficiency of the mechanism when we detect apps use these libraries.


\noindent \textbf{Runtime Correctness}. We further verify the decomposition correctness of \nickName{} on the 50 open-source apps. 
We first use the Monkey~\cite{monkey} tool to generate random streams of user events, such as clicks, touches, or gestures, as well as a number of system-level events, to run the original application for one minute. 
During the executions, we use the MonkeyRunner~\cite{monkeyrunner} to record these actions.
The recorded actions are then used to replay the decomposed apps running in the \nickName{} client for a fair comparison. 
For each app, we run both the original app and the decomposed app 10 times to collect the logs. 
We successfully run our decomposed apps in the \nickName{} client without crashes. 
According to the collected logs, our decomposed apps do not throw extra exceptions or cause errors during the executions, demonstrating the robustness of our approach.

\subsection{User-Perceived Performance}


\begin{figure*}[!t]
   \centering
  	\subfigure[Launching time of base bundles]{
     \label{fig:time_on_launch}
    \includegraphics[width=0.4\textwidth]{images/launch_time.pdf}}
      %\hspace{0in}
    \subfigure[Launching time of feature bundles in the warm start]{
    \label{fig:feature_load_time_warm}
    \includegraphics[width=0.4\textwidth]{images/feature_load_time_warm.pdf}}
  	%\hspace{0in}
  	\subfigure[Memory usage of launching base bundles]{
    \label{fig:launch_memory}
    \includegraphics[width=0.4\textwidth]{images/launch_memory.pdf}}
     % \hspace{0in}
    \subfigure[Memory usage of launching feature bundles]{
    \label{fig:load_memory}
    \includegraphics[width=0.4\textwidth]{images/load_memory.pdf}}
 \vspace{-1em}
  \caption{Runtime Performance}
  \vspace{-1em}
  \label{fig:evaluation}
\end{figure*}

Finally, we evaluate the runtime performance of the \nickName{} client using the 50 apps obtained in Section~\ref{subsec:robustness}. 
We use a Nexus 6 (3GB RAM, 32GB Rom, Quad-core 2.7 GHz) smartphone running Android 7.1.1 as our test device.

We measure the overhead when launching the base bundles with \nickName{} client compared to the overhead of launching the original app directly on the same platform. For each app, we choose the activities that are successor nodes of the home activity on the activity transition graph as the feature activities for testing, and open them with the \nickName{} client. For fair comparisons, we then launch the same activity in the original app directly. We compare the performance in terms of two metrics: activity load time~\cite{launch_time} and memory (RAM) usage. For a feature activity, we measure the performance on both cold start (the feature bundle is not installed on the device) and warm start (the feature bundle has been loaded previously). The cold start includes downloading the feature bundle, merging the resources, and loading the code. The warm start only needs to load the local code.  Figure~\ref{fig:evaluation} shows the results.


\noindent \textbf{Performance of launching the base bundle}. Figure~\ref{fig:time_on_launch} shows that launching the base bundle in the \nickName{} client performs even better than directly launching the original app. The base bundle contains only a part of code and resources extracted from the original app, and thus the launching process is more efficient. The median value for launching an app in the \nickName{} is about 654 ms, compared to 734 ms for the original app (about 10.9\% saving in the launching time). We also measure the memory usage as shown in Figure~\ref{fig:launch_memory}. We find that launching the base bundle requires less memory compared to launching the original app directly. In the median case, launching an app in \nickName{} client can save 6.5\% memory usage. It is worth to note that, the benefit from the reduced code base is somehow compromised by the overhead introduced by the virtualization layer of the \nickName{} client.
The reason is that our current implementation depends on \textit{VritualApp}, which loads some unnecessary libraries and incurs extra overhead. However, such an overhead can be further mitigated by implementing our approach at the kernel space. 



\noindent \textbf{Performance of launching feature bundles}. We also find that the code start process of a feature bundle takes a much longer time than the warm start process. The bottleneck lies in the merging process. The \nickName{} client needs to download and merge the resources from the feature bundle into the base bundle, which involves is a time-consuming recompression process~\cite{incrementalupdate}.  Figure~\ref{fig:time_on_merge_feature_bundle} shows that the median value for the time used by the \nickName client to merge the resources extracted from a feature bundle is 2404.9 ms. However, we can eliminate such a cost by prefetching the feature bundle in the background according to others' access frequencies~\cite{WWW2010Zhou}. In practice, end users do not have to wait for these time-consuming processes on warm start, because the later visit needs to only load the code on local device directly. Although the \nickName{} client introduces a virtualization layer that may incur extra overhead and latency, a decomposed app with a smaller size can be still launched faster. Figure~\ref{fig:feature_load_time_warm} shows that opening a feature activity in the \nickName client takes a comparable time for the warm start compared to opening the same activity in the original app directly. For some cases, the activity load time can be even reduced with \nickName{}. The median value of the time for opening a feature activity in the \nickName{} client is about 216ms, compared to 270ms in the Android OS (saving about \textbf{20\%} of theopening time).



Figure~\ref{fig:load_memory} shows the memory overhead when opening an activity in the decomposed app and the original app, respectively. We just measure the memory usage after the activity is launched, because the memory varies during the launching process. In the median case, launching an app in \nickName{} can save \textbf{10.7\%} of the used memory.




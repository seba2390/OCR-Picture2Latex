% !TEX root = XStreamFull.tex

\Cindy{Some stubs to include in the intro. We'll need to decide the extent this is a theory paper and the extent it is a systems/algorithms paper.  These pieces may move around when we turn our attention to the intro. I'm just putting down some thoughts from our discussions and some notation we will need as we go through the technical parts of the paper.}\Jon{I think this is mitigated now.  Cindy?}

%\Jon{relevant to Related Work section: Caveat application considerations
%like small components not being visible during their (brief) lifetime
%if you process edges in large batches. Maybe cite Fan Chung work on the
%    lifetime of the second largest component (size ~ 2 log n).} JWB mitigated
We assume that the graph-edge stream is {\em effectively infinite}. This means that as long as the algorithm is running, it must always be prepared for the arrival of another edge. At any time, the system has seen only a finite set of edges and need store only a finite graph representation.  However this graph can be arbitrarily large and may eventually exceed any particular finite storage. In
order to deal with this case, we define a streaming model to exploit
distributed systems with huge aggregate memory and to handle bulk deletions
customized by a user-provided deletion or ``aging'' predicate.  The most
straightforward predicate would be $\Call{Age}{\mbox{t}}$ (get rid
of edges older than a certain timestamp), but users may require bulk
deletions guided by different predicates.  For example, they may wish to
preserve some old edges of high value.


Previous theoretical work on infinite graph streams in a sliding-window model
does allow for automatic time-based expiration while maintaining connected
 components~\cite{crouch2013dynamic,mcgregor2014graph}.  We adapt and
 generalize these theoretical ideas by allowing user-defined deletion
 predicates and distributed computation.  Furthermore, in
 Section~\ref{sec:related-work}
 we briefly survey previous work on dynamic graph processing.
 For now, we simply note that while some of this literature achieves impressive
 edge ingestion rates, none of it explains how to continue ingestion
 indefinitely as the storage capacity fills up.  These dynamic methods
 accept a stream of insertions and deletions, and if the former dominates the
 latter, the system will eventually fill and fail.  In this paper, we spend
 most of our effort providing a theoretical basis for graph stream
 computations of arbitrary duration.  We ensure that each edge is
 stored only once in our distributed model during normal conditions, and
 that we recover to that steady state in a predictable way after an
 aging event.

 Many dynamic graph processing systems ingest edges concurrently
 in large blocks, making it potentially impossible to detect the emergence and
 disappearance of fine-grained detail such as
 $O(\log n)$-sized components that merge into a giant component,
 as predicted by~\cite{chung}.  We model ingestion at a single-edge
 granularity to ensure that phenomena such as this will be observable.

\paragraph{Contributions} We give a distributed algorithm for maintaining streaming connected components. Processors are connected in a
one-way ring, with only one processor connected to the outside. The algorithm is designed for cybersecurity monitoring and has the following set of features:
\begin{itemize}
\item The system works with an arbitrary number of processors, allowing the system to keep an arbitrary number of edges.
\item Each edge is stored on only one processor, requiring $O(1)$ space, so the asymptotic space complexity is optimal.
\item The system fails because of space only if all processors are holding edges to their maximum capacity.
\item Processing an edge or query requires almost-constant time per system ``tick,'' the time to run union-find (inverse Ackermann's function).
\item Connectivity-related queries, spanning-tree queries, etc, are answered at perfect granularity. Though there is some latency, the answer is perfect with respect to the graph in the system at the time the query was asked.  This is in contrast to systems that process edge changes in batches up to millions allowing no finer granularity to queries.
\item Because some cyber phenomena do not have explicit edge deletions, the system removes edges only when required.
\begin{itemize}
\item This edge deletion is done in bulk.  Though querying is disabled during data structure repair, the system continues to ingest incoming edges. There is no need to buffer or drop edges if deletion happens during a period of lower use such as at night.
\item The analyst can select any (constant-time) edge predicate to determine which edges survive a bulk deletion.  This allows analysts to keep edges they feel are of high value regardless of their age.
\item For age-based deletion, the system can trigger and select correct parameters for bulk deletion automatically.
\end{itemize}
\item If the analyst selects legal values (depending on properties of the hardware and input stream) for how many edges survive a bulk deletion and what fraction of the time the system must answer queries, the system will run indefinitely.
\end{itemize}

\Cindy{TODO: What have I missed.  Also, a similar list for the experiments.}

%\Alex{move the following into model section and replace with forward reference} JWB: deprecated, I think
\Cindy{These definitions should clarify a lot of concepts.  For example, a query sent at time t (that is between the tth potentially graph-changing event and the (t+1)st) answers the query based on graph $G(t)$.  It's possible for a vertex to be in $V(t)$ and $V(t'')$, but not $V(t')$ for some $t < t' < t''$.  At any time t, there is a primitive BB in the system for exactly each vertex in $V(t)$.}\Jon{This is mitigated, I think.  Cindy?}
\Cindy{NEW: I will check that we make each point.}

%\Cindy{TODO: Consider making current sections 1.1-1.3 a section 2 called Preliminaries.}
\section{Preliminaries}
\subsection{Modeling the graph through time}
We mark time based upon the arrival of any input stream element.  Time $t$
starts at zero and increments whenever a stream element arrives.
The input stream at time $t$ is the ordered stream that has arrived between
time $0$ and time $t$.
A stream element is an input edge $(u,v)$, a query (e.g., $\Call{Connected}{u,v}$), or a command (e.g. $\Call{Age}{timestamp}$).
In Section~\ref{sec:model} we formalize the operation
of our new model, \emph{\XStreamns}, at each of these ticks.
\begin{definition} 
\label{def:active}
\begin{tcolorbox}
\begin{description} 
\item \
\item[{\bf Active Edge:}] At any time $t > 0$, we say an edge is {\em active} if it has entered the system and no subsequent aging command has removed it. 
\item \
\item[{\bf Active Graph}:]
At any time $t > 0$, the active graph is $G_t = (V_t, E_t)$. Edge set $E_t$
is the set of active edges at time $t$ and the vertex set $V_t$ is the
set of endpoints of $E_t$.
\item \
\item[{\bf Active Stream}:] At any time $t > 0$, an active stream $A_t$ is
a subset of the input stream consisting only of active edges. \Cindy{We probably need a different notation, since we use $A_0$ to denote an initial finite graph input to DFR, following their notation.}
\end{description}
\end{tcolorbox}
\end{definition}

Note that $G_{t+1}$ differs from $G_t$ iff the stream element arriving at
time $t+1$ is an edge not already in $E_t$ or or an aging command.  In the
latter case, $E_{t+1}$ is the set of edges that survive the aging.

\noindent

% the algorithm never receives an ``end of graph'' marker that might signal a new pass in streaming algorithms for finite streams.

\Cindy{The older, so far unrevised intro follows this point.}\Jon{mitigated, I think.  Cindy?}

\subsection{Streaming models}
In classic streaming models, computing systems receive data in a sequence of pieces and do not have space to store the entire data set. As in online algorithms, systems must make irreversible decisions without knowledge of future data arrivals. Graph streams are a type of such data streams in which a sequence of edges arrives at the computing system, which may assemble some of the edges into a graph data structure. Applications include modeling the spread of diseases in health-care networks, analysis of social networks, and security and anomaly detection in computer-network data. We focus on cybersecurity applications, in which analysts can infer interesting information from graphs that model relationships between entities. As the scale of such graphs increases, analysts will need algorithms to at least partially automate stream analysis.

We present detailed algorithms and a complete implementation of the real-time graph-mining methodology introduced in~\cite{AMP:berry2013maintaining}. In this streaming model, the full graph is stored in a distributed system. The model is also capable of bulk edge deletion, while continuing to accept new edges. The algorithm continuously maintains connected-component information.  It can answer queries about components and connectivity, except during a period of data-structure repair immediately following a bulk delete.

In classic graph streaming models, such as in~\cite{AMP:munro1980selection,AMP:muthukrishnan2005data,AMP:raghavan1999computing}, the input is a finite sequence of edges, each consisting of a pair of vertices. The edge sequence is an arbitrary permutation of graph edges, which may include duplicates. The output consists of each vertex, along with a label, such that two vertices have the same label if and only if they belong to the same component. Algorithms for the classic streaming model have two parameters: $p$, the number of times the algorithm can see the input stream, or the number of passes on the stream, and $s$, the storage space available to the algorithm. 

\Alex{need note about properties of algo, incl. asymptotically optimal space}\Jon{Mitigated, I think.  Alex?}
\Cindy{I didn't really see where we said that each edge requires O(1) storage across the whole system and therefore the space is optimal. I'm going to try to add a easy-to-find contributions section early in the introduction.}
\Jon{mitigated}

\begin{figure}[htb]
\begin{center}
\includegraphics[width=3.5in]{w-stream-example.png} \\
\end{center}
\caption{\label{fig:wstream-example} Example of the first pass of the  \DFR 
connected components algorithm.
The \uf structure in the upper left has a capacity of four union
operations. This pass ingests five edges (shown in red) 
before filling, creating three super-nodes: $b$, $e$, and $j$,
which encapsulate vertices $f$, $g$, $h$, and $k$.
Edge $(e,g)$ was redundant. The remaining edges are relabled and
emitted as stream ``$A_1$,'' representing the contracted graph.
Then the contents of the \uf structure are emitted
(this is stream $B_1$).}
\end{figure}

The \emph{\WStreamns} model, developed in~\cite{AMP:demetrescu2009trading},
uses the concept multiple passes. Each pass can emit a customized
intermediate stream. \WStream can support several graph algorithms. However,
our work is specifically based upon the connected components algorithm
of~\cite{AMP:demetrescu2009trading}, which we will call \emph{\DFR} to
recognize the authors: Demetrescu, Finocchi, and Ribichini.

In the \emph{streamsort} model, introduced in~\cite{AMP:aggarwal2004streaming}, algorithms can create and process intermediate temporary streams, and reorder the contents of intermediate streams at no cost.


\subsection{\WStreamns}\label{sec:intro:wstream}
Because our work is an extension of the \DFR finite-stream connected-components algorithm based on the \WStream model, we describe that algorithm and model in detail now.  \DFR uses graph {\em contraction}. In contraction, one or more connected subgraphs are each replaced by a {\em supernode}.  Edges within a contracted subgraph disappear and edges with one endpoint inside a supernode now connect to the supernode.  For example, in Figure~\ref{fig:wstream-example}, connected subgraph (triangle) $f$, $e$, $g$, is contracted into supernode $e$.

In each pass, the W-Stream connected components algorithm ingests a finite stream and outputs a modified stream to read for the next pass. 
Each stream represents a progressively more contracted graph, where connected subgraphs contract to a node, until a single node represents each connected component. The stream at each pass comes in two parts. The first (A) part is the current, partially contracted graph, and the second (B) part lists the graph nodes buried inside supernodes. The initial input stream has all the graph edges in part A and an empty part B.  The last final-output stream has an empty part A and part B gives a component label for each vertex.
Figure~\ref{fig:wstream-example} illustrates the input and output of the first pass of the W-Stream connected-components algorithm.

During pass $i$, the algorithm ingests streams $A_{i-1}$ and $B_{i-1}$, in that order. 
First, it computes connected components using \uf
data structures until it runs out of memory.  More formally, $s$ is the
\emph{capacity} of the \WStream processor, measured in union operations. As shown in Figure~\ref{fig:wstream-example}, the set representative is one of the set elements, for reasons given later.
This \uf stage ingests a prefix of stream $A_{i-1}$.
Because its memory is now full, the processor must now emit information about the remaining stream rather than ingesting it. The algorithm incorporates what it has learned about the graph's connected components into the input for the next pass. Specifically, in the contracted graph corresponding to stream $A_i$ (called $G_{A_{i}}$), each set in the \uf data structure is represented as a supernode. 
% To generate the next output stream, the W-Stream algorithm contracts the connected components it found during the union-find stage.


The \DFR algorithm now generates the next stream $A_i$ from the remainder of stream $A_{i-1}$.
For each remaining edge $(u,v)$ in stream $A_{i-1}$, if endpoint $u$ is
buried within supernode $x$, we {\em relabel} $u$ to $x$. For example, 
in Figure~\ref{fig:wstream-example}, node $g$ is buried in supernode $e$.
Therefore, edge $(c,g)$ is relabeled to $(c,e)$.  If both endpoints are
relabeled to the same supernode, \DFR drops it according to contraction rules.

We now describe how to process stream $B_{i-1}$ and to emit stream $B_i$. In the first pass, stream $B_0$ is empty.  Stream $B_1$ tells which nodes are ``buried'' in the newly-created supernodes. Specifically, stream $B_1$ is a set of pairs $(u,x)$, where node $u$ is buried inside supernode $x$. Node $u$ will never appear in any future stream $A_i$. 
To process a non-empty stream $B_{i-1}$, we use the same relabeling strategy we used while emitting stream $A_i$.  However, the interpretation is different.  If $(u,x)$ is in stream $B_{i-1}$, and supernode $x$ is now part of a \uf set with representative $y$, we emit $(u,y)$ to stream $B_{i}$.  This means that node $u$ is part of supernode $y$ in stream $A_i$.

\iffalse
\cite{AMP:demetrescu2009trading} names the \uf structures that 
exist before the $i$'th pass $G_{B_{i-1}}$, as the the representative
relationships can be interpreted as graph edges.  Although these edges
may not be original input edges, they give rise to the same connected component
structure as that of the original stream.
In Figure~\ref{fig:wstream-example}, $G_{B_1}$ has the four edges colored blue.  Note that $G_{B_0}$ is
always the empty graph.


\Cindy{Have to describe processing the rest of the stream, which creates the A stream and the start of the B stream.  I think it would help to have figures here, e.g. the ones from our talks.} 

After all edges of the stream have been processed, the processor outputs (node, leader) pairs for each node in a contracted component, based on the updated state of the \uf structures.
\fi

This process repeats until pass $f$ where $A_f$ is the empty stream. Stream $B_f$ can be interpreted as connected-component labels.  Two nodes have the same supernode label if and only if they are in the same connected component. 

%The supernode existing leader names correspond to the connected component labels. 

%\Alex{begin adding of details for later reference}
%The graph induced by the first part of the stream (the partially contracted graph) on pass $i$ is denoted $G_{A_i}$. The graph induced by the second part of the stream (the descriptions of contents of contracted nodes) is denoted $G_{B_i}$. Initially, the first part of the stream contains the original graph and nothing has been contracted, so $G_{A_0} = G$ and $G_{B_i} = \emptyset$.

We now summarize the argument from~\cite{AMP:demetrescu2009trading} that the \DFR algorithm is correct.  The $B_i$ streams are pairs of vertices from the original graph that are in the same connected component by correctness of the union-find algorithm.  We can therefore interpret the pair $(u,x)$ as an edge in a star-graph representation for a (partial) connected component (in their lingo, 
a ``collection of stars'').
%So stream $B_i$ is a set of star graphs that we call $G_{B_i}$.

Correctness of \DFR follows from maintaining the following invariant at each pass.
\begin{invariant} (\cite{AMP:demetrescu2009trading} Invariant 2.2)\label{inv:wstreamreqs}
For each $i \in \{0,..,p\}$, $G_{B_i}$ is a collection of stars and $G_{A_i} \cup G_{B_i}$ has the same connected components as $G$.
\end{invariant}

\begin{observation} 
\label{obs:wstreamreqs}
\DFR computes the same set of connected components for any permutation of
the input stream, and any arbitrary duplication of stream elements.
\end{observation} 

\Alex{stub:  each edge only stored once so space is linear; add note to intro about asymptotically optimal space?} \Cindy{This probably has to move earlier in the introduction.}\Jon{I think this is mitigated (see above).  Cindy and Alex?}

\begin{figure}[htb]
\begin{center}
\includegraphics[height=1.5in]{w-stream-impl.png} \\
\end{center}
\caption{\label{fig:wstream-impl} Implementation of the \DFR connected
components algorithm in the \WStream model.
The output of pass $i$ must be stored to disk, then read back in as input
for pass $i+1$.}
\end{figure}

\iffalse
Note that since the \WStream model does not tolerate deletions, there is
no need to maintain the graph itself.  At pass $i$,  $G_{A_i}$ is a spanning
tree of input graph edges, but $G_{B_i}$ is simply a collection of ``stars'': a
relation that associates every vertex with a vertex representative (potentially
itself) shared by a set of connected vertices.
\fi





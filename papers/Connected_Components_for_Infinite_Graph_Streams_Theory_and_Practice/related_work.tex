This paper is motivated by the obseration that no other published work
meets the needs of the cybersecurity use case we describe in
Section~\ref{sec:intro}.  Most work on theoretical streaming problems,
best surveyed in~\cite{AMP:muthukrishnan2005data}, is limited to the finite case. Some research in the past decade has addressed 
infinite graph streaming in a sliding-window model~\cite{crouch2013dynamic,mcgregor2014graph} but the work is quite abstract, and expiration must be
addressed with every new stream observation.  We were unable to apply
this theory directly in a distributed system with bulk deletions, but our
\XSCC algorithm could be thought of as a generalized, distributed 
implementation of these sliding window ideas.

As far as we know, our \XStream model
and XS-CC graph-algorithmic use case comprise the first approach to
infinite graph streaming that is both theoretically-justified and practical.
We provided an initial view of the \XStream model in
a 2013 KDD workshop paper~\cite{AMP:berry2013maintaining}, and provide full
detail of a greatly-streamlined version in this paper. 
%\Jon{TODO: figure out what Tarjan did with online minimum spanning trees 
%to allow the sliding window algorithm to work, add lots of cites for
%infinite sliding window.}

As the previous sections have made clear, our focus is infinite streaming of
graph edges with theoretical guarantees and a well-defined expiration 
strategy with a path to implementation in simple distributed systems.
Thus, we have approached the problem from a theoretical streaming perspective,
focusing primarily on related ``per-edge arrival'' streaming details.
We have shown how to maintain connectivity
and spanning tree information. We hope that others will expand the set
of graph queries available in \XStreamns, and/or propose new infinite
streaming models.

The closest related work comes from the discipline of \emph{dynamic graph
algorithms}, which takes a different approach.  Work in this area
typically assumes that the graph in its entirety is stored in a shared address
space or supercomputing resource.  Updates to the graph come in batches and 
take the form of edge
insertions and sometimes deletions too.  After a batch of updates is received,
incremental graph algorithms update attributes such as connected components
or centrality values.  During this algorithmic update the stream is typically
stopped.  There
is no attempt to describe what running infinitely in a finite space would mean
other than to rely on an implicit assumption that the batches will have as
many deletions as insertions over time.  We know that in the cybersecurity
context, for example, this assumption will never be true. An impressive
survey of dynamic graph processing systems is found in~\cite{besta2019practice}.

We break down the area of dynamic graphs into data structure work
that builds a graph without computing any algorithm
(for example~\cite{ediger2012stinger,riedy2011tracking,pearce1}),
work that ``stops the world'' at each algorithmic update
(for
example~\cite{riedy2011tracking,saga,helen}),
and recent attempts to
to process graph updates update algorithmic results concurrently~\cite{yin2018new,yin2019concurrent,sallinen2019incremental,grossman2020hoover}.

The data structure group includes solutions such as~\cite{ediger2012stinger},
 which achieves a rate of over 3 million edges per second on a Cray
 XMT2 supercomputer using a batch size of 1,000,000 edge updates,
 and~\cite{pearce1}, which achieves a rate of more than two billion edges
 per second on a more modern supercomputer while maintaining some
 information about
 vertex degrees.  While these rates are impressive, approaches such as these
 require a supercomputer and don't specify how to continue running as
 their storage fills up.

When incremental computation of graph algorithms such as Breadth-First
Search (BFS), connected components, PageRank, and others, SAGA-Bench~\cite{saga}
can achieve latencies of a fraction of a second on conventional hardware
using an update batch size of 500,000 edges.  This tranlates to a few
million updates per second, while also maintaining incremental graph
algorithm solutions.  Wheatman and Xu also exploit large batches of edge
updates and advanced data strctures (packed-memory arrays) to approach
this problem~\cite{helen}.  They achieve amortized update rates of up to
80 million updates per second while maintaining per-batch solutions to
graph problems such as connected components, where update batches can be of
size 10,000,000 or greater.  Even if our analysts could tolerate such
batch sizes, however, what prevents us from
simply adopting their approach is the requirement that we must
have a methodology for running infinitely.

We conclude our discussion of the dynamic graph literature with recent
results that process graph updates and update algorithmic results without
interrupting the input stream. The HOOVER system can run vertex-centric
graph computations on supercomputers that update connected components
information at an ingestion rate of more than 600,000,000 edges per
second~\cite{grossman2020hoover}.  However, the update algorithm works only
for edge insertions so our requirements are not met and the system would
 quickly fill up. Yin, et al.~\cite{yin2018new} propose a concurrent streaming
 model, and Yin \& Riedy~\cite{yin2019concurrent} instantiate this model with
 an experimental study on Katz centrality.  However, overlapping graph update
 and graph computation still does not meet our need for a strategy to compute
 on infinite streams.

Massive amounts of data collected by recent information systems give rise to new challenges in the field of signal processing, machine learning, and data analysis.  One such challenge is to develop fast and accurate algorithms so as to find low-dimensional structures in large-scale high-dimensional data sets. The task of extracting such low-dimensional structures is encountered in many practical applications including motion segmentation and face clustering in computer vision \cite{yang2008unsupervised,vidal2008multiframe}, image representation and compression in image clustering \cite{ho2003clustering,hong2006multiscale}, and hybrid system identification in systems theory \cite{vidal2003algebraic}. In these settings, the data can be thought of as being a collection of points lying on a union of low-dimensional subspaces. The goal of subspace clustering is to organize data points into several clusters so that each cluster contains only the points from the same subspace.

Subspace clustering has drawn significant attention over the past decade \cite{vidal2011subspace}. Among various approaches to subspace clustering, methods that rely on spectral clustering \cite{ng2001spectral} to analyze the similarity matrix representing the relations among data points have received much attention due to their simplicity, theoretical rigour, and superior performance. These methods assume that the data is {\em self-expressive} \cite{elhamifar2009sparse}, i.e., each data point can be represented by a linear combination of the other points in the union of subspaces. This motivates the search for a a so-called subspace preserving similarity matrix {\color{black}{which establishes stronger connections among the points originating from a similar subspace}}. To form such a similarity matrix, the sparse subspace clustering (SSC) method in \cite{elhamifar2009sparse,elhamifar2013sparse} employs a sparse reconstruction algorithm referred to as basis pursuit (BP) that aims to minimize an $\ell_1$-norm objective by means of convex optimization approaches such as interior point \cite{kim2007interior} or alternating direction of method of multipliers (ADMM) \cite{boyd2011distributed}. In \cite{dyer2013greedy,you2015sparse}, orthogonal matching pursuit (OMP) is used to greedily build the similarity matrix. Low rank subspace clustering approaches in \cite{lu2012robust,liu2013robust,favaro2011closed,vidal2014low} rely on convex optimization techniques with $\ell_2$-norm and nuclear norm regularizations and find the singular value decomposition (SVD) of the data so as to build the similarity matrix. Finally, \cite{heckel2015robust} presents an algorithm that constructs the similarity matrix through thresholding the correlations among the data points. Performance of self-expressiveness-based subspace clustering schemes was analyzed in various settings. It was shown in \cite{elhamifar2009sparse,elhamifar2013sparse} that when the subspaces are disjoint (independent), the BP-based method is subspace preserving. \cite{soltanolkotabi2012geometric,soltanolkotabi2014robust} take a geometric point of view to further study the performance of BP-based SSC algorithm in the setting of intersecting subspaces and in the presence of outliers. These results are extended to the OMP-based SSC in \cite{dyer2013greedy,you2015sparse}.  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Sparse subspace clustering of large-scale data is computationally challenging. The computational complexity of state-of-the-art BP-based method in \cite{elhamifar2009sparse} and the low rank representation methods \cite{lu2012robust,liu2013robust,favaro2011closed,vidal2014low} is often prohibitive in practical applications. On the other hand, current scalable SSC algorithms, e.g., \cite{dyer2013greedy,you2015sparse}, may produce poor clustering solutions, especially in scenarios where the subspaces {\color{black}{are not well separated}}.
In this paper, we address these challenges by proposing a novel self-expressiveness-based algorithm for subspace clustering that exploits a fast variant of orthogonal least-squares (OLS) to efficiently form a similarity matrix by finding a sparse representation for each data point. We analyze the performance of the proposed scheme and show that in the scenarios where the subspaces are independent, the proposed algorithm always finds a solution that is subspace-preserving. Simulation studies illustrate that our proposed SSC algorithm significantly outperforms the state-of-the-art method \cite{elhamifar2009sparse} in terms of runtime while providing essentially the same or better clustering accuracy. The results further illustrate that, unlike the methods in \cite{elhamifar2009sparse,dyer2013greedy,you2015sparse}, when the subspaces are dependent our
proposed scheme finds a subspace preserving solution.
%\end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The rest of the paper is organized as follows. Section \oldref{sec:pre} formally states the subspace clustering problem and reviews some relevant concepts. In Section \oldref{sec:alg}, we introduce the accelerated sparse subspace clustering algorithm and analyze its performance. Section \oldref{sec:sim} presents the simulation results while the concluding remarks are stated in Section \oldref{sec:concl}. \footnote{The MATLAB implementation of the proposed algorithm is available at \url{https://github.com/realabolfazl/ASSC}.}
\documentclass{article}
\input{defspack}
\title{Accelerated Sparse Subspace Clustering}
%
% Single address.
% ---------------
\name{Abolfazl Hashemi and Haris Vikalo}
\address{Department of Electrical and Computer Engineering,  University of Texas at Austin, Austin, TX, USA}
\begin{document}
%\ninept
%
\maketitle
%
\begin{abstract}
State-of-the-art algorithms for sparse subspace clustering perform spectral clustering on a similarity matrix typically obtained by representing each data point as a sparse combination of other points using either basis pursuit (BP) or orthogonal matching pursuit (OMP). BP-based methods are often prohibitive in practice while the performance of OMP-based schemes are unsatisfactory, especially in settings where data points are highly similar. In this paper, we propose a novel algorithm that exploits an accelerated variant of orthogonal least-squares to efficiently find the underlying subspaces. We show that under certain conditions the proposed algorithm returns a subspace-preserving solution. Simulation results illustrate that the proposed method compares favorably with BP-based method in terms of running time while being significantly more accurate than OMP-based schemes. 
\end{abstract}
%
\begin{keywords}
sparse subspace clustering, accelerated orthogonal least squares, scalable algorithm, large-scale data
\end{keywords}
\vspace{-0.2cm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}\label{sec:intro}
\input{Secintro}
\vspace{-0.2cm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Problem Formulation}\label{sec:pre}
\input{Secpre}
\vspace{-0.2cm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Accelerated OLS for Subspace Clustering}\label{sec:alg}
\input{Secalg}
\vspace{-0.2cm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Simulation Results}\label{sec:sim}
\input{Secsim}
\vspace{-0.2cm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion} \label{sec:concl}
In this paper, we proposed a novel algorithm for clustering high dimensional data lying on a union of subspaces. The proposed algorithm, referred to as accelerated sparse subspace clustering (ASSC), employs a computationally efficient variant of the orthogonal least-squares algorithm to construct a similarity matrix under the assumption that each data point can be written as a sparse linear combination of other data points in the subspaces. ASSC then performs spectral clustering on the similarity matrix to find the clustering solution. We analyzed the performance of the proposed scheme and provided a theorem stating that if the subspaces are independent, the similarity matrix generated by ASSC is subspace-preserving. In simulations, we demonstrated that the proposed algorithm is orders of magnitudes faster than the BP-based SSC scheme \cite{elhamifar2009sparse,elhamifar2013sparse} and essentially delivers the same or better clustering solution. The results also show that ASSC outperforms the state-of-the-art OMP-based method \cite{dyer2013greedy,you2015sparse}, especially in scenarios where the data points across different subspaces are similar. 

As part of the future work, it would be of interest to extend our results and analyze performance of ASSC in the general setting where the subspaces are arbitrary and not necessarily independent. Moreover, it would be beneficial to develop distributed implementations for further acceleration of ASSC.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\bibliographystyle{ieeetr}\small
\bibliography{refs}
\end{document}

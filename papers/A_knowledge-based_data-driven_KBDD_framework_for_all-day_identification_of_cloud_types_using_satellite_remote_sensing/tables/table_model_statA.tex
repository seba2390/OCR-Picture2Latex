\begin{table}[H]
    \centering
    \vspace{-0.5cm}
    \caption{The classification evaluation indicators of various cloud types obtained by different models for 2022-09-23 03:00 (UTC+0).}
    \label{table:model_statA}
    \resizebox{0.95\linewidth}{!}{
        \begin{tabular}{cccccccccccc}
            \hline
            Model      & Indicator              & Cl      & Ci      & Cs      & Dc      & Ac      & As      & Ns      & Cu      & Sc      & St      \\
            \hline
            CldNet     & Precision              & 0.89926 & 0.81549 & 0.87483 & 0.89708 & 0.55967 & 0.73586 & 0.73301 & 0.72223 & 0.79858 & 0.72630 \\
            CldNet     & Recall                 & 0.91963 & 0.69801 & 0.90647 & 0.85264 & 0.56451 & 0.74197 & 0.68178 & 0.78788 & 0.82451 & 0.48151 \\
            CldNet     & $\mathrm{F_{1}}$-score & 0.90933 & 0.75219 & 0.89037 & 0.87430 & 0.56208 & 0.73890 & 0.70647 & 0.75363 & 0.81134 & 0.57910 \\
            SegNet     & Precision              & 0.75953 & 0.65885 & 0.68310 & 0.70178 & 0.37352 & 0.48296 & 0.44760 & 0.49174 & 0.51699 & 0.30031 \\
            SegNet     & Recall                 & 0.87888 & 0.52666 & 0.77155 & 0.57951 & 0.23953 & 0.50415 & 0.27200 & 0.52409 & 0.66293 & 0.03409 \\
            SegNet     & $\mathrm{F_{1}}$-score & 0.81486 & 0.58538 & 0.72464 & 0.63481 & 0.29188 & 0.49333 & 0.33837 & 0.50740 & 0.58093 & 0.06124 \\
            PSPNet     & Precision              & 0.77093 & 0.49427 & 0.55745 & 0.54970 & 0.30614 & 0.43938 & 0.49505 & 0.46337 & 0.49045 & 0.54712 \\
            PSPNet     & Recall                 & 0.77889 & 0.54580 & 0.73306 & 0.72357 & 0.25343 & 0.37933 & 0.32664 & 0.33915 & 0.58362 & 0.09041 \\
            PSPNet     & $\mathrm{F_{1}}$-score & 0.77489 & 0.51876 & 0.63331 & 0.62476 & 0.27730 & 0.40715 & 0.39359 & 0.39165 & 0.53299 & 0.15517 \\
            DeepLabV3+ & Precision              & 0.80689 & 0.70137 & 0.77049 & 0.80571 & 0.42516 & 0.60434 & 0.60918 & 0.52389 & 0.63459 & 0.57543 \\
            DeepLabV3+ & Recall                 & 0.86784 & 0.58361 & 0.81049 & 0.71387 & 0.37366 & 0.65713 & 0.44484 & 0.59872 & 0.65803 & 0.18535 \\
            DeepLabV3+ & $\mathrm{F_{1}}$-score & 0.83626 & 0.63709 & 0.78999 & 0.75701 & 0.39775 & 0.62963 & 0.51420 & 0.55881 & 0.64610 & 0.28039 \\
            UNet       & Precision              & 0.89000 & 0.82380 & 0.85197 & 0.88591 & 0.55346 & 0.69083 & 0.70279 & 0.71192 & 0.78000 & 0.66344 \\
            UNet       & Recall                 & 0.91971 & 0.66758 & 0.89256 & 0.78625 & 0.54091 & 0.73454 & 0.59482 & 0.78987 & 0.82110 & 0.47234 \\
            UNet       & $\mathrm{F_{1}}$-score & 0.90461 & 0.73751 & 0.87180 & 0.83311 & 0.54712 & 0.71201 & 0.64431 & 0.74887 & 0.80002 & 0.55181 \\
            ResUnet    & Precision              & 0.70701 & 0.60504 & 0.64891 & 0.71789 & 0.35650 & 0.42708 & 0.56189 & 0.48591 & 0.51580 & 0.08512 \\
            ResUnet    & Recall                 & 0.86831 & 0.55085 & 0.78377 & 0.51449 & 0.13640 & 0.44127 & 0.23545 & 0.52007 & 0.66036 & 0.00203 \\
            ResUnet    & $\mathrm{F_{1}}$-score & 0.77940 & 0.57668 & 0.71000 & 0.59940 & 0.19731 & 0.43406 & 0.33185 & 0.50241 & 0.57920 & 0.00396 \\
            UNetS      & Precision              & 0.87848 & 0.80943 & 0.83723 & 0.84560 & 0.52165 & 0.67380 & 0.66010 & 0.68090 & 0.74660 & 0.63135 \\
            UNetS      & Recall                 & 0.91656 & 0.65693 & 0.87540 & 0.78989 & 0.49330 & 0.69061 & 0.56905 & 0.76106 & 0.80982 & 0.37454 \\
            UNetS      & $\mathrm{F_{1}}$-score & 0.89711 & 0.72525 & 0.85589 & 0.81680 & 0.50708 & 0.68210 & 0.61120 & 0.71875 & 0.77693 & 0.47016 \\
            UNetS-W    & Precision              & 0.86887 & 0.82598 & 0.88479 & 0.87900 & 0.56838 & 0.74024 & 0.68192 & 0.71039 & 0.74202 & 0.54179 \\
            UNetS-W    & Recall                 & 0.91796 & 0.66130 & 0.91032 & 0.93918 & 0.48786 & 0.67082 & 0.76216 & 0.77122 & 0.84260 & 0.77500 \\
            UNetS-W    & $\mathrm{F_{1}}$-score & 0.89274 & 0.73452 & 0.89737 & 0.90810 & 0.52505 & 0.70382 & 0.71981 & 0.73955 & 0.78912 & 0.63774 \\
            UNetS-O    & Precision              & 0.86115 & 0.75843 & 0.73966 & 0.68304 & 0.49476 & 0.57628 & 0.57680 & 0.61483 & 0.63152 & 0.40416 \\
            UNetS-O    & Recall                 & 0.91666 & 0.57067 & 0.81494 & 0.61837 & 0.39027 & 0.67186 & 0.31917 & 0.69160 & 0.77872 & 0.03141 \\
            UNetS-O    & $\mathrm{F_{1}}$-score & 0.88804 & 0.65129 & 0.77548 & 0.64910 & 0.43635 & 0.62041 & 0.41094 & 0.65096 & 0.69744 & 0.05828 \\
            CldNet-W   & Precision              & 0.89334 & 0.83895 & 0.91096 & 0.90900 & 0.57737 & 0.77264 & 0.69976 & 0.74225 & 0.80456 & 0.64512 \\
            CldNet-W   & Recall                 & 0.92354 & 0.68315 & 0.92700 & 0.95484 & 0.56018 & 0.75058 & 0.82726 & 0.78538 & 0.84481 & 0.72012 \\
            CldNet-W   & $\mathrm{F_{1}}$-score & 0.90819 & 0.75307 & 0.91891 & 0.93135 & 0.56865 & 0.76145 & 0.75819 & 0.76321 & 0.82419 & 0.68056 \\
            CldNet-O   & Precision              & 0.88089 & 0.79055 & 0.78105 & 0.69935 & 0.54131 & 0.62346 & 0.53390 & 0.67256 & 0.68904 & 0.40466 \\
            CldNet-O   & Recall                 & 0.92033 & 0.61353 & 0.83083 & 0.75633 & 0.45802 & 0.69151 & 0.52409 & 0.71505 & 0.77811 & 0.22495 \\
            CldNet-O   & $\mathrm{F_{1}}$-score & 0.90018 & 0.69088 & 0.80517 & 0.72673 & 0.49620 & 0.65572 & 0.52895 & 0.69316 & 0.73087 & 0.28916 \\
            \hline
        \end{tabular}
    }
\end{table}
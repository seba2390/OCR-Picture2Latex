%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Forward Uncertainty Framework}
\label{Sec: Uncertainty framework}
%%%%%%%%%%%%%%%%%%%%%%%%%%%
%


%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\subsection{Formulation of Stochastic FPDE}
\label{Sec: Problem Definition}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
Let $\mathbb{D} = [0,T] \times [a_1,b_1] \times [a_2,b_2] \times \cdots \times [a_d,b_d]$ be the physical computational domain for some positive integer $d$ and stochastic function $u(t,\textbf{x};\omega): \mathbb{D} \times \Omega \rightarrow \mathbb{R}$, where $\omega \in \Omega$ denotes the random inputs of the system in a properly defined complete probability space $(\Omega, \mathcal{F},\mathbb{P})$. We consider the following SFPDE, subject to certain homogeneous Dirichlet initial/boundary conditions and stochastic process as additional force function, given as
%
\begin{align}
\label{Eq: Stochastic FPDE}
%
&
\mathcal{L}^{q(\omega)} \, u(t,\textbf{x};\omega) = F(t,\textbf{x};\omega)
\\
%&
%\mathcal{L}^{q(\omega)} \, = 
%\prescript{}{0}{\mathcal{D}}_{t}^{\alpha(\omega)}
%- \sum_{j=1}^{d} \, k_{j} \,\left[ \prescript{}{a_j}{\mathcal{D}}_{x_j}^{\beta_j(\omega)}
%+ \prescript{}{x_j}{\mathcal{D}}_{b_j}^{\beta_j(\omega)} \right]
%\\
%& 
%F(t,\textbf{x};\omega) = h(t,\textbf{x}) +  f(t;\omega) ,
%%
%\\
\label{Eq: IC}
& u \big\arrowvert_{t=0} = 0 ,  
%
\\
\label{Eq: BC}
& u \big\arrowvert_{x=a_j} = u \big\arrowvert_{x=b_j} = 0 , 
%
\end{align}
%
such that for $\mathbb{P}$-almost everywhere $\omega \in \Omega $ the equation holds. The stochastic fractional operator and force term, are given respectively as:
%
\begin{align}
\label{Eq: Stochastic Fractional Operator}
%
&
\mathcal{L}^{q(\omega)} \, = 
\prescript{}{0}{\mathcal{D}}_{t}^{\alpha(\omega)}
- \sum_{j=1}^{d} \, k_{j} \,\left[ \prescript{}{a_j}{\mathcal{D}}_{x_j}^{\beta_j(\omega)}
+ \prescript{}{x_j}{\mathcal{D}}_{b_j}^{\beta_j(\omega)} \right]
\\
& 
F(t,\textbf{x};\omega) = h(t,\textbf{x}) +  f(t;\omega) ,
%
\end{align}
%
where the fractional indices $\alpha(\omega) \in (0,1)$ and $\beta_j(\omega) \in (1,2), \,\, j=1,2,\cdots d$ are mutually independent random variables, $k_{j}$ are real positive constant coefficients, and the fractional derivatives are taken in the Riemann-Liouville sense. 
We assume that the driving terms $h$ and $f$ are properly posed, such that \eqref{Eq: Stochastic FPDE}-\eqref{Eq: BC} is well-posed $\mathbb{P}$-a.e. $\omega \in \Omega$, and also the solution in physical domain $\mathbb{D}$ is smooth enough such that we can construct a numerical scheme to solve each realization of SFPDE. As an extension to future works, the stochastic operator \eqref{Eq: Stochastic Fractional Operator} can be extended to $\alpha(\omega) \in (1,2)$ for the case of wave equations, and thus applied in formulating fractional models to study complex time-varying nonlinear fluid-solid interaction phenomena \cite{atanackovic2014,afzali2016vibrational,afzali2017analysis} and also the effect of damping in structural vibrations \cite{zamani2015asymmetric}.




%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\subsection{Representation of the Noise: Dimension Reduction}
\label{Sec: Noise}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
We approximate the additional random forcing term by representing $f(t;\omega)$ into its finite dimensional version and thus, reduce the infinite-dimensional probability space to a finite-dimensional space. This is achieved via truncating Karhunen-Lo\`{e}ve (KL) expansion with the desired accuracy\cite{Loeve77}. 

Let $(\Omega, \mathcal{F},\mathbb{P})$ be a complete probability space, where $\Omega$ is the space of events, $\mathcal{F} \subset 2^{\Omega}$ denotes the $\sigma$-algebra of sets in $\Omega$, and $\mathbb{P}$ is the probability measure. The random field $f(t;\omega)$ has the ensemble mean $\mathbb{E}\{f(t; \omega)\} = \bar{f}(t)$, finite variance $\mathbb{E}\{ [f(t; \omega) - \bar{f}(t; \omega)]^2\}$ and covariance $C_f( t_1, t_2) = \mathbb{E}\{ [f(t_1; \omega) - \bar{f}(t_1; \omega)] [f(t_2; \omega) - \bar{f}(t_2; \omega)]\}$.  The KL expansion of $f(t; \omega)$ takes the form  
%
%
\begin{align}
\label{KL}
f(t;\omega) = \bar{f}(t; \omega) + \sum_{k=1}^\infty \sqrt{\lambda_k} \, \psi_k(t) \, Q_k(\omega),
%
\end{align}
%
where $\boldsymbol Q(\omega) = \lbrace Q_k(\omega) \rbrace \big|_{k=1}^{k=\infty}$ is a set of mutually uncorrelated random variables with zero mean and unit variance, while $\psi_k(t)$ and $\lambda_k$ are the eigenfunction and eigenvalues of the covariance kernel $C_f(  t_1, t_2 )$. 
%
We obtain the covariance kernel $C_f$ and its eigenvalues and eigenfunctions, following~\cite{Su06} and by solving a stochastic Helmholtz equation
%
\begin{equation}
%
\label{Helmholtz_roughness}
\triangle f(t; \omega) - m^2 f(t; \omega) = g( t;\omega),
%
\end{equation}
%
where the random forcing $g(t;\omega)$ is a white-noise process with zero mean and unit variance. The eigenvalues and eigenvectors of~\eqref{Helmholtz_roughness} form a Fourier series, so that the KL expansion~\eqref{KL} is replaced with its sine Fourier series version
%
\begin{equation}
%
\label{Fourier_KL}
f(t;\omega) =\bar{f}(t; \omega) +  \sum_{k=1}^\infty \, a_k \, \sin\left(\frac{2 k \pi \, t}{T}\right) \, Q_k(\omega),
%
\end{equation}
%
in which the random variables $Q_k(\omega)$ are chosen to be \textit{uniformly} distributed with probability density function $\rho_k(q_k)$. $T$ is the length of the process along the $t$-axis, and the coefficients
%
\begin{equation}
%
\label{a_k}
a_k =   \frac{2}{\sqrt T \ell^2} \left[ 1 + \left(\frac{2\pi k}{T\ell} \right)^2 \right]^{-1},
%
\end{equation}
%
where $\ell =T/A$ and $A$ is the correlation length of $f(\mathbf x;\omega)$. To ensure that the random variables $Q_k(\omega)$ have zero mean and unit variance, we define them on $Q_k(\omega) \in [-\sqrt 3, \sqrt 3]$. We note that this process is consistent to the zero-Dirichlet initial condition given in \eqref{Eq: IC}. Next, in order to render~\eqref{Fourier_KL} computable, we truncate the infinite series with a prescribed ($\approx 90\%$) fraction of the energy of the process, following the finite-dimensional noise assumption in stochastic computations. To this end, we set $T=1$, the correlation length $A=T/2$, and consider only the first four terms in the KL expansion. Let  $f_M(t;\omega) = \frac{1}{\mu} \, \sum_{k=1}^M \, a_k \, \sin\left(\frac{2 k \pi \, t}{T}\right) \, Q_k(\omega)$ denote the normalized truncated expansion, assuming $\bar{f}_M(t;\omega)=0$, where $\mu = \max_{t} \big\lbrace \sigma[f_M(t;\omega)] \big\rbrace$ and $\sigma_{f_M}$ is the standard deviation of $f_M(t;\omega)$. Thus, we represent the random process to be employed in \eqref{Eq: Stochastic FPDE} as
%
\begin{equation}
%
f(t;\omega) = \epsilon f_M(t;\omega)
%
\end{equation}
%  
where $\epsilon$ is the amplitude of process. 

Therefore, the formulation of SFPDE ~\eqref{Eq: Stochastic FPDE} can be posed as follows: Find $u(t,\textbf{x};\omega): \mathbb{D}\times \Omega \rightarrow \mathbb{R}$ such that $\forall  t,\textbf{x} \in \mathbb{D}$  
%
\begin{align}
\label{Doob_momentum-1}
%
\prescript{}{0}{\mathcal{D}}_{t}^{\alpha(\omega)} u(t,\textbf{x};\omega) 
& - \sum_{j=1}^{d} \, k_{j} \,\left[ \prescript{}{a_j}{\mathcal{D}}_{x_j}^{\beta_j(\omega)}
+ \prescript{}{x_j}{\mathcal{D}}_{b_j}^{\beta_j(\omega)} \right]
u(t,\textbf{x};\omega) 
= h(t,\textbf{x}) +  f(t;Q_1(\omega) , Q_2(\omega) , \cdots , Q_M(\omega)) 
%
\end{align}
%
holds $\mathbb{P}$-a.s. for $\omega \in \Omega$, subject to the homogeneous initial and boundary conditions.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\subsection{Input Parametrization}
\label{Sec: Input Parametrization}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
Let $Z: \Omega \rightarrow \mathbb{R}^{\mathcal{N}}$ be the set of $\mathcal{N} = 1+d+M$ independent random parameters, given as
%
\begin{align*}
%
Z = \Big\lbrace \,  Z_i \, \Big\rbrace_{i=1}^{\mathcal{N}} 
= \Big\lbrace \, 
\alpha(\omega) , \beta_1(\omega) , \beta_2(\omega) , \cdots , \beta_d(\omega) , Q_1(\omega) , Q_2(\omega) , \cdots , Q_M(\omega) 
\, \Big\rbrace
%
\end{align*}
%
with probability density functions $\rho_i : \Gamma_i \rightarrow \mathbb{R}, \, i=1,2,\cdots,\mathcal{N}$, where their images $\Gamma_i \equiv Z_i(\Omega)$ are bounded intervals in $\mathbb{R}$. The joint probability density function (PDF) 
%
\begin{align}
%
\rho(\boldsymbol \xi) = \prod_{i=1}^{\mathcal{N}} \rho_i(Z_i), \quad \forall \boldsymbol{\xi} \in \Gamma
%
\end{align}
%
with the support $\Gamma = \prod_{i=1}^{\mathcal{N}} \Gamma_{i} \subset \mathbb{R}^{\mathcal{N}}$ constitutes a mapping of the sample space $\Omega$ onto the target space $\Gamma$. Therefore, a random vector $\boldsymbol \xi = (\xi_1, \xi_2,\ldots,\xi_{\mathcal{N}}) \in \Gamma $ denote an arbitrary point in the parametric space. 

According to the Doob-Dynkin lemma~\cite{Oksendal98}, the solution $u(t,\textbf{x};\omega)$ can be expressed as $u(t,\textbf{x};\boldsymbol \xi)$, which provides a very useful tool to work in the target space rather than the abstract sample space. Thus, the formulation of SFPDE ~\eqref{Eq: Stochastic FPDE} can be posed as: Find $u(t,\textbf{x};\boldsymbol\xi): \mathbb{D}\times \Gamma \rightarrow \mathbb{R}$ such that $\forall  t,\textbf{x} \in \mathbb{D}$    
%
\begin{align}
\label{Doob_momentum-2}
%
\prescript{}{0}{\mathcal{D}}_{t}^{\alpha(\boldsymbol{\xi})} u(t,\textbf{x};\boldsymbol{\xi}) 
& - \sum_{j=1}^{d} \, k_{j} \,
\left[ \prescript{}{a_j}{\mathcal{D}}_{x_j}^{\beta_j(\boldsymbol{\xi})}
+ \prescript{}{x_j}{\mathcal{D}}_{b_j}^{\beta_j(\boldsymbol{\xi})} 
\right]
u(t,\textbf{x};\boldsymbol{\xi}) 
= h(t,\textbf{x}) +  f(t;\boldsymbol{\xi}) 
%
\end{align}
%
holds $\rho$-a.s. for $\boldsymbol\xi(\omega) \in \Gamma$ and $\forall  t,\textbf{x}\in \mathbb{D}$, subject to proper initial and boundary conditions. 




%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Stochastic Sampling}
\label{Sec: Stochastic Discretization}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
We expound the two sampling methods, MCS and PCM to sample from random space and, then propagate the associated uncertainties by computing the statistics of stochastic solutions via post processing. 


\vspace{0.1 in}
\textbf{Monte Carlo Sampling: MCS.}
The general procedure in statistical Monte Carlo sampling is the three following steps.
%
\begin{enumerate}
	\item Generating a set of random variables $\boldsymbol{\xi}_i$, $i = 1,2 , \cdots,K$ for a prescribed number of realizations $K$.
	
	\item Solving the deterministic problem \eqref{Doob_momentum-2} and obtaining the solution $u_i = u(t,\textbf{x};\boldsymbol{\xi}_i)$ for each $i = 1,2 , \cdots,K$.
	
	\item Computing the solution statistics, e.g. $\mathbb{E}[u] = \frac{1}{M} \sum_{i=1}^{M} u_i$.
	
\end{enumerate}
%
We note that step 1 and 3 are pre- and post- processing steps, respectively. Step 2 requires repetitive simulation of deterministic counterpart of the problem, which we obtain by developing a Petrov-Galerkin spectral method in the physical domain. Although MCS is relatively easy to implement once a deterministic forward solver is developed, it requires too many samplings for the solution statistics to converge, and yet the extra numerical cost due to non-locality and memory effect in fractional operators are still remained. In addition, the number of required sampling also grows rapidly as the dimension of problem increases, resulting in an exhaustively long run time for the statistics to converge.
%


\vspace{0.1 in}
\textbf{Probability Collocation Method: PCM.}
We employ a high-order stochastic discretization in the random space following \cite{xiu2005, Foo08} in order to construct a probabilistic collocation method (PCM), which yields a high convergence rate with much fewer number of sampling. The idea of PCM is based on polynomial interpolation, however in the random space. Let $\Theta_\mathcal{N} = \big\{ \, \xi_i \, \big\}_{i=1}^{\mathcal{J}}$ be a set of prescribed sampling points. By employing the Lagrange interpolation polynomials $L_i$, the polynomial approximation $\mathcal{I}$ of
%a general smooth function, $f : \mathbb{R}^{\mathcal{N}} \rightarrow \mathbb{R}$ 
the stochastic solution $u$ in the random space can be expressed as: 
%
\begin{equation}
\label{Eq: Lagrange Int}
%
\hat{u}(t,\textbf{x}; \boldsymbol \xi)  =
\mathcal{I}u(t,\textbf{x}; \boldsymbol \xi) 
%\equiv \mathcal{L}^{\mathcal{P}} u(t,\textbf{x}; \boldsymbol \xi)
= \sum_{i=1}^{\mathcal{J}} u(t,\textbf{x}; \xi_i)L_i(\boldsymbol{\xi}).
%
\end{equation}
%
Therefore, the collocation procedure of solving \eqref{Doob_momentum-2} to obtain the stochastic solution $u$ is:

%
\begin{align}
\label{Eq: PCM formulation}
%
R \left( \hat{u}(t,\textbf{x};\boldsymbol{\xi}) \right) \Big|_{\xi_i} 
= 
\left(
\mathcal{L}^{q(\boldsymbol{\xi})} \, \hat{u}(t,\textbf{x};\boldsymbol{\xi})) - F(t,\textbf{x};\boldsymbol{\xi}) 
\right)\Big|_{\xi_i}  = 0 \quad i =1,2,\cdots,\mathcal{J},
%
\end{align}
%
where $\mathcal{L}^{q}$ is given in \eqref{Eq: Stochastic Fractional Operator}. By using the property of Lagrange interpolants that satisfy the Kronecker delta at the interpolation points, we obtain:
%
\begin{align}
\label{Eq: PCM formulation-2}
%
\mathcal{L}^{q(\xi_i)} \, u(t,\textbf{x};\boldsymbol{\xi})) 
= F(t,\textbf{x};\boldsymbol{\xi}),
\quad i =1,2,\cdots,\mathcal{J},
%
\end{align}
%
subject to proper initial/boundary conditions. Thus, the probabilistic collocation procedure is equivalent to solving $\mathcal{J}$ deterministic problems \eqref{Eq: PCM formulation-2} with conditions \eqref{Eq: IC} and \eqref{Eq: BC}. Once the deterministic solutions are obtained at each sampling point, the numerical stochastic solution is interpolated, using \eqref{Eq: Lagrange Int}  to construct a global approximate $\hat{u} (t,\textbf{x}; \boldsymbol \xi)$. We then obtain the solution statistics as  
%
\begin{align}
\label{Eq: Expectation STD}
%
\mathbb{E}[u] = \int_{\Gamma} \hat{u} (t,\textbf{x}; \boldsymbol \xi) \, \rho(\boldsymbol \xi)  \, \mathrm d \boldsymbol \xi ,
\quad
\sigma[u] =\sqrt{\mathbb{E}[ \hat{u}^2 ] -   \mathbb{E}[\hat{u}]^2 }.
%
\end{align}
% 
The above integrals can be computed efficiently by letting the interpolation/collocation points to be the same as a set of cubature rules $\Theta_\mathcal{N} = \big\{ \, \xi_i \, \big\}_{i=1}^{\mathcal{J}}$ on the parametric space with integration weights $\{\mathbf{w}_i\}_{i=1}^{\mathcal{J}}$, which are employed in computing the integral. By property of Kronecker delta of Lagrange interpolant and use of any quadrature rule over the above integral yields 
%
\begin{equation}
\label{Eq: Exp Approx}
\mathbb{E}[u(t,\textbf{x}:\boldsymbol{\xi})] 
\approx 
\sum_{i=1}^{\mathcal{J}} \, w_i \,u(t,\textbf{x};\xi_i).  
\end{equation}
% 



\vspace{0.1 in}
\textbf{Choice of Collocation/Interpolation Points.}
%
A natural choice of the sampling points is the tensor-product of one-dimensional sets, which is efficients for low-dimensional random spaces. However, in high-dimensional multivariate case, where $\mathcal{N} > 6$, the tensor-product interpolation operators are computationally expensive due to the increasing nested summation loops. In addition, the total number of sampling points grows rapidly by increase of dimension by $\mathcal{J}^\mathcal{N}$, where $\mathcal{J}$ is the number of points in each direction.

Another choice that provides an alternative to the more costly full tensor product rule is the isotropic Smolyak sparse grid operator $A(w , \mathcal{N})$~\cite{Smolyak63,nobile2008sparse} with two input parameters dimension size $\mathcal{N}$ and the level of grid $w$. The Smolyak algorithm significantly reduces the total number of sampling points; see Fig.\ref{Fig: Grids} for comparison of $A(2,2)$, $A(4,2)$, and $A(6,2)$ with full tensor product rule for a two-dimensional random spaces. The total number of sampling points for each case is also listed in Table \ref{Table: number of sparse nodal points}. More research has also been devoted to the analysis and construction of Smolyak sparse grids \cite{xiu2005,barthelmann2000high,novak1999simple,novak1996high}. 


%
%******************************************************************************************
%
\begin{figure}[t]
	\centering
	\begin{subfigure}{0.22\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{Sparse-N2-W2.pdf}
		\caption{}
		%\label{Fig:}
	\end{subfigure}
	%
	\begin{subfigure}{0.22\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{Sparse-N2-W4.pdf}
		\caption{}
		%\label{Fig:}
	\end{subfigure}
	%
	\begin{subfigure}{0.22\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{Sparse-N2-W6.pdf}
		\caption{}
		%\label{Fig:}
	\end{subfigure}
	%
	\begin{subfigure}{0.22\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{Full-Tensor.pdf}
		\caption{}
		%\label{Fig:}
	\end{subfigure}
	\caption{Illustration of sampling nodal points in two-dimensional random space, using Smolyak sparse grid generator (a) $\, A(2,2)$, (b) $\, A(4,2)$ ,(c) $\, A(6,2)$; and (d) full tensor product rule with 50 points in each direction. The total number of points in each case is, 25, 161, 837, and 2500, respectively. }
	\label{Fig: Grids}
\end{figure}
%
%****************************************************************************************** 
%




\begin{table}[h]
	\centering
	\caption{\label{Table: number of sparse nodal points} The total number of nodal points in random space sampling, using Smolyak sparse grid generator and full tensor product with 10 points in each direction.}
	\label{my-label}
	\begin{tabular}{|c||c||c cccc}
		\hline
		Space dimensionality & Full tensor product & \multicolumn{5}{c|}{Smolyak sparse grid generator $A(w,\mathcal{N})$} \\ 
		\hline\hline
		$\mathcal{N}$ &  & \multicolumn{1}{c}{$w=2$} & \multicolumn{1}{c}{$w=4$} & \multicolumn{1}{c}{$w=6$} & \multicolumn{1}{c}{$w=8$}  & \multicolumn{1}{c|}{$w=10$}    \\ \hline
		2 & $10^2$ & \multicolumn{1}{c|}{25} & \multicolumn{1}{c|}{161} & \multicolumn{1}{c|}{837} & \multicolumn{1}{c|}{4105} & \multicolumn{1}{c|}{19469}   \\ \hline
		5 & $10^5$ & \multicolumn{1}{c|}{131} & \multicolumn{1}{c|}{3376} & \multicolumn{1}{c|}{45458} & \multicolumn{1}{c|}{440953} & \multicolumn{1}{c|}{3542465} \\ \hline
		15& $10^{15}$ & \multicolumn{1}{c|}{1066} & \multicolumn{1}{c|}{197176} & \multicolumn{1}{c|}{15480304} &  & \\ \cline{1-5}
		25& $10^{25}$ & \multicolumn{1}{c|}{2901} & \multicolumn{1}{c|}{1445975} &  &  &  \\ \cline{1-4}
		55& $10^{55}$ & \multicolumn{1}{c|}{87780} &  &  &   &  \\ \cline{1-3}
	\end{tabular}
\end{table}










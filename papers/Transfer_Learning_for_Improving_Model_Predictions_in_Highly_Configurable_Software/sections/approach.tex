%!TEX root = ../paper.tex
\section{Cost-Aware Transfer Learning}
\label{sec:approach}

In this section, we explain our \emph{cost-aware transfer learning} solution to improve learning an accurate performance model.

\subsection{Solution overview}

An overview of our model learning methodology is depicted in Figure~\ref{fig:prediction-tl}. We use the observations that we can obtain cheaply, with the cost of $c_s$ for each sample, from an alternative measurable response function, $g(\cdot)$, that yields different but related response to the target response, $\mathcal{D}_s=\{(\mathbf{x}_s,y_s)|y_s=g(\mathbf{x}_s)+\epsilon_s, \mathbf{x}_s\in \mathbb{X}\}$, and transfer these observations to learn a performance model for the real system using only few observations from that system, $\mathcal{D}_t=\{(\mathbf{x}_t,y_t)|y_t=f(\mathbf{x}_t)+\epsilon_t, \mathbf{x}_t\in \mathbb{X}\}$.
The cost of obtaining each observation on the target system is $c_t$, and we assume that $c_s\ll c_t$ and that the source response function, $g(\cdot)$, is related (correlated) to the target function, and this relatedness contributes to the learning of the target function, using only sparse samples from the real system, \emph{i.e.}, $|\mathcal{D}_t|\ll |\mathcal{D}_s|$. Intuitively, rather than starting from scratch, we transfer the learned knowledge from the data we have collected using cheap methods such as simulators or previous system versions, to learn a more accurate model about the target configurable system and use this model to reason about its performance at runtime.
%The relatedness of the source and target response functions may appear in different forms. Figure~\ref{fig:fg} shows possible relationships in terms of (i) translation, (ii) noise, and (iii) discrepancies in boundaries.

\begin{figure}[t]
	\begin{center}
		\includegraphics[width=\columnwidth]{figures/tl-model-learning1}
		\caption{Overview of cost-aware transfer learning methodology.} %The learning process is based on a small subset of the overall configuration space that samples are taken from different sources and target.
		%Our methodology enables appropriate selection of samples from sources and target that gives the highest accuracy while satisfying budget.} %Subsequently, the predictive model can predict performance of an unseen configuration depending on its parameters.}
		\label{fig:prediction-tl}
	\end{center}
\end{figure}


In Figure~\ref{fig:example-synthetic}, we demonstrate the idea of transfer learning with a synthetic example. Only three observations are taken from a synthetic target function, $f(\cdot)$, and we try to learn a model, $\hat{f}(\mathbf{x})$, which provides predictions for unobserved response values at some input locations. Figure \ref{fig:example-synthetic}(b) depicts the predictions that are provided by the model trained using only the 3 samples without considering the transfer learning from any source. The predictions are accurate around the three observations, while highly inaccurate elsewhere. Figure \ref{fig:example-synthetic}(c) depicts the model trained over the 3 observations and 9 other observations from a different but related source. The predictions, thanks to transfer learning, are here closely following the true function with a narrow confidence interval (\emph{i.e.}, high confidence in predictions provided by the model). Interestingly, the confidence interval around points $\mathbf{x}=2,4$ in the model with transfer learning have disappeared, demonstrating more confident predictions with transfer learning.

Given a target environment, the effectiveness of any transfer learning depends on the source environment and how it is related to the target \cite{torrey2009transfer}. If the relationship is strong and the transfer learning method can take advantage of it, the performance in the target predictions can significantly improve via transfer. However, if the source response is not sufficiently related or if the transfer method does not exploit the relationship, the performance may not improve or even may decrease. We show this case via the synthetic example in Figure \ref{fig:example-synthetic}(d) where the prediction model uses 9 samples from a misleading function that is unrelated to the target function (the response remains constant as we increase $\mathbf{x}$); as a consequence, the predictions are very inaccurate and do not follow the growing trend of the true function. %Also the confidence interval is sharply increasing as we go further away from the the observations.

\begin{figure}[t]
	\begin{center}
		\includegraphics[width=\columnwidth]{figures/tl_example_synthetic-2}
		\caption{(a) 9 samples have been taken from a source (respectively 3 from a target); (b) [without transfer learning] a regression model is constructed using only the target samples. (c) [with transfer learning] another regression model is constructed using the target and the source samples. The new model is based on only 3 target measurements while providing accurate predictions. (d) [negative transfer] a regression model is constructed with a transfer from a misleading response function and therefore the model prediction is inaccurate.}
		\label{fig:example-synthetic}
	\end{center}
\end{figure}


%\begin{figure}[h]
%	\begin{center}
%		\includegraphics[width=\columnwidth]{figures/task_relatedness}
%		\caption{Two strategies for sampling sources: (a) choose a source response from which to transfer, (b) use the knowledge of how related the sources are to the target.}
%		\label{fig:task_relatedness}
%	\end{center}
%\end{figure}

For the choice of the number of samples from the source and target, we use a simple \emph{cost model} (cf. Figure \ref{fig:prediction-tl}) that is based on the number of source and target samples as follows:
\begin{align} \label{eq:cost-model}
\mathcal{C}(\mathcal{D}_s,\mathcal{D}_t)&=c_s\cdot |\mathcal{D}_s|+c_t \cdot |\mathcal{D}_t|+\mathcal{C}_{Tr}(|\mathcal{D}_s|,|\mathcal{D}_t|), \\
\mathcal{C}(\mathcal{D}_s,\mathcal{D}_t)&\le\mathcal{C}_{max},  \label{eq:cost-constraint}
\end{align}
where $\mathcal{C}_{max}$ is the experimental budget and $\mathcal{C}_{Tr}(|\mathcal{D}_s|,|\mathcal{D}_t|)$ is the cost of model training, which is a function of source and target sample sizes.
Note that this cost model makes the problem we have formulated in Eq. \eqref{eq:objective} into a multi-objective problem, where not only \emph{accuracy} is considered, but also \emph{cost} can be considered in the transfer learning process.


%\begin{figure*}[t]
%	\begin{center}
%		\includegraphics[width=\textwidth]{figures/fg}
%		\caption{Relationships between source and target response functions: (a) source is highly correlated with the target function but shifted or linearly skewed, (b) contain noise, (c) have discrepancies towards the boundaries, or (d) uncorrelated.}
%		\label{fig:fg}
%	\end{center}
%\end{figure*}




%\begin{figure}
%	\begin{center}
%		\includegraphics[width=0.7\columnwidth]{figures/pareto-synthetic-annotated}
%		\caption{Indifference curves representing combinations of $(|\mathcal{D}_t|,|\mathcal{D}_t|)$ associated with equal levels of prediction errors.}
%		\label{fig:pareto-synthetic}
%	\end{center}
%\end{figure}


\subsection{Model learning: Technical details}
\label{sec:gp}

We use Gaussian Process (GP) models to learn a reliable performance model $\hat{f}(\cdot)$ that can predict unobserved response values. The main motivation to choose GP here is that it offers a framework in which performance reasoning can be done using mean estimates as well as a confidence interval for each estimation. In other words, where the model is confident with its estimation, it provides a small confidence interval; on the other hand, where it is uncertain about its estimations it gives a large confidence interval meaning that the estimations should be used with precautions. The other reason is that all the computations are based on linear algebra which is cheap to compute. This is especially useful in the domain of self-adaptive systems where automated performance reasoning in the feedback loop is typically time constrained and should be robust against any sort of uncertainty including prediction errors. Also, for building GP models, we do not need to know any internal details about the system; the learning process can be applied in a black-box fashion using the sampled performance measurements. In the GP framework, it is also possible to incorporate domain knowledge as prior, if available, which can enhance the model accuracy \cite{jamshidi2016bo4co}.

In order to describe the technical details of our transfer learning methodology, let us briefly describe an overview of GP model regression; a more detailed description can be found elsewhere \cite{gpml}. GP models assume that the function $\hat{f}(\mathbf{x})$ can be interpreted as a probability distribution over functions:
\begin{equation} \label{eq:gp}
\mathbf{y}=\hat{f}(\mathbf{x}) \sim \mathcal{GP} (\mu(\mathbf{x}), k(\mathbf{x}, \mathbf{x}')),
\end{equation}
where $\mu:\mathbb{X}\rightarrow\mathbb{R}$ is the mean function and $k:\mathbb{X}\times\mathbb{X}\rightarrow\mathbb{R}$ is the covariance function (kernel function) which describes the relationship between response values, $\mathbf{y}$, according to the \emph{distance} of the input values $\mathbf{x},\mathbf{x}'$.
%Let us assume $\mathcal{D}=\{(\mathbf{x}_{i},y_{i}) | y_i:=f(\mathbf{x}_i)+\epsilon_i,i=1,\cdots,t\}$ be the collection of $t$ observations.
The mean and variance of the GP model predictions can be derived analytically \cite{gpml}:
\begin{align}
\mu_{t}(\mathbf{x})&=\mu(\mathbf{x})+\mathbf{k}(\mathbf{x})^\intercal (\mathbf{K}+\sigma^2\mathbf{I})^{-1} (\mathbf{y}-\boldsymbol{\mu}), \label{eq:gp-surrogate-mean}\\
\sigma_t^2(\mathbf{x})&=k(\mathbf{x},\mathbf{x})+\sigma^2\mathbf{I} - \mathbf{k}(\mathbf{x})^\intercal (\mathbf{K}+\sigma^2\mathbf{I})^{-1} \mathbf{k}(\mathbf{x}), \label{eq:gp-surrogate-sigma}
\end{align}
where $\mathbf{k}(\mathbf{x})^\intercal=[k(\mathbf{x},\mathbf{x}_1) \quad k(\mathbf{x},\mathbf{x}_2) \quad \dots \quad k(\mathbf{x},\mathbf{x}_t)]$, $\mathbf{I}$ is identity matrix and
\begin{equation} \label{eq:covariance}
\mathbf{K}:=
\begin{bmatrix}
k(\mathbf{x}_1,\mathbf{x}_1)  &  \dots & k(\mathbf{x}_1,\mathbf{x}_t)   \\
\vdots  & \ddots &  \vdots \\
k(\mathbf{x}_t,\mathbf{x}_1)  &  \dots & k(\mathbf{x}_t,\mathbf{x}_t)
\end{bmatrix}
\end{equation}

%In order to intuitively demonstrate the GP model predictions, we illustrate it through a one dimensional model in Figure \ref{fig:example-gp}. In the figure, the true function we try to predict using GP model, the mean estimation and the confidence interval at each point, cf. \eqref{eq:gp-surrogate-mean} and \eqref{eq:gp-surrogate-sigma}, and the observations are shown. Parts of the response function that is well explored (\emph{i.e.}, we have observations for) has small confidence interval, \emph{i.e.}, the variance of the predictions around those points are low. On the other hand, the parts of the space that are now well explored, the model is not confident enough with respect to the mean estimates and therefore the variances are high.

%\begin{figure}
%	\begin{center}
%		\includegraphics[width=0.73\columnwidth]{figures/gp-example2}
%			\caption{An example of one-dimensional GP model. Stars indicate the location of the data. The GP estimations, shown in red, runs along the means of the normally distributed confidence intervals shown in red shades. } %The solid green line is the mean prediction given the data, and the shaded grey area shows the confidence interval.}
%		\label{fig:example-gp}
%	\end{center}
%\end{figure}
GP models have shown to be effective for performance predictions in data scarce domains \cite{jamshidi2016bo4co}. However, as we have demonstrated in Figure \ref{fig:example-synthetic}, it may become inaccurate when the samples do not cover the space uniformly. For highly configurable systems, we require a large number of observations to cover the space uniformly, making GP models ineffective in such situations.

\subsection{Model prediction using transfer learning}
\label{sec:tl}


%We assume the existence of different sources $T$ (usually $T=2$ representing one source and one target) and the existence of training data associated with the sources as $\mathcal{D}=\{(\mathbf{x}^{j}_{i},y^j_{i})| y^j_{i}=f^j(\mathbf{x}_i)+\epsilon^j_i, j=1,\dots,T,i=1,\dots,t^j\}$, where $y^j_{i}$ is the observed response for the $j$th source on the $i$th input $\mathbf{x}^{j}_{i}$ representing the configuration under which the measurements are taken from the $j$th source. More specifically, we consider $t^j$ measurements are taken from the related source $j$ imposing a cost of $c_j$ for each sample. Without loss of generality, we assume $j=1$ is the target response. In order to associate the observations $(\mathbf{x}^{j}_{i},y^j_{i})$ to task $j$ a label $l^j=j$ is used.

%Now the critical part is how to learn from different samples that come from different sources to train a GP model. Note that the samples from different sources each construct a different response function, $f^j(\cdot)$ (see the definition of $\mathcal{D}$), that is totally different from other sources and the target function thus we cannot simply put them altogether as if they come the same source and train the GP model then. But in this work we assume that relevant sources are correlated with the target function (cf. Figure \ref{fig:fg}).
%For transfer learning, we assume the existence of different sources $T$ (usually $T=2$ representing one source and one target). Here, we intend to adapt the GP model learning that we presented in the previous section to exploit this relatedness between the sources and the target and learn a GP model that is more accurate than the one that is trained only on the target samples.

In transfer learning, the key question is how to make accurate predictions for the target environment using observations from other sources, $\mathcal{D}_s$. We need a measure of relatedness not only between input configurations but between the sources as well. The relationships between input configurations was captured in the GP models using the covariance matrix that was defined based on the kernel function in Eq. \eqref{eq:covariance}. More specifically, a kernel is a function that computes a dot product (a measure of ``similarity'') between two input configurations. So, the kernel helps to get accurate predictions for similar configurations. We now need to exploit the relationship between the source and target functions, $g,f$, using the current observations $\mathcal{D}_s,\mathcal{D}_t$ to build the predictive model $\hat{f}$.
To capture the relationship, we define the following kernel function:
\begin{align}
\label{eq:mt-kernel}
k(f,g,\mathbf{x},\mathbf{x}')=k_t(f,g)\times k_{xx}(\mathbf{x},\mathbf{x}'),
\end{align}
where the kernels $k_t$ represent the correlation between source and target function, while $k_{xx}$ is the covariance function for inputs. Typically, $k_{xx}$ is parameterized and its parameters are learned by maximizing the marginal likelihood of the model given the observations from source and target $\mathcal{D}=\mathcal{D}_s\cup\mathcal{D}_t$. Note that the process of maximizing the marginal likelihood is a standard method \cite{gpml}.
After learning the parameters of $k_{xx}$, we construct the covariance matrix exactly the same way as in Eq. \ref{eq:covariance} and derive the mean and variance of predictions using Eq. \eqref{eq:gp-surrogate-mean}, \eqref{eq:gp-surrogate-sigma} with the new $\mathbf{K}$. The main essence of transfer learning is, therefore, the kernel that captures the source and target relationship and provides more accurate predictions using the additional knowledge we can gain via the relationship between source and target.


%Note that $k_t$ depends only on the labels ${j}$ pointing to the versions for which we have some observations, and $k_{xx}$ depends only on the configuration $\mathbf{x}$.
%More specifically, we normalize $k_t$ to be a correlation matrix, so that it has ones along its diagonal. Then the extent of relatedness between any source and target is measured by their correlation. This matrix can be extended accordingly to accommodate for multiple sources, but here we assume we have one source.


%Figure \ref{fig:example-synthetic}(c) illustrates the predictions provided by an updated GP model using this idea. Further observations are available on another related source, whereas we only have few samples on the target function. Merely using these few samples would result in poor (uninformative) predictions. Using the correlation with the other two functions enables the GP model to provide more accurate predictions with a much higher confidence throughout estimations.

\subsection{Transfer learning in a self-adaptation loop}

Now that we have described the idea of transfer learning for providing more accurate predictions, the question is whether such an idea can be applied at runtime and how the self-adaptive systems can benefit from it. More specifically, we now describe the idea of model learning and transfer learning in the context of self-optimization, where the system adapts its configuration to meet performance requirements at runtime. The difference to traditional configurable systems is that we learn the performance model online in a feedback loop under time and resource constraints. Such performance reasoning is done more frequently for self-adaptation purposes. %For example, such models can be applied to change the configuration of a robot to consume less energy (\emph{e.g.}, swap the current localization with a less demanding one) to finish its mission in the situation where under the current configuration it will run out of the battery.

An overview of a self-optimization solution is depicted in Figure \ref{fig:mape-ke} following the MAPE-K framework~\cite{de2013software,kephart2003vision}. We consider the regression model that we learn via transfer learning in this work as the \underline{K}nowledge component of the MAPE-K that acts as an interface to which other components can query the performance. %We use transfer learning to make the knowledge more accurate using observations that are taken from a simulator or any other cheap sources. 
For deciding how many observations and from what source to transfer, we use the cost model that we have introduced earlier. At runtime, the managed system is \underline{M}onitored by pulling the end-to-end performance metrics (\emph{e.g.}, latency, throughput) from the corresponding sensors. Then, the retrieved performance data needs to be \underline{A}nalysed. Next, the model needs to be updated taking into account the new performance observations. Having updated the model, a new configuration may be \underline{P}lanned to replace the current configuration. Finally, the new configuration will be enacted by \underline{E}xecuting platform specific operations. This enables model-based knowledge evolution using machine learning~\cite{jamshidi2016managing}. 

The underlying model can be updated not only when a new observation is available but also by transferring the learning from other related sources. So at each adaptation cycle, we can update our belief about the correct response given data from the managed system and other related sources. This can be particularly useful when the adaptive systems need to make a decision when the internal knowledge utilized in the MAPE-K loop is not accurate enough, \emph{e.g.}, in early stages of learning when the system needs to react to environmental changes the internal knowledge is not accurate and as a result the adaptation decisions are sub-optimal \cite{jamshidi2016fuzzy}. In this situation, even the measurements from a noisy source (\emph{e.g.}, simulator) could be beneficial in order to boost the initial performance achievable using only the transferred knowledge, before any further learning is done. Also, another challenge that has been reported in the past is the slow convergent of the learning process \cite{jamshidi2016fuzzy}, in this situation, transfer learning can accelerate the learning process in the target environment given the transferred knowledge compared to the amount of time to learn it from scratch. %In this situation, the transfer can also be done from multiple sources with different degrees of relatedness to the target (\emph{e.g.}, different simulators with different level of fidelity).

%Note that in the adaptation process a configuration may fail, cf. Section \ref{sec:problem}. In this situation, we need an approach that learns this over time and avoid trying the configuration that may most probably will fail in a certain situation. More specifically, we can learn a classifier that approximates a constrain function, $c(\cdot)$, that has been discussed in Section \ref{sec:problem}. Therefore, at runtime, when the classifier predict that with a high chance the configuration will fail, we may want to avoid changing the current configuration to the new one but to the one that may provide a slightly lower performance but with a less chance of failure.


\begin{figure}[t]
	\begin{center}
		\includegraphics[width=\columnwidth]{figures/mape-ke-tl-1}
		\caption{Integrating transfer learning with MAPE-K loop, where knowledge update is realized with transfer learning.}
		\label{fig:mape-ke}
	\end{center}
\end{figure}

%!TEX root = ../paper.tex
\section{Introduction}
\label{sec:introduction}

Most software systems today are configurable, which gives end users, developers, and administrators the chance to customize the system to achieve a different functionality or tune its performance. In such systems, hundreds or even thousands of configuration parameters can be tweaked, making the system highly configurable~\cite{influence}. The exponentially growing configuration space, complex interactions, and unknown constraints among configuration options make it difficult to understand the performance of the system. As a consequence, many users rely on default configurations or they change only individual options in an ad-hoc way.

In this work, we deal with the type of configurable systems that operate in dynamic and uncertain environments (\emph{e.g.}, robotic systems). Therefore, it is desirable to react to environmental changes by tuning the configuration of the system when we anticipate that the performance will drop to an undesirable level. To do so, we use black-box performance models that describe how configuration options and their interactions influence the performance of a system (\emph{e.g.}, execution time). Black-box performance models are meant to ease understanding, debugging, and optimization of configurable systems~\cite{influence}. For example, a reasoning algorithm may use the learned model in order to identify the best performing configuration for a robot when it goes from indoor to an outdoor environment. % (as a result the configuration options regarding localizations may be adapted).

\begin{figure}[t]
	\begin{center}
		\includegraphics[width=0.7\columnwidth]{figures/tl-overview2}
		\caption{Transfer learning for performance model learning.}
		\label{fig:overview}
	\end{center}
\end{figure}

Typically, we learn a performance model for a given configurable system by measuring from a set of configurations selected by some sampling strategy. That is, we measure the performance of a given system multiple times in different configurations and learn how the configuration options and their interactions affect performance. However, such a way of learning from real systems, whether it is a robot or a software application, is a difficult task for several reasons: (i)~environmental changes (\emph{e.g.}, people wandering around robots), (ii)~high costs or risks of failure (\emph{e.g.}, a crashed robot), (iii)~the large amount of time required for measurements (\emph{e.g.}, we have to repeat the measurements several times to get a reliable value), and (iv)~changing system dynamics (\emph{e.g.}, robot motion). Moreover, it is often not possible to create potentially important scenarios in the real environment.

In this paper, as depicted in \figref{overview}, we propose a different solution: instead of taking the measurements from the real system, we reuse prior information (that we can get from other sources at a lower cost) in order to learn a performance model for the real system faster and cheaper. The concept of reusing information from other sources is the idea behind \emph{transfer learning}~\cite{torrey2009transfer,pan2010survey}. Similar to human beings that can learn from previous experience and transfer the learning to accomplish new tasks easier, quicker, and in a better way, in this work, we use other sources to provide cheaper samples for accelerating model learning. Instead of taking the measurements from the real system (we refer to as the \emph{target}), we measure the system performance using a proxy of the system (we refer to as the \emph{source}, \emph{e.g.}, a simulator). We then use a regression model that automatically learns the relationship between source and target to learn an accurate and reliable performance model using only a few samples taken from the real system, leading to much lower cost and faster learning period. 
We define a cost model that turns model learning into a multi-objective problem taking into account model accuracy as well as measurement cost. We demonstrate that our cost-aware transfer learning will enable accurate performance predictions by using only a few measurements of the target system. We evaluate our approach on (i) a robotic system, (ii) 3 stream processing applications, and (iii) a NoSQL database system. %We demonstrate that our approach enhances the model prediction accuracy with at least an order of magnitude comparing with the model that has been learned using only the measurements on the real system.

In summary, our contributions are the following:
\begin{itemize}
	\item A \emph{cost-aware transfer learning} method that learns accurate performance models for configurable software.
	\item An implementation, analysis and \emph{experimental evaluation} of our cost-aware transfer learning compared to a no transfer learning method.
	%\item \emph{Measurement datasets} worth several months of experimental time for the subject systems.
\end{itemize}

%In the rest, Section \ref{sec:background} overviews the problem and motivates the work via an example. Our transfer learning methodology is introduced in Section \ref{sec:approach} and then validated in Section \ref{sec:evaluation}. Section \ref{sec:related-work} positions the approach int he literature and Section \ref{sec:conclusions} concludes the paper.

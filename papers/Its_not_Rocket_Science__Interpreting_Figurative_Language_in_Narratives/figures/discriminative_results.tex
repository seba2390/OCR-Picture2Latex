
\begin{table}[t]
\small
\centering
\begin{tabular}{llll}
\toprule
\textbf{Method} & \textbf{Model} & \textbf{Idiom} & \textbf{Simile} \\ \midrule
\multicolumn{2}{l}{Majority} & 50.0 & 50.8 \\ \midrule
\multirow{3}{*}{Zero-shot} & GPT2-XL & 53.6 & 53.7 \\  
 & GPT3 & 60.2 & 62.4 \\ \
 & UnifiedQA & 67.7 & 60.6 \\ \midrule
\multirow{2}{*}{Few-shot} & GPT3 & 54.1 & 51.7 \\ 
 & PET & 66.1 & 55.2 \\ \midrule
\multirow{2}{*}{Supervised} & RoBERTa & 82.0 & 80.4 \\ 
& -narrative & 65.0 & 67.9 \\ \midrule
\multirow{2}{*}{\begin{tabular}[c]{@{}l@{}}Knowledge \\ Enhanced\end{tabular}} & Context & 82.8 & 79.9 \\ 
 & Literal & \textbf{83.5}* & \textbf{80.6} \\ \midrule
\multicolumn{2}{l}{Human Performance} & \textbf{92.0} & \textbf{95.0} \\ \bottomrule
\end{tabular}
\caption{Model performance (accuracy) on the idiom and simile discriminative tasks. $^*$ Difference is significant ($\alpha <0.07$) between the supervised and knowledge-enhanced models via t-test.}
\label{tab:discriminative_results}
\end{table}

% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Remove the "review" option to generate the final version.
\usepackage[review]{emnlp2021}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}
\usepackage{graphicx}
% \usepackage{cellspace}
\usepackage{tabularx}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{siunitx}
\sisetup{output-exponent-marker=\ensuremath{\mathrm{e}}}

\usepackage{xcolor, soul}
\definecolor{beaublue}{rgb}{0.74, 0.83, 0.9}
\sethlcolor{beaublue}


% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}


\usepackage{colortbl}
\usepackage[T1]{fontenc}
\usepackage{color,soul}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{diagbox}
\usepackage{booktabs}
\usepackage{amssymb}
\usepackage{xspace}
\usepackage{pifont}
\usepackage{enumitem}

\newcommand{\cmark}{\ding{51}\xspace}%
\newcommand{\xmark}{\ding{55}\xspace}%
\newcommand{\numData}{XXX\xspace}
\newcommand{\dataset}{Dataset Name}
\newcommand{\vs}[1]{\textcolor{blue!40}{VS: #1}}
\newcommand{\tc}[1]{\textcolor{red!40}{TC: #1}}
\newcommand{\lt}{\ensuremath <}
\newcommand{\gt}{\ensuremath >}
\newcolumntype{P}[1]{>{\raggedright\arraybackslash}p{#1}}
\newcommand{\specialcell}[2][c]{%
	\begin{tabular}[#1]{@{}c@{}}#2\end{tabular}}
\newcommand{\specialcellleft}[2][l]{%
	\begin{tabular}[#1]{@{}l@{}}#2\end{tabular}}

\definecolor{ForestGreen}{RGB}{34,139,34}



% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{It's not Rocket Science:\\Interpreting Figurative Language in Narratives}

\author{Tuhin Chakrabarty$^1$\thanks{~~Work done during internship at AI2.}~~~~~Vered Shwartz$^{2,3,4}$~~~~~Yejin Choi$^{2,3}$ \\
 $^1$Columbia University\\
 $^2$Allen Institute for Artificial Intelligence\\
 $^3$Paul G. Allen School of Computer Science \& Engineering, University of Washington\\  
 $^4$University of British Columbia\\
 {\tt\small tuhin.chakr@cs.columbia.edu, vshwartz@cs.ubc.ca, yejinc@allenai.org} \\
}

\begin{document}
\maketitle
\begin{abstract}
\input{0-abstract}
\end{abstract}

\section{Introduction}
\label{sec:intro}
\input{1-intro}

\section{Background}
\label{sec:bg}
\input{2-background}

\section{Data}
\label{sec:data}
\input{3-data}

\section{Discriminative Task}
\label{sec:disc}
\input{4-discriminative}

\section{Generative Task}
\label{sec:generative}
\input{5-generative}

\section{Conclusion}
\label{sec:conclusion}
To understand the figurative language inference capabilities of pre-trained language models  models, we introduce a narrative understanding benchmark focused on idioms and similes.Following the Story Cloze Test we design tasks in both discriminative and generative settings. Through extensive experiments on our benchmark we find that pre-trained language models irrespective of their size struggle to perform well in a zero or few shot setting. Our supervised baseline even though competitive is still behind human performance by a significant margin trained. Finally we show how knowledge-enhanced models that are inspired by the way humans process figurative language outperform all other approaches and is particularly compelling in the generative setting. Finally we find that that while the RoBERTa-large or GPT2-XL model is able to capture some aspects of figurative language, it fails when the interpretation requires word knowledge and pragmatic inferences. We hope this work will spark additional interest in the research community to incorporate and test for figurative language in their NLU systems.
\input{6-conclusion}

% Uncomment for camera-ready version
% \section*{Acknowledgements}

\bibliography{anthology,custom}
\bibliographystyle{acl_natbib}

\appendix

\section{\vs{Some appendix}}
\label{sec:appendix_whatever}

\vs{relation details comet}
\vs{more examples}
\vs{Change the labels to meaningful names}

\end{document}

%\section{Related Works}
% \add{Since  our work is a user study of SOC operators on SOAR tools, i recommend changing this related works to only users studies on SOCs and anything regarding a SOAR tool. I don't believe any such work has been done! so i think we can quickly move on. I suggest saying "there are many previous user studies on SOC personnel, the difficulties with their job, and their tools [cite blah blah]. in fact there are only a few works that even mention SOAR tools [cite blah blah] \\ I like the SOAR tool descriptions and motivation paragraphs with references, but they are a bit wordy as is. Recommend we keep them but condensify and work it in the intro where i defined the SOAR tool via the 6 characteristics. 
%Here we explore previous works that served to provide relevant background on SOAR tool development, as well as to inform our methods for handling missing data.
%\todo{while i agree this is what our work does, i think we don't make this gap apparent until this sentence}
% \subsection{Recommender Systems}
% Since operators recruited for this survey were assigned a subset of the tools to review, this means that we have missing data since every operator did not complete the survey for each tool. This section provides a linear progression of previous research that informs our approach followed by our algorithm for filling in missing values to populate a complete dataset. 
% Consider a vector, $\vec{r}(u, t)$, that comprises the ratings assigned by user $u$ to tool $t$. Breese et al. \cite{breese1998empirical} considers the single-criteria problem where $\vec{r}(u,t)$ is a single number. Unknown values are defined as follows, 
% \begin{equation}
%     \label{eq:breese}
%     \vec{r}(u,t): = \frac{1}{\sum_{v\in \text{Users}} \s(u,v) } \sum_{v\in \text{Users}} \s(u,v) r(v,t)
% \end{equation}
% where $\s(u,v)$ is a similarity measure of users $u$ and $v$ computed with a standard similarity measure (e.g, cosine, inverse Euclidean, Pearson correlation) applied to the vector of ratings from $u$ and $v$ on the set of items both users rated. 
% % This can be conceptualized as an expectation where likelihood is proportional user similarity. 
% % More generally, the fundamental concept put forward (that we leverage heavily) is called collaborative filtering---that a user's ratings are predicted based on (in this case proportional to) ratings of those of other users with similar ratings. 
% Adomavicius \& Kwon (AK) \cite{adomavicius2007new} extend this framework to multi-criteria ratings where $\vec{r}(u,t)$ is a vector with $\vec{r}(u,t,n)$ user $u$'s overall rating of tool $t$ on the $n^{th}$ aspect. 
% Setting a distance on rating vectors, $d_R(\vec{r}(u,t), \vec{r}(v,s))$, %($\ell^p$ and Mahalanobis distance are tested), 
% AK defines the distance between two users, $u, v$, as 
% \begin{equation}
%     \label{eq:distance}
%     d_{U}(u,v) = \sum_{t\in T_{u,v}} d_R(\vec{r}(u,t), \vec{r}(v,t)) /|T_{u,v}|
% \end{equation}
% where $T_{u,v}:= \{$tools $t$ rated by both $u$ and $v$\}. 

% The similarity of two users is simply an inverse function of their distance such that $\s(u,v):= 1/(1+d_{U}(u,v))$.  
% Notably, the general framework is symmetric in users and items; hence, item similarity could just as easily produce predicted missing values. 
% Finally, for each missing aspect rating ($j = 1, ..., n-1$) $\vec{r}(u,t,j)$ is predicted
% %\todo{n-1?} 
% according to Eg. \ref{eq:breese}, and supervised learning techniques are suggested for learning $\vec{r}(u,t,n)$ from the aspect ratings $\{\vec{r}(u,t,j): j = 1, ..., n-1\}.$
% %\todo{this is confusing}
% % Both AK and Breese et al. replaced $r(w,t)$ with $r(w,t)-\overline{r_w}$, where $\overline{r_w}$ is the mean of user $w$'s ratings, in Eq. \ref{eq:breese}. 
% % By predicting the variation from the mean, one allows for users whose mean ratings trends high/low.
% % \begin{itemize}
% % \item (Ratings distance)  $d_R(r(u,t), r(v,s)) := \|r(u,t) - r(v,s)\|_p$ for $p =  1, 2, \infty$ (Euclidean, Manhattan, Chebyshev), or Mahalanobis Distance, i.e., $(r(u,t)-r(v,t))^t C (r(u,t) - r(v,t)) $ with $C$ denoting the covariance of $r(\cdot, t) $. 
% % \item (User distance) $d_U(u,v): = \sum_{t\in I_{u,v}} d_R(r(u,t), r(v,t)) /|I_{u,v}|$, with $I_{u,v}:= \{$tools $t$ rated by both $u$ and $v$\}. 
% % \item (User similarity) $\s(u,v) := 1/(1+d_{U}(u,v))$ 
% % \end{itemize}
% %  two methods above are referred to as , as opposed to a progression of 
%  The progression of the research literature diverged from these ``instance-based'' methods to develop ``model-based'' methods, e.g., 
%  \cite{hofmann1999latent, si2003flexible, sahoo2012research}, which  seek Bayesian network models that include latent variables designed to encode clusters of similar users and of items.
% Results of Sahoo et al. \cite{sahoo2012research} conclude that model-based methods excel (in precision-recall balance and in precision-rank balance) when $\vec{r}$ is sparse (common, e.g., in online marketplaces with a huge inventory of items), whereas,  the instance-based method of AK excels
% %(specifically with $\ell^\infty$ ratings distance)\footnote{Through our testing we can provide intuition for why the $\ell^\infty$ ratings norm excels---in this situation, two users are similar  ($\s(u,v)$ small) iff \textit{all} co-rated items are rated similarly. 
% % Thus, predictions are almost exclusively based on those of other users with nearly identical preferences.} 
% for dense $\vec{r}$, which is the case in this study. 


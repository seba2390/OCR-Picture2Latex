\pdfoutput=1
\section{Introduction}
%
Real-world classification datasets often suffer from two issues, i.e., label noise~\cite{songLearningNoisyLabels2021} and class imbalance~\cite{heLearningImbalancedData2009}.
%
On the one hand, label noise often results from the limitation of data generation, e.g., sensor errors~\cite{elhadySystematicSurveySensor2018a} and mislabeling from crowdsourcing workers~\cite{tongxiaoLearningMassiveNoisy2015}.
%
Label noise misleads the training process of DNNs and degrades the model performance in various aspects~\cite{alganLabelNoiseTypes2020b,zhuClassNoiseVs2004a,frenayClassificationPresenceLabel2014a}.
%
On the other hand, imbalanced datasets are either naturally long-tailed~\cite{zhaoLongTailDistributionsUnsupervised2012a,vanhornDevilTailsFinegrained2017a} or biased from the real-world distribution due to imperfect data collection~\cite{pavonAssessingImpactClassImbalanced2011a,patelReviewClassificationImbalanced2020a}.
%
Training with imbalanced datasets usually results in poor classification performance on weakly represented classes~\cite{dongClassRectificationHard2017a,cuiClassBalancedLossBased2019,sinhaClassWiseDifficultyBalancedLoss2021a}.
%
Even worse, these two issues often coexist in real-world datasets~\cite{johnsonSurveyDeepLearning2019a}.

%
To prevent the model from memorizing noisy information, many important works have been proposed, including label smoothing~\cite{szegedyRethinkingInceptionArchitecture2016a}, noise adaptation~\cite{goldbergerTrainingDeepNeuralnetworks2017}, importance weighting~\cite{liuClassificationNoisyLabels2014}, GLC~\cite{hendrycksUsingTrustedData2018}, and Co-teach~\cite{hanCoteachingRobustTraining2018a}.
%
Meanwhile, \cite{dongClassRectificationHard2017a,cuiClassBalancedLossBased2019,sinhaClassWiseDifficultyBalancedLoss2021a,linFocalLossDense2020} propose effective methods to tackle class imbalance.
% 
However, these methods inevitably introduce hyper-parameters (e.g., the weighting factor in~\cite{cuiClassBalancedLossBased2019} and the focusing parameter in~\cite{linFocalLossDense2020}), compounding real-world deployment.

%
Inspired by recent advances in meta-learning, 
some works~\cite{renLearningReweightExamples2018,shuMetaWeightNetLearningExplicit2019a,huLearningDataManipulation2019a,wangOptimizingDataUsage2020b} propose to solve both issues by leveraging a clean and unbiased meta set.
%
These methods treat instance weights as hyper-parameters and
dynamically update these weights to circumvent hyper-parameter tuning.
%
Specifically, MWNet~\cite{shuMetaWeightNetLearningExplicit2019a} adopts an MLP with the instance loss as input and the instance weight as output.
%
Due to the MLP, MWNet has better scalability on large datasets compared with INSW~\cite{huLearningDataManipulation2019a} which assigns each instance with a learnable weight.
%
Although these methods can handle label noise and class imbalance to some extent, they cannot fully utilize class-level information within each instance, resulting in the potential loss of useful information.
%
For example, in a three-class classification task, every instance has three logits.
%
As shown in Figure~\ref{fig:motiv}, every logit corresponds to a class-level gradient flow which stems from the loss function and back-propagates.
%
These gradient flows represent three kinds of information: "not cat", "dog", and "not bird".
%
Instance weighting methods~\cite{shuMetaWeightNetLearningExplicit2019a,renLearningReweightExamples2018} alleviate label noise by downweighting all the gradient flows of the instance, which discards three kinds of information simultaneously. 
%
Yet, downweighting the "not bird" gradient flow is a waste of information.
%
Similarly, in class imbalance scenarios, different gradient flows represent different class-level information.
\begin{wrapfigure}[19]{l}{0.5\textwidth}
    \centering
    \includegraphics[scale=0.19]{figures/intro_motivation.png}
    \caption{Motivation for class-level weighting. For a noisy instance (e.g. cat mislabeled as "dog"), all gradient flows are downweighted by instance weighting. Although the gradient flows for "dog" and "not cat" contain harmful information, the gradient flow for "not bird" is still valuable for training, which should not be downweighted.}
    \label{fig:motiv}
\end{wrapfigure}
%
Therefore, it is necessary to reweight instances at the class level for better information usage.

%
To this end, we propose Generalized Data Weighting~(\textbf{GDW}) to tackle label noise and class imbalance by class-level gradient manipulation.
%
Firstly, we introduce class-level weights to represent the importance of different gradient flows and manipulate the gradient flows with these class-level weights.
%
Secondly, we impose a zero-mean constraint on class-level weights for stable training.
%
Thirdly, to efficiently obtain class-level weights, we develop a two-stage weight generation scheme embedded in  bi-level optimization.
%
As a side note, the instance weighting methods~\cite{renLearningReweightExamples2018,shuMetaWeightNetLearningExplicit2019a,huLearningDataManipulation2019a,wangOptimizingDataUsage2020b} can be considered special cases of GDW when class-level weights within any instance are the same.
%
In this way, GDW achieves impressive performance improvement in various settings.

%
To sum up, our contribution is two-fold:
\begin{enumerate}
    %
    \item For better information utilization, we propose GDW, a generalized data weighting method, which better handles label noise and class imbalance. To the best of our knowledge, we are the first to propose single-label class-level weighting on gradient flows.
    %
    \item To obtain class-level weights efficiently, we design a two-stage scheme embedded in a bi-level optimization framework, which does not introduce any extra computational cost.
    %
    To be specific, during the back-propagation we store intermediate gradients, with which we update class-level weights via a gradient descent step.
\end{enumerate}
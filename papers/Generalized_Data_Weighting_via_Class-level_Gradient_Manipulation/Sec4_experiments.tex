\pdfoutput=1
\section{Experiments}
%
We conduct extensive experiments on classification tasks to examine the performance of GDW.
%
We compare GDW with other methods in the label noise setting and class imbalance setting in Section~\ref{sec:noise} and Section~\ref{sec:imbalance}, respectively.
%
Next, we perform experiments on the real-world dataset Clothing1M~\cite{tongxiaoLearningMassiveNoisy2015} in Section~\ref{sec:real-world}.
%
We conduct further experiments to verify the performance of GDW in the mixed setting, i.e. the coexistence of label noise and class imbalance~(see Appendix~\ref{section: Appendix_F} for details).

\subsection{Label Noise Setting}
\label{sec:noise}
%
\noindent \textbf{Setup.} Following \cite{shuMetaWeightNetLearningExplicit2019a}, we study two settings of label noise: a) Uniform noise: every instance's label uniformly flips to other class labels with probability $p$; b) Flip noise: each class randomly flips to another class with probability $p$.
%
Note that the probability $p$ represents the noise ratio.
%
We randomly select $100$ clean images per class from CIFAR10~\cite{krizhevskyLearningMultipleLayers2009} as the meta set ($1000$ images in total).
%
Similarly, we select a total of $1000$ images from CIFAR100 as its meta set.
%
We use ResNet-32~\cite{heDeepResidualLearning2016} as the classifier model.

%
\noindent \textbf{Comparison methods.} We mainly compare GDW with meta-learning methods: 1) L2RW~\cite{renLearningReweightExamples2018}, which assigns weights to instances based on gradient directions;
2) INSW~\cite{huLearningDataManipulation2019a}, which derives instance weights adaptively from the meta set;
3) MWNet~\cite{shuMetaWeightNetLearningExplicit2019a}; 4) Soft-label~\cite{vyasLearningSoftLabels2020b}, which learns a label smoothing parameter for every instance; 5) Gen-label~\cite{alganMetaSoftLabel2021a}, which generates a meta-soft-label for every instance.
%
We also compare GDW with some traditional methods: 6) BaseModel, which trains ResNet-32 on the noisy training set; 7) Fine-tuning, which uses the meta set to fine-tune the trained model in BaseModel; 8) Co-teaching~\cite{hanCoteachingRobustTraining2018a}; 9) GLC~\cite{hendrycksUsingTrustedData2018}.
%

\noindent \textbf{Training.} Most of our training settings follow \cite{shuMetaWeightNetLearningExplicit2019a} and we use the cosine learning rate decay schedule~\cite{loshchilovSGDRStochasticGradient2016} for a total of $80$ epochs for all methods.
%
See Appendix \ref{section: Appendix_C} for details.

\begin{table}
	\centering
	\caption{Test accuracy on CIFAR10 and CIFAR100 with different uniform noise ratios.}  
	\label{tab:unif_noise_table}
	\scalebox{0.86}{
	\begin{tabular}{ccccccc}
		\specialrule{\cmidrulewidth}{0pt}{0pt}
		\multirow{2}*{Dataset} & \multicolumn{3}{c}{CIFAR10} &  \multicolumn{3}{c}{CIFAR100} \\
		\cmidrule(lr){2-4}
        \cmidrule(lr){5-7}
		%\specialrule{\cmidrulewidth}{0pt}{0pt}
		 & \multicolumn{1}{c}{$0\%$} & \multicolumn{1}{c}{$40\%$}  & \multicolumn{1}{c}{$60\%$}  & \multicolumn{1}{c}{$0\%$}  & \multicolumn{1}{c}{$40\%$}  & \multicolumn{1}{c}{$60\%$}  \\
		\specialrule{\cmidrulewidth}{0pt}{0pt}
		BaseModel & $92.73 \pm 0.37$ & $84.38 \pm 0.32$ & $77.92 \pm 0.29$ & $70.42 \pm 0.54$ & $57.28 \pm 0.80$ & $46.86 \pm 1.54$ \\
		Fine-tuning  & $92.77 \pm 0.37$ & $84.73 \pm 0.47$ & $78.41 \pm 0.31$ & $70.52 \pm 0.57$ & $57.38 \pm 0.87$ & $47.06 \pm 1.47$ \\
		Co-teaching  & $91.54 \pm 0.39$ & $85.26 \pm 0.56$ & $78.90 \pm 6.64$ & $68.33 \pm 0.13$ & \uline{$59.58 \pm 0.83$} & $37.74 \pm 2.60$ \\
		GLC  & $90.85 \pm 0.22$ & $86.12 \pm 0.54$ & \uline{$81.55 \pm 0.60$} & $65.05 \pm 0.59$ & $56.99 \pm 0.82$ & $41.74 \pm 1.98$ \\
		\specialrule{\cmidrulewidth}{0pt}{0pt}
		\specialrule{\cmidrulewidth}{0pt}{0pt}
		L2RW  & $89.70 \pm 0.50$ & $84.66 \pm 1.21$ & $79.98 \pm 1.18$ & $63.40 \pm 1.31$ & $47.06 \pm 4.84$ & $36.02 \pm 2.17$ \\
		INSW  & $92.70 \pm 0.57$ & $84.88 \pm 0.64$ & $78.77 \pm 0.82$ & $70.52 \pm 0.39$ & $57.11 \pm 0.66$ & $48.00 \pm 1.16$ \\
		MWNet  & \textbf{92.95} $\pm$ \textbf{0.33} & $86.46 \pm 0.31$ & $81.14 \pm 0.94$ & \uline{$\textbf{70.64} \pm \textbf{0.31}$} & {$58.37 \pm 0.33$} & \uline{$50.21 \pm 2.98$} \\
		Soft-label  & $92.63 \pm 0.27$ & \uline{$86.52 \pm 0.10$} & $80.94 \pm 0.25$ & $70.50 \pm 0.44$ & $57.48 \pm 0.43$ & $48.18 \pm 0.89$ \\
		Gen-label  & $92.56 \pm 0.56$ & $84.68 \pm 0.57$ & $78.32 \pm 0.94$ & $70.46 \pm 0.37$ & $57.86 \pm 0.50$ & $48.08 \pm 0.98$ \\
		\textbf{GDW}  & \uline{\textbf{92.94} $\pm$ \textbf{0.15}} & \textbf{88.14} $\pm$ \textbf{0.35} & \textbf{84.11} $\pm$ \textbf{0.21} & \textbf{70.65} $\pm$ \textbf{0.52} & \textbf{59.82} $\pm$ \textbf{1.62} & \textbf{53.33} $\pm$ \textbf{3.70} \\
		\specialrule{\cmidrulewidth}{0pt}{0pt}
	\end{tabular}
	}
\end{table}

\begin{table}
	\centering
	\caption{Test accuracy on CIFAR10 and CIFAR100 with different flip noise ratios.}  
	\label{tab:flip_noise_table}
	\scalebox{0.86}{
	\begin{tabular}{ccccccc}
		\specialrule{\cmidrulewidth}{0pt}{0pt}
		\multirow{2}*{Dataset} & \multicolumn{3}{c}{CIFAR10} &  \multicolumn{3}{c}{CIFAR100} \\
		\cmidrule(lr){2-4}
        \cmidrule(lr){5-7}
		%\specialrule{\cmidrulewidth}{0pt}{0pt}
		 & \multicolumn{1}{c}{$0\%$} & \multicolumn{1}{c}{$20\%$}  & \multicolumn{1}{c}{$40\%$}  & \multicolumn{1}{c}{$0\%$}  & \multicolumn{1}{c}{$20\%$}  & \multicolumn{1}{c}{$40\%$}  \\
		\specialrule{\cmidrulewidth}{0pt}{0pt}
		BaseModel & $92.73 \pm 0.37$ &$ 90.14 \pm 0.35$  &  $81.20 \pm 0.93$ &  $70.42 \pm 0.54$ & $64.96 \pm 0.16$ & $49.83 \pm 0.82$ \\
		Fine-tuning  & $92.77 \pm 0.37$  & $90.15\pm 0.36$ & $81.53 \pm 0.96$ & $70.52 \pm 0.57$ & $65.02 \pm 0.22$ & $50.23 \pm 0.71$ \\
		Co-teaching  & $91.54 \pm 0.39$ & $89.27 \pm 0.24$ & $69.77 \pm 3.97$ & $68.33 \pm 0.13$ & $62.96 \pm 0.73$ & $42.54 \pm 1.68$ \\
		GLC  & $90.85 \pm 0.22$ & \uline{$90.22 \pm 0.13$} & \textbf{89.74} $\pm$ \textbf{0.19} & $65.05 \pm 0.59$ & $64.11 \pm 0.40$ & \textbf{63.11} $\pm$ \textbf{0.93} \\
		\specialrule{\cmidrulewidth}{0pt}{0pt}
		\specialrule{\cmidrulewidth}{0pt}{0pt}
		L2RW  & $89.70 \pm 0.50$ & $88.21 \pm 0.49$ & $82.90 \pm 1.27$ &  $63.40 \pm 1.31$ & $55.27 \pm 2.27$ & $45.41 \pm 2.53$ \\
		INSW  & $92.70 \pm 0.57$ &  $89.90 \pm 0.45$ & $80.09 \pm 2.00$ &$70.52 \pm 0.39$ & \uline{$65.32 \pm 0.27$} & $50.13 \pm 0.39$ \\
		MWNet  & \textbf{92.95} $\pm$ \textbf{0.33} &  $89.93 \pm 0.17$ & $85.55 \pm 0.82$ &\uline{$\textbf{70.64} \pm \textbf{0.31}$} & $64.72 \pm 0.68$ & $50.62 \pm 0.46$ \\
		Soft-label  & $92.63 \pm 0.27$ & $90.17 \pm 0.47$ & $85.52 \pm 0.78$ & $70.50 \pm 0.44$ & $65.20 \pm 0.45$ & $50.97 \pm 0.41$ \\
		Gen-label      & $92.56 \pm 0.56$ & $90.18 \pm 0.13$ & $80.93 \pm 1.29$ & $70.46 \pm 0.37$ & $64.94 \pm 0.53$ & $49.93 \pm 0.55$ \\
		\textbf{GDW}  & \uline{\textbf{92.94} $\pm$ \textbf{0.15}} & \textbf{91.05} $\pm$ \textbf{0.26} & \uline{$87.70 \pm 0.37$} & \textbf{70.65} $\pm$ \textbf{0.52} & \textbf{65.41} $\pm$ \textbf{0.75} & \uline{$52.44 \pm 0.79$} \\
		\specialrule{\cmidrulewidth}{0pt}{0pt}
	\end{tabular}
	}
\end{table}


\noindent \textbf{Analysis.} For all experiments, we report the mean and standard deviation over $5$ runs in Table \ref{tab:unif_noise_table} and Table \ref{tab:flip_noise_table}, where 
the best results are in \textbf{bold} and the second-best results are marked by underlines.
%
First, we can observe that GDW outperforms nearly all the competing methods in all noise settings except for the $40\%$ flip noise setting.
%
Under this setting, GLC estimates the label corruption matrix well and thus performs the best, whereas the flip noise assumption scarcely holds in real-world scenarios.
%
Note that GLC also performs much better than MWNet under the $40\%$ flip noise setting as reported in \cite{shuMetaWeightNetLearningExplicit2019a}.
%
Besides, under all noise settings, GDW has a consistent performance gain compared with MWNet, which aligns with our motivation in Figure \ref{fig:motiv}.
%
Furthermore, as the ratio increases from $40\%$ to $60\%$ in the uniform noise setting, the gap between GDW and MWNet increases from $1.68\%$ to $2.97\%$ in CIFAR10 and $1.45\%$ to $3.12\%$ in CIFAR100.
%
Even under $60\%$ uniform noise, GDW still has low test errors in both datasets and achieves more than $3\%$ gain in CIFAR10 and $6\%$ gain in CIFAR100 compared with the second-best method.
%
Last but not least, GDW outperforms Soft-label and Gen-label in all settings.
%
One possible reason is that manipulating gradient flows is a more direct way to capture class-level information than learning labels.

\begin{figure}
\centering
\begin{minipage}[t]{.5\textwidth}
  \centering
    \captionsetup{width=.95\linewidth}
    \includegraphics[width=0.8\columnwidth]{figures/clean_and_noise_w_cifar10.png} 
    \caption{Class-level target weight~($\boldsymbol{\omega}_t$) distribution on CIFAR10 under $40\%$ uniform noise.
    $\boldsymbol{\omega}_t$ of most clean instances are larger than that of most noisy instances, which means $\boldsymbol{\omega}_t$
    can differentiate between clean and noisy instances.
    }
    \label{fig:clean_and_noise_w_cifar10}
\end{minipage}%
\begin{minipage}[t]{.5\textwidth}
  \centering
    \captionsetup{width=.95\linewidth}
    \includegraphics[width=0.8\columnwidth]{figures/exp_verification.png} 
    \caption{The change of class-level weights in an iteration for a noisy instance (cat mislabeled as "dog").  MWNet downweights all gradient flows. In contrast, GDW upweights the "not bird" gradient flow for better information use.}
    \label{fig:exp_verification}
\end{minipage}
\end{figure}

In Figure \ref{fig:clean_and_noise_w_cifar10}, we show the distribution of class-level target weight~($\boldsymbol\omega_t$) on clean and noisy instances in one epoch under the CIFAR10 40\% uniform noise setting.
%
We observe that $\boldsymbol\omega_t$ of most clean instances are larger than that of most noisy instances, which indicates that $\boldsymbol\omega_t$ can distinguish between clean instances and noisy instances.
%
This is consistent with Eq. (\ref{eq:grad1'})  that $\boldsymbol\omega_t$ serves as the instance weight. 

To better understand the changing trend of non-target class-level weights, we visualize the ratio of increased weights in one epoch in Figure \ref{fig:cifar10_unif_ratio_trend} under the CIFAR10 40\% uniform noise setting.
%
Specifically, there are three categories: \textbf{n}on-\textbf{t}arget \textbf{w}eights on \textbf{c}lean instances (\textbf{$\boldsymbol\omega^c_{nt}$}), \textbf{t}rue \textbf{t}arget \textbf{w}eights on \textbf{n}oisy instances (\textbf{$\boldsymbol\omega^{n}_{tt}$}) and \textbf{n}on-\textbf{t}arget (excluding true targets) \textbf{w}eights on \textbf{n}oisy instances ($\boldsymbol\omega^n_{nt}$).
%
Formally, "target weight" means the class-level weight on the label position.
%
"true-target weight" means the class-level weight on the true label position, which are only applicable for noisy instances. "non-target weight" means the class-level weight except the label position and the true label position.
%
For example, as shown in Figure \ref{fig:motiv} where a cat is mislabeled as "dog", the corresponding meanings of the notations are as follows: 1)~$\boldsymbol\omega^n_{t}$ means $\boldsymbol\omega_{dog}$ ("dog" is the target); 2)~$\boldsymbol\omega^n_{tt}$ means $\boldsymbol\omega_{cat}$ ("cat" is the ture target); 3)~$\boldsymbol\omega^n_{nt}$ means $\boldsymbol\omega_{bird}$ ("bird" is one of the non-targets).
%
For a correctly labeled cat, the corresponding meanings are: 1)~$\boldsymbol\omega^c_{t}=\boldsymbol\omega^c_{tt}$ means $\boldsymbol\omega_{cat}$~("cat" is both the target and the ture target); 2)~$\boldsymbol\omega^c_{nt}$ means $\boldsymbol\omega_{dog}$ and $\boldsymbol\omega_{bird}$ ("dog" and "bird" are both non-targets).

%
Note that in Figure \ref{fig:motiv}, $\boldsymbol\omega^n_{tt}$ represents the importance of the "not cat" gradient flow and $\boldsymbol\omega^n_{nt}$ represents the importance of the "not bird" gradient flow.
%
If the cat image in Figure \ref{fig:motiv} is correctly labeled as "cat", then
the two non-target weights $\boldsymbol\omega^c_{nt}$ are used to represent the importance of the "not dog" and the "not bird" gradient flows, respectively.
%
In one epoch, we calculate \textbf{the ratios of} the number of increased $\boldsymbol\omega^c_{nt}$, $\boldsymbol\omega^{n}_{tt}$ and $\boldsymbol\omega^n_{nt}$ \textbf{to} the number of all corresponding weights.
%
$\boldsymbol\omega^c_{nt}$ and $\boldsymbol\omega^n_{nt}$ are expected to increase since their gradient flows contain valuable information,
whereas $\boldsymbol\omega^{n}_{tt}$ is expected to decrease because the "not cat" gradient flow contains harmful information.
%
Figure \ref{fig:cifar10_unif_ratio_trend} aligns perfectly with our expectation.
%
Note that the lines of $\boldsymbol\omega^c_{nt}$ and $\boldsymbol\omega^n_{nt}$ nearly coincide with each other and fluctuate around $65\%$.
%
This means non-target weights on clean instances and noisy instances share the same changing pattern, i.e., around $65\%$ of $\boldsymbol\omega^c_{nt}$ and $\boldsymbol\omega^n_{nt}$ increase.
%
Besides, less than $20\%$ of $\boldsymbol\omega^{n}_{tt}$ increase and thus more than $80\%$ decrease, which means the gradient flows of $\boldsymbol\omega^{n}_{tt}$ contain much harmful information.

%
In Figure \ref{fig:exp_verification}, we show the change of class-level weights in an iteration for a noisy instance, i.e., a cat image mislabeled as "dog".
%
The gradient flows of "not cat" and "dog" contain harmful information and thus are downweighted by GDW.
%
In addition, GDW upweights the valuable "not bird" gradient flow from $0.45$ to $0.63$.
%
By contrast, unable to capture class-level information, MWNet downweights all gradient flows from $0.45$ to $0.43$, which leads to information loss on the "not bird" gradient flow.

\noindent \textbf{Training without the zero-mean constraint.} We have also tried training without the zero-mean constraint in Section \ref{subsec:restOn} and got poor results~(see Appendix \ref{subsection: Appendix_B.2} for details).
%
Denote the \textbf{t}rue \textbf{t}arget as $tt$ and one of the \textbf{n}on-\textbf{t}arget labels as $nt$ ($nt\neq tt$). 
%
Note that the gradient can be unrolled as (see Appendix \ref{subsection: Appendix_B.2} for details):
\begin{equation} \label{eq2}
f_{\boldsymbol \omega}\left(\nabla_{\boldsymbol \theta} \mathcal{L}\right) = \boldsymbol{\omega}_t \sum_j\left({\boldsymbol{p}'_j}-\mathbf{y}_j\right)\frac{\partial \boldsymbol{l}_j}{\partial \boldsymbol \theta} + \left(\sum_k{{\boldsymbol {\omega}_k} {\boldsymbol{p}_k}}-\boldsymbol{\omega}_t\right) \sum_j {\boldsymbol{p}'_j}\frac{\partial \boldsymbol{l}_j}{\partial \boldsymbol \theta}.
\end{equation}

%
If $\sum_k{{\boldsymbol \omega_k} {\boldsymbol p_k}}-\boldsymbol \omega_t$ is positive and the learning rate is small enough, $\left(\sum_k{{\boldsymbol \omega_k} {\boldsymbol p_k}}-\boldsymbol\omega_t\right) \boldsymbol p'_{tt} \frac{\partial \boldsymbol l_{tt}}{\partial \boldsymbol \theta}$ contributes to the decrease of the true target logit $\boldsymbol l_{tt}$  after a gradient descent step.
If negative,  $\left(\sum_k{{\boldsymbol \omega_k} { \boldsymbol p_k}}-\boldsymbol \omega_t\right) \boldsymbol p'_{nt} \frac{\partial \boldsymbol l_{nt}}{\partial \boldsymbol \theta}$ contributes to the increase of the non-target logit $\boldsymbol l_{nt}$.
%
Therefore, without the zero-mean constraint, the second term in Eq. (\ref{eq2}) may hurt the performance of the model regardless of the sign of $\sum_k{{\boldsymbol \omega_k} {\boldsymbol p_k}}-\boldsymbol \omega_t$.
%
Similarly, training without the constraint results in poor performance in other settings.
%
Hence we omit those results in the following subsections.

\begin{figure}
\centering
\begin{minipage}[t]{.5\textwidth}
  \centering
    \includegraphics[width=0.8\columnwidth]{figures/cifar10_unif_ratio_trend.png}
    \captionsetup{width=.95\linewidth}
    \caption{Ratio trend of the number of increased $\boldsymbol\omega^c_{nt}$, $\boldsymbol\omega^{n}_{tt}$, and $\boldsymbol\omega^n_{nt}$ under the CIFAR10 40\% uniform noise setting. 
    %
    Around $65\%$ of $\boldsymbol\omega^c_{nt}$ and $\boldsymbol\omega^n_{nt}$ increase since they contain useful information.
    %
    Besides, less than $20\%$ of $\boldsymbol\omega^{n}_{tt}$ increase and thus more than $80\%$ of $\boldsymbol\omega^{n}_{tt}$ decrease since they contain harmful information.
    }
    \label{fig:cifar10_unif_ratio_trend}
\end{minipage}%
\begin{minipage}[t]{.5\textwidth}
  \centering
    \includegraphics[width=0.82\columnwidth]{figures/cifar10_imb_ratio_trend.png}
    \captionsetup{width=.95\linewidth}
    \caption{Ratio trend of the number of increased $\boldsymbol{\omega}_8$ on $C9$ instances under the Long-Tailed CIFAR10 $\mu=0.1$ setting.
    %
    Less than $10\%$ of $\boldsymbol{\omega}_8$ increase and thus more than $90\%$ decrease.
    %
    A small $\boldsymbol{\omega}_8$ strikes a balance between two kinds of information: "$C8$" and "not $C8$",
    which better handles class imbalance.
    }
    \label{fig:cifar10_imb_ratio_trend}
\end{minipage}
\end{figure}


\subsection{Class Imbalance Setting}
\label{sec:imbalance}

\begin{table}
	\centering
	\caption{Test accuracy on the long-tailed CIFAR10 and CIFAR100 with different imbalance ratios.}  
	\label{tab:class_imbalance}
	\scalebox{0.84}{
	\begin{tabular}{ccccccc}
		\specialrule{\cmidrulewidth}{0pt}{0pt}
		\multirow{2}*{Dataset} & \multicolumn{3}{c}{CIFAR10} &  \multicolumn{3}{c}{CIFAR100} \\
		\cmidrule(lr){2-4}
        \cmidrule(lr){5-7}
		%\specialrule{\cmidrulewidth}{0pt}{0pt}
		 & \multicolumn{1}{c}{$\mu=1$} & \multicolumn{1}{c}{$\mu=0.1$}  & \multicolumn{1}{c}{$\mu=0.01$}  & \multicolumn{1}{c}{$\mu=1$}  & \multicolumn{1}{c}{$\mu=0.1$}  & \multicolumn{1}{c}{$\mu=0.01$}  \\
		\specialrule{\cmidrulewidth}{0pt}{0pt}
		BaseModel & $92.73 \pm 0.37$ & $85.93 \pm 0.57$ & $69.77 \pm 1.13$ & $70.42 \pm 0.54$ & $56.25 \pm 0.49$ & {$37.79 \pm 0.82$} \\
		Fine-tuning  & $92.77 \pm 0.37$ & $82.60 \pm 0.49$ & $59.76 \pm 1.00$ & $70.52 \pm 0.57$ & $55.95 \pm 0.50$ & $37.10 \pm 0.87$ \\
		Focal  & $91.68 \pm 0.49$ & $84.57 \pm 0.83$ & $65.78 \pm 4.02$ & $68.48 \pm 0.38$ & $55.02 \pm 0.51$ & $37.43 \pm 1.00$ \\
		Balanced  & $92.80 \pm 0.47$ & $86.05 \pm 0.46$ & $63.63 \pm 3.60$ & $70.56 \pm 0.56$ & $55.02 \pm 0.80$ & $27.60 \pm 1.39$ \\
		\specialrule{\cmidrulewidth}{0pt}{0pt}
		\specialrule{\cmidrulewidth}{0pt}{0pt}
		L2RW  & $89.70 \pm 0.50$ & $79.11 \pm 3.40$ & $51.15 \pm 7.13$ & $63.40 \pm 1.31$ & $46.28 \pm 4.51$ & $25.86 \pm 5.78$ \\
	    INSW  & $92.70 \pm 0.57$ & \uline{$86.31 \pm 0.28$} & \uline{$70.27 \pm 0.24$} & $70.52 \pm 0.39$ & $55.94 \pm 0.51$ & $37.67 \pm 0.59$ \\
		MWNet            & \textbf{92.95} $\pm$ \textbf{0.33} & $86.17 \pm 0.75$ & $62.70 \pm 1.76$ & \uline{$\textbf{70.64} \pm \textbf{0.31}$} & \uline{$56.49 \pm 1.52$} & \uline{$37.83 \pm 0.86$} \\
		\textbf{GDW}  & \uline{\textbf{92.94} $\pm$ \textbf{0.15}} & \textbf{86.77} $\pm$ \textbf{0.55} & \textbf{71.31} $\pm$ \textbf{1.03} & \textbf{70.65} $\pm$ \textbf{0.52} & \textbf{56.78} $\pm$ \textbf{0.52} & \textbf{37.94} $\pm$ \textbf{1.58} \\
		\specialrule{\cmidrulewidth}{0pt}{0pt}
	\end{tabular}
	}
\end{table}

\noindent \textbf{Setup and comparison methods.}
%
The imbalance factor $\mu \in (0, 1)$ of a dataset is defined as the number of instances in the smallest class divided by that of the largest~\cite{shuMetaWeightNetLearningExplicit2019a}.
%
Long-Tailed CIFAR \cite{krizhevskyLearningMultipleLayers2009} are created
by reducing the number of training instances per class according to an exponential function $n = n_i\mu^{i/(C-1)} $, where $i$ is the class index (0-indexed) and $n_i$ is the original number of training instances.
%
Comparison methods include: 1)~L2RW~\cite{renLearningReweightExamples2018}; 2)~INSW~\cite{huLearningDataManipulation2019a}; 3)~MWNet~\cite{shuMetaWeightNetLearningExplicit2019a}; 4)~BaseModel; 5)~Fine-tuning; 6)~Balanced~\cite{cuiClassBalancedLossBased2019}; 7)~Focal~\cite{linFocalLossDense2020}.

\noindent \textbf{Analysis.} As shown in Table \ref{tab:class_imbalance}, GDW performs best in nearly all settings and exceeds MWNet by $8.6\%$ when the imbalance ratio $\mu$ is $0.01$ in CIFAR10.
%
Besides, INSW achieves competitive performance at the cost of introducing a huge amount of learnable parameters (equal to the training dataset size $N$).
%
Furthermore, we find that BaseModel achieves competitive performance, but fine-tuning on the meta set hurts the model's performance.
%
We have tried different learning rates from $10^{-7}$ to $10^{-1}$ for fine-tuning, but the results are similar.
%
One explanation is that the balanced meta set worsens the model learned from the imbalanced training set.
%
These results align with the experimental results in \cite{huLearningDataManipulation2019a} which also deals with class imbalance.

%
Denote the smallest class as $C9$ and the second smallest class as $C8$ in Long-Tailed CIFAR10 with $\mu=0.1$.
%
Recall that $\boldsymbol \omega_j$ denotes the $j^{th}$ class-level weight.
%
For all $C9$ instances in an epoch, we calculate \textbf{the ratio of} the number of increased $\boldsymbol \omega_8$ \textbf{to} the number of all $\boldsymbol \omega_8$, and then visualize the ratio trend in Figure \ref{fig:cifar10_imb_ratio_trend}.
%
Since $C9$ is the smallest class, instance weighting methods upweight both $\boldsymbol \omega_8$ and $\boldsymbol \omega_9$ on a $C9$ instance.
%
Yet in Figure \ref{fig:cifar10_imb_ratio_trend}, less than $10\%$ of $\boldsymbol \omega_8$ increase and thus more than $90\%$
decrease.
%
This can be explained as follows.
%
There are two kinds of information in the long-tailed dataset regarded to $C8$: "$C8$" and "not $C8$".
%
Since $C8$ belongs to the minority class, the dataset is biased towards the "not $C8$" information.
%
Because $\boldsymbol \omega_8$ represents the importance of "not $C8$", a smaller $\boldsymbol \omega_8$ weakens the "not $C8$" information.
%
As a result, decreased $\boldsymbol \omega_8$ achieves a balance between two kinds of information: "$C8$" and "not $C8$", thus better handling class imbalance at the class level.
%
We have conducted further experiments on imbalanced settings to verify the effectiveness of GDW and see Appendix D for details.


\subsection{Real-world Setting}
\label{sec:real-world}


\noindent \textbf{Setup and training.} The Clothing1M dataset contains one million images from fourteen classes collected from the web~\cite{tongxiaoLearningMassiveNoisy2015}. 
%
Labels are constructed from surrounding texts of images and thus contain some errors.
%
We use the ResNet-18 model pre-trained on ImageNet~\cite{dengImageNetLargescaleHierarchical2009} as the classifier.
%
The comparison methods are the same as those in the label noise setting since the main issue of Clothing1M is label noise~\cite{tongxiaoLearningMassiveNoisy2015}.
%
All methods are trained for $5$ epochs via SGD with a $0.9$ momentum, a $10^{-3}$ initial learning rate, a $10^{-3}$ weight decay, and a $128$ batchsize.
%
See Appendix \ref{section: Appendix_E} for details.

\begin{table}
  \caption{Test accuracy on Clothing1M.}
  \label{tab: Clothing1M}
  \scalebox{0.733}{
  \centering
  \begin{tabular}{c c c c c c c c c c c c}
    \toprule
    Method     & BaseModel  & Fine-tuning & Co-teaching & GLC & L2RW & INSW & MWNet & Soft-label & Gen-label & \textbf{GDW} \\
    \midrule
    Accuracy($\%$) & $65.02$& $67.68$& $68.13$ & $68.60$ & \uline{$68.80$} & $68.25$ &$68.46$ &$68.69$ &$67.64$ & \textbf{69.39}      \\
    \bottomrule
  \end{tabular}
  }
\end{table}


\noindent \textbf{Analysis.} As shown in Table \ref{tab: Clothing1M}, GDW achieves the best performance among all the comparison methods and outperforms MWNet by $0.93\%$.
%
In contrast to unsatisfying results in previous settings, L2RW performs quite well in this setting.
%
One possible explanation is that, compared with INSW and MWNet which update weights iteratively, L2RW obtains instance weights only based on current gradients.
%
As a result, L2RW can more quickly adapt to the model's state, but meanwhile suffers from unstable weights~\cite{shuMetaWeightNetLearningExplicit2019a}.
%
In previous settings, we train models from scratch, which need stable weights to stabilize training.
%
Therefore, INSW and MWNet generally achieve better performance than L2RW.
%
Whereas in this setting, we use the pre-trained ResNet-18 model which is already stable enough.
%
Thus L2RW performs better than INSW and MWNet.

\pdfoutput=1
\section{Method}
\label{method}
\subsection{Notations}
%
In most classification tasks, there is a training set $D_{train}=\{(x_i, y_i)\}_{i=1}^N$ and we assume there is also a clean unbiased meta set $D_{meta}=\{(x_i^v, y_i^v)\}_{i=1}^M$.
%
We aim to alleviate label noise and class imbalance in  $D_{train}$ with $D_{meta}$.
%
The model parameters are denoted as $\boldsymbol \theta$, and the number of classes is denoted as $C$.

\subsection{Class-level Weighting by Gradient Manipulation}
\label{subsec:gradManip}
%
To utilize class-level information, we learn a class-level weight for every gradient flow instead of a scalar weight for all $C$ gradient flows in~\cite{shuMetaWeightNetLearningExplicit2019a}.
%
Denote $\mathcal{L}$ as the loss of any instance.
%
Applying the chain rule, we unroll the gradient of $\mathcal{L}$ w.r.t. $\boldsymbol \theta$ as
\begin{equation}
    \label{eq:chainRule}
    \nabla_{\boldsymbol \theta} \mathcal{L}= \frac{\partial \mathcal{L}}{\partial \mathbf{\boldsymbol \theta}} = \frac{\partial \mathcal{L}}{\partial \mathbf{l}} \frac{\partial \mathbf{l}}{\partial \mathbf{\boldsymbol \theta}} \doteq \mathbf{D}_{1}\mathbf{D}_{2},
\end{equation}
where $\mathbf{l}\in\mathbb{R}^C$ represents the predicted logit vector of the instance.
%
We introduce class-level weights $\boldsymbol \omega \in\mathbb{R}^C$ and denote the $j^{th}$ component of $\boldsymbol \omega$ as $\boldsymbol \omega_j$.
%
To indicate the importance of every gradient flow, we perform an element-wise product $f_{\boldsymbol \omega}(\cdot)$ on $\mathbf{D}_1$ with $\boldsymbol \omega$.
%
After this manipulation, the gradient becomes
\begin{equation}
    \label{eq:newGrad}
    f_{\boldsymbol \omega}\left(\nabla_{\boldsymbol \theta} \mathcal{L}\right) \doteq \left(\boldsymbol \omega \otimes \frac{\partial \mathcal L}{\partial \mathbf{l}}\right) \frac{\partial \mathbf{l}}{\partial \boldsymbol \theta} = \left(\boldsymbol \omega \otimes \mathbf{D}_1\right) \mathbf{D}_2 \doteq \mathbf{D}'_1\mathbf{D}_2,
\end{equation}
where $\otimes$ denotes the element-wise product of two vectors.
%
Note that $\boldsymbol \omega_j$ represents the importance of the $j^{th}$ gradient flow.
%
Obviously, instance weighting is a special case of GDW when elements of $\boldsymbol \omega$ are the same.
%
Most classification tasks~\cite{howardMobileNetsEfficientConvolutional2017a,qinRethinkingSoftmaxCrossEntropy2020a,zhaoBetterAccuracyefficiencyTradeoffs2021a} adopt the \textit{Softmax-CrossEntropy} loss.
%
In this case, we have $\mathbf{D}_1 = \mathbf p - \mathbf y$, where $\mathbf p \in \mathbb{R}^C$ denotes the probability vector output by \textit{softmax} and $\mathbf y\in\mathbb{R}^C$ denotes the one-hot label of the instance~(see Appendix~\ref{section: Appendx_A} for details).

%
As shown in Figure~\ref{fig:motiv}, for a noisy instance (e.g., cat mislabeled as "dog"), instance weighting
methods assign a low scalar weight to all gradient flows of the instance.
%
Instead, GDW assigns class-level weights to different gradient flows by leveraging the meta set.
%
In other words, GDW tries to downweight the gradient flows for "dog" and "not cat", and upweight the gradient flow for "not bird".
%
Similarly, in imbalance settings, different gradient flows have different class-level information.
%
Thus GDW can also better handle class imbalance by adjusting the importance of different gradient flows. 

\subsection{Zero-mean Constraint on Class-level Weights}
\label{subsec:restOn}
%
To retain the \textit{Softmax-CrossEntropy} loss structure, i.e. the $\boldsymbol p -\boldsymbol y$ form, after the manipulation, we impose a zero-mean constraint on $\mathbf{D}'_1$.
%
That is, we analyze the $j^{th}$ element of $\mathbf{D}'_1$~(see Appendix \ref{subsection: Appendix_B.1} for details):
\begin{align}
    \boldsymbol{\omega}_j(\boldsymbol{p}_j-\mathbf{y}_j) =& \boldsymbol{\omega}_t\left({\boldsymbol{p}'_j} - {\mathbf{y}_j}\right) + \left(\sum_k{{\boldsymbol{\omega}_k} {\boldsymbol{p}_k}}-\boldsymbol{\omega}_t\right){\boldsymbol{p}'_j}\label{eq:grad1'},
\end{align}
%
where $\boldsymbol{p}'_j \doteq \frac{\boldsymbol{\omega}_j\boldsymbol{p}_j}{\sum_k \boldsymbol{\omega}_k\boldsymbol{p}_k}$ is the weighted probability, and $\boldsymbol{\omega}_t$ denotes the class-level weight at the target (label) position.
%
We observe that the first term in Eq.~(\ref{eq:grad1'}) satisfies the structure of the gradient of the \textit{Softmax-CrossEntropy} loss, and thus propose to eliminate the second term which messes the structure.
%
Specifically, we let
\begin{equation}
    \label{eq:constraint}
     \sum_k{{\boldsymbol{\omega}_k} {\boldsymbol{p}_k}} - \boldsymbol{\omega}_t = 0\Rightarrow \boldsymbol{\omega}_t = \frac{\sum_{j\neq t}\boldsymbol{\omega}_j \boldsymbol{p}_j}{1 - \boldsymbol{p}_t},
\end{equation}
%
where $\boldsymbol{p}_t$ is the probability of the target class.
%
Note that $\sum_j \boldsymbol{\omega}_j\mathbf{y}_j = \boldsymbol{\omega}_t$, and thus we have
\begin{equation}
    \label{eq:constraint2}
    \sum_j\boldsymbol{\omega}_j(\boldsymbol{p}_j-\mathbf{y}_j) = 0.
\end{equation}
%
This restricts the mean of $\mathbf{D}'_1$ to be zero. 
%
Therefore,  we name this constraint as the \textbf{zero-mean constraint}.
%
With this, we have
\begin{equation}
    \label{eq:d1prime}
\mathbf D_1'= \boldsymbol{\omega}_t \left( \boldsymbol{p}' - \mathbf y\right).
\end{equation}
Eq. (\ref{eq:d1prime}) indicates that $\boldsymbol \omega$ adjust the gradients in two levels, i.e., instance level and class level.
%
Namely, the scalar $\boldsymbol{\omega}_t$ acts as the instance-level weight in previous instance weighting methods~\cite{renLearningReweightExamples2018,shuMetaWeightNetLearningExplicit2019a,huLearningDataManipulation2019a,wangOptimizingDataUsage2020b}, and the $\boldsymbol \omega_j$'s are the class-level weights manipulating gradient flows by adjusting the probability from $\mathbf p$ to $\mathbf p'$. 

\subsection{Efficient Two-stage Weight Generation Embedded in Bi-level Optimization}
\label{subsec:effiBilevel}
%

In this subsection, we first illustrate the three-step bi-level optimization framework in \cite{shuMetaWeightNetLearningExplicit2019a}.
%
Furthermore, we embed a two-stage scheme in the bi-level optimization framework to efficiently obtain class-level weights, with which we manipulate gradient flows and optimize model parameters.

%
\textbf{Three-step Bi-level Optimization.} 
%
Generally, the goal of classification tasks is to obtain the optimal model parameters $\boldsymbol \theta^*$ by minimizing the average loss on $D_{train}$, denoted as $\frac{1}{N}\sum_{i=1}^N l_{train}(x_i, y_i;\boldsymbol \theta)$.
%
As an instance weighting method, \cite{shuMetaWeightNetLearningExplicit2019a} adopt a three-layer MLP parameterized by $\boldsymbol \phi$ as the weighting network and take the loss of the $i^{th}$ instance as input and output a scalar weight $\omega_i$.
%
Then $\boldsymbol \theta^*$ is optimized by minimizing the instance-level weighted training loss:
\begin{equation}
    \label{eq:metaTheta}
    \boldsymbol \theta^*(\boldsymbol \phi) = \mathop{\arg\min}_{\boldsymbol \theta} \frac{1}{N}\sum_{i=1}^N\omega_i(\boldsymbol \phi)l_{train}(x_i, y_i;\boldsymbol \theta).
\end{equation}
%
To obtain the optimal $\omega_i$, they propose to use a meta set as meta-knowledge and minimize the meta-loss to obtain $\boldsymbol \phi^*$:
\begin{equation}
    \label{eq:metaPhi}
    \boldsymbol \phi^* = \mathop{\arg\min}_{\boldsymbol \phi}\frac{1}{M}\sum_{i=1}^M l_{val}(x_i^v, y_i^v;\boldsymbol \theta^*(\boldsymbol \phi)).
\end{equation}
%
Since the optimization for $\boldsymbol \theta^*(\boldsymbol \phi)$ and $\boldsymbol \phi^*$ is nested, they adopt an online strategy to update $\boldsymbol \theta$ and $\boldsymbol \phi$ with a three-step optimization loop for efficiency.
%
Denote the two sets of parameters at the $\tau^{th}$ loop as $\boldsymbol \theta _\tau$ and $\boldsymbol \phi _\tau$ respectively, and then the three-step loop is formulated as:
\begin{enumerate}[label=\textbf{Step \arabic*}]
    \item Update $\boldsymbol \theta_{\tau-1}$ to $\hat {\boldsymbol \theta}_\tau(\boldsymbol \phi)$ via an SGD step on a mini-batch training set by Eq. (\ref{eq:metaTheta}).
    \item With $\hat{\boldsymbol \theta}_\tau (\boldsymbol \phi)$, update $\boldsymbol \phi _{\tau-1}$ to $\boldsymbol \phi _\tau$ via an SGD step on a mini-batch meta set by Eq. (\ref{eq:metaPhi}).
    \item With $\boldsymbol \phi _\tau$, update $\boldsymbol \theta_{\tau-1}$ to $\boldsymbol \theta_\tau$ via an SGD step on the same mini-batch training set by Eq. (\ref{eq:metaTheta}).
\end{enumerate}
%
Instance weights in \textbf{Step 3} are better than those in \textbf{Step 1}, and thus are used to update $\boldsymbol \theta_{\tau-1}$.
%
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/flow_chart.png}
    \caption{Two-stage Weight Generation. "BP" denotes the back-propagation in \textbf{Step 2} of the bi-level optimization framework. $\mathbf g$ denotes the intermediate gradients w.r.t. $\boldsymbol \omega$. $\ominus$ denotes the minus operator. Note that $\boldsymbol \omega$ is the first-stage (instance-level) weight and $\boldsymbol \omega'$ is the second-stage (class-level) weight.}
    \label{fig:flowChart}
\end{figure}

\textbf{Two-stage Weight Generation.} 
%
To guarantee scalability, we apply the same weighting network in \cite{shuMetaWeightNetLearningExplicit2019a} to obtain weights.
%
To efficiently train $\boldsymbol \phi$ and $\boldsymbol \theta$, we also adopt the three-step bi-level optimization framework.
%
Moreover, we propose an efficient two-stage scheme embedded in \textbf{Step 1-3} to generate class-level weights.
%
This process does not introduce any extra computational cost compared to \cite{shuMetaWeightNetLearningExplicit2019a}.
%
We keep the notations of $\boldsymbol \theta_\tau$ and $\boldsymbol \phi_\tau$ unchanged.

%
The first stage is embedded in \textbf{Step 1}.
%
Explicitly, we obtain the first-stage class-level weights $\boldsymbol \omega_i = \omega_i \boldsymbol 1$, by cloning the output of the weighting network for $C$ times.
%
Then we leverage the cloned weights $\boldsymbol \omega_i$ to manipulate gradients and update $\boldsymbol \theta$ with a mini-batch of training instances:
\begin{equation}
    \label{eq:thetaHat}
    \hat {\boldsymbol\theta}_\tau \left(\boldsymbol \phi _{\tau-1}\right) \leftarrow \boldsymbol \theta_{\tau-1} - \eta_{\boldsymbol \theta} \frac{1}{n}\sum_{i=1}^{n}f_{\boldsymbol \omega _i\left(\boldsymbol \phi _{\tau-1}\right)} \left(\nabla_{\boldsymbol \theta} l_{train}(x_i, y_i;\boldsymbol \theta_{\tau-1})\right),
\end{equation}
where $n$ is the mini-batch size, $\eta_{\boldsymbol \theta}$ is the learning rate of $\boldsymbol \theta$, and $f_{\boldsymbol \omega _i\left(\boldsymbol \phi _{\tau - 1} \right)}(\cdot)$ is the gradient manipulation operation defined in Eq. (\ref{eq:newGrad}).

%
The second stage is embedded in \textbf{Step 2} and \textbf{Step 3}.
%
Specifically in \textbf{Step 2}, GDW optimizes $\boldsymbol \phi$ with a mini-batch meta set:
\begin{equation}
    \label{eq:phi}
    \boldsymbol \phi _{\tau} \leftarrow \boldsymbol \phi _{\tau-1} - \eta_{\boldsymbol \phi} \frac{1}{m} \sum_{i=1}^{m} \nabla_{\boldsymbol \phi _{\tau-1}} l_{meta}(x_i^v, y_i^v;\hat{\boldsymbol \theta} _\tau(\boldsymbol \phi_{\tau-1})),
\end{equation}
where $m$ is the mini-batch size and $\eta_{\boldsymbol \phi}$ is the learning rate of $\boldsymbol \phi$. 
%
During the back-propagation in updating $\boldsymbol \phi_\tau$, GDW generates the second-stage weights using the intermediate gradients $\mathbf g_i$ on $\boldsymbol \omega_i$. 
%
Precisely,
\begin{equation}
    \label{eq:newOmega}
    \boldsymbol \omega'_i = \boldsymbol \omega_i - \eta_{\boldsymbol\omega}  \rm{clip}(\frac{\mathbf{g_i}}{\|\mathbf{g_i}\|_1}, -c, c),
\end{equation}
where $\mathbf{g_i}$ represents $\frac{1}{m}\sum_{i=1}^m\nabla_{\boldsymbol\omega_i} l_{meta}(x_i^v, y_i^v;\hat{\boldsymbol \theta}_\tau(\boldsymbol \phi_{\tau-1}))$ and $c=0.2$ denotes the clip parameter.
%
Then we impose the zero-mean constraint proposed in Eq. (\ref{eq:constraint}) on $\boldsymbol \omega'_i$, which is later used in \textbf{Step 3} to update $\boldsymbol \theta_{\tau-1}$.
%
Note that the two-stage weight generation scheme does not introduce any extra computational cost compared to MWNet because this generation process only utilizes the intermediate gradients during the back-propagation.
%
In \textbf{Step 3}, we use $\boldsymbol \omega'_i$ to manipulate gradients and update the model parameters $\boldsymbol \theta_{\tau-1}$:
\begin{equation}
    \label{eq:newTheta}
    \boldsymbol \theta_\tau \leftarrow\boldsymbol \theta_{\tau-1} - \eta_{\boldsymbol \theta} \frac{1}{n} \sum_{i=1}^{n} f_{\boldsymbol \omega'_{i}}\left(\nabla_{\boldsymbol \theta} l_{train}(x_i, y_i;\boldsymbol \theta_{\tau-1})\right).
\end{equation}
%
The only difference between \textbf{Step 1} and \textbf{Step 3} is that we use $\boldsymbol \omega'_i$ instead of the cloned output of the weighting network $\boldsymbol \omega_i$ to optimize $\boldsymbol \theta$.
%
Since we only introduce $\boldsymbol \phi$ as extra learnable parameters, GDW can scale to large datasets.
%
We summarize GDW in Algorithm \ref{alg:GDW}.
%
Moreover, we visualize the two-stage weight generation process in Figure~\ref{fig:flowChart} for better demonstration.

%
\begin{algorithm}
\caption{Generalized Data Weighting via Class-Level Gradients Manipulation}\label{alg:GDW}
\hspace*{\algorithmicindent} \textbf{Input:} Training set: $D_{train}$, Meta set: $D_{meta}$, batch size $n,m$, \# of iterations $T$ \\
\hspace*{\algorithmicindent} Initial model parameters: $\boldsymbol \theta_0$, initial weighting network parameters: $\boldsymbol \phi_0$\\
\hspace*{\algorithmicindent} \textbf{Output:} Trained model: $\boldsymbol \theta_T$
\begin{algorithmic}[1]
\For{$\tau \leftarrow1$ \textbf{to} $T$}

\State $\{x_i, y_i\}_{i=1}^n\leftarrow$ SampleFrom$(D_{train})$
\State $\{x_i^v, y_i^v\}_{i=1}^m\leftarrow$ SampleFrom$(D_{meta})$
\State Generate $\boldsymbol \omega_i$ from $\mathcal{L}_i$ via the weighting network parameterized by $\boldsymbol \phi _{\tau-1}$
\State Manipulate gradients by Eq. (\ref{eq:newGrad}) and update $\hat{\boldsymbol \theta}_\tau$ by Eq. (\ref{eq:thetaHat})
\State Update $\boldsymbol \phi_\tau$ by Eq. (\ref{eq:phi}); 
\State Update $\boldsymbol \omega_i$ to $\boldsymbol \omega'_i$ by Eq. (\ref{eq:newOmega}) and constrain $\boldsymbol \omega'_i$ by Eq. (\ref{eq:constraint})
\State Manipulate gradients with $\boldsymbol \omega'_i$ by Eq. (\ref{eq:newGrad}) and update $\boldsymbol \theta_\tau$ by Eq. (\ref{eq:newTheta})
\EndFor
\end{algorithmic}
\end{algorithm}




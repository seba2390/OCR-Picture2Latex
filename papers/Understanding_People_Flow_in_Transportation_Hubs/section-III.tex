\section{Sensing Infrastructure and Data Descriptor}
\label{sec:sensing}
%
To characterize the X-ray queue area, we want to capture the occupancy pattern of the passengers over time. 
As we will see in Section \ref{sec:params}, counting people at the entrance or exit of the queue is not enough to understand the state and shape of the queue. Also, individually tracking people in such a large area is unreliable, due to frequent occlusion of passengers. We propose a descriptor 
that captures the dynamics of the space and is robust to misdetections.
We present here a sensing infrastructure and, based on 3D data processing, the proposed descriptor.

Fig. \ref{fig:rx-cams-fov} depicts the network of depth cameras installed to cover the final stage of the queue area.
\begin{figure}[tbh]
\centering
\includegraphics[width=0.38\textwidth]{./imgs/rx-cams-fov.pdf}
\caption{Camera setup in the X-ray queue with corresponding field of view (FOV). Each colored triangle represents the FOV of a different camera. Passengers enter from the right and exit on the left.}
\label{fig:rx-cams-fov}
\end{figure}
%
Cameras are calibrated and 3D point clouds are registered into a global reference frame. 
So, from depth images provided by the seven cameras (Fig. \ref{fig:img-depth}), we build a global 3D representation of the space (Fig. \ref{fig:pcl-rx-pre}).
%
\begin{figure}[tbh]
\centering
\subfloat[Depth image]{\includegraphics[width=0.14\textwidth]{./imgs/rx-cam5.png}
\label{fig:img-depth}}
\subfloat[3D point cloud of people standing]{\includegraphics[width=0.3\textwidth]{./imgs/pcl-rx-pre-seg_17_cropped.png}
\label{fig:pcl-rx-pre}}
\caption{Depth image and 3D representation: (a) Depth image from one of the cameras placed at the X-ray queue area at the Lisbon International Airport. The value of each pixel represents the depth of the object rather than its brightness or color. The colors are indexed to the distance to the camera, from blue (closer) to dark red (further). Dark blue represents areas not visible by the camera. (b) 3D representation of the space. Colors range from dark blue, for points closer to the ground plane, to dark red, for points further from the ground plane.}
\label{fig:3d-data}
\end{figure}%
%
Since we have a noisy sensor and multiple objects in the foreground, we used a procedure we developed in \cite{carvalho2016detecting} to detect people in 3D point clouds (Section \ref{sec:detection}).
%
Using the results of this detection procedure, we compute a ground occupancy map and use it as a descriptor for the passenger flow (Section \ref{sec:occ_map}).
%
\subsection{People Detection}
\label{sec:detection}
%
The method takes a 3D point cloud as input (Fig. \ref{fig:pcl-rx-pre}) and outputs the 3D points and centroids corresponding to each person. Fig. \ref{fig:pcl-rx-detections} shows the 3D point clouds classified as ``person'', with one color per person, and Fig. \ref{fig:people-centroids} shows the centroid of each person projected on the ground plane.
\begin{figure}[htb]
\centering
\subfloat[People detections]{\includegraphics[width=0.27\textwidth]{./imgs/pcl-rx-detections_17_cropped.png}
\label{fig:pcl-rx-detections}}
\subfloat[People centroids project on the floor]{\includegraphics[width=0.15\textwidth]{./imgs/people-centroids_17.pdf}
\label{fig:people-centroids}}
\caption{People detection method results: (a) point cloud of the people detection, with one color per person; (b) centroids $(x,y)$ of each detection.}
\label{fig:detection-out}
\end{figure}

The 3D space is scanned with a fixed size box and the point cloud falling within that volume is classified as \emph{person} or \emph{not person}.
The classifier, based on random trees, was trained with point clouds including people in different poses relative to the camera.
From each candidate point cloud, we compute its height, volume and the area occupied by the projection into the ground plane.
The output of this method is the labeling of the point cloud and the corresponding centroids in ground coordinates, $(x_i, y_i)$ for person $i$, as shown in Fig. \ref{fig:detection-out}.
For further details, including training process and performance, see \cite{carvalho2016detecting}.
%
\subsection{Queue Pattern Descriptor}
\label{sec:occ_map}
We characterize the shape of the pedestrian flow using an occupancy map as data descriptor for the queue state. 
We build this occupancy map from the centroids $(x_i, y_i)$ output from the people detection method.
%
The floor is discretized into a fixed size grid and we obtain a binary map where each cell of the map is set to $1$ if occupied and $0$ otherwise. 
A cell is occupied if a centroid falls into it.
Fig. \ref{fig:binary-buffer} shows a set of these binary maps, from frame $f-n$ to $f$, where each dot corresponds to a occupied cell in the map.

The occupancy map of a given time period is the spatio-temporal average of the set of binary maps for that same period\footnote{A map can be instantaneous or integrated into longer periods, such as $30s, 1min, 5min, 1h.$}. 
We could apply other filters to the buffer of binary maps, however, we found that using the spatio-temporal average successfully captures the shape of pedestrian flow.
Fig. \ref{fig:occ-map} shows an example of an occupancy map. 
This map is a vector in $\mathbb{R}^{d}$ that evolves in time, depending on the space usage, where $d$ is the number of spatial cells of the map. 
%%
\begin{figure}[hbt]
\centering
\subfloat[]{\includegraphics[width=0.14\textwidth]{./imgs/binary-buffer.pdf}
\label{fig:binary-buffer}}
\hspace{3mm}
\subfloat[]{\includegraphics[width=0.1\textwidth]{./imgs/occ_map_ex.png}
\label{fig:occ-map}}
\caption{Occupancy maps: (a) buffer of binary maps with dark red cells if occupied and white otherwise; (b) occupancy map for $5min$ sized buffer. The colors range from dark blue, for the null value, to dark red, for the maximum value of the map.}
\end{figure}
%

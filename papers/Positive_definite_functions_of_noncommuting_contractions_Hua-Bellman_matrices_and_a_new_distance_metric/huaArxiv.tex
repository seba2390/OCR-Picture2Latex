\documentclass[11pt]{article}
\include{header}
\usepackage{ss}       % SS Arxiv style file - Loads many packages
\include{macros}




\begin{document}
\title{Positive definite functions of noncommuting contractions, Hua-Bellman matrices, and a new distance metric}
\author{\name{Suvrit Sra} \email{suvrit@mit.edu}\\ \addr{LIDS, Massachusetts Institute of Technology, Cambridge, MA, USA}}

\maketitle


\begin{abstract}
  We study positive definite functions on noncommuting strict contractions. In particular, we study functions that induce positive definite Hua-Bellman matrices (i.e., matrices of the form $[\det(I-A_i^*A_j)^{-\alpha}]_{ij}$ where $A_i$ and $A_j$ are strict contractions and $\alpha\in\C$). We start by revisiting a 1959 work of \citeauthor{bellman1959} (R.~Bellman~\emph{Representation theorems and inequalities for Hermitian matrices}; Duke Mathematical J., 26(3), 1959) that studies Hua-Bellman matrices and claims a strengthening of \citeauthor{hua1955}'s representation theoretic results on their positive definiteness~(L.-K. Hua, \emph{Inequalities involving determinants}; Acta Mathematica Sinica, 5(1955), pp.~463--470). We uncover a critical error in Bellman's proof that has surprisingly escaped notice to date. We ``fix'' this error and provide conditions under which $\det(I-A^*B)^{-\alpha}$ is a positive definite function; our conditions correct Bellman's claim and subsume both Bellman's and Hua's prior results. Subsequently, we  build on our result and introduce a new hyperbolic-like geometry on noncommuting contractions, and remark on its potential applications.
\end{abstract}

\section{Introduction}
We study an important positive definite function on strictly contractive complex matrices, namely, $\det(I-Z)^{-\alpha}$, where $\|Z\| < 1$ and $\alpha \in \reals$. This function arises in a variety of contexts, including multivariable complex analysis~\citep{hua1955}, non-Euclidean geometry~\citep{sra2016}, mathematical optimization~\citep{sra2015}, combinatorics~\citep{branden2012,verejones1988}, probability theory~\citep{shirai2007}, and matrix analysis~\citep{fzhang2009,xuXu2009,ando2008}, among others.

More specifically, we study conditions under which $(A,B) \mapsto \det(I-A^*B)^{-\alpha}$ is a \emph{kernel function}, i.e., a function that admits an inner-product representation $\ip{\Phi_\alpha(A)}{\Phi_\alpha(B)}$. The study of such functions has a long history in mathematics, dating back at least to \citet{szego1933}, who studied the closely related question about positivity of Taylor series coefficients for $P^{-\alpha}$ for the polynomial $P(x) = \sum_{i=1}^n\prod_{j\neq i}(1-x_j)$. This question for other polynomials such as the determinantal polynomial $P(x) = \det(\sum_i x_iA_i)$  was revisited and closely studied by~\citet{scott2014}, who in particular approached it via complete monotonicity; their results form the basis of \citet{branden2012}'s results, which we will also build upon later in the paper.

There is an additional, different motivation behind our study. The starting point is an elegant block-matrix identity discovered by Loo-Keng Hua~\citep{hua1955}, which, for strict contractions $A$ and $B$ states that
\begin{equation*}
  I-B^*B + (A-B)^*(I-A^*A)^{-1}(A-B) = (I-A^*B)(I-AA^*)^{-1}(I-B^*A).
\end{equation*}
Hua's identity immediately implies the positive definiteness of the block matrix
\begin{equation*}
  \begin{bmatrix}
    \inv{(I-A^*A)} & \inv{(I-A^*B)}\\
    \inv{(I-B^*A)} & \inv{(I-B^*B)}
  \end{bmatrix},
\end{equation*}
a property that is otherwise not necessarily obvious. Subsequent to Hua's discovery, various other works, e.g.,~\citep{marcus1958}, \citep{bellman1959}, \citep{ando1980}, ~\citep{xuXu2009,xuXu2011}, and~\citep{fzhang2009}, among others, continued the study of Hua-like block matrices and operator inequalities induced by them.  %investigations. More recently, other authors also studied Hua-like matrix identities and inequalities, and several related questions were raised in~\citep{fzhang2009}.
Beyond Hua's work~\citep{hua1955}, a common  denominator of research on this topic has been~\citet{bellman1959}'s work that studies Hua matrices through the lens of positive definite functions. % This paper answers several (open) questions related to Hua-like matrices and inequalities. In particular, it answers a question of Bellman~\citep{bellman1959}; subsequently, it provides counterexamples to several conjectures proposed in~\citep{fzhang2009}. The paper also provides an elementary supplement to Bellman's determinantal inequalities by allowing complex matrices (for the setting where Bellman assumed real matrices), which also corrects a technical error in Bellman's original 1959 proof, which seems to have been overlooked so far.

In particular, \citet{bellman1959} claims that for \emph{contractive} real matrices $A_1,\ldots,A_m$ of size $n\times n$, the \emph{Hua-Bellman} matrix
\begin{equation}
  \label{eq:1}
  H_\alpha := [\det(I-A_i^TA_j)^{-\alpha}]_{i,j=1}^m,
\end{equation}
is positive definite for $\alpha$ being a half-integer $\alpha = j/2$ and for real $\alpha > \half(n-1)$. This positive definiteness is tantamount to $\det(I-A^*B)^{-\alpha}$ being a positive definite kernel function for the noted choice of $\alpha$. %said range of values by $\alpha$. % In his 1959 paper, Bellman wondered: \begin{quote}  \emph{``What the precise exponent should be is not clear.''}  \end{quote}
% More recently, \cite{fzhang2009} posed a series of questions regarding Hua-like matrices, and one of these questions generalizes Bellman's question to deal with strictly contractive rectangular complex matrices, and asks whether $H_\alpha \succeq 0$ for all real $\alpha \ge 0$ or whether it holds only for a subset of the positive reals. A question common to Bellman and Zhang is the following:
% \begin{ques}
% Determine the exponents $\alpha$ for which $H_\alpha \ge 0$.  
% \end{ques}
% We answer the above question by characterizing the values of $\alpha$ for which the Hua-like matrix $H_\alpha$ is positive definite.
Bellman claims to offer a significant simplication and generalization to \citet{hua1955}'s work that had already shown $H_\alpha \succeq 0$ for $n\times n$ complex contractions for $\alpha > n-1$ (Hua's result is based on representation theoretic ideas combined with multivariable complex analysis.). % uses group theoretical ideas. We provide an alternative proof below. (i) Bellman's original conclusion is \textbf{FALSE!}; we do not limit ourselves to real matrices and allow complex matrices.

While Bellman's investigation via integral representations of $\det(A)^{-\alpha}$ is foundational, unfortunately, his proof contains an error that also invalidates subsequent works that build on his claims. We uncover this old error bleow, and study the function $\det(I-A^*B)^{-\alpha}$ afresh, ultimately leading to Theorem~\ref{thm:main} that presents the most general conditions (known to us)  ensuring its positive definiteness. Subsequently, in Theorem~\ref{thm:dist} we present a closely related hyperbolic-like geometry on noncommuting strict contractions that is suggested by Hua-Bellman matrices. 

\subsection{Uncovering an old error}
\begin{claim}[\textbf{Theorem 3} in~\cite{bellman1959}]
  \label{claim:bellman}
  Let $A_1,\ldots,A_m$ be strictly contractive real matrices. Then, the matrix
  \begin{equation}
    \label{eq:bell}
    H_{k/2} = \left[\frac{1}{\det(I-A_i^TA_j)^{k/2}} \right]_{i,j=1}^m,
  \end{equation}
  is positive semidefinite for all integers $k\ge 1$.
\end{claim}
\noindent To prove this claim Bellman begins with the Gaussian integral representation %\begin{equation*}
$\frac{1}{\det(A)^{1/2}}  \propto \int_{\reals^m} e^{-x^TAx}dx$, %\end{equation*}
for a real symmetric positive definite matrix $A$. Then, on \citep[pg.~488, (7.6)]{bellman1959} Bellman recalls an inequality of~\citet{ostrow1951}:
\begin{equation}
  \label{eq:6}
  \det(I-A_i^TA_j) \ge \det(I - (A_i^TA_j)_s),
\end{equation}
where $X_s := \half(X+X^T)$. Subsequently, he  states that (\emph{sic.} Theorem) Claim~\ref{claim:bellman} ``{\it
  \ldots will be demonstrated if we prove that $[\det(I - (A_i^TA_j)_s)^{-k/2}]$ is positive semidefinite.''}

\vskip6pt
\noindent This location is where the error lies: just because inequality~\eqref{eq:6} holds, from positive definiteness of $[\det(I - (A_i^TA_j)_s)^{-k/2}]$ we cannot conclude that $H_{k/2}$ is also positive definite, since the former matrix only dominates $H_{k/2}$ entrywise, not in terms of its eigenvalues. The following counterexample makes this explicit.
\begin{center}
\rule{6cm}{0.4pt}

\textbf{Counterexample}
\vskip-4pt
\rule{6cm}{0.4pt}
\begin{small}
  \begin{equation*}
    \begin{split}
      (A_j)_{j=1}^6=\biggl(
        \begin{bmatrix}
          -2 & -9\\
          -5 & -10
        \end{bmatrix}, 
        \begin{bmatrix}
          9 & -5\\
          9 & 6
        \end{bmatrix},
        &\begin{bmatrix}
          -10 & -3\\
          -6  & 3
        \end{bmatrix},
        \begin{bmatrix}
          -8 &-8\\
          1  &-10
        \end{bmatrix},
        \begin{bmatrix}
          -2 & 1\\
          -6 &-1
        \end{bmatrix},
        \begin{bmatrix}
          -1 & 3\\
          10 &-6
        \end{bmatrix}
      \biggr)\\
      A_j &\gets \frac12 \frac{A_j}{\norm{A_j}}\quad\text{for}\ 1\le j\le 6,\\
      \lambda_{\min}([\det&(I-A_i^TA_j)^{-1/2}]) \approx -1.2066 \times 10^{-3}.
    \end{split}
  \end{equation*}
\end{small}
\rule{10cm}{0.4pt}
\end{center}
\noindent\emph{Remark:} We found that the larger the number $m$ of matrices, the easier it is to generate a counterexample; however, we could  not yet generate a counterexample for $m=5$. 

Given this counterexample, the immediate question is \emph{whether Bellman's motivation to generalize Hua's claim ($\alpha > n-1$ ensures that $H_\alpha \succeq 0$) can be still rescued?} We answer this question below and show that it is indeed possible to generalize Hua's result, and thereby uncover a deep and rich relation of $\det(I-A^*B)^{-\alpha}$ to combinatorics and the theory of positive definite functions. While we provide sufficient conditions on $\alpha$, we believe that they might also be necessary.

\section{Positive definite functions on noncommuting contractions}
In this section we present results characterizing the positive definiteness of Hua-Bellman matrices. To that end, we study the corresponding function $\det(I-A^*B)^{-\alpha}$ on $A, B \in \Cc_n$, the class of $n\times n$ strictly contractive (in operator norm) complex matrices. We provide  sufficient conditions on $\alpha$ to ensure its positive-definiteness that are defined using the following two sets of possible exponents:
\begin{align*}
  D_{\reals} &:= \{-(m+1) \mid m \in \mathbb{N}\} \cup \{\tfrac{m+1}{2} \mid m \in \mathbb{N}\} \cup \{0\},\\
  D_{\C}     &:= \{\pm(m+1) \mid m \in \mathbb{N}\} \cup \{0\}.
\end{align*}
Our definitions of $D_{\reals}$ and $D_{\C}$ follow~\citep{branden2012}, though after inverting the elements to align with our presentation better. The first main result of this section is:
\begin{theorem}
  \label{thm:main}
  Let $A, B \in \Cc_n$. Then, $\det(I-A^*B)^{-\alpha}$ is a positive definite function for $\alpha \in D_{\C} \cup \{x \in \reals \mid x > n-1\}$. If $A$ and $B$ are in addition real, then $\det(I-A^TB)^{-\alpha}$ is positive definite for $\alpha \in D_{\reals} \cup \{x\in \reals \mid x > n-1\}$.
\end{theorem}
\noindent The key ingredient in our proof of Theorem~\ref{thm:main} is the $\alpha$-permanent, which we now recall. % We recall its definition and relevant properties below. 

\subsection{$\alpha$-permanents}
The $\alpha$-permanent generalizes the matrix permanent and determinant, and was introduced by~\citet{verejones1988}. Let $\alpha\in \C$ and $A=(a_{ij})$ be an $n\times n$ matrix. Then, the \emph{$\alpha$-permanent} is defined as
\begin{equation}
  \label{eq:2}
  \aper(A) := \sum_{\sigma \in \mathfrak{S}_n} \alpha^{\myhash\sigma}\prod_{i=1}^n a_{i,\sigma(i)},%\quad\text{and} \adet(A) := \alpha^n\per_{1/\alpha}(A),
\end{equation}
where $\myhash\sigma$ denotes the number of disjoint cycles in the permutation $\sigma$. This object interpolates between the determinant and permanent, and enjoys a variety of applications and connections; see e.g.,~\citep{shirai2007,crane2013,frenkel2009}.

The first key property of $\alpha$-permanents that we will need is an inner-product based representation derived in Lemma~\ref{lem:perip}.
\begin{lemma}
  \label{lem:perip}
  Let $A$, $B$ be arbitrary square $n\times n$ matrices and $\alpha \in \C$. Then, $\aper(A^*B)$ can be written as a linear combination of inner products, i.e., there exist constants $c_1,c_2,\ldots,$ such that $\aper(A^*B) = \sum_j c_j\ip{\psi_j(A)}{\psi_j(B)}$ for some nonlinear maps $\{\psi_j\}_{j \ge 1}$.
  % \begin{equation}
  %   \label{eq:24}
  %   \aper(A^*B) = \langle \psi_\alpha(A), \psi_\alpha(B)\rangle,
  % \end{equation}
  % for some nonlinear map $\psi$ that maps its argument to some (unspecified) Hilbert space.
\end{lemma}
\begin{proof}
  Our proof relies on the (known) observation that the $\alpha$-permanent can be written in terms of immanants. To see how, let $\lambda \vdash n$ denote that $\lambda$ is a partition of the integer $n$. The \emph{immanant} of $A$ indexed by $\lambda$ is defined as (see~\citep{merris1997} for details)
  \begin{equation}
    \label{eq:25}
    d_\lambda(A) := \nlsum_{\sigma \in \mathfrak{S}_n} \chi_\lambda(\sigma) \nlprod_{i=1}^n a_{i,\sigma(i)},
  \end{equation}
  where $\chi_\lambda(\sigma)$ is the character associated to the irreducible representation $S^\lambda$, the Specht module corresponding to $\lambda \vdash n$---see~\citep{fulton2013} for details. Then, \citet[Eq.~(12)]{crane2013} shows that for each $\lambda$, there exist constants $c_\lambda^\alpha$ such that:\footnote{\citep[Theorem~2.4]{crane2013} notes that $c_\lambda^\alpha = \frac{1}{n!}\sum_{\sigma \in \mathfrak{S}_n} \alpha^{\myhash\sigma}\chi_\lambda(\sigma)$.}
  \begin{equation}
    \label{eq:26}
  \per_\alpha(A) = \nlsum_{\lambda \vdash n} c_\lambda^\alpha d_\lambda(A).
  \end{equation}
  Further, we know from multilinear matrix theory~\citep{merris1997} that for each $\lambda \vdash n$, there exists a projection $P_\lambda$ such that $d_\lambda(X)=\trace P_\lambda^* A^{\kron n}P$. Thus, we may write
  \begin{equation}
    \label{eq:27}
    d_\lambda(A^*B) = \trace P^*(A^*B)^{\kron n}P = \trace P^*(A^{\otimes d})^*(A^{\otimes d})P =: \ip{\psi_\lambda(A)}{\psi_\lambda(B)}.
  \end{equation}
  Plugging in representation~\eqref{eq:27} into identity~\eqref{eq:26} we obtain the identity
  \begin{align*}
    \per_\alpha(A^*B) = \nlsum_{\lambda \vdash n} c_\lambda^\alpha \ip{\psi_\lambda(A)}{\psi_\lambda(B)},
  \end{align*}
  which shows that $\aper(A^*B)$ is indeed a weighted sum of inner products.
\end{proof}

While Lemma~\ref{lem:perip} shows that $\aper(A^*B)$ can be written as a weighted sum of inner products, in general, this sum need not correspond to a usual (positive definite) inner product. In particular, it is not obvious when is $\aper(A^*A) \ge 0$. This rather nontrivial property was characterized by~\citep{branden2012} by building on the complete monotonicity theory established in~\citep{scott2014}; we recall the relevant result below.
\begin{theorem}[Theorem~2.3~\citep{branden2012}]
  \label{thm:branden2}
  Let $\alpha \in \reals$. Then, $\aper(A) \ge 0$ if and only if (i) $\alpha \in D_{\mathbb{R}}$ for $A$ real, symmetric positive definite; or (ii) $\alpha \in D_{\mathbb{C}}$ for $A$ Hermitian positive definite.
\end{theorem}
\noindent This theorem sheds light on the choice of $\alpha$ presented in Theorem~\ref{thm:main}. In addition to Lemma~\ref{lem:perip} and Theorem~\ref{thm:branden2}, our proof of Theorem~\ref{thm:main} relies on the following generalization of MacMahon's Master Theorem.
\begin{theorem}[\citep{verejones1988,branden2012}]
  \label{thm:mac}
  Let $\vm=(m_1,\ldots,m_n) \in \mathbb{N}^n$ and $A=[a_{ij}]_{i,j=1}^n$. Let $A[\vm]$ be the $|\vm|\times |\vm|$ matrix with $|\vm|=\nlsum_{j=1}^n m_j$, obtained by replacing the $(i,j)$-entry of $A$ by the $m_i\times m_j$ matrix $a_{ij}\bm{1}_{m_i}\bm{1}^T_{m_j}$. Let $X=\Diag(x_1,\ldots,x_n)$ and $\alpha \in \C$. Then,
  \begin{equation}
    \label{eq:3}
    \det(I - XA)^{-\alpha} = \sum_{\vm \in \mathbb{N}^n}\frac{\bm{x}^{\vm}}{\vm!}\per_\alpha(A[\vm]),
  \end{equation}
  where $\bm{x}^{\vm}=x_1^{m_1}\cdots x_n^{m_n}$ and $\vm!=m_1!\cdots m_n!$.
\end{theorem}
Theorem~\ref{thm:mac} writes the Taylor series of $\det(I-XA)^{-\alpha}$ using $\alpha$-permanents, and the conditions on $\alpha$ stipulated by Theorem~\ref{thm:branden2} ensure that all the coefficients of this series are nonnegative (provided $A$ is positive semidefinite), and therefore help establish the desired positive definiteness property, as elaborated in the proof below.
%\begin{theorem}
%  Let $A_i \in \reals^{m \times m}$ for $1\le i \le n$ be strictly contractive symmetric matrices. Then, the Hua-matrix $H_k=[\det(I-A_i^TA_j)^{-k}]$ is positive definite for $k \in \mathbb{N}$.
%\end{theorem}


\subsection{Proof of Theorem~\ref{thm:main}}
First, recall from \citep{hua1955} that if $\alpha > n-1$, then $\det(I-A^*B)^{-\alpha}$ is a positive definite function, a result that holds for complex contractions (and thus \emph{a forteriori} also for real ones). What remains to prove is the extended range of $\alpha$ values claimed in Theorem~\ref{thm:main}. The main idea to establish this extended range is to invoke Theorem~\ref{thm:mac}, and use it to represent $\det(I-A^*B)^{-\alpha}$ as the inner-product $ \ip{\Phi_\alpha(A)}{\Phi_\alpha(B)}$, where $\Phi_\alpha$ is a  nonlinear map that maps its argument to some Hilbert space. In other words, we build on Theorem~\ref{thm:mac} to prove that $\det(I-A^*B)^{-\alpha}$ is a \emph{kernel function}, and as a result, obtain positive definiteness of associated Hua-Bellman matrices. 

% \begin{enumerate}[leftmargin=1.3cm,label=\itshape{}Step~(\roman*)]
\vskip5pt
\noindent The first step is to realize that $A[\vm] = Q_{\vm}^*(A\otimes \bm{11}^T)Q_{\vm}$ for matrices $Q_{\vm}$ and $\bm{11}^T$ of appropriate sizes. Let $E_{ij}$ denote the $m_i \times m_j$ matrix of all ones, and $\bm{11}^T=E=[E_{ij}]_{i,j=1}^n$ the corresponding block matrix.\footnote{To reduce notational burden, we let the dependency of blocks of $E$ on $\vm$ remain implicit.} Then, consider the Khatri-Rao product between conformally partitioned matrices $A$ and $E$:
\begin{equation}
  \label{eq:4}
  A \ast E =
  \begin{bmatrix}
    a_{11}\kron E_{11} & \cdots  & a_{1n}\kron E_{1n}\\
    \vdots & \ddots & \vdots \\
    a_{n1} \kron E_{n1} & \cdots & a_{nn}\kron E_{nn}
  \end{bmatrix},
\end{equation}
which is nothing but $A[\vm]$ since $a_{ij}\kron E_{ij} = a_{ij}E_{ij}$. From basic properties of Khatri-Rao products~\citep{liu2008} it then follows that there exists a matrix $Q_{\vm}$ such that $A[\vm]=Q_{\vm}^*(A\kron E)Q_{\vm}$. To see this identification explicitly, let $Q_{\vm}$ be the diagonal matrix $\Diag(U^{\vm}_1,\ldots,U^{\vm}_n)$, where the $U^{\vm}_i$ are suitable subsets of the identity matrix such that $U^{\vm}_i{}^*EU^{\vm}_j=E_{ij}$. Then,
\begin{small}
  \begin{align}
    \nonumber
    Q_{\vm}^*(A\kron E)Q_{\vm} &= \begin{bmatrix}
      U^{\vm}_1{}^* && \\
      & \ddots & \\
      && U^{\vm}_n{}^*
    \end{bmatrix} 
    \begin{bmatrix}
      a_{11}E & \cdots  & a_{1n}E\\
      \vdots & \ddots & \vdots \\
      a_{n1}E & \cdots & a_{nn}E
    \end{bmatrix}
    \begin{bmatrix}
      U^{\vm}_1 && \\
      & \ddots & \\
      && U^{\vm}_n
    \end{bmatrix}\\
    \label{eq:5}
    &=
    \begin{bmatrix}
      a_{11}U^{\vm}_1{}^*EU^{\vm}_1 & a_{12}U^{\vm}_1{}^*EU^{\vm}_2 & \cdots a_{1n}U^{\vm}_1{}^*EU^{\vm}_n\\
      \\
      a_{n1}U^{\vm}_n{}^*EU^{\vm}_1 & a_{n2}U^{\vm}_n{}^*EU^{\vm}_2 & \cdots a_{nn}U^{\vm}_n{}^*EU^{\vm}_n
    \end{bmatrix}\\
    &=\begin{bmatrix}
      a_{11}E_{11} & \cdots  & a_{1n}E_{1n}\\
      \vdots & \ddots & \vdots \\
      a_{n1}E_{n1} & \cdots & a_{nn}E_{nn}
    \end{bmatrix}=A[\vm].
  \end{align}
\end{small}

Next, using~\eqref{eq:3} we see that
$\det(I-XA^*B)^{-\alpha} = \sum_{\vm \in \mathbb{N}^n}\frac{\bm{x}^{\vm}}{\vm!}\per_\alpha\bigl( (A^*B)[\vm]\bigr)$. Thus, identity~\eqref{eq:5} allows us to write
\begin{equation}
  \label{eq:7}
  (A^*B)[\vm] = Q_{\vm}^*( A^*B \kron \bm{11}^T)Q_{\vm} = Q_{\vm}^*((A\otimes 1^T)^*(B\otimes 1^T))Q_{\vm} =: \tilde{A}_{\vm}^*\tilde{B}_{\vm}.
\end{equation}
Representation~\eqref{eq:7} combined with Lemma~\ref{lem:perip} immediately allows us to write
\begin{equation}
  \label{eq:28}
  \aper((A^*B)[\vm]) = \nlsum_{\lambda \vdash n} c_\lambda^\alpha\ip{\psi_\lambda(\tilde{A}_{\vm})}{\psi_\lambda(\tilde{B}_{\vm})},
\end{equation}
which shows that $\per_\alpha( (A^*B)[\vm])$ is a linear combination of inner products. To complete the proof that~\eqref{eq:28} indeed defines a valid inner product, it remains to verify that this inner product is positive definite. Since the coefficients $c_\lambda^\alpha$ can be negative, this property is not obvious from~\eqref{eq:28}.
In fact, this property is fairly nontrivial, but fortunately, it follows from a result of~\citet{branden2012}. Indeed, since $(A^*A)[\vm]=\tilde{A}_{\vm}^*\tilde{A}_{\vm}$ is positive definite, nonnegativity of $\aper((A^*A)[\vm])$ follows from Theorem~\ref{thm:branden2}. Thus, \eqref{eq:28} is a true inner product, and depending on whether $A$ and $B$ are real or complex, the corresponding necessary and sufficient conditions on $\alpha$ are also obtained from Theorem~\ref{thm:branden2}.

Combined with Theorem~\ref{thm:mac}, we have thus shown that $\det(I-A^*B)^{-\alpha}$ is a nonnegative sum of inner products. Consequently, we can write $\det(I-A^*B)^{-\alpha}=\ip{\Phi_\alpha(A)}{\Phi_\alpha(B)}$, for a suitable map $\Phi_\alpha$, thus obtaining the desired inner product formulation.\qed

Corollary~\ref{cor:main} finally answers the questions posed by Bellman and Hua, regarding conditions ensuring the positive-definiteness of Hua-Bellman matrices.
\begin{cor}
  \label{cor:main}
  Let $m \ge 1$ and $A_1,\ldots,A_m \in \Cc_n$. Then $[\det(I-A_i^*A_j)^{-\alpha}]_{i,j=1}^m$ is Hermitian positive definite if $\alpha \in D_{\mathbb{C}} \cup \{x \in \reals \mid x > n-1\}$. Let $B_1,\ldots,B_m \in \Cc_n \cap \reals^{n\times n}$, then $[\det(I-B_i^TB_j)^{-\alpha}]$ is symmetric positive definite if $\alpha \in D_{\reals} \cup \{x \in \reals \mid x > n-1\}$.
\end{cor}

%\begin{enumerate}
%\item First observe that $\det(I-tA)^{-\alpha} = \sum_{\bm{n} \in \mathbb{N}^m}\frac{t^{|\vn|}}{\vn!}\per_\alpha(A[\bm{n}])$
%\item $A[\bm{n}] = Q^*(A\otimes 11^T)Q$ (show via Khatri-Rao product)
%\item $\det(I-tA^*B)^{-\alpha} = \sum_{\bm{n} \in \mathbb{N}^m}\frac{t^m}{m!}\per_\alpha(A^*B[\bm{n}])$
%\item $A^*B[\bm{n}] = Q^*(A^*B\otimes 11^T)Q = Q^*((A\otimes 1^T)^*(B\otimes 1^T))Q= Z_A^*Z_B$
%\item 
%\end{enumerate}


\section{A hyperbolic-like geometry on noncommuting contractions}
\label{sec:metric}
In this section, we introduce a new (to our knowledge) hyperbolic-like geometry on the space of contractions. The  distance function introduced is suggested by Hua-Bellman matrices, whose positive definiteness induces the nonnegativity of the proposed distance. The main result of this section is Theorem~\ref{thm:dist}, which formally introduces the said geometry.
\begin{theorem}
  \label{thm:dist}
  Let $\dist: \Cc_n \times \Cc_n \to \reals_+$ be defined as
  \begin{equation}
    \label{eq:dist}
    \dist^2(A, B) := 
    \log \frac{|\det(I-A^*B)|}{\sqrt{\det(I-A^*A)}\sqrt{\det(I-B^*B)}},\qquad A, B \in \Cc_n.
  \end{equation}
  Then, $(\Cc_n,\dist)$ is a metric space.
\end{theorem}

Before proving Theorem~\ref{thm:dist}, we first recall a closely related distance function.
\begin{theorem}[S-Divergence~\citep{sra2016}]
  \label{thm:sdiv}
  Let $X, Y$ be Hermitian positive definite. Then,
  \begin{equation}
    \label{eq:17}
    \sdiv^2(X,Y) := \log\frac{\det\left(\tfrac{X+Y}{2}\right)}{\sqrt{\det(X)}\sqrt{\det(Y)}},
  \end{equation}
  is the square of a distance, i.e., $\sdiv$ is a distance.
\end{theorem}

We will use Theorem~\ref{thm:sdiv} in conjunction with Theorem~\ref{thm:adiv} in our proof of Theorem~\ref{thm:dist}. Theorem~\ref{thm:adiv} is considerably more general than what we need, however, we believe that it may be of independent interest, so we state it in its more general form; it is the second key result of this section.
\begin{theorem}
  \label{thm:adiv}
  Let $X, Y$ be arbitrary complex matrices, and $0\le p \le 2$, then 
  \begin{equation}
    \label{eq:18}
    \adiv_p^2(X,Y) := \log\det(I + |X-Y|^p),
  \end{equation}
  is the square of a distance, i.e., $\adiv_p$ is a distance (here $|X| := (X^*X)^{1/2}$).
\end{theorem}
\noindent We will need the following simple observation in our proof of Theorem~\ref{thm:adiv}:
\begin{lemma}
  \label{lem:cve} Let $0\le p \le 2$. The function $f(t)=\sqrt{\log(1+t^p)}$ is concave on $(0,\infty)$.
\end{lemma}
\begin{proof}
  We prove that $f''(t) \le 0$. Since $f''(t)=-\frac{p t^{p-2} \left(p t^p+2 \left(t^p-p+1\right) \log \left(t^p+1\right)\right)}{4 \left(t^p+1\right)^2 \log ^{\frac{3}{2}}\left(t^p+1\right)}$, it suffices to verify that $\left(p t^p+2 \left(t^p-p+1\right) \log \left(t^p+1\right)\right) \ge 0$. Writing $t^p=x$, this inequality is equivalent to
  $p x + 2 (1+x)\log(1+x) \ge 2p\log(1+x)$. Since $(1+x)\log(1+x) \ge x$, the lhs exceeds $px+2x$ which combined with the inequality $\log(1+x) \le x$ yields $px+2x \ge (p+2)\log(1+x) \ge 2p\log(1+x)$ as desired since $p\le 2$.
\end{proof}

\begin{proof}[Proof of Theorem~{\ref{thm:adiv}}]
  The key idea is to reduce the question to a setting where we can apply a subadditivity theorem of~\citet{uchiyama2006} for singular values. In particular, for complex matrices $A$, $B$, $C$ of size $n\times n$, such that $C=A+B$, Uchiyama's theorem states that for any concave function $f: \reals_+\to (0,\infty)$ such that $f(0)=0$, we have
  \begin{equation}
    \label{eq:19}
    \{f(\sigma_j(C))\}_{j=1}^n \prec_w \{f(\sigma_j(A))+ f(\sigma_j(B))\}_{j=1}^n,
  \end{equation}
  where $\prec_w$ denotes the weak-majorization partial order (see e.g., \citep[Chapter~2]{bhatia1997}), and $\sigma_j(\cdot)$ denotes the $j$-th singular value (in decreasing order).

  Let $A=X-Z$, $B=Z-Y$, and $C=X-Y$; let $a_j$, $b_j$, and $c_j$ be their singular values. Since $f(t)=\sqrt{\log(1+t^p)}$ is concave (see Lemma~\ref{lem:cve}), from~\eqref{eq:19} we thus obtain
  \begin{equation}
    \label{eq:20}
    \{f(c_j)\}_j \prec_w \{f(a_j) + f(b_j)\}_j.
  \end{equation}
  We further know that if $x \prec_w y$ for $x, y \in \reals_+^n$, then $x^s \prec_w y^s$ for $s \ge 1$ (see e.g.,~\citep[Example II.3.5]{bhatia1997}). Consequently, for $s=2$ from inequality~\eqref{eq:20} we obtain
  \begin{equation}
    \label{eq:21}
    \{f(c_j)^2\}_j \prec_w \bigl(\{f(a_j) + f(b_j)\}_j\bigr)^2.
  \end{equation}
  Thus, in particular it follows from the majorization inequality~\eqref{eq:21} that
  \begin{equation}
    \label{eq:22}
    \nlsum_{j=1}^n \log(1+c_j^p) \le \nlsum_j \left(\sqrt{\log(1+a_j^p)} + \sqrt{\log(1+b_j^p)} \right)^2,
  \end{equation}
  so that upon taking square roots on both sides we obtain
  \begin{equation*}
    \sqrt{\nlsum_{j=1}^n \log(1+c_j^p)} \le \sqrt{\nlsum_j \left(\sqrt{\log(1+a_j^p)} + \sqrt{\log(1+b_j^p)} \right)^2}.
  \end{equation*}
  Appling Minkowski's inequality on the right hand side we get
  \begin{equation}
    \label{eq:23}
    \sqrt{\nlsum_{j=1}^n \log(1+c_j^p)} \le \sqrt{\nlsum_j \log(1+a_j^p)} + \sqrt{\nlsum_j \log(1+b_j^p)}.
  \end{equation}
  But $\nlsum_j\log(1+c_j^p)=\log\det(I+|C|^p)=\log\det(I+|X-Y|^p)=\adiv_p^2(X,Y)$. Thus, inequality~\eqref{eq:23} is nothing but the triangle inequality
  \begin{equation*}
    \adiv_p(X,Y) \le \adiv_p(X,Z) + \adiv_p(Y,Z),
  \end{equation*}
  which concludes the proof.
\end{proof}



Before presenting the proof of Theorem~\ref{thm:dist}, let us briefly note Corollary~\ref{cor:hyper} that also explains why we call the geometry induced by distance~\eqref{eq:dist} to be hyperbolic-like.
\begin{cor}
  \label{cor:hyper}
  After suitable rescaling, identify diagonal matrices $X, Y \in \Cc_n$ with contractive vectors $x, y \in \mathbb{C}^n$. Then, we have the distance
  \begin{equation*}
    d^2(X,Y) = \log \frac{|1-x^*y|}{\sqrt{(1-\|x\|^2)}\sqrt{(1-\|y\|^2)}},
  \end{equation*}
  which is similar to the Cayley-Klein-Hilbert distance~\citep[pg.~120]{deza2013}.
\end{cor}

%\noindent{\bfseries\itshape Proof of Theorem~\ref{thm:dist}}\\
To prove the hardest part of Theorem~\ref{thm:dist}, namely, the triangle inequality, we will proceed by rewriting $d^2(A,B)$ is a more amenable form. To that end, we need Lemma~\ref{lem:mobius}.
\begin{lemma}[M\"obius]
  \label{lem:mobius}
  Let $A, B \in \Cc_n$. There exist matrices $X$ and $Y$ such that
  \begin{enumerate}
  \item $I-A^*B = 2(I+X^*)^{-1}(X^*+Y)(I+Y)^{-1}$, and 
  \item $\real(X) \succ 0$, and $\real(Y) \succ 0$.
  \end{enumerate}
\end{lemma}
\begin{proof}
  \emph{Part~(i)}: Consider the M\"obius transformation $A \mapsto (X-I)(X+I)^{-1}$, which leads to $X=(I-A)^{-1}(I+A)$, an object that is well-defined because $I-A$ is invertible due to $A$ being a strict contraction. Using this transformation on $A$ and $B$ we obtain
  \begin{align*}
    I-A^*B &= I - (I+X^*)^{-1}(X^*-I)(Y-I)(Y+I)^{-1}\\
    &= I - (I+X^*)^{-1}[X^*Y-X^*-Y+I](Y+I)^{-1}\\
    &= (I+X^*)^{-1}\bigl[(I+X^*)(Y+I) - X^*Y+X^*+Y-I\bigr](Y+I)^{-1}\\
    &= (I+X^*)^{-1}[2X^*+2Y](Y+I)^{-1}.
  \end{align*}

  \noindent\emph{Part~(ii)}: From Part~(i), we have $I-A^*A=(I+X^*)^{-1}[2X^*+2Y](I+X)^{-1}$. Thus,
  \begin{equation*}
    \real(X) = \tfrac14(I+X^*)(I-A^*A)(I+X),
  \end{equation*}
  which is clearly strictly positive definite by assumption on $A$ and definition of $X$.
\end{proof}

\vspace*{8pt}
We are now ready to prove Theorem~\ref{thm:dist}.
\begin{proof}[\bfseries Proof of Theorem~\ref{thm:dist}]
  For $A, B, C \in \Cc_n$ we need to show that (i) $d(A,B)\ge 0$; (ii) $d(A,B)=d(B,A)$; and (iii) $d(A,B) \le d(A,C)+d(B,C)$. From the $2\times 2$ matrix version of Theorem~\ref{thm:main} Hua's classical inequality $|\det(I-A^*B)|\ge \sqrt{\det(I-A^*A)\det(I-B^*B)}$ follows immediately; here, the inequality holds strictly unless $A=B$. Thus, $d(A,B) \ge 0$ with equality if and only if $A=B$. Symmetry~(ii) of $d$ is evident, so it only remains to prove the triangle inequality~(iii).
  
  From Lemma~\ref{lem:mobius}-(i) it follows that there exist $X, Y$ such that
  \begin{align}
    \nonumber
    \dist^2(A,B) &= \log\frac{|\det(2X^*+2Y)|\sqrt{\det(I+X^*)(I+X)}\sqrt{\det(I+Y^*)(I+Y)}}
                       {|\det(I+X^*)| |\det(I+Y)|\sqrt{|\det(2X^*+2X)|}\sqrt{|\det(2Y^*+2Y)|}}\\
           \label{eq:11}
           &= \log\frac{|\det(X^*+Y)|}{\sqrt{|\det(X^*+X)|}\sqrt{|\det(Y^*+Y)|}} =: \delta^2(X,Y).
  \end{align}
  By Lemma~\ref{lem:mobius}-(ii) $X^*+X \succ 0$, so that we can rewrite~\eqref{eq:11} as
  \begin{equation}
    \label{eq:15}
    \delta^2(X,Y) = \log\frac{|\det(X^*+Y)|}{\sqrt{\det(X^*+X)}\sqrt{\det(Y^*+Y)}}.
  \end{equation}
  It remains to verify that $\delta$ defined by~\eqref{eq:15} is a distance.

  Write $X=\real(X)+i\imag(X)$ (similarly $Y$), so that $|\det(X^*+Y)|=|\det(\real(X+Y)+i[\imag(Y)-\imag(X)])|$.
  The matrix $\real(X+Y)$ is positive definite while $[\imag(Y)-\imag(X)]$ is Hermitian. Thus, there exists a matrix $T$ such that $T^*\real(X+Y)T=I$ and $T^*(\imag(Y)-\imag(X))T=D$ for some diagonal matrix $D$. Moreover, since $T^*\real(X)T+T^*\real(Y)T=I$, the matrices $T^*\real(X)T$ and $T^*\real(Y)T$ commute. As a result, they can be simulatenously diagonlized using a unitary matrix, say $U$. Thus, we can write $U^*T^*\real(X)TU=D_x$ and $U^*T^*\real(Y)TU=D_y$ for diagonal matrices $D_x$, $D_y$, and also $U^*T^*\imag(Y)TU=S_y$, and $U^*T^*\imag(X)TU=S_x$ for Hermitian matrices $S_x$, $S_y$, which permits us to rewrite~\eqref{eq:15} as
  \begin{equation}
    \label{eq:16}
    \delta^2(X,Y) = \log\frac{|\det(D_x+D_y+iU^*DU)|}{\sqrt{\det{2D_x}}\sqrt{\det{2D_y}}}.
  \end{equation}
  Since $D_x+D_y=I$, we can split~\eqref{eq:16} into two parts as follows:
  \begin{align*}
    \delta^2(X,Y) &= \log\frac{\det(D_x+D_y)}{\sqrt{\det{2D_x}}\sqrt{\det{2D_y}}} + \log|\det(I+iU^*DU)|\\
    &= \log\frac{\det\left(\tfrac{D_x+D_y}{2}\right)}{\sqrt{\det D_x}\sqrt{\det D_y}} + \log|\det(I+i(S_y-S_x))|\\
    &= \delta_S^2(D_x,D_y) + \half\log\det(I+(S_y-S_x)^2)\\
    &= \delta_S^2(D_x,D_y) + \half\delta_2^2(S_x,S_y),
  \end{align*}
  from which upon using Theorems~\ref{thm:sdiv} and \ref{thm:adiv}, the triangle inequality for $\delta(X,Y)$ follows.
\end{proof}

\emph{Remarks:} We believe that the distance functions~(\ref{eq:dist}) and~(\ref{eq:18}) may find several applications in a variety of domains. Our belief is based on the diverse body of applications the related S-Divergence~(\ref{eq:17}) has found, for instance in computer vision~\citep{cherian2012}, brain-computer interfaces and imaging~\citep{yger2016}, matrix means~\citep{sra2016,chebbi2012}, geometric optimization~\citep{sra2015,boumal2020}, numerical linear algebra~\citep{sra2016b}, signal processing~\citep{bouchard2018}, machine learning~\citep{zern2018,tiomoko2019}, quantum information theory~\citep{virosztek2021}, among many others.
%\section{Some applications and connections}

\setlength{\bibsep}{2pt}
\bibliographystyle{abbrvnat}
%\bibliography{hua}
\begin{thebibliography}{33}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ando(1980)]{ando1980}
T.~Ando.
\newblock {Hua--Marcus inequalities}.
\newblock \emph{Linear and Multilinear Algebra}, 8\penalty0 (4):\penalty0
  347--352, 1980.

\bibitem[Ando(2008)]{ando2008}
T.~Ando.
\newblock Positivity of operator-matrices of {H}ua-type.
\newblock \emph{Banach J. Math. Anal.}, 2\penalty0 (2):\penalty0 1--8, 2008.

\bibitem[Bellman(1959)]{bellman1959}
R.~Bellman.
\newblock Representation theorems and inequalities for {H}ermitian matrices.
\newblock \emph{Duke Mathematical Journal}, 26\penalty0 (3):\penalty0 485--490,
  09 1959.

\bibitem[Bhatia(1997)]{bhatia1997}
R.~Bhatia.
\newblock \emph{{Matrix Analysis}}.
\newblock Springer, 1997.

\bibitem[Bouchard et~al.(2018)Bouchard, Malick, and Congedo]{bouchard2018}
F.~Bouchard, J.~Malick, and M.~Congedo.
\newblock Riemannian optimization and approximate joint diagonalization for
  blind source separation.
\newblock \emph{IEEE Transactions on Signal Processing}, 66\penalty0
  (8):\penalty0 2041--2054, 2018.

\bibitem[Boumal(2020)]{boumal2020}
N.~Boumal.
\newblock \emph{An introduction to optimization on smooth manifolds}.
\newblock Online, 2020.

\bibitem[Br{\"a}nd{\'e}n(2012)]{branden2012}
P.~Br{\"a}nd{\'e}n.
\newblock Solutions to two problems on permanents.
\newblock \emph{Linear algebra and its applications}, 436\penalty0
  (1):\penalty0 53--58, 2012.

\bibitem[Chebbi and Moakher(2012)]{chebbi2012}
Z.~Chebbi and M.~Moakher.
\newblock Means of {H}ermitian positive-definite matrices based on the
  log-determinant $\alpha$-divergence function.
\newblock \emph{Linear Algebra and its Applications}, 436\penalty0
  (7):\penalty0 1872--1889, 2012.

\bibitem[Cherian et~al.(2012)Cherian, Sra, Banerjee, and
  Papanikolopoulos]{cherian2012}
A.~Cherian, S.~Sra, A.~Banerjee, and N.~Papanikolopoulos.
\newblock Jensen-{B}regman logdet divergence with application to efficient
  similarity search for covariance matrices.
\newblock \emph{IEEE transactions on pattern analysis and machine
  intelligence}, 35\penalty0 (9):\penalty0 2161--2174, 2012.

\bibitem[Crane(2013)]{crane2013}
H.~Crane.
\newblock Some algebraic identities for the $\alpha$-permanent.
\newblock \emph{Linear Algebra and Its Applications}, 439\penalty0
  (11):\penalty0 3445--3459, 2013.

\bibitem[Deza and Deza(2013)]{deza2013}
M.~M. Deza and E.~Deza.
\newblock \emph{Encyclopedia of distances}.
\newblock Springer, second edition, 2013.

\bibitem[Frenkel(2009)]{frenkel2009}
P.~E. Frenkel.
\newblock Remarks on the $\alpha$-permanent.
\newblock \emph{arXiv:0912.1018}, 2009.

\bibitem[Fulton and Harris(2013)]{fulton2013}
W.~Fulton and J.~Harris.
\newblock \emph{Representation theory: a first course}, volume 129.
\newblock Springer, 2013.

\bibitem[Hua(1955)]{hua1955}
L.-K. Hua.
\newblock Inequalities involving determinants.
\newblock \emph{Acta Math. Sinica}, 5:\penalty0 463--470, 1955.
\newblock (in Chinese). See also Transl. Amer. Math. Soc., Ser. II, 32 (1963);
  265--272.

\bibitem[Liu et~al.(2008)Liu, Trenkler, et~al.]{liu2008}
S.~Liu, G.~Trenkler, et~al.
\newblock Hadamard, khatri-rao, kronecker and other matrix products.
\newblock \emph{International Journal of Information and Systems Sciences},
  4\penalty0 (1):\penalty0 160--177, 2008.

\bibitem[Marcus(1958)]{marcus1958}
M.~Marcus.
\newblock On a determinantal inequality.
\newblock \emph{American Mathematical Monthly}, pages 266--268, 1958.

\bibitem[Merris(1997)]{merris1997}
R.~Merris.
\newblock \emph{Multilinear algebra}.
\newblock CRC Press, 1997.

\bibitem[Ostrowski and Taussky(1951)]{ostrow1951}
A.~M. Ostrowski and O.~Taussky.
\newblock On the variation of the determinant of a positive definite matrix.
\newblock \emph{Koninklijke Nederlandse Akademievan Wetenschappen. Proceed-
  ings,Series A}, 54\penalty0 (5):\penalty0 383, 1951.

\bibitem[Scott and Sokal(2014)]{scott2014}
A.~D. Scott and A.~D. Sokal.
\newblock Complete monotonicity for inverse powers of some combinatorially
  defined polynomials.
\newblock \emph{Acta Mathematica}, 213\penalty0 (2):\penalty0 323--392, 2014.

\bibitem[Shirai(2007)]{shirai2007}
T.~Shirai.
\newblock Remarks on the positivity of $\alpha$-determinants.
\newblock \emph{Kyushu Journal of Mathematics}, 61\penalty0 (1):\penalty0
  169--189, 2007.

\bibitem[Sra(2016{\natexlab{a}})]{sra2016}
S.~Sra.
\newblock {Positive definite matrices and the S-Divergence}.
\newblock \emph{Proceedings of the American Mathematical Society},
  144:\penalty0 2787--2797, 2016{\natexlab{a}}.

\bibitem[Sra(2016{\natexlab{b}})]{sra2016b}
S.~Sra.
\newblock On the matrix square root via geometric optimization.
\newblock \emph{The Electronic Journal of Linear Algebra}, 31:\penalty0
  433--443, 2016{\natexlab{b}}.

\bibitem[Sra and Hosseini(2015)]{sra2015}
S.~Sra and R.~Hosseini.
\newblock Conic geometric optimization on the manifold of positive definite
  matrices.
\newblock \emph{SIAM Journal on Optimization}, 25\penalty0 (1):\penalty0
  713--739, 2015.

\bibitem[Szeg\H{o}(1933)]{szego1933}
G.~Szeg\H{o}.
\newblock {\"U}ber gewisse {P}otenzreihen mit lauter positiven {K}oeffizienten.
\newblock \emph{Mathematische Zeitschrift}, 37\penalty0 (1):\penalty0 674--688,
  1933.

\bibitem[Tiomoko et~al.(2019)Tiomoko, Couillet, Bouchard, and
  Ginolhac]{tiomoko2019}
M.~Tiomoko, R.~Couillet, F.~Bouchard, and G.~Ginolhac.
\newblock Random matrix improved covariance estimation for a large class of
  metrics.
\newblock In \emph{International Conference on Machine Learning}, pages
  6254--6263. PMLR, 2019.

\bibitem[Uchiyama(2006)]{uchiyama2006}
M.~Uchiyama.
\newblock Subadditivity of eigenvalue sums.
\newblock \emph{Proceedings of the American Mathematical Society}, 134\penalty0
  (5):\penalty0 1405--1412, 2006.

\bibitem[Vere-Jones(1988)]{verejones1988}
D.~Vere-Jones.
\newblock A generalization of permanents and determinants.
\newblock \emph{Linear Algebra and Its Applications}, 111:\penalty0 119--124,
  1988.

\bibitem[Virosztek(2021)]{virosztek2021}
D.~Virosztek.
\newblock The metric property of the quantum {J}ensen-{S}hannon divergence.
\newblock \emph{Advances in Mathematics}, 380:\penalty0 107595, 2021.

\bibitem[Xu et~al.(2009)Xu, Xu, and Zhang]{xuXu2009}
C.~Xu, Z.~Xu, and F.~Zhang.
\newblock {Revisiting Hua-Marcus-Bellman-Ando inequalities on contractive
  matrices}.
\newblock \emph{Linear Algebra and its Applications}, 430\penalty0
  (5-6):\penalty0 1499--1508, Mar. 2009.

\bibitem[Xu et~al.(2011)Xu, Xu, and Zhang]{xuXu2011}
G.~Xu, C.~Xu, and F.~Zhang.
\newblock {Contractive matrices of Hua type}.
\newblock \emph{Linear and Multilinear Algebra}, 59\penalty0 (2):\penalty0
  159--172, Feb. 2011.

\bibitem[Yger et~al.(2016)Yger, Berar, and Lotte]{yger2016}
F.~Yger, M.~Berar, and F.~Lotte.
\newblock Riemannian approaches in brain-computer interfaces: a review.
\newblock \emph{IEEE Transactions on Neural Systems and Rehabilitation
  Engineering}, 25\penalty0 (10):\penalty0 1753--1762, 2016.

\bibitem[Zern et~al.(2018)Zern, Zisler, {\AA}str{\"o}m, Petra, and
  Schn{\"o}rr]{zern2018}
A.~Zern, M.~Zisler, F.~{\AA}str{\"o}m, S.~Petra, and C.~Schn{\"o}rr.
\newblock Unsupervised label learning on manifolds by spatially regularized
  geometric assignment.
\newblock In \emph{German Conference on Pattern Recognition}, pages 698--713.
  Springer, 2018.

\bibitem[Zhang(2009)]{fzhang2009}
F.~Zhang.
\newblock Recent results and and research problems on {H}ua matrices.
\newblock NIU Linear Algebra Meeting: presentation slides, Aug 2009.

\end{thebibliography}



\end{document}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:


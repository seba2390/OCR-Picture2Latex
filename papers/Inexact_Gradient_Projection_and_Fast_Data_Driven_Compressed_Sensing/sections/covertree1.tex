\subsection{Cover tree for fast NN}
With data driven CS formalism and discretization of the model  %$\Cc = \prod_{i=1}^N \Mb$, 
the projection step of IPG reduces to searching the nearest atom in each of the product spaces, however in a potentially very large size $d$ dictionary. 
A very well-established approach to overcome the complexity of an exhaustive nearest neighbour search on a large dataset consists of hierarchically partitioning the solution space and forming a \emph{tree} whose nodes representing those partitions, and then using branch-and-bound methods on the resulting tree for a fast Approximate NN (ANN) search with $o(d)$ complexity e.g. see~\cite{Navigating,beygelzimer2006cover}.

In this regard, we address the computational shortcoming of the projection step in the exact IPG by preprocessing $\widetilde \Cc$ and form a \emph{cover tree} structure suitable for fast ANN searches \cite{beygelzimer2006cover}. Cover tree is a levelled tree whose nodes at different scales form  covering nets for $\widetilde \Cc$ at multiple resolutions (i.e., coarse-to-fine dyadic coverage levels). %This structure hierarchically partitions the metric space and enables using branch-and-bound methods for fast NN search. 
While the tree construction is blind to the explicit structure of data, several key growth properties such as the tree's explicit depth, the number of children per node, and importantly the overall NN complexity are characterized by the intrinsic dimension $\dim(\widetilde \Cc)$ of the model (which in practice  is a small number e.g. when $\widetilde \Cc$ uniformly samples of a low dimensional manifold).





Let $\Tt_\Mb$ denotes a cover tree defined in order to arrange dataset $\Mb$.  %Cover tree is a leveled tree with multiple scales $i=0,\dots,L_{\max}$ where its nodes are associated with data points in  $\Mb$. 
We denote by $\Ss_i$ the set of nodes appear at scale $i=0,\dots,L_{\max}$.
The lowest scale $i=0$ correspond to the root $\Ss_0$ which is a point covering all data. We denote by $\sigma:=\max_{q\in\Mb}\dist(\Ss_0,q)$ the maximum coverage i.e. the maximum distance between the root and any other node on the tree. As we descend down the tree (i.e. incrementing the scale) the nodes present at higher scales cover their descendants at finer resolutions. More precisely, a cover tree structure must have the following  three properties:
% node $i$ denoted by $\Nn_{ji}$ represents a section of the space denoted by$\Ss_{ji}$. Nodes and represented partitions must satisfy the following three properties.
\begin{enumerate}
	\item Nesting: $\Ss_i \subseteq \Ss_{i+1}$, 
	that is once a point $p$ appears as a node in $\Ss_i$, then every lower level in the tree has a node associated with $p$.
	\item Covering: every node $q\in \Ss_{i+1}$ has a parent node  $p\in \Ss_{i}$, where $\dist(p,q)\leq \sigma2^{-i} $. As a result, covering becomes finer at higher scales in a dyadic fashion. 
	%and For every $p\in \Ss_{i−1}$, there exists
	%a q 2 Ci such that d(p, q) < 2i and the node in
	%level i associated with q is a parent of the node
	%in level i − 1 associated with p.
	
	\item Separation: nodes belonging to the same scale are separated by a minimal distance which dyadically shrinks at higher scales i.e. $\forall q,q'\in\Ss_i$ we have $\dist(q,q')>\sigma2^{-i}$.   
\end{enumerate}  
Each node $p$ also keeps the maximum distance to its descendants denoted by
\eq{maxdist(q):= \max_{q'\in \text{descendant}(q)} \dist(q,q'),
}
which will be useful for the fast NN search.  Note that one might decide to avoid saving $maxdist$ values and use the following upper bound instead.


{\lem{\label{lem:maxdist}For any $q\in \Ss_i$ and due to the covering property we have:
\begin{align}\label{eq:maxdist}
maxdist(q) \leq \sigma \left( 2^{-i}+2^{-i-1}	+ 2^{-i-2}+\dots \right)
< \sigma 2^{-i+1}.
\end{align}
}}

Depth of the \emph{implicit} cover tree (constructed w.r.t. the three constraints above) might grow very large for arbitrary datasets. Indeed we can easily verify that $L_{\max}\leq \log(\Delta(\Mb))$, where 
\eq{
	\Delta(\Mb):= \frac{\max_{p,q \in \Mb}\dist(p,q)}{\min_{p\neq q \in \Mb}\dist(p,q)}.
}
is the aspect ratio of $\Mb$. In practice however we only keep one copy of the nodes which do not have either parent or a child other than themselves. This \emph{explicit} representation efficiently reduces the required storage space to $O(n)$. 

\begin{algorithm}[t]
	\label{alg:findNN}
	\SetAlgoLined
	$Q_0 = \{\Ss_0\}$, where $\Ss_0$ is the root of $\Tt_{\Mb}$\\
	$d_{\min}=\norm{p-q_c}$\\
	$i=0$\\
	\While{$i<L_{\max}$ \& $! \textbf{stoppage}(\gamma)$}
	{
		$Q=\left\{\text{children}(q):\, q\in Q_i \right\} $\\
		$q^* = \argmin_{q\in Q} \norm{p-q}$, \quad $d = \norm{p-q^*}$ \\
		\If{$d<d_{\min}$}{$d_{\min}=d, \quad q_c=q^*$}
		$Q_{i+1} = \left\{q\in Q: \norm{p-q}\leq d_{\min} + maxdist(q) \right\}$\\
		$i  = i+1$\\
	}	
	\Return $q_c$\\%=\argmin_{q\in Q_{L_{\max}}} \norm{p-q}$\;
	\caption{\label{alg:NN} \textbf{ANN}(cover tree $\Tt_\Mb$, query point $p$, current estimate $q_c \in \Mb$, accuracy parameter $\gamma$)}
\end{algorithm}

Algorithm \ref{alg:NN} details the procedure for approximate nearest neighbour (ANN) search on a given cover tree. 
In short, we iteratively traverse down the cover tree and at each scale we populate the set of candidates $Q_i$ with nodes that can be ancestors of the closest NN point and discard others (this refinement uses the triangular inequality and the lower bound on the distance of the grandchildren of $Q$ to $p$, based on  $maxdist(q)$). In the next iteration, children of these candidates are similarly refined and added to the updated candidate set $Q_{i+1}$. At the finest scale (before stoppage) we search the whole set of final candidates and report an ANN point. Not that at each scale we only compute distances for non self-parent nodes (we pass, without computation, distance information of the self-parent children to finer scales).

Three stoppage criteria can be adopted:
\begin{itemize}
	\item \textbf{Fixed-precision:} that is traversing down the tree up to a scale for which the covering resolution falls below a threshold $\gamma$. Given the knowledge of $maxdist$ (or the bound in Lemma \ref{lem:maxdist}) we stop the search when
	%the stoppage can be refined to 
	\eq{ \max_{q\in Q_i} \{maxdist(q)\} < \gamma. }
	 This is similar as performing exact NN searches on a truncated (low-resolution) cover tree. 
	\item \textbf{PFP decaying at rate $r$:} as defined in Corollary \ref{cor:decay}. For this case we perform the stoppage procedure above for an updating accuracy parameter 
	\eq{ 
		\gamma := \nup^k =r^k
		}
	that geometrically decays at a certain rate $r<1$ through the iterations.
	\item \textbf{Relative $\epsilon$-ANN:} It is proposed by \nref KL [Nav.Nets] and Beygelzeimer et al. [CT] that if for a parameter $\gamma=\epsilon$ the search stops as soon as having
	\eq{(1+\frac{1}{\epsilon-1})\sigma2^{-i+1}\leq \argmin_{q\in Q_i} \norm{p-q}
		}
	then we achieve a relative accuracy of type defined by \eqref{eq:eproj}.  
\end{itemize}

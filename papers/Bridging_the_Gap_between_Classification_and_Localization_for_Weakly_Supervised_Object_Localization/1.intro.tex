\section{Introduction}
\label{sec:intro}
Object localization aims to find the area of a target object in a given image~\cite{ren2015faster,russakovsky2015imagenet,duan2019centernet,lin2017feature,tan2020efficientdet}. However, fully supervised approaches require accurate bounding box annotations, which require a tremendous cost. Weakly supervised object localization (WSOL) has been a great alternative because it requires only image-level labels to train a localization model~\cite{singh2017hide,choe2019attention,choe2020evaluation,pan2021unveiling, xue2019danet}.

The most commonly used approach for WSOL is a class activation map (CAM)~\cite{zhou2016learning}. CAM-based methods employ a global average pooling (GAP) layer~\cite{lin2013network} followed by a fully connected (FC) layer, and generate a CAM with the feature maps prior to the GAP layer.
A highly activated area in a CAM is predicted to be an object location.
However, it is widely observed that CAM identifies only the most discriminative parts of an object rather than the entire object area, resulting in low localization performance~\cite{mai2020erasing,lee2021anti,zhang2018adversarial}.

\input{fig_tab/fig_abs}

We ask the question, ``\textit{Why does CAM generated from an accurate classifier fail to highlight the entire object area?}''
To answer this, we provide a new perspective of decomposing CAM into two terms: (1) activation in a feature map and (2) cosine similarity between the feature vector at each spatial location and the class-specific weight in the FC layer.
Fig.~\ref{fig:first}(a) shows that only the bird's body is highly activated in the CAM of the vanilla model, leaving the wing less activated. However, looking at the activation in the feature map, the wing as well as the body is highly activated.
The low similarity of the wing region offsets the activation in the feature map, making the region invisible in the CAM.
Here, we find that the low cosine similarity, \ie, misalignment of feature directions to the class-specific weights, prevents the less discriminative part belonging to a target object from being highly activated in a CAM.
This is because training for classification only considers the feature averaged over all locations, not the feature at each spatial location.
This brings the gap between classification and localization.

Although various approaches have been proposed to expand the activated region to the entire object area in a CAM~\cite{zhang2018adversarial,choe2019attention,mai2020erasing,yun2019cutmix,xue2019danet,zhang2018self}, none of them discovered or mitigated the misalignment. Fig.~\ref{fig:first}(a) shows that EIL~\cite{mai2020erasing}, one of those approaches, expands the activated region in the feature map. However, it fails to increase the similarity in the object region; hence, the expansion effect is not as large in the CAM as in the activation of the feature map.

To bridge the gap between classification and localization, we propose feature direction alignment, a method to enhance the alignment of feature directions in the entire object region to the directions of class-specific weights while discouraging the alignment in the background region.
We also introduce consistency with attentive dropout, which ensures that the target object region has uniformly high activation in the feature map.
Fig.~\ref{fig:first}(b) shows that our method gradually aligns the feature directions to the class-specific weight as the training progresses.
The alignment results in high activation of less discriminative regions, \eg, wing, in the CAM, enabling accurate localization of the entire object.
We evaluate our method on the most widely used WSOL benchmark datasets: CUB-200-2011~\cite{welinder2010caltech} and ImageNet-1K~\cite{russakovsky2015imagenet}.
Our method achieves a state-of-the-art localization performance for both datasets.

The contributions of this paper can be summarized as follows:
\begin{itemize}
\setlength{\itemsep}{2pt}
\vspace{-3pt}
	\item[$\bullet$] We interpret a CAM in terms of the degree of alignment between the direction of input features and the direction of class-specific vectors, and find the gap between classification and localization.
	\vspace{-2pt}
	\item[$\bullet$] We propose a method to bridge the gap between classification and localization by aligning feature directions with class-specific weights.
	\vspace{-2pt}
	\item[$\bullet$] We demonstrate that our proposed method outperforms other state-of-the-art WSOL methods on the CUB-200-2011 and ImageNet-1K datasets.
\end{itemize}
\section{Related Work}
The WSOL method trains a model to localize objects using image-level labels. Zhou~\etal~\cite{zhou2016learning} introduce a CAM to identify the location of a target object via GAP layer~\cite{lin2013network}. However, it fails to identify the entire object region.

Various methods have been proposed to activate the entire object region in a CAM. HaS~\cite{singh2017hide} trains a classifier using images that are erased with a random patch. ACoL~\cite{zhang2018adversarial} employs two parallel classifiers to identify complementary regions. ADL~\cite{choe2019attention,choe2020attention} stochastically drops out the attentive feature in a single forward pass. Ki~\etal~\cite{ki2020sample} introduced contrastive learning with foreground features and background features. EIL~\cite{mai2020erasing} adopts an additional forward pass to classify with the feature whose highly activated regions are erased. SPG~\cite{zhang2018self} utilizes a deep feature to guide a shallow feature and $\text{I}^2\text{C}$~\cite{zhang2020inter} uses pixel-level correlations between two different images. CutMix~\cite{yun2019cutmix} combines two patches from different images and assigns a new class label based on the area of each patch. DANet~\cite{xue2019danet} leverages divergent activations with the hierarchy of classification labels.

\input{fig_tab/fig_cam_sim_norm}
\input{fig_tab/fig_oveview}

There have been attempts to obtain localization maps in different ways, pointing out the limitations of CAM-based methods. Pan~\etal~\cite{pan2021unveiling} proposed a method to utilize high-order point-wise correlation to generate localization maps. Kim~\etal~\cite{kim2021keep} proposed a CALM that learns to predict the location of the cue for recognition.

Several normalization methods have been proposed to obtain the bounding boxes around predicted object locations from a continuous localization map. Bae~\etal~\cite{bae2020rethinking} proposed several methods to address the bias in GAP, including a new normalization method, PaS, which restricts the maximum value of the activation map. IVR~\cite{kim2021normalization} is a normalization method that restricts the minimum value of the activation map.

Some works have adopted an auxiliary module for localization besides classification. GC-Net~\cite{lu2020geometry} adopts a separate detector for localization trained with a geometric constraint. FAM~\cite{meng2021foreground} generates a class-agnostic foreground map through a memory mechanism. ORNet~\cite{xie2021online} adopts an additional activation map generator and refines the activation map in an online manner. PSOL~\cite{zhang2020rethinking}, SLT-Net~\cite{guo2021strengthen}, and SPOL~\cite{wei2021shallow} use two separate networks for classification and localization.

Our method aims to address the gap between classification and localization without adopting any auxiliary module. The methods that adopt additional modules or even separate models use more parameters and computational resources.  Therefore, we compare our method mainly with the WSOL methods that use a single branch, for a fair comparison.
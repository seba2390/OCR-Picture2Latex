\section{Simulations}



The simulations are all carried through the benchmark platform of the OMPL \cite{sucan2012open} \cite{moll2015benchmarking}.
To validate the generalization ability of our method, we solve the planning problem in both the $SE(2)$ and $SE(3)$ state spaces with our method and several state-of-art algorithms.
In simulation environments, the state spaces are continuous. 
The algorithms that have been tested are all based on random sampling and take samples from these continuous state spaces without discretizing the space.
The robot is represented by a collection of convex polyhedrons and occupies a certain volume.


\subsection{Qualitative Analysis}

\input{SimulationResults_3D.tex}

% To provide a further explanation of our method, we use the RRT\# \cite{arslan2013use}, the AIT* \cite{strub2020adaptively}, and our method to solve the motion planning problem in an OMPL benchmark environment called the `BugTrap'.
To give more detail explanation about our approach, we employ the RRT\# \cite{arslan2013use}, AIT* \cite{strub2020adaptively}, and our own method to address the path planning challenge within the `BugTrap' OMPL benchmark environment.
The state space of the `BugTrap' environment is the $SE(2)$ state space, which is composed of the position $x$, $y$ and the orientation $w$.
The planning procedures of the RRT\# \cite{arslan2013use}, the AIT* \cite{strub2020adaptively}, and our method are illustrated in Fig. \ref{PlanningProcedure}, where obstacles, the free space, the start state, the goal region, and vertices are indicated with black, ivory white, pale blue, wine, and orange color, respectively.
We use the dark green lines and violet lines to show the forward tree and the current optimal solution, respectively.
The reverse trees are shown as the grey lines in the figure of the AIT* \cite{strub2020adaptively} and our method.


In the simulation shown in Fig. \ref{PlanningProcedure}, the planning problem contains two optimal solutions, one is to pass through the region upper the obstacle, and the other one is to pass through the lower part.
Fig. \ref{PlanningProcedure} shows that all the methods in Fig. \ref{PlanningProcedure} can acquire the global asymptotical optimality.
Both the AIT* and our method use the lazy reverse-searching tree to guide the sampling and have the graph pruning method to constraint the samples and the trees.
From the (j)-(m) in Fig. \ref{PlanningProcedure}, it can find that both the forward and reverse trees of our method are optimal under current state space abstraction.
In addition, our method concentrates on taking samples in the region with a higher potential to improve the current solution, which can be seen in (m) of Fig. \ref{PlanningProcedure}, our method pays more attention to the turning corners with our direct sampling method.


\subsection{Simulations in $SE(2)$ State Space}



We choose the $SE(2)$ environments shown in Fig. \ref{SimulationEnvironments_2D} to verify our method, and they are called the `BugTrap', the `Maze', and the `RandomPolygons' in the OMPL benchmark platform. 
To give the reader an intuitional understanding of our 2D planning simulations, we show the trajectories found by our method in Fig. \ref{SimulationPath_2D}.
The trajectories are interpolated in terms of time.


In our 2D simulations, the state space definition contains the position $x, y$ and orientation $w$.
To manifest the superiority of our method, we compared with seven different state-of-art algorithms, they are the RRT*, the BIT*, the AIT*, the ABIT*, the Informed RRT*, the RRT\#, and the Informed $+$ Relevant sampling method proposed in \cite{joshi2020relevant}.
In these simulations, we use the trajectory length as the cost metric.
The optimization objective is set as $\beta \times c_{opt}$, where the $c_{opt}$ is the cost of the optimal solution and $\beta$ is a number close to $100\%$.
% The $c_{opt}$ is the solution cost of the RRT* method after $300$ seconds' execution, which is nearly the optimal solution cost, and we choose to use this number to represent the optimal cost.
The $c_{opt}$ is the solution cost of the RRT* method after $300$ seconds of execution, which is nearly optimal. 
We choose to use this number to represent the optimal cost.
To reduce the randomness, each planner runs $100$ times in each environment.



The simulation results in the $SE(2)$ state spaces are shown in Fig. \ref{SimulationResults_2D}.
On the left side of the pictures, the charts shows the amount of time each planner took to generate the required path.
On the right side, the cost distribution is presented in terms of time. We begin plotting the line charts once 50\% of all runs have found a solution, and stop once 95\% have completed the problem-solving process. 
Hence, the speed of obtaining the initial solution can also be displayed in the same chart.
Additionally, error bars are provided for all bar charts and line charts.


The 2D simulation results show that our method acquired significant improvements and achieved better performance.
Both the initial solution quality and the convergence rate of our method are better than the others.
The only drawback of our method is we generate the initial solution slower than the others, but we acquired the best initial solution quality.
And our initial solution is better than the others' optimized solutions at the same time point.


\subsection{Simulations in $SE(3)$ State Space}



Besides the 2D simulation introduced previously, we also carried on the simulation in the $SE(3)$ state space. 
In the 3D simulations, we include the `3D\_Apartment' planning problem from the OMPL benchmark platform \cite{moll2015benchmarking}, which is a `piano movers' problem, as the left environment in Fig. \ref{SimulationEnvironments_3D} shows.
The other simulation is set as a planning problem in 3D narrow passage environment.
In the 3D simulation, planners and their parameter sets are the same as the planners we choose in 2D simulations.
Each planner will solve each planning problem 100 times to avoid the randomness.
The 3D simulation results are shown in Fig. \ref{SimulationResults_3D}.



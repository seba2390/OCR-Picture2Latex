\section{Methodology}


% \begin{figure}[h]
% \centering
% \includegraphics[width=0.5\textwidth]{./img/ConceptOfReverseTree.png}
% \caption{Conceptual illustration of the lazy reverse searching tree. The start point $x_{start}$ and goal region $\mathcal{X}_{goal}$ are illustrated as the green and blue circles, respectively. The solid black lines are the valid edges of the forward-searching tree $\mathcal{T}_{\mathcal{F}}$, the blue dashed lines are the edges of the lazy reverse-searching tree $\mathcal{T}_{\mathcal{R}}$, which are not executable.}
% \label{ConceptOfReverseTree}
% \end{figure}


\subsection{Relevant Region}



% The Informed sampling set is defined as a $d$-dimensional prolate hyper-spheroid, as shown in Equation \ref{InformedRegionFunciton}, which only contains a small portion of the whole state space $X \in \Re^d$.

% \begin{equation}
% \begin{aligned}
% \mathcal{X}_{informed} = \{ x \in \mathcal{X}_{free} \ | \ h(x_s, x) + h(x, x_g) < c_{current} \}
% \label{InformedRegionFunciton}
% \end{aligned}
% \end{equation}


% The Informed sampling strategy directly takes samples in the Informed set, and prunes the samples and vertices outside the Informed region. 
% This will increase the sampling efficiency and maintain a compact forward tree $\mathcal{T}_{\mathcal{F}}$.
% The $d$-dimensional prolate hyper-spheroid is updated whenever the current optimal solution is optimized.

% $h(x_s, x)$ and $h(x, x_g)$ are the estimated heuristic from the initial state $x_{start}$ to state $x \in \mathcal{X}$ and from state $x \in \mathcal{X}$ to the goal state $x_{goal} \in \mathcal{X}_{goal}$, respectively.

In this article, we use the optimal forward-searching tree $\mathcal{T}_{\mathcal{F}}$ to provide the cost-to-come estimation $h_{\mathcal{T}_{\mathcal{F}}}(v)$ of any vertex $v \in \mathcal{T}_{\mathcal{F}}$.
With the optimization objective, the $h_{\mathcal{T}_{\mathcal{F}}}(v) = d_{\mathcal{T}_{\mathcal{F}}}(v_{start}, \ v)$ is defined as the cumulative cost from the initial state $x_{start}=v_{start} \in \mathcal{T}_{\mathcal{F}}$ to the vertex $v$ via the current tree $\mathcal{T}_{\mathcal{F}}$.
And the planner guarantees that the newly added vertex is optimally connected to $\mathcal{T}_{\mathcal{F}}$ with a global replanning function.

The Relevant Region is defined as a subset of $\mathcal{X}_{free}$ of which the cardinality is smaller than the Informed sampling set \cite{gammell2014informed}. 
Our Relevant Region sampling strategy uses the optimal forward-searching tree $\mathcal{T}_{\mathcal{F}}$ to provide the optimal cost-to-come estimation.
And using the lazy reverse-searching tree $\mathcal{T}_{\mathcal{R}}$ to estimate the cost-to-go of the state $x$ in the RGG, the estimated result can be represented as $h_{\mathcal{T}_{\mathcal{R}}}(x) = d_{\mathcal{T}_{\mathcal{R}}}(x, \ x_{goal})$.
With the $h_{\mathcal{T}_{\mathcal{F}}}$ and $h_{\mathcal{T}_{\mathcal{R}}}$, the definition of relevant vertex is shown in (\ref{RelevantVertices}), where the $\mathcal{V}$ is the vertices set of the optimal forward-searching tree $\mathcal{T}_{\mathcal{F}}$ and $v \in \mathcal{V}$ is any vertex belongs to the $\mathcal{T}_{\mathcal{F}}$.

% The cost-to-come estimated via the forward searching tree $\mathcal{T}_{\mathcal{F}}$ is defined as $h_{\mathcal{T}_{\mathcal{F}}}(v) = d_{\mathcal{T}_{\mathcal{F}}}(v_{start}, \ v)$.
% instead of using the direct link to calculate the cost-to-come.

\begin{equation}
\begin{aligned}
\mathcal{V}_{rel} = \{ v \in \mathcal{V} \ | \ h_{\mathcal{T}_{\mathcal{F}}}(v) + h_{\mathcal{T}_{\mathcal{R}}}(v) < c_{cur} \}.
\label{RelevantVertices}
\end{aligned}
\end{equation}

We define the ball centered at the vertex $v$ with radius $\epsilon$ as:

\begin{equation}
\begin{aligned}
\mathcal{B}^{\epsilon}(v) = \{ x \in \mathcal{X} \ | \ \left\| x - v \right\|_2 < \epsilon, v \in \mathcal{V}_{rel}\}.
\label{RelevantBall}
\end{aligned}
\end{equation}

With the $h_{\mathcal{T}_{\mathcal{F}}}(v)$ and the $h_{\mathcal{T}_{\mathcal{R}}}(x)$, the estimated solution cost that pass by the state $x \in \mathcal{B}^{\epsilon}(v)$ can be written as $\hat{f}_v(x) = h_{\mathcal{T}_{\mathcal{F}}}(v) + d(v, x) + h_{\mathcal{T}_{\mathcal{R}}}(x)$, where the $d(v, x)$ denotes cost from vertex $v$ to state $x$.
The Relevant Region with the adaptive heuristic estimation of the current forward-searching tree is defined as (\ref{RelevantRegion}).

\begin{equation}
\begin{aligned}
\mathcal{X}^{\epsilon}_{rel} = \{x \ | \ x \in \mathcal{B}^{\epsilon}(v), \hat{f}_v(x) < c_{cur} \}.
\label{RelevantRegion}
\end{aligned}
\end{equation}


\subsection{Relevant Region Sampling Strategy}

The ultimate optimization objective is shown in (\ref{TrajectoryLengthOptimizationObjective}).
To meet the optimization requirement with fewer sampling points, we propose a novel method to generate samples in the most promising region.
Let the new sample be $x_{new} \in \mathcal{X}_{free}$, and it is related to the relevant point $v_{rel} \in \mathcal{V}_{rel}$, where $v_{rel}$ is chosen from the queue $\mathcal{Q}$ with the highest priority.
The $\mathcal{Q}$ is defined in terms of (\ref{WeightFunction}). 
The relationship between $x_{new}$ and $v_{rel}$ is $x_{new} = v_{rel} + \gamma e$.
where $\{ e\in E \ | \ e \in \Re^d, \left\| e \right\|_2 = 1\}$ denotes the direction for expanding which points from $v_{rel}$ to $x_{new}$, and $\gamma$ is a positive number which indicats the maximum promising cost magnitude to travel along the direction $e$, bounded by $\left(0, \gamma_{max} \right]$.
The sampling direction $e$ is generated by utilizing the information provided by the $\mathcal{T}_{\mathcal{R}}$, which is the direction along the edge of the $\mathcal{T}_{\mathcal{R}}$ pointing to the goal. 
Then we will use the solution of the following optimization problem to guide the sampling.

\begin{equation}
\begin{aligned}
\max & \ \gamma, \\
subject \ to: & \ \hat{f}_v(x) < c_{cur}, \\
& \ \gamma \in (0, \gamma_{max}].
\label{OptimizationProblem}
\end{aligned}
\end{equation}

The inequality in (\ref{OptimizationProblem}) equals to $h_{\mathcal{T}_{\mathcal{F}}}(v) + d(v, x) + h_{\mathcal{T}_{\mathcal{R}}}(x) < c_{cur}$. Then we will have:

\begin{equation}
\begin{aligned}
h_{\mathcal{T}_{\mathcal{R}}}(x) < c_{cur} - h_{\mathcal{T}_{\mathcal{F}}}(v) - \gamma.
\label{Reformate_1}
\end{aligned}
\end{equation}

Note that the right-hand side of the (\ref{Reformate_1}) is always positive,
we can obtain another inequality $\gamma < c_{cur} - h_{\mathcal{T}_{\mathcal{F}}}(v)$.
If the right-hand side $c_{cur} - h_{\mathcal{T}_{\mathcal{F}}}(v)$ is smaller than $0$, the outgoing edges connecting to $v$ and its children will be erased from the forward-searching tree $\mathcal{T}_{\mathcal{F}}$ iteratively.

By moving the $d(v, x) = \gamma$ in (\ref{OptimizationProblem}) to the left-hand side, we can get:

\begin{equation}
\begin{aligned}
\gamma < c_{cur} - h_{\mathcal{T}_{\mathcal{F}}}(v) - h_{\mathcal{T}_{\mathcal{R}}}(x).
\label{OptimizationSolution}
\end{aligned}
\end{equation}

So the (\ref{OptimizationSolution}) is the solution for the best cost magnitude to travel along direction $e$.
After giving the $\gamma$ an upper bound $\gamma_{max}$ for expanding, the final solution is:

\begin{equation}
\begin{aligned}
\gamma_{rel} =
min(c_{cur} - h_{\mathcal{T}_{\mathcal{F}}}(v) - h_{\mathcal{T}_{\mathcal{R}}}(x),\ \gamma_{max} ).
\label{GammaRelevant}
\end{aligned}
\end{equation}

% There may be some vertices $v \in \mathcal{T}_{\mathcal{F}}$ are not connected to the $\mathcal{T}_{\mathcal{R}}$. 
% In that situation, we have to use the cumulative cost along the direct link as the heuristic.
% So the solution of the optimization is shown in Equation. \ref{OriginalGamma} \cite{joshi2020relevant}.

% \begin{equation}
% \begin{aligned}
% & \gamma_{relevant} = \\
% & min((c_{cur} - h_{\mathcal{T}_{\mathcal{F}}}(v) + \left\| x_{goal} - v \right\|_2)/2, \ \gamma_{max}).
% \label{OriginalGamma}
% \end{aligned}
% \end{equation}

The calculated step size $\gamma_{rel}$ may be a negative number since the $h_{\mathcal{T}_{\mathcal{F}}}(v)$ and $h_{\mathcal{T}_{\mathcal{R}}}(x)$ always overestimate the cost.
In that case, the result will be invalid.




\begin{figure}[t]
    \centering
    \includegraphics[width=0.5\textwidth]{./img/RandomDirection.png}
    \caption{We add randomness to the $e$ and $\gamma$ since the lazy reverse-searching method can not guarantee edges in the $\mathcal{T}_{\mathcal{R}}$ are valid. 
    In this figure, the black blocks, solid green lines, dashed blue lines, and orange points represent the obstacles, forward tree, reverse tree, and the points in the current RGG, respectively.
    The right part of the figure is the local zoom of the left part.
    The purple circular sector shows the region where we may take samples in terms of the vertex $v_{rel}$.
    The region with darker purple has a higher probability of being sampled.}
    \label{RandomDirection}
\end{figure}

\begin{algorithm}[t]
    \caption{Relevant Sampling Strategy with Adaptive Heuristic Estimation for Asymptotically Optimal Motion Planning}
    \label{MainFunction}
        \hspace*{\algorithmicindent} \textbf{Input: $x_{start} \in \mathcal{X}_{free}$, $\mathcal{X}_{goal} \subset \mathcal{X}_{free}$ }; \\
        \hspace*{\algorithmicindent} \textbf{Output: $\mathcal{T}_{\mathcal{F}}$};
        \begin{algorithmic}[1]
        \State Init($\mathcal{T}_{\mathcal{F}}$, $\mathcal{T}_{\mathcal{R}}$, $\mathcal{V}_{sol}$);
        \While{\textbf{not} TerminateCondition()}
            \State $\mathcal{X}_{\mathcal{S}_{reuse}} \gets$ Prune($\mathcal{X}_{\mathcal{S}}$, $\mathcal{T}_{\mathcal{F}}$, $\mathcal{T}_{\mathcal{R}}$);   \label{pruneFunction}
            \State $\mathcal{X}_{\mathcal{S}_{new}} \gets$ Sample($m$, $P_{Inf}$, $\mathcal{T}_{\mathcal{F}}$);  \label{SampleLine}
            \State $\mathcal{X}_{\mathcal{S}} \gets \mathcal{X}_{\mathcal{S}_{reuse}} \cup \mathcal{X}_{\mathcal{S}_{new}}$;
            \State $\mathcal{T}_{\mathcal{R}}$ $\gets$ BuildReverseTree($\mathcal{X}_{\mathcal{S}}$);
            \State $\mathcal{T}_{\mathcal{F}}$ $\gets$ BuildForwardTree($\mathcal{T}_{\mathcal{F}}$, $\mathcal{T}_{\mathcal{R}}$); \label{BuildForwardTreeLine}
        \EndWhile
        \State \textbf{return} $\mathcal{T}_{\mathcal{F}}$;
    \end{algorithmic}
\end{algorithm}








% In addition, the vertices in the $\mathcal{T}_{\mathcal{R}}$ will be pruned if a local part of its branches is overcrowded, this will maintain a relatively uniformly distributed RGG and avoid over exploring a particular area.


% The Relevant Region sampling strategy will select one vertex $v_{expand} \in \mathcal{T}_{forward}$ which has the highest priority and calculate the expanding direction $\hat{e}$ and the best step size $\hat{\gamma}$. 
% Once the generated point $\hat{x}_{new}$ is valid, the $\hat{x}_{new}$ will be added to the batch, and the edge $(\hat{x}_{new}, v_{expand})$ is insert into the $\mathcal{Q}_{edges}$ for expansion.
% If the $\mathcal{T}_{\mathcal{R}}$ fails to provide a cost-to-go estimation, we will use $ \lambda \left\| \hat{x}_{new} - x_{goal} \right\|_2$ to estimate it, where the $\lambda$ is a punishment term since the Euclidean metric always underestimate the cost between two states.



% Since the randomly constructed RGG can not provide an ideal abstraction of the state space. 

% If $h_{\mathcal{T}_{\mathcal{F}}}(v) + h_{\mathcal{T}_{\mathcal{R}}}(v)/c_{cur} > 1$, the function will skip the vertex $v$. 

\begin{algorithm}[t]
	\caption{Sample($m$, $P_{Inf}$, $\mathcal{T}_{\mathcal{F}}$)}
    \label{SampleFunction}
        \begin{algorithmic}[1]
            \State $\mathcal{X}_{\mathcal{S}_{new}} \gets \emptyset $;
            \State $\mathcal{Q}$ = WeightVertices($\mathcal{T}_{\mathcal{F}}$); \label{WeightVertices}
            \State $\mathcal{X}_{\mathcal{S}_{new}} \gets $ $\mathcal{X}_{\mathcal{S}_{new}} \cup $ SampleRel($Q$); \label{RelevantSampleLine}
            \State $\mathcal{X}_{\mathcal{S}_{new}} \gets $ $\mathcal{X}_{\mathcal{S}_{new}} \cup $ SampleInf($m - \mathcal{X}_{\mathcal{S}_{new}}.size()$);
            \State \textbf{return} $\mathcal{X}_{\mathcal{S}_{new}}$;
        \end{algorithmic}
\end{algorithm}

\begin{equation}
    \begin{aligned}
        \label{WeightFunction}
        \mathcal{W} = \lambda_1 n_{s} + \lambda_2 n_{o} + \lambda_3 \frac{h_{\mathcal{T}_{\mathcal{F}}}(v) + h_{\mathcal{T}_{\mathcal{R}}}(v)}{c_{cur}}.
    \end{aligned}
\end{equation}

\begin{algorithm}[t]
	\caption{SampleRel($\mathcal{Q}$)}
    \label{SampleRelevantRegion}
        \begin{algorithmic}[1]
            \State $ExpandTimes$ = $int( (1 - P_{Inf}) m / \mathcal{Q}.size() )$;    \label{NumOfReleventQueue}
            \For{$v_{elem}$ \textbf{in} $\mathcal{Q}$}
                \State $\gamma$, $e$ = EstimateStepSizeAndDirection($v_{elem}$);
                \For{$iter$ \textbf{in} $iter = 1, 2, 3, \dots, ExpandTimes$}
                    \State $\hat{\gamma}$, $\hat{e}$ = GaussianNoise($\gamma$, $e$);
                    \State $\mathcal{X}_{\mathcal{S}_{new}}.append(v_{elem} + \hat{\gamma}\hat{e})$;
                \EndFor
            \EndFor
            \State \textbf{return} $\mathcal{X}_{\mathcal{S}_{new}}$;
        \end{algorithmic}
\end{algorithm}

\begin{algorithm}[t]
    \caption{BuildForwardTree($\mathcal{T}_{\mathcal{F}}$, $\mathcal{T}_{\mathcal{R}}$)}
    \label{BuildForwardTreeFunction}
        \begin{algorithmic}[1]
            \While{$\mathcal{Q}_{V}$.best() $\leq$ $\mathcal{Q}_{E}$.best()} \label{ExpandNextVertex}
            \State ExpandNextVertex($\mathcal{Q}_{V}$, $\mathcal{Q}_{E}$, $c_{cur}$);    
            \EndWhile
            \While{True}
            \State ($v_{min}$, $x_{min}$) $\gets$ PopBest($\mathcal{Q}_{E}$);
            \If{$g_{\mathcal{T}}(v_{min}) + \hat{c}(v_{min}, x_{min}) + \hat{h}(x_{min}) < c_{cur}$}
                \If{$g_{\mathcal{T}}(v_{min}) + \hat{c}(v_{min}, x_{min}) < g_{\mathcal{T}}(x_{min})$}
                    \State $c_{edge} \gets c(v_{min}, x_{min})$;
                    \If{$g_{\mathcal{T}}(v_{min}) + c_{edge} + \hat{h}(x_{min}) < c_{cur}$}
                        \If{$g_{\mathcal{T}}(v_{min}) + c_{edge} < g_{\mathcal{T}}(x_{min})$}   \label{EndPostpone}
                            \State $\mathcal{T}_{\mathcal{F}} \gets$ Extend($\mathcal{T}_{\mathcal{F}}$, $x_{min}$);
                            \State $\mathcal{T}_{\mathcal{F}}$ $\gets$ Replan($\mathcal{T}_{\mathcal{F}}$);
                            \State $c_i \gets min_{v_{goal} \in \mathcal{V}_{sol} }\{ g_\mathcal{T}(v_{goal}) \}$;
                        \EndIf
                    \EndIf
                \EndIf
            \Else 
                \State $\mathcal{Q}_V \gets \emptyset$; $\mathcal{Q}_E \gets \emptyset$;
                \State \textbf{break};
            \EndIf
            \EndWhile
        \end{algorithmic}
\end{algorithm}

In the implementation, each vertex will be used to calculate random sampling points multiple times with different random distortions in each iteration.
We add the random distortions to both the $e$ and $\gamma$ because edges in the $\mathcal{T}_{\mathcal{R}}$ are not valid under the constraints, and direct search along $e$ is not promising.
The searching direction and the expanding distance with random distortion are denoted as $\hat{e}$ and $\hat{\gamma}$, respectively, and the new sample is $\hat{x}_{new} = v_{rel} + \hat{\gamma}\hat{e}$.
We illustrate this in Fig. \ref{RandomDirection}.
The pale green points circled by the dotted lines in the right-hand side of Fig. \ref{RandomDirection} indicate the newly added sampling points with our direct sampling method in the current batch. 

\subsection{Proposed Algorithm}

\input{planningProcedure.tex}

The planning problem is defined by the state space $\mathcal{X}$, together with the start point $x_{start}$ and goal region $\mathcal{X}_{goal}$. 
The $\mathcal{T}_{\mathcal{F}}$, $\mathcal{T}_{\mathcal{R}}$, and $\mathcal{V}_{sol}$ are initialized as the $\emptyset$.
Our planner will try to find the optimal solution to the problem described in the (\ref{TrajectoryLengthOptimizationObjective}).


In the proposed method, we separate the sampling stage and the searching stage into two explicitly different procedures instead of performing them alternatively in each iteration. 
When processing the sampling stage, we sample a batch of points with the proposed sampling strategy.
In the searching stage, we perform the lazy reverse-searching and construct the $\mathcal{T}_{\mathcal{R}}$ implicitly, then expand the $\mathcal{T}_{\mathcal{F}}$ in terms of the adaptively heuristic estimation provided by the $\mathcal{T}_{\mathcal{R}}$. 
The replanning function will guarantee that all promising vertices in $\mathcal{T}_{\mathcal{F}}$ are optimal under the current topology abstraction. 
In the next iteration, samples in the previous batch are reused as long as they satisfy the inequation described in (\ref{RelevantRegion}).
The $\mathcal{T}_{\mathcal{R}}$ will be disposed of by the end of each iteration, we re-construct the $\mathcal{T}_{\mathcal{R}}$ from the sketch instead of rewiring it in the next iteration, this is due to the concern of the time efficiency.
The procedure of constructing the $\mathcal{T}_{\mathcal{R}}$ can be viewed as a simplified version of the heuristic-based FMT* algorithm without the edge evaluation.
Based on the proposed ideas, we designed the basic workflow of our method, as shown in the Algorithm. \ref{MainFunction}.




In the Line. \ref{pruneFunction} of Algorithm. \ref{MainFunction}, we include the graph pruning method to keep the cardinalities of forward and reverse trees as small as possible.
Graph pruning can enhance query efficiency.
If a sample is not connected to both the $\mathcal{T}_{\mathcal{F}}$ and the $\mathcal{T}_{\mathcal{R}}$ in the previous iteration or the sample is outside the promising region, we will prune it.

The details of the sampling method in Line. \ref{SampleLine} in Algorithm. \ref{MainFunction} is illustrated in Algorithm. \ref{SampleFunction}, the $m$ represents the batch size and the $P_{Inf}$ shows the propability we sample in the Informed space.
The $h_{\mathcal{T}_{\mathcal{F}}}(v)$ and $h_{\mathcal{T}_{\mathcal{R}}}(x)$ always over-estimate the cost, which means the Relevant Region with adaptive heuristic estimation itself can not guarantee the probabilistic completeness (adimissible heuristic in heuristic-based methods). 
Therefore, the samples in our method are generated in mixed mode. 
We use the direct sampling method to sample in the Informed space with the probability $P_{Inf}$. 
The function $\text{WeightVertices}(\mathcal{T}_{\mathcal{F}})$ will weight every vertex $v$ in the $\mathcal{T}_{\mathcal{F}}$ and put the weighted vertices into a priority queue $\mathcal{Q}$. 
The weight $\mathcal{W}$ of a particular vertex is designed according to its selected times $n_{s}$, outgoing edges $n_{o}$, and adaptively heuristic.
The weighting method is shown in (\ref{WeightFunction}), where the $\lambda_1$, $\lambda_2$, and $\lambda_3$ modulate the behavior of our weighting function \cite{joshi2020relevant}.
And the adaptively heuristic is normalized by the current optimal solution.
When generating the new samples, the construction of $\mathcal{T}_{\mathcal{R}}$ upon the current batch is not yet started.
Therefore, the estimated cost-to-go of state in $\mathcal{X}_{\mathcal{S}_{reuse}}$ comes from the $\mathcal{T}_{\mathcal{R}}$ of the last iteration, 
the newly added sample uses the optimal value of $h_{\mathcal{T}_{\mathcal{R}}}(x_{near}) + d(x, x_{near})$, where $h_{\mathcal{T}_{\mathcal{R}}}(x_{near})$ is the cost-to-go of its neighbors.
All samples in $\mathcal{X}_{\mathcal{S}}$ are stored in the GNAT.


\input{SimulationResults_2D.tex}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.46\textwidth]{./img/envs_2D.png}
    \caption{The 2D simulation environments. They are the 'BugTrap', the 'Maze', and the 'RandomPolygons' in the OMPL benchmark platform, respectively. The red cuboid shows the start state and the state in the goal region.}
    \label{SimulationEnvironments_2D}
\end{figure}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.46\textwidth]{./img/envsWithPath_2D.png}   
    \caption{The trajectories found by our planner in the 'BugTrap', the 'Maze', and the 'RandomPolygons' in the OMPL benchmark platform.}
    \label{SimulationPath_2D}
\end{figure}




The function $SampleRel(Q)$ in Line. \ref{RelevantSampleLine}, Algorithm. \ref{SampleFunction} is the method we use to generate samples with the proposed Relevant Region sampling strategy.
Details are shown in Algorithm. \ref{SampleRelevantRegion}. 
The variable $ExpandTimes$ shows the number of samples generated in terms of vertex $v_{elem}$ with different distortions.
The function $\text{SampleInf}()$ will take $m - \mathcal{X}_{\mathcal{S}_{new}}.size()$ samples in the Informed space \cite{gammell2018informed}.



% Once the initial feasible solution is found or a better solution is generated, the graph pruning will be enabled to reduce the number of points in the RGG with the Equation. \ref{InformedRegionFunciton}.

We utilize the idea of avoiding evaluating every edge in the forward-searching, which comes from the BIT* algorithm \cite{gammell2020batch}.
We illustrate the details of the function $\text{BuildForwardTree}(\mathcal{T}_{\mathcal{F}}, \mathcal{T}_{\mathcal{R}})$ (Line. \ref{MainFunction}, Algorithm. \ref{BuildForwardTreeLine}) in Algorithm. \ref{BuildForwardTreeFunction}.
The vertices in the $\mathcal{T}_{\mathcal{F}}$ will be put in an ordered queue $\mathcal{Q}_{V}$, the $\mathcal{Q}_{V}$ is sorted in terms of $\hat{f}(v) = h_{\mathcal{T}_{\mathcal{F}}}(v) + h_{\mathcal{T}_{\mathcal{R}}}(v)$. 
The $\mathcal{Q}_{E}$ is an ordered queue for the promising edges, which is sorted in terms of $h_{\mathcal{T}_{\mathcal{F}}}(v) + d(v, \hat{x}) + h_{\mathcal{T}_{\mathcal{R}}}(\hat{x})$.
Function $\hat{c}(v_{min}, x_{min})$ and $c(v_{min}, x_{min})$ calculate the estimated cost and the actual cost between vertex $v_{min}$ and state $x_{min}$.
The function $\text{Replan}(\mathcal{T}_{\mathcal{F}})$ guarantees the $\mathcal{T}_{\mathcal{F}}$ is optimal under current space abstraction \cite{arslan2013use}.


Whenever the planner generates a new feasible path connecting the start and the goal, it will trace back along the $\mathcal{T}_{\mathcal{F}}$ and compare it with the current optimal solution path. 
If the newly added path is better, the planner will output a new solution path and use the graph pruning method to restrict the samples to a more compact region.
Otherwise, the planning process will continue until the termination condition is met.
\vspace{-0.5em}
\section{Evaluation}
\vspace{-0.5em}

\begin{figure}
    \includegraphics[width=1.0\linewidth,valign=m]{figures/stepwise.pdf}
    \caption{An iterative editing workflow where the user modifies individual layers of generated images for the \textbf{Cake} and \textbf{Bento Box} scenes. In each example, the user generates an initial image using \textit{Collage Diffusion}, then improves the images using two refinement iterations, re-generating one of the original input layers in each refinement iteration. }
    \label{fig:stepwise}
\end{figure}

\begin{figure}[!htbp]
    \centering
    \textbf{Toys}

    ``a \ul{teddy bear}, a \ul{wood train}, and an \ul{american football}, in front of a \ul{tan background}''
    \begin{adjustbox}{max size={\linewidth}{\textheight}}
        \begin{tabular}[t]{p{.32\linewidth}|p{.32\linewidth}p{.32\linewidth}p{.32\linewidth}p{.32\linewidth}p{.32\linewidth}}
        \hfil\textbf{Input Layers (4)} & \hfil\textbf{SA} & \hfil\textbf{GH} & \hfil\textbf{GH+CA} & \hfil\textbf{GH+CA+TI} & \hfil\textbf{GH+CA+TI+LN} \\
        \includegraphics[width=\linewidth,valign=m]{claim_1/toyBoxFinal/init.jpg}  & \includegraphics[width=\linewidth,valign=m]{claim_1/toyBox/pnp.jpg} & \includegraphics[width=\linewidth,valign=m]{claim_1/toyBoxFinal/img2img-no_cac-no_ft-no_mask/8.jpg} & \includegraphics[width=\linewidth,valign=m]{claim_1/toyBoxFinal/img2img-with_cac-no_ft-no_mask/8.jpg} & \includegraphics[width=\linewidth,valign=m]{claim_1/toyBoxFinal/img2img-with_cac-with_ft-no_mask/8.jpg} & \includegraphics[width=\linewidth,valign=m]{claim_1/toyBoxFinal/img2img-with_cac-with_ft-with_mask/8.jpg} \\
        & Issues with harmonization on the football and merged teddy bears, no wood train in the bottom left & Harmonized image, no wood train in the bottom left & Wood train in the bottom left & Wood train with styling of wood closer to the starting image, white face and tie of teddy bear preserved & Wood train very similar to the original train, red color of tie preserved
    \end{tabular}
    \end{adjustbox}

    \textbf{Bento Box}

    ``a \ul{bento box} with \ul{rice}, \ul{edamame}, \ul{ginger}, and \ul{sushi}''
    \begin{adjustbox}{max size={\linewidth}{\textheight}}
        \begin{tabular}[t]{p{.32\linewidth}|p{.32\linewidth}p{.32\linewidth}p{.32\linewidth}p{.32\linewidth}p{.32\linewidth}}
            \hfil\textbf{Input Layers (5)} & \hfil\textbf{SA} & \hfil\textbf{GH} & \hfil\textbf{GH+CA} & \hfil\textbf{GH+CA+TI} & \hfil\textbf{GH+CA+TI+LN} \\
            \includegraphics[width=\linewidth,valign=m]{claim_1/bentoBoxFinal/init.jpg} & \includegraphics[width=\linewidth,valign=m]{claim_1/bentoBox/pnp.jpg} & \includegraphics[width=\linewidth,valign=m]{claim_1/bentoBoxFinal/img2img-no_cac-no_ft-no_mask/18.jpg} & \includegraphics[width=\linewidth,valign=m]{claim_1/bentoBoxFinal/img2img-with_cac-no_ft-no_mask/18.jpg} & \includegraphics[width=\linewidth,valign=m]{claim_1/bentoBoxFinal/img2img-with_cac-with_ft-no_mask/18.jpg} & \includegraphics[width=\linewidth,valign=m]{claim_1/bentoBoxFinal/img2img-with_cac-with_ft-with_mask/18.jpg} \\
            & Sushi orientation and shading not harmonized, edamame in place of ginger on the top left & Harmonized image, sushi in place of ginger in the top left, wasabi in place of rice in bottom left, no sushi in bottom right & Sushi and rice in currect locations, ginger paste instead of sliced sushi ginger in the top left & Sliced sushi ginger in the top left, darker rice in the bottom left, sushi on right more similar to layer & Sliced sushi ginger in the top left, dark rice in bottom left, sushi on right very similar to layer
        \end{tabular}
    \end{adjustbox}

    \textbf{Cake}

    ``a \ul{wood table} with two \ul{white chairs} behind, two \ul{pink decorated cakes} on top, \ul{maroon bookshelves} behind, and \ul{winter window}'' 
    \begin{adjustbox}{max size={\linewidth}{\textheight}}
        \begin{tabular}[t]{p{.32\linewidth}|p{.32\linewidth}p{.32\linewidth}p{.32\linewidth}p{.32\linewidth}p{.32\linewidth}}
            \hfil\textbf{Input Layers (5)} & \hfil\textbf{SA} & \hfil\textbf{GH} & \hfil\textbf{GH+CA} & \hfil\textbf{GH+CA+TI} & \hfil\textbf{GH+CA+TI+LN} \\
            \includegraphics[width=\linewidth,valign=m]{claim_1/cakeTable3Final/init.jpg} & \includegraphics[width=\linewidth,valign=m]{claim_1/cakeTable3/pnp.jpg} & \includegraphics[width=\linewidth,valign=m]{claim_1/cakeTable3Final/img2img-no_cac-no_ft-no_mask/0.jpg} & \includegraphics[width=\linewidth,valign=m]{claim_1/cakeTable3Final/img2img-with_cac-no_ft-no_mask/0.jpg} & \includegraphics[width=\linewidth,valign=m]{claim_1/cakeTable3Final/img2img-with_cac-with_ft-no_mask/0.jpg} & \includegraphics[width=\linewidth,valign=m]{claim_1/cakeTable3Final/img2img-with_cac-with_ft-with_mask/0.jpg} \\
            & Cake orientation not harmonized, bookshelf angle not harmonized, artifacts in the cakes, artifacts on the edges of the chairs & Harmonized image, white cakes in place of the chairs, no bookshelf & Brown table legs instead of black in the bottom right, chairs in the correct locations in top left, not many books on bookshelf in the top left, wooden floor around table & Black table leg in the bottom right, bookshelf with a few more books in the top left, wooden floor around table & Bookshelf with many books in the top left, carpet floor around the table
        \end{tabular}
    \end{adjustbox}
\caption{(Part 1) By leveraging layer information, \textit{Collage Diffusion} generates images with greater spatial and appearance fidelity than the baseline \textbf{GH} approach. For each scene above, there are several aspects in which \textbf{CA}, \textbf{TI}, and \textbf{LN} improve fidelity; we comment on some of these aspects in each row. Compared to \textbf{GH}, \textbf{SA} fails to effectively harmonize input layers; we comment on issues with harmonization in each row. }
\label{fig:mainResults1}
\end{figure}

\begin{figure}
    \centering

    \textbf{Veggie Face}

    ``a face made of vegetables, including a \ul{yellow bell pepper} and a \ul{green bell pepper}, a \ul{white cauliflower}, \ul{red potatoes}, \ul{baby corn}, \ul{small cucumber}, \ul{bean sprouts}, and \ul{floret broccoli}, on a \ul{grey background}''
    \begin{adjustbox}{max size={\linewidth}{\textheight}}
        \begin{tabular}[t]{p{.32\linewidth}|p{.32\linewidth}p{.32\linewidth}p{.32\linewidth}p{.32\linewidth}p{.32\linewidth}}
            \hfil\textbf{Input Layers (9)} & \hfil\textbf{SA} & \hfil\textbf{GH} & \hfil\textbf{GH+CA} & \hfil\textbf{GH+CA+TI} & \hfil\textbf{GH+CA+TI+LN} \\
            \includegraphics[width=\linewidth,valign=m]{claim_1/arcimboldoFinal/init.jpg} & \includegraphics[width=\linewidth,valign=m]{claim_1/arcimboldo2/pnp.jpg} & \includegraphics[width=\linewidth,valign=m]{claim_1/arcimboldoFinal/img2img-no_cac-no_ft-no_mask/6.jpg} & \includegraphics[width=\linewidth,valign=m]{claim_1/arcimboldoFinal/img2img-with_cac-no_ft-no_mask/6.jpg} & \includegraphics[width=\linewidth,valign=m]{claim_1/arcimboldoFinal/img2img-with_cac-with_ft-no_mask/6.jpg} & \includegraphics[width=\linewidth,valign=m]{claim_1/arcimboldoFinal/img2img-with_cac-with_ft-with_mask/6.jpg} \\
            & Image missing shadows, some potatoes replaced with bell peppers, beans in chin, corn mustache missing & Harmonized image, missing cucumber mouth, corn mustache, sprout beard, red potatoes & Cucumber in correct location, but corn and most bean sprouts missing, red potatoes in correct location & Small cucumber slices for mouth, and some surrounding sprouts that look very different from the ones in the starting image & Bean sprouts more similar to starting image, sliced cucumber mouth more similar to layer, corn mustache in correct location and in natural orientation for a mustache
        \end{tabular}
    \end{adjustbox}

    \textbf{Striped Sweater}

    ``a man wearing \ul{green pants}, a \ul{blue and green striped sweater}, a \ul{plaid scarf}, and a \ul{maroon beanie}''
    \begin{adjustbox}{max size={\linewidth}{\textheight}}
        \begin{tabular}[t]{p{.32\linewidth}|p{.32\linewidth}p{.32\linewidth}p{.32\linewidth}p{.32\linewidth}p{.32\linewidth}}
            \hfil\textbf{Input Layers (4)} & \hfil\textbf{SA} & \hfil\textbf{GH} & \hfil\textbf{GH+CA} & \hfil\textbf{GH+CA+TI} & \hfil\textbf{GH+CA+TI+LN} \\
            \includegraphics[width=\linewidth,valign=m]{claim_1/clothing4/init.jpg} & \includegraphics[width=\linewidth,valign=m]{claim_1/clothing4/pnp.jpg} & \includegraphics[width=\linewidth,valign=m]{claim_1/clothing4Final/img2img-no_cac-no_ft-no_mask/7.jpg} & \includegraphics[width=\linewidth,valign=m]{claim_1/clothing4Final/img2img-with_cac-no_ft-no_mask/7.jpg} & \includegraphics[width=\linewidth,valign=m]{claim_1/clothing4/img2img-with_cac-with_ft-no_mask/7.jpg} & \includegraphics[width=\linewidth,valign=m]{claim_1/clothing4Final/img2img-with_cac-with_ft-with_mask/7.jpg} \\
            & Lack of harmonization in both the beanie on the head and the scarf mixing with the sweater, some artifacts from input layers preserved & Harmonized image, a green sweater missing dark stripes, scarf not plaid, blue beanie instead of maroon & A sweater striped with green and blue, plaid scarf, blue beanie instead of maroon & A sweater striped with green and blue that are closer to the original colors, plaid scarf with correct size of squares, pants closer to the style of the input & A sweater with very similar color and pattern to original
        \end{tabular}
    \end{adjustbox}

    \textbf{Ceramic Bowl}

    ``a \ul{blue ceramic bowl} with \ul{red potatoes}, \ul{red apples}, and \\ \ul{red bananas}''
    \begin{adjustbox}{max size={\linewidth}{\textheight}}
        \begin{tabular}[t]{p{.32\linewidth}|p{.32\linewidth}p{.32\linewidth}p{.32\linewidth}p{.32\linewidth}p{.32\linewidth}}
            \hfil\textbf{Input Layers (4)} & \hfil\textbf{SA} & \hfil\textbf{GH} & \hfil\textbf{GH+CA} & \hfil\textbf{GH+CA+TI} & \hfil\textbf{GH+CA+TI+LN} \\
            \includegraphics[width=\linewidth,valign=m]{claim_1/fruit4Final/init.jpg} & \includegraphics[width=\linewidth,valign=m]{claim_1/fruit4/pnp.jpg} & \includegraphics[width=\linewidth,valign=m]{claim_1/fruit4Final/img2img-no_cac-no_ft-no_mask/6.jpg} & \includegraphics[width=\linewidth,valign=m]{claim_1/fruit4Final/img2img-with_cac-no_ft-no_mask/6.jpg} & \includegraphics[width=\linewidth,valign=m]{claim_1/fruit4Final/img2img-with_cac-with_ft-no_mask/6.jpg} & \includegraphics[width=\linewidth,valign=m]{claim_1/fruit4Final/img2img-with_cac-with_ft-with_mask/6.jpg} \\
            & Apple orientations not harmonized & Harmonized image, hybrid mixtures of apples, bananas, and potatoes throughout bowl & Brown potatoes instead of red in the bottom left, some yellow in the red bananas & All objects in the desired locations & Banana structure matching layer
        \end{tabular}
    \end{adjustbox}

    \textbf{Red Skirt}

    ``a person wearing a \ul{patterned red skirt}, \ul{buttoned blue blouse}, and \ul{pink summer coat}, in front of a \\ \ul{gray background}''
    \begin{adjustbox}{max size={\linewidth}{\textheight}}
        \begin{tabular}[t]{p{.32\linewidth}|p{.32\linewidth}p{.32\linewidth}p{.32\linewidth}p{.32\linewidth}p{.32\linewidth}}
            \hfil\textbf{Input Layers (4)} & \hfil\textbf{SA} & \hfil\textbf{GH} & \hfil\textbf{GH+CA} & \hfil\textbf{GH+CA+TI} & \hfil\textbf{GH+CA+TI+LN} \\
            \includegraphics[width=\linewidth,valign=m]{claim_1/clothing3/init.jpg} & \includegraphics[width=\linewidth,valign=m]{claim_1/clothing3/pnp.jpg} & \includegraphics[width=\linewidth,valign=m]{claim_1/clothing3/img2img-no_cac-no_ft-no_mask/4.jpg} & \includegraphics[width=\linewidth,valign=m]{claim_1/clothing3/img2img-with_cac-no_ft-no_mask/4.jpg} & \includegraphics[width=\linewidth,valign=m]{claim_1/clothing3/img2img-with_cac-with_ft-no_mask/4.jpg}  & \includegraphics[width=\linewidth,valign=m]{claim_1/clothing3/img2img-with_cac-with_ft-no_mask/4.jpg} \\
            & Image artifact on the sleeve, all objects correctly mapped to the desired locations, layer image structure preserved & Harmonized image, all objects correctly mapped to the desired locations & No additional benefit from CA & TI introduces folds in the skirt & No further changes with \textbf{LN}
        \end{tabular}
    \end{adjustbox}

\caption{(Part 2) By leveraging layer information, \textit{Collage Diffusion} generates images with greater spatial and appearance fidelity than the baseline \textbf{GH} approach. See \cref{fig:mainResults1} caption for more detail. }
\label{fig:mainResults2}
\end{figure}

We primarily measure the value of layer information by analyzing the ability of \textit{Collage Diffusion} to generate globally harmonized images that respect the spatial layout and visual characteristics specified by input layers (the goals from \cref{sec:problem}). 
First, we evaluate \textit{Collage Diffusion} with a user in the loop, illustrating sample editing pipelines for multiple scenes.
We also analyze the value of layers for image harmonization in non-interactive settings, comparing \textit{Collage Diffusion} against multiple image harmonization approaches that take text prompt $c$ and composite image $x_c$ as input, flattening the layers rather than directly leveraging them. 
We additionally ablate the impact of the individual components of \textit{Collage Diffusion}. 
Finally, we explore the flexibility of layer-based controls by preserving the image structures of individual layers using ControlNet. 
We choose to focus on qualitative evaluation because our goals are primarily visual and because generative metrics for distributional comparison (FID, etc.) are not applicable in the layer-conditional setting where no ground-truth test dataset for ``the perfect output'' exists. 
Nevertheless, we also present a short quantitative study that mirrors our qualitative observations.

\vspace{-0.5em}
\subsection{Experimental Setup}
\vspace{-0.5em}

We evaluate the capacity of \textit{Collage Diffusion} to generate images without a user in the loop against two prior work baselines that do not use layer information. We also ablate \textit{Collage Diffusion} to create (1) a baseline that omits textual inversion but does modify cross-attention using layer information, and (2) a baseline that modifies cross-attention, leverages textual inversion, but does not enable per-layer control over harmonization.
We evaluate the performance of the following methods for a range of scenes: 
\begin{enumerate}%
    \item \textbf{SA}: Image generation with \textbf{S}elf-\textbf{A}ttention control via Plug-and-Play Diffusion \cite{tumanyan2022plug} applied to composite image $x_c$, with negative prompt ``A collage''. This is a baseline that does not leverage layer information, but maintains the image structure of $x_c$ via self-attention control.
    \item \textbf{GH}: \textbf{G}lobal \textbf{H}armonization by applying SDEdit \cite{sdedit} (\cref{method:SDEdit}) to composite image $x_c$. This is another baseline that does not leverage layer information. 
    \item \textbf{GH+CA}: \textbf{GH} with modified \textbf{C}ross-\textbf{A}ttention (\cref{method:CAC}). This builds upon \textbf{GH} by using layer information to improve spatial fidelity, but lacks specific mechanisms to improve appearance fidelity. 
    \item \textbf{GH+CA+TI}: \textbf{GH} applied to composite image $x_c$ with both \textbf{CA} learned per-layer representations via \textbf{T}extual \textbf{I}nversion \cite{TextualInversion} (\cref{method:TI}). This leverages layer information to improve both spatial and appearance fidelity.
    \item \textbf{GH+CA+TI+LN} (\textit{Collage Diffusion}): \textbf{GH} applied to composite image $x_c$ with both \textbf{CA} and \textbf{TI}, with per-\textbf{L}ayer \textbf{N}oise control (\cref{method:layerNoise}). This leverages layer information to improve both spatial and appearance fidelity, and allows user control over the harmonization-fidelity tradeoff on a per-layer basis.
\end{enumerate}
Controlled image-to-image techniques \cite{prompt2prompt,brooks2022instructpix2pix,tumanyan2022plug,mokady2022null} adhere too closely to starting image structure, as discussed in \cref{related:img2img}, resulting in performance worse than the \textbf{GH} baseline.
Here, we evaluate against one of these methods in \textbf{SA} \cite{tumanyan2022plug}; see the Appendix for additional discussion. 
\vspace{-0.5em}
\paragraph{Scene construction.}
We evaluate \textit{Collage Diffusion} on seven diverse scenes created using an interactive layer editor UI that provides controls similar to those in popular layer-based image editing software.
Creating a scene using the UI is simple and straightforward--see the Appendix for a video example.

\vspace{-0.5em}
\paragraph{Model and optimization.}
We use the Stable Diffusion \cite{latentDiffusion} 2.1 base model as $D_\theta$ for \textbf{GH}, \textbf{GH+CA}, \textbf{GH+CA+TI}, and \textbf{GH+CA+TI+LN}, and generate images using the Euler ancestral solver with 50 steps. 
For each scene, we tune the noise added to the image to qualitatively optimize the harmonization-fidelity tradeoff; values are between $t=0.7$ and $t=0.8$ for all scenes tested. 
We use the official PyTorch implementation of \textbf{SA} \cite{tumanyan2022plug}. 
\vspace{-0.5em}
\paragraph{Metrics} 
\vspace{-0.5em}
We use the following metrics for quantitative evaluation. Our spatial fidelity goals aim for layer text $c_i$ to match the visual content in $x^*_c$ in regions where layer $i$ is visible---we measure this by computing CLIP \cite{radford2021learning} text-image similarity between $c_i$ and the corresponding region of $x^*_c$. 
Appearance fidelity aims for layer image $x_i$ to match the visual content in $x^*_c$ where layer $i$ is visible---we measure this by computing CLIP image-image similarity between $x_i$ and the corresponding region of $x^*_c$. 
We include additional details on metrics in the Appendix.
\vspace{-0.5em}
\subsection{Interactive Editing} \label{exp:interactive}
\vspace{-0.5em}
We illustrate interactive editing with \textit{Collage Diffusion} by repeatedly (1) generating 10 images using different random seeds, (2) allowing the user to select the image they like the most, and (3) selecting an object in this image that they are unsatisfied with and would like to re-generate. This process continues until the user is satisfied with all aspects of the generated image. 

\cref{fig:stepwise} illustrates the value of \emph{Collage Diffusion} for interactively authoring complex scenes.
For the ``Cake'' scene, the user generates a final image in three steps: (1) generating an initial collection of images from the input layers, (2) exploring different options for the cake, and (3) exploring different options for the winter window. 
Similarly, for ``Bento Box,'' the user generates a final image in three steps: (1) generating an initial collection of images from the input layers, (2) exploring different options for the sushi, and (3) exploring different options for the ginger. 
We successfully preserve all previously-generated objects while providing a diverse set of options for each modified object that match the layer specifications. 
This interactive refinement procedure is valuable for ensuring that the user is satisfied with all parts of the generated image.
\vspace{-0.5em}
\subsection{Non-Interactive Generation} \label{exp:mainResults}
\vspace{-0.5em}
\begin{table}[]
    \begin{tabular}{l|llll}
              & \textbf{GH} & \textbf{GH+CA} & \textbf{GH+CA} & \textbf{GH+CA} \\ 
              & & & \textbf{+TI} & \textbf{+TI+LN} \\
    \hline
    $\uparrow$Txt-Img. Sim.& 0.215 & 0.236 & 0.233 & 0.238 \\
    $\uparrow$Img-Img. Sim.& 0.846 & 0.867 & 0.877 & 0.893 \\
    \end{tabular}
    \caption{\textbf{CA}, \textbf{TI}, and \textbf{LN} help \textit{Collage Diffusion} improve both spatial fidelity, as measured by per-layer text-image similarity with the input layers, and appearance fidelity, as measured by per-layer image-image similarity with the input layers. Metrics are averaged across 10 image seeds and all layers for seven scenes.}
    \label{table:clip}
\end{table}
\cref{fig:mainResults1} and \ref{fig:mainResults2} compare the visual output of \textit{Collage Diffusion} with the baseline methods. 
We did not cherry-pick the individual image seeds for each scene---additional examples from each test scene are included in the Appendix, and reflect the same overall trends. 
\vspace{-1em}
\paragraph{GH generates globally-harmonized images, while SA struggles with harmonization.}
Comparison of the \textbf{SA} and \textbf{GH} columns in \cref{fig:mainResults1} and \ref{fig:mainResults2} illustrates the capacity of \textbf{GH} to generate a harmonized image from input $x_c$ while highlighting the downsides of manipulating self-attention to preserve image structure in \textbf{SA}. When image harmonization requires altering the orientations of objects in the scene---the sushi in ``Bento Box,'' the cakes in ``Cake,'' the apples in ``Ceramic Bowl,'' etc.---\textbf{SA} fails to harmonize the image due to the constraints placed on the self-attention maps. In contrast, \textbf{GH} reliably generates globally-harmonized images: the images have consistent perspective and lighting, with fewer artifacts. 
\vspace{-1em}
\paragraph{CA consistently improves spatial fidelity across scenes.} 
Comparison of the \textbf{GH} and \textbf{GH+CA} columns in \cref{fig:mainResults1} and \ref{fig:mainResults2} illustrates the benefits of layer-based cross-attention control.
In ``Bento Box,'' using \textbf{CA} results in ginger and rice in the appropriate locations in the generated output. \textbf{CA} also helps preserve the table legs in ``Cake,'' maps the correct fruits to the correct parts of ``Ceramic Bowl,'' etc.
This trend is also reflected quantitatively: in \cref{table:clip}, \textbf{GH+CA} has a higher average per-layer text-image similarity than \textbf{GH}, indicating better spatial fidelity. 
\vspace{-1em}
\paragraph{TI consistently improves appearance fidelity across scenes.} Having mapped the desired concepts to the desired locations, comparison of the \textbf{GH+CA} and \textbf{GH+CA+TI} columns in \cref{fig:mainResults1} and \ref{fig:mainResults2} illustrates the benefits of layer-based textual representations. 
\textbf{TI} helps generate a wood train with similar style to the starting image in ``Toys,'' the right type of sushi ginger in ``Bento Box,'' the proper legs for the table in ``Cake,'' the correct color and shape for the potatoes in ``Ceramic Bowl,'' the proper saturation of colors and presence of wrinkles in ``Clothing,'' etc. 
This trend is also reflected quantitatively: in \cref{table:clip}, \textbf{GH+CA+TI} has a higher average per-layer image-image similarity than \textbf{GH+CA}, indicating better appearance fidelity. 
\vspace{-1em}
\paragraph{LN consistently helps optimize the harmonization-fidelity tradeoff across scenes}
Having mapped the desired concepts to the desired locations, with textual inversion to increase appearance fidelity, comparison of the \textbf{GH+C+TI} and \textbf{GH+CA+TI+LN} columns in \cref{fig:mainResults1} and \ref{fig:mainResults2} illustrates the benefits of control over per-layer noise.
\textbf{LN} increases the preservation of the structure of the wood train in ``Toys'', the salmon on the sushi in ``Bento Box'', the books on the bookshelves in ``Cake'', the shape of the bananas in ``Ceramic Bowl'', the stripes of the sweater in ``Striped Sweater'', the corn and cucumber in ``Veggie Face,'' etc. For all these scenes, the quality of image harmonization is maintained across \textbf{GH+C+TI} and \textbf{GH+CA+TI+LN}. 
This trend is also reflected quantitatively: in \cref{table:clip}, \textbf{GH+CA+TI+LN} has higher average per-layer text-image and image-image similarity than \textbf{GH+CA+TI}, indicating better spatial and appearance fidelity. 
\vspace{-1.0em}
\paragraph{Where is layer-driven harmonization most helpful?} 
To understand the situations where layer information is most valuable,
we highlight the ``Red Skirt'' (\cref{fig:mainResults2}) and ``Cake'' (\cref{fig:mainResults1}) scenes as examples at either end of the range of difficulty where layers are valuable. 
When harmonization requires limited changes to image structure, \textbf{SA} can be suitable---while \textbf{SA} still produces artifacts on ``Red Skirt'', the approach is more effective than on other scenes because fewer changes in image structure are required to harmonize the image. 
When objects are easy to discriminate even after noise is added (large objects with distinct colors), \textbf{GH} performs well, and \textbf{GH+CA} provides negligible added value.
If the visual attributes that the user cares to preserve in the layer are well-described by the layer prompt, \textbf{TI} may be unnecessary---in \cref{fig:mainResults2}, the only added benefit in ``Red Skirt'' comes from the preservation of the folds on the skirt and the dark band around the waist.

On the other end of the spectrum, when the user is particular on the \emph{exact} appearance of many complex layers, even \textit{Collage Diffusion} may struggle to satisfy user intent across all objects in the scene. For instance, in ``Cake,'' the user may want a specific color and icing pattern on the cake, a snowy pine outside the window, a full bookshelf, etc. For these situations, our iterative editing workflow is valuable, as highlighted in \cref{exp:interactive} and \cref{fig:stepwise}.
\vspace{-0.5em}
\subsection{Flexible per-layer controls with ControlNet} \label{exp:ControlNet}
\vspace{-0.5em}

\begin{figure}
\begin{adjustbox}{max size={\linewidth}{\textheight}}
    \begin{tabular}[t]{p{.32\linewidth}p{.32\linewidth}|p{.32\linewidth}|p{.32\linewidth}p{.32\linewidth}p{.32\linewidth}p{.32\linewidth}}
        \hfil\textbf{Prompt} & \hfil\textbf{Input Layers} & \hfil\textbf{Preserved} & & \hfil\textbf{Outputs} & \\ 
            & & \hfil\textbf{features} & & & \\ 
    \hline
    {\begin{tiny}A \ul{pirate ship} moving across a \ul{stormy ocean with waves} colliding into a \ul{rocky shore} containing a \ul{lighthouse} on top, \ul{dark storm clouds} with lightning in the background\end{tiny}}& \includegraphics[width=\linewidth,valign=t]{interface_images/ship_input.png}
    & Preserve edges: ship, rocks, lighthouse & \includegraphics[width=\linewidth,valign=t]{interface_images/ship_1.png} & \includegraphics[width=\linewidth,valign=t]{interface_images/ship_2.png} & \includegraphics[width=\linewidth,valign=t]{interface_images/ship_3.png} \\
    \begin{tiny}A \ul{house} with a \ul{pink cherry blossom} next to a \ul{swimming pool} with a stone pool deck in the \ul{backyard}, \ul{sky with birds flying} in the background\end{tiny} & \includegraphics[width=\linewidth,valign=t]{interface_images/house_input.png}
    & Preserve edges: house, backyard & \includegraphics[width=\linewidth,valign=t]{interface_images/house_1.png} & \includegraphics[width=\linewidth,valign=t]{interface_images/house_2.png} & \includegraphics[width=\linewidth,valign=t]{interface_images/house_3.png} \\
    \end{tabular}
\end{adjustbox}
\caption{ControlNet lets users preserve edge maps on a per-layer basis. First row: high ControlNet weights preserve edge maps for the ships, rocks, and lighthouse. Second row: high ControlNet weights preserve edge maps for the house and the backyard.}
\label{fig:controlnet}
\end{figure}

In \cref{fig:controlnet}, our ControlNet extension enables users to preserve image structures on a per-layer basis. In the first row, high ControlNet weights preserve the edge maps of the ships, rocks, and lighthouse (note that the colors/textures of the rocks and lighthouse vary). The generated images have more variation in the ocean and sky. In the second row, high ControlNet weights strictly preserve the structure of the house, while loosely preserving the layout of the backyard, and allowing variation in the pool shape and pattern of birds in the sky. 


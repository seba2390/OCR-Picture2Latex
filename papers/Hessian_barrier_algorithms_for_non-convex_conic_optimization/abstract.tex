%----------------------------------------------------------------------
%%% Abtract
%----------------------------------------------------------------------
% !TEX root = ./HBAConicMain.tex
%
A key problem in mathematical imaging, signal processing and computational statistics is the minimization of non-convex objective functions that may be non-differentiable at the boundary of the feasible set. This paper proposes a new family of first- and second-order interior-point methods for non-convex optimization problems with linear and conic constraints, combining logarithmically homogeneous barriers with quadratic and cubic regularization respectively. Our approach is based on a potential-reduction mechanism and, under the Lipschitz continuity of the corresponding derivative with respect to the local barrier-induced norm, attains a suitably defined class of approximate first- or second-order KKT points with worst-case iteration complexity $O(\eps^{-2})$ (first-order) and $O(\eps^{-3/2})$ (second-order), respectively. Based on these findings, we develop new path-following schemes attaining the same complexity, modulo adjusting constants. These complexity bounds are known to be optimal in the unconstrained case, and our work shows that they are upper bounds in the case with complicated constraints as well. 
%A key feature of our methodology is the use of self-concordant barriers to construct strictly feasible iterates via a disciplined decomposition approach and without sacrificing on the iteration complexity of the method. 
To the best of our knowledge, this work is the first which achieves these worst-case complexity bounds under such weak conditions for general conic constrained non-convex optimization problems.



%We consider minimization of a continuous, possibly non-convex function over an intersection of a regular cone with an affine set.
%For such problems we define first- and second- order $\eps$-KKT points and propose a first- and a second-order algorithm.
%Our algorithms are based on the potential-reduction technique with the potential defined as a sum of the objective with either logarithmically homogeneous self-concordant barrier or self-scaled barrier for the cone involved in the problem statement.
%Our first-order algorithm has iteration complexity $O(\eps^{-2})$ to reach a first-order $\eps$-KKT point and our second-order algorithm has iteration complexity $O(\eps^{-3/2})$ to reach a second-order $\eps$-KKT point.
%Both complexities are optimal for the corresponding classes of problems since they match the lower bounds for unconstrained problems.


%For such problems we define first- and second- order $\eps$-KKT points and propose a first- and a second-order algorithm.
%Our algorithms are based on the potential-reduction technique with the potential defined as a sum of the objective with either %logarithmically homogeneous self-concordant barrier or self-scaled barrier for the cone involved in the problem statement.
%Our first-order algorithm has iteration complexity $O(\eps^{-2})$ to reach a first-order $\eps$-KKT point and our second-order algorithm %has iteration complexity $O(\eps^{-3/2})$ to reach a second-order $\eps$-KKT point.
%Both complexities are optimal for the corresponding classes of problems since they match the lower bounds for unconstrained problems.





%We consider a large class of optimization problems where the goal is to minimize a continuous, possibly non-convex function over an intersection of a regular cone with an affine set without assuming differentiability on the boundary of the feasible region. 
%First, we formulate $\eps$-stationary conditions for such problems.
%To deal with the conic constraint we utilize the machinery of logarithmically homogeneous self-concordant barriers and self-scaled barriers, and construct two potential-reduction techniques. 
%For the setting of the objective satisfying the descent lemma w.r.t. the local norm induced by the barrier, we propose a first-order algorithm with iteration complexity $O(\eps^{-2})$ which coincides with the lower bound for first-order methods for unconstrained problems.
%Under slightly relaxed conditions than the Hessian being Lipschitz w.r.t. the local norm induced by the barrier, we propose a second-order algorithm with iteration complexity $O(\eps^{-3/2})$ which coincides with the lower bound for second-order methods for unconstrained problems.
%Both our algorithms are adaptive to the corresponding Lipschitz constants and the obtained bounds can be considered as optimal in the corresponding class.




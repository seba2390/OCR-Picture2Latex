%----------------------------------------------------------------------
%%% Introduction
%----------------------------------------------------------------------
% !TEX root = ./HBAConicMain.tex
%
Let $\setE$ be a finite dimensional vector space with inner product $\inner{\cdot,\cdot}$ and norm $\norm{\cdot}$. In this paper we are concerned with solving constrained conic optimization problems of the form 
%%%%
\begin{equation}\label{eq:Opt}\tag{Opt}
 \min_{x} f(x)\quad \text{s.t.: } \bA x=b,\; x\in\bar{\setK}.
\end{equation}
%%%%%%
The main working assumption underlying our developments is as follows:
\begin{assumption}\label{ass:1}
\begin{enumerate}
\item $\bar{\setK}\subset\setE$ is a regular convex cone with nonempty interior $\setK$: $\bar{\setK}$ is closed convex, solid and pointed (i.e. contains no lines);
\item $\bA:\setE\to\R^{m}$ is a linear operator assigning each element $x\in\setE$ to a vector in $\R^m$ and having full rank\footnote{
Note that this assumption is not restrictive. If the linear operator maps a point $x$ to a lower-dimensional subset, then it is possible to eliminate redundant constraints, or we are working with an inconsistent system. The latter is excluded from our considerations, so in fact this assumption is without loss of generality. 
}
, i.e., $\image(\bA)=\R^{m}$, $b \in \R^{m}$; 
\item The feasible set $\bar{\setX}=\bar{\setK}\cap\setL$, where $\setL=\{x\in\setE\vert\bA x=b\}$, has nonempty relative interior denoted by $\setX=\setK\cap\setL$;
%\item The feasible set $\bar{\setX}\eqdef\bar{\setK}\cap\setL\neq\emptyset$, where $\setL\eqdef\{x\in\setE\vert\bA x=b\}$, is closed and convex;
%\item The relative interior of $\bar{\setX}$, denoted by $\setX\eqdef\setK\cap\setL$, is nonempty;
\item $f:\setE\to\R$ is possibly non-convex, continuous on $\bar{\setX}$ and continuously differentiable on $\setX$;
\item Problem \eqref{eq:Opt} admits a global solution. We let $f_{\min}(\setX)=\min\{f(x)\vert x\in\bar{\setX}\}$.
\end{enumerate}
\end{assumption}
%Note that $f$ is not assumed to be globally differentiable, but only over the relative interior of the feasible set. Problem \eqref{eq:Opt} contains many important classes of optimization problems as special cases. We summarize the three most-important ones below.
%%%%%%%NLP%%%%%%%%%%%%%%%
\begin{example}[NLP with non-negativity constraints]
\label{ex:NN}
For $\setE=\Rn$ and $\bar{\setK}\equiv \bar{\setK}_{\text{NN}}=\Rn_{+}$ we recover non-linear programming problems with linear equality constraints and non-negativity constraints: $\bar{\setX}=\{x\in\Rn\vert \bA x=b,\text{ and } x_{i}\geq 0\text{ for all }i=1,\ldots,n\}.$
\close
\end{example}
%%%%%%%%%SOC%%%%%
\begin{example}[Optimization over the Second-Order Cone]
\label{ex:SOC}
Consider $\setE=\R^{n+1}$ and $\bar{\setK}\equiv \bar{\setK}_{\text{SOC}}=\{x=(x_{0},\underline{x})\in\R\times\R^{n-1}\vert x_{0}\geq\norm{\underline{x}}_2\}$, the second-order cone (SOC). In this case problem \eqref{eq:Opt} becomes a non-linear second-order conic optimization problem. Such problems have a huge number of applications, including energy systems \cite{Mol19}, network localization \cite{Tse07}, among many others \cite{AliGol03}. \close
\end{example}
%%%%%%%%%%%SDP%%%%%%%%%
\begin{example}[Semi-definite programming]
\label{ex:SDP}
If $\setE=\symm^{n}$ is the space of real symmetric $n\times n$ matrices and $\bar{\setK}\equiv\bar{\setK}_{\text{SDP}}=\symm^{n}_{+}$ is the cone of positive semi-definite matrices, we obtain a non-linear semi-definite programming problem. Endow this space with the standard inner product $\inner{a,b}=\tr(ab)$. In this case, the linear operator $\bA$ assigns a matrix $x\in\symm^{n}$ to a vector $\bA x = [\inner{a_{1},x}, \ldots, \inner{a_{m},x}]^\top$.
%$\bA x=\left(\begin{array}{c} \inner{a_{1},x}\\
%\vdots\\
%\inner{a_{m},x}
%\end{array}\right)$. 
Such mathematical programs have received enormous attention due to the large number of applications in control theory, combinatorial optimization and engineering \cite{LauRen05,De-Klerk:2006aa,BenNem01}. \close
\end{example}
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Motivating applications}
\paragraph{Statistical estimation with non-convex regularization}
An important instance of \eqref{eq:Opt} is the composite optimization problem
\begin{equation}\label{eq:composite}
\min_{x}f(x)=\ell(x)+\lambda\sum_{i=1}^{n}\varphi(x_{i}^{p})\quad \text{s.t.: } x\in\bar{\setK}_{\text{NN}},
\end{equation}
where $\ell:\Rn\to\R$ is a smooth data fidelity function, $\varphi:\R\to\R$ is a convex function, $p\in(0,1)$, and $\lambda>0$ is a regularization parameter. A common use of this problem formulation is the regularized empirical risk-minimization problem in high-dimensional statistics, or the variational regularization technique in inverse problems. Common specifications for the regularizing function are $\varphi(s)=s$, or $\varphi(s)=s^{2/p}$. In the first case, we obtain 
$\sum_{i=1}^{n}\varphi(x^{p}_{i})=\sum_{i=1}^{n}x_{i}^{p}=\norm{x}^{p}_{p}$ on $\setK_{\text{NN}}$, whereas in the second case, we get $\sum_{i=1}^{n}\varphi(x^{p}_{i})=\sum_{i=1}^{n}x_{i}^{2}=\norm{x}^{2}_2$. Note that the first case yields the objective $f$ which is non-convex and non-differentiable at the boundary of the feasible set. It has been reported in imaging sciences that the use of such non-convex and non-differentiable regularizer has advantages in the restoration of piecewise constant images. \cite{BiaChe15} contains a nice survey of studies supporting this observation. Moreover, in variable selection, the $L_{p}$ penalty function with $p\in(0,1)$ owns the oracle property \cite{FanLi01} in statistics, while $L_{1}$ (called the LASSO) does not; problem \eqref{eq:composite} with $p\in(0,1)$ can be used for variable selection at the group and individual variable levels simultaneously, while the very same problem with $p=1$ can only work for individual variable selection \cite{HUANG:2009}. See \cite{GeJiaYe11,Chen:2014wx} for a complexity-theoretic analysis of this problem. 

\paragraph{Low rank matrix recovery}
Similar to the composite minimization problem \eqref{eq:composite}, there are many relevant optimization problems defined on matrix domains $\setE=\symm^{n}$, which are of the similar form, but now defined over a feasible set of the form $\bar{\setX}=\{x\in\setE\vert\bA x=b,x\in\bar{\setK}_{\text{SDP}}\}$. In particular, let us consider the composite model $f(x)=\ell(x)+r(x)$, with smooth loss function $\ell:\setE\to\R$, and with regularizer given in form of a matrix function $r(x)=\sum_{i}\sigma_{i}(x)^{p}$ on $x\in\setK_{\text{SDP}}$, where $p\in(0,1)$ and $\sigma_{i}(x)$ is the $i$-th singular value of the matrix $x$. The resulting optimization problem is a matrix-version of the non-convex regularized problem \eqref{eq:composite}. The use of the non-convex Schatten regularizer has received quite some attention because its favorable properties to promote sparse solutions. In particular, \cite{JiSoSzeYe13} used this approach to solve large-scale network localization problems with a potential reduction method based on a trust-region approach. Another application fitting into the above framework is the task to recover a low rank matrix $X\in\bar{\setK}_{\text{SDP}}$ from measurements $\scrP(x)=d\in\R^{m}$. To solve this problem an attractive formulation is to minimize $f(x)=\norm{\scrP(x)-d}^{2}+r(x)$, with $r(x)$ a $p$-Schatten norm for $p\in(0,1)$. See \cite{SurveyNonconvex} for a recent survey. 



\subsection{Challenges and contribution.}
One of the challenges to approach problem \eqref{eq:Opt} algorithmically is to deal with the feasible set $\setL\cap\bar{\setK}$. A projection-based approach faces the computational bottleneck to project onto the intersection of a cone with an affine set, which makes the majority of the existing first-order \cite{GhaLan16,nesterov2020primal-dual,guminov2021combination,carmon2017convex,agarwal2017finding,cartis2019optimality} and second-order \cite{NesPol06,conn2000trust,cartis2012complexity,CurRobSam17,CarGouToi12,birgin2017regularization,CarGouToi18,cartis2019optimality,doikov2021minimizing} methods practically less attractive, as they either are designed for unconstrained problems or use proximal steps in the updates. 
When primal feasibility is not a major concern, augmented Lagrangian algorithms \cite{birgin2017complexity,grapiglia2020complexity,Andreani:2019uf} are an alternative, though they do not always come with complexity guarantees.
%
%do not produce feasible iterates, are not applicable to our problem \eqref{eq:Opt} with general conic constraints, and not always have complexity guarantees. \MS{I don't agree here. Our setting can be handled by augmented Lagrangian ideas. I guess primal feasibility and convergence to a second-order stationary point is the main motivation for the method here. }
%
These observations motivate us to focus on primal barrier-penalty methods that allow to decompose the feasible set and treat $\bar{\setK}$ and $\setL$ separately.
Barrier methods are classical and powerful for convex optimization in the form of interior-point methods, but the results in the non-convex setting are in a sense fragmentary, with many different algorithms existing for different particular instantiations of \eqref{eq:Opt}. In particular, the main focus of barrier methods for non-convex optimization has been on particular cases, such as non-negativity constraints \cite{Ye92,TseBomSch11,HBA-linear,BiaCheYe15,HaeLiuYe18,NeiWr20} and quadratic programming \cite{Ye92,FayLu06,LuYua07}. 
In this paper we develop a flexible and unifying algorithmic framework that is able to provide first- and second-order interior-point algorithms for \eqref{eq:Opt} with potentially non-convex objective functions, potentially non-differentiable on the boundary, and general conic constraints. To the best of our knowledge, our method is the first one providing complexity results for first- and second-order algorithms to reach approximate first- and second-order KKT points, respectively, under such weak assumptions. 
%
\paragraph{Our approach.}
At the core of our approach is the assumption that the cone $\bar{\setK}$ admits a \emph{logarithmically homogeneous self-concordant barrier} (LHSCB) $h(x)$ (\cite{NesNem94}, cf. Definition \ref{def:LHSCB}), for which we can retrieve information about the function value $h(x)$, the gradient $\nabla h(x)$ and the Hessian $H(x)=\nabla^{2}h(x)$ with relative ease. This is not a very restrictive assumption, since all standard conic restrictions in optimization (i.e. $\bar{\setK}_{\text{NN}},\bar{\setK}_{\text{SOC}}$ and $\bar{\setK}_{\text{SDP}}$) have this property. Using this barrier, our algorithms are designed to reduce the \emph{potential function}
\begin{equation}\label{eq:potential}
F_{\mu}(x)=f(x)+\mu h(x),
\end{equation}
where $\mu>0$ is a (typically) small penalty parameter. By definition, the domain of the potential function $F_{\mu}$ is the interior of the cone $\bar{\setK}$. Therefore, any algorithm designed to reduce the potential will automatically respect the conic constraints, and the satisfaction of the linear constraints $\setL$ can be ensured by choosing search directions from the nullspace of the linear operator $\bA$. Our target is to identify points satisfying approximate necessary first- and second-order optimality conditions for problem \eqref{eq:Opt} expressed in terms of $\eps$-KKT and $(\eps_1,\eps_2)$-2KKT points respectively (cf. Section \ref{sec:Optimality} for a precise definition).

\paragraph{Approaching first-order stationary points.}
To produce a first-order stationary point, we construct a novel gradient-based method, which we call the \emph{adaptive Hessian barrier algorithm} ($\AHBA$, Algorithm \ref{alg:AHBA}). The main computational steps involved in $\AHBA$ is the identification of a search direction and a step size policy, guaranteeing feasibility and sufficient decrease in the potential function value. To find a step direction, we employ a linear model for $F_{\mu}$ regularized by the squared local norm induced by the Hessian of $h$ which is then minimized over the tangent space of the affine set $\setL$. The step-size is adaptively chosen to ensure feasibility and sufficient decrease in the objective function value $f$. For a judiciously chosen value of $\mu$, we prove that this gradient-based method enjoys the upper iteration complexity bound $O(\eps^{-2})$ for reaching an $\eps$-KKT point when a ``descent Lemma'' holds relative to the local norm induced by the Hessian of $h$ (cf. Assumption \ref{ass:gradLip} and Theorem \ref{Th:AHBA_conv} in Section \ref{sec:firstorder}). We then embed $\AHBA$ into a path-following scheme that iteratively reduces the value of $\mu$ making the algorithm parameter-free and any-time convergent with the $O(\eps^{-2})$ complexity.

\paragraph{Approaching second-order stationary points.}
We next move on to derive a second-order method called the \emph{second-order adaptive Hessian barrier algorithm} ($\SAHBA$, Algorithm \ref{alg:SOAHBA}). Under this approach the step direction is determined by a minimization subproblem over the same tangent space. 
But, in this case, the minimized model is composed of the linear model for $F_{\mu}$ augmented by second-order term for $f$ and regularized by the cube of the local norm induced by the Hessian of $h$. 
The regularization parameter is chosen adaptively to allow for potentially larger steps in the areas of small curvature.
For a judiciously chosen value of $\mu$, we establish (see Theorem \ref{Th:SOAHBA_conv}) the worst-case bound $O(\max\{\eps_1^{-3/2},\eps_2^{-3/2}\})$ on the number of iterations for reaching an $(\eps_1,\eps_2)$-2KKT point, under a weaker assumption that the Hessian of $f$ is Lipschitz relative to the local norm induced by the Hessian of $h$ (see Assumption \ref{ass:2ndorder} in Section \ref{sec:secondorder} for a precise definition). We then propose a path-following version of $\SAHBA$ that iteratively reduces the value of $\mu$ making the algorithm parameter-free and any-time convergent with $O(\max\{\eps_1^{-3/2},\eps_2^{-3/2}\})$ complexity.

\subsection{Related work}
\label{sec:related}
To the best of our knowledge, $\AHBA$ and $\SAHBA$ are the first interior-point algorithms that achieve such complexity bounds universally for the general non-convex problem template \eqref{eq:Opt}. Our closest algorithmic and complexity-theoretic competitors are \cite{HaeLiuYe18,NeiWr20}. Both papers focus on the special case of non-negativity constraints as in Example \ref{ex:NN} and fix $\mu$ before the start of the algorithm based on the desired accuracy $\eps$, which may require some hyperparameter tuning in practice and may not work if the desired accuracy is not yet known. Interestingly, for the special case $\bar{\setK}=\bar{\setK}_{\text{NN}}$, our general algorithms provide stronger results under weaker assumptions, compared to first- and second-order methods in \cite{HaeLiuYe18} and first-order implementation of the second-order method in \cite{NeiWr20} (cf. Sections \ref{sec:FO_discussion} and \ref{sec:SO_discussion}).% As said above, augmented Lagrangian algorithms do not guarantee feasibility of the obtained approximate solutions, are designed  for problems either with non-negativity constraints \cite{birgin2017complexity,grapiglia2020complexity,xie2019complexity} or with second-order/other symmetric cone constraints (yet, without complexity analysis) \cite{Andreani:2019uf}, unlike our setting of general cones, including non-symmetric. 
%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph{First-order methods.} In the unconstrained setting, when the gradient is Lipschitz continuous, the standard gradient descent achieves the lower iteration complexity bound $O(\eps^{-2})$ to find a first-order $\eps$-stationary point $\hat{x}$ such that $\norm{\nabla f(\hat{x})}_2 \leqslant\eps$  \cite{Nes18,CarDucHinSid19b,CarDucHinSid19}. 
Notably, despite problem \eqref{eq:Opt} has non-trivial constraints, our bound for $\AHBA$ matches this bound.
%Since constrained optimization is potentially more difficult than unconstrained and when $\setX$ is bounded our main assumption subsumes the standard  Lipschitz-gradient assumption (see Remark \ref{rem:bounded1}), we can consider our first-order complexity results as in some sense optimal. 
The original motivation for our work comes from the paper \cite{HBA-linear} on Hessian Barrier Algorithms, which in turn was strongly influenced by the continuous-time techniques of \cite{ABB04,BolTeb03}. Our results include second-order method and general conic constraints and hold far beyond the realm of \cite{HBA-linear}, where the complexity result is proved only for first-order method in the setting of non-negativity constraints and quadratic objective.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph{Second-order methods.}
In unconstrained optimization with Lipschitz continuous Hessian, cubic-regularized Newton methods \cite{Gri81,NesPol06} and second-order trust region algorithms \cite{conn2000trust,CarGouToi12,CurRobSam17} achieve the lower iteration complexity bound $O(\max\{\eps_1^{-3/2},\eps_2^{-3/2}\})$ \cite{CarDucHinSid19b,CarDucHinSid19} to find  a second-order $(\eps_1,\eps_2)$-stationary point; I.e. a point $\hat{x}$ satisfying $\norm{\nabla f(\hat{x})}\leq \eps_1$ and $\lambda_{\min} \left(\nabla^2 f(\hat{x})\right) \geq - \sqrt{\eps_2}$, where $\lambda_{\min}(\cdot)$ denotes the minimal eigenvalue of a matrix\footnote{A number of works, e.g. \cite{CarGouToi12,NeiWr20}, consider an $(\eps_1,\eps_2)$-stationary point defined as $\hat{x}$ such that $\|\nabla f(\hat{x}) \|_2 \leq \eps_1$ and $\lambda_{\min} \left(\nabla^2 f(\hat{x})\right) \geq - \eps_2$ and the corresponding complexity $O(\max\{\eps_1^{-3/2},\eps_2^{-3}\})$. Our definition and complexity bound are the same up to redefinition of $\eps_2$.}. 
Notably, despite problem \eqref{eq:Opt} has non-trivial constraints, our bound for $\SAHBA$ matches this bound.
%Since constrained optimization is potentially more difficult than unconstrained and when $\setX$ is bounded our main assumption subsumes the standard Lipschitz-Hessian assumption (see Remark \ref{Rm:Hess_Lip}), we can consider our second-order complexity results as in some sense optimal. 
The existing literature on non-convex problems with non-linear constraints either consider only equality constraints \cite{curtis2018complexity}, or only inequality constraints \cite{hinder2018worst-case}, or both, but require projection \cite{cartis2019optimality}. Moreover, they do not consider general conic constraints as in \eqref{eq:Opt}.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph{Approximate optimality conditions.}
\cite{BiaCheYe15} consider box-constrained minimization of the same objective as in \eqref{eq:composite} and propose a notion of $\eps$ scaled KKT points. 
Their definition is tailored to the geometry of the optimization problem, mimicking the complementarity slackness condition of the classical KKT theorem for the non-negative orthant. 
In particular, their first-order condition consist of feasibility of $x$ along with a scaled gradient condition.
\cite{HaeLiuYe18,NeiWr20} point out that without additional assumptions on $f$, points that satisfy the scaled gradient condition may not approach KKT points as $\eps$ decreases. 
Thus, \cite{HaeLiuYe18,NeiWr20}, provide alternative notions of approximate first- and second-order KKT conditions for the setting of non-negativity constraints. 
Inspired by \cite{HaeLiuYe18}, we define the corresponding notions for general cones. Our first-order conditions turn out to be stronger than that of  \cite{HaeLiuYe18,NeiWr20} and the second-order condition is equivalent to theirs in the particular case of non-negativity constraints (see Sections \ref{sec:FO_discussion} and \ref{sec:SO_discussion}). The proof that our algorithms are guaranteed to find such approximate KKT points requires some fine analysis exploiting the structural properties of logarithmically homogeneous barriers attached to the cone $\setK$, which, to the best of our knowledge, appear to be novel. 
 
%\subsection{Outline}
%The rest of the paper is organized as follows. Section \ref{sec:prelims} is technical and collects the relevant definitions, facts, and estimates provided by the theory of \ac{SC}  barriers. Section \ref{sec:Optimality} describes our notion of approximate first- and second-order KKT points that capture general cones in \eqref{eq:Opt}. Sections \ref{sec:firstorder} and \ref{sec:secondorder} introduce and analyze our new first-order and second-order interior-point methods together with their path-following versions. A detailed assessment of their iteration complexity, relative to the approximate KKT points, is provided, as well as discussions on relation to previous works.   

\subsection{Notation}
 In what follows $\setE$ denotes a finite-dimensional real vector space, and $\setE^{\ast}$ the dual space, which is formed by all linear functions on $\setE$. The value of $s\in\setE^{\ast}$ at $x\in\setE$ is denoted by $\inner{s,x}$. In the particular case where $\setE=\Rn$, we have $\setE=\setE^{\ast}$. Important elements of the dual space are gradients of differentiable functions $f:\setE\to\R$, denoted as $\nabla f(x)\in\setE^{\ast}$. For an operator $\bH:\setE\to\setE^{\ast}$, denote by $\bH^{\ast}$ is adjoint operator, defined by the identity 
 \[
(\forall u,v\in\setE): \qquad \inner{\bH u,v}:=\inner{u,\bH^{\ast}v}.
 \]
Thus, $\bH^{\ast}:\setE\to\setE^{\ast}$. It is called self-adjoint if $\bH=\bH^{\ast}$. We use $\lambda_{\max}(\bH)/\lambda_{\min}(\bH)$ to denote the maximum/minimum eigenvalue of such operators. Important examples of such self-adjoint operators are Hessians of twice differentiable functions $f:\setE\to\R$: 
\[
(\forall u,v\in\setE):\qquad \inner{\nabla^{2}f(x)u,v}=\inner{u,\nabla^{2}f(x)v}.
\]
Operator $\bH:\setE\to\setE^{\ast}$ is positive semi-definite if $\inner{\bH u,u}\geq 0$ for all $ u\in\setE$. If the inequality is always strict for non-zero $u$, then $\bH$ is called positive definite. These attributes are denoted as $\bH\succeq 0$ and $\bH\succ 0$, respectively.
By fixing a positive definite self-adjoint operator $\bH:\setE\to\setE^{\ast}$, we can define the following Euclidean norms
\[
\norm{u}=\inner{\bH u,u}^{1/2},\quad \norm{s}^{\ast}=\inner{s,\bH^{-1}s}^{1/2}\quad u\in\setE,s\in\setE^{\ast}.
\]
If $\setE=\Rn$, then $\bH$ is usually taken as the identity matrix $\bH=\bI$. 
The directional derivative of function $f$ is defined in the usual way:
\[
Df(x)[v]:=\lim_{\eps\to 0+} \frac{1}{\eps}[f(x+\eps v)-f(x)].
\]
More generally, for $v_{1},\ldots,v_{p}\in\setE$, we define $D^{p}f(x)[v_{1},\ldots,v_{p}]$ the $p$-th directional derivative at $x$ along directions $v_{i}\in\setE$. In that way we define $\nabla f(x)\in\setE^{\ast}$ by $Df(x)[u]=\inner{\nabla f(x),u}$ and the Hessian $\nabla^{2}f(x):\setE\to\setE^{\ast}$ by $\inner{\nabla^{2}f(x)u,v}=D^{2}f(x)[u,v]$. 
We denote $\setL_{0}=\{ v \in \setE \vert \bA v = 0\}$ the tangent space associated with the linear subspace $\setL\subset\setE$.


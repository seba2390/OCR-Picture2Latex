\section{Introduction}

Regardless of domain, scientists are rapidly embracing data-driven science as a 
means of extracting knowledge from large amounts of data. While there are many examples
of successful research based upon big data in the biomedical~\cite{toga15big}, physical~\cite{reed15exascale}
and social~\cite{foster2015tradition} sciences, many researchers still face challenges
managing and analyzing large amounts of data. These challenges are even more complex
when the data to be analyzed is sensitive, private, or valuable. Furthermore, the increasingly common
adoption of `discovery science', an approach that centers on iterative and exploratory analysis
of large volumes of data to discover patterns and correlations, is 
beyond the reach of many researchers who lack the expertise and computational infrastructure
to support such an approach to interrogating large, sensitive data. In practice, the requirements
for analyzing sensitive, big data using discovery and data science methodologies
necessitates flexible, intuitive, and efficient infrastructure. Yet, most highly secure, big data computational infrastructure is anything but flexible and intuitive.

To address the need for the secure and scalable management and 
analysis of data, we developed the Cloud Kotta secure data enclave~\cite{babuji16secure,babuji16kotta}
Cloud Kotta provides a cloud-based, elastically scalable environment that is 
able to meet the needs of sporadic and bursty scientific analysis workloads
while removing the need for owning and operating large scale infrastructure.
%investments and democratizing access to any researcher. 
It implements a fine grain access control model over managed research data 
allowing controlled access from within and outside the enclave. To address the need for reliability, scalability and collaborative access, Cloud Kotta is built upon Amazon Web Services (AWS). Over the past year, Cloud Kotta has been leveraged by dozens of researchers and students to analyze data using more than a quarter million core hours.

While Cloud Kotta has shown immense value, it, like many
other data enclaves, offers only a queue-based job submission model. 
Unfortunately, such models are not well-suited to the increasingly
common discovery science approaches used by researchers. Rather, discovery and data science approaches typically rely on lightweight scripting languages (e.g., R and Python), 
flexible data structures (e.g., dataframes), inline visualizations (to `inspect' the data), 
and exploratory statistical and machine learning algorithms.
These days, researchers rely on interactive analysis environments like Jupyter Notebooks~\cite{jupyter} 
to support iterative and collaborative analysis that marries code, equations, documentation, 
results, and visualizations. A quick and responsive environment that allows for fast, iterative
development is an ideal fit for analysis and discovery tasks. For this reason, these interactive development environments have quickly become crucial tools of
the applied data science community and are starting to gain favor across a broad range of computational sciences. However, maintaining the
high availability requirements of interactive compute resources can be expensive especially
with a large group of researches to support. Furthermore, providing interactive analysis
of secure data is particularly challenging.

In this paper, we describe a model for enabling interactive, multi-user analysis 
of secure data. We base our model on Jupyter Notebooks and Cloud Kotta to provide the security of a data enclave, scalable compute, and the interactivity required of today's discovery science. 
We have developed a Python library that enables specific functions in an analysis code, written in 
a Jupyter Notebook, to be seamlessly and securely submitted
to the Cloud Kotta execution fabric. Our approach streamlines
the interfaces between the analysis code and the execution
environment thereby offering native, synchronous Python input/output
alongside an asynchronous job-based model for long running analyses. 
To validate our model we describe several real-world use cases 
for which this system was used. 
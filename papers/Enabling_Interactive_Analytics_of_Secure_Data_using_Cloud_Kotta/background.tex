\section{Background and Motivation}

A gap has opened up between researchers' preferred methods for working with and interrogating data and the usability of the computational environments that host that work. Researchers are increasingly adopting highly flexible, iterative, approaches to data exploration. These approaches are most prominent in the applied data science and discovery science regimes in which large quantities of heterogeneous data are explored, smashed together, interrogated by general and specialized data mining and machine learning tools in a highly iterative process of rapid ideation and exploration. As this methodology has gained favor, researchers have attempted to leverage it in working with ever larger, more diverse, and highly sensitive data (e.g., patient, genetic, tax, commercial, etc.). At the same time, computational facilities, resources, and platforms have sought to optimize throughput, performance, and security with little regard for the interactivity or the intuitive, inventive, flights of exploratory fancy that researchers now crave. On one side of the gap, users of these facilities now have scale at the expense of flexibility and security at the expense of interactivity. On the other, users have flexibility and interactivity at the expense of scale and security.

Cloud Kotta was developed to serve the computational needs of a diverse network of scientists that rely on big data and computation to ask and answer big questions. Originally, Cloud Kotta was designed to virtually centralize the research efforts of a decentralized group around highly protected datasets. In order to carry out analysis of highly sensitive data at a distance, researchers were (initially) willing to suffer shortcomings related to interactivity and flexibility. However, iterating on models and troubleshooting bugs in the fairly rigid, queue-based job submission analysis workflows that Cloud Kotta supported proved cumbersome and, ultimately, frustrated research efforts.

For this reason, we sought to extend Cloud Kotta by developing and providing an interactive analysis environment that enables users to work directly with elastic computational resources and highly sensitive data in a flexible, secure, and interactive environment at scale. Specifically, for interactive data analysis on Cloud Kotta to be efficacious, we derived the following requirements.

The augmented system needed to: 
1) maintain high levels of security, ensuring that only permitted users
are able to access and interact with data while restricting what data can leave the system;
2) provide an intuitive interface that is both familiar to users and flexible
enough to support a broad range of analysis types;
3) seamlessly integrate with a diverse set of programming languages so that users do not
need to make significant modifications to their programs;
4) scale to support very large amounts of data and use of large compute
resources; and
5) embrace software as a service models such that users can access these
capabilities without installing software locally.  

In what follows, we sketch the Cloud Kotta architecture and then describe in detail our novel Jupyter integrations that enable interactive analysis of data within the Cloud Kotta environment. Additionally, we discuss three real-world use cases that have leveraged these capabilities to conduct science.

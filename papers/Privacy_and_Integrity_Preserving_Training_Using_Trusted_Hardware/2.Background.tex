\section{Related work and Background}
\label{sec:background}
 \newcolumntype{L}{>{\centering\arraybackslash}m{0.017\linewidth}} 
  \newcolumntype{D}{>{\arraybackslash}m{0.32\linewidth}} 
\begin{table*}[htb]
\caption{Comparison of applications and security guarantees of various prior techniques on neural networks' security}
\vskip -0.1mm
\label{tab:background}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lcccccccccccc}
	\hline
	\hline
	\textbf{Method} & \textbf{Training} & \textbf{Inference} & \textbf{DP} & \textbf{MPC} & \textbf{HE} & \textbf{TEE} & \textbf{Data Privacy} &  \textbf{Model Privacy(Client)}&\textbf{Model Privacy(Server)}&\textbf{Integrity}&\textbf{GPU Acceleration}&\textbf{Large DNNs}\\
	%%%%%%%%%
    \hline
	%%%%%%%%from quo
	%DP~\citep{abadi2016deep} &$\bullet$ & $\circ$ & $\bullet$	&  $\circ$&$\circ$ &$\circ$& $\bullet$&&&$\circ$\\
	SecureNN~\citep{wagh2019securenn} &$\bullet$ & $\bullet$ &  $\circ$& $\bullet$  & $\circ$&$\circ$&$\bullet$&$\bullet$&$\bullet$&$\circ$&$\bullet$&$\circ$\\
	%%%%%%%%from quo
	%ABY3~\citep{mohassel2018aby3} &$\bullet$ & $\circ$& $\circ$	 &  $\bullet$ & $\circ$ & $\circ$& $\bullet$&&& $\circ$\\
	%%%%%%%%
	%SecureML~\citep{mohassel2017secureml} &$\bullet$ & $\bullet$ & $\circ$	& $\bullet$ & $\bullet$&$\circ$&$\bullet$ &&& $\circ$\\
	Chiron~\citep{hunt2018chiron} &$\bullet$ & $\bullet$ & $\circ$	& $\circ$ & $\circ$&$\bullet$& $\bullet$&$\bullet$&$\bullet$& $\bullet$& $\circ$&$\circ$\\
	MSP~\citep{hynes2018efficient} &$\bullet$ &$\bullet$  & $\circ$	& $\circ$ &$\circ$ &$\bullet$& $\bullet$&$\bullet$&$\bullet$ &$\bullet$&$\circ$&$\circ$ \\
	
	
	Gazelle~\citep{juvekar2018gazelle} &$\circ$ &$\bullet$  &$\circ$  & $\circ$ & $\bullet$ &$\circ$&$\bullet$&$\circ$&$\circ$&$\circ$&$\bullet$&$\bullet$\\
	MiniONN~\citep{liu2017oblivious} &$\circ$ &$\bullet$  & $\circ$ & $\bullet$ & $\bullet$ &$\circ$&$\bullet$&$\bullet$&$\circ$&$\circ$&$\bullet$&$\bullet$\\
	CryptoNets~\citep{gilad2016cryptonets} &$\circ$ &$\bullet$  & $\circ$ & $\bullet$ & $\bullet$ &$\circ$&$\bullet$&$\bullet$&$\circ$&$\circ$&$\bullet$&$\bullet$\\
	Slalom~\citep{tramer2018slalom} &$\circ$ &$\bullet$  & $\circ$ & $\circ$ &$\circ$ & $\bullet$ & $\bullet$ &$\bullet$ &$\circ$&$\bullet$&$\bullet$&$\bullet$\\
	Origami~\citep{narra2019privacy} & $\circ$&$\bullet$  & $\circ$ & $\circ$ & $\circ$& $\circ$ & $\bullet$ &$\circ$&$\circ$&$\circ$&$\bullet$&$\bullet$ \\
	Shredder~\citep{mireshghallah2020shredder} & $\circ$&$\circ$  & $\circ$ & $\circ$ & $\circ$& $\bullet$ & $\bullet$ &$\circ$&$\circ$&$\circ$&$\bullet$&$\bullet$ \\
	Delphi~\citep{mishra2020delphi} & $\circ$&$\bullet$  & $\circ$ & $\bullet$ & $\bullet$&$\bullet$ & $\bullet$&$\bullet$&$\circ$&$\circ$&$\bullet$&$\bullet$ \\
	%Apple~\citep{team2017learning} & $\circ$&$\bullet$  & $\bullet$ &$\circ$ & $\circ$&$\bullet$ & $\bullet$ &&& $\circ$\\
	\textbf{DarKnight} & $\bullet$&$\bullet$  &$\circ$ & $\circ$ &$\circ$ &$\bullet$ &$\bullet$  &$\bullet$ &$\circ$&$\bullet$ &$\bullet$&$\bullet$\\
	\hline
\end{tabular}
}
\vskip -0.1mm
\end{table*}
There are a variety of approaches for protecting input and model privacy and computation integrity during DNN training and inference. These methods provide different privacy guarantees~\cite{mirshghallah2020privacy}. \textit{Homomorphic encryption (HE)} techniques encrypt input data and then perform inference directly on encrypted data. They usually provide a high theoretical privacy guarantee on data leakage, albeit with a significant performance penalty, and hence are rarely used in training DNNs. %\cite{gentry2009fully,liu2017oblivious,gilad2016cryptonets,juvekar2018gazelle}.  
\textit{Secure multi-party computing (MPC)} is another approach, where multiple servers may use custom data exchange protocols to protect input data. %~\citep{shokri2015privacy, mohassel2017secureml, wagh2019securenn, mohassel2018aby3}. %However, privacy comes at the cost of increased communication costs across multiple parties. 
They mostly use secret sharing schemes and have super-linear overhead as the number of sharers and colluding entities grow. %However, this approach requires multiple servers to perform training or inference. 
An entirely orthogonal approach is to use \textit{differential privacy (DP)}, which protects individual users' information through probabilistic guarantees by inserting noise signals to some parts of the computation. The tradeoff between utility and privacy is a challenge in this line of work. %, if the output of the DNN for that user is exposed~\citep{abadi2016deep, erlingsson2014rappor,team2017learning}.
%\textit{Additive Noise} is another approach mostly used for inference, where there is a trade-off between privacy, computational complexity and, model accuracy. In some of the works mentioned below a combination of forenamed techniques is used. 
TEEs attracted attention recently for their privacy and integrity properties~\cite{asvadishirehjini2020goat,mo2020darknetz, ng2019goten}. Among TEE-based approaches,~\cite{tramer2018slalom} introduced Slalom an \emph{inference} framework that uses TEE-GPU collaboration to protect data privacy and integrity. However, as stated in their work their model was not designed for training DNNs. \textit{Instance Hiding} is a recently introduced method~\cite{huang2020instahide}. In this work authors combined multiple images from a private dataset, merge them with a public image set, and using a sign flip function on pixels as random noise parameters. This method processes the encoded data without any decoding. However, privacy guarantees are not theoretically guaranteed, and in~\cite{carlini2020attack} authors designed an attack to break the system. In Table~\ref{tab:background}, we compare some of these approaches based on their privacy and integrity guarantees, and their applications.


\begin{comment}
\begin{table*}[!ht]
\centering
%\vspace{-2mm}
\caption{Various prior techniques and their applicability}
\label{tab:background}
\resizebox{\textwidth}{!}{%
%\begin{adjustbox}{width=\columnwidth,center}
\begin{tabular}{c|c|c|c|c|c}
\hline
\hline
           & \textbf{HE} & \textbf{MPC}   & \textbf{TEE} & \textbf{DiffP} & \textbf{Noise} \\ \hline
\makecell{\textbf{Inference}} &  \makecell{FHME~\citep{gentry2009fully},\\ MiniONN~\citep{liu2017oblivious}, \\ CryptoNets~\citep{gilad2016cryptonets}, \\ Gazelle~\citep{juvekar2018gazelle}  }   &  \makecell{SGXCMP~\citep{bahmani2017secure},\\ SecureML~\citep{mohassel2017secureml} } & \makecell{ Mlcapsule~\citep{hanzlik2018mlcapsule},\\  ObliviousTEE~\citep{ohrimenko2016oblivious},\\ P-TEE~\citep{gu2018securing},\\  Slalom~\citep{tramer2018slalom},\\ Origami~~\citep{narra2019privacy}}  &                      &  \makecell{Arden~\citep{wang2018not}, \\ NOffload~\citep{leroux2018privacy}, \\ Shredder~\citep{mireshghallah2020shredder}}     \\ \hline
\makecell{\textbf{Training}}  &       & \makecell{ SecureML~\citep{mohassel2017secureml},\\ SecureNN~\citep{wagh2019securenn},\\ ABY3~\citep{mohassel2018aby3} }& \makecell{MSP~\citep{hynes2018efficient}, \\ Chiron~\citep{hunt2018chiron} }  &  \makecell{DiffP~\citep{abadi2016deep}, \\ Rappor~\citep{erlingsson2014rappor}, \\ Apple~\citep{team2017learning} \\ PP DNN~\citep{shokri2015privacy}  }                    &  \\  
\hline
\end{tabular}
}
\end{table*}
\end{comment}




\section{Privacy Guarantee}
\label{sec:guarantee}
In this section, we bound the information that leaks, when using Darknight's blinding approach. 
In particular, we measure the amount of information the adversary can potentially gain about the raw data from the blinded data, if the adversary has access to an unlimited computation power. The amount of information leaked by $\bar{\mathbf x}^{(i)}$'s about $\mathbf x^{(1)},\dots,\mathbf x^{(K)}$ is the \textbf{mutual information (MI)} between these two sets of variables, defined by~\citep{cover1999elements}
\begin{align}
    I(\mathbf x^{(1)},\dots,\mathbf x^{(K)} ; \bar{\mathbf x}^{(1)},\dots,\bar{\mathbf x}^{(K+1)})=h(\mathbf x^{(j)})-h(\mathbf x^{(j)} |\bar{\mathbf x}^{(1)},\dots,\bar{\mathbf x}^{(K+1)})~.
\end{align}
Here, $ h(\cdot)$ denotes the Shannon entropy function. Note that the information that adversary can potentially learn about $\mathbf x^j$ by having all $\bar{\mathbf x}^i$'s is fundamentally bounded by  $I(\mathbf x^{(j)} ; \bar{\mathbf x}^{(1)},\dots,\bar{\mathbf x}^{(K+1)})$.  This mutual information in DarKnight can be bounded by the parameters used to blind the data.
\begin{thm}\label{thm:info_leakage1}
Assume that $X^1,\dots,X^K$ are scalars such that $|X^i|\leq C_1$ for all $i$. Suppose $\alpha_{i,j}$'s are standard Gaussian random variables and $R$ is a zero-mean Gaussian random variable with variance $\sigma^2$. Also $\bar X^i$ is defined as
\begin{align}
    \bar X^i=\sum_{j=1}^K \alpha_{j,i} X^j + \alpha_{(K+1),i} R~,\quad i=1,\dots,K+1~.
\end{align}
Then the information leaked from $\bar X^i$'s about $X^j$ is bounded by
\begin{align}\label{eq:infor_bound}
    I\left(X^1,\dots,X^K ; \bar X^1,\dots,\bar X^{(K+1)}\right)\leq \frac{16 K^4 C_1^2}{\sigma^2}~.
\end{align}
\end{thm}
%\vspace{-1mm}
The details of our proof is provided in Appendix A. Note that there is one source of information leakage not considered in the above bound, namely the leakage of inputs from gradients with respect to weight ($\triangledown \mathbf W$). But as we described in Equation \ref{eq:gamma_lin}, we only provide a single model update computed across all the inputs in a batch, which is similar to the state of art secure aggregation mechanisms used to bound such leakage ~\citep{bonawitz2017practical, zhu2019deep}. 

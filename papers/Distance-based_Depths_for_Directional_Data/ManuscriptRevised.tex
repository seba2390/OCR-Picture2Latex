\documentclass[usenames,dvipsnames]{article}

\renewcommand{\baselinestretch}{1.25}

\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{psfrag} 
\usepackage{graphicx}

\usepackage{natbib}       
\usepackage{mathptmx}       
\usepackage{helvet}         
\usepackage{courier}        
\usepackage{type1cm}  
\usepackage{wrapfig}
\usepackage{float}
\usepackage{floatflt}
\usepackage{makeidx}      
\usepackage{multicol}        
\usepackage[bottom]{footmisc}
\usepackage{url}
\usepackage{tikz}
\usepackage{fixltx2e}
\usepackage{enumitem}
\usepackage{multirow}

\input{rgb}

\usepackage{hyperref}
\hypersetup{pdfpagemode=FullScreen,   
backref,
colorlinks=true,
citecolor=Bittersweet,
linkcolor=Bittersweet,
urlcolor=Bittersweet
}

\textwidth 12.5cm 
\oddsidemargin 1.9cm 
\evensidemargin 1.9cm
\topmargin 0.5cm 
\textheight 21.5cm 
\voffset -1.5cm 
\baselineskip 1cm

\usepackage[labelsep=space]{caption}

\usepackage{epsfig}

%\usepackage{amsthm}
\newtheorem{lem}{Lemma}
\newtheorem{thm}{Theorem}
\newtheorem{mdef}{Definition}
\newtheorem{prop}{Proposition}
\newtheorem{rem}{Remark}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%





\begin{document}


% User-defined commands go here
\renewcommand{\eqref}[1]{(\ref{#1})}
\newcommand{\mb}[1]{\mathbf{#1}}
\newcommand{\mbb}[1]{\mathbb{#1}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\mt}[1]{\mathrm{#1}}
\newcommand{\rv}{random variable}
\newcommand{\cqfd}{\hfill $\square$}



\title{Distance-based Depths for Directional Data}
\author{\large Giuseppe Pandolfo$^*$, Davy Paindaveine$^\dagger$ and Giovanni Porzio$^\ddagger$\\[3mm]
{\normalsize University of Naples Federico II$^*$,
 Universit\'{e} libre de Bruxelles$^\dagger$}, \\
{\normalsize and University of Cassino and Southern Lazio$^\ddagger$}
 %\\[.1mm]
}
\date{}

\maketitle

%Arc distance depth
% chord distance depth
%  cosine distance depth
%   hyperspheres
%    spherical location
%     statistical depth
%      supervised classification 
%\KWDtitle{MSC 2010}Primary 62H11\sep secondary 62-07}




%%%%%%%%%%%%%%%% Abstract %%%%%%%%%%%%%%%%%%%%%%%%

\begin{abstract}
Directional data are constrained to lie on the unit sphere of~$\R^q$ for some~$q\geq 2$. To address the lack of a natural ordering for such data, depth functions have been defined on spheres. However, the depths available either lack flexibility or are so computationally expensive that they can only be used for very small dimensions~$q$. In this work, we improve on this by introducing a class of distance-based depths for directional data. Irrespective of the distance adopted, these depths can easily be computed in high dimensions too. We derive the main structural properties of the proposed depths and study how they depend on the distance used. We discuss the asymptotic and robustness properties of the corresponding deepest points. We show the practical relevance of the proposed depths in two applications, related to (i) spherical location estimation and (ii) supervised classification. For both problems, we show through simulation studies that distance-based depths have strong advantages over their competitors.
\end{abstract}



%%%%%%%%%%%%%%%% Introduction %%%%%%%%%%%%%%%%%%%%%%%%


\section{Introduction}

Directional data analysis is relevant when the sample space is the unit hypersphere~$\mathcal{S}^{q-1}\linebreak :=\left\{x \in \mathbb{R}^{q}:x^{T}x = 1\right\}$ in $\mathbb{R}^{q}$, which occurs when observations are directions, axes, rotations, or cyclic events. Applications arise in numerous fields, including astronomy, earth sciences, biology, meteorology and political science; see \cite{GiHa2010} for an exemple in the latter field. Directional data analysis can also be exploited to study patterns of unit vectors in~$\mathbb{R}^{q}$, such as those encountered in text mining \citep{Hoetal2012}.

Statistically, analyzing and describing directional data requires tackling some interesting problems associated with the lack of a reference direction and with a sense of rotation not uniquely defined. Another important issue when dealing with such data is the lack of a natural ordering, which generates a special interest in depth functions on the sphere. Parallel to their role in the usual Euclidean case, directional depths are to measure the degree of centrality of a given spherical location with respect to a distribution on the sphere and to provide a center-outward ordering of spherical locations; see \cite{AgoRom2013a}.  

Depth concepts for directional data were first considered by \cite{Sma1987} and \cite{LiuSin1992}. Following the pioneering work of \cite{Sma1987}, \cite{LiuSin1992} popularized the concept of \textit{angular Tukey depth} (ATD), which is the directional analog of the celebrated \emph{halfspace depth} \citep{Tuk1975}. The same paper introduced two further depths for directional data, namely the \textit{angular simplicial depth} (ASD), which is the directional version of the \emph{simplicial depth} from \cite{Liu1990}, and the \emph{arc distance depth} (ADD), which is based on the concept of arc length distance. 

Unlike the ADD, the ATD and ASD have been studied and used in the literature. For instance, \cite{RouStr2004} investigated some of the properties of the ATD, while \cite{AgoRom2013a} considered some of the possible applications of the ASD and ATD. {\ttfamily{R}} packages are also available for these depths: the package {\ttfamily{depth}} (\citealp{Genetal2012}) allows to compute ATD values for~$q = 2$ or $3$, whereas the package {\ttfamily{localdepth}} (\citealp{AgoRom2013b}) implements specific functions for the evaluation of the ATD for~$q=2$, and of the ASD for an arbitrary~$q\geq 2$. 

The main drawback of both the ASD and ATD is the computational effort they require, especially for higher dimensions~$q$. The \emph{angular Mahalanobis depth} of \cite{Leyetal2014}, that is based on a concept of directional quantiles, is computationally much more affordable, but suffers from other disadvantages: it requires the preliminary choice of a spherical location functional and it is less flexible than the ASD/ATD in the sense that it produces rotationally symmetric depth contours, even if the underlying distribution is not rotationally symmetric.

On the one hand, depth functions for directional data are useful, yet on the other hand, they lack flexibility (and depend on some user's choice) or are computationally too demanding. In order to improve on this, this work introduces a new class of directional depth functions that is based on spherical distances and contains the ADD as a particular case. These depth functions are computationally feasible even in high dimensions and are generally more flexible. Distance-based directional depths show several other advantages over their ASD/ATD competitors: they take positive values everywhere on~$\mathcal{S}^{q-1}$ (but in the uninteresting case of a point mass distribution), whereas the ASD/ATD can take zero values (which is undesirable when performing supervised classification). Further advantages of the proposed distance-based depths is that they typically do not provide ties in the sample case (whereas ties are unavoidable for the ASD/ATD, due to their step function nature) and that they do not require any assumption on the underlying distribution (unlike the angular Mahalanobis depth that, when based on the spherical mean, is not defined for zero-mean distributions).

The paper is organized as follows. In Section~\ref{secdef}, we introduce the proposed class of distance-based depth functions for directional data, and we consider three particular cases, namely the arc distance depth (ADD), the cosine distance depth (CDD) and the chord distance depth (ChDD). In Section~\ref{sec:StructProperties}, we derive the main structural properties of the proposed depths and study how they depend on the distance used. In Section~\ref{secillu}, we compare the various depths considered for several empirical distributions on the circle ($q=2$), which also allows us to illustrate the theoretical results of Section~\ref{sec:StructProperties}. In Section~\ref{sec:DistrProperties}, we discuss the asymptotic and robustness properties of the proposed concepts. In Section~\ref{secSimu}, we show the practical relevance of the distance-based depths in two applications, related to (i) spherical location estimation (Section~\ref{secSimusub1}) and (ii) supervised classification (Section~\ref{secSimusub2}). For both problems, we perform simulations that show the advantages of the proposed depths over their competitors. Final comments are provided in Section~\ref{secfinal}. Finally, an appendix collects technical proofs. 


%%%%%%%%%%%%%%%% Section 2 %%%%%%%%%%%%%%%%

\section{Distance-based depths for directional data}
\label{secdef}

\noindent In Definition~\ref{defclass} below, we introduce a class of depths on the unit sphere~$\mathcal{S}^{q-1}$. A particular member of this class will be obtained by fixing a particular (bounded) distance~$d(\cdot,\cdot)$ on~$\mathcal{S}^{q-1}$. For such a distance, $d^{\rm sup}:=\sup \{ d(\theta, \psi): \theta,\psi\in \mathcal{S}^{q-1}\}$ will throughout denote the upper bound of the distance between any two points on~$\mathcal{S}^{q-1}$.   

\vspace{-.3cm}
\begin{mdef}[Directional distance-based depths] 
\label{defclass}
Let~$d(\cdot,\cdot)$ be a bounded distance on $\mathcal{S}^{q-1}$ and $H$ be a distribution on~$\mathcal{S}^{q-1}$. Then the 
\emph{directional $d$-depth of~$\theta(\in \mathcal{S}^{q-1})$ with respect to~$H$} is
\begin{align}
\label{eq:class}
D_{d}\left(\theta, H\right) 
:= 
d^{\rm sup} 
- 
E_H[d(\theta, W)]
,	
\end{align}
where~$E_H$ is the expectation under the assumption that~$W$ has distribution~$H$.
\end{mdef}
\vspace{-.3cm}
While, in principle, any distance~$d$ can be used in this definition, it is natural to consider distances that are \emph{rotation-invariant} in the sense that~$d(O\theta,O\psi)=d(\theta,\psi)$ for any~$\theta,\psi\in\mathcal{S}^{q-1}$ and any $q\times q$ orthogonal matrix~$O$. As we show for the sake of completeness in the appendix (see Proposition~\ref{prodistinv}), any rotation-invariant distance~$d$ is of the form
$$
d(\theta,\psi)=d_{\delta}(\theta,\psi)=\delta(\theta'\psi)
$$ 
for some function~$\delta:[-1,1]\to\R^+$. The standard distance axioms impose that~$\delta(1)=0$ but do not impose that~$\delta$ is monotone non-increasing (unexpectedly, the triangle inequality may hold without this monotonicity condition). All classical choices, however, are monotone non-increasing; these include the \emph{arc length distance}~$d_{\rm arc}$ and the \emph{cosine distance}~$d_{\cos}$, that are associated with~$\delta(t)=\delta_{\rm arc}(t)=\arccos t$ and~$\delta(t)=\delta_{\cos}(t)=1-t$, respectively. Another rotation-invariant distance for which this monotonicity condition holds is the \emph{chord distance}~$d_{\rm chord}$ defined through~$d_{\rm chord}(\theta,\psi)=\|\theta-\psi\|=\sqrt{2(1-\theta'\psi)}
%=\sqrt{2\delta_{\cos}(\theta'\psi)}
\linebreak =:\delta_{\rm chord}(\theta'\psi)$. Throughout, we will denote the corresponding \emph{arc distance depth} (ADD), \emph{cosine distance depth} (CDD) and \emph{chord distance depth} (ChDD) as~$D_{\rm arc}$,~$D_{\cos}$ and~$D_{\rm chord}$, respectively.  

The ADD is the arc distance depth introduced by \cite{LiuSin1992}. For the CDD, a direct computation yields
\begin{equation}
	\label{cosinexplic}
D_{\cos}(\theta, H)
%:=
%d_{\cos}D(\theta, H) 
= 
2
- 
E_{H}[1-\theta' W]
= 
1
+ 
\theta' E_{H}[W]
%= 
%1
%+ 
%\|E_{H}[W]\| (\theta' \mu_H)
.
\end{equation}
Under the assumption that~$E_{H}[W]$ is non-zero, this rewrites
$D_{\cos}(\theta, H) 
= 
1
+ 
\|E_{H}[W]\| 
\linebreak (\theta' \mu_H)
$,
where~$\mu_H:=E_{H}[W]/\|E_{H}[W]\|$ is the spherical mean of~$H$. This shows that the CDD is then in a one-to-one relationship with the \emph{angular Mahalanobis depth} of \cite{Leyetal2014}, provided that the location functional needed in the latter is chosen as the spherical mean. We stress, however, that, unlike the angular Mahalanobis depth, the CDD does not require choosing a location functional on the sphere and is defined also in cases where~$\mu_H=0$. To the best of our knowledge, the ChDD has not been considered in the literature. 

%%%%%%%%%%%%%%%%% Section 3 %%%%%%%%%%%%%%%%%%%%%

\section{Structural properties}
\label{sec:StructProperties}

In this section, we derive the main properties of a generic directional $d$-depth. We start with the following  invariance result. 

\begin{thm}{\textbf{(Rotational invariance)}} 
\label{thmrotainv}
Let~$d=d_\delta$ be a rotation-invariant distance and~$H$ be a distribution on~$\mathcal{S}^{q-1}$. Then $D_{d_{\delta}}(\theta, H)$ is a rotation-invariant depth, in the sense that~$D_{d_{\delta}}(O\theta, H_O)=D_{d_{\delta}}(\theta, H)$ for any $q\times q$ orthogonal matrix~$O$, where~$H_O$ denotes the image of~$H$ by the transformation~$x\mapsto Ox$, that is, $H_O$ is the distribution of~$OW$ when~$W$ has distribution~$H$.
\end{thm}

A corollary is that if~$H$ is rotationally symmetric about~$\theta_0$ in the sense that~$H_O=H$ for any $q\times q$ orthogonal matrix~$O$ fixing~$\theta_0$, then $d_\delta (O\theta,H)=d_\delta (\theta, H)$ for any such $O$. In particular, for any~$\alpha$, the $\alpha$-depth region --- that, as usual, is defined as the collection of~$\theta$ values with a depth larger than or equal to~$\alpha$ --- is invariant under rotations fixing~$\theta_0$, hence reflects the symmetry of the distribution~$H$ about~$\theta_0$. 

In contrast, parallel to the angular Mahalanobis depth of \cite{Leyetal2014}, the CDD provides symmetric depth regions of this form for any $H$, i.e, irrespectively of the fact that~$H$ is rotationally symmetric or not. This follows from the comments at the end of Section~\ref{secdef}.

\begin{thm}{\textbf{(Continuity)}} 
\label{thcontinuity}
Assume that the distance~$d$ is continuous; if~$d=d_\delta$, then this is equivalent to assuming that~$\delta:[-1,1]\to \R^+$ is continuous. Let~$H$ be a distribution on~$\mathcal{S}^{q-1}$. Then, (i) the mapping~$\theta\mapsto D_{d}(\theta, H)$ is continuous on~$\mathcal{S}^{q-1}$; (ii) there exists~$\theta_{d}(H)\in\mathcal{S}^{q-1}$ such that $D_{d}(\theta_d(H),H)=\sup_{\theta\in\mathcal{S}^{q-1}} D_{d}(\theta,H)$. 
\end{thm}

Note that the continuity result in Theorem~\ref{thcontinuity}(i) holds without any assumption on~$H$, hence will also hold in the empirical case. Theorem~\ref{thcontinuity}(ii) guarantees the existence of a $D_{d}$-deepest point~$\theta_{d}(H)$. The deepest point (or collection of deepest points) typically depends on the distance~$d$ adopted. For the CDD, the deepest point is the spherical mean, provided that~${\rm E}_H[W]\neq 0$, whereas the deepest point for the ADD is the spherical median of \cite{Fis1985}, which reduces to the circular median (\citealp{MarJup2000},  p.~30) in dimension~$q=2$. 
This is in line with the Euclidean case where deepest points typically depend on the depth considered and may be multivariate medians (e.g., Tukey's halfspace or Liu's simplicial deepest points) or mean vectors (e.g., the zonoid of \cite{KosMos1997} or the moment-based Mahalanobis deepest points). 

The deepest point may not be unique; for the uniform distribution on $\mathcal{S}^{q-1}$, for instance, any rotation-invariant distance-based depth will be constant over the sphere (this readily follows from Theorem~\ref{thmrotainv}). 
This lack of unicity also holds in the Euclidean case, where the barycentre of the collection $\mathcal{C}$ of deepest points is often taken as its unique representative; for most depths, it then follows from the convexity of the depth regions (which guarantees convexity of $\mathcal{C}$) that this barycentre indeed has maximal depth.  
It is interesting to note that directional depths 
are fundamentally different in this respect, as no such convexity arguments can be used. The particular nature of the sample space may induce depth regions that are even disconnected. This may occur for some multimodal distributions~$H$; an example is given in Section~\ref{secillu}. 
In contrast, note that, for~$D_{\cos}$, the collection of deepest points is either $\left\{\mu_{H}\right\}$, when ${\rm E}_H[W]\neq 0$ , or $\mathcal{S}^{q-1}$, when ${\rm E}_H[W]=0$, and hence it is always spherically convex.

It is desirable that if the distribution~$H$ on~$\mathcal{S}^{q-1}$ has an ``indisputable" location centre~$\theta_0$, then the deepest point~$\theta_d(H)$ is unique and coincides with~$\theta_0$. The following theorem provides such a Fisher consistency result. 

\begin{thm}{\textbf{(Fisher consistency under monotone rotational symmetry)}} 
\label{thFishconsist}
Assume that the rotation-invariant distance~$d=d_\delta$ is based on a monotone strictly decreasing function~$\delta:[-1,1]\to \R^+$. Assume that the distribution~$H$ on~$\mathcal{S}^{q-1}$ admits a density of the form~$x\mapsto c_{q,h} h(x'\theta_0)$ for some~$\theta_0\in\mathcal{S}^{q-1}$ and some monotone strictly increasing function~$h:[-1,1]\linebreak \to \R^+$. Then, $\theta\mapsto D_{d_{\delta}}(\theta, H)$ is a monotone strictly increasing function of~$\theta'\theta_0$, so that $\theta\mapsto D_{d_{\delta}}(\theta, H)$ is uniquely maximized at~$\theta_0$. 
\end{thm}

Theorem~\ref{thFishconsist} ensures that the ADD-, CDD-, and ChDD-deepest points are equal and coincide with the modal location $\theta_0$ of $H$ in case the latter admits a density of the form given in the theorem.
The monotonicity result entails that, irrespective of the distance~$d_\delta$ used, the depth regions are of the form~$\{\theta\in\mathcal{S}^{q-1}: \theta'\theta_0\geq c\}$. 

In this setup, the maximal depth,~$\max_{\theta\in\mathcal{S}^{q-1}} D_{d_\delta}(\theta,H)$, measures the concentration of~$H$, as showed in the following theorem. 

\begin{thm}{\textbf{(Maximal depth as a concentration measure)}} 
\label{propconcentr}
Assume that the rotation-invariant distance~$d=d_\delta$ is based on a monotone strictly decreasing function~$\delta:[-1,1]\to \R^+$. Assume that the distribution~$H_\kappa$ on~$\mathcal{S}^{q-1}$ admits the density~$x\mapsto c_{q,\kappa,h} h(\kappa x'\theta_0)$ for some~$\theta_0\in\mathcal{S}^{q-1}$ and some monotone strictly increasing and differentiable function~$h:\R\to \R^+$ such that
$
t \mapsto t\,\frac{d}{dt}\log h(t)
$
is monotone strictly increasing. Then the maximal depth~$D_{d_{\delta}}(\theta_0, H_\kappa)$ is a strictly increasing function of~$\kappa$.  
\end{thm}
In Theorem \ref{propconcentr}, $\kappa$ plays the role of a concentration parameter; typically, the larger~$\kappa$,  the more concentrated the probability mass is about the modal location~$\theta_0$. Since the maximal depth is a strictly increasing function of~$\kappa$, it is itself a concentration (or spread) measure. Note that the assumption that $t \mapsto t\,\frac{d}{dt}\log h(t)
$ is monotone strictly increasing holds in particular if~$h$ is $\log$-convex, so that the result applies for von Mises--Fisher (vMF) distributions that are obtained for~$h\left(u\right)=\exp\left(u\right)$. While Theorem~\ref{propconcentr} restricts to rotationally symmetric distributions, the maximal cosine distance depth~$\max_{\theta\in\mathcal{S}^{q-1}} D_{\cos}(\theta,H)=1+\|E_{H}[W]\|$ is, irrespective of~$H$, related to the ``spherical variance" (\citealp{MarJup2000}, p.~164), that is, to the mean resultant length~$\|E_H[W]\|$ of~$W$.

We conclude this section by stating a property showing that the proposed depths may inherit anti-symmetry properties of the distances on which they are based. More precisely, we have the following result which is restricted to rotationally-invariant distances, although a similar result can be stated for an arbitrary distance~$d$. 
\setlength{\topsep}{1.5em}
\begin{thm}{\textbf{(Anti-symmetry)}} 
\label{thskewsym}
Assume that the rotation-invariant distance~$d=d_\delta$ is based on a function~$\delta:[-1,1]\to \R^+$ that is anti-symmetric about~$0$, i.e., $\delta(-t)+\delta(t)=\delta(-1)$. Let~$H$ be a distribution on~$\mathcal{S}^{q-1}$. Then, 
\begin{enumerate}[label=(\roman*), topsep=0pt, itemsep=-1ex]
\item $\theta\mapsto D_{d_{\delta}}(\theta, H)$ is anti-symmetric on~$\mathcal{S}^{q-1}$ in the sense that
\begin{equation*}
D_{d_{\delta}}(-\theta, H)=d_{\delta}^{\sup}-D_{d_{\delta}}(\theta,H);
\end{equation*}
\item If~$\theta_0$ has maximal depth, then~$-\theta_0$ has minimal depth.  
\end{enumerate}
\end{thm}
The arc length and cosine distances are based on anti-symmetric functions~$\delta$, but the chord distance is not. 
If~$\delta$ is anti-symmetric, then an antipodally symmetric distribution~$H \in \mathcal{S}^{q-1}$, under which~$H(-B) = H(B)$ for any measurable set~$B$ on~$\mathcal{S}^{q-1}$~, leads to a depth function $\theta\mapsto D_{d_{\delta}}(\theta,H)$ that is constant. This is another property contrasting sharply with the Euclidean case, where no distribution will provide a constant depth function. 
To show why the claim on the constancy holds true, consider an arbitrary measurable set~$B\subset\mathcal{S}^{q-1}$ such that~$\mathcal{S}^{q-1}=(-B)\cup B$ and~$(-B)\cap B=\emptyset$. Then, using the antipodal symmetry of~$H$ and the antisymmetry of~$\delta$, we obtain 
\begin{eqnarray*}
 D_{d_{\delta}}(\theta,H)
&=&
 \delta(-1)
-
\int_{-B}
\delta(\theta'w)
\,
dH(w)
-
\int_{B}
\delta(\theta'w)
\,
dH(w)
%
\\[2mm]
&= & 
 \delta(-1)
-
\int_{B}
\delta(-\theta'w)
\,
dH(w)
-
\int_{B}
\delta(\theta'w)
\,
dH(w)
%
\\[2mm]
&= & 
 \delta(-1)
-
\int_{B}
\delta(-1)
\,
dH(w)
=
\frac{ \delta(-1)}{2}
\cdot
\end{eqnarray*}
An interesting question is whether or not antipodal symmetry of~$H$ is also a necessary condition for the constancy of~$\theta\mapsto D_{d_{\delta}}(\theta,H)$ with an anti-symmetric function~$\delta$. While \cite{LiuSin1992} proved that this is indeed the case for the ADD in dimension~$q=2$ under the assumption that~$H$ admits a density, it is not the case for any~$\delta$ function. For instance, for the CDD, it directly follows from~(\ref{cosinexplic}) that~$\theta\mapsto D_{\cos}(\theta, H)$ is constant if and only if $E_{H}[W]=0$, which shows that antipodal symmetry is not a necessary condition for the constancy of~$D_{\cos}$. 

%%%%%%%%%%%%%%%%%%%%% Section 4 %%%%%%%%%%%%%%%%%%%%%%%%

\section{Illustrations}
\label{secillu}

This short section illustrates the theoretical results of the previous section for three empirical distributions on the circle~$\mathcal{S}^1$; we restrict to the circle to allow for a visual comparison of the various depths. Denoting as $H^{\rm vMF}_{\alpha,\kappa}$ the vMF distribution on~$\mathcal{S}^1$ with modal location~$\theta=(\cos\alpha,\sin\alpha)'$ and concentration~$\kappa$, the three empirical distributions considered are associated with a random sample of size~$n=500$ from each of the following distributions:
%
$H_1=H^{\rm vMF}_{\pi,2}$ (unimodal case),
%
$H_2=\frac{1}{2} H^{\rm vMF}_{\frac{3\pi}{4},5}+\frac{1}{2} H^{\rm vMF}_{\frac{5\pi}{4},5}$ (bimodal symmetric case), 
$H_3=\frac{1}{2} H^{\rm vMF}_{\frac{5\pi}{9},7}+\frac{1}{2} H^{\rm vMF}_{\frac{13\pi}{9},17}$ (bimodal asymmetric case).

For each of the resulting empirical distributions~$H_{\ell n}$, $\ell=1,2,3$,   Figure~\ref{Figillu} provides plots of the distance-based depths ADD, CDD and ChDD, as well as the competing angular simplicial depth (ASD) and angular Tukey depth (ATD). The ASD and ATD were computed through the packages {\ttfamily{localdepth}} and {\ttfamily{depth}}, respectively. The distance-based depths were computed by means of {\ttfamily{R}} functions written by the authors. Simulated data and their graphical representations were obtained through the {\ttfamily{R}} package {\ttfamily{circular}} (\citealp{LunAgo2013}), which is a standard reference to work with data on the unit circle. 

\begin{figure}[h!]
\captionsetup{font=scriptsize}
\begin{center}
\includegraphics[width=1.00\textwidth]{Figures/Fig1.pdf}
\end{center}
\vspace{-5mm}
\caption{Plots of the depth mapping~$\alpha\mapsto D({\cos \alpha \choose \sin  \alpha},H_{\ell n})$, for the distance-based depths ADD, CDD and ChDD,
%depths~$D_{\rm arc}$ (Arc), $D_{\cos}$ (Cos) and~$D_{\rm chord}$ (Chord), 
as well as the angular simplicial depth (ASD) and angular Tukey depth (ATD),
%
 and the empirical distributions~$H_{\ell n}$, $\ell=1,2,3$ described in Section~\ref{secillu} (for easier visualization, depth values were actually multiplied by~1.5 for distance-based depths, by~1 for the ASD, and by~0.5 for the ATD). Deepest points are maked by a black dot. The parent density is also plotted in each case. 
}
\label{Figillu}
%\vspace{-1em}
\end{figure}

For~$H_{1n}$, all distance-based depth functions are monotonically strictly decreasing from their deepest point ($\approx \pi$) and do so in a symmetric way, which is in accordance with Theorems~\ref{thmrotainv} and~\ref{thFishconsist}. These depths functions are also continuous; see Theorem~\ref{thcontinuity}. In contrast, the ATD is constant outside the interval of length~$\pi$ centered at its deepest point, which holds for any distribution on the circle (\citealp[Proposition~4.6.]{LiuSin1992}), and both the ASD and ATD are piecewise constant functions. The center-outward rankings provided by the ASD and ATD therefore yield many ties and are more rough than those given by distance-based depths.  
%
For the symmetric bimodal distribution~$H_{2n}$, all depth functions are unimodal, hence fail to capture the bimodality of the distribution, which is not a problem since depths are not density measures but rather centrality measures. 
In contrast with the Euclidean case, some directional depths may exhibit multimodality, as it is the case for the ChDD for the distribution $H_{3n}$, where modes are more separated than in $H_{2n}$; (\ref{cosinexplic}) entails that the CDD will never exhibit such a multimodal pattern. In this last example, the depth functions reflect the asymmetry of the distribution and do not identify the same deepest point; in particular, the CDD is maximized at the spherical mean, whereas the ADD is maximized at the circular median (\citealp{MarJup2000}, p.~20), and so are the ASD and ATD.  


%%%%%%%%%%%%%%%%% Section 5 %%%%%%%%%%%%%%%%%%%%%

\section{Asymptotic and robustness properties}
\label{sec:DistrProperties}

In this section, we present asymptotic results for the distance-based depths introduced in Definition~\ref{defclass} and for the corresponding deepest points, as well as a robustness result regarding the breakdown point of these. We start with a Glivenko-Cantelli-type result. 

\begin{thm}{\textbf{(Uniform almost sure consistency)}} 
\label{thunifconsistency}
Let~$d$ be a bounded and continuous distance on~$\mathcal{S}^{q-1}$ and~$H$ be a distribution on~$\mathcal{S}^{q-1}$. Denote as~$H_n$ the empirical distribution associated with a random sample of size~$n$ from~$H$. Then 
$$
\sup_{\theta\in\mathcal{S}^{q-1}} 
\big|D_{d}(\theta, H_n)-D_{d}(\theta, H)\big|
\to 
0
$$
almost surely as~$n\to\infty$. 
\end{thm}

This result implies that we may explore empirically the properties of~$D_d(\theta,H)$ by considering the corresponding sample depth function~$D_d(\theta,H_n)$ for a large~$n$. This justifies a posteriori the illustration of Theorem~\ref{thFishconsist} in the previous section.
The following asymptotic normality is a direct result of the central limit theorem.

\begin{thm}{\textbf{(Asymptotic normality of sample depth)}} 
\label{thasnormD}
Let~$d$ be a bounded distance on~$\mathcal{S}^{q-1}$ and~$H$ be a distribution on~$\mathcal{S}^{q-1}$. Denote as~$H_n$ the empirical distribution associated with a random sample of size~$n$ from~$H$. Then as~$n\to\infty$,
$
\sqrt{n}(D_{d}(\theta, H_n)-D_{d}(\theta, H))
$
converges weakly to the normal distribution with mean zero and variance~${\rm Var}_H[d(\theta,W)]$. 
\end{thm}

We turn to asymptotic and robustness results for deepest points. The following strong consistency result requires that the deepest point is uniquely defined, as it is in Theorem~\ref{thFishconsist}. 

\begin{thm}{\textbf{(Almost sure consistency of the deepest point)}} 
\label{thdeepestconsistency}
Let~$d$ be a bounded and continuous distance on~$\mathcal{S}^{q-1}$ and~$H$ be a distribution on~$\mathcal{S}^{q-1}$. Assume that the deepest point~$\theta_d(H)$ is unique. Denote as~$H_n$ the empirical distribution associated with a random sample of size~$n$ from~$H$, and let~$\theta_d(H_n)$ be an arbitrary deepest point with respect to~$H_n$. Then
$$
\theta_d(H_n)
\to
\theta_d(H)
$$
almost surely as~$n\to\infty$.  
\end{thm}

Constructing confidence zones for~$\theta_d(H)$ requires the availability of the asymptotic distribution of~$\theta_d(H_n)$. Since~$\theta_d(H_n)$ is an $M$-estimator for a location parameter on~$\mathcal{S}^{q-1}$, its asymptotic distribution can easily be obtained from the results of \cite{KoCha1993}, at least under rotationally symmetric distributions. %considered in Theorem~\ref{thFishconsist}. 
We do not pursue in this direction here.

Since deepest points are commonly used as robust location estimators, it is natural to investigate their robustness, and we therefore end this section by deriving a result on their breakdown point (BDP). In the directional setup considered, the classical BDP concept (\cite{Hametal1986}, pp.~97-98) is not suitable, and we adopt the directional concept of \cite{LiuSin1992} defining the BDP of the (more generally, of a) deepest point~$\theta_d(H)$ as the infimum 
of~$\varepsilon$ such that, for some contaminating distribution $G$ on~$\mathcal{S}^{q-1}$, $-\theta_d(H)$ is a deepest point of~$D_d(\theta, H_{\epsilon})$ with~$H_{\epsilon}:= \left(1 - \epsilon \right) H + \epsilon G$. The following result extends to an arbitrary distance~$d$ the lower bound result obtained in \cite{LiuSin1992} for the arc length distance.

\begin{thm}{\textbf{(Breakdown point of deepest points)}}
\label{thmbdp}
Let $d$ be a bounded distance on~$\mathcal{S}^{q-1}$ and~$H$ be a distribution on~$\mathcal{S}^{q-1}$. Let~$\theta_d(H)$ be a deepest point of~$D_{d}(\theta,H)$. Then the breakdown point of~$\theta_d(H)$ is larger than or equal to~$(D_{d}(\theta_d(H),H) - D_{d}(-\theta_d(H),H))\linebreak/(2d^{\rm sup})$.
\end{thm}

To investigate how the distance~$d$ affects the lower bound, we consider the important case of vMF distributions. If~$H^{\rm vMF}_{q,\theta_0,\kappa}$ denotes the vMF($\theta_0,\kappa$) distribution on~$\mathcal{S}^{q-1}$, then, for a rotation-invariant distance~$d_\delta$ that is decreasing in the sense of Theorem~\ref{thFishconsist}, we have~$\theta_{d_\delta}(H^{\rm vMF}_{q,\theta_0,\kappa})=\theta_0$ and  
$$
D_{d_\delta}(\pm\theta_0,H^{\rm vMF}_{q,\theta_0,\kappa})
=
d^{\rm sup}_\delta
-
\frac{ 
\int_{-1}^1
\delta(\pm v)
(1-v^2)^{(q-3)/2}
\exp(\kappa v) 
\,
dv
}
{\int_{-1}^1
(1-v^2)^{(q-3)/2}
\exp(\kappa v) 
\,
dv
} 
,
$$
which allows us to evaluate the lower bound from Theorem~\ref{thmbdp}. 

Figure~\ref{BDPfig} plots this lower bound as a function of~$\kappa$ for various dimensions~$q$ and for the ADD, CDD and ChDD. Clearly, irrespective of the dimension and the distance, the lower bound is arbitrarily small for arbitrarily small values of~$\kappa$ and goes to 50\% as~$\kappa$ goes to infinity. The lower bound decreases as the dimension~$q$ increases. More importantly, for vMF distributions, the CDD-deepest point, namely the spherical mean,
provides a larger lower bound than the ADD- and CHDD-deepest ones do.
%\vspace{-1.5em}
\begin{figure}[h!]
\captionsetup{font=scriptsize}
\begin{center} 
\makebox[\textwidth]{%
\includegraphics[width=\textwidth]{Figures/BDP.jpg}
}
\end{center}
\vspace{-1em}
\caption{Plots of the lower bound in Theorem~\ref{thmbdp}, for various dimensions~$q$ and for the ADD $(\rule[0.5ex]{0.4cm}{0.2pt})$, CDD $(\scriptsize\textendash\ \textendash)$, and ChDD $(\cdots)$, as a function of the concentration~$\kappa$ of the underlying vMF distribution on~$\mathcal{S}^{q-1}$.}
\label{BDPfig}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%% Section 6 %%%%%%%%%%%%%%%%%%%%%%%

\section{Applications}
\label{secSimu}

We present two applications, which are related to spherical location estimation and supervised classification. 

%%----------------------------------------------------

\subsection{Spherical location estimation}
\label{secSimusub1}

Depth functions find applications in robust statistics, with the deepest point considered as a robust location estimator.

For this reason, we conducted a simulation study to investigate the efficiency and robustness properties of the deepest points associated with the proposed distance-based depths, and to compare them with those of the competing ASD- and ATD-deepest points
We start with efficiency properties. For any combination of a dimension~$q\in\{3,5\}$, a sample size~$n\in\{25,50,100\}$ and a concentration~$\kappa\in\{5,10\}$, we generated $M=500$ independent random samples of size~$n$ from the distribution~$H^{\rm vMF}_{q,\theta,\kappa}$, where~$\theta=e_q$ is the last vector of the canonical basis of~$\R^q$. 
For each estimator~$\hat{\theta}$ of~$\theta$ considered, this leads to estimates~$\hat{\theta}_{1},\ldots,\hat{\theta}_{M}$. % For each estimator~$\hat{\theta}$ of~$\theta$ considered, namely, the deepest points associated with the ADD, CDD and ChDD, as well as with the ASD and ATD, this leads to estimates~$\hat{\theta}_{1},\ldots,\hat{\theta}_{M}$. 
Figure~\ref{Efficiencyfig} provides boxplots of the resulting squared errors 
\begin{equation}
{\rm SE}_{m} 
= 
 \|\hat{\theta}_{m}- \theta\|^2
= 
2 (1 - \hat{\theta}_{m}' \theta)
,
\qquad
m=1,\ldots, M,
\label{SEdef}	
\end{equation}
and indicates the resulting mean square errors~${\rm MSE} = (1/M) \sum_{m=1}^M {\rm SE}_{m}$. The computational burden for the ASD- and ATD-deepest points is so prohibitive that these were considered for dimension~$q=3$ only.

\begin{figure}[h!]
\captionsetup{font=scriptsize} 
\begin{center}  
\makebox[\textwidth]{%
\includegraphics[width=\textwidth]{Figures/PlotEfficiency.pdf}
}
\end{center}
\vspace{-5mm}
\caption{Boxplots, for~$q\in\{3,5\}$, $n\in\{25,50,100\}$ and~$\kappa\in\{5,10\}$, of the squared errors~${\rm SE}_{m}$, $m=1,\ldots,M$ (see~(\ref{SEdef})) of various depth-based estimators of~$\theta$ obtained from $M=500$ independent random samples of size~$n$ from the vMF distribution~$H^{\rm vMF}_{q,\theta,\kappa}$ with location~$\theta=e_q$ (the last vector of the canonical basis of~$\R^q$). The estimators considered are the ADD-, CDD- and ChDD-deepest points, as well as (due to computational issues, for dimension~$q=3$ only) the deepest points associated with the ASD and ATD. In each case, the corresponding mean square error~${\rm MSE} = (1/M) \sum_{m=1}^M {\rm SE}_{m}$ is provided.} 
\label{Efficiencyfig}
\end{figure}

Results indicate that, in dimension~$q=3$, the estimators associated with distance-based depths slightly dominate their ATD competitor and outperform their ASD one. As expected, the CDD-deepest point, that is the maximum likelihood estimator in the distributional setup considered, is in most cases the most efficient estimator. 
In dimension~$q=5$, where the ASD/ATD estimators could not be computed, the distance-based depths perform similarly. On the other hand, while the CDD estimator slightly dominates at all sample sizes in dimension $q = 3$, it dominates only at the largest considered sample size in dimension $q=5$.

We now turn to the investigation of robustness properties for which we restricted to dimension~$q=3$. For any combination of a contamination level~$\varepsilon\in\{0,0.05,0.10\}$ and a concentration~$\kappa\in\{5,10\}$, we generated $M=500$ independent random samples of size~$n=100$ from the contaminated distributions~$(1-\varepsilon)H^{\rm vMF}_{q,\theta,\kappa}+\varepsilon \Delta_{\theta_r}$, $r=1,2$, where~$\theta$ is set as~$e_q$, $\theta_1=e_{q-1}$, $\theta_2=-\theta$, $\Delta_{\psi}$ denotes the point mass distribution at~$\psi$. Hence, $r=1,2$ refers to contamination at an orthogonal point to~$\theta$ and at the antipodal point to~$\theta$, respectively. In each sample, the deepest points of the same five depths as in Figure~\ref{Efficiencyfig} were computed. The resulting boxplots of squared errors~${\rm SE}_m$ for $m=1,\ldots,M$ and the mean squared errors (${\rm MSE}$) are provided in Figure~\ref{Robustnessfig}. 

\begin{figure}[h!]
\captionsetup{font=scriptsize}
\begin{center}  
\makebox[\textwidth]{%
\includegraphics[width=\textwidth]{Figures/PlotRobustness.pdf}
}
\end{center}
\vspace{-5mm}
\caption{Boxplots, for~$q=3$, $\varepsilon\in\{0,0.05,0.10\}$ and~$\kappa\in\{5,10\}$, of the squared errors~${\rm SE}_{m}$, $m=1,\ldots,M$ (see~(\ref{SEdef})) of various depth-based estimators of~$\theta$ obtained from $M=500$ independent random samples of size~$n=100$ from the contaminated distribution~$(1-\varepsilon)H^{\rm vMF}_{q,\theta,\kappa}+\varepsilon \Delta_{\theta_r}$, where~$\theta$ is the last vector of the canonical basis of~$\R^q$, $\Delta_{\psi}$ denotes the point mass distribution at~$\psi$, and where $\theta_1$ (resp., $\theta_2$) is an orthogonal point to~$\theta$: $r=1$ (resp., the antipodal point to~$\theta$: $r=2$). The estimators considered are the ADD-, CDD- and ChDD-deepest points, as well as the deepest points associated with the ASD and ATD. In each case, the corresponding mean square error~${\rm MSE} = (1/M) \sum_{m=1}^M {\rm SE}_{m}$ is provided.} 
\label{Robustnessfig}
\end{figure}

The results show that the estimators associated with distance-based depths enjoy good robustness properties. In particular, irrespective of the contamination level~$\varepsilon$ and the type of contamination, the ADD, CDD and ChDD estimators outperform the ASD one in terms of robustness. The domination over the ATD estimator is less significant.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Supervised classification}
\label{secSimusub2}

Classification has been one of the most successful applications of statistical depth in the last decade, both for multivariate and functional data. While some proposals were based  on the use of local depth concepts (\citealp{PaiVanB2013}) or a depth-based version of kNN classification (\citealp{PaiVanB2012}), the dominant solution finds its source in the \emph{max-depth approach} of \cite{GhoCha2005B} that has later been refined by \cite{Lietal2012}. To the best of our knowledge, depth-based classification for directional data has not been considered in the literature. In this section, we show that the max-depth approach also applies for directional data and that, in conjunction with the proposed distance-based depths, it provides classifiers on the hypersphere that dominate ASD/ATD-based ones and that can be applied in higher dimensions as well. 

Consider the spherical classification problem where independent random samples~$W_{1i}$, $i=1,\ldots,n_1$ and~$W_{2i}$, $i=1,\ldots,n_2$, respectively, come from distributions~$H_1$ and~$H_2$ on~$\mathcal{S}^{q-1}$, and one is given the task to classify a point~$w(\in\mathcal{S}^{q-1})$ as arising from~$H_1$ (``population~1") or from~$H_2$ (``population~2"). Denoting as~$H_{\ell n_\ell}$ the empirical distribution associated with~$W_{\ell i}$, $i=1,\ldots,n_\ell$ ($\ell=1,2$),
%  If~$\theta\mapsto D(\theta,H)$ is a generic depth function on~$\mathcal{S}^{q-1}$ with respect to~$H$, 
the max-depth classifier associated with a depth~$D$ classifies~$w$ into population~1 if~$D(w,H_{1n_1})>D(w,H_{2n_2})$, and population~2 otherwise; if~$D(w,H_{1n_1})=D(w,H_{2n_2})$, then the classification decision is based on the flip of a fair coin.    

To investigate the finite-sample performances of such classifiers, we consider the Monte Carlo algorithm that was performed for dimensions~$q=2$ and~$q=10$. Denoting as~$e_j$ the $j$th vector in the canonical basis of~$\R^q$ and using the notations~$H^{\rm vMF}_{\alpha,\kappa}$ and~$H^{\rm vMF}_{q,\theta_1,\kappa}$ from Sections~\ref{secillu} and~\ref{sec:DistrProperties}, respectively, we considered the following three distributional setups:
% characterized by the following pairs of distributions:
\begin{itemize}
	\item Setup~A involves the vMF distributions~$H_1=H^{\rm vMF}_{\frac{\pi}{4},5}$ and~$H_2=H^{\rm vMF}_{\frac{3\pi}{4},5}$ for~$q=2$, and~$H_1=H^{\rm vMF}_{q,e_1,5}$ and~$H_2=H^{\rm vMF}_{q,e_q,5}$ for~$q=10$; Setup~A therefore involves distributions differing through the modal location only.
%
	\item In Setup~B,~$H_1=H^{\rm vMF}_{\frac{\pi}{3},2}$ and~$H_2=H^{\rm vMF}_{\frac{2\pi}{3},5}$ for~$q=2$, and~$H_1=H^{\rm vMF}_{q,e_q,2}$ and~$H_2=H^{\rm vMF}_{q,(\cos \frac{\pi}{6})e_{q-1}+(\sin \frac{\pi}{6})e_q,5}$ for~$q=10$; in this setup, distributions differ through location and concentration. 
%
	\item Setup~C involves discrimination between the vMF distribution~$H_1=H^{\rm vMF}_{\frac{3\pi}{4},4}$ and the mixture distribution~$H_2=\frac{1}{2}H^{\rm vMF}_{0,4}+\frac{1}{2}H^{\rm vMF}_{\frac{\pi}{2},4}$ for~$q=2$, and~$H_1=H^{\rm vMF}_{q,(\cos \frac{7\pi}{4})e_{q-1}+(\sin \frac{7\pi}{4})e_q,4}$ and~$H_2=\frac{1}{2}H^{\rm vMF}_{q,e_{q-1},4}+\frac{1}{2}H^{\rm vMF}_{q,e_q,4}$ for~$q=10$. 
\end{itemize}  
For each setup and each~$q$, we generated $M=250$ independent training samples of size~$n_{\rm train}=200$ and test samples of size~$n_{\rm test}=100$ by sampling randomly from~$\frac{1}{2}H_1+\frac{1}{2}H_2$. In replication~$m \in \{1,\ldots,250\}$, this associates with any depth~$D$ on~$\mathcal{S}^{q-1}$ the misclassification rate~$p_m(D)=N_m(D)/n_{\rm test}$, where~$N_m(D)$ is the number of observations in the $m$th test sample that were misclassified by the max-depth classifier associated with~$D$ when based on the $m$th training sample. Figure~\ref{Classifig} provides the boxplots, for several depths~$D$, of the resulting~$M=250$ misclassification rates. As in Section~\ref{secSimusub1}, the depths considered are the ADD, CDD, ChDD, ASD and ATD; again, computational issues prevented to consider the ASD and ATD in dimension~$q=10$.  


\begin{figure}[h!] 
\captionsetup{font=scriptsize}
\begin{center}  
\makebox[\textwidth]{%
\includegraphics[width=\textwidth]{Figures/Plotmaxdepth_class.pdf}
}
\end{center}
\vspace{-5mm}
\caption{Boxplots, for~$q\in\{2,10\}$, of the misclassification rates~$p_m(D)$, $m=1,\ldots,M$, obtained from $M=250$ independent replications in three different distributional setups (see Section~\ref{secSimusub2} for details), for the max-depth classifiers associated with the ADD, CDD, ChDD, ASD and ATD (due to computational issues, the ASD and ATD were considered for dimension~$q=2$ only). In each case, the corresponding mean misclassification rate~$p(D) = (1/M) \sum_{m=1}^M p_{m}(D)$ is provided.} 
\label{Classifig}
\end{figure}
 
Results indicate that distance-based depth classifiers dominate in most cases their counterparts based on the ASD/ATD. It is only in Setup~$C$ that the ASD/ATD classifiers seem to slightly improve over the ADD and CDD classifiers. In all cases, the classifier based on the ChDD is the best classifier. Most importantly, in higher dimensions, the computational burden for the ASD/ATD is such that only the distance-based depth classifiers can be used. 


%%%%%%%%%%%%%%%%% Section 7 %%%%%%%%%%%%%%%%%%%%%

\section{Discussion}
\label{secfinal}
 

In the Euclidean multivariate setup, statistical depth has allowed to tackle in a nonparametric and robust way diverse problems, including location/scatter estimation, two-sample hypothesis testing, supervised classification, etc. While depths in the spherical setup, such as the ASD and ATD, were proposed more than two decades ago, the concept has not made its way to applications. Arguably, the reasons are that these depths are, even for moderate dimensions, very computationally intensive and that it is challenging to derive their asymptotic properties.  

The class of distance-based depths for directional data defined in this work clearly improve on this. These depths were showed to be computable in higher dimensions, and asymptotic results can be obtained by using standard $M$-estimation techniques. For small dimensions, where distance-based depths as well as the ASD/ATD can be evaluated, we showed through simulations that inference procedures based on the former compete equally or even dominate those based on the latter. In high dimensions, only distance-based depths can be used for directional data, which makes them of potential interest for applications involving high-dimensional spherical problems, such as those encountered in magnetic resonance, gene expression, or text mining; see, among others, \cite{Dry2005}, \cite{banerjee2003generative}, and \cite{Banetal2005}. 

Perspectives for future research are rich and diverse. Obviously, it would be of interest to investigate how distance-based depths can tackle the problems considered in the aforementioned high-dimensional applications. More generally, irrespective of the dimension, it would be desirable to develop depth-based inference procedures in various setups, including two-sample hypothesis testing and supervised classification. Finally, the present work also raised some theoretical questions of interest. For instance, in dimension~$q=2$, the arc distance depth is constant if and only if the underlying distribution~$H$ is antipodal, whereas the cosine distance depth is constant if and only if~$H$ has zero mean. In view of this, it is natural to wonder what property of~$H$ is characterized by constancy of the chord distance depth. The question can be raised on the circle with $q=2$ or for a general dimension~$q>2$. Such characterization results are of interest since they obviously provide the basis for universally consistent tests of the corresponding properties. 




%%%%%%%%%%%%%%%%% Appendix %%%%%%%%%%%%%%%%%%%%%%%%%


\appendix



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

As announced in Section~\ref{sec:StructProperties}, we prove the following result for the sake of completeness.

\begin{prop}
\label{prodistinv}
	Let~$d$ be a rotation-invariant distance on~$\mathcal{S}^{q-1}$. Then there exists a function~$\delta:[-1,1]\to\R^+$ such that~$d(\theta,\psi)=\delta(\theta'\psi)$.
\end{prop}

Proof of Proposition~\ref{prodistinv}.
For any~$\theta,\psi\in\mathcal{S}^{p-1}$, let~$\psi_\theta=(\psi-(\psi'\theta)\theta)/\|\psi-(\psi'\theta)\theta\|$ and denote as $\Gamma_{\theta,\psi}$ an arbitrary $q\times (q-2)$ matrix such that~$O_{\theta,\psi}=(\theta \vdots \psi_\theta \vdots \Gamma_{\theta,\psi})$ is orthogonal (if~$q=2$, then we simply consider~$O_{\theta,\psi}=(\theta \vdots \psi_\theta)$). Since~$d$ is rotation-invariant, we have~$d(\theta,\psi)=d(O_{\theta,\psi}'\theta,O_{\theta,\psi}'\psi)=d(e_1,O_{\theta,\psi}'\psi)$, where~$e_1$ stands for the first vector of the canonical basis of~$\R^q$. The result then follows from the fact that 
$
O_{\theta,\psi}'\psi
=
(
\theta'\psi , (1-(\theta'\psi)^2)^{1/2},0,\ldots,0
)'
$
depends on~$\theta$ and~$\psi$ through~$\theta'\psi$ only.
\cqfd
\vspace{3mm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Proof of Theorem~\ref{thmrotainv}.
Using the notation introduced in the theorem, we have that $D_{d_{\delta}}(O\theta, H_O)
=\delta(-1)-E_{H_O}[\delta((O\theta)'W)]
=\delta(-1)-E_{H}[\delta((O\theta)'OW)]
=\delta(-1)
\linebreak
-E_{H}[\delta(\theta'W)]
=D_{d_{\delta}}(\theta, H)$.
\cqfd
\vspace{3mm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Proof of Theorem~\ref{thcontinuity}.
(i) Since the function~$w\mapsto d(\theta,w)$ is continuous in~$w$ for any~$\theta\in\mathcal{S}^{q-1}$ and is bounded, uniformly in~$\theta$, by the integrable function~$w\mapsto d^{\sup}$, the continuity of
$$ 
\theta\mapsto D_{d}(\theta, H)
=
d^{\sup}
-
\int_{\mathcal{S}^{q-1}}
d(\theta,w)
\,
dH(w)
$$
results from Corollary 2.8.7(i) in \cite{Bog2007}. (ii) The result follows from the fact that  a continuous function on a compact domain attains its maximal value.
\cqfd
\vspace{3mm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Proof of Theorem~\ref{thFishconsist}.
Since the distribution~$H$ is rotationally symmetric about~$\theta_0$, Theorem~\ref{thmrotainv} implies that~$D_{d_{\delta}}(\theta, H)$ depends on~$\theta$ only through~$\theta'\theta_0$. Consider then an arbitrary geodesic path~$t\mapsto \theta_t$ from~$\theta_0$ to~$\theta_1=-\theta_0$. The monotonicity assumption on~$h$ readily implies that, for any~$s\in[-1,1]$, the function~$t\mapsto P_{H}[ \theta_t'W \geq s]$ is monotone strictly decreasing. 
%  Indeed: assume that the geodesic path is equipped with its natural parametrization and let $t_1<t_2$. For any~$\psi\in\{ \psi: \theta_{t_2}'\psi \geq s \}\setminus \{ \psi: \theta_{t_1}'\psi \geq s \}$, one can consider the symmetric~$\tilde{\psi}$ of~$\psi$ with respect to~$\theta_{(t_1+t_2)/2}$. The result follows from the fact that the density of $\psi$ is smaller than that of $\tilde{\psi}}$.  
Since
\begin{eqnarray*}
E_H[\delta(\theta_t' W)]
&=&
\int_{0}^{\delta(-1)} z\, \frac{d}{dz} P_{H}[ \delta(\theta_t'W) \leq z] \,dz
\\[2mm]
&=&
\delta(-1) - \int_{0}^{\delta(-1)} P_{H}[ \delta(\theta_t'W) \leq z] \,dz
\\[2mm]
&=&
\delta(-1) - \int_{0}^{\delta(-1)} P_{H}[ \theta_t'W \geq \delta^{-1}(z)] \,dz
,
\end{eqnarray*}
it follows that
\begin{equation}
	\label{ahahah}
D_{d_{\delta}}(\theta_t, H)
=
\delta(-1)-E_H[\delta(\theta_t' W)]
=
\int_{0}^{\delta(-1)} P_{H}[ \theta_t'W \geq \delta^{-1}(z)] \,dz
\end{equation}
is strictly decreasing in~$t$. This establishes the result.
\cqfd
\vspace{3mm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Proof of Theorem~\ref{propconcentr}.
First note that for any~$s$, 
\begin{equation}
	\label{tqhz1}
P_{H_\kappa}[\theta_0'W\geq s]
=
\frac{ 
\int_{s}^1
(1-v^2)^{(q-3)/2}
h(\kappa v) 
\,
dv
}
{\int_{-1}^1
(1-v^2)^{(q-3)/2}
h(\kappa v) 
\,
dv
}
\end{equation}
(see, e.g., \citealp{PaiVer17b}), which provides
\begin{equation}
	\label{tqhz2}
\frac{P_{H_\kappa}[\theta_0'W\geq s]}{1-P_{H_\kappa}[\theta_0'W\geq s]}
=
\frac{ 
\int_{s}^1
(1-v^2)^{(q-3)/2}
h(\kappa v) 
\,
dv
}
{\int_{-1}^s
(1-v^2)^{(q-3)/2}
h(\kappa v) 
\,
dv
}
\cdot
\end{equation}
Differentiation with respect to~$\kappa$ yields
\begin{eqnarray*}
\lefteqn{
\frac{d}{ds}
\frac{P_{H_\kappa}[\theta_0'W\geq s]}{1-P_{H_\kappa}[\theta_0'W\geq s]}
}
\\[2mm]
& & 
\hspace{3mm} 
=
\frac{ 
\int_{s}^1
\int_{-1}^s
[
v
\dot h(\kappa v) 
h(\kappa u) 
-
u
\dot h(\kappa u) 
h(\kappa v) 
]
((1-u^2)(1-v^2))^{(q-3)/2}
\,
du
dv
}
{
(
\int_{-1}^s
(1-v^2)^{(q-3)/2}
h(\kappa v) 
\,
dv
)^2
}
\cdot
\end{eqnarray*}
Since~$t \mapsto t\,\frac{d}{dt}\log h(t)=t \dot{h}(t)/h(t)$ is strictly increasing, this derivative is strictly positive at any~$\kappa$, so that the lefthand side of~(\ref{tqhz2}), hence also that of~(\ref{tqhz1}),  is a monotone strictly increasing function of~$\kappa$. The result then follows from the identity
$
D_{d_{\delta}}(\theta_0, H_\kappa)
=
\int_{0}^{\delta(-1)} P_{H_\kappa}[ \theta_0'W \geq \delta^{-1}(z)] \,dz
$;
see~(\ref{ahahah}). % in the proof of Theorem~\ref{thFishconsist}. 
\cqfd
\vspace{3mm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Proof of Theorem~\ref{thskewsym}.
(i) The anti-symmetry of~$\delta(\cdot)$ readily yields
$
D_{d_{\delta}}(-\theta, H) 
+
D_{d_{\delta}}(\theta, H) 
=
2 \delta(-1) - E_{H}[d_\delta(-\theta,W)+d_\delta(\theta,W)]
=
2 \delta(-1) - E_{H}[\delta(-\theta' W)+\delta(\theta' W)]
\linebreak
=
\delta(-1) 
$,	
which establishes the result. (ii) Ad absurdum, assume that~$-\theta_0$ does not have minimal depth, so that there exists~$\theta_1\in\mathcal{S}^{q-1}$ with~$D_{d_{\delta}}(\theta_1, H)<D_{d_{\delta}}(-\theta_0, H)$. Then Part~(i) of the result implies that~$D_{d_{\delta}}(-\theta_1, H)>D_{d_{\delta}}(\theta_0, H)$, which contradicts the fact that~$\theta_0$ has maximal depth.
\cqfd
\vspace{3mm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Proof of Theorem~\ref{thunifconsistency}.
The result directly follows from Theorem~16(a) in \cite{Fer1996}.
\cqfd
\vspace{3mm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Proof of Theorem~\ref{thasnormD}.
The result trivially follows from applying the central limit theorem to the expression~$
\sqrt{n}(D_{d}(\theta, H_n)-D_{d}(\theta, H))
=
-n^{-1/2} \sum_{i=1}^n (d(\theta,W_i)- {\rm E}_H[d(\theta,W)])
$.
\cqfd
\vspace{3mm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Proof of Theorem~\ref{thdeepestconsistency}.
In view of Theorem~\ref{thunifconsistency}, the result is a corollary of Theorem~2.12 and Lemma~14.3 in \cite{Kos2008}.
\cqfd
\vspace{3mm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Proof of Theorem~\ref{thmbdp}.
From Lemma~2.3 in \cite{str1985}, we obtain that, for any~$\theta\in\mathcal{S}^{q-1}$, 
$
| D_{d}(\theta,H_\varepsilon)-D_{d}(\theta,H) |
%=
%(1-\varepsilon) \int d(\theta,\psi)\,dH(\psi)
%+
%\varepsilon \int d(\theta,\psi)\,dG(\psi)
%-
%\int d(\theta,\psi)\,dH(\psi)
%$$
%$$ 
%=
%-\varepsilon \int d(\theta,\psi)\,dH(\psi)
%+
%\varepsilon \int d(\theta,\psi)\,dG(\psi)
%$$
%$$
=
\varepsilon (E_G[d(\theta,W)]-E_H[d(\theta,W)])
%\bigg| \int_{\mathcal{S}^{q-1}} d(\theta_0(H),\psi)\,dG(\psi)
%-\int_{\mathcal{S}^{q-1}} d(\theta_0(H),\psi)\,dH(\psi)\bigg|
\leq 
\varepsilon d^{\rm sup} d_1(H,G)
,
$
where $d_1(H,G)$ denotes the variational distance between~$H$ and~$G$. %\color[rgb]{0.24,0.7,0.44} For countable spaces, ~$d_1$ is the half $L^{1}(H,G)$ norm between: $d_{1} \left(H, G\right) = \frac{1}{2} \left\|H - G\right\|_{1}$
Lemmas~2.4 and~2.5(i) in \cite{str1985} then yield that, still for any~$\theta\in\mathcal{S}^{q-1}$,
$
| D_{d}(\theta,H_\varepsilon)-D_{d}(\theta,H) |
\leq
\varepsilon d^{\rm sup}
.
$
The result readily follows.
\cqfd
\vspace{3mm}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%% Bibliography %%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%Bibliography

\bibliographystyle{chicago}
\bibliography{ManuscriptRevised.bib}           
\vspace{3mm} 



\end{document}





























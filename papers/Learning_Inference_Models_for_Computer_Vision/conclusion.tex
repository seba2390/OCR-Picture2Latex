\chapter{Conclusions and Outlook}
\label{chap:conclusion}

Generative models provide a strong set of tools for modeling the vision world
around us. But their use in computer vision is hampered by the complexity
of inference in them causing the vision community to favor data-hungry discriminative
models. Both generative and discriminative models have complementary advantages and
disadvantages as discussed in Chapter~\ref{chap:models}. Generative models provide
an easy handle for incorporating prior knowledge about the task but inference
is often too complex in them. Discriminative models, on the other hand, have
a straightforward inference scheme as forward evaluation of models, but lack
principled ways of incorporating prior knowledge into them.

This thesis work proposed techniques for alleviating some of the key issues
with prominent computer vision models by improving inference in them.
A common strategy that is followed across several techniques proposed in this
thesis is leveraging the complementary models for better inference in a given
model. That is, we leverage discriminative models for better inference in
generative computer vision models. And we used generative knowledge (in the form
of bilateral filters) and enriched the existing discriminative CNN models.
This way, this thesis made important steps in bridging the gap between
generative and discriminative vision models. The proposed inference techniques
are flexible enough to deal with different task scenarios (e.g.,\ availability
of large or small amounts of data).

\paragraph{Inference in Generative Vision Models} In the case of generative
models, we leverage discriminative clustering or random forests techniques
to accelerate and/or to improve the Bayesian inference. In Chapter~\ref{chap:infsampler},
we proposed a new sampling technique called `Informed Sampler', where discriminative models
help in better exploration of target domain, via \emph{informed} proposals,
while doing MCMC sampling. In Chapter~\ref{chap:cmp}, we proposed a new message passing technique called
`Consensus Message Passing' where random forest predictors are used for predicting
\emph{consensus} messages during standard message passing inference resulting in
convergence to better solutions.

In both `Informed Sampler' and `Consensus Message
Passing' (CMP), we made sure that the theoretical guarantees that come with
the well established inference techniques are not violated with our modified
inference schemes. In the informed sampler, we achieve this by injecting
discriminative knowledge in MCMC sampling via proposal distributions and
adhering to detailed balance condition while sampling. And in consensus
message passing, we used consensus messages from discriminative predictors only
during the first few iterations ensuring that the fixed point reached by our
modified inference is also a fixed point of standard message passing in the
model. We evaluated both the informed sampler and CMP techniques on three
different generative models each, reflecting a wide range of problem scenarios,
where we consistently observed improved inference with the proposed techniques
in comparison to standard sampling and message passing inference techniques.


\paragraph{Inference in Discriminative Vision Models} In this thesis, we focus
on the inference in prominent CNN models. Spatial convolutions form the basic
building block of most CNN architectures.
A key observation in this thesis work is that the bilateral
filters~\cite{aurich1995non,tomasi1998bilateral}
are a generalization of spatial convolutions and do not have many of the limitations
that spatial convolutions have. The key issue with the existing use of bilateral
filters is they are confined to fixed hand-tuned parameterization.

In Chapter~\ref{chap:bnn}, we proposed a generalized bilateral filter and devised
a gradient based technique for
learning the filter parameters. Experiments on wide range of problems showed the
superior performance of learnable bilateral filters with respect to using Gaussian
filter kernel. Learnable bilateral filters enabled us to stack several filters
together and learn all of them via back-propagation. Using this, we proposed
novel neural network architectures which we call `Bilateral Neural Networks' (BNN).

In Chapter~\ref{chap:vpn}, we showed how BNNs can be easily adapted to filter video
data for propagating temporal information across video frames.
In Chapter~\ref{chap:binception}, we proposed new and fast neural network modules, based
on explicit Gaussian bilateral filtering called `Bilateral Inceptions' and showcased
how we can modify existing segmentation CNN architectures for big improvements in
accuracy while adding little time overhead.

Bilateral filters form the core of mean-field
inference in DenseCRF models~\cite{krahenbuhl2012efficient} and provide a way to incorporate
prior knowledge about the scene in the form of dense feature-based connectivity
across the pixels. By integrating learnable bilateral filters into standard CNN architectures,
we brought the worlds of CRF and CNN closer, providing a way to incorporate prior
knowledge into CNNs.

\section{Summary of Contributions}

The following list summarizes the specific contributions of this thesis work:

\begin{itemize}
\item We devised a novel MCMC sampling approach called `Informed Sampler' (Chapter~\ref{chap:infsampler})
for doing Bayesian inference in complex generative vision models.
The Informed sampler leverages discriminative approaches
for improving the efficiency of MCMC sampling. Experiments on a wide range of generative vision
models showed significantly faster convergence of our sampler while maintaining higher acceptance rates.
This opens up possibilities for using complex generative models like graphics engines for addressing vision problems.

\item We devised a novel message passing technique called `Consensus Message Passing’ (CMP),
in Chapter~\ref{chap:cmp}, for doing Bayesian inference in layered graphical models used in vision.
Experiments on diverse
graphical models in vision showed that CMP resulted in significantly better performance compared
to standard message passing techniques such as expectation propagation or variational message passing.
Moreover, CMP is the first instance where the Infer.NET~\cite{InferNET2012} probabilistic programming language is shown to
be useful for addressing vision problems.

\item We parameterized bilateral filters as general sparse high dimensional filters (Chapter~\ref{chap:bnn}) and
devised an approach for learning the filter kernels via standard back-propagation learning
techniques. This resulted in a general technique for learning sparse high-dimensional filters,
which in turn resulted in a generalization of standard bilateral filters. Experiments on wide
range of applications showed improved performance with respect to standard Gaussian bilateral filters.

\item We also show how learning bilateral filters can generalize the fully-connected conditional
random field models (DenseCRF) to arbitrarily learned pairwise potentials (Section~\ref{sec:densecrf})
instead of standard Gaussian pairwise edge potentials.
DenseCRF is one of the widely used CRF techniques in vision and this generalization
carries forward to most of its existing applications and helps in better integration into end-to-end
trained models like convolutional neural networks (CNN).

\item Our technique for learning general sparse high dimensional filters also generalizes standard
spatial convolutions in CNN frameworks. This opens up possibilities for applying CNNs to
sparse high-dimensional data, which is not feasible with many standard CNN techniques. Moreover,
our technique can be used for learning image-adaptive filters inside CNNs instead of standard
image-agnostic 2D filters.

\item We adapted the learnable sparse high dimensional filters for video filtering, in Chapter~\ref{chap:vpn},
and proposed a novel neural network approach for propagating content across video frames.
We call our networks `Video Propagation Networks'~(VPN).
Experiments on video object segmentation and semantic video segmentation showed that VPN
outperformed existing task-specific methods while being faster.

\item In Chapter~\ref{chap:binception}, we devised a new CNN module called `Bilateral Inception'
that can be readily inserted into standard segmentation CNN models resulting in better performance
while producing the result at original image resolution and also alleviating some of the need for
post-processing. Experiments on state-of-the-art CNN models resulted in significantly better
performance with our inception module while being competitive in time.
\end{itemize}

\section{Outlook}

With the diverse range of experiments on each proposed technique, I hope to have
convinced the readers that this thesis work resulted in several important advances
for inference in computer vision models.
Inference in computer vision models is still a very active area of research
and I hope the work presented in this thesis aids in further advances in this
area of research. The following are some of the research topics that could benefit
from the concepts and techniques presented in this thesis.

\vspace{-0.2cm}
\paragraph{Leveraging Photo-Realistic Graphics for Vision:} As discussed in
Section~\ref{sec:inv-graphics}, modern graphics engines leverage dedicated hardware
setups and provide real-time renderings with stunning level of realism.
This is made possible with accurate modeling of image
formation. Such realistic graphics models are seldom utilized in building vision
systems due to the difficulty in posterior inference. The informed sampler
(Chapter~\ref{chap:infsampler}) and consensus message passing (Chapter~\ref{chap:cmp})
techniques presented in this thesis made important steps in making the inference
faster. But the proposed techniques are still not fast enough
for practical purposes. An important research direction is to further improve the
efficiency of inference by making use of the internals of state­-of­-the-­art rendering
mechanisms such as ‘Metropolis Light Transport’~\cite{vorba2014line}.
One way to achieve this is by improving MCMC sampling efficiency
via pre­-rejection using the rejection technique of~\cite{korattikara2013austerity},
without the need for doing full rendering for the rejected samples in MCMC.
This would result in a better coupling of graphics and Bayesian vision systems.

\vspace{-0.2cm}
\paragraph{CNNs for Sparse 3D Data:}
In recent years, there is an increasing need for techniques that efficiently
process 3D data, with the onset of cheaper 3D scanners and the consumer devices
that requires processing 3D data (e.g.~virtual reality devices such as Oculus Rift~\cite{oculus}).
One of the distinguishing characters of high-dimensional data such as 3D point clouds
or videos is that they are sparse. 3D point clouds are inherently sparse and the sparsity
of video data comes from the redundant representation across frames.
Learnable bilateral filters proposed in this thesis
(Chapter~\ref{chap:bnn}), provide a principled way to process sparse high-dimensional
data by enabling long-range data dependent connections. This thesis work also demonstrated
that one could easily integrate these sparse high-dimensional filters into other
CNN architectures and are also shown to be fruitful for video processing (Chapter~\ref{chap:vpn}).
I hope this thesis work inspires future research work for efficiently processing
3D data such as point clouds or meshes. Since the convolutions are performed in
bilateral space with sparsely populated cells, there is no need to voxelize a given
point cloud or meshes for doing 3D convolutions.
One of the limitations of bilateral neural networks
is that the bilateral feature scales are hand-­tuned.
There are other recent works such as~\cite{krahenbuhl2013parameter,kundu2016feature}
trying to optimize feature spaces for bilateral filtering but are not integrated into CNN frameworks.
An interesting future research direction is to bring these works together by learning feature spaces
for bilateral neural networks in an end-­to-­end fashion.

\vspace{-0.2cm}
\paragraph{Structured CNNs:} A​lthough images are represented with independent pixel values,
real­ world is highly structured and prior knowledge therein can be captured by rich
modeling tools like graphical models. For example, in the case of urban scene
understanding, one could leverage the prior knowledge that objects like cars and persons
stand on the ground plane; building facades are vertical etc. Most of the existing CNN
frameworks are agnostic to such explicit prior information. One may argue that the CNNs
are capable of implicitly learning such prior knowledge directly from the training data.
But, in practice, the amount of labelled training data is always limited and thus CNNs
need external prior constraints to be able to perform well on several real­ world problems
especially when the training data is very limited. In this thesis, we developed techniques
for incorporating prior knowledge into CNNs via learnable bilateral filters. Such prior
knowledge is low-level and, ideally I would like to have techniques for integrating
high-level prior knowledge (e.g., the prior knowledge that is encoded in
graphical models). Other existing works in this direction
(e.g.~\cite{jain2015structural,zheng2015conditional,tompson2014joint,chandra2016fast})
are also either limited in the type of prior knowledge they model and/or graphical
model constraints are generally enforced after the main CNN structure.
I believe that a fruitful direction to tackle this problem is developing structured
filters that can be easily integrated into CNN frameworks. The work presented in
this thesis make important steps in this direction.

\vspace{-0.2cm}
\paragraph{On Combining Generative and Discriminative Models:} Hybrid generative
and discriminative models are an active area of research and I believe that the
future of computer vision would be dominated by such hybrid models which are
scalable and generic to be applicable to a wide range of problem scenarios.
In Section~\ref{sec:gen-disc-comb}, we discussed several recent works that aim
to develop such hybrid models. Several inference techniques presented in this
thesis are based on the synergistic combinations of generative and discriminative
models. I hope that this thesis work inspires or aids in the further development
of hybrid generative and discriminative vision models.

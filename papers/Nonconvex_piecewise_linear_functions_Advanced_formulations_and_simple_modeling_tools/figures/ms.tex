% ----------------------------------------------------------------
% AMS-LaTeX Paper ************************************************
% **** -----------------------------------------------------------
% ----------------------------------------------------------------
% AMS-LaTeX Paper ************************************************
% **** -----------------------------------------------------------
\documentclass[mnsc]{informs3}  


\usepackage{natbib}
 \bibpunct[, ]{(}{)}{,}{a}{}{,}%
 \def\bibfont{\small}%
 \def\bibsep{\smallskipamount}%
 \def\bibhang{24pt}%
 \def\newblock{\ }%
 \def\BIBand{and}%

%% Hyperref setup
\usepackage[colorlinks=true,breaklinks=true,bookmarks=true,urlcolor=blue,
     citecolor=blue,linkcolor=blue,bookmarksopen=false,draft=false]{hyperref}

\def\EMAIL#1{\href{mailto:#1}{#1}}% When hyperref is used, otherwise outcomment 
\def\URL#1{\href{#1}{#1}}         % When hyperref is used, otherwise outcomment 

%% Setup of theorem styles. Outcomment only one. 
%% Preferred default is the first option.
\TheoremsNumberedThrough     % Preferred (Theorem 1, Lemma 1, Theorem 2)
%\TheoremsNumberedByChapter  % (Theorem 1.1, Lema 1.1, Theorem 1.2)

%% Setup of the equation numbering system. Outcomment only one.
%% Preferred default is the first option.
\EquationsNumberedThrough    % Default: (1), (2), ...
%\EquationsNumberedBySection % (1.1), (1.2), ...

% In the reviewing and copyediting stage enter the manuscript number.
%\MANUSCRIPTNO{} % When the article is logged in and DOI assigned to it,
                 %   this manuscript number is no longer necessary

\usepackage{thmtools,thm-restate}
%\usepackage{pstricks}
\usepackage{url}
%\usepackage{times}
%\usepackage[colorlinks=true,linkcolor=red]{hyperref}
\usepackage[verbose]{wrapfig}
\usepackage{blindtext}
\usepackage{rotating}
\usepackage{enumerate}
\usepackage{amsmath}
%\usepackage{amsthm}
\usepackage{float}
%\usepackage{fullpage}
\usepackage{verbatim}
\usepackage{amssymb}
\usepackage{color}
\usepackage{bbm}
\usepackage[TABBOTCAP]{subfigure}
\usepackage{tikz}
\usetikzlibrary{shapes}
\usetikzlibrary{arrows}
\usetikzlibrary{topaths}
\usepackage{stmaryrd}
%\usepackage[margins]{trackchanges}
%\renewcommand{\initialsOne}{jpv}
%\normalem
\usepackage{pdfsync}
\usepackage{graphicx}
%\usepackage{longtable}
%\newtheorem{proposition}{Proposition}
%\newtheorem{theorem}[proposition]{Theorem}
%\newtheorem{lemma}[proposition]{Lemma}
%\newtheorem{definition}[proposition]{Definition}
%\newtheorem{corollary}[proposition]{Corollary}
%\newtheorem{example}{Example}
%\newtheorem{question}{Question}
%\newtheorem{assumption}{Assumption}
%\newtheorem{observation}{Observation}
\newcommand{\set}[1]{\left\{#1\right\}}                     % Set operator
\newcommand{\abs}[1]{\left|#1\right|}                       % Absolute value
\newcommand{\Pow}[1]{{\cal P}\left(#1\right)}               % Power set
\newcommand{\bra}[1]{\left(#1\right)}     
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\sidx}[1]{\left\llbracket     #1 \right\rrbracket}  

%\newtheorem{Cor}{Corollary}
\newcommand{\Real}{\mathbb R}
\newcommand{\e}{\mathbf{e}}
\newcommand{\red}[1]{{\color{red}#1}}
\newcommand{\white}[1]{{\color{white}#1}}
\newcommand{\Int}{\mathbb Z}
\newcommand{\One}{\mathbb 1}
\newcommand{\trans}[1]{{#1}^{\ensuremath{\top}}}
\newcommand{\Restric}[1]{|_{#1}}
\DeclareMathOperator{\rc}{rc}
\DeclareMathOperator{\xrc}{xrc}
\DeclareMathOperator{\xc}{xc}
\DeclareMathOperator{\xmc}{xmc}
\DeclareMathOperator{\fxc}{fxc}
\DeclareMathOperator{\ixc}{ixc}
\DeclareMathOperator{\hc}{hc}
\DeclareMathOperator{\size}{size}
\DeclareMathOperator{\mmc}{mc}
\DeclareMathOperator{\kc}{kc}
\DeclareMathOperator{\rmc}{rmc}
\DeclareMathOperator{\supp}{supp}
\DeclareMathOperator{\proj}{proj}
\DeclareMathOperator{\conv}{conv}
\DeclareMathOperator{\ext}{ext}
\DeclareMathOperator{\ray}{ray}
\DeclareMathOperator{\convenv}{convenv}
\DeclareMathOperator{\cone}{cone}
\DeclareMathOperator{\aff}{aff}
\DeclareMathOperator{\spann}{span}
\DeclareMathOperator{\cl}{cl}
\DeclareMathOperator{\zconv}{zconv}
\DeclareMathOperator{\interior}{int}
\DeclareMathOperator{\gr}{gr}
\DeclareMathOperator{\epi}{epi}
\DeclareMathOperator{\ri}{ri}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\sym}{Sym}
%\renewcommand{\thefootnote}{\fnsymbol{footnote}}
\usepackage[symbol*]{footmisc}
%\DefineFNsymbols*{mylamport}{\dagger\ddagger\S\P\|{\dagger\dagger}{\ddagger\ddagger}{\S}{\P\P}{\dagger\dagger\dagger}{\ddagger\ddagger\ddagger}{\S}{\P\P\P}}
\DefineFNsymbolsTM*{mylamport*}{%
  \textdagger    \dagger
  \textdaggerdbl \ddagger
  \textsection   \mathsection
  \textparagraph \mathparagraph
  \textbardbl    \|%
  {\textdagger\textdagger}{\dagger\dagger}%
  {\textdaggerdbl\textdaggerdbl}{\ddagger\ddagger}%
  {\textsection\textsection}{\mathsection\mathsection}%
  {\textparagraph\textparagraph}{\mathparagraph\mathparagraph}%
  {\textdagger\textdagger\textdagger}{\dagger\dagger\dagger}%
  {\textdaggerdbl\textdaggerdbl\textdaggerdbl}{\ddagger\ddagger\ddagger}%
  {\textsection\textsection\textsection}%%
    {\mathsection\mathsection\mathsection}%
  {\textparagraph\textparagraph\textparagraph}%%
    {\mathparagraph\mathparagraph\mathparagraph}%
}
\setfnsymbol{mylamport*}
%\usepackage{float}
\begin{document}

\TITLE{Embedding Formulations and Complexity for Unions of Polyhedra}
\ARTICLEAUTHORS{%
\AUTHOR{Juan Pablo Vielma}
\AFF{Sloan School of Management, Massachusetts Institute of Technology, \EMAIL{jvielma@mit.edu}}
% Enter all authors
} % end of the block

\ABSTRACT{%

It is well known that selecting a good Mixed Integer Programming (MIP) formulation is crucial for an effective solution with state-of-the art solvers. While best practices and guidelines for constructing good formulations abound, there is rarely a systematic construction leading to the best possible formulation. We introduce embedding formulations and complexity as a new MIP formulation paradigm for systematically constructing formulations for disjunctive constraints that are optimal with respect to size. More specifically, they yield the smallest possible ideal formulation (i.e. one whose LP relaxation has integral extreme points) among all formulations that only use 0-1 auxiliary variables. We use the paradigm to characterize optimal formulations for SOS2 constraints and certain piecewise linear functions of two variables. We also show that the resulting formulations can provide a significant computational advantage over all known formulations for piecewise linear functions (up to 70 times speed improvement for the harder instances).


%We introduce embedding formulations as a new mixed integer programming formulation paradigm for disjunctive constraints. This paradigm is based on a geometric construction that includes a flexible use of 0-1 integer variables and always yields an ideal formulation. We use the paradigm to generalize the highly successful logarithmic formulation introduced by Vielma and Nemhauser (2010) and expand its computational effectiveness to a wider range of problems. In particular, we show that the generalization can provide a significant computational advantage over all known formulations for piecewise linear functions. We also show that embedding formulations can be highly sensitive to the specific use of 0-1 integer variables. For this reason, we study the size of the smallest possible embedding formulation, which we denote the embedding complexity. By studying this complexity, we prove size-optimality of the logarithmic formulation for SOS2 constraints and certain piecewise linear functions of two variables.  

 

%One desirable property for a Mixed Integer Programming (MIP) formulations is for its Linear Programming (LP) relaxation to have extreme points that comply
%Mixed integer programming formulations for unions of polyhedra can be divided into extended formulations that use both 0-1 and continuous auxiliary variables, and non-extended formulations that only use the 0-1 variables that are strictly necessary for a valid formulation. Standard extended formulations are small and ideal (their LP relaxations have integral extreme points). In contrast, small non-extended formulations are usually not ideal. However, a flexible use of the 0-1 variables can lead to non-extended formulations that are ideal, small and provide a significant computation advantage. In this paper we attempt to explain and expand the success of such formulations through a geometric characterization, which provides a systematic procedure to construct ideal formulations. The characterization yields two formulation complexity measures: the size of the smallest ideal and non-ideal non-extended formulations. We provide (nearly) matching upper and lower bounds for these measures for various unions of practical interest. In particular, for SOS2 constraints we show (near) optimality of an existing ideal formulation and introduce a non-ideal formulation that only uses a constant number of general inequalities. Finally, we consider how adding redundancy can simplify the construction of ideal formulations and compare the formulation complexity measures to other complexity notions.  

% Mixed integer programming formulations for unions of polyhedra or (polyhedral) disjunctive constraints can be divided into extended formulations that use both 0-1 and continuous auxiliary variables, and non-extended formulations that only use the 0-1 variables that are strictly necessary to construct a valid formulation. Standard extended formulations have sizes that are linear on the sizes of the polyhedra and have linear programming relaxations with extreme points that naturally satisfy the appropriate integrality constraints (such formulations are usually denoted ideal and are as strong as possible). In contrast, for non-extended formulation there usually is an important trade-off between strength and size. However, a flexible use of the 0-1 variables that signal the selection among the polyhedra can lead to non-extended formulations that are ideal and smaller than the best extended alternative. Furthermore, these formulations have been shown to provide a significant computation advantage. This paper attempts to explain and expand the success of such formulations by introducing a geometric characterization of them. This characterization is based on an embedding of the polyhedra in a higher dimensional space and provides a systematic procedure to construct ideal formulations. Furthermore, the characterization naturally leads to two notions of formulation complexity for unions of polyhedra: 1) the size of the smallest non-extended formulation, and 2) the size of the smallest ideal non-extended formulations. We analyze such measures for various disjunctions of practical interest by providing (nearly) matching upper and lower bounds, with special emphasis on the number of general inequalities (i.e. those that are not variable bounds). In particular, when analyzing Special Order Sets of type 2 (SOS2) we show optimality with respect to the number of general inequalities of an existing ideal formulation and introduce a non-ideal formulation that only uses a constant number of of general inequalities. Finally, we consider how adding redundancy to the disjunction can simplify the construction of ideal formulations and compare the formulation complexity measures to other complexity notions such as the size of the convex hull of the union of the polyhedra and the extension complexity of this convex hull.  


% In this paper we introducd a geometric characterization of Mixed Integer Programming (MIP) formulations for unions of polyhedra that 1) do not use auxiliary variables other than the 0-1 variables strictly needed to construct a valid formulation, and 2) 

% We consider a systematic procedure to construct small, but strong Mixed Integer Programming (MIP) formulations for unions of polyhedra. A key of the procedure is the flexible use of 0-1 variables that signal the selection among the polyhedra. This flexibility is achieved by considering several possible embeddings of the polyhedra in a higher dimensional space. An important characteristic of these formulations is that they do not use auxiliary variables other than the 0-1 variables strictly needed to construct a formulation (in contrast to extended formulations, which are allowed to use any number of auxiliary variables). Nonetheless, the formulations obtained through this procedure can be smaller that the smallest known alternative formulation (extended or not). Furthermore, the Linear Programming (LP) relaxation of these formulations often have extreme points that naturally satisfy the appropriate integrality constraints (such formulations are usually denoted ideal). 
 
% The proposed systematic procedure is based on a geometric characterization of a formulation that naturally leads to two notions of complexity for unions of polyhedra: 1) the size of the smallest non-extended formulation, and 2) the size of the smallest ideal non-extended formulations. We give upper and lower bounds for these complexity measures for several classes of polyhedra. We also study how the embedding selection affects the sizes of the associated formulations. Finally, we compare these measures to other complexity notions such as the size of the convex hull of the union of the polyhedra and the extension complexity of this convex hull.  
}%

% Sample
%\KEYWORDS{deterministic inventory theory; infinite linear programming duality; 
%  existence of optimal policies; semi-Markov decision process; cyclic schedule}
%\MSCCLASS{Primary: 90B05; secondary: 90C40, 90C90}
%\ORMSCLASS{Primary: Inventory/production: deterministic multi-item;
%  secondary: dynamic programming/optimal control: deterministic 
%  semi-Markov; programming: infinite dimensional}
%\HISTORY{Received November 20, 2003; revised March 8, 2004, and March 26, 2004.}

% Fill in data. If unknown, outcomment the field
\KEYWORDS{}
\MSCCLASS{}
\ORMSCLASS{Primary: ; secondary: }
\HISTORY{June 2nd, 2015}

\maketitle


\section{Introduction}




% In this talk we show how alternate uses of integer variables can lead to small integral formulations that do not use continuous auxiliary variables. For this we introduce the following generic class of MIP formulations for   \eqref{jpvDisj}.

% We consider a systematic procedure to construct small but strong Mixed Integer Programming (MIP) formulations for unions of polyhedra. A key of the procedure is the flexible use of 0-1 variables that signal the selection among the polyhedra. This flexibility is achieved by considering several possible embeddings of the polyhedra in a higher dimensional space. An important characteristic of these formulations is that they do not use auxiliary variables other than the 0-1 variables strictly needed to construct a formulation (in contrast to “extended” formulations, which are allowed to use any number of auxiliary variables). Nonetheless, the formulations obtained through this embedding procedure can be smaller that the smallest known alternative formulation (extended or not). Furthermore, the Linear Programming (LP) relaxation of these formulations often have extreme points that naturally satisfy the appropriate integrality constraints (such formulations are usually denoted “ideal”). These characteristics allow some versions of these formulations to provide a significant computational advantage over alternative formulations. 
 
% The embedding formulation approach leads to two notions of complexity for unions of polyhedra: 1) the size of the smallest non-extended formulation, and 2) the size of the smallest ideal non-extended formulations. We give upper and lower bounds for these complexity measures for several clases of polyhedra. We also study how the embedding selection affects the sizes of the associated formulations. Finally, we compare these measures to other complexity notions such as the size of the convex hull of the union of the polyhedra and the extension complexity of this convex hull.  
 



% We have introduced  a geometric procedure to construct formulations for unions of polyhedra that do not use auxiliary variables beyond the ones strictly necessary to construct a valid formulation. The construction is obtained by lifting the polyhedra and embedding them in a higher dimensional space and is a natural analog 
% to the construction of IP formulations for discrete sets. The construction yields a formal definition of any formulation without auxiliary variables and yields a precise geometric characterization of the strongest possible formulation, which is usually denoted ideal. The resulting formulation is potentially large, but we have shown that 

% embedding 
% The only auxiliary variables used by the formulation in Definition~\ref{formdef} are the  $0$-$1$ variables that are strictly necessary to construct a valid formulations. Such formulations are sometimes denoted \emph{projected formulations} (e.g. \cite[Section~6]{Mixed-Integer-Linear-Programming-Formulation-Techniques}).

% One systematic way to construct ideal formulations for unions of polyhedra is given in the following definition.

% Both the size of an arbitrary formulation and the size of an embedding formulation lead to a natural complexity measure for unions of polyhedra. 

In its more than 50 years of history  Mixed Integer Programming (MIP) has become an indispensable tool in Operations Research and Management Science. Enormous strides have been made  in the theoretical and  computational issues arising in solving  MIP problems and commercial  MIP solvers  can  solve a wide range of problems  \citep{50book}. One of the reasons for the success of  MIP is its modeling flexibility. For instance, 0-1 MIP can be used to model disjunctive constraints (i.e. the selection over a finite number of alternatives) appearing in a wide range of applications in transportation \citep{croxton2003comparison,roberti2014fixed}, telecommunication \citep{d2013gub} and scheduling \citep{manne1960job,pinedo2012scheduling}. Formulating problems using MIP is often straightforward. However, as most textbooks warn, some care should be taken in constructing MIP formulations as some formulation attributes can severely affect the effectiveness of solvers. Good formulations can be obtained following simple guidelines, but more elaborate techniques can provide a significant computational advantage \citep{Mixed-Integer-Linear-Programming-Formulation-Techniques}. For instance, consider the classical \emph{Special Ordered Sets of Type 2 (SOS2)} introduced by  \cite{Beale70}. SOS2 constraints on variables $\lambda\in \mathbb{R}^{n+1}$ require that (1) $\sum\nolimits_{i=1}^{n+1} \lambda_i=1$ and $\lambda_i\geq 0$ for all $i\in \set{1,\ldots,n+1}$, and (2) at most two $\lambda_i$ variables can be non-zero at the same time and
if $\lambda_i>0$ and $\lambda_j>0$, then they must be adjacent variables (i.e. $\abs{i-j}=1$). A textbook formulation for SOS2 constraints for $n=4$ is given by 
\begin{subequations}\label{CC1d}
\begin{alignat}{3}
\sum\nolimits_{i=1}^5 \lambda_i=1,\quad \lambda_i \geq 0 \quad \forall i\in \set{1,\ldots,5}, \quad\sum\nolimits_{i=1}^4 y_i=1,\quad y\in \set{0,1}^4\\
\lambda_1 \leq y_1,\quad \lambda_2\leq y_1+y_2,\quad \lambda_3 \leq y_2+y_3,\quad \lambda_4\leq y_3+y_4,\quad \lambda_5\leq y_4.\label{CC1dg}
\end{alignat}
\end{subequations}
To evaluate this formulation we consider two formulation attributes: formulation size and strength. For size we use the standard measure corresponding to the smallest number of linear inequalities needed to describe the formulation, ignoring equations and number of variables (as noted in \cite{Kaibel11} equations can be easily eliminated and variables do not add anything if not accompanied by inequalities). For strength we check if the Linear Programming (LP) relaxation of the formulation has extreme points or basic feasible solutions with fractional $y$ variables that always satisfy the integrality constraints. Formulations that satisfy this condition are often denoted \emph{ideal} and are expected to outperform similarly sized non-ideal formulations. Formulation \eqref{CC1d} fares well with regards to size, as its version for general $n$ only requires $2n+2$ inequalities. However, this small size comes at the cost of the formulation not being ideal. Fortunately, \cite{padberg00} showed how to strengthen \eqref{CC1d} to an ideal formulation without increasing the number of inequalities. For $n=4$ the resulting formulation is given by 
\begin{subequations}\label{CC1dstrong}
\begin{alignat}{3}
\sum\nolimits_{i=1}^5 \lambda_i=1,\quad \lambda_1\geq 0,\quad\lambda_5 \geq 0, \quad\sum\nolimits_{i=1}^4 y_i=1,\quad y\in \set{0,1}^4\\
\lambda_1\leq y_1\leq \lambda_1+\lambda_2\leq y_1+y_2\leq \lambda_1+\lambda_2+\lambda_3\leq y_1+y_2+y_3\leq \lambda_1+\lambda_2+\lambda_3+\lambda_4.\label{CC1dstrongg}
\end{alignat}
\end{subequations}
While both formulations have the same size, the majority of the inequalities of \eqref{CC1dstrong} correspond to general inequalities \eqref{CC1dstrongg}, which are not just variable bounds. In contrast, only half the inequalities of \eqref{CC1d} are general inequalities (see Table~\ref{formsizetable} for details). General inequalities usually have a stronger computational impact than variable bounds as the later can be treated implicitly by LP and MIP solvers. Hence the larger number of general inequalities of  \eqref{CC1dstrong} can cancel its advantage from being ideal and indeed it is often  computationally outperformed by non-ideal formulation \eqref{CC1d}. A solution to this issue can be found in an advanced  formulation technique introduced by  \cite{Modeling-Disjunctive-Constraints-FULL}. For $n=4$ this technique yields the formulation for SOS2 given by
\begin{subequations}\label{LogCC1dstrong}
\begin{alignat}{3}
\sum\nolimits_{i=1}^5 \lambda_i=1,\quad \lambda_i \geq 0 \quad \forall i\in \set{1,\ldots,5}, \quad y\in \set{0,1}^2\\
\lambda_1+\lambda_5\leq  1-y_1,\quad \lambda_3\leq y_1,\quad \lambda_4+\lambda_5\leq 1-y_2,\quad \lambda_1+\lambda_2\leq y_2.
\end{alignat}
\end{subequations}
This formulation is also ideal, but its version for general $n$ only requires  $2\lceil \log_2 n\rceil+n$ and only $2\lceil \log_2 n\rceil$ of these are general inequalities. This allows formulation \eqref{LogCC1dstrong} to have a significant computational advantage over \eqref{CC1d}, \eqref{CC1dstrong} and all known formulations for SOS2 \citep{Mixed-Integer-Models-for-Nonseparable,Modeling-Disjunctive-Constraints-FULL}.  An even more dramatic issue arises if we consider a 2-dimensional generalization of SOS2 constraints used to model piecewise linear functions of two variables \citep{lee01,Mixed-Integer-Models-for-Nonseparable}. As detailed in Table~\ref{formsizetable}, the cost of going from the non-ideal 2-dimensional generalization of  \eqref{CC1d} to the ideal 2-dimensional generalization of \eqref{CC1dstrong} is a significant increase in the number of inequalities, particularly general inequalities. However, the 2-dimensional generalization of formulation \eqref{LogCC1dstrong} still has a linear number of inequalities and a logarithmic number of general inequalities. This again gives it a significant computational advantage over all known formulations for piecewise linear functions of two variables \citep{Mixed-Integer-Models-for-Nonseparable,Modeling-Disjunctive-Constraints-FULL}.
\begin{table}[htpb]
\begin{center}
\bgroup
\def\arraystretch{2}%
\begin{tabular}{c|ll|ll}
& \multicolumn{2} {l|}{Traditional SOS2}& \multicolumn{2} {l}{2-D Generalization}\\
Formulation & General Inequalities &Bounds& General Inequalities &Bounds\\
\hline
\eqref{CC1d}& $n+1$ &$n+1$ & $\bra{\sqrt{n/2}+1}^2$ & $\bra{\sqrt{n/2}+1}^2$\\[2ex]
\eqref{CC1dstrong}& $2n$ &$2$& $\dbinom{2\sqrt{n/2}}{\sqrt{n/2}}$ & $\bra{\sqrt{n/2}+1}^2$\\[2ex]
\eqref{LogCC1dstrong} & $2\lceil \log_2 n\rceil$ &$n$& $4 \left\lceil \log_2 \sqrt{n/2}\right\rceil+ 2$ & $\bra{\sqrt{n/2}+1}^2$\\
\end{tabular}
\egroup
  \end{center}
\caption{Sizes of Formulations for SOS2 Constraints and its 2-dimensional Generalization.}\label{formsizetable}
\end{table}
 
The only dissadvantage of formulation \eqref{LogCC1dstrong} is its increase in complexity. In particular, while for formulations \eqref{CC1d} and  \eqref{CC1dstrong} we can easily interpret the role of the $0$-$1$ variables ($y_i=1$ if and only if $\lambda_i$ and $\lambda_{i+1}$ can be non-zero at the same time), the role of the $0$-$1$ variables is not so clear for \eqref{LogCC1dstrong} (for instance it uses two $0$-$1$ variables instead of four). This increase in complexity makes it hard to generalize \eqref{LogCC1dstrong} to other constraints. In fact, the 2-dimensional generalization of  \eqref{LogCC1dstrong} only works for very specific piecewise linear functions, while the 2-dimensional generalizations of \eqref{CC1d} and \eqref{CC1dstrong} work for a wide range of piecewise linear functions. 


In this paper we propose a new MIP formulation paradigm that should allow extending the success of formulation \eqref{LogCC1dstrong} to a wide range of applications. In particular, this paradigm can construct ideal formulations for any disjunctive constraint that requires a set of variables to be in the union of a finite number of polyhedra with mild technical requirements. We denote the formulations obtained through this paradigm \emph{embedding formulations} as they are based on a geometric construction that \emph{embeds} the disjunctive constraints onto a higher dimensional space that contains both the original variables in the constraint (e.g. the $\lambda$ variables for SOS2 constraints) and the $0$-$1$ variables of the formulation (e.g. the $y$ variables). One characteristic of embedding formulations is allowing a flexible use of $0$-$1$ variables that include both traditional uses such as in \eqref{CC1d} and  \eqref{CC1dstrong},  and more complex uses such as in \eqref{LogCC1dstrong}. This flexibility is the key to replicating the success of \eqref{LogCC1dstrong} as we show that the size of an embedding formulations can be extremely sensitive to the specific use of $0$-$1$ variables. For this reason we also study the  size of the smallest embedding formulation for a disjunctive constraint when we consider all possible uses of $0$-$1$ variables. We denote this the embedding complexity of the associated union of polyhedra. 
This complexity measure has theoretical interest on its own, but can also be used to evaluate the potential for improvement of existing formulations. For instance, studying this complexity allows us to show that \eqref{LogCC1dstrong} and its 2-dimensional generalization are (nearly) optimal with regard to size. To the best of our knowledge, these results are the first lower bounds on sizes of MIP formulations. Finally, we show how the embedding formulation paradigm can be used to generalize the 2-dimensional version of \eqref{LogCC1dstrong} to a wider range of piecewise linear functions than what was considered in  \cite{Modeling-Disjunctive-Constraints-FULL}. We also show how the resulting formulations can significantly outperform all other known formulations for piecewise linear functions of two variables. This generalization is based on two embedding formulation techniques. One technique is based on the computational calculation of a convex hull associated to the embedding formulation. To the best of our knowledge, this is the first example of a computational construction of an effective MIP formulation. The other technique yields a simple recipe for constructing formulations by relating embedding formulations with another class of formulations introduced in \cite{Modeling-Disjunctive-Constraints-FULL} and exploiting a redundant description of a disjunctive constraints. 

Throughout  the paper we use the following notation. For a set $S\subseteq \Real^d$ we let $\conv\bra{S}$, $\aff\bra{S}$, $\spann\bra{S}$ and $\dim\bra{S}$ be the convex hull, affine hull, linear span and the dimension of $S$ respectively. For a polyhedron $P\subseteq \Real^d$ we let $\ext\bra{P}$ and $\ray\bra{P}$ be the set of extreme points and extreme rays of $P$. We also let $P_\infty$ be the recession cone of $P$. Given two vectors $a, b\in \Real^V$ for a finite index set $V$ we let $a\cdot b=\sum\nolimits_{v\in V} a_v b_v$ be the inner product between $a$ and $b$. We also let ${\bf 0}\in \Real^V$ be the vector of all zeros and  $\e^v\in \Real^V$ be the unit vector such that $\e^v_u=1$ if $u=v$ and $\e^v_u=0$ otherwise. Finally, we let $\sidx{n}:=\set{1,\ldots,n}$, $\sidx{a,b}:=\set{a,a+1,\ldots, b-1,b}$ and $\mathbb{Q}$ be the set of rational numbers. 


\section{Geometric Construction of Formulations}\label{formulationsec}

We consider MIP formulations for the disjunctive constraint \begin{equation}\label{disjunction}
x\in \bigcup\nolimits_{i=1}^n P^i
\end{equation}
where $\mathcal{P}:=\set{P^i}_{i=1}^n$ is a finite family of polyhedra in $\Real^d$ that satisfy the following assumption.
\begin{assumption}\label{ass1}The family of polyhedra $\mathcal{P}:=\set{P^i}_{i=1}^n$ is such that  $P^i$ is a rational polyhedron and $\ext\bra{P^i}\neq \emptyset$ for all $i\in \sidx{n}$, and 
 $P^i_\infty=P^j_\infty$ for all $i,j\in \sidx{n}$.
\end{assumption}
Disjunctive constraint \eqref{disjunction} is exactly the type of practical\footnote{We can also consider unions of polyhedra without extreme points, but this is uncommon in practice.} constraints that can be modeled using $0$-$1$ MIP \citep{springerlink:10.1007/BFb0121015} and MIP formulations for it can be constructed using a wide range of techniques \citep{Mixed-Integer-Linear-Programming-Formulation-Techniques}.
For instance, if the polyhedra are described by linear inequalities, the following result from \cite{springerlink:10.1007/BFb0121015,balas85} gives an ideal and small formulation for \eqref{disjunction}. 
\begin{theorem}\label{BTheo}  Let $\mathcal{P}:=\set{P^i}_{i=1}^n$ be a finite family of polyhedra in $\Real^d$ satisfying Assumption~\ref{ass1}. Furthermore, for each $i\in\sidx{n}$, let $A^i\in \mathbb{Q}^{m_i\times d}$ and $b^i\in \mathbb{Q}^{m_i}$ be such that $P^i=\set{x\in \Real^d\,:\, A^i x\leq b^i}$. Then an ideal formulation of \eqref{disjunction} is given by 
\begin{alignat}{3}\label{BalasForm}
A^i x^i\leq b^i y_i\quad\forall i\in \sidx{n},\quad x=\sum\nolimits_{i=1}^n x^i,\quad \sum\nolimits_{i=1}^n y_i=1,\quad y\in \set{0,1}^n.
\end{alignat}
\end{theorem}
Formulation \eqref{BalasForm} achieves the feat of being ideal and small through the use of continuous auxiliary variables $x^i\in \Real^d$, which copy the original variables $x$ for each polyhedron. However, these continuous auxiliary variables can take away the potential computational advantage of \eqref{BalasForm}, particularly when small and ideal formulations without the continuous auxiliary variables are available (e.g. formulation \eqref{LogCC1dstrong} for SOS2 constraints). Unfortunately, there is no known general  formulation for disjunctive constraints that is small, ideal and  does not use these continuous auxiliary variables. To remedy this, we  present a general geometric construction for formulations without continuous auxiliary variables that is always ideal and can sometimes yield small formulations. We motivate this construction as an extension of a natural technique in combinatorial optimization, which also highlights the need to include some $0$-$1$ auxiliary variables $y$ in any MIP formulation of \eqref{disjunction}.

We can recover combinatorial optimization problems as a special case of \eqref{disjunction} when each polyhedron $P^i$ corresponds to a single element of $\set{0,1}^d$ (i.e. when $P^i=\set{v^i}$ with $v^i\in \set{0,1}^d$ for all $i$). In this case an ideal MIP formulation for \eqref{disjunction} is given by $x\in \conv\bra{\bigcup_{i=1}^n P^i}$ and $x\in \mathbb{Z}^d$, as $\conv\bra{\bigcup_{i=1}^n P^i}$ is guaranteed to be a rational polyhedron. Of course, constructing a description of $\conv\bra{\bigcup_{i=1}^n P^i}$ can be extremely complex and may require a number of inequalities that is exponential in $d$, even if $n$ is linear in $d$. In addition, $n$ is often exponential in $d$ for combinatorial optimization problems. However, studying this convex hull is the basis of extremely successful polyhedral approaches to tractable combinatorial optimization problems \citep{schrijver-bookCOMB}. Furthermore, as illustrated in the following example, this approach can be used to construct formulations for intractable constraints by combining ideal formulations for tractable sub-structures of the constraint. Of course, combining such ideal formulations yields a non-ideal formulations, but the formulations resulting from this combination can often remain computationally effective. 

\begin{example} Let $S_1=\set{(0,0)}\cup \set{(0,1)}\cup \set{(1,0)}$ and $S_2=\set{(0,0)}\cup \set{(0,1)}\cup \set{(1,1)}$. As depicted in Figure~\ref{combinatorialex}, $S_i=\conv\bra{S_i}\cap \mathbb{Z}^2$ for each $i$. Furthermore, while $\conv\bra{S_1\cap S_2}\neq \conv\bra{S_1}\cap\conv\bra{S_2}$ we do have $S_1\cap S_1=\conv\bra{S_1}\cap \conv\bra{S_2}\cap\mathbb{Z}^2$. However, while $\ext\bra{\conv\bra{S_i}}\subseteq \mathbb{Z}^2$ for each $i$, $\conv\bra{S_1}\cap\conv\bra{S_2}$ has one fractional extreme point.
\end{example}
  \begin{figure}[htpb]
  \begin{center}
  \subfigure[Sets $S_1$ and $\conv\bra{S_1}$ on top left,  $S_2$ and $\conv\bra{S_2}$ on bottom left, and $S_1\cap S_2$ and $\conv\bra{S_1}\cap\conv\bra{S_2}$ on right.]{\includegraphics[scale=0.3]{combining_formulations2b.pdf}\label{combinatorialex}}\quad\quad\quad 
    \subfigure[Sets $S_3$ and $\conv\bra{S_3}$ on top left,  $S_4$ and $\conv\bra{S_4}$ on bottom left, and $S_3\cap S_4$ and $\conv\bra{S_3}\cap\conv\bra{S_4}$ on right.]{\includegraphics[scale=0.3]{combining_formulations1b.pdf}\label{noncombinatorialex}}
  \end{center}
  \caption{Unions of polyhedra (depicted in red) and their convex hulls (depicted in light blue).}\label{complexityfig}
  \end{figure}

For more general polyhedra $P^i$ we may no longer have $\bigcup_{i=1}^n P^i=\conv\bra{\bigcup_{i=1}^n P^i}\cap \mathbb{Z}^d$. However, if we want to maximize a linear function over one disjunctive constraint the convex hull construction is usefull as $\max\set{c\cdot x\,:\, x\in \bigcup_{i=1}^n P^i}=\max\set{c\cdot x\,:\, x\in \conv\bra{\bigcup_{i=1}^n P^i}}$. Unfortunately, as illustrated in the following example, this no longer holds when we consider multiple disjunctive constraints. 
\begin{example}\label{examplemax} Let $S_3=\set{x\in \Real^2\,:\, 0\leq x_1\leq 1,\;x_2=0}\cup \set{x\in \Real^2\,:\, 0\leq x_2\leq 1,\;x_1=0}$ and $S_4=\set{x\in \Real^2\,:\, 0\leq x_1\leq 1,\;x_2=0}\cup \set{x\in \Real^2\,:\, 0\leq x_2\leq 1,\;x_1=1}$. These sets and their convex hulls are depicted in Figure~\ref{noncombinatorialex}. We can check that $\max\set{x_2\,:\, x\in S_l}=\max\set{x_2\,:\, x\in \conv\bra{S_l}}=1$ for $l\in \set{3,4}$. However, $0=\max\set{x_2\,:\, x\in S_3\cap S_4}<\max\set{x_2\,:\, x\in \conv\bra{S_3}\cap \conv\bra{S_4}}=1/2$.
\end{example}

One way to resolve the issue in Example~\ref{examplemax} is to intersect the disjunctive constraints before taking the convex hull. In Example~\ref{examplemax} this results in a single polyhedron, but in general can result in a disjunctive constraint with a number of polyhedra that is significantly larger than those of the original constraints (intersecting $k$ disjunctive constraints with $n$ polyhedra each can result in a disjunctive constraint with $n^k$ polyhedra). An alternative is to include $0$-$1$ auxiliary variables to construct a MIP formulation for the disjunctions. We can do this through general formulations such as \eqref{BalasForm} or through ad-hoc formulations. However, we instead propose to achieve it through a geometric construction that combines the convex hull construction with an embedding of the polyhedra into a space that includes the original $x$ variables and some $0$-$1$ variables $y$. This construction is depicted  in Figure~\ref{embeddingillust} for the polyhedra $P^1$ and $P^2$ in the left of the figure. The procedure first embeds the polyhedra into a space that contains an additional $0$-$1$ variable $y_1$ by converting the disjunction from $S:=P^1\cup P^2$ to  $S^+:=\bra{P^1\times \set{1}} \cup \bra{P^2\times \set{0}}$. While for the original polyhedron we do not expect to have $S=\conv(S)\cap \mathbb{Z}^2$ for the embedding we do  have $S^+=\conv\bra{S^+}\cap \bra{\mathbb{R}^2\times \mathbb{Z}}$ and in particular the projection of $\conv\bra{S^+}\cap \bra{\mathbb{R}^2\times \mathbb{Z}}$ onto the $x$ variables is equal to $S$. Furthermore, by construction the extreme points of $\conv\bra{S^+}$ have an integral $y_1$ component. Hence, an ideal formulation of $S$ is given by $\bra{x,y_1}\in \conv\bra{S^+}$ and $y_1\in \mathbb{Z}$. 
  \begin{figure}[htpb]
  \begin{center}
  \includegraphics[scale=0.4]{embedding1b.pdf}
  \end{center}
  \caption{Two polyhedra (left in red), their embedding into a space with one $0$-$1$ variable (right in red) and the convex hull of this embedding (right in light blue).}\label{embeddingillust}
  \end{figure}

Before formalizing this embedding construction and generalizing it for unions of more than two polyhedra we present the following example that illustrates how it resolves the issues encountered in Example~\ref{examplemax}.
\begin{example}\label{examplemaxfixed} Consider again sets $S_3$ and $S_4$ from Example~\ref{examplemax}. We have that $S_3=P^1\cup P^2$,  where $P^1=\set{x\in \Real^2\,:\, 0\leq x_1\leq 1,\;x_2=0}$ and $P^2=\set{x\in \Real^2\,:\, 0\leq x_2\leq 1,\;x_1=0}$. Similarly $S_4=Q^1\cup Q^2$,  where $Q^1=\set{x\in \Real^2\,:\, 0\leq x_1\leq 1,\;x_2=0}$ and $Q^2=\set{x\in \Real^2\,:\, 0\leq x_2\leq 1,\;x_1=1}$. Let $S_3^+=\bra{P^1\times \set{1}} \cup \bra{P^2\times \set{0}}$ and $S_4^+=\bra{Q^1\times \set{1}} \cup \bra{Q^2\times \set{0}}$. We can check that $\conv\bra{S_3^+}=\set{\bra{x,y}\in \Real^3\,:\, x_2\leq 1-y_1,\quad x_1\leq y_1,\quad x_1,\,x_2\geq 0}$ and that  $\conv\bra{S_4^+}=\set{\bra{x,z}\in \Real^3\,:\,  x_2\leq 1-z_1,\quad 1-z_1 \leq x_1, \quad x_1\leq 1,\quad x_2\geq 0}$. Hence, both convex hulls are rational polyhedra and we obtain the linear MIP formulation for  $P^1\cup P^2$ given by 
\begin{equation}\label{formexlastconst1}
\bra{x,y}\in \conv\bra{S_3^+}, \quad y_1\in \set{0,1}
\end{equation}
and the linear MIP formulation for $Q^1\cup Q^2$  given by 
\begin{equation}\label{formexlastconst2}
\bra{x,z}\in \conv\bra{S_4^+}, \quad z_1\in \set{0,1}.
\end{equation}
Because we used $0$-$1$ variable $y_1$ for the embedding of $P^1\cup P^2$ and a different $0$-$1$ variable $z_1$ for the embedding of $Q^1\cup Q^2$ we can combine the formulations for each disjunction into a formulation of $x\in \bra{P^1\cup P^2}\cap \bra{Q^1\cup Q^2}$. The resulting formulation is not ideal as we can  check that 
\[\bra{0.5,0.5,0.5,0.5}\in \ext\bra{\set{\bra{x,y,z}\in \Real^4\,:\, \bra{x,y}\in \conv\bra{S_3^+},\quad \bra{x,z}\in \conv\bra{S_4^+} }}.\]
However, the resulting formulation is certainly valid and, in particular yields $\max\set{x_2\,:\, x\in S_3\cap S_4}=\max\set{x_2\,:\, \bra{x,y,z}\in \Real^4,\quad \eqref{formexlastconst1},\quad \eqref{formexlastconst2} }=0$.
\end{example}
%   \begin{figure}[htpb]
%   \begin{center}
%   \includegraphics[scale=0.7
% ]{correctcombo.pdf}
%   \end{center}
%   \caption{Relation between complexity measures for unions of polyhedra.}\label{qqq}
%   \end{figure}

\subsection{Embedding Formulations}

One possible generalization of the embedding procedure in Figure~\ref{embeddingillust} to more than two polyhedra is to embed $\bigcup_{i=1}^n P^i$ into $\bigcup_{i=1}^n \bra{ P^i \times \set{\e^i}}$ where $\e^i$ is the $i$-th unit vector. This procedure is known as the \emph{Cayley trick} or \emph{Cayley Embedding} and is used to study Minkowski sums of polyhedra (e.g. \cite{caytrick,karavelas2013maximum,WeibelPhd}). We here consider a further generalization that pairs the polyhedra $P^i$ with any set of pairwise disjoint $0$-$1$ vectors instead of just the unit vectors $\e^i$. The following proposition shows that the convex hull of the resulting embedding is a rational polyhedron that can be used to construct an ideal formulation of $x\in \bigcup_{i=1}^n P^i$. 

\begin{proposition}\label{firstprop} Let $\mathcal{P}:=\set{P^i}_{i=1}^n$ be a finite family of polyhedra in $\Real^d$ satisfying Assumption~\ref{ass1}, $k\geq \left\lceil \log_2 n\right\rceil$,  
$H:=\set{h^i}_{i=1}^n\in \mathcal{H}_k(n):=\set{\set{h^i}_{i=1}^n\subseteq \set{0,1}^k\,:\,  h^i\neq h^j \quad \forall i\neq j}$
be a family of pairwise distinct $0$-$1$ vectors indexed in the same way as the polyhedra and
\begin{equation}\label{embconv}
Q\bra{\mathcal{P},H}:=\conv\bra{\bigcup_{i=1}^n P^i\times \set{h^i} }.
\end{equation}
 Then 
\begin{itemize}
\item $Q\bra{\mathcal{P},H}$ is a rational polyhedron,
\item $ \bra{x,y}\in Q\bra{\mathcal{P},H} \cap \bra{\Real^d\times\Int^k} \quad \Leftrightarrow \quad\exists i\in \sidx{n} \text{ s.t. } y=h^i\;\wedge\; x\in P^i,$ and
\item $\ext\bra{Q\bra{\mathcal{P},H}}\subseteq \Real^d\times \set{0,1}^k$.
\end{itemize}
\end{proposition}
\proof{Proof.}
By Assumption~\ref{ass1},  $\set{P^i\times \set{h^i}}_{i=1}^n$ is a finite family of non-empty polyhedra with identical recession cones. Then, by Lemma 4.41 and Corollary 4.44  in \cite{conforti2014integer}, $Q\bra{\mathcal{P},H}$ is a rational polyhedron and
$Q\bra{\mathcal{P},H}=\conv\bra{\bigcup_{i=1}^n \bigcup_{v\in \ext\bra{P^i}  }\set{v\times h^i}}+\cone\bra{ \bigcup_{r\in \ray\bra{P^1}  }\set{r\times {\bf 0}}}$.
This shows the first two properties of $Q\bra{\mathcal{P},H}$. The last follows by additionally noting that the $h^i$'s are distinct extreme points of $[0,1]^k$.
\Halmos\endproof


Similarly to Figure~\ref{embeddingillust} and Example~\ref{examplemaxfixed} we obtain a formulation from $Q\bra{\mathcal{P},H}$ by interpreting $H$ as possible values of a $k$-dimensional  $0$-$1$ variable $y$.
\begin{definition}[Embedding Formulation]\label{embeddingformdef}
 Let $\mathcal{P}:=\set{P^i}_{i=1}^n$ be a finite family of polyhedra in $\Real^d$ satisfying Assumption~\ref{ass1}, $k\geq \left\lceil \log_2 n\right\rceil$ and $H\in \mathcal{H}_k(n)$. The \emph{embedding formulation} for disjunctive constraint $x\in \bigcup_{i=1}^n P^i$ associated to $H$ is the ideal formulation given by 
 \[ \bra{x,y}\in Q\bra{\mathcal{P},H},\quad y\in \mathbb{Z}^k.\]
We refer to $H$ as the \emph{encoding} of the formulation and to $Q\bra{\mathcal{P},H}$ as the \emph{LP relaxation} of the formulation.
\end{definition}

Encoding $H$ can have a strong impact in the size of $Q\bra{\mathcal{P},H}$, but different encodings can yield formulations of the same size or even equivalent polyhedra $Q\bra{\mathcal{P},H}$. The following straightforward lemma shows one such possible equivalency. 
\begin{lemma}\label{isolemma}
Let $\mathcal{P}:=\set{P^i}_{i=1}^n$ be a finite family of polyhedra in $\Real^d$ satisfying Assumption~\ref{ass1}, $k_1,k_2\geq \left\lceil \log_2 n\right\rceil$, $H\in \mathcal{H}_{k_1}(n)$ and $G\in \mathcal{H}_{k_2}(n)$. If there exists an affine map  $A:\Real^{k_1}\to \Real^{k_2}$ such that $A$ is a bijection between $\conv\bra{H}$ and $\conv\bra{G}$ then $Q\bra{\mathcal{P},H}$ is affinely isomorphic  to $Q\bra{\mathcal{P},G}$.

In particular, if $H:=\set{h^i}_{i=1}^n$  where $h^i=\e^i$ for all $i\in \sidx{n}$, and  $G:=\set{g^i}_{i=1}^n$  where $g^i=\e^{\pi(i)}$ for all $i\in \sidx{n}$ and $\pi:\sidx{n}\to \sidx{n}$ is a permutation, then 
\[\bra{x,y}\in Q\bra{\mathcal{P},G} \quad \Leftrightarrow \quad \bra{x,y^\pi}\in Q\bra{\mathcal{P},H}  \]
where $y^\pi_{\pi\bra{i}}=y_i$ for all $i\in \sidx{n}$.
\end{lemma}

Lemma~\ref{isolemma} shows that when the encoding uses $n$ unit vectors $\e^i\in \set{0,1}^n$ the specific order or polytope-vector assignment in the embedding is inconsequential. Hence, when an encoding of this form is used we assume the unit vectors are assigned in their natural order and refer to the resulting embedding formulation as the \emph{unary encoded} formulation as this encoding can be interpreted as a \emph{unary encoding} of the selection among the polyhedra. A completely different class of encodings are obtained when  $n$ is a power of $2$ and  $\set{h^i}_{i=1}^n=\set{0,1}^k$ for $k=\log_2 n$. This case can be interpreted as a \emph{binary encoding} of the selection among the polyhedra and corresponds to the encodings with the smallest number of components or \emph{bits}. For this reason we refer to embedding formulations resulting from such encodings as \emph{binary encoded} formulations. Unlike unary encoded formulations, in Section~\ref{SOS2} we show that permuting the order of a binary encoding can lead to  binary encoded formulations of significantly different sizes. This potential size variability over binary and other encodings motivates the following complexity measure for unions of polyhedra, which quantifies the size of its smallest embedding formulation. 

\begin{definition}[Embedding Complexity] For a polyhedron $Q$ let $\size(Q)$ be equal to the number of facet defining inequalities of $Q$\footnote{Here we follow the usual convention of not including the number of equations or variables (e.g. \cite{Kaibel11}). We will refine this notion of size for a special class of polyhedra in Section~\ref{vsection}.}.  Then, for a family of polyhedra $\mathcal{P}:=\set{P^i}_{i=1}^n$ satisfying Assumption~\ref{ass1} we let its its \emph{embedding complexity} be 
\[\mmc\bra{\mathcal{P}}:=\min\set{\size\bra{Q\bra{\mathcal{P},H}}\,:\,  H\in \bigcup\nolimits_{k\geq \left\lceil \log_2 n\right\rceil}  \mathcal{H}_k(n) }.\]
\end{definition}

Constructing an embedding formulation even for a fixed $H$ requires a potentially costly convex hull calculation. Calculating the embedding complexity has the added difficulty of minimizing the size of these convex hulls over all possible encodings. Fortunately, as we show in the following sections it is sometimes possible to give tight bounds on the embedding complexity of specially structured disjunctions such as SOS2 constraints. We also show how we can computationally and theoretically construct embedding formulations that can provide a significant computational advantage. To achieve this we concentrate on disjunctive constraints with a special structure that generalize SOS2 constraints. For an example of how embedding formulations can lead to a computational advantage for disjunctions without this special structure we refer the reader to \cite{huchette2016strong}.


% \begin{assumption} $\conv{H}$ can be described by equality constraints and variable bounds. 
% \end{assumption}
\section{$\mathcal{V}$-formulations}\label{vsection}


To simplify our analysis of formulation complexities we now consider a class of disjunctions composed of unions of specially structured faces of a common simplex. These faces are obtained from the simplex by fixing certain variables to zero and can be defined as follows.

\begin{definition}\label{vformdef} Let $V$ be a finite set, $\Delta^V:=\set{\lambda\in \Real^V_+\,:\, \sum\nolimits_{v\in V} \lambda_v=1}$ be the standard simplex in $\mathbb{R}^V$ and  $\mathcal{T}:=\set{T_i}_{i=1}^n$ be a family of subsets of $V$. We let $\mathcal{P}\bra{\mathcal{T}}:=\set{P\bra{T_i}}_{i=1}^n$ where \[P\bra{T_i}:=\set{ \lambda\in \Delta^V\,:\, \lambda_v\leq 0\quad \forall v\notin T_i}\] for each $i\in\sidx{n}$. In addition, for any  $H:=\set{h^i}_{i=1}^n\in \mathcal{H}_k(n)$ we let
\[Q\bra{\mathcal{T},H}:=Q\bra{\mathcal{P}\bra{\mathcal{T}},H}=\conv\bra{\set{\bra{\lambda,y}\in \Real^V\times \Real^k\,:\, \exists i\in \sidx{n} \text{ s.t. }  \lambda\in P_i\quad\wedge\quad  y=h^i}}.\]

Finally, we let $\mmc\bra{\mathcal{T}}:=\mmc\bra{\mathcal{P}\bra{\mathcal{T}}}$.
\end{definition}

As described in the following definition, constraints of this form includes the \emph{special ordered sets of type 1} (SOS1) and the \emph{special ordered sets of type 2} (SOS2) introduced by Beale and Tomlin \cite{Beale70}.

\begin{definition} We say $\mathcal{T}:=\set{T_i}_{i=1}^n$ is an \emph{SOS1} constraint on $V:=\sidx{n}$ if and only if $T_i=\set{i}$ for $i\in \sidx{n}$. We also say $\mathcal{T}:=\set{T_i}_{i=1}^n$ is an \emph{SOS2} constraint on $V:=\sidx{n+1}$ if and only if $T_i=\set{i,i+1}$ for $i\in \sidx{n}$.
\end{definition}

Furthermore, specially structured unions of polyhedra from Definition~\ref{vformdef} are strongly related to commonly denoted $\mathcal{V}$-formulations for unions of arbitrary polyhedra (see Corollary 5.2 and 6.3 in \cite{Mixed-Integer-Linear-Programming-Formulation-Techniques}).
In fact, the following straightforward proposition shows that arbitrary unions of polyhedra are essentially linear images of these specially structured polyhedra.

\begin{proposition}\label{vformprop}Let $\mathcal{R}:=\set{R^i}_{i=1}^n$ be a finite family of polyhedra in $\Real^d$ satisfying Assumption~\ref{ass1},  $\mathcal{T}:=\set{T_i}_{i=1}^n$ with $T_i=\ext\bra{R^i}$. Then disjunctive constraint $x\in \bigcup_{i=1}^n R^i$ is equivalent to 
  \begin{subequations}\label{vformexunion}
      \begin{alignat}{3}
    \sum\nolimits_{i=1}^n\sum\nolimits_{v\in T_i}  v \lambda_{v}+\sum\nolimits_{r\in \ray\bra{R^1}} r \mu_r&=x&\label{vformnum}\\
            \mu&\in \Real^{\ray\bra{R^1}}\label{vformnum2}\\
            \lambda&\in \bigcup_{i=1}^n P\bra{T_i}\label{vformlambda}.
    \end{alignat}
  \end{subequations}
In particular, if $k\geq \left\lceil \log_2 n\right\rceil$ and $H\in \mathcal{H}_k(n)$ then an ideal formulation of $x\in \bigcup_{i=1}^n R^i$ is given by \eqref{vformnum}--\eqref{vformnum2}, $\bra{\lambda,y}\in Q\bra{\mathcal{T},H} $ and $y\in \mathbb{Z}^k$.
\end{proposition}

In the sequel we assume the following simplifying assumption that ensures no $\lambda$ variable is always fixed to zero. 

\begin{assumption} \label{assumption0} $\bigcup_{i=1}^n T_i=V$.
\end{assumption}

We also refine the notion of size of a formulation to account for different classes of inequalities. In particular, we differentiate between variable bounds and general inequalities as an increment on the later usually has a stronger computational impact. Finally, we refer to general inequalities that consider both $\lambda$ and $y$ variables as \emph{embedding inequalities} and they compose the most critical structure of an embedding formulation. We formalize this accounting for the specially structured families of polyhedra we consider in this section, but their extension to general families is straightforward. 
\begin{definition}\label{classdef}Let  
\begin{equation}\label{genericineql2}
\sum\nolimits_{v\in V} a_v\lambda_v +\sum\nolimits_{i=1}^n b_i y_i= a\cdot \lambda+b\cdot y\leq c 
\end{equation}
be an inequality in a minimal description of  $ Q\bra{\mathcal{T},H}$. We say \eqref{genericineql2} is an implied equation if it is satisfied at equality for all $\bra{\lambda,y} \in Q\bra{\mathcal{T},H}$. If \eqref{genericineql2} is not an implied equation we say that it is 
\begin{itemize}
\item a variable bound if  $\abs{v\in V\,:\, \abs{a_v}>0}+ \abs{i\in \sidx{i}\,:\, \abs{b_i}>0}=1$, 
\item an \emph{encoding inequality} if   $\abs{v\in V\,:\, \abs{a_v}>0}=0$, and
\item an \emph{embedding inequality} if  $\abs{v\in V\,:\, \abs{a_v}>0}\geq 1$ and $\abs{i\in \sidx{i}\,:\, \abs{b_i}>0}\geq1$.
\end{itemize}
We let $\size_E(Q)$, $\size_B(Q)$, $\size_C(Q)$ and  $\size_M(Q)$  be the restriction of $\size(Q)$ to implied equation, variable bounds, encoding inequalities and embedding inequalities respectively. We similarly define  $\mmc_E\bra{\mathcal{T}}$, $\mmc_B\bra{\mathcal{T}}$, $\mmc_C\bra{\mathcal{T}}$ and $\mmc_M\bra{\mathcal{T}}$.  
\end{definition}
It is easy to check that under Assumption~\ref{assumption0}, the classification in Definition~\ref{classdef} includes all possible inequalities in a minimal description of $ Q\bra{\mathcal{T},H}$.

\subsection{Optimal embedding formulation for disjoint case}

When the elements of $\mathcal{T}$ are disjoint we can obtain a description of $Q\bra{\mathcal{T},H}$ as a direct corollary of Proposition 9.3 in \cite{Mixed-Integer-Linear-Programming-Formulation-Techniques}.
\begin{proposition}Let $H:=\set{h^i}_{i=1}^n\in \mathcal{H}_k(n)$ and $\mathcal{T}:=\set{T_i}_{i=1}^n$ be such that $T_i\cap T_j=\emptyset $ for all $i\neq j$. Then $Q\bra{\mathcal{T},H}$ can be described by 
	\begin{subequations}\label{logextremepointform}
		\begin{alignat}{3}
		\sum\nolimits_{i=1}^n\sum\nolimits_{v\in T_i}  h^i\lambda_{v}&=y&\\
			\sum\nolimits_{v\in V}  \lambda_{v}&=1\\
			\lambda&\in  \Real_+^V&\quad& \\
			y&\in[0,1]^{k}.
		\end{alignat}
	\end{subequations}
\end{proposition}
A simple analysis of this description then yields the exact embedding complexity for this disjoint case. 
\begin{proposition}
If $T_i\cap T_j=\emptyset $ for all $i\neq j$, then $\mmc\bra{\mathcal{T}}=\mmc_B\bra{\mathcal{T}}=n$ and $\mmc_E\bra{\mathcal{T}}= \left\lceil \log_2 n \right\rceil +1$.
\end{proposition}
\proof{Proof.}
We can check that constraints $\lambda_v \geq 0 $ for $v\in V$ are facet defining for \eqref{logextremepointform} while constraints $0\leq y_i\leq 1$ for $i\in \sidx{k}$ are redundant for \eqref{logextremepointform}. In addition, if any of the equalities in \eqref{logextremepointform}
is linearly dependent on the others we can eliminate one of the equalities that includes $y$ and reduce the dimension of $y$.  
The result follows by noting that the smallest $k$ that for which exits $H\subseteq \set{0,1}^k$ such that $H\in \mathcal{H}(n)$ is $k=\left\lceil \log_2 n \right\rceil$. 
\Halmos\endproof

\subsection{Basic properties for connected case}\label{connectedsection}

To analyze the embedding complexity of more complicated cases it will be convenient to prove some basic properties of embedding formulations. A natural simplifying assumption for the non-disjoint case is the following connectivity condition. 

\begin{assumption}[Connectedness] \label{connectedassumption} For all $j\neq j'$ there exist $\set{i_1,\ldots,i_r}\subseteq \sidx{n}$ such that $j=i_1$, $j'=i_r$ and $T_{i_l}\cap T_{i_{l+1}}\neq \emptyset$ for all $l\in [r-1]$.
\end{assumption}

We note that many of the properties we  consider extend to the non-connected case by considering each \emph{connected components} separately (e.g. see \cite{lee01} for an example with the unary encoding). However, for simplicity and briefness we now assume the connectivity requirement. 

One important question about the size of embedding formulations is how are they affected by the complexity of encoding $H$. The encoding is a potentially arbitrary set of $0$-$1$ vectors and its convex hull could be extremely complicated. Hence the encoding inequalities of $Q\bra{\mathcal{T},H}$ could easily dominate the size of $Q\bra{\mathcal{T},H}$. Fortunately, the following results shows that under mild conditions encoding inequalities  are not facet defining for $Q\bra{\mathcal{T},H}$. A proof of this statement is included in Appendix~\ref{appendixproofconnectedsection}.
\begin{restatable}{proposition}{HfacetpropProp}\label{Hfacetprop} Let $\mathcal{T}$ be such that there is no $i,j\in \sidx{n}$, $i\neq j$ such that $T_i\subseteq T_j$. Then $\size_C\bra{Q\bra{\mathcal{T},H}}=0$ and none of the facet defining inequalities of $\conv\bra{H}$ is facet defining for $Q\bra{\mathcal{T},H}$.
\end{restatable}
The non-containment condition of Proposition~\ref{Hfacetprop} is a natural requirement to avoid a redundant description of the disjunctive constraint. Furthermore, in Section~\ref{redundancysection} we will see that $\size_C\bra{Q\bra{\mathcal{T},H}}=0$ can hold even if this condition is violated. However, Example~\ref{boundsexample} in  Appendix~\ref{appendixresconnectedsection} shows a case where the containment condition does not hold and a facet defining inequality of  $\conv\bra{H}$ is also facet defining for $Q\bra{\mathcal{T},H}$.


While facet defining inequalities for $\conv\bra{H}$ are rarely facet defining for $Q\bra{\mathcal{T},H}$ the implied equations of $\conv\bra{H}$ will always be implied equations for $Q\bra{\mathcal{T},H}$. To state this result we require the following definition. 

\begin{definition}For $H:=\set{h^i}_{i=1}^n$, let   $L\bra{H}:=\aff\bra{H}-h^1$ be the linear space parallel to the affine hull of $H$. 
\end{definition}


The following lemma is a direct generalization of Proposition~1 from \cite{lee01} whose proof we include in  Appendix~\ref{appendixproofconnectedsection} for completeness.


\begin{restatable}{lemma}{lambdaaffLemma}\label{lambdaaff} Let $H:=\set{h^i}_{i=1}^n\in \mathcal{H}_k(n)$ and $\mathcal{T}:=\set{T_i}_{i=1}^n$ satisfy Assumptions~\ref{assumption0} and \ref{connectedassumption}, then $\dim\bra{Q\bra{\mathcal{T},H}}=\abs{V}+\dim\bra{H}-1$ and the constraints defining $\aff\bra{Q\bra{\mathcal{T},H}}$ are precisely  
\begin{equation}\label{simplexequality}
\sum\nolimits_{v\in V}\lambda_v=1 
\end{equation}
and the constraints defining $\aff\bra{H}$ (i.e. equations that do not include the $\lambda$ variables)
\end{restatable}

Inequalities $\lambda_v\geq 0$ are often facet defining for $Q\bra{\mathcal{T},H}$. Furthermore, they rarely have a strong computational impact. For this reason we relegate a more precise analysis of them to Appendix~\ref{appendixresconnectedsection}.

\section{Bounds on embedding complexity for SOS2 constraints}\label{SOS2}
In this section we conduct a detailed analysis of all embedding formulations for SOS2 constraints on $V=\sidx{n+1}$. We begin with the following proposition that precisely characterizes such formulations and relates them to a family of hyperplanes associated to the encoding used to construct the formulation.


\begin{proposition}\label{sos1prophyper} For $H:=\set{h^i}_{i=1}^n\in \mathcal{H}_k(n)$ let $c^i=h^{i+1}-h^i$ for $i\in \sidx{n-1}$ and for $b\in L(H)\setminus \set{\bf 0}$ let  $M(b):=\set{y\in L(H)\,:\, b\cdot y=0}$ be the linear (or central) hyperplane defined by $b$ in $L(H)$.

If  $\set{b^i}_{i=1}^L\subseteq L(H)\setminus \set{\bf 0}$ is  such that $\set{M(b)}_{i=1}^{L}$  is the set of linear hyperplanes spanned by $\set{c^i}_{i=1}^{n-1}$ in $L(H)$, then $Q\bra{\mathcal{T},H}$ is equal to  
\begin{subequations}
\begin{alignat}{3}
\bra{b^i\cdot h^1}\lambda_{1}+\sum\nolimits_{v=2}^{n} \min\set{{b^i\cdot h^v} ,{b^i\cdot h^{v-1}}}\lambda_v+\bra{b^i\cdot h^n}\lambda_{n+1}& \leq \phantom{-}b^i\cdot y &\quad&\forall i \in \sidx{L}\\
-\bra{b^i\cdot h^1}\lambda_{1}-\sum\nolimits_{v=2}^{n} \max\set{{b^i\cdot h^v} ,{b^i\cdot h^{v-1}}}\lambda_v-\bra{b^i\cdot h^n}\lambda_{n+1}& \leq {-}b^i\cdot y &\quad&\forall i \in \sidx{L}\\
\sum\nolimits_{v=1}^{n+1} \lambda_v &=1\\
\lambda_v&\geq 0 &\quad& \forall v\in \sidx{n+1}\\
y&\in \aff\bra{H}.
\end{alignat}
\end{subequations} 
Furthermore, $\size_M\bra{Q\bra{\mathcal{T},H}}=2L$,  $2\leq \size_B\bra{Q\bra{\mathcal{T},H}}\leq n+1$, $\size_E\bra{Q\bra{\mathcal{T},H}}=1+k-\dim\bra{H}$ and $\size_C\bra{Q\bra{\mathcal{T},H}}=0$.
\end{proposition}
\proof{Proof.}
By Proposition~\ref{Hfacetprop} and by possibly adding multiples of $\sum\nolimits_{v=1}^{n+1} \lambda_v =1$ and the equations defining $\aff\bra{H}$, we may assume without loss of generality that any facet defining embedding inequality of $Q\bra{\mathcal{T},H}$ is of the form 
\begin{equation}\label{genericforsos2}
a\cdot\lambda \leq  b\cdot y
\end{equation}
with $a\neq {\bf 0}$ and $b\in L_1(H):=\set{b\in L(H)\,:\,\norm{b}=1}$ where $\norm{b}$ is the euclidean norm.
For each $v\in \sidx{n+1}$, $a\in \Real^{n+1}$  and $b\in \Real^n$ let \[E_v\bra{a,b}:=\begin{cases}\set{ i\in \set{1}\quad\quad\;\;\,\,:\,  a_v=b\cdot h^i} & v=1\\\set{i\in \set{v-1,v}\,:\,  a_v=b\cdot h^i} & v\in \sidx{2,n}\\\set{i\in \set{n}\quad\quad\;\;\,:\, a_v=b\cdot h^\iota} & v=n+1\\\end{cases}.\]
The set of extreme points of $Q\bra{\mathcal{T},H}$ supporting \eqref{genericforsos2} (i.e. those that satisfy it at equality) is precisely $X\bra{a,b}:=\set{\bra{e^v,h^i}\,:\,  v\in V,\quad  i\in E_v\bra{a,b}}$.
Furthermore, \eqref{genericforsos2} is faced defining if and only if $X\bra{a,b}$ is maximal with respect to inclusion (among all $a\in \Real^{n+1}$ and $b\in L_1(H)$ for which \eqref{genericforsos2} is an embedding inequality). Hence, \eqref{genericforsos2} is facet defining if and only if
\begin{enumerate}
\item $\abs{E_v\bra{a,b}}\geq 1$ for all $v\in \sidx{n+1}$, and
\item\label{condddd2} $\set{v\in\sidx{n+1} \,:\, \abs{E_{v}\bra{a,b}}= 2}$ is maximal with respect to inclusion.
\end{enumerate}
We have that $\abs{E_{v}\bra{a,b}}= 2$ can only hold if $v\in\sidx{2,	n}$ and  $c^{v-1}\cdot b=0$. Hence, condition \ref{condddd2} can only hold if $I\bra{b}:=\set{i \in \sidx{n-1}\,:\,  c^i\cdot b=0}$ is maximal. Furthermore, if $I\bra{b}$ is maximal then the unique $a\in\Real^{n+1}$ such that $a$ and $b$ satisfies both conditions and for which \eqref{genericforsos2} is an embedding inequality is given by $a_1=b\cdot h^1$, $a_v=\min\set{ b\cdot h^{v-1} , b\cdot h^{v} }$ for all $v\in \sidx{2,n}$ and $a_{n+1}= b\cdot h^n$.
We claim that there is a one-to-one correspondence between maximal sets $I\bra{b}$ for $b\in L_1(H)$ and the hyperplanes spanned by $\set{c^i}_{i=1}^{n-1}$ in $L(H)$. Indeed, let $M(b):=\set{y\in L(H)\,:\,  b\cdot y=0}$ be a hyperplane spanned by  $\set{c^i}_{i\in I}$ for some $I\subseteq \sidx{n-1}$.  Without loss of generality we may assume that $b\in L_1(H)$ and $I=I(b)$. Now, because $M(b)$ is a hyperplane in $L(H)$ spanned by $\set{c^i}_{i\in I(b)}$ we have that $\dim\bra{\set{c^i}_{i\in I(b)}}=\dim\bra{H}-1$.
Then, because vectors in $L_1\bra{H}$ are non-zero, $c^j\notin \spann\bra{\set{c^i}_{i\in I(b)}}$  for $j\in \sidx{n-1}\setminus I(b)$ and $\set{c^i}_{i=1}^{n-1}\subseteq L(H)$ we have that $I(b)$ is maximal. For the converse let $b\in L_1(H)$ be such that $I(b)$ is maximal. 
Then, because $\set{c^i}_{i=1}^{n-1}$ spans $L(H)$ we have that $\dim\bra{\set{c^i}_{i\in I(b)}}=\dim(H)-1$ and hence $M(b)$ is a hyperplane spanned by $\set{c^i}_{i\in I(b)}$.

To obtain the desired result it suffices to note that $I(b)=I(-b)$ and to show that if $I(b)$ is maximal, then $b$ and $-b$ yield different facets. The latter holds if there exists $v\in \sidx{2,n}$ such that $ b\cdot h^{v-1} \neq  b\cdot h^{v}$, which must hold for every $b\in L_1(H)$.
\Halmos\endproof

Because Proposition~\ref{sos1prophyper} characterizes every possible embedding formulation for SOS2 we can use it to obtain the following lower bound on $\mmc_M\bra{\mathcal{T}}$.

\begin{corollary}\label{soslb} If $\mathcal{T}$ is is an SOS2 constraint on  $V=\sidx{n+1}$, then $\mmc_M\bra{\mathcal{T}}\geq 2\lceil \log_2 n\rceil$. 
\end{corollary}
\proof{Proof.}
The number of (linear) hyperplanes spanned by $\set{c^i}_{i=1}^{n-1}$ in $L(H)$ is equal to the number of $1$-flats of the (central) hyperplane arrangement $\set{\set{b\in L(H)\,:\, c^i\cdot b =0}}_{i=1}^{n-1}$ in $L(H)$. Because $\spann\bra{\set{c^i}_{i=1}^{n-1}}=L(H)$ the number of such $1$-flats is at least $\dim(L(H))=\dim(H)$. Because all elements of $H$ are pairwise distinct  we have that $\dim(H)\geq \lceil \log_2 n\rceil$, which proves the result. 
\Halmos\endproof

Proposition~\ref{sos1prophyper} also allows us to recover known formulations for SOS2 constraints. For instance, the following corollary shows that the unary encoded embedding formulation for SOS2 is exactly formulation \eqref{CC1dstrong} introduced in  \cite{padberg00}.

\begin{corollary}\label{sosunary} If $\mathcal{T}$ is is an SOS2 constraint on  $V=\sidx{n+1}$ and $H$ is the unary encoding, then $Q\bra{\mathcal{T},H}$ is equal to  
\begin{subequations}
\begin{alignat}{3}
\sum\nolimits_{v=l+2}^{n+1} \lambda_v \leq \sum\nolimits_{i=l+1}^n y_i,\quad  
\sum\nolimits_{v=1}^{l} \lambda_v& \leq \sum\nolimits_{i=1}^l y_i &\quad&\forall l \in \sidx{n-1}\\
\sum\nolimits_{v=1}^{n+1} \lambda_v &=1\\
\sum\nolimits_{i=1}^{n} y_i &=1\\
\lambda_1\geq 0, \quad
\lambda_{n+1}&\geq 0. &\quad& 
\end{alignat}
\end{subequations}
Furthermore, $\size_M\bra{Q\bra{\mathcal{T},H}}=2(n-1)$,  $\size_B\bra{Q\bra{\mathcal{T},H}}=2$, $\size_E\bra{Q\bra{\mathcal{T},H}}=2$ and $\size_C\bra{Q\bra{\mathcal{T},H}}=0$.
\end{corollary} 

In addition, Proposition~\ref{sos1prophyper} can be used to recover and generalize formulation \eqref{LogCC1dstrong} introduced in \cite{Modeling-Disjunctive-Constraints-FULL}, which is known as the logarithmic formulation for SOS2. To describe such formulation we need the following definition, which describes a special class of binary encodings where adjacent elements (in the order induced by the SOS2 constraints) only differ in one bit or coordinate. 
\begin{definition} We say $H=\set{h^i}_{i=1}^n\in \mathcal{H}_{\lceil \log_2 n\rceil}(n)$ is a \emph{gray code} if and only if  for all $i\in \sidx{ n-1}$ we have $\sum\nolimits_{j=1}^{\lceil \log_2 n\rceil} \abs{h^{i}_j-h^{i+1}_j}=1$.
\end{definition}
Gray codes exist for any $n$ including the case where $n$ is not a power of two \cite{Wilf89}. This makes the logarithmic formulation valid for any value of $n$. However, as we will discuss in Appendix~\ref{logsos2emsec}, the logarithmic formulation is technically an embedding formulation only when  $n$ is a power of two. Fortunately, the following corollary of Proposition~\ref{sos1prophyper} adapts the logarithmic formulation to an embedding formulation for all $n$ (see \cite{MuldoonPhd} for an alternate derivation).
\begin{corollary}\label{sosub} If $\mathcal{T}$ is is an SOS2 constraint on  $V=\sidx{n+1}$ and $H$ is a gray code, then $Q\bra{\mathcal{T},H}$ is equal to  
\begin{subequations}\label{sos2formul}
\begin{alignat}{3}
h^1_i\lambda_{1}+\sum\nolimits_{v=2}^{n} \min\set{h^v_i,h^{v-1}_i}\lambda_v+h^n_i\lambda_{n+1}& \leq \phantom{-}y_i &\quad&\forall i \in \sidx{\left\lceil \log_2 n\right\rceil}\\
-h^1_i\lambda_{1}-\sum\nolimits_{v=2}^{n} \max\set{h^v_i,h^{v-1}_i}\lambda_v-h^n_i\lambda_{n+1}& \leq -y_i &\quad&\forall i \in \sidx{\left\lceil \log_2 n\right\rceil}\\
\sum\nolimits_{i=1}^{n+1} \lambda_v &=1\\
\lambda_v&\geq 0 &\quad& \forall v\in \sidx{n+1}.
\end{alignat}
\end{subequations}

Furthermore, $\size_M\bra{Q\bra{\mathcal{T},H}}=2\left\lceil \log_2 n\right\rceil$,  $2\leq \size_B\bra{Q\bra{\mathcal{T},H}}\leq n+1$, $\size_E\bra{Q\bra{\mathcal{T},H}}=1$ and  $\size_C\bra{Q\bra{\mathcal{T},H}}=0$.
\end{corollary} 

When combined with the lower bound from Corollary~\ref{soslb} we see that the adapted logarithmic formulation is optimal with respect to embedding inequalities and essentially optimal (up to logarithmic terms) with respect to all inequalities. 

\begin{corollary}\label{sosboundcoro}If $\mathcal{T}$  is an SOS2 constraint on  $V=\sidx{n+1}$, then
\begin{itemize}
\item $\mmc_M\bra{\mathcal{T}}=2\lceil \log_2 n\rceil$, and
\item  $n+1\leq \mmc\bra{\mathcal{T}}\leq n+1 +2\lceil \log_2 n\rceil$.
\end{itemize}
Furthermore, the upper bounds are achieved by a formulation with only one equation.
\end{corollary}
\proof{Proof.}
For the lower bound on $\mmc\bra{\mathcal{T}}$ we have that $Q\bra{\mathcal{T},H}$ is an \emph{extended formulation} of $\Delta^V$ and the extension complexity of $\Delta^V$ is lower bounded by $\abs{V}$ because the slack matrix of $\Delta^V$ has non-negative rank of $\abs{V}$ \citep{Kaibel11}. The other inequalities are direct from Corollaries~\ref{soslb} and \ref{sosub}. 
\Halmos\endproof

  
\subsection{Size distribution for binary encodings}\label{graphsec}

If $n=2^k$ for some $k\in \Int$ and $H\in \mathcal{H}_{k}(n)$, then Proposition~\ref{sos1prophyper} shows that the  number of embedding inequalities of $Q\bra{\mathcal{T},H}$ is upper bounded by $2 \binom{n-1}{k-1}$. The following proposition suggests that this upper bound may be nearly achieved. We include a proof of this result in Appendix~\ref{omproofapendix}.

\begin{restatable}{proposition}{antigraylemmaLem}\label{antigraylemma}Let $n=2^k$ for some $k\in \Int$. There exist $H\in \mathcal{H}_{k}(n)$ such that $\size_M\bra{Q\bra{\mathcal{T},H}}$ is equal to twice the number of affine hyperplanes spanned by $\set{0,1}^{k-1}$.
\end{restatable}



It is believed that the number of affine hyperplanes spanned by $\set{0,1}^{k-1}$ is close to its trivial upper bound of $\binom{n/2}{k-1}$ for $n=2^k$ (e.g. \cite{aichholzer1996classifying}). Both this upper bound and the embedding inequality bound of $2\binom{n-1}{k-1}$ grow roughly as $n^{\log_2n}$\footnote{We have $\Omega\bra{n^{(1-\varepsilon) \log_2 n}}=\binom{n/2}{k-1}\leq \binom{n-1}{k-1}\leq n^{\log_2 n}$ for all $\varepsilon>0$.}, which suggests that the worst case for the number of embedding inequalities of a binary encoded formulation is quasi-polynomial in $n$. 
Hence, it seems like an unfortunate selection of the specific binary encoding can lead to a formulation that is significantly larger than the lower bound from Corollary~\ref{soslb} or even the size of the unary encoded formulation from Corollary~\ref{sosunary}. Because its link with the number of hyperplanes spanned by subsets of $\set{0,1}^{k-1}$ (or $\set{-1,0,1}^{k-1}$), understanding the typical size of a binary encoded embedding formulation for SOS2 constraints may prove extremely challenging (e.g. \cite{voigt2006singular}). For this reason we only pursue a simple empirical study of the distribution of sizes for these formulations. For this study we selected $k\in \sidx{3,6}$ and calculated the number of embedding inequalities for randomly selected binary encodings (the ones associated to a random permutation of $\set{0,1}^{k}$). For $n=3$ we considered all $40,320$ possible encodings, while for $k\in \set{4,5}$ we only used a random sample of $10,000$ encodings and for $k=6$ we only used a random sample of $1,000$ encodings (calculating the formulation sizes for $k=6$ was already computational intensive). The results of this study are presented in Figure~\ref{randomfigure}.
\begin{figure}[htpb]
  \begin{center}
  \includegraphics[scale=0.4]{sos2.pdf}
  \end{center}
  \caption{Number of embedding inequalities for randomly selected encodings.}\label{randomfigure}
  \end{figure}
 The figure presents histograms for the number of embedding inequalities  for each $k$, together with the trivial upper bound of $2 \binom{n-1}{k-1}$ (depicted by the solid red line), the number of embedding inequalities of the unary encoded embedding formulation (depicted by the dotted blue line) and the number of embedding inequalities of the optimal binary encoded formulation (depicted by the dashed green line). The figure shows that the typical number of embedding inequalities of a binary encoded formulation seems to be much closer to the upper bound and suggests that a randomly selected encoding may often lead to a formulation that is significantly larger than even the unary encoded formulation. Hence a careful encoding selection appears crucial to obtain a small formulation.


\section{Formulations for Piecewise Linear Functions of Two Variables}\label{pwlsecc}

The results in Section~\ref{graphsec} show that it may be hard to construct small embedding formulations. However, we now show how small embedding formulations can be constructed for multivariate piecewise linear functions. MIP formulations for multivariate piecewise linear functions can be constructed from disjunctions that fit Definition~\ref{vformdef} (e.g.  \cite{lee01,Modeling-Disjunctive-Constraints-FULL,Mixed-Integer-Models-for-Nonseparable}). For simplicity,  we consider formulations for piecewise linear functions of two variables defined on grid triangulations on $\sidx{m+1}^2$ such as those depicted in Figure~\ref{newpwl2fig}. 
\begin{figure}[htpb]
  \begin{center}
  \subfigure[Piecewise Linear Function on the Union-Jack Triangulation for $m=8$]{\label{newpwl2fig1}\includegraphics[scale=0.3]{PWL.pdf}}\quad\quad\quad 
    \subfigure[The Union-Jack Triangulation for $m=2$.]{\label{newpwl2fig2}\includegraphics[scale=0.2]{triang2.pdf}}
  \end{center}
  \caption{Piecewise Linear Functions of Two Variables and Grid Triangulations.}\label{newpwl2fig}
  \end{figure}
More precisely, we consider functions $f:[1,m+1]^2\to \Real$ that are continuous in $[1,m+1]^2$ and affine in each triangle of the triangulation (e.g. for the triangulation in Figure~\ref{newpwl2fig2} it is affine in $\conv\bra{\set{\bra{1,1},\bra{1,2},\bra{2,2}}}$). As detailed in Appendix~\ref{PWLAPPENDIX}, we can construct a formulation of the graph or epigraph of such functions through Proposition~\ref{vformprop} and disjunction $\mathcal{P}\bra{\mathcal{T}}$ where $V=\sidx{m+1}^2$ and $\mathcal{T}$ corresponds to all triangles in the triangulation (e.g. for the triangulation in Figure~\ref{newpwl2fig2} $\mathcal{T}=\set{\set{\bra{1,1},\bra{1,2},\bra{2,2}},\set{\bra{1,1},\bra{2,1},\bra{2,2}},\ldots, \set{\bra{2,2},\bra{2,3},\bra{3,3}}}$). Constructing and analyzing  embedding formulations for triangulations can be significantly more complicated than for SOS2 constraints. However, using results from  \cite{lee01} and \cite{Modeling-Disjunctive-Constraints-FULL} we can give a rather precise analysis for a triangulation known as the \emph{union-jack} \citep{todd77}, which is depicted in Figure~\ref{newpwl2fig2} (See Definition~\ref{triangulationdef} for a precise description). In particular, we have that using the unary encoding leads to an extremely large embedding formulation, but using a carefully selected binary encoding leads to a simple formulation with near-optimal size. 
\begin{restatable}{corollary}{unionjackboundprop}\label{UnionJackCoro}Let $\mathcal{T}=\set{T_i}_{i=1}^n$ for $n=2 m^2$ be the union-jack triangulation on $V=\sidx{m+1}^2$.  Then $\size_C\bra{Q\bra{\mathcal{T},H}}=0$ and
\[
\bra{\sqrt{n/2}+1}^2\leq \mmc\bra{\mathcal{\mathcal{T}}}.
\]
If $H$ is the unary encoding then $\size_E\bra{Q\bra{\mathcal{T},H}}=2$, $\size_B\bra{Q\bra{\mathcal{T},H}}=\bra{\sqrt{n/2}+1}^2$ and 
\[\size_M\bra{Q\bra{\mathcal{T},H}}= \binom{2\sqrt{n/2}}{\sqrt{n/2}}\]
In contrast, if $m$ is a power of two, then there exist a binary encoding $H\in \mathcal{H}_{\log_2 n}(n)$ such that $\size_E\bra{Q\bra{\mathcal{T},H}}=1$, $\size_B\bra{Q\bra{\mathcal{T},H}}=\bra{\sqrt{n/2}+1}^2$ and 
\begin{equation}\label{unionjackopt}
\size_M\bra{Q\bra{\mathcal{T},H}} =  2  \log_2 n.
\end{equation}
\end{restatable}
In Appendix~\ref{unionjackcoroapendix} we include a formal proof of Corollary~\ref{UnionJackCoro}. A detailed description of the embedding formulation that achieves the nearly-optimal size \eqref{unionjackopt} is obtained as a special case of Proposition~\ref{generalpwlprop}. The following example illustrates this formulation for $m=2$.
\begin{example}\label{unionjackex}Let $\mathcal{T}=\set{T_i}_{i=1}^8$ be the the union-jack triangulation for $m=2$  and let $H$ be the encoding with the triangle-vector assignment depicted in Figure~\ref{newpwl2fig2}. That is let   
 \begin{alignat*}{3}
 h^1=(0,0,0),\; T_1=\set{\bra{1,1},\bra{2,1},\bra{2,2}};&\quad\quad\quad&h^2=(1,0,0),\; T_2=\set{\bra{1,1},\bra{1,2},\bra{2,2}};\\
 h^3=(0,0,1),\; T_3=\set{\bra{2,1},\bra{3,1},\bra{2,2}};&\quad\quad\quad&h^4=(1,0,1),\; T_4=\set{\bra{3,1},\bra{3,2},\bra{2,2}};\\ 
 h^5=(1,1,0),\; T_5=\set{\bra{1,2},\bra{2,2},\bra{1,3}};&\quad\quad\quad&h^6=(0,1,0),\; T_6=\set{\bra{2,2},\bra{2,3},\bra{1,3}};\\ 
 h^7=(0,1,1),\; T_7=\set{\bra{2,2},\bra{2,3},\bra{3,3}};&\quad\quad\quad&h^8=(1,1,1),\; T_8=\set{\bra{2,2},\bra{3,2},\bra{3,3}}.
  \end{alignat*}
  Then, $Q\bra{\mathcal{T},H}$ is given by
 \begin{subequations}\label{unionjackexform}
 \begin{alignat}{6}
   \lambda_{\bra{2,1}}+\lambda_{\bra{2,3}}&\leq 1-y_1,&\quad 
  \lambda_{\bra{1,2}}+\lambda_{\bra{3,2}}&\leq y_1&\quad& \\
    \lambda_{\bra{1,1}}+\lambda_{\bra{2,1}}+\lambda_{\bra{3,1}}& \leq 1-y_2, &\quad 
\lambda_{\bra{1,3}}+\lambda_{\bra{2,3}}+\lambda_{\bra{3,3}}& \leq y_2 &\quad&\\
  \lambda_{\bra{1,1}}+\lambda_{\bra{1,2}}+\lambda_{\bra{1,3}}& \leq 1-y_3, &\quad  
\lambda_{\bra{3,1}}+\lambda_{\bra{3,2}}+\lambda_{\bra{3,3}}& \leq y_3 &\quad&\\
 &&\sum\nolimits_{v\in V} \lambda_v &=1 \\
 &&\lambda_v &\geq 0 &&\forall v\in V.
 \end{alignat}
 \end{subequations}
\end{example}

 Corollary~\ref{UnionJackCoro} shows that the specific encoding used can have a significant impact on the size of an embedding formulation for triangulations. If fact, the formulation that achieves the nearly-optimal size \eqref{unionjackopt} uses a precisely tailored generalization of the gray codes for SOS2 constraints. Unfortunately, this generalization only works for the union-jack triangulation and it is sometimes preferable to use different triangulations such as the ones depicted in Figure~\ref{triag2} (e.g. \cite{Fitting-Piecewise-Linear}). In the following subsections we explore two techniques to construct small embedding formulations for these alternative triangulations.
\begin{figure}[htpb]
  \begin{center}
  \subfigure[Modified Union-Jack Triangulation for $m=4$.]{\label{triag2a}\quad\quad\quad\quad\quad\quad\includegraphics[scale=.2]{modJ1.pdf}\quad\quad\quad}
    \subfigure[K1 Triangulation for for $m=4$.]{\label{triag2b}\quad\quad\quad\includegraphics[scale=.2]{K1.pdf}\quad\quad\quad\quad\quad\quad}
  \end{center}
  \caption{Different Triangulations.}\label{triag2}
  \end{figure}

\subsection{Constructing Embedding Formulations Computationally}\label{cddsec}

One way to construct embedding formulations is to computationally construct the convex hull in \eqref{embconv} for a specific encoding. Picking a random encoding will likely result in an extremely large formulation (cf. Section~\ref{graphsec}). For this reason we now investigate the effectiveness of using a known favorable encoding for a similar constraint. For this we consider a the modification of the union-jack triangulation illustrated in Figure~\ref{triag2a}. This triangulation is obtained by changing the way the bottom-left and top-right squares of the triangulation are divided into two triangles (in the original triangulation they are divided into top-left and bottom-right triangles, and in the modified triangulation they are divided into bottom-left and top-right triangles). 

To construct an embedding formulation for this modified triangulation we adapt the encoding $H$ associated to the logarithmic formulation for the union-jack triangulation (i.e. the encoding that yields bound \eqref{unionjackopt}). The adaptation uses the same triangle-vector assignment for all triangles except for the ones belonging to the bottom-left and top-right squares. For those two squares the adaptation assigns to the bottom-left triangle the same $h^i$ assigned to the top-left triangle in the original encoding for the union-jack triangulation. Similarly, the adaptation assigns to top-right triangle the same $h^i$ assigned to the bottom-right triangle in the original encoding. To construct the formulation we simply compute the convex hull of $\bigcup_{=1}^n P\bra{T_i} \times \set{h^i}$ for this modified $H=\set{h^i}_{i=1}^n$ using the software cddlib \citep{cddlib}. 

We tried this for $m\in \set{4,8,16,32}$ and for all four cases the resulting embedding formulation only had four more inequalities than the formulation for the original union-jack triangulation. In addition, computing the convex hulls with cddlib for each $m\in \set{4,8,16,32}$ took respectively less than a second, 10 seconds, 24 minutes and 3.5 days on an Intel i7-3770 3.40GHz workstation with 32GB of RAM. The computational time can grow quickly with $m$, but fortunately this computation only has to be done once and the formulation can then be stored. Similar to traditional MIP formulations, the resulting stored embedding formulation can be used for free in any problem that requires a piecewise linear functions of two variables based on the modified union-jack triangulation. More specifically, the same formulation can be used independently of the specific data (e.g. actual function values) associated to the piecewise linear functions (cf. Proposition~\ref{vformprop} and Appendix~\ref{PWLAPPENDIX}).  Hence, 3.5 days does not seem that large when compared with the research time required to develop a small and ideal  ad-hoc MIP formulation. Of course, this statement is conditional on the resulting formulation being small (so that it can be effectively be stored and reused) and the formulation yielding a computational advantage (which is correlated with, but not guaranteed by a small size).  

To check if the formulation obtained with cddlib preserves the computational advantage of the logarithmic formulation for the original  union-jack triangulation, we replicate the computational experiments in   \cite{Modeling-Disjunctive-Constraints-FULL} and \cite{Mixed-Integer-Models-for-Nonseparable} for the modified union-jack triangulation. These experiments consider a series of transportation problems whose objective functions are the sum of $25$ piecewise linear functions of two variables on the $\sidx{m+1}^2$ grid for $m\in \set{4,8,16,32}$. For each $m$ the experiment considers $100$ randomly generated instances. With the exception of the logarithmic formulation, all formulations considered  in the original experiment are applicable for the modified union-jack triangulation. So we test all these formulations with the logarithmic formulation replaced by the embedding formulation constructed computationally using cddlib. All formulations were implemented using the JuMP modeling language \citep{jump,LubinDunningIJOC,DunningHuchetteLubin2015} and solved with Gurobi v6.5 \citep{gurobi} on an Intel i7-3770 3.40GHz workstation with 32GB of RAM. Solve times for all combinations of formulations and solver are presented in Figure~\ref{resfig1} for $m\in \set{4,8,16,32}$. We refer the reader to \cite{Mixed-Integer-Models-for-Nonseparable} for details on the benchmark formulations, but we note that DCC and MC is obtained by variants of Theorem~\ref{BTheo}, CC is the generalization of formulation \eqref{CC1d} and DCCLog is obtained by combining a variant of Theorem~\ref{BTheo} with the same encoding used for the embedding formulation. We can see that the embedding formulation can provide a significant computational advantage.
\begin{figure}[htpb]
  \begin{center}
  \includegraphics[scale=1]{J1Gurobi.pdf}
  \end{center}
  \caption{Solve Times for Modified Union-Jack Triangulation [s].}\label{resfig1}
  \end{figure}

\subsection{Embedding Formulations and Redundancy}\label{redundancysection}

A key to the success of the computationally constructed embedding formulation from the previous section was finding an encoding that yields a small embedding formulation. For the modified union-jack triangulation we achieved this using an encoding that was favorable for a similar triangulation (the traditional union-jack). Unfortunately, this encoding does not yield a small formulation for significantly different triangulations such as the K1 Triangulation  depicted in Figure~\ref{newredundant} for for $m=2$ (See Definition~\ref{triangulationdef} for a precise description). Furthermore, we tried several encoding generation heuristics and we could not find a favorable encoding for the K1 triangulation. Fortunately, we were able to generalize an ideal formulation from \cite{Modeling-Disjunctive-Constraints-FULL} to the K1 triangulation. While this formulation is not an embedding formulation for the K1 triangulation, it is an embedding formulation for a redundant description. We postpone a general description of this formulation to Proposition~\ref{generalpwlprop} in Section~\ref{indepandredundsec} and concentrate on how redundancy can help construct small embedding formulations. We also test the computational effectiveness of this approach. We begin with the following example, which analyses the formulation from Proposition~\ref{generalpwlprop} for the K1 Triangulation with $m=2$.

\begin{example}\label{lastex}Let $\mathcal{T}=\set{T_i}_{i=1}^8$ be the the K1 Triangulation for $m=2$ depicted in Figure~\ref{newredundant}. Then, an ideal formulation for $\mathcal{P}\bra{\mathcal{T}}$ is given by
 \begin{subequations}\label{lastexform}
 \begin{alignat}{6}
   \lambda_{\bra{1,1}}+\lambda_{\bra{3,3}}&\leq 1-y_1,&\quad 
  \lambda_{\bra{1,3}}+\lambda_{\bra{2,2}}+\lambda_{\bra{3,1}}&\leq y_1&\quad& \\
    \lambda_{\bra{1,2}}+\lambda_{\bra{2,1}}&\leq 1-y_2,&\quad 
  \lambda_{\bra{2,3}}+\lambda_{\bra{3,2}}&\leq y_2&\quad& \\
  \lambda_{\bra{1,1}}+\lambda_{\bra{2,1}}+\lambda_{\bra{3,1}}& \leq 1-y_3, &\quad 
\lambda_{\bra{1,3}}+\lambda_{\bra{2,3}}+\lambda_{\bra{3,3}}& \leq y_3 &\quad&\\
  \lambda_{\bra{1,1}}+\lambda_{\bra{1,2}}+\lambda_{\bra{1,3}}& \leq 1-y_4, &\quad  
\lambda_{\bra{3,1}}+\lambda_{\bra{3,2}}+\lambda_{\bra{3,3}}& \leq y_4 &\quad&\\
 &&\sum\nolimits_{v\in V} \lambda_v &=1 \\
 &&\lambda &\in \Real_+^V\\
  &&y&\in \set{0,1}^4. &\quad& 
 \end{alignat}
 \end{subequations}
Formulation \eqref{lastexform} is very similar to embedding formulation \eqref{unionjackexform} in Example~\ref{unionjackex}, but with four $0$-$1$ variables instead of three. Hence, it may have a similar assignment between  the possible values of its $0$-$1$ variables (encoding) and the triangles of K1. Indeed, such assignment is depicted in Figure~\ref{newredundant}. More specifically,  if we let 
 \begin{alignat*}{3}
 h^1=(0,0,0,0),\; T_1=\set{\bra{1,1},\bra{1,2},\bra{2,1}};&\quad\quad\quad&h^2=(1,0,0,0),\; T_2=\set{\bra{1,2},\bra{2,1},\bra{3,3}};\\
 h^3=(1,0,0,1),\; T_3=\set{\bra{2,1},\bra{3,1},\bra{2,2}};&\quad\quad\quad&h^4=(1,1,0,1),\; T_4=\set{\bra{3,1},\bra{3,2},\bra{2,2}};\\ 
 h^5=(1,0,1,0),\; T_5=\set{\bra{1,2},\bra{2,2},\bra{1,3}};&\quad\quad\quad&h^6=(1,1,1,0),\; T_6=\set{\bra{2,2},\bra{2,3},\bra{1,3}};\\ 
 h^7=(1,1,1,1),\; T_7=\set{\bra{2,2},\bra{2,3},\bra{3,2}};&\quad\quad\quad&h^8=(0,1,1,1),\; T_8=\set{\bra{3,2},\bra{3,2},\bra{3,3}},
  \end{alignat*}
  we can check that if $\bra{\lambda,y}$ is feasible for \eqref{lastexform} and $y=h^i$ for $i\in\sidx{8}$, then $\lambda\in P\bra{T_i}$. However, the LP relaxation of \eqref{lastexform} is not equal to $Q\bra{{\mathcal{T}},H}$ for $H=\set{h^i}_{i=1}^{8}$, because all $16$ possible values for $y$ are feasible for it. In fact, if we let    
   \begin{alignat*}{3}
 &\;\,h^9=(0,1,0,0),\; \;\,\overline{T}_9=\set{\bra{1,1}};&\quad&h^{10}=(1,1,0,0),\; \overline{T}_{10}=\set{\bra{2,2}};&\quad&h^{11}=(0,0,0,1),\; \overline{T}_{11}=\set{\bra{2,1}};\\
  &h^{12}=(0,1,0,1),\; \overline{T}_{12}=\set{\bra{2,3}};&&h^{13}=(0,0,1,0),\; \overline{T}_{13}=\set{\bra{1,2}};&&h^{14}=(0,1,1,0),\; \overline{T}_{14}=\set{\bra{2,3}};\\
   &h^{15}=(1,0,1,1),\; \overline{T}_{15}=\set{\bra{2,2}};&&h^{16}=(0,0,1,1),\; \overline{T}_{16}=\set{\bra{3,3}}.
  \end{alignat*}
  we can check that if $\bra{\lambda,y}$ is feasible for \eqref{lastexform} and $y=h^i$ for $i\in\sidx{9,16}$, then $\lambda\in P\bra{\overline{T}_i}$. Furthermore,  the LP relaxation of \eqref{lastexform} is precisely 
 $Q\bra{\overline{\mathcal{T}},H}$ for $H=\set{h^i}_{i=1}^{16}$ and  $\overline{\mathcal{T}}=\set{\overline{T}_i}_{i=1}^{16}$ with $\overline{T}_i=T_i$ for all $i\in\sidx{8}$ (The assignment for $i>8$ is also depicted in Figure~\ref{newredundant}). Finally, the number of  embedding inequalities  of $Q\bra{\overline{\mathcal{T}},H}$ is $8$, while we can check that \[\size_M\bra{Q\bra{\mathcal{T},\set{h^i}_{i=1}^8}}=19\quad \text{    and    }\quad \min_{H\in \mathcal{H}_{3}(8)}\size_M\bra{Q\bra{\mathcal{T},H}}\geq 9.\]
  \end{example}
\begin{figure}[htpb]
  \begin{center}
  \includegraphics[scale=0.25]{newredundant.pdf}
  \end{center}
  \caption{Number of embedding inequalities for randomly selected encodings.}\label{newredundant}
  \end{figure}
Formulation \eqref{lastexform} in Example~\ref{lastex} managed to have a smaller size than the smallest binary encoded embedding formulation by adding an extra $0$-$1$ component to the encoding and pairing the additional vectors $h^i$ with redundant polytopes that are contained in the polytopes of the original disjunction. The following definition formally characterizes such embedding formulations that redundantly augment a disjunction.
\begin{definition}[Redundant Embedding Formulation]\label{redundantdef}
Let $\mathcal{P}:=\set{P^i}_{i=1}^n$ and $\overline{\mathcal{P}}=\set{\overline{P}^i}_{i=1}^r$ be two finite families of polyhedra in $\Real^d$ satisfying Assumption~\ref{ass1}. We say $\overline{\mathcal{P}}$ is a \emph{redundant representation} of $\mathcal{P}$ if $r\geq n$
 and $\bigcup_{i=1}^r \overline{P}^i=\bigcup_{i=1}^n P^i$.  

Let $k\geq \left\lceil \log_2 r\right\rceil$, $H\in \mathcal{H}_k(r)$ and $\overline{\mathcal{P}}=\set{\overline{P}^i}_{i=1}^r$  be a redundant representation of $\mathcal{P}$. The \emph{redundant embedding formulation} for disjunctive constraint $x\in \bigcup_{i=1}^n P^i$ associated to $H$ and $\overline{\mathcal{P}}$ is 
 \[ \bra{x,y}\in Q\bra{\overline{\mathcal{P}},H},\quad y\in \mathbb{Z}^k.\] 
\end{definition}

Note that we allowed for $r$ to be equal to $n$ so that any embedding formulation is also a redundant embedding formulation. The following straightforward lemma gives a simple characterization for redundant representation for $\mathcal{V}$-formulations disjunctions introduced in Definition~\ref{vformdef}.
\begin{lemma} Let $\mathcal{T}:=\set{T_i}_{i=1}^n$ and $\overline{\mathcal{T}}:=\set{\overline{T}_i}_{i=1}^r$  be two families of subsets of a finite set $V$. Then $\mathcal{P}\bra{\overline{\mathcal{T}}}$ is a redundant representation of $\mathcal{P}\bra{\mathcal{T}}$ if and only if 
\begin{enumerate}
\item $r\geq n$,
\item for all $j \in \sidx{r}$ there exists $i\in \sidx{n}$ such that $\overline{T}_j\subseteq T_i$, and
\item for all $i\in \sidx{n}$ there exists $j \in \sidx{r}$ such that $\overline{T}_j=T_i$.
\end{enumerate}
In such case, we say that $\overline{\mathcal{T}}$ is a redundant representation of $\mathcal{T}$.
\end{lemma}

In Proposition~\ref{generalpwlprop} in Section~\ref{indepandredundsec}  we describe a redundant embedding formulation that can be used for the K1 triangulation. This formulation yields the following corollary, which shows we can nearly match the size of the smallest embedding formulation for the union-jack triangulation with a redundant embedding formulation for the K1 triangulation. 
\begin{corollary}\label{tiangcoro}Let $\mathcal{T}=\set{T_i}_{i=1}^n$ for $n=2 m^2$ be the K1 triangulation on $V=\sidx{m+1}^2$.  There exist $H\in \mathcal{H}_{k}(r)$ for $k=2 \left\lceil \log_2 \sqrt{n/2}\right\rceil+ 2\leq   \left\lceil \log_2 n\right\rceil+2$ and $r=2^k$, and a redundant representation $\overline{\mathcal{T}}=\set{\overline{T}_i}_{i=1}^r$ of $\mathcal{T}$ such that $\size_E\bra{Q\bra{\overline{\mathcal{T}},H}}=1$, $\size_B\bra{Q\bra{\overline{\mathcal{T}},H}}=\bra{\sqrt{n/2}+1}^2$ and 
\begin{equation}\label{redundantbound}
\size_M\bra{Q\bra{\overline{\mathcal{T}},H}} = 4 \left\lceil \log_2 \sqrt{n/2}\right\rceil+ 4\leq  2 \left\lceil \log_2 n\right\rceil+4.
\end{equation}
\end{corollary}
To check the computational effectiveness of the redundant embedding formulation that achieves \eqref{redundantbound} for the K1 triangulation, we repeat the experiments from Section~\ref{cddsec} for this triangulation. Again, all formulations except for the logarithmic formulation are valid for the K1 triangulation, so we just replace the later with the redundant embedding formulation instead for the formulation constructed with cddlib for the modified union-jack. The results of these experiments are presented in Figure~\ref{resfig2}. We can see that the redundant embedding formulation can provide a significant computational advantages. Unfortunately,  the formulation from Proposition~\ref{generalpwlprop} is not applicable for the modified union-jack triangulation of Section~\ref{cddsec} so we cannot compare it to the computationally generated embedding formulation considered in that section.
\begin{figure}[htpb]
    \begin{center}
  \includegraphics[scale=1]{K1Gurobi.pdf}
  \end{center}
  \caption{Solve Times for K1 Triangulation [s].}\label{resfig2}
  \end{figure}

As shown in the following straightforward proposition, an interesting property of redundant embedding formulations is that they characterize all ideal formulations which use only $0$-$1$ auxiliary variables. In particular, this shows that the redundant embedding complexity of a union of polyhedra (i.e. the natural extension of embedding complexity to redundant embedding formulations) is the size of the smallest formulation for the associated disjunctive constraint over all ideal formulations which use only $0$-$1$ auxiliary variables.

\begin{proposition}\label{idealeqembeddingprop}Let $\mathcal{P}:=\set{P^i}_{i=1}^n$ be a finite family of polyhedra in $\Real^d$ satisfying Assumption~\ref{ass1}, $k\geq \left\lceil \log_2 n\right\rceil$, $A\in \mathbb{Q}^{m\times d}$, $C\in \mathbb{Q}^{m\times k}$ and $b\in \mathbb{Q}^{m}$ be such that 
\begin{equation}
Ax+Cy\leq b,\quad y\in \set{0,1}^k
\end{equation}
is an ideal formulation for $x\in \bigcup_{i=1}^n P^i$. For each $y\in \set{0,1}^k$ let $P\bra{y}=\set{x\in \Real^d\,:\, Ax+Cy\leq b}$. Finally, let $r\geq n$ and $H:=\set{h^i}_{i=1}^r\in \mathcal{H}_k(r)$ be such that $H=\set{y\in \set{0,1}^k\,:\, P\bra{y} \neq \emptyset}$ and $\overline{P}^i=P\bra{h^i}$. Then  $\overline{\mathcal{P}}=\set{\overline{P}^i}_{i=1}^r$ is a redundant representation of $\mathcal{P}$ and
$Q\bra{\overline{\mathcal{P}},H}=\set{\bra{x,y}\in \mathbb{R}^{d+k}\,:\, Ax+Cy\leq b}$.
\end{proposition} 

\subsection{Embedding Formulations and Independent Branching Formulations}\label{indepandredundsec}

The redundant formulation that achieves bound \eqref{redundantbound} and the best computational performance in Figure~\ref{resfig2}  can be constructed through a procedure introduced in \cite{Modeling-Disjunctive-Constraints-FULL}. The resulting formulations are denoted \emph{independent branching formulations}. The following proposition shows independent branching formulations are redundant embedding formulation. 
\begin{proposition}\label{indepbranchprop}
Let $\mathcal{T}:=\set{T_i}_{i=1}^n$ be a family of subsets of a finite set $V$, and $\set{B_{k,0},B_{k,1}}_{k=1}^L$ with $B_{k,0},B_{k,1}\subseteq V$ be such that 
\begin{enumerate}
\item $B_{k,0}\cap B_{k,1}=\emptyset$ for all $k\in\sidx{L}$,
\item For all $i\in \sidx{n}$ there exist $s\in \set{0,1}^L$ such that $\bigcap_{k=1}^L B_{k,s_k}=T_i$, and
\item For all $s\in \set{0,1}^L$ there exist $i\in \sidx{n}$ such that $\bigcap_{k=1}^L B_{k,s_k}\subseteq T_i$.
\end{enumerate}
Then $\overline{\mathcal{T}}=\set{\overline{T}_s}_{s\in\set{0,1}^L}$ with $\overline{T}_s=\bigcap_{k=1}^L B_{k,s_k}$ is a redundant representation of $\mathcal{T}$. Furthermore, for $H=\set{s}_{s\in\set{0,1}^L}$ we have that $Q\bra{\overline{\mathcal{T}},H}$ is equal to 
 \begin{subequations}\label{logpaperform}
 \begin{alignat}{3}
 \sum\nolimits_{v\in V\setminus B_{k,0}} \lambda_v \leq 1-y_k,\quad
 \sum\nolimits_{v\in V\setminus B_{k,1}} \lambda_v &\leq y_k&\quad& \forall k\in \sidx{L}\\
 \sum\nolimits_{v\in V} \lambda_v &=1 \\
 \lambda_v &\geq 0 &\quad& \forall v\in V.
 \end{alignat}
 \end{subequations}
\end{proposition}
\proof{Proof.}
Following the proof of Theorem~1 in \cite{Modeling-Disjunctive-Constraints-FULL} we have that \eqref{logpaperform} is the LP relaxation of an ideal formulation. The result then follows directly from the proposition statement  and Proposition~\ref{idealeqembeddingprop}.
\Halmos\endproof
An advantage of formulation \eqref{logpaperform} is that it yields extremely simple formulations (e.g. formulation \eqref{lastexform} is a special case of \eqref{logpaperform}). In addition, if $L$ is small they can provide a significant computational advantage.  Of course, finding $\set{B_{k,0},B_{k,1}}_{k=1}^L$ with small $L$ for formulation \eqref{logpaperform} is a challenge on its own. For this reason, we end the paper showing how a small redundant embedding formulation can be constructed for various triangulations that include the K1 and union-jack triangulations. To achieve this we begin with a formal definition of a triangulation, which is based on the fact that for a fixed $m$ a  triangulation is uniquely determined by how each square in the grid associated to $\sidx{m+1}^2$ is divided into two triangles.

\begin{definition}[Grid Triangulation]\label{triangulationdef}Let $V=\sidx{m+1}^2$ and for each $r\in \sidx{m}^2$ let $g_r\in \set{1,2}$ be such that 
\begin{itemize}
\item $g_r=1$  if  square $[r_1,r_1+1]\times[r_2,r_2+1]$ is divided into top-left and lower-right triangles, and
\item $g_r=2$  if  square $[r_1,r_1+1]\times[r_2,r_2+1]$ is divided into bottom-left and top-right triangles.
\end{itemize}
The triangulation associated to $g\in \set{1,2}^{\sidx{m}^2}$ is given by 
  $\mathcal{T}=\set{S_r^{g_r},T_r^{g_r}}_{r\in\sidx{m}^2}$ such that  
\begin{alignat*}{3}
S_r^{1}&=\set{\bra{r_1,r_2},\bra{r_1,r_2+1},\bra{r_1+1,r_2+1}},\quad& T_r^{1}&=\set{\bra{r_1,r_2},\bra{r_1+1,r_2},\bra{r_1+1,r_2+1}}\\S_r^{2}&=\set{\bra{r_1,r_2},\bra{r_1,r_2+1},\bra{r_1+1,r_2}},\quad& T_r^{2}&=\set{\bra{r_1,r_2+1},\bra{r_1+1,r_2},\bra{r_1+1,r_2+1}}.
\end{alignat*}
\end{definition}
With this notation, the K1 triangulation corresponds to $g_r=2$ for all $r$ and the union-jack triangulation corresponds to $g_r=1$ when $r_1$ and $r_2$ have the same parity and $g_r=2$ when they do not. 

To construct the formulation for triangulations we also need a definition of a triangulation coloring. More precisely, we consider two colorings: one for the vertices $v\in V=\sidx{m+1}^2$ whose coordinates have the same parity, and one for the vertices whose coordinates have different parities. For both colorings we consider the same values for vertices that are connected by a diagonal of the triangulation (the line that divides a square) and different values for those that are not. Two such colorings for the K1 and union-jack triangulations are depicted in Figure~\ref{triag3}. A general coloring is formally defined as follows. 
\begin{definition}[Coloring of a Triangulation] Let 
\[
V_1=\set{\bra{i,j}\in\sidx{m+1}^2\,: \, i\equiv j \mod 2 }\quad\text{and}\quad
V_2=\set{\bra{i,j}\in\sidx{m+1}^2\,: \, i\not\equiv j \mod 2 }.\] We say a pair of labellings $C_l:V_l\to \set{0,1}$ for $l\in\set{1,2}$ is a coloring of the grid triangulation in $V=\sidx{m+1}^2$ associated to   $\set{g_r}_{r\in\sidx{m}^2}\subseteq \set{1,2}$ if and only if for all $l\in \set{1,2}$
\begin{enumerate}
\item  $C_l{\bra{i,j}}\neq C_l{\bra{i+1,j+1}}$ for all $\bra{i,j}\in V_l\cap \sidx{m}^2$ such that $g_{\bra{i,j}}=2$
\item  $C_l{\bra{i+1,j}}= C_l{\bra{i,j+1}}$ for all $\bra{i,j}\in V_l\cap \sidx{m}^2$ such that $g_{\bra{i,j}}=2$, 
\item  $C_l{\bra{i+1,j}}\neq C_l{\bra{i,j+1}}$ for all $\bra{i,j}\in V_l\cap \sidx{m}^2$ such that $g_{\bra{i,j}}=1$, and
\item    $C_l{\bra{i,j}}= C_l{\bra{i+1,j+1}}$ for all $\bra{i,j}\in V_l\cap \sidx{m}^2$ such that $g_{\bra{i,j}}=1$.
\end{enumerate}
\end{definition}
\begin{example}
Figure~\ref{triag3} shows colorings  for the K1 and union-jack triangulations. Elements in $V_1$ are marked with circles, elements in $V_2$ are marked with diamonds and the associated labels are shown inside these shapes. For general $m$ the coloring for the K1 triangulation is given by 
\begin{itemize}
\item $C_1\bra{i,j}=0$ if $i+j \equiv 2 \mod 4$ and $C_1\bra{i,j}=1$ if $i+j \equiv 0 \mod 4$ and, 
\item  $C_2\bra{i,j}=0$ if $i+j \equiv 3 \mod 4$ and $C_2\bra{i,j}=1$ if $i+j \equiv 1 \mod 4$. 
\end{itemize}
For general $m$ the coloring for the union-jack triangulation is given by 
\begin{itemize}
\item $C_1\bra{i,j}=0$ for all $\bra{i,j}\in V_1$ and, 
\item  $C_2\bra{i,j}=0$ if $i \equiv 0 \mod 2$ and $j \equiv 1 \mod 2$ and $C_2\bra{i,j}=1$ if $i \equiv 1 \mod 2$ and $j \equiv 0 \mod 2$. 
\end{itemize}
\end{example}
\begin{figure}[htpb]
  \begin{center}
  \subfigure[For K1 Triangulation for $m=2$.]{\label{triag3a}\quad\quad\includegraphics[scale=.5]{K1color.pdf}\quad\quad}
    \subfigure[For Union-Jack Triangulation for  $m=2$.]{\label{triag3b}\quad\quad\includegraphics[scale=.5]{J1color.pdf}\quad\quad}
  \end{center}
  \caption{Colorings of Grid Triangulations.}\label{triag3}
  \end{figure}

Finally, given a triangulation coloring we obtain a redundant embedding formulation through the following simple corollary of Proposition~\ref{indepbranchprop}.

\begin{corollary}\label{generalpwlprop} Let 
\begin{itemize}
\item $C_l:V_l\to  \set{0,1}$ for $l\in\set{1,2}$ be a coloring of a grid triangulation, and 
\item $H=\set{h^i}_{i=1}^m\subseteq \set{0,1}^{\lceil \log_2 m\rceil}$ be a gray code.
\end{itemize}
 Then a redundant embedding formulation for $\bigcup_{i=1}^n P\bra{T_i}$ is given by 
 \begin{subequations}\label{smalembpwl2d}
 \begin{alignat}{3}
  \sum\nolimits_{v \in V_l\,:\, C_l(v)=0} \lambda_{v}\leq 1-y^l,\quad
  \sum\nolimits_{v \in V_l\,:\, C_l(v)=1} \lambda_{v}&\leq \phantom{-}y^l&& \forall l\in \set{1,2},\label{smalembpwl2d2}\\
    \label{ggg1}\sum\nolimits_{i=1}^m\bra{-h^1_k\lambda_{\bra{1,i}}-\sum\nolimits_{j=2}^{m} \max\set{h^j_k,h^{j-1}_k}\lambda_{\bra{j,i}}-h^m_k\lambda_{\bra{m+1,i}}}& \leq -y_k^3 &&\forall k \in \sidx{\left\lceil \log_2 m\right\rceil}\\
\sum\nolimits_{i=1}^m\bra{h^1_k\lambda_{\bra{1,i}}+\sum\nolimits_{j=2}^{m} \min\set{h^j_k,h^{j-1}_k}\lambda_{\bra{j,i}} +h^m_k\lambda_{\bra{m+1,i}}}& \leq \phantom{-}y_k^3 &&\forall k \in \sidx{\left\lceil \log_2 m\right\rceil}\\
  \label{ggg2}\sum\nolimits_{i=1}^m\bra{-h^1_k\lambda_{\bra{i,1}}-\sum\nolimits_{j=2}^{m} \max\set{h^j_k,h^{j-1}_k}\lambda_{\bra{i,j}}-h^m_k\lambda_{\bra{i,m+1}}}& \leq -y_k^4 &&\forall k \in \sidx{\left\lceil \log_2 m\right\rceil}\\
\sum\nolimits_{i=1}^m\bra{h^1_k\lambda_{\bra{i,1}}+\sum\nolimits_{j=2}^{m} \min\set{h^j_k,h^{j-1}_k}\lambda_{\bra{i,j}} +h^m_k\lambda_{\bra{i,m+1}}}& \leq \phantom{-}y_k^4 &&\forall k \in \sidx{\left\lceil \log_2 m\right\rceil}\\
 \sum\nolimits_{v\in V} \lambda_v &=1 \\
 \lambda &\in \Real_+^V\\
  y^l&\in \set{0,1} && \forall l\in \set{1,2},\\
 y^3,y^4&\in \set{0,1}^{\lceil \log_2 m\rceil}.
 \end{alignat}
 \end{subequations}
 \end{corollary}



% \section*{Acknowledgments.}

% This research was partially supported by the National Science Foundation under grant CMMI-1351619.



\bibliographystyle{ormsv080}
\bibliography{references}

\begin{APPENDIX}{Additional Results and Omitted Proofs}



\section{Omitted Results and Proofs from Section~\ref{connectedsection}}

\subsection{Omitted Proofs}\label{appendixproofconnectedsection}

\lambdaaffLemma*
\proof{Proof.}
First note that by the definition of $Q\bra{\mathcal{T},H}$, both \eqref{simplexequality} and the constraints defining $\aff\bra{H}$ must be valid for $Q\bra{\mathcal{T},H}$.
Then, $\dim\bra{Q\bra{\mathcal{T},H}}\leq \abs{V}+\dim\bra{H}-1$ follows directly by noting that \eqref{simplexequality} is linearly independent from any equation that only consider the $y$ variables and that any equation that only considers the $y$ variables is implied by the equalities defining $\aff\bra{H}$.

For the reverse inequality let 
\begin{equation}\label{genericequation}
a\cdot \lambda +b\cdot y  =c
\end{equation}
be an arbitrary equation of $Q\bra{\mathcal{T},H}$. Suppose for a contradiction  that \eqref{genericequation} is linearly independent to \eqref{simplexequality} and the equations defining $\aff\bra{H}$. 
By subtracting multiples of \eqref{simplexequality} and the equations defining $\aff\bra{H}$ we may assume $c=0$ and $b\in L\bra{H}$. Letting $\bra{\lambda,y}=\bra{e^v,h^i}$ for $v\in T_i$ in \eqref{genericequation} we have that $b\cdot h^i=-a_v e^v$. Then, by Assumption~\ref{connectedassumption} we have that $b\cdot h^i=b\cdot h^j$ for all $i,j\in \sidx{n}$ and $a_u=a_{v}$ for all $u,v\in V$. This implies $b\cdot\bra{h^i-h^1}=0$ for all $i\in\sidx{n}$, which together with $b\in L\bra{H}$ implies $b=\bf 0$ and $a=\bf 0$. This contradicts our assumption of the linear independence of \eqref{genericequation}.
\Halmos\endproof



\HfacetpropProp*
\proof{Proof.}
Consider an inequality 
\begin{equation}\label{hineq}
b\cdot y\leq c
\end{equation}
 that is facet defining for $\conv\bra{H}$ and assume that it is facet defining for $Q\bra{\mathcal{T},H}$. Without loss of generality we may assume $b\in L(H)$ by possibly adding equations defining  $\aff\bra{H}$ to the inequality.   We will reach a contradiction by constructing a face of $Q\bra{\mathcal{T},H}$ that strictly contains the face
induced by \eqref{hineq}. To achieve this we will use the so-called \emph{facet procedure} \citep{applegate2001tsp,chvatal2013local,Espinoza2010559}.

First note that \eqref{hineq} cannot be facet defining for $Q\bra{\mathcal{T},H}$ unless \[a_v:=\min\set{ c- b\cdot h^i\,:\, i\in \sidx{n},\quad v\in T_i}=0\] for all $v\in V$ (if $a_v<0$ the inequality is invalid and if $a_v>0$ it can be strengthened by changing the coefficient of $\lambda_v$ from $0$ to $a_v$).
Now, let $I:=\set{i\in \sidx{n}\,:\, b\cdot h^i = c }$ and $i_0\in \sidx{n}\setminus I$ (such $i_0$ exists because $b\in L(H)$). Because, $c- b\cdot h^{i_0}>0$ and $a_v=0$ for all $v\in T_{i_0}$ we have that $T_{i_0}\subseteq \bigcup_{i\in I} T_i$. Then, by the assumption of non-containment between sets in $\mathcal{T}$ we must have $v_1,v_2\in T_{i_0}$ such that $v_1\neq v_2$. We have that $h^{i_0}$ is affinely independent of $\set{h^i}_{i\in I}$ (the later satisfy \eqref{hineq} at equality and the later satisfies it strictly) and hence $\bra{h^{i_0},e^{v_2}}$ is affinely independent of $\set{\bra{h^{i},e^{v}}\,:\,{i\in I,\;v\in T_i}}\cup \set{\bra{h^{i_0},e^{v_1}}}$. Then there exist $\bar{c}\in \Real$, $\bar{b}\in \Real^k$ and $\bar{a}\in \Real^V$ such that 
\begin{alignat}{3}
\bar{c}- \bar{b}\cdot h^i -\bar{a} \cdot \e^v&=0&\quad&\forall i\in I,\;v\in T_i\\
\bar{c}- \bar{b}\cdot h^{i_0} -\bar{a} \cdot\e^{v_1}&=0\\
\bar{c}- \bar{b}\cdot h^{i_0} -\bar{a} \cdot\e^{v_2}&>0.
\end{alignat}
Let $A=\set{\bra{i,v}\in \sidx{n}\times V\,:\, i\in \sidx{n},\quad v\in T_i,\quad \bar{c}- \bar{b}\cdot h^{i} -\bar{a} \cdot\e^{v}<0}$. If $A=\emptyset$ then $\bar{a} \cdot\lambda+ \bar{b}\cdot y  \leq\bar{c}$ is valid for  $Q\bra{\mathcal{T},H}$ and it defines a proper face ($\bra{h^{i_0},\e^{v_2}}$ satisfies it strictly). Furthermore, the face it defines strictly contains the face defined by \eqref{hineq} (it contains the extra point $\bra{h^{i_0},\e^{v_1}}$). This contradicts \eqref{hineq} being a facet. If $A\neq \emptyset $ let 
\[\alpha :=\max_{\bra{i,v}\in A} \frac{\bar{a} \cdot\e^{v} +\bar{b}\cdot h^{i} -\bar{c}}{c- b\cdot h^i}>0\]
and let $\bra{i^*,v^*}$ one element in $A$ than achieves this maximum. Then $\bar{a} \cdot\lambda+ \bra{\bar{b}+\alpha b}\cdot y  \leq\bar{c}+\alpha c$ is valid for  $Q\bra{\mathcal{T},H}$ and  it defines a proper face ($\bra{h^{i_0},\e^{v_2}}$ satisfies it strictly). Furthermore, the face it defines strictly contains the face defined by \eqref{hineq} (it contains the extra point $\bra{h^{i^*},\e^{v^*}}$). This again contradicts \eqref{hineq} being a facet.
\Halmos\endproof

\subsection{Omitted Results}\label{appendixresconnectedsection}


To analyze the cases when inequalities $\lambda_v\geq 0$ are facet defining we require the following definition. 

\begin{definition} We say $v\in V$ is a cut vertex of $\mathcal{T}$ if $\mathcal{T}':=\set{T_i\setminus \set{v}}_{i=1}^n$ does not satisfy connectedness assumption \ref{connectedassumption}.
\end{definition}

The following lemma is a direct generalization of one direction of Proposition~7 from \cite{lee01}. 

\begin{lemma}\label{cutvertexlemma}Let $H:=\set{h^i}_{i=1}^n\in \mathcal{H}_k(n)$ and $\mathcal{T}:=\set{T_i}_{i=1}^n$ satisfy Assumptions~\ref{assumption0} and \ref{connectedassumption}, and  $\abs{T_i}\geq 2$ for all $i\in \sidx{n}$ such that $v\in T_i$ and $v\in V$ is not a cut vertex of $\mathcal{T}$.  Then $\lambda_v\geq 0$ describes a facet of $Q\bra{\mathcal{T},H}$.
\end{lemma}
\proof{Proof.} Inequality $\lambda_v\geq 0$ describes a face of $Q\bra{\mathcal{T},H}$ as it is a valid inequality for it and is satisfied at equality for all points $\bra{e^u,h^i}$
for $u\in T_i\setminus \set{v}$. Let 
\begin{equation}\label{genericineql2222}
 a\cdot\lambda + b\cdot y\leq c 
\end{equation}
be a valid inequality of $Q\bra{\mathcal{T},H}$ that induces a facet containing the face induced by $\lambda_v\geq 0$. Without loss of generality we may again assume $c=0$ and $b\in L\bra{H}$. Because $v$ is not a cut vertex, \eqref{genericineql2222} is satisfied at equality by $\bra{e^u,h^i}$
for $u\in T_i\setminus \set{v}$, $T_i\setminus \set{v}\neq \emptyset $ for all $i\in \sidx{n}$ and Assumption~\ref{connectedassumption}, we have that $b\cdot h^i=b\cdot h^j$ for all $i,j\in \sidx{n}$ and $a_u=a_{u'}$ for all $u,u'\in V\setminus \set{v}$. This implies $b\cdot\bra{h^i-h^1}=0$ for all $i\in\sidx{n}$, which together with $b\in L\bra{H}$ implies $b=\bf 0$ and $a_u=0$ for all $u\in V\setminus\set{v}$. Validity of \eqref{genericineql2222} implies $a_v\leq 0$ and being facet defining further implies $a_v<0$. Then \eqref{genericineql2222} is a positive multiple of $\lambda_v\geq 0$  and hence $\lambda_v\geq 0$ is facet defining.   
\Halmos\endproof


For a case where condition $\abs{T_i}\geq 2$ does not hold and there exists $v\in V$, which is not a cut vertex, but $\lambda_v\geq 0$ is not facet defining see Example~\ref{boundsexample}. Further analysis of when $\lambda_v\geq 0$ is facet defining seems strongly dependent on the encoding used. For instance for the unary encoding we have the following result from \cite{lee01}.

\begin{lemma}[\cite{lee01}] If $H$ is the unary encoding, $\mathcal{T}:=\set{T_i}_{i=1}^n$ satisfy Assumptions~\ref{assumption0} and \ref{connectedassumption}, and $v\in V$ is  a cut vertex of $\mathcal{T}$, then $\lambda_v\geq 0$ is not facet defining for $Q\bra{\mathcal{T},H}$.
\end{lemma}

In contrast, the following example shows that determining when  $\lambda_v\geq 0$ is not facet defining is less clear  for binary encodings. 
\begin{example} Let $\mathcal{T}$ be an SOS2 constraint on  $V=\sidx{5}$ and $H=\set{\bra{0,1}^T,\bra{1,1}^T,\bra{1,0}^T,\bra{0,0}^T}$. Then $\lambda_v\geq 0$ is facet defining for $Q\bra{\mathcal{T},H}$ for cut vertex $v=2$, but not for cut   vertex $v=3$.
\end{example}

The following example illustrates what can happen when the conditions of Lemma~\ref{cutvertexlemma} and Proposition~\ref{Hfacetprop} do not hold. 
\begin{example}\label{boundsexample} For $V=\set{1,2}$, $n=2$, $T_1=\set{1,2}$, $T_2=\set{1}$, $h^1=0$, $h^2=1$ we have that $v=1$ is not a cut vertex, but $\lambda_1\geq 0$ is not facet defining for $Q\bra{\mathcal{T},H}$. We also have that $y_1\geq 0$ is facet defining.
\end{example}






\section{Omitted Results and Proofs from Section~\ref{SOS2}}

\subsection{Logarithmic Formulation for SOS2 Constraints and Embedding Formulations}\label{logsos2emsec}

The LP relaxation of the logarithmic formulation for SOS2 constraints on $V=\sidx{4}$ from \cite{Modeling-Disjunctive-Constraints-FULL} is given by 
 \begin{subequations}\label{embeddingsos2exind}
\begin{alignat}{3}
 \lambda_3 \leq  y_1,\quad
 -\lambda_2 -\lambda_3-\lambda_4& \leq  -y_1 &\quad&\\
  \lambda_4 \leq  y_2, \quad\quad\quad\;
  -\lambda_3-\lambda_4& \leq  -y_2 &\quad&\\
\sum\nolimits_{i=1}^{4} \lambda_v &=1\\
\lambda_i&\geq 0 &\quad& \forall i \in \sidx{4}.
\end{alignat}
\end{subequations}
Let ${h}^1=(0,0)^T$, $T_1=\set{1,2}$,  ${h}^2=(1,0)^T$, ${T}_2=\set{2,3}$, ${h}^3=(1,1)^T$, and ${T}_3=\set{3,4}$. We can check that if $\bra{\lambda,y}$ is feasible for \eqref{embeddingsos2exind} and $y=h^i$ for $i\in\sidx{3}$, then $\lambda\in P\bra{T_i}$. However, the LP relaxation of \eqref{embeddingsos2exind} is not equal to $Q\bra{{\mathcal{T}},H}$ for $H=\set{h^i}_{i=1}^{3}$ and $\mathcal{T}=\set{T_i}_{i=1}^3$, because all $4$ possible values for $y$ are feasible for it. In fact, $Q\bra{\mathcal{T},H}$ is equal to 
 \begin{subequations}\label{embeddingsos2ex}
\begin{alignat}{3}
 \lambda_3+\lambda_4 \leq  y_1, \quad
 -\lambda_2 -\lambda_3-\lambda_4& \leq  -y_1 &\quad&\\
  \lambda_4 \leq  y_2,\quad\quad\quad\;
  -\lambda_3-\lambda_4 &\leq  -y_2 &\quad&\\
\sum\nolimits_{i=1}^{4} \lambda_v &=1\\
\lambda_i&\geq 0 &\quad& \forall i \in \sidx{4}.
\end{alignat}
\end{subequations}
As noted in \cite{MuldoonPhd}, the feasible region of \eqref{embeddingsos2ex} is smaller than that of \eqref{embeddingsos2exind} as  $\bra{\lambda,y}=\bra{0,0,0,1,0,1}^T$ is feasible for  \eqref{embeddingsos2exind}, but not for \eqref{embeddingsos2ex}. Indeed, if we let   $\overline{h}^4=(0,1)^T$ and $\overline{T}_4=\set{4}$ we can check that if $\bra{\lambda,y}$ is feasible for \eqref{embeddingsos2exind} and $y=h^4$, then $\lambda\in P\bra{\overline{T}_4}$. Furthermore,  the LP relaxation of \eqref{embeddingsos2exind} is precisely 
 $Q\bra{\overline{\mathcal{T}},H}$ for $H=\set{h^i}_{i=1}^{4}$ and  $\overline{\mathcal{T}}=\set{\overline{T}_i}_{i=1}^{4}$ with $\overline{T}_i=T_i$ for all $i\in\sidx{3}$. Hence, the logarithmic formulation for SOS2 constraints \cite{Modeling-Disjunctive-Constraints-FULL}  fits Definition~\ref{redundantdef}. This is formalized by Proposition~\ref{indepbranchprop} as the logarithmic formulation for SOS2 constraints is an independent branching formulation \citep{Modeling-Disjunctive-Constraints-FULL}.


\subsection{Omitted Proof from Section~\ref{graphsec}}\label{omproofapendix}




To prove Proposition~\ref{antigraylemma} we need the following definition.

\begin{definition} Let $n=2^k$ for some $k\in \Int$. We say $H=\set{h^i}_{i=1}^{n}\in \mathcal{H}_{k}(n)$ is a \emph{anti-gray code}\footnote{The class of codes obtained by switching $n$ and $n-1$ in this definition is sometimes also referred to as anti-gray code.} if and only if $\sum\nolimits_{j=1}^{k} \abs{h^{2i-1}_j-h^{2i}_j}=n $ for all $i\in \sidx{ n/2}$ and $\sum\nolimits_{j=1}^{k} \abs{h^{2i}_j-h^{2i+1}_j}=n -1 $ for all $i\in \sidx{n/2-1}$.
\end{definition}

Anti-gray codes exist for all $k$ and can easily be constructed from gray codes (e.g. \cite{robinson1981counting}).  

\antigraylemmaLem*
\proof{Proof.}
Let $H$ be an anti-gray code and $c^i=h^{i+1}-h^i$ for $i\in \sidx{n-1}$. Because $H$ is an anti-gray code there exist $I\subseteq \sidx{n-1}$ with $\abs{I}=2^{k-1}$ such that $c^i\in \set{-1,1}^k$ for all $i\in I$. In addition, because $h^i\neq h^j$ for $i\neq j$ we have that $c^i\neq -c^j$ for all $i,j \in I$. Hence for all $s\in \set{-1,1}^k$ there exist $i\in I$ such that $s=c^i$ or $s=-c^i$. The result then follows from Proposition~\ref{sos1prophyper} by noting that $\set{c^i}_{i\in I}$ and $\set{\pm c^i}_{i\in I}$ span the same set of linear hyperplanes and that the number of linear hyperplanes spanned by $\set{-1,1}^k$ is equal to the number of affine hyperplanes spanned by $\set{0,1}^{k-1}$ (e.g. \cite{da2005recursivity})
\Halmos\endproof


\section{Omitted Results and Proofs from Section~\ref{pwlsecc}}

\subsection{Formulations for Piecewise Linear Functions}\label{PWLAPPENDIX}

The following direct corollary of Proposition~\ref{vformprop} shows how to construct embedding formulations for the graphs and epigraphs of piecewise linear functions of two variables. 
\begin{corollary}Let $f:[1,m+1]\to \Real$ be a continuous functions that is affine on each triangle of a grid triangulation $\mathcal{T}=\set{T_i}_{i=1}^{2m^2}$ of  $V=\sidx{m+1}^2$ (cf. Definition~\ref{triangulationdef}). Let $\gr(f):=\set{\bra{x,z}\in \Real^3\,:\, f(x)=z}$ and $\epi(f):=\set{\bra{x,z}\in \Real^3\,:\, f(x)\leq z}$. Then a disjunctive representation of $\gr(f)$ is given by  
  \begin{subequations}\label{vformexunionpwl}
      \begin{alignat}{3}
    \sum\nolimits_{v\in V}  v \lambda_{v}=x,\quad \sum\nolimits_{v\in V}  f(v) \lambda_{v}&=z&\label{vformnumpwl}\\
            \lambda&\in \bigcup_{i=1}^{2m^2} P\bra{T_i}.
    \end{alignat}
  \end{subequations}
  A disjunctive representation of $\epi(f)$ is obtained by replacing \eqref{vformnumpwl} by
  \begin{equation}
  \sum\nolimits_{v\in V}  v \lambda_{v}=x,\quad \sum\nolimits_{v\in V}  f(v) \lambda_{v}\leq z\label{vformnumpwlepi}
  \end{equation}
If $k\geq \left\lceil \log_2 2m^2\right\rceil$ and $H\in \mathcal{H}_k(n)$ then an ideal formulation of $\gr(f)$ is given by \eqref{vformnumpwl}, $\bra{\lambda,y}\in Q\bra{\mathcal{T},H} $ and $y\in \mathbb{Z}^k$. Similarly, an ideal formulation of $\gr(f)$ is given by \eqref{vformnumpwlepi}, $\bra{\lambda,y}\in Q\bra{\mathcal{T},H} $ and $y\in \mathbb{Z}^k$.
\end{corollary}
\subsection{Omitted Proof from Section~\ref{pwlsecc}}\label{unionjackcoroapendix}
\unionjackboundprop*
\proof{Proof.}
The lower bound on $\mmc\bra{\mathcal{T}}$ comes from Lemma~\ref{cutvertexlemma}. The sizes for the unary encoded formulation comes from Proposition~10 in \cite{lee01}, the comments before its statement and Proposition~\ref{idealeqembeddingprop}. The existence and sizes for the binary encoded formulation come from Propositions~\ref{idealeqembeddingprop} and \ref{generalpwlprop}.
\Halmos\endproof


\end{APPENDIX}
\end{document}


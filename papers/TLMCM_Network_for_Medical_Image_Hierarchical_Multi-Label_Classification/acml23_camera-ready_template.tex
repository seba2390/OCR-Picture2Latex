%\documentclass[wcp,gray]{jmlr} % test grayscale version
\documentclass[wcp]{jmlr}

% The following packages will be automatically loaded:
% amsmath, amssymb, natbib, graphicx, url, algorithm2e

%\usepackage{rotating}% for sideways figures and tables
\usepackage{longtable}% for long tables

% The booktabs package is used by this sample document
% (it provides \toprule, \midrule and \bottomrule).
% Remove the next line if you don't require it.
\usepackage{booktabs}
% The siunitx package is used by this sample document
% to align numbers in a column by their decimal point.
% Remove the next line if you don't require it.
%\usepackage[load-configurations=version-1]{siunitx} % newer version
%\usepackage{siunitx}
%\usepackage{natbib}

\usepackage{lineno}
%\linenumbers

% Do not comment the following commands:
\pagenumbering{gobble}
\newcommand{\cs}[1]{\texttt{\char`\\#1}}
\makeatletter
\let\Ginclude@graphics\@org@Ginclude@graphics 
\makeatother

\jmlrvolume{222}
\jmlryear{2023}
\jmlrworkshop{ACML 2023}

\title[Short Title]{TLMCM Network for Medical Image Hierarchical Multi-Label Classification}

 % Use \Name{Author Name} to specify the name.
 % If the surname contains spaces, enclose the surname
 % in braces, e.g. \Name{John {Smith Jones}} similarly
 % if the name has a "von" part, e.g \Name{Jane {de Winter}}.
 % If the first letter in the forenames is a diacritic
 % enclose the diacritic in braces, e.g. \Name{{\'E}louise Smith}

 % Two authors with the same address
 % \author{\Name{Author Name1} \Email{abc@sample.com}\and
 %  \Name{Author Name2} \Email{xyz@sample.com}\\
 %  \addr Address}

 % Three or more authors with the same address:
 \author{\Name{Meng Wu$^*$} \Email{mwu344@gatech.edu}\\
  \Name{Siyan Luo$^*$} \Email{sluo96@gatech.edu}\\
  \Name{Qiyu Wu$^*$} \Email{qwu346@gatech.edu}\\
  \addr College of Computing Georgia Tech
  \AND
  \Name{Wenbin Ouyang} \Email{wenbinoy@gmail.com}\\
  \addr Redmond WA, US 
  }


 % Authors with different addresses:
% \author{
%  \Name{Meng Wu$^*$} \Email{mwu344@gatech.edu}\\
%  \addr College of Computing Georgia Tech
%  \AND
% \Name{Siyan Luo$^*$} \Email{rocelaylaw@gmail.com}\\
%  \addr Address 2
%  \AND
% \Name{Qiyu Wu$^*$} \Email{xyz@sample.com}\\
%  \addr Address 3
%  \AND
% \Name{Wenbin Ouyang} \Email{xyz@sample.com}\\
%  \addr Address 4
% }

\editors{Berrin Yan{\i}ko\u{g}lu and Wray Buntine}

\begin{document}

\maketitle
\def\thefootnote{*}\footnotetext{These authors contributed equally to this work.}

\begin{abstract}
    Medical Image Hierarchical Multi-Label Classification (MI-HMC) is of paramount importance in modern healthcare, presenting two significant challenges: \textit{data imbalance} and \textit{hierarchy constraint}. Existing solutions involve complex model architecture design or domain-specific preprocessing, demanding considerable expertise or effort in implementation. To address these limitations, this paper proposes Transfer Learning with Maximum Constraint Module (TLMCM) network for the MI-HMC task. The TLMCM network offers a novel approach to overcome the aforementioned challenges, outperforming existing methods based on the $AU\overline{(PRC)}$(Area Under the Average Precision and Recall Curve) metric. In addition, this research proposes two novel accuracy metrics, $EMR$(Exact Match Ratio) and $HammingAccuracy$, which have not been extensively explored in the context of the MI-HMC task. Experimental results demonstrate that the TLMCM network achieves high multi-label prediction accuracy($80\%$-$90\%$) for MI-HMC tasks, making it a valuable contribution to healthcare domain applications. 
\end{abstract}
\begin{keywords}
hierarchical multi-label classification; medical image; transfer learning
\end{keywords}

\section{Introduction}

Hierarchical Multi-label Classification (HMC) is a classification task that involves hierarchically organized classes. In the domain of healthcare, the Medical Image Hierarchical Multi-label Classification (MI-HMC) is important for efficient image interpretation, retrieval, and diagnosis \cite{Cai01,Kim01}. The MI-HMC problem naturally arises in the medical industry and academia, given that X-ray images \cite{Chen01}, and microscope images \cite{Dimitrovski01} can incorporate tree-structured sub-categories. However, MI-HMC faces two key challenges: \textit{data imbalance} and  \textit{hierarchy constraint} \cite{Giunchiglia01}. Existing solutions involve complex model architectures \cite{Wehrmann01,Noor01} or domain-specific preprocessing \cite{Dimitrovski02,Quan01,pelka18}. %i.e. global single classifier with recursive regularization, separate classifiers for each node, and hybrid \cite{Wehrmann01,Noor01} 


%The task of medical image classification has become more prevalent, due to the rapid development of digital imaging in the medical domain, as it can greatly assist healthcare professionals in processing image data effectively for diagnosis, research, and teaching purposes \cite{Cai01,Kim01}. One particular task, known as the medical image Hierarchical Multi-label Classification(MI-HMC), has been playing a critical role in medical practice. For example, classifying X-ray images by assigning them labels in a predefined hierarchical structure based on biological taxonomy, enables efficient image interpretation and retrieval, and facilitates diagnosis for healthcare professionals.
 
%Thanks to the recent emergence of deep learning techniques, great progress has been made on image multi-label classification tasks in the past decade. However, the particular task of MI-HMC, although investigated in a few works of literature \cite{Yuan01,Kowsari01, Silla01}, still has yet to be thoroughly explored and studied. Formally, MI-HMC is a subtask of multi-label image classification, with the extra constraint that an image must be associated with a set of labels organized in a tree structure. The MI-HMC problem naturally arises in the medical industry and academia, given that X-ray images \cite{Chen01}, and microscope images \cite{Dimitrovski01} can incorporate tree-structured sub-categories. The two key challenges, which the MI-HMC task confronts in the same way as the generic HMC task, are data imbalance and \textit{hierarchy constraint} \cite{Giunchiglia01}. For example, deeper down the label hierarchy we expect fewer image data on a subcategory corresponding to a label node, so there might not be sufficient samples to learn for this label; on the other hand, the predication of two labels in different branches of the hierarchy tree(e.g. “chest” and “toe”) for one image should never be allowed, and this requirement is known as ``\textit{hierarchy constraint}" for HMC problems \cite{Giunchiglia01}. 

%Multiple methods have been employed to address the two challenges of the MI-HMC problem. One popular approach is to construct complicated model architecture to ensure that the hierarchical constraint must be respected \cite{Wehrmann01,Noor01}. For example, improvements in the model architectures are categorized into two types, global and local. Global models use only one classifier and leverage recursive regularization in loss function to enforce the hierarchical constraint and local approaches are the generation of a hierarchy of classifiers in which each classifier is responsible for the prediction of each node. A hybrid model architecture  \cite{Wehrmann01} which combines global and local are also explored. 
%The other common approach is to explore image characteristics with various types of feature extraction, which require complex image preprocessing and/or strong domain knowledge \cite{Dimitrovski02,Quan01}.

%However, most of these model designs add complexities and are not targeting image classifications.
% Neither approach is ideal, since it either requires considerable expertise on a specific task, or it entails substantial effort in model implementation. Moreover, it's often the case that the methods using these two approaches are usually generic solutions without the primary focus on the MI-HMC task, thus it may be effective in a statistical sense on various datasets, but may not be particularly effective on the specific MI-HMC tasks of our interest in this research.

In prior research, the emphasis has predominantly leaned towards generic solutions, often overlooking the specific intricacies of MI-HMC tasks. In our study, we introduce a novel approach, the Transfer Learning with Maximum Constraint Module (TLMCM) network, which squarely tackles the challenges inherent to the MI-HMC domain.

The TLMCM network combines a pretrained deep learning CNN model with a Maximum Constraint Module (MCM) as proposed by \cite{Giunchiglia01}. It effectively addresses the issue of data imbalance by harnessing the power of transfer learning techniques, which have previously demonstrated their efficacy on small image datasets. The MCM method we employ is meticulously designed to ensure the satisfaction of the "hierarchy constraint" in multi-label prediction results, and it boasts a straightforward implementation. One of the key advantages of the TLMCM network is that it obviates the need for extensive image preprocessing or domain-specific knowledge for feature extraction prior to model training.

% In this paper, we present a Transfer Learning with Maximum Constraint Module(TLMCM) network, which addresses the aforementioned challenges with a complete focus on the MI-HMC task. The TLMCM network combines a pretrained deep learning CNN model with a Maximum Constraint Module(MCM) \cite{Giunchiglia01}. It addresses the data imbalance issue by leveraging the transfer learning technique, which has been proven effective on small image datasets.  The employed MCM method was designed to ensure the \textit{hierarchy constraint} is satisfied on the multi-label prediction result and has straightforward implementation. The TLMCM network doesn't require any image preprocessing or domain knowledge for feature extraction, prior to the model training.

%For generic HMC tasks, it is mostly common to measure the model performance with the metric of Area Under Precision-Recall Curve($AU\overline{(PRC)}$) \cite{Giunchiglia01,Wehrmann01}. For the specific MI-HMC tasks, since each prediction can be represented by a single path in the hierarchical structure of the labels, we are able to utilize two accuracy metrics ($EMR$ and $HammingAccuracy$) \cite{Sorower01} to evaluate model performance on the MI-HMC task. We then evaluated the effectiveness of TLMCM with the three metrics on two different MI-HMC tasks on X-ray image datasets(ImageCLEF09A, ImageCLEF09D) \cite{clef}, and one auxiliary biomedical dataset(Diatom) \cite{diatom}. Our experiments show that the proposed TLMCM network brings remarkable improvements compared to the current state-of-the-art results \cite{Giunchiglia01}. Furthermore, high multi-label prediction accuracy has been achieved on all three tasks, which enables the enormous value of this research in real-world applications.

For generic HMC tasks, Area Under Precision-Recall Curve ($AU\overline{(PRC)}$) is the typical evaluation metric \cite{Giunchiglia01,Wehrmann01}. In specific MI-HMC tasks, where each prediction follows a distinct path in a hierarchical label structure, we introduce two new accuracy metrics: $EMR$ and $HammingAccuracy$ \cite{Sorower01}, for a comprehensive evaluation. We thoroughly assessed the TLMCM network using these three metrics on two MI-HMC tasks with X-ray image datasets (ImageCLEF09A and ImageCLEF09D) \cite{clef}. Our experiments demonstrate the superior performance of the TLMCM network compared to the current state-of-the-art methods \cite{Giunchiglia01}. Moreover, it achieves exceptionally high accuracy in multi-label predictions across both tasks, highlighting the practical significance of this research.

%To summarize, the main contributions of this work are the following:
%\begin{itemize}
%    \item We propose the compact TLMCM network which addresses the common challenges of the MI-HMC task. The TLMCM network has been proven very effective by its superior performance to the state-of-the-art baseline results on all three experiment tasks.  
%    \item We introduce two evaluation metrics $EMR$ and $HammingAccuracy$, which enable an intuitive interpretation of the model accuracy, for the specific task of MI-HMC. To the best of our knowledge, the metrics targeting accuracy evaluation on HMC problems have neither been widely reported nor carefully examined in the context of MI-HMC tasks.
%    \item We evaluate different transfer learning approaches with a thorough analysis of the TLMCM network for the purposes of problem understanding and implementation guidance.
%\end{itemize}

The key contributions of this work are: 1) the proposal of the compact and highly effective TLMCM network, which adeptly addresses common MI-HMC challenges and outperforms state-of-the-art methods in our experimental tasks; 2) the introduction of two novel evaluation metrics, $EMR$ and $HammingAccuracy$, facilitating intuitive accuracy assessment in the MI-HMC domain, an area where such metrics have been largely unexplored. 
%------------------------------------------------------------------------
\section{Related Work}
Current Hierarchical Multi-Label Classification (HMC) methods use local, global, or hybrid approaches. Local methods build separate classifiers for each node, while global methods use one classifier for the full hierarchy. Hybrids combine both \cite{pmlr-v80-wehrmann18a}. Recent work shows directly incorporating hierarchical information in model improves performance \cite{Giunchiglia01}. %in which constraint layers and loss functions have been used to effectively exploit this knowledge, ensuring the satisfaction of hierarchical constraints..
% In the realm of Hierarchical Multi-label Classification, existing research can be classified into local and global approaches, which vary in their methodologies for handling the label hierarchy. Local approaches involve constructing classifiers for individual nodes or levels in the hierarchy, whereas global approaches entail building a single classifier for the entire graph. In  \cite{pmlr-v80-wehrmann18a}, a hybrid model is also presented which combines both local and global optimizations. While these methods effectively capture hierarchical information, recent studies have shown that injecting hierarchical knowledge into a neural network can yield even better performance improvements. In  \cite{Giunchiglia01}, a constraint layer and loss are added to work synergistically to exploit the hierarchical knowledge which guarantees the satisfaction of hierarchical constraints. 
 For medical images, Hierarchical Medical Image Classification uses stacked deep learning models \cite{Kowsari01}, and deep Hierarchical Multi-Label Classification targets chest x-ray diagnosis \cite{Chen01}. Other work focuses on specific diseases \cite{Gour01} or body parts \cite{Hou01}.
% In the context of medical image analysis, Kowsari et al.introduced the Hierarchical Medical Image Classification model  \cite{Kowsari01}. This model employs stacks of deep learning models to provide specific insights at each level of the clinical image hierarchy. Furthermore, Chen et al. introduced a deep Hierarchical Multi-Label Classification (HMLC) method specifically tailored for Computer-Aided Diagnosis (CAD) solutions in Chest X-ray analysis  \cite{Chen01}. The HMLC approach contributes to improved diagnostic accuracy and efficiency in Chest X-ray analysis, aiding in timely and effective patient care. In addition to these general approaches, researchers have also focused on multi-label tasks specific to certain diseases, such as ophthalmological diseases  \cite{Gour01}, and targeted body parts, such as chest X-ray diagnosis  \cite{Hou01}.

%------------------------------------------------------------------------
\section{Methodology}

%In this section, we elaborate on our method in detail. %For the task of  Hierarchical Multi-Label Classification(HMC), we employ the Maximum Constraint Module(MCM) as presented in  \cite{Giunchiglia01}. %This method plays a crucial role in managing hierarchical label dependencies and enhancing the overall performance of our approach. In the realm of image classification, we harness the power of transfer learning, %a proven and successful technique, using ResNet50 pretrained on ImageNet as our backbone model \cite{He02}. %ResNet50 is widely acclaimed for its balanced trade-off between model weight and prediction performance, making it an ideal choice for transfer learning in our work. To formulate our approach, 
 We integrate the Maximum Constraint Module(MCM) as proposed in \cite{Giunchiglia01}, with the transfer learning process of a pretrained Convolutionnal Neural Network model ResNet50 \cite{He02} as the backbone. We make careful and essential adaptations to the architecture of ResNet50, for the purpose of addressing the unique challenges posed by the MI-HMC task, and further augmenting the model's capabilities in handling hierarchical multi-label classification.

%------------------------------------------------------------------------
\subsection{MCM Method}\label{sec:mcm}

A generic HMC task %with hierarchically structured labels. In such a task, every prediction
 must respect the \textit{hierarchy constraint}, i.e. for each label that is predicted to be true, all the ancestor labels as pre-defined in the hierarchy structure must also be predicted to be true \cite{Giunchiglia01}. %The concept of \textit{hierarchy constraint} could have two implications: first, the \textit{hierarchy constraint} must be satisfied in every prediction(there could be multiple ways to enforce it); second, the \textit{hierarchy constraint} could ``guide" our model in the training process so that a better model performance(e.g. accuracy) can be achieved. 
In this regard, we adopted the two key concepts proposed in  \cite{Giunchiglia01}: \textit{Max Constraint Module (MCM)} and  \textit{Maximum Constraint Loss (MCLoss)}.

Formally, for a generic HMC task with a set $S$ of $n$ labels in total, given a label $A$, let $D_A$ be the set of all labels which are the descendants of the label $A$ in the hierarchical structure, and a machine learning model $h$ predicts the label $A$ to be true with the probability of $h_A$, we then impose the MCM module on top of the output of the model $h$, such that the output of MCM for label $A$ is:
\begin{equation}\label{eq:mcm}
\operatorname{MCM}_A=\max_{B \in \mathcal{D}_A}\left(h_B\right)
\end{equation}

In addition, we can also guide the training process by incorporating the MCM constraint into the loss function of the underlying model $h$. Formally, let $y_A$ and $y_B$
be the ground truth value of label $A$ and $B$, the loss for label A is

\begin{equation}\label{eq:loss_a}
\begin{split}
\operatorname{MCLoss}_A = &-y_A \ln \left(\max _{B \in \mathcal{D}_A}\left(y_B h_B\right)\right) \\
&-\left(1-y_A\right) \ln \left(1-\mathbf{M C M}_A\right)
\end{split}
\end{equation}

Then the final loss function is defined as 

\begin{equation}\label{eq:loss_all}
\mathrm{MCLoss}=\sum_{A \in \mathcal{S}} \mathrm{MCLoss}_A
\end{equation}

According to  \cite{Giunchiglia01}, the novel $\mathrm{MCLoss}$ function could bring benefits to the gradient backpropagation to achieve a lower loss than the standard binary cross-entropy loss function.



%------------------------------------------------------------------------
\subsection{Transfer Learning}\label{sec:transferlearning}

For the backbone model, we retain the ResNet50 convolution blocks unchanged and focus on adapting the last fully-connected linear layer. %This adaptation serves two key purposes: (1) adjusting the output dimension to match the total number of possible labels, and (2) meeting the input requirements of the MCM module. 
In particular, we replace the original last layer with two fully-connected linear layers with a ReLU activation in between and a Sigmoid after. The hidden dimension is set to 256, and the output dimension is equal to the total number of labels. The Sigmoid layer converts the output scores into probabilities, as required by the MCM module.

The modified ResNet50 output is then fed into the MCM to predict the probability of truth for each label. We use the adapted loss function, $\mathrm{MCLoss}$, as defined in Equation (\ref{eq:loss_all}).
%For the generic HMC task, we can combine a machine learning model $h$ with the idea of MCM and \textit{MCLoss}, and 
The output are the probabilities for each label to be true. %Then we can choose a threshold on the probabilities to make the final prediction. 
In the specific task of MI-HMC, since the label structure is \textit{mono-hierarchical}(fully explained in the dataset description section \ref{sec:datasets}), we %don't need to choose a threshold, but instead 
just make our prediction that all labels corresponding to the \textit{maximum} probability of the MCM output are predicted to be true. %In other words, in the HMC task on medical images, the prediction for each sample is a \textit{single path} in the label hierarchy structure.
The whole architecture design is shown in Figure \ref{fig:proposed_method}.

There are two common approaches to transfer learning: (1)freezing the convolution module as the fixed feature extractor, and only training the linear classifier(ResNet50 as Fix Feature Extractor, hereafter referred to as RNFFE); (2) fine-tuning the convolution module with the pre-trained weights of the convolution module as well as the linear classifier module(ResNet50 Fine-Tuning, hereafter referred to as RNFT).
In the experiment section \ref{sec:expSetup}, we will explore whether RNFFE or RNFT is more suitable for the MI-HMC task.%, considering factors such as dataset size and similarity to the original dataset  \cite{cs231n}.

\begin{figure*}
    %\centering
    \begin{center}
    \fbox{\rule{0pt}{0.5in} \includegraphics[width=14cm]{figures/proposed_method_1.png} \rule{.08\linewidth}{0pt}}
    \end{center}
       \caption{TLMCM network architecture. The predicted labels are represented as dark blue solid circles, while the other non-predicted labels are shown as hollow circles.}
    \label{fig:proposed_method}
\end{figure*}


%------------------------------------------------------------------------
\section{Experiments}

%------------------------------------------------------------------------
\subsection{Datasets}\label{sec:datasets}

The main dataset that we used for this research is the 2009 ImageCLEF edition of the IRMA X-ray dataset \cite{clef}. 
%Many of these images are scans of old paper X-rays and do not meet current X-ray standards. Nevertheless, it still serves well for our research purposes.
Each image in the dataset was classified based on the IRMA code \cite{Lehmann01}. %This code includes four distinct classification categories: the technical code (T), representing the image modality; the directional code (D), indicating body orientations; the anatomical code (A), describing the body region examined; and the biological code (B), detailing the biological system examined. 
A classification code may consist of three or four digits, representing a \textit{mono-hierarchical} classification structure for the corresponding medical image. %For example, an A-code label of ``311" indicates the hierarchical classification of 3: ``spine", 31: ``cervical spine", 311: ``dens". 
A \textit{mono-hierarchical} label means that the classification hierarchy is a tree structure, thus each child node can only have one parent node.  
%To gain a better understanding, 
%A visual representation of a typical label hierarchical structure of the IRMA code can be seen in Fig \ref{fig:onecol}.
%A complete listing of IRMA code specifications can be found at  \cite{Lehmann01}. 

%\begin{figure}[t]
%    \begin{center}
%    \fbox{\rule{0pt}{1in}  \includegraphics[width=5cm]{figures/Hierarchical_annotation_of_medical_images.png} \rule{0.1\linewidth}{0pt}}
%    \end{center}
%       \caption {An example of hierarchy.}
%    \label{fig:long}
%    \label{fig:onecol}
%    \end{figure}
   

%In this work, we focused on the anatomical(A) and directional(D) code as these two enables direct comparison with the baseline result in [citation]. To make our conclusion more convincing, we also used an auxiliary Diatom dataset[citation] and compared our model performance on it against the baseline.
%The Diatom dataset contains about 3400 microscopy greyscale images of diatoms of different categories, also labeled in a hierarchical way based on their biological taxonomy.
%Although the Diatom dataset doesn't belong to the medical image domain, it does share some common characteristics with the medical X-ray images and can be utilized to evaluate the effectiveness of our model.
In this study, our focus was directed toward evaluating the effectiveness of our model on two specific classification codes: anatomical (A) of 110 labels, and directional (D) of 36 labels. The dataset consists of 14410 images in total, and we split it into the train/validation/test set with the ratio of 70:15:15.
This dataset choice of the (A) and (D) codes also allowed for a direct comparison with the baseline results\footnote{The ImageCLEF07 datasets from their research are an older version no longer available. However, the ImageCLEF09 datasets share the same chracteristics.}. 

%The statistical summary of used datasets is shown in Table \ref{fig:data}.

%\begin{table*}
    %\begin{center}
    %\begin{tabular}{ c c c c c } 
        %\hline
        %Dataset & n & Training & Validation & Test \\
        %\hline
        %ImageCLEF09A & 110 & 10086 & 2162 & 2162\\
        %ImageCLEF09D & 36 & 10086 & 2162 & 2162\\
        %%Diatom & 398 & 2764 & 315 & 315 \\
        %\hline
    %\end{tabular}
    %\end{center}
    %\caption{Summary of datasets. Number of labels(n), and number of data points for each dataset split.}
    %\label{fig:data}
%\end{table*}

%------------------------------------------------------------------------
\subsection{Evaluation Metrics}\label{sec:metric}


%Three metrics were used to evaluate the performance of our model: Area Under the average Precision and Recall Curve($AU\overline{(PRC)}$) \cite{Giunchiglia01,Sorower01}, Exact Match Ratio($EMR$, also known as subset accuracy)  \cite{Sorower01}, and the multi-label classification accuracy($HammingAccuracy$, also known as Hamming score) \cite{Sorower01}.

Area Under the average Precision and Recall Curve($AU\overline{(PRC)}$)  \cite{Giunchiglia01,Sorower01} is most commonly used in multi-label classification and tasks, %as it has the advantage of being independent of the chosen threshold for prediction \cite{Giunchiglia01,Wehrmann01}.
and is also the metric that we used to compare with the state-of-the-art baseline results.
%For the task of MI-HMC, since all labels are structured in a \textit{mono-hierarchical} way \cite{Lehmann01}(AKA a tree), %each prediction is expressed as a single path from the root to the node that the model predicts the highest probability. In this regard, 
%Additionally, we introduce the $EMR$ and $hammingAccuracy$, which are essentially two metrics evaluating model prediction accuracy. %measured in a strict criterion and a more relaxed criterion.
%They provide a straightforward and intuitive way to understand the model performance, where the $AU\overline{(PRC)}$ usually falls short.
%The meaning of $EMR$ and $HammingAccuracy$ needs to be carefully examined. In general, in a multi-label classification task, the prediction can be fully correct, partially correct, or fully incorrect \cite{Sorower01}. The $EMR$ metric simplifies the situation by trivially ignoring the case of partially correct and just considering it incorrect. That is, the
Additionally, Exact Match Ratio($EMR$) \cite{Sorower01} is a strict accuracy metric in that the prediction is considered correct only when the set of labels of prediction exactly matches the corresponding set of labels of ground truth. Formally, the $EMR$ is computed as follows:

\begin{equation}\label{eq:emr}
EMR = \frac{1}{n} \sum_{i=1}^n I\left(Y_i=Z_i\right)
\end{equation}
where, $I$ is the indicator function, $n$ is total number of all labels, $Y_i$ is the set of ground true labels for sample $i$, and $Z_i$ is the set of predicted labels for sample $i$.

From the application perspective of the MI-HMC task, if a prediction is partially correct, it still deserves some credit. %For example, for a ground truth A-code label is ``311"(meaning spine -- cervical spine -- dens), if the prediction is ``31"(meaning spine -- cervical spine), although it doesn't precisely predict the most specific body region, it is still largely correct, and it shouldn't be treated the same way as a prediction result of e.g. ``4"(meaning upper extremity/arm), which is completely incorrect. 
In this respect, we utilize the multi-label classification $HammingAccuracy$ \cite{Sorower01}, which is defined as the following with the same meaning as all notations defined in Eq. \ref{eq:emr}:

\begin{equation}\label{eq:hamming}
HammingAccuracy=\frac{1}{n} \sum_{i=1}^n \frac{\left|Y_i \cap Z_i\right|}{\left|Y_i \cup Z_i\right|}
\end{equation}

%In this equation, $Y_i \cap Z_i$ denotes the intersection of predicted labels and ground truth labels for the $i-th$ sample, and $Y_i \cup Z_i$ denotes the union of them. In the example above, for the ground true label ``311", an extract match prediction of ``311" contributes 1.0 to the $HammingAccuracy$ calculation(same as in the $EMR$ calculation), a partially correct prediction of ``31" contributes 0.667, while an incorrect prediction of ``4" contributes 0. In this way, by giving partial credit to the partially correct prediction, 
%The metric $HammingAccuracy$ provides a more objective evaluation for the MI-HMC task.
 %Naturally, we expect the $HammingAccuracy$ would normally be higher than the $EMR$ for all multi-label classification tasks as it is a more ``relaxed" metric for accuracy calculation.

%\begin{table*}
%    \begin{center}
%    \begin{tabular}{ c c c c c } 
%        \hline
%        %Dataset & 
%        learning\_rate & weight\_decay & batch\_size & number\_of\_epoches \\
%        \hline
%        %ImageCLEF09A & 
%        5e-6 & 1e-6 & 32 & 120\\
%        %ImageCLEF09D & 5e-6 & 1e-6 & 32 & 120\\
%        %Diatom & 5e-5 & 1e-6 & 32 & 120 \\
%        \hline
%    \end{tabular}
%    \end{center}
%    \caption{Key hyper-parameters for all datasets}
%    \label{fig:hyperParameter}
%\end{table*}

%------------------------------------------------------------------------
\subsection{Experiment setup}\label{sec:expSetup}

%We ran our model on the two medical image classification tasks on ImageCLEF09A and ImageCLEF09D, and one additional task on the auxiliary dataset Diatom. For ImageCLEF09A and ImageCLEF09D, on average they have more than 100 images per label and should be considered a relatively "large" image dataset[citation]. Moreover, they are greyscale X-ray images and should be considered quite "different" from the original ImageNetdataset that the ResNet50 had been trained on. Based on these characteristics, according to [citation], we may assume a good transfer learning approach would be the RNFT as stated in section \ref{sec:transferlearning}, i.e. fine-tuning the convolution module together with the linear classifier module.
%We conducted our model evaluation on two image classification tasks: ImageCLEF09A, ImageCLEF09D. Both tasks contain more than 100 images per label and are regarded as relatively ``large" image datasets based on an empirical rule stated in  \cite{Barz01}. These datasets consist of greyscale X-ray images, which significantly differ from the original ImageNet dataset that ResNet50 was initially trained on. Considering these characteristics and based on insights from  \cite{cs231n}, the most promising transfer learning approach would be RNFT (Fine-Tuning) as described in section \ref{sec:transferlearning}. This involves fine-tuning both the convolution module and the linear classifier module.

%There is often a third approach that is rather similar to but still differs from the above-mentioned two approaches. This approach is normally known as "training from scratch", i.e. it uses the same ResNet50 architecture with the same adaptation to the linear classifier, but randomly initializes all weights, rather than getting the pre-trained weights trained on the ImageNet. Then the model is also trained on all its layers.
%As an ablation study, we also included the ``training from scratch" experiment, which involves employing the same ResNet50 architecture with the same adaptation to the linear classifier, but with all weights randomly initialized instead of using pre-trained weights on ImageNet.
%We refer to the third approach as RNRI(ResNet50 with Random Initialization) hereafter. The RNRI approach should not be considered transfer learning, as there is no ``knowledge transfer" \cite{Kim01}.

%For the purpose of comparison, 
We performed experiments with both RNFFE and RNFT on the MI-HMC tasks of ImageCLEF09A and ImageCLEF09D. We maintained the same learning rate of $5e-6$, weight decay of $1e-6$, batch size of 32 and the total number of epoches of 120 for each task. The ReLU activation was used for the linear classifier and no dropout was applied.
Then we trained the model with the Adam optimizer. %The essential hyper-parameters employed in our experiments are summarized in Table \ref{fig:hyperParameter}.

The training was completed on the Google Cloud Platform(GCP) virtual machine. We used the regular configuration of the ``n1-standard-4" machine type, and 1 NVIDIA T4 GPU.  We finished 4 training sessions(2 tasks, 2 approaches) in 10 hours, which is reasonably computationally efficient. The code is at \url{https://github.com/flowing-time/IMAGE-HMC}.
%For each task, the RNFT approach, and the RNRI approach take much longer time than the RNFFE approach. This is expected as RNFT and RNRI have much deeper architecture and more parameters to train than RNFFE.
%Overall, the MI-HMC tasks with both approaches are reasonably computationally efficient regarding training time and resource consumption.
%the training cost(time and resource consumption) is \textbf{fair} on medical image HMC task with all three approaches.
% \begin{figure*}
%     \begin{center}
%     \includegraphics[scale=0.5]{figures/ImageCLEF09A_accuracy.jpg}
%     \end{center}
%     \caption{$AU\overline{(PRC)}$, $EMR$ and $HammingAccuracy$ learning curves}
%     \label{fig:metricCurve}
% \end{figure*}


%------------------------------------------------------------------------
\subsection{Results and discussions}
The $AU\overline{(PRC)}$, $EMR$, and $hammingAccuracy$ for the tasks of ImageCLEF09A and ImageCLEF09D are summarized in Table \ref{fig:test_result}.
%Traditionally, the $AU\overline{(PRC)}$ metric has been mostly commonly used to measure the performance of the HMC tasks. As shown in Table \ref{fig:test_result}, 
On both tasks, the transfer learning approach RNFT shows a significantly higher $AU\overline{(PRC)}$ score than the baseline results of C-HMCNN(h) in  \cite{Giunchiglia01} and some other recent models with good performance(e.g. \cite{Wehrmann01}, \cite{pelka18}). %Furthermore, on the auxiliary dataset Diatom, both approaches achieved better $AU\overline{(PRC)}$ score than the baseline C-HMCNN(h) model. 
%This result clearly proves the effectiveness of our methodology.%, i.e. combining the adapted ResNet50 model with the MCM module is well suitable for the MI-HMC tasks.

\begin{table*}
    % \begin{center}
    \begin{tabular}{c|c|ccccc}
    \hline
    Task & Metric & \shortstack[c]{RNFFE} & \shortstack[c]{RNFT} & \shortstack[c]{Giunchiglia\\(2020)} & \shortstack[c]{Wehrmann\\(2018)} & \shortstack[c]{Pelka\\(2018)}\\ \hline
    ~ & $AU\overline{(PRC)}$ & 0.858  & \textbf{0.984}   & 0.956 & 0.950 & N/A\\ 
    \shortstack[c]{ImageCLEF09A} & $EMR$ & 0.449  & \textbf{0.789}  & N/A  & N/A & 0.603\\ 
    ~ & $Hamming$ & 0.642  & \textbf{0.890}  & N/A  & N/A & N/A\\ \hline
    ~ & $AU\overline{(PRC)}$ & 0.928  & \textbf{0.984} & 0.927 & 0.920 & N/A\\ 
    \shortstack[c]{ImageCLEF09D} & $EMR$ & 0.451  & \textbf{0.880}  & N/A & N/A & 0.791\\ 
    ~ & $Hamming$ & 0.636  & \textbf{0.917}  & N/A & N/A & N/A\\ \hline
        %~ & $AU\overline{(PRC)}$ & 0.806  & \textbf{0.973} & 0.758 \\ 
        %Diatom & $EMR$ & 0.355  & \textbf{0.799}  & N/A\\ 
        %~ & $Hamming$ & 0.469  & \textbf{0.875}  & N/A\\ \hline
    \end{tabular}
    % \end{center}
    \caption{Test datasets result in summarization. The best results are in bold.}
    \label{fig:test_result}
\end{table*}

%Other than $AU\overline{(PRC)}$, we also proposed to examine the 
%For the other two other metrics, %($EMR$ and $HammingAccuracy$) as defined in section \ref{sec:metric}. %These two metrics provided us with a measurement of the model accuracy with a stricter criterion of $EMR$ and a more relaxed criterion of $hammingAccuracy$.
% RNFT achieved around 80\% $EMR$, for the tasks of ImageCLEF09A %and Diatom, 
%and almost 90\% for ImageCLEF09D, albeit it is a very strict criterion. If we relax the criterion with the $hammingAccuracy$, we achieved around 90\% for both tasks. 
To the best of our knowledge, the $EMR$ and $hammingAccuracy$ metrics have not been commonly reported on the previous HMC tasks. %presumably because the accuracy for multi-label classification tasks was rather low, especially for the $EMR$
Nevertheless, our TLMCM network shows 80\% - 90\% prediction accuracy on the MI-HMC task and demonstrated its great value in real-world healthcare applications.

%(analysis the result of transfer learning)
%(Compare the AU(PRC) with the baseline).
%(Explain the meaning of EMR and Hamming).

\begin{figure*}
    \begin{center}
    \includegraphics[scale=0.3]{figures/loss_metric_combine_v2.png}
    \end{center}
    \caption{Learning curves from from the left to right: loss, $AU\overline{(PRC)}$, $EMR$, $Hamming$}
    \label{fig:learningCurve}
\end{figure*}


For a better understanding of fine-turning approaches in our methodology, we plotted the learning curves of both approaches for the ImageCLEF09A task in Figure \ref{fig:learningCurve}. The logarithmic scale is used for the loss(1st colummn), while linear scale is used for the metrics(2nd, 3rd, 4th column).
It is clearly shown that significantly lower training and validation loss can be achieved by the RNFT approach than RNFFE. %Between RNFFE and RNRI, it's interesting to see they have similar validation loss, but the RNRI is able to continuously decrease its training loss even after 120 epochs. This should be an indication that for the MI-HMC task, the RNFFE approach does not have enough model complexity to learn, thus both the training and validation curve suffers high bias error. Between RNFT and RNRI, the model complexity is the same and the only difference is weight parameter initialization, i.e. the ``knowledge transfer", and the RNFE approach clearly benefits from the transfer learning to have a ``steeper" descent of loss function value over the training iteration, and lower final loss by the end of the training phase.
%We can further examine the three metrics ($AU\overline{(PRC)}$, $EMR$, and $HammingAccuracy$) in the learning curves of Figure \ref{fig:metricCurve}. Again, the RNFT approach shows a clear advantage over RNFFE. In the first row, 
In the 2nd column, we can see RNFT quickly attains the plateau of the highest $AU\overline{(PRC)}$ score, for both the training and validation set. The 3rd and 4th columns show the prediction accuracy($EMR$ and $HammingAccuracy$) over the training iterations and the RNFT approach is again the winner. %It's noteworthy that for the RNFT approach, although the $AU\overline{(PRC)}$ and validation loss plateaus at a certain point(e.g. after 40 epochs), the model continues to push the learning loss down and ramp up the accuracy effectively, even after 120 epoches. %Both approaches even show the trends of further increasing the accuracy after 120 epochs. One can explore further with more training costs and resources, while for the purpose of the research, as the RNFT approach converges to the highest $EMR$ and $HammingAccuracy$ early, %the game-winner is already clear.
%the efficacy of our TLMCM network is already clear.

Overall, the experiments show that for the MI-HMC task, our TLMCM network is highly effective, and the transfer learning approach of fine-tuning with pretrained weights(RNFT) should be the prioritized choice, as it does not only perform best in all three metrics but also achieves the best result with the fewest training iterations.

%------------------------------------------------------------------------
\section{Conclusion}


We proposed a novel %deep neural network architecture, known as 
TLMCM network for hierarchical multi-label classification on radiological medical images. To the best of our knowledge, TLMCM network is the first method to incorporate the Maximum Constraint Module (MCM) approach and transfer learning in medical image classification, eliminating the requirement for domain-specific knowledge in medical image pre-training. Our architecture outperformed current state-of-the-art models on the benchmark tasks of ImageCLEF09A, ImageCLEF09D. Furthermore, we introduced the metrics of $EMR$ and $Hamming Accuracy$ for evaluating the performance of TLMCM network in the context of the MI-HMC problem. %, providing a more intuitive understanding of the architecture’s accuracy. 
As part of our future work, our proposed architecture can be extended to larger medical image datasets that have deeper levels of hierarchy. Additionally, we plan to evaluate the TLMCM network on HMC image datasets in other domains such as object recognition, fashion and clothing, extending its application beyond radiological medical images to explore its potential in diverse fields.

%A figure in Fig.~\ref{fig:spiral}. Please use high quality graphics for your camera-ready submission -- if you can use a vector graphics format such as \texttt{.eps} or \texttt{.pdf}.
%\begin{figure}[htp]
%\begin{center}
%\includegraphics[width=0.5\textwidth]{spiral.eps}
%\caption{A spiral.}\label{fig:spiral}
%\end{center}
%\end{figure}
%
%An example of citation~ \cite{DBLP:conf/acml/2009}.
%
%\acks{Acknowledgements should go at the end, before appendices and references. You can uncomment this for the camera-ready version on paper acceptance.}

%\bibliographystyle{plain}
\bibliography{acml23}

%\appendix
%
%\section{First Appendix}\label{apd:first}
%
%This is the first appendix.
%
%\section{Second Appendix}\label{apd:second}
%
%This is the second appendix.
% \begin{table*}
%     \begin{center}
%     \begin{tabular}{c|c|ccccc}
%     \hline
%         Task & Metric & \shortstack[c]{RNFFE} & \shortstack[c]{RNFT} & \shortstack[c]{Giunchiglia(2020)} & \shortstack[c]{Wehrmann(2018)} & \shortstack[c]{Pelka(2018)}\\ \hline
%         ~ & $AU\overline{(PRC)}$ & 0.858  & \textbf{0.984}   & 0.956 & 0.950 & N/A\\ 
%         ImageCLEF09A & $EMR$ & 0.449  & \textbf{0.789}  & N/A  & N/A & 0.603\\ 
%         ~ & $Hamming$ & 0.642  & \textbf{0.890}  & N/A  & N/A & N/A\\ \hline
%         ~ & $AU\overline{(PRC)}$ & 0.928  & \textbf{0.984} & 0.927 & 0.920 & N/A\\ 
%         ImageCLEF09D & $EMR$ & 0.451  & \textbf{0.880}  & N/A & N/A & 0.791\\ 
%         ~ & $Hamming$ & 0.636  & \textbf{0.917}  & N/A & N/A & N/A\\ \hline
%         ~ & $AU\overline{(PRC)}$ & 0.806  & \textbf{0.973} & 0.758 & N/A & N/A\\ 
%         \shortstack[c]{Diatom(auxiliary)} & $EMR$ & 0.355  & \textbf{0.799}  & N/A & N/A & N/A\\ 
%         ~ & $Hamming$ & 0.469  & \textbf{0.875}  & N/A & N/A & N/A\\ \hline
%     \end{tabular}
%     \end{center}
% \end{table*}


\end{document}

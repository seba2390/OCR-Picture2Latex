\begin{table*}[!t]
\centering

\begin{tabular}{lccc}
\hline
\textbf{Method}                        & \textbf{MNLI dev-m} & \textbf{MNLI dev-mm} & \textbf{HANS}  \\ \hline
\multicolumn{4}{l}{\textit{\textbf{Prior model-centric methods}}}                  \\ \hline
PoE \cite{karimi-mahabadi-etal-2020-end}                           & 84.58      & 84.85       & 66.31 \\ \hline
Learned-Mixin \cite{clark-etal-2019-dont}                 & 80.50      & 81.20       & 64.00 \\ \hline
Conf-reg \cite{utama-etal-2020-towards}                      & 84.60      & 85.00       & 69.10 \\ \hline
\multicolumn{4}{l}{\textit{\textbf{Prior dataset refinement methods}}}             \\ \hline
z-filter (z-aug) \cite{wu2022generating}              & \textbf{84.72}      & \textbf{85.14}       & 62.57 \\ \hline
z-filter (par-z) \cite{wu2022generating}              & 82.48      & 82.95       & 65.11 \\ \hline
z-filter (seq-z) \cite{wu2022generating}              & 82.55      & 83.17       & 67.69 \\ \hline
\multicolumn{4}{l}{\textit{\textbf{Model trained on our augment dataset}}}          \\ \hline
IBADA (second indicator)       & 84.08      & 83.94       & \textbf{68.90} \\ \hline
IBADA (update shallow model)   & 83.89      & 84.03       & 68.34 \\ \hline
IBADA (second indicator) + PoE & 84.61      & 84.22       & \textbf{69.64} \\ \hline
\end{tabular}%
\caption{Accuracy on MNLI-matched (MNLI dev-m), MNLI-mismatched (MNLI dev-mm), and HANS. Our framework effectively balances the performance on both the dev set and the challenge set. Additionally, it exhibits promising results when combined with model-centric approaches such as POE, further enhancing overall performance.}
\label{tab:mnli results}
\end{table*}
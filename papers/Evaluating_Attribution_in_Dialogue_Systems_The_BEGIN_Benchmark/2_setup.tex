
\begin{table*}[ht]
\footnotesize
    \centering
    \begin{tabular}{c L{2cm} L{2cm} l L{7cm}}
    \toprule
    & \textbf{Category} & \textbf{Frequency} & \textbf{Example} \\
    \midrule
  \multirow{10}{*}{\rotatebox[origin=c]{90}{ \texttt{\textbf{WoW}}}} &  Fully Attributable  & 23.5\% &
        Knowledge: & \textbf{Raised in Compton, California, Lamar embarked on his musical career as a teenager} under the stage name k-dot, releasing a mix-tape that garnered local attention and led to his signing with indie record label top dawg entertainment.\\
        &&
        & History: & oh, yeah. I believe I've heard about that. The album has to be good then for sure. Do you know anything else about him or rap? \\
        &&&
        \textbf{T5 Response}: & Oh yes, I know that  \textcolor{teal}{the singer was raised in Compton, California and started on his musical career as a teenager}. 
        \\ \midrule
\multirow{10}{*}{\rotatebox[origin=c]{90}{ \texttt{\textbf{CMU-DoG}}}} &  Generic & 6.4\%  &
        Knowledge: & Throughout the film, the narrative is intercut with scenes from depositions taken in the Winklevoss twins' and Saverin's respective lawsuits against Zuckerberg and Facebook. ... After everyone leaves, Zuckerberg is shown sending a friend request to Albright on Facebook and then refreshing the webpage every few seconds as he waits for her response... \\
        &&& History: & The ending seems cools. Like after all of that happens he just goes to hang out with his kids.\\
        &&& \textbf{GPT2 Response}: & \textcolor{blue}{What else do you know about Zuckerberg?}
                            \\ \midrule

     \multirow{12}{*}{\rotatebox[origin=c]{90}{ \texttt{\textbf{TopicalChat}}}}  & Not Attributable & 70.1\% & 
        Knowledge: & Television (TV) is a telecommunication medium used for transmitting moving images in monochrome (black and white) .... Ringo Starr, George Carlin, and Alec Baldwin have all narrated Thomas the Tank Engine for at least 52 episodes each. There are over 750 episodes of "Pok√©mon": That's about 50 a year for 16 years straight.\\
        &&& History: & no, I haven't watched Pokemon. My sons use to play with when they were little. Now, they use their phones looking for Pokemon in the neighborhood. It is funny.\\
        &&& \textbf{DoHA Response}: & Pokemon \textcolor{red}{appeared in TV in 1952 and it was created by Ringo Starr and directed by George Carlin. In total, there were 100 episodes}.\\

     
        \bottomrule
    \end{tabular}
    \caption{\small Examples of each of the three categories of responses included in \begindata{}. For each category, we provide an example drawn from one of the four models trained on one of the three corpora (of course, all 12 models generated all three types of responses). The dialogue corpus used to train the model and generate the response is listed vertically. Text highlighted in green indicates information that is attributable to the knowledge; text in blue does not convey any information; and text in red is hallucinated and cannot be attributed to the knowledge.}
    \label{tab:benchmark:wow_cmu_begin_dist}
\end{table*}

\section{Task, Datasets and Models}
\label{sec:setup}

In {knowledge-grounded response generation}, the system is given a dialogue history
$\mathcal{H}=(u_1, \dots, u_{n-1})$, and knowledge $\mathcal{K}_n = (k_1, \dots, k_{j})$ at turn $n$, and is expected to generate a response $\bar{u}_{n}$ that is coherent with $\mathcal{H}$ and attributable to a non-empty subset $M_n \subset \mathcal{K}_n$.  Similar to the conversational QA task \cite{choi-etal-2018-quac, reddy-etal-2019-coqa}, the system is expected to use knowledge to respond to the user query. However, since the previous utterance may be an open-ended statement rather than a direct question (see the second and third examples in Table~\ref{tab:benchmark:wow_cmu_begin_dist}), there is a wider range of possible types of informative replies compared to the conversational QA task.

\textsc{Begin} consists of responses generated by language-model-based systems trained to perform this task. This section describes the models we train on this task and the corpora we use to train them.

\subsection{Dialogue Datasets}

For all three datasets, we use the training portion to train the model, the development set to tune hyperparameters, and the test set to generate the responses that are then annotated and included in the final \begindata{} benchmark.

\paragraph{Wizard of Wikipedia (WoW)} \textsc{WoW} dialogue \cite{dinan2018wizard} takes place between a Wizard and an Apprentice. The Wizard is tasked with providing information about a particular topic and the Apprentice, in turn, is expected to seek more information.
At each turn of the conversation, the Wizard is presented with passages from Wikipedia and chooses a span from the document---typically one or two sentences---that serves as evidence supporting their response.
We omitted examples where the Wizard did not explicitly select a passage as evidence for the response or where there was no dialogue history.  We also use the ``unseen'' topic portion of the test data. Overall, we used 82722 training examples, 8800 development examples, and 3902 test examples.

\paragraph{CMU-DoG} The CMU-DoG dataset \cite{zhou-etal-2018-dataset} consists of conversations about films. Each response is expected to be grounded in a section from Wikipedia. Workers can have either asymmetric or symmetric roles. In the asymmetric setting, one worker is asked to persuade the interlocutor to watch the movie using arguments from the document where only the persuader has access to the document. In the symmetric role, workers discuss together the content of the document. In total, there are 78136, 13800 and 13796 grounded responses (training/dev/test).
  
\paragraph{TopicalChat} TopicalChat \cite{Gopalakrishnan2019} consists of dialogues about a variety of topics. Workers are provided relevant facts from Reddit, Wikipedia and news articles. Analogous to \textsc{CMU-DoG}, the data collection protocol consists of two scenarios. In the symmetric scenario, workers have access to the same knowledge source; in the asymmetric scenario, they have access to different sources. They are asked to use the information from the documents to chat knowledgeably about the topic. In total, the dataset has 134572, 8790 and 8081 grounded responses (training/dev/test).

\subsection{Dialogue Models} We consider the outputs of four different dialogue systems; by selecting a relatively wide range of systems, we hope to encounter a range of attribution errors. Two of the systems are based on plain language models, GPT2-base \cite{radford2019language} and T5-base \cite{raffel2020exploring}. %
 The remaining two systems, DoHA \cite{prabhumoye-etal-2021-focused} and \CTRL{} \cite{rashkin-etal-2021-increasing}, are specifically designed as knowledge-grounded dialogue systems. 
DoHA augments a BART-based conversational model \cite{lewis2020bart} with a two-view attention mechanism that handles  the encoded document and the dilaogue history separately during generation. \CTRL{} augments T5-base with control tokens~\cite{keskar2019ctrl} that guide the generation towards less subjective and more grounded content.  We trained these models to generate responses based on a concatenation of two inputs: an evidence span (the knowledge snippet) and the dialogue history (we only use the previous turn $u_{n-1}$). 









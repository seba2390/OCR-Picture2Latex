\begin{table*}
  \caption{
  \textbf{Application-level co-simulation results.}
  % Each validation evaluated 2000 data points (images for vision tasks and sentences for the text-generation task) evenly sampled from the corresponding dataset.
  In each test, we evaluated 2000 CIFAR-10 images (for vision tasks) or 100 WikiText-2 sentences (for text generation) that were evenly sampled from the corresponding dataset.
  % The reference accuracy is collected by running application inference on the host machine (x86). (Over 2000 evenly sampled data from the dataset.)
  % The initial and final accuracy are from the simulation on the heterogeneous platform enabled by \TLA with accelerator backends listed in the second column.
  The reference results were obtained by running tasks in the original frameworks (MxNet for ResNet-20, PyTorch for the rest).
  The original results are %measured using 
  for the initial accelerator designs, modeled in ILA.
  The updated results, where provided, were obtained by modifying the ILA specifications
  according to %to correspond to 
  design revisions suggested by the accelerator developers.
  We measured the accuracy for image classification tasks (ResNet-20, MobileNet-V2) and perplexity for text generation (LSTM-WLM).}
  % As LSTM-WLM is a text generation model, we report the perplexity of the generated text rather than classification accuracy.
  % \hl{(Please check):} Q-MobileNet is the result of applying an 8-bit quantization~\cite{jacob2017quantization} to MobileNet V2 after flexible matching, turning all matrix multiplications into quantized matrix multiplications via a pass in Relay.
  \label{tab.verif-sim}
  \centering
  \begin{small}
  \begin{tabular}{|l|c|c|c|c|r|}
  \hline
  \multicolumn{1}{|c|}{Application} &
    \multicolumn{1}{c|}{Processing Platform} &
    \multicolumn{1}{c|}{Reference Result$^\ast$} &
    \multicolumn{1}{c|}{Original Result} &
    \multicolumn{1}{c|}{Updated Result} &
    \multicolumn{1}{c|}{Avg. Sim. Time$^\dagger$} \\
    \hline \hline

  LSTM-WLM & 
    FlexASR & 
    122.15 & 
    121.97 & 
    N/A &
    22.4s \\
    \hline

%   ResMLP  & 
%     VTA & 
%     64.9\% & 
%     62.2\% & 
%     \hl{?} & 
%     56min 41s \\
%     \hline

  ResNet-20 & 
    FlexASR &
    91.55\% &
    91.50\% &
    N/A &
    11.6s \\
    
   &
    HLSCNN &
    91.55\% &
    \cellcolor[HTML]{E9CECE}29.75\% &
    \cellcolor[HTML]{DDEFDE}92.10\% &
    7min 3s \\
    
   &
    FlexASR \& HLSCNN & 
    91.55\% & 
    \cellcolor[HTML]{E9CECE}29.15\% & 
    \cellcolor[HTML]{DDEFDE}91.85\% & 
    7min 6s \\ 
    \hline

  MobileNet-V2 &
    VTA &
    92.40\% &
    89.40\% &
    N/A &
    20min 15s \\
  
   &
    FlexASR &
    92.40\% &
    92.30\% &
    N/A &
    18.1s \\

   & 
    HLSCNN & 
    92.40\% & 
    \cellcolor[HTML]{E9CECE}10.35\% & 
    \cellcolor[HTML]{DDEFDE}91.50\% & 
    20min 33s \\
    
   & 
    FlexASR \& HLSCNN & 
    92.40\% & 
    \cellcolor[HTML]{E9CECE}10.35\% & 
    \cellcolor[HTML]{DDEFDE}91.20\% & 
    21min 01s \\

  % Q-MobileNet-V2 & VTA & 91.80\% & \hl{10.80\%} & N/A & 43min 13s \\

    \hline
  \end{tabular}
  \end{small}
  \begin{tablenotes}
    \item $\ast$ The reference result does not represent the best achievable accuracy/perplexity of the model on the given dataset. This table is intended for comparing the application-level results on different processing platforms.
    \item $\dagger$ Average simulation time of running one data point (e.g., an image or a sentence) on an AMD EPYC-7532 core.
    % \item $\ddagger$ R.S.O. = issue reported; case still open.
  \end{tablenotes}
\end{table*}

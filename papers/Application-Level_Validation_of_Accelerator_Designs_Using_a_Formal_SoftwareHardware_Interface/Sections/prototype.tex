\section{\TLA Prototype Implementation}
\label{sec.prototype}

\begin{figure*}
  \centering
  \includegraphics[width=\linewidth]{Figures/prototype.pdf}
  \caption{
  \textbf{Prototype implementation of the {\TLA} flow.}
  The green boxes represent additional inputs needed for the \TLA flow. The blue boxes represent the mostly automated capabilities added by the flow. The ILA specification model can also be used to formally verify the accelerator RTL implementation (as demonstrated in prior work~\cite{huang2018instruction}). The compiler IR rewrite rules and \mapping %compiler IR--ILA rewrite 
  rules can support other 
  %be additionally leveraged for a variety of 
  compiler optimization and verification tasks.
  %\aarti{change green box label to \mapping rules}
  }
  \label{fig.prototype}
\Description{}
\end{figure*}


As a demonstration of the {\TLA} methodology, we have implemented an end-to-end compilation and simulation flow for DL applications by integrating with existing compiler frameworks and the ILAng platform~\cite{huang2019ilang}, as shown in Fig.~\ref{fig.prototype}.
Specifically, 
  our prototype is integrated into the TVM DL compiler and uses Relay
  as the representation for DL applications~\cite{chen2018tvm, roesch2019relay}.
%We identify acceleration opportunities and generate corresponding ILA instructions by first converting Relay programs into Glenside, and then performing flexible matching via equality saturation on tensor programs using \egg~\cite{smith2021pure,willsey2021egg}.
We convert Relay programs into Glenside, and then perform flexible matching via equality saturation on tensor programs using \egg~\cite{smith2021pure,willsey2021egg}.
Finally, we use ILAng for co-simulating the compiled applications.

%
%Figure~\ref{fig.prototype} shows the workflow of our prototype.

% \input{floats/fig-prototype.tex}

\paragraph{DSL Front-End}
TVM is a compiler framework for DL applications. % that provides various capabilities for expressing and optimizing DL applications.
%
We make use of TVM's model importer as the front-end for DSL programs.
%
The importer takes programs written in common DL DSLs
%frameworks and interchange formats 
(e.g., ONNX~\cite{linux2019onnx}, PyTorch~\cite{paszke2019pytorch}, and TensorFlow~\cite{abadi2016tensorflow}) and translates them into Relay.

% We use Relay~\cite{roesch2019relay} as the top-level IR to define DL models in the compilation pipeline. We choose Relay because Relay programs are functional, which simplifies compilations to other representations in subsequent compiler passes. Moreover, TVM's model importer enables us to support a diversity of models by transforming DL models defined in high-level DSLs from other DL frameworks such as PyTorch~\cite{paszke2019pytorch} and TensorFlow~\cite{abadi2016tensorflow} to Relay programs. In addition, TVM's Relay codegen allows us to inject our backend for accelerator-specific ILA instructions.

\paragraph{Flexible Matching}
%Per 
As described earlier (\S\ref{sec.method.flexible}),
  we implement flexible matching
  by translating input
  programs from Relay
  into Glenside.
Given both compiler IR rewrites and 
{\mapping}s %rules %IR-accelerator rewrites 
via Glenside, \egg explores the space of acceleration opportunities using equality saturation.
%
%Upon reaching a fixed point, an optimal rewritten program is extracted based on a given cost function.
%
%Here, as a proof of concept, we implemented a cost function that maximizes the number of accelerator operations;
%we leave cost functions that best correspond to measures of performance for future work.
%
%(We leave implementing a precise cost function to developers, as that is not the focus of this paper.)


% We implement Flexible Matching, a pattern matching algorithm that explores opportunities for calling the accelerators by applying Equality Saturation on the imported model. 
% Unlike the syntactic pattern matching used in BYOC~\cite{chen2020byoc}, Flexible Matching exposes and matches computations, even don't match with the pattern syntactically, supported by target accelerators by exploring the space of equivalent model implementations.
% During the flexible matching pass, the imported model is compiled to Glenside~\cite{smith2021pure}, a pure tensor-level IR, and represented as an egraph.
% Leveraging the egg~\cite{willsey2021egg} Equality Saturation framework, we apply term rewriting rules on the Glenside representation to explore the space of equivalent model implementations.
% The rewrite rules are divided in two categories.
% One is Compiler IR rewrites, which transform (sub)computations of a model into equivalent forms, for example \texttt{reshape} and \texttt{transpose} reordering.
% The other is Accelerator-call rewrites, which defines transformations from the pattern of a computation supported by the target accelerator to an expression that represents invoking the corresponding accelerator function with inputs of the matched computation.
% Notice that even though there is only one left-hand-side pattern in an Accelerator-call rewrite representing the target-supported workload, our algorithm is capable to match the pattern as long as any computation semantically equivalent to the pattern appears in the model because the Compiler IR rewrites are able to expand the set of equivalent model implementations in which the target-supported workload is transformed into equivalent forms, including a version that matches with the left-hand-side pattern.
% When an Accelerator-call rewrite is fired and its left-hand-side pattern is matched, new implementations of the model with matched expressions substituted with accelerator calls are explored and memorized in the egraph representation, which discovers different ways of using the accelerator for a DL model. 
% When equality saturation reaches a fixpoint (no more equality can be found by applying rewrites rules) or egg encounters a timeout, we use a cost model to extract a \textit{canonical} representation from the egraph, which at this moment memoizes equivalent implementations from equality saturation. In order to maximize the utilization of the target accelerator, the cost model is designed such that the most number of accelerator calls can be made in the extracted model representation.

\paragraph{Code Generation}
Once flexible matching completes, the extracted rewritten program is translated back to Relay 
%(via a custom transpiler, about 700 lines of Python code) 
where accelerator 
operations %instructions 
are specially annotated. 
%Our transpiler implementation consists of about 700 lines of code, which supports a subset of Relay's syntax.
%
In our prototype, we use TVM's BYOC library~\cite{chen2021byoc}  to implement code generation (i.e., MMIO instructions and data movement code) for 
%these accelerator instructions.
these accelerator operations. 
\iffalse
\recheck{ skipped?
BYOC allows for invoking the target interface of a custom execution mechanism (e.g., an accelerator's MMIO loads/stores) by having TVM's runtime defer execution to a user-specified runtime when it reaches an annotated portion of the program.
%
We implemented a custom runtime in our prototype that dynamically produces the corresponding ILA instructions and invokes the ILAng-generated simulators.
Such a just-in-time approach allows for inspecting intermediate values in the program.
%We implemented a custom runtime that dynamically produces the corresponding ILA instructions and invokes the ILAng-generated simulators.
%
% Such a just-in-time approach helps in prototyping, as it simplifies the implementation and allows for easily inspecting intermediate values in the program.
%
(Note that BYOC also supports ahead-of-time compilation that, in principle, could eliminate the overhead from communication between the TVM runtime and the \TLA custom runtime.)
}
\fi

% BYOC allows for annotating portions of Relay programs to handle via a custom execution mechanism (such as an accelerator), providing faculties for invoking the target interface (e.g., MMIO loads/stores) by generating arbitrary C code and compiling it into a binary that is later invoked by TVM's runtime or by having TVM's runtime defer execution to a user-specified runtime when it reaches an annotated portion.
% (For the purposes of comparison, we also implement an exact matcher that recurses down Relay ASTs looking for exact syntactic matches to a pattern expression without an intermediate translation into Glenside.)
% For simplicity, our prototype uses a custom runtime to generate ILA instructions on the fly when an annotation is encountered; this approach allows for easily inspecting intermediate values in the program and invoking the ILAng-generated simulator (see below), at the expense of introducing overhead from communication between the TVM runtime, our custom {\TLA} runtime, and the simulator.
% Our runtime also supports mapping from ILA instructions to the corresponding MMIO loads and stores, which we use to invoke an implementation of FlexASR on an FPGA in Section~\ref{sec.eval-fpga}. 
% In principle, all the annotated portions could be ahead-of-time compiled into the corresponding ILA instructions via a C interface to eliminate some of the aforementioned communication overhead. 


%During execution, the TVM runtime defers those annotated operations to a custom runtime, in which the accelerator instructions are lowered to the corresponding MMIO loads and stores.


% We implement a compiler that transforms the Glenside representation of the extracted model back to a Relay program with accelerator calls annotated as done in \cite{chen2020byoc}. 
% While compiling the Relay program through TVM compilation passes, TVM recognizes the annotation and dispatches the workloads to the ILA backend, which generates ILA instructions of corresponding accelerators. During runtime, the accelerator call ILA instructions are lowered to MMIO instructions by a just-in-time compiler. 
% Finally, we leverage TVM to dispatch annotate regions to our compiler backend that generates ILA program fragments, which will then be lowered to MMIO instructions by a Just-in-time compiler. 


%\paragraph{ILA Modeling and Correctness Verification}
%
%We utilize ILAng~\cite{huang2019ilang}, an open-source platform for ILA-based modeling and verification, for developing the ILA models and performing ILA-based verification/validation.
%
%ILAng provides support for the following capabilities:
%\begin{enumerate}
  %\item (a) manually specifying and (b) semi-automatically synthesizing an ILA model~\cite{subramanyan2018template}.
  %\item refinement checking between an ILA specification and an RTL implementation.
  %\item automatic translation from semantics of ILA instructions to SMT formulas. 
  %\item generating a sound executable simulator based on the operational semantics defined by the ILA model.
%\end{enumerate}
%We use 1(a),~3, and~4 in this work.
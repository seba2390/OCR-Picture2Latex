\subsection{Identifying Acceleration Opportunities}
\label{sec.compilation-stats}

%We examined \TLA's capabilities in identifying acceleration opportunities. % using our compiler prototype.
%
We took the \AppNum DL applications, developed by different teams in different DSLs, and compiled them for the three target accelerators.
% down to \hl{a synthetic processing platform that contains a host processor and the three target accelerators}.
%
% Without any manual accelerator-specific program restructuring and modification, 
Our compiler successfully generated code that exploits the accelerators for supported computations.
%
%Furthermore, we demonstrate full-system deployment, running \TLA-generated code on physical hardware through FPGA emulation.

%\subsubsection{Portability and Flexible Matching}

Table~\ref{tab.compilation} shows the compilation statistics of using exact matching and flexible matching.
%
%It describes 
  %the application source language (Row~2) 
  %and 
  %the program complexity using the number of Relay operators as a proxy (Row~3). 
%
%It reports the number of identified accelerated operations in FlexASR, HLSCNN, and VTA when using exact/flexible matching in Rows~4-6. 
%
Note that some accelerator operators correspond to multiple Relay operators; in particular, 
%the 35-step FlexASR LSTM in LSTM-WLM is 566 operators 
the LSTM RNN in LSTM-WLM corresponds to 566 Relay operators 
and maps to \textit{one} FlexASR operator, which shows \TLA effectively overcoming a dramatic granularity mismatch between the compiler IR and accelerator operators.
%
%It also reports the corresponding statistics for using flexible matching in Rows~7-9.
%
%\hl{Computations in A, B, and C can be offloaded to accelerator X and Y.}
%
% \hl{Further, With flexible matching, the compiler optimizes D, E, and F by identifying and offloading to Z.}
%
%\hl{With no accelerator-specific modification on the programs}, 

Our results demonstrate \TLA's viability across a range of DL applications and accelerators with the successful identification of acceleration opportunities
%
%Furthermore, it provides 
and provide
evidence for the utility of flexible matching. % is useful for optimization.
%
% This demonstrates portability with the successful exploitation of accelerators without accelerator-specific modification and provides evidence that flexible matching is useful for optimization.
%
%For example, flexible matching revealed several offloads to FlexASR's linear layer in MobileNet-V2 by rewriting \texttt{add} to \texttt{nn.bias_add} (a special case of adding a vector to a tensor) when the dimensions were appropriate.
%\hl{Gus is rewriting this sentence.}
%\hl{AG: please relate text to entries/numbers in table, and add contrast with numbers for exact matching.}
%For example, flexible matching uncovered 41 offloads to FlexASR's linear layer in MobileNet-V2 by rewriting \texttt{nn.dense} to \texttt{nn.dense} followed by an add of a zero tensor.
%
For example, the linear layer rewrite %described in 
(\S\ref{sec.method.flexible})
  resulted in 66 invocations of FlexASR's linear layer
  in Transformer and 38 in ResMLP, in comparison to exact matching that produced no match. 
%Also note that 
Furthermore, certain Glenside rewrites~\cite{smith2021pure} that implement the \texttt{im2col} optimization~\cite{chellapilla2006high} 
rewrite 2D convolutions into matrix multiplications;
for VTA, this resulted in \emph{additional} 35 invocations in EfficientNet, 22 in ResNet-20, and 40 in MobileNet-V2.
Hence, flexible matching allowed us to support 2D convolutions on VTA even when 
there is no \mapping that maps 2D convolutions to VTA instructions.
%the prototype code generator did not explicitly implements 2D convolutions via VTA instructions.
%, despite the fact the prototype code generator did not explicitly implement 2D convolutions via VTA instructions.
Another rewrite
  that turns lone matrix multiplications
  into linear layers
  (by a zero-vector bias)
  works in concert with the \texttt{im2col} rewrites,
  resulting in offloads of 2D convolutions
  onto FlexASR  
  in EfficientNet, MobileNet-V2, and ResNet-20---%
  thus allowing an accelerator for NLP applications
  to also accelerate vision applications.
%result in many more offloads to VTA in that table; this is due to 2D convolutions being rewritten into matrix multiplications
%
Note that these additional acceleration opportunities
  were identified automatically
  and are examples of \textit{emergent effects} resulting from simple, reusable (accelerator-agnostic) compiler IR rewrite rules.

We additionally
  evaluate the robustness
  of flexible matching
  by comparing
%To demonstrate flexible matching robustness,
  %we used 
  the three implementations of ResNet-50
  from MLPerf~\cite{reddi2020mlperf}
  %giving the results 
  in Table~\ref{tab.compilation}, right.
Their Relay representations 
  differed in subtle ways (such as in reshaping operators)%
  \footnote{
For example, the TensorFlow implementation
  takes data in NHWC format rather than NCHW;
  Glenside can rewrite convolutions to use NCHW.}
  and are reflected in the difference in results of exact matching.
%The results highlight the robustness of flexible matching, 
Flexible matching found the same (increased) number of matches for each accelerator, regardless of its source DSL.

% We additionally assessed 
%   the ability of flexible matching to accommodate
%   differences between multiple real-world implementations 
%   %(which we term ``robustness'') 
%   of the same model,
%   %by analyzing the results 
%   %of applying flexible matching 
%   %to multiple implementations of the same model, 
%   all in different DSLs.
% Namely, we used the three implementations of ResNet-50
%   from the MLPerf benchmark~\cite{reddi2019mlperf},
%   %in PyTorch, ONNX, and TensorFlow
%   %and applied flexible matching
%   %after importing them into TVM,
%   giving the results in the right half of Table~\ref{tab.compilation}.
% The Relay representations of these models
%   differed in subtle ways (such as in reshaping operators), as indicated by the different numbers of operators in Row 3.
% In particular,
%   the TensorFlow implementation
%   takes data in NHWC format rather than NCHW,
%   which is the version used by the other implementations
%   and our exact matcher;
%   Glenside was able to rewrite its convolutions to use NCHW format,
%   thereby finding additional matches.   
% The results highlight the robustness of flexible matching, which was able to find the same increased number of matches for each accelerator, independent of the source.
% %However, when we applied flexible matching,
%   %there were fewer differences (give numbers of matches).
% %This suggests that the rewrite rules in Glenside
%   %were able to convert these different but equivalent implementations
%   %of the same model
%   %into a single representation,
%   %relieving developers of the burden of
%   %manually reconciling such differences.
% %SM Alternate text assuming results added to table 1: The results for ResNet-50 highlight the robustness of flexible matching - even with three different implementations of the model from different sources and subtle differences in their corresponding Relay representation, flexible matching was able to find the same number of matches independent of the source for each accelerator. }


% We utilized the Xilinx SDK~\cite{xsdk} to pass the accelerator instructions (i.e., MMIO commands) to the FPGA for invoking the accelerator interface and ultimately running LSTM and linear layer workloads onto the hardware. 
% The accelerator results read from the FPGA hardware exactly matched the ILA simulation -- confirming bit-level correctness of the {\TLA} methodology on a commodity hardware platform. 
% This also proves that we can rely on the ILA simulation-based approach for fast verification velocity after hardware ECOs rather than performing FPGA emulation which imposes significant engineering effort overheads. 
% \hl{Which application was this with the linear layer workload - need to mention that. Also why just this one application. Need to explain that.}


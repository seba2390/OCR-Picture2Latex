Ideally,
  accelerator development
  should be as easy as
  software development.
Several recent design languages/tools
  are working
  toward this goal,
  but actually testing early designs
  on real applications end-to-end 
  remains prohibitively difficult
  due to the costs of building specialized
  compiler and simulator support.
%This testing is critical as errors arise from differences in precise operator definitions, including numeric representations, between high-level application code and accelerator operations. Further, end-to-end testing reveals aberrant behaviors from errors accumulated over operators that per-operator unit tests miss and thus catches accelerator design issues early.
We propose a new first-in-class, mostly automated methodology 
termed ``\TLA'' %(short for ``DSLs to Accelerators''),
to enable
  end-to-end testing of prototype accelerator designs
  on unmodified source applications.
A key contribution of \TLA is the use of a formal software/hardware interface that specifies an accelerator's
  operations and their semantics. Specifically, we leverage the Instruction-Level Abstraction (ILA) formal specification for accelerators that has been successfully used thus far for accelerator implementation verification. We show how the ILA for accelerators serves as a software/hardware interface, similar to the Instruction Set Architecture (ISA) for processors, that can be used for automated development of compilers and instruction-level simulators.
  %to significantly reduce accelerator development costs. 
  Another key contribution of this work is to show how ILA-based accelerator semantics enables
  extending recent work on equality saturation
  to auto-generate basic compiler support
  for prototype accelerators in a technique we
  term ``flexible matching.''
By combining flexible matching with
  simulators auto-generated from ILA specifications,
  our approach enables end-to-end evaluation
  with modest engineering effort.
We detail several case studies
  of \TLA, which uncovered
  an unknown flaw in
  a recently published accelerator and
  facilitated its fix.
  
% %\hl{[Sharad]}
% %Emerging compute platforms are seeing an increasing use of 
% Specialized accelerators are increasingly used to meet the power-performance goals of emerging applications such as machine learning, image processing, and graph analysis. 
% %Application code running on a host processor invokes functions supported by these accelerators though "hardware function calls" which are typically provided through an API provided by the accelerator provider. These API function calls are generally made directly by the application writer, or possibly by the compiler. Each API call consists of low-level memory-mapped input-output (MMIO) instructions which read/write accelerator registers to specify operands, function invocation and read status and results. 
% Existing accelerator programming methodologies using APIs 
% %Effectively the accelerators are treated 
% %effectively treat the accelerators like peripheral devices, %. This accelerator programming methodology 
% have several limitations: 
% \begin{inlinelist}
% \item The application code lacks portability to other platforms and compiler frameworks; 
% \item the lack of integration of accelerator code in the compiler limits useful optimizations such as instruction selection and operator fusion; and 
% \item the opacity of the accelerator function semantics limits the ability to check the final code for correctness. 
% \end{inlinelist}
% % This is especially important for applications like ML where 
% %there are no standard definitions of complex functions like LSTM (Long Short-Term Memory) and 
% % accelerators often used specialized numeric representation for better power-performance to deliver acceptable results that are still considered "correct." 
% The root of these limitations is the lack of a formal software/hardware interface specification for accelerators. 

% In this paper, we use the recently developed Instruction-Level Abstraction (ILA) for accelerators to serve this purpose, similar to how the Instruction Set Architecture (ISA) has been used as the software/hardware interface for processors. 
% We propose a compiler flow termed \TLA  using the ILA and present
% % results 
% %of using a prototype based on this flow. 
% a prototype that demonstrates this flow for deep learning (DL) applications. 
% This prototype compiles programs from high-level domain-specific languages, e.g., PyTorch and MxNet, to multiple target accelerators with no target-specific extensions to the application or compiler --- thus demonstrating application portability. %We demonstrate the ease of including 
% It includes compiler optimizations through instruction selection using equality saturation-based flexible matching.
% Finally, we demonstrate checking the correctness of the resulting code through both formal verification of individual matched operations, as well as fully automated simulation-based validation of complete applications. 
% %The latter can show when specialized numerical representations in accelerators may lead to unacceptable application-level results as demonstrated through our case studies. 
% %This correctness checking exposes mismatches between the application-level and accelerator-implementation-level accuracy, which are hard to obtain in existing methodologies. \hl{IR specification vs. processor/accelerator implementation? Or application-level vs per-instruction/operator level?}
% %using low-level accelerator implementation simulation or without actual accelerator deployment. 
% The evaluation of the prototype compiler is based on \AppNum different DL applications and three different accelerators. 
% Overall, this methodology lays the foundation for integrating accelerators in compiler flows using a formal software/hardware interface.
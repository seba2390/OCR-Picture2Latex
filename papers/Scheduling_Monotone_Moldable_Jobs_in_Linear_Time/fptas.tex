\section{An FPTAS for Large Machine Counts}
\label{sec:fptas}

In this section, we present a fully polynomial approximation scheme (FPTAS)
for the case that $m \geq 8\frac{n}{\epsilon}$,
as stated in Theorem~\ref{thm:fptas}.
An FPTAS finds a $(1 + \epsilon)$-approximate solution
in time polynomial in the input length and $\frac{1}{\epsilon}$
for each $\epsilon \in (0, 1]$.
The case where $m$ is much larger than $n$ is the most interesting case
in our setting with compact input encoding,
because otherwise $m$ is polynomial in the input.
Furthermore, this allows us to focus on the case $m < 8\frac{n}{\epsilon}$
in the following chapters.

The algorithm itself is a \emph{dual approximate algorithm}~\cite{hochbaum87}.
A $c$-dual approximate algorithm accepts a number $d$ in addition to the instance as input.
It will output a solution with makespan at most~$cd$,
provided that a solution with makespan~$d$ exists.
Otherwise, it may reject the instance.
It is well known that a $c$-approximate dual algorithm with running time~$T(n, m)$
can be turned into a $(c + \epsilon)$-approximate algorithm
with running time~$\Landau{<=}{T'(n, m) + \log \frac{1}{\epsilon} \times T(n, m)}$,
where $T'(n, m)$ is the running time of an \emph{estimation} algorithm with arbitrary but constant estimation ratio.

An estimation algorithm with estimation ratio~$\rho$ computes a value~$\omega$
that estimates the minimum makespan within a factor of~$\rho$,
i.e.~$\omega \leq \OPT \leq \rho \omega$.
Here, we use an algorithm due to Ludwig and Tiwari~\cite{ludwig94}
with running time~$T'(n, m) = \Landau{<=}{n \log^2 m}$.
Although they do not explicitly state this,
their algorithm can be trivially turned into one with estimation ratio~$2$:

Their algorithm computes an allotment $a$
which allots to each job~$j \in J$ a number~$a_j$ of processors,
and this allotment minimizes the value
\begin{equation}
  \omega = \min \parens[4]{\frac{1}{m} \sum_{j \in J} \work{j}{a_j},
    \max_{j \in J} \ptm{j}{a_j}}
\end{equation}
among all allotments.
Therefore $\omega \leq \OPT$.
On the other hand, the list scheduling algorithm,
applied to the instance with the fixed allotment~$a$,
produces a schedule of makespan at most~$2 \omega$~\cite{garey75},
so $\OPT \leq 2 \omega$.


For our algorithm, we specify $c = 1 + \epsilon$,
resulting in a $1 + 2 \epsilon$ approximation ratio.
Our algorithms will frequently schedule jobs using the least number of processors
such that its processing time is below a threshold $t$.
Therefore let~$\procnum{j}{t} = \min \setst{p \in \natupto{m}}{\ptm{j}{p} \leq t}$,
see also the work of Mounié, Rapine, and Trystram~\cite{mounie07}.
Note that $\procnum{j}{t}$ can be found in time~$\Landau{<=}{\log m}$ by binary search.

The algorithm is extremely simple:
allot $\procnum{j}{(1+\epsilon) d}$ processors to each job~$j$
and schedule them simultaneously.
If this schedule requires more than $m$ machines, reject.

Clearly, the running time for the dual approximate algorithm is $\Landau{<=}{n \log m}$.
The final algorithm therefore requires
$\Landau{<=}{n \log m (\log m + \log \frac{1}{\epsilon})}$ time.


\subsection{Analysis}

It remains to show that the algorithm is indeed $(1+\epsilon)$-dual approximate.
The produced schedule clearly has makespan at most $(1+\epsilon) d$
by the definition of $\procnum{j}{(1+\epsilon) d}$.
To prove that the algorithm only rejects if there is no schedule with makespan~$d$,
we will argue that the produced schedule requires at most~$m$ processors,
i.e.~$\sum_{j \in J} \procnum{j}{(1+\epsilon) d} \leq m$,
provided that $d \geq d^*$,
where $d^*$~is the optimal makespan.

To this end, we consider the same algorithm with a more complex allotment rule,
which uses \emph{compression} of jobs,
our main technique for exploiting the monotony of the work functions.
Compression reduces the number of processors allotted to a job
in exchange for a bounded increase of its processing time.

\begin{lemma}
  \label{lemma:compression}
  If $j$ is a job that uses $b \geq \frac{1}{\rho}$~machines in some schedule,
  where~$\rho \in (0, 1/4]$,
  then we can free $\ceil{b\rho}$~machines and the schedule length increases
  by at most~$4\rho \ptm{j}{b}$.
\end{lemma}
We call the value $\rho$ the \emph{compression factor}.

\begin{proof}
  Formally, the statement of the lemma is
  $\ptm{j}{\floor{b(1-\rho)}} \leq (1 + 4\rho) \ptm{j}{b}$.
  For the proof we
  set~$b' = \ceil{b(1-2\rho)} \leq b$.
  Since~$b \geq \frac{1}{\rho}$ we have~$b\rho \geq 1$
  and thus~$b' \leq \floor{b(1-\rho)}$.
  This implies~$\ptm{j}{\floor{b(1-\rho)}} \leq \ptm{j}{b'}$
  Because our jobs are monotonic we have
  \begin{equation}
    \ptm{j}{b'} \times b' = \work{j}{b'} \leq \work{j}{b} = \ptm{j}{b} \times b \dpunct{.}
  \end{equation}
  Hence (and because~$1-2\rho \geq 1/2$) it follows that
  \begin{equation}
    \begin{aligned}
      \ptm{j}{b'} &\leq \ptm{j}{b} \times \frac{b}{b'} \leq \ptm{j}{b} \times \frac{b}{b(1-2\rho)} \\
      &= \ptm{j}{b} \times \parens[a]{\frac{1 - 2\rho}{1 - 2\rho} + \frac{2\rho}{1-2\rho}}  \\
      &\leq (1 + 4\rho) \ptm{j}{b}
    \end{aligned}
  \end{equation}
  and the lemma follows.
\end{proof}

Our second allotment rule has two steps.
\begin{enumerate}
  \item Allot $a_j = \procnum{j}{d}$ processors to each job~$j$.
  \item Compress each job that is allotted to at least $\frac{4}{\epsilon}$ processors
    with a factor of $\rho = \frac{\epsilon}{4}$.
\end{enumerate}
Note that $\rho \leq \frac{1}{4}$ because we assumed $\epsilon \leq 1$.
According to Lemma~\ref{lemma:compression},
each job has processing time at most $(1 + \epsilon) d$ with this allotment rule.

We claim that the resulting schedule requires at most $m$~processors.
Assume that this is not the case after the first step, i.e.~$\sum_{j \in J} a_j > m$,
otherwise the statement clearly holds.
Then the number of required processors is still bounded:

\begin{lemma}
  \label{lemma:first-step}
  If $d \geq d^*$ we have $\sum_{j \in J} a_j < m + n$.
\end{lemma}

\begin{proof}
  Let $J' = \setst{j \in J}{a_j = 1}$ and assume the statement holds
  if we remove the jobs in~$J'$ and their allotted machines,
  i.e.~$\sum_{j \in J \setminus J'} a_j < (m-\card{J'}) + (n-\card{J'})$.
  Then $\sum_{j \in J} a_j = \sum_{j \in J \setminus J'} a_j + \card{J'}
  < m + n - \card{J'} \leq m + n$.
  
  It is therefore sufficient to show the statement for jobs with $a_j > 1$.
  Assume that $d \geq d^*$.
  Then there is a schedule with makespan at most~$d$.
  For each job~$j$ let $a_j^*$ be the number of allotted processors in this schedule.
  Then $a_j \leq a_j^*$.
  Using the monotony of the work function, we have
  \begin{equation}
    \begin{aligned}
      \parens[4]{\sum_{j \in J} (a_j - 1)} d &= \sum_{j \in J} (a_j - 1)d  \\
      &< \sum_{j \in J} (a_j - 1) \ptm{j}{a_j -1} \\
      &= \sum_{j \in J} \work{j}{a_j - 1} \\
      &\leq \sum_{j \in J} \work{j}{a_j} 
       \leq \sum_{j \in J} \work{j}{a_j^*}
       \leq m d \dpunct{.}
    \end{aligned}
  \end{equation}
  Therefore $\parens[2]{\sum_{j \in J} a_j} - n = \sum_{j \in J} (a_j - 1) < m$,
  proving the lemma.
\end{proof}

Now partition the jobs into narrow and wide jobs, $J = J_N \cup J_W$.
The wide jobs are those that are compressed in the second step,
i.e.~$J_W = \setst{j \in J}{\procnum{j}{d} \geq \frac{1}{\rho}}$ and $J_N = J \setminus J_W$.
Let $\alpha = \sum_{j \in J_W} a_j$ and $\beta = \sum_{j \in J_N} a_j$.

In the second step, at least $\rho \alpha$ processors are freed.
By definition of the narrow jobs we have $\beta \leq n \frac{1}{\rho} = 4\frac{n}{\epsilon} \leq \frac{m}{2}$.
Since we assumed that $\alpha + \beta > m$ we have $\alpha > \frac{m}{2}$.
Therefore $\rho \alpha > \rho \frac{m}{2} \geq n$.
According to Lemma~\ref{lemma:first-step} we also have $\alpha + \beta \leq m + n$.
It follows that $(1-\rho)\alpha + \beta \leq m$, proving our claim.

To prove the claim about the first allotment rule,
we note that it cannot use more processors for any job, because it picks the minimum number of allotted processors when we target a makespan of $(1+\epsilon)d$.
Therefore, our algorithm is $(1+\epsilon)$-dual approximate,
proving Theorem~\ref{thm:fptas}.


\subsection{A PTAS for the General Case}

For the general case we can still achieve a PTAS.
When $m \geq 8 \frac{n}{\epsilon}$, simply use the previously described algorithm.
Otherwise apply the algorithm by Jansen and Thöle~\cite{jansen10}.
It is $(1 + \epsilon)$-approximate and has a running time polynomial in $n$ and $m$ (but exponential in $\frac{1}{\epsilon}$).
Since we use this algorithm only in the case that $m < 8 \frac{n}{\epsilon}$,
the running time is polynomial even when a compact input encoding is used for the processing times.
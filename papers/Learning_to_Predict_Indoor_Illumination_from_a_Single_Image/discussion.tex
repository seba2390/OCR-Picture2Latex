
\begin{figure}[!t]
\centering
\footnotesize
\setlength{\tabcolsep}{1pt}
\begin{tabular}{ccc}
%
\includegraphics[height=1.55cm]{images/failures/0273_input.png} & 
\includegraphics[height=1.55cm]{images/failures/0273_groundTruth_linear.png} & 
\includegraphics[height=1.55cm]{images/failures/0273_prediction_linear.png} \\
%
\includegraphics[height=1.55cm]{images/failures/1036_input.png} & 
\includegraphics[height=1.55cm]{images/failures/1036_groundTruth_linear.png} & 
\includegraphics[height=1.55cm]{images/failures/1036_prediction_linear.png} \\
%
\includegraphics[height=1.55cm]{images/failures/0021_input.png} & 
\includegraphics[height=1.55cm]{images/failures/0021_groundTruth_linear.png} & 
\includegraphics[height=1.55cm]{images/failures/0021_prediction_linear.png} \\

(a) Input photo & 
(b) Ground truth &
(c) Our prediction 
% 
\end{tabular}
\caption[]{Typical failure cases include incorrect spatial extent and orientation of light sources (often blurring them, top), scenes with complex geometry (middle), and images with strong local illumination variations (the lower half of the bottom image is lit, while the upper half is not).}
\label{f:failure-cases}
\vspace{1em}
\end{figure}


\section{Discussion}

Our main contribution in this paper is to frame illumination estimation from indoor scenes as an end-to-end learning problem. The major benefit of our approach is that it learns a direct mapping from image to lighting. Therefore, it does not make any assumption about the scene (other than it is captured indoors), it does not need to explicitly estimate other scene properties such as scene or camera geometry, nor does it need to use inverse rendering methods which are slow to optimize and prone to local minima. To make this learning possible, we introduce two additional contributions: 1) a method for detecting light sources in LDR panoramas which outperforms the state of the art; and 2) a panorama warping operation that allows us to adapt the lighting conditions for different cropped photos extracted from the panoramas. Together these steps allow us to automatically create labeled data from the SUN360 dataset~\cite{xiao-cvpr-12}, and train an LDR illumination prediction network. We fine-tuned this network using a new dataset of HDR environment maps to predict HDR scene illumination. Both quantitative and perceptual evaluations of our method show that it is significantly better than the state-of-the-art. 

\paragraph{Limitations and future work} 

While our network is good predicting at light locations, it sometimes has issues inferring the spatial extent and orientation of light sources, particularly for out-of-view lights. This might be partly caused by our in-network filtering. As a result, large area lights might be detected as smaller lights. More typically, sharp light sources get blurred out and do not create the kind of crisp cast shadows that are characteristic of them. Finally, the network can fail on images with complex, ambiguous geometric or photometric cues. Fig.~\ref{f:failure-cases} illustrates some of these scenarios. Generally speaking, the network is often better at recovering the light source locations than intensity, since the pre-training step (making the network retrieving light positions) has a much larger training set than the fine-tuning step. Also relevant is the exposure of the input LDR image, to which the light intensity estimator is much more sensitive than the light location estimator.

Our network was trained to predict light intensities and we used a simple scheme to assign color. Needless to say, light color plays an important role in image appearance, and we would like to robustly infer it too. We trained our network to predict one lighting solution for an input image. However, as noted previously, indoor illumination is localized in nature, and might vary even within an image (fig.~\ref{f:failure-cases}, bottom). Our long-term goal is to be able to recover this spatially-varying lighting distribution---a challenging problem that will certainly require datasets annotated with geometry and illumination.

Finally, while our work looks at only problem of lighting estimation, this problem is closely related to other scene inference tasks like geometric reconstruction and intrinsic images. Inferring all these properties jointly could benefit each individual task.



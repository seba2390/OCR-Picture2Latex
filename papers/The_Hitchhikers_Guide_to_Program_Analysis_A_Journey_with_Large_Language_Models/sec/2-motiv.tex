\begin{figure}[]
\hspace{-15pt}
\includegraphics[width=.5\textwidth]{figures/minted/case_sscanf.pdf}
\caption{Code snippet of \texttt{sscanf} and its usecase}
\label{fig:sscanf}
\end{figure}

\begin{table}[]
  \caption{UBITect's summary  for \texttt{sscanf}. Both \textit{use} and \textit{initialization} for \texttt{va\_args} are incorrect.
  \ding{51} and \ding{55} stand for whether this parameter will be used/initialized after its call.
   ``...'' represents all other parameters of \texttt{va\_args}.} 
  \begin{tabular}{l|ccccc}
  \toprule
   & \texttt{buf} & \texttt{fmt} & ... & \texttt{*buf} & \texttt{*fmt}  \\ \midrule
  Use & \ding{51} & \ding{51} & \ding{51} &  \ding{51} & \ding{51}  \\
  Initialize & \ding{55} & \ding{55} & \ding{55} & \ding{55} & \ding{55}\\ \bottomrule
  \end{tabular}
  \label{tab:sscanf_sum}
\end{table}


\section{Background \& Motivation}
\label{sec:moti}

% \yu{I feel we should talk about \S\ref{subsec:funda_chall} first, starting from something in high-level and then go to something in details.}

\subsection{UBITect and Motivating Example} 
\label{sec:ubitect}

% \yu{we can move it to the end of this section and change it to motivation}
UBITect is a state-of-the-art static analysis solution aiming at finding \ac{UBI} bugs in the Linux kernel~\cite{ubitect}. 
It employs a two-stage pipeline where the first stage employs a bottom-up summary-based static analysis of the Linux kernel. 
By design, this stage aims for scalability and sacrifices precision, producing a significant number of potential bugs (\ie $\sim$140k), most of which are false alarms. 
The static analysis is imprecise partly due to its lack of path sensitivity (often needed to discover UBI bugs). 
It is complemented by a second stage of static symbolic execution that filters as many false alarms as possible by verifying their path feasibility.
However, 40\% of the reported bugs are discarded due to timeout (10 minutes) or memory limitations (2 GB) during the symbolic execution, potentially missing genuine bugs.

% \haonan{explicitly say a false alarm}

% Each warning contains the name of the potential uninitialized variable, the function that defines the variable and the use of the uninitialized variable.

Figure \ref{fig:sscanf} shows a case where UBITect's static analysis stage considers it a potential UBI bug (a false alarm) and the subsequent symbolic execution stage times out and fails to generate a definitive conclusion. In other words, UBITect failed to rule out this case as a false alarm. 
%is up to the user to decide how to interpret the case. One can either conservatively ignore this potential bug or inspect it as if it is a real bug.
% In \texttt{libcfs\_ip\_str2addr}, \texttt{sscanf} gets four variables \texttt{a}, \texttt{b}, \texttt{c}, \texttt{d} at Line 3.
% Then static analysis thinks those variables may or may not be initialized inside the function call \texttt{sscanf(...)} at line 3.
% However, 
As Table \ref{tab:sscanf_sum} presents, the static analysis stage generates a summary of \texttt{sscanf()} as ``\textit{may not initialize}
parameters \texttt{a}, \texttt{b}, \texttt{c}, and \texttt{d}'' but \textit{does use them} at Line 3.
Consequently, the static analysis stage reports two locations of \textit{use-before-initialization} at Line 3 and Line 4, respectively.
% So UBITect would raise a possible UBI bug at line 4, which is a false positive generated from static analysis phase.
% As Table \ref{tab:sscanf_sum} presents 
% % \zhiyun{we have not even introduced the example yet? We should explain what the expected result is first.},
% the static analysis believes
% that parameters \texttt{a}, \texttt{b}, \texttt{c}, \texttt{d} are not initialized but used.
% \yu{remove \autoref{tab:sscanf_sum}}
% \haonan{can point out two lines?}
% This belief is incorrect in terms of use and initialization:
% UBITect fails in summarizing \texttt{sscanf} in two aspects because it is 1) 
% \zhiyun{can we be more explicit about the failure? Is it a false positive or multiple false positives??}
% \haonan{it is a timeout case, precisely inconclusive one} \zhiyun{here we are talking about static analysis only. no way it times out} \haonan{then FP for sure} \zhiyun{how many? let us be more clear about everything instead of having reviewers guess} \haonan{I see, 4 FPs for a,b,c,d} \zhiyun{at which line the FPs are reported.?} \haonan{theoretically it will have 8 warnings: 4 for Line 3 and 4 for Line 5, but UBITect does some heuristic things and we have the later 4 }
There are two reasons for the static analysis stage to consider the case a potential bug: 
1) \textbf{\textit{inability to recognize special functions}}: 
For soundness, UBITect assumed the \texttt{va\_start()} is a normal function. However, since it cannot find its definition, it has to conservatively assume that the arguments passed to it will be used inside.
Unfortunately, in reality, \texttt{va\_start} is a compiler built-in function that simply ``prepares' the arguments without any uses.
%a \texttt{va\_list} instance for accessing a variable number of arguments passed to a function. \zhiyun{I still do not understand what va\_start is doing.}
2) \textbf{\textit{insensitivity of path constraints}}: 
It fails to recognize the path constraint, \ie \texttt{if(sscanf(...)>=4)}, which ensures its arguments \texttt{a} to \texttt{d} must be initialized before use. 

% To handle this big amount of warnings
% The symbolic execution of UBITect is expected to solve the insensitivity problem.
% % but it fails for this case, and other 40\% cases.
% % Accordingly, UBITect uses symbolic execution
% In its second stage, UBITect confirms these warnings by verifying their path feasibility. 
% However, 40\% of the reported warnings are discarded due to timeout or memory limitations in symbolic execution, potentially rejecting genuine bugs.
% In this paper, we focus on these 40\% discarded cases; leveraging LLM, we provide a more confident analysis for these discarded cases and find missed bugs.
% \yu{If we focus on those discarded cases, we should not use the FP case as an example here.}


% \noindent\textbf{Motivating example.} 
% \work is motivated by a simple case in the Linux kernel:



% This code converts the ip address from a string to a number. It uses \texttt{sscanf} to get an IP address.
% We notice the program check its return value by \texttt{sscanf(...)>=4}, 
% and therefore all of \texttt{a,b,c,d} should be already initialized within the true branch. However, UBITect \cite{ubitect} will consider this code to contain "use before initialization" because it believes \texttt{a,b,c,d} may not be initialized after \texttt{sscanf}.


% \noinde nt
% Figure \ref{fig:sscanf} shows a simple IP string convert via \texttt{sscanf}.

% 

% \squishlist
\cut{

\vspace{3pt}
\noindent\textbf{Inability to Recognize Special Functions.} 
First, the report in line 4 is incorrect because there is no ``use'' of
\texttt{args} inside \texttt{sscanf()}, other than the \texttt{va\_start()} call
and \texttt{va\_end()} call in line 9 and line 11. Unfortunately, UBITect cannot
find the definition of these two functions and conservatively assumed that they
might ``use'' \texttt{args}. However, these functions are the compiler's built-in
ones that recognize variable-length arguments and no ``use'' is involved.
Instead, the semantic of \texttt{sscanf()} is to write new values into
\texttt{args} as opposed to ``use''.

\vspace{3pt}
\noindent\textbf{.} %\zhiyun{need a reference for post-condition}. 
Second, the report in line 5
is incorrect because the function summary generated by UBITect is insensitive to
, or postcondition \cite{DBLP:books/ph/Meyer97}. 
UBITect does not know the arguments \texttt{a},
\texttt{b}, \texttt{c}, \texttt{d} are always initialized if the return value is
greater than or equal to 4. Instead, its function summary is computed 
conservatively, estimating all function parameters ``may'' left uninitialized.
}

% \haonan{lack of path sensitivity}

% \yu{The reason is the limitation of less sensitivity. UBI is a summary based, forward analysis. If there is a top-down, backward analysis, it can also handle post-conditions.}





\subsection{Practical Challenges of Static Analysis}
\label{subsec:funda_chall}
% \yu{we should be more high-level, not only limit our discussion to the Linux kernel. For example, lib function for user space program analysis.}
% \yu{I think the order of three reasons should be: 1, inflexible analysis sensitivity, including Unawareness of post-conditions and Exhaustive Path Exploration. 2, Inherent Knowledge Boundaries. 3. Rigidity in Rule Expansion.}

% \haonan{and also symbolic execution}

In light of our motivating example of the \texttt{sscanf()} case, we 
can summarize the reasons for UBITect's failure as follows:
% it is infeasible to analyze functions like \texttt{sscanf} precisely.

%\squishlist
\vspace{3pt}
\noindent \textbf{Inherent Knowledge Boundaries.} 
Developers need to model specific functions or language features. Otherwise, they influence the correctness of the results. 
%omain-specific knowledge to examine specific functions and code that are otherwise non-analyzable. 
For compiler built-in functions, \eg \texttt{va\_start()}, their definitions are simply not available. %For instance, the omission of manual input for functions such as \texttt{va\_start()} can lead to inaccuracies in the static analysis, adversely impacting the overall process.
Beyond this example, there exists an array of other scenarios, which are particularly prevalent in the Linux kernel. These situations include assembly code, hardware behaviors, callback functions, concurrency, and compiler built-in functions. However, in practical terms, it is often time-consuming to discover and model all these cases, because they can be highly dependent on the analysis target and evolve over time. This limitation often compromises the effectiveness of static analysis, leaving it less precise and comprehensive than desired. 

% \cite{clangbuiltin}.
% \haonan{code functionality recognition}

\cut{
\vspace{3pt}
\noindent
\textbf{Lack of adaptability in Rule Expansion and Sensitivity Adjustment.}
%\zhiyun{consider changing the description here.}
%\haonan{I feel it is a bit weird to say the inflexibility, as it appears to be irrelevant to the precision/scalability }
Traditional static analysis tools rely on pre-defined rules that are often fixed and difficult to modify. If new rules or patterns need to be added or existing ones modified, it requires manual intervention and expertise in the underlying codebase. This lack of flexibility makes it challenging to adapt the analysis to evolving codebases or handle complex scenarios.
Even though UBITect was specifically designed to discover UBI bugs in the Linux kernel, it falls short of being aware of the postconditions to rule out false alarms.
Unfortunately, tailoring the degree of
analysis sensitivity is no less challenging, \eg it may strain the tool's scalability with increased sensitivity and add complexity to the analysis process.
}


\vspace{3pt}
\noindent \textbf{Exhaustive Path Exploration.}
% \yu{make it clear, symbolic execution or path sensitive analysis. This is the limitation of more sensitivity.}
% \haonan{this limitation is trying to say many analyzed code is unnecessary, and irrelevant to the task.}
% \haonan{Path sensitivity analysis; data-flow (in practice) imprecise.}
Correctly handling cases like \texttt{sscanf()} requires it to consider the check: \texttt{sscanf(...)>=4}. Unfortunately, 
existing path-sensitive static analysis (and symbolic execution) techniques operate under a methodical but exhaustive paradigm, exploring all potential execution paths through the codebase. While this approach is theoretically comprehensive, it often leads to a combinatorial explosion. The vast array of execution paths necessitates the exploration of myriad functions, many of which ultimately prove irrelevant to the specific analysis task at hand. 
In the \texttt{sscanf()} case, its return value is computed inside an unbounded loop when iterating over an unknown string variable \texttt{buf}.
This causes UBITect's symbolic execution to time out exactly due to this problem.
%\zhiyun{we should mention the complexity of sscanf() as an example, one loop embedded in another.}
%\zhiyun{the description should highlight the loops (variable number of iterations)}







\cut{
Static analysis techniques typically exhibit a certain level of inflexibility regarding
rule extension and context sensitivity adjustments. Adding new rules or
heuristics often means delving into the depths of the tool's codebase, requiring
expert intervention and a robust testing regime --- a process that can be
time-consuming and susceptible to error. 
Meanwhile, tailoring the degree of
context sensitivity is no less challenging, demanding a profound understanding
of the underlying analysis algorithms and potential ripple effects on the
results. Moreover, incorporating new rules or increased context
sensitivity may strain the tool's scalability, adding complexity to the
analysis process. Thus, broadening the rule set or modifying the
context sensitivity embodies a significant challenge for conventional static
analysis.
}


% \zhiyun{loops?}

% \zhiyun{Analysis of unnecessary code (larger scope than necessary). }

% \zhiyun{Lack of flexibility.}




\subsection{Capability of LLMs}
\label{subsec:cap}

Fortunately, \acp*{LLM} \cite{openai_2023_gpt_4} offers a promising
alternative to summarizing code behaviors~\cite{openai_training_2022} in a flexible way and bypassing the aforementioned challenges. This is because LLMs
are trained and aligned with extensive datasets that include both natural language and programs. 
%and show a promising understanding of program behavior summary . 
Specifically, we observe that LLMs possess fundamental abilities that assist in addressing each challenge: 1) \textit{\textbf{domain-specific code recognition}} and 2) 
\textit{\textbf{smart code summarization}}.
%and 3) \textit{\textbf{flexible rule encoding}}. 
% and they can even understand \textit{\textbf{Advanced Semantics for Programs}}

\vspace{3pt}
\noindent
\textbf{Domain-specific Programming Constructs Recognition.} 
This proficiency is showcased in three key areas: 1) \textit{\textbf{Function Recognition}}: LLMs can identify frequently used interfaces in the Linux kernel
from its semantics, such as \texttt{sscanf()}, \texttt{kzalloc()}, \texttt{kstrtoul()}, and  \textit{`list for each'}, simplifying the analysis and making the analysis more scalable.
2) \textit{\textbf{Function pointers and callbacks}}: LLMs can accurately interpret complex uses of function pointers as callbacks, which often require manual modeling. We will show an interesting case in \S\ref{subsec:case_study}.


\cut{
% LLMs
% learn to predict based on patterns in the training data, could indeed pick up
% on naming conventions or other patterns that often correlate with certain
% behaviors. 
LLMs display an impressive ability to
understand and interpret various advanced programming constructs that are specific to a domain, e.g., Linux kernel. In our own analysis, we observed LLMs are capable of recognizing several types of code patterns: 1) \textbf{\textit{Inline Assembly:}}
LLMs understand assembly instructions, helping to bridge the gap
between high-level code and machine instructions. 
This can help with summarizing the behavior of a function (which embeds inline assembly) more precisely.
2) \textit{\textbf{Function Pointers and
Callbacks:}} LLMs, like ChatGPT, have the capability to accurately interpret the
complex use of function pointers as callbacks, \eg specific callback APIs. This ability allows them to
anticipate potential impacts on the program state, thus enabling a broader and
more accurate analysis that can be difficult for static methods.
3) \textit{\textbf{Common APIs:}} LLMs recognize frequently used APIs and programming constructs in the Linux kernel, such as `list for each', \texttt{kzmalloc}, \texttt{kstrtoul} and
\texttt{get\_user\_pages\_unlocked}.
}


\vspace{3pt}
\noindent
\textbf{Smart Code Summarization.} 
LLMs can work with complicated functions;
% ignoring certain unnecessary parts while capturing the key logic. 
% \haonan{seems no reference, but the basis of our progressive prompt} \zhiyun{can you try harder? Otherwise, I am not sure if we can state this. It sounds highly speculative. I am pretty sure something similar has been said by others in the past.}
%This could be due to how it is trained, where it learns to identify and
%focus on the most important parts of the input data. 
for example, that they can summarize loop invariants \cite{pei_can_2023}, which is an inherently difficult task in program analysis. 
This is likely because it has been trained on various functions with loops and their semantics.
In contrast, traditional static analysis follows explicitly defined rules 
without a limited ability to generalize.
%On the other hand, LLMs can rely on implicit heuristics  driven by patterns learned during
%training, and can analyze code smartly.

% \yu{data flow or control flow should be more popular. not so called heuristic...}
% As a result, these heuristics may not always be obvious or directly
% controllable, and their effectiveness could depend on the specific contexts.
% On the other hand, 


\cut{
\vspace{3pt}
\noindent
\textbf{Flexible Rule Encoding.} 
One of the noteworthy advantages of using
LLMs for program analysis is their flexibility when it comes to rule encoding. 
In contrast to traditional
static analysis methods, which require both carefully designed rules and implementation tricks
to create a practical analysis tool,
LLMs can be used to describe rules with natural language and examples. 
For example, using LLMs, we can easily encode the rule about post-condition-aware analysis.
}
%training on a diverse and comprehensive dataset, LLMs learn a rich set of
%patterns and contexts, enabling them to adjust their `sensitivity' based on the
%specific task at hand.

% \vspace{3pt}
% \noindent
% \textbf{Advanced Semantics for Programs.} 

%precise function summaries by leveraging the knowledge obtained from extensive training data. 
%They encompass a vast knowledge base and recognize complex patterns, \yu{choose fitness sensitivity?}
%enabling the production of more precise and comprehensive summaries.

% \subsection{Goals}
% Based on the premise we discussed above, we propose our design goals as follows:

% \squishlist
% \item \textbf{Automated Function Summary.} Utilize LLM to generate function
%  summaries, especially for functions that are modeled by manual efforts in
%  existing work.
% \item \textbf{Integration with Established Work.} Integrate the LLM-based framework 
% with existing analysis tools. This can illustrate the enhancement of the overall effectiveness
% of static analysis.
% \squishend

\begin{figure}
  \centering
  \scalebox{1.0}{
  \hspace{-5pt}
  \input{figures/overall_v2.tex} 
  }
  \caption{The overview of \work. Start with the discarded cases by UBITect
   and determine whether these potential bugs are true or false.
   % \zhiyun{change the figure to filter style}
   }
  \label{fig:design-flow}
  \vspace{-5pt}
\end{figure}


\begin{figure}[t]
\hspace{-15pt}
\includegraphics[width=.5\textwidth]{figures/minted/case_problem.pdf}
\caption{A typical type of potential UBI bug. For each suspicious variable \(X\), we expect it to 1) have an initializer function that probably initializes  \(X\) and 2) use \(X\).  
}
\label{fig:prob_scope}
\end{figure}



% \vspace{-.1in}
\section{Conclusion}
% \vspace{-.05in}
% A. Challenges and limitations of using large language models in program analysis
% C. Opportunities for future research and development
% \begin{itemize}
%   \item reliability might be a problem. Careful prompts can mitigate, for example, "if you feel uncertain, you should ask for more information."
%   \item GPT is quickly evolving.
%   \item other fields besides function summary.
%   \item limitations (engineering efforts): concurrency, indirect call.
%   \item completely reconstruct existing tools to take a full use of it
% \end{itemize}

% \section{Conclusion}


% Through extensive experimentation, we demonstrate the potential of LLMs in
% identifying buggy code directly, as well as generating accurate and precise
% function summaries.

% Additionally, we explore several key aspects of prompt design and provide
% insights into leveraging LLMs more effectively for such tasks. While our results
% indicate promising performance in bug detection and function summarization, we
% acknowledge that there remains room for further optimization and improvements,
% particularly in prompt engineering.


%\haonan{...}
This work presents a novel approach that utilizes LLMs to aid static analysis using a completely automated agent.
By carefully considering the scope and designing the interactions with LLMs, our solution has yielded promising results.
We believe our effort only scratched the surface of the vast design space,
%Interesting directions include (1) investigating other strategies to divide the static analysis task into subtasks and offload them to LLMs, (2) understanding the implications of different strategies in terms of conversation length and accuracy, and (3) supporting more complex bug types, e.g., use-after-free and race condition bugs.
and hope our work will inspire future research in this exciting direction.

%\yu{we mentioned it in \S limitations}
%Another limitation is that we heavily rely on GPT-4, which is actually a closed API.

\cut{
In conclusion, paper presents a novel approach to detecting
use-before-initialization (UBI) bugs in the Linux kernel by employing large
language models (LLMs) such as ChatGPT. Our method involves generating precise
function summaries with the help of LLMs, which subsequently allows for more
accurate bug detection, reducing both false positives and false negatives.
}

\cut{
some questions copied from reviewer 2 for oakland poster, which may be helpful for future work, we can pick some:
How does the response for uncommon bugs look like? Did you observe imprecise responses for the bugs that are not very popular or appear in the codes of particular domains?
How do you address the issue of incorrect responses, and how do you measure the correctness of the responses? Does it require users to have sufficient domain knowledge regarding the bugs and the codes they are running the analysis on?
}
%\balance
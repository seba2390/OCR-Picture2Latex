\section{Related Work}

\textbf{Techniques of Utilizing LLMs.}
% \yu{why not "Prompt Engineering}
Wang \etal \cite{wang_voyager_2023} propose an embodied lifelong learning agent based on LLMs.
Pallagani \etal \cite{pallagani_understanding_2023} explores the capabilities of LLMs for automated planning.
 Weng \cite{weng2023prompt}  summarizes recent work in building
an autonomous agent based on LLMs and proposes two important components for planning: \textit{Task Decomposition} and \textit{Self-reflection}, which
are similar to the design of \work.
Beyond dividing tasks into small pieces, task decomposition techniques also include some universal strategies such as
Chain-of-thought \cite{wei_chain--thought_2023} and Tree-of-thought \cite{yao_tree_2023}.
The general strategy of self-reflection has been used in several flavors: ReAct \cite{yao2023react}, Reflexion \cite{shinn_reflexion_2023} and Chain of Hindsight \cite{liu_chain_2023}.
Despite the similarity in name, self-reflection is fundamentally \textit{different} from self-validation in \work where the former focuses on using external sources to provide feedback to their models. Huang \etal \cite{huang_large_2022} let an LLM self-improve its reasoning without supervised data by asking the LLM to lay out different possible results.

% These self-reflection techniques, which are different with the self-validation 
% They are similar to but different with self-validation 
% in \work. It is more about refining past decisions with 



\vspace{3pt}
\noindent
\textbf{LLMs for Program Analysis.} %Tian \etal \cite{tian_is_2023}, 
Ma \etal \cite{ma_scope_2023} and Sun \etal \cite{sun_automatic_2023}  explore the capabilities of LLMs when performing various program analysis tasks such as control flow graph construction, call graph analysis, and code summarization. They conclude that while LLMs can comprehend basic code syntax, they are somewhat limited in performing more sophisticated analyses such as pointer analysis and code behavior summarization.
In contrast to their findings, our research with \work has yielded encouraging results. We conjecture that this might be due to several reasons: (1) benchmark selection, \ie Linux kernel vs. others.
(2) Prompt designs. (3) GPT-3.5 vs. GPT-4.0 -- prior work only evaluated the results using only GPT-3.5.
Pei \etal \cite{pei_can_2023} use LLMs to reason about loop invariants with decent performance. In contrast, \work leverages LLMs for a variety of tasks (including program behavior summarization) and integrates them successfully into a static analysis pipeline.

% \zhiyun{to be edited}
%and do not adapt the methodologies of \work.
% It is partially because they do their expriments based on GPT-3.5 and therefore underestimate the potentials of LLMs.
% It also proves that utilizing LLMs is not trivial and our designs improving the performance of LLMs.
% \haonan{(or simply because we use GPT-4 but they use GPT-3.5)}

\vspace{3pt}
\noindent \textbf{\acp{LLM} for Software Engineering}. 
Xia \etal \cite{xia_keep_2023} propose an automated conversation-driven
program repair tool using ChatGPT, achieving nearly 50\% success rate. 
Pearce \etal \cite{pearce_examining_2023} examine zero-shot vulnerability
repair using LLMs and found promise in synthetic and hand-crafted scenarios but
faced challenges in real-world examples.
Chen \etal \cite{chen_teaching_2023} teach LLMs to debug its own predicted program to increase its correctness, but only
performs on relatively simple programs.
Lemieux \etal \cite{lemieux_codamosa_2023} leverages LLM to generate
tests for uncovered functions when the search-based approach got coverage stalled. 
Feng and Chen \cite{feng_prompting_2023} use LLM to replay Android bug automatedly.
% LangSimith is a platform proposed by
Recently, LangChain proposed LangSimith \cite{langchain_2023_announcing_2023}, a LLM-powered platform
for debugging, testing, and evaluating. 
These diverse applications underline the vast potential of LLMs in software engineering. \work complements these efforts by demonstrating the efficacy of LLMs in bug finding in the real world.

% None of the related work attempted to integrate LLM into a realistic bug-finding solution.
% \zhiyun{What's the difference between this paragraph and the previous one?}
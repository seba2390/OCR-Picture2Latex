\section{Conclusion}
\label{sec:conclusion}

In our early exploration of many sparsity patterns with complex training procedures, we found that a simple pattern (butterfly + low-rank) consistently (though not always) performed among the best.
This motivated us to propose Pixelated Butterfly, a simple and efficient sparse training method.
In our quest for simplicity and efficiency, we have chosen to use fixed sparsity
that aligns with modern hardware, which was sufficient to yield wall-clock
training time speedup without sacrificing accuracy.
We are excited about several future directions.
Inspired by the remarkable success of model pruning for inference, it is possible that dynamic block sparse mask could be made efficient yet still accurate.
Our flat butterfly is a simple first order approximation of the rich class of butterfly matrices, and there could be more sophisticated approximations that retain more expressiveness.
Our method is a first step towards the goal of making sparse models train faster than dense models and make them more accessible to the general machine learning community.


\iftoggle{arxiv}{}{
\textbf{Ethics Statement.}
As the amount of data and model size grows, our work seeks to understand how to train those large models more efficiently by exploiting sparsity. This potentially connects to energy savings during large-model training. In addition, this allows the general community that has limited access to the computational resources to train and understand those foundation models. Our method is applicable to popular models such as MLP-based and Transformer-based architectures, which may improve a wide range of applications, each with their own potential benefits and harms. For example, making language modeling more efficient might simplify the process of spreading misinformation. Similarly, better image classification models might make automatic surveillance easier. To alleviate the above risks, we need to address application-specific issues like privacy, bias and discrimination, going beyond the accuracy metric we currently considered. Specifically, for image classification task, while our work partially addresses the issue of environmental cost, it does not address other issues such as fairness and bias in model and datasets.   

\textbf{Reproducibility Statement.} To facilitate the reproducibility of our algorithms and results, (i) we include a link to downloadable source code in supplementary materials, (ii) for our theoretical statements and results,  we include clear explanations of any assumptions and a complete proof of the claims from~\cref{app:problem_formulation} to~\cref{sec:gradient_flow}; for any datasets used in the experiments, a complete description of the data processing steps is in~\cref{sec:experiment_details}.
}


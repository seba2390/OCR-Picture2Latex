\section{Benchmarking of Butterfly Multiply}
\label{sec:appx_benchmark}

We validate that flat butterfly matrices (sum of factors) can speed up multiplication on GPUs
compared to butterfly matrices (products of factors).

Consider the matrix $M \in \mathbb{R}^{n \times n}$ that can be written as products of butterfly factors of
strides of up $k$ (a power of 2), with residual connection:
\begin{equation*}
  M = (I + \lambda \vB_k^{(n)}) (I + \lambda \vB_{k/2}^{(n)}) \dots (I + \lambda \vB_2^{(n)}).
\end{equation*}
The first-order approximation of $M$ has the form of a flat butterfly matrix
with maximum stride $k$ (\cref{sec:flat_butterfly}):
\begin{equation*}
  M_\mathrm{flat} = I + \lambda (\vB_2^{(n)} + \dots + \vB_{k/2}^{(n)} + \vB_k^{(n)}).
\end{equation*}

Notice that $M$ is a product of $\log_2 k$ factors, each has $2n$ nonzeros, so
multiplying $M$ by a input vector $x$ costs $O(n \log k)$ operations (by
sequentially multiplying $x$ by the factors of $M$).
The flat version $M_\mathrm{flat}$ is a sparse matrix with $O(n \log k)$
nonzeros as well, and the cost of multiplying $M_\mathrm{flat} x$ is also
$O(n \log k)$.
However, in practice, multiplying $M_\mathrm{flat} x$ is much more efficient on
GPUs than multiplying $Mx$ because of the ease of parallelization.

We measure the total time of forward and backward passes of multiplying either
$M_\mathrm{flat} x$ and compare to that of multiplying $Mx$ for different
maximum strides, as shown
in~\cref{fig:flat_butterfly_speed}.
We see that ``flattening'' the products brings up to 3$\times$ speedup.
\begin{figure}[ht]
  \centering
  \includegraphics[width=0.6\linewidth]{figs/flat_butterfly_speed.pdf}
  \caption{\label{fig:flat_butterfly_speed}Speedup of multiplying
    $M_\mathrm{flat}x$ compared to multiplying $Mx$. Flattening the products
    yields up 3$\times$ speedup.}
\end{figure}

We use matrix size $1024 \times 1024$ with block size 32.
The input batch size is 2048.
We use the block sparse matrix multiply library from
\url{https://github.com/huggingface/pytorch_block_sparse}.
The speed measurement is done on a V100 GPU.



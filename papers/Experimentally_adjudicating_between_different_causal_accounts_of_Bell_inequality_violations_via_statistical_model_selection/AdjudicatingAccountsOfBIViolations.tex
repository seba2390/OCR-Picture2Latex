

%%% Version starting on Monday March 16th since V4 is left static starting today for tomorrow's meeting.

%%% Working version is V6 up to April 20th 2020, edits based on Rob's suggestions on the meeting in late march are in V6 but enacted in V7.

%% V7 goes static on Sunday May 31st when I sent out the email for the meeting. This draft was reworked for better notation however the introduction, abstract, supplementary material and discussion require some work.  I'll begin writting the supplementary material and adding it to V8 then also performing the required updates from the meeting to the main text in V8. Currently the supplementary material is just a bank of text we could use.

\documentclass[aps,pra,twocolumn,groupedaddress,nofootinbib,10pt]{revtex4-1}
\usepackage[english]{babel}
\usepackage{amsmath,amssymb,graphicx,enumerate,bbm,xcolor,latexsym}
\usepackage{mathtools}
%\usepackage{ulem}
\usepackage{comment}
\usepackage{paralist, tabularx}
\usepackage{nicefrac}
\usepackage{hyperref}
\bibliographystyle{apsrev4-1}

\newcommand{\nobracket}{}
\newcommand{\tmcolor}[2]{{\color{#1}{#2}}}
\newcommand{\tmem}[1]{{\em #1\/}}
\newcommand{\tmop}[1]{\ensuremath{\operatorname{#1}}}
\newcommand{\tmtextit}[1]{{\itshape{#1}}}
\newcommand{\tmtextup}[1]{{\upshape{#1}}}
\newenvironment{enumeratealpha}{\begin{enumerate}[a{\textup{)}}] }{\end{enumerate}}
\newenvironment{itemizedot}{\begin{itemize} \renewcommand{\labelitemi}{$\bullet$}\renewcommand{\labelitemii}{$\bullet$}\renewcommand{\labelitemiii}{$\bullet$}\renewcommand{\labelitemiv}{$\bullet$}}{\end{itemize}}
\newenvironment{proof}{\noindent\textbf{Proof\ }}{\hspace*{\fill}$\Box$\medskip}
\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}

\newcommand{\bel}[1]{{\color{red!70!blue} #1 }}
\newcommand{\term}[1]{\textcolor{medblue}{\textbf{\upshape #1}}}
%\newcommand{\rob}[1]{{\color{blue} #1}}
\newcommand{\rob}[1]{{\color{black} #1}}
\newcommand{\elie}[1]{{\color{purple} #1}}
\newcommand{\david}[1]{{\color{red} #1}}
\newcommand{\tcf}[1]{{\color{green!50!black} #1}}
\newcommand{\blk}[1]{{\color{black} #1}}


\newcommand{\tr}[1]{\mathrm{tr}\left\{ #1 \right\}}
\newcommand{\rmA}{\textrm{A}}
\newcommand{\rmB}{\textrm{B}}
\newcommand{\Tr}{\mathrm{tr}}
\newcommand{\ket}[1]{\left| #1 \right>} 
\newcommand{\bra}[1]{\left< #1 \right|} 
\newcommand{\id}{\mathbbm{1}}
\newcommand{\op}{\mathscr{O}}
\newcommand{\beq}{\begin{equation}}
\newcommand{\eeq}{\end{equation}}
\DeclarePairedDelimiter{\expec}{\langle}{\rangle}
\DeclarePairedDelimiter{\Bracket}{\lbrack}{\rbrack}
\DeclarePairedDelimiter{\norm}{\lVert}{\rVert}
\DeclarePairedDelimiter\abs{\lvert}{\rvert}
\usepackage{braket}

\newcommand{\LOSR}[0]{\ifmmode\textup{\upshape LOSR}\else{\textup{\upshape LOSR}}\fi}
\newcommand{\LO}[0]{\ifmmode\textup{\upshape LO}\else{\textup{\upshape LO}}\fi}
\newcommand{\LOCC}[0]{\ifmmode\textup{\upshape LOCC}\else{\textup{\upshape LOCC}}\fi}

\DeclareMathOperator*{\conv}{\longmapsto}
\DeclareMathOperator*{\interconv}{\longleftrightarrow}
\newcommand*{\Sinterconv}{\xleftrightarrow{\frak{S}}}
\newcommand{\convunder}[1]{\xmapsto{#1}}
\newcommand{\interconvunder}[1]{\xleftrightarrow{#1}}
\newcommand{\nconvunder}[1]{\mathrel{\mkern5.5mu\Arrownot\mkern-5.5mu\xmapsto{#1}}}
\usepackage[only,Arrownot]{stmaryrd}
\DeclareMathOperator*{\nconv}{\mathrel{\mkern5.5mu\Arrownot\mkern-5.5mu\longmapsto}}

\newtheorem{theo}{Theorem}
\newtheorem{thm}[theo]{Theorem}
\newtheorem{prop}[theo]{Proposition}
\newtheorem{Lemma}[theo]{Lemma}
\newtheorem{lem}[theo]{Lemma}
\newtheorem{cor}[theo]{Corollary}
\newtheorem{conj}[theo]{Conjecture}
\newtheorem{defn}[theo]{Definition}
\newtheorem{assu}[theo]{Assumption}
\newtheorem{rem}[theo]{Remark}
\newtheorem{ex}[theo]{Example}
\newtheorem{prob}[theo]{Problem}

\begin{document}

%\title{Experimental evidence against superluminal and superdeterministic accounts of Bell inequality violations}

\title{Experimentally adjudicating between different causal accounts of Bell inequality violations via statistical model selection}
%explanations 
%causally radical and inferentially radical 
%accounts
 %using model selection techniques}

\author{Patrick J. Daley, Kevin J. Resch}
\affiliation{Institute for Quantum Computing and Department of Physics \& Astronomy, University of Waterloo, Waterloo, Ontario N2L 3G1, Canada}
\author{Robert W. Spekkens}
\affiliation{Perimeter Institute for Theoretical Physics, 31 Caroline Street North, Waterloo, Ontario Canada N2L 2Y5}

\date{April 12, 2021}

\begin{abstract}
Bell inequalities follow from a set of seemingly natural assumptions about how to provide a causal model of a Bell experiment.  In the face of their violation, two types of causal models that modify some of these assumptions have been proposed:
%the only possibility for a causal model is to modify some of these assumptions.
% Their violation by quantum theory and by experiment imply that one or more of these assumptions must be abandoned. Proposed causal models that do so are of two types:
%Bell inequality violations by quantum theory and by experiment imply that one or more of the assumptions that go into deriving these inequalities must be abandoned. Proposed causal models that do so are of two types: 
(i) those that are parametrically conservative and structurally radical, such as models where the parameters are conditional probability distributions (termed `classical causal models') but where one posits inter-lab causal influences or superdeterminism, and (ii) those that are parametrically radical and structurally conservative, such as models where the labs are taken to be connected only by a common cause but where conditional probabilities are replaced by conditional density operators (these are termed `quantum causal models'). We here seek to adjudicate between these alternatives based on  their predictive power.
%, which we estimate using data obtained from a Bell experiment.  
 The data from a Bell experiment  is divided into a training set and a test set, and for each causal model, the parameters that yield the best fit for the training set are estimated and then used to make predictions about the test set.   Our main result is that
  %, when assessed by predictive power,
   the structurally radical classical causal models 
   %we consider
    are disfavoured relative to the structurally conservative quantum causal model.  
  Their lower predictive power seems to be due to the fact that, unlike the quantum causal model, they are prone to a certain type of overfitting wherein statistical fluctuations away from the no-signalling condition are mistaken for real features.
    %The lower predictive power of the structurally radical models seems to be due to the fact that they are prone to a certain type of overfitting wherein statistical fluctuations away from the no-signalling condition are mistaken for real features, a possibility that arises only for these models because only these admit of parameter values that can violate the no-signalling condition.
     Our technique shows that it is possible to witness quantumness even in a Bell experiment that does not close the locality loophole. It also overturns the notion that it is impossible to experimentally test the plausibility of superdeterminist models of Bell inequality violations.
\end{abstract}

\maketitle
%\tableofcontents


%\section{The main article}

%\color{red} [Below, I need to shift from `explanation' to `model' or `account', which in the language of causal-inferential theories is a shift from a claim to have a realist account to a claim merely to have an operational account.] \color{black}

%{\bf The bit we can make use of}
\textit{Introduction.}  There is now widespread agreement that the experimental evidence in favour of nature violating Bell inequalities~\cite{Bell64,CHSH,brunner2014bell}
 is persuasive~\cite{Belltest1,Belltest2,Belltest3}.  By contrast, 
 there is no agreement on how to provide a {\em causal account}
  of such violations~\cite{wood2015lesson}.
 One of the most popular views is that Bell inequality violations imply the existence of superluminal causal influences (typically understood as action at a distance)~\cite{maudlin2011quantum,norsen2006bell}.  Another view is that they imply the need for ``superdeterminism'', wherein  
% one or both setting variables not being independent of a hidden common  cause of the outcomes
the hidden variable that is a common cause of the two outcomes is also a cause of one or both of the setting variables
 %that is, the existence of a common cause of the setting variable in one or both labs and the hidden variable that influences both outcomes
 ~\cite{sep-bell-theorem,t2016cellular,hossenfelder2020rethinking}.  A third option is that the correct causal account is one wherein there is just a common cause of the two outcomes, but wherein correlations are computed using the formalism of {\em quantum causal models}~\cite{LeiferSpekkens,allen2017quantum,CostaShrapnel,BLO}.
%The nature of the causal influences that are posited by a given researcher's preferred account tend to depend on the interpretation of quantum theory which they favour. As an example, proponents of Bohmian mechanics~\cite{bohm1994undivided,sep-qm-bohm}  posit superluminal causal influences in their  model, while proponents of ``superdeterminism''~\cite{t2016cellular,hossenfelder2020rethinking} posit causes that influence both the setting variable in one lab and, typically indirectly, the outcome variable in the other lab 
 %(see Ref.~\cite{wood2015lesson} for a more detailed discussion.) 
It is tempting to think that the only way to adjudicate between such accounts, i.e., the only way to assess the quality of the accounts of the correlations that they offer, is to consider their merits relative to some philosophical or aesthetic criteria. Recall, however, that this was the standard attitude towards the question of the merit
%viability
 of local hidden variable models of quantum theory until Bell 
showed how the question can be assessed by empirical data~\cite{Bell64}.  Motivated by Bell's example, we undertake to show that the selection problem articulated above can also be assessed empirically.

%To date, the standard to which proposed causal accounts of Bell inequality violations have typically been held is whether the observations are reasonably likely given the model. 
To date, proposed causal accounts of Bell inequality violations have typically been held to the following standard: {\em that the observations be reasonably likely given the model}. 
   In other words, a given causal model  has generally been considered unobjectionable on empirical grounds as long as it does not {\em underfit} the data.   From the perspective of statistical model selection, however, a more methodologically sound figure of merit when comparing models is their {\em predictive power}.  The latter can be compromised not only when the model underfits the data, but for other reasons as well, such as the model {\em overfitting} the data.
Overfitting occurs when the model-fitting procedure mistakes statistical fluctuations in the data for real features, a mistake which implies reduced predictive accuracy on novel data with different fluctuations.
In this article, we propose to 
hold causal accounts to a higher standard
by developing a technique for assessing the relative merit of different 
%a particular set of 
causal models using standard model selection tools. We then apply the technique to data obtained from a Bell-type experiment.\color{black}


%Up until now, the only bar to which proposed causal explanations of Bell inequality violations have been held is the bar of {\em predicting that the observed correlations are likely given the model}.
%% that is, ``saving the phenomena''. 
%%are deemed that of {\em reproducing} the observed correlations.
%%the emphasis has been on whether or not they can {\em reproduce} the observed correlations.  
%In other words, a given explanatory model has generally been considered  {\em unobjectionable on empirical grounds} as long as it does not {\em underfit} the data.
%%That is, the focus has been on whether or not the models {\em under-fit} the data.
% From the perspective of statistical model selection, however, when comparing explanatory models, it is critical to also consider the extent to which they might {\em overfit} the data.  The reason is that both underfitting and overfitting tend to reduce the predictive power of a model. 
%% the predictive power of a model is reduced not only by underfitting but by overfitting as well.  
% %This is not simply a philosophical desideratum but a pragmatic one as well, since an over-fitting model results in poor predictive performance on future data sets. This is due to 
%Specifically, the parameter values in an overfitting model mistake statistical fluctuations in the data for real features and therefore have reduced predictive accuracy on novel data. 
%  Thus, {\em not overfitting the data} is a bar to which such models should be subjected. 
% %have not previously been subjected, but which they should be. 
%Towards this end, we here propose a technique for determining the relative worth of a particular set of explanatory causal models by using standard model selection tools, and we apply the technique to data obtained from a Bell-type experiment. \color{red} [Patrick's suggestion for how to rewrite this: people have been looking at underfitting.  Really we should be looking at predictive power.  Underfitting is not enough because it misses overfitting which also impacts predictive power by virtue of mistaking fluctuations for real patterns.  Therefore, we use standard model selection tools, assessing models by their predictive power rather than their ability to not underfit the data.] \color{black}

%  a variant of a Bell experiment. 

%\color{red} [where to say the following: These principles of model selection are broadly applicable and drastically under utilized in the physics community. Our specific problem, as with many others in this field, lies in a data-rich paradigm seldom studied by statisticians due to it's relatively simple solutions, solutions which are often overlooked.  ]
%
%[Mention: all QF experiments, not just Bell-type experiments, would benefit from a consideration of whether a given model overfits the data, rather than merely a demonstration that it fails to underfit the data.]
%\color{black}

 
%\color{red} [Making philosophy into something experimentally testable is analogous to what Bell did.] \color{black}

In our comparison of alternative causal accounts of Bell inequality violations,
   we will focus on the distinction between a set of accounts    that are {\em structurally radical and parametrically conservative}, on the one hand, and an account that is   {\em structurally conservative and parametrically radical} on the other.  By ``structural radicalness,'' we mean that the particular {\em causal  structure} that appears in a causal account 
  is not the one that one would expect a priori to hold for a Bell scenario (more on this below). 
  By ``parametric radicalness,'' we mean that the mathematical formalism by which one extracts statistical predictions from a given structure is not the conventional one used in classical causal modelling,
  but rather the modification thereof proposed in the recent literature on {\em quantum causal models}~\cite{allen2017quantum,CostaShrapnel,BLO}.  The result of our analysis is that the latter sort of account is favoured by the experimental data.


In order to be able to compare the predictive power of different causal accounts
%views on how to provide a causal account
 of Bell inequality violations, we must cast them
 %these views
  into a common framework.  For this purpose, we use a framework that subsumes both that
 of classical causal modelling~\cite{pearl2000causality,Spirtes00} and quantum generalizations thereof~\cite{allen2017quantum,CostaShrapnel,BLO}, thereby permitting   the relative predictive power of these views to be compared one to another using standard model selection techniques.
 Our proposal is an example of {\em causal discovery} using purely observational data.  Its relation to past work on causal discovery, both classical~\cite{pearl2000causality,Spirtes00} and quantum~\cite{giarmatzi2019quantum,bai2020efficient} is discussed in Appendix~\ref{priorwork}.
 %the Supplementary Material.
 
% We apply our technique on data from a photonic Bell-type experiment.  By virtue of violating Bell inequalities, this data is incompatible with the causal model contemplated by Bell---a classical causal model that only appeals to a common-cause mechanism between the labs.
% %\footnote{Note that our experiment does not seek to seal the detector loophole, the locality loophole, or the memory loophole [citations], at least not in the standard manner in which these loopholes are addressed (See comments in the discussion section).}
%The question that we address with our technique is:
%  of alternatives to this model that are {\em not} excluded by the data, which has the greatest predictive power?
  
%   We apply our technique on data from a photonic Bell-type experiment in order to answer the question: Of various different causal accounts of Bell inequality violations, which has the greatest predictive power? 
%  \color{red} [Shift to this]: 
%In comparing these alternatives, 

% In comparing the alternative causal accounts of Bell inequality violations,
%%In comparing the alternative accounts, 
%   we will focus on the distinction between those that are {\em structurally radical and parametrically conservative}, on the one hand, and those that are {\em structurally conservative and parametrically radical} on the other.  By ``structural radicalness,'' we mean that the particular {\em causal  structure} that appears in a causal account 
%  %(represented by a directed acyclic graph) 
%  is not the one that one would expect a priori to hold for a Bell scenario (more on this below). 
% %in tension with certain natural principles that have been endorsed in other contexts (more on this below). 
%  By ``parametric radicalness,'' we mean that the mathematical formalism by which one extracts statistical predictions from a given structure is not the conventional one used in classical causal modelling,
%   %(using conditional probability distributions),
%    \rob{ but rather the modification thereof proposed in the recent literature on {\em quantum causal models}~\cite{allen2017quantum,CostaShrapnel,BLO}.  The result of our analysis is that the latter sort of account is favoured by the experimental data.}
%%    In particular, we consider the parametrically radical causal accounts termed {\em quantum causal model} in the recent literature [citations].


%\color{red} [said already] We use the framework of classical and quantum causal models to describe these competing explanations~\cite{pearl2000causality,wood2015lesson,allen2017quantum}.  A causal model of an experiment consists of a i) a directed acyclic graph (DAG) whose nodes represents the variables (both observed and unobserved) and whose edges represents direct causal influences and ii) a rule for generating the probability distribution over the observed variables under an intervention for a given DAG.\color{black}


%  It differs from previous work in classical causal inference~\cite{pearl2000causality,Spirtes00} in that it is not limited to comparisons of models that are totally ordered in terms of their explanatory scope (as is the case for the preference ordering described in Definition 2.3.3 of Ref.~\cite{pearl2000causality}
   %\color{red} [I gave the def'n number for Pearl 1st edition, same def'n number in 2nd edition?]).\color{black} 
   %Articles exploring quantum analogues of causal discovery  [GiamatziCosta, ShrapnelCosta?] have thus far presumed a tomographic characterization of each gate in a circuit, rather than merely a distribution over the classical variables in the circuit. \color{red} [is that accurate? ]. \color{black} 
%   Finally, our framework is distinguished insofar as it allows a direct comparison between quantum and classical causal models using the same scoring criteria.



\color{black}




%$Summarizing then, classical causal models are inferentially conservative while quantum causal models are inferentially radical.


 %then this can be conceived as being due to ignorance of some causal parents of $X$ that are not included in the DAG, denoted $U$, via $P_{X|Pa(X)}= \sum_U \delta_{X,f(Pa(X),U)} P_U$.
%if $Pa(X)$ includes {\em all} of the causal parents of $X$, then $X$'s causal dependence on $Pa(X)$ is specified by a function, $X =f(Pa(X))$.  If, however, $Pa(X)$ includes only some of the parents of $X$, then 
%Specifically, the value of $X$ is presumed to be specified by the values of the elements of $Pa(X)$, through a conditional probability distribution $P_{X|Pa(X)}$.



%[Much of this has now been said already] This is not simply a philosophical desideratum but a pragmatic one as well, since an over-fitting model results in poor predictive performance on future data sets. This is due to the parameter values in such fits are vulnerable to spurious trends in the noise. It is natural, therefore, to assess the relative merit of a few different explanatory models of Bell inequality violations in terms of their relative predictive accuracy. These principles of model selection are broadly applicable and drastically under utilized in the physics community. Our specific problem, as with many others in this field, lies in a data-rich paradigm seldom studied by statisticians due to it's relatively simple solutions, solutions which are often overlooked. 



%We develop a framework to perform the model selection which is an example of causal discovery from observational data. It differs from previous work in classical [] and quantum [] causal inference in that it directly compares quantum and classical causal models using the same scoring criteria.
%
%We perform a photonic Bell experiment 
%%, with loopholes, 
%and analyze the resulting data\footnote{Note that our experiment does not seek to seal the detector loophole, the locality loophole or the memory loophole, at least not in the standard manner in which these loopholes are addressed (See comments in the discussion section).}. 
%%For the data that was collected, the
%The best-fit \textsc{cCE} and \textsc{cSD} 
% %super-luminal and super-deterministic
%causal  models are found to yield worse predictions than the best-fit \textsc{qCC} causal model. 
%%quantum causal model. 
%Consequently, this provides evidence against them being the correct causal explanation of Bell inequality violations. Our results, in addition to refuting the \textsc{cCC} causal model, 
%%addressed in Bell inequalities, 
%provides strong evidence in favour of maintaining conservative causal influences and instead modifying the inferential theory.

%----------------CAUSAL STRUCTURES SECTION---------------------------

\textit{The framework of classical and quantum causal models.}
%\textit{The framework of classical~\cite{Pearl2009} and quantum~\cite{Allen,SharpnelCosta} causal models.}
%\textit{Causal modelling classically and quantumly}
%\textit{The definition of classical and quantum causal models}
%\textit{Structural and parametric parts of a causal model}
%In describing the framework, we will emphasize the distinction between the structural and the parametric parts of causal models. 
For classical causal models, we use Pearl's framework~\cite{pearl2000causality}.
The structural part of a classical causal model is a specification of 
%A classical causal model represents 
the causal relations that hold among a set of systems (i.e., the {\em causal structure}) and is represented by a directed acyclic graph (DAG).  Examples are given in Figs.~\ref{DAGs}(b-d). Each node in the DAG represents a system, which in the classical case is associated to a random variable.
% (with a distinction among nodes corresponding to whether the system is observed or unobserved/latent, depicted as unshaded or shaded respectively).
%---in our convention, whether the node is unshaded or shaded).  
The directed edges into a node 
%associated to a classical variable
 $X$ from the causal parents of $X$, denoted ${\rm Pa}(X)$, represent 
%Each directed edge into a node $X$ from other nodes---termed the parents of $X$ and denoted ${\rm Pa}(X)$---represents
 the potential for a direct causal influence in the interventional sense (namely, that manipulating a variable in ${\rm Pa}(X)$ while keeping all other variables fixed allows one to alter the statistical distribution of $X$).
%, or, more technically, that the potential that the do-conditional $P_{X| {\rm do }\;{\rm Pa}(X)}$ is nontrivial).
%\color{red} [No.  Need a different way of describing this--- use `do-conditional'? Or maybe say `causal influence in the interventional sense']\color{black} from such a parent to $X$.
The parametric part of a classical causal model stipulates, for every node $X$, 
%a set of parameters describing precisely 
\rob{the possibilities for } how the statistical distribution over $X$ \rob{can depend}
%depends
 on a given intervention on ${\rm Pa}(X)$, \rob{that is, the possibilities for the} 
%This is achieved by a 
conditional probability distribution  $P_{X|{\rm Pa}(X)}$, termed the ``do-conditional''.
\rob{A causal model may stipulate a restriction on the possibilities for $P_{X|{\rm Pa}(X)}$ for each node $X$, although in this article we are primarily interested in the case where there is no restriction, in which case we call the model {\em parameter-unrestricted}.}
%\footnote{\label{SEMfootnote} \rob{[Move to SM?]}It is generally presumed that $X$ is fixed deterministically by some function $f$ of its full set of parents, which is the union of its parents in the DAG, ${\rm Pa}(X)$, together with parents that are not included in the DAG, $U$, so that $P_{X|{\rm Pa}(X),U}= \delta_{X,f({\rm Pa}(X),U)}$.  If an agent's knowledge of $U$ is represented by the distribution $P_U$, then $P_{X|{\rm Pa}(X)}= \sum_U \delta_{X,f({\rm Pa}(X),U)} P_U$.}.  
Let $V$ denote the full set of variables in the DAG.  The distributions over $V$
 %the full set, $V$, of variables in the DAG
  that are said to be {\em compatible} with the \rob{causal model}
  %DAG
%a given causal structure
 are those that can be expressed as the product $P_{V}=\prod_{X\in V} P_{X|{\rm Pa}(X)}$ 
%where the \rob{each element of the set $\{P_{X|{\rm Pa}(X)}\}_{X\in V}$ ranges over are arbitrary conditional distributions.
 where $\{P_{X|{\rm Pa}(X)}\}_{X\in V}$ \rob{are conditional distributions in the set allowed by the model, which is {\em any} conditional distribution in the case of a parameter-unrestricted model.}
% arbitrary conditional distributions. 
 %\rob{(Models that allow only a subset of valid conditional distributions we call {\em parameter-restricted}; these are discussed in the Supplementary Material.). [MAYBE WE SHOULD DEFINE COMPATIBILITY WITH THE MODEL RATHER THAN THE DAG AND DEFINE WHAT IT MEANS FOR A MODEL TO BE PARAMETER-UNRESTRICTED.]}
%The joint distribution over the full set of variables in the DAG, $V$, is given by $P_{V}=\Pi_{X\in V} P_{X|{\rm Pa}(X)}$.  
If only a subset, $O$, of the variables in $V$ are observed, such that the complementary set of variables, $V/O$, are unobserved (these are termed `latent variables'), then
%\rob{then the complementary set of variables, $V/O$, are said to be unobserved or ``latent''}, and 
 the compatible distributions on $O$ are computed by marginalization over the latent variables,
 %$V/O$, 
 $P_{O} = \sum_{V / O} P_{V}$. (Here, an expression such as $\sum_Y P_{XY}$ represents the distribution $P_X$ whose component at $X=x$ is $\sum_y P_{XY}(xy)$.)
%which is known as the ``Markov condition''.


 \begin{figure*}[t]
\begin{center}
\hspace{-2em}
\includegraphics[scale=0.25]{fig1_hybrid_jul9.png}
%\includegraphics[scale=0.18]{fig1_hybrid_jul9.png}
\caption{(a) The bipartite Bell experiment and (b)-(e) the four causal models thereof that we consider here.
Triangular  nodes represent classical variables, while circular ones represent quantum systems; shaded nodes represent variables/systems that are latent.  
% \rob{[@Parick: Labels of (b), (c), (d) and (e) should be small caps font and read $\textsc{cCC}$, $\textsc{cCE}$, $\textsc{cSD}$ and $\textsc{qCC}$ respectively. In (a), I think we should drop "entanglement source" and increase the font size for X, Y, S and T.]} 
} 
\label{DAGs}
\end{center}
\vspace{-2em}
\end{figure*}


%\color{red} [The following needs to be written shifting from ``inference'' to ``{\rm Pa}rameters'' and ``causal'' to ``structural''.  Also need a footnote on how functional dependences are replaced by isometries.] \color{black} 
Various proposals exist for how to define a quantum generalization of the notion of a causal model~\cite{allen2017quantum,CostaShrapnel,BLO}.  Although there are distinctions between these, they will not be relevant for the purposes of this article.
%Although the distinctions between these are relevant for some purposes, they are not relevant for the purposes of this article.  
%We can characterize such models as follows.  \color{red}[provide characterization]\color{black}
%As argued in \cite{Harrigan, LeiferSpekkens}, because 
%: the causal structure holding among a set of systems is represented by a DAG. 
%s equivalent 
%Like a classical causal model, a quantum causal model represents the causal structure holding among a set of systems by a DAG whose nodes are associated to the systems and whose directed edges represent direct causal influences. 
We follow Refs.~\cite{wood2015lesson, leifer2013towards} in taking the transition from classical to quantum causal models to be a transition in the nature of the parameters that supplement the causal structure, while the causal structure is taken to be
 %presumed that the structural part of a quantum causal model 
 represented in the same way as in a classical causal model, namely, by a DAG.
 % which distinguishes observed and unobserved systems.
 %, but where some of the systems may fail to be represented by random variables.
%Where a quantum causal model differs from a classical causal model is in the sort of parameters that supplement the causal structure.  
What one can \emph{infer} about a system $A$ given an intervention on its parents ${\rm Pa}(A)$ is no longer presumed to be represented by a conditional probability distribution,
 %for a variable associated to $A$ given variables associated to the parents of $A$, 
 but is instead represented by a more exotic mathematical object, termed a {\em conditional density operator}, denoted $\rho_{A|{\rm Pa}(A)}$~\cite{leifer2013towards}. \rob{It is a positive operator on the tensor product of the Hilbert spaces of $A$ and ${\rm Pa}(A)$ that satisfies ${\rm Tr}_A (\rho_{A|{\rm Pa}(A)}) =\mathbb{I}_{{\rm Pa}(A)}$.  An equivalent way of representing what one can infer about $A$ given an intervention on ${\rm Pa}(A)$, which makes the analogy to conditional probabilities less obvious but connects better to the conventional formalism, is as a completely positive trace-preserving map from ${\rm Pa}(A)$ to $A$.  (The equivalence of these two representations is established using the Choi-Jamio{\l}kowski isomorphism.)}
% or equivalently (using the Choi-Jamio{\l}kowski isomorphism) a completely positive trace-preserving map from ${\rm Pa}(A)$ to $A$.  
\rob{The parameter-unrestricted versions of quantum causal models, which are the only ones we consider here, impose no restriction on the possibilities for the conditional density operator.
We will also focus here on quantum causal models wherein }
%the case where
%In the examples of interest in this article,
 the only systems that can be intrinsically quantum are the latent systems, while all of the observed systems are classical, since this simplifies the analysis and is sufficient to describe the Bell scenario (see Fig.~\ref{DAGs}(e)).
%~\footnote{Note that the modifiers `classical' and `quantum' in this article refer to the {\em parameteric} part of the causal model and correspond to whether it is conservative or radical.} 
%(Below, we describe explicitly the set of compatible distributions over the observed variables in this case.)

%In this article, we follow Refs.~\cite{wood2015lesson, leifer2013towards} in taking the transition from classical to quantum causal models to be a transition in the nature of the parameters, such that the modifiers `classical' and `quantum' will here always refer to the {\em parameteric} part of the model and will correspond to whether it is conservative or radical.

%It is these aspects of the causal model that are presumed to be modified (i.e., made radical) in the transition from classical to quantum causal models, as has been argued in Refs.~\cite{wood2015lesson, leifer2013towards}.  Throughout this article, therefore,  the modifiers `classical' and `quantum' will always refer to the {\em parameteric} part of the model  and will correspond to whether it is conservative or radical.
  %\footnote{This gloss of what is innovative about a quantum causal model is not completely accurate, however, insofar as there are aspects of the causal model that are not given by the DAG but do not deserve to be considered as part of the theory of inference.  For instance, deterministic causal dependences in a quantum causal model are represented by isometries whereas they are represented by functions in classical causal models, a distinction that is not merely about the nature of inference.}

\begin{comment}
Given that proponents of superluminal causation and superdeterminism in causal accounts of Bell inequality violations believe that {\em classical probability theory} is the correct formalism to use when making inferences about systems appearing in their causal account,  their views must be  cast as  causal models which are {\em parametrically conservative}.  They will differ one from the other in the {\em causal structure} that they posit as underlying the Bell experiment. The structure they endorse will differ from the common-cause structure that is natural for the Bell scenario, and hence will be {\em structurally radical}.
\end{comment}
%The views of Bohmians and superdeterminists, who do not dispute that classical probability theory is the correct way to make inferences about any variables appearing in a causal explanation of the Bell experiment,  will be capture with classical causal models. 


%\color{red} [Bell experiment and different models thereof] \color{black}

%We develop a framework to perform the model selection which


 
\textit{The slate of causal models--}
%of a Bell experiment--}
%Specifically, 
We will consider a bipartite Bell experiment, depicted in Fig.~\ref{DAGs}(a).
%, for which the setup is depicted schematically in Fig.~\ref{BellExperiment}~\cite{brunner2014bell}. 
%We associate one lab to Alice and one to Bob.
We refer to the two labs as `Alice's' and `Bob's'.
% The variable corresponding to the measurement setting in Alice's lab (resp. Bob's) is denoted by $S$ (resp. $T$) and the variable describing the measurement outcome in Alice's lab (resp. Bob's) is denoted $X$ (resp. $Y$). 
 The variable corresponding to the measurement setting (resp. outcome) in Alice's lab is denoted by $S$ (resp. $X$) and the variable describing the measurement setting (resp. outcome) in Bob's lab is denoted $T$ (resp. $Y$).
In the case we consider here, the outcome variables will be binary but the setting variables can take a larger number of values.
The conditional probability of outcomes given settings is denoted by $P_{XY|ST}$. 
%Let the conditional probability that $X=x$ and $Y=y$ given that $S=s$ and $T=t$ be denoted $P(xy|st)$. 
The experimental data constitutes a finite sample from the distribution over $X$ and $Y$ for each set of values of $S$ and $T$, that is, a finite sample from $P^{(s,t)}_{XY} :=  \sum_{S,T} P_{XY|S,T} \delta_{S,s} \delta_{T,t}$ for each $(s,t)$.
%$P_{XY|S=s,T=t}$ for each $(s,t)$.

 
%The intuitive physical constraints for a Bell experiment (Fig. 1) result in a causal structure for the experiment shown in Fig. 2a. A theory of inference must also be taken to provide statistical predictions. The natural assumption would be a classical probability theory. This combination is rejected by a Bell inequality violation. 
%
%We consider three alternatives which can explain Bell inequality violations: (i) a causal model wherein the setting in one lab can influence the outcome in the other, (ii) a causal model wherein the hidden common cause can influence one of the setting variables, (iii) a causal model similar to standard local causality where the causal influences are governed by a different set of rules, specifically quantum ones.
%Consider a Bell experiment~\cite{brunner2014bell} where the variables denoting the measurement settings in Alice's and Bob's labs respectively are denoted $S$ and $T$ and the variables describing the binary outcome in the two labs are denoted $X$ and $Y$, depicted in Fig.~\ref{BellExperiment}. Let the conditional probability that $X=x$ and $Y=y$ given that $S=s$ and $T=t$ be denoted $P(xy|st)$. The experimental data constitutes a finite sample from the distribution over $X$ and $Y$ for each set of values of $S$ and $T$. 
%over outcome variables for each set of values of the setting variables. 
We begin by describing the causal model that is excluded by 
%Bell's theorem and experimental 
Bell inequality violations.  As argued in Ref.~\cite{wood2015lesson}, this is the classical causal model with the DAG of Fig.~\ref{DAGs}(b), which %we refer to as the {\em locally causal} DAG insofar as it is the one that embodies
describes a causal structure that fits Bell's intuitive notion of local causality~\cite{Bell64}, namely, that there is simply a common cause of the two outcomes. 
%\rob{The parameters are assumed to be unrestricted.}
%we term the {\em Bell} DAG or 
%as the DAG satisfying Bell's notion of {\em local causality}.  
%Note that: (1) the setting variables can be freely chosen (there are no edges incoming to $S$ or $T$), (2) a setting can only influence the measurement outcome in the same lab ($S \not\rightarrow Y$, $T \not\rightarrow X$) and (3) there is no causal influence from either outcome to the other outcome ($X \not\rightarrow Y$, $Y \not\rightarrow X$).The possibility of a latent variable ($\Lambda$) exerting influence on both of the measurement outcomes ($\Lambda \rightarrow X$ and $\Lambda \rightarrow Y$) is allowed.
%\footnote{This assumption means we aren't assuming causal sufficiency.}. 
%By the Markov condition~\cite{pearl2009}, 
%Using Pearl's causal modelling framework~\cite{pearl2009}, 
The correlations that are compatible with this causal model
%model
 are those of the form~\cite{pearl2000causality}
%any conditional distribution which can be generated from this model is of the form
%\begin{align}
%P_{_{\rm \scalebox{.6}{\hspace{-.15cm}\textsc{cCC}}}}(xy|st) &:= \sum_{\lambda=1}^N P_1(x|s\lambda)P_2(y|t\lambda) P_3(\lambda),\label{clcmodel}
%\end{align}
%for some conditional probability distributions $P_1,P_2,P_3$, where $N$ is the cardinality of the hidden variable $\Lambda$ (presumed to be discrete). 
\begin{align}
%P_{{\rm \scalebox{.6}{\hspace{-.15cm}\textsc{cCC}}}}(xy|st) &:= \sum_{\lambda} P_1(x|s\lambda)P_2(y|t\lambda) P_3(\lambda),\label{clcmodel}
%P^{{\rm \scalebox{.6}{\hspace{-.001cm}\textsc{cCC}}}}_{XY|ST}(xy|st) &:= \sum_{\lambda} P^{(1)}_{X|S\Lambda}(x|s\lambda)P^{(2)}_{Y|T\Lambda}(y|t\lambda) P^{(3)}_{\Lambda}(\lambda),\label{clcmodel}
P^{{\rm \scalebox{.6}{\hspace{-.001cm}\textsc{cCC}}}}_{XY|ST} &:= \sum_{\Lambda} P_{X|S\Lambda} P_{Y|T\Lambda} P_{\Lambda},\label{clcmodel}
\end{align}
for some conditional probability distributions $P_{X|S\Lambda},P_{Y|T\Lambda},P_{\Lambda}$.
%$P_1,P_2,P_3$.
%, where $N$ is the cardinality of the hidden variable $\Lambda$ (presumed to be discrete).
We refer to this model as  ``parametrically {\em classical} and structurally {\em common-cause}'', abbreviated \textsc{cCC}.
%structurally {\em locally causal},  abbreviated \textsc{cCC}. 
   It is the recasting, within the framework of causal models, of what is typically called a {\em local hidden variable model.} Distributions that are generated according to Eq.~(\ref{clcmodel}) satisfy Bell inequalities,
%~\cite{wood2015lesson} thereby
and therefore the \textsc{cCC} model is rejected if one observes a significant violation of such an inequality.  We now turn to a description of a variety of causal models that {\em can} violate Bell inequalities.

For anyone who presumes that the parameters in a causal model must be conditional probability distributions, it becomes necessary, in order to account for a Bell inequality violation, to presume a causal structure distinct from that of the DAG of Fig.~\ref{DAGs}(b).  We here consider the two most prominent classes of such parametrically conservative and structurally radical proposals.

%The two most prominent classes of proposals of this type are as follows:
%There are three classes of causal structures that have been proposed as underlying an account of Bell inequality violations.  We now review the two most prominent of these. 
%, which we now review. 
% Class (i). Those
 
% The most prominent class of parametrically classical proposals is the one wherein 
 
 
The first class consists of those models that posit
 %Class (i). It is posited
  that there is a causal influence {\em from} the setting or outcome variable in one lab {\em to} the setting or outcome variable in the other lab, so that there is a cause-effect relation between the labs, rather than simply a common-cause relation.
%  \rob{so that the labs are related as cause and effect rather than by a common cause.}
%  \footnote{One can even accommodate influences of this sort in both directions so long as this does not create any cycles.  Note, however, that not every causal structure meeting this description is necessarily sufficient for violating Bell inequalities.  For instance, merely positing a causal influence from one outcome to the other is insufficient~\cite{chaves2015unifying}.}  
%\color{red} [I believe that it has in fact been demonstrated that it is insufficient to have a causal influence from one outcome to the other. I will look into the paper by Chaves that I believe to have shown this.]\color{black}. 
We therefore refer to any such causal account  as parametrically {\em classical} and structurally {\em cause-effect}, abbreviated as \textsc{cCE}.
When the measurements in the labs are space-like separated---as they are in any experiment that seals the locality loophole~\cite{brunner2014bell}---these inter-lab causal influences must be superluminal\footnote{In fact, as shown in Ref.~\cite{bancal2014quantum}, such influences must have infinite speed.}.  
%We therefore refer to any such causal account as parametrically {\em classical} and structurally {\em superluminal}, abbreviated as \textsc{cCE}.
%\rob{[Kill this.]These are the models that best capture  the sort of causal account of Bell inequality violations that is endorsed by proponents of Bohmian mechanics. }
%In an abuse of terminology, we will also use the term \textsc{cCE} to refer to any model which posits a causal influence between the labs, even when the experiment being modelled has {\em not} sealed the locality loophole (as is the case with ours).
 %, for instance \color{red} Ref.~[SEParticleonBohm?,Goldstein?,Valentini?, Maudlin's book?].
 %\footnote{Note that in such models, the superluminal causal influences cannot be leveraged to send superluminal {\em signals}.} 
 In this article, we will consider one particular representative from the class of \textsc{cCE} models,
 %\textsc{cCE} models,
  %\rob{denoted \textsc{cCE}$_0$,}
 corresponding to assuming the DAG depicted in Fig.~\ref{DAGs}(c).  We denote it by a subscript `0', i.e., \textsc{cCE}$_0$, simply as a reminder that there are other
 models in the \textsc{cCE} class.
 % \rob{and allowing any classical parameter values.}
We will refer to  the cardinality of the set of values that a variable $\Lambda$ can take as simply the {\em cardinality of $\Lambda$}.  We consider each possibility for the cardinality of $\Lambda$---up to the cardinality that saturates the set of achievable distributions~\cite{rosset2018universal}---as a distinct model.  (A more detailed discussion of the cardinality of $\Lambda$ is provided in Appendix~\ref{DetailsOnSlate}.)
%the Supplementary Material.) 
 \rob{We assume that the model is parameter-unrestricted, so that 
%for each cardinality, 
we allow {\em any} classical parameter values.}
%  For each cardinality, we allow {\em any} classical parameter values; we refer to this latter assumption as the model being {\em parameter-unrestricted}.
 
%We consider each possibility for the cardinality of the latent variable $\Lambda$ [define cardinality here] (up to the cardinality that saturates the set of achievable distributions~\cite{rosset}) as a distinct model, allowing any classical parameter values relative to this choice. 
The compatible correlations in this case (for a fixed cardinality of $\Lambda$) are those that can be written as
% conditional distributions over the observed variables are those that can be written as
\begin{align}
P^{_{\rm \scalebox{.6}{\hspace{-.001cm}cCE}_0}}_{XY|ST}&:= \sum_{\Lambda} P_{X|S\Lambda} P_{Y|ST\Lambda} P_{\Lambda}, 
%P_{_{\rm \scalebox{.6}{\hspace{-.15cm}cSL}}}(xy|st)&:= \sum_{\lambda} P_1(x|s\lambda)P_2(y|st\lambda) P_3(\lambda), 
%P_{_{\rm \scalebox{.6}{\hspace{-.15cm}cSL}}}(xy|st) &:= 
%\sum_{\lambda=1}^N P_1(x|s\lambda)P_2(y|t\lambda) P_3(\lambda),
\label{cslmodel}
\end{align}
for some choice of conditional probability distributions $P_{X|S\Lambda}, P_{Y|ST\Lambda},$ and $P_{\Lambda}$.
%, where $N$ is the cardinality of the hidden variable $\Lambda$.


 %The second most prominent
 A second class of causal accounts consists of those models that posit that 
 there is a latent variable that causally influences not only the two outcomes, but also one or both of the setting variables.  
% the latent variable that is a common cause of the two outcomes can also causally influence one (or both) of the setting variables.
% there is a latent variable that acts as a common cause   of a setting variable in one lab and the outcome variable in the opposite lab.
 %\rob{\footnote{It is more typical to describe this case as psoiting a common cause of typically via the mediary of the latent variable  $\Lambda$ that acts as a common cause of the two outcomes)}. 
We refer to such models as  parametrically {\em classical} and  structurally {\em superdeterministic}, abbreviated as \textsc{cSD}.
  %Such strategies are typically termed ``superdeterministic''. 
% We will also consider one particular representative from class (ii),
%  %the class of superdeterministic classical causal models,
%   corresponding to the DAG depicted in Fig.~\ref{DAGs}(c) and referred to as the \textsc{cSD} model (for parametrically classical, structurally superdeterministic). 
    %We will also consider one particular representative from the class of \textsc{cSD} models,
 (See Ref.~\cite{wood2015lesson} for a justification of this causal-modelling perspective  on
  the hypothesis of superdeterminism.)
We will again consider one particular representative from this class, 
%which we denote by \textsc{cSD}$_0$ as a reminder that there are alternatives,
corresponding to assuming the DAG depicted in Fig.~\ref{DAGs}(d). \rob{We denote this model by \textsc{cSD}$_0$, where the subscript simply serves as a reminder that there are other representatives.}
 %\rob{and allowing any classical parameter values}.
 Again, we consider each possibility for the cardinality of the latent variable $\Lambda$ as a distinct model, and we \rob{take the model to be parameter-unrestricted.}
% take each of these  to be parameter-unrestricted.
 %\rob{and within each such model, we }
%allow any classical parameter values.  
Because the setting $S$ has a causal parent in this DAG, we must explicitly condition on $S$ to obtain the conditional $P_{XY|ST}$.
 %correlations,
That is, 
$P^{{\rm \textsc{cSD}}_0}_{XY|ST} = P^{{\rm \textsc{cSD}}_0}_{XYS|Y} / P^{{\rm \textsc{cSD}}_0}_{S|T}$. 
%$P^{_{\rm \scalebox{.6}{\hspace{-.001cm}\textsc{cSD}}}_0}_{XY|ST} = P^{_{\rm \scalebox{.6}{\hspace{-.001cm}\textsc{cSD}}}_0}_{XYS|Y} / P^{_{\rm \scalebox{.6}{\hspace{-.001cm}\textsc{cSD}}}_0}_{S|T}$. 
%$P_{_{\rm \scalebox{.6}{\hspace{-.15cm}\textsc{cSD}}}}(xy|st) = P_{_{\rm \scalebox{.6}{\hspace{-.15cm}\textsc{cSD}}}}(xys|t) / P^{_{\rm \scalebox{.6}{\hspace{-.15cm}\textsc{cSD}}}}{s|t}$. 
Consequently, the compatible correlations in this case (for a fixed cardinality of $\Lambda$) are those that can be written as
%conditional distributions over the observed variables in this case are those of the form
 \begin{align}
% P^{{\rm \scalebox{.6}{\hspace{-.001cm}\textsc{cSD}}}_0}_{XY|ST}
P^{{\rm \textsc{cSD}}_0}_{XY|ST}
&:=  \frac{ \sum_{\Lambda} P_{X|S\Lambda} P_{Y|T\Lambda} P_{S|\Lambda} P_{\Lambda}}{\sum_{\Lambda'} P_{S|\Lambda'} P_{\Lambda'}}. 
%P_{_{\rm \scalebox{.6}{\hspace{-.15cm}\textsc{cSD}}}}(xy|st) &:=  \frac{ \sum_{\lambda} P_1(x|s,\lambda)P_2(y|t,\lambda)P_3(s|\lambda)P_4(\lambda)}{\sum_{\lambda'} P_3(s|\lambda')P_4(\lambda')}. \label{cSDmodel}
\end{align}
for some choice of conditionals $P_{X|S\Lambda}$, $P_{Y|T\Lambda}$,  $P_{S|\Lambda}$ and $P_{\Lambda}$.
%where $P_1,P_2,P_3, P_4$ are conditional probability distributions and $N$ is the cardinality of the discrete hidden variable. 
%where the first equality follows from classical probability theory.
 
% \color{red} [It is sufficient to just say this in the discussion section]\color{black}
% In the discussion section, we will explain why our conclusions are likely to hold also 
%  %have continued to hold
%   for {\em any} superluminal, superdeterministic, or retrocausal classical causal model that can do justice to our experimental data.  
% % term the ``classical super-luminal''  model, and denoted {\rm cSL}.  
 
% ... where {\rm cSL} refers to ``classical super-luminal'' and {\rm cSD} refers to ``classical superdeterministic''. each of the superluminal and superdeterministic classes of models.  Specifically, the models depicted in Figs.    and we explain why our conclusions would be similar for other such models. 
 




 
%We will now discuss some alternative physical theories and the causal models of a Bell experiment they imply. Superluminal and Valentini blah blah blah. \rob{... where {\rm cSL} refers to ``classical super-luminal'' and {\rm cSD} refers to ``classical superdeterministic''.} \color{green} Rob, can you write out this paragraph\color{black}
%
%\begin{align}
%P_{_{\rm \scalebox{.6}{\hspace{-.15cm}cSL}}}(xy|st)&:= \sum_{\lambda} P_1(x|s\lambda)P_2(y|st\lambda) P_3(\lambda), \\
%P_{_{\rm \scalebox{.6}{\hspace{-.15cm}cSD}}}(xy|st)&:= \sum_{\lambda} \frac{P_1(x|s,\lambda)P_2(y|t,\lambda)P_3(s|\lambda)P_4(\lambda)}{\sum_{\lambda'} P_3(s|\lambda')P_4(\lambda')} \label{cSDmodel},
%\end{align}
%where $P_1,P_2,P_3, P_4$ are coditional probability distributions and $N$ is the cardinality of the discrete hidden variable. 

%The final causal model we consider is one that is structurally {\em  locally causal} (hence described by a DAG of the common-cause 
%locally causal
The final causal model we consider is one that is structurally of the common-cause form, just as \textsc{cCC} is, but  parametrically {\em quantum},  abbreviated \textsc{qCC} and
% {\em  locally causal} (hence described by a DAG of the common-cause  form) but  parametrically {\em quantum},  abbreviated \textsc{qCC} and
%a quantum causal model with the structure of the Bell DAG, 
 %but with quantum parameters, 
 depicted in Fig.~\ref{DAGs}(e).  Here, the latent common cause consists of the composite of the pair of quantum systems prepared in the Bell experiment, denoted $AB$.  The associated node in the DAG is depicted differently from the others  as a reminder that the parameters which make reference to it  are conditional density operators rather than conditional probability distributions.
%The final model we consider is a causal model with the structure of the Bell DAG but where  one allows the parameters to be more exotic than conditional probability distributions,  a strategy that is discussed in Refs.~\cite{LeiferSpekkens,wood2015lesson,allen2017quantum}. 
%In particular, e consider the case where the influence of the latent common cause is governed by the formalism of density operators and positive operator-valued measures (POVMs).  
%We refer to this as the \textsc{qCC} model, standing for parametrically quantum and structurally locally causal.
%The latent common cause is indicated in the DAG by a circular node to remind that the parameters related to it are exotic.
The distributions over the observed variables that are deemed compatible are computed from an expression similar to Eq.~\eqref{clcmodel}, but where do-conditionals 
%conditional probabilities
 are replaced by conditional density operators.  In the notation of Ref.~\cite{leifer2013towards}, this expression is
\begin{align}
P^{\;{\rm \scalebox{.6}{\hspace{-.15cm}\textsc{qCC}}}}_{XY|ST} &:= {\rm Tr}_{AB} \big( \rho_{X|SA} \;\rho_{Y|TB}\;  \rho_{AB} \big).\nonumber
%\label{qlcmodel1}
\end{align}
\rob{for some choice of conditional density operators $\rho_{X|SA}$, $\rho_{Y|TB}$, and $\rho_{AB}$}.  
%Here, $\rho_{D|C}$ denotes a positive operator on $CD$ satisfying ${\rm Tr}_D (\rho_{D|C}) =\mathbb{I}_C$.
In a more conventional notation, the compatible distributions 
%$P^{_{\rm \scalebox{.6}{\hspace{-.001cm}qLC}}}_{XY|ST}$ 
are those whose components can be expressed as:
%that can be written as:
%The implications of this expression for the compatible distributions  in a more conventional notation:
%which, as noted in Ref.~\cite{}, implies the following expression for the compatible distributions
% can be expressed in more conventional notation as
%The distributions that are compatible with  the \textsc{qCC} model are
\begin{align}
P^{_{\rm \scalebox{.6}{\hspace{-.001cm}\textsc{qCC}}}}_{XY|ST}(xy|st) &:= {\rm Tr}_{AB} \big[ (E^A_{x|s}\otimes E^B_{y|t}) \rho_{AB} \big],\label{qlcmodel}
%P_{_{\rm \scalebox{.6}{\hspace{-.15cm}qLC}}}(xy|st) &:= {\rm Tr}_{AB} \big( (E^A_{x|s}\otimes E^B_{y|t}) \rho_{AB} \big),\label{qlcmodel}
\end{align}
\rob{for some choices of $\{ E^{A}_{x|s}\}_{x}$ and $\{ E^{B}_{y|t}\}_{y}$, which are positive operator-valued measure on systems $A$ and $B$ respectively, and for some choice of $\rho_{AB}$, which is a density operator on the bipartite system $AB$.}
%where $\{ E^{A}_{x|s}\}_{x}$ (resp. $\{ E^{B}_{y|t}\}_{y}$) is a positive operator-valued measure on system $A$ (resp. $B$) and $\rho_{AB}$ is a density operator on the bipartite system $AB$.
 Note that one obtains a distinct model for every choice of Hilbert-space dimension for $A$ and $B$.
%state on the systems $A$ and $B$. 
%\color{green} Rob, can you add some reference to what system A and system B are in the context of a Bell experiment. \color{black}





%-----------------Model Selection---------------------------------




\textit{Model Selection.} Each causal model we consider defines, via Eqs.~(\ref{clcmodel})-(\ref{qlcmodel}), a set of correlations
%conditional probability distributions
 %$P(xy|st)$ 
 that are compatible with it. Each of these sets constitutes a statistical model. The problem of causal model selection,  therefore, reduces to statistical model selection. We denote the set of all possible distributions compatible with a causal model $\textsc{M}$ by $\mathcal{P}_{\textsc{M}}$. 
 
 % \rob{We will here be considering $M\in \{ \textsc{cCC},\textsc{cCE}_0,\textsc{cSD}_0,\textsc{qCC} \}$.} \rob{[Maybe stipulate here the variation in the cardinalities?]} 

%$M_{\rm C}$. 
 %The question of causal model selection can thereby be phrased in terms of statistical model selection. We want to know which set of probability distributions (a model) ``best'' describes the experimental data. \par
% \par

Consider the problem of identifying which values of the parameters in a causal model best fit a given set of observed data.  \rob{Quality of fit is measured by a loss function between the set of correlations realized by those parameter values (the realized statistical model) and the observed relative frequencies.} The best-fit model is the one that minimizes this loss function.  
%and the parameter estimate is chosen to be the one that minimizes this loss. 
  We will use the squared error loss function, which for our data corresponds to
 \begin{equation}
\rob{   {\rm loss}(P,F) =  \sum_{s,t,x,y}\big[ P_{XY|ST}(xy|st) -F(xy|st) \big]^2,   }
   \label{loss}
\end{equation}
 where $F(xy|st)$  is the observed relative frequency of outcomes $X=x$ and $Y=y$ given settings $S=s$ and $T=t$, while $P_{XY|ST}(xy|st)$ is the probability of outcomes $X=x$ and $Y=y$ given settings $S=s$ and $T=t$ for a particular choice of parameters in the model.  \rob{Here, $F$ and $P$ denote the matrices whose components are $F(xy|st)$ and $P_{XY|ST}(xy|st)$ respectively.}
 %Eq.~(\ref{L2loss}),  
We opt for this loss function as it is the most common choice\footnote{Although we also performed the data analysis using other loss functions and the conclusions remained the same.}.  \rob{The set of data that one uses to optimize the model parameters is called the {\bf training set}, denoted $F_{\rm train}$.}
%We take $F_{\rm train}(xy|st)$  to denote the observed relative frequency of outcomes $X=x$ and $Y=y$ given settings $S=s$ and $T=t$ in the training set of data, with  
The minimum value of the loss achieved by a model $M$ in a variation over parameter values consistent with that model is termed the {\bf training error} for $M$,
%Given this choice, the training error for model $\textsc{M}$ is
\begin{equation}
   %{\rm loss}_{\textsc{M}}(F_{\rm train}) 
\rob{   {\rm TrainingErr}_{\textsc{M}} = \min_{P\in \mathcal{P}_{\textsc{M}}} 
{\rm loss}(P,F_{\rm train})   }
   \label{L2loss}
\end{equation}
 %where $F_{\rm train}$  is the matrix of observed relative frequencies in the training data set. 
The set of correlations defined by the best-fit model is consequently
%are consequently given by the probability matrix
 \begin{equation}\label{bestfitmodel}
\rob{\hat{P}^{\textsc{M}}= \underset{P\in \mathcal{P}_{\textsc{M}}}{\rm argmin}  \ {\rm loss}(P,F_{\rm train})   }
\end{equation}
%\rob{[How to put the subscript underneath argmin?]}

%Consider the problem of identifying which values of the parameters in a causal model best fit a given set of observed data. Quality of fit is measured by a loss function and the parameter estimate is chosen to be the one that minimizes this loss. 
% The minimum value achieved by a model is termed the {\bf training error}.   We will use the squared error loss function, Eq.~(\ref{L2loss}),  as it is the most common choice\footnote{Although we also performed the data analysis using other loss functions and the conclusions remained the same.}. Given this choice, the training error for model $\textsc{M}$ is \color{red}
%\begin{equation}
%   {\rm loss}_{\textsc{M}} = \min_{P\in \mathcal{P}_{\textsc{M}}} \sum_{s,t,x,y}\big[ P_{XY|ST}(xy|st) -F_{\rm train}(xy|st) \big]^2, \label{L2loss}
%\end{equation}
%\color{black} where \color{red}$F_{\rm train}(xy|st)$ \color{black}  is the observed relative frequency of outcomes $X=x$ and $Y=y$ given settings $S=s$ and $T=t$ \color{red}{in the training data set}\color{black}. 

%Returning to the problem of comparing different models, one cannot simply stipulate choosing the model with the smallest training error as the selection criteria. 
Returning to the problem of model selection, the reason one cannot simply select the model with the smallest training error is that this would fail to take into account overfitting.
% and would consequently result in less predictive power. 
%This does not take into account overfitting and results in poor decisions. 
For example, in the case of a pair of models, $\textsc{M}$ and $\textsc{M}'$, 
%wherein $M'$ is nested within $M$, i.e.,
where there is strict inclusion of the sets of compatible distributions, $\mathcal{P}_{\textsc{M}'} \subset \mathcal{P}_{\textsc{M}}$,
%For example, in the case of nested statistical models (i.e., strict inclusion of the sets of compatible distributions, $M_i \subset M_{i+1}$), 
such a selection criterion would always prefer the model with the largest set of compatible distributions,
 %independent of the nature of the observed data
  even though the latter may be less predictively accurate. 
%A more appropriate criterion is to minimize the prediction loss of the model on independent data.
A more appropriate criterion is to select the model that minimizes the predictive error for independent data, a quantity termed 
 %This is called
 the {\bf test error}~\cite{hastie2003elements}. 
%There is no reason we should use a different loss function so the expected test error is
%\begin{equation}
%    \mathbb{E}[{\rm LOSS_{_X}}] =  \mathbb{E}_{F}\sum_{s,t,x,y}\big( \hat{P}_{_{\rm X}}(xy|st)- F(xy|st) \big)^2 ,\label{ExpectedTEloss}
%\end{equation}
%where $\hat{P}_{_{\rm X}}(xy|st)$ is the estimate resulting from minimizing the training error and the expectation value is taken over future conditional frequency observations $F(xy|st)$. 

%Unfortunately we
%One cannot calculate this value without knowing the underlying distribution, 
%[Stuff from this paragraph to be moved to SM]} 
%Because the test error is defined in terms of the true underlying distribution, which is unknown, one must in practice make use of an estimate of the latter.
Strictly speaking, the test error of a statistical model is defined as its quality of fit with the true underlying distribution.
%the quality fo fit between a statistical model and the true underlying distribution.  
However, the latter is unknown, and so in practice one makes use of an estimate of the test error.  We follow a standard approach for data-rich problems, wherein \rob{one estimates the test error of one's statistical model using a second data set} called the {\bf test set} and denoted $F_{\rm test}$. 
 %one splits the data into two sets, the {\em training set}, with which one fits the model parameters, and
  %the {\em test set}, with which one estimates the test error.
 Specifically, we use what is termed the {\em plug-in estimate} of the test error~\cite{wasserman2013all}, 
 %we evaluate
%without requiring any of the data to be set aside and not used for fitting the model parameters.
%so one must instead estimate it. 
%Common approaches to this problem include the Akaike Information Criteria (AIC), Bayesian Information Criteria (BIC) and Cross Validation (CV). These techniques allow the estimation of the distribution without requiring additional data to be set aside and not used for fitting the model parameters. This is useful when taking more data is difficult or impossible. In our experiment, however, this is not a constraint and we can instead simply sample more data and calculate the loss on a independent second data set
% \rob{[Fix the following equation to refer to loss(P,F)]}
\begin{equation}
     %{\rm \widehat{loss}_{\textsc{M}}}(F_{\rm test})
     {\rm \widehat{TestErr}}_{\textsc{M}} = {\rm loss}( \hat{P}^{\textsc{M}}, F_{\rm test})
     %=  \sum_{s,t,x,y}\big[  \hat{P}^{\textsc{M}}_{XY|ST}(xy|st)- F_{\rm test}(xy|st) \big]^2 
     \label{ExpectedTEloss},
\end{equation}
\rob{where  $\hat{P}^{\textsc{M}}$ is as defined in Eq.~\eqref{bestfitmodel}, namely, the statistical model defined by causal model $M$ and parameter values that yield the best fit to the training set. }
% $\hat{P}^{\textsc{M}}_{XY|ST}(xy|st)$ is the estimate of the distribution obtained from minimizing ${\rm loss}_{\textsc{M}}$ on the training data and \rob{$F_{\rm test}$ denotes the observed relative frequencies in the test data.}
If the test set is large, this is likely to be a good estimate \rob{of the true test error of the statistical model $\hat{P}^{\textsc{M}}$}. 
Our criterion for model selection is minimization of the estimated test error.   
% \rob{That is, if $\mathcal{M}$ denotes the slate of causal models under consideration, the favoured causal model is
%\begin{equation}
%\textsc{M}_*  = \underset{ \textsc{M} \in \mathcal{M} }{\rm argmin} \ {\rm \widehat{TestLoss}}_{\textsc{M}}.
%     \label{Favoured Model}
%\end{equation}
%}
Hereafter, we will refer to the estimated test error as simply the test error.


%\rob{[I suggest that we drop the paragraph below, and simply state in the SM that the cardinality of the latents can be conceptualized as one of the parameters in the fit, and so it is natural that we optimize over it as well.  That is, we parametrize in such a way that the cardinality is an integer parameter that we vary over.]}

\begin{comment}
Before continuing, we must address a nuance of the analysis. 
%an additional nuance must be addressed.
 %A causal model with a latent variable $\Lambda$ cannot be parameterized for an arbitrary cardinality of the set of values of $\Lambda$. 
The distributions compatible with a given classical causal model depend on the cardinality of any latent variable (i.e., the number of values it can take). A priori, it may seem reasonable to presume the cardinalities that saturate the set of distributions compatible with the causal structure (these are finite for classical causal models where the observed variables are discrete~\cite{rosset2018universal}). 
%does not grow under any further increases of the cardinality.
 %such that which saturates the model, meaning that the set of compatible distributions cannot be increased by further increases to the cardinality 
 %(Ref.~\cite{rosset} demonstrates that it is finite).  
 This choice, however, may overfit the data relative to a model with smaller cardinalities.  Consequently, for a given causal structure, we treat each possibility for latent cardinalities as a separate model and optimize over these.  Thus, the test error reported for  \textsc{cCE}$_0$ and \textsc{cSD}$_0$  is the {\em minimal} value of this loss in a variation over the cardinality of $\Lambda$. (We take a similar approach to cardinality in fits to the \textsc{cCC} model, to be discussed below.)
% \rob{For the \textsc{cCE}$_0$ and \textsc{cSD}$_0$ models, } we consider different possibilities for the cardinality of $\Lambda$, treating each hypothesis about this cardinality as a separate model.  The loss reported for  \textsc{cCE}$_0$ and \textsc{cSD}$_0$   is the {\em minimal} value of this loss in a variation over this cardinality.  \rob{(We take a similar approach to cardinality in fits to the \textsc{cCC} model, to be discussed below.)}
For the quantum model,  where the common cause is modelled as a bipartite system $AB$ rather than a variable $\Lambda$,  the analogue of the cardinality of $\Lambda$ is the dimension of the Hilbert space describing $AB$. 
%The quantum analogue of varying the cardinality of the set of values of the variable common cause is varying the dimension of this system.
%The quantum analogue of the cardinality of the variable $\Lambda$ is the dimension of the Hilbert space describing $AB$. 
We here presume that $A$ and $B$ are qubits, hence $AB$ is of dimension 4.
%each of dimension 2.
%consisting of a pair of qubits, 
%with one qubit distributed to each lab.  
Although one could explore \textsc{qCC} models with higher-dimensional common causes, we found that the model using two qubits already outperformed the other causal models on our slate of candidates, and so we did not need to consider any variation in the dimensionality.
%The reason we do not consider a variation of this dimension, 
%We do not vary our \textsc{qCC} models with different dimensions of the quantum common cause since two qubits was already sufficient to outperform the other causal models.
% it already outperformed the other causal structures when only considering the two-qubit case. 
\end{comment}

Note that for the \textsc{cCE}$_0$ and \textsc{cSD}$_0$ models, we treat each possibility for the cardinality of $\Lambda$ as a separate model and find the one with the most predictive power.
%optimize over these.  
Thus, the test error reported for these
 %\textsc{cCE}$_0$ and \textsc{cSD}$_0$  
 is the {\em minimal} value in a variation over this cardinality.  (We take a similar approach to cardinality in fits to the \textsc{cCC} causal model, to be discussed below.)
For the quantum model,  where the common cause is modelled as a bipartite quantum system $AB$ rather than a variable $\Lambda$,  the analogue of the cardinality of $\Lambda$ is the dimension of the Hilbert space describing $AB$. 
%We here presume that $A$ and $B$ are qubits, hence $AB$ is of dimension 4.  
%Although one could explore \textsc{qCC} models with higher-dimensional common causes, we found that the model using two qubits already outperformed the other causal models on our slate of candidates, and so we did not need to consider any variation in the dimensionality.
Because we found that the model wherein $AB$ is a pair of qubits 
%using two qubits 
already outperformed the other causal models on our slate of candidates, we did not explore \textsc{qCC} models with higher-dimensional common causes.




% -------------------------------------- Results Section -------------------------------------------------------



\begin{figure*}[t!]
\begin{center}
\includegraphics[scale=0.3]{experimentaldiagram_dephasing.png}
\caption{Experimental diagram.  Maximally polarization entangled photons pairs are created through parametric down conversion in both paths of a Sagnac interferometer.  After compensating for the drift in the fiber-optic, each photon is sent to a polarization measurement, where the choice of measurement is controlled by half-wave plates, and coincidence counts %between a photon being measured on both sides of the experiment 
are recorded.  In the dephased version of the experiment (discussed in Appendix~\ref{dephased}), 
%the Supplementary Material), 
a dephasing channel based on an LCR is implemented on one of the photons prior to measurement, while in the entangled version of the experiment, this channel is absent.
  PPKTP,  periodically-poled  potassium  titanyl  phosphate;  PBS,  polarizing beamsplitter;  LCR,  liquid  crystal  retarder;  HWP,  half-wave  plate;  QWP,  quarter-wave plate; DC, dichroic mirror}
\label{Experimental Diagram}
\end{center}
\vspace{-2em}
\end{figure*}




\textit{Results.} In our experiment, polarization entangled photons are generated using type-II spontaneous parametric down-conversion (Fig.~\ref{Experimental Diagram}) at a rate of 22000 singles/s and 800 coincidences/s with a 3ns coincidence window. The source produces the state $\frac{1}{\sqrt{2}}(\ket{HH}+\ket{VV})$ with $97.9\pm0.07\%$ fidelity. The photons are sent to different polarization analyzers, functioning as Alice's and Bob's labs, each one implementing one of six possible binary-outcome measurements. The data was collected for 10$s$ for each pair of values $(s,t)$ of the measurement setting variables,
%Each pair of measurement settings $(s,t)$ was used for 10 seconds, 
and the relative frequency $F(xy|st)$ with which Alice obtains outcome $x$ in coincidence with Bob obtaining outcome $y$ was recorded. \rob{The Poissonian noise model for the photon counts is used to generate bootstrap estimates of the confidence intervals.} 
%the frequencies $F(xy|st)$ recorded the 
%number of coincidences between Alice and Bob's outcomes for each measurement $(x,y)$. 
%\begin{equation}
%F(xy|st) = \frac{N_{xy|st}}{N_{00|st}+N_{10|st}+N_{01|st}+N_{11|st}}.
%\end{equation}
The entire experiment was performed twice, thereby yielding a training data set and a test data set. 
%repeated again immediately afterwards to collect a second data set called the test data. 
These two data sets are the only inputs to our causal discovery algorithm.

%As only the $\textsc{cCE}_0$, $\textsc{cSD}_0$, and $\textsc{qCC}$ models can account for the Bell inequality violations in our data, these are the ones we must adjudicate between.

%Of the four models we have defined, given that $\textsc{cCC}$ cannot account for experiment data that violates Bell inequalities 
Given that our purpose here is to adjudicate between models that {\em can} account for a violation of Bell inequalities, we leave aside $\textsc{cCC}$, and focus on adjudicating between  $\textsc{cCE}_0$, $\textsc{cSD}_0$, and $\textsc{qCC}$. 
%As only the $\textsc{cCE}_0$, $\textsc{cSD}_0$, and $\textsc{qCC}$ models can account for the Bell inequality violations in our data, these are the ones we must adjudicate between.
  The training errors and the test errors for each are shown in Fig.~\ref{EntangledLoss}. Recall that the selection criterion is minimization of the test error.
% the \textsc{qCC}  model emerges as the preferred model.  
%We now examine the likely reasons for this.
%The training losses and the test errores for each causal model in the set $\{ \textsc{cCC},\textsc{cCE},\textsc{cSD},\textsc{qCC}\}$ 
%are shown in Fig.~\ref{EntangledLoss}. \rob{[This should be modified to exclude \textsc{cCC}]} Recalling that the selection criteria is minimization of the test error, the \textsc{qCC}  model emerges as the preferred model.  We now examine the likely reasons for this.
% The difference between the \textsc{qCC} and \textsc{cCE} models is approximately 5 standard deviations with a similar gap between \textsc{qCC} and \textsc{cSD}. The training loss offers insight into the shortcomings of \textsc{cCE} and \textsc{cSD} relative to \textsc{qCC}.
%the other causal models.
%To begin with, \rob{and as a test of our model selection technique, we} consider the \textsc{cCC} model. \rob{We found that it has a training loss of $800 \pm ???$ [Patrick can you report the value],  far in excess of the training loss of \textsc{cCE}, \textsc{cSD} or \textsc{qCC}, indicating that it underfits the data relative to them.  This is to be expected, of course, because, unlike the latter three models, the \textsc{cCC} model cannot violate Bell inequalities and hence cannot do justice to the data.  It consequently also has little predictive power, achieving a test error of $800 \pm ???$ [Patrick can you report the value], also far in excess of \textsc{cCE}, \textsc{cSD} or \textsc{qCC}.}
As the difference in test error between  \textsc{cCE}$_0$ and \textsc{qCC} is approximately 5 standard deviations,
 %\rob{[@Patrick: The simulations described in the SM predicted that we would see a gap of 10 standard deviations.  Should we comment on this when we bring it up in the SM?]}, 
 and there is a similar gap between  \textsc{cSD}$_0$ and \textsc{qCC}, it follows that \textsc{qCC}  emerges as the preferred model with high statistical confidence.   

\textit{Discussion.} We now address the question of  {\em why} \textsc{qCC} tests better (i.e., achieves a lower test error) than \textsc{cCE}$_0$ and \textsc{cSD}$_0$.  The fact that both \textsc{cCE}$_0$ and \textsc{cSD}$_0$ {\em train} better (i.e., achieve a lower training error) than \textsc{qCC}
 %\textsc{qCC} {\em trains}  worse (i.e., achieves a higher training error) than either \textsc{cCE}$_0$ or \textsc{cSD}$_0$
  provides some insight into why this is the case.  When a model trains better but tests worse than another, a likely explanation is that the first is more prone to overfitting---achieving a better fit to the training data by fitting to statistical fluctuations found therein---and this in turn implies a worse fit to the test data. It is likely, therefore, that \textsc{cCE}$_0$ and \textsc{cSD}$_0$ overfit the data as compared
%relative
 to \textsc{qCC}.


%It has a much higher training loss than the other three models, indicating that it underfits the data relative to them.  This is to be expected, of course, because this model cannot violate Bell inequalities and hence judges the data unlikely.  Unlike the \textsc{cCC} model, the \textsc{cCE}, \textsc{cSD} and \textsc{qCC} models cannot be ruled out by a traditional Bell inequality and hence all train better (i.e., achieve a lower training loss) and  test better (i.e., achieve a lower test error) than the \textsc{cCC} model.
% 
% The difference in test error between  \textsc{cCE} and \textsc{qCC} is approximately 5 standard deviations with a similar gap between  \textsc{cSD} and \textsc{qCC}.   What we wish to understand 
% %are interested in understanding
%  is {\em why} \textsc{qCC} tests better than \textsc{cCE} and \textsc{cSD}.  The fact that  \textsc{qCC} {\em trains}  worse  than either \textsc{cCE} or \textsc{cSD} offers insight into why this is the case.  When a model trains better but tests worse than another, a likely explanation is that the first is more prone to overfitting---achieving a better fit to the training data by fitting to statistical fluctuations found therein---and this in turn implies a worse fit to the test data. 
 
%  The difference between the \textsc{qCC} and \textsc{cCE} models is approximately 5 standard deviations with a similar gap between \textsc{qCC} and \textsc{cSD}. The training loss offers insight into the shortcomings of \textsc{cCE} and \textsc{cSD} relative to \textsc{qCC}.

% Both models train better than the \textsc{qCC} model (i.e., achieve a lower training loss) but test worse (i.e., achieve a higher test error).  The fact that they train better and test worse than the \textsc{qCC} model suggests that they are more prone to overfitting, that is, fitting features of the statistical noise in the training data which are not reproduced in the test data.
%  are able to fit the initial training data better than \textsc{qCC}, but they both test worse. This implies that the fact that 
%  the improvement in their fit to the training data, relative to \textsc{qCC}, is a result of erroneously fitting parameters to features in the statistical noise.

\begin{figure}[htb]
\begin{center}
\includegraphics[scale=0.24]{fig3_entangled.png}
\caption{
%The results from the entangled experiment.
%The results of the experiment. 
Adjudicating between different causal models based on the experimental data.
 Plotted are the training error (blue) and test error (red) for the \textsc{cCE}$_0$, \textsc{cSD}$_0$ and \textsc{qCC} models. 
% Red denotes test error and blue denotes The red bar is test error for that model and the blue is the training loss. 
Error bars denote a confidence region of one standard deviation. The \textsc{qCC} model has the lowest test error and is therefore preferred. The fact that the larger test error of the \textsc{cCE}$_0$ and \textsc{cSD}$_0$ models is accompanied by {\em a lower training error}
%The fact that the \textsc{cCE}$_0$ and \textsc{cSD}$_0$ models have a larger test error {\em but a lower training loss}
%\textsc{qCC} also has the largest training loss 
suggests that they {\em overfit} the data relative to \textsc{qCC}.}
\label{EntangledLoss}
\end{center}
\vspace{-2em}
\end{figure}


%In order to provide an additional check of our model selection technique, we also considered the predictive power of the \textsc{cCC} model in our experiment.  We found that it has a training loss of $790 \pm 10$,  far in excess of the training loss of \textsc{cCE}, \textsc{cSD} or \textsc{qCC}, indicating that it underfits the data relative to them, as one expects given its inability to violate Bell inequalities.  It consequently also has little predictive power, achieving a test error of $800 \pm 10$, also far in excess of \textsc{cCE}, \textsc{cSD} or \textsc{qCC}. 
%As another check, we performed a second experiment, wherein the quantum source is dephased (such that the bipartite state it prepares is unentangled).In this case, one expects that the \textsc{cCC} model will have training and test errores comparable to the \textsc{qCC} model, and this is indeed what we find.  The results are presented in the Supplementary Material.  Interestingly, the \textsc{cCE} model trains noticeably better and tests noticeably worse than either \textsc{cCC} or \textsc{qCC}, while the  \textsc{cSD} model  trains marginally better and tests marginally worse, suggesting to us that the additional parametric freedom inherent in these models still leads them to fit to statistical noise even in the dephased version of the experiment.  


%A second experiment, wherein the quantum source is dephased (such that the bipartite state it prepares is unentangled), was also performed in order to provide an additional check of our model selection technique.  In this case, one expects that the \textsc{cCC} model will have predictive power comparable to the \textsc{qCC} model, and this is indeed what we find.  Interestingly, the \textsc{cCE} model trains noticeably better and tests noticeably worse than these, while the  \textsc{cSD} model  trains marginally better and tests marginally worse, suggesting to us that the additional parametric freedom inherent in these models still leads them to fit to statistical noise even in the dephased version of the experiment.  The results are presented in the Supplementary Material.



% --------------------------- Discussion ----------------------------------------

%superdeterminism papers: ~\cite{t2016cellular,hossenfelder2020rethinking}
%,sep-qm-retrocausality}.  

 In a Bell experiment, there is statistical {\em independence} between an outcome variable at one wing and the setting variable at the opposite wing.  This is typically termed the `no-signalling condition'.  Classical causal models that are structurally radical and \rob{parameter-unrestricted}
 %posit no restriction on the physically possible parameter values)
  can reproduce the no-signalling condition, but, as shown in Ref.~\cite{wood2015lesson} (see also Ref.~\cite{cavalcanti2018classical}), they can only do so for a {\em special class} of values of the parameters \rob{(which is a set of measure zero in the full set of possible parameter values, so that they {\em require fine-tuning} in order to do so).}
    %(i.e., they require {\em fine-tuning}). 
    Given that any finite sample of data exhibits statistical fluctuations {\em away} from such independence, in a structurally radical classical causal model, it is possible for the fitting procedure to mistake these fluctuations for real features, thereby yielding best-fit values of the parameters outside of the special class.  In short, such models have an opportunity to overfit the data.  
For structurally conservative models like \textsc{qCC}, on the other hand,  there is no possibility of such overfitting because  the no-signalling condition is implied by the causal structure and therefore
  holds for {\em all} choices of the parameter values.  
%\rob{By contrast, the \textsc{qCC} model reproduces the no-signalling condition for all values of the parameters in the model, and therefore does not fall victim to this type of overfitting.}
%These considerations provide the most plausible account of the fact
This is the reason, we believe, that \textsc{cCE}$_0$ and \textsc{cSD}$_0$ overfit the data as compared to \textsc{qCC}.

Although we have here considered only the \textsc{cCE}$_0$ representative of the \textsc{cCE} class of models and only the \textsc{cSD}$_0$ representative of the \textsc{cSD} class, similar considerations apply for other representatives.  More precisely, for {\em every} DAG in these classes---regardless of what pattern of interlab influences or superdeterministic common causes they posit---as long as the model is parameter-unrestricted,
%allows for arbitrary parameter values,
 the no-signalling condition is only reproduced for a special class of parameter values~\cite{wood2015lesson}.  Consequently, all such models are likely to be found to have less predictive power than $\textsc{qCC}$ by virtue of overfitting. 

%all other models yielding representatives of these classes (and involving no restriction in parameter values) {\em also} can only reproduce the no-signalling condition for a special class of parameter values~\cite{wood} suggests strongly that they too 

% that {\em every} model therein which allows for arbitrary parameter values relative to the DAG---regardless of what pattern of interlab influences or superdeterministic common causes it posits within the DAG---would also  be found to have less predictive power than $\textsc{qCC}$ by virtue of overfitting. 
 
%\rob{[Kevin suggests removing and I agree]} We have a similar expectation for classical causal models that are structurally radical in some other way, such as those which endorse retrocausal influences~\cite{price1994neglected,CostadeBeauregard1977duellistes,sep-qm-retrocausality}. 

% First note that  in a Bell experiment there is statistical {\em independence} between an outcome variable at one wing and the setting variable at the opposite wing.  This is typically termed the `no-signalling condition'.  Models that are structurally radical can reproduce the no-signalling condition, but, as shown in Ref.~\cite{wood2015lesson} (see also Ref.~\cite{cavalcanti2018classical}), they can only do so for a {\em special class} of values of the parameters. Given that any finite sample of data exhibits statistical fluctuations {\em away} from such independence, in a structurally radical model, it is possible for the fitting procedure to mistake these fluctuations for real features, thereby yielding best-fit values of the parameters outside of the special class.  In short, such models have an opportunity to overfit the data.

%i.e., to overfit the data, and to thereby predict violations of the independence relation that are not seen in the test data.
%do not imply the independence of outcomes at one wing from the setting at the other wing as a consequence of d-separation relations, but as a result of choosing the parameter values carefully.  Such models therefore allow for deviations from such independence.    Because 
%This is because, as shown in Ref.~\cite{wood2015lesson} (see also Ref.~\cite{cavalcanti2018classical}), {\em all} models that are parametrically conservative and structurally radical require fine-tuning of their parameters in order to reproduce the statistical independences between an outcome variable at one wing and the setting variable at the opposite wing.  These independences are typically called the `no-signalling conditions', and are a prediction of quantum theory that is supported by the data.
%Because structurally radical models have the capacity to describe violations of the no-signalling condition,
%\footnote{We noted in the main text that structurally radical models have the capacity to describe violations of the no-signalling condition.  Valentini endorses a version of Bohmian mechanics, hence a \textsc{cCE} causal account, and has proposed that violations of the no-signalling condition may be achieved in certain exotic scenarios.}, 
%they can mistake statistical fluctuations away from such independence---which are unavoidable in any {\em finite} sample of data---for real features, thereby leading to overfitting. 
  
%  For structurally conservative models like \textsc{qCC}, on the other hand, there is no possibility of such overfitting because the no-signalling condition is implied by the causal structure and therefore holds for {\em all} choices of the parameter values.
  
%The fluctuations away from such independence, which are unavoidable in any {\em finite} sample of data, may lead to overfitting in such models, 
  %For such models, there is the possibility of erroneously fitting to the fluctuations away from such independence that are seen in any finite sample of data, 
%  while for structurally conservative and parametrically radical models like \textsc{qCC}, there is no such possibility because the independence holds strictly for {\em all} choices of the parameter values. 
  %there are no choices of the parameter values that yield a failure of this independence.  

%We note that overfitting of this sort can occur even for classical causal models if the DAG allows for a failure of a statistical independence that is predicted by the true DAG.  As such, one expects to obtain similar results to the ones we have described even if the quantum source is dephased in such a way that  the bipartite state it prepares is unentangled.
Note that, relative to this account of the overfitting, one expects to obtain similar results 
%to the ones we have described
 even if the quantum source is dephased in such a way that  the bipartite state it prepares is unentangled.
  We confirmed this expectation by performing a dephased version of our experiment and verifying that although the \textsc{cCC} model now performs comparably to the \textsc{qCC} model (since it also satisfies the no-signalling condition for all parameter values), the \textsc{cCE}$_0$ model still trains noticeably better and tests noticeably worse than either the \textsc{cCC} or \textsc{qCC} models, while the  \textsc{cSD}$_0$ model trains marginally better and tests marginally worse.  This lends further support to our interpretation of the overfitting.  Details are provided in Appendix~\ref{dephased}.
  %the Supplementary Material.  



\textit{Conclusions.} 
In this article, we have confined our attention to causal model types wherein no restriction is imposed on the possible values of the parameters.
%The structurally radical classical causal models that are considered in our analysis impose no restriction on the possible values of the parameters.
%; they are {\em parameter-unrestricted}.  %[don't introduce new terminology here]
%The fact that such models are disfavoured relative to the quantum causal model \textsc{qCC} has consequences for various loopholes in Bell tests.  
The fact that \rob{the classical causal models that}
%such parameter-unrestricted model \rob{types} that
  posit 
 %parameter-unrestricted causal models with 
 inter-lab causal influences are disfavoured relative to models of the \textsc{qCC} type
 %{\em even when such influences are not in tension with relativity theory}
  implies that one does not need to seal the locality loophole in a Bell experiment (i.e., perform measurements at space-like separation) in order for it to provide evidence of quantumness.
  %\rob{---such causal influences are disfavoured even when they can do their job without . 
   In addition, the fact that the classical causal models that are superdeterministic are disfavoured relative to models of the \textsc{qCC} type overturns the claim that the loophole associated to the possibility of superdeterministic models
   %superdeterminism loophole
    cannot be closed. 
    % \rob{[Remove the following]} A similar point can be made about the loophole associated with the possibility of retrocausation.  

\rob{We now consider what conclusions can be drawn from our results and our data analysis technique if one relaxes the assumption that there is no restriction on parameter values, that is, what conclusions one can draw for {\em parameter-restricted} causal models.}

%consequences our technique and results  for {\em parameter-restricted} causal models.

%We cannot deliver such strong conclusions for parameter-restricted causal models.  Indeed, 
If  the range of parameter values is restricted in such a way that the model is compatible with {\em all and only}
%reproduces {\em precisely} the same set of
 the correlations achievable in operational quantum theory,
 %(or, equivalently, in the \textsc{qCC} model), 
% including the no-signalling condition,
 so that in particular the no-signalling condition is satisfied for all parameter values,
  then one cannot hope to experimentally distinguish it from \textsc{qCC} via our model selection technique.  The standard view of Bohmian mechanics~\cite{sep-qm-bohm} is likely to be an example of such a model (which is structurally radical  by virtue of allowing inter-lab causal influences).  Presumably, one can also construct superdeterministic   models of the Bell experiment that are of this type. 

If, on the other hand, the range of parameter values is restricted, but not such that it allows
%One can also consider models that are parameter-restricted but not so restricted as to allow
{\em  only} those correlations achievable in operational quantum theory, then the model remains an {\em empirical competitor} to operational quantum theory.
 %.  These constitute {\em empirical competitors} to operational quantum theory.  
 Many proponents of structurally radical ways out of the Bell no-go result \rob{do, in fact, endorse this type of model}
 %such models
  and indeed take its
  %their
   empirical inequivalence to operational quantum theory  to be one of its
   %their
    virtues.  Valentini's subquantum-nonequilibrium version of Bohmian mechanics~\cite{valentini1991signal1,valentini1991signal2,valentini2002signal,valentini2002signaldeterministic}, which explicitly allows for the possibility of violations of the no-signalling condition in Bell experiments, is an example of such a model.  Because a model with a more restricted scope of parameter values can in principle exhibit {\em less} overfitting than its parameter-unrestricted counterpart, the conclusions of our analysis need not apply to these.  Nonetheless, these models can be included in the slate to which one applies the model selection technique described here.  It is merely a question of specifying the range of parameter values and restricting the optimization to this range.  A more detailed description of these conclusions is included  in Appendix~\ref{detailsconclusions}.
    %the Supplementary Material.

\begin{comment}
We note that there may be ideas for how to provide a causal account of Bell inequality violations that resist being cast in the causal modelling framework that we have described here.   This possibility, however, merely prompts the question: how {\em should} such ideas be formalized so that they {\em can} be compared to other models---in particular the \textsc{qCC} model---using standard model selection techniques?  
\end{comment}

\rob{The results reported here serve as a constraint on }
%should guide 
the development of alternatives to quantum theory and of interpretations of the formalism.
More generally, \rob{the techniques we introduce have broad applicability in quantum foundations, as not just Bell-type experiments but {\em all} experiments seeking to adjudicate between different accounts of quantum phenomena} 
%all experiments in quantum foundations, not just Bell-type experiments, 
%would 
stand to benefit from a consideration of whether a given account thereof  {\em overfits} the data, rather than merely a demonstration that it does not underfit the data.


\acknowledgements

%\textbf{Acknowledgements.---} 
This research was supported in part by the Natural Sciences and Engineering Research
Council of Canada (NSERC), Canada Research Chairs,
Industry Canada, the Canada Foundation for Innovation (CFI), and the Canada First Research Excellence Fund (CFREF).
This research was also supported by Perimeter Institute for Theoretical Physics. Research at Perimeter Institute is supported by the Government of Canada through the Department of Innovation, Science and Economic Development Canada and by the Province of Ontario through the Ministry of Research, Innovation and Science. PD would like to thank Sacha Schwarz and Jean-Philippe MacLean for helpful discussions and tips.


%\part*{Supplementary material}
\appendix

\section{Further details on the slate of causal models}\label{DetailsOnSlate}

In the framework for causal modelling that we are presuming, the modifiers `classical' and `quantum' refer only to the {\em parametric} part of a causal model.  The latter is considered classical if the parameters can be specified as conditional probability distributions, while it is considered quantum if the parameters are specified as conditional density operators (or, equivalently, completely positive trace-perserving maps). The structural part of a causal model is presumed to always be stipulated by a DAG.\footnote{The notion of a superposition of causal structures, advocated in some works~\cite{hardy2005probability,oreshkov2012quantum,chiribella2013quantum}, may resist formulation in terms of DAGs.  If so, then this possibility is excluded from the causal modelling framework we adopt here.  Note, however, that this limitation would  not be consequential for the purposes of this article, as we are not aware of any attempts to provide a causal account of Bell inequality violations which appeals to superpositions of causal structures.} 
If the causal structure mirrors the structure of the usual quantum expression for the correlations 
%(Eq.~\eqref{qlcmodel} of the main text)
 when the latter is conceptualized as a contraction of tensors\footnote{See Ref.~\cite{hardy2012operator} for an articulation of this notion of structure for computations.}, then it is deemed conservative.  Otherwise, it is deemed radical.  \rob{In the case of a Bell experiment, the usual quantum expression for the correlations is given in Eq.~\eqref{qlcmodel} of the main text, so that an account has a conservative causal structure only if the DAG has the common-cause form of Figs.~\eqref{DAGs}(b) or (e).  }

% The formula for the quantum predictions in any given experiment in the usual operational formalism \rob{[citation]} can be taken to define a causal structure, which we will here term the {\em conservative causal structure} for that experiment.  
 
 A quantum causal model of the experiment is defined in such a way that it can provide a causal account of the quantum predictions using the conservative causal structure, but where the price for the structural conservatism  is that the model must be  parametrically radical.  A classical causal model  of the same experiment, by contrast, salvages parametric conservatism \rob{by using only conditional probability distributions, but is thereby forced to be radical at the level of the causal structure.}
%  while providing a causal account of the quantum predictions  by being structurally radical.

 
%Any causal account of Bell inequality violations that supposes that 

%It is worth noting that the modifiers `classical' and `quantum' in this article refer to the {\em parameteric} part of the causal model and correspond to whether it is conservative or radical.  The causal structure is presumed to be stipulated by a Directed Acyclic Graph.  


%{\bf Intro}

The causal-modelling perspective on the different ways out of the Bell no-go result was initiated in Ref.~\cite{wood2015lesson}.  That article stipulated how to recast within the framework of classical causal models the various traditional causal accounts of Bell inequality violations, all of which 
%.  ,  that is, the accounts which 
are parametrically conservative (i.e., parametrically {\em classical}) and structurally radical.  These are the accounts that invoke interlab cause-effect relations or superdeterminism.  We say a bit more about each case here.

%{\bf On superluminal models}

%On terminology: Note that the modifiers `classical' and `quantum' in this article refer to the {\em parameteric} part of the causal model and correspond to whether it is conservative or radical.
The \textsc{cCE} class of causal models of the Bell experiment, wherein one posits a cause-effect influence between the labs, subsumes several possibilities for the causal structure.  

% that are parametrically conservative (i.e., parametrically classical) and structurally superluminal, which we termed the \textsc{cCE} class.

In this article, we focussed on one such structure, 
%we focussed on a particular representative of this class, namely, the one 
wherein there is a causal influence from the setting $S$  to the outcome $Y$.  By symmetry, of course we could  just as well have considered the model wherein there is a causal influence from the setting $T$  to the outcome $X$.  A distinct model within the \textsc{cCE} class is one wherein there are setting-to-outcome causal influences in {\em both} directions, that is, $S\rightarrow Y$ {\em and} from $T \rightarrow X$.
%from $S$ to $Y$ {\em and} from $T$ to $X$. 
 Another such model is one wherein there is a causal influence from the {\em outcome} rather than setting on one wing to the outcome on the other wing, such as $X \rightarrow Y$. 
 More generally, every combination of influences between $S, X$ and $T, Y$ (e.g., every combination of arrows $X \rightarrow Y$, $S \rightarrow Y$, $S\rightarrow T$, $X\rightarrow T$,  $Y \rightarrow X$, $T \rightarrow X$, $T\rightarrow S$, $Y\rightarrow S$) that does not introduce cycles when added to the DAG of Fig.~\ref{DAGs}(b) constitutes an element of the \textsc{cCE} class of causal models. \rob{For all such models, the no-signalling condition is not implied by  the causal structure. }
   As we noted in the main text, the results of Ref.~\cite{wood2015lesson} \rob{imply that---assuming we are correct in our assessment that models that can violate the no-signalling condition tend to overfit the data---} {\em all} models \rob {in this class that can realize the quantum correlations}
   %such models
    will be found to overfit the data and therefore to test poorly. 
 %diagnosis of \textsc{cCE}$_0$ and \textsc{cSD}$_0$ as overfitting the data
%\rob{[Provide a figure illustrating these DAGs?]}

%Furthermore, it is worth noting
It is important to note that there are models in this class for which the modifications to the causal structure, radical as they are, still {\em underfit} quantumly realizable data and consequently do not even {\em train} well on such data.
%, let alone test well.
%which also fail to be predictive for quantumly realizable data because they {\em underfit} the data.   
An example is the classical causal model wherein the {\em outcome} at one wing (rather than the setting) has a causal influence on the outcome on the other wing, for instance, one where the DAG of Fig.~\ref{DAGs}(b) in the main text is supplemented by an arrow from $X$ to $Y$. 
 %Such a causal model is parametrically {\em classical} and structurally {\em superluminal}, hence another example of the class \textsc{cCE}.  
 For the case of ternary setting variables and binary outcomes, such a causal model was shown in Ref.~\cite{chaves2015unifying} to imply Bell-like inequalities that are quantumly violated.  As such, one expects that the performance of such models on experimental data that violates such inequalities would be comparable to the performance of the \textsc{cCC} model on our experimental data (see Sec.~\ref{cCCmodel}). 
That is, insofar as such models would {\em underfit} the data, they would both train and test poorly. \rob{The same comments apply to  causal structures wherein the outcome at one wing has an influence on the setting at the other wing.}
% For these types of models, the modifications to the causal structure, relative to the \textsc{cCC} model, is not sufficient to yield a viable causal account of the data. 

%One can also accommodate superluminal influences in both directions, so long as this does not create any cycles.  For instance, influences 

%Note, however, that not every causal structure meeting this description is sufficient for violating Bell inequalities.  For instance, merely positing a causal influence from one outcome to the other is insufficient~\cite{chaves2015unifying}.
 
%There are also causal models that are parametrically conservative (i.e., parametrically classical) and structurally radical but which nonetheless underfit data that is quantumly realizable.  For such models, the modifications to the causal structure, relative to the \textsc{cCC} model, is not sufficient to yield a viable causal account of the data.  An example is the classical causal model wherein the {\em outcome} at one wing (rather than the setting) has a causal influence on the outcome on the other wing.  Such a causal account is parametrically {\em classical} and structurally {\em superluminal}, hence another example of the class \textsc{cCE}.  For the case of ternary setting variables and binary outcomes, such a causal model was shown in Ref.~\cite{chaves2015unifying} to imply Bell-like inequalities that are quantumly violated.  As such, one expects that the performance of such models on experimental data that violates such inequalities would be comparable to the performance of the \textsc{cCC} model on our experimental data. That is, insofar as such models would underfit the data, the would both train and test poorly. 

%{\em On Valentini}: 
We noted in the main text that structurally radical models have the capacity to describe violations of the no-signalling condition, which ultimately is what causes them to overfit the data relative to the structurally conservative model.  An example helps to illustrate this point. Within the context of a pilot-wave theory, Valentini has proposed~\cite{valentini1991signal1,valentini1991signal2,valentini2002signal,valentini2002signaldeterministic} that obtaining the predictions of operational quantum theory might be contingent on the hidden variables being in a state of subquantum equilibrium, and that 
%deviations from this equilibrium, that is, 
states of subquantum {\em non}equilibrium---allowing for deviations from the predictions of operational quantum theory---might be possible in exotic scenarios.  In particular, 
%because pilot-wave theories explain Bell inequality violations by causal influences between the labs,
 the proposal explicitly allows for 
%subquantum nonequilibrium can imply 
violations of the no-signalling condition in subquantum nonequilibrium.  
%Valentini's proposal, therefore, embraces the capacity of a \textsc{cCE} causal model to violate the no-signalling condition.  
%We shall return to this proposal below.
%may be achieved in certain exotic scenarios.

%Models are meant to capture the precise flexibility of what they can represent, and so the question is whether this gloss has captured this flexibility. In the case of the causal account endorsed by Bohmians, our recasting into the causal modelling framework feels closer to Valentini's version of the account [citations] than the mainstream version [citations].

%{\bf On superdeterministic models}
%\textsc{cSD} models}


We now turn to the \textsc{cSD} class of causal models of the Bell experiment: classical causal models that posit that one or both of the setting variables share a common cause with the outcome variable \rob{at the opposite wing}.  \rob{If one considers the case where the setting $S$ shares a common cause with the outcome $Y$, then the resulting causal model is subsumed within the causal model for which the causal structure includes a three-way common cause of $S$, $X$ and $Y$.  The latter is the one depicted in Fig.~\ref{DAGs}(d) and which we have focussed on in this article.}
%Without loss of generality, one can absorb this common cause into the definition of $\Lambda$, leaving the DAG depicted in Fig.~\ref{DAGs}(d).}
\rob{Note that the superdeterminist view is sometimes described as positing a common cause $\Lambda'$ between a setting variable (say $S$) and the hidden variable $\Lambda$ in the DAG of Fig.~\ref{DAGs}(b), but without loss of generality one can absorb $\Lambda$ into the definition on $\Lambda'$, thereby obtaining the causal structure that posits a common cause of $S$, $X$ and $Y$.  
%In such arguments, it is critical that there is no upper bound on the cardinality of the latent variables.
}
%But this is strictly equivalent to positing a common cause of $S$, $X$ and $Y$.}  %\rob{[provide figure?]} 

 %There are several possibilities for the causal structure here as well. 
\rob{To obtain a distinct representative of the \textsc{cSD} class, it suffices to swap the roles of the pair of parties relative to the DAG of Fig.~\ref{DAGs}(d) and 
%presume that $\Lambda$ influences not only the pair of outcome variables, but the setting $T$.
have $\Lambda$ be a common cause of $T$, $X$ and $Y$.
%both outcomes as well as the setting $T$.
  Alternatively, one could presume that $\Lambda$ influences not only the pair of outcome variables, but {\em both} setting variables as well.  }
%As in the case of the \textsc{cCE} class, there are other causal structures that fall into the alternative possibilities for the causal structure 
%  For instance, one might presume a common cause of $S$, $X$ and $Y$, or of $T$, $X$ and $Y$, or indeed of all four variables.

\color{black}
%[3 variables connected by common cause versus 4 variables.  Mention that we don't need to distinguish latents.]

%As noted in Ref.~\cite{wood2015lesson}, there are several ways of accommodating the notion of superdeterminism within a causal model. (Ref.~\cite{schmid2020unscrambling} has also clarified how this is done.) The options are: relative to the Bell DAG, (i) a common cause of $S$ and $\Lambda$, (ii) a common cause of $T$ and $\Lambda$, or (iii) a common cause of both.  Usually, we just eliminate all of the unobserved stuff, in which case we have, relative to the Bell DAG, (i) a common cause of $S$ and $Y$, (ii) a common cause of $T$ and $X$, (iii) a common cause of $S,T,X$ and $Y$.  

As noted in Ref.~\cite{wood2015lesson}, generic values of the parameters in such models also yield nontrivial correlations between an outcome variable and the setting variable in the opposite lab, hence a violation of the no-signalling condition.  As in the \textsc{cCE} case, it is this possibility that makes such models prone to 
%Consequently, models in the \textsc{cSD} class, like those in the \textsc{cCE} class can which ultimately is what causes them to 
overfitting the data relative to the structurally conservative model.

%The authors of Ref. [Hossenfelder Palmer], in particular, have entertained the possibility that there may be ways of experimentally distinguishing superdeterministic accounts of Bell experiments from other accounts.   We have presented one means of doing so here.

%[Such a model has the potential to describe correlations between $Y$ and $S$.]

%Hossenfelder and Palmer claim that these things are never tested experimentally.  But we have provided this test here.

%Next, we turn to a class of causal accounts of Bell inequality violations  that we did not treat in detail in the main text, namely, retrocausal models~\cite{CostadeBeauregard1977duellistes,price1997time,price1994neglected,sep-qm-retrocausality, wharton2020colloquium}.  These posit causal influences that propagate backwards in time, such as an influence from the setting variable $S$ or $T$ to $\Lambda$. In keeping with the terminological conventions introduced in the article, it is appropriate to refer to such models as  parametrically {\em classical} and  structurally {\em retrocausal}, and denote the class as \textsc{cRC}. 

%{\bf On retrocausal models} 

%Models that posit causal influences that propagate backwards in time, such as an influence from a setting at one lab to the latent variable that is a common cause of the two outcomes, are termed {\em retrocausal}.

%There is also a tradition of using such models as a way out of the Bell no-go result \rob{[citations].  
  %[Price,Wharton, others?]  [review paper by Wharton]}
  
  
  %\rob{[Only retrocausal models that involve DAGs can be modelled here.  Maybe best to pull back on all claims about retrocausation. ELIMINATE]}
% Although we have not applied our model selection technique to any representative of this class of models, one could easily do so.  It would suffice to choose a particular DAG that incorporates retrocausal influences and allow for arbitrary parameter values in the model.  The general considerations of Ref.~\cite{wood2015lesson}, which were outlined in the discussion section, make it clear that any such model that allows for arbitrary parameter values is highly likely to achieve a performance that is comparable to the \textsc{cCE}$_0$ and \text{cSD}$_0$ models, that is, to train better than \textsc{qCC} but to test worse.


The distributions compatible with a given classical causal model depend on the cardinalities of the latent variables.
% $|X|$ of any latent variable $X$.
% (i.e., the number of values it can take),
Suppose a given causal model incorporates a latent variable $\Lambda$. The set of distributions that are compatible with the classical causal model where $\Lambda$ has cardinality $d$  contains the set of distributions where $\Lambda$ has cardinality $d'$ for any $d'<d$.
%Furthermore, the set of compatible distributions for one value of the cardinality of a given variable subsumes the one at every lower value of that cardinality. 
 Even if one is considering the true causal structure, therefore, if one assumes too low a cardinality for the latent variables, one might still underfit the data.  If not underfitting the data were the {\em only} standard of empirical success,  it would be reasonable to presume the cardinalities of the latent variables to be those that are just sufficient to saturate the set of distributions compatible with the causal structure (these are known to be finite for classical causal models where the observed variables are discrete~\cite{rosset2018universal}).   This choice, however, may {\em overfit} the data relative to a model with smaller cardinalities.  
 %By contrast, taking too small a value for these cardinalities might underfit the data. 
  This is why, for a given causal structure, we treat each possibility for latent cardinalities as a separate representative of its class of causal models, a separate model in the slate of candidates. 
  
 
% Consequently, for a given causal structure, we treat each possibility for latent cardinalities as a separate model and optimize over these.  Thus, the test error reported for  \textsc{cCE}$_0$ and \textsc{cSD}$_0$  is the {\em minimal} value of this loss in a variation over the cardinality of $\Lambda$. (We take a similar approach to cardinality in fits to the \textsc{cCC} model, to be discussed below.)

The \textsc{qCC} model posits the conservative causal structure, that is, a common cause acting between the labs, but it requires the parameters to be conditional density operators rather than conditional probability distributions, as noted in the main text.  

For such a model, the common cause is modelled as a bipartite quantum system $AB$ rather than a variable $\Lambda$,  so the analogue of the cardinality of $\Lambda$ is the dimension of the Hilbert space describing $AB$. Nonetheless, the same considerations hold: a dimension that is higher than the optimum may lead to overfitting of the data while a dimension that is lower than the optimum may lead to underfitting of the data, so it is best to treat each possibility for the dimension as a separate representative of the class of quantum causal models. As noted in the main text, however, the model wherein $A$ and $B$ are both qubits, so that $AB$ has dimension 4, already outperformed the other causal models on our slate of candidates, and so we did not need to consider any variation in this dimensionality.

    
%The spirit of the quantum common-cause (\textsc{qCC}) model explored in this article is akin to the one adopted in [BellQuantified] and refined in [Causal-Inferential]k, namely, that quantumness is a modification in 

%{\bf On the \textsc{qCC} model}


%One can imagine restricting the dimension of the quantum system acting as a common cause, but we here take this dimension to be arbitrary.

\subsection{On whether the \textsc{qCC} model provides a satisfactory causal explanation}

The idea that the best causal account of Bell inequality violations is achieved by \textsc{qCC}, that is, a causal model with a quantum common cause, is one that has been espoused in Refs.~\cite{leifer2013towards, wood2015lesson, allen2017quantum,wolfe2020quantifying}.  
As was acknowledged in those articles, however, 
whether 
such a causal model can really be deemed to achieve a {\em realist} account of the experimental data (as structurally radical classical causal models do) is one that has not yet been adequately answered.  Ref.~\cite{schmid2020unscrambling} argues that providing an affirmative answer to the question  
%and recently clarified in Ref.~\cite{schmid2020unscrambling}, is that whether such a causal model can really be deemed to achieve a {\em realist} account of the experimental data depends on 
% the success of 
depends on the success of a research program that seeks to modify the notions of causation and inference to achieve a novel, nonclassical, type of realism that can underlie operational quantum theory.\footnote{In terms of the framework introduced in Ref.~\cite{schmid2020unscrambling}, the present article is about adjudicating between different ``quotiented operational causal-inferential theories'' based on their power to predict the experimental data.  It is not directly about adjudicating between realist representations thereof.  However, the assumption that any realist representation of an operational causal-inferential theory 
%(by a ``realist causal-inferential theory'')
 must be {\em diagram-preserving} means that the latter must posit the same causal structure as the former for any given experiment.  (See Section V.A of Ref.~\cite{schmid2020unscrambling} for a defense of the assumption of diagram preservation.)   Consequently, if one provides experimental evidence against a given causal structure for operational accounts of the experiment, one has provided experimental evidence against that causal structure for realist accounts as well. }
 %, while still satisfying the principles which capture the essence of providing a causal explanation.     
% unscramble the notions of causation and inference.  More specifically, as Ref.~\cite{schmid2020unscrambling} argues, the challenge is to define a nonclassical realist causal-inferential theory that can yield all and only the predictions of operational quantum theory while satisfy certain principles that capture the essence of causal explanation. 
  %provides a representation of operational quantum theory, where the representation is required to satisfy certain principles. 
%A research program that seeks to devise a notion of nonclassical realism is described in Ref.~\cite{schmid2020unscrambling}.
%    It is argued there that achieving such nonclassical realism is a promising research program.  
    
%    the definition of causal and inferential notions may be altered in a realist theory that can do justice to operational quantum theory while preserving various principles. 

\begin{comment}
In the language of that article, everything we've done here is at the level of adjudicating between different options for the quotiented operational causal-inferential theory.  
%Thus our work can be conceptualized as a comparison of different hypotheses about the operational causal-inferential theory.  Essentially, 
Many distinct choice of causal structure plus choice of GPT can {\em reproduce} the experimental data.  \rob{ [Send reader to the section of that paper wherein we make the case for operational theories needing to make a hypothesis about the causal structure, rather than being able to infer it from data.]}
In spite of the many theories that can train well, they are nonetheless distinguishable in terms of their predictive power. 
\end{comment}


%What we said in the main text: ``In this article, we follow Refs.~\cite{wood2015lesson, leifer2013towards} in taking the transition from classical to quantum causal models to be a transition in the nature of the parameters that supplement the causal structure, while the causal structure is taken to be represented in the same way as in a classical causal model, namely, by a DAG which distinguished observed and unobserved systems.''



%In the framework of causal-inferential theories, how one models an experiment operationally depends on one's causal hypothesis about the experiment.  The particular structure of the computation of the correlations within an operational CI theory (understood as a tensor contraction) is required, by the assumption of diagram preservation, to mirror the causal structure that one hypothesizes.  This is quite different from the usual perspective wherein it is presumed that the disagreement between different positions on how to provide a causal account for Bell inequality violations is merely a disagreement at the level of realist models and not at the level of operational models. 


\begin{comment}
{\bf On dilations}

It is worth noting that positing a classical causal model wherein the parameters are conditional probability distributions does not commit one to indeterminism.  Any such model can, in fact, be dilated to a deterministic model. If the classical variable $X$ is given by a conditional probability distribution in terms of its causal parents in the DAG, ${\rm Pa}(X)$, then it is always possible to have $X$ be fixed deterministically by some function $f$ of a larger set of variables, namely, the union of ${\rm Pa}(X)$ with local causal parents of $X$ that were not included in the DAG, denoted $U$, so that $P_{X|{\rm Pa}(X),U}= \delta_{X,f({\rm Pa}(X),U)}$.  The reason is that the freedom in specifying the distribution over $U$, denoted $P_U$, allows one to recover any indeterministic conditional via $P_{X|{\rm Pa}(X)}= \sum_U \delta_{X,f({\rm Pa}(X),U)} P_U$.  This fact can be considered a generalization of Fine's theorem~\cite{fine1982hidden}.

%On dilations of models to deterministic models: 
%It is generally presumed that $X$ is fixed deterministically by some function $f$ of its full set of parents, which is the union of its parents in the DAG, ${\rm Pa}(X)$, together with parents that are not included in the DAG, $U$, so that $P_{X|{\rm Pa}(X),U}= \delta_{X,f({\rm Pa}(X),U)}$.  If an agent's knowledge of $U$ is represented by the distribution $P_U$, then $P_{X|{\rm Pa}(X)}= \sum_U \delta_{X,f({\rm Pa}(X),U)} P_U$.  

Similarly, positing a quantum causal model wherein the parameters are completely positive trace-preserving maps (which need not in general correspond to a unitary map)  does not commit one to indeterminism or to a failure of unitarity.  If the quantum system  $A$ is given by the image of a CPTP map $\mathcal{E}_{A|{\rm Pa}(A)}$ with input corresponding to its causal parents in the DAG, ${\rm Pa}(A)$, then it is always possible to consider the Stinespring dilation~\cite{Stinespring:55} of $\mathcal{E}_{A|{\rm Pa}(A)}$.  We simply imagine that the full set of causal parents of $A$ is not ${\rm Pa}(A)$ but ${\rm Pa}(A)$ supplemented by local causal parents of $A$ that were not included in the DAG, denoted $E$.  If we suppose that $E$ is prepared in a state $\rho_E$, and assume a (deterministic) isometry $V$ from $E \otimes {\rm Pa}(A)$ to $A$, the effective dependence of $A$ on ${\rm Pa}(A)$ is given by the CPTP map $\mathcal{E}_{A|{\rm Pa}(A)}(\cdot) = V (\cdot \otimes \rho_E) V^{\dag}$.  The Stinespring dilation theorem furthermore ensures that {\em any} CPTP map $\mathcal{E}_{A|{\rm Pa}(A)}$  can be realized in this way.


See Ref.~\cite{allen2017quantum} for further discussion of dilations in classical and quantum causal models.
\end{comment}



\section{Further details on the causal discovery algorithm}
 
 %\textit{On information criteria: In order to accommodate data-poor applications, a variety of techniques have been developed to estimate the test error while still using {\em all} of the acquired data for fitting the model parameters.  Common techniques of this sort include the Akaike Information Criteria (AIC), the Bayesian Information Criteria (BIC) and Cross Validation (CV).   The experiment we consider, however, is data-rich, and consequently we can simply fit the model parameters using one data set, termed the {\em training data}, and estimate the test error using a second data set, termed the {\em test data}.  
%These are referred to as the {\em training data} and the {\em test data} respectively.
% (In addition to being mathematically simpler, this approach requires fewer assumptions to be made about the underlying distribution~\cite{hastie2003elements}.) }


%The work of Ried et al.



We here provide further information about the algorithm we propose for adjudicating between causal models.
%This section provides further information on the novel causal discovery algorithm used for this experiment. 
%Unlike 
%previous work on
 A {\em classical} causal discovery algorithm~\cite{pearl2000causality,Spirtes00} adjudicates between different classical causal models based on purely observational data. 
 %causal structures assuming a classical causal model.
The algorithm we describe is also based on purely observational data, but 
   %Here, by contrast, 
   the slate of candidate causal models is allowed to include {\em intrinsically quantum} causal models and allows a direct comparison between these and classical causal models using the same scoring criteria.

In the statistics community, in order to accommodate data-poor applications, a variety of techniques have been developed to estimate the test error while still using {\em all} of the acquired data for fitting the model parameters.  Common techniques of this sort include the Akaike Information Criteria (AIC), the Bayesian Information Criteria (BIC) and Cross Validation (CV).    The experiment we consider, however, is data-rich, and consequently we can simply fit the model parameters using one data set, termed the {\em training set}, and estimate the test error using a second data set, termed the {\em test set}.  

A schematic of the algorithm is provided in Fig.~\ref{algorithm}. The input of the algorithm is the observed relative frequency $F(xy|st)$ of outcomes $X=x$ and $Y=y$ given settings $S=s$ and $T=t$ for the training set and the test set.
%, and a slate of candidate causal structures.
%The input is two data sets of empirical conditional distributions for each pair of measurement settings $F(xy|st)$ and a slate of candidate causal structures.   
The output of the algorithm is the training error and the estimated test error, as well as their standard deviations, for each of the causal models on the slate of candidates.  These allow for the determination of an ordering of the models by their relative predictive power, as well as an estimate of the statistical confidence of this ordering
%the relative predictive power of the different causal structures on the slate
%preferred causal structure
% (Fig.~\ref{algorithm}). 
 %Additional information is also produced, notably the training loss and the estimated test error and the standard deviation for these values. 
% These numbers give insights into the shortcomings of the nonpreferred causal structures and also an idea of the confidence in the verdict achieved by the model selection technique.

\begin{figure*}[t!]
%[htb]
\begin{center}
%\includegraphics[scale=0.18]{summary_2.png}
\includegraphics[scale=0.36]{summary_3.png}
\caption{A schematic of our model selection technique, where the quantities referenced are defined in Eqs.~\eqref{loss}, \eqref{bestfitmodel}, and \eqref{ExpectedTEloss} of the main text. 
%\rob{[@Patrick.  Can you redo this figure?  Replace the `$G_i$'s with $M_i$s, as we are adjudicating between models, not just structures. Maybe each figure on the left should have a `classical' or `quantum' label on it as well. The parameter set being optimized over should be denoted $\mathcal{P}_{M_i}$. Clarify that '$L$' (perhaps rename it whatever we chose to call it in the main text) represents the least-squared error function.  Maybe the predicted probabilities should be denoted $P_O$ (where $O$ represents the observed variables) and the frequencies to which they are being compared $F_O$.  In any case, we need to fix the notation in this figure to match the main paper and SM. I also think that it would be better to just use the 3 models that we compare in the paper as our illustrative example.  The bottom labels should be `Define a slate of causal models', `For each model, find the parameter values that minimize the Training loss', 'Using these parameter values, compute the test error for each model', and `Identify the model with the smallest test error'.]}
}
\label{algorithm}
\end{center}
\vspace{-2em}
\end{figure*}

For each causal model $M$, one minimizes the training error over the conditional probability distributions in the set $\mathcal{P}_M$ that are compatible with the model. 
%The first step of the algorithm is to minimize the training loss over the set of conditional probability distributions which are compatible with each causal structure, $\mathcal{P}_{\textsc{M}}$.
 %In our experiment 
 As noted in the main text, we take the least squared error as our loss function.  We note, however, that the data analysis was repeated for three other loss functions and the conclusions were essentially unchanged. 
 %it resulted in no meaningful changes in the conclusions.
 
%  In general, the algorithm could consider any causal explanation which predicts a set of conditional distributions which if observed would be compatible with the theory. This includes any causal explanation for a Bell experiment that couldn't be described within the DAG framework we use in the paper. The authors are not aware of any such causal explanations. 


The set of distributions that are compatible with a generic causal model $M$, that is, $\mathcal{P}_{M}$, is generally a nonconvex set~\cite{wolfe2019inflation}.  In particular, this is the case for the causal models of interest to us here whenever the cardinality of $\Lambda$ or the dimension of the $AB$ system are not maximal. Consequently, our technique requires a nonconvex optimization, which is generally difficult as there can be multiple local minima.
 %training loss function minimization will in general be over a non-convex set, since this is the nature of compatible distribution with DAGs. 
Indeed, the optimization comprises almost the entire computational burden of the algorithm. 
%This makes the minimization problem difficult to solve and have multiple local minima's. 
%To do so, we use NMinimize in Mathematica with the Nelder-Mead option. 
To do so, we use the Nelder-Mead method, implemented via NMinimize in Mathematica.
%We repeated the experiment and found the same results when using the simulated annealing option or a separate python BFGS algorithm.
We repeated each optimization 100 times which different random seeds in order to increase the chances of finding the global minimum. 
Given that our loss function is an {\em estimate} of the test error, identifying a local minimum rather than the global minimum provides a
%can be conceptualized as a comparatively
 worse estimate of the true test error. However, there is no reason to think that the model is more likely to get stuck in any one local minimum rather than another. 
%\rob{[It's a biased estimate, but that isn't a problem as long as its not unequal biasing.  In other words, there's no reason to thinking that any one model is more likely to get stuck in a local minimum than any other.]}

%Finding a global minimum is not a necessity since our loss function is an estimate of the test error. A local minima would just make the resulting number a poorer estimate. %We repeated many of the minimization with 80 different seeds in order to check if the minimum would be improved. In some cases it did but only by small amounts. 

The next step is to calculate, for each model on the slate of candidates,  the estimated test error for the distribution that was found to minimize the training error. 
%on the test set for each fitted distribution.
 This is a relatively 
 %comparatively
  inexpensive computation.  The model that is favoured by the model selection technique is the one which is estimated to have the most predictive power, that is, the one that achieves the smallest estimated test error.
% The resulting estimated test errores are the scores for each model. The model corresponding to the smallest score is selected. 
 
 Error bars for the training and test error are calculated by doing parametric bootstrap re-sampling 
 %\rob{[@Patrick: Do you know the answer to Kevin's question: is this what people call Monte Carlo error estimation?]}
  of the initial frequency counts in the data sets (a type of Monte Carlo error estimation). The entire algorithm is repeated to find the test and training errors for the re-sampled counts. We performed 10 re-samplings and used the empirical standard deviation of this sample as our error bars.

\begin{comment}
\rob{[Actually, the below suggests that we *have* allowed for parameter-restricted models!}

One final note should be made.  We have here presumed that for any latent node, the cardinality of the set of its possible values can be arbitrarily large.  For classical causal models, there is a maximum cardinality that can yield any compatible distribution over the observed variables\rob{[cite Rosset, Wolfe,Gisin]}.
%unknown.
%One of the nodes in our causal diagrams is latent, this means that its cardinality is unknown. 


This cardinality effects the set of compatible distributions. Say we could have taken the maximum latent cardinality for each structure to find the maximal set of compatible distribution. This would unfairly punish situations where the underlying causal structure has a smaller cardinality and thereby have a substantially smaller set of compatible distributions. This would result in an over-fitting model despite the causal structure being correct. For this reason we consider each individual cardinality and use the best scoring option as the score for that causal explanation. 
\end{comment}

As was noted in Section~\ref{DetailsOnSlate}, in order to find the most predictive model with a given causal structure,  one must allow for variability in the cardinality of the latent variables therein.  A brute-force optimization over the choice of these cardinalities, however, is computationally inefficient.  To reduce computation time, therefore, we introduce a heuristic for this optimization, which we now describe for the case of the Bell experiment.  For a given structurally radical hypothesis, such as \textsc{cCE}$_0$ or \textsc{cSD}$_0$, we order the causal models associated to it by the cardinality of $\Lambda$.  We then search through increasing values of cardinality for the most predictive model, and we end the search if either of the following two conditions are met: (i) for three consecutive values of the cardinality,  the training error decreases while the estimated test error increases, or (ii) for three consecutive values of the cardinality,  the training error and estimated test error take the same value.  The first condition is reasonable since it is likely to describe a situation wherein the increasing expressive power of the models is yielding increasing degrees of overfitting, so that continuing to increase the expressive power by increasing the cardinality would only further decrease the predictive power.  The second condition is reasonable since it is likely to describe a situation wherein the increasing expressive power of the models is not yielding increasing degrees of overfitting, but also not improving the fit, so that increasing the cardinality will not lead to any further increases in predictive power.\footnote{This can occur, for instance, if the cardinality has increased beyond the value that saturates the set of compatible distributions, supposing one does not know a priori what this value is. }
% allows it ould be by virtue of the fact }  \rob{[Question for Patrick: we used to say that the score might be unchanging because we've achieved the saturating cardinality.  But don't we know a priori when that happens?]}


%continues to get lower but the testing loss is getting higher for 3 in a row.


%To substantially reduce computation time, as opposed to scoring each cardinality in increasing order, we adopt a couple of principles to determine when we have passed the optimal cardinality since at this point we need not continue searching. The first condition for ending the search is: if the training loss continues to get lower but the testing loss is getting higher for 3 in a row. This situation occurs when we have already begun over-fittting the data so continuing would only make the situation worse. The second condition is: if the training and testing loss have remained the same value for three consecutive cardinalities. This suggests we have already surpassed the maximal cardinality or that the optimal solution is contained in the smaller set. 

%The final method is an extension of the first: if the test error has been above the test error (for any other model potentially within another class) for three in a row and the training loss has been below that same models training loss then stop. This condition is motivate in the same way the first was. It indicates that we have already begun over-fitting the data.

\subsection{Comparison to prior work}\label{priorwork}

As noted above, the fact that our model selection technique is applicable to purely observational data makes it a generalization of
%The framework for model selection developed here adjudicates between a set of candidate causal models based on {\em purely observational data}.  It is therefore in keeping with 
the standard notion of a {\em causal discovery algorithm} in the causal inference literature~\cite{pearl2000causality,Spirtes00}.
%, which is also based on purely observational data.  
 Ref.~\cite{ried2015quantum} also considered a quantum generalization of the notion of causal discovery, 
%i.e., using purely observational data, 
but only for the special case of distinguishing a cause-effect relation from a common-cause relation and only device-dependently.  
%The approach described here is a significant generalization.
Several other works~\cite{CostaShrapnel,giarmatzi2019quantum,bai2020efficient} have focussed on the problem of determining the causal structure based on {\em interventionist} data.\footnote{These works have also described their algorithms as instances of `causal discovery', although the usage of this term is somewhat at odds with the convention in the causal inference community of reserving this term for analyses based on observational data.}   That is, rather than making inferences about causal structure based on a probability distribution over the observed classical variables, as we do here, they do so based on a tomographic characterization of each process in a circuit that describes the causal relations.

%although it should be noted that they are unlike classical causal discovery algorithms 
 
\begin{comment}
\textbf{add comparison to Costa, as well as Bai, Chiribella.}

Ref.~\cite{ried2015quantum} considered causal discovery based on observational data, while other quantum generalizations of the notion of causal discovery focus on interventionist data~\cite{CostaShrapnel,giarmatzi2019quantum,bai2020efficient}.  

Articles exploring quantum analogues of causal discovery~\cite{giarmatzi2019quantum,CostaShrapnel,bai2020efficient}  have thus far presumed a tomographic characterization of each gate in a circuit, rather than merely a distribution over the classical variables in the circuit. \color{red} [is that accurate?]. \color{black}   They follow up in Bai and elsewhere by looking for independence relations.  This should be best-fit.
%Finally, our framework is distinguished insofar as it allows a direct comparison between quantum and classical causal models using the same scoring criteria.

Note that previous work on quantum causal discovery~\cite{giarmatzi2019quantum,CostaShrapnel,ried2015quantum} was of a different type insofar as it did not make use of purely observational data.

What about Ried et al.?  I would say that it was based on observational data insofar as one gets just the outcomes of the probe, while remaining uncertain about how, precisely, it interacted with the system (was it a measurement or a preparation?).

Patrick's take:

I have been reading over the work on their version of causal discovery ({https://arxiv.org/pdf/1512.07106.pdf, https://arxiv.org/pdf/1704.00800.pdf}) and this is my basic explanation of the classical analogue of their work.

You are given interventional data for a set of nodes. From this you can figure out the causal order, and also all the functional dependences, i.e. the SEM (equivalent to SCM). For each variable (Y) you draw an edge from each variable $(X_i)$ which appears in the SEM $Y=f(X_1,X_2,?.)$ if there is a non-trivial dependency on that variable. This will give you the correct DAG if the data was Markovian. Their algorithm checks if the data is Markovian before beginning. 

This would be considered nothing in the classical causal community since it?s basically switching between equivalent representations causal models. You have complete information of all the interventional distributions so that?s complete knowledge of the causal model (this is one representation of a causal model actually) and you are simply writing it down in another representation (SCM). In contrast, the PC, SGS, IC algorithms all work with observational data and are thereby compatible with multiple DAGs in a non-trivial sense. 

Additional side comment: The exact classical limit of their work would be more complicated since you have explicit input and output systems and information cannot be distributed willy nilly between labs.  They go into it and relate it to SWIGs which I might look over since I'm not familiar with the classical causal models with this input/output systems. But this doesn?t change the story above.
\end{comment}

\section{Further details on the experiment}

\subsection{Selection of the set of measurements}
%Measurement Selection}

%The Bell experiment we implement considers six different binary-outcome measurements in each lab.
%In our experimental implementation, Alice and Bob each have six different binary-outcome measurements they can perform.
In this section, we describe the motivation behind the choice and number of measurements we implemented in our Bell experiment. We sought to perform the minimal number of measurements which could distinguish the various causal models with high statistical confidence.
%sufficient statistical power. 
Minimizing the number of measurements is desirable because it limits the time required to complete the experiment and therefore also limits the error introduced by temporal drift of the experimental components.
%This was done in order to limit the temporal drift of any experimental components.
 We did not attempt, however, to find provably optimal sets. 
 Instead, we considered sets of binary-outcome projective measurements chosen in such a way as to be spread out over the Bloch sphere.  For different values of $n$, we chose $n$ rank-1 projectors that were equally spaced along a 1-parameter family that traces a spiralling curve on the Bloch sphere (see Fig.~\ref{bloch_sphere}). 
%lying on a spiralling curve on the Bloch sphere, and considered sets of $n$ measurements that were distributed roughly uniformly along this curve (see Fig.~\ref{bloch_sphere}).  
We then determined, by simulating data for an idealized version of our experiment,
%through simulated data,
 the minimal value of $n$ for which our causal discovery algorithm could distinguish the slate of causal models under investigation.  In this way, we settled on implementing {\em six} binary-outcome measurements at each side of our Bell experiment. 
% our Bell experiment. 

%Instead, we used an algorithm to select sets of measurements, which heuristically should be highly informative, and subsequently determine through simulated data the minimal number of measurements in this set for which the causal discovery algorithm could distinguish the slate of causal models under investigation.


\begin{figure}[h]
\begin{center}
\includegraphics[scale=0.45]{Bloch_jan21.png}
\caption{A qubit Bloch sphere. Each of the six red points correspond to the zero outcome for one of the six binary projective measurements each lab attempted to implement. These measurements were chosen so that they are distributed roughly uniformly around the surface of the sphere.}
\label{bloch_sphere}
\end{center}
\vspace{-2em}
\end{figure}

Our simulations indicated, in particular, that if instead of the six measurements along the Bloch sphere spiral, one were to implement the standard pair of measurements appearing in the Clauser-Horne-Shimony-Holt (CHSH) version of the Bell experiment, then the \textsc{cCE}$_0$, \textsc{cSD}$_0$ and \textsc{qCC} models had scores within one standard deviation of each other (for a quantity of data that was matched to what we could hope to achieve experimentally), such that our model selection technique could not reliably adjudicate between them.  
%Our simulations led to similar conclusions for three , four or five measurements.
  By contrast, for the six binary-outcome measurements described in Fig.~\ref{bloch_sphere}, the test error of the most predictive model (\textsc{qCC}) was separated from that of the other models (\textsc{cCE}$_0$ and \textsc{cSD}$_0$) by approximately 10 standard deviations \rob{in our simulations, thereby suggesting that this choice would be adequate for our purposes (which the experiment and our data analysis subsequently confirmed).}



%A typical (CHSH) Bell experiment uses two possible measurement settings at each lab.  In optical set-ups, the projective measurements are implemented using \rob{one half-wave-plate} in each lab. When they are implementing binary-outcome projective measurements, the wave-plate in Alice's lab can be $0$ or $22.5$ degrees from vertical while Bob's measurement choices are $11.25$ and $33.75$ degrees. An experiment with these measurements was simulated for a maximally entangled state. The exact probabilities of each measurement were calculated using quantum theory, then the recorded counts are sampled from a Poissonian distribution with this mean. Dark counts were also added. Two such data sets, for training and testing, and the conditional frequencies were inputed into the same causal analysis used for the main experiment. Despite being able to rule out the \textsc{cCC} model, unsurprisingly as this is the original goal of these experiments, the \textsc{cCE}$_0$, \textsc{cSD}$_0$ and \textsc{qCC} models had scores within one standard deviation of each other therefore could not be reliably distinguished. \rob{[The message here seems to be: if one were to implement two measurements rather than six at each wing, as in tests of CHSH, one would not be able to adjudicate effectively between the \textsc{cCE}$_0$, \textsc{cSD}$_0$ and \textsc{qCC} models. I think this needs to be stated more clearly as the point of this paragraph.]}

%To select the measurement settings when performing greater than two measurements, we sampled the two-qubit effects \rob{[Why ``two-qubit'' here?]} uniformly from the surface of a Bloch sphere (Fig.~\ref{bloch_sphere}). 

%Recalling that the two qubits in our experiment are the polarization degrees of freedom of a pair of photons, 
%In our experiment, we controlled which binary-outcome projective measurements is implemented by controlling the half-wave-plate angles in the polarization measurement.  


%The wave-plate angles that are needed to implement these measurements are calculated. This method intuitively should provide a balanced and thereby informative sample. \rob{[redundant?]} We simulated the experiment again with Alice and Bob having three measurement options each and subsequently ran the data through our causal analysis. The scoring difference between the three alternative causal models remained approximately one standard deviation. We continued adding measurements until a significant gap opened between the scores which occurred at six measurements. The \textsc{cCE}$_0$ and \textsc{cSD}$_0$ models had a score of approximately 10 standard deviations larger than \textsc{qCC}.

It is at present not clear how to anticipate by theoretical considerations rather than numerical simulations
%theoretically anticipate
  the minimum number of measurements required by our model selection technique to achieve a given level of statistical confidence.

%It is unclear why three measurements is insufficient whereas six is sufficient. It may be related to tomographic completeness. It could also be related to constraints between the measurement outcomes "geometry" in the different models. \rob{[What is meant here?]}This is an interesting question for future work.

%\subsection{Measurement Outcome Permutations}
% Include this section condensed into a few lines at most into the above section or into the main paper.
%In our experimental set-up the efficiency of our detectors depends on the actual detectors in addition to the coupling efficiency which is dependent on their alignment. Performing a two-outcome projective measurement where the outcomes has different efficiency will cause the effective measurement to no longer be able to be represented as a two outcome measurement. This can cause problems during the data analysis. One solution is to physically adjust the alignment in order to achieve approximately equal coupling efficiency. Alternatively, one can simply perform two measurements, the second being the measurement where the quantum mechanical prediction of the measurement sends the $\ket{0}$ outcome of the first measurement to the other detector. The counts of the two measurements are immediately combined in the lab and only this combined measurements counts or relative frequencies are reported. Despite the measurement selection being guided by quantum mechanical intuition, the measurement and analysis can still be done entirely without quantum mechanics. For example, when Alice sets the measurement device to perform the measurement $s=2$, the device automatically performs the two measurements and outcomes the combined results. This measurement is still describable using standard. 

%In our experiment we perform this measurement outcome permutation trick in order to have a simpler set of \textsc{qCC} causal models to minimize over, namely pairs of two-outcome effects. Without this techniques a \textsc{qCC} causal model would still fit however a more general description would be required.



\subsection{Performance of the model that is parametrically classical and structurally common-cause}\label{cCCmodel}

We noted in the main text that the \textsc{cCC} model, by virtue of being incapable of violating the Bell inequalities, cannot possibly do justice to our experimental data.  For this reason, it was not included it in the slate of candidate causal models among which we implemented model selection.  Nonetheless, confirming the expectation that the \textsc{cCC} model is not viable as a causal account of our Bell experiment provides an additional check on our model selection technique, and so we do so here.  Note that our technique does not establish the nonviability of this model in the standard way, that is, by demontrating that 
%does not, however, proceed in the usual manner of determining the number of standard deviations by which 
our experimental data violates a Bell inequality by many standard deviations.  Rather, it considers the training error and the test error of the \textsc{cCC} model for our data.  
%can be considered as an additional check of our model selection technique, 
%we also considered the predictive power of the \textsc{cCC} model in our experiment. 
 %We find that the \textsc{cCC} model
 The model is found to have a training error of $790 \pm 10$,  far in excess of the training error of \textsc{cCE}$_0$, \textsc{cSD}$_0$ or \textsc{qCC} \rob{(reported in Fig.~\ref{EntangledLoss} of the main text)}, indicating that it underfits the data relative to them, as one would expect
 %expects
  given its inability to violate Bell inequalities.  It consequently also has poor predictive power, achieving a test error of $800 \pm 10$, also far in excess of \textsc{cCE}$_0$, \textsc{cSD}$_0$ or \textsc{qCC}.  
 %This can be considered as providing an additional check on our model selection technique.
 %can be considered as an additional check  our model selection technique, 


\subsection{The dephased version of the experiment}\label{dephased}

%A second experiment was also performed in order to provide an additional check of our model selection technique.
We now describe the results of applying our model selection technique to the version of our experiment wherein the initial entangled state is completely dephased, so that it becomes a separable state. 

  Our primary motivation for doing so is to provide additional evidence for our interpretation of the results of the entangled version of the experiment.  As noted in the main text, the fact that \textsc{cCE}$_0$, \textsc{cSD}$_0$ train better but test worse than \textsc{qCC} suggests that they {\em overfit} the data relative to \textsc{qCC}. Specifically, the statistical fluctuations away from the no-signalling condition (which are possible in any finite-run data) can be mistaken as real features by \textsc{cCE}$_0$ and \textsc{cSD}$_0$, but not by \textsc{qCC}, since \textsc{qCC} satisfies the no-signalling condition for all parameter values.  But if this is indeed the case, then one expects analogous results in a dephased version of the experiment (which removes entanglement, leaving only classical correlations), where now the \textsc{cCC} model can do justice to the observations while also satisfying the no-signalling condition for all parameter values.  Because the dephased version of the experiment is also likely to exhibit statistical fluctuations away from the no-signalling condition, one expects that \textsc{cCE}$_0$ and \textsc{cSD}$_0$ can once again mistake these fluctuations for real features, while neither \textsc{qCC} nor \textsc{cCC} can do so, thereby leading \textsc{cCE}$_0$ and \textsc{cSD}$_0$ to overfit the data relative to \textsc{qCC} and \textsc{cCC}.

%{\em both} \textsc{qCC} and \textsc{cCC} will have more predictive power than \textsc{cCE}$_0$ or \textsc{cSD}$_0$, because the latter will again mistake the fluctuations for real features, and thereby overfit the data relative to \textsc{qCC} and \textsc{cCC}.  

%train better and test worse than 
%  this relative overfitting is likely to  (as noted in the main text).  

The dephased version of our experiment also provides another opportunity to check our model selection technique: given that it prepares a separable state and therefore cannot violate any Bell inequalities, one expects that the \textsc{cCC} model should have as much predictive power as the \textsc{qCC} model for this experiment.  
%the dephased version of our experiment, which does not violate any Bell inequalities, also provides another check on our model selection technique.
  
The entanglement between the two photons  is removed by implementing a completely dephasing channel in the basis of eigenstates of the Pauli $X$ operator (i.e., a noisy bit-flip channel) on one of the photons, via rapid switching between a Pauli $X$ gate and an identity gate. This is achieved using a liquid crystal retarder (LCR) that is switched 
 %driven by a 2kHz square wave, corresponding to switching 
 every 500$ms$. 
 %with a periodically alternating voltage  every 500ms, where.
%This channel is achieved using a liquid crystal retarder (LCR) driven by a 2kHz square wave with a periodically switching voltage, thereby achieving switching between a Pauli $X$ gate and an identity gate every 500ms.
 The bipartite state after the dephasing channel is found to have $98.3\pm0.07\%$ fidelity with the equal mixture of $\frac{1}{\sqrt{2}}(\ket{HH}+\ket{VV})$ and $\frac{1}{\sqrt{2}}(\ket{HV}+\ket{VH})$, which is a separable state, namely, $ \frac{1}{2} |DD\rangle \langle DD| + \frac{1}{2} |AA\rangle \langle AA|$.
 %Besides this difference in the bipartite state, 
The rest of the experiment proceeds as before, as does the data analysis.
 %Otherwise, the same measurements and analysis procedure is performed. 
 
% Since the lack of entanglement implies that the data should {\em satisfy} all Bell inequalities, we expect the \textsc{cCC} causal model to both train and test well, and this is indeed what we find. 
 
 The results of the experiment are presented in Fig.~\ref{DephasedLoss}.  
We confirm that the \textsc{cCC} model has a training error and test error that are comparable (i.e., within error) to those of the \textsc{qCC} model.
%and \textsc{qCC}  models now have comparable performances (within error).
 %The \textsc{cCC}, \textsc{qCC}, and \textsc{cSD}$_0$ causal models now all have comparable performances (within error). 
 %Interestingly,
%Fig.~\ref{DephasedLoss} also reveals that 
We also see that the \textsc{cCE}$_0$ model trains noticeably better and tests noticeably worse than either \textsc{cCC} or \textsc{qCC},
%these,
  while the  \textsc{cSD}$_0$ model  trains marginally better and tests marginally worse than these, thereby confirming our expectations about their relative performance. 
  %  As noted in the main text, this suggests to us  that the additional parametric freedom inherent in these models still leads them to fit to statistical noise even in the de-phased version of the experiment. 
  
%  overfit the data, relative to . }
 % Interestingly, the \textsc{cCE}$_0$ and \textsc{cSD}$_0$ causal models still overfit the data. 
 % Although it is interesting to note that the \textsc{cSD}$_0$ model only minimally overfits and is within the error tolerance.

\begin{figure}[htb]
\begin{center}
\includegraphics[scale=0.24]{fig6_dephased.png}
\caption{The results of the experiment with the de-phased source.
Plotted are the training error (blue) and test error (red) for the \textsc{cCC}, \textsc{cCE}$_0$, \textsc{cSD}$_0$ and \textsc{qCC} models. 
 %The red bar is test error for that model and the blue is the training error. 
 The error bars denote a confidence region of one standard deviation. 
  %\rob{In this case, the \textsc{cCC} and \textsc{qCC} models achieve the lowest test errores (within statistical uncertainty of one another), while the test error of \textsc{cSD}$_0$ is marginally higher and that of \textsc{cCE}$_0$ is significantly higher.   } 
 %\textsc{qCC}, \textsc{cCC} and \textsc{cSD}$_0$ models all have, within the statistical uncertainty, the same test error.
 }
\label{DephasedLoss}
\end{center}
\vspace{-2em}
\end{figure}



\section{Further details on the conclusions that can be drawn from our results}\label{detailsconclusions}

\subsection{Some distinctions among causal models}

We wish to  consider in more detail what our results imply for various loopholes in Bell experiments.  To prepare the ground for this discussion, it is useful 
%In preparation for our discussion in the next section about what our results imply for various loopholes in Bell experiments,
 %it is critical
  to introduce some distinctions among causal models based on the scope of parameter values that they allow. We do so in a manner
%define some distinctions among models in a manner 
that is not specific to the Bell experiment, so that such distinctions can be articulated for experiments with arbitrary compositional structures. 

% The formula for the quantum predictions in any given experiment in the usual operational formalism \rob{[citation]} can be taken to define a causal structure, which we will here term the {\em conservative causal structure} for that experiment.  
% 
% A quantum causal model of the experiment is defined in such a way that it can provide a causal account of the quantum predictions using the conservative causal structure, but where the price for the structural conservatism  is that the model must be  parametrically radical.  A classical causal model  of the experiment, by contrast, salvages parameteric conservatism and the quantum predictions by being structurally radical.
 
  % can also provide a causal account of the quantum predictions, and one that is parametrically conservative.  
%  However, if the experiment involves violations of Bell-like inequalities, then such a causal model needs to be structurally radical. 

%We denote the parametrically quantum but structurally conservative model of an experiment as \textsc{qCONS}, while a given class of parameterically classical but structurally radical models of the experiment will be denoted by  \textsc{qRAD}

%\rob{[Or should we do it this way? ] 
Let the DAG corresponding to the conservative causal structure for an experiment be denoted by $G$, while structurally radical alternatives to it are denoted $G_0, G_1, \dots$.  Let the model of the experiment that is structurally conservative but parametrically quantum (i.e., parametrically radical)
  %structurally conservative model of an experiment
   be denoted \textsc{q}$G$, and let the class of models that are 
   %structurally conservative but parametrically classical (i.e., parametrically conservative) 
 parametrically classical  (i.e., parametrically conservative) but structurally radical---in the sense of assuming a DAG $G_i$ that is not the conservative one---be denoted by  \textsc{c}$G_i$.
 
As noted in the main text, causal models can also be distinguished by what they assume about the cardinality of the latent variables in the DAG.    However, we shall not introduce additional notation for this distinction.  Rather we will presume that when a given class of causal models is considered as a candidate account of some data, it is the particular element of the class that {\em optimizes} the cardinality of the latent variables that is considered.
 
%\rob{[I guess we need to incorporate the cardinality of the latent variables as part of the parameter restriction and therefore describe our models as the {\em cardinality-optimized parameter-unrestricted} models.  I will need to implement this change.]}

Within a given class \textsc{c}$G_i$, one can distinguish different models based on the fact that one can imagine restrictions on the parameter values allowed in the model.  There can be different types of restrictions on the parameters, each of which leads to a different model within the class. 
% (We will not introduce any notation for this distinction however.)
%Different parameter-restricted models in the class  \textsc{c}$G^{(i)}$ will be denoted  \textsc{c}$G^{(i)}_0$, \textsc{c}$G^{(i)}_1$, $\dots$.

First, consider what it means to assume no such restriction.  For each variable $X$ corresponding to a node of $G_i$, the usual notion of a classical causal model allows {\em any} conditional probability distribution $P_{X|{\rm Pa}(X)}$ in the set $\mathcal{P}_{X|{\rm Pa}(X)}$ of all such conditionals.  As noted in the main text, we refer to such a classical causal model as the {\em parameter-unrestricted}  model for $G_i$. In the context of the Bell experiment,  \textsc{cCE}$_0$ is the parameter-unrestricted model for the DAG of Fig.~\ref{DAGs}(c), while \textsc{cSD}$_0$ is the parameter-unrestricted model for the DAG of Fig.~\ref{DAGs}(d).

But one can also define {\em parameter-restricted} classical causal models.  For one of more variables $X$ corresponding to the nodes of $G_i$, the possibilities for  $P_{X|{\rm Pa}(X)}$ are presumed to be restricted to   a set $\mathcal{P}^{\rm sub}_{X|{\rm Pa}(X)} \subset \mathcal{P}_{X|{\rm Pa}(X)}$, that is, to a strict subset of the usual possibilities.   We refer to such classical causal models as {\em parameter-restricted}  models for $G_i$, and denote them by \textsc{c}$_j G_i$, where $j$ is an index that ranges over the choice of parameter restriction.  More precisely, the $j$th parameter restriction is specified by specifying the set of allowed parameter values: $\mathcal{S}_j \equiv \{  \mathcal{P}^{\rm sub}_{X|{\rm Pa}(X)}\}_{X\in{\rm Nodes}(G_i)}$.

For a classical causal model based on a DAG $G_i$ and a parameter restriction described by $\mathcal{S}_j$, that is, for the model denoted by $\textsc{c}_jG_i$,
 %\equiv \{  \mathcal{P}^{\rm sub}_{X|{\rm Pa}(X)}\}_{X\in{\rm Nodes}(G_i)}$,
  the set $\mathcal{P}^{\textsc{c}_j G_i}$ of distributions on the set $O$ of observed variables in $G_i$ are those of the form
\beq
P_{O} = \sum_{{\rm Nodes}(G)/O} \left[ \prod_{X\in{\rm Nodes}(G)} P_{X|{\rm Pa}(X)} \right] 
\eeq
where $P_{X|{\rm Pa}(X)} \in \mathcal{P}^{\rm sub}_{X|{\rm Pa}(X)}$.   
In the case of the classical causal model for the DAG $G_i$  that is {\em parameter-unrestricted},  \textsc{c}$G_i$, the set of compatible distributions is denoted $ \mathcal{P}^{\textsc{c}G_i}$.

Clearly, the distributions that are compatible with a parameter-restricted classical causal model %with DAG $G_i$, that is, with
 \textsc{c}$_j G_i$, are included within those that are compatible with its parameter-unrestricted counterpart 
 %, the model
  $\textsc{c}G_i$,
$$\mathcal{P}^{\textsc{c}_j G_i} \subseteq \mathcal{P}^{\textsc{c}G_i}.$$
%Clearly, the compatible distributions for a parameter-restricted classical causal model for the DAG $G_i$, that is, a model \textsc{c}$_j G_i$, are included within those of its parameter-unrestricted counterpart, the model $\textsc{c}G_i$,
%$$\mathcal{P}^{\textsc{c}_j G_i} \subseteq \mathcal{P}^{\textsc{c}G_i}.$$
The interesting restrictions on the parameters, of course, are those for which we get a {\em strict} inclusion, $\mathcal{P}^{\textsc{c}_j G_i} \subset \mathcal{P}^{\textsc{c}G_i}$.


%To summarize,
%\begin{itemize}
%\item[$M$ is a parameter-unrestricted classical causal model for $G_i$:] $\mathcal{P}^{M} = \mathcal{P}^{\textsc{c}G_i}$
%\item[$M$ is a parameter-restricted classical causal model for $G_i$:] $\mathcal{P}^{M} \subseteq \mathcal{P}^{\textsc{c}G_i}$
%\end{itemize}
%The interesting restrictions on the parameters, of course, are those for which we get a strict inclusion, $\mathcal{P}^{M} \subset \mathcal{P}^{\textsc{c}G_i}_{\rm full} $.

Let $\mathcal{P}^{\textsc{q}G}$ denote the set of distributions on the observed variables that are compatible with a parametrically quantum (hence parametrically radical) and structurally conservative model, assuming no restriction on the parameters.  

Since, in this article, we are only interested in classical causal models that can fit data consistent with operational quantum theory, we limit the scope of possible parameter restrictions to those that can achieve such a fit. More precisely, we consider only those parameter-restricted classical causal models, $\textsc{c}_j G_i$, for which there is sufficient parametric freedom that the compatible distributions subsume those predicted by operational quantum theory, i.e.,  those for which
 $\mathcal{P}^{\textsc{c}_j G_i} \supseteq \mathcal{P}^{\textsc{q}G}$.\footnote{In other words, we are not interested here in models $\textsc{c}_j G_i$ wherein $ \mathcal{P}^{\textsc{c}_j G_i} \subset \mathcal{P}^{\textsc{q}G}$  or wherein neither set subsumes the other because in both such cases one could rule out $\textsc{c}_j G_i$ relative to $\textsc{q}G$ in the standard way, by noting that it underfits the data relative to $\textsc{q}G$.}


%We \rob{restrict our attention }consider those parameter-restricted classical causal models, $\textsc{c}_j G_i$, that have sufficient parametric freedom that the distributions over the observed variables that are compatible with it subsume those predicted by operational quantum theory, that is, those for which $\mathcal{P}^{\textsc{c}_j G_i} \supseteq \mathcal{P}^{\textsc{q}G}$. 
  For these, it is useful to introduce a further distinction, based on whether or not the parametric freedom is such that the compatible distributions {\em go beyond} those of operational quantum theory: 
%Among the parameter-restricted models, we can articulate a further distinction:
\begin{itemize}
\item[$\textsc{c}_j G_i$ is quantum-on-the-nose:] $ \mathcal{P}^{\textsc{c}_j G_i}= \mathcal{P}^{\textsc{q}G}$ 
\item[$\textsc{c}_j G_i$ is  quantum-extending:] $\mathcal{P}^{\textsc{c}_j G_i} \supset \mathcal{P}^{\textsc{q}G}$
\end{itemize}
In the quantum-on-the-nose case, the restriction on the set of parameters values is such that the set of compatible distributions on the observed variables for DAG $G_i$ coincides {\em precisely} with the set of distributions compatible with a quantum causal model for DAG $G$.
 %(the conservative causal structure).
   In the quantum-extending case, the set of compatible distributions is a strict superset of the latter.
%\footnote{We are not interested here in models $\textsc{c}_j G_i$ wherein $ \mathcal{P}^{\textsc{c}_j G_i} \subset \mathcal{P}^{\textsc{q}G}$  or wherein neither set subsumes the other because in both such cases one could rule out $\textsc{c}_j G_i$ relative to $\textsc{q}G$ in the standard way, by noting that it underfits the data relative to $\textsc{q}G$.}
%y are such that the former is a superset of the latter.


%\rob{[WAIT!  It is actually critical for the parameter restriction to have some consequence for the observed distributions.  For instance, if 2 variables $X$ and $Y$ are cause-effect and common-cause connected, then there are restrictions on the way $Y$ depends on its parents that nonetheless do not restrict the joint distributions on $X$ and $Y$.  ]}

%\rob{[Mention that there is no restriction on parameters in quantum models?]}

\begin{comment}
For the purposes of the discussion, it is useful to introduce the notion of a {\em parameter-restricted} classical causal model. 
 %It differs from the usual notion of a classical causal model insofar as it stipulates a restriction on the allowed parameter values. 
Let \textsc{cRAD} stand for a class of models that are parametrically conservative, but structurally radical in some way.  Let $G$ denote the DAG associated to the radical causal structure.   For each variable $X$ corresponding to a node of $G$, the usual notion of a classical causal model allows {\em any} conditional probability distribution $P_{X|{\rm Pa}(X)}$ in the set $\mathcal{P}_{X|{\rm Pa}(X)}$ of all such conditionals.  For the parameter-restricted notion of a causal model, on the other hand, it is the case that for one of more nodes $X$, the possibilities for  $P_{X|{\rm Pa}(X)}$ are presumed to be restricted to 
  a set $\mathcal{P}^{\rm sub}_{X|{\rm Pa}(X)} \subset \mathcal{P}_{X|{\rm Pa}(X)}$, that is, to a strict subset of the usual possibilities. 
   The distributions on the variables in the set $O$ of observable variables in $G$ which are compatible with such a model are those of the form
\beq
P_{O} = \sum_{{\rm Nodes}(G)/O} \left[ \Pi_{X\in{\rm Nodes}(G)} P_{X|{\rm Pa}(X)} \right] 
\eeq
where $P_{X|{\rm Pa}(X)} \in \mathcal{P}^{\rm sub}_{X|{\rm Pa}(X)}$.   

%The set of compatible distributions $P_O$ for a parameter-restricted model $M$ will again be denoted $\mathcal{P}^{M}$. 


Let $\mathcal{P}^{\textsc{cRad}}$ be the set of distributions $P_O$ that are compatible with a parametrically classical and structurally radical model for a given parameter restriction.   Note that different types of parameter restrictions lead to different possibilities for $\mathcal{P}^{\textsc{cRad}}$.  We denote the set with no restriction, termed the {\em parameter-unrestricted} model associated to \textsc{cRAD}, by $\mathcal{P}^{\textsc{cRad}}_{\rm full}$.  \textsc{cCE}$_0$ is the parameter-unrestricted model for the DAG of Fig.~\ref{DAGs}(b), while \textsc{cSD}$_0$ is the parameter-unrestricted model for the DAG of Fig.~\ref{DAGs}(c).
% and \textsc{cSD}$_0$ are examples of classical causal models that are parameter-unrestricted.
%\textsc{cCE}$_0$ and \textsc{cSD}$_0$ are examples of classical causal models that are parameter-unrestricted.

To summarize, the distinction between parameter-unrestricted and parameter-restricted models for a given parametrically conservative and structurally radical model can be formalized as:
%One relevant distinction among models is:
\begin{itemize}
\item[parameter-unrestricted:] $\mathcal{P}^{\textsc{cRad}} = \mathcal{P}^{\textsc{cRad}}_{\rm full} $
\item[parameter-restricted:] $\mathcal{P}^{\textsc{cRad}} \subset \mathcal{P}^{\textsc{cRad}}_{\rm full} $
\end{itemize}


Consider those parameter-restricted causal models that have sufficient parametric freedom to subsume
 the statistics predicted by operational quantum theory among the compatible distributions.  For these, it is useful to introduce a further distinction, based on whether the parametric freedom is such that the compatible distributions go beyond those of operational quantum theory.  
 
%For the purposes of defining the distinction among parameter-restricted models, 
Let $\mathcal{P}^{\textsc{qCons}}$ be the set of distributions $P_O$ that are compatible with a parametrically quantum and structurally conservative model.


Among the parameter-restricted models, we can articulate a further distinction:
%We can now articulate the distinction among parameter restrictions that is of interest to us:
% The distinction among parameter restrictions of interest to us is this one:
\begin{itemize}
%\item[quantum-on-the-nose] $\mathcal{P}^{\textsc{cRad}}_{\rm full} \supset \mathcal{P}^{\textsc{cRad}}= \mathcal{P}^{\textsc{qCons}}$.  
\item[quantum-on-the-nose] $ \mathcal{P}^{\textsc{cRad}}= \mathcal{P}^{\textsc{qCons}}$ 
%\item[quantum-extending] $\mathcal{P}^{\textsc{cRad}}_{\rm full} \supset \mathcal{P}^{\textsc{cRad}} \supset \mathcal{P}^{\textsc{qCons}}$
\item[quantum-extending] $\mathcal{P}^{\textsc{cRad}} \supset \mathcal{P}^{\textsc{qCons}}$
%\item[no restriction] $\mathcal{P}^{\textsc{cRad}} = \mathcal{P}^{\textsc{cRad}}_{\rm full} $
\end{itemize}
In the quantum-on-the-nose case, the restricted set of parameters values, $\{ \mathcal{P}^{\rm sub}_{X|{\rm Pa}(X)}\}_{X\in {\rm Nodes}(G)}$ for the radical causal structure are such that the set of compatible distributions coincides precisely  with the set of distributions compatible with a quantum causal model having the conservative causal structure.  In the quantum-extending case, the set of compatible distributions is a superset of the latter. 
%y are such that the former is a superset of the latter.
\end{comment}

%With these distinctions in mind, we are now in a position to discuss the pertinence of our data-analysis technique to various existing attitudes towards causal accounts of Bell inequality violations.
%We are now in a position to discuss what our results imply about various types of parametrically conservative and structurally radical causal accounts of Bell inequality violations.  

%We pause first 

It is useful to make explicit the connection between the distinctions introduced here and the models discussed in the main text. For a Bell experiment, the DAG $G$ corresponding to the conservative causal structure 
%(the analogue of $G$)
 is that of Fig.~\ref{DAGs}(b) or (e), the common-cause structure, while the possibilities for DAGs $G_0, G_1,\dots$  corresponding to radical causal structures
 %radical causal structures (the analogues of the $G_i$ above)
  include the various different ways of allowing cause-effect relations between the labs (with the DAG of Fig.~\ref{DAGs}(c) being one way of doing so) and the various different ways of allowing for superdeterminism (with the DAG of Fig.~\ref{DAGs}(d) being one way of doing so).
  %, and the various different ways of allowing for retrocausation. 
%depicted in Figs.~\ref{DAGs}(c-d) and variants of these 
%(see Ref.~\cite{wood2015lesson}). 
 It follows that the model $\textsc{qCC}$ plays the role of $\textsc{q}G$, while $\textsc{cCE}_0$ and $\textsc{cSD}_0$ are examples of parameter-unrestricted $\textsc{c}G_i$ models. 


With these distinctions in mind, we are now in a position to discuss the pertinence of our data-analysis technique to various existing attitudes towards causal accounts of Bell inequality violations.

%Of parameter-restricted causal models of the latter sort which aim to reproduce the predictions of quantum theory, one can distinguish two types:

%that aim to reproduce the predictions of operational quantum theory by adopting a causal structure distinct from the one that is suggested by quantum calculation.  For this purpose, we denote the ...
%\begin{itemize}
%\item[quantum-on-the-nose] In this case, the restricted parameters values, $\{ \mathcal{P}^{\rm sub}_{X|{\rm Pa}(X)}\}_{X\in {\rm Nodes}(G)}$ are such that the set of compatible distributions $P_O$ coincides with the set of distributions $P_O$ that are compatible with a quantum causal model having the vanilla causal structure, $\mathcal{P}^{M^{\rm pr}} = \mathcal{P}^{M^{\rm vq}}$.
%\item[quantum-extending] In this case, the restricted parameters values, $\{ \mathcal{P}^{\rm sub}_{X|{\rm Pa}(X)}\}_{X\in {\rm Nodes}(G)}$ are such that the set of compatible distributions $P_O$ coincides with a {\em superset} of distributions $P_O$ that are compatible with a quantum causal model having the vanilla causal structure, $\mathcal{P}^{M^{\rm pr}} \supset \mathcal{P}^{M^{\rm vq}}$.
%\end{itemize}

%{\bf Cause-effect models (Superluminality)}

\subsection{Reassessment of various loopholes in Bell experiments}

In discussions of Bell experiments, a ``loophole'' is generally taken to be a plausible reason for denying the validity of some assumption required for the derivation of the Bell inequalities (or at least the validity of this assumption for a particular experiment), such that one escapes the contradiction that exists between these assumptions and the observed violations of Bell inequalities. 

%{\bf The locality loophole}

Consider a Bell experiment that violates a Bell inequality, but where the measurements on the wings are not done at space-like separation (such as the one described in this article). 
Such an experiment is said to suffer from a {\em locality loophole}, by which it is meant that one has a plausible reason for denying the validity of Bell's notion of local causality in such an experiment, namely, that positing a causal influence between the labs does not require those influences to be superluminal, 
%hence is not in conflict with relativity, 
so that such influences should be considered 
%and therefore is completely 
unobjectionable.\footnote{It is of course possible to object to allowing such a causal influence on the grounds that it is not mediated by any system that is described in the quantum formalism, but we shall not take this course here.}

%Consider a Bell experiment that violates a Bell inequality, but where the measurements on the wings are not done at space-like separation (such as the one described in this article).   It is standard to say that such an experiment {\em fails to seal the locality loophole} because the observed correlations can be reproduced by a model positing causal influences between the laboratories.

For a Bell experiment that fails to achieve space-like separation, a model can {\em leverage} the locality loophole, that is, make use of a cause-effect relation between the labs, in order to reproduce the observations (in particular, the Bell inequality violations).
As a consequence, it is generally believed that 
%in order to be able to demonstrate quantumness, 
 a good Bell experiment {\em must seal the locality loophole}, that is, it must enforce space-like separations between the measurements in the laboratories.

%However, recalling that ``reproducing the  observations''  means merely to {\em not underfit} the data,
%However, recall that to ``reproduce the  observations''  is merely to {\em not underfit} the data.  \rob{As noted in the main text, however, a model's quality should be assessed in terms of its predictive power, which requires one to require models not only to not underfit, but to {\em overfit} the data either.  As such, the question arises of whether leveraging the locality loophole }  
%Our discussion of the higher bar of not 
 %the discussion provided in this article poses a challenge to this attitude. 
Recall that, as noted in the introduction, not underfitting the data is a low bar, and a better figure of merit in model selection is predictive power, which can be compromised not only by underfitting but by overfitting as well. 
%where one accumulates evidence against a model when one shows that it is less predictive than its competitors.  \rob{ And a model can have worse predictive power }
%, which can occur 
%if it merely  {\em overfits} the data relative to competitors.   
Therefore, although leveraging the locality loophole allows one to ``reproduce the  observations'', i.e., to pass the low  bar of not underfitting the data, it is not clear a priori whether it allows one to pass the high bar of not {\em overfitting} the data.
%A Bell experiment wherein the measurements are not space-like separated may still 
Thus, even though positing a causal influence between the labs may be unobjectionable from the perspective of relativity theory, it can remain objectionable by virtue of having poor predictive power. 
%leading to overfitting of the data. 
 In this way, one can in principle provide evidence against the hypothesis of inter-lab causal influences using model selection techniques.

%  If so, then one has a means of accumulating evidence against the hypothesis of inter-lab causal influences by model selection techniques, rather than by ensuring space-like separation.
% even when such influences are not ruled out by relativity.


%The attitude that the locality loophole {\em must be sealed} in order to demonstrate quantumness seems to be motivated by two considerations: (i) positing a causal influence between the labs is unobjectionable when such an influence does not come into conflict with relativity, and (ii) any classical causal model with a cause-effect relation between the labs, such as $\textsc{cCE}_0$ for instance, can reproduce the observations (in particular, the Bell inequality violations).

%We do not dispute (i) or (ii), but recalling that ``reproducing the  observations'' means merely to {\em not underfit} the data, the discussion provided in our article poses a challenge to this argument for the inadequacy of Bell experiments without space-like separation.  

%Such experiments are standardly thought to be unable to certify quantumness in a device-independent manner [citation].
%Assuming that ``reproducing the  observations'' is understood as not underfitting the data, then our results challenge the view that the locality loophole  must be sealed in Bell experiments.  
 
 %simply because a cause-effect model does not underfit the data.  
 
% As noted in the introduction, not underfitting the data is a low bar.  A better figure of merit in model selection is predictive power, where one accumulates evidence against a model when one shows that it has less predictive than its competitors, for instance, because it {\em overfits} the data relative to competitors.  
 
 
Note that the claim that it is critical to seal
%about the importance of sealing
 the locality loophole has not traditionally come with any caveats.  
 %For instance, no one has claimed that sealing this loophole is {\em only} important for causal models wherein the parameters are restricted.
For instance, no one has claimed that sealing this loophole is {\em only} important for causal models wherein the parameters are restricted but {\em not} important for causal models wherein the parameters are unrestricted.   
Consequently, we will take the claim that it is critical to seal the locality loophole to be overturned if it is overturned in the context of parameter-unrestricted causal models.
%If one takes cause-effect relations between time-like-separated labs  to be unobjectionable, then one should be content to consider parameter-unrestricted models in the $\textsc{cCE}$ class of models of the Bell experiment (such as \textsc{cCE}$_0$).  Indeed, we know of no discussion of models leveraging the locality loophole wherein  a restriction of the parameters is stipulated.
  Given that the parameter-unrestricted classical cause-effect model \textsc{cCE}$_0$ was found in our experiment to have less predictive power than the quantum common-cause model \textsc{qCC}, and given that all parameter-unrestricted models in the \textsc{cCE} class are likely to perform similarly to \textsc{cCE}$_0$ (as noted in our discussion section), our results show that one can indeed collect evidence {\em against the hypothesis of inter-lab causal influences}, without requiring the measurements to have been space-like separated.  
%  our results show that one can indeed collect evidence against explanations that leverage the locality loophole, {\em in the sense of providing evidence against the hypothesis of inter-lab causal influences}, without requiring the measurements to have been space-like separated.  
  %provides the means for demonstrating the need for quantumness in the causal account of the data without needing the measurements to be space-like separated, i.e., without requiring the experiment to have sealed the locality loophole. 

%Given that it is reasonable to formulate the type of cause-effect causal models that are at play in discussions of the locality loophole as parameter-unrestricted models
%Bell experiments without space-like separation as one that involves no restriction on the parameters
% (such as \textsc{cCE}$_0$), the analysis done here suggests strongly that one does need to seal the locality loophole to be able to certify quantumness by Bell inequality violations.
% this option is less predictive than a quantum common cause model. 


%{\bf The superdeterminism loophole}

%[Mention measurement dependence? cite Barrett-Gisin?]

%We now consider the question of the extent to which superdeterminism provides a way out of the Bell no-go result in light of our results, that is, we consider the claim that the loophole of superdeterminism cannot be closed. 

%The possibility of a superdeterministic model of Bell inequality violations is 
The {\em superdeterminism loophole} consists of the fact that it is possible to devise a superdeterministic model of a Bell experiment that reproduces the statistics predicted by quantum theory.  It is often claimed that this loophole cannot be tested experimentally.
% (see, however, Ref.~\cite{}). 
%First, consider the claim that the loophole of superdeterminism in Bell experiments cannot be closed because such models can reproduce the predictions of quantum theory.
%As usual, in discussions of Bell experiments, a ``loophole'' is a possibility for salvaging Bell's notion of local realism.  The claim, therefore, is that Bell's notion can be salvaged because a superdeterministic model salvages it while reproducing the observations (in particular, Bell inequality violations).
As before, ``reproducing the statistics'' means merely not underfitting the data, while
%As before, ``reproducing the observations'' is here to be understood as not underfitting. 
%  %If one interprets ``reproducing the predictions as not underfitting, then 
%  
%We see, therefore,   that this claim presumes that underfiting is the only possible evidence that could be provided against such models. 
 %But as noted in the introduction, 
 model selection techniques 
 %generally
  hold models to a higher bar of predictive power, including {\em not overfitting} the data.    
 %The claim that superdeterminism is an uncloseable loophole does not stipulate more than the possibility of there being correlation between the setting variables and $\Lambda$, so it is appropriate to associate such claims with the parameter-unrestricted version of a superdeterministic model.  

Because the claim about the untestability of the superdeterminism loophole have not been predicated on restricting the parameter values in a superdeterminist model, we shall consider this claim to be overturned if it is overturned in the context of parameter-unrestricted models.  We have here shown that the parameter-unrestricted superdeterministic model \textsc{cSD}$_0$ has less predictive power than the quantum common-cause model \textsc{qCC}, and we have argued (in the Discussion section) that this is likely to be the case for all parameter-unrestricted superdeterministic models. 
% Insofar as \textsc{cSD}$_0$ is likely to be representative of the performance of any such model, our analysis shows that these are less predictive than the quantum common-cause model \textsc{qCC}.  
Consequently, our results provide experimental evidence {\em against}
%{\em can} be provided against 
such superdeterministic models, contrary to the claim that the superdeterminist loophole cannot be tested.\footnote{See also Ref.~\cite{chaves2021causal} for a complementary perspective on how to modify a Bell experiment in order to be able to test the hypothesis of a  superdeterministic account of Bell inequality violations.}
 

%If one interprets the notion of a model *reproducing* the predictions of quantum theory as that model *being compatible with* the correlations predicted by quantum theory (in the sense of compatibility outlined above), then we dispute the soundness of the claim on the grounds that not underfitting data is not the only criterion for model selection.  .   Such a claim is only justified if one is holding the model to the "low bar? of making the observed data likely, that is, not underfitting it. If one holds a model to the higher bar of not *overfitting* the data, then given that it is reasonable to formulate the full scope of superdeterministic models in terms of a classical causal model with no restrictions on the parameters, such as \textsc{cSD}$_0$, the analysis done here suggests stongly that this option is less predictive than a quantum common cause model.  The loophiole consisting of the possibility of these types of superdeterministic models *can*, therefore, be closed, at least in relation to the alternative causal account provided by the \textsc{qCC} model. 


%{\bf The retrocausation loophole}

%\rob{[Perhaps revise]}
%It is unclear to us whether anyone has endorsed retrocausation as a loophole that cannot be tested.
% %sealed in Bell experiments.  
% Nonetheless, as we noted in the discussion section, any parameter-unrestricted retrocausal model is likely to perform as poorly, relative to the \textsc{qCC} model, as do parameter-unrestricted cause-effect and superdeterministic models, such as \textsc{cCE}$_0$ and \textsc{cSD}$_0$.
%%does not provide a way out of Bell's no-go any more than parameter-unrestricted cause-effect and superdeterministic models do.  
%Consequently, any claim of the untestability
%%uncloseability
% of the retrocausation loophole is seen to be just as untenable as the claim of the untestability
% %uncloseability
%  of the superdeterminism loophole.
%%, given the analysis technique described here. 

%The retrocausation loophole, therefore, can also be sealed by the sort of experiment we have described here.



\subsection{Models that are compatible with all and only the statistics predicted by quantum theory}
%Quantum-on-the-nose models}


%If the range of parameters values in a structurally radical model of the Bell experiment is stipulated to be so restricted that it is compatible with {\em all and only} the correlations achievable in the \textsc{qCC} model, then it satisfies the no-signalling condition for all parameter values, and one cannot hope to experimentally distinguish it from \textsc{qCC}. 

In a structurally radical model of the Bell experiment that is quantum-on-the-nose, the range of parameter values is so restricted that it is compatible with {\em all and only} the correlations achievable in the \textsc{qCC} model, and consequently satisfies the no-signalling condition for all parameter values in the restricted set.  In this case, one cannot hope to experimentally distinguish it from the \textsc{qCC} model.  
%One could Call these the \textsc{qCC}-mirroring model in the \textsc{cCE} and \textsc{cSD} classes.  
By choosing the parameter restriction carefully, one can in principle define a quantum-on-the-nose model for any structurally radical DAG that can reproduce Bell inequality violations, such as the DAGs associated to the \textsc{cCE}$_0$ and \textsc{cSD}$_0$ models.  

The standard view of Bohmian mechanics~\cite{sep-qm-bohm}
 %\rob{[Goldstein,SEP]}
  is likely to be an example of such a model, where the DAG is one that allows for causal influences between the setting variable in one lab and the outcome variable in the other and so is in the \textsc{cCE} class.
%  (such as in the \textsc{cCE} class). 
%the \textsc{cCE} class.
% This is the case, presumably, for the standard view of Bohmian mechanics [citations], which is in the \textsc{cCE} class of models.  

We are not aware of any superdeterministic 
%or retrocausal 
models that are quantum-on-the-nose, although in principle one could define models of this sort.  
%Finally, note that if someone were to endorse a superdeterministic model that was quantum-on-the-nose, then one could not experimentally adjudicate between such a model and any other that reproduced quantum theory.  
 %Nonetheless, many proponents of structurally radical ways out of the Bell no-go result take their models to be {\em empirical competitors} to quantum theory, that is, they take them to be experimentally distinguishable from it in principle. 
%Note that any such models can be considered to
Such a model would yield a novel type of superdeterminism 
%and retrocausation
 loophole insofar as it {\em would be} predicated on restrictions in the parameter values.  {\em This} loophole---unlike the one discussed above---{\em cannot} be closed by any experiment for which the correlations are consistent with operational quantum theory. 
 %experimentally.  

%But, of course,  is merely to note that for any set of models that are quantum-on-the-nose, it does not seem possible to adjudicate between them by experimental means. 


%{\bf quantum-on-the-nose cause-effect models}

%{\bf Extending}

\subsection{Models that are compatible with a superset of the statistics predicted by quantum theory}
%\subsection{Quantum-extending models}

Many proponents of structurally radical ways out of the Bell no-go result take their models to be {\em empirical competitors} to quantum theory, that is, they take them to be experimentally distinguishable from it in principle.  These structurally radical classical causal models are parameter-restricted but in a way that is quantum-extending.
%Now consider parameter-restricted models that are quantum-extending.
%  There are some that are quantum-on-the-nose. Standard Bohmian mechanics. 
%But there are also quantum-extending models of this sort.  

We begin with those that are structurally radical by virtue of positing inter-lab causal influences.
%a cause-effect relation between the labs.

We believe that Valentini's subquantum-nonequilibrium version of Bohmian mechanics~\cite{valentini1991signal1,valentini1991signal2,valentini2002signal,valentini2002signaldeterministic}, which can simulate quantum theory but also explicitly allows for violations of the no-signalling condition, is of this type. 

%Consider models that don't restrict the parameter values down to the \textsc{qCC}-mirroring set, but also don't allow for {\em all} parameter values, as \textsc{cCE}$_0$ and \textsc{cSD}$_0$ did.  Call these the \textsc{qCC}-extending models in the \textsc{cCE} and \textsc{cSD} classes.  We believe that Valentini's version of Bohmian mechanics [cite Valentini], which can simulate quantum theory but also explicitly allows for violations of the no-signalling condition, is of this type.   
Because such models posit a more restricted scope of parameter values than we have assumed in the optimization that finds the best-fit parameter values, and because such restrictions could in principle {\em reduce} the degree of overfitting, 
%the model selection we have implemented in
the data analysis we have implemented here does not adjudicate between models of this sort and \textsc{qCC}.   Nonetheless, 
%our analysis makes clear that 
in order to be able to achieve such an adjudication using our technique, 
%do so, 
 it suffices 
%for the proponent of a given hypothesis 
to stipulate the range of parameter values that are allowed within a given model and to repeat our analysis while restricting the optimization  to this range.

Note also that although  one cannot conclude, based on our analysis, that \textsc{qCC} has more predictive power than a model of the sort just mentioned,
%any model of the sort just mentioned has less predictive power than \textsc{qCC} for our experimental data,
 it is still the case that our experiment provided an opportunity for finding that \textsc{qCC} has {\em less} predictive power than these alternatives.  That is, our experiment provided an opportunity for finding that nature exhibits deviations from operational quantum theory, for instance, by exhibiting the sorts of violations of the no-signalling condition that are predicted by Valentini's non-equilibrium version of Bohmian mechanics.  No evidence for such deviations was found however.  This is not unexpected insofar as such deviations are thought to only arise in exotic experimental scenarios, but a precision test in a non-exotic scenario nonetheless implies the {\em possibility} for finding such deviations. (See, e.g., the discussion of the distinction articulated in  Ref.~\cite{mazurek2021experimentally} between `terra-nova' and `precision' strategies for finding new physics.)  
% but it provided no evidence in favour of this conclusion. 

%In particular, our experimental setup provided an opportunity for observing deviations from quantum theory consistent with Valentini's version of Bohmian mechanics, for instance, the superluminal signalling that this model predicts is possible. As it was, however, the data provided no evidence for such deviations.


%{\bf Quantum-on-the-nose superdeterministic models}

%An analogous class of models 
%approach to models
Quantum-extending models that are superdeterministic  are also possible in principle.  (There has certainly been at least one proposal for a superdeterministic model that is empirically distinguishable from quantum theory, namely, that of Ref.~\cite{hossenfelder2020rethinking}, but it is unclear to us whether or not it subsumes all the statistics predicted by operational quantum theory.)
%There certainly have been proposals for superdeterministic models that are empirically distinguishable from quantum theory (see, e.g., Ref.~\cite{hossenfelder2020rethinking}), although it is unclear to us whether or not these proposals subsume all the statistics predicted by operational quantum theory.
Our technique can in principle be used to adjudicate between such quantum-extending models and \textsc{qCC}.  It suffices to repeat our analysis with a fitting procedure that restricts the optimization to the appropriate range of parameter values.\footnote{Note that if a given proposed superdeterminist model {\em does not} subsume the statistics predicted by operational quantum theory, then it can also be disfavoured by our data analysis technique if our experimental data conforms with the quantum predictions. It is just that it will be disfavoured in the conventional way---on the grounds that it {\em underfits} the data.}

%A more refined attitude towards superdeterministic models is not merely to grant the possibility of correlation between the settings and $\Lambda$, but to propose a concrete model which commits to a set of parameter values.  One would ideally want to show that this at least reproduces the quantum statistics and some authors wish to allow it to accommodate nonquantum statistics in some regimes. (Indeed, there have been proposals for superdeterministic models that are empirically distinguishable from quantum theory [Hossenfelder and Palmer], although it is unclear whether these models subsumed all quantum predictions.)  It is conceivable that these are quantum-extending models.  (Any models that do not subsume the statistics predicted by operational quantum theory could also be excluded by our data analysis technique.  It's just that they would be excluded in the conventional way---on the grounds that they {\em underfit} the data.)  Our technique can be used to adjudicate between these and \textsc{qCC}.  It suffices to repeat our analysis with a fitting procedure that restricts the optimization to the specified set of parameter values.  In this way, one can hope to devise evidence in favour of \textsc{qCC} over such models. 

%Second, if someone endorses a superdeterministic model that, when cast in the framework of classical causal models, restricts the parameter values in a nontrivial way that nonetheless provides opportunities for deviations from quantum theory, then to adjudicate between it and \textsc{qCC}, one must repeat our analysis with a fitting procedure that restricts the optimization to the specified set of parameter values.  In this way, one can hope to devise evidence in favour of \textsc{qCC} over such a model. 



\subsection{Summary}

%To summarize: 
%Our conclusions
The conclusions we can draw  from our experimental results about the viability of various  causal models can be summarized as follows:
%depends on the type of models one considers:
% differ with the type of causal model one considers:
\begin{itemize}
\item[(i)] Our results provide evidence against the claim that it is possible to get around Bell's no-go result merely by endorsing 
%the way out of the Bell no-go result is {\em merely} to endorse 
one or another type of structural radicalism (together with parametric conservatism) 
%while not 
without explicitly articulating any
% (either implicitly or explicitly) no
%but {\em without} any
 restriction on the scope of parameter values.
 % that might supplement the causal structure.  
%Our results therefore provide a challenge to the view of those who suggest that Bell inequality violations imply superluminal influences or superdeterminism or retrocausation, but do not see fit to articulate any concrete model. 
 %Such a position, 
 Our results therefore provide a challenge to the position of those who suggest that Bell inequality violations imply superluminal influences or superdeterminism,
 % or retrocausation,
  but do not see fit to articulate any concrete model. 
\item[(ii)] Our results {\em do not} provide experimental evidence against parameter-restricted causal models that are quantum-on-the-nose (such as the standard version of Bohmian mechanics, or superdeterministic 
%or retrocausal 
analogues thereof). 
\item[(iii)] Our results also do not provide experimental evidence against parameter-restricted causal models that are quantum-extending (such as Valentini's subquantum-nonequilibrium version of Bohmian mechanics~\cite{valentini1991signal1,valentini1991signal2,valentini2002signal,valentini2002signaldeterministic}, or superdeterministic 
%or retrocausal 
analogues thereof), but our data analysis techniques {\em do} provide a means for experimentally assessing these against a quantum causal model if the parameter restriction that they endorse can be made precise.
\end{itemize} 
 


\bibliography{Ref_2018}




\end{document}



%!TEX root = main.tex

The presence of data races in concurrent software is the most common
indication of a programming error. Data races in programs can result
in nondeterministic behavior that can have unintended
consequences. Further, manual debugging of such errors 
is prohibitively difficult owing to nondeterminism.
Therefore, automated detection and elimination of data races is an
important problem that has received widespread attention from the
research community. 
% Race detection techniques can be broadly
% classified as either being
% static~\cite{Naik:2006:ESR:1133255.1134018,pratikakis11locksmith,Radoi:2013:PSR:2483760.2483765,racerx,voung2007relay,heisenbugs,Yahav:2001:VSP:373243.360206,echo},
% i.e., those that analyze source code to detect races, or
% dynamic~\cite{savage1997eraser,Pozniansky:2003:EOD:966049.781529,cp2012,wcp2017,rvpredict,elmas2007goldilocks,Said2011,fasttrack,vonPraun:2001:ORD:504311.504288,Sen:2008:RDR:1375581.1375584,Huang2016,ipa2016,SPA2009}, i.e., those that examine a single execution of the
% program to discover a data race in the program.
Dynamic race detection techniques examine a single execution of a
concurrent program to discover a data race in the program.
In this paper we focus on dynamic race detection.
% \ucomment{Put more blabber}

Dynamic race detection may either be sound or unsound. Unsound
techniques, like lockset based methods~\cite{savage1997eraser}, have
low overhead but they report potential races that are spurious. Sound
techniques~\cite{lamport1978time,Mattern1988,Said2011,rv2014,cp2012,wcp2017},
on the other hand, never report the presence of a data race, if none
exist. The most popular, sound technique is based on computing the
\emph{happens-before} (HB) partial order~\cite{lamport1978time} on the
events of the trace, and declares a data race when there is a pair of
conflicting events (reads/writes to a common memory location performed
by different threads, at least one of which is a write operation) that
are unordered by the partial order. There are two reasons for the
popularity of the HB technique. First, because it is sound, it does
not report false positives. Low false positive rates are critical for
the wide-spread use of debugging techniques~\cite{threadsanitizer,developersRace14}. Second, even
though HB-based algorithms may miss races detected by other sound
techniques~\cite{Said2011,rv2014,cp2012,wcp2017}, they have the lowest
overhead among sound techniques. Many
improvements~\cite{Pozniansky:2003:EOD:966049.781529,fasttrack,elmas2007goldilocks}
to the original vector clock algorithm~\cite{Mattern1988} have helped
reduce the overhead even further.

\input{ntrace1}

However, HB-based dynamic analysis tools suffer from some
drawbacks. Recall that a program has a data race, if there is some
execution of the program where a pair of conflicting data accesses are performed
consecutively. Even though HB is a sound technique, its soundness
guarantee is only limited to the \emph{first} pair of unordered
conflicting events; a formal definition of ``first'' unordered pair is
given later in the paper. Thus, a trace may have many HB-unordered
pairs of conflicting events (popularly called \emph{HB-races}) that do
not correspond to data races. To see this, consider the example
program and trace shown in Fig.~\ref{fig:example1}. The trace
corresponds to first executing the statement of thread $t_1$, before
executing the statements of thread $t_2$.  The statement $\texttt{y :=
x + 5}$ requires first reading the value of $x$ (which is $0$) and
then writing to $y$. Recall that HB orders (i) two events performed by
the same thread, and (ii) synchronization events performed by
different threads, in the order in which they appear in the
trace. Using $e_i$ to denote the $i$th event of the trace, in this
trace since there are no synchronization events, both $(e_1,e_4)$ and
$(e_2,e_3)$ are in HB race. Observe that while $e_2$ and $e_3$ can
appear consecutively in a trace (as in Fig.~\ref{fig:trace1}), there
is no trace of the program where $e_1$ and $e_4$ appear
consecutively. Thus, even though the events $e_1$ and $e_4$ are
unordered by HB,
they do not constitute a data race.

\input{ntrace2}

As a consequence, developers typically fix the first race discovered,
re-run the program and the dynamic race detection algorithm, and
repeat the process until no races are discovered. This approach to bug
fixing suffers from many disadvantages. First, running race detection
algorithms can be expensive~\cite{developersRace14}, and so running
them many times is a significant overhead. Second, even though only
the first HB race is guaranteed to be a real race, it doesn't mean
that it is the \emph{only} HB race that is real. Consider the example
shown in Fig.~\ref{fig:example2}. In the trace $\tr_2$ (shown in
Fig.~\ref{fig:trace2}), both pairs $(e_1,e_4)$ and $(e_2,e_3)$ are in
HB-race. $\tr_2$ demonstrates that $(e_2,e_3)$ is a valid data race
(because they are scheduled consecutively). But $(e_1,e_4)$ is also a
valid data race. This can be seen by first executing $\texttt{y :=
1;}$ in thread $t_2$, followed by $\texttt{if (x == 0) skip;}$ in
thread $t_1$, and then finally $\texttt{x := 2;}$ in $t_2$. The
approach of fixing the first race, and then re-executing and
performing race detection, not only unnecessarily ignores the race
$(e_1,e_4)$, but it might miss it completely because $(e_1,e_4)$ might
not show up as a HB race in the next execution due to the inherent
nondeterminism when executing multi-threaded programs.  As a result,
most practical race detection tools including
ThreadSanitizer~\cite{threadsanitizer}, Helgrind~\cite{helgrind}
and \fasttrack~\cite{fasttrack} report more than one race, even if
those races are likely to be false, to give software developers the
opportunity to fix more than just the first race.
In Appendix~\ref{app:false_races}, we illustrate
this observation on four practical dynamic race detection tools
based on the happens-before partial order. Each of these tools
resort to  na\"ively reporting races beyond the first race and produce
false positives as a result.

The central question we would like to explore in this paper is, can we
detect multiple races in a given trace, soundly? One approach would be
to mimic the software developer's strategy in using HB-race detectors
--- every time a race is discovered, force an order between the two
events constituting the race and then analyze the subsequent
events. This ensures that the HB soundness theorem then applies to
the \emph{next} race discovered, and so on. Such an algorithm can be
proved to only discover valid data races. For example, in trace
$\tr_1$ (Fig.~\ref{fig:example1}), after discovering the race
$(e_2,e_3)$ assume that the events $e_2$ and $e_3$ are ordered when
analyzing events after $e_3$ in the trace. By this algorithm, when we
process event $e_4$, we will conclude that $(e_1,e_4)$ are not in race
because $e_1$ comes before $e_2$, $e_2$ has been force ordered before
$e_3$, and $e_3$ is before $e_4$, and so $e_1$ is ordered before
$e_4$. However, force ordering will miss valid data races present in
the trace. Consider the trace $\tr_2$ from
Fig.~\ref{fig:example2}. Here the force ordering algorithm will only
discover the race $(e_2,e_3)$ and will miss $(e_1,e_4)$ which is a
valid data race. Another approach~\cite{rv2014}, is to search for a
reordering of the events in the trace that respects the data
dependencies amongst the read and write events, and the effect of
synchronization events like lock acquires and releases. Here one
encodes the event dependencies as logical constraints, where the
correct reordering of events corresponds to a satisfying truth
assignment. The downside of this approach is that the SAT formula
encoding event dependencies can be huge even for a trace with a few
thousand events. Typically, to avoid the prohibitive cost of
determining the satisfiability of such a large formula, the trace is
broken up into small ``windows'', and the formula only encodes the
dependencies of events within a window. In addition, solver timeouts
are added to give up the search for another reordering. As a
consequence this approach can miss many data races in practice (see
our experimental evaluation in Section~\ref{sec:exp}).

In this paper, we present a new partial order on events in an
execution that we call \emph{schedulable happens-before} (SHB) to
address these challenges. Unlike recent attempts~\cite{cp2012,wcp2017}
to \emph{weaken} HB to discover more races, SHB is
a \emph{strengthening} of HB --- some HB unordered events, will be
ordered by SHB. However, the first HB race (which is guaranteed to be
a real data race by the soundness theorem for HB) will also be SHB
unordered. Further, every race detected using SHB is a valid,
schedulable race. In addition, we prove that, not only does SHB
discover every race found by the na\"{i}ve force ordering algorithm
and more (for example, SHB will discover both races in
Fig.~\ref{fig:example2}), it will detect \emph{all HB-schedulable}
races. The fact that SHB detects precisely the set of HB-schedulable
races, we hope, will make it popular among software developers because
of its enhanced predictive power per trace and the absence of false
positives.

We then present a simple vector clock based algorithm for detecting
all SHB races. Because the algorithm is very close to the usual HB
vector clock algorithm, it has a low overhead. We also show how to
adapt existing improvements to the HB algorithm, like the use
of \emph{epochs}~\cite{fasttrack}, into the SHB algorithm to lower
overhead. We believe that existing HB-based detectors can be easily
modified to leverage the greater power of SHB-based analysis. 
%Like
%HB, our SHB-based algorithm uses $O(\log n)$ space for traces that
%have a constant number of variables, locks, and threads. While it
%detects all HB-schedulable write-write and write-read races, it does
%not detect all HB-schedulable read-write races. It turns out that
%detecting every HB-schedulable read-write race is a computationally
%harder problem; we show that any algorithm detecting every read-write
%race must use linear space, i.e., effectively store the entire trace.
%
We have implemented our SHB algorithm and analyzed its performance on
standard benchmarks. Our experiments demonstrate that (a) many HB
unordered conflicting events may not be valid data races, (b) there
are many valid races missed by the na\"{i}ve force ordering algorithm,
(c) SHB based analysis poses only a little overhead as compared to HB
based vector clock algorithm, and (d) improvements like the use of
epochs, are effective in enhancing the performance of SHB analysis.

% \subsection{Related Work}
% \ucomment{Put detailed related work.}

% \subsection{Outline}
The rest of the paper is organized as follows:
% \begin{itemize}
	% \item 
	Section~\ref{sec:prelim} introduces notations and definitions relevant for the paper.
	% \item 
	In Section~\ref{sec:shb}, we introduce the partial order SHB and present an exact 
	characterization of schedulable races using this partial order.
	% \item 
	In Section~\ref{sec:algo}, we describe a vector clock algorithm for detecting
	schedulable races based on SHB. We then show how to incorporate epoch-based
	optimizations to this vector clock algorithm.
	% \item 
	Section~\ref{sec:exp} describes our experimental evaluation.
	% \item 
	We discuss relevant related work in Section~\ref{sec:related} and present
	concluding remarks in Section~\ref{sec:conclusion}.
% \end{itemize}




%!TEX root = main.tex

We will discuss two algorithms for detecting races identified by the
$\shb{}$ partial order. 
The algorithm is based on efficient, vector clock based
computation of the $\shb{}$-partial order. It is similar to the
standard \textsc{Djit}$^+$
algorithm~\cite{Pozniansky:2003:EOD:966049.781529} to detect
HB-races. We will first briefly discuss vector clocks and
associated notations.  Then, we will discuss a one-pass streaming
vector clock algorithm to compute $\shb{}$ for detecting races.  
Finally, we will discuss how epoch optimizations, similar to \fasttrack~\cite{fasttrack} 
can be readily applied in our setting to enhance performance
of the proposed vector clock algorithm.

% \vspace{-0.1in}
\subsection{Vector Clocks and Times}
% \vspace{-0.1in}
% \paragraph{Vector Times and clocks} 
A vector \emph{time} \textit{VT : $\threads{\tr}$ $\to$ Nat} maps each
thread in a trace $\tr$ to a natural number.  Vector times support
comparison operation $\cle$ for point-wise comparison, join operation
($\mx$) for point-wise maximum, and update operation $V[n/t]$ which
assigns the time $n \in $\textit{Nat} to the component $t
\in \threads{\tr}$ in the vector time $V$.  Vector time $\bot$ maps all
threads to 0. Formally, 
% \vspace*{.2\baselineskip} 
% \begin{tabular}{rclcrcl}
% $V_1 \cle V_2$ & \! {iff} \! & $\forall t: V_1(t) \le V_2(t)$ &  & $V_1 \mx V_2$ & = & $\lambda t: \mathit{max}(V_1(t), V_2(t))$\\
% $V[n/u]$ & = & $\lambda t: \mathtt{if}\; (t = u)\; \mathtt{then}\; n\; \mathtt{else}\; V(t)$ & & $\bot$ & = & $\lambda t: 0$\\
% \end{tabular}
%
% \vspace*{.2\baselineskip} 
\begin{align*}
\begin{array}{rclr}
V_1 \cle V_2 & \text{iff} & \forall t: V_1(t) \le V_2(t) & \text{(Point-wise Comparison)}\\
V_1 \mx V_2 & = & \lambda t: \mathit{max}(V_1(t), V_2(t))  & \text{(VC-Join)}\\
V[n/u] & = & \lambda t: \mathtt{if}\; (t = u)\; \mathtt{then}\; n\; \mathtt{else}\; V(t) & \text{(VC-Update)}\\
\bot & = & \lambda t: 0 & \text{(VC-Bottom)}
\end{array}
\end{align*}
% \noindent 
Vector \emph{clocks} are place holders for vector timestamps, or
variables whose domain is the space of vector times.
All the above operations, therefore, also apply to vector clocks.
The algorithms described next maintain a state comprising of
several vector  clocks, whose values, at specific instants, 
will be used to assign timestamps to events.
We will use double struck font ($\Cc$, $\Ll$, $\Rr$, etc.,) for vector clocks 
and normal font ($C$, $R$, etc.,) for vector times .

\input{vc}


\subsection{Epoch optimization}
\label{sec:algo_epoch}

The epoch optimization, popularized
by \textsc{FastTrack}~\cite{fasttrack} exploits the insight that
`\textit{the full generality of vector clocks is unnecessary in most
cases}', and can result in significant performance enhancement,
especially when the traces are predominated by read and write events.

An epoch is a pair of an integer $c$ and a thread $t$, denoted by $c@t$.
Intuitively, epoch $c@t$ can be treated as the vector time $\bot[c/t]$.
Thus, in order to compare an epoch $c@t$ with vector time $V$, 
it suffices to compare the $t$-th component of $V$ with $c$.
That is,
% \begin{tabular}{rcl}
% $c@t \cle V$ & iff & $c \leq V(t)$.
% \end{tabular}
\begin{align*}
\begin{array}{rcl}
c@t \cle V & \text{iff} & c \leq V(t).
\end{array}
\end{align*}
%
Therefore, comparison between epochs is less expensive than that
between vector times --- $O(1)$ as opposed to $O((|\threads{\tr}|)$
for full vector times. To exploit this speedup, some vector clocks in
the new algorithm will adaptively store either epochs or vector times.

\input{pseudocode_sound_epoch}

Algorithm~\ref{algo:epoch} applies the epoch optimization to
Algorithm~\ref{algo:vc}.  Here, similar to the \fasttrack~algorithm,
we allow clocks $\Rr_x$ and $\Ww_x$ to be adaptive, while other clocks
($\Cc_t$, $\Ll_\lk$ and $\LW_x$) always store vector times.  The
optimization only applies to the $\read$ and $\texttt{write}$ handlers
and thus we omit the other handlers from the description as they are
same as those described in Algorithm~\ref{algo:vc}.  We also omit
the \texttt{Initialization} procedure which only differs in that the
$\Rr_x$ and $\Ww_x$ are initialized to the epoch $0@0$.

Depending upon how these clocks compare with the thread's clock $\Cc_t$,
the clocks switch back and forth between epoch and vector time values:
\begin{itemize}
\item Initially, both $\Rr_x$ and $\Ww_x$ are assigned the epoch $0@0$.
The element $0@0$ can be thought of as the analogue of $\bot$.

\item
The clock $\Ww_x$ is \emph{fully adaptive} --- it can switch back
and forth between vector and epoch times depending upon how it compares with $\Cc_t$. 
Notice that, in the \fasttrack~algorithm proposed in~\cite{fasttrack},
the clock $\Ww_x$ is always an epoch.
The underlying assumption for such a simplification is that all 
the events that write to a given memory location are 
totally ordered with respect to $\hb{}$.
This assumption, however, need not hold beyond the first HB race.
After the first race is encountered, two $\wt(x)$ events 
$e$ and $e'$ may be unordered by both $\hb{}$ and $\shb{}$.
In Algorithm~\ref{algo:epoch}, $\Ww_x$ has an epoch representation
if and only if the last write event $e$ on $x$
is such that $e' \shb{} e$ for every event $e'$
of the form $e' = \ev{\cdot, \wt(x)}$ in the trace seen so far.
When performing a write event $e = \ev{t, \wt(x)}$,
if $\Ww_x$ satisfies $\Ww_x \cle \Cc_t$ (Line 15), 
then the event $e$ is ordered after
all previous $\wt(x)$ events, and thus,
in this case, $\Ww_x$ is converted to an epoch representation 
independent of its original representation (see Line 16).
Otherwise, there are at least two $\wt(x)$ events that are
not ordered by $\shb{}$ and thus $\Ww_x$ becomes a full-fledged vector clock
(Lines 20 and 22).

\item
The clock $\Rr_x$ is only \emph{semi-adaptive} --- we do not switch back to
epoch representation once the clock $\Rr_x$ takes up a vector-time value.
The clock $\Rr_x$ is initialized to be an epoch.
When processing a read event $e = \ev{t, \rd(x)}$, if the algorithm
determines that there is a read event $e' = \ev{t', \rd(x)}$ observed earlier
such that $e' \not\leq_\textsf{SHB} e$, then the clock $\Rr_x$
takes a vector-time representation.
After this point, $\Rr_x$ stays in the vector clock representation forever.
The $\Rr_x$ clock is an epoch only if 
all the reads of $x$ observed are ordered totally by $\shb{}$.
Thus, in order to determine if $\Rr_x$ can be converted back to an epoch representation,
one needs to check if $(\Rr_x \cle \Cc_t)$ every time a read event is processed.
Since this is an expensive additional comparison and because most traces
from real-world examples are dominated by read events, we avoid such a check
and force $\Rr_x$ to be only semi-adaptive. 
This is similar to the \fasttrack~algorithm.
\end{itemize}
% Complete algorithm implementing this optimization can be found in Appendix~\ref{app:epoch}.
% \input{pseudocode2col_epoch}

As with \textsc{FastTrack}, the epoch optimization for $\shb{}$
is sound and does not lead to any loss of precision --- the optimized
algorithm (Algorithm~\ref{algo:epoch}) declares a race at an event $e$ 
iff the corresponding unoptimized algorithm (Algorithm~\ref{algo:vc}) declares a race at $e$.

One must however note that the new clock $\LW_x$
does not have an adaptive representation, and is always
required to be a vector clock. 
One can think of $\LW_x$ to be similar to, say, the clocks $\Ll_\lk$.
These clocks are used to maintain the partial order,
unlike the clocks $\Rr_x$ or $\Ww_x$ which are only
used to check for races.
Thus, one needs the full generality of vector times for $\LW_x$.

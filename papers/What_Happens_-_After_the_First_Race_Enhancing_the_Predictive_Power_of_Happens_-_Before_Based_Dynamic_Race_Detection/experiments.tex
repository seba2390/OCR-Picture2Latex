%!TEX root = main.tex

We first describe our implementation to detect
$\hb{}$-schedulable races.
We then present a brief description of the chosen benchmarks
and finally the results of evaluating our implementation
on these benchmarks.

\subsection{Implementation}
\label{subsec:impl}

We have implemented our SHB-based race detection algorithms
(Algorithm~\ref{algo:vc} and Algorithm~\ref{algo:epoch}) 
in our tool \tool, which is publicly available at~\cite{rapid}.
{\tool} is written in Java and supports
analysis on traces generated by the instrumentation and logging 
functionality provided by \rvpredict~\cite{rvpredict} to generate traces
from Java programs.
The traces generated by \rvpredict~contain read, write,
fork, join, acquire and release events.
We assume that the traces are sequentially consistent,
similar to the assumption made by~\cite{rv2014}. 
% \rvpredict, at least in theory, detects more races than 
% any existing sound race predictive algorithm.
We compare the performance of five dynamic race detection algorithms
to demonstrate the effectiveness of SHB-based sound reasoning:
% We have implemented our SHB-based race detection algorithms in the tool
% \tool~\cite{rapid}. {\tool} is written in Java 
% and uses the instrumentation and logging functionality
% of \rvpredict~\cite{rvpredict} for Java programs. We compare the
% performance of four race detection algorithms to demonstrate the
% effectiveness of SHB-based reasoning.
\begin{description}
\item[HB] We implemented the 
  \textsc{Djit}$^+$ algorithm for computing the $\hb{}$-partial order
  and detecting HB-races, in our tool~\tool.  As with popular
  implementations of \textsc{Djit}$^+$, our implementation
  of \textsc{Djit}$^+$ discovers all $\hb{}$-unordered pairs of
  conflicting events. This serves as a base line to demonstrate how
  many false positives would result, if one considered all HB-races
  (instead of $\hb{}$-schedulable races).  This algorithm is same as
  Algorithm~\ref{algo:vc} except that the lines involving the clock
  $\LW_x$ (Lines 5, 21 and 28) are absent.
\item[SHB] This is the implementation of Algorithm~\ref{algo:vc}
  in our tool~\tool. The soundness guarantee of Algorithm~\ref{algo:vc}
  (Theorem~\ref{thm:correct-races}) ensures that our implementation
  reports only (and all) $\hb{}$-schedulable races and thus reports no false alarms.
  % This algorithm also analyzes the complete trace (instead of terminating
  % after the first race) and does not raise any false alarms.
  % We have implemented both a vector clock-based
  % algorithm and its epoch-based optimization.
% \item[SHB(S)] This is the ``sound'' version of the SHB algorithm that checks 
%   conditions~\ref{lbl:sufficient-read} and~\ref{lbl:sufficient-write}
%   of Theorem~\ref{thm:SHBSoundness}. This algorithm \emph{only}
%   reports races that are schedulable, but it may miss some read-write
%   races that are schedulable. We have implemented both a vector clock
%   version and its epoch-based optimization for this algorithm.
\item[FHB] This is the algorithm that mimics a software developer's strategy 
  when using HB-race detectors. 
  This algorithm is a slight variant of the \textsc{Djit}$^+$
  algorithm and is implemented in our tool~\tool.
  Every time an HB-race is discovered,
  the algorithm force orders the events in race, before analyzing subsequent
  events in the trace.
  When processing a read event $e = \ev{t, \rd(x)}$, if the
  algorithm discovers a race (that is, if the check $\neg(\Ww_x \cle \Cc_t)$ passes),
  the algorithm reports a race and also updates the clock
  $\Cc_t$ as $\Cc_t := \Cc_t \sqcup \Ww_x$.
  Similarly, at a write event, the algorithm updates the clock
  $\Cc_t$ as $\Cc_t := \Cc_t \sqcup \Rr_x$ (resp. $\Cc_t := \Cc_t \sqcup \Ww_x$)
  if the check $\neg(\Rr_x \cle \Cc_t)$ (resp. $\neg(\Ww_x \cle \Cc_t)$) passes.
  % Recall that a vector clock algorithm (like $\textsc{Djit}^+$ or \fattrack)
  % detects a race $(e_1, e_2)$ when it observes the second event $e_2$
  % and checks 
  This algorithm is sound --- all races reported by this algorithm are
  schedulable, but it may fail to identify some races that are
  schedulable. The complete description of FHB is presented in Algorithm~\ref{algo:fhb}.
  \input{pseudocode_fhb}
\item[WCP] WCP or Weak Causal Precedence~\cite{wcp2017} is another sound
  partial order that can be employed for predictive data race
  detection.  WCP is weaker than both, its precursor CP~\cite{cp2012},
  and HB.  That is, whenever HB or CP detect the presence of a race in
  a trace, WCP will also do so, and in addition, there are traces when
  WCP can correctly detect the presence of a race when neither HB or
  CP can.  Nevertheless, WCP (and CP) also suffer from the same
  drawback as HB --- the soundness guarantee applies only to the first
  race. As a result, races beyond the first one, detected by WCP (or
  CP) may not be real races.  WCP admits a linear time vector clock
  algorithm and is also implemented in~\tool.  
\item[RVPredict] \rvpredict's race detection technology
relies on maximal causal models~\cite{rv2014}. 
\rvpredict~is sound and does not report any false alarms.
Besides, \rvpredict, at least in theory,
guarantees to detect more races than any other sound race prediction tool,
and thus more races than Algorithm~\ref{algo:vc} theoretically.
\rvpredict~encodes the problem of race detection as a logical formula
and uses an SMT solver to check for races.
\rvpredict~can analyze the traces generated using its logging functionality,
and thus is a natural choice for comparison.
\end{description}

Besides the vector clock algorithms (HB, SHB, FHB, WCP) described
above, we also implemented the epoch optimizations for HB and SHB
in~\tool.

\subsection{Benchmarks}

We measure the performance of our algorithms against traces drawn from
a wide variety of benchmark programs (Column 1 in
Table~\ref{tab:metadata}) that have previously been used to measure
the performance of other race detection
tools~\cite{cp2012,rv2014,wcp2017}. 
The set of benchmarks have been derived from different suites.  
The examples \textsf{airlinetickets} to \textsf{pingpong} are
small-sized, and belong to the IBM Contest benchmark
suite~\cite{Farchi2003}, with lines of code roughly varying from 40 to
0.5M.  The benchmarks \textsf{moldyn}
and \textsf{raytracer} are drawn from the Java
Grande Forum benchmark suite~\cite{JGF2001} and are medium-sized with about 3K lines of code.  
The third set of benchmarks correspond to real-world software 
applications and include Apache FTPServer, W3C Jigsaw web server, 
Apache Derby, and others (\textsf{xalan} to \textsf{eclipse}) 
derived from the DaCaPo benchmark suite (version 9.12)~\cite{DaCapo2006}.

In Table~\ref{tab:metadata}, we also describe the characteristics of
the generated traces that we use for analyzing our algorithms.  The
number of threads range from 3-12, the number of lock objects can be
as high as 8K.  The distinct memory locations accessed (Column 5) in
the traces can go as high as 10M.  The traces generated are dominated
by access events, with the majority of events being read events
(compare Columns 6, 7 and 8).

\subsection{Setup}
 
Our experiments were conducted on an 8-core 2.6GHz 46-bit Intel
Xeon(R) Linux machine, with HotSpot 1.8.0 64-Bit Server as the JVM and
50 GB heap space.  Using \rvpredict's logging functionality, we
generated one trace per benchmark and analyzed it with the various race
detection engines: HB, SHB, FHB, WCP and \rvpredict.

Our evaluation is broadly designed to evaluate our approach
based on the following aspects:

\begin{enumerate}
  \item \textbf{Reducing false positives:} Dynamic race detection
  tools based on Eraser style lockset based
  analysis~\cite{savage1997eraser} are known to scale better than
  those based on happens-before despite careful optimizations like the
  use of epochs~\cite{fasttrack}.  One of the main reasons for the
  popularity of HB-based race detection tools such
  as \fasttrack~\cite{fasttrack} and
  ThreadSanitizer~\cite{threadsanitizer} is the ability to produce
  reliable results (no false positives).  However, as pointed out in
  Section~\ref{sec:intro}, HB based analysis can report false races
  beyond the first race discovered.  The purpose of detecting
  $\hb{}$-schedulable races, instead of all HB-races, is to ensure
  that only correct races are reported.  However, since our algorithm
  for detecting $\hb{}$-schedulable races tracks additional vector
  clocks (namely $\LW_x$ for every memory location $x$), we would like
  to demonstrate the importance of such an additional book-keeping for
  ensuring soundness of happens-before based reasoning.

  \item \textbf{Prediction power:} As described in
  Section~\ref{sec:intro}, a na\"ive fix to the standard HB race
  detection algorithm is to employ the FHB algorithm --- after a race
  is discovered at an event, order the event with all conflicting
  events observed before it.  We would like to examine if the use of
  $\shb{}$-based reasoning enhances prediction power by detecting more
  races than this na\"ive strategy.  Further, we would like to
  evaluate if more powerful approaches like the use of SMT solvers
  in \rvpredict~give significantly more benefit as compared to our
  linear time streaming algorithm.

  \item \textbf{Scalability:} While Algorithm~\ref{algo:vc} runs in
  linear time, it tracks additional clocks ($\LW_x$ for every memory
  location $x$ accessed in the trace) over the standard HB vector
  clock algorithm.  Since this can potentially slow down analysis, we
  would like to evaluate the performance overhead due to this
  additional book-keeping.

  \item \textbf{Epoch optimization:} The standard epoch optimization
  popularized by \fasttrack~\cite{fasttrack} is designed to work for
  the case when all the writes to a memory location are totally
  ordered.  While this is true until the first race is discovered,
  this condition may not be guaranteed after the first race.  We will
  evaluate the effectiveness of our adaptation of this optimization to
  work beyond the first race.
\end{enumerate}

% \ucomment{Umang continues from this point.}

\subsection{Evaluation}

\input{table_metadata}
\input{table_races}

Our experimental results are summarized in
Table~\ref{tab:metadata}, Table~\ref{tab:races} and Table~\ref{tab:times}. 
Table~\ref{tab:metadata} describes information about
generated execution logs.
Table~\ref{tab:races} depicts the number of races and warnings
raised by the different race detection algorithms.
Columns 3-8 in Table~\ref{tab:races} report the number of distinct pairs
$(pc_1, pc_2)$ of program locations corresponding
to an identified data race.
That is, for every \emph{event} race pair $(e_1, e_2)$ identified by the different
race detection algorithms, we identify the pair of \emph{program locations}
that give rise to this event pair and report the total
number of such program location pairs (counting the
pairs $(pc_1, pc_2)$ and $(pc_2, pc_1)$ only once).
Since each of the vector clock algorithms (HB, SHB, FHB and WCP)
only report whether the event being processed is in race
with some earlier event, we need to perform a separate analysis step
using the vector timestamps, to determine the actual pair of events
(and thus the corresponding pair of program locations) in race.
In Columns 9, 10, 11 and 12 in Table~\ref{tab:races} we report the number of \emph{warnings}
raised by the four vector clock algorithms---HB, SHB, FHB and WCP respectively.
A warning is raised when at a read/write event $e$, we determine if
the event $e$ is in race with an earlier event, 
counting multiple warnings for a single event only once.
% As can be noted, naively running HB vector clock algorithm, can lead to
% a lot of warnings (see Column 2, for example, in \textsf{moldyn} or \textsf{lusearch}),
% and most of these are potentially spurious.
In Table~\ref{tab:times}, Columns 2, 5, 8, 9, 10 and 11 respectively
report the time taken by
different analyses engines --- HB, SHB, FHB, WCP and \rvpredict--- on the trace generated.
We also measure the time taken by the epoch optimizations
for both HB and SHB vector clock algorithms (Columns 4 and 7 respectively)
and report the speedup thus obtained over the na\"ive vector clock algorithms 
(Columns 4 and 7 respectively). 
When analyzing the generated traces using WCP, we filter out events
that are thread local; this does not affect any races.
The memory requirement of a na\"ive vector clock algorithm for WCP, 
as described in~\cite{wcp2017} can be a bottleneck and
removing thread local events allowed us to analyze the larger traces 
(\textsf{xalan}, \textsf{lusearch} and \textsf{eclipse}) without any memory blowup.
We next discuss our results in detail.

\subsubsection{Reducing false positives}
First, observe that both the number of races reported (Columns 3, 4
and 5 in Table~\ref{tab:races}) and the number of warnings raised
(Columns 8, 9 and 10) by HB, SHB and FHB are monotonically decreasing,
as expected --- HB detects all $\hb{}$-schedulable races but
additional false races, SHB detects exactly the set of
$\hb{}$-schedulable races and FHB detects a subset of
$\hb{}$-schedulable races.  Next, the number of races reported by HB
can be way higher than the actual number of $\hb{}$-schedulable races
(see \textsf{moldyn} and \textsf{lusearch}).  Similarly, the number of
warnings raised can be an order of magnitude larger than those raised
by either SHB or FHB.  Clearly, many of these warnings are potentially
spurious.  Thus, an incorrect use of the popular HB algorithm can
severely hamper developer productivity, and completely defies the
point of using a sound race detection analysis technique.
Further, in each of the benchmarks, both the set of races as well 
as the set of warnings
reported by WCP were a superset of those reported by HB. 
This follows from the fact that WCP is a strictly weaker relation than HB.

\input{ntrace4}

While Theorem~\ref{thm:SHBSoundness} guarantees that the each of the additional
race pairs reported by HB (over those reported by SHB) 
cannot be scheduled in any correct reordering of the observed trace 
that respects the induced $\hb{}$ partial order, it does not guarantee
that these extra races cannot be scheduled in \emph{any} correct reordering.
In order to see if the extra races reported by HB (Column 3 in Table~\ref{tab:races})
can be scheduled in a correct reordering that does not respect $\hb{}$ order,
we manually inspected the traces (annotated with their
vector timestamps) of \textsf{mergesort}, \textsf{moldyn}, \textsf{derby}, 
\textsf{ftpserver}, and \textsf{jigsaw}. In each of these benchmarks,
we found that all the extra race pairs reported by HB can indeed
\emph{not} be scheduled in \emph{any} correct reordering
(whether or not the correct reordering respects the induced $\hb{}$ partial order).
A common pattern that helped us conclude this observation has been depicted in
Fig.~\ref{fig:pattern1}.  Here, the trace writes to a memory location
$x$ in a thread $t_1$ (event $e_1$).  Then, sometime later, another
event $e_2$ performed by a different thread $t_2$ reads the value
written by $e_1$. This is then followed by other events of thread
$t_2$, not pertaining to memory location $x$.  Finally, thread $t_2$
reads the memory location $x$ again in event $e_3$.  This pattern is
commonly observed when a thread reads a shared variable (here, this
corresponds to the event $e_2$), takes a branch depending upon the
value observed and then accesses the shared memory again within the
branch.  HB misses this dependency relation thus induced, and
incorrectly reports that the pair $(e_1, e_3)$ is in race.  SHB, on
the other hand, correctly orders $e_1 \shb{} \ltho{}(e_3)$, and does not
report a race.

The two extra races reported by WCP but not by HB in \textsf{jigsaw}
could not be confirmed to be false positives.
Further, we did not inspect the extra races reported by HB or WCP (over SHB) 
in \textsf{xalan}, \textsf{lusearch}
and \textsf{eclipse} owing to time constraints.

\input{table_times}


\subsubsection{Prediction Power}
The na\"{i}ve algorithm FHB, while sound, can miss a lot of real races
(Column 5 in Table~\ref{tab:races}) and has a poor prediction power as
compared to the sound SHB algorithm.  See for
example, \textsf{lusearch} and \textsf{eclipse} where FHB misses
almost half the races reported by SHB.  Next, observe that
while \rvpredict, in theory, is \emph{maximally sound}, it can miss a
lot of races, sometimes even more than the naive FHB strategy (Columns
6 and 7 in Table~\ref{tab:races}).  This is because \rvpredict~relies
on SAT solving to determine data races.  As a result, in order to
scale to large traces obtained from real world software,
\rvpredict~resorts to \emph{windowing} --- dividing the trace into
smaller chunks and restricting its analysis to these smaller chunks.
This strategy, while useful for scalability, can miss data races that
are spread far across in the trace, yet can be captured using
happens-before like analysis.  Besides, since the underlying
DPLL-based SAT solvers may not terminate within reasonable
time, \rvpredict~sets a timeout for the solver --- this means that
even within a given window, \rvpredict~can miss races if the SAT
solver does not return an answer within the set timeout.  All these
observations clearly indicate the power of $\shb{}$-based reasoning.

Again, based on our manual inspection of program traces, we depict a common
pattern found in Fig.~\ref{fig:pattern2}.
Here, first, a thread $t_1$ writes to a shared variable $x$ (event $e_1$).
This is followed by another write to $x$ in a different thread $t_2$
(event $e_2$). Finally, the next access to $x$ is a read event $e_3$
performed by thread $t_2$.
While FHB correctly reports the first write-write race $(e_1, e_2)$,
it fails to detect the write-read race $(e_1, e_3)$ because of the
artificial order imposed between $e_1$ and $e_2$.
SHB, on the other hand, reports both $(e_1, e_2)$
and $(e_1, e_3)$ as $\hb{}$-schedulable races.

% \ucomment{Come back. Describe windowing here}

% One particular striking observation that we would like to bring to attention
% is that naively running HB vector clock algorithm, can lead to
% a lot of warnings (see Column 4, for example, in \textsf{moldyn} or \textsf{lusearch}),
% and most of these are potentially spurious.
% This can severely hamper developer productivity, and completely defies the point
% of using a sound technique.
% At the same time, naively fixing this issue can lead to loss in prediction power.
% See, for example, Columns 8 and 9 of \textsf{eclipse}, where
% SHB identifies 88 distinct pairs, whereas FHB only identifies about half of these races.


% \input{table2}
% We now address the results in Table~\ref{tab:time}. 
\subsubsection{Scalability}
% As can be seen, the number of read and write events (Columns 5 and 6) can get really large.
First, the size of the traces, that SHB and the other three
linear time vector clock algorithms can handle, can be really large,
of the order of hundreds of millions (\textsf{xalan}, \textsf{lusearch}, etc.,).
In contrast, \rvpredict~fails to scale for large traces, even after
employing a windowing strategy.
This is especially pronounced for the larger traces 
(\textsf{bufwriter}, \textsf{derby}-\textsf{xalan}).
This suggests the power of using a linear time vector clock algorithm
for dynamic race detection for real-world applications.
The small and medium sized examples almost always
finish with a few seconds for each of HB, SHB, FHB and WCP.
The larger examples \textsf{xalan}, \textsf{lusearch}
and \textsf{eclipse} can take as much as 4-10 minutes
for the vector clock algorithms and 6-15 minutes for
\rvpredict's analysis with a window size of 10K and a solver timeout
of 4 minutes.

\subsubsection{Epoch optimization}
The epoch optimization is indeed effective in improving the
performance of vector-clock algorithms even when all the write events
to a memory location may not be totally ordered.  The speedups vary
from 1.2x to 8.3x on small and medium sized benchmarks and from 1.2x
to 2.9x on larger traces.  The speedup obtained for HB race detection
is, in general, less than in the case of SHB algorithm.  This is
expected since SHB is strictly stronger than HB --- every pair of
events ordered by $\hb{}$ is also ordered by $\shb{}$, and not every
pair of events ordered by $\shb{}$ may be ordered by $\hb{}$.  As a
result, a write event can get ordered after all previous write events
more frequently when using $\shb{}$ than when using $\hb{}$.  This
means that in the epoch optimization for SHB, the $\Ww_x$ clocks take
up epoch representation more frequently than in the HB algorithm, and
this difference is reflected in Columns 5 and 8 of
Table~\ref{tab:times}.

% Here, the performance can degrade on small traces (because of possibility of
% extra computation in maintaining epochs, and switching back an forth too frequently).
% However, as expected, on the larger traces, the performance benefit is significant
% with about 20\% speedup on most examples, with the exception of \textsf{xalan} where
% the epoch optimization leads to a slight slowdown.

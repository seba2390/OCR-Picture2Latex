
\begin{figure}[tp]
  \centering
  \includegraphics[width=8.5cm]{figures/map_of_transformations_mini.pdf}
  \caption{
    (Color online) Real-space, auxiliary-space, latent-space variables, and the canonical transformations between them.
    }
\label{fig:map_of_transformations}
\end{figure}
The classical integrable system has $N-1$ action variables and the total momentum as conserved quantities.
We define $(I_N, \theta_N)$ as
\begin{align}
  \begin{split}
    I_N & = \frac{1}{2N}\left(\sum_{i=1}^N p_i\right)^2, \\
    \theta_N & = \frac{1}{\sqrt{N}}\sum_{i=1}^N q_i,
  \end{split}
\end{align}
and assume the total momentum to be zero to avoid a drift of the center of mass.
We also assume the potential function to be translation invariant and represented by the following form:
\begin{align}
    V(q) & = \sum_{i=1}^{N}v(r_{ii+1}), \label{eq:chain}
\end{align}
where $r_{ij}$ is the difference between the displacements of the adjacent particles $r_{ij} = q_i - q_j$.

For convenience, we call the space described by the canonical coordinates $x = \{p_i,q_i\}_{i=1}^{N}$ the real space.
We also introduce the auxiliary space variables $z = \{\xi_i,\zeta_i\}_{i=1}^{N}$, which are related to the action-angle variables by
\begin{align}
  \begin{split}
    I_i & = \frac{\xi_i^2 + \zeta_i^2}{2}, \\
    \theta_i & = \tan^{-1}\left(\frac{\xi_i}{\zeta_i}\right), \qquad i = 1, \ldots N-1,
  \end{split} \label{eq:latent_space_representation_of_action_angle_variables}
\end{align}
and $(\xi_N,\zeta_N)$ are the momentum and the position of the center of mass, respectively.
We introduce the auxiliary variables to represent the bounded property of the system and the conservation of the torus radii straightforwardly.
Let $\mathscr{F}$ and $f$ be the canonical transformations between the real-space, the auxiliary-space, and the latent-space variables, as shown in \reffig{fig:map_of_transformations}. We represent $f$ using a neural network~\cite{our_supplemental_material}.
The composite transformations, $\mathscr{F} \circ f$ and $f^{-1}\circ \mathscr{F}^{-1}$, are also canonical transformations.
The canonical transformation from the real-space variables into the action-angle variables was introduced in Ref.~\citen{Bondesan-Lamacraft2019}.
The existence of the action-angle variables was proven in some integrable systems~\cite{Nguyen2005,Ito1989,Kappeler1998,Kappelerf-Henricit2008,Henrici2015}.
\begin{figure}[tp]
  \centering
  \includegraphics[width=8cm]{figures/canonical_trans_diagrams.pdf}
  \caption{
    Schematic picture of our canonical transformations from real space to auxiliary space.
    (a) An elemental block constructing our canonical transformation.
    This block is a combination of a point transformation and a symplectic linear transformation.
    $\mathcal{F}$ is a bijective map represented by RealNVP.
    The transformation of $p$ is derived from the generator function obtained from the point transformation and
    $S$ stands for the symplectic linear transformation.
    (b) The whole structure of our canonical transformation.
    DHT stands for the discrete Hartley transformation and
    $B$ means the elemental block defined in (a).
    COM stands for the center of mass.
    }
  \label{fig:canonical_trans_diagrams}
\end{figure}

We represent $v(r)$ in \refeq{eq:chain} by using the residual neural network~\cite{He-etal2016,Sehanobish-etal2020}.
The transformation $f$ is composed of three transformations: the canonical transformation generated by point transformations represented by the neural network~\cite{Shuo-Hui-etal2020}, the symplectic linear transformation parameterized by the Iwasawa decomposition~\cite{Bondesan-Lamacraft2019,Iwasawa1949}, and the discrete Hartley transformation~\cite{Hartley1942,Bracewell1983}.
A schematic picture of our canonical transformations is illustrated in \reffig{fig:canonical_trans_diagrams}.
The point transformations are implemented using the RealNVP neural network, which is one of the invertible neural networks~\cite{RealNVP2017}.
The invertible neural network has the universal approximation property under some conditions~\cite{Teshima-et-al2020}.
Since the point transformation acts only on position coordinates, we introduce a
symplectic transformation to represent the coupling between position
and momentum coordinates. We thus expect our neural network to
possess high representability.
The discrete Hartley transformation is used for extracting the motion of the center of mass from the real space coordinates.
See Supplemental Material for details of the neural network and parameter settings~\cite{our_supplemental_material}.
We used the Adam optimizer~\cite{Adam2017}.
The learning rate was reduced after some epochs to improve the accuracy.
For the other hyperparameters in Adam, we used the same values proposed in Ref.~\citen{Adam2017}.

Training data in our approach are composed of samples of the action-angle variables $\{I_i,\theta_i\}_{i=1}^{N}$.
The action variables are sampled from the Boltzmann distribution $\rho_{\mathrm{B}}$,
\begin{align}
  \rho_{\mathrm{B}} = \frac{e^{-\frac{K(I)}{T}}}{Z}, \; Z = \int_0^{\infty} dI \;e^{-\frac{K(I)}{T}},
\end{align}
where $T$ is the temperature.
The angle variables are sampled from the uniform distribution.

We propose a loss function that consists of two parts: the loss of the action-variable conservation and the loss of the energy equivalence.
Specifically, the losses are given by the mean squared logarithmic error (MSLE) function, which is arguably one of the most useful loss functions for time series analysis~\cite{Liu-etal2017,Zhou-Huang2019,Van-etal2018},
\begin{align}
  \begin{split}
    L & = L_{I} + L_E , \\
    L_I & = \sum_{i=1}^{N-1}\sum_{k=1}^{N_{\mathrm{time}}}
    \frac{\average{|\log(I_i(t_0)+1) - \log(I_i(t_k)+1)|^2}_D}{(N-1)N_{\mathrm{time}}}, \\
    L_E & = \average{|\log(H(p,q)+1) - \log(K(I)+1)|^2}_D,
  \end{split} \label{eq:final_loss_function}
\end{align}
where $N$ is the number of particles, $N_\mathrm{time}$ is the number of time points, and $\average{\cdot}_D$ is the average over the input data.
The loss function $L_E$ quantifies the energy equivalence: the energy is invariant under the canonical transformation.
The loss function $L_I$ computes the difference between the action variables at two-time points.
We calculate the time evolution of the real space variables using the neural network potential function.
The initial state of the time evolution is set through the inverse canonical transformation from training data labeled as $\{I_i(t_0)\}_{i=1}^{N}$.
Then, $\{I_i(t_k)\}_{i=1}^{N}$ are calculated from the time series of $\{p_i,q_i\}_{i=1}^{N}$ through the canonical transformation.
In the present study, we used the adjoint method with a symplectic integrator~\cite{Sanz-Serna2016,NeuralODE} to reduce the memory consumption in the time evolution.

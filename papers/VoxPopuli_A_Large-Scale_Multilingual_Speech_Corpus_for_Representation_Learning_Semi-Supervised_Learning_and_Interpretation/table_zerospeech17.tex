\begin{table}[t]
    \centering
    \small
    \tabcolsep=0.16cm
    \begin{tabular}{r|c|c|c|c}
    \toprule
    & \multicolumn{4}{c}{Within/Across Speaker $\downarrow$} \\
    & En & Fr & Zh & Std. $\downarrow$ \\
    \midrule
    MFCC & 12.1/23.4 & 12.6/25.5 & 11.5/21.3 & - \\
    Sup.$^\dagger$ & 6.2/8.0 & 8.7/10.8 & 7.9/10.3 & - \\
    LL-6K$^\ddagger$ & 4.5/6.2 & 8.4/12.7 & 8.2/8.2 & 1.8/2.7 \\
    \midrule
    % \multicolumn{5}{c}{\vp} \\
    % \midrule
    % 8K & 9.3/13.2 & 11.8/16.1 & 10.1/11.3 & 1.0/2.0 \\
    % \midrule
    \multicolumn{5}{l}{\textit{\vp}} \\
    \midrule
    % En-500 & 7.7/11.2 & 10.9/16.1 & 9.6/11.1 & 1.3/2.3 \\
    En-500 & 6.9/9.9 & 9.6/14.5 & 8.7/9.7 & 1.1/2.2 \\
    % Fr-500 & 9.3/14.0 & 10.4/15.1 & 9.7/11.4 & 0.5/1.6 \\
    Fr-500 & 8.1/12.1 & 9.1/13.8 & 9.2/10.1 &  0.5/1.5 \\
    En+Fr-500 & 6.9/9.8 & 9.0/13.1 & 8.6/9.6 & 0.9/1.6 \\
    \bottomrule
    \end{tabular}
    \caption{\textbf{Phoneme discriminability of unsupervised features across languages.} We report ABX discriminability score on the 10s test set from ZeroSpeech 2017$^\dagger$ for English (``En"), French (``Fr") and Mandarin (``Zh"). We compare our models with the MFCC baseline, the supervised topline and the state-of-the-art monolingual (English) model$^\ddagger$. We measure the generality of the representations by standard deviation (``Std.") of the scores across the 3 languages. We see that multilingual representations generalize better and are more robust on unseen languages. $^\dagger$~\citet{dunbar2017zero}. $^\ddagger$~\citet{riviere2020unsupervised_wild}.}
    \label{tab:zerospeech17}
\end{table}

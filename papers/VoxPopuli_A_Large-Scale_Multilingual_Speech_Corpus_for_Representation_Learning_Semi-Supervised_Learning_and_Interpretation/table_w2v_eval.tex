\begin{table*}[t]
    \centering
    \small
    \tabcolsep=0.16cm
    \begin{tabular}{r@{\hs{1.2}}|c@{\hs{1.2}}c@{\hs{1.2}}c@{\hs{1.2}}c@{\hs{1.2}}|c@{\hs{1.4}}c@{\hs{1.4}}c@{\hs{1.4}}c@{\hs{1.4}}c@{\hs{1.4}}|c@{\hs{1.4}}c@{\hs{1.4}}c@{\hs{1.4}}c@{\hs{1.4}}c@{\hs{1.4}}|c@{\hs{1.2}}c}
    \toprule
    & PT & PT & \multicolumn{2}{c|}{Langs.} & \multicolumn{5}{c|}{PER $\downarrow$ (\vp~Langs.)} & \multicolumn{5}{c|}{PER $\downarrow$ (Other Langs.)} & \multicolumn{2}{c}{PER} \\
    & Domain & Hours & In & Out & Es & Fr & It & Nl & Sv & Ky & Ru & Tr & Tt & Zh & Avg. $\downarrow$ & Std. $\downarrow$ \\
    \midrule
    m-CPC$^\dagger$ & Out & 60K & 0 & 1 & 36.4 & 44.3 & 37.8 & 43.1 & 46.5 & 37.5 & 42.4 & 45.7 & 40.6 & 53.2 & 42.7 & 4.8 \\
    \midrule
    \multicolumn{10}{l}{\textit{wav2vec 2.0 Base (95M)}} \\
    \midrule
    XLSR-Mono$^\ddagger$ & In & $<$0.4K & 1 & 0 & \textbf{6.8} & 10.4 & 10.9 & 37.4 & 63.6 & 29.6 & 11.6 & 44.0 & 21.4 & 31.4 & 26.7 & 17.2 \\
    XLSR-10$^\ddagger$ & In & 1.4K & 10 & 1 & 9.4 & 13.4 & 13.8 & 16.3 & 21.0 & 8.6 & 11.2 & \textbf{11.7} & 8.3 & 24.5 & 13.8 & 5.1 \\
    VP-Mono-5K & Out & 4.5K & 1 & 0 & \textbf{6.8} & \textbf{8.6} & \textbf{7.5} & \textbf{9.7} & \textbf{9.3} & - & - & - & - & - & - & - \\
    VP-10K & Out & 10K & 5 & 18 & 8.5 & 11.9 & 11.0 & 13.6 & 15.0 & 10.9 & 12.4 & 13.1 & 8.8 & 19.3 & 12.5 & 3.0 \\
    VP-100K & Out & 100K & 5 & 18 & 7.6 & 10.3 & 9.7 & 12.2 & 13.0 & 9.4 & \textbf{10.7} & \textbf{11.7} & \textbf{8.0} & \textbf{17.5} & \textbf{11.0} & \textbf{2.7} \\
    \midrule
    \multicolumn{10}{l}{\textit{wav2vec 2.0 Large (317M)}} \\
    \midrule
    XLSR-10$^\ddagger$ & In & 1.4K & 10 & 1 & 7.9 & 12.6 & 11.7 & 14.0 & 20.6 & 7.0 & 9.3 & 9.7 & 7.2 & 22.8 & 12.3 & 5.2 \\
    XLSR-53$^\ddagger$ & In+Out & 56K & 10 & 43 & \textbf{2.9} & \textbf{5.0} & 6.7 & \textbf{5.8} & 12.2 & \textbf{6.1} & \textbf{8.1} & \textbf{7.1} & \textbf{5.1} & 18.3 & \textbf{7.6} & 4.2 \\
    VP-Mono-5K & Out & 4.5K & 1 & 0 & 5.5 & 7.0 & \textbf{6.1} & 7.2 & \textbf{6.3} & - & - & - & - & - & - & - \\
    VP-10K & Out & 10K & 5 & 18 & 6.3 & 8.9 & 7.9 & 9.3 & 9.7 & 9.3 & 9.2 & 11.3 & 7.6 & 18.8 & 9.8 & 3.2 \\
    VP-100K & Out & 100K & 5 & 18 & 5.4 & 7.7 & 6.5 & 8.0 & 8.3 & 8.5 & 8.0 & 9.8 & 6.9 & \textbf{17.3} & 8.6 & \textbf{3.1} \\
    \bottomrule
    \end{tabular}
    \caption{\textbf{Few-shot ASR with out-of-domain out-of-language unsupervised pre-training.} We adopt the Common Voice (CV) few-shot phoneme recognition setup$^\dagger$ and report test PER (phone error rate).
    Our wav2vec 2.0 models are pre-trained on \vp~(out-of-CV-domain) either with 4.5K-hour monolingual data (``VP-Mono-5K") or 10K-hour/100K-hour multilingual data (``VP-10K" and ``VP-100K"). Pre-training languages may include the ones being evaluated (``In") and others (``Out"). Our models outperform XLSR-Mono and XLSR-10 (same architecture as ours but using in-domain CV data) on most languages with out-of-domain and (partially) out-of-language pre-training. Our best model (VP-100K Large) performs competitively to XLSR-53, which leverages 52K-hour out-of-CV-domain data in addition to the CV data. $^\dagger$~\citet{riviere2020unsupervised} $^\ddagger$~\citet{conneau2020unsupervised}}
    \label{tab:cv_eval_per}
\end{table*}
\begin{table}[ht]
    \centering
    \small
    \begin{tabular}{c|c|c|cc|cc}
    \toprule
    \multirow{2}{*}{} & \multirow{2}{*}{Size} & \multirow{2}{*}{LM} & \multicolumn{2}{c|}{Dev} & \multicolumn{2}{c}{Test} \\
    & & & CER & WER & CER & WER \\
    \midrule
    \multirow{6}{*}{De} & \multirow{2}{*}{1h} & No & 16.0 & 61.1 & 17.6 & 63.6 \\
    & & Yes & 17.2 & 49.3 & 15.5 & 45.6 \\
    & \multirow{2}{*}{20h} & No  & 8.96 & 35.6 & 10.4 & 40.1 \\
    & & Yes & 6.99 & 19.5 & 8.45 & 26.7 \\
    & \multirow{2}{*}{314h} & No  & 3.83 & 15.0  & 4.70 &  17.0 \\
    && Yes  & 2.36  & 6.76  & 2.98 &  7.82 \\
    \midrule
    %\multirow{4}{*}{En}& \multirow{2}{*}{1h}& No & \todo{xx.x} & \todo{xx.x} & \todo{xx.x} & \todo{xx.x} \\
    %& & Yes & \todo{xx.x} & \todo{xx.x} \\
    %& \multirow{2}{*}{20h} & No & \todo{xx.x} & \todo{xx.x} \\
    %& & Yes & \todo{xx.x} & \todo{xx.x} \\
    %\midrule
    \multirow{5}{*}{Es} & \multirow{2}{*}{1h} & No & 12.7 & 43.4 & 14.0 & 45.9 \\
    & & Yes & 10.1 & 27.3 & 11.4 & 29.5 \\
    & \multirow{2}{*}{20h} &No  & 7.20 & 24.9 & 7.82 & 25.8 \\
    & & Yes & 5.46 & 15.9 & 6.36 & 17.7 \\
    & \multirow{2}{*}{203h} & No & 3.49 &  10.7 &  4.04 &  11.9  \\
    & & Yes & 3.11  & 8.93 & 3.60 & 10.0 \\
    \midrule
    \multirow{6}{*}{Fr} & \multirow{2}{*}{1h} & No & 22.2 & 64.6 & 24.4 & 70.7  \\
    & & Yes & 21.5 & 57.8 & 23.3 & 60.3 \\
    & \multirow{2}{*}{20h} & No & 11.8  & 38.3 & 13.4 & 41.6 \\
    & & Yes & 10.7 & 30.7 & 12.4 & 33.8\\
    &  \multirow{2}{*}{364h} & No & 4.9 & 16.9 & 5.91 & 18.8  \\
    && Yes & 2.73 & 8.31 & 3.57 & 9.56  \\
    % \midrule
    % \multirow{4}{*}{Pl} & \multirow{2}{*}{1h} & No & 12.6 & 48.9 & 15.0 & 59.2 \\
    % & & Yes & 8.11 & 26.5 & 9.40 & 27.3\\
    % & \multirow{2}{*}{20h} & No & 6.60  & 29.0  & 6.21 & 27.4\\
    % & & Yes & 3.59 & 13.5 & 3.37 & 11.0 \\
    \bottomrule
    \end{tabular}
    \caption{\textbf{ASR with out-of-domain unsupervised pretraining, with various datasets sizes for fine-tuning.} WER (word error rate) and CER (character error rate) results on Common Voice with a limited amount of data for fine-tuning. All models were pretrained on \vp 50k. We used 4-gram LM built out from Common Voice data.}
    \label{tab:ablation_cv}
\end{table}

In our next result, we relax the second order differentiability
condition on $\F$, and in the case $\beta <1$ we even allow for
arbitrary large values of the step size $h$ and the number of iterations $T$.
The result is less quantitative and the proof
is more involved: we use degree theory for continuous
mapping (the main notions  required in the proof are recalled in  \Cref{sec:defin-usef-results}).
\begin{theorem}\label{theo:irred_D}
Let $h > 0$ and $T \in \nsets$ and assume either
\begin{enumerate}[label=(\alph*)]
\item
\label{theo:irred_D_a}
\Cref{assum:regOne} $(\expozero)$ for some $\expozero \in \coint{0,1}$,
%   \begin{equation}
% \lim_{n \to \plusinfty}    \tvnorm{\delta_q \Pkerhmc[h][T]^n - \pi} = 0 \eqsp.
%  \end{equation}`
\item
\label{theo:irred_D_b}
\Cref{assum:regOne} $(1)$ and that  $T \in \nsets$ and $h > 0$ satisfy \eqref{eq:condition-h,T-harris}.
\end{enumerate}
%Moreover, $\Pkerhmc[h][T]$ is .
Then,
\begin{enumerate}[label=(\roman*)]
\item the HMC kernel $\Pkerhmc[h][T]$ defined by \eqref{eq:def_kernel_hmc} is irreducible, aperiodic, the Lebesgue measure is an
  irreducibility measure and any compact set of $\rset^d$ is  small.
\item $\Pkerhmc[h][T]$ is recurrent and for $\pi$-almost every $q \in \rset^d$,
$\lim_{n \to \plusinfty}    \tvnorm{\delta_q \Pkerhmc[h][T]^n - \pi} = 0$.
\end{enumerate}
\end{theorem}

\begin{proof}
The proof is postponed to \Cref{sec:proof-crefth_irred_D}.
\end{proof}


% \alain{put a sentence on the fact that most of HMC versions, the
%   invariance is checked and it is not enough for the convergence of
%   the algorithm}
To the best of the author's knowledge, the first results regarding the
irreducibility of the HMC algorithm are established in
\cite{cances:legoll:stoltz} under the assumption that $\U$ and
$\norm{\nabla \U}$ are bounded above. Note that these assumptions are
in general satisfied only for compact state space. Irreducibility has
also been tackled in
\cite{livingstone:betancourt:byrne:girolami:2016}: in this work
however, the number of leapfrog steps $T$ is assumed to be random and
independent of the current position and momentum. Under this setting
and additional conditions which in particular imply that the number of
leapfrog steps $T$ is equal to $1$ with positive probability,
\cite{livingstone:betancourt:byrne:girolami:2016} shows that the
kernel associated with the HMC algorithm is irreducible. Under this condition,
the proof is  a direct
consequence of the irreducibility of the MALA algorithm - a mixture of
Markov kernels is irreducible as soon as one component of the mixture
is irreducible; the irreducibility of MALA kernel has been established
in \cite{roberts:tweedie:1996}). Finally, \cite[Proposition
3.7]{bou:sanz:2017} shows that RHMC is irreducible under the condition
that $U$ is at least quadratic.  Note that \Cref{theo:irred_D}
establishes irreducibility of HMC of sub-quadratic potential. However,
leap-frog integrator is not numerically stable for lighter than
Gaussian target density, therefore other kind of integrators should be
used instead, see \eg~\cite[Chapter VI]{hairer:wanner:lubish:2002}. %One possibility would be  to consider a taming strategy as
%proposed in

Note that if $\expozero < 1$, then there is no condition in
\Cref{theo:irred_D} on the step-size for HMC to be ergodic. This
conclusion may at first glance be surprising since if $\pi$ is a
$d$-dimensional Gaussian distribution with covariance matrix $\Sigma$,
then the step-size $h$ has to be chosen smaller than
$2/\sqrt{\lambda_{\mathrm{max}}}$, where $\lambda_{\mathrm{max}}$ is
the largest eigenvalues of $\Sigma$, which is also the Lipschitz
constant of the gradient of the associated potential. If a larger
step-size $h$ is used, the leapfrog integrator is unstable, see
\eg~\cite[Example 3.4, Proposition 3.1]{bou-rabee:sanz-serna:2018},
meaning that the iterates of the algorithm diverge. But the Gaussian
distribution satisfies \Cref{assum:regOne}$(\expozero)$ for
$\expozero=1$ strictly.
% This result is however not that
% surprising because of the acceptance/rejection mechanism inherent to
% Metropolis-Hastings schemes: an MCMC algorithm can be (geometrically)
% ergodic whereas the proposal is null or even transient. The most
% straightforward example is the symmetric random walk Metropolis and
% the Metropolis Adjusted Langevin Algorithm (MALA). For the Metropolis
% algorithm, the proposal kernel is a random walk which is null if
% $ d \leq 2$ and transient otherwise. On the other hand, consider a
% target density $\pi$ of the form \eqref{eq:def_density_pi}, where
% $U: \rset^d \to \rset$ is continuously differentiable but with
% $\lim_{\norm{q}} \normLigne{\nabla U(q)}/ \normLigne{q} = \plusinfty$,
% take for example $U(x) = \norm[4]{x}$. Then the Euler Maruyama
% discretization of the Langevin diffusion associated with $U$ is
% unstable (see \cite[Theorem 3.2]{roberts:tweedie:1996}) for all
% discretization step-size but by \cite[Equation
% 9]{roberts:tweedie:1996:biometrika} and \cite[Corollary
% 2]{tierney:1994}, the associated MALA algorithm is Harris recurrent
% for any step-size, hence is ergodic (the $\phi$-irreducibility is all
% what is needed, since the Markov kernel is reversible and therefore
% admits an invariant distribution, which is unique). This former result
% holds for $U(x) = \norm[2]{x}$ for all $x \in \rset^d$ as well. By
% \cite[Theorem 3.1, Theorem 3.2]{roberts:tweedie:1996}, the
% Euler-Maruyama discretization is geometrically ergodic for step-size
% $h < 1/2$ and transient for $h > 1$, whereas MALA in this case is
% Harris recurrent for all discretization step-size $h$ by the same
% arguments as above.
We illustrate on a numerical example that under \Cref{assum:regOne}$(\expozero)$, for $\expozero <1$,
  the \textit{unadjusted} HMC proposal is in fact numerically stable
  and the HMC algorithm does converge for a step-size $h > 2 /
  \sqrt{\constzero}$, where $\constzero$ is the Lipschitz constant of $\nabla U$.
  In this example, we consider the potential $U : \rset \to \rset$ given
  for all $x \in \rset$ by $U(x) = 2 \defEnsLigne{1+\abs{x}^2}^{3/4}$. Then
  $U'(x) = 3(\abs{x}^2 +1)^{-1/4}x$ and is Lipschitz with constant
  $\constzero = 3$. We then run the unadjusted/adjusted HMC algorithm for a
  step-size $h =1.5 > 2/\sqrt{\constzero} \approx 1.15$ and a number of
  leapfrog-step $T =2$.  We can observe in
  \Cref{fig:experiments_convergence} the convergence of the HMC
  algorithm for the test function $f : q \mapsto \abs{q}^2$.
  \Cref{fig:experiments_stability} illustrates that the
  adjusted/unadjusted HMC are numerically stable even if $h =1.5 > 2/\sqrt{\constzero} \approx 1.15$, since the gradient
  is sub-linear.


\begin{figure}[h]
	\begin{center}		
		\includegraphics[width=12.2cm]{convergence_3_4_D}
\end{center}
	\caption{Convergence of the HMC algorithm for $U(x) = 2
  \defEnsLigne{1+\abs{x}^2}^{3/4}$, $h =1.5 > 2/\sqrt{\constzero}$ and $T=2$. The test function is $f : q \mapsto \abs{q}^2$. The red line indicates the real value of $\int_{\rset} f(q) \rmd \pi(q)$ estimated by numerical integration}
	\label{fig:experiments_convergence}
\end{figure}


\begin{figure}[h]
	\begin{center}
	\begin{tabular}{p{0.1cm}cp{0.1cm}c}
&		\includegraphics[width=5.8cm]{trace_plot_HMC_3_4_D}
		& &
		\includegraphics[width=5.8cm]{trace_plot_UHMC_3_4_D}\\
& (a) & & (b)
	\end{tabular}
\end{center}
	\caption{Trace plots for the adjusted (a) / unadjusted (b) HMC algorithm for $U(x) = 2
  \defEnsLigne{1+\abs{x}^2}^{3/4}$, $h =1.5 > 2/\sqrt{\constzero}$ and $T=2$.}
	\label{fig:experiments_stability}
\end{figure}


Finally, note that our results can be easily extended to the case
where the number of steps is random. We briefly describe the main arguments to obtain such
extension.
Let $(\varpi_i)_{i\in \nset^*}$ be a probability distribution on $\nset^*$ and $(h_i)_{i \in \nset^*}$ be a sequence of  positive real
numbers.  Define the randomized Hamiltonian kernel
$\randomkerhmc_{\mathbf{h},\bfvarpi}$ on $(\rset^d, \borelSet(\rset^d))$ associated with $(\varpi_i)_{i\in \nset^*}$ and
$(h_i)_{i \in \nset^*}$ by
\begin{equation}
\label{eq:randomhmc}
\randomkerhmc_{\mathbf{h},\bfvarpi} = \sum_{i\in \nset^*} \varpi_i \Pkerhmc[h_i][i] \eqsp.
\end{equation}
We denote by $\supp(\bfvarpi)= \set{i \in \nset^*}{\omega_i \ne 0}$ the support of the distribution $\bfvarpi$.
\begin{corollary}
  \label{coro:ergod-hmc-algor}
Let $\expozero \in \ccint{0,1}$ and assume \Cref{assum:regOne}($\expozero$).
Let $(\varpi_i)_{i\in \nset^*}$ be a probability distribution on $\nset^*$, $(h_i)_{i \in \nset^*}$ be a sequence of  positive real
numbers, and $\randomkerhmc_{\mathbf{h},\bfvarpi}$ be the randomized Hamiltonian kernel associated with $(\varpi_i)_{i\in \nset^*}$ and
$(h_i)_{i \in \nset^*}$.
\begin{enumerate}[label=(\alph*)]
\item
\label{coro:ergod-hmc-algor_a}
Assume that $\F$ is twice continuously and there exists $i \in \nset^*$ such that   $ [ \{1 + h_i\constzero^{1/2} \vartheta_1( h_i \constzero^{1/2}) \}^i - 1 ] < 1$ and  $\varpi_i > 0$   where $\vartheta_1$ is given by  \eqref{eq:def_vartheta_1}. Then the conclusions  of \Cref{theo:irred_harris}-\ref{theo:irred_harris_c} hold for $\randomkerhmc_{\mathbf{h},\bfvarpi}$.
\item
\label{coro:ergod-hmc-algor_b}
 If $\expozero \in \coint{0,1}$, then the conclusions of \Cref{theo:irred_D}-\ref{theo:irred_D_a} hold for $\randomkerhmc_{\mathbf{h},\bfvarpi}$.
\item
\label{coro:ergod-hmc-algor_c}
 If $\expozero = 1$ and there exists $i \in \supp(\bfvarpi)$ such that  $ [ \{1 + h_i \constzero^{1/2} \vartheta_1(h_i \constzero^{1/2}) \}^i - 1 ] < 1$, then the conclusions of \Cref{theo:irred_D}-\ref{theo:irred_D_b} hold for $\randomkerhmc_{\mathbf{h},\bfvarpi}$.
\end{enumerate}
\end{corollary}

\begin{proof}
  \ref{coro:ergod-hmc-algor_a} follows from \Cref{theo:irred_harris} and \Cref{propo:harris_rec}. \ref{coro:ergod-hmc-algor_b} and \ref{coro:ergod-hmc-algor_c} are straightforward applications of \Cref{theo:irred_D}.
\end{proof}

 % $\mathbb{P}(T=1) >0$ and there exists $s
% >0$ such that for all $q_0 \in
% \rset^d$,$\mathbb{E}[\rme^{s\Phiverletq[h][T](q_0,p_0)}]< \plusinfty$,
% where $\Phiverletq[h][T]$ is defined in \eqref{eq:def_Phiverletq} and
% $p_0$ is a standard Gaussian random variable, .

% Note that by \cite[Theorem 14.0.1]{meyn:tweedie:2009}, under
% \Cref{assum:regOne}($\expozero$) for $\expozero \in \coint{0,1}$,
% \Cref{theo:irred_D} implies that for all $T \in \nset^*$ and $h >0$, for
% $\pi$-almost every $q \in \rset^d$,
%   \begin{equation}
% \lim_{n \to \plusinfty}    \tvnorm{\delta_q \Pkerhmc[h][T]^n - \pi} = 0 \eqsp.
%   \end{equation}

% \begin{corollary}\label{co:irr}
% Assume  \Cref{assum:regOne} $(\expozero)$.
% \begin{enumerate}[label=(\alph*)]
% \item
% \label{item:co:irr_1}
% If $\expozero \in \coint{0,1}$ for all $h>0$ and $T \in
%   \nset^*$, $\Pkerhmc[h][T]$ is irreducible with respect to the Lebesgue
%   measure and therefore is ergodic: for all $x \in \rset^d$,
%   \begin{equation}
% \lim_{n \to \plusinfty}    \tvnorm{\delta_x \Pkerhmc[h][T]^n - \pi} = 0 \eqsp.
%   \end{equation}
% \item
% \label{item:co:irr_2}
% If $\expozero = 1$, there exists $\hirr>0$ such that for all $h \in \ocintLigne{0,\hirr}$ and $T \in \nset^*$, $\Pkerhmc[h][T]$ is irreducible with respect to the Lebesgue  measure and therefore is ergodic.
% \end{enumerate}
% \end{corollary}

% \begin{proof}
%   It is a direct consequence of \Cref{pr:small} and \cite[Corollary 2]{tierney:1994}.
% \end{proof}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:

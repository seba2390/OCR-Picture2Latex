\section{Introduction}\label{s:intro}

In the past few years there has been a renaissance of messaging
  systems~\cite{angel16unobservable, vandenhoof15vuvuzela, lazar16alpenhorn, 
  kwon17atom, tyagi17stadium, alexopoulos17mcmix} that allow users to 
  communicate online without their messages being observed by ISPs, companies, 
  or governments.
These systems target a property called metadata-privacy which is
  stronger than end-to-end encryption: encryption hides the content of 
  messages but it does not hide their existence nor any of their associated 
  metadata (identity of the sender or recipient, frequency, time,
  and duration of communication, etc.).
While hiding metadata has been the subject of a long line of work 
  dating back three decades~\cite{chaum81untraceable}, there is renewed 
  interest due to a proliferation of controversial surveillance 
  practices~\cite{guardian13nsa, intercept14new, guardian15gchq,
  eff15dragnet, tor15cmu}, and the monetization of users' private 
  information~\cite{wired12shady, cnet12facebook, forbes13att, reuters16yahoo}.

Existing metadata-private messaging (MPM) systems guarantee that as 
  long as the sender and the recipient of a message are not compromised, their 
  communication cannot be observed by an adversary (the adversary 
  learns that users are part of the system, but not whether they communicate).
If either the sender or the recipient is compromised, MPM systems
  provide no guarantees (e.g., a compromised sender could trivially 
  disclose to whom it is sending a message).
In this paper we investigate whether an adversary---by 
  compromising and leveraging a user's friends---can learn anything about 
  the user's \emph{other} ongoing communications.

At first glance the answer to the above question appears to be no (assuming 
  that the user does not voluntarily disclose the existence of other 
  communications to compromised friends).
After all, the guarantees of MPM systems 
  should prevent the adversary from learning anything about 
  conversations between uncompromised clients.
Nevertheless, we find that this is not actually the case: engaging in 
  a conversation with a compromised client consumes a limited resource, namely
  the number of concurrent conversations that a user can support.
By observing a client's responses (or lack thereof), a compromised friend can 
  learn whether the user has fully utilized this limited resource (i.e., the 
  user is busy talking to others).
In Section~\ref{s:attack} we show how this one bit of information enables 
  existing intersection and disclosure attacks~\cite{raymond00traffic, agrawal03disclosure, 
  kesdogan04hitting, kesdogan09breaking, danezis03statistical, mallesh10reverse, 
  troncoso08perfect,danezis09vida, danezis04statistical, danezis07two, 
  perezgonzales12understanding} that
  invalidate MPM systems' guarantees.

More interestingly, our \emph{compromised friend attack} applies to all 
  MPM systems that support a notion of 
  \emph{dialing}~\cite{lazar16alpenhorn} (or any 
  other mechanism that allows clients to start new conversations over time).
We give a formal characterization of the attack with a scenario that
  we call the \emph{exclusive call center problem}, which abstracts away
  the design or implementation of MPM systems.
We then introduce a primitive called a \emph{private answering
  machine} that solves the abstract problem and can be used
  by clients of MPM systems to prevent the compromised friend attack.
In particular, clients use a private answering machine 
  to select with which friends to communicate, while guaranteeing that 
  compromised friends learn no information about other ongoing communications.

Unfortunately, building a cryptographically-secure private 
  answering machine that does not require placing assumptions on the
  number of callers (i.e., the number of friends that a user can have) or 
  incurring prohibitive delay or bandwidth appears hard.
We compromise on this point and give a construction that 
  can be used by MPM systems under the assumption that users can place a
  bound on their maximum number of friends.
Our construction has two limitations: (1) it leaks the bound chosen by the 
  user, and (2) it increases the latency of communication between a 
  pair of users proportional to the chosen bound.
Despite these limitations, our work addresses a previously overlooked attack 
  and allows users in MPM systems to communicate without 
  leaking sensitive information. 

In summary, the contributions of this work are:
\begin{myitemize}

\item An abstraction that captures the leakage 
  from oversubscribing a fixed resource in the presence of
  adversarial probing~(\S\ref{s:problem}). 

\item The \emph{compromised friend attack} which exploits the fixed 
  communication capacity of MPM systems~(\S\ref{s:attack}).

\item The construction of a private answering machine~(\S\ref{s:solutions:bounded}) 
  that can be used in MPM systems to avoid leaking information
  to compromised friends about users' other ongoing conversations~(\S\ref{s:defense}).

\end{myitemize}

\section{Mitigation strategies}\label{s:defense}

We now discuss ways in which MPM systems could prevent a CF attack.
One option is for clients to use a private answering machine such as $M_3$ 
  (\S\ref{s:solutions:bounded}) to determine which of the new (or existing) 
  conversations to accept (or continue) without leaking information.
Clients would continue to exchange $k$ messages per round, but only a subset 
  of these messages (based on the output of $M_3$) would correspond to 
  actual conversations; the rest would act as cover traffic.
Note that with $M_3$, a compromised friend can learn how many other
  friends a user has, or at least an upper bound on it (i.e., $|\mathbb{C}|$).
Furthermore, $M_3$ accepts messages from a particular friend for a
  sliding window of $k$ rounds, so it is possible for two users' sliding windows 
  to never intercept.
As a result, if the MPM system does not allow the retrieval of messages
  from previous rounds, clients would be unable to communication without
  additional mechanisms.

In principle, when using $M_3$, we could set $\mathbb{C}$ to be all users in 
  the system rather than just a client's friends (so the adversary learns no 
  information); $M_3$'s function $id$ could be computed with a 
  collision-resistant hash function.
Provided that the number of total users ($n$) is $poly(\lambda$), this would 
  technically meet our liveness requirement (Definition~\ref{def:liveness}). 
In practice, however, this would result in a client accepting a call from a 
  given friend every $k$ out of $n$ rounds, which is a prohibitive delay 
  when $n$ is large.

The alternative to using a private answering machine is for clients to 
  set their communication capacity ($k$) to a value larger than their 
  maximum number of friends (under the assumption that each pair of friends 
  exchanges at most one message per round).
This too would leak the bound on the number of friends of a given client.
If a client wishes to keep this information private, a client could set $k$ to 
  be the total number of users in the system.
While this would leak no information, the communication and computational 
  costs of existing MPM systems increase linearly with $k$ (though some 
  systems have sublinear computational costs~\cite{angel16unobservable}), 
  making it prohibitive for systems with many users.
More worryingly, several MPM systems~\cite{tyagi17stadium, vandenhoof15vuvuzela} 
  provide guarantees that are based on differential privacy, and increasing
  the number of concurrent conversations ($k$) accelerates the consumption of 
  users' privacy budgets.

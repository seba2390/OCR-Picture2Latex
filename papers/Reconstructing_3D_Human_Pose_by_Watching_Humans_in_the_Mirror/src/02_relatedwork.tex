\begin{figure*}[t]
	\centering
	\includegraphics[width=1\linewidth,trim={0cm 0cm 0cm 0.5cm},clip]{figures/overview_comp.pdf}
	\vspace{-0.8cm}
	\caption{\textbf{Overview of our approach.} Given the input image (a), we first estimate the 2D keypoints and SMPL parameters as the initialization (b). Then, we minimize the reprojection error with mirror symmetry constraints for reconstruction (c). We collect a considerable number of Internet images (d) and build a dataset named Mirrored-Human (e) with pseudo ground-truth generated by our framework. The dataset can be used for the training of single-view methods.}
	\label{fig:method}
\end{figure*}

\subsection{3D human pose}
Benefiting from neural networks, the task of monocular 3D human pose estimation has made considerable progress. The skeleton-based approaches either lift the 2D pose to 3D~\cite{martinez_2017_3dbaseline, chen20173d, wandt2019repnet}, or adopt an end-to-end manner to regress the 3D pose directly from the image~\cite{sun2017compositional, sun2018integral, zhou2017towards, pavlakos2018ordinal}. The model-based approaches estimate the pose and shape simultaneously with parametric models~\cite{anguelov2005scape, SMPL:2015, STAR:2020, xu2020ghum}. Approaches along this line can be divided into two categories. Optimization-based methods fit the model using 2D evidence and some human body priors~\cite{Bogo:ECCV:2016, Lassner:UP:2017, SMPL-X:2019, dong2020motion}. Regression-based methods directly regress the model parameters from the image~\cite{hmrKanazawa17, omran2018nbf, xu2019denserac, humanMotionKanazawa19, zeng20203d}. Kolotouros~\etal~\cite{kolotouros2019spin} incorporate their advantages and propose a self-improving framework. To relax the heavy reliance on the model's parameter space, model-free approaches directly regress the 3D locations of the mesh vertices ~\cite{kolotouros2019cmr, Moon_2020_ECCV_I2L-MeshNet,Choi_2020_ECCV_Pose2Mesh}. For multi-person cases, previous works focus on how to extend single-person frameworks to multi-person ones~\cite{rogez2019lcr, mehta2019xnect} or model the interaction between people~\cite{zanfir2018monocular, fieraru3d}. Some recent works~\cite{Moon_2019_ICCV_3DMPPE, zhen2020smap, li2020hmor, lin2020hdnet, fabbri2020compressed} explore the representation of the absolute depth in the camera coordinate system.

In monocular settings, the depth ambiguity is inevitable. One solution is to utilize the additional supervision signal. Pavlakos \etal \cite{pavlakos2018ordinal} use the ordinal depths of human joints to weakly supervise the network. Kanazawa \etal \cite{hmrKanazawa17} train a discriminator network to judge if the estimated pose is reasonable. Some other works use temporal constraints \cite{kocabas2019vibe, tripathi2020posenet3d, peng2021neural} or geometric self-consistency \cite{chen2019unsupervised}.
Another line of work resolves the ambiguity with scene layouts. Hassan \etal \cite{PROX:2019} exploit static 3D scene structures with the inter-penetration and the contact constraints. Others \cite{mehta2019xnect, zanfir2018monocular} integrate the ground plane information to recover the 3D location and pose. We use the additional view provided by the mirror reflection to resolve the depth ambiguity.

Learning-based methods are inseparable from the training data. Existing widely-used 3D datasets such as Human3.6M~\cite{h36m_pami}, Human Eva~\cite{Sigal:IJCV:10b}, 
MPI-INF-3DHP~\cite{mono-3dhp2017} and Panoptic Studio~\cite{Joo_2017_TPAMI} are built with motion capture systems and thus have limited appearance and pose diversity. 3DPW~\cite{vonMarcard2018} is a recent dataset consisting of ordinary activities. The combination of a camera and several IMUs attached to the human body provides accurate 3D poses, but the dataset still lacks diversity. Kanazawa~\etal~\cite{humanMotionKanazawa19} contribute some Internet datasets which however lack 3D annotations. Arnab~\etal~\cite{Arnab_CVPR_2019} propose a bundle-adjustment-based algorithm, based upon which they generate 3D annotations for Internet data. However, this method still suffers from the depth ambiguity derived from monocular videos. To summarize, a \textit{large-scale} \textit{Internet} dataset with \textit{3D annotations} is still missing. We collect numerous Internet images containing mirrors and people with a large diversity in appearances and poses, and build a dataset using our reconstructed 3D poses as pseudo ground-truth, to address this problem to some extent.

\subsection{Reconstruction with mirrors}
Earlier years have witnessed some researches on the mirror geometry of a catadioptric system (mirrors + lenses), especially for reconstruction and extrinsic camera calibration~\cite{takahashi2012, rodrigues2010}. For 3D reconstruction that is more relevant to our task, some works use the configuration of two planar mirrors to capture stereo images~\cite{nene1998, gluckman2001catadioptric, tahara2015interference, lanman2009surround} or produce four virtual views by assuming there is a one-time interreflection between two mirrors~\cite{ying2012self}. They calibrate the mirror based on the image correspondences or silhouettes. Nguyen~\etal~\cite{nguyen20183d} use a depth sensor and at least two mirrors, trying to remove depth distortions. Akay~\etal~\cite{akay2014} reconstruct 3D object with a mirror and RGBD cameras. Hu~\etal~\cite{Hu2005MultipleView3R} only use one mirror and one RGB camera, but they need to label the object and mirror region. To the best of our knowledge, the task of exploiting mirror symmetry to recover 3D human pose and shape from an Internet image has not been discussed in literature. 

Furthermore, not only does the symmetry property exist in scenes with mirrors, but it also appears on symmetrical objects, which has been explored to reconstruct faces, cars, etc. Some works ~\cite{sinha2012detecting, jiang2009symmetric} explicitly detect the plane of symmetry with 2D correspondences and others~\cite{Wu_2020_CVPR} implicitly use the symmetry prior.








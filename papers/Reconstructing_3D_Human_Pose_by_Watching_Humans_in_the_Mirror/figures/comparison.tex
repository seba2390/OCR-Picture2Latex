\begin{figure*}[!ht]
	\begin{center}
    	\includegraphics[width=0.48\linewidth, trim=0 30 270 50,clip]{figures/qualitative/0.pdf}
    	\includegraphics[width=0.48\linewidth, trim=0 30 270 50,clip]{figures/qualitative/1.pdf}
    	\includegraphics[width=0.48\linewidth, trim=0 80 270 80,clip]{figures/qualitative/2.pdf}
    	\includegraphics[width=0.48\linewidth, trim=0 80 270 80,clip]{figures/qualitative/3.pdf}
	\end{center}
	\vspace{-5mm}
	\footnotesize{\hspace{6mm}\text{Input Image}\hspace{6mm}\text{SMPLify-X\cite{SMPL-X:2019}}\hspace{6mm}\text{SPIN\cite{kolotouros2019spin}}\hspace{13mm}\text{Ours}\hspace{12mm}\text{Input Image}\hspace{6mm}\text{SMPLify-X\cite{SMPL-X:2019}}\hspace{6mm}\text{SPIN\cite{kolotouros2019spin}}\hspace{13mm}\text{Ours}}
	\vspace{2mm}
	\caption{\textbf{Qualitative comparison of 3D pose estimation.} For each image, we show the results of the person estimated by the optimization-based method SMPLify-X~\cite{SMPL-X:2019} (red), the CNN-based method SPIN~\cite{kolotouros2019spin} (green) and our method (blue). For each block, top row shows the predicted mesh from the camera view and the bottom row shows another view. The circles emphasize some representative differences among three methods. The single-view optimization-based method produces inaccurate 3D poses despite smaller reprojection error. Our method produces more accurate 3D outputs given the same input.}
	\label{fig:comparisonpose}
	\vspace{-1cm}
\end{figure*}
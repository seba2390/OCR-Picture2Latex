\section{Background}

In this section we present essential background \cite{YN} for our solution of the problem discussed.
To start a strategic form game $\Gamma$ is a tuple $(N, (A_i)_{i \in N}, (u_i)_{i \in N})$. Here 
\begin{itemize}
    \item $N=\{1,2,\cdots,n\}$ denotes a finite set of players. 
    \item $A_{1},A_{2},\cdots,A_{n}$ are the strategy/action sets of the players. 
    \item $u_{i}:A_{1} \times A_{2}\times \cdots A_{n} \rightarrow \mathbb{R}, \forall i \in N$, denote utility functions of the players. 
\end{itemize}
Let $A \coloneqq A_{1} \times A_{2}\times \cdots A_{n}$ denote the set of strategy vectors. A typical strategy vector is $(a_{1},a_{2},\cdots,a_{n})$ where $a_{i}$ denotes the strategy of player $i.$ Also denote by $A_{-i}$, the Cartesian product $A_{1} \times \cdots \times A_{i-1} \times A_{i+1} \times \cdots A_{n}$. Therefore $A_{-i}$ is the set of strategy vectors that consists of strategies of all players other than $i$ and a typical strategy vector is of the form $(a_{1},a_{2},\cdots,a_{i-1},a_{i+1},\cdots,a_{n})$. Moreover $(a_{i},a_{-i})$ is a complete strategy vector for the game.
\par
Given a strategic form game $\Gamma=(N, (A_i)_{i \in N}, (u_i)_{i \in N})$ and a strategy vector $a_{-i} \in A_{-i}$, we call $a_{i} \in \arg\max_{a'_{i} \in A_{i}} u_{i}(a'_{i},s_{-i})$, a best response strategy of player $i$ given $a_{-i}.$ In simple terms, $a_{i}$ is a strategy that maximizes player $i$'s utility given the strategies of all other players in the game.
\par
Given a strategic form game $\Gamma=(N, (A_i)_{i \in N}, (u_i)_{i \in N})$, a strategy vector $a^{*}=(a^{*}_{1},a^{*}_{2},\cdots,a^{*}_{n})$ is called a pure strategy Nash equilibrium of $\Gamma$ if 
$$u_{i}(a^{*}_{i})=\max_{a_{i}\in A_{i}}u_{i}(a_{i},a^{*}_{-i}) ~ \forall i \in N.$$
In simple terms, in a strategy vector that is a Nash equilibrium every player has best response strategy given strategy vector of all other players.

It is important to note that Nash equilibrium is self-enforcing i.e., on the condition that every player other than player $i$ chooses his/her strategy in Nash equilibrium then player $i$ is better off with the strategy in Nash equilibrium. In other words Nash equilibrium secures cooperation among players.

In summary unilateral deviations from Nash equilibrium ensure detrimental payoff for the deviate. In a two-player game since there are only unilateral deviations of Nash equilibrium it is ideal that the second player play Nash equilibrium strategy on the condition that the first player plays Nash equilibrium strategy.


% \par
% An extensive form game $\Gamma$ is a tuple $(N,(A_{i})_{i \in N}, \mathbb{H}, P,(\mathbb{I}_{i})_{i \in N},(u_{i})_{i \in N}).$ Here
% \begin{itemize}
%     \item $N=\{1,2,\cdots,n\}$ is a finite set of players
%     \item $A_{i} ~ \forall i \in N$ is the set of actions available to player $i$
%     \item $\mathbb{H}$ is the set of all terminal histories where a terminal history is a path of actions from the start of the game to the end of the game such that it is not a proper sub history of any other terminal history. We denote by $S_{\mathbb{H}}$ the set of all proper sub histories of all terminal histories
%     \item $P:S_{\mathbb{H}} \rightarrow N$ is a player function that associates each proper sub history to a certain player
%     \item $\mathbb{I}_{i} ~ \forall i \in N$ is the set of all information sets of player $i$
%     \item $u_{i}: \mathbb{H} \rightarrow \mathbb{R} ~ \forall i \in N $ gives the real valued utility of player $i$ corresponding to each terminal history in $\mathbb{H}$
% \end{itemize}
% Given an extensive form game $\Gamma=(N,(A_{i})_{i \in N},\mathbb{H},P,(\mathbb{I}_{i})_{i \in N},(u_{i})_{i \in N})$, a strategy vector $s^*=(s^*_{1},s^*_{2},\cdots,s^*_{n})$ is called a pure strategy Nash equilibrium if $\forall i \in N,$
% $$u_{i}(O(s^*_{i},s^*_{-i}))\geq u_{i}(O(s^*_{i},s^*_{-i})) ~ \forall s_{i} \in S_{i},$$
% where $S_{i}$ is the set of all strategies of player $i, i\in N$ and $O(.)$ denotes the outcome corresponding to a strategy profile. 
% Given an extensive form game $\Gamma$ and a strategy vector $s=(s_1,s_2,\cdots,s_{n})$ in the game, the outcome resulting out of the terminal history corresponding to the strategy profile $s$ is called the outcome of $s$ and is denoted here as $O(s).$
% 
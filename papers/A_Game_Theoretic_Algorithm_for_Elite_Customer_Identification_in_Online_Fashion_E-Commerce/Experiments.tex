\section{Experiments}
We evaluated our algorithm on historical real world e-commerce data available at Myntra. We note two types of error in our classification. We classify a customer as elite and the customer doesn't comply, we call them as false-positives (fp). We call as false-negatives (fn) all those customers that are not elite but comply. Similarly we define true-positives (tp) and true-negatives (tn) in an analogous manner. With these definitions in place we compute precision and recall and evaluate our algorithm

We choose the day October 2, 2020 to evaluate our algorithm. We obtained for each customer that placed a return request on the Myntra platform on this day the repetition probability estimate and also product return compliance status of the customer in the past 9 months. We classified the customer according to Algorithm \ref{alg:Classify}

Our emphasis is on false-positives as it impacts returned product resale value. Hence we aim to maximize precision with a satisfactory recall. We note here that precision is given by $\frac{tp}{tp+fp}$ and recall is given by $\frac{tp}{tp+fn}$.

We compared our algorithm against classification algorithms like logistic regression and random forests. For these algorithms some of the important features are summarised in Table \ref{features}. We note that our algorithm has better recall compared to logistic regression and random forests and all algorithms report close to perfect precision. We summarise the comparison in Table \ref{exp:analysis}

We note that our algorithm is similar to a decision tree. Here, unlike splitting of a node in a classical decision tree, we split the node based on equilibrium strategy given by the game. Hence it may be possible to fine tune hyper parameters of ensemble classification algorithms, for e.g., of random forests to achieve better performance. However unlike these classification algorithms our algorithm is easily explainable- it is easy to see the conditions under which a customer is elite, a desirable feature for businesses in the context of customer experience. In summary, the classification algorithm based on game theory methodologies achieves desired precision with a satisfactory recall and has the additional advantage of explainability.

\begin{table}[ht]
\centering
\begin{tabular}{|l|l|l|l|}
\hline
          & Our  & Logistic & Random \\
          & Algorithm & Regression & Forests \\ \hline
Precision & \textbf{99.7\%}              &     99.7\%                &    99.6\%        \\ \hline
Recall    & \textbf{59.0\%}            &     48.4\%            &   57.8\%            \\ \hline
\end{tabular}
\caption{Comparison of our classification algorithm}
\label{exp:analysis}
\end{table}


\begin{table}[ht]
\centering
\begin{tabular}{|l|l|}
\hline
\textbf{Features}                & \textbf{Description}                                                                 \\ \hline
\#Q2                         & No. of compliance failures \\
                            & in last 9 months by customer                                                                       \\ \hline
\#Q1                       & No. of compliance successes \\
                            & in last 9 months  by customer                                               \\ \hline
nserves          & No. of times the \\ 
                    & returned product is served by Myntra                                       \\ \hline
$\delta$                   & Estimated probability of \\
                            & repetition of the game                                                           \\ \hline
l\_status             & Compliance state of \\ 
                        & last return request by customer                                          \\ \hline
\end{tabular}
\caption{Important features of the classification algorithms}
\label{features}
\end{table}

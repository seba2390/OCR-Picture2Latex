\begin{table}[t]
    % \centering
    % \small 
    \resizebox{\linewidth}{!}{
    \begin{tabular}{p{1.5cm}p{2cm}p{1cm}p{1.8cm}p{1.8cm}}
    \toprule
       \centering\textbf{Train On} & \textbf{Method}  & \textbf{IID$\downarrow$} &  \textbf{OOD avg.$\downarrow$}  & \textbf{ADV avg.$\downarrow$}\\
        \midrule
        
        \multirow{6}{*}{SQuAD} 
        & \textbf{MaxProb} & \underline{6.71} & \underline{46.73} & 33.69 \\ 
         & MCD lite & 6.06 & 44.56 & 33.34 \\ 
         & MCD  & \textbf{6.00} & \textbf{\colorbox{green}{44.35}} & 33.05 \\ 
        %  & LS & - & - & - \\ 
        & Calib C & 6.15 & 45.93 & 33.27 \\ 
        & Calib R & 6.25 & 45.94 & 33.18 \\ 
        & Calib T & 14.72 & 60.31 & 47.87 \\ 
        
         
    \bottomrule
    \end{tabular}
    }
    \caption{
    Comparing selective prediction performance (AUC of risk-coverage curve) of various approaches for QA datasets. 
    Lower AUC is better in SP. 
    MaxProb baseline scores are \underline{underlined}, best performance is in \textbf{bold}, and scores that considerably outperform MaxProb are \colorbox{green}{highlighted}.
    }
    \label{tab:QA_SP_perf}
\end{table}
\section{Motivation and Background} \label{Motivation}
\subsection{Motivation}
Different applications have different resource constraint with respect to CPU, memory, and bandwidth usage. Having a single resource manager for all existing resources and users in the system result in inefficiencies since it is not scalable and the operating system may not have enough information about application's needs. For example, traditional LRU-based cache strategy uses cache utilization as a metric to give larger cache size to the applications which have higher utilization and lower cache size to the applications with lower cache utilization. However more cache utilization does not always result in better performance. Streaming applications for example have very high cache utilization, but very small cache reuse. In fact, the streaming applications only need a small cache space to buffer the streaming data. With rapid improvements in semiconductor technology, more and more cores are being embedded into a single core and managing large scale application using a single resource manager becomes more challenging. \\
%\indent Even if the applications are forced to announce their resource demand, it is possible that they lie about their resource vector or run some useless instructions to pretend to utilize the allocated resources given to them.
\indent In addition, defining a single fairness parameter for multiple applications is non-trivial since applications have different bottlenecks and may get different performance benefits from each resources during each phases of its execution time. Defining a single reasonable parameter for fairness is somewhat problematic. For instance, simple assignment algorithms which try to equally distribute the resources between all applications ignores the fact that different applications have different resource constraints. As a consequence, this makes the centralized resource management systems very inefficient in terms of fairness as well as performance needs of applications. We need a decentralized framework, where all applications' performance benefit could be translated into a unique notion of fairness and performance objective (known as utility function in economics) and the algorithm tries to allocate resources based on this translated notion of fairness. This translation has been well defined in economics and marketing, where the diversity of customer needs, makes more economically efficient market \cite{zhou2014sharing}.\\
\indent Economists have shown that in an economically efficient market, having diverse resource constraints and letting the customers compete for the resources can make a Nash equilibrium where both the applications and the resource managers can be enriched. \\
\indent Furthermore, applications' demand changes over time. Most resource allocation schemes pre-allocate the resources without considering the dynamism in applications' need and number of users sharing the same resource over time. Therefore, applications' performance can degrade drastically over time. Figure~\ref{fig:Phases} shows phase transitions for instruction per cycle (IPC) of mcf application from \textit{spec 2006} over 50 billion instructions. \\ 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[!tb]
\centering
%\includegraphics[height=3in, width=1.5in]{NodeArchs2.pdf}
\includegraphics[height=1.5in, width=3.3in]{Images/Phases_May.pdf} %Phases.pdf
%\epsfig{file=Dataset.eps, height=2.5in, width=3in}
\caption{\label{fig:Phases}Phase transition in mcf with different L2 cache sizes.}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\indent We try to find a game-theoretic distributed resource management approach where the shared hardware resources are exposed to the applications and we will show that running a repeated auction game between different applications which are assumed to be rational, the output of the game would converge to a balanced Nash equilibrium allocation. In addition, we will compare the convergence time of the proposed algorithm in terms of dynamism in the system. We will evaluate our model with two case studies: 1- Private and Shared last level cache problem, where the applications have to decide if they would benefit from a larger cache space which can potentially get more congested or a smaller cache space which is potentially less congested. Based on the number of other applications in the system the application can change its strategy over the time. 2- Heterogeneous processors (\textit{Intel Xeon} and \textit{Xeon Phi}) problem, where we perform experiments to show how congestion affects the performance of different applications running on an \textit{Intel Xeon} or \textit{Xeon Phi} co-processors. Based on the congestion in the system the application can offload the most time consuming part of its code on \textit{Xeon Phi} co-processors or not.   
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Background}
%Congestion games have been studied in network routing protocols where the delay of each player choosing a path in the network depends on the number of players choosing the same route in the system. 
%Every congestion game is a potential game since there exists a potential function associated with it. In addition, every congestion game has a pure-strategy Nash equilibrium. A key assumption in congestion games is that all users have the same impact on the congestion. However, this assumption is not always true. In case of computer architecture resources, applications effect each other differently and dividing the pay-off function by the number of users running on the shared resource does not give us the correct utility. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Game theory has been used extensively in economics, political and social decision making situations \cite{tootaghaj2011game, tootaghaj2011risk, kotobi2017spectrum, kotobi2015introduction, kesidis2013distributed, kurve2013agent, wang2017using, wang2015recouping}. A game is a situation, where the the output of each player not only depends on her own action in the game, but also on the action of other players \cite{osborne1994course}. Auction games are a class of games which has been used to formulate real world problems of assigning different resources between $n$ users. Auction game framework can model resource competition, where the payoff (cost) of each application in the system is a function of the contention level (number of applications) in the game.\\
\indent Inspired by market-based interactions in real life games, there exists a repeated interaction between competitors in a resource sharing game. Assuming large number of applications, we show that the system gets to a Nash equilibrium where all applications are happy with their resource assignment and don't want to change their state. Furthermore, we show that the auction model is strategy-proof, such that no application can get more utilization by bidding more or less than the true value of the resource. In this paper we propose a distributed market based approach to enforce cost on each resource in the system and remove the complexity of resource assignment from the central decision maker.\\ 
\indent The traditional resource assignment is performed by the operating system or a central hardware to assign fair amount of resources to different applications. However, fair scheduling is not always optimal and solving the optimization problem of assigning $m$ resources between $n$ users in the system is an integer programming which is an NP-hard problem and finding the best assignment problem becomes computationally infeasible. Prior works focus on designing a fair scheduling function that maximizes all application's benefit \cite{zahedi2014ref, llull2017cooper, ghodsi2011dominant, zahedi2015sharing, fan2016computational}, while applications might have completely different demands and it is not possible to use the same fairness function for all. By shifting decision making to the individual applications, the system becomes scalable and the burden of establishing fairness is removed from the centralized decision maker, since individual applications have to compete for the resources they need. Applications start with the profiling utility functions for each resource and bid for the most profitable resource. During the course of execution time they can update their belief based on the observed performance metrics at each round of the auction. The idea behind updating the utility functions is that the history at each round of decision point shows the state of the game. This state indicates the contention on the current acquired resource. The pay-off function in each round depends on the state of the system and on the action of other applications in the system. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Sequential Auction}
Auction-based algorithms are used for maximum weighted perfect matching in a bipartite graph $G=(U,V, E)$ \cite{bertsekas1998network, kyle1985continuous, vasconcelos2009bipartite}. A vertex  $U_i \in U$ is the application in the auction and a vertex $V_j \in V$ is interpreted as a resource. The weight of each edge from $U_i$ to $V_j$ shows the utility of getting that particular resource by $U_i$. The prices are initially set to zero and will be updated during each iteration of the auction. In sequential auctions, each resource is taken out by the the auctioneer and is sequentially auctioned to the applications, until all the resources are sold out.
\subsubsection{Parallel Auction}
In a parallel auction, the applications submit their bids for the first most profitable item. The value of the bid at each iteration is computed based on the difference of the highest profitable object and the second highest profitable object. The auctioneer would assign the resources based on the current bids. At each iteration, the valuation of each resource is updated based on the observed information during run-time which shows the contention on that particular resource.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{CAGE: A Market-based Contention-aware Game-theoretic resource assignment}\label{Problem_definition}
\subsection{Model Description}
Consider $n$ applications and $i$ instances of $m$ different resources. Applications arrive in the system one at a time. The applications have to choose among $m$ resources. There exists a bipartite graph between the matching of the applications and the resources.\\
\indent In general, there can be more than one application to get a shared resources. However, each application can not get more than one of the available heterogeneous resources. For example, if we have two cache space of 128kB (one way) and 256kB (two ways), the application can either get the 128kB of cache space or 256kB and can't get both of them at the same time. Furthermore, each resource $m_i$ has a cost $C_i$ which is defined by the applications' bid in the auction. \\
\indent Figure~\ref{fig:auction} shows auction-based framework to support \textit{CAGE} between $N$ applications that execute together competing for $M$ different resources. Each application has a utility table that shows how much performance it gets from each $M$ resources at each time slot. Based on the utility tables, applications submit bids for the most profitable resource. Based on the submitted bids, the auctioneer decides about the resource assignment for each resource, and updates the prices. Next, the applications who did not get any assignment compete for the next most profitable resource based on the updated prices repeatedly until all applications are assigned.  Figure~\ref{fig:auction} shows an example of a resource assignment and the corresponding bipartite graph.
%Table~\ref{table:notation} shows the notation used in our formulation.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\begin{table}[!tb] 
\centering
\caption{Notation used in our formulations.}\label{Table:notation}
\begin{tabular}{|p{0.7in}||p{2.3in}|} 
\hline $N$ & Number of applications \\
\hline $K$ & Number of cache levels \\
\hline $T$ & Time intervals where the bidding is hold \\
\hline $m$ & Number of applications which can get a resource \\ 
\hline $p$ & Number of phases for each application during its course of execution time \\ 
\hline $n$ & Number of applications competing for a specified resource \\
\hline $M$ & Number of resources \\
\hline $P_i$ & Number of phases for application $i$ \\
\hline $\delta$ & dynamic factor that shows how much we can rely on the past iterations. \\
\hline $U$ & The applications which shows the left set of nodes in the bipartite graph. \\
\hline $V$ & The resources which shows the right set of nodes in the bipartite graph. \\
\hline $E$ & The edges in the bipartite graph. \\
\hline $G=(U,V,E)$ & A bipartite graph showing the resource allocation between the applications and the set of resources. \\
\hline $b_{i,k}$ & User i's bid for k th resource \\
\hline $B_i$ & The total budget (sum of bids) a user have \\
\hline $C_k$ & The total capacity of each resource \\
\hline $p_{j}$ & The price of resource $j \in V$ in the auction. \\
\hline $Bottleneck_{1,i}$ & The first bottleneck resource for application $i$ \\
\hline $Bottleneck_{2,i}$ & The second bottleneck resource for application $i$ \\
\hline $v_{i,m}(T)$ & The valuation function of application $i$ for resource $m$ at time $T$ \\
\hline
\end{tabular}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}[!htb]
\centering
%\includegraphics[height=3in, width=1.5in]{NodeArchs2.pdf}
\includegraphics[height=3.2in, width=6.5in]{Images/Auction_v2.pdf} %[height=4in, width=8in]
%\epsfig{file=Dataset.eps, height=2.5in, width=3in}
\caption{\label{fig:auction} Framework for auction-based resource assignment (CAGE).}
\end{figure*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{comment}
\begin{figure}[!htb]
\centering
%\includegraphics[height=3in, width=1.5in]{NodeArchs2.pdf}
\includegraphics[height=2.2in, width=1.3in]{Images/bipartite.pdf}
%\epsfig{file=Dataset.eps, height=2.5in, width=3in}
\caption{\label{fig:bipartite} Cache allocation as a bipartite graph.}
\end{figure}
\end{comment}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Problem Defenition} 
\indent We formulate our problem as an auction based mechanism to enforce cost/value updates for each resource as follows: \\
%The cost of each player to get a resource is the cost of the assigned resource divided by the number of players who share. 
\begin{itemize}
  \item \textbf{Valuation $\mathbf{v_{i,m}}$} : Any application has a valuation function which shows how much he benefits from $i th$ resource. The valuation function at time $t=0$ for cache contention case study is derived from the IPC (instruction per cycle) curves which is found using profiling, and for processor and co-processor contention case study is derived from the profiling solo performance metric of the application. However, in general, each application can choose its own utility function.  
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
    \item \textbf{Observed information}: The observed information at each time step is the performance value of the selected action in the game. Therefore, the applications repeatedly update the history of their valuation function over time.  
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%   
    \item \textbf{Belief updating}: At each iteration step of the auction, the applications update their valuation of each resource based on the observed performance on each resource. The update at time $T$ is derived using the following formula:
%\begin{small}
\begin{equation}\label{eq:belief}
v_{i,m}(T)=\frac{\sum\limits_{t=0}^T {\delta}^{T-t}  v_{i,m}(t)}{\sum\limits_{t=0}^T {\delta}^{T-t}} 
\end{equation}  
%\end{small}  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Where $v_{i,m}(t)$ shows the observed valuation of resource $m$ at time step $t$ by user $i$ in the system; $\delta$ shows the discount factor between 0 and 1 which shows how much a user relies on its past observations in the system. The discount factor is chosen to show the dynamics in the system. If the observed information in the system changes fast, the discount factor is nearly zero which means that we can't rely on the past observations very much. However if the system is more stable and the observed information does not change fast, the discount factor is chosen to be near 1. We choose the discount factor as the absolute value of the correlation coefficient of the observed values of the valuations at each iteration step which is calculated as follows:
%\begin{small}
\begin{equation}
\delta =  \frac{E(v_{i,m})^2}{{\sigma_{v_{i,m}}}^2}
\end{equation}  
%\end{small}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item \textbf{Action}: At each time step the applications decides which resource to bid and how much to bid for each resource. 
\end{itemize} 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\indent Table~\ref{Table:notation} shows important notation used throughout the paper. In the following sections, we describe our distributed optimization scheme to solve the problem. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{equation}
%min \sum\limits_{i=1}^n v_i C_k \frac{b_{i,k}}{\theta_k}, \\
%s.t. \sum\limits_{i=1}^n b_{i,k} \leq E_i
%\end{equation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Distributed Optimization Scheme}
The goal is to design a repeated auction mechanism which is run by the operating system to guide the applications to choose their best resource allocation strategy. The applications' goal is to maximize their own performance and the operating system wants to maximize the total utility it gains from the applications. Then, each application can use its own utility function and evaluates the resources based on how much it likes that particular resource. \\
\indent \textbf{Applications' approach}: The application $i$ want to maximize the total utility with respect to a limited budget for all phase $p$ of its execution time. \\
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%maximize \;\;\;\; \sum\limits_{i=1}^n v_i C_k \frac{b_{i,k}}{\theta_k},\\
%\begin{small}
\begin{align}
%\begin{IEEEeqnarray}{rCl}
\forall i \in U \; \; \; \; \; maximize \; \; \; \; \sum\limits_{p=1}^{P_i} \sum\limits_{m=1}^M  v_{i,m,p}-b_{i,m,p} , \nonumber \\
 % \IEEEyessubnumber\\
subject \; to \;\;\;\; \sum\limits_{p=1}^{P_i} \sum\limits_{m=1}^M b_{i,m,p} \leq B_i .
%\IEEEyessubnumber
%\end{IEEEeqnarray}
\end{align}
%\end{small}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\indent \textbf{OS's approach}: The operating system wants to maximize the social welfare function which is translated into submitted bids from the applications in a limited resource constraints.\\
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{small}
\begin{align}
%\begin{IEEEeqnarray}{rCl}
maximize \; \; \; \sum\limits_{i=1}^N \sum\limits_{p=1}^{P_i} \sum\limits_{m=1}^M b_{i,m,p} A_{i,m,p} , \nonumber \\ 
%\IEEEyessubnumber\\
subject \; to \;\;\;\; \sum\limits_{i=1}^N \sum\limits_{m=1}^M A_{i,m,p} \leq A_{max}, \; \; \; \; \forall p \in P , \nonumber \\
%\IEEEyessubnumber\\
A_{i,m,p} \in \{0,1\} , \; \; \; \; \forall i \in U, \; \;  \forall m \in V, \; \;  \forall p \in P .
%\IEEEyessubnumber
%\end{IEEEeqnarray}
\end{align}
%\end{small}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\indent \textbf{Illustrative example}: As an illustrative example, suppose we have two different resources, a large cache of 1MB which can be shared between applications, and two private caches of 512KB which are not shared. There are two applications competing for the cache space. One of the applications wants to minimize its request latency and the other one wants to maximize number of instructions executed per cycle. Suppose that both applications have two phases $(0,T)$ and $(T,2T)$.  Suppose if the first application gets the larger cache space its request latency reduces by 20 percent in first phase and by 40 percent in the second phase. The second application's \textit{IPC} increases by 35 percent in the first phase and by 25 percent in the second phase if it gets the larges cache space. Also, assume they both have 60 tokens (bids) to submit. The first application invests 20 token (bids) for the first phase and 40 tokens for the next phase. He should redistribute the tokens for the next phase if he did not get the resource he wants in the first phase. The second application invests 35 tokens in the first phase and 25 tokens in the next phase. The auctioneer (OS) at each phase decides to allocate which resource to which applications. Since, the social welfare would be maximized if the auctioneer allocates both applications with the larger cache space, they would both get the larger resource. Then the first application notices that its utility function does not improve as he predicts and adjusts the utility table and can either change its allocation or stay on current allocation. 
%If both applications bid 10\$ for the private cache and 15\$ for the shared cache, the operating system would allocate both the shared cache space and get 15\$ from each to maximize its revenue.  
\subsection{Analysis}
The distributed optimization problem seems complex. However, in reality the problem can be splitted into simpler subproblems since each application knows its bottleneck resource and would first bid for the first bottleneck resource to maximize its utility.\\
\indent We suppose all applications in the system are risk-neutral which means they have a linear valuation of utility function. Each risk neutral agent wants to maximize its expected revenue. Risk attitude behaviors are defined in \cite{ferber1999multi} where the agents can broadly be divided into risk averse, risk seeking and risk neutral. Risk averse agents prefer determinitic values rather than risky value profits and risk seeking applications have a superlinear utility function and prefer risky utilities than sure utilities. Next, we derive the Bayes Nash equilibrium strategy profile for all agents in the system assuming risk neutrality.  \\
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newtheorem{defi}{Definition}
\begin{defi}
A strategy profile $a$ is a pure Nash equilibrium if for every application $i$ and every strategy $a_i' \neq a_i \in A$ we have $u_i(a_i, a_{-i}) \geq u_i(a_i', a_{-i})$
\end{defi}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newtheorem{theorem}{Theorem}
\begin{theorem}\label{thm:neat}
%\emph{(Theorem)}
\label{Auction}
Suppose $n$ risk-neutral applications whose valuations are derived uniformly and independently from the interval $[0,1]$ compete for one resource which can be assigned to $m$ application who have the highest bid in the auction. We will show that Bayes Nash equilibrium bidding strategy for each application in the system is to bid $\frac{n-m}{n-m+1}v_i$ whre $v_i$ is the profit of application $i$ for getting the specified resource.  
\end{theorem}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%DIMAN COMMENTED PROOF FOR APPENDIX
\begin{comment}

\begin{proof}
Suppose all other applications' bidding strategy is to choose $\frac{n-m}{n-m+1}v_i$. Since the bidding values were derived uniformly in $[0, 1]$ all bids have the same probability. Therefore, if we consider the first application's expected utility to find its best response, we have:

\begin{equation}
%\begin{IEEEeqnarray}{rCl}
E[u_1] = \int_0^1  .... \int_0^1 \! (v_1 -b_1) \, \mathrm{d}u_2 \mathrm{d}u_3 ... \mathrm{d}u_{n-m} .  
%\end{IEEEeqnarray}
\end{equation}

The following integral breaks into two part where the first application wins the auction or not. 


%\begin{IEEEeqnarray}{rCl}
%E[u_1] = \int_0^{b_1}  .... \int_0^{b_1} \! (v_1 -b_1) \, \mathrm{d}u_2 \mathrm{d}u_3 ... %\mathrm{d}u_{n-m}  \\
%+ \int_{b_1}^1  .... \int_{b_1}^1 \! (v_1 -b_1) \, \mathrm{d}u_2 \mathrm{d}u_3 ... \mathrm{d}%u_{n-m}\nonumber 
%\end{IEEEeqnarray}

\begin{equation}
%\begin{IEEEeqnarray}{rCl}
E[u_1] = \int_0^{\frac{n-m+1}{n-m}b_1}  .... \int_0^{\frac{n-m+1}{n-m}b_1} \! (v_1 -b_1) \, \mathrm{d}u_2 ... \mathrm{d}u_{n-m}  \\
+ \int_{\frac{n-m+1}{n-m}v_1}^1  .... \int_{\frac{n-m+1}{n-m}v_1}^1 \! (v_1 -b_1) \, \mathrm{d}u_2 \mathrm{d}u_3 ... \mathrm{d}u_{n-m}\nonumber 
%\end{IEEEeqnarray}
\end{equation}

The second part of the integrals is the term where the first application doesn't win the auction. Therfore, the expected payoff of application 1 is equal with:

%\begin{IEEEeqnarray}{rCl}
%E[u_1] = \int_0^{b_1}  .... \int_0^{b_1} \! (v_1 -b_1) \, \mathrm{d}u_2 \mathrm{d}u_3 ... %\mathrm{d}u_{n-m}  \\
%= {({b_1}) }^{n-m} (v_1 -b_1). \nonumber 
%\end{IEEEeqnarray}

\begin{equation}
%\begin{IEEEeqnarray}{rCl}
E[u_1] =\int_0^{\frac{n-m+1}{n-m}b_1}  .... \int_0^{\frac{n-m+1}{n-m}b_1} \! (v_1 -b_1)  \mathrm{d}u_2 ... \mathrm{d}u_{n-m}  \\
= {(\frac{n-m+1}{n-m} b_1) }^{n-m} (v_1 -b_1). \nonumber 
%\end{IEEEeqnarray}
\end{equation}


Diffrentiating with respect to $b_1$ the optimal bid for application one is derived as follows:

%\begin{equation}
%\frac{\partial}{\partial b_1} ( {({b_1}) }^{n-m} (v_1 -b_1))=0.
%\end{equation}


\begin{equation}
\frac{\partial}{\partial b_1} ( {(\frac{n-m+1}{n-m} b_1) }^{n-m} (v_1 -b_1))=0.
\end{equation}

Which gives us the optimal bid for each application:
\begin{equation}
\Rightarrow b_1= \frac{n-m}{n-m+1}v_1
\end{equation}
\end{proof}
\end{comment}
%DIMAN COMMENTED PROOF FOR APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{algorithm}[!tb]
\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon    instead
\KwIn{A bipartite Graph (U, V, E).}
\KwOut{The allocation of resources to applications.}
At t=0 the valuation of each application for each resource is derived using profiling while running alone. 

For each application $U_i \in U$, the first bottleneck resource is
\[ Bottleneck_{1,i} = V_{i,m}=  arg \; \max_{m \in V} (v_{i,m}-p_{m})  \] 
Next, find the second bottleneck resource for each applications $U_i \in U$ in the system:
\[ Bottleneck_{2,i} = V_{i,k}=  arg \; \max_{k \in V, k \neq m} (v_{i,k}-p_{k})  \] 

Each application submits the bid for its first bottleneck resource using the following formula:
\[ b_{i,m} = V_m - V_k + p_{j} + \epsilon \]
Each resource $V_j \in V$, which can be shared between $m$ applications, is assigned to the $m$ highest bidding applications $Winner_j={i_1, i_2, ..., i_m}$ and the price for that resource is updated as follows:
\[ p_{j} =  arg \; \max_{i_1, i_2, ..., i_m \in U} \sum\limits_{k=1}^m (b_{i_k,j})  \]

The $minBid$ for each resource is updated as the minimum bid of $m$ applications who acquired the resource. That is
\[ minBid=  arg \; \min_{i \in Winner_j}  (b_{i,j}) \] 
 
\caption{CAGE: Parallel Auction for heterogeneous resource assignment.}
\label{algo:b}
\vspace{0\baselineskip}
\end{algorithm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\indent Theorem~\ref{thm:neat}, states that whenever there is a single resource that users compete to get it with different valuation functions, the Nash equilibrium strategy profile for risk-neutral users is to bid $\frac{n-m}{n-m+1}v_i$. This term tends to the true value of the object when n is a large number. \\
\indent In case of more than one resource competition we derive Algorithm~\ref{algo:b} and will prove that it is Nash equilibrium in the game. The algorithm is inspired by work of Bertsekas \cite{bertsekas1998network} that uses an auction for network flow problems. In the first step, all valuations are set to the solo-run of application's performance. Next, each application submits a bid for its first bottleneck resource. The bid should be larger than the price of the object which is intitialized to zero in the begining of the program. The applications only have incentive to bid a value no more than the difference of the first bottleneck and second bottleneck resource. Otherwise, it would submit a smaller bid to the second bottleneck and get the same revenue as paying more for the first bottleneck resource. In order to break the equal valuation function between two different applications, we use $\epsilon$ scaling such that at each iteration of the auction the prices should increase by a small number. 

%In addition, suppose we have 5 different memory bandwidth exposed to the applications Each application gets different performance benefit from different cache sizes and different memory bandwidth which is denoted in table  **. The applications need to submit their bids based on their performance benefits. 

%\begin{equation}
%\begin{split}
%\int_0^\frac{nb_1}{n-m}  .... \int_0^\frac{nb_1}{n-m} \! (\frac{v_1}{m} -b_1) \, \mathrm{d}u_2 %\mathrm{d}u_3 ... \mathrm{d}u_{n-m}= \\
%= {(\frac{nb_1}{n-m}) }^{n-m} (\frac{v_1}{m} -b_1). 
%\end{split}
%\end{equation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\[ \frac{\partial}{\partial b_1} ({(\frac{nb_1}{n-m}) }^{n-m} (\frac{v_1}{m} -b_1))

%\newtheorem{defi}{Definition}
%\begin{defi}
%Let's assume each user $Ui$ in the system is defined as one vertice of a graph $G$ in the system and let each edge in the graph show which subset of users can impact each others' performance and the associated weight of each edge show the cost function of how two users affect each others' performance in the system. Each edge has a weight function denoted by ${P1(n), P2(n), ... Pe(n)}$, where $e$ is the number of edges in Graph $G$. Let $A=A_1 \times A_2 \times ... \times A_n $ be the set of actions that each user can play. 
%\end{defi}
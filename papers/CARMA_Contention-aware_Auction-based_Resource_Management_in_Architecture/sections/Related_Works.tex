\section{Related Work} \label{Related_works}
With rapid improvement in computer technology, more and more cores are embedded in a single chip and applications competing for a shared resource is becoming common. On the one hand, managing scheduling of shared resources for large number of applications is challenging in a sense that the operating system doesn't know what is the performance metric for each application. But on the other hand, the operating system has a global view of the whole state of the system and can guide applications on choosing the shared resources.\\ 
\indent There has been several works, for managing the shared cache in multi-core systems. Qureshi et al. \cite{qureshi2006utility} showed that assigning more cache space to applications with more cache utility does not always lead to better performance since there exists applications with very low cache reuse which may have very high cache utilization. \\
\indent Several software and hardware approaches has been proposed to find the optimal partitioning of cache space for different applications \cite{zhuravlev2010addressing}. However, most of these approaches use brute force search of all possible combinations to find the best cache partitioning in run time or introduce a lot of overhead. There has been some approaches which use binary search to reduce searching all possible combinations \cite{kim2004fair, lin2008gaining, tam2009rapidmrc}. But none of these methods are scalable for the future many-core processor designs.\\
\indent There exists prior game-theoretic approaches designing a centralized scheduling framework that aims at a fair optimization of applications' utility \cite{zahedi2014ref, llull2017cooper, ghodsi2011dominant, zahedi2015sharing, fan2016computational}. Zahedi et al. in REF \cite{zahedi2014ref, zahedi2015sharing} use the Cobb-Douglas production function as a fair allocator for cache and memory bandwidth. They show that the Cobb-Douglas function provides game-theoretic properties such as sharing incentives, envy-freedom, and Pareto efficiency. But their approach is still centralized and spatially divides the shared resources to enforce a fair near-optimal policy sacrificing the performance. In their approach the centralized scheduler assumes all applications have the same priority for cache and memory bandwidth, while we do not have any assumption on this. Further, our auction-based resource allocation can be used for any number of resources and any priority for each application and the centralized scheduler does not need to have a global knowledge of these priorities.  \\
\indent Ghodi et al. in DRF \cite{ghodsi2011dominant} use another centralized fair policy to maximize the dominant resource utilization. But in practice it is not possible to clone any number of instances of each resources. %  the underlying scenario cloning the instances is very limited or superficial for practical purposes. 
Cooper \cite{llull2017cooper} enhances REF to capture colocated applications fairly, but it only addresses the special case of having two sets of applications with matched resources. Fan et al. \cite{fan2016computational} exploits computational sprinting architecture to improve task throughput assuming a class of applications where boosting their performance by increasing the power. \\
\indent While all prior works use a centralized scheduling that provides fairness and assume the same utility function for all, co-runners might have completely diverse needs and it is not efficient to use the same fairness/performance policy across them. 
In our auction-based resource scheduling provides scalability since individual applications compete for the shared resources based on their utility and the burden of decision making is removed from the central scheduler. We believe future CMPs should move toward a more decentralized approach which is more scalable and provides fair allocation of resources based on applications' needs. \\ 
%Providing the scalability of the system is getting better, if we make the individual applications our self administrators, and we can remove most of the performance-restricting policies such as fairness constraints from the centralized decision-maker. \\
\indent Auction theory which is a subfield of economics has recently been used as a tool to solve large scale resource assignement in cloud computing \cite{krishna2009auction, parsons2011auctions}. In an auction process, the buyers submit bids to get the commodities and sellers want to sell their commodities with the maximum price as possible. \\
\indent Our auction-based algorithm is inspired by work of Bertsekas \cite{bertsekas1998network} that uses an auction based mechanism for network flow problems. Our algorithm is an extension of local assignment problem proposed by Bertsekas et al that has been shown to converge to the global assignment within a linear approximation.
%\textcolor{red}{Not Complete yet}
\section{Motivation and Background} \label{Motivation}
\subsection{Motivation}
Different applications have different resource constraint with respect to CPU, memory, and bandwidth usage. Having a single resource manager for all existing resources and users in the system result in inefficiencies since it is not scalable and the operating system may not have enough information about applications' needs. For example, traditional LRU-based cache strategy uses cache utilization as a metric to give larger cache size to the applications which have higher utilization and lower cache size to the applications with lower cache utilization. However more cache utilization does not always result in better performance. Streaming applications for example have very high cache utilization, but very small cache reuse. In fact, the streaming applications only need a small cache space to buffer the streaming data. With rapid improvements in semiconductor technology, more and more cores are being embedded into a single core and managing large scale application using a single resource manager becomes more challenging. \\
%\indent Even if the applications are forced to announce their resource demand, it is possible that they lie about their resource vector or run some useless instructions to pretend to utilize the allocated resources given to them.
\indent In addition, defining a single fairness parameter for multiple applications is non-trivial since applications have different bottlenecks and may get different performance benefits from each resources during each phases of their execution time. Defining a single reasonable parameter for fairness is somewhat problematic. For instance, simple assignment algorithms which try to equally distribute the resources between all applications ignores the fact that different applications have different resource constraints. As a consequence, this makes the centralized resource management systems very inefficient in terms of fairness as well as performance needs of applications. We need a decentralized framework, where all applications' performance benefit could be translated into a unique notion of fairness and performance objective (known as utility function in economics) and the algorithm tries to allocate resources based on this translated notion of fairness. This translation has been well defined in economics and marketing, where the diversity of customer needs, makes more economically efficient market \cite{zhou2014sharing}. Economists have shown that in an economically efficient market, having diverse resource constraints and letting the customers compete for the resources can make a Nash equilibrium where both the applications and the resource managers can be enriched. Furthermore, applications' demand changes over time. Most resource allocation schemes pre-allocate the resources without considering the dynamism in applications' need and number of users sharing the same resource over time. Therefore, applications' performance can degrade drastically over time. Figure~\ref{fig:Phases} shows phase transitions for instruction per cycle (IPC) of mcf application from \textit{spec 2006} over 50 billion instructions. \\
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[!tb]
\centering
%\includegraphics[height=3in, width=1.5in]{NodeArchs2.pdf}
\includegraphics[height=1.8in, width=3.5in]{Images/Phases_May.pdf} %Phases.pdf
%\epsfig{file=Dataset.eps, height=2.5in, width=3in}
\vspace{-1.5\baselineskip}
\caption{\label{fig:Phases}Phase transition in mcf with different L2 cache sizes.}
\vspace{-1.0\baselineskip}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\indent We try to find a game-theoretic distributed resource management approach where the shared hardware resources are exposed to the applications and we show that by running a repeated auction game between different applications which are assumed to be rational, the output of the game converges to a balanced Nash equilibrium allocation. In addition, we compare the convergence time of the proposed algorithm in terms of dynamism in the system. We evaluate our model with two case studies: 1) Private and shared last level cache problem, where the applications have to decide if they would benefit from a larger cache space which can potentially get more congested or a smaller cache space which is potentially less congested. 2) Heterogeneous processors (\textit{Intel Xeon} and \textit{Xeon Phi}) problem, where we perform experiments to show how congestion affects the performance of different applications running on an \textit{Intel Xeon} or \textit{Xeon Phi} co-processors. Depending on the amount of congestion in the system, the application can offload the most time consuming part of its code on the \textit{Xeon Phi} co-processors or not.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{-1\baselineskip}
\subsection{Background}
%Congestion games have been studied in network routing protocols where the delay of each player choosing a path in the network depends on the number of players choosing the same route in the system. 
%Every congestion game is a potential game since there exists a potential function associated with it. In addition, every congestion game has a pure-strategy Nash equilibrium. A key assumption in congestion games is that all users have the same impact on the congestion. However, this assumption is not always true. In case of computer architecture resources, applications effect each other differently and dividing the payoff function by the number of users running on the shared resource does not give us the correct utility. 
Game theory has been used extensively in economics, political and social decision making situations \cite{tootaghaj2011game, tootaghaj2011risk, kotobi2017spectrum, kotobi2015introduction, kesidis2013distributed, kurve2013agent, wang2017using, wang2015recouping}. A game is a situation, where the output of each player not only depends on her own action in the game, but also on the action of other players \cite{osborne1994course}. Auction games are a class of games which has been used to formulate real-world problems of assigning different resources between $n$ users. Auction game framework can model resource competition, where the payoff (cost) of each application in the system is a function of the contention level (number of applications) in the game.\\
\indent Inspired by market-based interactions in real life games, there exists a repeated interaction between competitors in a resource sharing game. Assuming large number of applications, we show that the system gets to a Nash equilibrium where all applications are happy with their resource assignment and don't want to change their state. Furthermore, we show that the auction model is \textit{strategy-proof}, such that no application can get more utilization by bidding more or less than the true value of the resource. In this paper we propose a distributed market based approach to enforce cost on each resource in the system and remove the complexity of resource assignment from the central decision maker.\\ 
\indent The traditional resource assignment is performed by the operating system or a central hardware to assign fair amount of resources to different applications. However, fair scheduling is not always optimal and solving the optimization problem of assigning $m$ resources between $n$ users in the system is an integer programming which is an NP-hard problem and finding the best assignment problem becomes computationally infeasible. Prior works focus on designing a fair scheduling function that maximizes all application's benefit \cite{zahedi2014ref, llull2017cooper, ghodsi2011dominant, zahedi2015sharing, fan2016computational}, while applications might have completely different demands and it is not possible to use the same fairness function for all. By shifting decision making to the individual applications, the system becomes scalable and the burden of establishing fairness is removed from the centralized decision maker, since individual applications have to compete for the resources they need. Applications start by profiling the utility function for each resource and bid for the most profitable resource. During the course of execution time they can update their belief based on the observed performance metrics at each round of the auction. Updating the utility functions at each round of the auction is based on the history of the observed performance metrics which shows the state of the game. 
%The idea behind updating the utility functions is that the history at each round of the auction shows the state of the game. 
This state indicates the contention on the current acquired resources. The payoff function in each round depends on the state of the system and on the action of other applications in the system. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Sequential Auction}
Auction-based algorithms are used for maximum weighted perfect matching in a bipartite graph $G=(U,V, E)$ \cite{bertsekas1998network, kyle1985continuous, vasconcelos2009bipartite}. A vertex  $U_i \in U$ is the application in the auction and a vertex $V_j \in V$ is interpreted as a resource. The weight of each edge from $U_i$ to $V_j$ shows the utility of getting that particular resource by $U_i$. The prices are initially set to zero and will be updated during each iteration of the auction. In sequential auctions, each resource is taken out by the auctioneer and is sequentially auctioned to the applications, until all the resources are sold out.
\subsubsection{Parallel Auction}
In a parallel auction, the applications submit their bids for the first most profitable item. The value of the bid at each iteration is computed based on the difference of the highest profitable object and the second highest profitable object. The auctioneer would assign the resources based on the current bids. At each iteration, the valuation of each resource is updated based on the observed information during run-time which shows the contention on that particular resource.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Notation
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection*{Notation}
We refer to the frog model on $\Z^d$ with transition probabilities $\pi$ as $\fm(d, \pi)$. 
For $w, \alpha \in [0,1]$ and every vertex $x \in \Z^d$ let $(S_n^x)_{n \in \N_0}$ be a discrete time random walk on the lattice~$\Z^d$ starting at $x$ which moves according to the transition function $\pi_{w,\alpha}$ given by \eqref{transition_function}. Then $(S_n^x)_{n \in \N_0}$ describes the trajectory of the frog initially at vertex $x$. It starts to follow this trajectory once it is activated. We assume that the set $\{(S_n^x)_{n \in \N_0} \colon x \in \Z^d\}$ of random walks is independent, i.e.~active particles do not interact. Notice that this set of trajectories entirely determines the behaviour of the frog model. A formal definition of the frog model can be found in \cite{AMP02}. 
Note that $\pi_{1/d, 0}$ corresponds to a simple random walk on $\Z^d$. We write $\pi_{\text{sym}}$ in this case.

We refer to the frog that is initially at vertex $x\in \Z^d$ as ``frog~$x$''. 
We write $x \to y$ if frog $x$ (potentially) ever visits $y$, i.e.~$y \in \{S_n^x \colon n \in \N_0\}$.
For $x,y \in \Z^d$ and $A \subseteq \Z^d$ we say that there exists a frog path from $x$ to $y$ in $A$ and write $x \fp{A} y$ if there exist $n\in \N$ and $z_1, \ldots, z_n \in A$ such that $x \to z_1$, $z_i \to z_{i+1}$ for all $1\leq i < n$ and $z_n \to y$, or if $x \to y$ directly. Note that $x,y$ are not necessarily in $A$. Also the trajectories of the frogs $z_i$, $1 \leq i \leq n$, do not need to be in $A$.
For $x \in \Z^d$ we call the set 
\begin{equation}\label{def_frog_cluster}
\fc_x=\bigl\{y \in \Z^d \colon x \fp{\Z^d} y\bigr\} 
\end{equation}
the frog cluster of $x$. 
Note that, if frog $x$ ever becomes active, then every frog $y \in \fc_x$ is also activated. Observe that, as we only deal with recurrence and transience, the exact activation times are not important, but we are only interested in whether or not a frog is activated.

Further, we often use $(d-1)$-dimensional hyperplanes $H_n$ in $\Z^d$ defined by
\begin{equation}\label{definition_hyperplane}
H_n := \{x \in \Z^d \colon x_1=n\}
\end{equation}
for $n \in \Z$.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Some facts about random walks
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection*{Some facts about random walks}

We need to deal with hitting probabilities of random walks on $\Z^d$. For $x,y \in \Z^d$ recall that $\{x\to y\}$ denotes the event that the random walk started at $x$ ever visits the vertex $y$. Analogously, for $A\subseteq \Z^d$ we write $\{x \to A\}$ for the event that the random walk started at $x$ ever visits a vertex in $A$.

\begin{lemma}\label{lemma_hitting_probability_SRW}
For $d \geq 3$ and $w \in (0,1)$ consider a random walk on $\Z^d$ with transition function~$\pi_{w,0}$. There exists a constant $c=c(d,w) >0$ such that for all $x\in \Z^d$
\begin{equation*}
\P(0\to x) \geq c \lVert x \rVert_2^{-(d-2)},
\end{equation*}
where $\lVert x \rVert_2 = \bigl(\sum_{i=1}^{d} x_i^2\bigr)^{1/2} $ is the Euclidean norm.
\end{lemma}

A proof of the lemma for the simple random walk, i.e.~with transition function $\pi_{\text{sym}}$, can e.g.~be found in \cite[Theorem~2.4]{AMP02} and \cite[Lemma~2.4]{AMP02pt}. The proof can immediately be generalised to our set-up using \cite[Theorem~2.1.3]{LL10}.

\begin{lemma}\label{lemma_hitting_probability_RW_drift}
For $d \geq 1$ and $\alpha,w \in (0,1)$ consider a random walk on $\Z^d$ with transition function~$\pi_{w,\alpha}$. Then for each $\gamma > 0$ there is a constant $c = c(d, \gamma, w, \alpha) >0$ such that for all $n \in \N$ and $x \in \Z^d$ with $x_1=-n$ and $\lvert x_i \rvert \leq \gamma\sqrt{n}$, $2 \leq i \leq d$, it holds that
\begin{equation*}
 \P(x \to 0) \geq c n^{-(d-1)/2}.
\end{equation*}
\end{lemma}

For a proof see e.g.~\cite[Lemma 3.1]{DP14}. 

\begin{lemma}\label{lemma_hitting_probability_hyperplane}
 For $d \geq 1$ and $\alpha,w \in (0,1]$ consider a random walk on $\Z^d$ with transition function~$\pi_{w,\alpha}$. Then for every $n \in \N$ and $H_{-n}$ as defined in \eqref{definition_hyperplane}
 \begin{equation*}
  \P(0\to H_{-n}) = \Bigl(\frac{1-\alpha}{1+\alpha}\Bigr)^n.
 \end{equation*}
\end{lemma}

\begin{proof}
 As $\P(0\to H_{-n}) = \P(0\to H_{-1})^n$ for $n \in \N$, it suffices to prove the lemma for $n =1$. By the Markov property
 \begin{equation*}
  \P(0\to H_{-1}) = \frac{1-\alpha}{2} + \frac{1+\alpha}{2} \P(0\to H_{-2}).
 \end{equation*}
 The result follows after a straightforward calculation.
\end{proof}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Some facts about percolation
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection*{Some facts about percolation}

To prove recurrence we make use of the theory of independent site percolation on $\Z^d$ and therefore give a brief introduction here.
Let $p \in [0,1]$. Every site in $\Z^d$ is independently of the other sites declared open with probability $p$ and closed with probability $1-p$. An open cluster is a connected component of the subgraph induced by all open sites. It is well known that for $d \geq 2$ there is a critical parameter $p_c= p_c(d) \in (0,1)$ such that for all $p > p_c$ (supercritical phase) there is a unique infinite open cluster~$C$ almost surely, and for $p<p_c$ (subcritical phase) there is no infinite open cluster almost surely. Furthermore, denoting the open cluster containing the site~$x \in \Z^d$ by $C_x$, it holds that $\P(\lvert C_x \rvert=\infty)>0$ for $p>p_c$, and $\P(\lvert C_x \rvert=\infty)=0$ for $p<p_c$ and all $x \in \Z^d$. The following lemma states that the critical probability $p_c$ is small for $d$ large.

\begin{lemma}\label{lemma_pc_high_d}
For independent site percolation on $\Z^d$, 
\begin{equation*}
\lim_{d \to \infty} p_c(d) = 0.
\end{equation*}
\end{lemma}

Indeed, $p_c(d) = O\bigl(d^{-1}\bigr)$ holds. A proof of this result can e.g.~be found in \cite[Chapter~1, Theorem~7]{BR06}. Further, in the recurrence proofs we use the fact that an infinite open cluster is ``dense'' in $\Z^d$. The following weak version of denseness suffices.

\begin{lemma}\label{percolation_density}
Consider supercritical independent site percolation on $\Z^d$. There are constants $a,b>0$ such that 
\begin{equation*}
\P\bigl(\lvert A \cap C_x \rvert \geq a \lvert A \rvert \bigr) > b
\end{equation*}
for all $A \subseteq \Z^d$ and $x \in \Z^d$.
\end{lemma}

\begin{proof}
 
For $a>0$, $A \subseteq \Z^d$ and $x \in \Z^d$ the FKG-inequality yields
\begin{align*}
\P\bigl(\lvert A \cap C_x \rvert \geq a \lvert A \rvert \bigr)
& \geq \P\bigl( x \in C, \ \lvert A \cap C \rvert \geq a \lvert A \rvert \bigr)\\
& \geq \P( x \in C) \cdot \P\bigl(\lvert A \cap C \rvert \geq a \lvert A \rvert \bigr).
\end{align*}
Note that $\gamma:=\P( x \in C) \in (0,1)$ (and $\gamma$ does not depend on $x$) since the percolation is supercritical. By the Markov inequality
\begin{align*}
\P\bigl(\lvert A \cap C \rvert \geq a \lvert A \rvert \bigr)
& = 1 - \P\bigl(\lvert A \cap C^c \rvert \geq (1-a) \lvert A \rvert \bigr)\\
& \geq 1- \frac{\E \bigl[\lvert A \cap C^c \rvert \bigr] }{(1-a) \lvert A \rvert}\\
& = 1- \frac{1}{(1-a) \lvert A \rvert} \sum_{y \in A} \P(y \in C^c) \\
& = 1- \frac{1-\gamma}{1-a}>0,
\end{align*}
for $a$ small enough, which finishes the proof.
\end{proof}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% About Frogs
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection*{Some results about frogs}

As mentioned in the introduction, the frog model presented in this paper satisfies a zero-one law, which is shown in \cite[Theorem~1]{KZ17} in a more general set-up. See also Appendix~A in \cite{KZ17} for a comment on the slightly different definition of recurrence used there.

\begin{thm}[\cite{KZ17}]\label{lemma_zero_one_law}
For any $d \geq 1$ and any nearest neighbour transition function $\pi$,
we have for $\fm(d,\pi)$ that the probability that the origin is visited infinitely many times by active frogs is either $0$ or $1$.
\end{thm}

Due to this zero-one law, to show recurrence, we only need to prove that the origin is visited infinitely often with positive probability. 

In the symmetric frog model the set of vertices visited by active frogs, rescaled by time, converges to a convex set. This shape theorem is proven by Alves et al.~in \cite[Theorem 1.1]{AMP02} and we use it in one of the proofs concerning recurrence.

\begin{thm}[\cite{AMP02}]\label{lemma_shape_theorem}
Consider $\fm(d,\pi_{\text{sym}})$ and let $\xi_n$ be the set of all sites visited by active frogs by time~$n$ and $\overline{\xi}_n := \{x + (-\frac12, \frac12]^d \colon x \in \xi_n\}$. Then there is a non-empty convex symmetric set $\mathcal{A}=\mathcal{A}(d) \subseteq \R^d$, $\mathcal{A} \neq \{0\}$, such that, for any $0 < \varepsilon < 1$
 \begin{equation*}
  (1- \varepsilon) \mathcal{A} \subseteq \frac{\overline{\xi}_n}{n} \subseteq (1+ \varepsilon) \mathcal{A}
 \end{equation*}
for all $n$ large enough almost surely. 
\end{thm}

\begin{remark} \label{remark_shape}
The proof of Theorem~\ref{lemma_shape_theorem} goes through for the ``lazy'' version of the frog model, where in each step a frog decides to stay where it is with probability $q \in (0,1)$, independently of all other frogs.
\end{remark}

Further, we need a result on the frog model with death. For $s \in [0,1]$ it is defined just as the usual frog model, but every active frog dies at every step with probability $1-s$ independently of everything else. The parameter $s$ is called the survival probability. We denote this frog model on $\Z^d$ by $\fm^*(d,\pi,s)$ if the underlying random walk has transition function $\pi$. Further, we denote frog clusters in the frog model with death by $\fc^*$, analogous to the notation introduced in \eqref{def_frog_cluster} for the frog model without death. In this paper we only use the frog model with death in the symmetric case, i.e. $\pi= \pi_{\text{sym}}$. We say that the frog model with death survives if at any time there is at least one active frog.
The frog model with death is intensively studied in \cite{AMP02pt} and also in \cite{FMS04} and \cite{LMP05}. We need the following lemma in the proofs concerning transience. 

\begin{lemma}\label{lemma_1d_fm}
 For $\fm(1,\pi_{1,\alpha})$ with $\alpha > 0$ and $\fm^*(1,\pi_{sym},s)$ with $s < 1$ there is $c>0$ such that $\P(0 \fp{\Z} -n) \leq \e^{-cn}$ for all $n \in \N$. 
\end{lemma}

\begin{proof}
 Let $p$ be the probability that a frog starting from $0$ ever hits the vertex $-1$. In both models we have $p <1$. Obviously, as $s <1$, this is true for $\fm^*(d,\pi_{\text{sym}},s)$. For $\fm(1,\pi_{1,\alpha})$ it follows from Lemma~\ref{lemma_hitting_probability_hyperplane}.

 For $n \in \N$ define $Y_n = \lvert\{m > -n \colon m \to -n \}\rvert$ if $-n \in \fc_0$, respectively $-n \in \fc_0^*$. Otherwise set $Y_n =0$. If $-n$ is visited by active frogs, then $Y_n$ counts the number of frogs to the right of $-n$ that potentially ever reach $-n$. The process $(Y_n)_{n \in \N}$ is a Markov chain on $\N_0$ with
 \begin{equation*}
  Y_{n+1} = 
  \begin{cases}
   0 & \text{if $Y_n = 0$,} \\
   \operatorname{Binomial}(Y_n+1,p) & \text{if $Y_n > 0$}.
  \end{cases}
 \end{equation*}
 Note that $\P(0 \fp{\Z} -n) = \P(Y_n >0)$ by definition.
 A straightforward calculation shows that there is $k_0 \in \N$ such that $\P(Y_{n+1} < Y_n \mid Y_n = k) > \frac23$ for all $k \geq k_0$. Hence, we can dominate the Markov chain $(Y_n)_{n \in \N}$ by the Markov chain $(\widetilde{Y}_n)_{n \in \N}$ on $\{0, k_0, k_0+1, \ldots\}$ with transition probabilities 
   \begin{align*}
   \P(\widetilde{Y}_{n+1} = l \mid \widetilde{Y}_n =k) = 
   \begin{cases}
    \frac{1}{3} & \text{if $l=k+1$, $k > k_0$}, \\
    \frac{2}{3} & \text{if $l=k-1$, $k > k_0$}, \\
    (1-p)^{k_0+1} & \text{if $l=0$, $k = k_0$}, \\
    1-(1-p)^{k_0+1} & \text{if $l=k+1$, $k = k_0$}, \\
    1 & \text{if $l=k=0$}
   \end{cases}
  \end{align*}
 for all $n \in \N$ and starting point $\widetilde{Y}_1 = \max\{Y_1, k_0\}$. Obviously, we have $\P(Y_n >0) \leq \P(\widetilde{Y}_n >0)$ for all $n \in \N$.
 Let $T_k= \min\{n \in \N \colon \widetilde{Y}_n = k\}$ and $T_{k,l}=T_l - T_k$. Note that $\P(\widetilde{Y}_n >0) = \P(T_0 >n)$. For $t >0$,
we apply the Markov inequality and use the strong Markov property to get
 \begin{align}\label{proof_lemma_1d_fm_1}
 \P(T_0 > n) &=    \P\biggl(\sum_{k=k_0}^{\widetilde{Y}_1-1} T_{k+1,k} + T_{k_0,0} > n\biggr) \nonumber\\
             &\leq \e^{-tn}\E\biggl[\exp\biggl(t \sum_{k=k_0}^{\widetilde{Y}_1-1} T_{k+1,k} + tT_{k_0,0}\biggr)\biggr] \nonumber\\
             &=    \e^{-tn} \sum_{l=k_0}^{\infty} \prod_{k=k_0}^{l-1} \E\bigl[\exp(tT_{k+1,k})\bigr] \E\bigl[\exp( tT_{k_0,0})\bigr]\P(\widetilde{Y}_1 = l) \nonumber\\
             &=    \e^{-tn} \sum_{l=0}^{\infty} \E\bigl[\exp(tT_{k_0+1,k_0})\bigr]^l \E\bigl[\exp( tT_{k_0,0})\bigr]\P(\widetilde{Y}_1 = l+k_0).
 \end{align}
$\widetilde{Y}_1$ can only be equal to $l+k_0$ if at least one frog to the right of $l-1$ reaches $-1$. Thus, 
\begin{equation}\label{proof_lemma_1d_fm_2}
 \P(\widetilde{Y}_1 = l+k_0) \leq \sum_{i=l}^{\infty} p^{i+1} = p^l \frac{p}{1-p}. 
\end{equation}
Now, we choose $t>0$ small enough such that $\E\bigl[\exp(tT_{k_0+1,k_0})\bigr] < p^{-1}$. Then \eqref{proof_lemma_1d_fm_2} shows that the sum in \eqref{proof_lemma_1d_fm_1} is finite, which yields the claim.
\end{proof}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% More stuff
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection*{A lemma on Bernoulli random variables}

We will repeatedly use the following simple lemma. Note that the random variables in this lemma do not have to be independent.

\begin{lemma}\label{lemma_sum_rv}
For $i \in \N$ let $X_i$ be a Bernoulli($p_i$) random variable with $\inf_{i\in \N}p_i =:p >0$. Then for every $a >0$ and $n \in \N$ 
\begin{equation*}
\P \left(\frac{1}{n} \sum_{i=1}^n X_i \geq a \right) \geq p-a. 
\end{equation*}
\end{lemma}

\begin{proof}
Since $\E[X_i]\geq p$ and $\frac{1}{n} \sum_{i=1}^n X_i \leq 1$, we have
\begin{align*}
p \leq \E\left[\frac{1}{n}\sum_{i=1}^n X_i \right] \leq \P \left(\frac{1}{n}\sum_{i=1}^n X_i \geq a \right) + a ,
\end{align*}
which yields the claim.
\end{proof}








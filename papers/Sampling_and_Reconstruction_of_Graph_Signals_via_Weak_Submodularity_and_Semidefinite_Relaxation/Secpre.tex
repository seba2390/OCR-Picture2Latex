Let $\x$ be a zero-mean, random graph signal which is $k$-bandlimited in a given basis $\mathbf{V} \in \mathbb{R}^{N \times N}$. This means that the signal's so-called graph Fourier transform (GFT) $\bar{\x} = \V^\top \x$ is $k$-sparse. There are several choices for $\mathbf{V}$ in the literature with most aiming to decompose a graph signal into different modes of variation with respect to the graph topology. For instance, $\mathbf{V} = [\mathbf{v}_{1},\cdots,\mathbf{v}_{N}]$ can be defined via the Jordan decomposition of the adjacency matrix \cite{DSP_freq_analysis,deri2017spectral}, through the eigenvectors of the Laplacian when $\mathcal{G}$ is undirected \cite{shuman2013}, or it can be obtained as the result of an optimization procedure \cite{shafipour2017digraph,sardellitti}. We also assume that the signal in not necessarily stationary with respect to $\mathcal{G}$, and that $\bar{\x}$ is a zero-mean random vector with (generally non-diagonal) covariance matrix $\E[\bar{\x}\bar{\x}^\top]$ = $\P$. Recall that since $\x$ is bandlimited, $\bar{\x}$ is sparse with at most $k$ nonzero entries. Let $K$ be the support set of $\bar{\x}$, where $|K| = k$. Then, one can write $\x = \U\bar{\x}_K$, where $\U = \V_{K,c}$. 

Suppose that only a few (possibly noisy) entries of $\x$ can be observed, corresponding to 
taking measurements from a subset of nodes in $\mathcal{N}$. The goal of sampling is to
select the subset that enables reconstruction of the original signal with the smallest possible
distortion. Formally, let $\y = \x + \n$ be the noise-corrupted signal, where $\n \in \R^{N}$ is the zero-mean noise vector with covariance matrix $\E[\n\n^\top]=\sigma^2 \I_N$. Let $S \subseteq \mathcal{N}$ be a sampling subset of nodes and let $\hat{\x}$ be the reconstructed graph signal based on the measurements (i.e., the entries of $\y$) indexed by $S$. Since the signal is $k$-bandlimited, $\bar{\x}$ has at most $k$ nonzero entries. Therefore, we assume that the least mean square estimator of $\bar{\x}$ has at most  $k$ nonzero entries. This in turn imposes the constraint $|S|\leq k$. Now, 
since $\x = \U\bar{\x}_K$, the samples $\y_S$ and the non-zero frequency components of $\x$ are related via the Bayesian linear model
%
\begin{equation}\label{eq:model}
\y_S = \U_{S,r}\bar{\x}_K +\n_{S}.
\end{equation}
%
Hence, in order to find $\hat{\x}$ it suffices to estimate $\bar{\x}_K$ based on $\y_S$.
The least mean square estimator of $\bar{\x}_K$, denoted by $\hat{\bar{\x}}_{K_{\mathrm{lms}}}$, satisfies the Bayesian counterparts of the normal equations in the Gauss-Markov theorem (see e.g.,  \cite[Ch. 10]{kay1993fundamentals}). Accordingly, it is given by
%
\begin{equation}\label{eq:estf}
\hat{\bar{\x}}_{K_{\mathrm{lms}}} = \sigma^{-2}\bar{\S}_S \U_{S,r}^\top \y_S,
\end{equation}
%
where 
%
\begin{equation}\label{eq:covf}
\bar{\S}_S = \left(\P^{-1}+\sigma^{-2}\U_{S,r}^\top\U_{S,r}\right)^{-1}
\end{equation}
%
is the error covariance matrix of $\hat{\bar{\x}}_{K_{\mathrm{lms}}}$. Therefore, $\hat{\x} = \U\hat{\bar{\x}}_{K_{\mathrm{lms}}}$ and its error covariance matrix can be obtained as ${\S}_S = \U \bar{\S}_S \U^\top$.

The problem of sampling for near-optimal reconstruction can now be formulated as the task of choosing $S$ so as to minimize the mean square error (MSE) of the estimator $\hat{\x}$. Since the MSE is defined as the trace of the error covariance matrix, we obtain the following optimization problem,
% 
\begin{equation}\label{eq:probs}
\begin{aligned}
& \underset{S}{\text{min}}
\quad \mathrm{Tr}\left({\S}_S\right)
& \text{s.t.}\quad S \subseteq \mathcal{N}, \phantom{k}|S|\leq k.
\end{aligned}
\end{equation}
%
Using trace properties and the fact that $\U^\top\U$ is a Hermitian positive semidefinite matrix, \ref{eq:probs} simplifies to
%
\begin{equation}\label{eq:probf}
\begin{aligned}
& \underset{S}{\text{min}}
\quad \mathrm{Tr}\left(\bar{\S}_S\right)
& \text{s.t.}\quad S \subseteq \mathcal{N}, \phantom{k}|S| \leq k.
\end{aligned}
\end{equation}
%
The optimization problem \ref{eq:probf} is NP-hard and evaluating all ${N}\choose{k}$ possibilities to find an exact solution makes it intractable even for relatively small graphs. In the next section we propose two alternatives to find near-optimal solutions in polynomial time.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass{midl} % Include author names
%\documentclass[anon]{midl} % Anonymized submission

% The following packages will be automatically loaded:
% jmlr, amsmath, amssymb, natbib, graphicx, url, algorithm2e
% ifoddpage, relsize and probably more
% make sure they are installed with your latex distribution

\usepackage{mwe} % to get dummy images
% \usepackage{subcaption}
\usepackage{graphicx}
\usepackage{float}

% Header for extended abstracts
\jmlrproceedings{MIDL}{Medical Imaging with Deep Learning}
\jmlrpages{}
\jmlryear{2020}

% to be uncommented for submissions under review
\jmlrworkshop{Short Paper -- MIDL 2020}
\jmlrvolume{}
%\editors{Under Review for MIDL 2020}

\title[Assessing the validity of saliency maps for abnormality localization in medical imaging]{Assessing the validity of saliency maps for abnormality localization in medical imaging}

 % Use \Name{Author Name} to specify the name.
 % If the surname contains spaces, enclose the surname
 % in braces, e.g. \Name{John {Smith Jones}} similarly
 % if the name has a "von" part, e.g \Name{Jane {de Winter}}.
 % If the first letter in the forenames is a diacritic
 % enclose the diacritic in braces, e.g. \Name{{\'E}louise Smith}

 % Two authors with the same address
 % \midlauthor{\Name{Author Name1} \Email{abc@sample.edu}\and
 %  \Name{Author Name2} \Email{xyz@sample.edu}\\
 %  \addr Address}

 % Three or more authors with the same address:
 % \midlauthor{\Name{Author Name1} \Email{an1@sample.edu}\\
 %  \Name{Author Name2} \Email{an2@sample.edu}\\
 %  \Name{Author Name3} \Email{an3@sample.edu}\\
 %  \addr Address}


% Authors with different addresses:
% \midlauthor{\Name{Author Name1} \Email{abc@sample.edu}\\
% \addr Address 1
% \AND
% \Name{Author Name2} \Email{xyz@sample.edu}\\
% \addr Address 2
% }

%\footnotetext[1]{Contributed equally}

% More complicate cases, e.g. with dual affiliations and joint authorship
\midlauthor{\Name{Nishanth Thumbavanam Arun\midljointauthortext{Contributed equally}\nametag{$^{1}$}} \AND
\Name{Nathan Gaw\midlotherjointauthor\nametag{$^{2}$}} \AND
\Name{Praveer Singh\midlotherjointauthor\nametag{$^{1}$}} \AND
\Name{Ken Chang\midlotherjointauthor\nametag{$^{1}$}} \AND
\Name{Katharina Viktoria Hoebel\nametag{$^{1}$}} \AND
\Name{Jay Patel\nametag{$^{1}$}} \AND
\Name{Mishka Gidwani\nametag{$^{1}$}} \AND
\Name{Jayashree Kalpathy-Cramer\nametag{$^{1}$}}\Email{kalpathy@nmr.mgh.harvard.edu} \\
\addr $^{1}$ Athinoula A. Martinos Center for Biomedical Imaging, Department of Radiology, Massachusetts General Hospital, Boston, MA, USA \\
\addr $^{2}$ Arizona State University-Mayo Clinic Center for Innovative Imaging, School of Computing, Informatics, and Decision Systems Engineering, Tempe, AZ, USA
}

\begin{document}

\maketitle

\begin{abstract}
Saliency maps have become a widely used method to assess which areas of the input image are most pertinent to the prediction of a trained neural network. However, in the context of medical imaging, there is no study to our knowledge that has examined the efficacy of these techniques and quantified them using overlap with ground truth bounding boxes. In this work, we explored the credibility of the various existing saliency map methods on the RSNA Pneumonia dataset.  We found that GradCAM was the most sensitive to model parameter and label randomization, and was highly agnostic to model architecture.
\end{abstract}

\begin{keywords}
Saliency maps, localization, deep learning.
\end{keywords}

\section{Introduction}
Saliency maps have become a popular approach for post-hoc interpretability of Convolutional Neural Networks (CNNs). \cite{adebayo2018sanity} These maps are designed to highlight the salient components of the input images that are important to the model prediction. As a result, many deep learning medical imaging studies have used saliency maps to rationalize model prediction and provide localization. \cite{rajpurkar2017chexnet,bien2018deep,mitani2019detection} However, the validity of saliency maps has been called into question in a recent study showing that many popular saliency map approaches are not sensitive to model weight or label randomization for models evaluated on several datasets. \cite{adebayo2018sanity} In this study, we extend this work by evaluating popular saliency map methods both quantitatively and qualitatively for classification models trained  on the RSNA Pneumonia dataset. \cite{shih2019augmenting} Specifically, we assess the performance of these methods in localizing abnormalities in medical imaging by quantifying overlap with ground truth bounding boxes. Furthermore, we assess the effect of model weight and label randomization on localization performance. Lastly, we empirically study repeatability of the saliency maps, both within the same model architecture and across different model architectures.

\section{Methods and Results}
\subsection{Model and Data Randomization}
The saliency methods examined in our experiments are
Gradient Explanation \cite{simonyan2013deep},
Smoothgrad Integrated Gradients (IG) \cite{sundararajan2017axiomatic},
GradCAM \cite{selvaraju2016grad},
XRAI \cite{kapishnikov2019xrai}, and
Smoothgrad \cite{smilkov2017smoothgrad}. Along with using Spearman rank correlation to compare maps before and after model weight and label randomization, we leverage the ground-truth bounding box coordinates 
\par
\begin{figure}[H]
\centering\includegraphics[width=\linewidth]{fig1.jpg}
\caption{a) Visualization of saliency maps under cascading randomization on InceptionV3 (performance before randomization: AUC=0.98, precision=0.92) (b) Dice scores under cascading randomization (c) Spearman rank correlation under cascading randomization}
\label{fig:fig1}
\end{figure}

\noindent provided in the RSNA Pneumonia dataset to establish a quantitative baseline using the dice metric. To investigate the sensitivity of saliency methods under changes to model parameters, we employ cascading randomization. \cite{adebayo2018sanity} We observed that among these saliency techniques, GradCAM degraded with model randomization to a large degree whereas the other methods did not (Fig \ref{fig:fig1}). This is also verified in a label randomization experiment shown in Fig \ref{fig:fig2}(c) wherein we randomly flipped the labels and retrained the model to observe the difference in the dice scores of the saliency maps. In both the tests, it can be observed that gradient explanation, Smoothgrad IG, and XRAI do not degrade significantly under randomization, suggesting an undesirable invariance to model parameters and labels.

\subsection{Repeatability and Reproducibility}
We also conducted repeatability tests on these saliency methods by comparing maps from a) models with the same architecture trained independently (intra-architecture repeatability) \par

\begin{figure}[H]
\centering\includegraphics[width=\linewidth]{fig2.jpg}
\caption{(a) Visualizations from two independently trained InceptionV3 models (b) Visualizations from an InceptionV3 model (top row) and a DenseNet121 model (bottom row) (c) Comparison of dice score differences across saliency methods and architectures (d) Comparison of intra- vs. inter-architecture repeatability using Spearman rank correlation}
\label{fig:fig2}
\end{figure}

\noindent and b) models with different architectures (inter-architecture reproducibility). These experiments are designed to test if these saliency methods produce similar maps with a different set of weights and whether they are architecture agnostic. Fig \ref{fig:fig2}(a) shows considerable differences across all the different maps from two independently trained InceptionV3 models. Furthermore, Fig \ref{fig:fig2}(b) shows saliency maps differences between those produced from InceptionV3 (top row) versus those from DenseNet121 (bottom row). Fig \ref{fig:fig2}(d) demonstrates that both the Smoothgrad and Smoothgrad IG  yielded the most dissimilar maps across architectures while GradCAM yielded maps that were most similar.

\section{Discussion and Conclusion}
In this study, we evaluated the performance of several popular saliency methods on the RSNA Pneumonia Detection dataset in regards to their localization capabilities, robustness to model parameter and label randomization, as well as repeatability and reproducibility with model architectures.  It was found that GradCAM showed superior sensitivity to model parameter and label randomization, and was highly agnostic to model architecture. In future studies, we will further examine the effect of different model architectures on saliency maps and validate our findings on a separate medical imaging dataset.

\midlacknowledgments{We would like to thank Julius Adebayo for providing us with the cascading randomization code used in his work. \cite{adebayo2018sanity}

Research reported in this publication was supported by a training grant from the National Institute of Biomedical Imaging and Bioengineering (NIBIB) of the National Institutes of Health under award number 5T32EB1680 to K. Chang and J. B. Patel and by the National Cancer Institute (NCI) of the National Institutes of Health under Award Number F30CA239407 to K. Chang. The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health.

This publication was supported from the Martinos Scholars fund to K. Hoebel. Its contents are solely the responsibility of the authors and do not necessarily represent the official views of the Martinos Scholars fund.

This study was supported by National Institutes of Health (NIH) grants U01 CA154601, U24 CA180927, and U24 CA180918 and National Science Foundation (NSF) grant NSF 1622542 to J. Kalpathy-Cramer.

This research was carried out in whole or in part at the Athinoula A. Martinos Center for Biomedical Imaging at the Massachusetts General Hospital, using resources provided by the Center for Functional Neuroimaging Technologies, P41EB015896, a P41 Biotechnology Resource Grant supported by the National Institute of Biomedical Imaging and Bioengineering (NIBIB), National Institutes of Health.}

\bibliography{midl-samplebibliography}

\end{document}

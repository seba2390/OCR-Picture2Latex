\section{RELATED WORK}

We build on prior work from several areas,
including character animation, diversity optimization, human pose modeling, and high-jump analysis from biomechanics and kinesiology.

\subsection{Character Animation}
Synthesizing natural human motion is a long-standing challenge in computer animation. We first briefly review kinematic methods, and then provide a more detailed review of physics-based methods. To the best of our knowledge, there are no previous attempts to synthesize athletic high jumps or obstacle jumps using either kinematic or physics-based approaches. Both tasks require precise coordination and exhibit multiple strategies.

\paragraph{Kinematic Methods} 
Data-driven kinematic methods have demonstrated their effectiveness for synthesizing high-quality human motions based on captured examples. Such kinematic models have evolved from graph structures~\cite{Kovar:2002:MotionGraphs,Safonova-Interpolated-Motion-Graphs}, to Gaussian Processes~\cite{levine2012continuous, ye2010synthesis-responsive}, and recently deep neural networks \cite{Holden:2017:PFNN, Zhang:2018:MANN, starke2019neural-state-machine, starke2020local-motion-phases, lee2018interactive-RNN, Ling20}. Non-parametric models that store all example frames have limited capability of generalizing to new motions due to their inherent nature of data interpolation \cite{Clavet16}. Compact parametric models learn an underlying low-dimensional motion manifold. Therefore they tend to generalize better as new motions not in the training dataset can be synthesized by sampling in the learned latent space~\cite{Holden16}. Completely novel motions and strategies, however, are still beyond their reach. Most fundamentally, kinematic models do not take into account physical realism, which is important for athletic motions. We thus cannot directly apply kinematic methods to our problem of discovering unseen strategies for highly dynamic motions. However, we do adopt a variational autoencoder (VAE) similar to the one in~\cite{Ling20} as a means to
improve the naturalness of our learned motion strategies.

\paragraph{Physics-based Methods}
Physics-based control and simulation methods generate motions with physical realism and environmental interactions. The key challenge is the design or learning of robust controllers. Conventional manually designed controllers have achieved significant success for locomotion, e.g.,~\cite{Yin07,wang2009optimizing,Coros10,wang2012optimizing,geijtenbeek2013flexible,lee2014locomotion,felis2016synthesis,jain2009optimization}. The seminal work from Hodgins \textit{et al.} demonstrated impressive controllers for athletic skills such as a handspring vault, a standing broad jump, a vertical leap, somersaults to different directions, and platform dives~\cite{Hodgins95,Wooten98}. Such handcrafted controllers are mostly designed with finite state machines (FSM) and heuristic feedback rules, which require deep human insight and domain knowledge, and tedious manual trial and error. Zhao and van de Panne~\shortcite{Zhao05} thus proposed an interface to ease such a design process, and demonstrated controllers for diving, skiing and snowboarding. Controls can also be designed using objectives and constraints adapted to each motion phase, e.g.,~\cite{jain2009optimization,deLasa2010},
or developed using a methodology that mimics human coaching~\cite{ha2014-human-coach}. In general, manually designed controllers remain hard to generalize to different strategies or tasks. 

With the wide availability of motion capture data, many research endeavors have been focused on tracking-based controllers, which are capable of reproducing high-quality motions by imitating motion examples. Controllers for a wide range of skills have been demonstrated through trajectory optimization \cite{sok2007simulating,da2008interactive,muico2009contact,lee2010data-driven-biped,ye2010optimal,lee2014locomotion}, sampling-based algorithms \cite{Liu:2010:Samcon,Liu:2015:Samcon2,Liu16}, and deep reinforcement learning ~\cite{Peng2017deepLoco,Peng:2018:DeepMimic,Peng:2018:SFV,ma2021spacetime,Liu18,Lee19}.
Tracking controllers have also been combined with kinematic motion generators to support interactive control of simulated characters~\cite{Bergamin:2019:DReCon,Park:2019:LPS,won2020scalable}. Even though tracking-based methods have demonstrated their effectiveness on achieving task-related goals~\cite{Peng:2018:DeepMimic}, the imitation objective inherently restricts them from generalizing to novel motion strategies fundamentally different from the reference. Most recently, style exploration has also been demonstrated within a physics-based DRL framework using spacetime bounds~\cite{ma2021spacetime}. However, these remain style variations rather than strategy variations. Moreover, high jumping motion capture examples are difficult to find. We obtained captures of three high jump strategies, which we use to compare our synthetic results to.

Our goal is to discover as many strategies as possible, so example-free methods are most suitable in our case. Various tracking-free methods have been proposed via trajectory optimization or deep reinforcement learning. Heess \textit{et al.} \shortcite{Heess:2017:Emergence} demonstrate a rich set of locomotion behaviors emerging from just complex environment interactions. However, the resulting motions show limited realism in the absence of effective motion quality regularization. Better motion quality is achievable with sophisticated reward functions and domain knowledge, such as sagittal symmetry, which do not directly generalize beyond locomotion \cite{Yu:2018:LSLL,coumans2016pybullet,Xie2020allsteps,mordatch2013-cio-locomotion,mordatch2015interactive}. Synthesizing diverse physics-based skills without example motions generally requires optimization with detailed cost functions that are engineered specifically for each skill~\cite{AlBorno13}, and often only works for simplified physical models~\cite{Mordatch12}.


\subsection{Diversity Optimization}
Diversity Optimization is a problem of great interest in artificial intelligence \cite{hebrard2005finding-diverse,ursem2002diversity,srivastava2007diverse-plan,coman2011generating-diverse,pugh2016quality-diversity,lehman2011novelty-search}. It is formulated as searching for a set of configurations such that the corresponding outcomes have a large diversity while satisfying a given objective. Diversity optimization has also been utilized in computer graphics applications~\cite{merrell2011interactive,Agrawal:2013:Diverse}. For example, a variety of 2D and simple 3D skills have been achieved through jointly optimizing task objectives and a diversity metric within 
a trajectory optimization framework~\cite{Agrawal:2013:Diverse}. Such methods are computationally prohibitive for our case as learning the athletic tasks involve expensive DRL training through non-differentiable simulations, e.g., a single strategy takes six hours to learn even on a high-end desktop. 
We propose a diversity optimization algorithm based on the successful Bayesian Optimization (BO) philosophy for sample efficient black-box function optimization.

In Bayesian Optimization, objective functions are optimized purely through function evaluations as no derivative information is available. A Bayesian statistical \textit{surrogate model}, usually a Gaussian Process (GP) \cite{rasmussen2003gaussian-process}, is maintained to estimate the value of the objective function along with the uncertainty of the estimation. An \textit{acquisition function} is then repeatedly maximized for fast decisions on where to sample next for the actual expensive function evaluation. The next sample needs to be promising in terms of maximizing the objective function predicted by the surrogate model, and also informative in terms of reducing the uncertainty in less explored regions of the surrogate model~\cite{jones1998-bo-expected-improvement, frazier2009-bo-knowledge-gradient, GP-bandit}. BO has been widely adopted in machine learning for parameter and hyperparameter optimizations \cite{snoek2015scalable,klein2017fast,kandasamy2018neural,kandasamy2020tuning,korovina2020chembo,snoek2012practical}. Recently BO has also seen applications in computer graphics~\cite{koyama2017sequential,koyama2020sequential}, such as parameter tuning for fluid animation systems \cite{brochu2007preference}. 

We propose a novel acquisition function to encourage discovery of diverse motion strategies. We also decouple the exploration from the maximization for more robust and efficient strategy discovery. We name this algorithm Bayesian Diversity Search (BDS). The BDS algorithm searches for diverse strategies by exploring a low-dimensional initial state space defined at the take-off moment. Initial states exploration has been applied to find appropriate initial conditions for desired landing controllers \cite{ha2012falling}. In the context of DRL learning, initial states are usually treated as hyperparameters rather than being explored.

Recently a variety of DRL-based learning methods have been proposed to discover diverse control policies in machine learning, e.g.,  \cite{Eysenbach19,zhang2019novel-policies,Sun2020novel-policies,achiam2018variational,sharma2019dynamics,haarnoja2018soft,conti2018improving,houthooft2016vime,hester2017intrinsically,schmidhuber1991curious}. These methods mainly encourage exploration of unseen states or actions by jointly optimizing the task and novelty objectives~\cite{zhang2019novel-policies}, or optimizing intrinsic rewards such as heuristically defined curiosity terms~\cite{Eysenbach19,sharma2019dynamics}. We adopt a similar idea for novelty seeking in Stage~2 of our framework after BDS, but with a novelty metric and reward structure more suitable for our goal. Coupled with the Stage~1 BDS, we are able to learn a rich set of strategies for challenging tasks such as athletic high jumping.

\subsection{Natural Pose Space}

In biomechanics and neuroscience, it is well known that muscle synergies, or muscle co-activations, serve as motor primitives for the central nervous system to simplify movement control of the underlying complex neuromusculoskeletal systems~\cite{Overduin15,Zhao19}. In character animation, human-like character models are much simplified, but are still parameterized by 30+ DoFs. Yet the natural human pose manifold learned from motion capture databases is of much lower dimension \cite{Holden16}. The movement of joints are highly correlated as typically they are strategically coordinated and co-activated. Such correlations have been modelled through traditional dimensionality reduction techniques such as PCA \cite{chai2005performance-lowd}, or more recently, Variational AutoEncoders (VAE) \cite{habibie2017,Ling20}.

We rely on a VAE learned from mocap databases to produce natural target poses for our DRL-based policy network. Searching behaviors in low dimensional spaces has been employed in physics-based character animation to both accelerate the nonlinear optimization and improve the motion quality \cite{Safonova:2004:OptPCA}. Throwing motions based on muscle synergies extracted from human experiments have been synthesized on a musculoskeletal model \cite{cruz2017synergy}. Recent DRL methods either directly imitate mocap examples \cite{Peng:2018:DeepMimic, won2020scalable}, which makes strategy discovery hard if possible; or adopt a \textit{de novo} approach with no example at all \cite{Heess2015learning}, which often results in extremely unnatural motions for human like characters. Close in spirit to our work is \cite{ranganath2019lowd-joint-coactivation}, where a low-dimensional PCA space learned from a single mocap trajectory is used as the action space of DeepMimic for tracking-based control. We aim to discover new strategies without tracking, and we use a large set of generic motions to deduce a task-and-strategy-independent natural pose space. We also add action offsets to the P-VAE output poses so that large joint activation can be achieved for powerful take-offs.

{Reduced or latent parameter spaces based on statistical analysis of poses have been used for grasping control \cite{Ciocarlie10,Andrews13,Osa18}. A Trajectory Generator (TG) can provide a compact parameterization that can enable learning of reactive policies for complex behaviors~\cite{Iscen18}.
Motion primitives can also be learned from mocap and then be composed to learn new behaviors~\cite{Peng19}.}


\subsection{History and Science of High Jump}

The high jump is one of the most technically complex, strategically nuanced, and physiologically demanding sports among all track and field events \cite{Donnelly14}. Over the past 100 years, high jump has evolved dramatically in the Olympics. Here we summarize the well-known variations \cite{SevenStyles,Donnelly14}, and we refer readers to our supplemental video for more visual illustrations.
\begin{itemize}
    \item {The Hurdle}: the jumper runs straight-on to the bar, raises one leg up to the bar, and quickly raises the other one over the bar once the first has cleared. The body clears the bar upright.
    \item {Scissor Kick}: the jumper approaches the bar diagonally, throws first the inside leg and then the other over the bar in a scissoring motion. The body clears the bar upright.
    \item {Eastern Cutoff}: the jumper takes off like the scissor kick, but extends his back and flattens out over the bar.  
    \item {Western Roll}:the jumper also approaches the bar diagonally, but the inner leg is used for the take-off, while the outer leg is thrust up to lead the body sideways over the bar.
    \item {The Straddle}: similar to Western Roll, but the jumper clears the bar face-down.
    \item {Fosbury Flop}: The jumper approaches the bar on a curved path and leans away from the bar at the take-off point to convert horizontal velocity into vertical velocity and angular momentum. In flight, the jumper progressively arches their shoulders, back, and legs in a rolling motion, and lands on their neck and back. The jumper's Center of Mass (CoM) can pass under the bar while the body arches and slide above the bar. It has been the favored high jump technique in Olympic competitions since used by Dick Fosbury in the 1968 Summer Olympics. It was concurrently developed by Debbie Brill.
\end{itemize}

In biomechanics, kinesiology, and physical education, high jumps have been analyzed to a limited extent. We adopt the force limits reported in \cite{Okuyama03} in our simulations. Dapena simulated a higher jump by making small changes to a recorded jump \cite{Dapena02}. Mathematical models of the Center of Mass (CoM) movement have been developed to offer recommendations to increase the effectiveness of high jumps~\cite{Adashevskiy13}.

% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Remove the "review" option to generate the final version.
%\usepackage[review]{acl}
\usepackage[]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}
\usepackage{multirow}
\usepackage{comment}
\usepackage{bm}
\usepackage{enumerate}
\usepackage{amsmath,amsfonts}
\usepackage{enumitem}
\usepackage{natbib}

%\setitemize{noitemsep,topsep=0pt,parsep=0pt,partopsep=0pt}


% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

\usepackage{graphicx} 
\usepackage{amsmath}
\usepackage{makecell}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.
%Toward temporal reasoning in question answering

\newcommand{\xhdr}[1]{{\noindent\bfseries #1}.}
\newcommand{\xhdrnd}[1]{{\noindent\bfseries #1}} % no dot

\newcommand{\peng}[1]{{{\color{purple!60!blue}{[peng: #1]}}}}
\newcommand{\pengnote}[1]{{{\textcolor{BurntOrange}{[pengnote: #1]}}}}
\newcommand{\jing}[1]{{{\textcolor{red}{[jing: #1]}}}}
\newcommand{\chao}[1]{{{\textcolor{teal}{[chao: #1]}}}}
\newcommand{\gt}[1]{{{\textcolor{cyan}{[gt: #1]}}}}

\def\wg{\textsuperscript{1}}
\def\ws{\textsuperscript{2}}

%\title{Time-Sensitive Question Answering over Temporal Knowledge Graphs}
\title{Improving Time Sensitivity for Question Answering over Temporal Knowledge Graphs}
%\title{Time-Sensitive Filtering in Question Answering\\ over Temporal Knowledge Graphs}
%\title{Question Answering over Temporal Knowledge Graphs via\\ Temporal Contrastive Learning}
%\title{Temporal Contrastive Learning for Time-Sensitive Question Answering over Knowledge Graphs}

%\title{ Time-Sensitive Question Answering over Knowledge Graphs via\\ Temporal Contrastive Learning}

%Temporal Contrastive Expression Enhanced
%\title{Temporal Contrastive Question Answering over Knowledge Graphs}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a seperate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

\author{
Chao Shang\wg, Guangtao Wang\wg, Peng Qi\wg, 
Jing Huang\ws
\thanks{ \hspace{1mm} Work done at JD AI Research.} \\
  \wg JD AI Research\\
  \ws Alexa AI, Amazon\\
  \texttt{\{chao.shang3, guangtao.wang, peng.qi\}@jd.com} \\ \texttt{ jhuangz@amazon.com}\\}
  


\begin{document}
\maketitle
\begin{abstract}

%\peng{
Question answering over temporal knowledge graphs (KGs) efficiently uses facts contained in a temporal KG, which records entity relations and when they occur in time, to answer natural language questions (e.g., ``Who was the president of the US before Obama?''). These questions often involve three time-related challenges that previous work fail to adequately address: 1) questions often do not specify exact timestamps of interest (e.g., ``Obama'' instead of 2000); 2) subtle lexical differences in time relations (e.g., ``before'' vs ``after''); 3) off-the-shelf temporal KG embeddings that previous work builds on ignore the temporal order of timestamps, which is crucial for answering temporal-order related questions. In this paper, we propose a time-sensitive question answering (TSQA) framework to tackle these problems. TSQA features a timestamp estimation module to infer the unwritten timestamp from the question. We also employ a time-sensitive KG encoder to inject ordering information into the temporal KG embeddings that TSQA is based on. With the help of techniques to reduce the search space for potential answers, TSQA significantly outperforms the previous state of the art on a new benchmark for question answering over temporal KGs, especially achieving a 32\% (absolute) error reduction on complex questions that require multiple steps of reasoning over facts in the temporal KG.


%, which is trained with contrastive questions to highlight the contribution of time relation words.
%Here the contrastive questions are created by replacing time words such as replacing ``before" in the question by ``after".
%\jing{we need to explain here contrastive questions, or just leave them out. Very unclear to readers.} 
%A contrastive question pair only has the temporal words as the difference like ``before" in the question to ``after")

\end{abstract}
\begin{comment}

% version 4
%Question answering over knowledge graphs (KGs) is an extensively studied direction that uses facts contained in a KG to answer natural language questions. However, few studies pay attention to the question answering on temporal KGs. \peng{$\gets$ A bit verbose to start the abstract with. Maybe something like ``Question answering over knowledge graphs (KGs) efficiently uses facts contained in a KG to answer natural language questions, but few prior work focuses on temporal KGs where facts are associated with the timestamp they occur.''? This would also give the reader a bit of background on what ``temporal KG'' is supposed to mean, if it is, as we claimed, not widely studied. Or we could even just introduce TKGQA, and leave KGQA to the Introduction: ``Question answering over temporal knowledge graphs (KGs) ...''}
Question answering over knowledge graphs (KGs) efficiently uses facts contained in a KG to answer natural language questions, but few prior work focuses on temporal KGs (TKGs) where facts are associated with the time annotations (e.g. a timestamp 1990 or a time span [1990, 1993]) they occur.
The direction to deal with QA over a TKG is to improve the time sensitivity on both the time-related expressions in questions and the time annotation in a KG. 
The main challenges for time-sensitivity are:
%TSQA deals with three limitations: 
1) many temporal questions haven't included the exact timestamp (e.g. who is the president of USA before Obama?). For temporal reasoning, we need to estimate the time and use it to find the answer; 2) Temporal QA needs the understanding of time words (e.g. before) in questions; 3) Temporal KG embeddings ignore temporal order of timestamps.
In this paper, we propose a time-sensitive question answering framework (TSQA) on temporal knowledge graphs.
TSQA is consists of a time-aware KG encoder and a time-sensitive question answering module.
The time-aware KG encoder builds the temporal connections of the facts in a KG.
%timeline \peng{what timeline?} in KG to model the orders of the quadruples \peng{what quadruples?}.
The time-sensitive QA module utilizes neighboring graph %extraction \peng{whose neighbor?} 
of the entities appeared in question
to reduce the search space of answers, performs a time estimation for answer prediction, and further integrates time-sensitive contrastive learning to capture temporal signals in free-text questions.
Empirical evaluations show that our method significantly outperforms the state-of-the-art approaches, especially achieving 82\% relative improvement in terms of Hits@1 on complex temporal questions. 


%Firstly, the time-sensitive reasoning framework for QA is proposed which learns the time-sensitive KG embeddings, narrows down the answer space by a neighbor graph extraction and estimates the time based on the temporal expressions for discovering the answer. Secondly, a set of temporal contrastive question pairs is created as data augmentation, along with a contrastive loss and a temporal order loss to model temporal differences among questions and the temporal orders of answers. 
%and understand the meaning of different temporal expressions.
%Specifically, a time-sensitive filtering based QA framework is proposed to learn the time-sensitive KG embeddings, estimate the time based on the temporal expressions, and aware the meaning of different temporal expressions...
%fit the logic of answering the temporal questions, a multi-step reasoning approach is proposed for temporal reasoning, which includes time estimation, neighbor graph selection and timeline modeling.


% version 3

%Question answering over knowledge graphs (KGs) is an extensively studied direction that uses facts contained in a KG to answer natural language questions. However, few studies pay attention to the question answering on temporal KGs. \peng{$\gets$ A bit verbose to start the abstract with. Maybe something like ``Question answering over knowledge graphs (KGs) efficiently uses facts contained in a KG to answer natural language questions, but few prior work focuses on temporal KGs where facts are associated with the timestamp they occur.''? This would also give the reader a bit of background on what ``temporal KG'' is supposed to mean, if it is, as we claimed, not widely studied. Or we could even just introduce TKGQA, and leave KGQA to the Introduction: ``Question answering over temporal knowledge graphs (KGs) ...''}
Question answering over knowledge graphs (KGs) efficiently uses facts contained in a KG to answer natural language questions, but few prior work focuses on temporal KGs where facts are associated with the timestamp they occur.
The main challenge is to discover the right occurrence time based on time expression in question and time annotation in KG. \peng{$\gets$ what does this mean? could you give a quick example to someone who is not familiar with this problem at all?}
\chao{Understand the time information including time expression in question and time annotation in KG for estimating the occurrence time and discovering the answer.}
In this paper, we propose a time-sensitive question answering framework (TSQA) on temporal knowledge graphs for time reasoning.
%including temporal annotation in edges. 
%Specifically, 
TSQA is consists of a time-aware KG encoder and a time-sensitive question answering module.
The time-aware KG encoder builds the temporal connections of the facts in a KG.
%timeline \peng{what timeline?} in KG to model the orders of the quadruples \peng{what quadruples?}.
The time-sensitive QA module utilizes neighboring graph %extraction \peng{whose neighbor?} 
of the entities appeared in question
to reduce the search space of answers, performs a time estimation for answer prediction, and further integrates time-sensitive contrastive learning to capture temporal signals in free-text questions.
Empirical evaluations show that our method significantly outperforms the state-of-the-art approaches, especially achieving 82\% relative improvement in terms of Hits@1 on complex temporal questions. 

%Overall, I think we need to a) clearly introduce what the problem is we are addressing that anyone with a basic understanding of NLP/ML could understand what we are dealing with, and b) state our solution in a way that does not use jargons that are only introduced much later in the paper.

% version 2
Question answering over knowledge graphs (KGs) is an extensively studied direction that uses facts contained in a KG to answer natural language questions. 
However, few studies pay attention to the question answering on temporal KGs.
The main challenge is to locate the occurrence time based on time expression in question and time annotation in KG.
In this paper, we propose a time-sensitive question answering model (TSQA) on temporal knowledge graphs including temporal annotation in edges. 
Firstly, to fit the logic of answering the temporal questions, a multi-step reasoning approach is proposed for temporal reasoning, which includes time estimation, neighbor graph selection and timeline modeling.
Secondly, a set of temporal contrastive question pairs is created as data augmentation, along with a contrastive loss and a temporal order loss to model temporal differences among questions and the temporal orders of answers. 
Empirical evaluations show that our method is better performing than recently proposed methods, especially on complex temporal questions.


% version 1
%Question answering over knowledge graphs (KGs) is an extensively studied direction that utilizes the structure information contained in KGs to automatically answer natural language questions. %However, the generalization of these methods to temporal question answering is not straightforward.
Question answering over knowledge graphs (KGs) is an extensively studied direction that uses facts contained in a KG to answer natural language questions. 
However, few studies pay attention to the temporal question answering (TQA) on temporal KGs.
%that requires the temporal reasoning.
%multi-step temporal reasoning
%The main challenge is to understand the difference of time expressions (e.g., before and after) in questions that could cause mutually exclusive sets of answers.
The main challenges are to locate the occurrence time using time expression in question and time annotation in KG, and to understand the difference of time expressions (e.g., before and after) in questions that could cause mutually exclusive sets of answers.
%complex reasoning
%Narrow down the occurrence time of answers
% learn the multi-step temporal reasoning.
%, and to how to model the multi-step temporal reasoning.
%One key challenge is to understand the difference of time expressions in questions that could cause mutually exclusive sets of answers. 
% temporal order of answers
%Meanwhile, there is a gap between these time expressions and timestamps in KGs.
In this paper, we propose a multi-step temporal contrastive question answering model (TSQA) on dynamic knowledge graphs with temporal annotations. %Specifically, 
Firstly, to fit the logic of answering the temporal questions, a multi-step reasoning mechanism is proposed for complex temporal reasoning, which including neighbor graph selection and time estimation.
%and answer selection.
Secondly, a set of temporal contrastive question pairs is created as data augmentation, along with a contrastive loss and a temporal order loss to model temporal differences among questions and the temporal orders of answers. 
%\chao{Since the temporal reasoning is over the timeline, a time-sensitive encoder is proposed by adding the time position embeddings to build the timeline of all facts in KG.}
%Meanwhile, since temporal expressions are the operations on timeline, a time-sensitive encoder is proposed by adding the time position embeddings to build the timeline.
Empirical evaluations show that our method is better performing than a recently proposed methods, especially on complex temporal questions.
%as data augmentation, 
%more efficient???, and 
\end{comment}


% 1. QA in temporal KG, dataset

% 2. Existing solution cannot handle one example. Why => did not consider time sensitivity.

% 3. How to handle 

\begin{comment}

Logic: 
1 purpose: Time sensitivity

3 questions and solutions.
1) temporal questions require temporal reasoning. No methods contain an element of temporal reasoning.
Time Constraints
Most of questions haven't included the exact timestamp. 
For temporal reasoning, we need to estimate the time and use it to find the answer.
Solution: For temporal reasoning, one important step is estimating the occurrence time.

2) TKGQA needs the understanding of time words in questions.

Encoding the questions by Bert has one limitation. 
Transformer-based language models are not sensitive to the differences in temporal expressions. 
Solution: Temporal contrastive learning

3) 
For TKGQA, the traditional TKG embeddings ignore temporal order of timestamps in KG (e.g. [] is earlier than []). But it is 
TKGQA based on TKG embeddings
TKGQA needs the time order.
TKG embeddings ignore temporal order of timestamps in KG.

\end{comment}

\section{Introduction}

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.99\linewidth]{example_steps.png}
  \caption{An example of complex temporal question on a temporal KG. }
  \label{fig:example}
\end{figure}

%\peng{add a brief explanation for how this question should be answered, either in the caption or somehow in the figure?}

%\peng{
Temporal knowledge graphs (KGs) record the relations between entities and the timestamp or time period when such relation hold, e.g., in the form of a quadruple: (Franklin D. Roosevelt, position held, President of USA, [1933, 1945]).
This makes them a perfect source of knowledge to answer questions that involve knowledge of when certain events occurred as well as how they are related temporally (see Figure \ref{fig:example} for an example).
Unlike question answering (QA) over non-temporal KGs that is mainly concerned with relational inference, a core challenge in temporal KGQA is correctly identifying the time of reference mentioned explicitly or implicitly in the question, and locating relevant facts by jointly reasoning over relations and timestamps.

Inspired by work on relational KGQA \citep{huang2019knowledge, saxena2020improving}, where knowledge graph embeddings \cite{dasgupta2018hyte, garcia2018learning, goel2020diachronic, wu2020temp, lacroix2020tensor} learned independently of question answering are used as input to KGQA models, previous work \cite{saxena2021question} employs temporal KG embeddings to attack the problem of temporal KGQA.
Despite its relative success on simple temporal questions that directly queries facts in the KG with one out of the four facts left as the answer (e.g., ``When was Franklin D. Roosevelt the President of USA?'' or ``What position did Franklin D. Roosevelt hold between 1933 and 1945?''), this approach still struggles to handle questions that require multiple steps of relational-temporal reasoning (e.g., the example in Figure \ref{fig:example}).
 
We identify three main challenges that hinder further progress on temporal KGQA.
Firstly, complex temporal questions often require inferring the correct point of reference in time, which is not considered by previous work.
For instance, to correctly answer the question in Figure \ref{fig:example}, it is crucial that we first identify that World War II took place between 1939 and 1945, and look for entities with the desired relation with President of USA in the time interval specified by these times.
Secondly, unlike entity relations, which are usually expressed in natural language with a handful of content words that correspond well with their recorded relations in KGs (e.g., ``What position did ... hold ...'' vs the ``position held'' relation), temporal relations often involve just one or two prepositions (e.g., ``before'' or ``during'') and are expressed only implicitly in temporal KGs (e.g., nowhere is it clearly stated that 1931 is earlier than, or before, 1934, by a gap of 3 years).
As a result, a small lexical change can drastically alter the temporal relation expressed by the question, and therefore the answer set.
Thirdly, previous work on temporal KGQA build on temporal KG embeddings, where each timestamp is assigned a randomly initialized vector representation that is jointly optimized with entity and relation representations to reconstruct quadruples in the KG from embeddings.
While sound as a standalone method for encoding knowledge in temporal KGs, this approach does not guarantee that the learned timestamp representations can recover implicit temporal relations like temporal orders or distance, which are crucial for temporal KGQA.

In this paper, we propose a time-sensitive question answering framework (TSQA) to address these challenges.
We first equip the temporal KGQA model with a time estimation module that infers the unstated timestamps from questions as the first step of reasoning, and feed the result into relational inference as a reference timestamp.
Even without explicit training data for this module, the explicit factorization of the problem yields significant improvement over previous work on complex questions that require reasoning over multiple temporal quadruples.
To improve the sensitivity of our question encoder to time relation words, we also propose auxiliary contrastive losses that contrast the answer prediction and time estimation for questions that differ only by the time relation word (e.g., ``before'' vs ``after'').
By leveraging the mutual exclusiveness of answers and the prior knowledge regarding potential time estimates from different time relation words, we observe further improvements in model performance on complex questions.
Next, to learn temporal KG embeddings with prior knowledge of temporal order and distance built in, we introduce an auxiliary loss of time-order classification between each pair of timestamp embeddings.
As a result, the knowledge in the temporal KG can be distilled into the entity, relation, and timestamp embeddings where the timestamp embeddings can naturally recover order and distance information between the underlying timestamps, thus improving the performance of temporal KGQA where such information is crucial.
Finally, we enhance TSQA with KG-based approaches to narrow the search space to speed up model training and inference, as well as reduce the number of false positives in model prediction.
As a result, TSQA outperforms the previous state of the art on the \textsc{CronQuestions} benchmark \citep{saxena2021question} by a large margin.

To summarize, our contributions in this paper are: a) we propose a time-sensitive question answering framework (TSQA) that performs time estimation for complex temporal answers; b) we present contrastive losses that improve model sensitivity to time relation words in the question; c) we propose a time-sensitive temporal KG embedding approach that benefits temporal KGQA; d) with the help of KG-based pruning technique, our TSQA model outperforms the previous state of the art by a large margin.
%}


\begin{comment}

% Background 
Question answering over knowledge graphs (KGs) \cite{lukovnikov2017neural,abujabal2017automated,huang2019knowledge,saxena2020improving, dimitrakis2020survey} is widely studied due to the creation of large-scale knowledge graphs such as Wikidata \cite{vrandevcic2014wikidata} and Freebase \cite{bollacker2008freebase}. However, few studies focus on handling the temporal question answering on the temporal knowledge graph (Temporal KGQA). 
To handle the Temporal KGQA, the key is to improve the sensitivity of time in both temporal KG and questions.
Here there are two kinds of temporal information in the temporal KGQA task as shown in Figure \ref{fig:example}: 1) a temporal knowledge graph (TKG) contains the time annotation in the edges. Each edge is associated with a time duration that is in contrast to a regular KG;  2) the temporal questions usually contain many temporal expressions such as ``before'', ``first'', and ``during'' without the exact timestamp.


One of the recent active research areas is the temporal KG embeddings where entities, relations, and timestamps are embedded in a low-dimensional vector space \cite{dasgupta2018hyte, garcia2018learning, goel2020diachronic, wu2020temp, lacroix2020tensor}. 
%They are designed for the temporal KG completion task. 
Inspired by the methods \cite{huang2019knowledge,saxena2020improving} that use KG embeddings for the KGQA task, one reasonable way to solve the Temporal KGQA is taking advantage of the temporal knowledge in embedding space for temporal question answering. 
\citet{saxena2021question} proposed CronKGQA, which is a transformer-based solution that exploits recent advances in Temporal KG embeddings for question answering.


However, previous approaches are still very challenging to deal with the temporal KGQA.
Firstly, many temporal questions haven’t included the exact timestamp so that you cannot directly predict the answer by a one-step prediction \cite{saxena2021question} that recovers the (head, relation, time, ?) and (head, relation, ?, tail) directly without any time estimation. 
It is necessary to estimate the occurrence time and use it to discover the answer.
From the example in Figure \ref{fig:example}, we cannot find the answer ``Franklin D. Roosevelt" without the time estimation. 
An important step is to use the fact (WWII, occurred, 1939, 1945, significant event) in KG and temporal question to find the occurrence time. 
%Based on this prediction, we then predict ``Franklin Delano Roosevelt'' as the answer. 
Secondly, temporal QA needs the understanding of time words (e.g. before) in questions.
These time words, such as ``before" in this example, play an important role in temporal reasoning. 
For instance, replacing ``before" with ``after" in Figure \ref{fig:example} will cause a mutually exclusive set of answers due to the nuanced differences in temporal questions that could cause different occurrence time. 
Thirdly, the temporal KGQA task is based on the TKG embeddings. Meanwhile, we need the order of timestamps to locate the occurrence time. But the TKG embedding approaches that are designed on the KG completion task ignore the temporal order of timestamps. 


% Our approach
In this paper, we proposed a time-sensitive question answering framework (TSQA) over a temporal knowledge graph to handle these challenges. 
Firstly, a time-sensitive TKC-QA model is proposed that contains time estimation-based answer prediction and a neighbor graph extraction to limit the answer space (decrease the search space by more than 20 times in our experiments) by a neighbor graph extraction. 
%fit the logic of answering the temporal questions. This mechanism contains steps of subgraph selection, time prediction, and answer selection.
Secondly, we build temporal contrastive question pairs. Here a contrastive loss and a temporal order loss are used to model temporal differences in questions and their corresponding orders. 
%(2.4\% improvement on complex questions)
Thirdly, a time-aware encoder is proposed
to embed the time order of the facts in a temporal KG by adding learnable time positional embeddings.
%utilized \peng{did we propose this, or use something off the shelf?} 
%to learn the entity and time embeddings. 
As a result, we demonstrate that TSQA significantly improves Temporal KGQA performance comparing the existing approaches.

This work makes the following contributions:

1) We propose a time-sensitive question answering framework (TSQA) on temporal knowledge graphs. Our proposed TSQA outperforms the previous state-of-the-art by a large margin.
%Here A multi-step reasoning mechanism is proposed to model the steps of locating occurrence time.

2) TSQA provides a way for complex time-sensitive reasoning. It learns the time-sensitive KG embeddings, narrows down the answer space by a neighbor graph extraction and estimates the time based on the temporal expressions. 
%the temporal KG to build the timeline and learn the time-sensitive embeddings.

3) TSQA further includes a new way to build a temporal contrastive question set as data augmentation, along with a contrastive loss and a temporal order loss to model temporal differences among questions and the temporal orders of predicted time. 
%without any additional labeling 
%and adds two losses to learn the temporal differences in questions and their corresponding orders of estimated time. 
\end{comment}

%The temporal embedding methods learned from the KG completion task only care about one fact or quadruple \peng{what does this mean? aren't the embeddings optimized over all quadruples? Did we explain what ``quadruples'' are to the reader yet?} instead of the temporal relations across multiple quadruples \peng{do we actually achieve this?}, which is vital for temporal reasoning.

%But CronKGQA directly calculates the scores with all entities and timestamps in the whole KG which limits the scalability and increases the difficulty of discovering the answers.\peng{this is suddenly very low-level and hard to follow if the reader isn't already familiar with CronKGQA or how TKGQA is usually performed in prior work.}

%for answering the temporal questions, we need to narrow down the search space. \peng{why? how large is the search space if we don't narrow it down?} \chao{135347 entities. Shrink search space by more than 20 times.}
%for better locating the occurrence time since time isn't given. 

%to model timeline 
%Thirdly, the QA mechanism in CronKGQA is the one-step prediction that recovers the (head, relation, time, ?) and (head, relation, ?, tail) directly without any time estimation. \peng{why is this bad?}


%To understanding the temporal question is a process of complex temporal reasoning, which plays an important role for QA. We should estimate the occurrence time and use it to discover the answer.
%Clearly, we observe one-step prediction cannot directly find the answer ``Franklin D. Roosevelt". 
%Here we should model the timeline to learn a timeline-sensitive KG embedding.
%explored the temporal relations between facts along the timeline, which is vital for temporal filtering. %reasoning
%For instance, in Figure \ref{fig:example}, one-step prediction cannot directly predict the answer. 
%What's more, the temporal expression, such as ``before" in this example, plays an important role in temporal reasoning. Replacing ``before" by ``after" will cause a mutually exclusive set of answers due to the nuanced differences in temporal questions that could cause different occurrence time. 




%In addition, transformer-based language models \cite{vaswani2017attention} are not sensitive to the differences in temporal expressions.
%(e.g., a answer cannot simultaneously “before” and “after” another) 
%which attracts the attention by few works \cite{ning2020torque,dhingra2021time,shang2021open,han2021econet}. The temporal words, such as before and first, play an important role to estimate the time. 
%the difference of time expressions (e.g., before and after) in questions might be able to cause mutually exclusive sets of answers.

%We should build the ability to sense the difference between these temporal expressions.



%Thirdly, traditional temporal KG representation learning methods are only caring about one fact or quadruple instead of the temporal relations contained across multiple quadruples, which is vital for temporal reasoning. The facts have their orders, such as fact (President of USA, Position Held, Ronald Reagan) is earlier than (President of USA, Position Held, William J. Clinton). Hence we need to build the connections for the facts in KG and embed these temporal orders along the timeline into embedding space. 






%we need to learn the representations for both the entities and timestamps in KG and questions. Here we need to model the timeline in KG to build the connections of facts.

%To handle this task, the QA models are motivated to have the ability to locate the occurrence time using the time expression in question and time annotation in KG. 
%It requires multiple steps for the complex temporal reasoning as shown in Figure \ref{fig:example}. 
%Firstly, using the spatial information in KG is a primary step to limit the search space of answers.
%Thirdly, it is vital to understand the logic of time expression for estimating the occurrence time. In addition, the difference of time expressions (e.g., before and after) in questions might be able to cause mutually exclusive sets of answers.

%The current methods about temporal KG representation learning haven't build the timeline and enhance the sensitiveness of these words before.
%But using the time information to build connections among quadruples is important for answering the temporal questions.

%that could cause mutually exclusive sets of answers. For example, ``Who held the position of President of USA during WWII'' ave mutually exclusive sets of answers comparing to  ``Who held the position of President of USA before WWII''.
%The current approaches [] about QA on KG haven't explored the temporal information, while the methods about temporal KG representation learning haven't build the temporal relations between facts. 


% Challenges
%The task of temporal QA on knowledge graph with timestamps or time spans is to ...
%Existing methods 
%1. Why multi-step

%The focus of this work is on temporal question answering on knowledge graph, which is the task about embedding time information in KG and answering temporal natural language questions. The temporal QA on KG is a temporal reasoning process, which contains two main challenges.


%It is vital to model the differences in temporal expressions, which helps capture mutually exclusive questions.
%
%How to temporal reasoning based on the temporal expression.
%How to embedding the time and timeline into embedding space.

%To handle the temporal QA on knowledge graph with timestamps or time spans, we follow two directions.
%However, there are two challenges to handle the temporal QA. Firstly, the temporal words, such as before and first,  play an important role to explore the location of answers. However, most of models haven't designed any approach to enhance the sensitiveness of these words. For solving this challenge, we design contrastive questions to learn the differences.


\section{Related Work}
%In this paper, we focus on how to improve the time sensitivity and answer the temporal question. 
%Hence we summarize the related papers about how to embed the temporal information from KGs and how to enhance the temporal QA. 

% TKG embeddings
\xhdr{Temporal Knowledge Graph Embedding}
Knowledge graph embedding learning \cite{bordes2013translating,yang2014embedding, trouillon2016complex, dettmers2018convolutional,shang2019end,sun2019rotate,tang2019orthogonal,ji2021survey} has been an active research area with applications directly in knowledge base completion and relation extractions.
Recently, there are several works that extended the static KG embedding models to temporal KGs. \citet{jiang2016towards} first attempt to extend TransE \cite{bordes2013translating} by adding a timestamp embedding into the score function. Later, Hyte \cite{dasgupta2018hyte} projects each timestamp with a corresponding hyperplane and utilizes the TransE score in each space. \citet{garcia2018learning} extend TransE and DistMult by utilizing recurrent neural networks to learn time-aware representations of relation types.
TCompLEx \cite{lacroix2020tensor} extends the ComplEx with time based on the canonical decomposition of tensors of order 4.


% KGQA
\xhdr{Temporal QA on Knowledge Graph}
%Most of the 
Temporal QA have mostly been studied
in the context of reading comprehension. 
ForecastQA \cite{jin2021forecastqa} formulates the forecasting problem as a multiple-choice question answering task, where both the articles and questions include the timestamps. The recent released TORQUE \cite{ning2020torque} is a dataset that explores the temporal ordering relations between events described in a passage of text. 

Another direction is the temporal question answering over knowledge bases (KB)~\cite{jia2018tequila,jia2018tempquestions}, which retrieves time information from the KB. TempQuestions \cite{jia2018tempquestions} is a KGQA dataset specifically aimed at temporal QA. 
Based on this dataset, \citet{jia2018tequila} design a method that decomposes and rewrites each question into nontemporal sub-question and temporal sub-question. Here the KG used in TempQuestions is based on a subset of FreeBase which is not a temporal KG. Later \citet{jia2021complex} proposes a first end-to-end system (EXAQT) for answering complex temporal questions, which takes advantage of the question-relevant compact subgraphs within the KG, and relational graph convolutional networks \cite{schlichtkrull2018modeling} for predicting the answers. All previous datasets only include a limited number of temporal questions. 
Recently, a much larger %largest known 
temporal KGQA dataset \textsc{CronQuestions} \cite{saxena2021question} is released, which includes both the temporal questions and the temporal KG with time annotation for all edges.
Based on this dataset, the CronKGQA model \cite{saxena2021question} is presented that exploits recent advances in Temporal KG embeddings and achieves performance superior to all baselines. 
%Following this direction, this paper explores to improve the time sensitivity for answering the complex temporal question on a temporal KG.



\begin{figure*}[ht]
  \centering
  \includegraphics[width=\textwidth]{framework_new.png}
  \caption{The architecture of our TSQA model (\textbf{Left}: Time-aware TKG encoder; \textbf{Right}: Time-Sensitive TKG-QA). 
  }
  \label{fig:architecture}
\end{figure*}

%\peng{Consider writing \S3.1, 3.2 etc next to the components and point to them? This is a fairly complex figure to read. }

\section{Method}

% 3.1+3.2 Problem definition and framework
% 3.4 Time-Sensitive TKG-QA
% 3.4.1 Question Decomposition and Encoder (but shortened)
% 3.4.3 Time-sensitive QA
% 3.4.4 Temporal contrastive learning
% 3.4.2 Neighborhood graph extraction
% 3.3 Time-aware KG Encoder


In this section, we first give the problem definition of temporal question answering over temporal knowledge graph. Then, we introduce the framework to solve this problem, which %considers \jing{not a good word, how about "integrates"?} 
integrates time sensitivity into KG embedding and answer inference. Finally, we describe the key modules of our proposed system in details.  

% In this section, we describe the proposed multi-step temporal contrastive question answering method as shown in Figure \ref{fig:architecture}. The time-aware KG encoder is focused on building the connections of facts by adding the time position embeddings which is a timeline for representation learning. With time-aware embeddings as the input, the multi-step temporal QA aims to learn the logic of answering temporal questions containing shrinking the search space by neighbor extractions, predicting the occurrence time.


\subsection{Problem Definition and Framework}

\xhdrnd{QA on Temporal KG} aims at finding out the answer from a given temporal KG $G = (\mathcal{V}, \mathcal{E}, \mathcal{R}, T)$ for a given free-text temporal question $Q$ containing implicit temporal expression, and the answer is either an entity of entity set $\mathcal{V}$ or a timestamp of timestamp set $T$. Here, $\mathcal{E} \subseteq \mathcal{V} \times \mathcal{V}$ is a set of edges, and $\mathcal{R}$ is the set of relations. 
Edge from a quadruple $(s, r, [t_s, t_e], o)$ indicates the relation $r\in \mathcal{R}$ holds between subject entity $s$ and object entity $o$ during time interval $[t_s, t_e]$ ($t_s < t_e$ and $t_{e/s}\in T$).

%Edge consist of quadruples $(s, r, [t_s, t_e], o)$ indicates the relation $r\in \mathcal{R}$ holds between subject entity $s$ and object entity $o$ during time interval $[t_s, t_e]$ ($t_s < t_e$ and $t_{e/s}\in T$).

% We consider a temporal knowledge graph $G = (V, E)$ throughout this section, where $V$ is a set of nodes with $|V| = N$, and $E \subseteq V \times V$ is a set of edges with $|E| = M$ including the relation and time. Usually, knowledge graphs are treated as many triples in form of $(s, r, o)$, where $s$ is the subject entity, $o$ is the object entity and $r$ is the relation.
% For a temporal knowledge graph, time annotation is added to the edges.
% Consider the quadruple $(s, r, [t_s, t_e], o)$, where $t_s \in T$ and $t_e \in T$ denote the start and end time and $T$ is the total number of timestamps. The $e_s$, $e_r$, $e_o$, $e_t \in R^d$ represent the embeddings of subject entity, relation, object entity and time.
% The task of QA on temporal KG aims at answering temporal questions $Q$ that concern the temporal order of these events. 
%Here the answer event set is ${E\cup T}$.



%where es, eo ∈ RLe, rp ∈ RLr are representations of s, o and p. 



%represent the relations more accurately by recovering the original triplets in the KB. Both encoder and decoder are trained jointly by minimizing the discrepancy (cross-entropy) between the embeddings $e_s +e_r$ and $e_o$ to preserve the translational property $e_s +e_r \approx e_o$. 

%\subsection{Problem Definition.}

%\subsection{Framework}
\xhdr{Framework} Our framework resorts to KG embeddings along with pretrained language models to perform temporal KGQA.  Figure~\ref{fig:architecture} shows the architecture which consists of two modules: 1) time-aware TKG encoder; 2) time-sensitive question answer. 

The time-aware TKG encoder extends the existing TKG embedding method by adding an auxiliary time-order learning task to consider the quadruple orders. And the time sensitive QA module first performs neighboring graph extraction to reduce the search space for question answer, then performs joint training for answer/time prediction and time-sensitive contrastive learning to enhance the model ability in capturing temporal signals in free-text question. Next, we will introduce these two modules in details.

\subsection{Time-aware KG Encoder}

%\gt{
We first briefly review a time-aware KG embedding method based on TCompLEx \cite{lacroix2020tensor} since it has been used in \cite{saxena2021question} for TKGQA and shows competitive performance. Next, we show that how to perform TCompLEx on temporal KG, then analyze its weakness in TKGQA especially for complex question and further overcome such weakness by introducing an auxiliary time-order learning task in TKG embedding.
%}

%%% Guangtao
%\gt{

\xhdr{TCompLEx for TKG} TCompLEx is an extension of ComplEx considering time information, which not only encodes the entity and relation to complex vectors, but also maps each timestamp to a complex vector. To perform TCompLEx over temporal KG in our problem definition, we first reformulate each quadruple to a set of new quadruples by
\begin{equation}
    (s, r, [t_s, t_e], o) = \{(s, r, t, o)| t_s \leq t \leq t_e\}
\end{equation}


Let $\bm{e}_s$, $\bm{e}_r$, $\bm{e}_t$, $\bm{e_o}\in \mathbb{C}^{d}$ be the complex-value embeddings of $s, r, t, o$, respectively. Then, TCompLEx scores each quadruple $(s, r, t, o)$ by
\begin{equation}
\mathcal{S}(s,r,o,t) = Re(\langle \bm{e}_s, \bm{e}_r, \bm{e}_o, \bm{e}_t \rangle)
\end{equation}
where Re(.) denotes the real part of a complex vector, and $\langle\rangle$ denotes the multi-linear product.
%inner product.
%trilinear product \peng{but there are four elements in this bracket?}.

%Check
%\gt{
Finally, we use a loss function similar to the negative sampling loss for effectively TCompLEx training.
\begin{equation}\label{eq:tcomplex_loss}
\begin{split}
   L_{TC} = -log(\phi(\gamma - \mathcal{S}(s,r,o,t))) \\ - \frac{1}{K}\sum_{i=1}^{K}(log(\phi(\mathcal{S}(s'_{i},r,o'_{i},t'_{i}) - \gamma))),
\end{split}
\end{equation}
where $\gamma$ is a fixed margin, $\phi$ is the sigmoid function, $(s'_{i},r,o'_{i},t'_{i})$ is the $i$-th negative quadruple.

%\gt{
According to the loss function in equation~\ref{eq:tcomplex_loss}, we observe that TCompLEx only cares about whether the quadruple is true or false and ignores the orders of different quadruples occur. However, the time orders are critical to find the correct answer in knowledge graphs. For example, to answer the `Who is the President of USA before William J. Clinton?'', we need not only the two facts (President of USA, Position Held, Ronald Reagan, [1981, 1989]) and (President of USA, Position Held, William J. Clinton, [1993, 2001]), but also the time order of these facts. To overcome such a limit of TCompLEx in TKGQA, we introduce an auxiliary time-order learning task over time-embeddings.
%which is able to imply the occurrence orders of quadruples as each quadruple includes a timestamp. 

%\peng{I think this paragraph might need to be adjusted -- we don't inherently care about the order of the facts either, just that of the timestamp embeddings?}

%\gt{
\xhdr{Time-order learning in TKG} To keep the time order in embedding spaces, we first sort the timestamps in $T$ by an ascending order and get $(t_1, t_2, \cdots, t_{|T|})$ and $t_i < t_j$ if $1\leq i < j \leq |T|$. Let $\bm{t}_i =  [Re(\bm{e}_{t_i}), Im(\bm{e}_{t_i})] \in \mathbb{R}^{2d}$ be the concatenation the real and imaginary components of embedding $\bm{e}_{t_i}$ of timestamp $t_i$. Inspired by position embedding in \cite{vaswani2017attention}, we first initialize the timestamp embedding $\bm{t}_i$ as follows.
\begin{equation}
\begin{aligned}
\bm{t}_{i}[2k] = \sin(\frac{i}{10000^{2k/2d}})\\
\bm{t}_{i}[2k + 1] = \cos(\frac{i}{10000^{2k/2d}})
\end{aligned}
\end{equation}
where $0\leq k \leq d-1$.

Afterwards, for any pair of timestamps ($t_i, t_j$),  we calculate the probability of time order as:
\begin{equation}
    p_{t}(i,j) = sigmoid((\bm{t}_1-\bm{t}_2)^T \bm{W}_{t}),
\end{equation}
where $\bm{W}_t \in \mathbb{R}^{2d}$ represents a parameter vector.

Based on the time-order probabilities, we introduce a binary cross-entropy loss as a time-order constraint over timestamp embeddings as follow:
\begin{equation}
\begin{aligned}
    L_{TO} =& -\delta(i, j)\log(p_{t}(i, j)) \\ &- (1 -\delta(i, j))\log(1 - p_{t}(i, j)),
    \end{aligned}
\end{equation}
where $\delta(i,j) = 1$ if $t_i < t_j$ else $\delta(i,j) = 0$.

\xhdr{Joint-training} 
A weighted sum of T-CompLEx training loss and time-order constraint is considered as the final objective function for the joint training for TKG embedding.
%We combine the T-CompLEx training loss and time-order constraint as the final objective function for the joint training for TKG embedding.
% \begin{equation}
%     Loss = L_{TC} + \lambda \cdot L_{TO},
% \end{equation}
% where $\lambda > 0$ is the weight factor to make tradeoffs between two losses. \peng{if we don't mention $\lambda$ later, we could just not mention this equation and introduce it as a ``weighted sum'' to save space. Also, could we replace $*$ with $\cdot$ everywhere in the paper where we use it to denote multiplication? $*$ is the mathematical symbol for functional convolution...}




\begin{comment}
Since we focus on using KG embeddings to perform temporal KGQA, we investigate how to encode the entities, relations, and timestamps from a
temporal KG in a continuous low-dimensional vector space (called embeddings). These embeddings are then used for answering the temporal questions, which usually need multiple facts and the temporal order of these facts. For example, to answer the `Who is the President of USA before William J. Clinton?'', we need not only the two facts (President of USA, Position Held, Ronald Reagan, [1981, 1989]) and (President of USA, Position Held, William J. Clinton, [1993, 2001]), but also the order of them. However, most models \cite{lacroix2020tensor,jain2020temporal} are designed for knowledge graph completion that only cares about one fact instead of the order of them. 

For solving this challenge, we investigate the way to keep the timeline in embedding space.  
In our paper, inspired by position embedding \cite{vaswani2017attention} proposed in the language model, we add learnable temporal positional encodings to KG.
We get the initial position encoding as follows:
\begin{equation}
\begin{aligned}
PE(pos, 2i) = sin(\frac{pos}{10000^{2i/d}})\\
PE(pos, 2i+1) = cos(\frac{pos}{10000^{2i/d}})
\end{aligned}
\end{equation}
where pos is the position, i is the dimension and d is the dimension of the time positional encoding. Note these encodings are used as the initial time embeddings for training the link prediction. 

Then we use a specific KG embedding model named TCompLEx \cite{lacroix2020tensor} to predict the positive and negative tuples in an incomplete temporal KG. 
The TCompLEx is an extension of ComplEx with time. Each timestamp t is represented as a vector $e_t$.  Here the TComplEx scoring
function is
\begin{equation}
\mathcal{S}(s,r,o,t) = Re(\langle e_s, e_r, e_o, e_t \rangle)
\end{equation}
where Re(.) denotes the real part of a complex vector, and $\langle\rangle$ denotes the trilinear product.

In addition to this score function, in order to encode the order of timestamps, we add a simple temporal order loss as follow:
\begin{equation}
\mathcal{L}(t_1, t_2) = sigmoid((t_1-t_2)^T W)
\end{equation}
where $W \in R^{d}$ is the parameter vector.

\end{comment}

%\subsection{Multi-step Temporal QA}
\subsection{Time-Sensitive TKG-QA}

%\gt{
In this section, we introduce our time-sensitive question answering module from the following aspects in details: 1) question decomposition which divides the questions as entities and relations described in free-text; 2) entity neighboring sub-graph extraction which reduces the search space of candidate timestamps and answer entities; and 3) time-sensitive question answer which explores the time information implied in both KG and questions to help the model find the answer.
%}

\begin{comment}
In this section, a multi-step temporal QA framework is proposed for temporal reasoning.
To answer a temporal question, multiple steps are needed including limiting the scope of candidates to identify the exact answer, understanding the temporal expression, locating the occurrence time, and then finding the answers. 
%In our model, combination of time prediction and entity prediction fits this logic that includes the step to narrow down the time scope for finding the answers.
Importantly, a model that has the sensitiveness of the temporal expressions and their nuanced difference of time expressions (e.g., before and after) will be important for answering the questions.
\end{comment}

\subsubsection{Question Decomposition and Encoder}
\label{sec3_5}

% How to define the subject and object?
%\gt{
For each question $Q$, we first identify all the entities \{Ent$_1$, Ent$_2$, $\cdots$, Ent$_k$\} in $Q$ which also appear in KG $G$, i.e., Ent$_i \in E$ ($1\leq i \leq k$).
Then, by replacing the entities in question $Q$ with special token [\textit{subject}] and [\textit{object}] in order, we obtain an entity-independent temporal relation description in free-text named \textbf{temporal expression} $\hat{Q}$.
%in this paper.
%Then, by replacing the last entity Ent$_k$ in question $Q$ with a special token [\textit{subject}] and all the other entities with a special token [\textit{object}], we get an entity-independent temporal relation description in free-text named \textbf{temporal expression} $\hat{Q}$ in this paper.
%}

Taking the question ``When did \textbf{Obama} hold the position of \textbf{President of USA}?'' as an example, by replacing the identified entities ``President of USA'' and ``Obama'', we get its temporal expression as ``When did \textbf{\textit{subject}} hold the position of \textbf{\textit{object}}?''.

%\gt{
%Taking the question ``Who held the position of \textbf{President of USA} before \textbf{WWII}?'' as an example, ``President of USA'' and ``WWII'' are two identified entities. Then, the temporal expression w.r.t. such question in ``Who held the position of \textbf{\textit{object}} before \textbf{\textit{subject}}?''

%\gt{
%Once we get the question temporal expression $\hat{Q}$, we 
Next [CLS] + $\hat{Q}$ are fed into BERT that outputs [CLS] token embedding as $\bm{e}_{q}\in \mathbb{R}^{d_{bert}}$, where $d_{bert}$ is the output dimension of BERT, and two kinds of question representations as follows.
\begin{align}
    \bm{q}_r = \bm{W}_{q}^{r}(\delta(\bm{W}\bm{e}_{q}))\\
    \bm{q}_t = \bm{W}_{q}^{t}(\delta(\bm{W}\bm{e}_{q})),
\end{align}
where $\bm{q}_r,  \bm{q}_t \in \mathbb{R}^{2d}$ represents the embedding of relation and time implied in question, respectively. $\bm{W}\in {\mathbb{R}^{d_{bert}\times 2d}}$, $\bm{W}_{q}^{r}$, $\bm{W}_{q}^{t} \in \mathbb{R}^{ 2d \times 2d}$ are the parameter matrix, and $\delta$ represents the activation function. Finally, to facilitate the calculation with KG embeddings, we reformulate $\bm{q}_r, \bm{q}_t$ in complex space as:
\begin{align}
    \bm{q}_r = \bm{q}_r[0:d] + \sqrt{-1} \cdot \bm{q}_r[d:2d]\\
    \bm{q}_t = \bm{q}_t[0:d] + \sqrt{-1} \cdot \bm{q}_t[d:2d]
\end{align}


% \begin{align}
%     \bm{q}_r = \bm{q}_r[0:d] + i * \bm{q}_r[d:2d]\\
%     \bm{q}_t = \bm{q}_t[0:d] + i * \bm{q}_t[d:2d]
% \end{align}
% \peng{where $i=\sqrt{-1}$. (Could we use $j$ or just $\sqrt{-1}$ instead? $i$ is already used around line 318 to index entities)}


% \gt{\textbf{what kinds of temporal expression is feed into BERT, how to make use of the special token [\textit{time}]}}

%\noindent \textbf{Temporal Knowledge Graph Embedding.}
\subsubsection{Entity Neighbor Graph Extraction}


%\gt{
Let \{Ent$_1$, Ent$_2$, $\cdots$, Ent$_k$\} be the $k$ entities extracted from question $Q$, we first extract the $m$-hop neighboring sub-graph $G_i$ for each entity Ent$_i$. Then, by combining these $k$ sub-graphs, we obtain the search graph $G_q$ for question $Q$: $G_q =  	\cup_{i=1}^{k}G_i$. Suppose that $E_q$ and $T_q$ are the sets of entities and timestamps appearing in $G_{q}$, respectively, they constitute the search space of time and entity prediction in our TKG-QA method. In training stage, we set the hop number $m$ as the minimum value which results in correct answer entity appearing in $G_q$. In testing stage, we set $m$ as the largest hop number used in training stage. In practice, the size of graph $G_q$ in usually much smaller than that of whole graph $G$. For example, in CronKGQA, 
the average value of $|G_q|/|G|$ is about 3\%.

%\gt{
Entity Neighboring graph extraction aims at reducing the search space of candidate timestamps and answer entities.
%and is performed based on entities extracted from question. 
This results in not only more efficient training procedure, but also performance improvement of question answer because a larger number of candidates usually means a much more difficult learning problem. 
%\jing{Chao, please first write how the subgraphs are used. Then talking about the benefit. These sentences are not readable.}


%the average size of entities in $G_q$ divides the number of entities in $G$ is about 3\%.
%the average value of $|G_q|/|G|$ is about 3\%.
%? 1-hop

 

%The union of all sub-graphs extracted based on each anchor entity appearing in question.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{comment}

The CronKGQA \cite{saxena2021question} approach works by learning low-dimensional vector embeddings of entities and timestamps in KG and searching the answers from all of them. Inspired by information retrieval systems methods, we retrieve a broad set of candidate answers by extracting the neighbor graph $G_q$ using the entities of questions. Hence we get fine-grained candidates from the neighbor graph to identify the exact answer. The facts in the neighbor graph provide us with an answer space that includes the entity candidates and timestamp candidates. The neighbor graph $G_q$ is extracted directly using the n-hop neighbors of entities in question. Let $E_q$ and $T_q$ be the set of entities and the set of timestamps in $G_q$ respectively for question $q$.

\subsubsection{Temporal Expression Encoder}
\label{sec3_3_2}

For each question, we decompose it into question entities and a temporal expression template (e.g. ``Who held the position of $[object]$ before $[subject]$?''). Here we added three special tokens $[subject]$, $[object]$ and $[time]$ into the Bert-based model.  Using the temporal expression template instead of the whole question allows us to learn context-agnostic representations of temporal relations that generalize across questions that have different entities but the similar temporal expressions. 

A temporal expression encoder is utilized to encode each temporal expression template with a pretrained language model (use BERT in our experiments) to get the temporal relation embeddings. 
In details, we design to combine BERT with linear layers to get two temporal relation embeddings: $r_{time}$ and $r_{entity}$.  The $r_{time}$ will be used to do the time estimation and $r_{entity}$ will be used for the entity prediction.
\end{comment}

% \subsubsection{Time-based Reasoning}
\subsubsection{Time-Sensitive Question Answering}
\label{tbreasoning}

% \xhdr{Time Aware joint training for answer prediction}

% \xhdr{Time sensitive contrastive learning}
% Time contrastive question generation $\rightarrow$ how to generate contrastive question pair.
% \begin{itemize}
%     \item contrastive time order learning
%     \item contrastive answer learning
%     \item Joint training with question answer
% \end{itemize}

%Answering the temporal natural language questions requires temporal reasoning. Although CronKGQA \cite{saxena2021question} achieves great performance on simple temporal reasoning questions with the one step reasoning, its performance drop significantly when it comes to temporal questions requiring more complex reasoning.

%\gt{
For temporal question answer over KG, the interaction of time and answer entity prediction is very important since the time range brings a strong constraint on the search space of answers. However, the existing method \cite{saxena2021question} usually performs such two predictions independently which results in poor performance especially for complex questions which need to consider multiple facts to get the answer. To overcome this limitation, we directly feed the intermediate time representation $t_q$ learned from time estimation to answer prediction to enhance the interaction of these two tasks.
%}

%\noindent \textbf{Timestamp Estimation.}
\noindent \textbf{Time Estimation.}
%\gt{
Based on the embeddings $\bm{e}_s$ and $\bm{e}_o$ of subject entity $s$ and object entity $o$ from KG and the time embedding $\bm{q}_{t}$ from a question, we design the time estimation function $F_T$ for learning the time embedding $\bm{t}_q$ as follows:\footnote{A simple temporal question might contain the timestamp (e.g. 2001). In this case, we set $\bm{t}_q$ as the linear combination of this learned time embedding and the timestamp embedding from KG.} 
\begin{equation}
\begin{aligned}
\bm{t}_q &=  F_T(\bm{e}_s, \bm{q}_{t}, \bm{e}_o) \\
 & =  \bm{W}_{q}^{t}([Re(\langle \bm{e}_s, \bm{q}_{t}, \bm{e}_o\rangle), Im(\langle \bm{e}_s, \bm{q}_{t}, \bm{e}_o\rangle)]),
\end{aligned}
\label{eqa_time_emb}
\end{equation}
where $\bm{W}_{q}^{t} \in \mathbb{R}^{2d\times 2d}$ represents the parameter matrix. [.] is the concatenation function, $Re(.)$ denotes the real part of a complex vector and $Im(.)$ is the imaginary part.

After getting the time embedding w.r.t. question $\bm{t}_q$, for timestamp prediction, the following score function to estimate the score for each timestamp $t \in T_q$ as follow:
\begin{equation}
\mathcal{S}_t = Re(\langle \bm{t}_q, \bm{t} \rangle)
\end{equation}
%\gt{Adding cross entropy loss $L_{time}$ for optimization}


\xhdr{Entity Prediction} In enhance the interaction between time prediction and answer prediction, we update the embedding of entity w.r.t. question by considering time embedding $\bm{t_{q}}$ by an entity function $F_E$ as follow:
\begin{equation}
\bm{e}_q = F_E(\bm{e}_s, \bm{q}_r, \bm{t}_q) = \langle \bm{e}_s, \bm{q}_r, \bm{t}_q \rangle
\end{equation}
Finally, we score the entity $e\in E_{q}$ by:
\begin{equation}
\mathcal{S}_e = Re(\langle \bm{e}_q, \bm{e} \rangle)
\end{equation}

%\gt{Adding cross entropy loss $L_{ans}$ for optimization}

%\gt{
%According to the problem definition, 
The answer entity of the question is either timestamp or entity. Let $\mathcal{S}_a$ be the answer score and thus $\mathcal{S}_a = \mathcal{S}_t$ or $\mathcal{S}_e$ when the answer is timestamp or entity. Suppose $C$ represents the number of candidate answers (i.e., $C$ = $|E_{q}| + |T_{q}|$), then we can define the probability of $i$-th candidate answer being true as:
\begin{equation}
    P_{a,i} = \frac{\exp(\mathcal{S}_{a,i})}{\sum_{j=1}^{C}\exp(\mathcal{S}_{a,j}))}.
\end{equation}
Finally, we train the answer prediction model by minimizing the cross-entropy loss as follow:
\begin{equation}
    L_{answer}  = -\sum_{i}^{C} \bm{y}_{i} \log(P_{a,i}),
\end{equation}
where $\bm{y}_i$ = 1 if the $i$-th candidate is the true answer, otherwise $\bm{y}_i$ = 0.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{comment}

For each question, since we don't know the answer type, we combine the score $\mathcal{S}_t$ and $\mathcal{S}_e$ together: $S = [\mathcal{S}_t, \mathcal{S}_e]$. Here the dimension of $S$ is $C$. The probability $p_{answer}$ could be get 
\begin{equation}
p_{answer,i} = \frac{S_j}{\sum_{j}^{C} S_j}
\end{equation}


Then, we minimize the cross-entropy loss function
\begin{equation}
L_{answer}  = -\sum_{i}^{C} y_{i} log(p_{answer,i}),
\end{equation}
where $y$ is the answer label of a question. 


A temporal estimation step is designed to locate the right occurrence time. We extract a subject entity s and a \textbf{timestamp t} from the question. If either is missing, we will use the existing embedding as $e_s$ and $e_o$.
Based on the embeddings of subject entity s and object entity o from KG and the temporal relation embedding $r_{time}$ from a question, we design our time estimation function $F_T$ for learning the time embedding $t'_q$ as follows:
\begin{equation}
% \centering
\begin{aligned}
\bm{t}'_q &=  F_T(\bm{e}_s, \bm{q}_{t}, \bm{e}_o) \\
 & =  L_q([Re(\langle e_s, r_{time}, e_o\rangle), Im(\langle e_s, r_{time}, e_o\rangle)]) 
\end{aligned}
\end{equation}
where [.] is the concatenation function, $L_q$ is a linear function. $Re(.)$ denotes the real part of a complex vector and $Im(.)$ is the imaginary part.

Since some simple temporal questions might contain the timestamp directly, we could get the $time_q$ from a question. If the numerical timestamp is missing, we use a dummy time embedding instead. Then we get the final time estimation:
\begin{equation}
t_q = L_c([t'_q, time_q])
\label{eq5}
\end{equation}
where $L_c$ is a linear function.

After getting the vector of time estimation, if the answer type of a question is time, the following score function is able to get the scores
\begin{equation}
\mathcal{S}_t = Re(\langle t_q, t \rangle), t \in T_q 
\end{equation}

\noindent \textbf{Entity Answer Prediction.}
After getting the predicted time representation $t_q$, we first calculate the object entity embedding $e_q$ using entity function $F_E$
\begin{equation}
e_q = F_E(e_s, r_{entity}, t_q) = \langle e_s, r_{entity}, t_q \rangle
\end{equation}

Similar to the time estimation, the score function for entity is 
\begin{equation}
\mathcal{S}_e = Re(\langle e_q, e \rangle), e \in E_q
\end{equation}

\end{comment}

\subsubsection{Temporal Contrastive Learning}

%\gt{
The temporal question answer system should be sensitive to the temporal relation implied in the question. For example, the answer of ``What does happen before a given event?'' is quite different from that of ``What does happen after a given event?''. Existing works on TKG-QA usually resort to pre-trained language models for question understanding. But these models are not sensitive to the difference of temporal expressions in free-text~\cite{ning2020torque,dhingra2021time,shang2021open,han2021econet}, and thus prone to wrong predictions. 

To make the system %be able to accurately capture 
sensitive to the temporal relation implied in question, we resort to a contrastive learning method: %to improve the system's sensitivity to the changes of temporal expressions. 
we construct a contrastive question to the original question, then add auxiliary contrastive learning tasks to distinguish the latent temporal representation and prediction results coming from the pair of contrastive questions.
%}

%Transformer-based pre-trained language models are not sensitive to the differences in temporal expressions. This attracts the attention by few works \cite{ning2020torque,dhingra2021time,shang2021open,han2021econet}.The temporal words, such as before and first, play an important role to estimate the time. In this section, we explore to build the contrastive set for improve the sensitivity of the differences in temporal expressions.

%\gt{
\xhdr{Contrastive Question Generation} To generate the contrastive question $\bar{Q}$ for the given question $Q$, we first extract all the temporal words based on large number of questions in temporal question answer dataset, and then build a contrastive word pair dictionary by finding the antonyms. The dictionary consists of $\mathcal{D}_{contr}$ = \{(first, last), (before, after), (before, during), (during, after), (before, when), (when, after)\}. Based on such dictionary, we replace the temporal word in given question $Q$ by its antonym to generate its contrastive question $\bar{Q}$.
%}


%\xhdr{Contrastive Question Generation} In order to improve the sensitivity of the differences in temporal expressions, we design and create a contrastive question set using the existing temporal questions.

%The way to build this set is to replace the time words. Here is the dictionary for word replacement:

%\{$first \Longleftrightarrow last$, $before \Longleftrightarrow after$, $before \Longleftrightarrow during$, $after \Longleftrightarrow during$, $before \Longleftrightarrow when$, $after \Longleftrightarrow when$\}


\xhdr{Contrastive time order learning} For the contrastive question pair $Q$ and $\bar{Q}$, we follow the same encoder in Eq. \ref{eqa_time_emb} to get the corresponding time-aware embeddings $\bm{t}_q$ and $\bm{t}_{q_c}$, respectively. Meanwhile, according to the contrastive temporal word pair dictionary, suppose that we pickup the pair (word$_1$, word$_2$) $\in \mathcal{D}_{contr}$ for contrastive question construction, we can construct a question order label $y_o$: $y_o$ = 0 if $\bar{Q}$ is achieved by replacing word$_1$ as word$_2$, else $y_o$ = 1.

Afterward, we distinguish the temporal orders implied by word$_1$ and word$_2$ by predicting of the order label $y_o$ based on $\bm{t}_q$ and $\bm{t}_{q_c}$ as follow:
\begin{align}
    p_o & = sigmoid((\bm{t}_{q} - \bm{t}_{q_c})^{T}\bm{W}_o)\\
    \mathcal{L}_{\text{order}} & = -{{y}_o \log(p_{o})} - {(1-{y}_o) \log(1-p_{o})},
\end{align}
where $\bm{W}_o \in \mathbb{R}^{2d}$ represents the parameter vector to be learned.
%}


%\xhdr{Contrastive Temporal Order Learning}
%From equation \ref{eqa_time_emb}, the time estimation for each question is learned. Hence, we get two time embedding of $t_{q}$ and $t_{q_c}$ for a contrastive question pair $(q, q_c)$. $q_c$ is the contrastive question of $q$. The order prediction is a binary classification task including \{``left", ``right"\}. For instance, ``Who held the position of $[object]$ before $[subject]$?'' is happened before the ``Who held the position of $[object]$ after $[subject]$?'' so that the label is ``left".

%Then we design a order prediction function to predict the order of two time embeddings
%\begin{equation}
%P_o = sigmoid((\bm{t}_{q} - \bm{t}_{q_c})^{T}\bm{W}_o)
%\end{equation}
% where $\bm{W}_o \in \mathbb{R}^2d$ contains the parameters of this function. The order prediction task aims to optimize the following loss function:
% \begin{equation}
% \begin{aligned}
% \mathcal{L}_{\text{order}} = &-{\frac{1}{n}} \sum_{i=1}^{n}  {\Tilde{y}_i \log(P_{o,i})} \\
% &+ {(1-\Tilde{y}_i) \log(1-P_{o,i})}
% \end{aligned}
% \end{equation}
% where $\Tilde{y}$ is the label of the order. 
% Here we use $\alpha$ as the weight of loss $\mathcal{L}_{\text{order}}$.

%\gt{
\xhdr{Answer-guided Contrastive Learning} Let $\bm{S} = [\bm{s}_{1}, \cdots, \bm{s}_{C}]$, $\bm{\bar{S}} = [\bm{s}_{1}, \cdots, \bm{s}_{C}]$ be the answer scores w.r.t. questions $Q$ and its contrastive question $\bar{Q}$, respectively, where $C = |E_q| + |T_q|$. By stacking these two scores together, we get $\bm{S}_{q}$ = $[\bm{{S}}; \bm{\bar{S}}]\in \mathbb{R}^{2\times C}$. Then, we can apply softmax over $\bm{S}_{q}$ along the last dimension and get the probability scores $\bm{P}_{q} =softmax(\bm{S}_{q})\in \mathbb{R}^{2\times C}$ and $sum(\bm{P}_{q}[:,i]) = 1$ for $i= 1, \cdots, C$.
%}

% Due to the fact that the answers of question ${Q}$ are definitely not for question $\hat{Q}$, we can construct an answer-guided learning labels as $\bm{y}_{a} = [y_{a,1},\cdots, y_{a,C}]$ where $y_{a,i}$ = 1 if and only if the $i$-th candidate is true answer for ${Q}$. Then, we can get an answer-guided contrastive loss as follow:
% \begin{equation}
%     \mathcal{L}_{\text{contrast}} = -{\frac{1}{C}}\sum_{i=0}^{C} \bm{y}_{a,i} \log(\bm{P}_{q}[0,i])
% \end{equation}

%\gt{
Due to the fact that the answers of question ${Q}$ are definitely not for question $\bar{Q}$, we construct an answer-guided learning labels as $\bm{y}_{a} = [y_1,\cdots, y_C]$, where $y_i$ = 1 if and only if the $i$-th candidate is true answer for ${Q}$, otherwise $\bm{y}_i$ = 0. Then, we get an answer-guided contrastive loss as follow:
\begin{equation}
    \mathcal{L}_{\text{contrast}} = -{\frac{1}{C}}\sum_{j=0}^{C}{y}_i\log(\bm{P}_{q}[0,i])
\end{equation}
%}

% \xhdr{Answer-guided Contrastive Learning} For a given question $i$ ($1\leq i \leq N$), we could get the scores of all candidates as $\bm{S}_{i} = [\bm{s}_{i,0}, \cdots, \bm{s}_{i,m}]$, here $m = |E_q| + |T_q|$.
% By concatenating scores of two questions together, we can get a score tensor as $\bm{S} = [\bm{S}_{1};\bm{S}_{2}] \in \mathcal{R}^{2\times m }$. Then, we can get the probability of each word being an event as follow:
% \begin{equation}
%     \bm{z}_{i,j} = \frac{\exp(\bm{S}_{ij})}{\sum_{l=1}^2\exp(\bm{S}_{il})} 
% \end{equation}
% where $\bm{z}_{i,j}$ represents the probability of entity or timestamp $j$ being an answer event w.r.t. question $i$ ($1\leq i \leq N$, $1\leq j \leq m$). 

% For each candidate, we use the one-hot $\bm{\hat{y}} = [1, 0]$ as label. Then, the contrastive constraint aims to optimize the following loss function:
% \begin{equation}
%     \mathcal{L}_{\text{contrast}} = -{\frac{1}{m}}\sum_{j=0}^{m}  o_{j} \bm{\hat{y}_j}log(\bm{z}_{j})
% \end{equation}
% where $O=\{o_0, \cdots,o_m\}$ is a binary answer indicator (1 or 0) for original question with label.
% Here we use $\beta$ as the weight of loss $\mathcal{L}_{\text{contrast}}$.

%\gt{
\xhdr{Joint Training} We combine the answer prediction loss and contrastive losses as the final objective function for joint training:
\begin{equation}
    Loss = \mathcal{L}_{answer} + \lambda_{o} \cdot \mathcal{L}_{order} + \lambda_{c} \cdot \mathcal{L}_{contrast},
\end{equation}
where $\lambda_{o} > 0$, $\lambda_{c} >0$ are the weight factors to make tradeoffs between different losses.
%} 



\section{Experiments}
In this section, we conduct experiments to assess the effectiveness of our proposed method TSQA for TKG-QA. 
Our experimental results show that our approach obtains significant improvements over the baseline models.

\begin{table}[!ht]
    \centering 
    \small
    \begin{tabular}{c|c|c|c}
    \hline
    Category & Train & Dev &  Test \\ \hline \hline
    Simple Entity & 90,651 & 7,745 & 7,812 \\ 
    Simple Time & 61,471 & 5,197 & 5,046 \\ 
    Before/After & 23,869 & 1,982 & 2,151\\ 
    First/Last& 118,556& 11,198& 11,159\\ 
    Time Join& 55,453& 3,878& 3,832\\ 
    \hline  
    Entity Answer & 225,672&  19,362&  19,524\\ 
    Time Answer&  124,328&  10,638&  10,476\\ 
    \hline 
    Total&  350,000&  30,000&  30,000\\ 
    \hline 
    \end{tabular}
    \caption{\textsc{CronQuestions} dataset statistics as well as the numbers of questions across different types of reasoning required and answer types.}
    \label{DatasetStats}
\end{table}

\subsection{Experimental Setup}

\xhdr{Data} \textsc{CronQuestions}\footnote{\url{https://github.com/apoorvumang/CronKGQA}} is the largest known Temporal KGQA dataset consisting of two parts: a KG with temporal annotations, and a set of free-text questions requiring temporal reasoning. This Temporal KG has 125k entities and 328k facts (quadruples), while a set of 410k questions is given. The facts have the time spans in the edge. These time spans or timestamps were discretized to years.

%\peng{maybe first mention that there are entity questions and time questions? otherwise I'm afraid \textit{simple entity} and \textit{simple time} wouldn't make much sense on their own}

%\peng{
This dataset consists of questions that can be categorized into two groups based on their answer type: entity questions where the answer is an entity in the KG, and time questions where the answer is a timestamp.
The authors also categorize these questions into ``simple reasoning'' (including \textit{simple entity} and \textit{simple time} subtypes) and ``complex reasoning'' (including \textit{before/after}, \textit{first/last} and \textit{time join} subtypes). 
%\peng{remove: From another perspective, based on the answer type, the questions can also be categorized into two groups: entity questions including ``entity answer'' and  time questions including ``time answer''.} 
Table \ref{DatasetStats} provides the number of questions across different categories. Complex questions require complex temporal reasoning which takes advantage of multiple facts and temporal order of these facts.

\begin{table*}[!ht]
    \centering
    \small
    \begin{tabular}{c||c|c|c|c|c||c|c|c|c|c}
      \hline
      \multirow{3}{4em}{Model}  &  \multicolumn{5}{c||}{Hits@1} &  \multicolumn{5}{c}{Hits@10}  \\ 
      %\hline 
      \cline{2-11}
       &  & \multicolumn{2}{c|}{Question Type}& \multicolumn{2}{c||}{Answer Type} &  & \multicolumn{2}{c|}{Question Type}& \multicolumn{2}{c}{Answer Type}\\
      %\hline 
      \cline{2-11}
       & Overall & Complex & Simple & Entity & Time & Overall & Complex & Simple & Entity & Time  \\ \hline 
      %BERT & 0.071 & 0.086 & 0.052 & 0.077 & 0.06 & 0.213 & 0.205 &  0.225 & 0.192 & 0.253 \\
      %\hline 
      %\hline 
      %RoBERTa & 0.070 & 0.086 & 0.050 & 0.082 & 0.048 & 0.202 & 0.192 & 0.215 & 0.186 & 0.231 \\
      %\hline
      EmbedKGQA & 0.288 & 0.286 & 0.290 & 0.411 & 0.057 & 0.672 & 0.632 & 0.725 & 0.850 & 0.341 \\
      T-EaE-add & 0.278 &0.257& 0.306& 0.313& 0.213& 0.663& 0.614& 0.729& 0.662& 0.665 \\
      T-EaE-replace & 0.288 &0.257& 0.329& 0.318& 0.231& 0.678& 0.623& 0.753& 0.668& 0.698 \\
      CronKGQA & 0.647 & 0.392 & 0.987 & 0.699 & 0.549 & 0.884 & 0.802 & 0.992 & 0.898 & 0.857 \\
      %CRONKGQA+T & 0.661 &0.412 &0.989& 0.719 &0.556 &0.884 & 0.801 &0.992 &0.893 &0.866\\
      \hline
      %TSQA(Two-step) & 0.757 & 0.583 & 0.986 & 0.797 & 0.687 & 0.941 & 0.901 & 0.993 & 0.948 & 0.928 \\
      %TSQA-M & 0.816 & 0.688 & 0.985 & 0.816 & 0.818 & 0.978 & 0.964 & 0.997 & 0.980 & 0.975 \\
      %TSQA-P & 0.821 & 0.696 & 0.984 & 0.820 & 0.822 & 0.979 & 0.966 & 0.997 & 0.980 & 0.977 \\
      TSQA & \textbf{0.831} & \textbf{0.713} & \textbf{0.987} & \textbf{0.829} & \textbf{0.836} & \textbf{0.980} & \textbf{0.968} & \textbf{0.997} & \textbf{0.981} & \textbf{0.978} \\
      \hline
    \end{tabular} 
    \caption{Comparison of different TKG-QA models on \textsc{CronQuestions} dataset.}
    \label{ResultsTable2}
    %\bigskip
\end{table*}

\smallskip
\xhdrnd{Evaluation Metrics} include Hits@1 and Hits@10 , which is the standard evaluation metrics on \textsc{CronQuestions}~\cite{saxena2021question}.

\smallskip
\xhdr{Hyper-parameter setting} We train the TSQA models by setting the hyper-parameters as: learning rate = $\{$1$e^{-4}$, 2$e^{-5}$, 1$e^{-5}$ $\}$, $\lambda_{o}$ = $\{$0.5, 1.0, 2.0, 3.0, 5.0$\}$ and $\lambda_{c}$ = $\{$0.5, 1.0, 2.0, 3.0, 5.0$\}$, and pick up the best hyper-parameters on dev set % \jing{do you have dev data? or just tune on test data?} 
by the overall Hits@1 metrics. 
Our models are implemented by PyTorch and trained using NVIDIA Tesla V100 GPUs.
%For the loss function, we use the $\alpha=0.5$, $\beta=0.6$. 

\smallskip
\xhdr{Baselines} We select several recent SOTA TKG-QA models as our baselines as follow:
%Firstly, BERT, RoBERTa which are a variant of BERT are able to capture real world knowledge. Hence they can directly be applied to QA tasks. Here the version of the temporal KG in \textsc{CronQuestions} hasn't been used in these models.
\begin{itemize}[leftmargin=*]
    \item  EmbedKGQA \cite{saxena2020improving} is the first method to use KG embeddings for the multi-hop KGQA task. It uses ComplEx~\cite{trouillon2016complex} embeddings and can only deal with non-temporal KGs and single entity questions.

    \item T-EaE-add/replacement~\cite{saxena2021question} are two modifications of KG enhanced language model EaE~\cite{fevry2020entities}, which integrates entity knowledge into a transformer-based language model and has been used for TKG-QA~\cite{saxena2020improving}. T-EaE-add has all grounded entities and time spans marked in the question, and T-EaE-replace replaces the BERT embeddings with the entity/time embeddings instead of adding them with token embeddings.
    
    \item CronKGQA \cite{saxena2021question} extends EmbedKGQA to the temporal QA task, and takes advantage of the temporal KG embeddings to answering temporal questions. This is the current SOTA model on \textsc{CronQuestions}.
\end{itemize}

% Firstly, EmbedKGQA \cite{saxena2020improving} is the first method to use KG embeddings for
% % for the multi-hop KGQA task. EmbedKGQA uses ComplEx \cite{trouillon2016complex} embeddings and can only deal with non-temporal KGs and single entity question.

% Secondly, EaE \cite{fevry2020entities} provides a method to integrate entity knowledge into a transformer-based language model. \citet{saxena2021question} provided two modifications of EaE. T-EaE-add has the all grounded entities and time spans marked in the question, while T-EaE-replace replace the BERT embeddings with the entity/time embeddings intead of adding them with token embeddings.

% Thirdly, to extend EmbedKGQA to the temporal QA task, CronKGQA \cite{saxena2021question} is proposed. It taks advantage of the temporal KG embeddings to answering temporal questions.


\subsection{Main Results}
Table \ref{ResultsTable2} compares different TKG-QA methods in terms of Hits@1 and Hits@10. From this table, we observe that: 1) our proposed TSQA has achieved state-of-the-art performance in terms of all types of questions on both Hits@1 and Hits@10. 2) The performance improvement over the SOTA model is significant. TSQA outperforms the SOTA results by more than 82\% Hits@1 relative improvement (32\% absolute error reduction) on complex questions and 21\% Hits@10 relative improvement on simple questions.
These results proved the excellent performance of our proposed TSQA on question answering on the temporal knowledge graph, especially for complex temporal reasoning.

\begin{table}[!ht]
    \centering
    \small
    \resizebox{.48
\textwidth}{!}{
    \begin{tabular}{c||c|c|c|c|c}
    % \begin{tabular}{p{1.65cm}||p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}|p{0.7cm}}
    %\begin{tabular}{p{1.65cm}||c|c|c|c|c}
      %\hline
      %\multirow{3}{4em}{Model}  &  \multicolumn{5}{c||}{Hits@1}  \\ 
      %\hline 
      %\cline{2-11}
      % &  & \multicolumn{2}{c|}{Question Type}& \multicolumn{2}{c}{Answer Type} \\
      \hline 
      %\cline{2-11}
      Question type & \makecell[c]{Before\\After} & \makecell[c]{First\\Last} & \makecell[c]{Time\\Join} & \makecell[c]{Simple\\Entity} & \makecell[c]{Simple\\Time}   \\ 
      \hline 
      EmbedKGQA & 0.199 &  0.324 & 0.223 & 0.421 & 0.087   \\
      T-EaE-add &0.256& 0.285& 0.175& 0.296& 0.321  \\
      T-EaE-replace& 0.256& 0.288& 0.168& 0.318& 0.346 \\
      CronKGQA & 0.288 & 0.371& 0.511& 0.988& 0.985 \\
      \hline
      TSQA & \textbf{0.504} & \textbf{0.721} & \textbf{0.799} & \textbf{0.988} & \textbf{0.987} \\
      %TSQA & -- & -- & -- & -- & -- \\
      \hline
    \end{tabular} 
    }
    \caption{Comparison of different models w.r.t. question type in terms of Hits@1.}
    \label{ResultsTable3}
\end{table}

We also compare our method with baselines in terms of Hits@1 on different subtype questions in Table \ref{ResultsTable3}. From this table, we observe that: on complex questions, our proposed TSQA model outperforms all baseline models significantly. The relative improvement is up to 75\%, 94\%, 56\%, for ``before/after'', ``first/last'' and ``Time Joint'', respectively. The first two kinds of questions are more challenging as they require a better understanding of the temporal expressions in question. Our method is better in capturing such time-sensitivity change in temporal words and thus results in great improvement. Moreover, for the simple questions, our method still keeps competitive performance compared to the SOTA model.


%Table \ref{ResultsTable2} shows the performance of KG embedding-based models across different types of reasoning. We compare our proposed TSQA with baselines in terms of hits@1 and hits@10, respectively. We first observe that our proposed TSQA has achieved state-of-the-art performance in terms of all types of questions on both Hits@1 and Hits@10.  Most noteworthy, our various models on complex questions show more than 82\% improvement on Hits@1 and 21\% improvement on Hits@10 compared to the best baseline as shown in Table \ref{ResultsTable2}. It proves the ability of our model for complex temporal reasoning. Due to the significant improvement comparing all baselines, we claim our model is superior to baselines on question answering on the temporal knowledge graph. 

%What's more, we further compare the models on the subtypes of questions for understanding the various temporal reasoning. In Table \ref{ResultsTable3}, we observe CronKGQA performs very well on simple reasoning questions after using the temporal KG embedding.  However, all rest of the approach is hard to handle the complex reasoning including a time estimation. For instance, the time word like ``after'' will increase the difficulty to find the right time span. Among complex question types, our TSQA model outperforms all baseline models, especially on before/after and first/last questions with 75\% and 94.3\% relative improvements. These two kinds of questions are more challenging for other methods because of the impact of temporal words. For instance, it is easier to predict the answers for ``Who held the position of Governor of Western Australia during Games of the XXV Olympiad'' than the question ``Who held the position of Governor of Western Australia before Games of the XXV Olympiad". Our mechanism is better to sense these temporal expressions in the questions for better performance.
%The reason to limit the performance of baseline is duo the complex temporal reasoning





% \begin{table*}[t]
%     \centering
%     \small
%     \begin{tabular}{c||c|c|c|c|c|c|c|c}
%       \hline
%       %\multirow{3}{4em}{Model}  &  \multicolumn{8}{|c}{Hits@1}   \\ 
%       %\hline
%       %\cline{2-8}
%       \multirow{2}{4em}{Model}&  &\multicolumn{3}{c|}{Complex Reasoning}& \multicolumn{2}{c|}{Simple Reasoning} & \multicolumn{2}{c}{Answer Type}\\
%       %\hline 
%       \cline{2-9}
%       & Overall & Before/After & First/Last & Time Join & Simple Entity & Simple Time  & Entity & Time   \\ \hline 
%       %TSQA(Two-step) & 0.757 & 0.583 & 0.986 & 0.797 & 0.687 & 0.941 & 0.901 & 0.993 & 0.948 & 0.928 \\
%       TSQA_1 & 0.661 & 0.688 & 0.985 & 0.816 & 0.818 & 0.978 & 0.964 & 0.964 \\
%       TSQA_2 & 0.816 & 0.688 & 0.985 & 0.816 & 0.818 & 0.978 & 0.964 & 0.964 \\
%       TSQA_3 & 0.816 & 0.688 & 0.985 & 0.816 & 0.818 & 0.978 & 0.964 & 0.964 \\
%       \hline
%     \end{tabular} 
%     \caption{Ablation Tests.}
%     \label{AblationTable5}
% \end{table*}



\subsection{Ablation Study}
%\gt{
To understand the contributions of the proposed modules in our method, we perform an ablation study by sequentially removing the following components from our proposed TSQA: temporal Contrastive learning (TC), time-aware TKG embeddings (TKE), entity neighboring graph extractor (NG), and time estimation for question answer (TE) in Table~\ref{AblationTable4}. It is noted that removing TKE means that we replace TKE with T-CompLEx as KG encoder, and removing NG means that we perform QA over the whole knowledge graph.
%}


%\gt{
By comparing the two adjacent rows of this table, we can infer the contributions of TC, TKE, NG and TE, respectively: 1) all these modules improve the overall performance in terms of Hits@1, especially for complex questions; 2) by comparing the last two adjacent rows, the proposed time estimation brings significant Hits@1 improvement (14.5\%), since this module supplies the latent time embedding which not only enhances the interaction of timestamp estimation and answer estimation but also supplies a good anchor for finding the answer entity, which is very crucial for answering complex questions; 3) entity neighboring graph extraction gets 7.8\% Hits@1 improvement over complex questions by comparing rows ``{TC}-{TKE}'' and ``{TC}-{TKE}-{NG}'', since it significantly narrows down the search space of the candidate answers; 
4) by comparing the first three rows, time-aware TKG embedding (TKE) and temporal contrastive learning (TC) further boost the Hits@1 over complex questions. This is because the complex questions usually require the model  to capture time ordering information implied in temporal words of the question. 
And these two modules enhance temporal order learning by adding explicit time-order constraints.
%and simplifies the problem of finding correct answer. 
%4) by comparing the first three rows, time-aware TKG embedding (TKE) and temporal contrastive learning (TC) further boosts the Hits@1 over complex questions. This is due to the fact that the complex questions usually require the model 
%has the ability 
%to capture time ordering information implied in temporal words of the question. 
%And these two modules enhance the temporal order learning by adding explicit time-order constraints.
%and thus benefit the complex temporal question answer.


\begin{table}[!ht]
    \centering
    \small
    \resizebox{.48
\textwidth}{!}{
    \begin{tabular}{l||c|c|c|c|c}
      \hline
      \multirow{3}{4em}{Model}  &  \multicolumn{5}{c}{Hits@1} \\ 
      \cline{2-6}
       &  & \multicolumn{2}{c|}{Question Type}& \multicolumn{2}{c}{Answer Type} \\
      \cline{2-6}
      %\cline{2-11}
       & Overall & Complex & Simple & Entity & Time  \\ \hline
      %\hline
      TSQA & \textbf{0.831} & \textbf{0.713} & 0.987 & \textbf{0.829} & \textbf{0.836}  \\
      \hline
      %-{TKE} & 0.818& 0.690 & 0.986 & 0.818 & 0.818 & 0.978 & 0.963 & 0.997 & 0.979 & 0.977 
      -{TC} & 0.821 & 0.696 & 0.984 & 0.820 & 0.822  \\
      % PE
      -{TC}-{TKE} & 0.816 & 0.688 & 0.985 & 0.816 & 0.818  \\
      %NG
      -{TC}-{TKE}-{NG} & 0.757& 0.583& 0.986 & 0.797& 0.687\\
    %   -{TC}-{TKE}-{TE} & 0.696& 0.472& \textbf{0.990} & 0.723& 0.646& 0.944& 0.904& 0.997 & 0.947& 0.940\\
      %TE
      -{TC}-{TKE}-{NG}-{TE} & 0.661 &0.412 &\textbf{0.989}& 0.719 &0.556 \\
      % TSQA+QD 
      %-{EN} & -- & -- &--& -- &-- &-- & -- &-- &-- &--\\
      %-{TE} & -- &-- &--& -- &-- &-- & -- &-- &-- &--\\
      
      \hline
    \end{tabular} 
    }
    \caption{Results of the ablation study. ``-'' means to remove a module. 
    %Here is the dictionary of abbreviations:
    %\{TC: Temporal Contrastive Learning, TKE: time-aware TKG embeddings, NG: neighbor graph extraction, TE: time estimation\}.
    }
    \label{AblationTable4}
\end{table}

%}

%For understanding the reasons for such a significant improvement, we conduct the following ablation study to show the advantages of our TSQA model.

%Firstly, comparing the row 1 and row 2 without the contrastive questions and the losses, we conclude adding the sentitivity of time work benefits the performance. For contrastive learning, from the analysis, we find the temporal order loss plays a more important role in performance improvement. The reason is that the order of facts plays an important role in temporal reasoning.

%Secondly, the row 3 is the model that further remove the time-aware KG encoder. That means we remove the temporal positional embeddings from encoder. Compared to the row2 and row 3, it shows the temporal positional embeddings are useful to keep the order of fact and solve the complex temporal questions.

%Thirdly, it is vital to use the neighbor graph to shrink the search space of answers. Comparing the row 4 and row 3 with neighbor graph extraction, our model in row 3 improves the hits@1 score by 18.0\% on complex questions.  Meanwhile, comparing row 5 and row 6, narrowing down the answer space gets 7.6\% and 6.8 relative improvements in terms of Hits@1 and Hits@10 compared to the baseline. It proves limiting the searching space of answers should be a necessary step for QA.

%Fourthly, the key to answering the question is estimating the time during the temporal reasoning. The row 5 remove the time estimation step in subsection \ref{tbreasoning}. The result shows adding the time estimation and using it for answer prediction have extremely improved the performance for temporal QA comparing row 3 and row 5. It is consistent with our claim that we could handle complex temporal reasoning.


%Finally, as explained that we use the temporal expression template in section \ref{sec3_5}, last row represents that we apply this question decomposition and replace the question by the templates as input of the language model directly in CronKGQA. The explicit timestamps are not available in complex temporal questions, where it is still important to understand the temporal expressions. Using the temporal expression templates allow us to model temporal relations in a context-agnostic manner, which shares supervision signal from different questions. Hence the performance of complex questions is increased.

%Secondly, CronKGQA+NG represents that we add the neighbor graph extraction module into the CronKGQA model. After narrowing down the answer space, the overall performance has 7.6\% and 6.8 relative improvements in terms of Hits@1 and Hits@10 compared to the baseline. It proves limiting the searching space of answers should be a necessary step for QA.

 

%Fourthly, it is vital to use the neighbor graph to shrink the search space of answers. Comparing the row $\text{TSQA}_{TE}$ and $\text{TSQA}_{NG}$ with neighbor graph extraction, our model $\text{TSQA}_{NG}$ improves the hits@1 score by 18.0\% on complex questions. 

%Fifthly, the $\text{TSQA}_{PE}$ is the model that adds the temporal positional embeddings to encoder. Compared to the $\text{TSQA}_{TE}$ and $\text{TSQA}_{PE}$, it shows the temporal positional embeddings are useful to keep the order of fact and solve the complex temporal questions.



%Time embedding analysis
%Visualization
%Case study: 
%1.time embeddings
%-2.Contrastive study



\begin{comment}

\begin{table*}[t]
    \centering
    \small
    \begin{tabular}{l||c|c|c|c|c||c|c|c|c|c}
      \hline
      \multirow{3}{4em}{Model}  &  \multicolumn{5}{c||}{Hits@1} &  \multicolumn{5}{c}{Hits@10}  \\ 
      %\hline 
      \cline{2-11}
       &  & \multicolumn{2}{c|}{Question Type}& \multicolumn{2}{c||}{Answer Type} &  & \multicolumn{2}{c|}{Question Type}& \multicolumn{2}{c}{Answer Type}\\
      %\hline 
      \cline{2-11}
       & Overall & Complex & Simple & Entity & Time & Overall & Complex & Simple & Entity & Time  \\ \hline
      %\hline
      TSQA & \textbf{0.831} & \textbf{0.713} & 0.987 & \textbf{0.829} & \textbf{0.836} & \textbf{0.980} & \textbf{0.968} & \textbf{0.997} & \textbf{0.981} & \textbf{0.978} \\
      \hline
      %-{TKE} & 0.818& 0.690 & 0.986 & 0.818 & 0.818 & 0.978 & 0.963 & 0.997 & 0.979 & 0.977 
      -{TC} & 0.821 & 0.696 & 0.984 & 0.820 & 0.822 & 0.979 & 0.966 & 0.997 & 0.980 & 0.977 \\
      % PE
      -{TC}-{TKE} & 0.816 & 0.688 & 0.985 & 0.816 & 0.818 & 0.978 & 0.964 & 0.997 & 0.980 & 0.975 \\
      %NG
      -{TC}-{TKE}-{NG} & 0.757& 0.583& 0.986 & 0.797& 0.687& 0.941& 0.901& 0.993 & 0.948& 0.928\\
    %   -{TC}-{TKE}-{TE} & 0.696& 0.472& \textbf{0.990} & 0.723& 0.646& 0.944& 0.904& 0.997 & 0.947& 0.940\\
      %TE
      -{TC}-{TKE}-{NG}-{TE} & 0.661 &0.412 &\textbf{0.989}& 0.719 &0.556 &0.884 & 0.801 &0.992 &0.893 &0.866\\
      % TSQA+QD 
      %-{EN} & -- & -- &--& -- &-- &-- & -- &-- &-- &--\\
      %-{TE} & -- &-- &--& -- &-- &-- & -- &-- &-- &--\\
      
      \hline
    \end{tabular} 
    \caption{Results of the ablation study. ``-'' means to remove a module. 
    %Here is the dictionary of abbreviations:
    %\{TC: Temporal Contrastive Learning, TKE: time-aware TKG embeddings, NG: neighbor graph extraction, TE: time estimation\}.
    }
    \label{AblationTable4}
\end{table*}

\subsection{\chao{Temporal Position Embeddings}}

% \begin{table}[t]
%     \centering
%     \small
%     \begin{tabular}{c||c|c|c|c|c}
%       \hline
%       %\multirow{3}{4em}{Model}  &  \multicolumn{5}{c}{Hits@1}   \\ 
%       %\hline 
%       %\cline{2-11}
%       \multirow{2}{4em}{Model} &  & \multicolumn{2}{c|}{Question Type}& \multicolumn{2}{c}{Answer Type} \\
%       %\hline 
%       \cline{2-6}
%       & Overall & Complex & Simple & Entity & Time  \\ \hline
%       TSQA & 0.831 & 0.713 & 0.987 & -- & --\\
%       \hline
%     \end{tabular} 
%     \caption{Temporal position embedding learning.}
%     \label{TPE}
% \end{table}

We explore different ways to add the temporal position embeddings. First, the learnable temporal position embedding is used in all experiments .....

%\subsection{Temporal estimation.}

we prepare a set of pre-defined temporal relation types and map each question to one of the types. For example, the type for ``what happened before" is mapped to the type ``before".
We use temporal keywords, such as the ``before", ``after", ``while", to define six temporal types. 
%Based on this predefined temporal relation dictionary with six types, each question is assigned one type. 
In Table \ref{ablation_test}, we observe that the performance of this setting is significantly worse than our OTR-QA model.
%It is not a reasonable way to consider the open temporal relations as a set of limited predefined relation types. Hence encoding the OTR is a necessary step for solving the TQA task.
By using ``open'' relation extraction without pre-defined relation types, our OTR-QA model is much better in learning the variations and subtleties of temporal relations from limited textual descriptions.

%\subsection{contrastive Set}

%Create a dataset to evaluate our model contain 1631 contrastive question pairs.

Unicode cannot be used in Bib\TeX{} entries, and some ways of typing special characters can disrupt Bib\TeX's alphabetization. The recommended way of typing special characters is shown in Table~\ref{tab:accents}.

Please ensure that Bib\TeX{} records contain DOIs or URLs when possible, and for all the ACL materials that you reference.
Use the \verb|doi| field for DOIs and the \verb|url| field for URLs.
If a Bib\TeX{} entry has a URL or DOI field, the paper title in the references section will appear as a hyperlink to the paper, using the hyperref \LaTeX{} package.
\end{comment}

\section{Conclusion}
\label{sec:bibtex}

%\peng{
In this paper, we propose a time-sensitive question answering framework (TSQA) over temporal knowledge graphs (KGs). To facilitate the reasoning over temporal and relational facts over multiple facts, we propose a time estimation component to infer the unstated timestamp in the question. To further improve the model's sensitivity to time relation words in the question and facilitate temporal reasoning, we enhance the model with a temporal KG encoder that produces KG embeddings that can recover the implicit temporal order and distance between different timestamps, and with contrastive losses that compare temporally exclusive questions. With the help of answer search space pruning from entity neighboring sub-graphs, our TSQA model significantly improves the performance on complex temporal questions that require reasoning over multiple pieces of facts, and outperforms the previous state of the art by a large margin.
%on the \textsc{CronQuestions} benchmark by a large margin.
%}

% Jing: TLDR
% A time-sensitive question answering framework (TSQA) over temporal knowledge graphs that includes a time estimation module, a time-sensitive KG encoder and an answer search space pruning module.
% TLDR: any word limits?
%The size looks good. 

%Chao
%In this paper, we propose a time-sensitive question answering model (TSQA) on temporal knowledge graphs. The purpose is to increase the time sensitivity for complex temporal reasoning. To achieve that goal, we design: 1) a time-aware encoder that catches the orders of different quadruples by adding the temporal positional embeddings; 2) a time-sensitive TKG-QA module that utilizes the neighboring graphs of the entities appeared in question to reduce the search space for finding the answer, performs a time estimation for answer prediction, and further integrates temporal contrastive learning to enhance the sensitivity of the different time relation words for the temporal questions. We demonstrate that our TSQA model significantly improves upon the previous methods. In the future, we plan to extend it to the temporal QA over text and tables.


\section*{Acknowledgements}
This work is supported by the National Key Research and Development Program of China under Grant No. 2020AAA0108600.
%This work was supported by the National Key R\&D Program of China under Grant  No. 2020AAA0108600.

%This document has been adapted by 

% Entries for the entire Anthology, followed by custom entries
\bibliography{anthology,custom}
%\bibliography{custom}
\bibliographystyle{acl_natbib}

%\appendix

%\section{Example Appendix}
%\label{sec:appendix}

%This is an appendix.

\end{document}

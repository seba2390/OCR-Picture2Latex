\documentclass[aps, prd, reprint, nofootinbib, groupedaddress, showpacs]{revtex4-1}
\usepackage{amsmath,amssymb, amsthm,amstext}
\usepackage{natbib}
\usepackage{graphicx}
\usepackage{color}
\usepackage{array}
\usepackage{bm}
\usepackage{multirow}
\usepackage[breaklinks,colorlinks, citecolor=blue]{hyperref}
\usepackage{pifont, ragged2e}
\usepackage{enumitem}



\def\nn{\nonumber}
\def\be{\begin{equation}}
\def\ee{\end{equation}}
\def\mE{\mathcal E}
\def\Planck{\emph{Planck} }

\newcommand*\Bell{\ensuremath{\boldsymbol\ell}}
\newcommand{\xmark}{\text{\ding{55}}}

\begin{document}
\title{Approximate Likelihood Approaches for Detecting the Influence of Primordial
Gravitational Waves in Cosmic Microwave Background Polarization}
\author{Zhen Pan}
\email{zhpan@ucdavis.edu}
\affiliation{Department of Physics, University of California,
One Shields Avenue, Davis, CA, 95616}
\author{Ethan Anderes}
\email{anderes@ucdavis.edu}
\affiliation{Department of Statistics, University of California,
One Shields Avenue, Davis, CA, 95616, USA}
\author{Lloyd Knox}
\email{lknox@ucdavis.edu}
\affiliation{Department of Physics, University of California,
One Shields Avenue, Davis, CA, 95616, USA}

\date{\today}

\begin{abstract}
One of the major targets for next-generation cosmic microwave background (CMB)
experiments is the detection of the primordial B-mode signal. Planning is under
way for Stage-IV experiments that are projected to have instrumental noise small
enough to make lensing and foregrounds the dominant source of uncertainty for estimating
the tensor-to-scalar ratio $r$ from polarization maps.
This makes delensing a crucial part of future CMB polarization science.
In this paper we  present a likelihood method for estimating the
tensor-to-scalar ratio $r$ from CMB polarization observations, which
combines the benefits of a full-scale likelihood approach with the tractability
of the quadratic delensing technique.
This method is a pixel space, all order likelihood analysis of the quadratic delensed B modes,
and it essentially builds upon the quadratic
delenser by taking into account all order lensing and pixel space anomalies.
Its tractability relies on a crucial factorization of the pixel space covariance matrix of the
polarization observations which allows one to compute the full Gaussian approximate likelihood profile,
as a function of $r$, at the same computational cost of a single likelihood evaluation.
\end{abstract}

\pacs{98.70.Vc, 98.62.Sb}

\maketitle


\section{\label{sec:intro}Introduction}
The inflation paradigm has successfully explained the origin of primordial density
perturbations that grew into the Cosmic Microwave Background (CMB)
anisotropies and large scale structure we
observe \citep[e.g.][]{Mukhanov1981, Guth1981, Linde1982, Albrecht1982, Lidsey1997, Lyth1999}.
A key prediction of inflation is the background of primordial
gravitational waves (GWs) or tensor-mode perturbations
\citep[e.g.][]{Starobinskii1979, Rubakov1982, Fabbri1983,%
Abbott1984, Starobinskii1985},
which imprints a unique polarization pattern,
called a primordial B mode, on the CMB anisotropies
\cite{Stebbins1996, Kamionkowski1997a, Kamionkowski1997,Seljak1997,%
Seljak1997a,Zaldarriaga1997a}.
Further, detection of a nearly scale-invariant background of
GWs would severely challenge non-inflationary models
\cite[e.g.][]{Khoury2001, Khoury2001a,Khoury2003a,Steinhardt2002, Boyle2004a}.
The strength of primordial gravitational waves or tensor-mode power is commonly
quantified by the tensor-to-scalar ratio $r$.
Joint analysis of BICEP2/Keck Array and \Planck data yields an upper bound
$r < 0.12$ at $95\%$ confidence level \citep{BICEP2/Keck2015},
the bound is slightly tightened  when the \Planck high-$\ell$
polarization data are included \citep{PlanckCollaborationXX2015},
and BICEP2/Keck Collaboration gives the latest upper bound $r < 0.09$ at
$95\%$ confidence level \citep{BICEP2/Keck2016}.
Fourth generation experiments,
including COrE, LiteBird, and CMB Stage-IV,  are expected to
constrain $r$ with uncertainty $\sigma(r)\simeq 0.001$
\citep{COrECollaboration2011, LiteBirdCollaboration2014,%
LiteBird2016, s42016,Cabass2016, Kamionkowski2016, Delabrouille2017}.

The primordial B modes are contaminated by several sources:
emission from galactic dust and other foregrounds
\cite{Hildebrand1999, Draine2004, Benoit2004,Mortonson2014, Niemack2015,%
PlanckCollaborationXXX2016, PlanckCollaborationL2016, Krachmalnicoff2016},
instrumental noise, and gravitational lensing of scalar CMB perturbations.
The B modes generated by gravitational lensing of the CMB have  been detected
\citep{Hanson2013, Ade2014, VanEngelen2014, Story2014, BICEP2/Keck2015, PlanckCollaboration2015a}.
The lensed B-mode power spectrum is nearly a constant at small multipoles ($\ell \lesssim 1000$) and
therefore manifests as an effective white noise with amplitude $\sim 5$ $\mu$K-arcmin
\citep{Lewis2006, Sherwin2015}.
For CMB Stage-IV, we expect to decrease the instrumental noise to $\sim 1\ \mu$K-arcmin \citep{s42016}.
Then, the lensing B noise (and foregrounds) would become the dominant noise source
limiting the primordial B-mode survey.

Fortunately,  the lensing B noise is well understood.
Up to leading order, one can effectively delense observed B modes by utilizing
a quadratic combination of observed E modes and an estimate of the lensing potential field $\phi^{\rm est}$
\citep{Knox2002, Kesden2002, Seljak2003a, Simard2015a, Sherwin2015}.
We find that the validity of the quadratic delenser crucially depends on a partial cancellation of
higher order lensing terms (see Section \ref{sec:app4} for details).
However, in the regime of low instrumental noise and small lensing potential field estimate uncertainty,
higher-order lensing terms, ignored by the quadratic delensing technique,
can have an appreciable effect. These higher order terms not only induce
a delensing bias but also contain information on primordial B modes.
In addition, experimental complexities such as non-stationary noise and sky cuts
become non-trivial for spectral based methods such as the quadratic delenser.

As an alternative, a full-scale likelihood analysis of the tensor-to-scalar ratio $r$ can,
in principle, optimally account for all the Gaussian and non-Gaussian information in the CMB observations.
Unfortunately, a full likelihood analysis requires computation resources beyond
what is available in the near future.
In this paper, we introduce a likelihood approximation which is modified from the full-scale
likelihood, so as to be computationally tractable.

We start with introducing a Gaussian likelihood incorporating all the 2-point information.
A key element of our likelihood analysis is the covariance matrix of the polarization maps.
For each data pair ($d_i, d_j$) ($d$ can be $Q$ or $U$),  its covariance
depends on the primordial polarization power spectra $C_\ell^{EE}$ and $C_\ell^{BB,r}$,
lensing potential field $\phi(x)$ (and instrumental noise $N^{QQ}$ and $N^{UU}$),
where the E-mode power $C_\ell^{EE}$ has been well constrained
\citep[e.g.][]{PlanckCollaborationXI2015, PlanckCollaborationXIII2015},
while the primordial B-mode signal has not been detected.
Following the prediction of the inflation paradigm,
we assume the tensor perturbations to be scale-invariant and Gaussian.
Hence all the primordial B-mode  information is encoded in the single parameter $r$, the
tensor-to-scalar ratio at $k=0.05$ Mpc$^{-1}$.
Then the covariance matrix $\tilde \Sigma_{r,\phi}$
depends on the unknown parameter $r$ and the underlying lensing potential field $\phi(x)$,
where $\phi(x)$ can be estimated from exterior tracers, e.g. cosmic infrared background (CIB)
\citep{Song2003, Dole2006, PlanckCollaborationXVII2014,%
PlanckCollaboration2015a, Larsen2016, Manzotti2017} or
from intrinsic CMB via, e.g. quadratic estimators \citep{Hu2001, Hu2002b}
or Bayesian approach \citep{Hirata2003a, Hirata2003,Anderes2011, Anderes2015, Millea2017}.
We obtain a covariance matrix $\Sigma_r$ depending only on $r$ by marginalizing $\tilde \Sigma_{r,\phi}$
over uncertainties in the lensing potential field estimate $\phi^{\rm est}$.
With this full covariance matrix $\Sigma_r$, it is then straightforward to compute the likelihood of $r$
for given data vector $d$ by approximating $d$ as a Gaussian vector.

In principle, this Gaussian likelihood method can exploit
all the 2-point $r$ information from the polarization maps,
but usually the computation resource demands are still excessive. For example,
to constrain $r$ from some polarization maps with $p$ pixels,
we need to compute the full likelihood profile $L(r|d)$ as a function of $r$,
which in practice requires computing the likelihood on a range of $r$ values,
say $50$  values evenly distributed in the interval $[0, 0.2]$.
For each different $r$, we need to compute the quadratic form $d^\intercal\Sigma_r^{-1} d$ and
the determinant $\det(\Sigma_r)$, due to the $r$ dependence of the covariance matrix.
In any realistic experiments with $p \gtrsim 10^4$,
it is a huge amount of work to compute and invert the covariance matrix of dimension $2p\times 2p$
for that many $r$ values, where the factor $2$ comes from two observables $Q$ and $U$ on each pixel.

In this paper, we present a modified Gaussian likelihood tailoring
the full-scale likelihood analysis so as to be computationally tractable.
The method consists of two parts.
In the first part, we decompose the covariance matrix $\Sigma_r$ as $\Sigma^{\rm en}+ r\Sigma^{\rm b}$,
where $\Sigma^{\rm en}$ is the contribution from E modes and instrumental noise,
and $r\Sigma^{\rm b}$ is the contribution from B modes. This decomposition allows us to compute
the covariance $\Sigma_r$, as a function of $r$,
at the same computational cost of a single covariance matrix computation.
In the second part, we suppress data size by tracking only $s$
high signal-to-noise modes, say the large-scale quadratic delensed B modes.
We project out the lensing-generated B modes and obtain the delensed modes $B^{\rm del}$
from the polarization data $d$ via a projection matrix $v$,
$(^0B^{\rm del}_{\Bell})_s = (v^\intercal)_{s\times 2p} d_{2p}$,
with $s\sim 500$ and the upper left index $^0$ denoting the projected data vector
limited to the $s$ lowest frequency  modes available.
Then, the covariance matrix of the projected data vector  $^0B^{\rm del}_{\Bell}$
is given by $v^\intercal \Sigma_r v$,
with which the computation of the $r$ likelihood  $L(r|^0B^{\rm del}_{\Bell} )$
given the projected data vector turns out to be tractable.
This method can be naturally extended to incorporate higher frequency modes,
as we describe in Section \ref{sec:like}.


The paper is organized as follows. We introduce the quadratic delenser
and the likelihood based delenser in Section \ref{sec:delen} and Section \ref{sec:like}, respectively.
In Section \ref{sec:sims}, we apply the two $r$ constraining techniques
on simulations mimicking Stage III and IV CMB surveys,
and compare their $r$ constraints.
We conclude with Section \ref{sec:summary}. For reference, we derive the analytic expression
for the covariance matrices of the polarization maps, and the eigenvalue method for inverting large matrices
in Appendices \ref{sec:app1}, \ref{sec:app2} and \ref{sec:app3}, respectively.

\section{Quadratic Delenser}
\label{sec:delen}
For simplicity, we assume no contamination of foregrounds throughout this paper.
Then the observed B modes can generally be expressed as
\be
B^{\rm obs} = B^{r} + B^{\rm len} + N^B,
\ee
where $B^r, B^{\rm len}, N^B$ are primordial B signal, lensing B noise
and instrumental B noise, respectively. To constrain the primordial B signal,
delensing is essential, where we obtain an estimate of the lensing B noise and subtract it off from the
observed B modes. Here we introduce a quadratic delenser.

Accurate to the leading order of the lensing potential $\phi_{\Bell}$,
$B^{\rm len}$ is the convolution of the lensing potential and primordial E modes, i.e.,
\be
\label{eq:convol}
B^{\rm len}_{\Bell} = \int \frac{d^2\Bell'}{2\pi} \Bell'\cdot(\Bell-\Bell') \sin(2\varphi_{\Bell,\Bell'}) E_{\Bell'}\phi_{\Bell-\Bell'}.
\ee
Usually, the underlying lensing potential is not  known {\it a priori}, but can be estimated from either intrinsic CMB
or from external tracers. From an estimated lensing potential $\phi^{\rm est}_{\Bell}$
and observed modes $E_{\Bell}^{\rm obs}$, we construct a quadratic estimate of the lensing B noise
\be
\label{eq:wconvol}
B^{\rm len, est}_{\Bell} = \int \frac{d^2\Bell'}{2\pi} f_{\Bell,\Bell'} \Bell' \cdot(\Bell-\Bell')\sin(2\varphi_{\Bell,\Bell'})  E^{\rm obs}_{\Bell'} \phi^{\rm est}_{\Bell-\Bell'},
\ee
where $\varphi_{\Bell,\Bell'} = \varphi_{\Bell} - \varphi_{\Bell'}$,
$E^{\rm obs}$ is the observed E modes (to the lowest order, the difference between
lensed E and primordial E can be neglected),
and the weighting function $f_{\Bell,\Bell'}$ is to be determined by minimizing the residual,
$B_{\Bell}^{\rm res} = B^{\rm len}_{\Bell} - B^{\rm len, est}_{\Bell}$.
If we define the correlation coefficient of $\phi_{\Bell}$ and $\phi^{\rm est}_{\Bell}$
\be
\label{eq:corr}
\rho_\ell =  \frac{C_\ell^{\phi, \phi^{\rm est}}}{\sqrt{C_\ell^{\phi\phi} C_\ell^{\phi^{\rm est}\phi^{\rm est}}}},
\ee
the optimal weight at leading order was proved to be \citep{Sherwin2015}
\be
f_{\Bell,\Bell'} = \frac{C_{l'}^{EE}}{C_{l'}^{EE} + N_{l'}^{EE}} \rho_{|\Bell-\Bell'|}^2,
\ee
which enables a minimal residual power spectrum
\be
\label{eq:respower}
\begin{aligned}
C_{\Bell}^{BB, {\rm res}}
& =\int \frac{d^2\Bell'}{(2\pi)^2} \left[\Bell'\cdot(\Bell-\Bell') \sin(2\varphi_{\Bell,\Bell'})  \right]^2\\
&\times C_{\Bell'}^{EE} C^{\phi\phi}_{\Bell-\Bell'} (1-f_{\Bell,\Bell'}).
\end{aligned}
\ee

After subtracting off the template $B_{\Bell}^{\rm len, est}$, we obtain a quadratic delensed B-mode map
\be
\label{eq:bdel}
B_{\Bell}^{\rm del} = B_{\Bell}^{\rm obs} - B_{\Bell}^{\rm len, est} = B_{\Bell}^r + B_{\Bell}^{\rm res} + N_{\Bell}^B,
\ee
and its power spectrum
\be
\label{eq:delpower}
C_\ell^{BB, {\rm del}} = C_\ell^{BB,r} + C_\ell^{BB, {\rm res}} + N^{BB}_\ell.
\ee
From the delensed B modes, one can better constrain $r$ due to the suppressed lensing B noise.
Note that in the evaluation of
the residual lensing B power
$C_\ell^{BB, {\rm res}} $ of Eq. (\ref{eq:respower}) we have made two approximations:
1) we keep only the linear order lensing in $B^{\rm len}$;
2) we completely ignore the lensing in $E^{\rm obs}$.

\section{Gaussian Likelihood Delenser}
\label{sec:like}

In contrast to the quadratic delenser, the likelihood analysis works on observables
$Q^{\rm obs}$ and $U^{\rm obs}$ in pixel space.
Concatenating the polarization data on all pixels yields a length-$2p$ data vector
\be
d = [Q^{\rm obs}(x_1) \cdots Q^{\rm obs}(x_p), U^{\rm obs}(x_1) \cdots  U^{\rm obs}(x_p)]^\intercal,
\ee
with $p$ being the number of pixels.
We first evaluate the covariance matrix of the data vector,
which depends on the primordial polarization power spectra $C_\ell^{EE}$ and $C_\ell^{BB,r}$,
lensing potential field $\phi(x)$ (and instrumental noise). With $C_\ell^{EE}$ being well-determined,
and $C_\ell^{BB,r}$ being parametrized by the tensor-to-scalar ratio $r$,
we marginalize the covariance matrix $\tilde \Sigma_{r,\phi}$ over uncertainties in $\phi(x)$ estimate,
and obtain a covariance matrix $\Sigma_r$ depending only on $r$. Then it is straightforward to compute the approximate likelihood of $r$ for given data $d$
by approximating $d$ as a Gaussian vector, i.e.,
\be
\label{eq:likeli}
    -2\log L(r|d) = d^\intercal\Sigma^{-1}_r d + \log \det\Sigma_r,
\ee
up to a constant term.

\subsection{Comparison with the Quadratic Delenser}
Before delving into the details of the Gaussian likelihood delenser,
it would be useful to do a brief comparison with the quadratic delenser (see Table \ref{table1}):
\begin{itemize}
    \item The Quadratic Delenser works on the delensed modes $B^{\rm del}_{\Bell}$ in Fourier space,
    and approximates these modes as stationary and Gaussian, i.e.,
    \[
    \begin{pmatrix}
        \vdots \\
        B^{\rm del}_{\Bell}\\
        \vdots
    \end{pmatrix} \sim
    N(0, \begin{bmatrix}
    \ddots & 0 & 0 \\
    0 & C^{BB,\rm del}_{\ell} & 0\\
    0 & 0 & \ddots
    \end{bmatrix}),
    \]
    where the power spectrum $C^{BB,\rm del}_{\ell}$, derived in Eq. (\ref{eq:delpower}), only
    takes into account the leading-order in $\phi$.
    Therefore, the quadratic delenser exploits the 2-point information in
    a biased way by ignoring the non-stationarity and higher-order lensing in the power spectrum.

    \item The Gaussian Likelihood  Delenser works on the observables $d$ in pixel space, and approximates the data
    vector $d$ as Gaussian after marginalizing over uncertainties in the $\phi$ estimate. In the computation of
    the covariance matrix $\Sigma_r$, all-order lensing is taken into account
    and no stationarity assumption is made. Therefore, the Gaussian likelihood
    delenser naturally incorporates all the 2-point information.
\end{itemize}

\begin{table}
\begin{tabular}{ m{2.4cm} |c| c}
      Delenser & Quadratic Delenser  & Gaussian Likelihood  \\ \hline
     working space  & Fourier & pixel\\ \hline
      power spectrum / cov. matrix & leading order & all order\\ \hline
     non-stationarity& $\xmark $ & $\checkmark$ \\
     non-Gaussianity &  $\xmark $ & $\xmark $ \\ \hline
\end{tabular}
\caption{A brief comparison of the two delensers.}
\label{table1}
\end{table}

The Gaussian likelihood is potentially favored in several aspects,
but usually is computationally excessive.
As explained in the Introduction, the bottleneck of the likelihood analysis is
the covariance matrix $\Sigma_r$ related computation,
which is of large size $2p\times 2p$, and is a function of $r$.
Here we introduce a modified Gaussian likelihood method.
The method consists of two parts, covariance decomposition and data compression,
where the former allows us to compute the covariance matrix $\Sigma_r$,
as a function of $r$, at the computation cost of a single covariance matrix computation;
and the latter allows us to compress the covariance matrix
by tracking a small number of high $S/N$ modes.

\subsection{Covariance Decomposition}
To avoid repeating the computation of the covariance matrix $\Sigma_r$ for each different $r$,
we find it is possible to single out the $r$ dependence by decomposing the  covariance matrix as
\be
\label{eq:dec}
\Sigma_r = \Sigma^{\rm en} + r \Sigma^{\rm b},
\ee
where $\Sigma^{\rm en}$ is the contribution from E modes and instrumental noise,
and $r \Sigma^{\rm b}$ is the contribution from primordial B modes.
With this decomposition, we can obtain the covariance matrix $\Sigma_r$ as a function
of $r$, as long as the $r$-independent components $\Sigma^{\rm en}$ and  $\Sigma^{\rm b}$ are obtained.

For the covariance decomposition of Eq. (\ref{eq:dec}),
we first decompose observables $Q^{\rm obs}$ and $U^{\rm obs}$ as linear combinations of E modes and B modes.
Stokes parameters $Q$ and $U$ are related to coordinate independent quantities $E$ and $B$ via
\citep{Stebbins1996, Kamionkowski1997a, Kamionkowski1997, Seljak1997a}
\be
\label{eq:queb}
\begin{aligned}
Q_{\Bell} &= - \cos(2\varphi_{\Bell}) E_{\Bell} + \sin(2\varphi_{\Bell}) B_{\Bell}, \\
U_{\Bell} &= - \sin(2\varphi_{\Bell}) E_{\Bell} - \cos(2\varphi_{\Bell}) B_{\Bell}.
\end{aligned}
\ee
We define the following modulated E/B modes
\be
\begin{aligned}
SE_{\Bell} & \equiv - \sin(2\varphi_{\Bell}) E_{\Bell}, \quad  & SB_{\Bell}  \equiv +\sin(2\varphi_{\Bell}) B_{\Bell},\\
CE_{\Bell} & \equiv - \cos(2\varphi_{\Bell}) E_{\Bell}, \quad  & CB_{\Bell} \equiv -\cos(2\varphi_{\Bell}) B_{\Bell},
\end{aligned}
\ee
then the observables $Q^{\rm obs}$ and $U^{\rm obs}$ are consequently expressed as
\be
\begin{aligned}
Q^{\rm obs}(x) &= \widetilde{CE}(x) + \sqrt{r} \widetilde{SB^0}(x) + N^Q(x),\\
U^{\rm obs}(x) &= \widetilde{SE}(x) + \sqrt{r} \widetilde{CB^0}(x) + N^U(x),
\end{aligned}
\ee
where $B^0$ denotes fiducial B modes with unity power spectrum $C_\ell^{BB,r=1}$,
tildes denote lensed fields $\widetilde X(x) = X(x+\nabla\phi(x))$ ($X = CE, SE, CB, SB$),
and $N^{Q,U}$ is the $Q/U$ noise.

With above decomposition, we find the data vector $d$ is Gaussian with covariance $\tilde\Sigma_{r, \phi}$
for given $r$ and $\phi(x)$, i.e., $d \sim  N(0, \tilde\Sigma_{r, \phi})$, where
\be
\tilde\Sigma_{r, \phi} \equiv
\left[
\begin{tabular}{cc}
  $\tilde \Sigma^{Q^{\rm obs},Q^{\rm obs}}$ & $\tilde\Sigma^{Q^{\rm obs},U^{\rm obs}}$  \\
  $\tilde \Sigma^{Q^{\rm obs},U^{\rm obs}}$ & $\tilde\Sigma^{U^{\rm obs},U^{\rm obs}}$
  \end{tabular}
\right]_{r,\phi}
\ee
and the covariance matrix is naturally expressible in the form of Eq. (\ref{eq:dec}), i.e.,
\be
\label{eq:elements}
\begin{aligned}
    \tilde \Sigma^{Q^{\rm obs},Q^{\rm obs}} &= \tilde\Sigma^{CE,CE} + r \tilde\Sigma^{SB^0, SB^0} + \Sigma^{NQ,NQ},\\
    \tilde \Sigma^{Q^{\rm obs},U^{\rm obs}} &= \tilde\Sigma^{CE,SE} + r \tilde\Sigma^{SB^0, CB^0} ,\\
    \tilde \Sigma^{U^{\rm obs},U^{\rm obs}} &= \tilde\Sigma^{SE,SE} + r \tilde\Sigma^{CB^0, CB^0} + \Sigma^{NU,NU}.
\end{aligned}
\ee

In a more practical case, we only have an estimate of lensing potential $\phi_{\Bell}^{\rm est}$
which is a noisy version of the true $\phi_{\Bell}$,
i.e., $\phi_{\Bell}^{\rm est} = \phi_{\Bell} + n^\phi_{\Bell}$,
where $n^\phi_{\Bell}$ is the uncertainty of the $\phi$ estimate
and its power spectrum $N_\ell^{\phi\phi}$ is usually an output of the lensing estimator used.
For an unbiased estimator with Gaussian uncertainty, one can write $n^\phi_{\Bell}\sim N(0, N_\ell^{\phi\phi})$.
Then the correlation coefficient of $\phi$ and $\phi^{\rm est}$ defined in Eq. (\ref{eq:corr}) now
is explicitly known as
\be
\rho_\ell =  \sqrt{\frac{C_\ell^{\phi\phi}}{C_\ell^{\phi\phi} + N_\ell^{\phi\phi}}}.
\ee
In this context, one can treat $\phi^{\rm est}$ as data and compute the
posterior on $\phi$ given $\phi^{\rm est}$, i.e.,
\be
P(\phi_{\Bell} | \phi^{\rm est}_{\Bell})
\sim N\left(\mu\phi_{\Bell},
C_{\ell}^{n\phi,n\phi}\right).
\ee
with
\be
\label{eq:wf}
\begin{aligned}
\mu \phi_{\Bell} &= \frac{C_\ell^{\phi\phi}}{C_\ell^{\phi\phi} + N_\ell^{\phi\phi}} \phi_{\Bell}^{\rm est}
=\rho_\ell^2 \phi_{\Bell}^{\rm est}, \\
C_{\ell}^{n\phi,n\phi}& = \frac{C_\ell^{\phi\phi}}{C_\ell^{\phi\phi} + N_\ell^{\phi\phi}}N_\ell^{\phi\phi}
=\rho_\ell^2  N_\ell^{\phi\phi},
\end{aligned}
\ee
Therefore a sample $\phi_{\Bell}  \sim P(\phi_{\Bell} | \phi^{\rm est}_{\Bell})$ can be writen as
\be
\phi_{\Bell} = \mu\phi_{\Bell} + n\phi_{\Bell},
\ee
with $n\phi_{\Bell}\sim N(0, C_\ell^{n\phi,n\phi})$.


Marginalizing $\tilde \Sigma_{r,\phi}$ over $n\phi$, we obtain a covariance matrix only depending on $r$, i.e.,
$\Sigma_r \equiv \langle \tilde \Sigma_{r,\phi} \rangle_{n\phi}$,
where its analytic form is presented in Appendices \ref{sec:app1} and \ref{sec:app2}.
The computation of its inverse matrix $\Sigma_r^{-1}$ is presented in Appendix \ref{sec:app3}.

\subsection{Data Compression}
\subsubsection{idea}
To compress the data, we project the original length-$2p$ data vector $d$ to
a length-$s$ data ($s\sim 500$) via a projection matrix $v$, and apply the likelihood analysis on the
projected data $\hat d_s = (v^\intercal)_{s\times 2p} d_{2p}$. Let $\Sigma_r$ be the covariance matrix of data vector $d$,
then $v^\intercal\Sigma_r v$ is the covariance matrix of projected data vector $\hat d$, i.e.,
$d\sim N\left(0, \Sigma_r\right)$,
and
$\hat d \sim N\left(0, v^\intercal \Sigma_r v \right)$.
Then the likelihood of $r$ given projected data $\hat d$ is simply
\be
\label{eq:projlikeli}
    -2\log L(r|\hat d)
    = \hat d^\intercal (v^\intercal\Sigma_r v)^{-1} \hat d + \log \det(v^\intercal\Sigma_r v),
\ee
up to a constant term.

The goal is to find a projection matrix $v$ such that $\hat d$ is highly informative for $r$.
Since the primordial B modes at large scales are less contaminated by the lensing B noise,
a natural choice is to project the polarization data to the large-scale quadratic delensed modes
defined in Equation (\ref{eq:bdel}),
i.e., $\hat d^0 =$ $^0B_{\Bell}^{\rm del}$, where the upper index $^0$ denotes the projected data vector
limited to the $s$ lowest frequency  modes available (Figure \ref{fig:Bdel}).
The method can be naturally extended to higher frequency modes,
$\hat d^i = \ ^iB^{\rm del}_{\Bell}$ $(i = 1,2,\dots)$
with $\Bell$ running over the $s$ next/next-next/$\dots$ lowest frequency modes.
With these projected data vectors $\hat d^i = \ ^iB^{\rm del}_{\Bell}= (v^\intercal)^i d$,
the total likelihood is given by
\be
\label{eq:totlikeli}
    \log L(r|d) \approx \sum_{i=0}^{i_{\rm max}}\log L(r|\hat d^i),
\ee
assuming negligible correlation for different projected vectors.\footnote{
The large-scale delensed B modes are no longer the highest $S/N$ modes,
when foregrounds, contaminating the primordial B modes more at large scales, are considered.
Our methodology is flexible. In principle, modes could be selected that
minimizes noise and residual foreground contamination.}
We will confirm the validity of ignoring the cross correlation via simulations in Section \ref{sec:sims}.

\begin{figure}
\centering
\includegraphics[height=1.8in]{f1.pdf}
\caption{ \label{fig:Bdel}
The modes covered by each different projected vector $^i B_{\Bell}^{\rm del} (i = 0, 1, 2, \cdots)$.
Here we only show the modes with $\ell_2 \geq 0$, since our observables $Q^{\rm obs}$
and $U^{\rm obs}$ are real numbers.}
\end{figure}

We find that the modified Gaussian likelihood
method works better if we incorporate the same number of E modes
and delensed B modes in each projected vector,
i.e.,
\be
\label{eq:ebproj}
[\hat d^i]_{2s} =
\begin{bmatrix}
    (^iB^{\rm del}_{\Bell})_s\\
    (^iE^{\rm obs}_{\Bell})_s
\end{bmatrix}
= \begin{bmatrix}
    (v_b^\intercal)^i_{s\times 2p}\\
    (v_e^\intercal)^i_{s\times 2p}
\end{bmatrix}  d_{2p} = (v^\intercal)^i_{2s\times 2p} d_{2p}.
\ee

\subsubsection{projection matrix}
In this subsection, we focus on the computation of the projection matrix.
As described in Section \ref{sec:delen}, the quadratic delenser is actually a linear operator,
i.e.,
\be
\label{eq:qdrdel}
\begin{aligned}
d=(Q^{\rm obs}, U^{\rm obs})^\intercal &\xrightarrow{{\rm Eq.}(\ref{eq:queb})}  (E^{\rm obs}, B^{\rm obs}) ,  \\
 & \xrightarrow{{\rm Eq.}(\ref{eq:wconvol})} (B^{\rm len, est}, B^{\rm obs}) , \\
 & \xrightarrow {{\rm Eq.}(\ref{eq:bdel}) } B^{\rm obs}- B^{\rm len, est} = B^{\rm del}.
\end{aligned}
\ee
Therefore we can formally write the quadratic delensing as
$(B^{\rm del}_{\Bell})_{2p} = \mathcal P_{2p\times 2p} d_{2p}$,
where $\mathcal P$ is a concatenation of the three linear operations above,
and its matrix elements can be found by
recording the impulse response of the delensed modes
to each element in the data vector.
For example, we first do the quadratic delensing to a ``data vector"
$\delta_1 = (1,0, \dots,0)^\intercal_{2p}$
and denote the corresponding delensed modes as $(B^{\rm del}_{\Bell}|_{\delta_1})$,
i.e.,
\be
(B^{\rm del}_{\Bell}|_{\delta_1})_{2p} = \mathcal P_{2p\times2p} (\delta_1)_{2p} = \textrm{1st col. of}\ \mathcal P.
\ee
where $(B^{\rm del}_{\Bell}|_{\delta_1})$ is obtained via delensing of Eq. (\ref{eq:qdrdel}).
In this way, we obtain the matrix $\mathcal P$.

It is clear that the projection matrices of vectors $ ^iB^{\rm del}_{\Bell}$
correspond to row blocks of $\mathcal P$.
Explicitly, we write $(B^{\rm del}_{\Bell})_{2p} = \mathcal P_{2p\times 2p} d_{2p}$ as
\be
\begin{pmatrix}
    (^0B_{\Bell}^{\rm del})_s\\
    (^1B_{\Bell}^{\rm del})_s\\
    (^2B_{\Bell}^{\rm del})_s\\
    \dots
\end{pmatrix}
= \mathcal P_{2p\times 2p} d_{2p}
= \begin{pmatrix}
    (^0\mathcal P)_{s\times 2p}\\
    (^1\mathcal P)_{s\times 2p}\\
    (^2\mathcal P)_{s\times 2p}\\
    \dots
\end{pmatrix} d_{2p}.
\ee
and therefore we obtain $(v_b^\intercal)^i_{s\times 2p} = (^i\mathcal P)_{s\times 2p}$.
The projection matrices $(v_e^\intercal)^i$ can be obtained in a similar way.


\section{Simulations}
\label{sec:sims}
In this section, we apply the quadratic delenser and the modified Gaussian likelihood  method
on CMB polarization simulations, and compare the resulting $r$ constraints.
The fiducial cosmology we use is a flat $\Lambda$CDM cosmology with
a baryon density $\omega_{\rm b} = 0.02246$, a cold dark matter density $\omega_{\rm c} = 0.1185$,
a reionization optical depth $\tau = 0.1283$,
an angular size of sound horizon at recombination $100\theta_{\star} = 1.0410$,
an amplitude and a spectral index of the primordial scalar the perturbation power spectrum
$10^9A_{\rm s} = 2.1333, n_{\rm s} = 0.9686$,
and a tensor-to-scalar ratio $r$ in the range of $[0.001, 0.1]$.
For each different $r$, we simulate $500$ realizations of primordial polarization fields $Q(x)$ and $U(x)$,
then lense these fields via the same lensing potential field $\phi(x)$.
All the power spectra used in simulations are computed from the Boltzmann code  {\tt CLASS} \citep{Lesg2011}.


\subsection{Two Surveys}


\begin{table}
\scalebox{1.3} {
\begin{tabular}{ l r|c| c |c}
     &  & $\Delta_{\rm T} (\mu$K-arcmin) & $\theta_{\rm FWHM}$ & $f_{\rm sky}$ \\ \hline
    \multirow{2}{*}{Lb}  &  $\phi$ & 0.5  & $2'$ & \multirow{2}{*}{$2.7\%$}\\ \cline{2-4}
                         &  $B$    & 0.5 & $10'$ & \\ \hline
    \multirow{2}{*}{La}  &  $\phi$ & 1  & $2'$ & \multirow{2}{*}{$2.7\%$}\\ \cline{2-4}
                        &  $B$    & 1 & $10'$ & \\ \hline
    \multirow{2}{*}{N}  &  $\phi$ & 10  & $2'$  & \multirow{2}{*}{$2.7\%$} \\ \cline{2-4}
                        &  $B$ & 10 & $10'$ & \\ \hline
\end{tabular}
}
\caption{The three scenarios we simulated.}
\label{table}
\end{table}

\begin{figure}
\centering
\includegraphics[height=3in]{f2.pdf}
\caption{ \label{fig:phi_noise}
The $\phi(x)$ reconstruction noises for Scenario N ($\Delta_{\rm T} = 10$ $\mu$K-arcmin), La
($\Delta_{\rm T} = 1$ $\mu$K-arcmin) and Lb ($\Delta_{\rm T} = 0.5$ $\mu$K-arcmin) surveys.}
\end{figure}

We consider a survey strategy consisting of two different surveys of the same area of sky, differing
in angular resolution. The main goal of the higher-resolution survey is to allow for a reconstruction of
the lensing potential. Such reconstructions benefit from reaching an angular scale comparable to the typical
lensing deflection angle of $\sim 2$ arcmin. In contrast, the primordial B-mode signal is on fairly large angular scales of
greater than a degree. In principal, one high-resolution survey could be used both for the lensing reconstruction
and for sensitivity to the primordial B-mode signal. However, there are advantages to using a survey dedicated
to the large-scale signals. These advantages do not appear in the idealized analyses that we perform here,
as they are related to systematic error control and foreground cleaning, as we now explain briefly.
The large-scale survey can be achieved with a smaller telescope with a simplified optics chain.
Having a smaller telescope facilitates boresight rotation, which BICEP2/Keck have used for null
tests to bound certain systematic errors. Foreground cleaning is also likely to be more of a challenge
at larger angular scales than it is for the smaller-angular scales with the bulk of the lensing information,
and serves as a further driver of differences in optimal design for the two surveys.
For these reasons a two-survey approach is likely to be a part of the strawman concepts for
the CMB Stage-IV instrument soon to emerge from the CMB Stage-IV Concept Definition Taskforce.


In this paper, we simulate three scenarios.
We consider a scenario `N' in which the B-mode instrument noise power
is larger than the B-mode lensing power, and two scenarios
`La' and `Lb' with the opposite situation.
The more sensitive scenarios La and Lb are motivated by potential CMB-S4 scenarios.
Each scenario consists of two surveys, a high-resolution survey for $\phi$ reconstruction
and a low-resolution survey capturing the B-mode signal, covering the same patch of the sky
(see Table \ref{table} for the survey configurations in detail).
For the high-resolution surveys, the lensing potential reconstruction noise
expected from the EB quadratic estimator \citep{Hu2001, Hu2002b,Anderes2013}
is shown in Figure \ref{fig:phi_noise}.


\begin{figure*}
\centering
\includegraphics[height=4in]{f3.pdf}
\caption{\label{fig:f3}
Upper three panels show the detection levels $r/\sigma(r)$ expected from surveys of Scenario N, La, and Lb,
and lower three panels show the corresponding bias levels ${\rm Bias(r)}/r$.}
\end{figure*}



\subsection{$r$ Constraints}
For each simulated CMB realization, we first reconstruct the lensing potential field from
the $\phi$ survey (\emph{high} resolution survey)
using the EB quadratic estimator,
then use the reconstructed lensing field $\phi^{\rm est}(x)$ to delense the
\emph{low} resolution polarization maps using the quadratic delenser (Section \ref{sec:delen})
and the modified Gaussian likelihood method (Section \ref{sec:like}),
and finally compare their $r$ constraints from the two delensers.\footnote{For intrinsic estimators,
the reconstructed lensing potential field and its reconstruction noise are
correlated with the fields being delensed, and the correlation is expected to bias
the delensing. Fortunately, corresponding debias techniques have been extensively investigated
and used \citep[see e.g.][]{Teng2011,Namikawa2015,Sehgal2016,Carron2017}.
To avoid unnecessary complexity, we choose not to directly use the reconstructed field
$\phi^{\rm est}(x)$ for delensing,
instead use a simulated one $\phi^{\rm est}(x) = \phi(x) + n^\phi(x)$,
with $\phi(x)$ being the true lensing potential field and $n^\phi(x)$ being Gaussian noise
with power expected from the EB quadratic estimator (Figure \ref{fig:phi_noise}).}

In Figure \ref{fig:f3}, we show the detection level $r/\sigma(r)$
and bias level ${\rm Bias}(r)/r$ obtained from the quadratic delenser
and from the modified Gaussian likelihood method,
where $\sigma(r)$ and ${\rm Bias}(r)$ are the standard error and
the average bias of the $500$ best-fit $r$ values (from $500$ CMB realizations), respectively.
For Scenario N, both methods  obtain  similar $r$ detection levels,
while the modified Gaussian likelihood method shows its advantages in the
Scenario La and Lb.
We find that in the regime of low map noise  ($\lesssim 1$ $\mu$K-arcmin),
the bias of the modified Gaussian likelihood method is appreciably smaller than
that of the quadratic delenser (see next subsection for the detailed bias analysis
for the quadratic delenser).

For Scenario La with map noise $\Delta_{\rm T} = 1$ $\mu$K-arcmin and
sky coverage $f_{\rm sky} = 2.7\%$, we expect to detect the primordial B-mode signal at
$\sim 1\ \sigma$ level for $r = 0.001$ and at $\sim 15 \ \sigma$ level for $r = 0.1$.
The lower noise Scenario Lb with map noise $\Delta_{\rm T} = 0.5$ $\mu$K-arcmin
and the same sky coverage, only marginally increases the detection level,
due to the saturation of cosmic variance.

\subsection{Bias Analysis for the Quadratic Delenser}
\label{sec:app4}
In this subsection, we aim to quantify the bias of the quadratic delenser
introduced by ignoring the lensing in E modes and higher order lensing in
B modes.\footnote{ In principle, ignoring the non-stationarity of the delensed B modes also induces
some bias to the $r$ constraint. But we will see this bias is negligible. }
For clarity, we use the following notation to denote
the connection between lensed and primordial variables
\be
\begin{aligned}
\widetilde E = E + \delta E_{\text{\rm from E}} + \delta E_{\text{\rm from B}} , \\
\widetilde B = B + \delta B_{\text{\rm from E}} + \delta B_{\text{\rm from B}} ,
\end{aligned}
\ee
where $\delta X_{\text{\rm from Y}}$ is the lensing in (lensed) $X$ from  (primordial) $Y$.
In addition, $\delta E_{\text{\rm from B}}$ and $\delta B_{\text{\rm from B}}$ are much smaller
than their counterparts $\delta E_{\text{\rm from E}} $ and $\delta B_{\text{\rm from E}}$, so we simply ignore them
in this subsection.


\begin{figure*}
\centering
\includegraphics[height=2.8in]{f4a.pdf}
\includegraphics[height=2.8in]{f4b.pdf}
\caption{\label{fig:f4}
Bias analysis of the quadratic delenser via simulations under different assumptions:
(black/solid lines) null test assuming $E^{\rm obs} = E + N^E$ and
$B^{\rm obs} = B + \delta^1B_{\text{\rm from E}} + N^B$;
(green/bar lines) all order E from E test assuming
$E^{\rm obs} = E + \delta E_{\text{\rm from E}} + N^E$,
$B^{\rm obs} = B + \delta^1B_{\text{\rm from E}} + N^B$;
(blue/dashed lines) all order B from E test assuming
$E^{\rm obs} = E + N^E$ and
$B^{\rm obs} = B +  \delta B_{\text{\rm from E}} + N^B$;
(red/dots) all order E/B from E test assuming
$E^{\rm obs} = E + \delta E_{\text{\rm from E}} + N^E$ and
$B^{\rm obs} = B +  \delta B_{\text{\rm from E}} + N^B$.
}
\end{figure*}


\begin{enumerate}[label=(\roman*)]
    \item First we do a null test.
In accordance with the two approximations made in the quadratic delenser (Section \ref{sec:delen}),
we completely drop lensing in E modes and only keep linear order lensing in B modes, i.e.,
we simulate polarization maps assuming $E^{\rm obs} = E + N^E$
and $B^{\rm obs} = B + \delta^1B_{\text{\rm from E}} + N^B$, where
$N^{E/B}$ is the E/B map noise, and  $\delta^1B_{\text{\rm from E}}$ is the linear order lensing in B from E.
As expected, we find the quadratic delenser is not biased in this context
(Figure \ref{fig:f4}, black/solid lines).\footnote{From the null test,
where we ignore the non-stationarity of the delensed B modes,
we conclude that the bias induced by ignoring  the non-stationarity
is negligible.}\footnote{Comparing the detection level of the null test (solid line in the left panel of Figure \ref{fig:f4}),
and the detection level of the modified Gaussian likelihood (solid line in the second panel of Figure \ref{fig:f3}),
we find the two matches exactly. Therefore, we confirm the validity of
the two major approximations used in the modified Gaussian likelihood:
only keeping a few projected data vectors,
and igoring the cross relation between different projected data vectors.}

    \item To scrutinize the bias introduced by ignoring lensing in E modes,
we keep all order lensing in E modes and linear order lensing in B modes,
i.e., we simulate polarization maps assuming
$E^{\rm obs} = E +  \delta E_{\text{\rm from E}} + N^E$
and $B^{\rm obs} = B^r + \delta^1B_{\text{\rm from E}} + N^B$.
In this context, the quadratic delenser is highly biased (Figure \ref{fig:f4}, green/bar lines).

    \item In the same way, to test the bias introduced by ignoring high order lensing terms in B modes,
we ignore lensing in E modes and keep all order lensing in B modes, i.e.,
we do simulations assuming $E^{\rm obs} = E  + N^E$
and $B^{\rm obs} = B + \delta B_{\text{\rm from E}} + N^B$.
In this context, we also find the quadratic delenser is highly biased.
More interestingly, we find that the bias level almost exactly matches that of ignoring lensing in E modes
(Figure \ref{fig:f4}, blue/dashed lines).

    \item The final step is to check the interaction between the two bias terms from (iii) and (iv).
For this purpose, we keep all order lensing in E modes and all order lensing in B modes,
i.e., we simulate polarization maps assuming $E^{\rm obs} = E + \delta E_{\text{\rm from E}} + N^E$,
and $B^{\rm obs} = B +  \delta B_{\text{\rm from E}} + N^B$.
We find that the two bias contributions cancel to a high precision
and therefore the net bias is strongly suppressed (Figure \ref{fig:f4}, red/dots).

To make sense of the bias cancellation, we do a simple magnitude analysis.
In the quadratic delenser, we delense the B modes via a quadratic template subtraction
$B^{\rm res} = B_{\text{\rm from E}}- E^{\rm obs}*\phi^{\rm est}$,
and assume a residual power spectrum
$C^{BB,{\rm res}}_\ell = \langle |\delta^1 B_{\text{\rm from E}}- E*\phi^{\rm est}|_\ell^2 \rangle$,
where $*$ denotes the convolution defined in Equation (\ref{eq:convol},\ref{eq:wconvol}),
in the $\delta^1 B_{\text{\rm from E}}$ term we ignore
the second (and higher) order lensing in B modes $\delta^2 B_{\text{\rm from E}}$,
and in the $E*\phi$ term we ignore the difference of $E$ and $\widetilde E$.
Therefore the template subtraction used has an error
$\delta^2 B_{\text{\rm from E}}- \delta^1 E_{\text{\rm from E}} * \phi$,
where both error terms are of the same order $O(E\phi^2)$ considering that
\be
\begin{aligned}
&(\delta^2 B_{\text{\rm from E}})_{\Bell} \\
=& -\frac{1}{2}\int \frac{d^2 {\Bell_1}d^2 {\Bell_2}}{(2\pi)^2}
[({\Bell_1}+ {\Bell})\cdot({\Bell_1}+ {\Bell_2})]  \\
& [({\Bell_1}+ {\Bell})\cdot {\Bell_2}] E_{{\Bell_1}+ {\Bell}} \sin(2\varphi_{{\Bell_1}+ {\Bell}, {\Bell}})
\phi^*_{{\Bell_1}+ {\Bell_2}} \phi_{\Bell_2},
\end{aligned}
\ee
and
\be
\begin{aligned}
&(\delta^1 E_{\text{\rm from E}})_{\Bell} \\
= & \int \frac{d^2 {\Bell'}}{2\pi} {\Bell'} \cdot ({\Bell'}+ \Bell) E_{{\Bell'}+\Bell}
\cos(2\varphi_{{\Bell'}+\Bell,\Bell}) \phi^*_{\Bell'}.
\end{aligned}
\ee

\end{enumerate}


To summarize, in the quadratic delenser,
\be
B^{\rm del}_{\Bell} = B^r_{\Bell} + B^{\rm res}_{\Bell} + N^B_{\Bell},
\ee
we have ignored lensing in E modes and high order lensing in B modes when estimating
the residual power spectrum $\langle |B^{\rm res}_{\Bell}|^2\rangle$.
We find that each of the two approximation introduces a strong bias in the $r$ estimate,
while the two bias contributions cancel to a high precision,
and the validity of the quadratic delenser sensitively depends on the cancellation.

According to the above analysis, the bias in the residual power estimate
in principle is independent of primordial B-mode signal $B^r$,
therefore we naively expect a $r$-independent bias ${\rm Bias}(r)$
and therefore a bias level ${\rm Bias}(r)/r$ decaying with growing $r$,
which is indeed the behavior we observe for
$r\lesssim 0.01$ (Figure \ref{fig:f3} and \ref{fig:f4}).
But the bias level does not dies down for even greater $r$,
since the $r$ constraints become more sensitive to higher frequency
regime where the bias is stronger. Here we give an informal analysis
of the  bias level behavior.
From a single delensed B modes $B^{\rm del}_{\Bell}$,
we can estimate the primordial B-mode power spectrum
with root variance $\Delta C_{\Bell} = C^{BB,r}_{\Bell} + C^{BB,{\rm res}}_{\Bell} + N^{BB}_{\Bell}$,
and  consequently estimate $r$ with mean value
\be
r^{\rm est}_{\Bell} = \frac{|B^{\rm del}_{\Bell}|^2 - C^{BB,{\rm res}}_{\Bell}- N^{BB}_{\Bell}}{C^{BB,r=1}_{\Bell}},
\ee
and
with root variance $\sigma_{\Bell}(r) = \Delta C_{\Bell}/C^{BB,r=1}_{\Bell}$.
These estimators from different modes can be added with inverse-variance weighting
$r^{\rm est} = \sum_{\Bell} W_{\Bell} r^{\rm est}_{\Bell}$,
where
\be
W_{\Bell}(r) = \frac{\frac{1}{\sigma^2_{\Bell}(r)}}{\sum_{\Bell} \frac{1}{\sigma^2_{\Bell}(r)}}.
\ee
It is straightforward to understand that  $W_{\Bell}(r)$ increases with $r$ for large $|{\Bell}|$
where $C^{BB,{\rm res}}_{\Bell}+ N^{BB}_{\Bell}$ dominates $\Delta C_{\Bell}$,
and decreases with $r$ for small $|{\Bell}|$ where $C^{BB,r}_{\Bell} $ dominates $\Delta C_{\Bell}$.
In addition, we know that the quadratic delenser is a biased estimator, i.e.,
\be
\langle |B^{\rm del}_{\Bell}|^2 \rangle = C^{BB,{\rm res}}_{\Bell} + N^{BB}_{\Bell} + C^{BB,r}_{\Bell} + C^{BB,{\rm bias}}_{\Bell},
\ee
and
\be
\langle r^{\rm est}_{\Bell} \rangle = \frac{C^{BB,r}_{\Bell} + C^{BB,{\rm bias}}_{\Bell} }{C^{BB,r=1}_{\Bell}}
= r + r^{\rm bias}_{\Bell},
\ee
where $r^{\rm bias}_{\Bell}$ increases with $|{\Bell}|$.
Therefore, we have $\langle r^{\rm est}\rangle
= \sum_{\Bell} W_{\Bell} \langle r^{\rm est}_{\Bell}\rangle
= r   + \sum_{\Bell} W_{\Bell}(r) r^{\rm bias}_{\Bell}
= r   + {\rm Bias}(r)$,
with ${\rm Bias}(r)$ increasing with $r$.
It also explains the increasing bias level ${\rm Bias}(r)$ with
decreasing map noise $N^{BB}_{\Bell}$ (see Figure \ref{fig:f3}).
Note that we do not expect the quadratic delenser
to exactly match the inverse-variance weighted estimator described above, but the latter
should a good proxy for interpreting the bias behavior.


\subsection{Non-stationary Noise }
\label{sec:nonsta}

\begin{figure*}
\centering
\includegraphics[height=2in]{f5a.pdf}%
\includegraphics[height=2in]{f5b.pdf}%
\includegraphics[height=2in]{f5c.pdf}
\caption{\label{fig:nonsta}
The impact of non-stationary map noise on the $r$ constraints for the Scenario La experiments
($\Delta_{\rm T} = 1\ \mu$K-arcmin).
Left panel: the non-stationary noise modulation $\sigma(\mathbf x)$.
Middle/Right panel: the detection/bias level of $r$ constraints inferred from the two delensers.}
\end{figure*}

The modified Gaussian likelihood  works not only as a correction to
the quadratic template subtraction estimator,
but also shows its advantage in dealing with realistic experiment complexities,
e.g., non-stationary noise and sky cuts.
Here we explore an example of non-stationary noise with pixel
dependent noise, i.e., $\left< n(\mathbf x) n(\mathbf y)\right>
= \sigma^2(\mathbf x)\Delta_{\rm P}^2 \delta_D(\mathbf x-\mathbf y)$,
with $\Delta_{\rm P}=\sqrt{2} \ \Delta_{\rm T} = \sqrt{2}\ \mu$K-arcmin, and
$\sigma(\mathbf x)$  a pixel-dependent modulation (Figure \ref{fig:nonsta}).
We expect the likelihood based estimator to work robustly in the presence of non-stationary noise,
as long as we take the pixel dependent noise into account
when calculating the covariance matrix of noise (see Appendix \ref{sec:app2}).
But the non-stationary noise becomes troublesome for
the quadratic delenser in  Fourier space.
\footnote{In the case of non-stationary noise,
the noise power spectrum loses the protection of symmetry,
i.e, $\langle n_{\Bell}n_{\Bell'}\rangle = N_{\Bell,\Bell'}$ now depends on
both multipoles instead of their linear combination $\Bell,\Bell'$.
If we were to correctly use the quadratic delenser,
then the residual power evaluation in Equation (\ref{eq:respower})
becomes difficult, and is out of the scope of this paper.
Here we simply (but incorrectly) assume the stationary noise power spectrum in Equation (\ref{eq:respower}),
and test how the non-stationary noise biases the $r$ constraint from the quadratic delenser.}

Applying the two estimators on simulations with non-stationary noise,
we find that the modified Gaussian likelihood method works as well as in the case of stationary noise,
while the quadratic delenser is significantly biased (Figure \ref{fig:nonsta}).

\section{Summary and Conclusions}
\label{sec:summary}

Delensing is a crucial part for future CMB experiments aiming to detect a primordial B-mode signal.
Up to linear order, one can effectively delense observed B-modes by utilizing
a quadratic combination of observed E-modes and an estimate of the lensing potential.
This is the underlying idea of the quadratic delenser.
However, in the regime of small map noise,
the lensing in E modes, and higher order lensing in B modes
ignored by the quadratic delenser, significantly bias the $r$ constraint.
We investigated the bias induced by each of the two approximations via simulations,
finding that each of two approximations induce a large bias, while the two bias terms
partly cancel and therefore the net bias is moderately suppressed.
The validity of the quadratic delenser sensitively depends on the cancellation.

Alternatively,  a full-scale likelihood analysis of the tensor-to-scalar ratio $r$ can,
in principle, optimally account for all the $r$ information in the CMB observations and
remedy possible bias problems.
Unfortunately, a full likelihood analysis requires computation resources beyond
what is available in the near future.
In this paper, we presented a modified Gaussian likelihood method.
This method consists of two parts, covariance decomposition and data compression.
In the first part, we decomposed the covariance matrix
in the form of $\Sigma_r = \Sigma^{\rm en} + r \Sigma^{\rm b}$,
which allows us to compute the covariance matrix $\Sigma_r$, as a function of $r$, at the computational cost
of a single covariance matrix evaluation.
In the second part, we compressed the data size by keeping only $s\sim 500$
high signal-to-noise modes, say the large-scale quadratic delensed B modes.
We obtained these B modes from polarization data $d$ via a projection matrix $v$,
$(^0B^{\rm del}_{\Bell})_s = (v^\intercal)_{s\times 2p} d_{2p}$,
and applied the likelihood analysis on the projected data vector.
This method can be naturally extended to incorporate higher frequency modes.

Finally, we applied the quadratic delenser and
the modified Gaussian likelihood method on simulated CMB observations mimicking experiments of
Scenario N, La, and Lb, and compare the resulting $r$ constraints.
We found that, the two methods have similar performance in constraining $r$
for Scenario N, while the quadratic delenser does not perform
as well for the lower-noise Scenario La and Lb due to a strong $r$ constraint bias
in the regime of low map noise. For Scenario La, we expected to detect the
primordial B-mode signal at $\sim 1 \sigma$ level for $r=0.001$, and at $\sim 15 \sigma$ level for $r=0.1$,
from the modified Gaussian likelihood method.
For Scenario Lb with even lower map noise and the same sky coverage,
the detection level only marginally increases due to the saturation of cosmic variance.
Therefore it would be valuable to optimize the survey configurations (${\Delta_{\rm T}, f_{\rm sky}}$)
for the coming CMB experiments given a fixed amount of survey time \citep{s42016}.

We also explored the impact of realistic experiment complexities:
in the presence of non-stationary noise, the modified Gaussian likelihood method also works robustly
as long as we slightly modify the noise covariance matrix to take into account the pixel dependent noise.


\begin{acknowledgements}
ZP is supported by UC Davis Dissertation Year Fellowship.
EA acknowledges support from NSF CAREER grant DMS-1252795.
This work made extensive use of the NASA Astrophysics Data System and
of the {\tt astro-ph} preprint archive at {\tt arXiv.org}.
\end{acknowledgements}

\bibliography{ms}

\appendix
\section{Signal Covariance Matrix}
\label{sec:app1}

There are eight different terms in the map covariance matrix $\Sigma_r$:
$\{ \tilde\Sigma^{SE,SE},\tilde\Sigma^{CE,SE},\tilde\Sigma^{CE,CE} \}$,
$\{ \tilde\Sigma^{SB,SB},\tilde\Sigma^{CB,SB},\tilde\Sigma^{CB,CB} \}$,
and $\{ \Sigma^{NQ,NQ},\Sigma^{NU,NU} \}$ (see Equations (\ref{eq:elements})).
In this subsection, we show how the marginalization over uncertainty in the $\phi$ estimate
is done for the six lensed signal terms,
and leave the two noise terms to the next subsection.
Take $\tilde\Sigma^{XX} (X = SE)$ as an example,
\begin{widetext}
\be
\begin{aligned}
\left<\tilde\Sigma^{XX}_{r,\phi} \right>_{n\phi}
& = \left<\widetilde X(\mathbf x) \widetilde X(\mathbf y)  \right>_{n\phi} \\
& = \left<X(x + \nabla \mu\phi(\mathbf x) + \nabla n\phi(\mathbf x))
 X(\mathbf y + \nabla \mu\phi(\mathbf y) + \nabla n\phi(\mathbf y)) \right>_{n\phi} \\
& = \int \frac{d^2\Bell}{(2\pi)^2} e^{i \Bell\cdot (\mathbf x- \mathbf y+\nabla\mu\phi(\mathbf x) - \nabla\mu\phi(\mathbf y))}
C_\ell^{XX} \left< e^{i\Bell\cdot(\nabla n\phi(\mathbf x) -\nabla n\phi(\mathbf y))}\right>_{n\phi} \\
& = \int \frac{d^2\Bell}{(2\pi)^2} e^{i \Bell\cdot (\mathbf x-\mathbf y+\nabla\mu\phi(\mathbf x) - \nabla\mu\phi(\mathbf y))}
C_\ell^{XX} \exp\{-\Bell\cdot \left[\Sigma^{n\phi}(0)-\Sigma^{n\phi}(\mathbf x-\mathbf y)\right] \cdot \Bell\}  \\
&\simeq \int \frac{d^2\Bell}{(2\pi)^2} e^{i \Bell\cdot (\mathbf x-\mathbf y+\nabla\mu\phi(\mathbf x) - \nabla\mu\phi(\mathbf y))}
C_\ell^{XX} \left(1- \Bell\cdot \left[\Sigma^{n\phi}(0)-\Sigma^{n\phi}(\mathbf x-\mathbf y)\right] \cdot \Bell\right)  \\
& = \int \frac{d^2\Bell}{(2\pi)^2} e^{i \Bell\cdot (\mathbf x-\mathbf y+\nabla\mu\phi(\mathbf x) - \nabla\mu\phi(\mathbf y))} C_\ell^{XX}  \\
& - \sum_{p,q=1}^2 \left[\Sigma^{n\phi}(0)-\Sigma^{n\phi}(\mathbf x-\mathbf y)\right]_{p,q}
\int \frac{d^2\Bell}{(2\pi)^2} \ell_p \ell_q e^{i \Bell\cdot (\mathbf x-\mathbf y+\nabla\mu\phi(\mathbf x) - \nabla\mu\phi(\mathbf y))} C_\ell^{XX} \\
& = {\rm Cov}(X(\mathbf w), X(0))
+ \sum_{p,q=1}^2 \left[\Sigma^{n\phi}(0)-\Sigma^{n\phi}(\mathbf x-\mathbf y)\right]_{p,q}
\partial_{p,q} {\rm Cov}(X(\mathbf w), X(0))
\end{aligned}
\ee
where we have used cumulant expansion at the 4th equal sign,  $\left[\Sigma^{n\phi}(\mathbf x-\mathbf y)\right]_{p,q}$
is the covariance of $\nabla(n\phi)$, i.e.,
\be
\begin{aligned}
\label{eq:a2}
    \left[\Sigma^{n\phi}(\mathbf x-\mathbf y)\right]_{p,q}
  & = \left< \nabla_p n\phi(\mathbf x) \nabla_q n\phi(\mathbf y)\right>_{n\phi}
    = \int \frac{d^2\Bell}{(2\pi)^2} \ell_p \ell_q e^{i\Bell\cdot (\mathbf x-\mathbf y)} N_\ell^{\phi\phi},
\end{aligned}
\ee

\end{widetext}
and ${\rm Cov}(X(\mathbf w), X(0))$ is the covariance of $X$
at separation $\mathbf w =\mathbf x-\mathbf y + \nabla\mu\phi(\mathbf x)-\nabla\mu\phi(\mathbf y)$,
\be
\label{eq:a3}
    {\rm Cov}(X(\mathbf w), X(0)) = \int \frac{d^2\Bell}{(2\pi)^2} e^{i \Bell\cdot \mathbf w} C_\ell^{XX}.
\ee


The above two dimensional integrals (Equations (\ref{eq:a2}-\ref{eq:a3})) can be simplified as  one dimensional integrals
as follows. Take Equation (\ref{eq:a3}) as an example,
\be
\label{eq:a4}
\begin{aligned}
{\rm Cov}\left( X(\mathbf w), X(0) \right)
& = 4\partial_1^2\partial_2^2 \int \frac{d^2\Bell}{(2\pi)^2} e^{i\Bell\cdot \mathbf w} C_\ell^{\mE\mE}\\
&\equiv 4\partial_1^2\partial_2^2 K^{\mathcal E}(w),
\end{aligned}
\ee
where we have used $C_\ell^{XX} = 4\ell_1^2 \ell_2^2 (C_\ell^{EE}/\ell^4)$
and defined $C_\ell^{\mE\mE} \equiv C_\ell^{EE}/\ell^4 $.
Exploiting the integral representation of Bessel functions, we rewrite $K^{\mathcal E}(\mathbf w)$ as a one dimensional
integral
\be
\begin{aligned}
K^{\mathcal E}(\mathbf w)
&=\int \frac{d^2\Bell}{(2\pi)^2} e^{i\Bell\cdot \mathbf w} C_\ell^{\mE\mE} \\
&=\frac{1}{2\pi}\int  J_0\left(\ell w \right)  C_\ell^{\mE\mE} \ell d\ell,
\end{aligned}
\ee
which has no angular dependence.
For derivative calculation, we define $\hat K(w^2) \equiv K^{\mathcal E}(\mathbf w)$,
then
\be
\label{eq:a6}
\begin{aligned}
&\partial_1^2 \partial_2^2 K^{\mathcal E}(\mathbf w)
=\partial_1^2 \partial_2^2 \hat K (w^2) \\
&= 16w_1^2w_2^2 \ \hat K^{(4)}(w^2)  \\
& + 8(w_1^2 + w_2^2) \ \hat K^{(3)}(w^2)  + 4\hat K^{(2)}(w^2).
\end{aligned}
\ee
Using the property
\be
\frac{d}{dz} z^{-s} J_s(z) = - z^{-s} J_{s+1}(z),
\ee
the $n$-th order derivative $\hat K^{(n)}$ is explicitly expressed as
\be
\label{eq:a8}
\hat K^{(n)}(w^2)
= \frac{1}{2\pi} \int \left(-\frac{\ell}{2w} \right)^n  J_n(\ell w) \ell d\ell.
\ee
Collecting Equations (\ref{eq:a4}, \ref{eq:a6}, \ref{eq:a8}),  ${\rm Cov}\left( X(\mathbf w), X(0) \right)$
is decomposed into a few one dimensional integrals.
The calculation of $\partial_{p,q}{\rm Cov}\left( X(\mathbf w), X(0) \right)$ and
$\left[\Sigma^{n\phi}(\mathbf x-\mathbf y)\right]_{p,q}$ is conducted in the same way.
For other lensed terms, the above formulas apply similarly.

\section{Noise Covariance Matrix}
\label{sec:app2}

In Section \ref{sec:app1}, we completely ignore the consequence of the finite beam size in
the signal covariance evaluation, since the signal suppression by the beam convolution
can be interpreted as the noise enhancement by the beam deconvolution.
For noise field $n(\mathbf x)$,  we denote the deconvolved noise field as
$X(\mathbf x) = \varphi^{-1}_x[ n(\mathbf x) ]$, with
\be
\begin{aligned}
    \varphi^{-1}_x[ n(\mathbf x) ]
    &= \int \frac{d^2\Bell}{2\pi} e^{i\Bell\cdot \mathbf x}  \frac{n_{\Bell}}{\varphi_{\Bell} }\\
    &=\int \frac{d^2\Bell}{2\pi} \frac{d^2\mathbf x'}{2\pi}
    e^{i\Bell\cdot (\mathbf x- \mathbf x')}  \frac{n(\mathbf x')}{\varphi_{\Bell} },
\end{aligned}
\ee
\begin{widetext}
where for Gaussian beam profile
$\varphi(\mathbf x) = \frac{1}{2\pi\sigma_b^2} \exp\left(-\frac{\mathbf x^2}{2\sigma_b^2}\right)$,
$\varphi_{\Bell} = \exp \left(-\frac{l^2 \sigma_b^2}{2} \right)$, and $\sigma_b^2 = \theta^2_{\rm FWHM}/(8 \ln 2)$.
Then
\begin{align}
    \Sigma^{XX} = \left< X(\mathbf x) X(\mathbf y)\right>
    &= \int \frac{d^2\Bell}{2\pi}
    \frac{d^2\mathbf x'}{2\pi} \frac{d^2\mathbf k}{2\pi} \frac{d^2\mathbf y'}{2\pi}
    e^{i\Bell\cdot (\mathbf x- \mathbf x')}
     e^{i\mathbf k\cdot (\mathbf y- \mathbf y')}  \frac{1}{ \varphi_{\Bell}\varphi_{\mathbf k} }
    \left<n(\mathbf x') n(\mathbf y') \right>,
\end{align}
For simple white noise
$\left< n(\mathbf x) n(\mathbf y)\right> =\Delta_{\rm P}^2 \delta_D(\mathbf x-\mathbf y)$, we have
\begin{align}
    \left< X(\mathbf x) X(\mathbf y)\right>
    &= \int \frac{d^2\Bell}{(2\pi)^2}
    e^{i\Bell\cdot (\mathbf x -\mathbf y)}
    \frac{\Delta_{\rm P}^2 }{ \varphi_{\Bell} \varphi_{-\Bell} }
    = \Delta_{\rm P}^2 \int \frac{d^2\Bell}{(2\pi)^2}
    e^{i\Bell\cdot (\mathbf x -\mathbf y)}\ e^{\ell^2\sigma_b^2},
\end{align}

where
$\Delta_{\rm P}$ is polarization noise and we usually take $\Delta_{\rm P} = \sqrt{2} \Delta_{\rm T}$.
For more realistic non-stationary noise $\left< n(\mathbf x) n(\mathbf y)\right>
= \sigma^2(\mathbf x)\Delta_{\rm P}^2 \delta_D(\mathbf x-\mathbf y)$,
the covariance matrix of the deconvolved noise field $X(\mathbf x)$ is written as
\be
\begin{aligned}
    \left< X(\mathbf x) X(\mathbf y)\right>
    &= \left<\varphi_x^{-1}[n(\mathbf x)]  \ \varphi_y^{-1}[n(\mathbf y)]\right> \\
    &= \left<\varphi_x^{-1}[n(\mathbf x)]  \ \int \frac{d^2\Bell}{2\pi} \frac{d^2\mathbf y'}{2\pi}
    e^{i\Bell\cdot (\mathbf y- \mathbf y')}  \frac{n(\mathbf y')}{\varphi_{\Bell}} \right>\\
    &= \varphi_x^{-1} \left[  \int \frac{d^2\Bell}{2\pi} \frac{d^2\mathbf y'}{2\pi}
    e^{i\Bell\cdot (\mathbf y- \mathbf y')}  \frac{1}{\varphi_{\Bell}} \left<n(\mathbf x)n(\mathbf y') \right> \right] \\
    &=\varphi_x^{-1} \left[ \sigma^2(\mathbf x) \Delta_{\rm P}^2  \int \frac{d^2\Bell}{(2\pi)^2}
    e^{i\Bell\cdot (\mathbf y- \mathbf x)}  e^{\frac{\ell^2\sigma_b^2}{2}} \right]
\end{aligned}
\ee
where we have exchanged the order of deconvolution and ensemble average at the 3rd equal sign,
since deconvolution is a linear operator.

\be
\begin{aligned}
    \left< X(\mathbf x) X(\mathbf y)\right>
    &= \Delta_{\rm P}^2 \int \frac{d^2\Bell}{(2\pi)^2}
    \frac{d^2\mathbf k}{2\pi}     e^{i\Bell\cdot \mathbf x}
         e^{i\mathbf k\cdot \mathbf y}   \varphi_{\Bell}\varphi_{\mathbf k}
        \left[ \int \frac{d^2\mathbf x'}{2\pi}  e^{-i(\Bell + \mathbf k)\cdot \mathbf x'} \delta^2(\mathbf x') \right]\\
    &= \Delta_{\rm P}^2 \int \frac{d^2\Bell}{(2\pi)^2}
    \frac{d^2\mathbf k}{2\pi}     e^{i\Bell\cdot \mathbf x}
         e^{i\mathbf k\cdot \mathbf y}   \varphi_{\Bell}\varphi_{\mathbf k}\
          (\delta^2)_{\Bell + \mathbf k} \\
    &= \Delta_{\rm P}^2 \int \frac{d^2\Bell}{(2\pi)^2}
    e^{i\Bell\cdot \mathbf x} \varphi_{\Bell}
          \int \frac{d^2\mathbf k}{2\pi}
               e^{i\mathbf k\cdot \mathbf y}   \varphi_{\mathbf k}\
                (\delta^2)_{\Bell + \mathbf k}
\end{aligned}
\ee

\end{widetext}


\section{Inverse of Covariance Matrix}
\label{sec:app3}
The inverse covariance matrix $\Sigma_r^{-1}$ evaluation  is the key to
the $r$ likelihood in Equation~(\ref{eq:likeli}).
To avoid repeating the similar computation for every different $r$, we can single out the $r$ dependence
rewriting the covariance matrix in the form
$\Sigma_r = \Sigma^{\rm en} + r \Sigma^{\rm b}$,
where

\[
\begin{aligned}
\Sigma^{\rm en}
&=
\left(
\begin{tabular}{cc}
    $\tilde \Sigma^{CE,CE} + \Sigma^{NQ,NQ}$ & $\tilde\Sigma^{CE,SE}$ \\
    $\tilde \Sigma^{CE,SE}$ & $\tilde\Sigma^{SE,SE}+\Sigma^{NU, NU}$
\end{tabular}
\right), \\
\Sigma^{\rm b}
&=
\left(
\begin{tabular}{cc}
    $\tilde \Sigma^{SB^0,SB^0}$ & $\tilde \Sigma^{CB^0,SB^0}$ \\
    $\tilde \Sigma^{CB^0,SB^0}$ & $\tilde \Sigma^{CB^0,CB^0}$
\end{tabular}
\right).
\end{aligned}
\]


Both $\Sigma^{\rm en}$ and $\Sigma^{\rm b}$ are symmetric and positive definite.
We first decompose $\Sigma^{\rm b}$ as $\Sigma^{\rm b} = V\Lambda V^\intercal$,
with $\Lambda$ being a diagonal matrix composed of its eigenvalues,
and $V$ being a matrix composed of its eigenvectors.
Now we do a little manipulation to the covariance matrix
\be
\begin{aligned}
\Sigma_r
&= \Sigma^{\rm en}  + r V\Lambda V^\intercal \\
&= V\sqrt{\Lambda} \left(\sqrt{\Lambda^{-1}}V^\intercal \Sigma^{\rm en}V\sqrt{\Lambda^{-1}}  + r I\right) \sqrt{\Lambda} V^\intercal,
\end{aligned}
\ee
where we have used the orthogonality $V^\intercal = V^{-1}$. One more eigendecomposition,
$\sqrt{\Lambda^{-1}}V^\intercal \Sigma^{\rm en} V\sqrt{\Lambda^{-1}} = \hat V \hat \Lambda \hat V^\intercal$,
enables us further transform $\Sigma_r$ as
\be
\begin{aligned}
\Sigma_r
&= V\sqrt{\Lambda}\hat V \left( \hat \Lambda + r I\right)  \hat V^\intercal \sqrt{\Lambda} V^\intercal\\
&= V\sqrt{\Lambda}\hat V \left( \hat \Lambda + r I\right)  (V\sqrt{\Lambda}\hat V )^\intercal.
\end{aligned}
\ee
Here we can obtain the inverse matrix $\Sigma_r^{-1}$ at little cost, using the orthogonality of $V$ and $\hat V$.
And more beautifully,  all the matrices $V, \Lambda$ and $\hat V, \hat\Lambda$ have no $r$ dependence,
hence we obtain the inverse covariance matrix as a function of $r$ at the same computation cost
of a single inverse matrix computation.


\end{document}

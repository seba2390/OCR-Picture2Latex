\section{Synth-Validation}
\label{sec:algo}

Synth-validation consists of two steps: 1. creating generative distributions that are informed by the observed data (section \ref{sec:gen-model}) and 2. using data sampled from those distributions to benchmark causal inference methods (section \ref{sec:run-meth}). 

The entire process is visualized in figure \ref{fig:synth-val}

\subsection{Generative Modeling} 
\label{sec:gen-model}

In this section, we describe the algorithms we use to create the generative distributions for synth-validation. Our goal is not to directly estimate the unknown true data-generating distribution $P(X,W,Y)$. However, we will loosely use the term ``estimate'' to describe the process of creating our generative distributions, since they are informed by the observed data. If we were confident that we could estimate $P(X,W,Y)$ with a particular method, then causal inference could proceed by directly estimating $P(X,W,Y)$ and calculating the treatment effect under that model using equation \ref{eq:effect}.

Instead, we \emph{specify} a desired treatment effect prior to estimating each generative model. We call these ``synthetic treatment effects'' and write them as $\tilde{\tau}_i$. We discuss how to decide good values for these synthetic effects in section \ref{sec:synth-effect}. For each synthetic effect, we find a generative distribution $P(\tilde X, \tilde W, \tilde Y)$ that both satisfies the synthetic effect (i.e. $\tilde\tau = E_{\tilde X,\tilde Y}[\tilde Y| \tilde X, \tilde W=1] - E_{\tilde X,\tilde Y}[\tilde Y| \tilde X, \tilde W=0]$) and maximizes the likelihood of the observed data. The result is a set of distributions $\{P(\tilde X_1, \tilde W_1, \tilde Y_1), P(\tilde X_2, \tilde W_2, \tilde Y_2) \dots\}$. Using multiple distributions is analogous to regularization. Using a single estimate of $P(X,W,Y)$ for benchmarking purposes could ``over-fit'' to the observed data, whereas using a variety of handcrafted generative models that are not tailored to the observed data would ``under-fit'' by attempting to find a one-size-fits-all best method. Setting the treatment effect and allowing the data to dictate the rest of the distribution allows us to vary the generative distributions along the single parameter that we are interested in estimating. The choice of synthetic effects impacts how well the distributions $P(\tilde X, \tilde W, \tilde Y)$ can stand in for $P(X, W, Y)$ in the benchmarking process (figure \ref{fig:bakeoff}), but we show empirically that the heuristic we develop in section \ref{sec:synth-effect} makes synth-validation robust against misspecification.

To simplify the problem of optimally estimating distributions $P(\tilde X, \tilde W, \tilde Y)$ from the observed data $(\mathbf{x}, \mathbf{w}, \mathbf{y})$ we factor the distribution $P(\tilde X, \tilde W, \tilde Y) = P(\tilde Y | \tilde X, \tilde W)P(\tilde X, \tilde W)$ and estimate each factor separately. We estimate $P(\tilde X, \tilde W)$ with $P(X^*, W^*)$, which is the empirical distribution of $(X,W)$ and the nonparametric MLE \cite{Efron:1993dc}. This allows us to simplify the expression for the treatment effect (equation \ref{eq:effect}) by replacing the expectation over $\tilde X$ with a discrete sum:

\begin{equation}
\begin{array}{rcl}
\tilde \tau & = & E_{\tilde X, \tilde Y}[ \tilde Y| \tilde X, \tilde W=1]  - E_{\tilde X,\tilde Y}[\tilde Y| \tilde X, \tilde W=0] \\
& = & \frac{1}{n}\sum_iE_{\tilde Y}[ \tilde Y| \tilde X=x_i, \tilde W=1]  - \frac{1}{n}\sum_i E_{\tilde Y}[\tilde Y| \tilde X=x_i, \tilde W=0] \\
& = & \frac{1}{n}\sum_i[\mu_1(x_i) - \mu_0(x_i)]
\end{array}
\label{eq:constraint}
\end{equation}

where $\mu_0(\tilde x) = E[\tilde{Y}|\tilde X, \tilde W=0]$ and $\mu_1(\tilde x)=E[\tilde{Y}|\tilde X, \tilde W=0]$ are the conditional mean functions of the outcome given each treatment condition. 

The task is now to estimate $P(\tilde Y | \tilde X, \tilde W)$. For this we assume a model: 

\begin{equation}
\begin{array}{rcl}
\tilde y_i & = & I_0(\tilde w_i)\mu_0(\tilde x_i) + I_1(\tilde w_i)\mu_1(\tilde x_i)+ \varepsilon_i \\
\varepsilon_i & \overset{\text{I.I.D.}}{\sim} & \mathcal{E}
\end{array}
\end{equation}

We will soon discuss how to estimate $\mu_0(\tilde x)$ and $\mu_0(\tilde x)$, but for the time being, assume we have estimated these functions. We calculate the observed residuals $r_i = y_i - I_0(w_i)\mu_0(x_i) + I_1(w_i)\mu_1(x_i)$ and use their empirical distribution $P(R^*)$ as an estimate of $\mathcal{E}$, which is a noise model for the outcomes.

The final task is to estimate $\mu_0(\tilde x)$ and $\mu_1(\tilde x)$. Standard machine learning approaches will not work because we must also satisfy the constraint we derived in equation \ref{eq:constraint}. Recall that we are \emph{specifying} the synthetic average treatment effect $\tilde \tau$ for each generative distribution. However, there is no need to ignore the observed data: we can estimate $\mu_0(\tilde x)$ and $\mu_1(\tilde x)$ by constraining the fitting of predictive models for each function. 

\begin{equation}
\mu_0(\tilde x), \mu_1(\tilde x) = 
\begin{cases}
\underset{f_0, f_1 \in \mathcal{F}}{\text{argmin}} \ \  \sum_{\mathcal{S}_0}  l(y_i, f_0(x_i)) + \sum_{\mathcal{S}_1}  l(y_i, f_1(x_i)) \\
\text{subject to:   } \frac{1}{n}\sum_i[f_1(x_i) - f_0(x_i)] = \tilde \tau
\end{cases}
\label{eq:opt}
\end{equation}

$\mathcal{F}$ is a set of functions, or model space, over which the algorithm searches. $l(y,f)$ is a loss function that defines the quality of fit for each candidate function $f$. We describe algorithms that find approximate solutions to problem \ref{eq:opt} in section \ref{sec:fitting}.

$\mu_0(\tilde x)$ and $\mu_1(\tilde x)$ are not meant to be estimates of the true conditional mean functions of the outcome under the true unobserved distribution $P(X,W,Y)$. Rather, $\mu_0(\tilde x)$ and $\mu_1(\tilde x)$ are the most likely conditional means under the assumption that the true unknown effect is the synthetic effect $\tilde \tau$ and that $P(X,W) = P(X^*, W^*)$. Again, if we could confidently estimate the true conditional means, we would not need to compare different methods. In particular, because of confounding, we are concerned about our ability to accurately estimate the true conditional means in areas of low covariate support. 

As with setting the synthetic effect, estimating $\mu_0(\tilde x)$ and $\mu_1(\tilde x)$ requires making modeling choices, the most important of which is the model space $\mathcal{F}$. If a causal inference method uses conditional mean modeling over the same model space $\mathcal{F}$ to estimate the treatment effect, it will be correctly specified relative to the generative distributions $P(\tilde X, \tilde W, \tilde Y)$. This could mean that synth-validation would be biased towards selecting that method. However, we show that this bias is not observed in practice when using a space of flexible models and discuss why that may be so in section \ref{sec:disc}.

With $\mu_0(\tilde x)$, $\mu_1(\tilde x)$, and $P(R^*)$ in hand, we sample from $P(\tilde X, \tilde W, \tilde Y)$:

\begin{equation}
\begin{array}{rcl}
(\tilde x_i, \tilde w_i) & \overset{\text{I.I.D.}}{\sim} & P(X^*, W^*) \\
r_i & \overset{\text{I.I.D.}}{\sim} & P(R^*) \\
\tilde y_i & = & I_0(\tilde w_i)\mu_0(\tilde x_i) + I_1(\tilde w_i)\mu_1(\tilde x_i)+ r_i
\end{array}
\end{equation}

We do this $n$ times to get a synthetic dataset $(\tilde{\mathbf{x}}, \tilde{\mathbf{w}}, \tilde{\mathbf{y}})$. This is a semi-parametric bootstrap where the ``parametric model'' for $\tilde y$ is $I_0(\tilde w_i)\mu_0(\tilde x_i) + I_1(\tilde w_i)\mu_1(\tilde x_i)$.

We now have all of the pieces in place to be able to create and sample from generative distributions that have known average treatment effects and are informed by the observed data:

\begin{enumerate}
\item Pick a set of synthetic effects $\{\tilde \tau_1, \tilde \tau_2 \dots\}$ (section \ref{sec:synth-effect})
\item For each synthetic effect, estimate $\mu_0(\tilde x)$ and $\mu_1(\tilde x)$ (section \ref{sec:fitting})
\item For each synthetic effect, combine $\mu_0(\tilde x)$ and $\mu_1(\tilde x)$ with $P(X^*, W^*)$ in a semi-parametric bootstrap to sample from $P(\tilde X, \tilde W, \tilde Y)$
\end{enumerate}

%%%%%%%% 

\subsubsection{Choosing the synthetic effects}
\label{sec:synth-effect}

Setting the synthetic effect allows us to benchmark the performance of causal inference methods on the resulting synthetic data. To most closely model reality, we would want to set the synthetic effect to the true effect, but if we knew the true effect we would not need to model anything. Since we do not have the true effect, we could use plug-in estimates of it. However, as previously stated, there are many causal inference methods, each of which produces a different estimate of the causal effect, and we do not a-priori know which of them to trust. This is the problem that motivates synth-validation. 

Since we do not know the true effect, we create generative distributions that span several plausible effects. To define the set of synthetic effects, we run each causal inference method $t \in \mathcal{T}$ on the observed data and record each effect estimate $\hat\tau_t$. We set the largest and smallest plausible effects to be the median of the estimates plus or minus a number $\gamma$ times the range of all the estimates. From this span, we evenly sample $Q$ synthetic treatment effects and call these $\tilde\tau_1, \tilde\tau_2, \dots \tilde\tau_Q$. Although data-driven and theoretically motivated, this is a heuristic and we investigate the impact of the choice of $\gamma$ and $Q$ in our evaluation. 

\subsubsection{Fitting constrained conditional mean models}
\label{sec:fitting}

To create the conditional distribution $P(\tilde Y| \tilde X, \tilde W)$ we must estimate the conditional mean functions $\mu_0(\tilde x)$ and $\mu_1(\tilde x)$ by solving problem \ref{eq:opt}, which we restate here for convenience:

\begin{equation}
\mu_0(\tilde x), \mu_1(\tilde x) = 
\begin{cases}
\underset{f_0, f_1 \in \mathcal{F}}{\text{argmin}} \ \  \sum_{\mathcal{S}_0}  l(y_i, f_0(x_i)) + \sum_{\mathcal{S}_1}  l(y_i, f_1(x_i)) \\
\text{subject to:   } \frac{1}{n}\sum_i[f_1(x_i) - f_0(x_i)] = \tilde \tau
\end{cases}
\end{equation}

We present two algorithms that we use for this purpose: fit-plus-constant and constrained gradient boosting. Fit-plus-constant is simple and uses off-the shelf software, but finds minima that are suboptimal compared to constrained gradient boosting. 

\paragraph{Fit-plus-constant algorithms}
We present a simple algorithm that sub-optimally minimizes the objective while satisfying the constraint: First we use any regression method (e.g. linear regression, gradient tree boosting) with a model space $\mathcal{F}$ to fit two functions $h_0(x)$ and $h_1(x)$ to the untreated and treated subsamples of the data, respectively. These two functions represent the two potential outcomes ``surfaces''. We then optimize constants to add to each function so that the synthetic treatment effect is satisfied:

\begin{equation}
c^\dagger_0, c^\dagger_1 =
\begin{cases}
\underset{c_0, c_1}{\text{argmin}} \ \  
\begin{array}{l}
\sum_{i \in \mathcal{S}_0}  l(y_i, h_0(x_i) + c_0) + \\
\sum_{i \in \mathcal{S}_1 } l(y_i, h_1(x_i) + c_1) 
\end{array} \\
\text{subject to:   } \tilde{\tau} = \frac{1}{n}\sum_i^n \big[(h_1(x_i) + c_1) - (h_0(x_i) + c_0)\big]
\label{eq:opt-proj-consts}
\end{cases}
\end{equation}

Since $h_w(x_i)$ are pre-computed, they are constant quantities in optimization problem \ref{eq:opt-proj-consts}. Using a squared-error loss, the objective reduces to $\sum_i^n ( c_{w_i}^2 + c_{w_i}r_i)$ where $r_i= y_i - h_{w_i}(x_i,w_i)$ are the residuals of the model fits. The constraint reduces to $c_1-c_0 = \tilde{\tau} - \hat{\tau}_h$ where $\hat{\tau}_h = \frac{1}{n}\sum_i^n \big[h_1(x_i) - h_0(x_i)\big]$. This is a two-variable quadratic program with a linear constraint that is quickly solved by off-the-shelf software.

After solving for $c^\dagger_0$ and $c^\dagger_1$, we set $\mu_0(\tilde x ) = h_0(\tilde x) + c^\dagger_0$ and $\mu_1(\tilde x) = h_1(\tilde x) + c^\dagger_1$. This two-step approach (1. fit, 2. add constant) can be used with any off-the-shelf machine learning and optimization software. It is also easy to fit models with different synthetic effects because the potential outcome models $h_w$ do not need to be refit. However, for most practical model spaces $\mathcal{F}$, this algorithm is not a principled approach to finding an approximate optimum for problem \ref{eq:opt}.
 
\paragraph{Constrained gradient boosting}
We develop a better way to approximately solve problem \ref{eq:opt} using gradient boosting \cite{Friedman:2001ue}. We fit the model and satisfy the constraint in a single algorithm. Our approach is related to gradient projection methods \cite{Rosen:1961jl}.

We posit that $\mu_0(\tilde x)$ and $\mu_1(\tilde x)$ are linear combinations of $m$ basis functions $\mu_{w_m}(\tilde x) = \sum_j^m \nu_{w_j} b_{w_j}(\tilde x)$ which we will greedily learn in stages from the data. For simplicity of exposition, we use squared-error loss: $l(y,f) = (y-f)^2$.

We begin by setting each of $\nu_{0_1} = \nu_{1_1} = 1$ and setting each of the first pair of basis functions as constants so that the synthetic treatment effect is satisfied:

\begin{equation}
b_{1_1}, b_{0_1} =
\begin{cases}
\underset{c_0, c_1}{\text{argmin}} \ \ 
\begin{array}{l}
\sum_{i \in \mathcal{S}_0}  l(y_i, c_0) + \\
\sum_{i \in \mathcal{S}_1}  l(y_i, c_1) 
\end{array}\\
\text{subject to:   } \tilde{\tau} = \frac{1}{n}\sum_i^n \big[c_1 - c_0\big]
\end{cases}
\label{eq:first-opt}
\end{equation}

This is a two-variable linearly constrained quadratic program that is quickly solved with off-the-shelf software.

In each successive stage $m>1$, we use a learning algorithm with model space $\mathcal{B}$ (a ``weak learner'') to independently fit each of a pair of basis functions to the residuals of the previous fits: 

\begin{equation}
\begin{array}{rcl}
b_{0_m}(x) & = & \underset{b \in \mathcal{B}}{\text{argmin}} \sum_{i \in \mathcal{S}_0} l \left(r_{m-1_i} , b(x_i) \right) \\
b_{1_m}(x) & = & \underset{b \in \mathcal{B}}{\text{argmin}} \sum_{i \in \mathcal{S}_1} l \left(r_{m-1_i} , b(x_i) \right) 
\end{array}
\end{equation}

where $r_{m-1_i} =y_i - I_0(w_i)\mu_{0_{m-1}}(x_i) - I_1(w_i)\mu_{1_{m-1}}(x_i)$ is the residual of the fit at stage $m-1$. The most popular form of boosting uses regression trees for the model space $\mathcal{B}$, and we follow suit in our own implementation so that each basis function $b_{w_j}(x)$ is the output of a regression tree fit to the previous residual.

% where $r_{w_i} = \frac{\partial l(y,f)}{\partial f} \bigg|_{f = \hat{f}_{w_{(m-1)}}^{(\tilde{\tau})}(x_i)} \ \ \forall \ i \in \{i|w_i = w\}$. 

Presuming that the synthetic effect constraint (equation \ref{eq:constraint}) is satisfied at stage $m-1$, adding the basis functions $b_{0_m}(x)$ and $b_{1_m}(x)$ to the model breaks the constraint satisfaction because the basis functions are fit without regard to the constraint. To maintain the constraint satisfaction at stage $m$ we must set the multipliers $\nu_{0_m}$ and $\nu_{1_m}$ such that $\sum_i^n \big[ \nu_{1_m}b_{1_m}(x_i) - \nu_{0_m}b_{0_m}(x_i) \big] = 0$. We therefore solve the following optimization problem:

\begin{equation}
\nu_{0_m}, \nu_{1_m} =
\begin{cases}
\underset{c_0, c_1}{\text{argmin}} \ \ 
\begin{array}{l} 
\sum_{i \in \mathcal{S}_0} l \left( y_i, \mu_{0_{m-1}}(x_i) + c_{0}b_{0_{i_m}}(x_i) \right) + 
\lambda c_0^2 + \\
\sum_{i \in \mathcal{S}_1} l \left( y_i, \mu_{1_{m-1}}(x_i) + c_{1}b_{1_{i_m}}(x_i) \right) + 
\lambda c_1^2
\end{array} \\
\text{subject to:   } \sum_i^n \big[ c_1 b_{1_m}(x_i) - c_0 b_{0_m}(x_i) \big] = 0
\end{cases}
\label{eq:stage-opt}
\end{equation}

Since the constraint is satisfied for $m=1$ by solving problem \ref{eq:first-opt}, we have by induction that the constraint will be satisfied for any stage $m$.

Solving problem \ref{eq:stage-opt} preserves as much of the fit to the data as is possible while ensuring that the model at stage $m$ will continue to satisfy the synthetic treatment effect. This a constrained plane search that is the analogue of the unconstrained line search that takes place in standard boosting algorithms \cite{Hastie:2009fg}. The regularization terms $\lambda c_0^2$ and  $\lambda c_1^2$ take the place of the scaling parameter in standard boosting algorithms, which limits the contribution that each successive basis function has on the final fit. We discuss later why we use regularization in the optimization instead of scaling after optimization. % FOOTNOTE ABOUT WHY THIS IS? ACTUALLY, SHOULD I START WITH HIGH LAMBDA AND SCALE BACK AS FITTING PROGRESSES? IN THE FIRST FEW ITERATIONS, THE RELATIVE DECREASE OF THE LOSS WILL BE BIG RELATIVE TO \LAMBDA, SO THOSE TREES WILL HAVE A BIGGER RELATIVE EFFECT... NOT SURE IF BAD. MAYBE USE A MULTIPLE OF THE VALUE OF THE PREVIOUS RESIDUAL AS A REGULARIZATION PARAMETER? WHEN LOSS IS BIGGEST (BEGINNING), REGULARIZATION WILL BE V. STRONG, THEN DECREASING AS FIT GETS BETTER

Since we use trees as the basis functions in our implementation, we follow the example of standard tree boosting algorithms and directly optimize the fitted values in the leaf nodes instead of using the same multiplier across the entire tree \cite{Hastie:2009fg}. In other words, the tree-fitting step only determines the structure of each tree, not the predicted values in the leaves. Regardless, under squared-error loss, problem \ref{eq:stage-opt} is a quadratic problem with a linear constraint. The number of optimization variables is always small: either two in the case described here or two times the number of nodes allowed per tree (usually between $2^2$ to $2^5$ ) if optimizing the values in each leaf. These problems are solved very efficiently by off-the-shelf software.

The algorithm alternates between fitting a pair of basis functions and solving a small quadratic optimization problem until a user-set maximum number of stages have been fit. We use cross-validation for model selection among the parameters $m$, $\lambda$, and the tree depth. There is an important nuance when cross-validating in a constrained model space: when performing the optimizations in each stage (problem \ref{eq:stage-opt}), the constraint is evaluated over the whole dataset, even though the loss is only evaluated over the training data. The constraint does not give any information about the real outcomes in the held-out data, so using the held-out data in the constraint is still honest.

\subsection{Benchmarking causal inference methods on synthetic data}
\label{sec:run-meth}

We now have all the machinery that is necessary to create generative distributions that resemble the true unknown distribution. We now sample from these distributions and use that synthetic data, along with the known synthetic treatment effects, as benchmarks on which to evaluate our causal inference algorithms.

We take $K$ bootstrap samples from each of our $Q$ synthetic generative distributions, yielding $Q \times K$ synthetic datasets. We write each of these datasets as $d_{q,k}$ In this notation, $q$ indexes the synthetic treatment effect $\tilde\tau_q$ and its corresponding model and $k$ indexes the bootstrap sample.

We run each of our causal inference methods $t \in \mathcal{T}$ on each synthetic dataset $d_{q,k}$. This produces $|\mathcal{T}| \times Q \times K$ estimates of the synthetic treatment effect, which we call $\hat{\tilde\tau}_{t,q,k}$. 

To select a causal inference method, we first calculate the errors that each causal inference method makes in estimating the synthetic effects: $\tilde{e}_{t,q,k} = |\tilde\tau_q - \hat{\tilde\tau}_{t,q,k}|$. We select the causal inference method that has the least error averaged over all synthetic effects and bootstrap samples:

\begin{equation}
t^{\dagger} = \underset{t \in \mathcal{T}}{\text{argmin}} \sum_{q,k}^{Q,K} \tilde{e}_{t,q,k}
\label{eq:best-meth}
\end{equation}

\begin{figure}[h!]
\centering
\includegraphics[width=\textwidth]{synth-val} 
\caption{A visual representation of synth-validation. We begin with observed data and several causal inference methods to evaluate. We use the observed data and causal inference methods to create a set of synthetic effects. For each synthetic effect, we use a constrained fitting algorithm to estimate a conditional mean model. We use a semi-parametric bootstrap with each conditional mean model to create a generative distribution and sample data from it. The sampled data, along with the known synthetic average treatment effects, are used to benchmark the causal inference methods. The method with the lowest average error is selected.}
\label{fig:synth-val}
\end{figure}
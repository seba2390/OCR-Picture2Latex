\section{Pose initialization for Scene Graph Inference}

In the first stage of our scene graph inference algorithm, we obtain initial estimates of the 6DoF object poses via maximum-a-posteriori (MAP) inference in a restricted variant of our model that assumes no edges between objects in the scene graph. 
%The second stage of the algorithm, an MCMC algorithm targeting $p(G, \bm{\theta} | N, \mathbf{c}, \mathbf{Y})$, 
We maintain a set of particles with each particle assigned to a different object, and we have at least one particle assigned to each object. Then, for each particle we apply Metropolis-Hastings (MH) kernels to pose of the object that the particle is assigned to. After applying these MH kernels, we resample the set of particles using their normalized weights. We repeat this process of applying the MH kernels and resampling for a fixed number of iterations (proportional to the number of objects). We construct the MH kernels for each object by using spatial clustering and iterative closest point (ICP) to compute a set of  ``high-quality'' poses for each object type given the observed scene. We first apply DBSCAN to the set of points that are unexplained by the current hypothesized scene. Then we create a set of initial object pose hypotheses with translation selected from the $C$ cluster centers output by DBSCAN and orientation selected from the set of 24 nominal orientations, for a total of $24\cdot C$ poses. (The 24 orientations are the rotational symmetries of a cube.). Next, we refine these initial pose estimates using ICP. The ICP does not use the full object model, but rather renders the object at the hypothesized pose and computes the corresponding point cloud. We score the resulting pose estimates under the generative model and use the normalized weights to construct a mixture proposal that serves as the MH kernel.

In addition to the above MH kernel, we also experimented with kernels based on
Boltzmann proposals where the Hamiltonian is determined by performing a 3D
convolution of a mask with the observed point cloud. Such
proposals can potentially be used as ``compiled detectors" of the object models
$\mathbf{O}_{1:M}$, enabling us to perform online object learning and scene
parsing. This class of proposals takes the following general form:
\begin{enumerate}
\item Discretize the observation into a 3D grid $\Gamma$.
\item Given the object model $\mathbf{O}$, create $k$ convolutional masks to be
convolved with the grid. Each mask is meant to detect $\mathbf{O}$ at a certain
orientation. The candidate orientations are obtained from an appropriately fine
geodesic grid on a sphere.
\item Slide each mask over $\Gamma$ and calculate the convolution of the mask
and $\Gamma$. 
\item Fix $\beta > 0$, and propose a pose from a Boltzmann distribution
with temperature $\beta$, where the Hamiltonian of each pose is given by the
convolution of its associated mask with $\Gamma$.
\end{enumerate}
We tried multiple approaches for deriving convolutional masks from objects
models. Maximally informative and maximally correlated masks require us to
solve ill-posed optimization problems. Small windows sampled from the object
model are not informative. These masks can give good proposals when combined
with expensive ensembling and outlier detection, but they are unsuitable for
online settings. Our best results come from globally-sparse, locally-dense
\cite{schnabel2007efficient}, randomly selected masks. These masks are
computationally efficient to apply and give results that are qualitatively
comparable to the ICP-based kernel, but the sampling distribution of the masks
have high-variance. In future work, we plan to further investigate this class
of proposals.

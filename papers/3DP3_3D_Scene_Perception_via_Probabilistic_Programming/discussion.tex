
\section{Discussion}
\vspace{-2mm}This paper presented 3DP3, a framework for generative modeling, learning, and inference with structured scenes and image data;
and showed that it improves the accuracy of 6DoF object pose estimation in cluttered scenes.
We used probabilistic programs to conceive of our generative model and represent it concisely; and
we used a probabilistic programming system~\citep{cusumano2019gen} with programmable inference~\citep{mansinghka2018probabilistic} to manage the complexity of our inference and learning algorithm implementations.
The current work has several limitations:
Our algorithm runs $\approx20$x slower than the DenseFusion baseline.
Our shape-learning algorithm requires that the training scenes contain only the single novel object,
whose identity is known across training frames.
Adding the ability to segment and learn models of novel objects in cluttered scenes
and automatically train object detectors and pose estimators for these objects from short RGB-D video sequences,
is an ongoing direction of work.
The model also does not yet incorporate some important prior knowledge about scenes---interpenetration of objects is permitted,
and constraints on physical stability are not incorporated.
More experiments are also needed to understand the implications of a Bayesian treatment of 3D scene perception.

\section{Related Work}
\label{relatedwork}

Previously, mutual information has been used as a privacy metric in a number of settings,~\cite{salamatian2013hide, csiszar1996almost, calmon2015fundamental, sankar2013utility, sankarISIT,sankar, yamamoto1983source, hyposankar}. However, the framework and problem formulation for our setting (Internet of Things (IoT) privacy) is quite different from those encountered in previous work. More specifically, the IoT privacy problem we consider here is based on a large set of time-series data that belong to different users with different statistical patterns that has gone through a privacy-preserving mechanism, and the adversary is aiming at de-anonymizing and de-obfuscating the data.


Next, consider related works in smart-home/public environment Internet of Things (IoT) systems. The authors in \cite{8ukil2015privacy} investigate privacy for IoT smart energy metering where the concern results from the fact that any privacy breach can reveal in-house activity. A `Dynamic Privacy Analyzer' scheme is proposed as an attempt towards achieving a unique privacy metric that is derived from fundamental principles like robust statistics and information theory.
To deal with concerns in different smart-home IoT devices such as lights, smoke-alarms, power switches, baby monitors, and weighing scales, which again makes it possible for the entities to snoop and intrude into the family's activities, the authors in \cite{12sivaraman2015network} suggest that device-level protections be augmented with network-level security solutions. This can be achieved through software defined networking technology when used to dynamically block/quarantine suspicious devices. In \cite{10harris2016security}, the authors consider the privacy issues in public environments such as an IoT-enabled retail store. An IoT-enable retail store has the potential to provide rich, targeted information and services to users within the environment. However, to fully realize such potential, users must be willing to share certain data regarding their habits and preferences with the public IoT facility. To encourage users to share such information, the paper proposes a protocol to ensure the customers that their data will not be leaked to third parties.

As far as other applications of IoT is concerned, authors in \cite{9dalipi2016security} investigate privacy considerations for IoT applications on Smart Grids. In particular, the authors address three types of challenge domains: customer domain, information and communication domain, and the grid domain. In \cite{battery15}, the author tried to provide privacy for smart-metering systems with rechargeable batteries by obscuring the user's power demand.
In \cite{11al2015security}, the authors consider the privacy issue of wearable devices. These devices make it possible for health care services start a new phase in serving patients' needs and monitor their health remotely. Finally, authors in \cite{14sadeghi2015security}, overview the privacy challenges in  industrial IoT systems.

Among these applications, location privacy constitutes one of the most important aspects of IoT privacy. Location privacy preserving mechanisms (LPPMs) can be categorized into two main classes:
identity perturbation LPPMs (anonymization) ~\cite{1corser2016evaluating,hoh2005protecting,freudiger2007mix, ma2009location, shokri2011quantifying, Naini2016}
and location perturbation LPPMs (obfuscation)~\cite{shokri2012protecting, gruteser2003anonymous,  bordenabe2014optimal}.

There are various approaches suggested for identity perturbation LPPMs. Particularly,  k-anonymity approaches help to keep each user's identity indistinguishable within a group of $k-1$ other users ~\cite{1corser2016evaluating,2zhang2016designing,11dewri2014exploiting, gedik2005location, zhong2009distributed, mokbel2006new, sweeney2002k, bordenabe2014optimal, kalnis2007preventing,liu2013game}. Another proposal changes users' pseudonyms within areas called mix-zones~\cite{hoh2005protecting, beresford2003location, freudiger2009optimal, beresford2003location, palanisamy2011mobimix}. There are also various approaches used by location perturbation LPPMs.  For instance, cloaking replaces each user's location information with a larger region~\cite{18shokri2014hiding,8zurbaran2015near,hoh2007preserving, gruteser2003anonymous, gedik2005location, gedik2008protecting, bordenabe2014optimal, duckham2005formal, duckham2006spatiotemporal, xue2009location, wernke2014classification, cai2015cloaking, chow2011spatial, cheng2006preserving, mokbel2006new, kalnis2006preserving, khoshgozaran2011location, bamba2008supporting, um2010advanced, zhangwei2010distributed}, while an alternative direction is to use dummy locations in the set of possible locations of users~\cite{kido2005protection, krumm2009survey, shankar2009privately, chow2009faking, kido2005anonymous, lu2008pad}.
Some prior works combine techniques to achieve stronger location privacy. For instance, Freudiger et al.\ combine techniques from cryptography with mix-zones to improve location privacy~\cite{freudiger2007mix}.




Differential privacy, which aims at protecting queries on aggregated data, has also been applied to the problem of location privacy.
Particularly, several identity perturbation~\cite{lee2012differential, bordenabe2014optimal, chatzikokolakis2015geo, nguyen2013differential, machanavajjhala2008privacy} and location perturbation ~\cite{chatzikokolakis2013broadening,shokri2014optimal, chatzikokolakis2015location,andres2013geo,bordenabe2014optimal} LPPMs are based on differential privacy techniques.
Dewri~\cite{dewri2013local} combines k-anonymity and differential privacy to achieve higher location privacy. Alternatively, Andres et al.\ hide the exact location of a user in a region by adding Laplacian distributed noise  to achieve a desired level of geo-indistinguishability~\cite{andres2013geo}. In ~\cite{info2012}, it  is proved that differential privacy arises out of maximizing entropy principle which is equal to minimizing information leakage and is measured using the mutual information notion. ~\cite{yeb17} tries to reduce the expected estonimation loss by using differential privacy and constraining the privacy level.




Several studies aim at quantifying location privacy protection.  Shokri et al.~\cite{shokri2011quantifying, shokri2011quantifying2} define the expected estimation error of the adversary  as a metric to evaluate LPPM mechanisms.  Ma et al.~\cite{ma2009location}  use  uncertainty about users' location information to quantify user location privacy in vehicular networks.
To defeat localization attacks and achieve privacy at the same time, Shokri et al.~\cite{shokri2012protecting} proposed a method which finds optimal LPPM for an LBS given service quality constraints. Shokri et al.~\cite{shokri2012protecting} design LPPM mechanisms that will defeat localization attacks.
% To defeat localization attack and reach privacy at the same time, \cite{shokri2012protecting} proposed a method which finds optimal LPPM for LSB given service quality constraints.
In \cite{6li2016privacy} and \cite{4olteanu2016quantifying}, privacy leakage of location sharing and interdependent location privacy risks are quantified, respectively. A similar idea is proposed in \cite{14zhang2014privacy} where the quantification model is based on the Bayes conditional risk. Yu et al. \cite{diff2017} combine two complementary notations, geo-indstingushability and expected inference error, to achieve location privacy. The geo-indstingushability is derived from differential privacy but cannot adequately protect users' location against inference attacks of adversary by using prior information, and the expected inference error as privacy metric doesn't consider posterior information obtained from  pseudo-location. As a result, combining both notations gives users the opportunity to have location privacy. In addition, users are allowed to personalized error bound for different locations.

In \cite{5ullah2016novel}, the authors propose a novel model for preserving location privacy in IoT in which they propose the so-called Enhanced Semantic Obfuscation Technique (ESOT).
In \cite{7zhou2012preserving}, in the context of IoT based wireless sensor networks, the authors propose a flexible routing strategy, called Multi-routing Random Walk, which protects the sensor's location. Another approach has been proposed in \cite{6sathishkumar2016enhanced}.

The discussed studies demonstrate the growing importance of privacy. What is missing from the current literature is a solid theoretical framework for privacy that is general enough to encompass various privacy preserving methods in the literature. Such a framework will allow us to achieve provable privacy guarantees, obtain fundamental trade-offs between privacy and performance, and provide analytical tools to optimally achieve provable privacy.   The closest works to this paper are ~\cite{montazeri2016defining, Mont1610Achieving,tifs2016,sit2017,ciss2017}. As mentioned, these works only consider anonymization and only achiveability. In this paper, by considering obfuscation and anonymization, we characterize the limits of privacy in the entire $m(n)-a_n$ plane by considering both achievability and converse results.



























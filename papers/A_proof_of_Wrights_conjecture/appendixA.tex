%!TEX root = hopfwright.tex

%%%%%%%%%%%%%%%%%%
%%% Appendix A %%%
%%%%%%%%%%%%%%%%%%

\section{Appendix: Operator Norms}
\label{sec:OperatorNorms}
%%
%%\note[JB]{I think we should get rid of this proposition. It is not used anywhere (although there is a vague reference to it in the main text).}
%%
%%\begin{proposition} 
%%	\label{prop:ApproximateSolutionWorks}
%%Define $\bar{x}_{\epsilon}$ as in Definition \ref{def:xepsilon} and let $ x \in \ell^1_0$. 
%%If $ \| x - \bar{x}_\epsilon \| = \cO(\epsilon^2)$ then $F_\epsilon(x) = \cO(\epsilon^2)$. 
%%%%%
%%%%%	 \begin{eqnarray}
%%%%%	 \tilde{\alpha}( \epsilon) &:=& \pi /2 + \tfrac{\epsilon^2}{5} ( \tfrac{3\pi}{2} -1) \nonumber \\
%%%%%	 \tilde{\omega}( \epsilon) &:=& \pi /2 -  \tfrac{\epsilon^2}{5}  \nonumber \\
%%%%%	 \tilde{c}(\epsilon) 	  &:=& \{ \left(\tfrac{2 - i}{5}\right)  \epsilon^2 , 0,0, \dots \} \nonumber
%%%%%	 \end{eqnarray}
%%%%%Then $ \tilde{F}( \tilde{\alpha} (\epsilon) , \tilde{\omega}(\epsilon) , \tilde{c}(\epsilon) ) = \cO(\epsilon^3)$. 
%%\end{proposition}
%%
%%
%%\begin{proof}
%%	It suffices to prove the theorem centering our calculation around $ \{ \pp, \pp, \bar{c}_\epsilon \}$.  
%%	Since $ [ \bar{c}_\epsilon]_{k\geq 3 } =0$ and $ \|\bar{c}_\epsilon \| = \cO(\epsilon)$, then we may expand the function $F$ out  to order $ \cO(\epsilon^2)$ as follows: 
%%	\begin{eqnarray}
%%	\, [F(\alpha,\omega, c)]_1 &=& 
%%			i \omega + \alpha e^{-i \omega} + 
%%	\cO(\epsilon^2)  \\ 
%%	\, [F(\alpha,\omega, c)]_2 &=& 
%%			(  2 i \omega  + \alpha e^{ - 2 i \omega} ) c_2 + 
%%	\epsilon \alpha e^{-i \omega}  +
%%	\cO(\epsilon^2) \\ 
%%	\, [ F(\alpha,\omega, c) ]_{k \geq 3} &=&  
%%			\cO(\epsilon^2)
%%	\end{eqnarray}
%%	When  $ \{\alpha , \omega, c \} = \{ \pp, \pp , \bar{c}_{\epsilon} \}$ then both $0 = 	i \omega + \alpha e^{-i \omega} $ and $ 0 = (  2 i \omega  + \alpha e^{ - 2 i \omega} ) c_2 + 
%%	\epsilon \alpha e^{-i \omega}  $. 
%%	Hence, for any $ \| x - \{\pp,\pp, \bar{c}_{\epsilon}\} \| = \cO(\epsilon^2)$ it follows that $ F(x) = \cO(\epsilon^2)$. 
%%	
%%	
%%\end{proof}

%%%%	THIS IS THE OLD PROOF OF PROPOSITION A.1
%%%%
%%%%\begin{proof}
%%%%	Since $ c_{k\geq 3 } =0$ and $ \|c\| = \cO(\epsilon)$, then we may expand the function $F$ out  to order $ \cO(\epsilon^2)$ as follows: 
%%%%	\begin{eqnarray}
%%%%	\, [F(\alpha,\omega, c)]_1 &=& 
%%%%	i \omega + \alpha e^{-i \omega} + 
%%%%	\cO(\epsilon^2)  \\ 
%%%%	\, [F(\alpha,\omega, c)]_2 &=& 
%%%%	(  2 i \omega  + \alpha e^{ - 2 i \omega} ) c_2 + 
%%%%	\epsilon \alpha e^{-i \omega}  +
%%%%	\cO(\epsilon^2) \\ 
%%%%	\, [ F(\alpha,\omega, c) ]_{k \geq 3} &=&  
%%%%	\cO(\epsilon^2)
%%%%	\end{eqnarray}
%%%%	
%%%%	
%%%%	
%%%%	Hence, if we want to solve $ \tilde{F}(\alpha,\omega, c) = 0 + \cO( \epsilon^3)$, then $c_{k \geq 3} =0$. 
%%%%	To solve for $ \alpha, \omega,$ and $ c_2$, we rescale the first equation by $\epsilon$ and then attempt to solve the following system of equations.
%%%%	\begin{eqnarray}
%%%%	0 &=& 
%%%%	i \omega + \alpha e^{-i \omega} + 
%%%%	\alpha \left(e^{i \omega } + e^{-2 i \omega} \right)  c_2 \\
%%%%	0 &=& 
%%%%	( 2 i \omega  + \alpha e^{ - 2 i \omega} ) c_2 + 
%%%%	\epsilon^2 \alpha e^{-i \omega}  
%%%%	\end{eqnarray}
%%%%	Since we are solving for two real variables ($\alpha$ and $ \omega$) and one complex variable ($c_2$), if the equations are non-degenerate then there should be a unique solution. 
%%%%	We solve this equation by making the change of variables $ \alpha = \pp ( 1 + \alpha_1)$ and $ \omega = \pp ( 1 + \omega_1)$.
%%%%	Dividing through by $\pp$ in both equations and then linearizing in terms of $ \alpha_1, \omega_1 $ and $ c_2$ results in the following system of equations:
%%%%	\begin{eqnarray}
%%%%	0 &=&  -i \alpha_1 +(i - \pp) \omega_1  + (-1 + i) c_2 \\
%%%%	i \epsilon^2  &=&   - i \epsilon^2 \alpha_1 - \pp \epsilon ^2 \omega_1 + ( -1 + 2 i) c_2  
%%%%	\end{eqnarray}
%%%%	Separating this into real and imaginary parts, we obtain a system of four real equations and four real variables. 
%%%%	Solving this matrix equation then results in the desired  approximations. 
%%%%	
%%%%	
%%%%\end{proof}



% THIS PARAGRAPH CAN BE REMOVED TO REDUCE THE LENGTH
%  We evaluate the derivative in $ \tilde{x}_\epsilon = (\pi/2,\pi/2,c_2(\epsilon),0,0,\dots) $. The corrections of order $\epsilon^2$ in the $\alpha$- and $\omega$-component that are incorporated in $x_\epsilon$, see Definition~\ref{def:xepsilon}, are not needed here because we only need ????   then $ DF(x_\epsilon) + \cO(\epsilon^2)$ can be calculated to be:
%  	\begin{eqnarray}
%  	\frac{\partial F}{\partial  \alpha} \left(\tilde{x}_\epsilon \right)
%  	&=&
%  	[- i]_1 + [ -\left(\tfrac{2 - i}{5}\right) \epsilon]_2 + [-i \epsilon]_2 +  cO(\epsilon^2) \\
%  	%
%  	\frac{\partial F}{\partial  \omega}  (\tilde{x}_\epsilon)
%  	&=&
%  	[i - \tfrac{\pi}{2}]_1 +
%  	\epsilon [ (2 + \pi) ( \tfrac{1+ 2 i}{5})- \pp ]_2 + \cO(\epsilon^2) \\
%  	%
%  	\frac{\partial F}{\partial  c}  (\tilde{x}_\epsilon)
%  	&=&
%  	\tfrac{\pi}{2} ( i K^{-1} + U_{\omega_0} + \epsilon L_{\omega_0}) + cO(\epsilon^2)
%  	\end{eqnarray}
%  	Here, $\omega_0 = \omega(0) = \pi/2$.
%  	These equations are used to define $ A = A_0 + \epsilon A_1$, whence $A = F( x_\epsilon) + \cO(\epsilon^2)$.
%  	 By our choice of $\epsilon$ we know that  $ \epsilon\|  A_1 A_0^{-1}\| < $, so we can write the power series expansion of $A^{-1} = A_0^{-1} ( I + epsilon A_1 A_0^{-1})$ as follows
%  	 \[
%  	  A^{-1} = A_0^{-1} \sum_{k=0}^{\infty} \left( - \epsilon A_1 A_0^{-1} \right)^k
%  	 \]
%  	 If we truncate this power series and define $ A^{\dagger } := A_0^{-1} - \epsilon A_{0}^{-1} A_1 A_0^{-1}$, then it follows that $ A^{\dagger} = A^{-1} + \cO(\epsilon^2)$.
%  	 Thus, we have proven that $ A^{\dagger} = [DF(x_\epsilon)]^{-1} + \cO(\epsilon^2)$.
%
% \end{proof}

%
% \begin{proposition}
% 	Fix $ \epsilon \geq 0$ and suppose that  $ | \alpha - \pp| < r_\alpha$ and $| \omega - \pp| < r_\omega$ and  $\frac{1+4 \epsilon}{2} <\frac{\omega }{\alpha }$ and  define
% 	\[
% 	b_* = 2  \frac{\pp - r_{\omega}}{\pp + r_\alpha} -1 - \epsilon  (4/3+\sqrt{2 + 2 r_\omega } )
% 	\]
% 	and
% 	\[
% 	z^{\pm}_* =\frac{b_* \pm \sqrt{(b_*)^2- 4 \epsilon^2 }}{2 } .
% 	\]
% 	If there exists for some $ c \in \ell^1 / \C$ such that $\tilde{F}(\alpha, \omega,c) = 0$, then either $ |c| \leq  z_*^-$ or $ z_*^+ \leq |c| $.
%
% 	\noindent
% 	Additionally, $ \| K^{-1} c \| < 2 (\epsilon^2+ \|c\|^2)/ b_*$.
% 	\label{prop:Cone}
% \end{proposition}
%
%
% \begin{proof}
%
% 	Let us define the linear operator $B: \ell^1 / \C \to \ell^1 / \C$ by
% 	\[
% 	B = i \omega K^{-1} + \alpha U_{\omega} + \alpha \epsilon L_{\omega}.
% 	\]
% 	If  $ \tilde{F}( \alpha, \omega, c) =0$ then it follows that for the equations $\tilde{F}_{k\geq 2}$ we have
% 	\begin{eqnarray}
% 	0 &=& \tilde{F}(\alpha , \omega, c) \\
% 	0 &=& [ \epsilon^2 \alpha e^{- i \omega}]_2 + Bc  + \alpha [ U_{\omega} c ] * c \\
% 	- B c &=& [ \epsilon^2 \alpha e^{- i \omega}]_2 + \alpha [ U_{\omega} c ] * c \\
% 	c &=& - \alpha B^{-1} ( [ \epsilon^2  e^{- i \omega}]_2 + \ [ U_{\omega} c ] * c )
% 	\end{eqnarray}
% 	Taking norms, we obtain the following:
% 	\begin{eqnarray}
% 	|c | & \leq & \alpha \| B^{-1}\| \left( \epsilon^2  + \| [U_\omega c] * c \| \right)  \\
% 	(\alpha \| B^{-1}\|)^{-1} |c | & \leq &  ( \epsilon^2 + |c |^2) \\
% 	0 & \leq & |c|^2 - (\alpha \| B^{-1}\|)^{-1} |c| +  \epsilon^2
% 	\end{eqnarray}
% 	Let us define $ b = ( \alpha \| B^{-1} \|)^{-1}$
% 	The above quadratic has two zeros $z^+$ and $ z^-$ given by
% 	\[
% 	z^{\pm} =\frac{b \pm \sqrt{b^2- 4 \epsilon^2 }}{2 }
% 	\]
% 	These zeros have the property that either $ |c| \leq z^-$ or $ |c| \geq z^+$
% 	We calculate $ \| B^{-1}\|$.
% 	Since $ \frac{1+4 \epsilon}{2} <\frac{\omega }{\alpha }$ then $\| \frac{\alpha}{i \omega} (U_{\omega} + \epsilon L_{\omega})K\| <1$ and we can expand $B^{-1}$ using a geometric series.
% 	First we evaluate $B^{-1}$.
% 	\begin{eqnarray}
% 	B 	&=& i \omega K^{-1} + \alpha U_{\omega} + \alpha \epsilon L_{\omega} \\
% 	&=& i \omega \left[I + \frac{\alpha}{i \omega} (U_{\omega} + \epsilon L_{\omega}) K \right] K^{-1} \\
% 	B^{-1} &=& \frac{1}{i \omega } K \left[I + \frac{\alpha}{i \omega} (U_{\omega} + \epsilon L_{\omega})K \right]^{-1} \\
% 	&=& \frac{1}{i \omega } K  \sum_{n=0}^\infty \left( \frac{ - \alpha}{i \omega} \right)^n [(U_{\omega} + \epsilon L_{\omega})K]^n
% 		\end{eqnarray}
% 		We now calculate $\| B^{-1} \|$.
% 		\begin{eqnarray}
% 	\| B^{-1} \| &\leq &  \frac{\| K\|}{ \omega }   \sum_{n=0}^\infty \left( \frac{ \alpha}{ \omega} \right)^n \|(U_{\omega} + \epsilon L_{\omega}) K\|^n \\
% 	&=& \frac{\| K \|}{\omega  - \alpha \|(U_{\omega} + \epsilon L_{\omega}) K\|} \\
% 	&\leq & \frac{\| K \|}{\omega  - \alpha ( \| K \| + 2 \epsilon \| \sigma^+ K \| + 2 \epsilon \|\sigma^- K\|)} \\
% 	&\leq & \frac{1/2}{\omega  - \alpha (1/2+ 2\epsilon( 1/2 + 1/3) )} \\
% 	&=& \frac{1}{2 \omega  - \alpha (1 + \tfrac{10}{3}\epsilon)}.
% 	\end{eqnarray}
% 	Thereby, we have obtained the inequality $b \geq 2 \tfrac{\omega}{\alpha} - 1 - \tfrac{10}{3} \epsilon $.
%
% 	We can further improve this constant with the following observation.
% 	The norm of $ ( e^{-i \omega } I + U_{\omega}) K$ is concentrated in the first equation.
% 	One calculates that $ | [e^{-i \omega } I + U_{\omega} ]_2 |=  | e^{- i \omega} + e^{-2 i \omega}| = \sqrt{2 - 2 \sin (\omega-\pp) } $. So then $ \|\sigma^+ ( e^{-i \omega } I + U_{\omega}) K\| \leq  \sqrt{2 (1+ r_\omega) } /2$.
% 	Consequently $	\| B^{-1} \| \leq  [ 2 \omega - \alpha ( 1 + \epsilon (4/3+\sqrt{2 + 2 r_\omega } ))]^{-1}$.
% 	We can define a lower approximation to $b$ as follows:
% 	\[
% 	b_* = 2  \frac{\pp - r_{\omega}}{\pp + r_\alpha} -1 - \epsilon  (4/3+\sqrt{2 + 2 r_\omega } )
% 	\]
% 	If we calculate the derivative of $ z^{\pm}$ with respect to $b$, we find that $\frac{\partial }{\partial b} z^+>0 $ and $ \frac{\partial }{\partial b} z^-<0 $.
% 	To minimize $ z^+$ and maximize $z^-$ let us then define approximations to $ z^{\pm}$ as
% 	\[
% 	z^{\pm}_* =\frac{b_* \pm \sqrt{(b_*)^2- 4 \epsilon^2 }}{2 } .
% 	\]
% 	It then follows that either $ |c| \leq  z_*^-$ or $ z_*^+ \leq |c| $.
%
% 	Furthermore, since $\| K^{-1} c \| \leq  \alpha \| K^{-1} B^{-1} \| \, ( \epsilon^2 + \|c \|^2)$ and $ \| K^{-1} B^{-1} \| \leq ( \omega - \alpha \| ( U_\omega + \epsilon L_\omega ) K \|)^{-1}$, then it follows from our calculation of $ b_*$ that $ \| K^{-1} c \| < 2 (\epsilon^2+ \|c\|^2)/b_*$.
% \end{proof}



% Below, we make some definitions and prove some small propositions to assist with future calculations.
We set $\omega_0 = \pp$ and recall that 
\begin{alignat*}{1}
	[U_\omega a]_k & =  e^{-i k\omega} a_k \\
	[U_{\omega_0} a]_k & = (-i)^k a_k \\
	L_{\omega}  & =  \sigma^+( e^{-i\omega}  I + U_{\omega}) + \sigma^-( e^{i\omega} I + U_{\omega})  \\
	L_{\omega_0} & = \sigma^+( -i  I + U_{\omega_0}) + \sigma^-( i I + U_{\omega_0})  .
\end{alignat*}
% For future reference we compute $L_{\omega_0}$ where, as in Definition \ref{def:A}, we take $ \omega_0 = \pp$.
% \begin{eqnarray}
% L_{\omega_0} &=& \sigma^+( e^{- i \pp} I + U_{\omega_0}) + \sigma^-(e^{i \pp} I + U_{\omega_0}) \\
% &=& \sigma^+( -i  I + U_{\omega_0}) + \sigma^-( i I + U_{\omega_0})
% \end{eqnarray}
To more efficiently express the inverse of $ A_{0,*}$ we define an operator $\hat{U}: \ell^1_0 \to \ell^1_0 $ by
%
% \begin{definition}
% Define the map  $ \hat{U} : \ell^1_0 \to \ell^1_0 $ by:
\begin{equation}\label{e:defUhat}
[\hat{U} c]_{k\geq 2} := (1 - i k^{-1}e^{-i k \pi /2} )^{-1} c_k,
\end{equation}
so that  
$ A_{0,*}^{-1}=  \frac{2}{ i \pi } \hat{U} K $.
% \end{definition}
%
%
% \begin{proposition}
% The inverse of $ A_{0,*}$ is given by $A_{0,*}^{-1}=  \frac{2}{ i \pi } \hat{U} K $.
% \end{proposition}

% \begin{proof}
% 	The map $A_{0,*}$ is a diagonal operator and its inverse can be calculated as follows:
% 	\begin{eqnarray*}
% 	A_{0,*}^{-1} &=& \frac{2}{ \pi } (i K^{-1} + U_{\omega_0})^{-1} \\
% 	&=& \frac{2}{  \pi } [  (iK^{-1}) (I -i K U_{\omega_0}) ]^{-1} \\
% 	&=& \frac{2}{ i \pi } (I - i U_{\omega_0}K )^{-1} K   \\
% 	&=& \frac{2}{ i \pi } \hat{U} K
% 	\end{eqnarray*}
% \end{proof}
%

The operator norm of  $Q \in B(\ell^1_0,\ell^1)$ can be expressed using the basis elements $\e_k$ (which have norm $\|\e_k\|=2$):
\begin{equation}\label{e:operatornorm}
  \| Q \| = \frac{1}{2} \sup_{k \geq 2} \|Q \e_k\| .
\end{equation}
Some of the operators in $B(\ell^1_0,\ell^1)$ considered in these appendices restrict naturally to $B(\ell^1_0)$, with the same expression for the norm. For operators in $B(\ell^1)$ a similar expression for the norm holds (the supremum being over $k\geq 1$). We will abuse the notation $\|Q\|$ by not indicating explicitly which of these operator norms is considered; this will always be clear from the context.
%\note[JB]{This is not very clean of course, but I am not inclined to go over the paper and put subscripts everywhere to make all these distinctions.}
\begin{proposition}\label{p:severalnorms}
	The operators $\hat{U}, \hat{U} K, L_{\omega}, A_{0,*}^{-1}   $ and $A_{1,*}$ in $B(\ell^1_0,\ell^1)$  satisfy the bounds
\begin{align*}
\| \hat{U} \| 		=& \tfrac{5}{4} 						&\| A_{0,*}^{-1} \| =& \tfrac{2}{ \pi \sqrt{5}}	\\ 
\| \hat{U} K \| 	=& \tfrac{1}{ \sqrt{5}}	&\| A_{1,*} \| \leq& 2 \pi	 \\
\| L_{\omega} \| \leq& 4
\end{align*}
\end{proposition}
\begin{proof}
		The value $\| \hat{U} \e_k \|$ is maximized when $k=5$, whence  $\| \hat{U} \| = 5/4$. 
		The value $\| \hat{U} K \e_k \|$ is maximized when $k=2$, whence $\| \hat{U} K \| 	= \frac{1}{ \sqrt{5}}$ and $\| A_{0,*}^{-1}\| = \frac{2}{\pi \sqrt{5}} $. 
It follows from the definition of $L_\omega$ and the fact that $U_\omega$ is unitary that $ \| L_{\omega} \| \leq 4$, whereby it follows that  
$ \| A_{1,*} \| = \| \pp L_{\omega_0} \|  \leq 2 \pi$.
\end{proof}

We recall, for any $a\in \ell^1$, the splitting $a=a_1 \e_1 + \tilde{a}$ with $a_1 \in \C$ and $\tilde{a} \in \ell^1_0 $,  and as a tool in the estimates below we  introduce the projections 
\begin{alignat}{1}
	\pi_1 a &= a_1  \in \C \\
	\pi_{\geq 2} a & = \tilde{a}. \label{e:pige2}
\end{alignat}

\begin{proposition}
	\label{prop:A1A0}
	We have for the map $ A_1 A_0^{-1} : \ell^1 \to \ell^1$ that 
%\note[JB]{I don't think we should have a strict inequality here.}
	\begin{equation}
	\label{eq:A1A0}	
	\| A_1 A_0^{-1}\| = \frac{2 \sqrt{10}}{5} \, .
	\end{equation}
%\note[JB]{Perhaps the estimate is now
%$ \| A_1 A_0^{-1}\| = \max\{ \frac{1}{5}\sqrt{\frac{45+5\sqrt{17}}{2}}, \frac{2 \sqrt{10}}{5} \}  = \frac{2 \sqrt{10}}{5}$ ?}
\end{proposition}

\begin{proof}
%%	Expanding $A_1A_{0}^{-1}$  we obtain 
%%\note[JB]{This expansion uses imaginative notation. I propose to remove it.}
%%\begin{eqnarray}
%%A_1 A_0^{-1} &=&  (  A_{1,2} + A_{1,*})(  A_{0,1}^{-1} + A_{0,*}^{-1} ) \\
%%&=&   A_{1,2} A_{0,1}^{-1}  +  A_{1,*}     A_{0,*}^{-1} 
%%\end{eqnarray}
%%\note[JB]{I propose to replace it by the following}
Expanding $A_1A_{0}^{-1}$ we see that it splits into two parts: $A_{1,2} A_{0,1}^{-1}$ and $A_{1,*}     A_{0,*}^{-1}$, which we estimate separately. To be precise
\[
  A_1A_{0}^{-1} a = (i_\C A_{1,2} A_{0,1} i_\C^{-1} \pi_1 a) \e_2 
                    +  A_{1,*} A_{0,*}^{-1} \pi_{\ge 2} a.
\]
First, we calculate the matrix
\[
  A_{1,2} A_{0,1}^{-1}  = 
   \frac{1}{5}
  \left[
  \begin{matrix}
  3 & 2 \\
  -4  & 4 
  \end{matrix} 
  \right] .
\]
Using the identification of $\R^2$ and $\C$, which is an isometry if one uses the $2$-norm on $\R^2$,
this matrix contributes to $A_1 A_0^{-1}$
as an operator mapping the (complex) one-dimensional subspace spanned by~$\e_1$ to the (complex) one-dimensional subspace spanned by~$\e_2$. 
To determine its contribution to the estimate of the norm of $A_1 A_0^{-1}$,
we thus need to determine the $2$-norm of the matrix (as a linear map from $\R^2 \to \R^2$):
\[
  \| A_{1,2} A_{0,1}^{-1} \|  = \frac{1}{5} \sqrt{\frac{45+5\sqrt{17}}{2}}.
\]
%\note[JB]{Explained and improved the bound. Still needs to be reflected in the statement of the Proposition though.}
% We calculate the map $A_{1,2} A_{0,1}^{-1} :\{e_1\}   \to \{ \alpha , \omega \} \to \{e_2\} $
% \begin{eqnarray}
% A_{1,2} A_{0,1}^{-1} 		&=&
% \frac{1}{5}
% \left[
% \begin{matrix}
% -2 & 2-\tfrac{3 \pi}{2} \\
% -4  & 2(2+\pi)
% \end{matrix}
% \right]
% \cdot
% \left[
% \begin{matrix}
% 0 & - \pp \\
% -1  & 1
% \end{matrix}
% \right]^{-1}
% \\
% &=&  \frac{1}{5}
% \left[
% \begin{matrix}
% 3 & 2 \\
% -4  & 4
% \end{matrix}
% \right] \\
% \| A_{1,2} A_{0,1}^{-1} \| &\leq& \frac{8}{5} \label{eq:AppendixCheck}.
% \end{eqnarray}
% \marginpar{JJ: todo - Is the estimate in \ref{eq:AppendixCheck} right/ could it be sharpened?}
Next, we calculate a bound on the map $ A_{1,*}     A_{0,*}^{-1}: \ell^1_0 \to \ell^1$:
\begin{equation}\label{eq:LUK}
  \| A_{1,*}     A_{0,*}^{-1} \| =  \| L_{\omega_0} \hat{U} K \| .
\end{equation}
% \begin{eqnarray}
% A_{1,*}     A_{0,*}^{-1} 	&=&  \frac{\pi}{2} L_{\omega_0} \frac{2}{ i \pi } \hat{U} K  \\
% \| A_{1,*}     A_{0,*}^{-1} \| &= & \| L_{\omega_0} \hat{U} K \|  \label{eq:LUK}
% \end{eqnarray}
To bound \eqref{eq:LUK} we first compute how $L_{\omega_0} K \hat{U}    $ operates on basis elements $\e_k$ for $k\geq 2$: 
\[
L_{\omega_0} K \hat{U}     \e_{k} = \frac{ -i+(-i)^k }{k-i (-i)^{k}}   \e_{k+1}
+
\frac{ i+(-i)^k  }{k-i (-i)^{k}}   \e_{k-1} .
\]
Since the norm of this expression is maximized when $k=2$ and $  \| L_{\omega_0} K \hat{U}    \e_2 \| = \tfrac{4\sqrt{10}}{5}$,
%\note[JB]{Isn't that $\tfrac{4\sqrt{10}}{5}$? (norm below still correct)}
 we have calculated the $B(\ell^1_0,\ell^1)$ operator norm $ \|L_{\omega_0} K \hat{U}      \| = \tfrac{2\sqrt{10}}{5}$. 
%\change[J]{By combining the estimates above and using the triangle inequality, we arrive at the asserted bound.}{ 
As $\|A_1A_{0}^{-1}\|$ is equal to the maximum of  $ \| A_{1,2} A_{0,1}^{-1}\|$ and $\|A_{1,*}     A_{0,*}^{-1}\|$, it follows that 
	$ \| A_1 A_0^{-1}\| = \max\{ \frac{1}{5}\sqrt{\frac{45+5\sqrt{17}}{2}}, \frac{2 \sqrt{10}}{5} \}  = \frac{2 \sqrt{10}}{5}$.
%
% \begin{equation*}
% \| A_1 A_0^{-1}\|  \leq  \|  A_{1,2} A_{0,1}^{-1} 	 \| + \| A_{1,*}     A_{0,*}^{-1} \|  \frac{2}{5} \left(4+\sqrt{10}\right)
% \end{equation}
\end{proof}

\begin{proposition}
		\label{prop:A0A1}
		Define $\overline{A_0^{-1} A_1 } \in \text{\textup{Mat}}((\R^3,\R^3)$ by
	\[
\overline{A_0^{-1} A_1 } :=
\left(
\begin{array}{ccc}
0 & 0 & \tfrac{1}{2}\sqrt{2+\frac{\pi ^2}{2}} \\
0 & 0 & \frac{1}{\sqrt{2}}  \\
\frac{8}{5 \pi } & \frac{2\sqrt{16+8 \pi +5 \pi ^2}}{5 \pi } & \frac{2}{\sqrt{5}} \\
\end{array}
\right)
	\] 
%	\note[J]{Reflected changes in the statement of the proposition.}
	Then $\overline{A_0^{-1} A_1 } $ is an upper bound (as defined in Definition~\ref{def:upperbound}) for $A_0^{-1} A_1 $.
\end{proposition}
\begin{proof}
%%We expand $  A_0^{-1} A_1 $ as follows: 
%%\begin{eqnarray}
%%A_0^{-1} A_1 &=& ( A_{0,1}^{-1} + A_{0,*}^{-1}) ( A_{1,2} + A_{1,*}) \\
%%&=&  A_{0,*}^{-1}  A_{1,2} +  A_{0,1}^{-1} A_{1,*} + A_{0,*}^{-1} A_{1,*}
%%\end{eqnarray}
%%\note[JB]{Although the splitting is morally correct, the notation makes no sense to me. I propose to replace it by what is below.}
We write $x=(\alpha,\omega,c)$.
Let $\pi_{\alpha,\omega}$ be the projection onto $\R^2$, whereas $\pi_c$ is the projection onto $\ell^1_0$. 
Then we can expand $  A_0^{-1} A_1 $ as follows:
\begin{alignat}{1}
  \pi_{\alpha,\omega} A_0^{-1} A_1 x &=   A_{0,1}^{-1}  i_\C^{-1} \pi_{1} A_{1,*} \pi_c x  \label{e:complicated1} \\
  \pi_{c} A_0^{-1} A_1 x  &= 
  A_{0,*}^{-1} (( i_\C A_{1,2} \pi_{\alpha,\omega} x)   \e_2 ) + A_{0,*}^{-1} \pi_{\geq 2} A_{1,*} \pi_c x . \label{e:complicated2}
\end{alignat}
We estimate the three operators that appear separately.

First, we note that the term $A_{0,*}^{-1} (( i_\C A_{1,2} \pi_{\alpha,\omega} x)   \e_2 ) $ in~\eqref{e:complicated2} essentially represents an operator from $\R^2$ to the (complex) one-dimensional subspace spanned by $\e_2$. Using the identification of $\C$ with $\R^2$, this map is represented by the matrix 
\[
  \frac{-2 }{25 \pi }
  \left[
  \begin{matrix}
  1 & -2 \\
  2 & 1
  \end{matrix} 
  \right] 
  \cdot
  \left[
  \begin{matrix}
  -2 & 2-\tfrac{3 \pi}{2} \\
  -4  & 2(2+\pi) 
  \end{matrix} 
  \right] \\
  = \frac{2 }{25 \pi }
  \left[
  \begin{matrix}
  -6 & 6+ 11 \pp \\
  8  & \pi -8
  \end{matrix} 
  \right] .
\]
It then follows that 
%\note[J]{Added factor $2$ and changed $r_\alpha \mapsto |\alpha|$ and $r_\omega \mapsto |\omega|$}
\begin{alignat*}{1}
  \| A_{0,*}^{-1} (( i_\C A_{1,2} \pi_{\alpha,\omega} x)   \e_2 ) \|
&\leq 	\frac{4}{25 \pi} 
	\left(|\alpha| \sqrt{(-6)^2+8^2}   + 
	 |\omega|  \sqrt{( 6+ 11 \pp )^2 + (\pi-8)^2} 
	 \right) \\
	&= \frac{4}{5 \pi} \left( 2 |\alpha| + 
	\frac{\sqrt{16+8 \pi +5 \pi ^2}}{2} |\omega| \right) .
\end{alignat*}

% \begin{eqnarray*}
% A_{0,*}^{-1}  A_{1,2} &=&
% \frac{-2 }{25 \pi }
% \left[
% \begin{matrix}
% 1 & -2 \\
% 2 & 1
% \end{matrix}
% \right]
% \cdot
% \left[
% \begin{matrix}
% -2 & 2-\tfrac{3 \pi}{2} \\
% -4  & 2(2+\pi)
% \end{matrix}
% \right] \\
% &=& \frac{2 }{25 \pi }
% \left[
% \begin{matrix}
% -6 & 6+ 11 \pp \\
% 8  & \pi -8
% \end{matrix}
% \right]
% \end{eqnarray*}
% It then follows that
% \begin{eqnarray*}
% 	A_{0,*}^{-1}  A_{1,2} &\leq&
% 	\frac{2}{25 \pi}
% 	\left(r_\alpha \sqrt{(-6)^2+8^2}   +
% 	 r_\omega  \sqrt{( 6+ 11 \pp )^2 + (\pi-8)^2}
% 	 \right) \\
% 	&=& \frac{2}{5 \pi} \left( 2 r_\alpha +
% 	\frac{\sqrt{16+8 \pi +5 \pi ^2}}{2} r_\omega \right)
% \end{eqnarray*}
%
%
%\[
%A_{0,*}^{-1}  A_{1,2} \leq \frac{2}{5 \pi} \left( 2 r_\alpha + 
%\frac{\sqrt{16+8 \pi +5 \pi ^2}}{2} r_\omega \right) 
%\]
%
%

Next, we note that the term $A_{0,1}^{-1}  i_\C^{-1} \pi_{1} A_{1,*} \pi_c x $
in~\eqref{e:complicated1} essentially represents an operator from the (complex) one-dimensional subspace spanned by $\e_2$ to $\R^2$. Using the identification of $\C$ with $\R^2$, this map is represented by the matrix 
\[
 \pp 
 \left[
 \begin{matrix}
 0 & - \pp \\
 -1  & 1 
 \end{matrix} 
 \right]^{-1}
 \cdot
 \left[
 \begin{matrix}
 -1 & -1 \\
 1 &-1 
 \end{matrix} 
 \right] \\
 =
 \left[
 \begin{matrix}
 1 - \pp & 1 + \pp \\
 1  & 1
 \end{matrix} 
 \right] ,
\]
because $\pi_1 A_{1,*} \e_2 = \pp (i-1)$.
% Noting that $A_{0,1}^{-1}  A_{1,*} :\{ e_2 \} \to \{ \alpha , \omega\} $, we calculate:
% \begin{eqnarray}
% A_{0,1}^{-1}  A_{1,*} &=& A_{0,1}^{-1} [ \pp ( e^{ i \omega_0} +e^{-2 i \omega_0} )] \\
% &=& A_{0,1}^{-1} [ \pp ( i-1 )] \\
% &=& \pp
% \left[
% \begin{matrix}
% 0 & - \pp \\
% -1  & 1
% \end{matrix}
% \right]^{-1}
% \cdot
% \left[
% \begin{matrix}
% -1 & -1 \\
% 1 &-1
% \end{matrix}
% \right] \\
% &=&
% \left[
% \begin{matrix}
% 1 - \pp & 1 + \pp \\
% 1  & 1
% \end{matrix}
% \right]
% \end{eqnarray}
Hence
%\note[J]{Added factor of $\frac{1}{2}$.}
\begin{alignat*}{1}
  | \pi_\alpha  A_0^{-1} A_1 x |  &\leq  \tfrac{1}{2} \sqrt{ 2 + \tfrac{\pi^2}{2}}  \|c\| \\ 
  | \pi_\omega  A_0^{-1} A_1 x |  &\leq  \tfrac{1}{2}  \sqrt{2} \|c\|  . 
\end{alignat*}

% If we convert this into  $ \{ e_2 , \overline{ e_2} \}$ coordinates, then it follows that
% \[
% | \{ \alpha , \omega \} \cdot  A_{0,1}^{-1}  A_{1,*} \cdot c_2 | \leq
% \left\{ \sqrt{ 2 + \tfrac{\pi^2}{2}} , \sqrt{2} \right\}
% \]
%
%
%
 
Finally, note that the term $A_{0,*}^{-1}  \pi_{\geq 2} A_{1,*}$
appearing in~\eqref{e:complicated2} maps $\ell^1_0$ to itself. It can be expressed as
\[
A_{0,*}^{-1}  \pi_{\geq 2} A_{1,*}  = - i K \hat{U} \pi_{\geq 2} L_{\omega_0} .
\]
The operator $K \hat{U} \pi_{\geq 2} L_{\omega_0}$
 acts on basis elements $\{ \e_k\}_{k \geq 2}$ as follows:
\begin{alignat*}{1}
	K \hat{U} \pi_{\geq 2}  L_{\omega_0}  \e_2 &= -\frac{1+i}{4} \e_{3}  \\
	K \hat{U} \pi_{\geq 2}  L_{\omega_0}  \e_{k} &= \frac{-i+(-i)^k}{(k+1)-i (-i)^{k+1}} \e_{k+1} + \frac{i+(-i)^k}{(k-1) - i (-i)^{k-1}} \e_{k-1}
	\qquad\text{for } k \geq 3.
\end{alignat*}
Since $\max_{k\geq 2 } \| K \hat{U} \pi_{\geq 2} L_{\omega_0} \e_k \| = \| K
\hat{U} L_{\omega_0} \e_3 \| = \tfrac{4}{\sqrt{5}}$, 
the operator norm of $A_{0,*}^{-1}  \pi_{\geq 2} A_{1,*}$ is $\tfrac{2}{\sqrt{5}}$.

These three bounds on the three operators appearing in~\eqref{e:complicated1} and~\eqref{e:complicated2} lead to the asserted upper bound.
%
% \begin{eqnarray}
% A_{0,*}^{-1}  A_{1,*}  &=& \left( \frac{2}{i \pi } K \hat{U} \right) \left( \frac{\pi}{2} L_{\omega_0}\right) \\
% &=& - i K \hat{U} L_{\omega_0}
% %&=& - i K \hat{U} \left(  \sigma^+ \left( - i I + U_{\omega_0} \right)  + \sigma^- \left(  i I + U_{\omega_0} \right) \right)
% %
% %\| A_{0,*}^{-1}  A_{1,*} \|  &\leq& \| K \hat{U}   L_{\omega_0} \| \\
% %&\leq& \| K \hat{U} \sigma^+ \left( - i I + U_{\omega_0} \right) \| + \| K \hat{U} \sigma^- \left(  i I + U_{\omega_0} \right) \|\\
% %&\leq & \frac{1}{2 \sqrt{2}}+ \frac{2}{\sqrt{17}} .
% \end{eqnarray}
% Noting that $e_1$ is not in the domain of $\hat{U}$, we compute how $K \hat{U}   L_{\omega_0} $ operates on basis elements $\e_k$.
% \begin{eqnarray}
% 	K \hat{U}   L_{\omega_0}  e_2 &=& -\frac{1+i}{4} e_{3} \\
% 	K \hat{U}   L_{\omega_0}  e_{k\geq 3} &=& \frac{-i+(-i)^k}{(k+1)-i (-i)^{k+1}} e_{k+1} + \frac{i+(-i)^k}{(k-1) - i (-i)^{k-1}} e_{k-1}
% \end{eqnarray}
% Since $\max_{k\geq 2 } \| K \hat{U}   L_{\omega_0}  e_k \|_{\ell^1_0} =  \| K \hat{U}   L_{\omega_0}  e_3 \|_{\ell^1_0} = \tfrac{2}{\sqrt{5}}$, then we have calculated the $\ell^1_0$ operator norm  $ \| K \hat{U}   L_{\omega_0} \| = \tfrac{2}{\sqrt{5}}$.
% Hence, we obtain
% \[
%  A_0^{-1} A_1 \cdot r \leq
% \left(
% \begin{array}{ccc}
% 	0 & 0 & \sqrt{2+\frac{\pi ^2}{2}} \\
% 	0 & 0 & \sqrt{2} \\
% 	\frac{4}{5 \pi } & \frac{\sqrt{16+8 \pi +5 \pi ^2}}{5 \pi } & \frac{2}{
% 		\sqrt{5}}
% \end{array}
% \right) \cdot
% \left(
% \begin{array}{c}
% r_{\alpha } \\
% r_{\omega } \\
% r_c \\
% \end{array}
% \right)
% \]
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


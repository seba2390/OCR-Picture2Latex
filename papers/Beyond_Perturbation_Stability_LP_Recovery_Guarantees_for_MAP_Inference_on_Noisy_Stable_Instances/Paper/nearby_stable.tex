\section{Finding nearby stable instances}\label{sec:algorithm}
In this section, we describe an algorithm for efficiently finding $(2,1,\psi)$-expansion stable instances that are ``close'' to an observed instance $\obsins$. This algorithm allows us to check whether we can plausibly model real-world instances as ``corrupted'' versions of a $(2,1,\psi)$-expansion stable instance.

In addition to an observed instance $\obsins$, the algorithm takes as input a ``target'' labeling $x^t$. For example, $x^t$ could be a MAP solution of the observed instance. Surprisingly, once given a target solution, this algorithm is efficient.

We want to search over costs $c$ and weights $w$. 
The broad goal to solve the following optimization problem:
\begin{align}
\label{eqn:orig-searchprob}
\minimize_{c\ge 0,w\ge 0} \qquad & f(c,w)\\
\text{subject to} \qquad & (G,c,w) \text{ is } (2,1,\psi)\text{-expansion stable}\nonumber\\
\qquad & \text{with MAP solution } x^t\nonumber,
\end{align}
where $f(c,w)$ is any convex function of $c$ and $w$. 
In particular, we will use $f_1(c,w) = ||(c,w)-(\hc,\hw)||_1$
and $f_2(c,w) = \frac{1}{2}||(c,w) - (\hc,\hw)||_2^2$ for minimizing the L1 and L2 distances between to the observed instance.
The output of this optimization problem will give the closest objective vector $(\bc,\bw)$ for which the instance $\stabins$ is $(2,1,\psi)$-expansion stable.
If the optimal objective value of this optimization is 0, the observed instance $\obsins$ is $(2,1,\psi)$-expansion stable.

There is always a feasible $(c,w)$ for \eqref{eqn:orig-searchprob} (see Appendix~\ref{sec:algorithm_details} for a proof), but it may change many weights and costs. Next we derive an efficiently-solvable reformulation of \eqref{eqn:orig-searchprob}.
In the next section, we find that the changes to $\hc$ and $\hw$ required to find a $(2,1,\psi)$-expansion stable instance are relatively sparse in practice.
\begin{theorem}
\label{thm:eff-solvable}
The optimization problem \eqref{eqn:orig-searchprob} can be expressed as a convex minimization problem over a polytope described by $poly(n,m,k)$ constraints. When $f(c,w) = ||(c,w)-(\hc,\hw)||_1$, \eqref{eqn:orig-searchprob} can be expressed as a linear program.
\end{theorem}

 \begin{table*}[ht]
     \centering
     \caption{Results from the output of \eqref{eqn:alg} on three stereo vision instances. More details in Appendix \ref{sec:experiments_details}.}
     \begin{tabular}{lccccc}
          Instance & Costs changed & Weights changed & (normalized) Recovery error bound & $||\hat{x}_V - \hat{x}^{MAP}_V||_1/2n$ \\
          \toprule
          ${\tt tsukuba}$ & 4.9\% & 2.3\% & 0.0518 & 0.0027\\
          ${\tt venus}$ & 22.5\% & 1.3\%  & 0.0214 & 0.0016\\
          ${\tt cones}$ & 1.2\% & 2.1\% & 0.0437 & 0.0022\\
          \bottomrule
     \end{tabular}
     \label{tbl:boundtable}
 \end{table*}
 
The instance $(G,c,w)$ is $(2,1,\psi)$-expansion stable if $x^t$ is better than every expansion $y$ of $x^t$ in every $(2,1,\psi)$-perturbation of $(c,w)$. 
Let $\calE$ be the set of all expansions of the target solution $x^t$.
Then for all $\theta'$ within a $(2,1,\psi)$-perturbation of $\theta=(c,w)$, we should have that $\dot{\theta'}{x^t} \le \min_{y\in \calE}\dot{\theta'}{x^t}$.
It is enough to check the \emph{adversarial} $(2,1,\psi)$-perturbation $\theta_{adv}$. 
This perturbation makes the target solution $x^t$ as bad as possible. 
If $x^t$ is better than all the expansions $y\in \calE$ in this perturbation, it is better than all $y\in \calE$ in every $(2,1,\psi)$-perturbation (see Appendix~\ref{sec:algorithm_details} for a proof).
We set $\theta_{adv} = (c_{adv}, w_{adv})$ as:
\begin{equation*}
    c_{adv}(u,i) = \begin{cases}
    c(u,i) + \psi & i = x^t(u),\\
    c(u,i) & \text{otherwise}.
    \end{cases}
\end{equation*}
\begin{equation*}
    w_{adv}(u,v) = \begin{cases}
    w(u,v) & x^t(u) \ne x^t(u),\\
    \frac{1}{2}w(u,v) & \text{otherwise}.
    \end{cases}
\end{equation*}
The target solution $x^t$ is fixed, so $\dot{\theta_{adv}}{x^t}$ is a linear function of the optimization variables $c$ and $w$.
 For $\alpha \in [k]$, let $\calE^{\alpha}$ be the set of $\alpha$-expansions of $x^t$. Because $\calE = \cup_{\alpha \in [k]} \calE^{\alpha}$, we have $\dot{\theta'}{x^t} \le \min_{y\in \calE}\dot{\theta'}{x^t}$ if and only if $\dot{\theta'}{x^t} \le \min_{y\in \calE^{\alpha}}\dot{\theta'}{x^t}$ for all $\alpha \in [k]$.
We can simplify the original optimization problem to:
\begin{align*}
\minimize_{c\ge 0,w\ge 0} \qquad & f(c,w)\\
\text{subject to} \qquad & \dot{\theta_{adv}}{x^t} \le \min_{y\in \calE^{\alpha}}\dot{\theta_{adv}}{y} \qquad \forall\ \alpha \in [k],
\end{align*}
$\theta_{adv}$ is a linear function of $c,w$ as defined above. 
We now use the structure of the sets $\calE^{\alpha}$ to simplify the constraints. 
The optimal value of $\min_{y\in \calE^{\alpha}}\dot{\theta_{adv}}{y}$ is the objective value of the best (w.r.t. $\theta_{adv}$) $\alpha$-expansion of $x^t$.
The best $\alpha$-expansion of a fixed solution $x^t$ can be found by solving a minimum cut problem in an auxiliary graph $G^{x^t}_{aux}(\alpha)$ whose weights depend on linearly on the objective $\theta_{adv}$, and therefore depend linearly on our optimization variables $(c,w)$ \citep[Section 4]{BoyVekZab01}. 
Therefore, the optimization problem $\min_{y\in \calE^{\alpha}}\dot{\theta_{adv}}{y}$ can be expressed as a minimum cut problem. 
Because this minimum cut problem can be written as a linear program, we can rewrite each constraint as
\begin{equation}
\label{eqn:primalconstraint}
\dot{\theta_{adv}}{x^t} \le \min_{z: A(\alpha)z=b(\alpha), z\ge 0}\dot{\theta_{adv}}{z},
\end{equation}
where $\{A(\alpha)z = b(\alpha),\ z\ge 0\}$ is the feasible region of the standard metric LP corresponding to the minimum cut problem in $G^{x^t}_{aux}(\alpha)$. The number of vertices in $G^{x^t}_{aux}(\alpha)$ and the number of constraints in $A(\alpha) z = b(\alpha)$ is $\text{poly}(m,n,k)$ for all $\alpha$.
We now derive an equivalent linear formulation of \eqref{eqn:primalconstraint} using a careful application of strong duality. The dual to the LP on the RHS is:
\begin{align*}
\maximize_{\nu}~ &~ \dot{b(\alpha)}{\nu}, 
\text{ s.t. } %\qquad & 
A(\alpha)^T\nu \le \theta_{adv}.
\end{align*}
Because strong duality holds for this linear program, we have that \eqref{eqn:primalconstraint} holds if and only if there exists $\nu$ with $A(\alpha)^T\nu \le \theta_{adv}$ such that
$\dot{\theta_{adv}}{x^t} \le \dot{b(\alpha)}{\nu}$.

This is a linear constraint in $(c,w,\nu)$. By using this dual witness trick for each label $\alpha \in [k]$, we obtain:
\begin{alignat}{2}
\label{eqn:alg}
\minimize_{c\ge 0,w\ge 0,\{\nu_{\alpha}\}} \qquad & f(c,w)\\
\text{subject to} \qquad & \dot{\theta_{adv}}{x^t} \le \dot{b(\alpha)}{\nu_{\alpha}} \qquad &&\forall\ \alpha\nonumber\\
\qquad & A(\alpha)^T\nu_{\alpha} \le \theta_{adv} &&\forall\ \alpha\nonumber.
\end{alignat}
The constraints of \eqref{eqn:alg} are linear in the optimization variables $(c,w)$ and $\nu_{\alpha}$.
The dimension of $\theta_{adv}$ is $nk + mk^2$, so there are $k(nk + mk^2 + 1)$ constraints and $nk + m + \sum_{\alpha}|b(\alpha)| = poly(m,n,k)$ variables.
Because minimization of the L1 distance $f_1(c,w)$ can be encoded using a linear function and linear constraints, \eqref{eqn:alg} is a linear program in this case. 
It is clear from the derivation of \eqref{eqn:alg} that it is equivalent to \eqref{eqn:orig-searchprob}. 
This proves Theorem \ref{thm:eff-solvable}.
This formulation \eqref{eqn:alg} can easily be input into ``off-the-shelf'' convex programming packages such as Gurobi \citep{gurobi}.

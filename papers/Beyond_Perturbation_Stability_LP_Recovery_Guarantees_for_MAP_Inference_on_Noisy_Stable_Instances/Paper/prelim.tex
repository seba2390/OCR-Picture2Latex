\section{Preliminaries}
\label{sec:prelim}
In this section we introduce our notation, define the local LP relaxation for MAP inference, and give more details on perturbation stability.
As in the previous section, the MAP inference problem in the ferromagnetic Potts model on the instance $(G,c,w)$ can be written in \emph{energy minimization} form as:
\begin{equation}
\label{eqn:map-problem}
  \minimize_{x: V\to [k]}\sum_{u\in V}c(u, x(u)) + \smashoperator{\sum_{(u,v) \in E}}w(u,v)\indicator[x(u) \ne x(v)].
\end{equation}
Here $x$ is an \emph{assignment} (or labeling) of vertices to labels i.e. $x: V\to \{1,2,\dots,k\}$. We can identify each labeling $x$ with a point $(x_u : u\in V; x_{uv} : (u,v) \in E)$, where each $x_u \in \{0,1\}^k$ and each $x_{uv} \in \{0,1\}^{k\times k}$. 

In this work, we consider all node costs $c(u,i) \in \R$ and all edge weights $w(u,v) > 0$. We note that this is equivalent to the formulation where all node costs and edge weights are non-negative~\cite{KleinbergTardos02}. See Appendix~\ref{sec:prelim_details} for a proof of this equivalence. 

We encode the node costs and the edge weights in a vector $\theta \in \R^{nk + mk^2}$ where $n = \abs{V} \text{ and } m = \abs{E}$ s.t. $\theta(u,i) = c(u,i), \theta(u,v,i,j) = w(u,v)\indicator[i \ne j]$. Then the objective can be written as $\dot{\theta}{x}$. We set $x_u(i) = 1$ when $x(u) = i$, and 0 otherwise. Similarly, we set $x_{uv}(i,j) = 1$ when $x(u) = i$ and $x(v) = j$, and 0 otherwise. Where convenient, we use $x$ to refer to this point rather than the labeling $x: V \to [k]$.
We can then rewrite \eqref{eqn:map-problem} as:
\begin{alignat*}{2}
  \mindot_{x}\sum_{u\in V}&\sum_{i=1}^k c(u,i)x_u(i) + \smashoperator{\sum_{(u,v) \in E}}\ \ &&w(u,v)\sum_{i\ne j}x_{uv}(i,j)\\
  \text{subject to:}& \sum_{i=1}^k x_u(i) = 1 &&\forall\ u\in V\\
                    & \sum_{i=1}^k x_{uv}(i,j) = x_v(j)&& \forall\ (u,v)\in E,\ j\in [k]\\
                   & \sum_{j=1}^k x_{uv}(i,j) = x_u(i)&& \forall\ (u,v)\in E,\ i\in [k]\\
                   & x_{uv}(i,j) \in \{0,1\}&&\forall\ (u,v),\ (i,j)\\
                   & x_{u}(i) \in \{0,1\}&& \forall\ u,\ i.
\end{alignat*}
This is equivalent to \eqref{eqn:map-problem}, and is an integer linear program (ILP). By relaxing the integrality constraints from $\{0,1\}$ to $[0,1]$, we obtain the \emph{local LP relaxation}:
\begin{alignat*}{2}
  \mindot_{x\in L(G)}\sum_{u\in V}\sum_{i=1}^k c(u,i)x_u(i) + \smashoperator{\sum_{(u,v) \in E}}w(u,v)\sum_{i\ne j}x_{uv}(i,j),
\end{alignat*}
where $L(G)$ is the polytope defined by the same constraints as above, with $x \in \{0,1\}$ replaced with $x \in [0,1]$. This is known as the \emph{local polytope} \cite{wainwright2008graphical}. The vertices of $L(G)$ are either \emph{integral}, meaning all $x_u$ and $x_{uv}$ take values in $\{0,1\}$, or \emph{fractional}, when some variables take values in $(0,1)$. 
Integral vertices of this polytope correspond to labelings ${x: V\to [k]}$, so if the LP solution is obtained at an integral vertex, then it is also a MAP assignment.

If the solution $x^*$ of this relaxation on an instance $(G,c,w)$ is obtained at an integral vertex, we say the LP is \emph{tight} on the instance, because the LP has exactly recovered a MAP assignment. If the LP is not tight, there may still be some vertices $u$ where $x^*_u$ takes integral values. In this case, if $x^*_u(i) = 1$ and $\bar{x}(u) = i$, i.e., the LP solution agrees with the MAP assignment $\bar{x}$ at vertex $u$, the LP is said to be \emph{persistent} at $u$. $x^*_u(i) \in \{0,1\}$ does not imply the LP is persistent at $u$, in general. The LP solution $x^*$ is said to be persistent if it agrees with $\bar{x}$ at every vertex $u \in V$. 

\vspace{2pt}
\noindent {\em Recovery error:} In practice, the local LP relaxation is often not tight, but is \emph{nearly persistent}.
We will measure the recovery error of our LP solution in terms of the ``Hamming error'' between the LP solution and the MAP assignment. 

\begin{definition}[Recovery error]\label{def:hammingerror}
Given an instance $(G,c,w)$ of \eqref{eqn:map-problem}, let $\bar{x}$ be a MAP assignment, and let $x^*$ be a solution to the local LP relaxation. The recovery error  is given by (with some abuse of notation)
\begin{align*}
\frac{1}{2}\|x^* - \bar{x}\|_1 &:= \frac{1}{2}\|x^*_V - \bar{x}_V\|_1 \\
&=\frac{1}{2}\sum_{ u \in V} \sum_{i \in [k]} \big| x^*_u(i) - \indicator[\bar{x}(u) = i ] \big|.
\end{align*}
\end{definition}
$x_V \in \R^{nk}$ denotes the portion of $x$ restricted to the vertex set $V$. If $x^*$ is integral, the recovery error measures the number of vertices where $x^*$ disagrees with $\bar{x}$. When the recovery error of $x^*$ is $0$, the solution $x^*$ is {\em persistent}. 
We will say that the LP solution $x^*$ is {\em nearly persistent} when the recovery error of solution $x^*$ is a small fraction of $n$.

In our analysis, we will consider the following subset $L^*(G)$ of $L(G)$ which is easier to work with, and which contains all points we are interested in.

\begin{definition}[$L^*(G)$]
\label{def:L*}
We define $L^*(G) \subseteq L(G)$ to be the set of points $x \in L(G)$ which further satisfy the constraint that $x_{uv}(i,i) = \min(x_u(i), x_v(i))$ for all $(u,v) \in E$ and $i \in [k]$.
\end{definition}

\begin{restatable}[]{claim}{Lstarclaim}\label{claim:Lstar}
For a given graph $G$, every solution $x \in L(G)$ that minimizes $\dot{\theta}{x}$ for some valid objective vector $\theta=(c,w)$ also belongs to $L^*(G)$. Further, all integer solutions in $L(G)$ also belong to $L^*(G)$. 
\end{restatable}
We prove this claim in Appendix~\ref{sec:prelim_details}.

Our new stability result relies on the set of \emph{expansions} of a labeling $x$.
\begin{definition}[Expansion]
\label{def:expansion}
Let $x: V\to [k]$ be a labeling of $V$. For any label $\alpha \in [k]$, we say that $x'$ is an $\alpha$-expansion of $x$ if $x' \ne x$ and the following hold for all $u\in V$:
\begin{align*}
x(u) = \alpha &\implies x'(u) = \alpha,\\
x'(u) \ne \alpha &\implies x'(u) = x(u).
\end{align*}
That is, $x'$ may only expand the set of points labeled $\alpha$, and cannot make other changes to $x$.
\end{definition}

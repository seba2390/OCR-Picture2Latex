\section{Curvature around MAP solution and near persistence of the LP solution}\label{sec:stable-curvature}
In this section, we show that a condition related to $(2,1)$-expansion stability, called $(2,1,\psi)$-expansion stability, implies a ``curvature'' result for the objective function around the MAP solution $\bx$. On instances satisfying this condition, any point $\hx\in L(G)$ with objective close to $\bx$ also has small $\norm{\hx-\bx}_1$, so $\hx$ and $\bx$ are close in solution space. In other words, if the LP solution $\hat{x}$ to a ``corrupted'' $(2,1,\psi)$-expansion stable instance is near-optimal in the original $(2,1,\psi)$-expansion stable instance (whose solution is $\bx$), then the result in this section implies $\norm{\hx-\bx}_1$ is small. This immediately gives a version of the result in the right panel of Figure~\ref{fig:main-idea}: suppose we define an instance to be \emph{close} to a $(2,1,\psi)$-expansion stable $(G,\bar{c},\bar{w})$ if its LP solution $\hat{x}$ is approximately optimal in $(G,\bar{c},\bar{w})$. Then the curvature result implies that the LP approximately recovers the stable instance's MAP solution $\bx$ for all close instances. In Section \ref{sec:random-model}, we give a generative model where the generated instances are ``close'' according to this definition with high probability.


The $(2,1,\psi)$-expansion stability condition, for $\psi > 0$, says that the instance is $(2,1)$-expansion stable even if we allow all node costs $c(u,i)$ to be additively perturbed by up to $\psi$. This extra additive stability will allow us to prove the curvature result.
This is related to the use of additive stability in \citet{LanSonVij19} to give persistency guarantees.
\begin{definition}[$(2,1,\psi)$-expansion stable] For $\psi > 0$, we say an instance $(G,c,w)$ is $(2,1,\psi)$-expansion stable if $(G,c',w)$ is $(2,1)$-expansion stable for all $c'$ with $c \le c' \le c+ \psi \cdot \mathbf{1}$ where $\mathbf{1}$ is the all-ones vector.
\end{definition}

The following theorem shows low recovery error i.e., near persistence of the LP solution on $(2,1,\psi)$ expansion stable instances in terms of the gap in objective value.  
\begin{restatable}{theorem}{curvature}\label{thm:curvature}
Let $(G,c,w)$ be a $(2,1,\psi)$-expansion stable instance with MAP solution $\bar{x}$. 
Let $\theta = (c,w)$. Then for any $x \in L^*(G)$, the recovery error (see Def.~\ref{def:hammingerror}) satisfies
\begin{equation}\label{eq:deviationLP}
    \frac{1}{2}\norm{x - \bx}_1:=\frac{1}{2}\norm{x_V - \bx_V}_1 \le \frac{1}{\psi}\abs{\dot{\theta}{x}-\dot{\theta}{\bx}}.
\end{equation}
\end{restatable}
\begin{proof}[Proof (sketch)]
For any $x \in L^*(G)$, we construct a feasible solution $\hat{x}$ which is a strict convex combination of $x$ and $\bar{x}$ that is very close to $\bar{x}$. Then, we apply a rounding algorithm to $\hx$ to get a random integer solution $h$. Let $\hat\theta$ represent the worst $(2,1)$-perturbation for $\bar{x}$. This is the instance where all the edges not cut by $\bar{x}$ have their weights multiplied by $1/2$. We define the objective difference using $\hat\theta$ as $A_h = \dot{\hat\theta}{h} - \dot{\hat\theta}{\bar{x}}$. First we show an upper bound for $\E[A_h]$ using properties of the rounding algorithm. Then we show that for any solution $h$ in the support of our rounding algorithm, $A_h \geq \psi \cdot B_h$ where $B_h$ is the Hamming error of $h$ (when compared to $\bx$). 
On the other hand, one can also use the properties of the rounding algorithm to get a lower bound on $\E[B_h]$ in terms of the recovery error (i.e., Hamming error) of the LP solution. These bounds together imply the required upper bound on the recovery error of the LP solution. 
\end{proof}
We defer the complete proof and an alternate dual-based proof to Appendix~\ref{sec:stable-curvature_details}. 

Theorem \ref{thm:curvature} shows that on a $(2,1,\psi)$-expansion stable instance, small objective gap $\dot{\theta}{x} - \dot{\theta}{\bx}$ implies small distance $||x_V-\bx_V||_1$ in solution space. Although this holds for any $x \in L^*(G)$, we will be interested in $x$ that are LP solutions to an observed, corrupted version of the stable instance.

We now show that if the observed instance has a nearby stable instance, then the LP solution for the observed instance has small Hamming error. For any two instances $\hat{\theta} = (\hat{c},\hat{w})$ and $\bar{\theta} = (\bar{c}, \bar{w})$ on the same graph $G$, the metric between them $d(\hat{\theta},\bar{\theta}) \coloneqq \sup_{x \in L^*(G)} \abs{ \dot{\hat{\theta}}{x}  - \dot{\bar{\theta}}{x}}$.

\begin{restatable}[LP solution is good if there is a nearby stable instance]{corollary}{deviation}\label{cor:deviation}
Let $\hx^{MAP}$ and $\hx$ be the MAP and local LP solutions to an observed instance $\obsins$. Also, let $\bar{x}$ be the MAP solution for a latent $(2,1,\psi)$-expansion stable instance $\stabins$. If $\hat{\theta} = (\hat{c},\hat{w})$ and $\bar{\theta} = (\bar{c}, \bar{w})$, \[ \frac{1}{2}\norm{\hx_V - \hx^{MAP}_V}_1 \le \frac{2d(\hat{\theta}, \bar{\theta})}{\psi} + \frac{1}{2}\norm{\hx_V^{MAP} - \bx_V}_1. \]
\end{restatable}

We defer the proof of this corollary to Appendix~\ref{sec:stable-curvature_details}.

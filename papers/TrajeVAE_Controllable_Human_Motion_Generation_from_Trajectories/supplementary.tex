\documentclass[main.tex]{subfiles}











\begin{document}
\appendix
\setcounter{page}{1}

\twocolumn[
\centering
\Large
\textbf{\textsc{TrajeVAE}: Controllable Human Motion Generation from Trajectories} \\
\vspace{0.5em}Supplementary Material \\
\vspace{1.0em}
] %
\appendix

\section{Adapting MoGlow}
As mentioned in the main text, MoGlow \cite{henter2020moglow} conditions predicted poses on a \textit{control signal}. This signal represents relative and rotational velocities on the ground plane. Moreover, the authors use the exponential map representation but at the same time claim that MoGlow can be used for any other well-known skeleton representation. We identify the following changes to the original implementation that enabled us to use MoGlow in our framework:
\begin{enumerate}
    \item We change the exponential map representation to the 3D coordinates of $J$ joints.
    \item We replace the control signal represented as velocities into trajectories defined as poses with some of the joints set to 0. This increases the input signal's dimensionality from $3T$ to $3JT$ for $T$ time steps. However, it has a negligible effect on the performance.
    \item We also removed regularization techniques such as gradient norm clipping and gradient value clipping and disabled data normalization. These techniques deteriorate the learning, and the network does not converge in our scenario.
    \item For consistency with other methods, we use the Adam optimizer \cite{kingma2014adam} with the same learning rate regime.
\end{enumerate}
We left the rest of the implementation unchanged. 

\section{Implementation details}
\paragraph{\trajevae{}} MLPs applied in the input and in the CVAE's bottleneck output latent codes of size $256$. Therefore, vectors $\hat{\mathbf{H}}$ and $\bar{\mathbf{H}}$ processed by self-attention layers have a dimensionality $512$. The initial layer in the decoder $\mathcal{D}$ processes $\{[\mathbf{w}_t; \mathbf{w}_0]\}$ and is defined as a function: $f: \mathbb{R}^{768} \rightarrow \mathbb{R}^{512}$. The final layers outputs vectors of size $3J$.

All MLPs responsible for encoding poses and trajectories mentioned in the main text consists of the following structure: \code{Linear} $\rightarrow$ \code{Layer Normalization} $\rightarrow$ \code{Leaky ReLU($\alpha$=0.1)} $\rightarrow$ \code{Linear} $\rightarrow$ \code{Layer Normalization} $\rightarrow$ \code{Leaky ReLU($\alpha$=0.1)}, where $\alpha$ is a scale of the negative slope of the function. The initial MLP in the decoder $\mathcal{D}$  has the structure \code{Linear} $\rightarrow$ \code{Layer Normalization} $\rightarrow$ \code{Leaky ReLU($\alpha$=0.1)} $\rightarrow$ \code{Linear}.

The CVAE baseline operate with the same dimensionalities as \trajevae{}. We implement them in the same way as defined in \cite{yuan2020dlow}. The model uses GRU network to encode the temporal data. The recurrent decoder also receives a coordinate of the trajectory $\mathbf{y}_t$ in the time step $t$. 

We additionally apply dropout $=0.1$ to self-attention layers as described in \cite{vaswani2017attention}.


\section{Same pose, different trajectories}
We perform an additional experiment that confirms the generality of our approach.  We show results for a scenario when we use different trajectories for the same initial pose. As expected, the generated poses follow different trajectories even though such combinations do not occur in the dataset.

\paragraph{Preparing the data}
To maintain plausibility that a particular initial pose is physically capable of following a conditioning trajectory, we pair each initial pose $\mathbf{x}_0$ in the dataset with all trajectories where the distance between $\mathbf{x}_0$ and coordinates of the trajectory in a time step $t= 0$ is below $\epsilon_0 = 0.01$. Since obtaining the ground truth sequence $\mathbf{X}$ in such a case is not possible, we assume that the sequence $\mathbf{X}$ corresponding to a given trajectory is a sufficient approximation of the expected sequence. We evaluate \trajevae{} as previously using APD, ADE, FDE. We omit MMADE and MMFDE for its exponential computational complexity that this scenario creates.

\paragraph{Results} We present results in Tab.~\ref{tab:different-scenario}. Even though these trajectories do not come from the same sequence as the initial poses, \trajevae{} generates a sequence that follows the trajectory. The decrease in accuracy (ADE) between $k = 2$ and $k=3$ is caused by adding a trajectory that corresponds to the right hand, while $k < 2$ we add only trajectories regarding feet. While feet commonly behave similarly throughout the animation, hands have a significantly different motion from other joints.

The value $k=0$ corresponds to no trajectories, and therefore we omit it in the Tab.~\ref{tab:different-scenario}. Refer to supplementary files to find animations generated for initial poses with different trajectories.

\begin{table}[!htbp]
    \centering
    \small
    \begin{tabular}{cccc}
    \toprule
         $k$ & APD &    ADE &    FDE \\
        \midrule
         1 &     5.373 &  0.370 &  0.476 \\
         2 &     5.400 &  0.362 &  0.472 \\
         3 &     5.096 &  0.375 &  0.491 \\
         4 &     4.175 &  0.332 &  0.433 \\
    \bottomrule
    \end{tabular}
    \caption{
    \textbf{Quantitative results} for the Human3.6M dataset when $K=50$ samples are generated for the scenario where we use different trajectories from the whole dataset for the same initial pose. We assume different situations that \mbox{$k=\{1, 2, 3, 4\}$} trajectories are provided.}
    \label{tab:different-scenario}
\end{table}

\section{Extended ablation study}
In experiments, we provide results for an ablation study when only a trajectory for the right foot is provided. We additionally show in Tab.~\ref{tab:additional-ablation} results when we input no trajectories, or progressively add trajectories of the right foot, left foot, right hand, and left hand. The extended results show that our design decisions consistently affect scenarios when we vary the number of the input trajectories.

\begin{table}[htbp!]
    \centering
    \notsotiny
\begin{tabular}{lcccccc}
    \toprule
         \multirow{2}{*}{Method} & \multirow{2}{*}{$k$} & APD  & ADE  & FDE  & MMADE  & MMFDE  \\ 
         & & $\uparrow$ & $\downarrow$ & $\downarrow$& $\downarrow$& $\downarrow$\\
        \midrule
                  Base &  \multirow{5}{*}{0} &           1.237 &           0.525 &           0.749 &           0.634 &           0.801 \\
     + Learnable prior &   &           1.860 &  \textbf{0.502} &  \textbf{0.694} &  \textbf{0.611} &  \textbf{0.740} \\
                 + DCT &   &  \textbf{9.483} &           0.560 &           0.742 &           0.634 &           0.762 \\
 + Masked future poses &   &           8.936 &           0.539 &           0.724 &           0.616 &           0.748 \\
        \midrule
                  Base &  \multirow{5}{*}{1} &           1.220 &           0.481 &           0.695 &           0.640 &           0.811 \\
     + Learnable prior &   &           1.749 &  \textbf{0.448} &  \textbf{0.622} &           0.618 &           0.753 \\
                 + DCT &   &  \textbf{7.014} &           0.487 &           0.637 &           0.602 &           0.703 \\
 + Masked future poses &   &           6.803 &           0.472 &           0.623 &  \textbf{0.594} &  \textbf{0.695} \\
        \midrule
                  Base &  \multirow{5}{*}{2} &           1.217 &           0.466 &           0.672 &           0.642 &           0.812 \\
     + Learnable prior &   &           1.719 &  \textbf{0.418} &  \textbf{0.577} &           0.616 &           0.750 \\
                 + DCT &   &  \textbf{6.561} &           0.465 &           0.604 &           0.594 &           0.688 \\
 + Masked future poses &   &           6.286 &           0.448 &           0.587 &  \textbf{0.587} &  \textbf{0.681} \\
        \midrule
                  Base &  \multirow{5}{*}{3} &           1.248 &           0.376 &           0.549 &           0.639 &           0.802 \\
     + Learnable prior &   &           1.725 &  \textbf{0.327} &  \textbf{0.449} &           0.632 &           0.767 \\
                 + DCT &   &  \textbf{5.367} &           0.389 &           0.503 &           0.590 &           0.681 \\
 + Masked future poses &   &           4.861 &           0.361 &           0.474 &  \textbf{0.585} &  \textbf{0.674} \\
        \midrule
                  Base &  \multirow{5}{*}{4} &           1.261 &           0.339 &           0.498 &           0.641 &           0.805 \\
     + Learnable prior &   &           1.720 &  \textbf{0.281} &  \textbf{0.385} &           0.646 &           0.783 \\
                 + DCT &   &  \textbf{4.524} &           0.338 &           0.443 &           0.595 &           0.692 \\
 + Masked future poses &   &           3.857 &           0.312 &           0.412 &  \textbf{0.594} &  \textbf{0.689} \\
    \bottomrule
    \end{tabular}
    \caption{
        Influence of design decisions on obtained results for \mbox{$k=\{0, 1,2 ,3, 4\}$} trajectories. These trajectories refer to scenarios when we use no trajectories and then add progressively trajectories for the right foot, left foot, right hand, and left hand. The best results are in bold. 
    }
    \label{tab:additional-ablation}
\end{table}


\end{document}
\section{Conclusion}
\label{discussion}

We developed a framework for learning from sequences of user corrections during physical human-robot interaction. We introduced an auxiliary reward that models the connections between corrections, and leveraged mixed-integer programming to solve for the best possible sequence of corrections. Our results from online and in-person users demonstrate that our approach outperforms methods that take each correction independently, or wait for the final trajectory.

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper
  \usepackage{pgfplots}
  \pgfplotsset{compat=newest}
  %% the following commands are needed for some matlab2tikz features
  \usetikzlibrary{plotmarks}
  \usetikzlibrary{arrows.meta}
  \usepgfplotslibrary{patchplots}
  \usepackage{grffile}
  \usepackage{amsmath}
  \usepackage{blindtext}
  \usepackage[bottom]{footmisc}
  \usepackage{mathrsfs}
  \usepackage{lipsum}
 \usepackage{url}
 % table
 \usepackage{array}
\usepackage{booktabs}
\usepackage{float}
\usepackage{multirow}
\usepackage{cite}

\usepackage{svg}

\newlength\fwidth
 \usepackage[linesnumbered,ruled]{algorithm2e}

\usepackage{graphicx}
\usepackage{framed}
% \usepackage{subcaption}
\usepackage{indentfirst}
\usepackage{multirow}
\usepackage{makecell}
\let\proof\relax
\let\endproof\relax
\usepackage{amsmath, amssymb,amsthm}
\usepackage{color}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{hyperref}
\usepackage[capitalise]{cleveref}
\usepackage{comment}

\usepackage{makecell}
\let\labelindent\relax
\usepackage{enumitem}

\setcellgapes{1pt}
\newcommand{\shrink}{\vspace{-10pt}}
\newcommand{\shrinktop}{\vspace{-16pt}}
\newcommand{\shrinkbottom}{\vspace{-7pt}}

% \theoremstyle{exampstyle}
% \newtheorem{hypothesis}{H}
\newtheoremstyle{exampstyle}
{2pt} % Space above
{2pt} % Space below
{\itshape} % Body font
{} % Indent amount
{\bfseries} % Theorem head font
{.} % Punctuation after theorem head
{.5em} % Space after theorem head
{\thmname{#1}\thmnumber{#2}\thmnote{(#3)}} % Theorem head spec (can be left empty, meaning `normal')   
\theoremstyle{exampstyle}
\newtheorem{hypothesis}{H}

\usepackage{hyperref}

\newcommand{\ww}{w}                     % weight

\newcommand{\eref}[1]{Eq.~\eqref{#1}}  % Eqn 
\newcommand{\sref}[1]{Sec.~\ref{#1}}    % Section 
\newcommand{\figref}[1]{Fig.~\ref{#1}}  % Figure
\newcommand{\tabref}[1]{Table~\ref{#1}} % Table
\newcommand{\algoref}[1]{Alg.~\ref{#1}}  % Algorithm
\newcommand{\prg}[1]{\noindent\textbf{#1}} %Paragraph
%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts                              % This command is only needed if 
                                                          % you want to use the \thanks command

\overrideIEEEmargins                                      % Needed to meet printer requirements.

%In case you encounter the following error:
%Error 1010 The PDF file may be corrupt (unable to open PDF file) OR
%Error 1000 An error occurred while parsing a contents stream. Unable to analyze the PDF file.
%This is a known problem with pdfLaTeX conversion filter. The file cannot be opened with acrobat reader
%Please use one of the alternatives below to circumvent this error by uncommenting one or the other
%\pdfobjcompresslevel=0
%\pdfminorversion=4

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
%\usepackage{graphics} % for pdf, bitmapped graphics files
%\usepackage{epsfig} % for postscript graphics files
%\usepackage{mathptmx} % assumes new font selection scheme installed
%\usepackage{times} % assumes new font selection scheme installed
%\usepackage{amsmath} % assumes amsmath package installed
%\usepackage{amssymb}  % assumes amsmath package installed
\usepackage[colorinlistoftodos]{todonotes}
% \usepackage[disable]{todonotes}
\newcommand{\mengxi}[1]{\todo[inline,color=blue!20]{M: #1}}
\newcommand{\dylan}[1]{\todo[inline,color=teal!20]{Dy: #1}}
\newcommand{\jean}[1]{\todo[inline,color=red!40]{J: #1}}
\newcommand{\dorsa}[1]{\todo[inline,color=orange!20]{Do: #1}}
\newcommand{\mx}[1]{\textcolor{black}{#1}}
\newcommand{\mxdel}[1]{\textcolor{blue}{#1}}
\usepackage[font=footnotesize]{caption}
\usepackage{balance}
\usepackage{hyperref}
 \hypersetup{
     colorlinks=true,
     linkcolor=orange,
     filecolor=orange,
     citecolor=orange,      
     urlcolor=orange,
     }
% scriptsize
% footnotesize
% small
% normalsize
% large
% Large

% \title{\LARGE \bf
% Learning Robot Objectives from pHRI \\by Reasoning over Sequences of Corrections
% }
\title{\LARGE \bf
Learning Human Objectives from Sequences of Physical Corrections
}


\author{Mengxi Li$^{1}$, Alper Canberk$^{1}$, Dylan P. Losey$^{2}$, Dorsa Sadigh$^{1}$
\thanks{$^{1}$Intelligent and Interactive Autonomous Systems Group (\href{https://iliad.stanford.edu/}{ILIAD}), Dept of Computer Science, Stanford University, Stanford, CA 94305. \newline
$^{2}$ Collaborative Robotics Lab (\href{https://collab.me.vt.edu/}{Collab}), Virginia Tech.
\newline
{(e-mail: mengxili@stanford.edu)}}%
}


\begin{document}



\maketitle
\thispagestyle{empty}
\pagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}

When personal, assistive, and interactive robots make mistakes, humans naturally and intuitively correct those mistakes through physical interaction. In simple situations, one correction is sufficient to convey what the human wants. But when humans are working with multiple robots or the robot is performing an intricate task often the human must make \textit{several} corrections to fix the robot's behavior. Prior research assumes each of these physical corrections are \textit{independent} events, and learns from them one-at-a-time. However, this misses out on crucial information: each of these interactions are \textit{interconnected}, and may only make sense if viewed together. Alternatively, other work reasons over the \textit{final} trajectory produced by all of the human's corrections. But this method must wait until the end of the task to learn from corrections, as opposed to inferring from the corrections in an online fashion. In this paper we formalize an approach for learning from sequences of physical corrections during the current task. To do this we introduce an auxiliary reward that captures the human's trade-off between making corrections which improve the robot's immediate reward and long-term performance. We evaluate the resulting algorithm in remote and in-person human-robot experiments, and compare to both \textit{independent} and \textit{final} baselines. Our results indicate that users are best able to convey their objective when the robot reasons over their sequence of corrections.

\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{intro.tex}
\input{related_work.tex}
\input{formalism.tex}
\input{approach.tex}
\input{experiments.tex}
\input{discussion.tex}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \section*{APPENDIX}

% Appendixes should appear before the acknowledgment.

% \section*{Acknowledgements}
% We acknowledge funding from NSF Award 1941722, Fanuc Fellowship, and Qualcomm Innovation Fellowship for their support, and would like to thank Prof. Jeannette Bohg for insightful early discussion. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\clearpage
\section*{Acknowledgement}
We acknowledge funding from the NSF Award \#1941722 and \#2006388, Future of Life Institute, and DARPA Hicon-Learn project.

\balance
\bibliographystyle{IEEEtran}
\bibliography{main}


\end{document}

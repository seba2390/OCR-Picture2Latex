\section{Evaluation}
\label{sec:eval}
We evaluate our zero-cost model by asking four questions:
\begin{CompactItemize}
\item \textbf{Q1}: What is the cost of a context switch? (\secref{subsec:eval-transitions})
\item \textbf{Q2}: What is end-to-end performance gain of Wasm-based SFI due to zero-cost transitions? (\secref{subsec:eval-wasm})
\item \textbf{Q3}: What is the performance overhead of purpose-built zero-cost SFI enforcement? (\secref{subsec:eval-zerocostsfi})
\item \textbf{Q4}: Is the \verifname verifier effective? (\secref{subsec:verifier-eval})
\end{CompactItemize}

Since our zero-cost condition enforcement does incur some runtime overhead, \textbf{Q2} and \textbf{Q3} are heavily workload-dependent.
%
The benefit a workload receives from the zero-cost approach will be in direct proportion to the frequency with which it performs domain transitions.


\para{Systems}
To investigate the first three questions, we consider two groups of SFI systems.
%
The first group compares a number of different transition models for Wasm-based SFI for 64-bit binaries, built on top of the Lucet compiler~\cite{lucet}.
%
All of these will have identical runtime overhead, meaning that the only variance between them will be due to transition overhead.
%
The \trlucet build uses the original heavyweight springboards and trampolines
shipped with the Lucet runtime written in Rust.
%
\trfullswitch adopts techniques from NaCl and uses optimized
assembly to save and restore application context during transitions.
%
\trfast implements our zero-cost transition system, meaning transitions are
simple function calls.
%
To understand the overhead of register saving/restoring and stack
switching, we also evaluate a \trregsave build which saves/restores registers
like \trfullswitch, but shares the library and application stack like
\trfast.

The second group compares optimized SFI techniques for 32-bit binaries.
%
Wasm-based SFI imposes overheads far beyond what is strictly necessary to
enforce our zero-cost conditions, both because of the immaturity of the Lucet
compiler in comparison to more established compilers such as Clang, and because
Wasm inherently enforces additional restrictions on compiled code (e.g.,
structured intra-function control flow).
%
We design \trsegmentsfi~(\secref{sec:segments-secure}) to enforce only our zero-cost-conditions and nothing more, aiming to benchmark it against the Native Client 32-bit isolation scheme (\trnacl)~\cite{yee_native_2009}, arguably the fastest production SFI system available, which requires heavyweight transitions.
%
Both systems make use of memory segmentation, a 32-bit x86-only feature for fast memory isolation.
%
Unfortunately, we cannot make a uniform comparison between \trnacl, \trsegmentsfi, and \trfast since Lucet only supports a 64-bit target.

Each group additionally uses unsandboxed, insecure native execution (\texttt{Vanilla}) as a baseline.
%
To represent the best possible performance of schemes relying on heavyweight
transitions, we also benchmark \tridealheavy and \tridealheavysixfour,
ideal hardware isolation schemes, which incur no runtime
overhead but require heavyweight transitions.
%
To simulate the performance of these ideal schemes, we simply measure the performance
of native code with heavyweight trampolines.

We integrate all of the above SFI schemes into Firefox using the RLBox
framework~\cite{rlbox}.
%
Since RLBox already provides plugins for the \trlucet and \trnacl builds, we
only implement the plugins for the remaining system builds.

\para{Benchmarks}
%
We use a micro-benchmark to evaluate the cost of a single transition for our
different transition models, using unsandboxed native calls as a baseline
(\textbf{Q1}).

We answer questions \textbf{Q2}--\textbf{Q3} by measuring the end-to-end
performance of font and image rendering in Firefox, using a sandboxed
\libgraphite and \libjpeg, respectively.
%
We use these libraries because they have many cross-sandbox transitions, which
\citet{rlbox} previously observed to affect the overall browser performance.
%
To evaluate the performance of \libgraphite, we use Kew's
benchmark\footnote{Available at
\url{https://jfkthame.github.io/test/udhr_urd.html}}, which reflows the text on
a page ten times, adjusting the size of the fonts each time to negate the
effects of font caches.
%
When calling \libgraphite, Firefox makes a number of calls into the sandbox
roughly proportional to the number of glyphs on the page.
%
We run this benchmark 100 times and report the median execution
time below (all values have standard deviations within 1\%).

To evaluate the performance of \libjpeg, we measure the overhead of rendering
images of varying complexity and size.
%
Since the work done by the sandboxed \libjpeg, per call, is proportional to the
width of the image\dash---Firefox executes the library in \emph{streaming
mode}, one row at a time\dash---we consider images of different widths,
keeping the image height fixed.
%
This allows us to understand the benefits and limitations of zero-cost
transitions, since the proportion of execution time spent context-switching decreases
as the image width increases.
%
We do this for three images, of varying complexity: a simple image consisting
of a single color (\simplejpeg), a stock image from the Image Compression
benchmark suite\footnote{Online:
\url{https://imagecompression.info/test_images/}.  Visited Dec 9, 2020.}
(\stockjpeg), and an image of random pixels (\randomjpeg).
%
We render each image 500 times and report the median time (standard
deviations are all under 1\%).

Finally, we use \SPECOhSix to partly evaluate the sandboxing overhead of our
purpose-built \trsegmentsfi SFI system (\textbf{Q3}), and to measure
\verifname's verification speed (\textbf{Q4}).

\para{Machine and software setup}
%
We run all but the verification benchmarks on an \Intel
Core\textsuperscript{TM} i7-6700K machine with four 4GHz cores, 64GB RAM,
running Ubuntu 20.04.1 LTS (kernel version 5.4.0-58).
%
We run benchmarks with a shielded isolated cpuset~\cite{cpu-shielding}
consisting of one core with hyperthreading disabled and the clock frequency
pinned to 2.2GHz.
%
We generate Wasm sandboxed code in two steps: First, we compile C/\C++
to Wasm using Clang-11, and then compile Wasm to native code using the 
fork of the Lucet used by RLBox (snapshot from Dec 9, 2020).
%
We generate NaCl sandboxed code using a modified version of Clang-4.
%
We compile all other C/\C++ source code, including \trsegmentsfi sandboxed code and
benchmarks using Clang-11.
%
We implement our Firefox benchmarks on top of Firefox Nightly (from August 22,
2020).

\para{Summary of results}
%
We find that the performance of Wasm-based isolation
can be significantly improved by adopting zero-cost transitions, but that
Lucet-compiled WebAssembly's runtime overhead means that it does not outperform
more optimised isolation schemes in end-to-end tests.
%
The low performance overhead of \trsegmentsfi demonstrates that these runtime
overheads are not inherent to the zero-cost approach, and that an optimised
zero-cost SFI system can significantly outperform more traditional schemes,
especially for workloads with a large number of transitions.
%
Finally, we find that we can efficiently check zero-cost conditions at the
binary level, for Lucet compiled code, with no false positives.


\input{eval-transitions}
\input{eval-wasm}
\input{eval-zerocostsfi}
\input{eval-verifier}

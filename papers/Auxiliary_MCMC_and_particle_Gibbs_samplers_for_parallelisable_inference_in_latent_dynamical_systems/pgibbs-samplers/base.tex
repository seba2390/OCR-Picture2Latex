Most of the article so far has been concerned with MCMC algorithms using Kalman primitives to sample from a LGSSM proposal distribution designed as a local approximation of the target model at hand. This method, while expected to work particularly well when the prior is almost Gaussian and the potential relatively non-informative, presents at least three limitations: (i) it accepts or rejects a full trajectory at once, so that an unfortunate choice for a single time step would result in rejecting the full proposal, thereby hindering progress of the Markov chain; (ii) it requires that the full model be \emph{de facto} differentiable or has fully tractable moments, preventing its use in, for example, bounded state-spaces; (iii) it is hardly applicable to very non-Gaussian dynamics.
For these reasons, in this section, we turn ourselves to the successful class of particle MCMC algorithms, in particular particle Gibbs algorithms, and show how the auxiliary observation trick can be leveraged to design efficient MCMC samplers for Feynman--Kac models.
We first quickly recall the basic particle Gibbs algorithm, after which we show how it can be used to sample from an auxiliary target resembling~\eqref{eq:augmented-gaussian-fk}. A general method is first presented, after which we show how additional information may be used to improve the sampler.
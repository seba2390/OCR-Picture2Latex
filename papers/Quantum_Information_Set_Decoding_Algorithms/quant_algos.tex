\section{Quantum search algorithms}
\subsection{Grover search}
Grover's search algorithm \cite{G96a,G97} is, along with its generalisation \cite{BBHT98} which is used in this paper, an optimal algorithm for solving the following problem with a quadratic speed-up compared to the best-possible classical algorithm.
\begin{problem}[Unstructured search problem]
Given a set $\zE$ and a function $f : \zE \rightarrow \{0,1\}$, find an $x \in \zE$ such that $f(x) = 1$.
\end{problem}
In other words, we need to find an element that fulfils a certain property, and $f$ is an oracle for deciding whether it does. Moreover, in the new results presented in this paper, $f$ will be a quantum algorithm.
If we denote by $\varepsilon$ the proportion of elements $x$ of $\zE$ such that $f(x) = 1$, Grover's algorithm solves the problem above using $O(\frac{1}{\sqrt{\varepsilon}})$ queries to $f$, whereas in the classical setting this cannot be done with less than $O(\frac{1}{\varepsilon})$ queries.
Furthermore, if the algorithm $f$ executes in time $T_f$ on average, the average time complexity of Grover's algorithm will be $O(\frac{T_f}{\sqrt{\varepsilon}})$.
\subsection{Quantum Walk}
\subsubsection{Random Walk.}
Unstructured search problems as well as search problems with slightly more but still minimal structure may be recast as graph search problems.
\begin{problem}[Graph search problem]
Given a graph $G=(\zV,\zE)$ and a set of vertices $\zM \subset \zV$, called the set of \textit{marked elements}, find an $x \in \zM$.
\end{problem}
The graph search problem may then be solved using random walks (discrete-time Markov chains) on the vertices of the graph.
From now on, we will take the graph to be undirected, connected, and $d$-regular, i.e. such that each vertex has exactly $d$ neighbours.
\par{\em Markov chain.}
A Markov chain is given by an initial probability distribution $v$ and a stochastic transition matrix $M$. The transition matrix of a random walk on a graph (as specified above) is obtained from the graph's adjacency matrix $A$ by
$M=\frac{1}{d}A$.
\par{\em Eigenvalues and the spectral gap.}
A closer look at the eigenvalues and the eigenvectors of $M$ is needed in order to analyse the complexity of a random walk on a graph.
The eigenvalues will be noted $\lambda_i$ and the corresponding eigenvectors $v_i$. We will admit the following points (see \cite{CDS80}):\\
(i) all the eigenvalues lie in the interval $[-1,1]$;\\
 (ii) $1$ is always an eigenvalue, the corresponding eigenspace is of dimension $1$;\\
(iii) there is a corresponding eigenvector which is also a probability distribution (namely the uniform distribution $u$ over the vertices). 
It is the unique stationary distribution of the random walk.\\
  We will suppose that the eigenvalues are ordered from largest to smallest, so that $\lambda_1=1$ and $v_1=u$.
An important value associated with the transition matrix of a Markov chain is its \textit{spectral gap}, defined as 
$\delta \eqdef  1 - \max_{i=2,...,d}|\lambda_i|$.
Such a random walk on an undirected regular graph is always {\em reversible} and it is also {\em irreducible} because we have assumed that the graph is 
connected. The random walk is {\em aperiodic} in such a case if and only if the spectral gap $\delta$ is positive. In such a case,  a long enough random walk in the graph converges to the uniform distribution since for all $\eta>0$, we have $||M^kv - u|| < \eta$ for $k=\tilde O(1/\delta)$, where $v$ is the initial probability distribution.
 

Finding a marked element by running a Markov chain on the graph just consists in 

 \begin{algorithm}[H]
  \DontPrintSemicolon
  \KwIn{$G = (\zE,\zV)$, $\zM \subset \zV$, initial probability distribution $v$}
  \KwOut{An element $e \in \zM$}
   \textsc{Setup :} Sample a vertex $x$ according to $v$ and initialise the data structure.\;
   \Repeat{
     \textsc{Check :} \eIf{current vertex $x$ is marked}{
     \KwRet $x$\; 
   }{
     \RepeatU{$x$ is sampled according to a distribution close enough to the uniform distribution}{
       \textsc{Update :} \emph{Take one step of the random walk and update data structure accordingly.}\;
       }
     }
   }

  \caption{$RandomWalk$}
 \end{algorithm}

Let $\CS$ be the cost of \textsc{Setup}, $\CC$ be the cost of \textsc{Check} and $\CU$ be the cost of \textsc{Update}. 
It follows from the preceding considerations that $\tilde O(1/\delta)$ steps of the random walk are sufficient to sample $x$ according to the uniform distribution.
Furthermore, if we note $\varepsilon := \frac{|\zM|}{|\zV|}$ the proportion of marked elements, it is readily seen that the algorithm ends after $O(1/\varepsilon)$ iterations of the outer loop.
Thus the complexity of classical random walk is $\CS + \frac{1}{\varepsilon}\left(\CC + \frac{1}{\delta}\CU\right)$.

Several quantum versions of random walk algorithms have been proposed by many authors, notably Ambainis \cite{A07}, Szegedy \cite{S04}, and Magniez, Nayak, Roland and Santha \cite{MNRS07}. A survey of these results can be found in \cite{S08}. We use here the following result
\begin{theorem}[\cite{MNRS07}]
\label{th:quantumwalk}
Let $M$ be an aperiodic, irreducible and reversible Markov chain on a graph with spectral gap $\delta$, and $\varepsilon := \frac{|\zM|}{|\zV|}$ as above. Then there is a quantum walk algorithm that finds an element in $\zM$ with cost
\begin{equation}\label{eq:complexity_quantum_walk}
\boxed{\CS + \frac{1}{\sqrt\varepsilon}\left(\CC + \frac{1}{\sqrt\delta}\CU\right)}
\end{equation}
\end{theorem}

\subsubsection{Johnson graphs and product graphs.}
With the exception of Grover's search algorithm seen as a quantum walk algorithm, to date an overwhelming majority of quantum walk algorithms are based on Johnson graphs or a variant thereof. The decoding algorithms which shall be presented in this paper rely on cartesian products of Johnson graphs. All of these objects are defined in this section and some important properties are mentioned.
\begin{definition}[Johnson graphs]
\label{def_johnson_graph}
A Johnson graph $J(n,r)$ is an undirected graph whose vertices are the subsets containing $r$ elements of a set of size $n$, with an edge between two vertices $S$ and $S'$ iff $|S \cap S'| = r-1$. In other words, $S$ is adjacent to $S'$ if $S'$ can be obtained from $S$ by removing an element and adding a new element in its place.
\end{definition}
It is clear that $J(n,r)$ has $\binom{n}{r}$ vertices and is $r(n-r)$-regular. Its spectral gap is given by
\begin{equation}
\label{eq:spectral_gap_johnson}
\delta = \frac{n}{r(n-r)}.
\end{equation}
\begin{definition}[Cartesian product of graphs]
\label{def_product_graphs}
Let $G_1 = (\zV_1, \zE_1)$ and $G_2 = (\zV_2,\zE_2)$ be two graphs. Their cartesian product $G_1 \times G_2$ is the graph $G = (\zV,\zE)$ where:
\begin{enumerate}
  \item $\zV = \zV_1 \times \zV_2$, i.e. $\zV = \{v_1v_2~|~v_1 \in \zV_1, v_2 \in \zV_2\}$
  \item $\zE = \{(u_1u_2,v_1v_2)~|~ (u_1 = v_1 \wedge (u_2,v_2) \in \zE_2) \vee ((u_1,v_1) \in \zE_1 \wedge u_2 = v_2)\}$
\end{enumerate}
\end{definition}
The spectral gap of products of Johnson graphs is given by
\begin{restatable}[Cartesian product of Johnson graphs]{theorem}{thmProdJohnsonGraph}
\label{thm:product_johnsongraphs}
Let $J(n,r) = (\zV,\zE)$, $m \in \mathbb{N}$ and $J^m(n,r) := \times_{i=1}^m J(n,r) = (\zV_m,\zE_m)$. Then:
\begin{enumerate}
  \item $J^m(n,r)$ has $\binom{n}{r}^m$ vertices and is $md$-regular where $d = r(n-r)$.
  \item We will write $\delta(J)$ resp. $\delta(J^m)$ for the spectral gaps of $J(n,r)$ resp. $J^m(n,r)$. Then:\\
$\delta(J^m) \geq \frac{1}{m}\delta(J).$
 \item The random walk associated with $J^m(n,r)$ is  aperiodic, irreducible and reversible for all positive $m$, $n$ and $r<n$.
\end{enumerate}
\end{restatable}
For a proof of this statement, see the appendix.

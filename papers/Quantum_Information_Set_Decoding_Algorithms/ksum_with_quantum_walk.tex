{\tiny }\section{Solving the generalised $4$-sum problem with quantum walks and Grover search}

\subsection{The Shamir-Schroeppel idea}
As explained in Section \ref{sec:classical_quantum_decoding}, the more sophisticated ISD algorithms solve during the inner step 
an instance of the generalised $k$-sum problem.
The issue is to get a good quantum version of the classical algorithms used to solve this problem. That this task is non trivial can already be
guessed from Dumer's algorithm. Recall that it solves the generalised $2$-sum problem in time and space complexity $\OO{V}$ when 
$V=|\zV_0|=|\zV_1|=\Theta(|\zG|)$.
The problem is that if we wanted a quadratic speedup when compared to the classical Dumer algorithm,
then this would require a quantum algorithm solving the same problem in time $\OO{V^{1/2}}$, but this seems problematic since naive ways of quantising this algorithm 
stumble on the problem that the space complexity is a lower bound on the time complexity of the quantum algorithm.
This strongly motivates the choice of ways of solving the $2$-sum problem by using less memory. This can be done through the idea of Shamir and Schroeppel \cite{SS81}.
Note that the very same idea is also used for the same reason to 
speed up quantum algorithms for the subset sum problem in \cite[Sec. 4]{BJLM13}.
To explain the idea, suppose that $\zG$ factorises as $\zG = \zG_0 \times \zG_1$ where $|\zG_0| = \Theta(|\zG_1|)=\Theta(|\zG|^{1/2})$.
Denote for $i\in \{0,1\}$ by $\pi_i$ the projection from $\zG$ onto $\zG_i$ which to $g=(g_0,g_1)$ associates  $g_i$.

The idea is to construct $f(\zV_0)$ and $f(\zV_1)$ themselves as 
$f(\zV_0)=f(\zV_{00})+f(\zV_{01})$ and 
$f(\zV_1)=f(\zV_{10}) + f(\zV_{11})$ in such a way that  the $\zV_{ij}$'s are of size $O(V^{1/2})$
and to solve a $4$-sum problem by solving various $2$-sum problems. In our coding theoretic setting, it will be more convenient to explain everything directly in terms
of the $4$-sum problem which is given in this case by
\begin{problem}\label{pb:SS}
Assume that $k+\ell$  and $p$ are multiples of $4$. 
Let 
\begin{eqnarray*}
\zG & = &\Ft^\ell, \;\;\zE  =  \Ft^{k+\ell}, \;\;f(v)  =  H'{v}^T\\
\zV_{00} &\eqdef &\{(e_{00},0_{3(k+\ell)/4})\in \Ft^{k+\ell} : e_{00 }\in \Ft^{(k+\ell)/4},\; |e_{00}|=p/4\} \\
\zV_{01} &\eqdef &\{(0_{(k+\ell)/4},e_{01},0_{(k+\ell)/2})\in \Ft^{k+\ell} : e_{01 }\in \Ft^{(k+\ell)/4},\; |e_{01}|=p/4\} \\
\zV_{10} &\eqdef &\{(0_{(k+\ell)/2},e_{10},0_{(k+\ell)/4})\in \Ft^{k+\ell} : e_{10 }\in \Ft^{(k+\ell)/4},\; |e_{10}|=p/4\} \\
\zV_{11} &\eqdef &\{(0_{3(k+\ell)/4},e_{11})\in \Ft^{k+\ell} : e_{11}\in \Ft^{(k+\ell)/4},\; |e_{11}|=p/4\} 
\end{eqnarray*}
and $S$ be some element in $\zG$.
Find $(v_{00},v_{01},v_{10},v_{11})$ in $\zV_{00}\times \zV_{01} \times \zV_{10} \times \zV_{11}$ such 
that $f(v_{00})+f(v_{01})+f(v_{10})+f(v_{11})=S$ and $h(v_{00}+v_{01}+v_{10}+v_{11})$ is of weight $w$.
\end{problem}
Let us explain now how the Shamir-Schroeppel idea allows us to solve the $4$-sum problem in time $\OO{V}$ and space $\OO{V^{1/2}}$ when 
the $\zV_{ij}$'s are of order $\OO{V^{1/2}}$, 
$|\zG|$ is of order $V$ and when $\zG$ decomposes as the product of two groups $\zG_0$ and $\zG_1$ both of size $\Th{V^{1/2}}$.
The basic idea is  to solve for all possible $r \in \zG_1$ the following $2$-sum problems 
\begin{eqnarray}
\pi_1(f(v_{00})) +\pi_1(f(v_{01})) & = & r\label{eq:problem1}\\
\pi_1(f(v_{10}))  +\pi_1(f(v_{11})) & = & \pi_1(S)-r \label{eq:problem2}
\end{eqnarray}
Once these problems are solved we are left with  $\OO{V^{1/2} V^{1/2}/V^{1/2}}=\OO{V^{1/2}} $ solutions to the first problem and $\OO{V^{1/2}}$ solutions to the second.
Taking any pair $(v_{00},v_{01})$ solution to \eqref{eq:problem1}  and $(v_{10},v_{11})$ solution to \eqref{eq:problem2} yields a $4$-tuple which is a partial solution to the
$4$-sum problem
$$
\pi_1( f(v_{00}))+\pi_1(f(v_{01})) +\pi_1(f(v_{10}))+\pi_1(f(v_{11}))  = r + \pi_1(S)-r = \pi_1(S).
$$
Let $\zV'_0$ be the set of all pairs $(v_{00},v_{01})$ we have found for the 
first $2$-sum problem \eqref{eq:problem1}, whereas $\zV'_1$ is the set of all solutions to \eqref{eq:problem2}. 
To ensure that $f(v_{00})+f(v_{01}) +f(v_{10})+f(v_{11}) =  S$ 
we just have to 
solve the following $2$-sum problem
$$
\underbrace{\pi_0(f(v_{00})) + \pi_0(f(v_{01}) )}_{f'(v_{00},v_{01})}+ \underbrace{\pi_0(f(v_{10})) + \pi_0(f(v_{11}) )}_{f'(v_{10},v_{11})} = \pi_0(S)
$$
and $$
g(v_{00},v_{01},v_{10},v_{11})=0
$$
where $(v_{00},v_{01})$ is in $\zV'_0$, $(v_{10},v_{11})$ is in $\zV'_1$ and 
$g$ is the function whose root we want to find for the original $4$-sum problem.

This is again of complexity $\OO{V^{1/2} V^{1/2}/V^{1/2}}=\OO{V^{1/2}} $.
Checking a particular value of $r$ takes therefore $\OO{V^{1/2}}$
 operations. Since we have $\Th{V^{1/2}}$ values to check, the 
total complexity is $\OO{V^{1/2}V^{1/2}}=\OO{V}$, that is the same as before, but we need only $\OO{V^{1/2}}$ memory to store all intermediate sets.
\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{ss.png}
    \caption{
The Shamir-Schroeppel idea in the decoding context (see Problem \ref{pb:SS}): the support of the elements of $\zV_{ij}$ is represented in orange, while
the blue and green colours represent $\zG_0$ resp. $\zG_1$.}
    \label{fig:ss}
\end{figure}
\subsection{A quantum version of the Shamir-Schroeppel algorithm}

By following the approach of \cite{BJLM13}, we will define a quantum
algorithm for  
solving the $4$-sum problem
by combining Grover search with a quantum walk
with a complexity given by

\begin{proposition}\label{prop:easy}
Consider the generalised $4$-sum problem  with sets $\zV_u$ of size  $V$. Assume that 
$\zG$ can be decomposed as $\zG =\zG_0 \times \zG_1$. 
There is a quantum algorithm for solving the $4$-sum problem running in time $\OOt{|\zG_1|^{1/2}V^{4/5}}$
as soon as $|\zG_1| = \Om{V^{4/5}}$ and $|\zG| = \Om{V^{8/5}}$.
\end{proposition}

This is nothing but the idea of the algorithm \cite[Sec. 4]{BJLM13} laid out in a more general context.
The idea is as in the classical algorithm to look for the right value $r \in \zG_1$. This can be done with Grover search in 
time $\OO{|\zG_1|^{1/2}}$ instead of $\OO{|\zG_1|}$ in the classical case.
The quantum walk is then used to solve the following problem:

\begin{problem}\label{pb:shamir_shroeppel}
Find $(v_{00},v_{01},v_{10},v_{11})$ in $\zV_{00}\times \zV_{01} \times \zV_{10} \times \zV_{11}$ such that 
\begin{eqnarray*}
\pi_1(f(v_{00})) +\pi_1(f(v_{01})) & = & r \\
\pi_1(f(v_{10}))  +\pi_1(f(v_{11})) & = & \pi_1(S)-r \\
\pi_0(f(v_{00})) + \pi_0(f(v_{01})) + \pi_0(f(v_{10})) + \pi_0(f(v_{11})) & = &\pi_0(S)\\
g(v_{00},v_{01},v_{10},v_{11}) & = & 0.
\end{eqnarray*}
\end{problem}

For this, we choose subsets $\zU_i$'s of the $\zV_i$'s of a same size $U=\Th{V^{4/5}}$ and 
run a quantum walk on the graph whose vertices are all possible $4$-tuples of
sets of this kind and two $4$-tuples $(\zU_{00},\zU_{01},\zU_{10},\zU_{11})$ and
$(\zU_{00}',\zU_{01}',\zU_{10}',\zU_{11}')$ are adjacent if and only if we have for all $i$'s but one $\zU'_i=\zU_i$ and
for the remaining  $\zU'_i$ and $\zU_i$ we have $|\zU'_i \cap \zU_i|=U-1$.
Notice that this graph is nothing but $J^4(V,U)$.
By following \cite[Sec. 4]{BJLM13} it can be proved that 
\begin{restatable}{proposition}{propDataStructure}
\label{prop:data_structure}
Under the assumptions that $|\zG_1| = \Om{V^{4/5}}$ and $|\zG| = \Om{V^{8/5}}$,
it is possible to set up a data structure of size $\OO{U}$
to implement this quantum walk such that \\
(i) setting up the data structure takes time $\OO{U}$;\\
(ii) checking whether a new $4$-tuple leads to a solution to the problem above (and outputting the solution in this case) 
takes time $\OO{1}$,\\
(iii) updating the data structure takes time $\OO{\log U}$.
\end{restatable}
The proof which we give is adapted from \cite[Sec. 4]{BJLM13}.
\begin{proof}
$~$\\
\begin{enumerate}
\item \textbf{Setting up the data structure takes time $\OO{U}$.\\}
The data structure is set up more or less in the same way as in classical Shamir-Schroeppel's algorithm, i.e. by solving two 2-sum problems first and then using the result to solve a third and last 2-sum problem. There are however the following differences:\\ \\
(i) We no longer keep the results in a hashtable but in some other type of ordered data structure which allows for the insertion, deletion and search operations to be done in $\OO{\log U}$ time. For instance, \cite{BJLM13} chose radix trees. More detail will be given when we look at the \textsc{Update} operation.\\
(ii) Because we no longer use hashtables, we will need two data structures at each step, one to keep track of $f(v_{00})$ along with the associated $v_{00}$, $f(v_{00}) + f(v_{01})$ along with the associated $(v_{00},v_{01})$, etc. and another to keep track of $v_{00}$, $(v_{00}, v_{01})$, etc. separately. If we denote the first family of data structures by $\zD_f$ and the second family by $\zD_{\zV}$, this gives a total of 13 data structures (7 of type $\zD_{\zV}$ and 6 of type $\zD_f$, because no data structure is needed to  
store the sum of all four vectors which is simply $S$).\\ \\
Solving the first two 2-sum problems takes time $|\zU_{i0}| + |\zU_{i1}| + \frac{|\zU_{i0}|.|\zU_{i1}|}{|\zG_1|}$,
$i=0,1$, which is $\OO{U}$ because $|\zG_1| = \Om{V^{4/5}} = \Om{U}$. 
Denote by $\zU_{0}$ resp. $\zU_{1}$ the set of solutions to these two problems. These solutions are used to solve the second 2-sum, problem, which takes time 
$|\zU_{0}| + |\zU_{1}| + \frac{|\zU_{0}|.|\zU_{1}|}{|\zG_0|} = \OO{U}$ 
due to 
$\zG_0 = \zG / \zG_1$ 
and $|\zG| = \Om{V^{8/5}}$.\\ \\
Thus, setting up the data structure takes time $\OO{U}$.
\item \textbf{Updating the data structure takes time $\OO{\log U}$.\\}
Recall that the data structures are chosen such that the insertion, deletion and search operations take $\OO{\log U}$ time, and also that there are two data structures pertaining to each vector or pair of vectors, for a total of 13 data structures.\\ \\
Recall also that the update step consists in moving from one vertex of the Johnson graph $J^4(V,U)$ to one that is adjacent to it. Suppose, without loss of generality, that we move from the vertex $(\zU_{00},\zU_{01},\zU_{10},\zU_{11})$ to $(\zU_{00}',\zU_{01},\zU_{10},\zU_{11})$. Thus, a $v_{00} \in \zU_{00}$ has been replaced by a $u_{00} \in \zU_{00}$.\\ \\
Then, the low cost of the update step relies upon the following fundamental insight: there are in all $U$ possible ways of writing the sum $\pi_1(f(u_{00})) +\pi_1(f(v_{01}))$ (one for each $v_{01} \in \zU_{01}$). But we have one further constraint which is that this sum needs to be equal to a given $r \in \zG_1$. Thus, there are on average $\frac{|\zU_{ij}|}{|\zG_1|} = O(1)$ values of $v_{01} \in \zU_{01}$ which give a solution.\\ \\
Note that the same argument applies for the number of $(v_{10}, v_{11}) \in \zU_{1}$ that fulfil the condition
$$\pi_0(f(u_{00})) + \pi_0(f(v_{01})) + \pi_0(f(v_{10})) + \pi_0(f(v_{11})) ~ = ~\pi_0(S)$$
for a given 
$(u_{00}, v_{01}) \in \zU_{0}$
(where $\pi_0(S) \in \zG_0$), 
for in this case there are on average 
$\frac{|\zU_{0}|}{|\zG_0|} = O(1)$ 
such elements.\\ \\
This allows us to proceed as follows: we impose a constant limit on the number of $v_{01} \in \zU_{01}$ that correspond to a given $u_{00} \in \zU_{00}$ at each update operation. A similar limit is imposed on the number of $(v_{10}, v_{11}) \in \zU_{1}$. The probability of reaching this limit is negligeable, and if it is reached, we re-initialise the data structure, so this does not modify the overall complexity of the algorithm. Note also that there is no problem when the opposite situation happens, i.e. when there are no $v_{01} \in \zU_{01}$ corresponding to a given $u_{00} \in \zU_{00}$. Indeed, while this may result in the data structure being depleted, this is a temporary situation and the data structure will be refilled over time as more suitable elements occur.\\ \\
We now enumerate the steps needed to update the data structure. What we need to do is to remove the old element $v_{00}$ and everything that has been constructed using it, and add $u_{00}$ and everything that it allows to construct (within the limits discussed above).
First, to remove $v_{00}$ and the other elements it affects, we need to do the following:
\begin{enumerate}
\item Find and delete $v_{00}$ from the data structure $\zD_{\zU_{00}}$.
\item Calculate $f(v_{00})$, then find and delete it from the data structure $\zD_{f_{00}}$.
\item Find at most a constant number of $(v_{00}, v_{01})$ in $\zD_{\zU_{0}}$ and remove them.
\item For each of these $(v_{00}, v_{01})$, calculate $f(v_{00}) + f(v_{01})$ and remove it from $\zD_{f_{0}}$.
\item Find at most a constant number of $(v_{00}, v_{01}, v_{01}, v_{11})$ in $\zD_{\zU}$ and remove them.
\end{enumerate}
This step uses operations of negligeable cost (calculating $f(v_{00})$, etc.) and the number of operations of cost 
$\log(U)$ 
which it uses is bounded by a constant. Thus it takes time 
$\OO{\log(U)}$.\\ \\
To add $u_{00}$ and other new elements depending on it, we proceed as follows:
\begin{enumerate}
\item Insert $u_{00}$ in $\zD_{\zU_{00}}$.
\item Calculate $f(u_{00})$, then insert it in $\zD_{f_{00}}$.
\item Calculate $x=r - \pi_1(f(u_{00}))$ and find if there are elements $y$ in $\zD_{f_{01}}$ such that $\pi_1(y)=x$. For a constant number of associated $v_{01}$, insert $(u_{00}, v_{01})$ in $\zD_{\zU_{0}}$ and in $\zD_{f_{0}}$ associated with $r$.
\item Similarly there are a constant number of $(v_{01}, v_{11})$ that need to be updated, for those calculate $g(u_{00}, v_{01}, v_{10}, v_{11})$. If it is equal to zero, insert $(v_{00}, v_{01}, v_{10}, v_{11})$ in $\zD_{\zU}$.
\end{enumerate}
It is easy to see that this step also takes time 
$\OO{\log(U)}$.
\item \textbf{Checking whether a new $4$-tuple leads to a solution of the problem takes time $\OO{1}$.\\}
Checking that the right $4$-tuple is in $\zD_{\zU}$ requires looking for it in $\zD_{\zU}$ at the first step of the algorithm. This costs $O(\sqrt{U})$ using Grover search. At the following steps of the algorithm, it is enough to check the new elements (whose number is bounded by a constant) that have been added to $\zD_{\zU}$. So the checking cost is 
$\OO{1}$
 overall.$~\qed$
\end{enumerate}
\end{proof}
Proposition \ref{prop:easy} is essentially a corollary of this proposition. 

\begin{proof} [Proof of Proposition \ref{prop:easy}]
Recall that 
the cost of the quantum walk is given by
$
\CS + \frac{1}{\sqrt\varepsilon}\left(\CC + \frac{1}{\sqrt\delta}\CU\right)$
 where $\CS,\CC,\CU,\varepsilon$ and $\delta$
are the setup cost, the check cost, the update cost, the proportion of marked elements
and the spectral gap of the quantum walk. 
From Proposition \ref{prop:data_structure}, we know that
$\CS =  \OO{U} = \OO{V^{4/5}}$, $\CC  =  \OO{1}$,
and $\CU  =  \OO{\log U}$.
Recall that the spectral gap of $J(V,U)$ is equal to $\frac{V}{U(V-U)}$ by \eqref{eq:spectral_gap_johnson}.
This quantity is larger than $\frac{1}{U}$ and by using  
 Theorem \ref{thm:product_johnsongraphs} on the cartesian product of Johnson graphs, we obtain
$\delta = \Th{\frac{1}{U}}$.

Now for the proportion of marked elements we argue as follows. If Problem \ref{pb:shamir_shroeppel} has a solution $(v_{00},v_{01},v_{10},v_{11})$, then the probability that 
each of the sets $\zU_i$ contains $v_i$ is precisely $U/V=\Th{V^{-1/5}}$.
The probability $\varepsilon$ that all the $\zU_i$'s contain $v_i$ is then 
$\Th{V^{-4/5}}$.  
This gives a total cost of 
$$
\OO{V^{4/5}} + \OO{V^{2/5}}\left( \OO{1} + \OO{V^{2/5}}\OO{\log U}\right) = \OOt{V^{4/5}}.
$$
When we multiply this by the cost of Grover's algorithm for finding the right $r$ we have the aforementioned complexity.$~\qed$
\end{proof}

\subsection{Application to the decoding problem}
When applying this approach to the decoding problem we obtain
\begin{restatable}{theorem}{thmExpSSQW}
\label{th:expSSQW}
We can decode $w=\omega n$ errors in a random linear code of length $n$ and rate $R=\frac{k}{n}$  with a quantum complexity of
order $\OOt{2^{\alpha_{\text{SSQW}}(R,\omega)n}}$ where 
%\ghk{Corrected another $\ell$ that should be a $\lambda$}
$$
\alpha_{\text{SSQW}}(R, \omega) \eqdef \min_{(\pi,\lambda) \in \zR} \left(\frac{H_2(\omega) - (1-R-\lambda)H_2\left(\frac{\omega - \pi}{1 - R - \lambda}\right) - \frac{2}{5}(R+\lambda)H_2\left(\frac{\pi}{R+\lambda}\right)}{2} \right)$$
$$
\zR  \eqdef  \left\{\!(\pi,\lambda)\!\!\in\!\![0,\omega]\!\times\![0,1)\!:\lambda = \frac{2}{5}(R+\lambda)H_2\!\left(\!\frac{\pi}{R+\lambda}\!\right)\!\!,
\pi \leq R + \lambda, \lambda \leq 1-R-\omega+\pi \! \right\}
$$
%\Leftrightarrow \pi = (R+\lambda)H_2^{-1}\left(\frac{5\lambda}{2(R + \lambda)}\right)$
\end{restatable}
\begin{proof}
Recall (see \eqref{eq:T_quant_ISD}) that the quantum complexity is given by
\begin{equation}
\label{eq:complexitySSQW}
\tilde O\left(\frac{T_{\text{SSQW}}}{\sqrt{P_{\text{SSQW}}}}\right)
\end{equation}
where $T_{\text{SSQW}}$ is the complexity of the combination of Grover's algorithm and quantum walk
solving the generalised $4$-sum problem specified in Problem \ref{pb:shamir_shroeppel} and $P_{\text{SSQW}}$ is the probability
that the random set of $k + \ell$ positions $\zS$ and its random partition in $4$ sets of the same size that are chosen is such that 
all four of them contain exactly $p/4$ errors.
Note that $p$ and $\ell$ are chosen such that $k+\ell$ and $p$ are divisible by $4$.
$P_{\text{SSQW}}$ is given by
$$
P_{\text{SSQW}} = \frac{  {\binom{\frac{k+\ell}{4}}{\frac{p}{4}}}^4 \binom{n-k-\ell}{w - p}}{\binom{n}{w}}
$$
Therefore
\begin{equation}
\label{eq:PSSQW}
(P_{\text{SSQW}})^{-1/2} = \OOt{2^{\frac{H_2(\omega) - (1-R-\lambda)H_2\left(\frac{\omega - \pi}{1 - R - \lambda}\right) - (R+\lambda)H_2\left(\frac{\pi}{R+\lambda}\right) }{2} n}}
\end{equation}
where $\lambda \eqdef \frac{\ell}{n}$ and $\pi \eqdef \frac{p}{n}$. $T_{\text{SSQW}}$ is given by Proposition \ref{prop:easy}:
$$
T_{\text{SSQW}}  =  \OOt{|\zG_1|^{1/2}V^{4/5}}
$$
where the sets involved in the generalised $4$-sum problem are specified in Problem \ref{pb:shamir_shroeppel}.
This gives
$$
V  =  \binom{\frac{k + \ell}{4}}{\frac{p}{4}}
$$
We choose $\zG_1$ as 
\begin{equation}\label{eq:condition1}
\zG_1 = \Ft^{\lceil \frac{\ell}{2} \rceil}
\end{equation}
and the assumptions of Proposition \ref{prop:easy} are verified as soon as
$$
2^\ell = \Om{V^{8/5}}.
$$
which amounts to
$$
2^\ell = \Om{  {\binom{\frac{k + \ell}{4}}{\frac{p}{4}}}^{8/5}}
$$
This explains the condition 
\begin{equation}\label{eq:condition2}
\lambda = \frac{2}{5} (R + \lambda) H_2\left( \frac{\pi}{R+\lambda} \right)
\end{equation}
found in the definition of the region $\zR$.
With the choices \eqref{eq:condition1} and \eqref{eq:condition2}, 
we obtain
\begin{eqnarray}
T_{\text{SSQW}} &= &\OOt{V^{6/5}} \nonumber \\
& = & \OOt{ 2^{\frac{3}{10}(R+\lambda)H_2\left( \frac{\pi}{R+\lambda} \right)n}}\label{eq:TSSQW}
\end{eqnarray}
Substituting for $P_{\text{SSQW}}$ and $T_{\text{SSQW}}$ the expressions given by \eqref{eq:PSSQW} and \eqref{eq:TSSQW} finishes the proof of the
theorem. $~\qed$
\end{proof}

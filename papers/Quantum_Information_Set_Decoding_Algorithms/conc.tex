\section{Computing the complexity exponents	}
We used the software SageMath to numerically find the minima giving the complexity exponents in Theorems
\ref{th:expSSQW} and \ref{th:expMMTQWdiese} using golden section search and a recursive version thereof for two parameters.
We compare in Figure \ref{fig:complexities} the exponents $\alpha_{\text{Bernstein}}(R,\omega_{\text{GV}})$, $\alpha_{SSQW}(R,\omega_{\text{GV}})$ 
and $\alpha_{MMTQW}(R,\omega_{\text{GV}})$ that we have obtained with our approach. It can be observed that there is some improvement upon 
$\alpha_{\text{Bernstein}}$ with both algorithms especially in the range of rates between 0.3 and 0.7.
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.6\textwidth]{courbes_text.png}
    \caption{$\alpha_{\text{Bernstein}}$ in green, $\alpha_{SSQW}$ in pink, $\alpha_{MMTQW}$ in grey. \label{fig:complexities}}
    \label{fig:courbes}
\end{figure}
\section{Concluding remarks}
One may wonder why our best algorithm is a version of MMT's algorithm  and not BJMM's algorithm or May and Ozerov's algorithm. We did try to quantise BJMM's algorithm, but it turned out to have worse time complexity than MMT's algorithm (for more details, see \cite{K16}). 
This seems to be due to space complexity constraints. Space complexity is indeed a lower bound on the quantum complexity of the algorithm. It has actually   been shown \cite[Chap. 10, Sec. 3]{B12} that BJMM's algorithm uses more space than MMT's algorithm, even when it is optimised to use the least amount of space. Moreover, it is rather insightful that in all cases, the best quantum algorithms that we have obtained here are not direct quantised versions of the original Dumer or MMT's algorithms but quantised versions of modified versions of these algorithms that use less memory than the original
algorithms.

The case of the May and Ozerov algorithm is also intriguing. Again the large space complexity of the original version of this algorithm makes it a very challenging task to obtain a ``good'' quantised version of it.

Finally, it should be noticed that while sophisticated techniques such as MMT, BJMM \cite{MMT11,BJMM12} or May and Ozerov \cite{MO15} have managed to improve rather significantly upon the most naive ISD algorithm, namely Prange's algorithm \cite{P62}, the improvement that we obtain with more sophisticated techniques is much more modest when we consider our improvements of the quantised version of the Prange algorithm \cite{B10}. Moreover, the improvements we obtain on the exponent $\alpha_{\text{Bernstein}}(R,\omega)$ are smaller when $\omega$ is smaller than $\omega_{\text{GV}}$. Considering the techniques for proving that the exponent of classical ISD algorithms goes to the Prange exponent when the 
relative error weight goes to $0$ \cite{CS16}, we conjecture that it should be possible to prove that we actually have $\lim_{\omega \rightarrow 0^+} \frac{\alpha_{\text{MMTQW}}(R,\omega)}{\alpha_{\text{Bernstein}}(R,\omega)} = 1$.


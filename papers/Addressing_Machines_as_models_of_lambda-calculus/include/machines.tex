% !TEX root = ../DPIM.tex
% !TEX spellcheck = en-US

In this section we introduce the notion of an \emph{Addressing Machine}.
We first provide some intuitions, then we proceed with the formal description of such machines.
The general structure of an addressing machine is composed by two substructures:
\begin{itemize}
\item the \emph{internal components}, organized as follows:
	\begin{itemize}
	\item a finite number of \emph{internal registers};
	\item an \emph{internal program}.
\end{itemize}
\item the \emph{input-tape}.
\end{itemize}
As the name suggests, the addressing mechanism is central in this formalism.
Each addressing machine is associated with an address, receives a list of addresses in its input-tape and is able to transfer the computation to another machine by calling its address, possibly extending its input-tape.

\subsection{Tapes, Registers and Programs}
We consider fixed a countable set $\Addrs$ of \emph{addresses}, together with a constant $\Null\notin\Addrs$ that we call ``null'' and that corresponds to an uninitialized register.
\begin{defi} We let $\Addrs_\Null = \Addrs\cup\set{\Null}$.
\bsub
\item
	An \emph{$\Addrs$-valued tape} $T$ is a finite (possibly empty) ordered list of addresses $T = [a_1,\dots,a_n]$ with $a_i\in\Addrs$ for all $i \le n$.
	We write $\Tapes$ for the set of all $\Addrs$-valued tapes.
\item
	 Let $a\in\Addrs$ and $T,T'\in\Tapes$. We denote by $\Cons a {T}$ the tape having $a$ as first element and $T$ as tail. We write $\appT{T}{T'}$ for the concatenation of $T$ and $T'$, which is an $\Addrs$-valued tape itself.

\item
	Given an index $i\in\nat$, an $\Addrs_\Null$-valued \emph{register} $R_i$ is a memory-cell capable of storing either $\Null$ or an address $a\in\Addrs$.
 \item Given $\Addrs_\Null$-valued registers $R_0,\dots,R_{n}$ for $n\ge 0$, an address $a\in\Addrs$ and an index $i\in\nat$, we write $\vec R\repl{R_i}{a}$ for the registers $\vec R$ where the value of $R_i$ has been updated:
 \[
 R_0,\dots,R_{i-1},a,R_{i+1},\dots,R_{n}
 \]
Notice that, whenever $i > n$, we assume that $\vec R\repl{R_i}{a} = \vec R$.
\esub
\end{defi}

\noindent
Addressing machines can be seen as having a RISC architecture, since their internal program is composed by only three instructions. We describe the effects of these basic operations on a machine having $r$ internal registers $R_0,\dots,R_{r-1}$.
Therefore, when we say ``if an internal register $R_i$ exists'' we mean that the condition $0\le i< r$ is satisfied.
In the following, $i,j,k\in\nat$ correspond to indices of internal registers:
	\begin{itemize}
	\item $\Load i$: corresponds to the action of reading the first element $a$ from the input-tape $T$, and writing $a$ on the internal register $R_i$. If the input-tape is empty then the machine remains stuck waiting for an input (however, this is not considered as an error state).\\[3pt]
The \emph{precondition} to execute the operation is that the input-tape is non-empty, namely $T = \Cons a T'$; the \emph{postconditions} are that $R_i$, if it exists, contains the address $a$ and the input-tape of the machine becomes $T'$.
	If $R_i$ does not exist, i.e.\ when $i\ge r$, the content of $\vec R$ remains unchanged (i.e., the input element $a$ is read and subsequently thrown away).
	\item $\Apply i j k$: corresponds to the action of reading the contents of $R_i$ and $R_j$, calling an external \emph{application map} on the corresponding addresses $a_1,a_2$, and writing the result in the internal register $R_k$, if it exists.\\[3pt]
The \emph{precondition} is that $R_i,R_j$ exist and are initialized, i.e.\ $R_i,R_j\neq\Null$.
The \emph{postcondition} is that $R_k$, if it exists, contains the address of the machine of address $a_1$ whose input-tape has been extended with $a_2$.
Otherwise the content of $\vec R$ remains unchanged.
	\item
	$\Call i$: transfers the computation to the machine whose address is stored in $R_i$, extending its input-tape with the addresses that are left in $T$.\\[3pt]
	The \emph{precondition} is that $R_i$ exists and is initialized.
	The \emph{postcondition} is that the machine having the address stored in $R_i$ is executed on the extended input-tape.
	\end{itemize}

\noindent
We define what is a syntactically valid program of this language, and  introduce a decision procedure for verifying that the preconditions of each instruction are satisfied when it is executed.
As we will see in Lemma~\ref{lem:correction}, these properties are decidable and statically verifiable.
As a consequence, addressing machines will never give rise to an error at run-time.

\begin{defi}\label{def:progs}\
\bsub
\item\label{def:progs1}
	A \emph{program} $P$ is a finite list of instructions generated by the following grammar (where $\varepsilon$ represents the empty string, and $i,j,k\in\nat$):
	\[
	\begin{array}{lcl}
	\ins{P}&\eqbnf&\Load i;\, \ins{P}\mid \ins{A}\\
	\ins{A}&\eqbnf&\Apply ijk;\, \ins{A}\mid \ins{C}\\
	\ins{C}&\eqbnf&\Call i \mid \varepsilon
	\end{array}
	\]
	In other words a program starts with a list of $\ins{Load}$'s, continues with a list of $\ins{App}$'s and possibly ends with a $\ins{Call}$. Each of these lists may be empty, in particular the empty-program $\varepsilon$ can be generated.
\item\label{def:progs2}
	Given a program $P$, an $r\in\nat$, and a set $\cI\subseteq \set{0,\dots,r-1}$ of indices (representing initialized registers), define $\cI\models^{r} P$ as the least relation closed under the rules:
\[
	\begin{array}{ccccc}
		\infer{\cI\models^{r}\varepsilon}{}
		&&
		\infer{\cI\models^{r} \Apply ijk;\, \ins{A}}{\cI\cup\set{k}\models^{r}  \ins{A} & i,j\in \cI & k<r}
		&&
		\infer{\cI\models^{r} \Load i;\, \ins{P}}{\cI\cup\set{i}\models^{r}  \ins{P} & i< r}
		\\[3pt]
		\infer{\cI\models^{r}\Call i}{i\in \cI}&&
		\infer{\cI\models^{r} \Apply ijk;\, \ins{A}}{\cI\models^{r}  \ins{A} & i,j\in \cI & k\ge r}
		&&
		\infer{\cI\models^{r} \Load i;\, \ins{P}}{\cI\models^{r}  \ins{P} & i \ge r}
	\end{array}
\]
\item Let $r\in\nat$ and $\vec R = R_0,\dots,R_{r-1}$ be $\Addrs_\Null$-valued registers.
	We say that a program $P$ is \emph{valid with respect to $\vec R$} whenever $\cR\models^{r} P$ holds for
	\begin{equation}\label{eq:R}
		\cR = \set {i\st R_i \neq\Null \und 0\le i < r}
	\end{equation}
\esub
\end{defi}

\noindent
Notice that the notion of a valid program is independent from the tape of a machine.

\begin{exas} Consider addresses $a_1, a_2\in\Addrs $, as well as $\Addrs_\Null$-valued registers $R_0 = \Null$, $R_1 = a_1,R_2=a_2,R_3 = \Null$ (so $r = 4$).
In this example, the set $\cR$ of initialized registers as defined in~\eqref{eq:R} is $\cR = \set{1,2}$.
\[
	\begin{array}{lcc}
	P_n&\textrm{Program}&\cR\models^4 P_n\\
	\toprule
	P_0=&\Load 0;\Apply012;\Call 2&\checkmark\\
	P_1=&\Apply 120;\,\Apply 023;\,\Call 3&\checkmark\\
	P_2=&\Load 5;\, \Load 0;\,\Call 0&\checkmark\\
	P_3=&\Load 5;\, \Apply 12{5};\,\Call 2&\checkmark\\
	P_4=&\Apply 012;\,\Call 2&\xmark\\
	P_5=&\Load 0;\,\Call 3&\xmark\\
	P_6=&\Apply 123;\,\Call 5&\xmark\\
	\end{array}
\]
Above we use ``5'' as an index of an unexisting register.
Notice that a program trying to update an unexisting register remains valid (see $P_2,P_3$), the new value is simply discharged.
On the contrary, an attempt at reading the content of an uninitialized ($P_4,P_5$) or unexisting ($P_6$) register invalidates the whole program.
\end{exas}

\begin{nota}\label{nota:aboutprogs}
We use ``$-$'' to indicate an arbitrary index of an unexisting   register. E.g., the program $P_6$ will be written $\Apply 123;\,\Call -$.
We also write $\Load (i_1,\dots,i_k)$ as an abbreviation for $\Load i_1;\,\cdots;\,\Load i_k;$ . By employing all these notations, $P_2$ can be written as  $P_2= \Load (-,0);\Call 0$. % chktex 40 chktex 26
\end{nota}

\begin{lem}\label{lem:correction}
For all $\Addrs_\Null$-valued registers $\vec R$ and program $P$ it is decidable whether $P$ is valid with respect to $\vec R$.
\end{lem}

\begin{proof}
Decidability follows from the fact that the grammar in Definition~\ref{def:progs}\ref{def:progs1} is right-linear, the list of registers $\vec R$ is finite, the rules in Definition~\ref{def:progs}\ref{def:progs2} are syntax-directed and their side conditions are decidable.
%First, notice that the grammar in Definition~\ref{def:progs}\ref{def:progs1} is right-linear, therefore it is decidable whether $P$ is a production.
%Also, $r\in\nat$ therefore $\cR$ is finite and, since $P$ is also finite, the set $\cR$ remains finite during the execution of $\cR\models^{r} P$.
%Decidability follows from these properties, together with the fact that the first instruction of $P$ uniquely determines which rule from Definition~\ref{def:progs}\ref{def:progs2} should be applied (and these rules are exhaustive).
\end{proof}

\subsection{Addressing machines and their operational semantics}

Everything is in place to introduce the definition of an \am.
Thanks to Lemma~\ref{lem:correction} it is reasonable to require that an \am{} has a valid internal program.

\begin{defi}\label{def:AM}
\bsub
\item
	An \emph{addressing machine $\mM$ (with $r$ registers) over $\Addrs$} is given by a tuple:
\[
	\mM = \tuple{\vec R,P,T}
\] where:
\begin{itemize}
\item
	$\vec R = R_0,\dots,R_{r-1}$ are $\Addrs_\Null$-valued registers;
\item
	$P$ is a program valid w.r.t.\ $\vec R$;
\item
	$T$ is an $\Addrs$-valued \emph{(input) tape}.
\end{itemize}
\item
	We write $\mM.r$ for the number of registers of $\mM$, $\mM.\vec R$ for the list of its registers, $\mM.R_i$ for its $i$-th register, $\mM.P$ for the associated program and finally $\mM.T$ for its input tape.
\item
	We say that an addressing machine $\mM$ as above is \emph{stuck}, in symbols $\stuck{\mM}$, whenever its program has shape $\mM.P = \Load i;\ins{P}$ but its input-tape is empty $\mM.T = []$. Otherwise, $\mM$ is \emph{not stuck}, in symbols: $\lnot\stuck{\mM}$.
\item
	The set of all addressing machines over $\Addrs$ will be denoted by $\cM$.
\esub
\end{defi}

\noindent
The machines below will be used as running examples in the next sections.
Intuitively, the \am s $\mK,\mS,\mach{I},\mach{D},\mach{O}$ mimic the behavior of the \lam-terms $\comb{K}$, $\comb{S}$, $\comb{I}$, $\comb{\Delta}$ and $\comb{\Omega}$, respectively. For writing their programs, we adopt the conventions introduced in Notation~\ref{nota:aboutprogs}.

\begin{exas}\label{ex:ilprimoesempiononsiscordamai}
The following are addressing machines.
\bsub
\item\label{ex:ilprimoesempiononsiscordamai1}
	For every $n\in\nat$, define an addressing machine with $n+1$ registers as:
\[
	\mach{x}_n = \tuple{R_0,\dots,R_n,\varepsilon,[]},\textrm{ where }\vec R := \vec \Null.
\]
We call $\mach{x}_0,\mach{x}_1,\mach{x}_2,\dots$ \emph{indeterminate machines} because they share some analogies with variables (they can be used as place holders).
\item
The addressing machine $\mK$ with 1 register $R_0$ is defined by:
\[
	\mK = \tuple{\Null,\RaS (0,-); \Call 0,[]}
\]
\item The addressing machine $\mS$ with 3 registers is defined by:
\[
	\begin{array}{lcl}
	\mS &=& \tuple{\Null,\Null,\Null,P,[]}\textrm{, where:}\\
	\mS.P &=& \RaS (0, 1,2);\,\Apply 020;\\
	&&\Apply 121;\,\Apply 012;\,\Call 2\\
	\end{array}
\]
\item Assume that $k\in\Addrs$ represents the address associated with the \am{} $\mK$.
Define the \am{} $\mach{I}$ as $\mach{I} = \tuple{\Null^3,\mS.P,[k,k]}$.
\item The addressing machine $\mach{D}$ with 1 register is given by:
\[
	\mach{D} = \tuple{\Null,\RaS 0;\,\Apply 000;\,\Call 0,[]}
\]
\item Assume that $d\in\Addrs$ represents the address of the \am{} $\mach{D}$.
Define the \am{} $\mach{O}$ by setting $\mach{O} = \tuple{\Null,\mach{D}.P,[d]}$.
\esub
\end{exas}

\noindent
We now enter into the details of the addressing mechanism which constitutes the core of this formalism.
In an implementation of \am s, it would be reasonable to pick up a fresh address from $\Addrs$ whenever a new machine is constructed and save the correspondence in some address table. See Section~\ref{sec:conclusions} for more implementation details.
To construct a \lam-model, we need a uniform way of associating machines with their addresses.

\begin{defi} Fix a bijective map $\Lookup : \cM \to  \Addrs$ from the set of all \am s over $\Addrs$ to the set $\Addrs$ of addresses.
We call the map $\Lookup(\cdot)$ an \emph{Address Table Map (ATM)}.
\bsub
\item Given $M\in\cM$, we say that $\Lookup \mM$ is the \emph{address of} $\mM$.
\item
	Given an address $a\in\Addrs$, we write $\Lookinv{a}$ for the unique machine having address $a$. In other words, we have $\Lookinv{a} = \mM\iff \Lookup\mM = a$.
\item
	Given $\mM\in\cM$ and $T'\in\Tapes$, we write $\appT{\mM}{T'}$ for the machine
	\[
		\tuple{\mM.\vec R,\mM.P,\appT{\mM.T}{T'}}
	\]
\item
	Define the \emph{application map} $(\App{}{}) : \Addrs\times\Addrs\to \Addrs$ as follows
	\[
		\App{a}{b} = \Lookup (\append{\Lookinv{a}}{b})
	\]
	That is, the \emph{application} of $a$ to $b$ is the unique address $c$ of the \am{} obtained by adding $b$ at the end of the input tape of the \am{} $\Lookinv{a}$.
\esub
\end{defi}

\noindent
Since both $\cM$ and $\Addrs$ are countable sets, there exist $2^{\aleph_0}$ possible choices for an ATM\@.
\begin{rem}\label{rem:forever} Depending on the chosen ATM $\Lookup(-)$, there might exist \am s calling each other, as in $\mM = \tuple{\Lookup\mN,\Call 0,[]}$ and $\mN = \tuple{\Lookup\mM,\Call 0,[]}$, or even countably many machines $(\mM_n)_{n\in\nat}$ satisfying $\mM_n = \tuple{\Lookup\mM_{n+1},\varepsilon,[]}$.
Therefore, in general, the process of recursively dereferencing the addresses stored in the registers (or tape) of a machine might not terminate.
This kind of behaviour is not pathological, rather intrinsic to the notions of addresses and dereference operators.
\end{rem}
In practice, one may desire to work with an ATM performing the association between \am s and their addresses in a computable way.
However, we do not require our ATMs to satisfy any effectiveness conditions since it would be peculiar to propose a model of computation depending on a pre-existing notion of ``computable''. The results presented in this paper are independent from the ATM  under consideration.

\begin{defi}[Small step operational semantics]\label{def:smallstep}
Define a reduction strategy on \am s representing one head-step of computation
\[
	\redh\ \subseteq\cM\to\cM
\]
as the least relation closed under the following rules:
\[
	\begin{array}{lcl}
	\tuple{\vec R,\RaS i;P,\Cons a{T}} &\redh& \tuple{\vec R[R_i := a],P,T},\\
	\tuple{\vec R,\Apply i j k; P,T}&\redh&\tuple{\vec R[R_k := \App{R_i}{R_j}],P,T},\\
	\tuple{\vec R,\Call i,T}&\redh&\appT{\Lookinv {R_i}}{T}.\\
	\end{array}
\]
As usual, we write $\reddh$ for the transitive-reflexive closure of $\redh$.
We say that an \am{} $\mM$ \emph{is in a final state} if there is no $\mN$ such that $\mM\redh \mN$.
We write $\mM\reddh \stuck{\mN}$ whenever $\mM\reddh \mN$ and $\stuck{\mN}$ hold.
When $\mN$ is not important, we simply write $\mM\reddh\stuck{}$. Similarly, $\mM\not\reddh\stuck{}$ means that $\mM$ never reduces to a stuck \am.
\end{defi}

\begin{rem}\label{rem:aboutstuck}\
\bsub
\item Definition~\ref{def:smallstep} is well defined since the validity of a program is preserved by ${\sf h}$-reduction: if $\mM\redh\mN$ and $\mM.P$ is valid w.r.t.\ $\mM.\vec R$ then $\mN.P$ is valid w.r.t.\ $\mN.\vec R$. This follows immediately from Definition~\ref{def:progs}\ref{def:progs2}.
In particular when executing $\RaS i$, or $\Call i$, $R_i$ must be initialized and when executing $\Apply i j k$ we must have $R_i,R_j\neq\Null$.
\item\label{rem:aboutstuck2}
Addressing machines in a final state are either of the form $\tuple{\vec R,\varepsilon,T}$ or $\tuple{\vec R,\Load i;P,[]}$, and in the latter case they are stuck.
\esub
\end{rem}

\begin{lem}\label{lem:about_red}
The reduction strategy $\redh$ enjoys the following properties:
\bsub
\item\label{lem:about_red1}
	 Determinism: $\mM\redh \mN_1 \und \mM\redh \mN_2\ \Rightarrow\ \mN_1 = \mN_2$.
\item\label{lem:about_red2}
	Closure under application: $\forall a\in\Addrs\,.\,\mM\redh \mN\ \Rightarrow\ \append{\mM}{a}\redh \append{\mN}{a}$.
\esub
\end{lem}
\begin{proof} $(i)$ Since the applicable rule from Definition~\ref{def:smallstep}, if any, is uniquely determined by the first instruction on $\mM.P$ and its input-tape $\mM.T$.

$(ii)$ Easy. By cases on the rule applied for deriving $\mM\redh\mN$.
\end{proof}

\begin{exas}\label{ex:somemachines}
For brevity, we sometimes display only the first instruction of the internal program. Take $a,b,c\in\Addrs$.
\bsub
\item We show that $\mach K$ behaves as the first projection:
\[
	\begin{array}{lll}
	\append{\mK}{a,b}&=&\tuple{\Null,\RaS (0, -); \Call 0,[a,b]}\\
	&\redh&\tuple{a, \RaS -; \Call 0,[b]}
	\redh
	\tuple{a, \Call 0,[]}\redh\Lookinv a.\\
	\end{array}
\]
\item We verify that $\mach S$ behaves as the combinator $\comb{S}$ from combinatory logic:
\[
	\begin{array}{lll}
	\append{\mS}{a,b,c}&=&\tuple{\Null^3,\RaS (0,1,2); \cdots,[a,b,c]}\\
	&\reddh&\tuple{a,b,c,\Apply 020; \cdots,[]}\\
	&\redh&\tuple{\App{a}{c},b,c,\Apply 121; \cdots,[]}\\
	&\redh&\tuple{\App{a}{c},\App{b}{c},c,\Apply 012; \cdots,[]}\\
	&\redh&\tuple{\App{a}{c},\App{b}{c},\App{(\App{a}{c})}{(\App{b}{c})},\Call 2; \cdots,[]}\\
	&\redh&\Lookinv {\App{(\App{a}{c})}{(\App{b}{c})}}\\
	\end{array}
\]
\item As expected, $\mach{I}=\append{\mS}{\Lookup \mK,\Lookup \mK}$ behaves as the identity:
\[
	\begin{array}{lll}
	\append{\mach{I}}{a} &=&
	\tuple{\Null^3,\RaS (0,1,2);\cdots,[\Lookup{\mK},\Lookup{\mK},a]}\\
	&\reddh&\tuple{\Lookup{\mK},\Lookup{\mK},a,\Apply 020;\cdots,[]}\\
	&\redh&\tuple{\App{\Lookup{\mK}}{a},\Lookup{\mK},a,\Apply 121;\cdots,[]}\\
	&\redh&\tuple{\App{\Lookup{\mK}}{a},\App{\Lookup{\mK}}{a},a,\Apply 012;\cdots,[]}\\
	&\redh&\tuple{\App{\Lookup{\mK}}{a},\App{\Lookup{\mK}}{a},\App{\App{\Lookup{\mK}}{a}}{(\App{\Lookup{\mK}}{a})},\Call 2;[]}\\
	&\redh&\append{\mK}{a,\App{\Lookup{\mK}}{a}}\\
	&=&\tuple{\Null,\RaS (0,-);\cdots,[a,\App{\Lookup{\mK}}{a}]}\\
	&\reddh&\tuple{a,\App{\Lookup{\mK}}{a},\Call 0,[]}
	\redh\Lookinv{a}\\
	\end{array}
\]
\item Finally, we check that $\mach{O}$ gives rise to an infinite reduction sequence:
\[
	\begin{array}{lll}
	\mach{O} &=& \tuple{\Null,\RaS 0;\,\Apply 000;\,\Call 0,[\Lookup\mach{D}]}\\
	&\redh&\tuple{\Lookup\mach{D},\Apply 000;\,\Call 0,[]}\\
	&\redh&\tuple{\Lookup(\append{\mach{D}}{\Lookup\mach{D}}),\Call 0,[]}\redh \append{\mach{D}}{\Lookup\mach{D}}
	= \mach{O}\reddh\cdots\\
	\end{array}
\]
\esub
\end{exas}

\noindent
Similarly, we can define a big-step operational semantics relating an \am{} $\mM$ with its final result (if any).

\begin{defi}[Big-step semantics]
Define $\mM \goesto \mach{V}$, where $\mM,\mV\in\cM$ and $\mV$ is in a final state, as the least relation closed under the following rules:
\begin{gather*}
	\infer[(\textrm{Stuck})]{\mM \goesto \mM}{
		\mM.P = \RaS i;P'
		&
		\mM.T = []
		}
	\qquad\qquad
	\infer[(\textrm{End})]{\mM \goesto \mM}{
		\mM.P = \varepsilon
		}\\
		\infer[(\textrm{Load})]{\mM \goesto \mV}{
		\mM.P = \RaS i;P'
		&
		\mM.T = \Cons a{T'}
		&
		\tuple{\mM.\vec R\repl{R_i}{a},P',T'}\goesto \mV
		}
		\\
		\infer[(\textrm{App})]{
		\mM\goesto\mV}{\mM.P = \Apply i j k; P'
		&
		a = \App{\mM.R_i}{\mM.R_j}
		&
		\tuple{\mM.\vec R\repl{R_k}{a},\mM.P',\mM.T}\goesto\mV
	}
	\\
		\infer[(\textrm{Call})]{\mM\goesto \mV}{
			\mM.P = \Call i
			&
			\mM' = \Lookup^{-1}(\mM.R_i)
			&
			\append{\mM'}{\mM.T}\goesto \mV
	}
\end{gather*}

\begin{exa} Recall that $\mK.P = \Load (0,-);\,\Call 0$. Notice that we cannot prove $\append{\mK}{a,b}\goesto \Lookinv a$ for an arbitrary $a\in\Addrs$, as we need to ensure that the resulting machine is in a final state.
For this reason, we will use indeterminate machines $\mach{x}_1,\mach{x}_2$ from Example~\ref{ex:ilprimoesempiononsiscordamai}\ref{ex:ilprimoesempiononsiscordamai1}.
\[
	\infer{\append{\mK}{\Lookup \mach{x}_1,\Lookup \mach{x}_2}\goesto \mach{x}_1}{
	\mK.P = \Load 0;\,P';
	&
	\infer{\tuple{\Lookup\mach{x}_1,P',[\Lookup\mach{x}_2]}\goesto \mach{x}_1}{
		P'= \Load -;P'' &
		\infer{\tuple{\Lookup\mach{x}_1,P'',[]}\goesto \mach{x}_1}{
				P''=\Call 0
				&
				R_0 = \Lookup\mach{x}_1
				&
				\infer{\mach{x}_1\goesto \mach{x}_1}{\textrm{(End)}}
		}
	}
	&
	}
\]
\end{exa}
\end{defi}

We now show that the two operational semantics are equivalent on terminating computations.

\begin{prop}\label{prop:equivsem}
For $\mM,\mN\in\cM$, the following are equivalent:
\begin{enumerate}
\item $\mM\reddh \mN\not\redh$;
\item $\mM\goesto\mN$.
\end{enumerate}
\end{prop}

\begin{proof}
(1 $\Rightarrow$ 2) By induction on the length $n$ of the reduction $\mM=\mM_1\redh\mM_2\redh\cdots\redh \mM_n=\mN\not\redh$.

Case $n = 0$. By assumption $\mN$ is in a final state. By Remark~\ref{rem:aboutstuck}\ref{rem:aboutstuck2}, it is either of the form $\mN = \tuple{\vec R,\varepsilon,T}$ or it is stuck $\mN = \tuple{\vec R,\Load i;P,[]}$. In the former case we apply (\textrm{End}), in the latter (\textrm{Stuck}).

Case $n > 1$. Since $\mM_1\redh \mM_2$, we have $\mM_1.P\neq\varepsilon$.
As the length of $\mM_2\reddh \mN$ is $n-1$, by induction hypothesis we have a derivation of $\mM_2\goesto \mN$.
Depending on the first instruction in $\mM_1.P$, we use this derivation to apply the homonymous rule (Load), (App) or (Call) and derive $\mM\goesto \mN$.

(2 $\Rightarrow$ 1) By induction on a derivation of $\mM\goesto \mN$.

Cases (Stuck) or (End). Then, $\mM\reddh\mM=\mN$ by reflexivity of $\reddh$.

Case (Load), i.e.\ $\mM.P=\Load i;P'$. In this case, we have that $\mM\redh \tuple{\mM.\vec R\repl{R_i}{a},P',\mM.T}\reddh \mN$, by induction hypothesis.

Case (App), i.e.\ $\mM.P=\Apply ijk;P'$. Let us call $a = \App{\mM.R_j}{\mM.R_k}$. Then we have $\mM\redh \tuple{\mM.\vec R\repl{R_k}{a},P',\mM.T}\reddh \mN$, by induction hypothesis.

Case (Call), i.e.\ $\mM.P = \Call i$. In this case $\mM\redh \append{\mM'}{\mM.T}$ for $\mM' = \Lookinv{\mM.R_i}$. By induction hypothesis $\append{\mM'}{\mM.T}\reddh \mN$, whence $\mM\reddh \mN$.
\end{proof}


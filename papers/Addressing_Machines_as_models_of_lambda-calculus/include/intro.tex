% !TEX root = ../DPIM.tex
% !TEX spellcheck = en-US
In theoretical computer science several models of computation have been considered over the years, since the pioneering work of Turing~\cite{Turing36}.
Turing Machines (TMs) certainly played a crucial role in the understanding of the notion of computation, while Register Machines (RMs) are more adapted to represent programs executed in a von Neumann architecture~\cite{Rogers67}.
From a recursion-theoretic perspective, the class of partial recursive functions provides a natural description of those numeric functions that can be calculated by a mechanical device~\cite{Kleene36}.
In mathematical logic, \lam-calculus~\cite{Bare} and the related formalism --- combinatory logic~\cite{CurryF58} --- proved to be an inexhaustible source of inspiration for the development of formal systems, proof assistants and functional programming languages. As it is well-known, the basic computational mechanism of \lam-calculus is the {\em symbolic substitution of an expression for a variable}.
All these formalisms --- and many others that have been subsequently introduced --- are quite different, but they can be proved equivalent in the sense that they are capable of representing the same class of partial numerical functions, i.e.\ the class of partial recursive functions.
Despite the enormous importance of this result --- in particular as a strong evidence for the so called Turing-Church Thesis --- it is still of great interest to understand, at a deeper level, the relationships between the different computational formalisms.

In particular, the relationship between \lam-calculus and partial recursive functions was investigated by Henk Barendregt, who tried to build during his PhD a model of untyped \lam-calculus (\lam-model~\cite{Koymans82,Meyer82}) out of Kleene's partial combinatory algebra having the set of ``codes'' $\nat$ as underlying set and as application the partial operator $\{x\}(y)$, that can be interpreted as the possible result of applying the partial computable function with code $x$ to the input~$y$.
His intention was to use this binary operator $\{\cdot\}(\cdot)$ to construct a (total) combinatory algebra in such a way that Kleene's translation of \lam-calculus results would become a simple model-theoretic interpretation. It is important to observe that a direct approach cannot work, as recursive functions implicitly use the classic computational model, which requires that a function is \emph{strict} on its arguments, that is, the function is undefined whenever any of its arguments is undefined. On the other hand, both \lam-calculus and combinatory logic allow the representation of non-strict functions such as the combinator~$\comb{K}$.

Barendregt has set up several sophisticated constructions, but a definite solution is still missing.
The problem is nowadays receiving the attention of the scientific community because of the recent republication of his PhD thesis~\cite{BarendregtTh}, extended with commentaries.
On the bright side, these investigations led to the formulation of the famous $\omega$-rule because --- if such a \lam-model exists --- then it needs to satisfy this strong extensionality axiom.

Following the same line of research, but attacking the problem from a different angle, one might meaningfully wonder whether it is possible to construct a \lam-model based on appropriate abstract machines. The most obvious and canonical choice would be considering Turing Machines, but such an attempt has the same problem as the one encountered with recursive function, since TMs are strict on their arguments.
%In fact, while one can easily encode a TM within \lam-calculus~\cite{DalLagoA17}, for establishing the Turing-completeness of \lam-calculus it is preferable to show that all computable numeric functions are \lam-definable, rather than looking for faithful translation.
%The first problem that arises is how to handle non-terminating computations since the application in a \lam-model must be total.
A second problem is how to represent higher-order computations: in an imperative programming language a function can take another function as argument by working with its address, but in a TM this would require to encode processes as data and then manipulate and execute such codes indirectly. This makes the simple, intuitive notion of communication through addresses  extremely difficult to realize.
To this day, no \lam-model of this kind has ever been constructed.

In this article we define a class of abstract machines, where the notions of  address and communication (through addresses) are not only crucial to model computation, but they become the unique ingredients available.
These machines are called \emph{addressing machines} and possess a finite tape from which they can read the input, some internal registers where they can store values read from the tape, and an internal program which is composed by a  list of instructions that are executed sequentially.
The input-tape and the internal registers are reminiscent of those in TMs and RMs, respectively.
Every machine is uniquely identified by its address, which is a value taken from a fixed countable set $\Addrs$. In this formalism, addresses are the only available data-type --- this means that both the input-tape and the internal registers of a machine (once initialized) contain addresses from $\Addrs$.
Programs are written in an assembly language possessing only three instructions\footnote{This choice is made on purpose, in the attempt of determining the minimum amount of operations giving rise to a Turing-complete formalism.}.
Besides reading its inputs, an \am{} can apply two addresses $a,b$ with each other and store the resulting address $a\cdot b$ in an internal register.
Intuitively, $a\cdot b$ is obtained by first taking the machine $\mach{M}$ having address $a$, then appending $b$ to its input-tape, and finally calculating the address of this new machine.
This application operation being static and manipulating addresses exclusively is \emph{total} even when the referenced machines are non-terminating once executed.
As a last step of its execution, an addressing machine can transfer the computation to another machine, possibly extending its input-tape, by retrieving its address from a register.
Although not crucial in the abstract definition of an addressing machine, it should be clear at this point that any implementation of this formalism requires the association between the machines and their addresses to be effective (see Section~\ref{sec:conclusions} for more details).



Addressing machines share with \lam-calculus the fact that there is no fundamental distinction between processes and data-types: in order to perform calculations on natural numbers a machine needs to manipulate the addresses of the corresponding numerals.
Another similarity is the fact that in both settings communication is achieved by transferring the computation from one entity to another one.
In the case of \am s, the machine currently ``in execution'' transfers the control by calling the address of another machine. In \lam-calculus, the subterm ``in charge'' is the one occupying the so-called ``head position'' and the control of the computation is transferred when the head variable is substituted by another term.
It is worth noting that process calculi such as the $\pi$-calculus also address communication using the concept of channel, where messages are exchanged~\cite{Milner99,Sangiorgi01}. This is not the kind of communication that we are going to model here: our form of communication is encoded in the notion of address, so that a machine receiving a message results in a new machine with a different address. In other words, we do not model the dynamics of the communication, but the evolution of the machine addresses actually encodes the effects of communication.
Another difference is the fact that $\pi$-calculus naturally models parallel computations as well as concurrency, while \am s are designed for representing sequential computations (one machine at a time is executed).

\paragraph{Contents.} The aim of the paper is twofold.
On the one side we want to present the class of \am s and analyze their fundamental properties. This is done in Section~\ref{sec:machines}, where we describe their  operational semantics in two different styles: as a term rewriting system (small-step semantics) and as a set of inference rules (big-step semantics). The two approaches are shown to be equivalent in case of addressing machines executing a terminating program (Proposition~\ref{prop:equivsem}).
On the other side, we wish to construct a model of the untyped \lam-calculus based on \am s, and study the interpretations of \lam-terms.
For this reason, we recall in the preliminary Section~\ref{sec:pre} the main facts about \lam-calculus, its equational theories and denotational models.
It turns out that the set $\Addrs$ of addresses, together with the operation of application previously described, is not a combinatory algebra (nor, \emph{a fortiori}, a \lam-model). In Section~\ref{sec:combalg} we show that it can be turned into a combinatory algebra by quotienting under an equivalence relation arising naturally from our small-step operational semantics. Two addresses are equivalent if the corresponding machines are interconvertible using a more liberal rewriting relation. From the confluence property enjoyed by this relation, we infer the consistency of the algebra (Proposition~\ref{prop:cAisnonextcombal}).
Unfortunately, the combinatory algebra so-obtained is not yet a model of \lam-calculus --- there are still $\beta$-convertible \lam-terms having different interpretations. % (the counter-example is the same used for proving that the term model of combinatory logic is not a \lam-model).
Section~\ref{sec:consistency} is devoted to showing that a \lam-model actually arises when adding to the system a mild form of extensionality sharing similarities both with the $\omega$-rule in \lam-calculus~\cite{BarendregtTh} and with the rule $\zeta_\beta$ from combinatory logic~\cite{HindleyS86}. The consistency of the model follows from an analysis of the underlying ordinal.
Interestingly, the model itself is not extensional (Theorem~\ref{thm:Sinsonoextslm}).



\paragraph{Related works.} A preliminary version of \am s appeared in Della Penna's MSc thesis~\cite{DellaPennaTh}.
Other abstract machines having similar primitive instructions are present in the literature, but they were studied from the perspective of functional programs implementation,
see e.g.~\cite{FairbairnW87}. We do not claim that addressing machines are innovative, the originality of our work relies on the construction of a \lam-model (Section~\ref{sec:consistency}) and its analysis.
The practice of associating an address to a term is also well-established in the implementation of functional programming languages, and can be seen as the practical counterpart of explicit substitutions~\cite{LevyM99,BlancLM05,AccattoliCGC19}. The relationship between our \am s and explicit substitutions will be discussed  in Section~\ref{sec:conclusions}.

\clearpage
\appendix

\section{Appendix}
% \subsection{Edges Types in Inter-turn Module}\label{ap:graph}
% We follow \citet{lee2021graph} to establish four different types of edges in graph $\mathcal{G}$: Dialogue edge, to learn global information across the whole dialogue, all turn nodes are connected to the dialogue node; Speaker edge, every pair of turn nodes belongs to the same speaker are connected; Entity edge, an argument node is connected to a turn node if it is mentioned in this turn. To enable the model to directly learn the sequence information, every pair of turn nodes in a graph is connected via sequence edge. 
% \subsection{Experimental Setups}\label{ap:exp_setups}
\subsection{Datasets and Metrics}\label{ap:exp_setups}
%dialogue task分四种， intent prediction, slot-filling, semantic parsing, and dialogue state tracking. 然后我们完成的数据集任务是relation extraction, emotional recognition, speech act classification，不太确定是不是都能解决

\textbf{DialogRE} \citep{yu-etal-2020-dialogue} is a relation extraction task based on 1,788 dialogues from the Friends transcript. Each pair of arguments can be classified as one of 36 possible relation types. For each of the 10,168 human-annotated entity pairs, the trigger words are also provided. % such as neighbours or siblings. (subject, object, relation type) triplets

\textbf{EmoryNLP} \citep{zahiri:18a} is an emotion detection task based on 12,606 utterances from the Friends transcript. Each utterance can be classified as one of seven emotions, e.g., joyful, scared. 
%The label is human-annotated based on the dialogue context. 

\textbf{DailyDialog} \citep{DailyDialog} is a dialogue database containing 13,118 simple English dialogues. Each utterance can be assigned an emotion label from seven categories (anger, surprise, etc.). 
%targets both emotion detection and act classification. DailyDialog The label is human-annotated based on the dialogue context.  (Inform, Questions, Directives, Commissive) 

\textbf{MELD} \citep{poria-etal-2019-meld} is an emotion detection task based on 13,000 sentences from the Friends transcript. Each utterance can be classified as one of eight emotions, such as sad, disgust. % or neutral. 

%The label is human-annotated based on the multimodal cues of the dialogue, including visual, audio and textual information. 

\textbf{MRDA} \citep{MRDA} is a dialogue act task based on 75 hours of real-life meeting transcript. Each sentence is assigned a general dialogue act (topic change, repeat, etc.) and a specific dialogue act (apology, suggestion, etc.).  % explanation sympathy

\textbf{Metrics}. For DialogRE, F1 and F1$_c$ are used as evaluation metrics. F1$_c$ modifies F1 by taking an early part of the dialogue as input \cite{yu-etal-2020-dialogue}. For MELD and EmoryNLP, we use weighted-F1 as metrics. For DailyDialog, the Micro-F1 score excluding the neutral class is used as the metric. 

% \subsubsection{Hyperparameters}


% \subsection{Ablation Study and Analysis}\label{ap:ablation}
% \begin{wraptable}{r}{7cm}
% \vspace{-0.5cm}
% \begin{center}

% \begin{tabular}{l c c} 
%  \toprule
%   {\textbf{Method}} & \textbf{F1} & \textbf{F1$_c$} \\
%  \midrule
% HiDialog                      & 77.1        & 68.2       \\ 
% w/o attention mask & 76.5 (-0.6) & 67.9 (-0.3) \\
% w/o special tokens & 75.6 (-1.5) & 67.4 (-0.8) \\
% only intra-turn     & 74.4 (-2.7) & 66.6 (-1.6) \\
% \bottomrule
% \end{tabular}
% \end{center}
% \vspace{-0.2cm}
% \caption{Ablation Study on HiDialog components on DialogRE to evaluate the individual effect of turn-level attention, turn-level special tokens, and graph module. } %\textit{Ablation study. Turn-level} is omitted for brevity.}
% \label{tab:ablation_structure}
% \vspace{-0.2cm}
% \end{wraptable}

% \textbf{Ablation study on components.} We conduct an ablation study on DialogRE to evaluate the effectiveness of critical components in our method: turn-level attention, turn-level special tokens, and graph module. The results are reported in Table \ref{tab:ablation_structure}. First, we remove the turn-level attention mask. It can be observed that performance slightly drops. The inserted turn-level special tokens function as normal separators after the mask has been removed. Thus, these special tokens are able to aggregate information from the entire sequence, thus they are not context-aware at the turn level. Second, we remove the turn-level attention along with turn-level special tokens. The only difference between our final model and the ablated one is in how we initialize the node embedding of the graph module, that is, in this experiment, we average corresponding tokens for the initialization. The $F1$ score decreases by 1.5\% and the $F1_c$ score declines by 0.8\%, which indicates the turn-level attention is effective. 

% \begin{wraptable}{r}{7cm}
% \setlength{\tabcolsep}{9pt}
% \begin{center}
% \vspace{-0.5cm}
% \begin{tabular}{lccc} 
% \toprule
% \textbf{Method} & \textbf{I} &  \textbf{II} &  \textbf{III}\\
% \midrule
% BERT & 42.5  & 60.7 & 65.6 \\
% % BERT$_s$ & 46.5 & 61.5 & 69.4 \\
% GDPNet  & 47.4  &59.8  &68.1 \\
% RoBERTa$_s$ & 57.4 & 69.3 & 79.6 \\
% TUCORE-GCN  &62.3  &\textbf{71.3}  &79.9 \\
% \midrule
% HiDialog & \textbf{76.6}  & 70.5	& \textbf{80.9}  \\
% w/o graph module &65.5 & 69.9 & 79.4\\
% \bottomrule
% \end{tabular}
% \end{center}
% \vspace{-0.3cm}
% \caption{All methods performance on Dialogue Relation Extraction task using DialogRE dataset. Specifically, we break down the performance into three groups (I) asymmetric inverse relations, (II) symmetric inverse relations, and (III) others.}
% \label{tab:symmetric}
% \end{wraptable}
% \textbf{Analysis of relations}. We grouped the test set of DialogRE according to the relation types into three subsets: (I) asymmetric, when a relation type differs from its inversion (e.g. \textit{children} and \textit{parents});  (II) symmetric, when a relation type is the same as its inversion (e.g. \textit{spouse}); (III) other, when a relation type does not have inversion (e.g. \textit{age}). We compared the performance of our model with baselines and report the results in Table \ref{tab:symmetric}. As we can observe, there is a great performance increase in the asymmetric subset while the F1 score drops moderately for symmetric relations. This trend reverses when we remove the graph module in our method (i.e. symmetric $>$ asymmetric). 
% % \clearpage

% \textbf{Analysis of robustness against increasing utterance length.} With the hierarchical aggregation in HiDialog, each turn-level special token is enforced to capture intra-turn critical information regardless of the whole dialogue. This nature enables our method to handle dialogues of various lengths. Motivated by it, we further divide the samples in the DialogRE test set into six groups according to their lengths and report the F1 score for each group achieved by our method and previous SOTA, TUCORE-GCN. As shown in Figure \ref{fig:length}, our method consistently outperforms TUCORE-GCN in all groups, where the largest performance gap can be found in the group with less than 100 tokens. Moreover, TUCORE-GCN shows a great drop with an increase of length (i.e., from $[400,500)$ to $[500,+\infty)$), while HiDialog maintains decent performance for long sequences.

% \begin{minipage}[]{0.48\linewidth}
% \footnotesize
% \setlength{\tabcolsep}{9pt}
% \begin{center}
% % \vspace{-0.5cm}
% \begin{tabular}{lccc} 
% \toprule
% \textbf{Method} & \textbf{I} &  \textbf{II} &  \textbf{III}\\
% \midrule
% BERT & 42.5  & 60.7 & 65.6 \\
% % BERT$_s$ & 46.5 & 61.5 & 69.4 \\
% GDPNet  & 47.4  &59.8  &68.1 \\
% RoBERTa$_s$ & 57.4 & 69.3 & 79.6 \\
% TUCORE-GCN  &62.3  &\textbf{71.3}  &79.9 \\
% \midrule
% HiDialog & \textbf{76.6}  & 70.5	& \textbf{80.9}  \\
% w/o graph module &65.5 & 69.9 & 79.4\\
% \bottomrule
% \end{tabular}
% \end{center}
% % \vspace{-0.3cm}
% \captionof{table}{All methods performance on DialogRE. We break down the performance into three groups (I) asymmetric inverse relations, (II) symmetric inverse relations, and (III) others.}
% \label{tab:symmetric}
% \end{minipage}
% \hspace*{0.1cm}
% \begin{minipage}[]{0.5\linewidth}
% % \begin{figure}[h]
% % \vspace{-0.2cm}
% \footnotesize
% \centering
% \includegraphics[width=7cm]{sections/length.pdf}
% \vspace{-0.5cm}
% \captionof{figure}{Analysis of robustness of HiDialog tackling increasing utterance length compared to baseline TUCORE-GCN on DialogRE dataset.}
% % \vspace{-0.6cm}
% \label{fig:length}
% % \end{figure}
% \end{minipage}

% \begin{wrapfigure}{r}{0.6\textwidth}
% \vspace{-1.1cm}
% \begin{center}
% \includegraphics[width=0.6\textwidth]{sections/length.pdf}
% \vspace{-0.2cm}
% \caption{Analysis of the robustness of HiDialog tackling increasing utterance length compared to baseline TUCORE-GCN on DialogRE dataset.}
% \label{fig:length}
% \end{center}
% % \vspace{-1.2cm}
% \end{wrapfigure}
% \subsection{Related Work}\label{ap:related_work}
% % \subsubsection{Multi-Turn Dialogue Understanding}
% \textbf{Multi-Turn Dialogue Understanding}. Various tasks and corresponding benchmarks are proposed to evaluate the capacities of dialogue understanding models. Dialogue-based relation extraction (RE) is a classification task that assigns a pair of entities a relation label in a dialogue. Focusing on the word level,  \cite{xue2021gdpnet} constructed a multi-view graph with words in the dialogue as nodes and proposed Dynamic Time Warping Pooling to automatically select words in interest. SimpleRE \citep{SimpleRE} designed a novel input sequence format and utilized a Relation Refinement Gate to filter the semantic representation which is later fed into the classifier. TUCORE-GCN \citep{zahiri:18a} used a heterogeneous dialogue graph to encode the interaction between speakers, arguments and turns across the dialogues.
% % \citet{christopoulou-etal-2019-connecting} constructed an edge-oriented graph model to encode the dialogue as a graph with nodes and edges of different functions and applied an inference mechanism on the graph edges to recognize the internal relationship. By constructing a mention-level graph and an entity-level graph, \citet{zahiri:18a} reasoned the relation between entities by path inference.

% Emotion Recognition in Conversation (ERC) has been extensively studied in the research community. It aims to attach an emotional label to every turn in a given dialogue. \cite{kratzwald2018deep} customized the recurrent neural network with bidirectional processing to solve the problem of emotion classification. \cite{majumder2019dialoguernn} leveraged the Recurrent Neural Network to extract the information of the party states and use it to predict the emotion in conversations with two speakers. On top of the recurrent neural network, COSMIC \cite{ghosal2020cosmic} models the commonsense knowledge, mental states, events, and actions to enhance emotion detection in dialogue. 
% %Towards solving the context propagation problems in the recurrent neural network-based methods, \citet{ghosal-etal-2019-dialoguegcn} proposed a graph-based method that models the utterances as nodes and the speakers' dependency as edges. 

% Deep learning based methods have been extensively studied in recent works \citep{lee-dernoncourt-2016-sequential, chen2018dialogue, raheja2019dialogue} regarding Dialogue Act classification (DAC). \cite{chen2018dialogue} introduced a relation layer into the shared hierarchical encoder to model the interaction between the tasks of dialog act recognition and sentiment classification.
% %Combining recurrent neural networks and convolutional neural networks, \citet{lee-dernoncourt-2016-sequential} incorporated the preceding texts while classifying the act.


% % \subsubsection{Context-Aware Representation Learning}
% \textbf{Context-Aware Representation Learning}. To address dynamics and semantic changes in multi-turn dialogue, previous works extend pre-trained large language models to learn context-aware representations for turns \citep{lee2021graph, DialogXL, DCM, chapuis2020hierarchical}. TUCORE-GCN \citep{lee2021graph} proposes the turn attention module, masking out distant turns to learn the contextual embeddings. Instead of adding extra modules, DialogXL \citep{DialogXL} targets the encoder and incorporates four self-attention mechanisms to different attention heads to capture diverse dialog-aware information. Similarly, such dialogue-oriented self-attention can also be found in MDFN \citep{MDFN} where it is defined as utterance-aware and speaker-aware channels. However, most of them involve an additional pre-training stage \citep{DialogXL, DCM, chapuis2020hierarchical}. 
% %These efforts focus on the turn-level modeling but ignored the gap between the pre-training objective and dialogue understanding tasks. Also, though achieving preferable performance on limited datasets or tasks, these methods have not led to a unified solution to multi-turn dialogue understanding. 


\section{Experiments}
\subsection{Datasets and Metrics}

%dialogue task分四种， intent prediction, slot-filling, semantic parsing, and dialogue state tracking. 然后我们完成的数据集任务是relation extraction, emotional recognition, speech act classification，不太确定是不是都能解决

\textbf{DialogRE} \citep{yu-etal-2020-dialogue} is a relation extraction task based on 1,788 dialogues from the Friends transcript. Each pair of arguments can be classified as one of 36 possible relation types. For each of the 10,168 human-annotated entity pairs, the trigger words are also provided. % such as neighbours or siblings. (subject, object, relation type) triplets

\textbf{EmoryNLP} \citep{zahiri:18a} is an emotion detection task based on 12,606 utterances from the Friends transcript. Each utterance can be classified as one of seven emotions, e.g., joyful, scared. 
%The label is human-annotated based on the dialogue context. 

\textbf{DailyDialog} \citep{DailyDialog} is a dialogue database containing 13,118 simple English dialogues. Each utterance can be assigned an emotion label from seven categories (anger, surprise, etc.). 
%targets both emotion detection and act classification. DailyDialog The label is human-annotated based on the dialogue context.  (Inform, Questions, Directives, Commissive) 

\textbf{MELD} \citep{poria-etal-2019-meld} is an emotion detection task based on 13,000 sentences from the Friends transcript. Each utterance can be classified as one of eight emotions, such as sad, disgust. % or neutral. 

%The label is human-annotated based on the multimodal cues of the dialogue, including visual, audio and textual information. 
\begin{table}[t]
  % \setlength{\tabcolsep}{3.5pt}
% \footnotesize
% \scriptsize
  \centering
  \vspace{-0.35cm}
  \begin{tabular}{lllllll}
    \toprule
  \multirow{2}{*}{\textbf{Method}} &\multirow{2}{*}{\textbf{MELD}} & \multirow{2}{*}{\textbf{ENLP}} & \multirow{2}{*}{\textbf{DDialog}} & \multirow{2}{*}{\textbf{MRDA}} & \multicolumn{2}{c}{\textbf{DialogRE-Test}}      \\
    % \textbf{Method} &\textbf{MELD} & \textbf{ENLP} & \textbf{DDialog} &\textbf{MRDA} & \multicolumn{2}{c}{\textbf{DialogRE}}      \\
    %\cmidrule(r){2-5}
    \cmidrule(l){6-7}   
    % \cmidrule(l){2-2}  \cmidrule(l){3-3} \cmidrule(l){4-4} \cmidrule(l){5-5}  \cmidrule(l){6-7}  
      &  & & & & $F1$  & $F1_c$  \\
    \midrule
    % BERT &61.50	& 34.17	& 54.09& 91.0 & 58.5	& 53.2\\
    % +HiDialog & + 1.78	& +0.63 & +5.55 & +0.3 & + &\textbf{59.8}\\
    PHT  &61.90&-&	60.14&	\textbf{92.4}&- &- \\
    DialogXL  & 62.41 & 34.73 & 54.93 & -& - & -  \\
    % \midrule
    RoBERTa$_s$& 64.19&38.03	&61.65	&91.3	&71.3 & 63.7\\
+Intra-turn &\textbf{65.64}\textsubscript{\textcolor{green}{+1.45}}& \textbf{38.13}\textsubscript{\textcolor{green}{+0.1}} &\textbf{61.83}\textsubscript{\textcolor{green}{+0.28}}&91.5\textsubscript{\textcolor{green}{+0.2}} & \textbf{74.4}\textsubscript{\textcolor{green}{+3.1}}&\textbf{66.6}\textsubscript{\textcolor{green}{+2.9}}\\
    \bottomrule
  \end{tabular}
  % \vspace{-0.2cm}
  % \caption{All methods performance on 5 multi-turn dialogue-based understanding datasets: MELD, EmoryNLP (Weighted-F1), DailyDialog (Micro-F1), MRDA (Top-1 Acc.), DialogRE (F1 and F1$_c$), averaged over five runs. Performance gains over the RoBERTa$_s$ are highlighted in green.}
    \caption{All methods performance on 5 multi-turn dialogue-based understanding datasets: MELD, EmoryNLP, DailyDialog, MRDA, DialogRE, averaged over five runs. Performance gains over the RoBERTa$_s$ are highlighted in green.}
  \label{tab:exp-mtr}
  \vspace{-0.5cm}
\end{table}


\begin{minipage}[]{0.48\linewidth}
\footnotesize
\setlength{\tabcolsep}{7pt}
\begin{center}
\begin{tabular}{l c c} 
 \toprule
  {\textbf{Method}} & \textbf{F1} & \textbf{F1$_c$} \\
 \midrule
HiDialog                      & 77.1        & 68.2       \\ 
w/o attention mask & 76.5 (-0.6) & 67.9 (-0.3) \\
w/o special tokens & 75.6 (-1.5) & 67.4 (-0.8) \\
only intra-turn     & 74.4 (-2.7) & 66.6 (-1.6) \\
\bottomrule
\end{tabular}
\end{center}
\captionof{table}{Ablation Study on HiDialog components on DialogRE to evaluate the individual effect of turn-level attention, turn-level special tokens, and graph module. } %\textit{Ablation study. Turn-level} is omitted for brevity.}
\label{tab:ablation_structure}
\end{minipage}
\hspace*{0.1cm}
\begin{minipage}[]{0.48\linewidth}
\footnotesize
\setlength{\tabcolsep}{7pt}
\begin{center}
% \vspace{-0.5cm}
\begin{tabular}{lccc} 
\toprule
\textbf{Method} & \textbf{I} &  \textbf{II} &  \textbf{III}\\
\midrule
BERT & 42.5  & 60.7 & 65.6 \\
% BERT$_s$ & 46.5 & 61.5 & 69.4 \\
GDPNet  & 47.4  &59.8  &68.1 \\
RoBERTa$_s$ & 57.4 & 69.3 & 79.6 \\
TUCORE-GCN  &62.3  &\textbf{71.3}  &79.9 \\
\midrule
HiDialog & \textbf{76.6}  & 70.5	& \textbf{80.9}  \\
w/o graph module &65.5 & 69.9 & 79.4\\
\bottomrule
\end{tabular}
\end{center}
% \vspace{-0.3cm}
\captionof{table}{All methods performance on DialogRE. We break down the performance into three groups (I) asymmetric inverse relations, (II) symmetric inverse relations, and (III) others.}
\label{tab:symmetric}
\vspace{0.5cm}
\end{minipage}

\textbf{MRDA} \citep{MRDA} is a dialogue act task based on 75 hours of real-life meeting transcript. Each sentence is assigned a general dialogue act (topic change, repeat, etc.) and a specific dialogue act (apology, suggestion, etc.).  % explanation sympathy

\textbf{Metrics}. For DialogRE, F1 and F1$_c$ are used as evaluation metrics. F1$_c$ modifies F1 by taking an early part of the dialogue as input \cite{yu-etal-2020-dialogue}. For MELD and EmoryNLP, we use weighted-F1 as metrics. For DailyDialog, the Micro-F1 score excluding the neutral class is used as the metric. 
\subsection{Results and Analysis}
\textbf{Overall Performance}. We first evaluated HiDialog on the Dialogue Relation Extract (DRE) dataset, DialogRE \citep{yu-etal-2020-dialogue} and the Emotion Recognition in Conversation (ERC) dataset, MELD \citep{poria-etal-2019-meld}. We selected BERT \citep{bertbase}, GDPNet \citep{xue2021gdpnet}, RoBERTa$_s$ \citep{yu-etal-2020-dialogue}, SimpleRE \citep{SimpleRE}, and TUCORE-GCN \citep{lee2021graph} as baselines. As reported in Table \ref{tab:exp-re}, HiDialog established new state-of-the-art results on both datasets. 
On the DialogRE test set, HiDialog surpassed the previous SOTA, TUCORE-GCN, by 4\% in F1 and 2.3\% in F1$_c$. On the MELD dataset, HiDialog outperformed TUCORE-GCN by 1.5\% in weighted F1. 
%, surpassing the previous SOTA by 4\% in F1 and 2.3\% in F1$_c$ on the DialogRE test set, by 1.5\% in weighted F1 score on the MELD test set. 


\textbf{Towards Generality}.
% In view of the simplicity and effectiveness of the intra-turn modeling, it is expected to have a general use for further work on dialogue understanding. To validate this idea, we incorporate our intra-turn modeling into the baseline encoder, without any extra components such as the inter-turn module or speaker embeddings. For a fair comparison, only the global $[CLS]$ token embedding from the encoder output is fed into a softmax classifier to make a prediction. 
Our intra-turn modeling's simplicity suggests its potential as a valuable solution for enhancing dialogue understanding without the need for extra pre-training. To assess this claim, we integrated it into the baseline encoder without any additional components, such as an inter-turn module or speaker embeddings. For fair comparisons, only the encoder's global $[CLS]$ token was used in a softmax classifier for prediction.
%Our intra-turn modeling's simplicity and effectiveness suggest its potential as a valuable solution for enhancing dialogue understanding, without additional pre-training. 

% \begin{wraptable}{r}{8.2cm}
%   \setlength{\tabcolsep}{3.5pt}
% % \footnotesize
% \scriptsize
%   \centering
%   \vspace{-0.35cm}
%   \begin{tabular}{lllllll}
%     \toprule
%   \multirow{2}{*}{\textbf{Method}} &\multirow{2}{*}{\textbf{MELD}} & \multirow{2}{*}{\textbf{ENLP}} & \multirow{2}{*}{\textbf{DDialog}} & \multirow{2}{*}{\textbf{MRDA}} & \multicolumn{2}{c}{\textbf{DialogRE}}      \\
%     % \textbf{Method} &\textbf{MELD} & \textbf{ENLP} & \textbf{DDialog} &\textbf{MRDA} & \multicolumn{2}{c}{\textbf{DialogRE}}      \\
%     %\cmidrule(r){2-5}
%     \cmidrule(l){6-7}   
%     % \cmidrule(l){2-2}  \cmidrule(l){3-3} \cmidrule(l){4-4} \cmidrule(l){5-5}  \cmidrule(l){6-7}  
%       &  & & & & $F1$  & $F1_c$  \\
%     \midrule
%     % BERT &61.50	& 34.17	& 54.09& 91.0 & 58.5	& 53.2\\
%     % +HiDialog & + 1.78	& +0.63 & +5.55 & +0.3 & + &\textbf{59.8}\\
%     PHT  &61.90&-&	60.14&	\textbf{92.4}&- &- \\
%     DialogXL  & 62.41 & 34.73 & 54.93 & -& - & -  \\
%     % \midrule
%     RoBERTa$_s$& 64.19&38.03	&61.65	&91.3	&71.3 & 63.7\\
% +Intra-turn &\textbf{65.64}\textsubscript{\textcolor{green}{+1.45}}& \textbf{38.13}\textsubscript{\textcolor{green}{+0.1}} &\textbf{61.83}\textsubscript{\textcolor{green}{+0.28}}&91.5\textsubscript{\textcolor{green}{+0.2}} & \textbf{74.4}\textsubscript{\textcolor{green}{+3.1}}&\textbf{66.6}\textsubscript{\textcolor{green}{+2.9}}\\
%     \bottomrule
%   \end{tabular}
%   \vspace{-0.2cm}
%   % \caption{All methods performance on 5 multi-turn dialogue-based understanding datasets: MELD, EmoryNLP (Weighted-F1), DailyDialog (Micro-F1), MRDA (Top-1 Acc.), DialogRE (F1 and F1$_c$), averaged over five runs. Performance gains over the RoBERTa$_s$ are highlighted in green.}
%     \caption{All methods performance on 5 multi-turn dialogue-based understanding datasets: MELD, EmoryNLP, DailyDialog, MRDA, DialogRE, averaged over five runs. Performance gains over the RoBERTa$_s$ are highlighted in green.}
%   \label{tab:exp-mtr}
%   \vspace{-0.35cm}
% \end{wraptable}



% \begin{minipage}[]{0.5\linewidth}
% % \begin{figure}[h]
% % \vspace{-0.2cm}
% \footnotesize
% \centering
% \includegraphics[width=7cm]{sections/length.pdf}
% \vspace{-0.5cm}
% \captionof{figure}{Analysis of robustness of HiDialog tackling increasing utterance length compared to baseline TUCORE-GCN on DialogRE dataset.}
% \vspace{0.6cm}
% \label{fig:length}
% % \end{figure}
% \end{minipage}



We conducted the experiment on 5 datasets from 3 different tasks: DRE (DialogRE), ERC (MELD, EmoryNLP \citep{zahiri:18a}, DailyDialog \citep{DailyDialog}), and Dialogue Act Classification (MRDA \citep{MRDA}). We chose RoBERTa$_s$, Pretrained Hierarchical Transformer (PHT) \citep{chapuis2020hierarchical}, and DialogXL \citep{DialogXL} as baselines. Compared to PHT and DialogXL, both of which require additional pre-training to address the domain adaption gap, the performance of proposed intra-turn modeling is surprisingly good in all 5 datasets (Table \ref{tab:exp-mtr}). 

% Moreover, we conducted an ablation study and analysis, which further reveals HiDialog is good at handling asymmetric relations and robust against increasing utterance length (see Appendix \ref{ap:ablation}). 

% \begin{wraptable}{r}{7cm}
% % \scriptsize
% % \vspace{-0.5cm}
% % \setlength{\tabcolsep}{3.5pt}
% \begin{center}

% \begin{tabular}{l c c} 
%  \toprule
%   {\textbf{Method}} & \textbf{F1} & \textbf{F1$_c$} \\
%  \midrule
% HiDialog                      & 77.1        & 68.2       \\ 
% w/o attention mask & 76.5 (-0.6) & 67.9 (-0.3) \\
% w/o special tokens & 75.6 (-1.5) & 67.4 (-0.8) \\
% only intra-turn     & 74.4 (-2.7) & 66.6 (-1.6) \\
% \bottomrule
% \end{tabular}
% \end{center}
% % \vspace{-0.2cm}
% \caption{Ablation Study on HiDialog components on DialogRE to evaluate the individual effect of turn-level attention, turn-level special tokens, and graph module. } %\textit{Ablation study. Turn-level} is omitted for brevity.}
% \label{tab:ablation_structure}
% % \vspace{-0.2cm}
% \end{wraptable}



\textbf{Ablation study on components.} We conducted an ablation study on DialogRE to evaluate key components in HiDialog: turn-level attention, turn-level special tokens, and inter-turn module (Table \ref{tab:ablation_structure}). First, after we removed the turn-level attention mask, the performance slightly dropped. In this case, these special tokens are able to aggregate information from the entire sequence, thus they are not context-aware at the turn level. We experimented with removing intra-turn modeling, resulting in only one difference from the final HiDialog: here we used an average of corresponding token embeddings for initialization. The $F1$ score decreases by 1.5\% and the $F1_c$ score declines by 0.8\%.

\textbf{Analysis of relations}. We grouped the test set of DialogRE according to the relation types into three subsets: (I) asymmetric, when a relation type differs from its inversion (e.g. \textit{children} and \textit{parents});  (II) symmetric, when a relation type is the same as its inversion (e.g. \textit{spouse}); (III) other, when a relation type does not have inversion (e.g. \textit{age}). We compared the performance of our model with baselines and report the results in Table \ref{tab:symmetric}. As we can observe, there is a great performance increase in the asymmetric subset while the F1 score drops moderately for symmetric relations. This trend reverses when we remove the graph module in our method (i.e. symmetric $>$ asymmetric). 
% \clearpage

\textbf{Analysis of robustness against increasing utterance length.} With the hierarchical aggregation in HiDialog, each turn-level special token is enforced to capture intra-turn critical information regardless of the whole dialogue. This nature enables our method to handle dialogues of various lengths. Thus, we further divided the samples in the DialogRE test set into six groups according to their lengths and compared HiDialog against the previous SOTA, TUCORE-GCN. As shown in Figure \ref{fig:length}, our method consistently outperforms TUCORE-GCN in all groups, where the largest performance gap can be found in the group with less than 100 tokens. Moreover, TUCORE-GCN shows a great drop with an increase of length (i.e., from $[400,500)$ to $[500,+\infty)$), while HiDialog maintains decent performance for long sequences.

 \begin{figure}[t]
\centering
% \vspace{-0.2cm}
\footnotesize
\centering
\includegraphics[width=7cm]{sections/length.pdf}
% \vspace{-0.5cm}
\captionof{figure}{Analysis of robustness of HiDialog tackling increasing utterance length compared to baseline TUCORE-GCN on DialogRE dataset.}
% \vspace{0.6cm}
\label{fig:length}
\end{figure}


%Note that both PHT and DialogXL are pre-trained methods that require extra computation
%Moreover, it outperforms the current SOTA by 1.3\% in $F1$ and 0.7\% in $F1_c$ on the DialogRE dataset, by 0.3\% in weighted F1 on MELD.
%HiDialog performs well in managing asymmetric relations and handling longer utterances, as revealed in our ablation study (see Appendix \ref{ap:ablation}). It provides an effective solution for bridging the gap between pre-training on general corpora and dialogue understanding without additional computational costs or training data while maintaining good performance. 
%Considering that our turn-level attention is easy to adopt and does not introduce any parameters to the base encoder, we believe it can be used as a strong baseline or plug-in module for future work in the community.
%Our turn-level attention mechanism can be effortlessly integrated into the base encoder without introducing any new parameters. Thus, we anticipate that it will serve as a compelling baseline or plug-in module for upcoming research in this field.
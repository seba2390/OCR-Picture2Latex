
\documentclass{article} % For LaTeX2e
\usepackage{iclr2023_conference_tinypaper,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage{hyperref}
\usepackage{url}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{graphicx} 
\usepackage{fixltx2e}
\usepackage{wrapfig}
\usepackage{caption}
\newcommand*{\myalign}[2]{\multicolumn{1}{#1}{#2}}
\newcommand{\LX}[1]{\textcolor{teal}{[Xiao: #1]}}
\newcommand{\FZ}[1]{\textcolor{red}{[Fuzhao: #1]}}
\newcommand*\samethanks[1][\value{footnote}]{\footnotemark[#1]}

\title{Hierarchical Dialogue Understanding with Special Tokens and Turn-level Attention}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.

\author{Xiao Liu\thanks{This work was done during the author's time as a student at National University of Singapore}, Jian Zhang\thanks{Equal contributions}, Heng Zhang\samethanks, Fuzhao Xue, Yang You \\
Department of Computer Science, National University of Singapore\\
\texttt{\{liuxiao, zhang.jian, zhang\_heng, f.xue\}@u.nus.edu,} \\ \texttt{youy@comp.nus.edu.sg} \\
}
% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}


\maketitle

\begin{abstract}
Compared with standard text, understanding dialogue is more challenging for machines as the dynamic and unexpected semantic changes in each turn. To model such inconsistent semantics, we propose a \emph{simple but effective} \textbf{Hi}erarchical \textbf{Dialog}ue Understanding model, HiDialog. Specifically, we first insert multiple special tokens into a dialogue and propose the turn-level attention to learn turn embeddings hierarchically. Then, a heterogeneous graph module is leveraged to polish the learned embeddings. We evaluate our model on various dialogue understanding tasks including dialogue relation extraction, dialogue emotion recognition, and dialogue act classification. Results show that our simple approach achieves state-of-the-art performance on all three tasks above. All our source code is publicly available at \url{https://github.com/ShawX825/HiDialog}.
\end{abstract}

%%%%%%%
\input{sections/1_introduction.tex}
\input{sections/2_related}
\input{sections/3_method}
\input{sections/4_experiments}
\input{sections/5_conclusion}
% \LX{TODO: fix citation; Main experiment part}

% \LX{@Fuzhao, can we put ablation and analysis in the appendix?}
% \FZ{Yes}

% \LX{@Fuzhao, should we include related work part and put it in the appendix?}
% \FZ{Yes}

% \FZ{Use ChatGPT to help your writing.}

% \FZ{You can see the template I sent to you. That would give you more space to place your figure and tables.}


% \clearpage
\section*{Contribution}
This work has been expanded upon from a course project that was undertaken by the key authors, Xiao Liu, Jian Zhang, and Heng Zhang, during their time as students at the National University of Singapore. Fuzhao Xue, the teaching assistant, and project mentor played a role in guiding and shaping the outcome of this work. We are grateful to Yang You for providing us with valuable instructions and computational resources. 

\section*{Acknowledgement}
Yang You's research group is being sponsored by NUS startup grant (Presidential Young Professorship), Singapore MOE Tier-1 grant, ByteDance grant, ARCTIC grant, SMI grant and Alibaba grant. Our sincere appreciation also goes out to Min-Yen Kan, our course lecturer, for his invaluable suggestions during our enrollment.

% This work was extended from a course project during key authors' (Xiao Liu, Jian Zhang, Heng Zhang) time as students at the National University of Singapore. Fuzhao Xue was the teaching assistant and projector mentor of this work.


\section*{URM Statement}
The authors acknowledge that the first author of this work meets the URM criteria of ICLR 2023 Tiny Papers Track.

\bibliography{iclr2023_conference_tinypaper}
\bibliographystyle{iclr2023_conference_tinypaper}

% \input{sections/6_appendix}
\end{document}


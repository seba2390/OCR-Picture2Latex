\section{Implementation Details}
\label{sec:implementation_details}

\paragraph{Training details.} We train all the networks for 500 epochs  with Adam optimizer. 
The learning rate is set to 0.001 for Darcy flow and 0.005 for Navier-Stokes. We use learning rate weight decay of 1e-4 for both Navier-Stokes and Darcy flow. The batch size is set to 32.
In case of Darcy flow, we also use cosine annealing for learning rate scheduling. 
We run all our experiments on a combination of NVIDIA RTX A6000, NVIDIA GeForce RTX 2080 Ti and 3080 Ti. 
All networks can easily fit on a single NVIDIA RTX A6000, but training time varies between the networks. 

For FNO-DEQ, we use Anderson solver~\citep{anderson1965iterative} to solve for the fixed point in the forward pass. The maximum number of Anderson solver steps is kept fixed at 32 for Dary Flow, and 16 for Navier Stokes. For the backward pass, we use phantom gradients~\citep{geng2021training} which are computed as:
\begin{equation}
    \label{eq:phatom-grad}
    u^\star = \tau G_\theta(u^\star, a) + (1 - \tau)u^\star
\end{equation}
where $\tau$ is a tunable damping factor and $u^\star$ is the fixed point computed using Anderson solver in the forward pass. This step can be repeated $S$ times. We use $\tau=0.5$ and $S=1$ for Darcy Flow, and $\tau=0.8$ and $S=3$ for Navier-Stokes. 

For the S-FNO-DEQ used in \cref{table:results-darcy-flow-all}, we use Broyden's method \citep{broyden1965class} to solve for the fixed point in the forward pass and use exact implicit gradients, computed through implicit function theorem as shown in \cref{eq:implcit-grad-deq}, for the backward pass through DEQ. The maximum number of solver steps is fixed at 32.

For weight-tied networks, we repeatedly apply the FNO block to the input $12$ times for Darcy flow, and $6$ times for Navier-Stokes.

\paragraph{Network architecture details.} The width of an FNO layer set to 32 across all the networks. Additionally, we retain only 12 Fourier modes in FNO layer, and truncate higher Fourier modes. We use the code provided by \citet{li2020fourier} to replicate the results for FNO, and construct rest of the networks on top of this as described in \cref{sec:experiments}.








\section{Datasets}

\subsection{Darcy Flow}
\label{subsec:Darcy_flow_implementation}
As mentioned in \cref{sec:experiments} 
we use the dataset provided by~\cite{li2020fourier} for our experiments with steady-state Darcy-Flow.

All the models are trained on 1024 data samples and tested on 500 samples. The resolution of original images is $421 \times 421$ which we downsample to $85 \times 85$ for our experiments. For experiments with noisy inputs/observations, the variance of Gaussian noise that we add to PDEs are [0, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3]. 
\begin{figure}[!htbp]
    \centering
    \includegraphics[height=\textwidth]{Images/Darcy/darcy.png}
    \label{fig:darcy_flow}
    \caption{Samples from Darcy Flow}
\end{figure}

\subsection{Steady-State Incompressible Fluid Navier-Stoke}
\label{subsec:navier_stokes_implementation}
\begin{align*}
    u \cdot \nabla \omega &= \nu \Delta \omega + f, \qquad x \in \Omega\\
    \nabla \cdot u &= 0 \qquad\qquad\quad\;\;  x \in \Omega
\end{align*}
To generate the dataset for steady-state Navier-Stokes, 
instead of solving the steady state PDE using 
steady-state solvers like the SIMPLE algorithm~\cite{patankar1983calculation},
we first choose the solution $\omega^\star := \nabla \times u^\star$
of the PDE and then generate the corresponding equation, i.e. calculate the corresponding force term 
$f = u^\star \cdot \nabla \omega^\star - \nu \Delta \omega^\star.$


To generate the solutions $\omega^\star$, we forward propagate a relatively simple initial distribution of $\omega_0$ (sampled from a Gaussian random field) through a
time-dependent Navier-Stokes equation in the vorticity form for a short period of time. This ensures our dataset contains solutions $\omega^*$ that are rich and complex.  Precisely, recall the Navier-Stokes equations in their vorticity form:
\begin{equation}
\label{eq:navier_stokes_time_dependent}
\begin{split}
    \partial_t \omega(x,t) + u(x,t) \cdot \nabla \omega(x,t)
    &= \nu \Delta \omega(x,t) + g(x)  \qquad x \in (0, 2\pi)^2, t \in [0, T]\\
    \nabla \cdot u(x,t) &= 0 \qquad x \in (0, 2\pi)^2, t \in [0, T]\\
    \omega(x, 0) &= \omega_0(x) \qquad x \in (0, 2\pi)^2
\end{split}
\end{equation}
where $g(x) = \nabla \times \tilde{g}(x)$ and 
$\tilde{g}(x) = \sin(5x_1)\hat{x_2}$ 
is a divergence free forcing term and $x = (x_1, x_2)$ are the two coordinates of the input vector.
We forward propagate the equations \eqref{eq:navier_stokes_time_dependent}
using a pseudo-spectral method
using the functions provided in JAX-CFD~\citep{kochkov2021machine,Dresdner2022-Spectral-ML} package. 
The initial vorticity $\omega_0$ is sampled from a 
Gaussian random field $\gN(0, (5^{3/2}(I + 25\Delta)^{-2.5}))$, which is then made divergence free.
We forward propagate the Navier-Stokes equation in~\eqref{eq:navier_stokes_time_dependent}
for time $T = 0.5$ with $dt=0.002$ to get $\omega(1, x)$, 
which we choose as the solution to the steady-state PDE in~\eqref{eq:navier_stokes}, i.e, $\omega^\star$
for Equation~\ref{eq:navier_stokes}.

Subsequently, we use the stream function 
$\Psi$~\citep{batchelor1967introduction} to calculate 
$u = \left(\partial \Psi/\partial x_1, \partial \Psi/\partial x_2\right)$ 
by solving the Poisson equation $\Delta \Psi = \omega$ 
in the Fourier domain.
Furthermore, since 
$f = u^\star \cdot \nabla \omega^\star - \nu \Delta \omega^\star$
we use the stream function to calculate $(f_1, f_2)$, i.e., the different components of the force term.

We use $4500$ training samples and $500$ testing samples.
The input to the network is the vector field $\tilde{f} = (f_1, f_2)$ 
and we learn a map that outputs the vorticity $\omega^\star$.
The resolution of grid used to generate the dataset is $256 \times 256$ 
which we downsample to $128 \times 128$ while training the models. For experiments with noisy inputs/observations, we consider two values of maximum  variance of Gaussian noise: 1e-3 and 4e-3. 
The variances of the Gaussian noise that we add to the PDEs for the latter case are [0, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 2e-3, 4e-3].
However, when conducting experiments with a variance of 1e-3, we exclude the last two values of variance from this list.




\begin{figure}[!htbp]
    \centering
    \includegraphics[height=\textwidth]{Images/Navier-Stokes/visc-0.001/nu_0_001.png}
    \label{fig:navier-stokes-data-visc-0.001}
    \caption{Samples from Steady-state Navier-Stokes dataset with viscosity $0.001$. 
    Each triplet visualizes the inputs $f_1$, $f_2$ and the ground truth output i.e. $\omega^\star$. }
\end{figure}

\begin{figure}[!htbp]
    \centering
    \includegraphics[height=\textwidth]{Images/Navier-Stokes/visc-0.01/nu_0_01.png}
    \label{fig:navier-stokes-data-visc-0.01}
    \caption{Samples from Steady-state Navier-Stokes dataset with viscosity $0.01$. 
    Each triplet visualizes the inputs $f_1$, $f_2$ and the ground truth output i.e. $\omega^\star$. }
\end{figure}
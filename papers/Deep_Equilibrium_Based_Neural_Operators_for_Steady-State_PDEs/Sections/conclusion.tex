\section{Conclusion}


In this work, we demonstrate that the inductive bias of deep equilibrium models---and weight-tied networks in general---makes them ideal architectures for approximating neural operators for steady-state PDEs.
Our experiments on steady-state Navier-Stokes equation 
and Darcy flow equations show that weight-tied models and FNO-DEQ 
perform outperform FNO models with $\sim 4\times$ the number of 
parameters and depth. 
Our findings indicate that FNO-DEQ and weight-tied architectures 
are, in general, more robust to both input and observation noise compared to non-weight-tied architectures, including FNO.
We believe that our results complement any future progress in the design and development of PDE solvers \citep{tran2021factorized, li2022fourier} for steady-state PDEs,
and hope that our work motivates the study of relevant inductive biases that could be used to improve them.


\section{Acknowledgements}
TM 
is supported 
by CMU Software Engineering Institute via Department of Defense under contract FA8702-15-D-0002.
AP
is supported 
by a grant from the Bosch Center for Artificial Intelligence.
ZL gratefully acknowledges the NSF (FAI 2040929 and IIS2211955), UPMC, Highmark Health, Abridge, Ford Research, Mozilla, the PwC Center, Amazon AI, JP Morgan Chase, the Block Center, the Center for Machine Learning and Health, and the CMU Software Engineering Institute (SEI) via Department of Defense contract FA8702-15-D-0002, for their generous support of ACMI Labâ€™s research.
JL
is supported in part by NSF award DMS-2012286, and 
AR
is
supported in part by NSF awards IIS-2211907, CCF-2238523, Amazon Research Award, and the  CMU/PwC DT\&I Center.
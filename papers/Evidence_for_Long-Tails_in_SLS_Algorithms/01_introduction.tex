





Although algorithms for solving the $\NP$-complete satisfiability problem, so-called SAT solvers, are nowadays remarkably successful in solving large instances, randomized versions of these solvers often show a high variation in the runtime required to solve a fixed instance over repeated runs~\cite{GSCK00HeavyTailedPhenomena}.
In the past, research on randomized algorithms often focused on studying the unsteady behavior of statistical measures like the mean, variance, or higher moments of the runtime over repeated runs of the respective algorithm. In particular, these measures are unable to capture the long-tailed behavior of difficult instances.
In a different line of work~\cite{FRV97SummarizingCSPHardness,GS97AlgorithmPortfolioDesign,RF97StatisticalAnalysis}, the focus has shifted to studying the runtime distributions of search algorithms, which helps to understand these methods better and draw meaningful conclusions for the design of new algorithms.


Recently, the hybrid solver \algoformat{GapSAT}~\cite{LW20OnTheEffectOfLearnedClauses} was introduced, combining a stochastic local search~(SLS) solver with a conflict-driven clause learning~(CDCL) solver.
In the analysis conducted,
it was empirically shown that adding new clauses is beneficial to the mean runtime (in flips) of the SLS solver \probSAT{}~\cite{BalintImplementationOfProbSAT} underlying the hybrid model.
The authors also demonstrated that although adding new clauses can improve the mean runtime, there exist instances where adding clauses can harm the performance of SLS.
This behavior is worth studying to help eliminate the risk of increasing the runtime of such procedures.




For this reason, we study the runtime (or more precisely, hardness) distribution of the procedure~\Alfa{}, introduced in this work, that models the addition of a set of logically equivalent clauses~$\Clauses$ to a formula~$F$ and the subsequent solving of this amended formula~$F^{(1)} := F \cup \Clauses$ by an SLS solver.
Our empirical evaluations show that this distribution is long-tailed.
We want to stress the fact that studies on the runtime distribution of algorithms are quite sparse %
even though
knowledge of the runtime distribution of an algorithm is extremely valuable:
\textcolor{lipicsGray}{\textbf{(1)}}
Intuitively speaking, if the distribution is %
long-tailed, one knows there is a risk of ending in the tail and experiencing very long runs;
simultaneously, the knowledge that the time the algorithm used thus far is in the tail of the distribution can be exploited to restart the procedure (and create a new logically equivalent instance~$F^{(2)}$).
We will prove this statement in a rigorous manner 
for all long-tailed algorithms.
\textcolor{lipicsGray}{\textbf{(2)}}
Given the distribution of an algorithm's sequential runtime, it was shown 
how to predict and quantify the algorithm's expected speedup due to parallelization~\cite{ATCTC13UsingSequentialRuntimeDistributions}. %
\textcolor{lipicsGray}{\textbf{(3)}}
If the distribution of hardness is known, 
experiments with 
few
instances can lead to 
parameter estimations
of the underlying distribution~\cite{FRV97SummarizingCSPHardness}.	
\textcolor{lipicsGray}{\textbf{(4)}}~Knowledge of the distribution can help 
compare competing algorithms: %
one can test if the difference in the means of 
algorithm runtimes is significant if the distributions are known~\cite{FRV97SummarizingCSPHardness}.


\subsection{Our Contributions}


Our contributions consist of an empirical as well as theoretical part, specified below.

\subparagraph*{Statistical Runtime/Hardness Distribution Analysis.}


By conducting a plethora of experiments (total CPU time $80$ years) and using several statistical tools for the analysis of 
empirical
distributions,
we conjecture that
\Alfa{} equipped with SLS solvers based on Schöning's Random Walk Algorithm~\cite{Schoening02AProbabilisticAlgorithm}, \SRWA{} for short, follows a long-tailed distribution (Conjecture~\ref{conj:weak}).
The evidence obtained further suggests that this distribution is, in fact, lognormal (Conjecture~\ref{conj:strong}).
We measure the goodness-of-fit of our results over the whole domain using the $\chi^2$-statistic.


\subparagraph*{Restarts Are Useful For Long-Tailed Algorithms.}

Lorenz~\cite{Lorenz18RuntimeDistributions} has analyzed
the lognormal and the generalized Pareto distribution
for the usefulness of restarts and their optimal restart times.
Given that our Strong~Conjecture~\ref{conj:strong} holds, this result implies that restarts are useful for~\Alfa{}.
We will also show that this is the case if only the Weak~Conjecture~\ref{conj:weak} holds: We theoretically prove that restarts are useful for the class of algorithms exhibiting a long-tailed distribution.


\subsection{Related Work and Differentiation}




In~\cite{FRV97SummarizingCSPHardness}, the authors presented empirical evidence for the fact that the distribution of the effort (more precisely, the number of consistency checks) required for backtracking algorithms to solve constraint satisfaction problems randomly generated at the 50\,\% satisfiable point can be approximated by the Weibull distribution (in the satisfiable case) and the lognormal distribution (in the unsatisfiable case).
These results were later extended to a wider region around the 50\,\% satisfiable point~\cite{RF97StatisticalAnalysis}.
It should be emphasized that this study created all instances using the same generation model. This resulted in the creation of similar yet logically non-equivalent formulas.
We, however, will firstly use different models to rule out any influence of the generation model and secondly generate logically equivalent modifications~of~a base instance (see \refAlg{algo:main}).
This approach lends itself to the analysis of existing~SLS solvers~\cite{LW20OnTheEffectOfLearnedClauses}.
The major advantage is that the conducted work is not lost in the case~of a restart: only the logically equivalent instance could be \mbox{changed while keeping the current assignment}.


In~\cite{GSCK00HeavyTailedPhenomena}, the cost profiles of combinatorial search procedures were studied. 
The authors showed 
that 
they
are often characterized by %
the
Pareto-Lévy distribution %
and %
empirically demonstrated
how rapid randomized restarts can 
eliminate %
this tail behavior.
We will theoretically prove the effectiveness of restarts for the larger class of long-tailed distributions.




The paper~\cite{ATCTC13UsingSequentialRuntimeDistributions} studied the 
solvers \algoformat{Sparrow} and \algoformat{CCASAT}
and found that for randomly generated instances
the lognormal distribution is a good fit
for the runtime distributions.
For this, the Kolmogorov--Smirnov %
statistic $\sup_{t \in \R} | \hat{F}_n(t) - F(t) |$ was used.
Although the KS-test is very versatile, this comes with the disadvantage that its statistical power is rather low.
Clearly, the KS statistic is also nearly useless in the tails of a distribution: A high relative deviation of the empirical from the theoretical cumulative distribution function in either tail results in a very small absolute deviation.
It should also be remarked that the paper studies only few formulas in just two domains, 10 randomly generated and 9 crafted.
Our work will address both shortcomings in this paper: The $\chi^2$-test gives equal importance to the goodness-of-fit over the entire support; and various instance domain models (both theoretical and applied) are considered in this paper.


\begin{remark*}
	Unfortunately, the term heavy- or long-tailed distribution is not used consistently in the literature.
	We will follow~\cite{foss2011introduction} and use the notion given in~\refDef{def:long_tail}.
\end{remark*}





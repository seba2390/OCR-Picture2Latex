% !TEX root = ../CRCBook.tex


\graphicspath{{./stochastic/figures/}}


\chapter{Stochastic Behavior Trees}
\label{stochastic}
\label{ch:stochastic}


%\todopetter{do we keep this sentence? Yes, but we move it to the end of the paragraph, as in other chapters /P}


%{W}{e are interested}
In this chapter, we study the reliability of reactive  plan executions, in terms of execution times and success probabilities. 
To clarify what we mean by these concepts, we consider the following minimalistic example: a robot is searching for an object, and can choose between the two subtasks \emph{searching on the table}, and \emph{opening/searching  the drawer}.
One possible plan is depicted in Figure \ref{stoch:mcEx1}. Here, the robot first searches the table and then, if the object was not found on the table, opens the drawer and searches it. In the figure,  each task has an execution time and a success probability. For example, searching the table has a success probability of 0.1 and an execution time of 5s. Given a plan like this, it is fairly straightforward to compute the reliability of the entire plan, in terms of execution time distribution and success probability.
In this chapter, we show how to compute such performance metrics for arbitrary complex plans encoded using BTs.
In particular, we will define Stochastic BTs in Section~\ref{stoch:sec:analysis}, transform them into Discrete Time Markov Chains (DTMCs) in Section~\ref{stoch:sec:SBTtoDTCM}, compute reliabilities in Section~\ref{stoch:sec:reli} and describe examples Section~\ref{properties:sec:example:reliability}.
Some of the results of this chapter were previously published in the 
 paper \cite{Colledanchise14}.

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{frontMC.pdf}
\caption{A simple plan for a search task, modelled by a Markov Chain.
%Difference between a plan that optimizes expected success rate (top) and one that optimizes expected time to completion (bottom).
%Example of how the task "fueling up" of an aircraft can be accomplished in different way according to the desired performance.
}
\label{stoch:mcEx1}
\end{figure}

%Before motivating our study of BTs we will make a few more observations regarding the example above.
%First we note that the plan would still make sense if we changed the order of 
%\emph{searching on the table} and \emph{opening/searching the drawer}, both subtasks achieve the objective of finding the object. Such subtasks, where ordering is not critical, and succeeding in just one is enough, will be called \emph{Fallbacks}. Note however that it does not make sense to swap the order of \emph{opening  the drawer} and \emph{searching  the drawer}. Here, the order cannot be changed, and both subtasks must succeed. It does not make sense to search the drawer if we were not able to open it. We call such a set of subtasks a  \emph{Sequence}. 


Before motivating our study of BTs we will make a few more observations regarding the example above.
The ordering of the children of Fallback nodes (\emph{searching on the table} and \emph{opening/searching the drawer}) can in general be changed, whereas the ordering of the children of 
Sequence nodes (\emph{opening  the drawer} and \emph{searching  the drawer}) cannot.
Note also that adding subtasks to a Sequence generally decreases overall success probabilities, whereas adding Fallbacks generally increases overall success probabilities, as described in Section~\ref{sec:stochastic_extension}.


\begin{figure}[b]
\centering
\includegraphics[width=0.5\columnwidth]{frontBT.pdf}
\caption{The BT equivalent of the Markov chain in Figure \ref{stoch:mcEx1}. The atomic actions are the leaves of the tree, while the  interior nodes correspond to \emph{Sequence} compositions (arrow) and \emph{Fallbacks} compositions (question mark).
}
\label{stoch:btEx1}
\end{figure}



\section{Stochastic BTs}
\label{stoch:sec:analysis}

In this section we will show how some probabilistic measures, such as  Mean Time to Succeed (MTTS),  Mean Time to Fail (MTTF), and probabilities over time carry across modular compositions of BTs. The advantage of using BTs lie in their modularity and hierarchical structure, which provides good scalability, as explained above.  
%These features would be lost if the whole process from problem formulation to solution was carried out within the classical framework. 
To  address the questions above, we need to introduce some concepts from Markov theory.

\subsection{Markov Chains and Markov Processes}
Markov theory~\cite{norris1998markov} deals with memoryless processes. If a process is given by a sequence of actions that changes the system's state disregarding its history, a DTMC is suitable to model the plan execution. Whereas if a process is given by a transition rates between states, a Continuous Time Markov Chain (CTMC) it then suitable to model such plan execution.
A DTMC is given by a collection of states  $\mathcal{S}=\{s_1,s_2,\ldots,s_d\}$
and the transitions probabilities $p_{ij}$ between states $s_i$ and $s_j$. A CTMC is given by a collection of states $\mathcal{S}$ and the transition rates $q_{ij}^{-1}$ between states $s_i$ and $s_j$.


\begin{figure}[h]
\centering
\includegraphics[width=0.65\columnwidth ]{MCEx.pdf}
\caption{Example of a DTMC with 4 states and 6 transitions.}
\label{stoch:bg.fig.mc}
\end{figure}



\begin{definition}
The stochastic sequence $\{X_n, n = 0,1,2,\ldots\}$ is a DTMC provided that:
\begin{equation}
\begin{split}
&P\{X_{n+1} = s_{n+1} \vert X_{n} = s_{n}, X_{n-1} = s_{n-1}, \ldots, X_0 = s_0\} =\\
&=P\{X_{n+1} = s_{n+1} \vert X_{n} = s_{n}\}
\end{split}
\label{stoch:BG.eq.DTMC}
\end{equation}
$\forall \; n\in \mathbb{N}$, and $\forall \; s\in \mathcal{S}$
\end{definition}
The expression on the right hand side of~\eqref{stoch:BG.eq.DTMC} is the so-called \emph{one step transition probability} of the chain and denotes the probability that the process goes from state $s_{n}$ to state $s_{n+1}$. We use the following notation:
\begin{equation}
p_{ij} = P\{X_{n+1} = s_j \vert X_{n} = s_i\}
\end{equation}
to denote the probability to jump from a state $s_i$ to a state $s_j$. Since we only consider homogeneous DTMC, the above probabilities do not change in time.
\begin{definition}
\label{stoch:bg.def.p}
The \emph{one-step transition matrix} $P$ is a $\left\vert{\mathcal{S}}\right\vert \times \left\vert{\mathcal{S}}\right\vert$ matrix in which the entries are the transition probabilities $p_{ij}$.
\end{definition} 
Let $\pi(k)=[\pi_1(k),\ldots, \pi_{\left\vert{\mathcal{S}}\right\vert}(k)]^\top$, where $\pi_i$ is the probability of being in state $i$, then the Markov process can be described as a discrete time system with the following time evolution:
\begin{equation}
\label{stoch:bg.eq.discrete}
\begin{cases}
\pi(k+1)=P^\top\pi(k) \\
\pi(0)= \pi_0.
\end{cases}.
\end{equation}
where $\pi_0$ is assumed to be known a priori.


\begin{definition}
The stochastic sequence $\{X(t), t\geq 0 \}$ is a CTMC provided that:
\begin{equation}
\begin{split}
P\{&X(t_{n+1}) = s_{n+1} \vert X(t_{n}) = s_{n}, X(t_{n-1}) = s_{n-1}, \ldots,\\ 
,&X(t_0) = s_0\} =P\{X(t_{n+1}) = s_{n+1} \vert X(t_{n}) = s_{n}\}
\end{split}
\label{stoch:BG.eq.CTMC}
\end{equation}
\end{definition}
$\forall \; n\in \mathbb{N}$, $\forall \; s\in \mathcal{S}$, and all sequences $\{t_0,t_1,\ldots,t_{n+1}\}$ such that $t_0 < t_1 < \ldots <  t_{n} <  t_{n+1}$.
We use the following notation:
\begin{equation}
p_{ij}(\tau) = P\{X(t+\tau) = s_j \vert X(\tau) = s_i\}
\end{equation}
to denote the probability to be in a state $s_j$ after a time interval of length $\tau$ given that at present time is into a state $s_i$. Since we only consider homogeneous CTMC, the above probabilities only depend on the time length $\tau$.

To study the continuous time behavior of a Markov process we define the so-called \emph{infinitesimal generator matrix} $Q$.
\begin{definition}
The infinitesimal generator of the transition probability matrix $P(t)$ is given by:
\begin{equation}
Q = \left[q_{ij}\right]
\end{equation}
where 

\begin{equation}
q_{ij}=
   \begin{cases}
   \displaystyle\lim_{\Delta t \to 0} \frac{p_{ij}(\Delta t)}{\Delta t}& \text{if } i \neq j\\
   - \displaystyle\sum_{k \neq i} q_{kj} & \text{otherwise}.
  \end{cases}
  \label{stoch:bg.eq.infGen}
\end{equation}
\end{definition}
Then, the continuous time behavior of the Markov process is described by the following ordinary differential equation, known as the Cauchy problem:
\begin{equation}
\begin{cases}
\dot \pi(t)=Q^\top\pi(t) \\
\pi(0)=\pi_0
\end{cases}
\label{stoch:bg.eq.cauchy}
\end{equation}
where the initial probability vector $\pi_0$ is assumed to be known a priori.
\begin{definition}
The average sojourn time $SJ_i$ of a state $s_i$ in a CTMC is the average time spent in that state. It is given by~\cite{stewart2009}:
\begin{equation}
SJ_i = -\frac{1}{q_{ii}}
\label{stoch:BG.eq.meansj}
\end{equation} 
\end{definition}
\begin{definition}
Considering the CTMC $\{X(t), t\geq 0 \}$, the stochastic sequence $\{Y_n, n = 0,1,2,\ldots\}$ is a DTMC and it is called Embedded MC (EMC) of the process $X(t)$~\cite{stewart2009}.
\end{definition}
The transition probabilities of the EMC $r_{ij}$ are defined as:
\begin{equation}
r_{ij} = P\{Y_{n+1} = s_j \vert Y_{n} = s_i\}
\end{equation}
and they can be easily obtained as a function of the transition rates $q_{ij}$:
\begin{equation}
r_{ij}=
   \begin{cases}
   -\frac{q_{ij}}{q_{ii}}& \text{if } i \neq j\\
    \displaystyle 1-\sum_{k \neq i} r_{kj} & \text{otherwise}.
  \end{cases}
\end{equation}
On the other hand, the infinitesimal generator matrix $Q$ can be reconstructed from the EMC as follows
\begin{equation}
q_{ij}=
   \begin{cases}
   \frac{1}{SJ_j }r_{ij} & \text{if } i \neq j\\
   - \displaystyle\sum_{k \neq i} r_{kj} & \text{otherwise}
  \end{cases}.
\end{equation}


\subsection{Formulation}
\label{stoch:sec:problem_formulation}

We are now ready to make some definitions and assumptions, needed to compute the performance estimates.
%\begin{definition}
%A  BT  is a rooted tree defined as a two-tuple, \mbox{BT $=(\mathcal{V}, \mathcal{E})$} where:
%\begin{itemize}
%\item $\mathcal{V}=\mathcal{A} \cup \mathcal{C}\cup \mathcal{N}\cup \tau$ a finite set of nodes, composed by execution nodes (actions $\mathcal{A}$ and  conditions $\mathcal{C}$) control flow nodes $\mathcal{N}$ (e.g. fallbacks or sequences) and a root $\tau$. The nodes are numbered, $\mathcal{V} \subset \mathbb{N}$.
%\item $\mathcal{E} \subset \mathcal{V} \times \mathcal{V}$ is a finite set of edges.
%\end{itemize}
%\end{definition}
%As noted above, we are interested in describing the execution properties of a BT in terms of succees and fail probabilities, and time to success and failure  respectively. In order to facilitate  such an analysis, we make the following assumptions.

\begin{definition}
\label{stoch:def:stoc}
An action $\mathcal{A}$ in a BT, is called \emph{stochastic}
%\footnote{Unless otherwise specified, in this paper we call simply a BT when it is stochastic.}
 if the following holds:
\begin{itemize}
\item
It first returns Running, for an amount of time that might be zero or non-zero, then consistently returns either Success or Failure for the rest of the execution of its parent node.\footnote{The execution of the parent node starts when it receives a tick and finishes when it returns either Success/Failure to its parent.}
\item The probability to succeed $ p_s$ and the probability to fail $ p_f$ are known a priori.
%\item The probability to succeed at any given time $p_s(t)$ and the probability to fail at any given time $p_f(t)$ are known a priori. 
%\item The time to \emph{succeed} and the time to \emph{fail} are random variables with exponential distribution with rate $\mu$ and $\nu$ known a priori. 
\item The probability to succeed  $p_s(t)$ and the probability to fail $p_f(t)$ are exponentially distributed with the following Probability Density Functions (PDFs):
\begin{eqnarray}
 \hat p_s(t)&=& p_s \mu e^{-\mu t}\\
  \hat p_f(t)&=& p_f \nu e^{-\nu t}
\end{eqnarray}
from which we can calculate the Cumulative Distribution Functions (CDFs)
%\todo[inline]{ok?}
\begin{eqnarray}
 \bar p_s(t)&=& p_s 	(1- e^{-\mu t})\\
  \bar p_f(t)&=& p_f (1- e^{-\nu t})
\end{eqnarray}
\end{itemize} 
\end{definition}
\begin{definition}
\label{stoch:def:det}
An action $\mathcal{A}$ in a BT, is called \emph{deterministic} (in terms of execution time, not outcome) if the following holds:
\begin{itemize}
\item
It first returns Running, for an amount of time that might be zero or non-zero, then consistently returns either Success or Failure for the rest of the execution of its parent node.
\item The probability to succeed $p_s$ and the probability to fail $p_f$ are known a priori.
\item The time to \emph{succeed} and the time to \emph{fail} are deterministic variables $\tau_s$ and $\tau_f$ known a priori.
\item The probability to succeed  $p_s(t)$ and the probability to fail  $p_f(t)$ have the following PDFs:
\begin{eqnarray}
\hat p_s(t) &=& p_s  \delta(t-\tau_s)\label{stoch:eq:d1}  \\
\hat p_f(t) &=&  p_f  \delta(t-\tau_f)  \label{stoch:eq:d2}
\end{eqnarray}
where $\delta(\cdot)$ is the Dirac's delta function. From the PDFs we can calculate the CDFs:
\begin{eqnarray}
\bar p_s(t) &=& p_s  H(t-\tau_s)\label{stoch:eq:h1}  \\
\bar p_f(t) &=&  p_f  H(t-\tau_f)  \label{stoch:eqh2}
\end{eqnarray}
where $H(\cdot)$ is the step function.
%\todo[inline]{ok?}

\end{itemize} 
\end{definition}
%To have an analogy with stochastic actions we describe the probability to succeed and fail at any given time $p_s(t)$ and $p_f(t)$ as follows:
%\begin{equation}
%\label{stoch:eq:d1}
%p_s(t) =\tilde p_s  \delta(t-\tau_s)  
%\end{equation}
%\begin{equation}
%\label{stoch:eq:d2}
%p_f(t) = \tilde p_f  \delta(t-\tau_f)  
%\end{equation}
%where $\delta(\cdot)$ is the Dirac's delta function, the success and Failure rates are set to $\mu=\tau_s^{-1}$ and $\nu=\tau_f^{-1}$

\begin{remark}
 Note that it makes sense to sometimes have $\tau_s \neq \tau_f$. Imagine a door opening task which takes 10s to complete successfully but fails 30\% of the time after 5s when the critical grasp phase fails.
\end{remark}

\begin{example}
 For comparison, given a deterministic action with $\tau_s$, we let the rates of a stochastic action have $\mu=\tau_s^{-1}$. Then the PDFs and CDFs are as seen in 
Figure~\ref{stoch:DE.fig.prob}.
\end{example}
%
%An example of the Probability Density Functions (PDFs) and  Cumulative Distribution Functions (CDFs) for the Success of a stochastic and a deterministic action can
%be seen in  Figure~\ref{stoch:DE.fig.prob}. 
\begin{figure}[h]
\centering
\begin{subfigure}[h]{0.8\columnwidth}
\includegraphics[width=0.8\columnwidth]{probPlots2.pdf}
\caption{PDFs.}
\end{subfigure}
\begin{subfigure}[h]{0.8\columnwidth}
\includegraphics[width=0.8\columnwidth]{probPlots.pdf}
\caption{CDFs.}
\end{subfigure}
\caption{Cumulative and probability density distribution function for a deterministic (dark straight lines) and stochastic action (bright curves).}
\label{stoch:DE.fig.prob}
\end{figure} 


As we want to analyze the BT composition of actions, we must also define actions that include both stochastic and deterministic parts.

\begin{definition}
\label{stoch:def:hyb}
An action $\mathcal{A}$ in a BT, is called \emph{hybrid} if one of $p_s(t)$ and $p_f(t)$ is a random variable with exponential distribution, and the other one is deterministic.
\end{definition}

%Thus the success and Failure probabilities of a hybrid action have different distributions. One is described by an exponentially distributed random variable and the other as a deterministic variable.
Thus  hybrid actions come in two different variations:
%Here we investigate both cases:
\textbf{Deterministic Success Time}
For this type of hybrid action, the following holds:    
\begin{itemize}
\item
It first returns Running, for an amount of time that might be zero or non-zero, then consistently returns either Success or Failure for the rest of the execution of its parent node.
\item The probability to succeed $ p_s$ is known a priori.
%\item The probability to fail at any given time $ p_f(t)$ in known a priori. 
\item The time to \emph{succeed} is a deterministic variable $\tau_s$ known a priori.
%\item The time to \emph{fail} is a random variables with exponential distribution with rate $\nu$ known a priori. 
\item The probability to fail has the following PDF:
\begin{equation}
\hat p_f(t)=\begin{cases} p_f (1- e^{-\nu t}) &\mbox{if } t < \tau_s \\ 
1-p_s &\mbox{if } t = \tau_s \\
0 & \mbox{otherwise } 
 \end{cases}.
\end{equation}

\end{itemize}
In this case the CDF and the PDF of the probability to succeed are discontinuous. In fact this hybrid action will return Failure if, after the success time $\tau_s$, it does not return Success.
Then, to have an analogy with stochastic actions we derive the PDF of the probability to succeed:
\begin{equation}
\hat p_s(t) = p_s  \delta(t-\tau_s)  
\end{equation}
and the CDFs as follows:
\begin{equation}
\bar p_s(t) = p_s  H(t-\tau_s)  
\end{equation}
\begin{equation}
\bar p_f(t)=\begin{cases} p_f (1- e^{-\nu t}) &\mbox{if } t < \tau_s \\ 
1 - \bar p_s(t)& \mbox{otherwise }  \end{cases}.
\end{equation}
Thus, the probability of Running is zero after $\tau_s$ i.e. after $\tau_s$ it either fails or succeeds.
Moreover, the success rate is set to $\mu=\tau_s^{-1}$.

\textbf{Deterministic Failure Time}
For this type of hybrid action, the following holds:    
\begin{itemize}
\item It first returns Running, for an amount of time that might be zero or non-zero, then consistently returns either Success or Failure for the rest of the execution of its parent node.
%\item The probability to succeeds at any given time $\tilde p_s(t)$ in known a priori. 
\item The probability to fail $p_f$ is known a priori.
\item The time to \emph{succeed} is a random variables with exponential distribution with rate $\mu$ known a priori. 
%\item The time to \emph{fail} is a deterministic variable $\tau_f$ known a priori.
\item The probability to succeed has the following PDF:
\begin{equation}
\hat p_s(t)=\begin{cases} p_s (1- e^{-\mu t}) &\mbox{if } t < \tau_f \\ 
1-p_f &\mbox{if } t = \tau_f \\
0 & \mbox{otherwise } 
 \end{cases}.
\end{equation}
\end{itemize}
%Similarly to the deterministic actions, the CDF and the PDF are discontinuous. This hybrid action will return success if, after the failure time $\tau_f$, it does not return failure.
%Then, to have an analogy with stochastic actions we derive the probability to succeed and fail at any given time $p_s(t)$ and $p_f(t)$ as follows:
To have an analogy with stochastic actions we derive the PDF of the probability to fail:
\begin{equation}
\hat p_f(t) = p_f  \delta(t-\tau_f)  
\end{equation}
and the CDFs as follows:
\begin{equation}
\bar p_f(t) = p_f  H(t-\tau_f)  
\end{equation}
\begin{equation}
\bar p_s(t)=\begin{cases} p_s (1- e^{-\mu t}) &\mbox{if } t < \tau_f \\ 
1 - \bar p_f(t)& \mbox{otherwise }  \end{cases}.
\end{equation}


%\begin{equation}
%p_s(t)=\begin{cases} \tilde p_s(t) &\mbox{if } t < \tau_f \\ 
%1 - p_f(t)& \mbox{otherwise }  \end{cases}. \\
%\end{equation}
%\begin{equation}
%p_f(t) =\tilde p_f  \delta(t-\tau_f)  
%\end{equation}
Moreover, the failure rate is set to $\nu=\tau_f^{-1}$

\begin{remark}
Note that the addition of deterministic execution times makes~\eqref{stoch:bg.eq.cauchy} discontinuous on the right hand side, but it still has a unique solution in the Carath\'eodory sense~\cite{filippov1988differential}.
\end{remark}

We will now give an example of how these concepts transfer over BT compositions.

\begin{figure}[h]
\centering
\includegraphics[width=0.3\columnwidth]{BTparex.pdf}
\caption{Parallel node of Example \ref{stoch:ex:par}.}
\label{stoch:DE.fig.parexbt}
\end{figure}

\begin{example}
\label{stoch:ex:par}
Consider the BT in Figure~\ref{stoch:DE.fig.parexbt}. The Parallel node is set to returns Success as soon as one child returns Success, and the two children are of different kinds,
one deterministic and the other stochastic.
Note that the MTTS and MTTF of this BT has to account for the heterogeneity of its children. 
The deterministic child can succeed only at time $\tau_s$. The CDF of the Parallel node is given by the sum of the CDFs of its children. The PDF has a jump at time $\tau_s$ accounting for the fact that the Parallel node is more likely to return Success after that time.
Thus, the PDF and the CDF of a Success return status are shown in Figure~\ref{stoch:DE.fig.parexpd}. 

\begin{figure}[h]
\centering
\begin{subfigure}[h]{0.8\columnwidth}
\includegraphics[width=0.8\columnwidth]{PDFhybrid.pdf}
\caption{PDF.}
\end{subfigure}
\begin{subfigure}[h]{0.8\columnwidth}
\includegraphics[width=0.8\columnwidth]{CDFhybrid.pdf}
\caption{CDF.}
\end{subfigure}
\caption{Cumulative and probability density distribution function of Success of the Parallel node in Figure~\ref{stoch:DE.fig.parexbt}.}
\label{stoch:DE.fig.parexpd}
\end{figure}
\end{example}


\begin{definition}
A BT $\bt_1$ and a BT $\bt_2$ are said \emph{equivalent} if and only if 
$\bt_1$ can be created from $\bt_2$ by permutations of the children of Fallbacks and Parallel compositions.
%they their fallback and parallel nodes have the same children.
\label{stoch:PS.def.eq}
\end{definition}
An example of two equivalent BTs is shown in Figure~\ref{stoch:fig:search}.

\begin{assumption}
\label{stoch:ass:SBT:ac}
For each action $\mathcal{A}$ in the BT, one of the following holds
\begin{itemize}
\item The action $\mathcal{A}$ is a stochastic action.
\item The action $\mathcal{A}$ is a deterministic action. 
\item The action $\mathcal{A}$ is a hybrid action. 
\end{itemize} 
\end{assumption}


\begin{assumption}
\label{stoch:ass:SBT:cond}
For each condition $\mathcal{C}$ in the BT, the following holds
\begin{itemize}
\item It consistently returns the same value (Success or Failure) throughout the execution of its parent node.
\item The probability to succeed at any given time $p_s(t)$ and the probability to fail at any given time $p_f(t)$ are known a priori. 
\end{itemize} 
\end{assumption}
We are now ready to define a Stochastic BT (SBT).
\begin{definition}
A SBT is a BT satisfying Assumptions~\ref{stoch:ass:SBT:ac} and~\ref{stoch:ass:SBT:cond}.
\end{definition}


Given a SBT, we want to use the probabilistic descriptions of its actions and conditions, $p_s(t)$, $p_f(t)$, $\mu$ and $\nu$, to recursively compute analogous descriptions for every subtrees and finally the whole tree. %Formally the problem is as follows:

%\setcounter{theorem}{0}
%\begin{problem}
%\label{stoch:problem:main}
%Given a SBT as defined above.
%Compute the probabilistic measures $p_s(t)$, $p_f(t)$, $\mu$ and $\nu$  for  each  subtree, and ultimately the root of the SBT.
%\end{problem}
%%\todo[inline]{Does $\mu$ and $\nu$ have meaning for a hybrid BT such as the one in Fig 10?}
%
%
%\begin{problem}
%\label{stoch:problem:opt}
%Given a SBT as defined above and an objective that is a function of its probabilistic measures $p_s(t)$, $p_f(t)$, $\mu$ and $\nu$. Derive an equivalent SBT that maximizes the objective function.
%\end{problem}


To illustrate the investigated problems and SBTs we take a look at the following example.
\begin{example}
\label{stoch:ex:search}
Imagine a robot that is to search for a set of keys on a table and in a drawer. The robot knows that the keys are often located in the drawer, so that location is more likely than the table. However, searching the table takes less time, since the drawer must be opened first. Two possible plans are conceivable: searching the table first, and then the drawer, as in Figure~\ref{stoch:fig:searcht}, or the other way around as in Figure~\ref{stoch:fig:searchd}. These two plans can be formulated as SBTs and analyzed through the scope of Problem 1 and 2, using the results of Section~\ref{stoch:sec:analysis} below. Depending on the user requirements in terms of available time or desired reliability at a given time, the proper SBT can be chosen.
\begin{figure}
      %  \label{stoch:fig:search}
        \centering
        \begin{subfigure}[b]{0.5\columnwidth}
                \centering
                \includegraphics[width=0.8\columnwidth]{BTExTablefirst}
                \caption{}%BT modeling the plan in which the robot searches on the table first, and in the drawer only if the table search fails.
                 \label{stoch:fig:searcht}

        \end{subfigure}%
       ~ %add desired spacing between images, e. g. ~, \quad, \qquad etc.
          %(or a blank line to force the subfigure onto a new line)
        \begin{subfigure}[b]{0.5\columnwidth}
                \centering
                \includegraphics[width=0.8\columnwidth]{BTExDrawerfirst}
                \caption{}%BT modeling the plan in which the robot searches in the drawer first, and on the table only if the drawer search fails. 
                \label{stoch:fig:searchd}
        \end{subfigure}
        ~ %add desired spacing between images, e. g. ~, \quad, \qquad etc.
          %(or a blank line to force the subfigure onto a new line)
        
                        \caption{BT modeling of two plan options. In (a), the robot searches on the table first, and in the drawer only if the table search fails. In (b), the table is searched only if nothing is found in the drawer.}    
                        \label{stoch:fig:search}
\end{figure}
\end{example}
%\todopetter{Figure 9.7a looks very small}
\begin{remark}
 Note that Assumptions~\ref{stoch:ass:SBT:ac} corresponds to the return status  of the search actions in Example \ref{stoch:ex:search} behaving in a reasonable way, e.g., not switching between Success and Failure.
\end{remark}












\section{Transforming a SBT into a DTMC}
\label{stoch:sec:SBTtoDTCM}
The first step is to define, for each control flow node in $\mathcal{V}$, a vector representation of the children's outcomes and a description of its execution policy, then we map the execution into a DTMC with a direct representation of the one-step transition matrix, and finally we compute the probability of success and failure over time for each node.  

Note that the modularity of BTs comes from the recursive tree structure, any BT can be inserted as subtree in another BT.
This modularity allows us to do the analysis in a recursive fashion, beginning with the leaves of the BT, i.e. the actions and conditions which have known probabilistic parameters according to Assumptions~\ref{stoch:ass:SBT:ac} and~\ref{stoch:ass:SBT:cond}, and then progressing upwards in a scalable fashion.


 To keep track of the execution of a given flow control node,
the children outcomes  are collected in a vector state called the \emph{marking} of the node, and the transitions between markings are defined according to the execution policy of the node. 
In detail, let $\mathbf{m}(k)=[m_1(k),m_2(k),\ldots,m_N(k)]$ be a marking of a given BT node with $N$ children at time step $k$ with
\begin{equation}
m_i(k) =
	 \begin{cases} -1 &\mbox{if child $i$ returns Failure  at k}  \\
 		\hspace{8pt}1 & \mbox{if child $i$ returns Success  at k}\\
 		\hspace{8pt}0  & \mbox{otherwise} \\
 	\end{cases} 
\end{equation}
\begin{example}
\label{stoch:ex:Marking}
 Consider the BT in Figure\ref{stoch:fig:searcht}. If the first child (Search Table) has failed, and the second (Search Drawer) is currently running, the marking would be $\mathbf{m}(k)=[-1,0]$.
\end{example}
We define an \emph{event} related to a BT node when one of its children returns either Success or Failure.
Defining $\mathbf{e}_i(k)$ to be the vector associated to the event of the $i$-th running child, all zeros except the $i$-th entry which is equal to $e_i(k) \in \{-1,1\}$:
 \begin{equation}
e_i(k) = \begin{cases} -1 &\mbox{if child $i$ has failed at k}  \\
\hspace{8pt}1 & \mbox{if child $i$ has succeeeded at k.}
 \end{cases} 
\end{equation}


We would like to describe the time evolution of the node marking due to an event associated with the child $i$ as follows:
\begin{equation}
 \mathbf{m}(k+1)=\mathbf{m}(k)+\mathbf{e}_i(k)
\end{equation}
 with the event $\mathbf{e}_i(k)$ restricted to the feasible set of events at $\mathbf{m}(k)$, i.e. 
 $$\mathbf{e}_i(k) \in \mathcal{F}(\mathbf{m}(k)).$$ 
In general, $\mathcal{F}(\mathbf{m}(k)) \subset \mathcal{F}_0$, with
\begin{equation}
 \mathcal{F}_0=\{\mathbf{e}_i: \mathbf{e}_i\in \{-1,0,1\}^N, ||\mathbf{e}_i||_2=1 \},
\end{equation}
i.e. events having only one nonzero element, with value $-1$ or $1$. We will now describe the set $\mathcal{F}(\mathbf{m}(k))$ for the three different node types.

\subsubsection*{Feasibility condition in the Fallback node}
\begin{equation}
\begin{split}
\mathcal{F}_{FB}(\mathbf{m}(k))=\{\mathbf{e}_i\in  \mathcal{F}_0: & \exists i: m_i(k)=0, e_i \neq 0, \\ & m_j(k) = -1, \forall j, 0<j<i  \},
\end{split}
\end{equation}
i.e. the event of a child returning Success or Failure is only allowed if it was ticked, which only happens if it is the first child, or if all children before it have returned Failure.

\subsubsection*{Feasibility condition in the Sequence node}
\begin{equation}
\begin{split}
\mathcal{F}_{S}(\mathbf{m}(k))=\{\mathbf{e}_i\in  \mathcal{F}_0: & \exists i: m_i(k)=0, e_i \neq 0,  \\ & m_j(k) = 1, \forall j, 0<j<i  \},
\end{split}
\end{equation}
i.e. the event of a child returning Success or Failure is only allowed if it was ticked, which only happens if it is the first child, or if all children before it have returned Success.

\subsubsection*{Feasibility condition in the Parallell node}
\begin{equation}
\begin{split}
\mathcal{F}_{P}(\mathbf{m}(k))=\{\mathbf{e}_i\in  \mathcal{F}_0: 
& \exists i: m_i(k)=0, e_i \neq 0, \\
& \Sigma_{j:m_j(k)>0}m_j(k)<M \\
&  \Sigma_{j:m_j(k)<0}m_j(k)<N-M+1 \},
\end{split}
\end{equation}
i.e. the event of a child returning Success or Failure is only allowed it if has not returned yet, and the conditions for Success ($<M$ successful children) and Failure ($<N-M-1$ failed children) of the Parallel node are not yet fulfilled.

\begin{example}
Continuing Example \ref{stoch:ex:Marking} above, $\mathcal{F}(\mathbf{m}(k))=\mathcal{F}_{FB}([-1,0])=\{(0,1), (0, -1)\}$, i.e. the second child returning Success or Failure.
Note that if the first child would have returned Success, the feasible set would be empty $\mathcal{F}_{FB}([1,0])=\emptyset$.
\end{example}

%%%%
%We define an \emph{event} related to a BT node when one of its children returns either success or Failure.
%Defining $\mathbf{e}_i(k)$ to be the vector associated to the event of the $i$-th running child, all zeros except the $i$-th entry which is equal to $e_i \in \{-1,1\}$:
% \begin{equation}
%e_i = \begin{cases} -1 &\mbox{if child $i$ returns Failure}  \\
%\hspace{8pt}1 & \mbox{if child $i$ returns success.}
% \end{cases} 
%\end{equation}
%An event is \emph{feasible} only if the related children has been ticked (e.g. in a sequence node, a child $i$ can only be ticked if the previous one has succeeded, in which case there  is a feasible event associated to the child $i$), hence a transition between two markings exists if there is an associated feasible event.
%Let $\mathcal{F}(\mathbf{m}(k))$ be the set of feasible events at marking $\mathbf{m}(k)$, the marking sequence is given by $\mathbf{m}(k+1)=\mathbf{m}(k)+\mathbf{e}_i(k)$ with $\mathbf{e}_i\in \mathcal{F}(\mathbf{m}(k))$. \\
%
%\begin{example}
%Continuing the example above, $\mathcal{F}(\mathbf{m}(k))=\{(0,1), (0, -1)\}$, i.e. the second child returning success or Failure.
%\end{example}
%
%The reachability graph (RG) of a BT node can now be computed starting from the initial marking $\mathbf{m}(0)=\mathbf{0}$, taking into account all the possible event combinations that satisfy the feasibility condition.
%\subsubsection*{Feasibility condition in the Fallback node}
%An event $\mathbf{e}_i(k)$ in a fallback node is feasible if the corresponding child has not returned success or Failure and the node has not returned success/Failure yet: 
%\begin{equation}
%\begin{split}
%\mathcal{F}(\mathbf{m}(k))=\{&\mathbf{e}_1(k):{m}_{1}(k)=0 \;,\\ &\mathbf{e}_i(k):{m}_{i}(k)=0 \land {m}_{i-1}(k)=-1\}
%\end{split}
%\end{equation}
%\subsubsection*{Feasibility condition in the Sequence node}
%An event $\mathbf{e}_i(k)$ in a sequence node is feasible if the corresponding child has not returned success or Failure and the node has not returned success/Failure yet: 
%\begin{equation}
%\begin{split}
%\mathcal{F}(\mathbf{m}(k))=\{&\mathbf{e}_1(k):{m}_{1}(k)=0 \;,\\ & \mathbf{e}_i(k):{m}_{i}(k)=0 \land {m}_{i-1}(k)=1\}
%\end{split}
%\end{equation}
%\subsubsection*{Feasibility condition in the parallel node}
%An event $\mathbf{e}_i(k)$ in a parallel node with $N$ children, in which $M$ of them have to succeed, is feasible if the corresponding child has not returned success or Failure, if less than $M$ children have succeeded and if less than $N-M+1$ have failed: 
%\begin{equation}
%\begin{split}
%&\mathcal{F}(\mathbf{m}(k))= \{\mathbf{e}_i(k):m_{i}(k)=0 \; \land \displaystyle\sum_{j:m_j(k)>0}j<M \\ & \land \displaystyle\sum_{j:m_j(k)<0}j<N-M+1\}
%\end{split}
%\end{equation}
%%%

The \emph{Marking Reachability Graph} (MRG)\label{definition:RG}, see Figure \ref{stoch:app.fig.seq},
 of a BT node can now be computed starting from the initial marking $\mathbf{m}(0)=\mathbf{m}_0=\mathbf{0}^\top$, taking into account all the possible event combinations that satisfy the feasibility condition.

\begin{definition}
A marking $\mathbf{m}_{i}$ is reachable from a marking $\mathbf{m}_j$ if there exists a sequence of feasible events $\boldsymbol{\sigma}=[\sigma_1,\sigma_2,\ldots,\sigma_g]$ such that $\mathbf{m}_{i}= \mathbf{m}_{j} + \sum_{h=1}^g \sigma_h$.
\end{definition}
\begin{remark}
Note that $\mathbf{m}(k)=\mathbf{m}_i$ when $\mathbf{m}_i$ is the marking at time $k$.
\end{remark}
\begin{figure}[h]
\centering
\includegraphics[width=1\columnwidth ]{RGseq.pdf}
\caption{MRG of the Sequence node (rectangles) with $N$ children and its DTMC representation (circles).}
\label{stoch:app.fig.seq}
\end{figure}
\begin{figure}[h]
\centering
\includegraphics[width=1\columnwidth ]{RGsel.pdf}
\caption{MRG of the Fallback node (rectangles) with $N$ children and its DTMC representation (circles).}
\label{stoch:app.fig.sel}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=1\columnwidth ]{RGHybPar.pdf}
\caption{MRG of the Parallel node (rectangles) with $2$ children and its DTMC representation (circles).}
\label{stoch:app.fig.par}
\end{figure}

\subsection{Computing Transition Properties of the DTMC}
The MRG of a BT node comprises all the reachable markings, the transitions between them describe events which have a certain success/failure probability.  We can then map the node execution to a DTMC where the states are the markings in the MRG and the one-step transition matrix $P$ is given by the probability of jump between markings, with off diagonal entries defined as follows:

\begin{equation}
p_{ij}=
   \begin{cases}
   \tilde p_{sh} & \!\!\!\text{if } \mathbf{m}_j-\mathbf{m}_i\in \mathcal{F}(\mathbf{m}_i) \land  e_h\mathbf{e}_h^T(\mathbf{m}_j-\mathbf{m}_i)>0\\
   \tilde p_{fh} & \!\!\!\text{if } \mathbf{m}_j-\mathbf{m}_i\in \mathcal{F}(\mathbf{m}_i) \land  e_h\mathbf{e}_h^T(\mathbf{m}_j-\mathbf{m}_i)<0\\
   0 & \!\!\!\text{otherwise}
  \end{cases} 
\end{equation}
and diagonal entries defined as:
\begin{equation}
p_{ii}=1-\sum_{j}p_{ij}. 
\end{equation}
 with:
\begin{equation}
\tilde p_{sh} = \frac{p_{sh} \mu_h \nu_h}{p_{fh} \mu_h + p_{sh}\nu_h} \cdot \left( \sum_{j: \mathbf{e}_j \in \mathcal{F}(\mathbf{m}_i)} \frac{\mu_j \nu_j}{p_{fj} \mu_j + p_{sj}\nu_j} \right)^{-1}
\end{equation} 
and

\begin{equation}
\tilde p_{fh} = \frac{p_{fh} \mu_h \nu_h}{p_{fh} \mu_h + p_{sh}\nu_h} \cdot \left( \sum_{j: \mathbf{e}_j \in \mathcal{F}(\mathbf{m}_i)} \frac{\mu_j \nu_j}{p_{fj} \mu_j + p_{sj}\nu_j} \right)^{-1}
\end{equation} 
%\begin{equation}
%p_{ij}=
%   \begin{cases}
%   p_{sk} & \!\!\!\text{if } \mathbf{m}_j-\mathbf{m}_i\in \mathcal{F}(\mathbf{m}_i) \land  \mathbf{1}^T(\mathbf{m}_j-\mathbf{m}_i)>0\\
%   p_{fk} & \!\!\!\text{if } \mathbf{m}_j-\mathbf{m}_i\in \mathcal{F}(\mathbf{m}_i) \land  \mathbf{1}^T(\mathbf{m}_j-\mathbf{m}_i)<0\\
%   0 & \!\!\!\text{otherwise}
%  \end{cases} 
%\end{equation}
%\begin{equation}
%p_{ij}(k)=
%   \begin{cases}
%   p_{sj}(k) & \!\!\!\text{if } {m}_j(k)-{m}_i(k)=1	\land \mathbf{e}_i\!\in \mathcal{F}(\mathbf{m}_i(k))\\
%   p_{fj}(k) & \!\!\!\text{if } {m}_i(k)-{m}_j(k)=1\land \mathbf{e}_i \! \in \mathcal{F}(\mathbf{m}_i(k))\\
%   0 & \!\!\!\text{otherwise}
%  \end{cases} 
%\end{equation}
where $p_{sj}$ and $p_{fj}$ is the $p_{s}$ and $p_{f}$ of child $j$.

\begin{remark}
For Sequence and Fallback nodes the following holds: $\tilde p_{sh}=p_{sh}$ and $\tilde p_{fh}=p_{fh}$.
\end{remark}
In Figures.~\ref{stoch:app.fig.seq} and~\ref{stoch:app.fig.sel} the mapping from MRG to a DTCM related to a Sequence node and a Fallback node are shown. In Figure~\ref{stoch:app.fig.par} the mapping for a Parallel node with two children and $M=2$ is shown. We choose not to depict the mapping of a general Parallel node, due to its large amount of states and possible transition between them.

To obtain the continuous time probability vector $\pi(t)$ we need to compute the infinitesimal generator matrix $Q$ associated with the BT node. For doing so we construct a CTMC for which the EMC is the DTMC of the BT node above computed. According to~\eqref{stoch:bg.eq.infGen} the map from the EMC and the related CTMC is direct, given the average sojourn times $SJ_i$. 
\section{Reliability of a SBT}
\label{stoch:sec:reli}
\subsection{Average sojourn time}
We now compute the average sojourn time of each marking $\mathbf{m}_i$ of a BT node. 
\begin{lemma}
For a BT node with $p_{si},p_{fi}, \mu_i,\nu_i$ given for each child, the average sojourn time of in a marking $\mathbf{m}_i$ is:
%The mean sojourn time is:
\begin{equation}
SJ_i =\left(   \displaystyle\sum_{h:\mathbf{e}_h\in \mathcal{F}(\mathbf{m}_i)} \left(\frac{p_{sh}}{\mu_h}+\frac{p_{fh}}{\nu_h}\right)^{-1}     \right)^{-1}
\label{stoch:app.eq.sj}
\end{equation}  
with $h: \mathbf{e}_h \in \mathcal{F}(\mathbf{m}_i)$.

\end{lemma}
\begin{proof}

In each marking one of the following occur: the running child $h$ fails or succeeds. To take into account both probabilities and time rates, that influence the average sojourn time, we describe the child execution using an additional CTMC, depicted in Figure~\ref{stoch:app.fig.sjmc}

\begin{figure}[h]
\centering
\includegraphics[width=0.6\columnwidth ]{SJCTMC.pdf}
\caption{CTMC of a child's execution.}
\label{stoch:app.fig.sjmc}
\end{figure}
According to~\eqref{stoch:BG.eq.meansj} the average sojourn time is: 
\begin{equation}
\tau_i=\frac{p_{fh} \mu_h + p_{sh}\nu_h } {\nu_h\mu_h } = \frac{p_{sh}}{\mu_h}+\frac{p_{fh}}{\nu_h}
\end{equation}
and the rate of leaving that state is ${\tau_i}^{-1}$.
Now to account all the possible running children outcome, e.g. in a Parallel node, we consider all the rates associate to the running children. The rate of such node is the sum of all the rates associated to the running children ${\tau_i}^{-1}$. Finally, the average sojourn time of a marking $\mathbf{m}_i$ is given by the inverse of the combined rate:
\begin{equation}
\frac{1}{ SJ_i }= \displaystyle \sum_{h:\mathbf{e}_h\in \mathcal{F}(\mathbf{m}_h)} \frac{1}{\frac{p_{sh}}{\mu_h}+\frac{p_{fh}}{\nu_h}}
\end{equation}
from which we obtain~\eqref{stoch:app.eq.sj}.
\end{proof}
\begin{remark}
The EMC associated with the CTMC in Figure~\ref{stoch:app.fig.sjmc} is depicted in Figure~\ref{stoch:app.fig.dsjmc}. It describes the child's execution as a DTMC.
\end{remark}
\begin{figure}[h]
\centering
\includegraphics[width=0.45\columnwidth ]{SJDTMC.pdf}
\caption{DTMC of a child's execution.}
\label{stoch:app.fig.dsjmc}
\end{figure}

%Note that an example of the application of this Lemma can be found in Section~\ref{stoch:sec:numerical_results}, Equation \eqref{stoch:app.eq.exSj}.

\subsection{Mean Time To Fail and Mean Time To Succeed}
%Since we are interested in differentiating between time to succeed/fail we make a computation similar to the MTTA made in Section~\ref{stoch:sec:background}.
To derive a closed form of the mean time to fail MTTF/MTTS of a BT node, we take the probability to reach a success/failure state from the DTCM and the average time spent in each state visited before reaching this state obtained from~\eqref{stoch:app.eq.sj}.
We rearrange the state space of the DTMC so that the initial state is first, the other transient states are second, the failure states are second last and the success states are last:
\begin{equation}
P_c^\top=\left[
\begin{array}{ccc}
T & {0}& {0} \\ 
R_F & \mathbb{I} & {0} \\
R_S & {0} & \mathbb{I} 
\end{array} \right]
\label{stoch:Example.eq.MTTSform}
\end{equation}
where $T$ is the matrix describing the one-step transition from a transit state to another one, $R_F$ is a the matrix describing the one-step transition from a transit state to a failure state, and $R_S$ is the matrix describing the one-step transition from a transit state to a success state. We call this rearrangement the \emph{canonization} of the state space. 

%An example computation of $P_c^\top$ can be found in Section~\ref{stoch:sec:numerical_results}, Equation \eqref{stoch:app.eq.MTTSform}.

\begin{lemma}
Let $A$ be a matrix with the $ij$-th entry defined as $\exp(t_{ij})$ where $t_{ij}$ is the time needed to transit from a state $j$ to a state $i$ if $j,i$ are neighbors in the MRG, $0$ otherwise. 
The MTTF and MTTS of the BT node can be computed as follows
\begin{equation}
MTTF=\frac{\sum_{i=1}^{\left\vert{\mathcal{S}_F}\right\vert} u^F_{i1}\mbox{log}(h^F_{i1})}{\sum_{i=1}^{\left\vert{\mathcal{S}_F}\right\vert}u^F_{i1}}
\label{stoch:main.eq.mttf}
\end{equation}
where:
\begin{equation} 
H^F\triangleq A_F \sum_{i=0}^{\infty} A_T^i.
\label{stoch:main.eq.hf}
\end{equation}
and
\begin{equation}
MTTS=\frac{\sum_{i=1}^{\left\vert{\mathcal{S}_S}\right\vert} u^S_{i1}\mbox{log}(h^S_{i1})}{\sum_{i=1}^{\left\vert{\mathcal{S}_S}\right\vert}u^S_{i1}}
\label{stoch:main.eq.mtts}
\end{equation}
where:
\begin{equation} 
H^S \triangleq A_S \sum_{i=0}^{\infty} A_T^i
\label{stoch:main.eq.hs}
\end{equation}
where $A_T$, $A_F$, and $A_S$ are the submatrices of $A$ corresponding to the canonization described in~\eqref{stoch:Example.eq.MTTSform}, for which the following holds:
\begin{equation}
 A=\left[
\begin{array}{ccc}
A_T & {0}& {0} \\ 
A_F & {0} & {0} \\
A_S & {0} & {0} 
\end{array} \right].
\label{stoch:main.eq.A}
\end{equation}


\end{lemma}

\begin{proof}
Failure and success states are absorbing, hence we focus our attention on the probability of leaving a transient state, described by the matrix $U$, defined below:

\begin{equation}
U=\sum_{k=0}^\infty  T^i,
\label{stoch:bg.eq.u}
\end{equation}
Thus, considering $i$ as the initial transient state, the entries $u_{ij}$ is the mean number of visits of $j$ starting from $i$ before 
being absorbed, we have to distinguish the case in which the absorbing state is a failure state from the case in which it is a success state:
\vspace{-8pt}
\begin{eqnarray} 
U^F\triangleq R_F U
\label{stoch:mtt.eq.uf} \\
 U^S\triangleq R_S U .
\label{stoch:mtt.eq.us} 
\end{eqnarray}
Equations~\eqref{stoch:mtt.eq.uf} and~\eqref{stoch:mtt.eq.us} represent the mean number of visits before being absorbed in a failure or success state respectively.

To derive MTTF/MTTS we take into account the mean time needed to reach every single failure/success state with its probability, normalized over the probability of reaching any failure (success) state, starting from the initial state. Hence we sum the probabilities of reaching a state starting from the initial one, taking into account only the first column of the matrices obtaining \eqref{stoch:main.eq.mttf} and \eqref{stoch:main.eq.mtts}.
\end{proof}
\begin{remark}
Since there are no self loops in the transient state of the DTMC above, the matrix $T$ is nilpotent. Hence $u_{ij}$ is finite $\forall i,j$.
\end{remark}

\subsection{Probabilities Over Time} 
Since all the marking of a BT node have a non null corresponding average sojourn time, the corresponding DTMC is a EMC of a CTMC with infinitesimal generator matrix $Q(t)$ as defined in \eqref{stoch:bg.eq.infGen}. Hence, we can compute the probability distribution over time of the node according to~\eqref{stoch:bg.eq.cauchy} with the initial condition $\pi_0=[1 \;\mathbf{0}]^\top$ that represents the state in which none of the children have returned Success/Failure yet.

%An example computation of $Q(t)$ can be found in Section~\ref{stoch:sec:numerical_results}, Equation \eqref{stoch:app.eq.exQ}.

\subsection{Stochastic Execution Times}

\begin{proposition}
Given a SBT, with known probabilistic parameters for actions and conditions, we can compute probabilistic measures for the rest of the tree as follows:
For each node whose children have known probabilistic measures we compute the related DTMC. Now the probability of a node to return Success $p_s(t)$ (Failure $p_f(t)$) is given by the sum of the probabilities of the DTMC of being in a success (failure) state.
Let $\mathcal{S}_S\subset \mathcal{S}_A$, and $\mathcal{S}_F\subset \mathcal{S}_A$ be the set of the success and failure states respectively of a DTMC related to a node, i.e. those states representing a marking in which the node returns Success or Failure, with $\mathcal{S}_F \cup \mathcal{S}_S =\mathcal{S}_A$ and $\mathcal{S}_F \cap \mathcal{S}_S =\emptyset$. 

Then we have
\begin{eqnarray}
\bar p_s(t)=\displaystyle \sum_{i:s_i\in \mathcal{S}_S} \pi_i(t) \label{stoch:main.eq.ps} \\
\bar p_f(t)=\displaystyle \sum_{i:s_i\in \mathcal{S}_F} \pi_i(t)
\end{eqnarray}
where $\pi(t)$ is the probability vector of the DTMC related to the node (i.e. the solution of~\eqref{stoch:bg.eq.cauchy}). 
The time to succeed (fail) for a node is given by a random variable with exponential distribution 
and rate given by the inverse of the MTTS (MTTF) since for such random variables the mean time is given by the inverse of the rate.
\begin{eqnarray}
\mu=MTTS^{-1}\\
\nu=MTTF^{-1}
\label{stoch:main.eq.nu}
\end{eqnarray}
\end{proposition}
\begin{remark}
Proposition~\ref{stoch:main.eq.nu} holds also for deterministic and hybrid BTs, as \eqref{stoch:bg.eq.cauchy} has a unique solution in the Carath\'eodory sense~\cite{filippov1988differential}.

\end{remark}
\subsection{Deterministic Execution Times}
%\subsection{Analytical solution of deterministic nodes' probabilities}
\label{stoch:PS.numdet}

%\todo[inline]{Is it true that Prop 1 hold also for this case, but might lead to numerical difficulties?}

As the formulation of the deterministic case involves Dirac delta functions, see Equation (\ref{stoch:eq:d1})-(\ref{stoch:eq:d2}), the approach described above might lead to computational difficulties.
As an alternative, we can take advantage of the fact that we know the exact time of possible transitions.
%In case of deterministic actions, the success and failure probabilities calculation of their parent node involves discontinuous functions (i.e. Dirac's delta functions). This might entail numerical problems and the analytic solution of~\eqref{stoch:bg.eq.cauchy} might have intractable complexity. 
%On the other hand we can take advantage of the deterministic attributes which give the exact moment when an action can succeed or fail. 
Thus, the success and failure probabilities of a deterministic node are unchanged in the intervals between the $MTTF$ and $MTTS$ of its children. 

\begin{example}
 Consider the BT 
\begin{equation}
\mathcal{T}=\mbox{Fallback}(\mathcal{A}_1,\mathcal{A}_2)
\end{equation}
depicted in Figure~\ref{stoch:res.fig.BTdet} and let $\tau_{Fi}$ ($\tau_{Si}$) be the $MTTF$ ($MTTS$) of action $i$ and $p_{fi}$ ($p_{si}$) its probability to fail (succeed). The success/failure probability over time of the tree $\mathcal{T}$ is a discontinuous function depicted in Figure~\ref{stoch:res.fig.probdet}. 
\end{example} 

\begin{figure}[h]
\centering
\includegraphics[width=0.5\columnwidth]{fallbackDet.pdf}
\caption{Example of a Fallback node with two deterministic actions/subtrees.}
\label{stoch:res.fig.BTdet}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=0.8\columnwidth]{fallbackDetProb.pdf}
\caption{Failure (red, lower) and success (green, upper) probability of the deterministic node of example. The running probability is the complement of the other two (not shown). 
%\todo[inline]{$p_{s1}+p_{f1}p_{s2}$  at top green line?. DONE \emph{Michele}}
}
\label{stoch:res.fig.probdet}
\end{figure}

Hence the success and failure probability have discrete jumps over time. These piece-wise continuous functions can be described by the discrete time system~\eqref{stoch:bg.eq.discrete} introducing the information of the time when the transitions take place, which is more tractable than directly solving~\eqref{stoch:bg.eq.cauchy}. Then, the calculation of $\pi(t)$ is given by a zero order hold of the discrete solution.

\begin{proposition}
\label{stoch:ps.prop.det}
Let $P$ be the one-step transition matrix given in Definition~\ref{stoch:bg.def.p} and let $\tau_{Fi}$ ($\tau_{Si}$) be the time to fail (succeed) of action $i$ and $ p_{fi}$ ($  p_{si}$) its probability to fail (succeed). Let $\tilde \pi(\tau)=[\tilde \pi_1(\tau),\ldots, \tilde \pi_{\left\vert{\mathcal{S}}\right\vert}(\tau)]^\top$, where $ \tilde \pi_i(\tau)$ is the probability of being in a marking $\mathbf{m}_i$ at time $\tau$ of a MRG representing a deterministic node with $N$ children, let $\tilde P(\tau)$ be a matrix which entries $\tilde p_{ij}(\tau)$ are defined as:
\begin{equation}
\tilde p_{ij}(\tau) = \begin{cases} p_{ij} \cdot \delta(\tau-(log (\tilde a_{j1})) &\mbox{if } i\neq j \\ 
1- \displaystyle\sum_{k \neq i} \tilde p_{ik} & \text{otherwise}  \end{cases} 
\label{stoch:ps.eq.ptilde}
\end{equation}
with $\tilde a_{ij}$ the $ij$-th entry of the matrix $\tilde A$ defined as:
\begin{equation}
\tilde A \triangleq \sum_{i=0}^{\infty} A^i
\label{stoch:ps.eq.atilde}
\end{equation}
with $A$ as defined in~\eqref{stoch:main.eq.A}.

Then the evolution of $ \tilde \pi(k)$ process can be described as a discrete time system with the following time evolution:
\begin{equation}
\label{stoch:tildepi}
\tilde \pi(\tau +{\Delta \tau}) = \tilde P(\tau)^\top\tilde \pi(\tau) 
\end{equation}
where $\Delta \tau$ is the common factor of $\{\tau_{F1},\tau_{S1},\tau_{F2},\tau_{S2},\ldots,\tau_{FN},\tau_{SN}\}$
Then for, deterministic nodes, given $\tilde \pi(\tau)$ the probability over time is given by:
\begin{equation}
\label{stoch:ps.eq.pdet}
\pi(t) = \mbox{ZOH}(\tilde \pi(\tau))
\end{equation}
where ZOH is the zero order hold function.
\end{proposition}
\begin{proof}
The proof is trivial considering that \eqref{stoch:tildepi} is a piece-wise constant function and $\Delta \tau$ is the common faction of all the step instants.
\end{proof}


\section{Examples}
\label{properties:sec:example:reliability}
In this section, we present three examples.
The first  example is the BT in Figure~\ref{stoch:Example.Tree}, which is fairly small and allows us to show the details of each step.
The second example is the deterministic time version of the same BT, illustrating the differences between the two cases.
The third example involves a more complex BT, shown in Figure \ref{stoch:res.fig.BT}.
This example will be used to verify the approach numerically, by performing Monte Carlo simulations and comparing the numeric results to the analytical ones, see Table \ref{stoch:res.tab.param} and Figure \ref{stoch:res.fig.comparisondet}. It is also used to illustrate the difference in performance metrics, between two equivalent BTs, see Figure \ref{stoch:res.fig.comparison}.


%Two examples, one small that is solved in detail, and a more complex one, see Section~\ref{stoch:sec:numerical_results}, are now presented.
We will now carry out the computation of probabilistic parameters for an example SBT.
\label{stoch:Example.computed}
\begin{figure}
        \centering
        \begin{subfigure}[b]{0.4\columnwidth}
                \centering
                \includegraphics[width=\columnwidth]{BTMTTEx.pdf}
                \caption{BT of example.}
                \label{stoch:Example.Tree}
        \end{subfigure}%
        ~ %add desired spacing between images, e. g. ~, \quad, \qquad etc.
          %(or a blank line to force the subfigure onto a new line)
        \begin{subfigure}[b]{0.6\columnwidth}
                \centering
                \includegraphics[width=\columnwidth]{MCMTTEx.pdf}
                \caption{Markov Chain.}   
                \label{stoch:Example.MC}           
        \end{subfigure}
        ~ %add desired spacing between images, e. g. ~, \quad, \qquad etc.
          %(or a blank line to force the subfigure onto a new line)
        \caption{BT and related DTMC modeling the plan of Example~\ref{stoch:Example.computed}.}
\end{figure}
\begin{example}
Given the tree shown in Figure~\ref{stoch:Example.Tree}, its probabilistic parameters are given by evaluating the Fallback node, since it is the child of the root node. The given PDF of the $i$-th action are:
\begin{eqnarray}
 \hat p_s(t)&=& p_{s_i} \mu e^{-\mu_i t}\\
  \hat p_f(t)&=& p_{f_i} \nu e^{-\nu_i t}
\end{eqnarray}
where:
\begin{itemize}
\item $p_{f_i}$ probability of failure
\item $p_{s_i}$ probability of success
\item $\nu_i$ failure rate
\item $\mu_i$ success rate
\end{itemize}
The DTMC related as shown in Figure~\ref{stoch:Example.MC} has $\mathcal{S}=\{s_1,s_2,s_3,s_4,s_5,s_6,s_7\}$, $\mathcal{S}_F =\{s_4\}$ and $\mathcal{S}_S =\{s_5,s_6,s_7\}$. 
 
According to the canonization in \eqref{stoch:Example.eq.MTTSform}, the one-step transition matrix is:
\begin{equation}
\label{stoch:app.eq.MTTSform}
 P_c^\top=\left[
\begin{array}{ccccccc}
0 & 0 & 0 & 0 & 0 & 0 & 0 \\ 
p_{f_1} & 0 & 0 & 0 & 0 & 0 & 0 \\ 
0 & p_{f_2} & 0 & 0 & 0 & 0 & 0 \\ 
0 & 0 & p_{f_3} & 1 & 0 & 0 & 0 \\ 
p_{s_1} & 0 & 0 & 0 & 1 & 0 & 0 \\ 
0 & p_{s_2} & 0 & 0 & 0 & 1 & 0 \\ 
0 & 0 & p_{s_3} & 0 & 0 & 0 & 1
\end{array} \right]
\end{equation}

According to \eqref{stoch:app.eq.sj} the average sojourn times are collected in the following vector
\begin{equation}
\label{stoch:app.eq.exSj}
SJ =\left[\begin{array}{c c c}
\frac{p_{s_1}}{\mu_1}+\frac{p_{f_1}}{\nu_1},&\frac{p_{s_2}}{\mu_2}+\frac{p_{f_2}}{\nu_2},&\frac{p_{s_3}}{\mu_3}+\frac{p_{f_3}}{\nu_3} 
\end{array}\right]
\end{equation}

The infinitesimal generator matrix is defined, according to~\eqref{stoch:bg.eq.infGen}, as follows:
\begin{equation}
\label{stoch:app.eq.exQ}
\setlength\arraycolsep{3pt}
Q=\left[
\begin{array}{ccccccc}
\frac{-\mu_1 \nu_1 }{p_{s_1}\nu_1+p_{f_1}\mu_1} & \scriptstyle{0} & \scriptstyle{0}  & \scriptstyle{0}  & \scriptstyle{0}  & \scriptstyle{0}& \scriptstyle{0}  \\[1ex]
\frac{\mu_1 \nu_1 p_{f_1} }{p_{s_1}\nu_1+p_{f_1}\mu_1} & \frac{-\mu_2 \nu_2 }{p_{s_2}\nu_2+p_{f_2}\mu_2} & \scriptstyle{0}  & \scriptstyle{0}  & \scriptstyle{0}  & \scriptstyle{0}  & \scriptstyle{0}  \\ [1ex]
\scriptstyle{0}  & \frac{\mu_2 \nu_2 p_{f_2} }{p_{s_2}\nu_2+p_{f_2}\mu_2} & \frac{-\mu_3 \nu_3 }{p_{s_3}\nu_3+p_{f_3}\mu_3} & \scriptstyle{0}  & \scriptstyle{0}  & \scriptstyle{0}  & \scriptstyle{0}  \\ [1ex]
\scriptstyle{0}  & \scriptstyle{0}  & \frac{\mu_3 \nu_3 p_{f_3} }{p_{s_3}\nu_3+p_{f_3}\mu_3} & \scriptstyle{0}  & \scriptstyle{0}  & \scriptstyle{0}  & \scriptstyle{0}  \\ 
\frac{\mu_1 \nu_1 p_{s_1} }{p_{s_1}\nu_1+p_{f_1}\mu_1} & \scriptstyle{0}  & \scriptstyle{0}  & \scriptstyle{0}  & \scriptstyle{0}  & \scriptstyle{0}  & \scriptstyle{0}  \\ 
\scriptstyle{0}  & \frac{\mu_2 \nu_2 p_{s_2} }{p_{s_2}\nu_2+p_{f_2}\mu_2} & \scriptstyle{0}  & \scriptstyle{0}  & \scriptstyle{0}  & \scriptstyle{0}  & \scriptstyle{0}  \\ 
\scriptstyle{0}  & \scriptstyle{0}  & \frac{\mu_3 \nu_3 p_{s_3} }{p_{s_3}\nu_3+p_{f_3}\mu_3} & \scriptstyle{0}  & \scriptstyle{0}  & \scriptstyle{0}  & \scriptstyle{0} 
\end{array} \right].
\end{equation}
%We choose as initial probability the vector $$\pi_0=\left[\begin{array}{ccccccc}
%1 & 0 & 0 & 0 & 0 & 0 & 0
%\end{array} \right]^\top$$ describing the realistic case in which none of the BT actions have been ticked yet.
The probability vector, according to~\eqref{stoch:bg.eq.cauchy}, is given by:
\begin{equation}
\pi(t)=\left[\begin{array}{ccccccc}
\pi_1(t)&\!\!\!\pi_2(t)&\!\!\!\pi_3(t)&\!\!\!\pi_4(t)&\!\!\!\pi_5(t)&\!\!\!\pi_6(t)&\!\!\!\pi_7(t)
\end{array}\right]^\top
\end{equation}
%where $\mathcal{L}(\cdot)$ is the Laplace transform %and $\mathcal{L}^{-1}(\cdot)$ its inverse. Note %that in this example $\mathcal{L}(Q(t))=Q(t)=Q$.
%\\
We can now derive closed form expression for MTTS and MTTF.
Using the decomposition in~\eqref{stoch:Example.eq.MTTSform}, the matrices computed according \eqref{stoch:mtt.eq.us} and~\eqref{stoch:mtt.eq.uf} are:
\begin{eqnarray}
 U^S&=\left[
\begin{array}{ccc}
p_{s_1} &     0	 & 0 \\ 
p_{f_1}  p_{s_2} &    p_{s_2}&   0\\ 
p_{f_1} p_{f_2} p_{s_3}& p_{f_2} p_{s_3} & p_{s_3}
\end{array} \right]
\\
 U^F&=\left[
\begin{array}{ccc}
 p_{f_1}p_{f_2}p_{f_3}& p_{f_2}p_{f_3} & p_{f_3}
\end{array} \right]
\end{eqnarray}
Note that $U^S$ is a  $3 \times 3$ matrix and $U^S$ is a $1 \times 3$ matrix since there are $3$ transient states, $3$ success state and $1$ failure state.
For action $i$ we define $t_{f_i}= \nu_i^{-1}$ the time to fail and $t_{s_i}= \mu_i^{-1}$ the time to succeed. The non-zero entries of the matrix given by~\eqref{stoch:main.eq.A} are:
\begin{equation}
\begin{split}
a_{2,1}={e}^{t_{f_1}}\;\;\;a_{3,2}={e}^{t_{f_2}}\;\;\;a_{4,3}={e}^{t_{f_3}} \\
a_{5,1}={e}^{t_{s_1}}\;\;\;a_{6,2}={e}^{t_{s_2}}\;\;\;a_{7,3}={e}^{t_{s_3}}
\end{split}
\end{equation}
from which we derive~\eqref{stoch:main.eq.hf} and~\eqref{stoch:main.eq.hs} as:
\begin{eqnarray}
  H^S&=\left[
\begin{array}{ccc}
e^{t_{s_1}}&                0 &        0 \\
e^{t_{f_1}}e^{t_{s_2}}&          e^{t_{s_2}}&        0\\
 e^{t_{f_1}}e^{t_{f_2}}e^{t_{s_3}}& e^{t_{f_2}}e^{t_{s_3}}& e^{t_{s_3}}
\end{array} \right]
\\
  H^F&=\left[
\begin{array}{ccc}
 e^{t_{f_1}}e^{t_{f_2}}e^{t_{f_3}}& e^{t_{f_2}}e^{t_{f_3}}& e^{t_{f_3}}
\end{array} \right]
\end{eqnarray}
Using \eqref{stoch:main.eq.mttf} and~\eqref{stoch:main.eq.mtts} we obtain the MTTS and MTTF. 
%\begin{eqnarray}
%MTTS\!\!=\!\!\!\!\!\!&\frac{p_{s_1}t_{s_1}+p_{f_1}p_{s_2}(t_{f_1}+t_{s_2})+p_{f_1}p_{f_2}p_{s_3}(t_{f_1}+t_{f_2}+t_{s_3})}{p_{s_1}+p_{f_1}p_{s_2}+p_{f_1}p_{f_2}p_{s_3}}\\
%MTTF\!\!=\!\!\!\!\!\!&\frac{p_{f_1}p_{f_2}p_{f_3}(t_{f_1}+t_{f_2}+t_{f_3})}{p_{f_1}p_{f_2}p_{f_3}}
%\end{eqnarray}
Finally, the probabilistic parameters of the tree are expressed in a closed form according to \eqref{stoch:main.eq.ps}-\eqref{stoch:main.eq.nu}:
\begin{eqnarray}
\bar p_s(t)=\!\!\!&\pi_5(t)+\pi_6(t)+\pi_7(t) \\
\bar p_f(t)=\!\!\!&\pi_4(t) \\
\mu=\!\!\!&\frac{p_{s_1}+p_{f_1}p_{s_2}+p_{f_1}p_{f_2}p_{s_3}}{p_{s_1}t_{s_1}+p_{f_1}p_{s_2}(t_{f_1}+t_{s_2})+p_{f_1}p_{f_2}p_{s_3}(t_{f_1}+t_{f_2}+t_{s_3})}\\
\nu=\!\!\!&\frac{1}{t_{f_1}+t_{f_2}+t_{f_3}}
\end{eqnarray}

\end{example}

\begin{example}
Consider the BT given in Example~\ref{stoch:Example.computed}, we now compute the performances in case when the actions are all deterministic.

The computation of MTTF and MTTS follows from Example~\ref{stoch:Example.computed}, whereas the computation of $\pi(t)$ can be made according to Proposition~\ref{stoch:ps.prop.det}.

According to~\eqref{stoch:ps.eq.atilde} the matrix $\tilde A$ takes the form below

\begin{equation}
 \tilde A=\left[
\begin{array}{ccccccc}
0 & 0 & 0 & 0 & 0 & 0 & 0 \\ 
 e^{t_{f_1}} & 0 & 0 & 0 & 0 & 0 & 0 \\ 
 e^{t_{f_1}} e^{t_{f_2}}& e^{t_{f_2}} & 0 & 0 & 0 & 0 & 0 \\ 
 e^{t_{f_1}}e^{t_{f_2}} e^{t_{f_3}} & e^{t_{f_2}} e^{t_{f_3}} & e^{t_{f_3}} & 0 & 0 & 0 & 0 \\ 
e^{t_{s_1}} & 0 & 0 & 0 & 0 & 0 & 0 \\ 
 e^{t_{f_1}}e^{t_{s_2}} & e^{t_{s_2}} & 0 & 0 & 0 & 0 & 0 \\ 
 e^{t_{f_1}}e^{t_{f_2}}e^{t_{s_3}} & e^{t_{f_2}}e^{t_{s_3}} & e^{t_{s_3}} & 0 & 0 & 0 & 0
\end{array} \right]
\end{equation}
thereby, according to~\eqref{stoch:ps.eq.ptilde}, the modified one step transition matrix takes the form of
Figure~\ref{stoch:eq:largefig},
\begin{landscape}
\begin{figure}\centering
\setlength{\tabcolsep}{1em}
\vfill\hfill $\tiny
%\vfill\hfill $\scriptsize
\left[
\begin{array}{ccccccc}
1-(p_{f_1}\delta(t\minus{}t_{f_1})\plus{}p_{s_1}\delta(t\minus{}t_{s_1})) & 0 & 0 & 0 & 0 & 0 & 0 \\ 
p_{f_1}\delta(t\minus{}t_{f_1}) & 1-(p_{f_2}\delta(t\minus{}(t_{f_1}\plus{}t_{f_2}))\plus{}p_{s_2}\delta(t\minus{}(t_{f_1}\plus{}t_{s_2}))) & 0 & 0 & 0 & 0 & 0 \\ 
0 & p_{f_2}\delta(t\minus{}(t_{f_1}\plus{}t_{f_2})) & 1-(p_{f_3}\delta(t\minus{}(t_{f_1}\plus{}t_{f_2}\plus{}t_{f_3}))\plus{}p_{s_3}\delta(t\minus{}(t_{f_1}\plus{}t_{f_2}\plus{}t_{s_3}))) & 0 & 0 & 0 & 0 \\ 
0 & 0 & p_{f_3}\delta(t\minus{}(t_{f_1}\plus{}t_{f_2}\plus{}t_{f_3})) & 1 & 0 & 0 & 0 \\ 
p_{s_1}\delta(t\minus{}t_{s_1}) & 0 & 0 & 0 & 1 & 0 & 0 \\ 
0 & p_{s_2}\delta(t\minus{}(t_{f_1}\plus{}t_{s_2})) & 0 & 0 & 0 & 1 & 0 \\ 
0 & 0 & p_{s_3}\delta(t\minus{}(t_{f_1}\plus{}t_{f_2}\plus{}t_{s_3})) & 0 & 0 & 0 & 1
\end{array} \right]$ 
\vfill
 \captionsetup{justification=centering}
\caption{Modified one step transition matrix $\tilde P^\top$.}
 \label{stoch:eq:largefig}
\end{figure}
\end{landscape}
and the probability vector $\pi(t)$ is given by~\eqref{stoch:ps.eq.pdet}.
\end{example}



Below we present a more complex example, extending Example~\ref{stoch:Example.computed} above.
We use this example for two purposes, first, to verify the correctness of the proposed approach  using Monte Carlo simulations, and second, to illustrate how changes in the SBT lead to different performance metrics.
%end of blue
% \textcolor{blue}{and we show how the action sequence affects the BT performance}.
%Using this example, we can verify the analytical estimates given by the proposed approach by doing extensive Monte Carlo simulations.
%We can also illustrate what kind of results the proposed approach can give. 

\begin{example}
\label{stoch:PS.ex.complex}
The task given to a two armed robot is to find and collect objects which can be found either on the floor, in the drawers or in the closet. The time needed to search for a desired object on the floor is less than the time needed to search for it in the drawers, since the latter has to be reached and opened first. On the other hand, the object is more likely to be in the drawers than on the floor, or in the closet. Moreover, the available policies for picking up objects are the one-hand and the two-hands grasps. The one-hand grasp most likely fails, but it takes less time to check if it has failed or not. Given these options, the task can be achieved in different ways, each of them corresponding to a different performance measure.
The plan chosen for this example is modeled by the SBT shown in Figure~\ref{stoch:res.fig.BT}. 

The performance estimates given by the proposed approach for the whole BT, as well as for two sub trees can be seen in Figures~\ref{stoch:res.fig.7}-\ref{stoch:res.fig.35} .
\end{example}




\begin{figure}[h]
\centering
\includegraphics[width=\columnwidth]{BTExample.pdf}
\caption{BT modeling the search and grasp plan. The leaf nodes are labeled with a text, and the control flow nodes are labeled with a number, 
for easy reference.}
\label{stoch:res.fig.BT}
\end{figure}


We also use the example above to verify the correctness of the analytical estimates, and the results  can be seen in Table~\ref{stoch:res.tab.param}.
We compared the analytical solution derived using our approach with  numerical results given by a massive Monte Carlo simulation carried out using a BT implementation in the Robot Operative System (ROS)~\cite{Marzinotto14} where actions and conditions are performed using ROS nodes with outcomes computed using the \verb!C++! 
random number generator with exponential distribution. The BT implementation in ROS was run approximately 80000 times to have enough samples to get numerical averages close to the true values.
For each run we stored if the tree (and some subtrees) succeeded or failed and how long it took, allowing us to estimate $\mu$, $\nu$, $p_s(t)$, $p_f(t)$ experimentally. The match is reported in Figures~\ref{stoch:res.fig.7}-\ref{stoch:res.fig.35} and in Table~\ref{stoch:res.tab.times}. 
As can be seen, all estimates are within  0.18 \% of the analytical results.
%This method shows how analytical and numerical results matches, avoiding the sensitiveness of the latter to probabilistic measures.\\



\begin{table}[h]
\centering
  \begin{tabular}{| l | c | c | c |}\hline
    Measure & Analytical & Numerical & Relative Error \\ \hline \hline 
      $\mu_{0}$ & $\num{5.9039e-3}$ & $\num{5.8958e-3}$ & 0.0012 \\ \hline 
      $\nu_{0}$ & $\num{4.4832e-3}$ & $\num{4.4908e-3}$ & 0.0017 \\ \hline 
      $\mu_3$ &  $\num{6.2905e-3}$ & $\num{6.2998e-3}$  & 0.0014\\ \hline 
      $\nu_3$ & $\num{2.6415e-3}$ & $\num{2.6460e-3}$ & 0.0017 \\ \hline 
      $\mu_5$ & $\num{9.6060e-2}$ & $\num{9.5891e-2}$ &0.0018  \\ \hline 
      $\nu_5$ & $\num{4.8780e-2}$ & $\num{4.8701e-2}$ &0.0016 \\  
               \hline
  \end{tabular}
  \caption{Table comparing numerical and experimental results of MTTF and MTTS. The labels of the subscripts are given in Figure~\ref{stoch:res.fig.BT}}
  \label{stoch:res.tab.times}	
  \end{table}
\begin{table}[h]
\centering
  \begin{tabular}{| l | c | c | c | c |}\hline
    Label & $\mu$ & $\nu$ & $p_s(t)$ & $p_f(t)$\\ \hline \hline
    Obj. Pos. Retrieved & $-$ & $-$ & $p_{s5}(t)$ & $p_{f5}(t)$\\ \hline
    Object Grasped & $-$ & $-$ & $p_{s4}(t)$ & $p_{f4}(t)$\\ \hline
    Search on the Floor & $0.01$ & $0.0167$ & $0.3$ & $0.7$\\ \hline
    Search in the Drawer & $0.01$ & $0.01$ & $0.8$ & $0.2$\\ \hline
    Search in the Closet  & $0.005$ & $0.0056$ & $0.2$ & $0.8$\\ \hline
    One Hand Grasp & $0.1$ & $20$ & $0.1$ & $0.9$\\ \hline
    Two Hands Grasp & $0.1$ & $0.05$ & $0.5$ & $0.5$\\ 
    \hline
  \end{tabular}
  \caption{Table collecting given parameters, the labels of the control flow nodes are given in Figure~\ref{stoch:res.fig.BT}.}
  \label{stoch:res.tab.param}	
  \end{table}

\begin{figure}[!h]
\centering
\includegraphics[width=1.0\columnwidth]{/plotNUM4}
\caption{Probability distribution over time for the Root node of the larger BT in Figure~\ref{stoch:res.fig.BT}.  Numerical results are marked with an 'x' and analytical results are drawn using solid lines. Note how the failure probability is initially lower, but then becomes higher than the success probability after $t=500$.}
\label{stoch:res.fig.7}
\end{figure}




\begin{figure}[h]
\centering
        \begin{subfigure}[h]{0.8\columnwidth}
                \includegraphics[width=0.8\columnwidth]{plotNUM5}
                \caption{Node 5}
                \vspace{0.3cm}
                \label{stoch:res.fig.5}
        \end{subfigure}
        \begin{subfigure}[h]{0.8\columnwidth}
                \includegraphics[width=0.8\columnwidth]{plotNUM3}
                \caption{Node 3}   
                \label{stoch:res.fig.3}           
        \end{subfigure}
        ~ %add desired spacing between images, e. g. ~, \quad, \qquad etc.
          %(or a blank line to force the subfigure onto a new line)
        \caption{Comparison of probability distribution over time related to  Node 5 (a) and Node 3 (b).
        Numerical results are marked with an 'x' and analytical results are drawn using solid lines. The failure probabilities are lower in both plots.}
        \label{stoch:res.fig.35}
\end{figure}

To further illustrate the difference between modeling the actions as deterministic and stochastic,
we again use the BT in Figure \ref{stoch:res.fig.BT} and
compute the
 accumulated Succes/Failure/Running probabilities for the two cases.
Defining the time to succeed and fail as the inverse of the given rates and computing the probabilities as described in Section~\ref{stoch:PS.numdet}
we get the results depicted in 
 Figures~\ref{stoch:res.fig.comparisondet} and \ref{stoch:res.fig.35det}.   
 As can be seen, the largest deviation is found in the Failure probabilities. In the stochastic case the CDF rises instantly, whereas in the deterministic case it becomes non-zero only after all the Fallbacks in at least one of the two subtrees have failed. 

\begin{figure}[!h]
\centering
\includegraphics[width=1.0\columnwidth]{node1Comparison}
\caption{Comparison of Success/Failure/Running probabilities of the root node in the case of deterministic times (thick) and stochastic times (thin). }
\label{stoch:res.fig.comparisondet}
\end{figure}



\begin{figure}[h]
\centering
        \begin{subfigure}[h]{0.8\columnwidth}
                \centering
                \includegraphics[width=0.75\columnwidth]{node5Comparison-crop.pdf}
                \caption{Node 5}
                 \vspace{0.3cm}
                \label{stoch:res.fig.5compar}
        \end{subfigure}%
        \vspace{0.1cm}
        %add desired spacing between images, e. g. ~, \quad, \qquad etc.
          %(or a blank line to force the subfigure onto a new line)
        \begin{subfigure}[h]{0.8\columnwidth}
                \centering
                \includegraphics[width=0.75\columnwidth]{node3Comparison-crop.pdf}
                \caption{Node 3}   
                \label{stoch:res.fig.3compar}           
        \end{subfigure}
        ~ %add desired spacing between images, e. g. ~, \quad, \qquad etc.
          %(or a blank line to force the subfigure onto a new line)
        \caption{Comparison of Success/Failure/Running probabilities of the node 5 (a) and node 3 (b) in the case of deterministic times (thick) and stochastic times (thin).}
        \label{stoch:res.fig.35det}
\end{figure}


%\textcolor{blue}{

In Figure~\ref{stoch:res.fig.comparison}
the results of swapping the order of ``Search on the Floor" and ``Search in the Drawers" are shown in.
As can be seen, the success probability after 100s is about 30\% when starting with the drawers, and about 20\% when starting with the floor.
Thus the optimal solution is a new BT, with the drawer search as the first option.
Note that
the asymptotic probabilities are always the same for equivalent BT, see Definition \ref{stoch:PS.def.eq}, as the  changes considered are only permutations of Fallbacks.
 


\begin{figure}[h]
\centering
\includegraphics[width=1.0\columnwidth]{/comparison}
\caption{Success/Failure probabilities in the case of searching on the floor first (dashed) and searching in the drawer first (solid). Failure probabilities are lower in both cases.}
\label{stoch:res.fig.comparison}
\end{figure}

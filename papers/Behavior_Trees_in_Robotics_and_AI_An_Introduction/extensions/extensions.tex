% !TEX root = ../CRCBook.tex

\chapter{Extensions of Behavior Trees}
\label{ch:extensions}
\graphicspath{{extensions/}}

As the concept of BT has spread in the AI and robotics communities, a number of extensions have been proposed.
Many of them revolve around the Fallback node, and the observation that the ordering of a Fallback node is often somewhat arbitrary.
In the nominal case, the children of a Fallback node are different ways of achieving the same outcome,
which makes the ordering itself unimportant, but note that this is not the case when Fallbacks are used to increase reactivity with implicit sequences, as described in Section~\ref{sec:implicit_sequences}. 

In this chapter, we will describe a number of extensions of the BT concept that have been proposed.


\begin{figure}[h]
\centering
  \includegraphics[width=8cm]{burglar_utility}
\caption{The result of adding a utility Fallback in the BT controlling a burglar game character in Figure~\ref{design:fig:burglar_safety}.
Note how the Utility node enables a reactive re-ordering of the actions \emph{Escape} and \emph{Fight Cops}.}
\label{design:fig:burglar_utility}
\end{figure}

\section{Utility BTs}
%\label{sec:explicit_conditions}
Utility theory is the basic notion that if we can measure the utility of all potential decisions, it would make sense to 
choose the most useful one. In \cite{merrill2014building} it was suggested that a utility Fallback node would address what was described as the biggest drawback of BTs, i.e. having fixed priorities in the children of Fallback nodes.

A simple example can be seen in the burglar BT of Figure~\ref{design:fig:burglar_utility}.
How do we know that escaping is always better than fighting?
This is highly dependent on the circumstances, do we have a getaway vehicle, do we have a weapon, how many opponents are there, and what are their vehicles and weapons?

By letting the children of a utility Fallback node return their expected utility, the Fallback node can start with the node of highest utility. Enabling the burglar to escape when a getaway car is available, and fight when having a superior weapon at hand. 
In \cite{merrill2014building} it is suggested that all values are normalized to the interval $[0,1]$ to allow comparison between different actions.

Working with utilities is however not entirely straightforward. One of the core strengths of BTs is the modularity, how single actions are handled in the same way as a large tree.
But how do we compute utility for a tree?
Two possible solutions exist,
either we add Decorators computing utility below every utility Fallback node, 
or we add a utility estimate in all actions, and create  a way to propagate utility up the tree, passing both Fallbacks and Sequences. 
The former is a bit ad-hoc, while the latter presents some theoretical difficulties.

It is unclear how to aggregate and propagate utility in the tree. It is suggested in~\cite{merrill2014building} to use the max value in both Fallbacks and Sequences.
This is reasonable for Fallbacks, as the utility Fallback will prioritize the max utility child and execute it first, but one might also argue that a second Fallback child of almost as high utility should increase overall utility for the Fallback.
The max rule is less clear in the Sequence case, as there is no re-ordering, and a high utility child might not be executed due to a failure of another child before it.
These difficulties brings us to the next extension, the Stochastic BTs.


%\section{Fallback adaptation BTs}
%\label{sec:explicit_conditions}

\section{Stochastic BTs}
%\label{sec:explicit_conditions}
\label{sec:stochastic_extension}
A natural variation of the idea of utilities above is to consider success probabilities, as suggested in  \cite{Colledanchise14,hannaford2016simulation}.
If something needs to be done, the action with the highest success probability might be a good candidate.
Before going into details, we note that both costs, execution times, and possible undesired outcomes also matters,
but defer this discussion to a later time.

One advantage of considering success probabilities is that the aggregation across both Sequences and Fallbacks
is theoretically straightforward. Let  $P^s_i$ be the success probability of a given tree, then
the probabilities can be aggregated  as follows~\cite{hannaford2016simulation}:
\begin{equation}
 P^s_{\mbox{Sequence}} = \Pi_i P^s_i, \quad P^s_{\mbox{Fallback}} = 1- \Pi_i (1- P^s_i),
\end{equation}
since Sequences need all children to succeed, while Fallbacks need only one, with probability equal to the complement of all failing.
This is theoretically appealing, but relies on the implicit assumption that each action is only tried once. In a reactive BT for a robot picking and placing items,
you could imagine the robot first picking an item, then accidentally dropping it halfway, and then picking it up again. 
Note that the formulas above do not account for this kind of events.

Now the question comes to how we compute or estimate $P^s_i$ for the individual actions. A natural idea
is to learn this from experience~\cite{hannaford2016simulation}.
It is reasonable to assume that the success probability of an action, $P^s_i$, is  a function of the world state, so it would make sense to try to learn
the success probability as a function of state. Ideally we can classify situations such that one action is known to work in some situations,
and another is known to work in others. The continuous maximization of success probabilities in a Fallback node would then make
the BT choose the correct action depending on the situation at hand.

There might still be some randomness to the outcomes, and then the following estimate is reasonable
\begin{equation}
  P^s_i = \frac{\mbox{\# successes}}{\mbox{\# trials}}. 
\end{equation}
However, this leads to a exploit/explore problem \cite{hannaford2016simulation}. What if both available actions of a Fallback have high success probability?
Initially we try one that works, yielding a good estimate for that action. Then the optimization might continue to favor (exploit) that action,
never trying (explore) the other one that might be even better. For the estimates to converge for all actions, even the ones with
lower success estimates needs to be executed sometimes. One can also note that having multiple similar  robots connected to a cloud service
enables much faster learning of both forms of success estimates described above.

It was mentioned above that it might also be relevant to 
 include costs and execution times in the decision of what tree to execute. A formal treatment of both success probabilities and execution times can be found in 
 Chapter~\ref{ch:stochastic}. A combination of cost and success probabilities might result in a utility system, as described above, but finding the right combination of all three is still an open problem. 
 

\section{Temporary Modification of BTs}
Both in robotics and gaming there is sometimes a need to temporary modify the behavior of a BT.
In many robotics applications there is  an operator or collaborator that might want to temporarily 
influence the actions or priorities of a robot. For instance, convincing a service robot to set the table 
before doing the dirty dishes, or making a delivery drone complete the final mission even though
the battery is low enough to motivate an immediate recharge in normal circumstances.
In computer games, the AI is influenced by both level designers, responsible for the player experience,
and AI engineers, responsible for agents behaving rationally.
Thus, the level designers need a way of making some behaviors more likely, without causing
irrational side effects ruining the game experience.

\begin{figure}[h]
\centering
  \includegraphics[width=8cm]{burglar_agressive}
\caption{The \emph{agressive burglar} style, resulting from disabling  \emph{Escape} in the BT controlling a burglar game character in Figure~\ref{design:fig:burglar_safety}.}
\label{design:fig:burglar_agressive}
\end{figure}

This problem was discussed in one of the first papers on BTs \cite{isla2005handling}, 
with the proposed solutions being \emph{styles},
with each style corresponding to disabling a subset of the BT. For instance, the style \emph{agressive burglar}
might simply have the actions \emph{Escape} disabled, making it disregard injuries and attack until defeated, see Figure~\ref{design:fig:burglar_agressive}.
Similarly, the  \emph{Fight} action can be disabled in the \emph{pacifist burglar} style, as shown in Figure~\ref{design:fig:burglar_pacifist}.
A more elaborate solution to the same problem can be found in the Hinted BTs described below.

\begin{figure}[h]
\centering

  \includegraphics[width=8cm]{burglar_pacifist}
\caption{The \emph{pacifist burglar} style, resulting from disabling  \emph{Fight} in the BT controlling a burglar game character in Figure~\ref{design:fig:burglar_safety}.}
\label{design:fig:burglar_pacifist}
\end{figure}






%\subsection{Hinted BTs}
Hinted BTs were first introduced in \cite{ocio2010dynamic, ocio2012adapting}.
The key idea is to have an external entity, either human or machine, 
giving suggestions, so-called \emph{hints}, regarding actions to execute, to a  BT.
In robotics, the external entity might be an operator or user suggesting something, and in a computer game
it might be the level designer wanting to influence the behavior of a character  without having to edit the actual BT.

The hints can be both positive (+), in terms of suggested actions, and negative (-), actions to avoid,
and a somewhat complex example can be found in Figure~\ref{design:fig:burglar_hinted}.
 Multiple hints can be active simultaneously,
 each influencing the BT in one, or both, of two different ways.
  First they can effect the ordering of Fallback nodes. Actions or trees with positive hints are moved to the left, and ones with negative hints are moved to the right.
 Second, the BT is extended with additional conditions, checking if a specific hint is given.


\begin{figure}[h!]
\centering
  \includegraphics[width=\textwidth]{burglar_hinted}
\caption{The result of providing the hints \emph{Fight Cops+},  \emph{Brake Door Open+} and  \emph{Spend Money-} to the BT in Figure~\ref{design:fig:burglar_combined}. The dashed arrows indicated changes in the BT.}
\label{design:fig:burglar_hinted}
\end{figure}

In the BT of Figure~\ref{design:fig:burglar_hinted}, the following hints were given: \emph{Fight Cops+},  \emph{Brake Door Open+} and  \emph{Spend Money-}.
\emph{Fight Cops+} makes the burglar first considering the fight option, and only escaping when fighting fails.
 \emph{Brake Door Open+} makes the burglar try to brake the door, before seeing if it is open or not,
 and the new corresponding condition makes it ignore the requirements of having a weak door and a crowbar before attempting to brake the door.
Finally,   \emph{Spend Money-} makes the burglar prefer to drive around looking for promising houses rather than spending money.


\section{Other extensions of BTs}
In this section we will briefly describe a number of additional suggested extensions of BTs.
\subsection{Dynamic Expansion of BTs}
The concept of Dynamic Expansions was suggested in \cite{florez2008dynamic}.
Here, the basic idea is to let the BT designer leave some details of the BT to a run-time search.
To enable that search, some desired features of the action needed are specified, these include the
category, given a proposed behavior taxonomy, including \emph{Attack}, \emph{Defend}, \emph{Hunt}, and \emph{Move}. 
The benefit of the proposed approach is that newly created actions can be used in BTs that were created before the actions, 
as long as the BTs have specified the desired features that the new action should have.





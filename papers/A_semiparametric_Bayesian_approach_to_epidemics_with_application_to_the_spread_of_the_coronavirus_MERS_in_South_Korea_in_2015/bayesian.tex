A Bayesian Markov chain Monte Carlo algorithm for sampling from the posterior distribution is described in the supplement.
We list here the main steps of the algorithm,
without providing details,
and discuss its computing time.
Details can be found in the supplement.

To list the main steps of the algorithm,
let
\bi
\item $Z_{i,k} = 1$ if population member $i$ was assigned degree parameter $\gamma_k$ and $Z_{i,k}= 0$ otherwise ($i = 1, \dots, N$,\; $k = 1, \dots, K$);
\item $\bZ_i = (Z_{i,1}, \dots, Z_{i,K})$ and $\bZ_{-i} = (\bZ_1, \dots, \bZ_{i-1}, \bZ_{i+1}, \dots, \bZ_N)$ ($i = 1, \dots, N$),
and $\bZ = (\bZ_1, \dots, \bZ_N)$;
\item $\bgamma = (\gamma_1, \dots, \gamma_K)$;
\item $\bpi = (\pi_1, \dots, \pi_K)$.
\ei
As a consequence,
the degree parameter $\theta_i$ of population member $i$ can be expressed as 
\bea
\nonumber
\theta_i 
\= \bZ_i^\top\, \bgamma,
&& i = 1, \dots, N.
\eea
A Markov chain Monte Carlo algorithm for sampling from the posterior distribution can then be constructed by combining the following Markov chain Monte Carlo steps by means of cycling or mixing \citep*{Tl94,Li08},
assuming all unknown quantities have been initialized:
\begin{enumerate}
\item Impute the missing data:
\bi
\item Sample $\bX_{\mbox{\tiny mis}} \mid \bX_{\mbox{\tiny obs}} = \bx_{\mbox{\tiny obs}},\, \bY = \by,\, \bta$.
\item Sample $\bY_{\mbox{\tiny mis}} \mid \bX=\bx,\, \bY_{\mbox{\tiny obs}} = \by_{\mbox{\tiny obs}},\, \bZ=\bz,\, \bgamma,\, \bta$.
\ei
\item Sample the parameters of the population model:
\bi
\item Sample $\bgamma \mid \bY=\by,\, \bZ=\bz$.
\item Sample $\bZ_i \mid \bY=\by,\, \bZ_{-i} = \bz_{-i},\, \bgamma,\, \bpi$ ($i = 1, \dots, N$).
\item Set $\theta_i = \bZ_i^\top\, \bgamma$ ($i = 1, \dots, N$).
\item Sample $\bta \mid \bX = \bx,\, \bY = \by$.
% ($i < j = 1, \dots, N$).
\ei
\item Sample the hyperparameters:
\bi
\item Sample $\alpha \mid \bpi$.
\item Sample $\bpi \mid \bZ=\bz,\, \alpha$.
\item Sample $\mu \mid \sigma^2,\, \bgamma$.
\item Sample $\sigma^{2} \mid \mu,\, \bgamma$.
\ei
\end{enumerate}
%Here, 
%$\bX = (\bX_{\mbox{\tiny obs}}, \bX_{\mbox{\tiny mis}})$ and $\bY = (\bY_{\mbox{\tiny obs}}, \bY_{\mbox{\tiny mis}})$ refer to observed and missing data.
\hide{
Steps 1, 2, and 3 sample from the full conditional Gamma, Gaussian, and Gamma distributions of $\alpha$, $\mu$, and $\sigma^{-2}$.
Step 4 amounts to sampling stick-breaking weights $V_1, \dots, V_{K-1}$ from full conditional Beta distributions and setting $V_K = 1$,
then constructing $\bpi$ by using the stick-breaking construction described in Section 6.3.
}
Most of the Markov chain Monte Carlo steps involve Gibbs sampling from full conditional distributions (e.g., Beta, Gamma, and Gaussian distributions),
while the others are Metropolis-Hastings steps.
More details are provided in the supplement.
%Steps 6, 8, and 9 amount to sampling from full conditional distributions with finite support.
%All other steps (with the exception of Step 7, which computes $\btheta$ based on $\gamma$ and $\bZ_1, \dots, \bZ_N$) are Metropolis-Hastings steps.

The computing time of the algorithm is a function of
\bi
\item the number of subpopulations $K$, 
which satisfies $K \leq N$;
\item the number of infected population members $M$, 
which satisfies $M \leq N$ and in large populations satisfies $M \ll N$ (unless a non-negligible fraction of the population is infected);
\item the sampling design and the number of population members $n$ sampled out of the $N$ population members for the purpose of collecting data on contacts along with epidemiological data,
which satisfies $n \leq N$ and in large populations satisfies $n \ll N$ (unless a non-negligible fraction of the population is sampled);
\item the sparsity of the population contact network.
\ei
As a specific example,
consider ego-centric sampling, 
as described in Section 5.2.
An ego-centric sampling design samples $n$ out of the $N$ population members and,
for each sampled population member,
collects data on the contacts of the sampled population member with the $N-1$ other population members,
in addition to data on the transmissions, exposure, infectious, and removal times of infected population members.
As a result,
the computing time of each iteration of the Bayesian Markov chain Monte Carlo algorithm is $O(K\, n\, N)$,
because updates of the $K$ degree parameters $\gamma_1, \dots, \gamma_K$ involve computations of up to $n\, (N-1)$ probabilities of the form 
\bea
\nonumber
\mbP_{\theta_i,\theta_j}(Y_{i,j}=y_{i,j})
&=& \exp((\theta_i+\theta_j)\, y_{i,j} - \log(1 + \exp(\theta_i+\theta_j))),
\eea
where $\theta_i = \bZ_i^\top\, \bgamma$ and $\theta_j = \bZ_j^\top\, \bgamma$.

Having said that,
the computing time of $O(K\, n\, N)$ in the case of ego-centric sampling is based on worst-case scenarios and can be reduced to $O(K\, n)$ in special cases:
e.g.,
when the population contact network is sparse in the sense that many population members have few contacts,
it is possible to reduce the computing time by taking advantage of sparsity.
% An example is given by \citet{VuHuSc12},
% who take advantage of sparsity to reduce the computing time of likelihood-based algorithms for finite mixture models of network data (without epidemiological data).
In fact,
many real-world networks are sparse:
While population members can create up to $N-1$ contacts,
creating physical contacts that enable disease transmission requires geographical proximity and time.
As a consequence,
it is plausible that the expected degrees of many if not all population members are bounded above by a finite constant \citep*{Du92,RoChYu11,KrHaMo11,Lo12,AmChBiLe13,KrKo14,butts:jms:2018}.
In such cases,
the resulting population contact network is sparse, 
and one could reduce the worst-case computing time of $O(K\, n\, N)$ to $O(K\, n)$.
Some ideas of how to exploit sparsity for the purpose of reducing computing time can be found in, e.g., \citet*{RaNiHoYe12} and \citet*{VuHuSc12}.

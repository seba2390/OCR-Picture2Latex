\section{How can HTTP/2 and SPDY help}

\begin{figure}[htbp]
\centering
\subfigure[PLT of HTTP/2 divided by PLT of HTTP with 20ms RTT and 1mbps bandwidth]{
\label{fig:http2_vs_http_pkl}
\includegraphics[width=0.32\textwidth]{images/http2_vs_http_latency.png}}
\subfigure[PLT of HTTP/2 divided by PLT of HTTP with 0\% packet loss rate and 1mbps bandwidth]{
\label{fig:http2_vs_http_latency}
\includegraphics[width=0.32\textwidth]{images/http2_vs_http_pkl.png}}
\subfigure[PLT of HTTP/2 divided by PLT of HTTP with 2\% packet loss rate and 1mbps bandwidth]{
\label{fig:http2_vs_http_latency_2pkl}
\includegraphics[width=0.32\textwidth]{images/http2_vs_http_latency_2pkl.png}}
\caption{PLT of HTTP/2 divided by PLT of HTTP.}
\label{fig:http2_vs_http}
\end{figure}

HTTPS piggybacks HTTP entirely on top of TLS/SSL, whose end-end encryption ensures complete privacy. However, it needs one more expensive TLS/SSL handshake for each new connection, which costs extra tow Round-Trip Time. HTTPS slows down the landing page render as it takes a few hundred extra milliseconds to set up the HTTPS connection, which hinders its deployments in despite of its security.

SPDY is designed by Google to help reduce latency and bolster security. HTTP/2 is the next evolution of HTTP and is based on SPDY. HTTP/2 and SPDY attempt to outcome the shortcomings of HTTP, and focuses on performance, e.g., end-user perceived latency, network, and server resource usage. HTTP/2 and SPDY benefit from multiplexing and concurrency, stream dependencies, header compressions, and server push. After more than two years' discussion, 17 drafts, and 30 implements, IETF HTTP Working Group for publication as standards-track RFCs approved the HTTP/2 and associated HPACK specifications in February of 2015. Google have also announced to replace SPDY with HTTP/2. It is useful to deploy HTTP/2 or SPDY to speed Web pages as well as keep the security of HTTPS. SPDY shows a similar trend to HTTP/2, so we just show performance  of HTTP/2 versus HTTP under certain networks.

Figure~\ref{fig:http2_vs_http} shows the distribution of PLT of HTTP/2 divided by PLT of HTTP under different network conditions. We can find how HTTP/2 help under different conditons. Figure~\ref{fig:http2_vs_http_pkl} shows the PLT of HTTP/2 divided by PLT of HTTP when injecting different packet loss. We can find that Web page performance improvement gained by HTTP/2 decreases as packet loss rate raised. HTTP/2 reduces the PLT for 2.6\% $\sim$ 53.1\% of mobile pages, and help for 0.7\% $\sim$ 54.8\% of desktop pages. Meanwhile, we find that HTTP/2 gain more performance improvement of mobile pages compared to desktop pages, especially under high packet loss rate. Figure~\ref{fig:http2_vs_http_latency} and Figure~\ref{fig:http2_vs_http_latency_2pkl} show performance of HTTP/2 versus HTTP with different RTTs when injecting 0\% and 2\% packet loss rate, respectively. Figure~\ref{fig:http2_vs_http_latency} shows that HTTP/2 can help 53.1\% $\sim$ 82.3\% of mobile pages and 54.8\% $\sim$ 79.2\% of desktop pages. We find that HTTP/2 gain least performance improvements under low latency (20ms). However, Figure~\ref{fig:http2_vs_http_latency_2pkl} shows a reverse trend under high packet loss rate. This finding is consistent as our decision analysis, which shows that packet loss rate has more effect on performance of HTTP/2 and SPDY. Meanwhile, HTTP/2 is beaten by HTTP with at most 4\% performance improvement. Our results are consistent with prior studies~\cite{Saxce:INFCOM15, Varvello:CORR15}, which have shown that HTTP/2 only help under certain network conditions.

Overall, we need to address that HTTP/2 and SPDY do not always gain performance improvements. HTTP/2 helps under low packet loss rate, and performs better when loading mobile pages. When packet loss rate is low, HTTP/2 helps under high latency. We have discussed in previous section that high RTT favors HTTP/2 and SPDY against HTTP due to multiplexing. HTTP/2 and SPDY benefits from having a single connection and stream multiplexing. One connection per origin significantly reduces the associated overhead: fewer sockets to manage along the connection path, smaller memory footprint, better connection throughput, less time in slow-start, faster congestion and loss recovery. As the RTT goes up, new established TCP connections cost more time.
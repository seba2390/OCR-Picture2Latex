\section{Introduction}
The challenges of document classification in an industry setting are many: scalability, accuracy and degree of automation, speed of delivery requirements, and limited time available by domain business experts. While a company may have a large collection of documents and high level metadata consisting of broad classes spanning this collection, there are inevitably use cases and workflows that need more granular and specialized document classes. The document classification within these specialized workflows is typically done by business and domain experts, whose time is valuable, and better spent on other tasks. This setup calls for an automation process that can be trained to classify document sub-classes with smaller amounts of training data. Few-shot learning methods offer exactly this benefit. 

One possible approach is to pre-train a model on available large open-source document datasets. However, they tend to be significantly different from the internally generated workflow documents. Some reasons for this are that the open source document data sources may be scanned using lower quality scanners, the documents are of different types than those considered internal to the company, or the text content itself utilizes a different colloquial vocabulary. This paper proposes a few-shot meta-learning technique that utilizes both the visual and text components of a document, and is pre-trained on open source document datasets that are out of domain with respect to the internal company documents, which the model is evaluated on.


% Gartner has estimated 80\% of enterprises data is unstructured (emails, PDF and other documents). These documents contain rich information and knowledge about internal and external business communication and transactions. And they have ubiquitous applications in numerous industrial sectors such as finance, health care, and law etc. Therefore, being able to automatically and efficiently sort, analyze, and extract structure and content from document images can improve  efficiency and reduce cost for many business workflows. Document image classification is an import task in these automation solutions, and has been a popular research area for decades. Early works usually build classifiers that rely on Optical Character Recognition (OCR) to extract text information, and employ heuristics to model layout structural features. In light of the advancement of computer vision and deep learning, VGG-16 \cite{VGG16} pre-trained on ImageNet \cite{imagenet_cvpr09} reported good classification performance on data sets mixed of business letters, print advertisement, emails and magazine articles \cite{kumar2014structural}. Both \cite{bertgrid} and \cite{layoutLM} created document representations by encoding layout coordinates into positional embeddings as inputs to pre-trained BERT \cite{BERT} or transformer architectures. The latest PubLayNet \cite{publaynet} addresses the limited public available document image data sets by training a Mask R-CNN \cite{maskrcnn} model on 360k images of scientific articles, and enables transfer learning to other document domains. Motivated by the development of graph neural network algorithms \cite{gnn_survey,dgcnn,gnn_diffpool}, researchers \cite{gnn_multimodal} attempted to use graph convolutions to model the interactions among structural components of a document and between the visual and textual features, as an alternative to pixel level or token level document modeling. 
% In contrast to fast moving research progress in document analysis and classification, few have systematically studied the time and hardware resources when using different methods and the financial implications of the model design. However, as document image classifications have been primarily motivated by its potential in commercialization, it is imperative to study its model performance with computing resources requirements and financial implications. In this paper we propose an efficient document image classification framework as shown in Fig. \ref{fig:overview}. Semantics regions of a document is extracted by pre-trained PubLayNet, textual features are extracted by text embedding models and the image features are extracted by a pre-trained VGG-16 model. Graphs formed for the document, with the document class labels are used to train a sort pooling graph convolution network \cite{dgcnn} which normalizes and classify arbitrary graphs therefore documents. 
% The major contributions of our papers are as follows:
% \begin{itemize}
%     \item We propose a novel document image classification framework which applies a graph convolution neural network to a document image graph formed by semantic regions extracted from a pre-trained document segmentation model. Moreover both image and text features of the regions are extracted and assigned to the nodes so that information from both modalities are captured and propagated in the graph convolutions. To our best knowledge, our framework is the the first in effectively and economically integrating image, text, and layout information for document image classification using a graph convolution neural network.
%     \item We have rigorously bench marked our proposed method against state-of-the-art pre-trained vision models and transformer language models on document image data sets. These include an insurance related document image data set consisted of 11 classes and an open source data set of 10 classes. The results showed the classification results of our method are comparable to those of baseline models, if not better. 
%     \item We  extensively bench marked the computing resources required by all methods. The results showed our framework needs substantially less computing resources and less time, further indicating the cost advantages of training, deployment and hosting at scale. Efficient model also helps accelerate model iterations and update.   %\textbf{\textcolor{blue}{It also helps in future retraining of previously trained models in the event of new classes getting added to existing large enterprise level datasets }}
% \end{itemize}
% We also discussed a few potential document image classification applications and the infrastructure to deploy our framework. The potentially large scale adoption of document image classification further reinforced the need for an efficient document image classification method.  
%\begin{itemize}
%\item \textcolor{red}{TO ADDRESS THE INTUITION of USING GRAPH CONVOLUTION, WHAT IF USING FEATURES EXTRACTED FROM REGIONS ONLY}. 
%\item \textcolor{red}{TO ADDRESS THE RESOURCES LIMITATION IMPOSED BY LARGE MODELS}
%\item \textcolor{red}{need a consistent term for regions/structure/areas/semantics extracted by %publaynet and can refer to e.g. SEMANTIC REGION/LAYOUT}
%
%\end{itemize}


% the importance of efficient document classification in enterprise digital 
% look back at document classification history, latest advancement in computer vision, NLP, large pretrained model
% graph neural networks
% challenges: can only experiment on two public available data sets, few study on running time, hardware resources 
% lacks a real world applications that can drove the % choices of model design 
% In this paper we propose an efficient document classification pipeline, leveraging large pre-trained model document segmentation model and graph convolution network successful in graph data sets. 
% see the diagram, briefly explain the process 
% First paper applying graph convolution network on areas from document segmentation 
% Benchmarked with insurance related medical bill data sets and publically availabel  
% Comprehensive Benchmark model size, hardware resources, training time, inference time for each model 
% We also demonstrated several applications of this document classification model and how it can be deployed and scale using AWS services. 
% We conclude the paper with next steps in both further graph modeling research and scalability by the 
% need to handle new class types with very low R & D effort. 

% \begin{figure*}[t]
%   \begin{center}
%     \includegraphics[width=0.9\textwidth]{main/Images/EffGNN-2.png}
%   \end{center}
%   \caption{\textbf{Eff-GNN Framework overview:} textual embedding, segmented regions and image embeddings of an image are integrated when the graph of document is formed. Created graph is fed into the Graph Convolution Neural Network for graph classification as document image classification.}
%   \label{fig:overview}
% \end{figure*}
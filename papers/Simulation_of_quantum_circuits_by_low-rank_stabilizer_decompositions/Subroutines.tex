
Throughout this section we use the following notations.
Suppose $x\in  \{0,1\}^n$ is a bit string.
We shall consider $x$  as a row vector  and write $x^T$ for the transposed column vector. 
The Hamming weight of $x$ denoted $|x|$ is the number of ones in $x$.
The support of $x$  is the subset of indices $j\in [n]$ such that $x_j=1$.
Given a single-qubit operator
$P$  let $P(x)$ be an $n$-qubit product operator
that applies $P$ to each qubit in the support of $x$, that is, 
$P(x)=P^{x_1}\otimes \cdots \otimes P^{x_n}$.
We shall use the notation $\oplus$ for the addition of binary vectors modulo two.
Let  $x\cdot y\equiv \sum_{j=1}^n x_jy_j$.


\subsection{Phase-sensitive Clifford simulator}
\label{clifford_sim}
\newcommand{\modtwo}{\; (\mathrm{mod}\, 2)}
In this section we describe a  Clifford simulator based on stabilizer tableau~\cite{aaronson04improved}  that keeps track of the global phase of stabilizer states. 
We shall consider Clifford circuits expressed using a gate set
\be
\label{CLgates}
S, \quad CZ, \quad CX,
\quad H.
\ee
Here $CZ$ and $CX$ are controlled-$Z$ and -$X$ gates, 
$H$ is the Hadamard gate, and $S=|0\ra\la 0|+i|1\ra\la 1|$.

First let us define a data format to describe stabilizer states. 
Suppose $U$ is a unitary Clifford operator.
We say that $U$ is a control-type or
{\em C-type} operator
if
\be
\label{Ctype} 
U|0^n\ra=|0^n\ra.
\ee  
For example, the gates $S,CZ,CX$ and any product of such gates are C-type operators.
We say that $U$ is a Hadamard-type or {\em H-type} operator if
$U$ is a tensor product of the Hadamard and the identity gates. 
Previously known results on canonical decompositions of Clifford circuits~\cite{nest2008classical,garcia2012efficient,maslov2017shorter}
imply that any $n$-qubit stabilizer state $\phi$ can be expressed as 
\be
\label{phi}
|\phi\ra = \omega U_C U_H  |s\ra,
\ee
where $U_C$ and $U_H$ are C-type and H-type Clifford operators,
$s\in \{0,1\}^n$ is a basis vector, and $\omega$ is a complex number. 
We shall refer to the decomposition Eq.~(\ref{phi}) as a CH-form of $\phi$.
Note that this form may be non-unique.

We shall describe the unitary $U_C$ by its stabilizer tableaux,
that is, a list of Pauli operators $U_C^{-1} Z_p U_C$ and $U_C^{-1} X_p U_C$.
The global phase of $U_C$ is fixed by Eq.~(\ref{Ctype}).
Using Eq.~(\ref{Ctype}) one can check that 
$U^{-1}_C Z_p U_C$ is a tensor product of Pauli $Z$ and the identity operators $I$.
Thus the stabilizer tableaux of $U_C$ can be described by binary matrices
$F,G,M$ of size $n\times n$ and a phase vector $\gamma\in \ZZ_4^n$ such that 
\be
\label{tableaux}
U^{-1}_C Z_p U_C = \prod_{j=1}^n Z_j^{G_{p,j}} \quad \mbox{and} \quad 
U^{-1}_C X_p U_C = i^{\gamma_p}  \prod_{j=1}^n X_j^{F_{p,j}} Z_j^{M_{p,j}}
\ee
for all $p=1,\ldots,n$. Here  $X^0\equiv Z^0\equiv I$. 
We shall describe the unitary $U_H$ by a string $v\in \{0,1\}^n$ such that 
\be
\label{Htype}
U_H=H(v)\equiv H_1^{v_1} \otimes H_2^{v_2} \otimes \cdots \otimes H_n^{v_n}.
\ee
To summarize,  the CH-form is fully specified by the data $(F,G,M,\gamma,v,s,\omega)$.
Let us agree that  $\omega=1$ whenever it is omitted.


Below we  describe an algorithm that takes as input a
sequence of Clifford gates $U_1,\ldots,U_m$ from the gate set Eq.~(\ref{CLgates})
and outputs the CH-form of a stabilizer state
\be
\label{phi1}
|\phi\ra=U_m\cdots U_2 U_1 |0^n\ra.
\ee
The runtime is $O(n)$ per each gate $S,CZ,CX$ and $O(n^2)$ per
each Hadamard gate. 
We also show how to compute an amplitude $\la x|\phi\ra$
and sample $x$ from the distribution $|\la x|\phi\ra|^2$
assuming that $\phi$ is specified by its CH-form. These tasks 
take time $O(n^2)$.
Finally, we consider projective gates $(I+P)/2$, where $P$ is a Pauli
operator. We show how to simulate projective gates in time $O(n^2)$.



{\bf Simulation of unitary gates.}
The initial state $|0^n\ra$ has a trivial CH-form with $s=0^n$ and $U_C=U_H=I$.
Thus we initialize the CH data as   $G=F=I$,  $M$ is the zero matrix,
and  $\gamma,v,s$ are zero vectors.
Suppose $\phi$ is a stabilizer state with the CH form  
\[
|\phi\ra=U_C U_H|s\ra
\]
described by the data $(F,G,M,\gamma,v,s)$.
Consider a gate 
$\Gamma \in \{ S,  CZ, CX, H\}$
applied to some subset of qubits. 
The state $\Gamma |\phi\ra$ has a CH-form
\be
\label{C'H'}
\Gamma |\phi\ra=\Gamma U_C U_H|s\ra = \omega' U_C' U_H'|s'\ra
\ee
with the corresponding  data $(F',G',M',\gamma',v',s',\omega')$.
Let us show how to compute this data. 

The case $\Gamma \in \{S, CZ, CX\}$ is trivial: one can absorb 
$\Gamma$ into the C-layer obtaining $U_C'=\Gamma U_C$. The  stabilizer tableaux of $U_C$ is updated using
the standard Aaronson-Gottesman algorithm~\cite{aaronson04improved} 
(explicit update rules are provided at the 
end of this section). This update takes time $O(n)$.

Let $\Gamma=H_p$ be the Hadamard gate applied to a qubit $p\in [n]$.
Commuting  $H_p$  through the C- and H-layer using the identity $H_p=2^{-1/2}(X_p+Z_p)$
and Eq.~(\ref{tableaux})
one gets 
\be
\label{H1}
H_p|\phi\ra = 2^{-1/2}U_C U_H [ (-1)^\alpha |t\ra + i^{\gamma_p} (-1)^\beta |u\ra),
\ee
where $t,u\in \{0,1\}^n$ are defined by
\be
\label{H2}
t_j = s_j \oplus G_{p,j} v_j 
\quad \mbox{and} \quad 
u_j = s_j  \oplus F_{p,j}\bar{v}_j  \oplus M_{p,j} v_j
\ee
for $j=1,\ldots,n$. Here and below $\bar{v}_j\equiv 1-v_j$. Furthermore,
\be
\label{H4}
\alpha = \sum_{j=1}^n G_{p,j} \bar{v}_j s_j 
\quad
\mbox{and} 
\quad
\beta=
\sum_{j=1}^n M_{p,j} \bar{v}_j s_j   + F_{p,j}v_j (M_{p,j}+s_j).
\ee
The case $t=u$ is trivial: Eq.~(\ref{H1}) gives the desired CH-form
of $H_p|\phi\ra$ with  $s'=t=u$
and $\omega'=2^{-1/2}[ (-1)^\alpha + i^{\gamma_p} (-1)^\beta]$.
From now on assume that $t\ne u$. 
\begin{prop}
\label{prop:H}
Suppose $t,u\in \{0,1\}^n$ are distinct strings
and $\delta \in \ZZ_4$.
Then  the state
$U_H(|t\ra +  i^\delta  |u\ra)$ has a CH-form 
\be
\label{H5}
U_H( |t\ra + i^\delta |u\ra) = \omega W_C W_H |s'\ra,
\ee
where the C-layer $W_C$ consists of $O(n)$ gates
from the set $\{S,CZ,CX\}$.  The decomposition Eq.~(\ref{H5})
can be computed  in time $O(n)$.
\end{prop}
Choosing $\delta=\gamma_p+2(\alpha+\beta) {\pmod 4}$ and
substituting
Eq.~(\ref{H5}) into Eq.~(\ref{H1}) one gets
\be
\label{H6}
H_p|\phi\ra = 2^{-1/2} (-1)^\alpha \omega \cdot U_C W_C  \cdot W_H |s'\ra.
\ee
This gives the desired CH-form of $H_p|\phi\ra$ with
\be
\label{H7}
\omega'=2^{-1/2}(-1)^\alpha \omega, \quad U_C'=U_C W_C,
\quad U_H'=W_H.
\ee
Finally, one needs to compute the  stabilizer tableaux of $U_C'$.
Since $W_C$ consists of $O(n)$ gates $S,CZ,CX$
it suffices to give update rules for the stabilizer tableaux of $U_C$
under the right multiplications $U_C \gets U_C \Gamma$
with $\Gamma \in \{S,CZ,CX\}$.
Explicit update rules are provided at the end of this section
(this  is a straightforward application of the stabilizer formalism).
Each update rule takes time $O(n)$. Since
$W_C$ contains  $O(n)$ gates,  the full simulation cost of
the Hadamard gate is $O(n^2)$.


\begin{proof}[Proof of Prosposition~\ref{prop:H}]
We shall construct a C-type circuit  $V_C$  and bit strings
$y,z\in \{0,1\}^n$  such that
\begin{itemize}
\item $y$ and $z$ differ on a single bit $q\in [n]$,
\item $U_H |t\ra =V_C U_H |y\ra$,
\item $U_H |u\ra =V_C U_H |z\ra$.
\end{itemize}
Then 
\be
U_H(|t\ra + i^\delta |u\ra) =V_C U_H(|y\ra + i^\delta |z\ra).
\ee
Since $y_i=z_i$ for $i\ne q$  and $y_q\ne z_q$,
 the state  
$U_H(|y\ra + i^\delta |z\ra)$
is a tensor product of single-qubit states
$H^{v_i}|y_i\ra$ on qubits $i\ne q$ and
a stabilizer state $H^{v_q}(|y_q\ra + i^\delta |z_q\ra)$ on qubit $q$.
Let us write 
\[
H^{v_q}(|y_q\ra + i^\delta |z_q\ra)=\omega S^a H^b |c\ra
\]
for some  $a,b,c\in \{0,1\}$ and some complex number $\omega$.
We arrive at 
\[
U_H(|t\ra + i^\delta |u\ra) =  
\omega(V_C S_q^a) (U_H H_q^{b\oplus v_q}) |s'\ra,
\]
where $s'_q=c$ and $s'_i=y_i=z_i$ for $i\ne q$.
This is the desired form Eq.~(\ref{H5})
with $W_C=V_C S_q^a$
and $W_H=U_H H_q^{b\oplus v_q}$.

It remains to construct $V_C,y,z$ as above. 
We shall choose $V_C$ such that 
\be
\label{HCCH}
U_H V_C U_H = \prod_{i\in [n]\setminus q\, : \, t_i\ne u_i}\; \; CX_{q,i}
\ee
for some qubit $q\in [n]$ such that $t_q\ne u_q$. 
The circuit in the righthand side of Eq.~(\ref{HCCH}) 
 maps $t,u$ to strings $y,z$ that differ only on the $q$-th bit.
Accordingly, $V_C U_H|t\ra=U_H|y\ra$ and $V_C U_H|u\ra=U_H|z\ra$,
as desired.  

For each $b\in \{0,1\}$ define a subset
\[
\calV_b=\{ i\in [n] \, : \, v_i=b \quad \mbox{and} \quad t_i \ne u_i\}.
\]
Here $v\in \{0,1\}^n$ defines the H-layer $U_H$, see Eq.~(\ref{Htype}).
By assumption,   at least one of the subsets $\calV_b$ is non-empty.

Suppose first that $\calV_0\ne \emptyset$. Let $q$ be the first qubit of $\calV_0$. Define
\[
V_C = \prod_{i\in \calV_0\setminus q } CX_{q,i} \cdot \prod_{i\in \calV_1 } CZ_{q,i}.
\]
Here $CX_{q,i}$ has control $q$ and target $i$. 
If $\calV_0=\{q\}$ then gates $CX_{q,i}$ are skipped.
Likewise, if $\calV_1=\emptyset$ then the gates $CZ_{q,i}$ are skipped.
Simple algebra shows that $V_C$  obeys Eq.~(\ref{HCCH}).

Suppose now that $\calV_0= \emptyset$. Then $\calV_1\ne \emptyset$
since $t\ne u$.
Let $q$ be the first qubit of $\calV_1$. Define
\[
V_C=\prod_{i\in \calV_1\setminus q } CX_{i,q}.
\]
Let us agree that $V_C=I$ if $\calV_1=\{q\}$.
Simple algebra shows that $V_C$ obeys Eq.~(\ref{HCCH}).

In both cases  the strings $y,z$ have the form 
\[
\mbox{if $t_q=1$ then $y=u\oplus e_q$ and $z=u$},
\]
\[
\mbox{if $t_q=0$ then $y=t$ and $z=t\oplus e_q$}.
\]
Here $e_q\in \{0,1\}^n$ is a string with a single non-zero at the $q$-th bit.
\end{proof}

In the rest of this section we provide  rules for updating the stabilizer
tableaux of $U_C$ under the left and the right multiplications
$U_C\gets \Gamma U_C$ and $U_C \gets U_C \Gamma$, where
$\Gamma$ is one of the gates $S,CZ,CX$. 
We shall write $\calL[\Gamma]$ and $\calR[\Gamma]$ for the left and the right
multiplication by $\Gamma$. 
Below $p=1,\ldots,n$.
All  phase vector updates are performed modulo four.
\[
\calR[S_q] \, : \, \left\{
\ba{rcl}
M_{p,q} &\gets& M_{p,q} \oplus F_{p,q}  \\
\gamma_p &\gets&  \gamma_p - F_{p,q} \\
\ea \right.
\quad  \quad
 \calL[S_q] \, : \, \left\{
\ba{rcl}
M_{q,p} &\gets& M_{q,p} \oplus G_{q,p}\\
\gamma_q &\gets&  \gamma_q - 1  \\
\ea \right.
\]
\[
\calR[CZ_{q,r}] \, : \, \left\{
\ba{rcl}
M_{p,q} &\gets& M_{p,q} \oplus F_{p,r}  \\
M_{p,r} &\gets& M_{p,r} \oplus F_{p,q}  \\
\gamma_p &\gets&  \gamma_p + 2F_{p,q}F_{p,r}  \\
\ea \right.
\quad \quad
\calL[CZ_{q,r}] \, : \, \left\{
\ba{rcl}
M_{q,p} &\gets& M_{q,p} \oplus G_{r,p}  \\
M_{r,p} &\gets& M_{r,p} \oplus G_{q,p}  \\
\ea \right.
\]
\[
 \calR[CX_{q,r}] \, : \, \left\{
\ba{rcl}
G_{p,q} &\gets& G_{p,q} \oplus G_{p,r}  \\
F_{p,r} &\gets& F_{p,r} \oplus F_{p,q}  \\
M_{p,q} &\gets& M_{p,q} \oplus M_{p,r}\\
\ea \right.
\quad
 \quad
\calL[CX_{q,r}] \, : \, \left\{
\ba{rcl}
G_{r,p} &\gets& G_{r,p} \oplus G_{q,p}  \\
F_{q,p} &\gets& F_{q,p} \oplus F_{r,p}  \\
M_{q,p} &\gets& M_{q,p} \oplus M_{r,p}\\
\gamma_q &\gets& \gamma_q+ \gamma_r + 2(MF^T)_{q,r} \\
\ea \right.
\]

\noindent
{\bf Simulating measurements. }
Let $x\in \{0,1\}^n$ be a basis vector. Using Eqs.~(\ref{Ctype},\ref{tableaux}) one gets
\be
\label{amplitude}
\la x|U_C U_H|s\ra =\la 0^n| \left( \prod_{p=1}^n U_C^{-1} X_p^{x_p} U_C \right) U_H|s\ra
\equiv \la 0^n |Q U_H|s\ra.
\ee
Note that $Q$ is a product of $|x|$ Pauli operators that appear in Eq.~(\ref{tableaux}).
It can be computed inductively in time $O(n^2)$ by setting 
$Q=I$ and performing updates $Q\gets Q \cdot U_C^{-1} X_p^{x_p} U_C$ 
for each $p$ with $x_p=1$.  
Write $Q=i^\mu Z(t)X(u)$ for some $\mu\in \ZZ_4$ and
$t,u\in \{0,1\}^n$. Note that   $u=xF\modtwo$. Then
\be
\label{amplitude1}
\la x|U_C U_H|s\ra = 
\la 0^n|QU_H|s\ra=
2^{-|v|/2} i^\mu \prod_{j\, : \, v_j=1} (-1)^{u_j s_j}  \prod_{j\, : \, v_j=0} \la u_j|s_j\ra.
\ee
Thus computing the amplitude $\la x|U_C U_H|s\ra$ takes time $O(n^2)$.

Consider a probability distribution $P(x)=|\la x|U_CU_H|s\ra|^2$.
From Eq.~(\ref{amplitude1}) one infers that 
$P(x)=2^{-|v|}$ if $u_j=s_j$ for all bits $j$ with $v_j=0$
and $P(x)=0$ otherwise. 
Since $U_C$ preserves the Pauli commutation rules, one has 
$FG^T=I \modtwo$.  Thus
$x=wG^T\modtwo$, where $w\in \{0,1\}^n$ is a row vector satisfying $w_j=s_j$ if $v_j=0$.
The remaining bits of $w$ are picked uniformly at random.  
Thus one can sample $x$ from $P(x)$ as follows:
\begin{itemize}
\item Set $w=s$.
\item For each $j$ such that $v_j=1$ flip the $j$-th bit of $w$ with probability $1/2$.
\item Output $x=wG^T \modtwo$.
\end{itemize}
This takes time $O(n^2)$.
Finally, consider a projective gate $\Gamma=(I+P)/2$, where $P=P^\dag$ is a Pauli operator.
We have 
\[
\Gamma |\phi\ra=\Gamma U_C U_H |s\ra = (1/2)U_C U_H(I+ Q)|s\ra,
\]
where $Q$ is a Pauli operator that can be computed in time  $O(n^2)$ using the
stabilizer tableaux of $U_C$. 
Write $(I+Q)|s\ra=|s\ra + i^\delta |t\ra$ for some $t\in \{0,1\}^n$ and $\delta\in\ZZ_4$.
We can now compute the CH-form of $\Gamma|\phi\ra$ using Proposition~\ref{prop:H}
in the same fashion as was done above for the Hadamard gate.

\subsection{Heuristic Metropolis simulator}
\label{heuristic}Consider a state
$|\psi\ra=\sum_{\alpha=1}^k b_\alpha |\phi_\alpha\ra$,
where $\phi_1,\ldots,\phi_k$ are $n$-qubit stabilizer states.
We assume that all states $\phi_\alpha$ are specified by their CH-form.
This form can be efficiently computed using 
the Clifford simulator of Section~\ref{clifford_sim}.
Our goal is to sample $x\in \{0,1\}^n$ from the probability distribution
\[
P(x)=\frac{|\la x|\psi\ra|^2}{\|\psi\|^2}.
\]
To this end define a Metropolis-type Markov chain $\calM$ with a state space
$\Omega=\{ x\in \{0,1\}^n\, : \, P(x)>0\}$.
 Suppose the current state of the chain $x\in \Omega$.
Then the next state $x'$ is generated as follows.\\
\begin{itemize}
\item Pick an integer $j\in [n]$ uniformly at random and let $y=x\oplus e_j$.
\item If $P(y)\ge P(x)$ then set $x'=y$.
\item Otherwise generate a random bit $b\in \{0,1\}$ such that $\mathrm{Pr}(b=1)=P(y)/P(x)$.
\item If $b=1$ then set $x'=y$. Otherwise set $x'=x$.
\end{itemize}
We shall refer to the mapping $x\to x'$ as a Metropolis step.
Let us make a simplifying assumption that the chain $\calM$ is irreducible, that is,
for any pair of strings $x,y\in \Omega$  there exist a path
$x^0=x,x^1,\ldots,x^L=y\in \Omega$ such that $x^i$ and $x^{i+1}$ differ on 
a single bit for all $i$. Then 
$P(x)$ is the unique steady distribution of $\calM$.
One can (approximately) sample $x$ from $P(x)$ by 
implementing $T\gg 1$ Metropolis steps 
starting from some (random) initial state $x_{in}\in \Omega$
and using the final state as the output string. 

We claim that one can implement $T$ Metropolis  steps  in time 
\[
O(k n T) + O(k n^2). 
\]
Here the term $O(kn^2)$ is the cost of computing
the initial probability $P(x_{in})$ using the algorithm of Section~\ref{clifford_sim}.
Indeed, suppose we have already implemented
several steps  reaching some state $x\in \Omega$.
Let $y=x\oplus e_j$ be a proposed next state. 
Consider some fixed stabilizer state $\phi\equiv \phi_\alpha$ 
that contributes to $\psi$
and let $|\phi\ra=U_C U_H |s\ra$ be its CH-form.
Then
\be
\la y|\phi\ra=
\la x\oplus e_j|U_CU_H|s\ra = \la 0^n| U_C^{-1} X_j U_C \cdot Q_x U_H|s\ra,
\ee
where 
\[
Q_x\equiv \prod_{p=1}^n U_C^{-1} X_p^{x_p} U_C.
\]
Note that computing $Q_x$ for the initial state 
$x=x_{in}$ and $\alpha=1,\ldots,k$ takes time
$O(kn^2)$. 
Suppose $Q_x$ has been already computed.
 Since $U_C^{-1} X_j U_C$
is determined by the stabilizer tableaux of $U_C$, see Eq.~(\ref{tableaux}),
one can compute the product $Q_y= U_C^{-1} X_j U_C \cdot Q_x$ in time $O(n)$. 
Then the amplitude $\la y|\phi\ra=\la 0^n|Q_yU_H|s\ra$ can be
computed in time $O(n)$. This shows that the ratio
\[
\frac{P(y)}{P(x)}=\left| \frac{\sum_{\alpha=1}^k b_\alpha \la y|\phi_\alpha\ra}
{\sum_{\alpha=1}^k b_\alpha \la x|\phi_\alpha\ra} \right|^2.
\]
can be computed in time $O(k n)$
provided that one saves the Pauli $Q_x$
for each stabilizer term $\phi_\alpha$ after each Metropolis step.
This  achieves the runtime scaling quoted above.


In general there is no reason to expect that the Metropolis chain defined above is
irreducible. Furthermore, its mixing time is generally unknown. 
Thus the proposed algorithm should be considered as a heuristic. However, the numeric
results shown in Fig.~\ref{fig:QAOA1} were obtained using the Metropolis
method to sample from the output distribution of the QAOA circuit.

We expect that the Metropolis chain  may be rapidly mixing 
in the case when $\psi$ approximates the output state of some small-depth quantum circuit.
In particular, if $P(x)$ is the exact output distribution of a constant-depth circuit
and each Metropolis step flips $O(1)$ bits, one can use isoperimetric inequalities
derived in Refs.~\cite{eldar2017local,crosson2017quantum} to show that 
$P(x)$ is the uniqiue steady state of $\calM$
and its mixing time is at most $poly(n)$. 



\subsection{Fast norm estimation}
\label{Sec_fast_norm}
As before, consider a state
$|\psi\ra=\sum_{\alpha=1}^k b_\alpha |\phi_\alpha\ra$,
where $\phi_1,\ldots,\phi_k$ are $n$-qubit stabilizer states
specified by their CH-form.
Recall that our goal is to 
estimate the norm $\|\psi\|^2$ and to sample the probability
distribution $P(x)\sim |\la x|\psi\ra|^2$.
In this section 
we describe an algorithm that takes 
as input the target state $\psi$,
error tolerance parameters $\epsilon,\delta>0$, and
outputs a random number $\eta$ such that 
\be
\label{approx}
(1-\epsilon)\| \psi\|^2 \le \eta \le (1+\epsilon)\|\psi\|^2 
\ee
with probability at least $1-\delta$. The algorithm has runtime  
\be
\label{runtime}
O(k n^3 \epsilon^{-2} \log{\delta^{-1}}).
\ee
The key  idea  proposed in Ref.~\cite{bravyi2016improved}
is to estimate $\|\psi\|^2$ by computing inner products
between $\psi$ and randomly chosen stabilizer states $\phi$.
It can be shown~\cite{bravyi2016improved} that
the quantity $\eta \equiv 2^n |\la \phi|\psi\ra|^2$ is an unbiased estimator of 
$\|\psi\|^2$ with the standard deviation  $\approx \|\psi\|^2$,
provided that $\phi$ is drawn from the uniform distribution on the set of
stabilizer states. 
Thus the empirical mean of $\eta$ provides an estimate of $\|\psi\|^2$ with a small multiplicative error. 
The quantity $\eta$ can be computed in time $O(k n^3)$ since
$\la \phi|\psi\ra=\sum_{\alpha=1}^k b_\alpha \la \phi|\phi_\alpha\ra$
and the inner product between stabilizer states can be computed in time $O(n^3)$.

Here we improve upon the algorithm of Ref.~\cite{bravyi2016improved} 
in two respects. First, we show that 
the random stabilizer state $\phi$ used in the norm estimation method
can be drawn from a certain subset of stabilizer states that we call equatorial states. 
By definition, a stabilizer state $\phi$ is called equatorial iff it has equal amplitude
on each basis vector.  Sampling an equatorial state from the uniform distribution 
is particularly simple: all it takes is  tossing an unbiased coin $O(n^2)$ times. 
Secondly, we greatly simplify computation of the inner products $\la \phi |\phi_\alpha\ra$.
This is achieved by using the CH-form to describe stabilizer states
and by introducing a more efficient (and simpler) algorithm for computing
certain exponential sums (see Lemma~\ref{lemma:expo_sum} below).
 
We shall now formally describe the norm estimation algorithm.
Let $\calM_n$ be the set of symmetric $n\times n$ matrices $M$ 
with off-diagonal entries $\in \{0,1\}$ and diagonal 
entries $\in \{0,1,2,3\}$.
For any matrix $A\in \calM_n$ define a stabilizer state 
\begin{equation}
\label{eqa1}
|\phi_A\rangle =2^{-n/2} \sum_{x\in \{0,1\}^n}\; i^{x A x^T} |x\rangle.
\end{equation}
We shall refer to $\phi_A$ 
as an {\em equatorial state} (note that  $\phi_A$  lies
on the equator of the Bloch sphere for $n=1$). 
\begin{lemma}[\bf Norm Estimation]
\label{lemma:norm}
Let $\psi$ be an arbitrary $n$-qubit state.
Define a random variable
\begin{equation}
\label{xi}
\eta_A = 2^n |\langle \phi_A|\psi\rangle|^2,
\end{equation}
where $A\in \calM_n$ is chosen uniformly at random.
Then $\eta_A$ has mean  $\|\psi\|^2$
and its variance is at most $\|\psi\|^4$.
\end{lemma}



\begin{lemma}[\bf Inner Product]
\label{lemma:inner}
Suppose $|\phi\ra=U_CU_H|s\ra$ is a stabilizer state 
in the CH-form, where $U_H=H(v)$
and $U_C$ has a stabilizer tableaux $(F,G,M,\gamma)$.
 Suppose $\phi_A$ is an equatorial state
specified by a matrix  $A\in \calM_n$.  Define a matrix
$J\in \calM_n$ such that 
$\mathrm{diag}(J)=\gamma$ and $J_{a,b}=(MF^T)_{a,b} \modtwo$
for $a\ne b$. Define a matrix
\[
K=G^T(A+J)G.
\]
Then 
\be
\label{inner_explicit}
\la \phi | \phi_A\ra=2^{-(n+|v|)/2}  \cdot i^{sKs^T}\cdot (-1)^{s\cdot v} 
\sum_{x\le v} i^{xKx^T + 2x(s+sK)^T}.
\ee
Here the sum is over  $n$-bit strings $x$ satisfying
$x_j\le v_j$ for all $j$.
\end{lemma}
Since the Pauli operators $U_C^{-1} X_p U_C$
pairwise commute, $MF^T \modtwo$ is a symmetric matrix,
see Eq.~(\ref{tableaux}).
 Therefore $K$ is a symmetric
matrix and thus 
$i^{xKx^T}$  depends only
on off-diagonal elements of $K$ modulo two and diagonal elements of $K$
modulo four. Thus
the sum that appears in Eq.~(\ref{inner_explicit}) can be expressed as 
\[
\calZ(B)=\sum_{x\in \{0,1\}^{|v|}} i^{x Bx^T}
\]
for a suitable matrix $B\in \calM_{|v|}$,
namely, a restriction of the matrix $K+2\mathrm{diag}(s+sK)$
onto the subset of rows and columns $j$ with $v_j=1$.
We shall refer to $\calZ(B)$ as an exponential sum
associated with $B$. 
\begin{lemma}[\bf Exponential Sum]
\label{lemma:expo_sum}
There is a deterministic algorithm with a runtime 
$O(n^3)$ that takes as input a matrix $B\in \calM_n$ and
outputs integers $p,q\ge 0$ and $\alpha,\beta\in \{0,1\}$
such that $\calZ(B)=\alpha 2^p + i\beta2^q$.
\end{lemma}

The desired estimate of $\|\psi\|^2$ can now be obtained by sampling
i.i.d. random matrices $A_1,\ldots,A_L\in \calM_n$ and computing the empirical mean
$\eta= L^{-1}(\eta_{A_1}+\ldots +\eta_{A_L})$. Indeed, 
Lemma~\ref{lemma:norm} and the Chebyshev inequality imply that
$\eta$ achieves the desired approximation Eq.~(\ref{approx})
with probability at least $3/4$ if $L=4\epsilon^{-2}$. 
The error probability can be reduced to any desired level $\delta$
by generating $K=O(\log{\delta^{-1}})$ independent estimates $\eta^1,\ldots,\eta^K$
as above such that each estimate $\eta^a$ 
satisfies  Eq.~(\ref{approx}) with probability at least $3/4$.
Let $\eta_{med}$ be the median of $\eta^1,\ldots,\eta^K$.
Then standard arguments show that $\eta_{med}$ satisfies Eq.~(\ref{approx}) with probability at least $1-\delta$.
Computing each sample $\eta_{A_i}$ using Lemmas~\ref{lemma:inner},\ref{lemma:expo_sum} takes time $O(kn^3)$.
Since the total number of samples 
is $KL=O(\epsilon^{-2}\log{\delta^{-1}})$, we arrive at Eq.~(\ref{runtime}).


Finally, let us sketch how to use the norm estimation for sampling 
$x\in \{0,1\}^n$ from  a distribution 
\[
P(x)=\frac{|\la x|\psi\ra|^2}{\|\psi\|^2}.
\] 
Let $P_w(x_1,\ldots,x_w)$ be the marginal distribution  describing the first $w$
bits. We have $P_w(x)=\| \Pi \psi\|^2/\|\psi\|^2$, where
$\Pi$ projects the $j$-th qubit onto the state $x_j$ for $1\le j\le w$.
It can be written as 
\[
\Pi=2^{-w} \prod_{j=1}^w (I+(-1)^{x_j}Z_j)
\]
One can compute a rank-$k$ stabilizer decomposition of 
the state $\Pi |\psi\ra$ in time $O(kw n^2)$ using the Clifford simulator
of Section~\ref{clifford_sim}. 
By estimating the norms $\|\psi\|^2$ and $\|\Pi \psi\|^2$
one can approximate any
marginal probability $P_w(x)$ with a small multiplicative error.
In the same fashion one can approximate conditional probabilities
\[
P_w(x_w|x_1,\ldots,x_{w-1})=\frac{P_w(x_1,\ldots,x_w)}{P_{w-1}(x_1,\ldots,x_{w-1})}.
\]
Now one can sample the bits of $x$ one by one using the chain rule
\[
P(x)=P_1(x_1)P_2(x_2|x_1)\cdots P_n(x_n|x_1,\ldots,x_{n-1}).
\]
Clearly, the same method can be used to sample any marginal distribution of $P(x)$.

To avoid accumulation of errors, each of $O(n)$ steps in the chain rule requires an estimate
of the marginal probabilities  $P_w(x)$ with a multiplicative error $O(n^{-1})$.
(This guarantees that the full probability $P(x)$ is estimated using the chain rule
within a small multiplicative error.) 
This would require setting the precision $\epsilon$ in the norm estimation method as
$\epsilon=O(n^{-1})$. Thus the cost of each norm estimation would be $O(k n^3 \epsilon^{-2}) =O(k n^5)$.
Since the total number of norm estimations is $\Omega(n)$, the overall
runtime for generating a single sample from $P(x)$ with a small error would scale as
$O(k n^6)$. This quickly becomes impractical. 
However,  if our goal is to sample only $w$ bits from $P(x)$, a similar analysis
shows that the overall runtime scales as $O(k n^3 w^3)$.
Thus the sampling method based on the norm estimation is practical only for small values of $w$.
In contrast, Metropolis simulator allows one to sample all $n$ output bits
and has runtime  $O(k nT)$, where $T$ is the mixing time (which is generally unknown).


In the rest of this section we prove Lemmas~\ref{lemma:norm},\ref{lemma:inner},\ref{lemma:expo_sum}.

\begin{proof}[Proof of Lemma~\ref{lemma:norm}]
Let 
\[
Q_1=\EX_A |\phi_A\ra \la \phi_A|
\quad \mbox{and} \quad 
Q_2=\EX_A |\phi_A\ra \la \phi_A|^{\otimes 2}.
\]
Since the distribution of $A$ is invariant under shifts 
$A_{j,j}\gets A_{j,j}+2$, one concludes that $Q_1$ commutes with single-qubit Pauli-$Z$ operators.
Thus $Q_1$ is diagonal in the $Z$-basis. Furthermore, all diagonal matrix elements  of 
$|\phi_A\ra\la \phi_A|$ are equal to $2^{-n}$. This proves
$Q_1=2^{-n} I$ and thus  $\eta_A$ has expected value $2^n \la \psi|Q_1|\psi\ra=\|\psi\|^2$.

By definition,
\[
Q_2=4^{-n} \sum_{w,x,y,z} E(w,x,y,z) \cdot |w,x\rangle\langle y,z|\quad \mbox{where} \quad
E(w,x,y,z)=\EX_A \, i^{wAw^T + xAx^T - yAy^T -zAz^T}.
\]
Here the sum runs over all $n$-bit strings. 
We shall use the following fact.
\begin{prop}[\bf Ref.~\cite{bremner2016average}]
$E(w,x,y,z)=0$ unless 
$w+x=y+z {\pmod 4}$ and at least two of the strings $w,x,y$ coincide. 
\end{prop}
\begin{proof}
By definition, diagonal entries $A_{p,p}\in \ZZ_4$ 
and off-diagonal entries $A_{p,q}=A_{q,p}\in \ZZ_2$
are i.i.d. uniform random variables.
The entry $A_{p,p}$ contributes a factor $i^{A_{p,p}(w_p+x_p-y_p-z_p)}$ to $E(w,x,y,z)$.
Thus  $E(w,x,y,z)=0$ unless
\be
\label{E0part1}
w_p+x_p=y_p+z_p {\pmod 4}
\ee
for all $p$.  This proves the first claim.
The entry $A_{p,q}=A_{q,p}$
contributes a factor 
\begin{equation}
	(-1)^{A_{p,q}(w_p w_q + x_p x_q - y_p y_q - z_p z_q)} \nonumber
\end{equation}	
to $E(w,x,y,z)$. Thus  $E(w,x,y,z)=0$ unless
\be
\label{E0part2}
w_p w_q + x_p x_q - y_p y_q - z_p z_q = 0 {\pmod 2}.
\ee
From Eq.~(\ref{E0part1}) one gets $z_p = w_p+x_p+y_p {\pmod 2}$.
Substituting this expression for $z_p$ into Eq.~(\ref{E0part2}) one
 concludes
that $E(w,x,y,z)=0$ unless
\be
\label{E0part3}
(w_p x_q + w_q x_p) + (x_p y_q + x_q y_p) + (y_p w_q + y_q w_p) = 0 {\pmod 2}
\ee 
for all $p<q$. If $w=x=y$ then there remains  nothing to prove. 
Otherwise, there exists an index $p\in [n]$ such that 
exactly two of the variables $w_p,x_p,y_p$ coincide.
Since Eq.~(\ref{E0part3}) 
is symmetric under permutations of $w,x,y$, 
assume wlog that $x_p=y_p\ne w_p$.
Consider two cases.\\
{\em Case~1:} $x_p=y_p=0$ and $w_p=1$. Substituting this into Eq.~(\ref{E0part3}) one gets
$y_q=x_q$ for all $q\ne p$. Thus $x=y$.  \\
{\em Case~2:} $x_p=y_p=1$ and $w_p=0$. Substituting this into Eq.~(\ref{E0part3}) one gets
$y_q+x_q+w_q+w_q=0{\pmod 2}$ for all $q\ne p$, that is, $x=y$.\\
We conclude that at least two of the strings $w,x,y$ coincide.
\end{proof}
Let us consider the cases when $E(w,x,y,z)\ne 0$.
 {\em Case~1:} $w=x$.
Then $y+z=2x {\pmod 4}$ which is possible only if $y=z$
and thus $w=x=y=z$.
{\em Case~2:} $w=y$. Then $x=z$ and $E(y,x,y,x)=1$.
{\em Case~3:} $w=z$. Then $x=y$ and $E(z,x,x,z)=1$.
The above shows that 
non-zero contributions to $Q_2$ come only from the terms
$E(w,x,w,x)=E(w,x,x,w)=1$.  Thus 
\[
Q_2=4^{-n} (I+\mathrm{SWAP}) - 4^n \sum_x |x,x\rangle\langle x,x|,
\]
Here the last term is introduced to avoid overcounting since the terms with
$w=x=y=z$ appear in all three cases. We arrive at
\[
\EX_A (\eta_A^2) = 4^n \langle \psi^{\otimes 2} |Q_2|\psi^{\otimes 2}\rangle 
\le  \langle \psi^{\otimes 2} |I+\mathrm{SWAP}|\psi^{\otimes 2}\rangle
=2\|\psi\|^4.
\]
It follows that $\eta_A$ has variance at most $\|\psi\|^4$.
\end{proof}
\begin{proof}[Proof of Lemma~\ref{lemma:inner}]
Let $a\in \{0,1\}^n$ be an arbitrary string. From Eq.~(\ref{tableaux}) one easily gets
\[
U_C^{-1} X(a) U_C = \prod_{p=1}^n U_C^{-1} X_p^{a_p} U_C 
=i^{aJa^T} \cdot X(aF \modtwo )Z(aM \modtwo).
\]
Here $J\in \calM_n$ is defined in the statement of the lemma.
It follows that 
\[
U_C^{-1} |a\ra =U_C^{-1} X(a) U_C |0^n\ra = i^{aJa^T} |aF \modtwo\ra.
\] 
Therefore 
\[
U_C^{-1}|\phi_A\ra = 2^{-n/2} \sum_{x\in \{0,1\}^n} i^{x(A+J)x^T} |xF \modtwo\ra.
\]
Recall that $F G^T \modtwo=I$. Perform a change of variable $x=yG^T \modtwo$.
Then $x=yG^T + 2u$ for some integer vector $u$.
Using the fact that $A$ and $J$ are symmetric matrices one gets
\[
x(A+J)x^T=yG^T (A+J)G y^T + 4u(A+J)Gy^T + 4u(A+J)u^T.
\]
Denoting $K=G^T (A+J)G$ one gets
\be
\label{half1}
U_C^{-1}|\phi_A\ra 
=2^{-n/2} \sum_{y\in \{0,1\}^n} i^{y K y^T} |y\ra.
\ee
We have
\be
\label{half2}
U_H|s\ra = 2^{-|v|/2} \sum_{x\le v} (-1)^{s\cdot v + s\cdot x} |s\oplus x\ra,
\ee
Taking the inner product
of the states Eqs.~(\ref{half1},\ref{half2}) gives
\be
\label{aux_inner}
\la \phi |\phi_A\ra=\la s| U_H U_C^{-1} |\phi_A\ra = 2^{-(n+|v|)/2} (-1)^{s\cdot v} 
\sum_{x\le v} (-1)^{s\cdot x}\cdot  i^{ (s\oplus x)K (s\oplus x)^T}.
\ee
Writing $s\oplus x=s+x+2u$ for some integer vector $u$
and using the fact that $K$ is symmetric one gets
\[
(s\oplus x)K (s\oplus x)^T = (s+x)K(s+x)^T + 4uK(s+x)^T + 4uKu^T.
\]
It follows that 
\[
i^{(s\oplus x)K (s\oplus x)^T}=i^{sKs^T + xKx^T + 2xKs^T}.
\]
Combining this and Eq.~(\ref{aux_inner}) proves Eq.~(\ref{inner_explicit}).
\end{proof}

\begin{proof}[Proof of Lemma~\ref{lemma:expo_sum}]
Define a binary upper-triangular matrix $M$ of size $n\times n$
such that 
$M_{\alpha,\beta}=B_{\alpha,\beta}$  for $\alpha<\beta$.
Define binary vectors $L,K\in \{0,1\}^n$ such that 
$B_{\alpha,\alpha}=2L_\alpha + K_\alpha$ for all $\alpha$.
Then  $i^{xBx^T}=i^{q(x)}$, where $q\, : \, \{0,1\}^n \to \ZZ_4$
is a binary quadratic form  defined as 
\begin{equation}
\label{q}
q(x)=2\sum_{1\le \alpha< \beta \le n} M_{\alpha,\beta} x_\alpha x_\beta  + \sum_{1\le \alpha\le n} (2L_\alpha + K_\alpha) x_\alpha
{\pmod 4}.
\end{equation}
Our goal is to compute the exponential sum
\begin{equation}
\label{Z}
\calZ \equiv \sum_{x\in \{0,1\}^n} i^{q(x)}.
\end{equation}
The first observation is that exponential sums associated with $\ZZ_2$-valued quadratic forms
can be computed recursively.  Indeed, assume that $K_\alpha=0$ for all $\alpha$. 
Then 
\begin{equation}
\label{Zreal}
\calZ=\sum_{x\in \{0,1\}^n}  (-1)^{Q(x)} \quad  \mbox{where} \quad Q(x)=xM x^T + L x^T   {\pmod 2}.
\end{equation}
It will be convenient to consider more general quadratic forms $Q(x)$ as in Eq.~(\ref{Zreal})
where $M$ is an arbitrary binary matrix. We allow $M$ to be  non-symmetric
and  have non-zero diagonal. 

Consider first the trivial case when $M$ is a symmetric matrix. 
In this case all quadratic terms in $Q(x)$ cancel each other, that is, $Q(x)$ is linear.
Thus  $\calZ=2^n$ if $L=\mathrm{diag}(M)$ and $\calZ=0$ otherwise.

Suppose now that  $M$ is non-symmetric. 
We can assume wlog that $M_{1,2}\ne M_{2,1}$ (otherwise permute the variables). 
Then $M_{1,2}+M_{2,1}=1 {\pmod 2}$.
Write $x=(x_1,x_2,y)$ with $y\in \{0,1\}^{n-2}$. Define a partial sum 
\begin{equation}
\label{eq1partialsum}
\calZ(y) = \sum_{x_1,x_2\in \{0,1\}}\; (-1)^{Q(x_1,x_2,y)}=
\sum_{x_1,x_2\in \{0,1\}}\; (-1)^{x_1 x_2 + \mu_1(y)  x_1 + \mu_2(y) x_2 + Q_{else}(y)},
\end{equation}
where $Q_{else}(y)$ includes all terms in $Q(x)$ that do not depend on $x_1,x_2$, 
\[
\mu_1(y) = L_1  + M_{1,1} +  \sum_{3\le \alpha \le n} (M_{1, \alpha} + M_{\alpha,1}) y_\alpha
\equiv L_1 + M_{1,1} + m_1  y^T,
\]
\[
\mu_2(y)= L_2 +M_{2,2} +  \sum_{3\le \alpha \le n} (M_{2, \alpha}  + M_{\alpha,2}) y_\alpha 
\equiv L_2 + M_{2,2} +  m_2 y^T. 
\]
Here $m_1,m_2$ are row vectors of length $n-2$. 
A simple algebra shows that 
\begin{equation}
\label{identity}
\sum_{x_1,x_2\in \{0,1\}}\;  (-1)^{x_1 x_2 + \mu_1  x_1 + \mu_2 x_2}= 2(-1)^{\mu_1 \mu_2}
\qquad \mbox{for all $\mu_1,\mu_2\in \{0,1\}$}.
\end{equation}
Substituting this identity into Eq.~(\ref{eq1partialsum}) gives
\begin{equation}
% \label{eq3}
\calZ=\sum_{y\in \{0,1\}^{n-2}}\;  \calZ(y)=2 (-1)^{(L_1+M_{1,1})( L_2 + M_{2,2}) } \sum_{y\in \{0,1\}^{n-2}}\; (-1)^{Q'(y)},
\end{equation}
where $Q'(y)$ is a quadratic form that depends on  $n-2$ variables:
\begin{equation}
\label{eq5}
Q'(y)=y( M_{else} + m_1^T m_2 ) y^T + (L_{else} +  [L_1 + M_{1,1}] m_2 + [L_2 + M_{2,2}] m_1 )y^T
\end{equation}
The matrix $M_{else}$ and the vector $L_{else}$ are determined by
$Q_{else}(y)=yM_{else} y^T + L_{else} y^T$.
We have reduced the exponential sum problem with $n$ variables
to the one with $n-2$ variables. 
Clearly, the coefficients of $Q'(y)$ can be  computed 
in time $O(n^2)$. The overall runtime is $\sum_{k=1}^n O(k^2)=O(n^3)$.
This gives an algorithm for computing the exponential sum for a $\ZZ_2$-valued
quadratic form. 

{\em Remark:} The most time-consuming step is getting the matrix
$M_{else} + m_1^T m_2$. Since the arithmetics is mod-2, this amounts to flipping all
bits of $M_{else}$ in a submatrix formed by rows $i\in m_1$ and by columns $j\in m_2$.

Consider now a $\ZZ_4$-valued form $q(x)$ defined in Eq.~(\ref{q}).
Define a $\ZZ_2$-valued form 
\begin{equation}
\label{Q}
Q(x)=\sum_{1\le \alpha<\beta \le n} (M_{\alpha,\beta} + K_\alpha K_\beta) x_\alpha x_\beta
+ \sum_{1\le \alpha \le n} K_\alpha x_\alpha x_{n+1} + \sum_{1\le \alpha\le n} L_\alpha x_\alpha {\pmod 2}.
\end{equation}
\begin{prop}
Let $\calZ$ be the exponential sum defined by Eqs.~(\ref{q},\ref{Z}). Then 
\begin{equation}
\label{real}
\mathrm{Re}(\calZ)=\frac12 \sum_{x\in \{0,1\}^{n+1}} \; (-1)^{Q(x)}
\quad \mbox{and} \quad
\mathrm{Im}(\calZ)=\frac12 \sum_{x\in \{0,1\}^{n+1}} \; (-1)^{Q(x)+x_{n+1}}.
\end{equation}
\end{prop}
\begin{proof}
Write $q(x)=2r(x) + Kx^T  {\pmod 4}$, where $r(x)$ is a $\ZZ_2$-valued quadratic form.
Consider some $x\in \{0,1\}^n$ and let $\omega \equiv K x^T {\pmod 2}$.
One can easily check that
\[
i^{Kx^T } = (-1)^{\sum_{1\le \alpha<\beta\le n}\; K_\alpha K_\beta x_\alpha x_\beta} \cdot i^\omega.
\]
By definition $\omega\in \{0,1\}$ so that
\[
\mathrm{Re}(i^\omega)=\frac12 (1+(-1)^\omega) \quad \mbox{and} \quad
\mathrm{Im}(i^\omega)=\frac12 (1-(-1)^\omega).
\]
Define a $\ZZ_2$-valued form $Q'(x)=r(x) + \sum_{1\le \alpha<\beta\le n}\; K_\alpha K_\beta x_\alpha x_\beta$.
Then 
\[
\mathrm{Re}(i^{q(x)})=\frac12\left[  (-1)^{Q'(x)} + (-1)^{Q'(x) + K x^T}\right] \quad
\mbox{and} \quad
\mathrm{Im}(i^{q(x)})=\frac12\left[  (-1)^{Q'(x)} - (-1)^{Q'(x) + K x^T}\right].
\]
Finally, add an extra variable $x_{n+1}$ such that the two terms in the square brackets 
correspond to $x_{n+1}=0$ and $x_{n+1}=1$ respectively. We arrive at Eq.~(\ref{real})
with $Q(x,x_{n+1})=Q'(x) +x_{n+1}(K x^T)$.
\end{proof}
\end{proof}

{\em Remark:} Computing   exponential sums
associated with the real and imaginary parts
of $\calZ$ takes about the same time as computing a single exponential sum
Eq.~(\ref{Zreal}) because the forms $Q(x)$ and $Q(x)+x_{n+1}$
in Lemma~2 have the same quadratic parts. 

Numerics shows that the new algorithm 
for computing exponential sums
achieves a significant speedup as is shown in Table~\ref{table:1}. Altogether, the use of the phase-sensitive Clifford simulator, sampling with equatorial states, and the improved Exponential Sum routine lead to a significant performance increase in simulations. In Table~\ref{table:HStimings}, we compare the performance of the simulator in Ref.~\cite{bravyi2016improved} and this paper, when estimating the output probabilities of the Hidden Shift problem on $40$-qubits with the Sum-over-Cliffords method (see also Sections~\ref{sec:simulations} and \ref{sec:numericresults}).

\begin{table}[!h]
\centerline{
\begin{tabular}{r|c|c|c|c|c|c}
Number of variables $n$ & $\bf 10$ & $\bf 20$ & $\bf 30$ & $\bf 40$  & $\bf 50$ & $\bf 60$  \\
\hline
New runtime & $0.016$ & $0.017$ & $0.021$ & $0.023$ & $0.030$ & $0.036$  \\
\hline
BG16 runtime & $0.42$ & $0.50$ & $0.77$ & $1.10$ & $1.40$ & $1.72$  \\
\end{tabular}}
\caption{Average runtime in milliseconds  of
the new algorithm for computing exponential sums
and comparison with the algorithm of Ref.~\cite{bravyi2016improved}.
Both simulations were performed on a Linux PC with a 3.2$\mathrm{GHz}$ Intel~i5-6500 CPU.
}
\label{table:1}
\end{table}

\begin{table}[h]
\centerline{
	\begin{tabular}{c|c|c|c}
	Number of CCZ Gates & 2 & 4 & 6 \\
	\hline
	Number of states $\chi_{\Delta}$ & 39 & 149 & 497 \\
	\hline
	New Runtime $\left(\mathrm{s}\right)$ & 0.30 & 1.02 & 3.82 \\
	\hline
	BG16 Runtime $\left(\mathrm{s}\right)$ & 5.22 & 27.94 & 100.11 \\
	\end{tabular}
}
\caption{Average runtime of the Norm Estimation step in seconds, for the new implementation compared with that of Ref.~\cite{bravyi2016improved}. Norm Estimation is used to compute single qubit marginals on a $40$-qubit state, with precision $\Delta=0.3$. Both simulations were single-threaded, and run on a Linux PC with a 3.2$\mathrm{GHz}$ Intel i5-6500 CPU.}
\label{table:HStimings}
\end{table}

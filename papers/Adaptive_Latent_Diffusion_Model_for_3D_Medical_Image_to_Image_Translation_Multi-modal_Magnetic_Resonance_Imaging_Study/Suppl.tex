\clearpage
\setcounter{page}{1}
\setcounter{table}{0}
\setcounter{figure}{0}
\section*{Supplementary Materials}

\appendix

\renewcommand{\thesection}{\Alph{section}}
\renewcommand{\thefigure}{\Alph{figure}}
\renewcommand{\thetable}{\Alph{table}}

\section{Hyperparameter setting}

In this section, we provide a detailed description of the model architecture and hyperparameters for the autoencoder used in image compression, as well as the structure of the diffusion model. The input dimension for all networks is 3D. For the autoencoder, we applied the network architecture of VQGAN \cite{esser2021taming}, which is explained in Table \ref{tableA}. The structure of the MS-SPADE block present in the bottleneck of the autoencoder is described in Table \ref{tableB}. Additionally, we applied a UNet-based network architecture to the diffusion model used in previous studies \cite{ho2020denoising, rombach2022high}, which is explained in Table \ref{tableC}.

\begin{table}[h]
    \centering
    \scalebox{0.90}{
        \resizebox{\columnwidth}{!}{%
            \begin{tabular}{cccc}
                \toprule
                Input Size & dim $|\mathcal{Z}|$ & Channels & Embedding Size \\
                \midrule
                $192 \times 192 \times 144$ & 8192 & \text{[}256,512,512\text{]} &  3  \\
                \midrule
                Batch Size & Epochs & Model Size & Param Size \\
                \midrule
                1 & 500 & 749M & 237M  \\
                \bottomrule
            \end{tabular}
            }
    }
    \vspace{-6pt}
    \caption{Detailed Hyperparameters for latent diffusion model.} 
    \vspace{-9pt}
    \label{tableA}
\end{table}

\begin{table}[h]
    \centering
    \resizebox{\columnwidth}{!}{%
        \begin{tabular}{cccccccc}
            \toprule
            \multicolumn{8}{c}{MS-SPADE Block} \\
            \midrule
             Stream & Conv. & Act. & Norm. & Conv. & Act. & Norm. & Out ch.\\
             \midrule
             \textbf{In}& $C_{7}$ &  & IN &  & ReLU &  & 128\\
             \midrule
             \textbf{ResBlock}& $C_{3}$ & ReLU & IN & $C_{3}$ & ReLU & IN & \text{[}256,256\text{]}\\
            \midrule
             \textbf{SPADEBlock}& $C_{3}$ & ReLU & MS-SPADE & $C_{3}$ & ReLU & MS-SPADE & \text{[}256,256,256,128\text{]}\\
             \midrule
             \textbf{Out}& $C_{7}$ &  &  &  &  &  & 3\\
            \bottomrule
        \end{tabular}
        }
    \vspace{-6pt}
    \caption{Detailed MS-SPADE Block. $C_{i}$ is the convolution layer with $i \times i$ kernel. $IN$ is the instance normalization layer, and MS-SPADE is the Multi switchable SPADE layer that is applied differently depending on the target modality. Out ch. represents the output channels, and both ResBlocks and SPADEBlocks are repeated 2 and 4 times, respectively} 
    \vspace{-9pt}
    \label{tableB}
\end{table}

\begin{table}[h]
    \centering
    \resizebox{\columnwidth}{!}{%
        \begin{tabular}{ccccc}
            \toprule
            Stream & Condi & Batch Size  & Model Size & Param Size \\
            \midrule
            $48 \times 48 \times 36 \times 3$ &  \text{[}128,256,512\text{]} & 1 & 722M & 658M  \\
            \midrule
            Diffusion steps & Noise Scheculde & $\beta_{start}$ & $\beta_{end}$ & Epochs \\
            \midrule
            1000 & scaled-linear & 0.0015 & 0.0195 & 800 \\
            \bottomrule
        \end{tabular}
        }
    \vspace{-6pt}
    \caption{Detailed hyperparameters for latent diffusion model.} 
    \vspace{-9pt}
    \label{tableC}
\end{table}


\begin{figure*} [ht]
    \centerline{\includegraphics[scale=0.2]{fig-A.jpg}}
    \vspace{-10pt}
    \caption{ The figures showcase the image translation results on the IXI dataset from each source modality to the corresponding target modality using our proposed model for all possible combinations. }
    % \vspace{-3pt}
    \label{figA}
\end{figure*}

\begin{table*} [ht]
    \centering
    \scalebox{0.80}{
        \begin{tabular}{cccccccccc}
            \toprule
            \diagbox[height=1.5\line]{Source}{Target} & \multicolumn{3}{c}{T1} & \multicolumn{3}{c}{T2} & \multicolumn{3}{c}{PD} \\
            \cmidrule(lr){1-1} \cmidrule(lr){2-4} \cmidrule(l){5-7} \cmidrule(l){8-10} 
             Metric &\small{PSNR $\uparrow$}&\small{NMSE $\downarrow$}&\small{SSIM $\uparrow$}&\small{PSNR $\uparrow$}&\small{NMSE $\downarrow$}&\small{SSIM $\uparrow$}&\small{PSNR $\uparrow$}&\small{NMSE $\downarrow$}&\small{SSIM $\uparrow$}\\ 
            \midrule
            \multirow{2}{*}{T1} 
            & \textit{29.487} & \textit{0.047} & \textit{0.941}
            & 27.265 & 0.071 & 0.921
            & {27.729} & {0.072} & {0.922} \\
            & \textit{\footnotesize{$\pm$0.522}} & \textit{\footnotesize{$\pm$0.020}} & \textit{\footnotesize{$\pm$0.024}} & {\footnotesize{$\pm$0.629}} & {\footnotesize{$\pm$0.022}} & {\footnotesize{$\pm$0.015}} & 
            \footnotesize{$\pm$0.685} & \footnotesize{$\pm$0.025} & \footnotesize{$\pm$0.018} \\
            
            \multirow{2}{*}{T2} 
            & {27.368} & {0.074} & {0.929} 
            & \textit{29.259} & \textit{0.045} & \textit{0.937}
            & \textbf{27.913} & \textbf{0.067} & \textbf{0.927} \\
            & {\footnotesize{$\pm$0.624}} & {\footnotesize{$\pm$0.031}} & {\footnotesize{$\pm$0.027}} 
            & \textit{\footnotesize{$\pm$0.582}} & \textit{\footnotesize{$\pm$0.017}} & \textit{\footnotesize{$\pm$0.015}} & 
            \textbf{\footnotesize{$\pm$0.659}} & \textbf{\footnotesize{$\pm$0.023}} & \textbf{\footnotesize{$\pm$0.019}} \\

            \multirow{2}{*}{PD} 
            & \textbf{27.968} & \textbf{0.070} & \textbf{0.931} 
            & \textbf{27.834} & \textbf{0.067} & \textbf{0.925} 
            & \textit{29.396} & \textit{0.042} & \textit{0.939} \\
            & \textbf{\footnotesize{$\pm$0.521}} & \textbf{\footnotesize{$\pm$0.028}} & \textbf{\footnotesize{$\pm$0.028}} 
            & \textbf{\footnotesize{$\pm$0.627}} & \textbf{\footnotesize{$\pm$0.024}} & \textbf{\footnotesize{$\pm$0.025}}             & \textit{\footnotesize{$\pm$0.488}} & \textit{\footnotesize{$\pm$0.019}} & \textit{\footnotesize{$\pm$0.027}} \\
            
            \bottomrule
        \end{tabular}
    }
    \vspace{-3pt}
    \caption{The values present the quantitative evaluation of image translation results on the IXI dataset from source modalities to target modalities using our proposed model.} 
    \vspace{-8pt}
    \label{tableD}
\end{table*}

\section{Dataset}
We trained our model on the BraTS 2021 training dataset, encompassing 1251 subjects and four MRI modalities (T1, T1ce, T2, FLAIR). Each MRI scan measures $240\times240\times155$ in dimensions, with a spatial resolution of $1\times1\times1 mm^3$. To assess our model's image translation capabilities, we utilized the BraTS 2021 validation dataset, containing 219 subjects. Additionally, we tested our model using the IXI dataset, including T1, T2, and PD modalities. From the 574 subjects, 459 were allocated for training and 115 for testing. Each of these MRI scans measures $256\times150\times256$ in dimensions with a spatial resolution of $0.9375\times0.9375\times1.2 mm^3$



\section{Comparison Methods details}
To validate the effectiveness of our model, we used commonly used methods in medical image-to-image translation as comparison models. For 2D methods, we employed Pix2Pix \cite{isola2017image}, CycleGAN \cite{zhu2017unpaired}, NICEGAN \cite{chen2020reusing}, RegGAN, \cite{NEURIPS2021_0f281810} and ResViT \cite{dalmaz2022resvit}. For the 3D method, we employed the 3D versions of pix2pix and CycleGAN, as well as the EaGAN proposed as a 3D method, for comparison.
We compared using the discriminator-induced Ea-GAN (dEa-GAN) model as presented in the reference \cite{yu2019ea}. 3D methods are not as commonly used and come with higher computational costs making it challenging to extend existing 2D models to 3D. 
2D methods were executed with a batch size of 32 in the axial view. For the BraTS dataset, they operated on images sized $240\times240$, while for the IXI dataset, zero padding was added to process images at $256\times160$ dimensions. All 3D methods were conducted with a batch size of 1. On the BraTS dataset, images were cropped to $192\times192\times144$ after background removal. For the IXI dataset, images were cropped and padded to measure $256\times160\times224$.

\vspace{1cm}

\section{Additional Experimental Results}
We also analyze which source modality is most effective in synthesizing the target modality within the IXI dataset. Figure \ref{figA} provides the qualitative evaluation results of this multi-modal translation, while Table \ref{tableD} offers the quantitative assessment outcomes. From the qualitative evaluation, we observe that there are minimal differences between modalities, and most present a satisfactory translation performance. As for the quantitative evaluation, it is evident that PD is effective in image translation when generating T1, and similarly for T2. Conversely, T2 proves to be efficient when producing PD images.

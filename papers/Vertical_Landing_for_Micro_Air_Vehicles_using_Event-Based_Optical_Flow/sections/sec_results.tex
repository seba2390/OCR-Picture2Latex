\section{Constant Divergence Landing Experiments}
\label{sec:results}
This section presents experimental results of constant divergence landings with the presented algorithms in the control loop. In \cref{sec:results_controller} the divergence control law is defined, after which the experimental setup is detailed in \cref{sec:experimental_setup}. Results from the experiments are presented and discussed in \cref{sec:results_div_landings}.

\subsection{Divergence Controller}
\label{sec:results_controller}
The control law regulates $\vartheta_z$ through the vertical thrust $T$. The controller applies a thrust difference $\Delta T$ with respect to a nominal hover thrust $T_0$, such that $T = T_0 + \Delta T$. A simple proportional control law is applied to $\Delta T$ based on $\vartheta_z$, similar to \citet{DeCroon2016}:

\begin{equation}
\Delta T = k_P \left(\vartheta_{z_{r}}-\vartheta_z\right)
\end{equation}

The nominal hover thrust $T_0$ counteracts the weight of the test vehicle. Its value is adapted in-flight in the height control loop of the test vehicle's autopilot software. Before the start of each landing, the vehicle first performs automatic hover to obtain a stable estimate for $T_0$. During the subsequent landing maneuver its value is kept constant.

\subsection{Experimental Setup}
\label{sec:experimental_setup}
The flying platform used in this work is a customized quadrotor referred to as the MavTec. Its main component is a Lisa/M board, which features a 72MHz 32bit ARM microprocessor as well as a pressure sensor and 3-axis rate gyros, accelerometers, and magnetometers. The Lisa/M runs the open-source autopilot software Paparazzi\footnote{Paparazzi UAV, \url{http://wiki.paparazziuav.org/}}, which handles the control of the drone\footnote{Code used in project is publicly available at: \url{https://github.com/tudelft/paparazzi/tree/event_based_flow}}. The DVS is mounted at the bottom of the MavTec facing downwards, aligned according to the reference frame definitions of $\cal C$ and $\cal B$ in \cref{sec:model}. Experiments are performed indoors, using an Optitrack motion tracking system to measure ground truth position and attitude.

In addition, an Odroid XU4 board is mounted on the quadrotor, which processes the event output of the DVS. It features a Samsung Exynos 5422 octacore CPU (four cores at 2.1 GHz and four at 1.5 GHz). The Odroid receives the events from the DVS through a USB 2.0 connection and processes these through the C-based open-source software cAER\footnote{Code used in project is publicly available at: \url{https://github.com/tudelft/caer/tree/odroid-dvs}} \cite{Longinotti2014}. 

%Experiments are performed indoors, using an OptiTrack motion tracking system. In previous work using similar systems, test objects were fitted with passive markers, which reflect infrared strobing light generated by the system. However, in \cite{Censi2013} the strobing was found to interfere with DVS measurements, since the camera is most sensitive in the infrared spectrum. This was confirmed during early experiments with passive markers: even strobing reflected by the ground was perceivable by the DVS. In later experiments, the drone was instead fitted with active infrared LEDs, allowing OptiTrack strobing to be disabled. As a favorable side-effect, this facilitated timestamp synchronization of OptiTrack and on-board measurements.

\begin{figure*}[!ht]
	\centering
	\begin{framed}
		\begin{minipage}[c]{0.3\textwidth}
			\centering
		\subfloat[Top view]{
			\includegraphics[width=\textwidth]{images/mavtec.png}
			\label{fig:mavtec_top}
		}\par\vfill
		\subfloat[Bottom view showing the DVS]{
			\includegraphics[width=\textwidth]{images/mavtec_bottom2.png}
			\label{fig:mavtec_bottom}
		}
		\end{minipage}\hfill
		\begin{minipage}[c]{0.67\textwidth}
			\subfloat[Overview of the implementation]{
				\includegraphics[width=\textwidth]{images/flowchart_implementation}
				\label{fig:implementation}
			}
		\end{minipage}
		\caption{Overview of the experimental setup, including pictures of the MavTec. In \protect\subref{fig:mavtec_top} a top view of the vehicle is shown. The DVS is located at the bottom, protected by a foam cover. In \protect\subref{fig:mavtec_bottom} the cover is removed to expose the DVS. In \protect\subref{fig:implementation} an overview of the processing workflow is shown, indicating the distribution of processes over the Odroid and the Lisa/M processors.}
		\label{fig:mavtec}
	\end{framed}
\end{figure*}

An overview of the experimental setup is shown in \cref{fig:mavtec}, including an overview of the on-board processing workflow in \cref{fig:implementation}. The estimation pipeline is subdivided in two stages. First, raw events are transmitted from the DVS to the Odroid through a USB interface. In cAER, optical flow is computed from the events using an implementation of our optical flow algorithm. Any event for which flow is estimated, is transmitted to the Lisa/M board through a serial UART interface. This process is completely event-based and is performed in a single thread. Separate threads handle event reception and transmission through the USB and UART interfaces.

Second, in Paparazzi, a periodic follow-up processing thread runs at 100 Hz. At each iteration, all newly received optical flow events are collected and corrected for the quadrotor's attitude and rotational motion. When all new events are processed, new estimates of the scaled velocities are computed with accompanying confidence values. A separate thread running at 512 Hz performs divergence control using the new update for $\vartheta_z$, as well as horizontal position control and stabilization.

%The source code for our versions of cAER and Paparazzi are publicly available online\footnote{cAER: \url{https://github.com/baspijhor/caer/tree/flow_adaptive_final}\\Paparazzi: \url{https://github.com/baspijhor/paparazzi/tree/event_based_flow}}.

\subsection{Results}
\label{sec:results_div_landings}
Constant divergence landing maneuvers were performed for several values of the setpoint $\vartheta_{z_r}$. During the tests, the target ground location was covered with the roadmap textured mat shown in \cref{fig:roadmap}. Currently, no mechanism is implemented to account for instability of constant divergence landings at low height, as described in \citet{DeCroon2016}. Therefore, when significant self-induced oscillations are observed, the landing maneuver is manually terminated. 

Resulting flight profiles (height, vertical speed, and divergence) are shown in \cref{fig:const_div_landing_1} for setpoints of $\vartheta_{z_r}=\lbrace0.5, 0.7,1.0\rbrace$\footnote{Video of the landings performed can be found at: \url{https://www.youtube.com/playlist?list=PL_KSX9GOn2P8RBdSyzngewi76G37PI3SF}}. Note that these values are much higher than the setpoints in comparable frame-based experiments \cite{Herisse2012,Ho2016}. The estimates for $\vartheta_z$ are shown in comparison to the ground truth estimate and the corresponding setpoint. For these maneuvers, the proportional gain $k_P$ is set to 0.2. This gain ensures that the descent remains stable during the first part. Decent tracking performance is seen for the lower two setpoints, while at $\vartheta_{z_r}=1.0$ some overshoot is observed. Still, a faster response may be obtained with an adaptive gain, such as in \citet{Ho2016a}. 

The expected instability is also clearly visible. For each setpoint, oscillations with diverging amplitude start to appear when the height is around 0.6 m above the ground, requiring the maneuver to be aborted manually at the moment. Also, a time delay is observed, whose magnitude differs between datasets. By examining the cross-correlation functions of the estimate and ground truth signals, average time delays of 0.05 s, 0.04 s, and 0.10 s are observed for the respective signals. A possible cause for this is the latency in the UART interface between the Odroid and the Lisa/M. Also, part of the delay results from the confidence filter that delays visual observable updates around zero-crossings.

%(So far,) tests were executed using a setpoint of $\vartheta_{z_{ref}}=0.2$ above a roadmap floor texture. A typical flight profile is shown in \cref{fig:const_div_landing_1} together with estimates for $\vartheta_z$ and ground truth, as well as the estimate confidence. At the indicated point, the divergence controller switches on and gradually brings the drone towards the ground. Due to the low gain, $\vartheta_z$ converges relatively slowly to the setpoint, but results in a smooth descent. As expected from \citet{Ho2016}, oscillations are visible when the height is close to zero. In our tests, this prevented a final touchdown, and manual control was resumed at the end of the maneuver. Some small jumps are visible in the vertical velocity, due to local underestimation of $\vartheta_z$. Interestingly, during the oscillations in the final part, $\vartheta_z$ is overestimated. (With the implementation for these experiments, this is possibly due to residual horizontal motion, which at the time provided less favorable coupling with divergence).

\begin{figure}[h]
	\centering
	\setlength{\fwidth}{0.4\linewidth}
	\input{images/const_div_landing_1}
	\caption{Height above ground, vertical speed, and divergence measurements with ground truth during a constant divergence landings performed at three different divergence setpoints. In the bottom graph, the dotted, dashed, and solid lines represent the setpoint, ground truth, and estimate for $\vartheta_z$ respectively.}
	\label{fig:const_div_landing_1}
\end{figure}

In practice, the visual observable estimator thread running on the Lisa/M microprocessor does not maintain its target frequency of 100 Hz with an optical flow measurement rate $\rho_{F_{max}}$ of 2500 events per second. Instead, it drops to around 75 Hz during the landing maneuvers. However, given the limited processing power of the microprocessor, this is still a decent result. It well exceeds sampling rates seen in recent frame-based optical flow estimation pipelines, which are in the order of 15 to 25 Hz \cite{Herisse2012,Alkowatly2015,Ho2016a,DeCroon2016}. Also, with a lower setting of $\rho_{F_{max}}$ (around 2000 optical flow events per second), the target frequency of 100 Hz is well attainable. The Odroid can transmit up to approximately 8500 optical flow events per second over the UART connection, limited by the baud rate of 921.6 kB per second.

For the largest part, the maneuvers are executed successfully, even for high divergence values setpoints. With $\vartheta_{z_r}=1.0$, the MAV performs a rapid maneuver, descending from a height of 3.5 m to 1 m within 1.79 s. In comparable recent experiments with frame-based cameras for divergence measurement \cite{Ho2016a}, landings were performed up to $\vartheta_{z_r}=0.3$. Since higher values have not been attempted in these experiments, we cannot know for certain that frame-based optical flow is not applicable to such high speeds\footnote{It is planned to perform some landing tests outdoors in an unmodified outdoor environment to test the landing at even higher rates of divergence to explore the limits of our approach. The results of those tests may be included in a revised version of this paper.}.
%A time delay is also observed, which differs between datasets. By examining the cross-correlation functions of the estimate and ground truth signals, time delays of 0.05 s, 0.04 s, and 0.10 s are observed for the respective signals. A likely cause for this is the UART interface between the Odroid and the Lisa/M boards,

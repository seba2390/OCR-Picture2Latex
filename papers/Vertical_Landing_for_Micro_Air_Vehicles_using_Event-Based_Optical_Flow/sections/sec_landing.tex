\section{Estimation of Visual Observables from Event-Based Optical Flow}
\label{sec:landing_eof}
This section describes our approach for estimating visual observables from event-based optical flow. While optic flow estimation is performed asynchronously, most existing control systems still operate on a periodic basis. Similarly, the proposed algorithm aims to update the estimates of visual observables at a fixed rate. For each periodic iteration, all newly detected optical flow vectors between the current iteration and the previous one form a planar optical flow field, of which the parameters are estimated. 

The algorithm is based on two components. First, newly detected optical flow vectors are grouped per direction and incorporated into a weighted least-squares estimator for the visual observables, as discussed in \cref{sec:vo_directional_flow_fields}. To enable preservation of flow field information over subsequent periodic iterations, a recursive update technique is introduced in \cref{sec:vo_recursive}. In addition, a confidence value is computed and applied to filter the visual observable estimates, as is described in \cref{sec:vo_confidence}. The estimator is evaluated in combination with our event-based optical flow algorithm in \cref{sec:results_scaled_velocity}.

\subsection{Directional Flow Field Parameter Estimation}
\label{sec:vo_directional_flow_fields}
The presented approach is based on techniques introduced in \citet{DeCroon2013} and used in \citet{Alkowatly2015,Ho2016}, in which fully defined optical flow estimates are available. Since our optical flow algorithm provides normal flow output, a regular optical flow field representation as in \cref{eq:planar_flow_field1} leads to inaccurate parameter estimates. However, in planar flow fields, normal flow may already provide sufficient information for computing the visual observables. Along the direction of the flow vector, normal flow does provide accurate information. 

An example diverging flow field with both optical flow and normal flow is sketched in \cref{fig:normalFlowField}. Note that the normal flow in some cases deviates significantly from the optical flow equivalent, which leads to significant errors when computing the flow field parameters. However, when grouped by direction (which is done in \cref{fig:normalFlowField} through the arrow colors), the normal flow vectors indeed show the original pattern of divergence. This idea is central to the proposed directional flow fields approach.

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.35\linewidth]{normalFlowField}
	\caption{Example of a diverging flow field resulting from several randomly oriented moving edges. The gray vectors indicate the true flow field, while the colored vectors show the normal flow along the edge orientation. Each color indicates a group of normal flow vectors with similar direction.}
	\label{fig:normalFlowField}
\end{figure}

In order to observe flow field divergence along a normal flow direction, at least two separate normal flow vectors are required, whose positions are sufficiently apart. For example, in \cref{fig:normalFlowField} the purple group of normal flow vectors does not, by itself, provide sufficient information for perceiving divergence. Also, if the flow vectors are located in close proximity, errors in normal flow magnitude have a larger influence. In \cref{fig:normalFlowField} the green group is more sensitive to these errors than the red group, since the edges are located closely together. Grouping per direction enables assessment of the reliability of the flow field in each direction, taking the previous issues into account.

A set of $m$ directions $\lbrace\alpha_1,\alpha_2,\ldots,\alpha_N\rbrace$ is defined, where $\alpha_1=0$ and $\alpha_i-\alpha_{i-1} = \pi/m$. In this work, $m=6$ directions are used. For each newly available flow vector, we first determine the closest match of $\alpha_i$ to the flow direction $\alpha_f$. Each direction $\alpha_i$ accommodates both flow in similar and opposite direction, i.e. when $-\pi<\alpha_f<0$, a match is computed for $\alpha_f + \pi$. 

Along the selected direction $\alpha_i$, the projected normal flow position $S$ and magnitude $V$ are computed, hence obtaining a one-dimensional representation of the flow along $\alpha_i$:

\begin{equation}
\label{eq:transform_flow_field}
\left[ {\begin{array}{*{20}{c}}
	S\\
	V
	\end{array}} \right] = \left[ {\begin{array}{*{20}{c}}
	{\hat x}&{\hat y}\\
	{\hat u}&{\hat v}
	\end{array}} \right]\left[ {\begin{array}{*{20}{c}}
	{\cos \alpha_i }\\
	{\sin \alpha_i }
	\end{array}} \right]
\end{equation}

Subsequently, it is corrected for rotational motion by subtracting the normal component of the rotational flow:

\begin{equation}
\begin{aligned}
{V_T} = V &- \cos {\alpha _i}\left( {p - \hat yr - q\hat x\hat y + p{{\hat x}^2}} \right) \\~&+ \sin {\alpha _i}\left( {q - \hat xr - p\hat x\hat y + q{{\hat y}^2}} \right)
\end{aligned}
\end{equation}

For each direction, a one-dimensional flow field is maintained. From \cref{eq:planar_flow_field1} and \cref{eq:transform_flow_field}, the flow field in a single direction is expressed as:

\begin{equation}
\label{eq:flow_field_line}
V_T =  - {\vartheta _x}\cos \alpha_i  - {\vartheta _y}\sin \alpha_i  + {\vartheta _z}S
\end{equation}

To solve \cref{eq:flow_field_line} for the visual observables, a weighted least-squares solution is computed using the flow vectors from all directions. Let $\mathrm{c}_\alpha=\cos\alpha$ and $\mathrm{s}_\alpha=\sin\alpha$. The overdetermined system to be solved is composed as follows:
\begin{equation}
\label{eq:dir_flow_field_system}
\arraycolsep=1.4pt
\left[ {\begin{array}{*{20}{c}}
	{ - {\rm{c}}_{\alpha _1}}&{ - {\rm{s}}_{\alpha _1}}&{{S_{1,1}}}\\
	\vdots & \vdots & \vdots \\
	{ - {\rm{c}}_{\alpha _1}}&{ - {\rm{s}}_{\alpha _1}}&{{S_{1,{n_1}}}}\\
	{ - {\rm{c}}_{\alpha _2}}&{ - {\rm{s}}_{\alpha _2}}&{{S_{2,1}}}\\
	\vdots & \vdots & \vdots \\
	{ - {\rm{c}}_{\alpha _2}}&{ - {\rm{s}}_{\alpha _2}}&{{S_{1,{n_2}}}}\\
	\vdots & \vdots & \vdots \\
	{ - {\rm{c}}_{\alpha _m}}&{ - {\rm{s}}_{\alpha _m}}&{{S_{m,{n_m}}}}
	\end{array}} \right]\left[ {\begin{array}{*{20}{c}}
	{{\vartheta _x}}\\
	{{\vartheta _y}}\\
	{{\vartheta _z}}
	\end{array}} \right] \approx \left[ {\begin{array}{*{20}{c}}
	{{V_{1,1}}}\\
	\vdots \\
	{{V_{1,{n_1}}}}\\
	{{V_{2,1}}}\\
	\vdots \\
	{{V_{2,{n_2}}}}\\
	\vdots \\
	{{V_{m,{n_m}}}}
	\end{array}} \right]
\end{equation}
which has the form $\mathbf{A\Theta}\approx\mathbf{y}$. The weighted least-squares solution is then obtained from the normal equations:

\begin{equation}
\label{eq:weighted_least_squares}
\mathbf{A}^T\mathbf{W}\mathbf{A}\mathbf{\Theta}=\mathbf{A}^T \mathbf{Wy}
\end{equation} 
in which $\mathbf{W}$ a diagonal matrix composed of the weights per direction:

\begin{equation}
\mathbf{W} = \mathrm{diag}\Big(W_1,\cdots,W_1,W_2,\cdots,W_2,\cdots, W_m\Big)
\end{equation}

The weight $W_i$ is used to represent the reliability of normal flow along a direction $i$ based on the spread of $S_i$ along that direction. Its value is determined by the variance $\mathrm{Var}\lbrace S_i\rbrace$. We let $W_i$ scale linearly with $\mathrm{Var}\lbrace S_i\rbrace$, up to a maximum of $\mathrm{Var}\lbrace S\rbrace_{min}$:

\begin{equation}
\label{eq:weight_variance}
{W_{i} = \left\{ {\begin{array}{*{20}{c}}
	0&{\mathrm{Var}\lbrace S_i\rbrace= 0}\\
	{\frac{\mathrm{Var}\lbrace S_i\rbrace}{\mathrm{Var}\lbrace S\rbrace_{min}}}&0<{{\mathrm{Var}\lbrace S_i\rbrace} \le {\mathrm{Var}\lbrace S\rbrace_{min}}}\\
	1&{{\mathrm{Var}\lbrace S_i\rbrace} > {\mathrm{Var}\lbrace S\rbrace_{min}}}
	\end{array}} \right.}
\end{equation}

The minimum variance $\mathrm{Var}\lbrace S\rbrace_{min}$ is set to 600 pixels$^2$. 

Note also that, through the formulation of \cref{eq:dir_flow_field_system}, directions with more normal flow estimates have a larger influence on $\mathbf{\Theta}$. Hence, directions for which more information is available, contribute more to the solution.

\subsection{Recursive Updating of the Flow Field}
\label{sec:vo_recursive}
The solution to \cref{eq:weighted_least_squares} for $\mathbf{\Theta}$ provides the estimate for the visual observables. However, depending on the sampling rate of the estimator, it is possible that, during a single periodic iteration, too few normal flow estimates are available for an accurate fit. This leads to noise peaks in the measurement of $\mathbf{\Theta}$, especially during low speed motion. To limit this effect, the matrices $\mathbf{A}$ and $\mathbf{y}$ are not completely renewed at each iteration. Instead, rows from previous iterations are retained and assigned an exponentially decreasing weight, similar to an exponential moving average filter.

For an efficient implementation of the former, $\mathbf{A}$ and $\mathbf{y}$ are not explicitly composed as shown in \cref{eq:dir_flow_field_system}. Instead, our approach operates on the normal equations in \cref{eq:weighted_least_squares}. For each direction independently, we recursively update parts of the matrices $\mathbf{B}={{\bf{A}}^T}{\bf{WA}}$ and $\mathbf{C}={{\bf{A}}^T}{\bf{Wy}}$. These matrices are composed by the following elements:

\begin{equation}
\bf{B} = \left[ {\begin{array}{*{20}{c}}
	{{b_{11}}}&{{b_{21}}}&{{b_{31}}}\\
	{{b_{21}}}&{{b_{22}}}&{{b_{32}}}\\
	{{b_{31}}}&{{b_{32}}}&{{b_{33}}}
	\end{array}} \right],\;\mathbf{C} = \left[ {\begin{array}{*{20}{c}}
	{{c_1}}\\
	{{c_2}}\\
	{{c_3}}
	\end{array}} \right]
\end{equation}

From \cref{eq:dir_flow_field_system}, it can be shown that the elements of $\mathbf{B}$ are expressed as:

\begin{equation}
\def\arraystretch{2.2}
\begin{array}{c@{\hspace{0.5em}}c@{\hspace{0.5em}}c@{\hspace{0.5em}}c@{\hspace{0.5em}}c@{\hspace{0.5em}}c@{\hspace{0.5em}}c@{\hspace{0.5em}}}
{b_{11}} &=& \sum\limits_{i=1}^m {{W_i}{n_i}{{\left( {{\rm{c}}_{\alpha _i}} \right)}^2}}, &\;& {b_{21}} &=& \sum\limits_{i=1}^m {{W_i}{n_i}{\rm{c}}_{\alpha _i}{\rm{s}}_{\alpha _i}} \\
{b_{22}} &=& \sum\limits_{i=1}^m {{W_i}{n_i}{{\left( {{\rm{s}}_{\alpha _i}} \right)}^2}}, &\;& {b_{31}} &=& \sum\limits_{i=1}^m {{W_i}{\rm{c}}_{\alpha _i}\sum\limits_{j=1}^{n_i} {S_{i,j}}}  \\
{b_{33}} &=& \sum\limits_{i=1}^m {{W_i}\sum\limits_{j=1}^{n_i} {S_{i,j}^2} }, &\;&{b_{32}} &=& \sum\limits_{i=1}^m {{W_i}{\rm{s}}_{\alpha _i}\sum\limits_{j=1}^{n_i} {{S_{i,j}}}} 
\end{array}
\end{equation}

and those of $\mathbf{C}$ are expressed as:

\begin{equation}
\def\arraystretch{2.2}
\begin{array}{c@{\hspace{0.5em}}c@{\hspace{0.5em}}c@{\hspace{0.5em}}}
{c_1} &=& \sum\limits_{i=1}^m {{W_i}{\rm{c}}_{\alpha _i}\sum\limits_{j=1}^{n_i} {{V_{i,j}}} }\\
{c_2} &=& \sum\limits_{i=1}^m {{W_i}{\rm{s}}_{\alpha _i}\sum\limits_{j=1}^{n_i} {{V_{i,j}}} }\\
{c_3} &=& \sum\limits_{i=1}^m {{W_i}\sum\limits_{j=1}^{n_i} {{S_{i,j}}{V_{i,j}}} } 
\end{array}
\end{equation}

We introduce a shorthand notation $\Sigma_S^i = \sum_{j=1}^{n_i}S_{i,j}$ to represent the sums, cross-product sums, and sums of squares of $S$ and $V$ for direction $i$. The unweighted contribution of the associated flow vectors is then contained in $n_i$ and the sums $\Sigma_S^i$, $\Sigma_{S^2}^i$, $\Sigma_{V}^i$, and $\Sigma_{SV}^i$. These values are further referred to as the \emph{flow field statistics}. Hence, a newly detected flow vector is included in the flow field estimate by incrementing these quantities according to the values $S$ and $V$ of the new vector. 

What makes this decomposition interesting, is that the flow field statistics form a compact summary of the flow field, independent of the actual number of flow vectors. Thus, flow field information from a previous iteration can be efficiently included in subsequent ones, without increasing the size of the system in \cref{eq:dir_flow_field_system}. Now, at the start of each iteration, it is possible to include information from the flow field of the previous iteration, simply by preserving a fraction $F$ of the previous flow field statistics. Hence, the estimator accuracy is less dependent on the sampling rate of the algorithm.

The preservation process is illustrated using the statistic $\Sigma_{V}^i$. At the start of iteration $k$, $\Sigma_{V}^i$ is initialized as $\Sigma_{V}^i(k) = F \Sigma_{V}^i(k-1)$. During iteration $k$, $\Sigma_{V}^i$ is then updated using newly available normal flow vectors that are allocated to direction $i$. Hence, the complete update for $\Sigma_{V}^i$ is performed as follows:
\begin{equation}
\Sigma_{V}^i(k) = F \Sigma_{V}^i(k-1) + \sum_{j=1}^{n_i}{V_{i,j}}
\end{equation}

The value of $F$ is computed as:

\begin{equation}
F = 1-\frac{t(k)-t(k-1)}{k_f}
\end{equation}

where the time constant $k_f$ is assigned a value of 0.02 s. This step is similar for all statistics. When all newly available vectors are categorized and processed, the flow field is recomputed using \cref{eq:weighted_least_squares}. 


%Instead, they are updated through an infinite impulse response low-pass filter:
%
%\begin{equation}
%\begin{array}{l}
%{{\bf{B}}_{k + 1}} = {{\bf{B}}_k} + \left( {{{\bf{A}}^T}{\bf{WA}} - {{\bf{B}}_k}} \right)\alpha \\
%{{\bf{C}}_{k + 1}} = {{\bf{C}}_k} + \left( {{{\bf{A}}^T}{\bf{Wy}} - {{\bf{C}}_k}} \right)\alpha 
%\end{array}
%\end{equation}
%
%The update constant $\alpha$ is set to 0.5. The estimate for $\mathbf{\Theta}$ is then the solution to $\mathbf{B\Theta}=\mathbf{C}$.



\subsection{Confidence Estimation and Filtering}
\label{sec:vo_confidence}
In visual sensing, the reliability of motion estimates varies greatly depending on the environment. Factors such as visible texture and scene illumination have an effect on the estimate. With event-based sensing, motion in the scene is another key factor. 

Therefore, a confidence value is computed based on several characteristics of the flow field, in order to quantify the reliability of the estimate. This confidence value is defined as a product of three individual confidence metrics based on the following statistical quantities: 

\begin{itemize}
	\item The flow estimation rate $\rho_F$.
	\item The maximal variance $\mathrm{Var}\lbrace S\rbrace$ of all flow directions.
	\item The coefficient of determination $R^2$ of the solution to \cref{eq:weighted_least_squares}, applied here as a nondimensional measure of the fit quality.
\end{itemize}

$R^2$ is generally computed through the following \cite{Weisberg2005}:

\begin{equation}
\label{eq:R2}
{R^2} = 1 - \frac{\mathit{RSS}}{\mathit{TSS}}
\end{equation}

In this work, the Residual Sum of Squares (RSS) and Total Sum of Squares (TSS) are computed in weighted form as follows:

\begin{equation}
\begin{aligned}
\mathit{RSS} &=& {{\bf{y}}^T}{\bf{Wy}} - {{\bf{\Theta }}^T}{{\bf{A}}^T}{\bf{Wy}}\\
\mathit{TSS} &=& {{\bf{y}}^T}{\bf{Wy}} - \frac{\left({\sum\limits_{i = 1}^m {W\Sigma _V^i} }\right)^2}{{\sum\limits_{i = 1}^m {W{n_i}} }}
\end{aligned}
\end{equation}

For each indicator, a confidence value $k$ is computed ranging from 0 to 1 (higher is better), similar to the variance weight in \cref{eq:weight_variance}. The individual confidence values are thus dependent on settings for $R^2_{min}$, $\mathrm{Var}\lbrace S\rbrace_{min}$, and $\rho_{F_{min}}$ (not to be confused with $\rho_{F_{max}}$). The values of $R^2_{min}$ and $\rho_{F_{min}}$ are set to 1.0 and 500 respectively. Note that, since \cref{eq:weight_variance} already provides individual confidence values per direction in the form of $W$, we simply let $k_{\mathrm{Var}\lbrace S\rbrace}=\mathrm{max}\left({W_i:i=1,\ldots,m}\right)$.

The total confidence value $K$ is then the product of $k_{\rho_F}$, $k_{\mathrm{Var}\lbrace S\rbrace}$, and $k_{R^2}$. Hence, each individual confidence factor needs to be close to 1 in order to obtain a high $K$. For example, when $\rho_F$ and $R^2$ are very large, but the flow is very localized (the maximal value for $\mathrm{Var}\lbrace S\rbrace$ is small), the estimate is still not reliable. In this case, it is likely that a single visual feature causes the normal flow, which is insufficient for computing the visual observables.

The confidence $K$ is useful to monitor the estimate quality of the visual observables during flight. In addition, it is the main component of a \emph{confidence filter} for $\mathbf{\Theta}$. This filter is based on a conventional infinite impulse response low-pass filter, in which $K$ is multiplied with the filter's update constant. The final estimate for the visual observables $\hat{\mathbf{\Theta}}$ is determined through the following update equation at iteration $k$:

\begin{equation}
\mathbf{\hat\Theta} (k)=\mathbf{\hat\Theta}(k-1) + \left(\mathbf{\Theta}(k) - \mathbf{\hat\Theta}(k-1)\right)K \frac{t(k)- t(k-1)}{k_t}
\end{equation}

where $k_t$ is the time constant of the low-pass filter, which is set to 0.02 s. Lastly, a saturation limit is applied that caps the magnitude of the update of each individual value in $\mathbf{\Theta}$ to $\Delta \vartheta_{max}$ in order to reject significant outliers. The value for $\Delta \vartheta_{max}$ is set to 0.3.

\subsection{Results}
\label{sec:results_scaled_velocity}
For evaluating the accuracy of the presented visual observable estimator, we use the measurements generated for evaluating optical flow performance in \cref{sec:results_optical_flow}, which are generated through handheld motion. Optitrack position measurements provide the ground truth estimates for $\vartheta_x$, $\vartheta_y$, and $\vartheta_z$. For each set, normal flow estimates are computed using the C-based implementation discussed in \cref{sec:results_optical_flow}. The flow detection rate cap $\rho_{F_{max}}$ is set to 2500 flow vectors per second and the periodic estimator samples the visual observables at 100 Hz, similar to the on-board implementation in \cref{sec:results}.

In our experiments the main variable of interest is $\vartheta_z$, as it forms the basis for the constant divergence controller. Therefore, this variable is investigated over a wide range of velocities. However, the estimates of $\vartheta_x$ and $\vartheta_y$ are also interesting to assess, since a more elaborate optical flow based controller may also include the horizontal components for hover stabilization. The latter process does require the MAV to perform rolling and pitching motion, inducing rotational normal flow. Therefore, the effectiveness of derotation is evaluated as well.

\subsubsection{Vertical Motion}
For assessment of $\vartheta_z$ estimates, vertical oscillating motion was performed above both texture types. The vertical speed of these oscillations was gradually increased, hence covering a wide range of divergence values. This enables a first-order characterization of the estimator behavior.

\cref{fig:divergence_estimates} shows the resulting estimates compared to ground truth measurements, accompanied by height measurements $h=-Z_{\cal W}$. Detail sections are shown for low and high divergence motion, for which also the confidence value is shown. 

\begin{figure*}[!ht]
	\centering
	\setlength{\fwidth}{0.4\linewidth}
	\begin{framed}
		\subfloat[Checkerboard texture]	{
			\input{images/divergence_checkerboard_main}
			\label{fig:divergence_checkerboard}
		}
		\subfloat[Roadmap texture]	{
			\input{images/divergence_roadmap_main}
			\label{fig:divergence_roadmap}
		}	
		\caption{From top to bottom: Height measurements (top row) and estimates of $\vartheta_z$ (second row, red line) in comparison to ground truth measurements (blue line). The two bottom rows show detail sections of $\vartheta_z$ estimates (third row) at low speed and high speed, as well as the accompanying estimate confidence value $K$ (bottom row). Measurements are shown for \protect\subref{fig:divergence_checkerboard} checkerboard and \protect\subref{fig:divergence_roadmap} roadmap textures separately.}
		\label{fig:divergence_estimates}
	\end{framed}
\end{figure*}

The detail plots show that the estimator is relatively sensitive to local outliers in normal flow at low speeds. In addition, the confidence $K$ is generally low due to lower detection rates of optical flow and low value of $R^2$. At higher speeds, the errors are relatively smaller. Note that $K$ is also generally higher there. Somewhat lower confidence values are seen for the roadmap texture.

Around sign changes, brief moments are present where the confidence value $K$ is low. The result of this is that, due to the confidence filter, the update of $\hat{\vartheta}_z$ at these points is limited, which leads to a local delay with respect to the ground truth. However, when higher confidence estimates are available, the estimate quickly converges back to the ground truth value.

Based on the estimator results in \cref{fig:divergence_estimates} we can assess how the error varies with the ground truth divergence. \cref{fig:divergence_error_dist} shows the variation of the absolute error $\varepsilon_{\vartheta_z}=\lvert\hat{\vartheta}_z-\vartheta_z \rvert$ with the magnitude of $\vartheta_z$\footnote{The dataset used to generate these plots and statistics is currently being prepared to be made public. They are planned to be made public at: \url{https://beta.dataverse.nl/dataverse/mavlab}}. A quadratic model $\varepsilon = p_0 + p_1 \vartheta_z + p_2 \vartheta_z^2$ is fitted to the points, which is represented by the blue line. The values of $p_0$, $p_1$, and $p_2$ are shown in \cref{tab:div_error_parameters}. The errors of both the checkerboard set and the roadmap set are combined, since the estimator shows roughly the same error distribution for both cases with the quadratic fit almost flat for the divergences tested. Interestingly, the largest absolute errors appear to be present at low divergence. This results from the local delay occurring around zero-crossings in \cref{fig:divergence_estimates} where the confidence value of the filter is low. Note, however, that the error increase with the magnitude of $\lvert\vartheta_z\rvert$ is limited, which enables application of the presented pipeline to a wide range of velocities.

\begin{figure}[!ht]
	\centering
	\setlength{\fwidth}{0.6\linewidth}
	\renewcommand{\xlabeldist}{0.0}
	\renewcommand{\ylabeldist}{0.0}
	%\tikzset{external/export next=false}
	\input{images/divergence_abs_error}
	\caption{Absolute error distribution for the estimates of $\vartheta_z$ for a set of landing tests performed at different constant vertical speeds above the roadmap texture. The blue line shows a quadratic fit of the error and the dashed black line shows the 25, 50 and 75\% percentiles of the data. For comparison, the model obtained for the frame-based size divergence estimator \cite{Ho2016a} is shown as well.} 
	\label{fig:divergence_error_dist}
\end{figure}


In \citet{Ho2016a} an extensive characterization of two frame-based visual estimators for $\vartheta_z$ is performed, which includes an assessment of their absolute error distribution up to $\vartheta_z\approx 1.3$ (Fig. 10 in the paper). For a first-order comparison, \cref{fig:divergence_estimates} also shows the quadratic error fit obtained for the frame-based 'size divergence' estimator, which performed best in \citet{Ho2016a}. Compared to the presented event-based estimator, the size divergence estimator achieves slightly lower errors in the region of $\vartheta_z < 0.5$. However, for faster motion, the error is lower for our event-based estimator. Note that our quadratic model is based on relatively little measurements, and does not yet provide a full characterization.

\begin{table}[!ht]
	\centering
	\caption{Parameters of the quadratic fit models in \cref{fig:divergence_error_dist}.}
	\input{tables/div_error_parameters}
	\label{tab:div_error_parameters}
\end{table}

\subsubsection{Horizontal Motion}
Estimation performance for the components $\vartheta_x$ and $\vartheta_y$ is assessed through a dataset consisting of primarily horizontal motion. In the following set, the DVS is moved in a circular pattern above a checkerboard surface at approximately 0.8 m height.

The resulting visual observable estimates are shown in \cref{fig:horizontal_motion}. For completeness, the values of $\vartheta_z$ are displayed as well. Overall, the horizontal movement is captured well in the estimates, although some disturbances are still clearly present, for example around $t=23$ s. The deviations are comparable to those seen in the vertical motion dataset. A summary of the error values is presented in \cref{tab:horizontal_errors}.

\begin{figure}[!ht]
	\centering
%		\tikzset{external/force remake=true}
%	\renewcommand{\ylabeldist}{0.02}
	\setlength{\fwidth}{0.4\linewidth}
	\input{images/horizontal_motion}
	\caption{Height and visual observable measurements (blue) and estimates (red) during horizontal motion above checkerboard texture.}
	\label{fig:horizontal_motion}
\end{figure}

\begin{table}[!ht]
	\centering
	\caption{Mean and standard deviation of absolute errors for the estimates during horizontal motion, shown in \cref{fig:horizontal_motion}.}
	\input{tables/horizontal_errors}
	\label{tab:horizontal_errors}
\end{table}


\subsubsection{Effect of Derotation}
In order to assess how well normal flow can be derotated with the current setup, measurements were conducted in which the DVS performed pure rotation along all axes. We compare body rate measurements, ground truth values for $\vartheta_x$ and $\vartheta_y$, and estimates with and without derotation. \cref{fig:derotation} shows these quantities obtained in three separate sequences, in which each body rate is varied independently. 

\begin{figure}[!ht]
	\centering
%		\tikzset{external/force remake=true}
  	\setlength{\fwidth}{0.4\linewidth}
%	\renewcommand{\ylabeldist}{0.02}
	\input{images/derotation}
	\caption{Baseline and derotated estimates of $\vartheta_x$, $\vartheta_y$ compared to ground truth measurements and body rates $p$, $q$, and $r$. Note that the sign of $p$ is inverted to match $\vartheta_x$.}
	\label{fig:derotation}
\end{figure}

The most relevant influences are those of $p$ on $\vartheta_x$ and $q$ on $\vartheta_y$, which are shown in the top and middle graphs respectively. The influence of $r$ is less profound. For conciseness, only the effect of $r$ on $\vartheta_y$ is shown, which provided the clearest result. Some residual motion in $p$ and $q$ is present in the latter case, though it does not fully account for the deviation seen in \cref{fig:derotation}. Note that the derotation process generally performs well; the largest part of the rotational flow is successfully corrected in the derotated estimate. 
%Clearly, some over-estimation is present for $\vartheta_x$ and $\vartheta_y$ during roll and pitch motion, since horizontal motion is limited. This can in fact be explained by the offset between the camera focal point and the drone's center of gravity. The rotational motion induces an additional horizontal motion component at the focal point due to the offset. However, to account for this, knowledge of the height above ground is necessary. While in our experiments this is available through OptiTrack measurements, in autonomous vision-based flights measurements of $Z_{\cal C}$ are typically missing.

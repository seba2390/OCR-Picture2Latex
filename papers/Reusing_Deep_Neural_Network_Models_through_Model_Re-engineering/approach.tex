In this section, we introduce \projectName, a search-based approach to model re-engineering, which uses a gradient-based search method to find the target problem-related weights.

\begin{figure*}[t]
    \centering
    \includegraphics[width=17.5cm]{figures/workflow-2.pdf}
    \caption{The workflow of model re-engineering with \projectName.}
    \label{fig:workflow}
\end{figure*}

\subsection{Overview}
As illustrated in Figure \ref{fig:workflow}, the workflow of \projectName consists of three components: \textit{search space}, \textit{performance estimation strategy}, and \textit{search strategy}. 
Given an original model (a 3-class classification in Figure \ref{fig:workflow}), which consists of three neural network layers with fifteen weights, and a target dataset (binary classification in Figure \ref{fig:workflow}), the model re-engineering process is summarized as follows:

(1) \textit{Construction of Search Space}: A re-engineered model selectively removes part of the original model's weights according to a \textit{mask}. 
A \textit{mask} is a bit vector $[0,1]^L$, where $L$ is the number of weights in the original model, and each bit represents whether the corresponding weight is removed. 
In total, there are $2^L$ candidate masks, each of which corresponds to a candidate re-engineered model.
Consequently, the search space consists of $2^L$ candidates.
The mask is initialized with all element values as 1, representing that all weights are retained initially.
The first and second steps along with the component Search Space in Figure \ref{fig:workflow} display the above process, where $L=15$ and the search space size is $2^{15}$.

(2) \textit{Performance Estimation}: Given a candidate mask, the performance estimation strategy first constructs a candidate re-engineered model by removing weights according to the mask and appending a \textit{head} as the output layer.
The \textit{head}, which is a fully connected layer, is used to enable the candidate to adapt to the target problem, i.e., adapt the original \textit{N}-classification model to the target \textit{K}-classification problem.
Then, the objective function is defined as the weighted sum of the \textit{weight retention rate} of the candidate and the \textit{cross-entropy loss} between the candidate's predictions and corresponding actual labels on the \textit{target dataset}.
The objective function is used to evaluate the performance of a candidate. 
The resulting objective function value will be fed back to the searching process to guide the next search round. %
The third step along with the component Performance Estimation Strategy in Figure \ref{fig:workflow} display the estimation process.

(3) \textit{Searching Candidates}: The search strategy applies a gradient-based search method to explore the search space with the guidance of the objective function. The gradient-based search method not only efficiently explores the huge search space, but also optimizes the head at the same time.
In each search round, the search strategy sends the updated mask and head as a new candidate to the performance estimation strategy.
The fourth step along with the component Search Strategy in Figure \ref{fig:workflow} display the search process, where the head has two neurons as the target problem is binary classification.

\projectName iterates the search and estimation processes.
When the objective function value converges, \projectName %
outputs the re-engineered model. %
In the example shown in Figure \ref{fig:workflow}, the re-engineered model retains 7 out of 15 weights of the original model and performs binary classification.
We present the technical details of each step in the following.


\subsection{Construction of Search Space}
\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{figures/illustration_removal.pdf}
    \caption{The construction of a re-engineered model using the mask and head. }
    \label{fig:removal}
\end{figure}

The goal of model re-engineering is to obtain a new model which retains only the target problem-related weights of the original model.
Model re-engineering is formulated as a problem of searching for a new model from all candidate models, which selectively removes part of the original model's weights. 
If the searched model retains only the target problem-related weights, it is regarded as the re-engineered model.
In this problem, the search space consists of all possible candidate re-engineered models.
To facilitate a technical solution to this problem in practice, a \textit{mask} that records which weights are removed and retained in a candidate is used to represent a candidate, thereby omitting unnecessary details of a candidate, such as Max-pooling and Dropout layers.
Consequently, in \projectName, the search space consists of all candidate masks.

Specifically, a mask is a bit vector $[0,1]^L$, where $L$ is the number of weights in the original model, and 0 (or 1) represents the corresponding weight removed (or retained). 
Figure \ref{fig:removal} illustrates the use of a mask to remove weights from the original model.
By multiplying the weights of the trained model with the mask, \projectName sets the values of irrelevant weights to zero and keeps the values of relevant weights. 
The weights with values set to zero are involved in the computation but have no effect on the prediction, thus achieving the effect of removing irrelevant weights.
Note that, after model re-engineering, the computation of a re-engineered model involving the weights with zero values could be eliminated by special libraries (e.g., DeepSparse~\cite{deepsparse}), which will be discussed in Section \ref{subsec:exp_result}.


After the construction of search space, a mask initialized to all element values of 1 is fed to the performance estimation strategy. That is, the starting point of the search is a candidate that retains all the original model's weights.


\subsection{Performance Estimation}
The search aims to find the optimal mask, which corresponds to a candidate re-engineered model that retains only the target problem-related weights and can classify well on the target problem.
To achieve the goal, the performance estimation strategy defines the objective function of the search as the weighted sum of \textit{weight retention rate} and \textit{cross-entropy loss}.
The weight retention rate can measure the number of weights retained by the candidate.
The cross-entropy loss on the target dataset can measure the classification performance of the candidate on the target problem.

Specifically, when evaluating a candidate's performance, \projectName first constructs the candidate, as the computation of cross-entropy loss requires running the candidate on the target dataset.
Figure \ref{fig:removal} illustrates the construction of a candidate re-engineered model.
\projectName first multiplies the weights of the original model with the mask to remove part of the original model's weights, resulting in an intermediate model.
As the output layer has three neurons, the intermediate model is still a model for 3-class classification. 
To adapt the candidate to the number of classes of the target problem, the head, a fully connected layer, is appended after the intermediate model as the output layer of the candidate.
The head is randomly initialized in the first search round and will be updated along with the mask in the subsequent rounds.
In this example, the head has two neurons, which transforms the 3-class prediction of the intermediate model to the binary prediction, allowing the candidate to adapt to the target problem.

After constructing the candidate, the cross-entropy loss $\mathcal{L}_{ce}$ between the candidate's predictions on the target dataset and the actual labels is computed as follows:
\begin{gather}
    \mathcal{L}_{ce}=-\sum_{i=1}^K t_i \log(P_i(\mathcal{M}, \mathcal{H})),
\end{gather}
where $K$ is the number of classes in the target problem, $\mathcal{M}$ and $\mathcal{H}$ are the mask and head, $P_i(\mathcal{M}, \mathcal{H})$ is the prediction for the $i$-th class by a candidate constructed with $\mathcal{M}$ and $\mathcal{H}$, and $t_i$ is the probability of the $i$-th class in the one-hot representation of the actual label, with a value of 0 or 1.
A lower cross-entropy loss indicates that the candidate retains more target problem-related weights and hence achieves higher classification accuracy on the target dataset.

The weight retention rate $\mathcal{L}_{wr}$ is computed directly from the mask:
\begin{gather}
    \mathcal{L}_{wr}=\frac{1}{L}\sum_{i=1}^L \mathcal{M}[i],
\end{gather}
where $L$ is the number of weights in the original model.
A lower weight retention rate indicates that the candidate retains fewer weights.
Based on $\mathcal{L}_{ce}$ and $\mathcal{L}_{wr}$, the objective function $\mathcal{O}$ is defined as follows:
\begin{gather}
    \mathcal{O}=\mathcal{L}_{ce} + \alpha \times \mathcal{L}_{wr}, \label{eq:loss}
\end{gather}
where $\alpha$ is a weighting factor and is empirically set to 1.0. %
To minimize $\mathcal{O}$, \projectName tends to search for a candidate that retains only the target problem-related weights, as this candidate can achieve the highest classification accuracy while retaining as few weights as possible.



\subsection{Searching Candidates}
Large models can have billions of parameters, resulting in super huge search space.
To explore the huge search space efficiently, our search strategy applies a gradient-based search method.
In each search round, the search strategy finds a new candidate with a smaller objective function value by gradient descent based on the objective function value of the candidate in the previous round.
That is, the mask is updated by descending the gradient as follows:
\begin{gather}
    \mathcal{M^{'}} = \mathcal{M} - \xi \times \nabla_{\mathcal{M},\mathcal{H}}\mathcal{O}, \label{eq:update} \\
    \nabla_{\mathcal{M},\mathcal{H}}\mathcal{O}=\nabla_{\mathcal{M}, \mathcal{H}}\mathcal{L}_{ce} + \alpha \times \nabla_{\mathcal{M}}\mathcal{L}_{wr},
\end{gather}
where $\xi$ is the learning rate, and $\mathcal{M^{'}}$ is the updated mask corresponding to a new candidate with a smaller objective function value.

When applying gradient descent to update a mask, it is important to note that gradient descent requires the search space to be continuous and differentiable~\cite{darts}, while the search space composed of masks is discrete and non-differentiable.
Inspired by DARTS~\cite{darts}, the search strategy attaches a continuous number to each element of the mask, which can be considered as the relevance of the weight to the target problem.
Then an indicator function $\mathbbm{1}_{(0, +\infty)}{:}X {\to} \{0,1\}$ is used to set the element values corresponding to the weights with relevance greater than zero to 1 and the other element values to 0.
As the relevance is continuous, the search strategy uses gradient descent to update the relevance and thus can update the mask.

After satisfying the condition that the search space is continuous, another problem is that the indicator function is non-differentiable at $x{=}0$, and the derivative of the indicator function equals 0 everywhere except at $x{=}0$.
This problem prevents the common backward propagation based on gradient descent from directly applying to update relevance~\cite{binaryNN,binarizedNN_2}.
To address the problem, the technique named straight-through estimator~\cite{ste,binarizedNN_2} is used to estimate the gradient of the indicator function, which directly uses the gradient of the previous neural network layer as the gradient of the current neural network layer.


The head is updated along with the mask by descending the gradient $\nabla_{\mathcal{M},\mathcal{H}}\mathcal{L}_{ce}$.
After updating the mask and head, the search strategy sends them as a new candidate to the performance estimation strategy and starts the next round of search after getting the objective function value.







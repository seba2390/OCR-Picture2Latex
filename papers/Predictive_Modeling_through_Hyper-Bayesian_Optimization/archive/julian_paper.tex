\documentclass[preprint]{elsarticle}
\usepackage{lineno,hyperref}
% The following packages will be automatically loaded:
% amsmath, amssymb, natbib, graphicx, url, algorithm2e

%\usepackage{rotating}% for sideways figures and tables
\usepackage{longtable}% for long tables
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{mathrsfs}
\usepackage{amssymb}
% The booktabs package is used by this sample document
% (it provides \toprule, \midrule and \bottomrule).
% Remove the next line if you don't require it.
\usepackage{booktabs}
% The siunitx package is used by this sample document
% to align numbers in a column by their decimal point.
% Remove the next line if you don't require it.
%\usepackage[load-configurations=version-1]{siunitx} % newer version
%\usepackage{siunitx}
%\usepackage{natbib}
\usepackage{float}
\newfloat{algorithm}{tbp}{loa}
\providecommand{\algorithmname}{Algorithm}
\floatname{algorithm}{\protect\algorithmname}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
\usepackage{algorithmic}
\usepackage{algolyx}

% The following command is just for this sample document:
\newcommand{\cs}[1]{\texttt{\char`\\#1}}

%  \author{\Name{Julian Berk} \Email{jmberk@deakin.edu.au}\\
%  \Name{Sunil Gupta} \Email{sunil.gupta@deakin.edu.au}\\
%  \Name{Santu Rana} \Email{santu.rana@deakin.edu.au}\\
%  \Name{Svetha Venkatesh} \Email{svetha.venkatesh@deakin.edu.au}\\
%  \addr{Deakin University, Centre for Pattern Recognition and Data Analytics, Geelong, Australia}
%  \AND
%  \Name{Vu Nguyen} \Email{vu@robots.ox.ac.uk}\\
%  \addr{University of Oxford, Oxford, United Kingdom}
% }
%
%\editors{Wee Sun Lee and Taiji Suzuki}


\begin{document}
\begin{frontmatter}

\title{Bayesian Optimisation in Unknown Bounded Search Domains}

%% Group authors per affiliation:
\author[1]{Julian Berk\corref{cor1}}
\ead{jmberk@deakin.edu.au}
\author[1]{Sunil Gupta}
\ead{sunil.gupta@deakin.edu.au}
\author[1]{Santu Rana}
\ead{santu.rana@deakin.edu.au}
\author[2]{Vu Nguyen}
\ead{vu@robots.ox.ac.uk}
\author[1]{Svetha Venkatesh}
\ead{svetha.venkatesh@deakin.edu.au}

\address[1]{Deakin University, Applied Artificial Intelligence Institute, Geelong, Australia}
\address[2]{University of Oxford, Oxford, United Kingdom}
\cortext[cor1]{Corresponding author}

\begin{abstract}
Bayesian optimisation (BO) is one of the most sample efficient methods for determining the optima of expensive, noisy black-box functions. Despite its tremendous success in scientific discovery and hyperparameter tuning, it still requires a bounded search space. The search spaces boundaries are, however, often chosen heuristically with an educated guess. If the boundaries are misspecified, then the search space may either be unnecessarily large and hence more expensive to optimise, or it may simply not contain the global optimum. In this paper, we introduce a method for dynamically determining the bound directly from the data. This is done using a distribution of the bound derived in a Bayesian setting. The prior is chosen by the user and the likelihood is derived with Thompson sampling. This results in a bound that is both cheap to optimise and has a high probability of containing the global optimum. We compare the performance of our method with the alternative methods on a range of synthetic and real-world problems and demonstrate that our method achieves consistently superior results.
\end{abstract}

\begin{keyword}
Bayesian optimisation\sep Experimental design \sep Hyperparameter tuning
%\MSC[2010] 00-01\sep  99-00
\end{keyword}

\end{frontmatter}

\linenumbers


\section{Introduction}

The scientific method has been integral to humanity's prosperity.
From our health, to how we travel, to the way we socialise, scientific
discoveries have revolutionized every aspect of our lives. These discoveries
are often made through experimentation on unknown systems to determine their properties. Often these tests are essentially attempts to determine what input will produce the best output. For many years, experts would simply
make educated guesses as to which inputs to provide these systems or attempt to perform enough experiments to exhaustively explore all options. These approaches, however, require a large number of experiments in order to estimate their optimal input. Unfortunately, these experiments are often very costly, both in terms of money and man hours.
As such, there is great value in methods that can determine the optimum
of these systems in the fewest experiments possible.

\emph{Bayesian Optimisation }(BO) is one of the most sample efficient methods
for finding the optimal input for these expensive systems \citep{mockus1994application}.
It takes all past inputs and their associated outputs to generate a statistical
model of the system. This model is used to predict the input that
will allow the optimum to be discovered in the fewest experiments possible. The new input can then be used along with its corresponding output to improve the statistical model, which
is then used to find another input. This process can be repeated
until a satisfactory output has been obtained. The result is that far fewer experiments are needed than if the inputs were chosen in other ways, resulting in potentially lower costs. This may allow both research
grants and industrial R\&D budgets to stretch further, increasing
productivity and promoting innovation. Bayesian optimisation has already been used in a wide range of fields, including materials science \citep{li2017rapid,kikuchi2017bayesian,ju2017designing}, biomedical science \citep{turgeon2016cognitive,gonzalez2015bayesian}, and machine learning \citep{Snoek2012,klein2017fast,xia2017boosted}.

%There have already been many promising applications of BO in a wade range of fields, ranging from materials science, to biomedical science, and even computer science. Examples of applications in materials science are the
%development of new polymer fibres \cite{li2017rapid}, the determination
%of metal oxide grain bound structures \cite{kikuchi2017bayesian},
%and optimizing thermal conductance across nanostructures \cite{ju2017designing}.
%In biomedical science, it has been used for many applications including
%studying how age effects time perception \cite{turgeon2016cognitive}
%and synthetic gene design \cite{gonzalez2015bayesian}. An application of great interest to the computer science community is the selection of hyperparameters for other machine learning algorithms \cite{Snoek2012}.

The standard implementation of Bayesian optimisation requires a closed search space. This is for two reasons. Firstly, it is impossible to fully explore an unbounded, and hence infinitely large, search space in a finite number of iterations. Secondly, Bayesian \sloppy optimisation requires the global optimisation of an acquisition function. This has a known, closed form, so standard optimisation methods can be used. However, many of these methods, such as DIRECT \citep{jones2001direct} and multi-start local optimisation with a L-BFGS-B optimiser, require a finite search space throughout the whole process. Other methods, such as multi-start local optimisation with unbounded optimisers like the conjugate gradient method, do not necessarily require a finite search space, but instead require a large number of initial points which must be focused in a finite region for the algorithm to function.

While Bayesian optimisation requires a search space, there is often no accurate way of determining it. Currently, the search space may be chosen with an educated guess or may simply be left as the entire physically feasible region. This can lead to suboptimal results as large spaces are more expensive to explore \citep{nguyen2017bayesian}, but small spaces may not contain the desired optimum. As such, there is value in methods that can still efficiently find the global optimum even if the initial search space has been chosen incorrectly.

Very little work has been done in this area. The initial work by Shahriari \emph{et al} \cite{shahriari2016unbounded} suggested two methods. 
The first, called volume doubling, simply doubles the search space volume in all directions at set intervals. The second method uses a technically  unbounded space but is restricted via a regularization
on the acquisition function to prevent the solution from going
too far from a mean location. Unfortunately, this method has two problems: first, the regularisation level is independent of the optimisation problem making it potentially unsuitable, and second, it uses an arbitrary truncation for optimising the unbounded space.

To the best of our knowledge, the only other attempt to dynamically change
the search space is \cite{nguyen2018filtering}. This method expands an initially specified search space by a set factor determined by the algorithm budget. It computes and compares the lower and upper Gaussian process confidence bounds and then filters out
regions that are likely to have low function values. However, this approach expands the space only by a set amount, which is independent of the function. Furthermore, its convergence is compromised as the filtering will cause it to get stuck if the search bounding box becomes surrounded by a low-value region.

We propose a method for dynamically determining an appropriate bound, and hence an appropriate search space, for Bayesian optimisation problems using the collected data. As this bound is defined from the model's statistics, it will be tailored to the problem and hence will likely lead to more efficient optimisation than existing methods. Our method also shifts the centre of the search space as well as altering its size, allowing it to change such that it encloses the global maxima without simply growing in size. Moreover, while flexibly expanding the search space, our approach can also narrow down remote regions which are far away from our shifted center. This potentially leads to a far smaller final bound than competing methods. We expect our method to have the following advantages when compared to the previous methods:
\begin{itemize}
\item Regularised expected improvement: Our method is able to dynamically change the search bound, allowing it to find far away optima that Regularised Expected Improvement would be unable to due to its regularisation. 
\item Volume doubling: This method usually leads to an excessively large, and hence expensive, bound as it does not consider the systems statistics. Our method will generally produce a far smaller bound and hence be more efficient. It will also not expand excessively if the initial bound is good, while volume doubling will.
\item Filtering Bayesian optimisation: While its expansion is far more controlled than volume doubling, it is still unable to shrink its search space and it is also liable to get stuck if the current search space is surrounded by a valley of poor points. Our method is able to both expand and shrink its search space and has a non-zero probability of jumping over valleys of poor points due to its random elements.
\end{itemize}

Our method uses the collected data to derive a distribution for the most appropriate bound using Thompson sampling. A suitable bound can then be obtained from this distribution through full Bayesian sampling or MAP methods. We demonstrate the effectiveness of our method using a range of synthetic and real-world optimisation problems. In these, we show superior results to other related methods.

In summary, our main contributions are:
\begin{itemize}
\item We provide a detailed account of the existing unknown bound methods and their limitations.
\item We provide a novel method that addresses the limitations of the previous methods.
\item We perform a diverse set of experiments to verify the performance of our method. These include the optimisation of several synthetic functions, a machine learning hyperparameter tuning problem, and an alloy cooking simulation. 
\end{itemize}

%We first provide preliminary background in Gaussian process, Bayesian optimisation and previous work in Sec. \ref{sec:Background}. We then present our method in Sec. \ref{sec:Method} and demonstrate its performance on a range of benchmark and real-word problems including both machine learning hyperparameter tuning and a materials science application in Sec. \ref{sec:Results}. Finally, we conclude our findings in Sec. \ref{sec:Conclusion}.



\section{Background\label{sec:Background}}
In this section we give a short outline of Bayesian optimisation with an emphasis on how search space can influence performance. We also discuss how previous works have attempted to rectify misspecified search spaces. 
\subsection{Bayesian Optimisation}

Bayesian optimisation is a sample efficient technique for optimising noisy,
expensive systems \citep{mockus1994application}. It represents the system as a black-box function, which takes an input, $x$, with dimension, $d$, and gives a noisy output, $y=f(x)+\epsilon$. Here, $f(x)$ is the true function value at $x$ and $\epsilon \sim \mathcal{N}(0, \sigma^2_{noise})$, where $\sigma^2_{noise}$ is the variance of the noise corrupting the measurement. More formally, Bayesian optimisation seeks to find the input, $x^*$, that produces the optimal output over a \emph{bounded} search space, $\mathcal{X}\in\mathbb{R}^d$:
\begin{linenomath*}
\begin{equation}
x^{*}=\underset{x\in\mathcal{X}}{\arg\max f(x)}
\end{equation}
\end{linenomath*}
To do this, it first generates a statistical model of the system with the current data, $D_t=\left\lbrace x_i,y_i\right\rbrace^t_{i=1}$. This model is generally a \emph{Gaussian process} \citep{Rasmussen2006}, but there are also neural network and random forest based models \citep{snoek2015scalable}. Bayesian optimisation uses this model to select an input to test through the use of an \emph{acquisition function}, $\alpha(x)$, which is explained in more detail in Sec. \ref{subsec:Acquisition-Functions}. This input and its corresponding output are then added to the data, which can then be used to generate an improved statistical model. This process is iterated until a satisfactory result has been obtained or some other stopping condition has been met. See \cite{Brochu2010} for a more detailed review of Bayesian optimisation.

\subsection{Gaussian Process}
A Gaussian process model characterises the black-box function at each point as correlated Gaussian random variables \citep{Rasmussen2006}. This means that the behaviour of the model can be controlled entirely through means and covariances. The covariance function, also called the kernel function, $k(x_{i},x_{j})$, controls how any two points, $x_i$ and $x_j$, are correlated. This means that it essentially controls the shape of the function. Therefore, the selection of a sensible covariance function is vital. 
%For example, if we assume that the black-box function is continuous then we require a covariance function where nearby points are strongly correlated. One way to do this is to have the covariance function depend at least in part on $r=\left\Vert x_{i}-x_{j}\right\Vert ^{2}$. If the kernel depends on $x_i$ and $x_j$ purely though $r$, (i.e. $f(x_i,x_j)=f(r)$) it is invariant to translations and is therefore \emph{stationary}. Likewise, if it is invariant to rotations it is said to be \emph{isotropic}. While these two properties are not necessary for valid and efficient kernel, they generally reduce the numbers of hyperparameters the kernel has and allow the use of techniques such as Thompson sampling with random Fourier feature derived functions. One of the simplest of these is the \emph{square exponential kernel}; $k_{SE}(x_{i},x_{j})=\exp\left(-\frac{\left\Vert x_{i}-x_{j}\right\Vert ^{2}}{2l^{2}}\right)$.
One popular choice of kernel is the \emph{square exponential kernel}, $k_{SE}(x_{i},x_{j})=\exp\left(-\frac{\left\Vert x_{i}-x_{j}\right\Vert ^{2}}{2l^{2}}\right)$.

This is both one of the most popular and one of the simplest kernels as it only requires specifying a single hyperparameter, the lengthscale $l$. As such, we will use it for our experiments. %Note that there are other popular kernels, more of which can be found in Rasmussen \emph{et al} \cite{Rasmussen2006}.

Once the prior mean and kernel function are chosen, it can be augmented with the current data to generate a posterior distribution, $f(x)\vert D_{t}\sim\mathcal{GP}\left(m(x),\mathbf{K}_{t}\right)$
where $\mathbf{K}_t$ is the $t\times t$ kernel matrix with components $\mathbf{K}_{t,(i,j)}=k(x_i,x_j)$.
%\begin{equation}
%\mathbf{K}_{t}=\left[\begin{array}{ccc}
%k(x_{1},x_{1}) & \cdots & k(x_{1},x_{t})\\
%\vdots & \ddots & \vdots\\
%k(x_{t},x_{1}) & \cdots & k(x_{t},x_{t})
%\end{array}\right]
%\end{equation} This can then be used to give a full statistical estimate of the black box function through a predictive distribution, $p(f(x)\mid D_{t},x)=\mathcal{N}\left(\mu_{t}(x),\sigma_{t}(x)\right)$.
This allows us to find both the expected value of the function at any point through a predictive mean, $\mu_{t}(x)$, and to calculate its uncertainty through a predictive variance, $\sigma_{t}^{2}(x)$. Using the standard prior mean of $m(x)=0$, these are given by 
\begin{linenomath*}
\begin{eqnarray}
\mu_{t}(x)&=&\mathbf{k_{*}}(\mathbf{K}_{t}+\sigma^2_{noise}\mathbf{I})^{-1}\boldsymbol{y},\\\nonumber
\sigma_{t}^{2}(x)&=&k_{*\!*}-\mathbf{k_{*}}(\mathbf{K}_{t}+\sigma^2_{noise}\mathbf{I})^{\mathrm{-1}}\mathbf{k}_{*}^{\mathit{T}}
\end{eqnarray}
\end{linenomath*}
 with $k_{*\!*}=k_{t}(x,x)$ and $\mathbf{k}_{*}=[k(x_{1},x),k(x_{2},x),\ldots,k(x_{t},x)]$.
Here $\mathbf{I}$ is the identity matrix with the same dimensions
as $\mathbf{K}_{t}$, and $\sigma_{noise}$ is the output noise standard deviation. 

\subsection{Acquisition Functions\label{subsec:Acquisition-Functions}}

Once we have a statistical model, we must use it to generate a surrogate model that can be optimised to find the next input, $x_t$. This model is called an \emph{acquisition function}, $\alpha_t(x)$. The design of such a function is non-trivial, as it must balance selecting points to improve the Gaussian process (exploration) and focusing points in promising regions to find the global optimum (exploitation).

The exact mix of exploration and exploitation required will depend on the system being optimised. As such, several acquisition functions see practical use, including the Gaussian process upper confidence bound (GP-UCB) by \cite{srinivas2010}, entropy search (ES) by \cite{hennig2012entropy}, predictive entropy search (PES) by \cite{hernandez2014predictive}, knowledge gradient (KG) by \cite{scott2011correlated}, and expected improvement (EI) by \cite{jones1998efficient}. In this work, we use EI due to its strong performance and robustness. EI has the following closed form:
\begin{linenomath*}
\begin{equation}
\alpha_t^{EI}(x)=\begin{cases}
(\mu_t(x)-y^{+})\Phi(z)+\sigma_t(x)\phi(z), & \mathrm{if}\:\sigma_t(x)>0\\
0 & \mathrm{if}\:\sigma_t(x)=0
\end{cases}
\end{equation}
\end{linenomath*}
where $y_t^+=\max_{y_i \in D_t}{y_i}$ is the current best found function value, $z=\frac{\mu_t(x)-y^{+}}{\sigma_t(x)}$, $\phi$ is the standard
normal PDF, and $\Phi$ is the standard normal CDF. For a full analytical derivation of EI, we refer interested readers to \cite{nguyen2017regret}.

\subsection{Search Space}
Currently, Bayesian optimisation must be done within a finite search space, $\mathcal{X}$. The global optimisation of the acquisition function is simply not practically possible if the space is unbounded as it is impossible to adequately explore an unbounded space in a finite number of iterations. However, a poorly specified search space can lead to suboptimal performance. Small search spaces risk simply not containing the global optimum, while large search spaces are more costly to optimise \citep{nguyen2017bayesian}. For an example of a misspecified search space, see \textbf{ Fig. \ref{fig:SS_example}}.

\begin{figure}[h]
\centering
\includegraphics[width=0.48\columnwidth]{figs/small_bound.pdf}
%\includegraphics[width=0.48\columnwidth]{figs/large_bound.pdf}
\includegraphics[width=0.48\columnwidth]{figs/appropriate_bound.pdf}
\caption{Examples of boundaries for the Bayesian optimisation of a simple 1D function. The left bound does not contain the global maximum and its internal maxima is notably worse than the global one. The right bound contains the global maximum, making it appropriate for the function being optimised.}
\label{fig:SS_example}
\end{figure}

There are currently three proposed methods for expanding the search space. These are volume doubling, regularised expected improvement, and filtering Bayesian optimisation (FBO).

\subsubsection{Volume Doubling}
The first approach, volume doubling, was introduced by \cite{shahriari2016unbounded} as a heuristic method. It simply doubles the search space equally in each direction every $3d$ iterations. %It does so by an amount that increases the volume of the search space by a growth parameter, $\gamma$. In the initial work, the authors set the growth parameter and expiation frequency such that the volume doubles every $3d$ iterations.
While it does increase the size of the search space, it does so in a way that is completely ignorant of the model's statistics. This will often lead to poor performance, as it will expand in directions that are unlikely to contain the optimum and by amounts that may either be too large or small. It is, however, useful as a baseline.

\subsubsection{Regularised Expected Improvement}
The second method that \cite{shahriari2016unbounded} introduced attempts to remove the bound entirely. Instead, the user would specify a centroid and then select a regularising component. This will cause the acquisition function to tend to zero as it gets further away from the centroid. The rate of this decay is determined by one or more hyperparameters.

Two regularisation components were introduced. The first of these was a quadratic with $d$ width components, $w$, that control the decay in each dimension. The second of these was a hinge with a radius, $R$, and a decay rate, $\beta$. Both of these are centred around a centroid, $\bar{x}$. The quadratic, $Q$, and hinge, $H$, regularisation components are given below:
\begin{linenomath*}
\begin{eqnarray}
\zeta_Q(x)&=&(x-\bar{x})^T\mathrm{diag}(w^2)^{-1}(x-\bar{x})\\\nonumber
\zeta_H(x)&=&\mathbb{I}\left[\Vert x-\bar{x}\Vert_2>R\right]\left(\frac{\Vert x-\bar{x}\Vert_2-R}{\beta R}\right)^2
\end{eqnarray} 
\end{linenomath*}
%The hinge regularisation will not alter the acquisition function within $R$ of the centroid but will attenuate it at a rate proportional to $\beta$ outside of it. This means that $R$ can be seen as the radius of a soft bound. A second bound will also be needed to perform global optimisation on the acquisition function as all efficient global optimisers require at least an initial bound. This will need to be far larger than $R$ so that the decay from the regularisation will force the acquisition function to near-zero within this bound for the algorithm to behave as if it were unbounded. 
%
%Of these two regularisation components, the hinge is more robust. The quadratic will distort the acquisition function to heavily favour points near the centroid. This will lead to poor results unless the function optimum is very close to the centroid. As such, we have focused on the hinge regularisation component for our experiments.

While this method does make a misspecified bound less detrimental, it shares the same problem as volume doubling in that it does not consider the model's statistics. As the hyperparameters cannot be selected using marginal likelihood due to over-fitting issues \citep{shahriari2016unbounded}, their selection is as arbitrary as the selection of the search space in standard Bayesian optimisation. It is superior to a fixed bound as it can cope with the radius being slightly too small, but if the optimum lies significantly outside of the radius, then the algorithm will likely never find it due to the decay that the regularisation introduces. 

%As with volume doubling, it also favours all dimensions equally, where in reality a problem may require a far larger search space in some dimensions than it would in others. This means that even if the parameters are specified in a way that is appropriate for the problem, the search space may be much larger than necessary since the search space in all dimensions must be the same size as the largest one.

The method is also not technically unbounded, as a closed space is still required for the global optimisation of the acquisition function. This can be made to be large enough to enclose the vast majority of the acquisition function's mass, but it is still possible that it may not contain the global optimum. If it doesn't, there is no way for the algorithm to ever find it. In practical problems it can simply be chosen as the entire physically feasible region to circumvent this, but that may cause the global optimisation to become far more expensive than necessary.

%Lastly, this method has no convergence guarantees.

\subsubsection{Filtering Bayesian Optimisation}
Nguyen \emph{et al} \cite{nguyen2018filtering,nguyen2017bayesian} introduced a method that attempted to improve on the previous methods. At its core, their method is like volume doubling in that it starts with a small initial search space and then expands into a larger one, but it has two key differences that solve two of the previous method's problems. The first is that it only expands the radius, $h_t$, in each direction by a maximum of $\sqrt[d]{\frac{T}{t-1}}\times h_{t-1}$ each iteration, which guarantees that the regret is bounded.

The second issue in the methods by Shahriari \emph{et al} is that they effectively expand the search space without any regard to how poor the model predicts the regions to be. This can make the search space redundantly large. To rectify this, the method by Nguyen \emph{et al} filters the expansion to remove poor regions. It does this by using the GP posterior to calculate the upper confidence bound (UCB), $u(x)=\mu(x)+\sqrt{\beta}\sigma(x)$, and lower confidence bound (LCB), $l(x)=\mu(x)-\sqrt{\beta}\sigma(x)$. It then prevents expansion into regions where $u(x)<\max_{x\in \mathcal{X}_t}l(x)$. The global optimum of the LCB is a pessimistic estimate of $x^*$. Meanwhile, $u(x)$ is an optimistic estimate of the function value $x$. The authors argue that if the optimistic estimate of the function value at $x$ is worse than the pessimistic estimate of $x^*$ then it is unlikely that $x$ is the location of the global optimum. This means that the method only expands into regions that have a significant probability of containing the optimum instead of expanding into all regions equally.

While filtering Bayesian optimisation addresses the problems of the previous methods, it has issues of its own. While the initial expansion of $\sqrt[d]{\frac{T}{t-1}}\times h_{t-1}$ guarantees a regret bound, it still does not consider the data and therefore is unlikely to be the most efficient expansion. The filtering somewhat alleviates this problem, but it only prevents expansion into spaces that are already known to be bad. This means that if the method expands into regions that are later found to be undesirable it has no way of removing them. Lastly, the method can potentially get stuck in a particularly poor region as the filtering may prevent it from crossing a valley of poor points.

%\subsection{Thompson Sampling}
%Often it is desirable to utilise the distribution of the function maxima, $P_{f^*}$. However, this is generally not tractable so it must be approximated. This can be done by estimating samples of $f^*$ though Thompson sampling. This involves generating full samples of the black box function and then finding their maxima though global optimisation. There are multiple methods that can be used to generate these, but the most popular in Bayesian optimisation is to use random Fourier features \cite{hernandez2014predictive}.
%
%We aim to draw $M$ samples of the black-box function through the Gaussian process surrogate. We first present the function as a product of a basis function, $\phi(x)$, and weights, $\theta$
%\begin{equation}
%f(x)=\phi^T(x)\theta
%\end{equation}
%If the kernel chosen is stationary, such as the square exponential kernel described earlier, Bochner's theorem \cite{bochner1959lectures} lets us represent it through the use of its normalised Fourier dual, $\hat{s}(w)=s(w)/\beta$, as
%\begin{equation}
%k(x_i,x_j)=2\beta\mathbb{E}_{\hat{s}(w)}\left[\cos\left(w^Tx_i+b\right)\cos\left(w^Tx_j+b\right)\right]
%\end{equation}
%where $b\sim U[0,2\pi]$. As the kernel is a function of the basis, $k(x_i,x_j)=\phi(x_i)^T\phi(x_j)$, the above equation lets us approximate the basis with
%\begin{equation}
%\phi(x)=\sqrt{\frac{2\beta}{V}}\left\lbrace\cos(Wx+b),\sin(Wx+b)\right\rbrace
%\end{equation}
%where $W=[w_i,\ldots,w_V]$ are $V$ random frequencies.
%We then need to condition $\theta$ on the current data:
%\begin{equation}
%\theta=\mathbf{K}^{-1}\Phi^T\mathbf{y}
%\end{equation}
%where $\Phi=[\phi(x_1),\ldots,\phi(x_t)]$, $\sigma_n$ is the estimated noise level, $\mathbf{y}=[y_1,\ldots, y_t]$ is the current observations, and $\mathbf{K}=\Phi\Phi^T+\sigma_n^2\mathbf{I}$ is the kernel matrix given the current data and the chosen basis. With both $\theta$ and $\phi$, the black box function can be approximated with
%\begin{equation}
%f(x)\approx g_i(x)=\phi_i(x)^T\mathbf{K_i}^{-1}\Phi_i^T\mathbf{y},\quad i\in [1,M]
%\end{equation}
%Performing a global optimisation on this gives us the $M$ Thompson sample maxima,
%\begin{equation}
%g_i^*=\underset{x\in \mathcal{X}_t}{\max}g_i(x),~ i\in [1,M]
%\end{equation}
%
%One advantage of Thompson sampling is that it is relatively cheap compared to other parts of the BO algorithm. It only has a complexity $\mathcal{O}(MNV^2)$ where $N$ is the number of data points, $V$ is the number of random frequencies, and $M$ is the number of Thompson samples generated.

\section{The Proposed Method}\label{sec:Method}
In this section, we present our proposed method for advancing Bayesian optimisation for search spaces with unknown boundaries. Our problem statement can be written as 
\begin{linenomath*}
\begin{equation}
x^* = \underset{{x \in \mathcal{X}}}{\arg\max} f(x)
\end{equation}
\end{linenomath*}
where $\mathcal{X}$ denotes  a compact search space containing the global maximum of $f(x)$. We emphasize that $\mathcal{X}$ is \emph{unknown}.

Since $\mathcal{X}$ is \emph{unknown}, we develop a method to estimate a search space $\mathcal{B}$ that contains the global maximum $x^*$. We work with a probability distribution on the search space that allows search spaces with any finite bound. At each iteration, we use the available function observations to refine this distribution to estimate an effective search bound. In essence, our approach derives a distribution on the bound containing maxima, and then uses this distribution to estimate the bound.

\subsection{Distribution Derived Bound (DDB)}
We assume that a search space, $\mathcal{B}$, can be represented by a ``radius'', $r^*$, and a reference point, $x_0$, \emph{i.e.} $\mathcal{B}(r^*)\triangleq||x-x_0||_\infty<r^*$. We have  chosen the reference point as $x_t^+$, which is the location corresponding to the largest found function value $y_t^+=\underset{i\in[1,t]}{\max}y_i$ in $t$ iterations. We explicitly write $\mathcal{B}$ as $\mathcal{B}(r^*)$ and $\mathcal{B}(r^*)\triangleq||x-x_t^+||_\infty<r^*$. 
To check the suitability of a bound, $\mathcal{B}(r^*)$, whether it contains the global maximum, $x^*$, we define an event $E_{\mathcal{B}}\triangleq x^*\in \mathcal{B}(r^*)$. Next, conditioned on the event $E_{\mathcal{B}}$, we define a distribution on the radius, $r$, and thus indirectly define a distribution on 
the search space, ${\mathcal{B}(r)}$. We can then use Bayes theorem  to define a posterior distribution on $r$ given the current data ($D_t$) and the event $E_{\mathcal{B}}$ as
\begin{linenomath*}
\begin{equation}
p(r|D_t,E_{\mathcal{B}})\propto p(r|E_{\mathcal{B}})p(D_t|r,E_{\mathcal{B}}) \label{eqn:ddb_bayes_r}
\end{equation} 
\end{linenomath*}
In the above equation, $p(r|E_{\mathcal{B}})$ is a prior distribution encoding our belief about the bound $\mathcal{B}(r)$ containing $x^*$ and $p(D_t|r,E_{\mathcal{B}})$ is the likelihood of a bound, $\mathcal{B}(r)$, given the function observations, $D_t$ up to iteration $t$.
Next, we discuss how to specify the prior, $p(r|E_{\mathcal{B}})$, and the likelihood, $p(D_t|r,E_{\mathcal{B}})$.


\subsubsection{Prior Distribution.}
There are a few properties that are necessary to capture through our prior. First, the radius allowed by the prior must be strictly positive as zero or negative radii would not have any practical meaning. Secondly, the prior must be fairly broad to allow non-zero probability for any finite size bound. Finally, the prior must not assign a high probability to impractically large radii, instead we prefer it to penalise large boundaries. A distribution that satisfies all above properties is the gamma distribution: $p(r|E_{\mathcal{B}})=\text{Gamma}(r;\alpha,\beta)=\frac{\beta^\alpha}{\Gamma(\alpha)}r^{\alpha-1}e^{-\beta r}$, where $\alpha$ is a shape parameter and $\beta$ is a scale parameter. 

%The exact values of these parameters can be chosen by the user such that the mode corresponds to a sensible estimate of the radius and the distribution is appropriately wide.

\subsubsection{Likelihood Model.}
To define the likelihood, we essentially need to find the probability that the function maximum lies within $\mathcal{B}(r)$. In order to do this, we need to compute the probability of the event that the highest function value of $f(x)$ inside $\mathcal{B}(r)$ is bigger than the highest function value of $f(x)$ outside $\mathcal{B}(r)$, \emph{i.e.} $\mathbb{P}(D_t|r,E_{\mathcal{B}})=\mathbb{P}(\underset{x\in \mathcal{B}(r)}{\max}f(x)>\underset{{x\in \bar{\mathcal{B}}(r)}}{\max}f(x))$, where $f(x)$ is a random function drawn from the posterior Gaussian process after $t$ iterations and $\mathcal{\bar{B}}(r)=\mathbb{R}^d\setminus\mathcal{B}(r)$. Computing this probability is intractable as there is no closed form expression. However, it can be estimated using Monte Carlo sampling. We can utilise the Thompson sampling method by \cite{hernandez2014predictive} to draw a set of samples of ${f^{(i)}(x)}$ and thus get a sample set of ${\underset{x\in \mathcal{B}(r)}{\max}f^{(i)}(x)}$ and  ${\underset{{x\in \bar{\mathcal{B}}(r)}}{\max}f^{(i)}(x)}$ provided we can optimise $f^{(i)}(x)$ in $\mathcal{B}(r)$ and $\bar{\mathcal{B}}(r)$. While optimising $f^{(i)}(x)$ in $\mathcal{B}(r)$ is straightforward, optimising $f^{(i)}(x)$ in $\bar{\mathcal{B}(r)}$ is not due to $\bar{\mathcal{B}}(r)$ being unbounded. 

A way forward is to approximate the distribution of function maxima in $\bar{\mathcal{B}}(r)$.  We observe that, under the assumption of stationary kernel functions, the Gaussian process posterior distribution inside $\bar{\mathcal{B}}(r)$ has approximately zero mean and a variance of $k(x,x)$ as all the function observations are inside $\mathcal{B}(r)$ and therefore  distant. One's first instinct would then be to consider all the function values in $\bar{\mathcal{B}}(r)$ as an infinite number of i.i.d. normal random variables and use extreme-value distributions to estimate a sample of the maximum. However, in reality nearby points are mutually correlated (as dictated by the kernel function), so if a point is not the global maximum, it is likely that points nearby are also not the global maximum. Based on this idea, we can discretise the space $\bar{\mathcal{B}}(r)$ into a set of i.i.d. normal random variables with zero mean and variance $k(x,x)$. As the correlation is controlled by the lengthscale $l$, we define \emph{a packing number}, $\rho=q l$ that corresponds to the number of i.i.d. normal random variables in a unit volume of space where $q$ is a hyperparameter. We also approximate $\bar{\mathcal{B}}(r)$ by a large finite volume $V$, which can be set to a value beyond which the probability value $\mathbb{P}(D_t|r,E_{\mathcal{B}})$ starts to saturate.

Once we have a packing number, we can determine the probability of the maximum of  $f(x)$ inside $\bar{\mathcal{B}}(r)$ using the max-central limit theorem \citep{fisher1928limiting}:
\begin{linenomath*}
\begin{equation}
\mathbb{P}(\underset{{x\in \bar{\mathcal{B}}(r)}}{\max}f(x) \leq u^*)\approx F_{g}\left(\frac{u^*-m_{g}}{s_{g}}\right)
\end{equation}
\end{linenomath*}
where $F_{g}$ is the cdf of a Gumbel distribution and 
\begin{linenomath*}
\begin{equation}
m_{g}=\Phi^{-1}\left(1-\frac{1}{n}\right),\qquad s_{g}=\Phi^{-1}\left(1-\frac{1}{n\times e}\right)-\Phi^{-1}\left(1-\frac{1}{n}\right).
\label{eqn:gumbel} 
\end{equation}
\end{linenomath*}
The notation $\Phi^{-1}$ denotes the inverse normal CDF and $n$ is ${\rho}{V}$ rounded to the nearest integer. With this we can approximate the distribution, 
\begin{linenomath*}
\begin{eqnarray}
\mathbb{P}(D_t|r,E_{\mathcal{B}})&=& \mathbb{P}(\underset{{x\in \bar{\mathcal{B}}}}{\max}f(x) \leq g^*)
\approx \sum_{m=1}^{M}F_{g}\left(\frac{{g_m^*}-m_{g}}{s_{g}}\right)\label{eqn:prob_Dt_given_Eb}
\end{eqnarray}
\end{linenomath*}
where $g^*$ is a random variable denoting $\underset{{x\in \mathcal{B}(r)}}{\max}f(x)$ given $D_t$ and $\{{g_m^*}\}_{m=1}^M$ are the random draws from $g^*$. 

Although we can compute the probability $\mathbb{P}(D_t|r,E_{\mathcal{B}})$ for any given $r$, we still need to obtain the likelihood function $p(D_t|r,E_{\mathcal{B}})$ to be able to sample $r$ from its posterior. This will require us to compute $\mathbb{P}(D_t|r,E_{\mathcal{B}})$ for all possible $r$, which is clearly intractable. To solve this problem, we propose to use a parametric model for the probability $\mathbb{P}(D_t|r,E_{\mathcal{B}})$ whose parameters can be estimated with finite number of data samples of $r$ and $\mathbb{P}(D_t|r,E_{\mathcal{B}})$ computed using equation (\ref{eqn:prob_Dt_given_Eb}). The parametric model for the probability $\mathbb{P}(D_t|r,E_{\mathcal{B}})$ needs to have the following \emph{two properties}:
\begin{enumerate}
\item For any two boundaries sharing the same centroid, the larger bound will naturally have a higher probability of containing the global maximum, i.e.
\end{enumerate}
\begin{equation}
\mathbb{P}(D_t|r_1,E_{\mathcal{B}(r_1)}) \geq \mathbb{P}(D_t|r_2,E_{\mathcal{B}(r_2)}),\quad \mathsf{for} \quad r_1\geq r_2
\end{equation}
\begin{enumerate}
\setcounter{enumi}1
\item The probability $\mathbb{P}(D_t|r,E_{\mathcal{B}})$ will also increase with higher maximum function value observed through $D_t$, i.e. $y_t^+$. The larger the $y_t^+$ is, the more likely $r$ is to contain the true global maximum as $r$ is defined around the location $x_t^+$ corresponding to the observation $y_t^+$.  
\end{enumerate}
A distribution satisfying the above requirements is the log-logistic distribution:
\begin{linenomath*}
\begin{equation}
\mathbb{P}(D_t|r,E_{\mathcal{B}})=\frac{1}{1+(r/a)^{-y_t^+/b}}\label{eqn:loglog_CDF}
\end{equation}
\end{linenomath*}
where $a$ and $b$ are hyperparamaters. These can be estimated through a non-linear least squares regression, which fits equation (\ref{eqn:loglog_CDF}) using data: $\{r_i,F(r_i)\}$, where $r_i$ is a random radius sample drawn from its prior distribution and $F(r_i) = \mathbb{P}(D_t|r_i,E_{\mathcal{B}(r_i)})$ computed using equation (\ref{eqn:prob_Dt_given_Eb}). In particular, we  minimise the squared sum of the residuals as
\begin{linenomath*}
\begin{equation}
SSR=\underset{{a,b}}{\min} \sum_i{\left[F(r_i)-\frac{1}{1+(r_i/a)^{-y_t^+/b}}\right]^2}
\end{equation} 
\end{linenomath*}
Given the estimated hyperparameters $a$ and $b$, we can take the derivative of the above expression and write the likelihood or pdf $p(D_t|r,E_{\mathcal{B}})$ as
\begin{linenomath*}
\begin{equation}
p(D_t|r,E_{\mathcal{B}})=\frac{(y_t^+/{a})(r/a)^{y_t^+/b-1}}{(1+(r/a)^{y_t^+/b})^2}\label{eqn:likelihood}
\end{equation}
\end{linenomath*}
\subsubsection{Posterior Distribution.}

With both the prior and likelihood we can obtain a tractable form for the posterior distribution,
\begin{linenomath*}
\begin{eqnarray}
&&p(r|D_t,E_{\mathcal{B}})\propto p(r|E_{\mathcal{B}})p(D_t|r,E_{\mathcal{B}})\nonumber \\
&&= \left(\frac{\beta^\alpha}{\Gamma(\alpha)}r^{\alpha-1}e^{-\beta r}\right)\times\left(\frac{(y_t^+/{a})(r/a)^{y_t^+/b-1}}{(1+(r/a)^{y_t^+/b})^2}\right) \label{eqn:posterior}
\end{eqnarray}
\end{linenomath*}
We can determine the optimal radius, $r^*$, from the posterior in one of two ways. 

The first method is to use a maximum a posteriori (MAP) estimate by using a global optimiser to find the maximum of the posterior. As the posterior is the product of two unimodal functions arising from the log-logistic and gamma distributions, its maxima must lie between the mode of the log-logistic, $m_{ll}=a\left(\frac{b-1}{b+1}\right)^{1/b}$ and the mode of the gamma distribution, $m_{\gamma}=\frac{\alpha-1}{\beta}$. This gives us a closed bound, $[\min(m_{\gamma},m_{ll}),\max(m_{\gamma},m_{ll})]$ allowing us to use a standard global optimiser such as DIRECT \citep{jones2001direct} to determine the MAP estimate of the optimal radius, $r^*$.

The second method is a full Bayesian sampling approach. This involves generating several samples from the gamma prior over $r$ and re-sampling them through the weights computed by the log-logistic likelihood \citep{smith1992bayesian}. In particular, let us assume we have samples of $r$ from the gamma prior as $\{r_i\}_{i=1}^{L}$, we compute the likelihood value for each sample as $w_i = p(D_t|r_i,E_{\mathcal{B}})$. Next we normalise the weights to convert them to probabilities as $\tilde{w}_i=\frac{w_i}{\sum_{i=1}^{L}w_i}$. We then draw a sample of $r^*$ from the original sample set $\{r_i\}_{i=1}^{L}$ using the probabilities $\{\tilde{w}_i\}$.

The full Bayesian approach has two key advantages over the MAP variant. Although neither method is particularly costly in the context of Bayesian optimisation problems, the full Bayesian approach is slightly cheaper than the MAP variant as it does not require a relatively costly global optimisation step. The second advantage is that the randomness involved in the sampling ensures that there is a non-zero probability for any nonzero radius. This means that, unlike other methods such as FBO, the full Bayesian method will not get trapped by a surrounding poor region and hence will always have a non-zero chance of finding the global optimum. However, while the full Bayesian has its advantages, the MAP heuristic in practice has similar performance. As such, we believe both methods have merit and we will present results for both.

Once we have obtained a sample of the optimal radius, $r^*$, we can use it to define the bound for the current iteration of Bayesian optimisation as 
\begin{linenomath*}
\begin{equation}
\mathcal{B}(r^*)=||x-x_t^+||_\infty<r^*
\end{equation}
\end{linenomath*}
This can be updated with each iteration to ensure that the most appropriate bound is always used.

A summary of our method can be seen in \textbf{Algorithm \ref{alg:DDB_alg}}.
\begin{algorithm}[tb]
\caption{Bayesian Optimisation with Distribution Derived Bound (DDB)}
\label{alg:DDB_alg}
\textbf{Input}:$D_{t_0}=\lbrace x_i,y_i\rbrace_{i=1}^{t_0}$, \# Thompson samples $M$, \# radius samples $L$, \# Iterations $T$, Kernel lengthscale $l$, gamma shape parameter $\alpha$, gamma scale parameter $\beta$
\begin{algorithmic}[1] %[1] enables line numbers
\FOR{$t=t_0$ to $T$}
\STATE Build a Gaussian Process (GP) with $D_{t}$.
\STATE Generate $M$ samples of $g^*$ from the GP with Thompson sampling (refer to sec 2.1 of \cite{hernandez2014predictive}).
\STATE Draw $L$ samples of radius $\{r_i\}_{i=1}^L$ from the prior using $\alpha$ and $\beta$.
\STATE For each $r_i$, estimate $F(r_i)=\mathbb{P}(D_t|r_i,E_{\mathcal{B}(r_i)})$ with Eqn. (\ref{eqn:prob_Dt_given_Eb}).
\STATE Estimate log-logistic parameters, $a$ and $b$, by fitting $\{r_i,F(r_i)\}_{i=1}^L$ with non-linear least squares regression.
\IF{Full Bayesian method is used}

\STATE For each $\{r_i\}_{i=1}^L$, compute the likelihood, $w_i=\mathbb{P}(D_t|r_i,E_{\mathcal{B}(r_i)})$ with Eqn (\ref{eqn:likelihood}).
\STATE Normalise $\hat{w_i}=\frac{w_i}{\sum w_i}$ to convert them to posterior probabilities.
\STATE Draw a sample, $r^*$, from the set $\{r_i\}_{i=1}^L$ using $[\hat{w_1},\ldots,\hat{w_L}]$.
\ENDIF
\IF{MAP method is used}
\STATE Use a global optimisation algorithm on the posterior in Eqn. (\ref{eqn:posterior}) with the bound $\left[\min\left(a\left(\frac{b-1}{b+1}\right)^{1/b},\frac{\alpha-1}{\beta}\right),\max\left(a\left(\frac{b-1}{b+1}\right)^{1/b},\frac{\alpha-1}{\beta}\right)\right]$ to obtain $r^*$.
\ENDIF
\STATE Using the estimate of $r^*$, set $\mathcal{B}(r^*)$ as $||x-x_t^+||_\infty<r^*$.
\STATE Optimise the acquisition function over $\mathcal{B}(r^*)$ to obtain $x_{t+1}$ and use it to sample $y_{t+1}=f(x_{t+1})+\epsilon_n$ from the system.
\STATE Augment the data, $D_{t+1}=D_y\cup\{x_{t+1},y_{t+1}\}$.
\ENDFOR
\RETURN $x^+=x_i$ such that $y_i=\underset{t\in [1,T]}{\max} y_t$.

\end{algorithmic}
\end{algorithm}

\section{Experimental Results}\label{sec:Results}
In this section, we demonstrate the performance of our method by testing it against competing methods on a range of benchmark and real-world functions. The real-world functions include both hyperparameter optimisation for a SVR algorithm, and optimising the temperatures and cooking times for an alloy heat treatment design. \textbf{The Python code used for this paper can be found at \url{https://github.com/jmaberk/DDB}}.

\begin{figure}
\centering
\includegraphics[width=0.57\columnwidth]{figs/demonstation0.pdf}\includegraphics[width=0.32\columnwidth]{figs/radius0.pdf}
\includegraphics[width=0.57\columnwidth]{figs/demonstation1.pdf}
\includegraphics[width=0.32\columnwidth]{figs/radius1.pdf}
\includegraphics[width=0.57\columnwidth]{figs/demonstation2.pdf}
\includegraphics[width=0.32\columnwidth]{figs/radius2.pdf}
\includegraphics[width=0.57\columnwidth]{figs/demonstation3.pdf}
\includegraphics[width=0.32\columnwidth]{figs/radius3.pdf}
\caption{An example of the DDB method applied to a simple two peak Gaussian mixture. The plots on the left show the true function being optimised, the Gaussian process predictive mean and standard deviation, and the suggested bound. The plots on the right show the posterior distribution of the radius, $p(r|D_t,E_{\mathcal{B}})$. Note that the initial bound at iteration $0$ does not contain the global maximum but by the 3rd iteration DDB is able to alter the bound to rectify this.\label{fig:bound_example}}
\end{figure}

\subsection{Experimental Set-up} \label{sec:4p1}
Here we demonstrate both the full Bayesian (DDB-FB) and the MAP estimate (DDB-MAP) implementations of our method with prior distribution parameters, $\alpha=2$ and $\beta=1/2$. These are set such that the prior gamma distribution has a mean radius of 4, but they can be adjusted by the user to make the prior distribution conform to any prior knowledge of the systems bound. Likewise, a packing number parameter of $q=5$ is used but this can also be changed based on any prior knowledge of the systems lengthscale. We test our method by using it to adjust the bound of a standard Bayesian optimisation algorithm on a range of problems. The performance of this Bayesian optimisation algorithm is compared to ones with bounds found with the following methods:
\begin{itemize}
\item The standard fixed search bound (Standard bound).
\item Volume doubling every 3 iterations (Volume doubling) \citep{shahriari2016unbounded}.
\item Regularised EI with a hinge regularisation term with $R=0.5$, $\beta=1$, and $\bar{x}$ as the centre of the initial search space (Regularised) \citep{shahriari2016unbounded}.
\item Filtering Bayesian optimisation (FBO) \citep{nguyen2018filtering}.
\end{itemize}

All experiments are done with $20d$ iterations, where $d$ is the number of input dimensions, and $3d +1$ initial points chosen randomly with a Latin hypercube sample scheme \citep{jones2001taxonomy}. A maximum search space is selected for each function and the initial search space is randomly chosen in each run to be 10\% of a maximum possible search space. The data is normalised each time a new function value is obtained by sampling the recommended point. Each experiment is repeated 20 times with different initial search bound and initial points. The results of these experiments are then averaged and presented with error bars based off the standard error. For consistency, any function that is traditionally minimized is transformed into a maximization problem by taking its negative. The kernel for all examples is a square exponential kernel with an initial lengthscale of $2l^2=0.1$, which is adjusted using a GP marginal likelihood estimate every $2d$ iterations.

\subsection{Illustration of the Distribution Derived Bound}
In \textbf{Fig. \ref{fig:bound_example}} we show an illustration of our proposed DDB method. The function used is a simple 1D two peak Gaussian mixture and the algorithm is initialised with four points marked on the plot. The bound distribution, $p(r|D_t,E_{\mathcal{B}})$, is also shown.

The initial bound does not contain the global maximum, however DDB both shifts the centre of the search space and increases its radius such that it is substantially improved after one iteration. In the next iteration we can see that the bound has both been made larger and its centre has been shifted in the direction of the global maximum. At this point it encloses the global maximum. Note that outside of the first step, the size of the bound changes little between iterations but it is still able to enclose the global maximum. In addition, our method can automatically narrow down the search space to cull poor value regions. This property of our model is significant, and a key difference from all existing dynamic methods that continuously expand the search bound. 



\subsection{Benchmark Functions}
We test our method on a range of common benchmark functions to demonstrate its performance. These were the Branin (2D), Beale (2D), and Hartmann (3D and 6D) functions\footnote{All benchmark functions use the recommended parameters and maximum search space from \url{https://www.sfu.ca/~ssurjano/optimization.html}}. The results are shown in\textbf{ Fig. \ref{fig:benchmarks}}.  

\begin{figure}[h]
\centering
\includegraphics[width=0.48\columnwidth]{figs/branin_2_E3I}
\includegraphics[width=0.48\columnwidth]{figs/Beale_2_E3I}
 
\includegraphics[width=0.48\columnwidth]{figs/hartmann_3d_3_E3I}
\includegraphics[width=0.48\columnwidth]{figs/hartmann_6d_6_E3I}  
\caption{Comparative performance of the DDB method against other methods on several common benchmark functions. Note that methods that do not dynamically alter their bound perform very poorly, as they cannot find the global optimum if their bound is not properly initialised. Of the dynamic methods, DDB has the strongest performance. \label{fig:benchmarks}}
\end{figure}

The fixed bound and regularised methods can only reach the best optimum inside their effective search space, so they usually fail to reach the global optimum. Filtering Bayesian optimisation does better, but still performs poorly. This may be due to its failure to expand past an unfavourable region due to its filtering property or because of it cannot expand enough to reach the global optimum due to its constantly reducing expansion window. Volume doubling can achieve reasonable results due to the maximum bound being relatively small, but it does so slowly as it needs to explore an unnecessarily large search space. This often leads to poor early performance, making it unsuitable for problems with small iteration budgets.

DDB achieves the best final result in all above cases as it is able to shift the search space towards the optimum even if the initial bound is poor while keeping a smaller search space than competing methods.

\subsection{Machine Learning Hyperparameter Tuning}

The first real-world problem we will demonstrate our method on is that of tuning the hyperparameters of a support vector regression (SVR) \citep{drucker1997support} algorithm. This is simply the support vector machine classification algorithm extended to work on regression problems. It has three hyperparameters, the threshold, $\epsilon$, the kernel parameter, $\gamma$, and a soft margin parameter, $C$. Its performance is measured in root mean squared error (RMSE). Note that we have chosen to maximize the negative RMSE to keep the plots consistent. All experiments are done with the public Space GA scale dataset \footnote{ Dataset can be found at \url{https://www.csie.ntu.edu.tw~cjlin/libsvmtools/datasets/regression.html}}. The results are shown in\textbf{ Fig. \ref{fig:real_exp}}.

As with the benchmark functions, methods with static search spaces perform very poorly. FBO initially performs well but either the filtering or the diminishing expansion means that it is unable to reach the global optimum. Volume doubling has worse early performance than other dynamic methods but is able to pull ahead of FBO. Lastly, both implementations of DDB show superior performance as they are able to dynamically alter the search space while not getting stuck like FBO or making the search space unnecessarily large like volume doubling.

%It is also worth noting that the variance between runs is far higher in the static bound methods as their performance is heavily dependent on the initial search space.

\subsection{Materials Science Application: Alloy Cooking}
The final example of our methods performance is the optimisation of the hardness of an Aluminium-Scandium alloy in a simulation \cite{robson2003extension}. The hardening process consists of two stages: nucleation and precipitation. These are controlled through multiple cooking stages. Each of these has a duration and a temperature parameter that can be optimised through Bayesian optimisation. We test our method on a two-stage cooking simulation, giving four hyperparameters. The results are shown in\textbf{ Fig. \ref{fig:real_exp}}. 

\begin{figure}
\centering
\includegraphics[width=0.49\columnwidth]{figs/"SVR on Space GA_3_E3I".pdf}
\includegraphics[width=0.46\columnwidth]{figs/AlloyCooking_Profiling_4_E3I.pdf}
\caption{Performance of the DDB methods compared against that of other common methods on tuning the hyperparameters for a SVR algorithm (left) and a two step Aluminum-Scandium alloy cooking simulation (right). Again, methods that do not dynamically alter their bound achieve very poor results as it is impossible for them to find the global optimum if their search space is misspecified. Of the dynamic methods, DDB has the strongest performance. \label{fig:real_exp}}
\end{figure}

As previously observed, the static bound methods have inferior performance compared to the dynamic bound approaches. Likewise, DDB achieves the best performance out of the dynamic methods. Volume doubling, however, achieves poorer results than it did in the synthetic problems.

\subsection{Sensitivity to Hyperparameters}
Here we show the sensitivity of our method to variances in its hyperparameters. These are the packing number, $q$, and the parameters of our prior gamma distribution, which we chose to shift through $\alpha$. The tests were done using the MAP variant on the Hartmann 3D function also seen in Fig. \ref{fig:benchmarks} and their results are shown in Fig. \ref{fig:HP_test}. Outside of the parameter being investigated in the plot, these experiments are done as outlined in Section \ref{sec:4p1}. As the differences between the results is small, the plots are shown in a logarithmic scale and are zoomed in.  

\begin{figure}
\centering
\includegraphics[width=0.49\columnwidth]{figs/"hartmann_3d_3_E3I_q".pdf}
\includegraphics[width=0.49\columnwidth]{figs/hartmann_3d_3_E3I_gamma.pdf}
\caption{Sensitivity of DDB to hyperparameters for the MAP variant of DDB, with the sensitivity to the packing number, $q$, (left) and the sensitivity to changes in the prior through $\alpha$ (right). Note that, despite the log scale, there is little change in the results between the different hyperparameters. \label{fig:HP_test}}
\end{figure}

We can see that the system is insensitive to changes in $q$. The most significant difference is that a $q$ over 50 will cause a negligible performance drop. This is likely due to the fact that the likelihood model is an approximation of a limiting distribution, and as such will change little once $q$ becomes high enough.

Increasing the $\alpha$ parameter of the prior distribution will shift it right, causing it to favour larger radii. As the Hartmann function has its optima near a corner of the maximum search space, it favours larger radii and hence larger $\alpha$ perform better on it. However, if the optima was nearer the center of the maximum search space or if it had multiple equal optima, then it would favour a smaller radii and hence a smaller $\alpha$.

Another thing that changing $\alpha$ will do is make the prior distribution wider. This will make it less informative, which is appropriate if there is little prior knowledge about the system. The width can be change without shifting the mean distribution by changing $\beta$ as well as $\alpha$.

\section{Conclusion}\label{sec:Conclusion}
We have introduced a new method for dynamically altering the Bayesian optimisation search space. While other existing approaches keep expanding the search space, our method is different as it allows the search space to both expand and collapse. We also adjust this search space by deriving the appropriate bound inferred from the function observations which potentially leads to more efficient optimisation.
Our approach has been shown to perform better than alternative methods both on benchmark and real-world functions.

\subsubsection*{Acknowledgements.}
This research was supported by an Australian Government Research Training Program
(RTP) Scholarship awarded to JMA Berk, and was partially funded by the Australian
Government through the Australian Research Council (ARC). Prof Venkatesh is the
recipient of an ARC Australian Laureate Fellowship (FL170100006).
\bibliographystyle{elsarticle-num}
\bibliography{baysOptRevBibV3}
\end{document}
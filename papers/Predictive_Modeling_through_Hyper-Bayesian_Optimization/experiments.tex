Experimentation was conducted for discovering length scales and monotonicity information of synthetic functions and real world datasets using the Predictive modeling framework. In the experiments presented the framework was used to discover either monotonicity or the length scale values, but the framework can be extended to tune both, if required. Average of 50 trials are reported with error bars indicating standard error. The input ranges of each experiment were normalized. 

The results are shown in two cases: 

\textit{Case 1}: HyperBO vs Standard BO; 

\textit{Case 2}: Optimization performance of Best discovered hyperparameter values - re-running experiment with best scoring $\boldsymbol{\theta}$ from HyperBO run. This is used to test the validity of the hyperparameters found by HyperBO. If prior information is available about the true hyperparameter values (gold standard), these are compared against as well.

Code for all Length Scale experiments and synthetic monotonicity experiment can be found at https://bit.ly/2tElQBX. 
\subsection{Length Scale Experiments}
The Predictive modeling framework was applied to 3 real world datasets for tuning length scales, which included Concrete Compressive Strength, Combined Cycle Power Plant and QSAR fish toxicity, whilst searching for the maxima of the dataset. The length scale ranges were discretized between 0.1 and 0.6, with a step size of 0.05.  The performance of HyperBO in discovering the appropriate length scales for the models is displayed in Figure \ref{fig:LengthScale_experiments}. For these  experiments, the value of $\lambda$ in the scoring function (\ref{eq:length_score}) was set to $\frac{1}{ 0.6 \times d}$ in order to normalize the regularization term. In all experiments, tuning of length scale with the framework improves the performance, as shown in Figure \ref{fig:LengthScale_experiments}.

\subsubsection{Concrete Compressive Strength}
This dataset comprised of 8 variables from 1030 experiments to predict the compressive strength of concrete. The task of BO is to find the maximum compressive strength using the existing data points as a discrete search space.

\subsubsection{Combined Cycle Power Plant}
This dataset comprised of 4 variables from 9568 data points. The input variables, which include temperature, ambient pressure, relative humidity and exhaust vacuum predict  the hourly electrical energy output of a power plant. Here the task is to determine the maximum hourly energy output.

\subsubsection{QSAR fish toxicity}
This dataset is comprised of 6 molecular descriptors of 908 chemicals predicting toxicity towards the fish species known as Pimephales promelas (fathead minnow). The task here is to determine the maximum toxicity towards the fish.

\begin{figure}[t]
	\centering
	\subfloat[Goldstein-Price]{{\includegraphics[height = 3cm, width=3.5cm]{figures/Gold_Price_1a.png}}}%
	\qquad
	\subfloat[Goldstein-Price]{{\includegraphics[height = 3cm,width=3.5cm]{figures/Gold_Price_1b.png}}}%
	\qquad
	\subfloat[Diabetes]{{\includegraphics[height = 3cm,width=3.5cm]{figures/Diabetes_10D_1a.png}}}%
	\qquad
	\subfloat[Diabetes]{{\includegraphics[height = 3cm,width=3.5cm]{figures/Diabetes_10D_1b.png}}}%
	\qquad
	\subfloat[Boston]{{\includegraphics[height = 3cm,width=3.5cm]{figures/Boston_1a.png}}}%
	\qquad
	\subfloat[Boston]{{\includegraphics[height = 3cm,width=3.5cm]{figures/Boston_1b.png}}}%
	\caption{Regret vs Iteration results of Monotonicity tuning experiments Case 1: a,c,e) Standard BO outperforms HyperBO in early iterations but converges faster in later iterations as monotonicity information is extracted. b,d,f) Case 2: GP with best monotonicity information outperforms Standard BO and is close in performance to GP with prior monotonicity information (in Goldstein-Price function) (gold standard).}%
	\label{fig:Monotonicity_experiments}%
\end{figure}

\subsection{Monotonicity Experiments}
For the monotonicity experiments, the goal is to find the optima quicker and also reveal the existence of monotonicity between variables and the output. The values of $\boldsymbol{\theta}$ were discretized to [-6, 0]. In addition, a constraint was applied such that a value of [-6] could not be applied in both the negative and positive directions of a given dimension. This reduces the search space with the assumption that a given dimension could not be both monotonically increasing and decreasing at the same time. For the following experiments, the value of $\lambda$ in the scoring function (\ref{eq:score2}) was set to $\frac{1}{2 \times 6 \times d}$, to normalize the regularization term. Figure \ref{fig:Monotonicity_experiments}a),c),e) shows the performance of the Predictive Modeling framework compared to a Standard BO. Figure \ref{fig:Monotonicity_experiments}b),d),f) compares the performance of the best discovered hyperparameters compared to the Standard BO, and where possible, against prior knowledge of monotonicity (synthetic function)(the gold standard).

\subsubsection{Virtual Derivatives}
\textcolor{blue}{As per Section 2.5.1, virtual derivatives were added to incorporate monotonicity into the model.} The number of virtual derivatives was set to $5d$ where $d$ is the dimension of the data. This was to allow the virtual derivatives to enforce monotonicity strongly in the early iterations (when observations are low), and for observations to control the fit of the GP in later iterations (when observations are higher than virtual derivatives). These points were randomly placed in the search space.

\subsubsection{Goldstein-Price Function}
The trend towards the maxima of the Goldstein-Price function can be seen to decrease with respect to the first dimension, and increasing with respect to the second dimension (gold standard). When applying HyperBO, the average of the best monotonicity information from the trials returned a value of -3.24 (negative trend) for $x1$ and 2.64 (positive trend) $x2$. The results reflect the expected monotonicity, demonstrating how HyperBO is able to extract monotonicity information for the latent function during the optimization process.

\subsubsection{Diabetes}
The Diabetes dataset comprises of 10 variables (Age, Sex, BMI, Blood Pressure and 6 blood serum variables), from 443 patients, to predict the diabetes progression 1 year after baseline, and the task is to determine the patient with the highest disease progression.  The data of a particular patient was found to be an outlier and removed (the individual had a high disease progression, despite being quite young). Figure \ref{fig:Diabetes_mono}a) displays the correlation between the input variables and the output. This is used as a metric to assess our findings of monotonicity against. Figure \ref{fig:Diabetes_mono}b) displays the average direction of monotonicity for each feature.  For all but BP, S1, S2 and S5, monotonicity matched the correlation coefficient direction.

\begin{figure}
	\centering
	\subfloat[Correlation values]{{\includegraphics[height = 2.5cm, width=2.6cm]{figures/Diabetes_Correlation.png} }}%
	\qquad
	\subfloat[Difference of average monotonicity value]{{\includegraphics[height = 2.5cm, width=3.5cm]{figures/AverageMonotonicity_Diabetes.png} }}%
	\caption{Diabetes Dataset results. Green - Monotonicity matches correlation. Red - mismatch.}%
	\label{fig:Diabetes_mono}%
\end{figure}

\subsubsection{Boston Housing}
The Boston Housing dataset comprises of 13 features predicting the  median house price. The data was scaled with the median house price ranging between -2.5 and 2.5. For our experiment, only per capita crime rate (CRIM), non-retail business portion (INDUS), average number of rooms (RM), weighted distance to employment centres (DIS), pupil-teacher ratio (PTRATIO) portion of black residents (B), and \% of lower status (LSTAT)  were considered. The task was to discover the maximum median house price, whilst applying monotonic trends within the dataset. As there are multiple maxima in the dataset, the data was filtered to include only 1 maxima which was used in all experiments.

Figure \ref{fig:Boston_mono}a) shows the correlation coefficients between each input feature and the output. Figure \ref{fig:Boston_mono}b) displays the difference in the average monotonicity values for each dimension.

\begin{figure}
	\centering
	\subfloat[Correlation values]{{\includegraphics[height = 2.1cm, width=2.6cm]{figures/Boston_Correlation.png} }}%
	\qquad
	\subfloat[Difference of average monotonicity value]{{\includegraphics[height = 2.1cm, width=3.5cm]{figures/AverageMonotonicity_Boston.png} }}%
	\caption{Boston Housing dataset results. Green - Monotonicity matches correlation. Red - mismatch.}%
	\label{fig:Boston_mono}%
\end{figure}

\iffalse
Having observed the performance of the Predictive Monotonicity model search framework with HyperBO the following trends have emerged:
\begin{itemize}
	\item HyperBO performs best for complex functions which require a large number of samples. This is to balance the need for the number of models of monotonicity HyperBO must test. The number of monotonic models tested is equal to $(\frac{1}{K})$ of the number of total iterations $R$. A balance must be made in the selection of $K$ as, though a small value will result in more monotonic models being tested, it makes the scoring of these models unstable, as it is less lenient on the performance of the model and may score its performance poorly based on a few iterations governed by $K$.
	\item The framework was able to successfully extract most trends in the synthetic functions  as well as the real world datasets. It was interesting to observe in the results of the Diabetes dataset that as the maximum value did not follow on the trend of the data points, our framework monotonicity values were different to the correlation coefficient of the data.
	\item Exploring only monotonicity as derivative related information to be discovered and incorporated into a GP model can be limiting. Functions are often complex and not completely monotonous across an entire dimension range and as such further work is encouraged in developing this limitation further.  
\end{itemize}
\fi

\section{Solar neutrino analysis}
\label{sec:solaranalysis}
We will now use the insight gained through the studies described in this paper to design new spallation cuts for a specific SK-IV analysis. For this paper, we will focus on the solar neutrino measurements. Indeed, while many low energy analyses at SK target antineutrinos, whose interactions produce neutrons, solar neutrino interactions do not have a signature, so radioactive $\beta$ decays will look similar to them (except for the direction of the electron). Hence, even with SK-Gd, the solar neutrino analysis will continue to heavily rely on dedicated spallation tagging techniques, in addition to control of intrinsic radioactive backgrounds such as from the radon decay chain~\cite{Nakano:2019bnr}. In what follows we present an overview of the current analysis, and in particular of the previous spallation reduction strategy.

\subsection{Overview}
Here, we present a brief overview of the cuts used for the SK-IV solar neutrino analysis. A more detailed description of these cuts can be found in Ref.~\cite{skivsolar}.  

$^8$B and {\it hep} solar neutrinos from the Sun scatter elastically on electrons in SK, with the recoiling electron producing a single Cherenkov ring. The produced electrons have energies up to about 20~MeV; however, intrinsic radioactivity is a limiting background that dominates below about 5.5~MeV kinetic energy. In this paper, we therefore consider the 5.49$-$19.5 MeV energy range. The impact of these new spallation cut son the full SK-IV solar neutrino analysis will be described in~\cite{newsolarpaper}.

After high-efficiency noise reduction cuts are applied, notably rejecting events outside the FV, energy-dependent quality cuts are imposed on the reconstructed vertices and directions of the events, the goodness observables described in Sec.~\ref{sec:lowereco}. The major quality cuts select events based on their reconstruction goodness ($g_{R} = g^2_{t} - g^2_{p}$) and their \emph{effective} distance to the ID wall ---obtained by following their reconstructed direction backwards. We then check for consistency with a single electron ring (rather than, e.g. light deposited by $\beta\gamma$ decays of $^{16}$N). We parametrize the amount of multiple Coulomb scattering of the electron (the ``fuzziness" of the ring) with the ``multiple scattering goodness" to separate lower energy $\beta$ decays. Most of the remaining background events are removed using a dedicated spallation cut. 

The number of solar neutrinos can be readily extracted from the sample of events remaining after cuts by considering event directions. Indeed, electrons recoiling from neutrino elastic scattering will be almost collinear with the incoming neutrinos, that is the angle between the direction of a given event and the direction from the Sun at its detection time, $\theta_{Sun}$ is small (less than 15$^\circ$) and the $\cos\theta_{Sun}$ distribution is strongly peaked around $1$. The numbers of solar neutrinos and background events are extracted from a fit to the $\cos\theta_{Sun}$ distribution.


\subsection{Spallation cuts for the previous solar analyses}
\label{sec:spaprevious}
Spallation backgrounds can be significantly reduced by identifying space and time correlations between each isotope decay and its production in a hadronic shower initiated by a muon. To this end, each solar neutrino candidate selected using the noise reduction and quality cuts described above is paired with muons detected up to 100~s before it. For each pair, three observables are then considered: the time difference $\Delta t$ between the solar neutrino event candidate and the muon, the transverse distance of the candidate to the muon track $l_t$ ---defined in Fig.~\ref{fig:vardia}--- and the residual charge $Q_{res}$, defined as the excess charge deposited by the muon in the detector compared to the expectation from minimum ionization. For each observable, probability distribution functions~(PDFs) are then defined for spallation pairs, formed by isotope decay events and their parent muons, and for uncorrelated ``random'' pairs. These PDFs then allow to define a log likelihood function $\log_{10}\mathcal{L}$, whose functional form is as follows:

\begin{equation}
    \log_{10}\mathcal{L} = \log_{10} \left[ \prod_i \mbox{\it PDF}_{spall,i}(x_i)/\mbox{\it PDF}_{ran,i}(x_i) \right]
    \label{eq:loglike}
\end{equation}

\noindent where {\it PDF}$_{spall,i}$ and {\it PDF}$_{ran,i}$ designate the PDFs associated with a given observable $i$ for spallation and random pairs respectively. 

In the absence of a spallation simulation, the PDFs for spallation and random pairs need to be extracted from data. One sample is built by pairing solar event candidates with preceding muons (as described above). It will contain a mixture of spallation and random coincidence pairs. Using the times of events with energies much below 6~MeV, we construct a``random sample'' by generating a vertex from a uniform distribution filling the entire detector. When paired with preceding muons, this random sample estimates the random coincidence contribution, so the corresponding PDFs are extracted. Also, after subtraction of the random sample, the spallation PDFs are extracted from the data sample. Alternatively, we invert the time sequence and pair solar candidates with muons up to 100~s \emph{after} them. This inverted sample is used the same way as the random sample. Finally, in order to account for possible correlations between observables, the $l_t$ PDFs are computed for seven different $Q_{res}$ bins. Since the muon fitter used for these cuts considered only single through-going muons, a goodness-of-fit cut was also considered for this PDF in order not to be misled by poorly-fitted muon tracks. 

The final likelihood cut used for the solar analysis removed 90\% of spallation events with a position-averaged 20\% deadtime. This deadtime was measured with the random sample as a function of position. In the next section, we will show how the SK-IV new electronics, the new techniques described in this paper, and better muon reconstruction algorithms allow to further reduce this deadtime for the upcoming analysis.
\begin{table*}[t]
    \centering
    \small
    \begin{adjustbox}{width=\linewidth,center}
    \addtolength{\tabcolsep}{-2pt}
    \setlength{\tabcolsep}{2mm}{
    \begin{tabular}{ lcccccccl }
    \toprule 
     & TNEWS
     & IFLYTEK
     & CLUEWSC
     & AFQMC
     & CSL
     & OCNLI
     & C3
     & AVG
     \\
     \hline  
    % BERT-Chinese & 64.10 & 57.77 & 62.39 & 68.95 & 82.60 & 68.46 & 53.51 \\
    Sub-word                & 64.09 & 54.88 & 62.67 & 69.25 & 83.20 & 69.03 & 53.32 & 65.21 \\
    Sub-word + \cws{}       & 64.26 & 54.15 & 63.05 & 69.62 & 82.87 & 68.64 & 51.77 & 64.91 (-0.30) \\
    SubChar-Wubi            & 63.89 & 58.64 & 64.61 & 68.75 & 82.81 & 68.93 & 54.68 & 66.04 \\
    SubChar-Wubi + \cws{}   & 63.57 & 58.01 & 64.38 & 69.41 & 82.62 & 69.43 & 53.15 & 65.80 (-0.24) \\
    SubChar-Pinyin          & 63.68 & 58.81 & 65.90 & 68.89 & 82.87 & 67.98 & 53.03 & 65.88 \\
    SubChar-Pinyin + \cws{} & 63.73 & 57.89 & 64.51 & 69.66 & 82.90 & 69.93 & 53.63 & 66.04 (+0.16) \\
    \bottomrule
    \end{tabular}}
    \end{adjustbox}
    \caption{Results of models trained with different tokenizers. Numbers in brackets indicate the difference between adding and not adding the \cws{} step in tokenization. Adding \cws{} brings \textbf{no} significant improvement in performance.}
    \label{tab:cws_results}
    \end{table*}
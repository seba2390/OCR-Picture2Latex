This work is supported by the National Key Research and Development Program of China (No. 2020AAA0106500) and the National Natural Science Foundation of China (NSFC No. 62236004).

We thank Xu Han, Yusheng Su, Tianyu Gao and other members of THUNLP for their helpful discussion in the early stages of this work. We thank Jordan Boyd-Graber, Chen Zhao, Shi Feng, Neha Srikanth, Tonia Bleam, Leslie Li, and other members of UMD CLIP and Language Science Center for their helpful discussion and feedback. We also thank Nelson Liu and Canwen Xu for their constructive feedback on our early drafts. 
We especially appreciate the constructive reviews from TACL reviewers and action editors. 

This work is supported by the National Key Research and Development Program of China (No. 2020AAA0106500) and the National Natural Science Foundation of China (NSFC No. 62236004).

We thank Xu Han, Yusheng Su, Tianyu Gao and other members of THUNLP for their helpful discussion in the early stages of this work. We thank Jordan Boyd-Graber, Chen Zhao, Shi Feng, Neha Srikanth, Tonia Bleam, Leslie Li, and other members of UMD CLIP and Language Science Center for their helpful discussion and feedback. We also thank Nelson Liu and Canwen Xu for their constructive feedback on our early drafts. 
We especially appreciate the constructive reviews from TACL reviewers and action editors. 

\paragraph{Author contributions} Chenglei Si, Zhengyan Zhang, and Yingfa Chen wrote the code and conducted the experiments. Chenglei was in charge of tokenzer training and pretraining experiments, Zhengyan did the CWS experiments, Yingfa did the finetuning experiments. All three of them contributed to the analysis experiments.
Chenglei Si, Zhengyan Zhang, and Yingfa Chen wrote the initial draft; Fanchao Qi, Xiaozhi Wang, and Zhiyuan Liu significantly edited and improved the paper.
Yasheng Wang, Qun Liu, and Maosong Sun provided valuable advice to the research. Chenglei started this work back when he was visiting the THUNLP group in 2021. 
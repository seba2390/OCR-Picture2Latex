
\section{Conclusions}
This paper introduces the Elo-MMR rating system, which is in part a generalization of the two-player Glicko system, allowing an unbounded number of players. By developing a Bayesian model and taking the limit as the number of participants goes to infinity, we obtained simple, human-interpretable rating update formulas. Furthermore, we saw that the algorithm is asymptotically fast, embarrassingly parallel, robust to extreme performances, and satisfies the important \emph{aligned incentives} property. To our knowledge, our system is the first to rigorously prove all these properties in a setting with more than two individually ranked players. In terms of practical performance, we saw that it outperforms existing industry systems in both prediction accuracy and computation speed.
%In particular, we compare against the popular CodeForces, TopCoder, and TrueSkill rating systems, which are deployed on platforms with hundreds of thousands to millions of users.

This work can be extended in several directions. First, the choices we made in modeling ties, pseudodiffusions, and opponent subsampling are by no means the only possibilities consistent with our Bayesian model of skills and performances. Second, one may obtain better results by fitting the performance and skill evolution models to application-specific data.

Another useful extension would be to team competitions. While it's no longer straightforward to infer precise estimates of an individual's performance, Elo-MM$\chi$ can simply be applied at the team level. To make this useful in settings where players may form new teams in each round, we must model teams in terms of their individual members. In the case where a team's performance is modeled as the sum of its members' independent Gaussian contributions, elementary facts about multivariate Gaussian distributions enable posterior skill inferences at the individual level. Generalizing this approach remains an open challenge.

% Probably redundant: The algorithm itself is trivially parallelizable, and further speedup can be attained through a simple sub-sampling strategy. We believe there is potential to improve the performance even more, either through a more sophisticated sub-sampling strategy, interpolation, or by combining our two-phase approach with a factor graph framework similar to that of TrueSkill~\cite{HMG06, KFL01}. 

Over the past decade, online competition communities such as Codeforces have grown exponentially. As such, considerable work has gone into engineering scalable and reliable rating systems. Unfortunately, many of these systems have not been rigorously analyzed in the academic community. We hope that our paper and open-source release will open new explorations in this area.

%In addition, we invite non-technical sporting communities, such as the Spartan Race and DanceSport, to find uses of our skill estimation package.
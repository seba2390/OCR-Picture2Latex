\section{Conclusion}

In this paper, inspired by glyphs of Chinese characters could enhancing the representation of Chinese characters, we propose the Chinese pre-trained representation model named as GlyphCRM, based entirely on glyphs. To verify its effectiveness, we conduct extensive experiments on a wide range of Chinese NLU tasks. The surprising performance of GlyphCRM is that it outperforms previous state-of-the-art model BERT in 9 Chinese NLU tasks. The pre-training process and the fine-tuning results indicate that our model has stronger learning ability, transferability and generalization compared to BERT. It is worth mentioning that a larger pre-trained Chinese representation model GlyphCRM is coming\footnote{We will open the codes and pre-trained checkpoints soon.}.
\section{Experiment}
In this section, we first introduce the detailed experimental settings and the pre-training performance of our model. Secondly, we in-detail analyze the performance of GlyphCRM on 9 Chinese natural language understanding~(NLU) datasets.   

\begin{figure}[t]
    \centering
    \includegraphics[width=0.43\textwidth, height=0.30\textwidth]{loss.pdf}
    \caption{The pre-training loss curves of BERT and GlyphCRM in the first 6 epochs. Each point in the curve represents the average loss of current epoch. Epoch '0' represents the starting point of training. }
    \label{fig:loss}
\end{figure}
%Compared with BERT, the loss of our model drops significantly faster.

\subsection{Experimental settings}

\subsubsection{Model Architecture} The architecture of GlyphCRM and the baseline model BERT-Base we adopt both have 12 Transformer blocks. Each layer of them has 12 attention heads, and the size of hidden states is $768$. The total parameters of BERT-Base are \textbf{110} million, yet GlyphCRM only has \textbf{95} million parameters. In the case of the same number of Transformer blocks, the proposed model has fewer parameters. We separately pre-train BERT and GlyphCRM for $\textbf{15}$ and $\textbf{6}$ epochs\footnote{ Due to the limited computational resources and from the downward trend of the loss curve of GlyphCRM, we adopt it with being pre-trained 6 epochs for fine-tuning.} on the same processed $\textbf{3}$ million pre-trained Chinese corpora. From the downward trend of the two pre-training losses shown in Figure \ref{fig:loss}, we can observe that the representation model based entirely on glyphs of Chinese characters has a stronger learning ability than BERT. 



\subsubsection{Datasets for Evaluation} We first compare GlyphCRM and BERT on the following Chinese NLU datasets. 

\noindent\textbf{ChnSentiCorp:} ChnSentiCorp~\cite{chnSentiCorp} is the Chinese sentiment analysis dataset, including three-domain documents: education, movie, and house. Each domain contains two classification labels: positive and negative. We divide the data in each domain into training, validation, and test sets at the ratio of 0.8:0.1:0.1.

\noindent\textbf{Hotel Review Sentiment Analysis:} Hotel Review Sentiment An-alysis dataset\footnote{https://pan.baidu.com/s/1Y4vPSSH4ukPfO4ONUg2lSg} is collected from the Ctrip website, including 10k texts and two positive and negative classification labels. It is an unbalanced sentiment classification dataset, having 7k positive samples. We divide the data of each label into training, validation, and test sets at the ratio of 0.8:0.1:0.1. 

\noindent\textbf{Chinese Natural Language Inference:} The Chinese Natural Language Inference~(CNLI) is from the public evaluation tasks of the Seventeenth China National Conference on Computational Linguistics\footnote{http://www.cips-cl.org/static/CCL2018/call-evaluation.html} (CCL2018). We split the whole dataset into $90,000$, $10,000$, $10,000$ as the train, validation and test set. Each example contains two sentences, where the relationship between them is entailment, contradiction, or neural.

\noindent\textbf{THUCNews:} THUCNews~\cite{thunews} is a long document classification dataset. After processing the long document dataset, we retain 65k documents. We randomly select 10k samples as the test set, 5k samples as the validation set, and 50k samples as the training set. 

\noindent\textbf{TouTiaoCNews:} TouTiaoCNews~\footnote{https://github.com/aceimnorstuvwxz/toutiao-text-classfication-dataset} is the short news text classification dataset. It contains $382,688$ examples, and all documents are divided into 15 categories according to their content. We randomly divide the total data with a ratio of 0.8:0.1:0.1, separately as the train, validation, and test set. 

\noindent\textbf{MSRA-NER:} MSRA-NER~\cite{msra, nermsra} dataset is the sequence labeling task proposed by Microsoft Research Asia in 2006. It contains 7 tagging labels: O, B-PER, I-PER, B-ORG, I-ORG, B-LOC, and I-LOC. Hence, it can be regarded as the 7 classification task.

\noindent\textbf{People-NER:} The data of People-NER comes from the article of the People's Daily in 2014~\footnote{https://pan.baidu.com/s/1LDwQjoj7qc-HT9qwhJ3rcA}. It contains approximately 28k data, and has the same 7 tagging labels as MSRA-NER. We split it into train, validation, and test set, separately with $20,864$, $2,318$, and $4,636$ samples.

\noindent\textbf{Unknown character Statistics: } We count the distribution of unknown characters in the above 7 datasets according to the vocab of BERT. As the results shown in Table~\ref{tab:exp5}, despite the vocab of BERT has $21,128$ tokens, there are still many unknown characters in the long Chinese texts. Even for fine-grained classification tasks such as MSRA-NER and People-NER, there are usually many unknown characters in the dataset, so it is meaningful and valuable to solve the out-of-vocabulary problem. 


\begin{table}[t]
\renewcommand\arraystretch{1.1}
\small
\centering
 \caption{The detailed statistics of unknown characters (chars) in different datasets.}
\label{tab:exp5}
\begin{tabular}{lccc}
\toprule[0.9pt]
\multicolumn{1}{c}{\textbf{Dataset}} &  \multicolumn{1}{c}{\textbf{Unknown Chars}} & \multicolumn{1}{c}{\textbf{Total Chars}} &
\multicolumn{1}{c}{\textbf{Ratio~(\%)}}\\\midrule[0.7pt]
\multicolumn{4}{c}{\textbf{Validation}} \\\hline
\# ChnSentidev & $798$ & $123,568$ & $0.65$\\
\# CNLI & $722$ & $288,534$ & $0.25$\\
\# HRSA & $358$ & $123,690$ & $0.29$\\
\# THUCNews & $34,604$ & $2,004,771$ & $1.72$\\
\# TouTiaoCNews & $26,750$ & $1,384,652$ & $\textbf{1.93}$\\
\# MSRA-NER & $1,508$ & $142,095$ & $1.06$\\
\# People-NER & $1,061$ & $107,894$ & $0.98$\\
\midrule[0.7pt]
\multicolumn{4}{c}{\textbf{Test}} \\\hline
\# ChnSentidev & $790$ & $120,412$ & $0.66$\\
\# CNLI & $754$ & $285,167$ & $0.26$\\
\# HRSA & $322$ & $118,694$ & $0.27$\\
\# THUCNews & $69,686$ & $4,247,903$ & $1.64$\\
\# TouTiaoCNews & $26,805$ & $1,380,889$ & $\textbf{1.94}$\\
\# MSRA-NER & $1,468$ & $169,751$ & $0.86$\\
\# People-NER & $2,137$ & $215,530$ & $0.99$\\
\bottomrule[0.9pt]
\end{tabular}
\end{table}

\subsubsection{Experimental Details} We use 2 Tesla V100 GPUs to pre-train BERT and GlyphCRM on the processed 3 million Chinese texts with Adam~\cite{kingma2014method} optimizer with the initial learning rate to 0.0001, $\beta_{1} = 0.9$, $\beta_{2} = 0.999$.
The pre-training Chinese texts comes from the Chinese Wikipedia\footnote{https://dumps.wikimedia.org/zhwiki/}, and the preprocessing way is identical to BERT.
We set the weight decay to 0.01 and set the linear decay of learning rate, and the learning rate warmup over the first 10k steps.
We set the batch size and maximum input length to 256 and 512. The pre-training loss is the sum of the mean Masked LM likelihood and the mean NSP likelihood. Furthermore, we fine-tune GlyphCRM and BERT on the specific tasks with the same hyperparameter settings.
We set up different learning rates for different tasks, which are presented in the following experiment analyses. 

\subsection{Results and Analysis}
In this section, we will represent the comparison results between the previous state-of-the-art pre-trained model BERT and our designed model GlyphCRM. Note that we use the validation set to select the model with the best performance.

%each task is run \textbf{three} times to obtain the average evaluation result of validation and test sets as the final experiment result, which ensures the experiment result precise.

\subsubsection{Single Sentence Classification} ChnSentiCorp and Hotel Review Sentiment Analysis are coarse-grained sentiment classification datasets, where models are trained to perform sentence-level binary classification task. The evaluation metrics for all datasets are the prediction accuracy. For classification, we enable the last hidden state of $\rm[CLS]$ pass a fully connected linear layer followed by a softmax activation function to classify the input sentence. The experimental results are shown in Table~\ref{tab:exp1}.

%From the perspective of the task, the input text of them is one sentence and the target of prediction is two label.

The above experimental results show that whether it is from the validation set or the test set, the classification accuracy of our model significantly exceeds BERT on the two sentiment classification dataset, especially on the test set. For instance, $93.08~\rm{vs}~91.25$ on the test set of ChnSentiCorp and  $92.70~\rm{vs}~91.40$ for Hotel Review Sentiment Analysis. It demonstrates that GlyphCRM has a stronger ability to understand the semantics of whole sentences compared to BERT. Moreover, the experimental results in Table~\ref{tab:exp1} and loss curves in Figure~\ref{fig:loss} indicate that our model can learn the contextual information of the overall sentence better and faster. It may be attributed to the fact that the glyph features extracted by the HanGlyph module can sufficiently express the structure of Chinese characters, which has the easily distinguishable features.
In addition, GlyphCRM could distinguish the contextual semantics of positive and negative words according to the glyph features of them.  
Overall, the above analyses and the experimental results of comparison models further indicate that glyph features of Chinese characters are practical when used in the sentiment analysis task. 


%In addition, there is a big gap between positive words and negative words in the shape of Chinese characters, which GlyphCRM could easily distinguish. For instance, from the structure of the positive word '喜欢'~(like) and the negative word '憎恨'~(hate), we can observe that they have obviously different shapes. Overall, the above analyses and the experimental results of comparison models further indicate that glyph features of Chinese characters are practical when used in the sentiment analysis task.   

%the glyphs of Chinese characters, designed by humans, can contain a certain sentimental semantic and Chinese people usually use the visualization of Chinese characters to express their implied affective tendencies, e.g., the positive word '竹叶青'~(Zhuyeqing) can implicitly express the integrity, elegance, and handsomeness of bamboo, often used as a metaphor for a person's characteristics.

\begin{table}[t]
\renewcommand\arraystretch{1.1}
    \centering
     \caption{Automatic evaluation results on the validation and test sets of ChnSentiCorp and Hotel Review Sentiment Analysis. The leftmost column represents the model and their pre-training degree. LR represents the learning rate of a specific task~(Unless otherwise stated, the instruction LR in the following table are the same). $15e$ and $6e$ separately represent the pre-training epochs of BERT and GlyphCRM.}
    \label{tab:exp1}
    \begin{tabular}{lccc}
    \toprule[0.9pt]
    \multicolumn{1}{c}{\textbf{Model}} & \multicolumn{1}{c}{\textbf{LR}} & \multicolumn{1}{c}{\textbf{Dev ACC(\%)}} & \multicolumn{1}{c}{\textbf{Test ACC(\%)}} \\
    \midrule[0.7pt]
    \multicolumn{4}{c}{\textbf{ChnSentiCorp}}\\ \hline
    \# BERT$_{15e}$ & $2e-5$ & $92.66$ & $91.25$ \\
    \# GlyphCRMT$_{6e}$ & $2e-5$ & $\textbf{93.17}$ & $\textbf{93.08}$\\\midrule[0.7pt]
    \multicolumn{4}{c}{\textbf{Hotel Review Sentiment Analysis}}\\ \hline
    \# BERT$_{15e}$ & $2e-5$ & $92.88$ & $91.40$ \\
    \# GlyphCRM$_{6e}$ & $2e-5$ & $\textbf{93.80}$ & $\textbf{92.70}$\\
    \bottomrule[0.9pt]
    \end{tabular}
\end{table}

% a fully connected linear layer followed by a softmax activation function.

\subsubsection{Chinese Text Classification} After evaluating the performan-ce of models on the single sentence classification task, we tested them on two multi-sentence document classification datasets THU-CNews and TouTiaoCNews to evaluate their ability to understand Chinese long documents. Formally, we still take a fully connected linear layer followed by a softmax activation function to map the classification labels. The experimental results on validation and test sets are shown in Table~\ref{tab:exp2}. From the experimental results, we observe that the performance of GlyphCRM is still better than BERT, yet the gap between two models is smaller compared to being evaluated on the single sentence classification task. Specifically, the performance of our model separately exceeds BERT by about $0.5\%$ and $0.75\%$ on the validation and test sets, yet GlyphCRM outperforms BERT by about $1.5\%$ gains on two test sets as shown in Table~\ref{tab:exp1}. 
It indicates that the performance of our model based entirely on glyphs is comparable to and even surpasses BERT when dealing with long Chinese documents. Furthermore, whether from short text (at least one sentence) or long text, the pre-trained representation model based entirely on Chinese glyphs is simple and effective for Chinese multi-label classification tasks. 

%In practical applications, text classification is mainly used for information archiving and filtering, including news document classification and spam processing.

\begin{table}[t]
\renewcommand\arraystretch{1.1}
    \centering
     \caption{Automatic evaluation results on the validation and test sets of THUCNews and TouTiaoCNews. }
    \label{tab:exp2}
    \begin{tabular}{lccc}
    %\hline
    \toprule[0.9pt]
    \multicolumn{1}{c}{\textbf{Model}} & \multicolumn{1}{c}{\textbf{LR}} & \multicolumn{1}{c}{\textbf{Dev ACC(\%)}} & \multicolumn{1}{c}{\textbf{Test ACC(\%)}} \\\midrule[0.7pt]
    %\hline
    \multicolumn{4}{c}{\textbf{THUCNews}}\\ \hline
    \# BERT$_{15e}$ & $3e-5$ & $96.28$ & $95.41$ \\
    \# GlyphCRM$_{6e}$ & $3e-5$ & $\textbf{96.60}$ & $\textbf{96.32}$\\ \midrule[0.7pt]
    \multicolumn{4}{c}{\textbf{TouTiaoCNews}}\\ \hline
    \# BERT$_{15e}$ & $3e-5$ & $88.85$ & $88.84$ \\
    \# GlyphCRM$_{6e}$ & $3e-5$ & $\textbf{89.60}$ & $\textbf{89.45}$\\ \bottomrule[0.9pt]
    \end{tabular}
\end{table}


\subsubsection{Chinese Natural Language Inference} Natural language inference is mainly to determine whether there is an inference implication relationship between two sentences. It further investigates the model's ability to understand sentence semantics and has high transferability in real-word applications. We select a classic Chinese language inference evaluation dataset presented in CCL2018. We conduct the experiment with an initial learning rate $3e-5$, and the experimental results are shown in Table \ref{tab:exp3}.
\begin{table}[H]
\renewcommand\arraystretch{1.1}
    \centering
     \caption{Automatic evaluation results on the validation and test sets of Chinese natural language inference~(CNLI).}
    \label{tab:exp3}
    \begin{tabular}{lccc}
    \toprule[0.9pt]
    \multicolumn{1}{c}{\textbf{Model}} & \multicolumn{1}{c}{\textbf{LR}} & \multicolumn{1}{c}{\textbf{Dev ACC(\%)}} & \multicolumn{1}{c}{\textbf{Test ACC(\%)}} \\\midrule[0.7pt]
    \# BERT$_{15e}$ & $3e-5$ & $71.04$ & $69.74$ \\
    \# GlyphCRM$_{6e}$ & $3e-5$ & $\textbf{72.28}$ & $\textbf{71.80}$\\
    \bottomrule[0.9pt]
    \end{tabular}
\end{table}
\begin{CJK}{UTF8}{gbsn}
\begin{table}[H]
\renewcommand\arraystretch{1.15}
\small
\centering
\caption{Two instances of the test set of CNLI.}
\label{tab:exp6}
\begin{tabular}{|p{7.5cm}|}
%\toprule[0.9pt]
\hline
\multicolumn{1}{|c|}{\textbf{CNLI (test)}} \\
%\midrule[0.7pt]
\hline
$\bullet$~\textbf{Sentence A:} 一位黑发\textbf{女子}在\textbf{舞台}上用相机拍下了一张\textbf{乐队}的照片。(A black-haired \textbf{woman} took a photo of the \textbf{band} with a camera on the \textbf{stage}.)\\
$\bullet$~\textbf{Sentence B:} 一位\textbf{女士}正在一场\textbf{音乐会}上。(A \textbf{lady} is at a \textbf{concert}.)\\ 
$\bullet$~\textbf{Label:} \textcolor{blue}{Entailment}\\
$\bullet$~\textbf{BERT:} \textcolor{red}{Neural}\\
$\bullet$~\textbf{GlyphCRM:} Entailment\\
%\midrule[0.7pt]
\hline
$\bullet$~\textbf{Sentence A:} 一位有才华的男性艺术家正在外面的\textbf{伞}下\textbf{画漫画}。(A talented male artist is \textbf{drawing a comic} outside under an \textbf{umbrella}.)\\
$\bullet$~\textbf{Sentence B:} 这位艺术家在\textbf{购物中心}内的\textbf{售货亭}\textbf{工作}。(This artist works at the \textbf{kiosk} in the \textbf{shopping center}.)\\ 
$\bullet$~\textbf{Label:} \textcolor{orange}{Contradiction}\\
$\bullet$~\textbf{BERT:} \textcolor{red}{Neural}\\
$\bullet$~\textbf{GlyphCRM:} Contradiction\\
%\bottomrule[0.9pt]
\hline
\end{tabular}
\end{table}
\end{CJK}
Table~\ref{tab:exp3} shows that our model separately surpasses the benchmark model BERT by about 1.2\%, 2\% on the validation and test set, demonstrating that full glyphs of Chinese characters are expressive enough to be used for their representations.
The excellent performance may be attributed to two facts: 1) GlyphCRM can further capture sentence-level semantic according to the glyph features of consecutive Chinese characters. 2) Compared to directly converting the character into a vector, each Chinese character representation incorporating its glyph is more distinguishable in the semantic space.

%the pre-trained framework that combines convolutional neural network and Transformer has significantly enhanced the semantic comprehension ability for Chinese text, compared with the purely Transformer-based approach.
\begin{CJK}{UTF8}{gbsn}
Moreover, we select two examples from the test set to verify the performance of models, presented in Table~\ref{tab:exp6}. For the first instance, we observe that the first sentence can deduce the second sentence according to the keywords of the first sentence: '女子'~(women), '舞台'(stage), '乐队'~(band) and keywords of the second sentence: '女士'~(lady), '音乐会'~(concert). For the second instance, the semantics of keywords in the sentence B such as '购物中心'~(shopping center), '售货亭'~(kiosk) and '工作'~(working), are different from '伞'~(umbrella) and '画漫画'~(drawing comic) in sentence A. Judging from the inference results of models, BERT usually cannot infer the relationship between two sentences in many cases, thus determining that the two sentences are neural. However, our model incorporating glyphs has a great advantage in inferring the semantic relevance between sentences. 
\end{CJK}

%Moreover, we select two examples from the test set to verify our suggestions, presented in Table~\ref{tab:exp6}. Firstly, from the description of the first example, we can precisely determine that the first sentence can deduce the second sentence because this lady is at a concert and take a photo. The keywords of the first sentence: '女子'~(women), '舞台'(stage) and '乐队'~(band), and the keywords of the second sentence: '女士'~(lady) and '音乐会'~(concert) have an apparent similarity in the glyphs. Hence, the semantic similarity of the two sentences can be inferred according to the above keywords with similar glyphs. For the second example, the glyphs and semantics of keywords in the second sentence such as '购物中心'~(shopping center), '售货亭'~(kiosk) and '工作'~(working), are different from '伞'~(umbrella) and '画漫画'~(drawing comic) in the first sentence. We take '购物中心'~(shopping center), '售货亭'~(kiosk) and '画漫画'~(drawing comic) for examples to calculate their semantic similarities. Table~\ref{tab:similar} shows that our model is indeed easier to distinguish the semantics of keywords in different sentences compared with BERT. 

%As mentioned above, a phrase composed of multiple Chinese characters with specific glyphs can express implicit meanings, and our glyph-based approach aims to further capture these meanings.   
%\begin{table}[t]
%\renewcommand\arraystretch{1.1}
%    \footnotesize
%    \centering
%    \caption{Cosine similarities of keywords between two sentences in Table~\ref{tab:exp6}. We take the average of the character-level representation as the keywords' exclusive representation.}
%    \label{tab:similar}
%    \begin{tabular}{|l|c|c|}
%    \hline
%    \multicolumn{1}{|c|}{\diagbox{Sentence A}{Sentence B}} & \multicolumn{1}{|c|}{购物中心 (shopping center)} & \multicolumn{1}{|c|}{售货亭 (kiosk)}\\ \hline
    
%    \multicolumn{3}{|c|}{\textbf{BERT}$_{15e}$}\\\hline
%    画漫画 (drawing comic) & $0.9975$ & $0.9985$\\\hline
%    \multicolumn{3}{|c|}{\textbf{GlyphCRM}$_{6e}$}\\\hline
%    画漫画 (drawing comic) & $\mathbf{0.9371}$ & $\mathbf{0.9446}$\\\hline
%    \end{tabular}
%\end{table}

\begin{table}[t]
\renewcommand\arraystretch{1.1}
    \centering
     \caption{Automatic evaluation results on the validation and test sets of Chinese named entity recognition tasks, including MSRA-NER and People-NER. F1, P, and R represent F1-score, Precision, and Recall.}
    \label{tab:exp4}
    \begin{tabular}{lcccc}
    \toprule[0.9pt]
    \multicolumn{1}{c}{\textbf{Model}} & \multicolumn{1}{c}{\textbf{LR}} & \multicolumn{1}{c}{\textbf{F1(\%)}} & \multicolumn{1}{c}{\textbf{P(\%)}}&
    \multicolumn{1}{c}{\textbf{R(\%)}}\\\midrule[0.7pt]
    \multicolumn{5}{c}{\textbf{MSRA-NER~(validation)}}\\\hline
    \# BERT$_{15e}$ & $3e-5$ & $83.55$ & $81.69$& $85.48$\\
    \# GlyphCRM$_{6e}$ & $3e-5$ & $\textbf{90.15}$ & $\textbf{89.32}$& $\textbf{91.00}$\\\midrule[0.7pt]
    \multicolumn{5}{c}{\textbf{MSRA-NER~(test)}}\\ \hline
    \# BERT$_{15e}$ & $3e-5$ & $77.78$ & $75.84$ &$79.81$\\
    \# GlyphCRM$_{6e}$ & $3e-5$ & $\textbf{86.04}$ & $\textbf{85.53}$ &$\textbf{86.57}$\\ \midrule[0.7pt]
    \multicolumn{5}{c}{\textbf{People-NER~(validation)}}\\\hline
    \# BERT$_{15e}$ & $3e-5$ & $80.40$ & $78.61$& $82.27$\\
    \# GlyphCRM$_{6e}$ & $3e-5$ & $\textbf{85.62}$ & $\textbf{85.34}$& $\textbf{85.90}$\\\midrule[0.7pt]
    \multicolumn{5}{c}{\textbf{People-NER~(test)}}\\\hline
    \# BERT$_{15e}$ & $3e-5$ & $79.20$ & $76.91$& $81.64$\\
    \# GlyphCRM$_{6e}$ & $3e-5$ & $\textbf{84.05}$ & $\textbf{82.80}$& $\textbf{85.35}$\\
    \bottomrule[0.9pt]
    \end{tabular}
\end{table}

\subsubsection{Sequence Labeling} Compared to text classification tasks that focus on the overall understanding of input content, sequence labeling, e.g., word segmentation, part-of-speech tagging, named entity recognition, and relationship extraction, is more fine-grained classification tasks. It can be used to evaluate the ability of Chinese pre-trained representation models to represent Chinese characters, which is directly related to the fine-grained classification accuracy. Different from previous methods of adding CRF~\cite{laffertyCrf} network based on the pre-trained representation model, we just add a fully connected layer to the final output hidden states of models. So the whole architecture mainly relies on representation models. Notably, the final fully connected layer is exactly identical for GlyphCRM and BERT in order to compare them fairly. The performance of the whole network can directly evaluate the ability of the Chinese pre-trained representation model to express Chinese characters.
\begin{CJK}{UTF8}{gbsn}
\begin{table}[t]
\renewcommand\arraystretch{1.15}
\small
\centering
\caption{Two typical recognition instances of MSRA-NER and People-NER. 'O' represents that the character has no specific label as a category. 'B-LOC' and 'I-LOC' separately represent the start and inside of location words. Red-colored words are the error predictions. PER represents the name of Chinese people.}
%'PER' represents the label of person names.
\label{tab:exp7}
\begin{tabular}{|p{7.5cm}|}
%\toprule[0.9pt]
\hline
\multicolumn{1}{|c|}{\textbf{MSRA-NER~(test)}} \\
%\midrule[0.7pt]
\hline
$\bullet$~\textbf{Sentence}\\
这 是 一 座 典 型 的 加 泰 罗 尼 亚 民 居 ， 房 屋 的 建 筑 和 装 饰 风 格 与 周 围 民 居 没 有 什 么 区 别 。(This is a typical \textbf{Catalan house}, and the building and decoration style of the house is not different from the surrounding houses.)\\
$\bullet$~\textbf{True Label}\\
加 泰 罗 尼 亚：B-LOC I-LOC I-LOC I-LOC I-LOC\\ 
Others: O\\
$\bullet$~\textbf{BERT}\\
加 泰 罗 尼 亚 民 居: B-LOC I-ORG I-ORG I-ORG I-ORG \textcolor{red}{I-ORG I-ORG} \\
Others: O\\
$\bullet$~\textbf{GlyphCRM}\\
加 泰 罗 尼 亚：B-LOC I-LOC I-LOC I-LOC I-LOC\\ 
Others: O\\
%\midrule[0.7pt]
\hline
%\end{tabular}
%\end{table}
\multicolumn{1}{|c|}{\textbf{People-NER~(test)}} \\
\hline
$\bullet$~\textbf{Sentence} \\
崔 剑 平 连 衣 服 也 没 顾 得 脱 ， 便 飞 身 跃 入 水 中 ， 奋 力 向 溺 水 者 游 去 。(\textbf{Cui, Jianping} didn't even take off his clothes, so he flew into the water and swam to the drowning person.)\\
$\bullet$~\textbf{True Label} \\
崔 剑 平: B-PER I-PER I-PER\\
Others: O\\
$\bullet$~\textbf{BERT}\\
崔 剑 平: B-PER I-PER \textcolor{red}{O}\\
Others: O\\
$\bullet$~\textbf{GlyphCRM}\\
崔 剑 平: B-PER I-PER I-PER\\
Others: O\\
%\bottomrule[0.9pt]
\hline
\end{tabular}
\end{table}
\end{CJK}
We adopt the frequently used Chinese NER datasets MSRA-NER and People-NER to evaluate the fine-grained representation capability of GlyphCRM and BERT. The experimental results are shown in Table~\ref{tab:exp4}. Firstly, compared to the experimental results on Chinese text classification tasks, the performance of GlyphCRM and BERT has a greater gap in NER, e.g., F1-score: $90.15$ $\rm{vs}~83.55$ on MSRA validation, $86.04~\rm{vs}~77.78$ on MSRA test. Precision: $85.53$ $\rm{vs}$~$75.84$ on MSRA test, $82.80~\rm{vs}~76.91$ on People-NER test. Recall: $91.00~\rm{vs}~85.48$ on MSRA test, $85.35~\rm{vs}~81.64$ on People-NER test. It indicates that our model has a strong ability to understand the overall semantics of Chinese texts and excellent representation for the fine-grained (a single Chinese character) character semantics. Secondly, Table~\ref{tab:exp4} shows that the performance of our model is significantly higher than BERT in Precision and Recall, and the performance on the two indicators is not much different. It indicates that GlyphCRM has high overall recognition accuracy on sequence labeling tasks.

\begin{CJK}{UTF8}{gbsn}
Specifically, we select two typical examples from the test sets, presented in Table~\ref{tab:exp7}. 
BERT usually has inferior accuracy when predicting the ending position of location phrases. Yet, the glyph-based method can alleviate this problem by effectively learning the difference between phrases, e.g., the meaning conveyed by '民居'~(residence) and '加泰罗尼亚'~(Catalonia) and glyphs of them are different. The proposed model can predict it accurately yet BERT
give the wrong labels. 
Hence, the inferior performance of BERT on the People-NER containing many Chinese names is probably caused by inaccurately predicting Chinese names of triples or doubles as the second instance shown in Table \ref{tab:exp7}. Overall, GlyphCRM can learn the characteristics of Chinese phrases well according to the patterns of consecutive characters' glyphs on specific fine-tuning tasks.
\end{CJK}
\section{Transferability Assessment on Specialized Fields and Low-resource Tasks}

\textbf{Medical Field:} The transferability evaluation of pre-trained models has been attracting attention of many researchers because the high transferability means that models can adapt to a wide range of application scenarios. In this section, we first evaluate the two pre-trained models on the Chinese sentence semantic matching dataset in the medical field~(CMSSM), related to COVID-19. It is provided by More Health technology company\footnote{https://tianchi.aliyun.com/dataset/dataDetail?dataId=76751}. CMSSM is a fine-grained semantic matching task that mainly involves 10 diseases such as pneumonia, mycoplasma pneumonia, bronchitis, and so on. The length of each sentence is less than 20 words. Its training, validation and test set include $8,747$, $2,002$ and $7,032$ samples, respectively. 
%We use the validation set to help select the model with the best performance. fine-tune the two models with an initial learning rate $3e-5$ and 

\begin{CJK}{UTF8}{gbsn}
Table~\ref{tab:exp8} shows that the performance of GlyphCRM exceeds BERT by about 1\% both on the validation and test sets. It indicates that the performance of the Chinese pre-trained representation method based entirely on glyphs is excellent in the medical field. Generally speaking, the model pre-trained on large-scale open-domain corpora always performs poorly when fine-tuned in the specialized field~\cite{dont_stop_pretrain} due to exiting many professional terms. However, our pre-trained model can enlighten us to improve the model's transferability on specialized fields by introducing glyph vectors. After the retrospective analyses of CMSSM and the above 7 tasks, we observe that Chinese professional terms are usually composed of multiple Chinese pictographic characters, and their glyphs usually have certain links with the things to be described. For instance, '肺炎'~(Pneumonia) is usually caused by lung infections, and its symptom is fever. The glyph of '肺'~(lungs) is similar to the human organ lung, and '炎'~(scorching) is composed of two same radical '火'~(fire), which conveys a hot scene. The combination of multiple Chinese characters' glyphs can convey the characteristics of some objects. It is highly consistent with the Pictographic Theory of Chinese characters~\cite{chinese_word} and indicates that only using the glyph features of Chinese characters to represent them has the potential research value. 
\end{CJK}

\begin{table}[t]
\renewcommand\arraystretch{1.1}
    \centering
     \caption{Automatic evaluation results on the validation and test sets of CMSM.}
    \label{tab:exp8}
    \begin{tabular}{lccc}
    \toprule[0.9pt]
    \multicolumn{1}{c}{\textbf{Model}} & \multicolumn{1}{c}{\textbf{LR}} & \multicolumn{1}{c}{\textbf{Dev ACC(\%)}} & \multicolumn{1}{c}{\textbf{Test ACC(\%)}} \\\midrule[0.7pt]
    \# BERT$_{15e}$ & $3e-5$ & $89.41$ & $89.79$ \\
    \# GlyphCRM$_{6e}$ & $3e-5$ & $\textbf{90.71}$ & $\textbf{90.84}$\\
    \bottomrule[0.9pt]
    \end{tabular}
\end{table}

\begin{table}[t]
\renewcommand\arraystretch{1.1}
    \centering
     \caption{Automatic evaluation results on the validation and test sets of low-resource E-commerce Product Review Dataset for Sentiment Analysis task.}
    \label{tab:exp9}
    \begin{tabular}{lccc}
    \toprule[0.9pt]
    \multicolumn{1}{c}{\textbf{Model}} & \multicolumn{1}{c}{\textbf{LR}} & \multicolumn{1}{c}{\textbf{Dev ACC(\%)}} & \multicolumn{1}{c}{\textbf{Test ACC(\%)}} \\\midrule[0.7pt]
    \# BERT$_{15e}$ & $3e-5$ & $79.35$ & $73.61$ \\
    \# GlyphCRM$_{6e}$ & $3e-5$ & $\textbf{81.25}$ & $\textbf{76.07}$\\
    \bottomrule[0.9pt]
    \end{tabular}
\end{table}

\noindent\textbf{Few-shot Learning:} To evaluate the performance of pre-trained models on the low-resource task, we select a few-sample dataset E-commerce Product Review Dataset for Sentiment Analysis\cite{FewCLUE}. Its training, validation, and test set only contain 160, 160, and 610 samples, respectively. The experimental results of Table~\ref{tab:exp9} show that the performance of GlyphCRM outperforms BERT by about 2\% gains in accuracy both on the validation and test sets. It indicates that the generalization and transferability of our model is remarkable, especially on the low-resource task. 

To summarize, GlyphCRM can quickly adapt to various Chinese natural language understanding tasks and achieve promising performances. It is mainly attributed to the glyphs of Chinese characters conveying vivid and significant meanings. Meanwhile, the pre-trained model we design makes full use of the glyph features of Chinese characters and their contextual information. What is important is that our proposed approach can solve the out-of-vocabulary problem, which can be reflected by the improvement on some tests and high transferability on medical fields.












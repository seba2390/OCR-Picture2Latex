\documentclass[conference]{IEEEtran}

\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{bm}
\usepackage{amsmath}
\pgfplotsset{compat=1.16}

\DeclareMathOperator{\PM}{PM}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator*{\atanh}{atanh}

\begin{document}

\bstctlcite{IEEEexample:BSTcontrol}

\title{Successive Syndrome-Check Decoding of\\Polar Codes}

\author{
\IEEEauthorblockN{Seyyed Ali Hashemi\IEEEauthorrefmark{1}, Marco Mondelli\IEEEauthorrefmark{2}, John Cioffi\IEEEauthorrefmark{3}, Andrea Goldsmith\IEEEauthorrefmark{4}}

\IEEEauthorblockA{\IEEEauthorrefmark{1}Qualcomm, USA}
\IEEEauthorblockA{\IEEEauthorrefmark{2}Institute of Science and Technology, Austria}
\IEEEauthorblockA{\IEEEauthorrefmark{3}Department of Electrical Engineering, Stanford University, USA}
\IEEEauthorblockA{\IEEEauthorrefmark{4}Department of Electrical and Computer Engineering, Princeton University, USA}
\IEEEauthorblockA{hashemi@qti.qualcomm.com,
marco.mondelli@ist.ac.at,
cioffi@stanford.edu,
goldsmith@princeton.edu}
}
% make the title area
\maketitle

\begin{abstract}
A two-part successive syndrome-check decoding of polar codes is proposed with the first part successively refining the received codeword and the second part checking its syndrome. A new formulation of the successive-cancellation (SC) decoding algorithm is presented that allows for successively refining the received codeword by comparing the log-likelihood ratio value of a frozen bit with its predefined value. The syndrome of the refined received codeword is then checked for possible errors. In case there are no errors, the decoding process is terminated. Otherwise, the decoder continues to refine the received codeword. The proposed method is extended to the case of SC list (SCL) decoding by terminating the decoding process when the syndrome of the best candidate in the list indicates no errors. Simulation results show that the proposed method reduces the time-complexity of SC and SCL decoders and their fast variants, especially at high signal-to-noise ratios.
\end{abstract}

\IEEEpeerreviewmaketitle

\section{Introduction}

Polar codes are a class of coding schemes that can provably achieve the capacity of a binary-input memoryless symmetric channel with low-complexity encoding and decoding algorithms as the code length tends to infinity \cite{arikan2009}.
The successive-cancellation (SC) decoder for a polar code of length $N$, with which polar codes can achieve capacity, has complexity $O(N\log N)$. The SC list (SCL) decoding with list size $L>1$ improves the error rate performance of polar codes at finite block lengths and has complexity $O(LN\log N)$ \cite{tal2015list}. SC and SCL decoding algorithms are serial in nature in the sense that the decoders progress by decoding the bits one by one. Consequently, the latency of SC and SCL decoders is high, which adversely affects their practical implementation.

Several attempts have been made to improve the speed of SC and SCL decoders for polar codes. In particular, the decoding process is represented as message passing on a binary tree where the messages are either soft log-likelihood ratio (LLR) values or hard bit estimations. Since the calculation of soft messages is more costly than hard bit estimations, the decoding latency is modeled as the number of edges in the binary tree that need to be traversed by the underlying decoder to calculate the soft messages. The goal of fast SC and SCL decoders is to prune the decoding tree to reduce the number of edges. This pruning is achieved by the following main methods:
\begin{enumerate}
    \item Identifying specific constituent codes of polar codes that can be decoded efficiently without traversing the decoding tree \cite{BYuan2Bit,sarkis2013increasing,husmann2017reduced,alamdar2011simplified,sarkis2014fast,giard2016multi,hanif2017fast,condo2018generalized,gamage2019low,ercan2017reduced,ercan2019operation,sarkis2016fast,hashemi2016fast,hashemi2017fast,hanif2018fast,mondelli2021sublinear,hashemi2021parallelism};
    \item Checking the syndrome of the constituent codes of polar codes to avoid traversing the decoding tree when the syndrome check is satisfied \cite{yoo2016comml,choi2017comml,kim2018ET};
    \item Adjusting the code to increase the number of specific constituent codes of polar codes \cite{huang2012latency,balatsoukas2014enabling,zhang2015simplified,638mbps,giard2018fast};
    \item Comparing the error probability of constituent codes of polar codes with a threshold to avoid traversing the decoding tree when the error probability is small \cite{li2018low,zheng2020icc}.
\end{enumerate}
The first two methods are lossless in the sense that they do not result in error-correction performance degradation with respect to the conventional SC and SCL decoders, while the other two methods may cause error-correction performance loss.

In this paper, SC decoding is reformulated from a novel perspective that allows for successively refining the codeword that was received from the channel. It is shown that this codeword refinement strategy can only take place when a frozen bit that has a predefined value is decoded. Thus, there is no need to calculate soft messages for information bits. Moreover, the refinement of the received codeword is only necessary for those frozen bits whose LLR values do not match their predefined values. Using the equivalence of soft and hard decoding when there is no error, a successive syndrome-check decoder is presented that significantly speeds up the decoding process, especially when the transmission channel experiences low levels of noise.

\section{Preliminaries}

\subsection{Polar Codes} \label{sec:PC}

Let $K$ denote the number of information bits and $N=2^n$ denote the block length of the code. A polar code is represented by $\mathcal{P}\left(N,K\right)$ that has rate $R = \frac{K}{N}$. The encoded vector $\bm{x} = \{x_0,x_1,\ldots,x_{N-1}\}$ is generated by the multiplication of the input vector $\bm{u} = \{u_0,u_1,\ldots,u_{N-1}\}$ and the generator matrix $\bm{G}^{\otimes n}$, and it is expressed as $\bm{x}=\bm{u}\bm{G}^{\otimes n}$. The generator matrix is constructed by the $n$-th Kronecker power of the matrix $\bm{G}=\left[\begin{smallmatrix}1&0\\1&1\end{smallmatrix}\right]$.

The input vector $\bm{u}$ is divided into two sets: the set of $K$ information bits $\mathcal{I}$, and the set of $N-K$ frozen bits $\mathcal{F}$ whose values are known to the receiver. Without loss of generality, in this paper, all frozen bits are set to zero \cite{arikan2009}. Furthermore, the codeword $\bm{x}$ is modulated with binary phase-shift keying (BPSK) modulation that maps $\left\{0,1\right\}$ to $\left\{+1,-1\right\}$. The modulated signal is then transmitted through an additive white Gaussian noise (AWGN) channel. The received signal is transformed into log-likelihood ratio (LLR) values $\bm{y} = \{y_0,y_1,\ldots,y_{N-1}\}$ that is then processed for decoding. %Fig.~\ref{fig:pc-encoding} shows an example of the encoding on the factor graph of $\mathcal{P}(8,4)$, where $\mathcal{I} = \{u_3,u_5,u_6,u_7\}$ and $\mathcal{F} = \{u_0,u_1,u_2,u_4\}$.

%\begin{figure}
%    \centering
%    \input{figures/pc-enc8f}
%    \caption{Encoding of $\mathcal{P}(8,4)$ with $\mathcal{I} = \{u_3,u_5,u_6,u_7\}$ and $\mathcal{F} = \{u_0,u_1,u_2,u_4\}$.}
%    \label{fig:pc-encoding}
%\end{figure}

\subsection{Successive-Cancellation Decoding}

\begin{figure}
    \centering
    \input{figures/pc-dec8}
    \input{figures/pc-dec1}
    \caption{SC decoding on the factor graph of $\mathcal{P}(8,4)$ with $\mathcal{I} = \{u_3,u_5,u_6,u_7\}$ and $\mathcal{F} = \{u_0,u_1,u_2,u_4\}$ (left), and the building block of the SC decoder (right).}
    \label{fig:decGraph}
\end{figure}

SC decoding can be represented on a factor graph as illustrated in Fig.~\ref{fig:decGraph} for $\mathcal{P}(8,4)$ with $\mathcal{I} = \{u_3,u_5,u_6,u_7\}$ and $\mathcal{F} = \{u_0,u_1,u_2,u_4\}$. The factor graph has $n+1$ levels and each decoding step consists of traversing the factor graph by performing $f$ and $g$ functions on the building block of the SC decoder (see Fig.~\ref{fig:decGraph}) as
\begin{align}
    l_0 = f(y_0,y_1) &= 2 \atanh\left(\tanh\left(\frac{y_0}{2}\right)\tanh\left(\frac{y_1}{2}\right)\right) \\
    &\approx \sgn(y_0y_1)\min(|y_0|,|y_1|) \text{,} \label{eq:fFunction} \\
    \hat{u}_0 &= 0 \text{ if } l_0>0 \text{ or } u_0\in\mathcal{F} \text{ else } 1 \text{,} \label{eq:fu0} \\
    l_1 = g(y_0,y_1,\hat{u}_0) &= y_1 + (-1)^{\hat{u}_0}y_0 \text{,} \label{eq:gFunction} \\
    \hat{u}_1 &= 0 \text{ if } l_1>0 \text{ or } u_1\in\mathcal{F} \text{ else } 1 \text{.} \label{eq:gu1}
\end{align}
Note that after performing the $f$ function, the bit $u_0$ is estimated as $\hat{u}_0$, which is an input to the $g$ function. Finally, when $u_1$ is estimated as $\hat{u}_1$, the \emph{partial sums}, $x_0$ and $x_1$, can be calculated as
\begin{align}
    x_0 &= \hat{u}_0 \oplus \hat{u}_1 \text{,} \label{eq:x0} \\
    x_1 &= \hat{u}_1 \text{.} \label{eq:x1}
\end{align}

SC decoding has strong data dependency in the sense that the decoding of each bit $u_i$ requires the estimation of all the previous bits $\{u_0,u_1,\ldots,u_{i-1}\}$. In a fully-parallel implementation of the SC decoder \cite{arikan2009}, all the $f$ and $g$ functions that can be performed in parallel are grouped together. Thus, the latency is modeled as the number of times the groups of functions in (\ref{eq:fFunction}) and (\ref{eq:gFunction}) are performed to move from one level of the factor graph to another. This is due to the fact that the bit-wise calculations in (\ref{eq:x0}) and (\ref{eq:x1}) are of lower complexity than calculating the LLR values.

SCL decoding \cite{tal2015list} improves the error-correction performance of SC decoding by keeping a list of the most likely candidates at each decoding step. Instead of estimating each information bit as either $0$ or $1$ as in (\ref{eq:fu0}) and (\ref{eq:gu1}), SCL decoding considers both possibilities $0$ and $1$. To avoid an exponential growth in the number of candidates, SCL decoding keeps the $L$ most likely ones based on calculating a path metric. The latency of SCL decoding can be modelled similar to that of SC decoding, with the addition of $K$ time steps to update and sort the path metrics.

\subsection{Syndrome-Check Decoding}

The LLR values that are calculated based on the received message can be readily converted into estimated bits. A parity-check matrix can be used to check if these estimated bits represent a potential transmitted codeword. The idea is to generate a syndrome by multiplying the estimated bits $\bm{x}$ and the parity-check matrix $\bm{H}$, and check if all the parity constraints are satisfied. In case of a mismatch, the estimated bits $\bm{x}$ are refined as $\bm{x} = \bm{x}\oplus\bm{e}$ using an \emph{error vector} $\bm{e}$ and checked again against any parity violations. This process can be performed until $\bm{x}$ passes the syndrome check or a predefined maximum number of syndrome-check attempts is reached. Note that the parity-check matrix of polar codes is formed by selecting the columns of $\bm{G}^{\otimes n}$ that correspond to frozen bits. For $\mathcal{P}(8,4)$ with $\mathcal{I} = \{u_3,u_5,u_6,u_7\}$ and $\mathcal{F} = \{u_0,u_1,u_2,u_4\}$, $\bm{G}^{\otimes 3}$ and $\bm{H}$ are
\begin{equation*}
    \bm{G}^{\otimes 3} = \left[
        \begin{smallmatrix}
            1 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
            1 & 1 & 0 & 0 & 0 & 0 & 0 & 0\\
            1 & 0 & 1 & 0 & 0 & 0 & 0 & 0\\
            1 & 1 & 1 & 1 & 0 & 0 & 0 & 0\\
            1 & 0 & 0 & 0 & 1 & 0 & 0 & 0\\
            1 & 1 & 0 & 0 & 1 & 1 & 0 & 0\\
            1 & 0 & 1 & 0 & 1 & 0 & 1 & 0\\
            1 & 1 & 1 & 1 & 1 & 1 & 1 & 1\\
        \end{smallmatrix}
        \right] \text{, }
    \bm{H} = \left[
        \begin{smallmatrix}
            1 & 0 & 0 & 0 \\
            1 & 1 & 0 & 0 \\
            1 & 0 & 1 & 0 \\
            1 & 1 & 1 & 0 \\
            1 & 0 & 0 & 1 \\
            1 & 1 & 0 & 1 \\
            1 & 0 & 1 & 1 \\
            1 & 1 & 1 & 1 \\
        \end{smallmatrix}
        \right] \text{.}
\end{equation*}
Chase decoding \cite{chase} and guessing random additive noise decoding \cite{grand} are examples that incorporate syndrome-check decoding.

\section{Successive Syndrome-Check Decoding of Polar Codes}

In this section, SC decoding is reformulated to allow for performing successive syndrome checks. This results in an early-termination scheme for SC decoding that reduces the decoding latency, especially when the transmission channel experiences low levels of noise.

\subsection{Successive Syndrome-Check Decoding}

\begin{figure}
    \centering
    \input{figures/blockDiagram}
    \caption{Block diagram of the proposed successive syndrome-check decoder.}
    \label{fig:blockDiagram}
\end{figure}

Fig.~\ref{fig:blockDiagram} shows the block diagram of the proposed successive syndrome-check decoder. The decoder starts by making an initial estimate on the received codeword $\bm{x}$ based on the received LLR values as
\begin{equation}
    x_i = \begin{cases}0 & \text{if } y_i\geq0 \text{,}
    \\1 & \text{if } y_i<0 \text{.} \end{cases} \label{eq:xinit}
\end{equation}
The syndrome of $\bm{x}$ is calculated as $\bm{x}\bm{H}$ and is checked for possible errors. If $\bm{x}\bm{H}=0$, then $\bm{x}$ represents a valid codeword and thus $\bm{u} = \bm{x}\bm{G}^{\otimes n}$ is reported as the decoding result. Otherwise, if $\bm{x}\bm{H}\neq 0$, then there must be an error in the received message. To correct the error, the bit-by-bit decoding schedule of the SC decoder is exploited and the first $u_i \in \mathcal{F}$ is identified whose corresponding value in $\bm{x}\bm{H}$ is not $0$. In fact, starting from $u_0$ and up to the first $u_i \in \mathcal{F}$ where $u_i \neq 0$, any frozen bit whose corresponding value in the syndrome is $0$ does not need to be considered for error correction.

After identifying the first $u_i \in \mathcal{F}$ where $u_i \neq 0$, an error vector $\bm{e}_i$ is generated in an attempt to refine the received message $\bm{x}$. To generate $\bm{e}_i$, the LLR value associated with $u_i$ is calculated by moving from the right to the left of the factor-graph of Fig.~\ref{fig:decGraph}, using a reformulation of SC decoding as depicted in Fig.~\ref{fig:SSCdecBB}. In particular, the $g$ function in the SC decoder (\ref{eq:gFunction}) is replaced with
\begin{equation}
    l_1 = g(y_0,y_1,x_0,x_1) = y_1 + (-1)^{x_0\oplus x_1}y_0 \text{,} \label{eq:gFunctionS}
\end{equation}
where we used the fact that $u_0$ is decoded correctly and $\hat{u}_0 = x_0 \oplus x_1$. In other words, $\bm{x}$ includes all the refinements that result from decoding $u_0$. Note that due to the equivalence of soft and hard decoding when there is no error, the LLR of the first frozen bit whose corresponding estimate in the syndrome is $1$ must be negative, which is in violation of its estimate.

\begin{figure}
    \centering
    \input{figures/pc-dec1Ex}
    \caption{The building block of the proposed successive syndrome-check decoder.}
    \label{fig:SSCdecBB}
\end{figure}

Following the calculation of the LLR value, the error vector $\bm{e}_i$ is generated by moving from the left to the right of the factor-graph of Fig.~\ref{fig:decGraph}. When an $f$ function is encountered, the error follows the path corresponding to the input of $f$ function with the minimum absolute LLR value. When a $g$ function is encountered, the error follows both paths connected to the input of the $g$ function. In Fig.~\ref{fig:SSCdecBB}, the generation of $\bm{e}_i$ translates to
\begin{align}
    f&:
    \begin{cases}
    m = \displaystyle\argmin_{i\in \{0,1\}} |y_i| \text{,} \\
    x_m = 1 \oplus x_m \text{,}
    \end{cases} \label{eq:ferror} \\
    g&:
    \begin{cases}
    x_0 = 1 \oplus x_0 \text{,} \\
    x_1 = 1 \oplus x_1 \text{.}
    \end{cases} \label{eq:gerror}
\end{align}
$\bm{e}_i$ is then used to refine the received codeword $\bm{x}$ as
\begin{equation}
    \bm{x} = \bm{x}\oplus\bm{e}_i \text{.}
\end{equation}
The received codeword is repeatedly updated until its syndrome becomes $0$.

\begin{figure}
    \centering
    \input{figures/pc-dec8Ex3}
    \caption{Example of the proposed successive syndrome-check decoder for $\mathcal{P}(8,4)$ with $\mathcal{I} = \{u_3,u_5,u_6,u_7\}$ and $\mathcal{F} = \{u_0,u_1,u_2,u_4\}$. The LLR values received from the channel represent $\bm{x} = \{0,0,1,1,1,0,0,1\}$ with the syndrome $\bm{x}\bm{H} = \{0,0,1,0\}$. Therefore, the successive syndrome-check decoder starts by calculating the LLR value associated with $u_2$. The corresponding error vector is $\bm{e}_2 = \{1,0,1,0,0,0,0,0\}$ that is used to refine $\bm{x}$ to $\{1,0,0,1,1,0,0,1\}$. Since the syndrome of the refined $\bm{x}$ is $0$, the decoder outputs $\bm{u} = \bm{x}\bm{G}^{\otimes 3} = \{0,0,0,0,0,1,1,1\}$.}
    \label{fig:SSCdecEx}
\end{figure}

Fig.~\ref{fig:SSCdecEx} shows an example of the proposed successive syndrome-check decoder on the factor graph of $\mathcal{P}(8,4)$ with $\mathcal{I} = \{u_3,u_5,u_6,u_7\}$ and $\mathcal{F} = \{u_0,u_1,u_2,u_4\}$. The received values from the channel are turned into the LLR vector $\bm{y} = \{0.77,0.56,-0.08,-1.51,-1.44,2.89,2.33,-0.69\}$. The received codeword is then initialized based on (\ref{eq:xinit}) as $\bm{x} = \{0,0,1,1,1,0,0,1\}$. The syndrome of $\bm{x}$ is calculated as $\bm{x}\bm{H} = \{0,0,1,0\}$, which corresponds to $\{u_0,u_1,u_2,u_4\}$. Since $u_0 = u_1 = 0$, these two bits match the frozen bit value and thus, they do not need to undergo the decoding process. However, since $u_2 = 1$, the proposed successive syndrome-check decoder calculates its LLR value by traversing the factor graph from right to left, and stores the intermediate LLRs for error vector generation (see the red lines in Fig.~\ref{fig:SSCdecEx}). Note that the calculated LLR value of $u_2$ is indeed negative. The error vector $\bm{e}_2$ is then generated by traversing the factor graph from left to right (see the blue lines in Fig.~\ref{fig:SSCdecEx}). First, an $f$ function is encountered whose inputs are $-0.85$ and $1.3$. Therefore, the path corresponding to $-0.85$ is selected. Then, there is a $g$ function with inputs $-0.77$ and $-0.08$, and the path is extended on both inputs. Finally, the two paths are extended on the input of the two $f$ functions whose absolute LLR values are smaller. This results in $\bm{e}_2 = \{1,0,1,0,0,0,0,0\}$.
%Note that when an $f$ function is reached, the path extends only on one of its input but when a $g$ function is encountered, the path extends on both inputs.

After $\bm{e}_2$ is generated, $\bm{x}$ is refined as
\begin{equation}
    \bm{x} = \bm{x} \oplus \bm{e}_2 = \{1,0,0,1,1,0,0,1\} \text{.}
\end{equation}
This refined codeword has the syndrome $\bm{x}\bm{H} = \{0,0,0,0\}$, which passes the syndrome check. Therefore, the proposed decoder terminates the decoding process and outputs $\bm{u} = \bm{x}\bm{G}^{\otimes 3} = \{0,0,0,0,0,1,1,1\}$.

Note that the proposed decoder only needs to generate an error vector for the bits whose LLR values do not match their bit estimation\footnote{An LLR value matches a bit estimation if the LLR value is negative and the bit estimation is $1$, or if the LLR value is positive and bit estimation is $0$.}. In SC decoding, each information bit is decoded by making a decision based on the sign of the LLR value. Therefore, in SC decoding, the LLR values of information bits always match their bit estimation. Consequently, the error vector generation is only needed for the violating frozen bits whose LLR values are negative.

\subsection{Extension to SCL Decoding}

In SCL decoding, each information bit is estimated as both $0$ and $1$. Therefore, if the calculated LLR value of an information bit for each candidate in the list does not match its bit estimation, an error vector needs to be generated. As a result, the proposed successive syndrome-check decoder can be adapted to SCL decoding by generating error vectors not only for the violating frozen bits, but also for information bits. Similar to the case of SC decoding, if the syndrome of $\bm{x}$ is not zero, the first $u_i\in\mathcal{F}$ with $u \neq 0$ is identified. However, if there are information bits before that frozen bit, error vectors are generated for each information bit, $\bm{x}$ is refined for each candidate in the list, and the syndrome is calculated again for all $\bm{x}$. The process is continued until the syndrome of the best path in the list becomes $0$. Note that since there is a list of candidates, the error vector is generated based on the first violating frozen bit throughout the list. This guarantees that the error-correction performance of the proposed decoder is equivalent to that of the SCL decoder.

\section{Results}

This section presents latency results for the proposed successive syndrome-check decoder in terms of the number of time steps and compares them with the latency of the SC and SCL decoders. Similar to the case of SC and SCL decoding, the latency of the successive syndrome-check decoder is calculated by considering a fully-parallel implementation. Moreover, each level traversal on the factor graph based on (\ref{eq:fFunction}) and (\ref{eq:gFunctionS}) is equivalent to $1$ time step, and the bit-wise operations in (\ref{eq:ferror}) and (\ref{eq:gerror}) to generate the error vector and the calculation of the syndrome do not incur additional latency.

Fig.~\ref{fig:TvsSTime128} presents the required number of decoding time-steps for the proposed successive syndrome-check decoder that is based on SC decoding for $\mathcal{P}(128,64)$ used in the 5G standard. The results are compared with three fast SC decoders in the literature \cite{alamdar2011simplified,sarkis2014fast,hanif2017fast}. Fig.~\ref{fig:TvsSTime128SCL} shows the latency results of the proposed successive syndrome-check decoder based on SCL decoding for $\mathcal{P}(128,64)$ used in the 5G standard. The results are compared with three fast SCL decoders in \cite{hashemi2016fast,hashemi2017fast,hanif2018fast} and for all the decoders, $L=8$. Fig.~\ref{fig:TvsSTime128RM} plots the number of time-steps required for the proposed decoders and the fast SCL decoders in \cite{hashemi2016fast,hashemi2017fast,hanif2018fast} to decode a Reed-Muller (RM) code of length $128$ and rate $\frac{1}{2}$. The list size is set to $L=32$ to provide a frame error rate (FER) close to the maximum-likelihood decoding performance. It can be seen that in all the considered cases, the proposed method requires a smaller number of decoding time-steps in comparison with all the considered fast SC and SCL decoders at high signal-to-noise ratio (SNR) values. Note that in each considered scenario, the FER performance of the decoders are identical.

\begin{figure}[t]
    \centering
    \input{figures/TvsSTime128}
    \ref{legend-PLatcomp}
    \caption{Required number of decoding time-steps for $\mathcal{P}(128,64)$ used in the 5G standard. The FER at SNR~$=4$~dB is $1.6\times 10^{-3}$.}
    \label{fig:TvsSTime128}
\end{figure}

\section{Summary and Future Work}

In this paper, a successive syndrome-check decoder is presented that allows for early termination in SC and SCL decoding of polar codes. The proposed decoder is lossless in the sense that it does not degrade the error-correction performance of the underlying SC or SCL decoder. Moreover, the generation of error vectors in the proposed decoder obviates the need for generating partial sums, which are required in SC and SCL decoding. Simulation results show that at the same FER, the latency of the proposed decoder is smaller than that of the SC and SCL decoders at high SNR values.

Future work includes adapting the proposed successive syndrome-check decoder to the fast SC and SCL decoders. This ensures the worst-case latency of the decoder is the latency of the corresponding fast SC or SCL decoder. Another interesting direction for future work is to use a cyclic redundancy-check (CRC) to enable early-termination in addition to checking the syndrome. This is particularly useful in applications where polar codes are concatenated with a CRC.

\begin{figure}[t]
    \centering
    \input{figures/TvsSTime128SCL}
    \ref{legend-PLatcompSCL}
    \caption{Required number of decoding time-steps for $\mathcal{P}(128,64)$ used in the 5G standard. Note that $L=8$ for the SCL decoders. The FER at SNR~$=4$~dB is $1.1\times 10^{-3}$.}
    \label{fig:TvsSTime128SCL}
\end{figure}

\begin{figure}[t]
    \centering
    \input{figures/TvsSTime128RM}
    \ref{legend-RMLatcomp}
    \caption{Required number of decoding time-steps for a RM code of length $128$ and rate $\frac{1}{2}$. Note that $L=32$ for the SCL decoders. The FER at SNR~$=4$~dB is $2.3\times 10^{-5}$.}
    \label{fig:TvsSTime128RM}
\end{figure}

\section*{Acknowledgment}

This work is supported in part by ONR grant N00014-18-1-2191. S.~A.~Hashemi was supported by a Postdoctoral Fellowship from the Natural Sciences and Engineering Research Council of Canada (NSERC) and by Huawei. M. Mondelli was partially supported by the 2019 Lopez-Loreta Prize.

% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{arikan2009}
E.~Ar{\i}kan, ``Channel polarization: A method for constructing
  capacity-achieving codes for symmetric binary-input memoryless channels,''
  \emph{IEEE Trans. Inf. Theory}, vol.~55, no.~7, pp. 3051--3073, Jul. 2009.

\bibitem{tal2015list}
I.~Tal and A.~Vardy, ``List decoding of polar codes,'' \emph{IEEE Trans. Inf.
  Theory}, vol.~61, no.~5, pp. 2213--2226, 2015.

\bibitem{BYuan2Bit}
B.~{Yuan} and K.~K. {Parhi}, ``Low-latency successive-cancellation polar
  decoder architectures using 2-bit decoding,'' \emph{IEEE Trans. Circ. Syst.
  I: Regul.}, vol.~61, no.~4, pp. 1241--1254, April. 2014.

\bibitem{sarkis2013increasing}
G.~Sarkis and W.~J. Gross, ``Increasing the throughput of polar decoders,''
  \emph{IEEE Commun. Lett.}, vol.~17, no.~4, pp. 725--728, Apr. 2013.

\bibitem{husmann2017reduced}
C.~Husmann, P.~C. Nikolaou, and K.~Nikitopoulos, ``Reduced latency {ML} polar
  decoding via multiple sphere-decoding tree searches,'' \emph{IEEE Trans. Veh.
  Technol.}, vol.~67, no.~2, pp. 1835--1839, Feb. 2017.

\bibitem{alamdar2011simplified}
A.~Alamdar-Yazdi and F.~R. Kschischang, ``A simplified successive-cancellation
  decoder for polar codes,'' \emph{IEEE Commun. Lett.}, vol.~15, no.~12, pp.
  1378--1380, Dec. 2011.

\bibitem{sarkis2014fast}
G.~Sarkis, P.~Giard, A.~Vardy, C.~Thibeault, and W.~J. Gross, ``Fast polar
  decoders: Algorithm and implementation,'' \emph{IEEE J. Sel. Areas Commun.},
  vol.~32, no.~5, pp. 946--957, May. 2014.

\bibitem{giard2016multi}
P.~Giard, G.~Sarkis, C.~Thibeault, and W.~J. Gross, ``Multi-mode unrolled
  architectures for polar decoders,'' \emph{IEEE Trans. Circ. Syst. I: Regul.},
  vol.~63, no.~9, pp. 1443--1453, Sep. 2016.

\bibitem{hanif2017fast}
M.~Hanif and M.~Ardakani, ``Fast successive-cancellation decoding of polar
  codes: identification and decoding of new nodes,'' \emph{IEEE Commun. Lett.},
  vol.~21, no.~11, pp. 2360--2363, Nov. 2017.

\bibitem{condo2018generalized}
C.~{Condo}, V.~{Bioglio}, and I.~{Land}, ``Generalized fast decoding of polar
  codes,'' in \emph{IEEE Global Commun. Conf.}, Dec. 2018, pp. 1--6.

\bibitem{gamage2019low}
H.~Gamage, V.~Ranasinghe, N.~Rajatheva, and M.~Latva-aho, ``Low latency decoder
  for short blocklength polar codes,'' in \emph{European Conf. Netw. Commun.},
  2020, pp. 305--310.

\bibitem{ercan2017reduced}
F.~Ercan, C.~Condo, and W.~J. Gross, ``Reduced-memory high-throughput
  {F}ast-{SSC} polar code decoder architecture,'' in \emph{IEEE Int. Workshop
  Signal Process. Syst.}, Oct. 2017, pp. 1--6.

\bibitem{ercan2019operation}
F.~Ercan, T.~Tonnellier, C.~Condo, and W.~J. Gross, ``Operation merging for
  hardware implementations of fast polar decoders,'' \emph{J. Signal Process.
  Syst.}, vol.~91, no.~9, pp. 995--1007, Sep. 2019.

\bibitem{sarkis2016fast}
G.~Sarkis, P.~Giard, A.~Vardy, C.~Thibeault, and W.~J. Gross, ``Fast list
  decoders for polar codes,'' \emph{IEEE J. Sel. Areas Commun.}, vol.~34,
  no.~2, pp. 318--328, Feb. 2016.

\bibitem{hashemi2016fast}
S.~A. Hashemi, C.~Condo, and W.~J. Gross, ``A fast polar code list decoder
  architecture based on sphere decoding,'' \emph{IEEE Trans. Circ. Syst. I:
  Regul.}, vol.~63, no.~12, pp. 2368--2380, Dec. 2016.

\bibitem{hashemi2017fast}
S.~A. Hashemi, C.~Condo, and W.~J. Gross, ``Fast and flexible
  successive-cancellation list decoders for polar codes,'' \emph{IEEE Trans.
  Signal Process.}, vol.~65, no.~21, pp. 5756--5769, 2017.

\bibitem{hanif2018fast}
M.~Hanif, M.~H. Ardakani, and M.~Ardakani, ``Fast list decoding of polar codes:
  Decoders for additional nodes,'' in \emph{IEEE Wireless Commun. Netw. Conf.
  Workshops}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2018, pp. 37--42.

\bibitem{mondelli2021sublinear}
M.~Mondelli, S.~A. Hashemi, J.~M. Cioffi, and A.~Goldsmith, ``Sublinear latency
  for simplified successive cancellation decoding of polar codes,'' \emph{IEEE
  Trans. Wireless Commun.}, vol.~20, no.~1, pp. 18--27, 2021.

\bibitem{hashemi2021parallelism}
S.~A. Hashemi, M.~Mondelli, A.~Fazeli, A.~Vardy, J.~Cioffi, and A.~Goldsmith,
  ``Parallelism versus latency in simplified successive-cancellation decoding
  of polar codes,'' \emph{IEEE Trans. Wireless Commun.}, pp. 1--1, 2021.

\bibitem{yoo2016comml}
H.~{Yoo} and I.~{Park}, ``Efficient pruning for successive-cancellation
  decoding of polar codes,'' \emph{IEEE Commun. Lett.}, vol.~20, no.~12, pp.
  2362--2365, Dec. 2016.

\bibitem{choi2017comml}
J.~{Choi} and I.~{Park}, ``Improved successive-cancellation decoding of polar
  codes based on recursive syndrome decomposition,'' \emph{IEEE Commun. Lett.},
  vol.~21, no.~11, pp. 2344--2347, Nov. 2017.

\bibitem{kim2018ET}
D.~Kim and I.-C. Park, ``A fast successive cancellation list decoder for polar
  codes with an early stopping criterion,'' \emph{IEEE Trans. Signal Process.},
  vol.~66, no.~18, pp. 4971--4979, 2018.

\bibitem{huang2012latency}
Z.~Huang, C.~Diao, and M.~Chen, ``Latency reduced method for modified
  successive cancellation decoding of polar codes,'' \emph{Electron. Lett.},
  vol.~48, no.~23, pp. 1505--1506, Nov. 2012.

\bibitem{balatsoukas2014enabling}
A.~Balatsoukas-Stimming, G.~Karakonstantis, and A.~Burg, ``Enabling
  complexity-performance trade-offs for successive cancellation decoding of
  polar codes,'' in \emph{IEEE Int. Symp. Inf. Theory}, Jun. 2014, pp.
  2977--2981.

\bibitem{zhang2015simplified}
L.~Zhang, Z.~Zhang, X.~Wang, C.~Zhong, and L.~Ping, ``Simplified
  successive-cancellation decoding using information set reselection for polar
  codes with arbitrary blocklength,'' \emph{IET Commun.}, vol.~9, no.~11, pp.
  1380--1387, Jul. 2015.

\bibitem{638mbps}
P.~{Giard}, G.~{Sarkis}, C.~{Thibeault}, and W.~J. {Gross}, ``A 638 {Mbps}
  low-complexity rate 1/2 polar decoder on {FPGAs},'' in \emph{IEEE Int.
  Workshop on Sig. Proc. Systems}, Oct. 2015, pp. 1--6.

\bibitem{giard2018fast}
P.~Giard, A.~Balatsoukas-Stimming, G.~Sarkis, C.~Thibeault, and W.~J. Gross,
  ``Fast low-complexity decoders for low-rate polar codes,'' \emph{J. Signal
  Process. Syst.}, vol.~90, no.~5, pp. 675--685, May. 2018.

\bibitem{li2018low}
S.~Li, Y.~Deng, L.~Lu, J.~Liu, and T.~Huang, ``A low-latency simplified
  successive cancellation decoder for polar codes based on node error
  probability,'' \emph{IEEE Commun. Lett.}, vol.~22, no.~12, pp. 2439--2442,
  Dec. 2018.

\bibitem{zheng2020icc}
H.~{Zheng}, S.~A. {Hashemi}, Z.~{Cao}, A.~M.~J. {Koonen}, J.~{Cioffi}, and
  A.~{Goldsmith}, ``Threshold-based successive-cancellation decoding of polar
  codes,'' in \emph{IEEE Int. Conf. on Commun.}, Jun. 2020, pp. 1--6.

\bibitem{chase}
D.~Chase, ``Class of algorithms for decoding block codes with channel
  measurement information,'' \emph{IEEE Trans. Inf. Theory}, vol.~18, no.~1,
  pp. 170--182, 1972.

\bibitem{grand}
K.~R. Duffy, J.~Li, and M.~MÃ©dard, ``Capacity-achieving guessing random
  additive noise decoding,'' \emph{IEEE Trans. Inf. Theory}, vol.~65, no.~7,
  pp. 4023--4040, 2019.

\end{thebibliography}

\end{document}
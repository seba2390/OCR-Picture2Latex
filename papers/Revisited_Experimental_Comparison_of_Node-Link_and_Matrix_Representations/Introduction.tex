\section{Introduction}

Visualizing network data is known to 
benefit a wide range of domains, including biology, engineering, and social sciences~\cite{von2011visual}. The data visualization community has proposed many approaches to visual network exploration. 
By comparison, the body of work that evaluates the ability of such methods to support data-reading tasks is limited. 
%This paper augments the research landscape with a comparative user 
We describe the results of a comparative evaluation of the two most popular ways of visualizing networks: node-link diagrams (NL) and adjacency matrices (AM).   Specifically, we 
consider two interactive visualizations (NL and AM), using a crowdsourced, between-subject methodology, with $557$ distinct online users, $14$ evaluated tasks, and $1$ real-world dataset; see Fig.~\ref{fig:dataModel}.

%Previous reports of user studies that evaluate these 
Several earlier studies compare NL and AM visualizations on specific classes of networks and using a variety of tasks~\cite{ghoniem2004comparison,ghoniem2005readability,okoeecological,keller2006matrices}. They show that the effectiveness of the visualization depends heavily on the properties of the given dataset and the given data-reading tasks. For example, Ghoniem {\it et al.}'s seminal evaluation~\cite{ghoniem2004comparison} found that the two visualizations' ability to support specific tasks depends on the  size and density of the network. Similarly, it is reasonable to hypothesize that there might be differences depending on the   structure of the network (e.g., clustered networks, small-world networks). Thus exploring the effectiveness of NL and AM visualizations on different types of graphs, and using a broader spectrum of tasks, seems worthwhile.

Our study uses one real-world, scale-free dataset of 258 nodes and 1090 edges. This makes our dataset different in structure and larger than previously evaluated networks. For example, Ghoniem {\it et al.} evaluated random networks that were about $2.5$ times smaller, albeit somewhat denser. We argue (in section 3) that our chosen dataset is worth studying as it exemplifies a large class of networks that occur in real applications.

More recently, networks are used to solve increasingly complex problems and as a result, there is an expanding range of tasks that are relevant in real applications and which are of interest to the visualization community. Our study evaluates many tasks ($14$), carefully chosen to span multiple task taxonomies~\cite{lee2006task,amar2005low}. Many of these tasks were not previously investigated in the context of NL and AM representations.



\begin{figure*}[t]
  \centering
  \includegraphics[width=.95\linewidth]{images/Stimuli.png}
  \caption{Evaluated visualizations: node-link diagram and adjacency matrix.}
	\label{fig:dataModel}
\end{figure*}
Given the caveat that these results apply to the specific underlying network and the specific implementations of NL and AM visualizations, some of our results confirm prior observations in similar settings, while others are new. 
%For the network and visualizations we evaluated, 
NL outperforms AM for questions about graph topology (e.g., ``Select all neighbors of node," ``Is a highlighted node connected to a named node?"). 
Of $10$ such tasks, participants who used the node-link diagram were more accurate in $5$ and less accurate in $2$. NL and AM give similar results for $4$ tasks which tested the ability of the participants to identify and compare node groups or clusters,  %were generally comparable across the two visualizations, 
except one instance in which AM outperforms NL. Finally, NL and AM provide similar results on $2$ memorability tasks. The full results are shown in Figure 4.









\section{Discussion}

Based on the quantitative results and our own interactions with the visualizations, we believe the results can be explained by several factors.

First, NL can be more compact than AM since their layout fully leverages the 2D area, while matrices are constrained to two 1D linear node orders. Matrices favor dense networks (as number of edges increases, matrix size remains constant) but not sparse ones (empty matrices are as large as a dense ones). Instead, sparse NL diagrams can be packed tightly. At the extreme, an empty network can be shown without loss in readability using NL in a $\sqrt{N}\times\sqrt(N)$ square. The same empty network would require a $N \times N$ square in an AM.
Thus, as networks grow larger but not necessarily denser, AM may incur an increasing navigation cost. Concretely, our NL diagrams required less zooming for nodes to become legible and selected accurately. This could explain the differences in $T1$.


Second, NL draw a node's glyph and connections together. Thus, once a label is spotted, from it, its outgoing edges can be traced to other nodes and their labels. Moreover, the presence of the edge aids this tracing.  Instead, matrices show node information and edge information separately. Finding the endpoints of an edge involves two potentially long visual-traces along the horizontal and vertical axes. Similarly, finding an edge of an identified node involves a horizontal or vertical search. This could be one of the reasons for the large effect in $T9$. However,  this described behavior is only hypothesized and yet to be demonstrated.

Third,  Ghoniem {\it et al.} found that AM performs poorly on tasks involving long paths~\cite{ghoniem2004comparison}, and our results on $T10$ and $T13$ confirm this. Interestingly, the average time of participants performing path tasks ($T10$) in AM is significantly shorter than that for NL. However, we found that this is due to many AM users giving up on solving the task altogether early on. Moreover, NL layouts aim to place nodes so that their network distance matches their embedded distance. While matrices can also order rows and columns, they are constrained by the use of a single dimension. This could explain the results of $T5$: when one pair of nodes were in the same cluster and the other not, comparing their topological proximity was possible in both visualizations, but in all other cases NL outperforms AM.

Matrices eliminate occlusion and ambiguity problems. In NL diagrams it is sometimes difficult to tell if an edge connects to a node or passes through it, but this is not the case in AMs.  Moreover, many tasks that involve visual searches in unconstrained 2D space with NL, are easier with AM.
%can be done in matrices linearly. 
For example, finding a node in an AM involves a linear scan in 
a list of labels. Counting nodes with certain properties can also be done sequentially by moving through the matrix's headers. Such tasks are difficult in NL diagrams as users have to search a 2D space and keep track of already visited nodes.  This may account for $T4$, where AM outperforms NL: participants could systematically scan two selected AM node-rows and identify the columns where both rows had an edge. 

\subsubsection{Limitations:}

Several earlier studies comparing NL and AM considered the effects of network size and density~\cite{ghoniem2005readability,keller2006matrices}. While we recognize the value of this approach, this was beyond the scope of our current study. Instead, we aimed to understand how the two visualizations support a more complete range of tasks (14 versus previously 7 and 6) in a network that is representative of real-world networks in size and structure. It is unclear whether our results would generalize to real-world networks that are significantly larger or denser but our work does provide additional experimental data for a network unlike those evaluated earlier. 

We use one type of network and a single instance thereof. This is a methodological drawback which we accepted, due to the overhead associated with preparing multiple appropriate real-world networks for evaluation and phrasing participant instructions using the semantics of different networks. 
%This is not uncommon when working with real-world datasets. For example, Keller et al. evaluated three different types of networks in terms of size and density, but used a single network of each type. 
%Moreover, we argue that this 
While the limitations of this approach are non-trivial, we attempted to balance them by using multiple task-repeats of the same type and focusing on different parts of the network.
%two related reasons: our participants solved up to $10$ different repeats of each task, and, because the network is rather large, these repeats could focus on different parts of the network. 

The density of our network was significantly lower than~\cite{ghoniem2004comparison,keller2006matrices}.
%by Ghoniem et al. and Keller et al.
However, Melancon points out that large real-world networks with high densities are rare~\cite{melancon2006just}. He argues that the edge-to-node ratio is a better indicator for density in real-world networks as it is less sensitive to the number of nodes. Indeed, only $1$ of the $17$ networks we considered, and $3$ of the $19$ networks Melancon considered had densities higher than $0.2$. In $3$ of these $4$ cases, these dense networks were also the smallest in terms of number of nodes.   

As in recent studies, we  evaluate interactive visualizations. Given the  different visual encoding in NL and AM it is difficult to ensure that all interactions are fair to both visualizations. To alleviate this concern 
%we controlled the fairness of the choice process. We 
we relied on a detailed review of the NL and AM literature, and selected the most common interactions and their implementations (see Section 3.3). This ensured, at least to some degree, that we evaluated the interactive visualizations as they appear in practice.

Crowdsourced studies have known inherent limitations (e.g., difficulty controlling the experimental setup and verifying what participants do). % are using to conduct their sessions. 
By and large, however, crowdsourcing studies replicate prior controlled lab studies~\cite{heer2010crowdsourcing}.



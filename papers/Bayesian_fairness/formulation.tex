
\section{Bayesian Formulation}
\label{sec:formulation}

We first introduce a concrete, statistical decision problem. The true
(latent) outcome $\out$ is generated independently of the DM's
decision, with a probability distribution that depends on the
available information $\obs$. There also exists a sensitive attribute
variable $\sns$, which may be dependent on $\obs$.\footnote{Depending
  on the application scenario, $\sns$ may actually be a subset of
  $\obs$ and thus directly observable, while in other scenarios it may
  be latent. Here we focus on the case where $\sns$ is not directly
  observed.}

\begin{definition}[Statistical decision problem]
 See Figure~\ref{fig:bayes-rule} for the decision diagram. The DM
 observes $\obs \in \Obs$, then takes a decision $\act \in \Act$ and
 obtains utility $\util(\out, \act)$ depending on a true (latent)
 outcome $\out \in \Out$ generated from some distribution
 $P_\param(\out \mid \obs)$.  The DM has a belief $\bel \in \Bel$ in
 the form of a probability distribution on parameters $\param \in
 \Param$ on a family $\family \defn \cset{P_\param(y \mid x)}{\param
   \in \Param}$ of distributions. In the Bayesian case, the belief
 $\bel$ is a posterior formed through a prior and available data. The
 DM has a utility function $\util : \CY \times \CA \to \Reals$, with
 utility depending on the DM's action and the outcome.
  \begin{figure}
    \centering
    \begin{tikzpicture}
      \node[RV] at (-1,0) (b) {$\bel$}; 
      \node[RV,hidden] at (0,0) (p) {$\param$}; 
      \node[RV] at (0,-1) (z) {$z$}; 
      \node[RV] at (1,-1) (x) {$x$}; 
      \node[RV] at (1,0) (y) {$y$}; 
      \node[utility] at (2,0) (u) {$\util$}; 
      \node[RV] at (2,-1) (a) {$a$}; 
      \node[select] at (3,-1) (pol) {$\pol$}; 
      \draw[->] (x)--(y);
      \draw[->] (z)--(y);
      \draw[->] (x)--(z);
      \draw[->] (p)--(x);
      \draw[->] (p)--(y);
      \draw[->] (p)--(z);
      \draw[->] (b)--(p);
      \draw[->] (y)--(u);
      \draw[->] (a)--(u);
      \draw[->] (pol)--(a);
      \draw[->] (x)--(a);
    \end{tikzpicture}
    \caption{The basic Bayesian decision problem with observations $x$, outcome $y$, action $a$,  sensitive variable $z$,  utility $\util$, unknown parameter $\param$, belief $\bel$ and policy $\pol$. The joint distribution of $x,y,z$ is fully determined by the unknown parameter $\param$, while the conditional distribution of actions $a$ given observations $x$ is given by the selected policy $\pol$. The DM's  utility function is $\util$, while the fairness of the policy depends on the problem parameters.}
    \label{fig:bayes-rule}
  \end{figure}
\end{definition}

For simplicity, we will
assume that $\Obs$, $ \Act$, and $\Out$, are finite and discrete,
whereas $\Param$ will be a subset of $\Reals^n$. We focus on Bayesian
decision rules, i.e. rules whose decisions  depend upon a
posterior belief $\bel$. The Bayes-optimal
decision rule for a given posterior and utility, but ignoring
fairness, is defined below. 
%
\begin{definition}[Bayes-optimal decision rule]
  The Bayes-optimal decision rule $\pol^* : \Bel \times \CX \to \CA$ is a
  deterministic policy that maximizes the utility in expectation,
  i.e. takes action
  $\pol^*(\bel, x) \in \argmax_{a \in \CA} \util_{\bel}(a \mid x)$, with
  $\util_{\bel}(a \mid x) \defn \sum_y \util(y, a)  \Pbx{y}$,
  where  $\Pbx{y} \defn \int_\Param P_\param(y \mid x) \dd \bel (\param)$
  is the marginal distribution over outcomes conditional on the observations according to the DM's belief $\bel$.
  \label{def:Bayes-rule}
\end{definition}

The Bayes-optimal decision rule does not directly depend on the
sensitive variable $z$.  We are interested in operating over multiple
time periods. At time $t$, the DM observes $x_t$ and makes a
decision $a_t$ using policy $\pol_t$ and obtains some instantaneous
payoff $U_t = u(y_t, a_t)$ and fairness violation $F_t$.  As always,
the DM's utility is the sum of instantaneous payoffs over time, $U
\defn \sum_{t=1}^T u(y_t, a_t)$ and she is interested in finding a policy
maximising $U$ in expectation. Note the decision problem and its variables stay unchanged over time. %Only the DM's beliefs might change according to his observations. 

Although the Bayes-optimal decision rule brings the highest expected reward to 
the DM, it may be unfair.  
In the sequel, we will define analogs of the \emph{balance} notion of fairness in
terms of decision rules $\pol$, and investigate appropriate decision rules, that 
possibly result in randomized policies.  In particular, we shall consider a utility function that combines the DM's utility with the societal benefit due to fairness, and search for the Bayes-optimal decision rules with respect to this new,
combined utility.

% \cd{Consider removing the example.}
% The following example helps illustrate this decision problem.
% \begin{example}[Criminal recidivism]
%   Consider a judge wishing to decide whether or not to let an accused free pending trial. We take the distribution $P_\param(\out \mid \obs)$ to be the probability of recidivism $\out$ given an accused with characteristics $\obs$ that involve attributes such as previous convictions, association with known criminals, education, age, gender and ethnicity. Some of these, like gender and ethnicity may be sensitive attributes that require protection against non-discrimination. Other sensitive attributes may not be observed.
% The DM's utility may have the following structure
%   \begin{equation}
%     \util(\act, \out) = 
%     \begin{cases}
%       -C, &\act = \textrm{release}, \out=\textrm{violation}\\
%       0, &\act = \textrm{release}, \out=\textrm{no violation}\\
%       -1, &\act = \textrm{no release},
%     \end{cases}
%   \end{equation}
%   where not releasing the accused is discouraged, but a violation is
%   perhaps costly to society than keeping an individual in prison.
%   Here we must have $C > 1$, otherwise it's better to release
%   everybody. With this utility, somebody should be released if the
%   probability of violation is smaller than $1/C$.  \iffalse In our
%   synthetic recidivism data, \cd{I have not actually coded the
%     synhetic example, so that's one thing on our TO-DO list} we assume
%   that individuals are more likely to violate bail conditions, the
%   more criminal associates they have.  This in turn is correlated with
%   the neighborhood they live in, their income, and their
%   education. However, strong family ties reduce this probability.
%   Unfortunately, bail decisions are only made on the basis of quite
%   indirect evidence: past offences, association with known criminals,
%   education, age, gender, and race.  \fi
% \end{example}

%Typically, we would not only like to maximize expected utility, but also take into account possible fairness violations, i.e. the dependency of the decisions on sensitive attributes such as race.
%
In particular, we define a Bayesian analogue of the maximization problem defined in~\eqref{eq:oracle-decision-problem-weights}:
%
\begin{align}
  &\max_\pol  (1 - \lambda) \E^\pol_\bel \util - \lambda \E^\pol_\bel \fair
  \nonumber \\
  =&
  \max_\pol  \int_\Param \left[(1 - \lambda) \E^\pol_\param \util - \lambda \E^\pol_\param \fair\right] \dd\bel(\param).
  \label{eq:bayes-decision-problem-weights}
\end{align}
To make this concrete, in the sequel we shall define the appropriate Bayesian version of the fairness-as-balance condition.

%With this formulation the Bayes-optimal decision rule does not necessarily lead to a single optimal action for any given $x$. This is because $\E^\pol_\param \fair$ is defined through the complete contribution and is not decomposable in terms of individual actions $\act$. To make the above more concrete, in the sequel we shall define the appropriate Bayesian version of the fairness-as-balance condition.
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "subjective-fairness-nips"
%%% End:

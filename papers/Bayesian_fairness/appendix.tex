
\newpage
\section*{\LARGE Supplementary materials for ``Bayesian Fairness''}

\setcounter{section}{0}
%\setcounter{theorem}{0}

~\\

\section{Impossibility result}

\begin{theorem}\label{thm:impossible}
Calibration and balance conditions cannot hold simultaneously, except: (i) if there exists perfect decision rules that there exists $a,y$ s.t. $ P_\param^\pol(y\mid a) = 0 $ or $ P_\param^\pol(a\mid y) = 0 $, or (ii) $z$ is independent of $y$ that for each $z$, $ P_\param^\pol(z|y) \equiv \text{const.},~\forall y$.
\end{theorem}
\begin{proof}
We prove by contradiction. Using Bayes rule we first have
\begin{align}
    P_\param^\pol(a, z \mid y) =     P_\param^\pol(y, z \mid a) \cdot \frac{P_\param^\pol(a \mid y)}{P_\param^\pol(y \mid a)} ~.\label{eqn:1}
\end{align}
Suppose calibration condition holds, that is 
\[
P_\param^\pol(y, z \mid a) = P_\param^\pol(y \mid a) P_\param^\pol(z \mid a)
\]
Plug above into Eqn. (\ref{eqn:1}) we have 
\begin{align*}
    P_\param^\pol(a, z \mid y) &=    P_\param^\pol(y \mid a) P_\param^\pol(z \mid a) \cdot \frac{P_\param^\pol(a \mid y)}{P_\param^\pol(y \mid a)} \\
    &=P_\param^\pol(z \mid a) \cdot P_\param^\pol(a \mid y).
    \end{align*}
    On the other hand, if balanced condition holds too, we have
    \begin{align*}
    P_\param^\pol(a, z \mid y) =P_\param^\pol(a \mid y) \cdot P_\param^\pol(z \mid y) 
    \end{align*}
    Together we have that 
    \[
  P_\param^\pol(z \mid a) \cdot P_\param^\pol(a \mid y)  = P_\param^\pol(a \mid y) \cdot P_\param^\pol(z \mid y) \rightarrow   P_\param^\pol(z \mid a) =P_\param^\pol(z \mid y),
    \]
    which does not hold when condition (ii) does not hold, completing the proof. 
\end{proof}

~\\

\section{Trivial decision rules for balance}
\label{sec:counterexample}
 
\begin{theorem}
  A trivial decision rule of the form $\pol(a \mid x) = p_a$ can always satisfy balance for a Bayesian decision problem. However, it may be the only balanced decision rule, even when a non-trivial balanced policy can be found for every possible $\param \in \Param$.
  \label{lem:trivial-balance}
\end{theorem}
\begin{proof}
  For the first part, notice that Eqn. \eqref{eq:balanced-rule}
  can be always satisfied trivially if $\pol(a \mid x) = p_a$, i.e. we ignore the observations when taking our actions.
  For the second part, we can rewrite Eqn. \eqref{eq:balanced-rule} as
  \begin{align*}
    \sum_x \pol(a | x) \left[P_\theta(x, z | y) - P_\theta(x | y) P_\theta(z | y) \right] &= 0\\
    \sum_x \pol(a | x) \Delta_\theta(x, y, z) &= 0,
  \end{align*}
  where the $\Delta$ term is only dependent on the parameters.  This
  condition can be satisfied in two ways: the first is if the model
  $\param$ makes $x, z$ conditionally independent on $y$. The second
  is if the vector $\pol(a \mid \cdot)$ is orthogonal to
  $\Delta_\param(\cdot, y, z)$. If $|\CX| > |\CY \times \CZ|$, then,
  for any $\param$, we can always find a policy vector
  $\pol(a \mid \cdot)$ that is orthogonal to all vectors
  $\Delta_\param(\cdot, y, z)$. However, if these vectors across $\param$ have exactly degree of freedom being 1 (since they add up to 0, thus the rank of them can be at most the full rank - 1), then no single policy can be orthogonal
  to all, as otherwise the degree of freedom for this set of vectors will be at least 2. 
\end{proof}


\begin{example}
  In this balance example, there are two models. In the first model, for some value $y$, we have:
  \begin{align}
    P_{\param}(x=0|y) &= 1/4, &
                                P_{\param}(x=0|y,z=1) &= 1/4 - \epsilon, \\
    P_{\param}(x=1|y) &= 1/4, &
                                P_{\param}(x=1|y,z=1) &= 1/4 + \epsilon, \\
    P_{\param}(x=2|y) &= 1/4, &
                                P_{\param}(x=2|y,z=1) &= 1/4 + \epsilon, \\
  \end{align}
  so that
  \begin{align}
    P_{\param}(x=0|y) -  P_{\param}(x=0|y,z=1) &= \epsilon, \\
    P_{\param}(x=1|y) - P_{\param}(x=1|y,z=1) &=  - \epsilon\\
    P_{\param}(x=2|y) - P_{\param}(x=2|y,z=1) &=  - \epsilon
  \end{align}
  Similarly, we can construct models $\param'$ and $\param''$ so that the corresponding differences are $(-\epsilon, \epsilon, -\epsilon)$ and $(\epsilon, \epsilon, -\epsilon)$.
  For any policy $\pol(a \mid x)$ consider the vector $\pol_a = (\pol(a = 1 \mid x))_{x=1}^3$. Note that we can make the policy orthogonal to the first model simply by setting $\pol_a = (1/2, 1/2, 1)$.
\end{example}

~\\

\section{Proof of Theorem \ref{noise:model}}
\begin{proof}
We show the proof for Bayes-balance condition, while the proof for Marginal-balance resembles similarities. Denote the $(1-\delta)$-event that $\theta$ drawn from $\beta(\theta)$ that is $\epsilon$ close to the true model $\theta^*$ in all the conditional probabilities $P_{\theta}(x|y,z), P_{\theta}(x|y)$ as $\mathcal E$, then we have:
%\begin{align*}
%  &~~~\sum_x \pol(a | x)
%  \int_{\mathrlap{\Param }}
%    \left[P_\param(x, z | y)
%  - P_\param(x | y) P_\param(z | y) \right] \\
%  &=\int_{\theta \in \mathcal E} \sum_x \pol(a | x)
%    \left[P_{\param}(x, z | y)
%  - P_{\param}(x | y) P_{\param}(z | y) \right]\\
%  &+  \int_{\theta \notin \mathcal E}\sum_x \pol(a | x) \left[P_\param(x, z | y)
%  - P_\param(x | y) P_\param(z | y) \right] \\
% & \leq \int_{\theta \in \mathcal E} \sum_x \pol(a | x)
%    \left[P_{\param^*}(x, z | y)
%  - P_{\param^*}(x | y) P_{\param^*}(z | y) \right] +2\epsilon\\
%  &+\int_{\theta \notin \mathcal E}\sum_x \pol(a | x) \left[P_{\param^*}(x, z | y)
%  - P_{\param^*}(x | y) P_{\param^*}(z | y) \right] + 2\delta\\
%&  \leq \alpha+2(\epsilon+\delta).% \alpha \sum_x \pol(a | x) = \alpha.
%\end{align*}
\begin{align*}
  &~~~~~\bigl|\sum_x \pol(a | x)
    \left[P_{\param^*}(x, z | y)
  - P_{\param^*}(x | y) P_{\param^*}(z | y) \right]\bigr|\\
  &= \biggl|\int_{\theta \in \mathcal E} \sum_x \pol(a | x)
    \left[P_{\param^*}(x, z | y)
  - P_{\param^*}(x | y) P_{\param^*}(z | y) \right]\\
  &+\int_{\theta \notin \mathcal E}\sum_x \pol(a | x) \left[P_{\param^*}(x, z | y)
  - P_{\param^*}(x | y) P_{\param^*}(z | y) \right]\biggr|\\
  &\leq \biggl|\int_{\theta \in \mathcal E} \sum_x \pol(a | x)
    \left[P_{\param}(x, z | y)
  - P_{\param}(x | y) P_{\param}(z | y) \right] +2\epsilon\\
  &+\int_{\theta \notin \mathcal E}\sum_x \pol(a | x) \left[P_{\param^*}(x, z | y)
  - P_{\param}(x | y) P_{\param}(z | y) \right] + 2\delta\biggr|\\
  &\le \bigl |\sum_x \pol(a | x)
  \int_{\mathrlap{\Param }}
    \left[P_\param(x, z | y)
  - P_\param(x | y) P_\param(z | y) \right]\bigr| +  2(\epsilon+\delta).
  \end{align*}
  Summing over all $a,y,z$ gives us the results. 
\end{proof}
~\\

\section{Gradient calculations for optimal balance decision}
\label{sec:gradient}

For simplicity, let us define the vector in $\Simplex^{\CA}$:
\[
c_w(y,z) = \sum_x \pol_w(\cdot \mid x) \Delta(x, y, z),
\]
so that
\[
f_\lambda(w) = \util(\bel, \pol_w) -  \lambda \sum_{y,z} c_w(y,z)^\top c_w(y,z).
\]
Now
\begin{align*}
  &~~~~\grad_w \left(c_w(y,z)^\top c_w(y,z)\right)
  \\
  &= 
  \grad_w \sum_a c_w(y,z)_a^2\\
  &= 
  \sum_a 2 c_w(y,z)_a
  \grad_w c_w(y, z)_a
  \\
  \grad_w & c_w(y, z)_a
  = 
    \sum_x \grad_w \pol_w(a \mid x) \Delta(x, y, z),
\end{align*}
while
\begin{align}
  \grad \util(\bel, \pol_w)
  &=
    \int_\CX \dd \Pr_\bel(x) \grad_w \pol_w(a \mid x) \E_\bel (\util \mid x, a) 
\end{align}
Combining the two terms, we have
\begin{align*}
  \grad_w f_\lambda(w)
  &= 
    \int_\CX \grad_w \pol_w(a \mid x)
    \bigl[
    \dd \Pr_\bel(x) \E_\bel(U \mid x, a)
  \\
  &- 2 \lambda \sum_{y,z} c_w(y, z)_a \Delta(x, y, z) \dd \Lambda(x),
    \bigr].
\end{align*}
where $\Lambda$ is the Lebesgue measure.
We now derive the gradient for the $\grad_w \pol_w$ term. We consider
two parameterizations.
\paragraph{Independent policy parameters.} When $\pol(a \mid x) = w_{ax}$, we obtain
$$\partial \pol(a' \mid x') / \partial ax = \ind{ax = a'x'}$$.
This unfortunately requires projecting the policy parameters back to  the simplex. For this reason, it might be better to use a parameterization that allows unconstrained optimization. 
\paragraph{Softmax policy parameters.} When 
$$\pol(a \mid x) = e^{w_{ax}} / \sum_{a'} e^{w_{a'x}},$$
we have the following gradients:
\begin{align*}
  \partial \pol(a \mid x) / \partial ax
  &= 
    e^{w_{ax}} \sum_{a' \neq a} e^{w_{a'x}} \left(\sum_{a'} e^{w_{a'x}}\right)^{-2}
  \\
  \partial \pol(a \mid x) / \partial a'x
  &= 
    e^{w_{ax} + w_{a'x}}\left(\sum_{a''} e^{w_{a''x}}\right)^{-2}, ~ a \neq a'\\
  \partial \pol(a \mid x) / \partial a'x'
  &= 
    0, ~ ax \neq a'x'.
\end{align*}

~\\


\section{Empirical formulation.}
For infinite $\CX$, it may be more efficient to rewrite
\eqref{eq:balanced-bayes-constraint} as
\begin{align}
  0
  &=
    \int_{\CX} \pol(a \mid x) 
    \dd \left[ P(x, z \mid y)
    - P(x \mid y) P(z \mid y)\right]
  \\
  &= 
    \int_{\CX} \pol(a \mid x) 
    \left[ P(z \mid y, x)
    - P(z \mid y)\right] \dd P(x \mid y)\\
  &=
    \int_{\CX} \pol(a \mid x) 
    \left[ P(z \mid y, x)
    - P(z \mid y)\right] \frac{P(y \mid x)}{P(y)} \dd P(x)\\
  &\approx
    \sum_{x \sim P_\param(x)} \pol(a \mid x) 
    \left[ P(z \mid y, x)
    - P(z \mid y)\right] \frac{P(y \mid x)}{P(y)}
\intertext{simplifying by dropping the $P(y)$ term:}
  0 &\approx
    \sum_{x \sim P_\param(x)} \pol(a \mid x) 
    \left[ P(z \mid y, x)
    - P(z \mid y)\right] P(y \mid x),
\end{align}
This allows us to approximate the integral by sampling $x$, and can be
useful for e.g. regression problems.

\section{Complete figures}
This section has complete versions of the figures which could not fit in the main text.
\begin{figure*}
\centering
 \subfloat[$\lambda=0$]{
   \input{figures/sequential/finite-models-trade-lambda-0.tex}
  }
  \subfloat[$\lambda=0.25$]{
    \input{figures/sequential/finite-models-trade-lambda-0.25.tex}
  }
  \subfloat[$\lambda=0.5$]{
    \input{figures/sequential/finite-models-trade-lambda-0.5.tex}
  }
  \\
  \subfloat[$\lambda=0.75$]{
    \input{figures/sequential/finite-models-trade-lambda-0.75-2.tex}
  }
  \subfloat[$\lambda=1$]{
    \input{figures/sequential/finite-models-trade-lambda-1.tex}
  }
  \subfloat[legend]{
    \raisebox{4em}{\input{figures/sequential/finite-models-trade-legend.tex}}
  }
  \caption{\textbf{Synthetic data, utility-fairness trade-off.} This plot is generated from the same data as Figure~\ref{fig_exp_1}. However, now we are plotting the utility and fairness of each individual policy separately. In all cases, it can be seen that the Bayesian policy achieves the same utility as the non-Bayesian policy, while achieving a lower fairness violation.}
  \label{fig_exp_1:tradeoff_extend}
\end{figure*}

\begin{figure*}
\centering
  \subfloat[$\lambda=0$]{
    \input{figures/sequential/dirichlet-lambda-0.0.tex}
  }
  \subfloat[$\lambda=0.25$]{
    \input{figures/sequential/dirichlet-lambda-0.25.tex}
  }
  \subfloat[$\lambda=0.5$]{
    \input{figures/sequential/dirichlet-lambda-0.5.tex}
  }
  \\
  \subfloat[$\lambda=0.75$]{
    \input{figures/sequential/dirichlet-lambda-0.75.tex}
  }
  \subfloat[$\lambda=1$]{
    \input{figures/sequential/dirichlet-lambda-1.0.tex}
  }
  \subfloat[legend]{
    \raisebox{4em}{\input{figures/sequential/finite-models-legend.tex}}
  }

  \caption{\textbf{COMPAS dataset.} Demonstration of balance on the COMPAS dataset. The plots show the value measured on the holdout set for the \textbf{Bayes} and \textbf{Marginal} balance.
  Figures (a-e) show the utility achieved under different choices of $\lambda$ as we we observe each of the  6,000 training data points. Utility and fairness are measured on the empirical distribution of the remaining data and it can be seen that the Bayesian approach dominates as soon as fairness becomes important, i.e. $\lambda > 0$.  }
  \label{fig:compas-dbn_extend}
\end{figure*}


\begin{figure*}
\centering
  \subfloat[$\lambda=0$]{
    \input{figures/sequential/dirichlet-lambda-seq1-0.0.tex}
  }
  \subfloat[$\lambda=0.25$]{
    \input{figures/sequential/dirichlet-lambda-seq1-0.25.tex}
  }
  \subfloat[$\lambda=0.5$]{
    \input{figures/sequential/dirichlet-lambda-seq1-0.5.tex}
  }
  \\
  \subfloat[$\lambda=0.75$]{
    \input{figures/sequential/dirichlet-lambda-seq1-0.75.tex}
  }
  \subfloat[$\lambda=1$]{
    \input{figures/sequential/dirichlet-lambda-seq1-1.0.tex}
  }
  \subfloat[legend]{
    \raisebox{4em}{\input{figures/sequential/finite-models-legend.tex}}
  }
\caption{\textbf{Sequential allocation.} Performance measured with respect to the empirical model of the holdout COMPAS data, when the DM's actions affect which data will be seen. This means that wif a prisoner was not released, then the dependent variable $y$ will remain unseen. For that reason, the performance of the Bayesian approach dominates the classical approach even when fairness is not an issue, i.e. $\lambda = 0$.}
\label{fig:sequential-allocation_extend}
\end{figure*}





%\section{Proof of Lemma \ref{lemma:ult}}
%\begin{proof}
%  Let $a^*(x) \defn \max_a \E(\util \mid a, x)$ for some arbitrary
%  distribution. Then for any randomized policy $\pol$:
%  \begin{align*}
%  &\E^\pol(\util \mid x) =
%  \int_{\CA} \E(\util \mid a, x) \dd \pol(a \mid x)\\
%  &\leq \int_{\CA} \E(\util \mid a^*, x) \dd \pol(a \mid x)\\
%  &=\E(\util \mid a^*, x) \dd \pol(a \mid x).
%  \end{align*} 
%  We first apply this to the distribution $\bel(\param)$ to obtain the
%  result for Thompson sampling. For stochastic dominance, note that
%  $$\Pr_\bel(X > Y) = \int_\Param \Pr_\param(X > Y) \dd \bel(\param).$$
%  As stochastic dominance can be implemented by first sampling a
%  parameter and then sampling a dominant variable under this
%  parameter, we can reapply this fact and obtain the final result.
%\end{proof}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "subjective-fairness"
%%% End:

\setlength \fwidth {0.2\textwidth}

\begin{figure*}  
\centering
   \subfloat[$\lambda=0$]{
    \input{figures/sequential/finite-models-lambda-0.tex}
  }
  \subfloat[$\lambda=0.25$]{
    \input{figures/sequential/finite-models-lambda-0.25.tex}
  }
  \subfloat[$\lambda=0.5$]{
    \input{figures/sequential/finite-models-lambda-0.5.tex}
  }
  \\
  \subfloat[$\lambda=0.75$]{
    \input{figures/sequential/finite-models-lambda-0.75.tex}
  }
  \subfloat[$\lambda=1$]{
    \input{figures/sequential/finite-models-lambda-1.tex}
  }
  \subfloat[legend]{
    \raisebox{4em}{\input{figures/sequential/finite-models-legend.tex}}
  }
  \caption{\textbf{Synthetic data.} Test of effect of amount of data for Bayesian versus marginal decision rules, for different values of the $\lambda$ parameter, with respect to the true model. As more weight is placed on guaranteeing fairness, we see that the Bayesian approach is better able to guarantee fairness for the true model. The plots show the average performance over 10 runs, with an initially uniform prior over a set of 8 models, one of which is the correct one. In this setting $|\CA| = |\CY| = |\CZ| = 2$ and $|\CX| = 8$.}
  \label{fig_exp_1}
\end{figure*}

\section{Experiments} 
\label{sec:experiments}
In this section we study the utility-fairness trade-off on
artificial and real data sets.  We compare our approach, which uses a
decision rule based on the full Bayesian problem, to classical
approaches such as~\cite{HardtPNS16} which simply optimizes the DM's
policy with respect to a single model. Rather than introducing a new
fairness metric, we use a generalized version of the balance metric in
\cite{kleinberg2016inherent}, which is also a generalization of the
equality of opportunity in \cite{HardtPNS16}. We see that the Bayesian
approach very gracefully handles fairness, even with high model
uncertainty, while a marginal approach can be blatantly unfair.
%
For a fair comparison, in both cases we assume the same prior distribution for the
parameters. We focus on a simple model where posterior distributions can be calculated in closed-form, in order to focus on the choice of policy, rather than the case with approximate inference. However, our algorithm is generally applicable and could be combined with e.g. MCMC inference.

\textbf{Performance} is evaluated with respect to actual balance and
utility achieved: for the synthetic data this will be measured
according to the actual data-generating distribution, while for the
COMPAS data, it will be the empirical distribution on a holdout set.

\textbf{The algorithm} for optimising policies uses (stochastic) gradient descent. In particular, the Bayesian policy minimizes \eqref{eq:balanced-bayes-norm} by sampling $\param$ from the posterior distribution $\bel$ and then taking a step in the gradient direction. The marginal policy simply performs steepest gradient descent for the marginal model.
%Apart from the sampling, exactly the same amount of computation is used for both methods in all experiments.

\textbf{The results} shown in
Figures~\ref{fig_exp_1}--\ref{fig:sequential-allocation} display the
performance of the corresponding (Bayesian or marginal) decision rule
for different value of $\lambda$ as more data is acquired. In the
first two experiments, we assume that no matter what the decision of
the DM is, $z_t, y_t$ are always observed after the DM's decision and
so the model is fully updated. In that setting, it is not necessary
for the DM to take into account expected future information for her
actions. However, in the third experiment, described in
Section {\em Sequential allocation}, %~\ref{sec:sequential-experiment}, 
the values of $z_t$ and $y_t$
are only observed when the DM makes the decision $a_t = 1$, and the DM
faces a generalized exploration problem.

% \dcp{i hope we can be concrete about the computational approach used for classification, constrained optimization, etc.}\yang{I suppose this can be done via pointing to the gradient derivation in appendix. }
% \cd{I think what I wrote so far is enough.}


\textbf{The model} we employ throughout is a discrete Bayesian network
model, with finite $\CX, \CY, \CZ, \CA$. The models are thus described
through multinomial distributions that capture the dependency between
different random variables. The available data is used to calculate a
\emph{posterior} distribution $\bel(\param)$. From this, we calculate
both an approximate marginal balanced rule as well as a Bayesian
balanced rule. The former uses the marginal model directly, while the
latter uses $k = 16$ samples from the posterior
distribution.\footnote{We found empirically that 16 was a sufficient
  number for stable behaviour and efficient computation. For $k=1$ the
  algorithm devolves into an approximation of Thompson sampling.} We
tested these approaches both on synthetic data and on the COMPAS
dataset.
%
The conjugate prior distribution to this model is a simple Dirichlet-product, as the network is discrete. The graphical model is fully connected, so the model uses the factorization $P_\param(x, y, z) = P_\param(y \mid x, z) P_\param(x \mid z) P_\param(z)$. We used this simple modeling choice throughout the paper, apart from the small experiment on synthetic data in the following section. In all cases where a Dirichlet prior was used, the Dirichlet prior parameters were all set equal to $1/2$.




\subsection{Experiments on synthetic data.}
Here we consider a discrete decision problem, with $|\CX| = 8$,
$|\CY| = |\CZ| = |\CA| = 2$, and $\util(y, a) = \ind{y = a}$.  In our
first experiment, we generate $100$ observations from this model. We
performed the experiment 10 times, each time generating data from a
fully connected discrete Bayesian network with uniformly randomly
selected parameters. Unlike the rest of the paper, in this example,
the prior distribution has finite support on only 8 models. This means that the posterior will have effectively converged to the true model after 100 observations.



As can be seen in Figure \ref{fig_exp_1}, the relative performance of
the Bayesian approach w.r.t. the marginal approach increases as we put
more emphasis on fairness (Figure \ref{fig_exp_1}
(a) cares nothing about fairness.). In some cases (e.g. Figure \ref{fig_exp_1}
(c)), value for the marginal approach decreases at the beginning and
eventually reaches the same value as the Bayesian approach after
sufficient amount of data is received.  This conforms with our
hypothesis that one should take into account model uncertainty.  The
fact that both approaches converge toward the maximum value is in
accordance with our formal results (Theorem \ref{noise:model}).
     

Finally, Figure~\ref{fig_exp_1:tradeoff} and its extended version (Figure~\ref{fig_exp_1:tradeoff_extend} in supplementary materials) more clearly shows how well the two different solutions perform with respect to the utility fairness trade-off. As we vary $\lambda$ and the amount of data, both methods achieve the same utility. However the Bayesian approach consistently achieves lower fairness violations for similar $U$.


\subsection{Experiments on COMPAS data.}
For the COMPAS dataset, we consider a discretization where fields such as the number of offenses are converted to binary features.\footnote{We arrived at the specific discretization through cross validating the performance of a discrete Bayesian classifier over possible discretizations.} 
We used the first 6000 data points for training and the remaining 1214 points for validation. Two attributes are sensitive (sex, race), while 6 attributes (relating to prior convictions and age) are used for the policy.
With discretization, there are a total of 12 distinct values for the sensitive attributes and 141 for the observables used for the underlying model. The prediction is whether or not there is recidivism in the next two years, with utility function $\util(a, y) = \ind{a = y}$.

Figure~\ref{fig:compas-dbn} and its extended version (Figure~\ref{fig:compas-dbn_extend} in supplementary materials) show the results of applying our analysis
to the COMPAS dataset used by ProPublica. Since in this case the true
model was unknown, the results are calculated with respect to the
marginal model estimated on the holdout set. In this scenario we can see that when we only focus on classification performance, the marginal and Bayesian decision rules perform equally well. However, as we place more emphasis on fairness, we observe that the Bayesian approach dominates.
\footnote{We note here that measured performance performance may not monotonically increase with respect to the (rather small) holdout set. Even if we had converged to the true model, measuring with respect to an empirical estimate is problematic, as it will be $\epsilon$-far away from the true model. This is particularly important for fairness considerations.}

\begin{figure*}
\centering
%  \subfloat[$\lambda=0$]{
%    \input{figures/sequential/finite-models-trade-lambda-0.tex}
%  }
  \subfloat[$\lambda=0.25$]{
    \input{figures/sequential/finite-models-trade-lambda-0.25.tex}
  }
  \subfloat[$\lambda=0.5$]{
    \input{figures/sequential/finite-models-trade-lambda-0.5.tex}
  }
  \subfloat[$\lambda=0.75$]{
    \input{figures/sequential/finite-models-trade-lambda-0.75.tex}
  }
%  \subfloat[$\lambda=1$]{
%    \input{figures/sequential/finite-models-trade-lambda-1.tex}
%  }
  \subfloat[legend]{
    \raisebox{4em}{\input{figures/sequential/finite-models-trade-legend.tex}}
  }
  \caption{\textbf{Synthetic data, utility-fairness trade-off.} This plot is generated from the same data as Figure~\ref{fig_exp_1}. However, now we are plotting the utility and fairness of each individual policy separately. In all cases, it can be seen that the Bayesian policy achieves the same utility as the non-Bayesian policy, while achieving a lower fairness violation.}
  \label{fig_exp_1:tradeoff}
\end{figure*}

\begin{figure*}
\centering
  \subfloat[$\lambda=0$]{
    \input{figures/sequential/dirichlet-lambda-0.0.tex}
  }
%  \subfloat[$\lambda=0.25$]{
%    \input{figures/sequential/dirichlet-lambda-0.25.tex}
%  }
  \subfloat[$\lambda=0.5$]{
    \input{figures/sequential/dirichlet-lambda-0.5.tex}
  }
%  \\
%  \subfloat[$\lambda=0.75$]{
%    \input{figures/sequential/dirichlet-lambda-0.75.tex}
%  }
  \subfloat[$\lambda=1$]{
    \input{figures/sequential/dirichlet-lambda-1.0.tex}
  }
  \subfloat[legend]{
    \raisebox{4em}{\input{figures/sequential/finite-models-legend.tex}}
  }

  \caption{\textbf{COMPAS dataset.} Demonstration of balance on the COMPAS dataset. The plots show the value measured on the holdout set for the \textbf{Bayes} and \textbf{Marginal} balance.
  Figures (a-c) show the utility achieved under different choices of $\lambda$ as we we observe each of the  6,000 training data points. Utility and fairness are measured on the empirical distribution of the remaining data and it can be seen that the Bayesian approach dominates as soon as fairness becomes important, i.e. $\lambda > 0$.  }
  \label{fig:compas-dbn}
\end{figure*}

\begin{figure*}
\centering
  \subfloat[$\lambda=0$]{
    \input{figures/sequential/dirichlet-lambda-seq1-0.0.tex}
  }
%  \subfloat[$\lambda=0.25$]{
%    \input{figures/sequential/dirichlet-lambda-seq1-0.25.tex}
%  }
  \subfloat[$\lambda=0.5$]{
    \input{figures/sequential/dirichlet-lambda-seq1-0.5.tex}
  }
%  \\
%  \subfloat[$\lambda=0.75$]{
%    \input{figures/sequential/dirichlet-lambda-seq1-0.75.tex}
%  }
  \subfloat[$\lambda=1$]{
    \input{figures/sequential/dirichlet-lambda-seq1-1.0.tex}
  }
  \subfloat[legend]{
    \raisebox{4em}{\input{figures/sequential/finite-models-legend.tex}}
  }
\caption{\textbf{Sequential allocation.} Performance measured with respect to the empirical model of the holdout COMPAS data, when the DM's actions affect which data will be seen. This means that whenever a prisoner was not released, then the dependent variable $y$ will remain unseen. For that reason, the performance of the Bayesian approach dominates the classical approach even when fairness is not an issue, i.e. $\lambda = 0$.}
\label{fig:sequential-allocation}
\end{figure*}


\subsection{Sequential allocation.}
\label{sec:sequential-experiment}
Here the DM, at each time $t$ observes $x_t$ and has a choice of actions $a_t \in \{0,1\}$. The action both predicts $y_t \in \{0,1\}$ and has the following side-effect: the DM only observes $y_t, z_t$ after he makes the choice $a_t=1$, otherwise only $x_t$. 
The utility is not directly observed by the DM, and is measured against the empirical model in the holdout set, as before. We use the same COMPAS dataset, and the results are broadly similar, apart from the fact that the Bayesian decision rule appears to remain robust in this setting, while the marginal one's performance degrades.
We presume that this is because that the Bayesian decision rule explicitly taking into account uncertainty leads to more robust performance relative to the marginal decision rule, which does not.
The results are shown %in Figure~\ref{fig:sequential-allocation} in Appendix~\ref{sec:seq-results}.
in Figure~\ref{fig:sequential-allocation} and its extended version (Figure~\ref{fig:sequential-allocation_extend} in supplementary materials).
The larger discrepancy between for the Bayesian case
in Figure~\ref{fig:sequential-allocation}(a) implies that explicitly modelling uncertainty is also crucial for utility in this case.


%\label{sec:seq-results}

%%%appedix 2


% \paragraph{Continuous case with discrete $y$.}
% For the continuous case, we essentially just need to model a different
% joint distribution of $x, z$ for every choice of $y$. This should be
% possible.
% 
% \paragraph{Regression case.} 
% Let us consider the case of linear Bayesian regression, where $y$ is distributed according to a normal distribution given the observations $x$, the linear parameters $A$ and thecovariance matrix $\Sigma$, 
% \begin{align}
%   y \mid x, A, \Sigma &\sim \Gaussian(A x, \Sigma)\\
%   A &\sim \Gaussian(\mu, \sigma I)\\
%   \Sigma &\sim \Wishart(V),
% \end{align}
% where we assume that the prior distribution of $A$ is
% Gaussian\footnote{This is trivial to apply when $A$ is a vector. When
% $A$ is a matrix, then we simply consider the vectorisation of $A$.}
% and the prior distribution of $\Sigma$ is Wishart.  Then we can
% optimise our decision rule for either the marginal posterior of the
% Bayesian linear model or for the expected utility under our posterior
% distribution.  Let $\bel(\param)$ be the posterior distribution over
% parameters.  The difficulty is that the regression model gives us
% conditional probabilities $y, z \mid x$. So we can rewrite the constraint
% in terms of the regression model to obtain:
% \begin{align}
%   P_\param(x, z \mid y)
%   &=
%   P_\param(x, z, y) / P_\param(y)
%   =
%   P_\param(y, z \mid x) P_\param(x) / P_\param(y)
%   \\
%   P_\param(x \mid y)
%   &=
%   P_\param(x, y) / P_\param(y)
%   =
%   P_\param(y \mid x) P_\param(x) / P_\param(y)
%   \\
%   P_\param(z \mid y)
%   &=
%   \int_\CZ \dd P_\param(x, z \mid y)
%   =
%   P_\param(x) / P_\param(y) \int_\CZ \dd P_\param(y, z \mid x).
% \end{align}
% This implies that the regression model itself would not be sufficient: we'd also require to at least model the distribution of $y$ and $x$.
% 
% For our experiments, we use one of the datasets in~\citep{corbett2017algorithmic,chouldechova2016fair}.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "subjective-fairness-nips.tex"
%%% End:

\documentclass[twoside,11pt]{article}

\usepackage{blindtext}

% Any additional packages needed should be included after jmlr2e.
% Note that jmlr2e.sty includes epsfig, amssymb, natbib and graphicx,
% and defines many common macros, such as 'proof' and 'example'.
%
% It also sets the bibliographystyle to plainnat; for more information on
% natbib citation styles, see the natbib documentation, a copy of which
% is archived at http://www.jmlr.org/format/natbib.pdf

% Available options for package jmlr2e are:
%
%   - abbrvbib : use abbrvnat for the bibliography style
%   - nohyperref : do not load the hyperref package
%   - preprint : remove JMLR specific information from the template,
%         useful for example for posting to preprint servers.
%
% Example of using the package with custom options:
%
% \usepackage[abbrvbib, preprint]{jmlr2e}

\usepackage[preprint]{jmlr2e}
\usepackage{hyperref}
\usepackage{url}
\usepackage{mathrsfs, graphicx, multirow}
\usepackage{caption}
\usepackage{subfigure}
\usepackage{amsmath,amsfonts,bm}
\usepackage{color}
\usepackage{amsmath}
\allowdisplaybreaks[4]

% Definitions of handy macros can go here

\newcommand{\dataset}{{\cal D}}
\newcommand{\fracpartial}[2]{\frac{\partial #1}{\partial  #2}}

% Heading arguments are {volume}{year}{pages}{date submitted}{date published}{paper id}{author-full-names}

\usepackage{lastpage}
\jmlrheading{23}{2022}{1-\pageref{LastPage}}{1/21; Revised 5/22}{9/22}{21-0000}{Jiashuo Liu, Jiayun Wu, Bo Li and Peng Cui}

% Short headings should be running head and authors last names

\ShortHeadings{Predictive Heterogeneity: Measures and Applications}{Jiashuo Liu, Jiayun Wu, Bo Li and Peng Cui}

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}
%\newtheorem{theorem}{Theorem}
%\newtheorem{definition}{Definition}
%\newtheorem{proposition}{Proposition}
%\newtheorem{example}{Example}
%\newtheorem{remark}{Remark}



\firstpageno{1}

\begin{document}

\title{Predictive Heterogeneity: Measures and Applications}

\author{\name Jiashuo Liu\thanks{Equal Contributions.} \email liujiashuo77@gmail.com \\
       \addr Department of Computer Science and Technology\\
       Tsinghua University
       \AND
       \name Jiayun Wu$^*$ \email jiayun.wu.work@gmail.com \\
       \addr Department of Computer Science and Technology\\
		Tsinghua University
		\AND 
	   \name Bo Li \email libo@sem.tsinghua.edu.cn\\
	   \addr School of Economics and Management\\
	   Tsinghua University
	   \AND 
	   \name Peng Cui\thanks{Corresponding Author.} \email cuip@tsinghua.edu.cn\\
	   \addr Department of Computer Science and Technology\\
	   Tsinghua University
}

\editor{My editor}

\maketitle

\begin{abstract}%   <- trailing '%' for backward compatibility of .sty file
As an intrinsic and fundamental property of big data, data heterogeneity exists in a variety of real-world applications, such as precision medicine, autonomous driving, financial applications, etc.
For machine learning algorithms, the ignorance of data heterogeneity will greatly hurt the generalization performance and the algorithmic fairness, since the prediction mechanisms among different sub-populations are likely to differ from each other.
In this work, we focus on the data heterogeneity that affects the prediction of machine learning models, and firstly propose the \emph{usable predictive heterogeneity}, which takes into account the model capacity and computational constraints.
We prove that it can be reliably estimated from finite data with probably approximately correct (PAC) bounds.
Additionally, we design a bi-level optimization algorithm to explore the usable predictive heterogeneity from data.
Empirically, the explored heterogeneity provides insights for sub-population divisions in income prediction, crop yield prediction and image classification tasks, and leveraging such heterogeneity benefits the out-of-distribution generalization performance.
\end{abstract}

\begin{keywords}
  Predictive Heterogeneity, Out-of-Distribution Generalization, Computation Constraints
\end{keywords}

\input{data/1intro}
\input{data/2preliminary}
\input{data/3method}
\input{data/4optimization.tex}
\input{data/5experiment.tex}
\input{data/6related.tex}
\input{data/7conclusion.tex}


% Acknowledgements and Disclosure of Funding should go at the end, before appendices and references

%\acks{All acknowledgements go at the end of the paper before appendices and references.
%Moreover, you are required to declare funding (financial activities supporting the
%submitted work) and competing interests (related financial activities outside the submitted work).
%More information about this disclosure can be found on the JMLR website.}


% Manual newpage inserted to improve layout of sample file - not
% needed in general before appendices/bibliography.

\newpage


%\bibliography{sample}
%\bibliographystyle{sample}
\appendix
\input{data/8appendix}

\vskip 0.2in
\bibliography{sample}

\end{document}

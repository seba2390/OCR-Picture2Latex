\section{Experiments}
\label{section:exp}

\begin{figure}[b]
  \centering
  \includegraphics[width=\textwidth,height=4.5cm]{./fig/climate.png}
  \vskip -0.1in
  \caption{Results on the crop yield data. We color each region according to its main crop type, and the shade represents the proportion of the main crop type after smoothing via $k$-means ($k=3$).}
  \label{fig:climate}
  \vskip -0.2in
\end{figure}

\begin{figure}[t]
\centering
\begin{minipage}{.48\textwidth}
  \centering
  \includegraphics[width=\linewidth]{./fig/adults.png}
  \caption{Results on the Adults data. Here we show the average of features and the feature coefficients of the two learned sub-populations.}
  \label{fig:test1}
\end{minipage}%
\hfill
\begin{minipage}{.48\textwidth}
  \centering
  \includegraphics[width=\linewidth]{./fig/new_birds.png}
  \caption{Results on the Waterbird data. Here we \emph{randomly sample} 50 images for each class and each learned sub-population.}
  \label{fig:test2}
\end{minipage}
\vskip -0.2in
\end{figure}



\subsection{Reveal Explainable Sub-population Structures}
The predictive heterogeneity could provide valuable insights for the sub-population division and support decision-making across various fields, including agricultural and sociological research, as well as object recognition.
Our illustrative examples below reveal that the learned sub-population divisions are highly explainable and relevant for decision-making purposes.

\textbf{Example: Agriculture}\quad  It is known that the climate affects crop yields and crop suitability \citep{lobell2008prioritizing}.
We utilize the data from the NOAA database which contains daily weather from weather stations around the world.
Following \cite{zhao2021comparing}, we extracted summary statistics from the weather sequence of the year 2018, including the average yearly temperature, humidity, wind speed and rainy days.
The task is to predict the \emph{crop yield} in each place with \emph{weather summary statistics} and \emph{location covariates (i.e. longitude and latitude)} of the place.
For easy illustration, we focus on the places with crop types of wheat or rice.
Notably, our input covariates do \emph{not} contain the crop type information. 
We use MLP models in this task and set $K=2$ for our IM algorithm.

Given that crop yield prediction mechanisms are closely related to crop type, which is unknown in the prediction task, we believe this causes data heterogeneity in the entire dataset, and the recognized predictive heterogeneity should relate to it. 
To demonstrate the rationality of our measure, we plot the real distribution map of wheat and rice planting areas in Figure \ref{fig:climate}(a) and the learned two sub-populations of our IM algorithm in Figure \ref{fig:climate}(b). 
The division given by our algorithm is quite similar to the real division of the two crops, indicating the rationality of our measure. 
We observe some discrepancies in areas such as the Tibet Plateau in Asia, which we attribute to the absence of significant features such as population density and altitude that significantly affect crop yields.


\textbf{Example: Sociology}\quad 
We use the UCI Adult dataset \citep{misc_adult_2}, which is widely used in the study of algorithmic fairness and derived from the 1994 Current Population Survey conducted by the US Census Bureau.
The task is to predict whether the income of a person is greater or less than 50k US dollars based on personal features.
We use linear models in this task and set $K=2$.
In this example, we aim to investigate whether \emph{sub-population structures} within data affect the learning of machine learning models.

In Figure \ref{fig:test1} (a), we plot summary statistics for the two sub-populations, revealing a key difference in capital gain.
In Figure \ref{fig:test1} (b), we present the feature importance given by linear models for the two sub-populations, and find that for individuals with high capital gain, the prediction model mainly relies on capital gain, which is fair.
However, for individuals with low capital gain, models also consider sensitive attributes such as sex and marital status, which have been known to cause discrimination.
Our results are consistent with those found in \citep{zhao2021comparing} and can help identify potential inequalities in decision-making.
For example, our findings suggest potential discrimination towards individuals with low capital gain, which could motivate algorithmic design and improve policy fairness.

\textbf{Example: Object Recognition}\quad Finally, we utilize the Waterbird dataset \citep{sagawa2019distributionally}, which is widely used as a benchmark in the field of robust learning, to investigate the impact of spurious correlations on machine learning models.
The task is to recognize waterbirds or landbirds, but the images contain \emph{spurious correlations} between the background and the target label. 
For the majority of images, waterbirds are located on water and landbirds on land, whereas for a minority of images, this correlation is reversed. 
Therefore, the spurious correlation leads to predictive heterogeneity in this dataset, which could significantly affect the performance of machine learning models.
In this example, we use the ResNet18 and set $K=2$ in our IM algorithm.

Our method successfully captures the spurious correlation and identifies two sub-populations of images with inverse correlations between the object and the background.
To demonstrate the effectiveness of our method, we randomly sample 50 images for each class and each learned sub-population and plot them in Figure \ref{fig:test2}. 
In sub-population 1, the majority of landbirds are on the ground and waterbirds are in the water, while in sub-population 2, the majority of landbirds are in the water and waterbirds are on the ground.
Our findings suggest that the proposed approach can be leveraged by robust learning methods \citep{sagawa2019distributionally, koyama2020out} to improve the generalization ability of machine learning models. 
By eliminating the influence of spurious correlations, our method could significantly enhance the robustness and reliability of machine learning models. 
Overall, our study highlights the importance of addressing predictive heterogeneity in image classification tasks and provides a practical solution for achieving robust learning performance.


\begin{figure}[htbp]
\centering
\begin{minipage}{.48\textwidth}
  \centering
  \includegraphics[width=\linewidth]{./fig/age.png}
  \caption{Results on the COVID-19 data. We plot the age distributions of dead people ($Y=1$) in each learned subgroup.}
  \label{fig:COVID}
\end{minipage}%
\hfill
\begin{minipage}{.48\textwidth}
  \centering
  \includegraphics[width=\linewidth]{./fig/mean_features.png}
  \caption{Results on the COVID-19 data. We show the averages of typical features of dead people ($Y=1$) in each learned subgroup.}
  \label{fig:COVID2}
\end{minipage}
\vskip -0.2in
\end{figure}



\subsection{Assist Scientific Discovery: Uncover Factors Related to Mortality}
In order to fully demonstrate the efficacy of our predictive heterogeneity, we focus on the application of healthcare, utilizing the COVID-19 dataset of Brazilian patients. 
This dataset comprises 6882 COVID-positive patients from Brazil, whose data was recorded between February 27th and May 4th, 2020. 
The dataset includes a wide range of risk factors, including comorbidities, symptoms, and demographic characteristics. 
The binary label corresponds to mortality caused by COVID-19. 
Our aim is to validate the sub-populations learned through our methodology on this dataset, by thoroughly \emph{explaining each group} and showcasing how our predictive heterogeneity can be employed to \emph{uncover features related to mortality that are otherwise difficult to detect}.

\subsubsection{Learned Sub-populations.}
When predicting mortality based on risk factors, it is important to consider that patients with various underlying diseases and demographic characteristics, such as age and sex, may exhibit different probabilities of mortality. 
Furthermore, it is plausible that the mortality of different individuals can be attributed to distinct factors. 
In light of these considerations, the predictive heterogeneity for this dataset is caused by the diversity of mechanisms that contribute to mortality among various sub-populations.

In this experiment, we use linear models and the loss function is binary cross-entropy loss. 
We select the sub-population number $K\in \{2,3,4,5,6\}$ that exhibit the maximal empirical predictive heterogeneity$\hat{\mathcal{H}}_{\mathcal V}^{\mathscr E_K}(X\rightarrow Y;\mathcal D)$, which results in three distinct subgroups (the optimal $K=3$).
Besides, we empirically observe that when $K>3$, the learned sub-populations will shrink to 3 sub-populations.
In Figure \ref{fig:COVID} and \ref{fig:COVID2}, to conduct a more thorough examination of the learned subgroups, we analyze the age distribution of each group, as well as the average value of their corresponding risk factors. 
Our analysis reveals several noteworthy findings:
\begin{itemize}
	\item[1.] We observe a distinct difference in the age distribution of the learned subgroups. Specifically, Group 0 is primarily composed of individuals over the age of 70, while Group 1 consists of individuals around 60 years old. 
Group 2, on the other hand, is comprised of middle-aged individuals spanning multiple age groups.
	\item[2.]  The average values of the risk factors reveal notable differences among the various subgroups, indicative of distinct causes of mortality. More specifically, Group 0 exhibits a considerably higher prevalence of underlying diseases, such as renal, neurologic, liver, and immunosuppression, when compared to the other groups. In contrast, Group 1 shows a substantially lower level of underlying diseases in comparison. Interestingly, Group 2 does not exhibit any underlying diseases, yet has a markedly higher level of diarrhea and vomiting. These findings suggest that the learned subgroups may be used to identify specific risk factors associated with mortality, which can inform targeted interventions for individuals with distinct risk profiles.
\end{itemize}
Having identified distinct patterns among the subgroups, we seek to identify the specific risk factors associated with mortality. 
To further validate our findings, we incorporate the expertise of domain experts. 
By leveraging their insights, we are able to confirm the reliability of the identified risk factors and the importance of our subgroup analysis.


\subsubsection{Scientific Findings}
Based on the learned group, we fit a logistic regression model on each group and pick the top-6 features with the largest coefficients, which are shown in Table \ref{tab:top-features}.

Firstly, our analysis reveals that in Group 0 and 1, the top features associated with mortality are primarily SPO2 and underlying diseases, which align with the common risk factors of older individuals. 
In contrast, Group 2 exhibits a distinct set of top features, including symptoms of COVID-19 such as fever, cough, and vomiting. 
Notably, Group 2 is composed of middle-aged individuals spanning multiple age groups. 
Our findings suggest that severe COVID-19 symptoms can lead to mortality regardless of age.
%, further emphasizing the need for targeted interventions that account for individual risk factors.

Secondly, to further our analysis, we fit a model for the entire dataset and observe that the top features remain SPO2 and underlying diseases, consistent with the top features found for older individuals. 
However, this may not be beneficial or could even lead to harm for interventions targeted towards younger or middle-aged individuals who generally do not have severe underlying diseases. 
For instance, doctors may tend to treat younger patients with severe COVID-19 symptoms optimistically and underestimate their mortality risk because they typically do not have underlying diseases.
Thus, exploring and leveraging the predictive heterogeneity within the data can lead to more reliable scientific discoveries while avoiding potential harm caused by latent heterogeneity.

%Thirdly, from our analysis, we find two features on Group 2, i.e. vomiting and diarrhoea, which rarely appear in traditional analysis.
%We investigate the related literatures on COVID-19 and find that in various studies, these two features are recognized as important indicators of higher risk of mortality caused by COVID-19.
%\citet{2020COVID} highlighted the manifestations and potential mechanisms of gastrointestinal and hepatic injuries in COVID-19 to raise awareness of digestive system injury in COVID-19.
%\citet{Liu442} analyzed 29,393 laboratory-confirmed COVID-19 patients diagnosed before 21 March 2020 in cities outside of Wuhan in mainland China and found that  patients with fever and no GI symptoms and patients with both GI symptoms and fever all had significantly higher risk of death, where GI symptoms refer to one of the following symptoms (nausea, vomiting, diarrhoea or abdominal pain). 
%\citet{2021Gastrointestinal} also found that gastrointestinal symptoms are associated with severity of COVID-19, and the severe rate was more than 40\% in COVID-19 patients with gastrointestinal symptoms.
%\citet{0Diarrhea} demonstrated that the presence of diarrhea as a presenting symptom is associated with increased disease severity and likely worse prognosis.
%And \citet{2022COVID} called that COVID-19 should be considered in the differential diagnosis for patients who present with abdominal pain and gastrointestinal symptoms typical of gastroenteritis or surgical abdomen, even if they lack respiratory symptoms of COVID-19. 
%These studies validate the reliability of our findings, which also shows that our predictive heterogeneity could help to discover unusual risk factors that do not appear in the analysis on the overall dataset.


Thirdly, our analysis reveals two important features in Group 2, namely vomiting and diarrhea, which are rarely considered in traditional analysis. 
We have reviewed relevant literature on COVID-19 and discovered that various studies have recognized these two symptoms as important indicators of higher risk of mortality caused by COVID-19. 
\citet{2020COVID} highlighted the potential mechanisms of gastrointestinal and hepatic injuries in COVID-19 to raise awareness of digestive system injury in COVID-19. 
\citet{Liu442} analyzed 29,393 laboratory-confirmed COVID-19 patients diagnosed before March 21, 2020, in cities outside of Wuhan in mainland China and found that patients with both GI symptoms and fever and patients with fever alone had a significantly higher risk of death, where GI symptoms refer to one of the following symptoms: nausea, vomiting, diarrhea, or abdominal pain. 
\citet{2021Gastrointestinal} also found that gastrointestinal symptoms are associated with the severity of COVID-19, and the severe rate was more than 40\% in COVID-19 patients with gastrointestinal symptoms. 
\citet{0Diarrhea} demonstrated that the presence of diarrhea as a presenting symptom is associated with increased disease severity and likely worse prognosis. 
\citet{2022COVID} have called for the consideration of COVID-19 in the differential diagnosis for patients who present with abdominal pain and gastrointestinal symptoms typical of gastroenteritis or surgical abdomen, even if they lack respiratory symptoms of COVID-19. 
These studies validate the reliability of our findings and demonstrate that studies utilizing the proposed predictive heterogeneity can uncover unusual risk factors that do not appear in analysis of the overall dataset.

This example serves as an illustration of the potential benefits that our predictive heterogeneity can offer to a wide range of scientific fields.
By exploiting the heterogeneity within a dataset, our approach can reveal novel patterns and relationships that may be overlooked in traditional analyses, leading to more reliable and comprehensive scientific discoveries



\begin{table}[htbp]
\centering
\caption{Top features of each learned subgroup and overall data on the COVID-19 dataset.}
\label{tab:top-features}
\resizebox{\textwidth}{1.2cm}{
\begin{tabular}{c|llllll}
\hline
Group ID & \multicolumn{6}{c}{Top Features} \\ \hline
0        &    SPO2 &   Diabetes  &   Renal  & Neurologic    &  Pulmonary   &  Cardiovascular  \\ \hline
1        &    Diabetes &  SPO2   &  Neurologic   & Cardiovascular    & Pulmonary     &  Renal  \\ \hline
2        &    \bf Fever & \bf Cough   & Renal    & \bf Vomitting    & \bf Shortness of breath    &  \bf Dihareea  \\ \hline
All      &    SPO2 &    Renal &   Neurologic  &   Diabetes  & Pulmonary    &  Cardiovascular  \\ \hline
\end{tabular}}
\end{table}















\subsection{Benefit Generalization}
\label{section:ood}

\begin{table}[b]
\vskip -0.1in
\caption{Results of the experiments on out-of-distribution generalization, including the simulated data and colored MNIST data.}
\label{table:results}
%\vskip 0.005in
\centering\resizebox{\textwidth}{1.9cm}{
\begin{tabular}{|cc|cccc|||cc|}
\hline
\multicolumn{2}{|c|}{\multirow{3}{*}{\large Method}} & \multicolumn{4}{c|||}{\textbf{\large 1. Simulated Data}} & \multicolumn{2}{c|}{\textbf{\large 2. Colored MNIST}}\\ 
\multicolumn{2}{|c|}{}     &  \multicolumn{2}{c}{\bf Training Sub-population Error} & \multicolumn{2}{c|||}{\bf Test Error} & \multirow{2}{*}{\bf Train Accuracy} & \multicolumn{1}{c|}{\multirow{2}{*}{\bf Test Accuracy}}                                                                                                                  \\  
\multicolumn{2}{|l|}{}                                                                  & \multicolumn{1}{c}{Major ($r=1.9$)}            & \multicolumn{1}{c}{Minor ($r=-1.9$)}           & \multicolumn{1}{c}{$r=-2.3$}           & $r=-2.7$    &  &        \\ \hline
\multicolumn{2}{|c|}{ERM}                                 & \multicolumn{1}{c}{0.255{(\scriptsize$\pm 0.024$)}} & \multicolumn{1}{c|}{0.740{\scriptsize($\pm 0.022$)}} & \multicolumn{1}{c}{0.738{\scriptsize($\pm 0.035$)}} & 0.737{\scriptsize($\pm 0.023$)} & 0.998{\scriptsize($\pm 0.001$)} & 0.406{\scriptsize($\pm 0.019$)}  \\ 
\multicolumn{2}{|c|}{EIIL}                                   & \multicolumn{1}{c}{\bf 0.164{\scriptsize($\pm 0.014$)}} & \multicolumn{1}{c|}{1.428{\scriptsize($\pm 0.035$)}} & \multicolumn{1}{c}{1.431{\scriptsize($\pm 0.061$)}} & 1.431{\scriptsize($\pm 0.046$)} & 0.812{\scriptsize($\pm 0.006$)} & 0.610{\scriptsize($\pm 0.016$)}\\ \cline{1-2}
\multicolumn{1}{|c}{\multirow{3}{*}{\large KMeans}} & Balance   & \multicolumn{1}{c}{0.231{\scriptsize($\pm 0.022$)}} & \multicolumn{1}{c|}{0.847{\scriptsize($\pm 0.024$)}} & \multicolumn{1}{c}{0.846{\scriptsize($\pm 0.039$)}} & 0.845{\scriptsize($\pm 0.026$)}& \bf 0.999{\scriptsize($\pm 0.001$)} & 0.328{\scriptsize($\pm 0.021$)} \\ 
\multicolumn{1}{|c}{}                        & IRM        & \multicolumn{1}{c}{0.231{\scriptsize($\pm 0.022$)}} & \multicolumn{1}{c|}{0.845{\scriptsize($\pm 0.024$)}} & \multicolumn{1}{c}{0.844{\scriptsize($\pm 0.039$)}} & 0.843{\scriptsize($\pm 0.026$)} & 0.947{\scriptsize($\pm 0.004$)} & 0.259{\scriptsize($\pm 0.021$)}\\
\multicolumn{1}{|c}{}                        & IGA         & \multicolumn{1}{c}{0.235{\scriptsize($\pm 0.022$)}} & \multicolumn{1}{c|}{0.840{\scriptsize($\pm 0.023$)}} & \multicolumn{1}{c}{0.839{\scriptsize($\pm 0.038$)}} & 0.838{\scriptsize($\pm 0.027$)} & 0.997{\scriptsize($\pm 0.001$)} & 0.302{\scriptsize($\pm 0.021$)}\\ \cline{1-2}
\multicolumn{1}{|c}{\multirow{3}{*}{\large Ours}}   & Balance   & \multicolumn{1}{c}{0.403{\scriptsize($\pm 0.041$)}} & \multicolumn{1}{c|}{\bf 0.423{\scriptsize($\pm 0.016$)}} & \multicolumn{1}{c}{\bf 0.416{\scriptsize($\pm 0.022$)}} & \bf 0.416{\scriptsize($\pm 0.014$)} & 0.749{\scriptsize($\pm 0.012$)} & \bf 0.692{\scriptsize($\pm 0.039$)} \\ 
\multicolumn{1}{|c}{}                        & IRM        & \multicolumn{1}{c}{0.391{\scriptsize($\pm 0.039$)}} & \multicolumn{1}{c|}{\bf 0.432{\scriptsize($\pm 0.016$)}} & \multicolumn{1}{c}{\bf 0.430{\scriptsize($\pm 0.022$)}} &\bf 0.430{\scriptsize($\pm 0.014$)}  & 0.759{\scriptsize($\pm 0.014$)} & \bf 0.727{\scriptsize($\pm 0.047$)}\\
\multicolumn{1}{|c}{}                        & IGA        & \multicolumn{1}{c}{0.449{\scriptsize($\pm 0.037$)}} & \multicolumn{1}{c|}{\bf 0.426{\scriptsize($\pm 0.017$)}} & \multicolumn{1}{c}{\bf 0.417{\scriptsize($\pm 0.022$)}} &\bf 0.417{\scriptsize($\pm 0.014$)}  & 0.759{\scriptsize($\pm 0.012$)} & \bf  0.713{\scriptsize($\pm 0.034$)}\\ \hline
\end{tabular}
}
\end{table}


%\begin{figure}
%\centering
%\begin{minipage}{.69\textwidth}
%  \centering
%\subfigure[KMeans.] {
% \label{fig:a}     
%\includegraphics[width=0.3\linewidth]{./fig/kmeans.png}  
%}      
%\subfigure[EIIL.] {
% \label{fig:a}     
%\includegraphics[width=0.3\linewidth]{./fig/eiil.png}  
%}   
%\subfigure[Our IM.] {
% \label{fig:a}     
%	\includegraphics[width=0.3\linewidth]{./fig/ours.png}  
%	}
%	\vskip -0.1in
%  \caption{Sub-population division on the simulated data of three methods, where two colors denote two sub-populations.}
%  \label{fig:test3}
%\end{minipage}
%\hfill
%\begin{minipage}{.3\textwidth}
%  \centering
%  \includegraphics[width=\linewidth]{./fig/mnist.png}
%  \caption{Sub-population division on the MNIST data of our IM algorithm.}
%  \label{fig:test4}
%\end{minipage}
%\vskip -0.25in
%\end{figure}



\begin{figure}
\centering
\begin{minipage}{1.0\textwidth}
  \centering
\subfigure[KMeans.] {
 \label{fig:a}     
\includegraphics[width=0.3\linewidth]{./fig/kmeans.png}  
}      
\subfigure[EIIL.] {
 \label{fig:a}     
\includegraphics[width=0.3\linewidth]{./fig/eiil.png}  
}   
\subfigure[Our IM.] {
 \label{fig:a}     
	\includegraphics[width=0.3\linewidth]{./fig/ours.png}  
	}
	\vskip -0.1in
  \caption{Sub-population division on the simulated data of three methods, where two colors denote two sub-populations.}
  \label{fig:test3}
\end{minipage}
\end{figure}


 In this section, we aim to evaluate the efficacy of our IM algorithm in enhancing the out-of-distribution (OOD) generalization performance of machine learning models. 
 To this end, we conduct experiments on both simulated data and real-world colored MNIST data. 
 Our results suggest that the learned sub-population structures by our IM algorithm could significantly benefit the OOD generalization of machine learning models.

\textbf{Baselines}\quad First, we compare with \emph{empirical risk minimization} (ERM) and \emph{environment inference for invariant learning} (EIIL, \citep{creager2021environment}) which infers the environments for learning invariance.
Then we compare with the well-known \emph{KMeans} algorithm, which is the most popular clustering algorithm.
For our IM algorithm and KMeans, we involve three algorithms as backbones to leverage the learned sub-populations, including sub-population balancing and invariant learning methods.
The sub-population balancing simply equally weighs the learned sub-populations.
\emph{invariant risk minimization} (IRM, \citep{arjovsky2019invariant}) and \emph{inter-environment gradient alignment} (IGA, \citep{koyama2020out}) are typical methods in OOD generalization, which take the sub-populations as input environments to learn the invariant models.

\subsubsection{Simulation Data of Sample Selection Bias}
The input features $X=[S,T,V]^T\in\mathbb{R}^{10}$ consist of stable features $S\in\mathbb{R}^5$, noisy features $T\in\mathbb{R}^4$ and the spurious feature $V\in\mathbb{R}$:
\begin{small}
\begin{equation}
	S\sim\mathcal{N}(0,2\textbf{I}_5), T\sim\mathcal{N}(0,2\textbf{I}_4), Y=\theta_S^TS + h(S)+\mathcal{N}(0,0.5), V\sim\text{Laplace}(\text{sign}(r)\cdot Y, 1/(5\ln |r|))
\end{equation}	
\end{small}
where $\theta_S\in\mathbb{R}^5$ is the coefficient and $h(S)=S_1S_2S_3$ is the nonlinear term.
$|r|>1$ is a factor for each sub-population, and here the data heterogeneity is brought by the \emph{endogeneity with hidden variable} \citep{fan2014challenges}.
$V$ is the \emph{spurious feature} whose relationship with $Y$ is unstable across sub-populations and is controlled by the factor $r$.
Intuitively, $\text{sign}(r)$ controls whether the spurious correlation between $V$ and $Y$ is positive or negative. 
And $|r|$ controls the strength of the spurious correlation, i.e. the larger $|r|$ means the stronger spurious correlation.
In \emph{training}, we generate 10000 points, where the major group contains 80\% data with $r=1.9$ (i.e. strong \emph{positive} spurious correlation) and the minor group contains 20\% data with $r=-1.9$ (i.e. strong \emph{negative} spurious correlation).
In \emph{testing}, we test the performances of the two groups respectively, and we also set $r=-2.3$ and $r=-2.7$ to simulate stronger distributional shifts.
We use linear regression and set $K=2$ for all methods, and we report the mean-square errors (MSE) of all methods.

The results over 10 runs are shown in Table \ref{table:results}.
From the results in Table \ref{table:results}, for both the simulated and colored MNIST data, the two backbones with our IM algorithm achieve \emph{the best OOD generalization performances}.
Also, for the simulated data, the learned predictive heterogeneity enables backbone algorithms to equally treat the majority and minority inside data (i.e. low-performance gap between 'Major' and 'Minor'), and significantly benefits the OOD generalization.
Further, we plot the learned sub-populations of our IM algorithm in Figure \ref{fig:test3}.
From Figure \ref{fig:test3}, compared with KMeans and EIIL, our predictive heterogeneity exploits the spurious correlation between $V$ and $Y$, and enables the backbone algorithms to eliminate it.


%\textbf{Sensitivity of $K$}\quad We add more results of choosing different $K$s for this simulated experiment to show that the \emph{OOD generalization performances} of some typical algorithms plus our proposed method are not sensitive to the choices of $K$.
%\begin{figure}[h]
%    \centering
%    \includegraphics[width=0.7\textwidth]{./fig/appendix.png}
%    \caption{The out-of-distribution generalization error of our methods with Sub-population Balancing, IRM and IGA as backbones. Here we plot the errors of different backbones under $r=-2.7$, which introduces strong distributional shifts with training data.}
%    \label{fig:appendix-k}
%\end{figure}
%
%In Figure \ref{fig:appendix-k}, we show the out-of-distribution generalization error of our methods with Sub-population Balancing, IRM and IGA as backbones.
%We plot the OOD testing performances under $r=-2.7$, which has strong distributional shift with the training distribution.
%From the results, we can see that the performances of three OOD generalization methods \emph{do not be affected much} by the choice of $K$, and from Table \ref{table:results} , ours significantly outperforms all the baselines.

\subsubsection{Simulation Data of Hidden Variables}
\quad\textcolor{black}{Also, we add one more experiment to show that (1) when the chosen $K$ is smaller than the ground-truth, the performances of our methods will drop but are still better than ERM (2) when the chosen $K$ is larger, the performances are not affected much.}

\textcolor{black}{The input features $X=[S,T,V]\in\mathbb{R}^{10}$ consist of stable features $S\in\mathbb{R}^5$, noisy features $T\in\mathbb{R}^4$ and the spurious feature $V\in\mathbb R$:
$$
S\sim \mathcal{N}(2,2\mathbb I_5),\quad  T\sim \mathcal{N}(0, 2\mathbb I_4), \quad Y=\theta_S^TS + S_1S_2S_3+\mathcal{N}(0,0.5),
$$
and we generate the spurious feature via:
$$
V = \theta_V^e Y + \mathcal{N}(0, 0.3),
$$
where $\theta_V^e$ varies across sub-populations and is dependent on which sub-population the data point belongs to.
In training, we sample 8000 data points from $e_1$ with $\theta_V^1=3.0$, 1000 points from $e_2$ with $\theta_V^2=-1.0$, 1000 points from $e_3$ with $\theta_V^3=-2.0$ and 1000 points from $e_4$ with $\theta_V^4=-3.0$.
Therefore, the ground-truth number of sub-populations is 4.
In testing, we test the performances on $e_4$ with $\theta_V^4=-3.0$, which has strong distributional shifts from training data.
The average MSE over 10 runs are shown in Figure \ref{fig:appendix-rebuttal}.}


%\begin{figure}[h]
%    \centering
%    \includegraphics[width=0.6\textwidth]{./fig/appendix_rebuttal.png}
%    \caption{\textcolor{black}{The out-of-distribution generalization error of our methods with Sub-population Balancing, IRM and IGA as backbones for the added experiments. The ground-truth sub-population number is 4.}}
%    \label{fig:appendix-rebuttal}
%\end{figure}

\textcolor{black}{From the results, we can see that when $K$ is smaller than the ground-truth, increasing $K$ benefits the OOD generalization performance, and when $K$ is larger, the performances are not affected much.}

\textcolor{black}{For our IM algorithm, we think there are mainly two ways to choose $K$:}

\begin{itemize}
    \item \textcolor{black}{According to the predictive heterogeneity index: When the chosen $K$ is smaller than the ground-truth, our measure tends to increase quickly when increasing $K$; and when $K$ is larger than the ground-truth, the increasing speed will slow down, which could direct people to choose an appropriate $K$.}
    \item \textcolor{black}{According to the prediction model: Since our IM algorithm aims to learn sub-populations with different prediction mechanisms, one could compare the learned model parameters $\theta_1, \dots, \theta_K$ to judge whether $K$ is much larger than the ground-truth, i.e., if two resultant models are quite similar, $K$ may be too large (divide one sub-population into two). For linear models, one can directly compare the coefficients. For deep models, we think one can calculate the transfer losses across sub-populations.}
\end{itemize}


%\begin{figure}[b]
%\centering
%%\begin{minipage}{.5\textwidth}
%  \centering
%  \includegraphics[width=0.6\linewidth]{./fig/mnist.png}
%  \caption{Sub-population division on the MNIST data of our IM algorithm.}
%  \label{fig:test4}
%%\end{minipage}
%\vskip -0.25in
%\end{figure}


\begin{figure}[htbp]
\centering
\begin{minipage}{.55\textwidth}
  \centering
  \includegraphics[width=\linewidth]{./fig/appendix_rebuttal.png}
  \caption{The OOD generalization error of our methods with Sub-population Balancing, IRM and IGA as backbones for the added experiments. The ground-truth sub-population number is 4.}
  \label{fig:appendix-rebuttal}
\end{minipage}%
\hfill
\begin{minipage}{.42\textwidth}
  \centering
  \includegraphics[width=\linewidth]{./fig/mnist.png}
  \caption{Sub-population division on the MNIST data of our IM algorithm.}
  \label{fig:test4}
\end{minipage}
\vskip -0.2in
\end{figure}


\subsubsection{Colored MNIST}
Following \cite{arjovsky2019invariant}, we design a binary classification task constructed on the MNIST dataset.
Firstly, digits $0\sim4$ are labeled $Y=0$ and digits $5\sim 9$ are labeled $Y=1$. 
Secondly, noisy labels $\tilde{Y}$ are induced by randomly flipping the label $Y$ with a probability of 0.2.
Then we sample the colored id $V$ spurious correlated with $\tilde{Y}$ as 
\begin{equation}
	V=\Big\{\begin{array}{ll}
     +\tilde{Y}, &\text{with probability }r,  \\
     -\tilde{Y}, &\text{with probability }1-r.
\end{array}
\end{equation}

In fact, $r$ controls the spurious correlation between $\tilde{Y}$ and $V$. 
In \emph{training}, we randomly sample 10000 data points and set $r=0.85$, meaning that for 85\% of the data, $V$ is positively correlated with $\tilde{Y}$ and for the rest 15\%, the spurious correlation becomes negative, which causes data heterogeneity w.r.t. $V$ and $\tilde{Y}$.
In \emph{testing}, we set $r=0$ (\emph{strong negative spurious correlation}), bringing strong shifts between training and testing.

From the results in Table \ref{table:results}, for both the simulated and colored MNIST data, the two backbones with our IM algorithm achieve \emph{the best OOD generalization performances}.
We plot the learned sub-populations of our IM algorithm in Figure \ref{fig:test4}.
From Figure \ref{fig:test4}, the learned sub-populations of our method also reflect the different directions of the spurious correlation between digit labels $Y$ and colors (red or green), which helps backbone methods to avoid using colors to predict digits.























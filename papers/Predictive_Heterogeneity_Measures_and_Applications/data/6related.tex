\section{Related Work}
To the best of our knowledge, data heterogeneity has not converged to a uniform formulation so far, and has different meanings among different fields.
\cite{li1995definition} define the heterogeneity in \emph{ecology} based on the system property and complexity or variability.
\cite{rosenbaum2005heterogeneity} views the uncertainty of the potential outcome as unit heterogeneity in observational studies in \emph{economics}.
For \emph{graph} data, the heterogeneity refers to various types of nodes and edges (\cite{wang2019heterogeneous}).
More recently, in machine learning, several works of \emph{causal learning} \citep{peters2016causal, arjovsky2019invariant, koyama2020out, creager2021environment} and \emph{robust learning} \citep{sagawa2019distributionally} leverage heterogeneous data from multiple environments to improve the out-of-distribution generalization ability.
Specifically, invariant learning methods \citep{arjovsky2019invariant, koyama2020out, creager2021environment, zhou2022model} leverage the heterogeneous environment to learn the invariant predictors that have uniform performances across environments.
And in distributionally robust optimization field, \cite{sagawa2019distributionally, duchi2022distributionally} propose to optimize the worst-group prediction error to guarantee the OOD generalization performance.
However, in machine learning, previous works have not provided a precise definition or sound quantification of data heterogeneity, which makes it confusing and hard to leverage to develop more rational machine learning algorithms.

As for clustering algorithms, most algorithms only focus on the covariates $X$, typified by KMeans and Gaussian Mixture Model (GMM, \citep{reynolds2009gaussian}).
However, the learned clusters by KMeans can only reflect heterogeneous structures in $P(X)$, which is shown by our experiments.
Notably that our predictive heterogeneity could reflect the heterogeneity in $P(Y|X)$.
And the expectation maximization (EM, \citep{moon1996expectation}) can also be used for clustering.
However, our IM algorithm has essential differences from EM, for our IM algorithm infers latent variables that maximizes the predictive heterogeneity but EM maximizes the likelihood.
Also, there are methods \citep{creager2021environment} from the invariant learning field to infer environments.
Though it could benefit the OOD generalization, it lacks the theoretical foundation and only works in some settings.

\section{Discussion on differences with sub-group discovery}
\textcolor{black}{Subgroup discovery (SD, \citep{helal2016subgroup}) is aimed at extracting "interesting" relations among different variables ($X$) with respect to a target variable $Y$. Coverage and precision of each discovered group is the focus of such method. To be specific, it learns a partition on $P(X)$ such that some target label $y$ dominates within each group. The most siginficant gap between subgroup discovery and our predictive heterogeneity lies in the pattern of distributional shift among clusters: for subgroup discovery, $P(X)$ and $P(Y)$ varies across subgroups but there is a universal $P(Y|X)$. While for predictive heterogeneity $P(Y|X)$ differs across sub-population, which indicates diversified prediction mechanism. It is such disparity of prediction mechanism that inhibits   the performance of a universal predictive model on a heterogeneous dataset, which is the emphasis of OOD problem and group fairness.} 

\textcolor{black}{We think sub-group discovery is more applicable for settings where the distributional shift is minor while high explainability is required, since it generates simplified rules that people can understand. Also, sub-group discovery methods is suitable for the settings that only involve tabular data (typlically from a relational database), where the input features have clear semantics. 
And our proposed method could deal with general machine learning settings, including complicated data (e.g., image data) that involves representation learning.
Also, when people have to handle settings where data heterogeneity w.r.t. prediciton mechanism exists inside data, our method is more applicable.
However, both kinds of methods can be used to help people understand data and make more reasonable decisions.}

\section{Discussion on the Potential for fairness}
\textcolor{black}{We find combining our measure with algorithmic fairness is an interesting and promising direction and we think our measure has the potential to deal with algorithmic bias. 
Our method could generate sub-populations with possibly different prediction mechanisms, which could do some help in the following aspects:}

\textcolor{black}{\textbf{Risk feature selection}: we could select features according to our predictive heterogeneity measure to see what features bring the largest heterogeneity. If they are sensitive features, people should avoid their effects, and if they are not, they could direct people to build better machine learning models.}

\textcolor{black}{\textbf{Examine the algorithmic fairness}: we could use the learned sub-populations to examine whether a given algorithm is fair by calculating the performance gap across the sub-populations.}
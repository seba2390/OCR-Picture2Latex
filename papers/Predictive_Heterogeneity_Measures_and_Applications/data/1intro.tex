\section{Introduction}
% 大数据取得了很多进步
% 然而数据中存在着异质性，带来了很多挑战，若不加以注意会有很多问题，可以综述一些异质性的种类，
% 对于machine learning任务，predictive heterogeneity是比较重要的
% 现有工作没有具体形式化的描述，缺乏理论依据
% 本文贡献

% \xrz{Use `\textbackslash citep\{\}' instead of `(\textbackslash cite\{\})'. \textbackslash cite\{\} == \textbackslash citet\{\} is a subject. }





Big Data provides great opportunities for the growth and advancement of Artificial Intelligence (AI) systems. 
Nowadays, AI has emerged as a ubiquitous tool that permeates almost every aspect of the contemporary technological landscape, making it an indispensable asset in various fields and industries, such as scientific discoveries, policy-making, healthcare, drug discovery, and so on.
However, along with the widespread deployment of AI systems, the reliability, fairness, and stability of AI algorithms have been increasingly doubted.
For example, in sociological research \citep{2020Toward}, studies have shown that even for carefully designed randomized trials, there are huge selection biases, making scientific discoveries unreliable; in disease diagnosis, studies \citep{wynants2020prediction, roberts2021common} have found hundreds of existing AI algorithms fail to detect and prognosticate for COVID-19 using chest radiographs and CT scans; in social welfare, decision support AI systems for credit loan applications are found to exhibit biases against certain demographic groups \citep{hardt2016equality, verma2019weapons}; in various machine learning tasks, algorithms are faced with severely poor generalization performances under distributional shifts \citep{shen2021towards}, etc.
Another well-known example is Simpson's paradox, which brings false discoveries to the social research \citep{wagner1982simpson, hernan2011simpson}.


In order to mitigate the barriers that inhibit the deployment of AI systems in crucial, high-stakes applications, numerous researchers have taken recourse to the established research paradigm of model-centric AI, whereby they endeavor to develop innovative algorithms aimed at addressing these challenges.
However, in contemporary discourse about machine learning, it is increasingly evident that the challenges faced by algorithms extend beyond their intrinsic properties and extend to the nature of the data utilized in training these models. 
Specifically, the heterogeneity of data employed has emerged as a pivotal factor underlying these issues.
% heterogeneity definition % key problems
The concept of data heterogeneity encompasses the \emph{diversity} that exists within data, including \emph{variations in data sources, generation mechanisms, sub-populations}, and \emph{data structures}. 
Failure to account for such diversity in AI systems can lead to overemphasis on patterns found only in dominant sub-populations or groups, thereby resulting in false scientific discoveries, unreliable and inequitable decision-making, and poor generalization performance when confronted with new data. 
Given the high-stakes scenarios in which trustworthy AI is required, addressing the problem of data heterogeneity - an inherent property of big data - should receive increased attention. 
Moreover, in the current era of big models, where model development is approaching its limits, \emph{researchers have huge opportunities to explore the intricacies of big data}, thereby facilitating the development of AI in parallel with the advancement of AI models and algorithms.



% 相关文献中的定义：生态学、graph、causal、OOD中
Despite its widespread existence, due to its complexity, data heterogeneity has not converged to a uniform formulation so far, and has different meanings among different fields.
\cite{li1995definition} define the heterogeneity in \emph{ecology} based on the system property and complexity or variability.
\cite{rosenbaum2005heterogeneity} views the uncertainty of the potential outcome as unit heterogeneity in observational studies in \emph{economics}.
%\textcolor{black}{For \emph{graph} data, a heterogeneity graph refers to various types of nodes and edges in the graph (\cite{wang2019heterogeneous}).}
More recently, in machine learning, several works of \emph{causal learning} \citep{peters2016causal, arjovsky2019invariant, koyama2020out, liu2021heterogeneous,creager2021environment} and \emph{robust learning} \citep{sagawa2019distributionally, liu2022distributionally} leverage heterogeneous data from multiple environments to improve the out-of-distribution generalization ability.
\textcolor{black}{However, previous works have not provided a precise definition or sound quantification.
In this work, targeting at the prediction task in machine learning, from the perspective of \emph{prediction power}, we propose the predictive heterogeneity, a \emph{new type} of data heterogeneity.}


%From the machine learning perspective, the main concern is the possible negative effects of data heterogeneity on making predictions.
%Therefore, given the complexity of data heterogeneity, in this work, we focus on the data heterogeneity that affects the prediction of machine learning models, which could facilitate the building of machine learning systems, and we name it the \textbf{\emph{predictive heterogeneity}}.
%We raise the precise definition of predictive heterogeneity, which is quantified as the \emph{maximal additional predictive information} that can be gained by dividing the whole data distribution into sub-populations. 
%The new measure takes into account the model capacity and computational constraints, and can be reliably estimated from finite samples even in high dimensions with probably approximately correct (PAC) bounds.
%We theoretically analyze its properties and examine it under \emph{typical cases of data heterogeneity} \citep{fan2014challenges}.
%Additionally, we design the \textbf{\emph{information maximization (IM)}} algorithm to empirically explore the predictive heterogeneity inside data.
%Empirically, we find the explored heterogeneity is explainable and it provides insights for sub-population divisions in many fields, including \emph{agriculture, sociology, object recognition} and \emph{health-care}.
%And the explored sub-populations could be leveraged to find features that relate to the death of Covid-19, and enhance the out-of-distribution generalization performances of machine learning models, verified with both simulated and real-world data.

From a machine learning perspective, a major concern is the potential adverse effects of data heterogeneity on prediction accuracy. 
In this study, we propose predictive heterogeneity, which refers to the heterogeneity of data that impacts the performance of machine learning models. 
Our goal is to facilitate the development of machine learning systems by addressing this issue.
To this end, we introduce a precise definition of predictive heterogeneity that quantifies the maximal additional predictive information that can be obtained by dividing the entire data distribution into sub-populations. 
This measure takes into account the model capacity and computational constraints and can be accurately estimated from finite samples with probably approximately correct (PAC) bounds. 
We conduct a theoretical analysis of the properties of this measure and examine it under typical scenarios of data heterogeneity.
In addition, we propose the information maximization (IM) algorithm to empirically explore the predictive heterogeneity within data. 
Through our empirical investigations, we find that the explored heterogeneity is interpretable and provides valuable insights for sub-population divisions in various fields, such as agriculture, sociology, object recognition, and healthcare. 
Moreover, the identified sub-populations can be utilized to identify features related to Covid-19 mortality and enhance the out-of-distribution generalization performance of machine learning models. 
This has been confirmed through experiments with both simulated and real-world data.
In conclusion, our study contributes to the development of machine learning systems by providing a precise definition of predictive heterogeneity and a reliable measure for its estimation. 
Our findings demonstrate the potential of the IM algorithm for exploring predictive heterogeneity, assisting scientific discoveries and improving the generalization performance of machine learning models in real-world applications.









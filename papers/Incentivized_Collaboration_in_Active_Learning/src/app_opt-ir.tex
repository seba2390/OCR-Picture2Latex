\section{Proof of Theorem~\ref{thm:opt-ir}}\label{app:opt-ir}
\begin{proof}
    For any randomized optimal algorithm $\opt$, every realization of the internal randomness of $\opt$ must have the same query complexity and be optimal.
    Otherwise, there exists a realization with query complexity smaller than $\opt$, which conflicts with that $\opt$ is optimal. 
    Therefore, it suffices to prove the theorem for deterministic optimal collaborative algorithms.
    
    We will prove the theorem for deterministic algorithms by contradiction.
    Suppose that there exists a deterministic optimal collaborative algorithm $\opt$ that is not individually rational w.r.t. running itself as baseline. Hence, there exists an agent $i\in [k]$ such that $Q_{i}(\opt,\pi, \xset) > Q(\opt, \pi, \{X_i\})$.   
    In this case, we can construct another algorithm $\cA'$ with smaller label complexity, which will contradict  the optimality of $\opt$.
    
    The basic idea of $\cA'$ is to run $\opt$ over $(\pi,\{X_i\})$ first and to recover the labels of $X_i$. 
    Then, $\cA'$ simulates $\opt(\pi, \xset)$ and asks $\opt(\pi, \xset)$ what point to query. But whenever $\opt(\pi, \xset)$ asks to query the label of some point in $X_i$, since we already know the labeling of $X_i$, we can just feed $\opt(\pi, \xset)$ with these labels without actually asking agent $i$ to query them. 
    
    Thus, the label complexity of $\cA'$ is
    \begin{align*}
        Q(\cA',\pi,\xset) &= Q(\opt, \pi, \{X_i\}) + \sum_{j:j\neq i}Q_j(\opt, \pi, \xset)\\
        &< Q_{i}(\opt,\pi, \xset) + \sum_{j:j\neq i}Q_j(\opt, \pi, \xset) \\
        &= Q(\opt, \pi, \xset)= Q^*(\pi, \xset)\,,
    \end{align*}
    where the first inequality holds due to that $\opt$ is not IR and the last equality holds since $\opt$ is optimal.
    Since $Q^*(\pi, \xset)\leq Q(\cA',\pi,\xset)$ by definition, there is a contradiction.
\end{proof}
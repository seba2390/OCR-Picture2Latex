In this paper, we have initiated the study of collaboration in active learning in the presence of incentivized agents. We first show that an optimal collaborative algorithm is IR w.r.t. any baseline algorithm while approximate algorithms are not.
Then we provide meta-algorithms capable of producing IR/SIR algorithms given any baseline algorithm as input.
There are a few problems we leave open. First, relaxing the assumption that each agent $i$ has full knowledge of $X_{-i}$ (e.g., due to privacy concerns). Second, relaxing the assumption that agents provide reliable labels. 
% First, designing IR algorithms for stream-based active learning, or  relaxing the assumption that each agent has full knowledge of $X_{-i}$ (e.g., due to privacy concerns). 
Third, allowing different agents to have different baseline algorithms and be competitive with all of them (e.g., perhaps some agents care about different performance metrics such as average or worst case running time). Finally, finding a necessary and sufficient assumption(s) for the existence of efficient SIR algorithms will be an interesting direction (we only found a sufficient one).

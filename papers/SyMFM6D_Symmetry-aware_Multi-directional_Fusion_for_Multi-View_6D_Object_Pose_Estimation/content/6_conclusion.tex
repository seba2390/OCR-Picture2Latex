\section{Conclusion}

In this work, we present SyMFM6D, a novel approach for symmetry-aware multi-view 6D object pose estimation based on a deep multi-directional fusion network for RGB-D data. We additionally propose a novel method for predicting predefined 3D keypoints of symmetric objects based on a symmetry-aware objective function. Using the 3D keypoint predictions and an instance semantic segmentation, we compute the 6D poses of all objects in the scene simultaneously with least-squares fitting. Our experiments show that our symmetry-aware training procedure significantly improves the 6D pose estimation accuracy of both symmetric and non-symmetric objects due to synergy effects. Our method outperforms the state-of-the-art in single-view and multi-view 6D pose estimation on four very challenging datasets. We furthermore demonstrate the robustness of our approach towards inaccurately known camera poses and dynamic camera setups.

\subsection{Overview}
\begin{figure*}[h]
\begin{center}
\includegraphics[width=0.9\linewidth,height=5.5cm]{imgs/arch1_1.png}
\end{center}
%\caption{The overall structure of AsynDGAN. It is composed of two parts, a central generator $G$ and multiple distributed discriminators $D^1, D^2, \cdots, D^n$ in each medical entity. $G$ takes the mask as input and learns to fool the discriminators. Each discriminators learn to differentiate between the real images of current medical entities and synthetic images from $G$. Notice that each real image $y$ is only used in a specific discriminator located at one hospital/medical center, and only fake images, masks, and generator loss will be transferred between the central generator and hospitals/medical centers. The well-trained central generator then is used as an image provider to train the segmentation network as we expect the synthetic image to share the same or similar distribution with the real image.}
\caption{The overall structure of AsynDGAN. It contains two parts, a central generator $G$ and multiple distributed discriminators $D^1, D^2, \cdots, D^n$ in each medical entity. $G$ takes a task-specific input (segmentation masks in our experiments) and output synthetic images. Each discriminator learns to differentiate between the real images of current medical entity and synthetic images from $G$. The well-trained $G$ is then used as an image provider to train a task-specific model (segmentation in our experiments).}
\label{arch1}
\end{figure*}

Our proposed AsynDGAN is comprised of one central generator and multiple distributed discriminators located in different medical entities. 
In the following, we present the network architecture, object function and then analysis the procedure of the distributed asynchronized optimization.

\subsection{Network architecture}

%An overview of the proposed architecture is shown in Figure \ref{arch1}.
%The central generator, denoted as $G$, takes the segmentation masks as input and generates synthetic images to fool the discriminators. The local discriminators, denote as $D^1$ to $D^n$, learn to differentiate between the real images and the synthetic images. 
%Due to the sensitivity of patient images, the real images may not be accessed from the outside. Our architecture is naturally capable of such limitation since only the specific discriminator which located in the same medical entity could learn the real image. The synthetic images, masks, and the gradients will be transferred between the central generator and the medical entities while keeping the real image privately. 
%The generator will learn the joint distribution from different discriminators that belongs to different medical entities or diseases. Both generator and discriminator follow the convolution-Batchnorm-ReLu \cite{ioffe2015batch} basic block.
%The well-trained central generator will then be used as an image provider to train the segmentation network as we expect the synthetic image to share the same or similar distribution with the real image. We adopt U-Net \cite{ronneberger2015u} as the segmentation network to verify the efficiency of our AsynDGAN architecture. 
% The detailed architecture is described below.

An overview of the proposed architecture is shown in Figure~\ref{arch1}.
The central generator, denoted as $G$, takes task-specific inputs (segmentation masks in our experiments) and generates synthetic images to fool the discriminators. The local discriminators, denote as $D^1$ to $D^n$, learn to differentiate between the local real images and the synthetic images from $G$. 
Due to the sensitivity of patients' images, the real images in each medical center may not be accessed from outside. Our architecture is naturally capable of avoiding such limitation because only the specific discriminator in the same medical entity needs to access the real images. In this way, the real images in local medical entities will be kept privately. Only synthetic images, masks, and gradients are needed to be transferred between the central generator and the medical entities. 

The generator will learn the joint distribution from different datasets that belong to different medical entities. Then it can be used as an image provider to train a specific task, because we expect the synthetic images to share the same or similar distribution as the real images. In the experiments, we apply the AsynDGAN framework to segmentation tasks to illustrate its effectiveness. The U-Net~\cite{ronneberger2015u} is used as the segmentation model, and details about $G$ and $Ds$ designed for segmentation tasks are described below.


\subsubsection{Central generator}
For segmentation tasks, the central generator is an encoder-decoder network that consists of two stride-2 convolutions (for downsampling), nine residual blocks~\cite{he2016resnet}, and two transposed convolutions. All non-residual convolutional layers are followed by batch normalization~\cite{ioffe2015batch} and the ReLU activation. All convolutional layers use $3\times3$ kernels except the first and last layers that use $7\times7$ kernels.

\subsubsection{Distributed discriminators}
In the AsynDGAN framework, the discriminators are distributed over $N$ nodes (hospitals, mobile devices). Each discriminator $D_j$ only has access to data stored in the $j$-th node thus discriminators are trained in an asynchronized fashion. For segmentation, each discriminator has the same structure as that in PatchGAN~\cite{isola2016pix2pix}. The discriminator individually quantifies the fake or real value of different small patches in the image. Such architecture assumes patch-wise independence of pixels in a Markov random field fashion \cite{li2016precomputed,isola2017image}, and can capture the difference in geometrical structures such as background and tumors. 


\subsection{Objective of AsynDGAN}
The AsynDGAN is based on the conditional GAN~\cite{mirza2014conditiongan}. The objective of a classical conditional GAN is:
\begin{equation}
\begin{aligned}
\min\limits_{G}\max\limits_{D}V(D,G) &= \mathbb{E}_{x\sim s(x)}\mathbb{E}_{y\sim p_{data}(y|x)} [\log D(y|x)]\\
&+\mathbb{E}_{\hat{y}\sim p_{\hat{y}}(\hat{y}|x)} [\log(1-D(\hat{y}|x))]
\end{aligned}
\end{equation}
where $D$ represents the discriminator and $G$ is the generator. $G$ aims to approximate the conditional distribution $p_{data}(y|x)$ so that $D$ can not tell if the data is `fake' or not. The hidden variable $x$ is an auxiliary variable to control the mode of generated data~\cite{mirza2014conditiongan}. In reality, $x$ is usually a class label or a mask that can provide information about the data to be generated. Following previous works~(\cite{mathieu2015deep,isola2016pix2pix}), instead of providing Gaussian noise $z$ as an input to the generator, we provide the noise only in the form of dropout, which applied to several layers of the generator of AsynDGAN at both training and test time.

In the AsynDGAN framework, the generator is supervised by $N$ different discriminators. Each discriminator is associated with a subset of datasets. It is natural to quantify such a setting using a mixture distribution on auxiliary variable $x$. In another word, instead of given a naive $s(x)$, the distributions of $x$ becomes $s(x)=\sum\limits_{j\in[N]} \pi_js_j(x)$. For each sub-distribution, there is a corresponding discriminator $D_j$ which only receives data generated from prior $s_j(x)$. Therefore, the loss function of our AsynDGAN becomes:
\begin{equation}
\begin{aligned}
&\min\limits_{G}\max\limits_{D_1:D_N}V(D_{1:N},G) \\
&= \sum\limits_{j\in [N]} \pi_j \{\mathbb{E}_{x\sim s_j(x)}\mathbb{E}_{y\sim p_{data}(y|x)} [\log D_j(y|x)] \\
&+\mathbb{E}_{\hat{y}\sim p_{\hat{y}}(\hat{y}|x)} [\log(1-D_j(\hat{y}|x))]\}
%	&=\sum \pi_j\int\limits_{y} s_j(x)\int\limits_{x} p(y|x)log D_j(y,x)+q(y|x)log(1-D_j(y,x)) dxdy
\end{aligned}
\end{equation}
%	\begin{equation*}
%		L(q)=    \mathbb{E}_{x\sim p}[\pi_jp_j(x) log D_j(x)] + \mathbb{E}_{z\sim q} [q(z)log (1-D_j(z))]
%	\end{equation*}


\subsection{Optimization process}

\begin{figure}[t]
	\vspace{-2em}
	\begin{center}
		\includegraphics[width=5.5cm,height=5.2cm]{imgs/workflow.png}
	\end{center}
	%\caption{The optimization process: the solid arrows show the forward pass, the dotted arrows show gradient flow during the backward pass of our iterative update procedure. Solid blocks indicate that it is being updated while the dotted blocks indicate that the block is frozen during that update step. Red denotes source mask, and Blue denotes target real images}
	%\label{workflow}
	%\end{figure}
	%
	%
	%The optimization process is shown in Figure \ref{workflow}. In each iteration, a randomly sampled tuple $(x, y)$ is provided to the system. Then the network blocks are updated iteratively in the following order:
	%
	%\begin{enumerate}
	%	\item D-update: For each of the discriminator $i$ ($i<N$, N is the number of discriminators), it will calculate adversarial loss $ \mathcal{L}^i_{adv,D}$. The overall discriminator loss is given as: $\mathcal{L}_D=\sum^i_N \mathcal{L}^i_{adv,D}$
	%	\item G-update: After update all discriminators, the central generator will be updated using combination of adversarial loss $\mathcal{L}_{adv,G}$, L1 loss which encourages less blurring $\mathcal{L}_{L1,G}$ and a perception loss $\mathcal{L}_{perception,G}$. The overall generator loss is given as: $\mathcal{L}_G=\mathcal{L}_{adv,G}+\mathcal{L}_{L1,G}+\mathcal{L}_{perception,G}$
	%\end{enumerate}
	%
	%We will discuss the loss function in full detail in the next section.
	\caption{The optimization process of AsynDGAN. The solid arrows show the forward pass, and the dotted arrows show gradient flow during the backward pass of our iterative update procedure. The solid block indicate that it is being updated while the dotted blocks mean that they are frozen during that update step. Red and blue rectangles are source mask and target real image, respectively.}
	\label{workflow}
\end{figure}


The optimization process of the AsynDGAN is shown in Figure~\ref{workflow}. In each iteration, a randomly sampled tuple $(x, y)$ is provided to the system. Here, $x$ denotes the input label which observed by the generator, and $y$ is the real image only accessible by medical entities. Then the network blocks are updated iteratively in the following order:

%\begin{enumerate}[1)]
%	\item D-update: For each of the discriminators $j$ ( $j<N$, $N$ is the number of discriminators), it will calculate adversarial loss for $j$-th discriminator $D_j$. 
%	\item G-update: After update all discriminators, the central generator will then be updated using combination of adversarial loss $\sum_{j \in N} loss(D_j)$.
%\end{enumerate}

\begin{enumerate}[1)]
	\item D-update: Calculating the adversarial loss for $j$-th discriminator $D_j$ and update $D_j$, where $j=1, 2, \cdots, N$.
	\item G-update: After updating all discriminators, $G$ will be updated using the adversarial loss $\sum_{j=1}^N loss(D_j)$.
\end{enumerate}

This process is formulated as Algorithm~\ref{algo1}. We apply the cross entropy loss and in the algorithm and further analyze the AsynDGAN framework in this setting. We stress that the framework is general and can be collaborated with variants of GAN loss including Wasserstein distance and classical regression loss~\cite{arjovsky2017wasserstein,mao2017least}.


\begin{algorithm}[] 
	\caption{\small Training algorithm of AsynDGAN.
	}
	\begin{algorithmic}\label{algo1}
%		\label{alg:AGF}
		\FOR{number of total training iterations}
		\FOR{number of interations to train discriminator}
		\FOR{each node $j \in [N]$}
		\STATE{-- Sample  minibatch of of $m$ auxiliary variables $\{x^j_1,...,x^j_m\}$ from $s_j(x)$ and send to generator $G$.}
		\STATE{-- Generate $m$ fake data from generator $G$, $\{\hat{y}^j_1,...,\hat{y}^j_m\}\sim q(\hat{y}|x)$ and send to node $j$.}
		\STATE{-- Update the discriminator by ascending its stochastic gradient:
			\vspace{-0.5em}
			\[\nabla_{\theta_{D_j}} \frac{1}{m} \sum_{i=1}^m \left[
			\log D_j(y_i^j)
			+ \log (1-D_j(G(\hat{y}_i^j)))
			\right].
			\]}
			\vspace{-1.5em}
		\ENDFOR
		\ENDFOR
		\FOR{each node $j \in [N]$}
		\STATE{-- Sample  minibatch of $m$ auxiliary variables $\{x^j_1,...,x^j_m\}$ from $s_j(x)$ and send to generator $G$.}
		\vspace{-0.2em}		
		\STATE{-- Generate corresponding $m$ fake data from generator $G$, $\{\hat{y}^j_1,...,\hat{y}^j_m\}\sim q(\hat{y}|x)$ and send to node $j$.}
		\vspace{-0.2em}
		\STATE{-- Discriminator $D_j$ passes error to generator $G$.}
		\ENDFOR
		\STATE{-- Update $G$ by descending its stochastic gradient:
			\vspace{-0.5em}
			\[	\nabla_{\theta_G} \frac{1}{Nm} \sum_{j=1}^N\sum_{i=1}^m
			\log (1-D_j(G(\hat{y}^j_i))).\]}
			\vspace{-2em}
		\ENDFOR
		\\The gradient-based updates can use any standard gradient-based learning rule. We used momentum in our experiments.
	\end{algorithmic}
	\vspace{-0.3em}
\end{algorithm}



\subsection{Analysis: AsynDGAN learns the correct distribution}

In this section, we present a theoretical analysis of AsynDGAN and discuss the implications of the results. We first begin with a technical lemma describing the optimal strategy of the discriminator.

\begin{lemma}\label{lem1}
	When generator $G$ is fixed,  the optimal discriminator $D_j(y|x)$ is :\\
	\vspace{-0.5em}
	\begin{equation}
	D_j(y|x)=\frac{p(y|x)}{p(y|x)+q(y|x)}
	\end{equation}
\end{lemma}


Suppose in each training step the discriminator achieves its maxima criterion in Lemma \ref{lem1}, the loss function for the generator becomes:\\
\begin{equation*}
\begin{aligned}
\min\limits_{G}V(G)&= \mathbb{E}_{y}\mathbb{E}_{x\sim p_{data}(y|x)} [\log D(y|x)] \\
&+\mathbb{E}_{\hat{y}\sim p_{\hat{y}}(\hat{y}|x)} [\log(1-D(\hat{y}|x))]\\
&=\sum_{j\in[N]} \pi_j\int\limits_{y} s_j(x)\int\limits_{x} p(y|x)\log\frac{p(y|x)}{p(y|x)+q(y|x)}\\
&+q(y|x)\log\frac{q(y|x)}{p(y|x)+q(y|x)} dxdy\\
\end{aligned}
\end{equation*}
Assuming in each step, the discriminator always performs optimally, we show indeed the generative distribution $G$ seeks to minimize the loss by approximating the underlying distribution of data.
\begin{thm}
	Suppose the discriminators $D_{1\sim N}$ always behave optimally (denoted as $D^*_{1 \sim N}$), the loss function of generator is global optimal iff $q(y,x)=p(y,x)$ where the optimal value of $V(G,D^*_{1\sim N})$ is $-\log 4$. 
\end{thm}

\begin{remark}
	While analysis of AsynDGAN loss shares similar spirit with~\cite{goodfellow2014generative}, it has different implications. In the distributed learning setting, data from different nodes are often dissimilar. Consider the case where $\Omega(s_j(x)) \cap \Omega(s_k(y)) =\emptyset, \text{for } k \neq j$, the information for $p(y|x), y\in \Omega(s_j(x))$ will be missing if we lose the $j$-th node. The behavior of trained generative model is unpredictable when receiving auxiliary variables from unobserved  distribution $s_j(x)$.
	The AsynDGAN framework provides a solution for unifying different datasets by collaborating multiple discriminators.
\end{remark}
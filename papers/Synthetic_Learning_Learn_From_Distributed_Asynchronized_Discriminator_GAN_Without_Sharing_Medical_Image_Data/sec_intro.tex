\subsection{The privacy policies and challenges in medical intelligence}
The privacy issue, while important in every domain, is enforced vigorously for medical data. Multiple level of regulations such as HIPAA~\cite{annas2003hipaa,centers2003hipaa,mercuri2004hipaa,gostin2009beyond} and the approval process for the Institutional Review Board (IRB)~\cite{bankert2006institutional} protect the patients' sensitive data from malicious copy or even tamper evidence of medical conditions~\cite{mirsky2019ct}. Like a double-edge sword, these regulations objectively cause insufficient collaborations in health records.
For instance, America, European Union and many other countries do not allow patient data leave their country~\cite{kerikmae2017challenges,seddon2013cloud}. As a result, many hospitals and research institutions are wary of cloud platforms and prefer to use their own server. Even if in the same country the medical data collaborate still face a big hurdle.


\subsection{The restriction of the medical data accessibility}
It's widely known that sufficient data volume is necessary for training a successful machine learning algorithm~\cite{domingos2012few} for medical image analysis. 
However, due to the policies and challenges mentioned above, it is hard to acquire enough medical scans for training a machine learning model. In 2016, there were approximately 38 million MRI scans and 79 million CT scans performed in the United States~\cite{papanicolas2018health}. Even so, the available datasets for machine learning research are still very limited: the largest set of medical image data available to public is 32 thousand~\cite{yan2018deeplesion} CT images, only 0.02\% of the annual acquired images in the United States.
In contrast, the ImageNet~\cite{deng2009imagenet} project, which is the large visual dataset designed for use in visual object recognition research, has more than 14 million images that have been annotated in more than 20,000 categories.

\subsection{Learning from synthetic images: a solution}
In this work, we design a framework using centralized generator and distributed discriminators to learn the generative distribution of target dataset. In the health entities learning context, our proposed framework can aggregate datasets from multiple hospitals to obtain a faithful estimation of the overall distribution. The specific task (e.g., segmentation and classification) can be accomplished locally by acquiring data from the generator. Learning from synthetic images has several advantages:

\textbf{Privacy mechanism}:
The central generator has limited information for the raw images in each hospital. When the generator communicates with discriminators in hospitals, only information about the synthetic image is transmitted. Such a mechanism prohibits the central generator's direct access to raw data thus secures privacy.

\textbf{Synthetic data sharing}: The natural of synthetic data allows the generator to share the synthetic images without restriction. Such aggregation and redistribution system can build a public accessible and faithful medical database. The inexhaustible database can benefit researchers, practitioners and boost the development of medical intelligence.
  
\textbf{Adaptivity to architecture updates}: The machine learning architecture evolves rapidly to achieve a better performance by novel loss functions~\cite{sudre2017generalised,hochberg1964depth}, network modules~\cite{hoffman2016fcn, ronneberger2015u,milletari2016v,qu2019improving} or optimizers~\cite{ruder2016overview, zeiler2012adadelta, mason2000boosting,zhang2019taming,zhanglocal}. 
%To accelerate this process, modern machine learning frameworks like Pytorch~\cite{ketkar2017introduction} and Tensorflow~\cite{abadi2016tensorflow} provide more efficient ways to build and update networks and training configurations.
We could reasonably infer that the recently well-trained model may be outdated or underperformed in the future as new architectures invented. Since the private-sensitive data may be not always accessible, even if we trained a model based on these datasets, we couldn't embrace new architectures to achieve higher performance. Instead of training a task-specific model, our proposed method trains a generator that learns from distributed discriminators. Specifically, we learn the distribution of private datasets by a generator to produce synthetic images for future use, without worrying about the lost of the proprietary datasets.

%Our proposed approach
To the best of our knowledge, we are the first to use GAN to address the medical privacy problem. Briefly, our contributions lie in three folds: (1) A distributed asynchronized discriminator GAN (AsynDGAN) is proposed to learn the real images' distribution without sharing patients' raw data from different datasets. (2) AsynDGAN achieves higher performance than models that learn from real images of only one dataset. (3) AsynDGAN achieves almost the same performance as the model that learns from real images of all datasets.



%regulation...
%
%
%Especially when Adversarial Generative Network(GAN) attract everyone's attention, the privacy of medical data face a more serious challenge. Though we could apply GAN to achieve many goals like artifact reduction[adversarial sparse-view CBCT], domain adaption for different disease or modality[task driven...], data augmentation[], the GAN, like a double-edged sword, could also hurt us by tampering the medical images, ie., add or remove critical medical findings.


%Since patient data in European countries is typically not allowed to leave Europe, many hospitals and research institutions are wary of cloud platforms and prefer to use their own servers.


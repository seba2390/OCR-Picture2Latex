\noindent\textbf{Multimodal Action Classification and Detection.}
The field of action classification~\cite{i3d_carreira,two_stream_simonyan,c3d_tran} and action detection~\cite{sst_buch_cvpr17,daps,thumos2015,structured_segment_network} in RGB videos has been studied by the computer vision community for decades. The success in RGB videos has given rise to a series of studies on action recognition in multimodal videos~\cite{hbrnn,jiang2014easy,koppula2013learning,li2018visual,cad,wang2012mining}. Specifically, with the availability of depth sensors and joint tracking algorithms, extensive research has been done on action classification and detection in RGB-D videos~\cite{ni2013rgbd,shahroudy2017deep,shao2017performance,yu2016structure} as well as skeleton sequences~\cite{10-stream,lstm_trust_gate,attention_lstm,skeleton_visualization,ntu_rgbd,geometric_features}. Different from previous work, our model focuses on leveraging privileged modalities on a source dataset with abundant training examples. We show that it benefits action detection when the target training dataset is small in size, and when only one modality is available at test time.

\noindent\textbf{Video Understanding Under Limited Data.}
Our work is largely motivated by real-world situations where data and modalities are limited. For example, surveillance systems for fall detection~\cite{fall_detection_principles,fall_detection_survey} often face the challenge that annotated videos of fall incidents are hard to obtain, and more importantly, yhr recording of RGB videos is prohibited due to privacy concerns. Existing approaches to tackling this challenge include using transfer learning~\cite{luo2017label,transfer_learning_survey} and leveraging noisy data from web queries~\cite{chen2015webly,liang2016learning,yeung2017learning}. Specifically to our problem, it is common to transfer models trained on action classification to action detection.

The transfer learning methods are proved to be effective. However, it requires the source and target domains to have the same modalities. In reality, the source domain often contains richer modalities. For instance, suppose the depth video is the only available modality in the target domain, it remains nontrivial to transfer the other modalities (\textit{e.g.} RGB, optical flow) even though they are readily available in the source domain and could make the model more accurate. Our method provides a practical approach to leveraging the rich multimodal information in the source domain, benefiting the target domain of limited modalities.

\noindent\textbf{Learning Using Privileged Information.} Vapnik and Vashist~\cite{privileged_vapnik} introduced a \textit{Student-Teacher} analogy: in real-world human learning, the role of a teacher is crucial to the student's learning process since the teacher can provide explanations, comments, comparisons, metaphors, etc. They proposed a new learning paradigm called Learning Using Privileged Information (LUPI), where at training time, additional information about the training example is provided to the learning model. At test time, the privileged information is not available, and the student operates without the supervision of the teacher~\cite{privileged_vapnik}.

Several work employed privileged information (PI) on SVM classifiers~\cite{privileged_vapnik,hidden_information_wang}. Ding et al.~\cite{ding2015missing} handled missing modality transfer learning using latent low-rank constraint. Recently, the use of privileged information has been combined with deep learning in various settings such as PI reconstruction~\cite{privileged_on_depth_shi,pedestrian_xu}, information bottleneck~\cite{information_bottleneck_motiian}, and Multi-Instance Multi-Label (MIML) learning~\cite{yang2017miml}. The idea more related to our work is the combination of distillation and privileged information, which will be discussed next.

\noindent\textbf{Knowledge Distillation.}
Hinton et al.~\cite{distillation_hinton} introduced the idea of knowledge distillation, where knowledge from a large model is distilled to a small model, improving the performance of the small model at test time. This is done by adding a loss function that matches the outputs of the small network to the high-temperature soft outputs of the large network~\cite{distillation_hinton}. Lopez-Paz et al.~\cite{unifying} later proposed a generalized distillation that combined distillation and privileged information. This approach was adopted by~\cite{hallucination_hoffman} and~\cite{distillation_gupta} in cross-modality knowledge transfer. Our graph distillation method is different from prior work~\cite{distillation_hinton,li2017learning,unifying,privileged_on_depth_shi} in that the privileged information contains multiple modalities and that the distillation directions and weights are dynamically learned rather than being predefined by human experts.

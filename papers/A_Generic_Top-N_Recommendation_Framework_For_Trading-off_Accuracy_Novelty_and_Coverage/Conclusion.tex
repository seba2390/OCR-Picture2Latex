\section{Conclusion}
\label{sec:conclusion}
This paper presents a generic top-$\size$ recommendation framework for  trading-off accuracy, novelty, and coverage. To achieve this, we profile the users according to their preference for long-tail novelty. We examine various measures, and formulate an optimization problem to learn these user preferences from interaction data.  We then integrate the user preference estimates in our generic framework, GANC.  Extensive experiments on several datasets confirm that there are trade-offs between accuracy, coverage, and novelty. Almost all re-ranking models increase coverage and novelty at the cost of accuracy. However, existing re-ranking models typically rely on rating prediction models, and are hence more effective in dense settings. Using a generic approach, we can easily incorporate a suitable base accuracy recommender to devise an effective solution for both sparse and dense settings.  %Our results  also indicate there is no single method that outperforms other methods in all metrics. However our techniques obtain a significant improvement in coverage, while  . 
Although we integrated the  long-tail novelty preference estimates into a re-ranking framework, their use-case is not limited to these frameworks. In  the future, we intend to explore the temporal and topical dynamics of long-tail novelty preference, particularly in settings where contextual information is  available.  
%We achieve these objectives without using any additional contextual information.


\iffalse
While we focused on promoting long-tail items across users, we did not consider diversity of individual top-$\size$ recommendations, a factor that has been shown to positively affect consumer satisfaction. This is one direction for future work. Moreover, the sequential setting  in our work, creates a dependency between different batches, where,  the items recommended to a batch of users, depends on those recommended to previous batches. This dependency is created through the parameter $\mathbf{f}$, that is updated every time a top-$\size$ set  is allocated to a batch of users. A future direction for our work is to estimate a distribution over $\mathbf{f}$ that allows us to independently solve the problem for each user, leading to improvements across all performance metrics, including recommendation time. 

We design algorithms that take advantage of the structure in the value functions to obtain both efficient and scalable solutions. 
We design an algorithm that takes advantage of the structure in the value functions to obtain both efficient and scalable solutions. 

\textcolor{red}{Our  sequential  algorithms can be applied for batch recommendation contexts,~e.g., personalized email marketing, where based on prior interaction data between users and items,  a new round of recommendations must be sent to all users in the system.  However, the independent coverage algorithms lift the sequential setting restrictions and allow it be applied for re-ranking the output of base recommender in any setting. }A future direction for our work is to incorporate explicit diversity metrics in the framework. 
\fi


%We have a presented a submodular maximization framework to systematically trade-off relevance and diversity in recommendations to individual users and coverage across the item-space. This ensures both consumer and producer satisfaction. We model users according to their risk and focusing degrees and promote long-tail items to the right group of consumers. Consequently, we obtain a significant improvement in coverage while maintaining reasonable levels of user satisfaction. Furthermore, our methods are able to achieve a more balanced distribution across the set of recommended items. In the future, we plan to investigate the effect of using alternative base recommender systems. 

%Future Work
%However most of these methods assume that the ratings are missing at random (MAR). Since our method of generating recommendations is based on the completed matrix, assuming MAR might introduce additional bias, we will use methods which assume that the ratings at missing not at random (MNAR),explored in~\cite{steck2010training, icml2014c2_hernandez-lobatob14}. 	 
%Long Tail %Recently, authors in~\cite{cremonesi2010performance} conducted extensive experiments to evaluate the performances of various matrix factorization-based algorithms and neighborhood models on the task of recommending long tail items. Their experimental results show that long tail recommendation leads to a decrease in accuracy for all algorithms. They also showed that for this task, SVD outperforms other state-of-the-art algorithms. 

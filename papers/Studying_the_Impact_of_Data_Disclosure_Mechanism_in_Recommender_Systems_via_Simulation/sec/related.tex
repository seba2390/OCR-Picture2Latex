\section{Related Work}
In this section, we will review previous works which are highly related to ours in the three fields, i.e., recommender systems, privacy research in recommender systems, and simulation.



\subsection{Recommendation Systems} 
Recommender systems play an essential role in today's web service platforms, e.g., e-commerce~\cite{Linden:IC03:Amazon,xie21explore} and social media~\cite{Covington:recsys16:Deep,Ying:kdd18:Graph}, since they provide a personalized and convenient tool for every user to alleviate the information overload problem or explore serendipity things.
Besides the attention of industry, recommender systems have also become the most active direction in information retrieval research~\cite{Zhang:csur19:Deep,Quadrana:csur19:Sequence,Wu:Graph}.

Early works on recommender systems mainly model the users' interests statically as collaborative filtering (CF) task with implicit feedback.
Early representative works include item-base CF algorithms~\cite{Sarwar:www01:Item,Linden:IC03:Amazon} and matrix factorization (MF)~\cite{Mnih:nips08:Probabilistic,Koren:Computer09:Matrix}
Recently, deep learning has also revolutionized collaborative filtering.
One line of research seeks to improve the CF models with the representation learned from auxiliary information, e.g., text~\cite{Wang:kdd15:Collaborative} and images ~\cite{Wang:www17:What} using deep learning models.
While more mainstream way is to take the place of conventional CF models with more powerful neural models, like neural collaborative filtering (NCF)~\cite{He:www17:Neural} and graph neural network based recommendation models~\cite{Ying:kdd18:Graph,He:sigir20:LightGCN}.


In recent years, sequential recommendation has become another mainstream task in recommender systems since it can better capture users' dynamic interests from their historical behaviors~\cite{Quadrana:csur19:Sequence}.
Sequential recommendation has also experienced the development process from traditional markov chain based models~\cite{Shani:kmlr05:MDP,Rendle:www10:Factorizing} to neural sequential models, e.g., GRU4Rec~\cite{Hidasi:ICLR2016:gru4rec,hidasi2018recurrent} and self-attention models~\cite{kang2018self,Sun:cikm19:BERT4Rec}.
Considering that sequential recommendation has become the mainstream in real-world applications~\cite{lv2019sdm,Li:cikm19:Multi}, we study the proposed task with sequential models in this paper. 


\subsection{Privacy in Recommender Systems}
The research about privacy concerns in recommender systems can be classified into two categories: privacy-preserving recommendation modeling and decision making in privacy.

\textbf{Privacy-preserving recommendation modeling} mainly aims to protect user's sensitive information from being leaked by designing specific models.
An emerging paradigm is to use federated learning to train recommender systems without uploading users' data to the central server
\cite{Qi:emnlp20:Privacy,Muhammad:kdd20:FedFast,Lin:sigir20:Meta,wang:vldbj2021:fast}.
Federated learning dramatically enhances user privacy since user data never leaves their devices.
However, recent works have shown that federated learning can unintentionally leak information through gradients~\cite{Zhu:nips19:Deep,li2019privacy} and is also vulnerable to attacks like membership inference attacks~\cite{melis2019exploiting,nasr2019comprehensive}.
To address such issues, differential privacy~\cite{Dwork:Algorithmic}, a powerful mathematic framework for privacy, has been employed to guarantee user privacy in the procedure of recommender systems~\cite{McSherry:kdd09:Differentially,Berlioz:recsys15:Applying,shin2018privacy,Gao:sigir20:DPLCF}.
The basic idea of this paradigm is to add random noise into the recommender system to prevent information leakage.
As a promising framework, one limitation of differential privacy is that it usually decreases performance~\cite{Domingo:cacm21:Limits}.

\textbf{Decision making in privacy} from other disciplines, e.g., economic~\cite{lin2019valuing}, management sciences~\cite{Culnan:os99:Information}, and humanâ€“computer interaction~\cite{Knijnenburg:recsys12:Inspectability,Knijnenburg:tiis13:Making}, mainly focus on studying the problem like where privacy concerns come from and how to mitigate them.
They mainly study the procedure of user's decision making about information disclosure using the \textit{privacy calculus theory}~\cite{Laufer:si77:Privacy,Culnan:os99:Information}, which views privacy as an economic commodity.
It is to say that the user decides to disclose his/her information by weighing the anticipated risks of disclosing personal information against the perceived utility.
Numerous works have studied the factors that influenced the user's decision using questionnaires or mock-up applications~\cite{Knijnenburg:recsys12:Inspectability,Knijnenburg:tiis13:Making,Chen:CHI18:This,Zhang:hcs19:Proactive}.
Multiple studies highlight that ``control'' is a key factor in decision making about privacy, and providing control over the recommendation process to users can reduce their privacy concerns~\cite{Zhang2014-oa,Chen:CHI18:This}.
Going a step further, in this paper, we give users not only control over whether or not to disclose data, but also control over which data to disclose.
Then we investigate the consequences caused by this novel setting, including how users make choices and how different platform mechanisms and recommendation models perform.


Another close work to ours is \cite{Xin:nips14:Controlling} that studies a recommendation task where a small set of ``public'' users who disclose all their ratings (large amount) and a large set of ``private'' users refuse to disclose their data.
Our work differs from \cite{Xin:nips14:Controlling} in the following aspects:
\begin {enumerate*} [label=\roman*\upshape)]
\item Most importantly, as explained in the introduction and last paragraph, our goal is not the performances of the recommender systems;
\item We provide users with more fine-grained control over their data; 
\item our task is built on implicit feedback, which is the mainstream of the real-world applications.
\end {enumerate*} 




\subsection{Simulation}





Recent years have witnessed the wide applications of the simulation techniques among various scenarios, e.g., recommendation \cite{jannach2015recommenders,lucherini2021t,chaney2018algorithmic,yao2017beyond}, autopilot \cite{osinski2020simulation}, traffic scheduling \cite{chu2019multi,abdoos2020cooperative} and robotic \cite{rao2020rl}.
The primary reason to utilize simulation is that straightforwardly conducting experiments in the real world may remain too expensive~\cite{virtual_taobao} and risky \cite{osinski2020simulation}.
Besides, the solutions derived from simulations can be transferred to solve the real-world problems~\cite{virtual_taobao,tobin2017domain}.


In the research areas of recommender systems, it is of great significance to utilize the carefully designed simulation environments to efficiently evaluate recommendation policy~\cite{virtual_taobao} or draw insightful conclusions for specific studies such as societal impact analysis~\cite{chaney2018algorithmic}.
\citet{ie2019reinforcement} builds upon a simulation environment for slate-based recommender systems, which facilitates the recommendation policy evaluation. 
\citet{virtual_taobao} proposes to utilize the historical user behavior data to train the simulator and verifies that the policies trained in the simulator achieve superior online performance.
A series of works \cite{lucherini2021t,chaney2018algorithmic,yao2017beyond} utilize simulation environments to get in touch with user society impacts over recommender systems such as fairness and societal biases. 

There also exist a series of works to simulate user decisions to maximize their personalized utilities~\cite{jiang2017information,samadi2012advanced,kallstrom2019tunable}.
Typically, the user is modeled as a rational agent whose policy can be learned following a trial-and-error schema such as RL-based algorithms \cite{katehakis1987multi,kallstrom2019tunable}.
In this work, each user is modeled as a rational agent to optimize his (her) unique data disclosure policy under a designed platform mechanism. The efficiency of recommender systems is also evaluated within such a simulation environment.








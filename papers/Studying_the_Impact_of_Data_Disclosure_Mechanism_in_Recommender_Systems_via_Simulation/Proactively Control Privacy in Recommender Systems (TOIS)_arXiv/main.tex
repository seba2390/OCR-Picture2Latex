
\pdfoutput=1
\documentclass[acmsmall]{acmart}

\input{preamble}
\input{color}
\newtheorem{assumption}{Assumption}


\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\newcommand{\si}[1]{{\scriptstyle \mathcal{S}_i#1}}
\newcommand{\di}[1]{{\scriptstyle \mathcal{D}_i#1}}

\newcommand{\czq}[1]{\textcolor{black}{{#1}}}

\renewcommand{\arraystretch}{1.2}


\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

\setcopyright{acmcopyright}
\copyrightyear{2022}
\acmYear{2022}
\acmDOI{XXXXXXX.XXXXXXX}


\acmJournal{TOIS}
\acmVolume{37}
\acmNumber{4}
\acmArticle{111}
\acmMonth{8}





\begin{document}

\title{Studying the Impact of Data Disclosure Mechanism in Recommender Systems via Simulation}

\author{Ziqian Chen}
\email{eric.czq@alibaba-inc.com}
\affiliation{%
  \department{Damo Academy}
  \institution{Alibaba Group}
  \city{Hangzhou}
  \state{Zhejiang}
  \postcode{311121}
  \country{China}
}

\author{Fei Sun}
\authornote{Fei Sun is the corresponding author and now works at ICT, CAS.}
\orcid{0000-0002-6146-148X}
\email{ofey.sf@alibaba-inc.com}
\affiliation{%
  \department{Damo Academy}
  \institution{Alibaba Group}
  \city{Beijing}
  \postcode{100102}
  \country{China}
}

\author{Yifan Tang}
\email{yifan.tang95@gmail.com}
\affiliation{%
  \department{Luohan Academy}
  \institution{Alibaba Group}
  \city{Hangzhou}
  \state{Zhejiang}
  \postcode{311121}
  \country{China}
}

\author{Haokun Chen}
\email{hankel.chk@alibaba-inc.com}
\affiliation{%
  \department{Damo Academy}
  \institution{Alibaba Group}
  \city{Hangzhou}
  \state{Zhejiang}
  \postcode{311121}
  \country{China}
}

\author{Jinyang Gao}
\email{jinyang.gjy@alibaba-inc.com}
\affiliation{%
  \department{Damo Academy}
  \institution{Alibaba Group}
  \city{Hangzhou}
  \state{Zhejiang}
  \postcode{311121}
  \country{China}
}


\author{Bolin Ding}
\email{bolin.ding@alibaba-inc.com}
\affiliation{%
  \department{Damo Academy}
  \institution{Alibaba Group}
  \city{Seattle}
  \state{WA}
  \postcode{98004}
  \country{United States}
}


\begin{abstract}

Recently, privacy issues in web services that rely on users' personal data have raised great attention.
Despite that recent regulations force companies to offer choices for each user to opt-in or opt-out of data disclosure, real-world applications usually only provide an ``all or nothing'' binary option for users to either disclose all their data or preserve all data with the cost of no personalized service.


In this paper, we argue that such a binary mechanism is not optimal for both consumers and platforms.
To study how different privacy mechanisms affect users' decisions on information disclosure and how users' decisions affect the platform's revenue, we propose a privacy aware recommendation framework that gives users fine control over their data. 
In this new framework, users can proactively control which data to disclose based on the trade-off between anticipated privacy risks and potential utilities.
Then we study the impact of different data disclosure mechanisms via simulation with reinforcement learning due to the high cost of real-world experiments.
The results show that the platform mechanisms with finer split granularity and more unrestrained disclosure strategy can bring better results for both consumers and platforms than the ``all or nothing''  mechanism adopted by most real-world applications.


\end{abstract}


\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10002951.10003317.10003347.10003350</concept_id>
<concept_desc>Information systems~Recommender systems</concept_desc>
<concept_significance>500</concept_significance>
</concept>
  <concept>
  <concept_id>10002978.10003029.10011150</concept_id>
  <concept_desc>Security and privacy~Privacy protections</concept_desc>
  <concept_significance>500</concept_significance>
  </concept>
</ccs2012>
\end{CCSXML}
  
\ccsdesc[500]{Information systems~Recommender systems}
\ccsdesc[500]{Security and privacy~Privacy protections}

\keywords{Recommender System; Privacy; GDPR}



\maketitle

\input{sec/intro}
\input{sec/framework}
\input{sec/simulation}
\input{sec/exp}
\input{sec/related}

\section{Conclusions and Future Work}

This paper proposes a privacy aware recommendation framework based on privacy calculus theory to study what will happen if the platform gives users control over their data.
To avoid the great cost in online experiments, we propose to use reinforcement learning to simulate the users' privacy decision making under different platform mechanisms and recommendation models on public benchmark datasets.
The results show a well-designed data disclosure mechanism can perform much better than the popular ``all or nothing'' binary mechanism.
Our work provides some insights to improve current rough solutions in privacy protection regulations, e.g., opt-in under GDPR and opt-out under CCPA.

This paper only takes the first step in studying users' privacy decision making under different platform mechanisms, and several directions remain to be explored.
First, a more complex and accurate privacy cost function can help us better understand users' privacy decision making.
In this work we have modeled different users with their individual privacy sensitivity weights, and one may modify the privacy cost function on the effects of the users' trust towards the platform in the future.
Second, more sophisticated platform mechanisms are also worth exploring.
Recent mechanism design works also turn to the perspectives of deep neural network based mechanism designs, which can be explored with our proposed framework.
Last but not least, deploying online experiments and analyzing users' decisions in real-world can facilitate further researches.



\clearpage

\bibliographystyle{ACM-Reference-Format}
\bibliography{sample-base}



\end{document}

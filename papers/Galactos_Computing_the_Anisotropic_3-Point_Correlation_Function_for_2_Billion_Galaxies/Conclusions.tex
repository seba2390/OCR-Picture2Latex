\section{Conclusions}
In this paper we have presented Galactos, an algorithm to calculate both the isotropic and anisotropic 3PCF for the largest simulation dataset available (of about 2 billion halos) in 20 minutes on Cori. 
Data partitioning is performed by a scalable k-d tree, resulting in good load-balancing. 
Its single-node performance has been highly optimized for Intel Xeon Phi, reaching 39\%\ of peak, with efficient use of vectorization and the full memory hierarchy. 
Galactos presents almost perfect weak- and strong-scaling, and achieves a sustained 5.06~PF across 9636 nodes. 


The enormous speed of Galactos offers the opportunity to substantially accelerate all analysis steps for an anisotropic 3PCF measurement. In addition to the 3PCF of the data, a full 3PCF analysis demands running the algorithm on hundreds to thousands of catalogs with spatially random clustering. These random catalog results enable the removal of spurious signal generated by the survey geometry. 
This correction step is key for extracting constraints on cosmological parameters from the data, but increases the amount of computation required to solve the science problem by orders of magnitude compared to calculating the 3PCF for the data alone. 

Current observational datasets consist of roughly 10 million galaxies, a problem solvable in seconds on Cori with Galactos. In the next decade, these datasets will expand by several orders of magnitude to over 10 billion galaxies with surveys such as DESI, LSST, Euclid, and WFIRST. Galactos' speed (and scaling capabilities) will be essential for enabling the full scientific return from these datasets. 
In short, the algorithmic and computational developments of Galactos make the 3PCF of all future astronomical surveys for the next 20-30 years a solved problem with HPC. 

Furthermore, even with current resources, Galactos would enable computation of the 3PCF for all galaxies in the observable Universe (100 billion) in less than a day.



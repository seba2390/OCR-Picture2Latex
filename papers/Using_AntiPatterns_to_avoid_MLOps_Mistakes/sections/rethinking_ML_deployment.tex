\iffalse 
\begin{figure*}[!ht]
    \begin{minipage}{0.45\textwidth}
    \centering
    \includegraphics[scale=0.38]{figures/modelops_stage_1.png}
    \subcaption{Current state of ML deployment pipeline evaluation focuses only on the single stage performance of the ML model.}
    \label{fig:ml_deployment_1}
    \end{minipage}
    \hfill
    \begin{minipage}{0.45\textwidth}
    \centering
    \includegraphics[scale=0.38]{figures/modelops_stage_2.png}
    \subcaption{ML deployment pipelines are actually multi-stage decision systems with a hierarchical setup of learning, notification and intervention layers, each requiring evaluation.}
    \label{fig:ml_deployment_2}
    \end{minipage}
    \vfill
    \begin{minipage}{0.6\textwidth}
    \centering
    \includegraphics[scale=0.4]{figures/modelops_stage_3.png}
    \subcaption{A characterization (with state-specific illustrations) of the various operational states the ML deployment pipeline can assume.}
    \label{fig:ml_deployment_3}
    \end{minipage}
    \caption{Characterization of the updated ML deployment pipeline and the need for monitoring an expanded set of possible operational states.}
\end{figure*}
\fi 
Machine Learning (ML) models are usually evaluated with metrics (e.g., precision, recall, confusion matrices serve as evaluation metrics in a classification setting) that are solely focused on characterizing the performance of the core learning model. However, production systems are often decision guidance systems with multiple additional notification (e.g., a process that raises an alert when the core learning model yields a particular prediction) and intervention (e.g., a process that carries out an appropriate action based on the results of the notification system) layers built on top of the core learning layer. 

Fig.~\ref{fig:ml_deployment_1} showcases the outcomes in a traditional (ML focused) evaluation pipeline wherein an ML model predicts a transaction to have a \emph{Favorable} or \emph{Unfavorable} outcome. Depending on the application, the definition of what is considered \emph{Favorable} or \emph{Unfavorable} may differ. 

For illustration, let us consider a fraud detection application, wherein an unfavorable outcome would be defined as a fraudulent transaction while legitimate transactions would be considered favorable outcomes. An ML model tasked with detecting fraudulent transactions would predict whether each transaction was \emph{Favorable} or \emph{Unfavorable}. In this context, Fig.~\ref{fig:ml_deployment_1} indicates that the deployed ML model pipeline may enter four possible states during its operation life-cycle. However, Fig.~\ref{fig:ml_deployment_2} showcases a slightly more realistic ML pipeline wherein notification (send alerts) and intervention (take appropriate action) layers are added on top of the ML model decisions to appropriately raise alerts or intervene to arrest progress of a potentially fraudulent transaction detected by the ML model.

The addition of these alerting and notification mechanisms which are imperative and ubiquitous in enterprise ML settings augment the number of possible states the ML pipeline may enter during its operation. These new states the model may enter create more nuanced situations with new dilemmas which are not highlighted by a simplistic evaluation approach like the one indicated in Fig.~\ref{fig:ml_deployment_1}. For example, if we observe the state the pipeline reaches if the ML model predicts a transaction to be fraudulent (i.e., \emph{unfavorable}) and the notification pipeline does not notify the client of the model decision, then if the transaction is actually fraudulent, then this situation is fraught with ethical ramifications. This exhaustive state representation of the ML decision pipeline in Fig.~\ref{fig:ml_deployment_3} allows us to explicitly add high penalties to such states allowing the ML, notification and intervention models to be trained cognizant of such penalties, essentially allowing fine-grained control of the learning and decision process. A more rigorous approach is to use a reinforcement learning formulation to track decision making and actions as models are put in production.
\section{Numerical reconstructions}\label{sec:reconstructions} %bk 2021-11-28

In this section we give some details and show some reconstructions
of the algorithms described in section \ref{sec:recon_meth}.
We assume single mode excitation, set $\beta_i=1$ and
break the reconstructions into three separate paradigms as previously indicated
depending on which time ranges are feasible to be measured.

\input recon_figs.tex

We assume single mode excitation, set $\beta_i=1$ and 
break the reconstructions into three separate paradigms as indicated
in Section~\ref{sec:recon_meth} 
depending on which time ranges are feasible to be measured.

\noindent
\subsection{Full time measurements.}

The leftmost graph in Figure \ref{fig:h_and_hath} shows the actual time trace
of $h(t)$ 
over the range $0\leq t\leq 40$
for a damping model with three terms 
$b_i\partial_t^{\alpha_i}$, 
$i=1,2,3$.
Note the damped oscillatory behaviour evident and the range shown
is the one we are labelling as ``full-time'' despite the fact that we
will later look at the important case of 
the very long term
behaviour of the solution where the time values are substantially outside
of this range.  This time range terminology is highly dependent on the
values of critical constants in the model.
These include the size of the domain (which determines the scaling of the
eigenvalues $\{\lambda_n\}$), the wave speed $c$ and of course the strength
of the damping given by the coefficients $\{b_i\}$.
In our reconstructions we will typically take these constants to be of
approximate order unity but note the dependence on these quantities
and the effect that a substantial change would make.

To obtain this $h(t)$ our damping constants are of order 
$\sim 0.1-0.2$ and the combined term 
$\Lambda=c^2\lambda$ 
is taken to be unity.
Changes to the former would modify the time-decrease in $h$ and changes to the 
latter would alter the frequency of the oscillations.

The rightmost graph in Figure~\ref{fig:h_and_hath} shows the logarithm of the
Laplace transform $\hat{h}(s)$ together with the values of $\hat{h}_i(s)$ after
iteration $i$ of the scheme.
%%%%%%%%%%%%%%%%%%%
\begin{figure}[ht]
\hbox to \hsize{\hfill\copy\figureone\hfill\copy\figuretwo\hfill}
\small
\caption{\small {\bf Profiles of $h(t)$ and $\hat{h}(s)$, actual and after
iterations 1 and 2.}}
\label{fig:h_and_hath}
\end{figure}
%%%%%%%%%%%%

This demonstrates two important facts.
First, the very fast convergence of the scheme in the sense of the
convergence of the target Laplace transform function as the parameters
$\{\alpha_i,b_i\}$ are resolved.
The actual $\hat{h}(s)$ is shown by the solid black line, the initial approximation
by the dotted red curve and the first iteration by the dashed green curve
which, at this scale is already almost indistinguishable from the actual $\hat{h}$.
Second, given this it should be quite feasible to obtain reasonably
accurate values the parameters $\{\alpha_i,\,b_i\}$.
In addition, assuming we excite the system with an initial condition
equal to an eigenfunction corresponding to an actual eigenvalue $\lambda$,
we will be able to reconstruct the value of $c^2$ from 
the composite $\Lambda=c^2\lambda$. %bk 2021-11-28

\smallskip
In this situation, to reconstruct the parameters $\{\alpha_i,\,b_i,\, c^2\}$
we work directly with the representation $\hat{h}(s)$ or more exactly with its
logarithm which is a more convenient form for computing the Jacobian
\begin{equation}\label{eqn:log_F(s)}
\log\bigl(\hat{h}(s)\bigr) =
\log\Bigl( s + \sum_1^n b_i s^{\alpha_i-1}\Bigr) -
\log\Bigl( s^2 + \sum_1^n b_i s^{\alpha_i} + c^2\lambda\Bigr).
\end{equation}
Of course, to obtain $\hat{h}(s)$ we must approximate
the integral $\hat{h}(s) = \int_0^\infty e^{-st}h(t)\,dt$ and this indeed does
require full time measurements.
However, we do not actually need the values of the analytic function
$\hat{h}(s)$ for all $s$ for the Newton scheme and so if we only use $s$
values with $s>s_0$ then this allows us to ignore very large time measurements
and indeed we truncated these to $t\leq 40$.

The reconstruction of the components in the function $\hat{h}(s)$ is shown
graphically in Figure~\ref{fig:b_and_alpha} and in tabular form in 
Table~\ref{Table:Full_time_trace}.
The exact values were $\alpha=\{0.25, \, 0.5, \, 0.75\}$, $b=\{0.2,\,0.25,\,0.1\}$, $\Lambda=4$. %bk 2021-11-28
Note that we have included the value of the residual here and keeping track of
this value allows the iteration scheme to terminate when saturation has
occurred.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[H]
\centering
\small
\footnotesize
\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
\hline
iter & $\alpha_1$ & $\alpha_2$ & $\alpha_3$ & $b_1$ & $b_2$ & $b_3$ & $\Lambda$ & residual\\
\hline
	0 & 0.3000 & 0.6000 & 0.8000 & 0.3000 & 0.3750 & 0.1500 & 3.500 & {} \\
1 & 0.2448 & 0.5590 & 0.7946 & 0.1907 & 0.2612 & 0.1098 & 4.003 & 0.035032 \\
2 & 0.2506 & 0.5254 & 0.7695 & 0.2057 & 0.2747 & 0.1190 & 4.000 & 0.004371 \\
3 & 0.2492 & 0.5253 & 0.7700 & 0.2060 & 0.2784 & 0.1190 & 4.000 & 0.000075 \\
4 & 0.2491 & 0.5254 & 0.7700 & 0.2060 & 0.2748 & 0.1192 & 4.000 & 0.000000 \\
\hline
\end{tabular}
\small
\footnotesize
\caption{\bf Recovery of  damping terms and unknown $\Lambda$ from full time values.}
 \label{Table:Full_time_trace}
\end{table}
%%%%%%%%%%%%%%%%%%%
\begin{figure}[h]
\small
\hbox to \hsize{\hfill\copy\figurefour\hfill\copy\figurethree\hfill}
\caption{\small {\bf reconstructed values of $\{b_i\}$ and $\{\alpha_i\}$.
%The zero index is the initial approximation
The symbols in red are the exact values.}}
\label{fig:b_and_alpha}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\subsection{Large time measurements.}

Here we are trying to simulate the asymptotic values of the constituent
powers of $t$ occurring in the data function $h(t)$.
This was achieved by using a sample of points between $t_{\rm min}$
and $t_{\rm max}$.

\revision{\subsubsection*{A Newton based approach}}
We apply Newton's method to recover the constants $\{p_i,c_{k,\ell}\}$ in 
\[
\begin{aligned}
h(t) &= 
c_{1,1} t^{-p_1}
+c_{1,2} t^{-p_2}
+c_{1,3} t^{-p_3}
+c_{2,1} t^{-2p_1}
+c_{2,2} t^{-2p_2}
+c_{2,3} t^{-2p_3}
+c_{2,4} t^{-p_1-p_2}
\\&\quad+c_{2,5} t^{-p_2-p_3}
+c_{2,6} t^{-p_3-p_1}
+c_{3,1} t^{-3p_1}
+c_{3,2} t^{-3p_2}
+c_{3,3} t^{-2p_1-p_2}
+c_{3,4} t^{-p_1-2p_2}
\\&\quad+c_{3,5} t^{-2p_1-p_3}
+c_{3,6} t^{-p_1-2p_3}
+c_{3,7} t^{-2p_2-p_3}
+c_{3,8} t^{-p_2-2p_3}
+O(t^{-3p_3})
\end{aligned}
\]
which results from the expansion \eqref{eqn:hsing} in case of three terms,
and then recover $\alpha_i=p_i$ and $b_i=c_{1,i}\Gamma(1-p_i)$  
In the above we have neglected the term $t^{-3\alpha_3}$ as this would not arise
from the Tauberian theorem in the case that the largest power
$\alpha_3 \geq \frac{1}{3}$.
We may also have to exclude other terms such as  
$t^{-2\alpha_1-\alpha_2}$
if
$2\alpha_1 + \alpha_2 \geq 1$.
In practice, during the iteration process, terms should be included or excluded
in the code depending on this criterion: we did so by checking
if the argument passed to the $\Gamma$ function would be negative in which
case the term is deleted from use for that iteration step.

Values for the table shown below were
$t_{\rm min}=5\times 10^4$ and $t_{\rm max}=2\times 10^5$.
As a general rule, terms with small $\alpha$ values can be resolved
with a smaller value of $t_{\rm max}$, but for, say the recovery of
a pair of damping terms with $\alpha_i>0.8$, a larger value 
of $t_{\rm max}$ with commensurate accuracy will be needed.

The case of three damping terms 
$\{b_i\partial^{\alpha_i}_t\}_{i=1}^3$ 
with
$\alpha = \{\frac{1}{4},\,\frac{1}{3},\,\frac{2}{3}\}$ and $b_i=0.1$
is shown in Table~\ref{Table:large_tt} below.
The initial starting values were taken to be between ten and thirty percent
of the actual.
These are shown in the line corresponding to iteration $0$.

\begin{table}[ht]
\centering
\footnotesize
\begin{tabular}{|c|c|c|c|c|c|c|c|}
\hline
iter & $\alpha_1$ & $\alpha_2$ & $\alpha_3$ & $b_1$ & $b_2$ & $b_3$ & residual\\
\hline
0 & 0.2000 & 0.3000 & 0.6000 & 0.130 & 0.080 & 0.110 &\\			%bk 2021-11-28
1 & 0.2409 & 0.3572 & 0.6168 & 0.112 & 0.089 & 0.107 & 0.548761\\
2 & 0.2477 & 0.3307 & 0.6531 & 0.102 & 0.091 & 0.104 & 0.104843\\
3 & 0.2499 & 0.3346 & 0.6650 & 0.100 & 0.099 & 0.092 & 0.005124\\
4 & 0.2500 & 0.3332 & 0.6668 & 0.100 & 0.099 & 0.090 & 0.003625\\
5 & 0.2500 & 0.3331 & 0.6658 & 0.100 & 0.100 & 0.090 & 0.001134\\
6 & 0.2500 & 0.3332 & 0.6658 & 0.100 & 0.100 & 0.092 & 0.000578\\
7 & 0.2500 & 0.3332 & 0.6660 & 0.100 & 0.100 & 0.093 & 0.000357\\
8 & 0.2500 & 0.3333 & 0.6665 & 0.100 & 0.100 & 0.094 & 0.000240\\
\hline
\end{tabular}
\small
\caption{Large time values with 3 damping terms}
 \label{Table:large_tt}
\end{table}

There are features here that are typical of such reconstructions.
The reconstruction method resolves the lowest fractional power $\alpha_1$
and its coefficient $b_1$ quickly as this term is the most persistent one
for large times:
essential numerical convergence for $\{\alpha_1,\,b_1\}$ is obtained
by the third iteration.
The next lowest power and coefficient lags behind; here $\{\alpha_2,\,b_2\}$ is already at the stated accuracy by the fifth iteration.
In each case the power is resolved faster and more accurately than its
coefficient.
The third term also illustrates this;  the power is essentially resolved by
iteration 8, but in fact its coefficient $b_3$ is not resolved to the third
decimal place until iteration number 30.
This is seen quite clearly in the singular values of the Jacobian:
the largest singular values correspond to the lowest $\alpha$-values
and the smallest to the coefficients of the largest $\alpha$-powers.

As might be expected, resolving terms whose powers are quite close is
in general more difficult.
This is relatively insignificant for low $\alpha$ values.
For example, with $\alpha_1=0.2$ and $0.22<\alpha_2<0.25$ say, correct
resolution will be obtained although the coefficients will take longer to
resolve than indicated in Table~\ref{Table:large_tt}.
On the other hand if, say $\alpha_1=\frac{1}{4}$ and $\alpha_2=0.85$,
$\alpha_3=0.9$, then with the indicated range of time values used the code
will fail to recover this last pair.
If this is sensed and now only a single second power is requested
this will give a good estimate for $\alpha_2$ but its coefficient will
be overestimated.
Also, as indicated previously, $\alpha$ values close to one require
an extended time measurement range to stay closer to the asymptotic regime of $u(t)$.

\revision{
Note that the starting values were at least ten percent away from the exact values and one cannot expect the convergence radius of Newton's methods to be much larger for a problem exhibiting as high nonlinearity as the one at hand.
Still, let us point to the fact that in the single term case we do not need any starting guesses but obtain very good results directly from the asymptotic formulas \eqref{eqn:alpha-larget}, \eqref{eqn:b1-larget}. This might give the idea of using the asymptotics to construct starting guesses in the multi term case and then apply Newton. However, it is unclear how the asymptotics could yield starting values for terms other than the first one. A (theoretical, as it turns out) possibility for exploiting asympotics in the multi term case is described below. 
}
\Margin{Ref 2 (iv)}

\revision{\subsubsection*{Sucessive sequential use of asymptotic formulas}}
A few words are in order about an approach that from the above discussion
might seem a good or even a better alternative.

Since each damping term 
$b_i \partial^{\alpha_i}_t$ 
contributes a time trace term
with large time behaviour $c_i t^{-\alpha_i}$, it is feasible to take
$T$ sufficiently large so that
$c_i t^{-\alpha_i} <\!\!\!< c_1 t^{-\alpha_1}$ for $t>T$, that is, all but the
smallest damping power is negligible, and this can then be recovered.
In successive steps then we subtract this from the data $h$ to
get $h_1(t) = h(t) - c_1t^{-\alpha_1}$ and now seek to recover the next
lowest $\alpha$ power from the large time values of $h_1(t)$  in a range
$(\delta T,T)$ for $0<\delta<1$.
Then these steps can be repeated until there is no discernible signal remaining
in the sample interval $t_{\rm min},t_{\rm max}$.

This indeed works well under the right circumstances
for recovering two $\alpha$ values but the
coefficients $\{b_i\}$ are less well resolved.
It also requires a delicate splitting of the time interval and gives a
much poorer resolution of the two terms in the case where, say
$\alpha_1=0.2$ and $\alpha_2=0.25$  than that recovered from the Newton scheme.
For the recovery of three damping terms this was in general quite
ineffective.

Every time an $\alpha_i$ has been recovered, the remaining signal is significantly smaller than the previous, leading to an equally significant drop in effective accuracy.
Also, even if we just make a small error in the coefficient $b_i$, the relative error that is caused by this becomes completely dominant for large times. 

In short, this is an elegant and seemingly constructive approach to showing uniqueness for a finite number of damping terms. However, it has limited value from a numerical recovery perspective when used under a wide range of parameter values.

\subsection{Small time measurements.}

In this case we are simulating measurements taken over a very limited initial
time range: in fact we take the measurement interval to be $t\in [0, 0.1)$.
The line of attack is to use the known form of $\hat{h}(s)$ for large values of $s$
and convert the powers of $s$ appearing into powers of $t$ for small times
using the Tauberian theorem.
In case of two damping terms
this gives
\begin{equation*}%\label{eqn:small_t-form}
\begin{aligned}
%f_{\tiny\rm{small}}(t) &= 
%- \frac{\lambda}{\Gamma(4)})t^3 + \frac{\lambda^2}{\Gamma(6)}t^5
%-\frac{\lambda^3}{\Gamma(8)}t^7 \\
%&\quad - c_{1,1}t^{3-p_1} - c_{2,1}t^{3-p_2}) - c_{3,1}t^{3-p_3}  
% + c_{1,4}t^{5-p_1} + c_{2,4}t^{5-p_2} + c_{3,4}t^{5-p_3} \\
%&\quad + c_{1,6}t^{5-2p_1} + c_{2,6}t^{5-2p_2} + c_{3,6}t^{5-2p_3} 
% + c_{4,6}t^{5-p_1-p_2} + c_{5,6}t^{5-p_1-p_3}+ c_{6,6}t^{5-p_2-p_3}\\
-c^2\lambda h_{\tiny\rm{small}}(t)-h_{\tiny\rm{small}}''(t) 
&
=c_{1,1} t^{1-\alpha_1}
+c_{1,2} t^{1-\alpha_2}
+c_{2,1} t^{3-\alpha_1}
+c_{2,2} t^{3-\alpha_2}
\\&\quad
+c_{2,3} t^{3-2\alpha_1}
+c_{2,4} t^{3-\alpha_1-\alpha_2}
+c_{2,5} t^{3-2\alpha_2}
\end{aligned}
\end{equation*}
where each term $c_{k,\ell}$ is computed in terms of
$\{\alpha_i\}$, $\{b_i\}$ and $\lambda$, %bk 2021-11-28
cf. \eqref{eqn:smalltime}. 
							         
The values of $\{\alpha_i,c_{k,\ell}\}$ 
were then computed from the data by a Newton
scheme then finally converted back to the derived values of
$\{\alpha_i\}$ and $\{b_i\}$.

The exact values chosen were
$\alpha = \{0.25,\ 0.2\}$, $b = \{0.1,\ 0.1\}$ and the
initial starting guesses were $\alpha = \{0.3,\ 0.16\}$, $b = \{0.08,\ 0.12\}$.
We show the progression of the iteration in 
Table~\ref{tab:smalltime}. 

\begin{table}[H]
\centering
\small
\footnotesize
\begin{tabular}{|c|c|c|c|c|c|}
\hline
iter & $\alpha_1$ & $\alpha_2$ & $b_1$ & $b_2$ & residual\\
\hline
0 & 0.3000 & 0.1600 & 0.0800 & 0.1200 &  \\
1 & 0.2848 & 0.1673 & 0.0821 & 0.1160 & 0.034308 \\
2 & 0.2632 & 0.1944 & 0.0863 & 0.1142 & 0.024472 \\
3 & 0.2554 & 0.2016 & 0.0862 & 0.1140 & 0.002015 \\
4 & 0.2537 & 0.2033 & 0.0861 & 0.1139 & 0.000444 \\
5 & 0.2534 & 0.2036 & 0.0861 & 0.1139 & 0.000059 \\
6 & 0.2534 & 0.2036 & 0.0861 & 0.1139 & 0.000016 \\
7 & 0.2534 & 0.2036 & 0.0861 & 0.1139 & 0.000010 \\
\hline
\end{tabular}
\small
	\caption{{\small\bf Small time values with 2 damping terms.}
\label{tab:smalltime}}
\end{table}

While theory predicts reconstructibility of an arbitrary number of terms in both cases,
there is a clear difference in ability to reconstruct terms between the small time and the large time asymptotics. 
First of all, the method we described effectively only recovers two terms with small time measurements, as compared to three in the large time. 
The $b_i$ coefficients, which are always harder to obtain than the $\alpha_i$ exponents, are much worse than in the small time than in the large time regime.
This is partly explained by the higher degree of ill-posedness due to the necessity of differentiating the data twice. 




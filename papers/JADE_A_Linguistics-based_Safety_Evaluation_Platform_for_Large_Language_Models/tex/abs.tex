\begin{abstract}
\noindent\textbf{Abstract:} In this paper, we present \textit{JADE}, a targeted linguistic fuzzing platform which strengthens the linguistic complexity of seed questions to simultaneously and consistently break a wide range of widely-used LLMs categorized in three groups: eight open-sourced Chinese, six commercial Chinese and four commercial English LLMs. JADE generates three safety benchmarks for the three groups of LLMs, which contain unsafe questions that are highly threatening: the questions simultaneously trigger harmful generation of multiple LLMs, with an average unsafe generation ratio of \textbf{$70\%$} (please see the table below), while are still natural questions, fluent and preserving the core unsafe semantics. We release the benchmark demos generated for commercial English LLMs and open-sourced Chinese LLMs in the following link: \url{https://github.com/whitzard-ai/jade-db}. For readers who are interested in evaluating on more questions generated by JADE, please contact us.


% This results in a safety benchmark of natural questions which simultaneously trigger harmful generation of a wide range of widely-used LLMs below, in over $70\%$ test cases.



% Table generated by Excel2LaTeX from sheet 'Sheet2'
\begin{center}
\scalebox{0.65}{
    \begin{tabular}{lccccccc}
    \toprule
    \multirow{2}[3]{*}{\textbf{Group}} & \multicolumn{4}{c}{\multirow{2}[3]{*}{\textbf{Model Name}}} & \multicolumn{3}{c}{\textbf{Unsafe Generation Ratio}} \\
\cmidrule{6-8}          & \multicolumn{4}{c}{}          & \textbf{Average} & \textbf{Least} & \textbf{Most} \\
    \midrule
    \multirow{2}[2]{*}{\textbf{Open-sourced LLM (Chinese)}} & ChatGLM & ChatGLM2 & InternLM & Ziya  & \multirow{2}[2]{*}{74.13\%} & \multirow{2}[2]{*}{49.00\%} & \multirow{2}[2]{*}{93.50\%} \\
          & Baichuan & BELLE & MOSS  & ChatYuan2 &       &       &  \\
    \midrule
    \textbf{Commercial LLM (English)} & ChatGPT & Claude & PaLM2 & LLaMA2 & 74.38\% & 35.00\% & 91.25\% \\
    \midrule
    \multirow{2}[2]{*}{\textbf{Commercial LLM (Chinese)}} & Doubao & Wenxin Yiyan & ChatGLM & SenseChat & \multirow{2}[2]{*}{77.5\%} & \multirow{2}[2]{*}{56.00\%} & \multirow{2}[2]{*}{90.00\%} \\
          & Baichuan & ABAB  & \multicolumn{2}{c}{\footnotesize{(For the detailed info., please refer to Table 2)}} &       &       &  \\
    \bottomrule
    \end{tabular}}%
\end{center}





\textit{JADE} is based on Noam Chomsky's seminal theory of transformational-generative grammar. Given a seed question with unsafe intention, \textit{JADE} invokes a sequence of generative and transformational rules to increment the complexity of the syntactic structure of the original question, until the safety guardrail is broken. Our key insight is: Due to the complexity of human language, most of the current best LLMs can hardly recognize the invariant evil from the infinite number of different syntactic structures which form an unbound example space that can never be fully covered. Technically, the generative/transformative rules are constructed by native speakers of the languages, and, once developed, can be used to automatically grow and transform the parse tree of a given question, until the guardrail is broken. Besides, \textit{JADE} also incorporates an active learning algorithm to incrementally improve the LLM-based evaluation module, which
iteratively optimizes the prompts for evaluation with a small amount of annotated data, to effectively strengthen the alignment with the judgement made by human experts. For more evaluation results and demo, please check our website: \url{https://whitzard-ai.github.io/jade.html}.

\noindent\pxd{{\footnotesize[\textbf{Content Warning: This paper contains examples of harmful language.}]}}
\end{abstract}





% Featured by OpenAI's ChatGPT, the rise of aligned large language models (LLM) is recognized as a milestone in the history of AI, and catalyzes wild imagination on the arrival of \textit{Artificial General Intelligence} (AGI). To achieve harmless generation, many approaches are proposed to align the AI generation contents with human values, or called \textit{AI alignment}. This equips pretrained large language models with the ability of generating safe responses under unsafe requests. However, we find human language is more complex than the current best LLM can handle. To validate this point, 
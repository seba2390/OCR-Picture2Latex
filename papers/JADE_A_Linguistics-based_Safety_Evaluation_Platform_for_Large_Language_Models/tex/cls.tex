\section{Conclusion and Future Works}
In this paper, we revealed the unexplored yet fundamental limitation of aligned LLMs in handling unsafe questions of excessive linguistic complexity. Following such a motivation, we presenet a linguistic fuzzing platform called \textit{JADE}, which exploits the theory of transformational-generative grammar to automatically increase the complexity of a given seed question, without modifying the semantics, until the target model starts to generate inappropriate contents. To facilitate the automatic testing process, we also propose an LLM-based evaluation which relies on less human annotation via the idea of active prompt tuning. We validate our observation on a wide range of open-sourced and commercial LLMs. Our results show \textit{JADE} is effective in turning seed questions into highly threatening PoC questions of strong transferability among different LLMs. Besides, \textit{JADE} incurs much less costs in finding a successful PoC question in terms of both LLM queries and the gradient-free nature. Our framework is generic: When testing the normal functionality, one may also set the evaluation goal as
whether the generated answer to a given question is correct. Our grammar-based mutation can be
used to find many known generalization bugs including the ``Reversal Curse'' \cite{Berglund2023TheRC}. In the final part of this work, we systematize and explain some of the known failure modes of aligned LLMs from our novel perspective of the linguistic complexity upper bound, which empirically justifies the conjecture made by Noam Chomsky and other famous scholars on the limits of AI \cite{false_promise,marcus2023sentence}. 

% We hope it turns out to be a promsing portal for future works to understand the gap between the current best of AI and us, the \textit{homo sapiens}.   

\noindent\textbf{Future Research Directions.} In future work, our team will further deepen the existing results in \textit{unsafe generation detection} and \textit{safety protection for LLMs}.

\begin{itemize}
\item \textbf{Unsafe Generation Detection for LLM}: In this paper, we mainly rely on iterating to optimize the safety evaluation prompts, and achieving a relatively accurate auto-evaluation module, based on manual annotation of a small number of QA pairs of high uncertainty through active prompt fine-tuning. The current auto-evaluation module mainly supports binary labels, while the content generated by large models may vary in terms of \textbf{unsafe types and severity}. Therefore, in our future work, we will further improve the auto-evaluation module to achieve more fine-grained detection in terms of unsafe generation level and category. Additionally, we also hope to explore how to generate more interpretable detection results from the judgement LLM, which can assist users and model vendors in understanding the details of safety principle violation and constructing more responsible LLMs.

\item \textbf{Safety Protection for LLM}: Existing static safety benchmarks are limited in reflecting the actual risks of LLMs in adversarial scenarios. Although LLMs can refuse to answer inappropriate questions in daily uses, they cannot fundamentally learn how to generate safely. In this paper, we aim to position the \textit{JADE} platform as a starting point to further refine the linguistic mutation strategy, which would be more effective in  generating highly threatening test questions. The questions found by JADE can evolve and tailored for aligning with LLMs iteratively. Moreover, considering the challenge of handling linguistic complexity for the current best LLMs, it would be meaningful to further develop approaches to transfer a sentence of high complexity to its core semantics before querying the LLM. The tradeoff between helpfulness and protection effects should be well-balanced. A more fundamental solution is to incorporate the grammatical knowledge into the LLM at its design stage, which requires innovation in pretraining and finetuning algorithms for LLMs \cite{Wang2019TreeTI,Sartran2022TransformerGA}.  
\end{itemize}
\noindent\textit{Remark.} In the future, we plan to release more highly threatening questions generated by JADE. 
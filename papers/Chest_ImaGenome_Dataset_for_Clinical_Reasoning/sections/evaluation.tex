\section*{Dataset Evaluation}

% the notebooks for generating the Chest ImaGenome evaluation results in the tables below is provided under the "analysis" directory.


Table \ref{tab:object-attribute} (`analysis/generated via object-attribute-relation\_evaluation.ipynb')
reports the NLP pipeline's precision, recall and F1 scores for extracting the relationships between objects (anatomical locations) and CXR attributes (findings, diseases, technical assessment, etc) in the scene graphs. Since at their most granular level, the annotations are at the sentence-level, we report both the sentence-level and report-level results for 500 reports from the first exam of each patient. However, for most purposes, report-level annotations (the last annotation for each object-attribute relation for a study) are most suitable for downstream uses. The majority of the false positive results are due to failure to detect the laterality (i.e., left v.s. right) of attributes correctly as this information can often cross sentence boundaries, which is beyond the current NLP pipeline.

\begin{table}[t!]
\parbox{.45\linewidth}{
\centering
\footnotesize{
    \begin{tabular}{ccc}
    \hline
    Metric&Sentence-level&Report-level\\
    \hline
    \# of annotations&21593&16569\\
    Precision&0.932&0.938\\
    Recall&0.945&0.939\\
    F1-score&0.939&0.939\\
    \hline
    \end{tabular}
\caption{\label{tab:object-attribute} Object-attribute relations. Estimated inter-annotator (IA) agreement on 500 reports from first study: 0.984.}
}
}
% \hfill 
\hspace{15pt}
\parbox{.45\linewidth}{
\centering
\footnotesize{
    \begin{tabular}{ccc}
    \hline
    Metric&Sentence-level&Report-level\\
    \hline
    \# of annotations&5154 / 1787&3993 / 1374\\
    Precision&0.831 / 0.856&0.832 / 0.858\\
    Recall&0.590 / 0.663&0.762 / 0.790\\
    F1-score&0.690 / 0.747&0.796 / 0.823\\
    \hline
    \end{tabular}
\caption{\label{tab:object-comparison}Object-object comparison relations (attribute-sensitive / attribute-blind).
IA on 500 reports from second study: 0.962.}
}
}
\vspace{-0.5cm}
\end{table}

Table \ref{tab:object-comparison} (generated via `analysis/object-object-comparison-relation\_evaluation.ipynb')
shows the NLP results for comparison relations (improved, worsened, no change) between various anatomical locations described for the current study as compared to the patient's previous study. The results are again shown at both sentence-level and report-level for 500 reports from the second exam of each patient. For the attribute-sensitive results, a relation is correct if it describes the correct comparison and attribute for an object. Attribute-blind relations are correct as long as the object-to-object comparison relation is correct. Since comparison relations can cross both sentence and report boundaries, the performance from the current per sentence-based NLP pipeline is lower.

Lastly, Table \ref{tab:object-detect} in Supplementary shows more detailed evaluation at the object-level (anatomical location). The F1 scores are calculated for relations extracted between objects and attributes from the 500 gold standard reports (first study), which is a breakdown of report-level results in Table \ref{tab:object-attribute} for the bounding boxes (Bboxes) shown.  Using the $1,000$ CXR images in the gold standard dataset, we also calculated the intersection over union (IoU) between the automatically extracted Bboxes and the validated and corrected Bboxes (analysis/object-bbox-coordinates\_evaluation.ipynb). Since we used an agree-or-correct annotation strategy for more efficient annotation, we also show the percentage of bounding boxes requiring manual correction in the gold dataset and the percentage missing in the final Chest ImaGenome dataset. Missing bounding boxes could be due to Bbox extraction failure or the anatomical location genuinely not being visible in the image (i.e., cut off or not in field of view), which is not uncommon for the costophrenic angles and apical zones. Per attribute level performance is available on the PhysioNet repository (`analysis/affirmed\_attributes\_eval4paper.csv').

% \begin{table}[ht]
% \centering
% \begin{tabular}{|l|l|l|}
% \hline
% Condition & n & p \\
% \hline
% A & 5 & 0.1 \\
% \hline
% B & 10 & 0.01 \\
% \hline
% \end{tabular}
% \caption{\label{tab:example}Legend (350 words max). Example legend text.}
% \end{table}


% \hide{\begin{table}[t!]
% \centering
% \caption{CXR image object detection evaluation results. \** These anatomical locations are extracted by the Bbox pipeline but they are not manually annotated in the gold standard dataset due to resource constraints. \*** The mediastinum bounding boxes were not not directly annotated due to resource constraints. Mediastinum's bounding box boundary can be derived from the ground truth for the upper mediastinum and the cardiac silhouette. \il{move this to supplementary? Also, label goes after caption not inside it.}
% }\label{tab:object-detect}
% \resizebox{\textwidth}{!}{%
% \begin{tabular}{|l|c|c|c|c|c|}
% \hline
% \multicolumn{1}{|c|}{\textbf{\begin{tabular}[c]{@{}c@{}}Bbox name \\ (object)\end{tabular}}} & \multicolumn{1}{c|}{\textbf{\begin{tabular}[c]{@{}c@{}}Object-attribute relations  \\  frequency (500 reports)\end{tabular}}} & \multicolumn{1}{c|}{\textbf{\begin{tabular}[c]{@{}c@{}}Relationships F1\\ (500 reports)\end{tabular}}} & \multicolumn{1}{c|}{\textbf{\begin{tabular}[c]{@{}c@{}}Bbox IoU \\ (over 1000 images)\end{tabular}}} & \multicolumn{1}{c|}{\textbf{\begin{tabular}[c]{@{}c@{}}\% Bboxes corrected \\ (1000 images)\end{tabular}}} & \multicolumn{1}{c|}{\textbf{\begin{tabular}[c]{@{}c@{}}\% Relations missing \\ Bbox coordinates \\ (over whole dataset)\end{tabular}}} \\ \hline
% left lung & 1453 & 0.933 & 0.976 & 9.90\% & 0.03\% \\ \hline
% right lung & 1436 & 0.937 & 0.983 & 6.30\% & 0.04\% \\ \hline
% cardiac silhouette & 633 & 0.966 & 0.967 & 9.70\% & 0.01\% \\ \hline
% mediastinum & 601 & 0.952 & ** & ** & 0.02\% \\ \hline
% left lower lung zone & 609 & 0.932 & 0.955 & 8.60\% & 2.36\% \\ \hline
% right lower lung zone & 580 & 0.902 & 0.968 & 6.00\% & 2.27\% \\ \hline
% right hilar structures & 572 & 0.934 & 0.976 & 4.10\% & 1.91\% \\ \hline
% left hilar structures & 571 & 0.944 & 0.971 & 4.30\% & 2.28\% \\ \hline
% upper mediastinum & 359 & 0.94 & 0.994 & 1.40\% & 0.12\% \\ \hline
% left costophrenic angle & 298 & 0.908 & 0.929 & 9.60\% & 0.63\% \\ \hline
% right costophrenic angle & 286 & 0.918 & 0.944 & 6.90\% & 0.39\% \\ \hline
% left mid lung zone & 173 & 0.94 & 0.967 & 5.70\% & 2.79\% \\ \hline
% right mid lung zone & 169 & 0.83 & 0.968 & 5.30\% & 2.31\% \\ \hline
% aortic arch & 144 & 0.965 & 0.991 & 1.40\% & 0.62\% \\ \hline
% right upper lung zone & 117 & 0.873 & 0.972 & 5.80\% & 0.04\% \\ \hline
% left upper lung zone & 83 & 0.811 & 0.968 & 6.40\% & 0.22\% \\ \hline
% right hemidiaphragm & 78 & 0.947 & 0.955 & 7.90\% & 0.15\% \\ \hline
% right clavicle & 71 & 0.615 & 0.986 & 2.80\% & 0.50\% \\ \hline
% left clavicle & 67 & 0.642 & 0.983 & 3.00\% & 0.51\% \\ \hline
% left hemidiaphragm & 65 & 0.93 & 0.944 & 11.30\% & 0.14\% \\ \hline
% right apical zone & 58 & 0.852 & 0.969 & 5.40\% & 1.99\% \\ \hline
% trachea & 57 & 0.983 & 0.995 & 0.90\% & 0.24\% \\ \hline
% left apical zone & 47 & 0.938 & 0.963 & 6.20\% & 2.40\% \\ \hline
% carina & 41 & 0.975 & 0.994 & 0.80\% & 1.47\% \\ \hline
% svc & 19 & 0.973 & 0.995 & 0.70\% & 0.66\% \\ \hline
% right atrium & 14 & 0.963 & 0.979 & 4.00\% & 0.18\% \\ \hline
% cavoatrial junction & 5 & 1 & 0.977 & 4.30\% & 0.25\% \\ \hline
% abdomen & 80 & 0.904 & * & * & 0.26\% \\ \hline
% spine & 132 & 0.824 & * & * & 0.10\% \\ \hline
% \end{tabular}%
% }
% \vspace{-0.3cm}
% \end{table}
% }

% \caption{\label{tab:object-detect} CXR image object detection evaluation results. \\
% * These anatomical locations are extracted by the Bbox pipeline but they are not manually annotated in the gold standard dataset due to resource constraints.\\
% ** The mediastinum bounding boxes were not directly annotated due to resource constraints. Mediastinum's bounding box boundary can be derived from the ground truth for the upper mediastinum and the cardiac silhouette.
% }


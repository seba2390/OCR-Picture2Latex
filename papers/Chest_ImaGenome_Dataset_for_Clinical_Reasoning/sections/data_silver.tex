\section*{Data description}

The Chest ImaGenome dataset is committed to the PhysioNet repository in two main directories, one for the scene graphs that are automatically generated (``silver\_dataset''), and another for the 500 unique patient subset that was manually validated and corrected (``gold\_dataset''). Overall, $242,072$ scene graphs were automatically derived from $217,013$ unique CXR studies. The nodes and edges in the graph are defined in detail in Supplementary Table \ref{tab:define_nodes_edges}. On average 7 anatomical objects and 5 attributes are extracted from each study report. However, up to 29 anatomy objects can be detected in each CXR image with a percentage of misses < 0.02\% for most objects (See Table \ref{tab:object-detect} in Supplementary material). In addition, even without considering the related attribute(s), $678,543$ object-object comparison relations are extracted between anatomies across $128,468$ pairs of sequential CXR images. Detailed dataset characteristics are explained and provided in the PhysioNet repository (generate\_scenegraph\_statistics.ipynb). Figure \ref{fig:bbox-sample} shows an example of all the anatomical bounding boxes.

\vspace{-5pt}
\subsection*{Chest ImaGenome Scene Graph JSONs}
\vspace{-2pt}
%\noindent \textbf{Chest ImaGenome Scene Graph JSONs}: 
The `silver\_dataset/scene\_graph.zip' file is a directory that contains multiple JSON files, one for each scene graph. Each scene graph describes one frontal chest X-ray image. The structure for each scene graph JSON is described by components for easier explanation in Supplementary (Section \ref{jsonsg}). The first level of the JSON in Supplementary (\ref{json1}) describes the patient or study level information that may not be available in the image. The fields are: `image\_id' (dicom\_id in MIMIC-CXR), `viewpoint' (AP or PA), `patient\_id' (subject\_id in MIMIC-CXR), `study\_id' (study\_id in MIMIC-CXR), `gender' and `age\_decile' demographics (from MIMIC-CXR's metadata), `reason for exam' (patient history sentence(s) from the CXR reports with age removed), `StudyOrder' (the order of the CXR study for the patient, which is derived from chronologically ordering the DICOM timestamps), and `StudyDateTime; (from MIMIC's dicom metadata, which had been de-identified into the future).

% \hideseg{
% \vspace{-0.3cm}
% \begin{footnotesize}
% \begin{verbatim}
% {
%  `chest_imageimage_id': `10cd06e9-5443fef9-9afbe903-e2ce1eb5-dcff1097',
%  `viewpoint': `AP', `patient_id': 10063856, `study_id': 56759094,
%  `gender': `F', `age_decile': `50-60',
%  `reason_for_exam': `___F with hypotension.  Evaluate for pneumonia.',
%  `StudyOrder': 2, `StudyDateTime': `2178-10-05 15:05:32 UTC',
%  `objects': [ <...list of {} for each object...> ],
%  `attributes':[ <...list of {} for each object...> ],
%  `relationships':[ <...list of {} of comparison relationships between objects 
%  from sequential exams for the same patient...> ] 
% }
% \end{verbatim}
% \end{footnotesize}
% }

For each scene graph, there are 3 separate nested fields to describe the ``objects'' on the CXR images, the ``attributes'' related to the different objects as extracted from the corresponding reports, and ``relationships'' to describe comparison relations between sequential CXR images for the same patient. These 3 fields are a list of dictionaries, where the format of each dictionary is modeled after the respective JSONs in the Visual Genome dataset \cite{krishna2017visual}.

For objects, each dictionary has the format shown in Supplementary (\ref{json2}). The `object\_id' is unique across the whole dataset for the anatomical location on the particular image. Fields `x1', `y1', `x2', `y2', `width' and `height' are for a padded and resized 224x224 CXR frontal image, where coordinates `x1', `y1' are for the top left corner of the bounding box and `x2', `y2' are for the bottom right corner. The bounding box coordinates in the original image are denoted with `original\_*'. The remaining fields: `bbox\_name' is the name given to the anatomical location within the Chest ImaGenome dataset, and is useful for lookups in other parts of the scene graph JSON; `synsets' contain the UMLS CUI for the anatomical location concept; and the `name' is the UMLS name for that CUI \cite{bodenreider2004unified}. Note that CXRs are 2D images of a 3D structure so there are many overlying anatomical locations. A sample of 17 of the anatomical objects is plotted on a CXR as shown in Figure \ref{fig:bbox-sample}.
\vspace{-5pt}

\begin{figure}[!ht]
\centering
\includegraphics[scale=0.3]{figures/Figure_6_lung_mediastinum_clavicle_bboxes.pdf}
\caption{Sample CXR case with 17 overlaying clavicles, lung and mediastinum related anatomical bounding boxes (objects).}
\label{fig:bbox-sample}
\vspace{-12pt}
\end{figure}

% \hideseg{
% \vspace{-0.3cm}
% \begin{footnotesize}
% \begin{verbatim}
% {
%   `object_id': `10cd06e9-5443fef9-9afbe903-e2ce1eb5-dcff1097_right upper lung zone',
%   `x1': 48, `y1': 39, `x2': 111, `y2': 93,
%   `width': 63, `height': 54,
%   `bbox_name': `right upper lung zone',
%   `synsets': [`C0934570'],
%   `name': `Right upper lung zone',
%   `original_x1': 395, `original_y1': 532,
%   `original_x2': 1255, `original_y2': 1268,
%   `original_width': 860, `original_height': 736
% }
% \end{verbatim}
% \end{footnotesize}
% }

Each attribute dictionary, e.g., Supplementary  (\ref{json3}), aims to summarize all the CXR attribute descriptions for one anatomical location (`bbox\_name'). This means, for a particular CXR anatomical location, all the sentences describing attributes related to it have been grouped into the `phrases' field, where the order of sentences in the original report has been maintained. However, an anatomical location may not always be described or implied in the report. In that case, looking up dictionary[`bbox\_name'] will be False. The fields `synsets' and `name' are the same as in the objects' dictionaries, where they describe the UMLS CUI information for the anatomical location concept.
% \hideseg{
% \vspace{-0.3cm}
% \begin{footnotesize}
% \begin{verbatim}
% {
%   `right lung': True, `bbox_name': `right lung',
%   `synsets': [`C0225706'], `name': `Right lung',
%   `attributes': [[`anatomicalfinding|no|lung opacity',
%   `anatomicalfinding|no|pneumothorax',  `nlp|yes|normal'],
%   [`anatomicalfinding|no|pneumothorax']],
%   `attributes_ids': [[`CL556823', `C1963215;;C0032326', `C1550457'],
%   [`C1963215;;C0032326']],
%   `phrases': [`Right lung is clear without pneumothorax.', 
%   `No pneumothorax identified.'],
%   `phrase_IDs': [`56759094|10', `56759094|14'],
%   `sections': [`finalreport', `finalreport'],
%   `comparison_cues': [[], []],
%   `temporal_cues': [[], []],
%   `severity_cues': [[], []],
%   `texture_cues': [[], []],
%   `object_id': `10cd06e9-5443fef9-9afbe903-e2ce1eb5-dcff1097_right lung'
% }
% \end{verbatim}
% \end{footnotesize}
% }

The `attributes' field contains the relations between the anatomical location and the CXR attributes extracted from the respective sentences. Note that there can be multiple attributes extracted from each sentence. Therefore, the `attributes' field is a list of lists. The `attributes' in the lists follow the pattern of < categoryID | relation | label\_name >, where `categoryID' is the radiology semantic category the authors gave to the CXR concept in consultation with multiple radiologists, and relation is the NLP context relating the label\_name to the anatomical location as an attribute. If the relation is `no', then the `label\_name' is specifically negated in the sentence. If the relation is 'yes', then the `label\_name` is affirmed in the sentence. The order of the lists in the `attribute\_ids' field follow the lists in the `attributes' field and map each `label\_name' to UMLS CUIs. Thus, the way the Chest ImaGenome dataset is formulated, one can interpret a statement such as the `right lung' <has no> `lung opacity' as true in the extracted radiology knowledge graph, whereby each node has been mapped to an externally recognized ontology. 

The certainty of each relation in the CXR knowledge graph can be optionally further modified by the cues from the `severity\_cues' and `temporal\_cues' fields in each attribute dictionary. The severity cues can include `hedge', `mild', `moderate' or `severe', which are only assigned by co-occurrence at the sentence level. These extractions can benefit from future NLP improvement. Similarly, the temporal cues can modify the relation as either `acute' or `chronic' depending on clinical use cases.

The Chest ImaGenome categoryIDs can be used to differentiate the use case for different attributes:

$\bullet$ \textbf{anatomicalfinding} - findings of anatomies where there is some subjectivity in the grouping of the phrases used to extract the labels.
\vspace{-2pt}

$\bullet$ \textbf{disease} - descriptions that are more diagnostic level and often require patient information outside the image and most subjective to the reading radiologist's inference/impression.
\vspace{-2pt}

$\bullet$ \textbf{nlp} - normal / abnormal descriptions about different anatomical locations and can be subjective.
\vspace{-2pt}

$\bullet$ \textbf{technicalassessment} - image quality issues affecting interpretation of CXR observations.
\vspace{-2pt}

$\bullet$ \textbf{tubesandlines} - medical support devices where radiologists need to report any placement issues.
\vspace{-2pt}

$\bullet$ \textbf{devices}: medical devices where placement issues are less relevant
\vspace{-2pt}

$\bullet$ \textbf{texture} - these are only present in the 'texture\_cues' field, we kept a set of highly non-specific attributes (e.g. opacity, lucency, interstitial, airspace) that tend to form the initial most objective descriptions about what is observed in the images by radiologists. 

Finally, for comparison relationships, each dictionary has the format shown in Supplementary (\ref{json4}). Each relationship dictionary describes the comparison relation(s) relevant for only one anatomical location (`bbox\_name'). The `relationship\_id' uniquely identifies each comparison relationship between the object (`subject\_id') on the current exam and the object (`object\_id' for the same anatomical location) from the previous exam. The `predicate' and `synsets' are the UMLS CUIs for `relationship\_names', which is a list with usually one (but could be more) comparison relation type, which can be in [`comparison|yes|improved', `comparison|yes|worsened', `comparison|yes|no change']. The `attributes' field records the attributes that are related to the anatomical location as per the sentence from the original report (kept in the `phrase' field) that describes the comparison relationship.

% \hideseg{
% \vspace{-0.3cm}
% \begin{footnotesize}
% \begin{verbatim}
% {
%   `relationship_id': `56759094|7_54814005_C0929215_10cd06e9_4bb710ab',
%   `predicate': ``['No status change']'',
%   `synsets': [`C0442739'],
%   `relationship_names': [`comparison|yes|no change'],
%   `relationship_contexts': [1.0],
%   `phrase': `Compared with the prior radiograph, there is a persistent veil 
%   -like opacity\n over the left hemithorax, with a crescent of air surrounding 
%   the aortic arch,\n in keeping with continued left upper lobe collapse.',
%   `attributes': [`anatomicalfinding|yes|atelectasis',
%   `anatomicalfinding|yes|lobar/segmental collapse',
%   `anatomicalfinding|yes|lung opacity', `nlp|yes|abnormal'],
%   `bbox_name': `left upper lung zone',
%   `subject_id': `10cd06e9-5443fef9-9afbe903-e2ce1eb5-dcff1097_left upper lung zone',
%   `object_id': `4bb710ab-ab7d4781-568bcd6e-5079d3e6-7fdb61b6_left upper lung zone'
% }
% \end{verbatim}
% \end{footnotesize}
% }

% Not all the sentences in the MIMIC-CXR v2.0.0 reports have made it into the Chest ImaGenome dataset, which only contains sentences that have the specific objects, attributes or relations targeted by version 1.0.0 of the dataset. We provide the preprocessing steps (Preprocess_mimic_cxr_v2.0.0_reports.ipynb) done to index the sentences from the original text reports in the "utils" directory, the output of which is cxr-mimic-v2.0.0-processed-sentences_all.txt.

\vspace{-5pt}
\subsection*{CXR Scene Graphs Rendered in an Enriched RDF Format}
\vspace{-2pt}
%\textbf{CXR Scene Graphs Rendered in an enriched RDF Format}
Supplementary (\ref{json5}):
Radiology report sentences are fairly repetitive. Therefore, in the scene graph JSONS, one could see similar information described multiple times in different sentences for a study. In addition, in the MIMIC reports we worked with, each report could also have a preliminary read section (recorded by trainee radiologists - i.e., resident M.D.s) that comes before the final report section (approved by a fully trained and experienced radiologist). Therefore, occasionally, the extraction from the sentences near the beginning of a CXR report can be different from the conclusion sentences later in the report. To render the scene graphs easier for downstream utilization, we also provide post-processing utils (scenegraph\_postprocessing.py) to roll the annotations up to the study level for each relation. This is done by taking the last relation extracted for each anatomical location and attribute combinations for a report. The processing utils can either render the scene graphs in a tabular format or represent the information in a simpler enriched RDF format, which we used to generate the graph visualizations in Figure \ref{fig1.cxr_graph}. 

% \hideseg{
% \vspace{-0.3cm}
% \begin{footnotesize}
% \begin{verbatim}
% {
%  <study_id_i> : [
%                   [[node_id_1, node_type_1], [node_id_2, node_type_2], relation_name_A],
%                   [[node_id_1, node_type_1], [node_id_3, node_type_3], relation_name_B],
%                     ...
%                 ],
%  <study_id_i+1>:[
%                   [[node_id_1, node_type_1], [node_id_2, node_type_2], relation_name_A],
%                   [[node_id_1, node_type_1], [node_id_3, node_type_3], relation_name_B],
%                     ...
%                 ],
% }   
% \end{verbatim}
% \end{footnotesize}
% }

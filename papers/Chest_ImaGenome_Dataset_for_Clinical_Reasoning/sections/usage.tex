%\section*{Usage Notes}
\vspace{-5pt}
\section*{Clinical Applications}
% \textbf{Clinical applications}: 
\vspace{-5pt}
There are numerous clinical topics that may be explored for a dataset that links anatomic structures with individual abnormalities and simultaneously provides comparison relation annotations for sequential images. Monitoring the progression of pathologies that are visualized through chest imaging is the most unexplored clinical application of this dataset. In the in-patient setting, diagnosis and monitoring of pneumonia are typically performed through comparisons of sequential CXR images from admission\cite{kalil2016management}. The same management principle may apply to the evaluation of the progression of other diseases, such as pneumothorax, pulmonary edema, acute respiratory distress syndrome, or congestive heart failure \cite{henry2003bts, cardinale2014effectiveness, rubenfeld2012acute}. In the outpatient setting, surveillance of incidental pulmonary nodules, malignancies, tuberculosis, or interstitial lung disease is done through chest imaging in several-month intervals \cite{gould2013evaluation, koo2019chest, nahid2016official, hansell2015ct}. Furthermore, the methodological concepts of this dataset could be extended to other modes of imaging, such as computed tomography (CT), and magnetic resonance (MR) imaging, etc, further expanding the potential clinical utility of this project.


\textbf{Consistent dataset splits for performance reporting}: For reproducibility, we include splits for train, valid and test sets in the ``silver\_dataset/splits'' directory. The random data split was done at the patient level. We also included a file (images\_to\_avoid.csv) with image IDs (`dicom\_id') and `study\_id's for patients in the gold standard dataset, which should all be excluded from training and validation. 
%We expect all final benchmark reporting to be done on both the test set in the silver dataset and the manually annotated gold standard dataset.

As described, Chest ImaGenome has been constructed with multiple possible downstream tasks in mind. Here, we showcase two example tasks that can have the most immediate clinical applications, (i) outputting both the location and the type of CXR attribute for an image (Example Task 2) and (ii) comparing whether a location has worsened or improved across sequential exams (Example Task 1). Clinically, the two chosen types of tasks are the two most important ones for radiologists to report when interpreting CXRs. 


\textbf{Example Task 1: Change between sequential CXR exams.} CXRs are commonly repeatedly requested in the clinical workflow to assess for a myriad of attributes. Given a patient with sequential CXRs, the goal of this task is to automatically evaluate disease change over time based on two sequential CXR exams. We restricted the problem to a subset of the Chest ImaGenome dataset, i.e., to attributes related to congestive heart failure (CHF), as fluid management is one of the most routine clinical tasks for which CXRs can be ordered to guide the next steps (e.g. whether to give more intravenous fluid or give diuretics, etc). However, we note that users of this dataset can also explore comparison changes for other CXR attributes (e.g. pneumonia). Each CXR image is also associated with a bounding box that marks a localized area, e.g., ``left lung'' for specific anatomical finding (i.e., attribute), such as ``pulmonary edema/hazy opacity'', etc. In addition, the pair of CXR images is mapped to the comparison label that indicates whether the condition of the anatomical finding has improved or worsened. As a baseline example, we focus on change relations in the 'left lung' and 'right lung' objects that are related to the `pulmonary edema/hazy opacity' and `fluid overload/heart failure' attributes. The number of examples labeled in the training, validation and test data are $10,515$, $1,493$ and $2,987$, respectively. 
%is summarized in Table \ref{tab:change_dataset}. 
%Note that we also include a separate small gold standard sample that is validated by subject matter experts.
We design a siamese architecture (Figure \ref{fig:siamese} in Supplementary \ref{clinical_applications}) that first extracts the localized bounding box from each image and encodes the extracted image patches with a pre-trained ResNet101 autoencoder, denoted that is trained on several medical imaging datasets, e.g., NIH, CheXpert, and MIMIC datasets, etc. \cite{irvin2019chexpert,johnson2019mimic,wang2017chestx}. The autoencoder image representations are concatenated and passed through a dense layer with 128 neurons and ReLU activations, and a final classification layer. 
%The model architecture is implemented with TorchXRayVision \cite{Cohen2020xrv} and PyTorch Lighting \cite{falcon2019pytorch}. 
We train for $300$ epochs with cross-entropy, stochastic gradient descent, $1e-3$ learning rate, $0.1$ gradient clipping and $32$ batch size. We freeze the autoencoder weights and finetune the two last dense layers. On this challenging task of predicting change in localized anatomical findings between two sequential exams, we achieve an accuracy of $75.3\%$. %and $71.43\%$ on the test and gold test sets, respectively. 

 \textbf{Example Task 2: Localization of CXR attributes.} Knowing the anatomical location of non-specific findings/attributes on CXR images can help with narrowing down possible disease diagnoses and guide the next steps in requesting more specific imaging exams or treatment. To this end, we train a Faster R-CNN model \cite{ren2015faster} %using detectron2 \cite{wu2019detectron2}
to learn 18 anatomical locations within the dataset. We extract the 1024 dimension convolution feature vector of each anatomical region. We re-implement the state-of-the-art CheXGCN model \cite{chen2020label} %that uses a Graph Convolutional Network (GCN) model 
to learn the dependencies between attributes within the Chest X-ray. 
%In particular, the convolutions are replaced with the Faster R-CNN model. 
Similar to the work done by CheXGCN we model the correlation of the CXR attributes using a conditional probability (see Figure \ref{fig:gcn} in Supplementary \ref{clinical_applications}). We compare the results of the model with two baseline models, a Faster R-CNN model followed by a linear model without the GCN, and a Densenet model \cite{huang2017densely} without the Faster R-CNN to evaluate the effectiveness of the localized models. We focus on 9 common CXR attributes, which include lung opacity, pleural effusion, atelectasis, enlarged cardiac silhouette, pulmonary edema/hazy opacity, pneumothorax, consolidation, fluid overload/heart failure, pneumonia. The results of the experiments are shown in Table \ref{tab:attr_results} and the labels are ordered according to the attribute list above. 


\begin{table}[t!]
\centering
\caption{Anatomically localized CXR attribute detection (AUC scores). L1: Lung Opacity, L2: Pleural Effusion, L3: Atelectasis, L4: Enlarged Cardiac Silhouette, L5: Pulmonary Edema/Hazy Opacity, L6: Pneumothorax, L7: Consolidation, L8: Fluid Overload/Heart Failure, L9: Pneumonia.}
\resizebox{\textwidth}{!}{
\begin{tabular}{p{3cm}*{10}{p{0.8cm}}}
\toprule
Method & L1 &  L2 & L3 & L4 & L5 & L6 & L7 & L8 & L9 & \textbf{AVG}  \\
\midrule
Faster R-CNN & 0.84 & 0.89 & 0.77 & 0.85 & 0.87 & 0.77 & 0.75 & 0.81 & 0.71 & 0.80\\
GlobalView & \textbf{0.91} & \textbf{0.94} & 0.86 & 0.92 & 0.92 & \textbf{0.93} & 0.86 & 0.87 & 0.84 & 0.89\\
CheXGCN & 0.86 & 0.90 & \textbf{0.91} & \textbf{0.94} & \textbf{0.95} & 0.75 & \textbf{0.89} & \textbf{0.98} & \textbf{0.88} & \textbf{0.90}\\
\bottomrule 
\end{tabular}
}
\label{tab:attr_results}
\vspace{-15pt}
\end{table}

\hideseg{
\begin{table}[t!]
\centering
\caption{Change relation experiment: dataset statistics.}
%\resizebox{0.3\linewidth}{!}{%
\begin{tabular}{ccc} %p{0.45\linewidth}p{0.20\linewidth}p{0.20\linewidth}
\toprule
Data & \#Worsened & \#Improved \\ \midrule
\textbf{Train} & 5,802 & 4,713 \\
\textbf{Validation} & 808 & 685 \\
\textbf{Test} & 1,638 & 1,349 \\
%\textbf{Test (Gold)} & 51 & 47 \\
\bottomrule 
\end{tabular}
%}
\label{tab:change_dataset}
\vspace{-0.2cm}
\end{table}
}

\textbf{Dataset Limitations}: The Chest ImaGenome dataset came from only one U.S. hospital source. It is automatically generated and is limited by the performance of the NLP and the Bbox extraction pipelines. Furthermore, we cannot assume that all the clinically relevant CXR attributes are always described on every exam by the reporting radiologists. In fact, we have observed many implied object-attribute relation descriptions that are documented only in the form of comparisons (e.g. no change from previous) in short CXR reports. As such, even with perfect NLP extraction of object and attribute relations from individual reports, there would be missing information in the report knowledge graph constructed for some images. These technical areas are worth improving on in future research with more powerful NLP, image processing techniques and other graph-based techniques. Addressing missing relations will certainly improve this dataset too. Regardless, version 1.0.0 of the Chest ImaGenome dataset serves as a pioneering vision for a richer radiology imaging dataset.
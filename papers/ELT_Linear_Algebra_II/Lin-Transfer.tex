\section{ELT Transfer Principle}

The transfer principles are two theorems, presented in \cite{Akian2008}, which allows to conveniently transfer equalities between polynomial expressions in the classical theory to theorems about semirings with a negation map. We recall that any ELT algebra $\R$ has a negation map
$$\left(-\right)\layer{a}{\ell}=\layer{a}{-\ell}$$
and thus we may view each ELT algebra as a semiring with a negation map.\\

In this section, we use the transfer principles to prove two transfer principles for the ELT theory, and use these transfer principles to study the ELT adjoint matrix.

\subsection{The Transfer Principle}

In this subsection, we briefly introduce the two classical transfer principles given in \cite{Akian2008}.

\begin{defn}
A \textbf{positive polynomial expression} in the variables $\lambda_1,\dots,\lambda_m$ is a formal expression produced by the context-free grammar $E\mapsto E+E,\left(E\right)\times\left(E\right)$, where the symbols $0,1,\lambda_1,\dots,\lambda_m$ are thought of as terminal symbols of the grammar. A \textbf{monomial} in a positive polynomial expression is a sum of expressions of the form $c_I\lambda_1^{i_1}\dots \lambda_m^{i_m}$, where $I=\left(i_1,\dots,i_n\right)$ is fixed.
\end{defn}

That means that $0,1,\lambda_1,\dots,\lambda_m$ are positive polynomial expressions. Also, $\lambda_1+\left(\lambda_2\right)\times\left(\lambda_1+\lambda_3\right)$ is a positive polynomial expression. Any positive polynomial expression $E$ can be interpreted as a polynomial in $\N\left[\lambda_1,\dots,\lambda_m\right]$. We say that a monomial $\lambda_1^{i_1}\dots \lambda_m^{i_m}$ \textbf{appears} in the expression $E$ if there exists a positive integer $c$ such that $c\lambda_1^{i_1}\dots \lambda_m^{i_m}$ appears in the expansion of the polynomial obtained by interpreting $E$ in $\N\left[\lambda_1,\dots,\lambda_m\right]$.

If $R$ is a semiring with a negation map, and if $c\lambda_1^{i_1}\dots \lambda_m^{i_m}$ is a monomial, we define
$$\left(-\right)\left(c\lambda_1^{i_1}\dots \lambda_m^{i_m}\right)=\left(\left(-\right)c\right)\lambda_1^{i_1}\dots \lambda_m^{i_m}$$

\begin{defn}
Let $R$ be a semiring with a negation map. A \textbf{polynomial expression} is a formal expression of the form $P^+-P^-$, where $P^+$ and $P^-$ are positive polynomial expressions. A \textbf{monomial} in $P$ is a sum of the monomials $c_I\lambda_1^{i_1}\dots \lambda_m^{i_m}$ from $P^+$ and $c'_I\lambda_1^{i_1}\dots \lambda_m^{i_m}$ from $P^-$, where $I=\left(i_1,\dots,i_n\right)$ is fixed. We say that a monomial \textbf{appears} in the polynomial expression $P$, if it appears either in $P^+$ or in $P^-$.
\end{defn}

\begin{defn}
Let $P$ and $Q$ be polynomial expressions. We say that the identity $P=Q$ is valid in a semiring with a negation map $R$, if it holds for any semiring with a negation map $R$ and for any substitution $\lambda_1=r_1,\dots,\lambda_m=r_m$ of $r_1,\dots,r_m\in R$.
\end{defn}

Recall the relations $\symmdash$ and $\nabla$ from \sSref{sub:ELT-symmetrized}.

\begin{defn}
Let $P$ and $Q$ be polynomial expressions.
\begin{enumerate}
\item We say that the identity $P\nabla Q$ holds in all commutative semirings with a negation map, if for any semiring with a negation map $R$ and for any substitution $\lambda_1=r_1,\dots,\lambda_m=r_m$ of $r_1,\dots,r_m\in R$,
    $$P\left(r_1,\dots,r_n\right)\nabla Q\left(r_1,\dots,r_n\right)$$
\item We say that the identity $P\symmdash Q$ holds in all commutative semirings with a negation map, if for any semiring with a negation map $R$ and for any substitution $\lambda_1=r_1,\dots,\lambda_m=r_m$ of $r_1,\dots,r_m\in R$,
    $$P\left(r_1,\dots,r_n\right)\symmdash Q\left(r_1,\dots,r_n\right)$$
\end{enumerate}
\end{defn}

We recall the transfer principle (\cite[Theorems 4.20 and 4.21]{Akian2008}):

\begin{thm}[Transfer principle, weak form]
Let $P$ and $Q$ be polynomial expressions. If the identity $P=Q$ holds in all commutative rings, then the identity $P\nabla Q$ holds in all commutative semirings with negation map.
\end{thm}

\begin{thm}[Transfer principle, strong form]
Let $P$ and $Q$ be polynomial expressions. If the identity $P=Q$ holds in all commutative rings, and if $Q=Q^+-Q^-$ for some positive polynomial expressions such that there is no monomial appearing simultaneously in $Q^+$ and $Q^-$, then the identity $P\symmdash Q$ holds in all commutative semirings with negation map.
\end{thm}

The transfer principle allows us to prove several important theorems in a rather convenient way.

\begin{cor}[Multiplicativity of determinant]\label{cor:trans-det-mult}
Let $R$ be a semiring with a negation map, and let $A\in R^{n\times n}$. We define:
\begin{eqnarray*}
\det\left(A\right)^+&=&\sum_{\sigma\in A_n}a_{1,\sigma\left(1\right)}\dots a_{n,\sigma\left(n\right)}\\
\det\left(A\right)^-&=&\sum_{\sigma\in S_n\setminus A_n}a_{1,\sigma\left(1\right)}\dots a_{n,\sigma\left(n\right)}\\
\det\left(A\right)&=&\det\left(A\right)^+-\det\left(A\right)^-
\end{eqnarray*}
In \cite[Corollary 4.8]{Akian2008}, it is proven that if $R$ is a semiring with a negation map, then
$$\forall A,B\in R^{n\times n}:\det\left(AB\right)\symmdash\det\left(A\right)\det\left(B\right)$$
\end{cor}

\begin{cor}[Cayley-Hamilton theorem]\label{cor:cayley-hamilton}
Let $R$ be a semiring with a negation map, and let $A\in R^{n\times n}$. We know that over a commutative ring, $f_A\left(A\right)=0$. We can use the strong form of the transfer principle componentwise, and thus
$$f_A\left(A\right)\symmdash 0$$
In other words,
$$f_A\left(A\right)\in \left(R^\circ\right)^{n\times n}$$
\end{cor}

\subsection{Formulation and Proof of the ELT Transfer Principle}

We first recall that all of our ELT algebras are commutative ELT rings, meaning $\R=\ELT{\F}{\L}$ where $\F$ is an abelian group and $\L$ is a commutative ring.\\

We would like to have a tool of proving polynomial identities over commutative ELT rings. Recall that any ELT ring is a semiring with a negation map $a\mapsto\layer{0}{-1}a$ (\sSref{sub:ELT-symmetrized}), and thus we may apply the transfer principle. In order to strengthen the general transfer principle, we will use results from tropical linear algebra. This is formulated in the following theorems:

\begin{thm}[ELT Transfer Principle for equality]\label{thm:Trans-Princ}
Let $P$ and $Q$ be polynomial expressions. Assume that the identity $P=Q$ holds in all commutative rings. If the identity $P=Q$ holds in all commutative tropical algebras, then the identity $P=Q$ holds in all commutative ELT rings.
\end{thm}

\begin{thm}[ELT Transfer Principle for surpassing]\label{thm:Trans-Princ-Surpass}
Let $P$ and $Q$ be polynomial expressions. Assume that the identity $P=Q$ holds in all commutative rings. If the identity $P\ge Q$ holds in all commutative tropical algebras, then the identity $P\vDash Q$ holds in all commutative ELT rings.
\end{thm}

We prove two lemmas which will help us prove the theorems:

\begin{lem}\label{lem:sum-zero-one-big-surpass}
Let $\R$ be an ELT algebra, and let $\alpha,\beta\in\R$. If $s\left(\alpha+\minus\beta\right)=0$, and if $\t\left(\alpha\right)\ge\t\left(\beta\right)$, then $\alpha\vDash\beta$.
\end{lem}
\begin{proof}
Denote $\alpha=\layer{a}{\ell}$, $\beta=\layer{b}{k}$. $\t\left(\alpha\right)\ge\t\left(\beta\right)$ means $a\ge b$. We have two options:
\begin{enumerate}
\item If $a=b$, then $\alpha+\minus\beta=\layer{a}{\ell-k}\in\zeroset{\R}$. Thus, $\ell=k$, which implies $\alpha=\beta$.
\item If $a>b$, then $\alpha+\minus\beta=\alpha\in\zeroset{\R}$. Thus, $\ell=0$, and $\alpha=\alpha+\beta\vDash\beta$.
\end{enumerate}
In any case $\alpha\vDash\beta$, and thus we are finished.
\end{proof}

\begin{lem}\label{lem:hom-elt-maxplus}
Let $\R=\ELT{\F}{\L}$ be an ELT algebra. Endow $\F$ with a max-plus algebra, $\F_{\max}$. Then the function $\t:\R\to\F_{\max}$ is a ``homomorphism'', in the sense that:
\begin{enumerate}
\item $\forall x,y\in\R:\t\left(x+y\right)=\t\left(x\right)\oplus\t\left(y\right)$.
\item $\forall x,y\in\R:\t\left(xy\right)=\t\left(x\right)\odot\t\left(y\right)$.
\end{enumerate}
\end{lem}
\begin{proof}
Take $\layer{a_{1}}{\ell_{1}},\layer{a_{2}}{\ell_{2}}\in\R$.
\begin{enumerate}
\item If $a_1=a_2$, then
$$\t\left(\layer{a_{1}}{\ell_{1}}+\layer{a_{2}}{\ell_{2}}\right)=\t\left(\layer{a_1}{\ell_1+_\L\ell_2}\right)=a_1=a_1\oplus a_2=\t\left(\layer{a_{1}}{\ell_{1}}\right)\oplus\t\left(\layer{a_{2}}{\ell_{2}}\right)$$
Otherwise, without loss of generality, $a_1>a_2$, and thus
$$\t\left(\layer{a_{1}}{\ell_{1}}+\layer{a_{2}}{\ell_{2}}\right)=\t\left(\layer{a_1}{\ell_1}\right)=a_1=a_1\oplus a_2=\t\left(\layer{a_{1}}{\ell_{1}}\right)\oplus\t\left(\layer{a_{2}}{\ell_{2}}\right)$$
\item $\t\left(\layer{a_{1}}{\ell_{1}}\cdot\layer{a_{2}}{\ell_{2}}\right)=\t\left(\layer{\left(a_{1}+_\F a_{2}\right)}{\ell_{1}\cdot_\L\ell_{2}}\right)=a_1+_\F a_2=a_1\odot a_2=\t\left(\layer{a_{1}}{\ell_{1}}\right)\odot\t\left(\layer{a_{2}}{\ell_{2}}\right)$
\end{enumerate}
\end{proof}

We now prove these theorems. We note that since \Tref{thm:Trans-Princ} follows from \Tref{thm:Trans-Princ-Surpass}, we will only prove the latter.\\

\begin{proof}[Proof of \Tref{thm:Trans-Princ-Surpass}]
By the weak form of the general transfer principle, $s\left(P+\minus Q\right)=0$.

Let $\R=\ELT{\F}{\L}$ be a commutative ELT ring. We will now prove that for any substitution $\lambda_1=r_1,\dots,\lambda_m=r_m$ of $r_1,\dots,r_m\in\R$,
$$\t\left(P\left(r_1,\dots,r_m\right)\right)\ge\t\left(Q\left(r_1,\dots,r_m\right)\right)$$
We endow $\F$ with the max-plus operations. By Lemma (\Lref{lem:hom-elt-maxplus}) $\t:\R\to\F_{\max}$ is a homomorphism. Therefore, for any ELT polynomial $p\in\R\left[\lambda\right]$ and for any substitution $\lambda_1=r_1,\dots,\lambda_m=r_m$ of $r_1,\dots,r_m\in\R$,
$$\t\left(p\left(r_1,\dots,r_m\right)\right)=p\left(\t\left(r_1\right),\dots,\t\left(r_m\right)\right)$$
Thus, for any substitution $\lambda_1=r_1,\dots,\lambda_m=r_m$ of $r_1,\dots,r_m\in\R$,
$$\t\left(P\left(r_1,\dots,r_m\right)\right)=P\left(\t\left(r_1\right),\dots,\t\left(r_m\right)\right)\ge Q\left(\t\left(r_1\right),\dots,\t\left(r_m\right)\right)=\t\left(Q\left(r_1,\dots,r_m\right)\right)$$

We have proven that $s\left(P+\minus Q\right)=0$ and that $\t\left(P\right)\ge\t\left(Q\right)$; by \Lref{lem:sum-zero-one-big-surpass}, we are finished.
\end{proof}

\begin{rem}
Throughout the uses of the ELT transfer principle for equality, we need to check the corresponding identity in commutative tropical algebras. However, since major work has been done in the supertropical theory (see \cite{IR3}, \cite{Izhaki2009} and \cite{Izhaki2010b}), we usually check that one of the following conditions holds:
\begin{enumerate}
\item The identity $P=Q$ holds in all commutative supertropical algebras.
\item The identity $\nu\left(P\right)=\nu\left(Q\right)$ holds in all commutative supertropical algebras.
\end{enumerate}
Similarly, to prove a surpassing relation, we usually check that one of the following conditions holds:
\begin{enumerate}
\item The identity $P\ghs Q$ holds in all commutative supertropical algebras.
\item The identity $P\ge_\nu Q$ holds in all commutative supertropical algebras.
\end{enumerate}
\end{rem}

This tool allows us to prove many polynomial surpassing and equalities without effort. An example is given in the next subsection.

\subsection{Multiplicity of the ELT Determinant}

We return to \Cref{cor:trans-det-mult}, which holds in particular over commutative ELT rings. We first formulate this corollary in the ``ELT language'':

\begin{cor}[Multiplicativity of the ELT determinant]\label{cor:elt-det-mult}
Let $\R$ be a commutative ELT ring. If~$A,B\in \left(\overline{\R}\right)^{n\times n}$, then
$$\det\left(AB\right)\vDash\det\left(A\right)\cdot\det\left(B\right)$$
\end{cor}

We now present several corollaries from the multiplicativity of the ELT determinant, which are two cases in which the ELT determinant is strictly multiplicative. First, we prove a lemma that will be helpful for the first case:

\begin{lem}\label{lem:non-zero-surpass-equal}
If $x,y\in\R$ satisfy $x\vDash y$, and if $s\left(x\right)\neq0$, then $x=y$.
\end{lem}
\begin{proof}
Write $x=\layer{a}{\ell}$, $y=\layer{b}{k}$. Since $x\vDash y$, there is $c\in\F$ such that $x=y+\layer{c}{0}$. In other words,
$$\layer{a}{\ell}=\layer{b}{k}+\layer{c}{0}$$
By the definition of addition, $a\ge b$, and $a=\max\left\{b,c\right\}$. If $a>b$, then $a=c>b$, and thus
$$\layer{a}{\ell}=\layer{b}{k}+\layer{c}{0}=\layer{c}{0}$$
in contradiction to the fact that $\ell=s\left(x\right)\neq 0$. Thus, $x=y$.
\end{proof}

\begin{cor}\label{cor:det-is-mult-non-zero-prod}
If $s\left(\det\left(AB\right)\right)\neq 0$, then
$$\det\left(AB\right)=\det\left(A\right)\cdot\det\left(B\right)$$
\end{cor}
\begin{proof}
From \Cref{cor:elt-det-mult},
$$\det\left(AB\right)\vDash\det\left(A\right)\cdot\det\left(B\right)$$
By \Lref{lem:non-zero-surpass-equal}, we get equality.
\end{proof}

Another case in which the determinant is multiplicative is when either $A$ or $B$ are invertible:

\begin{thm}\label{thm:det-is-mult-invert-mat}
If $A,B\in \left(\overline{\R}\right)^{n\times n}$, such that $A$ or $B$ are invertible. Then
$$\det\left(AB\right)=\det\left(A\right)\cdot\det\left(B\right)$$
\end{thm}
\begin{proof}
Assume that $B$ is invertible (the second direction is proved similarly). We note that by \Cref{cor:elt-det-mult},
$$\det\left(AB\right)\vDash\det\left(A\right)\cdot\det\left(B\right)$$
but also
$$\det\left(A\right)=\det\left(\left(AB\right)B^{-1}\right)\vDash\det\left(AB\right)\cdot\det \left(B^{-1}\right)=\det\left(AB\right)\cdot\left(\det\left(B\right)\right)^{-1}.$$
The latter surpassing implies that
$$\det\left(A\right)\cdot\det\left(B\right)\vDash\det\left(AB\right).$$
Since $\vDash$ is antisymmetric on $\overline{\R}$, the conclusion follows.
\end{proof}

Although the determinant is not multiplicative, a natural question is: if $AB$ is non-singular, is $BA$ also non-singular? The answer to this question is negative, as the following example demonstrates:
\begin{example}
In $\R=\ELT{\mathbb{R}}{\mathbb{C}}$, consider
$$A=\begin{pmatrix}\layer{1}{1} & \layer{1}{1}\\
\layer{2}{1} & \layer{3}{1}
\end{pmatrix}$$
Then $\det\left(AA^{t}\right)=\layer{8}{1}$, yet $\det\left(A^{t}A\right)=\layer{10}{0}$.
\end{example}

\subsection{The ELT Adjoint Matrix and Quasi-Invertible Matrices}
As we have seen, the invertible matrices in the ELT sense are limited. So, we shall try to generalize this. Our goal is to find an equivalent condition to the fact that $\det\left(A\right)$ is invertible.

\begin{defn}
Let $\R$ be a commutative ELT ring. A \textbf{quasi-identity matrix} is a matrix $\tilde{I}\in \left(\overline{\R}\right)^{n\times n}$, which is idemopotent, nonsingular and defined by
$$\left(\tilde{I}\right)_{i,j}=\begin{cases}
\one & i=j\\
\alpha_{i,j} & i\neq j
\end{cases}$$
where $\alpha_{i,j}\in\overline{\R}$, $s\left(\alpha_{i,j}\right)=0$.
\end{defn}

\begin{defn}
Let $\R$ be a commutative ELT ring, and let $A\in \left(\overline{\R}\right)^{n\times n}$. A matrix $B\in \left(\overline{\R}\right)^{n\times n}$ is a \textbf{quasi-inverse} for $A$, if $AB$ and $BA$ are quasi-identity matrices. In this case, $A$ is called \textbf{quasi-invertible}. Note that $AB$ and $BA$ may differ.
\end{defn}

\begin{defn}
Let $\R$ be a commutative ELT ring, and let $A\in \left(\overline{\R}\right)^{n\times n}$. The \textbf{$\left(i,j\right)$-minor} $A_{i,j}'$ of a matrix $A=\left(a_{i,j}\right)$ is obtained by deleting the $i$-th row and the $j$-th column. Its ELT determinant is $a_{i,j}'=\det A_{i,j}'$.
\end{defn}

\begin{defn}
Let $\R$ be a commutative ELT ring, and let $A\in \left(\overline{\R}\right)^{n\times n}$. The \textbf{adjoint} matrix of $A$ is
$$\left(\adj\left(A\right)\right)_{i,j}=\layer 0{\varepsilon\left(i,j\right)}\, a_{j,i}'$$
where $\varepsilon\left(i,j\right)=\left(-1\right)^{i+j}$.
\end{defn}

We would like to prove that when $\det\left(A\right)$ is invertible in $\R$, $\left(\det \left(A\right)\right)^{-1}\adj\left(A\right)$ is a quasi-inverse of~$A$. We present here some corollaries from the ELT transfer principle, which together will prove the assertion (\Tref{thm:det-inv-then-A-quasinv}). We use the ELT transfer principles componentwise.

\begin{cor}\label{cor:A-times-adj}
$A\cdot\adj\left(A\right)=\det\left(A\right)I_{A}$, where $I_{A}\vDash I$.
\end{cor}
\begin{proof}
We use the ELT transfer principle for surpassing. This result is known in ring theory, and is proved in the supertropical theory (see \cite[Remark 4.5]{IR3}).
\end{proof}

\begin{cor}\label{cor:det-of-A-times-adj}
$$\det\left(A\cdot\adj\left(A\right)\right)=\det\left(A\right)^n$$
\end{cor}
\begin{proof}
We use the ELT transfer principle for equalities. This result is known in ring theory, and is proved in the supertropical theory (see \cite[Theorem~4.9]{IR3}).
\end{proof}

\begin{cor}\label{cor:A-times-adj-squared}
$$\left(A\cdot\adj\left(A\right)\right)^2=\det\left(A\right)\cdot A\cdot\adj\left(A\right)$$
\end{cor}
\begin{proof}
We use the ELT transfer principle for equalities. This result is known in ring theory, and is proved in the supertropical theory (see \cite[Theorem~4.12]{IR3}).
\end{proof}

\begin{thm}\label{thm:det-inv-then-A-quasinv}
If $\det\left(A\right)$ is invertible in $\R$, then $A$ is quasi-invertible.
\end{thm}
\begin{proof}
By \Cref{cor:A-times-adj}, $A\cdot\adj\left(A\right)=\det\left(A\right)\cdot I_{A}$, where $I_{A}\vDash I$. It is left to prove that $I_A$ is nonsingular and idempotent.

By \Cref{cor:det-of-A-times-adj}, $\det\left(A\cdot\adj\left(A\right)\right)=\det\left(A\right)^n$. But
$$\det\left(A\right)^n=\det\left(A\cdot\adj\left(A\right)\right)=\det\left(\det\left(A\right)I_A\right)=\det\left(A\right)^n\det\left(I_A\right)$$
Since $\det\left(A\right)$ is invertible, $\det\left(I_A\right)=\one$.

To prove that $I_A$ is idempotent, we use \Cref{cor:A-times-adj-squared}:
\begin{eqnarray*}
I_A^2&=&\left(\left(\det\left(A\right)\right)^{-1}A\cdot\adj\left(A\right)\right)^2= \left(\det\left(A\right)^2\right)^{-1}\left(A\cdot\adj\left(A\right)\right)^2=\\ &=&\left(\det\left(A\right)^2\right)^{-1}\det\left(A\right)\cdot A\cdot\adj\left(A\right)=\left(\det\left(A\right)\right)^{-1}A\cdot\adj\left(A\right)=I_A
\end{eqnarray*}
as required.
\end{proof}

\begin{rem}
Using the same arguments, one may show that $\adj\left(A\right)\cdot A$ is $\det\left(A\right)$ times a quasi-identity matrix.
\end{rem}

\begin{cor}\label{cor:quasi-invertible-mat}
Let $\R$ be a commutative ELT ring. Then $A$ is quasi-invertible if and only if $\det\left(A\right)$ is invertible.
\end{cor}

We will now use the theory of the ELT adjoint matrix to study the connection between matrix singularity and linear dependency. We recall the following theorem:
\begin{thm*}[{\cite[Theorem 1.6]{BS}}]
Let $\R=\ELT{\RR}{\mathbb{F}}$ be an ELT algebra, where $\mathbb{F}$ is an algebraically closed field. Consider $A\in\left(\overline{\R}\right)^{n\times n}$. Then the rows of $A$ are linearly dependent, iff the columns of $A$ are linearly dependent, iff $s\left(\det A\right)=0_\mathbb{F}$.
\end{thm*}

This theorem was proved using the Fundamental Theorem, thus only in the case of $\R=\ELT{\RR}{\mathbb{F}}$ where $\mathbb{F}$ is an algebraically closed field. We will prove the following:

\begin{thm}\label{thm:det-is-invertible}
Let $\R$ be a commutative ELT ring, and let $A\in\left(\overline{\R}\right)^{n\times n}$ an ELT matrix. If $\det A$ is invertible in $\R$, then the columns (respectively, rows) of $A$ are linearly independent.
\end{thm}

Before proving this theorem, we recall the Hungarian algorithm (\cite{K}):
\begin{defn}
An entry $a_{i,j}$ of a tropical matrix $A\in\left(\overline{G_{\max}}\right)^{n\times n}$ is called \textbf{column-critical} if it is maximal within its columns, i.e., if $\forall k:a_{i,j}\ge a_{k,j}$. A matrix $A$ is called \textbf{critical} if there exists a permutation $\sigma\in S_n$ such that $a_{1,\sigma\left(1\right)},\dots,a_{n,\sigma\left(n\right)}$ are column-critical.
\end{defn}

\begin{thm}[The Hungarian Algorithm]
Let $A\in\left(\overline{G_{\max}}\right)^{n\times n}$ be a tropical matrix. Then there are scalars $\alpha_1,\dots,\alpha_n\in\R^{\times}$ such that
$$\left(\begin{matrix}&\alpha_1\odot R_1\left(A\right)&\\&\vdots&\\&\alpha_n\odot R_n\left(A\right)&\end{matrix}\right)$$
is critical. In other words, there exists a diagonal matrix $D\in\left(\overline{G_{\max}}\right)^{n\times n}$, whose diagonal entries are not $-\infty$, such that $A\odot D$ is critical.
\end{thm}

In the ELT case, we say that a matrix $A\in\left(\overline{\R}\right)^{n\times n}$ is \textbf{critical} if $\t\left(A\right)=\left(\t\left(a_{i,j}\right)\right)\in\left(\overline{G_{\max}}\right)^{n\times n}$ is critical.

\begin{cor}\label{cor:hung-alg-for-ELT}
Let $A\in\left(\overline{\R}\right)^{n\times n}$. Then there exists an invertible diagonal matrix $D\in\left(\overline{\R}\right)^{n\times n}$ such that $DA$ is critical.
\end{cor}
\begin{proof}
Let $D'=\left(d'_{i,j}\right)\in\left(\overline{G_{\max}}\right)^{n\times n}$ be a diagonal matrix such that $D'\odot\t\left(A\right)$ is a critical tropical matrix. We define $D=\left(d_{i,j}\right)\in\left(\overline{\R}\right)^{n\times n}$ as
$$d_{i,j}=\left\{\begin{matrix}\layer{d'_{i,i}}{1},&i=j\\-\infty,&i\neq j\end{matrix}\right.$$
Obviously, $DA$ is critical (since $\t\left(DA\right)=\t\left(D\right)\odot\t\left(A\right)=D'\odot\t\left(A\right)$ is critical), as required.
\end{proof}

We are now ready to prove \Tref{thm:det-is-invertible}.

\begin{proof}[Proof of \Tref{thm:det-is-invertible}]
We prove the assertion on the columns of $A$. The assertion that the rows of $A$ are linearly independent can be proven by replacing $A$ with $A^t$.\\

Suppose that $s\left(Av\right)=\left(0,\dots,0\right)^t$ for some $v\in\left(\overline{\R^{\times}}\right)^n$. If
$$A^{\nabla}=\left(\det A\right)^{-1}\adj\left(A\right),$$
there exists a quasi-identity matrix $I'_A$ such that
$$A^{\nabla}A=I'_A$$
Thus,
$$s\left(I'_Av\right)=s\left(A^{\nabla}A\cdot v\right)=\left(0,\dots,0\right)^t.$$

We apply \Cref{cor:hung-alg-for-ELT} for $\left(I'_A\right)^t$ to find a diagonal invertible matrix $D\in\left(\overline{\R}\right)^{n\times n}$ such that $D\left(I'_A\right)^t$ is critical. By transposing this matrix, we get a matrix $I'_AD$ such that there is a permutation $\sigma\in S_n$ for which $\left(I'_AD\right){i,j}$ is row-critical in $I'_AD$. By \Tref{thm:det-is-mult-invert-mat},
$$\det\left(I'_AD\right)=\det I'_A\cdot\det D=\det D$$
is not of layer zero, i.e.\ $I'_AD$ is nonsingular. We note that the only non-zero layered track in $I'_A$ is the diagonal track, since any entry of $I'_A$ which is not on the diagonal is of layer zero; hence, we may assume $\sigma=\Id$, that is the diagonal entries are row-critical.\\

Returning to the original equation $s\left(I'_Av\right)=\left(0,\dots,0\right)^t$, we replace $I'_A$ by $B=I'_AD$ and $v$ by~$v'=D^{-1}v$ to get
$$s\left(Bv'\right)=\left(0,\dots,0\right)^t$$
Let $1\leq k\leq n$ such that
$$\t\left(v'_k\right)=\max_{1\leq i\leq n}\t\left(v'_i\right).$$
Then
$$\left(Bv'\right)_k=\sum_{i=1}^n b_{k,i}v'_i=\sum_{\substack{i=1\\i\neq k}}^n b_{k,i}v'_i+b_{k,k}v'_k.$$
We recall that $B=I'_AD$, where $I'_A$ is a quasi-identity matrix and $D$ is an invertible diagonal matrix. Thus, every entry of $B$ which is not on its diagonal is of layer zero. Furthermore, for any $i\neq k$ we have $\t\left(v'_i\right)\leq\t\left(v'_k\right)$ and $\t\left(b_{k,i}\right)\leq\t\left(b_{k,k}\right)$. Therefore each summand $b_{k,i}v'_i$ cannot dominate~$b_{k,k}v'_k$, implying
$$\left(Bv'\right)_k=b_{k,k}v'_k$$
which implies $s\left(b_{k,k}v'_k\right)=0$. Since $b_{k,k}=\left(I'_A\right)_{k,k}d_{k,k}=d_{k,k}$ is not of layer zero (because $D$ is invertible), we must have $s\left(v'_k\right)=0$. Now, $v_k=d_{k,k}^{-1}v'_k$ implies $s\left(v_k\right)=0$.\\

But $v\in\left(\overline{\R^{\times}}\right)^n$, therefore $s\left(v_k\right)=0$ implies $v_k=-\infty$. By the choice of $k$, we must have $v=\left(-\infty,\dots,-\infty\right)$, which proves that the columns of $A$ are linearly independent.
\end{proof}

\subsection{The ELT Characteristic Polynomial and ELT Eigenvalues}
\begin{defn}
Let $A\in \left(\overline{\R}\right)^{n\times n}$ be a matrix. The \textbf{ELT characteristic polynomial} of $A$ is defined to be
$$p_A(\lambda)=\det\left(\lambda I_n+\layer{0}{-1}A\right)$$
\end{defn}

\begin{defn}
Let $A\in \left(\overline{\R}\right)^{n\times n}$ be a matrix. A vector $v\in (\overline{\R^{\times}})^n$ is called an \textbf{eigenvector} of~$A$ with an \textbf{eigenvalue} $x\in\overline{\R}$ if $v\neq (-\infty,...,-\infty)$ and
$$Av=xv.$$
\end{defn}


\begin{prop}
Let $A\in \left(\overline{\R}\right)^{n\times n}$ be a matrix with eigenvalue $x$. Then $s\left(p_A(x)\right)=0_{\L}$.
\end{prop}

\begin{proof}
Choose $v$ to be an eigenvector of the eigenvalue $v$, then $Av=xv$. Therefore
$$Av+\layer{0}{-1}\cdot xv = \layer{0}{0}\cdot xv.$$
In other words,
$$s\left(xv+\layer{0}{-1}Av\right)=(0_{\L},...,0_{\L}).$$
Thus
$$s\left((xI_n+\layer{0}{-1}A)v\right)=(0_{\L},...,0_{\L}).$$

By \Tref{thm:det-is-invertible}, we conclude that $s\left(\det\left(xI_n+\layer{0}{-1}A\right)\right)=0_{\L}$, i.e., $s\left(p_A\left(x\right)\right)=0_{\L}$.
\end{proof}

Note that the other direction is not necessarily true, i.e., there could be an ELT root of the characteristic polynomial which is not an eigenvalue. Indeed, if one tried to prove that direction, he would encounter the following difficulty:
$$Av \neq Av+\layer{0}{-1}\cdot xv + xv.$$

\begin{example}
Consider the matrix $A\in\left(\overline{\R}\right)^{2\times 2}$,
$$A=\begin{pmatrix}\layer{1}{1} & \layer{2}{1} \\ \layer{2}{1} & \layer{3}{1} \end{pmatrix},$$

Its ELT characteristic polynomial is
\begin{eqnarray*}
p_A(\lambda)&=&\det\left(\lambda I_2+\layer{0}{-1}A\right)=
\det\left(\begin{matrix}\lambda+\layer{1}{-1} & \layer{2}{-1} \\
\layer{2}{-1} & \lambda+\layer{3}{-1}
\end{matrix}\right)\\
&=&(\lambda+\layer{1}{-1})(\lambda+\layer{3}{-1}) + \layer{4}{-1}=\lambda^2 + \layer{3}{-1}\cdot\lambda + \layer{4}{0}.
\end{eqnarray*}
If $\lambda=\layer{1}{0}$, $\lambda=\layer{\alpha}{\ell}$ with $\alpha < 1$ or $\lambda=\layer{3}{1}$, then $s\left(p_A(\lambda)\right)=0$.\\

The only eigenvalue of $A$ is $\lambda=\layer{3}{1}$, with
$$\begin{pmatrix}\layer{1}{1} & \layer{2}{1} \\ \layer{2}{1} & \layer{3}{1} \end{pmatrix}
\begin{pmatrix}\layer{0}{1} \\ \layer{1}{1} \end{pmatrix} =
\begin{pmatrix}\layer{3}{1} \\ \layer{4}{1} \end{pmatrix}=\layer{3}{1}\begin{pmatrix}\layer{0}{1} \\ \layer{1}{1} \end{pmatrix}.$$\\
\end{example}

One may also define an ELT eigenvalue and an eigenvector in the following way:

\begin{defn}\label{ELT_eigen_vector}
Let $A\in \left(\overline{\R}\right)^{n\times n}$ be a matrix. A vector $v\in (\overline{\R^{\times}})^n$ is called an \textbf{ELT eigenvector} of~$A$ with an \textbf{ELT eigenvalue} $x\in\overline{\R}$ if $v\neq (-\infty,...,-\infty)$ and
$$s\left(Av+\layer{0}{-1}xv\right)=(0_{\L},...,0_{\L}).$$
\end{defn}

This definition is similar to the concept of 'ghost surpass' given by Izhakian, Knebusch and Rowen (ref. \cite{IKR}).\\

\begin{prop}
Let $\R=\ELT{\RR}{\mathbb{F}}$ be an ELT algebra, where $\mathbb{F}$ is an algebraically closed field, and let $A\in \left(\overline{\R}\right)^{n\times n}$ be a matrix. Then $x$ is an ELT eigenvalue of $A$ if and only if $s\left(p_A(x)\right)=0_{\L}$.
\end{prop}

\begin{proof}
By \Dref{ELT_eigen_vector}, $x$ is an eigenvalue of $A$ if and only if there exists a vector $v\in (\overline{\R^{\times}})^n$ such that $v\neq (-\infty,...,-\infty)$ and $$s\left(xv+\layer{0}{-1}Av\right)=(0_{\L},...,0_{\L}),$$
if and only if the columns of $p_A(x)=x\cdot I_n+\layer{0}{-1}A$ are linearly dependent, if and only if $p_A(x)$ is singular (\cite[Theorem 1.7]{BS}).
\end{proof}

We finish by reformulating Cayley-Hamilton theorem (\Cref{cor:cayley-hamilton}) in the ``ELT language''.

\begin{cor}[ELT Cayley-Hamilton theorem]\label{cor:elt-cayley-hamilton}
Let $\R$ be a commutative ELT ring, and let $A\in \left(\overline{\R}\right)^{n\times n}$ be an ELT matrix. Then
$$s\left(p_A\left(A\right)\right)=0$$
\end{cor}
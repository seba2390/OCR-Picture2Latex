\section{Introduction}
\label{intro}

 Many large software packages in the domains of machine learning, cloud computing, and scientific computing use Python to design high-level algorithms and manage various dependencies. The success of Python is largely due to its simplicity, extensibility, and flexibility. Like most scripting languages, Python typically uses interpretation-based execution, which suffers from low performance. Thus, modern Python applications usually integrate native libraries written in C/C++/Fortran for computation kernels, as shown in Figure~\ref{fig:hybridmode}. Such libraries include Numpy~\cite{van2011numpy, harris2020array}, Scikit-learn~\cite{scikit-learn}, Tensorflow~\cite{tensorflow2015-whitepaper}, and PyTorch~\cite{paszke2017automatic} to name a few. Therefore, modern software packages can enjoy the simplicity and flexibility from Python as well as performance from native library.

\begin{figure}[t]
	\centering
	\includegraphics[width=0.8\linewidth]{Figures/software_stack_v2.pdf}
	\caption{The typical stack of production Python software packages. Python applications usually rely on native libraries for high performance but introduce an abstraction across the boundary of Python runtime and native libraries.}
	\label{fig:hybridmode}
\end{figure}

However, such programming model complicates the software stack, which results in new performance inefficiencies. Figure~\ref{fig:hybridmode} shows an abstraction across the boundary of Python runtime and native library, which logically splits the entire software stack. On the upper level, Python applications are disjoined from their execution behaviors because Python runtime (e.g., interpreter and GC) hides most of the execution details. On the lower level, the native libraries lose most of program semantic information, resulting in a challenge of associating execution behaviors with high-level algorithms. This knowledge gap leads to a new type of performance losses, which we refer to as {\em interaction inefficiencies}.

% As a dynamic programming language, Python has been increasingly popular\yu{remove popular} in various domains including scientific computing, machine learning, and clouding computing. Typically, Python applications have a hybrid runtime mode. Libraries such as Numpy~\cite{oliphant2006guide}~\cite{van2011numpy}, Scikit-learn~\cite{scikit-learn}, Tensorflow~\cite{tensorflow2015-whitepaper} and PyTorch~\cite{paszke2017automatic}, are implemented in static programming languages (C/C++), but invoked by applications with their Python abstractions. Such kind of executing mechanism is called {\it \ff}, which combines the best of both worlds: fruitful productivity of dynamic programming languages and high performance of static programming languages. However, Python applications still suffer poor performance, because the complex hybrid software stacks can easily introduce performance inefficiencies.
 
%   Programmers develop the performance-critical components with static programming languages, such as C or C++, and embed these binary libraries into the application by calling their Python interfaces (binary function call).

\begin{figure}[t]
\begin{lstlisting}[caption={Code snippet from Metaheuritics~\cite{nguyen2019building, nguyen2018resource}. Interaction inefficiencies exist in referencing Numpy arrays.},label=lst:motivated1]
def CEC_4(solution=None, problem_size=None, shift=0):
    ...
    for i in range(dim - 1):
        res += 100 * np.square(x[i]**2-x[i+1]) + np.square(x[i]-1)
    ...
\end{lstlisting}
\end{figure}

Let us examine a concrete example. See 
Listing~\ref{lst:motivated1}. This code snippet is from Metaheuristics~\cite{nguyen2019building, nguyen2018resource}, which implements the-state-of-the-art meta-heuristic algorithms.
It iterates a Numpy array {\tt x} in a {\tt for} loop. Here, no inefficiencies can be easily identified by examining the python code. However, massive redundant computation is revealed when we inspect the native Numpy libraries.
The Numpy index operator {\tt []} invokes the following function in the native library:

{\tt PyObject *array\_subscript\_asarray(
\tab \tab \tab PyArrayObject *array, \\
\tab \tab \tab PyObject *index)}

In this function, the first argument points to an array and the second argument points to an index. 
Besides returning the indexed array element, this function performs extra work, such as checking boundary safety and loading raw data region\footnote{Numpy array objects keep a pointer that points to the raw data region, where the real values are stored.}. This extra work is redundancy on the array {\tt x} when referencing different element of {\tt x} with {\tt []} across different iterations. We are able to eliminate most of the redundant work by applying the slice notation available in Python, as shown in Listing~\ref{lst:motivated2}. This optimization yields a 27.3$\times$ function-level speedup and a 6.3$\times$ speedup for the entire application.

Missing the usage of slice notation is the tip of an iceberg of the interaction inefficiencies, which can be in various forms such as API misuse, inefficient algorithms, redundant function invocations, and many others.  However, pinpointing interaction inefficiencies and providing optimization guidance is challenging because performance tools need to measure the entire software stack to bridge the gap of high-level Python code and low-level native libraries. %as shown in Figure~\ref{fig:hybridmode}.

Existing profilers lack of this capability: %Unfortunately, no existing tools can directly analyze interaction inefficiencies.
\emph{(i) Existing Python profilers}, such as cProfile~\cite{cProfile}, guppy3~\cite{guppy3}, PySpy~\cite{py-spy}, PyFlame~\cite{pyflame}, PyInstrument~\cite{pyinstrument}, PyCallGraph~\cite{pycallgraph}, PProfile~\cite{pprofile}, MemoryProfiler~\cite{memoryprofiler} and Austin~\cite{austin}, monitor the execution with Python interpreter APIs. They produce profiles by obtaining Python runtime information only. They attribute various metrics (e.g., execution time and memory consumption) to Python constructs such as methods or objects, but provide limited insights into the behavior of native library internals, which interact with OS and hardware. \emph{(ii) Existing native profilers}  working on native binary executables, such as VTune~\cite{reinders2005vtune}, Perf~\cite{de2010new},
Toddler~\cite{nistor2013toddler}, HPCTookit~\cite{adhianto2010hpctoolkit}, Witch~\cite{wen2018watching}, RedSpy~\cite{wen2017redspy}, DeadSpy~\cite{chabbi2012deadspy}, LoadSpy~\cite{loadspy}, provide low-level binary execution details. These tools use hardware performance monitoring units (PMUs) or binary instrumentation framework to analyze inefficient code generation but they lack the semantics from high-level Python code.


%loads the array object to perform some operations such as boundary check or raw data region load\footnote{Numpy array objects keep a pointer that points to the raw data region, where stores the real values.}, and return the indexing value back. From the Python source code aspect, arrays {\tt x} is accessed by different index in each iteration, which is not syntactically redundant. From native function aspect, without the knowledge of executing context in Python runtime, the native functions between each iteration are independent from each other, which is not logically redundant. However, from the omniscient point of view, array {\tt x} is repeatedly loaded by {\tt array\_subscript\_asarray} between iterations without modification, performing redundant \ffs. Listing~\ref{lst:motivated2} eliminates such redundancy and achieves 27.26$\times$ function speedup. This example highlights the importance of combining the knowledge from both high-level and low-level aspects on inefficiencies detection.


 
%Inefficiencies can arise from programmers' inattention of performance, inappropriate interface choice or flawed implementation method. \yu{polish}No matter what the root cause is, inefficiencies often behave as redundant \ffs in Python application, such as executing function with exact same context repeatedly\yu{CITE} or the result returned by the function is never used\yu{CITE}. Such kind of redundancies compose the majority of performance issues, because \ffs are quit expensive in Python applications.\yu{ADD A sentence: why expensive} Redundant \ffs not only introduce the wasting computations, but also derive overhead of Python runtimes. Locating and initiating function object, matching arguments' types and numbers, autoboxing and unboxing variables, acquiring global interpreter lock are some common overheads for each \ff \yu{CITE}. Although programmers can have highly-optimized native library with the help of profiling tools\yu{CITE} and compiler techniques\yu{CITE}, it can't easily neutralize the performance degradation caused by redundant \ffs in Python applications.
 
%However, it is quite difficult to detect redundant \ffs, because Python hybrid runtime forms a deep information gap between high-level applications and low-level systems. As shown in Figure~\ref{fig:hybridmode}, from high-level perspective, application delivers arguments and gathers returns to/from the library interfaces, without understanding the library behaviours on the operation system. From low-level perspective, library obtains arguments, executes and returns the computation results from/to the library interfaces, without knowing application executing context in Python runtime. Therefore, profiling information from either sides is not sufficient to detect redundant \ffs. Also, Python runtime has massive "noisy" operations, such as source code translation, memory pool management and garbage collection. These operations invoke additional computations or memory accesses, which buries  redundant \ffs in applications. It's difficult to distinguish runtime and application behaviors without high-level nor low-level information.






% \begin{figure}[t]
% \begin{lstlisting}[caption={Optimized code snippet for Listing~\ref{lst:motivated1}},label=lst:motivated2]
% def CEC_4(solution=None, problem_size=None, shift=0):
%     ...
%     res += np.sum(100 * np.square(x[0:dim-1]**2 -  x[1:dim]) + np.square(x[0:dim-1] - 1))
%     ...
% \end{lstlisting}
% %\vspace{-1em}
% \end{figure}





%The metrics they provide are
%limited in the Python runtime's scope, like function call based enumeration, line based execution time, objects' memory occupation and garbage collection overhead. They can not attribute some important system measurements like CPU cycles, stalls, cache misses and page faults. In other words, Python based profilers fail to provide valuable insights that how \ffs will behave on the operation system and impact to the hardware.

%Binary based profilers such as VTune~\cite{reinders2005vtune}, Perf~\cite{de2010new},
%Toddler~\cite{nistor2013toddler}, HPCTookit~\cite{adhianto2010hpctoolkit}, Witch~\cite{wen2018watching}, RedSpy~\cite{wen2017redspy}, DeadSpy~\cite{chabbi2012deadspy}, LoadSpy~\cite{loadspy} provide more advanced metrics obtained from hardware performance monitoring units (PMUs). They can identify inefficiencies that can not detected by Python based profilers. However, binary based profilers don't have enough domain information from Python runtime, resulting in profiling Python applications as binary executables. Due to the nature of interpreting execution, these binary based profilers 
%cannot map the inefficiencies to the Python source code. Also, binary based profilers fail to detect application inefficiencies accurately under the intervention of Python runtime, because the lack of domain information leads to the misestimation of inefficiencies. To sum up, binary based profilers cannot be directly applied for Python inefficiencies detection.
% For example, each Python dict object has a globally unique version number since the PEP509~\cite{pep509}. This version number is updated locally whenever a dict is modified and incremented globally whenever any dict is modified, but it is only used for implement fast guards on namespaces. When a code region modifies a Python dict with high frequency, the Python interpreter will update the dict's version number repeatedly without using it. The pattern that stores values to a same memory address again and again without loading them, is identified as dead store by binary based profilers. Binary based profilers will misreport this code region as an inefficiency. To sum up, binary based profilers can not be directly applied for Python inefficiencies detection.


Both existing Python and native profilers fail to identify the interaction inefficiencies. Motivated by the need to obtain holistic profiles from both Python code and native libraries, we propose \tool (\underline{P}ython \underline{I}nteraction in\underline{E}fficiency \underline{PROF}iler), a lightweight, insightful profiler to pinpoint interaction inefficiencies in Python programs. The key novelty is to leverage PMUs and other hardware facilities available in commodity CPU processors to monitor native execution and associate the analysis with Python semantics. 

\paragraph{Scope.}
First, we target only interaction inefficiencies between Python codes and native libraries, and measuring inefficiencies in pure Python or pure native codes is out of the scope. Second, we design \tool{} as a dynamic profiler that pinpoints inefficiencies in codes, but it is the responsibility of human programmers to investigate the profilers and optimize the codes. Third, \tool{} is input dependent; to ensure that it produces representative profiles, we recommend using typical inputs to study the given Python application. 


\paragraph{Our contributions.}
We made three contributions.
\begin{itemize}
\item We are the first to thoroughly study the interaction inefficiencies between Python codes and native libraries. We categorize the interaction inefficiencies by their root causes.

\item We design and implement \tool, the first profiler to identify interaction inefficiencies and provide intuitive optimization guidance. \tool works for production Python software packages in commodity CPU processors without modifying the software stack.

\item We utilize \tool to study more than 100 Python applications. We identify interaction inefficiencies in 17 real-world applications and optimize them for nontrivial speedups.
\end{itemize}

\begin{comment}
    \item We identified redundant \ffs as an important type of inefficiencies in Python applications.
    \item We characterized the Python inefficiencies into six types: loop invariant, input-based identical computation, inappropriate algorithm, slicing, redundant computation and API misuse.
    \item We proposed two novel Python inefficiency patterns: {\tt Mirror-nfc} and {\tt Ghost-nfc}. Our investigation of real-worlds Python applications shows that these two pattern are important indicators of Python diagnosis. 
    \item We design and implement a lightweight Python profiler \tool, to detect inefficiencies without curating the source code nor Python interpreter.
    \item Through our comprehensive evaluation, \tool can pinpoint inefficiency in well-known real-world applications with xx runtime overhead and xx memory, and yields up to xx speedups after eliminating the inefficiencies. 
\end{comment}

%reveal the inefficiency in motivated example shown in Listing~\ref{lst:motivated1}. The fundamental challenge here is to combine the information from top (applications) to bottom (operation system and hardware), but Python runtime builds a great barrier between them. This leads to our question: {\bf how can we perform a holistic profiling for Python applications?}

%We specifically aim to pinpoint inefficiencies rather than simply detect executing hotspots. Hotspots detectors are more suitable for understanding applications' behaviors but fail to categorize useful vs. wasteful resource usages. For example, repeatedly loading a constant array is apparently a wasting memory operation, but hotspots detectors show it as an efficient code region (good data locality) when measured by the metric of cache misses. Hotspots detectors highly restrain programmers' senses of whether a hotspot has potential optimizing opportunities or not.

%\myparabb{Our solution.} To address this issue, we focus on the redundant \ffs. Through the behaviors of \ffs, we characterize Python inefficiencies into \yu{TODO} categories. We propose \tool --- a lightweight profiler to perform the holistic profiling for Python applications. \tool detects redundant \ffs through monitoring accesses to Python Objects by applying PMUs and hardware debug registers. \tool builds hybrid call paths for Python applications by applying call stack unwinding and Python runtime inspection. Benefit from these two features, \tool can detect redundant \ffs and highlight inefficient code regions. To the best of our knowledge, \tool is the first holistic profiler to detect inefficiencies in Python applications. The contribution of this paper includes:

\paragraph{Organization.}
 Section~\ref{background} covers background and related work; Section~\ref{characterization} performs interaction inefficiency characterization; Section~\ref{design} describes the design and implementation of \tool; Section~\ref{evaluation} explains the evaluation; Section~\ref{casestudy} presentscase studies; Section~\ref{conclusions} concludes. 
 
% Despite the profiling granularity, we try to perform the profiling without curating applications' source code or Python interpreter.


% It is challenging to construct a holistic profiling for Python application. The challenges mainly come from x parts. First, it is difficult to gather 







\section{Introduction}
In recent years, Python has become the most prominent programming language for data modeling and library development, especially in the area of machine learning, thanks to its elegant design that offers high-level abstraction, and its powerful interoperability with native libraries that delivers heavy numeric computations. Decoupling data analysis and modeling logics from operation logics is the singular mechanism guiding the remarkable improvements in developers’ productivity in the past decade. Python enables small teams to build sophisticated model~\cite{meta} that were barely imaginable a few years ago, and enables large teams of modelers and numeric developers to seamlessly collaborate and develop highly influential frameworks such as Tensorflow~\cite{tensorflow2015-whitepaper} and Pytorch~\cite{paszke2017automatic}. %\textcolor{red}{Tied to ML? I am not sure if we should make this more general.} {\color{red} ZLiu: non-ml people dont really use Python (with native libraries)?}

While high-level languages to articulate business logics and native libraries to deliver efficient computation is not a new paradigm, downstream developers have not always understood the details of native libraries, and have implemented algorithms that interacted poorly with native codes. A well-known example of the \emph{interaction inefficiency} problem occurs when developers, who fail to recognize that certain matrix operations can be vectorized, write significantly slower loop-based solutions. MATLAB and Mathematica can alleviate the problem since these languages usually are locked with a fixed set of native libraries over a long time, and developers can establish simple best practice guidelines to eliminate most interaction inefficiencies (MATLAB contains the command, “try to vectorize whenever possible”). 


In the Python ecosystem, native libraries and downstream application codes evolve rapidly so they can interact in numerous and unexpected ways. Therefore, building a list to exhaust all interaction inefficiencies becomes infeasible. We seek a solution that will automatically identify the blocks of Python code that lead to inefficient interactions, through closing the knowledge gap between Python and native code. Existing profiling tools cannot address this issue. Python profiles~\cite{cProfile, guppy3, py-spy, pyflame, pyinstrument, pycallgraph, pprofile, memoryprofiler, austin} cannot step in native code so they do not know  execution details. Native profiling tools~\cite{reinders2005vtune, de2010new, nistor2013toddler, adhianto2010hpctoolkit, chabbi2012deadspy, wen2017redspy, loadspy, wen2018watching} can identify hotspots, which sometimes offer leads to problematic code blocks. But because these tools do not have knowledge about Python code's semantic, they cannot render detailed root cause and thus often make debugging remarkably challenging. 

%This problem is subtly different from mere performance tuning. For example, most profiling tools can identify hotspots, and with sufficient manual effort, a developer potentially can fix a misusage of native libraries. But tuning performance from hotspots deteriorates Python’s abstraction principle and drags model developers back to the days of excessive worry about details in lower-level software stacks.

%\textcolor{red}{Not very clear reference. which approach? some references may also help} Using hotspot-based profiling tools relies heavily on the assumption that an inefficient interaction directly translates to observable hotspots in benchmarks. More important, the approach deteriorates Python’s abstraction principle and drags model developers back to the days of excessive worry about details in lower-level software stacks.

We propose \tool, the first lightweight, insightful profiler to pinpoint interaction inefficiencies in Python programs. \tool works for production Python software packages running in commodity CPU processors without modifying the software stacks. 
Its backbones algorithmic module is a recently proposed technique based on hardware performance monitoring units (PMUs) and debug registers to efficiently identify redundant memory accesses (hereafter, referred to as CL-algorithm\footnote{Chabbi-Liu Algorithm.}~\cite{wen2018watching, su2019pinpointing}). CL-algorithm intelligently chooses a small collection of memory cells and uses hardware to track accesses to these cells at a fine granularity. For example, when the technique detects two consecutive writes of the same value to the same cell, it determines that the second write is unnecessary, and flags the responsible statement/function for further inspection. The developer can clearly see where a non-opt memory access occurs and why.  The technique already shows its potential for eliminating inefficiencies in monolithic codebases that use one programming language.

%CL-algorithm can be used in our setting because the most pronounced symptom of inefficient interactions is redundant memory accesses. \textcolor{red}{Check the grammar of the following sentence:}Nevertheless, correctly applying 

\tool leverages the CL-algorithm in a substantially more complex multi-languages environment, in which a dynamic and (predominantly) interpretation-based language Python is used to govern the semantics and native libraries compiled from C, C++, Fortran are used to execute high-performance computation. Doing so requires us to address three major challenges that crosscuts Python and native code. 

%We need tackle challenges that arise at three fronts. \textcolor{red}{Is this work only an application of an existing algorithm? may consider improving the presentation of the above two paragraphs.}

At the measurement front, we need to suppress false positives and avoid tracking irrelevant memory operations produced from Python interpreter and Python-native interactions. For example, memory accesses performed by Python interpreters may ``bait'' the CL-algorithm to waste resources (i.e., debug registers) on irrelevant variables such as reference counters. At the infrastructure front, we need to penetrate entire software stacks: it cannot see execution details (i.e, how memory is accessed) with only Python runtime information, or cannot understand program semantics with only native library knowledge. Our main task here is to compactly implement lock-free calling context trees that span both Python code and native libraries, and retain a large amount of information to effectively correlate redundant memory accesses with inefficient interactions. At the memory/safety front, we need to avoid unexpected behaviors and errors caused by Python runtime. For example, Python’s garbage collection (GC) may
reclaim memory that our tool is tracking. So delicate coordination between \tool and Python interpreter is needed to avoid unexpected behaviors and errors. 


% {\color{red} ZLiu: remove?}
%\yu{\tool takes the redundant memory access across native function calls as the indicator, collects instruction information of native functions and inspects Python runtime states on the fly, resulting in a holistic view for interaction inefficiency diagnosis. \tool organizes the profiling data with a novel lock-free calling context tree, to reduce the heavy memory consumption caused by recording dynamic information of Python runtime. \tool applies multiple methods to make sure the profiling procedure works well under the interfering of Python runtime.}


\iffalse
We propose \tool, the first lightweight, insightful profiler to pinpoint interaction inefficiencies in Python programs. \tool works for production Python software packages in commodity CPU processors without modifying the software stacks. Its barebones algorithmic module is a recently proposed technique based on hardware performance monitoring units (PMUs) and debug registers to efficiently identify redundant memory access. The technique intelligently chooses a small collection of memory cells and uses hardware to track accesses to these cells at a fine granularity. For example, when the technique detects two consecutive writes of the same value to the same cell, it determines that the second write is unnecessary, and flags the responsible statement/function for further inspection by the developer. The developer can clearly see where an inefficient memory access occurs and why.  The technique already shows early signs of potential in monolithic codebases that use one programming language (Java CITE and C++ CITE). 

\yu{(we need to emphasize the relationship: redundant memory access->redundant native function calls-> interaction inefficiency)}

\yu{We aim to apply this technique for a more complex goal: diagnosing interaction inefficiencies under a multi-language environment, in which a dynamic and (predominantly) interpretation-based language Python is used to govern the semantics and a static and compilation-based language(C, C++ or Fortran)is used to execute high-performance computation. Such a methodology brings us three major challenges.} 
% We aim to deploy this technique to a substantially more complex multi-language environment, in which a dynamic and (predominantly) interpretation-based language Python is used to govern the semantics and a static and compilation-based language \yu{ (C, C++ or Fortran)} is used to execute high-performance computation. We need to address two major challenges.  {\color{red} bring up interaction inefficiencies.}

\yu{First, it requires to accurately identify redundant memory access related to interaction inefficiencies. Either the noise triggered from software stack's upper-level such as the interfering of the Python garbage collector(GC), or the lower-level such as the memory inefficiencies inside native libraries, can be barriers to locate interaction inefficiencies. Second, diagnosing interaction inefficiencies needs to penetrate the entire software stacks: it cannot see execution details (i.e, how memory is accessed) with only Python runtime information, or cannot understand program semantics with only native library knowledge. The major task here is to compactly implement calling context trees that span both Python code and native libraries and retain a considerably larger amount of information compared to existing ones CITE. Third, coordinating upper/lower-level behaviors of software stack is a basic building block to deploy the hardware technique (PMUs and hardware debug registers) for detecting interaction inefficiencies. Without such a mechanism, both of layers in software stack can interfere each other, such as GC frees the memory location which the debug register is monitoring, or the PMUs interrupt the Python runtime in a improper moment, leading to unexpected errors.}
\fi



% First, PieProf needs to penetrate the entire software stacks implemented in different language. PieProf cannot see execution details (i.e, how memory is accessed) if implemented at Python interpreter, and cannot understand program semantics if implemented at the native library level. Our major task is to compactly implement calling context trees that span both Python \yu{code and native libraries} and retain a considerably larger amount of information compared to existing ones CITE. \yu{Specifically, PieProf not only requires to collect instruction information of native functions, but also needs to inspect Python runtime states on the fly, resulting in a holistic view for interaction inefficiency diagnosis.}


% Second, PieProf needs to circumvent nuances produced by non-interacting code. It needs to avoid investing resources to track redundant memory access within the same native function calls, or within pure Python code (which can be found by existing solutions CITE CHECK). It also needs to safely handle operations triggered by Python interpreters. For example, garbage collectors \jtan{(GC)} could frequently change reference counters or deallocate the memory that we are tracking. Thus, PieProf needs to carefully interact with GC to avoid tracking irrelevant variables (reference counters) or avoid segmentation fault.  

We note that while most of the downstream applications we examined are machine learning related, \tool is a generic tool that can be used in any codebase that requires Python-native library interactions. 



\begin{comment}
{\color{red}Xu: I think we should separate contribtion and outlines.} We designed and implemented \tool, and ran it over a large set of codebases. In our paper we explain four aspects of the problem/solution. 


\noindent{\emph{Section 3}}: We provide the first characterization of interaction inefficiencies, which reveals that (i) interaction inefficiencies widely  even in highly popular open source packages, demonstrating the importance of eliminating the problem, and (ii) professionals, not amateurs, developed a significant fraction of the inefficiencies we discovered. Our findings confirm the challenges of writing high quality code under tight engineering and time resource constraints, and highlights the need to build automatic tools to detect inefficiencies. 


\noindent{\emph{Section 4}}: We explain the design and implementation of \tool, and how how we address the aforementioned challenges. 


\noindent{\emph{Section 5}}: We use \tool to study a collection of highly ranked Python applications, including widely used ones like Scikit-learn \jtan{cite here or in the table}, Pytorch, and highly specialized ones like Meta-heuristics. By running only sample code provided by the applications, we identify actionable interaction inefficiencies from 17 applications with {\color{red}inconsequential} overheads. Moderate refactoring effort leads to significant performance improvement (e.g., half of them have 100\% or more improvement at the functional level). This is quite unexpected because happy paths (provided sample code) in high-profile projects usually are carefully optimized and have low coverage of codebase. %{\color{red} low overheads.}


%We use \tool to study more than 100 highly ranked Python applications in Github. We identify interaction inefficiencies in 17 real-world applications and optimize them for nontrivial speedups. \yu{with low oeverhead}


\noindent{\emph{Section 6}}: We compare \tool with existing tools in XXXgive numberXXX case studies and discuss the findings. 







Both existing Python and native profilers fail to identify the interaction inefficiencies. Motivated by the need to obtain holistic profiles from both Python code and native libraries, we propose \tool (\underline{P}ython \underline{I}nteraction in\underline{E}fficiency \underline{PROF}iler), a lightweight, insightful profiler to pinpoint interaction inefficiencies in Python programs. The key novelty is to leverage PMUs and other hardware facilities available in commodity CPU processors to monitor native execution and associate the analysis with Python semantics. 

\paragraph{Scope.}
First, we target only interaction inefficiencies between Python codes and native libraries, and measuring inefficiencies in pure Python or pure native codes is out of the scope. Second, we design \tool{} as a dynamic profiler that pinpoints inefficiencies in codes, but it is the responsibility of human programmers to investigate the profilers and optimize the codes. Third, \tool{} is input dependent; to ensure that it produces representative profiles, we recommend using typical inputs to study the given Python application. 
\end{comment}

\myparabb{\textbf{Contributions.}}
We make three contributions.
\begin{itemize}
\item We are the first to thoroughly study the interaction inefficiencies between Python codes and native libraries. We categorize the interaction inefficiencies by their root causes.

\item We design and implement \tool, the first profiler to identify interaction inefficiencies and provide intuitive optimization guidance, by carefully stepping through Python runtimes and native binaries. \tool works for production Python software packages in commodity CPU processors without modifying the software stacks.

\item Following the guidance of \tool, we examine a wide range of influential codebases and identify interaction inefficiencies in 17 real-world applications and optimize them for nontrivial speedups.
\end{itemize}


%\textcolor{red}{We usually omit this to save space. We can highlight some evaluation results here instead.}

\myparabb{\textbf{Organization.}}
Section~\ref{background} reviews the background and related work. Section~\ref{characterization} characterizes the interaction inefficiencies. Section~\ref{design} describes the design and implementation of \tool. Section~\ref{evaluation} explains the evaluation. Section~\ref{casestudy} presents case studies. Section~\ref{validity} discusses some threats to validity. Section~\ref{conclusions} presents some conclusions. 
 







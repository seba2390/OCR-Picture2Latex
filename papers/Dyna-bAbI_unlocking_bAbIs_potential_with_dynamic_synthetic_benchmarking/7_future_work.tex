Our work opens up multiple new directions for future research. \pybabi is readily extendable, for systematic probing of more diverse linguistic phenomena. A beneficial first step could include integration of other bAbI tasks such as spatial reasoning and agent motivations. That said, our experience suggests that the design of truly scalable synthetic and dynamic benchmarks poses significant theoretical and engineering challenges, warranting deeper research on their own right.

Our results raise new questions about the viability of learning robust situation models using standard question-answering training methods, and our datasets present new modelling challenges for future efforts. 

Additionally, \pybabi can naturally complement parallel work probing the the situation representations constructed by neural language models~\citep{li-etal-2021-implicit}, by facilitating tailored data generation for specific questions, thus broadening and deepening the scope of possible research.

In conclusion, we introduced \pybabi, a new framework for highly controllable bAbI task generation. We used it to create compositional generalization datasets providing new modelling challenges for state-of-the-art neural language models. More broadly, our results underscore the importance of agile development of benchmarks themselves, beyond only the models solving them.


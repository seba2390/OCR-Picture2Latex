% !TEX root = main.tex
% \documentclass[../main.tex]{subfiles}

% \begin{document}

\section{Related work} \label{sec:relatedwork}

First, we cover general theories of submodularity in sequences and explain how they cannot model the types of problems that our definition does. Then, we discuss applications in the specific context of recommender systems.

\subsection{Existing frameworks for submodularity in sequences} 
Alaei, Makhdoumi, and Malekian (2010) introduce the first generalizations of \emph{sequence-submodularity} and \emph{sequence-monotonicity} in the context of online ad allocation, and show that the greedy algorithm for sequence-submodular maximization achieves a $(1-\frac{1}{e})$-approximation to the optimal solution~\cite{Alaei19}. However, a major limitation of their model is that their definition of sequence-monotonicity is extremely strong. Their result requires that $f(A) \le f(B)$ for any sequences $A$ and $B$ such that $A$ is a subsequence of $B$, which in many settings is too restrictive to be useful. For instance, if an element $s_1$ only contributes to the value of the objective function when included as the first element of the input sequence but not as the second, it is possible to have $f(s_1) > f(s_2 s_1)$, violating sequence-monotonicity.

Similarly, Zhang et al. (2013) study the maximization of \emph{string submodular} functions of strings (or sequences) of actions chosen from a set, a notion similar to sequence-submodularity but only requiring monotonicity and diminishing returns with respect to prefixes, not all subsequences~\cite{Zhang16}. When the function also satisfies monotonicity with respect to postfixes and not only prefixes, then they, too, establish a $(1-\frac{1}{e})$-approximation ratio for the greedy algorithm, and provide improved guarantees when additional curvature constraints are satisfied. More formally, \emph{prefix/postfix monotonicity} requires that for any sequences $A$ and $B$ and their concatenation $A||B$, it must hold that $f(A||B)\ge f(A)$ (prefix monotonicity) \emph{and} $f(A||B) \ge f(B)$ (postfix monotonicity), properties which were both previously suggested by Streeter and Golovin (2008), who considered sequences in the context of an online submodular selection problem~\cite{StreeterGolovin}. As seen above, postfix monotonicity is not a natural property when modeling attention drop-off, since it would imply that prepending a ``bad'' movie that interests nobody at the front of a ranked list would capture more users, which clearly is not the case.

In another direction, Tschiatschek, Singla, and Krause (2017) approach the selection of maximizing sequences using submodularity by encoding sequential dependencies in a directed acyclic graph~\cite{Tschiatschek2017}, and Mitrovic et al. (2018) generalize this concept from DAGs to hypergraphs~\cite{Mitrovic18}. They place an edge between two nodes $(u,v)$ of the graph if there is additional utility in selecting element $u$ before element $v$, and then consider submodular functions on the edge set of the graph. However, this approach is only able to represent sequential dependencies inherent to the identity of a set of elements (for example, watching a prequel before the sequel), but it cannot represent decreasing attention or other complex dependencies dependencies that may vary with the objective function, or with the position and identity of other elements in the input sequence. 

Most recently, Bernardini, Fagnani, and Piacentini (2021) propose a framework in which the set of all elements is equipped with some property $g$, according to which it has a total ordering. Their objective function is defined recursively as the sum of the marginal increase of appending each element $\sigma$ to the list of earlier elements, weighted by $g(\sigma)$. Denoting the subsequence of the first $i$ elements in the list as $S_i$, for any function $g$ and any monotone submodular set function $h$, they study sequence functions of the form 
$$f(s_1 \dots s_k) = \sum_{i=1}^k g(s_i) \cdot [ h(S_i) - h(S_{i-1}) ].$$
Phrased this way, the sequential nature of the problem results from considering the marginal increase due to each element with respect to the set of elements before it, but the weight assigned to each marginal increase depends solely on the \emph{identity} of the element, not its rank. While this is a valid assumption in a number of applications, it does not hold in our particular use case of modeling sequential attention drop-off. In contrast, our framework encompasses functions of the form 
$$f(s_1 \dots s_k) = \sum_{i=1}^k g_i \cdot [ h(S_i) - h(S_{i-1}) ],$$ 
where $g_i$ can be thought of as the weight assigned to \emph{rank} $i$. This key difference allows us to avoid imposing a total $g$-ordering on the set of all elements (even if such an ordering does exist, this information may not be known to a system designer). Perhaps more significantly, it also introduces an additional sequential aspect that further differentiates our approach from traditional set submodularity. 


\subsection{Applications to diversifying and calibrating recommendations} 

One important topic in content presentation is the problem of curating search results that are useful to a diverse population of users. Agrawal et al. (2009) establish a mathematical formalization of this \emph{user coverage} problem, which they study through the lens of submodularity~\cite{agrawal2009}. They suppose that each item has some probability of satisfying every user type. Then, they seek to display a diverse set of search results to maximize the number of users who find at least one satisfactory document. That is, given a query, they seek to select $k$ search results to maximize the probability that a randomly chosen user drawn from a heterogeneous group likes at least one item in the set. The authors show that this objective is a monotone submodular set function, and consequently observe that there exists a $(1-\frac{1}{e})$-approximation algorithm for the problem. While mathematically elegant, a key limitation of this formulation is that it assumes that all users are equally patient and give equal consideration to all search results. Acknowledging that this is not an accurate representation of human patience and attention in the real world, the authors suggest as a direction for future work the formulation of an objective function that accounts for the distribution of users who stop at different points in the search results. Our work does exactly this. In doing so, the presentation order of the search results becomes important, and the objective function becomes a sequence function that must be studied using our new definition of ordered submodularity. 

Ashkan et al. (2015) also study diversification for user coverage in recommender systems, this time using a modular function subject to a submodular constraint~\cite{ashkan2015}. They maintain the consideration that recommendations should not be \emph{only} diverse, but also still broadly relevant and useful, by maximizing a weighted sum of a diversification metric and the sum of all the utilities of the recommended items. In their setup, the greedy approach to maximization is optimal. But again, their formulation assumes that all users have equal patience and consider all recommendations equally, so their optimality result does not hold when users have differential patience values. 

% \ercomment{how to distinguish diversity and calibration?? seems that broadly speaking, we can think of diversity as a property useful for large heterogeneous groups, and calibration as a property useful for personalizing to one user?}

% \jkcomment{I was also thinking about how to describe the relationship between the two problems. One possible way to think about it might be that "diversity" in recommendation results is a general informal term for having a set of results that aren't all the same; the coverage objective function is one way to get diversity, and the calibration objective function is another way to get diversity. (I also thought about the aspect of calibration being specific to one user, but you could potentially also say that for coverage if the situation is that you don't know which type the user is, so you show results that cover many types.)  Section 5.1 of the Steck paper gives his take on the difference between these different problem formulations, which is related though with a bit different emphasis.} 

Steck (2018) also considers the question of creating diversity in lists of recommendations, but with the different goal of creating recommendations that are \emph{calibrated} to the user's interests~\cite{Steck18}. (We note that in the literature, ``diversification'' has historically been used to refer to variants of the coverage problem previously discussed, but we find it more useful to think of ``diversity'' as a general concept describing lists that include a mixture of categories. The coverage objective is one way to achieve diversity by including as heterogeneous a mixture as possible; the calibration objective is another way that includes categories in a proportional mixture. Section 5.1 of~\cite{Steck18} discusses the relationship between diversity, calibration, and other metrics in more detail.) Steck proposes as a heuristic for calibration a modified version of the KL divergence from the recommended distribution to the user's preference distribution. When all the recommended items are assigned equal weight, this induces a submodular set function, which can be used for approximate maximization via the greedy algorithm. But in the case when the recommended items have unequal weights, such as when accounting for attention dropoff, his approximation results do not apply. We discuss more of the technical details of Steck's formalism in Section~\ref{sec:calibration} and describe extensions to our ordered-submodular optimization framework for sequences.

Lastly, another setting in which some notion of weights appears in submodular optimization is the context of knapsack constraints or budgets~\cite{Sviridenko, Alon2012, SomaKIK14}. Here, we note that despite the initial similarities in terminology, the use of weights as capacities in this line of work is quite different from the attenuation of attention and impact that we intend our weights to represent.

%\end{document}
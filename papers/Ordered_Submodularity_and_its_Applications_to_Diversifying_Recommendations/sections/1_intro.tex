% \documentclass[../main.tex]{subfiles}
% % \graphicspath{{\subfix{../images/}}}

% \begin{document}
% !TEX root = main.tex

\section{Introduction} \label{sec:intro}

Many important optimization problems involve selecting a subset
of items from a larger set. Examples of such tasks include influence
maximization in social networks~\cite{KKT03}, sensor placement and
experimental design~\cite{krause2008robust}, and recommendation
systems~\cite{Yue11, gabillon2013adaptive}. In domains in which the
goal is this type of subset selection,
\emph{submodularity} has been widely used to express the notion of
``diminishing marginal returns.'' Submodularity is a powerful
framework for approximate optimization; in particular, there is a rich
literature on approximation algorithms for selecting subsets 
achieving near-maximum value with respect to a submodular function
\cite{nemhauserwolseyfisher1978,
calinescu2011, filmus2013, vondrak2013, krause2014survey}.

An implicit modeling assumption in the use of submodularity is
that the order of the selected elements does not matter;
this is crucial, since submodularity is a property of functions
that operate on unordered sets.
However, in many applications, we are interested not only in the
elements of a set, but also the order in which the elements appear.
A broad category of such applications, in both on-line and off-line
settings, is the presentation of content to an audience ---
for example, search results, product or entertainment recommendations, 
news articles, social media posts, and many other instances.
Content presentation crucially depends on sequential effects 
due to well-documented phenomena in human behavior ---
specifically, that human cognition is generally limited to
serially processing information one piece at a time, rather than
processing all elements of a list in parallel. Moreover, people tend
to have limited attention span and patience, meaning that when
items of content are presented in a ranked list,
the higher-ranked items are likely to receive significantly greater attention
\cite{pan2007google}. This results in several empirical
observations, such as inverse power law relationships in number of
clicks on search results~\cite{williamsZipf} and sharp decreases in
webpage viewing time ``below the fold'' (content that does not fit on
the first screen and must be scrolled down to reach)~\cite{NNGfold}.

The use of optimization frameworks for content presentation
suggests some of the fundamental limits in the application of submodularity
for problem domains where sequential effects are important.
In particular, for a number of basic problems in ranking and recommendation,
standard formalisms model them as the problem of selecting
a subset of items to present to a user, then showing that
the resulting objective function over selected subsets is
submodular, and thus deriving guarantees for
approximating this objective function.
But if the value of a set of items to a user is strongly
dependent on the order in which it is presented, 
then the optimization is in fact taking place over sequences rather
than sets, and in this richer formalism submodularity would not
be applicable.

Our goal in this paper is to propose a formalism that can address 
these types of ordering issues in optimization problems generally,
and for a collection of basic content presentation problems in particular.
We begin by observing (and demonstrating in Section~\ref{sec:relatedwork})
that while other generalizations of submodularity to sequences 
have been formulated, they fundamentally make assumptions that are not
well-suited to modeling the sequential effects that arise from
phenomena like the diminshing attention of a user reading a ranked list.
Hence, a new notion of
submodularity for sequences is required. Here, we present such a
generalization of a combined monotonicity-submodularity property,
which we term \emph{ordered submodularity}.
We provide approximation guarantees for functions of this type,
and we show how they capture the sequential effects in a
range of standard content presentation problems.

\paragraph{\bf Motivating applications.} 
Throughout our work, it is useful to keep in mind the following two
standard problems in ranking and recommendation that help motivate our work.
The first is a {\em coverage} problem that is used for creating diversity
in ranked lists of items as follows 
\cite{agrawal2009, ashkan2015}.
Suppose we want to produce a list of $k$ recommendations (say of movies)
to show to a group of users.
Each movie can satisfy only some subset of the users, and we would like
to choose the $k$ movies so to maximize the number of users 
who like at least one item on the list.
(In this way, we seek to cover their preferences as completely as
possible with $k$ items.)
We can view the number of users satisfied 
as an objective function on the set of
$k$ items chosen; in \cite{agrawal2009} it is shown that this function
is monotone and submodular, and hence greedy maximization provides a
$(1-\frac{1}{e})$-approximation.
But as the authors of \cite{agrawal2009} observe, in the real application
users will have declining attention as they process the list of items,
and different users will stop reading the list at different points.
This basic addition to the model --- that users have
differential patience --- 
means that the order of the list is crucial for evaluating
the number of users that it satisfies; and once we introduce
ordering into the problem, the results from the large body of work on
submodular optimization no longer hold in this setting.
Is there still a way to find good approximations to the optimal 
ranked list?

The second problem we draw on for motivation is the task of
{\em calibrating} recommendations \cite{Steck18}.
In this problem, we present a list of $k$ recommendations
to a single user (again, suppose they are movies);
and we assume that each movie represents a distribution over {\em genres}.
(For example, a documentary in Italian about the national soccer team is a multi-genre mixture of a movie about sports, an Italian language film, and a documentary.)
The list of $k$ items thus induces an {\em average} distribution
over genres.
Now, the user has a {\em target distribution} over genres that
reflect the extent to which they want to consume each genre
in the long run.
A natural goal is that the average distribution induced by the
list of recommendations should be ``close'' (in a distributional sense)
to the target genre distribution of the user;
when these two distributions are close, we say that the set of
recommendations is {\em calibrated} to the user.
(For example, a user who likes both Italian language films and movies about sports might well be dissatisfied with recommendations consisting only of sports movies in English;
this set of recommendations would be badly calibrated to the
user's target distribution of genres.) 
For natural measures of distributional similarity, the selection of a
set of $k$ items to match the user's target distribution can be
formulated as the maximization of a submodular set function.
But here too, the work introducing this problem observed that since
user attention diminshes over the course of a ranked list, the
list of $k$ items is really producing a {\em weighted average} over
the genres of these items, with the earlier items in the list 
weighted more highly than the later ones \cite{Steck18}.
Once we introduce this natural addition to the problem, based on
ordering, it again
becomes unclear whether there are good algorithms to find provably
well-calibrated lists of recommendations.

\paragraph{\bf A new definition of ordered submodularity.}
In this paper we introduce a property called {\em ordered submodularity}
that can be viewed as an analogue of monotonicity and submodularity
for functions defined on sequences.
It captures both of the motivating applications described above,
and more generally captures a category of optimization problems 
which search over lists, and in which different list positions 
contribute differently to the objective function.

We define the property as follows.
Let $f$ be a function defined on a sequences of elements from some ground set;
we say that $f$ \emph{ordered-submodular} if for all
sequences of elements $s_1 s_2 \dots s_k$, the following property
holds for all $i \in [k]$ and all other elements $\bar{s}_i$: 
$$f(s_1 \dots s_i) -
f(s_1 \dots s_{i-1}) \ge f(s_1 \dots s_i \dots s_k) - f(s_1 \dots
s_{i-1} \bar{s}_i s_{i+1} \dots s_k).$$

Notice that if $f$ is an ordered-submodular function that takes
sequences as input but does not depend on their order
(that is, it produces the same value for all permutations of
a given sequence), then it follows immediately from the definition
that $f$ is a monotone submodular set function.
In this way, monotone submodular set functions are a special
case of our class of functions.

We prove that for any ordered-submodular function $f$,
the natural greedy algorithm for maximizing $f$ --- building 
a sequence by always appending the item that produces the
largest marginal gain --- is a $2$-approximation, and there
are simple examples of ordered-submodular functions for which
the greedy algorithm does no better than a factor of $2$.
This highlights a key distinction from the unordered case of
monotone submodular set functions: there the corresponding
greedy algorithm produces the strictly better approximation
guarantee of $(1 - 1/e)$. 
Hence the move to ordered submodularity
changes the approximability of the maximization problem
in a qualitative way: it still admits a small constant-factor bound,
but a different constant.

In the coverage problem described above 
with users of differential patience, we show directly that
the objective function is ordered-submodular, and this provides
the first non-trivial approximation guarantee for this problem.
(This problem provides some of the simple examples
in which the factor of 2 is tight for the performance of
the greedy algorithm.)
For the calibrated recommendation problem with ranked lists
described above, we need to specify how the distance between
distributions will be measured;
we show that that natural ways of measuring distance (such as the
classical family of $f$-divergences from the statistics and
information theory literature) give rise to ordered-submodular functions.
We thus obtain the first non-trivial approximation guarantee for this 
ordered problem as well.
As noted above, we find it interesting that existing formalisms
extending submodularity to sequences do not capture the
objective functions arising from problems such as these two,
and the way in which items in these problems 
contribute based on their position in a ranked list.\footnote{As one
indication of the differences at work, these earlier formalisms 
for submodularity over sequences have the property that 
the greedy algorithm continues to be a $(1-1/e)$-approximation
for the corresponding maximization problem.
But for the ordered coverage problem we have described here,
the greedy algorithm can differ from the optimum by a factor of 2;
this is the tight bound on its approximation performance, and it suggests
that the problem has a qualitatively different type of objective function.}
In the next section, we provide some detail for why these
alternative formalisms differ from our proposal and do not capture the objective functions
we consider in the paper; following this, we establish our
approximation results and their application to the problems discussed here.

%\end{document}

% this kind of attention drop-off due to rank.




% In the context of content ranking, i.e. the task of recommending to a
% user a sequence of items (web search results, suggested movies to
% watch, news articles, etc.) to maximize some measure of welfare,
% presentation order matters for this exact reason. Submodularity has
% been used to study content ranking and recommender systems, but the
% traditional set function formulation fails to capture these ordering
% effects. While other theories of submodularity in sequences have been
% formulated, they fundamentally make assumptions that are not
% well-suited to modeling this kind of attention drop-off due to rank,
% as we discuss in Section~\ref{sec:relatedwork}. Hence, a new notion of
% submodularity for sequences is required. Here, we present such a
% generalization of a combined monotonicity-submodularity property,
% which we term \emph{ordered-submodularity}.

% \todo{restructure -- 'here are two problems in recommending a list: diversification for coverage and calibration in personalization. here are two papers studying these issues. both of them raise the issue that this is unordered. but we would like to study earlier elements having more impact, in the ordered setting.}

% , articulated by Steck in his formulation of the problem
% \cite{Steck18}, is that 


% simple
% illustrative example of user impatience. Suppose we seek to curate a
% list of recommendations for a group of impatient users. Each movie can
% satisfy some subset of the users, but because of their impatience,
% each user is only willing to consider the first few suggestions
% (possibly a different amount for each user) before they get tired of
% scrolling and decide to walk away unsatisfied. Our goal as the system
% designer is to maximize the total number of users that our
% recommendation list satisfies. Note that the unordered version of this
% problem is an instance of the maximum coverage problem, one of the
% most classical NP-hard problems that can be approximated using
% submodularity. Indeed, the corresponding problem without finite
% patience limitations (perhaps the ``patient users'' problem) has been
% studied as an instance of monotone submodular set function
% maximization with a $(1-\frac{1}{e})$-approximation
% algorithm~\cite{agrawal2009, ashkan2015}. But once we introduce
% ordering into the problem, the results from the large body of work on
% submodular optimization no longer hold in this setting.\jkcomment{I'm
% realizing that there's a slight asymmetry in our naming of problems:
% both of our problems involve impatient users in a sense, and they
% differ more in that one is about calibration and one is about
% coverage. So I was starting to wonder if we should give this problem
% some name that involves "coverage" problem rather than calling it the
% "impatient users" problem. I do think "impatient users" evokes the
% right thing, but in a sense it applies to any problem (including our
% other one) where attention decreases over a list.}






% \todo{'this property is intended to generalize the properties the aplications have'.  our framework is more generally applicable to a wide range of optimization problems in which different list positions possess different properties, *including* the two we mentioned above}

% When $f$ is viewed \etcomment{is viewed the right word here? You mean when $f$ is such a function} as a set function that does not depend on the order of the elements in the input sequence, we recover the conventional properties of monotonicity and submodularity for set functions, indicating that our definition is a natural extension to the sequential setting. \etcomment{an alternate proposal for the end of this sentence, starting with "we recover": this property follows by combining monotonicity and submodularity, and has both monotonicity and submodularity as special cases.}


% \ercomment{is the ordering of sections (``finally'' but section 4 is before 5/6) weird?}\etcomment{How about just avoiding the word "Finally", and maybe calling it "Our main result in this paper" or something like this. Maybe calling it main result is bad: as suggesting the formalism and the application is clearly a main part also, maybe more main. But without a theorem we would have a paper, so maybe OK to call it main.}
% \jkcomment{I'm wondering if we should mention the 2-approximation higher up in the introduction, for example shortly after we introduce the definition, so that people get a more direct sense for the benefit of showing that objective functions satisfy the definition.} \etcomment{good idea! Maybe even the tightness to distinguish our model from the ones with the usual $(1-1/e)$ bounds!}

% , we study the natural greedy algorithm for ordered-submodular maximization in Section~\ref{sec:greedy_analysis} and prove that it is a $2$-approximation for this general class of problems. This performance bound is tight, including tight instances on the impatient users problem. 


% \etcomment{I don't understand the next two sentences. Property clearly true, but seems to be different than what ordered submodularity expresses.} Intuitively, in the impatient users application, appending a movie to the end of a list cannot decrease the number of satisfied users. Appending a movie later also satisfies fewer users than if it were added earlier in the sequence (since some of the users it could have satisfied may have been already satisfied by an earlier movie, or have just given up and walked away). In Section~\ref{sec:coverage}, we formally define the impatient users problem and show that it indeed can be modeled by our definition.


% In fact, our interest in this class of problems originated not from impatient users, but from a different problem in content management: calibrated recommendations. In this setting, we seek to generate a personalized list of recommendations for each individual user based on their historical preferences. It is generally desirable that our list of recommendations is not only accurate \etcomment{what is accurate} \ercomment{something about recommending things that are relevant and/or that the user is likely to enjoy?} but also \emph{calibrated}, meaning that it closely reflects the user's various interests in appropriate proportions. \etcomment{I would say more what calibrated is. I don't think most readers will know, and even if they do, they won't be upset if we say more. Not sure how to do this without naming a topic. We could go to restaurants, say and suggest "for example, in restaurant recommendations, a calibrated system needs to recommend a mix of cuisines, not only the cuisine the user selects most often". } Calibration heuristics have previously been studied under the lens of submodularity~\cite{Steck18}, and indeed, if users place equal weights on all items of a recommended set, calibration can be viewed as a submodular set optimization problem. However, we seek to model calibration more accurately by accounting for the fact that people place more weight on higher recommendations in the sequence. 

% Studying calibration requires a quantitative measure of ``closeness'' between the target distribution and the distribution induced by the list of recommendations. To enable this, we introduce the notion of \emph{overlap} between distributions, with the property that maximizing overlap is a heuristic for maximizing calibration. In Section~\ref{sec:calibration}, we formalize these definitions of calibration and overlap measures, and we establish that natural ways of measuring closeness (such as the classical family of $f$-divergences from the statistics and information theory literature) give rise to ordered-submodular functions. 



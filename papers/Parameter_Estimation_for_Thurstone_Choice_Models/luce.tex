
\begin{equation}
\ell(\theta) = \sum_{t=1}^m \log\left(\frac{e^{\theta_{y_t}}}{\sum_{v\in S_t}e^{\theta_v}}\right).
\label{equ:llikluce}
\end{equation}

\begin{theorem} If $\lambda_2(L_{\vec{M}})>0$, then with probability at least $1-2/n$, the maximum likelihood estimator $\widehat\theta$ satisfies
$$
\mse(\widehat\theta, \theta^\star)
\le c_{k,b}^2\frac{n(\log (n)+2)}{\lambda_2(L_\vec{M})^2}\frac{1}{m}
$$
where $c_{k,b} = 4k^2e^{4b}$.
\label{thm:full}
\end{theorem}

The log-likelihood function satisfies, for all $\theta\in \reals^n$,
$$
\frac{\partial^2 \ell(\theta)}{\partial \theta_i^2} = -\sum_{j\neq i} \frac{\partial^2\ell(\theta)}{\partial\theta_i \partial \theta_j} \hbox{ for all } i\in \{1,2,\ldots,n\}
$$
which is equivalent to $\nabla^2(-\ell(\theta))\vec{1} = \vec{0}$. Hence, by Lemma~\ref{lem:mle-taylor}, if $\min_{\theta\in \Theta}\lambda_2 \left(-\nabla^2 \ell (\theta) \right)>0$, we have
$$
\|\hat{\theta}-\theta^\star \|_2\le \frac{2\left\|\nabla (-
\ell (\theta^\star)) \right\|_2}{\min_{\theta \in \Theta }\lambda_2 \left(\nabla^2 (-\ell (\theta)) \right)}.
$$
This combined with the following two lemmas yields the statement of the theorem. 

\begin{lemma} The following lower bound holds:
\begin{equation}
\min_{\theta \in \Theta}\lambda_2 \left(\nabla^2 (-\ell (\theta)) \right) \ge \frac{1}{k^2 e^{4b}}\frac{m}{n} \lambda_2 (L_\vec{M}). 
\label{eq:w-l}
\end{equation}
\label{lem:L11}
\end{lemma}

 
\begin{lemma} With probability at least $1-2/n$,
\begin{equation}
\left\| \nabla (-\ell (\theta^\star)) \right\|_2 \le  2\sqrt{m (\log (n)+2)}. 
\label{eq:w-u}
\end{equation}
\label{lem:L12}
\end{lemma}


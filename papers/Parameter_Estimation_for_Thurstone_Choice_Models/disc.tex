
In this section, we discuss how the number of observations needed to attain a prescribed parameter estimation error depends on the cardinality of comparison sets. 

In Section~\ref{sec:mse}, we found that for a priori unbiased input comparisons, where each comparison set is of cardinality $k$ and is drawn uniformly at random from the set of all items, the number of observations needed for the mean squared error to be within a prescribed tolerance is of the order $\gamma_{F,k}$, defined by (\ref{equ:gamma}). In Section~\ref{sec:classy}, we found that this also so to ensure that the probability of classification error is within a prescribed tolerance. 

\begin{table}[h]
\caption{The values of parameters for our examples of \GT.}
\begin{center}
\begin{tabular}{c|cc}
$F$ & $\frac{\partial p_k(\vec{0})}{\partial x_1}$ & $\gamma_{F,k}$\\\hline
Gaussian & $O(\frac{1}{k^{2 - \epsilon}})$ & $\Omega(\frac{1}{k^{2\epsilon}})$\\
Double-exponential & $\frac{1}{\beta k^2}$ & $\beta^2\frac{k}{k-1}$\\
Laplace & $\frac{1-1/2^{k-1}}{\beta k(k-1)}$ & $\beta^2\frac{k-1}{k(1-1/2^{k-1})^2}$\\
Uniform & $\frac{1}{2a(k-1)}$ & $4a^2\frac{k-1}{k^3}$
\end{tabular}
\end{center}
\label{tab:gamma}
\end{table}

In Table~\ref{tab:gamma}, we show the values of the parameter $\gamma_{F,k}$ for several special instances of the Thurstone choice model, along with the values of $\partial p_k(\vec{0})/\partial x_1$. From the expressions in Table~\ref{tab:gamma}, we observe that for all the cases but the case of uniform distribution of noise, $\gamma_{F,k}$ decreases with the cardinality of comparison sets, but in a slow manner according to a diminishing returns relation. In particular, observe that for both double-exponential and Laplace distribution of noise, $\gamma_{F,k} = \Theta(1)$ and for Gaussian distribution of noise $\gamma_{F,k} = O(1/k^\epsilon)$. On the other hand, for uniform distribution of noise, $\gamma_{F,k} = \Theta(1/k^2)$. 

It is noteworthy that $\gamma_{F,k}$ satisfies the following bounds.

\begin{lemma} For any cumulative distribution function $F$ with density function $f$: 
\begin{enumerate}
\item If $f$ is even and continuously differentiable, then $\gamma_{F,k} = O(1)$. 
\item If $f$ is such that $f(x) \leq C$ for all $x\in \reals$, for a constant $C > 0$, then $\gamma_{F,k} = \Omega(1/k^2)$.
\end{enumerate}
\label{prop:gamma}
\end{lemma}

We observe that both double-exponential distribution and Laplace distribution of noise are extremal in the sense that they achieve the upper bound $\gamma_{F,k}=O(1)$. On the other hand, uniform distribution of noise is extremal in the sense that it achieves the lower bound $\gamma_{F,k}=\Omega(1/k^2)$. 

%{\red Note that $A$, $B$, and $C$ could depend on $k$ for a given $b>0$ as well as $\gamma_{F,k}$. Therefore, we should be careful to say that uniform distribution of noise is the extreme case. }

%More generally, it can be shown that $\gamma_{F,k} = \Theta(1/k^2)$ for any cumulative distribution function $F$ that has density function such that $f(x)\geq C$ for every point $x$ of its support, for a constant $C > 0$.

%\footnote{This follows by noting that by the second claim in Proposition~\ref{prop:gamma}, $\gamma_{F,k} = \Omega(1/k^2)$, and by (\ref{equ:gamma}) and the fact that by (\ref{equ:ch2}) $\partial p_k(\vec{0})/\partial x_1 = \Omega(1/k)$, we have $\gamma_{F,k} = O(1/k^2)$.} 

%TBD - can we exhibit a "natural" family of distribution of noise that can achieve $\gamma_{F,k} = \Theta(1/k^\alpha)$, for $0 \leq \alpha \leq 2$ ? If this is possible, here is one way to do this making use of (\ref{equ:ch2}): show that for every $c \in (0,1)$, there exists $F$ such that
%$$
%\int_{-a}^{a} (-f'(x))dF(x)^k = \Theta(k^c)
%$$ 
%where the support of $F$ is contained in $[-a,a]$. From (\ref{equ:ch2}), note that it is necessary that $f(a) = 0$.



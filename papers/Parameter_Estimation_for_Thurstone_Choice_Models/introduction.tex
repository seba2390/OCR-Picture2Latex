We consider the statistical inference problem of estimating individual strength or skill parameters of items based on observed choices of items from sets of two or more items. This accommodates the case of pair comparisons as a special case, where each comparison set consists of two items. In our more general case, each observation consists of a comparison set of two or more items and the identity of the chosen item from this set. In other words, each observation is a partial ranking, which is often referred to as a top-1 list. Many applications are accommodated by this framework, e.g., choices indicated by user clicks in various information retrieval systems, outcomes of single-winner contests in crowdsourcing services such as TopCoder or Taskcn, outcomes of hiring decisions where one applicant is hired among those who applied for a job, e.g., in online labour markets such as Fiverr and Upwork, as well as numerous sport competitions and online gaming platforms. 

We consider the parameter estimation for the statistical choice model known as the \emph{Thurstone choice} model; also referred to as the \emph{random utility model}. According to the Thurstone choice model, items are associated with latent performance random variables that are independent across different items and different comparisons. For any given comparison set, the choice is the item from this set with the largest performance random variable. For any given item, the performance random variable is equal to the sum of a strength parameter, whose value can be specific to this item, and a noise random variable according to a given cumulative distribution function. The values of the strength parameters are unknown and have to be estimated from the observed comparisons, and the distribution of noise random variables is assumed to be known. The Thurstone choice model accommodates many known choice models by admitting different distribution for noise random variables, e.g., Luce choice model (\cite{L59}) for comparison sets of two or more items, and its special case for pair comparisons, often referred to as the Bradley-Terry model (\cite{BT54}). 

In this paper, we study the accuracy of the maximum likelihood estimator of the parameter of the Thurstone choice model. Our goal is to characterize the accuracy of the maximum likelihood estimator and shed light on how it depends on the given Thurstone choice model and properties of the observed input data such as the number of observations and the structure of comparison sets. In particular, we consider the following statistical inference question. Suppose that the input observations are such that all comparison sets are of the same cardinality $k\geq 2$ and are unbiased, meaning that in expectation every comparison set of given cardinality occurs the same number of times in the input data. Then, we would like to understand how does the accuracy of the maximum likelihood estimator of the strength parameters depend on the cardinality of comparison sets. Notice that from any comparison set of cardinality $k$, we can deduce at most $k(k-1)/2$ pair comparisons. Intuitively, we would expect that the parameter estimation accuracy would increase with the cardinality of comparison sets. However, it is not a priori clear how fast the accuracy would improve and whether any significant gains can be achieved by increasing the sizes of comparison sets. Moreover, it is also not a priori clear whether or not there can be any significant difference between different Thurstone choice models, with respect to how the parameter estimation accuracy is related to the cardinality of comparison sets. We also consider these questions for parameter estimators that are derived by rank breaking methods, which amount to deducing one or more pair comparisons from each comparison of two or more items, assuming independence of these pair comparisons, and defining the estimator as the maximum likelihood estimator under these assumptions.  

The main contributions of this paper can be summarized as follows. 

We provide upper bounds on the mean squared error of the maximum likelihood estimator, and a lower bound that establishes their minimax optimality. We show that the effect of the structure of comparison sets on the mean squared error is captured by one key parameter: algebraic connectivity of a suitably defined weighted-adjacency matrix. The elements of this matrix correspond to distinct pairs of items and are equal to a weighted sum of the number of input comparisons of different cardinalities that contain the corresponding pair of items, where the weights are specific to given Thurstone choice model. 

For the statistical inference question of how the estimation accuracy improves with the cardinality of comparison sets, we derive a tight characterization of the mean squared error in terms of the cardinality of comparison sets (Corollary~\ref{cor:ksize}). This characterization reveals that for a broad class of Thurstone choice models, which includes the well-known cases such as the Luce choice model, there is a diminishing returns decrease of the mean squared error with the cardinality of comparison sets. For this class of Thurstone choice models, the mean squared error tends to be largely insensitive to the cardinality of comparison sets. On the other hand, we show that there exist Thurstone choice models for which the mean squared error decreases much faster with the cardinality of comparison sets. Perhaps suprisingly, in these cases, the amount of information extracted from a comparison set of cardinality $k$ is in the order of $k^2$ independent pair comparisons, which yields a $1/k^2$ reduction of the mean squared error of the maximum likelihood estimator. Section~\ref{sec:disc} provides more discussion.   

We consider two natural rank-breaking methods, one that deduces $k-1$ pair comparisons and one that deduces $1$ pair comparison from a comparison set of cardinality $k$ (Section~\ref{sec:rankbreaking}). We derive mean squared error upper bounds when choices are according to the Luce choice model for these two rank-breaking methods in Theorem~\ref{thm:break-1} and Theorem~\ref{thm:break}, respectively. These results show that both estimators are consistent. Interestingly, both mean squared error upper bounds are equal to that of the maximum likelihood estimator up to a constant factor. Hence, they both inherit all the properties that we established to hold for the mean squared error upper bound for the maximum likelihood estimator.   

We also consider a binary classification problem where all strength parameters associated with items take one of two possible values (separating items into two classes), and the goal is to correctly classify each item within a prescribed probability of classification error (Section~\ref{sec:classy}). We identify sufficient conditions for correctness of a simple point score classification algorithm (Theorem~\ref{thm:clustering-example}) and establish their tightness (Theorem~\ref{thm:clustering-low}). These conditions are of the same form as those that we imposed for deriving upper bounds on the mean squared error of the maximum likelihood parameter estimator.  

We present experimental results using both simulation and real-world data (Section~\ref{sec:exp}). In particular, we validate the claim that the mean squared error can decrease with the cardinality of comparison sets in a qualitatively different way depending on the given Thurstone choice model. We also evaluate algebraic connectivity of weighted-adjacency matrices for several real-world input data, demonstrating that it can cover a wide range of values depending on specific application scenario.

\subsection{Related Work}
\label{sec:related}

A model of comparative judgement for pair comparisons was introduced by \cite{T27}, which is a special case of a model that we refer to as a Thurstone choice model, for the case of pair comparisons and Gaussian random noise variables. A statistical model of pair comparisons that postulates that an item is chosen from a set of two items with probability proportional to the strength parameter of this item was introduced by \cite{Z29}, and was then popularized by the work of \cite{BT52,BT54} and others, and is often referred to as the Bradley-Terry model. The statistical model of choice where for any set of two or more items an item is chosen with probability proportional to its strength parameter was shown to be a unique model satisfying a set of axioms introduced by \cite{L59}, and is referred as the Luce choice model. The Bradley-Terry model is the special case of the Luce choice model for pair comparisons. The choice probabilities of the Luce choice model correspond to those of a Thurstone choice model with noise random variables according to a double-exponential distribution. Relationships between the Luce choice model and Thurstone choice model were studied by \cite{Y77}. A statistical model for full ranking outcomes (the outcome of a comparison is an ordered list of the compared items) where the ranking is in the order of sampling of items without replacement from the set of compared items and the sampling probabilities are proportional to the strengths of items is referred as the Plackett-Luce model (\cite{L59} and \cite{P75}).  

The Thurstone choice models have been used in the design of several popular skill rating systems, e.g., Elo rating system by \cite{E78} used for skill rating of chess players and in other sports, and TrueSkill by \cite{GMH07} used for skill rating of gamers of a popular online gaming platform. All these models are instances of Thurstone models, and are special instances of generalized linear models, see, e.g., \cite{NW72}, \cite{MN89}, and Chapter~9 in ~\cite{M12}. An exposition to the principles of skill rating systems is available in Chapter~9~in~\cite{V16}. 

The parameter estimation problem for the Bradley-Terry model of pair comparisons has been studied by many. The iterative methods for computing a maximum likelihood parameter estimate have been studied in the early work by \cite{hunter2004mm} and the recent work by \cite{maystre2015fast}. \cite{SY99} shown that the maximum likelihood parameter is consistent and asymptotically normal as the number of items $n$ grows large, under assumption that each pair is compared the same number of times and that the true parameter vector is such that the maximum distance between any of its coordinates is $o(\log(n))$. \cite{M99} studied Thurstonian model parameter estimation with noise random variables according to a Gaussian distribution.

The accuracy of the parameter estimation for various instances of Thurstone models has been studied in recent work. \cite{negahban2012rank} found a sufficient number of input pair comparisons to achieve a given mean squared error of a parameter estimator for the Bradley-Terry model and the input comparisons such that in expectation each distinct pair is compared the same number of times. In particular, they shown that under given assumptions, it suffices to observe $O(n \log(n))$ input pair comparisons. \cite{RA14} studied a statistical convergence property of ranking aggregation algorithms for pair comparisons not only for the Bradley-Terry model but also under some more general conditions referred to as low-noise and generalized low-noise. \cite{hajek2014minimax} provided a characterization of the mean squared error of the maximum likelihood parameter estimate for the Plackett-Luce model of full ranking outcomes. This work found that the algebraic connectivity of a weighted-adjacency matrix captures the effect of the structure of input comparison sets on the mean squared error of the maximum likelihood parameter estimator. \cite{SBBPRW16} established similar characterization results for the case of pair comparisons according to Thurstone choice models.   

Our work differs from previous work in that we consider characterization of the estimation accuracy for a general class of Thurstone choice models for arbitrary sizes of comparisons. Specifically, our work provides a first characterization of the estimation accuracy with respect to the cardinality of comparison sets for unbiased input comparisons, which reveals an insight into the fundamental limits of statistical inference for given cardinality of comparison sets. It is a folklore that different models of pair comparisons yield similar performance with respect to the prediction error, e.g.~\cite{S92}, which suggests that the precise choice of a Thurstone choice model does not matter much in applications. Our results show that there can be significant difference between two Thurstone choice models with respect to the statistical inference of model parameters. 

Parameter estimators derived by various rank-breaking methods have been studied by various authors. For instance, \cite{soufiani2013generalized} and \cite{soufiani14} studied rank-breaking methods for full ranking data and \cite{khetan2016data} studied rank-breaking methods for partial rankings. Recently, \cite{khetan2016} characterized a trade-off between the amount of information used per comparison and the mean squared error of a parameter estimate based on rank breaking. Our work is different in that we are interested in top-1 list observations and the effect of the structure of comparison sets for rank-breaking methods. For the top-1 list observations and any given comparison structure, our work provides upper bounds for the mean squared error of two natural ranking breaking methods and shows the optimality of them.


\subsection{Organization of the Paper}

Section~\ref{sec:defs} introduces problem formulation, some basic concepts and key technical results used to establish our main results. Section~\ref{sec:mse} provides a characterization of the mean squared error for the maximum likelihood parameter estimation, including both upper and lower bounds. Section~\ref{sec:rankbreaking} shows the same type of characterizations for two rank-breaking based parameter estimators. Section~\ref{sec:classy} establishes tight conditions for correct classification of items, when the strength parameters of items are of two possible types. Section~\ref{sec:disc} discusses how the estimation accuracy depends on the cardinality of comparison sets. Section~\ref{sec:exp} contains results of our experiments. Finally, Section~\ref{sec:conc} concludes the paper. Appendix contains some background facts and proofs of our theorems.

% ==================================================
\section{Related Work} \label{related}
% -----------------------------------

Our work spans two distinct areas of machine learning: learning under
weak supervision and extracting
relational information from high-dimensional data. By \emph{weak supervision}, we mean that our
model is required to solve a high-level task such as the binary
classification proposed on the left of Figure \ref{pento_sprites}
by observing only raw pixels.  
\ifarxiv
The information content of the gradients relative to sampling noise has been
studied \cite{2017failures} as a way of characterizing the difficulty of end-to-end learning.
\fi

Prior work in weak supervised learning (WSL) in the image domain has
focused on image segmentation by classifying them with a standard
multi-class loss objective \cite{oquab2015object} or by utilizing an
alternate loss such as a score-based \cite{durand2016weldon} objective.
Unsupervised representation learning can also be used to aid the model
in learning the end objective. The recent work of {\em Learning to Count}
\cite{noroozi2017representation} proposed a method for representation
learning in an unsupervised setting by using a pre-trained network
to learn counting of visual primitives. This method works well
when the features extracted from the pre-trained network are
semantically relevant to the current learning objective. Our work
differs from this and the WSL objective in the amount of supervision
provided to the model. We focus on supervised tasks where a model is not
provided with sub-problem class labels (or any other structured,
supervised information) and needs to learn a high-level representation of
the visual scene using few binary labels for each whole image.

Extracting relational information with neural networks has been studied in many settings
from text-based relationships \cite{das2016chains, weston2014memory} to
visual query answer (VQA) models such as the recent work of Relational
Networks \cite{santoro2017simple} and Show-Tell-Attend
\cite{xu2015show}. Relational Networks have been used to learn
relationships between objects in a scene given a rich textual query,
such as the CLEVR dataset \cite{johnson2017clevr}, which provides input
in the form of an image coupled with a textual query.  Despite having a pair-wise structure that we
intuitively think is useful for our All-Pairs problem, a Relational
Network \cite{santoro2017simple} does not solve our proposed dataset
(Section \ref{all_pairs}). To solve our problem, we introduce a model
called TypeNet which aggregates channel-wise statistics and solves the
overall task by combining these statistics.

Our TypeNet model takes inspiration from winner-take-all (WTA)
strategies \cite{srivastava2013compete,maass2000computational} and can build a set of problem-related,
local statistics to combine for predicting the end
objective. We demonstrate empirically that TypeNet outperforms
state-of-the-art models such as ResNet18, Resnet34 \cite{he2016deep},
VGG19 \& VGG16 with batch norm \cite{simonyan2014very}, and InceptionV3
\cite{szegedy2016rethinking} on the proposed All-Pairs problem.

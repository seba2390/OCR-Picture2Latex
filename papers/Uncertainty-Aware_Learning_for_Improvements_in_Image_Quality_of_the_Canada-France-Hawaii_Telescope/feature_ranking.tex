\subsection{Feature Ranking}\label{sec:featureRank}

One of our goals in this work is to understand the physical mechanisms that yield high and low IQ values so that, in the future, we can actuate the observatory to improve the realized IQ.  To accomplish this we need to understand the insights that the ML models decision making processes reveal. To this end, we utilize the methods of integrated Hessians and Shapley values \citep{explaining_explanations_hessians, gilda_mirkwood, gilda_mirkwood_software} for the MDN model. %, and the package \texttt{SHAP} for the machine learning model LGBM.
We use an implementation provided by the \texttt{pathexplainer} software package which compute feature attributions (or importances). The attributions plot ranks the 119 input features, guiding us on how important each feature is, relative to all other ones, in explaining the predicted MPIQ. These enables us to understand the model's decision making process, and to ascertain that the features deemed important by the model make sense physically.
 %On the other hand, the interactions plots help visualize second-order effects -- how one feature interacts with another to simultaneously impact the predicted MPIQ. These measures help us to understand the model's decision making process and help us check that the features deemed important by the model make sense physically.


\section{Shapley Values}\label{sec:shapley_values} \textbf{COPIED VERBATIM FROM ANOTHER PAPER I AM DRAFTING, WILL BE MODIFIED SUBSTANTIALLY}

Consider a dataset with $N$ features, $X=\left\{X^{(1)}, \ldots, X^{(N)}\right\},$ and a real-valued target variable, $y$. Given an instance (observation) $x \in X,$ a model $v$ forecasts the target as $v[x]$. \emph{Question}--Can we attribute the departure of a prediction $f[x]$ from its average value $\bar{y}$ in terms of the observed instance $x$? In a linear model, the answer is trivial :$v[x]-\bar{y}=\beta_{1} x^{(1)}+\cdots+\beta_{N} x^{(N)}$ (see Fig ()). We would like to do a similar local decomposition for any (non-linear) ML model.\footnote{As explained in \S\ref{} and evident from Figure {}, non-linear models provide much better predictions than linear ones.} Shapley values answer this \emph{attribution} problem through game theory \citep{shapley}. They originated with the purpose of resolving the following scenario--A group of differently skilled participants are all \emph{cooperating} with each other for a collective reward; how should the reward be \emph{fairly} divided amongst the group? In the context of machine learning, the participants are the features of our input dataset input and the collective payout is the model prediction. Here, we use Shapley values to calculate how much each individual feature \emph{marginally} contributes to the model output.

While a goal of this paper is to explain the contribution of each observing band to various galaxy properties, for the sake of simplicity we chose to explain Shapley values using a toy example. Let's say that we operate a small hedge fund, and our team consists of three people: \textbf{A}lice, \textbf{B}ob, and \textbf{C}arol. Everyday they together manage to make \textbf{X = 20} (thousand) dollars. Our year has been very profitable and we would like to distribute a bonus to the team members. In order for us to do that in a fair way we need to find out how much each person contributes to the production of the \textbf{X} dollars.

\begin{enumerate}
    \item First, we consider the $2^{N=3}$ possible coalitions (interactions) between the players (features), where some players (features) may not participate (i.e., remain at their average value), and other may participate (depart from their average value). See Table \ref{table:coalitions}.
    \item Second, we use the coalitions (interactions) table to compute the marginal contribution of each player (feature) conditional to the other players (features). The marginal impact of changing \emph{Alice} after changing \emph{Bob} may differ from the marginal impact of changing \emph{Bob} after changing \emph{Alice}. Accordingly, we must account for all possible $N!$ sequences of conditional effects. See Table \ref{table:marginal_conditional_contribution}.
    \item Finally, the \emph{Shapley value} of a player (feature) is the average conditional marginal contribution of that player across all the possible $N!$ ways of conditioning $v[.]$. See last row of Table \ref{table:marginal_conditional_contribution} and Equation \ref{eq:shapley_main}.
\end{enumerate}

\begin{table*}
\centering
\begin{tabular}{|c|c|c|c|}
\hline $\text{Alice} \neq \overline{\text{Alice}}$ & $\text{Bob} \neq \overline{\text{Bob}}$ & $\text{Carol} \neq \overline{\text{Carol}}$ & $v(...) \left(= v[x \mid \ldots]\right)-\bar{y}$ \\
\hline 0 & 0 & 0 & $v(\varnothing) (= v[x \mid 000])-\bar{y} = 0$ \\
\hline 0 & 0 & 1 & $v(C) (= v[x \mid 001])-\bar{y} = 10$ \\
\hline 0 & 1 & 0 & $v(B) (= v[x \mid 010])-\bar{y} = 5$ \\
\hline 0 & 1 & 1 & $v(B,C) (= v[x \mid 011])-\bar{y} = 7$ \\
\hline 1 & 0 & 0 & $v(A) (= v[x \mid 100])-\bar{y} = 2$ \\
\hline 1 & 0 & 1 & $v(A,C) (= v[x \mid 101])-\bar{y} = 8$ \\
\hline 1 & 1 & 0 & $v(A,B) (= v[x \mid 110])-\bar{y} = 10$ \\
\hline 1 & 1 & 1 & $v(A,B,C) (= v[x \mid 111])-\bar{y} = \textcolor{orange}{20}$ \\
\hline
\end{tabular}
\caption{In a model with 3 features, there are $2^{3}=8$ possible interactions. For each interaction, we compute the departure of the model's forecast from its baseline (average value). We encode as `1' a feature that is not at its average value (it forms part of a \emph{coalition}), and `0' a feature that is at its average value. Thus $v(A,B)=v(B,A)$, $v(B,C)=v(C,A)$, $v(A,C)=v(C,A)$, and $v(A,B,C)=v(B,A,C)=v(A,C,B)$.}
\label{table:coalitions}
\end{table*}

\iffalse
%similar plot to the one in /home/sgilda/Downloads/SSRN-id3637020.pdf, page 9
An attribution of the departure of a model's prediction, $f[x],$ from its average value, $\bar{y}$ Because addition is commutative, the sequence of the effects does not alter the result. Hence,
in a linear model, the attribution is invariant to the sequence of effects.
\fi

%\subsection{Coalitional Game Theory}

\begin{table*}%[h!]
\centering
\begin{tabular}{|l|l|l|l|l|}
\hline Combination & \multicolumn{1}{|c|} {Alice} & \multicolumn{1}{|c|} {Bob} & \multicolumn{1}{|c|} {Carol} & Total \\
\hline $\mathrm{A}, \mathrm{B}, \mathrm{C}$ & $v(\mathrm{A})-v(\varnothing) = 2$ & $v(\mathrm{A}, \mathrm{B})-v(\mathrm{A}) = 8$ & $v(\mathrm{A}, \mathrm{B}, \mathrm{C})-v(\mathrm{A}, \mathrm{B}) = 10$ & \textcolor{orange}{20}\\
\hline $\mathrm{A}, \mathrm{C}, \mathrm{B}$ & $v(\mathrm{A})-v(\varnothing) = 2$ & $v(\mathrm{A}, \mathrm{C}, \mathrm{B})-v(\mathrm{A}, \mathrm{C}) = 12$ & $v(\mathrm{A}, \mathrm{C})-v(\mathrm{A}) = 6$ & \textcolor{orange}{20} \\
\hline $\mathrm{B}, \mathrm{A}, \mathrm{C}$ & $v(\mathrm{B}, \mathrm{A})-v(\mathrm{B}) = 5$ & $v(\mathrm{B})-v(\varnothing) = 5$ & $v(\mathrm{B}, \mathrm{A}, \mathrm{C})-v(\mathrm{B}, \mathrm{A}) = 10$ & \textcolor{orange}{20} \\
\hline $\mathrm{B}, \mathrm{C}, \mathrm{A}$ & $v(\mathrm{B}, \mathrm{C}, \mathrm{A})-v(\mathrm{B}, \mathrm{C}) = 13$ & $v(\mathrm{B})-v(\varnothing) = 5$ & $v(\mathrm{B}, \mathrm{C})-v(\mathrm{B}) = 2$ & \textcolor{orange}{20} \\
\hline $\mathrm{C}, \mathrm{A}, \mathrm{B}$ & $v(\mathrm{C}, \mathrm{A})-v(\mathrm{B}) = 3$ & $v(\mathrm{C}, \mathrm{A}, \mathrm{B})-v(\mathrm{C}, \mathrm{A}) = 12$ & $v(\mathrm{C})-v(\varnothing) = 10$ & \textcolor{orange}{20} \\
\hline $\mathrm{C}, \mathrm{B}, \mathrm{A}$ & $v(\mathrm{C}, \mathrm{B}, \mathrm{A})-v(\mathrm{C}, \mathrm{B}) = 13$ & $v(\mathrm{C}, \mathrm{B})-v(\mathrm{C}) = -3$ & $v(\mathrm{C})-v(\varnothing) = 10$ & \textcolor{orange}{20} \\
\hline Average & $6.3$ & $6.5$ & $8$ & \textcolor{orange}{20} \\
\hline
\end{tabular}
\caption{In a model with 3 features, there are $3! = 6$ possible sequences. We can use the interactions table to derive the marginal contribution of each feature in each sequence. The Shapley values are the averages per column.}
\label{table:marginal_conditional_contribution}
\end{table*}

\iffalse
\begin{tabular}{l|l|l|l}
\multicolumn{1}{c|} { Sequence } & \multicolumn{1}{c|} {$x^{(1)}$} & \multicolumn{1}{c} {$x^{(2)}$} & \multicolumn{1}{c} {$x^{(3)}$} \\
\hline$x^{(1)}, x^{(2)}, x^{(3)}$ & $f[x \mid 100]$ & $f[x \mid 110]$ & $f[x \mid 111]$ \\
& $-f[x \mid 000]$ & $-f[x \mid 100]$ & $-f[x \mid 110]$ \\
\hline$x^{(1)}, x^{(3)}, x^{(2)}$ & $f[x \mid 100]$ & $f[x \mid 111]$ & $f[x \mid 101]$ \\
& $-f[x \mid 000]$ & $-f[x \mid 101]$ & $-f[x \mid 100]$ \\
\hline$x^{(2)}, x^{(1)}, x^{(3)}$ & $f[x \mid 110]$ & $f[x \mid 010]$ & $f[x \mid 111]$ \\
& $-f[x \mid 010]$ & $-f[x \mid 000]$ & $-f[x \mid 110]$ \\
\hline$x^{(2)}, x^{(3)}, x^{(1)}$ & $f[x \mid 111]$ & $f[x \mid 010]$ & $f[x \mid 011]$ \\
& $-f[x \mid 011]$ & $-f[x \mid 000]$ & $-f[x \mid 010]$ \\
\hline$x^{(3)}, x^{(1)}, x^{(2)}$ & $f[x \mid 101]$ & $f[x \mid 111]$ & $f[x \mid 001]$ \\
& $-f[x \mid 001]$ & $-f[x \mid 101]$ & $-f[x \mid 000]$ \\
\hline$x^{(3)}, x^{(2)}, x^{(1)}$ & $f[x \mid 111]$ & $f[x \mid 011]$ & $f[x \mid 001]$ \\
& $-f[x \mid 011]$ & $-f[x \mid 001]$ & $-f[x \mid 000]$
\end{tabular}
\fi
%that slide on Interaction Effects. Page 15

\underline{Eliminating Redundancy}: As we can appreciate from the numerical example, some calculations are redundant. For example, the marginal contribution of \emph{(Carol)} on sequence \emph{(Alice, Bob, Carol)} must be the same as the marginal contribution of \emph{(Carol)} on sequence \emph{(Bob, Alice, Carol)} because (a) in both cases \emph{Carol} comes in third position, and (b) the permutations of \emph{(Alice, Bob)} do not alter that marginal contribution. The Shapley value of a feature $i$ can be derived as the average contribution of $i$ across all possible coalitions $S$, where $S$ does not include feature $i$:

\begin{align}\label{eq:shapley_main}
    \phi_{i}(v)=\sum_{S \subseteq N \backslash\{i\}} \frac{|S| !(|N|-|S|-1) !}{|N| !}(v(S \cup\{i\})-v(S))
\end{align}

The above equation describes \emph{coalitional game} (the scenario described previously) with a set \textbf{\emph{N}} of \emph{n} features (players). The function $v$ gives the value (payout) for any subset of those features (players). For example, if $S$ be a subset of \textbf{\emph{N}}, then \emph{v(S)} gives us the value of that subset. Thus for a coalitional game \emph{(N, v)} Equation \ref{eq:shapley_main} outputs the value for feature \emph{i}, i.e. its the Shapley value.\footnote{Equation \ref{eq:shapley_main} computes the exact Shapley values by grouping the marginal conditional contributions in terms of coalitions $(S)$. For large $N,$ \cite{shap1} and \cite{shap2} have developed fast algorithms for the estimation of $\phi_{i}$} For ease of explanation, we focus our attention on calculating how many of the $X$ dollars can be attributed to \textbf{C}(arol), i.e. calculating the Shapley value for \textbf{C}. We then examine the various components of Equation \ref{eq:shapley_main} and study their significance.
\begin{itemize}
    \item If we relate this back to the parameters of the Shapley value formula we have $N = \{A, B, C\}$ and $i = C$. The highlighted section in Equation \ref{eq:shapley_highlight_0} (derived from Equation \ref{eq:shapley_main} by re-arranging some terms) says that we need to take our group of people and exclude the person that we are focusing on now. Then, we need to consider all of the possible subsets that can be formed. So if we exclude \textbf{C} from the group we are left with \emph{{A, B}}. From this remaining group we can form the following subsets (i.e. these are the sets that \emph{S} can take on): $\varnothing, A, B, AB$. In total, we can construct four unique subsets from the remaining team members, including the null set.
    \begin{align}\label{eq:shapley_highlight_0}
    \phi_{i}(v)=\frac{1}{|N|} \sum_{\textcolor{orange}{S \subseteq N \backslash\{i\}}}\left(\begin{array}{c}
    |N|-1 \\
    |S|
    \end{array}\right)^{-1}(v(S \cup\{i\})-v(S))
    \end{align}
    \item Next, we focus on the highlighted term  in Equation \ref{eq:shapley_highlight_1}.
    \begin{align}\label{eq:shapley_highlight_1}
    \phi_{i}(v)=\frac{1}{|N|} \sum_{S \subseteq N \backslash\{i\}}\left(\begin{array}{c}
    |N|-1 \\
    |S|
    \end{array}\right)^{-1}\textcolor{orange}{(v(S \cup\{i\})-v(S))}
    \end{align}
    This refers to the \emph{marginal value} of adding feature (player) $i$ to the dataset (game). Specifically, we want to see what the difference in the money earned daily if we add $C$ to each of our 4 subsets. We can represent these 4 marginal values visually as: $\Delta v_{C, \varnothing}, \Delta v_{AC, A}, \Delta v_{BC, B}, \Delta v_{A B C, A B}$. Each of these as a different scenario that we need to observe in order to fairly assess how much \textbf{C} contributes to the overall profit. This means that we need to observe how much money is produced if no one is working (i.e. the empty set $\varnothing$) and compare it to what happens if we only have \textbf{C} working. We also need to observe how much profit is earned by \textbf{A} and \textbf{B} working simultaneously and compare that to the profit earned by \textbf{A} and \textbf{B} together with \textbf{C}, and so on.
    \item Next, the summation in the Shapley value equation is telling us that we need to add all them together. However, we also need to scale each marginal value before we do that, which we are provided this prescription by the highlighted part in Equation \ref{eq:shapley_highlight_2}.
    \begin{align}\label{eq:shapley_highlight_2}
    \phi_{i}(v)=\frac{1}{|N|} \sum_{S \subseteq N \backslash\{i\}}\textcolor{orange}{\left(\begin{array}{c}
    |N|-1 \\
    |S|
    \end{array}\right)^{-1}}(v(S \cup\{i\})-v(S))
    \end{align}
    It calculates how many permutations of each subset \emph{size} we can have when constructing it out of all remaining team members excluding feature (player) \emph{i}. In other words, given \textbf{$\lvert$N$\rvert$-1} features (players), how many groups of size \textbf{$\lvert$S$\rvert$} can one form with them? We then use this number to divide the marginal contribution of feature (player) $i$ to all groups of size \textbf{$\lvert$S$\rvert$}. For our scenario, we have that \textbf{$\lvert$N$\rvert$-1 = 2}, i.e. these are the remaining team members when we are left with when calculating the Shapley value for \textbf{C}. In our case we will use that part of the equation to calculate how many groups we can form of size 0, 1, and 2, since those are only group sizes we can construct with the remaining players. So, for example, if we have that \textbf{$\lvert$S$\rvert$ = 1} then we get that we can construct 2 different groups of this size: \emph{A} and \emph{B}. This means that we should apply the following scaling factors to each of our 4 marginal values: $1\Delta v_{C, \varnothing}, \frac{1}{2}\Delta v_{A C, A}, \frac{1}{2}\Delta v_{B C, B}, 1\Delta v_{A B C, A B}$. By adding this scaling factor we are \emph{averaging out} the effect that the rest of the team members have for each subset size. This means that we are able to capture the \emph{average} marginal contribution of \textbf{C} when added to a team of size 0, 1, and 2 \emph{regardless} of the composition of these teams.
    \item Next, we focus on the remaining term, highlighted in Equation \ref{eq:shapley_highlight_3}.
    \begin{align}\label{eq:shapley_highlight_3}
    \phi_{i}(v)=\textcolor{orange}{\frac{1}{|N|}} \sum_{S \subseteq N \backslash\{i\}}\left(\begin{array}{c}
    |N|-1 \\
    |S|
    \end{array}\right)^{-1}(v(S \cup\{i\})-v(S))
    \end{align}
    So far we have averaged out the effects of the other team members for each subset size, allowing us to express how much \textbf{C} contributes to groups of size 0, 1, and 2. The final piece of the puzzle is to \emph{average out} the effect of the group size as well, i.e. how much does \textbf{C} contribute \emph{regardless} of the size of the team (number of explanatory features in the data set). For our scenario we do this by dividing with 3 since that is the number of different group sizes that we can consider. With this final step, we arrive at the point where can finally compute the Shapley value for \textbf{C}. We have observed how much she marginally contributes to all different coalitions the team that can be formed. We have also averaged out the effects of both team member composition as well as team size which finally allows us to compute the Shapley value for \textbf{C}:
    \begin{align}\label{eq:shapley_final}
        \phi_{C}(v) &= \frac{1}{3} \sum\left(1\Delta v_{C, \varnothing}, \frac{1}{2} \Delta v_{A C, A}, \frac{1}{2} \Delta v_{B C, B}, 1\Delta v_{ABC, AB}\right) \nonumber \\
        &= \frac{1}{3} \sum\left(1\times 10, \frac{1}{2} \times 6, \frac{1}{2} \times 2, 1\times 10\right) \nonumber \\
        &= 8
    \end{align}
    Comparing Equation \ref{eq:shapley_final} with the Shapley value for \textbf{C} in the last row of Table \ref{table:marginal_conditional_contribution}, we see that they match exactly.
\end{itemize}

After we have calculated the Shapley values for the rest of the features (players), we will know their individual contributions to the \textbf{X} dollars earned daily, allowing us to fairly divide the year-end bonus amongst all team members:
\begin{align}
    X &=v(\{A, B, C\}) \nonumber \\
    &=\phi_{A}(v)+\phi_{B}(v)+\phi_{C}(v)
\end{align}
This is also evident from the last row of Table \ref{table:marginal_conditional_contribution}, where the Shapley values for \textbf{A}, \textbf{B}, and \textbf{C} add to the total of 20.


\underline{Interaction Effects}: An interaction effect occurs when the effect of one variable on the output depends on the value of another variable. The estimation of interaction effects requires having an accurate attribution of the individual effect of the variables involved. This makes Shapley values particularly useful for estimating these. For $i \neq j$:
\begin{align}
    \phi_{i, j}=\sum_{S \subseteq(X \backslash\{i, j\})} \frac{\|S\| !(N-\|S\|-2) !}{2(N-1) !} \delta_{i, j}[S], \nonumber \\
    \delta_{i, j}[S]=v[S \cup\{i, j\}]-v[S \cup\{i\}]-v[S \cup\{j\}]+f[S]
\end{align}

\underline{Properties}:
This method is the provably [citation required] the only one that satisfies four axioms of \emph{fair} credit-attribution:
\begin{enumerate}
    \item \emph{Efficiency}: The sum of the Shapley values of all features (players) equals the value of the total coalition. That is, the value of $X = 20$ in the bottom-rightmost corner in Table \ref{table:coalitions} is the same as the $20$ in the bottom-rightmost cell in Table \ref{table:marginal_conditional_contribution}.
    \item \emph{Dummy Player}: If a feature (player) never adds any marginal value regardless of the coalition, its payoff (Shapley value $\phi_{i}(v)$) is 0.
    \item \emph{Symmetry}: All players have a fair chance to join the game. Thatâ€™s why Table \ref{table:coalitions} lists all the permutations of the players. If two players always add the same marginal value to any subset to which they are added, their payoff portion should be the same. In other words, $\phi_{i} = \phi_{j}$ IIF feature \emph{i} and feature \emph{j} contribute equally to all possible coalitions.
    \item \emph{Additivity}: A function with combined outputs has as Shapley values the sum of the constituent ones. For any pair of games $v, w$, $\phi(v+w) = \phi(v)+\phi(w)$, where $(v+w)(S)=v(S)+w(S) \forall S$. This property allows us to combine Shapley values from $n$ different models, thus enabling interpretability for ensembles. 
\end{enumerate}


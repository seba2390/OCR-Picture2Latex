\subsection{Boosted Trees and Deep Neural Networks}\label{sec:ml_vs_dl}
%\Simon{although this section is very interesting per se, I believe it should probably be shortened quite a bit, summarizing the main advantages of a network w.r.t. to tree-based methods, especially in view of streaming data.}
%While DNNs allow extraction of significantly richer patterns between inputs and output(s), they have earned a reputation for being `black-boxes' -- it can be difficult to explain the series of steps a neural network takes to find the relationships between the input features and the output(s) of interest. This is where tree-based models shine -- they are designed to be agglomeration of `if-then-else' statements, thus making it considerably easier to inspect the relationships both between the input features and the outputs, as well as among the features themselves. They pay a price for increased interpretability with decreased ability for feature extraction\footnote{That is, a machine learning model can only work with the user-provided features, whereas a deep enough neural network, in theory, can construct arbitrary complex combinations of these features if such an exercise results in better prediction of the output variable(s) of interest.}, and often times are not the tools of choice for \emph{unstructured data} -- images, videos, text and audio \citep{tabnet}. 

%This hierarchy, however, is reversed in the case of \emph{structured}, tabular\footnote{Tabular data is considered `structured' because typically a human decides to put the features (columns) and observations (rows) in a certain order, whereas images, audio and languages have a naturally occurring order and do not need to be `structured' by the user.} data, where features are individually meaningful and lack strong multi-scale temporal or spatial structures; in this setting, gradient boosted decision trees (GBDT) \citep{gradient_boosted_decision_trees_gbdt, xgboost, catboost} perform reasonably well.
%preferred for their exmore often than not outperform standard deep models on tabular-style datasets \citep{tabnet}, where features are individually meaningful and lack strong multi-scale temporal or spatial structures; the state-of-the-art performance in problems with tabular heterogeneous data is often achieved by such as gradient boosted decision trees (GBDT) \citep{gradient_boosted_decision_trees_gbdt, xgboost, catboost}.
%This raises two questions: (i) \emph{why} does deep learning perform poorly on tabular data, and (ii) \emph{how} can we fix it? \seb{not exactly sure that DL can be said to perform poorly on tabular data anymore - as it is examplified here.} \yst{agreed. This is an unnecessary shot/comparison} The key to answering question (i) is to understand the ways in which tabular data are fundamentally different from unstructured data:


%Our dataset consists of heterogeneous, sparse, and categorical data.  The dataset is heterogeneous due to the wide variety of sensors (wind speed, temperature, telescope pointing) each recorded in specific  units.  The dataset is sparse due to lost data, sensor failures, and sensor replacement or re-positioning.  The dataset is categorical (rather than continuous) because sensor measurements are often binned, e.g., wind speed below $5$ knots, $5$-$10$ knots, etc.  These characteristics induce a discontinuous feature space.  Tree-based models such as decision trees~\citep{decision_trees}, random forests~\citep{randomforests}, and gradient boosted trees \citep{xgboost, lightgbm} are well-matched to these data characteristics. Tree-based models select and combine features greedily to whittle down the list of pertinent features to include only the most predictive ones. Tree-based models easily handle categorical features using, e.g., one-hot encoding. Further, feature sparsity and the presence of NULL values is easily accommodated by such models,  they simply do not include feature cells containing such values in their splits.  In this paper we implement an off-the-shelf Light GBM model to provide a performance baseline. To extract feature importance and interactions from this tree-based model, we use the SHAP package \citep{shap1,shap2}.%; we expound on this in \S\ref{sec:DL_feature_imp}. 

Tree-based models such as simple decision trees~\citep{decision_trees}, random forests~\citep{randomforests}, and gradient boosted trees \citep{gradient_boosted_decision_trees_gbdt} are well-matched to these data characteristics. Tree-based models select and combine features greedily to whittle down the list of pertinent features to include only the most predictive ones. Further, feature sparsity and missing data is naturally accommodated by tree models, they simply do not include feature cells containing such values in their splits.  In this paper we implement an off-the-shelf model gradient boosting tree model to provide a performance baseline. To extract feature importance and interactions from this tree-based model, we use the SHAP package \citep{shap1,shap2}.%; we expound on this in \S\ref{sec:DL_feature_imp}. 
%\tcr{(SCD: Sankalp, can you work back over the second half of the following paragraph and pass back to me -- starting from "we overcome several deficiencies")}

However tree-based models require the human process of feature engineering and have been shown \citep{bengio2010decision} to poorly generalize.
In contrast to tree-based models, deep neural networks (DNNs) are powerful feature pre-processors. Using back-propagation, they learn a fine-tuned hierarchical representation of data by mapping input features to the output label(s). This allows us to shift our focus from feature engineering to fine-tuning the architecture, designing better loss functions, and generally experimenting with the mechanics of our neural network. As we will show, our neural network with little to no feature engineering \seb{Are we really doing no feature engineering for the MDN?}  performs better than the alternative tree-based boosted model that uses extensive feature engineering. In reported comparison cases, DNNs yield improved performance with larger sized datasets \citep{airbnb}. 

% SF: an interesting case, but not clear to me how DNN is a no-brainer for online-learning, and why we should worry about it in the future for our project.

%Finally, it is more natural to use DNNs in an online-mode, with data points `streaming in' rather than arriving in batches. On the other hand, tree-based models need access to all the data to determine best split points, and hence need to be trained every time a new observation comes in. While we do not use a large dataset (we have $\sim 60,000$ samples), or streaming data, in preparation for our future work on real-time predictions we believe it important to consider neural network models from the start.

%Turning to neural networks, the ideal architecture would be one designed to handle the peculiarities of the tabular data discussed above.  However, for the most part, neural networks are designed for unstructured data. While, as mentioned in Section \ref{sec:relatedWork}, there has been some work done in applying neural networks to tabular data \citep{milli2019nowcasting_paramal},  there remains significant room for improvement.

%In this paper, we overcome several deficiencies of traditional neural networks when applied to tabular data by designing and utilizing a feed-forward mixture density network (MDN) as depicted in Figure \ref{fig:1-to-1_plus_mdn}. %\Simon{Motivation for the MDN should be introduced here. Since we are not using DIMM information, atmospheric seeing acts here as a noise source with complex, heteroschedastic properties that an MDN is good at addressing}
%The VAE is capable of handling missing observations in data, as well as identifying which samples in its training set contain errant values, and hence allows us to use the versions of our input data containing all samples, $\mathcal{D_{F_L,S_L}}$ and $\mathcal{D_{F_S,S_L}}$.
%On the other hand, atmospheric seeing acts as a noise source with complex, heteroschedastic properties that an MDN is good at addressing. We use \texttt{BatchNorm} layers \citep{batchnorm} after the input layer of the MDN so that all features are placed on the same scale and none of them unduly affects the gradients and weights during flow through the network. For accessing feature importance and interactions, we use the recently open-sourced \textsc{Python} package \texttt{pathexplain}\footnote{\url{https://github.com/suinleelab/path_explain}} \citep{explaining_explanations_hessians}. 

\iffalse
\tcb{(SCD: I suggest we deleted the rest of the following})

\tcb{++++++++DELETE REST OF SUBSECTION++++++++++}

Neural networks face extra challenges when being applied to structured data while tree-based models

The structured data sets we work with have a number of characteristics that are important to note.
\begin{itemize}
    \item {\bf Heterogenity:}  Feature come from disparate sources, each with their own units. In our case the features included, e.g., environmental sensor measurements, observatory telemetry, and measured instrumental image quality.
    \item {\bf Sparsity:} Unlike data from audio, video and language, there can be relatively little variation in the values of a column in a table. There are often NULL values where no data was collected, or was lost or corrupted in the collation process. \tcr{(SCD: Sankalp, I don't get the point about the ``relatively little variation'')}
    \item {\bf Categorical:}  Feature are often categorical indicating, e.g., that the wind speed is below $5$ knots, between $5$ and $10$ knots, between $10$ and $20$ knots, or above $20$ knots.  In contrast, image pixel values are typically integers between $0$ and $255$ which is better modeled as a continuous range.
    \item {\bf Correlation:}  A minority of the columns in a table are often responsible for the majority of the predictive power. This is unlike the case for images, for instance, where in spite of local spatial correlations between pixels, it is difficult to claim, e.g., that it is the top-left cluster of them that is most helpful in predicting whether an image contains a cat or a dog. \tcr{(SCD: Simon makes a good comment about images being low-entropy, do we keep this or remove?)}
    \Simon{Here again, I would not define input correlations as specific to tabular data. Natural images e.g. have relatively low entropy - and hence can usually be compressed efficiently - and this in turn implies correlations between pixels}
\end{itemize}

%These issues complicate analysis of tabular data with DNNs.
These differences from unstructured data lead to a sparse and discontinuous high-dimensional feature space, making it difficult to exploit for deep neural networks (DNNs). On the other hand, tree-based models -- decision trees \citep{decision_trees}, random forests \citep{randomforests}, and gradient boosted trees \citep{xgboost, lightgbm} -- naturally profit from this landscape. They are by design able to select and combine features via a greedy heuristic, and thus whittle down the list of pertinent features to just the most predictive ones. They are also able to easily handle categorical features using any number of encoding schemes, the most commonly used one being one-hot encoding. The sparsity of features and the presence of NULL values is not of concern to them either, since they simply do not include feature cells containing such values in their splits.

Given the great fit between tree-based models and tabular data, the obvious question arises -- why even consider neural networks?
\begin{itemize}
    \item DNNs are powerful feature pre-processors. Using back-propagation, they learn a fine-tuned hierarchical representation of data by mapping input features to the output label(s). This allows us to shift our focus from feature engineering to fine-tuning the architecture, designing better loss functions, and generally experimenting with the mechanics of our neural network. As we show in Figures (xxx) and (xxx), our neural network with little to no feature engineering performs better than the alternative tree-based boosted model that uses extensive feature engineering.
    \item There is empirical proof that DNNs result in improved performance with larger sized datasets \citep{airbnb}.
    %\item Deep learning allows us to train systems end-to-end, which unlocks the possibility of using unlabelled samples to better predict the labelled ones (\emph{semi-supervised learning}, \S\ref{sec:DL_SSL}).
    \item %\Simon{This is probably a crucial argument for DNNs, as our input data set is here bound to grow with time}
    It is easier to use DNNs in an online-mode, with data points `streaming in' rather than arriving in batches. This is because tree-based models need access to all the data to determine best split points, and hence need to be trained every time a new observation comes in. While this work does not use streaming data, in preparation for our future work on real-time predictions we believe it best to move to a neural network from the get-go.
    \item Finally, tree-based models have been known to generalize poorly (\sg{Sebastien: you suggested this; can you expand + put in a couple of citations please?}).
\end{itemize}
%\input{tabnet}
\fi
%Clearly, the ideal model for working with the kind of tabular data we have from CFHT would be a neural network that is designed to handle the peculiarities of tabular data listed above, and is also easily explainable. As mentioned in Section \ref{sec:relatedWork}, there has been some work done in this field \citep{milli2019nowcasting_paramal}, but there is significant room for improvement. 


%\tcr{(SCD: Sankalp, Should these next two paragraph go here?  The previous two paragraph, respectively, discussed the data + tree-based models, and the NNets.  The next paragraph talks about "deficiencies of tree-bsead models" but the previous paragraph discussed deficiencies / challengaeas of NNets, so the transition is unclear.  I feel the paragraph really is discussing how we surmount the challenges facing the application of NNets to categorical data.  Is this what you're after?  And, if it is, should it go here?  (Maybe, b/c we discussed challenges faced by NNets)}


% SF: commented to move further
%For these reasons, in this paper we design and utilize a feed-forward mixture density network (MDN) as depicted in Figure \ref{fig:1-to-1_plus_mdn}. An MDN is able to capture the complex, heteroschedastic properties of seeing (IQ), and easily able to output uncertainties. 

%\Simon{Motivation for the MDN should be introduced here. Since we are not using DIMM information, atmospheric seeing acts here as a noise source with complex, heteroschedastic properties that an MDN is good at addressing}
%The VAE is capable of handling missing observations in data, as well as identifying which samples in its training set contain errant values, and hence allows us to use the versions of our input data containing all samples, $\mathcal{D_{F_L,S_L}}$ and $\mathcal{D_{F_S,S_L}}$.
%On the other hand, atmospheric seeing acts as a noise source with complex, heteroschedastic properties that an MDN is good at addressing.


% SF: commented to move further
%We use \texttt{BatchNorm} layers \citep{batchnorm} after the input layer of the MDN so that all features are placed on the same scale and none of them unduly affects the gradients and weights during flow through the network. For accessing feature importance and interactions, we use the recently open-sourced \textsc{Python} package \texttt{pathexplain}\footnote{\url{https://github.com/suinleelab/path_explain}} \citep{explaining_explanations_hessians}.

% SF: commented to move further
%In addition, we also utilize a robust variational autoencoder (see Section \ref{sec:rvae}) to study the impact of toggling vents between `ON' and `OFF'. The RVAE allows us to isolate out-of-distribution (OOD) samples -- those data points in the training and test sets which are not drawn from the same underlying distribution as the majority of samples in the training set. This serves two purposes. First, it allows us to analyze the impact of vent-toggling only on those samples that are `similar enough' to the majority of samples in the training set, thus increasing our confidence in downstream IQ prediction on these observations. Second, this allows us to suppress the effect of outliers in our measurements. This can be used for anomaly detection and hence predictive maintenance; we relegate this to future work and briefly discuss its implications in Section \ref{sec:conclusion}.

%We also use an off-the-shelf Light GBM model to serve as a baseline against which to measure the performance and validate the effort spent in creating our network. To extract feature importance and interactions from this tree-based model, we use the SHAP package \citep{shap1,shap2}.%; we expound on this in \S\ref{sec:DL_feature_imp}. 

%Fortunately, the past few years have seen extensive research into designing exactly such DNNs, specialized to beat their ML-based cousins on structured data. While some mimic decision tree ensembles \citep{node}, others focus on developing novel architectures using attention \citep{attention_is_all_you_need} suitable for handling tabular data \citep{selfattention_feature_importance, tabnet}. In this work, we use a modified version of the `TabNet' architecture \citep{tabnet}, with several improvements. TabNet uses a sparse, learnable mask on the input features--a kind of soft feature selection that favors the selection of just features that are important for the sample under consideration. It uses a special type of non-linearity called `sparsemax' \textbf{sparsemax citation}, along with an \emph{attention mechanism} \citep{attention_is_all_you_need} called `self-attention' to zero out the contributions of non-relevant features in through a sequence of several steps. TabNet is also able to naturally normalize features of varying ranges, and thus does not require feature pre-processing. For a more detailed description and a visual overview of their network, we refer the readers to \S$2$ and Figure 4, respectively, of \cite{tabnet}. While TabNet has feature interpretability built-in, it can only output the magnitude of the impact of a feature on the output, and not its direction. In other words, it cannot discriminate a feature positively impacting the MPIQ from a feature negatively impacting it, except in magnitude of their effects. For this reason, we do not use this functionality, and instead utilize the \textrm{pathexplain}\footnote{\url{https://github.com/suinleelab/path_explain}} package to obtain feature importance; we expound on this in \S\ref{sec:DL_feature_imp}.\seb{maybe punt some of the description into the related work section? Also: graph NN}.

\iffalse
In short, our inductive bias is that there are (highly) correlated features, so selecting the minimum set of features is the best strategy.

Fortunately, recent developments in attention and sparse regularization now pave the way to learn more efficiently from structured data.
\fi
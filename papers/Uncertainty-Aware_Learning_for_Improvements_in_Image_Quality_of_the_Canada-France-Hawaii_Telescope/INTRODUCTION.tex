\section{Introduction}\label{sec:introduction}

Situated at the summit of the 4,200m volcano of Maunakea on the island of Hawaii, the Canada-France-Hawaii Telescope is one of the world's most productive ground-based observatories~\citep{crabtree:2019}. The productivity of CFHT is due, in part, to the exquisite natural image quality (IQ) delivered at the observatory's location on Maunakea. Image quality is key metric of observatory operations and relates directly  to  realized signal-to-noise ratio (SNR) as well as to achievable spatial resolution. SNR and spatial resolution, in turn, dictate the information content of an image.  They thereby provide a direct measure of the efficacy of scientific observation.
%KW the following para looks fine to me
%The models we present predict IQ based on current environmental and dome operating conditions. The methodology we develop is general.  The technique should easily transfer to other observatories. An important motivation for developing these models is the following.  If we can accurately predict IQ then we can feed these predictions into a scheduling algorithm that sequences observations to match  conditions to experimental needs, thereby improving and accelerating science.  To provide the reader a sense of the operational parameters under our control, in Figure~\ref{fig.CFHTdiagram} we provide an illustration of CFHT.  Operational parameters we control include windscreen deployment and which dome vents to open and how much and when. While this long-term goal is beyond the scope of our present project and paper, it provides key motivation for the initial efforts described herein.

%\begin{figure*}
%    \centering
%    \includegraphics[width=1\textwidth]{nowcasting_paramal.png}
%%    \caption{Figure 1 from \cite{milli2019nowcasting_paramal}. We should generate a similar one using CFHT data.}
%    \label{fig:paramal}
%\end{figure*}

The difference between the theoretically achievable and measured IQ can be attributed to air turbulence in the optical path.  There are two sources of turbulence.  The first is atmospheric.  At the summit of Maunakea atmospheric turbulence is minimal due to the smooth laminar flow of the prevailing trade winds and the height of the summit; this is the reason CFHT and other world-class observatories are located on Maunakea.  The second is turbulence induced by local thermal gradients between the observatory dome itself (and the structures within) and the surrounding air.  There have been continual improvements in the CFHT facility since 1979, many aimed at reducing this source of turbulence. We particularly make note of the December 2012 installation of dome vents.  After a protracted mechanical commissioning period that lasted about 18 months, the vents  came online in July of 2014. By allowing the (generally) hotter air within the observatory to flush faster, the vents accelerate thermal equalization. A schematic of the dome and the vents is provided in Figure~\ref{fig:dome}. A listing of the temperature sensors marked in Figure~\ref{fig:dome} is provided in Table~\ref{tab:description_of_tempsensors}.
Even given these improvements, and as is the case with all major ground-based observatories, the IQ attained at CFHT rarely reaches what the site can theoretically deliver.\footnote{Direct (prime focus) wide field imaging systems that we consider in this paper are not compatible with adaptive optics~\citep{adaptiveoptics0,adaptiveoptics1}, which require a relay or an adaptive secondary mirror. Although such AO systems can be designed to specifically correct for ground layer, enabling imaging of wide fields at improved seeing resolutions~\citep{imaka}, they are not well suited to correct dome induced turbulence, which may not be homogeneously distributed over the pupil or may be at too high a spatial frequencies to be corrected by a deformable mirror.}

%KW update footnote per review comment.       

%% Also note that adaptive optics not great for wide field

Our project is motivated by our strong belief that the ability to model and predict IQ accurately in terms of the exogenous factors that affect IQ would prove enormously useful to observatory operations.  Observing time at world-class facilities like CFHT is oversubscribed many-fold by science proposals. Specifically at CFHT, good seeing time, defined as time when IQ is smaller than the mode seeing of $0.70''$ in the $r$-band, is oversubscribed roughly three-fold. Further, observations frequently either fail to meet, or exceed, the IQ requirements of their respective science proposals~\citep{milli2019nowcasting_paramal}. Through accurate predictions we can better match delivered IQ to scientific requirements.  We thereby aim to unlock the full science potential of the observatory. 
%\seb{probably we should not claim an operational forecasting just yet :). Maybe we should only focus on what we were able to predict/control *in the past*}.  
If we can predict the impact on IQ of the parameters the observatory can control (pointing, vent and wind-screen settings, cooling systems), then by adjusting these parameters and (perhaps) the order of imaging, we create an opportunity to accelerate scientific productivity.  In this work we lay the groundwork for  these types of improvements.

In this paper, we leverage almost a decade-worth of sensor telemetry data, post-processing IQ measurements, and exposure information that is collected in tandem with each CFHT observation.  Based on this data we build a predictive model of IQ. Through the implementation of a feed-forward mixture density network (MDN, \citealt{bishop_mdn}), we demonstrate that ancillary environmental and operating parameter data are sufficient to predict IQ accurately. Further, we illustrate that, keeping all other settings constant, there exists an optimal configuration of the dome vents that can substantially improve IQ. Our successes here lay the foundation for the development of automated control and scheduling software. 

%While this long-term goal is beyond the scope of our present project and paper, and before detailing the novel contributions of this paper, we summarize key motivations for the development of an automated scheduling approach.

%Given the short time frame over which turbulence evolves, and the universal use of IQ (colloquially referred to as `seeing') in observational astronomy, an ability to model and predict IQ accurately in terms of the factors that affect it can prove enormously useful in observatory operations.


   

\iffalse

%(\sg{Points 2 and 3 are copied as-is from the Paramal paper, and need to be modified based on corresponding Figure 1 from CFHT.})

%Our work constitutes the first step towards building first-ever machine-learning driven approach for real-time scheduling of astronomical observations at the Canada France Hawaii Telescope (CFHT). We train a deep neural network on this data archive to predict the IQ of each candidate scientific exposure as a function of environmental and observatory dome operating parameters. Our long-term goal is to leverage such predictors to schedule observations and dome controls to maximize IQ. Real-time scheduling is key for several reasons:
\begin{enumerate}
    \item \textbf{Improving the efficiency of operations:} Observing time at CFHT is oversubscribed with science proposals by a factor of $\sim 3$ \sg{(need citation)}. As a result, the the night-time operator \sg{(astronomer?)} must be judicious in selecting the correct observation given extant conditions. These conditions are comprised of weather/meteorological data, properties of the possible targets, configuration of the CFHT dome vents, and the atmospheric turbulence. The last of these is the most difficult to predict, and hence to account for in the decision-making process. Physically, optical turbulence presents itself as `seeing' or IQ, caused by optical path variance along the line of sight. %IQ is the the parameter used universally in observational astronomy to quantify the turbulent conditions, and limits the signal-to-noise ratio (SNR) of the obtained exposure.
    Owing to this complex, multi-parameter problem, an automated solution would go a long way in increasing efficiency and eliminating human error.
    \item \textbf{Decreasing the cost of operation:} CFHT costs around USD 25,000 to operate per night (a tenth of what next generation 30m-class telescopes will cost) (\sg{citation needed}). The amount of time spent on executing observations (OBs) obtained during conditions outside of the specified constraints and that are considered for repetition varies from instrument to instrument. At the VLT, on UT1 and UT2 the fraction of observations executed out of the constraints is between 5 and 10\%, while on UT3 and UT4 it is typically between 10 and 15\%.6 Looking specifically at the observations declared out-of constraint due to the seeing, an independent analysis done by inspecting manually the night log of UT3 during the Period P101 (April 2018 to October 2018) where SPHERE and VISIR were the only instruments operated in Service Mode, revealed a failure rate of 4.0\%. The ESO document Cou-1628 (2015) on the policy regarding GTO states that a night is charged 83 kEUR (in 2015 Euros) to an instrument consortium. In P101 at UT3, about 60\% of the time was dedicated to Service Mode observations. This makes a financial loss due to the seeing of 728 kEUR per year. Such a failure rate is in agreement with an independent study using UT1 to UT4 and VLTI observations carried out between Periods 90 (October 2012) and 97 (September 2016), whose core result was presented in Rejkuba et al. 2018,6 that derived a 4:5\% Â± 0:6\% failure rate due to the seeing only. This average value does however hide an important fact: the more demanding observations are the most affected by failures due to the seeing, as shown in Figure 1 (left). Therefore decreasing the time spent in out-of-constraints observations would benefit the most demanding programs to better exploit the excellent conditions of the Paranal site. This has great potential as the best conditions are mostly under-exploited, with very few proposals asking for demanding conditions, as this shown in Figure 1 (right) for the example of the SPHERE instrument in Period P101
    \item \textbf{Enabling more aggressive short-term scheduling with well-estimated risks:} Despite the fact that a failure rate of 4\% has a significant financial impact, as shown above, it still represents a small value. Indeed, looking at the pure statistics of the seeing, one would expect a failure rate of 34\% (respectively 27\%) for a seeing constraint of 0.8" (resp. 1.0") assuming that a one-hour observation is systematically started after the seeing has been below 0.8" (resp. 1") for 30min (ESO-internal study). The low achieved failure rate due to unmet seeing constraint stems likely both from a conservative choice of observation to undertake at any given opportunity by the night astronomer and from conservatism by the community, not requesting very demanding conditions (Figure 1 right). This means that there is room for improvement to schedule demanding programs more aggressively if one-hour nowcast is available to help the night astronomer assess the risk undertaken by doing so. By doing so, the community could also be less conservative and dare to ask for demanding programs exploiting the best conditions of the Paranal site.
    \item \textbf{Workshopping AI-based operation of the Maunakea Spectroscopic Explorer (MSE):} (\sg{a line or two about MSE}) where the knowledge of the turbulence will be even more paramount than at CFHT to best exploit the diffraction limit of this 10m class telescope. The pressure to get telescope time will be higher than at CFHT, therefore IQ prediction will be even more valuable to avoid wasting telescope time and make sure the systems are optimised to deliver the best performance over the course of the observations. CFHT thus represents the ideal platform for a pilot study at predicting the image quality. Such a pilot study will not only be useful to make the best choices in terms of instrumentation for turbulence monitoring at MSE, but also to gain experience on the best use of IQ predictions to maximise the science return.
\end{enumerate}
\fi

\begin{figure*}
   \centering
   \includegraphics[width=0.95\linewidth]{figures/dome.png}
   \caption{A schematic of the CFHT; top-view and profile. The twelve actionable dome vents are marked.  Important thermal sensors identified in past works (see Section~\ref{sec:relatedWork}) are highlighted. These sensors are detailed in Table~\ref{tab:description_of_tempsensors}.}
   \label{fig:dome}
\end{figure*}

%Improving the efficiency of operations will yield more science, and will pave the way for the more complicated scheduling tasks of next-generation telescopes.

%IQ measures the point-source blurring of a star and relates directly to signal-to-noise ratio (SNR). IQ degradation from the theoretical maximum results from turbulence both in the atmosphere and from the night-time cooling of the observatory dome. The summit of Mauna Kea is a prime site for an observatory as atmospheric turbulence is minimal due to the smooth flow of the prevailing trade winds and the height of the summit.  However, despite continual improvements in CFHT IQ since 1979, including the 2012 introduction of vents to assist in flushing hot air from the dome (see Figure~\ref{fig:dome}), as with all major ground-based observatories, IQ rarely reaches what the site can theoretically deliver.

%Through the implementation of a probabilistic DNN, we demonstrate that  ancillary environmental and operating parameter data are sufficient to predict IQ accurately. We illustrate that, keeping all other settings constant, there exist optimal configurations of dome vents that can substantially improve IQ. Our successes here lay the foundation for developing automated control and scheduling approaches.

%The models we present predict IQ based on current environmental and dome operating conditions. The methodology we develop is general.  The technique should easily transfer to other observatories. An important motivation for developing these models is the following.  If we can accurately predict IQ then we can feed these predictions into a scheduling algorithm that sequences observations to match  conditions to experimental needs, thereby improving and accelerating science.  To provide the reader a sense of the operational parameters under our control, in Figure~\ref{fig.CFHTdiagram} we provide an illustration of CFHT.  Operational parameters we control include windscreen deployment and which dome vents to open and how much and when. While this long-term goal is beyond the scope of our present project and paper, it provides key motivation for the initial efforts described herein.

The IQ prediction system we detail in this paper is developed for MegaPrime~\footnote{\url{https://www.cfht.hawaii.edu/Instruments/Imaging/MegaPrime/}}, a wide-field optical system with its mosaic camera MegaCam \citep{megacam}. MegaPrime is one of CFHT's most scientifically productive instruments. Built by CEA in Saclay, France, and deployed in 2003, MegaCam is a wide-field imaging camera. It is used extensively for large surveys covering thousands of square degrees in the sky and ranging in depth from 24 to 28.5 magnitude. MegaCam is placed at the prime focus of CFHT.  It includes an image stabilization unit and an auto-focus unit with two independent guide charge-coupled device (CCD) detectors. MegaCam consists of $40$ CCDs, each $2048 \times 4612$ pixels in size, for a total of $378$ megapixels. The image plane covers a $1 \degree \times 1 \degree$ square field of view at a resolution of $0.187''$ (arc-seconds) per pixel. The CFHT archive at the Canadian Astronomy Data Centre (CADC) contains close to 300k Megacam science exposures with 24 filter pass bands. These images have a median IQ of $\sim0.7''$ in the $r-$band. %(cf.~Figure \ref{fig:hist_preliminaries}).
One of our main results is that, based purely on environmental and observatory operating conditions, we can predict the \textit{effective} MegaPrime IQ (MPIQ for the rest of the paper) to a mean accuracy of about $0.07''$.

\begin{table}
    \centering
    \caption{Brief description of the temperature sensors marked in Figure~\ref{fig:dome}.}
    \label{tab:description_of_tempsensors}
    \begin{tabular}{ll}
        \toprule
        Probe label & Description\\ \midrule
        AIR-4 & Air temperature -- Caisson, west \\
        SURF-5 & Steel temperature -- Caisson, east \\
        AIR-6 & Air temperature -- Upper end, west \\
        AIR-23 & Air temperature -- Under end, east \\
        AIR-33 & Air temperature -- Under primary, west \\
        AIR-54 & Air temperature -- Mirror cell, west \\
        AIR-63 & Air temperature -- Under primary, south \\
        AIR-65 & Air temperature -- Inside spigot, north \\
        AIR-67 & Air temperature -- Under primary, north \\
        GLASS-70 & Glass temperature -- Under primary, south \\
        AIR-86 & Air temperature -- Weather tower \\
        AIR-101 & Air temperature -- MegaPrime exterior \\ \bottomrule
    \end{tabular}
\end{table}

\begin{table*}
\caption{Data fields in the MegaCam dataset.}
\label{table:megaCamData}
\centering
\begin{tabular}{p{0.15\linewidth} p{0.095\linewidth}p{0.05\linewidth} p{0.125\linewidth}p{0.45\linewidth}}\toprule\toprule
Parameter & Units & \#Features & Range & Description \\\midrule
\multicolumn{5}{l}{Environmental} \\ \midrule
Temperature & \degree C & 57 & [-8,20] / [-200,850] & Temperature values from sensors in and around the dome. Three sensors are placed within the  dome.  The rest are external.\\
Wind speed & knots & 1 & [0,35] & Wind speed at the weather tower.\\
Wind azimuth & NONE & 2 & [-1,1] & Sine and cosine of wind azimuth with respect to true north. \\
Humidity & \% & 2 & [1.4,100] & Measured both at the top of the observatory dome, and at the weather tower.\\%Dome-top, and WeatherTowerRelativeHumidity}\\
Dew point & \% & 2 & [1.4,100] & Measured both in the basement of the observatory building, and at the telescope mirror cell (near GLASS 70 in Figure \ref{fig:dome})\\%CosineRegulatorSupply, mirrorcelldewpointsouthinside
Barometric pressure & mm of Hg & 1 & [607,626] & Atmospheric pressure measured on the fourth floor of the observatory building.\\
MPIQ & $''$ & 1 & [0.35,2.36] & Measured seeing from MegaCam/MegaPrime.\\
\midrule
\multicolumn{5}{l}{Observatory} \\ \midrule
Vents & NONE; NONE; NONE & 36 & \{0,1\}; [0,1]; [0,1] & For each sample, we have three types of vent values: vent configuration (`OPEN' or `CLOSE'), and Sine and cosine of vent$_{\rm{AZ}}$ \\
Dome azimuth & NONE & 2 & & Sine and cosine of the angle of the slit-center from true North. \\
Pointing altitude & NONE & 1 & [0.15,1] & Sine of the angle of the telescope focus from the horizontal.\\
Pointing azimuth & NONE & 2 & [-1,1] & Sine and cosine of angle of the telescope focus from true north. \\
Wind screen position & NONE & 2 & [0,1] & Fraction that the wind screen is open. (The wind screen is located at the `Slit' position in the left of Figure \ref{fig:dome}.)\\
Central Wavelength & nm & 1 & [354,1170] & Central wavelengths of each of the 22 filters.\\
Dome Az $-$ Pointing Az & NONE & 2 & [-1,1] & Sine and cosine of difference between dome and pointing azimuths.\\
Dome Az $-$ Wind Az & NONE & 2 & [-1,1] & Sine and cosine of difference between dome and wind azimuths.\\
Pointing Az $-$ Wind Az & NONE & 2 & [-1,1] & Sine and cosine of difference between wind and pointing azimuths.\\
%IQ & & & & \\
%skyBkgd & & & & \\
\midrule
\multicolumn{5}{l}{Other} \\ \midrule
Exposure time & seconds & 1 & [30,1800] & Observation time per sample.\\
Observation Time & NONE & 4 & [-1,1] & Sine and cosine of $\frac{\rm{hour\_of\_day}}{23}$ and $\frac{\rm{week\_of\_year}}{51}$.\\
%MKAM IQ & & & & \\
%MKAM$_{\rm Az}$ & & & & \\
%MKAM$_{\rm Al}$ & & & & \\
\bottomrule
\end{tabular}
\end{table*}

%MKAM is a collaborative project between IFA (Institute for Astronomy, University of Hawaii), CFHT and the W.M. Keck Observatory. The goal of which is to install a seeing monitor on the CFHT site for use by all the observatories on the summit.  Provides a measure of the Fried parameter (r0) at a wavelength of 0.5 microns with a goal of an precision of better than $5\%$ at the observed zenith angle and azimuth and an estimate of r0 corrected to the zenith. The r0 value should be corrected for the finite exposure time of the instrument. Goal of an accuracy of $5\%$ in r0 and the measurements will be from at least six meters above grade. Fried's parameter r0 quantitatively expresses the image degradation due to atmospheric turbulence.  r0 represents the diameter of the coherent cells in the incident wave at the telescope pupil. \url{http://articles.adsabs.harvard.edu//full/1981SoPh...69..223R/0000227.000.html} the MASS profiler is an instrument in addition to the DIMM in MKAM. MASS Turbulence Profiler. MASS is an instrument to measure the vertical distribution of turbulence in terrestrial atmosphere by analysing the scintillation (twinkling) of bright stars. When stellar light passes through a turbulent layer and propagates down, its intensity fluctuates.

%\tcr{(SCD: Do we somehow need better to connect MegaPrine im the following to MegaCam in the preceeding?)} MegaPrime is located at the prime focus upper end and includes an image stabilization unit and a guide/autofocus unit with two independent guide CCD detectors.

We train our models to predict MegaPrime IQ (MPIQ) using CFHT observations dating back to July 23, 2014.  While the CFHT data catalogue dates back to 1979, we use  data only for the period in which the dome vents have been present.
% SF: push those details to the data section? 
%The ``raw'' data set\footnote{In Section \ref{sec:data_cleaning} we use this raw, parent data set to create 3 more data sets.} consists of 184,365 data records, each corresponding to a single MegaCam exposure. Each record contains a multi-dimensional ``input'' vector that consists of measurements from several environmental and dome-state sensors. Each record also contains a scalar ``output'' label which is the measured MPIQ value.
 The collected measurements include temperature, wind speed, barometric pressure, telescope altitude and azimuth, and configurations of the dome vents and windscreen. \footnote{We have made our data set publicly available at \url{https://www.cfht.hawaii.edu/en/science/ImageQuality2020/}.}  In Table~\ref{table:megaCamData} we summarize the environmental sensors, observatory parameters, and miscellaneous features used in this work.  %\tcr{(SCD: Is there a reason Table 2 is so many pages away, can we move it closer, or is it better to keep it near the data section?)}

Our goal is to toggle the twelve CFHT vents based on our predictions of MPIQ. We must thus err on the side of caution -- CFHT is already oversubscribed by a factor of $\sim 3$, and any mis-prediction of vent configurations would waste valuable time in re-observing targets. We therefore eschew point predictions in favor of making a prediction of the MPIQ distribution (the conditional PDF) for each data sample. We followed this procedure when presenting some preliminary results in \cite{gilda_cfht_neurips}. Here we extend that work significantly and make the following contributions:
\begin{enumerate}
    \item We compile and collate several sets of measurements from various environmental sensors, metadata about observatory operating conditions, and measured IQ from MegaCam on CFHT. We curate and combine these sources of data into a single dataset.  We publish the curated dataset.
    %We filter to reject unusable observations, e.g.,  non-sidereal tracking of solar system objects, and bad sensor values, e.g., those corresponding to  failed or removed sensors; our data curation process is detailed in Section~\ref{sec:data}. 
    % for conclusion:
    % In addition to enabling our research efforts, we hope that the easy availability of a large and cleaned data set will encourage the development of creative algorithms that will lead to novel science outcomes.
   %%%%%
   \item We use supervised learning algorithms to predict IQ at $0.07''$ accuracy. We present results for a gradient boosting tree algorithm and for a mixture density network (MDN). For the latter we provide a detailed analysis of {\it feature attributions}, assigning the relative contribution of each input variable to predicting MPIQ.
   %The neural network combines a robust variational autoencoder with a mixture density network, while the decision tree uses a light gradient boosted machine (LGBM) developed in~\citep{lightgbm}. As already mentioned, using the deep learning model we can predict MPIQ to a mean absolute error of $\sim0.07''$; the corresponding performance for the LGBM model is $\sim\sg{(SG: xxx''; waiting on Sebastien)}$. This proof-of-concept demonstrates the viability of explainable ML-based approaches to IQ determination.
   %%%%%
  
  % SF: commenting until we have results.
  %\item Third, we apply the MDN to the task of ranking the importance of predictive variables (features) in the prediction of IQ.  Such a ranking is beneficial for a couple of reasons. For one, the ranking helps us validate our model against  previous statistical studies of MPIQ. This is discussed in Section~\ref{sec:results}. 
   %Second, by heirarchically clustering features according to their importance, we are able to identify operating modes of the telescope. We relegate this task to a future publication.
  %%%%%

\item The IQ predictions we produce are robust. We perform an uncertainty quantification analysis.  Guided by a robust variational autoencoder (RVAE) that models the density of the data set, we identify non-representative configurations of our sensors.

%\item We develop a method that provides confidence estimates on the IQ prediction.  Such estimates aid us in understanding when to trust the model's predictions, and when not to. ML algorithms,  especially neural networks, are notoriously over-confident about their predictions \citep{lakshminarayanan_probability_calibration0}.  They often fail to recognize when a given sample is `out-of-distribution' (OoD), i.e., sampled from an operating regime distinct from the regime sampled in the training set. By leveraging gains in the field of uncertainty quantification \citep{kendall2017uncertainties}, probability calibration \citep{measuring_calibration_in_deep_learning}, and OoD detection \citep{likelihood_regret}, we increase the trustworthiness in our predicted optimal vent configurations by rejecting those configurations about which confident predictions cannot be made.
  %\item Fourth, we apply semi-supervised techniques to improve our predictive models. In addition to MegaPrime, CFHT sports a number of additional scientific instruments--\sg{Sankalp:check names in data from billy}. Just like MegaPrime, these are also ``labelled'' with their respective IQ values (per observation), while similarly being associated with environmental and dome data. Furthermore, there are vastly more such data points than there are of the labelled MegaCam data, some \tcr{XXXX,XXX} across all instruments versus $\sim 122000$ for MegaCam.  Semi-supervised techniques allow us to leverage these unlabelled (with respect to MegaCam) data to characterize better the intrinsic manifold in which the telescope operates.  The upshot is greatly improved IQ prediction, from \tcr{XXX} arcseconds to \tcr{YYY} arcseconds.  \tcr{(SCD: depends on what we get, could be that the improvement is small on average but large in parts of the parameter space where the original labelled data was sparse.  So, adjust based on what we find.)}%\yst{Are you thinking to include data that have IQ but simply not megaCam IQ and/or data without IQ?} \sg{No.}
 %\item Finally, we use a robust variational autoencoder (RVAE) to to differentiate observations/samples that are in-distribution (ID) from those that are out-of-distribution (OoD).
 \item We use our MDN to find the optimal vent configurations that would have resulted in the lowest IQ. We use these predictions to estimate the annual increase in science return and scientific observations.  We find the improvement to be $\sim 12\%$. This improvement results from increased observational efficiency at CFHT, in particular minimizing the observation times for hypothetical \textit{r-}band targets of the $25^{\rm th}$ magnitude to achieve an SNR of 10; these figures are representative of deep observations of faint targets of large imaging programs at CFHT like the Canada France Imaging Survey \footnote{\url{https://www.cfht.hawaii.edu/Science/CFIS/}}.
 %To the best of our knowledge, this is the first time in the field that utilizes machine learning as a tool to predict optimal vent configurations for a major ground-based observatory.
\end{enumerate}

We structure the rest of this paper as follows. In Section~\ref{sec:relatedWork} we discuss relevant previous work. In Section~\ref{sec:data} we explore in depth the various sources of input data and the processing pipeline we implement to collate and convert the data sources into the final usable dataset. In Section~\ref{sec:method} we describe in detail our methodology, including attributes of our gradient boosting tree and neural network methods, feature importance method, and our predictions for best vent configurations. In Section~\ref{sec:results} we present our results. We conclude in Section~\ref{sec:conclusion}.  To help keep our focus on astronomy, some supporting figures that help detail our machine-learning implementations are deferred to Appendix~\ref{sec.workflowFigs}.


%Finally, in Section~\ref{sec:conclusion}, we conclude the paper and discuss avenues for future work.  

%We also use a random forest model with the same dataset to show the relative performance gain achieved by using a more complicated model.
%%%%%%%%%%%%%%%%%%%
%%% commented out, might be useful elsewhere
%%%%%%%%%%%%%%%%%%%%%
\iffalse
Extracting and exploring feature importance helps us understand the effects detected by the model, and has several advantages:
\begin{itemize}
    \item We can improve the model by adding more features similar to those which most strongly describe patterns in the data. In this way, adding features is not a random generation of various covariates, but rather a deliberate process of adding informative parameters. Similarly, we can conclude which features are universally poor predictors, and remove them from our data, thus easing memory, compute, and time requirements. 
    \item For poor predictions, having access to feature importance values would help one explain \emph{why} a model failed. Is it due to abnormal operating conditions conditions, a bug in the code, or is model under/over-fitting? Armed with a better comprehension of valuable features would allow one to better reveal conditions leading to poor predictions.
    \item Being able to interpret the results of a machine learning model leads to better communication between data scientists, astronomers, and telescope engineers. \emph{maybe add a line or two here}
\end{itemize}
 In this way models can be converted from `black boxes' to `glass boxes'.

\fi
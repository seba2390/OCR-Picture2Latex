\begin{table}[htb]
\caption{Frequently used notations.}
\vspace{-3pt}
\begin{tabular}{c|l}
\toprule  
\textbf{Notation}  & \textbf{Description}  \\ \toprule
$\mathcal{T}$ & an episode, i.e., a sampled task with support and query set  \\
$\mathcal{T}^{(s)}$ & the support set of an episode \\
$\mathcal{T}^{(q)}$ & the query set of an episode \\
$P$-shot & number of training samples in support set of a sampled task \\ 
$N$-way & number of classes in support/query set of a sampled task \\
$Q$-query & number of samples in query set of a novel task \\ 
$K$ & number of clients \\ 
$C$ & fraction of clients updated in parallel \\
% $p(\mathcal{T})$ & the task distribution \\ 
% $\alpha$ &  Startup time of a single operation of gradients aggregation. \\
% $\beta$ & Transmission and aggregation time per gradient. \\
$w$ & meta-learning model, $w=\Tteq$ \\
$f_{w}$ & FSL model parameterized with $w$   \\
$F_{w}$ & task loss function induced by model $f_{w}$ \\
$\Theta$ & feature generator (FE) of a meta-learning model \\
$\theta$ & classifier (CLF) of a meta-learning model \\
$f_{\Theta,\theta}$ & FSL model parameterized with FE and CLF   \\
$\alpha$ & learning rate \\
% $L$ & The number of learnable layers (or tensors) of a deep model. \\
% titer & Time of an iteration. \\
% tf & Time of the forward pass in each iteration. \\
% tb & Time of the backward pass in each iteration. \\
% tu &  Time of the model update in each iteration. \\
% t1 & Time of the gradient calculation of layer l in each iteration. \\
% $\tau$ & The timestamp when layer l begins to calculate gradients. \\
% c & The non-overlapped communication cost in each iteration
\bottomrule
\end{tabular}
\label{tab:freq_notation}
\end{table}
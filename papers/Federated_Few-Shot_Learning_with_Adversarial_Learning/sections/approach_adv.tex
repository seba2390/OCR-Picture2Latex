\section{Improving FedFSL with better coordination}

So far, we have provided FedFSL-naive as a straightforward way of performing distributed few-shot learning. However, one unresolved technical challenge is that meta-learning
depends on sampled episodes that contain only very few labeled data points. In data-scarce scenarios, even the data distribution over the clients could be the same, the high variance of the data 
may lead to quite distinct gradient descent directions, and thus
the trained few-shot models could become quite distinct over the clients. This results in model divergence in aggregation.
Similar observations were also found in FedL tasks with non-IID data \cite{zhao2018federated, li2018federated} but this problem has been amplified in the data-scarce scenarios we consider.



\begin{figure}
\begin{center}
\includegraphics[clip, trim=0 0 0 0, width=0.42\textwidth]{figures/demo_mcd.pdf}
\end{center}
\vspace{-5pt}
\caption{Illustration of decision boundaries learned by (a) FedFSL-naive and (b) FedFSL-MI in two-client case. }
\label{fig:demo_mcd}
\vspace{-10pt}
\end{figure} 


In Fig.~\ref{fig:demo_mcd}(a), we illustrate a two-client case which follows FedFSL-naive scheme to learn models individually (left) first and average the models to obtain the federated decision boundary (right). However, the discrepancy between two client models makes them provide misaligned individual decision boundaries (left). Thus the aggregated central model provides less optimal federated decision boundary (right) with lots of misclassified data samples. 

In this section, we will discuss how to better coordinate client models with mutual information in \ref{sec:fed_maml_mi}, and we propose an adversarial learning procedures to further learn a discriminative feature space in \ref{sec:adv}.



\subsection{FedFSL with Mutual Information (MI)}
\label{sec:fed_maml_mi}
% We observe that recent improvement such as FedProx and FEDL propose to improve FedAvg by solving a surrogate function, with additional regularization to Recently, 

To better coordinate client models learned on distinct data sources,  we propose to regularize the local updates by minimizing the divergence between client models and the central model.
As the central model is shared with the clients at each round, it serves as an intermediate way of training the clients collaboratively without overfitting local data. 

\subsubsection{Mutual information (MI)}
Kullback-Leibler (KL) divergence is commonly used as a measure of the difference of two probability distributions. 
In a collection of multiple distributions, a summed pair-wise KL-divergence is used in
recent studies~\cite{belghazi2018mutual, zhang2018mutual} in ensemble learning to measure the total discrepancy of all those distributions, which we term it \textit{mutual information} (MI). 
In FedL, MI can be utilized to measure the discrepancy of all the participating client models. However, calculating the pairwise KL-divergence requires $\mathcal{O}(K^2)$ calculations which could impose heavy burdens to the central server.
We will propose a simplified MI proximal term and integrate it in FedFSL, and we target to minimize it for reducing internal discrepancy over client models. 

% Concretely, for client $k$ during $t$-th local update, let $p(w_k)$ and $p(w)$ be the probability output of client model $w_k$ and the global model $w^t$ respectively. 

\subsubsection{FedFSL-MI}
Formally, at $t$-th optimization round, we ask the central server to produce a k-exclusive global model $w^t_{\text{-}k}$ such that
\begin{equation}
\label{eq:fuse_mi}
w^{t}_{\text{-}k} =  \sum_{c=1,c\neq k}^K \frac{|\mathcal{B}_c|}{|\mathcal{B}_{\textit{-}k}|} \wsupsubeq{t}{c} \ ,
\end{equation} 
and send back to $k$-th client. The k-exclusive global model $w^{t}_{\text{-}k}$ is taken as an ensemble of all other client models except the $k$-th client. 

We now define the MI loss as the Kullback-Leibler (KL) divergence of probability outputs produced by the k-exclusive global model $w^{t}_{\text{-}k}$ and the client model $w_k$ over sampled tasks such that
\begin{equation}
\begin{split}
&\mathcal{L}_k^{MI}(w^t_{-k}, w_k) = \frac{1}{|\mathcal{B}_k|} \sum_{\Tcaleq_k} D_{KL} \left (p(w^t_{-k})~ ||~ p(w_k) \right ) \\
=&\frac{1}{|\mathcal{B}_k|} \sum_{\Tcaleq_k} (p(w^t_{-k}) \cdot \log p(w^t_{-k}) - p(w^t_{-k}) \cdot \log p(w_k)), \\
\end{split}
\label{eq:loss_kd}
\end{equation}
in which $p(\cdot)$ is the probability outputs of an FSL model. Given an $N$-way FSL task $\mathcal{T}_k$, $p(w)$ is the normalized $N$-way predictions over $N$ classes that sums to one. We aim to minimize MI in order to reduce the discrepancy.

By integrating MI into the original local FedFSL objective function \eqref{eq:fed_def_adp_k},
our new target is to jointly minimize the MI loss together with the local FSL task loss such that
% The client is updating its local model with a combined target of few-shot learning task objective \eqref{eq:fed_maml} and a weighted MI regularization target  \ref{eq:fuse_mi} such that
% By combining the FedFSL task in Eq~(\ref{eq:fed_maml}) and mutual information as regularization term, we obtain the objective
\begin{equation}
\begin{split}
&\wsupsubeq{*,t}{k}=\underset{w_k}{\text{min}} \ \mathcal{L}_k(w_k) + \gamma \mathcal{L}_k^{MI}(w^{t}_{\text{-}k}, w_k),
\end{split}
\label{eq:fed_maml_mi}
\end{equation}
in which the weight $\gamma>0$ can be searched by cross-validation. We call this new method \textbf{FedFSL-MI} (FedFSL with Mutual Information regularization).

As the k-exclusive global model is different from client to client, the central server needs to compute the global model $K$ times.
In practice, when $K$ is large (e.g., $\ge$10), we can conveniently reuse the aggregated central model $w^{t}$ as in \eqref{eq:fuse} to
approximate $w^{t}_{\text{-}k}$, leading to no additional computation cost. We will default to use $w^t$ to approximate $w^{t}_{\text{-}k}$ in our experiments to reduce computations in simulated mobile devices, and we will compare them in Sec.\ref{sec:ab_mi}.
% In two-client case, $w^{t}_{\text{-}k}$ can be obtained by directly exchanging models with each other.
% \hl{We summarize the procedures} in Algorithm~\ref{algo:fed_maml} with local objective \eqref{eq:fed_maml_mi}.



We illustrate the intuition of using MI in Figure~\ref{fig:demo_mcd}(b).  As we minimize the discrepancy among client models, we encourage the decision boundaries to be consistent across the clients. Thus the federated model could produce a better aligned decision boundary. In the empirical study, we will show that it leads to a significant improvement over FedFSL-naive. 
However, the decision boundaries could become complex due to the consistency constraint (Figure~\ref{fig:demo_mcd}(b) right), which we will discuss in next section.





\subsection{Improving feature space with adversarial learning}
\label{sec:adv}

One technical disadvantage of FedFSL-MI is that constraining the decision boundaries to be similar over clients would develop a complex classifier that overfits to training tasks.
However, the classes of testing data for FSL are different from the base classes of training data, which makes the complex decision boundary not useful to unseen tasks. This also presents a key difference between FSL and conventional supervised learning.

\subsubsection{Feature space}
We aim to improve the FedFSL-MI by learning a central model that can produce a better-aligned decision boundary for unseen tasks.
Recent studies of metric learning~\cite{schroff2015facenet, Gidaris_2018_CVPR} have shown that learning a good feature space is beneficial to various tasks as it provides good 
representations (also known as features or feature embeddings) for data samples. In an ideal feature space, samples of the same class or similar classes are close to each other, while samples of different classes are far away. For example, images of cats and tigers are close in feature space, while tigers and wolves could be far away due to their distinct visual features. 
% Similarly, words of close semantic meanings are usually closer in word embedding space~\cite{pennington2014glove}.


Researchers have also found that a representative feature space is a kind of transferable knowledge that can be used to learn unseen data samples. For example, pre-trained vision recognition models (i.e., ResNet)~\cite{sharif2014cnn, ren2015faster} and language models (i.e. BERT)~\cite{pennington2014glove, vaswani2017attention} can produce off-the-shelf image/language representations for various tasks. Few-shot classification, as we consider in this paper, will especially benefit from a discriminative and transferable feature space if such a feature space can be derived properly and efficiently in distributed scenarios. We will show it is feasible in next sections.
% as the decision boundary will be much easier to be learned with well represented data.

\subsubsection{Learn a consistent feature space}
To our best knowledge, how to learn a consistent and discriminative feature space with FedL has never been studied before.
The difficulty is how to construct a consistent feature space over many clients without sharing data.
% We will explore an efficient way of constructing such a feature space by explicitly optimizing for a discriminative feature generator for FedFSL models. 
Motivated by recent progress in Generative Adversarial Networks (GANs)~\cite{goodfellow2014generative, saito2018mcd}, we will decompose an FSL model as a feature generator and a classifier (i.e., discriminator) which can be optimized in an alternative and iterative fashion.
This new adversarial learning approach is named as \textbf{FedFSL-MI-Adv} (FedFSL with Mutual Information regularization and Adversarial learning).


% Notations of FedFSL-MI-Adv in details.
We first introduce some new notations to facilitate discussion.
Without loss of generality, a few-shot classification model can be represented as a feature generator $\Theta$ and a classifier $\theta$. For a given data sample $x$, we denote its generated feature as $f_{\Theta}(x)$. The output logits of the classification model is derived by applying the classifier on the feature such that $f_{\theta}\circ f_{\Theta}(x)$. Thus the predicted  probabilistic distribution over $N$ classes is denoted as
$p(\Theta, \theta)=\sigma (f_{\theta}\circ f_{\Theta}(x))$ in which $\sigma$ is the softmax function.  

In centralized training, the
feature generator and the classifier could be learned with supervised learning without many tricks. However, in distributed scenarios, we have to additionally consider aligning feature space learned with many clients. We propose a novel procedure that
alternatively trains the classifier and the generator as two opponents. We train the client model classifier to maximize the difference between its predictions and central model predictions, while train the client feature generator to minimize the difference. We will explain the details and intuitions.



\begin{figure}
\begin{center}
\includegraphics[clip, trim=0 0 0 0, width=0.42\textwidth]{figures/demo_mcd_adv.pdf}
\end{center}
\vspace{-5pt}
\caption{An example of federated decision boundaries learned by FedFSL-MI-adv with two-stage adversarial learning on two clients of different data distributions. }
\label{fig:demo_mcd_adv}
\vspace{-15pt}
\end{figure} 


% We now propose an adversarial learning based approach to improve FedFSI-MI by explicitly optimizing task-specific decision boundaries across the clients. 
% In comparison, FedFSL-MI optimizes the client model as a whole to minimize the difference between client and central model, thus may lead to a over-trained classifier. However, a task-specific classifier is usually not useful to new tasks on novel classes.


\subsubsection{Adversarial learning procedure}
We design a two-stage adversarial learning procedure for the local update for explicitly learning a consistent feature space.
In overall, the $(t\text{-}1)$-th communication round ends up by aggregating the
% includes updating $k$-th client model which yields $w^t_k=\Ttsupsubeq{t}{k}$, and aggregating 
client models to a central model in \eqref{eq:fuse} and sending it back to clients as $w_k=\Ttsupsubeq{}{k}$. 
At the beginning of next round of local update, 
each client initializes a new classifier $\theta_k'$.
The feature generator $\Theta_k$ and two classifiers $\theta_k$ and $\theta_k'$ are all trainable and will involve in a two-stage adversarial training procedure as follows. 


% We design a two-stage training process of our proposed method to alternatively update the classifiers $\theta_k$ and the generator $\Theta_k$ in adversarial fashion to build a discriminative feature generator.

\begin{itemize}[leftmargin=*]
    \item \textbf{Training stage-1} is to 
train two classifiers to produce \emph{distinct} decision boundaries, in the motivation of detecting ambiguous data samples in current feature space. Ambiguous samples are those lying near the decision boundaries that tend to be misclassified by two different classifiers, as shown in Fig.~\ref{fig:demo_mcd_adv}(stage-1). Intuitively, detecting those samples is the prerequisite of optimizing a feature space that resolves the ambiguity.
During this stage, the feature generator $\Theta_k$ remains fixed, while $\theta_k$ and $\theta_k'$ are updated.

We first define the adversarial loss to measure the difference of two classifiers $\theta_k$ and $\theta_k'$ by the KL divergence of their probabilistic outputs $p(\Theta, \theta)$ such that
\begin{equation}
\begin{split}
&\mathcal{L}_k^{adv}(\theta_k, \theta_k', \Theta_k) 
% = \sum_{\Tcaleq_k} \mathcal{L}^{kl}_{\Tcaleq} (f_{[\theta, \Theta]}, f_{[\theta_k, \Theta]}) \\
= \frac{1}{|\mathcal{B}_k|}\sum_{\Tcaleq_k} D_{KL} \left (p(\Theta_k, \theta_k)~ ||~ p(\Theta_k, \theta_k') \right ).
% =&\sum_{\Tcaleq_k} \mathrm{KL}\left( \sigma \left (\frac{f_{\theta_k^c} \circ f_{\Theta_k}}{T} \right),\sigma \left (\frac{f_{\theta_k} \circ f_{\Theta_k}}{T} \right ) \right ) \\
\end{split}
\label{eq:loss_adv}
\end{equation}
We simultaneously minimize the FSL local objective \eqref{eq:fed_def_adp_k} while \emph{maximize} the adversarial loss to encourage the disagreement of the two classifiers. Formally,
we define the objective of stage-1 as a combination of local task objective $\mathcal{L}_k$ \eqref{eq:fed_def_adp_k} and adversarial loss $\mathcal{L}_k^{adv}$ \eqref{eq:loss_adv} with weight $\eta>0$ such that
% \begin{equation}
% \begin{gathered}
% \underset{\theta_k,\theta_k'}{\text{min}}  \ \mathcal{L}_k^{st\text{-}1}(\theta_k, \theta_k'; \Theta_k) \\ 
% = \mathcal{L}_k (\theta_k; \Theta_k) +  \mathcal{L}_k (\theta_k'; \Theta_k) - \eta \mathcal{L}_k^{adv}(\theta_k, \theta_k' ; \Theta_k)
% \end{gathered}
% \label{eq:fed_mi_adv_1}
% \end{equation}
\begin{multline}
\underset{\theta_k,\theta_k'}{\text{min}}  \ \mathcal{L}_k^{st\text{-}1}(\theta_k, \theta_k'; \Theta_k) \\ 
= \mathcal{L}_k (\theta_k; \Theta_k) +  \mathcal{L}_k (\theta_k'; \Theta_k) - \eta \mathcal{L}_k^{adv}(\theta_k, \theta_k' ; \Theta_k).
\label{eq:fed_mi_adv_1}
\end{multline}

\item \textbf{Training stage-2} is to minimize adversarial loss for learning the discriminative feature generator.
In this stage, we fix the classifiers $\theta_k$ and $\theta_k'$ and train the generator $\Theta_k$ to minimize the discrepancy of the two classifiers measured by the adversarial loss.
The intuition is shown in Fig.~\ref{fig:demo_mcd_adv}(stage-2):
by \textit{minimizing} \eqref{eq:loss_adv},  the feature generator $\Theta$ is learning to push ambiguous data samples away from the decision boundaries, so that both classifiers could make the right predictions and their discrepancy gets reduced. As a result, the feature space (dashed circles) generated by $\Theta$ is trained to be discriminative which produces larger inter-class margins.

Formally, we define the objective of stage-2 as a combination of local task objective $\mathcal{L}_k$ and adversarial loss $\mathcal{L}_k^{adv}$ with weight $\lambda>0$ such that
\begin{multline}
\underset{\Theta_k}{\text{min}}  \ \mathcal{L}_k^{st\text{-}2}(\Theta_k; \theta_k, \theta_k') \\
= \mathcal{L}_k (\Theta_k; \theta_k) +  \mathcal{L}_k (\Theta_k; \theta_k') + \lambda \mathcal{L}_k^{adv}(\Theta_k ; \theta_k, \theta_k').
\label{eq:fed_mi_adv_2}
\end{multline}
\end{itemize}


%In practice we can also add entropy loss on $\theta$ to control its complexity.

% , as shown in top row of Figure~\ref{fig:two_stage}.
% to become as distinct as possible regarding their 
% Maximize discrepancy between global classifier and local classifier, while we also minimize cross-entropy loss as well as classifier entropy loss. In this stage, we fix feature generator $\Theta_k$ and update local classifier $\theta_k$, as shown in top of Figure~\ref{fig:pipe_mcd}.
% This time, we maximize the discrepancy to encourage classifiers to learn diverse task boundaries.




% in which $\lambda>0$ is the weight of the discrepancy loss which can be searched by cross-validation. 
By training the classifiers and the feature generator in an adversarial manner, we iteratively optimize the model to learn a discriminative feature generator which helps boost few-shot learning on unseen tasks.

In our toy example, the feature generator learned by cat and dog images is likely to distinguish these two categories by eyes and ears and other unique features of these two species. Thus, cat-like and dog-like images are projected with large margins in the feature space learned explicitly by our approach. This space is transferable to tasks such as classifying tiger and wolf images. In reality, the richer and more representative are the base classes, the more discriminative the feature space will be. 
Recently, centralized machine learning models~\cite{sharif2014cnn, vaswani2017attention} have been shown to be capable of learning generic and versatile feature spaces on complex structured data such as images and texts. We have shown that such a feature space can also be efficiently learned in distributed scenarios.

In conclusion, we have proposed a novel way of learning a discriminative feature space in FedFSL with an adversarial learning strategy.
We summarize FedFSL-MI-Adv in Algorithm~\ref{algo:fed_mi_adv}.
\input{sections/algo_3}





\section{Introduction}


\begin{figure}
\begin{center}
\includegraphics[clip, trim=0 0 10 10, width=0.42\textwidth]{figures/FedFSL.pdf}
\end{center}
\vspace{-10pt}
\caption{Overview of a FedFSL system. Distributed client devices train client models with sampled FSL tasks from local data. Then client models are sent to the central server and aggregated to a central model, which is sent back to clients for the next round of local updates.
}\label{fig:fl_fsl_demo}
\vspace{-10pt}
\end{figure}


In recent years, mobile devices such as smartphones and tablet computers have become perhaps the most frequent and convenient way of connecting users to the Internet. A capable mobile device can now get access to first-hand user data such as photos, voice, typing records, and so on, thus it becomes an ideal platform to deploy machine learning models to better understand user intents and assist in completing daily tasks.
% e.g., a pre-trained language model can help users auto-complete a phrase when replying a short message or an Email.


%However, training models on mobile devices is a challenging task. 
Conventional distributed machine learning approaches~\cite{li2014scaling, zhang2015deep} require the data to be transferred from clients to a central server, which raises serious concerns of data privacy.
A recent proposed approach to address this issue is \fdl (FedL)~\cite{fedavg,zhao2018federated,li2020federated}. In the FedL paradigm, each participating client computes a local machine learning model with its own data, while a central server periodically coordinates client models by model aggregation (without collecting the actual data). FedL provides a promising way of learning models on distributed devices while preserving data privacy and locality. 


However, existing FedL approaches assume each participating client has sufficient training data for the tasks of interest. The realistic situation is that data collected with mobile devices can be insufficient and almost always unlabeled. This severely limits the practicality and scalability of FedL in realistic applications.
For example, image classification with federated deep neural networks (DNNs) is a commonly compared task in recent FedL studies~\cite{fedavg,zhao2018federated,li2020federated}. Training such a DNN in supervised fashion requires hundreds of labeled training samples or more for every class. In reality, each mobile user may own just one or a few samples of each interested image category, and the mobile user often does not have time or interest to label these images. The huge gap between lab scenarios with abundant labeled data and real situations with scarce and mostly unlabeled data motivates us to consider the following question: \textbf{How to make FedL effective in data-scarce scenarios?}





\begin{table*}[htb]
\centering
\small
\begin{tabular}{l|ccccccc} \toprule  
\hspace{-5pt}
Method & Federated learning & Non-convex model & SGD solver  & Few-shot learning & Divergence &  Feature learning \\ \toprule
FedAvg\cite{fedavg} / FedProx\cite{li2018federated}   & \checkmark   & \checkmark & \checkmark         \\
FEDL~\cite{dinh2019federated}  & \checkmark  & & \checkmark  \\
% One-shot FL~\cite{guha2019one} & \checkmark & & &  \\ 
% Distillation~\cite{hinton2015distilling} &&\checkmark &\checkmark & & \checkmark \\
Mutual learning~\cite{zhang2018mutual}  & &\checkmark &\checkmark & &\checkmark                \\
Local adaptation~\cite{yu2020salvaging}  &\checkmark &\checkmark &\checkmark & &\checkmark    \\
Gradient-based FSL\cite{finn2017model} & &\checkmark &\checkmark & \checkmark    \\  
Metric-based  FSL~\cite{Gidaris_2018_CVPR} & &\checkmark &\checkmark & \checkmark &   & \checkmark\\ 
\midrule 
FedFSL-naive (\cite{chen2018fedmeta}, \ref{sec:fed_maml})    &\checkmark &\checkmark &\checkmark & \checkmark    \\
\textbf{FedFSL-MI} (ours, \ref{sec:fed_maml_mi})  &\textbf{\checkmark} &\textbf{\checkmark} &\textbf{\checkmark} &\textbf{\checkmark} & \textbf{\checkmark} &       \\ 
\textbf{FedFSL-MI-Adv} (ours, \ref{sec:adv})  &\textbf{\checkmark} &\textbf{\checkmark} &\textbf{\checkmark} &\textbf{\checkmark} & \textbf{\checkmark} & \textbf{\checkmark}    \\ \bottomrule
\end{tabular}
\vspace{1pt}
\caption{Comparisons of relevant approaches with supported features.}
\vspace{-15pt}
\label{tab:checklist}
\end{table*}



A recently developed approach to address the issue of insufficient training data is few-shot learning (FSL)~\cite{vinyals2016matching, finn2017model, li2017meta}. FSL aims to develop machine learning models to solve unseen tasks with very few labeled training data, but often in the context of a single data source.
In this paper, we propose a federated few-shot learning (FedFSL) framework for efficiently training few-shot classification models from many data sources. The few-shot model can tackle novel tasks with just a few labeled data for unseen classes. As shown in Fig.~\ref{fig:fl_fsl_demo}, the paradigm of FedFSL is to first perform local updates with few-shot tasks sampled from local data, then send local models to a central server for model aggregation and coordination.
Through inheriting the merits of FedL, FedFSL also preserves the data privacy and communication efficiency.

FedFSL has many potential applications for utilizing machine learning models on mobile devices. For example, a few-shot language model can be used to suggest words by learning from just a few typing records from each of many users; a few-shot sentiment analysis model can be used to depict user profiles given only a few tweets posted by each of the many users; a few-shot face recognition model can identify users and their friends by learning from just few annotated photos by each of many mobile users.
%media recommendation model can be used to suggest media contents such as movies and songs
%by learning from only a few browsing records of many users.




There are two technical challenges we encounter during the development of the FedFSL framework: 1) directly using the existing FedL approaches to the data-scarce scenarios may lead to misaligned decision boundaries produced by client models, and 2) constraining the decision boundaries to be similar over clients would develop a classifier overfit to training tasks but not transferable to unseen tasks. To address these issues, we propose to regularize local updates by minimizing the divergence between client models and the central model. We then formulate the training of the feature generator part and classifier part of the model in adversarial fashion. In this way, the client models are explicitly optimized to produce a discriminative feature space that can better represent unseen data samples. We demonstrate the intuitions and conduct experiments to show the effectiveness of our approaches.


Our contributions can be summarized as follows:
\begin{itemize}[leftmargin=*]
    \item We propose a novel federated few-shot learning framework (FedFSL) that can perform effective federated learning on few-shot tasks. This represents the first step in addressing the commonly encountered but overlooked scenarios in mobile computing where training data is scarce and testing tasks are distinct.
    \item We present the key innovations in formulating FSL with federated clients as well as explicitly optimizing the federated model by minimizing model discrepancy in challenging non-IID scenarios.
    \item We define a novel concept of mutual divergence of federated client models, which can be minimized to better coordinate the client training on scarce local data. 
    \item We design a dedicated adversarial learning approach to construct a discriminative feature space, which better generalizes to unseen tasks compared with existing training procedures of FSL models. 
     \item We evaluate our framework by modelling different types of structured data (such as images and sentences) with both CNN and RNN models, showing its effectiveness and practical usability in modelling various learning tasks in machine vision and NLP.
    \item Our approaches significantly outperform baselines that are either non-distributed or not aligning the feature space across the clients by more than 10\% on vision tasks and 5\% on language tasks.
    % by 10\%$\sim$20\% on benchmark datasets. Also, our model coordination technique boosts the performance by 5\%$\sim$10\%.
    %\tred{result} 
\end{itemize}




% In Figure~\ref{fig:fl_fsl_demo}, we show the FedFSL system design in which federated clients learn on sampled tasks with meta-learning and periodically upload their local model updates to a central server. The server maintains a global FSL model which synchronizes back to clients for coordination. Queries of learning novel classes could be fulfilled in any device such that its local copy of the global FSL model is learned to adapt to novel classes with given few data points.

%Given a set of base classes with suffi-
% cient labeled samples, and a set of novel classes with only
% a few labeled samples, FSL aims to learn a classifier for the
% novel classes by learning a generic knowledge from the base
% classes.



% Deep learning has achieved great success in various com-
% puter vision tasks [10, 26]. However, with a large number
% of parameters, deep neural networks require large amounts
% of labeled data for model training. This severely limits their
% scalability – for many rare classes, it is infeasible to col-
% lect a large number of labeled samples. In contrast, hu-
% mans can recognize an object after seeing it once. Inspired
% by the few-shot learning ability of humans, there has been
% an increasing interest in the few-shot learning (FSL) prob-
% ∗ This work was done when the first author was an intern at Huawei
% Noah’s Ark Lab.
% lem [6, 13, 25, 27]. Given a set of base classes with suffi-
% cient labeled samples, and a set of novel classes with only
% a few labeled samples, FSL aims to learn a classifier for the
% novel classes by learning a generic knowledge from the base
% classes.




% They  the learning task across the clients is identical and the aggregated global model is tuned to be optimal for that specific task. In reality, however, each device could have distinct tasks and insufficient number of task-specific data with labels. How to integrate the learning of different tasks of each device into a learning federation has never been discussed before. Yet there is an abundant of practical applications.
% For example, several parents could take photos for different specifies and train an image classification model that children can play with to recognize new species and learn new words.
% The data in each device could have different categories, and more devices may join the learning federation to contribute more data with more categories. How to modify the FL framework to adapt to \htg tasks in different participants becomes an open question. 

% In this paper, we propose an elegant solution to embrace the task \htgt in FL framework by adopting few-shot learning (FSL) methodology, which allows distinct tasks to be learned in each client and new task to be quickly adapted with just a few training samples.
% We call this learning scheme \textbf{federated few-shot learning (FedFSL)}, an overview of which is shown


 
 
 

% , which is the first work in this topic to the best of our knowledge. (2) We observe the class boundary misalignment problems across models learned at federated clients, and propose an adversarial approach to better produce distinct features for data points from different categories; (3) We perform extensive experiments to evaluate the performance of our approach with different federation settings and few-shot learning tasks. We show the superior results of our approach on two few-shot learning benchmark datasets. Our approach can be easily extended to various state-of-the-art gradient-based meta-learning approaches.






% We will consider few-shot classification tasks in this paper, so that each client model is learning on distinct classification tasks sampled from local data, while the aggregated global model is evaluated by unseen tasks sampled from a global data distribution.


% tackling federated few-shot classification tasks with a realistic yet very challenging setting. We assume that in the network multiple clients with different data sources
% form a learning federation, and each client is solving different tasks which might be completely non-overlapping. Our goal is to train a federated versatile model by aggregating the knowledge of all federated learning participants, that can generalize to various unseen tasks by observing just a few training data. 



% If the assumptions were violated, the  aggregated model would be diverged or subject to inferior performance. We call them \textit{task heterogeneity} and \textit{data scarcity} issues.
% Though some research efforts have been made to study FL with non-IID data~\cite{wang2020federated,zhao2018federated}, few of them investigated the case that the data is scarce or the tasks are different across the clients.
% which can extend FL to broader and more realistic use cases. 



% \tblue{Try connecting FL and FSL in this paragraph.}
% However, training machine learning models from mobile data is facing several severe challenges. First, data collected locally at a single device is often insufficient and biased, thus making it difficult of directly training a reliable model locally. Second, if we could gather data from a large number of mobile devices to a central server for model training, the communication cost would be very high due to limited bandwidth of these low-power devices. Third but not last, transferring data is  highly risky due to data leakage. Therefore, how to safely and efficiently access data on mobile devices to effectively train models has become an open research problem.




% With the huge increase in device capacity, more and more edge devices such as wearable cameras, smartphones, IoT sensors are able to collect data and perform model training. 
% However, as modern machine learning models (i.e., deep neural networks) grow large and sophisticated, training these models requires more and more labeled data and consumes a huge amounts of computational power.

%  This is either unrealistic or extremely costly in a highly distributed scenario such as in Figure~\ref{fig:cloud_query}. 


%%% paragraph 2,3 verbose
% Recently,
% \fdl (FL) has become a rapidly developing technique~\cite{fedavg,zhao2018federated,li2020federated} as it provides a promising way of learning models over a collection of highly distributed devices while preserving  data at local devices without transferring. To achieve this, the federated clients compute local model updates on their own training data and periodically upload their model weights to a central server. The server aggregates the client models to a global model and synchronizes it back to each client, then each client starts next round of local update based on the new model. This process is repeated until convergence or timeout. One important benefit of FL is that no local data would be transmitted between a client and the server or across the clients. This makes it possible to learn a unified model with sensitive data collected by multiple edge devices, while still secures data privacy. Recent study~\cite{li2018federated, dinh2019federated} also showed that FL can be efficiently deployed on heterogeneous devices and edge networks, which makes it an appealing topic in mobile computing now.

% privacy by keeping data on its original devices.
% and ensuring communication efficiency. 
% his technology allows users to
% collaboratively build a shared learning model while preserving
% all training data on their user equipment (UE). In particular,
% a UE computes the updates to the current global model on
% its local training data, which is then aggregated and fed-back
% by a central server, so that all UEs have access to the same
% global model to compute their new updates. This process
% is repeated until an accuracy level of the learning model is
% reached. In this way, the user data privacy is well protected
% because local training data are not shared, which thus differs
% FL from conventional approaches in data acquisition, storage,
% and training.


% Though \fdl has witnessed successes on a few supervised learning tasks, such as query suggestion~\cite{fedavg}, several limitations  refrain it from widely applying to learning generic machine learning tasks on distributed devices. 
% \tblue{This is for emphasizing FL tasks have to be same, cannot adapt to new tasks}


% Firstly, current FL scheme r. Otherwise, the model aggregation would be meaningless as the models are optimized for different tasks.  In other words, it is still unknown how to generalize the federated learning scheme to learning unseen tasks that is not visible to all clients. \hl{the example might be not that relevant}. For example, if we have several robots which are learning to shake hands with humans, while a few other robots learn to grab objects, it is unknown how to benefit the learning of each task with the other in federated setting as they have different objectives. We call this issue \textbf{Task heterogeneity}.
% First of all, the FL's scheme of  local update and central aggregation has an implied assumption such that the data distribution across the clients should be identical or similar. When this assumption is violated, say each client has highly skewed data, the model weight could be diverged and the aggregated model could significantly underperform~\cite{zhao2018federated}.  This results in a strong limitation of extending FL to mobile devices, as data collected locally is usually subject to skewed distribution due to geo-location difference, user preference, device heterogeneity and so on. We call this issue \textbf{Data heterogeneity}.

% current FL scheme cannot handle this case as the task objectives are different, though we know that these two tasks share certain knowledge that can be
% Imagine that if we aim to learn a good bird classifier from images, the data sources with images of other species such as dogs would find it no way of participating in the federated learning.



% images and is not able to build a robust learning model due to scarce data and biases in data. 
% We show a typical use case in Figure~\ref{fig:cloud_query}, in which a distributed machine learning system is deployed across multiple devices. A user query could be initialized from any device and to answer the query, knowledge has to be distilled from some databases and transferred to the user device. To design such a system, two core questions have to be answered: 1) how to distill relevant knowledge from distributed data sources that stored locally and 2) how to adapt the knowledge to a specific user query which is a most probably unseen task.


















% In this way, a new sample from the novel class can be recognized directly through a simple distance metric within the learned embedding space. The success of these metric based approaches relies on learning a discriminative embedding space.
% To further improve the performance, we introduce the
% adaptive margin in the embedding space, which helps to
% separate samples from different classes, especially for similar classes. The key insight of our approach is that the semantic similarity between different classes can be leveraged to generate adaptive margin between classes, i.e., the margin between similar classes should be larger than the one between dissimilar classes (as illustrated in Figure 1). By integrating the adaptive margin into the classification loss, our method learns a more discriminative embedding space
% with better generalization ability.
% Specifically, we first propose a class-relevant margin
% generator which produces an adaptive margin for each pair
% of classes based on their semantic similarity in the semantic space. By combining the margin generated by class relevant margin generator and the classification loss of FSL approaches, our class-relevant additive margin loss can effectively pull each class away from other classes. Considering the semantic context among a sampled training task in the FSL, we further develop a task-relevant margin generator. By comparing each class with the rest classes among the task in the semantic space, our task-relevant margin generator produces more suitable margin for each pair of classes. By involving these margin penalty, our task-relevant margin loss learns more discriminative embedding space, thus leads to stronger generalization ability to recognize novel


% The former limitation makes the training a modern complex model with millions of parameters infeasible (e.g. ResNet~\cite{he2016deep}), the latter one makes the model unable to generalize to new tasks such as few-shot learning. A natural idea to solve this dilemma is using federated few-shot learning. As the benefits of few-shot learning, the data is free from leakage?  Due to biases and different task boundaries, direct federation makes task boundary confused, and when applying a standard few-shot learning algorithm such as MAML, the gradients would not follow the correct direction. We apply adversarial learning idea to solve this problem. 
% We found this idea easy to embed to any few-shot learning framework such as maml and meta-transfer learning, and this method is practice. 
% We perform experiments on image recognition tasks on two benchmark few-shot learning datasets miniImageNet and Fewshot-CIFAR100 to study.
% We also propose a challenging realistic few-shot learning dataset from 
% real-world electricity industry, showing that in practice our method significantly outperformed all the baselines.





% Supervised deep learning have witnessed great advancement in various real-world applications in recent years, such as image recognition, object detection, language translation, etc. 
% However, supervised learning is suffering from data limitation problems in real cases. 
% To boost the performance of supervised in target tasks, collecting data as many as possible from different sources becomes not only important but also essential.
% For example, to build a robust image classification model which can recognize common categories, thousands of hundreds of labeled images have to be collected (e.g., ImageNet~\cite{deng2009imagenet}) for the training purpose.
% XXX make an example.


%%%%%% FROM META-GAN
% Deep neural networks have achieved great success in many artificial intelligence tasks. However, they tend to struggle when data is scarce or when they need to adapt to new tasks within a few numbers of
% steps. On the other hand, humans are able to learn new concepts quickly, given just a few examples. The reason for this performance gap between human and artificial learners is usually explained as that humans can effectively utilize prior experiences and knowledge when learning a new task, while
% artificial learners usually seriously overfit without the necessary prior knowledge.
{\SetAlgoNoLine
\begin{algorithm}[htp]
\small
\DontPrintSemicolon
\LinesNumberedHidden
\KwIn{A set of $K$ federated clients. A local FSL objective $\mathcal{L}_k$ for each client $k$.
}
\KwOut{A global model $w=\Ttsupsubeq{}{}$ optimized for FSL task.}
\textbf{Server executes:} \;
\Indp Initialize global model $w^0=\Ttsupsubeq{0}{}$ \;
$t \leftarrow 1$ \;
\While{t $\leq$ maximum rounds $T$}{
    % $m \leftarrow \max(C\cdot K, 1)$ \;
    % $S_t \leftarrow $ (a random subset of $m$ clients) \;
    \For{\textup{each client} $k$ \textup{\textbf{in parallel}}}{ 
    $\Ttsupsubeq{t}{k} \leftarrow $ ClientUpdate$(\Ttsupsubeq{t}{})$
    }
    Clients send models $\Ttsupsubeq{t}{1...K}$ to server \;
    $\Ttsupsubeq{t+1}{} \leftarrow \sum_{k=1}^K \frac{|\mathcal{B}_k|}{|\mathcal{B}|} \Ttsupsubeq{t}{k}$ \;
    The server sends $\Ttsupsubeq{t+1}{}$ back to clients \;
    $t \leftarrow t+1$ \;
 }
Return $\Ttsupsubeq{t}{}$ \;
\;
\Indm \textbf{ClientUpdate}$(\Ttsupsubeq{}{})$: \;
% \Indp $\mathcal{B}_k \leftarrow$ (split local data into batches of episodes) \;

\Indp \KwIn{global model from previous round $\Ttsupsubeq{t}{}$}
\KwOut{updated local model $\Ttsupsubeq{t}{k}$}

Sample a batch of episodes $\mathcal{B}_k=\{\mathcal{T}_1,...,\mathcal{T}_n\}$ \;
$\Ttsupsubeq{}{k} \leftarrow \Ttsupsubeq{t}{}$ \;
Initialize a new classifier $\theta_k'$ \;
$\theta_k, \theta_k' \leftarrow $ Solve Eq.\eqref{eq:fed_mi_adv_1} with SGD \;
$\Theta_k \leftarrow $ Solve Eq.\eqref{eq:fed_mi_adv_2} with SGD \;
$\Ttsupsubeq{t}{k} \leftarrow \Ttsupsubeq{}{k}$ \;
Return $\Ttsupsubeq{t}{k}$ \;



% $\theta_k^c \leftarrow \theta_k^t$\;
% \For{\textup{each episode} $\mathcal{T} \in \mathcal{B}_k$}{
%     // \textit{adapt to new task as in \eqref{eq:adp}} \;
%     $\Ttsupsubeq{}{k} \leftarrow \Ttsupsubeq{}{k}-\alpha \gradsubeq{\Ttsupsubeq{}{k}}f_{\mathcal{T}^{(s)}}(\Ttsupsubeq{}{k})$  \;
%     $[\Theta_k, \theta_k'] \leftarrow [\Theta_k, \theta_k']-\alpha \gradsubeq{[\Theta_k, \theta_k']}f_{\mathcal{T}^{(s)}}([\Theta_k, \theta_k'])$ \;
%     // \textit{stage-1 optimization as in \eqref{eq:fed_mi_adv_1}} \;
%     $\theta_k, \theta_k' \leftarrow \underset{\theta_k,\theta_k'}{\text{min}}  \ \mathcal{L}_k^{st\text{-}1}(\theta_k, \theta_k' ; \Theta_k)$ \;
%     // \textit{stage-2 optimization as in \eqref{eq:fed_mi_adv_2}} \;
%     $\Theta_k \leftarrow \underset{\Theta_k}{\text{min}} \ \mathcal{L}_k^{st\text{-}2}(\Theta_k; \theta_k, \theta_k')$
% }
\caption{FedFSL-MI-Adv algorithm.} \label{algo:fed_mi_adv}
%\end{algorithm2e}
\end{algorithm}
}




% {\SetAlgoNoLine
% \begin{algorithm}[htpb]
% \DontPrintSemicolon
% \LinesNumberedHidden
% \KwIn{A set of $K$ federated clients. A local FSL objective $\mathcal{L}_k$ for each client $k$.
% }
% \KwOut{A global model $\wsupsubeq{}{}$ optimized for FSL task.}
% \textbf{Server executes:} \;
% \Indp Initialize global model $w^0$ \;
% $t \leftarrow 1$ \;
% % Randomly initialize $\wsupsubeq{}{k}$ for all clients. \;
% %\For{\textup{each round} $t = 1,2,\dots,T$ } {
% \While{not done}{
%     \For{\textup{each client} $k$ \textup{\textbf{in parallel}}}{ 
%     $w_k^{t} \leftarrow $ ClientUpdate{$(k,w)$} 
%     }
%     Collect $w_k^{t}$ from all clients \;
%     $w \leftarrow \sum_{k=1}^K \frac{|\mathcal{B}_k|}{|\mathcal{B}|} w^{t}_k$  \tcp*[l]{model avg}
%     Send $w$ back to clients \;
%     $t \leftarrow t+1$
%  }
% \;
% \Indm \textbf{ClientUpdate}$(k,w)$: \;
% \Indp $\mathcal{B}_k \leftarrow$ (split local data into batches of episodes) \;
% \For{\textup{each episode} $\mathcal{T}_k \in \mathcal{B}_k$}{
%     $\wsupsubeq{}{} \leftarrow \wsupsubeq{}{}-\eta  \gradsubeq{\wsupsubeq{}{}}f_{\mathcal{T}^{(s)}_k}(w)$ \tcp*[l]{Eq.\eqref{eq:adp}}
%     % \LeftComment{// \textit{optimize local objective} $\mathcal{L}_k$} \;
%     $w \leftarrow \underset{\wsupsubeq{}{}}{\text{argmin}} \ \mathcal{L}_k(w)$  \tcp*[l]{Eq.\eqref{eq:fed_def_adp_k}}
% }
% % return $w$ to server \;
% \caption{FedFSL-naive framework.} \label{algo:fed_maml}
% %\end{algorithm2e}
% \end{algorithm}
% }


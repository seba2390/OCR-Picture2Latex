% last updated in April 2002 by Antje Endemann
% Based on CVPR 07 and LNCS, with modifications by DAF, AZ and elle, 2008 and AA, 2010, and CC, 2011; TT, 2014; AAS, 2016

\documentclass[runningheads]{llncs}
\usepackage{graphicx}
\usepackage{amsmath,amssymb} % define this before the line numbering.
%\usepackage{ruler}
\usepackage{color}
%\usepackage{times}
\usepackage{epsfig}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{pdfpages}
\usepackage{subcaption}
\captionsetup{compatibility=false}
%\usepackage{amsmath}
%\DeclareMathOperator*{\argmax}{arg\,max}
\usepackage[table,xcdraw]{xcolor}
\usepackage{tabularx} % for 'tabularx' environment
\usepackage{commath}
\usepackage{placeins}
\usepackage[width=122mm,left=12mm,paperwidth=146mm,height=193mm,top=12mm,paperheight=217mm]{geometry}
\newcommand{\vect}[1]{{\bf {#1}}}
\newcommand{\matx}[1]{{\cal {#1}}}
\newcommand{\expect}[1]{{\mathbb{E}}{{\left[{{#1}}\right]}}}
\DeclareMathOperator*{\argmin}{argmin}
\begin{document}
% \renewcommand\thelinenumber{\color[rgb]{0.2,0.5,0.8}\normalfont\sffamily\scriptsize\arabic{linenumber}\color[rgb]{0,0,0}}
% \renewcommand\makeLineNumber {\hss\thelinenumber\ \hspace{6mm} \rlap{\hskip\textwidth\ \hspace{6.5mm}\thelinenumber}}
% \linenumbers
\pagestyle{headings}
\mainmatter
\def\ECCV18SubNumber{1861}  % Insert your submission number here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
%\newcommand{\todo}[1]{{\bf To do: }{{\em #1}}\\}
\newcommand{\sign}[1]{{\mbox{sign}}{{#1}}}
%\newcommand{\notes}[1]{{\bf Notes:} {\em {#1}}}
%\newcommand{\notes}[1]{}
%\newcommand{\matx}[1]{{\bf {#1}}}
\newcommand{\ea}[0]{{\em et al. }}
\newcommand{\plan}[1] {{\bf Plan:}\\ {\em {#1}}}
\newcommand{\dafkld}[2]{{\mathbb{D}({{{#1}}}\! \mid \! \mid {{{#2}}})}}
%\newcommand{\norm}[1]{{\mid\!\mid\!\!{#1}\!\!\mid\!\mid}}
\newcommand{\pr}[1]{{\rm Pr}[#1]}
%\renewcommand{\thesection}{\Alph{section}}
%\renewcommand{\baselinestretch}{1.2}
\renewcommand{\refname}{}
\renewcommand{\contentsname}{\vspace*{-1.2cm}}
\newcommand{\newterm}[1]{{\bf #1}}
\newcommand{\capsty}[1]{{\em {#1}}}
%\newcommand{\vect}[1]{{\bf {#1}}}
\newcommand{\argmax}[1]{{\begin{array}{c}\mbox{argmax}\\{{#1}}\end{array}}}
\newcommand{\todo}[1]{{{\bf TODO:} {{#1}}}}
\newcommand{\covmat}[1]{{
{\small {\mathsf{Covmat}}
 \left( \left\{ 
{{#1}}
      \right\} \right)
}}}
%\def{\ECCV18SubNumber}{1861}
\newcommand{\mean}[1]{{{\mathsf{mean}}\left(
      \left\{{#1}\right\}\right)}}
%%%%%%%%% TITLE
\title{Quantitative Evaluation of Style Transfer}
\vspace{-3mm}
\authorrunning{Quantitative Evaluation of Style Transfer}

%\author{Anonymous ECCV submission}
\institute{University of Illinois at Urbana and Champaign}
%{Paper ID \ECCV18SubNumber}

\author{Mao-Chuang Yeh \and Shuai Tang \and Anand Bhattad \and D. A. Forsyth\\
University of Illinois at Urbana Champaign\\
\{myeh2, stang30, bhattad2, daf\}@illinois.edu}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
%\thispagestyle{empty}
\maketitle
% \begin{figure*}[!h]
% \centering
% \includegraphics[width=0.98\linewidth]{PlotsNCharts/good_examples_mul_loss.pdf}
% \caption{\em Style transfer examples demonstrate the advantages of our method (\textbf{right} image in every example) compared to Gatys' method \cite{gatys2016image} (\textbf{left} image). 
% We use cross-layer gram matrices for style losses (section \ref{sec:Cross}). Notice our method preserves prominent content boundaries (e.g. the tower and the boatman), while transferring patterns from the style image more completely. Our method excels at transferring style with long scale coherence (example 1,2); and preserves the appearance of material relief (example 3,4).}
% \label{fig:mulloss_comp}
% \vspace{-10mm}
% \end{figure*}
%%%%%%%%% ABSTRACT
\begin{abstract}
Style transfer methods produce a transferred image which is a rendering of a content image in the manner of a style image.
There is a rich literature of variant methods.  However, evaluation procedures are qualitative, mostly involving user studies.
We describe a novel quantitative evaluation procedure.  One plots effectiveness (a measure of the extent to which the
style was transferred) against coherence (a measure of the extent to which the transferred image decomposes into objects in the same way that the content image does) to obtain an EC plot.

We construct EC plots comparing a number of recent style transfer methods.  Most methods control within-layer gram
matrices, but we also investigate a method that controls cross-layer gram matrices.
These EC plots reveal a number of intriguing properties of recent
style transfer methods.  The style used has a strong effect on the outcome, for all methods.  Using large style weights
does not necessarily improve effectiveness, and can produce worse results.  Cross-layer gram matrices easily beat
all other methods, but some styles remain difficult for all methods.  Ensemble methods show real promise.  It is likely that, for
current methods, each style requires a different choice of weights to obtain the best results, so that automated weight
setting methods are desirable.  Finally, we show evidence comparing our EC evaluations to human evaluations.
\end{abstract}
\section{Introduction}
Style transfer methods apply the {\em style} from one example image to the {\em content} of another; 
for instance, one might render a camera image (the content) as a watercolor painting (the style). 
Recent work has shown that highly effective style transfer can be achieved by searching for an image such 
that early layers of CNN representation match the early layers of the style image and later layers match the later 
layers of a content image~\cite{gatys2016image}. Content matching is by comparing activations at each location of a 
feature map. Style matching is achieved by comparing summary statistics -- in particular, the gram matrix -- of the 
layers individually. Comparing gram matrices of individual layers ensures that small, medium and large patterns that 
are common in the style image appear with about the same frequency in the synthesized image, and that spatial co-occurrences 
between these patterns are about the same in synthesized and style image.

The current evaluation of style transfer methods are done primarily by visual inspection on a small set of different styles and content image pairs. To our knowledge, there are no quantitative protocols to evaluate the competence of 
style transfer apart from user studies ~\cite{li2018closed}. This may be due to the fact that {\em styles} are subjective and more subtle to define than textures, 
hence such effectiveness metric is hard to choose. Furthermore, quick adjustment to a method using user studies is difficult in practice.
 The quantitative evaluation such as the edge coherence between {\em contents} and stylized images is investigated in ~\cite{li2018closed}. Novak and Nikulin noticed that cross-layer 
 gram matrices reliably produce improvement on style transfer (\cite{novak2016improving}). However, 
 their work was an exploration of variants of style transfer rather than a thorough study to gain insights on 
 style summary statistics. Their primary suggestions are adding more layers for more features, and they don't pursue cross-layer gram matrices 
  and quantitatively compare variant modifications. 
  
  In this paper, %we show (a) methods to evaluate style transfer quantitatively and 
%  (b) strong evidence, both experimental and theoretical, that cross-layer gram matrices produce better style transfers.
% %  For instance, Novak and Nikulin~\cite{novak2016improving} 
% %  search a range of variant style transfer methods, including cross-layer gram matrices.  
% \noindent \textbf{Contributions:} 
% %\todo emphasize on building EC evaluation metric, less focus on detail cross-layer multiplicative loss method. 
% \begin{itemize} 
we offer a comprehensive quantitative evaluation procedure for style transfer methods. We evaluate style transfers on two criteria.  {\bf Effectiveness} measures whether transferred images have the desired style, using divergence between
convolutional feature layer distributions of the synthesized image and original image.  {\bf Coherence} measures whether the synthesized images respect the underlying
decomposition of the content image into objects, using established procedures together with the Berkeley segmentation dataset BSDS500 \cite{arbelaez2011contour}, and also using a novel measure of segment divergence.

We use our measures to compare several style transfer methods quantitatively.  
In particular, we show that controlling cross-layer, rather than within-layer, gram matrices produces quantitative improvements in style transfer over the original method due to instability in Gatys \ea proposed method (henceforth  Gatys)~\cite{gatys2016image} as described in Risser \ea~\cite{risser2017stable}.  
We construct explicit models of the symmetry groups for Gatys' style loss and the cross-layer style loss 
(improving over Risser \ea, who could not construct the groups). We discuss this in detail in section \ref{sec:symmetry}.  We show experimental evidence that 
the quantitative improvement over Gatys' method is due to the difference in symmetry groups. 
We show qualitative evidence suggesting that these quantitative improvements manifest in real images.

\section{Related work} \label{sec:gatys}
Bilinear models are capable of simple image style transfer~\cite{Tenenbaum2000} by factorizing style and content representations, but non-parametric methods like patch-based texture synthesis can deal with much more complex texture fields~\cite{Efros2001}.  Image analogies
use a rendering of one image in two styles to infer a mapping from a content image to a stylized
image~\cite{Hertzmann2001}. Researchers have been looking for versatile parametric methods to control style patterns at
different scales to be transferred. Adjusting filter statistics is known to yield texture
synthesis~\cite{debonet,simoncelli}.  Gatys \ea demonstrated that producing neural network layers with particular
summary statistics (i.e Gram matrices) yielded effective texture synthesis~\cite{NIPS2015_5633}. In a following paper,
Gatys \ea achieved style transfer by searching for an image that satisfies both style texture summary statistics and
content constraints~\cite{gatys2016image}. This work has been much elaborated. The search can be replaced with a
regression (at one scale~\cite{Johnson2016Perceptual}; at multiple scales~\cite{wang2016multimodal}; with
cached~\cite{chen2017stylebank} or learned~\cite{dumoulin2016learned} style representations) or a decoding process that
allows efficient adjusting of statistics ~\cite{DBLP:journals/corr/UlyanovVL16,huang2017arbitrary,UST,li2018closed}. Search can be sped up with local matching
methods~\cite{chen2016fast}. Methods that produce local maps (rather than pixels) result in photorealistic style
transfer~\cite{Shih2014,Luan2017}. Style transfer can be localized to masked regions~\cite{gatys2016controlling}. The
criterion of matching summary statistics is a Maximum Mean Discrepancy condition~\cite{li2017demystifying}. Style
transfer has also been used to enhance sketches~\cite{champandard2016semantic}.There is a comprehensive review in~\cite{jing2017neural}.

Gupta \ea ~\cite{gupta2017characterizing} study instability in style losses from videos, 
where they use prior video frames to stabilize current video frame by enforcing a temporal consistency loss. They demonstrate theoretically
instability in Gaty's method is linked to the size of the trace of the gram matrix. They support this argument with experimental evidence
that larger traces result in higher instability.

\vspace{-2mm}
\subsection{Gatys Method}
We review the original work of Gatys \ea \cite{gatys2016image} in detail to introduce notation.
Gatys finds an image where early layers of a CNN representation match the lower layers of the style image and higher layers match the higher layers of a content image.  Write $I_{s}$ (resp. $I_{c}$, $I_{n}$)  for the style (resp. content, new) image,
and $\alpha$ for some parameter balancing style and content losses ($L_s$ and $L_c$ respectively).  Occasionally, we
will write $I_n^m(I_c, I_s)$ for the image resulting from style transfer using method $m$ applied to the arguments.
We obtain $I_{n}$ by finding

\[
{\argmin_{I_n}} L_c(I_{n}, I_{c})+\alpha L_s(I_{n}, I_{s})
\]

Losses are computed on a network representation, with $L$ convolutional layers, where the $l$'th layer
produces a feature map $f^l$ of size $H^l \times W^l \times C^l$ (resp. height, width, and channel number).  We partition
the layers into three groups (style, content and target). Then we reindex the spatial variables (height and width) and
write $f^l_{k,p}$ for the response of the $k$'th channel at the  $p$'th location in the $l$'th convolutional layer. The
content loss $L_c$ is 

\[
L_c(I_{n}, I_{c}) = \frac{1}{2}\sum_{c} \sum_{k,p} \norm{f^c_{k,p}(I_{n}) - f^c_{k,p}(I_{c})}^2
\]

\noindent (where $c$ ranges over content layers). The {\em within-layer gram
  matrix} for the $l$'th layer is
\[
G_{ij}^l(I) = \sum_p \left[f_{i,p}^l(I)\right]\left[f_{j,p}^l(I)\right]^{T}.
\]

\noindent Write $w_l$ for the weight applied to the $l$'th layer.  Then 
\[
L_s^l(I_{n}, I_{s}) = \frac{1}{4{N^l}^2{M^l}^2}\sum_{s}w_l \sum_{i,j}\norm{G^s_{ij}(I_{n})-G^s_{ij}(I_{s})}^2
\]

\noindent where $s$ ranges over style layers. Gatys \ea use Relu1\_1, Relu2\_1, Relu3\_1, Relu4\_1, and Relu5\_1 as style layers, and layer Relu4\_2 
for the content loss, and search for $I_{n}$ using L-BFGS~\cite{liu1989limited}.  From now on, we write R51 for Relu5\_1, etc. 

\section{Quantitative Evaluation of Style Transfer}\label{effcoh}

A style transfer method should meet two basic tests.  The first is {\bf effectiveness} -- does the
method produce images in the desired style? The second is {\bf coherence} -- do the resulting images respect the
underlying decomposition of the content image into objects?   While final judgment should belong to the artist, we
construct numerical proxies that can be used to disqualify methods from a final user study. 
It is essential to test both properties (excellent results on coherence can
be obtained by simply not transferring style at all).  In this paper, we offer one possible
effectiveness statistic and two possible coherence statistics; however, we expect
other reasonable choices could apply.

{\bf Effectiveness:}  Assume that a style is applied to a content image. We would like to measure the extent to which the result reflects the style.  
There is good evidence that the distribution of features within lower feature layers of a CNN 
representation is an effective proxy to capture styles ~\cite{bau2017network}.  
We expect that individual transferred images might need to have small biases in the distribution of 
feature layers to account for the content, but over many images the distribution of features 
should reflect the style distribution.  In turn, a strong measure of effectiveness of style 
transfer for a particular image is the extent to which the distribution of feature layer values 
produced by the transferred image matches the corresponding distribution for the style image. 
In notation, write $\vect{f}^{l}_{p}(I)$ for the vector of responses  of all channels  at the  
$p$'th location in the $l$'th convolutional layer for image $I$. Now choose the $i$'th content 
image, the $j$'th style, and some method $m$.  
The distribution $P_{t, m}$ of $\vect{f}^{l}(I^m_n(I_c^i,I_s^j))$ should be similar to  
the distribution $P_s$ of $\vect{f}^{l}(I_s^j)$, with perhaps some smoothing  resulting 
from the need to meet content demands.   

Testing whether two datasets come from the same, unknown, distribution in high dimensions remains tricky 
(the method of~\cite{gretton2012kernel} is the current best alternative).  We do not expect the distributions
 to be exactly the same;  instead, we want to identify obvious (and so suspicious) large  differences. 
 The symmetry analysis below suggests that Gatys method will massively increase the variance of  
 $\vect{f}^{l}(I^g_n(I_c^i,I_s^j))$.  Observing major differences is straightforward with relatively 
 crude tools.   However, dimension is a problem.  Even assuming that each distribution is normal,  
 computing KL divergences is impractical, because the distributions are large and so the estimates 
 of the covariance matrices are unreliable.   

However, we seek a statistic that is large with high probability when $P_{t,m}$ and $P_s$ are strongly 
different, and small with high probability when they are similar.  A straightforward construction, 
after~\cite{DeshpandeCVPR2018} is as follows .
%Choose a set of content images $I_{c}^{i}$ and of style images $I_{s}^{j}$.   
Write $\vect{v}_k$ for a random unit vector.  We then compute
$p_p^m=\vect{v}_k^T\vect{f}_p^{l}(I^m_n(I_c^i,I_s^j))$ and $p_p^s=\vect{v}_k^T\vect{f}_p^{l}(I_s^j)$.  We assume that
these scalar datasets are normally distributed, and compute KL divergence $d(\vect{v}_k)$ from the style distribution to the transferred
distribution.  We now average over $R$ random unit vectors and form
\[
E=-\log \left(\frac{1}{R} \sum_{k}d(\vect{v}_k)\right)
                     \]                   
Large values of this statistic are obtained if there are few random directions in which the two distributions 
differ; small values suggest there are many such directions and so that the style transfer may not 
have succeeded. For all our analysis, we choose a single set of 128 random unit vectors that is reused for all methods.

{\bf Coherence:} A style transfer method that eliminates object boundaries would make it hard for humans to interpret
the output images, so a reasonable measure of a style transfer method is the extent to which it preserves object
boundaries.  We have two measures of coherence.  Our {\em boundary preservation} measure computes the extent to which a
boundary prediction algorithm produces true object boundaries for a given method, using the Berkeley segmentation dataset tests BSDS500~\cite{arbelaez2011contour}.  Our {\em object coherence} measure computes the extent to which textures are (a) coherent within object boundaries and (b) distinct from object to object.
{\em Boundary preservation} is treated as a straightforward application of existing methods to evaluate image boundaries.  We choose a boundary predictor (we used the contour detection of~\cite{arbelaez2011contour}); we apply the style transfer methods to images
from the BSDS500, using multiple style images, to obtain synthesized images; we apply the boundary predictor to the synthesized images; and we compute the area under curve (AUC) of the  probability of boundary (Pb) precision-recall curve for every synthesized image.  A higher AUC suggests better boundary
preservation.  As section~\ref{results} shows, this measure is highly variable depending on the style that is transferred, and so we compute a per-transferred image AUC. This evaluation method is not perfect.  Heavily textured styles may confuse the Pb evaluation without confusing human viewers, because the contour detector was not built with very aggressive texture fields in  mind (compare typical style transfer images with the  ``natural'' textures used to build BSDS500).  In particular, we might have texture fields that are strongly coherent within each object region and different from region to region, but where the contour detector has great difficulty identifying object boundaries. 

%\input{qual_land.tex}

An \textit{object coherence} measure is easy to obtain using the BSDS500 dataset, because each image comes with a ground truth contour
mask.  We choose some layer $l$, and write $\vect{f}_{S,i}=\vect{f}_{i}^{l}(I^g_n(I_c^i,I_s^j), S)$ (for brevity) for a feature
vector in that layer within some segment $S$, and $\left\{\vect{f}_{S,i}\right\}$ for all such feature
vectors.  Write $\mu_S=\mean{\vect{f}_S}$, and $\Sigma_b=\covmat{\mu_S}$ for the between class covariance matrix.
Assume that each segment has the same covariance(heteroskedasticity,
a tolerable assumption given that the method tries to impose a gram matrix on the layer), and construct the within-class covariance for all locations in a segment 
$\Sigma_w=\covmat{\vect{f}_{1,1}-\mu_1, \ldots \vect{f}_{n_S,n_f(S)}-\mu_{n_S}}$.
Now the
largest generalized eigenvalue $\lambda^{\mbox{max}}$ of $(\Sigma_b, \Sigma_w)$ measures the dispersion of the region
textures.   Notice that $\lambda^{\mbox{max}}\geq 0$, and simple plots (supplementary materials) suggest this has a
log-normal distribution over multiple style/content pairs.  We therefore use $L_m=\log \lambda^{\mbox{max}}_{m}$ as a
score to evaluate a method.  Larger values suggest more successful separation of regions.\\

{\bf Summarizing data with the EC plot.} Comparing style transfer methods requires a 
summary of: the expected effectiveness of a method at any coherence; the effect of style
 and of weight choice on performance; and the extent to which evidence supports a difference between methods.
 We compare methods using an effectiveness-coherence (EC) plot, which plots: 
 (a) a scatter plot of EC pairs obtained for various style/content/weight triplets;   
 (b) a Loess regression curve of E regressed against C for these triplets; and 
 (c) standard error regions for the regression.     
 Effectiveness is measured per layer and we show layer 1 plots in section \ref{ExpPro} (with others in the supplementary material). Coherence is measured either using per-image AUC of Pb (which does not depend on layers) or using $L_m$, \textit{object coherence}; this depends on the layer (more plots in supplementary material).
\input{qual_port.tex} %portrait mode qualitative
\section{Cross-layer Style Transfer}\label{sec:Cross}

\subsection{Cross-layer style loss}
We consider a style loss that takes into account between layer statistics.  The {\bf cross-layer, additive (ACG)} loss
is obtained as follows.  Consider layer $l$ and $m$, both style layers, with decreasing 
spatial resolution.  

Write $\uparrow f^{m}$ for an upsampling of  $f^m$ to $H^l\times W^l \times K^m$, and consider
\[
G_{ij}^{l,m}(I) = \sum_{p} \left[ f_{i,p}^l(I)\right]\left[\uparrow {f}_{j,p}^{m}(I)\right]^{T}.
\]
as the cross-layer gram matrix, We can form a style loss
\[
L_s(I, I_{s}) = \sum_{(l, m)\in {\cal L}} w^{l}\sum_{ij} \norm{G^{l,m}_{ij}(I)-G^{l,m}_{ij}(I_s)}^2
\]
(where ${\cal L}$ is a set of pairs of style layers).   We can substitute this loss into the original style loss, and
minimize as before.  All results here used a {\em pairwise descending} strategy, where one constrains each layer and its
successor (i.e. (R51, R41); (R41, R31); etc).  Alternatives include an {\em all distinct pairs} strategy, where one constrains all pairs of distinct
layers. Carefully controlling weights for each layer's style loss is not necessary in cross-layer gram matrix scenario.  
{\em Constraint counts} for cross-layer gram matrix methods are much lower than for with-in layer methods.  For a
pairwise descending strategy,  we have four cross-layer gram matrices, leading to  control of $64\times
128+128\times 256+256\times 512+512\times 512 = 434176 $ parameters; compare within layer gram matrices, which control 
$64^2+128^2+256^2+2\times512^2 = 610304$ parameters.  The experimental results suggest that the number of constraints is a poor way of evaluating a method.

\vspace{-2mm}
\subsection{Symmetries and Stability}\label{sec:symmetry}
 
Symmetries in a style transfer loss function occur when there is a transformation available that changes the style
transferred image without changing the value of the loss function.   Risser \ea note instability in Gatys' method;
symptoms are poor and good style transfers of the same style to the same content with about the same loss value~\cite{risser2017stable}.
They supply evidence that this behavior can be controlled by adding a histogram loss, which breaks the symmetry.
They do not write out the symmetry group as too complicated
(~\cite{risser2017stable}, p 4-6).   Gupta \ea ~\cite{gupta2017characterizing} make a strong experimental argument that instability in Gaty's method is linked to the size of the trace of the gram matrix (larger trace is linked to more instability).

One portion of the symmetry group is easy to construct.  In particular, we consider affine maps acting on a feature layer, and consider the effect on that layers gram matrix and
on the gram matrix of the next layer.  Notice this does not exhaust the available symmetries (for example, a spatial permutation of features
would not change the gram matrix).  We have no construction currently for spatial symmetries.
The supplementary materials give a construction for all affine maps that fix the gram matrix for a layer and its parent
(deeper networks follow the same lines).  It is necessary to assume the map from layer to layer is linear.  This is not
as restrictive as it may seem; the analysis yields a local construction about any generic operating point of the
network.  In summary, we have:

{\bf Symmetry group, within layer gram matrices, two layers:}
Assuming that the between layer map is affine, with matrix $\matx{M}$
representing the linear component.  With various assumptions about the
spatial statistics of layer 1 (supplementary materials), an element of the symmetry
group is obtained by:  choose $\vect{b}$ {\em not} of unit length, and
such that $\matx{M}\vect{b}=0$; now factor
$\matx{I}-\vect{b}\vect{b}^T=\matx{A}\matx{A}^T$; choose $\matx{U}$
orthonormal.  Then $(\vect{b}, \matx{A}\matx{U})$ is a symmetry of the
gram matrices in {\em both layers} (i.e the action of this element on
layer 1 fixes {\em both} gram matrices).   In particular, mapping all feature vectors $\vect{f}_p^1$ to
$\matx{A}\matx{U}\vect{f}_p^1+\vect{b}$ will result in no change in the gram matrix at either layer 1 or layer 2; but
the underlying image may change a lot, because $\matx{A}$ can rescale features and features are shifted.

{\bf Symmetry group, between layer gram matrix, two layers:}
Assuming that the between layer map is affine, with matrix $\matx{M}$
representing the linear component.  With various assumptions about the
spatial statistics of layer 1 (supplementary materials), the symmetry
group is obtained by:  choose $\matx{U}$
orthonormal.  Then $(\matx{U})$ is a symmetry of the between layer
gram matrix (i.e the action of this element on layer 1 fixes the
between layer gram matrix).  In particular, mapping all feature vectors $\vect{f}_p^1$ to
$\matx{U}\vect{f}_p^1$ will result in no change in the gram matrix at either layer 1 or layer 2; we expect much less
change in the underlying image.

The between-layer gram matrix loss has very different symmetries to Gatys'
(within-layer) method.  In particular, the symmetry of Gatys' method rescales
features while shifting the mean (because in this case $\matx{A}$ can contain
strong rescalings with the right choice of $\vect{b}$).   For the
cross-layer loss, the symmetry cannot rescale, and cannot shift the
mean.   This implies that, if one constructs numerous style
transfers with the same style using Gatys' method, the variance of the layer features should be much greater than that
observed for the between layer method. 

Furthermore, increasing style weights in Gatys method should result in poor
style transfers, by exaggerating the effects of the symmetry.    Finally, our construction casts light on part Gupta \ea's
observation linking large trace to instability. A small trace in the gram matrix implies many small eigenvalues.  In
turn, rescaling directions with small eigenvalues will change little unless very large scales are applied; but these
correspond to very large shifts in the mean, which are difficult to obtain with current random start methods.  However,
a large trace in the gram matrix implies that there are many directions where a small shift in the mean will result in a
small -- but visible, because the eigenvalue is big -- rescale from $\matx{A}$ will lead to real changes, and so there
is greater instability. 

Note that this analysis is limited by the fact that strong scales and shifts will likely cause RELU's to change state,
by the fact that it takes no account of the content loss, and by the absence of spatial symmetries.
But the analysis exposes the fact that quite large changes in early layers will leave the style loss unchanged.
Since we expect that at least some large changes in early layers will produce very little change in content
layers (otherwise image classification applications would not work), the analysis is a fair rough guide. Experimental
observations are consistent with the symmetry theory  (figure~\ref{aggweight}; and
section~\ref{results}).

\section{Experimental Procedures\label{ExpPro}}

{\bf Comparison data:}  It is important to do comparisons on a wide range of styles and contents.  
We have built two datasets, using 50 style images (see supplementary) and the 200 content images from the BSDS500  test set. The {\em main set} is used for most experiments, and was obtained by:  
take 20 evenly spaced weight values in the range 50-2000; 
then, for each weight value, choose 15 style/content pairs uniformly and at random.  
The {\em aggressive weighting set} is used to investigate the effect of extreme weights 
on Gatys method and the ACG method.  This was built by taking 20 weight values sampled uniformly and 
at random between 2000-10000; then, for each weight value, 
choose 15 style/content pairs uniformly and at random.   
For each method, we then produced 300 style transfer images using each weight-style-content triplet.  
For UST~\cite{UST}, since the maximum weight is one, 
we linearly map \textit{main set} weights to the zero-one range. 
Our samples are sufficient to produce 
clear differences in standard error bars and evaluate different methods ~\cite{Forsyth2018}. 
{\bf Methods.}  We compare the following methods:
\noindent {\em Gatys} (\cite{gatys2016image} and described above); we use the implementation by Gatys~\cite{leongatys}.
\noindent {\em ACG:} We used a {\em pairwise descending} strategy with pre-trained VGG-16 model. We use R11, R21, R31, R41, and R51 for style loss, and R42 for the content loss for style transfer.\\
\noindent {\em Cross-layer, multiplicative (MCG):}  A natural alternative to combine style and content losses is to multiply them; we form 
\[
L^m(I_n) = L_c(I_n, I_c) *  L_s(I_n, I_s).
\]
It provides a dynamical weighting between content loss and style loss during optimization. Although this loss function seems unreasonable, but we find them to perform competitively on a wide range of our EC plots (see supplementary).

\noindent {\em Gatys, with histogram loss:}  as advocated by \cite{risser2017stable}, we attach a histogram loss to
Gatys method.  
\noindent {\em ACG, with histogram loss:}  We use the implementation of ~\cite{abhiskk} for histogram adjustment.\\
\noindent {\em Universal style transfer:}(from \cite{UST}, and it's Pytorch implementation~\cite{SunshineAtNoon} %\footnote{https://github.com/sunshineatnoon/PytorchWCT}
;\\
\noindent {\em Ensemble Q:}  for each weight-style-content triple, we choose the result that produces the best  $Q=E*C$
over all methods.\\
\noindent {\em Ensemble E:} for each weight-style-content triple, we choose the result that produces the best  $E$
over all methods.

\input{ec_plot.tex} %inputs all methods ec plot

\section{Results\label{results}}
%\input{samples_table.tex}
\input{ec_plot_control.tex} %Inputs control figure

% We find that:
% \begin{itemize}
% \item [1.] Cross-layer style transfer offers the highest expected E values for any C value.  The effect is statistically 
%   significant. \stang{And the qualitative comparison over several styles (see Fig.~\ref{}) validates that too.}
% \item [2.] E values obtained by \st{cross-layer style transfer} \stang{ACG} are comparable to the E value for the original style.
% \item [3.] For all methods, style has a very strong effect on the performance of the transfer. 
% \item [5.] Neither ensemble method outperforms cross-layer style transfer. 
% \item [6.] Aggressive weights cause Gatys' method to underperform significantly, likely an effect of the loss symmetry.
% \end{itemize}
% }

{\bf ACG is better.} Figure~\ref{ecxvg} shows an EC plot of layer 1 comparing style transfers using the cross-layer additive loss (ACG) with transfers using five other non-ensemble losses. Note that cross-layer loss achieves much higher average E for a given value of C.  In various parts of the AUC range, additive cross-layer loss is somewhat outperformed by the multiplicative version, but in the high AUC regime it is much better.  \
The difference to every other method ranges from one to four standard errors over the range, hence our 300 sample size is large enough~\cite{Forsyth2018}; the ACG method is clearly significantly better.

{\bf Control.}  Figure~\ref{control} shows an EC plot of two controls.  In the first, the resized style image is reported as a transfer; this results as expected in high values of E, but low values of C. There is significant variance in E, an effect due to resizing.  However, the range of E's shows the size of the effect of resizing on E; on average, E slightly greater than 4.  In the second, the content image is reported as a transfer; this results  suggest that obtaining high C values (though not uniformly; some images remain hard to segment)  may at the cost of getting low E values nearly to zero (look at the differences of E values for two controls). This shows investigating E is necessary for all methods. .  


{\bf Histogram losses.} improves Gatys' method (compare green/light green on figure~\ref{ecxvg}) only at extreme weights and low C. This may be an effect of the loss of symmetry, explained below. They also weaken the performance of cross-layer style transfer (compare red/pink on figure~\ref{ecxvg}, about three standard errors). 

{\bf Ensemble methods.} do not outperform cross-layer style transfer (see figure~\ref{ensmethl}).  As comparing the red and cyan curves suggests, choosing the result with the best E is essentially the same as using the cross-layer style transfer result. The yellow curve shows the ensemble Q method, which works somewhat better than cross-layer style transfer in low C regimes, and somewhat worse in high C regimes.  This suggests that more sophisticated ensemble methods might yield even better performance.

\input{ec_plot_ensemble.tex}
\input{ec_plot_aggressive.tex}

{\bf Aggressive weights.} One might speculate that Gatys' method underperforms because the weight regime is inappropriate. Figure~\ref{aggweight} compares Gatys' method to cross-layer style transfer. Notice that large weights cause serious trouble for Gatys' method.  We believe that this is because large weights on the style loss cause the symmetry in Gatys' loss to manifest itself, resulting in significant rescaling of features. In particular, Gatys' method cannot achieve high E values, because symmetry in the style loss produces feature distributions that are quite different from that desired. Furthermore, larger weights on the style loss {\em do not} produce better style transfers (large diamonds toward the bottom left of the plot).  Instead, by exaggerating the effect of the symmetry, large weights produce transfers that both have low E (poor transfer) {\em and} low C (do not respect original segmentation).  

\textbf{User Study.} We obtained preference data from Amazon Mechanical Turk (AMT) workers. We use 300 \textit{main set} image pairs from ACG and Gatys results, each image pair is annotated by 10 workers in total, separated in two groups. Detailed worker-task statistics are present in supplementary materials

Mechanical turk worker data is extremely noisy, and so difficult to plot helpfully.  We distinguish between 44 master workers (who are known to be quite reliable) and 49 generic workers (about whom we know nothing).  We analyze using a logistic regression of preference for cross-layer (resp. Gatys) against
E values for Gatys and for cross-layer and C values for Gatys and for cross-layer.  Our analysis supports the idea that E and C predict worker preferences, but that
there are other likely sources of preference, too (or that better measures of E and C would help).  We have two datasets: one using master workers only, and the other using
workers of any type. \\
 {\em Analysis, master workers:}  all four regression coefficients and the intercept are different from zero with strong statistical significance  (for each coefficient, $p<0.025$).  Weights produced by this regression are:   Intercept: 0.3409;    $E_{Gatys}= -0.1484;    E_{ACG}=  0.1015;C_{Gatys}=-3.4369;C_{ACG}=3.8982$ \\
{\em Conclusion, master workers:} master workers slightly prefer cross-layer images over Gatys images, whatever E and C;
worker preference can be predicted by looking at E and C; in particular, master workers tend to prefer transfers with higher E and C values (if cross-layer has higher E and C, it will tend to be preferred, etc).  The difference in weight size is roughly proportional to the relative scales (a factor of about 10), but one measure may be more important to workers than others.  The regression has relatively high deviance (and
cross-validated AUC of predictions by this regression is approximately 0.57, depending on regularization constant), meaning that other factors may explain preferences, too.  \\
{\em Analysis, generic workers:}  three of four regression coefficients are different from zero with strong statistical significance (for each coefficient, $p<0.02$, but the intercept could be zero).  Significant weights produced by this regression
are:$E_{ACG}=0.076, C_{Gatys}=-3.38, C_{ACG}=3.77$.  However, a cross-validated L1 regularized logistic regression obtains an average AUC on held-out predictions of about 0.85 (depending on regularization coefficient) using only the $E_{Gatys}$ and $C_{ACG}$ coefficients; this suggests that a preference for cross layer images is predicted by large values E and C on Gatys images. \\
{\em Conclusion, generic workers.} worker preference can be predicted by looking at C, and checking whether the $E_{ACG}$ is large; in particular, workers tend to prefer transfers with higher  C value (if cross-layer has higher  C, it will tend to be preferred, etc).  The effect of E is small.  The regression has relatively high deviance, and there is good evidence of odd behavior by workers (who prefer cross-layer images when E and C is larger for Gatys), meaning there may be workers who are not attending to the task.

{\bf The experimental effects of symmetry:}  Our experimental evidence suggests the symmetries manifest themselves in
practice. Gatys' method significantly underperforms the cross-layer method by producing a lower E statistic for any C
statistic.  This suggests that the variance implied by the larger symmetry group is actually appearing.  In particular,
Gatys' symmetry group allows rescaling of features and shifting of their mean, which will cause the feature distribution
of the transferred image to move away from the feature distribution of the style, causing the lower E statistic.
Furthermore, Gatys' method has a strong tendency to produce very poor transfers when offered aggressive weighting of the
style loss.  We believe this is likely because large rescaling effects are suppressed when the style loss has a smaller
weight, because large rescaling will eventually lead to a change in the content loss.  But when the style loss has a
high weight, then the changes in the content loss are of small significance, and very significant variations can appear in the
early layers, forcing down the E value; the C value goes down because little weight is placed on the content loss. This
effect does not appear for the cross layer method, because rescaling isn't possible for those symmetries.
\vspace{-2mm}
 \section{Conclusion}
 \vspace{-1mm}
 In this paper we present a novel approach to quantitatively evaluate style transfer methods. Our metric is built with two factors in mind, Effectiveness: a good style transfer should preserve the desired characteristics of original style; Coherence: style transfer method should respect to content's underlying decomposition of object segments. We apply various style transfer methods which are built either on with-in layer or cross-layer gram matrices, and we compared stylized images both quantitatively using the proposed EC plots, and qualitatively showing their results as well as conducting user study. Using this analytical framework, we confirm Gatys method is troubled by symmetry group, especially so when having aggressive style weights. The cross-layer method, which has very different symmetry group setting, is less compromised and thus achieves higher EC score. This conclusion is supported by master AMT workers' preference from user study.       

%   Cross-layer gram matrices has significant improvements over all other methods, and they are evident from both quantitative (EC plots) and qualitative (user study and figures) evaluations.
%   Histogram adjustment focuses largely on fixing effective style transferred and breaking symmetric groups, and fails to preserve boundaries. 
%   The cross-layer gram matrices breaks the symmetry as well as consistently preserves the 
%   coherence in the transferred style as demonstrated in figure ~\ref{aggweight}.  
%   The universal style has low samples in the lowest quantile as they stylize images directly on content image (whereas, all other methods are initiated from Gaussian noise) leading to better coherence but not necessarily effectiveness.

\clearpage

\section*{References}
\vspace{-5mm}
{\small
\bibliographystyle{splncs}
\bibliography{main1}
}

% \input{qualitative_old.tex}
\input{supplementary.tex}


\end{document}
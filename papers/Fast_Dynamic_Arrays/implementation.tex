\label{sec:implementation}
We have implemented a generic version of the tiered vector data structure such
that the number of tiers and the size of each tier can be specified at compile
time. To the best of our knowledge, all prior implementations of the tiered vector are limited to the considerably simpler 2-tier version.
Also, most of the performance optimizations applied in the 2-tier
implementations do not easily generalize.
We have implemented the following variants of tiered vectors:
%\addtolength\leftmargini{7.5em}
%\begin{enumerate}[itemsep=-1ex,partopsep=1ex,parsep=1ex, itemindent=1.5em,align=left]
\begin{itemize}

    %\item[\textit{Original}]
    \item \textit{Original}
        The data structure described in Theorem~\ref{thm:pointer}.

    %\item[\textit{Optimized Original}]
    \item \textit{Optimized Original}
        As described in Theorem~\ref{thm:pointer}
        but with the offset of a node $v$ located
        in the parent of $v$, adjacent in memory to the
        pointer to $v$. Leaves only consist of an array of elements
        (since their parent store their offset)
        and the root's offset is maintained separately
        as there is no parent to store it in.

    %\item[\textit{Implicit}]
    \item \textit{Implicit}
        This is the data structure described in Theorem~\ref{thm:implicit}
        where the tree is represented implicitly in an array
        storing the offsets and the elements of the leaves are
        located in a single array.

    %\item[\textit{Packed Implicit}]
    \item\textit{Packed Implicit}
        This is the data structure described in Theorem~\ref{thm:implicit}
        with the following optimization;
        The offsets stored in the offset array
        are packed together and stored in as little space as possible.
        The maximum offset of a node $v$ in the tree is
        $n^{\epsilon(\height(v)+1)}$ and the
        number of bits needed to store all the offsets is therefore $\sum_{i=0}^l
        n^{1-i\epsilon}  \log(n^{i\epsilon}) = \log(n) \sum_{i=0}^l i\epsilon
        n^{1-i\epsilon}  \approx \epsilon n^{1-\epsilon} \log(n)$ (for sufficiently large $n$).
        Thus the $n^{1-\epsilon}$ offsets can
        be stored in approximately $\epsilon n^{1-\epsilon}$ words giving a space reduction
        of a constant factor $\epsilon$.
        The smaller memory footprint could lead to better cache performance.

    %\item[\textit{Lazy}]
    \item \textit{Lazy}
        This is the data structure described in Theorem~\ref{thm:lazy}
        where the tree is represented implicitly in an array
        storing the offsets and every leaf stores a pointer to an array
        storing only the elements of that leaf.

    %\item[\textit{Packed Lazy}]
    \item \textit{Packed Lazy}
        This is the data structure described in Theorem~\ref{thm:lazy}
        with the following optimization;
        The offset and the pointer stored in a leaf
        is packed together and stored at the same memory location.
        On most modern 64-bit systems -- including the one we are testing on
        -- a memory pointer is only allowed to address 48 bits.
        This means we have room to pack a 16 bit offset
        in the same memory location as the elements pointer,
        which results in one less memory probe during an access operation.

    %\item[\textit{Non-Templated}]
    \item \textit{Non-Templated}
            The implementations described above all use C++ templating
            for recursive functions
            in order to let the compiler do significant code optimizations.
            This implementation is template free and serves as a baseline
            to compare the performance gains given by templating.

    \end{itemize}
In Section~\ref{sec:experiments} we compare the performance of
these implementations.

\subsection{C++ Templates}

We use templates to support storing different types of data in our tiered
vector similar to what most other general purpose data structures in C++ do.
This is a well-known technique which we will not describe in detail.

However, we have also used \textit{template recursion} which is basically like a normal recursion except that the recursion parameter must be a compile-time constant. This allows the compiler to unfold the recursion at compile-time eliminating all (recursive) function calls by inlining code, and allows better local code optimizations. In our case, we exploit that the height of a tiered vector is constant.

To show the rather simple code resulting from this approach (disregarding the template stuff itself), we have included a snippet of the internals of our access operation:

\begin{verbatim}

template <class T, class Layer>
struct helper {
        static T& get(size_t node, size_t idx) {
            idx = (idx + get_offset(node)) % Layer::capacity;
            auto child = get_child(node, idx / Layer::child::capacity);
            return helper<T, typename Layer::child>::get(child, idx);
        }
}

template <class T, size_t W>
struct helper<T, Layer<W, LayerEnd> > {
        static T& get(size_t node, size_t idx) {
            idx = (idx + get_offset(node)) % L::capacity;
            return get_elem(node, idx);
        }
}
\end{verbatim}

We also briefly show how to use the data structure. To specify the desired height of the tree, and the width of the nodes on each tier, we also use templating:

\begin{verbatim}
Tiered<int, Layer<8, Layer<16, Layer<32>>>> tiered;
\end{verbatim}

This will define a tiered vector containing integers with three tiers. The
height of the underlying tree is therefore 3 where the root has 8 children,
each of which has 16 children each of which contains 32 elements. We call this configuration 8-16-32.

In this implementation of tiered vectors we have decided to let
the number of children on each level be a fixed number as described above. This
imposes a maximum on the number of elements that can be inserted. However, in a
production ready implementation, it would be simple to make it grow-able by
maintaining a single growth factor that should be multiplied on the number
of children on each level. This can be combined with the templated solution
since the growing is only on the number of children and not the height of the
tree (per definition of tiered vectors the height is constant). This will
obviously increase the running time for operations when growing/shrinking is
required, but will only have minimal impact on all other operations (they will
be slightly slower because computations now must take the growth factor into
account).

In practice one could also, for many uses, simply pick the number of children
on each level sufficiently large to ensure the number of elements that will be
inserted is less than the maximum capacity. This would result in a memory
overhead when the tiered vector is almost empty, but by choosing the right
variant of tiered vectors and the right parameters this overhead would in many
cases be insignificant.

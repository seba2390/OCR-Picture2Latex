\section{Preliminaries}\label{sec:preliminaries}

% We consider \emph{principal-agent} problems in which the agent can be of different types, with each agent's type being characterized by her own action costs and action-outcome distributions.
%
In this section, we introduce all the elements we need in the rest of this work.
%
Section~\ref{sec:preliminaries_problem} formally defines the problem we study, Section~\ref{sec:preliminaries_contracts} describes its solutions (contracts), while Section~\ref{sec:preliminaries_apx} defines which kind of approximation guarantees we look for in contracts.


\subsection{The Bayesian Principal-Agent Problem}\label{sec:preliminaries_problem}


An instance of the \emph{Bayesian principal-agent problem} is characterized by a tuple $(\Theta,A,\Omega)$, where: $\Theta$ is a finite set of $\ell \coloneqq |\Theta|$ agent's types; $A$ is a finite set of $n \coloneqq |A|$ actions available to the agent; and $\Omega$ is a finite set of $m \coloneqq |\Omega|$ possible outcomes.~\footnote{For the simplicity of exposition, we assume that all the agent's types share the same action set. All the results continue to hold even if each agent's type $\theta \in \Theta$ has her own action set $A_\theta$.}
%
The agent's type is drawn according to a fixed probability distribution known to the principal. 
%
We let $\mu \in \Delta_{\Theta}$ be such a distribution, with $\mu_\theta$ denoting the probability of type $\theta \in \Theta$ being selected.~\footnote{Given a finite set $X$, we denote with $\Delta_X$ the set of all the probability distributions defined over $X$.}
%
For each type $\theta \in \Theta$, we introduce $F_{\theta, a} \in \Delta_\Omega$ to denote the probability distribution over outcomes $ \Omega$ when an agent of type $\theta$ selects action $a \in A$, while $c_{\theta, a} \in [0,1]$ is the agent's cost for that action.~\footnote{For the ease of presentation, we assume that rewards and costs are in $[0,1]$. Notice that all the results in this work can be easily generalized to the case of an arbitrary range of positive numbers, by applying a suitable normalization.}
%
We let $F_{\theta, a, \omega} $ be the probability that $F_{\theta, a}$ assigns to $\omega \in \Omega$, so that $\sum_{\omega \in \Omega} F_{\theta, a, \omega}  =1$.
%
Each outcome $\omega \in \Omega$ is characterized by a reward $r_\omega \in [0,1]$ for the principal.
%
As a result, when an agent of type $\theta \in \Theta$ selects an action $a \in A$, then the principal achieves an expected reward $R_{\theta,a}$, which is defined as $R_{\theta,a} \coloneqq \sum_{\omega \in \Omega} F_{\theta, a, \omega} \, r_\omega$.
%
As in classical (non-Bayesian) principal-agent problems, the principal's objective is to commit to a contract that maximizes her expected utility, as we formally describe in the following.


\subsection{Contracts}\label{sec:preliminaries_contracts}


A \emph{contract} is specified by payments from the principal to the agent, which are contingent on the actual outcome achieved with the agent's action.
%
We let $p_\omega \ge 0$ be the payment associated to outcome $\omega \in\Omega$.
%
The assumption that payments are non-negative (\emph{i.e.}, they can only be from the principal to the agent, and \emph{not} the other way around) is common in contract theory, where it is known as \emph{limited liability}~\citep{carroll2015robustness}.
%
When an agent of type $\theta \in \Theta$ selects an action $a \in A$, then the expected payment to the agent is $P_{\theta,a} \coloneqq \sum_{\omega \in \Omega} F_{\theta, a, \omega} \, p_\omega$, while her utility is $P_{\theta,a} - c_{\theta, a}$.
%
On the other hand, the principal's expected utility in that case is $R_{\theta,a} -P_{\theta,a}$.
%, resulting in an expected social welfare of $R_{\theta,a}- c_{\theta,a}$.


Given a contract, an agent of type $\theta \in \Theta$ selects an action such that:
%
\begin{enumerate}
	\item it is \emph{incentive compatible} (IC), \emph{i.e.}, it maximizes her expected utility among actions in $A$;
	%
	\item it is \emph{individually rational} (IR), \emph{i.e.}, it has non-negative expected utility (if there is no IR action, then the agent of type $\theta$ abstains from playing so as to maintain the \emph{status quo}).
\end{enumerate}


For the ease of presentation, we adopt the following w.l.o.g. common assumption~\citep{dutting2019simple}, which guarantees that IR is always enforced and, thus, it allows us to focus on IC only.
%
\begin{assumption}\label{ass:ir}
	There exists an action $a \in A$ such that $c_{\theta, a} = 0$ for all $\theta \in \Theta$.
\end{assumption} 
%
The assumption ensures that each agent's type has always an action providing her with a non-negative utility, thus ensuring IR of any IC action.


We say that a contract \emph{implements} an action $a^\ast \in A$ for an agent of type $\theta \in \Theta$ if the agent chooses that action.~\footnote{As it is common in the literature~\citep{dutting2020complexity}, we assume that the agent breaks ties in favor of the principal, \emph{i.e.}, whenever there is more than one IC action, she selects the one maximizing the principal's expected utility.}
%
Finally, given a contract, by letting $a^\ast(\theta) \in A$ be the action implemented by such contract for an agent of type $\theta \in \Theta$, we can define the overall principal's expected utility as $ \sum_{\theta \in \Theta} \mu_\theta \left( R_{\theta,a^\ast (\theta)} -P_{\theta,a^\ast (\theta)} \right)$, which accounts for type probabilities.
%
% Similarly, the overall expected welfare is $\sum_{\theta \in \Theta} \mu_\theta \left( R_{\theta,a^\ast (\theta)} -c_{\theta,a^\ast (\theta)} \right)$.
%
A special class of simple contracts that is commonly studied in the literature is that of \emph{linear contracts}, which give payments equal to some fixed fraction of the outcome rewards~\citep{dutting2019simple}.
%
Thus, these contracts are completely characterized by a single parameter $\alpha \in [0,1]$, with their payments being defined as $p_\omega = \alpha \, r_\omega$ for every outcome $\omega \in \Omega$.
%
We refer the reader to the work by~\citet{dutting2019simple} for more details on linear contracts in non-Bayesian principal-agent problems, including their geometric interpretation. 



\subsection{Approximation Guarantees of Contracts}\label{sec:preliminaries_apx}


The goal of the principal is to design an \emph{optimal} contract, which is one maximizing her overall expected utility.
%
In the following, we denote with $OPT$ the principal's overall expected utility in an optimal contract.
%
As we show later in this work, computing an optimal contract in our setting is computationally intractable (with the exception of some special cases).
%
Thus, we look at suboptimal contracts providing some guaranteed approximation of the principal's optimal utility $OPT$.


Given a contract, we say that its {multiplicative loss} with respect to an optimal contract is $\rho \geq 1$ if it provides the principal with an overall expected utility of $\frac{OPT}{\rho}$.
%
Equivalently, we sometimes say that the contract provides a multiplicative approximation $\rho$ of an optimal one.
%
% Given $\rho >0$, a contract provides a multiplicative, respectively additive, $\rho$-approximation of an optimal contract if it achieves overall principal expected utility at least $\rho \, OPT$, respectively $OPT - \rho$.


We also study approximation guarantees of contracts by considering both additive and multiplicative approximations at the same time.
%
Formally, given a multiplicative approximation $\rho \geq 1$, we say that a contract provides a $\left( \rho, g(\rho) \right)$\emph{-bi-approximation} of an optimal one if it results in an overall principal's expected utility greater than or equal to $\frac{OPT}{\rho} - g(\rho)$, where $g(\rho)$ denotes a (positive) additive loss depending on the parameter $\rho$.
%
Intuitively, bi-approximations allow us to analyze the performances of contracts by carefully managing the trade off between a desired (constant) multiplicative approximation factor and an additional (small) additive loss.
%
We are interested in $\left( \rho, g(\rho) \right)$-bi-approximations such that the term $g(\rho)$ quickly approaches zero as $\rho$ increases.
%
In particular, later in this work, we focus on bi-approximations whose $g(\rho)$ terms decrease exponentially in $\rho$, so that the additive loss becomes quickly negligible. 



% OLD PART ON INDEXES
%
%
%\paragraph{Additional Notation}
%%
%In the rest of this work, we sometimes index agent's types with $k \in [\ell]$, letting $\Theta \coloneqq \{ \theta_k \}_{k \in [\ell]}$.
%%
%We also do the same for outcomes and agent's actions, letting $\Omega \coloneqq \{ \omega_j \}_{j \in [m]}$ and $A \coloneqq \{  a_i \}_{i \in [n]}$.
%%
%In these cases, with a slight abuse of notation, we sometimes identify elements of sets with their indexes (\emph{e.g.}, we use $k \in [\ell]$ to denote type $\theta_k \in \Theta$).
%%
%As a result, for $i \in [n]$, $j \in [m]$, and $k \in [\ell]$, we use the symbols $r_j$, $F_{k,i}$, $c_{k,i}$, $F_{k,i,j}$, $p_j$, $R_{k,i}$, and $P_{k,i}$.


\section{Proofs Omitted from Section~\ref{sec:tractable}}

\propositionTypes*

\begin{proof}
	%
	The algorithm works by solving Problem~\eqref{lp:min_pay} for every possible tuple $\left( a_\theta \right)_{\theta \in \Theta}$ in the set $\bigtimes_{\theta \in \Theta} A$.
	%
	Then, it picks the tuple (and the corresponding contract obtained by solving Problem~\eqref{lp:min_pay} for it) that results in the highest optimal value for Problem~\eqref{lp:min_pay}.
	%
	We prove the correctness of the algorithm by showing that the returned contract, identified by a vector $ p^\star \in \mathbb{R}^m$, must provide the principal with an expected utility at least as large as that of any other contract.
	%
	Let us take an arbitrary contract identified by vector $p \in \mathbb{R}^m$, and let $\left( a_\theta \right)_{\theta \in \Theta}$ be a tuple such that, for every $\theta \in \Theta$, the contract implements action $a_\theta$ for an agent of type $\theta$.
	%
	Then, by solving Problem~\eqref{lp:min_pay} for $\left( a_\theta \right)_{\theta \in \Theta}$, the algorithm finds a contract incentivizing the same tuple of agent actions and requiring the principal an expected payment smaller than or equal to that of $p$.
	%
	Notice that, since the contract found by solving the LP in Problem~\eqref{lp:min_pay} may lie on the boundary of its feasible region, there could be other tuples of agent actions that are incentivized by the contract.
	%
	However, by using the assumption that the agent always breaks ties in favor of the principal, we can conclude that the tuple of agent actions that is actually played must provide the principal with an expected reward greater than or equal to that obtained for $\left( a_\theta \right)_{\theta \in \Theta}$.
	%
	Thus, we can conclude that $p^\star$ provides the principal with an expected revenue greater than or equal to that of $p$, while requiring a smaller or equal payment, showing the correctness of the algorithm.
	%
	Finally, notice that the algorithm solves $n^\ell$ different LPs, one for each tuple in $\bigtimes_{\theta \in \Theta} A$.
	%
	The LPs have $m$ variables and $\ell \cdot n$ constraints, and, thus, they can be solved in time polynomial in $n$, $m$, and $\ell$.
	%
\end{proof}



\theoremOutcomes*

\begin{proof}
	The proof involves two steps.
	%
	\paragraph{First Step} We show that, for any contract defined by a vector $p \in P$, there exists another contract identified by a vector $p^\star \in P^\star$ providing the principal with an expected utility greater than or equal to that obtained for $p$.
	%
	Let $\textbf{a}=(a_\theta)_{\theta \in \Theta} \in \bigtimes_{\theta \in \Theta} A$ be a tuple of agent actions such that the contract $p$ implements action $a_\theta$ for every type $\theta \in \Theta$.
	%
	Let us define $p^\star \in P$ as the optimal solution of the LP in Problem~\eqref{lp:min_pay} for the tuple $(a_\theta)_{\theta \in \Theta}$.
	%
	Noticing that the objective of Problem~\eqref{lp:min_pay} is to minimize a linear function over the polytope $P(\textbf{a})$, we can assume w.l.o.g. that the vector $p^\star$ is a vertex of the polytope, \emph{i.e.}, that $p^\star \in \mathcal{V} (P(\textbf{a}))$.
	%
	Notice that, since $p^\star$ lies on a vertex of the feasible region of the LP, then there might be other tuples of agent actions that are incentivized by the contract identified by $p^\star$.
	%
	However, given the assumption that the agent breaks ties in favor of the principal, these would provide the principal with an expected reward greater than or equal to that obtained for $(a_\theta)_{\theta \in \Theta}$.
	%
	Thus, we can conclude that $p^\star$ has expected reward greater than or equal to that of $p$, while requiring a smaller or equal payment, proving the first step.
	
	\paragraph{Second Step}
	%
	We show that the size of $P^\star$ can be bounded by a polynomial in $n^m$ and $\ell^m$.
	%
	For any tuple of agent actions $\textbf{a}=(a_\theta)_{\theta \in \Theta} \in \bigtimes_{\theta \in \Theta} A$, the set $P(\textbf{a})$ is an $m$-dimensional polytope, and, thus, each vertex in $\mathcal{V}(P(\textbf{a}))$ is determined by the intersection of exactly $m$ hyperplanes among those defining it.
	%
	Each polytopes $P(\textbf{a})$ is characterized by a subset of the hyperplanes defining the sets $P(a,\theta)$ for $a \in A$ and $\theta \in \Theta$.
	%
	After removing duplicates, we can conclude that, for each $\theta \in \Theta$, there are at most $\binom{n}{2}$ hyperplanes resulting from Constraints~\ref{eq:hyperplane}, which are those defining the boundaries between the sets $P(a,\theta)$ and $P(a',\theta)$, for any pair of actions $a, a' \in A$ such that $a' \neq a$.
	%
	Moreover, there are $m$ hyperplanes resulting from non-negativity constraints, namely $p_\omega \geq 0$ for every $\omega \in \Omega$.
	%
	As a result, each polytope $P(\textbf{a})$ is defined by a subset of the same set of at most $\ell n^2 + m$ hyperplanes.
	%
	Hence, each vertex in $P^\star$ is obtained as the intersection of exactly $m$ of these at most $\ell n^2 + m$ hyperplanes and we can conclude that there are at most $\binom{\ell n^2+m}{m}$ vertices in $P^\star$.
	%
	%The same reasoning can be applied for any tuple of agent actions $\textbf{a}=(a_\theta)_{\theta \in \Theta} \in \bigtimes_{\theta \in \Theta} A$, proving that the size of $P^\star$ is $O\left( n^\ell \binom{\ell n^2+m}{m} \right)$.
	In conclusion, to find an optimal contract it is sufficient that the algorithm enumerates all the vertices in $P^\star$, which requires time polynomial in $n^m$ and $\ell^m$.
	%
\end{proof}
\section{Linear versus Optimal Contracts: The Bayesian Setting}\label{sec:linear}

We start by analyzing the performances of linear contracts with respect to optimal (possibly non-linear) ones.
%
Section~\ref{sec:linear_vs_optimal} studies how linear contracts perform in terms of multiplicative loss, while Section~\ref{sec:linear_bi_apx} provides our main results on the bi-approximation guarantees of linear contracts.



\subsection{Multiplicative Approximations}\label{sec:linear_vs_optimal}


We prove that, in Bayesian principal-agent problems, linear contracts do \emph{not} perform well when compared to optimal ones in terms of their multiplicative loss.
%  for a growing number of agent's types.
%
Formally, in the following Theorem~\ref{thm:linear_lower_bound}, we construct particular instances showing that, in the worst case, the multiplicative loss of any linear contract with respect to an optimal one increases at least linearly in the number of agent's types $\ell$.
% 
% we show that they cannot provide more than a fraction $\frac{2}{\ell}$ of the principal utility in an optimal (possibly non-linear) contract, where $\ell$ is the number of agent's types.
%
We remark that, in the instances used to prove the theorem, the agent has only two actions available (notice that $A = \{ a_1, a_2 \}$ in the proof).
%
This strengthens already-known results.
%
Indeed,~\citet{dutting2019simple} prove that, in the special case of non-Bayesian principal-agent problems, linear contracts are arbitrarily worse than optimal ones for a growing number of agent's actions, as their worst-case multiplicative loss is equal to $n$.
%
Our result shows that, in Bayesian settings with many agent's types, the multiplicative loss of linear contracts can be arbitrarily bad even in the basic case in which the agent has only two actions. 
%
%\textcolor{purple}{Io qui formulerei diversamente, dicendo che il vostro risultato rafforza quanto noto in letteratura, mostrando che persino quando l'agente ha due sole azioni allora i contratti lineari sono inefficienti. mentre in letteratura il risultato era noto per $n>2$. Il dubbio poi e' se nel modello di Dutting et al. il numero di azioni e' libero, ma immagino di si, altrimenti non ci sarebbe niente altro che varia. Propongo quanto segue:
%\begin{itemize}
%\item Noi raffiniamo il risultato noto in letteratura che mostra che in casi non Bayesiani i contratti lineari hanno un loss moltiplicativo lineare nel numero $n$ di azioni in caso peggiore;
%\item Qui mostriamo che nel caso Bayesiano, persino fissando a 2 le azioni, i contratti lineari hanno loss moltiplicativo lineare nel numero di tipi nel caso peggiore.
%\end{itemize}}
%%
%Notice that, in the instances used to prove the theorem, the agent has only two actions available.
%%
%Indeed, in general settings with an arbitrary number $n > 2$ of agent's actions, it is already known that linear contracts are \emph{not} satisfactory, as their worst-case multiplicative loss with respect to an optimal contract is $n$ even in the basic non-Bayesian model of~\citet{dutting2019simple}. \textcolor{purple}{Potrebbe essere carino dire che le due azioni sono $a_1,a_2$.}



\begin{theorem}\label{thm:linear_lower_bound}
	In Bayesian principal-agent problems, the worst-case multiplicative loss of any linear contract with respect to an optimal one is $\Omega(\ell)$, where $\ell$ is the number of agent's types.
	%
	% For every $\ell \in \mathbb{N}$, there exists a Bayesian principal-agent setting with $\ell$ agent's types such that the multiplicative loss of any linear contract with respect to an optimal one is at least $\frac{\ell}{2}$.
	%
	%any linear contract provides a multiplicative $O \left( \frac{1}{\ell} \right)$-approximation of an optimal contract.
\end{theorem}

\begin{proof}
	For any $\ell \in \mathbb{N}$, let us consider a principal-agent setting $(\Theta, A, \Omega)$ with outcome set $\Omega = \{ \omega_j \}_{j \in [m]}$, where we let $m = \ell +1$.
	%
	We define $r_{\omega_j} = 2^{-j}$ for $\omega_j \in \Omega \setminus \{ \omega_m \}$, while $r_{\omega_m} = 0$.
	%
	The set of agent's types is $\Theta = \{ \theta_k \}_{k \in [\ell]}$, with $\mu \in \Delta_\Theta$ being defined so that $\mu_{\theta_k} = \frac{1}{N} 2^{2(k - \ell)}$ for all $\theta_k \in \Theta$, where $N \coloneqq \sum_{k \in [\ell]} 2^{2(k - \ell)}$ is a suitably defined normalization constant.
	%
	Each agent of type $\theta_k \in \Theta$ has two actions available, namely $A = \{ a_1, a_2 \}$, with probability distributions defined so that $F_{\theta_k,a_1,\omega_k} = 1$ and $F_{\theta_k,a_2,\omega_m} = 1$.
	%
	Intuitively, action $a_1$ of type $\theta_k$ deterministically results in outcome $\omega_k$ (with reward $r_{\omega_k} = 2^{-k}$), while action $a_2$ leads to outcome $r_{\omega_m}$ no matter the agent's type (with reward $r_{\omega_m} = 0$).
	%
	Moreover, the action costs for type $\theta_k \in \Theta$ are $c_{\theta_k,a_1} = 2^{-k} \left(  1- 2^{-k}  \right)$ and $c_{\theta_k,a_2}= 0$.
	%
	The optimal (non-linear) contract sets the payments as follows: $p_{\omega_j} = 2^{-j} \left( 1-2^{-j} \right)$ for all $\omega_j \in \Omega \setminus \{ \omega_m \}$, while $p_{\omega_m} = 0$.
	%
	This contract implements action $a_1$ for each agent's type $\theta_k \in \Theta$, as her utility by playing $a_1$ is $P_{\theta_k, a_1} - c_{\theta_k, a_1} = p_{\omega_k} - c_{\theta_k,a_1} = 0$ and $r_{\omega_k} > 0$, while the utility of $a_2$ is zero and $r_{\omega_m} = 0$ (as previously stated, we assume that ties are broken in favor of the principal).
	%
	As a result, the contract provides the principal with an overall expected utility of:
	\[
		\sum_{\theta_k \in \Theta} \mu_{\theta_k} \left(  R_{\theta_k, a_1} - P_{\theta_k, a_1}  \right) = \frac{1}{N}\sum_{\theta_k \in \Theta} 2^{2(k - \ell)} \left[  2^{-k} - 2^{-k} \left( 1-2^{-k} \right)  \right] =\frac{1}{N}\sum_{\theta_k \in \Theta}   2^{-2\ell}= \frac{\ell \,  2^{-2\ell}}{N} .
	\]
	%
	Now, let us consider a linear contract with parameter $\alpha \in [0,1]$.
	%
	For an agent of type $\theta_k \in \Theta$, the contract implements action $a_1$ only if $P_{\theta_k, a_1} = p_{\omega_k} = \alpha\, r_{\omega_k} = \alpha\, 2^{-k} \geq  2^{-k} \left(  1- 2^{-k}  \right) = c_{\theta_k,a_1}$.
	%
	It is easy to check that an agent of type $\theta_k$ is incentivized to play $a_1$ if and only if $k \leq - \log_2 (1 -\alpha)$.
	%
	Let $k' \coloneqq \left\lfloor - \log_2 (1 -\alpha) \right\rfloor$ be the highest index among agent's types that are incentivized to play action $a_1$.
	%Let $k' \in [\ell]$ be the highest index among agent's types that are incentivized to play action $a_1$; it is easy to check that $k'$ is the highest index such that $k' \leq - \log_2 (1 -\alpha)$.
	%
	%Thus, for all the agent's types $k \in [\ell] : k \leq k'$, the contract implements action $a_1$.
	%
	%\textcolor{red}{Qui non capisco. Stai dimostrado quello che hai appena detto. Lo darei per scontato.}
	% Moreover, for every $k \in [\ell] : k \leq k'$, it holds that $\alpha \geq 1 - 2^{-k} \geq 1 - 2^{-k'}$   \textcolor{red}{penso sia $\alpha \geq 1 - 2^{-k'} \geq 1 - 2^{-k}$}, where the first inequality follows from the fact that the contract implements $a_1$ for type $k$, while the second one follows from $k \leq k'$.
	%
	Then, the overall principal's expected utility is:
	%
	\begin{align*}
		\sum_{\theta_k \in \Theta: k \leq k'} \mu_{\theta_k} (1 -\alpha) \, R_{\theta_k, a_1} & =\frac{1}{N} \sum_{\theta_k \in \Theta: k \leq k'}2^{2(k - \ell)} (1 -\alpha) \, 2^{-k} \leq \\
		& \leq \frac{1}{N} \sum_{\theta_k \in \Theta: k \leq k'}2^{2(k - \ell)} \, 2^{-k'} \, 2^{-k} = \frac{1}{N} 2^{-2 \ell} \, 2^{-k'} \sum_{\theta_k \in \Theta: k \leq k'} 2^{k} \leq \\
		 & \leq \frac{1}{N} 2^{-2 \ell} \,2^{-k'} \,2^{k' +1} = \frac{2 \, 2^{-2 \ell}}{N},
	\end{align*}
	%
	where the first inequality follows from $1 -\alpha \leq 1 - 2^{-k} \leq 1 - 2^{-k'}$ (since the contract implements $a_1$ for type $\theta_k$ and it holds $k \leq k'$). 
	%
	This concludes the proof.
\end{proof}




We remark that the approximation result in Theorem~\ref{thm:linear_lower_bound} is tight in many cases.
%
% \textcolor{purple}{questo paragrafo non e' molto chiaro, in particolar modo la questione del tight. Sarebbe bene discuterlo.}
%
This is readily seen by leveraging the approximation results of~\citet{dutting2019simple}.
%
Let us recall that~\citet{dutting2019simple} show that, in non-Bayesian principal-agent problems, linear contracts provide a constant multiplicative approximation of optimal ones, except in settings where the following three conditions hold \emph{simultaneously}: there are many agent's actions, there is a big spread of expected rewards, and there is a big spread of costs.
%
Thus, whenever at least one of the conditions above does \emph{not} hold in a Bayesian principal-agent setting, we have a simple polynomial-time algorithm that returns a linear contract with multiplicative loss $O(\ell)$ (matching the lower bound in Theorem~\ref{thm:linear_lower_bound}).
%
This algorithm computes an approximate linear contract of~\citet{dutting2019simple} for each agent's type {singularly} and returns the one providing the highest overall principal's expected utility (after weighting them by the corresponding type probabilities).~\footnote{For each agent's type $\theta \in \Theta$, the algorithm computes the linear contract of Theorem~5.1~in~\citep{dutting2019simple} if the number of actions is small (that of Theorem~5.5, respectively Theorem~5.7,~in~\citep{dutting2019simple} if the spread of rewards, respectively costs, is small).}
%
% \textcolor{purple}{riformulerei dicendo che l'algoritmo di Dutting et al assicura una approssimazione costante quando almeno una delle assunzioni sopra cade e questo permette di avere una approssimazione $O(l)$ nel nostro caso perche' basta prendere il tipo con probabilita' massima. Non e' invece chiaro cosa si puo' fare quando le tre assunzioni sopra valgono insieme.}
%
Let us also notice that, even in pathological cases in which all the conditions above hold simultaneously, the result in Theorem~\ref{thm:linear_lower_bound} is still tight in the number of agent's types $\ell$, though the multiplicative loss of linear contracts could be arbitrarily bad in one or more of the other parameters (number of agent's actions, spread of rewards, and spread of costs).
%
{For instance, \citet{guruganesh2020contracts} show that the worst-case loss is linear in the number of actions.}



\subsection{Bi-Approximation Guarantees}\label{sec:linear_bi_apx}

% Theorem~\ref{thm:linear_lower_bound} shows that, in Bayesian settings, linear contracts are very bad in terms of purely-multiplicative approximations.
%
The instances exploited in the proof of Theorem~\ref{thm:linear_lower_bound} suggest that the negative result holds only when the rewards (and, thus, the principal's expected utilities) are very small.
%
In particular, the rewards decrease exponentially in the approximation factor (the number of agent's types).
%
This suggests that linear contracts could provide nice approximation guarantees when looking at bi-approximations. 

Next, we prove that linear contracts achieve good bi-approximations of the optimal principal's expected utility: for any constant $\rho$, 
%tolto il \geq 1. fa confusione con il thm che ha >2
they provide a multiplicative approximation $\rho$ at the expense of an exponentially small additive loss $2^{-\Omega \left(  \rho \right) }$.
%
% Formally, Theorem~\ref{thm:mult_add_bayes} shows that, given a Bayesian principal-agent setting, there is a linear contract that provides a $\left( \rho, 2^{- d \rho + e } \right)$-bi-approximation of an optimal one, for two constants $d \in \mathbb{N}$ and $e \in \mathbb{Z}$ that do not depend on the problem instance.
%
Let us remark that the additive loss decreases exponentially as $\rho$ increases, becoming quickly negligible.
%
For instance, given a constant multiplicative approximation factor $\rho = 50$, the resulting additive loss is $2^{-24}$, while Theorem~\ref{thm:linear_lower_bound} shows that linear contracts provide a (non-constant) approximation decreasing linearly in the number of agent's types $\ell$ if we only consider multiplicative factors.
%
%
%
%\textcolor{purple}{mi pare di capire che approssimazioni additive sono poco studiate in letteratura, magari dire che nonostante siano poco esplorate finora mostriamo che e' interessante considerarle. *** Comprendere esattamente come vanno le approssimazioni, in particolare $2^{-\Omega \left( 1/ \rho \right) }$ e' tutto tranne intuitivo. E' pensabile una frase che dica: per esempio, quando $\rho$ va a 0, quando invece va a 1 succede questo, argomentando cosa succede all'approsimazione additiva e a quella moltiplicativa. E' vero quello che segue: $\frac{1}{2^{\Omega(1/\rho)}} = O(\frac{1}{2^{1/\rho}})$? Cioe' che l'approssimazione additiva e' boundata superiormente da $\frac{1}{2^{1/\rho}}$. Cosi' mi sembra molto piu' intuitiva.}


We start by proving the result in the easier non-Bayesian setting, in which $\ell = 1$.~\footnote{When we refer to a non-Bayesian principal-agent instance, we adopt the same notational conventions, dropping any reference to the types.}


First, we introduce the following observation that is useful to prove the following Theorem~\ref{thm:mult_add_no_bayes}, as well as other results in the rest of this work.
%
% Letting $OPT$ be the principal expected utility in an optimal contract, we show the following:

\begin{observation}\label{obs:opt_bound}
	Given a non-Bayesian principal-agent instance, it holds $OPT \leq \max_{a \in A} \left\{  R_a - c_a \right\}$.
\end{observation}
\begin{proof}
	It is sufficient to notice that, by the IR property, the agent's expected payment covers the cost $c_a$ of the implemented action $a\in A$, and, thus, the principal's expected utility is always upper-bounded by $R_a - c_a$.
\end{proof}


\begin{theorem}\label{thm:mult_add_no_bayes}
	Given a non-Bayesian principal-agent instance, linear contracts provide a $\big( \rho, 2^{-\Omega \left( \rho \right)} \big)$-bi-approximation of an optimal contract.
	%
	Moreover, for any $\rho \geq 2$, there is a linear contract $\alpha$ that provides a $\left( \rho, 2^{- d \rho + e } \right)$-bi-approximation of an optimal contract for two constants $d \in \mathbb{R}^+$ and $e \in \mathbb{R}$, where $\alpha = 1 - 2^{-i}$ for some $i = 1, \ldots, \left\lfloor \rho /2 \right\rfloor$.~\footnote{A bi-approximation as in Theorems~\ref{thm:mult_add_no_bayes}~and~\ref{thm:mult_add_bayes} for the cases in which $\rho \in [1,2)$ can be easily obtained by using the linear contract $\alpha=\frac{1}{2}$, which always provides an additive loss of $\frac{1}{2}$.}
\end{theorem}

\begin{proof}
	For the ease of presentation, given $\rho \ge 2$, we let $I \coloneqq \lfloor \rho / 2  \rfloor $, while $[I]$ is the set of integers from $1$ to $\lfloor \rho / 2  \rfloor$.
	%
	Moreover, for each $i \in [I]$, we define $\alpha_i \coloneqq 1 - 2^{-i} $, while, letting $A = \{ a_i \}_{i \in [n]}$, we assume w.l.o.g. that the first $I$ actions of $A$ are those implemented by the linear contracts with parameters $\alpha_i$, so that $a_i \in A $ denotes the agent's action implemented by $\alpha_i$.
	%
	For $i \in [I]: i > 1$, we also let $\alpha_{i-1, i} \in \left[  \alpha_{i-1}, \alpha_i \right]$ be the parameter identifying a linear contract such that the agent is indifferent between actions $a_{i-1}$ and $a_i$.
	%
	Whenever $a_{i-1}$ and $a_i$ are the same action, then we can set w.l.o.g. $\alpha_{i-1, i} \coloneqq \alpha_i$.
	%
	Instead, if $a_{i-1}$ and $a_i$ are different actions, it is easy to check that it must be $\alpha_{i-1, i} \coloneqq \frac{c_{a_{i-1}} - c_{a_i}}{R_{a_{i-1}} - R_{a_i}}$ (it cannot be the case that $R_{a_{i-1}} = R_{a_i}$, otherwise one between $a_{i-1}$ and $a_i$ would be weakly dominated by the other, and, thus, never implemented by a contract that breaks ties deterministically in favor of the principal).
	%
	Finally, for convenience, we let $\alpha_{0,1} \coloneqq 0$.
	%
	In the following, we show that at least one linear contract among those with parameters $\alpha_i$ for $i \in [I]$ provides the principal with expected utility at least $\frac{OPT}{\rho} - 2^{-\frac{\rho}{2}+1 }$.
	
	In the rest of the proof, we need the following observation due to~\citet{dutting2019simple}.
	%
	\begin{observation}[Essentially Observation~6 in~\citep{dutting2019simple}]\label{obs:delta_welfare}
		Given $i \in [I] : i > 1$, it holds:
		%
		\[
			\left(  R_{a_i} - c_{a_i} \right) - \left(  R_{a_{i-1}} - c_{a_{i-1}} \right) \leq 	\left(  1 - \alpha_{i-1, i} \right) R_{a_i}.
		\]
	\end{observation}
	%
	Observation~\ref{obs:delta_welfare} allows us to prove the following lemma.
	%
	\begin{lemma}\label{lem:telescoping}
		For every  $i' \in [I]$, it holds that:
		%
		\[
			R_{a_{i'}} - c_{a_{i'}} \leq \sum_{i \in [I]: i \leq i'} \left(  1  -\alpha_{i-1,i} \right) R_{a_i} .
		\]
	\end{lemma}
	%
	\begin{proof}
		The proof is by induction.
		%
		For the base case $i' = 1$, we have $\left( 1 - \alpha_{0,1} \right) R_{a_1} = R_{a_1} \geq R_{a_1} - c_{a_1}$.
		%
		Next, for every $i' \in [I]: i'\geq 2$, let us assume by induction that $R_{a_{i' - 1}} - c_{a_{i' -1}} \leq \sum_{i \in [I]: i \leq i' -1} \left(  1  -\alpha_{i-1,i} \right) R_{a_i} $.
		%
		Then, by using Observation~\ref{obs:delta_welfare} and the inductive hypothesis, we get:
		%
		\begin{align*}
			R_{a_{i'}} - c_{a_{i'}} & = R_{a_{i'}} - c_{a_{i'}} - \left(  R_{a_{i' -1}} - c_{a_{i' -1}} \right) + \left(  R_{a_{i' -1}} - c_{a_{i' -1}} \right) \leq \\
			& \leq \left(  1  -\alpha_{i'-1,i'} \right) R_{a_{i'}} + \sum_{i \in [I]: i \leq i' -1} \left(  1  -\alpha_{i-1,i} \right) R_{a_i} = \\
			& = \sum_{i \in [I]: i \leq i'} \left(  1  -\alpha_{i-1,i} \right) R_{a_i}.
		\end{align*}
		%
		This concludes the proof of the lemma.
	\end{proof}
	
	Now, we can prove the following:
	%
	\[
		\max_{i \in [I]} \left(  1  - \alpha_{i}  \right) R_{a_i} \geq \frac{1}{2} \max_{i \in [I]} \left(  1  - \alpha_{i-1, i}  \right) R_{a_i} \geq \frac{1}{2 I} \sum_{i \in [I]} \left( 1 - \alpha_{i-1, i}  \right) R_{a_i} \geq \frac{R_{a_I} - c_{a_I}}{2 I},
	\]
	%
	where the first inequality holds since $1 - \alpha_{i} = 2^{-i} = \frac{1}{2} 2^{- \left(  i -1 \right)} = \frac{1}{2} \left( 1 - \alpha_{i - 1} \right) \geq \frac{1}{2} \left( 1 - \alpha_{i - 1, i} \right) $, the second one holds by definition of $\max$, while the last one by Lemma~\ref{lem:telescoping}.
	%
	Finally, by letting $a^\ast \in \argmax_{a \in A} \left\{  R_a - c_a \right\}$, we have:
	\[
		R_{a_I} - c_{a_I} \geq \alpha_{I}  R_{a_I} - c_{a_I} \geq \alpha_{I}  R_{a^\star} - c_{a^\star} \geq \left( 1 - 2^{-I} \right) R_{a^\star} - c_{a^\star} \geq R_{a^\star} - c_{a^\star} - 2^{-I} \geq OPT - 2^{-I},
	\]
	%
	where the second inequality holds since the linear contract with parameter $\alpha_{I}$ implements action $a_I$, the second-last inequality follows from $R_{a^\star} \in [0,1]$, while the last one holds by Observation~\ref{obs:opt_bound}. 
	%\textcolor{purple}{non mi suona l'uso di last nella frase prima e anche la declinazione del verbo follows}
	%
	In conclusion,
	\[
		\max_{i \in [I]} \left(  1  - \alpha_{i} \right) R_{a_i} \geq \frac{R_{a_I} - c_{a_I}}{2 I} \geq \frac{OPT - 2^{-I}}{2 I} \geq   \frac{OPT}{\rho} - 2^{-\frac{\rho}{2} +1 }.
	\]
	%
	This concludes the proof of the theorem. 
	%\textcolor{purple}{tra teorema, osservazione, e lemma si fa un po' di casino. Forse potremmo scrivere, quando si chiude una proof, This concludes the proof of the observation, lemma, theorem}
	%
\end{proof}


We can exploit a reasoning similar to that used in the proof of Theorem~\ref{thm:mult_add_no_bayes} to prove our main result for the general Bayesian setting.

\begin{theorem}\label{thm:mult_add_bayes}
	Given a Bayesian principal-agent instance, linear contracts provide a $\big( \rho, 2^{-\Omega \left( \rho \right)} \big)$-bi-approximation of an optimal contract.
	Moreover, for any $\rho \geq 2$, there is a linear contract $\alpha$ that provides a $\left( \rho, 2^{- d \rho + e } \right)$-bi-approximation of an optimal contract for two constants $d \in \mathbb{R}^+$ and $e \in \mathbb{R}$, where $\alpha = 1 - 2^{-i}$ for some $i = 1, \ldots, \left\lfloor \rho /2 \right\rfloor$.
\end{theorem}

\begin{proof}
	The proof follows the lines of that of Theorem~\ref{thm:mult_add_no_bayes}, where we let $I \coloneqq \lfloor \rho / 2  \rfloor$ and $\alpha_i \coloneqq 1 - 2 ^{-i}$ for $i \in [I]$.
	%
	In this case, for every agent's type $\theta \in \Theta$, with a slight abuse of notation we define $a_i^\ast(\theta) \in A$ as the action implemented by the linear contract with parameter $\alpha_i$ for an agent of type $\theta$.
	%
	Moreover, for every $i \in [I]$, we introduce the parameters $\alpha_{a_{i-1}^\ast(\theta) , a_i^\ast(\theta) }$ (with $\alpha_{a_{0}^\ast(\theta) , a_1^\ast(\theta) } \coloneqq 0$), which are the analogous of the parameters $\alpha_{i - 1, i}$ in the proof of Theorem~\ref{thm:mult_add_no_bayes}, for actions $a_{i-1}^\ast(\theta)$ and $a_{i}^\ast(\theta)$.
	%
	Then, following steps similar to those in Theorem~\ref{thm:mult_add_no_bayes} (including an analogous of Lemma~\ref{lem:telescoping}), we can prove the following:
	%
	\begin{align*}
		\max_{i \in [I]} \sum_{\theta \in \Theta} \mu_{\theta} \left( 1 - \alpha_i \right) R_{\theta, a_i^\ast(\theta)} & \geq  \frac{1}{2} \max_{i \in [I]} \sum_{\theta \in \Theta} \mu_{\theta} \left( 1 - \alpha_{a_{i-1}^\ast(\theta) , a_i^\ast(\theta) } \right) R_{\theta, a_i^\ast(\theta)} \geq \\
		& \geq  \frac{1}{2 I} \sum_{\theta \in \Theta} \mu_{\theta} \sum_{i \in [I]} \left( 1 - \alpha_{a_{i-1}^\ast(\theta) , a_i^\ast(\theta) } \right) R_{\theta, a_i^\ast(\theta)} \geq \\
		& \geq  \frac{1}{2 I} \sum_{\theta \in \Theta} \mu_{\theta} \sum_{i \in [I]} \left( R_{\theta, a_I^\ast(\theta)}  - c_{\theta,a_I^\ast(\theta) } \right) \geq \\
		& \geq 	\frac{1}{2 I} \sum_{\theta \in \Theta} \mu_{\theta} \left(   OPT_{\theta} - 2^{-I} \right) \geq \\
		& \geq \frac{OPT}{\rho} - 2^{-\frac{\rho}{2}+ 1 },
	\end{align*}
	%
	where, in the second-last step, $OPT_{\theta}$ denotes the principal expected utility in an optimal contract for the non-Bayesian setting in which only type $\theta \in \Theta$ is present.
	%
\end{proof}

The following theorem shows that the bounds provided in Theorems~\ref{thm:mult_add_no_bayes}~and~\ref{thm:mult_add_bayes} are tight.
%
%Formally, Theorem~\ref{thm:mult_add_imp} shows that there is no linear contract that provides a $\left(  \rho ,2^{- d \rho + e} \right)$-bi-approximation of an optimal one, for two constants $d \in \mathbb{N}$ and $e \in \mathbb{Z}$ that do not depend on the problem instance.

\begin{theorem}\label{thm:mult_add_imp}
	No linear contract provides a $\big(  \rho ,2^{-O \left( \rho \right)} \big)$-approximation of an optimal contract, even in non-Bayesian principal-agent problems. Equivalently, for any $\rho \ge 1$, no linear contract provides a $\left(  \rho ,2^{- d \rho + e} \right)$-bi-approximation of an optimal one, for two constants $d \in \mathbb{N}$ and $e \in \mathbb{Z}$.
	%
	% \textcolor{purple}{come la scrivo rispetto a $\frac{1}{2^{1/\rho}}$? io ho dei dubbi che sia corretto usare $2^{-O \left( 1 / \rho \right)}$, questo non vorrebbe dire $\Omega(\frac{1}{2^{1/\rho}})$ e quindi mettere un lower bound all'errore additivo? io mi aspetto che si voglia dire che l'errore additivo e' $O(\frac{1}{2^{1/\beta}})$ con $\beta > \rho$}
\end{theorem}

\begin{proof}
	Given any $\rho \ge 1$, we show that there exists a non-Bayesian setting $(A,\Omega)$ in which, using a linear contract, it is impossible to obtain a $\left( \rho, 2^{-4 \rho -2} \right)$-approximation of the optimal expected utility for the principal.
	%
	In these instances, an optimal (non-linear) contract provides the principal with an expected utility $OPT > 4\rho 2^{-\lfloor4 \rho\rfloor-2},$ while the best linear contract achieves at most $2^{-\lfloor 4  \rho\rfloor-1}$ utility.
	%
	Since $\frac{ OPT}{\rho} -2^{-4 \rho -2}>2^{-\lfloor 4  \rho\rfloor-1}$, this concludes the proof.
	%
	Formally, let us take $\Omega=\{\omega_1, \omega_2,\omega_3\}$ and $A=\{a_i\}_{i \in [\gamma]} \cup \{ \bar a \}$, where $\gamma \coloneqq \lfloor 4 \rho \rfloor$.
	%
	Let $r_{\omega_1} = 1$ be the reward of outcome $\omega_1$, while the other outcomes provide zero reward, namely $r_{\omega_2} = r_{\omega_3} = 0$.
	%
	The agent's actions are such that $F_{a_1,\omega_1}=\frac{1}{2}$ and $F_{a_1,\omega_2}=\frac{1}{2}$, while $F_{a_i,\omega_1}=2^{-i}$ and  $F_{a_i,\omega_3}=1-2^{-i}$ for every $i\in [\gamma]: i > 1$.
	%
	Each action $a_i \in A$ has cost $c_{a_i}=2^{-i}-(\gamma-i+2)2^{-\gamma-2}$.
	%
	Moreover, the last action $\bar a \in A$ is such that $F_{\bar a,\omega_3}=1$ and $c_{\bar a} = 0$ (ensuring IR).
	%
	Simple arguments show that an optimal contract sets payments $p_{\omega_1} = p_{\omega_3} = 0$ and $p_{\omega_2}=1-(\gamma + 1) 2^{-\gamma-1}$, implementing action $a_1$ with a principal's expected utility $(\gamma+1) 2^{-\gamma-2}\ge 4\rho2^{-\lfloor 4  \rho \rfloor-2}$.
	%
	Intuitively, the contract is such that $P_{a_1} = c_{a_1}$, which ensures that the agent plays action $a_1$ (it is IC and ties are broken in favor of the principal), while minimizing the payment.
	%
	Next, we show that any linear contract provides the principal with an expected utility at most $2^{-\gamma-1}$.
	%
	First, let us notice that the principal's expected utility when implementing action $a_\gamma$ is at most $R_{a_\gamma}-c_{a_\gamma}=2^{-\gamma-1}$.
	%
	Instead, suppose that a linear contract implements an action $a_{i} \in A$ such that $i \in [\gamma] : 1 < i < \gamma$.
	%
	Then, it must be the case that $a_{i}$ provides the agent with an expected utility greater than or equal to that obtained by $a_{i+1}$, \emph{i.e.}, it must be $2^{-i} p_{\omega_1}+ \left( 1-2^{-i} \right)	p_{\omega_3} -c_{a_i} \geq 2^{-i-1} p_{\omega_1} + \left( 1-2^{-i-1} \right)	p_{\omega_3} - c_{a_{i+1}}$. Thus: 
	\[
		2^{-i} p_{\omega_1} - \left( 2^{-i}-(\gamma-i+2) 2^{-\gamma-2} \right) \ge 2^{-i-1} p_{\omega_1} - \left( 2^{-i-1}-(\gamma-i+1) 2^{-\gamma-2} \right), 
	\]
	which implies that $p_{\omega_1}\ge 1-2^{i+1-\gamma-2}$.
	%
	This prove that the expected utility for the principal is at most $\left( 1-p_{\omega_1} \right) 2^{-i}\le 2^{-\gamma-1}=2^{-\lfloor 4 \rho \rfloor-1} $, concluding the proof.
	%
\end{proof}


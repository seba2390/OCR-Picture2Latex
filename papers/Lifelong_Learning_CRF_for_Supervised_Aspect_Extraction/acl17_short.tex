\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{acl2017}
\usepackage{times}
\usepackage{latexsym}
\usepackage{helvet}
\usepackage{courier}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage{adjustbox}
\usepackage{multirow}
\usepackage{float}
\usepackage{textcomp}
\usepackage{algorithm,algorithmic}
\usepackage{amssymb,amsthm}
\usepackage{bbm}
\usepackage{url}

\aclfinalcopy % Uncomment this line for the final submission
\def\aclpaperid{3125} %  Enter the acl Paper ID here

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\theoremstyle{definition}
\newtheorem{defn}{Definition}

\usepackage[belowskip=-15pt,aboveskip=0pt]{caption}
%\setlength{\intextsep}{10pt plus 2pt minus 2pt}

\DeclareMathOperator*{\argmax}{arg\,max} % thin space, limits underneath in displays
\makeatletter
\newcommand{\ALOOP}[1]{\ALC@it\algorithmicloop\ #1%
    \begin{ALC@loop}}
    \newcommand{\ENDALOOP}{\end{ALC@loop}\ALC@it\algorithmicendloop}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\newcommand{\algorithmicbreak}{\textbf{break}}
\newcommand{\BREAK}{\STATE \algorithmicbreak}
\makeatother




\title{Lifelong Learning CRF for Supervised Aspect Extraction}


\author{Lei Shu, Hu Xu, Bing Liu\\
    Department of Computer Science\\
    University of Illinois at Chicago\\
    \{lshu3, hxu48, liub\}@uic.edu
}




\date{}

\begin{document}

\maketitle
\begin{abstract}
% One of the key tasks of sentiment analysis of product reviews is to extract product aspects or features that users have expressed opinions on. In this work, 
This paper makes a focused contribution to supervised aspect extraction. It shows that if the system has performed aspect extraction from many past domains and retained their results as knowledge, Conditional Random Fields (CRF) can leverage this knowledge in a lifelong learning manner to extract in a new domain markedly better than the traditional CRF without using this prior knowledge. The key innovation is that even after CRF training, the model can still improve its extraction with experiences in its applications. 
% with unlabeled data.

% The proposed method by exploiting sharing of aspects in multiple tasks using Conditional Random Fields. Although CRF and Hidden Markov Models (HMM) have been used for aspect extraction before, we show that by exploiting multiple tasks in CRF, significantly better results can be achieved. 
% much better results. proposed, we show that this supervised approach can be significantly improved by exploiting the idea of concept sharing across multiple domains. For example, ``screen'' is an aspect in iPhone, but not only iPhone has a screen, many electronic devices have screens too. When ``screen'' appears in a review of a new domain (or product), it is likely to be an aspect too. Knowing this information enables us to do much better extraction in the new domain. This paper proposes a novel extraction method exploiting this idea in the context of supervised sequence labeling. Experimental results show that it produces markedly better results than without using the past information.
\end{abstract}

\section{Introduction}
\label{sec:introduction}
Aspect extraction is a key task of opinion mining \cite{Liu2012}. It extracts opinion targets from opinion text. For example, from the sentence ``\emph{The battery is good}'', it aims to extract ``battery'', which is a product feature, also called an {\em aspect}. % that the writer of the sentence has expressed a positive opinion on. In product reviews, aspects are product attributes or features. 

%They are needed in many sentiment analysis applications.
% \cite{Pang2008OMS,Liu2012,Cambria2012}.

Aspect extraction 
%has been studied by many researchers. It 
is commonly done using a supervised or an unsupervised approach. The unsupervised approach includes methods such as frequent pattern mining~\cite{HuL2004,PopescuNE2005,Zhu2009}, syntactic rules-based extraction \cite{ZhuangJZ2006,WangBo2008,WuZHW2009,Zhang2010,QiuLBC2011,poria2014rule}, topic modeling \cite{MeiLWSZ2007,TitovM2008,LiHuangZhu2010,Brody2010,Wang2010,Moghaddam2011,Mukherjee2012,Lin2009,ZhaoJiang2010,Jo2011,FangHuang2012ACL,WangWWW2016}, word alignment \cite{KangLiu2013IJCAI}, label propagation \cite{Zhou-wan-xiao:2013:EMNLP,shu2016lifelong}, and others~\cite{zhao2015creating}.

This paper focuses on the supervised approach \cite{Jakob2010,Choi2010,Mitchell-EtAl:2013:EMNLP} using Conditional Random Fields (CRF) \cite{Lafferty2001conditional}. It shows that the results of CRF can be significantly improved by leveraging some prior knowledge automatically mined from the extraction results of previous domains, including domains without labeled data. 
% Such reviews are readily available and can be easily crawled from the Web, e.g., from Amazon.com's review pages. 
The improvement is possible because although every product (domain) is different, there is a fair amount of aspects sharing across domains~\cite{ChenLiu2014ICML}. For example, every review domain has the aspect \textit{price} and reviews of many products have the aspect \textit{battery life} or \textit{screen}. Those shared aspects may not appear in the training data but appear in unlabeled data and the test data.
We can exploit such sharing to help CRF perform much better.


% {chenLiu-ICML2014} Zhiyuan Chen and Bing Liu. Topic Modeling using Topics from Many Domains, Lifelong Learning and Big Data. Proceedings of the 31st International Conference on Machine Learning (ICML 2014), June 21-26, Beijing, China. 

% Since the proposed method will make use of the past extraction results as prior knowledge to help new or future extraction, it has to make sure that the knowledge is reliable. It is well-known that no statistical learning method can guarantee perfect results (as we will see later in the experiment section, CRF's extraction results are far from perfect). However, if we can find a set of shared aspects that have been extracted from multiple past domains, these aspects, which we call {\em reliable aspects}, are more likely to be correct. They can serve as the prior knowledge to help CRF extract from a new domain more effectively. For example, we have product reviews from three domains. After running a CRF-based extractor, a set of aspects is extracted from each domain reviews, which is listed below. Note that only four aspects are listed for each domain for illustration purposes.

%\vspace{-1mm}
%~~~~Camera Domain: \textit{price}, \textit{my wife}, \textit{battery life}, \textit{picture}

%\vspace{-2mm}
%~~~~Cellphone: \textit{picture}, \textit{husband}, \textit{battery life}, \textit{expensive}

%\vspace{-2mm}
%~~~~Washer: \textit{price}, \textit{water}, \textit{customer}, \textit{shoes}
%\vspace{-1mm}

%\noindent
%Clearly, some of the aspects are clearly incorrect, e.g., {\em my wife}, {\em husband}, and {\em customer} as they are not features of these products. However, if we focus on those aspects that appear at least in two domains, we can find the following set:

% \vspace{-1mm}
%~~~~\{\textit{price}, \textit{battery life},  \textit{picture}\}.
% \vspace{-1mm}

%\noindent
%This list of words is used as the past knowledge and given to CRF, which will leverage on it to perform better extraction in the new review domain. 

% We can see that the words in such a set are likely to belong to the same topic. Such, \{\textit{price}, \textit{cost}\} and \{\textit{price}, \textit{expensive}\}, can serve as \textit{prior knowledge}, which we call \textit{prior knowledge sets} (or \textit{pk-sets} for short), in a KBTM to improve the output topics for each of the three domains or a new domain. For example, after running a KBTM on the reviews of Domain $1$, we may find the new topic: {\textit{price}, \textit{cost}, \textit{expensive}, \textit{color}}, which has three coherent words in the top four positions rather than only two words as in the original topic. This represents a good topic improvement.

%\begin{enumerate}
%    \item {\em Model building phase}: Given a labeled training review set $D_t$, it builds a CRF model $M$. 
%    \item {\em Extraction phase}:  At any point in time, $M$ has been applied to extract from $n$ past domains of reviews $D=\{D_1,\dots,D_n\}$, which produced the corresponding sets of aspects $S=\{A_1,\dots, A_n\}$. A set of frequent aspects $K$ (the past knowledge) will be discovered from $S$. When faced with a new domain of reviews $D_{n+1}$, the algorithm first finds a set $K$ of reliable aspects from the aspect store $S$. $K$ is then used to help $M$ perform better extraction from $D_{n+1}$. The resulting set of aspects $A_{n+1}$ is added to $S$ for future use. 
    
% \end{enumerate}

% The key idea is that a trained CRF model can be used to extract aspects from reviews of a large number of domains or products. The past extraction results are used as prior knowledge to help extract aspects from the current or new domain reviews more accurately using the same CRF model with no extra manually labeled training examples or sequences. We describe the detailed technique in Section xx. This approach is based on the idea of lifelong learning~\cite{Thurn1995,ChenLiu-ICML-2014}.  We thus call the proposed method {\em Lifelong-CRF}.  

Due to leveraging the knowledge gained from the past to help the new domain extraction, we are using the idea of {\em lifelong machine learning} (LML)~\cite{ChenLiu2016,thrun1998lifelong,silver2013lifelong}, which is a continuous learning paradigm that retains the knowledge learned in the past and uses it to help future learning and problem solving with possible adaptations. % Formally, it is defined as follows~\cite{chen2015lifelong}: 

The setting of the proposed approach L-CRF ({\em Lifelong CRF}) is as follows: A CRF model $M$ has been trained with a labeled training review dataset. At a particular point in time, $M$ has extracted aspects from data in $n$ previous domains $D_1, \dots, D_n$ (which are unlabeled) and the extracted sets of aspects are $A_1, \dots, A_n$. Now, the system is faced with a new domain data $D_{n+1}$.  $M$ can leverage some {\em reliable prior knowledge} in $A_1, \dots, A_n$ to make a better extraction from $D_{n+1}$ than without leveraging this prior knowledge. 

The key innovation of L-CRF is that even after supervised training, the model can still improve its extraction in testing or its applications with experiences. Note that L-CRF is different from semi-supervised learning \cite{zhu2005semi} as the $n$ previous (unlabeled) domain data used in extraction are not used or not available during model training.

There are prior LML works for aspect extraction \cite{ChenZhiyuan2014ACL,liu2016improving}, but they were all unsupervised methods. Supervised LML methods exist \cite{chen2015lifelong,ruvolo2013ella}, but they are for classification rather than for sequence learning or labeling like CRF. A semi-supervised LML method is used in NELL\cite{mitchell2015}, but it is heuristic pattern-based. It doesn't use sequence learning and is not for aspect extraction. LML is related to transfer learning and multi-task learning~\cite{pan2010survey}, but they are also quite different (see~\cite{ChenLiu2016} for details).

% {mitchell2015} T. Mitchell, W. Cohen, E. Hruschka, P. Talukdar, J. Betteridge, A. Carlson, B. Dalvi, M.Gardner, B.Kisiel, J.Krishnamurthy, N.Lao, K.Mazaitis, T.Mohamed, N.Nakashole, E. Platanios, A. Ritter, M. Samadi, B. Settles, R. Wang, D. Wijaya, A. Gupta, X. Chen, A. Saparov, M. Greaves, and J. Welling. Never-ending learning. In AAAI, 2015. 

To the best of our knowledge, this is the first paper that uses LML to help a supervised extraction method to markedly improve its results.  
% All prior methods that use the idea of lifelong learning for aspect extraction are based on unsupervised learning ~\cite{ChenZhiyuan2014ACL,wang2016mining, shu2016lifelong, liu2016improving}. There are existing lifelong supervised learning methods~\cite{chen2015lifelong,ruvolo2013ella} but they are for classification rather than for sequence labeling. Lifelong learning is related to transfer learning and multi-task learning~\cite{pan2010survey}, but they are also different. See their differences in~\cite{ChenLiu2014ICML}. 

% {Ruvolo2013} Paul Ruvolo and Eric Eaton. 2013. ELLA: An efficient lifelong learning algorithm. In ICML, pages 507– 515.

% {silver2013} Daniel L Silver, Qiang Yang, and Lianghao Li. 2013. Lifelong Machine Learning Systems: Beyond Learning Algorithms. In AAAI Spring Symposium: Lifelong Machine Learning, pages 49–55.

% {thrun1998} Sebastian Thrun. 1998. Lifelong Learning Algorithms. In S Thrun and L Pratt, editors, Learning To Learn, pages 181–209. Kluwer Academic Publishers.


% \begin{defn}
%    \label{def:lifelong_machine_learning}
%    {\em Lifelong machine learning} (or simply lifelong learning) is a continuous learning process where the learner has performed a sequence of $n$ learning tasks, $T_1$, $T_2$, $\dots$, $T_{n}$, called the {\em past tasks}.  When faced with the $(n+1)$th task $T_{n+1}$ with its data $D_{n+1}$, the learner can leverage the {\em prior knowledge} $K$ gained in the past to help learn $T_{n+1}$. After the completion of learning $T_{n+1}$, $K$ is updated with the learned results from $T_{n+1}$.    
%\end{defn}

% We will discuss the related work that also uses the lifelong learning idea for aspect extraction in the next section. They are all based on unsupervised learning.  

% The key challenge of the proposed method is how to leverage $K$ to help $M$ to perform a better extraction. This paper proposes a novel method, which does not change the trained model $M$, but uses a set of dependency patterns generated from dependency relations and $K$ as feature values for CRF. As the algorithm extracts in more domains, $K$ also grows and the dependency patterns grow too, which gives the new domain richer feature information to enable the CRF model $M$ to perform better extraction in the new domain data $D_{n+1}$. 

% In summary, this paper makes the following contributions:

%\begin{enumerate}
    
%    \item It proposes a novel idea of exploiting review collections from past domains to learn prior knowledge to guide the CRF model in its sequence labeling process. To the best of our knowledge, this is the first time that lifelong learning is added to CRF. It is also the first time that lifelong learning is applied to supervised aspect extraction.
    
%    \item It proposes a novel method to incorporate the prior knowledge in the CRF prediction model for better extraction.  
    
%    \item Experimental results show that the proposed Lifelong-CRF outperforms baseline methods markedly.  
    
% \end{enumerate}

%\section{Related Work}
%{zhao2015creating} Yanyan Zhao, Bing Qin, Ting Liu: Creating a Fine-Grained Corpus for Chinese Sentiment Analysis. IEEE Intelligent Systems30(1): 36-43 (2015)

%{he2013dynamic}  Yulan He, Chenghua Lin, Wei Gao, Kam-Fai Wong: Dynamic joint sentiment-topic model. ACM TIST 5(1): 6 (2013)

%{katiyarinvestigating} Arzoo Katiyar, Claire Cardie:Investigating LSTMs for Joint Extraction of Opinion Entities and Relations. ACL (1) 2016

%\label{related work}
%As mentioned in the introduction, there are two main approaches to aspect extraction: \emph{supervised} and \emph{unsupervised}. The former is mainly based on CRF \cite{Jakob2010,Choi2010,Mitchell-EtAl:2013:EMNLP}, while the latter is mainly based on topic modeling \cite{MeiLWSZ2007,TitovM2008,LiHuangZhu2010,Brody2010,Wang2010,Moghaddam2011,Mukherjee2012,Lin2009,ZhaoJiang2010,Jo2011,FangHuang2012ACL}, and syntactic rules \cite{ZhuangJZ2006,WangBo2008,WuZHW2009,Zhang2010,QiuLBC2011,poria2014rule}. There are also frequency-based methods \cite{HuL2004,PopescuNE2005,Zhu2009}, word alignment methods \cite{KangLiu2013IJCAI}, label propagation methods \cite{Zhou-wan-xiao:2013:EMNLP}, and others~\cite{zhao2015creating}.


% {Poria2014}  Poria, S., Cambria, E., Ku, L.W., Gui, C. and Gelbukh, A., 2014, August. A rule-based approach to aspect extraction from product reviews. In Proceedings of the second workshop on natural language processing for social media (SocialNLP) (pp. 28-37).


%The technique proposed in this paper is in the context of supervised CRF \cite{Jakob2010,Choi2010,Mitchell-EtAl:2013:EMNLP}, which learns a sequence model to label aspects and non-aspects. Our work aims to improve it by exploiting the idea of lifelong learning. None of the existing supervised extraction methods have made use of this new idea. 

%Recent work has used deep learning for the task~\cite{wang2016recursive,lample2016neural}, which we will compare in our experiment. 

% {wang2016}Wang, W., Pan, S.J., Dahlmeier, D. and Xiao, X., 2016. Recursive Neural Conditional Random Fields for Aspect-based Sentiment Analysis. arXiv preprint arXiv:1603.06679. 


% [Guillaume2016]Guillaume Lample, Miguel Ballesteros, Kazuya Kawakami, Sandeep Subramanian and Chris Dyer. Neural Architectures for Named Entity Recognition. Proceedings of NAACL-2016. 

%Our work is most closely related to extraction methods that have already employed lifelong learning. However, all the current methods are unsupervised. For example, lifelong topic modeling-based methods in \cite{ChenZhiyuan2014ACL,wang2016mining} have been used for aspect extraction. However, topic models can only find some rough topics and are not effective for finding fine-grained aspects as a topical term does not necessarily mean an aspect. 
% For example, in a battery topic, a topic model may find topical terms such as ``battery,'' ``life,'' and ``time,'' etc., which are related to battery life, but each word is not an aspect. 
%Also, topic models only find aspects that are individual words, but many aspects of products are multiple word phrases, e.g., {\em battery life} and {\em picture quality}. Further, lifelong learning is used for unsupervised opinion target (aspect or entity) classification \cite{shu2016lifelong}, but not for aspect extraction. \cite{liu2016improving} proposed an unsupervised lifelong learning method based on dependency rules~\cite{QiuLBC2011} and recommendation. However, it is different from our method as our method is based on supervised sequence labeling. We aim to find more precise aspects using supervised learning and show that lifelong learning is also effective for supervised learning and to propose a novel method to incorporate it into the CRF labeling process. 

% {pan2010} Pan, Sinno Jialin and Yang, Qiang. A Survey on Transfer Learning. IEEE Trans. Knowl. Data Eng., 22(10):1345–1359, 2010.


\section{Conditional Random Fields}
CRF learns from an observation sequence $\mathbf{x}$ to estimate a label sequence $\mathbf{y}$: $p(\mathbf{y}|\mathbf{x}; \boldsymbol{\theta})$, where $\boldsymbol{\theta}$ is a set of weights. 
% We use $L$ to denote the length of the sequence, and 
Let $l$ be the $l$-th position in the sequence. The core parts of CRF are a set of feature functions $\mathcal {F}=\{f_h(y_{l},y_{l-1},\mathbf{x}_l)\}_{h=1}^{H}$ and their corresponding weights $\boldsymbol{\theta}=\{\theta_h\}_{h=1}^H$. 
%The conditional probability of the sequence of labels $\mathbf{y}$ is %given the sequence of observations $\mathbf{x}=(\mathbf{x}_1, \dots, \mathbf{x}_L)$ is
%    \begin{equation}
%    \label{lccrf}
%    \resizebox{0.85\hsize}{!}{
%        $p(\mathbf{y}|\mathbf{x}; \boldsymbol{\theta}) = \frac{1}{Z(\mathbf{x})} \prod_{l=1}^{L} \exp \Big\{ \sum_{h=1}^{H}\theta_{h}f_{h}(y_{l},y_{l-1},\mathbf{x}_{l}) \Big\} ,$
%    }
%    \end{equation}
%    where $Z(\mathbf{x})$ is for normalization.
%    where $Z(\mathbf{x})$ is the partition function:
%    \begin{equation}
%    \label{pf}
%    \resizebox{0.85\hsize}{!}{
%        $Z(\mathbf{x})=\sum_{\mathbf{y' \in \mathbf{Y}}}\prod_{l=1}^{L}\exp \Bigg\{ \sum_{h=1}^{H}\theta_{h}f_{h}(y_{l},y_{l-1},\mathbf{x}_{l}) \Bigg\} .$
%    }
%    \end{equation}
% \subsection{Parameter Estimation and Prediction}
%The weights $\boldsymbol{\theta} = \{\theta_1,\dots, \theta_H\}$ are estimated in training.
%by maximizing the log likelihood on the training data $D_t=\{(\mathbf{x}^{(1)},\mathbf{y}^{(1)}), \dots, (\mathbf{x}^{(n)},\mathbf{y}^{(n)})\}$. 
% \begin{equation}
% \label{learning}
%\hat{\boldsymbol{\theta}} = \argmax_{\boldsymbol{\theta}} \log \prod_{i=1}^{n} p(\mathbf{y}^{(i)}|\mathbf{x}^{(i)}; \boldsymbol{\theta}) .
% \end{equation}
%In testing, the prediction of labels is done by maximizing
%\begin{equation}
%\label{predict}
%\hat{\boldsymbol{\mathbf{y}}} = \argmax_{\boldsymbol{\mathbf{y}} \in \mathbf{Y}} p(\mathbf{y}|\mathbf{x}; \hat{\boldsymbol{\theta}}) .
%\end{equation}

%\subsection{Feature Function}
\noindent
{\bf Feature Functions}: We use two types of feature functions (FF). 
One is \emph{Label-Label (LL)} FF:
    \begin{equation}
    \label{ll feature function}
    \resizebox{0.85\hsize}{!}{
        $f_{ij}^{\textit{LL}}(y_l,y_{l-1})=\mathbbm{1}\{y_l=i\}\mathbbm{1}\{y_{l-1}=j\} ,\forall i,j \in \mathcal{Y},$
    }
    \end{equation}
where $\mathcal{Y}$ is the set of labels, and $\mathbbm{1}\{\cdot\} $ an indicator function.
The other is \emph{Label-Word (LW)} FF:
    \begin{equation}
    \label{lw feature function}
    \resizebox{0.85\hsize}{!}{
        $f_{iv}^{\textit{LW}}(y_l,\mathbf{x}_l) = \mathbbm{1}\{y_l=i\}\mathbbm{1}\{\mathbf{x}_l=v\} ,\forall i \in \mathcal{Y}, 
        \forall v \in \mathcal{V},$
    }
    \end{equation}
where $\mathcal{V}$ is the vocabulary. This FF returns $1$ when the $l$-th word is $v$ and the $l$-th label is $v$'s specific label $i$; otherwise $0$. $\mathbf{x}_l$ is the current word, and is represented as a multi-dimensional vector. Each dimension in the vector is a feature of $\mathbf{x}_l$.  

Following the previous work in \cite{Jakob2010}, 
we use the feature set \{W, -1W, +1W, P, -1P, +1P, G\}, where W is the word and P is its POS-tag, -1W is the previous word, -1P is its POS-tag, +1W is the next word, +1P is its POS-tag, and G is the generalized dependency feature. 

Under the Label-Word FF type, we have two sub-types of FF: {\em Label-dimension} FF and {\em Label-G} FF. Label-dimension FF is for the first 6 features, and Label-G is for the G feature. 
% Here, $\mathbf{x}_l$ is the current word and is represented as a multi-dimensional vector. We use $d$ 
%\in \mathcal{D}$ 
% to denote one feature of $\mathbf{x}_l$
% where $\mathcal{D}$ is the feature set of $\mathbf{x}_l$. 

The \emph{Label-dimension (L$d$)} FF is defined as
\begin{equation}
\label{ld feature function}
\resizebox{0.85\hsize}{!}{
    $f_{iv^d}^{\textit{L}d}(y_l,\mathbf{x}_l) = \mathbbm{1}\{y_l=i\}\mathbbm{1}\{\mathbf{x}_l^d=v^d\}, \forall i \in \mathcal{Y}, 
    \forall v^d \in \mathcal{V}^d ,$
}
\end{equation}
where $\mathcal{V}^d$ is the set of observed values in feature $d \in \{W, -1W, +1W, P, -1P, +1P\}$ and we call $\mathcal{V}^d$ feature $d$'s feature values. Eq. (\ref{ld feature function}) is a FF that returns $1$ when $\mathbf{x}_l$'s feature $d$ equals to the feature value $v^d$ and the variable $y_l$ ($l$th label) equals to the label value $i$; otherwise 0.

We describe G  and its feature function next, which also holds the key to the proposed L-CRF. 
        
% Because the size of the label set is small, the occurrence of each \textit{Label-Label} combination in the training data is sufficient to learn the corresponding weights for Eq. (\ref{ll feature function}) well. However, the set of observed words is much larger. The occurrence of each \textit{Label-Word} combination in the training data is not sufficient to ensure the corresponding weights are learned well for Eq. (\ref{lw feature function}). Further, there are many words that may not be observed in the training data but are later observed in the test data. CRF will suffer from low recall when there are no corresponding \textit{Label-Word} FF and weight that match those newly observed words. To solve this problem, we introduce an additional feature in the next section, which is also key to L-CRF.
\begin{table*}[ht]
    \centering
    %\begin{adjustbox}{max width= 0.95\textwidth}
    \scalebox{0.75}{
    \begin{tabular}{ c | c| l }
        \hline
        Index & Word & Dependency Relations  \\
        \hline
        1 & The & \{\textit{(det, battery, 2, NN , The, 1, DT)} \}\\
        \hline
        2 & battery &\{\textit{(nsubj, great, 7, JJ , battery, 2, NN), (det, battery, 2, NN , The, 1, DT), (nmod, battery, 2, NN, camera, 5, NN)} \} \\
        \hline
        3 & of &\{\textit{(case, camera, 5, NN, of, 3, IN)} \}\\
        \hline
        4 & this&\{\textit{(det, camera, 5, NN, this, 4, DT)} \}\\
        \hline
        5 & camera&\{\textit{(case, camera, 5, NN, of, 3, IN), (det, camera, 5, NN, this, 4, DT), (nmod, battery, 2, NN, camera, 5, NN)} \} \\
        \hline
        6 & is&\{\textit{(cop, great, 7, JJ , is, 6, VBZ)} \}\\
        \hline
        7 & great&\{\textit{(root, ROOT, 0, VBZ, great, 7, JJ), (nsubj, great, 7, JJ , battery, 2, NN), (cop, great, 7, JJ , is, 6, VBZ)} \} \\
        \hline 
    \end{tabular}
    }
    %\end{adjustbox}
    \caption{Dependency relations parsed from ``The battery of this camera is great''}
    \label{table:dr1}
\end{table*}
\section{General Dependency Feature (G)}
Feature G uses generalized dependency relations. What is interesting about this feature is that it enables L-CRF to use past knowledge in its sequence prediction at the test time in order to perform much better. This will become clear shortly. 
This feature 
% To enable L-CRF to adapt its prediction performance on the test data, we introduce the \emph{general dependency feature} (G), which is able to adjust its feature value as more knowledge is accumulated from previous domains. The general dependency feature 
takes a \emph{dependency pattern} as its value, which is generalized from dependency relations.

The general dependency feature (G) of the variable $\mathbf{x}_l$ takes a set of feature values $\mathcal{V}^{\textit{G}}$. Each feature value $v^{\textit{G}}$ is a dependency pattern. The \emph{Label-G (LG)} FF is defined as:
    \begin{equation}
    \label{lg feature function}
    \resizebox{0.85\hsize}{!}{
        $f_{iv^{\text{G}}}^{\textit{LG}}(y_l,\mathbf{x}_l) = \mathbbm{1}\{y_l=i\}\mathbbm{1}\{\mathbf{x}_l^{\textit{G}}=v^{\textit{G}}\} ,\forall i \in \mathcal{Y}, 
        \forall v^{\text{G}}\in \mathcal{V}^{\text{G}}.$
    }
    \end{equation}
Such a FF returns $1$ when the dependency feature of the variable $\mathbf{x}_l$ equals to a dependency pattern $v^{\textit{G}}$ and the variable $y_l$ equals to the label value $i$.

% also enables the capability of knowledge accumulation in lifelong learning, which will be clear shortly. 

%Sometimes, the word far from the current word can be helpful as well. For example, ``I bought this camera in the super-mall''. The word ``bought" (2 word-away) can help indicate ``camera'' as an aspect. However, once the size of the window is increased, some useless words are considered too. The word ``the'' (2 word-away) cannot help ``camera''. The increment of window's size introduces a lot of useless feature functions. 

% The feature set we use for CRF is \{G, W, -1W, +1W, P, -1P, +1P\}, which contains 6 common features and 1 general dependency feature (G). The general dependency feature (G) takes a \emph{dependency pattern} as a value. A dependency relation can link two words that may be far away from each other rather than a fixed-size window. The dependency feature also enables the capability of knowledge accumulation in lifelong learning, which will be clear shortly.  

\subsection{Dependency Relation}
Dependency relations have been shown useful in many sentiment analysis applications \cite{Johansson2010,Jakob2010}. A dependency relation \footnote{We obtain dependency relations using Stanford CoreNLP: http://stanfordnlp.github.io/CoreNLP/.} is a quintuple-tuple:  
$\textit{(type, gov, govpos, dep, deppos)},$
where $\textit{type}$ is the type of the dependency relation, \textit{gov} is the \emph{governor word}, \textit{govpos} is the POS tag of the governor word, \textit{dep} is the \emph{dependent word}, and \textit{deppos} is the POS tag of the dependent word. The $l$-th word can either be the governor word or the dependent word in a dependency relation. 




%\fi

% Table \ref{table:dr1} shows the dependency relations parsed from ``The battery of this camera is great''. The Index column shows the position of each word in the sentence. The Dependency Relations column lists all the dependency relations that each word involves. 

\subsection{Dependency Pattern}
% To allow a dependency pattern automatically accumulates knowledge, we group specific dependency relations into dependency patterns. The idea here is to allow a dependency pattern able to store and retrieve knowledge in order to adapt its pattern value. So when more knowledge is available, a test sequence may have better pattern values for prediction. 
We generalize dependency relations into {\em dependency patterns} using the following steps: 

\begin{enumerate}
    % \item Eliminate all indices since indices are specific to each sentence:
    % for example ``I like the battery of this camera''. The pattern ``the battery of this camera'' is located in different places comparing to ``The battery of this camera is great''.
    % $$\textit{(type, gov, govpos, dep, deppos)} .$$
    \item For each dependency relation, replace the current word (governor word or dependent word) and its POS tag with a wildcard since we already have the word (W) and the POS tag (P) features.
%. Second, we put a wildcard instead of removing it because we care more about the other word's influence on the current word. The wildcard keeps the information whether a word is a dependent word or a governor word. This is because without such information, ``the battery of this camera'' has the same $\textit{nmod}$ relation as ``the camera of this battery''.
    
%    To illustrate the process of this step, in Table \ref{table:dr1}, the 5th word ``camera'' is the dependent word in  $\textit{(nmod, battery, NN, camera, NN)}$ but the governor word in $\textit{(det, camera, NN, this, DT)}$. After applying wildcard, the relations for ``camera'' become:
%    \begin{equation}
%        \resizebox{0.75\hsize}{!}{
%            $\textit{(nmod, battery, NN, *), (det, *, this, DT), (case, *, of, IN)} . $
%        }
%    \end{equation}
%This is still not general enough because there are still actual words in the relations, which make the relations still too specific and difficult to apply to new domains (cross-domains) other than the training domain because those words may not appear in new domains. 
    % (?? everything below is not needed) Let us use an example to show how such dependency relations can help extract aspects, especially in a new domain. Assume the training domain is ``Camera''. ``Battery'' and ``camera'' are annotated as aspects (A). The label-general dependency (LG) feature's feature function for label being 'A' and general dependency feature being $\textit{nmod(battery, NN, *)}$ returns $1$ if ``camera'' is the argument.
%     \begin{equation}
    % \label{lg feature function}
%     f_{iv^G}^{\text{LG}}(y_l = \text{A},\mathbf{x}_l = \text{camera}) = 1, 
    % \end{equation}
    % where, $i = \text{A}$ and $v^G = \textit{nmod(battery, NN, *)}$.
    
    
%     The feature $\textit{nmod(battery, NN, *)}$ has a better correlation with current word's label be an aspect (A) because ``the battery of this camera'' is in the training data. When applying the model trained on the ``Camera'' domain to another domain like ``Phone'', the ``phone'' is likely predicted as an aspect in ``The battery of this phone is good'' because of the feature function Eq (\ref{lg feature function}), though ``phone'' never appeared in ``Camera'' domain (?? why).
    
%    However, such feature value format cannot help to extract ``signal'' in ``I'm satisfied with the signal of the phone''. Because, ``signal'' never appeared in the ``Camera'' domain and it does not have any dependency feature value similar to the aspect words in the ``Camera'' domain. To solve this problem, we define a general dependency feature value (?? I thought the above is already a general dependency feature; this item 2 is too long and too detailed and get people confused).
    
    \item Replace the context word (the word other than the $l$-th word) in each dependency relation with a knowledge label to form a more general dependency pattern. Let the set of aspects annotated in the training data be $K^t$. If the context word in the dependency relation appears in $K^t$, we replace it with a knowledge label `A' (aspect); otherwise `O' (other). 
    
    % Initially, $\text{K}$ contains all words which are annotated as an aspect in the training data.
    
%    For example, assuming the training domain is \textit{Camera}, The words ``battery'' and ``camera'' are in $K_t$. The above dependency relations for the word ``camera'' become:
%        \begin{equation}
%        \resizebox{0.75\hsize}{!}{
%            $\textit{(nmod, A, NN, *), (det, *, O, DT), (case, *, O, IN)} .$
%        }
%        \end{equation}
        
%        Likewise, the dependency relations of the word ``battery'' become:
%        \begin{equation}
%        \resizebox{0.75\hsize}{!}{
%            $\textit{(nsubj, O, JJ , *), (det, *, O, DT), (nmod, *, A, NN)} .$
%        }
%        \end{equation}

%    In the sentence ``The battery of this camera is great'', the 5th word ``camera'' makes the feature function Eq. (\ref{lg feature function 1}) returns $1$ because ``camera'' is an aspect and it has a dependency pattern $\textit{(nmod, A, NN, *)}$ .    
%    \begin{equation}
%        \label{lg feature function 1}
%        f_{iv^G}^{\textit{LG}}(y_l = \text{`A'},\mathbf{x}_l = \text{``camera''}) = 1, 
%    \end{equation}
%    where $i = \text{`A'}$ and $v^G = \textit{(nmod, A, NN, *)}$.
%    Likewise, the 2nd word ``battery'' makes the feature function Eq. (\ref{lg feature function 2}) returns $1$ because it is an aspect as well and it has a dependency pattern $\textit{nmod(*, A, NN)}$.
%    \begin{equation}
%        \label{lg feature function 2}
%        f_{iv^G}^{\textit{LG}}(y_l = \text{`A'}, \mathbf{x}_l = \text{``battery''}) = 1, 
%    \end{equation}
%    where $i = \text{`A'}$ and $v^G = \textit{(nmod, *, A, NN)}$.
    

\end{enumerate}

For example, we work on the sentence ``The battery of this camera is great.'' The dependency relations are given in Table \ref{table:dr1}. Assume the current word is ``battery,'' and ``camera'' is annotated as an aspect. The original dependency relation between ``camera'' and ``battery'' produced by a parser is (nmod, battery, NN, camera, NN). Note that we do not use the word positions in the relations in Table \ref{table:dr1}. Since the current word's information (the word itself and its POS-tag) in the dependency relation is redundant, we replace it with a wild-card. The relation becomes (nmod, *, camera, NN). Secondly, since ``camera'' is in $K^t$, we replace ``camera'' with a general label `A'. The final dependency pattern becomes (nmod,*, A, NN).

% The final forms of dependency relations are {\em dependency patterns}. 

We now explain why dependency patterns can enable a CRF model to leverage the past knowledge. The key is the knowledge label `A' above, which indicates a likely aspect. Recall that our problem setting is that when we need to extract from the new domain $D_{n+1}$ using a trained CRF model $M$, we have already extracted from many previous domains $D_1, \dots, D_n$ and retained their extracted sets of aspects $A_1, \dots, A_n$. Then, we can mine reliable aspects from $A_1, \dots, A_n$ and add them in $K^t$, which enables many knowledge labels in the dependency patterns of the new data $A_{n+1}$ due to sharing of aspects across domains. This enriches the dependency pattern features, which consequently allows more aspects to be extracted from the new domain $D_{n+1}$.   


% In this way, if we have more aspect knowledge in $K_t$, the dependency pattern for the $l$-th word is more likely to have a dependency pattern with label `A'. So the $l$-th word may have different dependency patterns given different $K_t$, and the trained CRF already know how to deal with similar dependency patterns with different knowledge labels from only the training data.
% We are now ready to present the proposed Lifelong-CRF method since dependency patterns are capable of accumulating knowledge. 

% The model trained in the ``Camera'' domain using the general dependency feature becomes more powerful with the growing of the knowledge. When applying such model on domain ``Phone'', ``phone'' in ``The battery of this phone'' is likely predicted as an aspect since it has a dependency feature equal to $\textit{nmod(A, NN, *)}$. In this round, the knowledge $\text{K}$ does not include ``phone''. The general dependency feature of ``signal'' is $\textit{nmod(*, O, NN)}$. The word ``signal'' is unlikely to be predicted as an aspect. 
    
% Since ``phone'' is predicted as an aspect. We can update the knowledge $\text{K}$ to include ``phone''. Then the general dependency feature of ``signal'' is changed to $\textit{nmod(*, A, NN)}$ like ``battery'' in ``Camera'' domain. This feature value has a higher correlation with this word being labeled as an aspect by the model. With the growing of knowledge, the general dependency feature of ``signal'' is changed, it is likely to be predicted as an aspect.
    
% Without re-training the model, updating the knowledge can make the model be better through predicting more unannotated data. This technique is very helpful in practice. Because, the sequence tagging models like CRF, LSTM-CRF are expensive to train. And annotated training data is limited. 

% In the next section, we will discuss how the model becomes powerful with the growing of knowledge through predicting large unannotated datasets. 


\begin{algorithm}
    \caption{Lifelong Extraction of L-CRF}\label{algo:pred}
    \begin{algorithmic}[1]
        %        \show
        %        \LOOP
        \STATE $K_p \leftarrow \emptyset$
        \ALOOP{} % Outer loop
        \STATE $F \leftarrow \text{FeatureGeneration}(D_{n+1}, K)$ \label{test:1}
        \STATE $A_{n+1} \leftarrow \text{Apply-CRF-Model}(M, F)$  \label{test:2}
        \STATE $S \leftarrow S \cup \{A_{n+1}\}$
        \STATE $K_{n+1} \leftarrow \text{Frequent-Aspects-Mining}(S,\lambda)$
        \IF {$K_p = K_{n+1}$}
        \BREAK
        \ELSE
        \STATE $K \leftarrow K^t \cup K_{n+1}$\label{test:3}
        \STATE $K_p \leftarrow K_{n+1}$\label{test:4}
        \STATE $S \leftarrow S - \{A_{n+1}\}$
        \ENDIF
        \ENDALOOP
    \end{algorithmic}
\end{algorithm}
%\begin{figure}[htbp]
%    \label{LPC}
%    \centering
%    \includegraphics[width=0.45\textwidth]{LPC.pdf}
%    \caption{Learning, Predicting, and Cumulating}
%\end{figure}
\section{The Proposed L-CRF Algorithm}

% The traditional supervised machine learning tries to fit a model by given training data $\{(\mathbf{x}^{(i)}, \mathbf{y}^{(i)})\}$. Once the model is trained, given a new observation $\mathbf{x}$, such model predicts an $\mathbf{y}$. The functionality of training data in this process is to fit a model. However, the performance of such model is limited by the limitation of annotated data. It cannot handle unseen observation which comes in the future. 

% To make the model stronger, un-annotated data is used. Expectation-Maximization (EM) is the technique utilizing un-annotated data and do iteratively predicting and re-training to strengthen the model. EM can help the simple supervised algorithm like Naive Bayes a lot because the iterative training cost for that algorithm is not huge. For the sequence tagging methods like CRF and LSTM-CRF, the training cost is huge. Iteratively re-training those model is not applicable.

% We propose a Lifelong CRF technique which takes advantage of un-annotated data and becomes stronger through predicting and cumulating knowledge without re-training the CRF model.

% \subsection{Knowledge Cumulating and Filtering}
% Besides fitting a model, we think the functionality of training data can be more. The training data is very reliable knowledge. It can contribute to a knowledge base as well as to a model. In Figure \ref{LPC} learning part, training data is contributed to a knowledge as well as a model. Further, a model can take training data as input as well as knowledge. 

% General dependency feature relies on the knowledge. A model trained by general dependency feature fits knowledge as well as observations. After predicting, the prediction and the observation are updated into the knowledge. With the growing of knowledge, general dependency feature of a word changes. Then, using the same model, the prediction of this word may be different with the change of its dependency feature.

% It realizes that predicting more, the knowledge becomes more and the model becomes stronger. However, some knowledge may not be accurate if we apply them directly without filtering, it can cause a problem. So, besides cumulating knowledge, we filter knowledge by frequency. The filtered knowledge is called reliable knowledge. when updating the general dependency feature, we only use reliable knowledge, not all knowledge. We think this process is similar to human learning. This process is lifelong.

% We combine this process with CRF model and call it Lifelong CRF.

% \subsection{Lifelong CRF}

We now present the L-CRF algorithm. As the dependency patterns for the general dependency feature do not use any actual words and they can also use the prior knowledge, they are quite powerful for cross-domain extraction (the test domain is not used in training). 

Let $K$ be a set of {\em reliable aspects} mined from the aspects extracted in past domain datasets using the CRF model $M$. Note that we assume that $M$ has already been trained using some labeled training data $D^t$. Initially, $K$ is $K^t$ (the set of all annotated aspects in the training data $D^t$). The more domains $M$ has worked on, the more aspects it extracts, and the larger the set $K$ gets. When faced with a new domain $D_{n+1}$, $K$ allows the general dependency feature to generate more dependency patterns related to aspects due to more knowledge labels `A' as we explained in the previous section. Consequently, CRF has more informed features to produce better extraction results. 
% More patterns generate more feature functions, which enable the CRF model $M$ to extract more and better aspects in the new domain.  

L-CRF works in two phases: {\em training phase} and {\em lifelong extraction phase}. The training phase trains a CRF model $M$ using the training data $D^t$, which is the same as normal CRF training, and will not be discussed further. In the lifelong extraction phase, $M$ is used to extract aspects from coming domains ($M$ does not change and the domain data are unlabeled). All the results from the domains are retained in past aspect store $S$. At a particular time, it is assumed $M$ has been applied to $n$ past domains, and is now faced with the $n+1$ domain. L-CRF uses $M$ and reliable aspects (denoted $K_{n+1}$) mined from $S$ and $K^t$ ($K=K^t \cup K_{n+1}$) to extract from $D_{n+1}$.  Note that aspects $K_t$ from the training data are considered always reliable as they are manually labeled, thus a subset of $K$. We cannot use all extracted aspects from past domains as reliable aspects due to many extraction errors. But those aspects that appear in multiple past domains are more likely to be correct. Thus $K$ contains those frequent aspects in $S$. The lifelong extraction phase is in Algorithm \ref{algo:pred}.

\textbf{Lifelong Extraction Phase}: 
%We assume that the learned model has performed extraction on previous $n$ domains. When a new domain dataset $D_{n+1}$ arrives in the system, it uses 
Algorithm \ref{algo:pred} performs extraction on $D_{n+1}$ iteratively. 
% Algorithm \ref{algo:pred} works in the following steps: 
\begin{enumerate}
    \item It generates features ($F$) on the data $D_{n+1}$ (line \ref{test:1}), and applies the CRF model $M$ on $F$ to produce a set of aspects $A_{n+1}$ (line \ref{test:2}). 
    %It is important to note that $K$ grows as the system worked on more domains, which enables the system to generate more dependency patterns-based feature functions for the new data, and consequently better extraction results from the new domain as we will see in the experiment section. 
    \item $A_{n+1}$ is added to $S$, the past aspect store. From $S$, we mine a set of frequent aspects $K_{n+1}$. The frequency threshold is $\lambda$.
    \item If $K_{n+1}$ is the same as $K_p$ from the previous iteration, the algorithm exits as no new aspects can be found. We use an iterative process because each extraction gives new results, which may increase the size of $K$, the reliable past aspects or past knowledge. The increased $K$ may produce more dependency patterns, which can enable more extractions. 
    \item Else: some additional reliable aspects are found. $M$ may extract additional aspects in the next iteration. Lines \ref{test:3} and \ref{test:4} update the two sets for the next iteration.
\end{enumerate}

% \textbf{Model Training Phase}: Given the annotated training data set $D_t$ and the set $K_t$ of all annotated aspects in $D_t$, it first generates all feature functions (including dependency pattern-based ones) to give the data $F$ with features (line \ref{train:1}). It then trains a CRF model $M$ by running a CRF learning algorithm (line \ref{train:2}). $K_t$ is assigned to $K$ as the initial set of reliable aspects (line \ref{train:3}), which will be used in subsequent extraction tasks in new domains. 
%\begin{algorithm}
%   \caption{Model Training Phrase}\label{algo:train}
%    \begin{algorithmic}[1]
%        \STATE $F \leftarrow \text{FeatureGeneration}(D_t, K_t)$ \label{train:1}
 %       \STATE $M \leftarrow \text{Train-CRF}(F)$ \label{train:2}
 %       \STATE $K \leftarrow K_t$    \label{train:3}
%    \end{algorithmic}
% \end{algorithm}

     \begin{table}[t]
         \centering
         %\begin{adjustbox}{max width=0.5 \textwidth}  
            \scalebox{0.85}{
             \begin{tabular}{c|c|c|c}
                 \hline
                 {\bf Domain}&{\bf \# Sent.}& {\bf \# Asp.}& {\bf \# non-asp. words}  \\\hline
                 Computer     &536    &1173    &7675\\\hline
                 Camera     &609    &1640    &9849\\\hline
                 Router     &509    &1239    &7264\\\hline
                 Phone         &497    &980    &7478\\\hline
                 Speaker      &510    &1299    &7546\\\hline
                 DVD Player &506    &928    &7552\\\hline
                 Mp3 Player &505    &1180     &7607\\\hline
             \end{tabular}
             }
        %\end{adjustbox}    
        \caption{{Annotation details of the datasets}}\label{tab:annotation} 
     \end{table}

\iffalse
     \begin{table}[h]
         \centering
         \begin{adjustbox}{max width=0.5 \textwidth}  

             \begin{tabular}{c|c|c|c|c}
                 \hline
                 {\bf Dataset}& {\bf Domain}&{\bf \# of Sentences}& {\bf \# of Aspects}& {\bf \# of non-aspect words}  \\\hline
                 D1 & Computer     &536    &1173    &7675\\\hline
                 D2 & Camera     &609    &1640    &9849\\\hline
                 D3 & Router     &509    &1239    &7264\\\hline
                 D4 & Phone         &497    &980    &7478\\\hline
                 D5 & Speaker      &510    &1299    &7546\\\hline
                 D6 & DVD Player &506    &928    &7552\\\hline
                 D7 & Mp3 Player &505    &1180     &7607\\\hline
             \end{tabular}
             
        \end{adjustbox}    
         \caption{{Annotation details of the  benchmark datasets}}\label{tab:annotation}
     \end{table}
     


\begin{table*}[!t]
    \centering
    \caption{Aspect extraction results in precision, recall and F$_1$ score: Cross-Domain and In-Domain ($-$X means all except domain X)
    }
    \label{tab:result}
    \scalebox{0.9}{
    %\begin{adjustbox}{max width=1.02\textwidth}    
        \begin{tabular}{c|c|c c c|c c c|c c c|c|c c c|c c c|c c c }
            \hline    
            &\multicolumn{10}{|c|}{\textbf{Cross-Domain}}    &\multicolumn{10}{|c}{\textbf{In-Domain}}\\\hline
            \multirow{2}{*}{Training}&\multirow{2}{*}{Testing}&\multicolumn{3}{ |c| }{CRF}& \multicolumn{3}{ |c| }{CRF+R}& \multicolumn{3}{ |c| }{L-CRF} &
            \multirow{2}{*}{Testing}&\multicolumn{3}{ |c| }{CRF}& \multicolumn{3}{ |c| }{CRF+R}& \multicolumn{3}{ |c}{L-CRF} \\
            &&$\mathcal{P}$& $\mathcal{R}$&$\mathcal{F}_1$&$\mathcal{P}$& $\mathcal{R}$&$\mathcal{F}_1$
            &$\mathcal{P}$& $\mathcal{R}$&$\mathcal{F}_1$
            &&$\mathcal{P}$& $\mathcal{R}$&$\mathcal{F}_1$&    $\mathcal{P}$& $\mathcal{R}$&$\mathcal{F}_1$ &    $\mathcal{P}$& $\mathcal{R}$&$\mathcal{F}_1$\\\hline
            $-$Computer&Computer&86.6&51.4&64.5&23.2&90.4&37.0&82.2&62.7&71.1&$-$Computer&84.0&71.4&77.2&23.2&93.9&37.3&81.6&75.8&78.6\\\hline
            $-$Camera&Camera&84.3&48.3&61.4&21.8&86.8&34.9&81.9&60.6&69.6&$-$Camera&83.7&70.3&76.4&20.8&93.7&34.1&80.7&75.4&77.9\\\hline
            $-$Router&Router&86.3&48.3&61.9&24.8&92.6&39.2&82.8&60.8&70.1&$-$Router&85.3&71.8&78.0&22.8&93.9&36.8&82.6&76.2&79.3\\\hline
            $-$Phone&Phone&72.5&50.6&59.6&20.8&81.2&33.1&70.1&59.5&64.4&$-$Phone&85.0&71.1&77.5&25.1&93.7&39.6&82.9&74.7&78.6\\\hline
            $-$Speaker&Speaker&87.3&60.6&71.6&22.4&91.2&35.9&84.5&71.5&77.4&$-$Speaker&83.8&70.3&76.5&20.1&94.3&33.2&80.1&75.8&77.9\\\hline
            $-$DVDplayer&DVDplayer&72.7&63.2&67.6&16.4&90.7&27.7&69.7&71.5&70.6&$-$DVDplayer&85.0&72.2&78.1&20.9&94.2&34.3&81.6&76.7&79.1\\\hline
            $-$Mp3player&Mp3player&87.5&49.4&63.2&20.6&91.9&33.7&84.1&60.7&70.5&$-$Mp3player&83.2&72.6&77.5&20.4&94.5&33.5&79.8&77.7&78.7\\\hline\hline
            &\textbf{Average}&82.5&53.1&64.3&21.4&89.3&34.5&79.3&63.9&70.5&\textbf{Average}&84.3&71.4&77.3&21.9&94.0&35.5&81.3&76.0&78.6\\\hline    
            &\multicolumn{10}{|c|}{\textbf{Cross-Domain}}    &\multicolumn{10}{|c}{\textbf{In-Domain}}\\\hline
            \multirow{2}{*}{Training}&\multirow{2}{*}{Testing}&\multicolumn{3}{ |c| }{CRF}& \multicolumn{3}{ |c| }{CRF+R}& \multicolumn{3}{ |c| }{L-CRF} &
            \multirow{2}{*}{Testing}&\multicolumn{3}{ |c| }{CRF}& \multicolumn{3}{ |c| }{CRF+R}& \multicolumn{3}{ |c}{L-CRF} \\
            &&$\mathcal{P}$& $\mathcal{R}$&$\mathcal{F}_1$&$\mathcal{P}$& $\mathcal{R}$&$\mathcal{F}_1$
            &$\mathcal{P}$& $\mathcal{R}$&$\mathcal{F}_1$
            &&$\mathcal{P}$& $\mathcal{R}$&$\mathcal{F}_1$&    $\mathcal{P}$& $\mathcal{R}$&$\mathcal{F}_1$ &    $\mathcal{P}$& $\mathcal{R}$&$\mathcal{F}_1$\\\hline
        \end{tabular}
        
    %\end{adjustbox}    
    }
\end{table*}

\fi

\begin{table*}[ht]
    \centering
    \scalebox{0.95}{
    \begin{tabular}{c|c|c c c|c c c|c c c }
            \hline    
            \multicolumn{11}{c}{\textbf{Cross-Domain}} \\\hline  
            \multirow{2}{*}{Training}&\multirow{2}{*}{Testing}&\multicolumn{3}{ |c| }{CRF}& \multicolumn{3}{ |c| }{CRF+R}& \multicolumn{3}{ |c }{L-CRF} \\

            &&$\mathcal{P}$& $\mathcal{R}$&$\mathcal{F}_1$&$\mathcal{P}$& $\mathcal{R}$&$\mathcal{F}_1$
            &$\mathcal{P}$& $\mathcal{R}$&$\mathcal{F}_1$\\\hline

            $-$Computer&Computer&86.6&51.4&64.5&23.2&90.4&37.0&82.2&62.7&71.1\\\hline
            $-$Camera&Camera&84.3&48.3&61.4&21.8&86.8&34.9&81.9&60.6&69.6\\\hline
            $-$Router&Router&86.3&48.3&61.9&24.8&92.6&39.2&82.8&60.8&70.1\\\hline
            $-$Phone&Phone&72.5&50.6&59.6&20.8&81.2&33.1&70.1&59.5&64.4\\\hline
            $-$Speaker&Speaker&87.3&60.6&71.6&22.4&91.2&35.9&84.5&71.5&77.4\\\hline
            $-$DVDplayer&DVDplayer&72.7&63.2&67.6&16.4&90.7&27.7&69.7&71.5&70.6\\\hline
            $-$Mp3player&Mp3player&87.5&49.4&63.2&20.6&91.9&33.7&84.1&60.7&70.5\\\hline\hline
            &\textbf{Average}&82.5&53.1&64.3&21.4&89.3&34.5&79.3&63.9&70.5\\\hline 
  
            \multicolumn{11}{c}{\textbf{In-Domain}}\\\hline
            $-$Computer&$-$Computer&84.0&71.4&77.2&23.2&93.9&37.3&81.6&75.8&78.6\\\hline
            $-$Camera&$-$Camera&83.7&70.3&76.4&20.8&93.7&34.1&80.7&75.4&77.9\\\hline
            $-$Router&$-$Router&85.3&71.8&78.0&22.8&93.9&36.8&82.6&76.2&79.3\\\hline
            $-$Phone&$-$Phone&85.0&71.1&77.5&25.1&93.7&39.6&82.9&74.7&78.6\\\hline
            $-$Speaker&$-$Speaker&83.8&70.3&76.5&20.1&94.3&33.2&80.1&75.8&77.9\\\hline
            $-$DVDplayer&$-$DVDplayer&85.0&72.2&78.1&20.9&94.2&34.3&81.6&76.7&79.1\\\hline
            $-$Mp3player&$-$Mp3player&83.2&72.6&77.5&20.4&94.5&33.5&79.8&77.7&78.7\\\hline\hline
            &\textbf{Average}&84.3&71.4&77.3&21.9&94.0&35.5&81.3&76.0&78.6\\\hline             
        \end{tabular}
        }
    \caption{Aspect extraction results in precision, recall and F$_1$ score: Cross-Domain and In-Domain ($-$X means all except domain X)} 
    \label{tab:result} 
\end{table*}


%\subsection{Lifelong Process}
%Initially, there is a training data set $D_t$. The words annotated as aspect are put into a knowledge base $K$. Because such knowledge is from training data, they are reliable. So they belong to reliable knowledge $K$. The reliable knowledge is a subset of the knowledge base $K \in K$. 

%\begin{enumerate}
%    \item Given $D_t$ and $K$, we build a CRF model $M$ using general dependency feature as well as other traditional features. 
%    \item $M$ predicts a large number of unannotated reviews of past domains or products $D=\{D_1,\dots,D_n\}$ to extract aspects from each domain $D_i$. Each unannotated data (observation) has general dependency feature decided by $K$.
%    \item The resulting aspects $A=\{A_1,\dots, A_n\}$. The resulting aspects are updated into the knowledge base $K \leftarrow K \cup A$.
%    \item The frequent aspects $A_F$ which appeared multiple times in one domain and also appeared in multiple domains are reliable knowledge. They are updated into the reliable knowledge $K \leftarrow R \cup A_F$.
%    \item Go back to 2 with the updated $K$ and $K$.
%    \item When encountering a new dataset $D_{n+1}$, $M$ predicts it based on the general dependency features relating to the latest $K$. The resulting aspects are updated into the knowledge $K \leftarrow K \cup A_{n+1}$. Then go back to 4 for updating reliable knowledge $K$. 
    
%\end{enumerate}
%The CRF model $M$ does not change. With the increment of knowledge based $K$ and reliable knowledge $K$, model $M$ can achieve better performance. It is a lifelong CRF. Comparing the cost of training, the cost of predicting is small. So, Lifelong CRF is applicable in real life.

      
\section{Experiments} 
    We now evaluate the proposed L-CRF method and compare with baselines.  
    
\subsection{Evaluation Datasets}
    We use two types of data for our experiments. The first type consists of seven (7) annotated benchmark review datasets from 7 domains (types of products). Since they are annotated, they are used in training and testing. The first 4 datasets are from~\cite{HuL2004}, which actually has 5 datasets from 4 domains. Since we are mainly interested in results at the domain level, we did not use one of the domain-repeated datasets. The last 3 datasets of three domains (products) are from~\cite{liu2016improving}. These datasets are used to make up our CRF training data $D^t$ and test data $D_{n+1}$. The annotation details are given in Table \ref{tab:annotation}. 
    
    % All these datasets have been used previously for aspect extraction~\cite{HuL2004,Jakob2010,liu2016improving} Details of the datasets are in Table \ref{tab:annotation}. 
    
    
    
    % They have been used for target extraction, and thus have annotated targets, but not using BIO (Beginning, Inside, Outside) rule. We made this annotation. The labels we use are $\{ \text{B-Aspect, I-Aspect, O}\}$. 
    % In Tabel \ref{tab:annotation}, the number of Aspects counts the words annotated as B-Aspect and I-Aspect. 
    
    The second type has 50 unlabeled review datasets from 50 domains or types of products~\cite{ChenLiu2014ICML}. Each dataset has 1000 reviews. They are used as the past domain data, i.e., $D_1, \dots, D_n$ ($n=50$). Since they are not labeled, they cannot be used for training or testing. % All these datasets were downloaded from the paper authors' web pages. 
    
    % Zhiyuan Chen and Bing Liu. Topic Modeling using Topics from Many Domains, Lifelong Learning and Big Data. Proceedings of the 31st International Conference on Machine Learning (ICML 2014), June 21-26, Beijing, China. 
    
    % For completeness, we also give and overall accuracy as evaluation measures. We translate both B-Aspect and I-Aspect to Aspect and report the performance of Aspect. The evaluation is based on each token, if this token is annotated as B-Aspect or I-Aspect, and the prediction is B-Aspect or I-Aspect, we treat it as a true positive.
    
\subsection{Baseline Methods} % Since the goal of this paper is to study whether lifelong learning can be exploited to improve supervised learning for aspect extraction, 
    We compare L-CRF with CRF. We will not compare with unsupervised methods, which have been shown improvable by lifelong learning~\cite{ChenZhiyuan2014ACL,liu2016improving}. The frequency threshold $\lambda$ in Algorithm 1 used in our experiment to judge which extracted aspects are considered reliable is empirically set to $2$.    
    % We compare the following methods, including our proposed method, {\em Lifelong CRF}. 
    
    {\bf CRF}: We use the linear chain CRF from  \footnote{https://github.com/huangzhengsjtu/pcrf/}. Note that CRF uses all features including dependency features as the proposed L-CRF but does not employ the 50 domains unlabeled data used for lifelong learning
     %CRFsuite~\cite{CRFsuite}. % CRF has been used for the task by many researchers~\cite{Jakob2010,Choi2010,Mitchell-EtAl:2013:EMNLP}. 
    
    {\bf CRF+R}: It treats the reliable aspect set $K$ as a dictionary. It adds those reliable aspects in $K$ that are not extracted by CRF but are in the test data to the final results. We want to see whether incorporating $K$ into the CRF extraction through dependency patterns in L-CRF is actually needed.     

We do not compare with domain adaptation or transfer learning because domain adaption basically uses the source domain labeled data to help learning in the target domain with few or no labeled data. Our 50 domains used in lifelong learning have no labels. So they cannot help in transfer learning. Although in transfer learning, the target domain usually has a large quantity of unlabeled data, but the 50 domains are not used as the target domains in our experiments. 
  %  {\em LSTM-CRF}: This is a recent state-of-the-art deep learning method based on Long Short-Term Memory (LSTM) recurrent neural network and conditional random fields~\cite{lample2016neural}. It uses two sources of word representation: character-level word embeddings and word-level word embeddings from the supervised corpus. The LSTM-CRF implementation\footnote{http://github.com/glample/tagger} does embedding by itself from the training data. We thus only need to provide it with labeled sequences of words. Further, LSTM-CRF requires a validation dataset. So we allocate a portion of the annotated data as the validation dataset. Note that LSTM-CRF does not have lifelong learning capability. 
    
 %   {\em Lifelong-CRF}: This is our proposed system. The frequency threshold $\lambda$ in Algorithm 2 used in our experiment to judge which extracted aspects are considered reliable is empirically set to $2$. 
    
\subsection{Experiment Setting} 

To compare the systems using the same training and test data, for each dataset we use 200 sentences for training and 200 sentences for testing to avoid bias towards any dataset or domain because we will combine multiple domain datasets for CRF training. We conducted both cross-domain and in-domain tests. Our problem setting is cross-domain. In-domain is used for completeness. In both cases, we assume that extraction has been done for the 50 domains. 
    % Also, training and testing on the same domains (in-domain) are less interesting because those aspects appeared in the training data are very likely to appear in the test data because they are all about reviews of the same products. 
    
    
%    \begin{enumerate}
    {\bf Cross-domain experiments}: We combine 6 labeled domain datasets for training (1200 sentences) and test on the 7th domain (not used in training). This gives us 7 {\em cross-domain} results. This set of tests is particularly interesting as it is desirable to have the trained model used in cross-domain situations to save manual labeling effort. 
    
    {\bf In-domain experiments}: We train and test on the same 6 domains (1200 sentences for training and 1200 sentences for testing). This also gives us 7 {\em in-domain} results. % Note that although we call these in-domain experiments, both the training and testing data use the same 6 domains. 
%     \end{enumerate}
    
    
    {\bf Evaluating Measures}: 
    We use the popular precision $\mathcal{P}$, recall $\mathcal{R}$, and $\mathcal{F}_1$-score. % to evaluate our results on the extracted aspects.  
    
    \subsection{Results and Analysis}
    
    All the experiment results are given in Table \ref{tab:result}. % We analyze the results of cross-domain and in-domain in turn. Cross-domain is the main setting of interest as it is very undesirable to manually label data for every domain in practice. 
    
%    \begin{enumerate}
       {\bf Cross-domain}: Each $-$X in column 1 means that domain X is not used in training. X in column 2 means that domain X is used in testing. We can see that L-CRF is markedly better than CRF and CRF+R in $\mathcal{F}_1$. CRF+R is very poor due to poor precisions, which shows treating the reliable aspects set $K$ as a dictionary isn't a good idea. 
        
        % From the cross-domain results in the table, we observe the following: In $\mathcal{F}_1$ score, Lifelong-CRF is much better than CRF. On average the $\mathcal{F}_1$ score improves from $64.3$ to $70.5$. This is a major improvement. The main improvement is on the recall, which is markedly better. 
        %Lifelong-CRF is also much better than LSTM-CRF. On average, CRF and LSTM-CRF perform similarly on these cross-domain experiments. 
        % CRF+R's results are very poor due to poor precisions, which show that treating the reliable aspects set $K$ as a dictionary is a bad idea. Incorporating $K$ into the CRF model is important because many aspects in $K$ are not correct or not applicable to the new/test domain. CRF model $M$ will not extract many of them. 
        
       {\bf In-domain}: $-$X in training and test columns means that the other 6 domains are used in both training and testing (thus in-domain). We again see that L-CRF is consistently better than CRF and CRF+R in $\mathcal{F}_1$. The amount of gain is smaller. This is expected because most aspects appeared in training probably also appear in the test data as they are reviews from the same 6 products.
        
        % From the in-domain results in the table, we observe the following: Lifelong-CRF still improves CRF, but the amount of improvement is considerably smaller. This is expected as we discuss above because most of the aspects appeared in training probably also appeared in the test data because they are reviews from the same 6 products. Again CRF+R does poorly due to the same reason. 
       % Interestingly, LSTM-CRF is doing better than the other methods, which shows that this deep learning method has some advantage when it is tested in-domain. Unfortunately, LSTM-CRF could not be incorporated with the lifelong learning capability. This is an interesting future research direction.  
        
%    \end{enumerate}
    
    \section{Conclusion}
    
    This paper proposed a lifelong learning method to enable CRF to leverage the knowledge gained from extraction results of previous domains (unlabeled) to improve its extraction. Experimental results showed the effectiveness of L-CRF. The current approach does not change the CRF model itself. In our future work, we plan to modify CRF so that it can consider previous extraction results as well as the knowledge in previous CRF models. 
    
\section*{Acknowledgments} 
This work was supported in part by grants from National Science Foundation (NSF) under grant no. IIS-1407927 and IIS-1650900. 
    
    
    \bibliography{acl2017}
    \bibliographystyle{acl_natbib}

\end{document}

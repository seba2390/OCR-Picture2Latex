\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{multirow}
\usepackage{makecell}
\usepackage{bbm}
\usepackage{commath}
\usepackage{lipsum}
\usepackage{stfloats}
\usepackage{comment}
\usepackage{caption}
\usepackage[dvipsnames]{xcolor}
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}
% \usepackage[accsupp]{axessibility}  % Improves PDF readability for those with disabilities.

\iccvfinalcopy % *** Uncomment this line for the final submission

\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}


\ificcvfinal\pagestyle{empty}\fi

\begin{document}

\setlength{\abovedisplayskip}{3pt}
\setlength{\belowdisplayskip}{3pt}

\makeatletter
\newcommand{\thickhline}{%
    \noalign {\ifnum 0=`}\fi \hrule height 1pt
    \futurelet \reserved@a \@xhline
}

\makeatother
\newcommand{\MATTHIAS}[1]{{\emph{\textcolor{red}{\textbf{Matthias:~#1}}}}}
\newcommand{\ANGIE}[1]{{\emph{\textcolor{blue}{Angie: #1}}}}
\newcommand{\JUSTUS}[1]{{\emph{\textcolor{magenta}{Justus: #1}}}}
\newcommand{\YAWAR}[1]{{\emph{\textcolor{ForestGreen}{Yawar:~#1}}}}
\newcommand{\FANGCHANG}[1]{{\emph{\textcolor{brown}{Fangchang:~#1}}}}
\newcommand{\TODO}[1]{{\emph{\textcolor{BrickRed}{TODO: #1}}}}


%%%%%%%%% TITLE
\title{RetrievalFuse: Neural 3D Scene Reconstruction with a Database}


\author{
Yawar Siddiqui$^1$~~~
Justus Thies$^{1,2}$~~~
Fangchang Ma$^3$~~~
Qi Shan$^3$~~~
Matthias Nie{\ss}ner$^1$
Angela Dai$^1$~~~
\vspace{0.2cm} \\ 
$^1$Technical University of Munich~~~
$^2$Max Planck Institute for Intelligent Systems, TÃ¼bingen~~~
$^3$Apple
\vspace{0.2cm} \\ 
}

\twocolumn[{%
	\renewcommand\twocolumn[1][]{#1}%
	\maketitle
	\begin{center}
	    \vspace{-0.65cm}
		\includegraphics[width=\linewidth]{figures/method_overview.jpg}
	    \vspace{-0.515cm}
		\captionof{figure}{
		We present a new approach for 3D reconstruction conditioned on sparse point clouds or low-resolution geometry. 
		Rather than encoding the full generative process in the neural network, which can struggle to represent local detail, we leverage an additional database of volumetric chunks from train scene data. 
		For a given input, multiple approximate reconstructions are first created with retrieved database chunks, which are then fused together with an attention-based blending~-- facilitating transfer of coherent structures and local detail from the retrieved train chunks to the output reconstruction.
		}
		\label{fig:teaser}
	\end{center}    
	\vspace{0.15cm}
}]

\maketitle
% Remove page # from the first page of camera-ready.
\ificcvfinal\thispagestyle{empty}\fi

%%%%%%%%% ABSTRACT
\input{00_abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}
\input{01_introduction}

\section{Related Works}
\input{02_related_works}

\section{Method}
\input{03_method}

\section{Results}
\input{04_experiments}

\section{Conclusion}
\input{05_conclusion}

\paragraph{Acknowledgements.}
{
\small
This work was supported by the Bavarian State Ministry of Science and the Arts  coordinated by the Bavarian Research Institute for Digital Transformation (bidt), a TUM-IAS Rudolf M{\"o}{\ss}bauer Fellowship, an NVidia Professorship Award, the ERC Starting Grant Scan2CAD (804724), and the German Research Foundation (DFG) Grant Making Machine Learning on Static and Dynamic 3D Data Practical. Apple was not involved in the evaluations and implementation of the code. 
}

\newpage
{\small
\bibliographystyle{ieee_fullname}
\bibliography{bib}
}

\clearpage
\newpage
\begin{appendix}
\input{06_appendix}
\end{appendix}

\end{document}

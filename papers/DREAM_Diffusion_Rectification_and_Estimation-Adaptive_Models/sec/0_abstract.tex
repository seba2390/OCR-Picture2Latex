\begin{abstract}
% Diffusion-based image super-resolution (SR) has gained significant attention for its generative quality, yet a notable training-sampling discrepancy in standard diffusion models limits their full potential. We introduce the Diffusion Rectification and Estimation-Adaptive Model (DREAM), a novel training paradigm requiring minimal code changes (just three lines) but offering substantial improvements in aligning training with sampling. DREAM comprises two components: \emph{diffusion rectification}, which adjusts training to reflect the sampling process,  and \emph{estimation adaptation}, which balances perception against distortion. Our experiments show that DREAM significantly outperforms baseline methods across various diffusion-based SR approaches, accelerates training convergence by $2$ to $3\times $,  and enhances sampling efficiency, needing $10$ to $20\times$ fewer steps for comparable or superior results. We hope DREAM will inspire a rethinking of diffusion model training paradigms.

We present DREAM, a novel training framework representing \textbf{D}iffusion \textbf{R}ectification and \textbf{E}stimation-\textbf{A}daptive \textbf{M}odels,  requiring minimal code changes (just three lines) yet significantly enhancing the alignment of training with sampling in diffusion models. DREAM features two components: \emph{diffusion rectification}, which adjusts training to reflect the sampling process,  and \emph{estimation adaptation}, which balances perception against distortion. When applied to image super-resolution (SR), DREAM adeptly navigates the tradeoff between minimizing distortion and preserving high image quality.  Experiments demonstrate DREAM's superiority over standard diffusion-based SR methods, showing a $2$ to $3\times $ faster training convergence and a $10$ to $20\times$ reduction in necessary sampling steps  to achieve comparable or superior results. We hope DREAM will inspire a rethinking of diffusion model training paradigms. 

% Diffusion-based image super-resolution (SR) has garnered significant attention due to their superior generative quality. However, a notable training-sampling discrepancy within the standard diffusion training limits its full potential. We present a simple yet effective Diffusion Rectification and Estimation-Adaptive Model (DREAM) serving as a new diffusion training paradigm. This framework necessitates as few as three lines of code change in the existing diffusion training, but substantially enhances the alignment between training and sampling, yielding remarkable improvements in balancing distortion and perception. DREAM contains two components: \emph{diffusion rectification}  and \emph{estimation adaptation}. The former amends the diffusion training behavior to accommodate the sampling process, while the latter aids in achieving a superior balance between perception and distortion. Experiments demonstrate that when applied to various diffusion-based SR methods, DREAM consistently outperforms the baseline methods by a significant margin, accelerates training convergence ($2$ to $3\times $ faster), and improves sampling efficiency (requiring $10$ to $20\times$ fewer sampling steps to attain competitive or superior performance). We hope that this simple framework will motivate a rethinking of the diffusion model training paradigm.

 
% Diffusion-based Image super-resolution (SR) methods has attracted significant interest given their superior generation quality. However, a discernible training-sampling discrepancy persists within the standard framework, limiting the full potential of current methods . Specifically, the denoiser networks work with the noisy image formed from the \textbf{ground-truth} high-resolution images during training while in the absence of this ground truth during sampling, the  networks uses the \textbf{estimation} from previous sampling step during sampling. Due to the prediction error, the input noisy images are  inconsistent between the two processes.  To bridge such gap, we introduce a novel training strategy (DREAM) comprising two components: \textbf{dynamic rectification} and \textbf{estimation-adaptation}. The dynamic rectification extends the existing diffusion model pipeline by integrating estimation, which serves as the foundation of aligning training process with sampling process. However, a sole reliance on dynamic rectification introduces a  tradeoff between the reduced distortion and poorer image-quality. By synergizing both approaches, estimation-adaptation proficiently marries the strengths of standard diffusion and dynamic rectification. The experimental results affirm the efficacy of the DREAM approach in harmonizing training with sampling. Due to the improved alignment,  our methods achieves notable enhancements in both distortion reduction and image quality across different datasets and preceding methods in either pixel space or latent space. Moreover, compared with standard diffusion training, our method can significantly accelerate the training convergence and improve the sampling efficiency.   

% \begin{itemize}[leftmargin=0.12in,topsep=-0.1em,itemsep=0.11em]
%     \item \textbf{\emph{By 10.3 Plan}:} 
%     \begin{itemize}
%         \item SR3 DIV finalize: 1. baseline, 2. p=? (3, 4)
%         \item SR3 Face finalize: p=? (p=2, p=3, p=4)
%         \item IDM Face finalize (p=2, p=3?)
%         \item ResShift DIV finalize: 1. baseline, 2. p=? (p=3, p=4)
%     \end{itemize}
%     \item \textbf{\emph{Title}: ???}
%     \item  \textbf{Introduction:} 
%     \begin{itemize}
%         \item training and sampling discrepency
%         \item SA
%         \item achieve the balance between SA and vanilla via dynamic learning scheduler
%         \item higher regression metrics + maintaining image quality
%     \end{itemize}
%     \item \textbf{\emph{Background}}
%     \item \textbf{\emph{Method}}
%     \begin{itemize}
%         \item SA
%         \begin{itemize}
%             \item intro, experiments; SR3 on DIV (v.s. baseline SA)
%             \item pros and cons
%             \item gradient analysis
%             \item learning patterns for different timestamps
%         \end{itemize}
%         \item Dynamic Learning Scheduler
%         \begin{itemize}
%             \item detailed info
%             \item interpretation
%             \item analysis with supporting experiments
%         \end{itemize}
%     \end{itemize}
%     \item \textbf{\emph{Experiments}}
%     \begin{itemize}
%         \item Datasets: Face and DIV;
%         \item Models: 
%         \begin{itemize}
%             \item Image Space: SR3 (DIV and Face)and IDM (Face);
%             \item Latent Space: ResShift (DIV)
%         \end{itemize}
%         \item Qualitative and quantitative metrics
%         \item Other implications:
%         \begin{itemize}
%             \item Training and Sampling efficiency
%             \item fine-tuning?
%             \item different noise? (dicussion)
%             \item incoporate LDL?
%             \item Continuous consistency?
%         \end{itemize}
%     \end{itemize}
% \end{itemize}
\end{abstract}
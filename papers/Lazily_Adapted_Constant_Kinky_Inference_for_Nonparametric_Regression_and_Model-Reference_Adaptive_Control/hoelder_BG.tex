\subsection{H\"older and Lipschitz continuity for inference}%\label{sec:HoeldNLipfacts}
\label{sec:Hoelder_brief}
\subsubsection{Introduction and related work}



H\"older continuous functions are uniformly continuous functions that may exhibit infinitely many points of non-differentiability and yet are sufficiently regular to facilitate inference. That is, they have properties that make it possible to make assertions of global properties on the basis of a finite function sample. 

H\"older continuity is a generalisation of Lipschitz continuity.  Lipschitz properties are widely used in applied mathematics to establish error bounds and, among many other, find application in optimisation \cite{Shubert:72,direct:93} and quadrature \cite{Baran2008,curbera1998,dereich2006} and are a key property to establish convergence properties of approximation rules in (stochastic) differential equations \cite{kloedenandplaten1992,Gardiner2009}. 
Furthermore, most machine learning methods for function interpolation seem to impose smoothness (and thereby, H\"older continuity) on the function. For instance, with our Lem. \ref{lem:Hoeldarithmetic} derived below, it would be possible to show that any finite \textit{radial basis function neural network} \cite{Broomhead1988} with a smooth basis function is H\"older continuous on a compact domain. Or, a \textit{Gaussian process} with a smooth covariance function also has a smooth mean function and a.s. smooth sample paths  \cite{GPbook:2006,grimmetbook2001}. Therefore, posterior inference over functions on compact support made with such a Gaussian process on the basis of a finite sample is H\"older continuous. 


Recently, we have become aware of related work published in mathematical and operations research journals \cite{Cooper2006,Cooper1995,Zabinsky2003,Beliakov2006,Beliakovsmoothing2007}. For instance, Zabinsky et. al. \cite{Zabinsky2003} consider the problem of estimating a one-dimensional Lipschitz function (with respect to the canonical norm-induced metric). Similar to the analysis we employ to establish our guarantees, they use a pair of bounding functions and make predictions by taking the average of these functions. While we have developed our kinky inference rule independently, it can be seen as a generalisation of their approach. Our method provides extensions to H\"older continuous multi-output functions over general, multi-dimensional (pseudo-) metric spaces, can cope with with erroneous observations and inputs, can fold in additional knowledge about boundedness, learn parameters from data and provides different guarantees such as (uniform) convergence of the prediction uncertainty. 
As part of the analysis of our method, we construct delimiting functions we refer to as \textit{ceiling} and \textit{floor} functions. The construction of similar functions is a recurring theme that, in the standard Lipschitz context, can be found in global  optimisation \cite{Shubert:72}, quadrature \cite{Baran2008}, interpolation \cite{Beliakov2006,Beliakovsmoothing2007}, as well as in the analysis of linear splines for function estimation \cite{Cooper1995}. Cooper \cite{Cooper2006,Cooper1995} utilises such upper and lower bound functions in a multi-dimensional setting to derive probabilistic PAC-type error bounds \cite{Valiant1984} for a linear interpolation rule. He assumes the data is sampled uniformly at random on a hypercube domain. This precludes the application of his results to much of our control applications where the data normally is collected along continuous trajectories visited by a controlled plant. Our inference rule is different from his and our guarantees do not rely on distributional assumptions. This of course is important in control settings where the common assumption that the input data was drawn independently from a fixed distribution typically is not met.
%As a special case of our kinky inference framework, we consider a case, called \textit{kNN-KI}. Here, the inference over function values is based on up to (approximate) k nearest neighbours aiming to reduce computational prediction effort to log-time. Approaches to this end include maintaining a data structure for fast nearest neighbour search \cite{Bentleykdtree:1975} or utilising locally sensitive hash functions \cite{RusselNorvigbook2009}. 
In this thread of works, perhaps the work that is most closely related to ours is the function interpolation method of Beliakov \cite{Beliakov2006} that is a special case of a kinky inference rule: For a single-output function that is Lipschitz with respect to a special input space norm and where the data is error-free, the authour provides an algorithm that promises logarithmic prediction time. Unfortunately, many of his assumptions are unrealistic in a control setting. And, the improved prediction time is achieved by constructing a data structure from batch data which precludes its use in an online learning setting. However, future work might explore in how far his ideas can be 
converted into an online learning rule. Furthermore, in learning situations where Beliakov's interpolation method is applicable, our theoretical results extend to his work. For instance, our results show how Lipschitz constant estimation can be harnessed to render his approach a universal approximator.

Other work of relevance can be found in analysis. For instance, Miculescu \cite{Miculescu2000} presents work proving that any continuous function on a metric space is a uniform limit of a sequence of \emph{locally} Lipschitz functions and also mentions that the stronger statement, that every function is a limit of a sequence of globally Lipschitz functions, is not true in general. However, he cites earlier work \cite{Georganopoulos1967} that does show that every real-valued continuous function on \emph{compact} domain is a uniform limit of a sequence of Lipschitz functions. In some sense, our work develops a related statement as a by-product. 
From our convergence guarantee of the LACKI rule, we have derived constructive method for showing 
that any continuous function on compact domain is the uniform limit of a sequence of H\"older functions up to an arbitrarily small error.

Finally, in the context of control, Milanese and Novara \cite{Milanese2004} considered NSM methods for interpolation. For a fixed Lipschitz constant, their prediction rule can be
seen as a special case of ours without the $\lbf$ and $\ubf$ parameters and with special choices of metrics. Similar to us, they do consider the problem of estimating the Lipschitz constant from the data and consider bounded noise. However, they obtain the Lipschitz constant estimate via the maximum partial derivative of an arbitrarily chosen fitted parametric model of a bounded input set. And, they give no guarantees on the quality of the resulting estimator that is fitted to the data like this nor do they discuss the impact of the choice of parametric model or the fitting method on the quality of the estimator.
 
%\jcom{Need to read \cite{Georganopoulos1967}}
%\jcom{Need to reassess the following in the light of the newly found control paper:}
%None of the aforementioned works seems to consider interval-bounded input uncertainty and observational errors, fold in additional knowledge such as boundedness or considers inference over multi-output functions as we do. Most importantly the combination with our online constant estimation rule, leading to our LACKI inference rule, as well as our universal approximation guarantees are novel.
%Finally, we are not aware of any work that employs H\"older-based methods in the context of model-reference adaptive control. 


%In particular, we will look into the inference problems of bounded optimisation and quadrature. That is, based on the knowledge of a sample of a H\"older continuous function we will derive upper and lower bounds on its maximum, minimum and definite Riemann integral. In addition we will touch upon adaptive algorithms that can utilise knowledge of the function's H\"older properties to guide exploration. That is, since the regularity of the function allows us to provide interval bounds on the uncertainty of the function, the magnitude of the uncertainty can be a guide to identify regions that are to be sampled next in order to maximise the shrinkage of the provided error bounds. 
%\jcom{The latter is more the 1-dim case, which I may or may not include}\\

\subsubsection{Basic facts and derivations}
In preparation of subsequent parts of the work that take advantage of H\"older properties this section will proceed to establish essential prerequisites.
The remainder of this section is structured as follows: Firstly, we will go over basic definitions and engage in some preliminary derivations that will be of importance throughout this work.
While we do not claim novelty on any of the results we provide proofs for in this section, we had not found them in the literature and hence, had to derive them on our own.

Firstly, we commence with introducing the notions of (pseudo-) metric spaces.

\begin{defn}[(Pseudo-) metrics]
Let $\inspace$ be a set. A mapping $\metric_\inspace: \inspace^2 \to \Real$ is called a \emph{pseudo-metric} if it positive ($\forall x,x' \in \inspace: \metric_\inspace(x,x') \geq 0$) and satisfies the triangle inequality ($\forall x,x',x'' \in \inspace: \metric(x,x') \leq \metric_\inspace(x,x'') + \metric (x'',x')$). If furthermore the pseudo-metric $\metric$ is definite $(i.e. \forall x,x' \in \inspace_\inspace: \metric_\inspace(x,x') =0 \Leftrightarrow x=x')$ then 
the mapping $\metric$ is called a \emph{metric}. The set $\inspace$ endowed with a (pseudo-) metric $\metric_\inspace: \inspace^2 \to \Real$ or the pair $(\inspace, \metric_\inspace)$ are called \emph{(pseudo-) metric space}.
 \end{defn}

\begin{defn} 
Let $(\inspace ,\metric_\inspace ), (\outspace , \metric_\outspace )$ be two (pseudo-) metric spaces and 
$I \subset \inspace$ be an open set. A function $f: \inspace \to \outspace $ is called (L-p-) \emph{H\"older} 
(continuous) on $I \subset \inspace$ if there exists a \emph{(H\"older) constant} $L \geq 0$ and \emph{(H\"older) 
exponent} $p\geq 0$ such that 
\[\forall x,x' \in I : \metric_\outspace \bigl(f(x),f(x')\bigr) \leq L \, \bigl( \metric_\inspace (x,x') \bigr)^p. \]
We denote the space of all L-p- H\"older functions by $\hoelset{L}{}{p}$.
\end{defn}

H\"older functions are known to be uniformly continuous. 
A special case of importance is the class of $L$-\textit{Lipschitz} functions. These are H\"older continuous 
functions with exponent $p=1$. In this context, coefficient $L$ is referred to as\textit{ Lipschitz constant} or \textit{Lipschitz number}.

\begin{ex}[Square root function]\label{ex:sqrtfctHoelder}
As an example of a H\"older function that is not Lipschitz we can consider $x \mapsto \sqrt x$ on domain $I = [0+\epsilon,c]$ where 
$c >\epsilon \geq 0 $. For $\epsilon >0 $ the function is Lipschitz with $L = \sup_{x \in I} \frac{1} {2 \sqrt{x}}$. We can see that the 
coefficient grows infinitely large as $\epsilon \to 0$. By contrast, the function is H\"older continuous 
with H\"older coefficient $L=1$ and exponent $p=\frac 1 2 $ for any bounded $I \subset \Real$.
We can see this as follows: Let $\epsilon =0,$ $x,y \in I$ and, without loss of generality,  $y \geq x$. Let $\xi := \sqrt{x}, \gamma := \sqrt{y}$ and thus, $\gamma \geq \xi$. We have:
$\xi \leq \gamma $ $\Leftrightarrow 2 \xi^2 \leq 2\xi\gamma$ $\Leftrightarrow \gamma^2 - 2 \xi\gamma + \xi^2  \leq \gamma^2 - \xi^2$ $\Leftrightarrow (\gamma-\xi)^2  \leq \gamma^2-\xi^2$ $\Leftrightarrow \abs{\gamma-\xi}^2  \leq \abs{\gamma^2-\xi^2}$
$\Leftrightarrow \abs{\gamma-\xi}  \leq \sqrt{\abs{\gamma^2-\xi^2}}$  $\Leftrightarrow \abs{\sqrt{x}-\sqrt{y}} \leq \abs{y-x}^{\frac{1}{2}}$. Since, $x,y$ were chosen arbitrarily, we have shown H\"older continuity as desired.
\end{ex}

Most commonly, one considers H\"older continuity for the special case of the standard metric induced by a norm, i.e.  $\metric(x,x') = \norm{x-x'}$.
For a function $f: \inspace \to \outspace$, the H\"older condition becomes:
\[\forall x,x' \in I : \norm{f(x)-f(x')}_\outspace \leq L \, \norm{x-x'}_\inspace^p. \]

Similarly, we can consider H\"older continuity for each output component: 

\begin{defn} \label{def:outputwisehoelder}
Let $\outspace \subseteq \Real^m $ and $\inspace$ be a space endowed with a metric (or indeed a semi-metric) $\metric_\inspace$. Then, the function $f: \inspace \to \outspace$ is output-component-wise H\"older continuous with exponent $p$ and constant $L \in \Real^m_{\geq 0}$ if $f \in \hoelset L { } p$ where
$\hoelset L {\metric_\inspace} p:= \bigl\{ \phi: \inspace \to \outspace \,\ | \, \forall j \in \{1,...,m \}, \forall x,x' \in \inspace: \abs{\phi_j(x) - \phi_j(x')} \leq L_j \metric^p_\inspace(x,x') \bigr\}$
is the set of all functions whose component functions are H\"older continuous with respect to input space metric $\metric_\inspace$ and an output space metric that is induced by the canonical norm $\metric_{\outspace} (x,x')= \abs{x-x'}$.  
\end{defn}

\begin{remark}[Best H\"older constant]
Note for $p \in (0,1], 0 \leq L_1 \leq L_2$ we have $\hoelset {L_1} {\metric_\inspace} p \subseteq \hoelset {L_2} { } p$. The smallest $L^* \geq 0$ such that function if is $L^*-p-$ H\"older, $f \in \hoelset {L^*} {\metric_\inspace} p$, is called the \emph{best} H\"older constant of $f$.
\end{remark}

Generally, it is obviously true that $\hoelset{L}{}{p} \subseteq \hoelset{L'}{}{p}$ for $L' \geq L$.
With regard to the H\"older exponent, we will now show that smaller exponents are less restrictive than larger ones. 




\begin{lem} \label{lem:hoeldexpprop2}
Let $\inspace$ be the input space (not necessarily bounded). For some $p \in (0,1], L \geq 0$ assume that  and $f:\inspace \to \outspace$ is locally $L-p$-H\"older continuous.
Then we have: (i) for any $ q \in (0,p]$, f is also locally $L-q$-H\"older. 
(ii) If $f:\inspace \to \outspace$ is bounded with $\sup_{x,x' \in \inspace} \metric_\outspace (f(x),f(x')) \leq B \in \Real$ and globally $L-p$ H\"older then $f$ is globally $L^*-q$-H\"older, where $L^* := \max\{L,B \}$ and $q \in (0,p]$. In particular, on compact support, Lipschitz continuity entails \emph{H\"older} continuity for any H\"older exponent $p \in [0,1)$.
\begin{proof}
(i) Let $p \in (0,1], f \in \hoelset L { } p $ and $p = q+r, r \in [0,1)$. Let $\xi \in \inspace$ and $I$ denote the intersection of the domain with an $\epsilon$-ball around $\xi$ such that $f$ satisfies the H\"older condition on $I$ and such that $\sup_{x,x' \in I} \metric_\inspace(x,x') \leq 1$.  For all $x,x' \in I$ we have $\metric_\outspace (f(x),f(x')) \leq L\metric_\inspace^p (x,x') = L \metric_\inspace^q(x,x') \metric_\inspace^r(x,x') \leq L \metric_\inspace^q(x,x')$ where the last inequality holds since $r \in [0,1)$ and $\sup_{x,x' \in I} \metric_\inspace(x,x') \leq 1$.

(ii) Let $x,x' \in \inspace$. If $\metric_\inspace(x,x') \leq 1$ we can show $\metric_\outspace (f(x),f(x'))  \leq L \metric_\inspace^q(x,x')$ following through the same sequence of inequalities as above in the proof of (i). Now, let $\metric(x',x) >1$. We have $\metric_\outspace (f(x),f(x')) \leq B \leq B  \metric_\inspace(x,x')^q$.
\end{proof}
\end{lem}

%Note for compact domains local H\"older continuity implies global H\"older continuity with the same parameters. Therefore Lem. \ref{lem:hoeldexpprop1} would also be implied 
%by Lem. \ref{lem:hoeldexpprop2}.(i) in cases where $\inspace$ is compact.



%We conclude this section by the following theorem stating that any concatenation of H\"older continuous functions is H\"older continuous:
%
%\begin{thm} \label{thm:concathoelder}
%Let $(\statespace, \metric)$ be a metric space and $f,g : \statespace \to \statespace$ be two H\"older continuous mappings with H\"older constants $L_f, L_g$ and H\"older exponents $p_f,p_g$, respectively.
%Then, the concatenation $h=f \circ g: \statespace \to \statespace $ is also H\"older continuous with H\"older constant $L_h:= L_f L_g^{p_f}$ and exponent $p_h:=p_g \, p_f$.
%That is, 
%\[\forall \state,\state' \in \statespace: \metric\bigl(h(\state),h(\state')\bigr) \leq L_h \bigl(\metric(\state,\state')\bigr)^{p_h}.\]
%\begin{proof}
%%\begin{align}
%$\metric\bigl(f \circ g(\state),f\circ g(\state')\bigr) \leq L_f  \Bigl(\metric(g(\state),g(\state'))\Bigr)^{p_f}$
%$\leq L_f  \Bigl(L_g \metric(\state,\state')^{p_g}\Bigr)^{p_f}$ $= L_f L_g^{p_f}   \Bigl(\metric(\state,\state')\Bigr)^{p_g\, p_f} $ where in the first step we were using Hoelder-continuity of $f$ and in the second, we were using H\"older continuity of $g$ combined with the fact that $(\cdot)^{p_f}$ is a monotonically increasing  function. 
%
%\end{proof}
%\end{thm} 
%In conjunction with H\"older properties of the square root function established in Ex. \ref{ex:sqrtfctHoelder}, Thm. 
%\ref{thm:concathoelder} immediately yields the following result:
%\begin{cor}
%If $f: \statespace \to \statespace $ is H\"older continuous with constant $L_f$ and exponent $p_f$ then $\sqrt{f}$ also is Hoelder, having  H\"older constant $\sqrt{L_f}$ and exponent $p_f$.
%\end{cor}


\begin{thm} \label{thm:hoelderconcat}
Let $(\statespace, \d)$ be a metric space and $f,g : \statespace \to \statespace$ be two H\"older continuous mappings with H\"older constants $L(f), L(g)$ and H\"older exponents $p_f,p_g$, respectively.
Then, the concatenation $h=f \circ g: \statespace \to \statespace $ is also H\"older continuous with H\"older constant $L(h):= L(f) L(g)^{p_f}$ and exponent $p_h:=p_g \, p_f$.
That is, 
\[\forall \state,\state' \in \statespace: \d\bigl(h(\state),h(\state')\bigr) \leq L(h) \, \bigl(\d(\state,\state')\bigr)^{p_h}.\]
\begin{proof}
%\begin{align}
$\d\bigl(f \circ g(\state),f\circ g(\state')\bigr)$ $\leq L(f)\,  \Bigl(\d(g(\state),g(\state'))\Bigr)^{p_f}$
$\leq L(f)\,  \Bigl(L(g)\, \d(\state,\state')^{p_g}\Bigr)^{p_f}$ 

$= L(f)\, L(g)\,^{p_f}   \Bigl(\d(\state,\state')\Bigr)^{p_g\, p_f} $ where in the first step we were using H\"older-continuity of $f$ and in the second, we were using H\"older continuity of $g$ combined with the fact that $(\cdot)^{p_f}$ is a monotonically increasing  function. 
\end{proof}
\end{thm} 






%A special case of H\"older continuity is Lipschitz continuity. A Lipschitz continuous function is H\"older continuous with exponent 1.
%If the metric space is $(\Real,(x,y) \mapsto \abs{x-y})$, $f$ is Lipschitz with constant $L(f)$ if $\forall t,t': \abs{f(t)-f(t')} \leq L(f) \, \abs{t-t'}$. 

Several numerical methods, such as Lipschitz optimisation \cite{Shubert:72}, rely on the knowledge of a Lipschitz constant. In the more general case of H\"older continuous functions this will correspond to the need of knowing a H\"older constant and exponent. To avoid having to derive these for each new function from first principles, we establish the following collection of facts that allows us determine bounds on H\"older constants of combinations of functions with known H\"older parameters.
While we provide proofs for a restatement in the H\"older continuous setting, a number of the following statements have also been proven in \cite{Weaver1999} in the context of Lipschitz algebras.





\begin{lem}[H\"older arithmetic] \label{lem:Hoeldarithmetic}
Let, $I,J \subset \inspace$ where $\inspace$ is a metric space endowed with metric $\metric$. Let $f : \inspace \to \Real$ be H\"older on $I$ with constant $L_I (f) \in \Real_+$ 
and $g :\inspace \to \Real$ be H\"older on $J$ with constant $L_J (g) \in \Real_+$. Assume both functions have the same H\"older exponent $p \in (0,1]$. That is, $\forall x, x' \in \inspace: \abs{f(x)-f(x')} \leq L(f) \metric(x,x')^p$ and  $\forall x, x' \in \inspace: \abs{g(x)-g(x')} \leq L(g)  \metric(x,x')^p$.
We have:

\begin{enumerate}
	\item Mapping $x \mapsto |f(x)|$ is H\"older on $I$ with constant $L_I(f)$ and exponent $p_f$.
	\item If $g$ is H\"older on all of $J=f(I)$ the concatenation $g \circ f: t \mapsto g(f(t))$ is H\"older on $I$ with constant 
	      $L_I(g \circ f) \leq$ $L_J (g) \, L_I^p(f)$ and exponent $p^2$.
	\item Let $r \in \Real$. $r \, f: x \mapsto r \, f(x)$ is H\"older on $I$ having a constant $L_I (r \,f) = |r| \, L_I(f)$.
	\item $f+g: x \mapsto f(x) + g(x)$ has H\"older constant at most $L_I(f) + L_J(g)$.
	\item Let $m_f = \sup_{x\in \inspace } f(x)$ and $m_g = \sup_{x \in \inspace } g(x)$. Product function $f\cdot g: x \mapsto f(x) \, g(x)$ has H\"older exponent $p$ and a H\"older constant on $I$ which is at most $(m_f \, L_J(g)+ m_g \, L_I(f))$.
	%\item Let $\tilde h(x) = \min\{f(x),g(x) \}$, $h(x) = \max\{f(x), g(x) \}, \forall x \in \inspace  \cap J$. We have $L_{I \cap J}(h) \leq \max\{L_I(f),L_J(g)\}$ and $L_{I \cap J}(\tilde h) \leq \max\{L_I(f),L_J(g)\}$.	
	\item For some countable index set $\indsett$, let the sequence of functions $f_i$ be H\"older with exponent $p$ and constant $L(f_i)$ each. Furthermore, let $H(x) =\sup_{i \in \indsett} f_i(x) $ and $h(x) := \inf_{i \in \indsett} f_i(x)$ be finite for all $x$. Then $H,h$ are also H\"older with exponent $p$ and have a H\"older constant which is at most $\sup_{i \in \indsett} L(f_i)$.
	\item Let $b := \inf_{x \in \inspace }| f(x)| > 0$ and let 
	$\phi(x) = \frac{1}{f(x)}, \forall x \in \inspace$ be well-defined.  
	      Then $L_I(\phi) \leq b^{-2} \, L_I(f)$.  
	\item Let $p=1$ (that is we consider the Lipschitz case), let $I$ be convex and $\metric(x,x') = \norm{x-x'}$ where $\norm{\cdot}$ is a norm that induces a sub-multiplicative matrix norm (e.g. all $p-$ norms are valid). $f$ cont. differentiable on I $\Rightarrow$ $L_I(f) \leq \sup_{x \in I } \norm{\nabla f(x)}. $ 
	For one-dimensional input space, $\inspace = \Real$, $L_I(f) = \sup_{x \in I } \abs{\nabla f(x)}$ is the smallest Lipschitz number. 
	 \item Let $c \in \Real$, $f( t) = c, \forall x \in I $. Then $f$ is H\"older continuous with constant $L_I(f) =0$ and for any coefficient $p_f \in \Real$.  
	\item $L_I(f^2) \leq 2 \, L_I(f)\, \sup_{t \in I} f\,$.
	\item With conditions as in 8), and input space dimension one, we have $\forall q \in \mathbb Q : L_I(f^q) = |q| \,\sup_{\tau \in \indset } |f^{q-1}(\tau) \, \dot f(\tau)| $.
\end{enumerate}
\begin{proof}

\textbf{1)}  We show $|f|$ has the same constant and exponent as $f$. Let $X,X' \in \inspace $ arbitrary. 
We enter a case differentiation:

\textit{1st case: $f(x), f(x') \geq 0$}. 

Hence, $\bigl| \abs{f(x)}- \abs{f(x')} \bigr| = \bigl| f(x) - f(x') \bigr|  \stackrel{f \,Hoelder}{\leq} L_I(f) \metric(x,x')^{p}$.\\

\textit{2nd case: $f(x) \geq 0, f(x') \leq 0$.} 

Note, $|y| = - y$, iff $y \leq 0$. Hence,  $\bigl| |f(x)| - |f(x')| \bigr| \leq \bigl| |f(x)| + |f(x')| \bigr| $
$= \bigl| |f(x)| - f(x') \bigr|  =  \bigl| f(x) - f(x') \bigr| \leq L_I(f) \, \metric(x,x')^{p}$.\\

\textit{3rd case: $f(x) \leq 0, f(x') \geq 0$.} Completely analogous to the second case.\\

\textit{4th case: $f(x), f(x') \leq 0$}. 

$\bigl| |f(x)| - |f(x')| \bigr| = \bigl| f(x') - f(x) \bigr|= \bigl| f(x) - f(x') \bigr|  \stackrel{f \, Hoelder}{\leq} L_I(f) \metric(x,x')^{p}$.\\

The remaining points are also proven in \cite{Weaver1999} in the context of Lipschitz functions.

\textbf{2)} Special case of Thm. \ref{thm:hoelderconcat}.
% For arbitrary $t,t' \in \indset $ we have:
%
%$\bigl| g(f(t)) - g(f(t'))| \bigr| \leq L_J(g) \, |f(t) - f(t') | \leq L_J(g) \, L_I(f)\, |t-t'|$ 
%where the two inequalities are due to the Lipschitz properties of $g$ and $f$, respectively.\\

\textbf{3)}  For arbitrary $x,x' \in \inspace , r \in \Real$ we have:

$\bigl| r \, f(x) - r \, f(x')| \bigr| = |r|\, |f(x) - f(x')| \leq |r| \,L_I(f)\,  \metric(x,x')^{p}$.\\ 

\textbf{4)}  For arbitrary $x,x' \in \inspace , r \in \Real$ we have:

$\bigl| g(x) + f(x) - (g(x') + f(x'))| \bigr| = \bigl| g(x)  - g(x') + f(x)- f(x')| \bigr|$ 
$\leq \bigl| g(x)  - g(x')\bigr|  + \bigl| f(x)- f(x')| \bigr|$ $\leq (L_J(g)+L_I(f))\,  \metric(x,x')^{p}$.\\

\textbf{5)}  Let  $x,x' \in \inspace $, $d := f(t) - f(t')$.

$\bigl| g(x) f(x) - g(x')  f(x') \bigr| = \bigl| g(x) (f(x') +d) - g(x') f(x') \bigr|$ 
$= \bigl|\bigl( g(x) - g(x') \bigl)  f(x')+ g(x)  d \bigr|  $

$\leq \bigl| g(x) - g(x') \bigr|  |f(x')|   + \bigl|g(x)\bigr| \,  |d|  $
$\leq L_I(g) \metric(x,x')^p  |f(x')|   + \bigl|g(x)\bigr| \,  L_I(f) \metric(x,x')^p  $

$\leq L_I(g) \metric(x,x')^p  \sup_{x' \in \inspace } \{|f(x')|\}  \\ + \sup_{x \in \inspace }\{\bigl|g(x)\bigr|\} \,  L_I(f) \metric(x,x')^p  $

$= \Bigl(L_I(g)  \sup_{x' \in \inspace } \{|f(x')|\}   \\+ \sup_{x \in \inspace }\{\bigl|g(x)\bigr|\} \,  L_I(f)\Bigl) \metric(x,x')^p  $.\\

\textbf{6)}  The proof of Proposition 1.5.5 in \cite{Weaver1999} proves our statement if one replaces their 
metric $\rho$ by $\metric^p$.

\textbf{7)}  Let  $x,x' \in \inspace $.
$\bigl| \frac{1}{f(x)} - \frac{1}{f(x')} \bigr|$ 
$=\bigl| \frac{f(x')}{f(x') f(x)} -\frac{f(x)}{f(x') f(x)} \bigr|$ 
$= \frac{\bigl|f(x')-f(x) \bigr|}{\bigl|f(x')\bigr| \bigr| f(x)\bigr|}$ 
$\leq \frac{L_I(f) \metric(x,x')^p}{\inf_{x \in \inspace } |f(x)|^2}$.\\

\textbf{8)} Let $p=1$ and $\metric(x,x') = \norm{x-x'}$ be a norm that induces a sub-multiplicative matrix norm. Define $\ell := \sup_{x \in I } \norm{ \nabla f(x) } = L_I(f)$. 
Firstly, we show that it is a Lipschitz constant: Let $x,x' \in I $ and 
$\overline{xx'} := \{tx + (1-t) x' \, | \, t \in [0,1]\}$. 
%$\overline{xx'} := \{y | \exists t \in [0,1] : y = tx + (1-t) x'\}$. 
Owing to convexity of I, $\overline{xx'} \subset I$. Due to the mean value theorem $\exists \xi \in \overline{xx'} \subset I: |f(x) - f(x')|=  T_\xi (x-x')$. where $T_\xi (x) = \SP{\nabla f(\xi)}{ x}$ is a linear OP. Assuming the derivative of $f$ is bounded, $T_\xi$ is a bounded OP and we have $\abs{T_\xi (x-x') } \leq \matnorm{T_\xi} \norm{x-x'}$ where 
$\matnorm{T_\xi} = \sup_{\norm{x} = 1} \abs{\SP{\nabla f(\xi)}{x}} \leq \norm{\nabla f(\xi)}$. In conjunction,
$|f(x) - f(x')| \leq \norm{\nabla f(\xi)} \norm{x-x'}$. 

Secondly, we show that $\ell$ is the smallest Lipschitz constant in the one-dimensional case: Let $\bar \ell$ be another Lipschitz constant on $I$ such that $\bar \ell \leq \ell$. Of course, here $\norm{\cdot} = \abs{\cdot}$. Since $I$ is compact and $\norm{\nabla f(\cdot) }$ is continuous, there is some $\xi \in I$ such that $\norm{\nabla f(\xi)} = \sup_{x \in I} \norm{\nabla f(\xi)} = \ell$. Pick any sequence $(y_k)_{k=1}^\infty$ contained in $I$ such that $y_k \stackrel{k \to \infty}{\longrightarrow} \xi$ and $y_k \neq \xi$.
$\forall k: y_k \in I $ and $\bar \ell$ is a Lipschitz constant on $I$. Hence, $ \bar \ell \geq \frac{|f(y_k) - f(\xi)|}{\norm{y_k-\xi}}\stackrel{k \to \infty}{\longrightarrow} \norm{ \nabla f(\xi)} = \ell$. Thus, $\bar \ell = \ell$.

\textbf{9)} Trivial. 

\textbf{10)} Special case of property 5).

\textbf{11)} $L(f^q) \stackrel{8)}{=} \sup_{\tau \in \indset } |\dif{}{t} f^q(\tau)| = |q| \,\sup_{\tau \in \indset } |f^{q-1}(\tau) \, \dot f(\tau)| $. 
\end{proof}
\end{lem} 

As a simple illustration, assume we desire to establish that $f(t) = \max\{ 1- 3 \sin(t), \exp\bigl(- \sin(t) \bigr)\}$ is Lipschitz and to find a Lipschitz number on $\Real$. Application of 8. shows that $t \mapsto \sin(t)$ and $t \mapsto \exp(- t)$ have a Lipschitz number of $1$. Application, of 2., 9. 1. and 6. then show that $L(f) =3$ is a Lipschitz number of $f$.


%As another example we consider the standard deviation of the Ornstein-Uhlenbeck process:
%\begin{ex} \label{ex:hoelderOUstd}
%Consider the function $h(t) = f \circ g(t)$ where $f(\cdot) = \sqrt \cdot$ is the square root function and $g(t) = \frac{B^2}{2 K} (1- \fexp{-2Kt}) $, $K >0$. $g$ is the non-stationary factor of the variance trajectory of an Ornstein-Uhlenbeck process (cf. Sec. \ref{sec:OUprocess}). We show that $h$ is H\"older and has constant $L(h)= \sqrt{2K}$ and H\"older exponent $p_h = \frac 1 2$. This can be easily done by applying Lem. \ref{lem:Hoeldarithmetic}.8 to show that $L(g)$ is Lipschitz with constant $L(g) = B^2 $ and then combining the H\"older constant and exponent derived in Ex. \ref{ex:sqrtfctHoelder} with Thm. \ref{thm:hoelderconcat} to yield the H\"older exponent $p_h = p_g p_f = \frac 1 2$ and constant $L(h) = 1 \sqrt{L(g)}  = \abs B$.  
%\end{ex}

%An example important to our considerations above is the establishment of Lipschitz bounds of an RBFN:
%\begin{ex} \label{ex:hoelderRBFN}

%\end{ex}

\subsection{H\"older continuity of the exponentiated map }

 %
The main objective of this subsection is to show that, for each $s \in \inspace$, the function $\phi_s: x \mapsto L \metric(x,s)^p$ is H\"older continuous with coefficient $L$ and exponent $p$ with respect to (pseudo-) metric $\metric: \inspace^2 \to \Real$. This is important in our derivations since these maps are essential building blocks of the kinky inference procedure. Therefore it is easy to employ Lem. \ref{lem:Hoeldarithmetic} to show that the full kinky inference rule is H\"older continuous.

To establish the H\"older regularity result, we will first show that $(x,y) \mapsto \metric(x,y)^p$, for $p \in (0,1] $, is a metric.  This can be utilised to show that
$\phi_s \in \hoelset L \metric p$.




Before proceeding we need to establish a few facts. 
Firstly, we remind ourselves of the following well-known fact:
\begin{lem} \label{lem:pd_n_concave_subadditive}
A nonnegative, concave function $g:\Real_{\geq 0} \to \Real$ with $g(0) = 0$ is subadditive. 
That is, $\forall x,y \in \Real_{\geq 0}: g(x+y) \leq g(x) + g(y)$. 
 \begin{proof}
If $x = y = 0$ then subadditivity trivally holds:  $0=g(x+y) \leq g(x) + g(y) = 0$.
So, let $x, y \in \Real_+$ such that $x >0 \vee y >0$.
We have, $g( x +y) = \frac{x}{x+y} g(x+y) + \frac{y}{x+y} g(x+y) \leq g(\frac{x}{x+y} (x+y) ) +  g(\frac{y}{x+y}(x+y)) = g(x) + g(y)$.
Taking into account that $\frac{x}{x+y}, \frac{x}{x+y} \in [0,1]$, the last inequality can be seen as follows:

 Since $g$ is concave we have 
$\forall p \in [0,1], x \in \Real: g(p x) =  g(px + (1-p) 0) \geq p g(x) + (1-p) g(0) \geq p g(x)  $. The last inequality follows from $g(0) \geq 0$.
\end{proof}
\end{lem}

\begin{lem} \label{lem:x2p_pdNsubadd}
 Let $h: \begin{cases} \Real_{\geq 0} \to \Real_{\geq 0},\\ \, x \mapsto x^p\end{cases}$, for $p \in (0,1] $. $h$ is positive definite and subadditive. 
 That is, (i) $h(0) = 0 $ and  $h(x) > 0, \forall x \neq 0$ and (ii) $\forall x,y \in \Real_{\geq 0}: h(x+y) \leq h(x) + h(y)  $.
 Moreover, $h$ is concave. If $p \in (0,1)$, h is strictly concave. 
 
\begin{proof}
\textit{Pos. def. :} $h(0) = 0$.  Also $\lim_{x \to 0_+} h(x) =0$. Since $\nabla h (x) = p h^{p-1}(x) >0 $ for $x >0$, $h$ is strictly monotonically increasing on $\Real_+$. Hence, $h(x) > 0, \forall x >0$. 

\textit{Concavity:} If $p =1$, $h$ is linear and hence, concave. If $p \in (0,1)$, $\nabla^2 h(x) = p (p-1) h(x)^{p-2} > 0$ regardless of $x$.

\textit{Subadditivity:} Follows directly with Lem. \ref{lem:pd_n_concave_subadditive} on the basis of established positive definiteness and concavity.
  %
\end{proof}
\end{lem}



\begin{lem}\label{lem:hoeldererror_metric}
Let $p \in (0,1]$.
With definitions as above, we assume that set $\inspace$ is endowed with a pseudo- metric $\metric$. Function
$\metricp: \begin{cases} \inspace \times \inspace \to \Real_{\geq 0} \\ (x,y) \mapsto \Bigl(\metric(x,y)\Bigr)^p \end{cases}$ is a pseudo-metric on $\inspace$.
If $\metric$ is a metric then so is $\metricp$.
\begin{proof}
 By Lem. \ref{lem:x2p_pdNsubadd}, $x\mapsto x^p$ is pos. def. and sub-additive. Therefore, positive definiteness and the triangle inequality of $\metric$ readily extend to $\metricp$ as follows: 

\textit{Pos. def.:}
Let $x=0$. $\metricp(x,x) = \metric(x,x)^p = 0^p = 0$. If $x \neq 0$ then $k :=\metric(x,x) \neq 0$. Hence   $\metricp(x,x) = d(x,x)^p = k^p \neq 0$.

\textit{Triangle inequality:}
Choose arbitrary $x,y,z \in \inspace $. We have $\metricp(x,z) = \metric(x,z)^p \leq (\metric(x,y) + \metric(y,z) \bigr)^p \leq \metric(x,y)^p + \metric(y,z)^p = \metricp(x,y) + \metricp(y,z)$. Here, the first inequality followed from the triangle inequality of pseudo-metric $\metric$ and the second from subadditivity properties established in Lem. \ref{lem:x2p_pdNsubadd}.

\textit{Symmetry:} If $\metric$ is a metric it is symmetric. Hence, $\metricp(x,y) = \metric(x,y)^p = \metric(y,x)^p = \metricp(y,x), \forall x,y \in \inspace $ in which case $\metric$ also is symmetric.
\end{proof}
\end{lem}

Before proceeding we establish a slight generalisation of the well-known \textit{reverse triangle inequality}:

\begin{lem}[Reverse Triangle Inequality] \label{thm:revtriangle}
Let  $\inspace$ be a set and $\metric : \inspace^2 \to \Real$ a symmetric function that satisfies the triangle inequality. 
That is,  $\forall x,y,z \in \inspace: \metric (x,y) = \metric(y,x) \wedge \metric(x,z) \leq \metric(x,y) + \metric(y,z)$.

Then \[\forall x,y,z \in \inspace: \abs{\metric(x,y) - \metric(z,y)} \leq \metric(x,z).\]
\begin{proof}
For contradiction, assume 
$\abs{\metric(x,y) - \metric(z,y)}>\metric(x,z)$ for some $x,y,z \in \inspace$.
This is implies  
$
(i)\,\,\, \metric(x,y) - \metric(z,y)>\metric(x,z) 
\, \, $  or  $
\,\,  (ii) \,\,\,\, \metric(z,y)-\metric(x,y) >\metric(x,z)$.
Both inequalities contradict the triangle inequality:
$(i) \Leftrightarrow \metric(x,y)  >\metric(x,z) +\metric(z,y) $ and 
$(ii) \Leftrightarrow  \metric(z,y) > \metric(x,z) + \metric(x,y) =  \metric(z,x) + \metric(x,y)$.

\end{proof}
\end{lem}


\begin{lem}
Let $\metric$ be a (pseudo-) metric on $\inspace$. For arbitrary $s \in \inspace $ we define $\phi_s: \inspace \to \Real $ as $\phi_s: x \mapsto \metric (x,s) $.
$\phi_s $ is Lipschitz with respect to metric $\metric$. That is, \[\forall x,y \in \inspace : \abs{\phi_s(x) - \phi_s(y) } \leq \metric (x,y). \]
\begin{proof}
$\abs{\phi_s(x) - \phi_s(y)} = \abs{\metric(x,s) - \metric(y,s)} \stackrel{Thm. \ref{thm:revtriangle}} {\leq} \metric(x,y), \forall x,y,s \in \inspace $.
\end{proof}
\end{lem}
Finally, combining this lemma with Lem. \ref{lem:hoeldererror_metric} immediately establishes that mappings of the form $\metric(\cdot,s)^p$ are H\"older continuous with exponent $p$ ($\in (0,1]$):

\begin{thm} \label{thm:d2pmapishoelder}
Let $\metric$ be a (pseudo-) metric on set $\inspace$ and let $p \in (0,1], L \geq 0$. For arbitrary $s \in \inspace $ we define $\phi_s:\begin{cases}  \inspace \to \Real \\ x \mapsto L \, \bigl(\metric (x,s) \bigr)^p\end{cases}$.
$\phi_s $ is H\"older with exponent $p$. That is, \[\forall x,y \in \inspace : \abs{\phi_s(x) - \phi_s(y) } \leq L \, \metric (x,y)^p. \]
In particular, for any norm $\norm \cdot$ on $G$ and $s \in \inspace $, mapping $x \mapsto L \norm{x-s}^p$ is H\"older with constant $L$ and exponent $p$.

\begin{proof}
By Lem. \ref{lem:hoeldererror_metric}, $\metric^p(\cdot,\cdot)$ is a (pseudo-) metric on $\inspace$. Hence, Lem. \ref{thm:revtriangle} is applicable yielding:
$\abs{\phi_s(x) - \phi_s(y)} = L \, \abs{\metric(x,s)^p - \metric(y,s)^p} \stackrel{Lem. \ref{thm:revtriangle} } {\leq} \metric(x,y)^p, \forall x,y,s \in \inspace$. The last sentence concerning the norms follows from the fact that a mapping $(x,y) \mapsto \norm{x-y}$ defines a metric.
\end{proof}
\end{thm}



 %At first glance, the result may seem intuitive. However, it should be noted that, for $p >1$, $x \mapsto \norm{x -s}^p$ no longer is H\"older with exponent $p$. This is consistent with the well-known fact that H\"older functions with exponent $>1$ are constant functions.
%
%We conclude this section by the following theorem stating that any concatenation of H\"older continuous functions is H\"older continuous:
%
%\begin{thm} \label{thm:concathoelder}
%Let $(\statespace, \metric)$ be a metric space and $f,g : \statespace \to \statespace$ be two H\"older continuous mappings with  H\"older  constants $L_f, L_g$ and H\"older exponents $p_f,p_g$, respectively.
%Then, the concatenation $h=f \circ g: \statespace \to \statespace $ is also H\"older continuous with H\"older constant $L_h:= L_f L_g^{p_f}$ and exponent $p_h:=p_g \, p_f$.
%That is, 
%\[\forall \state,\state' \in \statespace: \metric\bigl(h(\state),h(\state')\bigr) \leq L_h \bigl(\metric(\state,\state')\bigr)^{p_h}.\]
%\begin{proof}
%%\begin{align}
%$\metric\bigl(f \circ g(\state),f\circ g(\state')\bigr) \leq L_f  \Bigl(\metric(g(\state),g(\state'))\Bigr)^{p_f}$
%$\leq L_f  \Bigl(L_g \metric(\state,\state')^{p_g}\Bigr)^{p_f}$ $= L_f L_g^{p_f}   \Bigl(\metric(\state,\state')\Bigr)^{p_g\, p_f} $ where in the first step we were using Hoelder-continuity of $f$ and in the second, we were using H\"older continuity of $g$ combined with the fact that $(\cdot)^{p_f}$ is a monotonically increasing  function. 
%
%\end{proof}
%\end{thm} 
%In conjunction with H\"older properties of the square root function established in Ex. \ref{ex:sqrtfctHoelder}, Thm. 
%\ref{thm:concathoelder} immediately yields the following result:
%\begin{cor}
%If $f: \statespace \to \statespace $ is H\"older continuous with constant $L_f$ and exponent $p_f$ then $\sqrt{f}$ also is Hoelder, having  H\"older constant $\sqrt{L_f}$ and exponent $p_f$.
%\end{cor}

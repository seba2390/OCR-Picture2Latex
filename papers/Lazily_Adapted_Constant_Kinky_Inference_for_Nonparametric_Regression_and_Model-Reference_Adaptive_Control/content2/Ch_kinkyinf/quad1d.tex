\section{Task 2 -- Quadrature}
\label{sec:quadr}

Many numerical methods and bounds rely on derivatives to drive the algorithm and to provide accuracy bounds. For instance, Newton's method searches for roots on the basis of derivatives but is well-known to diverge when attempting to find the root of $x \mapsto x^{1/3}$ which exhibits unbounded derivatives around the root. Or, Gaussian quadrature provides numerical estimates of a one-dimensional integrand on the basis of polynomial interpolation. However, its error bounds depend on the supremum of higher-order derivatives  within the integration domain and hence are not applicable for functions that are not sufficiently smooth or have derivatives that are unbounded, unknown, unbounded or generally hard to maximise. \jcom{citations}
Therefore, Hoelder continuity has recently be considered for quadrature of one dimensional functions \cite{Baran2008}. In this section, we present an approach that allows for numerical integration of Hoelder continuous integrands. We allow for sample function values that are corrupted by noise of an unknown distribution but have known support.

\subsection{Quadrature on one-dimensional domains}
\label{sec:quadr_1dim} 

We consider the case of integration of $L$-Lipschitz continuous functions on one-dimensional domains with metric $\metric: (x,y) \mapsto \abs{x-y}^p$ for some $p \in (0,1]$. That is, the integrand is H\"older continuous with constant $L$ and H\"older exponent $p$.

Let $a,b \in \Real, a \leq b, I := [a,b] \subset \Real$.
We assume we have access to an erroneous sample of a H\"older function $f: I \to \Real $ on a finite grid $G_{N_n} =\{s_1,\ldots,s_{N_n}\} \subset I$, where $a = s_0 \leq s_1 \leq ...\leq s_{N_n}\leq s_{{N_n}+1} =b$. We define $I_i = [s_i,s_{i+1}]$.

Previously, we assumed $L$ was constant. However, from now on, we assume we are given different constants $L_i := L[I_i] \in \Real$ for each interval $I_i$ $(i = 0,\ldots,{N_n})$.  

Our goal is to compute conservative estimates of the definitive Riemann integral \[S := \int_{I} f(t) \, \d t.\] 

In particular, given a finite budget of ${N_n} \in \nat$ function evaluations, we desire (i) to find two  estimates $S^\decke_n , S^\boden_n$ of the definite integral that are upper and lower conservative, respectively. That is, we desire 
\[S^\boden_n \leq S \leq S^\decke_n. \] Furthermore, we desire (ii) convergence to the true value in the limit of an infinite number of function evaluations. That is, we require
$S^\boden_n, S^\decke_n \stackrel{{N_n} \to \infty}{\longrightarrow} S $.
Finally, we desire (iii) $S^\decke_n,S^\boden_n$ to be expressed in closed-form. 

In the one-dimensional case, one obvious way to achieve this is to use the integrals of the H\"older ceiling and floor. That is, we define $S^\decke_n := \int_I \decke_n^* (t) \,dt $ and $S^\boden_n := \int_I \boden_n^* (t) \,dt $. 

(i) follows directly from the properties of the enclosing functions established by Thm. \ref{thm:enclosure1d_desiderata}.

 (iii) is easily addressed via noticing that both ceiling and floor functions are piece-wise polynomial functions. 
 Hence, their definite integrals can be derived in closed-form.  



 Define the \emph{(sub-domain) partitioning} sequence $\xi:=(\xi_0,\ldots,\xi_{{N_n}+1})$ where
$\xi_1, \ldots, \xi_{{N_n}-1} \in \Real$ are called \emph{sub-domain partition points}. 

\begin{defn}[Admissible partitioning sequence]\label{def:xisandJis_1d}
We call partition sequence $\xi$ \emph{admissible} (with respect to sample grid $s_0,\ldots,s_{{N_n}+1}$) if  \[\xi_{i-1} \leq s_i  \leq \xi_{i} \] for $i=1,\ldots,{N_n}-1\text{ and }\xi_0 = s_0, \xi_{N_n} = s_{{N_n}+1}$.
Admissible partitioning sequence $\xi$ defines a partition of \emph{sub-domain intervals} $J_1,\ldots,J_{N_n}$ where the $i$th \emph{sub-domain} interval is defined as \[J_i := [\xi_{i-1},\xi_{i}]\]  $(i \in \{0,\ldots,{N_n}\})$. 

\end{defn}
\begin{rem}
Let  \[S^\decke_n (\xi) := \sum_{i=1}^{N_n} \int_{J_i} \decke^i_n (t) dt \] and 
\[S^\boden_n (\xi) := \sum_{i=1}^{N_n} \int_{J_i} \boden^i_n (t) dt. \]
Lem. \ref{lem:samplefloorceiling} implies that these two integrals are upper and lower bounds of the ground-truth integral. That is, for any admissible $\xi$ satisfying the constraints given in Def. \ref{def:xisandJis_1d} we have
\[S^\boden_n(\xi) \leq \int_I f(t) dt \leq S^\decke_n(\xi). \]
\end{rem}

In preparation of what is to come, we derive the integrals of the sample ceiling and floor functions on the sub-domains.  
\begin{lem} \label{lem:subdomints_1d}
 Remember, the definitions of the (one-dimensional) sample-ceiling  $\decke_n^i (x; L) :x \mapsto  \overline f (s_i) +L_j \abs{x - s_i}^p $ and sample-floor function  
$\boden_n^i (x; L) :x \mapsto  \underline f (s_i) - L_j \abs{x - s_i}^p $ for $x \in I_j$ where 
$L_j = L[I_j]$ is the H\"older coefficient on interval $I_j = (s_j,s_{j+1})$. As before, $J_i = [\xi_{i-1}, \xi_{i}]$ where we choose the $\xi_i$ to be admissible. 
We have:
\begin{enumerate}
	\item $\int_{J_{i}} \decke^i_n(t) \, dt =\overline f(s_i) (\xi_{i} - \xi_{i-1}) +  \frac{L_{i-1}}{{p+1}}(s_i - \xi_{i-1} )^{p+1} + \frac{L_i}{{p+1}} (\xi_{i}-s_i )^{p+1} $.
	\item $\int_{J_{i}} \boden^i_n(t) \, dt =\underline f(s_i)  (\xi_{i}  -  \xi_{i-1} )- \frac{L_{i-1}}{{p+1}} (s_i- \xi_{i-1} )^{p+1} -
 \frac{L_i}{{p+1}} (\xi_{i}-s_i )^{p+1}$.
\end{enumerate}

\begin{proof}
The proof consists in applying simple integration rules to piece-wise linear function. For the ceiling the calculation is as follows: \\
%
$\int_{\xi_{i-1}}^{\xi_i} \decke^i_n(t) \, dt
= \int_{\xi_{i-1}}^{s_i} \overline f (s_i) +L_{i-1} (s_i - t)^p \, dt + \int_{s_i}^{\xi_i} 
\overline f (s_i) +L_i (t - s_i)^p \, dt \\ 
 = \bigl[t \overline f(s_i) - \frac{L_{i-1} (s_i-t )^{p+1}}{p+1}\bigr]_{\xi_{i-1}}^{s_i} + \bigl[t
 \overline f(s_i) + \frac{L_i (t-s_i )^{p+1}}{p+1}\bigr]_{s_i}^{\xi_{i}} \\
= s_i \overline f(s_i) -  \xi_{i-1} \overline f(s_i) + \frac{L_{i-1} (s_i-\xi_{i-1} )^{p+1}}{{p+1}} + 
\xi_{i} \overline f(s_i) + \frac{L_i (\xi_{i}-s_i )^{p+1}}{{p+1}} - s_i \overline f(s_i) \\
= \overline f(s_i)  (\xi_{i}  -  \xi_{i-1} )+ \frac{L_{i-1} (s_i-\xi_{i-1} )^{p+1}}{{p+1}} + 
 \frac{L_i (\xi_{i}-s_i )^{p+1}}{{p+1}}$.

For the sample floor, the calculations are analogous:\\
%
$\int_{\xi_{i-1}}^{\xi_i} \boden^i_n(t) \, dt  
= \int_{\xi_{i-1}}^{s_i} \underline f (s_i) -L_{i-1} (s_i - t)^p \, dt 
+ \int_{s_i}^{\xi_i} \overline f (s_i) -L_i (t - s_i)^p \, dt \\ 
 = \bigl[t \underline f(s_i) + \frac{L_{i-1} (s_i - t )^{p+1}}{p+1}\bigr]_{\xi_{i-1}}^{s_i} 
 + \bigl[t \underline f(s_i) - \frac{L_i (t-s_i )^{p+1}}{{p+1}}\bigr]_{s_i}^{\xi_{i}} \\
= \underline f(s_i)  (\xi_{i}  -  \xi_{i-1} )- \frac{L_{i-1} (s_i-\xi_{i-1} )^{p+1}}{p+1} -
 \frac{L_i (\xi_{i}-s_i )^{p+1}}{p+1}$.

\end{proof}
\end{lem}

Thereby, we have derived closed-form solutions of the integral bounds $S^\decke_n (\xi),S^\boden_n (\xi)$ for any admissible partition sequence $\xi$:

\begin{thm} \label{thm:ceilfloorintofxi} We have 

\begin{align} S^\decke_n (\xi) &= \sum_{i=1}^{N_n}  \tilde f(s_i) (\xi_{i} - \xi_{i-1}) + E(\xi_{i-1},\xi_i \,; s_i,L_i,\varepsilon_i)
	\end{align} 
	and 
 \begin{align} S^\boden_n (\xi) &= \sum_{i=1}^{N_n}  \tilde f(s_i) (\xi_{i} - \xi_{i-1}) -  E(\xi_{i-1},\xi_i \,; s_i,L_i,\varepsilon_i)
\end{align}
where 

\[E(x,y \,;s,L_{i-1},L,e) :=  (y - x)\, e \,+ \frac{L_i}{{p+1}} (y-s )^{p+1}+  \frac{L_{i-1}}{{p+1}}(s-x)^{p+1}     \] for 
$x,y,s, \in \Real, e, L \geq 0$.


\begin{proof}
\begin{align*} S^\decke_n (\xi) &= \sum_{i=1}^{N_n} \int_{J_i} \decke^i_n (t) dt \\
&\stackrel{Lem. \ref {lem:subdomints_1d}}{=}  \sum_{i=1}^{N_n} \overline f(s_i) (\xi_{i} - \xi_{i-1}) 
+ \frac{L_i}{{p+1}} (\xi_{i}-s_i )^{p+1}+  \frac{L_{i-1}}{{p+1}}(s_i- \xi_{i-1} )^{p+1}  \\
&= \sum_{i=1}^{N_n} (\tilde f(s_i) + \varepsilon_i) (\xi_{i} - \xi_{i-1})+ \frac{L_i}{{p+1}} (\xi_{i}-s_i )^{p+1}+  \frac{L_{i-1}}{{p+1}}(s_i- \xi_{i-1} )^{p+1} \\
&= \sum_{i=1}^{N_n} \tilde f(s_i) (\xi_{i} - \xi_{i-1})  + \Bigl( \varepsilon_i (\xi_{i} - \xi_{i-1}) +  \frac{L_i (\xi_{i}-s_i )^{p+1}+  L_{i-1}(s_i-\xi_{i-1} )^{p+1} }{p+1} \Bigr).
	\end{align*} 
	Similarly, 
	\begin{align*} S^\boden_n (\xi) &= \sum_{i=1}^{N_n} \int_{J_i} \boden^i_n (t) dt \\
&\stackrel{Lem. \ref {lem:subdomints_1d}}{=}  \sum_{i=1}^{N_n} \underline f(s_i) (\xi_{i} - \xi_{i-1}) - \frac{L_i}{p+1} (\xi_{i}-s_i )^{p+1}-  \frac{L_{i-1}}{{p+1}}(s_i-\xi_{i-1} )^{p+1}  \\
&= \sum_{i=1}^{N_n} (\tilde f(s_i) - \varepsilon_i) (\xi_{i} - \xi_{i-1}) -  \frac{ L_i (\xi_{i}-s_i )^{p+1}+  L_{i-1} (s_i-\xi_{i-1} )^{p+1} }{{p+1}} \\
&= \sum_{i=1}^{N_n} \tilde f(s_i) (\xi_{i} - \xi_{i-1})  - \Bigl( \varepsilon_i (\xi_{i} - \xi_{i-1}) + \frac{ L_i (\xi_{i}-s_i )^{p+1}+  L_{i-1} (s_i-\xi_{i-1})^{p+1} }{{p+1}} \Bigr).
	\end{align*} 
\end{proof}
\end{thm}

One can construe summand $ \tilde f(s_i) (\xi_{i} - \xi_{i-1})$ as an estimate of the integral on $J_i$
and $ E(\xi_{i-1},\xi_i \,; s_i,L_i,\varepsilon_i)$ as an error term due to unknown variation up to $L_i$ and measurement error $\varepsilon_i$.
Note, in the absence of measurement errors, as the grid becomes increasingly dense (as ${N_n} \to \infty$), the error due to variation will vanish and the integral estimate $\sum_{i=1}^{N_n} \tilde f(s_i) (\xi_{i} - \xi_{i-1})$ converge to the true integral of $f$.

%
%
%\begin{ques} When we sample  errors (uniformly from a const interval)  and let the grid become dense (but keep pruning) should the sampling error not also vanish since only samples are kept that are informative? Or would the probability of sampling informative values shrink to zero for denser grids? (it might) So what is the stationary uncertainty?
%\end{ques} 

Our next task will be to find $\xi$ such that our integral estimates become as tight as possible. 
Since $\xi_0 = s_0 $ and $\xi_{{N_n}} = s_{{N_n}+1}$ are uniquely predetermined, 
all we are left to do is to find the non-boundary partition points 
$\Xi:=(\xi_1,...,\xi_{{N_n}-1})$. Since we require each $\xi_i$ to be admissible, that is to lie in interval $I_i = [s_{i},s_{i+1}]$, we can reduce the problem of finding $\xi_i$ to determining $\lambda_i \in [0,1]$ where \[\xi_i = s_{i} + \lambda_i (s_{i+1}-s_{i}) = s_{i+1} - (1-\lambda_i) (s_{i+1}-s_{i}) .\]  
That is, we desire to find admissible solutions
\begin{equation}
\Xi^\decke := \argmin_{(\lambda_1,...,\lambda_{{N_n}-1})} \mathfrak S^\decke_n\bigl(\lambda_1,...,\lambda_{{N_n}-1}\bigr)
\end{equation} and
 \begin{equation}
\Xi^\boden := \argmax_{(\lambda_1,...,\lambda_{{N_n}-1})} \mathfrak S^\boden_n\bigl(\lambda_1,...,\lambda_{{N_n}-1}\bigr)
\end{equation}
where  
\begin{align}
\mathfrak S^\decke_n\bigl(\lambda_1,...,\lambda_{{N_n}-1}\bigr) := S^\decke_n\bigl((\xi_0,s_{1} + \lambda_1 (s_{2}-s_{1}),...,s_{{N_n}-1} + \lambda_{{N_n}-1} (s_{{N_n}}-s_{{N_n}-1}),\xi_{{N_n}})\bigr)\\
\mathfrak S^\boden_n\bigl(\lambda_1,...,\lambda_{{N_n}-1}\bigr) := S^\boden_n\bigl((\xi_0,s_{1} + \lambda_1 (s_{2}-s_{1}),...,s_{{N_n}-1} + \lambda_{{N_n}-1} (s_{{N_n}}-s_{{N_n}-1}),\xi_{{N_n}})\bigr).
\end{align}

 
Fortunately, this task is simplified by the analytic properties of the objective functions.
For $i \in \{1,\ldots,{N_n}-1\}$ the partial derivatives are 
\begin{align*}
\partial_i \mathfrak S^\decke_n (\lambda_1,\ldots,\lambda_{{N_n}-1}) &= \tilde f(s_i) - \tilde f(s_{i+1})  + \varepsilon_i - \varepsilon_{i+1} 
+ L_i   (s_{i+1}-s_i )^p   (\lambda_i^p- (1-\lambda_i )^p)\\
\partial_i \mathfrak S^\boden_n (\lambda_1,\ldots,\lambda_{{N_n}-1}) &= \tilde f(s_i)  - \tilde f(s_{i+1}) - \varepsilon_i + \varepsilon_{i+1} - L_i   (s_{i+1}-s_i )^p   (\lambda_i^p- (1-\lambda_i )^p).
\end{align*}
%\begin{align*}
%\partial_i \mathfrak S^\decke_n (\xi_1^,...,\xi_n) &= \tilde f(s_i) - \tilde f(s_{i+1})  + \varepsilon_i - \varepsilon_{i+1} + L_i  (\xi_{i}-s_i )^p    - L_{i}  (s_{i+1} - \xi_{i} )^p\\
%\partial_i \mathfrak S^\boden_n (\xi_1,...,\xi_n) &= \tilde f(s_i)  - \tilde f(s_{i+1}) - \varepsilon_i + \varepsilon_{i+1} - L_i  (\xi_{i}-s_i )^p    + L_{i}  (s_{i+1} - \xi_{i})^p
%\end{align*}
%for $i \in \{1,\ldots,{N_n}-1\}$.

Therefore,the second partial derivatives are :
\[
\partial_i \partial_j \mathfrak S^\decke_n (\lambda_1,\ldots,\lambda_{{N_n}-1}) = \begin{cases}  L_i   (s_{i+1}-s_i )^p   (p \, \lambda_i^{p-1}+ p (1-\lambda_i )^{p-1})&, \text{ if } i =j\\ 0 &, \text{ otherwise} \end{cases}
\]
and 
\[
\partial_i \partial_j \mathfrak S^\boden_n (\lambda_1,\ldots,\lambda_{{N_n}-1})= \begin{cases}  - L_i   (s_{i+1}-s_i )^p   (p \lambda_i^{p-1}+ p (1-\lambda_i )^{p-1}) &,  \text{ if }  i =j\\ 0 &, \text{ otherwise.} \end{cases}
\]
Hence, $\nabla^2 \mathfrak S^\boden_n $ and $\nabla^2 \mathfrak S^\decke_n$ are negative definite and positive definite, respectively. Thus, $\mathfrak S^\boden_n, \mathfrak S^\decke_n$ are concave and convex respectively.  Therefore, global extrema exist and, for the optimal ceiling and floor partition, all we need to do is to solve the equations: 
\begin{align}
\nabla \mathfrak S^\decke_n (\lambda_1^\decke,\ldots, \lambda_{N_u-1}^\decke) = 0\\
\nabla \mathfrak S^\boden_n (\lambda_1^\boden,\ldots, \lambda_{N_u-1}^\boden) = 0.
\end{align}





Setting each $i$th partial derivative to zero yields the $N_u-1$ equation pairs :

%%\begin{align*}
%\begin{equation} \label{eq:lambdaceil}
%(\lambda_i^\decke )^p- (1-\lambda_i^\decke )^p = \frac{\tilde f(s_{i+1}) - \tilde f(s_i) + \varepsilon_{i+1} - \varepsilon_i}{ L_i   (s_{i+1}-s_i )^p}  \end{equation}
    %which we need to solve for $\lambda_i \in [0,1]$ to obtain $\xi^\decke_i$ and
%\begin{equation} \label{eq:lambdafloor} \lambda_i^p- (1-\lambda_i )^p =-\frac{\tilde f(s_{i+1}) - \tilde f(s_i) + \varepsilon_{i+1} - \varepsilon_i}{ L_i   (s_{i+1}-s_i )^p}  \end{equation}
%which we need to solve for $\lambda_i \in [0,1]$ to obtain $\xi^\boden_i$.
%%\end{align*}

\begin{align}
g(\lambda_i^\decke) &= \gamma_i \label{eq:g1}\\
   g(\lambda_i^\boden) &= -\gamma_i. \label{eq:g2}
\end{align}
where \[g(\lambda) := \lambda^p- (1-\lambda )^p \] and \[\gamma_i := \frac{\tilde f(s_{i+1}) - \tilde f(s_i) + \varepsilon_{i+1} - \varepsilon_i}{ L_i   (s_{i+1}-s_i )^p}.\]

It is easy to show that both equations can always be solved: Firstly, due to the H\"older properties of the target, we have $\gamma_i \in [-1,1]$. Moreover, $g$ injectively maps $[0,1]$ to $[-1,1]$ (which implies that we can always find a solution by inverting $g$). This is true since $\nabla g (\lambda) = p \lambda^{p-1} + p (1-\lambda)^{p-1} >0 $ and thus, $g$ is strictly monotonously increasing on $[0,1]$. Moreover $g(0) = -1$ and $g(1) = 1$. The rest follows from the Intermediate Value Theorem. Example plots of $g$ for various choices of $p$ are depicted in Fig. \ref{fig:gvonp}. 

Note,
$g(\lambda) = - g(1-\lambda) $ for $\lambda \in [0,1]$. Thus, 
\begin{equation} \lambda_i^\decke = 1 - \lambda_i^\boden,\,\,\forall i. \end{equation} Therefore, solving Eq. \ref{eq:g1} automatically yields a solution to Eq. \ref{eq:g2}.


\begin{figure}[htb] \label{fig:gvonp}
	\centering
		\includegraphics[scale =.4]{content/content_hoelderquad2/figs/gvonp.pdf}
	\caption{Function $g$ as a function of $\lambda$ for varying H\"older exponents $p$.}
\end{figure}


To solve for the $\lambda_i$, and thus, the breakpoints $\xi_i$, for several H\"older exponents $p$, closed -form solutions can be easily derived. For instance, for $p=1$ we have

\begin{align}
 \xi_i^\decke &= \frac{ s_i    + s_{i+1}}{2} + \frac{\varepsilon_{i+1} - \varepsilon_i   +\tilde f(s_{i+1}) - \tilde f(s_i) }{ 2 L_i} \\
&= \frac{ s_i    + s_{i+1}}{2} + \frac{ \overline f(s_{i+1}) - 
\overline f(s_i) }{ 2 L_i} \label{eq:lipxiceil}
\end{align}

and 

\begin{align}
   \xi_{i}^\boden    &=   \frac{ s_i    + s_{i+1}}{2} - \frac{\varepsilon_{i+1} - \varepsilon_i   +\tilde f(s_{i+1}) - \tilde f(s_i) }{ 2 L_i} \\
&= \frac{ s_i    + s_{i+1}}{2} - \frac{ \underline f(s_{i+1}) - 
\underline f(s_i) }{ 2 L_i} \label{eq:lipxifloor}
\end{align}

%\begin{align}
 %\xi_i^\decke &= \frac{\varepsilon_{i+1} - \varepsilon_i   +\tilde f(s_{i+1}) - \tilde f(s_i) +L_i s_i    + 
%L_{i+1}s_{i+1}}{ L_i+ L_{i+1}} \\
%&= \frac{L_i s_i    + L_{i+1}s_{i+1} + \overline f(s_{i+1}) - 
%\overline f(s_i) }{ L_i+ L_{i+1}}
%\end{align}
%
%and 
%
%\begin{align}
   %\xi_{i}^\boden    &=   \frac{ L_{i+1} s_{i+1} + L_i s_i + \tilde f(s_i) - \tilde f(s_{i+1})  - \varepsilon_i  + \varepsilon_{i+1}}{L_i+ L_{i+1}}\\
	%&=   \frac{L_i s_i+ L_{i+1} s_{i+1}  + \underline f(s_i) - \underline f(s_{i+1})  }{L_i+ L_{i+1}}
%\end{align}

for $ i \in \{1,\ldots,{N_n}-1\} $.



Not surprisingly, we have recovered the break-points of the ceiling and floor functions as per  Lem. \ref{lem:ceiling_maxvalues} and Lem. \ref{lem:floor_minvalues}. Both Lemmata also establish admissibility of our solutions (i.e. $\xi^\decke_i, \xi^\boden_i \in I_i)$. 

Consequently, the best partition point sequences  $\Xi^\decke,\Xi^\boden  $ yield integral bounds that coincide with the integrals of the optimal ceiling and floor functions:
$\mathfrak S^\decke_n\bigl(\lambda_1^\decke ,...,\lambda_{{N_n}-1}^\decke \bigr) = \int_I \decke^*_n(t) dt$ and
$\mathfrak S^\boden_n\bigl(\lambda_1^\boden ,...,\lambda_{{N_n}-1}^\boden \bigr) = \int_I \boden^*_n(t) dt.$

In case no closed form solution is known, we can approximate numerically. Due to the simplicity of the problem at hand, this can be achieved rapidly with a robust root finding algorithm such as Ridder's method \cite{ridders1979}. By construction, a suboptimal solution still yields conservative integral estimate bounds so we can stop the root finding method after a few iterations without obtaining overly confident bounds. 

%
%Of course, we could also derive the tightest integral estimate bounds by directly integrating the optimal enclosure:
%
%\begin{thm} \label{thm:quad_ceil} 
%Remember, the sample grid is given by erroneous function samples at inputs $s_1 < \ldots < s_n$. Let  
%$s_0 = \inf I \leq s_1, s_{{N_n}+1} = \sup I \geq s_n$ and  $\xi^{\decke}_i =  \frac{s_i+s_{i+1}}{2}+ \frac{\overline f(s_{i+1}) - \overline f(s_i)}{2 L_i}  $.
%%augmented grid $\tilde G_n = (t_1, \xi_1^\decke, t_2, \xi_2^\decke, t_3,\ldots,t_{{N_n}-1},\xi_{{N_n}-1}^\decke,t_{{N_n}} )$, and let $\tau_j$ denote the $j$th element 
%%of augmented grid $\tilde G_n$.
%We have 
%\begin{align*}
%\int_I \decke_n^* (t) \, \d t  &=s_{{N_n}+1} \overline f(s_n)  - s_0 \overline f(s_{1}) + \frac{L_0 (s_0 -s_{1})^2}{2} + \frac{L_{{N_n}} (s_{{N_n}+1}-s_n )^2}{2}  \\
		 %&+\sum_{i=1}^{{N_n}-1} \xi^\decke_{i} \bigl( \overline f(s_i) - \overline f(s_{i+1}) \bigr) + \frac{L_i}{2} \bigl( (\xi^\decke_{i}-s_i )^2+ (\xi^\decke_{i} -s_{i+1})^2 \bigr)\\
		%&\Bigl(= \mathfrak S^\decke_n (\Xi^\decke)\Bigr).
%\end{align*}
%
%%\[ S^\decke_n  = \frac{1}{2} \sum_{i=1}^{3{N_n}-1} \bigl(\,(\tau_{i+1} - \tau_i) \,\bigl(\decke_nx^i(\xi^{\decke}_i)(
%%\tau_{i+1}) - \decke_n^i(\xi^{\decke}_i)(
%%\tau_{i})\bigr), \, ({N_n} > 1);\]
%%
%%\[ S^\decke_n  = \frac{1}{2} \sum_{i=1}^{3{N_n}} \bigl(\,(\tau_{i+1} - \tau_i) \,\bigl(\decke_n^i(\xi^{\decke}_i)(
%%\tau_{i+1}) - \decke_n^i(\xi^{\decke}_i)(
%%\tau_{i})\bigr), \, ({N_n} = 1).\]
%
%\begin{proof} With 
%$\alpha^\decke_i: x \mapsto \overline f(a_i) + L_i (x - s_i)$ and $\beta^\decke_i: x \mapsto
%\overline f(b_i) -L_i (x - s_{i+1})$ the H\"older ceiling on $I_i$ coincides with the piecewise-linear function $t \mapsto \min\{ \alpha^\decke_i(t), \beta^\decke_i(t)\}$; as per Lem. \ref{lem:ceiling_maxvalues}, for all $t \in I_i$, we have $\decke_n^*(t) = 
 %\begin{cases}  
 %\overline f(a_i) + L_i (t - s_i), & t \leq \xi^\decke_i \\
 %\overline f(b_i) -L_i (t - s_{i+1}), & t > \xi^\decke_i 
 %\end{cases}$.
%
%Therefore,
%
%%\begin{align*}
%$S^\decke_n = \int_I \decke_n^* (t) \, \d t\\
 %%
 %\stackrel{Thm. \ref{thm:lipceil1d}}{=} \int_{I_0}  \decke^*_1 (t) \, \d t + \int_{I_{N_n}}  \decke^{N_n}_{N_n} (t) \, \d t + \sum_{i=1}^{{N_n}-1} \int_{I_i} \min\{\decke_n^i(t),\decke_n^{i+1}(t) \}\, \d t\\
 %%
 %\stackrel{Lem. \ref{lem:ceiling_maxvalues}} {=} \int_{I_0}  \decke^1_{N_n} (t) \, \d t + \int_{I_{N_n}}  \decke^{N_n}_{N_n} (t) \, \d t + \sum_{i=1}^{{N_n}-1} \Bigl(\int_{s_i}^{\xi^\decke_i} \decke_n^i(t) \, \d t + \int_{\xi^\decke_i}^{s_{i+1}} \decke_n^{i+1}(t) \, \d t \Bigl)\\
%%  
  %= \int_{I_0}  \decke^1_{N_n} (t) \, \d t + \int_{I_{N_n}}  \decke^{N_n}_{N_n} (t) \, \d t \\
	 %+ \sum_{i=1}^{{N_n}-1} \bigl( \int_{s_i}^{\xi^\decke_{i}}  \overline f(s_i) + L_i (t - s_i) \, \d t + \int_{\xi^\decke_{i}}^{s_{i+1}}   \overline f(s_{i+1}) -L_i (t - s_{i+1})\, \d t \bigr)\\
  %%
  %= \int_{I_0}  \decke^1_{N_n} (t) \, \d t + \int_{I_{N_n}}  \decke^{N_n}_{N_n} (t) \, \d t \\
	 %+ \sum_{i=1}^{{N_n}-1} \bigl( \bigl[t \overline f(s_i) + \frac{L_i (t-s_i )^2}{2}\bigr]_{s_i}^{\xi^\decke_{i}}  + \bigl[t \overline f(s_{i+1}) - \frac{L_i (t -s_{i+1})^2}{2}\bigr]^{s_{i+1}}_{\xi^\decke_{i}} \bigr)\\
  %%
  %= \int_{I_0}  \decke^1_{N_n} (t) \, \d t + \int_{I_{N_n}}  \decke^{N_n}_{N_n} (t) \, \d t \\
	 %+ \sum_{i=1}^{{N_n}-1} \Bigl( \xi^\decke_{i} \overline f(s_i) + \frac{L_i (\xi^\decke_{i}-s_i )^2}{2} - s_i \overline f(s_i)   
  %- \xi^\decke_{i} \overline f(s_{i+1}) + \frac{L_i (\xi^\decke_{i} -s_{i+1})^2}{2}  + s_{i+1} \overline f(s_{i+1}) \Bigr)\\
  %%
    %=  \int_{s_0}^{s_1}  \decke^1_{N_n} (t) \, \d t + \int_{s_{N_n}}^{s_{{N_n}+1}}  \decke^{N_n}_{N_n} (t) \, \d t \\
	%+ s_{N_n} \overline f(s_{N_n}) - s_1 \overline f(s_1)+\sum_{i=1}^{{N_n}-1} \xi^\decke_{i} \bigl( \overline f(s_i) - \overline f(s_{i+1}) \bigr) + \frac{L_i}{2} \bigl( (\xi^\decke_{i}-s_i )^2+ (\xi^\decke_{i} -s_{i+1})^2 \bigr)      \\
		%%
    %=  \bigl[t \overline f(s_{1}) - \frac{L_0 (t -s_{1})^2}{2}\bigr]^{s_{1}}_{s_0} +   \bigl[t \overline f(s_{N_n}) + \frac{L_{N_n} (t-s_{N_n} )^2}{2}\bigr]_{s_{N_n}}^{s_{{N_n}+1}}  + s_{N_n} \overline f(s_{N_n}) - s_1 \overline f(s_1) \\
		 %+\sum_{i=1}^{{N_n}-1} \xi^\decke_{i} \bigl( \overline f(s_i) - \overline f(s_{i+1}) \bigr) + \frac{L_i}{2} \bigl( (\xi^\decke_{i}-s_i )^2+ (\xi^\decke_{i} -s_{i+1})^2 \bigr)     \\ 
				%%
    %=  s_1 \overline f(s_{1})  - s_0 \overline f(s_{1}) + \frac{L_0 (s_0 -s_{1})^2}{2} -   s_{N_n} \overline f(s_{N_n}) + s_{{N_n}+1} \overline f(s_{N_n}) + \frac{L_{N_n} (s_{{N_n}+1}-s_{N_n} )^2}{2}  + s_{N_n} \overline f(s_{N_n}) - s_1 \overline f(s_1) \\
		 %+\sum_{i=1}^{{N_n}-1} \xi^\decke_{i} \bigl( \overline f(s_i) - \overline f(s_{i+1}) \bigr) + \frac{L_i}{2} \bigl( (\xi^\decke_{i}-s_i )^2+ (\xi^\decke_{i} -s_{i+1})^2 \bigr)     \\ 
						%%
    %= s_{{N_n}+1} \overline f(s_{N_n})  - s_0 \overline f(s_{1}) + \frac{L_0 (s_0 -s_{1})^2}{2} + \frac{L_{N_n} (s_{{N_n}+1}-s_{N_n} )^2}{2}  \\
		 %+\sum_{i=1}^{{N_n}-1} \xi^\decke_{i} \bigl( \overline f(s_i) - \overline f(s_{i+1}) \bigr) + \frac{L_i}{2} \bigl( (\xi^\decke_{i}-s_i )^2+ (\xi^\decke_{i} -s_{i+1})^2 \bigr).   \\ $
		%%\end{align*}
		%
%\end{proof}
%
%\end{thm}
%
%Of course, we can derive the completely analogous statement for the H\"older floor. 
%
%
%\begin{thm} \label{thm:quad_floor} Remember, the sample grid is given by erroneous function samples at inputs $s_1 < \ldots < s_{N_n}$ and let 
%$s_0 = \inf I \leq s_1, s_{{N_n}+1} = \sup I \geq s_{N_n}$. As before, let $\xi^{\mathfrak l}_i := \frac{s_i+s_{i+1}}{2} - \frac{\underline f(s_{i+1}) - \underline f(s_i)}{2 L_i}  $. 
%%augmented grid $\tilde G_{N_n} = (t_1, \xi_1^\boden, t_2, \xi_2^\boden, t_3,\ldots,t_{{N_n}-1},\xi_{{N_n}-1}^\boden,t_{{N_n}} )$, and let $\tau_j$ denote the $j$th element 
%%of augmented grid $\tilde G_{N_n}$.
%We have \\
%\begin {align*}
%\int_I \boden_n^* (t) \, \d t&=s_{{N_n}+1} \underline f(s_{N_n})-s_0 \underline f(s_1) - \frac{1}{2} L_0 (s_0 - s_1)^2  - \frac{1}{2} L_{N_n} (s_{{N_n}+1} - s_{N_n})^2 \\
%&+  \sum_{i=1}^{{N_n}-1} \Bigl(\xi^\boden_{i} \bigl( \underline f(s_i) - \underline f(s_{i+1})\bigr) - \frac{L_i}{2} \bigl( (\xi^\boden_{i}-s_i )^2 + (\xi^\boden_{i} -s_{i+1})^2 \bigr) 
 %\Bigr)\\
%&\Bigl(= \mathfrak S^\boden_n (\Xi^\boden)\Bigr).
%\end{align*} 
%
%
%%\[ S^\boden_n  = \frac{1}{2} \sum_{i=1}^{3{N_n}-1} \bigl(\,(\tau_{i+1} - \tau_i) \,\bigl(\boden_n^i(\xi^{\boden}_i)(
%%\tau_{i+1}) - \boden_n^i(\xi^{\boden}_i)(
%%\tau_{i})\bigr), \, ({N_n} > 1);\]
%%
%%\[ S^\boden_n  = \frac{1}{2} \sum_{i=1}^{3{N_n}} \bigl(\,(\tau_{i+1} - \tau_i) \,\bigl(\boden_n^i(\xi^{\boden}_i)(
%%\tau_{i+1}) - \boden_n^i(\xi^{\boden}_i)(
%%\tau_{i})\bigr), \, ({N_n} = 1).\]
%
%\begin{proof} By virtue of Lem. \ref{lem:floor_minvalues} we have 
 %$\forall t \in I_i: \,\,\, \boden^*_{N_n}(t) = 
 %\begin{cases}  
 %\alpha_i^{\mathfrak l} (t), & t \leq \xi_i^\boden \\
 %\beta_i^{\mathfrak l} (t), & t \geq \xi_i^\boden
 %\end{cases}$ 
%% 
 %where $\alpha^\boden_i( t) = \underline f(s_i) - L_i (t - s_i)$ and $\beta^\boden_i( t) =
%\underline f(s_{i+1}) +L_i (t - s_{i+1})$.\\
%
%Therefore,
%
%$S^\boden_n = \int_I \boden_n^* (t) \, \d t\\
%\stackrel{Thm\ref{thm:lipfloor1d}}{=} \int_{I_0}  \boden^*_1 (t) \, \d t + \int_{I_{N_n}}  \boden^{N_n}_{N_n} (t) \, \d t + \sum_{i=1}^{{N_n}-1} \int_{I_i} \max\{\boden_n^i(t),\boden_n^{i+1}(t) \}\, \d t\\
%%
 %\stackrel{Lem. \ref{lem:floor_minvalues}} {=} \int_{I_0}  \boden^1_{N_n} (t) \, \d t + \int_{I_{N_n}}  \boden^{N_n}_{N_n} (t) \, \d t + \sum_{i=1}^{{N_n}-1} \Bigl(\int_{s_i}^{\xi^\boden_i} \boden_n^i(t) \, \d t + \int_{\xi^\boden_i}^{s_{i+1}} \boden_n^{i+1}(t) \, \d t \Bigl)\\
%%
  %% 
  %= \int_{I_0}  \boden^1_{N_n} (t) \, \d t + \int_{I_{N_n}}  \boden^{N_n}_{N_n} (t) \, \d t + \sum_{i=1}^{{N_n}-1} \bigl( \int_{s_i}^{\xi^\boden_{i}}  \underline f(s_i) - L_i (t - s_i) \, \d t + \int_{\xi^\boden_{i}}^{s_{i+1}}   \underline f(s_{i+1}) +L_i (t - s_{i+1})\, \d t \bigr)\\
  %%
  %= \int_{I_0}  \boden^1_{N_n} (t) \, \d t + \int_{I_{N_n}}  \boden^{N_n}_{N_n} (t) \, \d t +\sum_{i=1}^{{N_n}-1} \bigl( \bigl[t \underline f(s_i) - \frac{L_i (t-s_i )^2}{2}\bigr]_{s_i}^{\xi^\boden_{i}}  + \bigl[t \underline f(s_{i+1}) + \frac{L_i (t -s_{i+1})^2}{2}\bigr]^{s_{i+1}}_{\xi^\boden_{i}} \bigr)\\
  %%
  %= \int_{I_0}  \boden^1_{N_n} (t) \, \d t + \int_{I_{N_n}}  \boden^{N_n}_{N_n} (t) \, \d t +\sum_{i=1}^{{N_n}-1} \Bigl( \xi^\boden_{i} \underline f(s_i) - \frac{L_i (\xi^\boden_{i}-s_i )^2}{2} - s_i \underline f(s_i)   
  %- \xi^\boden_{i} \underline f(s_{i+1}) - \frac{L_i (\xi^\boden_{i} -s_{i+1})^2}{2}  + s_{i+1} \underline f(s_{i+1}) \Bigr)\\
  %%
    %\stackrel{\text{telescope-} \sum}{=}  \int_{I_0}  \boden^1_{N_n} (t) \, \d t + \int_{I_{N_n}}  \boden^{N_n}_{N_n} (t) \, \d t + s_{N_n} \underline f(t_{N_n}) - s_1 \underline f(s_1)+\sum_{i=1}^{{N_n}-1} \Bigl(\xi^\boden_{i} \underline f(s_i) - \frac{L_i (\xi^\boden_{i}-s_i )^2}{2}   
  %- \xi^\boden_{i} \underline f(s_{i+1}) - \frac{L_i (\xi^\boden_{i} -s_{i+1})^2}{2}  \Bigr) \\
  %%%
  %%= \int_{I_0}  \boden^1_{N_n} (t) \, \d t + \int_{I_{N_n}}  \boden^{N_n}_{N_n} (t) \, \d t + s_{N_n} \underline f(t_{N_n}) - s_1 \underline f(t_1)+  \sum_{i=1}^{{N_n}-1} \Bigl(\xi^\boden_{i} \bigl( \underline f(s_i) - \underline f(s_{i+1})\bigr) - \frac{L_i}{2} \bigl( (\xi^\boden_{i}-s_i )^2 + (\xi^\boden_{i} -s_{i+1})^2 \bigr) 
 %%\Bigr)  \\
 %%%
  %= [t \underline f(s_1) + \frac{1}{2} L_0 (t - s_1)^2]_{s_0}^{s_1}  + [s \underline f(s_{N_n}) - \frac{1}{2} L_{N_n} (t - s_{N_n})^2]_{s_{N_n}}^{s_{{N_n}+1}}  + s_{N_n} \underline f(t_{N_n}) - s_1 \underline f(s_1)+  \sum_{i=1}^{{N_n}-1} \Bigl(\xi^\boden_{i} \bigl( \underline f(s_i) - \underline f(s_{i+1})\bigr) - \frac{L_i}{2} \bigl( (\xi^\boden_{i}-s_i )^2 + (\xi^\boden_{i} -s_{i+1})^2 \bigr) 
 %\Bigr) \\
%%
  %= s_{{N_n}+1} \underline f(s_{N_n})-s_0 \underline f(s_1) - \frac{1}{2} L_0 (s_0 - s_1)^2  - \frac{1}{2} L_{N_n} (s_{{N_n}+1} - s_{N_n})^2 +  \sum_{i=1}^{{N_n}-1} \Bigl(\xi^\boden_{i} \bigl( \underline f(s_i) - \underline f(s_{i+1})\bigr) - \frac{L_i}{2} \bigl( (\xi^\boden_{i}-s_i )^2 + (\xi^\boden_{i} -s_{i+1})^2 \bigr) 
 %\Bigr) 
%$
 %
 %
 %
%
%\end{proof}
%
%\end{thm}

Note, the definite integrals only require the existing function samples on our grid $G_{N_n}$. 

\subsubsection{Batch quadrature algorithm}
We are now in a position to turn our preparatory derivations into an algorithm implementing a batch quadrature rule. 
The algorithm is provided in 
%\IncMargin{-2em}
\begin{algorithm} 
\label{alg:batchhoelderquad1}
\begin{small}
%\SetKwData{flag}{flag}
\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
%
\Input{H\"older coefficients $L_1,\ldots$, and exponent $p$,00.
erroneous sample $D_n= \{\bigl( s_i, \tilde f_i, \varepsilon(s_i) \bigr) \vert i=1,\ldots, N_n \} $.}
\Output{Integral estimate lower and upper bounds $S^\boden_n, S^\decke_n $}
\BlankLine
%\emph{special treatment of the first line}\;
%$\flag \leftarrow 0$;\\
1: // \texttt{Solve for breakpoints: } \\
2: $ (\lambda_1^\decke,...,\lambda_{{N_n}-1}^\decke) \leftarrow \argmin_{(\lambda_1,...,\lambda_{{N_n}-1})} \mathfrak S^\decke_n\bigl(\lambda_1,...,\lambda_{{N_n}-1}\bigr)$\\
%3: 
%$ (\lambda_1^\boden,...,\lambda_{{N_n}-1}^\boden) \leftarrow \argmax_{(\lambda_1,...,\lambda_{{N_n}-1})} \mathfrak S^\boden_n\bigl(\lambda_1,...,\lambda_{{N_n}-1}\bigr)$

3: 
\ForEach {$i \in \{1,\ldots,N_n-1 \}$}{ 4: $\xi_i^\decke \leftarrow s_{i} + \lambda_i^\decke (s_{i+1}-s_{i})$ ;\\
5: $\xi_i^\boden \leftarrow s_{i} + (1-\lambda_i^\decke) (s_{i+1}-s_{i})$}

5:  \texttt{// Compute integral bounds as per Thm. \ref{thm:ceilfloorintofxi}:}\\
6: $S^\decke_n \leftarrow \sum_{i=1}^{N_n}  \tilde f(s_i) (\xi_{i}^\decke - \xi_{i-1}^\decke) +  (\xi_{i}^\decke - \xi_{i-1}^\decke)\, \varepsilon_i \,+ \frac{L_i}{{p+1}} (\xi_{i}^\decke-s_i )^{p+1}+  \frac{L_{i-1}}{{p+1}}(s_i-\xi_{i-1}^\decke)^{p+1} $\\	 
7: $S^\boden_n \leftarrow \sum_{i=1}^{N_n}  \tilde f(s_i) (\xi_{i}^\boden - \xi_{i-1}^\boden) - (\xi_i^\boden - \xi_{i-1}^\boden)\, \varepsilon_i \,- \frac{L_i}{{p+1}} (\xi_i^\boden-s_i )^{p+1} - \frac{L_{i-1}}{{p+1}}(s_i-\xi_{i-1}^\boden)^{p+1}   $.
\BlankLine
\caption{Batch algorithm yielding a lower and upper bound $S^\decke_n, S^\boden_n $ of the integral to be estimated as per $S^\decke_n \geq \int_I f(x) \d x \geq S^\boden_n $. A point estimate $\hat S_n$ could for instance be obtained as per $\hat S_n := \frac{S^\decke_n + S^\boden_n}{2} $ with error bound $\hat E_n = \frac{S^\decke_n - S^\boden_n}{2}$.}

\end{small}
\end{algorithm}

The statement of the algorithm is fairly general. As stated previously, for special cases the breakpoints $\xi^\decke, \xi^\boden$ can be calculated in closed form (e.g. as per Eq. \ref{eq:lipxifloor} and Eq. \ref{eq:lipxiceil} for the case $p=1$) and directly inserted in lines $5$ and $6$. In all other cases, we have already described how the $\lambda_i^\decke, \lambda_i^\boden$ can be calculated by solving Eq. \ref{eq:lambdaceil} and Eq. \ref{eq:lambdafloor}, respectively. If required, root-finding methods can be employed to solve these equations numerically. For convenience, this approach is epitomised in Alg. \ref{alg:numsolve4lambdahoelderquad}.

%\IncMargin{-2em}
\begin{algorithm} \label{alg:numsolve4lambdahoelderquad}
\begin{small}
%\SetKwData{flag}{flag}
\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
%
\Input{H\"older coefficients $L_i$, and exponent $p$. 

erroneous sample $D_n= \{\bigl( s_i, \tilde f_i, \varepsilon(s_i) \bigr) \vert i=1,\ldots, N_n \} $.}
\Output{Integral estimate lower and upper bounds $S^\boden_n, S^\decke_n $}
\BlankLine
%\emph{special treatment of the first line}\;
%$\flag \leftarrow 0$;\\
1: // \texttt{Solve for breakpoints: } \\
2: $ (\lambda_1^\decke,...,\lambda_{{N_n}-1}^\decke) \leftarrow \argmin_{(\lambda_1,...,\lambda_{{N_n}-1})} \mathfrak S^\decke_n\bigl(\lambda_1,...,\lambda_{{N_n}-1}\bigr)$\\
3: 
$ (\lambda_1^\boden,...,\lambda_{{N_n}-1}^\boden) \leftarrow \argmax_{(\lambda_1,...,\lambda_{{N_n}-1})} \mathfrak S^\boden_n\bigl(\lambda_1,...,\lambda_{{N_n}-1}\bigr)$

4: 
\ForEach {$i \in \{1,\ldots,N_n-1 \}$}{ $\xi_i^\decke \leftarrow s_{i} + \lambda_i^\decke (s_{i+1}-s_{i})$ ;
$\xi_i^\boden \leftarrow s_{i} + \lambda_i^\boden (s_{i+1}-s_{i})$}

5:  \texttt{// Compute integral bounds as per Thm. \ref{thm:ceilfloorintofxi}:}\\
6: $S^\decke_n \leftarrow \sum_{i=1}^{N_n}  \tilde f(s_i) (\xi_{i}^\decke - \xi_{i-1}^\decke) +  (\xi_{i}^\decke - \xi_{i-1}^\decke)\, \varepsilon_i \,+ \frac{L_i}{{p+1}} (\xi_{i}^\decke-s_i )^{p+1}+  \frac{L_{i-1}}{{p+1}}(s_i-\xi_{i-1}^\decke)^{p+1} $\\	 
7: $S^\boden_n \leftarrow \sum_{i=1}^{N_n}  \tilde f(s_i) (\xi_{i}^\boden - \xi_{i-1}^\boden) - (\xi_i^\boden - \xi_{i-1}^\boden)\, \varepsilon_i \,- \frac{L_i}{{p+1}} (\xi_i^\boden-s_i )^{p+1} - \frac{L_{i-1}}{{p+1}}(s_i-\xi_{i-1}^\boden)^{p+1}   $.
\BlankLine
\caption{Batch algorithm yielding a lower and upper bound $S^\decke_n, s^\boden_n $ of the integral to be estimated as per $\decke_n \geq \int_I f(x) \d x \geq \boden_n $. A point estimate $\hat S_n$ could for instance be obtained as per $\hat S_n := \frac{S^\decke_n + S^\boden_n}{2} $ with error bound $\hat E_n = \frac{S^\decke_n - S^\boden_n}{2}$.}


\end{small}
\end{algorithm}


\subsubsection{Adaptive quadrature and error convergence -- open} Next, we will investigate . That is, we want to establish convergence of our integrals' estimates to the true definite integral. To this end, we note that $S^\decke_n - S^\boden_n$ quantifies the error or magnitude of our uncertainty about the true integral $S$. 

\begin{thm}
\begin{align*}
		E_n := S^\decke_n - S^\boden_n 
& ...\\
\end{align*}
Furthermore, we have $\lim_{{N_n} \to \infty} S^\decke_n - S^\boden_n =0$, if grid $G_{N_n} \stackrel{{N_n} \to \infty}{\to} G$, where $G$ is dense in domain interval $I$. 

\begin{proof}

Let $e_i = \varepsilon(s_{i+1}) - \varepsilon(s_{i})$ and $d_i = \tilde f(s_{i+1}) - \tilde f(s_i)$.
Note, $\underline f(s_{i+1}) - \underline f(s_i) = d_i - e_i$ and $\overline f(s_{i+1}) - \overline f(s_i) = d_i + e_i$. Furthermore, we define $Q_i := \frac{s_i -s_{i+1}}{2}, P_i:= \frac{d_i + \varepsilon_i}{2 L_i}$ and $M_i := \frac{d_i - \varepsilon_i}{2 L_i}$.
With these definitions, we have \\
$(i)\, \xi^\decke_i - s_i = - Q_i + P_i $\\
%
$(ii) \,\xi^\decke_i - s_{i+1} =  Q_i + P_i $\\
%
$(iii) \,\xi^\boden_i - s_{i} =  -Q_i - M_i $\\
%
$(iv) \, \xi^\boden_i - s_{i+1} =  Q_i - M_i $.

We have:
\begin{align*}
S^\decke_n  - S^\boden_n =& s_{{N_n}+1} (\overline f(s_{N_n}) - \underline f(s_{N_n})) + s_0 ( \underline f(s_1) -  \overline f(s_1))\\ \\ 
&+  L_0 (s_0 - s_1)^2  + L_{N_n} (s_{{N_n}+1} - s_{N_n})^2\\
		 &+\sum_{i=1}^{{N_n}-1} \xi^\decke_{i} \bigl( \overline f(s_i) - \overline f(s_{i+1}) \bigr) - \xi^\boden_{i} \bigl( \underline f(s_i) - \underline f(s_{i+1})\bigr) \\
		&+ \sum_{i=1}^{{N_n}-1} \frac{L_i}{2} \bigl( (\xi^\decke_{i}-s_i )^2+ (\xi^\decke_{i} -s_{i+1})^2 \bigr) + \frac{L_i}{2} \bigl( (\xi^\boden_{i}-s_i )^2 + (\xi^\boden_{i} -s_{i+1})^2 \bigr) \\
		%
		\stackrel{\text{ }}{=} 
& s_{{N_n}+1} 2 \varepsilon_{N_n} - s_0 2 \varepsilon_1 +  L_0 (s_0 - s_1)^2  + L_{N_n} (s_{{N_n}+1} - s_{N_n})^2\\
		 &-\sum_{i=1}^{{N_n}-1} \xi^\decke_{i} \bigl( d_i+ e_i \bigr) + \xi^\boden_{i} \bigl(  d_i-e_i \bigr) \\
		&+ \sum_{i=1}^{{N_n}-1} \frac{L_i}{2} \Bigl( (\xi^\decke_{i}-s_i )^2+ (\xi^\decke_{i} -s_{i+1})^2  +  (\xi^\boden_{i}-s_i )^2 + (\xi^\boden_{i} -s_{i+1})^2 \Bigr) \\
\end{align*}
%
\begin{align*}
		\stackrel{\text{(i)-(iv) }}{=} 
& s_{{N_n}+1} 2 \varepsilon_{N_n} - s_0 2 \varepsilon_1 +  L_0 (s_0 - s_1)^2  + L_{N_n} (s_{{N_n}+1} - s_{N_n})^2\\
		 &-\sum_{i=1}^{{N_n}-1} \xi^\decke_{i} \bigl( d_i+ e_i \bigr) + \xi^\boden_{i} \bigl(  d_i-e_i \bigr) \\
		&+  \sum_{i=1}^{{N_n}-1} \frac{L_i}{2} \Bigl( (-Q_i+P_i)^2+ (Q_i+P_i)^2  +  (-Q_i - M_i)^2 + (Q_i - M_i)^2 \Bigr) \\
\end{align*}
%
\begin{align*}
		\stackrel{ }{=} 
& s_{{N_n}+1} 2 \varepsilon_{N_n} - s_0 2 \varepsilon_1 +  L_0 (s_0 - s_1)^2  + L_{N_n} (s_{{N_n}+1} - s_{N_n})^2\\
		&+  \sum_{i=1}^{{N_n}-1} L_i \Bigl( 2 Q_i^2+  P_i^2  +   M_i^2 \Bigr) 
		-\sum_{i=1}^{{N_n}-1} (\xi^\decke_{i} - \xi^\boden_i ) e_i  + (\xi^\boden_{i}+ \xi^\decke_i) d_i
		\\
\end{align*}
%
It can be easily verified that $2 Q_i^2 = \frac{(s_i - s_{i+1})^2}{2}$ and $M_i^2 + P_i^2 = \frac{d_i^2 + e_i^2}{2 L_i^2}$, as well as 
$\xi^\decke_i + \xi^\boden_i = (s_i + s_{i+1}) + \frac{e_i}{L_i}$ and $\xi^\decke_i - \xi^\boden_i = \frac{d_i}{L_i}$.

Substituting these relations into the equation and some simplifying arithmetics yield:
\begin{align*}
		E_n = S^\decke_n - S^\boden_n 
& =s_{{N_n}+1} 2 \varepsilon_{N_n} - s_0 2 \varepsilon_1 +  L_0 (s_0 - s_1)^2  + L_{N_n} (s_{{N_n}+1} - s_{N_n})^2\\
		&+  \sum_{i=1}^{{N_n}-1} L_i \frac{(s_i - s_{i+1})^2}{2} +  \frac{d_i^2 + e_i^2}{2 L_i} \\
		&-\sum_{i=1}^{{N_n}-1} \frac{d_i}{L_i} e_i  + d_i (s_i + s_{i+1}) + d_i \frac{e_i}{L_i} 
		\\
\end{align*}

Resubstitution of the definitions of $e_i$ and $d_i$ yields the desired result.
\end{proof}
\end{thm}

\begin{thm}
\[E_n := S^\decke_n - S^\boden_n = \frac{1}{2} \sum_{i=1}^{{N_n}-1} L_i (s_{i+1} -s_i)^2 - \frac{\bigl(f(s_{i+1}) -f(s_i)\bigr)^2}{L_i} \geq 0.\] 
Furthermore, we have $\lim_{{N_n} \to \infty} S^\decke_n - S^\boden_n =0$, if grid $G_{N_n} \stackrel{{N_n} \to \infty}{\to} G$, where $G$ is dense in domain interval $I$. 

\begin{proof}


Referring to Thm. \ref{thm:quad_ceiling} and Thm. \ref{thm:quad_ceiling}, using the definitions of the $\xi^\decke_i$ and $\xi^\boden_i$, as well as a bit of algebraic manipulation, yields the desired equality 
$S^\decke_n - S^\boden_n = \frac{1}{2} \sum_{i=1}^{{N_n}-1} L_i (s_{i+1} -s_i)^2 - \frac{\bigl(f(s_{i+1}) -f(s_i)\bigr)^2}{L_i}$. 

For each $i$ we have can make the following argument:
Due to H\"older continuity, we have  
$\frac{\bigl(f(s_{i+1}) -f(s_i)\bigr)^2}{L_i^2}  \leq (s_{i+1}-s_i)^{2p}$.

Hence,
$a_{N_n}^i:=L_i (s_{i+1} -s_i)^{2p} - \frac{\bigl(f(s_{i+1}) -f(s_i)\bigr)^2}{L_i}$

$=L_i [(s_{i+1} -s_i)^{2p} - \frac{\bigl(f(s_{i+1}) -f(s_i)\bigr)^2}{L_i^2}]$.

$\geq L_i [(s_{i+1} -s_i)^2 - (s_{i+1} -s_i)^2] =0$.
Thus, $S^\decke_n - S^\boden_n = \sum_i a_{N_n}^i \geq 0$. \\

Finally, we prove vanishing error in the limit of a dense grid. 
Let $(G_{N_n})$ a sequence of grids converging to a grid $G$ that is dense in $I$. By Thm. \ref{thm:enclosure1d_desiderata}, we know that $\lim_{{N_n} \to \infty} \decke_n = \lim_{{N_n} \to \infty}
    \boden_n = f$ \textit{uniformly}. Due to uniform convergence, we can exchange integral and limites. That is, we have 

$0 = \int_I f(t) \, \d t - \int_I f(t) \, \d t$
$=  \int_I \lim_{{N_n} \to \infty} \decke_n(t) \, \d t  - \int_I \lim_{{N_n} \to \infty}  \boden_n (t) \, \d t$
$\stackrel{unif. conv.}{=} \lim_{{N_n} \to \infty} \int_I \decke_n(t) \, \d t  - \lim_{{N_n} \to \infty} \int_I \boden_n (t) \, \d t$    
$=\lim_{{N_n} \to \infty} S^\decke_n - S^\boden_n $.






\end{proof}

\end{thm}

\begin{thm}
\[E_n := S^\decke_n - S^\boden_n = \frac{1}{2} \sum_{i=1}^{{N_n}-1} L_i (s_{i+1} -s_i)^2 - \frac{\bigl(f(s_{i+1}) -f(s_i)\bigr)^2}{L_i} \geq 0.\] 
Furthermore, we have $\lim_{{N_n} \to \infty} S^\decke_n - S^\boden_n =0$, if grid $G_{N_n} \stackrel{{N_n} \to \infty}{\to} G$, where $G$ is dense in domain interval $I$. 

\begin{proof}
Referring to Thm. \ref{thm:quad_ceiling} and Thm. \ref{thm:quad_ceiling}, using the definitions of the $\xi^\decke_i$ and $\xi^\boden_i$, as well as a bit of algebraic manipulation, yields the desired equality 
$S^\decke_n - S^\boden_n = \frac{1}{2} \sum_{i=1}^{{N_n}-1} L_i (s_{i+1} -s_i)^2 - \frac{\bigl(f(s_{i+1}) -f(s_i)\bigr)^2}{L_i}$. 

For each $i$ we have can make the following argument:
Due to H\"older continuity, we have  
$\frac{\bigl(f(s_{i+1}) -f(s_i)\bigr)^2}{L_i^2}  \leq (s_{i+1}-s_i)^2$.

Hence,
$a_{N_n}^i:=L_i (s_{i+1} -s_i)^2 - \frac{\bigl(f(s_{i+1}) -f(s_i)\bigr)^2}{L_i}$

$=L_i [(s_{i+1} -s_i)^2 - \frac{\bigl(f(s_{i+1}) -f(s_i)\bigr)^2}{L_i^2}]$.

$\geq L_i [(s_{i+1} -s_i)^2 - (s_{i+1} -s_i)^2] =0$.
Thus, $S^\decke_n - S^\boden_n = \sum_i a_{N_n}^i \geq 0$. \\

Finally, we prove vanishing error in the limit of a dense grid. 
Let $(G_{N_n})$ a sequence of grids converging to a grid $G$ that is dense in $I$. By Thm. \ref{thm:enclosure1d_desiderata}, we know that $\lim_{{N_n} \to \infty} \decke_n = \lim_{{N_n} \to \infty}
    \boden_n = f$ \textit{uniformly}. Due to uniform convergence, we can exchange integral and limites. That is, we have 

$0 = \int_I f(t) \, \d t - \int_I f(t) \, \d t$
$=  \int_I \lim_{{N_n} \to \infty} \decke_n(t) \, \d t  - \int_I \lim_{{N_n} \to \infty}  \boden_n (t) \, \d t$
$\stackrel{unif. conv.}{=} \lim_{{N_n} \to \infty} \int_I \decke_n(t) \, \d t  - \lim_{{N_n} \to \infty} \int_I \boden_n (t) \, \d t$    
$=\lim_{{N_n} \to \infty} S^\decke_n - S^\boden_n $.






\end{proof}

\end{thm}

We see from the expression that the error is larger for function samples whose values do not differ much. 


%Thus, $a^i_{N_n} = \abs{a^i_{N_n}}$.
%
%Hence,  sequence $(q_{N_n})_{{N_n} \in \nat}$, $q_{N_n} := S^\decke_n - S^\boden_n = \frac{1}{2} \sum_{i=1}^{{N_n}-1} a_{N_n}^i$ is convergent, iff the series is absolutely convergent.
%
%
%Let $s_{N_n} := \max_i a^i_{N_n} = \max_i \abs{a_{N_n}^i}.$ We show $q_{N_n} \to 0$ by showing $({N_n}-1) s_{N_n} \to 0$ (as ${N_n} \to \infty$).


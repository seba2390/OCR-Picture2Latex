

\section{Problem Definition}
\label{sec:prob_def}
In Ex. \ref{ex:topinf_quad}, we provided an example of a topological inference problem for conservative quadrature. Unfortunately, the proof of conservativeness of the trapezoid method relies upon existence and knowledge of second derivatives and is restricted to one-dimensional integrands. Many applications demand coarser knowledge and applicability to a less-restricted class of integrands. 

%As a basic example, consider the ordinary differential equation $\frac{\d x}{\d t} = (\xi - x)$ where $\xi: I \subset \Real \to \Real $ is an absolutely continuous function superimposed by a countable number of steps. Suppose, the ODE describes the trajectory $x: I \to \Real$ of a controlled particle in one-dimensional state space. Based on $N$ time-state observations $D_N=(t_1,x_1 ),..., (t_N,x_N )$ we desire to estimate the total distance travelled $S$ in time interval $I$, $S = \int_I x(t) \d t$. Solving

\jcom{REVISE:}

\textbf{Setting.}
Let $d \in \nat$ and $I=[a_1,b_1] \times \ldots \times [a_d,b_d] \subset \Real^d$ be a bounded hyperrectangle domain. Assume, we have access to a sample set $D_N:= \{\bigl( s_i, \tilde f_i, \varepsilon(s_i) \bigr) \vert i=1,\ldots, N \} $ containing $N \in \nat$ samples value $\tilde f_i$ of the target function $f: I \to \Real$ at sample input $s_i \in I$. The samples have interval-bounded error given by $\varepsilon : I \to \Real_{\geq 0}$. That is, all we know is that $f(s_i) \in [\underline f(s_i), \overline f(s_i) ]$ where $\underline f(s_i) := \tilde f_i - \varepsilon(s_i)$ and $\overline f(s_i) := \tilde f_i + \varepsilon(s_i)$.

The interpretation of the errors depends on the given application. For instance, in an experimental setting they could represent measurement errors. Most relevant to this work, the errors might represent approximation errors that arise if the target has to be approximated numerically.

Furthermore, for each sub-hyperrectangle $J \subset I$ we have access to a Lipschitz number $L_J \geq 0$. That is, $L_J$ is a number such that $\forall x,x' \in J: \abs{f(x) - f(x')} \leq L_J \, \norm{ x- x'}$ where $\norm \cdot$ is a fixed norm on $I$.\footnote{Note, due to norm-equivalence in finite-dimensional space, it is of no principal concern which norm is chosen.} 

 Based on sample set $D_N$, we desire to design algorithms solving the following two
tasks:

\subsection{Task 1 -- Computing a conservative \textit{function estimate}}
\label{sec:problemdef_task1}
Compute a function $B: D_N \mapsto (\decke_N,\boden_N)$ estimating the target that satisfies the following \textbf{desiderata}:
\begin{enumerate}
	\item \textit{Conservatism}. $\decke_N, \boden_N :I \to \Real$ functions that enclose the target conservatively. That is, 
			we can guarantee  $\decke_N(x) \geq f(x) \geq \boden_N(x), \forall x \in I$. (We will refer to $\decke_N, \boden_N$ as (Lipschitz-) ceiling and floor, respectively. 
				\item \textit{Convergence} to the target. If $(D_N)_{N \in \nat }$ is a sample set sequence whose inputs converge to a dense subset of $I$ (as $N \to \infty$), we require $\exists \gamma, \phi \geq 0: \decke_N - f \stackrel{N \to \infty} \longrightarrow \gamma \leq \varepsilon, f- \boden_N \stackrel{N \to \infty} \longrightarrow \phi \leq \varepsilon$ pointwise. In the absence of errors ($\varepsilon \equiv 0$) this means uniform convergence to the target.
				\item \textit{Optimality}. We desire the enclosure to be optimal. That is, to $\decke_N, \boden_N$ should be as tight as possible, without losing conservativeness.
\end{enumerate}

From the perspective of topological inference, the estimator is a data inference method for function estimation:
$B(\cdot) = M_{dinf}(\mathcal K_{prior}, \cdot, \gamma ) $ (for some sufficiently large $\gamma$) mapping sample data into a hypothesis interval of possible functions. 
Here,  our a priori knowledge is that we know, for each $J \subset I$ a nonnegative number $L_J$ such that the underlying target $f \in \mathcal F$ is $L_J-$Lipschitz on $J$. That is, $\mathcal K_{prior} =\{\phi \in \mathcal F \,|\, \forall J \subset I \forall x,x' \in J: \abs(\phi(x) - \phi(x') \leq L_J \norm{x-x'}\}$. 
Note, we will not explicitly compute the prior knowledge set. Instead will will fold in the Lipschitz continuity to define an optimal estimator output defining an enclosure that coincides with $\mathcal K_{post} \subset \mathcal K_{prior}$ and hence, with $T (\mathcal K_{post} \cup \mathcal K_{prior})$. Therefore, the resulting inference mechanism will be optimal. 

Note, how our desiderata are equivalent to the corresponding notions of the inference mechanism that is to be designed.

\subsection{Task 2 -- Estimating definite integrals.}
	\label{sec:problemdef_task2}
 Compute an \textit{integral estimator} $E: D_N \mapsto (\underline S_N, \overline S_N)$ of the definite integral $S := \int_I f(x) \, \d x$. The estimator's outputs translate to an estimate $\hat S_N = \frac{\underline S_N+ \overline S_N}{2}$ of $S$ with error $\mathfrak E(D_N) =\overline S_N - \hat S_N = \frac{1}{2} \abs{\overline S_N - \underline S_N}$. Similarly to before, we desire our estimator to exhibit the following properties:
\begin{enumerate}
			\item \textit{Conservatism}.  Regardless of $D_N$, we can guarantee $\overline S_N \geq S \geq \underline S_N$. 
			
			\item \textit{Convergence} to the ground truth. If $(D_N)_{N \in \nat }$ is a sample set sequence whose inputs converge to a dense subset of $I$ (as $N \to \infty$) and $\varepsilon$ is integrable, we require $\abs{\overline S_N - \underline S_N} \stackrel{N \to \infty} \longrightarrow \int_I  \overline \varepsilon(x) \d x$ where $\overline \varepsilon$ is the smallest upper bound function on $\varepsilon$ that is integrable. In the absence of errors ($\varepsilon \equiv 0$) this implies convergence of estimate $\hat S_N$ to the true integral $S$.
			\item \textit{Optimality}. Finally, we desire the bounds to be optimal, that is, to be as tight as possible, without losing conservativeness.
\end{enumerate}

Viewed from the perspective of our topological inference frame-work, the estimator is a data inference method for quadrature:
$E(\cdot) = M_{dinf}(\mathcal K_{prior}, \cdot, \gamma ) $ (for some sufficiently large $\gamma$) mapping sample data into a hypothesis interval of possible functions. 
Here,  our a priori knowledge is that we know, for each $J \subset I$ a nonnegative number $L_J$ such that the underlying target $f \in \mathcal F$ is $L_J-$Lipschitz on $J$. That is, $\mathcal K_{prior} =\{\phi \in \mathcal F \,|\, \forall J \subset I \forall x,x' \in J: \abs(\phi(x) - \phi(x') \leq L_J \norm{x-x'}\}$. 
Note, we will not explicitly compute the prior knowledge set. Instead will will fold in the Lipschitzness to define an optimal estimator output defining an enclosure that coincides with $ T (\mathcal K_{post} \cup \mathcal K_{prior})$ and thus, is optimal.

As for Task 1, our desiderata are equivalent to the corresponding notions of the inference mechanism that is to be designed.


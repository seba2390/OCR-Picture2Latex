
\subsection{An incremental lazy update rule for the H\"older constant}
\label{sec:lazyconstants}
Above our theoretical guarantees are based on the assumption that the parameters $L(n)$ were set to a fixed H\"older constant of the target function. In other words, if we know a H\"older constant $L^*$ of the ground truth $f$ then setting $L(n)=L^*,\forall n$ ensures the desired conservatism and convergence properties of the KI rule. However, in a black-box learning setting, a H\"older constant may not be know a priori. Therefore, the estimation of Lipschitz constants on the basis of a sample is a problem that has been considered by several authors in the past \cite{Wood1996,Beliakov2006}. For instance, Wood and Zhang \cite{Wood1996} reduced the problem of estimating a global Lipschitz constant of a one-dimensional function to fitting a Weibull distribution to random absolute slope estimates between uniformly sampled inputs. Unfortunately, their results are restricted to one-dimensional functions that satisfy the Gnedenko condition and where one has access to a batch of samples drawn i.i.d. uniformly at random and no observational errors. Beliakov \cite{Beliakov2006} used a simple empirical estimator of a Lipschitz constant that did not require distributional assumptions and can be seen as a simple special case of our proposed lazy method. In contrast to his estimator, our approach is designed to receive data incrementally and makes provisions for observational noise in the sample. We do not make any distributional assumptions about the noise or any assumptions about the target other than that it is 
a continuous function from a pseudo-metric space into an additive group endowed with a translation-invariant metric. 
  


%
%\subsection{A Bayesian treatment of probabilistically uncertain H\"older constants}
%\label{sec:bayesupdatelipconst}
%Throughout the previous section we have assumed that the H\"older constants were known to us. 
%However, in many cases, we may be uncertain about the best H\"older constant. We assume the uncertainty is expressed as a distribution. Following the Bayesian point of view, we interpret probability densities over events as subjective degrees of beliefs that these events hold true. 
%In the following subsection, we describe how to utilize the densities over the best H\"older constant $L^* \in \Real_+$ to yield a (once again, conservative) bound on the probability of our functions estimates and integrands not being conservative. After that, we will address the question of how to update our beliefs over $L^*$ in the light of new function evaluations in a Bayesian manner.
%
%For simplicity, we will assume there are no observational errors and that there are no a priori bounds. That is, $\obserr_i = 0, \, \forall i$ and $\lbf = -\infty, \ubf = \infty$. Furthermore, we tacitly assume the H\"older exponent $p$ is known and fixed.
%
%Let $\pi: \Real_+ \to \Real_+$ be a density encoding our belief over best H\"older constant $L^*$ of target function $f$.
%In the absence of bounds and observational error, we define the H\"older enclosure $\einschluss (\ell) =\{ \phi \,| \, \phi(x) \in \prederrbox_n(x)\}$  where $\prederrbox_n$ is the uncertainty hyperrectangle defined above (see Eq. \ref{eq:prederrint}), computed on the basis of H\"older constant $L=\ell$.
%Assume we construct a H\"older enclosure $\einschluss (\ell)$ based on choosing $\ell \in \Real_+$ as a H\"older constant.  How large do we need to choose $\ell$ to guarantee that $f$ is completely contained in the enclosure? Since we are uncertain about the true H\"older constant, this question can only be framed probabilistically. That is, for a given certainty threshold  $\theta \in (0,1)$ we desire to find $\ell > 0$ such that 
%\[ \theta \leq \Pr[ f \in \einschluss (\ell) ]. \]  
%
%\begin{thm} \label{thm:ksjhdkjs} Let $\decke_n,\boden_n$ be a valid ceiling and floor function, respectively.
%Let $P: t \mapsto \int_{x \leq t} \pi(x) \,\d x $ our density's cumulative distribution function (cdf).
%We have, \[P(\ell) \geq \theta \Rightarrow \theta \leq \Pr[ f \in \einschluss (\ell) ].  \] 
%\begin{proof} 
%Let $L^*$ denote the best H\"older constant of function $f$.
%
% $\forall \ell \geq L \geq 0 :   \Pr[ f \in \einschluss (\ell) | L^*=L] = 1$. 
%Hence,
%$
%\Pr\bigl[ f \in \einschluss (\ell) \bigr] 
%= \int_0^\ell \Pr\bigl[ f \in \einschluss (\ell) | L^*=L\bigr] \,\d P(L) 
% + \int_\ell^\infty \Pr\bigl[ f \in \einschluss (\ell) | L^*=L\bigr] \,\d P(L) 
%=  \int_0^\ell \,\d P(L) + \int_\ell^\infty \Pr\bigl[ f \in \einschluss (\ell) | L^*=L\bigr] \,\d P(L)  
%\geq \int_0^\ell \,\d P(L) 
%= P(\ell).$
%\end{proof}
%\end{thm}
%
%That is to say, in order to guarantee conservativeness of our enclosure, all we need to do is to compute it on the basis of 
%a fixed H\"older constant that is just large enough such that $P(\ell) = \int_0^l \pi(L) \,dL \geq \theta$. Notice, if the integral cannot easily be determined in closed-form, but a H\"older constant for density $\pi$ is known, we can employ our H\"older quadrature method described previously (based on a known constant), to evaluate $P(\ell)$ conservatively by finding a lower bound on it. \\
%
%
%%When it comes to the task of quadrature, in the presence of an uncertain H\"older constant, the error bounds of the integral estimates afforded by our method also are valid to a level of probabilistic belief. 
%%
%%Combining Thm. \ref{thm:ksjhdkjs} with our boundedness results for conservative quadrature of Sec. \ref{sec:quadr} immediately yields the following result:
%%\begin{cor}
%%Let $S := \int_I f(t) \, \d t$. 
%%With the definitions introduced above, we have  \[P(\ell) \geq \theta \Rightarrow \theta \leq \Pr\Bigl[ \hat S^\decke_N \geq S \geq \hat S^\boden_N  \Bigr]  \] 
%%where $\hat S^\decke_N , \hat S^\boden_N $ are computed assuming a H\"older constant of $\ell$. 
%%
%%\end{cor}
%%
%%The Corollary asserts that if we check that $P(\ell) \geq \theta$ for some desired threshold $\theta$ then our probabilistic belief in the integral $S$ being within the interval $[S_n^\boden,S_n^\decke]$ also is at least $\theta$.
%
%\subsubsection{A Bayesian update rule}
% Define $\metric_{\outspace}(f_1,f_2) = \abs{f_1-f_2}$ and let $\metric_{\inspace}(x,y)$ be some input space (pseudo-) metric as before. 
%
%%That is a H\"older constant $L$ with respect to the canonical metric $(x,y) \mapsto \norm{x-y}$ is a Lipschitz constant w.r.t $\metric_\inspace$. We will refer to $L$ uniformly as \textit{H\"older} constant.
%
%
%Assume we hold a prior belief over the best H\"older constant $L^*$ encoded as a density $\pi_0 : I \subset \Real_+ \to [0,1]$.
%Assume we are given a sample $D = \{(s_i,f_i)\}_{i=1,...,N}$ of input-function value pairs, $x_i \in \mathcal X$, $f_i = f(s_i) \in \outspace, \forall i$, the question arises of to calculate a posterior in the light of the new data. 
%
%Since we assume $f :\mathcal X \to \mathcal Y \subseteq \Real$ is H\"older we have $ \frac{\metric_\outspace(f_i,f_j)}{\metric_{\inspace}(s_i,s_j)} \leq L^*,  (i,j =1,...,N, x_i \neq x_j)$ where $L^*$ is the best H\"older constant of $f$. So, our observations allow us to infer that the \emph{empirical H\"older constant} 
%\begin{equation}
%	L_D := \max_{i,j,i\neq j} \frac{\metric_\outspace(f_i,f_j)}{\metric^p_{\inspace}(s_i,s_j)}
%	\label{eq:LD}
%\end{equation}
%is a lower bound on the best H\"older constant.\footnote{In the context of a special Lipschitz interpolation rule, Beliakov \cite{Beliakov2006} considered this quantity as an estimate of the Lipschitz constant.} Note, the computation of an update of this quantity can be done with computational effort linear in the number of pre-existing quantities. 
%That is, assuming a pre-existing data set $D$ and that we make an additional observation $s_{N+1},f_{N+1}$ which is incorporated into the updated data set $D' = D \cup \{(s_{N+1},f_{N+1})\}$. Instead of computing $L_{D'}$ from scratch as per Eq. \ref{eq:LD}, we can leverage:
%
%\begin{equation}
%	L_{D'}=\max \{L_D,L'\}, \,\text{ where } L' := \max_{i=1,\ldots,N} \frac{\metric_\outspace(f_{N+1},f_i)}{\metric^p_{\inspace}(s_{N+1},s_i)} 
%	\label{eq:LDupdate}
%\end{equation}
%
%which can be computed in $\mathcal O(d N)$ where as before, $d = \dim \inspace$.
%The remaining question is how to derive a posterior over $L^*$ based on this newly observed lower bound. 
%%
%%\begin{ques}
%%How can we prove that there is no information about the H\"older constant in the data other than $L_D$? That is, in particular, that \[p(L^*|D) \stackrel{!}{=}p(L^* |L_D) ??\]
%%\end{ques}
%%
%%
%%We will discuss two approaches, the Minimum-Relative-Entropy approach and Bayesian inference.
%%
%
%
%%\subsubsection{Bayesian approach}
%
%By Bayes theorem, we can write 
%\[\pi(L|L_{D'}) = \frac{\pi(L_{D'}|L) \, \pi_0(L) }{ \int_I \pi(L_{D'}|L) \, \pi_0(L) \, \d L}.\]
%
%If we are uncertain about which empirical H\"older constant we observe given the real H\"older constant  $L^* = L$ we set the Likelihood function 
%\[ \pi(L_{D'}|L) = \begin{cases} 0, L_{D'} > L\\ \frac{1}{L}, \text{otherwise}. \end{cases}.\]
%
%Of course, if the definite integrals of prior $\pi_0$ are not known in closed form, we need to approximate numerically. Depending on knowledge of smoothness properties we can either employ standard methods such as Gaussian quadrature or, if necessary, utilise our H\"older quadrature methods to that effect.
%%\begin{ques}[@Mike]
%%What is the likelihood function $p(L_D|L)= ... ?$
%%\end{ques}
%
%%\subsubsection{Minimum-Relative-Entropy Approach} 
%%
%%Computing posteriors from priors subject to constraints is the focus of max-ent inference. 
%%
%%Remember, 
%%\begin{defn}[Relative Entropy] For two densities $p,q: I  \to [0,1]$ the \textit{relative entropy} or \textit{Kullback-Leibler divergence} is defined as 
%%\[\KLD {p}{q} = \int_{I} p(x) \log \frac{p(x)}{q(x)} d\mu(x)\] where $\mu$ is a measure appropriate for domain $I$.
%%\end{defn}
%%
%%For example, if $I \subset \Real$ then $\mu$ is normally tacitly assumed to be the standard Lebesgue measure. If $I$ is a discrete set, $\mu$ is noramlly assumed to be the counting measure. In this case \[\KLD {p}{q} = \sum_{x\in I} p(x) \log_2 \frac{p(x)}{q(x)}. \]
%%
%%For our problem, we can pose the desired posterior density as the solution to the variational problem:
%%
%%\begin{align}
%%\argmin_p & \KLD {p}{p_0}\\
%%\text{s.t.:}&\\
%%& p(l) \in [0,1], \forall l \geq 0\\
%%&\SP{p}{e}_{L_2(\Real)} =1\\
%%& \SP{p}{\chi_{[0,L_D]}}_{L_2(\Real)} =0
%%\end{align}
%%
%%where $e: t \mapsto 1$ is the constant mapping to $1$ and $\chi_{[0,L_D]}$ is the indicator function for interval $[0,L_D]$.
%%
%%\begin{ques}
%%Can we solve this variational problem in closed form? How can we solve them numerically. If we have no clue, we can make everything discrete as follows...
%%\end{ques}
%%
%%\emph{Discretization}.
%%For practical purposes, it will be convenient to reduce the problem to a standard convex optimization problem as follows:
%%Let $J_1,...,J_m \subset I$ be a partition of $I\subset \Real_+$.
%%Instead of expressing a belief as a density on a continuous interval we may limit our modelling efforts to defining a belief as a discrete distribution function $\pi_0 : \{ 1,...,m\} \to [0,1], i \mapsto \Pr[ L \in J_i]$.  
%%
%%\begin{rem}
%%Notice, that this belief encoding may be easier to specify than the density on a continuum of points. 
%%For instance, assume $I = [a,b] , 0<a<b \in \Real_+ \cup \{\infty\}$ and let $a=t_0<t_1<...<t_m =b$ such that $J_i = [t_{i-1},t_i], (i=1,...,m)$.
%%Then, knowing the continuous density $p_0$ on $I$ allows us to compute the discrete density via $ \pi_0 (i) = \int_{J_i} p_0(t) \,dt=P_0 (t_i) - P_0(t_{i-1})$. The inverse computation (from discrete to continuous distribution) is not possible without further assumptions.
%%\end{rem}
%%
%%We anticipate our discretization to spawn information loss, since we only encode information about the interval not about the relative location of the H\"older number within the interval. This will be investigated next.
%%
%%%Let $\tau \in (0,1]$ denote this relative interval coordinate. That is to say, H\"older number $L = t_{i-1}+ \tau (t_i -t_{i-1}) $ is completely given by coordinates $(i,\tau) \in \{1,...,m\} \times (0,1]$ . 
%%%
%%%After discretization, our uncertainty about the exact H\"older number (not just the interval) is described by $\tilde p_0(L) =  \pi_0(i) \, p_\tau[\tau | i ]$. Assuming that, after discretization, we are completely oblivious about the location within the interval, we have $p_\tau [\tau | i ] = \frac{1}{| (0,1] |} =1$.
%%%Hence, 
%%%
%%%The magnitude of the information loss due to discretziation could be quantified as 
%%%\begin{align*}
% %%H_{\tilde p_0}-H_{ p_0}  &=\int_I p_0(t) \log p_0(t) \, dt  - \bigl(\sum_{i=1}^m \pi_0(i)   \log \pi_0(i) \bigr) \\
%%%& =  \sum_{i=1}^m \int_{J_i} p_0(t) \log p_0(t) \, dt  \\ 
%%%&- \bigl(\sum_{i=1}^m \int_{J_i} p_0(t) \,dt  \log \int_{J_i} p_0(t) \,dt \bigr)\\
%%%% 
%%%& =  \sum_{i=1}^m \Bigl(\int_{J_i} p_0(t) \log [p_0(t)] \, dt  \\
%%%&-   \int_{J_i} p_0(t) \,dt  \log [\int_{J_i} p_0(t) \,dt] \Bigr)\\
%%%& \stackrel{!?}{\leq} 0
%%%\end{align*}
%%%
%%%
%%%WEIRD !!!  The loss should be greater than 0, not smaller ! 
%%%Mhh... perhaps I should instead try this (?? Makes any difference??)
%%
%%In the discretized situation, our ignorance over $L^*$ can be encoded by the density  $\tilde p_0(L) =  \sum_{i=1}^m \pi_0(i) \, p_L [L| i ]$. Assuming that, after discretization, we are completely oblivious about the location within the interval, we have $p_L [L | i ] = \frac{1}{| J_i |} =\frac{1}{| t_i-t_{i-1} |}$.
%%Hence, $\tilde p_0(L)  =  \sum_{i=1}^m  \frac{\pi_0(i)}{| J_i |} $. 
%%
%%The magnitude of the information loss due to discretziation could be quantified as 
%%\begin{align*}
% %H_{\tilde p_0}-H_{ p_0}  &=\int_I p_0(L) \log p_0(L) \, dL  - \int_I \tilde p_0(L)    \log  \tilde p_0(L) \, dL \\
%%& = \int_I p_0(L) \log p_0(L) \, dL  \\
%%&- \int_I\sum_{i=1}^m \pi_0(i) \, p_L [L| i ]    \log \bigl(\sum_{i=1}^m \pi_0(i) \, p_L [L| i ]\bigr) \, dL \\
%%& = \int_I p_0(L) \log p_0(L) \, dL  \\
%%&- \int_I\sum_{i=1}^m \frac{\pi_0(i)}{|J_i|}     \log \bigl(\sum_{i=1}^m \frac{\pi_0(i)}{|J_i|} \bigr) \, dL \\
%%& = \int_I p_0(L) \log p_0(L) \, dL  \\
%%&- |I|  \log \bigl(\sum_{i=1}^m \frac{\pi_0(i)}{|J_i|} \bigr) \sum_{i=1}^m \frac{\pi_0(i)}{|J_i|}     \\
%%& =  \sum_{i=1}^m \Bigl(\int_{J_i} p_0(t) \log [p_0(t)] \, dt \Bigr)   \\
%%&- |I|  \log \bigl(\sum_{i=1}^m \frac{\int_{J_i} p_0(t) dt}{|J_i|} \bigr) \sum_{i=1}^m \frac{\int_{J_i} p_0(t) dt}{|J_i|}     \\
%%& \stackrel{!?} {\geq }0
%%\end{align*}
%%
% %
%%However, the benefit is that (continuous) extremization problem is reduced to a tractable, discrete optimization problem of dimensionality $m$. In fact, it is a convex program with linear constraints:
%%
%%\begin{align}
%%\argmin_p & \KLD {\pi}{\pi_0}\\
%%\text{s.t.:}&\\
%%& \pi(i) \in [0,1], \forall i \in\{1,...,m\}\\
%%&\SP{p}{e}_{2} =1\\
%%& \SP{p}{n_{L_D}}_{2} =0
%%\end{align}
%%where $e$ is a vector of $m$ ones and $n_{L_D}$ is suitably defined to mimic a discretized version of the indicator function above and whose $i$th component is defined as follows:
%%
%%$n_{L_D} (i) = \begin{cases} 1, t_i \geq L_D\\ 0, \text{otherwise.} \end{cases}$ Of course, if $t_{i-1} < L_D < t_i$ for some $i$, we have once again thrown away information,as the constraint $\SP{p}{n_{L_D}}_{2} =0$ does not capture the knowledge that there must be zero probability mass on $K_i' := [t_{i-1},L_D)$ as well. To cover this, we could consider 
%%introducing an additional component representing the probability on $K_i$  and replace the original meaning of the original $i$th component by representing the probability on  $J_i' = [L_D, t_i] =J_i - K_i$ instead of on $J_i$. In this case, the CP becomes $m+1$-dimensional. Since this is always possible to do, we can assume, without loss of generality, that $L_D $ will always be an element of $t_1,...,t_m$ for some $m$.
%%
%%
%%Note, an $m$-dimensional CP can be solved in worst-time complexity $\mathcal O(m^3)$ (LOOK IT UP!!).
%%
%%
%%\begin{rem}
%%We could investigate how the information loss (which we would expect to grow as a function of $m$) compares to the 
%%the gain in computational complexity. We should then conceive a common exchange rate / currency / trade-off parameter to 
%%find a good cut-off point.
%%\end{rem}
%%
%
%
%\begin{figure}
%        \centering
%				  \subfigure[Inferred model with $L=10$.]{
%    %\includegraphics[width = 3.7cm, height = 3cm]{content/figures/graph1_klein.eps}
%    \includegraphics[width = 4.5cm]
%								%{content/Ch_kinkyinf/figs/resultswingrock_555trials}
%								{content/Ch_kinkyinf/figs/predL10}
%    \label{fig:Hoelderconstvar1}
%  } 	
%	 \subfigure[Inferred model with $L=0.1$.]{
%    %\includegraphics[width = 3.7cm, height = 3cm]{content/figures/graph1_klein.eps}
%    \includegraphics[width = 4.5cm]
%								%{content/Ch_kinkyinf/figs/resultswingrock_555trials}
%								{content/Ch_kinkyinf/figs/predLpt1}
%    \label{fig:Hoelderconstvar2}
%  } 	%\hspace{2cm}
%	 \subfigure[Inferred model with $L=1$.]{
%    %\includegraphics[width = 3.7cm, height = 3cm]{content/figures/graph1_klein.eps}
%    \includegraphics[width = 4.5cm]
%								%{content/Ch_kinkyinf/figs/resultswingrock_555trials}
%								{content/Ch_kinkyinf/figs/predL1}
%    \label{fig:Hoelderconstvar3}
%  } 		
%	\label{fig:Hoelderconstvar}
%   \caption{Example of the predictions of the values of ground-truth function $x \mapsto \sqrt{\abs{\sin(x)}}$ using varying H\"older constants. For all predictions, a standard metric $\metric_\inspace(x,x') = \abs{x-x'}$ and a H\"older exponent of $p= \frac 1 2$ was employed. The global H\"older constant (and hence, the optimal constant) was $L=1$. }
%\end{figure}	 


%\subsection{A lazy update rule} 
\label{sec:lazylipconstupdate}
%We assume there is a global H\"older constant that is uncertain. 
%In the presence of uncertainty it is important to be able to update the H\"older constant $L$ in the light of the data. After all, if chosen too conservatively high, the regularity properties of the actual ground truth will be lost and yield predictions that are too steep and, for large $L$, yield step function predictions (cf. Fig \ref{fig:Hoelderconstvar1}). And, if decision making takes the error bounds provided into account, the unnecessary uncertainty may result in overly cautious behaviour and hence, poor performance. 
%On the other hand, underestimating $L$ may even be worse. If $L$ is chosen too small then the error bounds are off and predictions may be unable to accurately infer the true shape of the function (cf. Fig \ref{fig:Hoelderconstvar2}). 
%
%Above we have outlined a Bayesian treatment in the face of probabilistic uncertainty. This is an adequate choice if one's uncertainty can be specified by a prior and if the necessary integrals can be computed efficiently. 
%
%In practice, both can be difficult and we might resort to a more pragmatic approach which we will outline in this subsection. Furthermore, the Bayesian approach can fall prey to stubbornness and cannot recover from false beliefs of impossibility. That is, if an observed data point provides evidence for the validity of an event that has zero measure under the prior the posterior will be unable to adjust and also ascribe zero-measure to the event, even if most strongly supported by the evidence.  
%
%To avoid underestimating the H\"older constant without resorting to overly conservative choices of $L$ it might be possible to start with a good estimate of $L$ that is not overly conservative and to update 
%this lazily, that is, only if required. 

\subsubsection{A first update rule}
 In this subsection, we present an incremental update law that allows our method to increase the estimate of the H\"older constant if newly available data suggests the previously assumed upper bound on the constant was insufficiently high.
 
Assume we have sequential access to a sequence $\seq{\data_n}{n \in \nat}$ of data sets $\data_n:= \{\bigl( s_i, \tilde f_i \bigr) \vert i=1,\ldots, N_n\} $ with $\data_n \subset \data_{n+1}$ ($n \in \nat$) with observational error bound $\obserr$. For simplicity (of notation), we will for now assume that the input space pseudo-metric is a full metric. That is, that we have $\metric_\inspace(x,x') = 0 \Leftrightarrow x=x'$.
%For notational brievty we introduce the set $$\mathcal U := \{ (x,x') \in \inspace^2 | \metric_\inspace(x,x') >0 \}.$$
  We will consider the task of utilising the data to compute estimates to update a deterministic belief over a H\"older constant. In order to bound the conservatism of our uncertainty bounds derived from the constant in the context of kinky inference, the ability to uncover low H\"older constants or even the \emph{optimal} H\"older constant $L^* = \sup_{x'\neq x } \frac{\metric_\outspace \bigl(f(x) - f(x')\bigr)}{\metric_{\inspace}^p(x,x') }$ of the target function $f$ are of particular interest. 
Remember, $\hoelset p {} {L'}  \subset \hoelset p {} {L''} $ for $L'' \geq L'$. Therefore, in order not to inflate the set of hypothesis functions that could have generated the data more than necessary, one might choose not to rule out any lower global H\"older constant candidates unless the data suggests ones has to. In this approach, after having observed $\data_{N_n+1}$, $L(n+1)$ is chosen to be just large enough such that the H\"older condition is not in conflict with sample-consistency, i.e. such that $\mathcal K(\data_{N_n+1}) \cap \bigl(  \mathcal K_{prior} \cup \hoelset p {} {L(n+1)} \bigr) \neq \emptyset$. This approach gives rise to a \emph{lazy} update rule which only increases the current estimate $L(n)$ by the minimal amount necessary to remove any inconsistency with the new data if such inconsistencies are detected. %if the new data point is otherwise inconsistent with it.

Before introducing our lazy update approach in full generality, we will consider a special case first:
For simplicity, we assume that the target is real-valued with $\outspace \subseteq \Real, \metric_\outspace(y,y') = \abs{y-y'}$ for all $y,y \in \outspace$ and that a uniform observational error bound $\obserr =\obserr(x) \in \Real_{\geq 0}, \forall x$ is given. Furthermore, we assume the bounding functions $\ubf,\lbf$ are inactive, i.e. $\lbf \equiv -\infty, \ubf \equiv \infty$. Therefore, the uncertainty hyperrectangle $\prederrbox_n(x)$ around the prediction $\predfn(x)$ coincides with the interval $[\boden_n\bigl(x; L(n)\bigr) ,\decke_n\bigl(x; L(n)\bigr)]$.


For now, we also assume that at each time $n$ we receive one new data point. In this scenario we have $\data_{n+1} \backslash \data_n=\{(s_{N_n+1},\tilde f_{N_n+1}) \}$ with $N_n = n$. Given that at time $n$ the lazy estimator proposes the optimal H\"older constant $L^*$ to be $L(n) \in \Real_{\geq 0}$, how should the arrival of the new data point $(s_{N_n+1},\tilde f_{N_n+1},\obserr)$ affect the belief in the H\"older constant? %Now assume that a new sample observation $(s_{N_n+1},f_{N_n+1}, \obserr)$ arrives.  
Following our lazy approach, we only make modifications if the previous estimate is unduly low in the light of the new data. Here the new data point $(s_{N_n+1},\tilde f_{N_n+1},\obserr)$ is evidence for constant $L(n)$ to be unduly low if it falls outside of the prediction uncertainty  interval $\prederrbox_n(x)$. This is the case if 
$\tilde f_{N_n+1} +\obserr < \boden_n(s_{{N_n}+1}) \vee \tilde f_{{N_n}+1} - \obserr > \decke_n\bigl(s_{{N_n}+1}; L(n)\bigr)$ or equivalently, if 
$\tilde f_{{N_n}+1} +\obserr < \max_{i=1,\dots,N_n} \tilde f_i - \obserr - L(n) \metric^p_{\inspace}(s_{{N_n}+1},s_i) \vee \tilde f_{{N_n}+1} - \obserr > \min_{i=1,\dots,N_n} \tilde f_i + \obserr + L(n) \metric^p_{\inspace}(s_{{N_n}+1},s_i)$.
Equivalently, this means that 
\begin{equation}
	\abs{\tilde f_{{N_n}+1} -\tilde f_i} > 2 \obserr +  L(n) \metric^p_{\inspace}(s_{N_n+1},s_i) \, \forall i \in \{1,...,N_n\}. 
\label{eq:Lupdatecond}
\end{equation}
This is a condition one could test for in $\mathcal O(d \, N_n)$ steps. If the condition is met, we can change the presupposed H\"older constant  to assume a value such that the condition is no longer met. To this end, we can choose the updated H\"older constant $L({n+1})$ to be 
%
\begin{equation}
	L({n+1}) := \max\left\{ L(n), \max_{i=1,...,N_n} \frac{\abs{\tilde f_{{N_n}+1}-\tilde f_i} -  2 \obserr}{\metric^p_{\inspace}(s_{N_n+1},s_i)} \right\}
\label{eq:Lupdateeq}
\end{equation}
which can be computed in $\mathcal O(M \, N_n)$, assuming the metrics can be evaluated in the order of $\mathcal O(M)$ computational steps. 
%
Note, if we set $L(0) = L(1) := 0$, we are guaranteed that our incremental estimate $L({n+1}) $ coincides with the empirical H\"older constant estimate $$L({\data_{n+1}} ) :=  \max \bigl\{0,\max_{i,j =1,...,N_{n+1}, i\neq j} \frac{\metric_\outspace(\tilde f_i,\tilde f_j) -2 \obserr}{\metric^p_{\inspace}(s_i,s_j)} \bigr\}.$$ As we will see below, this estimate always is a lower bound on the true lowest H\"older constant $L^* = \sup_{x \in \inspace, x' \in \inspace\backslash \{x\}} \frac{\abs{f(x) - f(x')}}{\metric_{\inspace}(x,x') }$.



\subsubsection{Generalisations and properties} 
Next, we will examine our lazy update rule in a generalised setting. Here, we assume the target function is a mapping $f: \inspace \to \outspace$ where the input space $\inspace$ is endowed with a pseudo-metric $\metric_\inspace$ and the output space $\outspace$ is an additive group, endowed with a pseudo-metric $\metric_\outspace$ that is translation-invariant, i.e. $\metric_\outspace(y+\tau,y'+\tau) = \metric_\outspace(y,y'),\forall y,y',\tau \in \outspace$. Throughout the remainder of the article, we will frequently take maxima over sets. 
Now allowing for non-definite pseudo-metrics, we need to ensure none of the denominators can be zero. For notiational convenience, for two sets $S,S' \subset \inspace$ of inputs we define  $$U(S,S') := \{(s,s') \in S \times S' | \metric_\inspace(s,s') >0\}$$ as the set of input pairs that the pseudo-metric can tell apart and define $U_n := U(G_n,G_n) $.
For notational simplicity, we assume $\max(\emptyset) = -\infty$ and $\max(S\cup \{
-\infty\}) = \max (S)$ for any set $S$.

We assume that a priori, that is, before having seen any data, we know a lower bound $\underline L$ on the optimal H\"older constant $L^* \in \Real_{\geq 0}$.
At time $n$ we desire to entertain a deterministic belief $\ell_n \geq 0$ about H\"older constant $L^*$ which is consistent with the data $\data_n$ observed so far.
In this context consistency means that 
$\ell_n $ is at least as large as the empirical estimator $\ell({\data_n};\hestthresh,\underline L)$ of the constant defined as follows:  
%\begin{equation}
%\ell(\data_n;\hestthresh,\underline L)  :=  \begin{cases} \underline L &, \text{ if } N_n =\abs{\data_n} \leq 1\\ 
% \max \Bigl\{ \max_{i,j =1,...,N_n, i\neq j} \frac{\metric_\outspace(\tilde f_i,\tilde f_j) - \hestthresh}{\metric_{\inspace}^p(s_i,s_j)},\underline L \Bigr\}.
% &, \text{ otherwise }. \end{cases}
%\end{equation}
\begin{equation}\label{eq:lazyconstupdaterule_batch}
\ell(\data_n;\hestthresh,\underline L)  := 
 \max \Bigl\{ \underline L, \max_{(s,s') \in U_n} \frac{\metric_\outspace(\tilde f_i,\tilde f_j) - \hestthresh}{\metric_{\inspace}^p(s_i,s_j)}\Bigr\}.
\end{equation}

 Here $\hestthresh \in \Real$ is a parameter which, consistent with our considerations above, by default we set to $\hestthresh = 2 \metric_\outspace(0, \obserr)$. This imposes a tolerance margin that is necessary since the presence of observational error $\obserr$ could cause the \emph{empirical H\"older constant} $\ell(\data_n;0,\underline L)$ to overestimate the actual smallest constant $L$ in an unbounded manner. 
Parameter $\underline L$ is an a priori specifiable lower bound on the true best H\"older constant $L^*$. In the absence of further domain-specific a priori knowledge on this bound we can always set $\underline L=0$ (since negative constants are not meaningful in the definition of H\"older continuity). 
In the absence of observational errors (i.e. in case $\obserr =0$) it should be clear that the sequence of estimates $\seq{\ell(\data_n;\lambda,0)_n;0,\underline L)}{n \in \nat}$ converges to $L^*$ if the sequence of grids $\seq{G_n}{n \in \nat}$ converges to a dense subset of the domain $\inspace$ (and provided that indeed $\underline L \leq L^*$).

However, in the presence of observational errors, $\ell(\data_n;0,\underline L)$ can in general overestimate the H\"older constant with arbitrarily high error. Fortunately, parameter $\hestthresh$ can prevent this:
Provided that $\hestthresh$ is chosen sufficiently large and that the a priori lower bound is a valid lower bound (i.e. $\underline L \leq L^*$), it is easy to show that the empirical estimates of the constant converge and never exceed the true optimal H\"older constant $L^*$. 
This is formalised as follows:

\begin {lem} \label{lem:constadaptation_boundedness} Let $\metric_\outspace: \outspace^2 \to \Real$ be a translation-invariant pseudo-metric on an abelian group $(\outspace,+)$.n Define $L^*$ to be the best H\"older constant of the target $f$.
With the definitions as above, we have:
\begin{itemize}
\item \textbf{(I)} If $D \subset D'$ then $\ell(D;\hestthresh,\underline L) \leq \ell(D';\hestthresh,\underline L)$.
\end{itemize}
If $\hestthresh \geq 2 \metric_\outspace(0,\obserr)$ we have:
\begin{itemize}
\item \textbf{(II)} $\forall n \in \nat: \ell(\data_n; \hestthresh,\underline L) \leq \max\{L^*,\underline L\}$ and  
\item \textbf{(III)} the sequence \seq{\ell(\data_n; \hestthresh,\underline L)}{n \in \nat} of empirical estimators monotonically converges to a number less than or equal to $\max\{L^*,\underline L\}$ provided that $\data_{n} \subset \data_{n+1}, \forall n \in \nat$.
\end{itemize}
\end{lem}
\begin{proof}
\textbf{(I)} This follows trivially from the fact that $\max S \leq \max M$ for two sets $S \subseteq M$. \\
\textbf{(II) }
We know that the $\tilde f_i$ are noisy observations of the ground truth $f(s_i)$ $(i=1,...,N_n$. That is, there exist $\phi$ such that $(i)$ $\tilde f = f + \phi$  and $(ii)$ $\metric_\outspace(0,\phi_i) \leq \metric_\outspace(0,\obserr)$ $(i =1,\ldots, N_n)$. 
Furthermore, note that in general (cf. Lem. \ref{lem:bilinaddtransinvgroup}), in additive groups $(G,+)$ endowed with a translation-invariant pseudo-metric $\metric_G$ one has $(iii)$ $\forall g,g',g'' \in G: \metric_G (g+g',g'') \leq \metric_G (g+g',g)+\metric_G(g,g'') = \metric_G (g',0)+\metric_G (g,g'')$. Finally, we remind ourselves that $(iv)$ $L^* \geq \sup_{x,x' \in \inspace, \metric_\inspace(x,x')>0} \frac{\metric_\outspace\bigl(f(x),f(x') \bigr)}{\metric_{\inspace}^p(x,x')}$ $\geq \ell(S;0,0)$ for any finite subset of input points $S \subset \inspace$.

These facts allow us to reason as follows:
%\begin{tiny}
\begin{align}
&\ell(\data_n;\hestthresh,\underline L)  %& = \max \bigl\{ 0, \max_{i,j =1,...,N_n, i\neq j} \frac{\metric_\outspace(\tilde f_i,\tilde f_j) - \hestthresh}{\metric_{\inspace}^p(s_i,s_j)} \bigr\} \\ 
\\
 &\stackrel{(i)}{=} \max \Bigl\{ \underline L, \max_{(s,s') \in U_n} \frac{\metric_\outspace\bigl( f(s) + \phi(s),f(s')+\phi(s')\bigr) - \hestthresh}{\metric_{\inspace}^p(s,s')} \Bigr\}\\
  &\stackrel{(iii)}{\leq} \max \Bigl\{ \underline L, \max_{(s,s') \in U_n} \frac{\metric_\outspace\bigl( f(s),f(s') \bigr)  + \metric_\outspace(0,\phi(s)) + \metric_\outspace(0,\phi(s')) - \hestthresh}{\metric_{\inspace}^p(s,s')} \Bigr\}\\
    &\stackrel{(ii)}{\leq} \max \Bigl\{ \underline L,  \max_{(s,s') \in U_n} \frac{\metric_\outspace\bigl( f(s),f(s') \bigr)  }{\metric_{\inspace}^p(s,s')} +\frac{2 \metric_\outspace(0,\obserr) - \hestthresh}{\metric_{\inspace}^p(s,s')} \Bigr\}\\
        &\stackrel{(iv)}{\leq}  \max \Bigl\{ \underline L, L^* +\max_{(s,s') \in U_n} \frac{2 \metric_\outspace(0,\obserr) - \hestthresh}{\metric_{\inspace}^p(s,s')} \Bigr\}.
\end{align} 
%\end{tiny}
Hence, for $\ell(\data_n;\hestthresh,\underline L) \leq \max\{L^*,\underline L\}$ to hold it suffices to choose parameter $\hestthresh$ such that \newline
%
$L^* +\max_{(s,s') \in U_n}  \frac{2 \metric_\outspace(0,\obserr) - \hestthresh}{\metric_{\inspace}^p(s,s)} \leq L^*$.
Since the denominators cannot be negative, this holds if the nominator $2 \metric_\outspace(0,\obserr) - \hestthresh$ is not positive, i.e. if $2 \metric_\outspace(0,\obserr) \leq \hestthresh$. \\
\textbf{(III)} is entailed by applying the monotone convergence theorem in conjunction with (I) and (II).
\end{proof}
For time $n$, let $S_{n+1} := G_{n+1} \backslash G_n$ be the set of new sample inputs.
Similarly to above, we can define an incremental update rule recursively as follows: 
\begin{align} \label{eq:Hoelconstlazyupdateincr}
\ell_{n+1} &:= \max\Bigl\{\ell_n, \max_{(s,s') \in U(G_n, S_{n+1})} \frac{\metric_\outspace\bigl(\tilde f(s),\tilde f(s')\bigr) - \hestthresh}{\metric_{\inspace}^p(s,s')},\\
&\max_{(s,s') \in U(S_{n+1}, S_{n+1})} \frac{\metric_\outspace\bigl(\tilde f(s),\tilde f(s')\bigr) - \hestthresh}{\metric_{\inspace}^p(s,s')} \Bigr\},
\end{align} for $n \in \nat$ 
and where 
$\ell_0 := \underline L$. 
The effort for computing $\ell_{n+1}$ is in the order of $\mathcal O\bigl(M (\abs{S_{n+1}} N_n+ \abs{S_{n+1}}^2)\bigr)$ where $M$ denotes the effort for evaluating the pseudo-metrics.
By construction, we have \[\ell_n =\ell(\data_n;\hestthresh,\underline L), \forall n \in \nat.\] Therefore, our convergence and boundedness results about the sequence
 $\seq{\ell(\data_n;\hestthresh,\underline L)}{n \in \nat}$ readily apply to the incrementally computed sequence of estimators $\seq{\ell_n}{n \in \nat}$.

%\begin{rem} Above, we have assumed that the input space pseudo-metric was a full metric. This was done for notational convenience to keep the statements of our maximisations terse. The modifications to these statements to accommodate a non-definite input pseudo-metric is straight-forward: all we need to do is to only consider input pairs $s_i,s_j$ in the maximisation steps that give rise to non-zero denominators $\metric_\inspace(s_i,s_j)$. For example, \end{rem}
\begin{figure*}[ht!]
        \centering
				  \subfigure[Open-loop plan.]{
    %\includegraphics[width = 3.7cm, height = 3cm]{content/figures/graph1_klein.eps}
    \includegraphics[width = 5cm, clip, trim = 3.5cm 9.5cm 4.5cm 9cm]
								%{content/Ch_kinkyinf/figs/resultswingrock_555trials}
								{content/Ch_kinkyinf/figs/akt1_plan1}
    \label{fig:akt1fig1}
  } 	 
					  \subfigure[Planned trajectory.]{
    %\includegraphics[width = 3.7cm, height = 3cm]{content/figures/graph1_klein.eps}
    \includegraphics[width = 5cm, clip, trim = 3.5cm 9.5cm 4.5cm 9cm]
								%{content/Ch_kinkyinf/figs/resultswingrock_555trials}
								{content/Ch_kinkyinf/figs/akt1_plan1traj}
    \label{fig:akt1fig2}
  } 	  
					  \subfigure[Actual trajectory.]{
    %\includegraphics[width = 3.7cm, height = 3cm]{content/figures/graph1_klein.eps}
    \includegraphics[width = 5cm, clip, trim = 3.5cm 9.5cm 4.5cm 9cm]
								%{content/Ch_kinkyinf/figs/resultswingrock_555trials}
								{content/Ch_kinkyinf/figs/akt1_exec1traj}
    \label{fig:akt1fig3}
  } 	 
%
   \caption{\textit{Exp1.} The leftmost plot shows the plans of agent 1 (blue) and agent 2 (green). The boxes depict the safety tube bounding the error whereas the circles indicate the physical expansion of the circular agents. Their start positions are $S1 = (-5,0)^\top$ and $S2 = (5,0)^\top$ while their goal locations are $G1 = (-1,0)^\top$ and $G2 = (1,0)^\top$, respectively. With the agents having a radius of $r=0.5$ and not assuming any disturbances, the planner computes control actions that are projected to allow the agents to come to rest at their goal locations (see Fig. \ref{fig:akt1fig2} and Fig \ref{fig:akt1fig2}). However, when the plans are executed in the real system, the unforeseen drift $f$ causes the trajectories to collide when the plans are executed (Fig. \ref{fig:akt1fig3}).  }
		\label{fig:KIcollavoidopenloopakt1}
\end{figure*}	
%
\section{Application to collision avoidance of learning agents with uncertain drift}
\label{sec:KIcollavoiddiscretetime}
%\textbf{Overview.} 

Due to its mathematical properties, optimal multi-agent planning with collision avoidance is a hard coordination problem \cite{lavallebook:2006}. In the context of model-predictive control (MPC) \cite{Jmacmpcbook2002}, it is typically modelled as a finite-time horizon problem and stated as a \textit{mixed integer linear programme (MILP)} (e.g. \cite{schouwenaars2001mixed,Kuwata2005,Kuwata2006,LyonsACC2012,Lyons2011}). In robust predictive control, it is assumed that the agents are governed by control-affine dynamics up to some error whose norm is bounded \cite{Kuwata2005,Kuwata2006}. This gives rise to a \textit{tube} of conceivable trajectories around an error-free \textit{nominal} trajectory whose expansion (i.e. tube radius) reflects the maximum error norm. Collision avoidance can be enforced by adding constraints to the statement of the optimisation problem that ensure that the tubes cannot overlap.

In this section, we connect this planning approach to our kinky inference method. Here, the error is due to epistemic uncertainty over the governing dynamics. 
In particular, we will assume that the drift of the system is uncertain. The drift then is (partially) inferred from observations employing kinky inference. Folding in information about the drift afforded by the partially identified model, the agents are controlled with a variation of the optimisation-based open-loop MPC approach considered in \cite{LyonsACC2012,Lyons2011}. Taking the uncertainty estimates around the KI predictions into account, collision avoidance is ensured by constraints on the tube distances around the uncertain trajectories. In contrast to \cite{LyonsACC2012,Lyons2011} the size of the tubes is chiefly determined by the uncertainty quantification provided by the kinky inference rule. Assuming the prior assumptions are true and the drift is contained in $\mathcal K_{prior}$ (cf. Sec. \ref{sec:KI_core}), Thm. \ref{thm:KIdesiderata} asserts that the resulting controls will be conservative. That is, as long as we ensure the tubes do not intersect, the actual trajectories are guaranteed not to intersect. In addition, the theorem guarantees that the conservatism will shrink as additional data about the drift will become available. 

Below, we will provide illustrations of the application of these results to the multi-agent collision avoidance problem. The simulations behave as predicted by our theory. 
There are numerous works in the control literature that give guarantees on control success in a robust setting as well as a vast number of works on multi-agent 
coordination and collision avoidance (e.g. \cite{schouwenaars2001mixed,Kuwata2005,Kuwata2006,Ong2010,LyonsACC2012,calliessARMS2011:LNAI}). Nonetheless, we believe this to be the first work that can provide guarantees on the belief of collision avoidance that is due to bounds of learning algorithms that have identified an uncertain dynamic system.

\subsection{Conservative predictive control for collision avoidance of kinky inference learners}


Suppose we have $A$ agents with index set $\agset, \abs{\agset}=A$. Each agent $\agi \in \agset$ has plant dynamics 
\begin{equation}
	x^\agi[{k+1}] = A x^\agi[k] + B u^\agi[k] + f(x^\agi[k])
\end{equation}
with matrices as defined in the double-integrator UAV model considered in \cite{LyonsACC2012}. 
Here, $x^\agi[k]$ denotes the state of agent $\agi$ at discrete time $k \in \{1,...,T\}$ and $u^\agi[k]$ is the pertaining control action chosen by the agent.
%That is, we chose 
%\begin{footnotesize}
%\begin{align}
		%A = \left(\begin{array}[h]{cccc}
				%1 & 0&\tinc&0\\
				%0 & 1&0&\tinc\\
				%0 & 0&1&0\\
				%0 & 0&0&1
		%\end{array}\right), \, & 
			%B = \left(\begin{array}[h]{cc}
				%0& 0\\
				%0 & 0\\
				%\tinc & 0\\
				%0 & \tinc
		%\end{array}\right)
%\end{align}
%\end{footnotesize}
%
%where $\tinc = 0.2$ was a predefined time increment representing the temporal discretisation resolution of the discrete-time approximation of the dynamics.


 
\begin{figure*}
        \centering
				  \subfigure[Open-loop plan.]{
    %\includegraphics[width = 3.7cm, height = 3cm]{content/figures/graph1_klein.eps}
    \includegraphics[width = 5cm, clip, trim = 3.5cm 9.5cm 4.5cm 9cm]
								%{content/Ch_kinkyinf/figs/resultswingrock_555trials}
								{content/Ch_kinkyinf/figs/akt2_plan1}
    \label{fig:akt2fig1}
  } 	 
					  \subfigure[Planned trajectory.]{
    %\includegraphics[width = 3.7cm, height = 3cm]{content/figures/graph1_klein.eps}
    \includegraphics[width = 5cm, clip, trim = 3.5cm 9.5cm 4.5cm 9cm]
								%{content/Ch_kinkyinf/figs/resultswingrock_555trials}
								{content/Ch_kinkyinf/figs/akt2_plan1traj}
    \label{fig:akt2fig2}
  } 	  
					  \subfigure[Actual trajectory.]{
    %\includegraphics[width = 3.7cm, height = 3cm]{content/figures/graph1_klein.eps}
    \includegraphics[width = 5cm, clip, trim = 3.5cm 9.5cm 4.5cm 9cm]
								%{content/Ch_kinkyinf/figs/resultswingrock_555trials}
								{content/Ch_kinkyinf/figs/akt2_exec1traj}
    \label{fig:akt2fig3}
  } 	 
	%
   \caption{Exp2. Taking into account the conservative uncertainty bounds of the kinky inference predictions, the decisions (control actions) are conservative and hence, collisions are avoided during plan execution (Fig. \ref{fig:akt2fig3}) according to plan (Fig. \ref{fig:akt2fig1} and Fig. \ref{fig:akt2fig2}). Due to the poorly trained predictor the uncertainty is large and the plans are so conservative the goals are never reached. }
	\label{fig:KIcollavoidopenloopakt2}
\end{figure*}	 


As before, $f$ is an (uncertain or unknown) drift, $x^\agi[k] \in \statespace \subset \Real^4$ denotes the state at time step $k$ and $u^\agi[k]$ is the pertaining control input to be determined by the planner. In our collision avoidance scenario interactions between agents take place on a map of locations $\iaspace = [-10,10]^2 \subset \Real^2$. We assume the first two components of the state are locations and the final two are the pertaining velocities.
A collision is the event where the plant locations of two agents get too close to each other, which is to be avoided. Formally, a collision is considered to occur if $\exists k \in \nat, \agi, \agii \in \agset: \norm{\isv^\agi[k] - \isv^\agii[k]} \leq \Lambda$ where $\Lambda \in \Real_+$ is the agents' physical radius and $s^\agi = (x_1^\agi,x_2^\agi)^\top \in \iaspace$ is agent $\agi$'s interaction-space positions, i.e. its location in the environment given by a (bounded) set of attainable locations $\iaspace$.
 
\textbf{Exp. 1.}
In predictive control, a correct model can be crucial for control success \cite{Jmacmpcbook2002}. This holds true especially in open-loop control where no feedback is provided to reduce the effects of model uncertainty. As an illustration, consider the plots of Fig. \ref{fig:KIcollavoidopenloopakt1}. Here, two agents were tasked to move from their start locations to their respective goal locations. Assuming our linear double-integrator model in the absence of a nonlinear drift ($f \equiv 0$), they plan 
to generate control sequences $( u^\agi[k])_{k=1,...,T}$ offline (by solving aforementioned optimisation problem similar to \cite{Lyons2011}) so that the resulting trajectories are anticipated to lead the agents' plants to settle at their respective goal locations $G1 = (-1,0)^\top$ and $G2 = (1,0)^\top$ in a cost-optimal manner. 

We then simulated the trajectories resulting from executing the planned control sequences. However, deviating from the control-affine model utilised during planning, we set the drift function to the non-zero function $f(x) := f^\agi(x) := \tinc \bigl(0,0, - \sin(0.5\, x_1), - \sin(0.5 \, x_2) \bigr)$ for all agents $\agi \in \agset =\{1,2\}$.  In the context of mobile robot control, the drift function might simulate gravitational terms due to an a priori uncertain hilly terrain that has a valley around the origin. (That is, the gravitational forces are proportional to the slope of the terrain. So, with this choice of drift forces pushing towards the origin in a neighbourhood of the origin, this corresponds to a valley being located at the origin.) 

Since the influence of the drift $f$ was unaccounted for during planning, the actual trajectories (Fig. \ref{fig:akt1fig3}), resulting from executing the plans, markedly deviated from the anticipated ones (Fig. \ref{fig:akt1fig2}), yielding a collision around time step $k = 12$ (refer to Fig. \ref{fig:akt1fig3}).  

 

\begin{figure*}
        \centering
				  \subfigure[Open-loop plan.]{
    %\includegraphics[width = 3.7cm, height = 3cm]{content/figures/graph1_klein.eps}
    \includegraphics[width = 5cm, clip, trim = 3.5cm 9.5cm 4.5cm 9cm]
								%{content/Ch_kinkyinf/figs/resultswingrock_555trials}
								{content/Ch_kinkyinf/figs/akt3_plan1}
    \label{fig:akt3fig1}
  } 	 
					  \subfigure[Planned trajectory.]{
    %\includegraphics[width = 3.7cm, height = 3cm]{content/figures/graph1_klein.eps}
    \includegraphics[width = 5cm, clip, trim = 3.5cm 9.5cm 4.5cm 9cm]
								%{content/Ch_kinkyinf/figs/resultswingrock_555trials}
								{content/Ch_kinkyinf/figs/akt3_plan1traj}
    \label{fig:akt3fig2}
  } 	  
					  \subfigure[Actual trajectory after plan execution.]{
    %\includegraphics[width = 3.7cm, height = 3cm]{content/figures/graph1_klein.eps}
    \includegraphics[width = 5cm, clip, trim = 3.5cm 9.5cm 4.5cm 9cm]
								%{content/Ch_kinkyinf/figs/resultswingrock_555trials}
								{content/Ch_kinkyinf/figs/akt3_exec1traj}
    \label{fig:akt3fig3}
  } 	 
%
   \caption{\textit{Exp3.} The simulation is restarted, but with a KI given 100 randomised, noisy observations of the drift resulting in reduced uncertainty bounds (compare the box size in Fig. \ref{fig:akt3fig1} against those in Fig. \ref{fig:akt2fig1}). This reduces the conservatism of the plans markedly (Fig. \ref{fig:akt3fig1} and Fig. \ref{fig:akt3fig2}). With the adaptive element being well trained to compensate for the drift, the executed trajectories match the planned trajectories closely. The reduced conservatism allows the trajectories to arrive close to their goals. }
	%to be reached, before the growing uncertainty bounds cause the green agent to slowly withdraw.   }
		\label{fig:KIcollavoidopenloopakt3}
\end{figure*}	 
%
\textbf{Exp. 2.} 
To compensate for this, we employed a kinky inference learner to infer the drift based on a noisy sample. The latter could be obtained via observing state differences $\d x[k] = x[k+1] - x[k]$ and then solving for $f(x[k]) = \d x[k
] - A x[k] + B u[k]$. Assuming the state is observable up to error $\varepsilon_x$ this allows us to generate a data set of the form $\data_n = \bigl\{ x[k_i], f(x[k_i]), \varepsilon\bigr \vert i=1, \ldots, N_n\}$ where $\varepsilon$ captures the effects of input and output noise as discussed above.


We initialised the KI learner with one training point for the drift value at each agent's start location in interaction space $\iaspace = [-10,10]^2$, perturbed by some noise of $\varepsilon = 0.01$. That is, with notation of Sec. \ref{sec:KI_core}, we generated
 a data set $\data_1 = \{ (S1, f(S1), 0.01), (S2, f(S2), 0.01)  \}$. The parameters were chosen to $L=1,p=1,\ubf = \infty, \lbf = -\infty$. Appealing to arguments of maximal derivatives (cf. \cite{Weaver1999}), it is easy to see that the drift $f$ is Lipschitz with constant $L=\frac 1 2$. Therefore, $f \in \mathcal K_{prior}$ as required by Thm. \ref{thm:KIdesiderata} to establish conservatism of the uncertainty bounds. 
(Note, in practice, the constant $L$ could also be estimated from the data \cite{anonymous,Wood1996}.) Folding in knowledge that the drift was only dependent on interaction space inputs, the KI learner determined a maximum error of $\maxerr = \sup_{\isv \in \iaspace} \norm{\prederr_1(\isv)}_{\infty } = 1.27$. The resulting (coarse) prediction model $\predf_1(\cdot)$ is depicted in Fig. \ref{fig:KIcollavoidopenlooppredmodels1} for various query points on a subset of the interaction space $\iaspace$.
 

In lieu to feedback linearisation and MRAC control approaches \cite{chowdharyacc2013} discussed above, we chose a control $u^\agi[k]:= (- \nu^\agi_{ad} + \bar u^\agi[k]  ) $ with $\nu^\agi_{ad} =  \predf(x)$ defined by the kinky inference prediction rule as per Def. \ref{def:KIL}. Here, $\bar u^\agi$ denotes a pseudo control yet to be defined. In contrast, to MRAC \cite{chowdharyacc2013} we did not ascribe a fixed feedback policy to the pseudo-control. Instead, we intended to determine the pseudo control trajectory with MILP-based open-loop planning analogously to the procedure in Exp.1.

Applying the control yielded the closed-loop dynamics,
\begin{equation}
	x^\agi[{k+1}] = A x^\agi[k] + B \bar u^\agi[k] + F(x^\agi[k])
\end{equation}
 where $F(x) = f(x) - \predf(x) $ denotes an uncertain increment determining the deviation of the actual trajectory $x^\agi [\cdot]$ from the nominal trajectory 
given by the \textit{nominal dynamics}
\begin{equation}
	\bar x^\agi[{k+1}] = A \bar x^\agi[k] + B \bar u^\agi[k].
\end{equation}
%
Note, in contrast to the work in stochastic collision avoidance \cite{LyonsACC2012} we have based our planner on, the discrepancy is not modelled in a stochastic manner, but is assumed to be due to rest uncertainty of the kinky inference rule. 
Since the latter provides an error estimate around its predictions, we can utilise these uncertainty quantifications to bound the discrepancy between nominal and actual dynamics.
Since we aim to do planning on the basis of the nominal model, we need to determine how much extra space to leave between the agents to enforce collision avoidance in the presence of error $e^\agi[k] = x^\agi[k] - \bar x^\agi[k]$. 
In other words, how large do we have to choose the tube radius around the nominal trajectory?

In pursuit of an answer, we once again consider the error dynamics:
\begin{equation}
	e^\agi[{k+1}] = A e^\agi[k] + F(x^\agi[k]). 
\end{equation}
%where $F_k = F(x[k])$.


%Going through analogous steps as in Sec. \ref{sec:KIMRACstabbounds} (with $A$ in place of $M$), we see that 
%
%$e^\agi[k]= A^k \, \vc e^\agi[0] +  \sum_{i=0}^{k-1} A^{k-1-i} \, \vc F(x^\agi[i])	$ and hence, 
%%\begin{equation}
	%$\norm{\vc e^\agi[k]} \leq \matnorm{A^{k}} \, \norm{\vc e^\agi[0]} +  \maxerr_k	 \sum_{i=0}^{k-1}  \matnorm{A^{k-1-i}}$
%%\end{equation}
%where $\maxerr_k	= \max_{i=1,...,k-1} \norm{F(x^\agi[i])}$. Since $F$ is nonlinear, we would rather allow our control decisions to be conservative than having to incorporate the nonlinear term $F(x)$ in the  constraints of our optimisation problem. 
%%(Note, that for certain input norms, the KI rule generates piece-wise linear prediction uncertainty functions. In future work, we would like to investigate using this property to convert constraints on $F$ into linear constraints. We hope to be able to do so employing techniques akin to LP conversion techniques found in piece-wise linear optimisation \cite{boyd:2004}. )
%
%%\begin{figure}
        %%\centering
				  %%\subfigure[S.]{
    %%%\includegraphics[width = 3.7cm, height = 3cm]{content/figures/graph1_klein.eps}
    %%\includegraphics[width = 5cm]
								%%%{content/Ch_kinkyinf/figs/resultswingrock_555trials}
								%%{content/Ch_kinkyinf/figs/akt1_dist}
    %%\label{fig:KIcollavoidopenlooppredmodels1}
  %%} 	 
				  %%\subfigure[Initial prediction.]{
    %%%\includegraphics[width = 3.7cm, height = 3cm]{content/figures/graph1_klein.eps}
    %%\includegraphics[width = 5cm]
								%%%{content/Ch_kinkyinf/figs/resultswingrock_555trials}
								%%{content/Ch_kinkyinf/figs/akt1_dist}
    %%\label{fig:KIcollavoidopenlooppredmodels1}
  %%} 	 
				  %%\subfigure[Initial prediction.]{
    %%%\includegraphics[width = 3.7cm, height = 3cm]{content/figures/graph1_klein.eps}
    %%\includegraphics[width = 5cm]
								%%%{content/Ch_kinkyinf/figs/resultswingrock_555trials}
								%%{content/Ch_kinkyinf/figs/akt1_dist}
    %%\label{fig:KIcollavoidopenlooppredmodels1}
  %%} 	 
	%%\label{fig:stagesoccostmashfe}
   %%\caption{Distance of the actual trajectories.}
%%\end{figure}	 
%
%Therefore, we replace $\maxerr_k$ by the more conservative constant 
%%
%%\begin{equation}
	%$\maxerr := \sup_{s \in \iaspace} \norm{F(s)} \leq c \sup_{s \in \iaspace} \norm{\prederr(s)}_\infty.$
%%\end{equation}
%%
%Here, $c$ is a norm conversion constant that ensures
%
 %$\norm{\cdot } \leq c \norm{\cdot}_\infty$. For instance, if $\norm{\cdot}$ denotes the Euclidean norm, then $c = \sqrt 2$ (e.g. \cite{koenigsberger:2000}).
%
%
%This allows us to obtain the state-independent bound 


%Define $\maxerr_k	= \max_{i=1,...,k-1} \norm{F(x^\agi[i])}$ and 
Let $\maxerr := \sup_{s \in \iaspace} \norm{F(s)} \leq c \sup_{s \in \iaspace} \norm{\prederr(s)}_\infty.$
%\end{equation}
%
Here, $c$ is a norm conversion constant that ensures
 $\norm{\cdot } \leq c \norm{\cdot}_\infty$. For instance, if $\norm{\cdot}$ denotes the Euclidean norm, then $c = \sqrt 2$ (e.g. \cite{koenigsberger:2000}).

Leveraging sub-multiplicativity and sub-additivity of vector and matrix norms, an inductive argument shows 
%
\begin{eqnarray} \label{eq:tuberadKIMPCcollavoid}
	\norm{\vc e^\agi[k]} \leq \matnorm{A^{k}} \, \norm{\vc e^\agi[0]} +  \maxerr	 \sum_{i=0}^{k-1} \matnorm{A^{k-1-i}} =: r^\agi[k].
\end{eqnarray}

%
%This bound $r^\agi_k$ is more conservative than if we had based it upon $\maxerr_k$ instead of on $\maxerr$. Nonetheless, it has the advantage of being state-independent and hence, can be pre-computed for all time steps within a given planning horizon.

In the absence of a nonlinear dependence on the state, open-loop planning could be conducted based on mixed-integer linear programming, analogously to the approach described in \cite{Lyons2011}. The difference between the approaches is that in our simulations, the radii $r^\agi[k]$ of the tube were computed as per Eq. \ref{eq:tuberadKIMPCcollavoid}. In particular, they were based on the uncertainty due to the KI predictions quantified by $\prederr$ rather than on the basis of probabilistic tail radii. To enforce collision avoidance, we then introduced tube constraints of the form $\gamma^{\agi,\agii}[k] > 0, \forall k \forall \agi,\agii \in \agset$ with 
$\gamma^{\agi,\agii}(k) = \norm{\bar \isv^\agi[k] - \bar \isv^\agii[k] }_\infty - \Lambda - r^\agi[k] - r^\agii[k] $ where the tube radii $r^\agi[k], r^\agii[k]$ were defined as in Eq. \ref{eq:tuberadKIMPCcollavoid} and rule out the possibility of any collisions between agents $\agi$ and $\agii$.

The results of the planning process with these conservative constraints are depicted in Fig. \ref{fig:KIcollavoidopenloopakt2}.


This time, the planner had successfully taken into account the uncertainty, resulting in successful collision avoidance. However, due to the fact that the drift model had been scarcely identified, the resulting large uncertainty estimates, in conjunction with the conservatism of the decision making process due to our bounds, caused the planner to conceive control actions that resulted in trajectories that kept a rather larger safety distance between the agents. While this did prevent collisions, the goal locations could not be reached (Fig. \ref{fig:akt2fig3}).


 
\textbf{Exp. 3.}
Since all uncertainty is due to epistemic uncertainty of the inductive inference rule over the deterministic drift field, we expect the conservatism to reduce with increasing learning experience. To test this, we updated the data set from $\data_1$ to $\data_2$ the latter of which now contained 100 samples of the drift drawn uniformly at random from the interaction space. 
The results are shown in Fig. \ref{fig:KIcollavoidopenloopakt3}.
As expected, the reduced uncertainty bound ($\maxerr = 0.31$) yielded less conservative plans (see Fig. \ref{fig:akt3fig1}). Furthermore, the actual trajectories observed from plan execution (Fig. \ref{fig:akt3fig3})  closely matched the planned trajectories (Fig. \ref{fig:akt3fig2}). This probably was a result of the improved identification result (see Fig. \ref{fig:KIcollavoidopenlooppredmodels}) afforded by the larger data set. Note, the reduced uncertainty allowed the trajectories to closely approach their goal positions (Fig. \ref{fig:akt3fig3}). Since we had tied the agents' cost to the distances to their goal state, this translates to reduced social stage cost. 

In conclusion, our simulations have demonstrated that the uncertainty quantifications of our kinky inference method can be successfully employed to facilitate conservative decision making in the context of multi-agent collision avoidance such that guarantees on collision avoidance can be given (whose veracity rests on the prior assumption $f \in \mathcal K_{prior}$). As expected, the simulations have illustrated the positive effect increased certainty (via learning) has on the conservatism of the decision-making process and hence, on the social cost (measuring distances to the goals) of the resulting trajectories (see Fig. \ref{fig:KIsoccost}).  
\begin{figure} 
        \centering
				  \subfigure[Initial prediction $\predf_1$.]{
    %\includegraphics[width = 3.7cm, height = 3cm]{content/figures/graph1_klein.eps}
    \includegraphics[width = 5cm]
								%{content/Ch_kinkyinf/figs/resultswingrock_555trials}
								{content/Ch_kinkyinf/figs/akt2learneddrift}
    \label{fig:KIcollavoidopenlooppredmodels1}
  } 	 
					  \subfigure[Improved prediction $\predf_2$.]{
    %\includegraphics[width = 3.7cm, height = 3cm]{content/figures/graph1_klein.eps}
    \includegraphics[width = 5cm]
								%{content/Ch_kinkyinf/figs/resultswingrock_555trials}
								{content/Ch_kinkyinf/figs/akt3learneddrift}
    \label{fig:KIcollavoidopenlooppredmodels2}
  } 	
							  \subfigure[Social cost after each experiment.]{
    %\includegraphics[width = 3.7cm, height = 3cm]{content/figures/graph1_klein.eps}
    \includegraphics[width = 5cm, clip, trim = 3.1cm 9.5cm 4.5cm 9cm]
								%{content/Ch_kinkyinf/figs/resultswingrock_555trials}
								{content/Ch_kinkyinf/figs/soccost}
    \label{fig:KIsoccost}
  } 
	%
   \caption{Belief over drift models based on $\data_1$ and $\data_2 \supset \data_1$ with $\abs{\data_1} = 2, \abs{\data_2} = 100$. Here, the top figures show the predictions of $\predf_{n,3}(s)$ and the bottom plots depict the predictions of $\predf_{n,4}(s)$ for $n =1$ and $n=2$, respectively. The ground-truth drift model was $f(x) = \bigl(0,0, - \sin(0.5 \, x_1), - \sin( 0.5 \, x_2) \bigr)^\top$. Rightmost plot: Social cost after each experiment. Note how the reduced uncertainty translated to reduced social cost of the last experiment (bar plot 3) vs the cost in the second (bar plot 2). While the first experiment (bar plot 1) also accumulated low social cost, a collision occurred.}
	\label{fig:KIcollavoidopenlooppredmodels}
\end{figure}	 
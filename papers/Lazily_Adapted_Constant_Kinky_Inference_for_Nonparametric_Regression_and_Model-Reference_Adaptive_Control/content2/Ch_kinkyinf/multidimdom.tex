\section{Conservative integration on multi-dimensional domains}
This time, the target function is assumed to be of the form $f: I \subset \Real^d \to \Real$ where $I$ is a $d-$dimensional hyper-rectangle.

Evoking Fubini's theorem, one could in principle apply the one-dimensional method developed above recursively in order to compute conservative estimates of $\int_I f(x) \, \d x$. Unfortunately, the necessity to evaluate $f$ at all corner points of $I$ renders the approach intractable for high-dimensional situations $d>>1$ -- the number of corner points of a $d$-dimensional hyper-rectangle is $2^d$. 
To overcome this limitation, we borrow a trick used in the DIRECT optimisation algorithm (CITE!!!!): instead of sampling at the corner points, we will always sample the centre point of a hyperrectangle. Thereby, we decouple the number of samples from the dimensionality of the problem.

\subsection{Conservative estimates and definite integrals on multi-dimensional domains based on 1-norm integrals}
Assume our grid $G_N$ is given by a sequence of $N$ tuples $\bigl(s_{i}^N, f(s_{i}^N), J_{i}^N\bigr)_{i=1,\ldots,N}$ where the sub-hyperrectangles $J_{1}^N,\ldots, J_{N}^N$ partition $I$ up to a zero-set, $s_i^N \in J^N_i$ is a sample of the function. We assume, each hyperrectangle $J_{i}^N$ is given by a Cartesian product of intervals $[-a_{i,1}^N,b_{i,1}^N] \times \ldots \times [-a_{d,1}^N,b_{d,1}^N]$ where \emph{``radii''} $a_{i,1}^N,b_{i,1}^N,\ldots, a_{i,d}^N,b_{i,d}^N\in \Real_+$ are known we can reconstruct hyperrectangle $J^N_i$ by pointwise addition: $J^N_i= s_i^N + \bigl( [-a_{i,1}^N,b_{i,1}^N] \times \ldots \times [-a_{d,1}^N,b_{d,1}^N] \bigr)$. 


For ease of notation, we will omit superscript $N$ when $N$ is fixed and it is not necessary to distinguish between 
grids of different resolutions. Similarly, when the hyperrectangle is fixed, we will omit subscript $i$. For example, $a_{i,j}^N , b_{i,j}^N$ are the radii of the $i$th hyperrectangle in the $j$th dimension. If we consider a particular hyperrectangle for grid $G_N$ $(N \text{fixed})$ we may write these as $a_j,b_j$.

\begin{figure}[htbp]
			\centering
			\includegraphics[scale =.2]{content/figs/rect2.pdf}
	%
	%
	\caption{A hyperrectangle in two dimensional space given by radii and sample point.}
	\label{fig:rect2}
\end{figure}


\begin{lem} \label{lem:defint_of_1norm}
Let $s \in \Real^d$ the sample point of hyperrectangle $J = \{ x \in \Real^d \vert \,(x-s)\, \in ([-a_1,b_1] \times \ldots \times [-a_d,b_d])\}\subset \Real^d$ where $a_1,b_1,\ldots,a_d,b_d \in \Real_+$ are the ``radii'' of the hyperrectangle.
We have 
\begin{align}
\bar S  &= \int_{J} \norm{x-s}_1 \d x \\
& =  \frac{1}{2} \Bigl( \prod_{j=1}^d a_j + b_j\Bigr)  \sum_{i=1}^d \frac{a_i^2+b_i^2}{a_i + b_i}  .
\end{align}

%(where we adhere to the convention $\prod_{j=1}^0 \rho_j = 1$).


\begin{proof}
Let $\bar J := J - s$.
We have $\bar S= \int_{\bar J} \norm{x}_1 \d x$.
We will proof the claim by induction on dimension $d$. \\
%
\textit{Base case} ($d=1$). $\int_{-a_1}^{b_1} \abs{x_1} dx_1 = \frac{1}{2} (a_1^2+b_1^2)$.\\
%
\textit{Induction hypothesis (I.H.).} For some dimension $d$ we have $ \bar S = \int_{-a_{d}}^{b_{d}}  \ldots \int_{-a_{1}}^{b_{1}}  \sum_{i=1}^{d} \abs{x_i} \d x_1 \ldots \d x_{d} =  \frac{1}{2} \sum_{i=1}^d  \Bigl( (a_i^2+b_i^2) \prod_{j=1,j\neq i}^d (a_j + b_j) \Bigr)$.\\
%
\textit{Induction step ($d \to d+1$).} Assume we are in $d+1$ dimensional space. 
Using Fubini's theorem we get 
$\int_{\bar J \times [-a_{d+1},b_{d+1}]} \norm{x}_1 \d x$
%
$ = \int_{-a_{d+1}}^{b_{d+1}}\ldots \int_{-a_{1}}^{b_{1}} \sum_{i=1}^{d+1} \abs{x_i} \d x_1 \ldots \d x_{d+1}$
%
$ = \int_{-a_{d+1}}^{b_{d+1}}\ldots \int_{-a_{1}}^{b_{1}}  \abs{x_{d+1}} \d x_1 \ldots \d x_{d+1} +  \int_{-a_{d+1}}^{b_{d+1}} \bigl( \int_{-a_{d}}^{b_{d}}  
\ldots \int_{-a_{1}}^{b_{1}}  \sum_{i=1}^{d} \abs{x_i} \d x_1 \ldots \d x_{d} \bigr) \d x_{d+1}$ 
%
$ \stackrel{I.H.}{=}   \frac{1}{2} (a_{d+1}^2 +b_{d+1}^2) \int_{-a_{d}}^{b_{d}}\ldots \int_{-a_{1}}^{b_{1}}  \d x_1 \ldots \d x_{d} +  \int_{-a_{d+1}}^{b_{d+1}} \frac{1}{2} \sum_{i=1}^d  \Bigl( (a_i^2+b_i^2) \prod_{j=1,j\neq i}^d (a_j + b_j) \Bigr) \d x_{d+1} $ 
%
$ =   \frac{1}{2} (a_{d+1}^2 +b_{d+1}^2) \bigl(\prod_{j=1}^d (a_j+b_j)\bigr) + (a_{d+1}+ b_{d+1} ) \frac{1}{2} \sum_{i=1}^d  \Bigl( (a_i^2+b_i^2) \prod_{j=1,j\neq i}^d (a_j + b_j) \Bigr) $ 
%
$  =\frac{1}{2} \sum_{i=1}^{d+1}  \Bigl( (a_i^2+b_i^2) \prod_{j=1,j\neq i}^{d+1} (a_j + b_j) \Bigr) $. 

\end{proof}
\end{lem}


\begin{rem}
Note, by pre-computing the product, the formula can be computed in $\mathcal O(d )$.
\end{rem}

\subsection{Conservative estimates and definite integrals on multi-dimensional domains based on max-norm integrals}

\subsubsection{Grids sampling centre points of hyperrectangles }
 For now, assume our grid $G_N$ consists of $N$ sub-hyperrectangles $J_1^N,\ldots,J_N^N$ that partition $I$. Let $c_i^N$ denote the centre point of $J_i^N$ and, let $r_j^i$ denote half of $J_i$'s edge length in the $j$th dimension $(j=1,...,d)$. 
That, is each grid $G_N$ is given by a sequence of triples $(c_i^N, f(c_i^N), r^N)_{i=1}^N$ where $c_i \in \Real^d$ is a centre point of $i$th hyperrectangle $J_i^N = c_i^N + [-r_{1,1}^N,+r_{1,1}^N] \times \ldots \times  [-r_{i,d}^N,+r_{i,d}^N] $ and $r_i^N$ is the vector of radii.  

For ease of notation, we will omit superscript $N$ when $N$ is fixed and it is not necessary to distinguish between 
grids of different resolutions. Similarly, when the hyperrectangle is fixed, we will omit subscript $i$. For example, $r_{i,j}^N$ is the radius of the $i$th hyperrectangle in the $j$th dimension. If we consider a particular hyperrectangle for grid $G_N$ $(N \text{fixed})$ we may write this as $r_j$.

\begin{figure}[htbp]
			\centering
			\includegraphics[scale =.2]{content/figs/rect1.pdf}
	%
	%
	\caption{A hyperrectangle in two dimensional space given by radii and centre point.}
	\label{fig:rect1}
\end{figure}


\textbf{Lipschitz Ceiling}. For now, let us only be concerned with upper bound estimates. 

Due to Lipschitz continuity on each hyperrectangle, we have 


\[\forall i \forall x,x' \in J_i: \abs{f(x) - f(x')} \leq L_i \norm{x-x'}. \]

In particular, 

\[\forall i \forall x \in J_i: f(x) - f(c_i) \leq\abs{f(x) - f(c_i)} \leq L_i \norm{x-c_i}. \]
Hence, 
\begin{align}
\forall i \forall x \in J_i: f(x)  &\leq f(c_i) + L_i \norm{x-c_i} \\
&\leq f(c_i) + \ell_i \norm{x-c_i}_{\infty}:= \decke^i_N(x)
\end{align}
where $\ell_i = \sqrt d L_i$ is a Lipschitz constant for the max-norm.
The last inequality is due to the well-known relationship 
$\norm{x}_\infty \leq \norm{x}_2 \leq \sqrt{d} \, \norm{x}_\infty $.

Thereby, we can define a new \textit{Lipschitz ceiling} 

\[\decke_N: x \mapsto \sum_{i=1}^N \chi_{J_i} (x) \, \decke^i_N(x)\]
guaranteeing to be an upper bound on $f$:

\[\decke_N( x) \geq f(x), \forall x \in I \subset \Real^d.\]

Therefore, 

\[\hat S_N^\decke:=\int_I \decke_N( x) d\mu(x) \geq \int_I f(x) \d\mu(x) =: S, \forall x \in I \subset \Real^d.\]
If each $\decke^i_N$ are integrable, we have 
\begin{equation}
\sum_{i=1}^N \int_{J_i} \decke^i_N( x) d\mu(x)=\hat S_N^\decke \geq \int_I f(x) \d\mu(x).
\label{eq:defint_ceiling2}
\end{equation}
Fortunately, we can evaluate $\hat S_i :=\int_{J_i} \decke^i_N( x) d\mu(x)$ in closed-form. To this end, we can use the following lemma:



%
%\begin{lem} Let $c \in \Real^d$, $l\in \Real$ be the edge length of hyper-square $J := \menge{x \in \Real^d}{ (x -c) \in [-r,r]^d } \subset \Real^d$ where $r= \frac{1}{2} l$. 
%We have \[
%\bar S = \int_{J} \norm{x-c}_\infty \d x = \frac{d}{2(d+1)}  l^{d+1}.\]
%
%
%\begin{proof}
%The idea of the proof will be to establish that the desired definite integral coincides with the volume of a $d+1$-dimensional hyperrectangle $B$  minus the volume of an inverted $d+1$-dimensional hyper-pyramid $P$ with a $d$-dimensional hyper-square base $J$ and height $r$. 
%It is well known, that such a hyper-pyramid has volume $\frac{1}{ d+1} r l^{d}$. 
%Hyper-rectangle $B$ has edge length $l$ in the first $d$ dimensions and edge length $r$ in the $d+1$th. Therefore, its volume is $r l^{d}$
%
%Before proceeding, we need to introduce the notion of an \textit{inverted hyper-pyramid}. For convenience, we will translate the space. Note, this neither  changes any volumes nor the definite integral we desire to calculate. That is, utilizing the substitution rule for definite integration, we see
%$\bar S = \int_{J} \norm{x-c}_\infty \d x =  \int_{J'} \norm{x}_\infty \d x$ where $J' = J - c = \{\xi \in \Real^d | (\xi_1,...,\xi_d)^T \in J'\} = [-r,r]^d$ is a translated version of hyperrectangle $J$. We will derive the last integral.
%
%A regular \emph{inverted} (half-open) hyper-pyramid (centred at zero) is the set
%$P:=\{ \xi \in \Real^{d+1} \, \vert \,  \xi_{d+1} \in (0,r], \forall j \in \{1,\ldots,d\}:\xi_j \in (-\xi_{d+1}, \xi_{d+1} )  \}.$
%
%For $d=2$, one can imagine the inverted pyramid as one standing on its tip on point $0 \in \Real^{d+1}$.
%An illustration of this case can be found in Fig. \ref{fig:pyramid_sampled_green}.
%\begin{figure}
%	\centering
%		\includegraphics[scale =.5]{content/figs/pyramid_sampled_green.pdf}
%	\caption{Samples drawn from an inverted pyramid centred at the origin and with edge length $l=2$.}
%	\label{fig:pyramid_sampled_green}
%\end{figure}
%
%
%
%
%Now, let $V(S) \in \Real$ denote the volume of a set $S \subset \Real^{d+1}$ and define 
%
%$K =\menge{\xi \in \Real^{d+1}}{ \xi_{d+1} \leq \norm{\xi}_{\infty}, (\xi_1,...,\xi_d)^T \in J', \xi_{d+1} \in [0,r]  }$  
%
%$
%= \menge{\xi \in \Real^{d+1}}{(\xi_1,...,\xi_d)^T \in J, \,  \, 0 \leq \xi_{d+1} \leq \max_{j \in \{1,...,d\}} \abs{\xi_j}\leq r }$.
%
%
%We have $\bar S = V(K)$. (Do I NEED TO JUSTIFY THIS ?????????????????)
%Furthermore, define $B := [-r,r]^{d} \times [0,r] = J' \times [0,r]$. We can show \[ K = B - P \] and hence, \[\bar S= V(K) = V(B) - V(P) = r l^{d} - \frac{1}{d+1} r l^{d} = \frac{d}{2(d+1)} l^{d+1}. \]
%
%It remains to be shown that indeed we have $K = B - P$:  
%To this end, we show that $B$ is partitioned into $K$ and $P$. 
%
%Firstly, we notice that obviously $K \subset B$ and $P \subset B$. 
%
%Secondly, we prove 
%%
%%%- --- beweis dass schnitt leer ist----
%% \underline{$K \cap P \stackrel{!}{=} \{\emptyset\}$}: For contradiction, assume $K \cap P \neq\{\emptyset\}$ and choose any $x \in K \cap P$. Since $x \in K$ we can choose $j \in \{1,...,d\}$ such that 
%%
%%$x_{d+1} \leq |x_j|$. That is, $x_{d+1} \leq x_j$ (i) or $x_{d+1} \leq -x_j$ (ii).
%%
%%1st case: Assume $x_{d+1} \leq x_j$. Since also $x \in P$, we have $x_j < x_{d+1}$. Hence, $x_{d+1} < x_{d+1}$ which is the desired contradiction.
%%
%%2nd case: Assume $x_{d+1} \leq -x_j$. Hence, $-x_{d+1} \geq x_j$. Since $x \in P$, we also have $x_j > -x_{d+1}$. In conjunction, this yields $-x_{d+1} > - x_{d+1}$ and thus, our desired contradiction.\\
%%%------------- beweis des leeren schnittes ende ---------------
%\underline{$x \notin K \wedge x \in B \Leftrightarrow x \in P$}: 
%
%%Note, $x \in K \cup P \Leftrightarrow x \in K \vee x \in P \Leftrightarrow (x \notin K \Rightarrow x \in P) \wedge (x \notin P \Rightarrow x \in K)$.
%
%$ x \in B \wedge x \notin K$  
%
%$\Leftrightarrow ( x \in [-r,r]^d \times [0,r] \wedge \bigl( x_{d+1} \notin [0,r] \vee (\exists j \in \{1,...,d\}: x_j \notin [-r,r]) \vee x_{d+1} > \max_{j \in \{1,...,d\}} \abs{x_j} \bigr) $ 
%
%$\Leftrightarrow (\forall j \in \{1,...,d\}: x_j \in [-r,r]) \wedge  r \geq x_{d+1} > \max_{j \in \{1,...,d\}} \abs{x_j} \geq 0 $
%
%$\Leftrightarrow x_{d+1} \in (0,r] \wedge \forall j \in \{1,...,d\}: (x_j \in [-r,r] \wedge  x_{d+1} > \abs{x_j} ) $
%
%$\Leftrightarrow x \in P$.
%
%\end{proof}
%\end{lem}


%-------------------

\begin{lem} \label{lem:defint_of_maxnorm}
Let $c \in \Real^d$ the centre point of hyperrectangle $J = \{ x \in \Real^d \vert \,(x-c)\, \in ([-r_1,r_1] \times \ldots \times [-r_d,r_d])\}\subset \Real^d$ where $r_1,\ldots,r_d \in \Real_+$ are the ``radii'' of the hyperrectangle. Let $r^* := \max\{r_1,\ldots,r_d \}$ and let $\mathfrak p: \in \text{Perm}(d)$ be a permutation such that $\rho_0 := 0 \leq \rho_1 := r_{\mathfrak p(1)}\leq \ldots \leq \rho_d := r_{\mathfrak p(d)} =r^*$.
We have 
\begin{align}
\bar S  &= \int_{J} \norm{x-c}_\infty \d x \\
& =  2^d r^* (\prod_{q=1}^d r_q) - 2^d \sum_{q=0}^{d-1} \frac{\prod_{j=1}^{q} \rho_j }{d-q+1} (\rho_{q+1}^{d-q+1} - \rho_{q}^{d-q+1} )
\end{align}

(where we adhere to the convention $\prod_{j=1}^0 \rho_j = 1$).


\begin{proof}
Before commencing further, note $\bar S = \int_{J} \norm{x-c}_\infty \d x = \int_{J'} \norm{x}_\infty \d x$ where 
\[J' =[-r_1,r_1] \times \ldots \times [-r_d,r_d] \subset \Real^d \]
 is a $d$-dimensional hyperrectangle. We will derive the value of the latter definite integral. For a set $S \subset \Real^d$ let $\Vol_{d}(S)$ be its volume (measure) in $d$ dimensions. By realizing that $\norm{x}_\infty \geq 0,\forall x \in J'$ we notice that $\int_{J'} \norm{x}_\infty \d x$ equals the volume of the set of points in $d+1$-dimensional space whose first $d$ components form a vector in $J'$ and whose last components are below the maximum norm and above zero. That is, $\int_{J'} \norm{x}_\infty \d x = \text{Vol}_{d+1}(K)$ where 
\[K :=\menge{\xi \in J' \times (0,r^*]}{ \xi_{d+1} \leq \norm{ \pi_{d}(\xi)}_{\infty}} 
 \] 
 where \[r^* := \max\{r_1,\ldots,r_d \}\] is the maximum radius 
 and \[\pi_d: \begin{cases} \Real^{d+1} \to \Real^d\\ (x_1,\ldots,x_d,x_{d+1})^T \mapsto (x_1,\ldots,x_d)^T 
 \end{cases}  \] is the projection onto the first $d$ components.
A key component of our proof is to establish that the desired definite integral coincides with the volume of the $d+1$-dimensional hyperrectangle 
%
\[B:= J' \times (0,r^*] \]  minus the volume of an half-open convex set \\
%
%\begin{small}

\[P:=\bigl\{ \xi \in B \, \vert  \forall  j \in \{1,...,d\} :\abs{\xi_j} < \min\{r_j,\xi_{d+1}\}   \bigr\}\]

%\end{small}
%
whose volume we can determine in closed form (as we will do below). In fact, one can notice that for equal radii $r_1,...,r_d = r^*$, $P$ is an inverted $d+1$-dimensional hyper-pyramid with a $d$-dimensional hyper-square base $J'$ and height $r^*$. 
An illustration of this case for $d=2$ can be found in Fig. \ref{fig:pyramid_samples}.

%\begin{figure*}
%	\centering
%		\includegraphics[scale =.5]{content/figs/maxnorm_fct_regular.pdf}
%	\caption{Surface plot of the maxnorm function on $J' =[-1,1] \times [-1,1]$}
%	\label{fig:maxnorm_fct_regular}
%\end{figure*} & 
%
%
%
%\begin{figure}
%	\centering
%		\includegraphics[scale =.5]{content/figs/pyramid_sampled_green.pdf}
%	\caption{Samples drawn from an inverted pyramid centred at the origin and with uniform radius $r_1=r_2=1$.}
%	\label{fig:pyramid_sampled_green}
%\end{figure}



\begin{figure*}
        \centering
        \begin{subfigure}
                \centering
                \includegraphics[scale =.20]{content/figs/maxnorm_samples.pdf}
               % \caption{Samples from $x \mapsto \norm{x}_{\infty}$ on  $J' =[-1,1] \times [-1,1]$.}
               % \label{fig:gull}
        \end{subfigure}%
         %add desired spacing between images, e. g. ~, \quad, \qquad etc. 
          %(or a blank line to force the subfigure onto a new line)
        \begin{subfigure}
                \centering
                \includegraphics[scale =.20]{content/figs/pyramid_sampled_green.pdf}
                %\caption{Samples from the interior of $P$.}
                %\label{fig:tiger}
        \end{subfigure}
        %
        \begin{subfigure}
                \centering
                \includegraphics[scale =.20]{content/figs/maxnorm_and_pyramid_samples.pdf}
                %\caption{Both merged. Note, }
                %\label{fig:tiger2}
        \end{subfigure}
         %add desired spacing between images, e. g. ~, \quad, \qquad etc. 
          %(or a blank line to force the subfigure onto a new line)
       \caption{Left: Samples from $x \mapsto \norm{x}_{\infty}$ on  $J' =[-1,1] \times [-1,1]$. Centre: Samples drawn from an inverted pyramid $P$ centred at the origin and base $J'$. Right: Note, how the points of $P$ are contained in the intersection of $B =[-1,1]^2 \times (0,1]$ and the epigraph of $x \mapsto \norm{x}_{\infty}$. }
       \label{fig:pyramid_samples}
\end{figure*}	


As explained above, $\bar S = \Vol(K)$. 
Below, we will show \[ K = B \backslash P \] and hence, 
\begin{equation}
\bar S= \Vol(B) - \Vol(P)=  r^* \prod_{i=1}^d (2r_i) - \Vol(P). 
\end{equation}

So, we need to derive two things:\\
 
(I) Firstly, it remains to be shown that indeed we have $K = B - P$.\\
(II) Secondly, we need to find a closed-form formula for $\Vol (P)$.\\
 


Derivation of (I). In order to prove $K = B \backslash P$. We notice that, by definition, $K,P \subset B$. Next, we show that $B$ is partitioned into $K$ and $P$ which we achieve by showing the following equivalence: 

\[\forall x \in B: x \in K \oplus x \in P. \]

where $\oplus$ denotes the \emph{exclusive or}. 

The \textit{exclusive or} statement can be rewritten as 

$x \notin K \wedge x \in B \Leftrightarrow x \in P \wedge x \in B$ which we show as follows: 

%Note, $x \in K \cup P \Leftrightarrow x \in K \vee x \in P \Leftrightarrow (x \notin K \Rightarrow x \in P) \wedge (x \notin P \Rightarrow x \in K)$.

$ x \in B \wedge x \notin K$  

$\Leftrightarrow ( x \in J' \times (0,r^*] \wedge \bigl( x \notin J' \times (0,r^*] \vee x_{d+1} > \max_{j \in \{1,...,d\}} \abs{x_j} \bigr) $ 

$\Leftrightarrow ( x \in J' \times (0,r^*] \wedge   x_{d+1} > \max_{j \in \{1,...,d\}} \abs{x_j} \geq 0 $

$\Leftrightarrow x_{d+1} \in (0,r^*] \wedge \forall j \in \{1,...,d\}: (x_j \in [-r_j,r_j] \wedge  x_{d+1} > \abs{x_j} ) $

$\Leftrightarrow x \in B \wedge \forall j \in \{1,...,d\} : \min \{x_{d+1}, r_j\} > \abs{x_j } \bigr\}$

$\Leftrightarrow x \in P \wedge x \in B$.\\


Derivation of (II). We desire to determine $\Vol_{d+1}(P)$. We have 

\[\Vol_{d+1}(P) = \int_0^{r^*} \Vol_d \bigl(R(h)\bigr) \, dh\]
%\end{equation} 

where $R(h) = \bigl\{(\xi_1,...,\xi_d)^T \vert  \forall  j \in \{1,...,d\} :\abs{\xi_j} < \min\{r_j,h \} \bigr\} = \pi_d(P \cap \{x \in \Real^{d+1} | x_{d+1} =h \})$ is the set of all points of $P$ having ``height'' $h \in (0,r^*]$.
Let $\mathfrak p: \in \text{Perm}(d)$ be a permutation such that $\rho_0 := 0 \leq \rho_1 := r_{\mathfrak p(1)}\leq \ldots \leq \rho_d := r_{\mathfrak p(d)} =r^*$.

So, we can write \[R(h) = \bigl\{(\xi_1,...,\xi_d)^T \vert  \forall  j \in \{1,...,d\} :\abs{\xi_{\mathfrak p (j)}} < \min\{\rho_j,h \} \bigr\}. \]
We have, 
$\Vol_{d+1}(P) = \int_0^{r^*} \Vol_d \bigl(R(h)\bigr) \, dh$ 
\begin{equation}
\label{eq:volgenhyperpyramid}
= \int_0^{\rho_1} \Vol_d \bigl(R(h)\bigr) \, dh + \sum_{i=1}^{d-1} \int_{\rho_i}^{\rho_{i+1}} \Vol_d \bigl(R(h)\bigr) \, dh.
\end{equation}

We note,
$\forall h \in (0, \rho_1):  h < \rho_j, \forall j >1$. Hence, $\forall h \in (0, \rho_1): R(h) = \bigl\{(\xi_1,...,\xi_d)^T \vert  \forall  j \in \{1,...,d\} :\abs{\xi_j} < h \bigr\}$ which is a hyper-square in $R^d$ with edge length $2h$. Hence, \[\Vol_d\bigl(R(h)\bigr) = (2h)^d, \,\,\,\, \forall h \in (0, \rho_1).\] 
Hence, 
\begin{equation}
\int_0^{\rho_1} \Vol_d\bigl(R(h)\bigr) \, dh = \int_0^{\rho_1} (2h)^d \, dh = \frac{2^d \rho_1^{d+1}}{d+1}.
\end{equation}

Analogously, let  $i \in \{1,...,d-1\}$ and  $h \in (\rho_i, \rho_{i+1})$ arbitrary. We have $  \rho_1 \leq ... \leq \rho_i <h < \rho_{i+1} \leq ... \leq \rho_d$. Hence, $R(h) = \bigl\{(\xi_1,...,\xi_d)^T \vert  \forall  j \in \{1,...,d\} :\abs{\xi_{\mathfrak p (j)}} < \min\{\rho_j,h \} \bigr\} = \bigl\{(\xi_1,...,\xi_d)^T \vert  \forall  j \in \{1,...,i\} :\abs{\xi_{\mathfrak p (j)}} < \rho_j,  \forall  j \in \{i+1,...,d\} :\abs{\xi_{\mathfrak p (j)}} < h \bigr\}$ being a hyperrectangle. 
Thus, $\Vol_d\bigl(R(h) \bigr) = (2h)^{d-i} \prod_{j=1}^{i} (2\rho_j), \forall i \in \{1,...,d-1\}, h \in (\rho_i, \rho_{i+1}).$

Hence, 
\begin{eqnarray}
\int_{\rho_i}^{\rho_{i+1}} \Vol_d\bigl(R(h)\bigr) \, dh = \prod_{j=1}^{i} 2\rho_j \int_{\rho_i}^{\rho_{i+1}} (2h)^{d-i}  \, dh \\= 2^d \frac{\prod_{j=1}^{i} \rho_j }{d-i+1} (\rho_{i+1}^{d-i+1} - \rho_{i}^{d-i+1} ).
\end{eqnarray}

Inserting the formulae into Eq. \ref{eq:volgenhyperpyramid} yields the solution:

\[\Vol_{d+1}(P) = 2^d \sum_{i=0}^{d-1} \frac{\prod_{j=1}^{i} \rho_j }{d-i+1} (\rho_{i+1}^{d-i+1} - \rho_{i}^{d-i+1} ). \]

\end{proof}
\end{lem}

As a special case we obtain for hyper-square domains:
\begin{cor} Let $c \in \Real^d$, $l\in \Real$ be the edge length of hyper-square $J := \menge{x \in \Real^d}{ (x -c) \in [-r,r]^d } \subset \Real^d$ where $r= \frac{1}{2} l$. 
We have \[
\bar S = \int_{J} \norm{x-c}_\infty \d x = \frac{d}{2(d+1)}  l^{d+1}.\]
\end{cor}


 Let $J_i = c_i + ([-r_1(i),r_1(i)]\times,\ldots, \times[-r_d(i),r_d(i)])$ ($r_j(i) >0, \forall j$) be a hyperrectangle with centre point $c_i \in \Real^d$. As in Lem. \ref{lem:defint_of_maxnorm},  $r^{*}(i) := \max\{r_1(i),\ldots,r_d(i) \}$ and let $\mathfrak p^i: \in \text{Perm}(d)$ be a permutation such that $\rho_0(i) := 0 \leq \rho_1(i) := r_{\mathfrak p^i(1)}(i)\leq \ldots \leq \rho_d(i) := r_{\mathfrak p^i(d)}(i) =r^{*}(i)$. We can utilize Lem. \ref{lem:defint_of_maxnorm} to calculate our conservative estimate of the integral:

\begin{align*}
%
\hat S_{N,i}^\decke &=\int_{J_i} \decke^i_N( x) \, \d x \\
%
& = \int_{J_i} f(c_i) + \ell_i \norm{x-c_i}_{\infty} \, \d x \\
%
& = \int_{J_i} f(c_i) \, \d x + \ell_i \int_{J_i}  \norm{x-c_i}_{\infty} \, \d x \\
%
& = f(c_i) \Vol(J_i) + \ell_i 2^d r^{*}(i) (\prod_{q=1}^d r_q(i)) \\
&- \ell_i 2^d \sum_{q=0}^{d-1} \frac{\prod_{j=1}^{q} \rho_j(i) }{d-q+1} \bigl(\rho_{q+1}^{d-q+1}(i) - \rho_{q}^{d-q+1}(i) \bigr) \\
%
& = \bigl(f(c_i) + \ell_i r^{*}(i) \bigr) \,2^d (\prod_{q=1}^d r_q(i)) \\
&- \ell_i 2^d \sum_{q=0}^{d-1} \frac{\prod_{j=1}^{q} \rho_j(i) }{d-q+1} \bigl(\rho_{q+1}^{d-q+1}(i) - \rho_{q}^{d-q+1}(i) \bigr) \\
\end{align*}

In conjunction with Eq. \ref{eq:defint_ceiling}, this yields 
\begin{align} \label{eq:quadupper_multidim}
\hat S_N^\decke &= \sum_{i=1}^N \int_{J_i} \decke^i_N( x) \d x \\
&= \sum_{i=1}^N  \Bigl[ \bigl(f(c_i) + \ell_i r^{*}(i) \bigr) \,2^d (\prod_{q=1}^d r_q(i)) \\
&- \ell_i 2^d \sum_{q=0}^{d-1} \frac{\prod_{j=1}^{q} \rho_j(i) }{d-q+1} \bigl(\rho_{q+1}^{d-q+1}(i) - \rho_{q}^{d-q+1}(i) \bigr) \Bigr]\\
& \geq \int_I f(x) \,dx = S.
\end{align}


\textbf{Lipschitz floor.}

The derivation is completely analogous to the derivation of the Lipschitz ceiling provided above. 

Lipschitz continuity gives

\[\forall i \forall x,x' \in J_i: \abs{f(x) - f(x')} \leq L_i \norm{x-x'}. \]

and hence, 

\[\forall i \forall x \in J_i: f(c_i) - f(x) \leq\abs{f(c_i) - f(x)} \leq L_i \norm{x-c_i}. \]
Thus, 
\begin{align}
\forall i \forall x \in J_i: f(x)  &\geq f(c_i) - L_i \norm{x-c_i} \\
&\geq f(c_i) - \ell_i \norm{x-c_i}_{\infty}:= \boden^i_N(x)
\end{align}
where $\ell_i = \sqrt d L_i$ is a Lipschitz constant for the max-norm.

Therefore, we can define a new \textit{Lipschitz floor} 

\[\boden_N: x \mapsto \sum_{i=1}^N \chi_{J_i} (x) \, \boden^i_N(x)\]
guaranteeing to be a \emph{lower} bound on $f$:

\[\boden_N( x) \leq f(x), \forall x \in I \subset \Real^d.\]

Therefore, 

\[\hat S_N^\boden:=\int_I \boden_N( x) \, \d x \leq \int_I f(x) \, \d x  = S, \forall x \in I \subset \Real^d.\]
Each $\boden^i_N$ being integrable, we have 
\begin{equation}
\sum_{i=1}^N \int_{J_i} \boden^i_N( x) d\mu(x)=\hat S_N^\boden \leq \int_I f(x) \, \d x.
\label{eq:defint_ceiling}
\end{equation}
Fortunately, we can evaluate $\hat S_{N,i} :=\int_{J_i} \boden^i_N( x) \, \d x$ in closed-form. To this end, we once again evoke Lem. \ref{lem:defint_of_maxnorm} to deduce:

\begin{align*} 
%
\hat S_{N,i}^\boden &=\int_{J_i} \boden^i_N( x) \, \d x \\
%
& = \int_{J_i} f(c_i) - \ell_i \norm{x-c_i}_{\infty} \, \d x \\
%
& = \int_{J_i} f(c_i) \, \d x - \ell_i \int_{J_i}  \norm{x-c_i}_{\infty} \, \d x \\
%
& = f(c_i) \Vol(J_i) - \ell_i 2^d r^{*}(i) (\prod_{q=1}^d r_q(i)) \\
&+ \ell_i 2^d \sum_{q=0}^{d-1} \frac{\prod_{j=1}^{q} \rho_j(i) }{d-q+1} \bigl(\rho_{q+1}^{d-q+1}(i) - \rho_{q}^{d-q+1}(i) \bigr) \\
%
& = \bigl(f(c_i) -  \ell_i r^{*}(i) \bigr) \,2^d (\prod_{q=1}^d r_q(i)) \\
&+ \ell_i 2^d \sum_{q=0}^{d-1} \frac{\prod_{j=1}^{q} \rho_j(i) }{d-q+1} \bigl(\rho_{q+1}^{d-q+1}(i) - \rho_{q}^{d-q+1}(i) \bigr). 
\end{align*}
%
Therefore,
\begin{align} \label{eq:quadlower_multidim}
\hat S_N^\boden &= \sum_{i=1}^N \int_{J_i} \boden^i_N( x) \d x \\
&= \sum_{i=1}^N  \Bigl[ \bigl(f(c_i) -  \ell_i r^{*}(i) \bigr) \,2^d (\prod_{q=1}^d r_q(i)) \\
&+ \ell_i 2^d \sum_{q=0}^{d-1} \frac{\prod_{j=1}^{q} \rho_j(i) }{d-q+1} \bigl(\rho_{q+1}^{d-q+1}(i) - \rho_{q}^{d-q+1}(i) \bigr) \Bigr]\\
& \geq \int_I f(x) \,dx = S.
\end{align}

\textbf{Convergence.}


We have shown $S$

As before we will have to argue that $\decke_N \to f$ uniformly and hence, $\hat S_N^\decke \to S$ as $N \to \infty$ 
for a dense grid sequence $G_N$.
Let $(G_N)_{N \in \nat}$ be a sequence of grids in $\Real^d$. For each  $N \in \nat$, we denote $G_N =: \{\bigl(c_1^N,f(c_1^N), J_1^N\bigr),\ldots,\bigl(c_N^N,f(c_N^N), J_N^N\bigr)\}$ being a set of triples consisting of centre points $c_i^N$, function values $f(c_i^N)$ and hyperrectangle $J_i^N$ (centred around $c_i^N$). 
Superscript $N$, in $c_i^N$ serves to distinguish between the $i$th domain sample in the grid for different choices of $N \in \nat$. Above, we could afford to omit these superscripts, simply writing $c_i$, tacitly assuming fixed $N$. However, for the following argument the superscripts become necessary.
Also, remember, we assumed the hyperrectangles partition the domain. That is, $\forall N \in \nat \forall 1\leq j< q \leq N:  I = \bigcup_{i=1}^N J_i^N \wedge J_j^N \cap J_q^N = \emptyset$.


For $N \in \nat$, $\bar r_i^N = \max\{ r_{i,1}^N,\ldots, r_{i,d}^N\}$ denotes the maximum radius of hyperrectangle $J_i^N = c_i + \bigl([-r_{i,1}^N ,r_{i,1}^N ]\times \ldots \times [-r_{i,d}^N ,r_{i,d}^N ] \bigr)$. Furthermore, $\bar r^N := \max_{i \in \{1,...,N\}} \bar r_i^N$ is the maximum radius of any hyperrectangle in the $N$th partition of $I$.


\begin{defn}[``Eventually dense partition'']
 We say the grid sequence $G_N$ becomes an ``eventually dense partition'' of $I$ if the hyperrectangles shrink indefinitely while still partitioning the entirety of $I$. That is, \\
 
$G_N$ ``becomes an eventually dense partition '' of $I$ $:\Longleftrightarrow$ 
$\bar r^N \stackrel{N \to \infty}{\longrightarrow} 0$ $ \wedge \forall N \in \nat: \Bigl(I = \bigcup_{i=1}^N J_i^N \wedge \forall 1\leq j< q \leq N : J_j^N \cap J_q^N = \emptyset\Bigr)$.

Here, $\bar r^N \stackrel{N \to \infty}{\longrightarrow} 0$ is equivalent to $\forall \epsilon >0 \exists N_0 \in \nat \forall N > N_0 \forall i \in \{1,...,N\}: 0< \bar r_i^N < \epsilon $.
\label{defn:eventuallydensepartition}
\end{defn}
%
%\begin{lem}
%Let $(G_N)_{N \in \nat}$ be a sequence of grids that becomes dense in $I$.
%
%Eventually, the maximum expansion of each hypersquare in the grid becomes arbitrarily small. More precisely, we have  
%$\forall \epsilon > 0 \exists N_0  \in \nat \, \forall N \geq N_0 \forall i \in \{1,\ldots,N\}: \bar r_i^N  \leq \epsilon$.
%
%\begin{proof}
%Assume the conclusion does not hold. That is, $\exists \epsilon > 0 \forall N_0  \in \nat \, \exists N \geq N_0 \exists i \in \{1,\ldots,N\}: \bar r_i^N  > \epsilon$. So, assume $\bar r_i^N  > \epsilon$ where the negation of the conclusion of the lemma implies that $N$ can be arbitrarily large. Now, choose $x \in J_i$
%\end{proof}
%
%\end{lem}

In preparation for the following theorem, we will establish the following observation:
\begin{lem} \label{lem:supinfonJimultidim}
We have:

(I) $\sup_{x \in J_i} \decke_N^i (x) = f(c_i) + \ell_i \bar r_i^N$,\\


(II) $\inf_{x \in J_i}  \boden^i_N(x) = f(c_i) - \ell_i \bar r_i^N$\\
 
and\\

(III)  $\sup_{x \in J_i} \decke_N^i (x) - \boden_N^i(x) = 2 \ell_i \bar r_i^N$.


\begin{proof}
Referring to the relevant definitions, we see that $\sup_{x \in J_i} \norm{x-c_i}_{\infty} = \bar r_i^N$.
Hence, 

(I): $\sup_{x \in J_i} \decke^i_N(x) = f(c_i) + \ell_i \sup_{x \in J_i} \norm{x-c_i}_{\infty}$
$= f(c_i) + \ell_i \bar r_i^N$.

(II): $\inf_{x \in J_i} \boden^i_N(x) = f(c_i) - \ell_i \sup_{x \in J_i} \norm{x-c_i}_{\infty}$
$= f(c_i) + \ell_i \bar r_i^N$.

(III): $\sup_{x \in J_i} \decke_N^i (x) - \boden_N^i(x) = 2 \ell_i \sup_{x \in J_i} \norm{x-c_i}_{\infty}  =  2 \ell_i \bar r_i^N. $
\end{proof} 
\end{lem}


\begin{thm}
If $G_N$ becomes eventually dense in $I$, we have: $\decke_N, \boden_N$ converge to target function $f: I\subset \Real^d \to \Real$ uniformly on domain $I$.

\begin{proof}

Since $G$ is dense with respect to a canonical metric, it is also dense with respect to the max-norm metric $d: \Real^d \times \Real^d \to \Real, (x,\xi) \mapsto \norm{x-\xi}_{\infty}$.

We show that sequence, $(\phi_N)$, $\phi_N \in \einschluss = \{ \phi: I \to \Real | \forall x \in I : \decke_N(x) \geq \phi(x) \geq \boden_N(x) \}$ converges uniformly to $f$, regardless of the identity of $f$, as long as $G_N$ becomes eventually a dense partition of $I$. 

That is, we show $\forall \epsilon >0 \exists N_0 \forall N \geq N_0 \forall x \in I : \abs{\phi_N(x) - f(x)} \leq \epsilon$:
 

Let $\epsilon > 0$ and define $\ell := \max_{i=1,...,N-1} \ell_i$ to be the maximum Lipschitz constant of the intervals $J_1,...,J_N$. Since $G_N$ becomes eventually dense, we know that $\bar r^N \stackrel{N \to \infty}{\longrightarrow} 0 $. Hence, $\exists N_0 \in \nat \forall N > N_0 \forall i \in \{1,...,N\}: 0< \bar r_i^N \leq \delta:=\frac{\epsilon}{2 \ell} $ for some $N_0 \in \nat$.


So, let $N \geq N_0$. 
Note, $\sup_{ x \in I} \abs{\phi_N(x) - f(x)} \leq \sup_{ x \in I} \abs{\decke_N(x) - \boden_N (x)} \leq \max_{i\in \{1,...,N\}} \sup_{ x \in J_i} \abs{\decke_N^i(x) - \boden_N^i (x)}$
$\leq \max_{i}  \abs{\sup_{ x \in J_i}\decke_N^i(x) - \inf_{ x \in J_i} \boden_N^i (x)}$
$\stackrel{Lem. \ref{lem:supinfonJimultidim}}{=} \max_i \abs{ f(c_i) + \ell_i \bar r_i^N - f(c_i) + \ell_i \bar r_i^N}$
$=\max_i \abs{ 2 \ell_i \bar r_i^N}$
$\stackrel{\bar r_i^N \leq \delta}{\leq} 2 \max_i \abs{ l_i \delta } = 2 \delta \max_i l_i = \epsilon$.
Thus, $\forall x \in I: \abs{\phi_N(x) - f(x)} \leq \epsilon$.

We have shown  $\forall \epsilon >0 \exists N_0 \forall N \geq N_0  \sup_{x \in I} \abs{\phi_N(x) - f(x)} \leq \epsilon$ which is equivalent to uniform convergence to $f$.


\end{proof}

\end{thm}

Having established conditions under which our conservative estimates $\decke_N, \boden_N$ converge uniformly to the ground-truth $f$, we apply this result to establish convergence of the corresponding definite integrals to the definite integral of $f$. Owing to the uniformity of our previous convergence results, this proof goes through in a straight-forward manner. 


\begin{thm}\label{thm:defintconv_multidim}
If the grid sequence $G_N$ becomes an eventually dense partition of domain $I$, our conservative definite integrals converge to the ground truth. That is, we have 
\[\forall N \in \nat : \hat S^\decke_N \geq \int_I f(x) \, \d x \geq  \hat S^\boden_N \]

\[ \hat S^\decke_N, \hat S^\boden_N  \stackrel{N \to \infty}{\longrightarrow} \int_I f(x) \, \d x,  \]
 


where $\hat S^\decke_N$ and $ \hat S^\boden_N$ are defined as in Eq. \ref{eq:quadupper_multidim} and Eq. \ref{eq:quadlower_multidim}, respectively. 

\begin{proof}
The first inequalities, $\forall N \in \nat : \hat S^\decke_N \geq \int_I f(x) \, \d x \geq  \hat S^\boden_N$
are a direct consequence of the conservativeness of our estimates. That is, it follows from  $\decke_N(x) \geq f(x) \geq \boden_N(x),\forall x \in I, \forall N \in \nat $ which was shown above utilizing the Lipschitz properties of $f$.

As for the convergence properties, recall that $G_N$ becoming dense implies uniform convergence of the conservative estimates to $f$. 
Due to uniform convergence, we can exchange integral and limites. That is, we have 

$0 = \int_I f(t) \, dt - \int_I f(t) \, dt$
$=  \int_I \lim_{N \to \infty} \decke_N(t) \, dt  - \int_I \lim_{N \to \infty}  \boden_N (t) \, dt$
$\stackrel{unif. conv.}{=} \lim_{N \to \infty} \int_I \decke_N(t) \, dt  - \lim_{N \to \infty} \int_I \boden_N (t) \, dt$    
$=\lim_{N \to \infty} \hat S^\decke_N - \hat S^\boden_N $. Combining this with $\forall N \in \nat : \hat S^\decke_N \geq \int_I f(x) \, \d x \geq  \hat S^\boden_N $ yields the desired result: $\hat S^\decke_N, \hat S^\boden_N  \stackrel{N \to \infty}{\longrightarrow} \int_I f(x) \, \d x$. 


\end{proof}

\end{thm}

\subsubsection{Grids with function samples at arbitrary points within hyperrectangles}
Above, our conservative estimates were based on the assumption that the grid was constructed such that the $N$ function samples 
where always obtained at centre points of the hyperrectangles partitioning the domain in question. If we have complete control over where to sample the target function, it will always possible to construct a grid where this assumption holds true.

However, in certain scenarios, we may have to lift this assumption. For instance, in cases where the samples of the function values represent observational data from experiments where active sampling is not possible or to costly to ensure. 
While we can still partition our integration domain $I$ into $N$ hyperrectangles $J_i^N$   such that each function sample input $c_i^N \in \Real^d$ lies in hyperrectangle $J_i^N$ $(i=1,...,N)$, it may not necessarily be possible to ensure, that $c_i^N$ is a centre point of $J_i^N$. In this case, we need to alter the definition of a grid $G_N$ to be a sequence of $N$ triples $\bigl(c_i^N,f(c_i^N), [-a_i^N,b_i^N]\bigr)$ where $a_i^N,b_i^N \in  \Real_+^d$  $(i=1,...,N)$. Here, each hyperrectangle $J_i^N$ is defined as the set of points 
$c_i^N + [-a_{i,1}^N,b_{i,1}^N] \times \ldots \times [-a_{i,d}^N,b_{i,d}^N]$. 

It will be the goal of the remainder of this section to extend our results to such grids. While our formulas will be recursive rather than closed-form, the solutions are exact and computational effort can be bounded before run-time.
As before, we will omit indices $i$ and $N$, for ease of notation, wherever possible.

In preparation of the following we need the following lemma:

\begin{lem} \label{lem:intcompeven}
For $i=1,...,d$ let $0 < a_i \leq b_i$, and let 

$f: J= [-a_1,b_1] \times ... \times [-a_d,b_d]\to \Real$ \textit{even} in the $j$th component. That is, $\forall i \in \{1,...,d\}: f\bigl( x_1,...,x_d \bigr) =  f\bigl( x_1,...,x_{j-1},-x_j,x_{j+1},...,x_d \bigr)$. If $f$ is Riemann integrable, we have 

$
\int_{-a_1}^{b_1} \ldots \int_{-a_{d}}^{b_{d}} f(x_1,\ldots,x_d ) \, \,dx_1 \ldots \d x_d \\
 =\int_{-a_1}^{b_1} \ldots\int_{-a_{j-1}}^{b_{j-1}} \int_{-b_j}^{a_j} \int_{-a_{j+1}}^{b_{j+1}} \ldots \int_{-a_{d}}^{b_{d}} f(x_1,\ldots,x_d ) \, \,dx_1 \ldots \d x_d  
$
where $\int $ denotes the Riemann integral.

\begin{proof}
Since $f$ is Riemann integrable, it is continuous almost everywhere. Since the integral does not change if we alter the function on a zero-measure subset, we can, without loss of generality, assume that it is continuous on $J$. Hence, we can apply Fubini's theorem. Therefore, without loss of generality, we can assume $j=d$ (if $j<d$ Fubini's allows us to reorder the components to make the $j$th the last component). That is, we assume that $f$ is even in its last input component.

\begin{align*}
&\int_{-a_1}^{b_1} \ldots \int_{-a_{d}}^{b_{d}} f(x_1,\ldots,x_d ) \, \,dx_1 \ldots \d x_d\\
% 
&=\lim_{N_1 \to \infty} \ldots \lim_{N_d \to \infty} \sum_{i_1=1}^{N_1} \ldots \\ 
&\ldots \sum_{i_{d-1}=1}^{N_{d-1}} \Bigl(\sum_{i_d=1}^{N_d} f(-a_1 + i_1 \frac{b_1+a_1}{N_1},...,-a_d + i_d \frac{b_d+a_d}{N_d})  \Bigr)\\
&\stackrel{(i)}{=}\lim_{N_1 \to \infty} \ldots \lim_{N_d \to \infty} \sum_{i_1=1}^{N_1} \ldots \\ 
&\ldots \sum_{i_{d-1}=1}^{N_{d-1}} \Bigl(\sum_{i_d=1}^{N_d} f(-a_1 + i_1 \frac{b_1+a_1}{N_1},...,a_d - i_d \frac{b_d+a_d}{N_d})  \Bigr)\\
&\stackrel{(ii)}{=}\lim_{N_1 \to \infty} \ldots \lim_{N_d \to \infty} \sum_{i_1=1}^{N_1} \ldots \\ 
&\ldots \sum_{i_{d-1}=1}^{N_{d-1}} \Bigl(\sum_{i_d=1}^{N_d} f(-a_1 + i_1 \frac{b_1+a_1}{N_1},...,-b_d + i_d \frac{b_d+a_d}{N_d})  \Bigr)\\
%
&=\int_{-a_1}^{b_1} \ldots \int_{-a_{d-1}}^{b_{d-1}} \int_{-b_{d}}^{a_{d}}f(x_1,\ldots,x_d ) \, \,dx_1 \ldots \d x_d.
\end{align*}
Equality (i) follows from the assumption that $f$ is $d-$ even.
Equality $(ii)$ can be seen by showing $\Bigl(\sum_{i=1}^{N_d} f(-a_1 + i_1 \frac{b_1+a_1}{N_1},...,p_i)  \Bigr) =\Bigl(\sum_{k=1}^{N_d} f(-a_1 + i_1 \frac{b_1+a_1}{N_1},...,q_k)  \Bigr) $ where $p_i = a_d - i \frac{b_d+a_d}{N_d}$ and $q_k = -b_d + k \frac{b_d+a_d}{N_d}$ for $i,k \in \{1,...,N_d\}$. 
We prove this equality by showing 
$\forall i \in \{1,...,N_d\} \exists !  k \in \{1,...,N_d\}: p_i = q_k $ as follows:

Let $i,j \in \{1,...,N_d\}$.
$p_i = q_j \stackrel{def.}{\Leftrightarrow}  a_d - i \frac{b_d+a_d}{N_d} = -b_d + j \frac{b_d+a_d}{N_d} $
$\Leftrightarrow a_d +b_d  =  (j+i) \frac{b_d+a_d}{N_d} \stackrel{(iii)}{\Leftrightarrow}  1 =  (j+i) \frac{1}{N_d} $
${\Leftrightarrow}  i = N_d -j$.

$(iii):$ Equivalence holds since we can divide by $a_d+b_d >0 $ (remember, $b_d \geq a_d > 0$).  
\end{proof}

\end{lem}

\begin{thm}  For $j \in \{1,...,d\}$ let $0 \leq a_j \leq b_j$ $J^{\neg j} := \prod_{i \in \{1,...,d\} \backslash \{j\}} \, [-a_i,b_i]$ the Cartesian product of all intervals except$ [-a_j,b_j]$. Similarly, $x_{\neg j}$ denotes the vector $(x_1,...,x_{j-1},x_{j+1},...,x_d)$ of all components of $x \in \Real^d$, except the $j$th.  
\\ 

Let $M_j := \int_{-a_j}^{b_j} \int_{J^{\neg j}} \norm{x}_\infty \d x_{\neg j} \d x_j$.\\
Assume, we know how to calculate \\
$S_j = \int_{-a_d}^{a_d} \int_{J^{\neg j}} \norm{x}_\infty  \d x_{\neg j} \d x_j$ and \\
$B_j = \int_{-b_d}^{b_d} \int_{J^{\neg j}} \norm{x}_\infty \d x_{\neg j} \d x_j$. We have,
\[M_j = \frac{B_j + S_j}{2}.\]

\begin{proof}
Define $F_j : x_j \mapsto \int_{J^{\neg j}} \norm{(x_1,...,x_d)}_\infty \d x_{\neg j} $. We have,
 
$M_j =  \int_{-a_j}^{b_j} F_j(x_j) \d x_j $
$= \frac{ 2 \int_{-a_j}^{a_j} F_j(x_j) \d x_j + 2 \int_{a_j}^{b_j} F_j(x_j) \d x_j }{2}$
$\stackrel{(i) }{=} \frac{ 2 \int_{-a_j}^{a_j} F_j(x_j) \d x_j +  \int_{a_j}^{b_j} F_j(x_j) \d x_j 
+ \int_{-b_j}^{-a_j} F_j(x_j) \d x_j }{2}$
${=} \frac{  \int_{-a_j}^{a_j} F_j(x_j) \d x_j +  \int_{-b_j}^{b_j} F_j(x_j) \d x_j}{2}$.
Here, equality (i) follows from application of Lem. \ref{lem:intcompeven} to the term $\int_{a_j}^{b_j} F_j(x_j) \d x_j $.
\end{proof}
\end{thm}

We can utilize this theorem in conjunction with Lem. Lem. \ref{lem:defint_of_maxnorm} to prove correctness of the following recursive algorithm:  

\IncMargin{-1em}
\begin{algorithm}
\begin{small}
%\SetKwData{flag}{flag}
\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
%
\Input{Domain $J =  \prod_{i \in \{1,...,d\}} \, [-a_i,b_i], \forall i: b_i \geq a_i >0$}
\Output{Integral $S \, \, (= \int_J \norm{x}_{\infty} \d x)$}
\BlankLine
%\emph{special treatment of the first line}\;
%$\flag \leftarrow 0$;\\
\For{$i \in \{1,...,d\}$}{

\If{ $a_i \neq b_i$}
{
$S \leftarrow \frac{1}{2} Alg. \ref{alg:recursivequad1} (J^{\neg i} \times [-a_i,a_i])  + \frac{1}{2} Alg. \ref{alg:recursivequad1} (J^{\neg i} \times [-b_i,b_i]) $;
return S;
}

}
Compute $S$ according to Lem. \ref{lem:defint_of_maxnorm};\\
return S;

\caption{Recursive integration method.}

\label{alg:recursivequad1}
\end{small}
\end{algorithm}

PROBLEM: recursion might be evoked for each dimension. So, worst-case complexity is at least of the order of $2^d$!!

\begin{ques}
Surely, we can do better than that! ?
\end{ques}

\section{LACKI and model reference adaptive control for online learning and aircraft tracking control in the presence of wing rock dynamics }
\label{sec:KIMRAC}
As pointed out in \cite{chowdharyacc2013}, modern fighter aircraft designs are susceptible to lightly damped oscillations in roll known as ``wing rock''. Commonly occurring during landing \cite{Saad2000}, removing wing rock from the dynamics is crucial for precision control of such aircraft.
Precision tracking control in the presence of wing rock is a nonlinear problem of practical importance and has served as a test bed for a number nonlinear adaptive control methods \cite{Chowdhary2013,Monahemi1996,chowdharyacc2013}.

We replicate the experiments of the recent work of Chowdhary et. al. \cite{Chowdhary2013,ChowdharyCDC2013}.\footnote{We are grateful to the authors for kindly providing the code.}
Here the authors have compared their Gaussian process based approach, called \textit{GP-MRAC}, to the more established adaptive model-reference control approach based on RBF networks \cite{Sanner1992,Kim1998}, referred to as \textit{RBFN-MRAC}. Replacing the Gaussian process learner by our kinky inference learner, we readily obtain an analogous approach which we will refer to as \emph{kinky inference model reference adaptive control} (\textit{LACKI-MRAC}). As an additional baseline, we also examine the performance of a simple linear controller.

While with the exact same parameters settings of the experiments in \cite{Chowdhary2013}, performance of our LACKI-MRAC method comes second to GP-MRAC, we also evaluate the performance of all controllers over a range of 555 random parameter settings and initial conditions. As we will see, across this range of problem instances and parameter settings, LACKI-MRAC markedly outperforms all other methods.

\subsection{Model reference adaptive control}
Before proceeding with the wing rock application we will commence with (i) outlining model reference adaptive control (MRAC) \cite{astroemadaptivectrlbook2013} as considered in \cite{Chowdhary2013} and (ii) describe the deployment of the LACKI learning algorithm to this framework to yield our LACKI-MRAC adaptive controller. 
We will now rehearse the description of MRAC for second-order systems following \cite{Chowdhary2013}:

Assume $m \in \nat$ to be the dimensionality of a configuration of the system in question and define $d = 2m$ to be the dimensionality of the pertaining state space $\statespace$.

Let $x = [x_1;x_2] \in \statespace$ denote the state of the plant to be controlled.
Given the control-affine system 
 %
\begin{align}
\dot x_1 = x_2, \hspace{1cm}  \dot x_2 = a(x) + b(x) \, u(x) \label{eq:secorddynctrlaff}
\end{align}
%
it is desired to find a control law $u(x)$ such that the closed-loop dynamics exhibit a desired reference behaviour:
%
\begin{align}
\dot \xi_1 = \xi_2, \hspace{1cm}   \dot \xi_2 = f_{r}(\xi,r)
\end{align}
where $r$ is a reference command $f_r$ some desired response and $t \mapsto \xi (t)$ is the reference trajectory.

If a priori $a$ and $b$ are believed to coincide with $\hat a_0, \hat b_0$ respectively, the inversion control 
$u = \hat b_0^{-1} (- \hat a_0 +u')$ is applied. This reduces the closed-loop dynamics to 
$\dot x_1 = x_2, \dot x_2 = u' + \tilde a(x,u) $
where $\tilde a(x,u)$ captures the modelling error of the dynamics: 
\begin{equation}
	\tilde a (x,u ) = a(x) - \hat a_0(x) + \bigl(b(x) - \hat b_0(x)\bigr) u.
\end{equation}
 For $m = \frac d 2$, let $I_m \in \Real^{m \times m}$ denote the $m \times m$- identity matrix.  If $b$ was perfectly known, then $b - \hat b_0^{-1} = 0$ and the model error can be written as $\tilde a (x)= a(x) - \hat a_0(x)$. In particular, $\tilde a$ has lost its dependence on the control input. 



In this situation \cite{Chowdhary2013,ChowdharyCDC2013} propose to set 
the pseudo control as follows: $u'(x) :=  \nu_{r} + \nu_{pd} - \nu_{ad}$ where $\nu_{r} = f_{r}(\xi,r)$is a feed-forward reference term,  $\nu_{ad}$ is a yet to be defined output of a learning module \emph{adaptive element} and $\nu_{pd} = (K_1 \, K_2) e$ is a feedback error term designed to decrease the \textit{tracking error} $e(t) = \xi(t) - x(t)$ by defining $K_1,K_2 \in \Real^{m \times m}$ as in described in what is to follow.

Inserting these components, we see that the resulting \textit{error dynamics} are:
%
%
\begin{equation}\label{eq:errordynmrac}
	\dot e = \dot \xi - [x_2; \nu_r + \nu_{pd}+ \tilde a(x) ] = M e + B \bigl(\nu_{ad}(x) -  \tilde a(x)\bigr)
\end{equation}
%
%
where $M = \left(\begin{array}[h]{cc}
			O_m &  \, I_{m}\\
			-K_1 & -K_2 
					\end{array}\right)$ and $B = \left(\begin{array}[h]{c}
			O_m \\ I_m
					\end{array}\right)$.
If the feedback gain matrices $K_1,K_2$ parametrising $\nu_{pd}$ are chosen such that $M$ is stable then the error dynamics converge to zero as desired if the learning error $E_\lambda$ vanishes: $E_\lambda (x(t)) = \norm{\nu_{ad}(x(t)) - \tilde a(x(t))} \stackrel{t \to \infty} {\longrightarrow} 0$. 

It is assumed that the adaptive element is the output of a learning algorithm that is tasked to learn $\tilde a$ online. This is done by continuously feeding it training examples of the form $\bigl(x(t_i), \tilde a(x(t_i)) + \varepsilon_i\bigr)$ where $\varepsilon_i$ is observational noise.  

Intuitively, assuming the learning algorithm is suitable to learn target $\tilde a$ (i.e. $\tilde a$ is close to some element in the hypothesis space \cite{mitchellbook:97} of the learner) and that the controller manages to keep the visited state space bounded, the learning error (as a function of time $t$) should vanish.

Substituting different learning algorithms yields different adaptive controllers. \textit{RBFN-MRAC} \cite{Kim1998} utilises radial basis function neural networks for this purpose whereas \textit{GP-MRAC} 
employs Gaussian process learning \cite{GPbook:2006} to learn $\tilde a$ \cite{Chowdhary2013,ChowdharyCDC2013}. 

In what is to follow, we utilise our LACKI learning method as the adaptive element. Following the nomenclature of the previous methods we name the resulting adaptive controller \textit{LACKI-MRAC}.

\subsection{The wing rock control problem}
The wing rock dynamics control problem considers an aircraft in flight. Denoting $x_1$ to be the roll attitude (angle of the aircraft wings) and $x_2$ the roll rate (measured in angles per second), the controller can set the aileron control input $u$ to influence the state $x := [x_1;x_2]$.

Based on \cite{Monahemi1996}, Chowdhary et. al. \cite{Chowdhary2013,ChowdharyCDC2013} consider a second-order control-affine model of the wing rock dynamics as per  Eq. \ref{eq:secorddynctrlaff} 
where $b =3$ is a known constant and 
$a(x) = W_0^* + W_1^* x_1 + W_2^* x_2 + W_3^* \abs{x_1} x_2 + W_4^* \abs{x_2} x_2 + W^*_5 x_2^3$ is an priori unknown nonlinear drift. 



Note, the drift is non-smooth but, employing Lem. \ref{lem:Hoeldarithmetic}, it would be easy to derive a Lipschitz constant on any bounded subset of state space if the parameters $W := (W_0^*,\ldots, W_5^*)$ were known.

To control the system, we employ LACKI-MRAC as the adaptive element $\nu_{ad}$. Our simulations were computed on the basis of a first-order Euler approximation of the continuous-time dynamics
with a time increment step size of $\tinc = 0.1 [sec.]$

Our kinky inference learner was initialised with $L(0) =\underline L =p= 1$. The parameters $L(n)$ were  updated online following our lazy update method as per Eq. \ref{eq:lazyconstupdaterule_batch_main} with $\hestthresh = 0$. 

Since the point of learning-based and adaptive control is to be able to adapt to various settings, we test the controllers across a range of randomised problem settings, initial conditions and parameter settings.
We created 555 randomised test runs of the wingrock tracking problems and tested each algorithm on each one of them. The initial state $x(t_0)$ was drawn uniformly at random from $[0,7] \times [0,7]$, the initial kernel length scales were drawn uniformly at random from $[0.05,2]$, and used both for RBF-MRAC and GP-MRAC. The H\"older constant $L$ for the LACKI-MRAC was initialised at random from the same interval but allowed to be adapted as part of the online learning process. The parameter weights $W$ of the system dynamics specified above were multiplied by a constant drawn uniformly at random from the interval $[0,2]$. To allow for better predictive performance of GP-MRAC we doubled the maximal budget to 200 training examples. 
The feedback gains were chosen to be one, $K_1=K_2=1$. 

In addition to the three adaptive controllers we also tested the performance of a simple $PD$- controller with just these feedback gains (i.e. we executed x-MRAC with adaptive element $\nu_{ad}=0$). This served as a baseline comparison to highlight the benefits of the adaptive element over simple feedback control.

The performance of all controllers across these randomised trials is depicted in Fig. \ref{fig:wingrockresultsbp}. Each data point of each boxplot represent a performance measurement for one particular trial.


\begin{figure}
        \centering
				%  \subfigure[Results over 555 randomised examples.]{
    %\includegraphics[width = 3.7cm, height = 3cm]{content/figures/graph1_klein.eps}
   \includegraphics[width = 8cm, clip, trim = 1.5cm 8cm 1cm 7cm]
								%{content/Ch_kinkyinf/figs/resultswingrock_555trials}
								{content/Ch_kinkyinf/figs/wingrockbp}
   % \label{fig:wingrockresultsbp}
  %} 
   \caption{Performance of the different online controllers over a range of 555 trials with randomised parameter settings and initial conditions. 1: RBF-MRAC, 2: GP-MRAC, 3: LACKI-MRAC, 4: linear controller.  LACKI-MRAC outperforms all other methods with respect to all performance measures, except for prediction runtime (where the parametric learner RBF-MRAC performs best).} 
       \label{fig:wingrockresultsbp}
\end{figure}	  

 






	For each method, the figures show the boxplots of the following recorded quantities: 
	\begin{itemize}
		\item log-XERR: cummulative angular position error (log-deg), i.e. $\log(\int_{t_0}^{t_f} \norm{\xi_1(t) - x_1 (t)} \dt )$.
		\item log-XDOTERR:  cummulative roll rate error (log-deg/sec.), i.e. $\log(\int_{t_0}^{t_f} \norm{\xi_2(t) - x_2 (t)} \dt )$.
		\item log-PREDERR: log-prediction error. \\ That is,  $\log(\int_{t_0}^{t_f} \norm{\nu_{ad}(x(t)) - \tilde a(x(t))} \dt )$.
		\item log-CMD: cummulative control magnitude (log-scale), i.e. $\log(\int_{t_0}^{t_f} \norm{u(t)} \dt )$.
		\item log-max. RT(predictions): the log of the maximal runtime (within time span $[t_0,t_f]$) each method took to generate a prediction $\nu_{ad}$ within the time span.
		\item log-max. RT (learning): the log of the maximal runtime (within time span $[t_0,t_f]$) it took each method to incorporate a new training example of the drift $\tilde a$.
	\end{itemize}
	
	
	
%	\begin{wrapfigure}{r}{0.5\textwidth}
%  \begin{center}
%    \includegraphics[width=0.48\textwidth,clip, trim = 1.5cm 8cm 1cm 7cm]{content/Ch_kinkyinf/figs/wingrockbp}
%      \end{center}
%   \caption{Performance of the different online controllers over a range of 555 trials with randomised parameter settings and initial conditions. 1: RBF-MRAC, 2: GP-MRAC, 3: LACKI-MRAC, 4: linear controller.  LACKI-MRAC outperforms all other methods with respect to all performance measures, except for prediction runtime (where the parametric learner RBF-MRAC performs best).} 
%   	       \label{fig:wingrockresultsbp}
%\end{wrapfigure}	
	
	
	As can be seen from Fig. \ref{fig:wingrockresultsbp}, all three adaptive methods outperformed the simple $PD$- controller in terms of tracking error. 
	
	In terms of prediction runtime, the RBF-MRAC outperformed both GP-MRAC and LACKI-MRAC. This is hardly surprising. After all, RBF-MRAC is a parametric method with constant prediction time. By contrast, both non-parametric methods will have prediction times growing with the number of training examples.
That is, it would be the case if GP-MRAC were given an infinite training size budget. Indeed one might argue whether GP-MRAC, if operated with a finite budget, actually is a parametric approximation where the parameter consists of the hyper-parameters along with the fixed-size training data matrix $X$. When comparing the (maximum) prediction and learning runtimes one should also bear in mind that GP-MRAC predicted with up to 200 examples in the training data set. By contrast, LACKI-MRAC undiscerningly had incorporated all 10001 training points by the end of each trial.

Across the remaining metrics, LACKI-MRAC markedly outperformed all other methods.

Note, we have also attempted to test all methods across a greater range of problem settings, including larger initial states, more varied hyper-parameter settings, lower feedback gains and more varied choices of dynamics coefficients $W$. However, this resulted in GP-MRAC to often run into conditioning problems. This is a common issue in GP learning due to the necessity of matrix inversion or Cholesky decompositions of the covariance matrix. Similar behaviour ensued when setting the training size budget to large values. All these changes often resulted in long learning runtimes, spiky control outputs and thus, poor overall performance. Similarly, code execution of our RBF-MRAC implementation was frequently interrupted with error messages when the state was initialised to positions outside of the rectangle $[0,7] \times [0,7]$.

We have not investigated the root cause of these issues in greater detail yet. However, it might be worth exploring whether the great robustness of kinky inference might be an additional selling point that sets it apart from other recent adaptive control methods. Such robustness is of course important in control settings such as flight control where failure or erratic behaviour of the adaptive element may result in critical incidents. 
%
An example where GP-MRAC failed to track the reference occurred when repeating our first experiment  with the following modifications: The initial state was chosen to be $x(t_0) = (-90,40)^\top$ corresponding to a rapidly rotating aircraft. Furthermore, the wing rock coefficients $W$ were multiplied by a factor of $5$, amplifying the non-linearities of the drift field. 

When initialised with the length scale parameter of 0.3, the GP ran into conditioning problems and caused the output of the adaptive element in GP-MRAC to produce spikes of very large magnitude and to further destabilise the system. We tried the problem with various kernel length scale settings ranging from $0.3$ to $20$. Increasing the length scale parameter to length scale of at least 1 seemed to fix the conditioning problem. Nonetheless, the GP-MRAC still did not manage to learn and stabilise the system in any of these settings. A record of GP-MRAC's performance in this example (for length scale of 1) is depicted in  Fig. \ref{fig:gpfail} (top row). As the plots show, the GP starts with relatively high tracking and prediction error from which it cannot recover. At about 26 seconds into the simulation the state rapidly diverges.

 
\begin{figure*}
        \centering
				  \subfigure[Position (GP-MRAC).]{
    %\includegraphics[width = 3.7cm, height = 3cm]{content/figures/graph1_klein.eps}
    \includegraphics[width = 5cm, clip, trim = 3cm 9cm 3cm 9cm]
								%{content/Ch_kinkyinf/figs/resultswingrock_555trials}
								{content/Ch_kinkyinf/figs/gpfail1}
   % \label{fig:wingrockresultsbp}
  } 
					  \subfigure[Tracking error (GP-MRAC).]{
    %\includegraphics[width = 3.7cm, height = 3cm]{content/figures/graph1_klein.eps}
    \includegraphics[width = 5cm, clip, trim = 3cm 9cm 3cm 9cm]
								%{content/Ch_kinkyinf/figs/resultswingrock_555trials}
								{content/Ch_kinkyinf/figs/gpfail2}
   % \label{fig:wingrockresultsbp}
  } 
							  \subfigure[Log - prediction error (GP-MRAC).]{
    %\includegraphics[width = 3.7cm, height = 3cm]{content/figures/graph1_klein.eps}
    \includegraphics[scale =.34]
								%{content/Ch_kinkyinf/figs/resultswingrock_555trials}
								{content/Ch_kinkyinf/figs/gpfail_gpprederr}
   % \label{fig:wingrockresultsbp}
  } 
					  \subfigure[Position (LACKI-MRAC).]{
    %\includegraphics[width = 3.7cm, height = 3cm]{content/figures/graph1_klein.eps}
    \includegraphics[width = 5cm, clip, trim = 3cm 9cm 3cm 9cm]
								%{content/Ch_kinkyinf/figs/resultswingrock_555trials}
								{content/Ch_kinkyinf/figs/gpfail1_hfe}
   % \label{fig:wingrockresultsbp}
  } 
					  \subfigure[Tracking error (LACKI-MRAC).]{
    %\includegraphics[width = 3.7cm, height = 3cm]{content/figures/graph1_klein.eps}
    \includegraphics[width = 5cm, clip, trim = 3cm 9cm 3cm 9cm]
								%{content/Ch_kinkyinf/figs/resultswingrock_555trials}
								{content/Ch_kinkyinf/figs/gpfail2_hfe}
   % \label{fig:wingrockresultsbp}
  } 
%
					  \subfigure[Log - prediction error (LACKI-MRAC).]{
    %\includegraphics[width = 3.7cm, height = 3cm]{content/figures/graph1_klein.eps}
    \includegraphics[scale =.34]
								%{content/Ch_kinkyinf/figs/resultswingrock_555trials}
								{content/Ch_kinkyinf/figs/gpfail_hfeprederr}
   % \label{fig:wingrockresultsbp}
  } 
						  %\subfigure[State path (LACKI-MRAC).]{
    %%\includegraphics[width = 3.7cm, height = 3cm]{content/figures/graph1_klein.eps}
    %\includegraphics[width = 5cm, clip, trim = 2cm 9cm 1cm 7cm]
								%%{content/Ch_kinkyinf/figs/resultswingrock_555trials}
								%{content/Ch_kinkyinf/figs/gpfail_statepathHfe}
   %% \label{fig:wingrockresultsbp}
  %} 	
	%
   \caption{Example where GP-MRAC fails. By contrast, LACKI-MRAC manages to adapt and direct the system back to the desired trajectory.}
	\label{fig:gpfail}
\end{figure*}	 
%

For comparison, we also tried LACKI-MRAC on the same problem. Starting with initial $L(0) =\underline L =1$ as before. Starting out with a relatively large tracking and prediction error, LACKI-MRAC nonetheless managed to recover and successfully track the system (see  Fig. \ref{fig:gpfail}, bottom row). The state path and learned drift model obtained by LACKI-MRAC are depicted in Fig. \ref{fig:gpfail2}.

\begin{figure}
        \centering
				  \subfigure[State path (LACKI-MRAC).]{
    %\includegraphics[width = 3.7cm, height = 3cm]{content/figures/graph1_klein.eps}
    \includegraphics[width = 6cm, clip, trim = 3cm 9cm 3cm 9cm]
								%{content/Ch_kinkyinf/figs/resultswingrock_555trials}
								{content/Ch_kinkyinf/figs/gpfail_statepathHfe}
   % \label{fig:wingrockresultsbp}
  } 	\hspace{.5cm}
	  \subfigure[Learned drift model (LACKI-MRAC).]{
    %\includegraphics[width = 3.7cm, height = 3cm]{content/figures/graph1_klein.eps}
    \includegraphics[width = 6cm, clip, trim = 3cm 9cm 3cm 9cm]
								%{content/Ch_kinkyinf/figs/resultswingrock_555trials}
								{content/Ch_kinkyinf/figs/gpfail_hfelearnedmodel}
   % \label{fig:wingrockresultsbp}
  } 	
	%
   \caption{Depicted are the state path and the drift model learned online by LACKI-MRAC.}
	\label{fig:gpfail2}
\end{figure}	 
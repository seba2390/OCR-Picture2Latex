\section{What are the consequences of a media-driven intervention strategy?}
\label{sec:consequences}

\para{Overview.}
Thus far, our analysis has demonstrated that administrative interventions
for toxic content are largely driven by internal and media pressure. We now
seek to understand whether such reactionary administrative
intervention strategies are effective at curbing problematic activities (that
are associated with the target subreddit) across the platform. Our hypothesis
is that: \emph{(H2) Prior media attention on communities which receive
interventions for toxic content: (1) increases the prevalence of problematic
activity on the platform and (2) reduces the effectiveness of the issued
interventions.} We test this hypothesis using an interrupted time series
analysis to check whether community-specific increases in user growth rates
and platform-wide increases in problematic discourse (that is associated with
the intervened subreddit) occur as a consequence of the media pressure they
receive and the administrative intervention they are handed out. If
part (1) of this hypothesis is valid, it suggests that media attention
on a problematic community increases the prevalence of the problematic
discourse within the community and across the platform. If part (2) of this
hypothesis is valid, it suggests that media-driven interventions are less
effective at curbing the spread of problematic discourse across the platform
than their non-(media)impacted counterparts.

\subsection{Methods} \label{sec:consequences:methods}

\para{Tracking growth rates within an intervened subreddit.} For each of the
120 intervened subreddits in our dataset, we compute the monthly `growth' of
the community. 
This growth for a given month is computed by counting the number of unique
users that made their first contributions to the community during that month.
Put another way, this measures the number of new contributors to a community
each month. This metric is used to identify the impact that media coverage has
on intervened communities. Note that this metric cannot be used to identify the
impact of administrative interventions since the community itself becomes
inactive after the intervention.
We hypothesize that media attention results in an
increase in the growth rate of a community --- \ie more users begin directly
participating in the problematic discourse as a result of the media attention.

\para{Identifying and tracking problematic discourse of an intervened
community.} For our analysis, we seek to measure if the ``problematic
discourse'' of an intervened community begins to spread across the platform as 
a consequence of media attention and administrative interventions on the
community. This requires us to identify and track this problematic discourse.
We do this by using the vocabulary unique to the intervened subreddit as
a proxy for the problematic discourse occurring on it. By tracking the
prevalence of this unique vocabulary on other subreddits, we effectively
measure the adoption of the problematic vocabulary across the platform. We
derive the unique vocabulary associated with a community using the
\emph{Sparse Additive Generative Model (SAGE)} \cite{SAGE}. SAGE extracts
keywords that are unique to our intervened subreddit relative to a set
of reference subreddits (the default subreddits in our case). Using this
process, we extract the 500 most unique keywords for each intervened community
and manually confirming their relevance and specificity to the intervened
community. For example, (\textit{fakecel, truecel, zyrros, femoid...}) were the
extracted from \subreddit{Incels} and
(\textit{eyethespy, thankq, ibor...}) were extracted from
\subreddit{greatawakening}. 
We then count the frequency of occurrence of these keywords across
the remainder of the platform (\ie excluding the intervened subreddit itself)
for each month. 
We note that this approach has also been used in prior work measuring 
the spread of ideologies \cite{eshwar2017you}. 

\para{Identifying the effects of media coverage and administrative
interventions using interrupted time series analysis.} Interrupted time series
analysis test for any significant changes in the rate of a given variable after
an event of interest occurs. It models the time series prior to the event and
forecasts the time series after the event. If there is a statistically
significant difference in the forecasted and actual time series after the
event, the event is said to have an effect on the variable being tracked. We
run three interrupted time series analyses for each of our 120 intervened
communities: (1) for communities experiencing pre-intervention media attention,
using community growth rates as the variable and media attention as the event,
(2) for communities experiencing pre-intervention media attention, using the
growth in prevalence of intervened subreddit vocabulary on other subreddits as
the variable and media attention as the event, and (3) for all intervened
subreddits, using the prevalence of intervened subreddit vocabulary on other
subreddits as the variable and the administrative intervention as the event.
All together, these analyses will identify the impact of media attention on
problematic discourse and activity.

\para{Comparing the effectiveness of media-driven interventions with
interventions not impacted by media coverage.} Finally, we split our dataset of
120 intervened subreddits into those which generated media pressure (treatment)
and those that did not (control). We then compare the effects of administrative
interventions on these two groups with a focus on the percentage increase in
occurrences of their vocabulary on other subreddits. A statistically
significant difference in this variable between the two groups would suggest
the possibility that media-driven interventions are less effective at curbing
the spread of problematic discourse and ideologies.


% In this section we measure the effect of media advertisement and reactive
% intervention on the spread of dangerous ideologies. First, we perform automatic
% keyword analysis to construct community vocabulary unique to and representative
% of each intervened community. Next, we group communities discussing similar
% topics based on the similarity of the vocabulary resulting in X different
% topics. Finally, we perform interrupted time series analysis to test whether
% media advertisement and/or reactive intervention leads to increase in the
% spread of dangerous topics.
% 
% \subsection{Constructing community vocabulary}
% First, for each of the intervened subreddits, we obtain the keywords
% representing their discourse. Our aim is to identify keywords that are
% pertinent to the discourse in the community. The eventual goal of these
% keywords is to identify instances of discourse outside the intervened
% community. To obtain these keywords, as used in previous studies tracking
% communities and discussion on reddit, we perform automatic keyword detection
% using the \textit{Sparse Additive Generative Model (SAGE)}. We use SAGE to
% extract community keywords from intervened community by first constructing
% a base vocabulary from keywords occurring in our base communities made up of
% default subreddits. Next, we compute the difference of vocabulary between each
% intervened community and the base subreddits. This gives us keywords in order
% of their uniqueness to their presence intervened community. We collect 500 most
% unique keywords for each of the community to construct their community
% vocabulary. We manually validate the keywords representation of the community
% discourse by sampling 20 keywords for each community and confirming their
% relevance. \note{todo add table}
% 
% \subsection{Tracking growth and discussion}
% For each of the intervened community, we measure the influx of unique users
% each month. We compute the first order difference of this time-series to
% compute the monthly growth rate of unique users. This enables us to measure the
% internal growth of the community representing the acceptance of ideology. Next,
% given the keywords from the community vocabulary of each of the intervened
% community, we track the occurrences of these keywords on posts and comments
% outside the intervened community from 01/2015 to 04/2020. This provides us with
% the metric of attention/spread of the topic on Reddit for each month
% represented as the adoption of community vocabulary outside the community. We
% compute the first order difference of the external adoption of community
% vocabulary to give us the growth rate of external adoption of community
% vocabulary.  
% 
% \subsection{Identifying Issues}
% Next, to verify whether media advertisement and reactive intervention increase
% the spread of dangerous ideologies. We group the communities based on the topic
% of their discussion. We first identify 5 central communities for each topic.
% These central communities are: \subreddit{Incels}, \subreddit{The\_Donald},
% \subreddit{proED}, \subreddit{greatawakening}, \subreddit{FULLCOMMUNISIM},
% \subreddit{GenderCritical}, \subreddit{whitebeauty} and \subreddit{AbusePorn2}.
% We construct a group of subreddit around each central community, this group
% contains subreddits sharing similar topic of discourse. After identifying these
% 8 central communities representing a single topic, we perform intersection of
% the keywords from these central communities to each of the community. If
% a community shares more than 20\% of its keyword with the central community we
% consider the intervened community as the part of that group. We present these
% topics and their communities in \note{add table.} \note{we will add a table
% showing each of the the group, the central subreddit, the similar subreddits in
% it, the topic of discussion and a sample of keywords.} A single topic, such as
% the Incel philosophy has multiple communities on Reddit ranging from
% \subreddit{Incels}, \subreddit{Braincels} and \subreddit{shortcels}. These
% communities are part of a bigger subculture labeled the \textit{Manosphere} by
% researchers. We construct these groups using the community vocabulary
% constructed in \note{ref part 1}.
% 
% 
% \subsection{Interrupted Time Analysis}
% To measure any significant positive change in the acceptance and growth of the
% community, we perform interrupted time series analysis (ITS). Interrupted time
% series analysis tests for any significant changes in the rate of the time
% series after an intervention. ITS models the time series prior to an
% intervention and forecasts the time series post intervention. If there is
% a significant difference in predicted and actual time series post intervention,
% the intervention is considered to have a significant effect on the time series.
% 
% 
% \para{Media}
% In this analysis, we measure the advertising effect of media on the dangrous
% communtiies. We perform the interrupted time analysis with the first negative
% media attention received by the subreddit as the intervention and observe
% whether this it had any effect on the 1) growth rate of the community itself
% and 2) growth of external adoption of community vocabulary representing the
% spread of the discourse externally. We hypothesize, media's attention towards
% toxic commnunities leads 1) increased awareness of the community and therefore
% an increase in the growth rate of users in the community and 2) increased
% growth rate of external adoption of community vocabulary.
% 
% \para{Intervention}
% In this analysis, we measure the effectiveness of interventions in quelling the
% dangerous discourse. We hypothesize performing reactive moderation on dangerous
% subreddits do not effectively deplatform the dangerous ideologies. We perform
% interrupted time series analysis on the spread of discourse outside the
% intervened community with the banning/quarnatining as the intervention point.
% 
% The results of our study have thus far shown that Reddit appears to perform
% administrative bans in reaction to negative attention from the media
% (\Cref{sec:h1}) and this may result in inconsistent application of their
% anti-toxicity content policy due to the inconsistent coverage of toxicity by
% the media (\Cref{sec:h2}). In this section, we seek to understand whether bans
% that occur due to such reactionary strategies are effective at curbing related
% toxicity on Reddit. Specifically, we analyze the effectiveness of the
% reactionary ban interventions to curb the dangerous discourse. At a high-level,
% we use an interrupted time series analysis to check whether the discourse
% surrounding these issues discussed in the banned communities was quelled as
% a consequence of the ban intervention. Our results show, for most of the cases,
% that the discourse around these problematic ideologies continued to grow on
% Reddit even after the intervention was applied suggesting the reactionary
% intervention to be ineffective.  
% As platforms fail to minimize the reach of such dangerous ideas, in an attempt
% to criticize the platform and their lack of policiing, the mainstream media and
% online users can inadvertently bring these dangerous ideologies to the
% mainstream discourse. Social media platforms and laws governing the content
% moderation on these platforms such as Section 230 are based on the theory of
% marketplace of ideas and free speech suggest no speech shall be censored and
% only be countered by more speech. The theory suggests the population would
% reach the truth eventually and dangerous ideas would die themselves. Therefore,
% bringing new ideas (even dangerous ideas) to a wider audience in an open and
% free society capable of critical thinking and debate should not experience
% significant negative effect and would eventually eliminate dangerous
% ideologies. However, as established by numerous previous studies, these ideas
% fails in an online society driven by algorithmic personalization and filter
% bubbles. Rather than exposing dangerous ideas to everyone, platform designs
% (intentionally or not) tend to target vulnerable individuals with these ideas
% resulting in drastic consequences.
% 
% % TODO: citations
% 
% In the previous section, we highlighted Reddit’s reactionary moderation driven
% by media pressure to close communities. We also revealed media pressure is not
% consistently driven by toxicity. These results altogether show Reddit’s
% moderation strategies are reactive and inconsistent in the cases of moderating
% toxic communities. The banned communities we observe in our analysis include
% subreddits with discourse on socio-political issues and topics such as
% anti-feminism, white supremacy, conspiracies, and anti-LGBTQ. Most of these
% communities represented the biggest online headquarters for such ideologies and
% aided in its spread in the mainstream. Therefore, timely and effective
% interventions of these communities are crucial to curb dangerous ideologies. In
% this section we aim to measure the mainstream media’s inadvertent publicizing
% of dangerous ideologies and the effectiveness of Reddit’s reactive and
% inconsistent interventions. We measure the change in acceptance and ubiquity of
% these ideologies inside and outside these communities after their closure and
% media’s initial mention.
% 
% 
% %We design experiments to determine whether the negative attention from any of
% %the three sources is `advertising’ the violating community. We measure the
% %effect of negative attention has on the activity of the community before it is
% %closed by Reddit. In this analysis we represent activity in two forms: total
% %amount of content posted on the community and number of incoming users.
% %Representing activity as number of incoming users reveals the reach the
% %negative attention has in compelling uses to join. The total amount of content
% %posted on the community represents increase in activity by new and existing
% %users towards the ideology contained in the community. We hypothesize negative
% %attention to have a positive effect on both of these variables. If there is
% %a significant increase in activity in the form of total content posted or
% %incoming users during and after the negative attention is given to the
% %community we can conclude negative attention effectively advertises the
% %community before the intervention. 
% 
% %Next we explore the effects of negative attention on the ideology outside of
% %the community after the intervention. We track discussion around selected
% %ideologies and analyze their growth after the community they were hosted in
% %are banned. For our analysis we select two of the recent issues to track: the
% %incel culture and the QAnon conspiracy. These issues either started on Reddit
% %or had their biggest community on Reddit. In this section we measure the
% %effect of media-driven interventions on the popularity of the ideology. We
% %look at how the influx of users changed as more negative attention was brought
% %to the subreddit. Finally, we measure the activity around the incel ideology
% %after the media-driven ban of the community.  
% 
% \section{Methods}


\subsection{Analysis and results}

\para{Overview of analyses.} To test our hypothesis ($H2$), we conduct three
different analyses with each testing the impact of media pressure and
interventions on subreddit growth and spread of problematic discourse.

% Our results in this section confirm 1) media attention, in some cases, results
% in growth of dangerous communities and the normalization of the dangerous
% ideologies outside the community and 2) (reactive) interventions are not
% effective in deplatforming the dangerous discourse from Reddit. 
% 
% \subsection{Media}
% 
% \subsubsection{Growth}
% \subsubsection{Spread}
% 

\para{Analysis 1: For toxic communities, what is the impact of negative media
attention on subreddit growth?} We now focus on the subset of our intervened
subreddits which received negative media attention prior to their
administrative intervention for toxic content --- 43 in total. We conduct an
interrupted time series analysis to test whether there was anomalous community
growth (quantified by the rate of new creators joining the community) after the
first time they received media attention. Across all 43 intervened  subreddits
with prior media attention, we see that 28 had statistically significant
increases in user growth after the first time they received media attention.
The average growth observed was 439\%. Despite these alarming increases, the
impact of media attention appears disparate for different communities --- \eg
\subreddit{greatawakening} grew 4174\% while \subreddit{Mr\_Trump} only grew
42\% (both are statistically significant from our interrupted time series
analysis). Grouping the subreddits by their topics, we see patterns emerge ---
groups that received the most negative media  attention (subreddits in the
manosphere, qanon, and extremist ideology categories) also had the largest
growth rates from negative media attention. A subset of these results, grouped
by `subreddit topic' are reported in \Cref{table:consequences:results} in the
\emph{User growth (post-media)} column. Our findings provide
evidence that negative media attention increases the growth rate for toxic
communities. 


\para{Analysis 2: For toxic communities, what is the impact of negative media
attention on the spread of problematic community vocabulary?} Once again we 
focus on the 43 intervened subreddits which received negative media attention
prior to their interventions. We use an interrupted time series analysis to
test whether the vocabulary of problematic subreddits is more commonly adopted
across the platform after the first time they received media attention. The
interrupted time series analysis returns statistically significant results if,
given prior data, the growth of usage of the vocabulary on other subreddits is
anomalous after the first media attention. We find that 20 of our 43 subreddits
recorded statistically significant changes in the adoption of their
vocabulary across the platform. The average increase across all 43 subreddits
was 128\%. Once again, we find that the effects are disparate across
communities -- \eg \subreddit{shortcels} experienced an increase of 1270\%
while \subreddit{Mr\_Trump} experienced a decrease of 79\%. Specifically
analyzing subreddits by their category, we find that only subreddits in the
`manosphere' experienced a consistent and significant increase in their
vocabulary adoption rates after the first time they received media attention.
A subset of these results are reported in the \emph{Voc. growth (post-media)}
column in \Cref{table:consequences:results}. Our findings show that
media attention results in increased adoption of an toxic
community's vocabulary across the platform.


\para{Analysis 3: What is the impact of administrative interventions on the
spread of problematic community vocabulary?} We use an interrupted time series
analysis to test whether the growth in usage vocabulary of a problematic
subreddit across the platform varies depending on whether the subreddit
received media attention or not. On average, across all 120 intervened
subreddits we find that 52 subreddits had a statistically significant change in
vocabulary adoption across the platform. Of these, 26 had received media
attention prior to the intervention and 26 had not. The average increase
observed in the subreddits that received media attention was 321\% and
348\% for those that did not. We note that the difference between the two
groups was not found to be statistically significant. Breaking down our results
by subreddit topic, we find that subreddits in the manosphere were once again
found to have their vocabulary consistently adopted across Reddit even after
the intervention. This breakdown is illustrated in the \emph{Voc. growth
(post-int.)} column in \Cref{table:consequences:results}. Our findings show
that subreddits which receive interventions content see their
vocabulary being adopted across the platform after an intervention, regardless
of whether they received prior media attention or not. 


%\para{Analysis 4: Does media attention prior to an intervention reduce the
%effectiveness of the intervention?}

\para{Takeaways.} We validated one of our hypotheses
($H2(1)$) that media attention on problematic communities increases the
user growth rate in the community itself and increases the adoption of the
community's vocabulary across the platform. Our findings were unable to
validate our second hypothesis ($H2(2)$) that prior media attention on
problematic communities reduced the effectiveness of administrative
interventions. All together, our study allows us to conclude that media
attention on a problematic community does lead to an increase in problematic
activity within and outside the community itself. However, reactionary
administrative interventions do not appear to have a significantly different
impact on the communities which receive media attention.


% Out of the 120 banned communities, 45 communities get negative media attention
% before their intervention. Performing interrupted time series analysis on the
% spread of dangerous discourse before and after the initial negative media
% attention towards a community shows, for some groups of communities, this
% attention can spread the dangerous discourse out from the community by either
% the inception of new communities or normalization of discourse in existing
% communities. Looking at the topic groups we observe communities related to
% \textit{Porn} and \textit{Eating disorders} are not influenced by media
% attention with none of the communities in the group experiencing an increase in
% their community vocabulary externally. Our results show, 100\% communities in
% \textit{Mansophere} topic experience a significant increase in growth rate,
% 385\% on average, after their initial media pressure. Next, 14\% (3
% communtiies) of the right-wing subreddits show significant  increase in the
% discourse externally. We observe the central community in right-wing
% \subreddit{The\_Donald} not experiencing any change in external influence after
% the initial media attention. Furthermore, we observe \subreddit{Mr\_Trump}
% discourse significantly decreasing (by 79\%) after the initial media attention.
% Finally, we observe no significant increase in external adoption of
% \textit{QAnon} vocabulary after their ban. \note{todo: add result table.} 
% 
% \subsection{Intervention}
% Performing interrupted analysis to identify the effectiveness of intervention
% to deplatform dangerous discourse shows interventions are more likely to
% increase the spread externally than media attention. Out of all of the
% intervened communities, 53 experience an increase in discourse externally.
% Looking at our groups we observe all communities from \textit{Mansophere} and
% \textit{Eating Disorders} experience significant increase (317\% and 380\%
% respectively). Next, we test whether subreddits which experienced media
% attention and therefore a reactive intervention exhibit more likelihood of
% spreading externally. Our result shows subreddits with no initial media
% attention are equally likely to spread their discourse externally after an
% intervention as subreddit with some initial negative media attention. However,
% we observe for subreddits which experienced media attention and exhibit
% significant increase in external spread after an intervention have a positive
% correlation (0.46) between the length of time between the first media attention
% and intervention and \% increase of spread after ban. Next, our analysis on
% measuring the effect of amount of media mentions on the external adoption of
% community vocabulary shows a correlation of 0.2.
% 
% 
% \subsection{Case Study: Mansophere}
% Started in a fringe community, \textit{Incel} is the philosophy of involuntary
% celibacy mainly adopted by young male individuals who consider themselves
% unable to attract women and therefore involuntary celibate. Over the years,
% Incel communities have become toxic and misogynistic even resulting in violent
% outbursts including around 11 mass shootings in US by self-identified Incels.
% Reddit has played a significant role in nurturing this ideology by hosting one
% of its biggest community \subreddit{incels} on its platform. \subreddit{Incels}
% was banned in November 2017 after an update in Reddit’s policy. However, since
% then similar communities have been created to take the place of
% \subreddit{Incels}, these include communities such as \subreddit{Braincels}. In
% this section we perform qualitative analysis on the Incel subculture. We study
% the influence of these communities after their intervention and after the
% attention given to them by media. 
% 
% \para{Media advertisement}
% The first community related to the incel philosophy was \subreddit{Incels}.
% Reddit faced first criticism against \subreddit{Incels} on 10/2017. A month
% after, Reddit updated its policy and banned \subreddit{Incels} on 11/2017.
% Apart from this, \subreddit{Incels} had faced significant amount of internal
% pressure along with external pressure in form of petitions to close the
% subreddit. In this section, we aim to measure whether the media pressure caused
% the subreddit to gain new users and posters. Our results show \note{add
% results.}. Following the ban on 11/2017, we observe the community keywords
% experience a widespread significant increase on other communities. The second
% biggest incel community, \subreddit{Braincels}, was created before
% \subreddit{Incels}. It quickly grew to beacome the biggest incel community
% after the \subreddit{Incels} ban. Users from \subreddit{Incels} migrated to
% \subreddit{Braincels} and continued their discourse here. This migration of
% users and therefore the unsuccessful ban of \subreddit{Incels} resulted in even
% more negative media attention towards Reddit to close the incel communities
% especially \subreddit{Braincels}. Looking at the media’s effect on
% \subreddit{Braincels} growth we observe a significant increase in users
% internally and discourse externally (392\%). The negative media attention
% towards \subreddit{Braincels} resulted in advertisement and normalization of
% the incel culture. Finally after its quarantine (X months after the first media
% attention) and ban (X months after the first media mentions), we observe, yet
% again, significant increase in incel culture on the platform possibly from
% users migrating to other incel communities.  
% 

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}
\begin{table}[]
\resizebox{\columnwidth}{!}{%
\begin{tabular}{cllll}
\toprule
\multicolumn{1}{l}{\textbf{Topic}} &
  \textbf{Communities} &
  \textbf{\begin{tabular}[c]{@{}l@{}}User growth\\(post-media)\end{tabular}} &
    \textbf{\begin{tabular}[c]{@{}l@{}}Voc. growth\\(post-media)\end{tabular}} &
      \textbf{\begin{tabular}[c]{@{}l@{}}Voc. growth\\(post-int.)\end{tabular}}  \\ \hline \\ [-1.5ex] 
\multirow{8}{*}{\rotatebox[origin=c]{90}{\textbf{Manosphere}}}
				     & \text{Incels}      & \textbf{+512\%}  & \textbf{+216\%}  & \textbf{+205\%}  \\
                                     & \text{Braincels}             & \textbf{+1647\%} & \textbf{+231\%}  & \textbf{+228\%}  \\
                                     & \text{shortcels}             & -100\%           & \textbf{+1270\%} & \textbf{+1259\%} \\
                                     & \text{TheRedPill}            & \textbf{+32\%}   & \textbf{+219\%}  & \textbf{+250\%}  \\
                                     & \text{MGTOW}                 & \textbf{+212\%}  & \textbf{+213\%}  & \textbf{+473\%}  \\
                                     & \text{JustBeWhite}           & \textbf{-}       & \textbf{-}       & \textbf{+217\%}  \\
                                     & \text{milliondollarextreme}  & \textbf{-}       & \textbf{+283\%}  & \textbf{+283\%}  \\
                                     & \text{CringeAnarchy}         & \textbf{+124\%}  & \textbf{+94\%}   & \textbf{+131\%}  \\ [-1.5ex] \\ \hline \\ [-1.5ex]
\multirow{8}{*}{\rotatebox[origin=c]{90}{\textbf{QAnon}}}
				     & \text{greatawakening} & \textbf{+4174\%} & \textbf{-29\%}   & +46\%            \\
                                     & \text{TheCalmBeforeTheStorm} & \textbf{-}       & -                & -2\%             \\
                                     & \text{uncensorednews}        & \textbf{+285\%}  & \textbf{-59\%}   & \textbf{-7\%}    \\
                                     & \text{TheNewRight}           & \textbf{+56\%}   & +11\%            & +43\%            \\
				     & \text{The\_Donald}           & \textbf{+524\%}  & \textbf{+124\%}  & +46\%            \\
                                     & \text{Right\_Wing\_Politics} & \textbf{+401\%}  & +44\%            & +73\%            \\
                                     & \text{new\_right}            & \textbf{+401\%}  & -92\%            & +23\%            \\
                                     & \text{Mr\_Trump}             & \textbf{+42\%}   & \textbf{-79\%}   & \textbf{+284\%}  \\ [-1.5ex] \\ \hline \\ [-1.5ex]
% \multirow{5}{*}{\rotatebox[origin=c]{90}{\textbf{Eating disorders}}}
%                                      & \text{proED}        & -                & -                & \textbf{+279\%}  \\
%                                      & \text{EDFood}                & -                & -                & \textbf{+378\%}  \\
%                                      & \text{ProEDmemes}            & -                & -                & \textbf{+217\%}  \\
%                                      & \text{thinspo}               & -                & -                & \textbf{+428\%}  \\
%                                      & \text{Amberlynn}             & \textbf{-}       & \textbf{-}       & \textbf{+616\%}  \\ [-1.5ex] \\ \hline \\ [-1.5ex]
\multirow{25}{*}{\rotatebox[origin=c]{90}{\textbf{Extremist groups}}}
				     & \text{The\_Donald} & \textbf{+524\%}  & \textbf{+124\%}  & +46\%            \\
                                     & \text{TheNewRight}           & \textbf{+56\%}   & +11\%            & +43\%            \\
                                     & \text{DebateAltRight}        & -                & -                & +125\%           \\
                                     & \text{WhiteRights}           & \textbf{+40\%}   & -45\%            & \textbf{+32\%}   \\
                                     & \text{Mr\_Trump}             & \textbf{+42\%}   & \textbf{-79\%}   & \textbf{+284\%}  \\
                                     & \text{Physical\_Removal}     & \textbf{+412\%}  & -32\%            & -68\%            \\
                                     & \text{Right\_Wing\_Politics} & \textbf{+401\%}  & +44\%            & +73\%            \\
                                     & \text{RightwingLGBT}         & \textbf{+562\%}  & +22\%            & +102\%           \\
				     & \text{european}              & -                & -                & \textbf{+312\%}  \\
                                     & \text{SargonofAkkad}         & -                & -                & -6\%             \\
                                     & \text{SubforWhitePeopleOnly} & -                & -                & +53\%            \\
                                     & \text{TheCalmBeforeTheStorm} & -                & -                & -2\%             \\
                                     & \text{ImGoingToHellForThis}  & -                & -                & \textbf{+577\%}  \\
				     & \text{CringeAnarchy}         & \textbf{+124\%}  & \textbf{+94\%}   & \textbf{+131\%}  \\
                                     & \text{The\_Europe}           & +15\%            & -41\%            & +45\%            \\
				     & \text{uncensorednews}        & \textbf{+285\%}  & \textbf{-59\%}   & \textbf{-7\%}    \\
                                     & \text{altright}              & -                & -                & -29\%            \\
                                     & \text{antifa}                & -                & -                & +182\%           \\
                                     & \text{europeannationalism}   & \textbf{+130\%}  & \textbf{-41\%}   & \textbf{+15\%}   \\
				     & \text{greatawakening}        & \textbf{+4174\%} & \textbf{-29\%}   & +46\%            \\
                                     & \text{milliondollarextreme}  & \textbf{-}       & \textbf{+283\%}  & \textbf{+283\%}  \\
                                     & \text{new\_right}            & \textbf{+401\%}  & -92\%            & +23\%            \\
                                     & \text{smuggies}              & -                & -                & \textbf{+25\%}   \\
                                     & \text{toosoon}               & -                & -                & +115\%           \\
                                     & \text{ChapoTrapHouse}        & \textbf{+563\%}  & \textbf{+177\%}  & \textbf{+3\%}    \\
                                     & \text{whitebeauty}           & -51\%            & +111\%           & \textbf{+137\%}  \\ [-1.5ex] \\ \hline \\ [-1.5ex]
% \multirow{5}{*}{\rotatebox[origin=c]{90}{\textbf{Porn}}}
% 				     & \text{AbusePorn2} $\dagger$  & -                & -                & +26\%            \\
%                                      & \text{Misogynyfetish}        & -                & -                & +42\%            \\
%                                      & \text{RapeFantasy}           & -                & -                & -34\%            \\
%                                      & \text{StruggleFucking}       & -                & -                & -29\%            \\
%                                      & \text{fuckmeat}              & -                & -                & -26\%	     \\ [-1.5ex] \\ \hline \\ [-1.5ex]
\multirow{1}{*}{\rotatebox[origin=c]{90}{\textbf{}}}
%				     & \text{Other Subreddits}      & +48\%  (12/22 sig.) & +191\%  (7/22 sig.)          & +379\%  (30/78 sig.)          \\
				     & \textbf{Average}    & +439\% (28*) & +128\%  (20*)             & +321\%  (52*)  \\
\bottomrule
\end{tabular}%
}
\caption{\label{tab:h2-results} (Partial) Results for impact of media attention
and interventions on user growth and vocabulary adoption rate. \textbf{Bold}
values denote a statistically significant
difference in the forecasted and actual time series (p < 0.05).
Subreddits are grouped by their manually assigned category. Values in brackets
in the {\bf Average} row denote the number of statistically significant
changes.} 
\label{table:consequences:results}
\end{table}



% \subsection{discussion}
% Our results along with previous works on the effectiveness of moderation
% highlight the flaws in the current moderation strategies of platforms
% (specifically Reddit). In our first section we demonstrate how Reddit is
% reluctant towards closing communities unless enough internal or media
% pressure is present. Furthermore, Reddit's administrative decisions towards
% toxicity is dependent upon the popularity of the community as well where
% popular communities do no experience the same treatment (intervention) as
% smaller ones. Moderation is one of the key commodities that a social media
% platform offers, however our results show current moderation techniques built
% 1) without any legal pressure (Section 230) 2) to intervene and discourage
% profitable behavior 3) by the capitalist social media sites where their value
% is driven by number of active users are failing to effectively create an open
% and safe platform. In our results we focus on the single case study of the
% Incel community which originated and spread from online fringe communities,
% eventually resulting in violent outbursts and terrorism. We observe how
% media's effort to pressure Reddit in closing these communities only aided in
% the normalization and mainstreaming of such ideologies furthermore, Reddit's
% effort to close these communities were futile due to user migration to other
% subreddits. Our results show the spread of dangerous ideologies by media
% mentions does not significantly effect the period after intervention but we
% see clear growth of users in the community after media attention. 

\section{Introduction}
\label{sec:introduction}

%\para{Why media attention and platform moderation may be related.}
Strict platform moderation is rarely a first-order priority for newly developed
online platforms. After all, the early adopters are often homogenous with
a shared goal of nurturing the community. However, as platforms become more
mainstream and contend with a large and consistent influx of new users, each
with their own ideals and agendas, effective and timely platform moderation
becomes paramount to maintaining a civil community. Despite the absence of any
legal consequences for not effectively moderating platforms, effective
moderation is often tied to another goal of the platform -- avoiding negative
media attention so that the platform remains appealing to advertisers who
ultimately are their primary revenue source. Complicating matters, as
economically rational actors, platforms need to also account for the loss in
users and popularity as a result of platform-wide moderation decisions. This
suggests that the effectiveness of moderation on platforms might be tied to the
media's coverage of their failures as well as the costs of moderation decisions
on platform activity. The research presented in this paper investigates these
relationships on Reddit. 

\para{Reddit's history with media-driven moderation decisions.}
The story of platform moderation on Reddit appears similar to the evolutionary
trend described above. In its early days, Reddit was celebrated as the bastion
of free speech due to its minimal moderation and interference. However, as its
popularity grew over the years it found itself being criticized by outsiders
and the media for its lack of effective moderation. There have been numerous
examples of Reddit's moderation decisions being driven by media pressure
including \subreddit{The\_Donald} which was only shutdown after widespread
reporting in the media for the violent and incivil political discourse it
facilitated, \subreddit{TheFappening} which was shutdown only after reports of
its role as the facilitator in the distribution of involuntary pornography
involving celebrities, \subreddit{CoonTown} which was not banned during
Reddit's first purge of `hateful' subreddits until criticism from mainstream
media outlets \cite{Moyer-WaPo2015}, and most notably -- \subreddit{jailbait}.
The \subreddit{jailbait} subreddit was one of the earliest cases of Reddit
moderation being performed only in reaction to media attention
\cite{centivany2016values}. The subreddit featured provocative pictures of
minors and due to the lack of any rules against it, Reddit condoned its
existence even awarding it the \textit{voted best subreddit of 2008}
\cite{Chen-Jailbait2012}. In September 2011, in a segment on his show,
Anderson Cooper of CNN brought \subreddit{jailbait} to wider attention heavily
criticizing Reddit on hosting such content. Following more negative attention,
the subreddit was finally banned by administrators in October 2011. This
extremely delayed intervention led many, including the creator of the
subreddit, to speculate that the closing of the subreddit was only direct
response to the negative attention \cite{Tufekci-CITP2012}.
This speculation was further validated by the lack of administrative action
against other `bait'-type subreddits such as \subreddit{asianjailbait}. Taken
together, these anecdotes suggest that media pressure does impact Reddit's
moderation decisions. The extent of this impact is the subject of this
research.


% Since its inception, Reddit has updated and enforced its content policy numerous
% times, even in the face of loss and despite the lack of any legal obligation.
% New platforms rarely develop or enforce their content policy: having homogenous
% users with a shared goal of nurturing the community there is little need for
% moderation. As platforms grow, however, they harbor diverse sets of users
% including users with anti-social behavior. For the sake of maintaining a civil
% community platforms then need to develop rules and perform moderation. Alongside
% to maintaining a civil community, moderation is required for another reason.
% Newer platforms are hidden from the scrutiny and attention of mainstream media
% and users. As the platform's popularity reaches a wider audience, the need to
% showcase a favorable side to the mainstream increases, thus requiring some form
% of policing. Following this pattern, Reddit, since its early days has been
% celebrated as the bastion of free speech due to its minimal moderation and
% interference. However, as Reddit’s popularity grew over the years it found
% itself being criticized by outsiders and media for its lack of policing.
% Reddit's subsequent administrative actions appeared to be influenced by negative
% coverage and pressure from its users and media. These administrative actions
% often came at Reddit's own 1) user loss, for example the closing of its second
% most popular subreddit \subreddit{The\_Donald} after much deliberation from the
% media and user, and 2) financial loss, for example, the closing of one of its
% most profitable subreddit \subreddit{TheFappening} after much public ethical
% debate surrounding its existence. These along with other similar instances of
% administrative actions suggest Reddit employs reactive moderation strategies
% driven by negative attention and media pressure.
% 
% One of the first cases of Reddit reacting to negative media attention was the
% closing of a \subreddit{jailbait} \cite{centivany2016values}. The subreddit
% featured provocative pictures of minors and due to the lack of any rules against
% it, Reddit condoned its existence even awarding it the \textit{voted best
% subreddit of 2008}. In September 2011, in a segment on his show, Anderson Cooper
% of CNN brought \subreddit{jailbait} to wider attention heavily criticizing
% Reddit on hosting such content. Multiple other negative attention followed which
% were followed by the closure of the subreddit in October 2011. Many, including
% the creator of the subreddit, speculate the closing of the subreddit was only
% direct response to the negative attention, this was made more evident by the
% lack of adminitstrative against other `bait’ type subreddits such as
% \subreddit{asianjailbait} and \subreddit{malejailbait}. In figure 1, we show
% similar cases of policy updates speculated to be a response towards negative
% attention from the mainstream media.
% \note{Think of policy violating subreddit}.
% 
% \begin{figure*}
% \centering
% \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{figures/policy-updates.pdf}
% \caption{Content policy updates by Reddit administration as a reaction to negative media coverage.}
% \end{figure*}
% 

\para{The consequences of media-driven moderation.} Aid from the media, users,
and outsiders helps platforms conduct effective moderation. By bringing
attention to egregious content and highlighting gaps in its policies, such
attention can help platforms perform difficult administrative actions and
evolve their content policy. However, over reliance on the media for moderation
may lead to several problems including: inconsistent enforcement of policies
owing to the medias own inconsistent coverage of problematic content, delayed
moderation decisions due to the fact that action is taken only after
a violation is egregious enough to warrant coverage by the media, and finally
the normalization of problematic behaviours since media coverage may only focus
on the egregious violations while ignoring the problematic behaviours leading
up to it. Our work seeks to uncover whether these consequences are also
experienced by Reddit.

 % insights can lead to inconsistent moderation since the attention is
 % disproportionately brought to only extreme cases of obvious and known
 % anti-social behavior. Furthermore, such reliance can also bring extreme or
 % dangerous ideas to the mainstream and thus potentially normalizing such
 % ideologies.
 % 
 % \parait{Moderation decisions are not timely.} Foremost, administrative actions
 % as a response towards negative attention usually come delayed and only towards
 % extreme cases, leading to inconsistent and ineffective moderation. Widespread
 % attention highlight cases where the hosting platform has failed to effectively
 % interfere or allowed problematic content for some time. Reliance on such
 % negative attention causes inconsistent and delayed administrative actions. Such
 % inconsistencies in policing and the lack of transparency make the policies and
 % rules ineffective.
 % 
 % \parait{Problematic content is normalized.}
 % Secondly, mainstream medias interference in policing problematic content can
 % inadvertently bring wider attention dangerous fringe ideologies. Bringing these
 % ideologies to the wider attention ends up legitimizing them. An example of such
 % a case is the QAnon conspiracy, originating from fringe communities in platforms
 % with minimal moderation, QAnon found mainstream news attention which pushed the
 % conspiracy further into mainstream politics and discussion. Furthermore,
 % following Anderson Cooper's segment on \subreddit{jailbait}, the subreddit
 % experienced a significant increase in traffic. Administrative actions driven by
 % mainstream attention can lead to normalization of harmful ideologies and
 % behavior and can bring them to wider attention, in turn making the administrative
 % action ineffective. 
 % 
 % In conclusion we highlighted how Reddit, despite the lack of legal obligations
 % due to Section 230, has performed many administrative actions, some even at face
 % of loss. We suggest Reddit’s administrative actions are influenced by negative
 % attention which makes them only reactive to such attention. Finally we state how
 % reliance on reactive moderation strategies are inconsistent and can normalize
 % harmful ideology. In the next section, we outline the hypotheses that we test in
 % this work. First, we hypothesize \textbf{the administrative actions taken by
 % Reddit come at immediate loss for Reddit’s business model}. If valid, this
 % hypothesis would highlight the need for understanding the reasons behind such
 % actions. Given the anecdotal evidence, Reddit performs these costly
 % interventions to appease the media and users and therefore we hypothesize that
 % \textbf{Reddit’s administrative actions are a response towards negative
 % attention}. If valid, we also hypothesize drawbacks of reliance on such form of
 % moderation: 1) \textbf{Reactive moderation strategies are inconsistent} and 2)
 % \textbf{Reactive moderation strategies can advertise and normalize harmful
 % behavior}.
 % 

\para{Our hypotheses.} This research seeks to highlight the extent to which
media reporting drives Reddit moderation decisions and the consequences it
subsequently faces. Specifically, we explore the following hypotheses.

\parait{H1: In communities with toxic content, Reddit's administrative
interventions  for violating the content policy related to toxicity occur
because of media pressure. (\Cref{sec:relationship})} We test the validity of
this hypothesis by checking if media pressure generated by a subreddit
(quantified from negative media coverage of a subreddit) mediates the
relationship between its measured levels of toxicity and administrative
interventions for violating the content policy related to toxic content. Our
analysis shows that measures of media pressure and internal pressure completely
explains any relationship between measured levels of toxicity and
administrative interventions for violating the content policy related to toxic
content. This suggests a reactionary moderation strategy.

% We test the relationship
% between media pressure (from negative media coverage) and administrative
% interventions applied to toxic communities for evidence of a causal
% relationship. Our initial analysis shows that both toxicity and media
% pressure are similarly correlated with administrative interventions. However,
% using mediation analysis, we show that the effect of toxicity on administrative
% interventions are fully mediated by media pressure in certain circumstances.
% 
\parait{H2: Prior media attention on communities which receive interventions
for toxic content: (1) increases the prevalence of problematic activity on the
platform and (2) reduces the effectiveness of the issued interventions.
(\Cref{sec:consequences})} We
now focus on subreddits which: (1) received an administrative intervention for
violating the content policy regarding toxic content and (2) received negative
media attention prior to the administrative intervention. 
For these subreddits, we conduct an interrupted time series analysis to
understand the platform-wide increase of problematic activity related to the
toxic community as a consequence of: (1) the media pressure they receive and
(2) the administrative intervention. Our analysis shows that
media pressure and interventions both increase the levels of problematic
activity. However, we find that the effects of the intervention are not
statistically different from the effects observed by the communities which
received no media pressure prior to their intervention --- \ie interventions
are not less effective when they are preceded by media attention on the
targeted community.

    
% 
%   \item {\em H2: Reddit's administrative interventions are inconsistently
%     applied.} This hypothesis aims to understand whether Reddit's
%     administrative bans and the media coverage that precedes them are impacted
%     by factors such as subreddit popularity and engagement. We perform
%     moderation analysis to uncover the inconsistencies between the relationship
%     of toxicity and negative attention and explore the effect of the factors
%     responsible for these inconsistencies. 
% 
%   \item {\em H3: Problematic behavior is normalized by media driven
%   interventions.} This hypothesis aims to understand whether media-driven
%   interventions result in widespread discussion and a subsequent rise in
%   problematic discourse similar to those reported by the media. We perform
%   interrupted time series analysis to measure effects of media-driven
%   interventions on the problematic discourse.
% 
% \end{itemize}

% \subsection{H0: Administrative actions come at a loss for Reddit's business
% model.}
% This hypothesis demonstrates the loss Reddit faces as a result of its
% administrative actions. et al. shows how toxicity, misinformation and extremism
% is profitable for social media platforms. This highlights the conflict between
% policing and profitability. Our hypothesis suggests, violating communities are
% profitable for Reddit and restricting their access leads to user migration and
% lower user engagement. We statistical analysis to measure losses incurred by
% Reddit after administrative actions. If valid, our hypothesis calls for reasons
% for such actions, reasons, which we test in our next hypothesis.
% 
% 
% \subsection{H1: Reddit interventions are a response towards negative attention}
% This hypothesis demonstrates how Reddit's administrative actions are a response
% towards negative attention either from users within the platform, from
% mainstream media or both.  We perform a quantitative analysis to support the
% anecdotal claims on Reddit's reluctance to take administrative actions against
% violations especially toxicity unless pressured to do so by mainstream media and
% users. To test this hypothesis, we perform mediation analysis to establish
% relationships between violations, the negative criticism faced by Reddit and
% past administrative actions. If valid, our hypothesis will highlight the
% shortcomings of current moderation strategies and the need for alternative
% strategies or legislation. Finally, to understand the dangers of reliance on
% reactive moderation strategies, we test the following hypothesis.
% 
% \subsection{H3: Reactive moderation strategies are inconsistent} 
% Validating H1 suggests Reddit's moderation are reactive towards negative
% attention. This hypothesis tests one of the dangers of reactive moderation i.e.
% reactive moderation strategies are inconsistent.  Since reactive moderation
% techniques rely on external negative attention to drive administrative action,
% we hypothesize, attention to violating communities is inconsistent, partially
% dependent on the community's popularity and its type of violations. If valid,
% this hypothesis would further prove the ineffectiveness of reactive moderation.
% 
% \subsection{H2: Reactive moderation strategies bring widespread attention to the
% violations}
% Finally, this hypothesis tests how reactive moderation strategies help in
% bringing widespread attention to dangerous ideologies. We hypothesize, in order
% to bring attention to uncivil and violating behavior on the platform mainstream
% media and users can, inadvertently, bring these dangerous and extreme ideologies
% to the mainstream. Although, the negative attention might influence Reddit to
% take administrative actions against a particular violation, bringing attention
% to said violation can legitimize it and propel it further into mainstream
% dialogue aggravating the situation. If valid, our hypothesis would confirm the
% dangers and counter-productiveness of reactive moderation strategies and therefore once again, highlight the need for alternative strategies or
% legislation.
% 


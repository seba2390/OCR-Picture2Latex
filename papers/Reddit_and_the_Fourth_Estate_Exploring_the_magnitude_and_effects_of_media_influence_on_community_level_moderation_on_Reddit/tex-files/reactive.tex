\section{Are Reddit's administrative interventions influenced by media
pressure?} \label{sec:relationship}
% The goal of this section is to understand the role of media pressure on
% Reddit’s administrative decisions. We hypothesize, based on previous studies
% TODO CITE and reported incidents of Reddit's administrative actions, that
% \textbf{Reddit’s administrative actions towards closing its communities are
% largely driven by media pressure}. In other words, pressure from media towards
% subreddits (represented by percentage of negative articles written by
% mainstream and popular media outlets criticizing the community) influences
% Reddit’s administration to close or quarantine the subreddit. If valid, our
% hypothesis would highlight Reddit’s reliance on reactive moderation strategies
% towards closing dangerous communities on its platform. On a larger scale, it
% would underscore the need for better moderation techniques and even policy
% changes. To test this, we use previous interventions, media pressure received
% by each community and percentage of toxic content present in each community to
% measure the relationships between interventions and media pressure. We perform
% the following experiments to validate our hypothesis.
%
\para{Overview.} In this section, we explore the relationship between media
pressure and administrative interventions in the context of toxic Reddit
communities. Our focus is solely on subreddits which were banned or quarantined for violating
the content policy related to toxicity\footnote{``Rule 1: Remember the human.
Reddit is a place for creating community and belonging, not for attacking
marginalized or vulnerable groups of people. Everyone has a right to use
Reddit free of harassment, bullying, and threats of violence. Communities and
users that promote hate based on identity or vulnerability will be banned.''}.
Our hypothesis is that: \emph{(H1) In communities with toxic content, Reddit's
administrative interventions for violating the content policy related to
toxicity occur because of media pressure.} Therefore, we
seek to test whether the effect of a subreddit's measured toxicity on
administrative interventions for violating the content policy related to
toxicity occurs because of the pressure generated by the media. Put
another way: when the toxicity of two subreddits are controlled for does the
subreddit garnering more negative media attention become more likely to
receive an administrative intervention for violating the content policy related
to toxic content? If this hypothesis is valid, it would suggest that Reddit
employs a reactionary administrative strategy which delays administrative
interventions for toxic communities until media pressure forces action. 
% To test this
% hypothesis, we study the toxicity and negative media attention experienced by
% communities that did and did not receive an administrative intervention for
% violating the `anti-toxicity' content policy. Specifically, we conduct 
% the following analyses.

% In our first experiment we test the sub-hypothesis that intervened subreddits
% received significantly more media pressure than active subreddits and had no
% significant difference in the toxicity exhibited compared to currently active
% communities. If valid, this would imply Reddit's administrative actions are
% driven by media pressure since intervened subreddits have received more media
% pressure but are similarly toxic to active subreddits. Our results show that
% intervened communities received significantly higher media pressure but they
% also exhibited significantly higher toxicity. This suggest that although media
% pressure seemed to have influenced Reddit's administrative actions, toxicity
% also played a role in the administrative decisions. This implies a more complex
% relationship between toxicity, media pressure and interventions.
% In our second experiment, we explore the relationship between toxicity, media
% pressure and intervention. We hypothesize, the relationship between toxicity
% and interventions is mediated by media pressure. If valid, this suggests
% toxicity indirectly influences Reddit's administration through its effect on
% media outlets to pressure Reddit. To test this, we design a mediation model
% using two different datasets: D3 and DP. Our results suggests that toxicity
% influences interventions directly as well as indirectly through media pressure.

% Finally, given the influence of toxicity on media pressure, in this experiment,
% we explore the robustness of this relationship under different conditions. We
% hypothesize that media pressure is inconsistently influenced by toxicity. If
% valid, this would suggest media pressure is not always driven by toxicity and
% therefore reliance on media pressure by Reddit, as shown in previous results,
% as a proxy for toxicity is not an effective strategy. We perform experiments
% using a dataset controlled for toxicity to measure the consistency of
% correlation between the two variables. Our dataset reveal contradictions to the
% positive correlations between toxicity and media pressure.  Using this
% knowledge we redesign our mediation model with the addition of suitable
% moderators such as popularity, profitability and discussion topic which
% determine the validity of relationships between toxicity and media pressure.

 

\subsection{Methods and datasets} \label{sec:relationship:methods}

\para{Quantifying subreddit toxicity.} We quantify the toxicity of
a subreddit as the percentage of toxic content (posts and comments) present in
a subreddit. The use of this metric is supported by comments from Reddit
administrators. For example, in response to a question demanding transparency
in their administrative interventions for violations of Rule 1, \emph{u/spez}
(an administrator and co-founder of Reddit) indicated that ``high ratio'' of
hateful content was a major criteria for
interventions.\footnote{https://www.reddit.com/r/announcements/comments/hi3oht/update\_to\_our\_content\_policy/fwe83at/}
This also motivates our study of the relationship between toxicity, media
pressure, and administrative interventions for toxic content. In order to
identify toxic content, we leverage the Perspective
API\footnote{https://www.perspectiveapi.com/} --- a Google-owned tool for
identifying online toxic content. We use the Perspective API to identify
the percentage of all toxic comments and posts on a subreddit. We quantify the
toxicity of a subreddit as $T(s) = \frac{\text{\# toxic comments} \in
s + \text{\# toxic posts} \in s}{\text{\# comments} \in s + \text{\# posts} \in
s}$. We note that the Perspective API has been validated for use with Reddit
and has been leveraged to quantify subreddit toxicity in several previous
studies  \cite{mittos2020and, zannettou2020measuring} and has also been used as
a plugin to aid moderation.
\footnote{https://www.perspectiveapi.com/case-studies/}

\para{Quantifying negative media attention as media pressure.} We seek to
quantify negative attention towards subreddits from popular media outlets. We
start by identifying the number of published media articles that mention
a subreddit in a negative or critical tone. We refer to each of these articles
as a `negative media mention'. To measure the negative media mentions for
a subreddit, we use the MIT media cloud API\footnote{https://mediacloud.org/}
to obtain articles mentioning the subreddit's name. We restrict our analysis to
articles from US `top sources' and `mainstream media' sites as categorized by
the MIT media cloud. We focus the remainder of our analysis only
on articles published between 01/2015 and 04/2020. Further, for subreddits
which received an intervention we only include pre-intervention articles (\ie
those published up to the month prior to the intervention). We do this to
ensure the exclusion of articles which report the occurrence of an
intervention. Next, for each article, we use the entity-level sentiment
analysis API from the Google NLP
platform\footnote{https://cloud.google.com/natural-language} to measure the
sentiment towards the subreddit. Articles which include negative sentiments
towards the subreddit are counted as negative media mentions. We quantify the
`media pressure' towards a subreddit $s$ as $P_{media}(s)
= \frac{\text{negative media mentions of }s}{\text{total media mentions of
}s+L}$, where $L$ is the Laplace smoothing constant and is set to 10. This
metric captures the frequency of negative media mentions relative to all media
mentions received by a subreddit. %The smoothing constant, $L$, %ensures that
%subreddits with high values ($P_{media} \approx$ 1) are indicative of high
%media attention which is mostly negative. Conversely, lower values ($P_{media}
%\approx$ 0) are indicative of very low negative media attention, regardless of
%the total media attention received. Addition of this smoothing parameter
The presence of `total media mentions' and the smoothing constant $L$
ensures that the quantified media pressure ($P_{media}$): (1) is not identical
for two subreddits $a$ and $b$, where $a$ and $b$ have similarly high ratio of
negative:total media mentions but differ significantly in their raw number of
total media mentions and (2) is not identical for two subreddits $a$ and
$b$, where $a$ and $b$ have the same number of negative media mentions but
significantly different total media mentions.

\para{Identifying subreddits receiving administrative interventions for
violating the content policy related to toxicity.} Reddit's content policy
requires communities (\ie subreddits) to adhere to eight rules
\footnote{https://www.redditinc.com/policies/content-policy}. Violation of
these rules are meant to result in administrative interventions by Reddit. In
this paper, we focus on the communities found to be in violation of \emph{Rule
1} (commonly referred to as the anti-toxicity policy). We focus on this rule
specifically because it was the subject of the most administrative
interventions during the period of this study (from 01/2015 to 04/2020).
Further, anecdotes of media-driven interventions appear to occur most
frequently for communities found to be violating this policy, perhaps due to
its subjective nature. In order to identify subreddits banned/quarantined for violations
related to the anti-toxicity content policy, we scraped the homepages of all
subreddits and identified the ones marked as banned or quarantined for
violations of the policy \footnote{Reddit provides specific violations in the
subreddit homepage when a ban occurs. See \url{www.reddit.com/r/The\_Donald} as
an example.}. In total, 120 of the 535 subreddits which received an
administrative intervention from 01/2015 to 04/2020 were targeted for the
violation of this policy. In the remainder of this paper we broadly use the
term `administrative interventions' to refer to administrative interventions
whose stated reason was a violation of the anti-toxicity content policy.

\begin{table}[]
\resizebox{\columnwidth}{!}{%
\begin{tabular}{@{}clcccc@{}}
\textbf{Dataset}    & \textbf{Label} & \textbf{Subreddits}
  & \textbf{\begin{tabular}[c]{@{}c@{}}Avg.\\ Toxicity \\($T$)\end{tabular}}
    & \textbf{\begin{tabular}[c]{@{}c@{}}Negative\\Media\\Mentions\end{tabular}}
      & \textbf{\begin{tabular}[c]{@{}c@{}}Avg. Media \\ Pressure \%age\\
      ($P_{media}$)\end{tabular}} \\
\toprule
  \multirow{2}{*}{\D{3K}} & Intervened     & 29   & \textbf{23\%} & 407
  & \textbf{18.7} \\ \cmidrule(l){2-6}
		    & Active         & 2971 & \textbf{8\% } & 644 & \textbf{0.9}  \\
        \midrule
  \multirow{2}{*}{\D{P}} & Intervened     & 120  & \textbf{24\%} & 463
  & \textbf{5.6}  \\ \cmidrule(l){2-6} 
		    & Active         & 120  & \textbf{6\%}  & 8   & \textbf{0.2}  \\
        \midrule
  \multirow{2}{*}{\D{T}} & Intervened     & 120  &         24\%  & 463
  & \textbf{5.6}  \\ \cmidrule(l){2-6} 
		    & Active         & 120  &         24\%  & 31  & \textbf{1.9}  \\
        \bottomrule
  \multirow{2}{*}{All} & Intervened     & 120  &   {\bf 24\%}  & 463
  & \textbf{5.6}  \\ \cmidrule(l){2-6} 
        & Active         & 3211  &        {\bf 9\%}  & 683  & \textbf{0.9}  \\
        \bottomrule
\\
\end{tabular}%
}
\caption{Characteristics of the datasets used in this study. Bold values
  indicate a statistically significant ($p$ < .05) difference between the
  attributes for the intervened and active groups in the corresponding
  dataset.}
\label{table:relationship:datasets}
\end{table}

\para{Datasets.}
Our data was gathered using Pushshift \cite{PushShift-Reddit} and comprised of
all the comments and posts made on Reddit during the period from 01/2015 to
04/2020. In total, this included 5B comments and 684M posts from 39M unique
users. For the analysis presented in this section, we use this data to
construct three different datasets that are described below. The
characteristics of each dataset is illustrated in
\Cref{table:relationship:datasets}.

\parait{Dataset of most active subreddits (\D{3K}):} This dataset contains all
the content (comments, posts, and media mentions) associated with the 3000 most
active subreddits between 01/2015 and 04/2020. We define activity as the
average number of monthly comments and posts made on the subreddit. For
subreddits which receive an administration intervention (referred to as
`intervened subreddits'), this average is computed only over the post-creation
and pre-intervention months that occurred within the period from 01/2015 to
04/2020. For subreddits without an administrative intervention (referred to as
`active subreddits'), this average is computed over all the post-creation
months that occurred between 01/2015 and 04/2020. In total, this dataset
contained 29 intervened subreddits and 2971 active subreddits.

\parait{Dataset of popularity-controlled subreddits (\D{P}):} This dataset
contains all the content associated with all 120 subreddits which received an 
intervention for violating the `anti-toxicity' policy between 01/2015 and
04/2020. For each of these intervened subreddits, we also include content
associated with an active subreddit that has the most similar popularity.
Popularity is measured by the average number of active users on the subreddit
each month (\ie the number of unique users making posts or comments on the
subreddit). As above, this average is only computed over the subreddit's
post-creation and pre-intervention period between 01/2015 and 04/2020.
A Kolmogorov-Smirnoff goodness-of-fit test shows that the
distributions of popularity observed within the two groups of subreddits in
this dataset (\ie active and intervened) are statistically similar ($p$ < .05).

\parait{Dataset of toxicity-controlled subreddits (\D{T}):} This dataset also
contains all the content associated with our 120 intervened subreddits.
However, the active subreddits in this dataset are obtained by matching each
intervened subreddit with the non-intervened subreddit having the most similar
toxicity ($T$) score. Similar to the previous datasets, toxicity scores were
only computed over the post-creation and pre-intervention period between
01/2015 and 04/2020. A Kolmogorov-Smirnoff goodness-of-fit test shows that the
distributions of toxicity scores observed within the two groups of subreddits
in this dataset are similar ($p$ < .05).

\subsection{Analysis and results}\label{sec:relationship:results}

\para{Overview of analyses.} 
% Since we are focused on interventions for toxic
% content, it is only natural to expect a causal relationship between toxicity
% ($T$) and an intervention. However, by showing that this relationship between
% $T$ and interventions is in fact entirely mediated by $P_{media}$ we will have
% discovered strong evidence of a media-driven intervention strategy. This is
% precisely the method of testing we leverage. 
We conduct three observational
experiments to better understand the influence of toxicity ($T$) and media
pressure ($P_{media}$) on each other and on administrative interventions for
toxic content. Each experiment builds on the previous and eventually provides
a test for \emph{H1}. 
% An overview of each experiment is provided below.
% 
% \parait{Analysis 1: What are the characteristics of intervened subreddits?} We
% begin by measuring the differences between subreddits which received
% interventions for toxic content and those that did not, with a focus on
% measures of toxicity and media pressure received as a result of them. We
% hypothesize a strong correlation between: (1) toxicity ($T$) and receiving an
% intervention for toxic content and (2) media pressure ($P_{media}$) and
% receiving an intervention for toxic content. If our hypothesis is true, it
% suggests the need to further explore the interactions between toxicity and
% media pressure and their influence on administrative interventions for toxic
% content. 
% 
% \parait{Analysis 2: Does media pressure mediate the relationship
% between toxicity and administrative interventions for toxic content?} We use
% a mediation model to test if media pressure ($P_{media}$) {mediates} the
% relationship between toxicity ($T$) and administrative interventions for toxic
% content. If the mediation relationship is found to be statistically
% significant, this indicates that media pressure predicts administrative
% interventions while controlling for the toxicity of a community. Although this
% result is necessary to validate our hypothesis, it is not sufficient due to the
% lack of accounting for possibly confounding variables such as subreddit
% popularity.
% 
% \parait{Analysis 3: Under what conditions does media pressure
% \underline{completely mediate} the relationship between toxicity and
% administrative interventions for toxic content?}
% We complete our mediation analysis by including several third variables such as
% community popularity, revenue earned from the community, and community topic as
% moderating variables. We also include
% additional mediating variables such as `internal pressure' ($P_{int}$) and
% `external pressure' ($P_{ext}$) which seek to capture the negative attention
% a community has received from non-media sources. If a mediation relationship is
% found to be statistically significant and complete under specific moderating
% conditions, it indicates that the mediating variables (\ie media pressure,
% internal pressure, or external pressure) completely explain the relationship
% between toxicity ($T$) and administrative interventions for toxic content. Put
% another way, when a subreddit exhibits specific characteristics (\ie values for
% the moderating variables), the influence of toxicity on administrative
% interventions for toxic content is only significant because of its effect on
% the mediating variables ($P_{media}$, $P_{ext}$, and $P_{int}$). Such a result
% would be sufficient to validate our hypothesis.

% Since our
% model: (1) obeys temporal precedence and
% % (we do not include data of toxicity or media attention
% % for any period after the intervention occurred) 
% (2) shows significant mediating relationships in the presence of any other
% reasonable third variable, this finding would be sufficient evidence of a causal
% relationship between the mediators and administrative interventions handed out
% for toxic content \cite{Pieters-JCR2017}.


\para{Analysis 1: What are the characteristics of intervened subreddits?} We
begin our analysis by simply comparing the distributions and means of toxicity
scores ($T$) and media pressure scores ($P_{media}$) for active and intervened
subreddits in each of our three datasets (\D{3K}, \D{P}, and \D{T}). 

\parait{Differences in distributions of $P_{media}$ and $T$:} In all three
datasets, we find that the distribution of $P_{media}$ scores is statistically
significantly different for active and intervened subreddits. Similarly, we see
statistically significant differences in $T$ scores for active and intervened
subreddits in \D{3K} and \D{P} (not in \D{T} which specifically controls for
toxicity across the two groups). Looking at the means, we see that on average
and across all three datasets, intervened subreddits have over $6\times$ higher
$P_{media}$ and $2.5\times$ higher $T$ scores than non-intervened subreddits.
Interestingly, we find that even when toxicity scores are controlled (\D{T}),
the mean $P_{media}$ score of intervened subreddits is nearly $3\times$ higher
than their equally toxic non-intervened counterparts. These results suggest
that $P_{media}$ may be more predictive (than $T$) of administrative
interventions. However, we note that only 43 of the 120
intervened subreddits had received media attention prior to their intervention.
This suggests that $P_{media}$ is not the only influence or predictor of an
intervention. A full breakdown of $T$ and $P_{media}$ scores for each group and
dataset is provided in \Cref{table:relationship:datasets}.

\parait{Predictive powers of $T$ and $P_{media}$ on administrative
interventions:} Next, we construct a logistic regression model that uses $T$
and $P_{media}$ to predict administrative interventions. We find that both
variables are statistically significant predictors of administrative
interventions with identical odds ratios of 4\% --- \ie all else equal, a unit
increase in $T$ or $P_{media}$ increases the odds of a subreddit receiving an
intervention by 4\%. This result suggests that the administrative interventions
may be influenced by both $T$ and $P_{media}$ and therefore justifies further
investigation into their relationship with each other and with administrative
interventions.

% To evaluate our hypothesis, \textbf{Reddit’s administrative decisions for its
% communities are largely driven by negative media pressure}, first, we compare
% the distribution of media pressure and toxicity in banned communities with
% active communities. We hypothesize that banned communities receive
% disproportionately more media pressure before their intervention than active
% communities and exhibit no difference in toxicity. Results with significant
% correlation between media pressure and intervention would enable us to explore
% media pressure as a causal variable. To further explore this causality, we
% additionally test for significant differences in toxicity exhibited by the
% communities and compare the correlation between media pressure and toxicity. 
% 
% If valid, this hypothesis would suggest a positively correlated relationship
% between media pressure and intervention. To test this hypothesis, we use our D3
% dataset of 3k most active subreddits. We split the 3k subreddits into two
% groups: intervened or active, based on their status at the time of our
% experiment. Next, we gather media pressure for each subreddit and construct two
% distributions of media pressure received by each group. Our hypothesis is valid
% if there is statistically significant difference in the distribution of media
% pressure between the two groups. Next, we repeat this experiment by replacing
% media mentions and toxicity. Absence of a significant difference in toxicity
% between banned and active group would suggest the administrative decisions are
% not driven by toxicity.
% 
% \para{Results}
% Comparing the distribution of toxicity and media pressure in intervened
% communities with active communities show that 1) \emph{intervened communities
% receive significantly higher media pressure (19 times higher on average)
% compared to active communities}, and 2) \emph{intervened communities exhibit
% significantly more percent of toxic content (2.7 times on average) compared to
% active communities}. Our logistic regression model show both toxicity and media
% pressure are significant predictor of interventions. The results from the
% logistic regression show, if controlled for everything, a unit increase in
% toxicity of a community, we expect to see 4\% increase in the odds of
% a subreddit being banned, similarly, a unit increase in media pressure would
% yield an 4\% increase in the odds of a subreddits being banned. Furthermore, we
% also observe, a single negative article about the community increases the odds
% of intervention by 24\%. These results imply interventions are influenced by
% both, toxicity and media pressure and therefore require further exploration.

\begin{figure}[t]

\begin{subfigure}[b]{\linewidth}
         \centering
         \includegraphics[width=\linewidth]{figures/H1/mediation-D3.pdf}
         \caption{Mediation effects observed on \D{3K}. The direct effect ($T
         \rightarrow I$) is .04 (log odds) and the indirect effect ($T
         \rightarrow P_{media} \rightarrow I$) is .13 (log odds). Both
         effects are statistically significant ($p$ < .05).}
         \label{figure:relationship:simplemediation:D3k}
     \end{subfigure}

     \begin{subfigure}[b]{\linewidth}
         \centering
           \includegraphics[width=\linewidth]{figures/H1/mediation-DP.pdf}
         \caption{Mediation effects observed on \D{P}.  The direct effect ($T
         \rightarrow I$) is .08 (log odds) and the indirect effect ($T
         \rightarrow P_{media} \rightarrow I$) is .18 (log odds). Both
         effects are statistically significant ($p$ < .05).}
         \label{figure:relationship:simplemediation:Dp}
         \label{fig:H1-mediation-DP}
     \end{subfigure}
     \caption{A preliminary mediation analysis: Does $P_{media}$ mediate the
     relationship between $T$ and $I$? Solid lines indicate statistically
     significant effects. Values indicate correlation coefficients between
     variables. }
     \label{figure:relationship:simplemediation}
\end{figure}

\para{Analysis 2: Does media pressure mediate the relationship between toxicity
and administrative interventions?} Our previous results show
that $P_{media}$ and $T$ scores are predictive of administrative interventions
on subreddits.  Further, we find that $T$ is a statistically significant
predictor of $P_{media}$. Both these findings suggest the possibility of $T$
having its relationship with administrative interventions mediated by
$P_{media}$ --- \ie the effects of $T$ on administrative interventions may be
explained by $T$'s effects of $P_{media}$. We explore this with a  mediation
model.

% \parait{Primer on mediation analysis.} Mediation analysis is a standard toolkit
% for explaining the underlying mechanism of the relationship between two (often)
% correlated variables --- an independent variable ($IV$) and a dependent
% variable ($DV$) \cite{Baron-JPSP1988}. Simply put, a mediation model tests
% whether the predictive power of $IV$ on the value of $DV$ is reduced when some
% mediation variable $MV$ is introduced in the regression. If this reduction is
% statistically significant, we say that $MV$ mediates the relationship between
% $IV$ and $DV$ --- \ie the relationship between $IV$ and $DV$ may be explained
% by the effect of $IV$ on $MV$ (and $MV$ to $DV$). We say that the $MV$
% completely mediates the relationship between $IV$ and $DV$ if after the
% inclusion of $MV$, the direct effect of $IV$ on $DV$ becomes insignificant ---
% \ie all of $IV$'s effect on $DV$ is explained by its relationship with
% $MV$ (and $MV$ with $DV$). 
% 
\parait{Testing $P_{media}$ as a mediation variable.} We now consider
a mediation model which uses $T$ as the independent variable, an indicator
variable ($I$) to represent administrative interventions ($I_s=1$ if the
subreddit $s$ received an administrative intervention and
$I_s=0$ otherwise) as the dependent variable, and $P_{media}$ as the mediating
variable. We conduct our mediation analysis on the \D{3K} and \D{P} datasets.
Note that the \D{T} dataset cannot be used since it explicitly controls for
toxicity (the independent variable in our model) which would forcibly remove
any effects from $T\rightarrow I$.
Our models, the direct $T \rightarrow I$ effects, and indirect $T \rightarrow
P_{media} \rightarrow I$ are illustrated in
\Cref{figure:relationship:simplemediation:D3k} (for dataset \D{3K}) and 
\Cref{figure:relationship:simplemediation:Dp} (for dataset \D{p}). In both
cases, we see that the mediation occurring through $P_{media}$ is statistically
significant and that the indirect effect from $T \rightarrow P_{media}
\rightarrow I$ is substantially higher than the direct effect from $T
\rightarrow I$. In the \D{3K} dataset, a unit increase in $T$ will result in
a 4\% increase in the odds of an intervention solely due to $T$ and a 14\%
increase in the odds of an intervention because of the effect of $T$ on
$P_{media}$. Similarly, in the \D{p} dataset, a unit increase in $T$ will
result in a 8\% increase in the odds of an intervention solely due to $T$ and
a 19\% increase in the odds of an intervention because of the effect of $T$ on
$P_{media}$. Thus, we can conclude that $P_{media}$ has a partial
mediating effect on $T \rightarrow I$. %the relationship between $T$ and $I$.

\para{Analysis 3: Further exploring the relationship between toxicity and
administrative interventions?} We now seek to build
a complete model to explain the relationships between $T$, $P_{media}$, and
$I$. Our initial analysis which shows that $P_{media} > 0$ only in 43
communities and the existence of only a partial mediation by $P_{media}$
suggests the possibility for additional influences between $T\rightarrow I$. We
explore this possibility by incorporating several third variables into our
model: (as moderators) subreddit popularity, subreddit topic, and subreddit
profitability; and (as mediators) internal pressure and external pressure.
%These additions help us develop a more explanatory model which incorporates
%variables which may influence or explain the interactions between $T$ and $I$.
We use this model to analyze the \D{P} dataset since it is the most complete
and allows effects of toxicity.
% since it presents a balanced dataset that
% exposes effects of toxicity.
% Next, we investigate the statistically significant mediating relationships in
% this complete model to explain the pathways between subreddit toxicity and
% administrative interventions for violating the content policy related to
% toxic content.

\parait{Including moderating variables.} \emph{Subreddit popularity} is
a measure of the average number of active contributors to
a subreddit per month. In our model, we specifically investigate how subreddit
popularity may influence the relationship between $T \rightarrow P_{media}$ and
$T \rightarrow I$. The inclusion of popularity allows us to investigate whether
the $T \rightarrow P_{media}$ or $T \rightarrow I$ effects are significant and
stronger for subreddits of different popularity levels. 
%--- \eg are more popular
%subreddits more likely to generate media pressure than less popular subreddits
%when toxicity is controlled; are more popular subreddits less likely to face an
%intervention than less popular subreddits when media pressure is controlled.
%(indicating a bias in favor of popular subreddits by Reddit's administrators)?
Next, we include \emph{subreddit topic} as a moderator. For this, we leverage
TF-IDF to generate keyword vectors for each subreddit and then apply $k$-means
clustering over these vectors ($k$=8 was found to perform best for subreddits
in the \D{p} dataset). We manually label each cluster with the general
topics of subreddits contained in them. The topics identified were: sports,
politics, forums, memes, gore, porn, games, and health. All
subreddits in a cluster received the cluster's topic as its own. In our
analysis of subreddit topics, we were specifically interested in studying the
effects of subreddit topic on $T \rightarrow P_{media}$.
%---  \ie did subreddits
%around specific topics attract more negative media coverage than their
%counterparts when toxicity scores are controlled.
Finally, we introduce a \emph{subreddit profitability} variable as a moderator.
In addition to advertising revenue, Reddit is supported by Redditors' purchase
of Reddit coins
\footnote{\url{https://reddithelp.com/hc/en-us/articles/360043034252}}. These
coins allow Redditors to reward high-quality posts and comments with awards and
reactions. We estimate the amount of non-advertising revenue generated by
a subreddit by tracking the average number of awards donated to posts and
comments on the subreddit each month. This estimate is used as a proxy for
subreddit profitability. In our analysis, we are specifically interested in
understanding how subreddit profitability moderates the relationships between
$T \rightarrow I$ and $T \rightarrow P_{media} \rightarrow I$.
%--- \ie do more
%profitable subreddits receive administrative interventions at a lower rate than
%their less profitable counterparts when $T$ or $T$ and $P_{media}$ are
%controlled.

\parait{Introducing mediating variables.} Our complete model also seeks to
understand if the influence of pressure on administrators originating from within
the Reddit community (internal non-media pressure or $P_{int}$) and pressure on
administrators originating from other platforms (external non-media pressure or
$P_{ext}$) may mediate $T\rightarrow I$. In order to measure $P_{int}$ for
a subreddit, we obtain all pre-intervention and post-creation comments made on
Reddit between 01/2015 and 04/2020 which mention the specific subreddit in
a negative sentiment. Then we set $P_{int} = \frac{\text{negative comment
mentions of }s}{\text{total comment mentions of }s+L}$. We quantify external
pressure for a subreddit by gathering all pre-intervention and post-creation
tweets made on Twitter between 01/2015 and 04/2020 which mention the specific
subreddit in a negative sentiment. Same as before, we set $P_{ext}
= \frac{\text{negative Twitter mentions of }s}{\text{total Twitter mentions of
}s+L}$. We select Twitter as our proxy for external pressure due to its
ubiquity, size, and prominence in the activist community. 
% These three pressure variables ($P_{int}, P_{media},
% P_{ext}$) are tested for mediation of $T\rightarrow I$.
% Given these variables, we then redesign our original
% mediation model. 
% In the extended model, we propose a serial mediation of the
% form $P_{int} \rightarrow P_{media} \rightarrow P_{ext}$ between $T$ and $I$
% --- \ie we theorize that
% toxic communities are first noticed and reported by Redditors resulting in
% increased $P_{int}$ and this eventually causes media reporting of the toxic
% communities resulting in increased $P_{media}$ which results in increased
% negative attention from users of external platforms ($P_{ext}$)
% which finally results in an administrative intervention.

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{figures/H1/e3-mediation.pdf}
    \caption{A complete mediation analysis. Solid
    lines indicate statistically significant effects and dashed lines indicate
    insignificant effects. Values indicate the correlation coefficients between
    variables. Variables in yellow boxes were included as moderators. Green
    and red arrows indicate a statistically significant amplifying and
    dampening moderation effect, respectively.}
    \label{figure:relationship:e3mediation}
\end{figure}

\parait{Pathways to administrative interventions.} The results of our complete
mediation analysis are illustrated in \Cref{figure:relationship:e3mediation}. 
First, we see that \emph{$P_{int}$ and $P_{media}$ \underline{completely mediate} the
    relationship between $T$ and $I$.} The inclusion of $P_{int}$ and
    $P_{media}$ as mediators between $T$ and $I$ cause the direct effect $T
    \rightarrow I$ to become insignificant. This allows us to conclude that any
    effect that $T$ has on $I$ is only because of its effect on $P_{int}$ and
    $P_{media}$. Analyzing the pathways to influence $I$, we see that all the
    indirect effects through $P_{int}$ and $P_{media}$ are statistically
    significant. Of these paths, the indirect
    effect from $T \rightarrow P_{int} \rightarrow P_{media} \rightarrow I$ is
    found to be the strongest with a unit increase in $T$ resulting in a 2.3\%
    increase in the odds of an intervention through this path. Smaller effects
    are observed on the $T \rightarrow P_{media} \rightarrow I$ and $T
    \rightarrow P_{int} \rightarrow I$ paths where a unit increase in $T$
    increases the odds of intervention by 1.2\% and 1.7\%, respectively.
Our model also shows that \emph{subreddit popularity moderates relationships with $P_{media}$ and
    the effect of $T$ on $I$.} Specifically, we find that subreddit popularity
    is a statistically
    significant amplifier in the $T \rightarrow P_{media}$ and $P_{int}
    \rightarrow P_{media}$ relationships --- \ie the influence of $T$ and
    $P_{int}$ on $P_{media}$ is higher for more popular subreddits than less
    popular ones when toxicity or $P_{int}$ are controlled for. This
    intuitively makes sense --- after all, media outlets' interest in covering
    a subreddit is likely related to the popularity of the subreddit. We
    also find that the effect of $T \rightarrow I$ reduces as popularity
    increases and this effect, although small, becomes statistically
    significant for subreddits with popularity in the 84th percentile and
    higher. This finding suggests a marginal hesitation to apply
    administrative interventions to more popular subreddits when toxicity is
    controlled for.
We note that \emph{Subreddit topic, subreddit
    profitability, and external pressure yielded no statistically significant
    influences in our model.} This suggests that subreddit topic does not
    influence     media pressure when toxicity is controlled, subreddit
    profitability never     influences administrative interventions (through
    the direct or indirect     path), external pressure is not influenced by
    media pressure or toxicity,     and external pressure does not influence
    administrator intervention     decisions.


\para{Takeaways.} Our results confirm our original hypothesis that in
communities with toxic content ($T$), Reddit's administrative interventions
for violating the content policy related to toxicity occur ($I$) because of
media pressure ($P_{media}$). However, our analysis shows that the mediating
effect of media pressure ($T \rightarrow P_{media} \rightarrow I$) does not
completely explain the relationship between $T$ and $I$. We find that
incorporating the effects of internal pressure ($P_{int}$) in our model yields
two additional statistically significant pathways: $T \rightarrow P_{int}
\rightarrow I$ and $T \rightarrow P_{int} \rightarrow P_{media} \rightarrow I$
whose addition completely explains any effect from $T$ to $I$. Taken all
together, this suggests a reactionary moderation strategy in which any
administrative interventions handed out for toxic content are driven by
internal pressure from Redditors and media pressure from negative media
attention.


% 
% Finally, in this section we explore the relationship between toxicity and media
% pressure. Previous results suggest media pressure is driven by toxicity and
% therefore might serve as a proxy for toxicity for Reddit to moderate
% communities.
% 
% To validate this claim, we test consistency of the relationship between
% toxicity and media pressure is consistently significant under different
% factors. In our Dt dataset, containing all intervened subreddits along with
% active subreddits with similar toxicity, we observe (as shown in
% \Cref{table:dataset:distribution}) the media pressure is significantly higher
% (2 times higher) for the subreddits that eventually get banned. These
% contradictions to the toxicity and media pressure relationship highlights the
% inconsistency of media pressure reliance on toxicity. To explore the factors
% which influence the validity of this relationship we perform moderation
% analysis. We hypothesize popularity, profitability and the topic of discourse
% moderate the relationship with more popular subreddits with discourse on
% political and social issues getting more pressure due to their toxicity
% compared to subreddits with relatively low popularity and non-political
% topics.
% 
% \para{Results}
% Running a simple mediation model on our Dt dataset shows toxicity is no longer
% influencing interventions or media pressure. Interventions are solely driven by
% media pressure. Next using the same dataset dt, we include popularity as the
% moderator between media pressure. We observe, popularity moderates the
% relationship between toxicity and media pressure, toxicity significantly
% effects media pressure only for cases where subreddit is popular.  
% 
% Our Dt dataset represents treatment subreddits that have been banned and
% control subreddits that have similar propensity for being banned based on their
% toxicity but are still active. We observe the treatment group having
% significantly higher media pressure as compared to the control group. Similarly
% toxic group of subreddits, with different media pressure, suggest the
% relationship between media pressure and toxicity is not consistent. Our simple
% moderation model shows the influence of toxicity on media pressure is moderated
% by how popular the subreddit is. This relationship between toxicity and media
% pressure is only valid for subreddits TODO this much popular. Using these
% results we construct our final mediation model which includes popularity as
% a mediator between toxicity and media pressure.
% 
% 
% \subsection{Experiment 4}
% 
% Until now, we have looked at the direct relationships of media pressure with
% interventions and toxicity. In this section, we attempt to identify the
% indirect influences and effects of media pressure. For this, we introduce two
% new sources of pressure: 1) internal pressure and 2) external pressure. We
% quantify internal pressure as the percentage of negative mentions of the
% community by Reddit users. To measure this, we obtain all comments mentioning
% the subreddit and perform sentiment analysis to identify negative mentions. We
% characterize external pressure as the pressure faced by Reddit from users
% outside its platform criticizing Reddit for hosting any subreddit. We quantify
% external pressure using the percentage of negative mentions of the community by
% Twitter users. We select Twitter as the source to measure external pressure due
% to its ubiquity, size and prominence in activist community. We measure external
% pressure by searching for mentions of the community on Twitter using Twitter's
% API and performing sentiment analysis on the tweets to identify negative
% mentions. After obtaining pressure from these additional sources we redesign
% mediation model with internal pressure, media pressure and external pressure as
% the mediators. We hypotheize toxicity of subreddits regardless of their
% popularity to be first identified by the Reddit's community itself resulting in
% pressure from within. This pressure is then amplified by media outlets
% influenced by the internal criticism towards Reddit to close the communities.
% Finally, we hypothesize, media pressure in the form of negative articles brings
% widespread awarness to these violations which results in external users in
% sharing these articles and similar sentiment towards these communities. Our
% hypothesized chain of influnces looks like this: $Toxicity \rightarrow Internal
% Pressure \rightarrow Media  Pressure \rightarrow External  Pressure \rightarrow
% Intervention$.
% 
% \para{Results}
% Running a medition model with 3 mediators on the DP dataset shows two routes of
% significant effect of toxicity on intervention both mediated by media
% presssure. Results from this analysis (shown in \Cref{fig:H1-mediation-IN-EN})
% confirm our previous results and additionaly show inclusion of secondary
% pressure from internal and external users makes media pressure completely
% mediate the relationship between toxicity and intervention. Complete mediation
% implies toxicity does not significantly influences interveniton rather only
% effects intervention indirectly through influencing internal mentions and media
% pressure. Our results show toxicity still influences intervention the most
% through its effect on media pressure but now toxicity's effect on media
% pressure is largely mediated by intenral pressure. Looking at the
% interventions, we observe the status of the subreddit to be the most influences
% by media pressure with the odds of a subreddit being closed increasing by 9\%
% after a unit increase in media pressure compared to 4\% increase after a unit
% increase in internal pressure. Finally, no significant relation between
% external pressure is shown suggesting, Reddit's administrative decisions are
% not driven by external pressure. Taken altogether, our results show Reddit's
% administrative actions are not a results of toxicity's direct effects rather
% through its effect on media and internal pressure.
% 
% \begin{figure}
% 	\includegraphics[width=\linewidth]{figures/H1/mediation-IN-EN.pdf}
% 	\caption{Dataset P}
% 	\label{fig:H1-mediation-IN-EN}
% \end{figure}
% 
% 
% \subsection{Conclusion}
% Taken altogether, our results show that Reddit's administrative decisions are
% driven by media pressure, which is inconsistently influenced by toxicity. Our
% results show Reddit intervenes communities with high media pressure. We also
% show how media outlets view toxic communities more negatively, however, this
% relationship is also dependent on popularity which means only popular and toxic
% communities receive enough media pressure for Reddit to take an action against
% them. 

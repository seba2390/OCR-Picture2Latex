\section{Results and Discussion}
\label{sec:results}

 
 
 %MOVED
 %\subsection{Instructional Design}
  %\subsubsection{Structure}
  %By definition communication involves an exchange of messages tied by a cause-effect relation, so all of the VP considered here follow the Narrative design structure \cite{bearman2001random}. 9 VPs are categorized as exclusively Narrative, while the rest (n=7) also display characteristics typical of the Problem-Solving style of VP, namely history-taking \cite{maicher2017developing} \cite{hirumi2016advancing}, clinical reasoning \cite{zlotos2016scenario}, \cite{richardson2019virtual} \cite{peddle2016virtual}, \cite{peddle2019development}, physical examinations \cite{hirumi2016advancing} \cite{adefila2020students}, compilation and consultation of EMRs (Electronic Medical Records) \cite{maicher2017developing}, \cite{adefila2020students} and medication administration \cite{adefila2020students}.
 %\subsubsection{Interaction}
 %Most of the analysed VPs (n=10) have a Closed-Option interface, 4 are Free-Text, one is unclear \cite{adefila2020students}, and one VP has both options \cite{hirumi2016advancing}. Some arguments have been made about the fact that a Closed-Option interaction may be more suitable for novices, who for example may still be inexperienced about the procedures to follow in a patient encounter, while a Free-Text interface may be more useful and less restrictive for experienced students \cite{jacklin2019virtual}, \cite{carnell2015adapting}. Also, as stressed by \cite{hirumi2016advancing}, having both options (like in NERVE \cite{hirumi2016advancing}) implies that the same VP can be used both for learning sessions with the less stress-inducing Closed-Option variant, and for rehearsal/evaluation sessions with the more open-ended Free-Text variant.\par
 %5 VPs leverage Non-Verbal interaction, which is a fundamental aspect of human communication. Detection of non-verbal cues is achieved via Microsoft Kinect (n=2) \cite{maicher2017developing}, \cite{guetterman2019medical}, \cite{kron2017using}, a standard RGB camera (n=1) \cite{dupuy2019virtual}, or by another human (n=2) \cite{banszki2018clinical}, \cite{quail2016student}. In these last two instances, a human located in a separate room controlled both the non-verbal input (by observing the user interacting with the VP) and output (by controlling the gestures and facial expressions of the VP) of the simulation. While this approach may be valid for a single study or an application at the proof-of-concept stage of development, it is clearly inapplicable for a finished product.\par
 %5 VPs feature Voice Controls, two of which \cite{dupuy2019virtual}, \cite{guetterman2019medical} are Closed-Option and not Free-Text. \par
 
 %\subsubsection{Feedback and Gamification}
% Considering the fact that immediate and after-action feedback is cited by many as one of the most important features in communication-based VPs and virtual learning in general \cite{zlotos2016scenario}, \cite{mckimm2006abc}, \cite{albright2018using}, \cite{jacklin2018improving}, \cite{maicher2017developing}, it is surprising that 5 of the considered simulations don't mention any type of feedback inside the simulation. 
 %Three VPs \cite{zlotos2016scenario}, \cite{dupuy2019virtual}, \cite{peddle2019development} offer the possibility, after the simulation is over, to go back and replay certain parts to see different possible outcomes. 
 %MPathic-VR \cite{guetterman2019medical}, \cite{kron2017using} employs a two-run structure, where the first run is envisioned as a learning phase, then, after feedback is given on the learner's performance, a second evaluation run of the same scenario starts immediately.
 %Two simulations \cite{o2019suicide}, \cite{albright2018using} make use of a Virtual Instructor to discuss and give feedback on the user's choices.
 %The VP presented in \cite{albright2018using} features an on-screen trust meter, giving feedback to the user about how effective their communication choices are at building rapport with the patient.
 %Also, gamification (or serious-game) elements are quite uncommon, only 2 simulations \cite{guetterman2019medical}, \cite{dupuy2019virtual} mention any kind of scoring system or timer. Also elements like rankings or any other features that could foster competition are completely absent. Two notable exceptions are \cite{szilas2019virtual} and \cite{adefila2020students}. The former \cite{szilas2019virtual} is a simulation is envisioned as a serious game intended to simulate interactions with Alzheimer patients. The latter \cite{adefila2020students} advances the very peculiar idea of a Tamagotchi-style VP, that needs to be cared for in real time over a two week period. Here caring for the patient, an elederly woman called Hollie, effectively and at regular intervals ensures an improvement of her health conditions, while neglecting her could cause her to die. 
 %Ci sarebbero anche altri dettagli da dire qua, ma visto che non sono particolarmente interessanti direi che uno si può tranquillamente guardare la tabella.
 %\subsection{Technical Design}
 %\subsubsection{Hardware}
 %Mah, non mi sembra che ci siano considerazioni particolarmente interessanti da fare, se uno vuole vedere l'hardware credo basti guardarsi la tabella. E in ogni caso quello che c'era di interessante da dire è già detto in altre sezioni
 %9 simulations in total are Web-Based, so they don't require any particular hardware besides any device with internet capabilities. Standalone applications on the other hand often employ additional devices to maximize immersion and/or presence. 3 VPs are displayed on large monitors \cite{banszki2018clinical}, \cite{dupuy2019virtual}, \cite{quail2016student}, while 4 applications use cameras \cite{dupuy2019virtual}, \cite{}, or Microsoft Kinect \cite{}, \cite{} as sensors to capture the user's non-verbal cues.
 %
   %\subsubsection{Interface}
  %The majority (n=10) of simulations employs real time 3D graphics, 3 use static images and 2 use pre-recorderd live-action videos. A notable outlier is \cite{foster2016using}, which actually compares 3 different VPs, two of which are Text-Based and one features pre-rendered CG videos created with The Sims 3 videogame. The ample use of visual media is coherent with the requirements of VPs focused on narrative aspects and communication, since maximizing immersion and presence is extremely important, and a text-based approach, which can be sufficient for more Problem-Solving oriented VPs, can be too restrictive. While pre-recorded videos (live-action or CG) can be effective, they fall behind in terms of flexibility to simulations presented with real time CG. Tweaking and expanding a real-time 3D application can be done in a much more modular fashion. %non so ste ultime due frasi non mi sono uscite benissimo... non so se si capisce quello che voglio dire.
   %\subsubsection{Web-Based / Standalone}
  %A total of 9 VPs are Web-Based, 5 are standalone applications, one is unclear and one is deployed in both versions. There are advantages and disadvantages to both variants: Web-Based applications are more immediate and accessible, due to the fact that they can be accessed by virtually any device with internet access and are generally less resource-intensive in terms of computational capabilities. This flexibility can also foster self-learning at places and times convenient for the learner. On the other hand standalone applications trade off some of this flexibility with a wider array of possible features, as seen in \cite{maicher2017developing} (the VP deployed in both forms), where the web version forfeits the speech recognition and gesture/posture detection modules.
   %\subsubsection{Other technical features}
   %5 articles \cite{banszki2018clinical}, \cite{maicher2017developing}, \cite{jacklin2018improving}, \cite{guetterman2019medical}, \cite{quail2016student} mention non-verbal output (body posture, facial expression) among the expressive capabilities of their VP, but in two of these \cite{banszki2018clinical}, \cite{quail2016student} the non-verbal cues are piloted by a human and not %by the simulation itself.
   %Non-verbal input and relative devices have already been discussed in the \textbf{Interaction} section above.
   %\cite{dupuy2019virtual} uses the Affectiva software, capable of tracking the face of the user through a webcam and detect their facial expression during the interaction.
   %3 VPs \cite{zlotos2016scenario}, \cite{jacklin2018improving}, \cite{guetterman2019medical}, have recorded voiceover of an actor saying the patient's responses and there is no mention of text-to-speech software in any of the other articles. The same argument that has been made above about video recordings versus real time 3D graphics can be made for recorded voiceover, in the sense that an actor's recording may be more immersive but is definitely less flexible than a procedurally generated audio, making the simulation harder to tweak or expand in successive iterations.
   %2 VPs \cite{zlotos2016scenario}, \cite{maicher2017developing} include motion-captured animations (animations performed by real people). Animations obtained via motion-capture are generally more realistic than hand-crafted ones since they portray nuances of movements not easily reproducible by animation artists, adding to the sense of immersion. 
   %Sta roba del multi-party o multi-NPC o multi-VH che dir si voglia che dico adesso forse è da spostare in una sezione diversa? non fa proprio parte del technical design... spostalo nelle conclusioni
   
  
  %\subsection{Educational Design}
  %Questi due valori non sono riportati in tabella (in ogni caso i dati li abbiamo), banalmente perché non mi bastava lo spazio sulle colonne, in ogni caso le discussioni su questo argomento sono meno interessanti del resto, quindi bisogna prendere delle decisioni su come e quanto parlarne.
  %\subsubsection{Aim?} \edo{scopo dell'articolo in termini di: a chi è rivolto e cosa si vuole verificare, in forse}
  %\subsubsection{User-Target}
  %\edo{TODO?}
   %\subsubsection{Environment}
  %\edo{TODO?}
  %\subsection{Effectiveness}
  %The objective of this article is not to assess the results of studies or gauge the effectiveness of VPs, since this has already been done extensively in literature \cite{citations here}, \cite{citations here}, \cite{citations here}, \cite{citations here}. The general consensus on the usefulness of VP simulations is generally optimistic, and this is confirmed by all of the articles considered in this review, all of which reports effects which are either positive or comparable to other traditional methods (when control groups are present). Also the methodologies and objectives of each articles considered here are quite heterogeneous, ranging from gauging the users' satisfaction \cite{o2019suicide}, to improvement of empathy \cite{foster2016using} \cite{guetterman2019medical} \cite{dupuy2019virtual} \cite{zlotos2016scenario}, to effects on clinical educators rather than students \cite{banszki2018clinical}. \par
 
 
 %Mah, questo paper l'abbiamo cassato alla fine, quindi direi che questo si può eliminare
 %An interesting result reported by one of the examined papers \cite{volante2016effects} is that males are found to be much more empathetic than females towards Virtual Humans. This discovery is was confirmed by objective measurements obtained via an Electro-Dermal Activity sensor applied to the users' wrist in this particular experiment.
Placeholder translation systems enable the users to specify how a specific phrase is translated in the output sentence.
The system is trained to output special placeholder tokens, and the user-specified term is injected into the output through the context-free replacement of the placeholder token.
However, this approach could result in ungrammatical sentences because it is often the case that the specified term needs to be inflected according to the context of the output, which is unknown before the translation.
To address this problem, we propose a novel method of placeholder translation that can inflect specified terms according to the grammatical construction of the output sentence.
We extend the sequence-to-sequence architecture with a character-level decoder that takes the lemma of a user-specified term and the words generated from the word-level decoder to output the correct inflected form of the lemma.
We evaluate our approach with a Japanese-to-English translation task in the scientific writing domain, and show that our model can incorporate specified terms in the correct form more successfully than other comparable models.\footnote{Code is available at \url{https://github.com/Ryou0634/placeholder_translation}.}

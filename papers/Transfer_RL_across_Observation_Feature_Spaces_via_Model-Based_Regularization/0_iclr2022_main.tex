
\documentclass{article} % For LaTeX2e
\usepackage{iclr2022_conference,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}
% \newcommand{\mytitle}{Cross-domain Transfer Reinforcement Learning with Model Regularized Representation}

\usepackage[colorlinks=true,linkcolor=blue,citecolor=green,urlcolor=blue]{hyperref}

\newcommand{\mytitle}
%{Transfer RL across Observation Representations via Model-Based Regularization}
{Transfer RL across Observation Feature Spaces via Model-Based Regularization}
\input{packages}
\include{macros}
% transfer RL, representation learning, model regularized representation, transfer learning between observation representation with model regularization, under changing views? between tasks with different views/observations
\title{\mytitle}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.

\author{
Yanchao Sun\textsuperscript{\dag}\thanks{The work was done while the author was an intern at Unity Technologies. } 
\quad
Ruijie Zheng\textsuperscript{\dag} 
\quad
Xiyao Wang\textsuperscript{\dag} 
\quad
Andrew Cohen\textsuperscript{\ddag}
\quad
Furong Huang\textsuperscript{\dag}  \\
\textsuperscript{\dag} \text{University of Maryland, College Park} \quad
  \textsuperscript{\ddag} Unity Technologies \\
%   \textsuperscript{\rm 3} Institute of Automation, Chinese Academy of Science
%   \qquad 
%   \textsuperscript{\rm 4} Unity Technologies \\
  \textsuperscript{\dag}\texttt{\{ycs,rzheng12,xywang,furongh\}@umd.edu}
%   \\
%   \texttt{\textsuperscript{\rm 3}xiyaowang96@gmail.com}
  \quad
  \textsuperscript{\ddag}\texttt{andrew.cohen@unity3d.com}
}

% \author{Yanchao Sun \\
% University of Maryland\\
% \texttt{ycs@umd.edu} \\
% \And
% Ruijie Zheng \\
% University of Maryland\\
% \texttt{rzheng12@umd.edu} \\
% \And
% Xiyao Wang \\
% Chinese Academy of Science\\
% \texttt{xiyaowang96@gmail.com} \\
% \AND
% Andrew Cohen \\
% Unity Technologies \\
% \texttt{andrew.cohen@unity3d.com}
% \And
% Furong Huang \\
% University of Maryland\\
% \texttt{furongh@umd.edu} \\
% }

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}
\maketitle

\begin{abstract} 
In many reinforcement learning (RL) applications, the observation space is specified by human developers and restricted by physical realizations, and may thus be subject to dramatic changes over time (e.g. increased number of observable features). However, when the observation space changes, the previous policy will likely fail due to the mismatch of input features, and another policy must be trained from scratch, which is inefficient in terms of computation and sample complexity. Following theoretical insights, we propose a novel algorithm which extracts the latent-space dynamics in the source task, and transfers the dynamics model to the target task to use as a model-based regularizer. Our algorithm works for drastic changes of observation space (e.g. from vector-based observation to image-based observation), without any inter-task mapping or any prior knowledge of the target task. Empirical results show that our algorithm significantly improves the efficiency and stability of learning in the target task.
\end{abstract}
% \ac{No mention of theoretical contributions in the abstract}
\input{s1-intro}
\input{s2-prelim}
\input{s3-setup}
\input{s4-method}
\input{s5-related}
\input{s6-exp}
\input{s7-conclusion}
\section*{Acknowledgements}
This work is supported by Unity Technologies, National Science Foundation IIS-1850220 CRII Award 030742-00001, DOD-DARPA-Defense Advanced Research Projects Agency Guaranteeing AI Robustness against Deception (GARD), and Adobe, Capital One and JP Morgan faculty fellowships.
\input{s8-ethics}



\bibliography{references}
\bibliographystyle{iclr2022_conference}

\newpage
\appendix
{\centering{\Large Appendix: \mytitle}}
\input{a0-prelim}
\input{a3-representation}
\input{a1-proofs}
\input{a4-avi}
\input{a2-exp}

\end{document}

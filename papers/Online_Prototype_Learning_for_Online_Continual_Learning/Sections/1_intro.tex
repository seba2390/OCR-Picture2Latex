\section{Introduction}
\label{intro}
Current artificial intelligence systems~\cite{ResNet, DNN, VGG, ViT} have shown excellent performance on the tasks at hand; however, they are prone to forget previously learned knowledge while learning new tasks, known as 
\emph{catastrophic forgetting}~\cite{catastrophic, catastrophic2, EWC}. 
Continual learning (CL)~\cite{survey1, survey2, survey3, CL_CIL1} aims to learn continuously from a non-stationary data stream while adapting to new data and mitigating catastrophic forgetting, offering a promising path to human-like artificial general intelligence.
Early CL works consider the task-incremental learning (TIL) setting, where the model selects the task-specific component for classification with task identifiers~\cite{regular1, kd1, para-iso1, survey3}. However, this setting lacks flexibility in real-world scenarios.
In this paper, we focus on a more general and realistic setting---the class-incremental learning (CIL) in the online CL mode~\cite{online_survey, onlineCL1, onlineCL2, ASER}---where the model learns incrementally classes in a sequence of tasks from a single-pass data stream and cannot access task identifiers at inference.



Various online CL methods have been proposed to mitigate catastrophic forgetting~\cite{ASER, SCR, DVC, online_pro_accum, ER, ER_AML, onlineCL1}. Among them, replay-based methods~\cite{ER,  SCR, OCM, MIR, DVC} have shown promising performance by storing a subset of data from old classes as exemplars for experience replay. 
Unlike previous methods that focus on sample storage~\cite{ASER, GSS},
we are interested in how generalizable the learned features are to new classes, and aim to understand why the online learning models fail to generalize well from a new perspective of shortcut learning.


\input{Figures/Heatmap_firstPage}


Intuitively, the neural network tends to ``take shortcuts''~\cite{shortcut} and focuses on simplistic features.
\textit{This behavior of shortcut learning is especially serious in online CL}, since the model may learn biased and inadequate features from the single-pass data stream.
Specifically, the model may be more inclined to learn trivial solutions \emph{unrelated} to objects, which are hard to generalize and easily forgotten. 
Take Fig.~\ref{fig:heatmap} as an example, when classifying two classes, saying airplanes in the sky and cat on the grass, the model may easily identify the shortcut clue between two classes---blue sky vs. green grass---unfortunately, the learned features are delicate and unrelated to the classes of interest. When new bird and deer classes come, which may also have sky or grass, the model has to be updated due to inapplicable previous knowledge, leading to poor generalization and catastrophic forgetting.
Thus, learning \emph{representative} features that best characterize the class is crucial to resist shortcut learning and catastrophic forgetting, especially in online CL.



In addition, 
the intuitive manifestation of catastrophic forgetting is the confusion between classes. 
To alleviate class confusion, many works~\cite{OCM, kd1, iCaRL, DER++, Co2L, protoAug} employ self-distillation~\cite{kd_work, kd_work2} to preserve previous knowledge.
However, the premise for knowledge distillation to succeed is that the model has learned sufficient discriminative features in old classes, and these features still remain discriminative when learning new classes. As mentioned above, the model may learn  oversimplified features due to shortcut learning, significantly compromising the generalization to new classes.
Thus, distilling these biased features may have an adverse impact on new classes. 
In contrast, we consider a more general paradigm to maintain discrimination among all seen classes, which can tackle the limitations of knowledge distillation.



In this paper, we aim to learn representative features of each class and discriminative features between classes, both crucial to mitigate catastrophic forgetting.
Toward this end, we present the Online Prototype learning (\frameworkName) framework for online continual learning.
The online prototype introduced is defined as ``a representative embedding for a group of instances in a mini-batch.'' There are two reasons for this design: (1) for new classes, the data arrives sequentially from a single-pass stream, and we cannot access all samples of one class at any time step (iteration); and (2) for old classes, computing the prototypes of all samples in the memory bank at each time step is computationally expensive, especially for the online scenario with limited resources. 
Thus, \emph{our online prototypes only utilize the data available at the current time step (\ie, data within a mini-batch), which is more suitable for online CL}. 



To resist shortcut learning in online CL and maintain discrimination among seen classes, we first propose Online Prototype Equilibrium (\methodname) to learn representative and discriminative features for achieving an equilibrium status that separates all seen classes well while learning new classes.
Second, 
instead of employing knowledge distillation that may distill unfaithful knowledge from previous models,
we devise a novel Adaptive Prototypical Feedback (\dataaugname) 
that can leverage the feedback of online prototypes to first sense the classes---that are easily misclassified---and then adaptively enhance their decision boundaries.


The contributions are summarized as follows. 
\begin{enumerate}[leftmargin=12pt, itemsep=0pt, topsep=0pt, partopsep=0pt, noitemsep]
    \item[1)] We identify shortcut learning as the key limiting factor for online CL, where the learned features may be biased, not generalizable to new tasks, and may have an adverse impact on knowledge distillation. To the best of our knowledge, this is the first time to identify the shortcut learning issues in online CL, offering new insights into why online learning models fail to generalize well. 
    \item[2)] We present the online prototype learning framework for online CL, in which the proposed online prototype equilibrium encourages learning representative and discriminative features while adaptive prototypical feedback leverages the feedback of online prototypes to 
    sense easily misclassified classes and enhance their boundaries. 
    \item[3)] Extensive experimental results on widely-used benchmark datasets demonstrate the superior performance of our method over the state-of-the-art baseline methods.
\end{enumerate}


\input{Figures/Framework.tex}



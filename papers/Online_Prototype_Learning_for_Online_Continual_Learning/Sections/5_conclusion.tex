\section{Conclusion}

This paper identifies shortcut learning as the key limiting factor for online CL, where the learned features are biased and not generalizable to new tasks. It also sheds light on why the online learning models fail to generalize well.
Based on these,
we present a novel online prototype learning (OnPro) framework to address shortcut learning and mitigate catastrophic forgetting.
Specifically,
by taking full advantage of introduced online prototypes,
the proposed \methodname aims to learn representative features of each class and discriminative features between classes for achieving an equilibrium status that separates all seen classes well when learning new classes, 
while the proposed \dataaugname is able to sense easily misclassified classes and enhance their decision boundaries with the feedback of online prototypes.
Extensive experimental results on widely-used benchmark datasets validate the effectiveness of the proposed \frameworkName as well as its components.
In the future, we will try more efficient alternatives, such as designing a margin loss to ensure discrimination between classes further.